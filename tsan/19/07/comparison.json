{"files":[{"patch":"@@ -41,1 +41,1 @@\n-  static const uint weak_count = 8 JVMTI_ONLY(+ 1) JFR_ONLY(+ 1);\n+  static const uint weak_count = 8 JVMTI_ONLY(+ 1) JFR_ONLY(+ 1) TSAN_ONLY(+1);\n","filename":"src\/hotspot\/share\/gc\/shared\/oopStorageSet.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+#include \"tsan\/tsanOopMap.hpp\"\n@@ -97,0 +98,4 @@\n+\n+  TSAN_RUNTIME_ONLY(\n+    TsanOopMap::notify_tsan_for_freed_and_moved_objects();\n+  );\n","filename":"src\/hotspot\/share\/gc\/shared\/weakProcessor.inline.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -199,0 +199,1 @@\n+  LOG_TAG(tsan) \\\n","filename":"src\/hotspot\/share\/logging\/logTag.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -130,1 +130,2 @@\n-  TSAN_RUNTIME_ONLY(\n+  \/\/ Allocate weak storage unconditionally if INCLUDE_TSAN is true.\n+  TSAN_ONLY(\n","filename":"src\/hotspot\/share\/runtime\/init.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -39,7 +39,9 @@\n-  TsanIgnoreList::init();\n-  if (__tsan_java_init == NULL) {  \/\/ We always need tsan runtime functions.\n-    vm_shutdown_during_initialization(\"libtsan cannot be located\");\n-    return JNI_ERR;\n-  }\n-  __tsan_java_init((julong)Universe::heap()->reserved_region().start(),\n-                   (julong)Universe::heap()->reserved_region().byte_size());\n+  TSAN_RUNTIME_ONLY(\n+    TsanIgnoreList::init();\n+    if (__tsan_java_init == NULL) {  \/\/ We always need tsan runtime functions.\n+      vm_shutdown_during_initialization(\"libtsan cannot be located\");\n+      return JNI_ERR;\n+    }\n+    __tsan_java_init((julong)Universe::heap()->reserved_region().start(),\n+                     (julong)Universe::heap()->reserved_region().byte_size());\n+  );\n","filename":"src\/hotspot\/share\/tsan\/tsan.cpp","additions":9,"deletions":7,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/shared\/oopStorageSet.hpp\"\n@@ -32,0 +33,1 @@\n+#include \"runtime\/atomic.hpp\"\n@@ -36,0 +38,1 @@\n+#include \"tsan\/tsanOopMapTable.hpp\"\n@@ -37,0 +40,1 @@\n+#include \"utilities\/resizeableResourceHash.hpp\"\n@@ -38,7 +42,0 @@\n-extern \"C\" int jio_printf(const char *fmt, ...);\n-\n-#if 0\n-#define DEBUG_PRINT(...) jio_printf(__VA_ARGS__)\n-#else\n-#define DEBUG_PRINT(...)\n-#endif\n@@ -46,156 +43,0 @@\n-\n-  struct PendingMove {\n-    char *source_begin() const { return source_address; }\n-    char *source_end() const { return source_address + n_bytes; }\n-    char *target_begin() const { return target_address; }\n-    char *target_end() const { return target_address + n_bytes; }\n-    char *source_address;\n-    char *target_address;\n-    size_t n_bytes;  \/\/ number of bytes being moved\n-  };\n-\n-  \/\/ Our data\n-  class TsanOopSizeMap *oop_map = NULL;\n-\n-  \/**\n-   * TsanOopSizeMap is a hash map of {oopDesc * -> size}.\n-   *\/\n-  class TsanOopSizeMap : public CHeapObj<mtInternal> {\n-\n-    class TsanOop : public CHeapObj<mtInternal> {\n-      \/* We track the lifecycle (alloc\/move\/free) of interesting oops;\n-       * tsan needs to know. *\/\n-      oopDesc *_oop;  \/\/ key\n-\n-      \/* We cache the oop's size, since we cannot reliably determine it after\n-       * the oop is freed. Size is measured in number of HeapWords. *\/\n-      uintx _oop_size;  \/\/ value\n-\n-    public:\n-      TsanOop():_oop(NULL), _oop_size(0) {}\n-      void set_oop(oopDesc *o, uintx s) { _oop = o; _oop_size = s; }\n-      bool has_oop() const { return _oop != NULL; }\n-      oopDesc *get_oop() const { return _oop; }\n-      uintx get_oop_size() const { return _oop_size; }\n-    };\n-\n-    size_t _size;\n-    size_t _n_elements;\n-    float _load_factor;\n-    TsanOop *_buckets;\n-\n-    static uintx _hash64(uintx key) {\n-      key = ~key + (key << 21);\n-      key ^= (key >> 24);\n-      key += (key << 3) + (key << 8);\n-      key ^= (key >> 14);\n-      key += (key << 2) + (key << 4);\n-      key ^= (key >> 28);\n-      key += (key << 31);\n-      return key;\n-    }\n-\n-    static uintx _hash32(uintx key) {\n-      key = ~key + (key << 15);\n-      key ^= (key >> 12);\n-      key += (key << 2);\n-      key ^= (key >> 4);\n-      key *= 2057;\n-      key ^= (key >> 16);\n-      return key;\n-    }\n-\n-    TsanOop* find_bucket(oopDesc* o) {\n-      uintx h = reinterpret_cast<uintx>((address)o);\n-      TsanOop* bucket;\n-      do {\n-        h = hash(h);\n-        bucket = &_buckets[h % _size];\n-      } while (bucket->has_oop() && bucket->get_oop() != o);\n-      return bucket;\n-    }\n-\n-    static bool collect_oops(BoolObjectClosure* is_alive,\n-                             OopClosure* f,\n-                             GrowableArray<PendingMove>* moves,\n-                             int* n_downward_moves,\n-                             char** min_low,\n-                             char** max_high);\n-\n-    static void handle_overlapping_moves(GrowableArray<PendingMove>& moves,\n-                                         char* min_low,\n-                                         char* max_high);\n-\n-  public:\n-    TsanOopSizeMap(size_t initial_size)\n-        : _size(initial_size), _n_elements(0), _load_factor(0.7) {\n-      _buckets = new TsanOop[_size];\n-    }\n-\n-    ~TsanOopSizeMap() {\n-      delete [] _buckets;\n-    }\n-\n-    static uintx hash(uintx key) {\n-      return (sizeof(uintx) == 4) ? _hash32(key) : _hash64(key);\n-    }\n-\n-    \/\/ Put an oop and oop size into the hash map.\n-    \/\/ Ok to call multiple times on same oop.\n-    \/\/ Return true if seen for first time; else return false.\n-    \/\/ Synchronized in mutator threads with TsanOopMap_lock.\n-    bool put(oopDesc* o, uintx s) {\n-      TsanOop* bucket = find_bucket(o);\n-\n-      if (!bucket->has_oop()) {\n-        if (++_n_elements > _load_factor * _size) {\n-          grow();\n-          bucket = find_bucket(o);\n-        }\n-        bucket->set_oop(o, s);\n-        return true;\n-      } else {\n-        assert(s == bucket->get_oop_size(), \"same oop should have same size\");\n-        return false;\n-      }\n-    }\n-\n-    void grow(void) {\n-      TsanOop *old_buckets = _buckets;\n-      size_t old_size = _size;\n-      _size *= 2;\n-\n-      _buckets = new TsanOop[_size];\n-\n-      for (uintx i = 0; i < old_size; i++) {\n-        if (old_buckets[i].has_oop()) {\n-          put(old_buckets[i].get_oop(), old_buckets[i].get_oop_size());\n-        }\n-      }\n-      delete [] old_buckets;\n-    }\n-\n-    \/\/ Call this function at the end of the garbage collection to\n-    \/\/ notify TSan about object location changes and to build oops map.\n-    static void rebuild_oops_map(BoolObjectClosure *is_alive,\n-                                 OopClosure *pointer_adjuster);\n-\n-#ifdef ASSERT\n-    bool exists(oopDesc *o) const {\n-      uintx h = reinterpret_cast<uintx>((address)o);\n-      TsanOop *bucket = NULL;\n-\n-      do {\n-        h = hash(h);\n-        bucket = &_buckets[h % _size];\n-      } while (bucket->has_oop() && bucket->get_oop() != o);\n-\n-      return bucket->has_oop() && bucket->get_oop() == o;\n-    }\n-#endif\n-\n-    size_t size() const { return _size; }\n-    oopDesc *oop_at(size_t i) const { return _buckets[i].get_oop(); }\n-    uintx oop_size_at(size_t i) const { return _buckets[i].get_oop_size(); }\n-  };\n-\n@@ -214,2 +55,0 @@\n-  \/\/ TsanOopSizeMap::rebuild_oop_map below uses an instance of this\n-  \/\/ class to order object moves, please see additional comments there.\n@@ -261,87 +100,1 @@\n-  bool TsanOopSizeMap::collect_oops(BoolObjectClosure* is_alive,\n-                                    OopClosure* pointer_adjuster,\n-                                    GrowableArray<PendingMove>* moves,\n-                                    int* n_downward_moves,\n-                                    char** min_low,\n-                                    char** max_high) {\n-    size_t map_size = oop_map->size();\n-\n-    \/\/ Traverse oop map. For each object that survived GC calculate its new\n-    \/\/ oop, add it to the new oop map, and append the move from the source oop\n-    \/\/ to the target one to the moves list. While doing that, collect oop\n-    \/\/ source and target ranges and count the moves that move an object\n-    \/\/ downwards (this is heuristics to order the moves, see below).\n-    TsanOopSizeMap* new_map = new TsanOopSizeMap(map_size \/ 2);\n-    *n_downward_moves = 0;\n-    bool disjoint_regions;\n-    char *source_low = reinterpret_cast<char *>(UINTPTR_MAX);\n-    char *source_high = NULL;\n-    char *target_low = reinterpret_cast<char *>(UINTPTR_MAX);\n-    char *target_high = NULL;\n-    size_t deleted_objects = 0;\n-    size_t unmoved_objects = 0;\n-    size_t total_size_words = 0;\n-    CollectedHeap *heap = Universe::heap();\n-    for (size_t i = 0; i < map_size; i++) {\n-      oopDesc *source_obj = oop_map->oop_at(i);\n-\n-      if (source_obj != NULL && heap->is_in(source_obj)) {\n-        uintx obj_size = oop_map->oop_size_at(i);\n-        size_t obj_size_bytes = obj_size * HeapWordSize;\n-        if (is_alive->do_object_b(source_obj)) {\n-          \/\/ The object survived GC, add its updated oop to the new oops map.\n-          oop target_oop = cast_to_oop((intptr_t)source_obj);\n-          pointer_adjuster->do_oop(&target_oop);\n-          \/\/ The memory pointed by target_oop may not be a valid oop yet,\n-          \/\/ for example the G1 full collector needs to adjust all pointers\n-          \/\/ first, then compacts and moves the objects. In this case\n-          \/\/ TsanOopSizeMap::rebuild_oops_map() is called during the adjust-\n-          \/\/ pointer phase, before the collector moves the objects. Thus,\n-          \/\/ we cannot use heap->is_in() or oopDesc::is_oop() to check\n-          \/\/ target_oop.\n-          assert(heap->is_in(target_oop), \"Adjustment failed\");\n-          oopDesc *target_obj = target_oop;\n-          new_map->put(target_obj, obj_size);\n-          if (target_obj == source_obj) {\n-            ++unmoved_objects;\n-            continue;\n-          }\n-          if (target_obj < source_obj) {\n-            ++(*n_downward_moves);\n-          }\n-          \/\/ Append to the moves list.\n-          PendingMove move = {(char *)source_obj, (char *)target_obj,\n-                              obj_size_bytes};\n-          total_size_words += obj_size;\n-          moves->append(move);\n-\n-          \/\/ Update source and target ranges.\n-          source_low = MIN2(source_low, move.source_begin());\n-          source_high = MAX2(source_high, move.source_end());\n-          target_low = MIN2(target_low, move.target_begin());\n-          target_high = MAX2(target_high, move.target_end());\n-        } else {  \/\/ dead!\n-          __tsan_java_free((char *)source_obj, obj_size_bytes);\n-          ++deleted_objects;\n-        }\n-      }\n-    }\n-\n-    \/\/ Update the oop map.\n-    delete TsanOopMapImpl::oop_map;\n-    TsanOopMapImpl::oop_map = new_map;\n-\n-    disjoint_regions = (source_low >= target_high || source_high <= target_low);\n-    log_debug(gc)(\n-          \"Tsan: map of \" SIZE_FORMAT \" objects, \" SIZE_FORMAT \" deleted, \"\n-          SIZE_FORMAT \" unmoved, \" SIZE_FORMAT \" to move \"\n-          \"(\" SIZE_FORMAT \" words), %soverlap\",\n-          map_size, deleted_objects, unmoved_objects, (size_t)moves->length(),\n-          total_size_words, disjoint_regions ? \"no \" : \"\");\n-\n-    *min_low = MIN2(source_low, target_low);\n-    *max_high = MAX2(source_high, target_high);\n-    return disjoint_regions;\n-  }\n-\n-  void TsanOopSizeMap::handle_overlapping_moves(GrowableArray<PendingMove>& moves,\n+  static void handle_overlapping_moves(GrowableArray<PendingMove>& moves,\n@@ -354,5 +107,4 @@\n-    DEBUG_PRINT(\"%s:%d: %d objects occupying %d words between %p and %p\\n\",\n-                __FUNCTION__, __LINE__, moves.length(),\n-                occupied_memory.bit_count(),\n-                MIN2(source_low, target_low),\n-                MAX2(source_high, target_high));\n+    log_debug(tsan)(\"%s:%d: %d objects occupying %d words between %p and %p\\n\",\n+                    __FUNCTION__, __LINE__, moves.length(),\n+                    occupied_memory.bit_count(),\n+                    min_low, max_high);\n@@ -402,0 +154,3 @@\n+          log_trace(tsan)(\"__tsan_java_move for [\" PTR_FORMAT \", \" PTR_FORMAT  \"] -> [\" PTR_FORMAT \", \" PTR_FORMAT \"]\\n\",\n+                          (uintx)m.source_begin(), (uintx)m.source_end(),\n+                          (uintx)m.target_begin(), (uintx)m.target_end());\n@@ -417,2 +172,2 @@\n-      DEBUG_PRINT(\"%s:%d: %d moved, %d remaining\\n\", __FUNCTION__, __LINE__,\n-                  moves_this_cycle, remaining_moves);\n+      log_debug(tsan)(\"%s:%d: %d moved, %d remaining\\n\", __FUNCTION__, __LINE__,\n+                       moves_this_cycle, remaining_moves);\n@@ -422,46 +177,0 @@\n-\n-  void TsanOopSizeMap::rebuild_oops_map(BoolObjectClosure *is_alive,\n-                                        OopClosure *pointer_adjuster) {\n-    ResourceMark rm;\n-    GrowableArray<PendingMove> moves(MAX2((int)(oop_map->size() \/ 100),\n-                                          100000));\n-    bool disjoint_regions;\n-    int n_downward_moves;\n-    char *min_low, *max_high;\n-\n-    {\n-      disjoint_regions = collect_oops(is_alive, pointer_adjuster, &moves,\n-                                      &n_downward_moves, &min_low, &max_high);\n-    }\n-    if (moves.length() == 0) {\n-      return;\n-    }\n-\n-    \/\/ Notifying TSan is straightforward when source and target regions\n-    \/\/ do not overlap:\n-    if (disjoint_regions) {\n-      for (int i = 0; i < moves.length(); ++i) {\n-        const PendingMove &m = moves.at(i);\n-        __tsan_java_move(m.source_begin(), m.target_begin(), m.n_bytes);\n-      }\n-      return;\n-    }\n-\n-    \/\/ Source and target ranges overlap, the moves need to be ordered to prevent\n-    \/\/ overwriting. Overall, this can take N^2 steps if only one object can be\n-    \/\/ moved during the array traversal; however, when we are dealing with\n-    \/\/ compacting garbage collector, observation shows that the overwhelming\n-    \/\/ majority of the objects move in one direction. If we sort the moves (in\n-    \/\/ the ascending order if dominant direction is downwards, in the descending\n-    \/\/ order otherwise), chances are we will be able to order the moves in a few\n-    \/\/ traversals of the moves array.\n-    {\n-      moves.sort((2 * n_downward_moves > moves.length()) ? lessThan : moreThan);\n-      log_debug(gc)(\"Tsan: sort %d objects\", moves.length());\n-    }\n-\n-    {\n-      handle_overlapping_moves(moves, min_low, max_high);\n-    }\n-  }\n-\n@@ -470,0 +179,2 @@\n+static OopStorage* _weak_oop_storage;\n+static TsanOopMapTable* _oop_map;\n@@ -471,0 +182,2 @@\n+\/\/ This is called with TSAN_ONLY, as we want to always create the weak\n+\/\/ OopStorage so the number matches with the 'weak_count' in oopStorageSet.hpp.\n@@ -472,1 +185,10 @@\n-  TsanOopMapImpl::oop_map = new TsanOopMapImpl::TsanOopSizeMap(512);\n+  \/\/ No need to do register_num_dead_callback for concurrent work as we do\n+  \/\/ TsanOopMapTable cleanup, i.e. removing entries for freed objects during\n+  \/\/ GC by calling TsanOopMap::notify_tsan_for_freed_and_moved_objects() from\n+  \/\/ WeakProcessor.\n+  _weak_oop_storage = OopStorageSet::create_weak(\"Tsan weak OopStorage\", mtInternal);\n+  assert(_weak_oop_storage != nullptr, \"sanity\");\n+\n+  TSAN_RUNTIME_ONLY(\n+    _oop_map = new TsanOopMapTable();\n+  );\n@@ -476,1 +198,1 @@\n-  delete TsanOopMapImpl::oop_map;\n+  delete _oop_map;\n@@ -479,5 +201,17 @@\n-void TsanOopMap::weak_oops_do(\n-    BoolObjectClosure* is_alive,\n-    OopClosure* pointer_adjuster) {\n-  if (!ThreadSanitizer) return;\n-  assert(SafepointSynchronize::is_at_safepoint(), \"must be at a safepoint\");\n+OopStorage* TsanOopMap::oop_storage() {\n+  assert(_weak_oop_storage != NULL, \"sanity\");\n+  return _weak_oop_storage;\n+}\n+\n+\/\/ Called during GC by WeakProcessor.\n+void TsanOopMap::notify_tsan_for_freed_and_moved_objects() {\n+  assert(_oop_map != nullptr, \"must be\");\n+  assert(SafepointSynchronize::is_at_safepoint(), \"must be\");\n+\n+  bool disjoint_regions;\n+  int n_downward_moves = 0;\n+  char *min_low, *max_high;\n+  char *source_low = reinterpret_cast<char *>(UINTPTR_MAX);\n+  char *source_high = NULL;\n+  char *target_low = reinterpret_cast<char *>(UINTPTR_MAX);\n+  char *target_high = NULL;\n@@ -485,7 +219,35 @@\n-  \/\/ We're mutating oopMap, but we don't need to acquire TsanOopMap_lock:\n-  \/\/ Mutation to map happens at (A) constructor (single threaded) and\n-  \/\/ (B) add (in mutator threads) and (C) do_weak_oops (single-threaded).\n-  \/\/ Calls between add are synchronized.\n-  \/\/ Calls between add and do_weak_oops are synchronized via STW GC.\n-  TsanOopMapImpl::TsanOopSizeMap::rebuild_oops_map(\n-      is_alive, pointer_adjuster);\n+  ResourceMark rm;\n+  GrowableArray<TsanOopMapImpl::PendingMove> moves(MAX2((int)(_oop_map->size()), 100000));\n+\n+  {\n+    MutexLocker mu(TsanOopMap_lock, Mutex::_no_safepoint_check_flag);\n+    _oop_map->collect_moved_objects_and_notify_freed(\n+                                 &moves, &source_low, &source_high,\n+                                 &target_low, &target_high,\n+                                 &n_downward_moves);\n+  }\n+\n+  \/\/ No lock is needed after this point.\n+  if (moves.length() != 0) {\n+    \/\/ Notify Tsan about moved objects.\n+    disjoint_regions = (source_low >= target_high || source_high <= target_low);\n+    min_low = MIN2(source_low, target_low);\n+    max_high = MAX2(source_high, target_high);\n+\n+    if (disjoint_regions) {\n+      for (int i = 0; i < moves.length(); ++i) {\n+        const TsanOopMapImpl::PendingMove &m = moves.at(i);\n+        log_trace(tsan)(\"__tsan_java_move for [\" PTR_FORMAT \", \" PTR_FORMAT  \"] -> [\" PTR_FORMAT \", \" PTR_FORMAT \"]\\n\",\n+                        (uintx)m.source_begin(), (uintx)m.source_end(),\n+                        (uintx)m.target_begin(), (uintx)m.target_end());\n+        __tsan_java_move(m.source_begin(), m.target_begin(), m.n_bytes);\n+      }\n+    } else {\n+      \/\/ Source and target ranges overlap, the moves need to be ordered to prevent\n+      \/\/ overwriting. Overall, this can take N^2 steps if only one object can be\n+      \/\/ moved during the array traversal.\n+      moves.sort((2 * n_downward_moves > moves.length()) ?\n+                 TsanOopMapImpl::lessThan : TsanOopMapImpl::moreThan);\n+      handle_overlapping_moves(moves, min_low, max_high);\n+    }\n+  }\n@@ -498,1 +260,1 @@\n-void TsanOopMap::add_oop_with_size(oopDesc *addr, int size) {\n+void TsanOopMap::add_oop_with_size(oopDesc *addr, size_t size) {\n@@ -500,1 +262,1 @@\n-  assert(TsanOopMapImpl::oop_map != NULL, \"TsanOopMap not initialized\");\n+  assert(_oop_map != NULL, \"TsanOopMapTable not initialized\");\n@@ -502,1 +264,1 @@\n-  bool alloc = false;\n+  bool added = false;\n@@ -505,2 +267,1 @@\n-    \/\/ N.B. addr->size() may not be available yet!\n-    alloc = TsanOopMapImpl::oop_map->put(addr, size);\n+    added = _oop_map->add_oop_with_size(addr, size);\n@@ -508,1 +269,3 @@\n-  if (alloc) {\n+  if (added) {\n+    log_trace(tsan)(\"__tsan_java_alloc for: \" PTR_FORMAT \", \" PTR_FORMAT \"\\n\",\n+                    (uintx)addr, (uintx)addr + size * HeapWordSize);\n@@ -514,2 +277,4 @@\n-  \/\/ N.B. oop's size field must be init'ed; else addr->size() crashes.\n-  TsanOopMap::add_oop_with_size(addr, addr->size());\n+  \/\/ We need object size when notify tsan about a freed object.\n+  \/\/ We cannot call size() for an object after it's freed, so we\n+  \/\/ need to save the size information in the table.\n+  add_oop_with_size(addr, addr->size());\n@@ -521,1 +286,1 @@\n-  assert(TsanOopMapImpl::oop_map != NULL, \"TsanOopMap not initialized\");\n+  assert(_oop_map != NULL, \"TsanOopMap not initialized\");\n@@ -523,1 +288,1 @@\n-  bool in_map = false;\n+  size_t oop_size = 0;\n@@ -526,1 +291,1 @@\n-    in_map = TsanOopMapImpl::oop_map->exists(addr);\n+    oop_size = _oop_map->find(addr);\n@@ -528,1 +293,1 @@\n-  return in_map;\n+  return oop_size != 0;\n","filename":"src\/hotspot\/share\/tsan\/tsanOopMap.cpp","additions":96,"deletions":331,"binary":false,"changes":427,"status":"modified"},{"patch":"@@ -29,0 +29,5 @@\n+#include \"tsan\/tsanOopMapTable.hpp\"\n+\n+\/\/ Forward declarations\n+class OopStorage;\n+\n@@ -33,3 +38,0 @@\n-\/\/ The map is implemented as a hash map of oop address to oop size.\n-\/\/ Oop size must be cached, as it is unsafe to call size() after reference is\n-\/\/ collected.\n@@ -42,0 +44,8 @@\n+\/\/\n+\/\/ WeakHandles are used to track Java objects for TSAN (see tsanOopMapTable.hpp\n+\/\/ for details). We create OopStorge for TSAN and WeakHandles used by TsanOopMap\n+\/\/ are allocated from the TSAN OopStorage. Since we need to notify TSAN to\n+\/\/ update TSAN metadata \"in time\" for moved and freed Java objects (before any\n+\/\/ mutators read\/write those), we cannot do that concurrently, e.g. in\n+\/\/ ServiceThread. Instead we process the moved & freed objects and notify\n+\/\/ TSAN a during STW GC pause.\n@@ -48,4 +58,1 @@\n-  \/\/ Called to clean up oops that have been saved in our mapping,\n-  \/\/ but which no longer have other references in the heap.\n-  static void weak_oops_do(BoolObjectClosure* is_alive,\n-                           OopClosure* f);\n+\n@@ -56,1 +63,1 @@\n-  static void add_oop_with_size(oopDesc* addr, int size);\n+  static void add_oop_with_size(oopDesc* addr, size_t size);\n@@ -61,0 +68,5 @@\n+\n+  static OopStorage* oop_storage();\n+\n+  \/\/ Used by GC.\n+  static void notify_tsan_for_freed_and_moved_objects();\n","filename":"src\/hotspot\/share\/tsan\/tsanOopMap.hpp","additions":20,"deletions":8,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -0,0 +1,159 @@\n+\/*\n+ * Copyright (c) 2024, Google and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"tsan\/tsanExternalDecls.hpp\"\n+#include \"tsan\/tsanOopMap.hpp\"\n+#include \"tsan\/tsanOopMapTable.hpp\"\n+\n+TsanOopMapTableKey::TsanOopMapTableKey(oop obj) {\n+  _wh = WeakHandle(TsanOopMap::oop_storage(), obj);\n+  _obj = obj;\n+}\n+\n+TsanOopMapTableKey::TsanOopMapTableKey(const TsanOopMapTableKey& src) {\n+  _wh = src._wh;\n+  _obj = src._obj;\n+}\n+\n+void TsanOopMapTableKey::release_weak_handle() const {\n+  _wh.release(TsanOopMap::oop_storage());\n+}\n+\n+oop TsanOopMapTableKey::object_no_keepalive() const {\n+  return _wh.peek();\n+}\n+\n+void TsanOopMapTableKey::update_obj() {\n+  oop obj = _wh.peek();\n+  if (obj != nullptr && obj != _obj) {\n+    _obj = obj;\n+  }\n+}\n+\n+TsanOopMapTable::TsanOopMapTable() : _table(512, 0x3fffffff) {}\n+\n+void TsanOopMapTable::clear() {\n+  struct RemoveAll {\n+    bool do_entry(const TsanOopMapTableKey & entry, uintx size) {\n+      entry.release_weak_handle();\n+      return true;\n+    }\n+  } remove_all;\n+\n+  _table.unlink(&remove_all);\n+  assert(_table.number_of_entries() == 0, \"invariant\");\n+}\n+\n+TsanOopMapTable::~TsanOopMapTable() {\n+  clear();\n+}\n+\n+bool TsanOopMapTable::add_oop_with_size(oop obj, size_t size) {\n+  TsanOopMapTableKey new_entry(obj);\n+  bool added;\n+  if (obj->fast_no_hash_check()) {\n+    added = _table.put_when_absent(new_entry, size);\n+  } else {\n+    size_t* v = _table.put_if_absent(new_entry, size, &added);\n+    *v = size;\n+  }\n+\n+  if (added) {\n+    if (_table.maybe_grow(true \/* use_large_table_sizes *\/)) {\n+      log_info(tsan)(\"TsanOopMapTable resize to %d, %d entries\",\n+                     _table.table_size(), _table.number_of_entries());\n+    }\n+  }\n+  return added;\n+}\n+\n+#ifdef ASSERT\n+bool TsanOopMapTable::is_empty() {\n+  assert(TsanOopMap_lock->is_locked(), \"sanity check\");\n+  return _table.number_of_entries() == 0;\n+}\n+\n+size_t TsanOopMapTable::find(oop obj) {\n+  if (is_empty()) {\n+    return 0;\n+  }\n+\n+  if (obj->fast_no_hash_check()) {\n+    return 0;\n+  }\n+\n+  TsanOopMapTableKey item(obj);\n+  size_t* size = _table.get(item);\n+  return size == nullptr ? 0 : *size;\n+}\n+#endif\n+\n+\/\/ - Notify Tsan about freed objects.\n+\/\/ - Colllect objects moved bt GC and add a PendingMove for each moved\n+\/\/   objects in a GrowableArray.\n+void TsanOopMapTable::collect_moved_objects_and_notify_freed(\n+         GrowableArray<TsanOopMapImpl::PendingMove> *moves,\n+         char **src_low, char **src_high,\n+         char **dest_low, char **dest_high,\n+         int *n_downward_moves) {\n+  struct IsDead {\n+    GrowableArray<TsanOopMapImpl::PendingMove> *_moves;\n+    char **_src_low;\n+    char **_src_high;\n+    char **_dest_low;\n+    char **_dest_high;\n+    int  *_n_downward_moves;\n+    IsDead(GrowableArray<TsanOopMapImpl::PendingMove> *moves,\n+           char **src_low, char **src_high,\n+           char **dest_low, char **dest_high,\n+           int  *n_downward_moves) : _moves(moves), _src_low(src_low), _src_high(src_high),\n+                                     _dest_low(dest_low), _dest_high(dest_high),\n+                                     _n_downward_moves(n_downward_moves) {}\n+    bool do_entry(TsanOopMapTableKey& entry, uintx size) {\n+      oop wh_obj = entry.object_no_keepalive();\n+      if (wh_obj == nullptr) {\n+        log_trace(tsan)(\"__tsan_java_free for \" PTR_FORMAT \"\\n\", (long unsigned int)entry.obj());\n+        __tsan_java_free((char *)entry.obj(), size * HeapWordSize);\n+        entry.release_weak_handle();\n+        return true;\n+      } else if (wh_obj != entry.obj()) {\n+        TsanOopMapImpl::PendingMove move =\n+          {(char *)entry.obj(), (char *)wh_obj, size * HeapWordSize};\n+        _moves->append(move);\n+        *_src_low = MIN2(*_src_low, move.source_begin());\n+        *_src_high = MAX2(*_src_high, move.source_end());\n+        *_dest_low = MIN2(*_dest_low, move.target_begin());\n+        *_dest_high = MAX2(*_dest_high, move.target_end());\n+        if (*_dest_low < *_src_low) {\n+          ++(*_n_downward_moves);\n+        }\n+\n+        entry.update_obj();\n+      }\n+      return false;\n+    }\n+  } is_dead(moves, src_low, src_high, dest_low, dest_high, n_downward_moves);\n+  _table.unlink(&is_dead);\n+}\n","filename":"src\/hotspot\/share\/tsan\/tsanOopMapTable.cpp","additions":159,"deletions":0,"binary":false,"changes":159,"status":"added"},{"patch":"@@ -0,0 +1,119 @@\n+\/*\n+ * Copyright (c) 2024, Google and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_TSAN_TSANOOPMAPTABLE_HPP\n+#define SHARE_TSAN_TSANOOPMAPTABLE_HPP\n+\n+#include \"gc\/shared\/collectedHeap.hpp\"\n+#include \"memory\/allocation.hpp\"\n+#include \"oops\/oop.inline.hpp\"\n+#include \"oops\/weakHandle.hpp\"\n+#include \"tsan\/tsanOopMap.hpp\"\n+#include \"utilities\/resizeableResourceHash.hpp\"\n+\n+namespace TsanOopMapImpl {\n+\n+  struct PendingMove {\n+    char *source_begin() const { return source_address; }\n+    char *source_end() const { return source_address + n_bytes; }\n+    char *target_begin() const { return target_address; }\n+    char *target_end() const { return target_address + n_bytes; }\n+    char *source_address;\n+    char *target_address;\n+    size_t n_bytes;  \/\/ number of bytes being moved\n+  };\n+\n+}  \/\/ namespace TsanOopMapImpl\n+\n+\/\/ For tracking the lifecycle (alloc\/move\/free) of interesting oops\n+\/\/ that tsan needs to know.\n+class TsanOopMapTableKey : public CHeapObj<mtInternal> {\n+ private:\n+  WeakHandle _wh;\n+\n+  \/\/ Address of the oop tracked by the WeakHandle.\n+  \/\/ After an object is freed, the WeakHandle points to null oop. We\n+  \/\/ need to cache the original oop address for notifying Tsan after\n+  \/\/ the object is freed.\n+  oopDesc *_obj;\n+\n+ public:\n+  TsanOopMapTableKey(oop obj);\n+  TsanOopMapTableKey(const TsanOopMapTableKey& src);\n+  TsanOopMapTableKey& operator=(const TsanOopMapTableKey&) = delete;\n+\n+  void release_weak_handle() const;\n+  oop object_no_keepalive() const;\n+\n+  oop obj() const { return _obj; };\n+  void update_obj();\n+\n+  static unsigned get_hash(const TsanOopMapTableKey& entry) {\n+    assert(entry._obj != nullptr, \"sanity\");\n+    return (unsigned int)entry._obj->identity_hash();\n+  }\n+\n+  static bool equals(const TsanOopMapTableKey& lhs, const TsanOopMapTableKey& rhs) {\n+    oop lhs_obj = lhs._obj != nullptr ? (oop)lhs._obj : lhs.object_no_keepalive();\n+    oop rhs_obj = rhs._obj != nullptr ? (oop)rhs._obj : rhs.object_no_keepalive();\n+    return lhs_obj == rhs_obj;\n+  }\n+};\n+\n+typedef\n+ResizeableResourceHashtable <TsanOopMapTableKey, size_t,\n+                             AnyObj::C_HEAP, mtInternal,\n+                             TsanOopMapTableKey::get_hash,\n+                             TsanOopMapTableKey::equals> RRHT;\n+\n+\/\/ The TsanOopMapTable contains entries of TsanOopMapTableKey:oop_size pairs\n+\/\/ (as key:value). The oop sizes are saved in the table because we need to\n+\/\/ use the size information when notify TSAN about an freed object.\n+class TsanOopMapTable : public CHeapObj<mtInternal> {\n+ private:\n+  RRHT _table;\n+\n+ public:\n+  TsanOopMapTable();\n+  ~TsanOopMapTable();\n+\n+  void clear();\n+\n+  unsigned size() const { return _table.table_size(); };\n+\n+  bool add_oop_with_size(oop obj, size_t size);\n+\n+#ifdef ASSERT\n+  bool   is_empty();\n+  size_t find(oop obj);\n+#endif\n+\n+  void collect_moved_objects_and_notify_freed(\n+           GrowableArray<TsanOopMapImpl::PendingMove> *moves,\n+           char **src_low, char **src_high,\n+           char **dest_low, char **dest_high,\n+           int  *n_downward_moves);\n+};\n+\n+#endif \/\/ SHARE_TSAN_TSANOOPMAPTABLE_HPP\n","filename":"src\/hotspot\/share\/tsan\/tsanOopMapTable.hpp","additions":119,"deletions":0,"binary":false,"changes":119,"status":"added"},{"patch":"@@ -193,0 +193,1 @@\n+          \"called_from_lib:\/libjava.so\\n\"\n@@ -199,1 +200,2 @@\n-          \"race_top:^java.util.concurrent.ConcurrentHashMap\\n\");\n+          \"race_top:^java.util.concurrent.ConcurrentHashMap\\n\"\n+          \"race:^java.util.concurrent.locks\\n\");\n","filename":"src\/java.base\/share\/native\/launcher\/main.c","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"}]}