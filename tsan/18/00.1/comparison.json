{"files":[{"patch":"@@ -2,1 +2,2 @@\n-project=jdk\n+project=tsan\n+repository=tsan\n","filename":".jcheck\/conf","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -784,0 +784,9 @@\n+  # With tsan enabled, process reaper often causes SOE. it makes jtreg test failure.\n+  ifeq ($(INCLUDE_TSAN), true)\n+    ifeq ($(call isTargetCpuArch, aarch64), true)\n+      $1_JTREG_BASIC_OPTIONS += -vmoption:-Djdk.lang.processReaperUseDefaultStackSize=true\n+      $1_JTREG_LAUNCHER_OPTIONS += -Djdk.lang.processReaperUseDefaultStackSize=true\n+      $$(info tsan enabled, process reaper will use default JVM stack size.)\n+    endif\n+  endif\n+\n","filename":"make\/RunTests.gmk","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -294,1 +294,9 @@\n-    if test \"x$OPENJDK_TARGET_OS\" = xaix; then\n+    # Use -Os on aarch64 to work around known llvm issue,\n+    # (see https:\/\/bugs.llvm.org\/show_bug.cgi?id=44581) which makes release build crash in aarch64.\n+    if test \"x$OPENJDK_TARGET_CPU\" = xaarch64; then\n+      C_O_FLAG_HIGHEST_JVM=\"-Os\"\n+      C_O_FLAG_HIGHEST=\"-Os\"\n+      C_O_FLAG_HI=\"-Os\"\n+      C_O_FLAG_NORM=\"-Os\"\n+      C_O_FLAG_DEBUG_JVM=\"\"\n+    elif test \"x$OPENJDK_TARGET_OS\" = xaix; then\n@@ -556,0 +564,6 @@\n+    # Disable experimental isel due to a known issue in llvm-8, which generates wrong debug info.\n+    # (see https:\/\/bugs.llvm.org\/show_bug.cgi?id=40887)\n+    if test \"x$OPENJDK_TARGET_CPU\" = xaarch64; then\n+      TOOLCHAIN_CFLAGS_JVM=\"$TOOLCHAIN_CFLAGS_JVM -fno-experimental-isel\"\n+    fi\n+\n","filename":"make\/autoconf\/flags-cflags.m4","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -49,1 +49,1 @@\n-    serialgc services shenandoahgc static-build vm-structs zero zgc \\\n+    serialgc services shenandoahgc static-build tsan vm-structs zero zgc \\\n@@ -77,0 +77,1 @@\n+m4_define(jvm_feature_desc_tsan, [enable ThreadSanitizer support])\n@@ -328,0 +329,47 @@\n+###############################################################################\n+# Check if the feature 'tsan' is available on this platform.\n+#\n+AC_DEFUN_ONCE([JVM_FEATURES_CHECK_TSAN],\n+[\n+  JVM_FEATURES_CHECK_AVAILABILITY(tsan, [\n+    AC_MSG_CHECKING([if platform is supported by TSAN])\n+    if test \"x$OPENJDK_TARGET_OS\" = \"xlinux\" && \\\n+        (test \"x$OPENJDK_TARGET_CPU\" = \"xx86_64\" || \\\n+         test \"x$OPENJDK_TARGET_CPU\" = \"xaarch64\"); then\n+      AC_MSG_RESULT([yes])\n+    else\n+      AC_MSG_RESULT([no, $OPENJDK_TARGET_OS-$OPENJDK_TARGET_CPU])\n+      AVAILABLE=false\n+    fi\n+  ])\n+])\n+\n+###############################################################################\n+# Support for --<enable|disable>-tsan-launcher flag.\n+#\n+# TODO(tsan-dev): Ideally we should use AC_DEFUN_ONCE. However, with AC_DEFUN_ONCE,\n+# we cannot read variables such as $INCLUDE_TSAN or $JVM_FEATURES_ACTIVE. They would\n+# become empty value.\n+AC_DEFUN([JVM_FEATURES_TSAN_LAUNCHER_FLAG],\n+[\n+  # Add a configure option --<enable|disable>-tsan-launcher to allow\n+  # more control on whether to link TSAN runtime with the launcher.\n+  AC_ARG_ENABLE(tsan-launcher, AS_HELP_STRING(\n+        [--enable-tsan-launcher],\n+        [link tsan runtime with the default JDK launcher. Default is consistent with whether tsan feature is enabled.]))\n+  AC_MSG_CHECKING([if tsan should be linked with JDK launcher])\n+  if test \"x$INCLUDE_TSAN\" = \"xtrue\"; then\n+    if test \"x$enable_tsan_launcher\" = \"xno\"; then\n+      AC_MSG_RESULT([no, forced])\n+      INCLUDE_TSAN=\"false\"\n+    else\n+      AC_MSG_RESULT([yes])\n+    fi\n+  else\n+    AC_MSG_RESULT([no, tsan feature is disabled])\n+    if test \"x$enable_tsan_launcher\" = \"xyes\"; then\n+      AC_MSG_ERROR([--enable-tsan-launcher can only be used when tsan feature is enabled.])\n+    fi\n+  fi\n+])\n+\n@@ -399,0 +447,1 @@\n+  JVM_FEATURES_CHECK_TSAN\n@@ -535,0 +584,3 @@\n+  if ! JVM_FEATURES_IS_ACTIVE(tsan); then\n+    INCLUDE_TSAN=\"false\"\n+  fi\n@@ -561,0 +613,1 @@\n+  INCLUDE_TSAN=\"true\"\n@@ -588,0 +641,2 @@\n+  JVM_FEATURES_TSAN_LAUNCHER_FLAG($INCLUDE_TSAN)\n+\n@@ -598,0 +653,1 @@\n+  AC_SUBST(INCLUDE_TSAN)\n","filename":"make\/autoconf\/jvm-features.m4","additions":57,"deletions":1,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -889,0 +889,1 @@\n+INCLUDE_TSAN:=@INCLUDE_TSAN@\n","filename":"make\/autoconf\/spec.gmk.in","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -79,0 +79,1 @@\n+# INCLUDE_TSAN   If true, pass compiler and linker flags for TSAN.\n@@ -144,0 +145,11 @@\n+  ifeq ($$($1_INCLUDE_TSAN), true)\n+    $1_CFLAGS += -DINCLUDE_TSAN\n+    # TSAN runtime needs to be statically or dynamically linked with the launcher\n+    # instead of libjvm.so, because initialization of TSAN runtime has to happen\n+    # early at program start.\n+    # '-fsanitize=thread' works as a link-only flag for either GCC or Clang.\n+    # With GCC, it dynamically links with libtsan.so; with Clang, it statically\n+    # links the runtime into the launcher's executable.\n+    $1_LDFLAGS += -fsanitize=thread\n+  endif\n+\n","filename":"make\/common\/modules\/LauncherCommon.gmk","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+TsanSymbolize\n","filename":"make\/data\/hotspot-symbols\/symbols-shared","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -138,0 +138,1 @@\n+JVM_GetTsanEnabled\n","filename":"make\/data\/hotspot-symbols\/symbols-unix","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -166,0 +166,5 @@\n+ifneq ($(call check-jvm-feature, tsan), true)\n+  JVM_CFLAGS_FEATURES += -DINCLUDE_TSAN=0\n+  JVM_EXCLUDE_PATTERNS += tsan\n+endif\n+\n","filename":"make\/hotspot\/lib\/JvmFeatures.gmk","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+    INCLUDE_TSAN := $(INCLUDE_TSAN), \\\n","filename":"make\/modules\/java.base\/Launcher.gmk","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -155,0 +155,4 @@\n+ifeq ($(INCLUDE_TSAN), true)\n+  LIBJLI_CFLAGS += -DINCLUDE_TSAN\n+endif\n+\n","filename":"make\/modules\/java.base\/lib\/CoreLibraries.gmk","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -861,0 +861,7 @@\n+\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_CFLAGS_libAbstractNativeLoop := -fsanitize=thread\n+  ifeq ($(TOOLCHAIN_TYPE), gcc)\n+    # Ignore unresolved symbols from TSAN's runtime.\n+    # The symbols will be available at runtime as TSAN runtime is linked with the launcher.\n+    BUILD_HOTSPOT_JTREG_LIBRARIES_LDFLAGS_libAbstractNativeLoop := -Wl,--unresolved-symbols=ignore-in-object-files\n+  endif\n","filename":"make\/test\/JtregNativeHotspot.gmk","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -733,0 +733,3 @@\n+\n+  TSAN_RUNTIME_ONLY(push_ptr(lock_reg));\n+\n@@ -835,0 +838,9 @@\n+\n+  TSAN_RUNTIME_ONLY(\n+    pop_ptr(lock_reg);\n+    pusha();\n+    call_VM(noreg,\n+            CAST_FROM_FN_PTR(address, SharedRuntime::tsan_interp_lock),\n+            lock_reg);\n+    popa();\n+  );\n@@ -853,0 +865,8 @@\n+  TSAN_RUNTIME_ONLY(\n+    pusha();\n+    call_VM(noreg,\n+            CAST_FROM_FN_PTR(address, SharedRuntime::tsan_interp_unlock),\n+            lock_reg);\n+    popa();\n+  );\n+\n@@ -1548,0 +1568,4 @@\n+  TSAN_RUNTIME_ONLY(call_VM(noreg,\n+                            CAST_FROM_FN_PTR(address,\n+                            SharedRuntime::tsan_interp_method_entry)));\n+\n@@ -1581,0 +1605,7 @@\n+  TSAN_RUNTIME_ONLY(\n+    push(state);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address,\n+                 SharedRuntime::tsan_interp_method_exit));\n+    pop(state);\n+  );\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":31,"deletions":0,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -1743,0 +1743,9 @@\n+  TSAN_RUNTIME_ONLY(\n+    \/\/ protect the args we've loaded\n+    save_args(masm, total_c_args, c_arg, out_regs);\n+    __ call_VM(noreg,\n+      CAST_FROM_FN_PTR(address, SharedRuntime::tsan_interp_method_entry),\n+      rthread);\n+    restore_args(masm, total_c_args, c_arg, out_regs);\n+  );\n+\n@@ -1821,0 +1830,8 @@\n+\n+    TSAN_RUNTIME_ONLY(\n+      __ pusha();\n+      __ call_VM(noreg,\n+                 CAST_FROM_FN_PTR(address, SharedRuntime::tsan_oop_lock),\n+                 obj_reg);\n+      __ popa();\n+    );\n@@ -1922,0 +1939,8 @@\n+    TSAN_RUNTIME_ONLY(\n+      __ pusha();\n+      __ call_VM(noreg,\n+                 CAST_FROM_FN_PTR(address, SharedRuntime::tsan_oop_unlock),\n+                 obj_reg);\n+      __ popa();\n+    );\n+\n@@ -1969,0 +1994,7 @@\n+  TSAN_RUNTIME_ONLY(\n+    save_native_result(masm, ret_type, stack_slots);\n+    __ call_VM_leaf(\n+         CAST_FROM_FN_PTR(address, SharedRuntime::tsan_interp_method_exit));\n+    restore_native_result(masm, ret_type, stack_slots);\n+  );\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":32,"deletions":0,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -753,0 +753,81 @@\n+#if INCLUDE_TSAN\n+\n+void TemplateTable::tsan_observe_load_or_store(const Address& field,\n+                                               TsanMemoryReadWriteFunction tsan_function) {\n+  assert(ThreadSanitizer, \"ThreadSanitizer should be set\");\n+  if (!ThreadSanitizerJavaMemory) {\n+    return;\n+  }\n+\n+  __ pusha();\n+  __ push_d(v0);\n+  __ lea(c_rarg0, field);\n+  __ get_method(c_rarg1);\n+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, tsan_function),\n+                  c_rarg0 \/* addr *\/, c_rarg1 \/* method *\/, rbcp \/* bcp *\/);\n+  __ pop_d(v0);\n+  __ popa();\n+}\n+\n+void TemplateTable::tsan_observe_get_or_put(const Address &field,\n+                                            Register flags,\n+                                            TsanMemoryReadWriteFunction tsan_function,\n+                                            TosState tos) {\n+  assert(ThreadSanitizer, \"ThreadSanitizer should be set\");\n+\n+  TsanMemoryReleaseAcquireFunction releaseAcquireFunction =\n+      tsan_release_acquire_method(tsan_function);\n+\n+  Label done, notAcquireRelease;\n+\n+  \/\/ We could save some instructions by only saving the registers we need.\n+  __ pusha();\n+  \/\/ pusha() doesn't save v0, which tsan_function clobbers and the\n+  \/\/ interpreter still needs.\n+  \/\/ This really only needs to be done for some of the float\/double accesses,\n+  \/\/ but it's here because it's cleaner.\n+  __ push_d(v0);\n+  \/\/ For volatile reads\/writes use an acquire\/release.\n+  \/\/ If a reference is annotated to be ignored, assume it's safe to\n+  \/\/ access the object it's referring to and create a happens-before relation\n+  \/\/ between the accesses to this reference.\n+  if (tos == atos) {\n+    int32_t acquire_release_mask = 1 << ConstantPoolCacheEntry::is_volatile_shift |\n+      1 << ConstantPoolCacheEntry::is_tsan_ignore_shift;\n+    \/\/ acquire_release_mask (0x8200000) can not be encoded into 'tst', but it can be\n+    \/\/ encoded into just one 'mov' instruction.\n+    __ mov(rscratch1, acquire_release_mask);\n+    __ tst(flags, rscratch1);\n+    __ br(Assembler::EQ, notAcquireRelease);\n+  } else {\n+    __ tbz(flags, ConstantPoolCacheEntry::is_volatile_shift, notAcquireRelease);\n+  }\n+\n+  __ lea(c_rarg0, field);\n+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, releaseAcquireFunction), c_rarg0);\n+  if (ThreadSanitizerJavaMemory) {\n+    __ b(done);\n+    __ bind(notAcquireRelease);\n+\n+    \/\/ Ignore reads\/writes to final fields. They can't be racy.\n+    __ tbnz(flags, ConstantPoolCacheEntry::is_final_shift, done);\n+\n+    \/\/ Don't report races on tsan ignored fields.\n+    __ tbnz(flags, ConstantPoolCacheEntry::is_tsan_ignore_shift, done);\n+\n+    __ lea(c_rarg0, field);\n+    __ get_method(c_rarg1);\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, tsan_function),\n+                    c_rarg0 \/* addr *\/, c_rarg1 \/* method *\/, rbcp \/* bcp *\/);\n+\n+    __ bind(done);\n+  } else {\n+    __ bind(notAcquireRelease);\n+  }\n+  __ pop_d(v0);\n+  __ popa();\n+}\n+\n+\n+#endif\n+\n@@ -762,1 +843,3 @@\n-  __ access_load_at(T_INT, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(2)), noreg, noreg);\n+  Address addr(r0, r1, Address::uxtw(2));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read4));\n+  __ access_load_at(T_INT, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);\n@@ -774,1 +857,3 @@\n-  __ access_load_at(T_LONG, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(3)), noreg, noreg);\n+  Address addr(r0, r1, Address::uxtw(3));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read8));\n+  __ access_load_at(T_LONG, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);\n@@ -786,1 +871,3 @@\n-  __ access_load_at(T_FLOAT, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(2)), noreg, noreg);\n+  Address addr(r0, r1, Address::uxtw(2));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read4));\n+  __ access_load_at(T_FLOAT, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);\n@@ -798,1 +885,3 @@\n-  __ access_load_at(T_DOUBLE, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(3)), noreg, noreg);\n+  Address addr(r0, r1, Address::uxtw(3));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read8));\n+  __ access_load_at(T_DOUBLE, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);\n@@ -810,4 +899,4 @@\n-  do_oop_load(_masm,\n-              Address(r0, r1, Address::uxtw(LogBytesPerHeapOop)),\n-              r0,\n-              IS_ARRAY);\n+  Address addr(r0, r1, Address::uxtw(LogBytesPerHeapOop));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, UseCompressedOops ? SharedRuntime::tsan_read4\n+                                                                       : SharedRuntime::tsan_read8));\n+  do_oop_load(_masm, addr, r0, IS_ARRAY);\n@@ -825,1 +914,3 @@\n-  __ access_load_at(T_BYTE, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(0)), noreg, noreg);\n+  Address addr(r0, r1, Address::uxtw(0));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read1));\n+  __ access_load_at(T_BYTE, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);\n@@ -837,1 +928,3 @@\n-  __ access_load_at(T_CHAR, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(1)), noreg, noreg);\n+  Address addr(r0, r1, Address::uxtw(1));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read2));\n+  __ access_load_at(T_CHAR, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);\n@@ -843,0 +936,3 @@\n+#ifdef ASSERT\n+  TSAN_RUNTIME_ONLY(__ stop(\"bytecode rewrite should have been disabled in TSAN\"););\n+#endif\n@@ -866,1 +962,3 @@\n-  __ access_load_at(T_SHORT, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(1)), noreg, noreg);\n+  Address addr(r0, r1, Address::uxtw(1));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read2));\n+  __ access_load_at(T_SHORT, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);\n@@ -1060,1 +1158,3 @@\n-  __ access_store_at(T_INT, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(2)), r0, noreg, noreg, noreg);\n+  Address addr(r3, r1, Address::uxtw(2));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write4));\n+  __ access_store_at(T_INT, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg, noreg);\n@@ -1072,1 +1172,3 @@\n-  __ access_store_at(T_LONG, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(3)), r0, noreg, noreg, noreg);\n+  Address addr(r3, r1, Address::uxtw(3));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write8));\n+  __ access_store_at(T_LONG, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg, noreg);\n@@ -1084,1 +1186,3 @@\n-  __ access_store_at(T_FLOAT, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(2)), noreg \/* ftos *\/, noreg, noreg, noreg);\n+  Address addr(r3, r1, Address::uxtw(2));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write4));\n+  __ access_store_at(T_FLOAT, IN_HEAP | IS_ARRAY, addr, noreg \/* ftos *\/, noreg, noreg, noreg);\n@@ -1096,1 +1200,3 @@\n-  __ access_store_at(T_DOUBLE, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(3)), noreg \/* dtos *\/, noreg, noreg, noreg);\n+  Address addr(r3, r1, Address::uxtw(3));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write8));\n+  __ access_store_at(T_DOUBLE, IN_HEAP | IS_ARRAY, addr, noreg \/* dtos *\/, noreg, noreg, noreg);\n@@ -1111,1 +1217,3 @@\n-\n+  \/\/ do tsan write after r4 has been defined.\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(element_address, UseCompressedOops ? SharedRuntime::tsan_write4\n+                                                                                  : SharedRuntime::tsan_write8));\n@@ -1173,1 +1281,3 @@\n-  __ access_store_at(T_BYTE, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(0)), r0, noreg, noreg, noreg);\n+  Address addr(r3, r1, Address::uxtw(0));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write1));\n+  __ access_store_at(T_BYTE, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg, noreg);\n@@ -1186,1 +1296,3 @@\n-  __ access_store_at(T_CHAR, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(1)), r0, noreg, noreg, noreg);\n+  Address addr(r3, r1, Address::uxtw(1));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write2));\n+  __ access_store_at(T_CHAR, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg, noreg);\n@@ -2306,0 +2418,10 @@\n+    TSAN_RUNTIME_ONLY(\n+      \/\/ Draw a happens-before edge from the class's static initializer to\n+      \/\/ this lookup.\n+      __ pusha();\n+      __ mov(c_rarg0, obj);\n+      __ call_VM_leaf(CAST_FROM_FN_PTR(address,\n+                                       SharedRuntime::tsan_acquire),\n+                                       c_rarg0);\n+      __ popa();\n+    );\n@@ -2510,0 +2632,1 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read1, btos));\n@@ -2523,0 +2646,1 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read1, ztos));\n@@ -2536,0 +2660,5 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field,\n+                                            raw_flags,\n+                                            UseCompressedOops ? SharedRuntime::tsan_read4\n+                                                              : SharedRuntime::tsan_read8,\n+                                            atos));\n@@ -2547,0 +2676,1 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read4, itos));\n@@ -2559,0 +2689,1 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read2, ctos));\n@@ -2571,0 +2702,1 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read2, stos));\n@@ -2583,0 +2715,1 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read8, ltos));\n@@ -2595,0 +2728,1 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read4, ftos));\n@@ -2609,0 +2743,1 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read8, dtos));\n@@ -2716,0 +2851,1 @@\n+  \/\/ save raw flags in r5\n@@ -2745,0 +2881,1 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write1, btos));\n@@ -2760,0 +2897,1 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write1, ztos));\n@@ -2775,0 +2913,5 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field,\n+                                              r5,\n+                                              UseCompressedOops ? SharedRuntime::tsan_write4\n+                                                                : SharedRuntime::tsan_write8,\n+                                              atos));\n@@ -2791,0 +2934,1 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write4, itos));\n@@ -2806,0 +2950,1 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write2, ctos));\n@@ -2821,0 +2966,1 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write2, stos));\n@@ -2836,0 +2982,1 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write8, ltos));\n@@ -2851,0 +2998,1 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write4, ftos));\n@@ -2868,0 +3016,1 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write8, dtos));\n@@ -3041,0 +3190,3 @@\n+#ifdef ASSERT\n+  TSAN_RUNTIME_ONLY(__ stop(\"bytecode rewrite should have been disabled in TSAN\"););\n+#endif\n@@ -3134,0 +3286,3 @@\n+#ifdef ASSERT\n+  TSAN_RUNTIME_ONLY(__ stop(\"bytecode rewrite should have been disabled in TSAN\"););\n+#endif\n@@ -3600,0 +3755,8 @@\n+\n+     TSAN_RUNTIME_ONLY(\n+      \/\/ return value of new oop is in r0.\n+      __ push(atos);\n+      __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::tsan_track_obj), r0);\n+      __ pop(atos);\n+    );\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":181,"deletions":18,"binary":false,"changes":199,"status":"modified"},{"patch":"@@ -1199,0 +1199,1 @@\n+  TSAN_RUNTIME_ONLY(push_ptr(lock_reg));\n@@ -1308,0 +1309,9 @@\n+\n+  TSAN_RUNTIME_ONLY(\n+    pop_ptr(lock_reg);\n+    pusha();\n+    call_VM(noreg,\n+            CAST_FROM_FN_PTR(address, SharedRuntime::tsan_interp_lock),\n+            lock_reg);\n+    popa();\n+  );\n@@ -1327,0 +1337,8 @@\n+  TSAN_RUNTIME_ONLY(\n+    pusha();\n+    call_VM(noreg,\n+            CAST_FROM_FN_PTR(address, SharedRuntime::tsan_interp_unlock),\n+            lock_reg);\n+    popa();\n+  );\n+\n@@ -2058,0 +2076,4 @@\n+  TSAN_RUNTIME_ONLY(call_VM(noreg,\n+                            CAST_FROM_FN_PTR(address,\n+                                             SharedRuntime::tsan_interp_method_entry)));\n+\n@@ -2095,0 +2117,7 @@\n+  TSAN_RUNTIME_ONLY(\n+    push(state);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address,\n+                                  SharedRuntime::tsan_interp_method_exit));\n+    pop(state);\n+  );\n+\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":29,"deletions":0,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -2114,0 +2114,9 @@\n+  TSAN_RUNTIME_ONLY(\n+    \/\/ protect the args we've loaded\n+    save_args(masm, total_c_args, c_arg, out_regs);\n+    __ call_VM(noreg,\n+      CAST_FROM_FN_PTR(address, SharedRuntime::tsan_interp_method_entry),\n+      r15_thread);\n+    restore_args(masm, total_c_args, c_arg, out_regs);\n+  );\n+\n@@ -2196,0 +2205,8 @@\n+\n+    TSAN_RUNTIME_ONLY(\n+      __ pusha();\n+      __ call_VM(noreg,\n+                 CAST_FROM_FN_PTR(address, SharedRuntime::tsan_oop_lock),\n+                 obj_reg);\n+      __ popa();\n+    );\n@@ -2302,0 +2319,8 @@\n+    TSAN_RUNTIME_ONLY(\n+      __ pusha();\n+      __ call_VM(noreg, CAST_FROM_FN_PTR(address,\n+                                         SharedRuntime::tsan_oop_unlock),\n+                 obj_reg);\n+      __ popa();\n+    );\n+\n@@ -2346,0 +2371,8 @@\n+\n+  TSAN_RUNTIME_ONLY(\n+    save_native_result(masm, ret_type, stack_slots);\n+    __ call_VM_leaf(\n+         CAST_FROM_FN_PTR(address, SharedRuntime::tsan_interp_method_exit));\n+    restore_native_result(masm, ret_type, stack_slots);\n+  );\n+\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":33,"deletions":0,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -771,0 +771,97 @@\n+#if INCLUDE_TSAN\n+\n+void TemplateTable::tsan_observe_get_or_put(\n+    const Address &field,\n+    Register flags,\n+    TsanMemoryReadWriteFunction tsan_function,\n+    TosState tos) {\n+  assert(flags == rdx, \"flags should be in rdx register\");\n+  assert(ThreadSanitizer, \"ThreadSanitizer should be set\");\n+\n+  TsanMemoryReleaseAcquireFunction releaseAcquireFunction =\n+      tsan_release_acquire_method(tsan_function);\n+\n+  Label done, notAcquireRelease;\n+\n+  \/\/ We could save some instructions by only saving the registers we need.\n+  __ pusha();\n+  \/\/ pusha() doesn't save xmm0, which tsan_function clobbers and the\n+  \/\/ interpreter still needs.\n+  \/\/ This really only needs to be done for some of the float\/double accesses,\n+  \/\/ but it's here because it's cleaner.\n+  __ push_d(xmm0);\n+  DEBUG_ONLY(\n+    __ pusha();\n+    __ movptr(c_rarg0, field.base());\n+    __ leaq(c_rarg1, field);\n+    __ subq(c_rarg1, field.base());\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::verify_oop_index),\n+                    c_rarg0 \/* oop *\/, c_rarg1 \/* index *\/);\n+    __ popa();\n+  );\n+  \/\/ For volatile reads\/writes use an acquire\/release.\n+  \/\/ If a reference is annotated to be ignored, assume it's safe to\n+  \/\/ access the object it's referring to and create a happens-before relation\n+  \/\/ between the accesses to this reference.\n+  int32_t acquire_release_mask = 1 << ConstantPoolCacheEntry::is_volatile_shift |\n+      ((tos == atos) ? 1 << ConstantPoolCacheEntry::is_tsan_ignore_shift : 0);\n+  __ testl(flags, acquire_release_mask);\n+  __ jcc(Assembler::zero, notAcquireRelease);\n+\n+  __ leaq(c_rarg0, field);\n+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, releaseAcquireFunction), c_rarg0);\n+  if (ThreadSanitizerJavaMemory) {\n+    __ jmp(done);\n+\n+    __ bind(notAcquireRelease);\n+    \/\/ Ignore reads\/writes to final fields. They can't be racy.\n+    int32_t ignore_mask = 1 << ConstantPoolCacheEntry::is_final_shift |\n+        1 << ConstantPoolCacheEntry::is_tsan_ignore_shift;\n+    __ testl(flags, ignore_mask);\n+    __ jcc(Assembler::notZero, done);\n+\n+    __ leaq(c_rarg0, field);\n+    __ get_method(c_rarg1);\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, tsan_function),\n+                    c_rarg0 \/* addr *\/, c_rarg1 \/* method *\/, rbcp \/* bcp *\/);\n+\n+    __ bind(done);\n+  } else {\n+    __ bind(notAcquireRelease);\n+  }\n+  __ pop_d(xmm0);\n+  __ popa();\n+}\n+\n+void TemplateTable::tsan_observe_load_or_store(\n+    const Address& field, TsanMemoryReadWriteFunction tsan_function) {\n+  assert(ThreadSanitizer, \"ThreadSanitizer should be set\");\n+  if (!ThreadSanitizerJavaMemory) {\n+    return;\n+  }\n+  \/\/ We could save some instructions by only saving the registers we need.\n+  __ pusha();\n+  \/\/ pusha() doesn't save xmm0, which tsan_function clobbers and the\n+  \/\/ interpreter still needs.\n+  \/\/ This really only needs to be done for some of the float\/double accesses,\n+  \/\/ but it's here because it's cleaner.\n+  __ push_d(xmm0);\n+  DEBUG_ONLY(\n+    __ pusha();\n+    __ movptr(c_rarg0, field.base());\n+    __ leaq(c_rarg1, field);\n+    __ subq(c_rarg1, field.base());\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::verify_oop_index),\n+                    c_rarg0 \/* oop *\/, c_rarg1 \/* index *\/);\n+    __ popa();\n+  );\n+  __ leaq(c_rarg0, field);\n+  __ get_method(c_rarg1);\n+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, tsan_function),\n+                  c_rarg0 \/* addr *\/, c_rarg1 \/* method *\/, rbcp \/* bcp *\/);\n+  __ pop_d(xmm0);\n+  __ popa();\n+}\n+\n+#endif  \/\/ INCLUDE_TSAN\n+\n@@ -776,4 +873,4 @@\n-  __ access_load_at(T_INT, IN_HEAP | IS_ARRAY, rax,\n-                    Address(rdx, rax, Address::times_4,\n-                            arrayOopDesc::base_offset_in_bytes(T_INT)),\n-                    noreg, noreg);\n+  Address addr(rdx, rax, Address::times_4,\n+               arrayOopDesc::base_offset_in_bytes(T_INT));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read4));\n+  __ access_load_at(T_INT, IN_HEAP | IS_ARRAY, rax, addr, noreg, noreg);\n@@ -789,4 +886,5 @@\n-  __ access_load_at(T_LONG, IN_HEAP | IS_ARRAY, noreg \/* ltos *\/,\n-                    Address(rdx, rbx, Address::times_8,\n-                            arrayOopDesc::base_offset_in_bytes(T_LONG)),\n-                    noreg, noreg);\n+  Address addr(rdx, rbx, Address::times_8,\n+               arrayOopDesc::base_offset_in_bytes(T_LONG));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read8));\n+  __ access_load_at(T_LONG, IN_HEAP | IS_ARRAY, noreg \/* ltos *\/, addr, noreg,\n+                    noreg);\n@@ -802,5 +900,5 @@\n-  __ access_load_at(T_FLOAT, IN_HEAP | IS_ARRAY, noreg \/* ftos *\/,\n-                    Address(rdx, rax,\n-                            Address::times_4,\n-                            arrayOopDesc::base_offset_in_bytes(T_FLOAT)),\n-                    noreg, noreg);\n+  Address addr(rdx, rax, Address::times_4,\n+               arrayOopDesc::base_offset_in_bytes(T_FLOAT));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read4));\n+  __ access_load_at(T_FLOAT, IN_HEAP | IS_ARRAY, noreg \/* ftos *\/, addr, noreg,\n+                    noreg);\n@@ -814,5 +912,5 @@\n-  __ access_load_at(T_DOUBLE, IN_HEAP | IS_ARRAY, noreg \/* dtos *\/,\n-                    Address(rdx, rax,\n-                            Address::times_8,\n-                            arrayOopDesc::base_offset_in_bytes(T_DOUBLE)),\n-                    noreg, noreg);\n+  Address addr(rdx, rax, Address::times_8,\n+               arrayOopDesc::base_offset_in_bytes(T_DOUBLE));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read8));\n+  __ access_load_at(T_DOUBLE, IN_HEAP | IS_ARRAY, noreg \/* dtos *\/, addr, noreg,\n+                    noreg);\n@@ -826,6 +924,7 @@\n-  do_oop_load(_masm,\n-              Address(rdx, rax,\n-                      UseCompressedOops ? Address::times_4 : Address::times_ptr,\n-                      arrayOopDesc::base_offset_in_bytes(T_OBJECT)),\n-              rax,\n-              IS_ARRAY);\n+  Address addr(rdx, rax,\n+               UseCompressedOops ? Address::times_4 : Address::times_ptr,\n+               arrayOopDesc::base_offset_in_bytes(T_OBJECT));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(\n+      addr, UseCompressedOops ? SharedRuntime::tsan_read4\n+                              : SharedRuntime::tsan_read8));\n+  do_oop_load(_masm, addr, rax, IS_ARRAY);\n@@ -839,3 +938,4 @@\n-  __ access_load_at(T_BYTE, IN_HEAP | IS_ARRAY, rax,\n-                    Address(rdx, rax, Address::times_1, arrayOopDesc::base_offset_in_bytes(T_BYTE)),\n-                    noreg, noreg);\n+  Address addr(rdx, rax, Address::times_1,\n+               arrayOopDesc::base_offset_in_bytes(T_BYTE));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read1));\n+  __ access_load_at(T_BYTE, IN_HEAP | IS_ARRAY, rax, addr, noreg, noreg);\n@@ -849,3 +949,4 @@\n-  __ access_load_at(T_CHAR, IN_HEAP | IS_ARRAY, rax,\n-                    Address(rdx, rax, Address::times_2, arrayOopDesc::base_offset_in_bytes(T_CHAR)),\n-                    noreg, noreg);\n+  Address addr(rdx, rax, Address::times_2,\n+               arrayOopDesc::base_offset_in_bytes(T_CHAR));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read2));\n+  __ access_load_at(T_CHAR, IN_HEAP | IS_ARRAY, rax, addr, noreg, noreg);\n@@ -875,3 +976,4 @@\n-  __ access_load_at(T_SHORT, IN_HEAP | IS_ARRAY, rax,\n-                    Address(rdx, rax, Address::times_2, arrayOopDesc::base_offset_in_bytes(T_SHORT)),\n-                    noreg, noreg);\n+  Address addr(rdx, rax, Address::times_2,\n+               arrayOopDesc::base_offset_in_bytes(T_SHORT));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read2));\n+  __ access_load_at(T_SHORT, IN_HEAP | IS_ARRAY, rax, addr, noreg, noreg);\n@@ -1069,4 +1171,4 @@\n-  __ access_store_at(T_INT, IN_HEAP | IS_ARRAY,\n-                     Address(rdx, rbx, Address::times_4,\n-                             arrayOopDesc::base_offset_in_bytes(T_INT)),\n-                     rax, noreg, noreg, noreg);\n+  Address addr(rdx, rbx, Address::times_4,\n+               arrayOopDesc::base_offset_in_bytes(T_INT));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write4));\n+  __ access_store_at(T_INT, IN_HEAP | IS_ARRAY, addr, rax, noreg, noreg, noreg);\n@@ -1083,4 +1185,5 @@\n-  __ access_store_at(T_LONG, IN_HEAP | IS_ARRAY,\n-                     Address(rcx, rbx, Address::times_8,\n-                             arrayOopDesc::base_offset_in_bytes(T_LONG)),\n-                     noreg \/* ltos *\/, noreg, noreg, noreg);\n+  Address addr(rcx, rbx, Address::times_8,\n+               arrayOopDesc::base_offset_in_bytes(T_LONG));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write8));\n+  __ access_store_at(T_LONG, IN_HEAP | IS_ARRAY, addr, noreg \/* ltos *\/, noreg,\n+                     noreg, noreg);\n@@ -1097,4 +1200,5 @@\n-  __ access_store_at(T_FLOAT, IN_HEAP | IS_ARRAY,\n-                     Address(rdx, rbx, Address::times_4,\n-                             arrayOopDesc::base_offset_in_bytes(T_FLOAT)),\n-                     noreg \/* ftos *\/, noreg, noreg, noreg);\n+  Address addr(rdx, rbx, Address::times_4,\n+               arrayOopDesc::base_offset_in_bytes(T_FLOAT));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write4));\n+  __ access_store_at(T_FLOAT, IN_HEAP | IS_ARRAY, addr, noreg \/* ftos *\/, noreg,\n+                     noreg, noreg);\n@@ -1110,4 +1214,5 @@\n-  __ access_store_at(T_DOUBLE, IN_HEAP | IS_ARRAY,\n-                     Address(rdx, rbx, Address::times_8,\n-                             arrayOopDesc::base_offset_in_bytes(T_DOUBLE)),\n-                     noreg \/* dtos *\/, noreg, noreg, noreg);\n+  Address addr(rdx, rbx, Address::times_8,\n+               arrayOopDesc::base_offset_in_bytes(T_DOUBLE));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write8));\n+  __ access_store_at(T_DOUBLE, IN_HEAP | IS_ARRAY, addr, noreg \/* dtos *\/,\n+                     noreg, noreg, noreg);\n@@ -1128,0 +1233,4 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(\n+      element_address, UseCompressedOops ? SharedRuntime::tsan_write4\n+                                         : SharedRuntime::tsan_write8));\n+\n@@ -1186,4 +1295,4 @@\n-  __ access_store_at(T_BYTE, IN_HEAP | IS_ARRAY,\n-                     Address(rdx, rbx,Address::times_1,\n-                             arrayOopDesc::base_offset_in_bytes(T_BYTE)),\n-                     rax, noreg, noreg, noreg);\n+  Address addr(rdx, rbx, Address::times_1,\n+               arrayOopDesc::base_offset_in_bytes(T_BYTE));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write1));\n+  __ access_store_at(T_BYTE, IN_HEAP | IS_ARRAY, addr, rax, noreg, noreg, noreg);\n@@ -1199,4 +1308,4 @@\n-  __ access_store_at(T_CHAR, IN_HEAP | IS_ARRAY,\n-                     Address(rdx, rbx, Address::times_2,\n-                             arrayOopDesc::base_offset_in_bytes(T_CHAR)),\n-                     rax, noreg, noreg, noreg);\n+  Address addr(rdx, rbx, Address::times_2,\n+               arrayOopDesc::base_offset_in_bytes(T_CHAR));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write2));\n+  __ access_store_at(T_CHAR, IN_HEAP | IS_ARRAY, addr, rax, noreg, noreg, noreg);\n@@ -2720,0 +2829,10 @@\n+    TSAN_RUNTIME_ONLY(\n+      \/\/ Draw a happens-before edge from the class's static initializer to\n+      \/\/ this lookup.\n+      __ pusha();\n+      __ movq(c_rarg0, obj);\n+      __ call_VM_leaf(CAST_FROM_FN_PTR(address,\n+                                       SharedRuntime::tsan_acquire),\n+                      c_rarg0);\n+      __ popa();\n+    );\n@@ -2883,0 +3002,5 @@\n+  \/\/ During a TSAN instrumented run, move flags into rdx so we can later\n+  \/\/ examine whether the field is volatile or has been annotated to be ignored\n+  \/\/ by Tsan.\n+  TSAN_RUNTIME_ONLY(__ movl(rdx, flags));\n+\n@@ -2895,0 +3019,2 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+      field, rdx, SharedRuntime::tsan_read1, btos));\n@@ -2908,0 +3034,2 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+      field, rdx, SharedRuntime::tsan_read1, ztos));\n@@ -2921,0 +3049,4 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+      field, rdx, UseCompressedOops ? SharedRuntime::tsan_read4\n+                                    : SharedRuntime::tsan_read8,\n+      atos));\n@@ -2932,0 +3064,2 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+      field, rdx, SharedRuntime::tsan_read4, itos));\n@@ -2944,0 +3078,2 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+      field, rdx, SharedRuntime::tsan_read2, ctos));\n@@ -2956,0 +3092,2 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+      field, rdx, SharedRuntime::tsan_read2, stos));\n@@ -2970,0 +3108,2 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+      field, rdx, SharedRuntime::tsan_read8, ltos));\n@@ -2981,0 +3121,2 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+      field, rdx, SharedRuntime::tsan_read4, ftos));\n@@ -2997,0 +3139,2 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+      field, rdx, SharedRuntime::tsan_read8, dtos));\n@@ -3132,2 +3276,0 @@\n-  __ shrl(rdx, ConstantPoolCacheEntry::is_volatile_shift);\n-  __ andl(rdx, 0x1);\n@@ -3136,1 +3278,1 @@\n-  __ testl(rdx, rdx);\n+  __ testl(rdx, 1 << ConstantPoolCacheEntry::is_volatile_shift);\n@@ -3173,0 +3315,2 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+        field, rdx, SharedRuntime::tsan_write1, btos));\n@@ -3188,0 +3332,2 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+        field, rdx, SharedRuntime::tsan_write1, ztos));\n@@ -3203,0 +3349,4 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, rdx,\n+        UseCompressedOops ? SharedRuntime::tsan_write4\n+                          : SharedRuntime::tsan_write8,\n+        atos));\n@@ -3219,0 +3369,2 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+        field, rdx, SharedRuntime::tsan_write4, itos));\n@@ -3234,0 +3386,2 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+        field, rdx, SharedRuntime::tsan_write2, ctos));\n@@ -3249,0 +3403,2 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+        field, rdx, SharedRuntime::tsan_write2, stos));\n@@ -3264,0 +3420,2 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+        field, rdx, SharedRuntime::tsan_write8, ltos));\n@@ -3282,0 +3440,2 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+        field, rdx, SharedRuntime::tsan_write4, ftos));\n@@ -3300,0 +3460,2 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+        field, rdx, SharedRuntime::tsan_write8, dtos));\n@@ -4083,0 +4245,8 @@\n+    TSAN_RUNTIME_ONLY(\n+      \/\/ return value of new oop is in rax.\n+      __ push(atos);\n+      __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::tsan_track_obj),\n+                      rax);\n+      __ pop(atos);\n+    );\n+\n","filename":"src\/hotspot\/cpu\/x86\/templateTable_x86.cpp","additions":230,"deletions":60,"binary":false,"changes":290,"status":"modified"},{"patch":"@@ -654,0 +654,23 @@\n+\n+#if (INCLUDE_TSAN) && defined(AARCH64)\n+  \/\/ Current TSAN memory mapping for 48bits aarch64, a large continuous space could be allocated between\n+  \/\/ kMidAppMemBeg = 0x0aaaa00000000ull and kMidAppMemEnd = 0x0aaaf00000000ull, which is only 20GB size.\n+  \/\/ Take 16GB here for safer allocation.\n+  const julong max_avail_vmspace = 16ULL * G; \/\/ 16GB\n+  const u8 msb_in_aarch64 = 47; \/\/ Only support 48-bits space now.\n+\n+  \/\/ Based on tsan memory mapping for 48bits aarch64,\n+  \/\/ libjvm.so will be loaded between kHiAppMemBeg = 0x0ffff00000000ull and kHiAppMemEnd = 0x1000000000000ull\n+  u8 vm_addr_u8 = reinterpret_cast<u8>(&__FUNCTION__);\n+  \/\/ High address in 48bits user space is like 0x0000ffffxxxxxxxx.\n+  assert((vm_addr_u8  >> msb_in_aarch64) == 0x1, \"warning: allocation could fail in non 48-bit address space.\");\n+\n+  if (result) {\n+    *limit = MIN2(*limit, max_avail_vmspace);\n+  } else {\n+    *limit = max_avail_vmspace;\n+  }\n+\n+  result = true;\n+#endif\n+\n","filename":"src\/hotspot\/os\/posix\/os_posix.cpp","additions":23,"deletions":0,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -636,1 +636,2 @@\n-  assert(((intptr_t)os::current_stack_pointer() & (StackAlignmentInBytes-1)) == 0, \"incorrect stack alignment\");\n+  \/\/ TODO: TSAN requires being built with Clang, but stack alignment assertion fails with Clang.\n+  \/\/ assert(((intptr_t)os::current_stack_pointer() & (StackAlignmentInBytes-1)) == 0, \"incorrect stack alignment\");\n","filename":"src\/hotspot\/os_cpu\/linux_x86\/os_linux_x86.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -37,0 +37,3 @@\n+#if INCLUDE_TSAN\n+#include \"classfile\/tsanIgnoreList.hpp\"\n+#endif \/\/ INCLUDE_TSAN\n@@ -948,0 +951,1 @@\n+    _field_TsanIgnore,\n@@ -985,0 +989,5 @@\n+\n+#if INCLUDE_TSAN\n+  void set_tsan_ignore(bool tsan_ignore) { set_annotation(_field_TsanIgnore); }\n+  bool is_tsan_ignore() const { return has_annotation(_field_TsanIgnore); }\n+#endif  \/\/ INCLUDE_TSAN\n@@ -1533,0 +1542,7 @@\n+    TSAN_RUNTIME_ONLY(\n+      if (ThreadSanitizerIgnoreFile != NULL &&\n+          TsanIgnoreList::match(_class_name, name, type)) {\n+        parsed_annotations.set_tsan_ignore(true);\n+      }\n+    );\n+\n@@ -1953,0 +1969,8 @@\n+#if INCLUDE_TSAN\n+    case VM_SYMBOL_ENUM_NAME(java_util_concurrent_annotation_LazyInit): {\n+      if (_location != _in_field) {\n+        break;  \/\/ only allow for fields\n+      }\n+      return _field_TsanIgnore;\n+    }\n+#endif  \/\/ INCLUDE_TSAN\n@@ -1971,0 +1995,5 @@\n+  TSAN_RUNTIME_ONLY(\n+    if (is_tsan_ignore())\n+      (f->field_flags_addr())->update_tsan_ignore(true);\n+  );\n+\n@@ -5370,0 +5399,19 @@\n+#if INCLUDE_TSAN\n+  if (ThreadSanitizer && !ik->is_interface()) {\n+    ik->ensure_space_for_methodids(0);\n+    int num_methods = ik->methods()->length();\n+    for (int index = 0; index < num_methods; index++) {\n+      \/\/ Make sure each method has a jmethodID.\n+      \/\/ This allows us to avoid allocating jmethodIDs during program execution.\n+      jmethodID id = ik->methods()->at(index)->jmethod_id();\n+#ifdef ASSERT\n+      u8 id_u8 = reinterpret_cast<u8>(id);\n+      assert((id_u8 & right_n_bits(3)) == 0, \"jmethodID is not aligned\");\n+      AARCH64_ONLY(id_u8 >>= 36;\n+                   assert(id_u8 == 0 || id_u8 == 0xaaa || id_u8 == 0xfff, \"jmethodID is not aligned\");\n+                   )\n+#endif\n+    }\n+  }\n+#endif \/\/ INCLUDE_TSAN\n+\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":48,"deletions":0,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -293,0 +293,3 @@\n+  \/\/ FIXME: Is this still needed?\n+#if INCLUDE_TSAN\n+#endif  \/\/ INCLUDE_TSAN\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -264,0 +264,1 @@\n+  template(java_util_concurrent_annotation_LazyInit,                         \"Ljava\/util\/concurrent\/annotation\/LazyInit;\") \\\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -249,0 +249,4 @@\n+  \/\/ TODO(tsan): _reserved MemRegion is not available to all collectors.\n+  \/\/ Should we support collectors without _reserved MemRegion? See 8224815.\n+  TSAN_ONLY(MemRegion reserved_region() const { return _reserved; })\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -236,0 +236,3 @@\n+  TSAN_RUNTIME_ONLY(\n+      SharedRuntime::tsan_track_obj_with_size(obj(), (int)_allocator._word_size);\n+  );\n","filename":"src\/hotspot\/share\/gc\/shared\/memAllocator.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -345,0 +345,6 @@\n+\/*\n+ * java.lang.ref.Finalizer\n+ *\/\n+JNIEXPORT jboolean JNICALL\n+JVM_GetTsanEnabled(JNIEnv *env);\n+\n","filename":"src\/hotspot\/share\/include\/jvm.h","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -716,0 +716,5 @@\n+  bool is_tsan_ignore = false;\n+#if INCLUDE_TSAN\n+  is_tsan_ignore = info.field_flags().is_stable() || info.field_flags().is_tsan_ignore();\n+#endif  \/\/ INCLUDE_TSAN\n+\n@@ -724,1 +729,2 @@\n-    info.access_flags().is_volatile()\n+    info.access_flags().is_volatile(),\n+    is_tsan_ignore\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -29,0 +29,3 @@\n+#if INCLUDE_TSAN\n+#include \"runtime\/sharedRuntime.hpp\"\n+#endif\n@@ -70,0 +73,21 @@\n+#if INCLUDE_TSAN\n+\n+TemplateTable::TsanMemoryReleaseAcquireFunction TemplateTable::tsan_release_acquire_method(\n+    TsanMemoryReadWriteFunction tsan_function) {\n+  if (tsan_function == SharedRuntime::tsan_read1\n+      || tsan_function == SharedRuntime::tsan_read2\n+      || tsan_function == SharedRuntime::tsan_read4\n+      || tsan_function == SharedRuntime::tsan_read8) {\n+    return SharedRuntime::tsan_acquire;\n+  } else if (tsan_function == SharedRuntime::tsan_write1\n+      || tsan_function == SharedRuntime::tsan_write2\n+      || tsan_function == SharedRuntime::tsan_write4\n+      || tsan_function == SharedRuntime::tsan_write8) {\n+    return SharedRuntime::tsan_release;\n+  }\n+  ShouldNotReachHere();\n+  return NULL;\n+}\n+\n+#endif\n+\n","filename":"src\/hotspot\/share\/interpreter\/templateTable.cpp","additions":24,"deletions":0,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -355,0 +355,33 @@\n+#if INCLUDE_TSAN\n+   typedef void (*TsanMemoryReleaseAcquireFunction)(void* \/* address *\/);\n+\n+   typedef void (*TsanMemoryReadWriteFunction)(void* \/* address *\/,\n+                                               Method* \/* method *\/,\n+                                               address \/* bcp *\/);\n+\n+   \/\/ The corresponding tsan_acquire\/release function for a\n+   \/\/ TsanMemoryReadWriteFunction.\n+   static TsanMemoryReleaseAcquireFunction tsan_release_acquire_method(TsanMemoryReadWriteFunction tsan_function);\n+\n+   \/\/ Tell tsan that a member\/static variable has been read from or written to.\n+   \/\/ tsan_function must be one of the SharedRuntime::tsan_read\/write*\n+   \/\/ functions.\n+   \/\/ Flags is the register that contains the field cache entry flags bitfield.\n+   \/\/ Because the field may be volatile, for a write, this function must be\n+   \/\/ called before the write; for a read, this function must be called after\n+   \/\/ the read. This way the acquire\/release is ordered correctly relative to the\n+   \/\/ read\/write.\n+   static void tsan_observe_get_or_put(const Address &field,\n+                                       Register flags,\n+                                       TsanMemoryReadWriteFunction tsan_function,\n+                                       TosState tos);\n+\n+   \/\/ Tell tsan that an array has been read from or written to.\n+   \/\/ tsan_function must be one of the SharedRuntime::tsan_read\/write*\n+   \/\/ functions.\n+   \/\/ Unlike tsan_observe_get_or_put(), the ordering relative to the\n+   \/\/ read\/write does not matter since array loads\/stores are never volatile.\n+   static void tsan_observe_load_or_store(const Address& address,\n+                                          TsanMemoryReadWriteFunction tsan_function);\n+#endif\n+\n","filename":"src\/hotspot\/share\/interpreter\/templateTable.hpp","additions":33,"deletions":0,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -124,1 +124,2 @@\n-                                       bool is_volatile) {\n+                                       bool is_volatile,\n+                                       bool is_tsan_ignore) {\n@@ -131,1 +132,2 @@\n-                  ((is_final    ? 1 : 0) << is_final_shift),\n+                  ((is_final    ? 1 : 0) << is_final_shift) |\n+                  ((is_tsan_ignore ? 1 : 0) << is_tsan_ignore_shift),\n","filename":"src\/hotspot\/share\/oops\/cpCache.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -182,0 +182,1 @@\n+    is_tsan_ignore_shift       = 27,  \/\/ Should the field be ignored by TSAN?\n@@ -224,1 +225,2 @@\n-    bool            is_volatile                  \/\/ the field is volatile\n+    bool            is_volatile,                 \/\/ the field is volatile\n+    bool            is_tsan_ignore               \/\/ the field should be ignored by TSAN\n","filename":"src\/hotspot\/share\/oops\/cpCache.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -78,0 +78,3 @@\n+#if INCLUDE_TSAN\n+      _ff_tsan_ignore,  \/\/ TSAN should ignore memory accesses to this field\n+#endif  \/\/ INCLUDE_TSAN\n@@ -113,0 +116,3 @@\n+#if INCLUDE_TSAN\n+    bool is_tsan_ignore() const     { return test_flag(_ff_tsan_ignore); }\n+#endif  \/\/ INCLUDE_TSAN\n@@ -119,0 +125,3 @@\n+#if INCLUDE_TSAN\n+    void update_tsan_ignore(bool z) { update_flag(_ff_tsan_ignore, z); }\n+#endif  \/\/ INCLUDE_TSAN\n@@ -223,1 +232,0 @@\n-\n","filename":"src\/hotspot\/share\/oops\/fieldInfo.hpp","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -101,0 +101,3 @@\n+#if INCLUDE_TSAN\n+#include \"runtime\/sharedRuntime.hpp\"\n+#endif\n@@ -751,0 +754,6 @@\n+    TSAN_RUNTIME_ONLY(\n+      \/\/ Construct a happens-before edge between the write of _init_state to\n+      \/\/ fully_initialized and here. This is to read\/write of natives related\n+      \/\/ to class static initializer.\n+      SharedRuntime::tsan_acquire((address)java_mirror());\n+    );\n@@ -1195,0 +1204,8 @@\n+  if (state == fully_initialized) {\n+        TSAN_RUNTIME_ONLY(\n+        \/\/ Construct a happens-before edge between the write of _init_state to\n+        \/\/ fully_initialized and the later checking if it's initialized.\n+        SharedRuntime::tsan_release((address)java_mirror());\n+      );\n+  }\n+\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -98,0 +98,3 @@\n+#if INCLUDE_TSAN\n+#include \"tsan\/tsan.hpp\"\n+#endif  \/\/ INCLUDE_TSAN\n@@ -3224,0 +3227,8 @@\n+\/\/ java.lang.ref.Finalizer \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+JVM_ENTRY(jboolean, JVM_GetTsanEnabled(JNIEnv *env))\n+  TSAN_ONLY(return ThreadSanitizer;)\n+  NOT_TSAN(return JNI_FALSE;)\n+JVM_END\n+\n+\n@@ -3492,1 +3503,3 @@\n-  return new PlatformMutex();\n+  void *mon = new PlatformMutex();\n+  TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_CREATE(mon));\n+  return mon;\n@@ -3498,0 +3511,1 @@\n+  TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_DESTROY(mon));\n@@ -3505,0 +3519,1 @@\n+  TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_ACQUIRED(mon));\n@@ -3511,0 +3526,1 @@\n+  TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_RELEASED(mon));\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":17,"deletions":1,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -82,0 +82,3 @@\n+#if INCLUDE_TSAN\n+#include \"tsan\/tsan.hpp\"\n+#endif  \/\/ INCLUDE_TSAN\n@@ -3658,0 +3661,4 @@\n+\/\/ Tsan note: The JVMTI raw monitors are instrumented at JvmtiRawMonitor call\n+\/\/ sites instead of inside the JvmtiRawMonitor implementation. This seems\n+\/\/ cleaner, and mirrors instrumentation of JVM_RawMonitor* functions.\n+\n@@ -3667,0 +3674,2 @@\n+  TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_CREATE(rmonitor));\n+\n@@ -3689,0 +3698,1 @@\n+        TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_RELEASED(rmonitor));\n@@ -3707,0 +3717,1 @@\n+  TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_DESTROY(rmonitor));\n@@ -3729,0 +3740,1 @@\n+    TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_ACQUIRED(rmonitor));\n@@ -3747,0 +3759,1 @@\n+    TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_RELEASED(rmonitor));\n@@ -3760,0 +3773,4 @@\n+\n+  \/\/ A wait is modeled in Tsan as a simple release-acquire pair.\n+  \/\/ The matching release annotation is below.\n+  TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_RELEASED(rmonitor));\n@@ -3763,0 +3780,2 @@\n+  \/\/ The matching acquire annotation is above.\n+  TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_ACQUIRED(rmonitor));\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnv.cpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -33,0 +33,3 @@\n+#if INCLUDE_TSAN\n+#include \"tsan\/tsan.hpp\"\n+#endif  \/\/ INCLUDE_TSAN\n@@ -52,0 +55,1 @@\n+      TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_ACQUIRED(rmonitor));\n","filename":"src\/hotspot\/share\/prims\/jvmtiRawMonitor.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -70,0 +70,3 @@\n+#if INCLUDE_TSAN\n+#include \"tsan\/tsan.hpp\"\n+#endif  \/\/ INCLUDE_TSAN\n@@ -75,0 +78,16 @@\n+\/\/ Tsan should know that the JVMTI TagMap is protected by a mutex.\n+class TsanMutexScope : public StackObj {\n+ private:\n+  Mutex *_lock;  \/\/ Keep my own reference, for destructor.\n+\n+ public:\n+  \/\/ Don't actually lock it, just tell tsan we did.\n+  TsanMutexScope(Mutex* mutex) : _lock(mutex) {\n+    TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_ACQUIRED(_lock));\n+  }\n+\n+  ~TsanMutexScope() {\n+    TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_RELEASED(_lock));\n+  }\n+};\n+\n@@ -87,0 +106,18 @@\n+  \/\/ TSAN Note: we cannot tell TSAN about the creation of this lock due to\n+  \/\/ this being seen as racy though is not really.\n+  \/\/\n+  \/\/ The JvmtiTagMap gets created by the first thread to call tag_map_for; which\n+  \/\/ uses a lock to create it if need be.\n+  \/\/\n+  \/\/ This means that this lock is created under a mutex but then,\n+  \/\/ subsequent uses do not have a lock to protect it (because not\n+  \/\/ needed in this case), however TSAN sees it as being needed because:\n+  \/\/  - Another thread can come and get the newly created JvmtiTagMap without a\n+  \/\/  lock and acquire the lock.\n+  \/\/  - This provokes a race for TSAN on the lock itself, though there is no\n+  \/\/  real issue.\n+  \/\/\n+  \/\/  Not creating the lock or having a fence mechanism to tell TSAN this is\n+  \/\/  safe (a fake lock around this lock for example) seem to be the only\n+  \/\/  solutions.\n+\n@@ -95,1 +132,0 @@\n-\n@@ -103,0 +139,2 @@\n+\n+  \/\/ TSAN Note: see above for the Tsan creation note.\n@@ -332,0 +370,1 @@\n+  TSAN_ONLY(TsanMutexScope tms(lock()));\n@@ -357,0 +396,1 @@\n+  TSAN_ONLY(TsanMutexScope tms(lock()));\n@@ -856,0 +896,2 @@\n+  JvmtiTagMap* _tag_map;\n+\n@@ -857,2 +899,3 @@\n-  VM_HeapIterateOperation(ObjectClosure* blk, GrowableArray<jlong>* objects) :\n-    _blk(blk), _dead_objects(objects) { }\n+  VM_HeapIterateOperation(ObjectClosure* blk, GrowableArray<jlong>* objects,\n+                          JvmtiTagMap* tag_map) :\n+    _blk(blk), _dead_objects(objects), _tag_map(tag_map) { }\n@@ -862,0 +905,6 @@\n+    \/\/ Simulates barrier synchronization on safepoint.\n+    \/\/ This annotation is reasonably minimal in number of tsan callbacks.\n+    \/\/ By passing the lock directly, we are not actually locking it, just\n+    \/\/ telling TSAN we are to \"simulate\" the lock.\n+    TSAN_ONLY(TsanMutexScope tms(_tag_map->lock()));\n+\n@@ -1112,1 +1161,1 @@\n-    VM_HeapIterateOperation op(&blk, &dead_objects);\n+    VM_HeapIterateOperation op(&blk, &dead_objects, this);\n@@ -1139,1 +1188,1 @@\n-    VM_HeapIterateOperation op(&blk, &dead_objects);\n+    VM_HeapIterateOperation op(&blk, &dead_objects, this);\n@@ -1312,0 +1361,1 @@\n+    TSAN_ONLY(TsanMutexScope tms(lock()));\n@@ -2932,0 +2982,5 @@\n+  \/\/ This annotation is reasonably minimal in number of tsan callbacks.\n+  \/\/ By passing the lock directly, we are not actually locking it, just\n+  \/\/ telling TSAN we are to \"simulate\" the lock.\n+  TSAN_ONLY(TsanMutexScope tms(_tag_map->lock()));\n+\n","filename":"src\/hotspot\/share\/prims\/jvmtiTagMap.cpp","additions":60,"deletions":5,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -59,0 +59,1 @@\n+\n","filename":"src\/hotspot\/share\/prims\/jvmtiTagMap.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -63,0 +63,3 @@\n+#if INCLUDE_TSAN\n+#include \"tsan\/tsanExternalDecls.hpp\"\n+#endif\n@@ -251,0 +254,8 @@\n+  TSAN_RUNTIME_ONLY(\n+    void* addr = index_oop_from_field_offset_long(p, offset);\n+    if (UseCompressedOops) {\n+      __tsan_read4_pc(addr, SharedRuntime::tsan_code_location(0, 0));\n+    } else {\n+      __tsan_read8_pc(addr, SharedRuntime::tsan_code_location(0, 0));\n+    }\n+  );\n@@ -258,0 +269,8 @@\n+  TSAN_RUNTIME_ONLY(\n+    void* addr = index_oop_from_field_offset_long(p, offset);\n+    if (UseCompressedOops) {\n+      __tsan_write4_pc(addr, SharedRuntime::tsan_code_location(0, 0));\n+    } else {\n+      __tsan_write8_pc(addr, SharedRuntime::tsan_code_location(0, 0));\n+    }\n+  );\n@@ -265,0 +284,4 @@\n+  TSAN_RUNTIME_ONLY(\n+    void* addr = index_oop_from_field_offset_long(p, offset);\n+    __tsan_java_acquire(addr);\n+  );\n@@ -272,0 +295,4 @@\n+  TSAN_RUNTIME_ONLY(\n+    void* addr = index_oop_from_field_offset_long(p, offset);\n+    __tsan_java_release(addr);\n+  );\n@@ -280,1 +307,1 @@\n-#define DEFINE_GETSETOOP(java_type, Type) \\\n+#define DEFINE_GETSETOOP(java_type, Type, size) \\\n@@ -283,1 +310,6 @@\n-  return MemoryAccess<java_type>(thread, obj, offset).get(); \\\n+  java_type ret = MemoryAccess<java_type>(thread, obj, offset).get(); \\\n+  TSAN_RUNTIME_ONLY( \\\n+    void* addr = index_oop_from_field_offset_long(JNIHandles::resolve(obj), offset); \\\n+    __tsan_read##size##_pc(addr, SharedRuntime::tsan_code_location(0, 0)); \\\n+  ); \\\n+  return ret; \\\n@@ -287,0 +319,4 @@\n+  TSAN_RUNTIME_ONLY( \\\n+    void* addr = index_oop_from_field_offset_long(JNIHandles::resolve(obj), offset); \\\n+    __tsan_write##size##_pc(addr, SharedRuntime::tsan_code_location(0, 0)); \\\n+  ); \\\n@@ -292,8 +328,8 @@\n-DEFINE_GETSETOOP(jboolean, Boolean)\n-DEFINE_GETSETOOP(jbyte, Byte)\n-DEFINE_GETSETOOP(jshort, Short);\n-DEFINE_GETSETOOP(jchar, Char);\n-DEFINE_GETSETOOP(jint, Int);\n-DEFINE_GETSETOOP(jlong, Long);\n-DEFINE_GETSETOOP(jfloat, Float);\n-DEFINE_GETSETOOP(jdouble, Double);\n+DEFINE_GETSETOOP(jboolean, Boolean, 1)\n+DEFINE_GETSETOOP(jbyte, Byte, 1)\n+DEFINE_GETSETOOP(jshort, Short, 2);\n+DEFINE_GETSETOOP(jchar, Char, 2);\n+DEFINE_GETSETOOP(jint, Int, 4);\n+DEFINE_GETSETOOP(jlong, Long, 8);\n+DEFINE_GETSETOOP(jfloat, Float, 4);\n+DEFINE_GETSETOOP(jdouble, Double, 8);\n@@ -306,1 +342,6 @@\n-  return MemoryAccess<java_type>(thread, obj, offset).get_volatile(); \\\n+  java_type ret = MemoryAccess<java_type>(thread, obj, offset).get_volatile(); \\\n+  TSAN_RUNTIME_ONLY( \\\n+    void* addr = index_oop_from_field_offset_long(JNIHandles::resolve(obj), offset); \\\n+    __tsan_java_acquire(addr); \\\n+  ); \\\n+  return ret; \\\n@@ -310,0 +351,4 @@\n+  TSAN_RUNTIME_ONLY( \\\n+    void* addr = index_oop_from_field_offset_long(JNIHandles::resolve(obj), offset); \\\n+    __tsan_java_release(addr); \\\n+  ); \\\n@@ -712,0 +757,24 @@\n+\/\/ Calls __tsan_java_release() on construct and __tsan_java_acquire() on destruct.\n+class ScopedReleaseAcquire: public StackObj {\n+private:\n+  void* _addr;\n+public:\n+  ScopedReleaseAcquire(volatile void* addr) {\n+    TSAN_RUNTIME_ONLY(\n+      _addr = const_cast<void*>(addr);\n+      __tsan_java_release(_addr);\n+    );\n+  }\n+\n+  ScopedReleaseAcquire(oop obj, jlong offset) {\n+    TSAN_RUNTIME_ONLY(\n+      _addr = index_oop_from_field_offset_long(obj, offset);\n+      __tsan_java_release(_addr);\n+    );\n+  }\n+\n+  ~ScopedReleaseAcquire() {\n+    TSAN_RUNTIME_ONLY(__tsan_java_acquire(_addr));\n+  }\n+};\n+\n@@ -717,0 +786,1 @@\n+  ScopedReleaseAcquire releaseAcquire(p, offset);\n@@ -724,0 +794,1 @@\n+  ScopedReleaseAcquire releaseAcquire(p, offset);\n@@ -730,0 +801,1 @@\n+  ScopedReleaseAcquire releaseAcquire(addr);\n@@ -738,0 +810,1 @@\n+  ScopedReleaseAcquire releaseAcquire(p, offset);\n@@ -745,0 +818,1 @@\n+  ScopedReleaseAcquire releaseAcquire(addr);\n@@ -751,0 +825,1 @@\n+  ScopedReleaseAcquire releaseAcquire(addr);\n","filename":"src\/hotspot\/share\/prims\/unsafe.cpp","additions":86,"deletions":11,"binary":false,"changes":97,"status":"modified"},{"patch":"@@ -3968,0 +3968,11 @@\n+  TSAN_RUNTIME_ONLY(\n+    \/\/ Currently TSAN is only implemented for interpreter.\n+    set_mode_flags(_int);\n+    \/\/ TSAN instrumentation is not implemented for the RewriteBytecodes\n+    \/\/ code paths because TSAN slows down the application so much that the\n+    \/\/ performance benefits from rewriting bytecodes is negligible.\n+    FLAG_SET_ERGO(RewriteBytecodes, false);\n+    FLAG_SET_ERGO(RewriteFrequentPairs, false);\n+    \/\/ Turn off CDS, it interferes with eagerly allocating jmethodIDs.\n+    no_shared_spaces(\"CDS is not compatible with TSAN\");\n+  );\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -1968,0 +1968,11 @@\n+  TSAN_ONLY(product(bool, ThreadSanitizer, false,                           \\\n+          \"Enable ThreadSanitizer lock instrumentation\"))                   \\\n+                                                                            \\\n+  TSAN_ONLY(product(bool, ThreadSanitizerJavaMemory, true,                  \\\n+          \"Detect Java data races with ThreadSanitizer. \"                   \\\n+          \"This is only enabled if -XX:+ThreadSanitizer is set.\"))          \\\n+                                                                            \\\n+  TSAN_ONLY(product(ccstr, ThreadSanitizerIgnoreFile, NULL,                 \\\n+          \"File containing a list of ignored field patterns for \"           \\\n+          \"ThreadSanitizer.\"))                                              \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -73,0 +73,1 @@\n+TSAN_ONLY(jint tsan_init();)\n@@ -103,0 +104,1 @@\n+TSAN_ONLY(void tsan_exit();)\n@@ -114,1 +116,0 @@\n-\n@@ -129,0 +130,6 @@\n+  TSAN_RUNTIME_ONLY(\n+    status = tsan_init();\n+    if (status != JNI_OK) {\n+      return status;\n+    }\n+  );\n@@ -195,0 +202,3 @@\n+\n+    TSAN_RUNTIME_ONLY(tsan_exit());\n+\n","filename":"src\/hotspot\/share\/runtime\/init.cpp","additions":11,"deletions":1,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -127,0 +127,4 @@\n+#if INCLUDE_TSAN\n+Mutex*   TsanOopMap_lock              = NULL;\n+#endif\n+\n@@ -301,0 +305,4 @@\n+  TSAN_RUNTIME_ONLY(\n+    MUTEX_DEFN(TsanOopMap_lock               , PaddedMutex  , nosafepoint);\n+  );\n+\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -138,0 +138,3 @@\n+#if INCLUDE_TSAN\n+extern Mutex*   TsanOopMap_lock;                 \/\/ guards shared map of oops\n+#endif\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -84,0 +84,4 @@\n+#if INCLUDE_TSAN\n+#include \"tsan\/tsanExternalDecls.hpp\"\n+#include \"tsan\/tsanOopMap.hpp\"\n+#endif\n@@ -1087,0 +1091,173 @@\n+#if INCLUDE_TSAN\n+\n+JRT_LEAF(void, SharedRuntime::verify_oop_index(oopDesc* obj, int index))\n+  assert(oopDesc::is_oop(obj), \"invalid oop\");\n+  assert(index >= 0, \"index is less than 0\");\n+  int obj_size_in_bytes = obj->size() * HeapWordSize;\n+  assert(index < obj_size_in_bytes, \"index %d >= obj size %d\", index, obj_size_in_bytes);\n+JRT_END\n+\n+\/\/ TSAN: method entry callback from interpreter\n+\/\/ (1) In order to have the line numbers in the call stack, we use the caller\n+\/\/     address instead of the method that's being called. This also matches\n+\/\/     the entry\/exit convention that TSAN uses for C++.\n+\/\/ We use JRT_ENTRY since call_VM_leaf doesn't set _last_Java_sp that we need.\n+JRT_ENTRY(void, SharedRuntime::tsan_interp_method_entry(JavaThread* current))\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  DEBUG_ONLY(NoHandleMark nhm;)\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+\n+  RegisterMap unused_reg_map(current,\n+                             RegisterMap::UpdateMap::skip,\n+                             RegisterMap::ProcessFrames::include,\n+                             RegisterMap::WalkContinuation::skip);\n+\n+  \/\/ These asserts should be removed once\n+  \/\/ we support more than just the interpreter for TSAN.\n+  assert(!current->last_frame().is_compiled_frame(),\n+         \"Current frame should not be a compiled frame\");\n+  const frame sender = current->last_frame().real_sender(&unused_reg_map);\n+  assert(!sender.is_compiled_frame(), \"Sender should not be a compiled frame\");\n+\n+  jmethodID jmethod_id = 0;\n+  u2 bci = 0;\n+  \/\/ TODO: is (0, 0) really the best we can do\n+  \/\/ when the sender isn't an interpreted frame?\n+  if (sender.is_interpreted_frame()) {\n+    jmethod_id = sender.interpreter_frame_method()->find_jmethod_id_or_null();\n+    bci = sender.interpreter_frame_bci();\n+  }\n+  __tsan_func_entry(tsan_code_location(jmethod_id, bci));\n+JRT_END\n+\n+\/\/ TSAN: method exit callback from interpreter\n+JRT_LEAF(void, SharedRuntime::tsan_interp_method_exit())\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+  __tsan_func_exit();\n+JRT_END\n+\n+void SharedRuntime::tsan_oop_lock(Thread* thread, oop obj) {\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+  assert(thread != NULL, \"null thread\");\n+  assert(obj != NULL, \"null oop\");\n+  assert(oopDesc::is_oop(obj), \"invalid oop\");\n+\n+  TsanOopMap::add_oop(obj);\n+  __tsan_java_mutex_lock((julong)(oopDesc*)obj);\n+}\n+\n+void SharedRuntime::tsan_oop_unlock(Thread *thread, oop obj) {\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+  assert(thread != NULL, \"null thread\");\n+  assert(obj != NULL, \"null oop\");\n+  assert(oopDesc::is_oop(obj), \"invalid oop\");\n+  assert(TsanOopMap::exists(obj), \"oop seen in unlock but not tracked\");\n+\n+  __tsan_java_mutex_unlock((julong)(oopDesc*)obj);\n+}\n+\n+void SharedRuntime::tsan_oop_rec_lock(Thread* thread, oop obj, int rec) {\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+  assert(thread != NULL, \"null thread\");\n+  assert(obj != NULL, \"null oop\");\n+  assert(oopDesc::is_oop(obj), \"invalid oop\");\n+\n+  TsanOopMap::add_oop(obj);\n+  __tsan_java_mutex_lock_rec((julong)(oopDesc*)obj, rec);\n+}\n+\n+int SharedRuntime::tsan_oop_rec_unlock(Thread *thread, oop obj) {\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+  assert(thread != NULL, \"null thread\");\n+  assert(obj != NULL, \"null oop\");\n+  assert(oopDesc::is_oop(obj), \"invalid oop\");\n+  assert(TsanOopMap::exists(obj), \"oop seen in unlock but not tracked\");\n+\n+  return __tsan_java_mutex_unlock_rec((julong)(oopDesc*)obj);\n+}\n+\n+JRT_LEAF(void, SharedRuntime::tsan_interp_lock(JavaThread* thread,\n+                                               BasicObjectLock* elem))\n+  DEBUG_ONLY(thread->last_frame().interpreter_frame_verify_monitor(elem);)\n+  assert(elem != NULL, \"null elem\");\n+\n+  oop obj = elem->obj();\n+  tsan_oop_lock(thread, obj);\n+\n+  assert(obj == elem->obj(), \"oop changed\");\n+  DEBUG_ONLY(thread->last_frame().interpreter_frame_verify_monitor(elem);)\n+JRT_END\n+\n+JRT_LEAF(void, SharedRuntime::tsan_interp_unlock(JavaThread* thread,\n+                                                 BasicObjectLock* elem))\n+  DEBUG_ONLY(thread->last_frame().interpreter_frame_verify_monitor(elem);)\n+  assert(elem != NULL, \"null elem\");\n+\n+  oop obj = elem->obj();\n+  tsan_oop_unlock(thread, obj);\n+\n+  assert(obj == elem->obj(), \"oop changed\");\n+  DEBUG_ONLY(thread->last_frame().interpreter_frame_verify_monitor(elem);)\n+JRT_END\n+\n+\/\/ Should be JRT_LEAF, but this is called very early during VM startup, so we\n+\/\/ are sometimes in '_thread_in_vm' state.\n+\/\/ NOTE: DO NOT add operations that can safepoint, enter GC, or throw an\n+\/\/ exception!\n+void SharedRuntime::tsan_track_obj_with_size(oopDesc* obj, int size) {\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+  assert(oopDesc::is_oop(obj), \"Bad oopDesc passed to tsan_track_obj_with_size().\");\n+  TsanOopMap::add_oop_with_size(obj, size);\n+}\n+\n+JRT_LEAF(void, SharedRuntime::tsan_track_obj(oopDesc* obj))\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+  assert(oopDesc::is_oop(obj), \"Bad oopDesc passed to tsan_track_obj().\");\n+  TsanOopMap::add_oop(obj);\n+JRT_END\n+\n+\/\/ TODO: Make tsan_acquire\/release JRT_LEAF\n+\/\/ Currently it can't be JRT_LEAF because there are calls from the VM\n+\/\/ (instanceKlass.cpp), and JRT_LEAF only allows calls from Java\/native code.\n+\/\/ We need to figure out a better way of being able to call TSAN functions from\n+\/\/ the VM.\n+void SharedRuntime::tsan_acquire(void* address) {\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+  assert(address != NULL, \"Cannot acquire at address 0\");\n+  __tsan_java_acquire(address);\n+}\n+\n+void SharedRuntime::tsan_release(void* address) {\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+  assert(address != NULL, \"Cannot release at address 0\");\n+  __tsan_java_release(address);\n+}\n+\n+#define TSAN_MEMORY_ACCESS(name)                                               \\\n+  JRT_LEAF(void, SharedRuntime::tsan_##name(                                   \\\n+      void* addr,                                                              \\\n+      Method* method,                                                          \\\n+      address bcp))                                                            \\\n+    assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");                      \\\n+    assert(ThreadSanitizerJavaMemory, \"Need -XX:+ThreadSanitizerJavaMemory\");  \\\n+    jmethodID mid = method->find_jmethod_id_or_null();                         \\\n+    int bci = method->bci_from(bcp);                                           \\\n+    __tsan_##name##_pc(addr, tsan_code_location(mid, bci));                    \\\n+  JRT_END\n+\n+TSAN_MEMORY_ACCESS(read1)\n+TSAN_MEMORY_ACCESS(read2)\n+TSAN_MEMORY_ACCESS(read4)\n+TSAN_MEMORY_ACCESS(read8)\n+TSAN_MEMORY_ACCESS(write1)\n+TSAN_MEMORY_ACCESS(write2)\n+TSAN_MEMORY_ACCESS(write4)\n+TSAN_MEMORY_ACCESS(write8)\n+\n+#endif \/\/ INCLUDE_TSAN\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":177,"deletions":0,"binary":false,"changes":177,"status":"modified"},{"patch":"@@ -290,0 +290,91 @@\n+#if INCLUDE_TSAN\n+  \/\/ TSAN instrumentation\n+\n+  \/\/ TSAN uses a 64-bit value to identify code location.\n+  \/\/ TSAN uses the uppermost 3 bits (63:61) for the internal purposes.\n+  \/\/ If bit 60 is set, TSAN recognizes that the code location belongs to the\n+  \/\/ JVM, and will call __tsan_symbolize_external_ex() for symbolization rather\n+  \/\/ than TSAN's own symbolizer. See __sanitizer::kExternalPCBit and\n+  \/\/ __tsan::__tsan_symbolize_external_ex() in TSAN for more details.\n+  \/\/ The lower 60 bits may contain either a packed bytecode location, or an\n+  \/\/ instruction address inside the code generated by JIT compiler.\n+  \/\/ A packed code location has the method ID in bits 59:16 and the bytecode\n+  \/\/offset within method in bits 15:0. 44 bits (59:16) are enough to encode any\n+  \/\/ 47-bit 8-byte-aligned address, which is the maximum address space TSAN\n+  \/\/ allows. The next 16 bits are used for storing the bci.\n+  \/\/ | Tsan: 3 | TsanJava: 1 | jmethodID: 44 | BCI: 16 |\n+  static const int tsan_method_id_alignment_bits = 3;\n+  static const int tsan_bci_bits = 16;\n+  static const u8 tsan_bci_mask = right_n_bits(tsan_bci_bits);\n+  static const int tsan_method_id_shift = tsan_bci_bits -\n+      tsan_method_id_alignment_bits;\n+  static const u8 tsan_fake_pc_bit = 1L << 60;\n+  static void * tsan_code_location(jmethodID jmethod_id_ptr, u2 bci) {\n+    return (void *)(tsan_fake_pc_bit |\n+      (((u8)(jmethod_id_ptr)) << tsan_method_id_shift) | bci);\n+  }\n+  static jmethodID tsan_method_id_from_code_location(u8 loc) {\n+    u8 id =\n+        (loc & ~(tsan_fake_pc_bit | tsan_bci_mask)) >> tsan_method_id_shift;\n+\n+    \/\/ Typical method ID in aarch64 is like 0xffff_xxxx_xxxx_xxxx, which couldn't be represented by 47-bits.\n+    \/\/ But there are only 3 application memory regions in tsan for 48bits aarch64, the highest 4 bits\n+    \/\/ of addresses are 0x0, 0xa and 0xf respectively. The encoding function tsan_code_location() will\n+    \/\/ overwrite bit 47 for internal purpose, Therefore, we restore bit 47 here according to\n+    \/\/ the value of bits 46:44. if it is 0x2 or 0x7, restore bit 47 to 1.\n+#ifdef AARCH64\n+    u8 highest4bits = id >> 44;\n+    if (highest4bits == 0x7ULL || highest4bits == 0x2ULL) {\n+      id |= (0x1ULL << 47);\n+    }\n+#endif\n+\n+    return (jmethodID)id;\n+  }\n+  static u2 tsan_bci_from_code_location(u8 loc) {\n+    return (u2)(loc & tsan_bci_mask);\n+  }\n+\n+  \/\/ These functions are wrappers around TSAN callbacks,\n+  \/\/ which are listed in tsanExternalDecls.hpp. The VM uses only these\n+  \/\/ functions to push events to ThreadSanitizer.\n+\n+  \/\/ Verify that an oop is valid and that the index is within the object size.\n+  static void verify_oop_index(oopDesc* obj, int index);\n+\n+  \/\/ Java method entry\/exit from code run by template interpreter\n+  static void tsan_interp_method_entry(JavaThread *thread);\n+  static void tsan_interp_method_exit();\n+\n+  \/\/ Monitor acquire\/release in VM code\n+  \/\/ (e.g., generated native method wrapper, JNI heavyweight locks)\n+  static void tsan_oop_lock(Thread* thread, oop obj);\n+  static void tsan_oop_unlock(Thread* thread, oop obj);\n+  \/\/ Monitor acquire\/release in VM code; recursive lock variant (e.g., wait())\n+  static void tsan_oop_rec_lock(Thread* thread, oop obj, int rec);\n+  static int tsan_oop_rec_unlock(Thread* thread, oop obj);\n+\n+  \/\/ Monitor acquire\/release from code run by template interpreter\n+  static void tsan_interp_lock(JavaThread* thread, BasicObjectLock* elem);\n+  static void tsan_interp_unlock(JavaThread* thread, BasicObjectLock* elem);\n+\n+  \/\/ Address must point to an object in the Java heap.\n+  static void tsan_acquire(void* address);\n+  static void tsan_release(void* address);\n+\n+  \/\/ Called whenever an obj is created.\n+  static void tsan_track_obj_with_size(oopDesc* obj, int size);\n+  static void tsan_track_obj(oopDesc* obj);\n+\n+  \/\/ Memory reads\/writes from code run by template interpreter\n+  static void tsan_read1(void* addr, Method* method, address bcp);\n+  static void tsan_read2(void* addr, Method* method, address bcp);\n+  static void tsan_read4(void* addr, Method* method, address bcp);\n+  static void tsan_read8(void* addr, Method* method, address bcp);\n+  static void tsan_write1(void* addr, Method* method, address bcp);\n+  static void tsan_write2(void* addr, Method* method, address bcp);\n+  static void tsan_write4(void* addr, Method* method, address bcp);\n+  static void tsan_write8(void* addr, Method* method, address bcp);\n+\n+#endif \/\/ INCLUDE_TSAN\n+\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":91,"deletions":0,"binary":false,"changes":91,"status":"modified"},{"patch":"@@ -671,0 +671,1 @@\n+  TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_lock(current, obj()));\n@@ -684,0 +685,1 @@\n+    TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_unlock(current, obj));\n@@ -699,0 +701,1 @@\n+    TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_lock(_thread, _obj()));\n@@ -704,0 +707,1 @@\n+    TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_unlock(_thread, _obj()));\n@@ -723,0 +727,7 @@\n+\n+  TSAN_ONLY(int tsan_rec = 0;)\n+  TSAN_RUNTIME_ONLY(\n+    tsan_rec = SharedRuntime::tsan_oop_rec_unlock(THREAD, obj());\n+    assert(tsan_rec > 0, \"tsan: unlocking unlocked mutex\");\n+  );\n+\n@@ -725,0 +736,2 @@\n+  TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_rec_lock(THREAD, obj(), tsan_rec));\n+\n@@ -1799,0 +1812,4 @@\n+    \/\/ Note well -- this occurs ONLY on thread exit, and is a last ditch\n+    \/\/ effort to release all locks. Hence, we don't need to record tsan's\n+    \/\/ recursion count -- it will never be locked again.\n+    TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_rec_unlock(_thread, (oop)mid->object()));\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -0,0 +1,530 @@\n+\/*\n+ * Copyright (c) 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, Google and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"gc\/shared\/gcTraceTime.inline.hpp\"\n+#include \"gc\/shared\/gcId.hpp\"\n+#include \"gc\/shared\/referenceProcessor.hpp\"\n+#include \"memory\/resourceArea.hpp\"\n+#include \"oops\/oop.inline.hpp\"\n+#include \"runtime\/mutexLocker.hpp\"\n+#include \"runtime\/safepointVerifiers.hpp\"\n+#include \"tsan\/tsanExternalDecls.hpp\"\n+#include \"tsan\/tsanOopMap.hpp\"\n+#include \"utilities\/bitMap.inline.hpp\"\n+\n+extern \"C\" int jio_printf(const char *fmt, ...);\n+\n+#if 0\n+#define DEBUG_PRINT(...) jio_printf(__VA_ARGS__)\n+#else\n+#define DEBUG_PRINT(...)\n+#endif\n+namespace TsanOopMapImpl {\n+\n+  struct PendingMove {\n+    char *source_begin() const { return source_address; }\n+    char *source_end() const { return source_address + n_bytes; }\n+    char *target_begin() const { return target_address; }\n+    char *target_end() const { return target_address + n_bytes; }\n+    char *source_address;\n+    char *target_address;\n+    size_t n_bytes;  \/\/ number of bytes being moved\n+  };\n+\n+  \/\/ Our data\n+  class TsanOopSizeMap *oop_map = NULL;\n+\n+  \/**\n+   * TsanOopSizeMap is a hash map of {oopDesc * -> size}.\n+   *\/\n+  class TsanOopSizeMap : public CHeapObj<mtInternal> {\n+\n+    class TsanOop : public CHeapObj<mtInternal> {\n+      \/* We track the lifecycle (alloc\/move\/free) of interesting oops;\n+       * tsan needs to know. *\/\n+      oopDesc *_oop;  \/\/ key\n+\n+      \/* We cache the oop's size, since we cannot reliably determine it after\n+       * the oop is freed. Size is measured in number of HeapWords. *\/\n+      uintx _oop_size;  \/\/ value\n+\n+    public:\n+      TsanOop():_oop(NULL), _oop_size(0) {}\n+      void set_oop(oopDesc *o, uintx s) { _oop = o; _oop_size = s; }\n+      bool has_oop() const { return _oop != NULL; }\n+      oopDesc *get_oop() const { return _oop; }\n+      uintx get_oop_size() const { return _oop_size; }\n+    };\n+\n+    size_t _size;\n+    size_t _n_elements;\n+    float _load_factor;\n+    TsanOop *_buckets;\n+\n+    static uintx _hash64(uintx key) {\n+      key = ~key + (key << 21);\n+      key ^= (key >> 24);\n+      key += (key << 3) + (key << 8);\n+      key ^= (key >> 14);\n+      key += (key << 2) + (key << 4);\n+      key ^= (key >> 28);\n+      key += (key << 31);\n+      return key;\n+    }\n+\n+    static uintx _hash32(uintx key) {\n+      key = ~key + (key << 15);\n+      key ^= (key >> 12);\n+      key += (key << 2);\n+      key ^= (key >> 4);\n+      key *= 2057;\n+      key ^= (key >> 16);\n+      return key;\n+    }\n+\n+    TsanOop* find_bucket(oopDesc* o) {\n+      uintx h = reinterpret_cast<uintx>((address)o);\n+      TsanOop* bucket;\n+      do {\n+        h = hash(h);\n+        bucket = &_buckets[h % _size];\n+      } while (bucket->has_oop() && bucket->get_oop() != o);\n+      return bucket;\n+    }\n+\n+    static bool collect_oops(BoolObjectClosure* is_alive,\n+                             OopClosure* f,\n+                             GrowableArray<PendingMove>* moves,\n+                             int* n_downward_moves,\n+                             char** min_low,\n+                             char** max_high);\n+\n+    static void handle_overlapping_moves(GrowableArray<PendingMove>& moves,\n+                                         char* min_low,\n+                                         char* max_high);\n+\n+  public:\n+    TsanOopSizeMap(size_t initial_size)\n+        : _size(initial_size), _n_elements(0), _load_factor(0.7) {\n+      _buckets = new TsanOop[_size];\n+    }\n+\n+    ~TsanOopSizeMap() {\n+      delete [] _buckets;\n+    }\n+\n+    static uintx hash(uintx key) {\n+      return (sizeof(uintx) == 4) ? _hash32(key) : _hash64(key);\n+    }\n+\n+    \/\/ Put an oop and oop size into the hash map.\n+    \/\/ Ok to call multiple times on same oop.\n+    \/\/ Return true if seen for first time; else return false.\n+    \/\/ Synchronized in mutator threads with TsanOopMap_lock.\n+    bool put(oopDesc* o, uintx s) {\n+      TsanOop* bucket = find_bucket(o);\n+\n+      if (!bucket->has_oop()) {\n+        if (++_n_elements > _load_factor * _size) {\n+          grow();\n+          bucket = find_bucket(o);\n+        }\n+        bucket->set_oop(o, s);\n+        return true;\n+      } else {\n+        assert(s == bucket->get_oop_size(), \"same oop should have same size\");\n+        return false;\n+      }\n+    }\n+\n+    void grow(void) {\n+      TsanOop *old_buckets = _buckets;\n+      size_t old_size = _size;\n+      _size *= 2;\n+\n+      _buckets = new TsanOop[_size];\n+\n+      for (uintx i = 0; i < old_size; i++) {\n+        if (old_buckets[i].has_oop()) {\n+          put(old_buckets[i].get_oop(), old_buckets[i].get_oop_size());\n+        }\n+      }\n+      delete [] old_buckets;\n+    }\n+\n+    \/\/ Call this function at the end of the garbage collection to\n+    \/\/ notify TSan about object location changes and to build oops map.\n+    static void rebuild_oops_map(BoolObjectClosure *is_alive,\n+                                 OopClosure *pointer_adjuster);\n+\n+#ifdef ASSERT\n+    bool exists(oopDesc *o) const {\n+      uintx h = reinterpret_cast<uintx>((address)o);\n+      TsanOop *bucket = NULL;\n+\n+      do {\n+        h = hash(h);\n+        bucket = &_buckets[h % _size];\n+      } while (bucket->has_oop() && bucket->get_oop() != o);\n+\n+      return bucket->has_oop() && bucket->get_oop() == o;\n+    }\n+#endif\n+\n+    size_t size() const { return _size; }\n+    oopDesc *oop_at(size_t i) const { return _buckets[i].get_oop(); }\n+    uintx oop_size_at(size_t i) const { return _buckets[i].get_oop_size(); }\n+  };\n+\n+  \/\/ Two little callbacks used by sort.\n+  int lessThan(PendingMove *l, PendingMove *r) {\n+    char *left = l->target_begin();\n+    char *right = r->target_begin();\n+    return (left < right) ? -1 : (left == right ? 0 : 1);\n+  }\n+\n+  int moreThan(PendingMove *l, PendingMove *r) {\n+    return lessThan(r, l);\n+  }\n+\n+  \/\/ Maintains the occupancy state of the given heap memory area.\n+  \/\/ TsanOopSizeMap::rebuild_oop_map below uses an instance of this\n+  \/\/ class to order object moves, please see additional comments there.\n+  class OccupancyMap: public StackObj {\n+    \/\/ Internally it is a BitMap. A bit is set if the corresponding HeapWord\n+    \/\/ is currently occupied, cleared otherwise (HeapWord is Java object\n+    \/\/ allocation unit).\n+    char *mem_begin_;\n+    char *mem_end_;\n+    CHeapBitMap bitmap_;\n+    BitMap::idx_t to_idx(char *mem) const {\n+      return (mem - mem_begin_) \/ HeapWordSize;\n+    }\n+  public:\n+    \/\/ NOTE: The constructor creates a bitmap on the resource area.\n+    \/\/ The bitmap can be quite large (it is 16MB per every 1GB of heap,\n+    \/\/ so it is worth releasing it as soon as possible by creating a\n+    \/\/ ResourceMark.\n+    OccupancyMap(char *mem_begin, char *mem_end)\n+        : mem_begin_(mem_begin), mem_end_(mem_end),\n+          bitmap_((mem_end - mem_begin) \/ HeapWordSize, mtInternal) {}\n+    bool is_range_vacant(char *from, char *to) const {\n+      assert(from < to, \"bad range\");\n+      assert(from >= mem_begin_ && from < mem_end_,\n+             \"start address outside range\");\n+      assert(to > mem_begin_ && to <= mem_end_, \"end address outside range\");\n+      BitMap::idx_t idx_to = to_idx(to);\n+      return bitmap_.find_first_set_bit(to_idx(from), idx_to) == idx_to;\n+    }\n+    void range_occupy(char *from, char *to) {\n+      assert(from < to, \"range_occupy: bad range\");\n+      assert(from >= mem_begin_ && from < mem_end_,\n+             \"start address outside range\");\n+      assert(to > mem_begin_ && to <= mem_end_, \"end address outside range\");\n+      bitmap_.set_range(to_idx(from), to_idx(to));\n+    }\n+    void range_vacate(char *from, char *to) {\n+      assert(from < to, \"bad range\");\n+      assert(from >= mem_begin_ && from < mem_end_,\n+             \"start address outside range\");\n+      assert(to > mem_begin_ && to <= mem_end_, \"end address outside range\");\n+      bitmap_.clear_range(to_idx(from), to_idx(to));\n+    }\n+    int bit_count() const {\n+      return bitmap_.size();\n+    }\n+  };\n+\n+  bool TsanOopSizeMap::collect_oops(BoolObjectClosure* is_alive,\n+                                    OopClosure* pointer_adjuster,\n+                                    GrowableArray<PendingMove>* moves,\n+                                    int* n_downward_moves,\n+                                    char** min_low,\n+                                    char** max_high) {\n+    size_t map_size = oop_map->size();\n+\n+    \/\/ Traverse oop map. For each object that survived GC calculate its new\n+    \/\/ oop, add it to the new oop map, and append the move from the source oop\n+    \/\/ to the target one to the moves list. While doing that, collect oop\n+    \/\/ source and target ranges and count the moves that move an object\n+    \/\/ downwards (this is heuristics to order the moves, see below).\n+    TsanOopSizeMap* new_map = new TsanOopSizeMap(map_size \/ 2);\n+    *n_downward_moves = 0;\n+    bool disjoint_regions;\n+    char *source_low = reinterpret_cast<char *>(UINTPTR_MAX);\n+    char *source_high = NULL;\n+    char *target_low = reinterpret_cast<char *>(UINTPTR_MAX);\n+    char *target_high = NULL;\n+    size_t deleted_objects = 0;\n+    size_t unmoved_objects = 0;\n+    size_t total_size_words = 0;\n+    CollectedHeap *heap = Universe::heap();\n+    for (size_t i = 0; i < map_size; i++) {\n+      oopDesc *source_obj = oop_map->oop_at(i);\n+\n+      if (source_obj != NULL && heap->is_in(source_obj)) {\n+        uintx obj_size = oop_map->oop_size_at(i);\n+        size_t obj_size_bytes = obj_size * HeapWordSize;\n+        if (is_alive->do_object_b(source_obj)) {\n+          \/\/ The object survived GC, add its updated oop to the new oops map.\n+          oop target_oop = cast_to_oop((intptr_t)source_obj);\n+          pointer_adjuster->do_oop(&target_oop);\n+          \/\/ The memory pointed by target_oop may not be a valid oop yet,\n+          \/\/ for example the G1 full collector needs to adjust all pointers\n+          \/\/ first, then compacts and moves the objects. In this case\n+          \/\/ TsanOopSizeMap::rebuild_oops_map() is called during the adjust-\n+          \/\/ pointer phase, before the collector moves the objects. Thus,\n+          \/\/ we cannot use heap->is_in() or oopDesc::is_oop() to check\n+          \/\/ target_oop.\n+          assert(heap->is_in(target_oop), \"Adjustment failed\");\n+          oopDesc *target_obj = target_oop;\n+          new_map->put(target_obj, obj_size);\n+          if (target_obj == source_obj) {\n+            ++unmoved_objects;\n+            continue;\n+          }\n+          if (target_obj < source_obj) {\n+            ++(*n_downward_moves);\n+          }\n+          \/\/ Append to the moves list.\n+          PendingMove move = {(char *)source_obj, (char *)target_obj,\n+                              obj_size_bytes};\n+          total_size_words += obj_size;\n+          moves->append(move);\n+\n+          \/\/ Update source and target ranges.\n+          source_low = MIN2(source_low, move.source_begin());\n+          source_high = MAX2(source_high, move.source_end());\n+          target_low = MIN2(target_low, move.target_begin());\n+          target_high = MAX2(target_high, move.target_end());\n+        } else {  \/\/ dead!\n+          __tsan_java_free((char *)source_obj, obj_size_bytes);\n+          ++deleted_objects;\n+        }\n+      }\n+    }\n+\n+    \/\/ Update the oop map.\n+    delete TsanOopMapImpl::oop_map;\n+    TsanOopMapImpl::oop_map = new_map;\n+\n+    disjoint_regions = (source_low >= target_high || source_high <= target_low);\n+    log_debug(gc)(\n+          \"Tsan: map of \" SIZE_FORMAT \" objects, \" SIZE_FORMAT \" deleted, \"\n+          SIZE_FORMAT \" unmoved, \" SIZE_FORMAT \" to move \"\n+          \"(\" SIZE_FORMAT \" words), %soverlap\",\n+          map_size, deleted_objects, unmoved_objects, (size_t)moves->length(),\n+          total_size_words, disjoint_regions ? \"no \" : \"\");\n+\n+    *min_low = MIN2(source_low, target_low);\n+    *max_high = MAX2(source_high, target_high);\n+    return disjoint_regions;\n+  }\n+\n+  void TsanOopSizeMap::handle_overlapping_moves(GrowableArray<PendingMove>& moves,\n+                                                char* min_low,\n+                                                char* max_high) {\n+    \/\/ Populate occupied memory. The bitmap allocated by the OccupancyMap can\n+    \/\/ be fairly large, scope this code and insert a ResourceMark\n+    ResourceMark rm;\n+    OccupancyMap occupied_memory(min_low, max_high);\n+    DEBUG_PRINT(\"%s:%d: %d objects occupying %d words between %p and %p\\n\",\n+                __FUNCTION__, __LINE__, moves.length(),\n+                occupied_memory.bit_count(),\n+                MIN2(source_low, target_low),\n+                MAX2(source_high, target_high));\n+    for (int i = 0; i < moves.length(); ++i) {\n+      PendingMove &m = moves.at(i);\n+      occupied_memory.range_occupy(m.source_begin(), m.source_end());\n+    }\n+\n+    \/\/ Keep traversing moves list until everything is moved\n+    int passes = 0;\n+    for (int remaining_moves = moves.length(); remaining_moves > 0; ) {\n+      ++passes;\n+      int moves_this_cycle = 0;\n+      for (int i = 0; i < moves.length(); ++i) {\n+        if (moves.at(i).n_bytes == 0) {\n+           \/\/ Already moved this one.\n+           continue;\n+        }\n+\n+        \/\/ Check if this move is currently possible.\n+        \/\/ For this, everything in the target region that is not in the source\n+        \/\/ region has to be vacant.\n+        bool can_move;\n+        PendingMove &m = moves.at(i);\n+        if (m.target_begin() < m.source_begin()) {\n+          \/\/ '+++++++' is region being moved, lower addresses are to the left:\n+          \/\/ Moving downwards:\n+          \/\/         ++++++++         SOURCE\n+          \/\/    ++++++++              TARGET\n+          \/\/ or\n+          \/\/              ++++++++    SOURCE\n+          \/\/    ++++++++              TARGET\n+          can_move = occupied_memory.is_range_vacant(\n+              m.target_begin(), MIN2(m.target_end(), m.source_begin()));\n+        } else {\n+          \/\/ Moving upwards:\n+          \/\/    ++++++++              SOURCE\n+          \/\/         ++++++++         TARGET\n+          \/\/ or\n+          \/\/    ++++++++              SOURCE\n+          \/\/              ++++++++    TARGET\n+          can_move = occupied_memory.is_range_vacant(\n+              MAX2(m.source_end(), m.target_begin()), m.target_end());\n+        }\n+        if (can_move) {\n+          \/\/ Notify TSan, update occupied region.\n+          __tsan_java_move(m.source_begin(), m.target_begin(), m.n_bytes);\n+          occupied_memory.range_vacate(m.source_begin(), m.source_end());\n+          occupied_memory.range_occupy(m.target_begin(), m.target_end());\n+          \/\/ Indicate that this move has been done and remember that we\n+          \/\/ made some progress.\n+          m.n_bytes = 0;\n+          ++moves_this_cycle;\n+        }\n+      }\n+      \/\/ We have to make some progress, otherwise bail out:\n+      guarantee(moves_this_cycle, \"Impossible to reconcile GC\");\n+\n+      guarantee(remaining_moves >= moves_this_cycle,\n+                \"Excessive number of moves\");\n+      remaining_moves -= moves_this_cycle;\n+      DEBUG_PRINT(\"%s:%d: %d moved, %d remaining\\n\", __FUNCTION__, __LINE__,\n+                  moves_this_cycle, remaining_moves);\n+    }\n+    log_debug(gc)(\"Tsan: Move %d passes\", passes);\n+  }\n+\n+  void TsanOopSizeMap::rebuild_oops_map(BoolObjectClosure *is_alive,\n+                                        OopClosure *pointer_adjuster) {\n+    ResourceMark rm;\n+    GrowableArray<PendingMove> moves(MAX2((int)(oop_map->size() \/ 100),\n+                                          100000));\n+    bool disjoint_regions;\n+    int n_downward_moves;\n+    char *min_low, *max_high;\n+\n+    {\n+      disjoint_regions = collect_oops(is_alive, pointer_adjuster, &moves,\n+                                      &n_downward_moves, &min_low, &max_high);\n+    }\n+    if (moves.length() == 0) {\n+      return;\n+    }\n+\n+    \/\/ Notifying TSan is straightforward when source and target regions\n+    \/\/ do not overlap:\n+    if (disjoint_regions) {\n+      for (int i = 0; i < moves.length(); ++i) {\n+        const PendingMove &m = moves.at(i);\n+        __tsan_java_move(m.source_begin(), m.target_begin(), m.n_bytes);\n+      }\n+      return;\n+    }\n+\n+    \/\/ Source and target ranges overlap, the moves need to be ordered to prevent\n+    \/\/ overwriting. Overall, this can take N^2 steps if only one object can be\n+    \/\/ moved during the array traversal; however, when we are dealing with\n+    \/\/ compacting garbage collector, observation shows that the overwhelming\n+    \/\/ majority of the objects move in one direction. If we sort the moves (in\n+    \/\/ the ascending order if dominant direction is downwards, in the descending\n+    \/\/ order otherwise), chances are we will be able to order the moves in a few\n+    \/\/ traversals of the moves array.\n+    {\n+      moves.sort((2 * n_downward_moves > moves.length()) ? lessThan : moreThan);\n+      log_debug(gc)(\"Tsan: sort %d objects\", moves.length());\n+    }\n+\n+    {\n+      handle_overlapping_moves(moves, min_low, max_high);\n+    }\n+  }\n+\n+}  \/\/ namespace TsanOopMapImpl\n+\n+\n+void TsanOopMap::initialize_map() {\n+  TsanOopMapImpl::oop_map = new TsanOopMapImpl::TsanOopSizeMap(512);\n+}\n+\n+void TsanOopMap::destroy() {\n+  delete TsanOopMapImpl::oop_map;\n+}\n+\n+void TsanOopMap::weak_oops_do(\n+    BoolObjectClosure* is_alive,\n+    OopClosure* pointer_adjuster) {\n+  if (!ThreadSanitizer) return;\n+  assert(SafepointSynchronize::is_at_safepoint(), \"must be at a safepoint\");\n+\n+  \/\/ We're mutating oopMap, but we don't need to acquire TsanOopMap_lock:\n+  \/\/ Mutation to map happens at (A) constructor (single threaded) and\n+  \/\/ (B) add (in mutator threads) and (C) do_weak_oops (single-threaded).\n+  \/\/ Calls between add are synchronized.\n+  \/\/ Calls between add and do_weak_oops are synchronized via STW GC.\n+  TsanOopMapImpl::TsanOopSizeMap::rebuild_oops_map(\n+      is_alive, pointer_adjuster);\n+}\n+\n+\/\/ Safe to deal with raw oop; for example this is called in a LEAF function\n+\/\/ There is no safepoint in this code: 1) special mutex is used, and\n+\/\/ 2) there is no VM state transition\n+\/\/ We cannot use ordinary VM mutex, as that requires a state transition.\n+void TsanOopMap::add_oop_with_size(oopDesc *addr, int size) {\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  assert(TsanOopMapImpl::oop_map != NULL, \"TsanOopMap not initialized\");\n+  guarantee(addr != NULL, \"null oop\");\n+  bool alloc = false;\n+  {\n+    MutexLocker mu(TsanOopMap_lock, Mutex::_no_safepoint_check_flag);\n+    \/\/ N.B. addr->size() may not be available yet!\n+    alloc = TsanOopMapImpl::oop_map->put(addr, size);\n+  }\n+  if (alloc) {\n+    __tsan_java_alloc(addr, size * HeapWordSize);\n+  }\n+}\n+\n+void TsanOopMap::add_oop(oopDesc *addr) {\n+  \/\/ N.B. oop's size field must be init'ed; else addr->size() crashes.\n+  TsanOopMap::add_oop_with_size(addr, addr->size());\n+}\n+\n+#ifdef ASSERT\n+bool TsanOopMap::exists(oopDesc *addr) {\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  assert(TsanOopMapImpl::oop_map != NULL, \"TsanOopMap not initialized\");\n+  guarantee(addr != NULL, \"null oop\");\n+  bool in_map = false;\n+  {\n+    MutexLocker mu(TsanOopMap_lock, Mutex::_no_safepoint_check_flag);\n+    in_map = TsanOopMapImpl::oop_map->exists(addr);\n+  }\n+  return in_map;\n+}\n+#endif\n","filename":"src\/hotspot\/share\/tsan\/tsanOopMap.cpp","additions":530,"deletions":0,"binary":false,"changes":530,"status":"added"},{"patch":"@@ -268,0 +268,19 @@\n+#ifndef INCLUDE_TSAN\n+#define INCLUDE_TSAN 1\n+#endif\n+\n+#if INCLUDE_TSAN\n+#define TSAN_ONLY(code) code\n+#define TSAN_RUNTIME_ONLY(code) \\\n+    do { \\\n+      if (ThreadSanitizer) { \\\n+        code; \\\n+      } \\\n+    } while (0)\n+#define NOT_TSAN(code)\n+#else\n+#define TSAN_ONLY(code)\n+#define TSAN_RUNTIME_ONLY(code)\n+#define NOT_TSAN(code) code\n+#endif\n+\n","filename":"src\/hotspot\/share\/utilities\/macros.hpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -96,0 +96,5 @@\n+                if (TSAN_ENABLED) {\n+                  \/\/ TODO: Move this call to when a batch of finalizers\n+                  \/\/ are added to the queue.\n+                  tsanFinalize();\n+                }\n@@ -182,0 +187,4 @@\n+    private final static boolean TSAN_ENABLED = isTsanEnabled();\n+    private static native boolean isTsanEnabled();\n+    private native void tsanFinalize();\n+\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/Finalizer.java","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -113,0 +113,1 @@\n+    exports java.util.concurrent.annotation;\n","filename":"src\/java.base\/share\/classes\/module-info.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -176,0 +176,34 @@\n+\n+#ifdef INCLUDE_TSAN\n+\/*\n+ * Because currently we link TSAN runtime with the launcher,\n+ * these functions have to reside in the launcher in order to properly\n+ * override TSAN's internal \"weak\" version of these functions when\n+ * the TSAN runtime is initialized, which happens in ELF .preinit_array.\n+ * 'visibility(\"default\")' is needed due to CFLAGS '-fvisibility=hidden'.\n+ *\/\n+\n+\/*\n+ * Override ThreadSanitizer's default race suppression list, so Java TSAN\n+ * does not report C\/C++ races within the JVM itself.\n+ *\/\n+__attribute__((visibility(\"default\"))) const char *__tsan_default_suppressions() {\n+  return (\"called_from_lib:\/libjvm.so\\n\"\n+          \"called_from_lib:\/libjimage.so\\n\"\n+          \/\/ Intentional races in java.lang.invoke.* related to counters\n+          \"race:^java.lang.invoke.\\n\"\n+          \/\/ classic lazy init on String.hash\n+          \/\/ TODO: use field suppression\n+          \"race_top:^java.lang.String.hashCode\\n\"\n+          \/\/ Suppress known, benign races in j.c.u\n+          \"race_top:^java.util.concurrent.ConcurrentHashMap\\n\");\n+}\n+\n+__attribute__((visibility(\"default\"))) void __tsan_symbolize_external_ex(\n+    uint64_t loc,\n+    TsanSymbolizeAddFrameFunc add_frame,\n+    void *ctx) {\n+  tsan_symbolize_func(loc, add_frame, ctx);\n+}\n+#endif \/\/ INCLUDE_TSAN\n+\n","filename":"src\/java.base\/share\/native\/launcher\/main.c","additions":34,"deletions":0,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -2,1 +2,2 @@\n- * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021 Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019 Google and\/or its affiliates. All rights reserved.\n@@ -26,0 +27,1 @@\n+#include \"jni.h\"\n@@ -30,0 +32,14 @@\n+void __tsan_java_finalize() __attribute__((weak));\n+\n+JNIEXPORT void JNICALL\n+Java_java_lang_ref_Finalizer_tsanFinalize(JNIEnv *env, jclass unused)\n+{\n+  __tsan_java_finalize();\n+}\n+\n+JNIEXPORT jboolean JNICALL\n+Java_java_lang_ref_Finalizer_isTsanEnabled(JNIEnv *env, jclass unused)\n+{\n+  return JVM_GetTsanEnabled(env);\n+}\n+\n","filename":"src\/java.base\/share\/native\/libjava\/Finalizer.c","additions":17,"deletions":1,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -223,0 +223,8 @@\n+#ifdef INCLUDE_TSAN\n+\/*\n+ * Function pointer to JVM's TSAN symbolize function.\n+ *\/\n+__attribute__((visibility(\"default\")))\n+TsanSymbolize_t tsan_symbolize_func = NULL;\n+#endif\n+\n@@ -298,0 +306,3 @@\n+#ifdef INCLUDE_TSAN\n+    tsan_symbolize_func = ifn.TsanSymbolize;\n+#endif\n","filename":"src\/java.base\/share\/native\/libjli\/java.c","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -567,0 +567,9 @@\n+#ifdef INCLUDE_TSAN\n+    ifn->TsanSymbolize = (TsanSymbolize_t)\n+        dlsym(libjvm, \"TsanSymbolize\");\n+    if (ifn->TsanSymbolize == NULL) {\n+        JLI_ReportErrorMessage(DLL_ERROR2, jvmpath, dlerror());\n+        return JNI_FALSE;\n+    }\n+#endif\n+\n","filename":"src\/java.base\/unix\/native\/libjli\/java_md.c","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"}]}