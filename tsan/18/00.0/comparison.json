{"files":[{"patch":"@@ -5,0 +5,1 @@\n+version=21\n@@ -18,1 +19,1 @@\n-files=.*\\.cpp|.*\\.hpp|.*\\.c|.*\\.h|.*\\.java|.*\\.cc|.*\\.hh|.*\\.m|.*\\.mm|.*\\.gmk|.*\\.m4|.*\\.ac|Makefile\n+files=.*\\.cpp|.*\\.hpp|.*\\.c|.*\\.h|.*\\.java|.*\\.cc|.*\\.hh|.*\\.m|.*\\.mm|.*\\.md|.*\\.gmk|.*\\.m4|.*\\.ac|Makefile\n","filename":".jcheck\/conf","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2016, 2021, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2016, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -96,0 +96,3 @@\n+JTREG_TEST_THREAD_FACTORY_DIR := $(TEST_IMAGE_DIR)\/jtreg_test_thread_factory\n+JTREG_TEST_THREAD_FACTORY_JAR := $(JTREG_TEST_THREAD_FACTORY_DIR)\/jtregTestThreadFactory.jar\n+\n@@ -142,1 +145,1 @@\n-# to use on command line. The other two are for predifined configurations in JDL\n+# to use on command line. The other two are for predefined configurations in JDL\n@@ -199,0 +202,1 @@\n+$(eval $(call SetTestOpt,REPORT,JTREG))\n@@ -202,2 +206,2 @@\n-        TEST_MODE ASSERT VERBOSE RETAIN MAX_MEM RUN_PROBLEM_LISTS \\\n-        RETRY_COUNT MAX_OUTPUT, \\\n+        TEST_MODE ASSERT VERBOSE RETAIN TEST_THREAD_FACTORY MAX_MEM RUN_PROBLEM_LISTS \\\n+        RETRY_COUNT REPEAT_COUNT MAX_OUTPUT REPORT $(CUSTOM_JTREG_SINGLE_KEYWORDS), \\\n@@ -205,1 +209,2 @@\n-        EXTRA_PROBLEM_LISTS LAUNCHER_OPTIONS, \\\n+        EXTRA_PROBLEM_LISTS LAUNCHER_OPTIONS \\\n+        $(CUSTOM_JTREG_STRING_KEYWORDS), \\\n@@ -351,0 +356,11 @@\n+# with test id: dir\/Test.java#selection -> Test.java#selection -> .java#selection -> #selection\n+#      without: dir\/Test.java           -> Test.java           -> .java           -> <<empty string>>\n+TestID = \\\n+    $(subst .sh,,$(subst .html,,$(subst .java,,$(suffix $(notdir $1)))))\n+\n+# The test id starting with a hash (#testid) will be stripped by all\n+# evals in ParseJtregTestSelectionInner and will be reinserted by calling\n+# TestID (if it is present).\n+ParseJtregTestSelection = \\\n+    $(call IfAppend, $(call ParseJtregTestSelectionInner, $1), $(call TestID, $1))\n+\n@@ -357,1 +373,1 @@\n-define ParseJtregTestSelection\n+define ParseJtregTestSelectionInner\n@@ -421,0 +437,9 @@\n+ParseTestSelection = \\\n+    $(strip $(or \\\n+      $(call ParseCustomTestSelection, $1) \\\n+      $(call ParseGtestTestSelection, $1) \\\n+      $(call ParseMicroTestSelection, $1) \\\n+      $(call ParseJtregTestSelection, $1) \\\n+      $(call ParseSpecialTestSelection, $1) \\\n+    ))\n+\n@@ -423,20 +448,2 @@\n-TESTS_TO_RUN :=\n-$(foreach test, $(TEST), \\\n-  $(eval PARSED_TESTS := $(call ParseCustomTestSelection, $(test))) \\\n-  $(if $(strip $(PARSED_TESTS)), , \\\n-    $(eval PARSED_TESTS += $(call ParseGtestTestSelection, $(test))) \\\n-  ) \\\n-  $(if $(strip $(PARSED_TESTS)), , \\\n-    $(eval PARSED_TESTS += $(call ParseMicroTestSelection, $(test))) \\\n-  ) \\\n-  $(if $(strip $(PARSED_TESTS)), , \\\n-    $(eval PARSED_TESTS += $(call ParseJtregTestSelection, $(test))) \\\n-  ) \\\n-  $(if $(strip $(PARSED_TESTS)), , \\\n-    $(eval PARSED_TESTS += $(call ParseSpecialTestSelection, $(test))) \\\n-  ) \\\n-  $(if $(strip $(PARSED_TESTS)), , \\\n-    $(eval UNKNOWN_TEST := $(test)) \\\n-  ) \\\n-  $(eval TESTS_TO_RUN += $(PARSED_TESTS)) \\\n-)\n+TESTS_TO_RUN := $(strip $(foreach test, $(TEST), $(call ParseTestSelection, $(test))))\n+UNKNOWN_TEST := $(strip $(foreach test, $(TEST), $(if $(call ParseTestSelection, $(test)), , $(test))))\n@@ -450,3 +457,0 @@\n-TESTS_TO_RUN := $(strip $(TESTS_TO_RUN))\n-\n-\n@@ -526,1 +530,1 @@\n-\t      test cases? ran\/ { print $$$$2 }' $$($1_RESULT_FILE))) \\\n+\t      test (cases?|suites?) ran\/ { print $$$$2 }' $$($1_RESULT_FILE))) \\\n@@ -745,0 +749,1 @@\n+  JTREG_TEST_THREAD_FACTORY ?=\n@@ -747,0 +752,18 @@\n+  JTREG_REPEAT_COUNT ?= 0\n+  JTREG_REPORT ?= files\n+\n+  ifneq ($$(JTREG_RETRY_COUNT), 0)\n+    ifneq ($$(JTREG_REPEAT_COUNT), 0)\n+      $$(info Error: Cannot use both JTREG_RETRY_COUNT and JTREG_REPEAT_COUNT together.)\n+      $$(info Please choose one or the other.)\n+      $$(error Cannot continue)\n+    endif\n+  endif\n+\n+  ifneq ($$(JTREG_TEST_THREAD_FACTORY), )\n+    $1_JTREG_BASIC_OPTIONS += -testThreadFactoryPath:$$(JTREG_TEST_THREAD_FACTORY_JAR)\n+    $1_JTREG_BASIC_OPTIONS += -testThreadFactory:$$(JTREG_TEST_THREAD_FACTORY)\n+    $1_JTREG_BASIC_OPTIONS += $$(addprefix $$(JTREG_PROBLEM_LIST_PREFIX), $$(wildcard \\\n+\t$$(addprefix $$($1_TEST_ROOT)\/, ProblemList-$$(JTREG_TEST_THREAD_FACTORY).txt) \\\n+    ))\n+  endif\n@@ -773,0 +796,2 @@\n+  # test.boot.jdk is used by some test cases that want to execute a previous\n+  # version of the JDK.\n@@ -777,0 +802,1 @@\n+      -vmoption:-Dtest.boot.jdk=\"$$(BOOT_JDK)\" \\\n@@ -784,2 +810,0 @@\n-  # Some tests needs to find a boot JDK using the JDK8_HOME variable.\n-  $1_JTREG_BASIC_OPTIONS += -e:JDK8_HOME=$$(BOOT_JDK)\n@@ -790,0 +814,2 @@\n+  else ifeq ($$(call isTargetOs, linux), true)\n+      $1_JTREG_BASIC_OPTIONS += -e:_JVM_DWARF_PATH=$$(SYMBOLS_IMAGE_DIR)\n@@ -844,0 +870,2 @@\n+  $$(eval $$(call SetupRunJtregTestCustom, $1))\n+\n@@ -855,1 +883,2 @@\n-          -status:$$$${JTREG_STATUS} \\\n+          -report:$${JTREG_REPORT} \\\n+          $$$${JTREG_STATUS} \\\n@@ -878,0 +907,12 @@\n+  ifneq ($$(JTREG_REPEAT_COUNT), 0)\n+    $1_COMMAND_LINE := \\\n+        for i in {1..$$(JTREG_REPEAT_COUNT)}; do \\\n+          $$(PRINTF) \"\\nRepeating Jtreg run: $$$$i out of $$(JTREG_REPEAT_COUNT)\\n\"; \\\n+          $$($1_COMMAND_LINE); \\\n+          if [ \"`$$(CAT) $$($1_EXITCODE)`\" != \"0\" ]; then \\\n+            $$(PRINTF) \"\\nFailures detected, no more repeats.\\n\"; \\\n+            break; \\\n+          fi; \\\n+        done\n+  endif\n+\n@@ -1174,3 +1215,1 @@\n-    ifneq ($(and $(HG), $(wildcard $(TOPDIR)\/.hg)), )\n-      DIFF_COMMAND := $(HG) -R $(TOPDIR) diff -r $(TEST_OPTS_JCOV_DIFF_CHANGESET) > $(JCOV_SOURCE_DIFF)\n-    else ifneq ($(and $(GIT), $(wildcard $(TOPDIR)\/.git)), )\n+    ifneq ($(and $(GIT), $(wildcard $(TOPDIR)\/.git)), )\n@@ -1179,2 +1218,2 @@\n-      $(info Error: Must be either hg or git source tree for diff coverage.)\n-      $(error Neither hg nor git source tree.)\n+      $(info Error: Must be a git source tree for diff coverage.)\n+      $(error No git source tree.)\n","filename":"make\/RunTests.gmk","additions":77,"deletions":38,"binary":false,"changes":115,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2011, 2021, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2011, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -54,0 +54,8 @@\n+    elif test \"x$OPENJDK_TARGET_OS\" = xaix; then\n+      # Linking is different on aix\n+      SHARED_LIBRARY_FLAGS=\"-shared -Wl,-bM:SRE -Wl,-bnoentry\"\n+      SET_EXECUTABLE_ORIGIN=\"\"\n+      SET_SHARED_LIBRARY_ORIGIN=''\n+      SET_SHARED_LIBRARY_NAME=''\n+      SET_SHARED_LIBRARY_MAPFILE=''\n+\n@@ -98,0 +106,4 @@\n+\n+  # Debug prefix mapping if supported by compiler\n+  DEBUG_PREFIX_CFLAGS=\n+\n@@ -100,1 +112,13 @@\n-    CFLAGS_DEBUG_SYMBOLS=\"-g\"\n+    if test \"x$ALLOW_ABSOLUTE_PATHS_IN_OUTPUT\" = \"xfalse\"; then\n+      # Check if compiler supports -fdebug-prefix-map. If so, use that to make\n+      # the debug symbol paths resolve to paths relative to the workspace root.\n+      workspace_root_trailing_slash=\"${WORKSPACE_ROOT%\/}\/\"\n+      DEBUG_PREFIX_CFLAGS=\"-fdebug-prefix-map=${workspace_root_trailing_slash}=\"\n+      FLAGS_COMPILER_CHECK_ARGUMENTS(ARGUMENT: [${DEBUG_PREFIX_CFLAGS}],\n+        IF_FALSE: [\n+            DEBUG_PREFIX_CFLAGS=\n+        ]\n+      )\n+    fi\n+\n+    CFLAGS_DEBUG_SYMBOLS=\"-g -gdwarf-4\"\n@@ -103,1 +127,18 @@\n-    CFLAGS_DEBUG_SYMBOLS=\"-g\"\n+    if test \"x$ALLOW_ABSOLUTE_PATHS_IN_OUTPUT\" = \"xfalse\"; then\n+      # Check if compiler supports -fdebug-prefix-map. If so, use that to make\n+      # the debug symbol paths resolve to paths relative to the workspace root.\n+      workspace_root_trailing_slash=\"${WORKSPACE_ROOT%\/}\/\"\n+      DEBUG_PREFIX_CFLAGS=\"-fdebug-prefix-map=${workspace_root_trailing_slash}=\"\n+      FLAGS_COMPILER_CHECK_ARGUMENTS(ARGUMENT: [${DEBUG_PREFIX_CFLAGS}],\n+        IF_FALSE: [\n+            DEBUG_PREFIX_CFLAGS=\n+        ]\n+      )\n+    fi\n+\n+    # -gdwarf-4 and -gdwarf-aranges were introduced in clang 5.0\n+    GDWARF_FLAGS=\"-gdwarf-4 -gdwarf-aranges\"\n+    FLAGS_COMPILER_CHECK_ARGUMENTS(ARGUMENT: [${GDWARF_FLAGS}],\n+        IF_FALSE: [GDWARF_FLAGS=\"\"])\n+\n+    CFLAGS_DEBUG_SYMBOLS=\"-g ${GDWARF_FLAGS}\"\n@@ -111,0 +152,5 @@\n+  if test \"x$DEBUG_PREFIX_CFLAGS\" != x; then\n+    CFLAGS_DEBUG_SYMBOLS=\"$CFLAGS_DEBUG_SYMBOLS $DEBUG_PREFIX_CFLAGS\"\n+    ASFLAGS_DEBUG_SYMBOLS=\"$ASFLAGS_DEBUG_SYMBOLS $DEBUG_PREFIX_CFLAGS\"\n+  fi\n+\n@@ -137,5 +183,1 @@\n-      DISABLED_WARNINGS=\"4800\"\n-      if test \"x$TOOLCHAIN_VERSION\" = x2017; then\n-        # VS2017 incorrectly triggers this warning for constexpr\n-        DISABLED_WARNINGS+=\" 4307\"\n-      fi\n+      DISABLED_WARNINGS=\"4800 5105\"\n@@ -158,0 +200,4 @@\n+      # gcc10\/11 on ppc generate lots of abi warnings about layout of aggregates containing vectors\n+      if test \"x$OPENJDK_TARGET_CPU_ARCH\" = \"xppc\"; then\n+        DISABLED_WARNINGS=\"$DISABLED_WARNINGS psabi\"\n+      fi\n@@ -162,0 +208,1 @@\n+      BUILD_CC_DISABLE_WARNING_PREFIX=\"-Wno-\"\n@@ -170,1 +217,0 @@\n-\n@@ -203,1 +249,1 @@\n-      # get's added conditionally on whether we produce debug symbols or not.\n+      # gets added conditionally on whether we produce debug symbols or not.\n@@ -256,0 +302,4 @@\n+    elif test \"x$OPENJDK_TARGET_OS\" = xaix; then\n+      C_O_FLAG_HIGHEST_JVM=\"-O3 -finline-functions\"\n+      C_O_FLAG_HIGHEST=\"-O3 -finline-functions\"\n+      C_O_FLAG_HI=\"-O3 -finline-functions\"\n@@ -260,2 +310,2 @@\n-      C_O_FLAG_NORM=\"-O2\"\n-      C_O_FLAG_DEBUG_JVM=\"-O0\"\n+    C_O_FLAG_NORM=\"-O2\"\n+    C_O_FLAG_DEBUG_JVM=\"-O0\"\n@@ -432,0 +482,3 @@\n+    if test \"x$TOOLCHAIN_TYPE\" = xclang && test \"x$OPENJDK_TARGET_OS\" = xaix; then\n+      DEBUG_CFLAGS_JVM=\"-fpic -mcmodel=large\"\n+    fi\n@@ -449,3 +502,6 @@\n-    ALWAYS_DEFINES_JDK=\"-DWIN32_LEAN_AND_MEAN -D_CRT_SECURE_NO_DEPRECATE \\\n-        -D_CRT_NONSTDC_NO_DEPRECATE -DWIN32 -DIAL\"\n-    ALWAYS_DEFINES_JVM=\"-DNOMINMAX -DWIN32_LEAN_AND_MEAN\"\n+    # Access APIs for Windows 8 and above\n+    # see https:\/\/docs.microsoft.com\/en-us\/cpp\/porting\/modifying-winver-and-win32-winnt?view=msvc-170\n+    ALWAYS_DEFINES_JDK=\"-DWIN32_LEAN_AND_MEAN -D_WIN32_WINNT=0x0602 \\\n+        -D_CRT_SECURE_NO_WARNINGS -D_CRT_NONSTDC_NO_DEPRECATE -DWIN32 -DIAL\"\n+    ALWAYS_DEFINES_JVM=\"-DNOMINMAX -DWIN32_LEAN_AND_MEAN -D_WIN32_WINNT=0x0602 \\\n+        -D_CRT_SECURE_NO_WARNINGS -D_CRT_NONSTDC_NO_DEPRECATE\"\n@@ -464,0 +520,6 @@\n+  if test \"x$TOOLCHAIN_TYPE\" = xclang && test \"x$OPENJDK_TARGET_OS\" = xaix; then\n+    # clang compiler on aix needs -ffunction-sections\n+    TOOLCHAIN_CFLAGS_JVM=\"$TOOLCHAIN_CFLAGS_JVM -ffunction-sections -ftls-model -fno-math-errno -fstack-protector\"\n+    TOOLCHAIN_CFLAGS_JDK=\"-ffunction-sections -fsigned-char -fstack-protector\"\n+  fi\n+\n@@ -465,1 +527,1 @@\n-    TOOLCHAIN_CFLAGS_JVM=\"$TOOLCHAIN_CFLAGS_JVM -fcheck-new -fstack-protector\"\n+    TOOLCHAIN_CFLAGS_JVM=\"$TOOLCHAIN_CFLAGS_JVM -fstack-protector\"\n@@ -512,1 +574,1 @@\n-    TOOLCHAIN_CFLAGS_JVM=\"-qtbtable=full -qtune=balanced \\\n+    TOOLCHAIN_CFLAGS_JVM=\"-qtbtable=full -qtune=balanced -fno-exceptions \\\n@@ -515,2 +577,2 @@\n-    TOOLCHAIN_CFLAGS_JVM=\"-nologo -MD -MP\"\n-    TOOLCHAIN_CFLAGS_JDK=\"-nologo -MD -Zc:wchar_t-\"\n+    TOOLCHAIN_CFLAGS_JVM=\"-nologo -MD -Zc:preprocessor -Zc:strictStrings -MP\"\n+    TOOLCHAIN_CFLAGS_JDK=\"-nologo -MD -Zc:preprocessor -Zc:strictStrings -Zc:wchar_t-\"\n@@ -520,6 +582,1 @@\n-  # Ideally we would have a common level across all toolchains so that all sources\n-  # are sure to conform to the same standard. Unfortunately neither our sources nor\n-  # our toolchains are in a condition to support that. But what we loosely aim for is\n-  # C99 level.\n-    # Explicitly set C99. clang and xlclang support the same flag.\n-    LANGSTD_CFLAGS=\"-std=c99\"\n+    LANGSTD_CFLAGS=\"-std=c11\"\n@@ -528,6 +585,1 @@\n-    # MSVC doesn't support C99\/C11 explicitly, unless you compile as C++:\n-    # LANGSTD_CFLAGS=\"-TP\"\n-    # but that requires numerous changes to the sources files. So we are limited\n-    # to C89\/C90 plus whatever extensions Visual Studio has decided to implement.\n-    # This is the lowest bar for shared code.\n-    LANGSTD_CFLAGS=\"\"\n+    LANGSTD_CFLAGS=\"-std:c11\"\n@@ -588,0 +640,3 @@\n+  elif test \"x$TOOLCHAIN_TYPE\" = xclang && test \"x$OPENJDK_TARGET_OS\" = xaix; then\n+    JVM_PICFLAG=\"-fpic -mcmodel=large -Wl,-bbigtoc\n+    JDK_PICFLAG=\"-fpic\n@@ -624,1 +679,1 @@\n-      -DJNIEXPORT='__attribute__((visibility(\\\"hidden\\\")))'\"\n+      -DJNIEXPORT='__attribute__((visibility(\\\"default\\\")))'\"\n@@ -665,1 +720,1 @@\n-  # toolchain dependend, per-cpu\n+  # toolchain dependent, per-cpu\n@@ -733,0 +788,3 @@\n+    if test \"x$OPENJDK_TARGET_OS\" = xaix; then\n+      $1_CFLAGS_CPU=\"-mcpu=pwr8\"\n+    fi\n@@ -767,4 +825,2 @@\n-  if test \"x$TOOLCHAIN_TYPE\" = xmicrosoft && test \"x$ENABLE_REPRODUCIBLE_BUILD\" = xtrue; then\n-    # Enabling deterministic creates warnings if __DATE__ or __TIME__ are\n-    # used, and since we are, silence that warning.\n-    REPRODUCIBLE_CFLAGS=\"-experimental:deterministic -wd5048\"\n+  if test \"x$TOOLCHAIN_TYPE\" = xmicrosoft; then\n+    REPRODUCIBLE_CFLAGS=\"-experimental:deterministic\"\n@@ -797,2 +853,1 @@\n-    elif test \"x$TOOLCHAIN_TYPE\" = xmicrosoft &&\n-        test \"x$ENABLE_REPRODUCIBLE_BUILD\" = xtrue; then\n+    elif test \"x$TOOLCHAIN_TYPE\" = xmicrosoft; then\n@@ -801,3 +856,1 @@\n-      workspace_root_win=`$FIXPATH_BASE print \"${WORKSPACE_ROOT%\/}\"`\n-      PATHMAP_FLAGS=\"-pathmap:${workspace_root_win\/\/\\\/\/\\\\\\\\}=s \\\n-          -pathmap:${workspace_root_win}=s\"\n+      PATHMAP_FLAGS=\"-pathmap:${WORKSPACE_ROOT}=s\"\n@@ -824,0 +877,2 @@\n+  FLAGS_SETUP_BRANCH_PROTECTION\n+\n@@ -829,1 +884,1 @@\n-      $REPRODUCIBLE_CFLAGS\"\n+      $REPRODUCIBLE_CFLAGS $BRANCH_PROTECTION_CFLAGS\"\n@@ -834,1 +889,1 @@\n-      $FILE_MACRO_CFLAGS $REPRODUCIBLE_CFLAGS\"\n+      $FILE_MACRO_CFLAGS $REPRODUCIBLE_CFLAGS $BRANCH_PROTECTION_CFLAGS\"\n@@ -888,2 +943,2 @@\n-  # These flags are required for GCC 6 builds as undefined behaviour in OpenJDK code\n-  # runs afoul of the more aggressive versions of these optimisations.\n+  # These flags are required for GCC 6 builds as undefined behavior in OpenJDK code\n+  # runs afoul of the more aggressive versions of these optimizations.\n@@ -900,0 +955,21 @@\n+\n+AC_DEFUN_ONCE([FLAGS_SETUP_BRANCH_PROTECTION],\n+[\n+  # Is branch protection available?\n+  BRANCH_PROTECTION_AVAILABLE=false\n+  BRANCH_PROTECTION_FLAG=\"-mbranch-protection=standard\"\n+\n+  if test \"x$OPENJDK_TARGET_CPU\" = xaarch64; then\n+    if test \"x$TOOLCHAIN_TYPE\" = xgcc || test \"x$TOOLCHAIN_TYPE\" = xclang; then\n+      FLAGS_COMPILER_CHECK_ARGUMENTS(ARGUMENT: [${BRANCH_PROTECTION_FLAG}],\n+          IF_TRUE: [BRANCH_PROTECTION_AVAILABLE=true])\n+    fi\n+  fi\n+\n+  BRANCH_PROTECTION_CFLAGS=\"\"\n+  UTIL_ARG_ENABLE(NAME: branch-protection, DEFAULT: false,\n+      RESULT: USE_BRANCH_PROTECTION, AVAILABLE: $BRANCH_PROTECTION_AVAILABLE,\n+      DESC: [enable branch protection when compiling C\/C++],\n+      IF_ENABLED: [ BRANCH_PROTECTION_CFLAGS=${BRANCH_PROTECTION_FLAG}])\n+  AC_SUBST(BRANCH_PROTECTION_CFLAGS)\n+])\n","filename":"make\/autoconf\/flags-cflags.m4","additions":122,"deletions":46,"binary":false,"changes":168,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2011, 2021, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2011, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -48,1 +48,1 @@\n-    jvmci jvmti link-time-opt management minimal nmt opt-size parallelgc \\\n+    jvmci jvmti link-time-opt management minimal opt-size parallelgc \\\n@@ -71,1 +71,0 @@\n-m4_define(jvm_feature_desc_nmt, [include native memory tracking (NMT)])\n@@ -252,2 +251,8 @@\n-    AC_MSG_CHECKING([for dtrace tool])\n-    if test \"x$DTRACE\" != \"x\" && test -x \"$DTRACE\"; then\n+    AC_MSG_CHECKING([for dtrace tool and platform support])\n+    if test \"x$OPENJDK_TARGET_CPU_ARCH\" = \"xppc\"; then\n+      AC_MSG_RESULT([no, $OPENJDK_TARGET_CPU_ARCH])\n+      AVAILABLE=false\n+    elif test \"x$OPENJDK_TARGET_CPU_ARCH\" = \"xs390\"; then\n+      AC_MSG_RESULT([no, $OPENJDK_TARGET_CPU_ARCH])\n+      AVAILABLE=false\n+    elif test \"x$DTRACE\" != \"x\" && test -x \"$DTRACE\"; then\n@@ -269,16 +274,0 @@\n-###############################################################################\n-# Check if the feature 'jfr' is available on this platform.\n-#\n-AC_DEFUN_ONCE([JVM_FEATURES_CHECK_JFR],\n-[\n-  JVM_FEATURES_CHECK_AVAILABILITY(jfr, [\n-    AC_MSG_CHECKING([if platform is supported by JFR])\n-    if test \"x$OPENJDK_TARGET_OS\" = xaix; then\n-      AC_MSG_RESULT([no, $OPENJDK_TARGET_OS-$OPENJDK_TARGET_CPU])\n-      AVAILABLE=false\n-    else\n-      AC_MSG_RESULT([yes])\n-    fi\n-  ])\n-])\n-\n@@ -296,0 +285,2 @@\n+    elif test \"x$OPENJDK_TARGET_CPU\" = \"xriscv64\"; then\n+      AC_MSG_RESULT([yes])\n@@ -311,1 +302,3 @@\n-        test \"x$OPENJDK_TARGET_CPU\" = \"xaarch64\" ; then\n+        test \"x$OPENJDK_TARGET_CPU\" = \"xaarch64\" || \\\n+        test \"x$OPENJDK_TARGET_CPU\" = \"xppc64le\" || \\\n+        test \"x$OPENJDK_TARGET_CPU\" = \"xriscv64\"; then\n@@ -408,0 +401,8 @@\n+    elif test \"x$OPENJDK_TARGET_CPU\" = \"xppc64le\" || \\\n+        test \"x$OPENJDK_TARGET_CPU\" = \"xriscv64\"; then\n+      if test \"x$OPENJDK_TARGET_OS\" = \"xlinux\"; then\n+        AC_MSG_RESULT([yes])\n+      else\n+        AC_MSG_RESULT([no, $OPENJDK_TARGET_OS-$OPENJDK_TARGET_CPU])\n+        AVAILABLE=false\n+      fi\n@@ -443,1 +444,0 @@\n-  JVM_FEATURES_CHECK_JFR\n@@ -450,6 +450,0 @@\n-  # Filter out features by default for all variants on certain platforms.\n-  # Make sure to just add to JVM_FEATURES_PLATFORM_FILTER, since it could\n-  # have a value already from custom extensions.\n-  if test \"x$OPENJDK_TARGET_OS\" = xaix; then\n-    JVM_FEATURES_PLATFORM_FILTER=\"$JVM_FEATURES_PLATFORM_FILTER jfr\"\n-  fi\n@@ -476,1 +470,1 @@\n-    JVM_FEATURES_VARIANT_UNAVAILABLE=\"cds compiler1 compiler2 \\\n+    JVM_FEATURES_VARIANT_UNAVAILABLE=\"compiler1 compiler2 \\\n@@ -487,1 +481,1 @@\n-        jfr jni-check jvmci jvmti management nmt parallelgc services \\\n+        jfr jni-check jvmci jvmti management parallelgc services \\\n@@ -582,4 +576,0 @@\n-  if JVM_FEATURES_IS_ACTIVE(management) && ! JVM_FEATURES_IS_ACTIVE(nmt); then\n-    AC_MSG_ERROR([Specified JVM feature 'management' requires feature 'nmt' for variant '$variant'])\n-  fi\n-\n","filename":"make\/autoconf\/jvm-features.m4","additions":25,"deletions":35,"binary":false,"changes":60,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2011, 2021, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2011, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -38,0 +38,5 @@\n+# How configure was originally called, if not called directly\n+REAL_CONFIGURE_COMMAND_EXEC_SHORT := @REAL_CONFIGURE_COMMAND_EXEC_SHORT@\n+REAL_CONFIGURE_COMMAND_EXEC_FULL := @REAL_CONFIGURE_COMMAND_EXEC_FULL@\n+REAL_CONFIGURE_COMMAND_LINE := @REAL_CONFIGURE_COMMAND_LINE@\n+\n@@ -41,1 +46,1 @@\n-# Path to autoconf if overriden by the user, to be used by \"make reconfigure\"\n+# Path to autoconf if overridden by the user, to be used by \"make reconfigure\"\n@@ -57,0 +62,3 @@\n+# Make sure we override any local CLASSPATH variable\n+export CLASSPATH := @CLASSPATH@\n+\n@@ -129,1 +137,7 @@\n-ENABLE_REPRODUCIBLE_BUILD := @ENABLE_REPRODUCIBLE_BUILD@\n+ISO_8601_FORMAT_STRING := @ISO_8601_FORMAT_STRING@\n+\n+ifneq ($(SOURCE_DATE), updated)\n+  # For \"updated\" source date value, these are set in InitSupport.gmk\n+  export SOURCE_DATE_EPOCH := $(SOURCE_DATE)\n+  SOURCE_DATE_ISO_8601 := @SOURCE_DATE_ISO_8601@\n+endif\n@@ -141,1 +155,1 @@\n-  # Prohibit msys2 from attemping any path wrangling\n+  # Prohibit msys2 from attempting any path wrangling\n@@ -239,1 +253,1 @@\n-VERSION_CFLAGS := \\\n+VERSION_CFLAGS = \\\n@@ -347,0 +361,2 @@\n+BUILD_JTREG_TEST_THREAD_FACTORY := @BUILD_JTREG_TEST_THREAD_FACTORY@\n+\n@@ -359,0 +375,6 @@\n+HSDIS_BACKEND := @HSDIS_BACKEND@\n+ENABLE_HSDIS_BUNDLING := @ENABLE_HSDIS_BUNDLING@\n+HSDIS_CFLAGS := @HSDIS_CFLAGS@\n+HSDIS_LDFLAGS := @HSDIS_LDFLAGS@\n+HSDIS_LIBS := @HSDIS_LIBS@\n+\n@@ -367,0 +389,3 @@\n+# Whether the boot jdk jar supports --date=TIMESTAMP\n+BOOT_JDK_JAR_SUPPORTS_DATE:=@BOOT_JDK_JAR_SUPPORTS_DATE@\n+\n@@ -387,0 +412,3 @@\n+# Fallback linker\n+ENABLE_FALLBACK_LINKER:=@ENABLE_FALLBACK_LINKER@\n+\n@@ -399,0 +427,1 @@\n+BRANCH_PROTECTION_CFLAGS := @BRANCH_PROTECTION_CFLAGS@\n@@ -412,0 +441,2 @@\n+# Source folder for user provided cacerts PEM files\n+CACERTS_SRC=@CACERTS_SRC@\n@@ -423,8 +454,9 @@\n-export ASAN_ENABLED:=@ASAN_ENABLED@\n-export DEVKIT_LIB_DIR:=@DEVKIT_LIB_DIR@\n-ifeq ($(ASAN_ENABLED), yes)\n-  export ASAN_OPTIONS=handle_segv=0 detect_leaks=0\n-  ifneq ($(DEVKIT_LIB_DIR),)\n-    export LD_LIBRARY_PATH:=$(LD_LIBRARY_PATH):$(DEVKIT_LIB_DIR)\n-  endif\n-endif\n+ASAN_ENABLED:=@ASAN_ENABLED@\n+\n+# LeakSanitizer\n+LSAN_ENABLED:=@LSAN_ENABLED@\n+\n+# UndefinedBehaviorSanitizer\n+UBSAN_ENABLED:=@UBSAN_ENABLED@\n+UBSAN_CFLAGS:=@UBSAN_CFLAGS@\n+UBSAN_LDFLAGS:=@UBSAN_LDFLAGS@\n@@ -441,1 +473,2 @@\n-# The macosx code signing identity to use\n+# The macosx code signing configuration\n+MACOSX_CODESIGN_MODE:=@MACOSX_CODESIGN_MODE@\n@@ -529,2 +562,1 @@\n-# Xcode SDK path\n-SDKROOT:=@SDKROOT@\n+SYSROOT := @SYSROOT@\n@@ -572,1 +604,0 @@\n-GNM:=@GNM@\n@@ -605,1 +636,1 @@\n-# Set origin using the linker, ie use the relative path to the dependent library to find the dependees.\n+# Set origin using the linker, ie use the relative path to the dependent library to find the dependencies.\n@@ -648,1 +679,1 @@\n-JMOD = $(JMOD_CMD) $(JAVA_TOOL_FLAGS_SMALL)\n+JMOD = $(JMOD_CMD)\n@@ -667,0 +698,2 @@\n+    --add-exports jdk.internal.opt\/jdk.internal.opt=jdk.compiler.interim \\\n+    --add-exports jdk.internal.opt\/jdk.internal.opt=jdk.javadoc.interim \\\n@@ -685,0 +718,1 @@\n+JMOD_COMPRESS:=@JMOD_COMPRESS@\n@@ -701,0 +735,1 @@\n+IS_GNU_DATE:=@IS_GNU_DATE@\n@@ -750,1 +785,0 @@\n-HG:=@HG@\n@@ -757,1 +791,0 @@\n-XCODEBUILD=@XCODEBUILD@\n@@ -920,1 +953,6 @@\n-BASE_NAME := $(VERSION_SHORT)+$(VERSION_BUILD)_$(OPENJDK_TARGET_BUNDLE_PLATFORM)\n+ifneq ($(VERSION_BUILD), )\n+  BASE_NAME := $(VERSION_SHORT)+$(VERSION_BUILD)_$(OPENJDK_TARGET_BUNDLE_PLATFORM)\n+else\n+  BASE_NAME := $(VERSION_SHORT)_$(OPENJDK_TARGET_BUNDLE_PLATFORM)\n+endif\n+\n","filename":"make\/autoconf\/spec.gmk.in","additions":60,"deletions":22,"binary":false,"changes":82,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2011, 2020, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2011, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -36,1 +36,0 @@\n-# On AIX\/xlc we need at least xlc 13.1 for the symbol hiding (see JDK-8214063)\n@@ -43,0 +42,2 @@\n+else ifeq ($(TOOLCHAIN_TYPE), xlc)\n+  LAUNCHER_CFLAGS += -qvisibility=hidden\n@@ -90,1 +91,1 @@\n-  $1_JAVA_ARGS += -ms8m\n+    $1_JAVA_ARGS += -ms8m\n@@ -100,3 +101,6 @@\n-  $1_JAVA_ARGS_STR := '{ $$(strip $$(foreach a, \\\n-      $$(addprefix -J, $$($1_JAVA_ARGS)) $$($1_LAUNCHER_CLASS), \"$$a\"$(COMMA) )) }'\n-  $1_CFLAGS += -DJAVA_ARGS=$$($1_JAVA_ARGS_STR)\n+\n+  ifneq ($$($1_JAVA_ARGS), )\n+    $1_JAVA_ARGS_STR := '{ $$(strip $$(foreach a, \\\n+        $$(addprefix -J, $$($1_JAVA_ARGS)) $$($1_LAUNCHER_CLASS), \"$$a\"$(COMMA) )) }'\n+    $1_CFLAGS += -DJAVA_ARGS=$$($1_JAVA_ARGS_STR)\n+  endif\n@@ -130,1 +134,0 @@\n-          $(SUPPORT_OUTPUTDIR)\/native\/java.base\/$(LIBRARY_PREFIX)fdlibm$(STATIC_LIBRARY_SUFFIX) \\\n@@ -155,0 +158,10 @@\n+  $1_EXTRA_FILES := $(LAUNCHER_SRC)\/main.c\n+\n+  ifeq ($(ASAN_ENABLED), true)\n+    $1_EXTRA_FILES += $(TOPDIR)\/make\/data\/asan\/asan_default_options.c\n+  endif\n+\n+  ifeq ($(LSAN_ENABLED), true)\n+    $1_EXTRA_FILES += $(TOPDIR)\/make\/data\/lsan\/lsan_default_options.c\n+  endif\n+\n@@ -157,1 +170,1 @@\n-      EXTRA_FILES := $(LAUNCHER_SRC)\/main.c, \\\n+      EXTRA_FILES := $$($1_EXTRA_FILES), \\\n@@ -211,1 +224,3 @@\n-# the case), so piggyback man page generation on the launcher compilation.\n+# the case), so piggyback man page generation on the launcher compilation. This\n+# file may be included from other places as well, so only process man pages\n+# when called from <module>\/Launcher.gmk.\n@@ -213,1 +228,1 @@\n-ifeq ($(call isTargetOsType, unix), true)\n+ifeq ($(call isTargetOsType, unix)+$(MAKEFILE_PREFIX), true+Launcher)\n@@ -257,3 +272,3 @@\n-\t\t@@COPYRIGHT_YEAR@@ => $(COPYRIGHT_YEAR) ; \\\n-\t\t@@VERSION_SHORT@@ => $(VERSION_SHORT) ; \\\n-\t\t@@VERSION_SPECIFICATION@@ => $(VERSION_SPECIFICATION), \\\n+              @@COPYRIGHT_YEAR@@ => $(COPYRIGHT_YEAR) ; \\\n+              @@VERSION_SHORT@@ => $(VERSION_SHORT) ; \\\n+              @@VERSION_SPECIFICATION@@ => $(VERSION_SPECIFICATION), \\\n","filename":"make\/common\/modules\/LauncherCommon.gmk","additions":28,"deletions":13,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2016, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2016, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -33,0 +33,1 @@\n+JVM_IsForeignLinkerSupported\n","filename":"make\/data\/hotspot-symbols\/symbols-shared","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2016, 2021, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2016, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -49,0 +49,1 @@\n+JVM_CurrentCarrierThread\n@@ -50,0 +51,1 @@\n+JVM_SetCurrentThread\n@@ -82,0 +84,1 @@\n+JVM_GetClassFileVersion\n@@ -123,0 +126,1 @@\n+JVM_GetNextThreadIdOffset\n@@ -139,0 +143,1 @@\n+JVM_GetStackTrace\n@@ -151,0 +156,1 @@\n+JVM_IsFinalizationEnabled\n@@ -153,0 +159,2 @@\n+JVM_IsPreviewEnabled\n+JVM_IsContinuationsSupported\n@@ -158,1 +166,0 @@\n-JVM_IsThreadAlive\n@@ -161,0 +168,1 @@\n+JVM_LoadZipLibrary\n@@ -177,0 +185,1 @@\n+JVM_PrintWarningAtDynamicAgentLoad\n@@ -184,0 +193,1 @@\n+JVM_RegisterContinuationMethods\n@@ -187,1 +197,1 @@\n-JVM_ResumeThread\n+JVM_ReportFinalizationComplete\n@@ -192,0 +202,1 @@\n+JVM_SetStackWalkContinuation\n@@ -195,2 +206,0 @@\n-JVM_StopThread\n-JVM_SuspendThread\n@@ -211,0 +220,14 @@\n+\n+# Virtual thread notifications for JVMTI\n+JVM_VirtualThreadStart\n+JVM_VirtualThreadEnd\n+JVM_VirtualThreadMount\n+JVM_VirtualThreadUnmount\n+JVM_VirtualThreadHideFrames\n+\n+# Scoped values\n+JVM_EnsureMaterializedForStackWalk_func\n+JVM_FindScopedValueBindings\n+JVM_ScopedValueCache\n+JVM_SetScopedValueCache\n+#\n","filename":"make\/data\/hotspot-symbols\/symbols-unix","additions":28,"deletions":5,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2013, 2021, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2013, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -61,0 +61,4 @@\n+ifeq ($(JVM_VARIANT), core)\n+  JVM_CFLAGS_FEATURES += -DVMTYPE=\\\"Core\\\"\n+endif\n+\n@@ -87,1 +91,1 @@\n-      jvmtiClassFileReconstituter.cpp jvmtiTagMapTable.cpp\n+      jvmtiClassFileReconstituter.cpp jvmtiTagMapTable.cpp jvmtiAgent.cpp jvmtiAgentList.cpp\n@@ -125,7 +129,0 @@\n-ifneq ($(call check-jvm-feature, nmt), true)\n-  JVM_CFLAGS_FEATURES += -DINCLUDE_NMT=0\n-  JVM_EXCLUDE_FILES += \\\n-      memBaseline.cpp memReporter.cpp mallocTracker.cpp virtualMemoryTracker.cpp nmtCommon.cpp \\\n-      memTracker.cpp nmtDCmd.cpp mallocSiteTable.cpp threadStackTracker.cpp\n-endif\n-\n@@ -155,0 +152,1 @@\n+  JVM_EXCLUDE_PATTERNS += gc\/x\n@@ -176,6 +174,14 @@\n-  # NOTE: Disable automatic opimization level and let the explicit cflag control\n-  # optimization level instead. This activates O3 on slowdebug builds, just\n-  # like the old build, but it's probably not right.\n-  JVM_OPTIMIZATION :=\n-  JVM_CFLAGS_FEATURES += -O3 -flto\n-  JVM_LDFLAGS_FEATURES += -O3 -flto -fuse-linker-plugin -fno-strict-aliasing\n+  # Set JVM_OPTIMIZATION directly so other jvm-feature flags can override it\n+  # later on if desired\n+  JVM_OPTIMIZATION := HIGHEST_JVM\n+  ifeq ($(call isCompiler, gcc), true)\n+    JVM_CFLAGS_FEATURES += -flto=auto -fuse-linker-plugin -fno-strict-aliasing -fno-fat-lto-objects\n+    JVM_LDFLAGS_FEATURES += $(CXX_O_FLAG_HIGHEST_JVM) -flto=auto -fuse-linker-plugin -fno-strict-aliasing\n+  else ifeq ($(call isCompiler, microsoft), true)\n+    JVM_CFLAGS_FEATURES += -GL\n+    JVM_LDFLAGS_FEATURES += -LTCG:INCREMENTAL\n+  endif\n+else\n+  ifeq ($(call isCompiler, gcc), true)\n+    JVM_LDFLAGS_FEATURES += -O1\n+  endif\n@@ -191,1 +197,0 @@\n-      biasedLocking.cpp \\\n","filename":"make\/hotspot\/lib\/JvmFeatures.gmk","additions":21,"deletions":16,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -83,1 +83,1 @@\n-      EXTRA_OBJECT_FILES := $(SUPPORT_OUTPUTDIR)\/native\/$(MODULE)\/libjava\/childproc.o, \\\n+      EXTRA_OBJECT_FILES := $(SUPPORT_OUTPUTDIR)\/native\/$(MODULE)\/libjava\/childproc$(OBJ_SUFFIX), \\\n","filename":"make\/modules\/java.base\/Launcher.gmk","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2011, 2020, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2011, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,32 +26,0 @@\n-##########################################################################################\n-# libfdlibm is statically linked with libjava below and not delivered into the\n-# product on its own.\n-\n-BUILD_LIBFDLIBM_OPTIMIZATION := NONE\n-\n-# If FDLIBM_CFLAGS is non-empty we know that we can optimize\n-# fdlibm when adding those extra C flags. Currently GCC,\n-# and clang only.\n-ifneq ($(FDLIBM_CFLAGS), )\n-  BUILD_LIBFDLIBM_OPTIMIZATION := LOW\n-endif\n-\n-LIBFDLIBM_SRC := $(TOPDIR)\/src\/java.base\/share\/native\/libfdlibm\n-LIBFDLIBM_CFLAGS := -I$(LIBFDLIBM_SRC) $(FDLIBM_CFLAGS)\n-\n-$(eval $(call SetupNativeCompilation, BUILD_LIBFDLIBM, \\\n-    NAME := fdlibm, \\\n-    TYPE := STATIC_LIBRARY, \\\n-    OUTPUT_DIR := $(SUPPORT_OUTPUTDIR)\/native\/$(MODULE), \\\n-    SRC := $(LIBFDLIBM_SRC), \\\n-    OPTIMIZATION := $(BUILD_LIBFDLIBM_OPTIMIZATION), \\\n-    CFLAGS := $(CFLAGS_JDKLIB) $(LIBFDLIBM_CFLAGS), \\\n-    CFLAGS_windows_debug := -DLOGGING, \\\n-    CFLAGS_aix := -qfloat=nomaf, \\\n-    DISABLED_WARNINGS_gcc := sign-compare misleading-indentation array-bounds, \\\n-    DISABLED_WARNINGS_clang := sign-compare misleading-indentation, \\\n-    DISABLED_WARNINGS_microsoft := 4146 4244 4018, \\\n-    ARFLAGS := $(ARFLAGS), \\\n-    OBJECT_DIR := $(SUPPORT_OUTPUTDIR)\/native\/$(MODULE)\/libfdlibm, \\\n-))\n-\n@@ -94,2 +62,1 @@\n-    EXTRA_HEADER_DIRS := libfdlibm, \\\n-    DISABLED_WARNINGS_gcc := unused-result unused-function, \\\n+    DISABLED_WARNINGS_gcc_ProcessImpl_md.c := unused-result, \\\n@@ -101,1 +68,0 @@\n-    LIBS := $(BUILD_LIBFDLIBM_TARGET), \\\n@@ -117,1 +83,0 @@\n-$(BUILD_LIBJAVA): $(BUILD_LIBFDLIBM)\n@@ -137,1 +102,3 @@\n-    DISABLED_WARNINGS_gcc := unused-function implicit-fallthrough, \\\n+    DISABLED_WARNINGS_gcc_zip_util.c := unused-function, \\\n+    DISABLED_WARNINGS_clang := deprecated-non-prototype, \\\n+    DISABLED_WARNINGS_clang_gzwrite.c := format-nonliteral, \\\n@@ -174,2 +141,4 @@\n-  # Supply the name of the C runtime lib.\n-  LIBJLI_CFLAGS += -DMSVCR_DLL_NAME='\"$(notdir $(MSVCR_DLL))\"'\n+  # Supply the name of the C runtime libs.\n+  ifneq ($(MSVCR_DLL), )\n+    LIBJLI_CFLAGS += -DMSVCR_DLL_NAME='\"$(notdir $(MSVCR_DLL))\"'\n+  endif\n@@ -209,2 +178,2 @@\n-    DISABLED_WARNINGS_gcc := unused-function implicit-fallthrough, \\\n-    DISABLED_WARNINGS_clang := sometimes-uninitialized format-nonliteral, \\\n+    DISABLED_WARNINGS_gcc := unused-function, \\\n+    DISABLED_WARNINGS_clang := format-nonliteral deprecated-non-prototype, \\\n@@ -236,0 +205,1 @@\n+      DISABLED_WARNINGS_clang_aix := format-nonliteral deprecated-non-prototype, \\\n","filename":"make\/modules\/java.base\/lib\/CoreLibraries.gmk","additions":12,"deletions":42,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2015, 2020, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2015, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -102,5 +102,0 @@\n-NSK_GC_LOCK_MALLOC_INCLUDES := \\\n-    -I$(VM_TESTBASE_DIR)\/nsk\/share\/gc\/lock\/malloc \\\n-    -I$(VM_TESTBASE_DIR)\/nsk\/share\/native \\\n-    -I$(VM_TESTBASE_DIR)\/nsk\/share\/jni\n-\n@@ -144,1 +139,1 @@\n-   NO_FRAMEPOINTER_CFLAGS := -fomit-frame-pointer\n+  NO_FRAMEPOINTER_CFLAGS := -fomit-frame-pointer\n@@ -151,2 +146,4 @@\n-BUILD_HOTSPOT_JTREG_LIBRARIES_CFLAGS := -D__STDC_FORMAT_MACROS -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS\n-BUILD_HOTSPOT_JTREG_EXECUTABLES_CFLAGS := -D__STDC_FORMAT_MACROS -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS\n+JVMTI_COMMON_INCLUDES=-I$(TOPDIR)\/test\/lib\/jdk\/test\/lib\/jvmti\n+\n+BUILD_HOTSPOT_JTREG_LIBRARIES_CFLAGS := -D__STDC_FORMAT_MACROS -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS $(JVMTI_COMMON_INCLUDES)\n+BUILD_HOTSPOT_JTREG_EXECUTABLES_CFLAGS := -D__STDC_FORMAT_MACROS -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS $(JVMTI_COMMON_INCLUDES)\n@@ -180,2 +177,0 @@\n-BUILD_HOTSPOT_JTREG_LIBRARIES_CFLAGS_libMallocLocker := $(NSK_GC_LOCK_MALLOC_INCLUDES)\n-\n@@ -349,0 +344,1 @@\n+BUILD_HOTSPOT_JTREG_LIBRARIES_CFLAGS_libsuspendvthr001 := $(NSK_JVMTI_AGENT_INCLUDES)\n@@ -854,18 +850,18 @@\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LDFLAGS_libtest-rw := -z noexecstack\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LDFLAGS_libtest-rwx := -z execstack\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libstepBreakPopReturn := -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libIndyRedefineClass := -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefineClasses := -lpthread\n-    BUILD_HOTSPOT_JTREG_EXECUTABLES_LIBS_exeinvoke := -ljvm -lpthread\n-    BUILD_HOTSPOT_JTREG_EXECUTABLES_LIBS_exestack-gap := -ljvm -lpthread\n-    BUILD_HOTSPOT_JTREG_EXECUTABLES_LIBS_exestack-tls := -ljvm\n-    BUILD_TEST_exeinvoke_exeinvoke.c_OPTIMIZATION := NONE\n-    BUILD_HOTSPOT_JTREG_EXECUTABLES_LIBS_exeFPRegs := -ldl\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libAsyncGetCallTraceTest := -ldl\n-\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_CFLAGS_libAbstractNativeLoop := -fsanitize=thread\n-    ifeq ($(TOOLCHAIN_TYPE), gcc)\n-      # Ignore unresolved symbols from TSAN's runtime.\n-      # The symbols will be available at runtime as TSAN runtime is linked with the launcher.\n-      BUILD_HOTSPOT_JTREG_LIBRARIES_LDFLAGS_libAbstractNativeLoop := -Wl,--unresolved-symbols=ignore-in-object-files\n-    endif\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LDFLAGS_libtest-rw := -z noexecstack\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LDFLAGS_libtest-rwx := -z execstack\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libstepBreakPopReturn := -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libIndyRedefineClass := -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefineClasses := -lpthread\n+  BUILD_HOTSPOT_JTREG_EXECUTABLES_LIBS_exeinvoke := -ljvm -lpthread\n+  BUILD_HOTSPOT_JTREG_EXECUTABLES_LIBS_exestack-gap := -ljvm -lpthread\n+  BUILD_HOTSPOT_JTREG_EXECUTABLES_LIBS_exestack-tls := -ljvm\n+  BUILD_TEST_exeinvoke_exeinvoke.c_OPTIMIZATION := NONE\n+  BUILD_HOTSPOT_JTREG_EXECUTABLES_LIBS_exeFPRegs := -ldl\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libAsyncGetCallTraceTest := -ldl\n+\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_CFLAGS_libAbstractNativeLoop := -fsanitize=thread\n+  ifeq ($(TOOLCHAIN_TYPE), gcc)\n+    # Ignore unresolved symbols from TSAN's runtime.\n+    # The symbols will be available at runtime as TSAN runtime is linked with the launcher.\n+    BUILD_HOTSPOT_JTREG_LIBRARIES_LDFLAGS_libAbstractNativeLoop := -Wl,--unresolved-symbols=ignore-in-object-files\n+  endif\n@@ -873,1 +869,1 @@\n-  BUILD_HOTSPOT_JTREG_EXCLUDE += libtest-rw.c libtest-rwx.c libTestJNI.c \\\n+  BUILD_HOTSPOT_JTREG_EXCLUDE += libtest-rw.c libtest-rwx.c \\\n@@ -880,3 +876,4 @@\n-    BUILD_HOTSPOT_JTREG_EXECUTABLES_CFLAGS_exeFPRegs := -MT\n-    BUILD_HOTSPOT_JTREG_EXCLUDE += exesigtest.c libterminatedThread.c\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libatExit := jvm.lib\n+  BUILD_HOTSPOT_JTREG_EXECUTABLES_CFLAGS_exeFPRegs := -MT\n+  BUILD_HOTSPOT_JTREG_EXCLUDE += exesigtest.c libterminatedThread.c libTestJNI.c libCompleteExit.c libTestPsig.c libnativeStack.c exeGetCreatedJavaVMs.c\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libatExit := jvm.lib\n+  BUILD_HOTSPOT_JTREG_EXECUTABLES_LIBS_exedaemonDestroy := jvm.lib\n@@ -884,634 +881,651 @@\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbootclssearch_agent += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsystemclssearch_agent += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetsysprop001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetsysprop002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetlocal001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetlocal002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libGetEnv001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetvern001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetfldecl002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetfldecl004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetfldecl001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libloadedclss001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libloadedclss002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libextevents001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdatadumpreq001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtimerinfo001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrstat002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrstat005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrstat004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrstat003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrstat001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libframecnt001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libframecnt002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libframecnt003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcontmon003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcontmon002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcontmon001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrtimerinfo001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetenvstor001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetenvstor002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetenvstor003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libframeloc002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libframeloc003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libframeloc001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass009 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass031 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass030 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass008 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass015 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass012 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass024 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass023 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass022 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass025 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass013 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass014 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libstressRedefine += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass011 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass029 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass016 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass020 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass018 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass027 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass019 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass026 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass021 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass028 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass017 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass010 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetjlocfmt002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetjlocfmt001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetlocal003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetlocal004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetallstktr001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetcpool001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libextmech += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libagentthr += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libheapref += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librefignore += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libIsSyntheticIssynth001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liblinetab004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgc += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmonitor += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfollowref002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfollowref005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfollowref004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfollowref003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfollowref006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfollowref001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclsldrclss00x += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libearlyretvoid += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libearlyretlong += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libearlyretint += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libearlyretbase += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libearlyretstr += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libearlyretobj += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libearlyretfp += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetavailproc001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclstat006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclstat007 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclstat005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrinfo002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrinfo001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetthrdstor002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetthrdstor003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetthrdstor001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjsize001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libaddcaps001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libaddcaps002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libaddcaps003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclmthd007 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclmthd006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclmthd005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfieldacc003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfieldacc004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfieldacc002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfieldacc001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetsrcfn006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetsrcfn005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetsrcfn004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetthrdstor001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libintrpthrd001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libintrpthrd002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libintrpthrd003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnativemethbind002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnativemethbind004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnativemethbind003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnativemethbind001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetenvstor001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetextevent001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetpotcaps001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterobjreachobj001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterobjreachobj002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterobjreachobj005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterobjreachobj004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterobjreachobj003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclrfldw002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclrfldw001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libvminit001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsuspendthrd001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsuspendthrd002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsuspendthrd003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdeclcls002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdeclcls003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdeclcls001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetjniftab002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetjniftab001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgeterrname002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgeterrname001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsettag001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libstopthrd007 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libstopthrd006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgenevents001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetfldmdf004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetfldmdf003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libresumethrdlst001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libresumethrdlst002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetbrk008 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetbrk007 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetbrk005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetbrk002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetbrk003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsuspendthrdlst001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsuspendthrdlst002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libIsMethodSyntheticIssynth001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libissynth002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libagentonunload001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetsysprop002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetsysprop003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libMethodBind += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libOnUnload += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libStackTrace += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefineCFLH += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libAddToBootstrapClassLoaderSearch += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libDispose += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libenvironment += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnosuspendMonitorInfo += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnosuspendStackTrace += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetNullVMInit += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtimers += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libHeap += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libHotSwap += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach046Agent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach041Agent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach015Agent01 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach015Agent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach015Target += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach012Agent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach040Agent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach014Agent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach022Agent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach038Agent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach009Agent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsimpleAgent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach037Agent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach008Agent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach039Agent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach020Agent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach042Agent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach045Agent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach045Agent03 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach045Agent02 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach045Agent01 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach002aAgent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach021Agent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach050Agent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach002Agent00 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgettag001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnframepop001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnframepop003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnframepop002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libvmobjalloc001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjwithtags001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnntfy004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnntfy003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnntfy002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnntfy001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmethmod001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmethmod002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmentry002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmentry001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterheap004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterheap003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterheap002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterheap005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterheap007 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterheap006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterheap001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe010 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe011 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe008 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe009 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe007 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcurthrtimerinfo001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnwait004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnwait003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnwait002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnwait005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnwait001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfldw001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfldw006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfldw003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfldw004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfldw005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfldw002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclrfmodw001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclrfmodw002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libisnative002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libisnative001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterreachobj002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterreachobj005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterreachobj004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterreachobj003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterreachobj001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liballthr001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liballthr002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjhashcode001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdyncodgen001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetnotif001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmexit001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmexit002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmethloc002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmethloc001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbreakpoint001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetcaps001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetcaps002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclsldrclss001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclsldrclss002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liblinetab001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liblinetab003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liblinetab002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmaxloc001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmaxloc002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassfloadhk002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassfloadhk005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassfloadhk004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassfloadhk003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassfloadhk008 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassfloadhk006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassfloadhk001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassfloadhk007 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassfloadhk009 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetintrf006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetintrf007 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetintrf005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libexcatch001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libresumethrd002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libresumethrd001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjfree001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjfree002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfieldmod002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfieldmod001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libextfuncs001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libSetNativeMethodPrefix002Main += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libSetNativeMethodPrefix002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libSetNativeMethodPrefix001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassprep001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetvrbflag002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetvrbflag001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmcontentered001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetevntcallb001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetevntcallb002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetevntcallb003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnntfyall002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnntfyall004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnntfyall003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnntfyall001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgcfinish001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libownmoninf002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libownmoninf003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libownmoninf001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetfldnm003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetfldnm004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetfldnm005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgf08t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgf08t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgf08t003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgf01t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgf06t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgf04t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbi02t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbi02t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbi03t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbi03t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbi04t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbi01t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbi01t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libex03t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm02t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm03t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t013 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t014 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t015 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t012 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t008 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t009 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t007 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t019 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t021 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t017 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t010 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t011 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t016 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t020 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t018 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp02t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp02t003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp02t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp05t003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp05t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp04t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp04t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp03t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp03t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp06t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp06t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp06t003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp01t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp01t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp01t003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp07t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp07t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtc04t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtc03t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtc03t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtc02t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtc05t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtc01t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma08t001a += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma08t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma01t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma01t001a += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma06t001a += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma06t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma07t001a += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma07t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma05t001a += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma05t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma02t001a += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma02t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma03t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma03t001a += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma04t003a += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma04t003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma04t002a += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma04t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma04t001a += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma04t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t003a += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t004a += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t005a += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t002a += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t007 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t007a += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t008 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t008a += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t001a += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t006a += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs103t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs104t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs104t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs301t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs301t005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs301t004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs301t003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs301t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs203t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs203t004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs203t003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs203t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs204t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs204t003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs204t004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs204t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs202t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs202t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_build += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t011 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t010 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t007 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t009 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t008 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t012 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs201t003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs201t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs201t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem06t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem01t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem01t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem07t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem07t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t008 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t009 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t007 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t012 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t010 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t011 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem05t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem05t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem04t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libji01t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libji06t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libji03t003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libji03t004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libji03t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libji03t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libji05t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap10t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap11t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap02t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap05t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap05t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap04t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap04t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap04t003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap03t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap12t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap06t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap01t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap09t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap07t001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap07t002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthreadstart001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthreadstart003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthreadstart002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmonenter002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmonenter003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmonenter004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmonenter001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdealloc001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libexceptionjni001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libisfldsin003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libisfldsin002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrgrpinfo001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrgrpinfo002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libAbort += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libCallbacks += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libNonConcreteKlassFilter += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libConcreteKlassFilter += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libHeapFilter += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmcontenter001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclrbrk001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclrbrk002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclrbrk005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtopthrgrp002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtopthrgrp001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libisarray004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libisarray005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbytecodes003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbytecodes002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbytecodes001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthreadend001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthreadend002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetthrdgrpchld001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmonitorwait001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liballoc001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsrcdebugex003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsrcdebugex002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsrcdebugex001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcrrawmon002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcrrawmon001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetjniftab001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetjniftab002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclsldr003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclsldr002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclsldr001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcurthrcputime001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmonexit001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmonexit002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmonexit005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmonexit003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libisobsolete001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libargsize001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libargsize002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclfld007 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclfld006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclfld005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetstacktr006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetstacktr001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetstacktr008 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetstacktr009 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetstacktr007 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetstacktr002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetstacktr005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetstacktr004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetstacktr003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liblocaltab001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liblocaltab004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liblocaltab003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liblocaltab002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liblocaltab005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassload001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libisintrf004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libisintrf005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libframepop001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libframepop002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclsig005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclsig004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclsig006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdisposeenv002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdisposeenv001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libexception001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libresexhausted += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgcstart001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgcstart002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterinstcls005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterinstcls002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterinstcls003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterinstcls004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterinstcls001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterinstcls006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterinstcls007 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmethname002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmethname003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmethname001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libforcegc001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libforcegc002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgettime001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjmonusage004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjmonusage003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjmonusage002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjmonusage005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjmonusage006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjmonusage001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libagentonload001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libagentonload002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libagentonload003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrcputime002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrcputime001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmonitorwaited001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libForceEarlyReturn001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libagentthr003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libagentthr002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libagentthr001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcompmethunload001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libretransform002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libretransform004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libretransform003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclmdf007 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclmdf006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclmdf004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclmdf005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetlocal001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetlocal004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetlocal003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetlocal002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcompmethload001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetsysprops001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetsysprops002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdrrawmon003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdrrawmon004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdrrawmon001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsinglestep001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsinglestep003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsinglestep002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librelcaps001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librelcaps002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfmodw004 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfmodw003 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfmodw002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfmodw005 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfmodw006 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfmodw001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libvmdeath001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetphase001 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetphase002 += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libterminatedThread += -lpthread\n-    BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libatExit += -ljvm\n+  BUILD_HOTSPOT_JTREG_EXECUTABLES_LIBS_exedaemonDestroy := -ljvm\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbootclssearch_agent += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsystemclssearch_agent += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetsysprop001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetsysprop002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetlocal001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetlocal002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libGetEnv001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetvern001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetfldecl002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetfldecl004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetfldecl001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libloadedclss001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libloadedclss002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libextevents001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdatadumpreq001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtimerinfo001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrstat002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrstat005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrstat004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrstat003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrstat001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libframecnt001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libframecnt002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libframecnt003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcontmon003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcontmon002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcontmon001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrtimerinfo001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetenvstor001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetenvstor002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetenvstor003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libframeloc002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libframeloc003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libframeloc001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass009 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass031 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass030 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass008 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass015 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass012 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass024 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass023 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass022 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass025 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass013 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass014 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libstressRedefine += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass011 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass029 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass016 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass020 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass018 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass027 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass019 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass026 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass021 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass028 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass017 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefclass010 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetjlocfmt002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetjlocfmt001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetlocal003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetlocal004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetallstktr001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetcpool001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libextmech += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libagentthr += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libheapref += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librefignore += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libIsSyntheticIssynth001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liblinetab004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgc += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmonitor += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfollowref002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfollowref005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfollowref004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfollowref003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfollowref006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfollowref001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclsldrclss00x += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libearlyretvoid += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libearlyretlong += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libearlyretint += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libearlyretbase += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libearlyretstr += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libearlyretobj += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libearlyretfp += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetavailproc001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclstat006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclstat007 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclstat005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrinfo002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrinfo001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetthrdstor002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetthrdstor003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetthrdstor001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjsize001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libaddcaps001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libaddcaps002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libaddcaps003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclmthd007 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclmthd006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclmthd005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfieldacc003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfieldacc004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfieldacc002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfieldacc001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetsrcfn006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetsrcfn005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetsrcfn004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetthrdstor001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libintrpthrd001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libintrpthrd002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libintrpthrd003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnativemethbind002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnativemethbind004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnativemethbind003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnativemethbind001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetenvstor001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetextevent001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetpotcaps001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterobjreachobj001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterobjreachobj002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterobjreachobj005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterobjreachobj004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterobjreachobj003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclrfldw002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclrfldw001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libvminit001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsuspendthrd001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsuspendthrd002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsuspendthrd003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsuspendvthr001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdeclcls002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdeclcls003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdeclcls001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetjniftab002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetjniftab001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgeterrname002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgeterrname001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsettag001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libstopthrd007 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libstopthrd006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgenevents001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetfldmdf004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetfldmdf003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libresumethrdlst001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libresumethrdlst002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetbrk008 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetbrk007 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetbrk005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetbrk002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetbrk003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsuspendthrdlst001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsuspendthrdlst002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libIsMethodSyntheticIssynth001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libissynth002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libagentonunload001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetsysprop002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetsysprop003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libMethodBind += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libOnUnload += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libStackTrace += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libredefineCFLH += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libAddToBootstrapClassLoaderSearch += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libDispose += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libenvironment += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnosuspendMonitorInfo += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnosuspendStackTrace += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetNullVMInit += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtimers += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libHeap += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libHotSwap += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach046Agent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach041Agent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach015Agent01 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach015Agent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach015Target += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach012Agent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach040Agent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach014Agent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach022Agent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach038Agent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach009Agent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsimpleAgent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach037Agent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach008Agent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach039Agent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach020Agent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach042Agent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach045Agent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach045Agent03 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach045Agent02 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach045Agent01 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach002aAgent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach021Agent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach050Agent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libattach002Agent00 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgettag001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnframepop001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnframepop003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnframepop002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libvmobjalloc001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjwithtags001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnntfy004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnntfy003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnntfy002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnntfy001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmethmod001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmethmod002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmentry002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmentry001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterheap004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterheap003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterheap002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterheap005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterheap007 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterheap006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterheap001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe010 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe011 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe008 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe009 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libpopframe007 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcurthrtimerinfo001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnwait004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnwait003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnwait002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnwait005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnwait001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfldw001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfldw006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfldw003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfldw004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfldw005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfldw002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclrfmodw001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclrfmodw002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libisnative002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libisnative001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterreachobj002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterreachobj005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterreachobj004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterreachobj003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterreachobj001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liballthr001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liballthr002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjhashcode001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdyncodgen001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetnotif001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmexit001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmexit002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmethloc002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmethloc001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbreakpoint001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetcaps001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetcaps002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclsldrclss001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclsldrclss002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liblinetab001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liblinetab003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liblinetab002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmaxloc001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmaxloc002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassfloadhk002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassfloadhk005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassfloadhk004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassfloadhk003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassfloadhk008 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassfloadhk006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassfloadhk001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassfloadhk007 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassfloadhk009 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetintrf006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetintrf007 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetintrf005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libexcatch001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libresumethrd002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libresumethrd001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjfree001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjfree002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfieldmod002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libfieldmod001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libextfuncs001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libSetNativeMethodPrefix002Main += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libSetNativeMethodPrefix002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libSetNativeMethodPrefix001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassprep001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetvrbflag002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetvrbflag001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmcontentered001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetevntcallb001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetevntcallb002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetevntcallb003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnntfyall002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnntfyall004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnntfyall003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmnntfyall001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgcfinish001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libownmoninf002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libownmoninf003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libownmoninf001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetfldnm003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetfldnm004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetfldnm005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgf08t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgf08t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgf08t003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgf01t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgf06t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgf04t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbi02t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbi02t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbi03t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbi03t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbi04t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbi01t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbi01t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libex03t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm02t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm03t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t013 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t014 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t015 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t012 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t008 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t009 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t007 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t019 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t021 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t017 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t010 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t011 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t016 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t020 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t018 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcm01t004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp02t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp02t003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp02t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp05t003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp05t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp04t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp04t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp03t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp03t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp06t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp06t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp06t003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp01t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp01t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp01t003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp07t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsp07t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtc04t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtc03t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtc03t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtc02t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtc05t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtc01t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma08t001a += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma08t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma01t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma01t001a += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma06t001a += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma06t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma07t001a += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma07t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma05t001a += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma05t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma02t001a += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma02t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma03t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma03t001a += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma04t003a += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma04t003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma04t002a += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma04t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma04t001a += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma04t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t003a += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t004a += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t005a += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t002a += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t007 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t007a += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t008 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t008a += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t001a += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libma10t006a += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs103t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs104t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs104t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs301t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs301t005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs301t004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs301t003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs301t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs203t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs203t004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs203t003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs203t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs204t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs204t003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs204t004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs204t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs202t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs202t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_build += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t011 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t010 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t007 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t009 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t008 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs302t012 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs201t003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs201t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libhs201t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem06t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem01t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem01t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem07t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem07t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t008 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t009 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t007 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t012 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t010 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem02t011 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem05t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem05t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libem04t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libji01t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libji06t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libji03t003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libji03t004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libji03t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libji03t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libji05t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap10t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap11t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap02t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap05t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap05t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap04t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap04t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap04t003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap03t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap12t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap06t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap01t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap09t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap07t001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libap07t002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthreadstart001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthreadstart003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthreadstart002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmonenter002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmonenter003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmonenter004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmonenter001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdealloc001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libexceptionjni001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libisfldsin003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libisfldsin002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrgrpinfo001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrgrpinfo002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libAbort += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libCallbacks += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libNonConcreteKlassFilter += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libConcreteKlassFilter += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libHeapFilter += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmcontenter001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclrbrk001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclrbrk002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclrbrk005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtopthrgrp002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libtopthrgrp001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libisarray004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libisarray005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbytecodes003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbytecodes002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libbytecodes001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthreadend001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthreadend002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetthrdgrpchld001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmonitorwait001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liballoc001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsrcdebugex003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsrcdebugex002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsrcdebugex001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcrrawmon002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcrrawmon001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetjniftab001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetjniftab002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclsldr003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclsldr002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclsldr001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcurthrcputime001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmonexit001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmonexit002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmonexit005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librawmonexit003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libisobsolete001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libargsize001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libargsize002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclfld007 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclfld006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclfld005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetstacktr006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetstacktr001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetstacktr008 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetstacktr009 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetstacktr007 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetstacktr002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetstacktr005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetstacktr004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetstacktr003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liblocaltab001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liblocaltab004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liblocaltab003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liblocaltab002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_liblocaltab005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libclassload001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libisintrf004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libisintrf005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libframepop001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libframepop002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclsig005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclsig004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclsig006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdisposeenv002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdisposeenv001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libexception001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libresexhausted += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgcstart001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgcstart002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterinstcls005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterinstcls002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterinstcls003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterinstcls004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterinstcls001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterinstcls006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libiterinstcls007 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmethname002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmethname003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmethname001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libforcegc001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libforcegc002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgettime001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjmonusage004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjmonusage003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjmonusage002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjmonusage005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjmonusage006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjmonusage001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libagentonload001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libagentonload002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libagentonload003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrcputime002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libthrcputime001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libmonitorwaited001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libForceEarlyReturn001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libagentthr003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libagentthr002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libagentthr001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcompmethunload001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libretransform002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libretransform004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libretransform003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclmdf007 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclmdf006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclmdf004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetclmdf005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetlocal001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetlocal004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetlocal003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetlocal002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libcompmethload001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetsysprops001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetsysprops002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdrrawmon003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdrrawmon004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libdrrawmon001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsinglestep001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsinglestep003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsinglestep002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librelcaps001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_librelcaps002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfmodw004 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfmodw003 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfmodw002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfmodw005 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfmodw006 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libsetfmodw001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libvmdeath001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetphase001 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libgetphase002 += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libterminatedThread += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libatExit += -ljvm\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libCompleteExit += -lpthread\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libnativeStack += -lpthread\n+  BUILD_HOTSPOT_JTREG_EXECUTABLES_LIBS_exeGetCreatedJavaVMs := -ljvm -lpthread\n+endif\n+\n+ifeq ($(ASAN_ENABLED), true)\n+  # Any executable which launches the JVM and uses a custom launcher needs to explicitly link in the\n+  # default ASan options.\n+  BUILD_HOTSPOT_JTREG_EXTRA_FILES += $(TOPDIR)\/make\/data\/asan\/asan_default_options.c\n+endif\n+\n+ifeq ($(LSAN_ENABLED), true)\n+  # Any executable which launches the JVM and uses a custom launcher needs to explicitly link in the\n+  # default LSan options.\n+  BUILD_HOTSPOT_JTREG_EXTRA_FILES += $(TOPDIR)\/make\/data\/lsan\/lsan_default_options.c\n@@ -1535,0 +1549,1 @@\n+      EXTRA_FILES := $(BUILD_HOTSPOT_JTREG_EXTRA_FILES), \\\n","filename":"make\/test\/JtregNativeHotspot.gmk","additions":682,"deletions":667,"binary":false,"changes":1349,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -42,1 +42,1 @@\n-#include \"runtime\/biasedLocking.hpp\"\n+#include \"runtime\/javaThread.hpp\"\n@@ -46,1 +46,0 @@\n-#include \"runtime\/thread.inline.hpp\"\n@@ -121,1 +120,1 @@\n-               verify_oop(r0, state);               break;\n+               interp_verify_oop(r0, state);        break;\n@@ -144,1 +143,1 @@\n-    cbz(rscratch1, L); \/\/ if (thread->jvmti_thread_state() == NULL) exit;\n+    cbz(rscratch1, L); \/\/ if (thread->jvmti_thread_state() == nullptr) exit;\n@@ -174,1 +173,6 @@\n-  lea(rdispatch, Address(rdispatch, offset));\n+  \/\/ Use add() here after ARDP, rather than lea().\n+  \/\/ lea() does not generate anything if its offset is zero.\n+  \/\/ However, relocs expect to find either an ADD or a load\/store\n+  \/\/ insn after an ADRP.  add() always generates an ADD insn, even\n+  \/\/ for add(Rn, Rn, 0).\n+  add(rdispatch, rdispatch, offset);\n@@ -275,3 +279,3 @@\n-  ldr(result, Address(result, ConstantPool::cache_offset_in_bytes()));\n-  ldr(result, Address(result, ConstantPoolCache::resolved_references_offset_in_bytes()));\n-  resolve_oop_handle(result, tmp);\n+  ldr(result, Address(result, ConstantPool::cache_offset()));\n+  ldr(result, Address(result, ConstantPoolCache::resolved_references_offset()));\n+  resolve_oop_handle(result, tmp, rscratch2);\n@@ -280,1 +284,1 @@\n-  load_heap_oop(result, Address(result, index, Address::uxtw(LogBytesPerHeapOop)));\n+  load_heap_oop(result, Address(result, index, Address::uxtw(LogBytesPerHeapOop)), tmp, rscratch2);\n@@ -287,1 +291,1 @@\n-  ldr(klass, Address(cpool,  ConstantPool::resolved_klasses_offset_in_bytes())); \/\/ klass = cpool->_resolved_klasses\n+  ldr(klass, Address(cpool,  ConstantPool::resolved_klasses_offset())); \/\/ klass = cpool->_resolved_klasses\n@@ -386,1 +390,1 @@\n-  verify_oop(r0, state);\n+  interp_verify_oop(r0, state);\n@@ -390,1 +394,1 @@\n-  verify_oop(r0, state);\n+  interp_verify_oop(r0, state);\n@@ -425,1 +429,1 @@\n-  mov(r13, sp);\n+  mov(r19_sender_sp, sp);\n@@ -468,1 +472,1 @@\n-    verify_oop(r0, state);\n+    interp_verify_oop(r0, state);\n@@ -514,1 +518,1 @@\n-  dispatch_base(state, Interpreter::dispatch_table(state), generate_poll);\n+  dispatch_base(state, Interpreter::dispatch_table(state), \/*verifyoop*\/true, generate_poll);\n@@ -527,1 +531,1 @@\n-\/\/ Unlock any Java monitors from syncronized blocks.\n+\/\/ Unlock any Java monitors from synchronized blocks.\n@@ -588,1 +592,1 @@\n-  ldr(r0, Address(c_rarg1, BasicObjectLock::obj_offset_in_bytes()));\n+  ldr(r0, Address(c_rarg1, BasicObjectLock::obj_offset()));\n@@ -665,1 +669,1 @@\n-    ldr(rscratch1, Address(c_rarg1, BasicObjectLock::obj_offset_in_bytes()));\n+    ldr(rscratch1, Address(c_rarg1, BasicObjectLock::obj_offset()));\n@@ -732,1 +736,1 @@\n-  if (UseHeavyMonitors) {\n+  if (LockingMode == LM_MONITOR) {\n@@ -737,1 +741,1 @@\n-    Label done;\n+    Label count, done;\n@@ -743,2 +747,2 @@\n-    const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n-    const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();\n+    const int obj_offset = in_bytes(BasicObjectLock::obj_offset());\n+    const int lock_offset = in_bytes(BasicObjectLock::lock_offset());\n@@ -760,2 +764,54 @@\n-    if (UseBiasedLocking) {\n-      biased_locking_enter(lock_reg, obj_reg, swap_reg, tmp, false, done, &slow_case);\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      ldr(tmp, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      fast_lock(obj_reg, tmp, rscratch1, rscratch2, slow_case);\n+      b(count);\n+    } else if (LockingMode == LM_LEGACY) {\n+      \/\/ Load (object->mark() | 1) into swap_reg\n+      ldr(rscratch1, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      orr(swap_reg, rscratch1, 1);\n+\n+      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+      str(swap_reg, Address(lock_reg, mark_offset));\n+\n+      assert(lock_offset == 0,\n+             \"displached header must be first word in BasicObjectLock\");\n+\n+      Label fail;\n+      cmpxchg_obj_header(swap_reg, lock_reg, obj_reg, rscratch1, count, \/*fallthrough*\/nullptr);\n+\n+      \/\/ Fast check for recursive lock.\n+      \/\/\n+      \/\/ Can apply the optimization only if this is a stack lock\n+      \/\/ allocated in this thread. For efficiency, we can focus on\n+      \/\/ recently allocated stack locks (instead of reading the stack\n+      \/\/ base and checking whether 'mark' points inside the current\n+      \/\/ thread stack):\n+      \/\/  1) (mark & 7) == 0, and\n+      \/\/  2) sp <= mark < mark + os::pagesize()\n+      \/\/\n+      \/\/ Warning: sp + os::pagesize can overflow the stack base. We must\n+      \/\/ neither apply the optimization for an inflated lock allocated\n+      \/\/ just above the thread stack (this is why condition 1 matters)\n+      \/\/ nor apply the optimization if the stack lock is inside the stack\n+      \/\/ of another thread. The latter is avoided even in case of overflow\n+      \/\/ because we have guard pages at the end of all stacks. Hence, if\n+      \/\/ we go over the stack base and hit the stack of another thread,\n+      \/\/ this should not be in a writeable area that could contain a\n+      \/\/ stack lock allocated by that thread. As a consequence, a stack\n+      \/\/ lock less than page size away from sp is guaranteed to be\n+      \/\/ owned by the current thread.\n+      \/\/\n+      \/\/ These 3 tests can be done by evaluating the following\n+      \/\/ expression: ((mark - sp) & (7 - os::vm_page_size())),\n+      \/\/ assuming both stack pointer and pagesize have their\n+      \/\/ least significant 3 bits clear.\n+      \/\/ NOTE: the mark is in swap_reg %r0 as the result of cmpxchg\n+      \/\/ NOTE2: aarch64 does not like to subtract sp from rn so take a\n+      \/\/ copy\n+      mov(rscratch1, sp);\n+      sub(swap_reg, swap_reg, rscratch1);\n+      ands(swap_reg, swap_reg, (uint64_t)(7 - (int)os::vm_page_size()));\n+\n+      \/\/ Save the test result, for recursive case, the result is zero\n+      str(swap_reg, Address(lock_reg, mark_offset));\n+      br(Assembler::EQ, count);\n@@ -763,0 +819,1 @@\n+    bind(slow_case);\n@@ -764,19 +821,5 @@\n-    \/\/ Load (object->mark() | 1) into swap_reg\n-    ldr(rscratch1, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    orr(swap_reg, rscratch1, 1);\n-\n-    \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-    str(swap_reg, Address(lock_reg, mark_offset));\n-\n-    assert(lock_offset == 0,\n-           \"displached header must be first word in BasicObjectLock\");\n-\n-    Label fail;\n-    if (PrintBiasedLockingStatistics) {\n-      Label fast;\n-      cmpxchg_obj_header(swap_reg, lock_reg, obj_reg, rscratch1, fast, &fail);\n-      bind(fast);\n-      atomic_incw(Address((address)BiasedLocking::fast_path_entry_count_addr()),\n-                  rscratch2, rscratch1, tmp);\n-      b(done);\n-      bind(fail);\n+    \/\/ Call the runtime routine for slow case\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      call_VM(noreg,\n+              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter_obj),\n+              obj_reg);\n@@ -784,43 +827,3 @@\n-      cmpxchg_obj_header(swap_reg, lock_reg, obj_reg, rscratch1, done, \/*fallthrough*\/NULL);\n-    }\n-\n-    \/\/ Fast check for recursive lock.\n-    \/\/\n-    \/\/ Can apply the optimization only if this is a stack lock\n-    \/\/ allocated in this thread. For efficiency, we can focus on\n-    \/\/ recently allocated stack locks (instead of reading the stack\n-    \/\/ base and checking whether 'mark' points inside the current\n-    \/\/ thread stack):\n-    \/\/  1) (mark & 7) == 0, and\n-    \/\/  2) sp <= mark < mark + os::pagesize()\n-    \/\/\n-    \/\/ Warning: sp + os::pagesize can overflow the stack base. We must\n-    \/\/ neither apply the optimization for an inflated lock allocated\n-    \/\/ just above the thread stack (this is why condition 1 matters)\n-    \/\/ nor apply the optimization if the stack lock is inside the stack\n-    \/\/ of another thread. The latter is avoided even in case of overflow\n-    \/\/ because we have guard pages at the end of all stacks. Hence, if\n-    \/\/ we go over the stack base and hit the stack of another thread,\n-    \/\/ this should not be in a writeable area that could contain a\n-    \/\/ stack lock allocated by that thread. As a consequence, a stack\n-    \/\/ lock less than page size away from sp is guaranteed to be\n-    \/\/ owned by the current thread.\n-    \/\/\n-    \/\/ These 3 tests can be done by evaluating the following\n-    \/\/ expression: ((mark - sp) & (7 - os::vm_page_size())),\n-    \/\/ assuming both stack pointer and pagesize have their\n-    \/\/ least significant 3 bits clear.\n-    \/\/ NOTE: the mark is in swap_reg %r0 as the result of cmpxchg\n-    \/\/ NOTE2: aarch64 does not like to subtract sp from rn so take a\n-    \/\/ copy\n-    mov(rscratch1, sp);\n-    sub(swap_reg, swap_reg, rscratch1);\n-    ands(swap_reg, swap_reg, (uint64_t)(7 - os::vm_page_size()));\n-\n-    \/\/ Save the test result, for recursive case, the result is zero\n-    str(swap_reg, Address(lock_reg, mark_offset));\n-\n-    if (PrintBiasedLockingStatistics) {\n-      br(Assembler::NE, slow_case);\n-      atomic_incw(Address((address)BiasedLocking::fast_path_entry_count_addr()),\n-                  rscratch2, rscratch1, tmp);\n+      call_VM(noreg,\n+              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n+              lock_reg);\n@@ -828,3 +831,1 @@\n-    br(Assembler::EQ, done);\n-\n-    bind(slow_case);\n+    b(done);\n@@ -832,4 +833,2 @@\n-    \/\/ Call the runtime routine for slow case\n-    call_VM(noreg,\n-            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n-            lock_reg);\n+    bind(count);\n+    increment(Address(rthread, JavaThread::held_monitor_count_offset()));\n@@ -874,1 +873,1 @@\n-  if (UseHeavyMonitors) {\n+  if (LockingMode == LM_MONITOR) {\n@@ -877,1 +876,1 @@\n-    Label done;\n+    Label count, done;\n@@ -885,3 +884,5 @@\n-    \/\/ Convert from BasicObjectLock structure to object and BasicLock\n-    \/\/ structure Store the BasicLock address into %r0\n-    lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n+    if (LockingMode != LM_LIGHTWEIGHT) {\n+      \/\/ Convert from BasicObjectLock structure to object and BasicLock\n+      \/\/ structure Store the BasicLock address into %r0\n+      lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset()));\n+    }\n@@ -890,1 +891,1 @@\n-    ldr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+    ldr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset()));\n@@ -893,1 +894,17 @@\n-    str(zr, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+    str(zr, Address(lock_reg, BasicObjectLock::obj_offset()));\n+\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      Label slow_case;\n+\n+      \/\/ Check for non-symmetric locking. This is allowed by the spec and the interpreter\n+      \/\/ must handle it.\n+      Register tmp = rscratch1;\n+      \/\/ First check for lock-stack underflow.\n+      ldrw(tmp, Address(rthread, JavaThread::lock_stack_top_offset()));\n+      cmpw(tmp, (unsigned)LockStack::start_offset());\n+      br(Assembler::LE, slow_case);\n+      \/\/ Then check if the top of the lock-stack matches the unlocked object.\n+      subw(tmp, tmp, oopSize);\n+      ldr(tmp, Address(rthread, tmp));\n+      cmpoop(tmp, obj_reg);\n+      br(Assembler::NE, slow_case);\n@@ -895,2 +912,15 @@\n-    if (UseBiasedLocking) {\n-      biased_locking_exit(obj_reg, header_reg, done);\n+      ldr(header_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      tbnz(header_reg, exact_log2(markWord::monitor_value), slow_case);\n+      fast_unlock(obj_reg, header_reg, swap_reg, rscratch1, slow_case);\n+      b(count);\n+      bind(slow_case);\n+    } else if (LockingMode == LM_LEGACY) {\n+      \/\/ Load the old header from BasicLock structure\n+      ldr(header_reg, Address(swap_reg,\n+                              BasicLock::displaced_header_offset_in_bytes()));\n+\n+      \/\/ Test for recursion\n+      cbz(header_reg, count);\n+\n+      \/\/ Atomic swap back the old header\n+      cmpxchg_obj_header(swap_reg, header_reg, obj_reg, rscratch1, count, \/*fallthrough*\/nullptr);\n@@ -898,12 +928,1 @@\n-\n-    \/\/ Load the old header from BasicLock structure\n-    ldr(header_reg, Address(swap_reg,\n-                            BasicLock::displaced_header_offset_in_bytes()));\n-\n-    \/\/ Test for recursion\n-    cbz(header_reg, done);\n-\n-    \/\/ Atomic swap back the old header\n-    cmpxchg_obj_header(swap_reg, header_reg, obj_reg, rscratch1, done, \/*fallthrough*\/NULL);\n-\n-    str(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes())); \/\/ restore obj\n+    str(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset())); \/\/ restore obj\n@@ -912,0 +931,1 @@\n+    b(done);\n@@ -913,1 +933,2 @@\n-    bind(done);\n+    bind(count);\n+    decrement(Address(rthread, JavaThread::held_monitor_count_offset()));\n@@ -915,0 +936,1 @@\n+    bind(done);\n@@ -932,1 +954,1 @@\n-  \/\/ Test MDO to avoid the call if it is NULL.\n+  \/\/ Test MDO to avoid the call if it is null.\n@@ -1323,1 +1345,1 @@\n-  \/\/ observed the item[start_row] is NULL.\n+  \/\/ observed the item[start_row] is null.\n@@ -1339,1 +1361,1 @@\n-\/\/   if (row[0].rec != NULL) {\n+\/\/   if (row[0].rec != nullptr) {\n@@ -1342,1 +1364,1 @@\n-\/\/     if (row[1].rec != NULL) {\n+\/\/     if (row[1].rec != nullptr) {\n@@ -1345,1 +1367,1 @@\n-\/\/       if (row[2].rec != NULL) { count.incr(); goto done; } \/\/ overflow\n+\/\/       if (row[2].rec != nullptr) { count.incr(); goto done; } \/\/ overflow\n@@ -1517,1 +1539,1 @@\n-void InterpreterMacroAssembler::verify_oop(Register reg, TosState state) {\n+void InterpreterMacroAssembler::_interp_verify_oop(Register reg, TosState state, const char* file, int line) {\n@@ -1519,1 +1541,1 @@\n-    MacroAssembler::verify_oop(reg);\n+    MacroAssembler::_verify_oop_checked(reg, \"broken oop\", file, line);\n@@ -1630,1 +1652,1 @@\n-         \" last_sp != NULL\");\n+         \" last_sp != nullptr\");\n@@ -1658,1 +1680,1 @@\n-         \" last_sp != NULL\");\n+         \" last_sp != nullptr\");\n@@ -1807,1 +1829,1 @@\n-      \/\/ begining of the ProfileData we intend to update to check its\n+      \/\/ beginning of the ProfileData we intend to update to check its\n@@ -1817,1 +1839,1 @@\n-      ldrh(rscratch1, Address(tmp, Method::intrinsic_id_offset_in_bytes()));\n+      ldrh(rscratch1, Address(tmp, Method::intrinsic_id_offset()));\n@@ -1880,0 +1902,11 @@\n+\n+void InterpreterMacroAssembler::load_resolved_indy_entry(Register cache, Register index) {\n+  \/\/ Get index out of bytecode pointer, get_cache_entry_pointer_at_bcp\n+  get_cache_index_at_bcp(index, 1, sizeof(u4));\n+  \/\/ Get address of invokedynamic array\n+  ldr(cache, Address(rcpool, in_bytes(ConstantPoolCache::invokedynamic_entries_offset())));\n+  \/\/ Scale the index to be the entry index * sizeof(ResolvedInvokeDynamicInfo)\n+  lsl(index, index, log2i_exact(sizeof(ResolvedIndyEntry)));\n+  add(cache, cache, Array<ResolvedIndyEntry>::base_offset_in_bytes());\n+  lea(cache, Address(cache, index));\n+}\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":160,"deletions":127,"binary":false,"changes":287,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,0 +31,1 @@\n+#include \"code\/compiledIC.hpp\"\n@@ -43,0 +44,1 @@\n+#include \"oops\/method.inline.hpp\"\n@@ -44,0 +46,3 @@\n+#include \"runtime\/continuation.hpp\"\n+#include \"runtime\/continuationEntry.inline.hpp\"\n+#include \"runtime\/globals.hpp\"\n@@ -81,2 +86,2 @@\n-    rbp_off = 0,\n-    rbp_off2,\n+    rfp_off = 0,\n+    rfp_off2,\n@@ -104,1 +109,4 @@\n-  int v0_offset_in_bytes(void)   { return 0; }\n+  int v0_offset_in_bytes();\n+\n+  \/\/ Total stack size in bytes for saving sve predicate registers.\n+  int total_sve_predicate_in_bytes();\n@@ -116,3 +124,3 @@\n-                rfp_off = r0_off + (RegisterImpl::number_of_registers - 2) * RegisterImpl::max_slots_per_register,\n-                return_off = rfp_off + RegisterImpl::max_slots_per_register,      \/\/ slot for return address\n-                reg_save_size = return_off + RegisterImpl::max_slots_per_register};\n+                rfp_off = r0_off + (Register::number_of_registers - 2) * Register::max_slots_per_register,\n+                return_off = rfp_off + Register::max_slots_per_register,      \/\/ slot for return address\n+                reg_save_size = return_off + Register::max_slots_per_register};\n@@ -128,1 +136,1 @@\n-  int slots_per_vect = FloatRegisterImpl::save_slots_per_register;\n+  int slots_per_vect = FloatRegister::save_slots_per_register;\n@@ -132,1 +140,1 @@\n-    slots_per_vect = FloatRegisterImpl::slots_per_neon_register;\n+    slots_per_vect = FloatRegister::slots_per_neon_register;\n@@ -142,1 +150,1 @@\n-  int r0_offset = (slots_per_vect * FloatRegisterImpl::number_of_registers) * BytesPerInt;\n+  int r0_offset = v0_offset_in_bytes() + (slots_per_vect * FloatRegister::number_of_registers) * BytesPerInt;\n@@ -146,0 +154,17 @@\n+int RegisterSaver::v0_offset_in_bytes() {\n+  \/\/ The floating point registers are located above the predicate registers if\n+  \/\/ they are present in the stack frame pushed by save_live_registers(). So the\n+  \/\/ offset depends on the saved total predicate vectors in the stack frame.\n+  return (total_sve_predicate_in_bytes() \/ VMRegImpl::stack_slot_size) * BytesPerInt;\n+}\n+\n+int RegisterSaver::total_sve_predicate_in_bytes() {\n+#ifdef COMPILER2\n+  if (_save_vectors && Matcher::supports_scalable_vector()) {\n+    return (Matcher::scalable_vector_reg_size(T_BYTE) >> LogBitsPerByte) *\n+           PRegister::number_of_registers;\n+  }\n+#endif\n+  return 0;\n+}\n+\n@@ -150,0 +175,3 @@\n+  int sve_predicate_size_in_slots = 0;\n+  int total_predicate_in_bytes = total_sve_predicate_in_bytes();\n+  int total_predicate_in_slots = total_predicate_in_bytes \/ VMRegImpl::stack_slot_size;\n@@ -153,2 +181,5 @@\n-  sve_vector_size_in_bytes = Matcher::scalable_vector_reg_size(T_BYTE);\n-  sve_vector_size_in_slots = Matcher::scalable_vector_reg_size(T_FLOAT);\n+  if (use_sve) {\n+    sve_vector_size_in_bytes = Matcher::scalable_vector_reg_size(T_BYTE);\n+    sve_vector_size_in_slots = Matcher::scalable_vector_reg_size(T_FLOAT);\n+    sve_predicate_size_in_slots = Matcher::scalable_predicate_reg_slots();\n+  }\n@@ -159,1 +190,0 @@\n-    int vect_words = 0;\n@@ -163,1 +193,1 @@\n-      extra_save_slots_per_register = sve_vector_size_in_slots - FloatRegisterImpl::save_slots_per_register;\n+      extra_save_slots_per_register = sve_vector_size_in_slots - FloatRegister::save_slots_per_register;\n@@ -165,1 +195,1 @@\n-      extra_save_slots_per_register = FloatRegisterImpl::extra_save_slots_per_neon_register;\n+      extra_save_slots_per_register = FloatRegister::extra_save_slots_per_neon_register;\n@@ -167,3 +197,4 @@\n-    vect_words = FloatRegisterImpl::number_of_registers * extra_save_slots_per_register \/\n-                 VMRegImpl::slots_per_word;\n-    additional_frame_words += vect_words;\n+    int extra_vector_bytes = extra_save_slots_per_register *\n+                             VMRegImpl::stack_slot_size *\n+                             FloatRegister::number_of_registers;\n+    additional_frame_words += ((extra_vector_bytes + total_predicate_in_bytes) \/ wordSize);\n@@ -187,1 +218,1 @@\n-  __ push_CPU_state(_save_vectors, use_sve, sve_vector_size_in_bytes);\n+  __ push_CPU_state(_save_vectors, use_sve, sve_vector_size_in_bytes, total_predicate_in_bytes);\n@@ -197,1 +228,1 @@\n-  for (int i = 0; i < RegisterImpl::number_of_registers; i++) {\n+  for (int i = 0; i < Register::number_of_registers; i++) {\n@@ -199,1 +230,1 @@\n-    if (r <= rfp && r != rscratch1 && r != rscratch2) {\n+    if (i <= rfp->encoding() && r != rscratch1 && r != rscratch2) {\n@@ -202,4 +233,3 @@\n-      int sp_offset = RegisterImpl::max_slots_per_register * i +\n-                      FloatRegisterImpl::save_slots_per_register * FloatRegisterImpl::number_of_registers;\n-      oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset + additional_frame_slots),\n-                                r->as_VMReg());\n+      int sp_offset = Register::max_slots_per_register * i +\n+                      FloatRegister::save_slots_per_register * FloatRegister::number_of_registers;\n+      oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset + additional_frame_slots), r->as_VMReg());\n@@ -209,1 +239,1 @@\n-  for (int i = 0; i < FloatRegisterImpl::number_of_registers; i++) {\n+  for (int i = 0; i < FloatRegister::number_of_registers; i++) {\n@@ -213,2 +243,2 @@\n-      sp_offset = use_sve ? (sve_vector_size_in_slots * i) :\n-                            (FloatRegisterImpl::slots_per_neon_register * i);\n+      sp_offset = use_sve ? (total_predicate_in_slots + sve_vector_size_in_slots * i) :\n+                            (FloatRegister::slots_per_neon_register * i);\n@@ -216,1 +246,1 @@\n-      sp_offset = FloatRegisterImpl::save_slots_per_register * i;\n+      sp_offset = FloatRegister::save_slots_per_register * i;\n@@ -218,2 +248,1 @@\n-    oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset),\n-                              r->as_VMReg());\n+    oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset), r->as_VMReg());\n@@ -228,1 +257,1 @@\n-                   Matcher::scalable_vector_reg_size(T_BYTE));\n+                   Matcher::scalable_vector_reg_size(T_BYTE), total_sve_predicate_in_bytes());\n@@ -235,2 +264,2 @@\n-  __ leave();\n-\n+  __ ldp(rfp, lr, Address(__ post(sp, 2 * wordSize)));\n+  __ authenticate_return_address();\n@@ -241,0 +270,2 @@\n+\/\/ The SVE supported min vector size is 8 bytes and we need to save\n+\/\/ predicate registers when the vector size is 8 bytes as well.\n@@ -242,15 +273,1 @@\n-  return size > 8;\n-}\n-\n-\/\/ The java_calling_convention describes stack locations as ideal slots on\n-\/\/ a frame with no abi restrictions. Since we must observe abi restrictions\n-\/\/ (like the placement of the register window) the slots must be biased by\n-\/\/ the following value.\n-static int reg2offset_in(VMReg r) {\n-  \/\/ Account for saved rfp and lr\n-  \/\/ This should really be in_preserve_stack_slots\n-  return (r->reg2stack() + 4) * VMRegImpl::stack_slot_size;\n-}\n-\n-static int reg2offset_out(VMReg r) {\n-  return (r->reg2stack() + SharedRuntime::out_preserve_stack_slots()) * VMRegImpl::stack_slot_size;\n+  return size > 8 || (UseSVE > 0 && size >= 8);\n@@ -266,2 +283,2 @@\n-\/\/ and VMRegImpl::stack0+1 refers to the memory word 4-byes higher.  Register\n-\/\/ up to RegisterImpl::number_of_registers) are the 64-bit\n+\/\/ and VMRegImpl::stack0+1 refers to the memory word 4-byes higher.\n+\/\/ Register up to Register::number_of_registers are the 64-bit\n@@ -376,0 +393,1 @@\n+  __ authenticate_return_address(c_rarg1, rscratch1);\n@@ -411,1 +429,1 @@\n-  __ mov(r13, sp);\n+  __ mov(r19_sender_sp, sp);\n@@ -528,6 +546,4 @@\n-  \/\/ Note: r13 contains the senderSP on entry. We must preserve it since\n-  \/\/ we may do a i2c -> c2i transition if we lose a race where compiled\n-  \/\/ code goes non-entrant while we get args ready.\n-\n-  \/\/ In addition we use r13 to locate all the interpreter args because\n-  \/\/ we must align the stack to 16 bytes.\n+  \/\/ Note: r19_sender_sp contains the senderSP on entry. We must\n+  \/\/ preserve it since we may do a i2c -> c2i transition if we lose a\n+  \/\/ race where compiled code goes non-entrant while we get args\n+  \/\/ ready.\n@@ -557,1 +573,1 @@\n-      (Interpreter::code() != NULL || StubRoutines::code1() != NULL)) {\n+      (Interpreter::code() != nullptr || StubRoutines::final_stubs_code() != nullptr)) {\n@@ -565,1 +581,1 @@\n-    if (Interpreter::code() != NULL)\n+    if (Interpreter::code() != nullptr) {\n@@ -569,1 +585,2 @@\n-    if (StubRoutines::code1() != NULL)\n+    }\n+    if (StubRoutines::initial_stubs_code() != nullptr) {\n@@ -571,1 +588,2 @@\n-                  StubRoutines::code1()->code_begin(), StubRoutines::code1()->code_end(),\n+                  StubRoutines::initial_stubs_code()->code_begin(),\n+                  StubRoutines::initial_stubs_code()->code_end(),\n@@ -573,1 +591,2 @@\n-    if (StubRoutines::code2() != NULL)\n+    }\n+    if (StubRoutines::final_stubs_code() != nullptr) {\n@@ -575,1 +594,2 @@\n-                  StubRoutines::code2()->code_begin(), StubRoutines::code2()->code_end(),\n+                  StubRoutines::final_stubs_code()->code_begin(),\n+                  StubRoutines::final_stubs_code()->code_end(),\n@@ -577,0 +597,1 @@\n+    }\n@@ -685,0 +706,4 @@\n+  __ mov(rscratch2, rscratch1);\n+  __ push_cont_fastpath(rthread); \/\/ Set JavaThread::_cont_fastpath to the sp of the oldest interpreted frame we know about; kills rscratch1\n+  __ mov(rscratch1, rscratch2);\n+\n@@ -727,1 +752,1 @@\n-  \/\/ compiled code, which relys solely on SP and not FP, get sick).\n+  \/\/ compiled code, which relies solely on SP and not FP, get sick).\n@@ -751,1 +776,1 @@\n-  address c2i_no_clinit_check_entry = NULL;\n+  address c2i_no_clinit_check_entry = nullptr;\n@@ -774,1 +799,0 @@\n-  __ flush();\n@@ -782,1 +806,1 @@\n-  assert(regs2 == NULL, \"not needed on AArch64\");\n+  assert(regs2 == nullptr, \"not needed on AArch64\");\n@@ -884,166 +908,0 @@\n-\/\/ On 64 bit we will store integer like items to the stack as\n-\/\/ 64 bits items (Aarch64 abi) even though java would only store\n-\/\/ 32bits for a parameter. On 32bit it will simply be 32 bits\n-\/\/ So this routine will do 32->32 on 32bit and 32->64 on 64bit\n-static void move32_64(MacroAssembler* masm, VMRegPair src, VMRegPair dst) {\n-  if (src.first()->is_stack()) {\n-    if (dst.first()->is_stack()) {\n-      \/\/ stack to stack\n-      __ ldr(rscratch1, Address(rfp, reg2offset_in(src.first())));\n-      __ str(rscratch1, Address(sp, reg2offset_out(dst.first())));\n-    } else {\n-      \/\/ stack to reg\n-      __ ldrsw(dst.first()->as_Register(), Address(rfp, reg2offset_in(src.first())));\n-    }\n-  } else if (dst.first()->is_stack()) {\n-    \/\/ reg to stack\n-    \/\/ Do we really have to sign extend???\n-    \/\/ __ movslq(src.first()->as_Register(), src.first()->as_Register());\n-    __ str(src.first()->as_Register(), Address(sp, reg2offset_out(dst.first())));\n-  } else {\n-    if (dst.first() != src.first()) {\n-      __ sxtw(dst.first()->as_Register(), src.first()->as_Register());\n-    }\n-  }\n-}\n-\n-\/\/ An oop arg. Must pass a handle not the oop itself\n-static void object_move(MacroAssembler* masm,\n-                        OopMap* map,\n-                        int oop_handle_offset,\n-                        int framesize_in_slots,\n-                        VMRegPair src,\n-                        VMRegPair dst,\n-                        bool is_receiver,\n-                        int* receiver_offset) {\n-\n-  \/\/ must pass a handle. First figure out the location we use as a handle\n-\n-  Register rHandle = dst.first()->is_stack() ? rscratch2 : dst.first()->as_Register();\n-\n-  \/\/ See if oop is NULL if it is we need no handle\n-\n-  if (src.first()->is_stack()) {\n-\n-    \/\/ Oop is already on the stack as an argument\n-    int offset_in_older_frame = src.first()->reg2stack() + SharedRuntime::out_preserve_stack_slots();\n-    map->set_oop(VMRegImpl::stack2reg(offset_in_older_frame + framesize_in_slots));\n-    if (is_receiver) {\n-      *receiver_offset = (offset_in_older_frame + framesize_in_slots) * VMRegImpl::stack_slot_size;\n-    }\n-\n-    __ ldr(rscratch1, Address(rfp, reg2offset_in(src.first())));\n-    __ lea(rHandle, Address(rfp, reg2offset_in(src.first())));\n-    \/\/ conditionally move a NULL\n-    __ cmp(rscratch1, zr);\n-    __ csel(rHandle, zr, rHandle, Assembler::EQ);\n-  } else {\n-\n-    \/\/ Oop is in an a register we must store it to the space we reserve\n-    \/\/ on the stack for oop_handles and pass a handle if oop is non-NULL\n-\n-    const Register rOop = src.first()->as_Register();\n-    int oop_slot;\n-    if (rOop == j_rarg0)\n-      oop_slot = 0;\n-    else if (rOop == j_rarg1)\n-      oop_slot = 1;\n-    else if (rOop == j_rarg2)\n-      oop_slot = 2;\n-    else if (rOop == j_rarg3)\n-      oop_slot = 3;\n-    else if (rOop == j_rarg4)\n-      oop_slot = 4;\n-    else if (rOop == j_rarg5)\n-      oop_slot = 5;\n-    else if (rOop == j_rarg6)\n-      oop_slot = 6;\n-    else {\n-      assert(rOop == j_rarg7, \"wrong register\");\n-      oop_slot = 7;\n-    }\n-\n-    oop_slot = oop_slot * VMRegImpl::slots_per_word + oop_handle_offset;\n-    int offset = oop_slot*VMRegImpl::stack_slot_size;\n-\n-    map->set_oop(VMRegImpl::stack2reg(oop_slot));\n-    \/\/ Store oop in handle area, may be NULL\n-    __ str(rOop, Address(sp, offset));\n-    if (is_receiver) {\n-      *receiver_offset = offset;\n-    }\n-\n-    __ cmp(rOop, zr);\n-    __ lea(rHandle, Address(sp, offset));\n-    \/\/ conditionally move a NULL\n-    __ csel(rHandle, zr, rHandle, Assembler::EQ);\n-  }\n-\n-  \/\/ If arg is on the stack then place it otherwise it is already in correct reg.\n-  if (dst.first()->is_stack()) {\n-    __ str(rHandle, Address(sp, reg2offset_out(dst.first())));\n-  }\n-}\n-\n-\/\/ A float arg may have to do float reg int reg conversion\n-static void float_move(MacroAssembler* masm, VMRegPair src, VMRegPair dst) {\n-  assert(src.first()->is_stack() && dst.first()->is_stack() ||\n-         src.first()->is_reg() && dst.first()->is_reg(), \"Unexpected error\");\n-  if (src.first()->is_stack()) {\n-    if (dst.first()->is_stack()) {\n-      __ ldrw(rscratch1, Address(rfp, reg2offset_in(src.first())));\n-      __ strw(rscratch1, Address(sp, reg2offset_out(dst.first())));\n-    } else {\n-      ShouldNotReachHere();\n-    }\n-  } else if (src.first() != dst.first()) {\n-    if (src.is_single_phys_reg() && dst.is_single_phys_reg())\n-      __ fmovs(dst.first()->as_FloatRegister(), src.first()->as_FloatRegister());\n-    else\n-      ShouldNotReachHere();\n-  }\n-}\n-\n-\/\/ A long move\n-static void long_move(MacroAssembler* masm, VMRegPair src, VMRegPair dst) {\n-  if (src.first()->is_stack()) {\n-    if (dst.first()->is_stack()) {\n-      \/\/ stack to stack\n-      __ ldr(rscratch1, Address(rfp, reg2offset_in(src.first())));\n-      __ str(rscratch1, Address(sp, reg2offset_out(dst.first())));\n-    } else {\n-      \/\/ stack to reg\n-      __ ldr(dst.first()->as_Register(), Address(rfp, reg2offset_in(src.first())));\n-    }\n-  } else if (dst.first()->is_stack()) {\n-    \/\/ reg to stack\n-    \/\/ Do we really have to sign extend???\n-    \/\/ __ movslq(src.first()->as_Register(), src.first()->as_Register());\n-    __ str(src.first()->as_Register(), Address(sp, reg2offset_out(dst.first())));\n-  } else {\n-    if (dst.first() != src.first()) {\n-      __ mov(dst.first()->as_Register(), src.first()->as_Register());\n-    }\n-  }\n-}\n-\n-\n-\/\/ A double move\n-static void double_move(MacroAssembler* masm, VMRegPair src, VMRegPair dst) {\n-  assert(src.first()->is_stack() && dst.first()->is_stack() ||\n-         src.first()->is_reg() && dst.first()->is_reg(), \"Unexpected error\");\n-  if (src.first()->is_stack()) {\n-    if (dst.first()->is_stack()) {\n-      __ ldr(rscratch1, Address(rfp, reg2offset_in(src.first())));\n-      __ str(rscratch1, Address(sp, reg2offset_out(dst.first())));\n-    } else {\n-      ShouldNotReachHere();\n-    }\n-  } else if (src.first() != dst.first()) {\n-    if (src.is_single_phys_reg() && dst.is_single_phys_reg())\n-      __ fmovd(dst.first()->as_FloatRegister(), src.first()->as_FloatRegister());\n-    else\n-      ShouldNotReachHere();\n-  }\n-}\n-\n@@ -1115,73 +973,0 @@\n-\/\/ Unpack an array argument into a pointer to the body and the length\n-\/\/ if the array is non-null, otherwise pass 0 for both.\n-static void unpack_array_argument(MacroAssembler* masm, VMRegPair reg, BasicType in_elem_type, VMRegPair body_arg, VMRegPair length_arg) { Unimplemented(); }\n-\n-\n-class ComputeMoveOrder: public StackObj {\n-  class MoveOperation: public ResourceObj {\n-    friend class ComputeMoveOrder;\n-   private:\n-    VMRegPair        _src;\n-    VMRegPair        _dst;\n-    int              _src_index;\n-    int              _dst_index;\n-    bool             _processed;\n-    MoveOperation*  _next;\n-    MoveOperation*  _prev;\n-\n-    static int get_id(VMRegPair r) { Unimplemented(); return 0; }\n-\n-   public:\n-    MoveOperation(int src_index, VMRegPair src, int dst_index, VMRegPair dst):\n-      _src(src)\n-    , _dst(dst)\n-    , _src_index(src_index)\n-    , _dst_index(dst_index)\n-    , _processed(false)\n-    , _next(NULL)\n-    , _prev(NULL) { Unimplemented(); }\n-\n-    VMRegPair src() const              { Unimplemented(); return _src; }\n-    int src_id() const                 { Unimplemented(); return 0; }\n-    int src_index() const              { Unimplemented(); return 0; }\n-    VMRegPair dst() const              { Unimplemented(); return _src; }\n-    void set_dst(int i, VMRegPair dst) { Unimplemented(); }\n-    int dst_index() const              { Unimplemented(); return 0; }\n-    int dst_id() const                 { Unimplemented(); return 0; }\n-    MoveOperation* next() const        { Unimplemented(); return 0; }\n-    MoveOperation* prev() const        { Unimplemented(); return 0; }\n-    void set_processed()               { Unimplemented(); }\n-    bool is_processed() const          { Unimplemented(); return 0; }\n-\n-    \/\/ insert\n-    void break_cycle(VMRegPair temp_register) { Unimplemented(); }\n-\n-    void link(GrowableArray<MoveOperation*>& killer) { Unimplemented(); }\n-  };\n-\n- private:\n-  GrowableArray<MoveOperation*> edges;\n-\n- public:\n-  ComputeMoveOrder(int total_in_args, VMRegPair* in_regs, int total_c_args, VMRegPair* out_regs,\n-                    BasicType* in_sig_bt, GrowableArray<int>& arg_order, VMRegPair tmp_vmreg) { Unimplemented(); }\n-\n-  \/\/ Collected all the move operations\n-  void add_edge(int src_index, VMRegPair src, int dst_index, VMRegPair dst) { Unimplemented(); }\n-\n-  \/\/ Walk the edges breaking cycles between moves.  The result list\n-  \/\/ can be walked in order to produce the proper set of loads\n-  GrowableArray<MoveOperation*>* get_store_order(VMRegPair temp_register) { Unimplemented(); return 0; }\n-};\n-\n-\n-static void rt_call(MacroAssembler* masm, address dest) {\n-  CodeBlob *cb = CodeCache::find_blob(dest);\n-  if (cb) {\n-    __ far_call(RuntimeAddress(dest));\n-  } else {\n-    __ lea(rscratch1, RuntimeAddress(dest));\n-    __ blr(rscratch1);\n-  }\n-}\n-\n@@ -1210,0 +995,258 @@\n+\/\/ on exit, sp points to the ContinuationEntry\n+static OopMap* continuation_enter_setup(MacroAssembler* masm, int& stack_slots) {\n+  assert(ContinuationEntry::size() % VMRegImpl::stack_slot_size == 0, \"\");\n+  assert(in_bytes(ContinuationEntry::cont_offset())  % VMRegImpl::stack_slot_size == 0, \"\");\n+  assert(in_bytes(ContinuationEntry::chunk_offset()) % VMRegImpl::stack_slot_size == 0, \"\");\n+\n+  stack_slots += (int)ContinuationEntry::size()\/wordSize;\n+  __ sub(sp, sp, (int)ContinuationEntry::size()); \/\/ place Continuation metadata\n+\n+  OopMap* map = new OopMap(((int)ContinuationEntry::size() + wordSize)\/ VMRegImpl::stack_slot_size, 0 \/* arg_slots*\/);\n+\n+  __ ldr(rscratch1, Address(rthread, JavaThread::cont_entry_offset()));\n+  __ str(rscratch1, Address(sp, ContinuationEntry::parent_offset()));\n+  __ mov(rscratch1, sp); \/\/ we can't use sp as the source in str\n+  __ str(rscratch1, Address(rthread, JavaThread::cont_entry_offset()));\n+\n+  return map;\n+}\n+\n+\/\/ on entry c_rarg1 points to the continuation\n+\/\/          sp points to ContinuationEntry\n+\/\/          c_rarg3 -- isVirtualThread\n+static void fill_continuation_entry(MacroAssembler* masm) {\n+#ifdef ASSERT\n+  __ movw(rscratch1, ContinuationEntry::cookie_value());\n+  __ strw(rscratch1, Address(sp, ContinuationEntry::cookie_offset()));\n+#endif\n+\n+  __ str (c_rarg1, Address(sp, ContinuationEntry::cont_offset()));\n+  __ strw(c_rarg3, Address(sp, ContinuationEntry::flags_offset()));\n+  __ str (zr,      Address(sp, ContinuationEntry::chunk_offset()));\n+  __ strw(zr,      Address(sp, ContinuationEntry::argsize_offset()));\n+  __ strw(zr,      Address(sp, ContinuationEntry::pin_count_offset()));\n+\n+  __ ldr(rscratch1, Address(rthread, JavaThread::cont_fastpath_offset()));\n+  __ str(rscratch1, Address(sp, ContinuationEntry::parent_cont_fastpath_offset()));\n+  __ ldr(rscratch1, Address(rthread, JavaThread::held_monitor_count_offset()));\n+  __ str(rscratch1, Address(sp, ContinuationEntry::parent_held_monitor_count_offset()));\n+\n+  __ str(zr, Address(rthread, JavaThread::cont_fastpath_offset()));\n+  __ str(zr, Address(rthread, JavaThread::held_monitor_count_offset()));\n+}\n+\n+\/\/ on entry, sp points to the ContinuationEntry\n+\/\/ on exit, rfp points to the spilled rfp in the entry frame\n+static void continuation_enter_cleanup(MacroAssembler* masm) {\n+#ifndef PRODUCT\n+  Label OK;\n+  __ ldr(rscratch1, Address(rthread, JavaThread::cont_entry_offset()));\n+  __ cmp(sp, rscratch1);\n+  __ br(Assembler::EQ, OK);\n+  __ stop(\"incorrect sp1\");\n+  __ bind(OK);\n+#endif\n+\n+  __ ldr(rscratch1, Address(sp, ContinuationEntry::parent_cont_fastpath_offset()));\n+  __ str(rscratch1, Address(rthread, JavaThread::cont_fastpath_offset()));\n+  __ ldr(rscratch1, Address(sp, ContinuationEntry::parent_held_monitor_count_offset()));\n+  __ str(rscratch1, Address(rthread, JavaThread::held_monitor_count_offset()));\n+\n+  __ ldr(rscratch2, Address(sp, ContinuationEntry::parent_offset()));\n+  __ str(rscratch2, Address(rthread, JavaThread::cont_entry_offset()));\n+  __ add(rfp, sp, (int)ContinuationEntry::size());\n+}\n+\n+\/\/ enterSpecial(Continuation c, boolean isContinue, boolean isVirtualThread)\n+\/\/ On entry: c_rarg1 -- the continuation object\n+\/\/           c_rarg2 -- isContinue\n+\/\/           c_rarg3 -- isVirtualThread\n+static void gen_continuation_enter(MacroAssembler* masm,\n+                                 const methodHandle& method,\n+                                 const BasicType* sig_bt,\n+                                 const VMRegPair* regs,\n+                                 int& exception_offset,\n+                                 OopMapSet*oop_maps,\n+                                 int& frame_complete,\n+                                 int& stack_slots,\n+                                 int& interpreted_entry_offset,\n+                                 int& compiled_entry_offset) {\n+  \/\/verify_oop_args(masm, method, sig_bt, regs);\n+  Address resolve(SharedRuntime::get_resolve_static_call_stub(), relocInfo::static_call_type);\n+\n+  address start = __ pc();\n+\n+  Label call_thaw, exit;\n+\n+  \/\/ i2i entry used at interp_only_mode only\n+  interpreted_entry_offset = __ pc() - start;\n+  {\n+\n+#ifdef ASSERT\n+    Label is_interp_only;\n+    __ ldrw(rscratch1, Address(rthread, JavaThread::interp_only_mode_offset()));\n+    __ cbnzw(rscratch1, is_interp_only);\n+    __ stop(\"enterSpecial interpreter entry called when not in interp_only_mode\");\n+    __ bind(is_interp_only);\n+#endif\n+\n+    \/\/ Read interpreter arguments into registers (this is an ad-hoc i2c adapter)\n+    __ ldr(c_rarg1, Address(esp, Interpreter::stackElementSize*2));\n+    __ ldr(c_rarg2, Address(esp, Interpreter::stackElementSize*1));\n+    __ ldr(c_rarg3, Address(esp, Interpreter::stackElementSize*0));\n+    __ push_cont_fastpath(rthread);\n+\n+    __ enter();\n+    stack_slots = 2; \/\/ will be adjusted in setup\n+    OopMap* map = continuation_enter_setup(masm, stack_slots);\n+    \/\/ The frame is complete here, but we only record it for the compiled entry, so the frame would appear unsafe,\n+    \/\/ but that's okay because at the very worst we'll miss an async sample, but we're in interp_only_mode anyway.\n+\n+    fill_continuation_entry(masm);\n+\n+    __ cbnz(c_rarg2, call_thaw);\n+\n+    const address tr_call = __ trampoline_call(resolve);\n+    if (tr_call == nullptr) {\n+      fatal(\"CodeCache is full at gen_continuation_enter\");\n+    }\n+\n+    oop_maps->add_gc_map(__ pc() - start, map);\n+    __ post_call_nop();\n+\n+    __ b(exit);\n+\n+    CodeBuffer* cbuf = masm->code_section()->outer();\n+    address stub = CompiledStaticCall::emit_to_interp_stub(*cbuf, tr_call);\n+    if (stub == nullptr) {\n+      fatal(\"CodeCache is full at gen_continuation_enter\");\n+    }\n+  }\n+\n+  \/\/ compiled entry\n+  __ align(CodeEntryAlignment);\n+  compiled_entry_offset = __ pc() - start;\n+\n+  __ enter();\n+  stack_slots = 2; \/\/ will be adjusted in setup\n+  OopMap* map = continuation_enter_setup(masm, stack_slots);\n+  frame_complete = __ pc() - start;\n+\n+  fill_continuation_entry(masm);\n+\n+  __ cbnz(c_rarg2, call_thaw);\n+\n+  const address tr_call = __ trampoline_call(resolve);\n+  if (tr_call == nullptr) {\n+    fatal(\"CodeCache is full at gen_continuation_enter\");\n+  }\n+\n+  oop_maps->add_gc_map(__ pc() - start, map);\n+  __ post_call_nop();\n+\n+  __ b(exit);\n+\n+  __ bind(call_thaw);\n+\n+  __ rt_call(CAST_FROM_FN_PTR(address, StubRoutines::cont_thaw()));\n+  oop_maps->add_gc_map(__ pc() - start, map->deep_copy());\n+  ContinuationEntry::_return_pc_offset = __ pc() - start;\n+  __ post_call_nop();\n+\n+  __ bind(exit);\n+  continuation_enter_cleanup(masm);\n+  __ leave();\n+  __ ret(lr);\n+\n+  \/\/\/ exception handling\n+\n+  exception_offset = __ pc() - start;\n+  {\n+      __ mov(r19, r0); \/\/ save return value contaning the exception oop in callee-saved R19\n+\n+      continuation_enter_cleanup(masm);\n+\n+      __ ldr(c_rarg1, Address(rfp, wordSize)); \/\/ return address\n+      __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::exception_handler_for_return_address), rthread, c_rarg1);\n+\n+      \/\/ see OptoRuntime::generate_exception_blob: r0 -- exception oop, r3 -- exception pc\n+\n+      __ mov(r1, r0); \/\/ the exception handler\n+      __ mov(r0, r19); \/\/ restore return value contaning the exception oop\n+      __ verify_oop(r0);\n+\n+      __ leave();\n+      __ mov(r3, lr);\n+      __ br(r1); \/\/ the exception handler\n+  }\n+\n+  CodeBuffer* cbuf = masm->code_section()->outer();\n+  address stub = CompiledStaticCall::emit_to_interp_stub(*cbuf, tr_call);\n+  if (stub == nullptr) {\n+    fatal(\"CodeCache is full at gen_continuation_enter\");\n+  }\n+}\n+\n+static void gen_continuation_yield(MacroAssembler* masm,\n+                                   const methodHandle& method,\n+                                   const BasicType* sig_bt,\n+                                   const VMRegPair* regs,\n+                                   OopMapSet* oop_maps,\n+                                   int& frame_complete,\n+                                   int& stack_slots,\n+                                   int& compiled_entry_offset) {\n+    enum layout {\n+      rfp_off1,\n+      rfp_off2,\n+      lr_off,\n+      lr_off2,\n+      framesize \/\/ inclusive of return address\n+    };\n+    \/\/ assert(is_even(framesize\/2), \"sp not 16-byte aligned\");\n+    stack_slots = framesize \/  VMRegImpl::slots_per_word;\n+    assert(stack_slots == 2, \"recheck layout\");\n+\n+    address start = __ pc();\n+\n+    compiled_entry_offset = __ pc() - start;\n+    __ enter();\n+\n+    __ mov(c_rarg1, sp);\n+\n+    frame_complete = __ pc() - start;\n+    address the_pc = __ pc();\n+\n+    __ post_call_nop(); \/\/ this must be exactly after the pc value that is pushed into the frame info, we use this nop for fast CodeBlob lookup\n+\n+    __ mov(c_rarg0, rthread);\n+    __ set_last_Java_frame(sp, rfp, the_pc, rscratch1);\n+    __ call_VM_leaf(Continuation::freeze_entry(), 2);\n+    __ reset_last_Java_frame(true);\n+\n+    Label pinned;\n+\n+    __ cbnz(r0, pinned);\n+\n+    \/\/ We've succeeded, set sp to the ContinuationEntry\n+    __ ldr(rscratch1, Address(rthread, JavaThread::cont_entry_offset()));\n+    __ mov(sp, rscratch1);\n+    continuation_enter_cleanup(masm);\n+\n+    __ bind(pinned); \/\/ pinned -- return to caller\n+\n+    \/\/ handle pending exception thrown by freeze\n+    __ ldr(rscratch1, Address(rthread, in_bytes(Thread::pending_exception_offset())));\n+    Label ok;\n+    __ cbz(rscratch1, ok);\n+    __ leave();\n+    __ lea(rscratch1, RuntimeAddress(StubRoutines::forward_exception_entry()));\n+    __ br(rscratch1);\n+    __ bind(ok);\n+\n+    __ leave();\n+    __ ret(lr);\n+\n+    OopMap* map = new OopMap(framesize, 1);\n+    oop_maps->add_gc_map(the_pc - start, map);\n+}\n+\n@@ -1227,1 +1270,1 @@\n-  } else if (iid == vmIntrinsics::_invokeBasic || iid == vmIntrinsics::_linkToNative) {\n+  } else if (iid == vmIntrinsics::_invokeBasic) {\n@@ -1229,0 +1272,3 @@\n+  } else if (iid == vmIntrinsics::_linkToNative) {\n+    member_arg_pos = method->size_of_parameters() - 1;  \/\/ trailing NativeEntryPoint argument\n+    member_reg = r19;  \/\/ known to be free at this point\n@@ -1290,2 +1336,66 @@\n-                                                BasicType ret_type,\n-                                                address critical_entry) {\n+                                                BasicType ret_type) {\n+  if (method->is_continuation_native_intrinsic()) {\n+    int exception_offset = -1;\n+    OopMapSet* oop_maps = new OopMapSet();\n+    int frame_complete = -1;\n+    int stack_slots = -1;\n+    int interpreted_entry_offset = -1;\n+    int vep_offset = -1;\n+    if (method->is_continuation_enter_intrinsic()) {\n+      gen_continuation_enter(masm,\n+                             method,\n+                             in_sig_bt,\n+                             in_regs,\n+                             exception_offset,\n+                             oop_maps,\n+                             frame_complete,\n+                             stack_slots,\n+                             interpreted_entry_offset,\n+                             vep_offset);\n+    } else if (method->is_continuation_yield_intrinsic()) {\n+      gen_continuation_yield(masm,\n+                             method,\n+                             in_sig_bt,\n+                             in_regs,\n+                             oop_maps,\n+                             frame_complete,\n+                             stack_slots,\n+                             vep_offset);\n+    } else {\n+      guarantee(false, \"Unknown Continuation native intrinsic\");\n+    }\n+\n+#ifdef ASSERT\n+    if (method->is_continuation_enter_intrinsic()) {\n+      assert(interpreted_entry_offset != -1, \"Must be set\");\n+      assert(exception_offset != -1,         \"Must be set\");\n+    } else {\n+      assert(interpreted_entry_offset == -1, \"Must be unset\");\n+      assert(exception_offset == -1,         \"Must be unset\");\n+    }\n+    assert(frame_complete != -1,    \"Must be set\");\n+    assert(stack_slots != -1,       \"Must be set\");\n+    assert(vep_offset != -1,        \"Must be set\");\n+#endif\n+\n+    __ flush();\n+    nmethod* nm = nmethod::new_native_nmethod(method,\n+                                              compile_id,\n+                                              masm->code(),\n+                                              vep_offset,\n+                                              frame_complete,\n+                                              stack_slots,\n+                                              in_ByteSize(-1),\n+                                              in_ByteSize(-1),\n+                                              oop_maps,\n+                                              exception_offset);\n+    if (method->is_continuation_enter_intrinsic()) {\n+      ContinuationEntry::set_enter_code(nm, interpreted_entry_offset);\n+    } else if (method->is_continuation_yield_intrinsic()) {\n+      _cont_doYield_stub = nm;\n+    } else {\n+      guarantee(false, \"Unknown Continuation native intrinsic\");\n+    }\n+    return nm;\n+  }\n+\n@@ -1314,1 +1424,1 @@\n-                                       (OopMapSet*)NULL);\n+                                       nullptr);\n@@ -1316,7 +1426,2 @@\n-  bool is_critical_native = true;\n-  address native_func = critical_entry;\n-  if (native_func == NULL) {\n-    native_func = method->native_function();\n-    is_critical_native = false;\n-  }\n-  assert(native_func != NULL, \"must have function\");\n+  address native_func = method->native_function();\n+  assert(native_func != nullptr, \"must have function\");\n@@ -1335,13 +1440,1 @@\n-  int total_c_args = total_in_args;\n-  if (!is_critical_native) {\n-    total_c_args += 1;\n-    if (method->is_static()) {\n-      total_c_args++;\n-    }\n-  } else {\n-    for (int i = 0; i < total_in_args; i++) {\n-      if (in_sig_bt[i] == T_ARRAY) {\n-        total_c_args++;\n-      }\n-    }\n-  }\n+  int total_c_args = total_in_args + (method->is_static() ? 2 : 1);\n@@ -1351,1 +1444,1 @@\n-  BasicType* in_elem_bt = NULL;\n+  BasicType* in_elem_bt = nullptr;\n@@ -1354,5 +1447,4 @@\n-  if (!is_critical_native) {\n-    out_sig_bt[argc++] = T_ADDRESS;\n-    if (method->is_static()) {\n-      out_sig_bt[argc++] = T_OBJECT;\n-    }\n+  out_sig_bt[argc++] = T_ADDRESS;\n+  if (method->is_static()) {\n+    out_sig_bt[argc++] = T_OBJECT;\n+  }\n@@ -1360,24 +1452,2 @@\n-    for (int i = 0; i < total_in_args ; i++ ) {\n-      out_sig_bt[argc++] = in_sig_bt[i];\n-    }\n-  } else {\n-    in_elem_bt = NEW_RESOURCE_ARRAY(BasicType, total_in_args);\n-    SignatureStream ss(method->signature());\n-    for (int i = 0; i < total_in_args ; i++ ) {\n-      if (in_sig_bt[i] == T_ARRAY) {\n-        \/\/ Arrays are passed as int, elem* pair\n-        out_sig_bt[argc++] = T_INT;\n-        out_sig_bt[argc++] = T_ADDRESS;\n-        ss.skip_array_prefix(1);  \/\/ skip one '['\n-        assert(ss.is_primitive(), \"primitive type expected\");\n-        in_elem_bt[i] = ss.type();\n-      } else {\n-        out_sig_bt[argc++] = in_sig_bt[i];\n-        in_elem_bt[i] = T_VOID;\n-      }\n-      if (in_sig_bt[i] != T_VOID) {\n-        assert(in_sig_bt[i] == ss.type() ||\n-               in_sig_bt[i] == T_ARRAY, \"must match\");\n-        ss.next();\n-      }\n-    }\n+  for (int i = 0; i < total_in_args ; i++ ) {\n+    out_sig_bt[argc++] = in_sig_bt[i];\n@@ -1389,1 +1459,1 @@\n-  out_arg_slots = c_calling_convention_priv(out_sig_bt, out_regs, NULL, total_c_args);\n+  out_arg_slots = c_calling_convention_priv(out_sig_bt, out_regs, nullptr, total_c_args);\n@@ -1392,1 +1462,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1405,28 +1475,0 @@\n-  if (is_critical_native) {\n-    \/\/ Critical natives may have to call out so they need a save area\n-    \/\/ for register arguments.\n-    int double_slots = 0;\n-    int single_slots = 0;\n-    for ( int i = 0; i < total_in_args; i++) {\n-      if (in_regs[i].first()->is_Register()) {\n-        const Register reg = in_regs[i].first()->as_Register();\n-        switch (in_sig_bt[i]) {\n-          case T_BOOLEAN:\n-          case T_BYTE:\n-          case T_SHORT:\n-          case T_CHAR:\n-          case T_INT:  single_slots++; break;\n-          case T_ARRAY:  \/\/ specific to LP64 (7145024)\n-          case T_LONG: double_slots++; break;\n-          default:  ShouldNotReachHere();\n-        }\n-      } else if (in_regs[i].first()->is_FloatRegister()) {\n-        ShouldNotReachHere();\n-      }\n-    }\n-    total_save_slots = double_slots * 2 + single_slots;\n-    \/\/ align the save area\n-    if (double_slots != 0) {\n-      stack_slots = align_up(stack_slots, 2);\n-    }\n-  }\n@@ -1542,1 +1584,1 @@\n-  bs->nmethod_entry_barrier(masm);\n+  bs->nmethod_entry_barrier(masm, nullptr \/* slow_path *\/, nullptr \/* continuation *\/, nullptr \/* guard *\/);\n@@ -1588,3 +1630,3 @@\n-  bool reg_destroyed[RegisterImpl::number_of_registers];\n-  bool freg_destroyed[FloatRegisterImpl::number_of_registers];\n-  for ( int r = 0 ; r < RegisterImpl::number_of_registers ; r++ ) {\n+  bool reg_destroyed[Register::number_of_registers];\n+  bool freg_destroyed[FloatRegister::number_of_registers];\n+  for ( int r = 0 ; r < Register::number_of_registers ; r++ ) {\n@@ -1593,1 +1635,1 @@\n-  for ( int f = 0 ; f < FloatRegisterImpl::number_of_registers ; f++ ) {\n+  for ( int f = 0 ; f < FloatRegister::number_of_registers ; f++ ) {\n@@ -1599,4 +1641,1 @@\n-  \/\/ This may iterate in two different directions depending on the\n-  \/\/ kind of native it is.  The reason is that for regular JNI natives\n-  \/\/ the incoming and outgoing registers are offset upwards and for\n-  \/\/ critical natives they are offset down.\n+  \/\/ For JNI natives the incoming and outgoing registers are offset upwards.\n@@ -1607,8 +1646,3 @@\n-  if (!is_critical_native) {\n-    for (int i = total_in_args - 1, c_arg = total_c_args - 1; i >= 0; i--, c_arg--) {\n-      arg_order.push(i);\n-      arg_order.push(c_arg);\n-    }\n-  } else {\n-    \/\/ Compute a valid move order, using tmp_vmreg to break any cycles\n-    ComputeMoveOrder cmo(total_in_args, in_regs, total_c_args, out_regs, in_sig_bt, arg_order, tmp_vmreg);\n+  for (int i = total_in_args - 1, c_arg = total_c_args - 1; i >= 0; i--, c_arg--) {\n+    arg_order.push(i);\n+    arg_order.push(c_arg);\n@@ -1622,14 +1656,1 @@\n-    if (c_arg == -1) {\n-      assert(is_critical_native, \"should only be required for critical natives\");\n-      \/\/ This arg needs to be moved to a temporary\n-      __ mov(tmp_vmreg.first()->as_Register(), in_regs[i].first()->as_Register());\n-      in_regs[i] = tmp_vmreg;\n-      temploc = i;\n-      continue;\n-    } else if (i == -1) {\n-      assert(is_critical_native, \"should only be required for critical natives\");\n-      \/\/ Read from the temporary location\n-      assert(temploc != -1, \"must be valid\");\n-      i = temploc;\n-      temploc = -1;\n-    }\n+    assert(c_arg != -1 && i != -1, \"wrong order\");\n@@ -1650,17 +1671,3 @@\n-        if (is_critical_native) {\n-          unpack_array_argument(masm, in_regs[i], in_elem_bt[i], out_regs[c_arg + 1], out_regs[c_arg]);\n-          c_arg++;\n-#ifdef ASSERT\n-          if (out_regs[c_arg].first()->is_Register()) {\n-            reg_destroyed[out_regs[c_arg].first()->as_Register()->encoding()] = true;\n-          } else if (out_regs[c_arg].first()->is_FloatRegister()) {\n-            freg_destroyed[out_regs[c_arg].first()->as_FloatRegister()->encoding()] = true;\n-          }\n-#endif\n-          int_args++;\n-          break;\n-        }\n-        assert(!is_critical_native, \"no oop arguments\");\n-        object_move(masm, map, oop_handle_offset, stack_slots, in_regs[i], out_regs[c_arg],\n-                    ((i == 0) && (!is_static)),\n-                    &receiver_offset);\n+        __ object_move(map, oop_handle_offset, stack_slots, in_regs[i], out_regs[c_arg],\n+                       ((i == 0) && (!is_static)),\n+                       &receiver_offset);\n@@ -1674,1 +1681,1 @@\n-        float_move(masm, in_regs[i], out_regs[c_arg]);\n+        __ float_move(in_regs[i], out_regs[c_arg]);\n@@ -1682,1 +1689,1 @@\n-        double_move(masm, in_regs[i], out_regs[c_arg]);\n+        __ double_move(in_regs[i], out_regs[c_arg]);\n@@ -1687,1 +1694,1 @@\n-        long_move(masm, in_regs[i], out_regs[c_arg]);\n+        __ long_move(in_regs[i], out_regs[c_arg]);\n@@ -1694,1 +1701,1 @@\n-        move32_64(masm, in_regs[i], out_regs[c_arg]);\n+        __ move32_64(in_regs[i], out_regs[c_arg]);\n@@ -1704,1 +1711,1 @@\n-  if (method->is_static() && !is_critical_native) {\n+  if (method->is_static()) {\n@@ -1708,2 +1715,1 @@\n-              JNIHandles::make_local(method->method_holder()->java_mirror()),\n-              \/*immediate*\/true);\n+              JNIHandles::make_local(method->method_holder()->java_mirror()));\n@@ -1771,2 +1777,1 @@\n-    assert(!is_critical_native, \"unhandled\");\n-\n+    Label count;\n@@ -1785,14 +1790,35 @@\n-    if (UseBiasedLocking) {\n-      __ biased_locking_enter(lock_reg, obj_reg, swap_reg, tmp, false, lock_done, &slow_path_lock);\n-    }\n-\n-    \/\/ Load (object->mark() | 1) into swap_reg %r0\n-    __ ldr(rscratch1, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    __ orr(swap_reg, rscratch1, 1);\n-\n-    \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-    __ str(swap_reg, Address(lock_reg, mark_word_offset));\n-\n-    \/\/ src -> dest iff dest == r0 else r0 <- dest\n-    { Label here;\n-      __ cmpxchg_obj_header(r0, lock_reg, obj_reg, rscratch1, lock_done, \/*fallthrough*\/NULL);\n+    if (LockingMode == LM_MONITOR) {\n+      __ b(slow_path_lock);\n+    } else if (LockingMode == LM_LEGACY) {\n+      \/\/ Load (object->mark() | 1) into swap_reg %r0\n+      __ ldr(rscratch1, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ orr(swap_reg, rscratch1, 1);\n+\n+      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+      __ str(swap_reg, Address(lock_reg, mark_word_offset));\n+\n+      \/\/ src -> dest iff dest == r0 else r0 <- dest\n+      __ cmpxchg_obj_header(r0, lock_reg, obj_reg, rscratch1, count, \/*fallthrough*\/nullptr);\n+\n+      \/\/ Hmm should this move to the slow path code area???\n+\n+      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n+      \/\/  1) (mark & 3) == 0, and\n+      \/\/  2) sp <= mark < mark + os::pagesize()\n+      \/\/ These 3 tests can be done by evaluating the following\n+      \/\/ expression: ((mark - sp) & (3 - os::vm_page_size())),\n+      \/\/ assuming both stack pointer and pagesize have their\n+      \/\/ least significant 2 bits clear.\n+      \/\/ NOTE: the oopMark is in swap_reg %r0 as the result of cmpxchg\n+\n+      __ sub(swap_reg, sp, swap_reg);\n+      __ neg(swap_reg, swap_reg);\n+      __ ands(swap_reg, swap_reg, 3 - (int)os::vm_page_size());\n+\n+      \/\/ Save the test result, for recursive case, the result is zero\n+      __ str(swap_reg, Address(lock_reg, mark_word_offset));\n+      __ br(Assembler::NE, slow_path_lock);\n+    } else {\n+      assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+      __ ldr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ fast_lock(obj_reg, swap_reg, tmp, rscratch1, slow_path_lock);\n@@ -1800,19 +1826,2 @@\n-\n-    \/\/ Hmm should this move to the slow path code area???\n-\n-    \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-    \/\/  1) (mark & 3) == 0, and\n-    \/\/  2) sp <= mark < mark + os::pagesize()\n-    \/\/ These 3 tests can be done by evaluating the following\n-    \/\/ expression: ((mark - sp) & (3 - os::vm_page_size())),\n-    \/\/ assuming both stack pointer and pagesize have their\n-    \/\/ least significant 2 bits clear.\n-    \/\/ NOTE: the oopMark is in swap_reg %r0 as the result of cmpxchg\n-\n-    __ sub(swap_reg, sp, swap_reg);\n-    __ neg(swap_reg, swap_reg);\n-    __ ands(swap_reg, swap_reg, 3 - os::vm_page_size());\n-\n-    \/\/ Save the test result, for recursive case, the result is zero\n-    __ str(swap_reg, Address(lock_reg, mark_word_offset));\n-    __ br(Assembler::NE, slow_path_lock);\n+    __ bind(count);\n+    __ increment(Address(rthread, JavaThread::held_monitor_count_offset()));\n@@ -1821,1 +1830,0 @@\n-\n@@ -1837,2 +1845,1 @@\n-  if (!is_critical_native) {\n-    __ lea(c_rarg0, Address(rthread, in_bytes(JavaThread::jni_environment_offset())));\n+  __ lea(c_rarg0, Address(rthread, in_bytes(JavaThread::jni_environment_offset())));\n@@ -1840,5 +1847,4 @@\n-    \/\/ Now set thread in native\n-    __ mov(rscratch1, _thread_in_native);\n-    __ lea(rscratch2, Address(rthread, JavaThread::thread_state_offset()));\n-    __ stlrw(rscratch1, rscratch2);\n-  }\n+  \/\/ Now set thread in native\n+  __ mov(rscratch1, _thread_in_native);\n+  __ lea(rscratch2, Address(rthread, JavaThread::thread_state_offset()));\n+  __ stlrw(rscratch1, rscratch2);\n@@ -1846,1 +1852,1 @@\n-  rt_call(masm, native_func);\n+  __ rt_call(native_func);\n@@ -1875,12 +1881,0 @@\n-  \/\/ If this is a critical native, check for a safepoint or suspend request after the call.\n-  \/\/ If a safepoint is needed, transition to native, then to native_trans to handle\n-  \/\/ safepoints like the native methods that are not critical natives.\n-  if (is_critical_native) {\n-    Label needs_safepoint;\n-    __ safepoint_poll(needs_safepoint, false \/* at_return *\/, true \/* acquire *\/, false \/* in_nmethod *\/);\n-    __ ldrw(rscratch1, Address(rthread, JavaThread::suspend_flags_offset()));\n-    __ cbnzw(rscratch1, needs_safepoint);\n-    __ b(after_transition);\n-    __ bind(needs_safepoint);\n-  }\n-\n@@ -1899,1 +1893,3 @@\n-  __ dmb(Assembler::ISH);\n+  if (!UseSystemMemoryBarrier) {\n+    __ dmb(Assembler::ISH);\n+  }\n@@ -1943,2 +1939,0 @@\n-    __ resolve(IS_NOT_NULL, obj_reg);\n-\n@@ -1953,0 +1947,1 @@\n+    Label done, not_recursive;\n@@ -1954,4 +1949,6 @@\n-    Label done;\n-\n-    if (UseBiasedLocking) {\n-      __ biased_locking_exit(obj_reg, old_hdr, done);\n+    if (LockingMode == LM_LEGACY) {\n+      \/\/ Simple recursive lock?\n+      __ ldr(rscratch1, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+      __ cbnz(rscratch1, not_recursive);\n+      __ decrement(Address(rthread, JavaThread::held_monitor_count_offset()));\n+      __ b(done);\n@@ -1960,4 +1957,1 @@\n-    \/\/ Simple recursive lock?\n-\n-    __ ldr(rscratch1, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-    __ cbz(rscratch1, done);\n+    __ bind(not_recursive);\n@@ -1970,10 +1964,20 @@\n-\n-    \/\/ get address of the stack lock\n-    __ lea(r0, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-    \/\/  get old displaced header\n-    __ ldr(old_hdr, Address(r0, 0));\n-\n-    \/\/ Atomic swap old header if oop still contains the stack lock\n-    Label succeed;\n-    __ cmpxchg_obj_header(r0, old_hdr, obj_reg, rscratch1, succeed, &slow_path_unlock);\n-    __ bind(succeed);\n+    if (LockingMode == LM_MONITOR) {\n+      __ b(slow_path_unlock);\n+    } else if (LockingMode == LM_LEGACY) {\n+      \/\/ get address of the stack lock\n+      __ lea(r0, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+      \/\/  get old displaced header\n+      __ ldr(old_hdr, Address(r0, 0));\n+\n+      \/\/ Atomic swap old header if oop still contains the stack lock\n+      Label count;\n+      __ cmpxchg_obj_header(r0, old_hdr, obj_reg, rscratch1, count, &slow_path_unlock);\n+      __ bind(count);\n+      __ decrement(Address(rthread, JavaThread::held_monitor_count_offset()));\n+    } else {\n+      assert(LockingMode == LM_LIGHTWEIGHT, \"\");\n+      __ ldr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ tbnz(old_hdr, exact_log2(markWord::monitor_value), slow_path_unlock);\n+      __ fast_unlock(obj_reg, old_hdr, swap_reg, rscratch1, slow_path_unlock);\n+      __ decrement(Address(rthread, JavaThread::held_monitor_count_offset()));\n+    }\n@@ -2010,1 +2014,1 @@\n-    __ resolve_jobject(r0, rthread, rscratch2);\n+    __ resolve_jobject(r0, r1, r2);\n@@ -2018,5 +2022,3 @@\n-  if (!is_critical_native) {\n-    \/\/ reset handle block\n-    __ ldr(r2, Address(rthread, JavaThread::active_handles_offset()));\n-    __ str(zr, Address(r2, JNIHandleBlock::top_offset_in_bytes()));\n-  }\n+  \/\/ reset handle block\n+  __ ldr(r2, Address(rthread, JavaThread::active_handles_offset()));\n+  __ str(zr, Address(r2, JNIHandleBlock::top_offset()));\n@@ -2026,5 +2028,3 @@\n-  if (!is_critical_native) {\n-    \/\/ Any exception pending?\n-    __ ldr(rscratch1, Address(rthread, in_bytes(Thread::pending_exception_offset())));\n-    __ cbnz(rscratch1, exception_pending);\n-  }\n+  \/\/ Any exception pending?\n+  __ ldr(rscratch1, Address(rthread, in_bytes(Thread::pending_exception_offset())));\n+  __ cbnz(rscratch1, exception_pending);\n@@ -2037,3 +2037,2 @@\n-  if (!is_critical_native) {\n-    \/\/ forward the exception\n-    __ bind(exception_pending);\n+  \/\/ forward the exception\n+  __ bind(exception_pending);\n@@ -2041,3 +2040,2 @@\n-    \/\/ and forward the exception\n-    __ far_jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n-  }\n+  \/\/ and forward the exception\n+  __ far_jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n@@ -2096,1 +2094,1 @@\n-    rt_call(masm, CAST_FROM_FN_PTR(address, SharedRuntime::complete_monitor_unlocking_C));\n+    __ rt_call(CAST_FROM_FN_PTR(address, SharedRuntime::complete_monitor_unlocking_C));\n@@ -2123,1 +2121,1 @@\n-  rt_call(masm, CAST_FROM_FN_PTR(address, SharedRuntime::reguard_yellow_pages));\n+  __ rt_call(CAST_FROM_FN_PTR(address, SharedRuntime::reguard_yellow_pages));\n@@ -2225,1 +2223,1 @@\n-  OopMap* map = NULL;\n+  OopMap* map = nullptr;\n@@ -2231,1 +2229,1 @@\n-  \/\/ address has been pushed on the the stack, and return values are in\n+  \/\/ address has been pushed on the stack, and return values are in\n@@ -2368,1 +2366,1 @@\n-\n+  __ protect_return_address(r3, rscratch1);\n@@ -2397,1 +2395,1 @@\n-#ifdef ASSERT0\n+#ifdef ASSERT\n@@ -2399,2 +2397,1 @@\n-    __ ldr(rscratch1, Address(rthread,\n-                              JavaThread::last_Java_fp_offset()));\n+    __ ldr(rscratch1, Address(rthread, JavaThread::last_Java_fp_offset()));\n@@ -2427,1 +2424,1 @@\n-  __ ldrw(rcpool, Address(r5, Deoptimization::UnrollBlock::unpack_kind_offset_in_bytes()));\n+  __ ldrw(rcpool, Address(r5, Deoptimization::UnrollBlock::unpack_kind_offset()));\n@@ -2432,1 +2429,1 @@\n-  \/\/ QQQ this is useless it was NULL above\n+  \/\/ QQQ this is useless it was null above\n@@ -2473,1 +2470,1 @@\n-  __ ldrw(r2, Address(r5, Deoptimization::UnrollBlock::size_of_deoptimized_frame_offset_in_bytes()));\n+  __ ldrw(r2, Address(r5, Deoptimization::UnrollBlock::size_of_deoptimized_frame_offset()));\n@@ -2477,0 +2474,1 @@\n+  __ authenticate_return_address();\n@@ -2483,1 +2481,1 @@\n-  __ ldrw(r19, Address(r5, Deoptimization::UnrollBlock::total_frame_sizes_offset_in_bytes()));\n+  __ ldrw(r19, Address(r5, Deoptimization::UnrollBlock::total_frame_sizes_offset()));\n@@ -2487,1 +2485,1 @@\n-  __ ldr(r2, Address(r5, Deoptimization::UnrollBlock::frame_pcs_offset_in_bytes()));\n+  __ ldr(r2, Address(r5, Deoptimization::UnrollBlock::frame_pcs_offset()));\n@@ -2493,1 +2491,1 @@\n-  __ ldr(r4, Address(r5, Deoptimization::UnrollBlock::frame_sizes_offset_in_bytes()));\n+  __ ldr(r4, Address(r5, Deoptimization::UnrollBlock::frame_sizes_offset()));\n@@ -2496,1 +2494,1 @@\n-  __ ldrw(r3, Address(r5, Deoptimization::UnrollBlock::number_of_frames_offset_in_bytes()));\n+  __ ldrw(r3, Address(r5, Deoptimization::UnrollBlock::number_of_frames_offset()));\n@@ -2508,1 +2506,1 @@\n-                       caller_adjustment_offset_in_bytes()));\n+                       caller_adjustment_offset()));\n@@ -2618,0 +2616,1 @@\n+  __ protect_return_address();\n@@ -2667,1 +2666,1 @@\n-    __ ldrw(rscratch1, Address(r4, Deoptimization::UnrollBlock::unpack_kind_offset_in_bytes()));\n+    __ ldrw(rscratch1, Address(r4, Deoptimization::UnrollBlock::unpack_kind_offset()));\n@@ -2670,1 +2669,1 @@\n-    __ stop(\"SharedRuntime::generate_deopt_blob: last_Java_fp not cleared\");\n+    __ stop(\"SharedRuntime::generate_uncommon_trap_blob: expected Unpack_uncommon_trap\");\n@@ -2688,1 +2687,1 @@\n-                      size_of_deoptimized_frame_offset_in_bytes()));\n+                      size_of_deoptimized_frame_offset()));\n@@ -2692,0 +2691,1 @@\n+  __ authenticate_return_address();\n@@ -2700,1 +2700,1 @@\n-                      total_frame_sizes_offset_in_bytes()));\n+                      total_frame_sizes_offset()));\n@@ -2706,1 +2706,1 @@\n-                     Deoptimization::UnrollBlock::frame_pcs_offset_in_bytes()));\n+                     Deoptimization::UnrollBlock::frame_pcs_offset()));\n@@ -2711,1 +2711,1 @@\n-                     frame_sizes_offset_in_bytes()));\n+                     frame_sizes_offset()));\n@@ -2716,1 +2716,1 @@\n-                      number_of_frames_offset_in_bytes())); \/\/ (int)\n+                      number_of_frames_offset())); \/\/ (int)\n@@ -2728,1 +2728,1 @@\n-                      caller_adjustment_offset_in_bytes())); \/\/ (int)\n+                      caller_adjustment_offset())); \/\/ (int)\n@@ -2809,1 +2809,1 @@\n-  address call_pc = NULL;\n+  address call_pc = nullptr;\n@@ -2814,0 +2814,5 @@\n+  \/\/ When the signal occurred, the LR was either signed and stored on the stack (in which\n+  \/\/ case it will be restored from the stack before being used) or unsigned and not stored\n+  \/\/ on the stack. Stipping ensures we get the right value.\n+  __ strip_return_address();\n+\n@@ -2819,1 +2824,1 @@\n-  \/\/ work outselves.\n+  \/\/ work ourselves.\n@@ -2833,0 +2838,1 @@\n+    __ protect_return_address(r20, rscratch1);\n@@ -2873,0 +2879,1 @@\n+    __ authenticate_return_address(r20, rscratch1);\n@@ -2887,0 +2894,1 @@\n+    __ protect_return_address(r20, rscratch1);\n@@ -2917,1 +2925,1 @@\n-  assert (StubRoutines::forward_exception_entry() != NULL, \"must be generated before\");\n+  assert (StubRoutines::forward_exception_entry() != nullptr, \"must be generated before\");\n@@ -2929,1 +2937,1 @@\n-  OopMap* map = NULL;\n+  OopMap* map = nullptr;\n@@ -2971,1 +2979,1 @@\n-  \/\/ We are back the the original state on entry and ready to go.\n+  \/\/ We are back to the original state on entry and ready to go.\n@@ -2998,1 +3006,1 @@\n-\/\/ This is here instead of runtime_x86_64.cpp because it uses SimpleRuntimeFrame\n+\/\/ This is here instead of runtime_aarch64_64.cpp because it uses SimpleRuntimeFrame\n@@ -3047,0 +3055,1 @@\n+  __ protect_return_address();\n@@ -3100,0 +3109,1 @@\n+  __ authenticate_return_address(r3);\n@@ -3131,251 +3141,0 @@\n-\/\/ ---------------------------------------------------------------\n-\n-class NativeInvokerGenerator : public StubCodeGenerator {\n-  address _call_target;\n-  int _shadow_space_bytes;\n-\n-  const GrowableArray<VMReg>& _input_registers;\n-  const GrowableArray<VMReg>& _output_registers;\n-\n-  int _frame_complete;\n-  int _framesize;\n-  OopMapSet* _oop_maps;\n-public:\n-  NativeInvokerGenerator(CodeBuffer* buffer,\n-                         address call_target,\n-                         int shadow_space_bytes,\n-                         const GrowableArray<VMReg>& input_registers,\n-                         const GrowableArray<VMReg>& output_registers)\n-   : StubCodeGenerator(buffer, PrintMethodHandleStubs),\n-     _call_target(call_target),\n-     _shadow_space_bytes(shadow_space_bytes),\n-     _input_registers(input_registers),\n-     _output_registers(output_registers),\n-     _frame_complete(0),\n-     _framesize(0),\n-     _oop_maps(NULL) {\n-    assert(_output_registers.length() <= 1\n-           || (_output_registers.length() == 2 && !_output_registers.at(1)->is_valid()), \"no multi-reg returns\");\n-  }\n-\n-  void generate();\n-\n-  int spill_size_in_bytes() const {\n-    if (_output_registers.length() == 0) {\n-      return 0;\n-    }\n-    VMReg reg = _output_registers.at(0);\n-    assert(reg->is_reg(), \"must be a register\");\n-    if (reg->is_Register()) {\n-      return 8;\n-    } else if (reg->is_FloatRegister()) {\n-      bool use_sve = Matcher::supports_scalable_vector();\n-      if (use_sve) {\n-        return Matcher::scalable_vector_reg_size(T_BYTE);\n-      }\n-      return 16;\n-    } else {\n-      ShouldNotReachHere();\n-    }\n-    return 0;\n-  }\n-\n-  void spill_output_registers() {\n-    if (_output_registers.length() == 0) {\n-      return;\n-    }\n-    VMReg reg = _output_registers.at(0);\n-    assert(reg->is_reg(), \"must be a register\");\n-    MacroAssembler* masm = _masm;\n-    if (reg->is_Register()) {\n-      __ spill(reg->as_Register(), true, 0);\n-    } else if (reg->is_FloatRegister()) {\n-      bool use_sve = Matcher::supports_scalable_vector();\n-      if (use_sve) {\n-        __ spill_sve_vector(reg->as_FloatRegister(), 0, Matcher::scalable_vector_reg_size(T_BYTE));\n-      } else {\n-        __ spill(reg->as_FloatRegister(), __ Q, 0);\n-      }\n-    } else {\n-      ShouldNotReachHere();\n-    }\n-  }\n-\n-  void fill_output_registers() {\n-    if (_output_registers.length() == 0) {\n-      return;\n-    }\n-    VMReg reg = _output_registers.at(0);\n-    assert(reg->is_reg(), \"must be a register\");\n-    MacroAssembler* masm = _masm;\n-    if (reg->is_Register()) {\n-      __ unspill(reg->as_Register(), true, 0);\n-    } else if (reg->is_FloatRegister()) {\n-      bool use_sve = Matcher::supports_scalable_vector();\n-      if (use_sve) {\n-        __ unspill_sve_vector(reg->as_FloatRegister(), 0, Matcher::scalable_vector_reg_size(T_BYTE));\n-      } else {\n-        __ unspill(reg->as_FloatRegister(), __ Q, 0);\n-      }\n-    } else {\n-      ShouldNotReachHere();\n-    }\n-  }\n-\n-  int frame_complete() const {\n-    return _frame_complete;\n-  }\n-\n-  int framesize() const {\n-    return (_framesize >> (LogBytesPerWord - LogBytesPerInt));\n-  }\n-\n-  OopMapSet* oop_maps() const {\n-    return _oop_maps;\n-  }\n-\n-private:\n-#ifdef ASSERT\n-  bool target_uses_register(VMReg reg) {\n-    return _input_registers.contains(reg) || _output_registers.contains(reg);\n-  }\n-#endif\n-};\n-\n-static const int native_invoker_code_size = 1024;\n-\n-RuntimeStub* SharedRuntime::make_native_invoker(address call_target,\n-                                                int shadow_space_bytes,\n-                                                const GrowableArray<VMReg>& input_registers,\n-                                                const GrowableArray<VMReg>& output_registers) {\n-  int locs_size  = 64;\n-  CodeBuffer code(\"nep_invoker_blob\", native_invoker_code_size, locs_size);\n-  NativeInvokerGenerator g(&code, call_target, shadow_space_bytes, input_registers, output_registers);\n-  g.generate();\n-  code.log_section_sizes(\"nep_invoker_blob\");\n-\n-  RuntimeStub* stub =\n-    RuntimeStub::new_runtime_stub(\"nep_invoker_blob\",\n-                                  &code,\n-                                  g.frame_complete(),\n-                                  g.framesize(),\n-                                  g.oop_maps(), false);\n-  return stub;\n-}\n-\n-void NativeInvokerGenerator::generate() {\n-  assert(!(target_uses_register(rscratch1->as_VMReg())\n-           || target_uses_register(rscratch2->as_VMReg())\n-           || target_uses_register(rthread->as_VMReg())),\n-         \"Register conflict\");\n-\n-  enum layout {\n-    rbp_off,\n-    rbp_off2,\n-    return_off,\n-    return_off2,\n-    framesize \/\/ inclusive of return address\n-  };\n-\n-  assert(_shadow_space_bytes == 0, \"not expecting shadow space on AArch64\");\n-  _framesize = align_up(framesize + (spill_size_in_bytes() >> LogBytesPerInt), 4);\n-  assert(is_even(_framesize\/2), \"sp not 16-byte aligned\");\n-\n-  _oop_maps  = new OopMapSet();\n-  MacroAssembler* masm = _masm;\n-\n-  address start = __ pc();\n-\n-  __ enter();\n-\n-  \/\/ lr and fp are already in place\n-  __ sub(sp, rfp, ((unsigned)_framesize-4) << LogBytesPerInt); \/\/ prolog\n-\n-  _frame_complete = __ pc() - start;\n-\n-  address the_pc = __ pc();\n-  __ set_last_Java_frame(sp, rfp, the_pc, rscratch1);\n-  OopMap* map = new OopMap(_framesize, 0);\n-  _oop_maps->add_gc_map(the_pc - start, map);\n-\n-  \/\/ State transition\n-  __ mov(rscratch1, _thread_in_native);\n-  __ lea(rscratch2, Address(rthread, JavaThread::thread_state_offset()));\n-  __ stlrw(rscratch1, rscratch2);\n-\n-  rt_call(masm, _call_target);\n-\n-  __ mov(rscratch1, _thread_in_native_trans);\n-  __ strw(rscratch1, Address(rthread, JavaThread::thread_state_offset()));\n-\n-  \/\/ Force this write out before the read below\n-  __ membar(Assembler::LoadLoad | Assembler::LoadStore |\n-            Assembler::StoreLoad | Assembler::StoreStore);\n-\n-  __ verify_sve_vector_length();\n-\n-  Label L_after_safepoint_poll;\n-  Label L_safepoint_poll_slow_path;\n-\n-  __ safepoint_poll(L_safepoint_poll_slow_path, true \/* at_return *\/, true \/* acquire *\/, false \/* in_nmethod *\/);\n-\n-  __ ldrw(rscratch1, Address(rthread, JavaThread::suspend_flags_offset()));\n-  __ cbnzw(rscratch1, L_safepoint_poll_slow_path);\n-\n-  __ bind(L_after_safepoint_poll);\n-\n-  \/\/ change thread state\n-  __ mov(rscratch1, _thread_in_Java);\n-  __ lea(rscratch2, Address(rthread, JavaThread::thread_state_offset()));\n-  __ stlrw(rscratch1, rscratch2);\n-\n-  __ block_comment(\"reguard stack check\");\n-  Label L_reguard;\n-  Label L_after_reguard;\n-  __ ldrb(rscratch1, Address(rthread, JavaThread::stack_guard_state_offset()));\n-  __ cmpw(rscratch1, StackOverflow::stack_guard_yellow_reserved_disabled);\n-  __ br(Assembler::EQ, L_reguard);\n-  __ bind(L_after_reguard);\n-\n-  __ reset_last_Java_frame(true);\n-\n-  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-  __ ret(lr);\n-\n-  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-\n-  __ block_comment(\"{ L_safepoint_poll_slow_path\");\n-  __ bind(L_safepoint_poll_slow_path);\n-\n-  \/\/ Need to save the native result registers around any runtime calls.\n-  spill_output_registers();\n-\n-  __ mov(c_rarg0, rthread);\n-  assert(frame::arg_reg_save_area_bytes == 0, \"not expecting frame reg save area\");\n-  __ lea(rscratch1, RuntimeAddress(CAST_FROM_FN_PTR(address, JavaThread::check_special_condition_for_native_trans)));\n-  __ blr(rscratch1);\n-\n-  fill_output_registers();\n-\n-  __ b(L_after_safepoint_poll);\n-  __ block_comment(\"} L_safepoint_poll_slow_path\");\n-\n-  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-\n-  __ block_comment(\"{ L_reguard\");\n-  __ bind(L_reguard);\n-\n-  spill_output_registers();\n-\n-  rt_call(masm, CAST_FROM_FN_PTR(address, SharedRuntime::reguard_yellow_pages));\n-\n-  fill_output_registers();\n-\n-  __ b(L_after_reguard);\n-\n-  __ block_comment(\"} L_reguard\");\n-\n-  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-\n-  __ flush();\n-}\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":580,"deletions":821,"binary":false,"changes":1401,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,0 +28,1 @@\n+#include \"compiler\/compilerDefinitions.inline.hpp\"\n@@ -140,3 +141,3 @@\n-\/\/ Miscelaneous helper routines\n-\/\/ Store an oop (or NULL) at the Address described by obj.\n-\/\/ If val == noreg this means store a NULL\n+\/\/ Miscellaneous helper routines\n+\/\/ Store an oop (or null) at the Address described by obj.\n+\/\/ If val == noreg this means store a null\n@@ -148,1 +149,1 @@\n-  __ store_heap_oop(dst, val, r10, r1, decorators);\n+  __ store_heap_oop(dst, val, r10, r11, r3, decorators);\n@@ -155,1 +156,1 @@\n-  __ load_heap_oop(dst, src, r10, r1, decorators);\n+  __ load_heap_oop(dst, src, r10, r11, decorators);\n@@ -311,1 +312,1 @@\n-void TemplateTable::ldc(bool wide)\n+void TemplateTable::ldc(LdcType type)\n@@ -316,1 +317,1 @@\n-  if (wide) {\n+  if (is_ldc_wide(type)) {\n@@ -345,1 +346,1 @@\n-  __ mov(c_rarg1, wide);\n+  __ mov(c_rarg1, is_ldc_wide(type) ? 1 : 0);\n@@ -378,1 +379,1 @@\n-void TemplateTable::fast_aldc(bool wide)\n+void TemplateTable::fast_aldc(LdcType type)\n@@ -386,1 +387,1 @@\n-  int index_size = wide ? sizeof(u2) : sizeof(u1);\n+  int index_size = is_ldc_wide(type) ? sizeof(u2) : sizeof(u1);\n@@ -413,1 +414,1 @@\n-    __ resolve_oop_handle(tmp);\n+    __ resolve_oop_handle(tmp, r5, rscratch2);\n@@ -416,1 +417,1 @@\n-    __ mov(result, 0);  \/\/ NULL object reference\n+    __ mov(result, 0);  \/\/ null object reference\n@@ -732,2 +733,0 @@\n-  \/\/ check array\n-  __ null_check(array, arrayOopDesc::length_offset_in_bytes());\n@@ -1161,1 +1160,1 @@\n-  __ access_store_at(T_INT, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg);\n+  __ access_store_at(T_INT, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg, noreg);\n@@ -1175,1 +1174,1 @@\n-  __ access_store_at(T_LONG, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg);\n+  __ access_store_at(T_LONG, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg, noreg);\n@@ -1189,1 +1188,1 @@\n-  __ access_store_at(T_FLOAT, IN_HEAP | IS_ARRAY, addr, noreg \/* ftos *\/, noreg, noreg);\n+  __ access_store_at(T_FLOAT, IN_HEAP | IS_ARRAY, addr, noreg \/* ftos *\/, noreg, noreg, noreg);\n@@ -1203,1 +1202,1 @@\n-  __ access_store_at(T_DOUBLE, IN_HEAP | IS_ARRAY, addr, noreg \/* dtos *\/, noreg, noreg);\n+  __ access_store_at(T_DOUBLE, IN_HEAP | IS_ARRAY, addr, noreg \/* dtos *\/, noreg, noreg, noreg);\n@@ -1221,1 +1220,1 @@\n-  \/\/ do array store check - check for NULL value first\n+  \/\/ do array store check - check for null value first\n@@ -1249,1 +1248,1 @@\n-  \/\/ Have a NULL in r0, r3=array, r2=index.  Store NULL at ary[idx]\n+  \/\/ Have a null in r0, r3=array, r2=index.  Store null at ary[idx]\n@@ -1253,1 +1252,1 @@\n-  \/\/ Store a NULL\n+  \/\/ Store a null\n@@ -1284,1 +1283,1 @@\n-  __ access_store_at(T_BYTE, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg);\n+  __ access_store_at(T_BYTE, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg, noreg);\n@@ -1299,1 +1298,1 @@\n-  __ access_store_at(T_CHAR, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg);\n+  __ access_store_at(T_CHAR, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg, noreg);\n@@ -1863,6 +1862,0 @@\n-  \/\/ We might be moving to a safepoint.  The thread which calls\n-  \/\/ Interpreter::notice_safepoints() will effectively flush its cache\n-  \/\/ when it makes a system call, but we need to do something to\n-  \/\/ ensure that we see the changed dispatch table.\n-  __ membar(MacroAssembler::LoadLoad);\n-\n@@ -1986,1 +1979,1 @@\n-    \/\/ r0: osr nmethod (osr ok) or NULL (osr not possible)\n+    \/\/ r0: osr nmethod (osr ok) or null (osr not possible)\n@@ -2084,6 +2077,0 @@\n-  \/\/ We might be moving to a safepoint.  The thread which calls\n-  \/\/ Interpreter::notice_safepoints() will effectively flush its cache\n-  \/\/ when it makes a system call, but we need to do something to\n-  \/\/ ensure that we see the changed dispatch table.\n-  __ membar(MacroAssembler::LoadLoad);\n-\n@@ -2345,1 +2332,1 @@\n-\/\/     writes act as aquire & release, so:\n+\/\/     writes act as acquire & release, so:\n@@ -2402,1 +2389,1 @@\n-    __ clinit_barrier(temp, rscratch1, NULL, &clinit_barrier_slow);\n+    __ clinit_barrier(temp, rscratch1, nullptr, &clinit_barrier_slow);\n@@ -2430,1 +2417,1 @@\n-    __ resolve_oop_handle(obj);\n+    __ resolve_oop_handle(obj, r5, rscratch2);\n@@ -2434,4 +2421,0 @@\n-\n-      \/\/ java_lang_Class::_init_lock_offset may not have been initialized\n-      \/\/ when generating code. It will be initialized at runtime though.\n-      \/\/ So calculate its address and read from it at runtime.\n@@ -2440,5 +2423,0 @@\n-      Address init_lock_offset_address((address) java_lang_Class::init_lock_offset_addr(),\n-                                       relocInfo::none);\n-      __ lea(rscratch1, init_lock_offset_address);\n-      __ ldrw(rscratch1, Address(rscratch1, 0));\n-      __ add(c_rarg0, c_rarg0, rscratch1);\n@@ -2453,0 +2431,69 @@\n+\/\/ The rmethod register is input and overwritten to be the adapter method for the\n+\/\/ indy call. Link Register (lr) is set to the return address for the adapter and\n+\/\/ an appendix may be pushed to the stack. Registers r0-r3 are clobbered\n+void TemplateTable::load_invokedynamic_entry(Register method) {\n+  \/\/ setup registers\n+  const Register appendix = r0;\n+  const Register cache = r2;\n+  const Register index = r3;\n+  assert_different_registers(method, appendix, cache, index, rcpool);\n+\n+  __ save_bcp();\n+\n+  Label resolved;\n+\n+  __ load_resolved_indy_entry(cache, index);\n+  \/\/ Load-acquire the adapter method to match store-release in ResolvedIndyEntry::fill_in()\n+  __ lea(method, Address(cache, in_bytes(ResolvedIndyEntry::method_offset())));\n+  __ ldar(method, method);\n+\n+  \/\/ Compare the method to zero\n+  __ cbnz(method, resolved);\n+\n+  Bytecodes::Code code = bytecode();\n+\n+  \/\/ Call to the interpreter runtime to resolve invokedynamic\n+  address entry = CAST_FROM_FN_PTR(address, InterpreterRuntime::resolve_from_cache);\n+  __ mov(method, code); \/\/ this is essentially Bytecodes::_invokedynamic\n+  __ call_VM(noreg, entry, method);\n+  \/\/ Update registers with resolved info\n+  __ load_resolved_indy_entry(cache, index);\n+  \/\/ Load-acquire the adapter method to match store-release in ResolvedIndyEntry::fill_in()\n+  __ lea(method, Address(cache, in_bytes(ResolvedIndyEntry::method_offset())));\n+  __ ldar(method, method);\n+\n+#ifdef ASSERT\n+  __ cbnz(method, resolved);\n+  __ stop(\"Should be resolved by now\");\n+#endif \/\/ ASSERT\n+  __ bind(resolved);\n+\n+  Label L_no_push;\n+  \/\/ Check if there is an appendix\n+  __ load_unsigned_byte(index, Address(cache, in_bytes(ResolvedIndyEntry::flags_offset())));\n+  __ tbz(index, ResolvedIndyEntry::has_appendix_shift, L_no_push);\n+\n+  \/\/ Get appendix\n+  __ load_unsigned_short(index, Address(cache, in_bytes(ResolvedIndyEntry::resolved_references_index_offset())));\n+  \/\/ Push the appendix as a trailing parameter\n+  \/\/ since the parameter_size includes it.\n+  __ push(method);\n+  __ mov(method, index);\n+  __ load_resolved_reference_at_index(appendix, method);\n+  __ verify_oop(appendix);\n+  __ pop(method);\n+  __ push(appendix);  \/\/ push appendix (MethodType, CallSite, etc.)\n+  __ bind(L_no_push);\n+\n+  \/\/ compute return type\n+  __ load_unsigned_byte(index, Address(cache, in_bytes(ResolvedIndyEntry::result_type_offset())));\n+  \/\/ load return address\n+  \/\/ Return address is loaded into link register(lr) and not pushed to the stack\n+  \/\/ like x86\n+  {\n+    const address table_addr = (address) Interpreter::invoke_return_entry_table_for(code);\n+    __ mov(rscratch1, table_addr);\n+    __ ldr(lr, Address(rscratch1, index, Address::lsl(3)));\n+  }\n+}\n+\n@@ -2459,1 +2506,1 @@\n-                                               bool is_invokedynamic) {\n+                                               bool is_invokedynamic \/*unused*\/) {\n@@ -2480,1 +2527,1 @@\n-  size_t index_size = (is_invokedynamic ? sizeof(u4) : sizeof(u2));\n+  size_t index_size = sizeof(u2);\n@@ -2511,1 +2558,1 @@\n-      __ mov(c_rarg1, zr); \/\/ NULL object reference\n+      __ mov(c_rarg1, zr); \/\/ null object reference\n@@ -2516,1 +2563,1 @@\n-    \/\/ c_rarg1: object pointer or NULL\n+    \/\/ c_rarg1: object pointer or null\n@@ -2777,1 +2824,1 @@\n-    \/\/ c_rarg1: object pointer set up above (NULL if static)\n+    \/\/ c_rarg1: object pointer set up above (null if static)\n@@ -2835,1 +2882,1 @@\n-    __ access_store_at(T_BYTE, IN_HEAP, field, r0, noreg, noreg);\n+    __ access_store_at(T_BYTE, IN_HEAP, field, r0, noreg, noreg, noreg);\n@@ -2851,1 +2898,1 @@\n-    __ access_store_at(T_BOOLEAN, IN_HEAP, field, r0, noreg, noreg);\n+    __ access_store_at(T_BOOLEAN, IN_HEAP, field, r0, noreg, noreg, noreg);\n@@ -2888,1 +2935,1 @@\n-    __ access_store_at(T_INT, IN_HEAP, field, r0, noreg, noreg);\n+    __ access_store_at(T_INT, IN_HEAP, field, r0, noreg, noreg, noreg);\n@@ -2904,1 +2951,1 @@\n-    __ access_store_at(T_CHAR, IN_HEAP, field, r0, noreg, noreg);\n+    __ access_store_at(T_CHAR, IN_HEAP, field, r0, noreg, noreg, noreg);\n@@ -2920,1 +2967,1 @@\n-    __ access_store_at(T_SHORT, IN_HEAP, field, r0, noreg, noreg);\n+    __ access_store_at(T_SHORT, IN_HEAP, field, r0, noreg, noreg, noreg);\n@@ -2936,1 +2983,1 @@\n-    __ access_store_at(T_LONG, IN_HEAP, field, r0, noreg, noreg);\n+    __ access_store_at(T_LONG, IN_HEAP, field, r0, noreg, noreg, noreg);\n@@ -2952,1 +2999,1 @@\n-    __ access_store_at(T_FLOAT, IN_HEAP, field, noreg \/* ftos *\/, noreg, noreg);\n+    __ access_store_at(T_FLOAT, IN_HEAP, field, noreg \/* ftos *\/, noreg, noreg, noreg);\n@@ -2970,1 +3017,1 @@\n-    __ access_store_at(T_DOUBLE, IN_HEAP, field, noreg \/* dtos *\/, noreg, noreg);\n+    __ access_store_at(T_DOUBLE, IN_HEAP, field, noreg \/* dtos *\/, noreg, noreg, noreg);\n@@ -3105,1 +3152,1 @@\n-    __ access_store_at(T_LONG, IN_HEAP, field, r0, noreg, noreg);\n+    __ access_store_at(T_LONG, IN_HEAP, field, r0, noreg, noreg, noreg);\n@@ -3108,1 +3155,1 @@\n-    __ access_store_at(T_INT, IN_HEAP, field, r0, noreg, noreg);\n+    __ access_store_at(T_INT, IN_HEAP, field, r0, noreg, noreg, noreg);\n@@ -3111,1 +3158,1 @@\n-    __ access_store_at(T_BOOLEAN, IN_HEAP, field, r0, noreg, noreg);\n+    __ access_store_at(T_BOOLEAN, IN_HEAP, field, r0, noreg, noreg, noreg);\n@@ -3114,1 +3161,1 @@\n-    __ access_store_at(T_BYTE, IN_HEAP, field, r0, noreg, noreg);\n+    __ access_store_at(T_BYTE, IN_HEAP, field, r0, noreg, noreg, noreg);\n@@ -3117,1 +3164,1 @@\n-    __ access_store_at(T_SHORT, IN_HEAP, field, r0, noreg, noreg);\n+    __ access_store_at(T_SHORT, IN_HEAP, field, r0, noreg, noreg, noreg);\n@@ -3120,1 +3167,1 @@\n-    __ access_store_at(T_CHAR, IN_HEAP, field, r0, noreg, noreg);\n+    __ access_store_at(T_CHAR, IN_HEAP, field, r0, noreg, noreg, noreg);\n@@ -3123,1 +3170,1 @@\n-    __ access_store_at(T_FLOAT, IN_HEAP, field, noreg \/* ftos *\/, noreg, noreg);\n+    __ access_store_at(T_FLOAT, IN_HEAP, field, noreg \/* ftos *\/, noreg, noreg, noreg);\n@@ -3126,1 +3173,1 @@\n-    __ access_store_at(T_DOUBLE, IN_HEAP, field, noreg \/* dtos *\/, noreg, noreg);\n+    __ access_store_at(T_DOUBLE, IN_HEAP, field, noreg \/* dtos *\/, noreg, noreg, noreg);\n@@ -3333,1 +3380,1 @@\n-  if (is_invokedynamic || is_invokehandle) {\n+  if (is_invokehandle) {\n@@ -3402,1 +3449,0 @@\n-  __ null_check(recv, oopDesc::klass_offset_in_bytes());\n@@ -3491,2 +3537,1 @@\n-  \/\/ Get receiver klass into r3 - also a null check\n-  __ null_check(r2, oopDesc::klass_offset_in_bytes());\n+  \/\/ Get receiver klass into r3\n@@ -3507,1 +3552,1 @@\n-  \/\/ Get receiver klass into r3 - also a null check\n+  \/\/ Get receiver klass into r3\n@@ -3509,1 +3554,0 @@\n-  __ null_check(r2, oopDesc::klass_offset_in_bytes());\n@@ -3607,1 +3651,1 @@\n-  prepare_invoke(byte_no, rmethod, r0);\n+  load_invokedynamic_entry(rmethod);\n@@ -3635,1 +3679,0 @@\n-  Label initialize_object; \/\/ including clearing the fields\n@@ -3668,5 +3711,0 @@\n-  \/\/  Else If inline contiguous allocations are enabled:\n-  \/\/    Try to allocate in eden.\n-  \/\/    If fails due to heap end, go to slow path.\n-  \/\/\n-  \/\/  If TLAB is enabled OR inline contiguous is enabled:\n@@ -3677,2 +3715,0 @@\n-  const bool allow_shared_alloc =\n-    Universe::heap()->supports_inline_contig_alloc();\n@@ -3686,14 +3722,0 @@\n-    } else {\n-      \/\/ initialize both the header and fields\n-      __ b(initialize_object);\n-    }\n-  } else {\n-    \/\/ Allocation in the shared Eden, if allowed.\n-    \/\/\n-    \/\/ r3: instance size in bytes\n-    if (allow_shared_alloc) {\n-      __ eden_allocate(r0, r3, 0, r10, slow_case);\n-  }\n-  \/\/ If UseTLAB or allow_shared_alloc are true, the object is created above and\n-  \/\/ there is an initialize need. Otherwise, skip and go to the slow path.\n-  if (UseTLAB || allow_shared_alloc) {\n@@ -3704,1 +3726,0 @@\n-    __ bind(initialize_object);\n@@ -3720,5 +3741,1 @@\n-    if (UseBiasedLocking) {\n-      __ ldr(rscratch1, Address(r4, Klass::prototype_header_offset()));\n-    } else {\n-      __ mov(rscratch1, (intptr_t)markWord::prototype().value());\n-    }\n+    __ mov(rscratch1, (intptr_t)markWord::prototype().value());\n@@ -3734,1 +3751,1 @@\n-           CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_object_alloc), r0);\n+           CAST_FROM_FN_PTR(address, static_cast<int (*)(oopDesc*)>(SharedRuntime::dtrace_object_alloc)), r0);\n@@ -3785,1 +3802,0 @@\n-  __ null_check(r0, arrayOopDesc::length_offset_in_bytes());\n@@ -3833,1 +3849,1 @@\n-  \/\/ Collect counts on whether this test sees NULLs a lot or not.\n+  \/\/ Collect counts on whether this test sees nulls a lot or not.\n@@ -3886,1 +3902,1 @@\n-  \/\/ Collect counts on whether this test sees NULLs a lot or not.\n+  \/\/ Collect counts on whether this test sees nulls a lot or not.\n@@ -3895,2 +3911,2 @@\n-  \/\/ r0 = 0: obj == NULL or  obj is not an instanceof the specified klass\n-  \/\/ r0 = 1: obj != NULL and obj is     an instanceof the specified klass\n+  \/\/ r0 = 0: obj == nullptr or  obj is not an instanceof the specified klass\n+  \/\/ r0 = 1: obj != nullptr and obj is     an instanceof the specified klass\n@@ -3951,1 +3967,1 @@\n-\/\/ [saved rbp    ] <--- rbp\n+\/\/ [saved rfp    ] <--- rfp\n@@ -3956,1 +3972,1 @@\n-  \/\/ check for NULL object\n+  \/\/ check for null object\n@@ -3968,1 +3984,1 @@\n-  __ mov(c_rarg1, zr); \/\/ points to free slot or NULL\n+  __ mov(c_rarg1, zr); \/\/ points to free slot or null\n@@ -3982,1 +3998,1 @@\n-    __ ldr(rscratch1, Address(c_rarg3, BasicObjectLock::obj_offset_in_bytes()));\n+    __ ldr(rscratch1, Address(c_rarg3, BasicObjectLock::obj_offset()));\n@@ -4006,0 +4022,6 @@\n+\n+    __ check_extended_sp();\n+    __ sub(sp, sp, entry_size);           \/\/ make room for the monitor\n+    __ mov(rscratch1, sp);\n+    __ str(rscratch1, Address(rfp, frame::interpreter_frame_extended_sp_offset * wordSize));\n+\n@@ -4012,2 +4034,0 @@\n-    __ sub(sp, sp, entry_size);           \/\/ make room for the monitor\n-\n@@ -4033,1 +4053,1 @@\n-  \/\/ The object has already been poped from the stack, so the\n+  \/\/ The object has already been popped from the stack, so the\n@@ -4038,1 +4058,1 @@\n-  __ str(r0, Address(c_rarg1, BasicObjectLock::obj_offset_in_bytes()));\n+  __ str(r0, Address(c_rarg1, BasicObjectLock::obj_offset()));\n@@ -4055,1 +4075,1 @@\n-  \/\/ check for NULL object\n+  \/\/ check for null object\n@@ -4077,1 +4097,1 @@\n-    __ ldr(rscratch1, Address(c_rarg1, BasicObjectLock::obj_offset_in_bytes()));\n+    __ ldr(rscratch1, Address(c_rarg1, BasicObjectLock::obj_offset()));\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":141,"deletions":121,"binary":false,"changes":262,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -38,1 +38,1 @@\n-#include \"runtime\/biasedLocking.hpp\"\n+#include \"runtime\/javaThread.hpp\"\n@@ -42,1 +42,0 @@\n-#include \"runtime\/thread.inline.hpp\"\n@@ -63,2 +62,1 @@\n-  Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n-  load_klass(obj, obj, tmp_load_klass);\n+  load_klass(obj, obj, rscratch1);\n@@ -185,1 +183,1 @@\n-      \/\/ begining of the ProfileData we intend to update to check its\n+      \/\/ beginning of the ProfileData we intend to update to check its\n@@ -194,1 +192,1 @@\n-      cmpw(Address(tmp, Method::intrinsic_id_offset_in_bytes()), static_cast<int>(vmIntrinsics::_compiledLambdaForm));\n+      cmpw(Address(tmp, Method::intrinsic_id_offset()), static_cast<int>(vmIntrinsics::_compiledLambdaForm));\n@@ -270,1 +268,1 @@\n-    cmpptr(Address(rbp, frame::interpreter_frame_last_sp_offset * wordSize), (int32_t)NULL_WORD);\n+    cmpptr(Address(rbp, frame::interpreter_frame_last_sp_offset * wordSize), NULL_WORD);\n@@ -273,1 +271,1 @@\n-         \" last_sp != NULL\");\n+         \" last_sp != null\");\n@@ -302,1 +300,1 @@\n-    cmpptr(Address(rbp, frame::interpreter_frame_last_sp_offset * wordSize), (int32_t)NULL_WORD);\n+    cmpptr(Address(rbp, frame::interpreter_frame_last_sp_offset * wordSize), NULL_WORD);\n@@ -305,1 +303,1 @@\n-         \" last_sp != NULL\");\n+         \" last_sp isn't null\");\n@@ -353,1 +351,1 @@\n-               movptr(oop_addr, (int32_t)NULL_WORD);\n+               movptr(oop_addr, NULL_WORD);\n@@ -367,2 +365,2 @@\n-  movl(tos_addr,  (int) ilgl);\n-  movl(val_addr,  (int32_t) NULL_WORD);\n+  movl(tos_addr, ilgl);\n+  movl(val_addr, NULL_WORD);\n@@ -390,2 +388,2 @@\n-  movl(tos_addr,  (int32_t) ilgl);\n-  movptr(val_addr,  NULL_WORD);\n+  movl(tos_addr, ilgl);\n+  movptr(val_addr, NULL_WORD);\n@@ -404,1 +402,1 @@\n-    jcc(Assembler::zero, L); \/\/ if (thread->jvmti_thread_state() == NULL) exit;\n+    jcc(Assembler::zero, L); \/\/ if (thread->jvmti_thread_state() == nullptr) exit;\n@@ -515,2 +513,2 @@\n-  movptr(result, Address(result, ConstantPool::cache_offset_in_bytes()));\n-  movptr(result, Address(result, ConstantPoolCache::resolved_references_offset_in_bytes()));\n+  movptr(result, Address(result, ConstantPool::cache_offset()));\n+  movptr(result, Address(result, ConstantPoolCache::resolved_references_offset()));\n@@ -531,1 +529,1 @@\n-  movptr(resolved_klasses, Address(cpool, ConstantPool::resolved_klasses_offset_in_bytes()));\n+  movptr(resolved_klasses, Address(cpool, ConstantPool::resolved_klasses_offset()));\n@@ -847,1 +845,1 @@\n-    cmpptr(rcx, (int32_t)min_frame_size);\n+    cmpptr(rcx, min_frame_size);\n@@ -884,1 +882,1 @@\n-    jump(dispatch_addr);\n+    jump(dispatch_addr, noreg);\n@@ -890,1 +888,1 @@\n-    jump(dispatch_addr);\n+    jump(dispatch_addr, noreg);\n@@ -971,1 +969,1 @@\n-\/\/ Unlock any Java monitors from syncronized blocks.\n+\/\/ Unlock any Java monitors from synchronized blocks.\n@@ -1007,1 +1005,1 @@\n-  set_last_Java_frame(rthread, noreg, rbp, (address)pc());\n+  set_last_Java_frame(rthread, noreg, rbp, (address)pc(), rscratch1);\n@@ -1043,1 +1041,1 @@\n-  movptr(rax, Address(robj, BasicObjectLock::obj_offset_in_bytes()));\n+  movptr(rax, Address(robj, BasicObjectLock::obj_offset()));\n@@ -1126,1 +1124,1 @@\n-    cmpptr(Address(rmon, BasicObjectLock::obj_offset_in_bytes()), (int32_t) NULL);\n+    cmpptr(Address(rmon, BasicObjectLock::obj_offset()), NULL_WORD);\n@@ -1172,0 +1170,1 @@\n+  pop_cont_fastpath();\n@@ -1201,1 +1200,1 @@\n-  if (UseHeavyMonitors) {\n+  if (LockingMode == LM_MONITOR) {\n@@ -1206,1 +1205,1 @@\n-    Label done;\n+    Label count_locking, done, slow_case;\n@@ -1209,2 +1208,1 @@\n-    const Register tmp_reg = rbx; \/\/ Will be passed to biased_locking_enter to avoid a\n-                                  \/\/ problematic case where tmp_reg = no_reg.\n+    const Register tmp_reg = rbx;\n@@ -1212,1 +1210,1 @@\n-    const Register rklass_decode_tmp = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n+    const Register rklass_decode_tmp = rscratch1;\n@@ -1214,2 +1212,2 @@\n-    const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n-    const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();\n+    const int obj_offset = in_bytes(BasicObjectLock::obj_offset());\n+    const int lock_offset = in_bytes(BasicObjectLock::lock_offset());\n@@ -1219,2 +1217,0 @@\n-    Label slow_case;\n-\n@@ -1231,15 +1227,62 @@\n-    if (UseBiasedLocking) {\n-      biased_locking_enter(lock_reg, obj_reg, swap_reg, tmp_reg, rklass_decode_tmp, false, done, &slow_case);\n-    }\n-\n-    \/\/ Load immediate 1 into swap_reg %rax\n-    movl(swap_reg, (int32_t)1);\n-\n-    \/\/ Load (object->mark() | 1) into swap_reg %rax\n-    orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-\n-    \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-    movptr(Address(lock_reg, mark_offset), swap_reg);\n-\n-    assert(lock_offset == 0,\n-           \"displaced header must be first word in BasicObjectLock\");\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+#ifdef _LP64\n+      const Register thread = r15_thread;\n+#else\n+      const Register thread = lock_reg;\n+      get_thread(thread);\n+#endif\n+      \/\/ Load object header, prepare for CAS from unlocked to locked.\n+      movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      fast_lock_impl(obj_reg, swap_reg, thread, tmp_reg, slow_case);\n+    } else if (LockingMode == LM_LEGACY) {\n+      \/\/ Load immediate 1 into swap_reg %rax\n+      movl(swap_reg, 1);\n+\n+      \/\/ Load (object->mark() | 1) into swap_reg %rax\n+      orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+\n+      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+      movptr(Address(lock_reg, mark_offset), swap_reg);\n+\n+      assert(lock_offset == 0,\n+             \"displaced header must be first word in BasicObjectLock\");\n+\n+      lock();\n+      cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      jcc(Assembler::zero, count_locking);\n+\n+      const int zero_bits = LP64_ONLY(7) NOT_LP64(3);\n+\n+      \/\/ Fast check for recursive lock.\n+      \/\/\n+      \/\/ Can apply the optimization only if this is a stack lock\n+      \/\/ allocated in this thread. For efficiency, we can focus on\n+      \/\/ recently allocated stack locks (instead of reading the stack\n+      \/\/ base and checking whether 'mark' points inside the current\n+      \/\/ thread stack):\n+      \/\/  1) (mark & zero_bits) == 0, and\n+      \/\/  2) rsp <= mark < mark + os::pagesize()\n+      \/\/\n+      \/\/ Warning: rsp + os::pagesize can overflow the stack base. We must\n+      \/\/ neither apply the optimization for an inflated lock allocated\n+      \/\/ just above the thread stack (this is why condition 1 matters)\n+      \/\/ nor apply the optimization if the stack lock is inside the stack\n+      \/\/ of another thread. The latter is avoided even in case of overflow\n+      \/\/ because we have guard pages at the end of all stacks. Hence, if\n+      \/\/ we go over the stack base and hit the stack of another thread,\n+      \/\/ this should not be in a writeable area that could contain a\n+      \/\/ stack lock allocated by that thread. As a consequence, a stack\n+      \/\/ lock less than page size away from rsp is guaranteed to be\n+      \/\/ owned by the current thread.\n+      \/\/\n+      \/\/ These 3 tests can be done by evaluating the following\n+      \/\/ expression: ((mark - rsp) & (zero_bits - os::vm_page_size())),\n+      \/\/ assuming both stack pointer and pagesize have their\n+      \/\/ least significant bits clear.\n+      \/\/ NOTE: the mark is in swap_reg %rax as the result of cmpxchg\n+      subptr(swap_reg, rsp);\n+      andptr(swap_reg, zero_bits - (int)os::vm_page_size());\n+\n+      \/\/ Save the test result, for recursive case, the result is zero\n+      movptr(Address(lock_reg, mark_offset), swap_reg);\n+      jcc(Assembler::notZero, slow_case);\n@@ -1247,46 +1290,1 @@\n-    lock();\n-    cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    if (PrintBiasedLockingStatistics) {\n-      cond_inc32(Assembler::zero,\n-                 ExternalAddress((address) BiasedLocking::fast_path_entry_count_addr()));\n-    }\n-    jcc(Assembler::zero, done);\n-\n-    const int zero_bits = LP64_ONLY(7) NOT_LP64(3);\n-\n-    \/\/ Fast check for recursive lock.\n-    \/\/\n-    \/\/ Can apply the optimization only if this is a stack lock\n-    \/\/ allocated in this thread. For efficiency, we can focus on\n-    \/\/ recently allocated stack locks (instead of reading the stack\n-    \/\/ base and checking whether 'mark' points inside the current\n-    \/\/ thread stack):\n-    \/\/  1) (mark & zero_bits) == 0, and\n-    \/\/  2) rsp <= mark < mark + os::pagesize()\n-    \/\/\n-    \/\/ Warning: rsp + os::pagesize can overflow the stack base. We must\n-    \/\/ neither apply the optimization for an inflated lock allocated\n-    \/\/ just above the thread stack (this is why condition 1 matters)\n-    \/\/ nor apply the optimization if the stack lock is inside the stack\n-    \/\/ of another thread. The latter is avoided even in case of overflow\n-    \/\/ because we have guard pages at the end of all stacks. Hence, if\n-    \/\/ we go over the stack base and hit the stack of another thread,\n-    \/\/ this should not be in a writeable area that could contain a\n-    \/\/ stack lock allocated by that thread. As a consequence, a stack\n-    \/\/ lock less than page size away from rsp is guaranteed to be\n-    \/\/ owned by the current thread.\n-    \/\/\n-    \/\/ These 3 tests can be done by evaluating the following\n-    \/\/ expression: ((mark - rsp) & (zero_bits - os::vm_page_size())),\n-    \/\/ assuming both stack pointer and pagesize have their\n-    \/\/ least significant bits clear.\n-    \/\/ NOTE: the mark is in swap_reg %rax as the result of cmpxchg\n-    subptr(swap_reg, rsp);\n-    andptr(swap_reg, zero_bits - os::vm_page_size());\n-\n-    \/\/ Save the test result, for recursive case, the result is zero\n-    movptr(Address(lock_reg, mark_offset), swap_reg);\n-\n-    if (PrintBiasedLockingStatistics) {\n-      cond_inc32(Assembler::zero,\n-                 ExternalAddress((address) BiasedLocking::fast_path_entry_count_addr()));\n+      bind(count_locking);\n@@ -1294,1 +1292,2 @@\n-    jcc(Assembler::zero, done);\n+    inc_held_monitor_count();\n+    jmp(done);\n@@ -1299,4 +1298,9 @@\n-    call_VM(noreg,\n-            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n-            lock_reg);\n-\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      call_VM(noreg,\n+              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter_obj),\n+              obj_reg);\n+    } else {\n+      call_VM(noreg,\n+              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n+              lock_reg);\n+    }\n@@ -1341,1 +1345,1 @@\n-  if (UseHeavyMonitors) {\n+  if (LockingMode == LM_MONITOR) {\n@@ -1344,1 +1348,1 @@\n-    Label done;\n+    Label count_locking, done, slow_case;\n@@ -1352,3 +1356,5 @@\n-    \/\/ Convert from BasicObjectLock structure to object and BasicLock\n-    \/\/ structure Store the BasicLock address into %rax\n-    lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n+    if (LockingMode != LM_LIGHTWEIGHT) {\n+      \/\/ Convert from BasicObjectLock structure to object and BasicLock\n+      \/\/ structure Store the BasicLock address into %rax\n+      lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset()));\n+    }\n@@ -1357,1 +1363,1 @@\n-    movptr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+    movptr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset()));\n@@ -1360,1 +1366,1 @@\n-    movptr(Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()), (int32_t)NULL_WORD);\n+    movptr(Address(lock_reg, BasicObjectLock::obj_offset()), NULL_WORD);\n@@ -1362,20 +1368,33 @@\n-    if (UseBiasedLocking) {\n-      biased_locking_exit(obj_reg, header_reg, done);\n-    }\n-\n-    \/\/ Load the old header from BasicLock structure\n-    movptr(header_reg, Address(swap_reg,\n-                               BasicLock::displaced_header_offset_in_bytes()));\n-\n-    \/\/ Test for recursion\n-    testptr(header_reg, header_reg);\n-\n-    \/\/ zero for recursive case\n-    jcc(Assembler::zero, done);\n-\n-    \/\/ Atomic swap back the old header\n-    lock();\n-    cmpxchgptr(header_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-\n-    \/\/ zero for simple unlock of a stack-lock case\n-    jcc(Assembler::zero, done);\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+#ifdef _LP64\n+      const Register thread = r15_thread;\n+#else\n+      const Register thread = header_reg;\n+      get_thread(thread);\n+#endif\n+      \/\/ Handle unstructured locking.\n+      Register tmp = swap_reg;\n+      movl(tmp, Address(thread, JavaThread::lock_stack_top_offset()));\n+      cmpptr(obj_reg, Address(thread, tmp, Address::times_1,  -oopSize));\n+      jcc(Assembler::notEqual, slow_case);\n+      \/\/ Try to swing header from locked to unlocked.\n+      movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n+      fast_unlock_impl(obj_reg, swap_reg, header_reg, slow_case);\n+    } else if (LockingMode == LM_LEGACY) {\n+      \/\/ Load the old header from BasicLock structure\n+      movptr(header_reg, Address(swap_reg,\n+                                 BasicLock::displaced_header_offset_in_bytes()));\n+\n+      \/\/ Test for recursion\n+      testptr(header_reg, header_reg);\n+\n+      \/\/ zero for recursive case\n+      jcc(Assembler::zero, count_locking);\n+\n+      \/\/ Atomic swap back the old header\n+      lock();\n+      cmpxchgptr(header_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+\n+      \/\/ zero for simple unlock of a stack-lock case\n+      jcc(Assembler::notZero, slow_case);\n@@ -1383,0 +1402,4 @@\n+      bind(count_locking);\n+    }\n+    dec_held_monitor_count();\n+    jmp(done);\n@@ -1384,0 +1407,1 @@\n+    bind(slow_case);\n@@ -1385,1 +1409,1 @@\n-    movptr(Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()), obj_reg); \/\/ restore obj\n+    movptr(Address(lock_reg, BasicObjectLock::obj_offset()), obj_reg); \/\/ restore obj\n@@ -1411,1 +1435,1 @@\n-  \/\/ Test MDO to avoid the call if it is NULL.\n+  \/\/ Test MDO to avoid the call if it is null.\n@@ -1490,1 +1514,1 @@\n-    addptr(data, (int32_t) -DataLayout::counter_increment);\n+    addptr(data, -DataLayout::counter_increment);\n@@ -1494,1 +1518,1 @@\n-    addptr(data, (int32_t) DataLayout::counter_increment);\n+    addptr(data, DataLayout::counter_increment);\n@@ -1502,1 +1526,1 @@\n-    sbbptr(data, (int32_t)0);\n+    sbbptr(data, 0);\n@@ -1794,1 +1818,1 @@\n-  \/\/ observed the item[start_row] is NULL.\n+  \/\/ observed the item[start_row] is null.\n@@ -1810,1 +1834,1 @@\n-\/\/   if (row[0].rec != NULL) {\n+\/\/   if (row[0].rec != nullptr) {\n@@ -1813,1 +1837,1 @@\n-\/\/     if (row[1].rec != NULL) {\n+\/\/     if (row[1].rec != nullptr) {\n@@ -1816,1 +1840,1 @@\n-\/\/       if (row[2].rec != NULL) { count.incr(); goto done; } \/\/ overflow\n+\/\/       if (row[2].rec != nullptr) { count.incr(); goto done; } \/\/ overflow\n@@ -2012,9 +2036,8 @@\n-\/\/ Jump if ((*counter_addr += increment) & mask) satisfies the condition.\n-void InterpreterMacroAssembler::increment_mask_and_jump(Address counter_addr,\n-                                                        int increment, Address mask,\n-                                                        Register scratch, bool preloaded,\n-                                                        Condition cond, Label* where) {\n-  if (!preloaded) {\n-    movl(scratch, counter_addr);\n-  }\n-  incrementl(scratch, increment);\n+\/\/ Jump if ((*counter_addr += increment) & mask) == 0\n+void InterpreterMacroAssembler::increment_mask_and_jump(Address counter_addr, Address mask,\n+                                                        Register scratch, Label* where) {\n+  \/\/ This update is actually not atomic and can lose a number of updates\n+  \/\/ under heavy contention, but the alternative of using the (contended)\n+  \/\/ atomic update here penalizes profiling paths too much.\n+  movl(scratch, counter_addr);\n+  incrementl(scratch, InvocationCounter::count_increment);\n@@ -2023,2 +2046,2 @@\n-  if (where != NULL) {\n-    jcc(cond, *where);\n+  if (where != nullptr) {\n+    jcc(Assembler::zero, *where);\n@@ -2046,1 +2069,1 @@\n-    SkipIfEqual skip(this, &DTraceMethodProbes, false);\n+    SkipIfEqual skip(this, &DTraceMethodProbes, false, rscratch1);\n@@ -2102,1 +2125,1 @@\n-    SkipIfEqual skip(this, &DTraceMethodProbes, false);\n+    SkipIfEqual skip(this, &DTraceMethodProbes, false, rscratch1);\n@@ -2111,0 +2134,14 @@\n+\n+void InterpreterMacroAssembler::load_resolved_indy_entry(Register cache, Register index) {\n+  \/\/ Get index out of bytecode pointer, get_cache_entry_pointer_at_bcp\n+  get_cache_index_at_bcp(index, 1, sizeof(u4));\n+  \/\/ Get address of invokedynamic array\n+  movptr(cache, Address(rbp, frame::interpreter_frame_cache_offset * wordSize));\n+  movptr(cache, Address(cache, in_bytes(ConstantPoolCache::invokedynamic_entries_offset())));\n+  if (is_power_of_2(sizeof(ResolvedIndyEntry))) {\n+    shll(index, log2i_exact(sizeof(ResolvedIndyEntry))); \/\/ Scale index by power of 2\n+  } else {\n+    imull(index, index, sizeof(ResolvedIndyEntry)); \/\/ Scale the index to be the entry index * sizeof(ResolvedInvokeDynamicInfo)\n+  }\n+  lea(cache, Address(cache, index, Address::times_1, Array<ResolvedIndyEntry>::base_offset_in_bytes()));\n+}\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":188,"deletions":151,"binary":false,"changes":339,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,0 +31,1 @@\n+#include \"code\/compiledIC.hpp\"\n@@ -46,0 +47,1 @@\n+#include \"oops\/method.inline.hpp\"\n@@ -47,0 +49,3 @@\n+#include \"runtime\/continuation.hpp\"\n+#include \"runtime\/continuationEntry.inline.hpp\"\n+#include \"runtime\/globals.hpp\"\n@@ -153,2 +158,2 @@\n-  static OopMap* save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words, bool save_vectors);\n-  static void restore_live_registers(MacroAssembler* masm, bool restore_vectors = false);\n+  static OopMap* save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words, bool save_wide_vectors);\n+  static void restore_live_registers(MacroAssembler* masm, bool restore_wide_vectors = false);\n@@ -171,1 +176,1 @@\n-OopMap* RegisterSaver::save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words, bool save_vectors) {\n+OopMap* RegisterSaver::save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words, bool save_wide_vectors) {\n@@ -173,4 +178,1 @@\n-  int num_xmm_regs = XMMRegisterImpl::number_of_registers;\n-  if (UseAVX < 3) {\n-    num_xmm_regs = num_xmm_regs\/2;\n-  }\n+  int num_xmm_regs = XMMRegister::available_xmm_registers();\n@@ -178,2 +180,2 @@\n-  if (save_vectors && UseAVX == 0) {\n-    save_vectors = false; \/\/ vectors larger than 16 byte long are supported only with AVX\n+  if (save_wide_vectors && UseAVX == 0) {\n+    save_wide_vectors = false; \/\/ vectors larger than 16 byte long are supported only with AVX\n@@ -181,1 +183,1 @@\n-  assert(!save_vectors || MaxVectorSize <= 64, \"Only up to 64 byte long vectors are supported\");\n+  assert(!save_wide_vectors || MaxVectorSize <= 64, \"Only up to 64 byte long vectors are supported\");\n@@ -183,1 +185,1 @@\n-  save_vectors = false; \/\/ vectors are generated only by C2 and JVMCI\n+  save_wide_vectors = false; \/\/ vectors are generated only by C2 and JVMCI\n@@ -204,1 +206,1 @@\n-  if (save_vectors) {\n+  if (save_wide_vectors) {\n@@ -226,1 +228,1 @@\n-      for(int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+      for(int n = 0; n < KRegister::number_of_registers; n++) {\n@@ -233,1 +235,1 @@\n-      \/\/ Save upper bank of ZMM registers(16..31) for double\/float usage\n+      \/\/ Save upper bank of XMM registers(16..31) for scalar or 16-byte vector usage\n@@ -236,0 +238,1 @@\n+      int vector_len = VM_Version::supports_avx512vl() ?  Assembler::AVX_128bit : Assembler::AVX_512bit;\n@@ -237,1 +240,1 @@\n-        __ movsd(Address(rsp, base_addr+(off++*64)), as_XMMRegister(n));\n+        __ evmovdqul(Address(rsp, base_addr+(off++*64)), as_XMMRegister(n), vector_len);\n@@ -242,1 +245,1 @@\n-      for(int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+      for(int n = 0; n < KRegister::number_of_registers; n++) {\n@@ -301,1 +304,1 @@\n-  if (save_vectors) {\n+  if (save_wide_vectors) {\n@@ -364,5 +367,2 @@\n-void RegisterSaver::restore_live_registers(MacroAssembler* masm, bool restore_vectors) {\n-  int num_xmm_regs = XMMRegisterImpl::number_of_registers;\n-  if (UseAVX < 3) {\n-    num_xmm_regs = num_xmm_regs\/2;\n-  }\n+void RegisterSaver::restore_live_registers(MacroAssembler* masm, bool restore_wide_vectors) {\n+  int num_xmm_regs = XMMRegister::available_xmm_registers();\n@@ -375,1 +375,1 @@\n-  if (restore_vectors) {\n+  if (restore_wide_vectors) {\n@@ -380,1 +380,1 @@\n-  assert(!restore_vectors, \"vectors are generated only by C2\");\n+  assert(!restore_wide_vectors, \"vectors are generated only by C2\");\n@@ -386,1 +386,1 @@\n-  if (restore_vectors) {\n+  if (restore_wide_vectors) {\n@@ -408,1 +408,1 @@\n-      for (int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+      for (int n = 0; n < KRegister::number_of_registers; n++) {\n@@ -415,1 +415,1 @@\n-      \/\/ Restore upper bank of ZMM registers(16..31) for double\/float usage\n+      \/\/ Restore upper bank of XMM registers(16..31) for scalar or 16-byte vector usage\n@@ -418,0 +418,1 @@\n+      int vector_len = VM_Version::supports_avx512vl() ?  Assembler::AVX_128bit : Assembler::AVX_512bit;\n@@ -419,1 +420,1 @@\n-        __ movsd(as_XMMRegister(n), Address(rsp, base_addr+(off++*64)));\n+        __ evmovdqul(as_XMMRegister(n), Address(rsp, base_addr+(off++*64)), vector_len);\n@@ -424,1 +425,1 @@\n-      for (int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+      for (int n = 0; n < KRegister::number_of_registers; n++) {\n@@ -468,2 +469,2 @@\n-\/\/ and VMRegImpl::stack0+1 refers to the memory word 4-byes higher.  Register\n-\/\/ up to RegisterImpl::number_of_registers) are the 64-bit\n+\/\/ and VMRegImpl::stack0+1 refers to the memory word 4-byes higher.\n+\/\/ Register up to Register::number_of_registers are the 64-bit\n@@ -562,1 +563,1 @@\n-  __ cmpptr(Address(rbx, in_bytes(Method::code_offset())), (int32_t)NULL_WORD);\n+  __ cmpptr(Address(rbx, in_bytes(Method::code_offset())), NULL_WORD);\n@@ -618,3 +619,3 @@\n-  \/\/ Interpreter::stackElementSize is the space we need. Plus 1 because\n-  \/\/ we also account for the return address location since\n-  \/\/ we store it first rather than hold it in rax across all the shuffling\n+  \/\/ Interpreter::stackElementSize is the space we need.\n+\n+  assert(total_args_passed >= 0, \"total_args_passed is %d\", total_args_passed);\n@@ -622,1 +623,1 @@\n-  int extraspace = (total_args_passed * Interpreter::stackElementSize) + wordSize;\n+  int extraspace = (total_args_passed * Interpreter::stackElementSize);\n@@ -625,0 +626,2 @@\n+  \/\/ This is not currently needed or enforced by the interpreter, but\n+  \/\/ we might as well conform to the ABI.\n@@ -627,4 +630,10 @@\n-  \/\/ Get return address\n-  __ pop(rax);\n-\n-  __ mov(r13, rsp);\n+  __ lea(r13, Address(rsp, wordSize));\n+\n+#ifdef ASSERT\n+  __ check_stack_alignment(r13, \"sender stack not aligned\");\n+#endif\n+  if (extraspace > 0) {\n+    \/\/ Pop the return address\n+    __ pop(rax);\n+\n+    __ subptr(rsp, extraspace);\n@@ -633,1 +642,2 @@\n-  __ subptr(rsp, extraspace);\n+    \/\/ Push the return address\n+    __ push(rax);\n@@ -635,2 +645,8 @@\n-  \/\/ Store the return address in the expected location\n-  __ movptr(Address(rsp, 0), rax);\n+    \/\/ Account for the return address location since we store it first rather\n+    \/\/ than hold it in a register across all the shuffling\n+    extraspace += wordSize;\n+  }\n+\n+#ifdef ASSERT\n+  __ check_stack_alignment(rsp, \"callee stack not aligned\", wordSize, rax);\n+#endif\n@@ -782,4 +798,1 @@\n-  \/\/ Pick up the return address\n-  __ movptr(rax, Address(rsp, 0));\n-\n-      (Interpreter::code() != NULL || StubRoutines::code1() != NULL)) {\n+      (Interpreter::code() != nullptr || StubRoutines::final_stubs_code() != nullptr)) {\n@@ -792,0 +805,2 @@\n+    \/\/ Pick up the return address\n+    __ movptr(rax, Address(rsp, 0));\n@@ -793,1 +808,1 @@\n-    if (Interpreter::code() != NULL)\n+    if (Interpreter::code() != nullptr) {\n@@ -795,1 +810,2 @@\n-                  Interpreter::code()->code_start(), Interpreter::code()->code_end(),\n+                  Interpreter::code()->code_start(),\n+                  Interpreter::code()->code_end(),\n@@ -797,1 +813,2 @@\n-    if (StubRoutines::code1() != NULL)\n+    }\n+    if (StubRoutines::initial_stubs_code() != nullptr) {\n@@ -799,1 +816,2 @@\n-                  StubRoutines::code1()->code_begin(), StubRoutines::code1()->code_end(),\n+                  StubRoutines::initial_stubs_code()->code_begin(),\n+                  StubRoutines::initial_stubs_code()->code_end(),\n@@ -801,1 +819,2 @@\n-    if (StubRoutines::code2() != NULL)\n+    }\n+    if (StubRoutines::final_stubs_code() != nullptr) {\n@@ -803,1 +822,2 @@\n-                  StubRoutines::code2()->code_begin(), StubRoutines::code2()->code_end(),\n+                  StubRoutines::final_stubs_code()->code_begin(),\n+                  StubRoutines::final_stubs_code()->code_end(),\n@@ -805,0 +825,1 @@\n+    }\n@@ -816,3 +837,6 @@\n-  \/\/ Cut-out for having no stack args.  Since up to 2 int\/oop args are passed\n-  \/\/ in registers, we will occasionally have no stack args.\n-  int comp_words_on_stack = 0;\n+  \/\/ Pick up the return address\n+  __ pop(rax);\n+\n+  \/\/ Convert 4-byte c2 stack slots to words.\n+  int comp_words_on_stack = align_up(comp_args_on_stack*VMRegImpl::stack_slot_size, wordSize)>>LogBytesPerWord;\n+\n@@ -820,8 +844,0 @@\n-    \/\/ Sig words on the stack are greater-than VMRegImpl::stack0.  Those in\n-    \/\/ registers are below.  By subtracting stack0, we either get a negative\n-    \/\/ number (all values in registers) or the maximum stack slot accessed.\n-\n-    \/\/ Convert 4-byte c2 stack slots to words.\n-    comp_words_on_stack = align_up(comp_args_on_stack*VMRegImpl::stack_slot_size, wordSize)>>LogBytesPerWord;\n-    \/\/ Round up to miminum stack alignment, in wordSize\n-    comp_words_on_stack = align_up(comp_words_on_stack, 2);\n@@ -831,1 +847,0 @@\n-\n@@ -940,0 +955,2 @@\n+  __ push_cont_fastpath(); \/\/ Set JavaThread::_cont_fastpath to the sp of the oldest interpreted frame we know about\n+\n@@ -953,1 +970,1 @@\n-  \/\/ only needed becaus eof c2 resolve stubs return Method* as a result in\n+  \/\/ only needed because eof c2 resolve stubs return Method* as a result in\n@@ -977,1 +994,1 @@\n-  \/\/ compiled code, which relys solely on SP and not RBP, get sick).\n+  \/\/ compiled code, which relies solely on SP and not RBP, get sick).\n@@ -998,1 +1015,1 @@\n-    __ cmpptr(Address(rbx, in_bytes(Method::code_offset())), (int32_t)NULL_WORD);\n+    __ cmpptr(Address(rbx, in_bytes(Method::code_offset())), NULL_WORD);\n@@ -1006,1 +1023,1 @@\n-  address c2i_no_clinit_check_entry = NULL;\n+  address c2i_no_clinit_check_entry = nullptr;\n@@ -1012,1 +1029,1 @@\n-      Register flags  = rscratch1;\n+      Register flags = rscratch1;\n@@ -1033,1 +1050,0 @@\n-  __ flush();\n@@ -1041,1 +1057,1 @@\n-  assert(regs2 == NULL, \"not needed on x86\");\n+  assert(regs2 == nullptr, \"not needed on x86\");\n@@ -1233,214 +1249,0 @@\n-\/\/ Unpack an array argument into a pointer to the body and the length\n-\/\/ if the array is non-null, otherwise pass 0 for both.\n-static void unpack_array_argument(MacroAssembler* masm, VMRegPair reg, BasicType in_elem_type, VMRegPair body_arg, VMRegPair length_arg) {\n-  Register tmp_reg = rax;\n-  assert(!body_arg.first()->is_Register() || body_arg.first()->as_Register() != tmp_reg,\n-         \"possible collision\");\n-  assert(!length_arg.first()->is_Register() || length_arg.first()->as_Register() != tmp_reg,\n-         \"possible collision\");\n-\n-  __ block_comment(\"unpack_array_argument {\");\n-\n-  \/\/ Pass the length, ptr pair\n-  Label is_null, done;\n-  VMRegPair tmp;\n-  tmp.set_ptr(tmp_reg->as_VMReg());\n-  if (reg.first()->is_stack()) {\n-    \/\/ Load the arg up from the stack\n-    __ move_ptr(reg, tmp);\n-    reg = tmp;\n-  }\n-  __ testptr(reg.first()->as_Register(), reg.first()->as_Register());\n-  __ jccb(Assembler::equal, is_null);\n-  __ lea(tmp_reg, Address(reg.first()->as_Register(), arrayOopDesc::base_offset_in_bytes(in_elem_type)));\n-  __ move_ptr(tmp, body_arg);\n-  \/\/ load the length relative to the body.\n-  __ movl(tmp_reg, Address(tmp_reg, arrayOopDesc::length_offset_in_bytes() -\n-                           arrayOopDesc::base_offset_in_bytes(in_elem_type)));\n-  __ move32_64(tmp, length_arg);\n-  __ jmpb(done);\n-  __ bind(is_null);\n-  \/\/ Pass zeros\n-  __ xorptr(tmp_reg, tmp_reg);\n-  __ move_ptr(tmp, body_arg);\n-  __ move32_64(tmp, length_arg);\n-  __ bind(done);\n-\n-  __ block_comment(\"} unpack_array_argument\");\n-}\n-\n-\n-\/\/ Different signatures may require very different orders for the move\n-\/\/ to avoid clobbering other arguments.  There's no simple way to\n-\/\/ order them safely.  Compute a safe order for issuing stores and\n-\/\/ break any cycles in those stores.  This code is fairly general but\n-\/\/ it's not necessary on the other platforms so we keep it in the\n-\/\/ platform dependent code instead of moving it into a shared file.\n-\/\/ (See bugs 7013347 & 7145024.)\n-\/\/ Note that this code is specific to LP64.\n-class ComputeMoveOrder: public StackObj {\n-  class MoveOperation: public ResourceObj {\n-    friend class ComputeMoveOrder;\n-   private:\n-    VMRegPair        _src;\n-    VMRegPair        _dst;\n-    int              _src_index;\n-    int              _dst_index;\n-    bool             _processed;\n-    MoveOperation*  _next;\n-    MoveOperation*  _prev;\n-\n-    static int get_id(VMRegPair r) {\n-      return r.first()->value();\n-    }\n-\n-   public:\n-    MoveOperation(int src_index, VMRegPair src, int dst_index, VMRegPair dst):\n-      _src(src)\n-    , _dst(dst)\n-    , _src_index(src_index)\n-    , _dst_index(dst_index)\n-    , _processed(false)\n-    , _next(NULL)\n-    , _prev(NULL) {\n-    }\n-\n-    VMRegPair src() const              { return _src; }\n-    int src_id() const                 { return get_id(src()); }\n-    int src_index() const              { return _src_index; }\n-    VMRegPair dst() const              { return _dst; }\n-    void set_dst(int i, VMRegPair dst) { _dst_index = i, _dst = dst; }\n-    int dst_index() const              { return _dst_index; }\n-    int dst_id() const                 { return get_id(dst()); }\n-    MoveOperation* next() const       { return _next; }\n-    MoveOperation* prev() const       { return _prev; }\n-    void set_processed()               { _processed = true; }\n-    bool is_processed() const          { return _processed; }\n-\n-    \/\/ insert\n-    void break_cycle(VMRegPair temp_register) {\n-      \/\/ create a new store following the last store\n-      \/\/ to move from the temp_register to the original\n-      MoveOperation* new_store = new MoveOperation(-1, temp_register, dst_index(), dst());\n-\n-      \/\/ break the cycle of links and insert new_store at the end\n-      \/\/ break the reverse link.\n-      MoveOperation* p = prev();\n-      assert(p->next() == this, \"must be\");\n-      _prev = NULL;\n-      p->_next = new_store;\n-      new_store->_prev = p;\n-\n-      \/\/ change the original store to save it's value in the temp.\n-      set_dst(-1, temp_register);\n-    }\n-\n-    void link(GrowableArray<MoveOperation*>& killer) {\n-      \/\/ link this store in front the store that it depends on\n-      MoveOperation* n = killer.at_grow(src_id(), NULL);\n-      if (n != NULL) {\n-        assert(_next == NULL && n->_prev == NULL, \"shouldn't have been set yet\");\n-        _next = n;\n-        n->_prev = this;\n-      }\n-    }\n-  };\n-\n- private:\n-  GrowableArray<MoveOperation*> edges;\n-\n- public:\n-  ComputeMoveOrder(int total_in_args, const VMRegPair* in_regs, int total_c_args, VMRegPair* out_regs,\n-                  const BasicType* in_sig_bt, GrowableArray<int>& arg_order, VMRegPair tmp_vmreg) {\n-    \/\/ Move operations where the dest is the stack can all be\n-    \/\/ scheduled first since they can't interfere with the other moves.\n-    for (int i = total_in_args - 1, c_arg = total_c_args - 1; i >= 0; i--, c_arg--) {\n-      if (in_sig_bt[i] == T_ARRAY) {\n-        c_arg--;\n-        if (out_regs[c_arg].first()->is_stack() &&\n-            out_regs[c_arg + 1].first()->is_stack()) {\n-          arg_order.push(i);\n-          arg_order.push(c_arg);\n-        } else {\n-          if (out_regs[c_arg].first()->is_stack() ||\n-              in_regs[i].first() == out_regs[c_arg].first()) {\n-            add_edge(i, in_regs[i].first(), c_arg, out_regs[c_arg + 1]);\n-          } else {\n-            add_edge(i, in_regs[i].first(), c_arg, out_regs[c_arg]);\n-          }\n-        }\n-      } else if (in_sig_bt[i] == T_VOID) {\n-        arg_order.push(i);\n-        arg_order.push(c_arg);\n-      } else {\n-        if (out_regs[c_arg].first()->is_stack() ||\n-            in_regs[i].first() == out_regs[c_arg].first()) {\n-          arg_order.push(i);\n-          arg_order.push(c_arg);\n-        } else {\n-          add_edge(i, in_regs[i].first(), c_arg, out_regs[c_arg]);\n-        }\n-      }\n-    }\n-    \/\/ Break any cycles in the register moves and emit the in the\n-    \/\/ proper order.\n-    GrowableArray<MoveOperation*>* stores = get_store_order(tmp_vmreg);\n-    for (int i = 0; i < stores->length(); i++) {\n-      arg_order.push(stores->at(i)->src_index());\n-      arg_order.push(stores->at(i)->dst_index());\n-    }\n- }\n-\n-  \/\/ Collected all the move operations\n-  void add_edge(int src_index, VMRegPair src, int dst_index, VMRegPair dst) {\n-    if (src.first() == dst.first()) return;\n-    edges.append(new MoveOperation(src_index, src, dst_index, dst));\n-  }\n-\n-  \/\/ Walk the edges breaking cycles between moves.  The result list\n-  \/\/ can be walked in order to produce the proper set of loads\n-  GrowableArray<MoveOperation*>* get_store_order(VMRegPair temp_register) {\n-    \/\/ Record which moves kill which values\n-    GrowableArray<MoveOperation*> killer;\n-    for (int i = 0; i < edges.length(); i++) {\n-      MoveOperation* s = edges.at(i);\n-      assert(killer.at_grow(s->dst_id(), NULL) == NULL, \"only one killer\");\n-      killer.at_put_grow(s->dst_id(), s, NULL);\n-    }\n-    assert(killer.at_grow(MoveOperation::get_id(temp_register), NULL) == NULL,\n-           \"make sure temp isn't in the registers that are killed\");\n-\n-    \/\/ create links between loads and stores\n-    for (int i = 0; i < edges.length(); i++) {\n-      edges.at(i)->link(killer);\n-    }\n-\n-    \/\/ at this point, all the move operations are chained together\n-    \/\/ in a doubly linked list.  Processing it backwards finds\n-    \/\/ the beginning of the chain, forwards finds the end.  If there's\n-    \/\/ a cycle it can be broken at any point,  so pick an edge and walk\n-    \/\/ backward until the list ends or we end where we started.\n-    GrowableArray<MoveOperation*>* stores = new GrowableArray<MoveOperation*>();\n-    for (int e = 0; e < edges.length(); e++) {\n-      MoveOperation* s = edges.at(e);\n-      if (!s->is_processed()) {\n-        MoveOperation* start = s;\n-        \/\/ search for the beginning of the chain or cycle\n-        while (start->prev() != NULL && start->prev() != s) {\n-          start = start->prev();\n-        }\n-        if (start->prev() == s) {\n-          start->break_cycle(temp_register);\n-        }\n-        \/\/ walk the chain forward inserting to store list\n-        while (start != NULL) {\n-          stores->append(start);\n-          start->set_processed();\n-          start = start->next();\n-        }\n-      }\n-    }\n-    return stores;\n-  }\n-};\n-\n@@ -1468,0 +1270,338 @@\n+static void check_continuation_enter_argument(VMReg actual_vmreg,\n+                                              Register expected_reg,\n+                                              const char* name) {\n+  assert(!actual_vmreg->is_stack(), \"%s cannot be on stack\", name);\n+  assert(actual_vmreg->as_Register() == expected_reg,\n+         \"%s is in unexpected register: %s instead of %s\",\n+         name, actual_vmreg->as_Register()->name(), expected_reg->name());\n+}\n+\n+\n+\/\/---------------------------- continuation_enter_setup ---------------------------\n+\/\/\n+\/\/ Arguments:\n+\/\/   None.\n+\/\/\n+\/\/ Results:\n+\/\/   rsp: pointer to blank ContinuationEntry\n+\/\/\n+\/\/ Kills:\n+\/\/   rax\n+\/\/\n+static OopMap* continuation_enter_setup(MacroAssembler* masm, int& stack_slots) {\n+  assert(ContinuationEntry::size() % VMRegImpl::stack_slot_size == 0, \"\");\n+  assert(in_bytes(ContinuationEntry::cont_offset())  % VMRegImpl::stack_slot_size == 0, \"\");\n+  assert(in_bytes(ContinuationEntry::chunk_offset()) % VMRegImpl::stack_slot_size == 0, \"\");\n+\n+  stack_slots += checked_cast<int>(ContinuationEntry::size()) \/ wordSize;\n+  __ subptr(rsp, checked_cast<int32_t>(ContinuationEntry::size()));\n+\n+  int frame_size = (checked_cast<int>(ContinuationEntry::size()) + wordSize) \/ VMRegImpl::stack_slot_size;\n+  OopMap* map = new OopMap(frame_size, 0);\n+\n+  __ movptr(rax, Address(r15_thread, JavaThread::cont_entry_offset()));\n+  __ movptr(Address(rsp, ContinuationEntry::parent_offset()), rax);\n+  __ movptr(Address(r15_thread, JavaThread::cont_entry_offset()), rsp);\n+\n+  return map;\n+}\n+\n+\/\/---------------------------- fill_continuation_entry ---------------------------\n+\/\/\n+\/\/ Arguments:\n+\/\/   rsp: pointer to blank Continuation entry\n+\/\/   reg_cont_obj: pointer to the continuation\n+\/\/   reg_flags: flags\n+\/\/\n+\/\/ Results:\n+\/\/   rsp: pointer to filled out ContinuationEntry\n+\/\/\n+\/\/ Kills:\n+\/\/   rax\n+\/\/\n+static void fill_continuation_entry(MacroAssembler* masm, Register reg_cont_obj, Register reg_flags) {\n+  assert_different_registers(rax, reg_cont_obj, reg_flags);\n+#ifdef ASSERT\n+  __ movl(Address(rsp, ContinuationEntry::cookie_offset()), ContinuationEntry::cookie_value());\n+#endif\n+  __ movptr(Address(rsp, ContinuationEntry::cont_offset()), reg_cont_obj);\n+  __ movl  (Address(rsp, ContinuationEntry::flags_offset()), reg_flags);\n+  __ movptr(Address(rsp, ContinuationEntry::chunk_offset()), 0);\n+  __ movl(Address(rsp, ContinuationEntry::argsize_offset()), 0);\n+  __ movl(Address(rsp, ContinuationEntry::pin_count_offset()), 0);\n+\n+  __ movptr(rax, Address(r15_thread, JavaThread::cont_fastpath_offset()));\n+  __ movptr(Address(rsp, ContinuationEntry::parent_cont_fastpath_offset()), rax);\n+  __ movq(rax, Address(r15_thread, JavaThread::held_monitor_count_offset()));\n+  __ movq(Address(rsp, ContinuationEntry::parent_held_monitor_count_offset()), rax);\n+\n+  __ movptr(Address(r15_thread, JavaThread::cont_fastpath_offset()), 0);\n+  __ movq(Address(r15_thread, JavaThread::held_monitor_count_offset()), 0);\n+}\n+\n+\/\/---------------------------- continuation_enter_cleanup ---------------------------\n+\/\/\n+\/\/ Arguments:\n+\/\/   rsp: pointer to the ContinuationEntry\n+\/\/\n+\/\/ Results:\n+\/\/   rsp: pointer to the spilled rbp in the entry frame\n+\/\/\n+\/\/ Kills:\n+\/\/   rbx\n+\/\/\n+void static continuation_enter_cleanup(MacroAssembler* masm) {\n+#ifdef ASSERT\n+  Label L_good_sp;\n+  __ cmpptr(rsp, Address(r15_thread, JavaThread::cont_entry_offset()));\n+  __ jcc(Assembler::equal, L_good_sp);\n+  __ stop(\"Incorrect rsp at continuation_enter_cleanup\");\n+  __ bind(L_good_sp);\n+#endif\n+\n+  __ movptr(rbx, Address(rsp, ContinuationEntry::parent_cont_fastpath_offset()));\n+  __ movptr(Address(r15_thread, JavaThread::cont_fastpath_offset()), rbx);\n+  __ movq(rbx, Address(rsp, ContinuationEntry::parent_held_monitor_count_offset()));\n+  __ movq(Address(r15_thread, JavaThread::held_monitor_count_offset()), rbx);\n+\n+  __ movptr(rbx, Address(rsp, ContinuationEntry::parent_offset()));\n+  __ movptr(Address(r15_thread, JavaThread::cont_entry_offset()), rbx);\n+  __ addptr(rsp, checked_cast<int32_t>(ContinuationEntry::size()));\n+}\n+\n+static void gen_continuation_enter(MacroAssembler* masm,\n+                                   const VMRegPair* regs,\n+                                   int& exception_offset,\n+                                   OopMapSet* oop_maps,\n+                                   int& frame_complete,\n+                                   int& stack_slots,\n+                                   int& interpreted_entry_offset,\n+                                   int& compiled_entry_offset) {\n+\n+  \/\/ enterSpecial(Continuation c, boolean isContinue, boolean isVirtualThread)\n+  int pos_cont_obj   = 0;\n+  int pos_is_cont    = 1;\n+  int pos_is_virtual = 2;\n+\n+  \/\/ The platform-specific calling convention may present the arguments in various registers.\n+  \/\/ To simplify the rest of the code, we expect the arguments to reside at these known\n+  \/\/ registers, and we additionally check the placement here in case calling convention ever\n+  \/\/ changes.\n+  Register reg_cont_obj   = c_rarg1;\n+  Register reg_is_cont    = c_rarg2;\n+  Register reg_is_virtual = c_rarg3;\n+\n+  check_continuation_enter_argument(regs[pos_cont_obj].first(),   reg_cont_obj,   \"Continuation object\");\n+  check_continuation_enter_argument(regs[pos_is_cont].first(),    reg_is_cont,    \"isContinue\");\n+  check_continuation_enter_argument(regs[pos_is_virtual].first(), reg_is_virtual, \"isVirtualThread\");\n+\n+  \/\/ Utility methods kill rax, make sure there are no collisions\n+  assert_different_registers(rax, reg_cont_obj, reg_is_cont, reg_is_virtual);\n+\n+  AddressLiteral resolve(SharedRuntime::get_resolve_static_call_stub(),\n+                         relocInfo::static_call_type);\n+\n+  address start = __ pc();\n+\n+  Label L_thaw, L_exit;\n+\n+  \/\/ i2i entry used at interp_only_mode only\n+  interpreted_entry_offset = __ pc() - start;\n+  {\n+#ifdef ASSERT\n+    Label is_interp_only;\n+    __ cmpb(Address(r15_thread, JavaThread::interp_only_mode_offset()), 0);\n+    __ jcc(Assembler::notEqual, is_interp_only);\n+    __ stop(\"enterSpecial interpreter entry called when not in interp_only_mode\");\n+    __ bind(is_interp_only);\n+#endif\n+\n+    __ pop(rax); \/\/ return address\n+    \/\/ Read interpreter arguments into registers (this is an ad-hoc i2c adapter)\n+    __ movptr(c_rarg1, Address(rsp, Interpreter::stackElementSize*2));\n+    __ movl(c_rarg2,   Address(rsp, Interpreter::stackElementSize*1));\n+    __ movl(c_rarg3,   Address(rsp, Interpreter::stackElementSize*0));\n+    __ andptr(rsp, -16); \/\/ Ensure compiled code always sees stack at proper alignment\n+    __ push(rax); \/\/ return address\n+    __ push_cont_fastpath();\n+\n+    __ enter();\n+\n+    stack_slots = 2; \/\/ will be adjusted in setup\n+    OopMap* map = continuation_enter_setup(masm, stack_slots);\n+    \/\/ The frame is complete here, but we only record it for the compiled entry, so the frame would appear unsafe,\n+    \/\/ but that's okay because at the very worst we'll miss an async sample, but we're in interp_only_mode anyway.\n+\n+    __ verify_oop(reg_cont_obj);\n+\n+    fill_continuation_entry(masm, reg_cont_obj, reg_is_virtual);\n+\n+    \/\/ If continuation, call to thaw. Otherwise, resolve the call and exit.\n+    __ testptr(reg_is_cont, reg_is_cont);\n+    __ jcc(Assembler::notZero, L_thaw);\n+\n+    \/\/ --- Resolve path\n+\n+    \/\/ Make sure the call is patchable\n+    __ align(BytesPerWord, __ offset() + NativeCall::displacement_offset);\n+    \/\/ Emit stub for static call\n+    CodeBuffer* cbuf = masm->code_section()->outer();\n+    address stub = CompiledStaticCall::emit_to_interp_stub(*cbuf, __ pc());\n+    if (stub == nullptr) {\n+      fatal(\"CodeCache is full at gen_continuation_enter\");\n+    }\n+    __ call(resolve);\n+    oop_maps->add_gc_map(__ pc() - start, map);\n+    __ post_call_nop();\n+\n+    __ jmp(L_exit);\n+  }\n+\n+  \/\/ compiled entry\n+  __ align(CodeEntryAlignment);\n+  compiled_entry_offset = __ pc() - start;\n+  __ enter();\n+\n+  stack_slots = 2; \/\/ will be adjusted in setup\n+  OopMap* map = continuation_enter_setup(masm, stack_slots);\n+\n+  \/\/ Frame is now completed as far as size and linkage.\n+  frame_complete = __ pc() - start;\n+\n+  __ verify_oop(reg_cont_obj);\n+\n+  fill_continuation_entry(masm, reg_cont_obj, reg_is_virtual);\n+\n+  \/\/ If isContinue, call to thaw. Otherwise, call Continuation.enter(Continuation c, boolean isContinue)\n+  __ testptr(reg_is_cont, reg_is_cont);\n+  __ jccb(Assembler::notZero, L_thaw);\n+\n+  \/\/ --- call Continuation.enter(Continuation c, boolean isContinue)\n+\n+  \/\/ Make sure the call is patchable\n+  __ align(BytesPerWord, __ offset() + NativeCall::displacement_offset);\n+\n+  \/\/ Emit stub for static call\n+  CodeBuffer* cbuf = masm->code_section()->outer();\n+  address stub = CompiledStaticCall::emit_to_interp_stub(*cbuf, __ pc());\n+  if (stub == nullptr) {\n+    fatal(\"CodeCache is full at gen_continuation_enter\");\n+  }\n+\n+  \/\/ The call needs to be resolved. There's a special case for this in\n+  \/\/ SharedRuntime::find_callee_info_helper() which calls\n+  \/\/ LinkResolver::resolve_continuation_enter() which resolves the call to\n+  \/\/ Continuation.enter(Continuation c, boolean isContinue).\n+  __ call(resolve);\n+\n+  oop_maps->add_gc_map(__ pc() - start, map);\n+  __ post_call_nop();\n+\n+  __ jmpb(L_exit);\n+\n+  \/\/ --- Thawing path\n+\n+  __ bind(L_thaw);\n+\n+  __ call(RuntimeAddress(StubRoutines::cont_thaw()));\n+\n+  ContinuationEntry::_return_pc_offset = __ pc() - start;\n+  oop_maps->add_gc_map(__ pc() - start, map->deep_copy());\n+  __ post_call_nop();\n+\n+  \/\/ --- Normal exit (resolve\/thawing)\n+\n+  __ bind(L_exit);\n+\n+  continuation_enter_cleanup(masm);\n+  __ pop(rbp);\n+  __ ret(0);\n+\n+  \/\/ --- Exception handling path\n+\n+  exception_offset = __ pc() - start;\n+\n+  continuation_enter_cleanup(masm);\n+  __ pop(rbp);\n+\n+  __ movptr(c_rarg0, r15_thread);\n+  __ movptr(c_rarg1, Address(rsp, 0)); \/\/ return address\n+\n+  \/\/ rax still holds the original exception oop, save it before the call\n+  __ push(rax);\n+\n+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::exception_handler_for_return_address), 2);\n+  __ movptr(rbx, rax);\n+\n+  \/\/ Continue at exception handler:\n+  \/\/   rax: exception oop\n+  \/\/   rbx: exception handler\n+  \/\/   rdx: exception pc\n+  __ pop(rax);\n+  __ verify_oop(rax);\n+  __ pop(rdx);\n+  __ jmp(rbx);\n+}\n+\n+static void gen_continuation_yield(MacroAssembler* masm,\n+                                   const VMRegPair* regs,\n+                                   OopMapSet* oop_maps,\n+                                   int& frame_complete,\n+                                   int& stack_slots,\n+                                   int& compiled_entry_offset) {\n+  enum layout {\n+    rbp_off,\n+    rbpH_off,\n+    return_off,\n+    return_off2,\n+    framesize \/\/ inclusive of return address\n+  };\n+  stack_slots = framesize \/  VMRegImpl::slots_per_word;\n+  assert(stack_slots == 2, \"recheck layout\");\n+\n+  address start = __ pc();\n+  compiled_entry_offset = __ pc() - start;\n+  __ enter();\n+  address the_pc = __ pc();\n+\n+  frame_complete = the_pc - start;\n+\n+  \/\/ This nop must be exactly at the PC we push into the frame info.\n+  \/\/ We use this nop for fast CodeBlob lookup, associate the OopMap\n+  \/\/ with it right away.\n+  __ post_call_nop();\n+  OopMap* map = new OopMap(framesize, 1);\n+  oop_maps->add_gc_map(frame_complete, map);\n+\n+  __ set_last_Java_frame(rsp, rbp, the_pc, rscratch1);\n+  __ movptr(c_rarg0, r15_thread);\n+  __ movptr(c_rarg1, rsp);\n+  __ call_VM_leaf(Continuation::freeze_entry(), 2);\n+  __ reset_last_Java_frame(true);\n+\n+  Label L_pinned;\n+\n+  __ testptr(rax, rax);\n+  __ jcc(Assembler::notZero, L_pinned);\n+\n+  __ movptr(rsp, Address(r15_thread, JavaThread::cont_entry_offset()));\n+  continuation_enter_cleanup(masm);\n+  __ pop(rbp);\n+  __ ret(0);\n+\n+  __ bind(L_pinned);\n+\n+  \/\/ Pinned, return to caller\n+\n+  \/\/ handle pending exception thrown by freeze\n+  __ cmpptr(Address(r15_thread, Thread::pending_exception_offset()), NULL_WORD);\n+  Label ok;\n+  __ jcc(Assembler::equal, ok);\n+  __ leave();\n+  __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+  __ bind(ok);\n+\n+  __ leave();\n+  __ ret(0);\n+}\n+\n@@ -1485,1 +1625,1 @@\n-  } else if (iid == vmIntrinsics::_invokeBasic || iid == vmIntrinsics::_linkToNative) {\n+  } else if (iid == vmIntrinsics::_invokeBasic) {\n@@ -1487,0 +1627,3 @@\n+  } else if (iid == vmIntrinsics::_linkToNative) {\n+    member_arg_pos = method->size_of_parameters() - 1;  \/\/ trailing NativeEntryPoint argument\n+    member_reg = rbx;  \/\/ known to be free at this point\n@@ -1548,2 +1691,60 @@\n-                                                BasicType ret_type,\n-                                                address critical_entry) {\n+                                                BasicType ret_type) {\n+  if (method->is_continuation_native_intrinsic()) {\n+    int exception_offset = -1;\n+    OopMapSet* oop_maps = new OopMapSet();\n+    int frame_complete = -1;\n+    int stack_slots = -1;\n+    int interpreted_entry_offset = -1;\n+    int vep_offset = -1;\n+    if (method->is_continuation_enter_intrinsic()) {\n+      gen_continuation_enter(masm,\n+                             in_regs,\n+                             exception_offset,\n+                             oop_maps,\n+                             frame_complete,\n+                             stack_slots,\n+                             interpreted_entry_offset,\n+                             vep_offset);\n+    } else if (method->is_continuation_yield_intrinsic()) {\n+      gen_continuation_yield(masm,\n+                             in_regs,\n+                             oop_maps,\n+                             frame_complete,\n+                             stack_slots,\n+                             vep_offset);\n+    } else {\n+      guarantee(false, \"Unknown Continuation native intrinsic\");\n+    }\n+\n+#ifdef ASSERT\n+    if (method->is_continuation_enter_intrinsic()) {\n+      assert(interpreted_entry_offset != -1, \"Must be set\");\n+      assert(exception_offset != -1,         \"Must be set\");\n+    } else {\n+      assert(interpreted_entry_offset == -1, \"Must be unset\");\n+      assert(exception_offset == -1,         \"Must be unset\");\n+    }\n+    assert(frame_complete != -1,    \"Must be set\");\n+    assert(stack_slots != -1,       \"Must be set\");\n+    assert(vep_offset != -1,        \"Must be set\");\n+#endif\n+\n+    __ flush();\n+    nmethod* nm = nmethod::new_native_nmethod(method,\n+                                              compile_id,\n+                                              masm->code(),\n+                                              vep_offset,\n+                                              frame_complete,\n+                                              stack_slots,\n+                                              in_ByteSize(-1),\n+                                              in_ByteSize(-1),\n+                                              oop_maps,\n+                                              exception_offset);\n+    if (method->is_continuation_enter_intrinsic()) {\n+      ContinuationEntry::set_enter_code(nm, interpreted_entry_offset);\n+    } else if (method->is_continuation_yield_intrinsic()) {\n+      _cont_doYield_stub = nm;\n+    }\n+    return nm;\n+  }\n+\n@@ -1569,7 +1770,1 @@\n-                                       (OopMapSet*)NULL);\n-  }\n-  bool is_critical_native = true;\n-  address native_func = critical_entry;\n-  if (native_func == NULL) {\n-    native_func = method->native_function();\n-    is_critical_native = false;\n+                                       nullptr);\n@@ -1577,1 +1772,2 @@\n-  assert(native_func != NULL, \"must have function\");\n+  address native_func = method->native_function();\n+  assert(native_func != nullptr, \"must have function\");\n@@ -1590,13 +1786,1 @@\n-  int total_c_args = total_in_args;\n-  if (!is_critical_native) {\n-    total_c_args += 1;\n-    if (method->is_static()) {\n-      total_c_args++;\n-    }\n-  } else {\n-    for (int i = 0; i < total_in_args; i++) {\n-      if (in_sig_bt[i] == T_ARRAY) {\n-        total_c_args++;\n-      }\n-    }\n-  }\n+  int total_c_args = total_in_args + (method->is_static() ? 2 : 1);\n@@ -1606,1 +1790,1 @@\n-  BasicType* in_elem_bt = NULL;\n+  BasicType* in_elem_bt = nullptr;\n@@ -1609,5 +1793,4 @@\n-  if (!is_critical_native) {\n-    out_sig_bt[argc++] = T_ADDRESS;\n-    if (method->is_static()) {\n-      out_sig_bt[argc++] = T_OBJECT;\n-    }\n+  out_sig_bt[argc++] = T_ADDRESS;\n+  if (method->is_static()) {\n+    out_sig_bt[argc++] = T_OBJECT;\n+  }\n@@ -1615,24 +1798,2 @@\n-    for (int i = 0; i < total_in_args ; i++ ) {\n-      out_sig_bt[argc++] = in_sig_bt[i];\n-    }\n-  } else {\n-    in_elem_bt = NEW_RESOURCE_ARRAY(BasicType, total_in_args);\n-    SignatureStream ss(method->signature());\n-    for (int i = 0; i < total_in_args ; i++ ) {\n-      if (in_sig_bt[i] == T_ARRAY) {\n-        \/\/ Arrays are passed as int, elem* pair\n-        out_sig_bt[argc++] = T_INT;\n-        out_sig_bt[argc++] = T_ADDRESS;\n-        ss.skip_array_prefix(1);  \/\/ skip one '['\n-        assert(ss.is_primitive(), \"primitive type expected\");\n-        in_elem_bt[i] = ss.type();\n-      } else {\n-        out_sig_bt[argc++] = in_sig_bt[i];\n-        in_elem_bt[i] = T_VOID;\n-      }\n-      if (in_sig_bt[i] != T_VOID) {\n-        assert(in_sig_bt[i] == ss.type() ||\n-               in_sig_bt[i] == T_ARRAY, \"must match\");\n-        ss.next();\n-      }\n-    }\n+  for (int i = 0; i < total_in_args ; i++ ) {\n+    out_sig_bt[argc++] = in_sig_bt[i];\n@@ -1644,1 +1805,1 @@\n-  out_arg_slots = c_calling_convention(out_sig_bt, out_regs, NULL, total_c_args);\n+  out_arg_slots = c_calling_convention(out_sig_bt, out_regs, nullptr, total_c_args);\n@@ -1656,34 +1817,0 @@\n-  if (is_critical_native) {\n-    \/\/ Critical natives may have to call out so they need a save area\n-    \/\/ for register arguments.\n-    int double_slots = 0;\n-    int single_slots = 0;\n-    for ( int i = 0; i < total_in_args; i++) {\n-      if (in_regs[i].first()->is_Register()) {\n-        const Register reg = in_regs[i].first()->as_Register();\n-        switch (in_sig_bt[i]) {\n-          case T_BOOLEAN:\n-          case T_BYTE:\n-          case T_SHORT:\n-          case T_CHAR:\n-          case T_INT:  single_slots++; break;\n-          case T_ARRAY:  \/\/ specific to LP64 (7145024)\n-          case T_LONG: double_slots++; break;\n-          default:  ShouldNotReachHere();\n-        }\n-      } else if (in_regs[i].first()->is_XMMRegister()) {\n-        switch (in_sig_bt[i]) {\n-          case T_FLOAT:  single_slots++; break;\n-          case T_DOUBLE: double_slots++; break;\n-          default:  ShouldNotReachHere();\n-        }\n-      } else if (in_regs[i].first()->is_FloatRegister()) {\n-        ShouldNotReachHere();\n-      }\n-    }\n-    total_save_slots = double_slots * 2 + single_slots;\n-    \/\/ align the save area\n-    if (double_slots != 0) {\n-      stack_slots = align_up(stack_slots, 2);\n-    }\n-  }\n@@ -1761,1 +1888,1 @@\n-  assert_different_registers(ic_reg, receiver, rscratch1);\n+  assert_different_registers(ic_reg, receiver, rscratch1, rscratch2);\n@@ -1807,1 +1934,2 @@\n-  bs->nmethod_entry_barrier(masm);\n+  \/\/ native wrapper is not hot enough to micro optimize the nmethod entry barrier with an out-of-line stub\n+  bs->nmethod_entry_barrier(masm, nullptr \/* slow_path *\/, nullptr \/* continuation *\/);\n@@ -1820,9 +1948,1 @@\n-    {\n-      Label L;\n-      __ mov(rax, rsp);\n-      __ andptr(rax, -16); \/\/ must be 16 byte boundary (see amd64 ABI)\n-      __ cmpptr(rax, rsp);\n-      __ jcc(Assembler::equal, L);\n-      __ stop(\"improperly aligned stack\");\n-      __ bind(L);\n-    }\n+  __ check_stack_alignment(rsp, \"improperly aligned stack\");\n@@ -1873,3 +1993,3 @@\n-  bool reg_destroyed[RegisterImpl::number_of_registers];\n-  bool freg_destroyed[XMMRegisterImpl::number_of_registers];\n-  for ( int r = 0 ; r < RegisterImpl::number_of_registers ; r++ ) {\n+  bool reg_destroyed[Register::number_of_registers];\n+  bool freg_destroyed[XMMRegister::number_of_registers];\n+  for ( int r = 0 ; r < Register::number_of_registers ; r++ ) {\n@@ -1878,1 +1998,1 @@\n-  for ( int f = 0 ; f < XMMRegisterImpl::number_of_registers ; f++ ) {\n+  for ( int f = 0 ; f < XMMRegister::number_of_registers ; f++ ) {\n@@ -1884,4 +2004,1 @@\n-  \/\/ This may iterate in two different directions depending on the\n-  \/\/ kind of native it is.  The reason is that for regular JNI natives\n-  \/\/ the incoming and outgoing registers are offset upwards and for\n-  \/\/ critical natives they are offset down.\n+  \/\/ For JNI natives the incoming and outgoing registers are offset upwards.\n@@ -1893,8 +2010,3 @@\n-  if (!is_critical_native) {\n-    for (int i = total_in_args - 1, c_arg = total_c_args - 1; i >= 0; i--, c_arg--) {\n-      arg_order.push(i);\n-      arg_order.push(c_arg);\n-    }\n-  } else {\n-    \/\/ Compute a valid move order, using tmp_vmreg to break any cycles\n-    ComputeMoveOrder cmo(total_in_args, in_regs, total_c_args, out_regs, in_sig_bt, arg_order, tmp_vmreg);\n+  for (int i = total_in_args - 1, c_arg = total_c_args - 1; i >= 0; i--, c_arg--) {\n+    arg_order.push(i);\n+    arg_order.push(c_arg);\n@@ -1908,14 +2020,0 @@\n-    if (c_arg == -1) {\n-      assert(is_critical_native, \"should only be required for critical natives\");\n-      \/\/ This arg needs to be moved to a temporary\n-      __ mov(tmp_vmreg.first()->as_Register(), in_regs[i].first()->as_Register());\n-      in_regs[i] = tmp_vmreg;\n-      temploc = i;\n-      continue;\n-    } else if (i == -1) {\n-      assert(is_critical_native, \"should only be required for critical natives\");\n-      \/\/ Read from the temporary location\n-      assert(temploc != -1, \"must be valid\");\n-      i = temploc;\n-      temploc = -1;\n-    }\n@@ -1936,13 +2034,0 @@\n-        if (is_critical_native) {\n-          unpack_array_argument(masm, in_regs[i], in_elem_bt[i], out_regs[c_arg + 1], out_regs[c_arg]);\n-          c_arg++;\n-#ifdef ASSERT\n-          if (out_regs[c_arg].first()->is_Register()) {\n-            reg_destroyed[out_regs[c_arg].first()->as_Register()->encoding()] = true;\n-          } else if (out_regs[c_arg].first()->is_XMMRegister()) {\n-            freg_destroyed[out_regs[c_arg].first()->as_XMMRegister()->encoding()] = true;\n-          }\n-#endif\n-          break;\n-        }\n-        assert(!is_critical_native, \"no oop arguments\");\n@@ -1983,24 +2068,19 @@\n-  if (!is_critical_native) {\n-    \/\/ point c_arg at the first arg that is already loaded in case we\n-    \/\/ need to spill before we call out\n-    c_arg = total_c_args - total_in_args;\n-\n-    if (method->is_static()) {\n-\n-      \/\/  load oop into a register\n-      __ movoop(oop_handle_reg, JNIHandles::make_local(method->method_holder()->java_mirror()));\n-\n-      \/\/ Now handlize the static class mirror it's known not-null.\n-      __ movptr(Address(rsp, klass_offset), oop_handle_reg);\n-      map->set_oop(VMRegImpl::stack2reg(klass_slot_offset));\n-\n-      \/\/ Now get the handle\n-      __ lea(oop_handle_reg, Address(rsp, klass_offset));\n-      \/\/ store the klass handle as second argument\n-      __ movptr(c_rarg1, oop_handle_reg);\n-      \/\/ and protect the arg if we must spill\n-      c_arg--;\n-    }\n-  } else {\n-    \/\/ For JNI critical methods we need to save all registers in save_args.\n-    c_arg = 0;\n+  \/\/ point c_arg at the first arg that is already loaded in case we\n+  \/\/ need to spill before we call out\n+  c_arg = total_c_args - total_in_args;\n+\n+  if (method->is_static()) {\n+\n+    \/\/  load oop into a register\n+    __ movoop(oop_handle_reg, JNIHandles::make_local(method->method_holder()->java_mirror()));\n+\n+    \/\/ Now handlize the static class mirror it's known not-null.\n+    __ movptr(Address(rsp, klass_offset), oop_handle_reg);\n+    map->set_oop(VMRegImpl::stack2reg(klass_slot_offset));\n+\n+    \/\/ Now get the handle\n+    __ lea(oop_handle_reg, Address(rsp, klass_offset));\n+    \/\/ store the klass handle as second argument\n+    __ movptr(c_rarg1, oop_handle_reg);\n+    \/\/ and protect the arg if we must spill\n+    c_arg--;\n@@ -2010,1 +2090,1 @@\n-  \/\/ be pushed on the stack when we do a a stack traversal). It is enough that the pc()\n+  \/\/ be pushed on the stack when we do a stack traversal). It is enough that the pc()\n@@ -2017,1 +2097,1 @@\n-  __ set_last_Java_frame(rsp, noreg, (address)the_pc);\n+  __ set_last_Java_frame(rsp, noreg, (address)the_pc, rscratch1);\n@@ -2024,1 +2104,1 @@\n-    SkipIfEqual skip(masm, &DTraceMethodProbes, false);\n+    SkipIfEqual skip(masm, &DTraceMethodProbes, false, rscratch1);\n@@ -2067,2 +2147,1 @@\n-    assert(!is_critical_native, \"unhandled\");\n-\n+    Label count_mon;\n@@ -2082,6 +2161,5 @@\n-    if (UseBiasedLocking) {\n-      __ biased_locking_enter(lock_reg, obj_reg, swap_reg, rscratch1, rscratch2, false, lock_done, &slow_path_lock);\n-    }\n-\n-    \/\/ Load immediate 1 into swap_reg %rax\n-    __ movl(swap_reg, 1);\n+    if (LockingMode == LM_MONITOR) {\n+      __ jmp(slow_path_lock);\n+    } else if (LockingMode == LM_LEGACY) {\n+      \/\/ Load immediate 1 into swap_reg %rax\n+      __ movl(swap_reg, 1);\n@@ -2089,2 +2167,2 @@\n-    \/\/ Load (object->mark() | 1) into swap_reg %rax\n-    __ orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      \/\/ Load (object->mark() | 1) into swap_reg %rax\n+      __ orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n@@ -2092,2 +2170,2 @@\n-    \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-    __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n+      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n@@ -2095,4 +2173,4 @@\n-    \/\/ src -> dest iff dest == rax else rax <- dest\n-    __ lock();\n-    __ cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    __ jcc(Assembler::equal, lock_done);\n+      \/\/ src -> dest iff dest == rax else rax <- dest\n+      __ lock();\n+      __ cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ jcc(Assembler::equal, count_mon);\n@@ -2100,1 +2178,1 @@\n-    \/\/ Hmm should this move to the slow path code area???\n+      \/\/ Hmm should this move to the slow path code area???\n@@ -2102,8 +2180,8 @@\n-    \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-    \/\/  1) (mark & 3) == 0, and\n-    \/\/  2) rsp <= mark < mark + os::pagesize()\n-    \/\/ These 3 tests can be done by evaluating the following\n-    \/\/ expression: ((mark - rsp) & (3 - os::vm_page_size())),\n-    \/\/ assuming both stack pointer and pagesize have their\n-    \/\/ least significant 2 bits clear.\n-    \/\/ NOTE: the oopMark is in swap_reg %rax as the result of cmpxchg\n+      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n+      \/\/  1) (mark & 3) == 0, and\n+      \/\/  2) rsp <= mark < mark + os::pagesize()\n+      \/\/ These 3 tests can be done by evaluating the following\n+      \/\/ expression: ((mark - rsp) & (3 - os::vm_page_size())),\n+      \/\/ assuming both stack pointer and pagesize have their\n+      \/\/ least significant 2 bits clear.\n+      \/\/ NOTE: the oopMark is in swap_reg %rax as the result of cmpxchg\n@@ -2111,2 +2189,2 @@\n-    __ subptr(swap_reg, rsp);\n-    __ andptr(swap_reg, 3 - os::vm_page_size());\n+      __ subptr(swap_reg, rsp);\n+      __ andptr(swap_reg, 3 - (int)os::vm_page_size());\n@@ -2114,3 +2192,11 @@\n-    \/\/ Save the test result, for recursive case, the result is zero\n-    __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n-    __ jcc(Assembler::notEqual, slow_path_lock);\n+      \/\/ Save the test result, for recursive case, the result is zero\n+      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n+      __ jcc(Assembler::notEqual, slow_path_lock);\n+    } else {\n+      assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+      \/\/ Load object header\n+      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ fast_lock_impl(obj_reg, swap_reg, r15_thread, rscratch1, slow_path_lock);\n+    }\n+    __ bind(count_mon);\n+    __ inc_held_monitor_count();\n@@ -2119,1 +2205,0 @@\n-\n@@ -2134,2 +2219,1 @@\n-  if (!is_critical_native) {\n-    __ lea(c_rarg0, Address(r15_thread, in_bytes(JavaThread::jni_environment_offset())));\n+  __ lea(c_rarg0, Address(r15_thread, in_bytes(JavaThread::jni_environment_offset())));\n@@ -2137,3 +2221,2 @@\n-    \/\/ Now set thread in native\n-    __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_native);\n-  }\n+  \/\/ Now set thread in native\n+  __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_native);\n@@ -2144,1 +2227,1 @@\n-  __ restore_cpu_control_state_after_jni();\n+  __ restore_cpu_control_state_after_jni(rscratch1);\n@@ -2167,11 +2250,0 @@\n-  \/\/ If this is a critical native, check for a safepoint or suspend request after the call.\n-  \/\/ If a safepoint is needed, transition to native, then to native_trans to handle\n-  \/\/ safepoints like the native methods that are not critical natives.\n-  if (is_critical_native) {\n-    Label needs_safepoint;\n-    __ safepoint_poll(needs_safepoint, r15_thread, false \/* at_return *\/, false \/* in_nmethod *\/);\n-    __ cmpl(Address(r15_thread, JavaThread::suspend_flags_offset()), 0);\n-    __ jcc(Assembler::equal, after_transition);\n-    __ bind(needs_safepoint);\n-  }\n-\n@@ -2188,1 +2260,2 @@\n-  __ membar(Assembler::Membar_mask_bits(\n+  if (!UseSystemMemoryBarrier) {\n+    __ membar(Assembler::Membar_mask_bits(\n@@ -2191,0 +2264,1 @@\n+  }\n@@ -2236,1 +2310,1 @@\n-  Label unlock_done;\n+  Label unlock_done;\n@@ -2240,0 +2314,2 @@\n+    Label fast_done;\n+\n@@ -2251,4 +2327,8 @@\n-    Label done;\n-\n-    if (UseBiasedLocking) {\n-      __ biased_locking_exit(obj_reg, old_hdr, done);\n+    if (LockingMode == LM_LEGACY) {\n+      Label not_recur;\n+      \/\/ Simple recursive lock?\n+      __ cmpptr(Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size), NULL_WORD);\n+      __ jcc(Assembler::notEqual, not_recur);\n+      __ dec_held_monitor_count();\n+      __ jmpb(fast_done);\n+      __ bind(not_recur);\n@@ -2257,6 +2337,1 @@\n-    \/\/ Simple recursive lock?\n-\n-    __ cmpptr(Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size), (int32_t)NULL_WORD);\n-    __ jcc(Assembler::equal, done);\n-\n-    \/\/ Must save rax if if it is live now because cmpxchg must use it\n+    \/\/ Must save rax if it is live now because cmpxchg must use it\n@@ -2267,0 +2342,7 @@\n+    if (LockingMode == LM_MONITOR) {\n+      __ jmp(slow_path_unlock);\n+    } else if (LockingMode == LM_LEGACY) {\n+      \/\/ get address of the stack lock\n+      __ lea(rax, Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+      \/\/  get old displaced header\n+      __ movptr(old_hdr, Address(rax, 0));\n@@ -2268,9 +2350,12 @@\n-    \/\/ get address of the stack lock\n-    __ lea(rax, Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-    \/\/  get old displaced header\n-    __ movptr(old_hdr, Address(rax, 0));\n-\n-    \/\/ Atomic swap old header if oop still contains the stack lock\n-    __ lock();\n-    __ cmpxchgptr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    __ jcc(Assembler::notEqual, slow_path_unlock);\n+      \/\/ Atomic swap old header if oop still contains the stack lock\n+      __ lock();\n+      __ cmpxchgptr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ jcc(Assembler::notEqual, slow_path_unlock);\n+      __ dec_held_monitor_count();\n+    } else {\n+      assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n+      __ fast_unlock_impl(obj_reg, swap_reg, lock_reg, slow_path_unlock);\n+      __ dec_held_monitor_count();\n+    }\n@@ -2284,2 +2369,1 @@\n-    __ bind(done);\n-\n+    __ bind(fast_done);\n@@ -2296,1 +2380,1 @@\n-    SkipIfEqual skip(masm, &DTraceMethodProbes, false);\n+    SkipIfEqual skip(masm, &DTraceMethodProbes, false, rscratch1);\n@@ -2319,5 +2403,3 @@\n-  if (!is_critical_native) {\n-    \/\/ reset handle block\n-    __ movptr(rcx, Address(r15_thread, JavaThread::active_handles_offset()));\n-    __ movl(Address(rcx, JNIHandleBlock::top_offset_in_bytes()), (int32_t)NULL_WORD);\n-  }\n+  \/\/ reset handle block\n+  __ movptr(rcx, Address(r15_thread, JavaThread::active_handles_offset()));\n+  __ movl(Address(rcx, JNIHandleBlock::top_offset()), NULL_WORD);\n@@ -2329,5 +2411,3 @@\n-  if (!is_critical_native) {\n-    \/\/ Any exception pending?\n-    __ cmpptr(Address(r15_thread, in_bytes(Thread::pending_exception_offset())), (int32_t)NULL_WORD);\n-    __ jcc(Assembler::notEqual, exception_pending);\n-  }\n+  \/\/ Any exception pending?\n+  __ cmpptr(Address(r15_thread, in_bytes(Thread::pending_exception_offset())), NULL_WORD);\n+  __ jcc(Assembler::notEqual, exception_pending);\n@@ -2341,3 +2421,2 @@\n-  if (!is_critical_native) {\n-    \/\/ forward the exception\n-    __ bind(exception_pending);\n+  \/\/ forward the exception\n+  __ bind(exception_pending);\n@@ -2345,3 +2424,2 @@\n-    \/\/ and forward the exception\n-    __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n-  }\n+  \/\/ and forward the exception\n+  __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n@@ -2371,1 +2449,1 @@\n-    __ cmpptr(Address(r15_thread, in_bytes(Thread::pending_exception_offset())), (int32_t)NULL_WORD);\n+    __ cmpptr(Address(r15_thread, in_bytes(Thread::pending_exception_offset())), NULL_WORD);\n@@ -2402,1 +2480,1 @@\n-    __ movptr(Address(r15_thread, in_bytes(Thread::pending_exception_offset())), (int32_t)NULL_WORD);\n+    __ movptr(Address(r15_thread, in_bytes(Thread::pending_exception_offset())), NULL_WORD);\n@@ -2411,1 +2489,1 @@\n-      __ cmpptr(Address(r15_thread, in_bytes(Thread::pending_exception_offset())), (int)NULL_WORD);\n+      __ cmpptr(Address(r15_thread, in_bytes(Thread::pending_exception_offset())), NULL_WORD);\n@@ -2498,1 +2576,1 @@\n-  OopMap* map = NULL;\n+  OopMap* map = nullptr;\n@@ -2503,1 +2581,1 @@\n-  \/\/ address has been pushed on the the stack, and return values are in\n+  \/\/ address has been pushed on the stack, and return values are in\n@@ -2537,1 +2615,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_vectors*\/ true);\n+  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_wide_vectors*\/ true);\n@@ -2555,1 +2633,1 @@\n-  (void) RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_vectors*\/ true);\n+  (void) RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_wide_vectors*\/ true);\n@@ -2569,1 +2647,1 @@\n-    __ movptr(Address(r15_thread, in_bytes(JavaThread::jvmci_implicit_exception_pc_offset())), (int32_t)NULL_WORD);\n+    __ movptr(Address(r15_thread, in_bytes(JavaThread::jvmci_implicit_exception_pc_offset())), NULL_WORD);\n@@ -2574,1 +2652,1 @@\n-    RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_vectors*\/ true);\n+    RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_wide_vectors*\/ true);\n@@ -2576,1 +2654,1 @@\n-    __ set_last_Java_frame(noreg, noreg, NULL);\n+    __ set_last_Java_frame(noreg, noreg, nullptr, rscratch1);\n@@ -2581,1 +2659,1 @@\n-    __ movl(r14, (int32_t)Deoptimization::Unpack_reexecute);\n+    __ movl(r14, Deoptimization::Unpack_reexecute);\n@@ -2621,1 +2699,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_vectors*\/ true);\n+  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_wide_vectors*\/ true);\n@@ -2633,1 +2711,1 @@\n-  __ movptr(Address(r15_thread, JavaThread::exception_pc_offset()), (int32_t)NULL_WORD);\n+  __ movptr(Address(r15_thread, JavaThread::exception_pc_offset()), NULL_WORD);\n@@ -2658,1 +2736,1 @@\n-  __ set_last_Java_frame(noreg, noreg, NULL);\n+  __ set_last_Java_frame(noreg, noreg, nullptr, rscratch1);\n@@ -2661,3 +2739,1 @@\n-    __ cmpptr(Address(r15_thread,\n-                    JavaThread::last_Java_fp_offset()),\n-            (int32_t)0);\n+    __ cmpptr(Address(r15_thread, JavaThread::last_Java_fp_offset()), NULL_WORD);\n@@ -2688,1 +2764,1 @@\n-  __ movl(r14, Address(rdi, Deoptimization::UnrollBlock::unpack_kind_offset_in_bytes()));\n+  __ movl(r14, Address(rdi, Deoptimization::UnrollBlock::unpack_kind_offset()));\n@@ -2693,1 +2769,1 @@\n-  \/\/ QQQ this is useless it was NULL above\n+  \/\/ QQQ this is useless it was null above\n@@ -2695,2 +2771,2 @@\n-  __ movptr(Address(r15_thread, JavaThread::exception_oop_offset()), (int32_t)NULL_WORD);\n-  __ movptr(Address(r15_thread, JavaThread::exception_pc_offset()), (int32_t)NULL_WORD);\n+  __ movptr(Address(r15_thread, JavaThread::exception_oop_offset()), NULL_WORD);\n+  __ movptr(Address(r15_thread, JavaThread::exception_pc_offset()), NULL_WORD);\n@@ -2727,1 +2803,1 @@\n-  __ movl(rcx, Address(rdi, Deoptimization::UnrollBlock::size_of_deoptimized_frame_offset_in_bytes()));\n+  __ movl(rcx, Address(rdi, Deoptimization::UnrollBlock::size_of_deoptimized_frame_offset()));\n@@ -2734,1 +2810,1 @@\n-  __ movptr(rbp, Address(rdi, Deoptimization::UnrollBlock::initial_info_offset_in_bytes()));\n+  __ movptr(rbp, Address(rdi, Deoptimization::UnrollBlock::initial_info_offset()));\n@@ -2740,1 +2816,1 @@\n-  __ movl(rbx, Address(rdi, Deoptimization::UnrollBlock::total_frame_sizes_offset_in_bytes()));\n+  __ movl(rbx, Address(rdi, Deoptimization::UnrollBlock::total_frame_sizes_offset()));\n@@ -2745,1 +2821,1 @@\n-  __ movptr(rcx, Address(rdi, Deoptimization::UnrollBlock::frame_pcs_offset_in_bytes()));\n+  __ movptr(rcx, Address(rdi, Deoptimization::UnrollBlock::frame_pcs_offset()));\n@@ -2751,1 +2827,1 @@\n-  __ movptr(rsi, Address(rdi, Deoptimization::UnrollBlock::frame_sizes_offset_in_bytes()));\n+  __ movptr(rsi, Address(rdi, Deoptimization::UnrollBlock::frame_sizes_offset()));\n@@ -2754,1 +2830,1 @@\n-  __ movl(rdx, Address(rdi, Deoptimization::UnrollBlock::number_of_frames_offset_in_bytes()));\n+  __ movl(rdx, Address(rdi, Deoptimization::UnrollBlock::number_of_frames_offset()));\n@@ -2766,1 +2842,1 @@\n-                       caller_adjustment_offset_in_bytes()));\n+                       caller_adjustment_offset()));\n@@ -2778,1 +2854,1 @@\n-  __ movptr(Address(rbp, frame::interpreter_frame_last_sp_offset * wordSize), (int32_t)NULL_WORD );\n+  __ movptr(Address(rbp, frame::interpreter_frame_last_sp_offset * wordSize), NULL_WORD);\n@@ -2808,1 +2884,1 @@\n-  __ set_last_Java_frame(noreg, rbp, the_pc);\n+  __ set_last_Java_frame(noreg, rbp, the_pc, rscratch1);\n@@ -2879,1 +2955,1 @@\n-  __ set_last_Java_frame(noreg, noreg, NULL);\n+  __ set_last_Java_frame(noreg, noreg, nullptr, rscratch1);\n@@ -2907,2 +2983,2 @@\n-    __ cmpptr(Address(rdi, Deoptimization::UnrollBlock::unpack_kind_offset_in_bytes()),\n-            (int32_t)Deoptimization::Unpack_uncommon_trap);\n+    __ cmpptr(Address(rdi, Deoptimization::UnrollBlock::unpack_kind_offset()),\n+              Deoptimization::Unpack_uncommon_trap);\n@@ -2910,1 +2986,1 @@\n-    __ stop(\"SharedRuntime::generate_deopt_blob: expected Unpack_uncommon_trap\");\n+    __ stop(\"SharedRuntime::generate_uncommon_trap_blob: expected Unpack_uncommon_trap\");\n@@ -2928,1 +3004,1 @@\n-                       size_of_deoptimized_frame_offset_in_bytes()));\n+                       size_of_deoptimized_frame_offset()));\n@@ -2935,1 +3011,1 @@\n-  __ movptr(rbp, Address(rdi, Deoptimization::UnrollBlock::initial_info_offset_in_bytes()));\n+  __ movptr(rbp, Address(rdi, Deoptimization::UnrollBlock::initial_info_offset()));\n@@ -2941,1 +3017,1 @@\n-  __ movl(rbx, Address(rdi ,Deoptimization::UnrollBlock::total_frame_sizes_offset_in_bytes()));\n+  __ movl(rbx, Address(rdi ,Deoptimization::UnrollBlock::total_frame_sizes_offset()));\n@@ -2946,1 +3022,1 @@\n-  __ movptr(rcx, Address(rdi, Deoptimization::UnrollBlock::frame_pcs_offset_in_bytes()));\n+  __ movptr(rcx, Address(rdi, Deoptimization::UnrollBlock::frame_pcs_offset()));\n@@ -2952,1 +3028,1 @@\n-  __ movptr(rsi, Address(rdi, Deoptimization::UnrollBlock:: frame_sizes_offset_in_bytes()));\n+  __ movptr(rsi, Address(rdi, Deoptimization::UnrollBlock:: frame_sizes_offset()));\n@@ -2955,1 +3031,1 @@\n-  __ movl(rdx, Address(rdi, Deoptimization::UnrollBlock:: number_of_frames_offset_in_bytes())); \/\/ (int)\n+  __ movl(rdx, Address(rdi, Deoptimization::UnrollBlock:: number_of_frames_offset())); \/\/ (int)\n@@ -2965,1 +3041,1 @@\n-  __ movl(rbx, Address(rdi, Deoptimization::UnrollBlock:: caller_adjustment_offset_in_bytes())); \/\/ (int)\n+  __ movl(rbx, Address(rdi, Deoptimization::UnrollBlock:: caller_adjustment_offset())); \/\/ (int)\n@@ -2979,1 +3055,1 @@\n-  __ movptr(Address(rbp, frame::interpreter_frame_last_sp_offset * wordSize), (int32_t)NULL_WORD );\n+  __ movptr(Address(rbp, frame::interpreter_frame_last_sp_offset * wordSize), NULL_WORD);\n@@ -2996,1 +3072,1 @@\n-  __ set_last_Java_frame(noreg, rbp, the_pc);\n+  __ set_last_Java_frame(noreg, rbp, the_pc, rscratch1);\n@@ -3037,1 +3113,1 @@\n-  assert(StubRoutines::forward_exception_entry() != NULL,\n+  assert(StubRoutines::forward_exception_entry() != nullptr,\n@@ -3049,1 +3125,1 @@\n-  address call_pc = NULL;\n+  address call_pc = nullptr;\n@@ -3052,1 +3128,1 @@\n-  bool save_vectors = (poll_type == POLL_AT_VECTOR_LOOP);\n+  bool save_wide_vectors = (poll_type == POLL_AT_VECTOR_LOOP);\n@@ -3067,1 +3143,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, save_vectors);\n+  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, save_wide_vectors);\n@@ -3071,1 +3147,1 @@\n-  \/\/ work outselves.\n+  \/\/ work ourselves.\n@@ -3073,1 +3149,1 @@\n-  __ set_last_Java_frame(noreg, noreg, NULL);\n+  __ set_last_Java_frame(noreg, noreg, nullptr, rscratch1);  \/\/ JavaFrameAnchor::capture_last_Java_pc() will get the pc from the return address, which we store next:\n@@ -3101,1 +3177,1 @@\n-  __ cmpptr(Address(r15_thread, Thread::pending_exception_offset()), (int32_t)NULL_WORD);\n+  __ cmpptr(Address(r15_thread, Thread::pending_exception_offset()), NULL_WORD);\n@@ -3106,1 +3182,1 @@\n-  RegisterSaver::restore_live_registers(masm, save_vectors);\n+  RegisterSaver::restore_live_registers(masm, save_wide_vectors);\n@@ -3179,1 +3255,1 @@\n-  RegisterSaver::restore_live_registers(masm, save_vectors);\n+  RegisterSaver::restore_live_registers(masm, save_wide_vectors);\n@@ -3203,1 +3279,1 @@\n-  assert (StubRoutines::forward_exception_entry() != NULL, \"must be generated before\");\n+  assert (StubRoutines::forward_exception_entry() != nullptr, \"must be generated before\");\n@@ -3208,2 +3284,2 @@\n-  CodeBuffer buffer(name, 1000, 512);\n-  MacroAssembler* masm                = new MacroAssembler(&buffer);\n+  CodeBuffer buffer(name, 1200, 512);\n+  MacroAssembler* masm = new MacroAssembler(&buffer);\n@@ -3214,1 +3290,1 @@\n-  OopMap* map = NULL;\n+  OopMap* map = nullptr;\n@@ -3219,1 +3295,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_vectors*\/ false);\n+  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_wide_vectors*\/ false);\n@@ -3223,1 +3299,1 @@\n-  __ set_last_Java_frame(noreg, noreg, NULL);\n+  __ set_last_Java_frame(noreg, noreg, nullptr, rscratch1);\n@@ -3242,1 +3318,1 @@\n-  __ cmpptr(Address(r15_thread, Thread::pending_exception_offset()), (int32_t)NULL_WORD);\n+  __ cmpptr(Address(r15_thread, Thread::pending_exception_offset()), NULL_WORD);\n@@ -3253,1 +3329,1 @@\n-  \/\/ We are back the the original state on entry and ready to go.\n+  \/\/ We are back to the original state on entry and ready to go.\n@@ -3265,1 +3341,1 @@\n-  __ movptr(Address(r15_thread, JavaThread::vm_result_offset()), (int)NULL_WORD);\n+  __ movptr(Address(r15_thread, JavaThread::vm_result_offset()), NULL_WORD);\n@@ -3279,257 +3355,0 @@\n-#ifdef COMPILER2\n-static const int native_invoker_code_size = MethodHandles::adapter_code_size;\n-\n-class NativeInvokerGenerator : public StubCodeGenerator {\n-  address _call_target;\n-  int _shadow_space_bytes;\n-\n-  const GrowableArray<VMReg>& _input_registers;\n-  const GrowableArray<VMReg>& _output_registers;\n-\n-  int _frame_complete;\n-  int _framesize;\n-  OopMapSet* _oop_maps;\n-public:\n-  NativeInvokerGenerator(CodeBuffer* buffer,\n-                         address call_target,\n-                         int shadow_space_bytes,\n-                         const GrowableArray<VMReg>& input_registers,\n-                         const GrowableArray<VMReg>& output_registers)\n-   : StubCodeGenerator(buffer, PrintMethodHandleStubs),\n-     _call_target(call_target),\n-     _shadow_space_bytes(shadow_space_bytes),\n-     _input_registers(input_registers),\n-     _output_registers(output_registers),\n-     _frame_complete(0),\n-     _framesize(0),\n-     _oop_maps(NULL) {\n-    assert(_output_registers.length() <= 1\n-           || (_output_registers.length() == 2 && !_output_registers.at(1)->is_valid()), \"no multi-reg returns\");\n-\n-  }\n-\n-  void generate();\n-\n-  int spill_size_in_bytes() const {\n-    if (_output_registers.length() == 0) {\n-      return 0;\n-    }\n-    VMReg reg = _output_registers.at(0);\n-    assert(reg->is_reg(), \"must be a register\");\n-    if (reg->is_Register()) {\n-      return 8;\n-    } else if (reg->is_XMMRegister()) {\n-      if (UseAVX >= 3) {\n-        return 64;\n-      } else if (UseAVX >= 1) {\n-        return 32;\n-      } else {\n-        return 16;\n-      }\n-    } else {\n-      ShouldNotReachHere();\n-    }\n-    return 0;\n-  }\n-\n-  void spill_out_registers() {\n-    if (_output_registers.length() == 0) {\n-      return;\n-    }\n-    VMReg reg = _output_registers.at(0);\n-    assert(reg->is_reg(), \"must be a register\");\n-    MacroAssembler* masm = _masm;\n-    if (reg->is_Register()) {\n-      __ movptr(Address(rsp, 0), reg->as_Register());\n-    } else if (reg->is_XMMRegister()) {\n-      if (UseAVX >= 3) {\n-        __ evmovdqul(Address(rsp, 0), reg->as_XMMRegister(), Assembler::AVX_512bit);\n-      } else if (UseAVX >= 1) {\n-        __ vmovdqu(Address(rsp, 0), reg->as_XMMRegister());\n-      } else {\n-        __ movdqu(Address(rsp, 0), reg->as_XMMRegister());\n-      }\n-    } else {\n-      ShouldNotReachHere();\n-    }\n-  }\n-\n-  void fill_out_registers() {\n-    if (_output_registers.length() == 0) {\n-      return;\n-    }\n-    VMReg reg = _output_registers.at(0);\n-    assert(reg->is_reg(), \"must be a register\");\n-    MacroAssembler* masm = _masm;\n-    if (reg->is_Register()) {\n-      __ movptr(reg->as_Register(), Address(rsp, 0));\n-    } else if (reg->is_XMMRegister()) {\n-      if (UseAVX >= 3) {\n-        __ evmovdqul(reg->as_XMMRegister(), Address(rsp, 0), Assembler::AVX_512bit);\n-      } else if (UseAVX >= 1) {\n-        __ vmovdqu(reg->as_XMMRegister(), Address(rsp, 0));\n-      } else {\n-        __ movdqu(reg->as_XMMRegister(), Address(rsp, 0));\n-      }\n-    } else {\n-      ShouldNotReachHere();\n-    }\n-  }\n-\n-  int frame_complete() const {\n-    return _frame_complete;\n-  }\n-\n-  int framesize() const {\n-    return (_framesize >> (LogBytesPerWord - LogBytesPerInt));\n-  }\n-\n-  OopMapSet* oop_maps() const {\n-    return _oop_maps;\n-  }\n-\n-private:\n-#ifdef ASSERT\n-bool target_uses_register(VMReg reg) {\n-  return _input_registers.contains(reg) || _output_registers.contains(reg);\n-}\n-#endif\n-};\n-\n-RuntimeStub* SharedRuntime::make_native_invoker(address call_target,\n-                                                int shadow_space_bytes,\n-                                                const GrowableArray<VMReg>& input_registers,\n-                                                const GrowableArray<VMReg>& output_registers) {\n-  int locs_size  = 64;\n-  CodeBuffer code(\"nep_invoker_blob\", native_invoker_code_size, locs_size);\n-  NativeInvokerGenerator g(&code, call_target, shadow_space_bytes, input_registers, output_registers);\n-  g.generate();\n-  code.log_section_sizes(\"nep_invoker_blob\");\n-\n-  RuntimeStub* stub =\n-    RuntimeStub::new_runtime_stub(\"nep_invoker_blob\",\n-                                  &code,\n-                                  g.frame_complete(),\n-                                  g.framesize(),\n-                                  g.oop_maps(), false);\n-  return stub;\n-}\n-\n-void NativeInvokerGenerator::generate() {\n-  assert(!(target_uses_register(r15_thread->as_VMReg()) || target_uses_register(rscratch1->as_VMReg())), \"Register conflict\");\n-\n-  enum layout {\n-    rbp_off,\n-    rbp_off2,\n-    return_off,\n-    return_off2,\n-    framesize \/\/ inclusive of return address\n-  };\n-\n-  _framesize = align_up(framesize + ((_shadow_space_bytes + spill_size_in_bytes()) >> LogBytesPerInt), 4);\n-  assert(is_even(_framesize\/2), \"sp not 16-byte aligned\");\n-\n-  _oop_maps  = new OopMapSet();\n-  MacroAssembler* masm = _masm;\n-\n-  address start = __ pc();\n-\n-  __ enter();\n-\n-  \/\/ return address and rbp are already in place\n-  __ subptr(rsp, (_framesize-4) << LogBytesPerInt); \/\/ prolog\n-\n-  _frame_complete = __ pc() - start;\n-\n-  address the_pc = __ pc();\n-\n-  __ set_last_Java_frame(rsp, rbp, (address)the_pc);\n-  OopMap* map = new OopMap(_framesize, 0);\n-  _oop_maps->add_gc_map(the_pc - start, map);\n-\n-  \/\/ State transition\n-  __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_native);\n-\n-  __ call(RuntimeAddress(_call_target));\n-\n-  __ restore_cpu_control_state_after_jni();\n-\n-  __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_native_trans);\n-\n-  \/\/ Force this write out before the read below\n-  __ membar(Assembler::Membar_mask_bits(\n-          Assembler::LoadLoad | Assembler::LoadStore |\n-          Assembler::StoreLoad | Assembler::StoreStore));\n-\n-  Label L_after_safepoint_poll;\n-  Label L_safepoint_poll_slow_path;\n-\n-  __ safepoint_poll(L_safepoint_poll_slow_path, r15_thread, true \/* at_return *\/, false \/* in_nmethod *\/);\n-  __ cmpl(Address(r15_thread, JavaThread::suspend_flags_offset()), 0);\n-  __ jcc(Assembler::notEqual, L_safepoint_poll_slow_path);\n-\n-  __ bind(L_after_safepoint_poll);\n-\n-  \/\/ change thread state\n-  __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_Java);\n-\n-  __ block_comment(\"reguard stack check\");\n-  Label L_reguard;\n-  Label L_after_reguard;\n-  __ cmpl(Address(r15_thread, JavaThread::stack_guard_state_offset()), StackOverflow::stack_guard_yellow_reserved_disabled);\n-  __ jcc(Assembler::equal, L_reguard);\n-  __ bind(L_after_reguard);\n-\n-  __ reset_last_Java_frame(r15_thread, true);\n-\n-  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-  __ ret(0);\n-\n-  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-\n-  __ block_comment(\"{ L_safepoint_poll_slow_path\");\n-  __ bind(L_safepoint_poll_slow_path);\n-  __ vzeroupper();\n-\n-  spill_out_registers();\n-\n-  __ mov(c_rarg0, r15_thread);\n-  __ mov(r12, rsp); \/\/ remember sp\n-  __ subptr(rsp, frame::arg_reg_save_area_bytes); \/\/ windows\n-  __ andptr(rsp, -16); \/\/ align stack as required by ABI\n-  __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, JavaThread::check_special_condition_for_native_trans)));\n-  __ mov(rsp, r12); \/\/ restore sp\n-  __ reinit_heapbase();\n-\n-  fill_out_registers();\n-\n-  __ jmp(L_after_safepoint_poll);\n-  __ block_comment(\"} L_safepoint_poll_slow_path\");\n-\n-  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-\n-  __ block_comment(\"{ L_reguard\");\n-  __ bind(L_reguard);\n-  __ vzeroupper();\n-\n-  spill_out_registers();\n-\n-  __ mov(r12, rsp); \/\/ remember sp\n-  __ subptr(rsp, frame::arg_reg_save_area_bytes); \/\/ windows\n-  __ andptr(rsp, -16); \/\/ align stack as required by ABI\n-  __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::reguard_yellow_pages)));\n-  __ mov(rsp, r12); \/\/ restore sp\n-  __ reinit_heapbase();\n-\n-  fill_out_registers();\n-\n-  __ jmp(L_after_reguard);\n-\n-  __ block_comment(\"} L_reguard\");\n-\n-  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-\n-  __ flush();\n-}\n-#endif \/\/ COMPILER2\n-\n@@ -3748,0 +3567,2 @@\n+  int divisor = sizeof(julong) * 4;\n+  guarantee(longwords <= 8192 \/ divisor, \"must be\");\n@@ -3749,1 +3570,0 @@\n-  guarantee(total_allocation <= 8192, \"must be\");\n@@ -3777,0 +3597,2 @@\n+  int divisor = sizeof(julong) * 3;\n+  guarantee(longwords <= (8192 \/ divisor), \"must be\");\n@@ -3778,1 +3600,0 @@\n-  guarantee(total_allocation <= 8192, \"must be\");\n@@ -3874,1 +3695,1 @@\n-  __ set_last_Java_frame(noreg, noreg, the_pc);\n+  __ set_last_Java_frame(noreg, noreg, the_pc, rscratch1);\n@@ -3912,2 +3733,2 @@\n-  __ movptr(Address(r15_thread, JavaThread::exception_handler_pc_offset()), (int)NULL_WORD);\n-  __ movptr(Address(r15_thread, JavaThread::exception_pc_offset()), (int)NULL_WORD);\n+  __ movptr(Address(r15_thread, JavaThread::exception_handler_pc_offset()), NULL_WORD);\n+  __ movptr(Address(r15_thread, JavaThread::exception_pc_offset()), NULL_WORD);\n@@ -3916,1 +3737,1 @@\n-  __ movptr(Address(r15_thread, JavaThread::exception_oop_offset()), (int)NULL_WORD);\n+  __ movptr(Address(r15_thread, JavaThread::exception_oop_offset()), NULL_WORD);\n@@ -3933,9 +3754,0 @@\n-void SharedRuntime::compute_move_order(const BasicType* in_sig_bt,\n-                                       int total_in_args, const VMRegPair* in_regs,\n-                                       int total_out_args, VMRegPair* out_regs,\n-                                       GrowableArray<int>& arg_order,\n-                                       VMRegPair tmp_vmreg) {\n-  ComputeMoveOrder order(total_in_args, in_regs,\n-                         total_out_args, out_regs,\n-                         in_sig_bt, arg_order, tmp_vmreg);\n-}\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":690,"deletions":878,"binary":false,"changes":1568,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,0 +29,1 @@\n+#include \"gc\/shared\/gc_globals.hpp\"\n@@ -145,3 +146,3 @@\n-\/\/ Miscelaneous helper routines\n-\/\/ Store an oop (or NULL) at the address described by obj.\n-\/\/ If val == noreg this means store a NULL\n+\/\/ Miscellaneous helper routines\n+\/\/ Store an oop (or null) at the address described by obj.\n+\/\/ If val == noreg this means store a null\n@@ -155,1 +156,4 @@\n-  __ store_heap_oop(dst, val, rdx, rbx, decorators);\n+  __ store_heap_oop(dst, val,\n+                    NOT_LP64(rdx) LP64_ONLY(rscratch2),\n+                    NOT_LP64(rbx) LP64_ONLY(r9),\n+                    NOT_LP64(rsi) LP64_ONLY(r8), decorators);\n@@ -292,1 +296,1 @@\n-      __ movflt(xmm0, ExternalAddress((address) &one));\n+      __ movflt(xmm0, ExternalAddress((address) &one), rscratch1);\n@@ -295,1 +299,1 @@\n-      __ movflt(xmm0, ExternalAddress((address) &two));\n+      __ movflt(xmm0, ExternalAddress((address) &two), rscratch1);\n@@ -323,1 +327,1 @@\n-      __ movdbl(xmm0, ExternalAddress((address) &one));\n+      __ movdbl(xmm0, ExternalAddress((address) &one), rscratch1);\n@@ -353,1 +357,1 @@\n-void TemplateTable::ldc(bool wide) {\n+void TemplateTable::ldc(LdcType type) {\n@@ -358,1 +362,1 @@\n-  if (wide) {\n+  if (is_ldc_wide(type)) {\n@@ -386,1 +390,1 @@\n-  __ movl(rarg, wide);\n+  __ movl(rarg, is_ldc_wide(type) ? 1 : 0);\n@@ -418,1 +422,1 @@\n-void TemplateTable::fast_aldc(bool wide) {\n+void TemplateTable::fast_aldc(LdcType type) {\n@@ -424,1 +428,1 @@\n-  int index_size = wide ? sizeof(u2) : sizeof(u1);\n+  int index_size = is_ldc_wide(type) ? sizeof(u2) : sizeof(u1);\n@@ -449,1 +453,1 @@\n-    __ resolve_oop_handle(tmp);\n+    __ resolve_oop_handle(tmp, rscratch2);\n@@ -452,1 +456,1 @@\n-    __ xorptr(result, result);  \/\/ NULL object reference\n+    __ xorptr(result, result);  \/\/ null object reference\n@@ -528,1 +532,1 @@\n-      __ jcc(Assembler::notEqual, notInt);\n+      __ jccb(Assembler::notEqual, notInt);\n@@ -536,1 +540,1 @@\n-      __ jcc(Assembler::notEqual, notFloat);\n+      __ jccb(Assembler::notEqual, notFloat);\n@@ -544,1 +548,1 @@\n-      __ jcc(Assembler::notEqual, notShort);\n+      __ jccb(Assembler::notEqual, notShort);\n@@ -552,1 +556,1 @@\n-      __ jcc(Assembler::notEqual, notByte);\n+      __ jccb(Assembler::notEqual, notByte);\n@@ -560,1 +564,1 @@\n-      __ jcc(Assembler::notEqual, notChar);\n+      __ jccb(Assembler::notEqual, notChar);\n@@ -568,1 +572,1 @@\n-      __ jcc(Assembler::notEqual, notBool);\n+      __ jccb(Assembler::notEqual, notBool);\n@@ -582,1 +586,1 @@\n-      __ jcc(Assembler::notEqual, notLong);\n+      __ jccb(Assembler::notEqual, notLong);\n@@ -592,1 +596,1 @@\n-      __ jcc(Assembler::notEqual, notDouble);\n+      __ jccb(Assembler::notEqual, notDouble);\n@@ -750,2 +754,0 @@\n-  \/\/ check array\n-  __ null_check(array, arrayOopDesc::length_offset_in_bytes());\n@@ -1172,1 +1174,1 @@\n-  __ access_store_at(T_INT, IN_HEAP | IS_ARRAY, addr, rax, noreg, noreg);\n+  __ access_store_at(T_INT, IN_HEAP | IS_ARRAY, addr, rax, noreg, noreg, noreg);\n@@ -1187,1 +1189,1 @@\n-                     noreg);\n+                     noreg, noreg);\n@@ -1202,1 +1204,1 @@\n-                     noreg);\n+                     noreg, noreg);\n@@ -1216,1 +1218,1 @@\n-                     noreg, noreg);\n+                     noreg, noreg, noreg);\n@@ -1239,2 +1241,1 @@\n-  Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n-  __ load_klass(rbx, rax, tmp_load_klass);\n+  __ load_klass(rbx, rax, rscratch1);\n@@ -1243,1 +1244,1 @@\n-  __ load_klass(rax, rdx, tmp_load_klass);\n+  __ load_klass(rax, rdx, rscratch1);\n@@ -1265,1 +1266,1 @@\n-  \/\/ Have a NULL in rax, rdx=array, ecx=index.  Store NULL at ary[idx]\n+  \/\/ Have a null in rax, rdx=array, ecx=index.  Store null at ary[idx]\n@@ -1269,1 +1270,1 @@\n-  \/\/ Store a NULL\n+  \/\/ Store a null\n@@ -1286,2 +1287,1 @@\n-  Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n-  __ load_klass(rcx, rdx, tmp_load_klass);\n+  __ load_klass(rcx, rdx, rscratch1);\n@@ -1298,1 +1298,1 @@\n-  __ access_store_at(T_BYTE, IN_HEAP | IS_ARRAY, addr, rax, noreg, noreg);\n+  __ access_store_at(T_BYTE, IN_HEAP | IS_ARRAY, addr, rax, noreg, noreg, noreg);\n@@ -1311,1 +1311,1 @@\n-  __ access_store_at(T_CHAR, IN_HEAP | IS_ARRAY, addr, rax, noreg, noreg);\n+  __ access_store_at(T_CHAR, IN_HEAP | IS_ARRAY, addr, rax, noreg, noreg, noreg);\n@@ -1658,1 +1658,1 @@\n-#else\n+#else \/\/ !_LP64\n@@ -1667,1 +1667,1 @@\n-#endif\n+#endif \/\/ _LP64\n@@ -1676,1 +1676,1 @@\n-#else\n+#else \/\/ !_LP64\n@@ -1721,1 +1721,1 @@\n-#else\n+#else \/\/ !_LP64\n@@ -1731,1 +1731,1 @@\n-#endif\n+#endif \/\/ _LP64\n@@ -1740,1 +1740,1 @@\n-#else\n+#else \/\/ !_LP64\n@@ -1769,1 +1769,1 @@\n-#endif\n+#endif \/\/ _LP64\n@@ -1803,1 +1803,1 @@\n-    __ xorps(xmm0, ExternalAddress((address) float_signflip));\n+    __ xorps(xmm0, ExternalAddress((address) float_signflip), rscratch1);\n@@ -1815,1 +1815,1 @@\n-    __ xorpd(xmm0, ExternalAddress((address) double_signflip));\n+    __ xorpd(xmm0, ExternalAddress((address) double_signflip), rscratch1);\n@@ -1936,1 +1936,1 @@\n-    __ cmp64(rax, ExternalAddress((address) &is_nan));\n+    __ cmp64(rax, ExternalAddress((address) &is_nan), rscratch1);\n@@ -1960,1 +1960,1 @@\n-    __ cmp64(rax, ExternalAddress((address) &is_nan));\n+    __ cmp64(rax, ExternalAddress((address) &is_nan), rscratch1);\n@@ -1972,1 +1972,1 @@\n-#else\n+#else \/\/ !_LP64\n@@ -2163,1 +2163,1 @@\n-#endif\n+#endif \/\/ _LP64\n@@ -2217,1 +2217,1 @@\n-#else\n+#else \/\/ !_LP64\n@@ -2309,1 +2309,0 @@\n-    int increment = InvocationCounter::count_increment;\n@@ -2319,2 +2318,2 @@\n-      __ increment_mask_and_jump(mdo_backedge_counter, increment, mask, rax, false, Assembler::zero,\n-          UseOnStackReplacement ? &backedge_counter_overflow : NULL);\n+      __ increment_mask_and_jump(mdo_backedge_counter, mask, rax,\n+          UseOnStackReplacement ? &backedge_counter_overflow : nullptr);\n@@ -2327,2 +2326,2 @@\n-    __ increment_mask_and_jump(Address(rcx, be_offset), increment, mask,\n-        rax, false, Assembler::zero, UseOnStackReplacement ? &backedge_counter_overflow : NULL);\n+    __ increment_mask_and_jump(Address(rcx, be_offset), mask, rax,\n+        UseOnStackReplacement ? &backedge_counter_overflow : nullptr);\n@@ -2354,1 +2353,1 @@\n-      \/\/ rax: osr nmethod (osr ok) or NULL (osr not possible)\n+      \/\/ rax: osr nmethod (osr ok) or null (osr not possible)\n@@ -2681,2 +2680,1 @@\n-    Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n-    __ load_klass(rdi, robj, tmp_load_klass);\n+    __ load_klass(rdi, robj, rscratch1);\n@@ -2705,0 +2703,1 @@\n+    __ push_cont_fastpath();\n@@ -2707,0 +2706,1 @@\n+    __ pop_cont_fastpath();\n@@ -2732,1 +2732,1 @@\n-\/\/     writes act as aquire & release, so:\n+\/\/     writes act as acquire & release, so:\n@@ -2798,1 +2798,1 @@\n-    __ clinit_barrier(klass, thread, NULL \/*L_fast_path*\/, &L_clinit_barrier_slow);\n+    __ clinit_barrier(klass, thread, nullptr \/*L_fast_path*\/, &L_clinit_barrier_slow);\n@@ -2828,1 +2828,1 @@\n-    __ resolve_oop_handle(obj);\n+    __ resolve_oop_handle(obj, rscratch2);\n@@ -2832,4 +2832,0 @@\n-\n-      \/\/ java_lang_Class::_init_lock_offset may not have been initialized\n-      \/\/ when generating code. It will be initialized at runtime though.\n-      \/\/ So calculate its address and read from it at runtime.\n@@ -2838,6 +2834,0 @@\n-      AddressLiteral init_lock_offset_address(\n-          (address) java_lang_Class::init_lock_offset_addr(),\n-          relocInfo::none);\n-      __ lea(rax, init_lock_offset_address);\n-      __ movl(rax, Address(rax, 0));\n-      __ addq(c_rarg0, rax);\n@@ -2852,0 +2842,68 @@\n+void TemplateTable::load_invokedynamic_entry(Register method) {\n+  \/\/ setup registers\n+  const Register appendix = rax;\n+  const Register cache = rcx;\n+  const Register index = rdx;\n+  assert_different_registers(method, appendix, cache, index);\n+\n+  __ save_bcp();\n+\n+  Label resolved;\n+\n+  __ load_resolved_indy_entry(cache, index);\n+  __ movptr(method, Address(cache, in_bytes(ResolvedIndyEntry::method_offset())));\n+\n+  \/\/ Compare the method to zero\n+  __ testptr(method, method);\n+  __ jcc(Assembler::notZero, resolved);\n+\n+  Bytecodes::Code code = bytecode();\n+\n+  \/\/ Call to the interpreter runtime to resolve invokedynamic\n+  address entry = CAST_FROM_FN_PTR(address, InterpreterRuntime::resolve_from_cache);\n+  __ movl(method, code); \/\/ this is essentially Bytecodes::_invokedynamic\n+  __ call_VM(noreg, entry, method);\n+  \/\/ Update registers with resolved info\n+  __ load_resolved_indy_entry(cache, index);\n+  __ movptr(method, Address(cache, in_bytes(ResolvedIndyEntry::method_offset())));\n+\n+#ifdef ASSERT\n+  __ testptr(method, method);\n+  __ jcc(Assembler::notZero, resolved);\n+  __ stop(\"Should be resolved by now\");\n+#endif \/\/ ASSERT\n+  __ bind(resolved);\n+\n+  Label L_no_push;\n+  \/\/ Check if there is an appendix\n+  __ load_unsigned_byte(index, Address(cache, in_bytes(ResolvedIndyEntry::flags_offset())));\n+  __ testl(index, (1 << ResolvedIndyEntry::has_appendix_shift));\n+  __ jcc(Assembler::zero, L_no_push);\n+\n+  \/\/ Get appendix\n+  __ load_unsigned_short(index, Address(cache, in_bytes(ResolvedIndyEntry::resolved_references_index_offset())));\n+  \/\/ Push the appendix as a trailing parameter\n+  \/\/ since the parameter_size includes it.\n+  __ load_resolved_reference_at_index(appendix, index);\n+  __ verify_oop(appendix);\n+  __ push(appendix);  \/\/ push appendix (MethodType, CallSite, etc.)\n+  __ bind(L_no_push);\n+\n+  \/\/ compute return type\n+  __ load_unsigned_byte(index, Address(cache, in_bytes(ResolvedIndyEntry::result_type_offset())));\n+  \/\/ load return address\n+  {\n+    const address table_addr = (address) Interpreter::invoke_return_entry_table_for(code);\n+    ExternalAddress table(table_addr);\n+#ifdef _LP64\n+    __ lea(rscratch1, table);\n+    __ movptr(index, Address(rscratch1, index, Address::times_ptr));\n+#else\n+    __ movptr(index, ArrayAddress(table, Address(noreg, index, Address::times_ptr)));\n+#endif \/\/ _LP64\n+  }\n+\n+  \/\/ push return address\n+  __ push(index);\n+}\n+\n@@ -2858,1 +2916,1 @@\n-                                               bool is_invokedynamic) {\n+                                               bool is_invokedynamic \/*unused*\/) {\n@@ -2874,1 +2932,1 @@\n-  size_t index_size = (is_invokedynamic ? sizeof(u4) : sizeof(u2));\n+  size_t index_size = sizeof(u2);\n@@ -2905,1 +2963,1 @@\n-      __ xorptr(rax, rax);      \/\/ NULL object reference\n+      __ xorptr(rax, rax);      \/\/ null object reference\n@@ -2911,1 +2969,1 @@\n-    \/\/ rax,:   object pointer or NULL\n+    \/\/ rax,:   object pointer or null\n@@ -3187,1 +3245,1 @@\n-    \/\/ c_rarg1: object pointer set up above (NULL if static)\n+    \/\/ c_rarg1: object pointer set up above (null if static)\n@@ -3259,1 +3317,1 @@\n-    __ access_store_at(T_BYTE, IN_HEAP, field, rax, noreg, noreg);\n+    __ access_store_at(T_BYTE, IN_HEAP, field, rax, noreg, noreg, noreg);\n@@ -3276,1 +3334,1 @@\n-    __ access_store_at(T_BOOLEAN, IN_HEAP, field, rax, noreg, noreg);\n+    __ access_store_at(T_BOOLEAN, IN_HEAP, field, rax, noreg, noreg, noreg);\n@@ -3313,1 +3371,1 @@\n-    __ access_store_at(T_INT, IN_HEAP, field, rax, noreg, noreg);\n+    __ access_store_at(T_INT, IN_HEAP, field, rax, noreg, noreg, noreg);\n@@ -3330,1 +3388,1 @@\n-    __ access_store_at(T_CHAR, IN_HEAP, field, rax, noreg, noreg);\n+    __ access_store_at(T_CHAR, IN_HEAP, field, rax, noreg, noreg, noreg);\n@@ -3347,1 +3405,1 @@\n-    __ access_store_at(T_SHORT, IN_HEAP, field, rax, noreg, noreg);\n+    __ access_store_at(T_SHORT, IN_HEAP, field, rax, noreg, noreg, noreg);\n@@ -3365,1 +3423,1 @@\n-    __ access_store_at(T_LONG, IN_HEAP | MO_RELAXED, field, noreg \/* ltos*\/, noreg, noreg);\n+    __ access_store_at(T_LONG, IN_HEAP | MO_RELAXED, field, noreg \/* ltos*\/, noreg, noreg, noreg);\n@@ -3384,1 +3442,1 @@\n-    __ access_store_at(T_FLOAT, IN_HEAP, field, noreg \/* ftos *\/, noreg, noreg);\n+    __ access_store_at(T_FLOAT, IN_HEAP, field, noreg \/* ftos *\/, noreg, noreg, noreg);\n@@ -3405,1 +3463,1 @@\n-    __ access_store_at(T_DOUBLE, IN_HEAP | MO_RELAXED, field, noreg \/* dtos *\/, noreg, noreg);\n+    __ access_store_at(T_DOUBLE, IN_HEAP | MO_RELAXED, field, noreg \/* dtos *\/, noreg, noreg, noreg);\n@@ -3548,1 +3606,1 @@\n-    __ access_store_at(T_LONG, IN_HEAP, field, noreg \/* ltos *\/, noreg, noreg);\n+    __ access_store_at(T_LONG, IN_HEAP, field, noreg \/* ltos *\/, noreg, noreg, noreg);\n@@ -3554,1 +3612,1 @@\n-    __ access_store_at(T_INT, IN_HEAP, field, rax, noreg, noreg);\n+    __ access_store_at(T_INT, IN_HEAP, field, rax, noreg, noreg, noreg);\n@@ -3557,1 +3615,1 @@\n-    __ access_store_at(T_BOOLEAN, IN_HEAP, field, rax, noreg, noreg);\n+    __ access_store_at(T_BOOLEAN, IN_HEAP, field, rax, noreg, noreg, noreg);\n@@ -3560,1 +3618,1 @@\n-    __ access_store_at(T_BYTE, IN_HEAP, field, rax, noreg, noreg);\n+    __ access_store_at(T_BYTE, IN_HEAP, field, rax, noreg, noreg, noreg);\n@@ -3563,1 +3621,1 @@\n-    __ access_store_at(T_SHORT, IN_HEAP, field, rax, noreg, noreg);\n+    __ access_store_at(T_SHORT, IN_HEAP, field, rax, noreg, noreg, noreg);\n@@ -3566,1 +3624,1 @@\n-    __ access_store_at(T_CHAR, IN_HEAP, field, rax, noreg, noreg);\n+    __ access_store_at(T_CHAR, IN_HEAP, field, rax, noreg, noreg, noreg);\n@@ -3569,1 +3627,1 @@\n-    __ access_store_at(T_FLOAT, IN_HEAP, field, noreg \/* ftos*\/, noreg, noreg);\n+    __ access_store_at(T_FLOAT, IN_HEAP, field, noreg \/* ftos*\/, noreg, noreg, noreg);\n@@ -3572,1 +3630,1 @@\n-    __ access_store_at(T_DOUBLE, IN_HEAP, field, noreg \/* dtos*\/, noreg, noreg);\n+    __ access_store_at(T_DOUBLE, IN_HEAP, field, noreg \/* dtos*\/, noreg, noreg, noreg);\n@@ -3744,1 +3802,1 @@\n-  if (is_invokedynamic || is_invokehandle) {\n+  if (is_invokehandle) {\n@@ -3783,3 +3841,6 @@\n-    LP64_ONLY(__ lea(rscratch1, table));\n-    LP64_ONLY(__ movptr(flags, Address(rscratch1, flags, Address::times_ptr)));\n-    NOT_LP64(__ movptr(flags, ArrayAddress(table, Address(noreg, flags, Address::times_ptr))));\n+#ifdef _LP64\n+    __ lea(rscratch1, table);\n+    __ movptr(flags, Address(rscratch1, flags, Address::times_ptr));\n+#else\n+    __ movptr(flags, ArrayAddress(table, Address(noreg, flags, Address::times_ptr)));\n+#endif \/\/ _LP64\n@@ -3832,3 +3893,1 @@\n-  __ null_check(recv, oopDesc::klass_offset_in_bytes());\n-  Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n-  __ load_klass(rax, recv, tmp_load_klass);\n+  __ load_klass(rax, recv, rscratch1);\n@@ -3925,3 +3984,1 @@\n-  __ null_check(rcx, oopDesc::klass_offset_in_bytes());\n-  Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n-  __ load_klass(rlocals, rcx, tmp_load_klass);\n+  __ load_klass(rlocals, rcx, rscratch1);\n@@ -3949,2 +4006,1 @@\n-  __ null_check(rcx, oopDesc::klass_offset_in_bytes());\n-  __ load_klass(rdx, rcx, tmp_load_klass);\n+  __ load_klass(rdx, rcx, rscratch1);\n@@ -4069,2 +4125,1 @@\n-  prepare_invoke(byte_no, rbx_method, rax_callsite);\n-\n+  load_invokedynamic_entry(rbx_method);\n@@ -4096,1 +4151,0 @@\n-  Label initialize_object;  \/\/ including clearing the fields\n@@ -4126,5 +4180,0 @@\n-  \/\/  Else If inline contiguous allocations are enabled:\n-  \/\/    Try to allocate in eden.\n-  \/\/    If fails due to heap end, go to slow path.\n-  \/\/\n-  \/\/  If TLAB is enabled OR inline contiguous is enabled:\n@@ -4136,8 +4185,0 @@\n-  const bool allow_shared_alloc =\n-    Universe::heap()->supports_inline_contig_alloc();\n-\n-#ifndef _LP64\n-  if (UseTLAB || allow_shared_alloc) {\n-    __ get_thread(thread);\n-  }\n-#endif \/\/ _LP64\n@@ -4147,0 +4188,1 @@\n+    NOT_LP64(__ get_thread(thread);)\n@@ -4151,12 +4193,0 @@\n-    } else {\n-      \/\/ initialize both the header and fields\n-      __ jmp(initialize_object);\n-  } else {\n-    \/\/ Allocation in the shared Eden, if allowed.\n-    \/\/\n-    \/\/ rdx: instance size in bytes\n-    __ eden_allocate(thread, rax, rdx, 0, rbx, slow_case);\n-  }\n-  \/\/ If UseTLAB or allow_shared_alloc are true, the object is created above and\n-  \/\/ there is an initialize need. Otherwise, skip and go to the slow path.\n-  if (UseTLAB || allow_shared_alloc) {\n@@ -4167,1 +4197,0 @@\n-    __ bind(initialize_object);\n@@ -4198,9 +4227,3 @@\n-    if (UseBiasedLocking) {\n-      __ pop(rcx);   \/\/ get saved klass back in the register.\n-      __ movptr(rbx, Address(rcx, Klass::prototype_header_offset()));\n-      __ movptr(Address(rax, oopDesc::mark_offset_in_bytes ()), rbx);\n-    } else {\n-      __ movptr(Address(rax, oopDesc::mark_offset_in_bytes ()),\n-                (intptr_t)markWord::prototype().value()); \/\/ header\n-      __ pop(rcx);   \/\/ get saved klass back in the register.\n-    }\n+    __ movptr(Address(rax, oopDesc::mark_offset_in_bytes()),\n+              (intptr_t)markWord::prototype().value()); \/\/ header\n+    __ pop(rcx);   \/\/ get saved klass back in the register.\n@@ -4211,2 +4234,1 @@\n-    Register tmp_store_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n-    __ store_klass(rax, rcx, tmp_store_klass);  \/\/ klass\n+    __ store_klass(rax, rcx, rscratch1);  \/\/ klass\n@@ -4215,1 +4237,1 @@\n-      SkipIfEqual skip_if(_masm, &DTraceAllocProbes, 0);\n+      SkipIfEqual skip_if(_masm, &DTraceAllocProbes, 0, rscratch1);\n@@ -4219,1 +4241,1 @@\n-           CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_object_alloc), rax);\n+           CAST_FROM_FN_PTR(address, static_cast<int (*)(oopDesc*)>(SharedRuntime::dtrace_object_alloc)), rax);\n@@ -4273,1 +4295,0 @@\n-  __ null_check(rax, arrayOopDesc::length_offset_in_bytes());\n@@ -4314,2 +4335,1 @@\n-  Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n-  __ load_klass(rbx, rdx, tmp_load_klass);\n+  __ load_klass(rbx, rdx, rscratch1);\n@@ -4330,1 +4350,1 @@\n-  \/\/ Collect counts on whether this check-cast sees NULLs a lot or not.\n+  \/\/ Collect counts on whether this check-cast sees nulls a lot or not.\n@@ -4372,2 +4392,1 @@\n-  Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n-  __ load_klass(rdx, rdx, tmp_load_klass);\n+  __ load_klass(rdx, rdx, rscratch1);\n@@ -4378,1 +4397,1 @@\n-  __ load_klass(rdx, rax, tmp_load_klass);\n+  __ load_klass(rdx, rax, rscratch1);\n@@ -4394,1 +4413,1 @@\n-  \/\/ Collect counts on whether this test sees NULLs a lot or not.\n+  \/\/ Collect counts on whether this test sees nulls a lot or not.\n@@ -4403,2 +4422,2 @@\n-  \/\/ rax = 0: obj == NULL or  obj is not an instanceof the specified klass\n-  \/\/ rax = 1: obj != NULL and obj is     an instanceof the specified klass\n+  \/\/ rax = 0: obj == nullptr or  obj is not an instanceof the specified klass\n+  \/\/ rax = 1: obj != nullptr and obj is     an instanceof the specified klass\n@@ -4466,1 +4485,1 @@\n-  \/\/ check for NULL object\n+  \/\/ check for null object\n@@ -4482,1 +4501,1 @@\n-  __ xorl(rmon, rmon); \/\/ points to free slot or NULL\n+  __ xorl(rmon, rmon); \/\/ points to free slot or null\n@@ -4495,1 +4514,1 @@\n-    __ cmpptr(Address(rtop, BasicObjectLock::obj_offset_in_bytes()), (int32_t) NULL_WORD);\n+    __ cmpptr(Address(rtop, BasicObjectLock::obj_offset()), NULL_WORD);\n@@ -4499,1 +4518,1 @@\n-    __ cmpptr(rax, Address(rtop, BasicObjectLock::obj_offset_in_bytes()));\n+    __ cmpptr(rax, Address(rtop, BasicObjectLock::obj_offset()));\n@@ -4543,1 +4562,1 @@\n-  \/\/ The object has already been poped from the stack, so the\n+  \/\/ The object has already been popped from the stack, so the\n@@ -4548,1 +4567,1 @@\n-  __ movptr(Address(rmon, BasicObjectLock::obj_offset_in_bytes()), rax);\n+  __ movptr(Address(rmon, BasicObjectLock::obj_offset()), rax);\n@@ -4563,1 +4582,1 @@\n-  \/\/ check for NULL object\n+  \/\/ check for null object\n@@ -4588,1 +4607,1 @@\n-    __ cmpptr(rax, Address(rtop, BasicObjectLock::obj_offset_in_bytes()));\n+    __ cmpptr(rax, Address(rtop, BasicObjectLock::obj_offset()));\n@@ -4617,1 +4636,1 @@\n-  __ jump(ArrayAddress(wtable, Address(noreg, rbx, Address::times_ptr)));\n+  __ jump(ArrayAddress(wtable, Address(noreg, rbx, Address::times_ptr)), rscratch1);\n","filename":"src\/hotspot\/cpu\/x86\/templateTable_x86.cpp","additions":186,"deletions":167,"binary":false,"changes":353,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,4 +25,1 @@\n-\n-#include \"jvm.h\"\n-#ifdef LINUX\n-#endif\n+#include \"jvm.h\"\n@@ -36,1 +33,0 @@\n-#include \"utilities\/globalDefinitions.hpp\"\n@@ -46,0 +42,1 @@\n+#include \"runtime\/park.hpp\"\n@@ -48,0 +45,1 @@\n+#include \"utilities\/defaultStream.hpp\"\n@@ -50,0 +48,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -52,0 +51,6 @@\n+#ifdef AIX\n+#include \"loadlib_aix.hpp\"\n+#endif\n+#ifdef LINUX\n+#include \"os_linux.hpp\"\n+#endif\n@@ -56,0 +61,1 @@\n+#include <locale.h>\n@@ -63,0 +69,3 @@\n+#include <spawn.h>\n+#include <sys\/time.h>\n+#include <sys\/times.h>\n@@ -90,0 +99,7 @@\n+static jlong initial_time_count = 0;\n+\n+static int clock_tics_per_sec = 100;\n+\n+\/\/ Platform minimum stack allowed\n+size_t os::_os_min_stack_allowed = PTHREAD_STACK_MIN;\n+\n@@ -127,1 +143,1 @@\n-        jio_snprintf(buffer, bufferSize, \"%s (max size \" UINT64_FORMAT \" kB). To ensure a full core dump, try \\\"ulimit -c unlimited\\\" before starting Java again\", core_path, uint64_t(rlim.rlim_cur) \/ 1024);\n+        jio_snprintf(buffer, bufferSize, \"%s (max size \" UINT64_FORMAT \" k). To ensure a full core dump, try \\\"ulimit -c unlimited\\\" before starting Java again\", core_path, uint64_t(rlim.rlim_cur) \/ K);\n@@ -146,2 +162,2 @@\n-    if (fr.fp() == NULL || fr.cb() != NULL ||\n-        fr.sender_pc() == NULL || os::is_first_C_frame(&fr)) break;\n+    if (fr.fp() == nullptr || fr.cb() != nullptr ||\n+        fr.sender_pc() == nullptr || os::is_first_C_frame(&fr)) break;\n@@ -157,1 +173,1 @@\n-    stack[frame_idx] = NULL;\n+    stack[frame_idx] = nullptr;\n@@ -163,6 +179,0 @@\n-\n-bool os::unsetenv(const char* name) {\n-  assert(name != NULL, \"Null pointer\");\n-  return (::unsetenv(name) == 0);\n-}\n-\n@@ -186,0 +196,6 @@\n+\/\/ Return true if user is running as root.\n+bool os::have_special_privileges() {\n+  static bool privileges = (getuid() != geteuid()) || (getgid() != getegid());\n+  return privileges;\n+}\n+\n@@ -196,1 +212,1 @@\n-  if (native_dir == NULL) {\n+  if (native_dir == nullptr) {\n@@ -211,1 +227,1 @@\n-    if (fullname == NULL) {\n+    if (fullname == nullptr) {\n@@ -239,0 +255,19 @@\n+\/\/ Is a (classpath) directory empty?\n+bool os::dir_is_empty(const char* path) {\n+  DIR *dir = nullptr;\n+  struct dirent *ptr;\n+\n+  dir = ::opendir(path);\n+  if (dir == nullptr) return true;\n+\n+  \/\/ Scan the directory\n+  bool result = true;\n+  while (result && (ptr = ::readdir(dir)) != nullptr) {\n+    if (strcmp(ptr->d_name, \".\") != 0 && strcmp(ptr->d_name, \"..\") != 0) {\n+      result = false;\n+    }\n+  }\n+  ::closedir(dir);\n+  return result;\n+}\n+\n@@ -242,1 +277,1 @@\n-  if (requested_addr != NULL) {\n+  if (requested_addr != nullptr) {\n@@ -257,1 +292,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -287,1 +322,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -292,1 +327,1 @@\n-  if (base != NULL) {\n+  if (base != nullptr) {\n@@ -299,1 +334,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -301,1 +336,1 @@\n-  if (base != NULL && addr != base) {\n+  if (base != nullptr && addr != base) {\n@@ -305,1 +340,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -312,1 +347,1 @@\n-  assert(base != NULL, \"Base cannot be NULL\");\n+  assert(base != nullptr, \"Base cannot be null\");\n@@ -359,2 +394,2 @@\n-  if (extra_base == NULL) {\n-    return NULL;\n+  if (extra_base == nullptr) {\n+    return nullptr;\n@@ -373,3 +408,3 @@\n-  char* extra_base = reserve_mmapped_memory(extra_size, NULL);\n-  if (extra_base == NULL) {\n-    return NULL;\n+  char* extra_base = reserve_mmapped_memory(extra_size, nullptr);\n+  if (extra_base == nullptr) {\n+    return nullptr;\n@@ -379,1 +414,1 @@\n-  if (replace_existing_mapping_with_file_mapping(aligned_base, size, file_desc) == NULL) {\n+  if (replace_existing_mapping_with_file_mapping(aligned_base, size, file_desc) == nullptr) {\n@@ -388,1 +423,1 @@\n-  int result = ::vsnprintf(buf, len, fmt, args);\n+  ALLOW_C_FUNCTION(::vsnprintf, int result = ::vsnprintf(buf, len, fmt, args);)\n@@ -422,1 +457,1 @@\n-  int currsec = time(NULL);\n+  int currsec = time(nullptr);\n@@ -449,1 +484,1 @@\n-      if (output_k) { st->print(UINT64_FORMAT \"k\", uint64_t(rlim.rlim_cur) \/ 1024); }\n+      if (output_k) { st->print(UINT64_FORMAT \"k\", uint64_t(rlim.rlim_cur) \/ K); }\n@@ -456,1 +491,1 @@\n-      if (output_k) { st->print(UINT64_FORMAT \"k\", uint64_t(rlim.rlim_max) \/ 1024); }\n+      if (output_k) { st->print(UINT64_FORMAT \"k\", uint64_t(rlim.rlim_max) \/ K); }\n@@ -525,1 +560,1 @@\n-void os::Posix::print_user_info(outputStream* st) {\n+void os::print_user_info(outputStream* st) {\n@@ -539,1 +574,1 @@\n-  print_umask(st, umsk);\n+  os::Posix::print_umask(st, umsk);\n@@ -544,0 +579,35 @@\n+\/\/ Print all active locale categories, one line each\n+void os::print_active_locale(outputStream* st) {\n+  st->print_cr(\"Active Locale:\");\n+  \/\/ Posix is quiet about how exactly LC_ALL is implemented.\n+  \/\/ Just print it out too, in case LC_ALL is held separately\n+  \/\/ from the individual categories.\n+  #define LOCALE_CAT_DO(f) \\\n+    f(LC_ALL) \\\n+    f(LC_COLLATE) \\\n+    f(LC_CTYPE) \\\n+    f(LC_MESSAGES) \\\n+    f(LC_MONETARY) \\\n+    f(LC_NUMERIC) \\\n+    f(LC_TIME)\n+  #define XX(cat) { cat, #cat },\n+  const struct { int c; const char* name; } categories[] = {\n+      LOCALE_CAT_DO(XX)\n+      { -1, nullptr }\n+  };\n+  #undef XX\n+  #undef LOCALE_CAT_DO\n+  for (int i = 0; categories[i].c != -1; i ++) {\n+    const char* locale = setlocale(categories[i].c, nullptr);\n+    st->print_cr(\"%s=%s\", categories[i].name,\n+                 ((locale != nullptr) ? locale : \"<unknown>\"));\n+  }\n+}\n+\n+void os::print_jni_name_prefix_on(outputStream* st, int args_size) {\n+  \/\/ no prefix required\n+}\n+\n+void os::print_jni_name_suffix_on(outputStream* st, int args_size) {\n+  \/\/ no suffix required\n+}\n@@ -560,1 +630,1 @@\n-  void* p = ::mmap(NULL, s, PROT_NONE,\n+  void* p = ::mmap(nullptr, s, PROT_NONE,\n@@ -659,0 +729,15 @@\n+void* os::get_default_process_handle() {\n+#ifdef __APPLE__\n+  \/\/ MacOS X needs to use RTLD_FIRST instead of RTLD_LAZY\n+  \/\/ to avoid finding unexpected symbols on second (or later)\n+  \/\/ loads of a library.\n+  return (void*)::dlopen(nullptr, RTLD_FIRST);\n+#else\n+  return (void*)::dlopen(nullptr, RTLD_LAZY);\n+#endif\n+}\n+\n+void* os::dll_lookup(void* handle, const char* name) {\n+  return dlsym(handle, name);\n+}\n+\n@@ -660,1 +745,34 @@\n-  ::dlclose(lib);\n+  \/\/ os::Linux::dll_path returns a pointer to a string that is owned by the dynamic loader. Upon\n+  \/\/ calling dlclose the dynamic loader may free the memory containing the string, thus we need to\n+  \/\/ copy the string to be able to reference it after dlclose.\n+  const char* l_path = nullptr;\n+#ifdef LINUX\n+  char* l_pathdup = nullptr;\n+  l_path = os::Linux::dll_path(lib);\n+  if (l_path != nullptr) {\n+    l_path = l_pathdup = os::strdup(l_path);\n+  }\n+#endif  \/\/ LINUX\n+  if (l_path == nullptr) {\n+    l_path = \"<not available>\";\n+  }\n+  int res = ::dlclose(lib);\n+\n+  if (res == 0) {\n+    Events::log_dll_message(nullptr, \"Unloaded shared library \\\"%s\\\" [\" INTPTR_FORMAT \"]\",\n+                            l_path, p2i(lib));\n+    log_info(os)(\"Unloaded shared library \\\"%s\\\" [\" INTPTR_FORMAT \"]\", l_path, p2i(lib));\n+  } else {\n+    const char* error_report = ::dlerror();\n+    if (error_report == nullptr) {\n+      error_report = \"dlerror returned no error description\";\n+    }\n+\n+    Events::log_dll_message(nullptr, \"Attempt to unload shared library \\\"%s\\\" [\" INTPTR_FORMAT \"] failed, %s\",\n+                            l_path, p2i(lib), error_report);\n+    log_info(os)(\"Attempt to unload shared library \\\"%s\\\" [\" INTPTR_FORMAT \"] failed, %s\",\n+                  l_path, p2i(lib), error_report);\n+  }\n+  \/\/ Update the dll cache\n+  AIX_ONLY(LoadedLibraries::reload());\n+  LINUX_ONLY(os::free(l_pathdup));\n@@ -667,4 +785,0 @@\n-int os::fsync(int fd) {\n-  return ::fsync(fd);\n-}\n-\n@@ -679,1 +793,1 @@\n-FILE* os::open(int fd, const char* mode) {\n+FILE* os::fdopen(int fd, const char* mode) {\n@@ -683,3 +797,3 @@\n-size_t os::write(int fd, const void *buf, unsigned int nBytes) {\n-  size_t res;\n-  RESTARTABLE((size_t) ::write(fd, buf, (size_t) nBytes), res);\n+ssize_t os::pd_write(int fd, const void *buf, size_t nBytes) {\n+  ssize_t res;\n+  RESTARTABLE(::write(fd, buf, nBytes), res);\n@@ -693,4 +807,0 @@\n-int os::close(int fd) {\n-  return ::close(fd);\n-}\n-\n@@ -706,1 +816,1 @@\n-  assert(dirname != NULL, \"just checking\");\n+  assert(dirname != nullptr, \"just checking\");\n@@ -711,1 +821,1 @@\n-  assert(dirp != NULL, \"just checking\");\n+  assert(dirp != nullptr, \"just checking\");\n@@ -716,1 +826,1 @@\n-  assert(dirp != NULL, \"just checking\");\n+  assert(dirp != nullptr, \"just checking\");\n@@ -724,4 +834,0 @@\n-int os::socket(int domain, int type, int protocol) {\n-  return ::socket(domain, type, protocol);\n-}\n-\n@@ -744,2 +850,2 @@\n-struct hostent* os::get_host_by_name(char* name) {\n-  return ::gethostbyname(name);\n+void os::exit(int num) {\n+  ALLOW_C_FUNCTION(::exit, ::exit(num);)\n@@ -748,2 +854,2 @@\n-void os::exit(int num) {\n-  ::exit(num);\n+void os::_exit(int num) {\n+  ALLOW_C_FUNCTION(::_exit, ::_exit(num);)\n@@ -756,1 +862,1 @@\n-\/\/            lib_name: Name of library to look in, NULL for shared libs.\n+\/\/            lib_name: Name of library to look in, null for shared libs.\n@@ -770,1 +876,1 @@\n-  if (lib_name != NULL) {\n+  if (lib_name != nullptr) {\n@@ -774,1 +880,1 @@\n-      if ((start = strrchr(lib_name, *os::file_separator())) != NULL) {\n+      if ((start = strrchr(lib_name, *os::file_separator())) != nullptr) {\n@@ -778,1 +884,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -784,1 +890,1 @@\n-  len = (lib_name != NULL ? name_len : 0) + strlen(sym_name) + 2;\n+  len = (lib_name != nullptr ? name_len : 0) + strlen(sym_name) + 2;\n@@ -786,2 +892,2 @@\n-  if (agent_entry_name == NULL) {\n-    return NULL;\n+  if (agent_entry_name == nullptr) {\n+    return nullptr;\n@@ -790,1 +896,1 @@\n-  if (lib_name != NULL) {\n+  if (lib_name != nullptr) {\n@@ -797,0 +903,6 @@\n+\/\/ Sleep forever; naked call to OS-specific sleep; use with CAUTION\n+void os::infinite_sleep() {\n+  while (true) {    \/\/ sleep forever ...\n+    ::sleep(100);   \/\/ ... 100 seconds at a time\n+  }\n+}\n@@ -803,1 +915,1 @@\n-  ::nanosleep(&req, NULL);\n+  ::nanosleep(&req, nullptr);\n@@ -819,2 +931,2 @@\n-  \/\/ Work around linux NPTL implementation error, see also os::create_thread() in os_linux.cpp.\n-  LINUX_ONLY(stack_size -= guard_size);\n+  \/\/ Work around glibc stack guard issue, see os::create_thread() in os_linux.cpp.\n+  LINUX_ONLY(if (os::Linux::adjustStackSizeForGuardPages()) stack_size -= guard_size;)\n@@ -823,1 +935,1 @@\n-    stack_size \/ 1024, guard_size \/ 1024,\n+    stack_size \/ K, guard_size \/ K,\n@@ -830,1 +942,1 @@\n-  if (filename == NULL || outbuf == NULL || outbuflen < 1) {\n+  if (filename == nullptr || outbuf == nullptr || outbuflen < 1) {\n@@ -833,1 +945,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -836,1 +948,1 @@\n-  char* result = NULL;\n+  char* result = nullptr;\n@@ -839,1 +951,1 @@\n-  \/\/ POSIX.1-2008 allows to specify NULL for the output buffer, in which case\n+  \/\/ POSIX.1-2008 allows to specify null for the output buffer, in which case\n@@ -841,2 +953,2 @@\n-  char* p = ::realpath(filename, NULL);\n-  if (p != NULL) {\n+  ALLOW_C_FUNCTION(::realpath, char* p = ::realpath(filename, nullptr);)\n+  if (p != nullptr) {\n@@ -849,1 +961,1 @@\n-    ::free(p); \/\/ *not* os::free\n+    ALLOW_C_FUNCTION(::free, ::free(p);) \/\/ *not* os::free\n@@ -853,1 +965,1 @@\n-    \/\/ that it complains about the NULL we handed down as user buffer.\n+    \/\/ that it complains about the null we handed down as user buffer.\n@@ -858,2 +970,2 @@\n-      p = ::realpath(filename, outbuf);\n-      if (p != NULL) {\n+      ALLOW_C_FUNCTION(::realpath, p = ::realpath(filename, outbuf);)\n+      if (p != nullptr) {\n@@ -909,67 +1021,0 @@\n-\/\/ Check minimum allowable stack sizes for thread creation and to initialize\n-\/\/ the java system classes, including StackOverflowError - depends on page\n-\/\/ size.\n-\/\/ The space needed for frames during startup is platform dependent. It\n-\/\/ depends on word size, platform calling conventions, C frame layout and\n-\/\/ interpreter\/C1\/C2 design decisions. Therefore this is given in a\n-\/\/ platform (os\/cpu) dependent constant.\n-\/\/ To this, space for guard mechanisms is added, which depends on the\n-\/\/ page size which again depends on the concrete system the VM is running\n-\/\/ on. Space for libc guard pages is not included in this size.\n-jint os::Posix::set_minimum_stack_sizes() {\n-  size_t os_min_stack_allowed = PTHREAD_STACK_MIN;\n-\n-  _java_thread_min_stack_allowed = _java_thread_min_stack_allowed +\n-                                   StackOverflow::stack_guard_zone_size() +\n-                                   StackOverflow::stack_shadow_zone_size();\n-\n-  _java_thread_min_stack_allowed = align_up(_java_thread_min_stack_allowed, vm_page_size());\n-  _java_thread_min_stack_allowed = MAX2(_java_thread_min_stack_allowed, os_min_stack_allowed);\n-\n-  size_t stack_size_in_bytes = ThreadStackSize * K;\n-  if (stack_size_in_bytes != 0 &&\n-      stack_size_in_bytes < _java_thread_min_stack_allowed) {\n-    \/\/ The '-Xss' and '-XX:ThreadStackSize=N' options both set\n-    \/\/ ThreadStackSize so we go with \"Java thread stack size\" instead\n-    \/\/ of \"ThreadStackSize\" to be more friendly.\n-    tty->print_cr(\"\\nThe Java thread stack size specified is too small. \"\n-                  \"Specify at least \" SIZE_FORMAT \"k\",\n-                  _java_thread_min_stack_allowed \/ K);\n-    return JNI_ERR;\n-  }\n-\n-  \/\/ Make the stack size a multiple of the page size so that\n-  \/\/ the yellow\/red zones can be guarded.\n-  JavaThread::set_stack_size_at_create(align_up(stack_size_in_bytes, vm_page_size()));\n-\n-  \/\/ Reminder: a compiler thread is a Java thread.\n-  _compiler_thread_min_stack_allowed = _compiler_thread_min_stack_allowed +\n-                                       StackOverflow::stack_guard_zone_size() +\n-                                       StackOverflow::stack_shadow_zone_size();\n-\n-  _compiler_thread_min_stack_allowed = align_up(_compiler_thread_min_stack_allowed, vm_page_size());\n-  _compiler_thread_min_stack_allowed = MAX2(_compiler_thread_min_stack_allowed, os_min_stack_allowed);\n-\n-  stack_size_in_bytes = CompilerThreadStackSize * K;\n-  if (stack_size_in_bytes != 0 &&\n-      stack_size_in_bytes < _compiler_thread_min_stack_allowed) {\n-    tty->print_cr(\"\\nThe CompilerThreadStackSize specified is too small. \"\n-                  \"Specify at least \" SIZE_FORMAT \"k\",\n-                  _compiler_thread_min_stack_allowed \/ K);\n-    return JNI_ERR;\n-  }\n-\n-  _vm_internal_thread_min_stack_allowed = align_up(_vm_internal_thread_min_stack_allowed, vm_page_size());\n-  _vm_internal_thread_min_stack_allowed = MAX2(_vm_internal_thread_min_stack_allowed, os_min_stack_allowed);\n-\n-  stack_size_in_bytes = VMThreadStackSize * K;\n-  if (stack_size_in_bytes != 0 &&\n-      stack_size_in_bytes < _vm_internal_thread_min_stack_allowed) {\n-    tty->print_cr(\"\\nThe VMThreadStackSize specified is too small. \"\n-                  \"Specify at least \" SIZE_FORMAT \"k\",\n-                  _vm_internal_thread_min_stack_allowed \/ K);\n-    return JNI_ERR;\n-  }\n-  return JNI_OK;\n-}\n-\n@@ -1005,2 +1050,1 @@\n-  case os::pgc_thread:\n-  case os::cgc_thread:\n+  case os::gc_thread:\n@@ -1049,1 +1093,1 @@\n-    if (cb == NULL || !cb->is_nmethod() || cb->is_frame_complete_at(pc)) {\n+    if (cb == nullptr || !cb->is_nmethod() || cb->is_frame_complete_at(pc)) {\n@@ -1078,1 +1122,2 @@\n-      if (overflow_state->in_stack_reserved_zone(addr)) {\n+      \/\/ vthreads don't support this\n+      if (!thread->is_vthread_mounted() && overflow_state->in_stack_reserved_zone(addr)) {\n@@ -1084,1 +1129,1 @@\n-          if (activation.sp() != NULL) {\n+          if (activation.sp() != nullptr) {\n@@ -1101,1 +1146,1 @@\n-      \/\/ Throw a stack overflow exception.  Guard pages will be reenabled\n+      \/\/ Throw a stack overflow exception.  Guard pages will be re-enabled\n@@ -1111,2 +1156,2 @@\n-    \/\/ Fatal red zone violation.  Disable the guard pages and fall through\n-    \/\/ to handle_unexpected_exception way down below.\n+    \/\/ Fatal red zone violation. Disable the guard pages and keep\n+    \/\/ on handling the signal.\n@@ -1122,2 +1167,2 @@\n-#if !defined(AIX) && !defined(__APPLE__)\n-    \/\/ bsd and aix don't have this\n+#ifdef LINUX\n+    \/\/ This only works with os::Linux::manually_expand_stack()\n@@ -1141,1 +1186,1 @@\n-#endif \/\/ AIX or BSD\n+#endif \/\/ LINUX\n@@ -1159,56 +1204,0 @@\n-Thread* os::ThreadCrashProtection::_protected_thread = NULL;\n-os::ThreadCrashProtection* os::ThreadCrashProtection::_crash_protection = NULL;\n-\n-os::ThreadCrashProtection::ThreadCrashProtection() {\n-  _protected_thread = Thread::current();\n-  assert(_protected_thread->is_JfrSampler_thread(), \"should be JFRSampler\");\n-}\n-\n-\/*\n- * See the caveats for this class in os_posix.hpp\n- * Protects the callback call so that SIGSEGV \/ SIGBUS jumps back into this\n- * method and returns false. If none of the signals are raised, returns true.\n- * The callback is supposed to provide the method that should be protected.\n- *\/\n-bool os::ThreadCrashProtection::call(os::CrashProtectionCallback& cb) {\n-  sigset_t saved_sig_mask;\n-\n-  \/\/ we cannot rely on sigsetjmp\/siglongjmp to save\/restore the signal mask\n-  \/\/ since on at least some systems (OS X) siglongjmp will restore the mask\n-  \/\/ for the process, not the thread\n-  pthread_sigmask(0, NULL, &saved_sig_mask);\n-  if (sigsetjmp(_jmpbuf, 0) == 0) {\n-    \/\/ make sure we can see in the signal handler that we have crash protection\n-    \/\/ installed\n-    _crash_protection = this;\n-    cb.call();\n-    \/\/ and clear the crash protection\n-    _crash_protection = NULL;\n-    _protected_thread = NULL;\n-    return true;\n-  }\n-  \/\/ this happens when we siglongjmp() back\n-  pthread_sigmask(SIG_SETMASK, &saved_sig_mask, NULL);\n-  _crash_protection = NULL;\n-  _protected_thread = NULL;\n-  return false;\n-}\n-\n-void os::ThreadCrashProtection::restore() {\n-  assert(_crash_protection != NULL, \"must have crash protection\");\n-  siglongjmp(_jmpbuf, 1);\n-}\n-\n-void os::ThreadCrashProtection::check_crash_protection(int sig,\n-    Thread* thread) {\n-\n-  if (thread != NULL &&\n-      thread == _protected_thread &&\n-      _crash_protection != NULL) {\n-\n-    if (sig == SIGSEGV || sig == SIGBUS) {\n-      _crash_protection->restore();\n-    }\n-  }\n-}\n-\n@@ -1241,1 +1230,1 @@\n-  os::PlatformMutex::init();\n+  PlatformMutex::init();\n@@ -1244,1 +1233,1 @@\n-static int (*_pthread_condattr_setclock)(pthread_condattr_t *, clockid_t) = NULL;\n+static int (*_pthread_condattr_setclock)(pthread_condattr_t *, clockid_t) = nullptr;\n@@ -1251,1 +1240,5 @@\n-\n+#if defined(_ALLBSD_SOURCE)\n+  clock_tics_per_sec = CLK_TCK;\n+#else\n+  clock_tics_per_sec = sysconf(_SC_CLK_TCK);\n+#endif\n@@ -1261,1 +1254,1 @@\n-  if (condattr_setclock_func != NULL) {\n+  if (condattr_setclock_func != nullptr) {\n@@ -1270,1 +1263,1 @@\n-  if (_pthread_condattr_setclock != NULL) {\n+  if (_pthread_condattr_setclock != nullptr) {\n@@ -1283,0 +1276,2 @@\n+\n+  initial_time_count = javaTimeNanos();\n@@ -1288,1 +1283,1 @@\n-               (_pthread_condattr_setclock != NULL ? \"\" : \" not\"));\n+               (_pthread_condattr_setclock != nullptr ? \"\" : \" not\"));\n@@ -1450,1 +1445,0 @@\n-\n@@ -1453,2 +1447,45 @@\n-\/\/ Shared pthread_mutex\/cond based PlatformEvent implementation.\n-\/\/ Not currently usable by Solaris.\n+\/\/ Time since start-up in seconds to a fine granularity.\n+double os::elapsedTime() {\n+  return ((double)os::elapsed_counter()) \/ os::elapsed_frequency(); \/\/ nanosecond resolution\n+}\n+\n+jlong os::elapsed_counter() {\n+  return os::javaTimeNanos() - initial_time_count;\n+}\n+\n+jlong os::elapsed_frequency() {\n+  return NANOSECS_PER_SEC; \/\/ nanosecond resolution\n+}\n+\n+bool os::supports_vtime() { return true; }\n+\n+\/\/ Return the real, user, and system times in seconds from an\n+\/\/ arbitrary fixed point in the past.\n+bool os::getTimesSecs(double* process_real_time,\n+                      double* process_user_time,\n+                      double* process_system_time) {\n+  struct tms ticks;\n+  clock_t real_ticks = times(&ticks);\n+\n+  if (real_ticks == (clock_t) (-1)) {\n+    return false;\n+  } else {\n+    double ticks_per_second = (double) clock_tics_per_sec;\n+    *process_user_time = ((double) ticks.tms_utime) \/ ticks_per_second;\n+    *process_system_time = ((double) ticks.tms_stime) \/ ticks_per_second;\n+    *process_real_time = ((double) real_ticks) \/ ticks_per_second;\n+\n+    return true;\n+  }\n+}\n+\n+char * os::local_time_string(char *buf, size_t buflen) {\n+  struct tm t;\n+  time_t long_time;\n+  time(&long_time);\n+  localtime_r(&long_time, &t);\n+  jio_snprintf(buf, buflen, \"%d-%02d-%02d %02d:%02d:%02d\",\n+               t.tm_year + 1900, t.tm_mon + 1, t.tm_mday,\n+               t.tm_hour, t.tm_min, t.tm_sec);\n+  return buf;\n+}\n@@ -1456,0 +1493,3 @@\n+struct tm* os::localtime_pd(const time_t* clock, struct tm*  res) {\n+  return localtime_r(clock, res);\n+}\n@@ -1472,1 +1512,1 @@\n-os::PlatformEvent::PlatformEvent() {\n+PlatformEvent::PlatformEvent() {\n@@ -1481,1 +1521,1 @@\n-void os::PlatformEvent::park() {       \/\/ AKA \"down()\"\n+void PlatformEvent::park() {       \/\/ AKA \"down()\"\n@@ -1523,1 +1563,7 @@\n-int os::PlatformEvent::park(jlong millis) {\n+int PlatformEvent::park(jlong millis) {\n+  return park_nanos(millis_to_nanos_bounded(millis));\n+}\n+\n+int PlatformEvent::park_nanos(jlong nanos) {\n+  assert(nanos > 0, \"nanos are positive\");\n+\n@@ -1543,1 +1589,1 @@\n-    to_abstime(&abst, millis_to_nanos_bounded(millis), false, false);\n+    to_abstime(&abst, nanos, false, false);\n@@ -1555,3 +1601,1 @@\n-      \/\/ OS-level \"spurious wakeups\" are ignored unless the archaic\n-      \/\/ FilterSpuriousWakeups is set false. That flag should be obsoleted.\n-      if (!FilterSpuriousWakeups) break;\n+      \/\/ OS-level \"spurious wakeups\" are ignored\n@@ -1577,1 +1621,1 @@\n-void os::PlatformEvent::unpark() {\n+void PlatformEvent::unpark() {\n@@ -1620,1 +1664,1 @@\n- os::PlatformParker::PlatformParker() : _counter(0), _cur_index(-1) {\n+ PlatformParker::PlatformParker() : _counter(0), _cur_index(-1) {\n@@ -1623,1 +1667,1 @@\n-  status = pthread_cond_init(&_cond[ABS_INDEX], NULL);\n+  status = pthread_cond_init(&_cond[ABS_INDEX], nullptr);\n@@ -1629,1 +1673,1 @@\n-os::PlatformParker::~PlatformParker() {\n+PlatformParker::~PlatformParker() {\n@@ -1751,1 +1795,1 @@\n-os::PlatformMutex::Mutex::Mutex() : _next(NULL) {\n+PlatformMutex::Mutex::Mutex() : _next(nullptr) {\n@@ -1756,1 +1800,1 @@\n-os::PlatformMutex::Mutex::~Mutex() {\n+PlatformMutex::Mutex::~Mutex() {\n@@ -1761,2 +1805,2 @@\n-pthread_mutex_t os::PlatformMutex::_freelist_lock;\n-os::PlatformMutex::Mutex* os::PlatformMutex::_mutex_freelist = NULL;\n+pthread_mutex_t PlatformMutex::_freelist_lock;\n+PlatformMutex::Mutex* PlatformMutex::_mutex_freelist = nullptr;\n@@ -1764,1 +1808,1 @@\n-void os::PlatformMutex::init() {\n+void PlatformMutex::init() {\n@@ -1769,1 +1813,1 @@\n-struct os::PlatformMutex::WithFreeListLocked : public StackObj {\n+struct PlatformMutex::WithFreeListLocked : public StackObj {\n@@ -1781,1 +1825,1 @@\n-os::PlatformMutex::PlatformMutex() {\n+PlatformMutex::PlatformMutex() {\n@@ -1785,1 +1829,1 @@\n-    if (_impl != NULL) {\n+    if (_impl != nullptr) {\n@@ -1787,1 +1831,1 @@\n-      _impl->_next = NULL;\n+      _impl->_next = nullptr;\n@@ -1794,1 +1838,1 @@\n-os::PlatformMutex::~PlatformMutex() {\n+PlatformMutex::~PlatformMutex() {\n@@ -1796,1 +1840,1 @@\n-  assert(_impl->_next == NULL, \"invariant\");\n+  assert(_impl->_next == nullptr, \"invariant\");\n@@ -1801,1 +1845,1 @@\n-os::PlatformMonitor::Cond::Cond() : _next(NULL) {\n+PlatformMonitor::Cond::Cond() : _next(nullptr) {\n@@ -1806,1 +1850,1 @@\n-os::PlatformMonitor::Cond::~Cond() {\n+PlatformMonitor::Cond::~Cond() {\n@@ -1811,1 +1855,1 @@\n-os::PlatformMonitor::Cond* os::PlatformMonitor::_cond_freelist = NULL;\n+PlatformMonitor::Cond* PlatformMonitor::_cond_freelist = nullptr;\n@@ -1813,1 +1857,1 @@\n-os::PlatformMonitor::PlatformMonitor() {\n+PlatformMonitor::PlatformMonitor() {\n@@ -1817,1 +1861,1 @@\n-    if (_impl != NULL) {\n+    if (_impl != nullptr) {\n@@ -1819,1 +1863,1 @@\n-      _impl->_next = NULL;\n+      _impl->_next = nullptr;\n@@ -1826,1 +1870,1 @@\n-os::PlatformMonitor::~PlatformMonitor() {\n+PlatformMonitor::~PlatformMonitor() {\n@@ -1828,1 +1872,1 @@\n-  assert(_impl->_next == NULL, \"invariant\");\n+  assert(_impl->_next == nullptr, \"invariant\");\n@@ -1835,1 +1879,1 @@\n-os::PlatformMutex::PlatformMutex() {\n+PlatformMutex::PlatformMutex() {\n@@ -1840,1 +1884,1 @@\n-os::PlatformMutex::~PlatformMutex() {\n+PlatformMutex::~PlatformMutex() {\n@@ -1845,1 +1889,1 @@\n-os::PlatformMonitor::PlatformMonitor() {\n+PlatformMonitor::PlatformMonitor() {\n@@ -1850,1 +1894,1 @@\n-os::PlatformMonitor::~PlatformMonitor() {\n+PlatformMonitor::~PlatformMonitor() {\n@@ -1858,2 +1902,1 @@\n-int os::PlatformMonitor::wait(jlong millis) {\n-  assert(millis >= 0, \"negative timeout\");\n+int PlatformMonitor::wait(uint64_t millis) {\n@@ -1864,1 +1907,2 @@\n-    \/\/ MAX_SECS anyway, so just do that here.\n+    \/\/ MAX_SECS anyway, so just do that here. This also handles values\n+    \/\/ larger than int64_t max.\n@@ -1866,1 +1910,1 @@\n-      millis = jlong(MAX_SECS) * MILLIUNITS;\n+      millis = uint64_t(MAX_SECS) * MILLIUNITS;\n@@ -1868,1 +1912,1 @@\n-    to_abstime(&abst, millis_to_nanos(millis), false, false);\n+    to_abstime(&abst, millis_to_nanos(int64_t(millis)), false, false);\n@@ -1901,5 +1945,3 @@\n-int os::fork_and_exec(const char* cmd, bool prefer_vfork) {\n-  const char * argv[4] = {\"sh\", \"-c\", cmd, NULL};\n-\n-  pid_t pid ;\n-\n+int os::fork_and_exec(const char* cmd) {\n+  const char* argv[4] = {\"sh\", \"-c\", cmd, nullptr};\n+  pid_t pid = -1;\n@@ -1907,22 +1949,5 @@\n-\n-  \/\/ Use always vfork on AIX, since its safe and helps with analyzing OOM situations.\n-  \/\/ Otherwise leave it up to the caller.\n-  AIX_ONLY(prefer_vfork = true;)\n-  pid = prefer_vfork ? ::vfork() : ::fork();\n-\n-  if (pid < 0) {\n-    \/\/ fork failed\n-    return -1;\n-\n-  } else if (pid == 0) {\n-    \/\/ child process\n-\n-    ::execve(\"\/bin\/sh\", (char* const*)argv, env);\n-\n-    \/\/ execve failed\n-    ::_exit(-1);\n-\n-  } else  {\n-    \/\/ copied from J2SE ..._waitForProcessExit() in UNIXProcess_md.c; we don't\n-    \/\/ care about the actual exit code, for now.\n-\n+  \/\/ Note: cast is needed because posix_spawn() requires - for compatibility with ancient\n+  \/\/ C-code - a non-const argv\/envp pointer array. But it is fine to hand in literal\n+  \/\/ strings and just cast the constness away. See also ProcessImpl_md.c.\n+  int rc = ::posix_spawn(&pid, \"\/bin\/sh\", nullptr, nullptr, (char**) argv, env);\n+  if (rc == 0) {\n@@ -1930,1 +1955,0 @@\n-\n@@ -1940,1 +1964,0 @@\n-\n@@ -1955,0 +1978,3 @@\n+  } else {\n+    \/\/ Don't log, we are inside error handling\n+    return -1;\n@@ -1958,0 +1984,19 @@\n+bool os::message_box(const char* title, const char* message) {\n+  int i;\n+  fdStream err(defaultStream::error_fd());\n+  for (i = 0; i < 78; i++) err.print_raw(\"=\");\n+  err.cr();\n+  err.print_raw_cr(title);\n+  for (i = 0; i < 78; i++) err.print_raw(\"-\");\n+  err.cr();\n+  err.print_raw_cr(message);\n+  for (i = 0; i < 78; i++) err.print_raw(\"=\");\n+  err.cr();\n+\n+  char buf[16];\n+  \/\/ Prevent process from exiting upon \"read error\" without consuming all CPU\n+  while (::read(0, buf, sizeof(buf)) <= 0) { ::sleep(100); }\n+\n+  return buf[0] == 'y' || buf[0] == 'Y';\n+}\n+\n@@ -1977,1 +2022,1 @@\n-  if (abort_hook != NULL) {\n+  if (abort_hook != nullptr) {\n@@ -1996,1 +2041,1 @@\n-  ::_exit(1);\n+  os::_exit(1);\n@@ -2005,3 +2050,3 @@\n-    os::signal_raise(SIGKILL);\n-  } else {\n-    ::abort();\n+    ::raise(SIGKILL);\n+    \/\/ ::raise is not noreturn, even though with SIGKILL it definitely won't\n+    \/\/ return.  Hence \"fall through\" to ::abort, which is declared noreturn.\n@@ -2009,0 +2054,1 @@\n+  ::abort();\n@@ -2010,0 +2056,4 @@\n+\n+const char* os::file_separator() { return \"\/\"; }\n+const char* os::line_separator() { return \"\\n\"; }\n+const char* os::path_separator() { return \":\"; }\n","filename":"src\/hotspot\/os\/posix\/os_posix.cpp","additions":351,"deletions":301,"binary":false,"changes":652,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,1 +26,0 @@\n-#include \"jvm.h\"\n@@ -33,0 +32,1 @@\n+#include \"jvm.h\"\n@@ -35,1 +35,2 @@\n-#include \"os_share_linux.hpp\"\n+#include \"os_linux.hpp\"\n+#include \"os_posix.hpp\"\n@@ -42,0 +43,1 @@\n+#include \"runtime\/javaThread.hpp\"\n@@ -47,1 +49,0 @@\n-#include \"runtime\/thread.inline.hpp\"\n@@ -128,1 +129,1 @@\n-  if (uc != NULL) {\n+  if (uc != nullptr) {\n@@ -133,3 +134,3 @@\n-    epc = NULL;\n-    if (ret_sp) *ret_sp = (intptr_t *)NULL;\n-    if (ret_fp) *ret_fp = (intptr_t *)NULL;\n+    epc = nullptr;\n+    if (ret_sp) *ret_sp = (intptr_t *)nullptr;\n+    if (ret_fp) *ret_fp = (intptr_t *)nullptr;\n@@ -145,0 +146,6 @@\n+  if (!is_readable_pointer(epc)) {\n+    \/\/ Try to recover from calling into bad memory\n+    \/\/ Assume new frame has not been set up, the same as\n+    \/\/ compiled frame stack bang\n+    return fetch_compiled_frame_from_context(ucVoid);\n+  }\n@@ -205,1 +212,1 @@\n-  if (info == NULL || info->si_code <= 0 || info->si_code == SI_NOINFO) {\n+  if (info == nullptr || info->si_code <= 0 || info->si_code == SI_NOINFO) {\n@@ -207,1 +214,1 @@\n-    info = NULL;\n+    info = nullptr;\n@@ -213,1 +220,1 @@\n-  address stub = NULL;\n+  address stub = nullptr;\n@@ -215,1 +222,1 @@\n-  address pc          = NULL;\n+  address pc          = nullptr;\n@@ -218,1 +225,1 @@\n-  if (info != NULL && uc != NULL && thread != NULL) {\n+  if (info != nullptr && uc != nullptr && thread != nullptr) {\n@@ -221,6 +228,3 @@\n-#ifndef AMD64\n-    \/\/ Halt if SI_KERNEL before more crashes get misdiagnosed as Java bugs\n-    \/\/ This can happen in any running code (currently more frequently in\n-    \/\/ interpreter code but has been seen in compiled code)\n-      fatal(\"An irrecoverable SI_KERNEL SIGSEGV has occurred due \"\n-            \"to unstable signal handling in this distribution.\");\n+      \/\/ An irrecoverable SI_KERNEL SIGSEGV has occurred.\n+      \/\/ It's likely caused by dereferencing an address larger than TASK_SIZE.\n+      return false;\n@@ -229,1 +233,0 @@\n-#endif \/\/ AMD64\n@@ -259,2 +262,2 @@\n-        CodeBlob* cb = CodeCache::find_blob_unsafe(pc);\n-        CompiledMethod* nm = (cb != NULL) ? cb->as_compiled_method_or_null() : NULL;\n+        CodeBlob* cb = CodeCache::find_blob(pc);\n+        CompiledMethod* nm = (cb != nullptr) ? cb->as_compiled_method_or_null() : nullptr;\n@@ -262,1 +265,1 @@\n-        if ((nm != NULL && nm->has_unsafe_access()) || is_unsafe_arraycopy) {\n+        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_arraycopy) {\n@@ -346,1 +349,1 @@\n-      stub == NULL &&\n+      stub == nullptr &&\n@@ -349,1 +352,1 @@\n-    int page_size = os::vm_page_size();\n+    size_t page_size = os::vm_page_size();\n@@ -409,1 +412,1 @@\n-  if (stub != NULL) {\n+  if (stub != nullptr) {\n@@ -411,1 +414,1 @@\n-    if (thread != NULL) thread->set_saved_exception_pc(pc);\n+    if (thread != nullptr) thread->set_saved_exception_pc(pc);\n@@ -443,18 +446,3 @@\n-\/\/ Check that the linux kernel version is 2.4 or higher since earlier\n-\/\/ versions do not support SSE without patches.\n-bool os::supports_sse() {\n-#ifdef AMD64\n-  return true;\n-#else\n-  struct utsname uts;\n-  if( uname(&uts) != 0 ) return false; \/\/ uname fails?\n-  char *minor_string;\n-  int major = strtol(uts.release,&minor_string,10);\n-  int minor = strtol(minor_string+1,NULL,10);\n-  bool result = (major > 2 || (major==2 && minor >= 4));\n-  log_info(os)(\"OS version is %d.%d, which %s support SSE\/SSE2\",\n-               major,minor, result ? \"DOES\" : \"does NOT\");\n-  return result;\n-#endif \/\/ AMD64\n-}\n-\n+  \/\/ Note: this code runs on startup, and therefore should not be slow,\n+  \/\/ see JDK-8283200.\n+\n@@ -463,3 +451,3 @@\n-  char data[2048] = {0}; \/\/ lines should fit in 2K buf\n-  size_t len = sizeof(data);\n-  FILE *fp = fopen(\"\/proc\/cpuinfo\", \"r\");\n+\n+  \/\/ Attempt 1 (faster): Read the microcode version off the sysfs.\n+  FILE *fp = os::fopen(\"\/sys\/devices\/system\/cpu\/cpu0\/microcode\/version\", \"r\");\n@@ -467,0 +455,12 @@\n+    int read = fscanf(fp, \"%x\", &result);\n+    fclose(fp);\n+    if (read > 0) {\n+      return result;\n+    }\n+  }\n+\n+  \/\/ Attempt 2 (slower): Read the microcode version off the procfs.\n+  fp = os::fopen(\"\/proc\/cpuinfo\", \"r\");\n+  if (fp) {\n+    char data[2048] = {0}; \/\/ lines should fit in 2K buf\n+    size_t len = sizeof(data);\n@@ -469,1 +469,1 @@\n-        if (strstr(data, \"microcode\") != NULL) {\n+        if (strstr(data, \"microcode\") != nullptr) {\n@@ -471,1 +471,1 @@\n-          if (rev != NULL) sscanf(rev + 1, \"%x\", &result);\n+          if (rev != nullptr) sscanf(rev + 1, \"%x\", &result);\n@@ -478,0 +478,1 @@\n+\n@@ -486,2 +487,2 @@\n-size_t os::Posix::_compiler_thread_min_stack_allowed = 48 * K;\n-size_t os::Posix::_java_thread_min_stack_allowed = 40 * K;\n+size_t os::_compiler_thread_min_stack_allowed = 48 * K;\n+size_t os::_java_thread_min_stack_allowed = 40 * K;\n@@ -489,1 +490,1 @@\n-size_t os::Posix::_vm_internal_thread_min_stack_allowed = 64 * K;\n+size_t os::_vm_internal_thread_min_stack_allowed = 64 * K;\n@@ -491,1 +492,1 @@\n-size_t os::Posix::_vm_internal_thread_min_stack_allowed = (48 DEBUG_ONLY(+ 4)) * K;\n+size_t os::_vm_internal_thread_min_stack_allowed = (48 DEBUG_ONLY(+ 4)) * K;\n@@ -509,1 +510,1 @@\n-  if (context == NULL) return;\n+  if (context == nullptr) return;\n@@ -512,0 +513,1 @@\n+\n@@ -553,1 +555,1 @@\n-  st->print(\", CR2=\" PTR64_FORMAT, (uint64_t)uc->uc_mcontext.cr2);\n+  st->print(\", CR2=\" UINT64_FORMAT_X_0, (uint64_t)uc->uc_mcontext.cr2);\n@@ -557,0 +559,1 @@\n+}\n@@ -558,3 +561,7 @@\n-  intptr_t *sp = (intptr_t *)os::Linux::ucontext_get_sp(uc);\n-  st->print_cr(\"Top of Stack: (sp=\" PTR_FORMAT \")\", p2i(sp));\n-  print_hex_dump(st, (address)sp, (address)(sp + 8), sizeof(intptr_t));\n+void os::print_tos_pc(outputStream *st, const void *context) {\n+  if (context == nullptr) return;\n+\n+  const ucontext_t* uc = (const ucontext_t*)context;\n+\n+  address sp = (address)os::Linux::ucontext_get_sp(uc);\n+  print_tos(st, sp);\n@@ -566,1 +573,1 @@\n-  address pc = os::Posix::ucontext_get_pc(uc);\n+  address pc = os::fetch_frame_from_context(uc).pc();\n@@ -571,2 +578,7 @@\n-void os::print_register_info(outputStream *st, const void *context) {\n-  if (context == NULL) return;\n+void os::print_register_info(outputStream *st, const void *context, int& continuation) {\n+  const int register_count = AMD64_ONLY(16) NOT_AMD64(8);\n+  int n = continuation;\n+  assert(n >= 0 && n <= register_count, \"Invalid continuation value\");\n+  if (context == nullptr || n == register_count) {\n+    return;\n+  }\n@@ -575,10 +587,5 @@\n-\n-  st->print_cr(\"Register to memory mapping:\");\n-  st->cr();\n-\n-  \/\/ this is horrendously verbose but the layout of the registers in the\n-  \/\/ context does not match how we defined our abstract Register set, so\n-  \/\/ we can't just iterate through the gregs area\n-\n-  \/\/ this is only for the \"general purpose\" registers\n-\n+  while (n < register_count) {\n+    \/\/ Update continuation with next index before printing location\n+    continuation = n + 1;\n+# define CASE_PRINT_REG(n, str, id) case n: st->print(str); print_location(st, uc->uc_mcontext.gregs[REG_##id]);\n+    switch (n) {\n@@ -586,16 +593,16 @@\n-  st->print(\"RAX=\"); print_location(st, uc->uc_mcontext.gregs[REG_RAX]);\n-  st->print(\"RBX=\"); print_location(st, uc->uc_mcontext.gregs[REG_RBX]);\n-  st->print(\"RCX=\"); print_location(st, uc->uc_mcontext.gregs[REG_RCX]);\n-  st->print(\"RDX=\"); print_location(st, uc->uc_mcontext.gregs[REG_RDX]);\n-  st->print(\"RSP=\"); print_location(st, uc->uc_mcontext.gregs[REG_RSP]);\n-  st->print(\"RBP=\"); print_location(st, uc->uc_mcontext.gregs[REG_RBP]);\n-  st->print(\"RSI=\"); print_location(st, uc->uc_mcontext.gregs[REG_RSI]);\n-  st->print(\"RDI=\"); print_location(st, uc->uc_mcontext.gregs[REG_RDI]);\n-  st->print(\"R8 =\"); print_location(st, uc->uc_mcontext.gregs[REG_R8]);\n-  st->print(\"R9 =\"); print_location(st, uc->uc_mcontext.gregs[REG_R9]);\n-  st->print(\"R10=\"); print_location(st, uc->uc_mcontext.gregs[REG_R10]);\n-  st->print(\"R11=\"); print_location(st, uc->uc_mcontext.gregs[REG_R11]);\n-  st->print(\"R12=\"); print_location(st, uc->uc_mcontext.gregs[REG_R12]);\n-  st->print(\"R13=\"); print_location(st, uc->uc_mcontext.gregs[REG_R13]);\n-  st->print(\"R14=\"); print_location(st, uc->uc_mcontext.gregs[REG_R14]);\n-  st->print(\"R15=\"); print_location(st, uc->uc_mcontext.gregs[REG_R15]);\n+    CASE_PRINT_REG( 0, \"RAX=\", RAX); break;\n+    CASE_PRINT_REG( 1, \"RBX=\", RBX); break;\n+    CASE_PRINT_REG( 2, \"RCX=\", RCX); break;\n+    CASE_PRINT_REG( 3, \"RDX=\", RDX); break;\n+    CASE_PRINT_REG( 4, \"RSP=\", RSP); break;\n+    CASE_PRINT_REG( 5, \"RBP=\", RBP); break;\n+    CASE_PRINT_REG( 6, \"RSI=\", RSI); break;\n+    CASE_PRINT_REG( 7, \"RDI=\", RDI); break;\n+    CASE_PRINT_REG( 8, \"R8 =\", R8); break;\n+    CASE_PRINT_REG( 9, \"R9 =\", R9); break;\n+    CASE_PRINT_REG(10, \"R10=\", R10); break;\n+    CASE_PRINT_REG(11, \"R11=\", R11); break;\n+    CASE_PRINT_REG(12, \"R12=\", R12); break;\n+    CASE_PRINT_REG(13, \"R13=\", R13); break;\n+    CASE_PRINT_REG(14, \"R14=\", R14); break;\n+    CASE_PRINT_REG(15, \"R15=\", R15); break;\n@@ -603,8 +610,8 @@\n-  st->print(\"EAX=\"); print_location(st, uc->uc_mcontext.gregs[REG_EAX]);\n-  st->print(\"EBX=\"); print_location(st, uc->uc_mcontext.gregs[REG_EBX]);\n-  st->print(\"ECX=\"); print_location(st, uc->uc_mcontext.gregs[REG_ECX]);\n-  st->print(\"EDX=\"); print_location(st, uc->uc_mcontext.gregs[REG_EDX]);\n-  st->print(\"ESP=\"); print_location(st, uc->uc_mcontext.gregs[REG_ESP]);\n-  st->print(\"EBP=\"); print_location(st, uc->uc_mcontext.gregs[REG_EBP]);\n-  st->print(\"ESI=\"); print_location(st, uc->uc_mcontext.gregs[REG_ESI]);\n-  st->print(\"EDI=\"); print_location(st, uc->uc_mcontext.gregs[REG_EDI]);\n+    CASE_PRINT_REG(0, \"EAX=\", EAX); break;\n+    CASE_PRINT_REG(1, \"EBX=\", EBX); break;\n+    CASE_PRINT_REG(2, \"ECX=\", ECX); break;\n+    CASE_PRINT_REG(3, \"EDX=\", EDX); break;\n+    CASE_PRINT_REG(4, \"ESP=\", ESP); break;\n+    CASE_PRINT_REG(5, \"EBP=\", EBP); break;\n+    CASE_PRINT_REG(6, \"ESI=\", ESI); break;\n+    CASE_PRINT_REG(7, \"EDI=\", EDI); break;\n@@ -612,2 +619,4 @@\n-\n-  st->cr();\n+    }\n+# undef CASE_PRINT_REG\n+    ++n;\n+  }\n@@ -633,77 +642,0 @@\n-\n-\/*\n- * IA32 only: execute code at a high address in case buggy NX emulation is present. I.e. avoid CS limit\n- * updates (JDK-8023956).\n- *\/\n-void os::workaround_expand_exec_shield_cs_limit() {\n-#if defined(IA32)\n-  assert(Linux::initial_thread_stack_bottom() != NULL, \"sanity\");\n-  size_t page_size = os::vm_page_size();\n-\n-  \/*\n-   * JDK-8197429\n-   *\n-   * Expand the stack mapping to the end of the initial stack before\n-   * attempting to install the codebuf.  This is needed because newer\n-   * Linux kernels impose a distance of a megabyte between stack\n-   * memory and other memory regions.  If we try to install the\n-   * codebuf before expanding the stack the installation will appear\n-   * to succeed but we'll get a segfault later if we expand the stack\n-   * in Java code.\n-   *\n-   *\/\n-  if (os::is_primordial_thread()) {\n-    address limit = Linux::initial_thread_stack_bottom();\n-    if (! DisablePrimordialThreadGuardPages) {\n-      limit += StackOverflow::stack_red_zone_size() +\n-               StackOverflow::stack_yellow_zone_size();\n-    }\n-    os::Linux::expand_stack_to(limit);\n-  }\n-\n-  \/*\n-   * Take the highest VA the OS will give us and exec\n-   *\n-   * Although using -(pagesz) as mmap hint works on newer kernel as you would\n-   * think, older variants affected by this work-around don't (search forward only).\n-   *\n-   * On the affected distributions, we understand the memory layout to be:\n-   *\n-   *   TASK_LIMIT= 3G, main stack base close to TASK_LIMT.\n-   *\n-   * A few pages south main stack will do it.\n-   *\n-   * If we are embedded in an app other than launcher (initial != main stack),\n-   * we don't have much control or understanding of the address space, just let it slide.\n-   *\/\n-  char* hint = (char*)(Linux::initial_thread_stack_bottom() -\n-                       (StackOverflow::stack_guard_zone_size() + page_size));\n-  char* codebuf = os::attempt_reserve_memory_at(hint, page_size);\n-\n-  if (codebuf == NULL) {\n-    \/\/ JDK-8197429: There may be a stack gap of one megabyte between\n-    \/\/ the limit of the stack and the nearest memory region: this is a\n-    \/\/ Linux kernel workaround for CVE-2017-1000364.  If we failed to\n-    \/\/ map our codebuf, try again at an address one megabyte lower.\n-    hint -= 1 * M;\n-    codebuf = os::attempt_reserve_memory_at(hint, page_size);\n-  }\n-\n-  if ((codebuf == NULL) || (!os::commit_memory(codebuf, page_size, true))) {\n-    return; \/\/ No matter, we tried, best effort.\n-  }\n-\n-  MemTracker::record_virtual_memory_type((address)codebuf, mtInternal);\n-\n-  log_info(os)(\"[CS limit NX emulation work-around, exec code at: %p]\", codebuf);\n-\n-  \/\/ Some code to exec: the 'ret' instruction\n-  codebuf[0] = 0xC3;\n-\n-  \/\/ Call the code in the codebuf\n-  __asm__ volatile(\"call *%0\" : : \"r\"(codebuf));\n-\n-  \/\/ keep the page mapped so CS limit isn't reduced.\n-#endif\n-}\n-\n","filename":"src\/hotspot\/os_cpu\/linux_x86\/os_linux_x86.cpp","additions":107,"deletions":175,"binary":false,"changes":282,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"jvm.h\"\n@@ -45,0 +44,1 @@\n+#include \"jvm.h\"\n@@ -54,0 +54,1 @@\n+#include \"oops\/fieldInfo.hpp\"\n@@ -89,1 +90,0 @@\n-\n@@ -143,0 +143,8 @@\n+#define JAVA_18_VERSION                   62\n+\n+#define JAVA_19_VERSION                   63\n+\n+#define JAVA_20_VERSION                   64\n+\n+#define JAVA_21_VERSION                   65\n+\n@@ -154,2 +162,2 @@\n-  assert(stream != NULL, \"invariant\");\n-  assert(cp != NULL, \"invariant\");\n+  assert(stream != nullptr, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n@@ -165,1 +173,0 @@\n-  assert(cfs->allocated_on_stack(), \"should be local\");\n@@ -318,1 +325,1 @@\n-        assert(utf8_buffer != NULL, \"null utf8 buffer\");\n+        assert(utf8_buffer != nullptr, \"null utf8 buffer\");\n@@ -332,1 +339,1 @@\n-        if (result == NULL) {\n+        if (result == nullptr) {\n@@ -395,1 +402,1 @@\n-  assert(cp != NULL, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n@@ -399,1 +406,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -423,2 +430,2 @@\n-  assert(cp != NULL, \"invariant\");\n-  assert(stream != NULL, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n+  assert(stream != nullptr, \"invariant\");\n@@ -451,2 +458,2 @@\n-        const int klass_ref_index = cp->klass_ref_index_at(index);\n-        const int name_and_type_ref_index = cp->name_and_type_ref_index_at(index);\n+        const int klass_ref_index = cp->uncached_klass_ref_index_at(index);\n+        const int name_and_type_ref_index = cp->uncached_name_and_type_ref_index_at(index);\n@@ -654,1 +661,1 @@\n-          cp->name_and_type_ref_index_at(index);\n+          cp->uncached_name_and_type_ref_index_at(index);\n@@ -677,1 +684,1 @@\n-          cp->name_and_type_ref_index_at(index);\n+          cp->uncached_name_and_type_ref_index_at(index);\n@@ -696,2 +703,3 @@\n-            \/\/ Method name and signature are verified above, when iterating NameAndType_info.\n-            \/\/ Need only to be sure signature is non-zero length and the right type.\n+            \/\/ Method name and signature are individually verified above, when iterating\n+            \/\/ NameAndType_info.  Need to check here that signature is non-zero length and\n+            \/\/ the right type.\n@@ -702,1 +710,1 @@\n-          \/\/ 4509014: If a class method name begins with '<', it must be \"<init>\"\n+          \/\/ If a class method name begins with '<', it must be \"<init>\" and have void signature.\n@@ -704,8 +712,10 @@\n-          if (tag == JVM_CONSTANT_Methodref &&\n-              name_len != 0 &&\n-              name->char_at(0) == JVM_SIGNATURE_SPECIAL &&\n-              name != vmSymbols::object_initializer_name()) {\n-            classfile_parse_error(\n-              \"Bad method name at constant pool index %u in class file %s\",\n-              name_ref_index, THREAD);\n-            return;\n+          if (tag == JVM_CONSTANT_Methodref && name_len != 0 &&\n+              name->char_at(0) == JVM_SIGNATURE_SPECIAL) {\n+            if (name != vmSymbols::object_initializer_name()) {\n+              classfile_parse_error(\n+                \"Bad method name at constant pool index %u in class file %s\",\n+                name_ref_index, THREAD);\n+              return;\n+            } else if (!Signature::is_void_method(signature)) { \/\/ must have void signature.\n+              throwIllegalSignature(\"Method\", name, signature, CHECK);\n+            }\n@@ -725,1 +735,1 @@\n-              cp->name_and_type_ref_index_at(ref_index);\n+              cp->uncached_name_and_type_ref_index_at(ref_index);\n@@ -767,3 +777,1 @@\n-  NameSigHash*  _next;             \/\/ Next entry in hash table\n-};\n-static const int HASH_ROW_SIZE = 256;\n+  static const int HASH_ROW_SIZE = 256;\n@@ -772,4 +780,3 @@\n-static unsigned int hash(const Symbol* name, const Symbol* sig) {\n-  unsigned int raw_hash = 0;\n-  raw_hash += ((unsigned int)(uintptr_t)name) >> (LogHeapWordSize + 2);\n-  raw_hash += ((unsigned int)(uintptr_t)sig) >> LogHeapWordSize;\n+  NameSigHash(Symbol* name, Symbol* sig) :\n+    _name(name),\n+    _sig(sig) {}\n@@ -777,23 +784,2 @@\n-  return (raw_hash + (unsigned int)(uintptr_t)name) % HASH_ROW_SIZE;\n-}\n-\n-\n-static void initialize_hashtable(NameSigHash** table) {\n-  memset((void*)table, 0, sizeof(NameSigHash*) * HASH_ROW_SIZE);\n-}\n-\/\/ Return false if the name\/sig combination is found in table.\n-\/\/ Return true if no duplicate is found. And name\/sig is added as a new entry in table.\n-\/\/ The old format checker uses heap sort to find duplicates.\n-\/\/ NOTE: caller should guarantee that GC doesn't happen during the life cycle\n-\/\/ of table since we don't expect Symbol*'s to move.\n-static bool put_after_lookup(const Symbol* name, const Symbol* sig, NameSigHash** table) {\n-  assert(name != NULL, \"name in constant pool is NULL\");\n-\n-  \/\/ First lookup for duplicates\n-  int index = hash(name, sig);\n-  NameSigHash* entry = table[index];\n-  while (entry != NULL) {\n-    if (entry->_name == name && entry->_sig == sig) {\n-      return false;\n-    }\n-    entry = entry->_next;\n+  static unsigned int hash(NameSigHash const& namesig) {\n+    return namesig._name->identity_hash() ^ namesig._sig->identity_hash();\n@@ -802,8 +788,5 @@\n-  \/\/ No duplicate is found, allocate a new entry and fill it.\n-  entry = new NameSigHash();\n-  entry->_name = name;\n-  entry->_sig = sig;\n-\n-  \/\/ Insert into hash table\n-  entry->_next = table[index];\n-  table[index] = entry;\n+  static bool equals(NameSigHash const& e0, NameSigHash const& e1) {\n+    return (e0._name == e1._name) &&\n+          (e0._sig  == e1._sig);\n+  }\n+};\n@@ -811,2 +794,4 @@\n-  return true;\n-}\n+using NameSigHashtable = ResourceHashtable<NameSigHash, int,\n+                                           NameSigHash::HASH_ROW_SIZE,\n+                                           AnyObj::RESOURCE_AREA, mtInternal,\n+                                           &NameSigHash::hash, &NameSigHash::equals>;\n@@ -820,3 +805,3 @@\n-  assert(stream != NULL, \"invariant\");\n-  assert(cp != NULL, \"invariant\");\n-  assert(has_nonstatic_concrete_methods != NULL, \"invariant\");\n+  assert(stream != nullptr, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n+  assert(has_nonstatic_concrete_methods != nullptr, \"invariant\");\n@@ -828,1 +813,1 @@\n-    _local_interfaces = MetadataFactory::new_array<InstanceKlass*>(_loader_data, itfs_len, NULL, CHECK);\n+    _local_interfaces = MetadataFactory::new_array<InstanceKlass*>(_loader_data, itfs_len, nullptr, CHECK);\n@@ -878,16 +863,10 @@\n-    NameSigHash** interface_names = NEW_RESOURCE_ARRAY_IN_THREAD(THREAD,\n-                                                                 NameSigHash*,\n-                                                                 HASH_ROW_SIZE);\n-    initialize_hashtable(interface_names);\n-    bool dup = false;\n-    const Symbol* name = NULL;\n-    {\n-      debug_only(NoSafepointVerifier nsv;)\n-      for (index = 0; index < itfs_len; index++) {\n-        const InstanceKlass* const k = _local_interfaces->at(index);\n-        name = k->name();\n-        \/\/ If no duplicates, add (name, NULL) in hashtable interface_names.\n-        if (!put_after_lookup(name, NULL, interface_names)) {\n-          dup = true;\n-          break;\n-        }\n+    \/\/ Set containing interface names\n+    ResourceHashtable<Symbol*, int>* interface_names = new ResourceHashtable<Symbol*, int>();\n+    for (index = 0; index < itfs_len; index++) {\n+      const InstanceKlass* const k = _local_interfaces->at(index);\n+      Symbol* interface_name = k->name();\n+      \/\/ If no duplicates, add (name, nullptr) in hashtable interface_names.\n+      if (!interface_names->put(interface_name, 0)) {\n+        classfile_parse_error(\"Duplicate interface name \\\"%s\\\" in class file %s\",\n+                               interface_name->as_C_string(), THREAD);\n+        return;\n@@ -896,4 +875,0 @@\n-    if (dup) {\n-      classfile_parse_error(\"Duplicate interface name \\\"%s\\\" in class file %s\",\n-                             name->as_C_string(), THREAD);\n-    }\n@@ -967,0 +942,2 @@\n+    _method_ChangesCurrentThread,\n+    _method_JvmtiMountTransition,\n@@ -1029,2 +1006,2 @@\n-    _field_annotations(NULL),\n-    _field_type_annotations(NULL) {}\n+    _field_annotations(nullptr),\n+    _field_type_annotations(nullptr) {}\n@@ -1062,1 +1039,1 @@\n-  assert(buffer != NULL, \"invariant\");\n+  assert(buffer != nullptr, \"invariant\");\n@@ -1076,1 +1053,1 @@\n-  assert(buffer != NULL, \"invariant\");\n+  assert(buffer != nullptr, \"invariant\");\n@@ -1129,4 +1106,4 @@\n-  assert(cp != NULL, \"invariant\");\n-  assert(buffer != NULL, \"invariant\");\n-  assert(coll != NULL, \"invariant\");\n-  assert(loader_data != NULL, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n+  assert(buffer != nullptr, \"invariant\");\n+  assert(coll != nullptr, \"invariant\");\n+  assert(loader_data != nullptr, \"invariant\");\n@@ -1163,2 +1140,2 @@\n-    if (aname == NULL)  break;  \/\/ invalid annotation name\n-    const Symbol* member = NULL;\n+    if (aname == nullptr)  break;  \/\/ invalid annotation name\n+    const Symbol* member = nullptr;\n@@ -1168,1 +1145,1 @@\n-      if (member == NULL)  break;  \/\/ invalid member name\n+      if (member == nullptr)  break;  \/\/ invalid member name\n@@ -1213,5 +1190,5 @@\n-  assert(cfs != NULL, \"invariant\");\n-  assert(constantvalue_index_addr != NULL, \"invariant\");\n-  assert(is_synthetic_addr != NULL, \"invariant\");\n-  assert(generic_signature_index_addr != NULL, \"invariant\");\n-  assert(parsed_annotations != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n+  assert(constantvalue_index_addr != nullptr, \"invariant\");\n+  assert(is_synthetic_addr != nullptr, \"invariant\");\n+  assert(generic_signature_index_addr != nullptr, \"invariant\");\n+  assert(parsed_annotations != nullptr, \"invariant\");\n@@ -1223,1 +1200,1 @@\n-  const u1* runtime_visible_annotations = NULL;\n+  const u1* runtime_visible_annotations = nullptr;\n@@ -1225,1 +1202,1 @@\n-  const u1* runtime_invisible_annotations = NULL;\n+  const u1* runtime_invisible_annotations = nullptr;\n@@ -1227,1 +1204,1 @@\n-  const u1* runtime_visible_type_annotations = NULL;\n+  const u1* runtime_visible_type_annotations = nullptr;\n@@ -1229,1 +1206,1 @@\n-  const u1* runtime_invisible_type_annotations = NULL;\n+  const u1* runtime_invisible_type_annotations = nullptr;\n@@ -1290,1 +1267,1 @@\n-        if (runtime_visible_annotations != NULL) {\n+        if (runtime_visible_annotations != nullptr) {\n@@ -1297,1 +1274,1 @@\n-        assert(runtime_visible_annotations != NULL, \"null visible annotations\");\n+        assert(runtime_visible_annotations != nullptr, \"null visible annotations\");\n@@ -1316,1 +1293,1 @@\n-          assert(runtime_invisible_annotations != NULL, \"null invisible annotations\");\n+          assert(runtime_invisible_annotations != nullptr, \"null invisible annotations\");\n@@ -1320,1 +1297,1 @@\n-        if (runtime_visible_type_annotations != NULL) {\n+        if (runtime_visible_type_annotations != nullptr) {\n@@ -1327,1 +1304,1 @@\n-        assert(runtime_visible_type_annotations != NULL, \"null visible type annotations\");\n+        assert(runtime_visible_type_annotations != nullptr, \"null visible type annotations\");\n@@ -1340,1 +1317,1 @@\n-          assert(runtime_invisible_type_annotations != NULL, \"null invisible type annotations\");\n+          assert(runtime_invisible_type_annotations != nullptr, \"null invisible type annotations\");\n@@ -1467,4 +1444,4 @@\n-  assert(cfs != NULL, \"invariant\");\n-  assert(fac != NULL, \"invariant\");\n-  assert(cp != NULL, \"invariant\");\n-  assert(java_fields_count_ptr != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n+  assert(fac != nullptr, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n+  assert(java_fields_count_ptr != nullptr, \"invariant\");\n@@ -1472,3 +1449,2 @@\n-  assert(NULL == _fields, \"invariant\");\n-  assert(NULL == _fields_annotations, \"invariant\");\n-  assert(NULL == _fields_type_annotations, \"invariant\");\n+  assert(nullptr == _fields_annotations, \"invariant\");\n+  assert(nullptr == _fields_type_annotations, \"invariant\");\n@@ -1485,24 +1461,3 @@\n-  \/\/ The field array starts with tuples of shorts\n-  \/\/ [access, name index, sig index, initial value index, byte offset].\n-  \/\/ A generic signature slot only exists for field with generic\n-  \/\/ signature attribute. And the access flag is set with\n-  \/\/ JVM_ACC_FIELD_HAS_GENERIC_SIGNATURE for that field. The generic\n-  \/\/ signature slots are at the end of the field array and after all\n-  \/\/ other fields data.\n-  \/\/\n-  \/\/   f1: [access, name index, sig index, initial value index, low_offset, high_offset]\n-  \/\/   f2: [access, name index, sig index, initial value index, low_offset, high_offset]\n-  \/\/       ...\n-  \/\/   fn: [access, name index, sig index, initial value index, low_offset, high_offset]\n-  \/\/       [generic signature index]\n-  \/\/       [generic signature index]\n-  \/\/       ...\n-  \/\/\n-  \/\/ Allocate a temporary resource array for field data. For each field,\n-  \/\/ a slot is reserved in the temporary array for the generic signature\n-  \/\/ index. After parsing all fields, the data are copied to a permanent\n-  \/\/ array and any unused slots will be discarded.\n-  ResourceMark rm(THREAD);\n-  u2* const fa = NEW_RESOURCE_ARRAY_IN_THREAD(THREAD,\n-                                              u2,\n-                                              total_fields * (FieldInfo::field_slots + 1));\n+  \/\/ Allocate a temporary resource array to collect field data.\n+  \/\/ After parsing all fields, data are stored in a UNSIGNED5 compressed stream.\n+  _temp_field_info = new GrowableArray<FieldInfo>(total_fields);\n@@ -1510,3 +1465,1 @@\n-  \/\/ The generic signature slots start after all other fields' data.\n-  int generic_signature_slot = total_fields * FieldInfo::field_slots;\n-  int num_generic_signature = 0;\n+  ResourceMark rm(THREAD);\n@@ -1521,0 +1474,1 @@\n+    FieldInfo::FieldFlags fieldFlags(0);\n@@ -1554,2 +1508,2 @@\n-      if (parsed_annotations.field_annotations() != NULL) {\n-        if (_fields_annotations == NULL) {\n+      if (parsed_annotations.field_annotations() != nullptr) {\n+        if (_fields_annotations == nullptr) {\n@@ -1557,1 +1511,1 @@\n-                                             _loader_data, length, NULL,\n+                                             _loader_data, length, nullptr,\n@@ -1561,1 +1515,1 @@\n-        parsed_annotations.set_field_annotations(NULL);\n+        parsed_annotations.set_field_annotations(nullptr);\n@@ -1563,2 +1517,2 @@\n-      if (parsed_annotations.field_type_annotations() != NULL) {\n-        if (_fields_type_annotations == NULL) {\n+      if (parsed_annotations.field_type_annotations() != nullptr) {\n+        if (_fields_type_annotations == nullptr) {\n@@ -1568,1 +1522,1 @@\n-                                                         NULL,\n+                                                         nullptr,\n@@ -1572,1 +1526,1 @@\n-        parsed_annotations.set_field_type_annotations(NULL);\n+        parsed_annotations.set_field_type_annotations(nullptr);\n@@ -1579,4 +1533,1 @@\n-        access_flags.set_field_has_generic_signature();\n-        fa[generic_signature_slot] = generic_signature_index;\n-        generic_signature_slot ++;\n-        num_generic_signature ++;\n+        fieldFlags.update_generic(true);\n@@ -1586,5 +1537,0 @@\n-    FieldInfo* const field = FieldInfo::from_field_array(fa, n);\n-    field->initialize(access_flags.as_short(),\n-                      name_index,\n-                      signature_index,\n-                      constantvalue_index);\n@@ -1603,6 +1549,4 @@\n-    \/\/ After field is initialized with type, we can augment it with aux info\n-    if (parsed_annotations.has_any_annotations()) {\n-      parsed_annotations.apply_to(field);\n-      if (field->is_contended()) {\n-        _has_contended_fields = true;\n-      }\n+    FieldInfo fi(access_flags, name_index, signature_index, constantvalue_index, fieldFlags);\n+    fi.set_index(n);\n+    if (fieldFlags.is_generic()) {\n+      fi.set_generic_signature_index(generic_signature_index);\n@@ -1610,0 +1554,5 @@\n+    parsed_annotations.apply_to(&fi);\n+    if (fi.field_flags().is_contended()) {\n+      _has_contended_fields = true;\n+    }\n+    _temp_field_info->append(fi);\n@@ -1611,0 +1560,1 @@\n+  assert(_temp_field_info->length() == length, \"Must be\");\n@@ -1621,1 +1571,1 @@\n-          const FieldInfo* const f = FieldInfo::from_field_array(fa, i);\n+          const FieldInfo* const f = _temp_field_info->adr_at(i);\n@@ -1636,7 +1586,6 @@\n-      FieldInfo* const field = FieldInfo::from_field_array(fa, index);\n-      field->initialize((u2)JVM_ACC_FIELD_INTERNAL,\n-                        (u2)(injected[n].name_index),\n-                        (u2)(injected[n].signature_index),\n-                        0);\n-\n-      const BasicType type = Signature::basic_type(injected[n].signature());\n+      FieldInfo::FieldFlags fflags(0);\n+      fflags.update_injected(true);\n+      AccessFlags aflags;\n+      FieldInfo fi(aflags, (u2)(injected[n].name_index), (u2)(injected[n].signature_index), 0, fflags);\n+      fi.set_index(index);\n+      _temp_field_info->append(fi);\n@@ -1645,0 +1594,1 @@\n+      const BasicType type = Signature::basic_type(injected[n].signature());\n@@ -1650,21 +1600,1 @@\n-  assert(NULL == _fields, \"invariant\");\n-\n-  _fields =\n-    MetadataFactory::new_array<u2>(_loader_data,\n-                                   index * FieldInfo::field_slots + num_generic_signature,\n-                                   CHECK);\n-  \/\/ Sometimes injected fields already exist in the Java source so\n-  \/\/ the fields array could be too long.  In that case the\n-  \/\/ fields array is trimed. Also unused slots that were reserved\n-  \/\/ for generic signature indexes are discarded.\n-  {\n-    int i = 0;\n-    for (; i < index * FieldInfo::field_slots; i++) {\n-      _fields->at_put(i, fa[i]);\n-    }\n-    for (int j = total_fields * FieldInfo::field_slots;\n-         j < generic_signature_slot; j++) {\n-      _fields->at_put(i++, fa[j]);\n-    }\n-    assert(_fields->length() == i, \"\");\n-  }\n+  assert(_temp_field_info->length() == index, \"Must be\");\n@@ -1675,16 +1605,10 @@\n-    NameSigHash** names_and_sigs = NEW_RESOURCE_ARRAY_IN_THREAD(\n-      THREAD, NameSigHash*, HASH_ROW_SIZE);\n-    initialize_hashtable(names_and_sigs);\n-    bool dup = false;\n-    const Symbol* name = NULL;\n-    const Symbol* sig = NULL;\n-    {\n-      debug_only(NoSafepointVerifier nsv;)\n-      for (AllFieldStream fs(_fields, cp); !fs.done(); fs.next()) {\n-        name = fs.name();\n-        sig = fs.signature();\n-        \/\/ If no duplicates, add name\/signature in hashtable names_and_sigs.\n-        if (!put_after_lookup(name, sig, names_and_sigs)) {\n-          dup = true;\n-          break;\n-        }\n+    \/\/ Set containing name-signature pairs\n+    NameSigHashtable* names_and_sigs = new NameSigHashtable();\n+    for (int i = 0; i < _temp_field_info->length(); i++) {\n+      NameSigHash name_and_sig(_temp_field_info->adr_at(i)->name(_cp),\n+                               _temp_field_info->adr_at(i)->signature(_cp));\n+      \/\/ If no duplicates, add name\/signature in hashtable names_and_sigs.\n+      if(!names_and_sigs->put(name_and_sig, 0)) {\n+        classfile_parse_error(\"Duplicate field name \\\"%s\\\" with signature \\\"%s\\\" in class file %s\",\n+                               name_and_sig._name->as_C_string(), name_and_sig._sig->as_klass_external_name(), THREAD);\n+        return;\n@@ -1693,4 +1617,0 @@\n-    if (dup) {\n-      classfile_parse_error(\"Duplicate field name \\\"%s\\\" with signature \\\"%s\\\" in class file %s\",\n-                             name->as_C_string(), sig->as_klass_external_name(), THREAD);\n-    }\n@@ -1705,1 +1625,1 @@\n-  assert(cfs != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n@@ -1708,1 +1628,1 @@\n-  assert(exception_table_start != NULL, \"null exception table\");\n+  assert(exception_table_start != nullptr, \"null exception table\");\n@@ -1757,1 +1677,1 @@\n-  if ((*write_stream) == NULL) {\n+  if ((*write_stream) == nullptr) {\n@@ -1846,1 +1766,1 @@\n-  assert(localvariable_table_start != NULL, \"null local variable table\");\n+  assert(localvariable_table_start != nullptr, \"null local variable table\");\n@@ -1864,1 +1784,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -1870,1 +1790,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -1903,2 +1823,1 @@\n-                                      bool need_verify,\n-  assert(cfs != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n@@ -1908,1 +1827,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1912,1 +1831,1 @@\n-  assert(stackmap_table_start != NULL, \"null stackmap table\");\n+  assert(stackmap_table_start != nullptr, \"null stackmap table\");\n@@ -1914,1 +1833,1 @@\n-  \/\/ check code_attribute_length first\n+  \/\/ check code_attribute_length\n@@ -1917,3 +1836,0 @@\n-  if (!need_verify && !DumpSharedSpaces) {\n-    return NULL;\n-  }\n@@ -1927,2 +1843,2 @@\n-  assert(cfs != NULL, \"invariant\");\n-  assert(checked_exceptions_length != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n+  assert(checked_exceptions_length != nullptr, \"invariant\");\n@@ -1935,1 +1851,1 @@\n-  assert(checked_exceptions_start != NULL, \"null checked exceptions\");\n+  assert(checked_exceptions_start != nullptr, \"null checked exceptions\");\n@@ -1964,2 +1880,2 @@\n-  assert(name != NULL, \"invariant\");\n-  assert(sig != NULL, \"invariant\");\n+  assert(name != nullptr, \"invariant\");\n+  assert(sig != nullptr, \"invariant\");\n@@ -1999,0 +1915,10 @@\n+    case VM_SYMBOL_ENUM_NAME(jdk_internal_vm_annotation_ChangesCurrentThread_signature): {\n+      if (_location != _in_method)  break;  \/\/ only allow for methods\n+      if (!privileged)              break;  \/\/ only allow in privileged code\n+      return _method_ChangesCurrentThread;\n+    }\n+    case VM_SYMBOL_ENUM_NAME(jdk_internal_vm_annotation_JvmtiMountTransition_signature): {\n+      if (_location != _in_method)  break;  \/\/ only allow for methods\n+      if (!privileged)              break;  \/\/ only allow in privileged code\n+      return _method_JvmtiMountTransition;\n+    }\n@@ -2053,1 +1979,1 @@\n-      if (!privileged)              break;  \/\/ only allow in priviledged code\n+      if (!privileged)              break;  \/\/ only allow in privileged code\n@@ -2065,0 +1991,1 @@\n+    \/\/ Setting the contended group also sets the contended bit in field flags\n@@ -2067,1 +1994,1 @@\n-    f->set_stable(true);\n+    (f->field_flags_addr())->update_stable(true);\n@@ -2070,1 +1997,1 @@\n-      f->set_tsan_ignore(true);\n+      (f->field_flags_addr())->update_tsan_ignore(true);\n@@ -2083,1 +2010,1 @@\n-    m->set_caller_sensitive(true);\n+    m->set_caller_sensitive();\n@@ -2085,1 +2012,1 @@\n-    m->set_force_inline(true);\n+    m->set_force_inline();\n@@ -2087,1 +2014,5 @@\n-    m->set_dont_inline(true);\n+    m->set_dont_inline();\n+  if (has_annotation(_method_ChangesCurrentThread))\n+    m->set_changes_current_thread();\n+  if (has_annotation(_method_JvmtiMountTransition))\n+    m->set_jvmti_mount_transition();\n@@ -2089,1 +2020,1 @@\n-    m->set_has_injected_profile(true);\n+    m->set_has_injected_profile();\n@@ -2093,1 +2024,1 @@\n-    m->set_hidden(true);\n+    m->set_is_hidden();\n@@ -2095,1 +2026,1 @@\n-    m->set_scoped(true);\n+    m->set_scoped();\n@@ -2097,1 +2028,1 @@\n-    m->set_intrinsic_candidate(true);\n+    m->set_intrinsic_candidate();\n@@ -2099,1 +2030,1 @@\n-    m->set_has_reserved_stack_access(true);\n+    m->set_has_reserved_stack_access();\n@@ -2103,1 +2034,1 @@\n-  assert(ik != NULL, \"invariant\");\n+  assert(ik != nullptr, \"invariant\");\n@@ -2111,1 +2042,0 @@\n-      ik->set_prototype_header(markWord::prototype());\n@@ -2145,0 +2075,1 @@\n+                            256, AnyObj::RESOURCE_AREA, mtInternal,\n@@ -2179,1 +2110,1 @@\n-      if (entry == NULL) {\n+      if (entry == nullptr) {\n@@ -2244,1 +2175,1 @@\n-                             NULL,\n+                             nullptr,\n@@ -2267,3 +2198,1 @@\n-\/\/ The promoted_flags parameter is used to pass relevant access_flags\n-\/\/ from the method back up to the containing klass. These flag values\n-\/\/ are added to klass's access_flags.\n+\/\/ The has_localvariable_table parameter is used to pass up the value to InstanceKlass.\n@@ -2274,1 +2203,1 @@\n-                                      AccessFlags* const promoted_flags,\n+                                      bool* const has_localvariable_table,\n@@ -2276,3 +2205,3 @@\n-  assert(cfs != NULL, \"invariant\");\n-  assert(cp != NULL, \"invariant\");\n-  assert(promoted_flags != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n+  assert(has_localvariable_table != nullptr, \"invariant\");\n@@ -2311,1 +2240,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -2319,1 +2248,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -2324,0 +2253,1 @@\n+    verify_legal_name_with_signature(name, signature, CHECK_NULL);\n@@ -2328,1 +2258,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -2340,1 +2270,1 @@\n-  const unsafe_u2* exception_table_start = NULL; \/\/ (potentially unaligned) pointer to array of u2 elements\n+  const unsafe_u2* exception_table_start = nullptr; \/\/ (potentially unaligned) pointer to array of u2 elements\n@@ -2343,2 +2273,2 @@\n-  const unsafe_u2* checked_exceptions_start = NULL; \/\/ (potentially unaligned) pointer to array of u2 elements\n-  CompressedLineNumberWriteStream* linenumber_table = NULL;\n+  const unsafe_u2* checked_exceptions_start = nullptr; \/\/ (potentially unaligned) pointer to array of u2 elements\n+  CompressedLineNumberWriteStream* linenumber_table = nullptr;\n@@ -2352,4 +2282,4 @@\n-  u2* localvariable_table_length = NULL;\n-  const unsafe_u2** localvariable_table_start = NULL; \/\/ (potentially unaligned) pointer to array of LVT attributes\n-  u2* localvariable_type_table_length = NULL;\n-  const unsafe_u2** localvariable_type_table_start = NULL; \/\/ (potentially unaligned) pointer to LVTT attributes\n+  u2* localvariable_table_length = nullptr;\n+  const unsafe_u2** localvariable_table_start = nullptr; \/\/ (potentially unaligned) pointer to array of LVT attributes\n+  u2* localvariable_type_table_length = nullptr;\n+  const unsafe_u2** localvariable_type_table_start = nullptr; \/\/ (potentially unaligned) pointer to LVTT attributes\n@@ -2357,1 +2287,1 @@\n-  const u1* method_parameters_data = NULL;\n+  const u1* method_parameters_data = nullptr;\n@@ -2363,1 +2293,1 @@\n-  const u1* stackmap_data = NULL;\n+  const u1* stackmap_data = nullptr;\n@@ -2367,1 +2297,1 @@\n-  const u1* runtime_visible_annotations = NULL;\n+  const u1* runtime_visible_annotations = nullptr;\n@@ -2369,1 +2299,1 @@\n-  const u1* runtime_invisible_annotations = NULL;\n+  const u1* runtime_invisible_annotations = nullptr;\n@@ -2371,1 +2301,1 @@\n-  const u1* runtime_visible_parameter_annotations = NULL;\n+  const u1* runtime_visible_parameter_annotations = nullptr;\n@@ -2373,1 +2303,1 @@\n-  const u1* runtime_invisible_parameter_annotations = NULL;\n+  const u1* runtime_invisible_parameter_annotations = nullptr;\n@@ -2375,1 +2305,1 @@\n-  const u1* runtime_visible_type_annotations = NULL;\n+  const u1* runtime_visible_type_annotations = nullptr;\n@@ -2377,1 +2307,1 @@\n-  const u1* runtime_invisible_type_annotations = NULL;\n+  const u1* runtime_invisible_type_annotations = nullptr;\n@@ -2382,1 +2312,1 @@\n-  const u1* annotation_default = NULL;\n+  const u1* annotation_default = nullptr;\n@@ -2408,1 +2338,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -2427,1 +2357,1 @@\n-      assert(code_start != NULL, \"null code start\");\n+      assert(code_start != nullptr, \"null code start\");\n@@ -2541,1 +2471,1 @@\n-            return NULL;\n+            return nullptr;\n@@ -2543,1 +2473,1 @@\n-          stackmap_data = parse_stackmap_table(cfs, code_attribute_length, _need_verify, CHECK_NULL);\n+          stackmap_data = parse_stackmap_table(cfs, code_attribute_length, CHECK_NULL);\n@@ -2562,1 +2492,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -2575,1 +2505,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -2584,1 +2514,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -2597,1 +2527,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -2606,1 +2536,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -2614,1 +2544,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2620,1 +2550,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2624,1 +2554,1 @@\n-        if (runtime_visible_annotations != NULL) {\n+        if (runtime_visible_annotations != nullptr) {\n@@ -2628,1 +2558,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2632,1 +2562,1 @@\n-        assert(runtime_visible_annotations != NULL, \"null visible annotations\");\n+        assert(runtime_visible_annotations != nullptr, \"null visible annotations\");\n@@ -2646,1 +2576,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2652,1 +2582,1 @@\n-          assert(runtime_invisible_annotations != NULL, \"null invisible annotations\");\n+          assert(runtime_invisible_annotations != nullptr, \"null invisible annotations\");\n@@ -2656,1 +2586,1 @@\n-        if (runtime_visible_parameter_annotations != NULL) {\n+        if (runtime_visible_parameter_annotations != nullptr) {\n@@ -2660,1 +2590,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2664,1 +2594,1 @@\n-        assert(runtime_visible_parameter_annotations != NULL, \"null visible parameter annotations\");\n+        assert(runtime_visible_parameter_annotations != nullptr, \"null visible parameter annotations\");\n@@ -2671,1 +2601,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2677,1 +2607,1 @@\n-          assert(runtime_invisible_parameter_annotations != NULL,\n+          assert(runtime_invisible_parameter_annotations != nullptr,\n@@ -2682,1 +2612,1 @@\n-        if (annotation_default != NULL) {\n+        if (annotation_default != nullptr) {\n@@ -2686,1 +2616,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2690,1 +2620,1 @@\n-        assert(annotation_default != NULL, \"null annotation default\");\n+        assert(annotation_default != nullptr, \"null annotation default\");\n@@ -2693,1 +2623,1 @@\n-        if (runtime_visible_type_annotations != NULL) {\n+        if (runtime_visible_type_annotations != nullptr) {\n@@ -2697,1 +2627,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2701,1 +2631,1 @@\n-        assert(runtime_visible_type_annotations != NULL, \"null visible type annotations\");\n+        assert(runtime_visible_type_annotations != nullptr, \"null visible type annotations\");\n@@ -2709,1 +2639,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2716,1 +2646,1 @@\n-          assert(runtime_invisible_type_annotations != NULL, \"null invisible type annotations\");\n+          assert(runtime_invisible_type_annotations != nullptr, \"null invisible type annotations\");\n@@ -2729,1 +2659,1 @@\n-  if (linenumber_table != NULL) {\n+  if (linenumber_table != nullptr) {\n@@ -2765,0 +2695,1 @@\n+                                     _cp->symbol_at(name_index),\n@@ -2773,1 +2704,1 @@\n-  m->compute_from_signature(cp->symbol_at(signature_index));\n+  m->constMethod()->compute_from_signature(cp->symbol_at(signature_index), access_flags.is_static());\n@@ -2779,1 +2710,1 @@\n-  if (stackmap_data != NULL) {\n+  if (stackmap_data != nullptr) {\n@@ -2790,1 +2721,1 @@\n-  if (linenumber_table != NULL) {\n+  if (linenumber_table != nullptr) {\n@@ -2825,1 +2756,1 @@\n-    promoted_flags->set_has_localvariable_table();\n+    *has_localvariable_table = true;\n@@ -2840,1 +2771,1 @@\n-    m->set_hidden(true);\n+    m->set_is_hidden();\n@@ -2861,1 +2792,2 @@\n-  if (name == vmSymbols::finalize_method_name() &&\n+  if (InstanceKlass::is_finalization_enabled() &&\n+      name == vmSymbols::finalize_method_name() &&\n@@ -2880,3 +2812,0 @@\n-\/\/ The promoted_flags parameter is used to pass relevant access_flags\n-\/\/ from the methods back up to the containing klass. These flag values\n-\/\/ are added to klass's access_flags.\n@@ -2886,1 +2815,1 @@\n-                                    AccessFlags* promoted_flags,\n+                                    bool* const has_localvariable_table,\n@@ -2890,4 +2819,4 @@\n-  assert(cfs != NULL, \"invariant\");\n-  assert(promoted_flags != NULL, \"invariant\");\n-  assert(has_final_method != NULL, \"invariant\");\n-  assert(declares_nonstatic_concrete_methods != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n+  assert(has_localvariable_table != nullptr, \"invariant\");\n+  assert(has_final_method != nullptr, \"invariant\");\n+  assert(declares_nonstatic_concrete_methods != nullptr, \"invariant\");\n@@ -2895,1 +2824,1 @@\n-  assert(NULL == _methods, \"invariant\");\n+  assert(nullptr == _methods, \"invariant\");\n@@ -2904,1 +2833,1 @@\n-                                                   NULL,\n+                                                   nullptr,\n@@ -2911,1 +2840,1 @@\n-                                    promoted_flags,\n+                                    has_localvariable_table,\n@@ -2929,17 +2858,10 @@\n-      NameSigHash** names_and_sigs = NEW_RESOURCE_ARRAY_IN_THREAD(\n-        THREAD, NameSigHash*, HASH_ROW_SIZE);\n-      initialize_hashtable(names_and_sigs);\n-      bool dup = false;\n-      const Symbol* name = NULL;\n-      const Symbol* sig = NULL;\n-      {\n-        debug_only(NoSafepointVerifier nsv;)\n-        for (int i = 0; i < length; i++) {\n-          const Method* const m = _methods->at(i);\n-          name = m->name();\n-          sig = m->signature();\n-          \/\/ If no duplicates, add name\/signature in hashtable names_and_sigs.\n-          if (!put_after_lookup(name, sig, names_and_sigs)) {\n-            dup = true;\n-            break;\n-          }\n+      \/\/ Set containing name-signature pairs\n+      NameSigHashtable* names_and_sigs = new NameSigHashtable();\n+      for (int i = 0; i < length; i++) {\n+        const Method* const m = _methods->at(i);\n+        NameSigHash name_and_sig(m->name(), m->signature());\n+        \/\/ If no duplicates, add name\/signature in hashtable names_and_sigs.\n+        if(!names_and_sigs->put(name_and_sig, 0)) {\n+          classfile_parse_error(\"Duplicate method name \\\"%s\\\" with signature \\\"%s\\\" in class file %s\",\n+                                 name_and_sig._name->as_C_string(), name_and_sig._sig->as_klass_external_name(), THREAD);\n+          return;\n@@ -2948,4 +2870,0 @@\n-      if (dup) {\n-        classfile_parse_error(\"Duplicate method name \\\"%s\\\" with signature \\\"%s\\\" in class file %s\",\n-                               name->as_C_string(), sig->as_klass_external_name(), THREAD);\n-      }\n@@ -2974,1 +2892,1 @@\n-  intArray* method_ordering = NULL;\n+  intArray* method_ordering = nullptr;\n@@ -2993,1 +2911,1 @@\n-  assert(cfs != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n@@ -3007,1 +2925,1 @@\n-  assert(cfs != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n@@ -3021,1 +2939,1 @@\n-  assert(cfs != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n@@ -3024,1 +2942,1 @@\n-  assert(sde_buffer != NULL, \"null sde buffer\");\n+  assert(sde_buffer != nullptr, \"null sde buffer\");\n@@ -3076,0 +2994,1 @@\n+\n@@ -3105,8 +3024,9 @@\n-      \/\/ To maintain compatibility, throw an exception if duplicate inner classes\n-      \/\/ entries are found.\n-      guarantee_property((_inner_classes->at(idx) != _inner_classes->at(y) ||\n-                          _inner_classes->at(idx+1) != _inner_classes->at(y+1) ||\n-                          _inner_classes->at(idx+2) != _inner_classes->at(y+2) ||\n-                          _inner_classes->at(idx+3) != _inner_classes->at(y+3)),\n-                         \"Duplicate entry in InnerClasses attribute in class file %s\",\n-                         CHECK_(true));\n+      \/\/ 4347400: make sure there's no duplicate entry in the classes array\n+      if (_major_version >= JAVA_1_5_VERSION) {\n+        guarantee_property((_inner_classes->at(idx) != _inner_classes->at(y) ||\n+                            _inner_classes->at(idx+1) != _inner_classes->at(y+1) ||\n+                            _inner_classes->at(idx+2) != _inner_classes->at(y+2) ||\n+                            _inner_classes->at(idx+3) != _inner_classes->at(y+3)),\n+                           \"Duplicate entry in InnerClasses attribute in class file %s\",\n+                           CHECK_(true));\n+      }\n@@ -3132,1 +3052,1 @@\n-  if (inner_classes_attribute_start != NULL) {\n+  if (inner_classes_attribute_start != nullptr) {\n@@ -3167,0 +3087,7 @@\n+\n+    if (outer_class_info_index != 0) {\n+      const Symbol* const outer_class_name = cp->klass_name_at(outer_class_info_index);\n+      char* bytes = (char*)outer_class_name->bytes();\n+      guarantee_property(bytes[0] != JVM_SIGNATURE_ARRAY,\n+                         \"Outer class is an array class in class file %s\", CHECK_0);\n+    }\n@@ -3198,2 +3125,1 @@\n-  \/\/ 4347400: make sure there's no duplicate entry in the classes array\n-  \/\/ Also, check for circular entries.\n+  \/\/ Check for circular and duplicate entries.\n@@ -3201,1 +3127,1 @@\n-  if (_need_verify && _major_version >= JAVA_1_5_VERSION) {\n+  if (_need_verify) {\n@@ -3233,1 +3159,1 @@\n-  if (nest_members_attribute_start != NULL) {\n+  if (nest_members_attribute_start != nullptr) {\n@@ -3265,1 +3191,1 @@\n-  if (permitted_subclasses_attribute_start != NULL) {\n+  if (permitted_subclasses_attribute_start != nullptr) {\n@@ -3313,1 +3239,1 @@\n-  if (record_attribute_start != NULL) {\n+  if (record_attribute_start != nullptr) {\n@@ -3321,1 +3247,1 @@\n-    MetadataFactory::new_array<RecordComponent*>(_loader_data, components_count, NULL, CHECK_0);\n+    MetadataFactory::new_array<RecordComponent*>(_loader_data, components_count, nullptr, CHECK_0);\n@@ -3344,1 +3270,1 @@\n-    const u1* runtime_visible_annotations = NULL;\n+    const u1* runtime_visible_annotations = nullptr;\n@@ -3346,1 +3272,1 @@\n-    const u1* runtime_invisible_annotations = NULL;\n+    const u1* runtime_invisible_annotations = nullptr;\n@@ -3349,1 +3275,1 @@\n-    const u1* runtime_visible_type_annotations = NULL;\n+    const u1* runtime_visible_type_annotations = nullptr;\n@@ -3351,1 +3277,1 @@\n-    const u1* runtime_invisible_type_annotations = NULL;\n+    const u1* runtime_invisible_type_annotations = nullptr;\n@@ -3384,1 +3310,1 @@\n-        if (runtime_visible_annotations != NULL) {\n+        if (runtime_visible_annotations != nullptr) {\n@@ -3392,1 +3318,1 @@\n-        assert(runtime_visible_annotations != NULL, \"null record component visible annotation\");\n+        assert(runtime_visible_annotations != nullptr, \"null record component visible annotation\");\n@@ -3406,1 +3332,1 @@\n-          assert(runtime_invisible_annotations != NULL, \"null record component invisible annotation\");\n+          assert(runtime_invisible_annotations != nullptr, \"null record component invisible annotation\");\n@@ -3411,1 +3337,1 @@\n-        if (runtime_visible_type_annotations != NULL) {\n+        if (runtime_visible_type_annotations != nullptr) {\n@@ -3419,1 +3345,1 @@\n-        assert(runtime_visible_type_annotations != NULL, \"null record component visible type annotation\");\n+        assert(runtime_visible_type_annotations != nullptr, \"null record component visible type annotation\");\n@@ -3433,1 +3359,1 @@\n-          assert(runtime_invisible_type_annotations != NULL, \"null record component invisible type annotation\");\n+          assert(runtime_invisible_type_annotations != nullptr, \"null record component invisible type annotation\");\n@@ -3472,1 +3398,1 @@\n-  assert(cfs != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n@@ -3486,2 +3412,2 @@\n-  assert(cfs != NULL, \"invariant\");\n-  assert(cp != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n@@ -3568,3 +3494,3 @@\n-  assert(cfs != NULL, \"invariant\");\n-  assert(cp != NULL, \"invariant\");\n-  assert(parsed_annotations != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n+  assert(parsed_annotations != nullptr, \"invariant\");\n@@ -3588,1 +3514,1 @@\n-  const u1* runtime_visible_annotations = NULL;\n+  const u1* runtime_visible_annotations = nullptr;\n@@ -3590,1 +3516,1 @@\n-  const u1* runtime_invisible_annotations = NULL;\n+  const u1* runtime_invisible_annotations = nullptr;\n@@ -3592,1 +3518,1 @@\n-  const u1* runtime_visible_type_annotations = NULL;\n+  const u1* runtime_visible_type_annotations = nullptr;\n@@ -3594,1 +3520,1 @@\n-  const u1* runtime_invisible_type_annotations = NULL;\n+  const u1* runtime_invisible_type_annotations = nullptr;\n@@ -3599,1 +3525,1 @@\n-  const u1* inner_classes_attribute_start = NULL;\n+  const u1* inner_classes_attribute_start = nullptr;\n@@ -3603,1 +3529,1 @@\n-  const u1* nest_members_attribute_start = NULL;\n+  const u1* nest_members_attribute_start = nullptr;\n@@ -3605,1 +3531,1 @@\n-  const u1* record_attribute_start = NULL;\n+  const u1* record_attribute_start = nullptr;\n@@ -3607,1 +3533,1 @@\n-  const u1* permitted_subclasses_attribute_start = NULL;\n+  const u1* permitted_subclasses_attribute_start = nullptr;\n@@ -3685,1 +3611,1 @@\n-        if (runtime_visible_annotations != NULL) {\n+        if (runtime_visible_annotations != nullptr) {\n@@ -3692,1 +3618,1 @@\n-        assert(runtime_visible_annotations != NULL, \"null visible annotations\");\n+        assert(runtime_visible_annotations != nullptr, \"null visible annotations\");\n@@ -3711,1 +3637,1 @@\n-          assert(runtime_invisible_annotations != NULL, \"null invisible annotations\");\n+          assert(runtime_invisible_annotations != nullptr, \"null invisible annotations\");\n@@ -3749,1 +3675,1 @@\n-        if (runtime_visible_type_annotations != NULL) {\n+        if (runtime_visible_type_annotations != nullptr) {\n@@ -3756,1 +3682,1 @@\n-        assert(runtime_visible_type_annotations != NULL, \"null visible type annotations\");\n+        assert(runtime_visible_type_annotations != nullptr, \"null visible type annotations\");\n@@ -3770,1 +3696,1 @@\n-          assert(runtime_invisible_type_annotations != NULL, \"null invisible type annotations\");\n+          assert(runtime_invisible_type_annotations != nullptr, \"null invisible type annotations\");\n@@ -3922,1 +3848,1 @@\n-  assert(k != NULL, \"invariant\");\n+  assert(k != nullptr, \"invariant\");\n@@ -3932,1 +3858,1 @@\n-  if (_sde_buffer != NULL) {\n+  if (_sde_buffer != nullptr) {\n@@ -3940,4 +3866,4 @@\n-    if (_class_annotations == NULL &&\n-        _class_type_annotations == NULL &&\n-        _fields_annotations == NULL &&\n-        _fields_type_annotations == NULL) {\n+    if (_class_annotations == nullptr &&\n+        _class_type_annotations == nullptr &&\n+        _fields_annotations == nullptr &&\n+        _fields_type_annotations == nullptr) {\n@@ -3958,1 +3884,1 @@\n-    \/\/ The annotations arrays below has been transfered the\n+    \/\/ The annotations arrays below has been transferred the\n@@ -3960,4 +3886,4 @@\n-    _class_annotations       = NULL;\n-    _class_type_annotations  = NULL;\n-    _fields_annotations      = NULL;\n-    _fields_type_annotations = NULL;\n+    _class_annotations       = nullptr;\n+    _class_type_annotations  = nullptr;\n+    _fields_annotations      = nullptr;\n+    _fields_type_annotations = nullptr;\n@@ -3970,1 +3896,1 @@\n-  assert(this_klass != NULL, \"invariant\");\n+  assert(this_klass != nullptr, \"invariant\");\n@@ -3974,1 +3900,2 @@\n-  this_klass->set_fields(_fields, java_fields_count);\n+  this_klass->set_fieldinfo_stream(_fieldinfo_stream);\n+  this_klass->set_fields_status(_fields_status);\n@@ -3999,3 +3926,3 @@\n-  AnnotationArray* annotations = NULL;\n-  if (runtime_visible_annotations != NULL ||\n-      runtime_invisible_annotations != NULL) {\n+  AnnotationArray* annotations = nullptr;\n+  if (runtime_visible_annotations != nullptr ||\n+      runtime_invisible_annotations != nullptr) {\n@@ -4006,1 +3933,1 @@\n-    if (runtime_visible_annotations != NULL) {\n+    if (runtime_visible_annotations != nullptr) {\n@@ -4011,1 +3938,1 @@\n-    if (runtime_invisible_annotations != NULL) {\n+    if (runtime_invisible_annotations != nullptr) {\n@@ -4025,2 +3952,2 @@\n-  assert(cp != NULL, \"invariant\");\n-  const InstanceKlass* super_klass = NULL;\n+  assert(cp != nullptr, \"invariant\");\n+  const InstanceKlass* super_klass = nullptr;\n@@ -4060,1 +3987,1 @@\n-    _nonstatic_oop_maps = NULL;\n+    _nonstatic_oop_maps = nullptr;\n@@ -4115,1 +4042,1 @@\n-   * Since field layout sneeks in oops before values, we will be able to condense\n+   * Since field layout sneaks in oops before values, we will be able to condense\n@@ -4173,1 +4100,1 @@\n-  assert(ik != NULL, \"invariant\");\n+  assert(ik != nullptr, \"invariant\");\n@@ -4175,1 +4102,1 @@\n-  const Klass* const super = ik->super();\n+  const InstanceKlass* const super = ik->java_super();\n@@ -4181,1 +4108,1 @@\n-        (super != NULL && super->has_finalizer())) {\n+        (super != nullptr && super->has_finalizer())) {\n@@ -4190,1 +4117,2 @@\n-  if (m != NULL && !m->is_empty_method()) {\n+  if (InstanceKlass::is_finalization_enabled() &&\n+      (m != nullptr) && !m->is_empty_method()) {\n@@ -4210,1 +4138,1 @@\n-  if (super == NULL) {\n+  if (super == nullptr) {\n@@ -4224,1 +4152,1 @@\n-      if (constructor != NULL && constructor->is_vanilla_constructor()) {\n+      if (constructor != nullptr && constructor->is_vanilla_constructor()) {\n@@ -4237,1 +4165,1 @@\n-      || (ik->name() == vmSymbols::java_lang_Class() && ik->class_loader() == NULL)\n+      || (ik->name() == vmSymbols::java_lang_Class() && ik->class_loader() == nullptr)\n@@ -4262,2 +4190,2 @@\n-  assert(local_ifs != NULL, \"invariant\");\n-  assert(loader_data != NULL, \"invariant\");\n+  assert(local_ifs != nullptr, \"invariant\");\n+  assert(loader_data != nullptr, \"invariant\");\n@@ -4269,1 +4197,1 @@\n-  if (super != NULL) {\n+  if (super != nullptr) {\n@@ -4296,1 +4224,1 @@\n-    if (super != NULL) {\n+    if (super != nullptr) {\n@@ -4315,1 +4243,1 @@\n-      assert(e != NULL, \"just checking\");\n+      assert(e != nullptr, \"just checking\");\n@@ -4323,1 +4251,1 @@\n-  assert(this_klass != NULL, \"invariant\");\n+  assert(this_klass != nullptr, \"invariant\");\n@@ -4326,1 +4254,1 @@\n-  if (super != NULL) {\n+  if (super != nullptr) {\n@@ -4344,1 +4272,1 @@\n-      if (super_package != NULL &&\n+      if (super_package != nullptr &&\n@@ -4366,1 +4294,1 @@\n-      if (msg == NULL) {\n+      if (msg == nullptr) {\n@@ -4392,1 +4320,1 @@\n-  assert(this_klass != NULL, \"invariant\");\n+  assert(this_klass != nullptr, \"invariant\");\n@@ -4397,1 +4325,1 @@\n-    assert (k != NULL && k->is_interface(), \"invalid interface\");\n+    assert (k != nullptr && k->is_interface(), \"invalid interface\");\n@@ -4414,1 +4342,1 @@\n-      if (msg == NULL) {\n+      if (msg == nullptr) {\n@@ -4439,1 +4367,1 @@\n-  assert(this_klass != NULL, \"invariant\");\n+  assert(this_klass != nullptr, \"invariant\");\n@@ -4453,3 +4381,3 @@\n-      const Klass* k = this_klass->super();\n-      const Method* super_m = NULL;\n-      while (k != NULL) {\n+      const InstanceKlass* k = this_klass->java_super();\n+      const Method* super_m = nullptr;\n+      while (k != nullptr) {\n@@ -4460,1 +4388,1 @@\n-          if (super_m == NULL) {\n+          if (super_m == nullptr) {\n@@ -4485,1 +4413,1 @@\n-          k = super_m->method_holder()->super();\n+          k = super_m->method_holder()->java_super();\n@@ -4489,1 +4417,1 @@\n-        k = k->super();\n+        k = k->java_super();\n@@ -4498,1 +4426,1 @@\n-  assert(this_klass != NULL, \"invariant\");\n+  assert(this_klass != nullptr, \"invariant\");\n@@ -4544,1 +4472,0 @@\n-  const bool major_gte_14  = _major_version >= JAVA_14_VERSION;\n@@ -4800,1 +4727,1 @@\n-\/\/ be taken as a fieldname. Allow '\/' if slash_ok is true.\n+\/\/ be taken as a fieldname. Allow non-trailing '\/'s if slash_ok is true.\n@@ -4802,1 +4729,1 @@\n-\/\/ Return NULL if no fieldname at all was found, or in the case of slash_ok\n+\/\/ Return null if no fieldname at all was found, or in the case of slash_ok\n@@ -4827,1 +4754,1 @@\n-          return NULL;  \/\/ Don't permit consecutive slashes\n+          return nullptr;  \/\/ Don't permit consecutive slashes\n@@ -4866,1 +4793,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -4872,1 +4799,1 @@\n-    return (not_first_ch) ? old_p : NULL;\n+    return (not_first_ch) ? old_p : nullptr;\n@@ -4874,1 +4801,1 @@\n-  return (not_first_ch) ? p : NULL;\n+  return (not_first_ch && !last_is_slash) ? p : nullptr;\n@@ -4881,1 +4808,1 @@\n-\/\/ Return NULL if no legal signature is found.\n+\/\/ Return null if no legal signature is found.\n@@ -4889,1 +4816,1 @@\n-    case JVM_SIGNATURE_VOID: if (!void_ok) { return NULL; }\n+    case JVM_SIGNATURE_VOID: if (!void_ok) { return nullptr; }\n@@ -4914,1 +4841,1 @@\n-        if (c != NULL) {\n+        if (c != nullptr) {\n@@ -4921,1 +4848,1 @@\n-            return NULL;\n+            return nullptr;\n@@ -4926,1 +4853,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -4933,1 +4860,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -4941,1 +4868,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -4944,1 +4871,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -4960,1 +4887,1 @@\n-      legal = (p != NULL) && ((p - bytes) == (int)length);\n+      legal = (p != nullptr) && ((p - bytes) == (int)length);\n@@ -4964,1 +4891,1 @@\n-        legal = (p != NULL) && ((p - bytes) == (int)length);\n+        legal = (p != nullptr) && ((p - bytes) == (int)length);\n@@ -4976,1 +4903,1 @@\n-    assert(_class_name != NULL, \"invariant\");\n+    assert(_class_name != nullptr, \"invariant\");\n@@ -4999,1 +4926,1 @@\n-        legal = (p != NULL) && ((p - bytes) == (int)length);\n+        legal = (p != nullptr) && ((p - bytes) == (int)length);\n@@ -5009,1 +4936,1 @@\n-    assert(_class_name != NULL, \"invariant\");\n+    assert(_class_name != nullptr, \"invariant\");\n@@ -5024,1 +4951,1 @@\n-  assert(name != NULL, \"method name is null\");\n+  assert(name != nullptr, \"method name is null\");\n@@ -5037,1 +4964,1 @@\n-      legal = (p != NULL) && ((p - bytes) == (int)length);\n+      legal = (p != nullptr) && ((p - bytes) == (int)length);\n@@ -5046,1 +4973,1 @@\n-    assert(_class_name != NULL, \"invariant\");\n+    assert(_class_name != nullptr, \"invariant\");\n@@ -5068,1 +4995,1 @@\n-  if (p == NULL || (p - bytes) != (int)length) {\n+  if (p == nullptr || (p - bytes) != (int)length) {\n@@ -5073,0 +5000,26 @@\n+\/\/ Check that the signature is compatible with the method name.  For example,\n+\/\/ check that <init> has a void signature.\n+void ClassFileParser::verify_legal_name_with_signature(const Symbol* name,\n+                                                       const Symbol* signature,\n+                                                       TRAPS) const {\n+  if (!_need_verify) {\n+    return;\n+  }\n+\n+  \/\/ Class initializers cannot have args for class format version >= 51.\n+  if (name == vmSymbols::class_initializer_name() &&\n+      signature != vmSymbols::void_method_signature() &&\n+      _major_version >= JAVA_7_VERSION) {\n+    throwIllegalSignature(\"Method\", name, signature, THREAD);\n+    return;\n+  }\n+\n+  int sig_length = signature->utf8_length();\n+  if (name->utf8_length() > 0 &&\n+      name->char_at(0) == JVM_SIGNATURE_SPECIAL &&\n+      sig_length > 0 &&\n+      signature->char_at(sig_length - 1) != JVM_SIGNATURE_VOID) {\n+    throwIllegalSignature(\"Method\", name, signature, THREAD);\n+  }\n+}\n+\n@@ -5084,8 +5037,0 @@\n-  \/\/ Class initializers cannot have args for class format version >= 51.\n-  if (name == vmSymbols::class_initializer_name() &&\n-      signature != vmSymbols::void_method_signature() &&\n-      _major_version >= JAVA_7_VERSION) {\n-    throwIllegalSignature(\"Method\", name, signature, CHECK_0);\n-    return 0;\n-  }\n-\n@@ -5102,1 +5047,1 @@\n-    while ((length > 0) && (nextp != NULL)) {\n+    while ((length > 0) && (nextp != nullptr)) {\n@@ -5114,11 +5059,4 @@\n-      if (name->utf8_length() > 0 && name->char_at(0) == JVM_SIGNATURE_SPECIAL) {\n-        \/\/ All internal methods must return void\n-        if ((length == 1) && (p[0] == JVM_SIGNATURE_VOID)) {\n-          return args_size;\n-        }\n-      } else {\n-        \/\/ Now we better just have a return value\n-        nextp = skip_over_field_signature(p, true, length, CHECK_0);\n-        if (nextp && ((int)length == (nextp - p))) {\n-          return args_size;\n-        }\n+      \/\/ Now we better just have a return value\n+      nextp = skip_over_field_signature(p, true, length, CHECK_0);\n+      if (nextp && ((int)length == (nextp - p))) {\n+        return args_size;\n@@ -5129,1 +5067,1 @@\n-  throwIllegalSignature(\"Method\", name, signature, CHECK_0);\n+  throwIllegalSignature(\"Method\", name, signature, THREAD);\n@@ -5134,1 +5072,1 @@\n-  assert(_field_info != NULL, \"invariant\");\n+  assert(_field_info != nullptr, \"invariant\");\n@@ -5139,1 +5077,1 @@\n-  assert(_field_info != NULL, \"invariant\");\n+  assert(_field_info != nullptr, \"invariant\");\n@@ -5144,1 +5082,1 @@\n-  assert(_field_info != NULL, \"invariant\");\n+  assert(_field_info != nullptr, \"invariant\");\n@@ -5150,2 +5088,2 @@\n-  assert(ik != NULL, \"invariant\");\n-  assert(methods != NULL, \"invariant\");\n+  assert(ik != nullptr, \"invariant\");\n+  assert(methods != nullptr, \"invariant\");\n@@ -5246,1 +5184,1 @@\n-  if (_klass != NULL) {\n+  if (_klass != nullptr) {\n@@ -5268,1 +5206,1 @@\n-  assert(ik != NULL, \"invariant\");\n+  assert(ik != nullptr, \"invariant\");\n@@ -5275,1 +5213,1 @@\n-  \/\/ including classes in the bootstrap (NULL) class loader.\n+  \/\/ including classes in the bootstrap (null) class loader.\n@@ -5282,1 +5220,1 @@\n-  assert(_field_info != NULL, \"invariant\");\n+  assert(_field_info != nullptr, \"invariant\");\n@@ -5296,1 +5234,1 @@\n-  assert(_fac != NULL, \"invariant\");\n+  assert(_fac != nullptr, \"invariant\");\n@@ -5304,1 +5242,1 @@\n-  if (cl_inst_info.dynamic_nest_host() != NULL) {\n+  if (cl_inst_info.dynamic_nest_host() != nullptr) {\n@@ -5309,8 +5247,13 @@\n-  assert(NULL == _cp, \"invariant\");\n-  assert(NULL == _fields, \"invariant\");\n-  assert(NULL == _methods, \"invariant\");\n-  assert(NULL == _inner_classes, \"invariant\");\n-  assert(NULL == _nest_members, \"invariant\");\n-  assert(NULL == _combined_annotations, \"invariant\");\n-  assert(NULL == _record_components, \"invariant\");\n-  assert(NULL == _permitted_subclasses, \"invariant\");\n+  assert(nullptr == _cp, \"invariant\");\n+  assert(nullptr == _fieldinfo_stream, \"invariant\");\n+  assert(nullptr == _fields_status, \"invariant\");\n+  assert(nullptr == _methods, \"invariant\");\n+  assert(nullptr == _inner_classes, \"invariant\");\n+  assert(nullptr == _nest_members, \"invariant\");\n+  assert(nullptr == _combined_annotations, \"invariant\");\n+  assert(nullptr == _record_components, \"invariant\");\n+  assert(nullptr == _permitted_subclasses, \"invariant\");\n+\n+  if (_has_localvariable_table) {\n+    ik->set_has_localvariable_table(true);\n+  }\n@@ -5356,1 +5299,1 @@\n-  ik->set_package(cld, NULL, CHECK);\n+  ik->set_package(cld, nullptr, CHECK);\n@@ -5359,1 +5302,1 @@\n-  assert(methods != NULL, \"invariant\");\n+  assert(methods != nullptr, \"invariant\");\n@@ -5374,1 +5317,1 @@\n-      (_super_klass != NULL && _super_klass->has_miranda_methods())\n+      (_super_klass != nullptr && _super_klass->has_miranda_methods())\n@@ -5384,2 +5327,2 @@\n-  _transitive_interfaces = NULL;\n-  _local_interfaces = NULL;\n+  _transitive_interfaces = nullptr;\n+  _local_interfaces = nullptr;\n@@ -5398,1 +5341,1 @@\n-      ( _super_klass != NULL && _super_klass->has_contended_annotations())) {\n+      ( _super_klass != nullptr && _super_klass->has_contended_annotations())) {\n@@ -5421,1 +5364,1 @@\n-  assert(module_entry != NULL, \"module_entry should always be set\");\n+  assert(module_entry != nullptr, \"module_entry should always be set\");\n@@ -5435,1 +5378,1 @@\n-  assert(_all_mirandas != NULL, \"invariant\");\n+  assert(_all_mirandas != nullptr, \"invariant\");\n@@ -5490,1 +5433,1 @@\n-      if (ik->java_super() != NULL) {\n+      if (ik->java_super() != nullptr) {\n@@ -5497,1 +5440,1 @@\n-      if (local_interfaces != NULL) {\n+      if (local_interfaces != nullptr) {\n@@ -5513,1 +5456,1 @@\n-  set_klass_to_deallocate(NULL);\n+  set_klass_to_deallocate(nullptr);\n@@ -5550,1 +5493,1 @@\n-  _class_name(NULL),\n+  _class_name(nullptr),\n@@ -5556,5 +5499,6 @@\n-  _cp(NULL),\n-  _fields(NULL),\n-  _methods(NULL),\n-  _inner_classes(NULL),\n-  _nest_members(NULL),\n+  _cp(nullptr),\n+  _fieldinfo_stream(nullptr),\n+  _fields_status(nullptr),\n+  _methods(nullptr),\n+  _inner_classes(nullptr),\n+  _nest_members(nullptr),\n@@ -5562,16 +5506,17 @@\n-  _permitted_subclasses(NULL),\n-  _record_components(NULL),\n-  _local_interfaces(NULL),\n-  _transitive_interfaces(NULL),\n-  _combined_annotations(NULL),\n-  _class_annotations(NULL),\n-  _class_type_annotations(NULL),\n-  _fields_annotations(NULL),\n-  _fields_type_annotations(NULL),\n-  _klass(NULL),\n-  _klass_to_deallocate(NULL),\n-  _parsed_annotations(NULL),\n-  _fac(NULL),\n-  _field_info(NULL),\n-  _method_ordering(NULL),\n-  _all_mirandas(NULL),\n+  _permitted_subclasses(nullptr),\n+  _record_components(nullptr),\n+  _local_interfaces(nullptr),\n+  _transitive_interfaces(nullptr),\n+  _combined_annotations(nullptr),\n+  _class_annotations(nullptr),\n+  _class_type_annotations(nullptr),\n+  _fields_annotations(nullptr),\n+  _fields_type_annotations(nullptr),\n+  _klass(nullptr),\n+  _klass_to_deallocate(nullptr),\n+  _parsed_annotations(nullptr),\n+  _fac(nullptr),\n+  _field_info(nullptr),\n+  _temp_field_info(nullptr),\n+  _method_ordering(nullptr),\n+  _all_mirandas(nullptr),\n@@ -5581,1 +5526,0 @@\n-  _rt(REF_NONE),\n@@ -5588,1 +5532,1 @@\n-  _sde_buffer(NULL),\n+  _sde_buffer(nullptr),\n@@ -5601,0 +5545,1 @@\n+  _has_localvariable_table(false),\n@@ -5608,1 +5553,1 @@\n-  _class_name = name != NULL ? name : vmSymbols::unknown_class_name();\n+  _class_name = name != nullptr ? name : vmSymbols::unknown_class_name();\n@@ -5611,3 +5556,3 @@\n-  assert(_loader_data != NULL, \"invariant\");\n-  assert(stream != NULL, \"invariant\");\n-  assert(_stream != NULL, \"invariant\");\n+  assert(_loader_data != nullptr, \"invariant\");\n+  assert(stream != nullptr, \"invariant\");\n+  assert(_stream != nullptr, \"invariant\");\n@@ -5615,1 +5560,1 @@\n-  assert(_class_name != NULL, \"invariant\");\n+  assert(_class_name != nullptr, \"invariant\");\n@@ -5646,10 +5591,11 @@\n-  _cp = NULL;\n-  _fields = NULL;\n-  _methods = NULL;\n-  _inner_classes = NULL;\n-  _nest_members = NULL;\n-  _permitted_subclasses = NULL;\n-  _combined_annotations = NULL;\n-  _class_annotations = _class_type_annotations = NULL;\n-  _fields_annotations = _fields_type_annotations = NULL;\n-  _record_components = NULL;\n+  _cp = nullptr;\n+  _fieldinfo_stream = nullptr;\n+  _fields_status = nullptr;\n+  _methods = nullptr;\n+  _inner_classes = nullptr;\n+  _nest_members = nullptr;\n+  _permitted_subclasses = nullptr;\n+  _combined_annotations = nullptr;\n+  _class_annotations = _class_type_annotations = nullptr;\n+  _fields_annotations = _fields_type_annotations = nullptr;\n+  _record_components = nullptr;\n@@ -5662,1 +5608,1 @@\n-  if (_cp != NULL) {\n+  if (_cp != nullptr) {\n@@ -5665,2 +5611,3 @@\n-  if (_fields != NULL) {\n-    MetadataFactory::free_array<u2>(_loader_data, _fields);\n+\n+  if (_fieldinfo_stream != nullptr) {\n+    MetadataFactory::free_array<u1>(_loader_data, _fieldinfo_stream);\n@@ -5669,1 +5616,5 @@\n-  if (_methods != NULL) {\n+  if (_fields_status != nullptr) {\n+    MetadataFactory::free_array<FieldStatus>(_loader_data, _fields_status);\n+  }\n+\n+  if (_methods != nullptr) {\n@@ -5675,1 +5626,1 @@\n-  if (_inner_classes != NULL && _inner_classes != Universe::the_empty_short_array()) {\n+  if (_inner_classes != nullptr && _inner_classes != Universe::the_empty_short_array()) {\n@@ -5679,1 +5630,1 @@\n-  if (_nest_members != NULL && _nest_members != Universe::the_empty_short_array()) {\n+  if (_nest_members != nullptr && _nest_members != Universe::the_empty_short_array()) {\n@@ -5683,1 +5634,1 @@\n-  if (_record_components != NULL) {\n+  if (_record_components != nullptr) {\n@@ -5687,1 +5638,1 @@\n-  if (_permitted_subclasses != NULL && _permitted_subclasses != Universe::the_empty_short_array()) {\n+  if (_permitted_subclasses != nullptr && _permitted_subclasses != Universe::the_empty_short_array()) {\n@@ -5695,1 +5646,1 @@\n-  if (_combined_annotations != NULL) {\n+  if (_combined_annotations != nullptr) {\n@@ -5702,1 +5653,1 @@\n-    \/\/ If the _combined_annotations pointer is non-NULL,\n+    \/\/ If the _combined_annotations pointer is non-null,\n@@ -5704,4 +5655,4 @@\n-    assert(_class_annotations       == NULL, \"Should have been cleared\");\n-    assert(_class_type_annotations  == NULL, \"Should have been cleared\");\n-    assert(_fields_annotations      == NULL, \"Should have been cleared\");\n-    assert(_fields_type_annotations == NULL, \"Should have been cleared\");\n+    assert(_class_annotations       == nullptr, \"Should have been cleared\");\n+    assert(_class_type_annotations  == nullptr, \"Should have been cleared\");\n+    assert(_fields_annotations      == nullptr, \"Should have been cleared\");\n+    assert(_fields_type_annotations == nullptr, \"Should have been cleared\");\n@@ -5718,2 +5669,2 @@\n-  _transitive_interfaces = NULL;\n-  _local_interfaces = NULL;\n+  _transitive_interfaces = nullptr;\n+  _local_interfaces = nullptr;\n@@ -5724,1 +5675,1 @@\n-  if (_klass_to_deallocate != NULL) {\n+  if (_klass_to_deallocate != nullptr) {\n@@ -5732,2 +5683,2 @@\n-  assert(stream != NULL, \"invariant\");\n-  assert(_class_name != NULL, \"invariant\");\n+  assert(stream != nullptr, \"invariant\");\n+  assert(_class_name != nullptr, \"invariant\");\n@@ -5810,1 +5761,1 @@\n-  assert(class_name_in_cp != NULL, \"class_name can't be null\");\n+  assert(class_name_in_cp != nullptr, \"class_name can't be null\");\n@@ -5831,1 +5782,1 @@\n-    assert(_class_name != NULL, \"Unexpected null _class_name\");\n+    assert(_class_name != nullptr, \"Unexpected null _class_name\");\n@@ -5846,2 +5797,2 @@\n-                           class_name_in_cp->as_C_string(),\n-                           _class_name->as_C_string()\n+                           _class_name->as_C_string(),\n+                           class_name_in_cp->as_C_string()\n@@ -5869,1 +5820,1 @@\n-      if (stream->source() != NULL) {\n+      if (stream->source() != nullptr) {\n@@ -5891,1 +5842,1 @@\n-  assert(_local_interfaces != NULL, \"invariant\");\n+  assert(_local_interfaces != nullptr, \"invariant\");\n@@ -5903,1 +5854,1 @@\n-  assert(_fields != NULL, \"invariant\");\n+  assert(_temp_field_info != nullptr, \"invariant\");\n@@ -5906,1 +5857,0 @@\n-  AccessFlags promoted_flags;\n@@ -5909,1 +5859,1 @@\n-                &promoted_flags,\n+                &_has_localvariable_table,\n@@ -5914,4 +5864,1 @@\n-  assert(_methods != NULL, \"invariant\");\n-\n-  \/\/ promote flags from parse_methods() to the klass' flags\n-  _access_flags.add_promoted_flags(promoted_flags.as_int());\n+  assert(_methods != nullptr, \"invariant\");\n@@ -5927,1 +5874,1 @@\n-  assert(_inner_classes != NULL, \"invariant\");\n+  assert(_inner_classes != nullptr, \"invariant\");\n@@ -5956,1 +5903,1 @@\n-    jio_snprintf(addr_buf, 20, SIZE_FORMAT_HEX, new_id);\n+    jio_snprintf(addr_buf, 20, SIZE_FORMAT_X, new_id);\n@@ -5967,1 +5914,1 @@\n-  assert(_class_name != NULL, \"Unexpected null _class_name\");\n+  assert(_class_name != nullptr, \"Unexpected null _class_name\");\n@@ -5984,1 +5931,1 @@\n-  assert(stream != NULL, \"invariant\");\n+  assert(stream != nullptr, \"invariant\");\n@@ -5986,2 +5933,2 @@\n-  assert(cp != NULL, \"invariant\");\n-  assert(_loader_data != NULL, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n+  assert(_loader_data != nullptr, \"invariant\");\n@@ -5995,1 +5942,1 @@\n-  if (_super_class_index > 0 && NULL == _super_klass) {\n+  if (_super_class_index > 0 && nullptr == _super_klass) {\n@@ -6005,1 +5952,4 @@\n-    _super_klass = (const InstanceKlass*)\n+    if (loader.is_null() && super_class_name == vmSymbols::java_lang_Object()) {\n+      _super_klass = vmClasses::Object_klass();\n+    } else {\n+      _super_klass = (const InstanceKlass*)\n@@ -6012,0 +5962,1 @@\n+    }\n@@ -6014,1 +5965,1 @@\n-  if (_super_klass != NULL) {\n+  if (_super_klass != nullptr) {\n@@ -6032,1 +5983,1 @@\n-  assert(_transitive_interfaces != NULL, \"invariant\");\n+  assert(_transitive_interfaces != nullptr, \"invariant\");\n@@ -6055,2 +6006,2 @@\n-  assert(_fac != NULL, \"invariant\");\n-  assert(_parsed_annotations != NULL, \"invariant\");\n+  assert(_fac != nullptr, \"invariant\");\n+  assert(_parsed_annotations != nullptr, \"invariant\");\n@@ -6059,1 +6010,1 @@\n-  FieldLayoutBuilder lb(class_name(), super_klass(), _cp, _fields,\n+  FieldLayoutBuilder lb(class_name(), super_klass(), _cp, \/*_fields*\/ _temp_field_info,\n@@ -6063,3 +6014,7 @@\n-  \/\/ Compute reference typ\n-  _rt = (NULL ==_super_klass) ? REF_NONE : _super_klass->reference_type();\n-\n+  int injected_fields_count = _temp_field_info->length() - _java_fields_count;\n+  _fieldinfo_stream =\n+    FieldInfoStream::create_FieldInfoStream(_temp_field_info, _java_fields_count,\n+                                            injected_fields_count, loader_data(), CHECK);\n+  _fields_status =\n+    MetadataFactory::new_array<FieldStatus>(_loader_data, _temp_field_info->length(),\n+                                            FieldStatus(0), CHECK);\n@@ -6071,2 +6026,2 @@\n-  if (klass != NULL) {\n-    assert(NULL == _klass, \"leaking?\");\n+  if (klass != nullptr) {\n+    assert(nullptr == _klass, \"leaking?\");\n@@ -6082,2 +6037,2 @@\n-  if (klass != NULL) {\n-    assert(NULL == _klass_to_deallocate, \"leaking?\");\n+  if (klass != nullptr) {\n+    assert(nullptr == _klass_to_deallocate, \"leaking?\");\n@@ -6093,1 +6048,1 @@\n-  assert(_stream != NULL, \"invariant\");\n+  assert(_stream != nullptr, \"invariant\");\n@@ -6097,0 +6052,27 @@\n+\n+ReferenceType ClassFileParser::super_reference_type() const {\n+  return _super_klass == nullptr ? REF_NONE : _super_klass->reference_type();\n+}\n+\n+bool ClassFileParser::is_instance_ref_klass() const {\n+  \/\/ Only the subclasses of j.l.r.Reference are InstanceRefKlass.\n+  \/\/ j.l.r.Reference itself is InstanceKlass because InstanceRefKlass denotes a\n+  \/\/ klass requiring special treatment in ref-processing. The abstract\n+  \/\/ j.l.r.Reference cannot be instantiated so doesn't partake in\n+  \/\/ ref-processing.\n+  return is_java_lang_ref_Reference_subclass();\n+}\n+\n+bool ClassFileParser::is_java_lang_ref_Reference_subclass() const {\n+  if (_super_klass == nullptr) {\n+    return false;\n+  }\n+\n+  if (_super_klass->name() == vmSymbols::java_lang_ref_Reference()) {\n+    \/\/ Direct subclass of j.l.r.Reference: Soft|Weak|Final|Phantom\n+    return true;\n+  }\n+\n+  return _super_klass->reference_type() != REF_NONE;\n+}\n+\n@@ -6104,1 +6086,1 @@\n-  if (class_name != NULL) {\n+  if (class_name != nullptr) {\n@@ -6107,1 +6089,1 @@\n-    return strchr(name, JVM_SIGNATURE_DOT) == NULL;\n+    return strchr(name, JVM_SIGNATURE_DOT) == nullptr;\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":603,"deletions":621,"binary":false,"changes":1224,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,3 +29,3 @@\n-#include \"oops\/oop.hpp\"\n-#include \"oops\/symbol.hpp\"\n-#include \"runtime\/os.hpp\"\n+#include \"oops\/oopsHierarchy.hpp\"\n+#include \"runtime\/handles.hpp\"\n+#include \"utilities\/macros.hpp\"\n@@ -35,0 +35,1 @@\n+class JvmtiThreadState;\n@@ -37,51 +38,0 @@\n-\/\/ Interface for manipulating the basic Java classes.\n-\n-#define BASIC_JAVA_CLASSES_DO_PART1(f) \\\n-  f(java_lang_Class) \\\n-  f(java_lang_String) \\\n-  f(java_lang_ref_Reference) \\\n-  \/\/end\n-\n-#define BASIC_JAVA_CLASSES_DO_PART2(f) \\\n-  f(java_lang_System) \\\n-  f(java_lang_ClassLoader) \\\n-  f(java_lang_Throwable) \\\n-  f(java_lang_Thread) \\\n-  f(java_lang_ThreadGroup) \\\n-  f(java_lang_InternalError) \\\n-  f(java_lang_AssertionStatusDirectives) \\\n-  f(java_lang_ref_SoftReference) \\\n-  f(java_lang_invoke_MethodHandle) \\\n-  f(java_lang_invoke_DirectMethodHandle) \\\n-  f(java_lang_invoke_MemberName) \\\n-  f(java_lang_invoke_ResolvedMethodName) \\\n-  f(java_lang_invoke_LambdaForm) \\\n-  f(java_lang_invoke_MethodType) \\\n-  f(java_lang_invoke_CallSite) \\\n-  f(java_lang_invoke_ConstantCallSite) \\\n-  f(java_lang_invoke_MethodHandleNatives_CallSiteContext) \\\n-  f(java_security_AccessControlContext) \\\n-  f(java_lang_reflect_AccessibleObject) \\\n-  f(java_lang_reflect_Method) \\\n-  f(java_lang_reflect_Constructor) \\\n-  f(java_lang_reflect_Field) \\\n-  f(java_lang_reflect_RecordComponent) \\\n-  f(java_nio_Buffer) \\\n-  f(reflect_ConstantPool) \\\n-  f(reflect_UnsafeStaticFieldAccessorImpl) \\\n-  f(java_lang_reflect_Parameter) \\\n-  f(java_lang_Module) \\\n-  f(java_lang_StackTraceElement) \\\n-  f(java_lang_StackFrameInfo) \\\n-  f(java_lang_LiveStackFrameInfo) \\\n-  f(java_util_concurrent_locks_AbstractOwnableSynchronizer) \\\n-  f(jdk_internal_invoke_NativeEntryPoint) \\\n-  f(jdk_internal_misc_UnsafeConstants) \\\n-  f(java_lang_boxing_object) \\\n-  f(vector_VectorPayload) \\\n-  \/\/end\n-\n-#define BASIC_JAVA_CLASSES_DO(f) \\\n-        BASIC_JAVA_CLASSES_DO_PART1(f) \\\n-        BASIC_JAVA_CLASSES_DO_PART2(f)\n-\n@@ -131,0 +81,2 @@\n+  static inline unsigned int hash_code_impl(oop java_string, bool update);\n+\n@@ -149,1 +101,0 @@\n-  static Handle char_converter(Handle java_string, jchar from_char, jchar to_char, TRAPS);\n@@ -227,0 +178,1 @@\n+  static unsigned int hash_code_noupdate(oop java_string);\n@@ -232,4 +184,2 @@\n-  \/\/ Conversion between '.' and '\/' formats\n-  static Handle externalize_classname(Handle java_string, TRAPS) {\n-    return char_converter(java_string, JVM_SIGNATURE_SLASH, JVM_SIGNATURE_DOT, THREAD);\n-  }\n+  \/\/ Conversion between '.' and '\/' formats, and allocate a String from the result.\n+  static Handle externalize_classname(Symbol* java_name, TRAPS);\n@@ -241,3 +191,2 @@\n-  \/\/ Testers\n-  static bool is_instance(oop obj);\n-  static inline bool is_instance_inlined(oop obj);\n+  \/\/ Tester\n+  static inline bool is_instance(oop obj);\n@@ -278,1 +227,0 @@\n-  static int _init_lock_offset;\n@@ -293,1 +241,0 @@\n-  static void set_init_lock(oop java_class, oop init_lock);\n@@ -305,0 +252,2 @@\n+  static void allocate_mirror(Klass* k, bool is_scratch, Handle protection_domain, Handle classData,\n+                              Handle& mirror, Handle& comp_mirror, TRAPS); \/\/ returns mirror and comp_mirror\n@@ -309,2 +258,0 @@\n-  static void update_archived_primitive_mirror_native_pointers(oop archived_mirror) NOT_CDS_JAVA_HEAP_RETURN;\n-  static void update_archived_mirror_native_pointers(oop archived_mirror) NOT_CDS_JAVA_HEAP_RETURN;\n@@ -314,4 +261,1 @@\n-  static void archive_basic_type_mirrors() NOT_CDS_JAVA_HEAP_RETURN;\n-  static oop  archive_mirror(Klass* k) NOT_CDS_JAVA_HEAP_RETURN_(NULL);\n-  static oop  process_archived_mirror(Klass* k, oop mirror, oop archived_mirror)\n-                                      NOT_CDS_JAVA_HEAP_RETURN_(NULL);\n+  static void create_scratch_mirror(Klass* k, TRAPS) NOT_CDS_JAVA_HEAP_RETURN;\n@@ -326,2 +270,1 @@\n-  static Klass* as_Klass_raw(oop java_class);\n-  static BasicType as_BasicType(oop java_class, Klass** reference_klass = NULL);\n+  static BasicType as_BasicType(oop java_class, Klass** reference_klass = nullptr);\n@@ -350,1 +293,1 @@\n-  static oop  init_lock(oop java_class);\n+  \/\/ FIXME: Is this still needed?\n@@ -352,2 +295,0 @@\n-  static oop* init_lock_addr(oop java_class);\n-  static const int* init_lock_offset_addr() { return &_init_lock_offset; }\n@@ -355,3 +296,0 @@\n-  static void clear_init_lock(oop java_class) {\n-    set_init_lock(java_class, NULL);\n-  }\n@@ -375,3 +313,2 @@\n-  static int oop_size(oop java_class);\n-  static int oop_size_raw(oop java_class);\n-  static void set_oop_size(HeapWord* java_class, int size);\n+  static size_t oop_size(oop java_class);\n+  static void set_oop_size(HeapWord* java_class, size_t size);\n@@ -379,1 +316,0 @@\n-  static int static_oop_field_count_raw(oop java_class);\n@@ -402,0 +338,6 @@\n+#define THREAD_INJECTED_FIELDS(macro)                                  \\\n+  macro(java_lang_Thread, jvmti_thread_state, intptr_signature, false) \\\n+  macro(java_lang_Thread, jvmti_VTMS_transition_disable_count, int_signature, false) \\\n+  macro(java_lang_Thread, jvmti_is_in_VTMS_transition, bool_signature, false) \\\n+  JFR_ONLY(macro(java_lang_Thread, jfr_epoch, short_signature, false))\n+\n@@ -403,0 +345,2 @@\n+  friend class java_lang_VirtualThread;\n+  friend class JVMCIVMStructs;\n@@ -406,0 +350,1 @@\n+  static int _holder_offset;\n@@ -407,1 +352,0 @@\n-  static int _group_offset;\n@@ -410,1 +354,3 @@\n-  static int _priority_offset;\n+  static int _jvmti_thread_state_offset;\n+  static int _jvmti_VTMS_transition_disable_count_offset;\n+  static int _jvmti_is_in_VTMS_transition_offset;\n@@ -413,4 +359,1 @@\n-  static int _daemon_offset;\n-  static int _stillborn_offset;\n-  static int _stackSize_offset;\n-  static int _thread_status_offset;\n+  static int _continuation_offset;\n@@ -419,0 +362,2 @@\n+  static int _scopedValueBindings_offset;\n+  JFR_ONLY(static int _jfr_epoch_offset;)\n@@ -427,0 +372,1 @@\n+  static JavaThread* thread_acquire(oop java_thread);\n@@ -429,0 +375,3 @@\n+  static void release_set_thread(oop java_thread, JavaThread* thread);\n+  \/\/ FieldHolder\n+  static oop holder(oop java_thread);\n@@ -440,3 +389,0 @@\n-  \/\/ Stillborn\n-  static bool is_stillborn(oop java_thread);\n-  static void set_stillborn(oop java_thread);\n@@ -456,1 +402,16 @@\n-  static jlong thread_id(oop java_thread);\n+  static int64_t thread_id(oop java_thread);\n+  static ByteSize thread_id_offset();\n+  \/\/ Continuation\n+  static inline oop continuation(oop java_thread);\n+\n+  static JvmtiThreadState* jvmti_thread_state(oop java_thread);\n+  static void set_jvmti_thread_state(oop java_thread, JvmtiThreadState* state);\n+  static int  VTMS_transition_disable_count(oop java_thread);\n+  static void inc_VTMS_transition_disable_count(oop java_thread);\n+  static void dec_VTMS_transition_disable_count(oop java_thread);\n+  static bool is_in_VTMS_transition(oop java_thread);\n+  static void set_is_in_VTMS_transition(oop java_thread, bool val);\n+  static int  is_in_VTMS_transition_offset();\n+\n+  \/\/ Clear all scoped value bindings on error\n+  static void clear_scopedValueBindings(oop java_thread);\n@@ -468,0 +429,7 @@\n+  \/\/ Fill in current stack trace, can cause GC\n+  static oop async_get_stack_trace(oop java_thread, TRAPS);\n+\n+  JFR_ONLY(static u2 jfr_epoch(oop java_thread);)\n+  JFR_ONLY(static void set_jfr_epoch(oop java_thread, u2 epoch);)\n+  JFR_ONLY(static int jfr_epoch_offset() { CHECK_INIT(_jfr_epoch_offset); })\n+\n@@ -472,0 +440,47 @@\n+\/\/ Interface to java.lang.Thread$FieldHolder objects\n+\n+class java_lang_Thread_FieldHolder : AllStatic {\n+ private:\n+  static int _group_offset;\n+  static int _priority_offset;\n+  static int _stackSize_offset;\n+  static int _daemon_offset;\n+  static int _thread_status_offset;\n+\n+  static void compute_offsets();\n+\n+ public:\n+  static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;\n+\n+  static oop threadGroup(oop holder);\n+\n+  static ThreadPriority priority(oop holder);\n+  static void set_priority(oop holder, ThreadPriority priority);\n+\n+  static jlong stackSize(oop holder);\n+\n+  static bool is_daemon(oop holder);\n+  static void set_daemon(oop holder, bool val);\n+\n+  static void set_thread_status(oop holder, JavaThreadStatus status);\n+  static JavaThreadStatus get_thread_status(oop holder);\n+\n+  friend class JavaClasses;\n+};\n+\n+\/\/ Interface to java.lang.Thread$Constants objects\n+\n+class java_lang_Thread_Constants : AllStatic {\n+ private:\n+  static int _static_VTHREAD_GROUP_offset;\n+  static int _static_NOT_SUPPORTED_CLASSLOADER_offset;\n+\n+  static void compute_offsets();\n+  static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;\n+\n+ public:\n+  static oop get_VTHREAD_GROUP();\n+\n+  friend class JavaClasses;\n+};\n+\n@@ -478,5 +493,0 @@\n-  static int _threads_offset;\n-  static int _groups_offset;\n-  static int _destroyed_offset;\n-  static int _nthreads_offset;\n-  static int _ngroups_offset;\n@@ -487,1 +497,0 @@\n-\n@@ -492,1 +501,1 @@\n-  static oop  parent(oop java_thread_group);\n+  static oop parent(oop java_thread_group);\n@@ -495,9 +504,0 @@\n-  \/\/ (\"name as oop\" accessor is not necessary)\n-  \/\/ Number of threads in group\n-  static int nthreads(oop java_thread_group);\n-  \/\/ threads\n-  static objArrayOop threads(oop java_thread_group);\n-  \/\/ Number of threads in group\n-  static int ngroups(oop java_thread_group);\n-  \/\/ groups\n-  static objArrayOop groups(oop java_thread_group);\n@@ -506,2 +506,0 @@\n-  \/\/ Destroyed\n-  static bool is_destroyed(oop java_thread_group);\n@@ -510,0 +508,1 @@\n+\n@@ -515,0 +514,43 @@\n+\/\/ Interface to java.lang.VirtualThread objects\n+\n+class java_lang_VirtualThread : AllStatic {\n+ private:\n+  static int static_vthread_scope_offset;\n+  static int _carrierThread_offset;\n+  static int _continuation_offset;\n+  static int _state_offset;\n+  JFR_ONLY(static int _jfr_epoch_offset;)\n+ public:\n+  enum {\n+    NEW          = 0,\n+    STARTED      = 1,\n+    RUNNABLE     = 2,\n+    RUNNING      = 3,\n+    PARKING      = 4,\n+    PARKED       = 5,\n+    PINNED       = 6,\n+    YIELDING     = 7,\n+    TERMINATED   = 99,\n+\n+    \/\/ can be suspended from scheduling when unmounted\n+    SUSPENDED    = 1 << 8,\n+    RUNNABLE_SUSPENDED = (RUNNABLE | SUSPENDED),\n+    PARKED_SUSPENDED   = (PARKED | SUSPENDED)\n+  };\n+\n+  static void compute_offsets();\n+  static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;\n+\n+  \/\/ Testers\n+  static bool is_subclass(Klass* klass) {\n+    return klass->is_subclass_of(vmClasses::VirtualThread_klass());\n+  }\n+  static bool is_instance(oop obj);\n+\n+  static oop vthread_scope();\n+  static oop carrier_thread(oop vthread);\n+  static oop continuation(oop vthread);\n+  static int state(oop vthread);\n+  static JavaThreadStatus map_state_to_thread_status(int state);\n+};\n+\n@@ -529,3 +571,4 @@\n-    trace_next_offset    = 4,\n-    trace_hidden_offset  = 5,\n-    trace_size           = 6,\n+    trace_conts_offset   = 4,\n+    trace_next_offset    = 5,\n+    trace_hidden_offset  = 6,\n+    trace_size           = 7,\n@@ -572,0 +615,1 @@\n+\n@@ -573,1 +617,5 @@\n-  static void get_stack_trace_elements(Handle throwable, objArrayHandle stack_trace, TRAPS);\n+  static void get_stack_trace_elements(int depth, Handle backtrace, objArrayHandle stack_trace, TRAPS);\n+\n+  \/\/ For recreating class initialization error exceptions.\n+  static Handle create_initialization_error(JavaThread* current, Handle throwable);\n+\n@@ -877,1 +925,1 @@\n-  \/\/ Allocation. Returns a boxed value, or NULL for invalid type.\n+  \/\/ Allocation. Returns a boxed value, or null for invalid type.\n@@ -913,0 +961,1 @@\n+  static inline oop weak_referent(oop ref);\n@@ -916,0 +965,1 @@\n+  static inline void clear_referent_raw(oop ref);\n@@ -928,0 +978,2 @@\n+  static inline bool is_weak(oop ref);\n+  static inline bool is_soft(oop ref);\n@@ -1034,1 +1086,1 @@\n-    return vmClasses::LambdaForm_klass() != NULL &&\n+    return vmClasses::LambdaForm_klass() != nullptr &&\n@@ -1046,1 +1098,1 @@\n-class jdk_internal_invoke_NativeEntryPoint: AllStatic {\n+class jdk_internal_foreign_abi_NativeEntryPoint: AllStatic {\n@@ -1050,5 +1102,1 @@\n-  static int _shadow_space_offset;\n-  static int _argMoves_offset;\n-  static int _returnMoves_offset;\n-  static int _need_transition_offset;\n-  static int _name_offset;\n+  static int _downcall_stub_address_offset;\n@@ -1063,5 +1111,1 @@\n-  static jint       shadow_space(oop entry);\n-  static oop        argMoves(oop entry);\n-  static oop        returnMoves(oop entry);\n-  static jboolean   need_transition(oop entry);\n-  static oop        name(oop entry);\n+  static jlong      downcall_stub_address(oop entry);\n@@ -1072,1 +1116,1 @@\n-    return vmClasses::NativeEntryPoint_klass() != NULL &&\n+    return vmClasses::NativeEntryPoint_klass() != nullptr &&\n@@ -1078,6 +1122,88 @@\n-  static int shadow_space_offset_in_bytes()    { return _shadow_space_offset;    }\n-  static int argMoves_offset_in_bytes()        { return _argMoves_offset;        }\n-  static int returnMoves_offset_in_bytes()     { return _returnMoves_offset;     }\n-  static int need_transition_offset_in_bytes() { return _need_transition_offset; }\n-  static int method_type_offset_in_bytes()     { return _method_type_offset;     }\n-  static int name_offset_in_bytes()            { return _name_offset;            }\n+  static int method_type_offset_in_bytes()           { return _method_type_offset; }\n+  static int downcall_stub_address_offset_in_bytes() { return _downcall_stub_address_offset; }\n+};\n+\n+class jdk_internal_foreign_abi_ABIDescriptor: AllStatic {\n+  friend class JavaClasses;\n+\n+ private:\n+  static int _inputStorage_offset;\n+  static int _outputStorage_offset;\n+  static int _volatileStorage_offset;\n+  static int _stackAlignment_offset;\n+  static int _shadowSpace_offset;\n+  static int _scratch1_offset;\n+  static int _scratch2_offset;\n+\n+  static void compute_offsets();\n+\n+ public:\n+  static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;\n+\n+  \/\/ Accessors\n+  static objArrayOop inputStorage(oop entry);\n+  static objArrayOop outputStorage(oop entry);\n+  static objArrayOop volatileStorage(oop entry);\n+  static jint        stackAlignment(oop entry);\n+  static jint        shadowSpace(oop entry);\n+  static oop         scratch1(oop entry);\n+  static oop         scratch2(oop entry);\n+\n+  \/\/ Testers\n+  static bool is_subclass(Klass* klass) {\n+    return vmClasses::ABIDescriptor_klass() != nullptr &&\n+      klass->is_subclass_of(vmClasses::ABIDescriptor_klass());\n+  }\n+  static bool is_instance(oop obj);\n+};\n+\n+class jdk_internal_foreign_abi_VMStorage: AllStatic {\n+  friend class JavaClasses;\n+\n+ private:\n+  static int _type_offset;\n+  static int _indexOrOffset_offset;\n+  static int _segmentMaskOrSize_offset;\n+  static int _debugName_offset;\n+\n+  static void compute_offsets();\n+\n+ public:\n+  static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;\n+\n+  \/\/ Accessors\n+  static jbyte  type(oop entry);\n+  static jint   index_or_offset(oop entry);\n+  static jshort segment_mask_or_size(oop entry);\n+  static oop    debugName(oop entry);\n+\n+  \/\/ Testers\n+  static bool is_subclass(Klass* klass) {\n+    return vmClasses::VMStorage_klass() != nullptr &&\n+      klass->is_subclass_of(vmClasses::VMStorage_klass());\n+  }\n+  static bool is_instance(oop obj);\n+};\n+\n+class jdk_internal_foreign_abi_CallConv: AllStatic {\n+  friend class JavaClasses;\n+\n+ private:\n+  static int _argRegs_offset;\n+  static int _retRegs_offset;\n+\n+  static void compute_offsets();\n+\n+ public:\n+  static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;\n+\n+  \/\/ Accessors\n+  static objArrayOop argRegs(oop entry);\n+  static objArrayOop retRegs(oop entry);\n+\n+  \/\/ Testers\n+  static bool is_subclass(Klass* klass) {\n+    return vmClasses::CallConv_klass() != nullptr &&\n+      klass->is_subclass_of(vmClasses::CallConv_klass());\n+  }\n+  static bool is_instance(oop obj);\n@@ -1181,3 +1307,0 @@\n-    \/\/ The SEARCH_* bits are not for MN.flags but for the matchFlags argument of MHN.getMembers:\n-    MN_SEARCH_SUPERCLASSES   = 0x00100000, \/\/ walk super classes\n-    MN_SEARCH_INTERFACES     = 0x00200000, \/\/ walk implemented interfaces\n@@ -1362,1 +1485,1 @@\n-  static ClassLoaderData* loader_data_raw(oop loader);\n+  static ClassLoaderData* loader_data(oop loader);\n@@ -1366,0 +1489,1 @@\n+  static oop parent_no_keepalive(oop loader);\n@@ -1493,0 +1617,1 @@\n+  static int _contScope_offset;\n@@ -1498,1 +1623,1 @@\n-  static void set_method_and_bci(Handle stackFrame, const methodHandle& method, int bci, TRAPS);\n+  static void set_method_and_bci(Handle stackFrame, const methodHandle& method, int bci, oop cont, TRAPS);\n@@ -1502,0 +1627,1 @@\n+  static void set_contScope(oop info, oop value);\n@@ -1591,10 +1717,0 @@\n-class java_nio_Buffer: AllStatic {\n- private:\n-  static int _limit_offset;\n-\n- public:\n-  static int  limit_offset() { CHECK_INIT(_limit_offset); }\n-  static void compute_offsets();\n-  static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;\n-};\n-\n@@ -1770,14 +1886,0 @@\n-#define DECLARE_INJECTED_FIELD_ENUM(klass, name, signature, may_be_java) \\\n-  klass##_##name##_enum,\n-\n-#define ALL_INJECTED_FIELDS(macro)          \\\n-  STRING_INJECTED_FIELDS(macro)             \\\n-  CLASS_INJECTED_FIELDS(macro)              \\\n-  CLASSLOADER_INJECTED_FIELDS(macro)        \\\n-  RESOLVEDMETHOD_INJECTED_FIELDS(macro)     \\\n-  MEMBERNAME_INJECTED_FIELDS(macro)         \\\n-  CALLSITECONTEXT_INJECTED_FIELDS(macro)    \\\n-  STACKFRAMEINFO_INJECTED_FIELDS(macro)     \\\n-  MODULE_INJECTED_FIELDS(macro)             \\\n-  INTERNALERROR_INJECTED_FIELDS(macro)\n-\n@@ -1787,0 +1889,2 @@\n+enum class InjectedFieldID : int;\n+\n@@ -1794,4 +1898,0 @@\n-  enum InjectedFieldID {\n-    ALL_INJECTED_FIELDS(DECLARE_INJECTED_FIELD_ENUM)\n-    MAX_enum\n-  };\n@@ -1806,2 +1906,7 @@\n-};\n-#undef DECLARE_INJECTED_FIELD_ENUM\n+  static void compute_offset(int &dest_offset,\n+                             InstanceKlass* ik, Symbol* name_symbol, Symbol* signature_symbol,\n+                             bool is_static = false);\n+  static void compute_offset(int& dest_offset, InstanceKlass* ik,\n+                             const char* name_string, Symbol* signature_symbol,\n+                             bool is_static = false);\n+};\n@@ -1811,0 +1916,1 @@\n+\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.hpp","additions":276,"deletions":170,"binary":false,"changes":446,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -65,0 +65,2 @@\n+  template(java_lang_Thread_FieldHolder,              \"java\/lang\/Thread$FieldHolder\")             \\\n+  template(java_lang_Thread_Constants,                \"java\/lang\/Thread$Constants\")               \\\n@@ -66,0 +68,3 @@\n+  template(java_lang_BaseVirtualThread,               \"java\/lang\/BaseVirtualThread\")              \\\n+  template(java_lang_VirtualThread,                   \"java\/lang\/VirtualThread\")                  \\\n+  template(java_lang_BoundVirtualThread,              \"java\/lang\/ThreadBuilders$BoundVirtualThread\") \\\n@@ -69,1 +74,3 @@\n-  template(java_lang_ThreadDeath,                     \"java\/lang\/ThreadDeath\")                    \\\n+  template(java_lang_Runnable,                        \"java\/lang\/Runnable\")                       \\\n+  template(jdk_internal_vm_ContinuationScope,         \"jdk\/internal\/vm\/ContinuationScope\")        \\\n+  template(jdk_internal_vm_StackChunk,                \"jdk\/internal\/vm\/StackChunk\")               \\\n@@ -94,0 +101,2 @@\n+  template(jdk_internal_vm_FillerObject,              \"jdk\/internal\/vm\/FillerObject\")             \\\n+                                                                                                  \\\n@@ -112,0 +121,2 @@\n+  template(java_lang_ScopedValue,                     \"java\/lang\/ScopedValue\")                    \\\n+  template(java_lang_ScopedValue_Carrier,             \"java\/lang\/ScopedValue$Carrier\")            \\\n@@ -119,0 +130,1 @@\n+  template(java_net_URLClassLoader,                   \"java\/net\/URLClassLoader\")                  \\\n@@ -127,0 +139,1 @@\n+  template(java_nio_Buffer,                           \"java\/nio\/Buffer\")                          \\\n@@ -143,0 +156,1 @@\n+  template(sun_invoke_util_ValueConversions,          \"sun\/invoke\/util\/ValueConversions\")         \\\n@@ -309,0 +323,4 @@\n+                                                                                                  \\\n+  template(jdk_internal_vm_annotation_ChangesCurrentThread_signature,  \"Ljdk\/internal\/vm\/annotation\/ChangesCurrentThread;\")  \\\n+  template(jdk_internal_vm_annotation_JvmtiMountTransition_signature,  \"Ljdk\/internal\/vm\/annotation\/JvmtiMountTransition;\")  \\\n+                                                                                                  \\\n@@ -337,0 +355,2 @@\n+  template(asFixedArity_name,                         \"asFixedArity\")                             \\\n+  template(asFixedArity_signature,                    \"()Ljava\/lang\/invoke\/MethodHandle;\")        \\\n@@ -341,1 +361,1 @@\n-  template(linkDynamicConstant_signature, \"(Ljava\/lang\/Object;ILjava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;)Ljava\/lang\/Object;\") \\\n+  template(linkDynamicConstant_signature, \"(Ljava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;)Ljava\/lang\/Object;\") \\\n@@ -343,1 +363,1 @@\n-  template(linkCallSite_signature, \"(Ljava\/lang\/Object;ILjava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;[Ljava\/lang\/Object;)Ljava\/lang\/invoke\/MemberName;\") \\\n+  template(linkCallSite_signature, \"(Ljava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;[Ljava\/lang\/Object;)Ljava\/lang\/invoke\/MemberName;\") \\\n@@ -350,4 +370,8 @@\n-  \/* Foreign API Support *\/                                                                                          \\\n-  template(jdk_internal_invoke_NativeEntryPoint,                 \"jdk\/internal\/invoke\/NativeEntryPoint\")           \\\n-  template(jdk_internal_invoke_NativeEntryPoint_signature,       \"Ljdk\/internal\/invoke\/NativeEntryPoint;\")         \\\n-  template(jdk_incubator_foreign_MemoryAccess,       \"jdk\/incubator\/foreign\/MemoryAccess\")        \\\n+  \/* Foreign API Support *\/                                                                       \\\n+  template(jdk_internal_foreign_abi_NativeEntryPoint,                \"jdk\/internal\/foreign\/abi\/NativeEntryPoint\") \\\n+  template(jdk_internal_foreign_abi_ABIDescriptor,                   \"jdk\/internal\/foreign\/abi\/ABIDescriptor\") \\\n+  template(jdk_internal_foreign_abi_VMStorage,                       \"jdk\/internal\/foreign\/abi\/VMStorage\") \\\n+  template(jdk_internal_foreign_abi_VMStorage_signature,             \"Ljdk\/internal\/foreign\/abi\/VMStorage;\") \\\n+  template(jdk_internal_foreign_abi_VMStorage_array_signature,       \"[Ljdk\/internal\/foreign\/abi\/VMStorage;\") \\\n+  template(jdk_internal_foreign_abi_VMStorage_array_array_signature, \"[[Ljdk\/internal\/foreign\/abi\/VMStorage;\") \\\n+  template(jdk_internal_foreign_abi_CallConv,                        \"jdk\/internal\/foreign\/abi\/UpcallLinker$CallRegs\") \\\n@@ -372,0 +396,1 @@\n+  template(getStackTrace_name,                        \"getStackTrace\")                            \\\n@@ -375,1 +400,0 @@\n-  template(stillborn_name,                            \"stillborn\")                                \\\n@@ -379,0 +403,2 @@\n+  template(runWith_method_name,                       \"runWith\")                                  \\\n+  template(interrupt_method_name,                     \"interrupt\")                                \\\n@@ -380,1 +406,0 @@\n-  template(add_method_name,                           \"add\")                                      \\\n@@ -383,5 +408,0 @@\n-  template(threads_name,                              \"threads\")                                  \\\n-  template(groups_name,                               \"groups\")                                   \\\n-  template(destroyed_name,                            \"destroyed\")                                \\\n-  template(nthreads_name,                             \"nthreads\")                                 \\\n-  template(ngroups_name,                              \"ngroups\")                                  \\\n@@ -396,0 +416,32 @@\n+  template(notifyJvmtiStart_name,                     \"notifyJvmtiStart\")                         \\\n+  template(notifyJvmtiEnd_name,                       \"notifyJvmtiEnd\")                           \\\n+  template(notifyJvmtiMount_name,                     \"notifyJvmtiMount\")                         \\\n+  template(notifyJvmtiUnmount_name,                   \"notifyJvmtiUnmount\")                       \\\n+  template(notifyJvmtiHideFrames_name,                \"notifyJvmtiHideFrames\")                    \\\n+  template(doYield_name,                              \"doYield\")                                  \\\n+  template(enter_name,                                \"enter\")                                    \\\n+  template(enterSpecial_name,                         \"enterSpecial\")                             \\\n+  template(onContinue_name,                           \"onContinue0\")                              \\\n+  template(getStacks_name,                            \"getStacks\")                                \\\n+  template(onPinned_name,                             \"onPinned0\")                                \\\n+  template(scope_name,                                \"scope\")                                    \\\n+  template(yieldInfo_name,                            \"yieldInfo\")                                \\\n+  template(tail_name,                                 \"tail\")                                     \\\n+  template(size_name,                                 \"size\")                                     \\\n+  template(argsize_name,                              \"argsize\")                                  \\\n+  template(mode_name,                                 \"mode\")                                     \\\n+  template(numFrames_name,                            \"numFrames\")                                \\\n+  template(numOops_name,                              \"numOops\")                                  \\\n+  template(stack_name,                                \"stack\")                                    \\\n+  template(maxSize_name,                              \"maxSize\")                                  \\\n+  template(reset_name,                                \"reset\")                                    \\\n+  template(done_name,                                 \"done\")                                     \\\n+  template(mounted_name,                              \"mounted\")                                  \\\n+  template(numInterpretedFrames_name,                 \"numInterpretedFrames\")                     \\\n+  template(jfrTraceId_name,                           \"jfrTraceId\")                               \\\n+  template(fp_name,                                   \"fp\")                                       \\\n+  template(sp_name,                                   \"sp\")                                       \\\n+  template(pc_name,                                   \"pc\")                                       \\\n+  template(cs_name,                                   \"cs\")                                       \\\n+  template(refStack_name,                             \"refStack\")                                 \\\n+  template(refSP_name,                                \"refSP\")                                    \\\n@@ -404,0 +456,1 @@\n+  template(bootLoader_name,                           \"bootLoader\")                               \\\n@@ -414,1 +467,1 @@\n-  template(wait_name,                                 \"wait\")                                     \\\n+  template(wait_name,                                 \"wait0\")                                    \\\n@@ -456,0 +509,1 @@\n+  template(cont_name,                                 \"cont\")                                     \\\n@@ -466,2 +520,0 @@\n-  template(fileToEncodedURL_name,                     \"fileToEncodedURL\")                         \\\n-  template(fileToEncodedURL_signature,                \"(Ljava\/io\/File;)Ljava\/net\/URL;\")           \\\n@@ -477,0 +529,3 @@\n+  template(jvmti_thread_state_name,                   \"jvmti_thread_state\")                       \\\n+  template(jvmti_VTMS_transition_disable_count_name,  \"jvmti_VTMS_transition_disable_count\")      \\\n+  template(jvmti_is_in_VTMS_transition_name,          \"jvmti_is_in_VTMS_transition\")              \\\n@@ -486,0 +541,3 @@\n+  template(checkIndex_name,                           \"checkIndex\")                               \\\n+  template(jfr_epoch_name,                            \"jfr_epoch\")                                \\\n+  template(maxThawingSize_name,                       \"maxThawingSize\")                           \\\n@@ -501,0 +559,1 @@\n+  template(bool_bool_void_signature,                  \"(ZZ)V\")                                    \\\n@@ -506,0 +565,2 @@\n+  template(float_bool_signature,                      \"(F)Z\")                                     \\\n+  template(double_bool_signature,                     \"(D)Z\")                                     \\\n@@ -529,0 +590,5 @@\n+  template(runnable_signature,                        \"Ljava\/lang\/Runnable;\")                     \\\n+  template(continuation_signature,                    \"Ljdk\/internal\/vm\/Continuation;\")           \\\n+  template(continuationscope_signature,               \"Ljdk\/internal\/vm\/ContinuationScope;\")      \\\n+  template(stackchunk_signature,                      \"Ljdk\/internal\/vm\/StackChunk;\")             \\\n+  template(vthread_signature,                         \"Ljava\/lang\/VirtualThread;\")                \\\n@@ -536,0 +602,2 @@\n+  template(string_byte_array_signature,               \"(Ljava\/lang\/String;)[B\")                   \\\n+  template(string_bool_byte_array_signature,          \"(Ljava\/lang\/String;Z)[B\")                  \\\n@@ -549,0 +617,1 @@\n+  template(runnable_void_signature,                   \"(Ljava\/lang\/Runnable;)V\")                                   \\\n@@ -551,0 +620,1 @@\n+  template(void_threadgroup_array_signature,          \"()[Ljava\/lang\/ThreadGroup;\")                               \\\n@@ -552,0 +622,1 @@\n+  template(string_boolean_class_signature,            \"(Ljava\/lang\/String;Z)Ljava\/lang\/Class;\")                   \\\n@@ -560,0 +631,1 @@\n+  template(void_byte_array_signature,                 \"()[B\")                                                     \\\n@@ -561,0 +633,1 @@\n+  template(void_BuiltinClassLoader_signature,         \"()Ljdk\/internal\/loader\/BuiltinClassLoader;\")               \\\n@@ -573,0 +646,1 @@\n+  template(thread_fieldholder_signature,              \"Ljava\/lang\/Thread$FieldHolder;\")                           \\\n@@ -585,0 +659,1 @@\n+  template(weakreference_array_signature,             \"[Ljava\/lang\/ref\/WeakReference;\")                           \\\n@@ -597,1 +672,3 @@\n-  template(reflect_method_signature,                  \"Ljava\/lang\/reflect\/Method;\")                                                    \\\n+  template(reflect_method_signature,                  \"Ljava\/lang\/reflect\/Method;\")                               \\\n+  template(getStackTrace_signature,                    \"()[Ljava\/lang\/StackTraceElement;\")                        \\\n+                                                                                                                  \\\n@@ -680,1 +757,7 @@\n-  template(serializePropertiesToByteArray_signature,   \"()[B\")                                                    \\\n+  template(serializeSavedPropertiesToByteArray_name,   \"serializeSavedPropertiesToByteArray\")                     \\\n+  template(encodeThrowable_name,                       \"encodeThrowable\")                                         \\\n+  template(encodeThrowable_signature,                  \"(Ljava\/lang\/Throwable;JI)I\")                              \\\n+  template(decodeAndThrowThrowable_name,               \"decodeAndThrowThrowable\")                                 \\\n+  template(encodeAnnotations_name,                     \"encodeAnnotations\")                                       \\\n+  template(encodeAnnotations_signature,                \"([BLjava\/lang\/Class;Ljdk\/internal\/reflect\/ConstantPool;Z[Ljava\/lang\/Class;)[B\")\\\n+  template(decodeAndThrowThrowable_signature,          \"(IJZ)V\")                                                  \\\n@@ -694,1 +777,1 @@\n-  template(dumpSharedArchive_signature,                     \"(ZLjava\/lang\/String;)V\")                             \\\n+  template(dumpSharedArchive_signature,                     \"(ZLjava\/lang\/String;)Ljava\/lang\/String;\")            \\\n@@ -697,0 +780,1 @@\n+  template(java_lang_Enum,                                  \"java\/lang\/Enum\")                                     \\\n@@ -708,0 +792,1 @@\n+  template(url_array_classloader_void_signature,            \"([Ljava\/net\/URL;Ljava\/lang\/ClassLoader;)V\")          \\\n@@ -709,0 +794,5 @@\n+  \/* Thread.dump_to_file jcmd *\/                                                                                  \\\n+  template(jdk_internal_vm_ThreadDumper,           \"jdk\/internal\/vm\/ThreadDumper\")                                \\\n+  template(dumpThreads_name,                       \"dumpThreads\")                                                 \\\n+  template(dumpThreadsToJson_name,                 \"dumpThreadsToJson\")                                           \\\n+\n@@ -795,1 +885,1 @@\n-    assert(_type_signatures[t] != NULL, \"domain check\");\n+    assert(_type_signatures[t] != nullptr, \"domain check\");\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":112,"deletions":22,"binary":false,"changes":134,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -34,0 +34,1 @@\n+#include \"oops\/stackChunkOop.hpp\"\n@@ -47,1 +48,1 @@\n-class AbstractGangTask;\n+class WorkerTask;\n@@ -62,1 +63,1 @@\n-class WorkGang;\n+class WorkerThreads;\n@@ -65,1 +66,1 @@\n-class ParallelObjectIterator : public CHeapObj<mtGC> {\n+class ParallelObjectIteratorImpl : public CHeapObj<mtGC> {\n@@ -67,0 +68,1 @@\n+  virtual ~ParallelObjectIteratorImpl() {}\n@@ -68,1 +70,13 @@\n-  virtual ~ParallelObjectIterator() {}\n+};\n+\n+\/\/ User facing parallel object iterator. This is a StackObj, which ensures that\n+\/\/ the _impl is allocated and deleted in the scope of this object. This ensures\n+\/\/ the life cycle of the implementation is as required by ThreadsListHandle,\n+\/\/ which is sometimes used by the root iterators.\n+class ParallelObjectIterator : public StackObj {\n+  ParallelObjectIteratorImpl* _impl;\n+\n+public:\n+  ParallelObjectIterator(uint thread_num);\n+  ~ParallelObjectIterator();\n+  void object_iterate(ObjectClosure* cl, uint worker_id);\n@@ -80,1 +94,1 @@\n-class CollectedHeap : public CHeapObj<mtInternal> {\n+class CollectedHeap : public CHeapObj<mtGC> {\n@@ -84,0 +98,1 @@\n+  friend class DisableIsGCActiveMark; \/\/ Disable current IsGCActiveMark\n@@ -85,0 +100,1 @@\n+  friend class ParallelObjectIterator;\n@@ -93,0 +109,4 @@\n+  \/\/ First, set it to java_lang_Object.\n+  \/\/ Then, set it to FillerObject after the FillerObject_klass loading is complete.\n+  static Klass* _filler_object_klass;\n+\n@@ -99,0 +119,2 @@\n+  \/\/ (Minimum) Alignment reserve for TLABs and PLABs.\n+  static size_t _lab_alignment_reserve;\n@@ -102,0 +124,2 @@\n+  static size_t _stack_chunk_max_size; \/\/ 0 for no limit\n+\n@@ -146,0 +170,1 @@\n+  static inline void zap_filler_array_with(HeapWord* start, size_t words, juint value);\n@@ -159,2 +184,0 @@\n-  virtual void check_for_non_bad_heap_word_value(HeapWord* addr, size_t size)\n-    PRODUCT_RETURN;\n@@ -180,1 +203,1 @@\n-    assert(heap != NULL, \"Uninitialized heap\");\n+    assert(heap != nullptr, \"Uninitialized heap\");\n@@ -192,0 +215,12 @@\n+  static inline size_t stack_chunk_max_size() {\n+    return _stack_chunk_max_size;\n+  }\n+\n+  static inline Klass* filler_object_klass() {\n+    return _filler_object_klass;\n+  }\n+\n+  static inline void set_filler_object_klass(Klass* k) {\n+    _filler_object_klass = k;\n+  }\n+\n@@ -249,3 +284,1 @@\n-  DEBUG_ONLY(bool is_in_or_null(const void* p) const { return p == NULL || is_in(p); })\n-\n-  virtual uint32_t hash_oop(oop obj) const;\n+  DEBUG_ONLY(bool is_in_or_null(const void* p) const { return p == nullptr || is_in(p); })\n@@ -256,3 +289,3 @@\n-  oop obj_allocate(Klass* klass, int size, TRAPS);\n-  virtual oop array_allocate(Klass* klass, int size, int length, bool do_zero, TRAPS);\n-  oop class_allocate(Klass* klass, int size, TRAPS);\n+  oop obj_allocate(Klass* klass, size_t size, TRAPS);\n+  virtual oop array_allocate(Klass* klass, size_t size, int length, bool do_zero, TRAPS);\n+  oop class_allocate(Klass* klass, size_t size, TRAPS);\n@@ -282,18 +315,2 @@\n-  virtual size_t min_dummy_object_size() const;\n-  size_t tlab_alloc_reserve() const;\n-\n-  \/\/ Some heaps may offer a contiguous region for shared non-blocking\n-  \/\/ allocation, via inlined code (by exporting the address of the top and\n-  \/\/ end fields defining the extent of the contiguous allocation region.)\n-\n-  \/\/ This function returns \"true\" iff the heap supports this kind of\n-  \/\/ allocation.  (Default is \"no\".)\n-  virtual bool supports_inline_contig_alloc() const {\n-    return false;\n-  }\n-  \/\/ These functions return the addresses of the fields that define the\n-  \/\/ boundaries of the contiguous allocation area.  (These fields should be\n-  \/\/ physically near to one another.)\n-  virtual HeapWord* volatile* top_addr() const {\n-    guarantee(false, \"inline contiguous allocation not supported\");\n-    return NULL;\n+  static constexpr size_t min_dummy_object_size() {\n+    return oopDesc::header_size();\n@@ -301,3 +318,4 @@\n-  virtual HeapWord** end_addr() const {\n-    guarantee(false, \"inline contiguous allocation not supported\");\n-    return NULL;\n+\n+  static size_t lab_alignment_reserve() {\n+    assert(_lab_alignment_reserve != SIZE_MAX, \"uninitialized\");\n+    return _lab_alignment_reserve;\n@@ -362,0 +380,9 @@\n+  \/\/ Return true, if accesses to the object would require barriers.\n+  \/\/ This is used by continuations to copy chunks of a thread stack into StackChunk object or out of a StackChunk\n+  \/\/ object back into the thread stack. These chunks may contain references to objects. It is crucial that\n+  \/\/ the GC does not attempt to traverse the object while we modify it, because its structure (oopmap) is changed\n+  \/\/ when stack chunks are stored into it.\n+  \/\/ StackChunk objects may be reused, the GC must not assume that a StackChunk object is always a freshly\n+  \/\/ allocated object.\n+  virtual bool requires_barriers(stackChunkOop obj) const = 0;\n+\n@@ -391,2 +418,3 @@\n-  virtual ParallelObjectIterator* parallel_object_iterator(uint thread_num) {\n-    return NULL;\n+ protected:\n+  virtual ParallelObjectIteratorImpl* parallel_object_iterator(uint thread_num) {\n+    return nullptr;\n@@ -395,0 +423,1 @@\n+ public:\n@@ -423,0 +452,6 @@\n+  \/\/ GCs are free to represent the bit representation for null differently in memory,\n+  \/\/ which is typically not observable when using the Access API. However, if for\n+  \/\/ some reason a context doesn't allow using the Access API, then this function\n+  \/\/ explicitly checks if the given memory location contains a null value.\n+  virtual bool contains_null(const oop* p) const;\n+\n@@ -454,2 +489,0 @@\n-  \/\/ Callback for when nmethod is about to be deleted.\n-  virtual void flush_nmethod(nmethod* nm) = 0;\n@@ -468,9 +501,10 @@\n-  \/\/ Provides a thread pool to SafepointSynchronize to use\n-  \/\/ for parallel safepoint cleanup.\n-  \/\/ GCs that use a GC worker thread pool may want to share\n-  \/\/ it for use during safepoint cleanup. This is only possible\n-  \/\/ if the GC can pause and resume concurrent work (e.g. G1\n-  \/\/ concurrent marking) for an intermittent non-GC safepoint.\n-  \/\/ If this method returns NULL, SafepointSynchronize will\n-  \/\/ perform cleanup tasks serially in the VMThread.\n-  virtual WorkGang* safepoint_workers() { return NULL; }\n+  \/\/ Workers used in non-GC safepoints for parallel safepoint cleanup. If this\n+  \/\/ method returns null, cleanup tasks are done serially in the VMThread. See\n+  \/\/ `SafepointSynchronize::do_cleanup_tasks` for details.\n+  \/\/ GCs using a GC worker thread pool inside GC safepoints may opt to share\n+  \/\/ that pool with non-GC safepoints, avoiding creating extraneous threads.\n+  \/\/ Such sharing is safe, because GC safepoints and non-GC safepoints never\n+  \/\/ overlap. For example, `G1CollectedHeap::workers()` (for GC safepoints) and\n+  \/\/ `G1CollectedHeap::safepoint_workers()` (for non-GC safepoints) return the\n+  \/\/ same thread-pool.\n+  virtual WorkerThreads* safepoint_workers() { return nullptr; }\n@@ -479,8 +513,11 @@\n-  \/\/ and Release*Critical() family of functions. If supported, the GC\n-  \/\/ must guarantee that pinned objects never move.\n-  virtual bool supports_object_pinning() const;\n-  virtual oop pin_object(JavaThread* thread, oop obj);\n-  virtual void unpin_object(JavaThread* thread, oop obj);\n-\n-  \/\/ Is the given object inside a CDS archive area?\n-  virtual bool is_archived_object(oop object) const;\n+  \/\/ and Release*Critical() family of functions. The GC must guarantee\n+  \/\/ that pinned objects never move and don't get reclaimed as garbage.\n+  \/\/ These functions are potentially safepointing.\n+  virtual void pin_object(JavaThread* thread, oop obj) = 0;\n+  virtual void unpin_object(JavaThread* thread, oop obj) = 0;\n+\n+  \/\/ Support for loading objects from CDS archive into the heap\n+  \/\/ (usually as a snapshot of the old generation).\n+  virtual bool can_load_archived_objects() const { return false; }\n+  virtual HeapWord* allocate_loaded_archive_space(size_t size) { return nullptr; }\n+  virtual void complete_loaded_archive_space(MemRegion archive_space) { }\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":94,"deletions":57,"binary":false,"changes":151,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,0 +27,1 @@\n+#include \"classfile\/vmClasses.hpp\"\n@@ -36,1 +37,1 @@\n-#include \"runtime\/sharedRuntime.hpp\"\n+#include \"runtime\/continuationJavaClasses.inline.hpp\"\n@@ -38,1 +39,2 @@\n-#include \"runtime\/thread.inline.hpp\"\n+#include \"runtime\/sharedRuntime.hpp\"\n+#include \"runtime\/javaThread.hpp\"\n@@ -57,1 +59,1 @@\n-  void notify_allocation();\n+  void notify_allocation(JavaThread* thread);\n@@ -61,2 +63,1 @@\n-  void notify_allocation_dtrace_sampler();\n-  void check_for_bad_heap_word_value() const;\n+  void notify_allocation_dtrace_sampler(JavaThread* thread);\n@@ -84,2 +85,1 @@\n-      verify_after();\n-      notify_allocation();\n+      notify_allocation(_thread);\n@@ -103,1 +103,1 @@\n-    *obj_ptr = NULL;\n+    *obj_ptr = nullptr;\n@@ -119,1 +119,1 @@\n-  if (obj() != NULL) {\n+  if (obj() != nullptr) {\n@@ -151,16 +151,0 @@\n-void MemAllocator::Allocation::verify_after() {\n-  NOT_PRODUCT(check_for_bad_heap_word_value();)\n-}\n-\n-void MemAllocator::Allocation::check_for_bad_heap_word_value() const {\n-  MemRegion obj_range = _allocator.obj_memory_range(obj());\n-  HeapWord* addr = obj_range.start();\n-  size_t size = obj_range.word_size();\n-  if (CheckMemoryInitialization && ZapUnusedHeapArea) {\n-    for (size_t slot = 0; slot < size; slot += 1) {\n-      assert((*(intptr_t*) (addr + slot)) != ((intptr_t) badHeapWordVal),\n-             \"Found badHeapWordValue in post-allocation check\");\n-    }\n-  }\n-}\n-\n@@ -175,1 +159,1 @@\n-  _thread->as_Java_thread()->check_for_valid_safepoint_state();\n+  JavaThread::cast(_thread)->check_for_valid_safepoint_state();\n@@ -236,1 +220,1 @@\n-void MemAllocator::Allocation::notify_allocation_dtrace_sampler() {\n+void MemAllocator::Allocation::notify_allocation_dtrace_sampler(JavaThread* thread) {\n@@ -241,2 +225,2 @@\n-    if (klass != NULL && klass->name() != NULL) {\n-      SharedRuntime::dtrace_object_alloc(obj(), (int)word_size);\n+    if (klass != nullptr && klass->name() != nullptr) {\n+      SharedRuntime::dtrace_object_alloc(thread, obj(), word_size);\n@@ -247,1 +231,1 @@\n-void MemAllocator::Allocation::notify_allocation() {\n+void MemAllocator::Allocation::notify_allocation(JavaThread* thread) {\n@@ -250,1 +234,1 @@\n-  notify_allocation_dtrace_sampler();\n+  notify_allocation_dtrace_sampler(thread);\n@@ -257,1 +241,1 @@\n-HeapWord* MemAllocator::allocate_outside_tlab(Allocation& allocation) const {\n+HeapWord* MemAllocator::mem_allocate_outside_tlab(Allocation& allocation) const {\n@@ -260,1 +244,1 @@\n-  if (mem == NULL) {\n+  if (mem == nullptr) {\n@@ -264,1 +248,0 @@\n-  NOT_PRODUCT(Universe::heap()->check_for_non_bad_heap_word_value(mem, _word_size));\n@@ -271,1 +254,1 @@\n-HeapWord* MemAllocator::allocate_inside_tlab(Allocation& allocation) const {\n+HeapWord* MemAllocator::mem_allocate_inside_tlab(Allocation& allocation) const {\n@@ -275,2 +258,2 @@\n-  HeapWord* mem = _thread->tlab().allocate(_word_size);\n-  if (mem != NULL) {\n+  HeapWord* mem = mem_allocate_inside_tlab_fast();\n+  if (mem != nullptr) {\n@@ -281,1 +264,5 @@\n-  return allocate_inside_tlab_slow(allocation);\n+  return mem_allocate_inside_tlab_slow(allocation);\n+}\n+\n+HeapWord* MemAllocator::mem_allocate_inside_tlab_fast() const {\n+  return _thread->tlab().allocate(_word_size);\n@@ -284,2 +271,2 @@\n-HeapWord* MemAllocator::allocate_inside_tlab_slow(Allocation& allocation) const {\n-  HeapWord* mem = NULL;\n+HeapWord* MemAllocator::mem_allocate_inside_tlab_slow(Allocation& allocation) const {\n+  HeapWord* mem = nullptr;\n@@ -296,1 +283,1 @@\n-    if (mem != NULL) {\n+    if (mem != nullptr) {\n@@ -305,1 +292,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -315,1 +302,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -322,1 +309,1 @@\n-  if (mem == NULL) {\n+  if (mem == nullptr) {\n@@ -327,1 +314,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -351,0 +338,16 @@\n+\n+HeapWord* MemAllocator::mem_allocate_slow(Allocation& allocation) const {\n+  \/\/ Allocation of an oop can always invoke a safepoint.\n+  debug_only(JavaThread::cast(_thread)->check_for_valid_safepoint_state());\n+\n+  if (UseTLAB) {\n+    \/\/ Try refilling the TLAB and allocating the object in it.\n+    HeapWord* mem = mem_allocate_inside_tlab_slow(allocation);\n+    if (mem != nullptr) {\n+      return mem;\n+    }\n+  }\n+\n+  return mem_allocate_outside_tlab(allocation);\n+}\n+\n@@ -353,3 +356,4 @@\n-    HeapWord* result = allocate_inside_tlab(allocation);\n-    if (result != NULL) {\n-      return result;\n+    \/\/ Try allocating from an existing TLAB.\n+    HeapWord* mem = mem_allocate_inside_tlab_fast();\n+    if (mem != nullptr) {\n+      return mem;\n@@ -359,1 +363,1 @@\n-  return allocate_outside_tlab(allocation);\n+  return mem_allocate_slow(allocation);\n@@ -363,1 +367,1 @@\n-  oop obj = NULL;\n+  oop obj = nullptr;\n@@ -367,1 +371,1 @@\n-    if (mem != NULL) {\n+    if (mem != nullptr) {\n@@ -371,2 +375,2 @@\n-      \/\/ so reset it to NULL if mem is NULL.\n-      obj = NULL;\n+      \/\/ so reset it to null if mem is null.\n+      obj = nullptr;\n@@ -379,1 +383,1 @@\n-  assert(mem != NULL, \"cannot initialize NULL object\");\n+  assert(mem != nullptr, \"cannot initialize null object\");\n@@ -387,7 +391,3 @@\n-  assert(mem != NULL, \"NULL object pointer\");\n-  if (UseBiasedLocking) {\n-    oopDesc::set_mark(mem, _klass->prototype_header());\n-  } else {\n-    \/\/ May be bootstrapping\n-    oopDesc::set_mark(mem, markWord::prototype());\n-  }\n+  assert(mem != nullptr, \"null object pointer\");\n+  \/\/ May be bootstrapping\n+  oopDesc::set_mark(mem, markWord::prototype());\n@@ -395,1 +395,1 @@\n-  \/\/ object zeroing are visible before setting the klass non-NULL, for\n+  \/\/ object zeroing are visible before setting the klass non-null, for\n@@ -417,1 +417,1 @@\n-  \/\/ non-NULL klass field indicates that the object is parsable by\n+  \/\/ non-null klass field indicates that the object is parsable by\n@@ -429,1 +429,1 @@\n-  \/\/ non-NULL _klass field indicates that the object is parsable by\n+  \/\/ non-null _klass field indicates that the object is parsable by\n@@ -433,1 +433,1 @@\n-  java_lang_Class::set_oop_size(mem, (int)_word_size);\n+  java_lang_Class::set_oop_size(mem, _word_size);\n","filename":"src\/hotspot\/share\/gc\/shared\/memAllocator.cpp","additions":66,"deletions":66,"binary":false,"changes":132,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -154,1 +154,4 @@\n-JVM_LoadLibrary(const char *name);\n+JVM_LoadZipLibrary();\n+\n+JNIEXPORT void * JNICALL\n+JVM_LoadLibrary(const char *name, jboolean throwException);\n@@ -168,0 +171,9 @@\n+JNIEXPORT jboolean JNICALL\n+JVM_IsPreviewEnabled(void);\n+\n+JNIEXPORT jboolean JNICALL\n+JVM_IsContinuationsSupported(void);\n+\n+JNIEXPORT jboolean JNICALL\n+JVM_IsForeignLinkerSupported(void);\n+\n@@ -219,1 +231,1 @@\n-JVM_InitStackTraceElementArray(JNIEnv *env, jobjectArray elements, jobject throwable);\n+JVM_InitStackTraceElementArray(JNIEnv *env, jobjectArray elements, jobject backtrace, jint depth);\n@@ -243,2 +255,2 @@\n-                  jint skip_frames, jint frame_count, jint start_index,\n-                  jobjectArray frames);\n+                  jint skip_frames, jobject contScope, jobject cont,\n+                  jint frame_count, jint start_index, jobjectArray frames);\n@@ -251,0 +263,3 @@\n+JNIEXPORT void JNICALL\n+JVM_SetStackWalkContinuation(JNIEnv *env, jobject stackStream, jlong anchor, jobjectArray frames, jobject cont);\n+\n@@ -257,12 +272,0 @@\n-JNIEXPORT void JNICALL\n-JVM_StopThread(JNIEnv *env, jobject thread, jobject exception);\n-\n-JNIEXPORT jboolean JNICALL\n-JVM_IsThreadAlive(JNIEnv *env, jobject thread);\n-\n-JNIEXPORT void JNICALL\n-JVM_SuspendThread(JNIEnv *env, jobject thread);\n-\n-JNIEXPORT void JNICALL\n-JVM_ResumeThread(JNIEnv *env, jobject thread);\n-\n@@ -276,1 +279,4 @@\n-JVM_Sleep(JNIEnv *env, jclass threadClass, jlong millis);\n+JVM_Sleep(JNIEnv *env, jclass threadClass, jlong nanos);\n+\n+JNIEXPORT jobject JNICALL\n+JVM_CurrentCarrierThread(JNIEnv *env, jclass threadClass);\n@@ -281,0 +287,3 @@\n+JNIEXPORT void JNICALL\n+JVM_SetCurrentThread(JNIEnv *env, jobject thisThread, jobject theThread);\n+\n@@ -287,0 +296,3 @@\n+JNIEXPORT jobject JNICALL\n+JVM_GetStackTrace(JNIEnv *env, jobject thread);\n+\n@@ -300,0 +312,18 @@\n+JNIEXPORT jobject JNICALL\n+JVM_ScopedValueCache(JNIEnv *env, jclass threadClass);\n+\n+JNIEXPORT void JNICALL\n+JVM_SetScopedValueCache(JNIEnv *env, jclass threadClass, jobject theCache);\n+\n+JNIEXPORT jobject JNICALL\n+JVM_FindScopedValueBindings(JNIEnv *env, jclass threadClass);\n+\n+JNIEXPORT jlong JNICALL\n+JVM_GetNextThreadIdOffset(JNIEnv *env, jclass threadClass);\n+\n+\/*\n+ * jdk.internal.vm.Continuation\n+ *\/\n+JNIEXPORT void JNICALL\n+JVM_RegisterContinuationMethods(JNIEnv *env, jclass cls);\n+\n@@ -455,1 +485,1 @@\n- * Module support funcions\n+ * Module support functions\n@@ -724,0 +754,2 @@\n+JNIEXPORT void JNICALL\n+JVM_EnsureMaterializedForStackWalk_func(JNIEnv* env, jobject vthread, jobject value);\n@@ -762,0 +794,9 @@\n+\/*\n+ * java.lang.ref.Finalizer\n+ *\/\n+JNIEXPORT void JNICALL\n+JVM_ReportFinalizationComplete(JNIEnv *env, jobject finalizee);\n+\n+JNIEXPORT jboolean JNICALL\n+JVM_IsFinalizationEnabled(JNIEnv *env);\n+\n@@ -1108,0 +1149,30 @@\n+\/*\n+ * Virtual thread support.\n+ *\/\n+JNIEXPORT void JNICALL\n+JVM_VirtualThreadStart(JNIEnv* env, jobject vthread);\n+\n+JNIEXPORT void JNICALL\n+JVM_VirtualThreadEnd(JNIEnv* env, jobject vthread);\n+\n+JNIEXPORT void JNICALL\n+JVM_VirtualThreadMount(JNIEnv* env, jobject vthread, jboolean hide);\n+\n+JNIEXPORT void JNICALL\n+JVM_VirtualThreadUnmount(JNIEnv* env, jobject vthread, jboolean hide);\n+\n+JNIEXPORT void JNICALL\n+JVM_VirtualThreadHideFrames(JNIEnv* env, jobject vthread, jboolean hide);\n+\n+\/*\n+ * Core reflection support.\n+ *\/\n+JNIEXPORT jint JNICALL\n+JVM_GetClassFileVersion(JNIEnv *env, jclass current);\n+\n+\/*\n+ * Return JNI_TRUE if warnings are printed when agents are dynamically loaded.\n+ *\/\n+JNIEXPORT jboolean JNICALL\n+JVM_PrintWarningAtDynamicAgentLoad(void);\n+\n","filename":"src\/hotspot\/share\/include\/jvm.h","additions":90,"deletions":19,"binary":false,"changes":109,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,1 +26,0 @@\n-#include \"jvm_io.h\"\n@@ -37,0 +36,1 @@\n+#include \"interpreter\/bytecodeTracer.hpp\"\n@@ -41,0 +41,1 @@\n+#include \"jvm_io.h\"\n@@ -58,1 +59,1 @@\n-#include \"runtime\/biasedLocking.hpp\"\n+#include \"runtime\/continuation.hpp\"\n@@ -136,1 +137,1 @@\n-    \/\/ That is why we must check both ProfileInterpreter and mdo != NULL.\n+    \/\/ That is why we must check both ProfileInterpreter and mdo != nullptr.\n@@ -138,1 +139,1 @@\n-    if (mdo != NULL) {\n+    if (mdo != nullptr) {\n@@ -186,1 +187,1 @@\n-  assert(result != NULL || is_fast_aldc, \"null result only valid for fast_aldc\");\n+  assert(result != nullptr || is_fast_aldc, \"null result only valid for fast_aldc\");\n@@ -196,2 +197,2 @@\n-      oop coop = m->constants()->resolved_references()->obj_at(rindex);\n-      oop roop = (result == NULL ? Universe::the_null_sentinel() : result);\n+      oop coop = m->constants()->resolved_reference_at(rindex);\n+      oop roop = (result == nullptr ? Universe::the_null_sentinel() : result);\n@@ -317,1 +318,1 @@\n-    if (trap_mdo == NULL) {\n+    if (trap_mdo == nullptr) {\n@@ -320,1 +321,1 @@\n-      Method::build_interpreter_method_data(trap_method, THREAD);\n+      Method::build_profiling_method_data(trap_method, THREAD);\n@@ -330,1 +331,1 @@\n-    if (trap_mdo != NULL) {\n+    if (trap_mdo != nullptr) {\n@@ -374,0 +375,3 @@\n+  \/\/ Remove the ScopedValue bindings in case we got a StackOverflowError\n+  \/\/ while we were trying to manipulate ScopedValue bindings.\n+  current->clear_scopedValueBindings();\n@@ -385,0 +389,3 @@\n+  \/\/ Remove the ScopedValue bindings in case we got a StackOverflowError\n+  \/\/ while we were trying to manipulate ScopedValue bindings.\n+  current->clear_scopedValueBindings();\n@@ -411,1 +418,5 @@\n-    note_trap(current, Deoptimization::Reason_class_check);\n+    if (s == vmSymbols::java_lang_ArrayStoreException()) {\n+      note_trap(current, Deoptimization::Reason_array_check);\n+    } else {\n+      note_trap(current, Deoptimization::Reason_class_check);\n+    }\n@@ -496,1 +507,1 @@\n-    assert(h_exception.not_null(), \"NULL exceptions should be handled by athrow\");\n+    assert(h_exception.not_null(), \"null exceptions should be handled by athrow\");\n@@ -539,1 +550,1 @@\n-  if (EnableJVMCI && h_method->method_data() != NULL) {\n+  if (EnableJVMCI && h_method->method_data() != nullptr) {\n@@ -541,2 +552,2 @@\n-    ProfileData* pdata = h_method->method_data()->allocate_bci_to_data(current_bci, NULL);\n-    if (pdata != NULL && pdata->is_BitData()) {\n+    ProfileData* pdata = h_method->method_data()->allocate_bci_to_data(current_bci, nullptr);\n+    if (pdata != nullptr && pdata->is_BitData()) {\n@@ -555,2 +566,2 @@\n-  address continuation = NULL;\n-  address handler_pc = NULL;\n+  address continuation = nullptr;\n+  address handler_pc = nullptr;\n@@ -580,1 +591,1 @@\n-    JvmtiExport::notice_unwind_due_to_exception(current, h_method(), handler_pc, h_exception(), (handler_pc != NULL));\n+    JvmtiExport::notice_unwind_due_to_exception(current, h_method(), handler_pc, h_exception(), (handler_pc != nullptr));\n@@ -607,1 +618,1 @@\n-  assert(missingMethod != NULL, \"sanity\");\n+  assert(missingMethod != nullptr, \"sanity\");\n@@ -633,2 +644,2 @@\n-               recvKlass ? recvKlass->external_name() : \"NULL\",\n-               interfaceKlass ? interfaceKlass->external_name() : \"NULL\");\n+               recvKlass ? recvKlass->external_name() : \"nullptr\",\n+               interfaceKlass ? interfaceKlass->external_name() : \"nullptr\");\n@@ -707,1 +718,1 @@\n-  is_tsan_ignore = info.access_flags().is_stable() || info.access_flags().is_tsan_ignore();\n+  is_tsan_ignore = info.field_flags().is_stable() || info.field_flags().is_tsan_ignore();\n@@ -733,0 +744,1 @@\n+  assert(LockingMode != LM_LIGHTWEIGHT, \"Should call monitorenter_obj() when using the new lightweight locking\");\n@@ -736,3 +748,0 @@\n-  if (PrintBiasedLockingStatistics) {\n-    Atomic::inc(BiasedLocking::slow_path_entry_count_addr());\n-  }\n@@ -741,1 +750,1 @@\n-         \"must be NULL or an object\");\n+         \"must be null or an object\");\n@@ -744,1 +753,1 @@\n-         \"must be NULL or an object\");\n+         \"must be null or an object\");\n@@ -750,0 +759,16 @@\n+\/\/ NOTE: We provide a separate implementation for the new lightweight locking to workaround a limitation\n+\/\/ of registers in x86_32. This entry point accepts an oop instead of a BasicObjectLock*.\n+\/\/ The problem is that we would need to preserve the register that holds the BasicObjectLock,\n+\/\/ but we are using that register to hold the thread. We don't have enough registers to\n+\/\/ also keep the BasicObjectLock, but we don't really need it anyway, we only need\n+\/\/ the object. See also InterpreterMacroAssembler::lock_object().\n+\/\/ As soon as legacy stack-locking goes away we could remove the other monitorenter() entry\n+\/\/ point, and only use oop-accepting entries (same for monitorexit() below).\n+JRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter_obj(JavaThread* current, oopDesc* obj))\n+  assert(LockingMode == LM_LIGHTWEIGHT, \"Should call monitorenter() when not using the new lightweight locking\");\n+  Handle h_obj(current, cast_to_oop(obj));\n+  assert(Universe::heap()->is_in_or_null(h_obj()),\n+         \"must be null or an object\");\n+  ObjectSynchronizer::enter(h_obj, nullptr, current);\n+  return;\n+JRT_END\n@@ -765,1 +790,1 @@\n-  elem->set_obj(NULL);\n+  elem->set_obj(nullptr);\n@@ -782,7 +807,3 @@\n-  assert(exception() != NULL, \"vm result should be set\");\n-  current->set_vm_result(NULL); \/\/ clear vm result before continuing (may cause memory leaks and assert failures)\n-  if (!exception->is_a(vmClasses::ThreadDeath_klass())) {\n-    exception = get_preinitialized_exception(\n-                       vmClasses::IllegalMonitorStateException_klass(),\n-                       CATCH);\n-  }\n+  assert(exception() != nullptr, \"vm result should be set\");\n+  current->set_vm_result(nullptr); \/\/ clear vm result before continuing (may cause memory leaks and assert failures)\n+  exception = get_preinitialized_exception(vmClasses::IllegalMonitorStateException_klass(), CATCH);\n@@ -811,1 +832,1 @@\n-  Handle receiver(current, NULL);\n+  Handle receiver(current, nullptr);\n@@ -838,1 +859,12 @@\n-                                 CHECK);\n+                                 THREAD);\n+\n+    if (HAS_PENDING_EXCEPTION) {\n+      if (ProfileTraps && PENDING_EXCEPTION->klass()->name() == vmSymbols::java_lang_NullPointerException()) {\n+        \/\/ Preserve the original exception across the call to note_trap()\n+        PreserveExceptionMark pm(current);\n+        \/\/ Recording the trap will help the compiler to potentially recognize this exception as \"hot\"\n+        note_trap(current, Deoptimization::Reason_null_check);\n+      }\n+      return;\n+    }\n+\n@@ -941,2 +973,1 @@\n-  ConstantPoolCacheEntry* cp_cache_entry = pool->invokedynamic_cp_cache_entry_at(index);\n-  cp_cache_entry->set_dynamic_call(pool, info);\n+  pool->cache()->set_dynamic_call(info, pool->decode_invokedynamic_index(index));\n@@ -985,2 +1016,2 @@\n-  assert(branch_bcp != NULL || nm == NULL, \"always returns null for non OSR requests\");\n-  if (branch_bcp != NULL && nm != NULL) {\n+  assert(branch_bcp != nullptr || nm == nullptr, \"always returns null for non OSR requests\");\n+  if (branch_bcp != nullptr && nm != nullptr) {\n@@ -997,1 +1028,1 @@\n-    if (nm != NULL && bs_nm != NULL) {\n+    if (nm != nullptr && bs_nm != nullptr) {\n@@ -1000,1 +1031,1 @@\n-        nm = NULL;\n+        nm = nullptr;\n@@ -1004,1 +1035,1 @@\n-  if (nm != NULL && current->is_interp_only_mode()) {\n+  if (nm != nullptr && current->is_interp_only_mode()) {\n@@ -1010,1 +1041,1 @@\n-    nm = NULL;\n+    nm = nullptr;\n@@ -1014,1 +1045,1 @@\n-    if (nm != NULL) {\n+    if (nm != nullptr) {\n@@ -1032,2 +1063,2 @@\n-  const int branch_bci = branch_bcp != NULL ? method->bci_from(branch_bcp) : InvocationEntryBci;\n-  const int bci = branch_bcp != NULL ? method->bci_from(last_frame.bcp()) : InvocationEntryBci;\n+  const int branch_bci = branch_bcp != nullptr ? method->bci_from(branch_bcp) : InvocationEntryBci;\n+  const int bci = branch_bcp != nullptr ? method->bci_from(last_frame.bcp()) : InvocationEntryBci;\n@@ -1035,1 +1066,1 @@\n-  nmethod* osr_nm = CompilationPolicy::event(method, method, branch_bci, bci, CompLevel_none, NULL, CHECK_NULL);\n+  nmethod* osr_nm = CompilationPolicy::event(method, method, branch_bci, bci, CompLevel_none, nullptr, CHECK_NULL);\n@@ -1038,1 +1069,1 @@\n-  if (osr_nm != NULL && bs_nm != NULL) {\n+  if (osr_nm != nullptr && bs_nm != nullptr) {\n@@ -1040,22 +1071,1 @@\n-      osr_nm = NULL;\n-    }\n-  }\n-\n-  if (osr_nm != NULL) {\n-    \/\/ We may need to do on-stack replacement which requires that no\n-    \/\/ monitors in the activation are biased because their\n-    \/\/ BasicObjectLocks will need to migrate during OSR. Force\n-    \/\/ unbiasing of all monitors in the activation now (even though\n-    \/\/ the OSR nmethod might be invalidated) because we don't have a\n-    \/\/ safepoint opportunity later once the migration begins.\n-    if (UseBiasedLocking) {\n-      ResourceMark rm;\n-      GrowableArray<Handle>* objects_to_revoke = new GrowableArray<Handle>();\n-      for( BasicObjectLock *kptr = last_frame.monitor_end();\n-           kptr < last_frame.monitor_begin();\n-           kptr = last_frame.next_monitor(kptr) ) {\n-        if( kptr->obj() != NULL ) {\n-          objects_to_revoke->append(Handle(current, kptr->obj()));\n-        }\n-      }\n-      BiasedLocking::revoke(objects_to_revoke, current);\n+      osr_nm = nullptr;\n@@ -1071,1 +1081,1 @@\n-  if (mdo == NULL)  return 0;\n+  if (mdo == nullptr)  return 0;\n@@ -1080,1 +1090,1 @@\n-  assert(mdo != NULL, \"must not be null\");\n+  assert(mdo != nullptr, \"must not be null\");\n@@ -1118,1 +1128,1 @@\n-  guarantee(data != NULL, \"profile data must be valid\");\n+  guarantee(data != nullptr, \"profile data must be valid\");\n@@ -1130,1 +1140,1 @@\n-  \/\/ We used to need an explict preserve_arguments here for invoke bytecodes. However,\n+  \/\/ We used to need an explicit preserve_arguments here for invoke bytecodes. However,\n@@ -1152,0 +1162,1 @@\n+  assert(current == JavaThread::current(), \"pre-condition\");\n@@ -1169,1 +1180,1 @@\n-  if ((ik->field_access_flags(index) & JVM_ACC_FIELD_ACCESS_WATCHED) == 0) return;\n+  if (!ik->field_status(index).is_access_watched()) return;\n@@ -1171,1 +1182,1 @@\n-  bool is_static = (obj == NULL);\n+  bool is_static = (obj == nullptr);\n@@ -1194,1 +1205,1 @@\n-  if ((ik->field_access_flags(index) & JVM_ACC_FIELD_MODIFICATION_WATCHED) == 0) return;\n+  if (!ik->field_status(index).is_modification_watched()) return;\n@@ -1210,1 +1221,1 @@\n-  bool is_static = (obj == NULL);\n+  bool is_static = (obj == nullptr);\n@@ -1258,1 +1269,1 @@\n-  return (Interpreter::contains(pc) ? 1 : 0);\n+  return (Interpreter::contains(Continuation::get_top_return_pc_post_barrier(JavaThread::current(), pc)) ? 1 : 0);\n@@ -1267,1 +1278,1 @@\n-\/\/ dependant code)\n+\/\/ dependent code)\n@@ -1275,2 +1286,2 @@\n-  if (handler_blob == NULL) {\n-    return NULL;\n+  if (handler_blob == nullptr) {\n+    return nullptr;\n@@ -1285,1 +1296,1 @@\n-  if (_fingerprints != NULL) {\n+  if (_fingerprints != nullptr) {\n@@ -1288,1 +1299,1 @@\n-  if (set_handler_blob() == NULL) {\n+  if (set_handler_blob() == nullptr) {\n@@ -1296,2 +1307,2 @@\n-  _fingerprints = new(ResourceObj::C_HEAP, mtCode)GrowableArray<uint64_t>(32, mtCode);\n-  _handlers     = new(ResourceObj::C_HEAP, mtCode)GrowableArray<address>(32, mtCode);\n+  _fingerprints = new (mtCode) GrowableArray<uint64_t>(32, mtCode);\n+  _handlers     = new (mtCode) GrowableArray<address>(32, mtCode);\n@@ -1307,1 +1318,1 @@\n-  if (handler != NULL) {\n+  if (handler != nullptr) {\n@@ -1317,1 +1328,1 @@\n-  if (method->signature_handler() == NULL) {\n+  if (method->signature_handler() == nullptr) {\n@@ -1328,1 +1339,1 @@\n-      \/\/ allow CPU dependant code to optimize the fingerprints for the fast handler\n+      \/\/ allow CPU dependent code to optimize the fingerprints for the fast handler\n@@ -1340,1 +1351,1 @@\n-        if (handler == NULL) {\n+        if (handler == nullptr) {\n@@ -1343,1 +1354,1 @@\n-          \/\/ debugging suppport\n+          \/\/ debugging support\n@@ -1354,1 +1365,2 @@\n-              Disassembler::decode(handler, handler + buffer.insts_size());\n+              Disassembler::decode(handler, handler + buffer.insts_size(), tty\n+                                   NOT_PRODUCT(COMMA &buffer.asm_remarks()));\n@@ -1402,1 +1414,1 @@\n-    if (_handlers != NULL) {\n+    if (_handlers != nullptr) {\n@@ -1446,5 +1458,5 @@\n-BufferBlob*              SignatureHandlerLibrary::_handler_blob = NULL;\n-address                  SignatureHandlerLibrary::_handler      = NULL;\n-GrowableArray<uint64_t>* SignatureHandlerLibrary::_fingerprints = NULL;\n-GrowableArray<address>*  SignatureHandlerLibrary::_handlers     = NULL;\n-address                  SignatureHandlerLibrary::_buffer       = NULL;\n+BufferBlob*              SignatureHandlerLibrary::_handler_blob = nullptr;\n+address                  SignatureHandlerLibrary::_handler      = nullptr;\n+GrowableArray<uint64_t>* SignatureHandlerLibrary::_fingerprints = nullptr;\n+GrowableArray<address>*  SignatureHandlerLibrary::_handlers     = nullptr;\n+address                  SignatureHandlerLibrary::_buffer       = nullptr;\n@@ -1470,0 +1482,1 @@\n+  assert(current == JavaThread::current(), \"pre-condition\");\n@@ -1501,2 +1514,2 @@\n-  Symbol* cname = cpool->klass_name_at(cpool->klass_ref_index_at(cp_index));\n-  Symbol* mname = cpool->name_ref_at(cp_index);\n+  Symbol* cname = cpool->klass_name_at(cpool->klass_ref_index_at(cp_index, code));\n+  Symbol* mname = cpool->name_ref_at(cp_index, code);\n@@ -1512,1 +1525,1 @@\n-    current->set_vm_result(NULL);\n+    current->set_vm_result(nullptr);\n@@ -1523,0 +1536,1 @@\n+  assert(current == JavaThread::current(), \"pre-condition\");\n@@ -1526,1 +1540,1 @@\n-  BytecodeTracer::trace(mh, last_frame.bcp(), tos, tos2);\n+  BytecodeTracer::trace_interpreter(mh, last_frame.bcp(), tos, tos2);\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":119,"deletions":105,"binary":false,"changes":224,"status":"modified"},{"patch":"@@ -229,2 +229,2 @@\n-void TemplateTable::def(Bytecodes::Code code, int flags, TosState in, TosState out, void (*gen)(bool arg    ), bool arg) {\n-  def(code, flags, in, out, (Template::generator)gen, (int)arg);\n+void TemplateTable::def(Bytecodes::Code code, int flags, TosState in, TosState out, void (*gen)(LdcType ldct), LdcType ldct) {\n+  def(code, flags, in, out, (Template::generator)gen, (int)ldct);\n@@ -277,2 +277,2 @@\n-  def(Bytecodes::_ldc                 , ubcp|____|clvm|____, vtos, vtos, ldc                 ,  false       );\n-  def(Bytecodes::_ldc_w               , ubcp|____|clvm|____, vtos, vtos, ldc                 ,  true        );\n+  def(Bytecodes::_ldc                 , ubcp|____|clvm|____, vtos, vtos, ldc                 ,  ldc_normal  );\n+  def(Bytecodes::_ldc_w               , ubcp|____|clvm|____, vtos, vtos, ldc                 ,  ldc_wide    );\n@@ -511,2 +511,2 @@\n-  def(Bytecodes::_fast_aldc           , ubcp|____|clvm|____, vtos, atos, fast_aldc           ,  false       );\n-  def(Bytecodes::_fast_aldc_w         , ubcp|____|clvm|____, vtos, atos, fast_aldc           ,  true        );\n+  def(Bytecodes::_fast_aldc           , ubcp|____|clvm|____, vtos, atos, fast_aldc           ,  ldc_normal  );\n+  def(Bytecodes::_fast_aldc_w         , ubcp|____|clvm|____, vtos, atos, fast_aldc           ,  ldc_wide    );\n","filename":"src\/hotspot\/share\/interpreter\/templateTable.cpp","additions":6,"deletions":6,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,1 +29,1 @@\n-#include \"memory\/allocation.hpp\"\n+#include \"memory\/allStatic.hpp\"\n@@ -67,1 +67,1 @@\n-  bool      is_valid() const                     { return _gen != NULL; }\n+  bool      is_valid() const                     { return _gen != nullptr; }\n@@ -86,0 +86,1 @@\n+  enum LdcType   { ldc_normal = 0, ldc_wide = 1 }; \/\/ LDC type\n@@ -108,0 +109,5 @@\n+  static bool is_ldc_wide(LdcType type) {\n+    assert(type == ldc_wide || type == ldc_normal, \"sanity\");\n+    return (type == ldc_wide);\n+  }\n+\n@@ -131,1 +137,1 @@\n-  static void ldc(bool wide);\n+  static void ldc(LdcType type);\n@@ -133,1 +139,1 @@\n-  static void fast_aldc(bool wide);\n+  static void fast_aldc(LdcType type);\n@@ -263,0 +269,1 @@\n+  static void load_invokedynamic_entry(Register method);\n@@ -330,1 +337,1 @@\n-  static void def(Bytecodes::Code code, int flags, TosState in, TosState out, void (*gen)(bool arg    ), bool arg    );\n+  static void def(Bytecodes::Code code, int flags, TosState in, TosState out, void (*gen)(LdcType ldct), LdcType ldct);\n","filename":"src\/hotspot\/share\/interpreter\/templateTable.hpp","additions":13,"deletions":6,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,0 +26,1 @@\n+#include \"cds\/archiveBuilder.hpp\"\n@@ -29,0 +30,1 @@\n+#include \"classfile\/systemDictionaryShared.hpp\"\n@@ -30,0 +32,1 @@\n+#include \"code\/codeCache.hpp\"\n@@ -50,0 +53,1 @@\n+#include \"runtime\/mutexLocker.hpp\"\n@@ -58,1 +62,1 @@\n-  _f1 = NULL;\n+  _f1 = nullptr;\n@@ -63,19 +67,1 @@\n-void ConstantPoolCacheEntry::verify_just_initialized(bool f2_used) {\n-  assert((_indices & (~cp_index_mask)) == 0, \"sanity\");\n-  assert(_f1 == NULL, \"sanity\");\n-  assert(_flags == 0, \"sanity\");\n-  if (!f2_used) {\n-    assert(_f2 == 0, \"sanity\");\n-  }\n-}\n-\n-void ConstantPoolCacheEntry::reinitialize(bool f2_used) {\n-  _indices &= cp_index_mask;\n-  _f1 = NULL;\n-  _flags = 0;\n-  if (!f2_used) {\n-    _f2 = 0;\n-  }\n-}\n-\n-int ConstantPoolCacheEntry::make_flags(TosState state,\n+intx ConstantPoolCacheEntry::make_flags(TosState state,\n@@ -85,1 +71,1 @@\n-  int f = ((int)state << tos_state_shift) | option_bits | field_index_or_method_params;\n+  intx f = ((int)state << tos_state_shift) | option_bits | field_index_or_method_params;\n@@ -118,1 +104,1 @@\n-  assert(f1 != NULL, \"\");\n+  assert(f1 != nullptr, \"\");\n@@ -177,1 +163,1 @@\n-  assert(method->interpreter_entry() != NULL, \"should have been set at this point\");\n+  assert(method->interpreter_entry() != nullptr, \"should have been set at this point\");\n@@ -182,1 +168,1 @@\n-  InstanceKlass* holder = NULL;  \/\/ have to declare this outside the switch\n+  InstanceKlass* holder = nullptr;  \/\/ have to declare this outside the switch\n@@ -270,1 +256,1 @@\n-             method->method_holder()->is_reentrant_initialization(Thread::current()),\n+             method->method_holder()->is_init_thread(JavaThread::current()),\n@@ -362,4 +348,0 @@\n-void ConstantPoolCacheEntry::set_dynamic_call(const constantPoolHandle& cpool, const CallInfo &call_info) {\n-  set_method_handle_common(cpool, Bytecodes::_invokedynamic, call_info);\n-}\n-\n@@ -377,0 +359,2 @@\n+  \/\/ Lock fields to write\n+  MutexLocker ml(cpool->pool_holder()->init_monitor());\n@@ -378,8 +362,0 @@\n-  JavaThread* current = JavaThread::current();\n-  objArrayHandle resolved_references(current, cpool->resolved_references());\n-  \/\/ Use the resolved_references() lock for this cpCache entry.\n-  \/\/ resolved_references are created for all classes with Invokedynamic, MethodHandle\n-  \/\/ or MethodType constant pool cache entries.\n-  assert(resolved_references() != NULL,\n-         \"a resolved_references array should have been created for this class\");\n-  ObjectLocker ol(resolved_references, current);\n@@ -421,1 +397,1 @@\n-  LogStream* log_stream = NULL;\n+  LogStream* log_stream = nullptr;\n@@ -457,3 +433,2 @@\n-    assert(appendix_index >= 0 && appendix_index < resolved_references->length(), \"oob\");\n-    assert(resolved_references->obj_at(appendix_index) == NULL, \"init just once\");\n-    resolved_references->obj_at_put(appendix_index, appendix());\n+    oop old_oop = cpool->set_resolved_reference_at(appendix_index, appendix());\n+    assert(old_oop == nullptr, \"init just once\");\n@@ -469,2 +444,2 @@\n-  if (log_stream != NULL) {\n-    this->print(log_stream, 0);\n+  if (log_stream != nullptr) {\n+    this->print(log_stream, 0, cpool->cache());\n@@ -477,35 +452,1 @@\n-bool ConstantPoolCacheEntry::save_and_throw_indy_exc(\n-  const constantPoolHandle& cpool, int cpool_index, int index, constantTag tag, TRAPS) {\n-\n-  assert(HAS_PENDING_EXCEPTION, \"No exception got thrown!\");\n-  assert(PENDING_EXCEPTION->is_a(vmClasses::LinkageError_klass()),\n-         \"No LinkageError exception\");\n-\n-  \/\/ Use the resolved_references() lock for this cpCache entry.\n-  \/\/ resolved_references are created for all classes with Invokedynamic, MethodHandle\n-  \/\/ or MethodType constant pool cache entries.\n-  JavaThread* current = THREAD;\n-  objArrayHandle resolved_references(current, cpool->resolved_references());\n-  assert(resolved_references() != NULL,\n-         \"a resolved_references array should have been created for this class\");\n-  ObjectLocker ol(resolved_references, current);\n-\n-  \/\/ if f1 is not null or the indy_resolution_failed flag is set then another\n-  \/\/ thread either succeeded in resolving the method or got a LinkageError\n-  \/\/ exception, before this thread was able to record its failure.  So, clear\n-  \/\/ this thread's exception and return false so caller can use the earlier\n-  \/\/ thread's result.\n-  if (!is_f1_null() || indy_resolution_failed()) {\n-    CLEAR_PENDING_EXCEPTION;\n-    return false;\n-  }\n-\n-  Symbol* error = PENDING_EXCEPTION->klass()->name();\n-  Symbol* message = java_lang_Throwable::detail_message(PENDING_EXCEPTION);\n-\n-  SystemDictionary::add_resolution_error(cpool, index, error, message);\n-  set_indy_resolution_failed();\n-  return true;\n-}\n-\n-Method* ConstantPoolCacheEntry::method_if_resolved(const constantPoolHandle& cpool) {\n+Method* ConstantPoolCacheEntry::method_if_resolved(const constantPoolHandle& cpool) const {\n@@ -516,1 +457,1 @@\n-    if (f1 != NULL) {\n+    if (f1 != nullptr) {\n@@ -525,1 +466,0 @@\n-      case Bytecodes::_invokedynamic:\n@@ -528,0 +468,2 @@\n+      case Bytecodes::_invokedynamic:\n+        ShouldNotReachHere();\n@@ -554,1 +496,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -558,1 +500,1 @@\n-oop ConstantPoolCacheEntry::appendix_if_resolved(const constantPoolHandle& cpool) {\n+oop ConstantPoolCacheEntry::appendix_if_resolved(const constantPoolHandle& cpool) const {\n@@ -560,1 +502,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -562,2 +504,1 @@\n-  objArrayOop resolved_references = cpool->resolved_references();\n-  return resolved_references->obj_at(ref_index);\n+  return cpool->resolved_reference_at(ref_index);\n@@ -597,1 +538,1 @@\n-  assert (_f1 != NULL, \"should not call with uninteresting entry\");\n+  assert (_f1 != nullptr, \"should not call with uninteresting entry\");\n@@ -615,1 +556,1 @@\n-  if (m != NULL) {\n+  if (m != nullptr) {\n@@ -626,1 +567,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -628,1 +569,1 @@\n-  Method* m = NULL;\n+  Method* m = nullptr;\n@@ -633,2 +574,2 @@\n-    \/\/ NULL _f1 means this is a virtual entry so also not interesting\n-    return NULL;\n+    \/\/ null _f1 means this is a virtual entry so also not interesting\n+    return nullptr;\n@@ -643,3 +584,3 @@\n-  assert(m != NULL && m->is_method(), \"sanity check\");\n-  if (m == NULL || !m->is_method()) {\n-    return NULL;\n+  assert(m != nullptr && m->is_method(), \"sanity check\");\n+  if (m == nullptr || !m->is_method()) {\n+    return nullptr;\n@@ -651,1 +592,1 @@\n-void ConstantPoolCacheEntry::print(outputStream* st, int index) const {\n+void ConstantPoolCacheEntry::print(outputStream* st, int index, const ConstantPoolCache* cache) const {\n@@ -654,7 +595,40 @@\n-  \/\/ print entry\n-  st->print(\"%3d  (\" PTR_FORMAT \")  \", index, (intptr_t)this);\n-  st->print_cr(\"[%02x|%02x|%5d]\", bytecode_2(), bytecode_1(),\n-               constant_pool_index());\n-  st->print_cr(\"                 [   \" PTR_FORMAT \"]\", (intptr_t)_f1);\n-  st->print_cr(\"                 [   \" PTR_FORMAT \"]\", (intptr_t)_f2);\n-  st->print_cr(\"                 [   \" PTR_FORMAT \"]\", (intptr_t)_flags);\n+  \/\/ print universal entry info\n+  st->print_cr(\"%3d\", index);\n+  st->print_cr(\" - this: \" PTR_FORMAT, p2i(this));\n+  st->print_cr(\" - bytecode 1: %s %02x\", Bytecodes::name(bytecode_1()), bytecode_1());\n+  st->print_cr(\" - bytecode 2: %s %02x\", Bytecodes::name(bytecode_2()), bytecode_2());\n+  st->print_cr(\" - cp index: %5d\", constant_pool_index());\n+  if (is_method_entry()) {\n+    ResourceMark rm;\n+    constantPoolHandle cph(Thread::current(), cache->constant_pool());\n+    Method* m = method_if_resolved(cph);\n+    st->print_cr(\" - F1:  [   \" PTR_FORMAT \"]\", (intptr_t)_f1);\n+    st->print_cr(\" - F2:  [   \" PTR_FORMAT \"]\", (intptr_t)_f2);\n+    st->print_cr(\" - method: \" INTPTR_FORMAT \" %s\", p2i(m), m != nullptr ? m->external_name() : nullptr);\n+    st->print_cr(\" - flag values: [%02x|0|0|%01x|%01x|%01x|%01x|0|%01x|%01x|00|00|%02x]\",\n+                 flag_state(), has_local_signature(), has_appendix(),\n+                 is_forced_virtual(), is_final(), is_vfinal(),\n+                 indy_resolution_failed(), parameter_size());\n+    st->print_cr(\" - tos: %s\\n - local signature: %01x\\n\"\n+                 \" - has appendix: %01x\\n - forced virtual: %01x\\n\"\n+                 \" - final: %01x\\n - virtual final: %01x\\n - resolution failed: %01x\\n\"\n+                 \" - num parameters: %02x\",\n+                 type2name(as_BasicType(flag_state())), has_local_signature(), has_appendix(),\n+                 is_forced_virtual(), is_final(), is_vfinal(),\n+                 indy_resolution_failed(), parameter_size());\n+    if ((bytecode_1() == Bytecodes::_invokehandle)) {\n+      oop appendix = appendix_if_resolved(cph);\n+      if (appendix != nullptr) {\n+        st->print(\"  appendix: \");\n+        appendix->print_on(st);\n+      }\n+    }\n+  } else {\n+    assert(is_field_entry(), \"must be a field entry\");\n+    st->print_cr(\" - F1:  [   \" PTR_FORMAT \"]\", (intptr_t)_f1);\n+    st->print_cr(\" - F2:  [   \" PTR_FORMAT \"]\", (intptr_t)_f2);\n+    st->print_cr(\" - flag values: [%02x|0|1|0|0|0|%01x|%01x|0|0|%04x]\",\n+                 flag_state(), is_final(), is_volatile(), field_index());\n+    st->print_cr(\" - tos: %s\\n - final: %d\\n - volatile: %d\\n - field index: %04x\",\n+                 type2name(as_BasicType(flag_state())), is_final(), is_volatile(), field_index());\n+  }\n@@ -672,2 +646,3 @@\n-                                     const intStack& invokedynamic_index_map,\n-                                     const intStack& invokedynamic_map, TRAPS) {\n+                                     const intStack& invokedynamic_map,\n+                                     const GrowableArray<ResolvedIndyEntry> indy_entries,\n+                                     TRAPS) {\n@@ -675,1 +650,1 @@\n-  const int length = index_map.length() + invokedynamic_index_map.length();\n+  const int length = index_map.length();\n@@ -678,0 +653,11 @@\n+  \/\/ Initialize ResolvedIndyEntry array with available data\n+  Array<ResolvedIndyEntry>* resolved_indy_entries;\n+  if (indy_entries.length()) {\n+    resolved_indy_entries = MetadataFactory::new_array<ResolvedIndyEntry>(loader_data, indy_entries.length(), CHECK_NULL);\n+    for (int i = 0; i < indy_entries.length(); i++) {\n+      resolved_indy_entries->at_put(i, indy_entries.at(i));\n+    }\n+  } else {\n+    resolved_indy_entries = nullptr;\n+  }\n+\n@@ -679,1 +665,1 @@\n-    ConstantPoolCache(length, index_map, invokedynamic_index_map, invokedynamic_map);\n+              ConstantPoolCache(length, index_map, invokedynamic_map, resolved_indy_entries);\n@@ -683,1 +669,0 @@\n-                                   const intArray& invokedynamic_inverse_index_map,\n@@ -692,10 +677,0 @@\n-  \/\/ Append invokedynamic entries at the end\n-  int invokedynamic_offset = inverse_index_map.length();\n-  for (int i = 0; i < invokedynamic_inverse_index_map.length(); i++) {\n-    int offset = i + invokedynamic_offset;\n-    ConstantPoolCacheEntry* e = entry_at(offset);\n-    int original_index = invokedynamic_inverse_index_map.at(i);\n-    e->initialize_entry(original_index);\n-    assert(entry_at(offset) == e, \"sanity\");\n-  }\n-\n@@ -710,2 +685,3 @@\n-void ConstantPoolCache::verify_just_initialized() {\n-  DEBUG_ONLY(walk_entries_for_initialization(\/*check_only = *\/ true));\n+\/\/ Record the GC marking cycle when redefined vs. when found in the loom stack chunks.\n+void ConstantPoolCache::record_gc_epoch() {\n+  _gc_epoch = CodeCache::gc_epoch();\n@@ -714,2 +690,7 @@\n-void ConstantPoolCache::remove_unshareable_info() {\n-  walk_entries_for_initialization(\/*check_only = *\/ false);\n+#if INCLUDE_CDS\n+void ConstantPoolCache::save_for_archive(TRAPS) {\n+  ClassLoaderData* loader_data = constant_pool()->pool_holder()->class_loader_data();\n+  _initial_entries = MetadataFactory::new_array<ConstantPoolCacheEntry>(loader_data, length(), CHECK);\n+  for (int i = 0; i < length(); i++) {\n+    _initial_entries->at_put(i, *entry_at(i));\n+  }\n@@ -718,1 +699,1 @@\n-void ConstantPoolCache::walk_entries_for_initialization(bool check_only) {\n+void ConstantPoolCache::remove_unshareable_info() {\n@@ -720,38 +701,9 @@\n-  \/\/ When dumping the archive, we want to clean up the ConstantPoolCache\n-  \/\/ to remove any effect of linking due to the execution of Java code --\n-  \/\/ each ConstantPoolCacheEntry will have the same contents as if\n-  \/\/ ConstantPoolCache::initialize has just returned:\n-  \/\/\n-  \/\/ - We keep the ConstantPoolCache::constant_pool_index() bits for all entries.\n-  \/\/ - We keep the \"f2\" field for entries used by invokedynamic and invokehandle\n-  \/\/ - All other bits in the entries are cleared to zero.\n-  ResourceMark rm;\n-\n-  InstanceKlass* ik = constant_pool()->pool_holder();\n-  bool* f2_used = NEW_RESOURCE_ARRAY(bool, length());\n-  memset(f2_used, 0, sizeof(bool) * length());\n-\n-  Thread* current = Thread::current();\n-\n-  \/\/ Find all the slots that we need to preserve f2\n-  for (int i = 0; i < ik->methods()->length(); i++) {\n-    Method* m = ik->methods()->at(i);\n-    RawBytecodeStream bcs(methodHandle(current, m));\n-    while (!bcs.is_last_bytecode()) {\n-      Bytecodes::Code opcode = bcs.raw_next();\n-      switch (opcode) {\n-      case Bytecodes::_invokedynamic: {\n-          int index = Bytes::get_native_u4(bcs.bcp() + 1);\n-          int cp_cache_index = constant_pool()->invokedynamic_cp_cache_index(index);\n-          f2_used[cp_cache_index] = 1;\n-        }\n-        break;\n-      case Bytecodes::_invokehandle: {\n-          int cp_cache_index = Bytes::get_native_u2(bcs.bcp() + 1);\n-          f2_used[cp_cache_index] = 1;\n-        }\n-        break;\n-      default:\n-        break;\n-      }\n-    }\n+  \/\/ <this> is the copy to be written into the archive. It's in the ArchiveBuilder's \"buffer space\".\n+  \/\/ However, this->_initial_entries was not copied\/relocated by the ArchiveBuilder, so it's\n+  \/\/ still pointing to the array allocated inside save_for_archive().\n+  assert(_initial_entries != nullptr, \"archived cpcache must have been initialized\");\n+  assert(!ArchiveBuilder::current()->is_in_buffer_space(_initial_entries), \"must be\");\n+  for (int i=0; i<length(); i++) {\n+    \/\/ Restore each entry to the initial state -- just after Rewriter::make_constant_pool_cache()\n+    \/\/ has finished.\n+    *entry_at(i) = _initial_entries->at(i);\n@@ -759,0 +711,1 @@\n+  _initial_entries = nullptr;\n@@ -760,8 +713,3 @@\n-  if (check_only) {\n-    DEBUG_ONLY(\n-      for (int i=0; i<length(); i++) {\n-        entry_at(i)->verify_just_initialized(f2_used[i]);\n-      })\n-  } else {\n-    for (int i=0; i<length(); i++) {\n-      entry_at(i)->reinitialize(f2_used[i]);\n+  if (_resolved_indy_entries != nullptr) {\n+    for (int i = 0; i < _resolved_indy_entries->length(); i++) {\n+      resolved_indy_entry_at(i)->remove_unshareable_info();\n@@ -771,0 +719,1 @@\n+#endif \/\/ INCLUDE_CDS\n@@ -777,1 +726,10 @@\n-  set_reference_map(NULL);\n+  set_reference_map(nullptr);\n+#if INCLUDE_CDS\n+  if (_initial_entries != nullptr) {\n+    Arguments::assert_is_dumping_archive();\n+    MetadataFactory::free_array<ConstantPoolCacheEntry>(data, _initial_entries);\n+    if (_resolved_indy_entries)\n+      MetadataFactory::free_array<ResolvedIndyEntry>(data, _resolved_indy_entries);\n+    _initial_entries = nullptr;\n+  }\n+#endif\n@@ -783,1 +741,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -795,1 +753,1 @@\n-void ConstantPoolCache::set_archived_references(oop o) {\n+void ConstantPoolCache::set_archived_references(int root_index) {\n@@ -797,1 +755,1 @@\n-  _archived_references_index = HeapShared::append_root(o);\n+  _archived_references_index = root_index;\n@@ -806,0 +764,11 @@\n+  if (_resolved_indy_entries != nullptr) {\n+    for (int j = 0; j < _resolved_indy_entries->length(); j++) {\n+      Method* old_method = resolved_indy_entry_at(j)->method();\n+      if (old_method == nullptr || !old_method->is_old()) {\n+        continue;\n+      }\n+      Method* new_method = old_method->get_new_method();\n+      resolved_indy_entry_at(j)->adjust_method_entry(new_method);\n+      log_adjust(\"indy\", old_method, new_method, trace_name_printed);\n+    }\n+  }\n@@ -809,1 +778,1 @@\n-    if (old_method == NULL || !old_method->is_old()) {\n+    if (old_method == nullptr || !old_method->is_old()) {\n@@ -825,0 +794,12 @@\n+  if (_resolved_indy_entries) {\n+    for (int i = 0; i < _resolved_indy_entries->length(); i++) {\n+      Method* m = resolved_indy_entry_at(i)->method();\n+      if (m != nullptr && !resolved_indy_entry_at(i)->check_no_old_or_obsolete_entry()) {\n+        log_trace(redefine, class, update, constantpool)\n+          (\"cpcache check found old method entry: class: %s, old: %d, obsolete: %d, method: %s\",\n+           constant_pool()->pool_holder()->external_name(), m->is_old(), m->is_obsolete(), m->external_name());\n+        return false;\n+      }\n+    }\n+  }\n+\n@@ -827,1 +808,1 @@\n-    if (m != NULL && !entry_at(i)->check_no_old_or_obsolete_entries()) {\n+    if (m != nullptr && !entry_at(i)->check_no_old_or_obsolete_entries()) {\n@@ -839,2 +820,2 @@\n-    if (entry_at(i)->get_interesting_method_entry() != NULL) {\n-      entry_at(i)->print(tty, i);\n+    if (entry_at(i)->get_interesting_method_entry() != nullptr) {\n+      entry_at(i)->print(tty, i, this);\n@@ -850,0 +831,89 @@\n+  if (_resolved_indy_entries != nullptr) {\n+    it->push(&_resolved_indy_entries, MetaspaceClosure::_writable);\n+  }\n+}\n+\n+bool ConstantPoolCache::save_and_throw_indy_exc(\n+  const constantPoolHandle& cpool, int cpool_index, int index, constantTag tag, TRAPS) {\n+\n+  assert(HAS_PENDING_EXCEPTION, \"No exception got thrown!\");\n+  assert(PENDING_EXCEPTION->is_a(vmClasses::LinkageError_klass()),\n+         \"No LinkageError exception\");\n+\n+  MutexLocker ml(THREAD, cpool->pool_holder()->init_monitor());\n+\n+  \/\/ if the indy_info is resolved or the indy_resolution_failed flag is set then another\n+  \/\/ thread either succeeded in resolving the method or got a LinkageError\n+  \/\/ exception, before this thread was able to record its failure.  So, clear\n+  \/\/ this thread's exception and return false so caller can use the earlier\n+  \/\/ thread's result.\n+  if (resolved_indy_entry_at(index)->is_resolved() || resolved_indy_entry_at(index)->resolution_failed()) {\n+    CLEAR_PENDING_EXCEPTION;\n+    return false;\n+  }\n+\n+  Symbol* error = PENDING_EXCEPTION->klass()->name();\n+  Symbol* message = java_lang_Throwable::detail_message(PENDING_EXCEPTION);\n+\n+  int encoded_index = ResolutionErrorTable::encode_cpcache_index(\n+                          ConstantPool::encode_invokedynamic_index(index));\n+  SystemDictionary::add_resolution_error(cpool, encoded_index, error, message);\n+  resolved_indy_entry_at(index)->set_resolution_failed();\n+  return true;\n+}\n+\n+oop ConstantPoolCache::set_dynamic_call(const CallInfo &call_info, int index) {\n+  ResourceMark rm;\n+  MutexLocker ml(constant_pool()->pool_holder()->init_monitor());\n+  assert(index >= 0, \"Indy index must be positive at this point\");\n+\n+  if (resolved_indy_entry_at(index)->method() != nullptr) {\n+    return constant_pool()->resolved_reference_from_indy(index);\n+  }\n+\n+  if (resolved_indy_entry_at(index)->resolution_failed()) {\n+    \/\/ Before we got here, another thread got a LinkageError exception during\n+    \/\/ resolution.  Ignore our success and throw their exception.\n+    guarantee(index >= 0, \"Invalid indy index\");\n+    int encoded_index = ResolutionErrorTable::encode_cpcache_index(\n+                          ConstantPool::encode_invokedynamic_index(index));\n+    JavaThread* THREAD = JavaThread::current(); \/\/ For exception macros.\n+    constantPoolHandle cp(THREAD, constant_pool());\n+    ConstantPool::throw_resolution_error(cp, encoded_index, THREAD);\n+    return nullptr;\n+  }\n+\n+  Method* adapter            = call_info.resolved_method();\n+  const Handle appendix      = call_info.resolved_appendix();\n+  const bool has_appendix    = appendix.not_null();\n+\n+  LogStream* log_stream = nullptr;\n+  LogStreamHandle(Debug, methodhandles, indy) lsh_indy;\n+  if (lsh_indy.is_enabled()) {\n+    ResourceMark rm;\n+    log_stream = &lsh_indy;\n+    log_stream->print_cr(\"set_method_handle bc=%d appendix=\" PTR_FORMAT \"%s method=\" PTR_FORMAT \" (local signature) \",\n+                         0xba,\n+                         p2i(appendix()),\n+                         (has_appendix ? \"\" : \" (unused)\"),\n+                         p2i(adapter));\n+    adapter->print_on(log_stream);\n+    if (has_appendix)  appendix()->print_on(log_stream);\n+  }\n+\n+  if (has_appendix) {\n+    const int appendix_index = resolved_indy_entry_at(index)->resolved_references_index();\n+    objArrayOop resolved_references = constant_pool()->resolved_references();\n+    assert(appendix_index >= 0 && appendix_index < resolved_references->length(), \"oob\");\n+    assert(resolved_references->obj_at(appendix_index) == nullptr, \"init just once\");\n+    resolved_references->obj_at_put(appendix_index, appendix());\n+  }\n+\n+  \/\/ Populate entry with resolved information\n+  assert(resolved_indy_entries() != nullptr, \"Invokedynamic array is empty, cannot fill with resolved information\");\n+  resolved_indy_entry_at(index)->fill_in(adapter, adapter->size_of_parameters(), as_TosState(adapter->result_type()), has_appendix);\n+\n+  if (log_stream != nullptr) {\n+    resolved_indy_entry_at(index)->print_on(log_stream);\n+  }\n+  return appendix();\n@@ -857,1 +927,9 @@\n-  for (int i = 0; i < length(); i++) entry_at(i)->print(st, i);\n+  for (int i = 0; i < length(); i++) entry_at(i)->print(st, i, this);\n+  for (int i = 0; i < resolved_indy_entries_length(); i++) {\n+    ResolvedIndyEntry* indy_entry = resolved_indy_entry_at(i);\n+    indy_entry->print_on(st);\n+    if (indy_entry->has_appendix()) {\n+      st->print(\"  appendix: \");\n+      constant_pool()->resolved_reference_from_indy(i)->print_on(st);\n+    }\n+  }\n","filename":"src\/hotspot\/share\/oops\/cpCache.cpp","additions":256,"deletions":178,"binary":false,"changes":434,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -32,0 +32,1 @@\n+#include \"oops\/resolvedIndyEntry.hpp\"\n@@ -37,2 +38,0 @@\n-class PSPromotionManager;\n-\n@@ -136,1 +135,0 @@\n-  friend class constantPoolCacheKlass;\n@@ -151,1 +149,1 @@\n-    assert(existing_f1 == NULL || existing_f1 == f1, \"illegal field change\");\n+    assert(existing_f1 == nullptr || existing_f1 == f1, \"illegal field change\");\n@@ -164,1 +162,1 @@\n-  int make_flags(TosState state, int option_bits, int field_index_or_method_params);\n+  intx make_flags(TosState state, int option_bits, int field_index_or_method_params);\n@@ -234,1 +232,1 @@\n-    const methodHandle& method,                  \/\/ the method\/prototype if any (NULL, otherwise)\n+    const methodHandle& method,                  \/\/ the method\/prototype if any (null, otherwise)\n@@ -264,5 +262,0 @@\n-  void set_dynamic_call(\n-    const constantPoolHandle& cpool,             \/\/ holding constant pool (required for locking)\n-    const CallInfo &call_info                    \/\/ Call link information\n-  );\n-\n@@ -290,7 +283,0 @@\n-  \/\/ Return TRUE if resolution failed and this thread got to record the failure\n-  \/\/ status.  Return FALSE if another thread succeeded or failed in resolving\n-  \/\/ the method and recorded the success or failure before this thread had a\n-  \/\/ chance to record its failure.\n-  bool save_and_throw_indy_exc(const constantPoolHandle& cpool, int cpool_index,\n-                               int index, constantTag tag, TRAPS);\n-\n@@ -299,2 +285,2 @@\n-  Method*      method_if_resolved(const constantPoolHandle& cpool);\n-  oop        appendix_if_resolved(const constantPoolHandle& cpool);\n+  Method*      method_if_resolved(const constantPoolHandle& cpool) const;\n+  oop        appendix_if_resolved(const constantPoolHandle& cpool) const;\n@@ -327,2 +313,2 @@\n-  int indices() const                            { return _indices; }\n-  int indices_ord() const;\n+  intx indices() const                           { return _indices; }\n+  intx indices_ord() const;\n@@ -386,1 +372,1 @@\n-  void print (outputStream* st, int index) const;\n+  void print (outputStream* st, int index, const ConstantPoolCache* cache) const;\n@@ -393,3 +379,0 @@\n-\n-  void verify_just_initialized(bool f2_used);\n-  void reinitialize(bool f2_used);\n@@ -411,0 +394,5 @@\n+\n+  \/\/ The narrowOop pointer to the archived resolved_references. Set at CDS dump\n+  \/\/ time when caching java heap object is supported.\n+  CDS_JAVA_HEAP_ONLY(int _archived_references_index;) \/\/ Gap on LP64\n+\n@@ -419,3 +407,7 @@\n-  \/\/ The narrowOop pointer to the archived resolved_references. Set at CDS dump\n-  \/\/ time when caching java heap object is supported.\n-  CDS_JAVA_HEAP_ONLY(int _archived_references_index;)\n+\n+  \/\/ RedefineClasses support\n+  uint64_t             _gc_epoch;\n+\n+  Array<ResolvedIndyEntry>* _resolved_indy_entries;\n+\n+  CDS_ONLY(Array<ConstantPoolCacheEntry>* _initial_entries;)\n@@ -429,2 +421,2 @@\n-                    const intStack& invokedynamic_inverse_index_map,\n-                    const intStack& invokedynamic_references_map);\n+                    const intStack& invokedynamic_references_map,\n+                    Array<ResolvedIndyEntry>* indy_info);\n@@ -434,1 +426,0 @@\n-                  const intArray& invokedynamic_inverse_index_map,\n@@ -439,2 +430,3 @@\n-                                     const intStack& invokedynamic_cp_cache_map,\n-                                     const intStack& invokedynamic_references_map, TRAPS);\n+                                     const intStack& invokedynamic_references_map,\n+                                     const GrowableArray<ResolvedIndyEntry> indy_entries,\n+                                     TRAPS);\n@@ -446,2 +438,2 @@\n-  oop  archived_references() NOT_CDS_JAVA_HEAP_RETURN_(NULL);\n-  void set_archived_references(oop o) NOT_CDS_JAVA_HEAP_RETURN;\n+  oop  archived_references() NOT_CDS_JAVA_HEAP_RETURN_(nullptr);\n+  void set_archived_references(int root_index) NOT_CDS_JAVA_HEAP_RETURN;\n@@ -450,1 +442,1 @@\n-  inline oop resolved_references();\n+  inline objArrayOop resolved_references();\n@@ -455,0 +447,9 @@\n+  Array<ResolvedIndyEntry>* resolved_indy_entries()          { return _resolved_indy_entries; }\n+  ResolvedIndyEntry* resolved_indy_entry_at(int index) const { return _resolved_indy_entries->adr_at(index); }\n+  int resolved_indy_entries_length()                   const { return _resolved_indy_entries->length();      }\n+  void print_resolved_indy_entries(outputStream* st)   const {\n+    for (int i = 0; i < _resolved_indy_entries->length(); i++) {\n+        _resolved_indy_entries->at(i).print_on(st);\n+    }\n+  }\n+\n@@ -456,1 +457,2 @@\n-  static int resolved_references_offset_in_bytes() { return offset_of(ConstantPoolCache, _resolved_references); }\n+  static ByteSize resolved_references_offset()   { return byte_offset_of(ConstantPoolCache, _resolved_references); }\n+  static ByteSize invokedynamic_entries_offset() { return byte_offset_of(ConstantPoolCache, _resolved_indy_entries); }\n@@ -458,1 +460,1 @@\n-  \/\/ CDS support\n+#if INCLUDE_CDS\n@@ -460,1 +462,3 @@\n-  void verify_just_initialized();\n+  void save_for_archive(TRAPS);\n+#endif\n+\n@@ -475,1 +479,0 @@\n-  friend class constantPoolCacheKlass;\n@@ -512,0 +515,9 @@\n+  void record_gc_epoch();\n+  uint64_t gc_epoch() { return _gc_epoch; }\n+\n+  \/\/ Return TRUE if resolution failed and this thread got to record the failure\n+  \/\/ status.  Return FALSE if another thread succeeded or failed in resolving\n+  \/\/ the method and recorded the success or failure before this thread had a\n+  \/\/ chance to record its failure.\n+  bool save_and_throw_indy_exc(const constantPoolHandle& cpool, int cpool_index, int index, constantTag tag, TRAPS);\n+  oop set_dynamic_call(const CallInfo &call_info, int index);\n","filename":"src\/hotspot\/share\/oops\/cpCache.hpp","additions":54,"deletions":42,"binary":false,"changes":96,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2011, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2011, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,2 +28,1 @@\n-#include \"oops\/constantPool.hpp\"\n-#include \"oops\/symbol.hpp\"\n+#include \"memory\/allocation.hpp\"\n@@ -31,0 +30,1 @@\n+#include \"utilities\/unsigned5.hpp\"\n@@ -33,0 +33,16 @@\n+static constexpr u4 flag_mask(int pos) {\n+  return (u4)1 << pos;\n+}\n+\n+\n+\/\/ Helper class for access to the underlying Array<u1> used to\n+\/\/ store the compressed stream of FieldInfo\n+template<typename ARR, typename OFF>\n+struct ArrayHelper {\n+  uint8_t operator()(ARR a, OFF i) const { return a->at(i); };\n+  void operator()(ARR a, OFF i, uint8_t b) const { a->at_put(i,b); };\n+  \/\/ So, an expression ArrayWriterHelper() acts like these lambdas:\n+  \/\/ auto get = [&](ARR a, OFF i){ return a[i]; };\n+  \/\/ auto set = [&](ARR a, OFF i, uint8_t x){ a[i] = x; };\n+};\n+\n@@ -43,0 +59,4 @@\n+  friend class FieldInfoStream;\n+  friend class FieldStreamBase;\n+  friend class FieldInfoReader;\n+  friend class VMStructs;\n@@ -45,31 +65,17 @@\n-  \/\/ fields\n-  \/\/ Field info extracted from the class file and stored\n-  \/\/ as an array of 6 shorts.\n-\n-#define FIELDINFO_TAG_SIZE             2\n-#define FIELDINFO_TAG_OFFSET           1 << 0\n-#define FIELDINFO_TAG_CONTENDED        1 << 1\n-\n-  \/\/ Packed field has the tag, and can be either of:\n-  \/\/    hi bits <--------------------------- lo bits\n-  \/\/   |---------high---------|---------low---------|\n-  \/\/    ..........................................CO\n-  \/\/    ..........................................00  - non-contended field\n-  \/\/    [--contention_group--]....................10  - contended field with contention group\n-  \/\/    [------------------offset----------------]01  - real field offset\n-\n-  \/\/ Bit O indicates if the packed field contains an offset (O=1) or not (O=0)\n-  \/\/ Bit C indicates if the field is contended (C=1) or not (C=0)\n-  \/\/       (if it is contended, the high packed field contains the contention group)\n-\n-  enum FieldOffset {\n-    access_flags_offset      = 0,\n-    name_index_offset        = 1,\n-    signature_index_offset   = 2,\n-    initval_index_offset     = 3,\n-    low_packed_offset        = 4,\n-    high_packed_offset       = 5,\n-    field_slots              = 6\n-  };\n- private:\n-  u2 _shorts[field_slots];\n+  class FieldFlags {\n+    friend class VMStructs;\n+    friend class JVMCIVMStructs;\n+\n+    \/\/ The ordering of this enum is totally internal.  More frequent\n+    \/\/ flags should come earlier than less frequent ones, because\n+    \/\/ earlier ones compress better.\n+    enum FieldFlagBitPosition {\n+      _ff_initialized,  \/\/ has ConstantValue initializer attribute\n+      _ff_injected,     \/\/ internal field injected by the JVM\n+      _ff_generic,      \/\/ has a generic signature\n+      _ff_stable,       \/\/ trust as stable b\/c declared as @Stable\n+      _ff_contended,    \/\/ is contended, may have contention-group\n+#if INCLUDE_TSAN\n+      _ff_tsan_ignore,  \/\/ TSAN should ignore memory accesses to this field\n+#endif  \/\/ INCLUDE_TSAN\n+    };\n@@ -78,3 +84,6 @@\n-  void set_name_index(u2 val)                    { _shorts[name_index_offset] = val;         }\n-  void set_signature_index(u2 val)               { _shorts[signature_index_offset] = val;    }\n-  void set_initval_index(u2 val)                 { _shorts[initval_index_offset] = val;      }\n+    \/\/ Some but not all of the flag bits signal the presence of an\n+    \/\/ additional 32-bit item in the field record.\n+    static const u4 _optional_item_bit_mask =\n+      flag_mask((int)_ff_initialized) |\n+      flag_mask((int)_ff_generic)     |\n+      flag_mask((int)_ff_contended);\n@@ -82,3 +91,55 @@\n-  u2 name_index() const                          { return _shorts[name_index_offset];        }\n-  u2 signature_index() const                     { return _shorts[signature_index_offset];   }\n-  u2 initval_index() const                       { return _shorts[initval_index_offset];     }\n+    \/\/ boilerplate:\n+    u4 _flags;\n+\n+    bool test_flag(FieldFlagBitPosition pos) const {\n+      return (_flags & flag_mask(pos)) != 0;\n+    }\n+    void update_flag(FieldFlagBitPosition pos, bool z) {\n+      if (z)    _flags |=  flag_mask(pos);\n+      else      _flags &= ~flag_mask(pos);\n+    }\n+\n+   public:\n+    FieldFlags(u4 flags) {\n+      _flags = flags;\n+    }\n+    u4 as_uint() const { return _flags; }\n+    bool has_any_optionals() const {\n+      return (_flags & _optional_item_bit_mask) != 0;\n+    }\n+\n+    bool is_initialized() const     { return test_flag(_ff_initialized); }\n+    bool is_injected() const        { return test_flag(_ff_injected); }\n+    bool is_generic() const         { return test_flag(_ff_generic); }\n+    bool is_stable() const          { return test_flag(_ff_stable); }\n+    bool is_contended() const       { return test_flag(_ff_contended); }\n+#if INCLUDE_TSAN\n+    bool is_tsan_ignore() const     { return test_flag(_ff_tsan_ignore); }\n+#endif  \/\/ INCLUDE_TSAN\n+\n+    void update_initialized(bool z) { update_flag(_ff_initialized, z); }\n+    void update_injected(bool z)    { update_flag(_ff_injected, z); }\n+    void update_generic(bool z)     { update_flag(_ff_generic, z); }\n+    void update_stable(bool z)      { update_flag(_ff_stable, z); }\n+    void update_contended(bool z)   { update_flag(_ff_contended, z); }\n+#if INCLUDE_TSAN\n+    void update_tsan_ignore(bool z) { update_flag(_ff_tsan_ignore, z); }\n+#endif  \/\/ INCLUDE_TSAN\n+  };\n+\n+ private:\n+  \/\/ The following items are the unpacked bitwise information content\n+  \/\/ of a field record.  Per-field metadata extracted from the class\n+  \/\/ file are stored logically as a group of these items.  The\n+  \/\/ classfile parser produces these records in a temporary array, and\n+  \/\/ then compresses them into a FieldInfoStream.\n+  \/\/\n+  u4 _index;                    \/\/ which field it is\n+  u2 _name_index;               \/\/ index in CP of name\n+  u2 _signature_index;          \/\/ index in CP of descriptor\n+  u4 _offset;                   \/\/ offset in object layout\n+  AccessFlags _access_flags;    \/\/ access flags (JVM spec)\n+  FieldFlags _field_flags;      \/\/ VM defined flags (not JVM spec)\n+  u2 _initializer_index;        \/\/ index from ConstantValue attr (or 0)\n+  u2 _generic_signature_index;  \/\/ index from GenericSignature attr (or 0)\n+  u2 _contention_group;         \/\/ index from @Contended group item (or 0)\n@@ -87,17 +148,8 @@\n-  static FieldInfo* from_field_array(Array<u2>* fields, int index) {\n-    return ((FieldInfo*)fields->adr_at(index * field_slots));\n-  }\n-  static FieldInfo* from_field_array(u2* fields, int index) {\n-    return ((FieldInfo*)(fields + index * field_slots));\n-  }\n-  void initialize(u2 access_flags,\n-                  u2 name_index,\n-                  u2 signature_index,\n-                  u2 initval_index) {\n-    _shorts[access_flags_offset] = access_flags;\n-    _shorts[name_index_offset] = name_index;\n-    _shorts[signature_index_offset] = signature_index;\n-    _shorts[initval_index_offset] = initval_index;\n-    _shorts[low_packed_offset] = 0;\n-    _shorts[high_packed_offset] = 0;\n-  }\n+  FieldInfo() : _name_index(0),\n+                _signature_index(0),\n+                _offset(0),\n+                _access_flags(AccessFlags(0)),\n+                _field_flags(FieldFlags(0)),\n+                _initializer_index(0),\n+                _generic_signature_index(0),\n+                _contention_group(0) { }\n@@ -106,5 +158,30 @@\n-  u2 access_flags() const                        { return _shorts[access_flags_offset];            }\n-  u4 offset() const {\n-    assert((_shorts[low_packed_offset] & FIELDINFO_TAG_OFFSET) != 0, \"Offset must have been set\");\n-    return build_int_from_shorts(_shorts[low_packed_offset], _shorts[high_packed_offset]) >> FIELDINFO_TAG_SIZE;\n-  }\n+  FieldInfo(AccessFlags access_flags, u2 name_index, u2 signature_index, u2 initval_index, FieldInfo::FieldFlags fflags) :\n+            _name_index(name_index),\n+            _signature_index(signature_index),\n+            _offset(0),\n+            _access_flags(access_flags),\n+            _field_flags(fflags),\n+            _initializer_index(initval_index),\n+            _generic_signature_index(0),\n+            _contention_group(0) {\n+              if (initval_index != 0) {\n+                _field_flags.update_initialized(true);\n+              }\n+            }\n+\n+  u4 index() const                           { return _index; }\n+  void set_index(u4 index)                   { _index = index; }\n+  u2 name_index() const                      { return _name_index; }\n+  void set_name_index(u2 index)              { _name_index = index; }\n+  u2 signature_index() const                 { return _signature_index; }\n+  void set_signature_index(u2 index)         { _signature_index = index; }\n+  u4 offset() const                          { return _offset; }\n+  void set_offset(u4 offset)                 { _offset = offset; }\n+  AccessFlags access_flags() const           { return _access_flags; }\n+  FieldFlags field_flags() const             { return _field_flags; }\n+  FieldFlags* field_flags_addr()             { return &_field_flags; }\n+  u2 initializer_index() const               { return _initializer_index; }\n+  void set_initializer_index(u2 index)       { _initializer_index = index; }\n+  u2 generic_signature_index() const         { return _generic_signature_index; }\n+  void set_generic_signature_index(u2 index) { _generic_signature_index = index; }\n+  u2 contention_group() const                { return _contention_group; }\n@@ -113,1 +190,1 @@\n-    return (_shorts[low_packed_offset] & FIELDINFO_TAG_CONTENDED) != 0;\n+    return _field_flags.is_contended();\n@@ -117,7 +194,2 @@\n-    assert((_shorts[low_packed_offset] & FIELDINFO_TAG_OFFSET) == 0, \"Offset must not have been set\");\n-    assert((_shorts[low_packed_offset] & FIELDINFO_TAG_CONTENDED) != 0, \"Field must be contended\");\n-    return _shorts[high_packed_offset];\n- }\n-\n-  bool is_offset_set() const {\n-    return (_shorts[low_packed_offset] & FIELDINFO_TAG_OFFSET)!= 0;\n+    assert(is_contended(), \"\");\n+    return _contention_group;\n@@ -126,6 +198,3 @@\n-  Symbol* name(ConstantPool* cp) const {\n-    int index = name_index();\n-    if (is_internal()) {\n-      return lookup_symbol(index);\n-    }\n-    return cp->symbol_at(index);\n+  void set_contended_group(u2 group) {\n+    _field_flags.update_contended(true);\n+    _contention_group = group;\n@@ -134,6 +203,2 @@\n-  Symbol* signature(ConstantPool* cp) const {\n-    int index = signature_index();\n-    if (is_internal()) {\n-      return lookup_symbol(index);\n-    }\n-    return cp->symbol_at(index);\n+  bool is_offset_set() const {\n+    return _offset != 0;\n@@ -142,6 +207,1 @@\n-  void set_access_flags(u2 val)                  { _shorts[access_flags_offset] = val;             }\n-  void set_offset(u4 val)                        {\n-    val = val << FIELDINFO_TAG_SIZE; \/\/ make room for tag\n-    _shorts[low_packed_offset] = extract_low_short_from_int(val) | FIELDINFO_TAG_OFFSET;\n-    _shorts[high_packed_offset] = extract_high_short_from_int(val);\n-  }\n+  inline Symbol* name(ConstantPool* cp) const;\n@@ -149,6 +209,1 @@\n-  void set_contended_group(u2 val) {\n-    assert((_shorts[low_packed_offset] & FIELDINFO_TAG_OFFSET) == 0, \"Offset must not have been set\");\n-    assert((_shorts[low_packed_offset] & FIELDINFO_TAG_CONTENDED) == 0, \"Overwritting contended group\");\n-    _shorts[low_packed_offset] |= FIELDINFO_TAG_CONTENDED;\n-    _shorts[high_packed_offset] = val;\n-  }\n+  inline Symbol* signature(ConstantPool* cp) const;\n@@ -156,3 +211,1 @@\n-  bool is_internal() const {\n-    return (access_flags() & JVM_ACC_FIELD_INTERNAL) != 0;\n-  }\n+  inline Symbol* lookup_symbol(int symbol_index) const;\n@@ -160,7 +213,3 @@\n-  bool is_stable() const {\n-    return (access_flags() & JVM_ACC_FIELD_STABLE) != 0;\n-  }\n-  void set_stable(bool z) {\n-    if (z) _shorts[access_flags_offset] |=  JVM_ACC_FIELD_STABLE;\n-    else   _shorts[access_flags_offset] &= ~JVM_ACC_FIELD_STABLE;\n-  }\n+  void print(outputStream* os, ConstantPool* cp);\n+  void static print_from_growable_array(outputStream* os, GrowableArray<FieldInfo>* array, ConstantPool* cp);\n+};\n@@ -168,9 +217,1 @@\n-#if INCLUDE_TSAN\n-  bool is_tsan_ignore() const {\n-    return (access_flags() & JVM_ACC_FIELD_TSAN_IGNORE) != 0;\n-  }\n-  void set_tsan_ignore(bool z) {\n-    if (z) _shorts[access_flags_offset] |=  JVM_ACC_FIELD_TSAN_IGNORE;\n-    else   _shorts[access_flags_offset] &= ~JVM_ACC_FIELD_TSAN_IGNORE;\n-  }\n-#endif  \/\/ INCLUDE_TSAN\n+class FieldInfoStream;\n@@ -178,4 +219,102 @@\n-  Symbol* lookup_symbol(int symbol_index) const {\n-    assert(is_internal(), \"only internal fields\");\n-    return Symbol::vm_symbol_at(static_cast<vmSymbolID>(symbol_index));\n-  }\n+\/\/ Gadget for sizing and\/or writing a stream of field records.\n+template<typename CON>\n+class Mapper {\n+  CON* _consumer;  \/\/ can be UNSIGNED5::Writer or UNSIGNED5::Sizer\n+  int _next_index;\n+public:\n+  Mapper(CON* consumer) : _consumer(consumer) { _next_index = 0; }\n+  int next_index() const { return _next_index; }\n+  void set_next_index(int next_index) { _next_index = next_index; }\n+  CON* consumer() const { return _consumer; }\n+  void map_field_info(const FieldInfo& fi);\n+};\n+\n+\/\/ Gadget for decoding and reading the stream of field records.\n+class FieldInfoReader {\n+  friend class FieldInfoStream;\n+  friend class ClassFileParser;\n+  friend class FieldStreamBase;\n+  friend class FieldInfo;\n+\n+  UNSIGNED5::Reader<const u1*, int> _r;\n+  int _next_index;\n+\n+  public:\n+  FieldInfoReader(const Array<u1>* fi);\n+\n+  private:\n+  uint32_t next_uint() { return _r.next_uint(); }\n+  void skip(int n) { int s = _r.try_skip(n); assert(s == n,\"\"); }\n+\n+public:\n+  int has_next() { return _r.has_next(); }\n+  int position() { return _r.position(); }\n+  int next_index() { return _next_index; }\n+  void read_field_info(FieldInfo& fi);\n+  \/\/ skip a whole field record, both required and optional bits\n+  FieldInfoReader&  skip_field_info();\n+\n+  \/\/ Skip to the nth field.  If the reader is freshly initialized to\n+  \/\/ the zero index, this will call skip_field_info() n times.\n+  FieldInfoReader& skip_to_field_info(int n);\n+\n+  \/\/ for random access, if you know where to go up front:\n+  FieldInfoReader& set_position_and_next_index(int position, int next_index);\n+};\n+\n+\/\/ The format of the stream, after decompression, is a series of\n+\/\/ integers organized like this:\n+\/\/\n+\/\/   FieldInfoStream := j=num_java_fields k=num_injected_fields Field[j+k] End\n+\/\/   Field := name sig offset access flags Optionals(flags)\n+\/\/   Optionals(i) := initval?[i&is_init]     \/\/ ConstantValue attr\n+\/\/                   gsig?[i&is_generic]     \/\/ signature attr\n+\/\/                   group?[i&is_contended]  \/\/ Contended anno (group)\n+\/\/   End = 0\n+\/\/\n+class FieldInfoStream : AllStatic {\n+  friend class fieldDescriptor;\n+  friend class JavaFieldStream;\n+  friend class FieldStreamBase;\n+  friend class ClassFileParser;\n+\n+ public:\n+  static int num_java_fields(const Array<u1>* fis);\n+  static int num_injected_java_fields(const Array<u1>* fis);\n+  static int num_total_fields(const Array<u1>* fis);\n+\n+  static Array<u1>* create_FieldInfoStream(GrowableArray<FieldInfo>* fields, int java_fields, int injected_fields,\n+                                                          ClassLoaderData* loader_data, TRAPS);\n+  static GrowableArray<FieldInfo>* create_FieldInfoArray(const Array<u1>* fis, int* java_fields_count, int* injected_fields_count);\n+  static void print_from_fieldinfo_stream(Array<u1>* fis, outputStream* os, ConstantPool* cp);\n+};\n+\n+class FieldStatus {\n+  enum FieldStatusBitPosition {\n+    _fs_access_watched,       \/\/ field access is watched by JVMTI\n+    _fs_modification_watched, \/\/ field modification is watched by JVMTI\n+    _initialized_final_update \/\/ (static) final field updated outside (class) initializer\n+  };\n+\n+  \/\/ boilerplate:\n+  u1 _flags;\n+  static constexpr u1 flag_mask(FieldStatusBitPosition pos) { return (u1)1 << (int)pos; }\n+  bool test_flag(FieldStatusBitPosition pos) { return (_flags & flag_mask(pos)) != 0; }\n+  \/\/ this performs an atomic update on a live status byte!\n+  void update_flag(FieldStatusBitPosition pos, bool z);\n+  \/\/ out-of-line functions do a CAS-loop\n+  static void atomic_set_bits(u1& flags, u1 mask);\n+  static void atomic_clear_bits(u1& flags, u1 mask);\n+\n+  public:\n+  FieldStatus() { _flags = 0; }\n+  FieldStatus(u1 flags) { _flags = flags; }\n+  u1 as_uint() { return _flags; }\n+\n+  bool is_access_watched()        { return test_flag(_fs_access_watched); }\n+  bool is_modification_watched()  { return test_flag(_fs_modification_watched); }\n+  bool is_initialized_final_update() { return test_flag(_initialized_final_update); }\n+\n+  void update_access_watched(bool z);\n+  void update_modification_watched(bool z);\n+  void update_initialized_final_update(bool z);\n","filename":"src\/hotspot\/share\/oops\/fieldInfo.hpp","additions":256,"deletions":117,"binary":false,"changes":373,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,1 +26,0 @@\n-#include \"jvm.h\"\n@@ -29,0 +28,1 @@\n+#include \"cds\/heapShared.hpp\"\n@@ -36,2 +36,0 @@\n-#include \"classfile\/resolutionErrors.hpp\"\n-#include \"classfile\/symbolTable.hpp\"\n@@ -50,0 +48,1 @@\n+#include \"jvm.h\"\n@@ -67,0 +66,1 @@\n+#include \"oops\/instanceStackChunkKlass.hpp\"\n@@ -77,0 +77,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -78,1 +79,0 @@\n-#include \"runtime\/biasedLocking.hpp\"\n@@ -82,0 +82,1 @@\n+#include \"runtime\/javaThread.inline.hpp\"\n@@ -85,1 +86,1 @@\n-#include \"runtime\/thread.inline.hpp\"\n+#include \"runtime\/threads.hpp\"\n@@ -87,0 +88,1 @@\n+#include \"services\/finalizerService.hpp\"\n@@ -92,0 +94,1 @@\n+#include \"utilities\/pair.hpp\"\n@@ -102,1 +105,0 @@\n-\n@@ -116,1 +118,1 @@\n-    char* data = NULL;                                           \\\n+    char* data = nullptr;                                        \\\n@@ -119,1 +121,1 @@\n-    if (clss_name != NULL) {                                     \\\n+    if (clss_name != nullptr) {                                  \\\n@@ -129,1 +131,1 @@\n-    char* data = NULL;                                           \\\n+    char* data = nullptr;                                        \\\n@@ -132,1 +134,1 @@\n-    if (clss_name != NULL) {                                     \\\n+    if (clss_name != nullptr) {                                  \\\n@@ -147,0 +149,1 @@\n+bool InstanceKlass::_finalization_enabled = true;\n@@ -150,1 +153,1 @@\n-  assert(class_name != NULL, \"invariant\");\n+  assert(class_name != nullptr, \"invariant\");\n@@ -158,1 +161,1 @@\n-    if (super_klass != NULL) {\n+    if (super_klass != nullptr) {\n@@ -167,0 +170,6 @@\n+static inline bool is_stack_chunk_class(const Symbol* class_name,\n+                                        const ClassLoaderData* loader_data) {\n+  return (class_name == vmSymbols::jdk_internal_vm_StackChunk() &&\n+          loader_data->is_the_null_class_loader_data());\n+}\n+\n@@ -172,1 +181,1 @@\n-  if (_nest_members == NULL || _nest_members == Universe::the_empty_short_array()) {\n+  if (_nest_members == nullptr || _nest_members == Universe::the_empty_short_array()) {\n@@ -204,2 +213,2 @@\n-  assert(k != NULL, \"sanity check\");\n-  assert(_permitted_subclasses != NULL && _permitted_subclasses != Universe::the_empty_short_array(),\n+  assert(k != nullptr, \"sanity check\");\n+  assert(_permitted_subclasses != nullptr && _permitted_subclasses != Universe::the_empty_short_array(),\n@@ -243,1 +252,1 @@\n-\/\/ (such as a native JIT thread) then we simply return NULL, which in turn\n+\/\/ (such as a native JIT thread) then we simply return null, which in turn\n@@ -250,2 +259,2 @@\n-\/\/ VirtualMachineErrors are propagated with a NULL return.\n-\/\/ Under any conditions where the _nest_host can be set to non-NULL the resulting\n+\/\/ VirtualMachineErrors are propagated with a null return.\n+\/\/ Under any conditions where the _nest_host can be set to non-null the resulting\n@@ -256,1 +265,1 @@\n-  if (nest_host_k != NULL) {\n+  if (nest_host_k != nullptr) {\n@@ -269,1 +278,1 @@\n-      return NULL; \/\/ sentinel to say \"try again from a different context\"\n+      return nullptr; \/\/ sentinel to say \"try again from a different context\"\n@@ -279,1 +288,1 @@\n-        return NULL; \/\/ propagate VMEs\n+        return nullptr; \/\/ propagate VMEs\n@@ -296,1 +305,1 @@\n-      const char* error = NULL;\n+      const char* error = nullptr;\n@@ -358,3 +367,3 @@\n-  assert(host != NULL, \"NULL nest host specified\");\n-  assert(_nest_host == NULL, \"current class has resolved nest-host\");\n-  assert(nest_host_error() == NULL, \"unexpected nest host resolution error exists: %s\",\n+  assert(host != nullptr, \"null nest host specified\");\n+  assert(_nest_host == nullptr, \"current class has resolved nest-host\");\n+  assert(nest_host_error() == nullptr, \"unexpected nest host resolution error exists: %s\",\n@@ -362,1 +371,1 @@\n-  assert((host->_nest_host == NULL && host->_nest_host_index == 0) ||\n+  assert((host->_nest_host == nullptr && host->_nest_host_index == 0) ||\n@@ -373,1 +382,1 @@\n-    } else if (_nest_members != NULL && _nest_members != Universe::the_empty_short_array()) {\n+    } else if (_nest_members != nullptr && _nest_members != Universe::the_empty_short_array()) {\n@@ -385,0 +394,1 @@\n+  assert(this_key != nullptr, \"sanity\");\n@@ -400,1 +410,1 @@\n-  if (cur_host == NULL) {\n+  if (cur_host == nullptr) {\n@@ -405,1 +415,1 @@\n-  if (k_nest_host == NULL) {\n+  if (k_nest_host == nullptr) {\n@@ -421,1 +431,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -435,1 +445,1 @@\n-  assert(class_name != NULL, \"invariant\");\n+  assert(class_name != nullptr, \"invariant\");\n@@ -437,1 +447,1 @@\n-  assert(loader_data != NULL, \"invariant\");\n+  assert(loader_data != nullptr, \"invariant\");\n@@ -442,14 +452,2 @@\n-  if (REF_NONE == parser.reference_type()) {\n-    if (class_name == vmSymbols::java_lang_Class()) {\n-      \/\/ mirror\n-      ik = new (loader_data, size, THREAD) InstanceMirrorKlass(parser);\n-    }\n-    else if (is_class_loader(class_name, parser)) {\n-      \/\/ class loader\n-      ik = new (loader_data, size, THREAD) InstanceClassLoaderKlass(parser);\n-    } else {\n-      \/\/ normal\n-      ik = new (loader_data, size, THREAD) InstanceKlass(parser, InstanceKlass::_kind_other);\n-    }\n-  } else {\n-    \/\/ reference\n+  if (parser.is_instance_ref_klass()) {\n+    \/\/ java.lang.ref.Reference\n@@ -457,0 +455,12 @@\n+  } else if (class_name == vmSymbols::java_lang_Class()) {\n+    \/\/ mirror - java.lang.Class\n+    ik = new (loader_data, size, THREAD) InstanceMirrorKlass(parser);\n+  } else if (is_stack_chunk_class(class_name, loader_data)) {\n+    \/\/ stack chunk\n+    ik = new (loader_data, size, THREAD) InstanceStackChunkKlass(parser);\n+  } else if (is_class_loader(class_name, parser)) {\n+    \/\/ class loader - java.lang.ClassLoader\n+    ik = new (loader_data, size, THREAD) InstanceClassLoaderKlass(parser);\n+  } else {\n+    \/\/ normal\n+    ik = new (loader_data, size, THREAD) InstanceKlass(parser);\n@@ -462,1 +472,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -471,1 +481,1 @@\n-  if (m != NULL) {\n+  if (m != nullptr) {\n@@ -485,1 +495,1 @@\n-  assert(default_vtable_indices() == NULL, \"only create once\");\n+  assert(default_vtable_indices() == nullptr, \"only create once\");\n@@ -490,6 +500,10 @@\n-InstanceKlass::InstanceKlass(const ClassFileParser& parser, unsigned kind, KlassID id) :\n-  Klass(id),\n-  _nest_members(NULL),\n-  _nest_host(NULL),\n-  _permitted_subclasses(NULL),\n-  _record_components(NULL),\n+static Monitor* create_init_monitor(const char* name) {\n+  return new Monitor(Mutex::safepoint, name);\n+}\n+\n+InstanceKlass::InstanceKlass(const ClassFileParser& parser, KlassKind kind, ReferenceType reference_type) :\n+  Klass(kind),\n+  _nest_members(nullptr),\n+  _nest_host(nullptr),\n+  _permitted_subclasses(nullptr),\n+  _record_components(nullptr),\n@@ -501,2 +515,3 @@\n-  _reference_type(parser.reference_type()),\n-  _init_thread(NULL)\n+  _reference_type(reference_type),\n+  _init_monitor(create_init_monitor(\"InstanceKlassInitMonitor_lock\")),\n+  _init_thread(nullptr)\n@@ -505,1 +520,0 @@\n-  set_kind(kind);\n@@ -511,1 +525,1 @@\n-  assert(NULL == _methods, \"underlying memory not zeroed?\");\n+  assert(nullptr == _methods, \"underlying memory not zeroed?\");\n@@ -514,6 +528,0 @@\n-\n-  \/\/ Set biased locking bit for all instances of this class; it will be\n-  \/\/ cleared if revocation occurs too often for this type\n-  if (UseBiasedLocking && BiasedLocking::enabled()) {\n-    set_prototype_header(markWord::biased_locking_prototype());\n-  }\n@@ -524,1 +532,1 @@\n-  if (methods != NULL && methods != Universe::the_empty_method_array() &&\n+  if (methods != nullptr && methods != Universe::the_empty_method_array() &&\n@@ -528,1 +536,1 @@\n-      if (method == NULL) continue;  \/\/ maybe null if error processing\n+      if (method == nullptr) continue;  \/\/ maybe null if error processing\n@@ -547,1 +555,1 @@\n-    Array<InstanceKlass*>* sti = (super_klass == NULL) ? NULL :\n+    Array<InstanceKlass*>* sti = (super_klass == nullptr) ? nullptr :\n@@ -549,1 +557,1 @@\n-    if (ti != sti && ti != NULL && !ti->is_shared()) {\n+    if (ti != sti && ti != nullptr && !ti->is_shared()) {\n@@ -556,1 +564,1 @@\n-      local_interfaces != NULL && !local_interfaces->is_shared()) {\n+      local_interfaces != nullptr && !local_interfaces->is_shared()) {\n@@ -563,1 +571,1 @@\n-  if (record_components != NULL && !record_components->is_shared()) {\n+  if (record_components != nullptr && !record_components->is_shared()) {\n@@ -575,3 +583,2 @@\n-\n-  if (java_mirror() != NULL) {\n-    java_lang_Class::set_klass(java_mirror(), NULL);\n+  if (java_mirror() != nullptr) {\n+    java_lang_Class::set_klass(java_mirror(), nullptr);\n@@ -591,1 +598,1 @@\n-  assert(array_klasses() == NULL, \"array classes shouldn't be created for this class yet\");\n+  assert(array_klasses() == nullptr, \"array classes shouldn't be created for this class yet\");\n@@ -595,1 +602,4 @@\n-  release_C_heap_structures_internal();\n+  \/\/ Can't release the constant pool or MethodData C heap data here because the constant\n+  \/\/ pool can be deallocated separately from the InstanceKlass for default methods and\n+  \/\/ redefine classes.  MethodData can also be released separately.\n+  release_C_heap_structures(\/* release_sub_metadata *\/ false);\n@@ -598,1 +608,1 @@\n-  set_methods(NULL);\n+  set_methods(nullptr);\n@@ -601,1 +611,1 @@\n-  set_record_components(NULL);\n+  set_record_components(nullptr);\n@@ -603,1 +613,1 @@\n-  if (method_ordering() != NULL &&\n+  if (method_ordering() != nullptr &&\n@@ -608,1 +618,1 @@\n-  set_method_ordering(NULL);\n+  set_method_ordering(nullptr);\n@@ -611,1 +621,1 @@\n-  if (default_methods() != NULL &&\n+  if (default_methods() != nullptr &&\n@@ -617,1 +627,1 @@\n-  set_default_methods(NULL);\n+  set_default_methods(nullptr);\n@@ -620,1 +630,1 @@\n-  if (default_vtable_indices() != NULL &&\n+  if (default_vtable_indices() != nullptr &&\n@@ -624,1 +634,1 @@\n-  set_default_vtable_indices(NULL);\n+  set_default_vtable_indices(nullptr);\n@@ -630,1 +640,1 @@\n-  if (secondary_supers() != NULL &&\n+  if (secondary_supers() != nullptr &&\n@@ -637,1 +647,1 @@\n-  set_secondary_supers(NULL);\n+  set_secondary_supers(nullptr);\n@@ -640,2 +650,7 @@\n-  set_transitive_interfaces(NULL);\n-  set_local_interfaces(NULL);\n+  set_transitive_interfaces(nullptr);\n+  set_local_interfaces(nullptr);\n+\n+  if (fieldinfo_stream() != nullptr && !fieldinfo_stream()->is_shared()) {\n+    MetadataFactory::free_array<u1>(loader_data, fieldinfo_stream());\n+  }\n+  set_fieldinfo_stream(nullptr);\n@@ -643,2 +658,2 @@\n-  if (fields() != NULL && !fields()->is_shared()) {\n-    MetadataFactory::free_array<jushort>(loader_data, fields());\n+  if (fields_status() != nullptr && !fields_status()->is_shared()) {\n+    MetadataFactory::free_array<FieldStatus>(loader_data, fields_status());\n@@ -646,1 +661,1 @@\n-  set_fields(NULL, 0);\n+  set_fields_status(nullptr);\n@@ -650,1 +665,1 @@\n-  if (constants() != NULL) {\n+  if (constants() != nullptr) {\n@@ -658,1 +673,1 @@\n-    set_constants(NULL);\n+    set_constants(nullptr);\n@@ -661,1 +676,1 @@\n-  if (inner_classes() != NULL &&\n+  if (inner_classes() != nullptr &&\n@@ -666,1 +681,1 @@\n-  set_inner_classes(NULL);\n+  set_inner_classes(nullptr);\n@@ -668,1 +683,1 @@\n-  if (nest_members() != NULL &&\n+  if (nest_members() != nullptr &&\n@@ -673,1 +688,1 @@\n-  set_nest_members(NULL);\n+  set_nest_members(nullptr);\n@@ -675,1 +690,1 @@\n-  if (permitted_subclasses() != NULL &&\n+  if (permitted_subclasses() != nullptr &&\n@@ -680,1 +695,1 @@\n-  set_permitted_subclasses(NULL);\n+  set_permitted_subclasses(nullptr);\n@@ -683,1 +698,1 @@\n-  if (annotations() != NULL && !annotations()->is_shared()) {\n+  if (annotations() != nullptr && !annotations()->is_shared()) {\n@@ -686,1 +701,1 @@\n-  set_annotations(NULL);\n+  set_annotations(nullptr);\n@@ -688,2 +703,5 @@\n-  if (Arguments::is_dumping_archive()) {\n-    SystemDictionaryShared::remove_dumptime_info(this);\n+  SystemDictionaryShared::handle_class_unloading(this);\n+\n+#if INCLUDE_CDS_JAVA_HEAP\n+  if (DumpSharedSpaces) {\n+    HeapShared::remove_scratch_objects(this);\n@@ -691,0 +709,1 @@\n+#endif\n@@ -694,1 +713,1 @@\n-  return _record_components != NULL &&\n+  return _record_components != nullptr &&\n@@ -700,1 +719,1 @@\n-  return _permitted_subclasses != NULL &&\n+  return _permitted_subclasses != nullptr &&\n@@ -712,19 +731,0 @@\n-void InstanceKlass::eager_initialize(Thread *thread) {\n-  if (!EagerInitialization) return;\n-\n-  if (this->is_not_initialized()) {\n-    \/\/ abort if the the class has a class initializer\n-    if (this->class_initializer() != NULL) return;\n-\n-    \/\/ abort if it is java.lang.Object (initialization is handled in genesis)\n-    Klass* super_klass = super();\n-    if (super_klass == NULL) return;\n-\n-    \/\/ abort if the super class should be initialized\n-    if (!InstanceKlass::cast(super_klass)->is_initialized()) return;\n-\n-    \/\/ call body to expose the this pointer\n-    eager_initialize_impl();\n-  }\n-}\n-\n@@ -739,1 +739,0 @@\n-\/\/ To remove these from requires an incompatible change and CCC request.\n@@ -745,61 +744,0 @@\n-oop InstanceKlass::init_lock() const {\n-  \/\/ return the init lock from the mirror\n-  oop lock = java_lang_Class::init_lock(java_mirror());\n-  \/\/ Prevent reordering with any access of initialization state\n-  OrderAccess::loadload();\n-  assert(lock != NULL || !is_not_initialized(), \/\/ initialized or in_error state\n-         \"only fully initialized state can have a null lock\");\n-  return lock;\n-}\n-\n-\/\/ Set the initialization lock to null so the object can be GC'ed.  Any racing\n-\/\/ threads to get this lock will see a null lock and will not lock.\n-\/\/ That's okay because they all check for initialized state after getting\n-\/\/ the lock and return.\n-void InstanceKlass::fence_and_clear_init_lock() {\n-  \/\/ make sure previous stores are all done, notably the init_state.\n-  OrderAccess::storestore();\n-  java_lang_Class::clear_init_lock(java_mirror());\n-  assert(!is_not_initialized(), \"class must be initialized now\");\n-}\n-\n-void InstanceKlass::eager_initialize_impl() {\n-  EXCEPTION_MARK;\n-  HandleMark hm(THREAD);\n-  Handle h_init_lock(THREAD, init_lock());\n-  ObjectLocker ol(h_init_lock, THREAD);\n-\n-  \/\/ abort if someone beat us to the initialization\n-  if (!is_not_initialized()) return;  \/\/ note: not equivalent to is_initialized()\n-\n-  ClassState old_state = init_state();\n-  link_class_impl(THREAD);\n-  if (HAS_PENDING_EXCEPTION) {\n-    CLEAR_PENDING_EXCEPTION;\n-    \/\/ Abort if linking the class throws an exception.\n-\n-    \/\/ Use a test to avoid redundantly resetting the state if there's\n-    \/\/ no change.  Set_init_state() asserts that state changes make\n-    \/\/ progress, whereas here we might just be spinning in place.\n-    if (old_state != _init_state)\n-      set_init_state(old_state);\n-  } else {\n-    \/\/ linking successfull, mark class as initialized\n-    TSAN_RUNTIME_ONLY(\n-      \/\/ Construct a happens-before edge between the write of _init_state to\n-      \/\/ fully_initialized and the later checking if it's initialized.\n-      void* const lock_address = reinterpret_cast<void*>(\n-          java_lang_Class::init_lock_addr(java_mirror()));\n-      SharedRuntime::tsan_release(lock_address);\n-    );\n-    set_init_state(fully_initialized);\n-    fence_and_clear_init_lock();\n-    \/\/ trace\n-    if (log_is_enabled(Info, class, init)) {\n-      ResourceMark rm(THREAD);\n-      log_info(class, init)(\"[Initialized %s without side effects]\", external_name());\n-    }\n-  }\n-}\n-\n-\n@@ -818,4 +756,3 @@\n-      \/\/ fully_initialized and here.\n-      void* const lock_address = reinterpret_cast<void*>(\n-          java_lang_Class::init_lock_addr(java_mirror()));\n-      SharedRuntime::tsan_acquire(lock_address);\n+      \/\/ fully_initialized and here. This is to read\/write of natives related\n+      \/\/ to class static initializer.\n+      SharedRuntime::tsan_acquire((address)java_mirror());\n@@ -840,0 +777,20 @@\n+void InstanceKlass::check_link_state_and_wait(JavaThread* current) {\n+  MonitorLocker ml(current, _init_monitor);\n+\n+  \/\/ Another thread is linking this class, wait.\n+  while (is_being_linked() && !is_init_thread(current)) {\n+    ml.wait();\n+  }\n+\n+  \/\/ This thread is recursively linking this class, continue\n+  if (is_being_linked() && is_init_thread(current)) {\n+    return;\n+  }\n+\n+  \/\/ If this class wasn't linked already, set state to being_linked\n+  if (!is_linked()) {\n+    set_init_state(being_linked);\n+    set_init_thread(current);\n+  }\n+}\n+\n@@ -877,1 +834,1 @@\n-  if (super_klass != NULL) {\n+  if (super_klass != nullptr) {\n@@ -918,3 +875,2 @@\n-    HandleMark hm(THREAD);\n-    Handle h_init_lock(THREAD, init_lock());\n-    ObjectLocker ol(h_init_lock, jt);\n+    LockLinkState init_lock(this, jt);\n+\n@@ -928,0 +884,3 @@\n+        if (is_shared()) {\n+          assert(!verified_at_dump_time(), \"must be\");\n+        }\n@@ -959,1 +918,2 @@\n-      \/\/ 2) the class is loaded by built-in class loader but failed to add archived loader constraints\n+      \/\/ 2) the class is loaded by built-in class loader but failed to add archived loader constraints or\n+      \/\/ 3) the class was not verified during dump time\n@@ -961,1 +921,2 @@\n-      if (is_shared() && SystemDictionaryShared::check_linking_constraints(THREAD, this)) {\n+      if (is_shared() && verified_at_dump_time() &&\n+          SystemDictionaryShared::check_linking_constraints(THREAD, this)) {\n@@ -973,11 +934,1 @@\n-      if (UseVtableBasedCHA) {\n-        MutexLocker ml(THREAD, Compile_lock);\n-        set_init_state(linked);\n-\n-        \/\/ Now flush all code that assume the class is not linked.\n-        if (Universe::is_fully_initialized()) {\n-          CodeCache::flush_dependents_on(this);\n-        }\n-      } else {\n-        set_init_state(linked);\n-      }\n+      set_initialization_state_and_notify(linked, THREAD);\n@@ -1038,0 +989,56 @@\n+using InitializationErrorTable = ResourceHashtable<const InstanceKlass*, OopHandle, 107, AnyObj::C_HEAP, mtClass>;\n+static InitializationErrorTable* _initialization_error_table;\n+\n+void InstanceKlass::add_initialization_error(JavaThread* current, Handle exception) {\n+  \/\/ Create the same exception with a message indicating the thread name,\n+  \/\/ and the StackTraceElements.\n+  \/\/ If the initialization error is OOM, this might not work, but if GC kicks in\n+  \/\/ this would be still be helpful.\n+  JavaThread* THREAD = current;\n+  Handle init_error = java_lang_Throwable::create_initialization_error(current, exception);\n+  ResourceMark rm(THREAD);\n+  if (init_error.is_null()) {\n+    log_trace(class, init)(\"Initialization error is null for class %s\", external_name());\n+    return;\n+  }\n+\n+  MutexLocker ml(THREAD, ClassInitError_lock);\n+  OopHandle elem = OopHandle(Universe::vm_global(), init_error());\n+  bool created;\n+  if (_initialization_error_table == nullptr) {\n+    _initialization_error_table = new (mtClass) InitializationErrorTable();\n+  }\n+  _initialization_error_table->put_if_absent(this, elem, &created);\n+  assert(created, \"Initialization is single threaded\");\n+  log_trace(class, init)(\"Initialization error added for class %s\", external_name());\n+}\n+\n+oop InstanceKlass::get_initialization_error(JavaThread* current) {\n+  MutexLocker ml(current, ClassInitError_lock);\n+  if (_initialization_error_table == nullptr) {\n+    return nullptr;\n+  }\n+  OopHandle* h = _initialization_error_table->get(this);\n+  return (h != nullptr) ? h->resolve() : nullptr;\n+}\n+\n+\/\/ Need to remove entries for unloaded classes.\n+void InstanceKlass::clean_initialization_error_table() {\n+  struct InitErrorTableCleaner {\n+    bool do_entry(const InstanceKlass* ik, OopHandle h) {\n+      if (!ik->is_loader_alive()) {\n+        h.release(Universe::vm_global());\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+  };\n+\n+  assert_locked_or_safepoint(ClassInitError_lock);\n+  InitErrorTableCleaner cleaner;\n+  if (_initialization_error_table != nullptr) {\n+    _initialization_error_table->unlink(&cleaner);\n+  }\n+}\n+\n@@ -1048,0 +1055,1 @@\n+  bool throw_error = false;\n@@ -1054,2 +1062,1 @@\n-    Handle h_init_lock(THREAD, init_lock());\n-    ObjectLocker ol(h_init_lock, jt);\n+    MonitorLocker ml(THREAD, _init_monitor);\n@@ -1058,4 +1065,1 @@\n-    \/\/ If we were to use wait() instead of waitInterruptibly() then\n-    \/\/ we might end up throwing IE from link\/symbol resolution sites\n-    \/\/ that aren't expected to throw.  This would wreak havoc.  See 6320309.\n-    while (is_being_initialized() && !is_reentrant_initialization(jt)) {\n+    while (is_being_initialized() && !is_init_thread(jt)) {\n@@ -1064,2 +1068,2 @@\n-      ol.wait_uninterruptibly(jt);\n-      jt->set_class_to_be_initialized(NULL);\n+      ml.wait();\n+      jt->set_class_to_be_initialized(nullptr);\n@@ -1069,1 +1073,1 @@\n-    if (is_being_initialized() && is_reentrant_initialization(jt)) {\n+    if (is_being_initialized() && is_init_thread(jt)) {\n@@ -1082,13 +1086,6 @@\n-      DTRACE_CLASSINIT_PROBE_WAIT(erroneous, -1, wait);\n-      ResourceMark rm(THREAD);\n-      const char* desc = \"Could not initialize class \";\n-      const char* className = external_name();\n-      size_t msglen = strlen(desc) + strlen(className) + 1;\n-      char* message = NEW_RESOURCE_ARRAY(char, msglen);\n-      if (NULL == message) {\n-        \/\/ Out of memory: can't create detailed error message\n-          THROW_MSG(vmSymbols::java_lang_NoClassDefFoundError(), className);\n-      } else {\n-        jio_snprintf(message, msglen, \"%s%s\", desc, className);\n-          THROW_MSG(vmSymbols::java_lang_NoClassDefFoundError(), message);\n-      }\n+      throw_error = true;\n+    } else {\n+\n+      \/\/ Step 6\n+      set_init_state(being_initialized);\n+      set_init_thread(jt);\n@@ -1096,0 +1093,1 @@\n+  }\n@@ -1097,3 +1095,14 @@\n-    \/\/ Step 6\n-    set_init_state(being_initialized);\n-    set_init_thread(jt);\n+  \/\/ Throw error outside lock\n+  if (throw_error) {\n+    DTRACE_CLASSINIT_PROBE_WAIT(erroneous, -1, wait);\n+    ResourceMark rm(THREAD);\n+    Handle cause(THREAD, get_initialization_error(THREAD));\n+\n+    stringStream ss;\n+    ss.print(\"Could not initialize class %s\", external_name());\n+    if (cause.is_null()) {\n+      THROW_MSG(vmSymbols::java_lang_NoClassDefFoundError(), ss.as_string());\n+    } else {\n+      THROW_MSG_CAUSE(vmSymbols::java_lang_NoClassDefFoundError(),\n+                      ss.as_string(), cause);\n+    }\n@@ -1107,1 +1116,1 @@\n-    if (super_klass != NULL && super_klass->should_be_initialized()) {\n+    if (super_klass != nullptr && super_klass->should_be_initialized()) {\n@@ -1124,0 +1133,1 @@\n+        add_initialization_error(THREAD, e);\n@@ -1137,1 +1147,1 @@\n-    if (class_initializer() != NULL) {\n+    if (class_initializer() != nullptr) {\n@@ -1158,4 +1168,2 @@\n-    set_initialization_state_and_notify(fully_initialized, CHECK);\n-    {\n-      debug_only(vtable().verify(tty, true);)\n-    }\n+    set_initialization_state_and_notify(fully_initialized, THREAD);\n+    debug_only(vtable().verify(tty, true);)\n@@ -1172,0 +1180,1 @@\n+      add_initialization_error(THREAD, e);\n@@ -1192,15 +1201,25 @@\n-void InstanceKlass::set_initialization_state_and_notify(ClassState state, TRAPS) {\n-  Handle h_init_lock(THREAD, init_lock());\n-  if (h_init_lock() != NULL) {\n-    ObjectLocker ol(h_init_lock, THREAD);\n-    TSAN_RUNTIME_ONLY(\n-      \/\/ Construct a happens-before edge between the write of _init_state to\n-      \/\/ fully_initialized and the later checking if it's initialized.\n-      void* const lock_address = reinterpret_cast<void*>(\n-          java_lang_Class::init_lock_addr(java_mirror()));\n-      SharedRuntime::tsan_release(lock_address);\n-    );\n-    set_init_thread(NULL); \/\/ reset _init_thread before changing _init_state\n-    set_init_state(state);\n-    fence_and_clear_init_lock();\n-    ol.notify_all(CHECK);\n+void InstanceKlass::set_initialization_state_and_notify(ClassState state, JavaThread* current) {\n+  MonitorLocker ml(current, _init_monitor);\n+\n+  if (state == fully_initialized) {\n+        TSAN_RUNTIME_ONLY(\n+        \/\/ Construct a happens-before edge between the write of _init_state to\n+        \/\/ fully_initialized and the later checking if it's initialized.\n+        SharedRuntime::tsan_release((address)java_mirror());\n+      );\n+  }\n+\n+  if (state == linked && UseVtableBasedCHA && Universe::is_fully_initialized()) {\n+    DeoptimizationScope deopt_scope;\n+    {\n+      \/\/ Now mark all code that assumes the class is not linked.\n+      \/\/ Set state under the Compile_lock also.\n+      MutexLocker ml(current, Compile_lock);\n+\n+      set_init_thread(nullptr); \/\/ reset _init_thread before changing _init_state\n+      set_init_state(state);\n+\n+      CodeCache::mark_dependents_on(&deopt_scope, this);\n+    }\n+    \/\/ Perform the deopt handshake outside Compile_lock.\n+    deopt_scope.deoptimize_marked();\n@@ -1208,2 +1227,1 @@\n-    assert(h_init_lock() != NULL, \"The initialization state should never be set twice\");\n-    set_init_thread(NULL); \/\/ reset _init_thread before changing _init_state\n+    set_init_thread(nullptr); \/\/ reset _init_thread before changing _init_state\n@@ -1212,0 +1230,41 @@\n+  ml.notify_all();\n+}\n+\n+\/\/ Update hierarchy. This is done before the new klass has been added to the SystemDictionary. The Compile_lock\n+\/\/ is grabbed, to ensure that the compiler is not using the class hierarchy.\n+void InstanceKlass::add_to_hierarchy(JavaThread* current) {\n+  assert(!SafepointSynchronize::is_at_safepoint(), \"must NOT be at safepoint\");\n+\n+  \/\/ In case we are not using CHA based vtables we need to make sure the loaded\n+  \/\/ deopt is completed before anyone links this class.\n+  \/\/ Linking is done with _init_monitor held, by loading and deopting with it\n+  \/\/ held we make sure the deopt is completed before linking.\n+  if (!UseVtableBasedCHA) {\n+    init_monitor()->lock();\n+  }\n+\n+  DeoptimizationScope deopt_scope;\n+  {\n+    MutexLocker ml(current, Compile_lock);\n+\n+    set_init_state(InstanceKlass::loaded);\n+    \/\/ make sure init_state store is already done.\n+    \/\/ The compiler reads the hierarchy outside of the Compile_lock.\n+    \/\/ Access ordering is used to add to hierarchy.\n+\n+    \/\/ Link into hierarchy.\n+    append_to_sibling_list();                    \/\/ add to superklass\/sibling list\n+    process_interfaces();                        \/\/ handle all \"implements\" declarations\n+\n+    \/\/ Now mark all code that depended on old class hierarchy.\n+    \/\/ Note: must be done *after* linking k into the hierarchy (was bug 12\/9\/97)\n+    if (Universe::is_fully_initialized()) {\n+      CodeCache::mark_dependents_on(&deopt_scope, this);\n+    }\n+  }\n+  \/\/ Perform the deopt handshake outside Compile_lock.\n+  deopt_scope.deoptimize_marked();\n+\n+  if (!UseVtableBasedCHA) {\n+    init_monitor()->unlock();\n+  }\n@@ -1216,2 +1275,2 @@\n-  if (ik == NULL) {\n-    return NULL;\n+  if (ik == nullptr) {\n+    return nullptr;\n@@ -1221,2 +1280,2 @@\n-    if (ikls != NULL && !ikls->is_loader_alive()) {\n-      return NULL;  \/\/ don't return unloaded class\n+    if (ikls != nullptr && !ikls->is_loader_alive()) {\n+      return nullptr;  \/\/ don't return unloaded class\n@@ -1234,2 +1293,2 @@\n-  assert(addr != NULL, \"null addr\");\n-  if (addr != NULL) {\n+  assert(addr != nullptr, \"null addr\");\n+  if (addr != nullptr) {\n@@ -1242,1 +1301,1 @@\n-  if (ik == NULL) {\n+  if (ik == nullptr) {\n@@ -1255,1 +1314,1 @@\n-\/\/   NULL                  - no implementor\n+\/\/   null                  - no implementor\n@@ -1273,1 +1332,1 @@\n-  if (super_ik != NULL && super_ik->implements_interface(this))\n+  if (super_ik != nullptr && super_ik->implements_interface(this))\n@@ -1280,1 +1339,1 @@\n-  if (iklass == NULL) {\n+  if (iklass == nullptr) {\n@@ -1296,1 +1355,1 @@\n-    set_implementor(NULL);\n+    set_implementor(nullptr);\n@@ -1326,1 +1385,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1334,1 +1393,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1371,1 +1430,1 @@\n-  int size = objArrayOopDesc::object_size(length);\n+  size_t size = objArrayOopDesc::object_size(length);\n@@ -1382,1 +1441,1 @@\n-    tty->print_cr(\" (\" INTPTR_FORMAT \") as finalizable\", p2i(i));\n+    tty->print_cr(\" (\" PTR_FORMAT \") as finalizable\", p2i(i));\n@@ -1388,1 +1447,1 @@\n-  methodHandle mh (THREAD, Universe::finalizer_register_method());\n+  methodHandle mh(THREAD, Universe::finalizer_register_method());\n@@ -1390,0 +1449,1 @@\n+  MANAGEMENT_ONLY(FinalizerService::on_register(h_i(), THREAD);)\n@@ -1395,1 +1455,1 @@\n-  int size = size_helper();  \/\/ Query before forming handle.\n+  size_t size = size_helper();  \/\/ Query before forming handle.\n@@ -1406,0 +1466,12 @@\n+instanceOop InstanceKlass::allocate_instance(oop java_class, TRAPS) {\n+  Klass* k = java_lang_Class::as_Klass(java_class);\n+  if (k == nullptr) {\n+    ResourceMark rm(THREAD);\n+    THROW_(vmSymbols::java_lang_InstantiationException(), nullptr);\n+  }\n+  InstanceKlass* ik = cast(k);\n+  ik->check_valid_for_instantiation(false, CHECK_NULL);\n+  ik->initialize(CHECK_NULL);\n+  return ik->allocate_instance(THREAD);\n+}\n+\n@@ -1425,1 +1497,1 @@\n-  if (array_klasses_acquire() == NULL) {\n+  if (array_klasses_acquire() == nullptr) {\n@@ -1433,1 +1505,1 @@\n-      if (array_klasses() == NULL) {\n+      if (array_klasses() == nullptr) {\n@@ -1448,2 +1520,2 @@\n-  if (oak == NULL) {\n-    return NULL;\n+  if (oak == nullptr) {\n+    return nullptr;\n@@ -1468,1 +1540,1 @@\n-  if (clinit != NULL && clinit->has_valid_initializer_flags()) {\n+  if (clinit != nullptr && clinit->has_valid_initializer_flags()) {\n@@ -1471,1 +1543,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1477,1 +1549,1 @@\n-       (ReplaySuppressInitializers >= 2 && class_loader() != NULL))) {\n+       (ReplaySuppressInitializers >= 2 && class_loader() != nullptr))) {\n@@ -1482,0 +1554,11 @@\n+#if INCLUDE_CDS\n+  \/\/ This is needed to ensure the consistency of the archived heap objects.\n+  if (has_archived_enum_objs()) {\n+    assert(is_shared(), \"must be\");\n+    bool initialized = HeapShared::initialize_enum_klass(this, CHECK);\n+    if (initialized) {\n+      return;\n+    }\n+  }\n+#endif\n+\n@@ -1490,1 +1573,1 @@\n-    ls.print_cr(\"%s (\" INTPTR_FORMAT \")\", h_method() == NULL ? \"(no method)\" : \"\", p2i(this));\n+    ls.print_cr(\"%s (\" PTR_FORMAT \")\", h_method() == nullptr ? \"(no method)\" : \"\", p2i(this));\n@@ -1492,1 +1575,1 @@\n-  if (h_method() != NULL) {\n+  if (h_method() != nullptr) {\n@@ -1505,1 +1588,1 @@\n-  if (oop_map_cache == NULL) {\n+  if (oop_map_cache == nullptr) {\n@@ -1508,1 +1591,1 @@\n-    if ((oop_map_cache = _oop_map_cache) == NULL) {\n+    if ((oop_map_cache = _oop_map_cache) == nullptr) {\n@@ -1523,0 +1606,10 @@\n+FieldInfo InstanceKlass::field(int index) const {\n+  for (AllFieldStream fs(this); !fs.done(); fs.next()) {\n+    if (fs.index() == index) {\n+      return fs.to_FieldInfo();\n+    }\n+  }\n+  fatal(\"Field not found\");\n+  return FieldInfo();\n+}\n+\n@@ -1548,1 +1641,1 @@\n-    if (intf2 != NULL) return intf2;\n+    if (intf2 != nullptr) return intf2;\n@@ -1551,1 +1644,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1563,1 +1656,1 @@\n-    if (intf != NULL) return intf;\n+    if (intf != nullptr) return intf;\n@@ -1567,1 +1660,1 @@\n-    if (supr != NULL) return InstanceKlass::cast(supr)->find_field(name, sig, fd);\n+    if (supr != nullptr) return InstanceKlass::cast(supr)->find_field(name, sig, fd);\n@@ -1570,1 +1663,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1583,1 +1676,1 @@\n-    if (intf != NULL) return intf;\n+    if (intf != nullptr) return intf;\n@@ -1587,1 +1680,1 @@\n-    if (supr != NULL) return InstanceKlass::cast(supr)->find_field(name, sig, is_static, fd);\n+    if (supr != nullptr) return InstanceKlass::cast(supr)->find_field(name, sig, is_static, fd);\n@@ -1590,1 +1683,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1607,1 +1700,1 @@\n-  while (klass != NULL) {\n+  while (klass != nullptr) {\n@@ -1620,1 +1713,2 @@\n-  if (!is_loaded()) {\n+  \/\/ Redefined scratch classes are on the list and need to be cleaned\n+  if (!is_loaded() && !is_scratch_class()) {\n@@ -1652,5 +1746,0 @@\n-\n-static int compare_fields_by_offset(int* a, int* b) {\n-  return a[0] - b[0];\n-}\n-\n@@ -1659,1 +1748,1 @@\n-  if (super != NULL) {\n+  if (super != nullptr) {\n@@ -1664,3 +1753,0 @@\n-  \/\/ In DebugInfo nonstatic fields are sorted by offset.\n-  int* fields_sorted = NEW_C_HEAP_ARRAY(int, 2*(length+1), mtClass);\n-  int j = 0;\n@@ -1670,12 +1756,0 @@\n-      fields_sorted[j + 0] = fd.offset();\n-      fields_sorted[j + 1] = i;\n-      j += 2;\n-    }\n-  }\n-  if (j > 0) {\n-    length = j;\n-    \/\/ _sort_Fn is defined in growableArray.hpp.\n-    qsort(fields_sorted, length\/2, 2*sizeof(int), (_sort_Fn)compare_fields_by_offset);\n-    for (int i = 0; i < length; i += 2) {\n-      fd.reinitialize(this, fields_sorted[i + 1]);\n-      assert(!fd.is_static() && fd.offset() == fields_sorted[i], \"only nonstatic fields\");\n@@ -1685,1 +1759,0 @@\n-  FREE_C_HEAP_ARRAY(int, fields_sorted);\n@@ -1688,4 +1761,3 @@\n-\n-void InstanceKlass::array_klasses_do(void f(Klass* k, TRAPS), TRAPS) {\n-  if (array_klasses() != NULL)\n-    array_klasses()->array_klasses_do(f, THREAD);\n+\/\/ first in Pair is offset, second is index.\n+static int compare_fields_by_offset(Pair<int,int>* a, Pair<int,int>* b) {\n+  return a->first - b->first;\n@@ -1694,3 +1766,29 @@\n-void InstanceKlass::array_klasses_do(void f(Klass* k)) {\n-  if (array_klasses() != NULL)\n-    array_klasses()->array_klasses_do(f);\n+void InstanceKlass::print_nonstatic_fields(FieldClosure* cl) {\n+  InstanceKlass* super = superklass();\n+  if (super != nullptr) {\n+    super->print_nonstatic_fields(cl);\n+  }\n+  ResourceMark rm;\n+  fieldDescriptor fd;\n+  \/\/ In DebugInfo nonstatic fields are sorted by offset.\n+  GrowableArray<Pair<int,int> > fields_sorted;\n+  int i = 0;\n+  for (AllFieldStream fs(this); !fs.done(); fs.next()) {\n+    if (!fs.access_flags().is_static()) {\n+      fd = fs.field_descriptor();\n+      Pair<int,int> f(fs.offset(), fs.index());\n+      fields_sorted.push(f);\n+      i++;\n+    }\n+  }\n+  if (i > 0) {\n+    int length = i;\n+    assert(length == fields_sorted.length(), \"duh\");\n+    \/\/ _sort_Fn is defined in growableArray.hpp.\n+    fields_sorted.sort(compare_fields_by_offset);\n+    for (int i = 0; i < length; i++) {\n+      fd.reinitialize(this, fields_sorted.at(i).second);\n+      assert(!fd.is_static() && fd.offset() == fields_sorted.at(i).first, \"only nonstatic fields\");\n+      cl->do_field(&fd);\n+    }\n+  }\n@@ -1796,1 +1894,1 @@\n-  assert(((meth == NULL) || !meth->is_static()),\n+  assert(((meth == nullptr) || !meth->is_static()),\n@@ -1864,1 +1962,1 @@\n-  return hit >= 0 ? methods->at(hit): NULL;\n+  return hit >= 0 ? methods->at(hit): nullptr;\n@@ -1950,1 +2048,1 @@\n-  assert(end_ptr != NULL, \"just checking\");\n+  assert(end_ptr != nullptr, \"just checking\");\n@@ -1971,1 +2069,1 @@\n-  while (klass != NULL) {\n+  while (klass != nullptr) {\n@@ -1977,1 +2075,1 @@\n-    if (method != NULL) {\n+    if (method != nullptr) {\n@@ -1983,1 +2081,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1991,1 +2089,1 @@\n-  while (klass != NULL) {\n+  while (klass != nullptr) {\n@@ -2005,2 +2103,2 @@\n-  Method* m = NULL;\n-  if (default_methods() != NULL) {\n+  Method* m = nullptr;\n+  if (default_methods() != nullptr) {\n@@ -2010,1 +2108,1 @@\n-  if (m == NULL) {\n+  if (m == nullptr) {\n@@ -2024,1 +2122,1 @@\n-  InstanceKlass *ik = NULL;\n+  InstanceKlass *ik = nullptr;\n@@ -2028,1 +2126,1 @@\n-    if (m != NULL && m->is_public() && !m->is_static() &&\n+    if (m != nullptr && m->is_public() && !m->is_static() &&\n@@ -2033,1 +2131,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -2036,11 +2134,9 @@\n-\/* jni_id_for_impl for jfieldIds only *\/\n-JNIid* InstanceKlass::jni_id_for_impl(int offset) {\n-  MutexLocker ml(JfieldIdCreation_lock);\n-  \/\/ Retry lookup after we got the lock\n-  JNIid* probe = jni_ids() == NULL ? NULL : jni_ids()->find(offset);\n-  if (probe == NULL) {\n-    \/\/ Slow case, allocate new static field identifier\n-    probe = new JNIid(this, offset, jni_ids());\n-    set_jni_ids(probe);\n-  }\n-  return probe;\n+PrintClassClosure::PrintClassClosure(outputStream* st, bool verbose)\n+  :_st(st), _verbose(verbose) {\n+  ResourceMark rm;\n+  _st->print(\"%-18s  \", \"KlassAddr\");\n+  _st->print(\"%-4s  \", \"Size\");\n+  _st->print(\"%-20s  \", \"State\");\n+  _st->print(\"%-7s  \", \"Flags\");\n+  _st->print(\"%-5s  \", \"ClassName\");\n+  _st->cr();\n@@ -2049,0 +2145,34 @@\n+void PrintClassClosure::do_klass(Klass* k)  {\n+  ResourceMark rm;\n+  \/\/ klass pointer\n+  _st->print(PTR_FORMAT \"  \", p2i(k));\n+  \/\/ klass size\n+  _st->print(\"%4d  \", k->size());\n+  \/\/ initialization state\n+  if (k->is_instance_klass()) {\n+    _st->print(\"%-20s  \",InstanceKlass::cast(k)->init_state_name());\n+  } else {\n+    _st->print(\"%-20s  \",\"\");\n+  }\n+  \/\/ misc flags(Changes should synced with ClassesDCmd::ClassesDCmd help doc)\n+  char buf[10];\n+  int i = 0;\n+  if (k->has_finalizer()) buf[i++] = 'F';\n+  if (k->is_instance_klass()) {\n+    InstanceKlass* ik = InstanceKlass::cast(k);\n+    if (ik->has_final_method()) buf[i++] = 'f';\n+    if (ik->is_rewritten()) buf[i++] = 'W';\n+    if (ik->is_contended()) buf[i++] = 'C';\n+    if (ik->has_been_redefined()) buf[i++] = 'R';\n+    if (ik->is_shared()) buf[i++] = 'S';\n+  }\n+  buf[i++] = '\\0';\n+  _st->print(\"%-7s  \", buf);\n+  \/\/ klass name\n+  _st->print(\"%-5s  \", k->external_name());\n+  \/\/ end\n+  _st->cr();\n+  if (_verbose) {\n+    k->print_on(_st);\n+  }\n+}\n@@ -2052,3 +2182,6 @@\n-  JNIid* probe = jni_ids() == NULL ? NULL : jni_ids()->find(offset);\n-  if (probe == NULL) {\n-    probe = jni_id_for_impl(offset);\n+  MutexLocker ml(JfieldIdCreation_lock);\n+  JNIid* probe = jni_ids() == nullptr ? nullptr : jni_ids()->find(offset);\n+  if (probe == nullptr) {\n+    \/\/ Allocate new static field identifier\n+    probe = new JNIid(this, offset, jni_ids());\n+    set_jni_ids(probe);\n@@ -2061,1 +2194,1 @@\n-  if (inner_class_list == NULL) {\n+  if (inner_class_list == nullptr) {\n@@ -2076,1 +2209,1 @@\n-  assert (inner_class_list != NULL, \"_inner_classes list is not set up\");\n+  assert (inner_class_list != nullptr, \"_inner_classes list is not set up\");\n@@ -2096,1 +2229,1 @@\n-  jmethodID id = NULL;\n+  jmethodID id = nullptr;\n@@ -2100,1 +2233,1 @@\n-  \/\/ transitions from NULL to non-NULL which is safe because we use\n+  \/\/ transitions from null to non-null which is safe because we use\n@@ -2111,1 +2244,1 @@\n-  \/\/ grow and we'll have transitions from non-NULL to bigger non-NULL.\n+  \/\/ grow and we'll have transitions from non-null to bigger non-null.\n@@ -2116,1 +2249,1 @@\n-  if (jmeths != NULL) {\n+  if (jmeths != nullptr) {\n@@ -2122,9 +2255,2 @@\n-      \/\/ cache can grow so we have to be more careful\n-      if (Threads::number_of_threads() == 0 ||\n-          SafepointSynchronize::is_at_safepoint()) {\n-        \/\/ we're single threaded or at a safepoint - no locking needed\n-        get_jmethod_id_length_value(jmeths, idnum, &length, &id);\n-      } else {\n-        MutexLocker ml(JmethodIdCreation_lock, Mutex::_no_safepoint_check_flag);\n-        get_jmethod_id_length_value(jmeths, idnum, &length, &id);\n-      }\n+      MutexLocker ml(JmethodIdCreation_lock, Mutex::_no_safepoint_check_flag);\n+      get_jmethod_id_length_value(jmeths, idnum, &length, &id);\n@@ -2136,3 +2262,3 @@\n-  if (jmeths == NULL ||   \/\/ no cache yet\n-      length <= idnum ||  \/\/ cache is too short\n-      id == NULL) {       \/\/ cache doesn't contain entry\n+  if (jmeths == nullptr ||   \/\/ no cache yet\n+      length <= idnum ||     \/\/ cache is too short\n+      id == nullptr) {       \/\/ cache doesn't contain entry\n@@ -2140,2 +2266,2 @@\n-    \/\/ This function can be called by the VMThread so we have to do all\n-    \/\/ things that might block on a safepoint before grabbing the lock.\n+    \/\/ This function can be called by the VMThread or GC worker threads so we\n+    \/\/ have to do all things that might block on a safepoint before grabbing the lock.\n@@ -2145,2 +2271,2 @@\n-    jmethodID  to_dealloc_id     = NULL;\n-    jmethodID* to_dealloc_jmeths = NULL;\n+    jmethodID  to_dealloc_id     = nullptr;\n+    jmethodID* to_dealloc_jmeths = nullptr;\n@@ -2149,1 +2275,1 @@\n-    jmethodID* new_jmeths = NULL;\n+    jmethodID* new_jmeths = nullptr;\n@@ -2160,18 +2286,1 @@\n-    jmethodID new_id = NULL;\n-    if (method_h->is_old() && !method_h->is_obsolete()) {\n-      \/\/ The method passed in is old (but not obsolete), we need to use the current version\n-      Method* current_method = method_with_idnum((int)idnum);\n-      assert(current_method != NULL, \"old and but not obsolete, so should exist\");\n-      new_id = Method::make_jmethod_id(class_loader_data(), current_method);\n-    } else {\n-      \/\/ It is the current version of the method or an obsolete method,\n-      \/\/ use the version passed in\n-      new_id = Method::make_jmethod_id(class_loader_data(), method_h());\n-    }\n-\n-    if (Threads::number_of_threads() == 0 ||\n-        SafepointSynchronize::is_at_safepoint()) {\n-      \/\/ we're single threaded or at a safepoint - no locking needed\n-      id = get_jmethod_id_fetch_or_update(idnum, new_id, new_jmeths,\n-                                          &to_dealloc_id, &to_dealloc_jmeths);\n-    } else {\n+    {\n@@ -2179,0 +2288,12 @@\n+      jmethodID new_id = nullptr;\n+      if (method_h->is_old() && !method_h->is_obsolete()) {\n+        \/\/ The method passed in is old (but not obsolete), we need to use the current version\n+        Method* current_method = method_with_idnum((int)idnum);\n+        assert(current_method != nullptr, \"old and but not obsolete, so should exist\");\n+        new_id = Method::make_jmethod_id(class_loader_data(), current_method);\n+      } else {\n+        \/\/ It is the current version of the method or an obsolete method,\n+        \/\/ use the version passed in\n+        new_id = Method::make_jmethod_id(class_loader_data(), method_h());\n+      }\n+\n@@ -2185,1 +2306,1 @@\n-    if (to_dealloc_jmeths != NULL) {\n+    if (to_dealloc_jmeths != nullptr) {\n@@ -2189,1 +2310,1 @@\n-    if (to_dealloc_id != NULL) {\n+    if (to_dealloc_id != nullptr) {\n@@ -2207,1 +2328,1 @@\n-    if (id == NULL) {\n+    if (id == nullptr) {\n@@ -2225,6 +2346,4 @@\n-  assert(new_id != NULL, \"sanity check\");\n-  assert(to_dealloc_id_p != NULL, \"sanity check\");\n-  assert(to_dealloc_jmeths_p != NULL, \"sanity check\");\n-  assert(Threads::number_of_threads() == 0 ||\n-         SafepointSynchronize::is_at_safepoint() ||\n-         JmethodIdCreation_lock->owned_by_self(), \"sanity check\");\n+  assert(new_id != nullptr, \"sanity check\");\n+  assert(to_dealloc_id_p != nullptr, \"sanity check\");\n+  assert(to_dealloc_jmeths_p != nullptr, \"sanity check\");\n+  assert(JmethodIdCreation_lock->owned_by_self(), \"sanity check\");\n@@ -2234,1 +2353,1 @@\n-  jmethodID  id     = NULL;\n+  jmethodID  id     = nullptr;\n@@ -2237,1 +2356,1 @@\n-  if (jmeths == NULL ||                         \/\/ no cache yet\n+  if (jmeths == nullptr ||                      \/\/ no cache yet\n@@ -2239,1 +2358,1 @@\n-    if (jmeths != NULL) {\n+    if (jmeths != nullptr) {\n@@ -2252,1 +2371,1 @@\n-  if (id == NULL) {\n+  if (id == nullptr) {\n@@ -2275,3 +2394,3 @@\n-  assert(cache != NULL, \"sanity check\");\n-  assert(length_p != NULL, \"sanity check\");\n-  assert(id_p != NULL, \"sanity check\");\n+  assert(cache != nullptr, \"sanity check\");\n+  assert(length_p != nullptr, \"sanity check\");\n+  assert(id_p != nullptr, \"sanity check\");\n@@ -2282,1 +2401,1 @@\n-    *id_p = NULL;\n+    *id_p = nullptr;\n@@ -2289,1 +2408,1 @@\n-\/\/ Lookup a jmethodID, NULL if not found.  Do no blocking, no allocations, no handles\n+\/\/ Lookup a jmethodID, null if not found.  Do no blocking, no allocations, no handles\n@@ -2294,2 +2413,2 @@\n-  jmethodID id = NULL;\n-  if (jmeths != NULL &&                         \/\/ If there is a cache\n+  jmethodID id = nullptr;\n+  if (jmeths != nullptr &&                      \/\/ If there is a cache\n@@ -2297,1 +2416,1 @@\n-    id = jmeths[idnum+1];                       \/\/ Look up the id (may be NULL)\n+    id = jmeths[idnum+1];                       \/\/ Look up the id (may be null)\n@@ -2307,2 +2426,2 @@\n-int InstanceKlass::mark_dependent_nmethods(KlassDepChange& changes) {\n-  return dependencies().mark_dependent_nmethods(changes);\n+void InstanceKlass::mark_dependent_nmethods(DeoptimizationScope* deopt_scope, KlassDepChange& changes) {\n+  dependencies().mark_dependent_nmethods(deopt_scope, changes);\n@@ -2315,4 +2434,0 @@\n-void InstanceKlass::remove_dependent_nmethod(nmethod* nm) {\n-  dependencies().remove_dependent_nmethod(nm);\n-}\n-\n@@ -2345,2 +2460,2 @@\n-      if (impl != NULL && !impl->is_loader_alive()) {\n-        \/\/ NULL this field, might be an unloaded instance klass or NULL\n+      if (impl != nullptr && !impl->is_loader_alive()) {\n+        \/\/ null this field, might be an unloaded instance klass or null\n@@ -2348,1 +2463,1 @@\n-        if (Atomic::cmpxchg(iklass, impl, (InstanceKlass*)NULL) == impl) {\n+        if (Atomic::cmpxchg(iklass, impl, (InstanceKlass*)nullptr) == impl) {\n@@ -2366,2 +2481,2 @@\n-    if (mdo != NULL) {\n-      MutexLocker ml(SafepointSynchronize::is_at_safepoint() ? NULL : mdo->extra_data_lock());\n+    if (mdo != nullptr) {\n+      MutexLocker ml(SafepointSynchronize::is_at_safepoint() ? nullptr : mdo->extra_data_lock());\n@@ -2392,1 +2507,15 @@\n-  it->push(&_methods);\n+#if INCLUDE_CDS\n+  \/\/ For \"old\" classes with methods containing the jsr bytecode, the _methods array will\n+  \/\/ be rewritten during runtime (see Rewriter::rewrite_jsrs()). So setting the _methods to\n+  \/\/ be writable. The length check on the _methods is necessary because classes which\n+  \/\/ don't have any methods share the Universe::_the_empty_method_array which is in the RO region.\n+  if (_methods != nullptr && _methods->length() > 0 &&\n+      !can_be_verified_at_dumptime() && methods_contain_jsr_bytecode()) {\n+    \/\/ To handle jsr bytecode, new Method* maybe stored into _methods\n+    it->push(&_methods, MetaspaceClosure::_writable);\n+  } else {\n+#endif\n+    it->push(&_methods);\n+#if INCLUDE_CDS\n+  }\n+#endif\n@@ -2402,1 +2531,4 @@\n-  it->push(&_fields);\n+\n+  it->push(&_fieldinfo_stream);\n+  \/\/ _fields_status might be written into by Rewriter::scan_method() -> fd.set_has_initialized_final_update()\n+  it->push(&_fields_status, MetaspaceClosure::_writable);\n@@ -2407,1 +2539,3 @@\n-    int nof_interfaces = (method_table_offset_in_words - itable_offset_in_words())\n+    int itable_offset_in_words = (int)(start_of_itable() - (intptr_t*)this);\n+\n+    int nof_interfaces = (method_table_offset_in_words - itable_offset_in_words)\n@@ -2411,1 +2545,1 @@\n-      if (ioe->interface_klass() != NULL) {\n+      if (ioe->interface_klass() != nullptr) {\n@@ -2427,0 +2561,1 @@\n+#if INCLUDE_CDS\n@@ -2429,1 +2564,2 @@\n-  if (can_be_verified_at_dumptime()) {\n+  if (is_linked()) {\n+    assert(can_be_verified_at_dumptime(), \"must be\");\n@@ -2446,1 +2582,1 @@\n-  \/\/ being added to class hierarchy (see SystemDictionary:::add_to_hierarchy()).\n+  \/\/ being added to class hierarchy (see InstanceKlass:::add_to_hierarchy()).\n@@ -2462,1 +2598,1 @@\n-  if (array_klasses() != NULL) {\n+  if (array_klasses() != nullptr) {\n@@ -2466,4 +2602,4 @@\n-  \/\/ These are not allocated from metaspace. They are safe to set to NULL.\n-  _source_debug_extension = NULL;\n-  _dep_context = NULL;\n-  _osr_nmethods_head = NULL;\n+  \/\/ These are not allocated from metaspace. They are safe to set to null.\n+  _source_debug_extension = nullptr;\n+  _dep_context = nullptr;\n+  _osr_nmethods_head = nullptr;\n@@ -2471,4 +2607,4 @@\n-  _breakpoints = NULL;\n-  _previous_versions = NULL;\n-  _cached_class_file = NULL;\n-  _jvmti_cached_class_field_map = NULL;\n+  _breakpoints = nullptr;\n+  _previous_versions = nullptr;\n+  _cached_class_file = nullptr;\n+  _jvmti_cached_class_field_map = nullptr;\n@@ -2477,4 +2613,4 @@\n-  _init_thread = NULL;\n-  _methods_jmethod_ids = NULL;\n-  _jni_ids = NULL;\n-  _oop_map_cache = NULL;\n+  _init_thread = nullptr;\n+  _methods_jmethod_ids = nullptr;\n+  _jni_ids = nullptr;\n+  _oop_map_cache = nullptr;\n@@ -2482,1 +2618,1 @@\n-  _nest_host = NULL;\n+  _nest_host = nullptr;\n@@ -2485,0 +2621,13 @@\n+  _init_monitor = nullptr;\n+\n+  remove_unshareable_flags();\n+}\n+\n+void InstanceKlass::remove_unshareable_flags() {\n+  \/\/ clear all the flags\/stats that shouldn't be in the archived version\n+  assert(!is_scratch_class(), \"must be\");\n+  assert(!has_been_redefined(), \"must be\");\n+#if INCLUDE_JVMTI\n+  set_is_being_redefined(false);\n+#endif\n+  set_has_resolved_methods(false);\n@@ -2491,1 +2640,1 @@\n-  if (array_klasses() != NULL) {\n+  if (array_klasses() != nullptr) {\n@@ -2498,1 +2647,1 @@\n-  _package_entry = NULL;\n+  _package_entry = nullptr;\n@@ -2501,1 +2650,1 @@\n-    _package_entry = NULL;\n+    _package_entry = nullptr;\n@@ -2504,1 +2653,1 @@\n-      _package_entry = NULL;\n+      _package_entry = nullptr;\n@@ -2508,1 +2657,1 @@\n-      _package_entry = NULL;\n+      _package_entry = nullptr;\n@@ -2517,0 +2666,10 @@\n+void InstanceKlass::compute_has_loops_flag_for_methods() {\n+  Array<Method*>* methods = this->methods();\n+  for (int index = 0; index < methods->length(); ++index) {\n+    Method* m = methods->at(index);\n+    if (!m->is_overpass()) { \/\/ work around JDK-8305771\n+      m->compute_has_loops_flag();\n+    }\n+  }\n+}\n+\n@@ -2519,1 +2678,1 @@\n-  \/\/ SystemDictionary::add_to_hierarchy() sets the init_state to loaded\n+  \/\/ InstanceKlass::add_to_hierarchy() sets the init_state to loaded\n@@ -2551,1 +2710,4 @@\n-  if (array_klasses() != NULL) {\n+  if (array_klasses() != nullptr) {\n+    \/\/ To get a consistent list of classes we need MultiArray_lock to ensure\n+    \/\/ array classes aren't observed while they are being restored.\n+     MutexLocker ml(MultiArray_lock);\n@@ -2557,5 +2719,0 @@\n-  \/\/ Initialize current biased locking state.\n-  if (UseBiasedLocking && BiasedLocking::enabled()) {\n-    set_prototype_header(markWord::biased_locking_prototype());\n-  }\n-\n@@ -2565,1 +2722,3 @@\n-    set_prototype_header(markWord::prototype());\n+\n+  \/\/ restore the monitor\n+  _init_monitor = create_init_monitor(\"InstanceKlassInitMonitorRestored_lock\");\n@@ -2575,0 +2734,5 @@\n+  if (MetaspaceShared::is_in_shared_metaspace(this)) {\n+    \/\/ This is a class that was dumped into the base archive, so we know\n+    \/\/ it was verified at dump time.\n+    return true;\n+  }\n@@ -2578,1 +2742,1 @@\n-  if (java_super() != NULL && !java_super()->can_be_verified_at_dumptime()) {\n+  if (java_super() != nullptr && !java_super()->can_be_verified_at_dumptime()) {\n@@ -2591,27 +2755,11 @@\n-void InstanceKlass::set_shared_class_loader_type(s2 loader_type) {\n-  switch (loader_type) {\n-  case ClassLoader::BOOT_LOADER:\n-    _misc_flags |= _misc_is_shared_boot_class;\n-    break;\n-  case ClassLoader::PLATFORM_LOADER:\n-    _misc_flags |= _misc_is_shared_platform_class;\n-    break;\n-  case ClassLoader::APP_LOADER:\n-    _misc_flags |= _misc_is_shared_app_class;\n-    break;\n-  default:\n-    ShouldNotReachHere();\n-    break;\n-  }\n-}\n-\n-void InstanceKlass::assign_class_loader_type() {\n-  ClassLoaderData *cld = class_loader_data();\n-  if (cld->is_boot_class_loader_data()) {\n-    set_shared_class_loader_type(ClassLoader::BOOT_LOADER);\n-  }\n-  else if (cld->is_platform_class_loader_data()) {\n-    set_shared_class_loader_type(ClassLoader::PLATFORM_LOADER);\n-  }\n-  else if (cld->is_system_class_loader_data()) {\n-    set_shared_class_loader_type(ClassLoader::APP_LOADER);\n+bool InstanceKlass::methods_contain_jsr_bytecode() const {\n+  Thread* thread = Thread::current();\n+  for (int i = 0; i < _methods->length(); i++) {\n+    methodHandle m(thread, _methods->at(i));\n+    BytecodeStream bcs(m);\n+    while (!bcs.is_last_bytecode()) {\n+      Bytecodes::Code opcode = bcs.next();\n+      if (opcode == Bytecodes::_jsr || opcode == Bytecodes::_jsr_w) {\n+        return true;\n+      }\n+    }\n@@ -2619,0 +2767,1 @@\n+  return false;\n@@ -2620,0 +2769,1 @@\n+#endif \/\/ INCLUDE_CDS\n@@ -2639,3 +2789,1 @@\n-  if (Arguments::is_dumping_archive()) {\n-    SystemDictionaryShared::remove_dumptime_info(ik);\n-  }\n+  SystemDictionaryShared::handle_class_unloading(ik);\n@@ -2645,1 +2793,1 @@\n-    log_info(class, unload)(\"unloading class %s \" INTPTR_FORMAT, ik->external_name(), p2i(ik));\n+    log_info(class, unload)(\"unloading class %s \" PTR_FORMAT, ik->external_name(), p2i(ik));\n@@ -2651,1 +2799,1 @@\n-  assert(ik != NULL, \"invariant\");\n+  assert(ik != nullptr, \"invariant\");\n@@ -2663,2 +2811,2 @@\n-void InstanceKlass::release_C_heap_structures() {\n-\n+\/\/ Called also by InstanceKlass::deallocate_contents, with false for release_sub_metadata.\n+void InstanceKlass::release_C_heap_structures(bool release_sub_metadata) {\n@@ -2666,2 +2814,1 @@\n-  release_C_heap_structures_internal();\n-  constants()->release_C_heap_structures();\n+  Klass::release_C_heap_structures();\n@@ -2670,5 +2817,3 @@\n-  methods_do(method_release_C_heap_structures);\n-}\n-\n-void InstanceKlass::release_C_heap_structures_internal() {\n-  Klass::release_C_heap_structures();\n+  if (release_sub_metadata) {\n+    methods_do(method_release_C_heap_structures);\n+  }\n@@ -2676,3 +2821,2 @@\n-  \/\/ Can't release the constant pool here because the constant pool can be\n-  \/\/ deallocated separately from the InstanceKlass for default methods and\n-  \/\/ redefine classes.\n+  \/\/ Destroy the init_monitor\n+  delete _init_monitor;\n@@ -2681,1 +2825,1 @@\n-  if (_oop_map_cache != NULL) {\n+  if (_oop_map_cache != nullptr) {\n@@ -2683,1 +2827,1 @@\n-    _oop_map_cache = NULL;\n+    _oop_map_cache = nullptr;\n@@ -2688,1 +2832,1 @@\n-  set_jni_ids(NULL);\n+  set_jni_ids(nullptr);\n@@ -2691,2 +2835,2 @@\n-  if (jmeths != (jmethodID*)NULL) {\n-    release_set_methods_jmethod_ids(NULL);\n+  if (jmeths != (jmethodID*)nullptr) {\n+    release_set_methods_jmethod_ids(nullptr);\n@@ -2696,1 +2840,1 @@\n-  assert(_dep_context == NULL,\n+  assert(_dep_context == nullptr,\n@@ -2707,1 +2851,1 @@\n-  if (_cached_class_file != NULL) {\n+  if (_cached_class_file != nullptr) {\n@@ -2709,1 +2853,1 @@\n-    _cached_class_file = NULL;\n+    _cached_class_file = nullptr;\n@@ -2714,0 +2858,4 @@\n+\n+  if (release_sub_metadata) {\n+    constants()->release_C_heap_structures();\n+  }\n@@ -2717,2 +2865,2 @@\n-  if (array == NULL) {\n-    _source_debug_extension = NULL;\n+  if (array == nullptr) {\n+    _source_debug_extension = nullptr;\n@@ -2735,2 +2883,0 @@\n-  int hash_len = 0;\n-  char hash_buf[40];\n@@ -2742,1 +2888,1 @@\n-  char* dest = NEW_RESOURCE_ARRAY(char, src_length + hash_len + 3);\n+  char* dest = NEW_RESOURCE_ARRAY(char, src_length + 3);\n@@ -2762,6 +2908,1 @@\n-  \/\/ If we have a hash, append it\n-  for (int hash_index = 0; hash_index < hash_len; ) {\n-    dest[dest_index++] = hash_buf[hash_index++];\n-  }\n-\n-  \/\/ Add the semicolon and the NULL\n+  \/\/ Add the semicolon and the null\n@@ -2810,1 +2951,1 @@\n-  if (is_shared() && _package_entry != NULL) {\n+  if (is_shared() && _package_entry != nullptr) {\n@@ -2816,1 +2957,1 @@\n-      _package_entry = NULL;\n+      _package_entry = nullptr;\n@@ -2823,1 +2964,1 @@\n-      (pkg_entry != NULL) ? NULL : ClassLoader::package_from_class_name(name());\n+      (pkg_entry != nullptr) ? nullptr : ClassLoader::package_from_class_name(name());\n@@ -2826,1 +2967,1 @@\n-  if (pkg_entry != NULL) {\n+  if (pkg_entry != nullptr) {\n@@ -2832,1 +2973,1 @@\n-  if (pkg_name != NULL && loader_data != NULL) {\n+  if (pkg_name != nullptr && loader_data != nullptr) {\n@@ -2835,1 +2976,1 @@\n-    _package_entry = pkg_entry != NULL ? pkg_entry : loader_data->packages()->lookup_only(pkg_name);\n+    _package_entry = pkg_entry != nullptr ? pkg_entry : loader_data->packages()->lookup_only(pkg_name);\n@@ -2840,1 +2981,1 @@\n-    if (_package_entry == NULL) {\n+    if (_package_entry == nullptr) {\n@@ -2847,2 +2988,2 @@\n-        assert(ModuleEntryTable::javabase_moduleEntry() != NULL, JAVA_BASE_NAME \" module is NULL\");\n-        _package_entry = loader_data->packages()->lookup(pkg_name, ModuleEntryTable::javabase_moduleEntry());\n+        assert(ModuleEntryTable::javabase_moduleEntry() != nullptr, JAVA_BASE_NAME \" module is null\");\n+        _package_entry = loader_data->packages()->create_entry_if_absent(pkg_name, ModuleEntryTable::javabase_moduleEntry());\n@@ -2850,3 +2991,2 @@\n-        assert(loader_data->unnamed_module() != NULL, \"unnamed module is NULL\");\n-        _package_entry = loader_data->packages()->lookup(pkg_name,\n-                                                         loader_data->unnamed_module());\n+        assert(loader_data->unnamed_module() != nullptr, \"unnamed module is null\");\n+        _package_entry = loader_data->packages()->create_entry_if_absent(pkg_name, loader_data->unnamed_module());\n@@ -2857,1 +2997,1 @@\n-      assert(_package_entry != NULL, \"Package entry for class %s not found, loader %s\",\n+      assert(_package_entry != nullptr, \"Package entry for class %s not found, loader %s\",\n@@ -2874,1 +3014,1 @@\n-                      (loader_data != NULL) ? loader_data->loader_name_and_id() : \"NULL\",\n+                      (loader_data != nullptr) ? loader_data->loader_name_and_id() : \"null\",\n@@ -2889,1 +3029,1 @@\n-  if (_package_entry != NULL) {\n+  if (_package_entry != nullptr) {\n@@ -2913,2 +3053,2 @@\n-    classloader2 = NULL;\n-    classpkg2 = NULL;\n+    classloader2 = nullptr;\n+    classpkg2 = nullptr;\n@@ -2947,2 +3087,2 @@\n-    \/\/ Check that package_from_class_name() returns NULL, not \"\", if there is no package.\n-    assert(other_pkg == NULL || other_pkg->utf8_length() > 0, \"package name is empty string\");\n+    \/\/ Check that package_from_class_name() returns null, not \"\", if there is no package.\n+    assert(other_pkg == nullptr || other_pkg->utf8_length() > 0, \"package name is empty string\");\n@@ -2951,1 +3091,1 @@\n-      this->package() != NULL ? this->package()->name() : NULL;\n+      this->package() != nullptr ? this->package()->name() : nullptr;\n@@ -2953,1 +3093,1 @@\n-    if (this_package_name == NULL || other_pkg == NULL) {\n+    if (this_package_name == nullptr || other_pkg == nullptr) {\n@@ -2982,1 +3122,1 @@\n-      class_name != NULL && class_name->utf8_length() >= 5) {\n+      class_name != nullptr && class_name->utf8_length() >= 5) {\n@@ -2994,1 +3134,1 @@\n-      assert(pkg_name != NULL, \"Error in parsing package name starting with 'java\/'\");\n+      assert(pkg_name != nullptr, \"Error in parsing package name starting with 'java\/'\");\n@@ -3030,1 +3170,1 @@\n-  InstanceKlass* outer_klass = NULL;\n+  InstanceKlass* outer_klass = nullptr;\n@@ -3038,0 +3178,12 @@\n+      if (!ok->is_instance_klass()) {\n+        \/\/ If the outer class is not an instance klass then it cannot have\n+        \/\/ declared any inner classes.\n+        ResourceMark rm(THREAD);\n+        Exceptions::fthrow(\n+          THREAD_AND_LOCATION,\n+          vmSymbols::java_lang_IncompatibleClassChangeError(),\n+          \"%s and %s disagree on InnerClasses attribute\",\n+          ok->external_name(),\n+          external_name());\n+        return nullptr;\n+      }\n@@ -3041,1 +3193,1 @@\n-    if (NULL == outer_klass) {\n+    if (nullptr == outer_klass) {\n@@ -3053,1 +3205,1 @@\n-  if (NULL == outer_klass) return NULL;\n+  if (nullptr == outer_klass) return nullptr;\n@@ -3107,1 +3259,1 @@\n-  if (m != NULL) {\n+  if (m != nullptr) {\n@@ -3142,1 +3294,1 @@\n-  return NULL; \/\/ offset entry not found\n+  return nullptr; \/\/ offset entry not found\n@@ -3155,1 +3307,1 @@\n-  if (!intf_method->is_abstract() && default_methods() != NULL) {\n+  if (!intf_method->is_abstract() && default_methods() != nullptr) {\n@@ -3180,1 +3332,1 @@\n-  if (default_methods() != NULL) {\n+  if (default_methods() != nullptr) {\n@@ -3183,1 +3335,1 @@\n-      if (old_method == NULL || !old_method->is_old()) {\n+      if (old_method == nullptr || !old_method->is_old()) {\n@@ -3212,1 +3364,1 @@\n-  assert(prev == NULL || !prev->is_in_use() COMPILER2_PRESENT(|| StressRecompilation),\n+  assert(prev == nullptr || !prev->is_in_use() COMPILER2_PRESENT(|| StressRecompilation),\n@@ -3225,1 +3377,1 @@\n-    if (inv != NULL && inv->is_in_use()) {\n+    if (inv != nullptr && inv->is_in_use()) {\n@@ -3234,1 +3386,1 @@\n-  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? NULL : CompiledMethod_lock\n+  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? nullptr : CompiledMethod_lock\n@@ -3237,1 +3389,1 @@\n-  nmethod* last = NULL;\n+  nmethod* last = nullptr;\n@@ -3243,1 +3395,1 @@\n-  while(cur != NULL && cur != n) {\n+  while(cur != nullptr && cur != n) {\n@@ -3251,1 +3403,1 @@\n-  nmethod* next = NULL;\n+  nmethod* next = nullptr;\n@@ -3255,1 +3407,1 @@\n-    if (last == NULL) {\n+    if (last == nullptr) {\n@@ -3262,1 +3414,1 @@\n-  n->set_osr_link(NULL);\n+  n->set_osr_link(nullptr);\n@@ -3264,1 +3416,1 @@\n-  while (cur != NULL) {\n+  while (cur != nullptr) {\n@@ -3275,2 +3427,2 @@\n-int InstanceKlass::mark_osr_nmethods(const Method* m) {\n-  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? NULL : CompiledMethod_lock,\n+int InstanceKlass::mark_osr_nmethods(DeoptimizationScope* deopt_scope, const Method* m) {\n+  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? nullptr : CompiledMethod_lock,\n@@ -3280,1 +3432,1 @@\n-  while (osr != NULL) {\n+  while (osr != nullptr) {\n@@ -3283,1 +3435,1 @@\n-      osr->mark_for_deoptimization();\n+      deopt_scope->mark(osr);\n@@ -3292,1 +3444,1 @@\n-  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? NULL : CompiledMethod_lock,\n+  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? nullptr : CompiledMethod_lock,\n@@ -3295,2 +3447,2 @@\n-  nmethod* best = NULL;\n-  while (osr != NULL) {\n+  nmethod* best = nullptr;\n+  while (osr != nullptr) {\n@@ -3312,1 +3464,1 @@\n-        if (best == NULL || (osr->comp_level() > best->comp_level())) {\n+        if (best == nullptr || (osr->comp_level() > best->comp_level())) {\n@@ -3324,2 +3476,2 @@\n-  assert(match_level == false || best == NULL, \"shouldn't pick up anything if match_level is set\");\n-  if (best != NULL && best->comp_level() >= comp_level) {\n+  assert(match_level == false || best == nullptr, \"shouldn't pick up anything if match_level is set\");\n+  if (best != nullptr && best->comp_level() >= comp_level) {\n@@ -3328,1 +3480,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -3337,1 +3489,1 @@\n-  \"allocated\", \"loaded\", \"linked\", \"being_initialized\", \"fully_initialized\", \"initialization_error\"\n+  \"allocated\", \"loaded\", \"being_linked\", \"linked\", \"being_initialized\", \"fully_initialized\", \"initialization_error\"\n@@ -3356,0 +3508,4 @@\n+const char* InstanceKlass::init_state_name() const {\n+  return state_names[init_state()];\n+}\n+\n@@ -3363,1 +3519,2 @@\n-  st->print(BULLET\"state:             \"); st->print_cr(\"%s\", state_names[_init_state]);\n+  st->print(BULLET\"flags:             \"); _misc_flags.print_on(st);               st->cr();\n+  st->print(BULLET\"state:             \"); st->print_cr(\"%s\", init_state_name());\n@@ -3369,1 +3526,1 @@\n-  for (n = 0; sub != NULL; n++, sub = sub->next_sibling()) {\n+  for (n = 0; sub != nullptr; n++, sub = sub->next_sibling()) {\n@@ -3398,1 +3555,1 @@\n-  if (Verbose && default_methods() != NULL) {\n+  if (Verbose && default_methods() != nullptr) {\n@@ -3404,1 +3561,1 @@\n-  if (default_vtable_indices() != NULL) {\n+  if (default_vtable_indices() != nullptr) {\n@@ -3410,1 +3567,1 @@\n-  if (class_loader_data() != NULL) {\n+  if (class_loader_data() != nullptr) {\n@@ -3415,1 +3572,1 @@\n-  if (source_file_name() != NULL) {\n+  if (source_file_name() != nullptr) {\n@@ -3420,1 +3577,1 @@\n-  if (source_debug_extension() != NULL) {\n+  if (source_debug_extension() != nullptr) {\n@@ -3433,1 +3590,1 @@\n-         pv_node != NULL;\n+         pv_node != nullptr;\n@@ -3443,1 +3600,1 @@\n-  if (generic_signature() != NULL) {\n+  if (generic_signature() != nullptr) {\n@@ -3450,1 +3607,1 @@\n-  if (record_components() != NULL) {\n+  if (record_components() != nullptr) {\n@@ -3454,1 +3611,1 @@\n-  if (java_mirror() != NULL) {\n+  if (java_mirror() != nullptr) {\n@@ -3459,1 +3616,1 @@\n-    st->print_cr(BULLET\"java mirror:       NULL\");\n+    st->print_cr(BULLET\"java mirror:       null\");\n@@ -3461,1 +3618,1 @@\n-  st->print(BULLET\"vtable length      %d  (start addr: \" INTPTR_FORMAT \")\", vtable_length(), p2i(start_of_vtable())); st->cr();\n+  st->print(BULLET\"vtable length      %d  (start addr: \" PTR_FORMAT \")\", vtable_length(), p2i(start_of_vtable())); st->cr();\n@@ -3463,1 +3620,1 @@\n-  st->print(BULLET\"itable length      %d (start addr: \" INTPTR_FORMAT \")\", itable_length(), p2i(start_of_itable())); st->cr();\n+  st->print(BULLET\"itable length      %d (start addr: \" PTR_FORMAT \")\", itable_length(), p2i(start_of_itable())); st->cr();\n@@ -3471,1 +3628,1 @@\n-  ik->do_nonstatic_fields(&print_nonstatic_field);\n+  ik->print_nonstatic_fields(&print_nonstatic_field);\n@@ -3491,1 +3648,1 @@\n-   if (_obj == NULL) {\n+   if (_obj == nullptr) {\n@@ -3507,1 +3664,1 @@\n-    if (value != NULL &&\n+    if (value != nullptr &&\n@@ -3513,1 +3670,0 @@\n-      if (!WizardMode)  return;  \/\/ that is enough\n@@ -3517,1 +3673,1 @@\n-  st->print_cr(BULLET\"---- fields (total size %d words):\", oop_size(obj));\n+  st->print_cr(BULLET\"---- fields (total size \" SIZE_FORMAT \" words):\", oop_size(obj));\n@@ -3519,1 +3675,1 @@\n-  do_nonstatic_fields(&print_field);\n+  print_nonstatic_fields(&print_field);\n@@ -3525,11 +3681,2 @@\n-    Klass* mirrored_klass = java_lang_Class::as_Klass(obj);\n-    st->print(BULLET\"fake entry for mirror: \");\n-    Metadata::print_value_on_maybe_null(st, mirrored_klass);\n-    st->cr();\n-    Klass* array_klass = java_lang_Class::array_klass_acquire(obj);\n-    st->print(BULLET\"fake entry for array: \");\n-    Metadata::print_value_on_maybe_null(st, array_klass);\n-    st->cr();\n-    st->print_cr(BULLET\"fake entry for oop_size: %d\", java_lang_Class::oop_size(obj));\n-    st->print_cr(BULLET\"fake entry for static_oop_field_count: %d\", java_lang_Class::static_oop_field_count(obj));\n-    if (real_klass != NULL && real_klass->is_instance_klass()) {\n+    if (real_klass != nullptr && real_klass->is_instance_klass()) {\n+      st->print_cr(BULLET\"---- static fields (%d):\", java_lang_Class::static_oop_field_count(obj));\n@@ -3561,1 +3708,1 @@\n-      && java_lang_String::value(obj) != NULL) {\n+      && java_lang_String::value(obj) != nullptr) {\n@@ -3572,1 +3719,1 @@\n-    if (k != NULL) {\n+    if (k != nullptr) {\n@@ -3586,1 +3733,1 @@\n-    if (vmentry != NULL) {\n+    if (vmentry != nullptr) {\n@@ -3592,1 +3739,1 @@\n-    if (vmtarget != NULL) {\n+    if (vmtarget != nullptr) {\n@@ -3598,1 +3745,1 @@\n-      if (clazz != NULL) {\n+      if (clazz != nullptr) {\n@@ -3601,1 +3748,1 @@\n-        st->print(\"NULL\");\n+        st->print(\"null\");\n@@ -3604,1 +3751,1 @@\n-      if (name != NULL) {\n+      if (name != nullptr) {\n@@ -3607,1 +3754,1 @@\n-        st->print(\"NULL\");\n+        st->print(\"null\");\n@@ -3620,1 +3767,3 @@\n-  log_to_classlist();\n+  if (ClassListWriter::is_enabled()) {\n+    ClassListWriter::write(this, cfs);\n+  }\n@@ -3634,4 +3783,4 @@\n-  if (cfs != NULL) {\n-    if (cfs->source() != NULL) {\n-      const char* module_name = (module_entry->name() == NULL) ? UNNAMED_MODULE : module_entry->name()->as_C_string();\n-      if (module_name != NULL) {\n+  if (cfs != nullptr) {\n+    if (cfs->source() != nullptr) {\n+      const char* module_name = (module_entry->name() == nullptr) ? UNNAMED_MODULE : module_entry->name()->as_C_string();\n+      if (module_name != nullptr) {\n@@ -3651,4 +3800,4 @@\n-        current->as_Java_thread()->security_get_caller_class(1):\n-        NULL;\n-      \/\/ caller can be NULL, for example, during a JVMTI VM_Init hook\n-      if (caller != NULL) {\n+        JavaThread::cast(current)->security_get_caller_class(1):\n+        nullptr;\n+      \/\/ caller can be null, for example, during a JVMTI VM_Init hook\n+      if (caller != nullptr) {\n@@ -3678,1 +3827,1 @@\n-    debug_stream.print(\" klass: \" INTPTR_FORMAT \" super: \" INTPTR_FORMAT,\n+    debug_stream.print(\" klass: \" PTR_FORMAT \" super: \" PTR_FORMAT,\n@@ -3682,1 +3831,1 @@\n-    if (local_interfaces() != NULL && local_interfaces()->length() > 0) {\n+    if (local_interfaces() != nullptr && local_interfaces()->length() > 0) {\n@@ -3686,1 +3835,1 @@\n-        debug_stream.print(\" \" INTPTR_FORMAT,\n+        debug_stream.print(\" \" PTR_FORMAT,\n@@ -3747,1 +3896,1 @@\n-  if (subklass() != NULL) {\n+  if (subklass() != nullptr) {\n@@ -3754,1 +3903,1 @@\n-  if (sib != NULL) {\n+  if (sib != nullptr) {\n@@ -3773,1 +3922,1 @@\n-  if (transitive_interfaces() != NULL) {\n+  if (transitive_interfaces() != nullptr) {\n@@ -3782,1 +3931,1 @@\n-  if (methods() != NULL) {\n+  if (methods() != nullptr) {\n@@ -3795,1 +3944,1 @@\n-  if (method_ordering() != NULL) {\n+  if (method_ordering() != nullptr) {\n@@ -3816,1 +3965,1 @@\n-  if (default_methods() != NULL) {\n+  if (default_methods() != nullptr) {\n@@ -3829,1 +3978,1 @@\n-  if (jni_ids() != NULL) {\n+  if (jni_ids() != nullptr) {\n@@ -3834,1 +3983,1 @@\n-  if (constants() != NULL) {\n+  if (constants() != nullptr) {\n@@ -3860,1 +4009,1 @@\n-  while (current != NULL) {\n+  while (current != nullptr) {\n@@ -3864,1 +4013,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -3868,1 +4017,1 @@\n-  while (current != NULL) {\n+  while (current != nullptr) {\n@@ -3882,1 +4031,1 @@\n-  while (current != NULL) {\n+  while (current != nullptr) {\n@@ -3895,0 +4044,3 @@\n+  if (state > loaded) {\n+    assert_lock_strong(_init_monitor);\n+  }\n@@ -3898,1 +4050,2 @@\n-  assert(good_state || state == allocated, \"illegal state transition\");\n+  bool link_failed = _init_state == being_linked && state == loaded;\n+  assert(good_state || state == allocated || link_failed, \"illegal state transition\");\n@@ -3900,2 +4053,2 @@\n-  assert(_init_thread == NULL, \"should be cleared before state change\");\n-  _init_state = (u1)state;\n+  assert(_init_thread == nullptr, \"should be cleared before state change\");\n+  Atomic::store(&_init_state, state);\n@@ -3911,1 +4064,1 @@\n-bool InstanceKlass::_has_previous_versions = false;\n+bool InstanceKlass::_should_clean_previous_versions = false;\n@@ -3918,3 +4071,3 @@\n-bool InstanceKlass::has_previous_versions_and_reset() {\n-  bool ret = _has_previous_versions;\n-  log_trace(redefine, class, iklass, purge)(\"Class unloading: has_previous_versions = %s\",\n+bool InstanceKlass::should_clean_previous_versions_and_reset() {\n+  bool ret = _should_clean_previous_versions;\n+  log_trace(redefine, class, iklass, purge)(\"Class unloading: should_clean_previous_versions = %s\",\n@@ -3922,1 +4075,1 @@\n-  _has_previous_versions = false;\n+  _should_clean_previous_versions = false;\n@@ -3933,1 +4086,1 @@\n-  if (previous_versions() == NULL) {\n+  if (previous_versions() == nullptr) {\n@@ -3943,1 +4096,1 @@\n-  assert(loader_data != NULL, \"should never be null\");\n+  assert(loader_data != nullptr, \"should never be null\");\n@@ -3954,1 +4107,1 @@\n-  for (; pv_node != NULL; ) {\n+  for (; pv_node != nullptr; ) {\n@@ -3957,1 +4110,1 @@\n-    assert(pvcp != NULL, \"cp ref was unexpectedly cleared\");\n+    assert(pvcp != nullptr, \"cp ref was unexpectedly cleared\");\n@@ -3965,3 +4118,1 @@\n-        (\"previous version \" INTPTR_FORMAT \" is dead.\", p2i(pv_node));\n-      \/\/ For debugging purposes.\n-      pv_node->set_is_scratch_class();\n+        (\"previous version \" PTR_FORMAT \" is dead.\", p2i(pv_node));\n@@ -3971,1 +4122,1 @@\n-      pv_node->link_previous_versions(NULL);   \/\/ point next to NULL\n+      pv_node->link_previous_versions(nullptr);   \/\/ point next to null\n@@ -3981,2 +4132,1 @@\n-      log_trace(redefine, class, iklass, purge)(\"previous version \" INTPTR_FORMAT \" is alive\", p2i(pv_node));\n-      assert(pvcp->pool_holder() != NULL, \"Constant pool with no holder\");\n+      assert(pvcp->pool_holder() != nullptr, \"Constant pool with no holder\");\n@@ -3985,2 +4135,8 @@\n-      \/\/ found a previous version for next time we do class unloading\n-      _has_previous_versions = true;\n+      if (pvcp->is_shared()) {\n+        \/\/ Shared previous versions can never be removed so no cleaning is needed.\n+        log_trace(redefine, class, iklass, purge)(\"previous version \" PTR_FORMAT \" is shared\", p2i(pv_node));\n+      } else {\n+        \/\/ Previous version alive, set that clean is needed for next time.\n+        _should_clean_previous_versions = true;\n+        log_trace(redefine, class, iklass, purge)(\"previous version \" PTR_FORMAT \" is alive\", p2i(pv_node));\n+      }\n@@ -4003,1 +4159,1 @@\n-      _previous_versions != NULL) {\n+      _previous_versions != nullptr) {\n@@ -4017,1 +4173,1 @@\n-             prev_version != NULL;\n+             prev_version != nullptr;\n@@ -4082,2 +4238,0 @@\n-    \/\/ For debugging purposes.\n-    scratch_class->set_is_scratch_class();\n@@ -4088,5 +4242,3 @@\n-  \/\/ Add previous version if any methods are still running.\n-  \/\/ Set has_previous_version flag for processing during class unloading.\n-  _has_previous_versions = true;\n-  log_trace(redefine, class, iklass, add) (\"scratch class added; one of its methods is on_stack.\");\n-  assert(scratch_class->previous_versions() == NULL, \"shouldn't have a previous version\");\n+  \/\/ Add previous version if any methods are still running or if this is\n+  \/\/ a shared class which should never be removed.\n+  assert(scratch_class->previous_versions() == nullptr, \"shouldn't have a previous version\");\n@@ -4095,0 +4247,8 @@\n+  if (cp_ref->is_shared()) {\n+    log_trace(redefine, class, iklass, add) (\"scratch class added; class is shared\");\n+  } else {\n+    \/\/  We only set clean_previous_versions flag for processing during class\n+    \/\/ unloading for non-shared classes.\n+    _should_clean_previous_versions = true;\n+    log_trace(redefine, class, iklass, add) (\"scratch class added; one of its methods is on_stack.\");\n+  }\n@@ -4100,1 +4260,1 @@\n-  Method* m = NULL;\n+  Method* m = nullptr;\n@@ -4104,1 +4264,1 @@\n-  if (m == NULL || m->method_idnum() != idnum) {\n+  if (m == nullptr || m->method_idnum() != idnum) {\n@@ -4112,1 +4272,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -4120,1 +4280,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -4123,1 +4283,1 @@\n-  if (m != NULL && m->orig_method_idnum() == idnum) {\n+  if (m != nullptr && m->orig_method_idnum() == idnum) {\n@@ -4134,1 +4294,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -4140,2 +4300,2 @@\n-  if (holder == NULL) {\n-    return NULL; \/\/ The version of klass is gone, no method is found\n+  if (holder == nullptr) {\n+    return nullptr; \/\/ The version of klass is gone, no method is found\n@@ -4161,39 +4321,0 @@\n-bool InstanceKlass::is_shareable() const {\n-#if INCLUDE_CDS\n-  ClassLoaderData* loader_data = class_loader_data();\n-  if (!SystemDictionaryShared::is_sharing_possible(loader_data)) {\n-    return false;\n-  }\n-\n-  if (is_hidden()) {\n-    return false;\n-  }\n-\n-  if (module()->is_patched()) {\n-    return false;\n-  }\n-\n-  return true;\n-#else\n-  return false;\n-#endif\n-}\n-\n-void InstanceKlass::log_to_classlist() const {\n-#if INCLUDE_CDS\n-  ResourceMark rm;\n-  if (ClassListWriter::is_enabled()) {\n-    if (!ClassLoader::has_jrt_entry()) {\n-       warning(\"DumpLoadedClassList and CDS are not supported in exploded build\");\n-       DumpLoadedClassList = NULL;\n-       return;\n-    }\n-    if (is_shareable()) {\n-      ClassListWriter w;\n-      w.stream()->print_cr(\"%s\", name()->as_C_string());\n-      w.stream()->flush();\n-    }\n-  }\n-#endif \/\/ INCLUDE_CDS\n-}\n-\n@@ -4203,2 +4324,2 @@\n-  assert(_current != NULL, \"required\");\n-  if (_visit_subclasses && _current->subklass() != NULL) {\n+  assert(_current != nullptr, \"required\");\n+  if (_visit_subclasses && _current->subklass() != nullptr) {\n@@ -4209,1 +4330,1 @@\n-  while (_current->next_sibling() == NULL && _current != _root) {\n+  while (_current->next_sibling() == nullptr && _current != _root) {\n@@ -4214,1 +4335,1 @@\n-    _current = NULL;\n+    _current = nullptr;\n@@ -4220,0 +4341,1 @@\n+\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":837,"deletions":715,"binary":false,"changes":1552,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,1 +26,0 @@\n-#include \"jvm.h\"\n@@ -33,1 +32,1 @@\n-#include \"classfile\/classLoader.hpp\"\n+#include \"classfile\/classLoader.inline.hpp\"\n@@ -51,0 +50,1 @@\n+#include \"jvm.h\"\n@@ -66,0 +66,1 @@\n+#include \"prims\/foreignGlobals.hpp\"\n@@ -68,1 +69,1 @@\n-#include \"prims\/jvmtiThreadState.hpp\"\n+#include \"prims\/jvmtiThreadState.inline.hpp\"\n@@ -72,0 +73,1 @@\n+#include \"runtime\/continuation.hpp\"\n@@ -80,0 +82,1 @@\n+#include \"runtime\/javaThread.hpp\"\n@@ -87,1 +90,1 @@\n-#include \"runtime\/thread.inline.hpp\"\n+#include \"runtime\/threadIdentifier.hpp\"\n@@ -110,0 +113,3 @@\n+#if INCLUDE_MANAGEMENT\n+#include \"services\/finalizerService.hpp\"\n+#endif\n@@ -148,1 +154,1 @@\n-  const char * source_file = NULL;\n+  const char * source_file = nullptr;\n@@ -150,1 +156,1 @@\n-  InstanceKlass* caller = NULL;\n+  InstanceKlass* caller = nullptr;\n@@ -161,1 +167,1 @@\n-    Method* last_caller = NULL;\n+    Method* last_caller = nullptr;\n@@ -187,1 +193,1 @@\n-    } else if (last_caller != NULL &&\n+    } else if (last_caller != nullptr &&\n@@ -207,1 +213,1 @@\n-      if (s != NULL) {\n+      if (s != nullptr) {\n@@ -212,1 +218,1 @@\n-  if (caller != NULL) {\n+  if (caller != nullptr) {\n@@ -217,1 +223,1 @@\n-      if (source_file != NULL) {\n+      if (source_file != nullptr) {\n@@ -290,1 +296,1 @@\n-  if (src == NULL || dst == NULL) {\n+  if (src == nullptr || dst == nullptr) {\n@@ -307,1 +313,1 @@\n-  Handle value_str  = java_lang_String::create_from_platform_dependent_str((value != NULL ? value : \"\"), CHECK);\n+  Handle value_str  = java_lang_String::create_from_platform_dependent_str((value != nullptr ? value : \"\"), CHECK);\n@@ -340,1 +346,1 @@\n-  while (p != NULL) {\n+  while (p != nullptr) {\n@@ -345,1 +351,1 @@\n-        Handle value_str  = java_lang_String::create_from_platform_dependent_str((value != NULL ? value : \"\"), CHECK_NULL);\n+        Handle value_str  = java_lang_String::create_from_platform_dependent_str((value != nullptr ? value : \"\"), CHECK_NULL);\n@@ -427,6 +433,0 @@\n-#if INCLUDE_CDS\n-  \/\/ Link all classes for dynamic CDS dumping before vm exit.\n-  if (DynamicDumpSharedSpaces) {\n-    DynamicArchive::prepare_for_dynamic_dumping_at_exit();\n-  }\n-#endif\n@@ -442,1 +442,1 @@\n-  before_exit(thread);\n+  before_exit(thread, true);\n@@ -490,1 +490,1 @@\n-JVM_ENTRY_NO_ENV(jboolean, JVM_IsUseContainerSupport(void))\n+JVM_LEAF(jboolean, JVM_IsUseContainerSupport(void))\n@@ -509,1 +509,1 @@\n-  if (!ShowCodeDetailsInExceptionMessages) return NULL;\n+  if (!ShowCodeDetailsInExceptionMessages) return nullptr;\n@@ -516,1 +516,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -519,1 +519,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -528,1 +528,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -535,2 +535,2 @@\n-JVM_ENTRY(void, JVM_InitStackTraceElementArray(JNIEnv *env, jobjectArray elements, jobject throwable))\n-  Handle exception(THREAD, JNIHandles::resolve(throwable));\n+JVM_ENTRY(void, JVM_InitStackTraceElementArray(JNIEnv *env, jobjectArray elements, jobject backtrace, jint depth))\n+  Handle backtraceh(THREAD, JNIHandles::resolve(backtrace));\n@@ -540,1 +540,1 @@\n-  java_lang_Throwable::get_stack_trace_elements(exception, stack_trace, CHECK);\n+  java_lang_Throwable::get_stack_trace_elements(depth, backtraceh, stack_trace, CHECK);\n@@ -555,2 +555,2 @@\n-                                     jint skip_frames, jint frame_count, jint start_index,\n-                                     jobjectArray frames))\n+                                     jint skip_frames, jobject contScope, jobject cont,\n+                                     jint frame_count, jint start_index, jobjectArray frames))\n@@ -558,1 +558,1 @@\n-    THROW_MSG_(vmSymbols::java_lang_InternalError(), \"doStackWalk: no stack trace\", NULL);\n+    THROW_MSG_(vmSymbols::java_lang_InternalError(), \"doStackWalk: no stack trace\", nullptr);\n@@ -562,1 +562,2 @@\n-\n+  Handle contScope_h(THREAD, JNIHandles::resolve(contScope));\n+  Handle cont_h(THREAD, JNIHandles::resolve(cont));\n@@ -571,1 +572,1 @@\n-    THROW_MSG_(vmSymbols::java_lang_IllegalArgumentException(), \"not enough space in buffers\", NULL);\n+    THROW_MSG_(vmSymbols::java_lang_IllegalArgumentException(), \"not enough space in buffers\", nullptr);\n@@ -574,2 +575,2 @@\n-  oop result = StackWalk::walk(stackStream_h, mode, skip_frames, frame_count,\n-                               start_index, frames_array_h, CHECK_NULL);\n+  oop result = StackWalk::walk(stackStream_h, mode, skip_frames, contScope_h, cont_h,\n+                               frame_count, start_index, frames_array_h, CHECK_NULL);\n@@ -596,1 +597,10 @@\n-                                   start_index, frames_array_h, THREAD);\n+                                  start_index, frames_array_h, THREAD);\n+JVM_END\n+\n+JVM_ENTRY(void, JVM_SetStackWalkContinuation(JNIEnv *env, jobject stackStream, jlong anchor, jobjectArray frames, jobject cont))\n+  objArrayOop fa = objArrayOop(JNIHandles::resolve_non_null(frames));\n+  objArrayHandle frames_array_h(THREAD, fa);\n+  Handle stackStream_h(THREAD, JNIHandles::resolve_non_null(stackStream));\n+  Handle cont_h(THREAD, JNIHandles::resolve_non_null(cont));\n+\n+  StackWalk::setContinuation(stackStream_h, anchor, frames_array_h, cont_h, THREAD);\n@@ -603,2 +613,2 @@\n-  \/\/ as implemented in the classic virtual machine; return 0 if object is NULL\n-  return handle == NULL ? 0 : ObjectSynchronizer::FastHashCode (THREAD, JNIHandles::resolve_non_null(handle)) ;\n+  \/\/ as implemented in the classic virtual machine; return 0 if object is null\n+  return handle == nullptr ? 0 : ObjectSynchronizer::FastHashCode (THREAD, JNIHandles::resolve_non_null(handle)) ;\n@@ -663,2 +673,2 @@\n-  const int size = obj->size();\n-  oop new_obj_oop = NULL;\n+  const size_t size = obj->size();\n+  oop new_obj_oop = nullptr;\n@@ -687,0 +697,16 @@\n+\/\/ java.lang.ref.Finalizer \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+JVM_ENTRY(void, JVM_ReportFinalizationComplete(JNIEnv * env, jobject finalizee))\n+  MANAGEMENT_ONLY(FinalizerService::on_complete(JNIHandles::resolve_non_null(finalizee), THREAD);)\n+JVM_END\n+\n+JVM_LEAF(jboolean, JVM_IsFinalizationEnabled(JNIEnv * env))\n+  return InstanceKlass::is_finalization_enabled();\n+JVM_END\n+\n+\/\/ jdk.internal.vm.Continuation \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+JVM_ENTRY(void, JVM_RegisterContinuationMethods(JNIEnv *env, jclass cls))\n+  CONT_RegisterNativeMethods(env, cls);\n+JVM_END\n+\n@@ -710,1 +736,1 @@\n-    assert(m != NULL, \"sanity\");\n+    assert(m != nullptr, \"sanity\");\n@@ -732,1 +758,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -737,1 +763,1 @@\n-  oop mirror = NULL;\n+  oop mirror = nullptr;\n@@ -742,1 +768,1 @@\n-  if (mirror == NULL) {\n+  if (mirror == nullptr) {\n@@ -756,1 +782,1 @@\n-  if (name == NULL || (int)strlen(name) > Symbol::max_length()) {\n+  if (name == nullptr || (int)strlen(name) > Symbol::max_length()) {\n@@ -759,1 +785,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -765,2 +791,2 @@\n-  if (k == NULL) {\n-    return NULL;\n+  if (k == nullptr) {\n+    return nullptr;\n@@ -785,1 +811,1 @@\n-  oop protection_domain = NULL;\n+  oop protection_domain = nullptr;\n@@ -789,1 +815,1 @@\n-  \/\/ The caller is also passed as NULL by the java code if there is no security\n+  \/\/ The caller is also passed as null by the java code if there is no security\n@@ -791,1 +817,1 @@\n-  if (from_class != NULL && loader_oop != NULL) {\n+  if (from_class != nullptr && loader_oop != nullptr) {\n@@ -800,1 +826,1 @@\n-  if (log_is_enabled(Debug, class, resolve) && result != NULL) {\n+  if (log_is_enabled(Debug, class, resolve) && result != nullptr) {\n@@ -813,2 +839,2 @@\n-  Klass* from_class = (from_class_oop == NULL)\n-                           ? (Klass*)NULL\n+  Klass* from_class = (from_class_oop == nullptr)\n+                           ? (Klass*)nullptr\n@@ -816,3 +842,3 @@\n-  oop class_loader = NULL;\n-  oop protection_domain = NULL;\n-  if (from_class != NULL) {\n+  oop class_loader = nullptr;\n+  oop protection_domain = nullptr;\n+  if (from_class != nullptr) {\n@@ -827,1 +853,1 @@\n-  if (log_is_enabled(Debug, class, resolve) && result != NULL) {\n+  if (log_is_enabled(Debug, class, resolve) && result != nullptr) {\n@@ -848,1 +874,1 @@\n-  if (source == NULL)  source = \"__JVM_DefineClass__\";\n+  if (source == nullptr)  source = \"__JVM_DefineClass__\";\n@@ -864,1 +890,1 @@\n-  TempNewSymbol class_name = name == NULL ? NULL :\n+  TempNewSymbol class_name = name == nullptr ? nullptr :\n@@ -903,1 +929,1 @@\n-  if (lookup_k == NULL) {\n+  if (lookup_k == nullptr) {\n@@ -915,1 +941,1 @@\n-  InstanceKlass* host_class = NULL;\n+  InstanceKlass* host_class = nullptr;\n@@ -930,1 +956,1 @@\n-    if (classData != NULL) {\n+    if (classData != nullptr) {\n@@ -949,1 +975,1 @@\n-  TempNewSymbol class_name = name == NULL ? NULL :\n+  TempNewSymbol class_name = name == nullptr ? nullptr :\n@@ -957,1 +983,1 @@\n-  InstanceKlass* ik = NULL;\n+  InstanceKlass* ik = nullptr;\n@@ -1009,1 +1035,1 @@\n-  return jvm_define_class_common(name, loader, buf, len, pd, NULL, THREAD);\n+  return jvm_define_class_common(name, loader, buf, len, pd, nullptr, THREAD);\n@@ -1026,1 +1052,1 @@\n-  if (lookup == NULL) {\n+  if (lookup == nullptr) {\n@@ -1030,1 +1056,1 @@\n-  assert(buf != NULL, \"buf must not be NULL\");\n+  assert(buf != nullptr, \"buf must not be null\");\n@@ -1047,1 +1073,1 @@\n-  if (str == NULL) return NULL;\n+  if (str == nullptr) return nullptr;\n@@ -1062,1 +1088,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1068,1 +1094,1 @@\n-  \/\/   us to pass the NULL as the initiating class loader.\n+  \/\/   us to pass the null as the initiating class loader.\n@@ -1070,3 +1096,3 @@\n-  Klass* k = SystemDictionary::find_instance_or_array_klass(klass_name,\n-                                                              h_loader,\n-                                                              Handle());\n+  Klass* k = SystemDictionary::find_instance_or_array_klass(THREAD, klass_name,\n+                                                            h_loader,\n+                                                            Handle());\n@@ -1074,1 +1100,1 @@\n-  if (k == NULL) {\n+  if (k == nullptr) {\n@@ -1080,1 +1106,1 @@\n-  return (k == NULL) ? NULL :\n+  return (k == nullptr) ? nullptr :\n@@ -1128,1 +1154,1 @@\n-  assert (cls != NULL, \"illegal class\");\n+  assert (cls != nullptr, \"illegal class\");\n@@ -1206,1 +1232,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1212,2 +1238,2 @@\n-  \/\/ is an array, return NULL.\n-  if (signers == NULL) return NULL;\n+  \/\/ is an array, return null.\n+  if (signers == nullptr) return nullptr;\n@@ -1243,2 +1269,2 @@\n-  if (mirror == NULL) {\n-    THROW_(vmSymbols::java_lang_NullPointerException(), NULL);\n+  if (mirror == nullptr) {\n+    THROW_(vmSymbols::java_lang_NullPointerException(), nullptr);\n@@ -1249,1 +1275,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1264,1 +1290,1 @@\n-  if (!UsePrivilegedStack) return NULL;\n+  if (!UsePrivilegedStack) return nullptr;\n@@ -1274,2 +1300,2 @@\n-  oop previous_protection_domain = NULL;\n-  Handle privileged_context(thread, NULL);\n+  oop previous_protection_domain = nullptr;\n+  Handle privileged_context(thread, nullptr);\n@@ -1277,1 +1303,1 @@\n-  oop protection_domain = NULL;\n+  oop protection_domain = nullptr;\n@@ -1308,1 +1334,1 @@\n-    if ((previous_protection_domain != protection_domain) && (protection_domain != NULL)) {\n+    if ((previous_protection_domain != protection_domain) && (protection_domain != nullptr)) {\n@@ -1320,1 +1346,1 @@\n-    if (is_privileged && privileged_context.is_null()) return NULL;\n+    if (is_privileged && privileged_context.is_null()) return nullptr;\n@@ -1338,0 +1364,48 @@\n+class ScopedValueBindingsResolver {\n+public:\n+  InstanceKlass* Carrier_klass;\n+  ScopedValueBindingsResolver(JavaThread* THREAD) {\n+    Klass *k = SystemDictionary::resolve_or_fail(vmSymbols::java_lang_ScopedValue_Carrier(), true, THREAD);\n+    Carrier_klass = InstanceKlass::cast(k);\n+  }\n+};\n+\n+JVM_ENTRY(jobject, JVM_FindScopedValueBindings(JNIEnv *env, jclass cls))\n+  ResourceMark rm(THREAD);\n+  GrowableArray<Handle>* local_array = new GrowableArray<Handle>(12);\n+  JvmtiVMObjectAllocEventCollector oam;\n+\n+  static ScopedValueBindingsResolver resolver(THREAD);\n+\n+  \/\/ Iterate through Java frames\n+  vframeStream vfst(thread);\n+  for(; !vfst.at_end(); vfst.next()) {\n+    int loc = -1;\n+    \/\/ get method of frame\n+    Method* method = vfst.method();\n+\n+    Symbol *name = method->name();\n+\n+    InstanceKlass* holder = method->method_holder();\n+    if (name == vmSymbols::runWith_method_name()) {\n+      if ((holder == resolver.Carrier_klass\n+           || holder == vmClasses::VirtualThread_klass()\n+           || holder == vmClasses::Thread_klass())) {\n+        loc = 1;\n+      }\n+    }\n+\n+    if (loc != -1) {\n+      javaVFrame *frame = vfst.asJavaVFrame();\n+      StackValueCollection* locals = frame->locals();\n+      StackValue* head_sv = locals->at(loc); \/\/ java\/lang\/ScopedValue$Snapshot\n+      Handle result = head_sv->get_obj();\n+      assert(!head_sv->obj_is_scalar_replaced(), \"found scalar-replaced object\");\n+      if (result() != nullptr) {\n+        return JNIHandles::make_local(THREAD, result());\n+      }\n+    }\n+  }\n+\n+  return nullptr;\n+JVM_END\n@@ -1341,1 +1415,1 @@\n-  return (k != NULL) && k->is_array_klass() ? true : false;\n+  return (k != nullptr) && k->is_array_klass() ? true : false;\n@@ -1438,1 +1512,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1442,1 +1516,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1448,2 +1522,2 @@\n-  if (outer_klass == NULL)  return NULL;  \/\/ already a top-level class\n-  if (!inner_is_member)  return NULL;     \/\/ a hidden class (inside a method)\n+  if (outer_klass == nullptr)  return nullptr;  \/\/ already a top-level class\n+  if (!inner_is_member)  return nullptr;     \/\/ a hidden class (inside a method)\n@@ -1458,1 +1532,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1462,1 +1536,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1474,1 +1548,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1479,1 +1553,1 @@\n-  assert (cls != NULL, \"illegal class\");\n+  assert (cls != nullptr, \"illegal class\");\n@@ -1483,1 +1557,1 @@\n-  \/\/ Return null for arrays and primatives\n+  \/\/ Return null for arrays and primitives\n@@ -1488,1 +1562,1 @@\n-      if (sym == NULL) return NULL;\n+      if (sym == nullptr) return nullptr;\n@@ -1493,1 +1567,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1498,1 +1572,1 @@\n-  assert (cls != NULL, \"illegal class\");\n+  assert (cls != nullptr, \"illegal class\");\n@@ -1508,1 +1582,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1545,1 +1619,1 @@\n-  oop mirror    = NULL;\n+  oop mirror    = nullptr;\n@@ -1560,2 +1634,2 @@\n-  assert(m != NULL, \"cannot find method\");\n-  return m;  \/\/ caller has to deal with NULL in product mode\n+  assert(m != nullptr, \"cannot find method\");\n+  return m;  \/\/ caller has to deal with null in product mode\n@@ -1567,1 +1641,1 @@\n-  assert (cls != NULL, \"illegal class\");\n+  assert (cls != nullptr, \"illegal class\");\n@@ -1574,1 +1648,1 @@\n-      if (type_annotations != NULL) {\n+      if (type_annotations != nullptr) {\n@@ -1580,1 +1654,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1584,1 +1658,1 @@\n-  assert (method != NULL, \"illegal method\");\n+  assert (method != nullptr, \"illegal method\");\n@@ -1587,2 +1661,2 @@\n-  if (m == NULL) {\n-    return NULL;\n+  if (m == nullptr) {\n+    return nullptr;\n@@ -1592,1 +1666,1 @@\n-  if (type_annotations != NULL) {\n+  if (type_annotations != nullptr) {\n@@ -1597,1 +1671,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1601,1 +1675,1 @@\n-  assert (field != NULL, \"illegal field\");\n+  assert (field != nullptr, \"illegal field\");\n@@ -1605,1 +1679,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1630,1 +1704,1 @@\n-    return (jobjectArray)NULL;\n+    return (jobjectArray)nullptr;\n@@ -1655,1 +1729,1 @@\n-      \/\/ For a 0 index, give a NULL symbol\n+      \/\/ For a 0 index, give a null symbol\n@@ -1657,1 +1731,1 @@\n-        mh->constants()->symbol_at(params[i].name_cp_index) : NULL;\n+        mh->constants()->symbol_at(params[i].name_cp_index) : nullptr;\n@@ -1724,1 +1798,1 @@\n-  if (k != NULL && k->is_instance_klass()) {\n+  if (k != nullptr && k->is_instance_klass()) {\n@@ -1734,1 +1808,1 @@\n-\/\/ or NULL if the attribute is not present.\n+\/\/ or null if the attribute is not present.\n@@ -1745,1 +1819,1 @@\n-  if (components != NULL) {\n+  if (components != nullptr) {\n@@ -1756,1 +1830,1 @@\n-      assert(component != NULL, \"unexpected NULL record component\");\n+      assert(component != nullptr, \"unexpected null record component\");\n@@ -1763,1 +1837,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1830,1 +1904,1 @@\n-      result->obj_at_put(i, NULL);\n+      result->obj_at_put(i, nullptr);\n@@ -1893,1 +1967,1 @@\n-  return (jclass) (host == NULL ? NULL :\n+  return (jclass) (host == nullptr ? nullptr :\n@@ -1912,1 +1986,1 @@\n-    int length = members == NULL ? 0 : members->length();\n+    int length = members == nullptr ? 0 : members->length();\n@@ -1928,1 +2002,1 @@\n-            return NULL; \/\/ propagate VMEs\n+            return nullptr; \/\/ propagate VMEs\n@@ -2004,1 +2078,1 @@\n-          return NULL; \/\/ propagate VMEs\n+          return nullptr; \/\/ propagate VMEs\n@@ -2034,1 +2108,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -2055,1 +2129,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -2090,1 +2164,1 @@\n-  if (k == NULL) return NULL;\n+  if (k == nullptr) return nullptr;\n@@ -2106,1 +2180,1 @@\n-    if (k_o == NULL) return NULL;\n+    if (k_o == nullptr) return nullptr;\n@@ -2155,1 +2229,1 @@\n-    if (k_o == NULL) return NULL;\n+    if (k_o == nullptr) return nullptr;\n@@ -2162,1 +2236,1 @@\n-  if (target_klass == NULL) {\n+  if (target_klass == nullptr) {\n@@ -2364,1 +2438,1 @@\n-  assert(cls != NULL, \"bad class\");\n+  assert(cls != nullptr, \"bad class\");\n@@ -2376,1 +2450,1 @@\n-  bool system_class = k->class_loader() == NULL;\n+  bool system_class = k->class_loader() == nullptr;\n@@ -2598,1 +2672,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -2614,1 +2688,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -2630,1 +2704,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -2645,1 +2719,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -2672,1 +2746,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -2691,1 +2765,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -2805,1 +2879,1 @@\n-  if (Arguments::vfprintf_hook() != NULL) {\n+  if (Arguments::vfprintf_hook() != nullptr) {\n@@ -2825,1 +2899,1 @@\n-  if (Arguments::vfprintf_hook() != NULL) {\n+  if (Arguments::vfprintf_hook() != nullptr) {\n@@ -2829,1 +2903,1 @@\n-    size_t count = ::write(defaultStream::output_fd(), s, (int)len);\n+    bool dummy = os::write(defaultStream::output_fd(), s, len);\n@@ -2858,1 +2932,21 @@\n-  JavaThread *native_thread = NULL;\n+#if INCLUDE_CDS\n+  if (DumpSharedSpaces) {\n+    \/\/ During java -Xshare:dump, if we allow multiple Java threads to\n+    \/\/ execute in parallel, symbols and classes may be loaded in\n+    \/\/ random orders which will make the resulting CDS archive\n+    \/\/ non-deterministic.\n+    \/\/\n+    \/\/ Lucikly, during java -Xshare:dump, it's important to run only\n+    \/\/ the code in the main Java thread (which is NOT started here) that\n+    \/\/ creates the module graph, etc. It's safe to not start the other\n+    \/\/ threads which are launched by class static initializers\n+    \/\/ (ReferenceHandler, FinalizerThread and CleanerImpl).\n+    if (log_is_enabled(Info, cds)) {\n+      ResourceMark rm;\n+      oop t = JNIHandles::resolve_non_null(jthread);\n+      log_info(cds)(\"JVM_StartThread() ignored: %s\", t->klass()->external_name());\n+    }\n+    return;\n+  }\n+#endif\n+  JavaThread *native_thread = nullptr;\n@@ -2878,1 +2972,1 @@\n-    if (java_lang_Thread::thread(JNIHandles::resolve_non_null(jthread)) != NULL) {\n+    if (java_lang_Thread::thread(JNIHandles::resolve_non_null(jthread)) != nullptr) {\n@@ -2881,3 +2975,0 @@\n-      \/\/ We could also check the stillborn flag to see if this thread was already stopped, but\n-      \/\/ for historical reasons we let the thread detect that itself when it starts running\n-\n@@ -2901,1 +2992,1 @@\n-      if (native_thread->osthread() != NULL) {\n+      if (native_thread->osthread() != nullptr) {\n@@ -2912,1 +3003,1 @@\n-  assert(native_thread != NULL, \"Starting null thread?\");\n+  assert(native_thread != nullptr, \"Starting null thread?\");\n@@ -2914,1 +3005,4 @@\n-  if (native_thread->osthread() == NULL) {\n+  if (native_thread->osthread() == nullptr) {\n+    ResourceMark rm(thread);\n+    log_warning(os, thread)(\"Failed to start the native thread for java.lang.Thread \\\"%s\\\"\",\n+                            JavaThread::name_for(JNIHandles::resolve_non_null(jthread)));\n@@ -2926,8 +3020,1 @@\n-#if INCLUDE_JFR\n-  if (Jfr::is_recording() && EventThreadStart::is_enabled() &&\n-      EventThreadStart::is_stacktrace_enabled()) {\n-    JfrThreadLocal* tl = native_thread->jfr_thread_local();\n-    \/\/ skip Thread.start() and Thread.start0()\n-    tl->set_cached_stack_trace_id(JfrStackTraceRepository::record(thread, 2));\n-  }\n-#endif\n+  JFR_ONLY(Jfr::on_java_thread_start(thread, native_thread);)\n@@ -2940,68 +3027,0 @@\n-\/\/ JVM_Stop is implemented using a VM_Operation, so threads are forced to safepoints\n-\/\/ before the quasi-asynchronous exception is delivered.  This is a little obtrusive,\n-\/\/ but is thought to be reliable and simple. In the case, where the receiver is the\n-\/\/ same thread as the sender, no VM_Operation is needed.\n-JVM_ENTRY(void, JVM_StopThread(JNIEnv* env, jobject jthread, jobject throwable))\n-  ThreadsListHandle tlh(thread);\n-  oop java_throwable = JNIHandles::resolve(throwable);\n-  if (java_throwable == NULL) {\n-    THROW(vmSymbols::java_lang_NullPointerException());\n-  }\n-  oop java_thread = NULL;\n-  JavaThread* receiver = NULL;\n-  bool is_alive = tlh.cv_internal_thread_to_JavaThread(jthread, &receiver, &java_thread);\n-  Events::log_exception(thread,\n-                        \"JVM_StopThread thread JavaThread \" INTPTR_FORMAT \" as oop \" INTPTR_FORMAT \" [exception \" INTPTR_FORMAT \"]\",\n-                        p2i(receiver), p2i(java_thread), p2i(throwable));\n-\n-  if (is_alive) {\n-    \/\/ jthread refers to a live JavaThread.\n-    if (thread == receiver) {\n-      \/\/ Exception is getting thrown at self so no VM_Operation needed.\n-      THROW_OOP(java_throwable);\n-    } else {\n-      \/\/ Use a VM_Operation to throw the exception.\n-      JavaThread::send_async_exception(java_thread, java_throwable);\n-    }\n-  } else {\n-    \/\/ Either:\n-    \/\/ - target thread has not been started before being stopped, or\n-    \/\/ - target thread already terminated\n-    \/\/ We could read the threadStatus to determine which case it is\n-    \/\/ but that is overkill as it doesn't matter. We must set the\n-    \/\/ stillborn flag for the first case, and if the thread has already\n-    \/\/ exited setting this flag has no effect.\n-    java_lang_Thread::set_stillborn(java_thread);\n-  }\n-JVM_END\n-\n-\n-JVM_ENTRY(jboolean, JVM_IsThreadAlive(JNIEnv* env, jobject jthread))\n-  oop thread_oop = JNIHandles::resolve_non_null(jthread);\n-  return java_lang_Thread::is_alive(thread_oop);\n-JVM_END\n-\n-\n-JVM_ENTRY(void, JVM_SuspendThread(JNIEnv* env, jobject jthread))\n-  ThreadsListHandle tlh(thread);\n-  JavaThread* receiver = NULL;\n-  bool is_alive = tlh.cv_internal_thread_to_JavaThread(jthread, &receiver, NULL);\n-  if (is_alive) {\n-    \/\/ jthread refers to a live JavaThread, but java_suspend() will\n-    \/\/ detect a thread that has started to exit and will ignore it.\n-    receiver->java_suspend();\n-  }\n-JVM_END\n-\n-\n-JVM_ENTRY(void, JVM_ResumeThread(JNIEnv* env, jobject jthread))\n-  ThreadsListHandle tlh(thread);\n-  JavaThread* receiver = NULL;\n-  bool is_alive = tlh.cv_internal_thread_to_JavaThread(jthread, &receiver, NULL);\n-  if (is_alive) {\n-    \/\/ jthread refers to a live JavaThread.\n-    receiver->java_resume();\n-  }\n-JVM_END\n-\n-\n@@ -3010,2 +3029,2 @@\n-  oop java_thread = NULL;\n-  JavaThread* receiver = NULL;\n+  oop java_thread = nullptr;\n+  JavaThread* receiver = nullptr;\n@@ -3025,1 +3044,1 @@\n-JVM_ENTRY(void, JVM_Yield(JNIEnv *env, jclass threadClass))\n+JVM_LEAF(void, JVM_Yield(JNIEnv *env, jclass threadClass))\n@@ -3031,10 +3050,3 @@\n-static void post_thread_sleep_event(EventThreadSleep* event, jlong millis) {\n-  assert(event != NULL, \"invariant\");\n-  assert(event->should_commit(), \"invariant\");\n-  event->set_time(millis);\n-  event->commit();\n-}\n-\n-JVM_ENTRY(void, JVM_Sleep(JNIEnv* env, jclass threadClass, jlong millis))\n-  if (millis < 0) {\n-    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), \"timeout value is negative\");\n+JVM_ENTRY(void, JVM_Sleep(JNIEnv* env, jclass threadClass, jlong nanos))\n+  if (nanos < 0) {\n+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), \"nanosecond timeout value out of range\");\n@@ -3051,2 +3063,1 @@\n-  HOTSPOT_THREAD_SLEEP_BEGIN(millis);\n-  EventThreadSleep event;\n+  HOTSPOT_THREAD_SLEEP_BEGIN(nanos \/ NANOSECS_PER_MILLISEC);\n@@ -3054,1 +3065,1 @@\n-  if (millis == 0) {\n+  if (nanos == 0) {\n@@ -3059,2 +3070,2 @@\n-    if (!thread->sleep(millis)) { \/\/ interrupted\n-      \/\/ An asynchronous exception (e.g., ThreadDeathException) could have been thrown on\n+    if (!thread->sleep_nanos(nanos)) { \/\/ interrupted\n+      \/\/ An asynchronous exception could have been thrown on\n@@ -3063,3 +3074,0 @@\n-        if (event.should_commit()) {\n-          post_thread_sleep_event(&event, millis);\n-        }\n@@ -3075,3 +3083,0 @@\n-  if (event.should_commit()) {\n-    post_thread_sleep_event(&event, millis);\n-  }\n@@ -3081,1 +3086,1 @@\n-JVM_ENTRY(jobject, JVM_CurrentThread(JNIEnv* env, jclass threadClass))\n+JVM_ENTRY(jobject, JVM_CurrentCarrierThread(JNIEnv* env, jclass threadClass))\n@@ -3083,1 +3088,1 @@\n-  assert(jthread != NULL, \"no current thread!\");\n+  assert(jthread != nullptr, \"no current carrier thread!\");\n@@ -3087,0 +3092,17 @@\n+JVM_ENTRY(jobject, JVM_CurrentThread(JNIEnv* env, jclass threadClass))\n+  oop theThread = thread->vthread();\n+  assert(theThread != (oop)nullptr, \"no current thread!\");\n+  return JNIHandles::make_local(THREAD, theThread);\n+JVM_END\n+\n+JVM_ENTRY(void, JVM_SetCurrentThread(JNIEnv* env, jobject thisThread,\n+                                     jobject theThread))\n+  oop threadObj = JNIHandles::resolve(theThread);\n+  thread->set_vthread(threadObj);\n+  JFR_ONLY(Jfr::on_set_current_thread(thread, threadObj);)\n+JVM_END\n+\n+JVM_ENTRY(jlong, JVM_GetNextThreadIdOffset(JNIEnv* env, jclass threadClass))\n+  return ThreadIdentifier::unsafe_offset();\n+JVM_END\n+\n@@ -3089,2 +3111,2 @@\n-  JavaThread* receiver = NULL;\n-  bool is_alive = tlh.cv_internal_thread_to_JavaThread(jthread, &receiver, NULL);\n+  JavaThread* receiver = nullptr;\n+  bool is_alive = tlh.cv_internal_thread_to_JavaThread(jthread, &receiver, nullptr);\n@@ -3097,1 +3119,0 @@\n-\n@@ -3101,1 +3122,1 @@\n-  if (obj == NULL) {\n+  if (obj == nullptr) {\n@@ -3108,0 +3129,4 @@\n+JVM_ENTRY(jobject, JVM_GetStackTrace(JNIEnv *env, jobject jthread))\n+  oop trace = java_lang_Thread::async_get_stack_trace(JNIHandles::resolve(jthread), THREAD);\n+  return JNIHandles::make_local(THREAD, trace);\n+JVM_END\n@@ -3132,0 +3157,11 @@\n+JVM_ENTRY(jobject, JVM_ScopedValueCache(JNIEnv* env, jclass threadClass))\n+  oop theCache = thread->scopedValueCache();\n+  return JNIHandles::make_local(THREAD, theCache);\n+JVM_END\n+\n+JVM_ENTRY(void, JVM_SetScopedValueCache(JNIEnv* env, jclass threadClass,\n+                                       jobject theCache))\n+  arrayOop objs = arrayOop(JNIHandles::resolve(theCache));\n+  thread->set_scopedValueCache(objs);\n+JVM_END\n+\n@@ -3139,1 +3175,1 @@\n-  if (vmClasses::reflect_CallerSensitive_klass() != NULL) {\n+  if (vmClasses::reflect_CallerSensitive_klass() != nullptr) {\n@@ -3205,1 +3241,1 @@\n-  if (ref != NULL) {\n+  if (ref != nullptr) {\n@@ -3225,0 +3261,3 @@\n+  \/\/ PhantomReference has it's own implementation of refersTo().\n+  \/\/ See: JVM_PhantomReferenceRefersTo\n+  assert(!java_lang_ref_Reference::is_phantom(ref_oop), \"precondition\");\n@@ -3233,1 +3272,1 @@\n-  if (java_lang_ref_Reference::unknown_referent_no_keepalive(ref_oop) == NULL) {\n+  if (java_lang_ref_Reference::unknown_referent_no_keepalive(ref_oop) == nullptr) {\n@@ -3267,1 +3306,1 @@\n-    if (loader != NULL && !SystemDictionary::is_platform_class_loader(loader)) {\n+    if (loader != nullptr && !SystemDictionary::is_platform_class_loader(loader)) {\n@@ -3275,1 +3314,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -3284,1 +3323,1 @@\n-  if (arr == NULL) {\n+  if (arr == nullptr) {\n@@ -3371,1 +3410,6 @@\n-JVM_ENTRY_NO_ENV(void*, JVM_LoadLibrary(const char* name))\n+JVM_LEAF(void*, JVM_LoadZipLibrary())\n+  ClassLoader::load_zip_library_if_needed();\n+  return ClassLoader::zip_library_handle();\n+JVM_END\n+\n+JVM_ENTRY_NO_ENV(void*, JVM_LoadLibrary(const char* name, jboolean throwException))\n@@ -3379,13 +3423,18 @@\n-  if (load_result == NULL) {\n-    char msg[1024];\n-    jio_snprintf(msg, sizeof msg, \"%s: %s\", name, ebuf);\n-    \/\/ Since 'ebuf' may contain a string encoded using\n-    \/\/ platform encoding scheme, we need to pass\n-    \/\/ Exceptions::unsafe_to_utf8 to the new_exception method\n-    \/\/ as the last argument. See bug 6367357.\n-    Handle h_exception =\n-      Exceptions::new_exception(thread,\n-                                vmSymbols::java_lang_UnsatisfiedLinkError(),\n-                                msg, Exceptions::unsafe_to_utf8);\n-\n-    THROW_HANDLE_0(h_exception);\n+  if (load_result == nullptr) {\n+    if (throwException) {\n+      char msg[1024];\n+      jio_snprintf(msg, sizeof msg, \"%s: %s\", name, ebuf);\n+      \/\/ Since 'ebuf' may contain a string encoded using\n+      \/\/ platform encoding scheme, we need to pass\n+      \/\/ Exceptions::unsafe_to_utf8 to the new_exception method\n+      \/\/ as the last argument. See bug 6367357.\n+      Handle h_exception =\n+        Exceptions::new_exception(thread,\n+                                  vmSymbols::java_lang_UnsatisfiedLinkError(),\n+                                  msg, Exceptions::unsafe_to_utf8);\n+\n+      THROW_HANDLE_0(h_exception);\n+    } else {\n+      log_info(library)(\"Failed to load library %s\", name);\n+      return load_result;\n+    }\n@@ -3407,1 +3456,1 @@\n-                    find_result != NULL ? \"Found\" : \"Failed to find\",\n+                    find_result != nullptr ? \"Found\" : \"Failed to find\",\n@@ -3420,0 +3469,12 @@\n+JVM_LEAF(jboolean, JVM_IsPreviewEnabled(void))\n+  return Arguments::enable_preview() ? JNI_TRUE : JNI_FALSE;\n+JVM_END\n+\n+JVM_LEAF(jboolean, JVM_IsContinuationsSupported(void))\n+  return VMContinuations ? JNI_TRUE : JNI_FALSE;\n+JVM_END\n+\n+JVM_LEAF(jboolean, JVM_IsForeignLinkerSupported(void))\n+  return ForeignGlobals::is_foreign_linker_supported() ? JNI_TRUE : JNI_FALSE;\n+JVM_END\n+\n@@ -3424,1 +3485,1 @@\n-  if (str == NULL) return NULL;\n+  if (str == nullptr) return nullptr;\n@@ -3442,1 +3503,1 @@\n-  void *mon = new os::PlatformMutex();\n+  void *mon = new PlatformMutex();\n@@ -3451,1 +3512,1 @@\n-  delete ((os::PlatformMutex*) mon);\n+  delete ((PlatformMutex*) mon);\n@@ -3457,1 +3518,1 @@\n-  ((os::PlatformMutex*) mon)->lock();\n+  ((PlatformMutex*) mon)->lock();\n@@ -3466,1 +3527,1 @@\n-  ((os::PlatformMutex*) mon)->unlock();\n+  ((PlatformMutex*) mon)->unlock();\n@@ -3477,1 +3538,1 @@\n-  \/\/   us to pass the NULL as the initiating class loader.  The VM is responsible for\n+  \/\/   us to pass the null as the initiating class loader.  The VM is responsible for\n@@ -3479,1 +3540,1 @@\n-  \/\/   protection_domain. The protection_domain is passed as NULL by the java code\n+  \/\/   protection_domain. The protection_domain is passed as null by the java code\n@@ -3503,1 +3564,1 @@\n-      assert(ret_type != NULL, \"sanity check: ret_type oop must not be NULL!\");\n+      assert(ret_type != nullptr, \"sanity check: ret_type oop must not be null!\");\n@@ -3537,1 +3598,1 @@\n-  HeapShared::initialize_from_archived_subgraph(k, THREAD);\n+  HeapShared::initialize_from_archived_subgraph(THREAD, k);\n@@ -3566,2 +3627,2 @@\n-  Symbol* interface_method_name = NULL;\n-  if (interfaceMethodName != NULL) {\n+  Symbol* interface_method_name = nullptr;\n+  if (interfaceMethodName != nullptr) {\n@@ -3597,3 +3658,3 @@\n-  if (interfaceMethodName == NULL || factoryType == NULL || interfaceMethodType == NULL ||\n-      implementationMember == NULL || dynamicMethodType == NULL) {\n-    THROW_(vmSymbols::java_lang_NullPointerException(), NULL);\n+  if (interfaceMethodName == nullptr || factoryType == nullptr || interfaceMethodType == nullptr ||\n+      implementationMember == nullptr || dynamicMethodType == nullptr) {\n+    THROW_(vmSymbols::java_lang_NullPointerException(), nullptr);\n@@ -3606,1 +3667,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -3625,2 +3686,2 @@\n-  jclass jcls = NULL;\n-  if (lambda_ik != NULL) {\n+  jclass jcls = nullptr;\n+  if (lambda_ik != nullptr) {\n@@ -3628,1 +3689,1 @@\n-    jcls = loaded_lambda == NULL ? NULL : (jclass) JNIHandles::make_local(THREAD, loaded_lambda->java_mirror());\n+    jcls = loaded_lambda == nullptr ? nullptr : (jclass) JNIHandles::make_local(THREAD, loaded_lambda->java_mirror());\n@@ -3632,1 +3693,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -3636,1 +3697,1 @@\n-JVM_ENTRY(jboolean, JVM_IsCDSDumpingEnabled(JNIEnv* env))\n+JVM_LEAF(jboolean, JVM_IsCDSDumpingEnabled(JNIEnv* env))\n@@ -3640,1 +3701,1 @@\n-JVM_ENTRY(jboolean, JVM_IsSharingEnabled(JNIEnv* env))\n+JVM_LEAF(jboolean, JVM_IsSharingEnabled(JNIEnv* env))\n@@ -3646,2 +3707,2 @@\n-    const char* release = Abstract_VM_Version::vm_release();\n-    const char* dbg_level = Abstract_VM_Version::jdk_debug_level();\n+    const char* release = VM_Version::vm_release();\n+    const char* dbg_level = VM_Version::jdk_debug_level();\n@@ -3652,4 +3713,4 @@\n-    seed += (jlong)Abstract_VM_Version::vm_major_version();\n-    seed += (jlong)Abstract_VM_Version::vm_minor_version();\n-    seed += (jlong)Abstract_VM_Version::vm_security_version();\n-    seed += (jlong)Abstract_VM_Version::vm_patch_version();\n+    seed += (jlong)VM_Version::vm_major_version();\n+    seed += (jlong)VM_Version::vm_minor_version();\n+    seed += (jlong)VM_Version::vm_security_version();\n+    seed += (jlong)VM_Version::vm_patch_version();\n@@ -3666,1 +3727,1 @@\n-JVM_ENTRY(jboolean, JVM_IsDumpingClassList(JNIEnv *env))\n+JVM_LEAF(jboolean, JVM_IsDumpingClassList(JNIEnv *env))\n@@ -3677,1 +3738,1 @@\n-  if (line != NULL) {\n+  if (line != nullptr) {\n@@ -3682,1 +3743,1 @@\n-      \/\/ Note: LambdaFormInvokers::append_filtered and LambdaFormInvokers::append take same format which is not\n+      \/\/ Note: LambdaFormInvokers::append take same format which is not\n@@ -3684,1 +3745,1 @@\n-      LambdaFormInvokers::append_filtered(os::strdup((const char*)c_line, mtInternal));\n+      LambdaFormInvokers::append(os::strdup((const char*)c_line, mtInternal));\n@@ -3708,1 +3769,1 @@\n-  DynamicArchive::dump(archive_name, CHECK);\n+  DynamicArchive::dump_for_jcmd(archive_name, CHECK);\n@@ -3740,1 +3801,1 @@\n-  if (threads == NULL) {\n+  if (threads == nullptr) {\n@@ -3775,1 +3836,1 @@\n-JVM_ENTRY_NO_ENV(void*, JVM_GetManagement(jint version))\n+JVM_LEAF(void*, JVM_GetManagement(jint version))\n@@ -3797,2 +3858,2 @@\n-  if (ofClass == NULL) {\n-    return NULL;\n+  if (ofClass == nullptr) {\n+    return nullptr;\n@@ -3803,1 +3864,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -3807,1 +3868,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -3812,1 +3873,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -3840,1 +3901,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -3864,1 +3925,1 @@\n-JVM_ENTRY_NO_ENV(jint, JVM_FindSignal(const char *name))\n+JVM_LEAF(jint, JVM_FindSignal(const char *name))\n@@ -3867,0 +3928,122 @@\n+\n+JVM_ENTRY(void, JVM_VirtualThreadStart(JNIEnv* env, jobject vthread))\n+#if INCLUDE_JVMTI\n+  if (!DoJVMTIVirtualThreadTransitions) {\n+    assert(!JvmtiExport::can_support_virtual_threads(), \"sanity check\");\n+    return;\n+  }\n+  if (JvmtiVTMSTransitionDisabler::VTMS_notify_jvmti_events()) {\n+    JvmtiVTMSTransitionDisabler::VTMS_vthread_start(vthread);\n+  } else {\n+    \/\/ set VTMS transition bit value in JavaThread and java.lang.VirtualThread object\n+    JvmtiVTMSTransitionDisabler::set_is_in_VTMS_transition(thread, vthread, false);\n+  }\n+#else\n+  fatal(\"Should only be called with JVMTI enabled\");\n+#endif\n+JVM_END\n+\n+JVM_ENTRY(void, JVM_VirtualThreadEnd(JNIEnv* env, jobject vthread))\n+#if INCLUDE_JVMTI\n+  if (!DoJVMTIVirtualThreadTransitions) {\n+    assert(!JvmtiExport::can_support_virtual_threads(), \"sanity check\");\n+    return;\n+  }\n+  if (JvmtiVTMSTransitionDisabler::VTMS_notify_jvmti_events()) {\n+    JvmtiVTMSTransitionDisabler::VTMS_vthread_end(vthread);\n+  } else {\n+    \/\/ set VTMS transition bit value in JavaThread and java.lang.VirtualThread object\n+    JvmtiVTMSTransitionDisabler::set_is_in_VTMS_transition(thread, vthread, true);\n+  }\n+#else\n+  fatal(\"Should only be called with JVMTI enabled\");\n+#endif\n+JVM_END\n+\n+\/\/ If notifications are disabled then just update the VTMS transition bit and return.\n+\/\/ Otherwise, the bit is updated in the given jvmtiVTMSTransitionDisabler function call.\n+JVM_ENTRY(void, JVM_VirtualThreadMount(JNIEnv* env, jobject vthread, jboolean hide))\n+#if INCLUDE_JVMTI\n+  if (!DoJVMTIVirtualThreadTransitions) {\n+    assert(!JvmtiExport::can_support_virtual_threads(), \"sanity check\");\n+    return;\n+  }\n+  if (JvmtiVTMSTransitionDisabler::VTMS_notify_jvmti_events()) {\n+    JvmtiVTMSTransitionDisabler::VTMS_vthread_mount(vthread, hide);\n+  } else {\n+    \/\/ set VTMS transition bit value in JavaThread and java.lang.VirtualThread object\n+    JvmtiVTMSTransitionDisabler::set_is_in_VTMS_transition(thread, vthread, hide);\n+  }\n+#else\n+  fatal(\"Should only be called with JVMTI enabled\");\n+#endif\n+JVM_END\n+\n+\/\/ If notifications are disabled then just update the VTMS transition bit and return.\n+\/\/ Otherwise, the bit is updated in the given jvmtiVTMSTransitionDisabler function call below.\n+JVM_ENTRY(void, JVM_VirtualThreadUnmount(JNIEnv* env, jobject vthread, jboolean hide))\n+#if INCLUDE_JVMTI\n+  if (!DoJVMTIVirtualThreadTransitions) {\n+    assert(!JvmtiExport::can_support_virtual_threads(), \"sanity check\");\n+    return;\n+  }\n+  if (JvmtiVTMSTransitionDisabler::VTMS_notify_jvmti_events()) {\n+    JvmtiVTMSTransitionDisabler::VTMS_vthread_unmount(vthread, hide);\n+  } else {\n+    \/\/ set VTMS transition bit value in JavaThread and java.lang.VirtualThread object\n+    JvmtiVTMSTransitionDisabler::set_is_in_VTMS_transition(thread, vthread, hide);\n+  }\n+#else\n+  fatal(\"Should only be called with JVMTI enabled\");\n+#endif\n+JVM_END\n+\n+\/\/ Always update the temporary VTMS transition bit.\n+JVM_ENTRY(void, JVM_VirtualThreadHideFrames(JNIEnv* env, jobject vthread, jboolean hide))\n+#if INCLUDE_JVMTI\n+  if (!DoJVMTIVirtualThreadTransitions) {\n+    assert(!JvmtiExport::can_support_virtual_threads(), \"sanity check\");\n+    return;\n+  }\n+  assert(!thread->is_in_VTMS_transition(), \"sanity check\");\n+  assert(thread->is_in_tmp_VTMS_transition() != (bool)hide, \"sanity check\");\n+  thread->toggle_is_in_tmp_VTMS_transition();\n+#else\n+  fatal(\"Should only be called with JVMTI enabled\");\n+#endif\n+JVM_END\n+\n+\/*\n+ * Return the current class's class file version.  The low order 16 bits of the\n+ * returned jint contain the class's major version.  The high order 16 bits\n+ * contain the class's minor version.\n+ *\/\n+JVM_ENTRY(jint, JVM_GetClassFileVersion(JNIEnv* env, jclass current))\n+  oop mirror = JNIHandles::resolve_non_null(current);\n+  if (java_lang_Class::is_primitive(mirror)) {\n+    \/\/ return latest major version and minor version of 0.\n+    return JVM_CLASSFILE_MAJOR_VERSION;\n+  }\n+  assert(!java_lang_Class::as_Klass(mirror)->is_array_klass(), \"unexpected array class\");\n+\n+  Klass* c = java_lang_Class::as_Klass(mirror);\n+  assert(c->is_instance_klass(), \"must be\");\n+  InstanceKlass* ik = InstanceKlass::cast(c);\n+  return (ik->minor_version() << 16) | ik->major_version();\n+JVM_END\n+\n+\/*\n+ * Ensure that code doing a stackwalk and using javaVFrame::locals() to\n+ * get the value will see a materialized value and not a scalar-replaced\n+ * null value.\n+ *\/\n+JVM_ENTRY(void, JVM_EnsureMaterializedForStackWalk_func(JNIEnv* env, jobject vthread, jobject value))\n+  JVM_EnsureMaterializedForStackWalk(env, value);\n+JVM_END\n+\n+\/*\n+ * Return JNI_TRUE if warnings are printed when agents are dynamically loaded.\n+ *\/\n+JVM_LEAF(jboolean, JVM_PrintWarningAtDynamicAgentLoad(void))\n+  return (EnableDynamicAgentLoading && !FLAG_IS_CMDLINE(EnableDynamicAgentLoading)) ? JNI_TRUE : JNI_FALSE;\n+JVM_END\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":508,"deletions":325,"binary":false,"changes":833,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -40,0 +40,1 @@\n+#include \"memory\/allocation.hpp\"\n@@ -66,0 +67,1 @@\n+#include \"runtime\/javaThread.inline.hpp\"\n@@ -69,0 +71,1 @@\n+#include \"runtime\/os.hpp\"\n@@ -72,1 +75,1 @@\n-#include \"runtime\/thread.inline.hpp\"\n+#include \"runtime\/threads.hpp\"\n@@ -133,1 +136,1 @@\n-\/\/ mem_ptr - pre-checked for NULL\n+\/\/ mem_ptr - pre-checked for null\n@@ -140,1 +143,1 @@\n-\/\/ mem - NULL is a valid value, must be checked\n+\/\/ mem - null is a valid value, must be checked\n@@ -146,2 +149,2 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n-\/\/ data - NULL is a valid value, must be checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n+\/\/ data - null is a valid value, must be checked\n@@ -149,5 +152,21 @@\n-JvmtiEnv::SetThreadLocalStorage(JavaThread* java_thread, const void* data) {\n-  JvmtiThreadState* state = java_thread->jvmti_thread_state();\n-  if (state == NULL) {\n-    if (data == NULL) {\n-      \/\/ leaving state unset same as data set to NULL\n+JvmtiEnv::SetThreadLocalStorage(jthread thread, const void* data) {\n+  JavaThread* current = JavaThread::current();\n+  JvmtiThreadState* state = nullptr;\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(current);\n+\n+  JavaThread* java_thread = nullptr;\n+  oop thread_obj = nullptr;\n+  if (thread == nullptr) {\n+    java_thread = current;\n+    state = java_thread->jvmti_thread_state();\n+  } else {\n+    jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n+    if (err != JVMTI_ERROR_NONE) {\n+      return err;\n+    }\n+    state = java_lang_Thread::jvmti_thread_state(thread_obj);\n+  }\n+  if (state == nullptr) {\n+    if (data == nullptr) {\n+      \/\/ leaving state unset same as data set to null\n@@ -157,2 +176,4 @@\n-    state = JvmtiThreadState::state_for(java_thread);\n-    if (state == NULL) {\n+    HandleMark hm(current);\n+    Handle thread_handle(current, thread_obj);\n+    state = JvmtiThreadState::state_for(java_thread, thread_handle);\n+    if (state == nullptr) {\n@@ -168,1 +189,1 @@\n-\/\/ data_ptr - pre-checked for NULL\n+\/\/ data_ptr - pre-checked for null\n@@ -172,1 +193,1 @@\n-  if (thread == NULL) {\n+  if (thread == nullptr) {\n@@ -174,1 +195,1 @@\n-    *data_ptr = (state == NULL) ? NULL :\n+    *data_ptr = (state == nullptr) ? nullptr :\n@@ -187,1 +208,1 @@\n-    JavaThread* java_thread = NULL;\n+    JvmtiVTMSTransitionDisabler disabler(thread);\n@@ -189,1 +210,4 @@\n-    jvmtiError err = JvmtiExport::cv_external_thread_to_JavaThread(tlh.list(), thread, &java_thread, NULL);\n+\n+    JavaThread* java_thread = nullptr;\n+    oop thread_obj = nullptr;\n+    jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n@@ -194,2 +218,4 @@\n-    JvmtiThreadState* state = java_thread->jvmti_thread_state();\n-    *data_ptr = (state == NULL) ? NULL :\n+    HandleMark hm(current_thread);\n+    Handle thread_handle(current_thread, thread_obj);\n+    JvmtiThreadState* state = JvmtiThreadState::state_for(java_thread, thread_handle);\n+    *data_ptr = (state == nullptr) ? nullptr :\n@@ -205,2 +231,2 @@\n-\/\/ module_count_ptr - pre-checked for NULL\n-\/\/ modules_ptr - pre-checked for NULL\n+\/\/ module_count_ptr - pre-checked for null\n+\/\/ modules_ptr - pre-checked for null\n@@ -215,3 +241,3 @@\n-\/\/ class_loader - NULL is a valid value, must be pre-checked\n-\/\/ package_name - pre-checked for NULL\n-\/\/ module_ptr - pre-checked for NULL\n+\/\/ class_loader - null is a valid value, must be pre-checked\n+\/\/ package_name - pre-checked for null\n+\/\/ module_ptr - pre-checked for null\n@@ -222,0 +248,1 @@\n+\n@@ -228,1 +255,1 @@\n-  *module_ptr = module != NULL ? JNIHandles::make_local(THREAD, module) : NULL;\n+  *module_ptr = module != nullptr ? JNIHandles::make_local(THREAD, module) : nullptr;\n@@ -233,2 +260,2 @@\n-\/\/ module - pre-checked for NULL\n-\/\/ to_module - pre-checked for NULL\n+\/\/ module - pre-checked for null\n+\/\/ to_module - pre-checked for null\n@@ -253,3 +280,3 @@\n-\/\/ module - pre-checked for NULL\n-\/\/ pkg_name - pre-checked for NULL\n-\/\/ to_module - pre-checked for NULL\n+\/\/ module - pre-checked for null\n+\/\/ pkg_name - pre-checked for null\n+\/\/ to_module - pre-checked for null\n@@ -275,3 +302,3 @@\n-\/\/ module - pre-checked for NULL\n-\/\/ pkg_name - pre-checked for NULL\n-\/\/ to_module - pre-checked for NULL\n+\/\/ module - pre-checked for null\n+\/\/ pkg_name - pre-checked for null\n+\/\/ to_module - pre-checked for null\n@@ -297,2 +324,2 @@\n-\/\/ module - pre-checked for NULL\n-\/\/ service - pre-checked for NULL\n+\/\/ module - pre-checked for null\n+\/\/ service - pre-checked for null\n@@ -318,3 +345,3 @@\n-\/\/ module - pre-checked for NULL\n-\/\/ service - pre-checked for NULL\n-\/\/ impl_class - pre-checked for NULL\n+\/\/ module - pre-checked for null\n+\/\/ service - pre-checked for null\n+\/\/ impl_class - pre-checked for null\n@@ -345,2 +372,2 @@\n-\/\/ module - pre-checked for NULL\n-\/\/ is_modifiable_class_ptr - pre-checked for NULL\n+\/\/ module - pre-checked for null\n+\/\/ is_modifiable_class_ptr - pre-checked for null\n@@ -366,2 +393,2 @@\n-\/\/ class_count_ptr - pre-checked for NULL\n-\/\/ classes_ptr - pre-checked for NULL\n+\/\/ class_count_ptr - pre-checked for null\n+\/\/ classes_ptr - pre-checked for null\n@@ -374,3 +401,3 @@\n-\/\/ initiating_loader - NULL is a valid value, must be checked\n-\/\/ class_count_ptr - pre-checked for NULL\n-\/\/ classes_ptr - pre-checked for NULL\n+\/\/ initiating_loader - null is a valid value, must be checked\n+\/\/ class_count_ptr - pre-checked for null\n+\/\/ classes_ptr - pre-checked for null\n@@ -384,1 +411,1 @@\n-\/\/ is_modifiable_class_ptr - pre-checked for NULL\n+\/\/ is_modifiable_class_ptr - pre-checked for null\n@@ -393,1 +420,1 @@\n-\/\/ classes - pre-checked for NULL\n+\/\/ classes - pre-checked for null\n@@ -411,1 +438,1 @@\n-    if (k_mirror == NULL) {\n+    if (k_mirror == nullptr) {\n@@ -430,1 +457,1 @@\n-    if (ik->get_cached_class_file_bytes() == NULL) {\n+    if (ik->get_cached_class_file_bytes() == nullptr) {\n@@ -464,1 +491,1 @@\n-\/\/ class_definitions - pre-checked for NULL\n+\/\/ class_definitions - pre-checked for null\n@@ -485,1 +512,1 @@\n-\/\/ size_ptr - pre-checked for NULL\n+\/\/ size_ptr - pre-checked for null\n@@ -498,1 +525,1 @@\n-\/\/ prefix - NULL is a valid value, must be checked\n+\/\/ prefix - null is a valid value, must be checked\n@@ -501,2 +528,2 @@\n-  return prefix == NULL?\n-              SetNativeMethodPrefixes(0, NULL) :\n+  return prefix == nullptr?\n+              SetNativeMethodPrefixes(0, nullptr) :\n@@ -508,1 +535,1 @@\n-\/\/ prefixes - pre-checked for NULL\n+\/\/ prefixes - pre-checked for null\n@@ -526,1 +553,1 @@\n-\/\/ callbacks - NULL is a valid value, must be checked\n+\/\/ callbacks - null is a valid value, must be checked\n@@ -530,0 +557,1 @@\n+  JvmtiVTMSTransitionDisabler disabler;\n@@ -535,1 +563,1 @@\n-\/\/ event_thread - NULL is a valid value, must be checked\n+\/\/ event_thread - null is a valid value, must be checked\n@@ -538,5 +566,1 @@\n-  if (event_thread == NULL) {\n-    \/\/ Can be called at Agent_OnLoad() time with event_thread == NULL\n-    \/\/ when Thread::current() does not work yet so we cannot create a\n-    \/\/ ThreadsListHandle that is common to both thread-specific and\n-    \/\/ global code paths.\n+  bool enabled = (mode == JVMTI_ENABLE);\n@@ -544,4 +568,4 @@\n-    \/\/ event_type must be valid\n-    if (!JvmtiEventController::is_valid_event_type(event_type)) {\n-      return JVMTI_ERROR_INVALID_EVENT_TYPE;\n-    }\n+  \/\/ event_type must be valid\n+  if (!JvmtiEventController::is_valid_event_type(event_type)) {\n+    return JVMTI_ERROR_INVALID_EVENT_TYPE;\n+  }\n@@ -549,1 +573,4 @@\n-    bool enabled = (mode == JVMTI_ENABLE);\n+  \/\/ assure that needed capabilities are present\n+  if (enabled && !JvmtiUtil::has_event_capability(event_type, get_capabilities())) {\n+    return JVMTI_ERROR_MUST_POSSESS_CAPABILITY;\n+  }\n@@ -551,4 +578,4 @@\n-    \/\/ assure that needed capabilities are present\n-    if (enabled && !JvmtiUtil::has_event_capability(event_type, get_capabilities())) {\n-      return JVMTI_ERROR_MUST_POSSESS_CAPABILITY;\n-    }\n+  if (event_type == JVMTI_EVENT_CLASS_FILE_LOAD_HOOK && enabled) {\n+    record_class_file_load_hook_enabled();\n+  }\n+  JvmtiVTMSTransitionDisabler disabler;\n@@ -556,3 +583,5 @@\n-    if (event_type == JVMTI_EVENT_CLASS_FILE_LOAD_HOOK && enabled) {\n-      record_class_file_load_hook_enabled();\n-    }\n+  if (event_thread == nullptr) {\n+    \/\/ Can be called at Agent_OnLoad() time with event_thread == nullptr\n+    \/\/ when Thread::current() does not work yet so we cannot create a\n+    \/\/ ThreadsListHandle that is common to both thread-specific and\n+    \/\/ global code paths.\n@@ -560,1 +589,1 @@\n-    JvmtiEventController::set_user_enabled(this, (JavaThread*) NULL, event_type, enabled);\n+    JvmtiEventController::set_user_enabled(this, nullptr, (oop) nullptr, event_type, enabled);\n@@ -563,2 +592,4 @@\n-    JavaThread* java_thread = NULL;\n-    jvmtiError err = JvmtiExport::cv_external_thread_to_JavaThread(tlh.list(), event_thread, &java_thread, NULL);\n+\n+    JavaThread* java_thread = nullptr;\n+    oop thread_obj = nullptr;\n+    jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), event_thread, &java_thread, &thread_obj);\n@@ -570,5 +601,0 @@\n-    \/\/ event_type must be valid\n-    if (!JvmtiEventController::is_valid_event_type(event_type)) {\n-      return JVMTI_ERROR_INVALID_EVENT_TYPE;\n-    }\n-\n@@ -580,11 +606,1 @@\n-    bool enabled = (mode == JVMTI_ENABLE);\n-\n-    \/\/ assure that needed capabilities are present\n-    if (enabled && !JvmtiUtil::has_event_capability(event_type, get_capabilities())) {\n-      return JVMTI_ERROR_MUST_POSSESS_CAPABILITY;\n-    }\n-\n-    if (event_type == JVMTI_EVENT_CLASS_FILE_LOAD_HOOK && enabled) {\n-      record_class_file_load_hook_enabled();\n-    }\n-    JvmtiEventController::set_user_enabled(this, java_thread, event_type, enabled);\n+    JvmtiEventController::set_user_enabled(this, java_thread, thread_obj, event_type, enabled);\n@@ -600,1 +616,1 @@\n-\/\/ capabilities_ptr - pre-checked for NULL\n+\/\/ capabilities_ptr - pre-checked for null\n@@ -610,1 +626,1 @@\n-\/\/ capabilities_ptr - pre-checked for NULL\n+\/\/ capabilities_ptr - pre-checked for null\n@@ -620,1 +636,1 @@\n-\/\/ capabilities_ptr - pre-checked for NULL\n+\/\/ capabilities_ptr - pre-checked for null\n@@ -628,1 +644,1 @@\n-\/\/ capabilities_ptr - pre-checked for NULL\n+\/\/ capabilities_ptr - pre-checked for null\n@@ -639,1 +655,1 @@\n-\/\/ segment - pre-checked for NULL\n+\/\/ segment - pre-checked for null\n@@ -658,1 +674,1 @@\n-    if (zip_entry == NULL) {\n+    if (zip_entry == nullptr) {\n@@ -677,1 +693,1 @@\n-\/\/ segment - pre-checked for NULL\n+\/\/ segment - pre-checked for null\n@@ -683,1 +699,1 @@\n-    for (SystemProperty* p = Arguments::system_properties(); p != NULL; p = p->next()) {\n+    for (SystemProperty* p = Arguments::system_properties(); p != nullptr; p = p->next()) {\n@@ -700,1 +716,1 @@\n-    if (zip_entry == NULL) {\n+    if (zip_entry == nullptr) {\n@@ -705,3 +721,1 @@\n-    \/\/ lock the loader\n-    Handle loader = Handle(THREAD, SystemDictionary::java_system_loader());\n-    ObjectLocker ol(loader, THREAD);\n+    Handle loader(THREAD, SystemDictionary::java_system_loader());\n@@ -750,1 +764,1 @@\n-\/\/ phase_ptr - pre-checked for NULL\n+\/\/ phase_ptr - pre-checked for null\n@@ -765,1 +779,1 @@\n-\/\/ data - NULL is a valid value, must be checked\n+\/\/ data - null is a valid value, must be checked\n@@ -773,1 +787,1 @@\n-\/\/ data_ptr - pre-checked for NULL\n+\/\/ data_ptr - pre-checked for null\n@@ -780,1 +794,1 @@\n-\/\/ version_ptr - pre-checked for NULL\n+\/\/ version_ptr - pre-checked for null\n@@ -788,1 +802,1 @@\n-\/\/ name_ptr - pre-checked for NULL\n+\/\/ name_ptr - pre-checked for null\n@@ -795,1 +809,1 @@\n-  if (name == NULL) {\n+  if (name == nullptr) {\n@@ -832,1 +846,1 @@\n-\/\/ format_ptr - pre-checked for NULL\n+\/\/ format_ptr - pre-checked for null\n@@ -844,1 +858,1 @@\n-\/\/ thread_state_ptr - pre-checked for NULL\n+\/\/ thread_state_ptr - pre-checked for null\n@@ -848,2 +862,1 @@\n-  JavaThread* java_thread = NULL;\n-  oop thread_oop = NULL;\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n@@ -852,18 +865,8 @@\n-  if (thread == NULL) {\n-    java_thread = current_thread;\n-    thread_oop = java_thread->threadObj();\n-\n-    if (thread_oop == NULL || !thread_oop->is_a(vmClasses::Thread_klass())) {\n-      return JVMTI_ERROR_INVALID_THREAD;\n-    }\n-  } else {\n-    jvmtiError err = JvmtiExport::cv_external_thread_to_JavaThread(tlh.list(), thread, &java_thread, &thread_oop);\n-    if (err != JVMTI_ERROR_NONE) {\n-      \/\/ We got an error code so we don't have a JavaThread *, but\n-      \/\/ only return an error from here if we didn't get a valid\n-      \/\/ thread_oop.\n-      if (thread_oop == NULL) {\n-        return err;\n-      }\n-      \/\/ We have a valid thread_oop so we can return some thread state.\n-    }\n+  JavaThread* java_thread = nullptr;\n+  oop thread_oop = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_oop);\n+  if (err != JVMTI_ERROR_NONE && err != JVMTI_ERROR_THREAD_NOT_ALIVE) {\n+    \/\/ We got an error code so we don't have a JavaThread*, but only\n+    \/\/ return an error from here if the error is not because the thread\n+    \/\/ is a virtual thread.\n+    return err;\n@@ -872,16 +875,4 @@\n-  \/\/ get most state bits\n-  jint state = (jint)java_lang_Thread::get_thread_status(thread_oop);\n-\n-  if (java_thread != NULL) {\n-    \/\/ We have a JavaThread* so add more state bits.\n-    JavaThreadState jts = java_thread->thread_state();\n-\n-    if (java_thread->is_suspended()) {\n-      state |= JVMTI_THREAD_STATE_SUSPENDED;\n-    }\n-    if (jts == _thread_in_native) {\n-      state |= JVMTI_THREAD_STATE_IN_NATIVE;\n-    }\n-    if (java_thread->is_interrupted(false)) {\n-      state |= JVMTI_THREAD_STATE_INTERRUPTED;\n-    }\n+  if (java_lang_VirtualThread::is_instance(thread_oop)) {\n+    *thread_state_ptr = JvmtiEnvBase::get_vthread_state(thread_oop, java_thread);\n+  } else {\n+    *thread_state_ptr = JvmtiEnvBase::get_thread_state(thread_oop, java_thread);\n@@ -889,2 +880,0 @@\n-\n-  *thread_state_ptr = state;\n@@ -895,1 +884,1 @@\n-\/\/ thread_ptr - pre-checked for NULL\n+\/\/ thread_ptr - pre-checked for null\n@@ -898,2 +887,4 @@\n-  JavaThread* current_thread  = JavaThread::current();\n-  *thread_ptr = (jthread)JNIHandles::make_local(current_thread, current_thread->threadObj());\n+  JavaThread* cur_thread = JavaThread::current();\n+  oop thread_oop = get_vthread_or_thread_oop(cur_thread);\n+\n+  *thread_ptr = (jthread)JNIHandles::make_local(cur_thread, thread_oop);\n@@ -904,2 +895,2 @@\n-\/\/ threads_count_ptr - pre-checked for NULL\n-\/\/ threads_ptr - pre-checked for NULL\n+\/\/ threads_count_ptr - pre-checked for null\n+\/\/ threads_ptr - pre-checked for null\n@@ -909,1 +900,1 @@\n-  Handle *thread_objs = NULL;\n+  Handle *thread_objs = nullptr;\n@@ -920,1 +911,1 @@\n-    *threads_ptr = NULL;\n+    *threads_ptr = nullptr;\n@@ -939,1 +930,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -941,13 +932,15 @@\n-JvmtiEnv::SuspendThread(JavaThread* java_thread) {\n-  \/\/ don't allow hidden thread suspend request.\n-  if (java_thread->is_hidden_from_external_view()) {\n-    return JVMTI_ERROR_NONE;\n-  }\n-  if (java_thread->is_suspended()) {\n-    return JVMTI_ERROR_THREAD_SUSPENDED;\n-  }\n-  if (!JvmtiSuspendControl::suspend(java_thread)) {\n-    \/\/ Either the thread is already suspended or\n-    \/\/ it was in the process of exiting.\n-    if (java_thread->is_exiting()) {\n-      return JVMTI_ERROR_THREAD_NOT_ALIVE;\n+JvmtiEnv::SuspendThread(jthread thread) {\n+  JavaThread* current = JavaThread::current();\n+  HandleMark hm(current);\n+  Handle self_tobj;\n+\n+  jvmtiError err;\n+  {\n+    JvmtiVTMSTransitionDisabler disabler(true);\n+    ThreadsListHandle tlh(current);\n+    JavaThread* java_thread = nullptr;\n+    oop thread_oop = nullptr;\n+\n+    err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_oop);\n+    if (err != JVMTI_ERROR_NONE) {\n+      return err;\n@@ -955,1 +948,8 @@\n-    return JVMTI_ERROR_THREAD_SUSPENDED;\n+\n+    \/\/ Do not use JvmtiVTMSTransitionDisabler in context of self suspend to avoid deadlocks.\n+    if (java_thread != current) {\n+      err = suspend_thread(thread_oop, java_thread, \/* single_suspend *\/ true, nullptr);\n+      return err;\n+    }\n+    \/\/ protect thread_oop as a safepoint can be reached in disabler destructor\n+    self_tobj = Handle(current, thread_oop);\n@@ -957,1 +957,3 @@\n-  return JVMTI_ERROR_NONE;\n+  \/\/ Do self suspend for current JavaThread.\n+  err = suspend_thread(self_tobj(), current, \/* single_suspend *\/ true, nullptr);\n+  return err;\n@@ -962,2 +964,2 @@\n-\/\/ request_list - pre-checked for NULL\n-\/\/ results - pre-checked for NULL\n+\/\/ request_list - pre-checked for null\n+\/\/ results - pre-checked for null\n@@ -966,29 +968,18 @@\n-  int self_index = -1;\n-  int needSafepoint = 0;  \/\/ > 0 if we need a safepoint\n-  ThreadsListHandle tlh(current);\n-  for (int i = 0; i < request_count; i++) {\n-    JavaThread *java_thread = NULL;\n-    jvmtiError err = JvmtiExport::cv_external_thread_to_JavaThread(tlh.list(), request_list[i], &java_thread, NULL);\n-    if (err != JVMTI_ERROR_NONE) {\n-      results[i] = err;\n-      continue;\n-    }\n-    \/\/ don't allow hidden thread suspend request.\n-    if (java_thread->is_hidden_from_external_view()) {\n-      results[i] = JVMTI_ERROR_NONE;  \/\/ indicate successful suspend\n-      continue;\n-    }\n-    if (java_thread->is_suspended()) {\n-      results[i] = JVMTI_ERROR_THREAD_SUSPENDED;\n-      continue;\n-    }\n-    if (java_thread == current) {\n-      self_index = i;\n-      continue;\n-    }\n-    if (!JvmtiSuspendControl::suspend(java_thread)) {\n-      \/\/ Either the thread is already suspended or\n-      \/\/ it was in the process of exiting.\n-      if (java_thread->is_exiting()) {\n-        results[i] = JVMTI_ERROR_THREAD_NOT_ALIVE;\n-        continue;\n+  HandleMark hm(current);\n+  Handle self_tobj;\n+  int self_idx = -1;\n+\n+  {\n+    JvmtiVTMSTransitionDisabler disabler(true);\n+    ThreadsListHandle tlh(current);\n+\n+    for (int i = 0; i < request_count; i++) {\n+      JavaThread *java_thread = nullptr;\n+      oop thread_oop = nullptr;\n+      jthread thread = request_list[i];\n+      jvmtiError err = JvmtiExport::cv_external_thread_to_JavaThread(tlh.list(), thread, &java_thread, &thread_oop);\n+\n+      if (thread_oop != nullptr &&\n+          java_lang_VirtualThread::is_instance(thread_oop) &&\n+          !JvmtiEnvBase::is_vthread_alive(thread_oop)) {\n+        err = JVMTI_ERROR_THREAD_NOT_ALIVE;\n@@ -997,13 +988,5 @@\n-      results[i] = JVMTI_ERROR_THREAD_SUSPENDED;\n-      continue;\n-    }\n-    results[i] = JVMTI_ERROR_NONE;  \/\/ indicate successful suspend\n-  }\n-  if (self_index >= 0) {\n-    if (!JvmtiSuspendControl::suspend(current)) {\n-      \/\/ Either the thread is already suspended or\n-      \/\/ it was in the process of exiting.\n-      if (current->is_exiting()) {\n-        results[self_index] = JVMTI_ERROR_THREAD_NOT_ALIVE;\n-      } else {\n-        results[self_index] = JVMTI_ERROR_THREAD_SUSPENDED;\n+      if (err != JVMTI_ERROR_NONE) {\n+        if (thread_oop == nullptr || err != JVMTI_ERROR_INVALID_THREAD) {\n+          results[i] = err;\n+          continue;\n+        }\n@@ -1011,2 +994,6 @@\n-    } else {\n-      results[self_index] = JVMTI_ERROR_NONE;  \/\/ indicate successful suspend\n+      if (java_thread == current) {\n+        self_idx = i;\n+        self_tobj = Handle(current, thread_oop);\n+        continue; \/\/ self suspend after all other suspends\n+      }\n+      results[i] = suspend_thread(thread_oop, java_thread, \/* single_suspend *\/ true, nullptr);\n@@ -1015,0 +1002,6 @@\n+  \/\/ Self suspend after all other suspends if necessary.\n+  \/\/ Do not use JvmtiVTMSTransitionDisabler in context of self suspend to avoid deadlocks.\n+  if (self_tobj() != nullptr) {\n+    \/\/ there should not be any error for current java_thread\n+    results[self_idx] = suspend_thread(self_tobj(), current, \/* single_suspend *\/ true, nullptr);\n+  }\n@@ -1020,5 +1013,3 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n-JvmtiEnv::ResumeThread(JavaThread* java_thread) {\n-  \/\/ don't allow hidden thread resume request.\n-  if (java_thread->is_hidden_from_external_view()) {\n-    return JVMTI_ERROR_NONE;\n+JvmtiEnv::SuspendAllVirtualThreads(jint except_count, const jthread* except_list) {\n+  if (!JvmtiExport::can_support_virtual_threads()) {\n+    return JVMTI_ERROR_MUST_POSSESS_CAPABILITY;\n@@ -1027,2 +1018,54 @@\n-  if (!java_thread->is_suspended()) {\n-    return JVMTI_ERROR_THREAD_NOT_SUSPENDED;\n+  JavaThread* current = JavaThread::current();\n+  HandleMark hm(current);\n+  Handle self_tobj;\n+\n+  {\n+    ResourceMark rm(current);\n+    JvmtiVTMSTransitionDisabler disabler(true);\n+    ThreadsListHandle tlh(current);\n+    GrowableArray<jthread>* elist = new GrowableArray<jthread>(except_count);\n+\n+    jvmtiError err = JvmtiEnvBase::check_thread_list(except_count, except_list);\n+    if (err != JVMTI_ERROR_NONE) {\n+      return err;\n+    }\n+\n+    \/\/ Collect threads from except_list for which resumed status must be restored (only for VirtualThread case)\n+    for (int idx = 0; idx < except_count; idx++) {\n+      jthread thread = except_list[idx];\n+      oop thread_oop = JNIHandles::resolve_external_guard(thread);\n+      if (java_lang_VirtualThread::is_instance(thread_oop) && !JvmtiVTSuspender::is_vthread_suspended(thread_oop)) {\n+          \/\/ is not suspended, so its resumed status must be restored\n+          elist->append(except_list[idx]);\n+      }\n+    }\n+\n+    for (JavaThreadIteratorWithHandle jtiwh; JavaThread *java_thread = jtiwh.next(); ) {\n+      oop vt_oop = java_thread->jvmti_vthread();\n+      if (!java_thread->is_exiting() &&\n+          !java_thread->is_jvmti_agent_thread() &&\n+          !java_thread->is_hidden_from_external_view() &&\n+          vt_oop != nullptr &&\n+          ((java_lang_VirtualThread::is_instance(vt_oop) &&\n+            JvmtiEnvBase::is_vthread_alive(vt_oop) &&\n+            !JvmtiVTSuspender::is_vthread_suspended(vt_oop)) ||\n+            (vt_oop->is_a(vmClasses::BoundVirtualThread_klass()) && !java_thread->is_suspended())) &&\n+          !is_in_thread_list(except_count, except_list, vt_oop)\n+         ) {\n+        if (java_thread == current) {\n+          self_tobj = Handle(current, vt_oop);\n+          continue; \/\/ self suspend after all other suspends\n+        }\n+        suspend_thread(vt_oop, java_thread, \/* single_suspend *\/ false, nullptr);\n+      }\n+    }\n+    JvmtiVTSuspender::register_all_vthreads_suspend();\n+\n+    \/\/ Restore resumed state for threads from except list that were not suspended before.\n+    for (int idx = 0; idx < elist->length(); idx++) {\n+      jthread thread = elist->at(idx);\n+      oop thread_oop = JNIHandles::resolve_external_guard(thread);\n+      if (JvmtiVTSuspender::is_vthread_suspended(thread_oop)) {\n+        JvmtiVTSuspender::register_vthread_resume(thread_oop);\n+      }\n+    }\n@@ -1030,2 +1073,4 @@\n-  if (!JvmtiSuspendControl::resume(java_thread)) {\n-    return JVMTI_ERROR_INTERNAL;\n+  \/\/ Self suspend after all other suspends if necessary.\n+  \/\/ Do not use JvmtiVTMSTransitionDisabler in context of self suspend to avoid deadlocks.\n+  if (self_tobj() != nullptr) {\n+    suspend_thread(self_tobj(), current, \/* single_suspend *\/ false, nullptr);\n@@ -1034,0 +1079,17 @@\n+} \/* end SuspendAllVirtualThreads *\/\n+\n+\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n+jvmtiError\n+JvmtiEnv::ResumeThread(jthread thread) {\n+  JvmtiVTMSTransitionDisabler disabler(true);\n+  ThreadsListHandle tlh;\n+\n+  JavaThread* java_thread = nullptr;\n+  oop thread_oop = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_oop);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+  err = resume_thread(thread_oop, java_thread, \/* single_resume *\/ true);\n+  return err;\n@@ -1038,2 +1100,2 @@\n-\/\/ request_list - pre-checked for NULL\n-\/\/ results - pre-checked for NULL\n+\/\/ request_list - pre-checked for null\n+\/\/ results - pre-checked for null\n@@ -1042,0 +1104,3 @@\n+  oop thread_oop = nullptr;\n+  JavaThread* java_thread = nullptr;\n+  JvmtiVTMSTransitionDisabler disabler(true);\n@@ -1043,0 +1108,1 @@\n+\n@@ -1044,5 +1110,7 @@\n-    JavaThread* java_thread = NULL;\n-    jvmtiError err = JvmtiExport::cv_external_thread_to_JavaThread(tlh.list(), request_list[i], &java_thread, NULL);\n-    if (err != JVMTI_ERROR_NONE) {\n-      results[i] = err;\n-      continue;\n+    jthread thread = request_list[i];\n+    jvmtiError err = JvmtiExport::cv_external_thread_to_JavaThread(tlh.list(), thread, &java_thread, &thread_oop);\n+\n+    if (thread_oop != nullptr &&\n+        java_lang_VirtualThread::is_instance(thread_oop) &&\n+        !JvmtiEnvBase::is_vthread_alive(thread_oop)) {\n+      err = JVMTI_ERROR_THREAD_NOT_ALIVE;\n@@ -1050,4 +1118,5 @@\n-    \/\/ don't allow hidden thread resume request.\n-    if (java_thread->is_hidden_from_external_view()) {\n-      results[i] = JVMTI_ERROR_NONE;  \/\/ indicate successful resume\n-      continue;\n+    if (err != JVMTI_ERROR_NONE) {\n+      if (thread_oop == nullptr || err != JVMTI_ERROR_INVALID_THREAD) {\n+        results[i] = err;\n+        continue;\n+      }\n@@ -1055,3 +1124,27 @@\n-    if (!java_thread->is_suspended()) {\n-      results[i] = JVMTI_ERROR_THREAD_NOT_SUSPENDED;\n-      continue;\n+    results[i] = resume_thread(thread_oop, java_thread, \/* single_resume *\/ true);\n+  }\n+  \/\/ per-thread resume results returned via results parameter\n+  return JVMTI_ERROR_NONE;\n+} \/* end ResumeThreadList *\/\n+\n+\n+jvmtiError\n+JvmtiEnv::ResumeAllVirtualThreads(jint except_count, const jthread* except_list) {\n+  if (!JvmtiExport::can_support_virtual_threads()) {\n+    return JVMTI_ERROR_MUST_POSSESS_CAPABILITY;\n+  }\n+  jvmtiError err = JvmtiEnvBase::check_thread_list(except_count, except_list);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+  ResourceMark rm;\n+  JvmtiVTMSTransitionDisabler disabler(true);\n+  GrowableArray<jthread>* elist = new GrowableArray<jthread>(except_count);\n+\n+  \/\/ Collect threads from except_list for which suspended status must be restored (only for VirtualThread case)\n+  for (int idx = 0; idx < except_count; idx++) {\n+    jthread thread = except_list[idx];\n+    oop thread_oop = JNIHandles::resolve_external_guard(thread);\n+    if (java_lang_VirtualThread::is_instance(thread_oop) && JvmtiVTSuspender::is_vthread_suspended(thread_oop)) {\n+      \/\/ is suspended, so its suspended status must be restored\n+      elist->append(except_list[idx]);\n@@ -1059,0 +1152,1 @@\n+  }\n@@ -1060,3 +1154,13 @@\n-    if (!JvmtiSuspendControl::resume(java_thread)) {\n-      results[i] = JVMTI_ERROR_INTERNAL;\n-      continue;\n+  for (JavaThreadIteratorWithHandle jtiwh; JavaThread *java_thread = jtiwh.next(); ) {\n+    oop vt_oop = java_thread->jvmti_vthread();\n+    if (!java_thread->is_exiting() &&\n+        !java_thread->is_jvmti_agent_thread() &&\n+        !java_thread->is_hidden_from_external_view() &&\n+        vt_oop != nullptr &&\n+        ((java_lang_VirtualThread::is_instance(vt_oop) &&\n+          JvmtiEnvBase::is_vthread_alive(vt_oop) &&\n+          JvmtiVTSuspender::is_vthread_suspended(vt_oop)) ||\n+          (vt_oop->is_a(vmClasses::BoundVirtualThread_klass()) && java_thread->is_suspended())) &&\n+        !is_in_thread_list(except_count, except_list, vt_oop)\n+    ) {\n+      resume_thread(vt_oop, java_thread, \/* single_resume *\/ false);\n@@ -1064,0 +1168,2 @@\n+  }\n+  JvmtiVTSuspender::register_all_vthreads_resume();\n@@ -1065,1 +1171,7 @@\n-    results[i] = JVMTI_ERROR_NONE;  \/\/ indicate successful resume\n+  \/\/ Restore suspended state for threads from except list that were suspended before.\n+  for (int idx = 0; idx < elist->length(); idx++) {\n+    jthread thread = elist->at(idx);\n+    oop thread_oop = JNIHandles::resolve_external_guard(thread);\n+    if (!JvmtiVTSuspender::is_vthread_suspended(thread_oop)) {\n+      JvmtiVTSuspender::register_vthread_suspend(thread_oop);\n+    }\n@@ -1067,2 +1179,1 @@\n-  \/\/ per-thread resume results returned via results parameter\n-} \/* end ResumeThreadList *\/\n+} \/* end ResumeAllVirtualThreads *\/\n@@ -1072,2 +1183,25 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n-JvmtiEnv::StopThread(JavaThread* java_thread, jobject exception) {\n+JvmtiEnv::StopThread(jthread thread, jobject exception) {\n+  JavaThread* current_thread = JavaThread::current();\n+\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(current_thread);\n+  JavaThread* java_thread = nullptr;\n+  oop thread_oop = nullptr;\n+\n+  NULL_CHECK(thread, JVMTI_ERROR_INVALID_THREAD);\n+\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_oop);\n+\n+  bool is_virtual = thread_oop != nullptr && thread_oop->is_a(vmClasses::BaseVirtualThread_klass());\n+\n+  if (is_virtual && !is_JavaThread_current(java_thread, thread_oop)) {\n+    if (!is_vthread_suspended(thread_oop, java_thread)) {\n+      return JVMTI_ERROR_THREAD_NOT_SUSPENDED;\n+    }\n+    if (java_thread == nullptr) { \/\/ unmounted virtual thread\n+      return JVMTI_ERROR_OPAQUE_FRAME;\n+    }\n+  }\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n@@ -1078,1 +1212,1 @@\n-  JavaThread::send_async_exception(java_thread->threadObj(), e);\n+  JavaThread::send_async_exception(java_thread, e);\n@@ -1089,1 +1223,3 @@\n-  JavaThread* java_thread = NULL;\n+  HandleMark hm(current_thread);\n+\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n@@ -1091,1 +1227,4 @@\n-  jvmtiError err = JvmtiExport::cv_external_thread_to_JavaThread(tlh.list(), thread, &java_thread, NULL);\n+\n+  JavaThread* java_thread = nullptr;\n+  oop thread_obj = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n@@ -1095,0 +1234,15 @@\n+\n+  if (java_lang_VirtualThread::is_instance(thread_obj)) {\n+    \/\/ For virtual threads we have to call into Java to interrupt:\n+    Handle obj(current_thread, thread_obj);\n+    JavaValue result(T_VOID);\n+    JavaCalls::call_virtual(&result,\n+                            obj,\n+                            vmClasses::Thread_klass(),\n+                            vmSymbols::interrupt_method_name(),\n+                            vmSymbols::void_method_signature(),\n+                            current_thread);\n+\n+    return JVMTI_ERROR_NONE;\n+  }\n+\n@@ -1099,1 +1253,1 @@\n-  java_lang_Thread::set_interrupted(JNIHandles::resolve(thread), true);\n+  java_lang_Thread::set_interrupted(thread_obj, true);\n@@ -1107,1 +1261,1 @@\n-\/\/ info_ptr - pre-checked for NULL\n+\/\/ info_ptr - pre-checked for null\n@@ -1113,0 +1267,2 @@\n+  JavaThread* java_thread = nullptr;\n+  oop thread_oop = nullptr;\n@@ -1114,0 +1270,1 @@\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n@@ -1116,5 +1273,5 @@\n-  \/\/ if thread is NULL the current thread is used\n-  oop thread_oop = NULL;\n-  if (thread == NULL) {\n-    thread_oop = current_thread->threadObj();\n-    if (thread_oop == NULL || !thread_oop->is_a(vmClasses::Thread_klass())) {\n+  \/\/ if thread is null the current thread is used\n+  if (thread == nullptr) {\n+    java_thread = JavaThread::current();\n+    thread_oop = get_vthread_or_thread_oop(java_thread);\n+    if (thread_oop == nullptr || !thread_oop->is_a(vmClasses::Thread_klass())) {\n@@ -1124,1 +1281,0 @@\n-    JavaThread* java_thread = NULL;\n@@ -1130,1 +1286,3 @@\n-      if (thread_oop == NULL) {\n+      \/\/ In the virtual thread case the cv_external_thread_to_JavaThread is expected to correctly set\n+      \/\/ the thread_oop and return JVMTI_ERROR_INVALID_THREAD which we ignore here.\n+      if (thread_oop == nullptr) {\n@@ -1133,1 +1291,0 @@\n-      \/\/ We have a valid thread_oop so we can return some thread info.\n@@ -1136,0 +1293,1 @@\n+  \/\/ We have a valid thread_oop so we can return some thread info.\n@@ -1145,3 +1303,18 @@\n-  priority = java_lang_Thread::priority(thread_obj());\n-  thread_group = Handle(current_thread, java_lang_Thread::threadGroup(thread_obj()));\n-  is_daemon = java_lang_Thread::is_daemon(thread_obj());\n+\n+  if (java_lang_VirtualThread::is_instance(thread_obj())) {\n+    priority = (ThreadPriority)JVMTI_THREAD_NORM_PRIORITY;\n+    is_daemon = true;\n+    if (java_lang_VirtualThread::state(thread_obj()) == java_lang_VirtualThread::TERMINATED) {\n+      thread_group = Handle(current_thread, nullptr);\n+    } else {\n+      thread_group = Handle(current_thread, java_lang_Thread_Constants::get_VTHREAD_GROUP());\n+    }\n+  } else {\n+    priority = java_lang_Thread::priority(thread_obj());\n+    is_daemon = java_lang_Thread::is_daemon(thread_obj());\n+    if (java_lang_Thread::get_thread_status(thread_obj()) == JavaThreadStatus::TERMINATED) {\n+      thread_group = Handle(current_thread, nullptr);\n+    } else {\n+      thread_group = Handle(current_thread, java_lang_Thread::threadGroup(thread_obj()));\n+    }\n+  }\n@@ -1154,1 +1327,1 @@\n-    if (name() != NULL) {\n+    if (name() != nullptr) {\n@@ -1158,1 +1331,1 @@\n-      n = UNICODE::as_utf8((jchar*) NULL, utf8_length);\n+      n = UNICODE::as_utf8((jchar*) nullptr, utf8_length);\n@@ -1162,1 +1335,1 @@\n-    if (info_ptr->name == NULL)\n+    if (info_ptr->name == nullptr)\n@@ -1170,2 +1343,2 @@\n-  info_ptr->context_class_loader = (context_class_loader.is_null()) ? NULL :\n-                                     jni_reference(context_class_loader);\n+  info_ptr->context_class_loader = (context_class_loader.is_null()) ? nullptr :\n+                                    jni_reference(context_class_loader);\n@@ -1178,3 +1351,3 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n-\/\/ owned_monitor_count_ptr - pre-checked for NULL\n-\/\/ owned_monitors_ptr - pre-checked for NULL\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n+\/\/ owned_monitor_count_ptr - pre-checked for null\n+\/\/ owned_monitors_ptr - pre-checked for null\n@@ -1182,2 +1355,1 @@\n-JvmtiEnv::GetOwnedMonitorInfo(JavaThread* java_thread, jint* owned_monitor_count_ptr, jobject** owned_monitors_ptr) {\n-  jvmtiError err = JVMTI_ERROR_NONE;\n+JvmtiEnv::GetOwnedMonitorInfo(jthread thread, jint* owned_monitor_count_ptr, jobject** owned_monitors_ptr) {\n@@ -1185,5 +1357,1 @@\n-\n-  EscapeBarrier eb(true, calling_thread, java_thread);\n-  if (!eb.deoptimize_objects(MaxJavaStackTraceDepth)) {\n-    return JVMTI_ERROR_OUT_OF_MEMORY;\n-  }\n+  HandleMark hm(calling_thread);\n@@ -1193,1 +1361,1 @@\n-      new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<jvmtiMonitorStackDepthInfo*>(1, mtServiceability);\n+      new (mtServiceability) GrowableArray<jvmtiMonitorStackDepthInfo*>(1, mtServiceability);\n@@ -1195,4 +1363,20 @@\n-  \/\/ It is only safe to perform the direct operation on the current\n-  \/\/ thread. All other usage needs to use a direct handshake for safety.\n-  if (java_thread == calling_thread) {\n-    err = get_owned_monitors(calling_thread, java_thread, owned_monitors_list);\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(calling_thread);\n+\n+  JavaThread* java_thread = nullptr;\n+  oop thread_oop = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_oop);\n+  if (err != JVMTI_ERROR_NONE) {\n+    delete owned_monitors_list;\n+    return err;\n+  }\n+\n+  if (java_lang_VirtualThread::is_instance(thread_oop)) {\n+    \/\/ There is no monitor info to collect if target virtual thread is unmounted.\n+    if (java_thread != nullptr) {\n+      VirtualThreadGetOwnedMonitorInfoClosure op(this,\n+                                                 Handle(calling_thread, thread_oop),\n+                                                 owned_monitors_list);\n+      Handshake::execute(&op, java_thread);\n+      err = op.result();\n+    }\n@@ -1200,4 +1384,16 @@\n-    \/\/ get owned monitors info with handshake\n-    GetOwnedMonitorInfoClosure op(calling_thread, this, owned_monitors_list);\n-    Handshake::execute(&op, java_thread);\n-    err = op.result();\n+    EscapeBarrier eb(true, calling_thread, java_thread);\n+    if (!eb.deoptimize_objects(MaxJavaStackTraceDepth)) {\n+      delete owned_monitors_list;\n+      return JVMTI_ERROR_OUT_OF_MEMORY;\n+    }\n+\n+    if (java_thread == calling_thread) {\n+      \/\/ It is only safe to make a direct call on the current thread.\n+      \/\/ All other usage needs to use a direct handshake for safety.\n+      err = get_owned_monitors(calling_thread, java_thread, owned_monitors_list);\n+    } else {\n+      \/\/ get owned monitors info with handshake\n+      GetOwnedMonitorInfoClosure op(calling_thread, this, owned_monitors_list);\n+      Handshake::execute(&op, java_thread);\n+      err = op.result();\n+    }\n@@ -1205,0 +1401,1 @@\n+\n@@ -1227,3 +1424,3 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n-\/\/ monitor_info_count_ptr - pre-checked for NULL\n-\/\/ monitor_info_ptr - pre-checked for NULL\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n+\/\/ monitor_info_count_ptr - pre-checked for null\n+\/\/ monitor_info_ptr - pre-checked for null\n@@ -1231,2 +1428,1 @@\n-JvmtiEnv::GetOwnedMonitorStackDepthInfo(JavaThread* java_thread, jint* monitor_info_count_ptr, jvmtiMonitorStackDepthInfo** monitor_info_ptr) {\n-  jvmtiError err = JVMTI_ERROR_NONE;\n+JvmtiEnv::GetOwnedMonitorStackDepthInfo(jthread thread, jint* monitor_info_count_ptr, jvmtiMonitorStackDepthInfo** monitor_info_ptr) {\n@@ -1234,5 +1430,1 @@\n-\n-  EscapeBarrier eb(true, calling_thread, java_thread);\n-  if (!eb.deoptimize_objects(MaxJavaStackTraceDepth)) {\n-    return JVMTI_ERROR_OUT_OF_MEMORY;\n-  }\n+  HandleMark hm(calling_thread);\n@@ -1242,1 +1434,1 @@\n-         new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<jvmtiMonitorStackDepthInfo*>(1, mtServiceability);\n+         new (mtServiceability) GrowableArray<jvmtiMonitorStackDepthInfo*>(1, mtServiceability);\n@@ -1244,9 +1436,9 @@\n-  \/\/ It is only safe to perform the direct operation on the current\n-  \/\/ thread. All other usage needs to use a direct handshake for safety.\n-  if (java_thread == calling_thread) {\n-    err = get_owned_monitors(calling_thread, java_thread, owned_monitors_list);\n-  } else {\n-    \/\/ get owned monitors info with handshake\n-    GetOwnedMonitorInfoClosure op(calling_thread, this, owned_monitors_list);\n-    Handshake::execute(&op, java_thread);\n-    err = op.result();\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(calling_thread);\n+\n+  JavaThread* java_thread = nullptr;\n+  oop thread_oop = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_oop);\n+  if (err != JVMTI_ERROR_NONE) {\n+    delete owned_monitors_list;\n+    return err;\n@@ -1255,0 +1447,27 @@\n+  if (java_lang_VirtualThread::is_instance(thread_oop)) {\n+    \/\/ There is no monitor info to collect if target virtual thread is unmounted.\n+    if (java_thread != nullptr) {\n+      VirtualThreadGetOwnedMonitorInfoClosure op(this,\n+                                                 Handle(calling_thread, thread_oop),\n+                                                 owned_monitors_list);\n+      Handshake::execute(&op, java_thread);\n+      err = op.result();\n+    }\n+  } else {\n+    EscapeBarrier eb(true, calling_thread, java_thread);\n+    if (!eb.deoptimize_objects(MaxJavaStackTraceDepth)) {\n+      delete owned_monitors_list;\n+      return JVMTI_ERROR_OUT_OF_MEMORY;\n+    }\n+\n+    if (java_thread == calling_thread) {\n+      \/\/ It is only safe to make a direct call on the current thread.\n+      \/\/ All other usage needs to use a direct handshake for safety.\n+      err = get_owned_monitors(calling_thread, java_thread, owned_monitors_list);\n+    } else {\n+      \/\/ get owned monitors info with handshake\n+      GetOwnedMonitorInfoClosure op(calling_thread, this, owned_monitors_list);\n+      Handshake::execute(&op, java_thread);\n+      err = op.result();\n+    }\n+  }\n@@ -1258,1 +1477,1 @@\n-                      (unsigned char**)monitor_info_ptr)) == JVMTI_ERROR_NONE) {\n+                        (unsigned char**)monitor_info_ptr)) == JVMTI_ERROR_NONE) {\n@@ -1280,2 +1499,2 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n-\/\/ monitor_ptr - pre-checked for NULL\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n+\/\/ monitor_ptr - pre-checked for null\n@@ -1283,2 +1502,1 @@\n-JvmtiEnv::GetCurrentContendedMonitor(JavaThread* java_thread, jobject* monitor_ptr) {\n-  jvmtiError err = JVMTI_ERROR_NONE;\n+JvmtiEnv::GetCurrentContendedMonitor(jthread thread, jobject* monitor_ptr) {\n@@ -1286,0 +1504,1 @@\n+  HandleMark hm(calling_thread);\n@@ -1287,2 +1506,24 @@\n-  \/\/ It is only safe to perform the direct operation on the current\n-  \/\/ thread. All other usage needs to use a direct handshake for safety.\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(calling_thread);\n+\n+  JavaThread* java_thread = nullptr;\n+  oop thread_oop = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_oop);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+\n+  if (java_lang_VirtualThread::is_instance(thread_oop)) {\n+    \/\/ There is no monitor info to collect if target virtual thread is unmounted.\n+    if (java_thread != nullptr) {\n+      GetCurrentContendedMonitorClosure op(calling_thread, this, monitor_ptr, \/* is_virtual *\/ true);\n+      Handshake::execute(&op, java_thread);\n+      err = op.result();\n+    } else {\n+      *monitor_ptr = nullptr;\n+      if (!JvmtiEnvBase::is_vthread_alive(thread_oop)) {\n+        err = JVMTI_ERROR_THREAD_NOT_ALIVE;\n+      }\n+    }\n+    return err;\n+  }\n@@ -1290,1 +1531,3 @@\n-    err = get_current_contended_monitor(calling_thread, java_thread, monitor_ptr);\n+    \/\/ It is only safe to make a direct call on the current thread.\n+    \/\/ All other usage needs to use a direct handshake for safety.\n+    err = get_current_contended_monitor(calling_thread, java_thread, monitor_ptr, \/* is_virtual *\/ false);\n@@ -1293,1 +1536,1 @@\n-    GetCurrentContendedMonitorClosure op(calling_thread, this, monitor_ptr);\n+    GetCurrentContendedMonitorClosure op(calling_thread, this, monitor_ptr, \/* is_virtual *\/ false);\n@@ -1302,2 +1545,2 @@\n-\/\/ proc - pre-checked for NULL\n-\/\/ arg - NULL is a valid value, must be checked\n+\/\/ proc - pre-checked for null\n+\/\/ arg - null is a valid value, must be checked\n@@ -1308,2 +1551,2 @@\n-  JavaThread* java_thread = NULL;\n-  oop thread_oop = NULL;\n+  JavaThread* java_thread = nullptr;\n+  oop thread_oop = nullptr;\n@@ -1316,1 +1559,1 @@\n-    if (thread_oop == NULL) {\n+    if (thread_oop == nullptr) {\n@@ -1322,1 +1565,5 @@\n-  if (java_thread != NULL) {\n+  if (thread_oop->is_a(vmClasses::BaseVirtualThread_klass())) {\n+    \/\/ No support for virtual threads.\n+    return JVMTI_ERROR_UNSUPPORTED_OPERATION;\n+  }\n+  if (java_thread != nullptr) {\n@@ -1332,3 +1579,1 @@\n-  {\n-    MutexLocker mu(current_thread, Threads_lock); \/\/ grab Threads_lock\n-    JvmtiAgentThread *new_thread = new JvmtiAgentThread(this, proc, arg);\n+  JvmtiAgentThread* new_thread = new JvmtiAgentThread(this, proc, arg);\n@@ -1337,12 +1582,7 @@\n-    \/\/ At this point it may be possible that no osthread was created for the\n-    \/\/ JavaThread due to lack of memory.\n-    if (new_thread == NULL || new_thread->osthread() == NULL) {\n-      if (new_thread != NULL) {\n-        new_thread->smr_delete();\n-      }\n-      return JVMTI_ERROR_OUT_OF_MEMORY;\n-    }\n-\n-    java_lang_Thread::set_thread(thread_hndl(), new_thread);\n-    java_lang_Thread::set_priority(thread_hndl(), (ThreadPriority)priority);\n-    java_lang_Thread::set_daemon(thread_hndl());\n+  \/\/ At this point it may be possible that no osthread was created for the\n+  \/\/ JavaThread due to lack of resources.\n+  if (new_thread->osthread() == nullptr) {\n+    \/\/ The new thread is not known to Thread-SMR yet so we can just delete.\n+    delete new_thread;\n+    return JVMTI_ERROR_OUT_OF_MEMORY;\n+  }\n@@ -1350,4 +1590,2 @@\n-    new_thread->set_threadObj(thread_hndl());\n-    Threads::add(new_thread);\n-    Thread::start(new_thread);\n-  } \/\/ unlock Threads_lock\n+  JavaThread::start_internal_daemon(current_thread, new_thread, thread_hndl,\n+                                    (ThreadPriority)priority);\n@@ -1362,2 +1600,2 @@\n-\/\/ group_count_ptr - pre-checked for NULL\n-\/\/ groups_ptr - pre-checked for NULL\n+\/\/ group_count_ptr - pre-checked for null\n+\/\/ groups_ptr - pre-checked for null\n@@ -1388,1 +1626,1 @@\n-\/\/ info_ptr - pre-checked for NULL\n+\/\/ info_ptr - pre-checked for null\n@@ -1412,1 +1650,1 @@\n-  if (name != NULL) {\n+  if (name != nullptr) {\n@@ -1417,1 +1655,1 @@\n-    info_ptr->name = NULL;\n+    info_ptr->name = nullptr;\n@@ -1423,5 +1661,4 @@\n-\n-\/\/ thread_count_ptr - pre-checked for NULL\n-\/\/ threads_ptr - pre-checked for NULL\n-\/\/ group_count_ptr - pre-checked for NULL\n-\/\/ groups_ptr - pre-checked for NULL\n+\/\/ thread_count_ptr - pre-checked for null\n+\/\/ threads_ptr - pre-checked for null\n+\/\/ group_count_ptr - pre-checked for null\n+\/\/ groups_ptr - pre-checked for null\n@@ -1430,0 +1667,1 @@\n+  jvmtiError err;\n@@ -1434,4 +1672,4 @@\n-  Handle *thread_objs = NULL;\n-  Handle *group_objs  = NULL;\n-  int nthreads = 0;\n-  int ngroups = 0;\n+  Handle *thread_objs = nullptr;\n+  objArrayHandle group_objs;\n+  jint nthreads = 0;\n+  jint ngroups = 0;\n@@ -1445,50 +1683,8 @@\n-  { \/\/ Cannot allow thread or group counts to change.\n-    ObjectLocker ol(group_hdl, current_thread);\n-\n-    nthreads = java_lang_ThreadGroup::nthreads(group_hdl());\n-    ngroups  = java_lang_ThreadGroup::ngroups(group_hdl());\n-\n-    if (nthreads > 0) {\n-      ThreadsListHandle tlh(current_thread);\n-      objArrayOop threads = java_lang_ThreadGroup::threads(group_hdl());\n-      assert(nthreads <= threads->length(), \"too many threads\");\n-      thread_objs = NEW_RESOURCE_ARRAY(Handle,nthreads);\n-      for (int i = 0, j = 0; i < nthreads; i++) {\n-        oop thread_obj = threads->obj_at(i);\n-        assert(thread_obj != NULL, \"thread_obj is NULL\");\n-        JavaThread *java_thread = NULL;\n-        jvmtiError err = JvmtiExport::cv_oop_to_JavaThread(tlh.list(), thread_obj, &java_thread);\n-        if (err == JVMTI_ERROR_NONE) {\n-          \/\/ Have a valid JavaThread*.\n-          if (java_thread->is_hidden_from_external_view()) {\n-            \/\/ Filter out hidden java threads.\n-            hidden_threads++;\n-            continue;\n-          }\n-        } else {\n-          \/\/ We couldn't convert thread_obj into a JavaThread*.\n-          if (err == JVMTI_ERROR_INVALID_THREAD) {\n-            \/\/ The thread_obj does not refer to a java.lang.Thread object\n-            \/\/ so skip it.\n-            hidden_threads++;\n-            continue;\n-          }\n-          \/\/ We have a valid thread_obj, but no JavaThread*; the caller\n-          \/\/ can still have limited use for the thread_obj.\n-        }\n-        thread_objs[j++] = Handle(current_thread, thread_obj);\n-      }\n-      nthreads -= hidden_threads;\n-    } \/\/ ThreadsListHandle is destroyed here.\n-\n-    if (ngroups > 0) {\n-      objArrayOop groups = java_lang_ThreadGroup::groups(group_hdl());\n-      assert(ngroups <= groups->length(), \"too many groups\");\n-      group_objs = NEW_RESOURCE_ARRAY(Handle,ngroups);\n-      for (int i = 0; i < ngroups; i++) {\n-        oop group_obj = groups->obj_at(i);\n-        assert(group_obj != NULL, \"group_obj != NULL\");\n-        group_objs[i] = Handle(current_thread, group_obj);\n-      }\n-    }\n-  } \/\/ ThreadGroup unlocked here\n+  err = get_live_threads(current_thread, group_hdl, &nthreads, &thread_objs);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+  err = get_subgroups(current_thread, group_hdl, &ngroups, &group_objs);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n@@ -1500,1 +1696,1 @@\n-  if ((nthreads > 0) && (*threads_ptr == NULL)) {\n+  if (nthreads > 0 && *threads_ptr == nullptr) {\n@@ -1503,1 +1699,1 @@\n-  if ((ngroups > 0) && (*groups_ptr == NULL)) {\n+  if (ngroups > 0 && *groups_ptr == nullptr) {\n@@ -1515,1 +1711,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -1517,2 +1713,2 @@\n-\/\/ frame_buffer - pre-checked for NULL\n-\/\/ count_ptr - pre-checked for NULL\n+\/\/ frame_buffer - pre-checked for null\n+\/\/ count_ptr - pre-checked for null\n@@ -1520,2 +1716,29 @@\n-JvmtiEnv::GetStackTrace(JavaThread* java_thread, jint start_depth, jint max_frame_count, jvmtiFrameInfo* frame_buffer, jint* count_ptr) {\n-  jvmtiError err = JVMTI_ERROR_NONE;\n+JvmtiEnv::GetStackTrace(jthread thread, jint start_depth, jint max_frame_count, jvmtiFrameInfo* frame_buffer, jint* count_ptr) {\n+  JavaThread* current_thread = JavaThread::current();\n+  HandleMark hm(current_thread);\n+\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(current_thread);\n+\n+  JavaThread* java_thread = nullptr;\n+  oop thread_obj = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+\n+  if (java_lang_VirtualThread::is_instance(thread_obj)) {\n+    if (java_thread == nullptr) {  \/\/ Target virtual thread is unmounted.\n+      ResourceMark rm(current_thread);\n+\n+      VM_VirtualThreadGetStackTrace op(this, Handle(current_thread, thread_obj),\n+                                       start_depth, max_frame_count,\n+                                       frame_buffer, count_ptr);\n+      VMThread::execute(&op);\n+      return op.result();\n+    }\n+    VirtualThreadGetStackTraceClosure op(this, Handle(current_thread, thread_obj),\n+                                         start_depth, max_frame_count, frame_buffer, count_ptr);\n+    Handshake::execute(&op, java_thread);\n+    return op.result();\n+  }\n@@ -1539,2 +1762,2 @@\n-\/\/ stack_info_ptr - pre-checked for NULL\n-\/\/ thread_count_ptr - pre-checked for NULL\n+\/\/ stack_info_ptr - pre-checked for null\n+\/\/ thread_count_ptr - pre-checked for null\n@@ -1557,1 +1780,1 @@\n-\/\/ thread_list - pre-checked for NULL\n+\/\/ thread_list - pre-checked for null\n@@ -1559,1 +1782,1 @@\n-\/\/ stack_info_ptr - pre-checked for NULL\n+\/\/ stack_info_ptr - pre-checked for null\n@@ -1563,0 +1786,1 @@\n+  JvmtiVTMSTransitionDisabler disabler;\n@@ -1565,0 +1789,1 @@\n+\n@@ -1568,0 +1793,2 @@\n+\n+    jthread thread = thread_list[0];\n@@ -1569,1 +1796,2 @@\n-    err = JvmtiExport::cv_external_thread_to_JavaThread(tlh.list(), *thread_list, &java_thread, NULL);\n+    oop thread_obj = nullptr;\n+    err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n@@ -1574,2 +1802,12 @@\n-    GetSingleStackTraceClosure op(this, current_thread, *thread_list, max_frame_count);\n-    Handshake::execute(&op, java_thread);\n+    if (java_lang_VirtualThread::is_instance(thread_obj) && java_thread == nullptr) {\n+      \/\/ Target virtual thread is unmounted.\n+      ResourceMark rm(current_thread);\n+      MultipleStackTracesCollector collector(this, max_frame_count);\n+      collector.fill_frames(thread, java_thread, thread_obj);\n+      collector.allocate_and_fill_stacks(\/* thread_count *\/ 1);\n+      *stack_info_ptr = collector.stack_info();\n+      return collector.result();\n+    }\n+\n+    GetSingleStackTraceClosure op(this, current_thread, thread, max_frame_count);\n+    Handshake::execute(&op, &tlh, java_thread);\n@@ -1593,2 +1831,2 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n-\/\/ count_ptr - pre-checked for NULL\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n+\/\/ count_ptr - pre-checked for null\n@@ -1596,2 +1834,3 @@\n-JvmtiEnv::GetFrameCount(JavaThread* java_thread, jint* count_ptr) {\n-  jvmtiError err = JVMTI_ERROR_NONE;\n+JvmtiEnv::GetFrameCount(jthread thread, jint* count_ptr) {\n+  JavaThread* current_thread = JavaThread::current();\n+  HandleMark hm(current_thread);\n@@ -1599,4 +1838,19 @@\n-  \/\/ retrieve or create JvmtiThreadState.\n-  JvmtiThreadState* state = JvmtiThreadState::state_for(java_thread);\n-  if (state == NULL) {\n-    return JVMTI_ERROR_THREAD_NOT_ALIVE;\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(current_thread);\n+\n+  JavaThread* java_thread = nullptr;\n+  oop thread_obj = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+\n+  if (java_lang_VirtualThread::is_instance(thread_obj)) {\n+    if (java_thread == nullptr) {  \/\/ Target virtual thread is unmounted.\n+      VM_VirtualThreadGetFrameCount op(this, Handle(current_thread, thread_obj),  count_ptr);\n+      VMThread::execute(&op);\n+      return op.result();\n+    }\n+    VirtualThreadGetFrameCountClosure op(this, Handle(current_thread, thread_obj), count_ptr);\n+    Handshake::execute(&op, java_thread);\n+    return op.result();\n@@ -1608,1 +1862,1 @@\n-    err = get_frame_count(state, count_ptr);\n+    err = get_frame_count(java_thread, count_ptr);\n@@ -1611,1 +1865,1 @@\n-    GetFrameCountClosure op(this, state, count_ptr);\n+    GetFrameCountClosure op(this, count_ptr);\n@@ -1619,1 +1873,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -1621,1 +1875,24 @@\n-JvmtiEnv::PopFrame(JavaThread* java_thread) {\n+JvmtiEnv::PopFrame(jthread thread) {\n+  JavaThread* current_thread = JavaThread::current();\n+  HandleMark hm(current_thread);\n+\n+  if (thread == nullptr) {\n+    return JVMTI_ERROR_INVALID_THREAD;\n+  }\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(current_thread);\n+\n+  JavaThread* java_thread = nullptr;\n+  oop thread_obj = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n+\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+  bool self = java_thread == current_thread;\n+\n+  err = check_non_suspended_or_opaque_frame(java_thread, thread_obj, self);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+\n@@ -1624,1 +1901,1 @@\n-  if (state == NULL) {\n+  if (state == nullptr) {\n@@ -1629,1 +1906,0 @@\n-  JavaThread* current_thread = JavaThread::current();\n@@ -1638,2 +1914,2 @@\n-  if (java_thread == current_thread) {\n-    op.doit(java_thread, true \/* self *\/);\n+  if (self) {\n+    op.doit(java_thread, self);\n@@ -1647,1 +1923,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -1649,2 +1925,2 @@\n-\/\/ method_ptr - pre-checked for NULL\n-\/\/ location_ptr - pre-checked for NULL\n+\/\/ method_ptr - pre-checked for null\n+\/\/ location_ptr - pre-checked for null\n@@ -1652,2 +1928,24 @@\n-JvmtiEnv::GetFrameLocation(JavaThread* java_thread, jint depth, jmethodID* method_ptr, jlocation* location_ptr) {\n-  jvmtiError err = JVMTI_ERROR_NONE;\n+JvmtiEnv::GetFrameLocation(jthread thread, jint depth, jmethodID* method_ptr, jlocation* location_ptr) {\n+  JavaThread* current_thread = JavaThread::current();\n+  HandleMark hm(current_thread);\n+\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(current_thread);\n+\n+  JavaThread* java_thread = nullptr;\n+  oop thread_obj = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+\n+  if (java_lang_VirtualThread::is_instance(thread_obj)) {\n+    if (java_thread == nullptr) {  \/\/ Target virtual thread is unmounted.\n+      err = get_frame_location(thread_obj, depth, method_ptr, location_ptr);\n+      return err;\n+    }\n+    VirtualThreadGetFrameLocationClosure op(this, Handle(current_thread, thread_obj),\n+                                            depth, method_ptr, location_ptr);\n+    Handshake::execute(&op, java_thread);\n+    return op.result();\n+  }\n@@ -1669,1 +1967,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ Threads_lock NOT held, java_thread not protected by lock\n@@ -1672,3 +1970,17 @@\n-JvmtiEnv::NotifyFramePop(JavaThread* java_thread, jint depth) {\n-  JvmtiThreadState *state = JvmtiThreadState::state_for(java_thread);\n-  if (state == NULL) {\n+JvmtiEnv::NotifyFramePop(jthread thread, jint depth) {\n+  ResourceMark rm;\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh;\n+\n+  JavaThread* java_thread = nullptr;\n+  oop thread_obj = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+\n+  JavaThread* current = JavaThread::current();\n+  HandleMark hm(current);\n+  Handle thread_handle(current, thread_obj);\n+  JvmtiThreadState *state = JvmtiThreadState::state_for(java_thread, thread_handle);\n+  if (state == nullptr) {\n@@ -1678,0 +1990,12 @@\n+  if (java_lang_VirtualThread::is_instance(thread_handle())) {\n+    VirtualThreadSetFramePopClosure op(this, thread_handle, state, depth);\n+    MutexLocker mu(current, JvmtiThreadState_lock);\n+    if (java_thread == nullptr || java_thread == current) {\n+      \/\/ Target virtual thread is unmounted or current.\n+      op.doit(java_thread, true \/* self *\/);\n+    } else {\n+      Handshake::execute(&op, java_thread);\n+    }\n+    return op.result();\n+  }\n+\n@@ -1679,2 +2003,2 @@\n-  MutexLocker mu(JvmtiThreadState_lock);\n-  if (java_thread == JavaThread::current()) {\n+  MutexLocker mu(current, JvmtiThreadState_lock);\n+  if (java_thread == current) {\n@@ -1693,1 +2017,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -1695,1 +2019,1 @@\n-JvmtiEnv::ForceEarlyReturnObject(JavaThread* java_thread, jobject value) {\n+JvmtiEnv::ForceEarlyReturnObject(jthread thread, jobject value) {\n@@ -1698,1 +2022,1 @@\n-  return force_early_return(java_thread, val, atos);\n+  return force_early_return(thread, val, atos);\n@@ -1702,1 +2026,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -1704,1 +2028,1 @@\n-JvmtiEnv::ForceEarlyReturnInt(JavaThread* java_thread, jint value) {\n+JvmtiEnv::ForceEarlyReturnInt(jthread thread, jint value) {\n@@ -1707,1 +2031,1 @@\n-  return force_early_return(java_thread, val, itos);\n+  return force_early_return(thread, val, itos);\n@@ -1711,1 +2035,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -1713,1 +2037,1 @@\n-JvmtiEnv::ForceEarlyReturnLong(JavaThread* java_thread, jlong value) {\n+JvmtiEnv::ForceEarlyReturnLong(jthread thread, jlong value) {\n@@ -1716,1 +2040,1 @@\n-  return force_early_return(java_thread, val, ltos);\n+  return force_early_return(thread, val, ltos);\n@@ -1720,1 +2044,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -1722,1 +2046,1 @@\n-JvmtiEnv::ForceEarlyReturnFloat(JavaThread* java_thread, jfloat value) {\n+JvmtiEnv::ForceEarlyReturnFloat(jthread thread, jfloat value) {\n@@ -1725,1 +2049,1 @@\n-  return force_early_return(java_thread, val, ftos);\n+  return force_early_return(thread, val, ftos);\n@@ -1729,1 +2053,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -1731,1 +2055,1 @@\n-JvmtiEnv::ForceEarlyReturnDouble(JavaThread* java_thread, jdouble value) {\n+JvmtiEnv::ForceEarlyReturnDouble(jthread thread, jdouble value) {\n@@ -1734,1 +2058,1 @@\n-  return force_early_return(java_thread, val, dtos);\n+  return force_early_return(thread, val, dtos);\n@@ -1738,1 +2062,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -1740,1 +2064,1 @@\n-JvmtiEnv::ForceEarlyReturnVoid(JavaThread* java_thread) {\n+JvmtiEnv::ForceEarlyReturnVoid(jthread thread) {\n@@ -1743,1 +2067,1 @@\n-  return force_early_return(java_thread, val, vtos);\n+  return force_early_return(thread, val, vtos);\n@@ -1751,4 +2075,4 @@\n-\/\/ klass - NULL is a valid value, must be checked\n-\/\/ initial_object - NULL is a valid value, must be checked\n-\/\/ callbacks - pre-checked for NULL\n-\/\/ user_data - NULL is a valid value, must be checked\n+\/\/ klass - null is a valid value, must be checked\n+\/\/ initial_object - null is a valid value, must be checked\n+\/\/ callbacks - pre-checked for null\n+\/\/ user_data - null is a valid value, must be checked\n@@ -1758,2 +2082,2 @@\n-  Klass* k = NULL;\n-  if (klass != NULL) {\n+  Klass* k = nullptr;\n+  if (klass != nullptr) {\n@@ -1761,1 +2085,1 @@\n-    if (k_mirror == NULL) {\n+    if (k_mirror == nullptr) {\n@@ -1768,1 +2092,1 @@\n-    if (klass == NULL) {\n+    if (klass == nullptr) {\n@@ -1773,1 +2097,1 @@\n-  if (initial_object != NULL) {\n+  if (initial_object != nullptr) {\n@@ -1775,1 +2099,1 @@\n-    if (init_obj == NULL) {\n+    if (init_obj == nullptr) {\n@@ -1789,3 +2113,3 @@\n-\/\/ klass - NULL is a valid value, must be checked\n-\/\/ callbacks - pre-checked for NULL\n-\/\/ user_data - NULL is a valid value, must be checked\n+\/\/ klass - null is a valid value, must be checked\n+\/\/ callbacks - pre-checked for null\n+\/\/ user_data - null is a valid value, must be checked\n@@ -1795,2 +2119,2 @@\n-  Klass* k = NULL;\n-  if (klass != NULL) {\n+  Klass* k = nullptr;\n+  if (klass != nullptr) {\n@@ -1798,1 +2122,1 @@\n-    if (k_mirror == NULL) {\n+    if (k_mirror == nullptr) {\n@@ -1805,1 +2129,1 @@\n-    if (k == NULL) {\n+    if (k == nullptr) {\n@@ -1816,1 +2140,1 @@\n-\/\/ tag_ptr - pre-checked for NULL\n+\/\/ tag_ptr - pre-checked for null\n@@ -1836,4 +2160,4 @@\n-\/\/ tags - pre-checked for NULL\n-\/\/ count_ptr - pre-checked for NULL\n-\/\/ object_result_ptr - NULL is a valid value, must be checked\n-\/\/ tag_result_ptr - NULL is a valid value, must be checked\n+\/\/ tags - pre-checked for null\n+\/\/ count_ptr - pre-checked for null\n+\/\/ object_result_ptr - null is a valid value, must be checked\n+\/\/ tag_result_ptr - null is a valid value, must be checked\n@@ -1858,2 +2182,2 @@\n-\/\/ object_reference_callback - pre-checked for NULL\n-\/\/ user_data - NULL is a valid value, must be checked\n+\/\/ object_reference_callback - pre-checked for null\n+\/\/ user_data - null is a valid value, must be checked\n@@ -1869,4 +2193,4 @@\n-\/\/ heap_root_callback - NULL is a valid value, must be checked\n-\/\/ stack_ref_callback - NULL is a valid value, must be checked\n-\/\/ object_ref_callback - NULL is a valid value, must be checked\n-\/\/ user_data - NULL is a valid value, must be checked\n+\/\/ heap_root_callback - null is a valid value, must be checked\n+\/\/ stack_ref_callback - null is a valid value, must be checked\n+\/\/ object_ref_callback - null is a valid value, must be checked\n+\/\/ user_data - null is a valid value, must be checked\n@@ -1881,2 +2205,2 @@\n-\/\/ heap_object_callback - pre-checked for NULL\n-\/\/ user_data - NULL is a valid value, must be checked\n+\/\/ heap_object_callback - pre-checked for null\n+\/\/ user_data - null is a valid value, must be checked\n@@ -1888,1 +2212,1 @@\n-  JvmtiTagMap::tag_map_for(this)->iterate_over_heap(object_filter, NULL, heap_object_callback, user_data);\n+  JvmtiTagMap::tag_map_for(this)->iterate_over_heap(object_filter, nullptr, heap_object_callback, user_data);\n@@ -1894,2 +2218,2 @@\n-\/\/ heap_object_callback - pre-checked for NULL\n-\/\/ user_data - NULL is a valid value, must be checked\n+\/\/ heap_object_callback - pre-checked for null\n+\/\/ user_data - null is a valid value, must be checked\n@@ -1903,1 +2227,1 @@\n-  if (klass == NULL) {\n+  if (klass == nullptr) {\n@@ -1916,1 +2240,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -1918,1 +2242,1 @@\n-\/\/ value_ptr - pre-checked for NULL\n+\/\/ value_ptr - pre-checked for null\n@@ -1920,1 +2244,1 @@\n-JvmtiEnv::GetLocalObject(JavaThread* java_thread, jint depth, jint slot, jobject* value_ptr) {\n+JvmtiEnv::GetLocalObject(jthread thread, jint depth, jint slot, jobject* value_ptr) {\n@@ -1925,0 +2249,3 @@\n+  HandleMark hm(current_thread);\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(current_thread);\n@@ -1926,3 +2253,3 @@\n-  VM_GetOrSetLocal op(java_thread, current_thread, depth, slot);\n-  VMThread::execute(&op);\n-  jvmtiError err = op.result();\n+  JavaThread* java_thread = nullptr;\n+  oop thread_obj = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n@@ -1931,0 +2258,11 @@\n+  }\n+  bool self = is_JavaThread_current(java_thread, thread_obj);\n+\n+  if (java_lang_VirtualThread::is_instance(thread_obj)) {\n+    VM_VirtualThreadGetOrSetLocal op(this, Handle(current_thread, thread_obj),\n+                                     current_thread, depth, slot, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+    if (err == JVMTI_ERROR_NONE) {\n+      *value_ptr = op.value().l;\n+    }\n@@ -1932,2 +2270,7 @@\n-    *value_ptr = op.value().l;\n-    return JVMTI_ERROR_NONE;\n+    \/\/ Support for ordinary threads\n+    VM_GetOrSetLocal op(java_thread, current_thread, depth, slot, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+    if (err == JVMTI_ERROR_NONE) {\n+      *value_ptr = op.value().l;\n+    }\n@@ -1935,0 +2278,1 @@\n+  return err;\n@@ -1937,1 +2281,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -1939,1 +2283,1 @@\n-\/\/ value - pre-checked for NULL\n+\/\/ value - pre-checked for null\n@@ -1941,1 +2285,1 @@\n-JvmtiEnv::GetLocalInstance(JavaThread* java_thread, jint depth, jobject* value_ptr){\n+JvmtiEnv::GetLocalInstance(jthread thread, jint depth, jobject* value_ptr){\n@@ -1946,0 +2290,3 @@\n+  HandleMark hm(current_thread);\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(current_thread);\n@@ -1947,3 +2294,3 @@\n-  VM_GetReceiver op(java_thread, current_thread, depth);\n-  VMThread::execute(&op);\n-  jvmtiError err = op.result();\n+  JavaThread* java_thread = nullptr;\n+  oop thread_obj = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n@@ -1952,0 +2299,11 @@\n+  }\n+  bool self = is_JavaThread_current(java_thread, thread_obj);\n+\n+  if (java_lang_VirtualThread::is_instance(thread_obj)) {\n+    VM_VirtualThreadGetReceiver op(this, Handle(current_thread, thread_obj),\n+                                   current_thread, depth, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+    if (err == JVMTI_ERROR_NONE) {\n+      *value_ptr = op.value().l;\n+    }\n@@ -1953,2 +2311,7 @@\n-    *value_ptr = op.value().l;\n-    return JVMTI_ERROR_NONE;\n+    \/\/ Support for ordinary threads\n+    VM_GetReceiver op(java_thread, current_thread, depth, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+    if (err == JVMTI_ERROR_NONE) {\n+      *value_ptr = op.value().l;\n+    }\n@@ -1956,0 +2319,1 @@\n+  return err;\n@@ -1959,1 +2323,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -1961,1 +2325,1 @@\n-\/\/ value_ptr - pre-checked for NULL\n+\/\/ value_ptr - pre-checked for null\n@@ -1963,1 +2327,2 @@\n-JvmtiEnv::GetLocalInt(JavaThread* java_thread, jint depth, jint slot, jint* value_ptr) {\n+JvmtiEnv::GetLocalInt(jthread thread, jint depth, jint slot, jint* value_ptr) {\n+  JavaThread* current_thread = JavaThread::current();\n@@ -1966,1 +2331,4 @@\n-  ResourceMark rm;\n+  ResourceMark rm(current_thread);\n+  HandleMark hm(current_thread);\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(current_thread);\n@@ -1968,4 +2336,26 @@\n-  VM_GetOrSetLocal op(java_thread, depth, slot, T_INT);\n-  VMThread::execute(&op);\n-  *value_ptr = op.value().i;\n-  return op.result();\n+  JavaThread* java_thread = nullptr;\n+  oop thread_obj = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+  bool self = is_JavaThread_current(java_thread, thread_obj);\n+\n+  if (java_lang_VirtualThread::is_instance(thread_obj)) {\n+    VM_VirtualThreadGetOrSetLocal op(this, Handle(current_thread, thread_obj),\n+                                     depth, slot, T_INT, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+    if (err == JVMTI_ERROR_NONE) {\n+      *value_ptr = op.value().i;\n+    }\n+  } else {\n+    \/\/ Support for ordinary threads\n+    VM_GetOrSetLocal op(java_thread, depth, slot, T_INT, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+    if (err == JVMTI_ERROR_NONE) {\n+      *value_ptr = op.value().i;\n+    }\n+  }\n+  return err;\n@@ -1975,1 +2365,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -1977,1 +2367,1 @@\n-\/\/ value_ptr - pre-checked for NULL\n+\/\/ value_ptr - pre-checked for null\n@@ -1979,1 +2369,2 @@\n-JvmtiEnv::GetLocalLong(JavaThread* java_thread, jint depth, jint slot, jlong* value_ptr) {\n+JvmtiEnv::GetLocalLong(jthread thread, jint depth, jint slot, jlong* value_ptr) {\n+  JavaThread* current_thread = JavaThread::current();\n@@ -1982,1 +2373,4 @@\n-  ResourceMark rm;\n+  ResourceMark rm(current_thread);\n+  HandleMark hm(current_thread);\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(current_thread);\n@@ -1984,4 +2378,26 @@\n-  VM_GetOrSetLocal op(java_thread, depth, slot, T_LONG);\n-  VMThread::execute(&op);\n-  *value_ptr = op.value().j;\n-  return op.result();\n+  JavaThread* java_thread = nullptr;\n+  oop thread_obj = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+  bool self = is_JavaThread_current(java_thread, thread_obj);\n+\n+  if (java_lang_VirtualThread::is_instance(thread_obj)) {\n+    VM_VirtualThreadGetOrSetLocal op(this, Handle(current_thread, thread_obj),\n+                                     depth, slot, T_LONG, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+    if (err == JVMTI_ERROR_NONE) {\n+      *value_ptr = op.value().j;\n+    }\n+  } else {\n+    \/\/ Support for ordinary threads\n+    VM_GetOrSetLocal op(java_thread, depth, slot, T_LONG, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+    if (err == JVMTI_ERROR_NONE) {\n+      *value_ptr = op.value().j;\n+    }\n+  }\n+  return err;\n@@ -1991,1 +2407,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -1993,1 +2409,1 @@\n-\/\/ value_ptr - pre-checked for NULL\n+\/\/ value_ptr - pre-checked for null\n@@ -1995,1 +2411,2 @@\n-JvmtiEnv::GetLocalFloat(JavaThread* java_thread, jint depth, jint slot, jfloat* value_ptr) {\n+JvmtiEnv::GetLocalFloat(jthread thread, jint depth, jint slot, jfloat* value_ptr) {\n+  JavaThread* current_thread = JavaThread::current();\n@@ -1998,1 +2415,4 @@\n-  ResourceMark rm;\n+  ResourceMark rm(current_thread);\n+  HandleMark hm(current_thread);\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(current_thread);\n@@ -2000,4 +2420,26 @@\n-  VM_GetOrSetLocal op(java_thread, depth, slot, T_FLOAT);\n-  VMThread::execute(&op);\n-  *value_ptr = op.value().f;\n-  return op.result();\n+  JavaThread* java_thread = nullptr;\n+  oop thread_obj = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+  bool self = is_JavaThread_current(java_thread, thread_obj);\n+\n+  if (java_lang_VirtualThread::is_instance(thread_obj)) {\n+    VM_VirtualThreadGetOrSetLocal op(this, Handle(current_thread, thread_obj),\n+                                     depth, slot, T_FLOAT, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+    if (err == JVMTI_ERROR_NONE) {\n+      *value_ptr = op.value().f;\n+    }\n+  } else {\n+    \/\/ Support for ordinary threads\n+    VM_GetOrSetLocal op(java_thread, depth, slot, T_FLOAT, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+    if (err == JVMTI_ERROR_NONE) {\n+      *value_ptr = op.value().f;\n+    }\n+  }\n+  return err;\n@@ -2007,1 +2449,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -2009,1 +2451,1 @@\n-\/\/ value_ptr - pre-checked for NULL\n+\/\/ value_ptr - pre-checked for null\n@@ -2011,1 +2453,2 @@\n-JvmtiEnv::GetLocalDouble(JavaThread* java_thread, jint depth, jint slot, jdouble* value_ptr) {\n+JvmtiEnv::GetLocalDouble(jthread thread, jint depth, jint slot, jdouble* value_ptr) {\n+  JavaThread* current_thread = JavaThread::current();\n@@ -2014,1 +2457,4 @@\n-  ResourceMark rm;\n+  ResourceMark rm(current_thread);\n+  HandleMark hm(current_thread);\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(current_thread);\n@@ -2016,4 +2462,26 @@\n-  VM_GetOrSetLocal op(java_thread, depth, slot, T_DOUBLE);\n-  VMThread::execute(&op);\n-  *value_ptr = op.value().d;\n-  return op.result();\n+  JavaThread* java_thread = nullptr;\n+  oop thread_obj = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+  bool self = is_JavaThread_current(java_thread, thread_obj);\n+\n+  if (java_lang_VirtualThread::is_instance(thread_obj)) {\n+    VM_VirtualThreadGetOrSetLocal op(this, Handle(current_thread, thread_obj),\n+                                     depth, slot, T_DOUBLE, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+    if (err == JVMTI_ERROR_NONE) {\n+      *value_ptr = op.value().d;\n+    }\n+  } else {\n+    \/\/ Support for ordinary threads\n+    VM_GetOrSetLocal op(java_thread, depth, slot, T_DOUBLE, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+    if (err == JVMTI_ERROR_NONE) {\n+      *value_ptr = op.value().d;\n+    }\n+  }\n+  return err;\n@@ -2023,1 +2491,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -2026,1 +2494,2 @@\n-JvmtiEnv::SetLocalObject(JavaThread* java_thread, jint depth, jint slot, jobject value) {\n+JvmtiEnv::SetLocalObject(jthread thread, jint depth, jint slot, jobject value) {\n+  JavaThread* current_thread = JavaThread::current();\n@@ -2029,1 +2498,12 @@\n-  ResourceMark rm;\n+  ResourceMark rm(current_thread);\n+  HandleMark hm(current_thread);\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(current_thread);\n+\n+  JavaThread* java_thread = nullptr;\n+  oop thread_obj = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+  bool self = is_JavaThread_current(java_thread, thread_obj);\n@@ -2032,3 +2512,13 @@\n-  VM_GetOrSetLocal op(java_thread, depth, slot, T_OBJECT, val);\n-  VMThread::execute(&op);\n-  return op.result();\n+\n+  if (java_lang_VirtualThread::is_instance(thread_obj)) {\n+    VM_VirtualThreadGetOrSetLocal op(this, Handle(current_thread, thread_obj),\n+                                     depth, slot, T_OBJECT, val, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+  } else {\n+    \/\/ Support for ordinary threads\n+    VM_GetOrSetLocal op(java_thread, depth, slot, T_OBJECT, val, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+  }\n+  return err;\n@@ -2038,1 +2528,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -2041,1 +2531,2 @@\n-JvmtiEnv::SetLocalInt(JavaThread* java_thread, jint depth, jint slot, jint value) {\n+JvmtiEnv::SetLocalInt(jthread thread, jint depth, jint slot, jint value) {\n+  JavaThread* current_thread = JavaThread::current();\n@@ -2044,1 +2535,12 @@\n-  ResourceMark rm;\n+  ResourceMark rm(current_thread);\n+  HandleMark hm(current_thread);\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(current_thread);\n+\n+  JavaThread* java_thread = nullptr;\n+  oop thread_obj = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+  bool self = is_JavaThread_current(java_thread, thread_obj);\n@@ -2047,3 +2549,13 @@\n-  VM_GetOrSetLocal op(java_thread, depth, slot, T_INT, val);\n-  VMThread::execute(&op);\n-  return op.result();\n+\n+  if (java_lang_VirtualThread::is_instance(thread_obj)) {\n+    VM_VirtualThreadGetOrSetLocal op(this, Handle(current_thread, thread_obj),\n+                                     depth, slot, T_INT, val, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+  } else {\n+    \/\/ Support for ordinary threads\n+    VM_GetOrSetLocal op(java_thread, depth, slot, T_INT, val, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+  }\n+  return err;\n@@ -2053,1 +2565,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -2056,1 +2568,2 @@\n-JvmtiEnv::SetLocalLong(JavaThread* java_thread, jint depth, jint slot, jlong value) {\n+JvmtiEnv::SetLocalLong(jthread thread, jint depth, jint slot, jlong value) {\n+  JavaThread* current_thread = JavaThread::current();\n@@ -2059,1 +2572,12 @@\n-  ResourceMark rm;\n+  ResourceMark rm(current_thread);\n+  HandleMark hm(current_thread);\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(current_thread);\n+\n+  JavaThread* java_thread = nullptr;\n+  oop thread_obj = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+  bool self = is_JavaThread_current(java_thread, thread_obj);\n@@ -2062,3 +2586,13 @@\n-  VM_GetOrSetLocal op(java_thread, depth, slot, T_LONG, val);\n-  VMThread::execute(&op);\n-  return op.result();\n+\n+  if (java_lang_VirtualThread::is_instance(thread_obj)) {\n+    VM_VirtualThreadGetOrSetLocal op(this, Handle(current_thread, thread_obj),\n+                                     depth, slot, T_LONG, val, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+  } else {\n+    \/\/ Support for ordinary threads\n+    VM_GetOrSetLocal op(java_thread, depth, slot, T_LONG, val, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+  }\n+  return err;\n@@ -2068,1 +2602,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -2071,1 +2605,2 @@\n-JvmtiEnv::SetLocalFloat(JavaThread* java_thread, jint depth, jint slot, jfloat value) {\n+JvmtiEnv::SetLocalFloat(jthread thread, jint depth, jint slot, jfloat value) {\n+  JavaThread* current_thread = JavaThread::current();\n@@ -2074,1 +2609,12 @@\n-  ResourceMark rm;\n+  ResourceMark rm(current_thread);\n+  HandleMark hm(current_thread);\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(current_thread);\n+\n+  JavaThread* java_thread = nullptr;\n+  oop thread_obj = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+  bool self = is_JavaThread_current(java_thread, thread_obj);\n@@ -2077,3 +2623,13 @@\n-  VM_GetOrSetLocal op(java_thread, depth, slot, T_FLOAT, val);\n-  VMThread::execute(&op);\n-  return op.result();\n+\n+  if (java_lang_VirtualThread::is_instance(thread_obj)) {\n+    VM_VirtualThreadGetOrSetLocal op(this, Handle(current_thread, thread_obj),\n+                                     depth, slot, T_FLOAT, val, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+  } else {\n+    \/\/ Support for ordinary threads\n+    VM_GetOrSetLocal op(java_thread, depth, slot, T_FLOAT, val, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+  }\n+  return err;\n@@ -2083,1 +2639,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -2086,1 +2642,2 @@\n-JvmtiEnv::SetLocalDouble(JavaThread* java_thread, jint depth, jint slot, jdouble value) {\n+JvmtiEnv::SetLocalDouble(jthread thread, jint depth, jint slot, jdouble value) {\n+  JavaThread* current_thread = JavaThread::current();\n@@ -2089,1 +2646,12 @@\n-  ResourceMark rm;\n+  ResourceMark rm(current_thread);\n+  HandleMark hm(current_thread);\n+  JvmtiVTMSTransitionDisabler disabler(thread);\n+  ThreadsListHandle tlh(current_thread);\n+\n+  JavaThread* java_thread = nullptr;\n+  oop thread_obj = nullptr;\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+  bool self = is_JavaThread_current(java_thread, thread_obj);\n@@ -2092,3 +2660,13 @@\n-  VM_GetOrSetLocal op(java_thread, depth, slot, T_DOUBLE, val);\n-  VMThread::execute(&op);\n-  return op.result();\n+\n+  if (java_lang_VirtualThread::is_instance(thread_obj)) {\n+    VM_VirtualThreadGetOrSetLocal op(this, Handle(current_thread, thread_obj),\n+                                     depth, slot, T_DOUBLE, val, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+  } else {\n+    \/\/ Support for ordinary threads\n+    VM_GetOrSetLocal op(java_thread, depth, slot, T_DOUBLE, val, self);\n+    VMThread::execute(&op);\n+    err = op.result();\n+  }\n+  return err;\n@@ -2102,1 +2680,1 @@\n-\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n+\/\/ method - pre-checked for validity, but may be null meaning obsolete method\n@@ -2128,1 +2706,1 @@\n-\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n+\/\/ method - pre-checked for validity, but may be null meaning obsolete method\n@@ -2213,2 +2791,2 @@\n-\/\/ signature_ptr - NULL is a valid value, must be checked\n-\/\/ generic_ptr - NULL is a valid value, must be checked\n+\/\/ signature_ptr - null is a valid value, must be checked\n+\/\/ generic_ptr - null is a valid value, must be checked\n@@ -2219,1 +2797,1 @@\n-  Klass* k = NULL;\n+  Klass* k = nullptr;\n@@ -2224,2 +2802,2 @@\n-  if (signature_ptr != NULL) {\n-    char* result = NULL;\n+  if (signature_ptr != nullptr) {\n+    char* result = nullptr;\n@@ -2238,2 +2816,2 @@\n-  if (generic_ptr != NULL) {\n-    *generic_ptr = NULL;\n+  if (generic_ptr != nullptr) {\n+    *generic_ptr = nullptr;\n@@ -2242,1 +2820,1 @@\n-      if (soo != NULL) {\n+      if (soo != nullptr) {\n@@ -2244,1 +2822,1 @@\n-        if (gen_sig != NULL) {\n+        if (gen_sig != nullptr) {\n@@ -2262,1 +2840,1 @@\n-\/\/ status_ptr - pre-checked for NULL\n+\/\/ status_ptr - pre-checked for null\n@@ -2280,1 +2858,1 @@\n-\/\/ source_name_ptr - pre-checked for NULL\n+\/\/ source_name_ptr - pre-checked for null\n@@ -2308,1 +2886,1 @@\n-\/\/ modifiers_ptr - pre-checked for NULL\n+\/\/ modifiers_ptr - pre-checked for null\n@@ -2332,2 +2910,2 @@\n-\/\/ method_count_ptr - pre-checked for NULL\n-\/\/ methods_ptr - pre-checked for NULL\n+\/\/ method_count_ptr - pre-checked for null\n+\/\/ methods_ptr - pre-checked for null\n@@ -2373,1 +2951,1 @@\n-      result_list[result_index] = NULL;\n+      result_list[result_index] = nullptr;\n@@ -2380,1 +2958,1 @@\n-      if (id == NULL) {\n+      if (id == nullptr) {\n@@ -2396,1 +2974,1 @@\n-    \/\/ copy results skipping NULL methodIDs\n+    \/\/ copy results skipping null methodIDs\n@@ -2400,1 +2978,1 @@\n-      if (result_list[index] == NULL) {\n+      if (result_list[index] == nullptr) {\n@@ -2417,2 +2995,2 @@\n-\/\/ field_count_ptr - pre-checked for NULL\n-\/\/ fields_ptr - pre-checked for NULL\n+\/\/ field_count_ptr - pre-checked for null\n+\/\/ fields_ptr - pre-checked for null\n@@ -2471,2 +3049,2 @@\n-\/\/ interface_count_ptr - pre-checked for NULL\n-\/\/ interfaces_ptr - pre-checked for NULL\n+\/\/ interface_count_ptr - pre-checked for null\n+\/\/ interfaces_ptr - pre-checked for null\n@@ -2497,1 +3075,1 @@\n-    const int result_length = (interface_list == NULL ? 0 : interface_list->length());\n+    const int result_length = (interface_list == nullptr ? 0 : interface_list->length());\n@@ -2516,2 +3094,2 @@\n-\/\/ minor_version_ptr - pre-checked for NULL\n-\/\/ major_version_ptr - pre-checked for NULL\n+\/\/ minor_version_ptr - pre-checked for null\n+\/\/ major_version_ptr - pre-checked for null\n@@ -2542,3 +3120,3 @@\n-\/\/ constant_pool_count_ptr - pre-checked for NULL\n-\/\/ constant_pool_byte_count_ptr - pre-checked for NULL\n-\/\/ constant_pool_bytes_ptr - pre-checked for NULL\n+\/\/ constant_pool_count_ptr - pre-checked for null\n+\/\/ constant_pool_byte_count_ptr - pre-checked for null\n+\/\/ constant_pool_bytes_ptr - pre-checked for null\n@@ -2593,1 +3171,1 @@\n-\/\/ is_interface_ptr - pre-checked for NULL\n+\/\/ is_interface_ptr - pre-checked for null\n@@ -2600,1 +3178,1 @@\n-      if (k != NULL && k->is_interface()) {\n+      if (k != nullptr && k->is_interface()) {\n@@ -2612,1 +3190,1 @@\n-\/\/ is_array_class_ptr - pre-checked for NULL\n+\/\/ is_array_class_ptr - pre-checked for null\n@@ -2619,1 +3197,1 @@\n-      if (k != NULL && k->is_array_klass()) {\n+      if (k != nullptr && k->is_array_klass()) {\n@@ -2631,1 +3209,1 @@\n-\/\/ classloader_ptr - pre-checked for NULL\n+\/\/ classloader_ptr - pre-checked for null\n@@ -2645,1 +3223,1 @@\n-    if (result_oop == NULL) {\n+    if (result_oop == nullptr) {\n@@ -2658,1 +3236,1 @@\n-\/\/ source_debug_extension_ptr - pre-checked for NULL\n+\/\/ source_debug_extension_ptr - pre-checked for null\n@@ -2686,1 +3264,1 @@\n-\/\/ hash_code_ptr - pre-checked for NULL\n+\/\/ hash_code_ptr - pre-checked for null\n@@ -2701,1 +3279,1 @@\n-\/\/ info_ptr - pre-checked for NULL\n+\/\/ info_ptr - pre-checked for null\n@@ -2716,3 +3294,3 @@\n-\/\/ name_ptr - NULL is a valid value, must be checked\n-\/\/ signature_ptr - NULL is a valid value, must be checked\n-\/\/ generic_ptr - NULL is a valid value, must be checked\n+\/\/ name_ptr - null is a valid value, must be checked\n+\/\/ signature_ptr - null is a valid value, must be checked\n+\/\/ generic_ptr - null is a valid value, must be checked\n@@ -2723,1 +3301,1 @@\n-  if (name_ptr == NULL) {\n+  if (name_ptr == nullptr) {\n@@ -2728,1 +3306,1 @@\n-    if (*name_ptr == NULL)\n+    if (*name_ptr == nullptr)\n@@ -2732,1 +3310,1 @@\n-  if (signature_ptr== NULL) {\n+  if (signature_ptr== nullptr) {\n@@ -2737,1 +3315,1 @@\n-    if (*signature_ptr == NULL)\n+    if (*signature_ptr == nullptr)\n@@ -2741,2 +3319,2 @@\n-  if (generic_ptr != NULL) {\n-    *generic_ptr = NULL;\n+  if (generic_ptr != nullptr) {\n+    *generic_ptr = nullptr;\n@@ -2744,1 +3322,1 @@\n-    if (soop != NULL) {\n+    if (soop != nullptr) {\n@@ -2746,1 +3324,1 @@\n-      if (gen_sig != NULL) {\n+      if (gen_sig != nullptr) {\n@@ -2759,1 +3337,1 @@\n-\/\/ declaring_class_ptr - pre-checked for NULL\n+\/\/ declaring_class_ptr - pre-checked for null\n@@ -2768,1 +3346,1 @@\n-\/\/ modifiers_ptr - pre-checked for NULL\n+\/\/ modifiers_ptr - pre-checked for null\n@@ -2780,1 +3358,1 @@\n-\/\/ is_synthetic_ptr - pre-checked for NULL\n+\/\/ is_synthetic_ptr - pre-checked for null\n@@ -2792,4 +3370,4 @@\n-\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n-\/\/ name_ptr - NULL is a valid value, must be checked\n-\/\/ signature_ptr - NULL is a valid value, must be checked\n-\/\/ generic_ptr - NULL is a valid value, must be checked\n+\/\/ method - pre-checked for validity, but may be null meaning obsolete method\n+\/\/ name_ptr - null is a valid value, must be checked\n+\/\/ signature_ptr - null is a valid value, must be checked\n+\/\/ generic_ptr - null is a valid value, must be checked\n@@ -2802,1 +3380,1 @@\n-  if (name_ptr == NULL) {\n+  if (name_ptr == nullptr) {\n@@ -2809,1 +3387,1 @@\n-  if (signature_ptr == NULL) {\n+  if (signature_ptr == nullptr) {\n@@ -2817,2 +3395,2 @@\n-  if (generic_ptr != NULL) {\n-    *generic_ptr = NULL;\n+  if (generic_ptr != nullptr) {\n+    *generic_ptr = nullptr;\n@@ -2820,1 +3398,1 @@\n-    if (soop != NULL) {\n+    if (soop != nullptr) {\n@@ -2822,1 +3400,1 @@\n-      if (gen_sig != NULL) {\n+      if (gen_sig != nullptr) {\n@@ -2835,2 +3413,2 @@\n-\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n-\/\/ declaring_class_ptr - pre-checked for NULL\n+\/\/ method - pre-checked for validity, but may be null meaning obsolete method\n+\/\/ declaring_class_ptr - pre-checked for null\n@@ -2845,2 +3423,2 @@\n-\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n-\/\/ modifiers_ptr - pre-checked for NULL\n+\/\/ method - pre-checked for validity, but may be null meaning obsolete method\n+\/\/ modifiers_ptr - pre-checked for null\n@@ -2855,2 +3433,2 @@\n-\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n-\/\/ max_ptr - pre-checked for NULL\n+\/\/ method - pre-checked for validity, but may be null meaning obsolete method\n+\/\/ max_ptr - pre-checked for null\n@@ -2866,2 +3444,2 @@\n-\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n-\/\/ size_ptr - pre-checked for NULL\n+\/\/ method - pre-checked for validity, but may be null meaning obsolete method\n+\/\/ size_ptr - pre-checked for null\n@@ -2878,3 +3456,3 @@\n-\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n-\/\/ entry_count_ptr - pre-checked for NULL\n-\/\/ table_ptr - pre-checked for NULL\n+\/\/ method - pre-checked for validity, but may be null meaning obsolete method\n+\/\/ entry_count_ptr - pre-checked for null\n+\/\/ table_ptr - pre-checked for null\n@@ -2920,3 +3498,3 @@\n-\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n-\/\/ start_location_ptr - pre-checked for NULL\n-\/\/ end_location_ptr - pre-checked for NULL\n+\/\/ method - pre-checked for validity, but may be null meaning obsolete method\n+\/\/ start_location_ptr - pre-checked for null\n+\/\/ end_location_ptr - pre-checked for null\n@@ -2940,3 +3518,3 @@\n-\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n-\/\/ entry_count_ptr - pre-checked for NULL\n-\/\/ table_ptr - pre-checked for NULL\n+\/\/ method - pre-checked for validity, but may be null meaning obsolete method\n+\/\/ entry_count_ptr - pre-checked for null\n+\/\/ table_ptr - pre-checked for null\n@@ -2951,1 +3529,1 @@\n-  if (!ik->access_flags().has_localvariable_table()) {\n+  if (!ik->has_localvariable_table()) {\n@@ -2977,3 +3555,3 @@\n-      char *name_buf = NULL;\n-      char *sig_buf = NULL;\n-      char *gen_sig_buf = NULL;\n+      char *name_buf = nullptr;\n+      char *sig_buf = nullptr;\n+      char *gen_sig_buf = nullptr;\n@@ -3017,3 +3595,3 @@\n-\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n-\/\/ bytecode_count_ptr - pre-checked for NULL\n-\/\/ bytecodes_ptr - pre-checked for NULL\n+\/\/ method - pre-checked for validity, but may be null meaning obsolete method\n+\/\/ bytecode_count_ptr - pre-checked for null\n+\/\/ bytecodes_ptr - pre-checked for null\n@@ -3039,2 +3617,2 @@\n-\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n-\/\/ is_native_ptr - pre-checked for NULL\n+\/\/ method - pre-checked for validity, but may be null meaning obsolete method\n+\/\/ is_native_ptr - pre-checked for null\n@@ -3049,2 +3627,2 @@\n-\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n-\/\/ is_synthetic_ptr - pre-checked for NULL\n+\/\/ method - pre-checked for validity, but may be null meaning obsolete method\n+\/\/ is_synthetic_ptr - pre-checked for null\n@@ -3059,2 +3637,2 @@\n-\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n-\/\/ is_obsolete_ptr - pre-checked for NULL\n+\/\/ method - pre-checked for validity, but may be null meaning obsolete method\n+\/\/ is_obsolete_ptr - pre-checked for null\n@@ -3071,1 +3649,1 @@\n-  if (method == NULL || method->is_obsolete()) {\n+  if (method == nullptr || method->is_obsolete()) {\n@@ -3087,2 +3665,2 @@\n-\/\/ name - pre-checked for NULL\n-\/\/ monitor_ptr - pre-checked for NULL\n+\/\/ name - pre-checked for null\n+\/\/ monitor_ptr - pre-checked for null\n@@ -3091,1 +3669,1 @@\n-  JvmtiRawMonitor* rmonitor = new JvmtiRawMonitor(name);\n+  JvmtiRawMonitor* rmonitor = new (std::nothrow) JvmtiRawMonitor(name);\n@@ -3128,1 +3706,1 @@\n-    if (rmonitor->owner() != NULL) {\n+    if (rmonitor->owner() != nullptr) {\n@@ -3247,1 +3825,1 @@\n-\/\/ function_table - pre-checked for NULL\n+\/\/ function_table - pre-checked for null\n@@ -3258,1 +3836,1 @@\n-\/\/ function_table - pre-checked for NULL\n+\/\/ function_table - pre-checked for null\n@@ -3262,1 +3840,1 @@\n-  if (*function_table == NULL)\n+  if (*function_table == nullptr)\n@@ -3299,2 +3877,2 @@\n-\/\/ extension_count_ptr - pre-checked for NULL\n-\/\/ extensions - pre-checked for NULL\n+\/\/ extension_count_ptr - pre-checked for null\n+\/\/ extensions - pre-checked for null\n@@ -3307,2 +3885,2 @@\n-\/\/ extension_count_ptr - pre-checked for NULL\n-\/\/ extensions - pre-checked for NULL\n+\/\/ extension_count_ptr - pre-checked for null\n+\/\/ extensions - pre-checked for null\n@@ -3315,1 +3893,1 @@\n-\/\/ callback - NULL is a valid value, must be checked\n+\/\/ callback - null is a valid value, must be checked\n@@ -3325,1 +3903,1 @@\n-\/\/ info_ptr - pre-checked for NULL\n+\/\/ info_ptr - pre-checked for null\n@@ -3333,1 +3911,1 @@\n-\/\/ nanos_ptr - pre-checked for NULL\n+\/\/ nanos_ptr - pre-checked for null\n@@ -3336,0 +3914,9 @@\n+  Thread* thread = Thread::current();\n+\n+  \/\/ Surprisingly the GetCurrentThreadCpuTime is used by non-JavaThread's.\n+  if (thread->is_Java_thread()) {\n+    if (JavaThread::cast(thread)->is_vthread_mounted()) {\n+      \/\/ No support for a VirtualThread (yet).\n+      return JVMTI_ERROR_UNSUPPORTED_OPERATION;\n+    }\n+  }\n@@ -3341,1 +3928,1 @@\n-\/\/ info_ptr - pre-checked for NULL\n+\/\/ info_ptr - pre-checked for null\n@@ -3349,2 +3936,1 @@\n-\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n-\/\/ nanos_ptr - pre-checked for NULL\n+\/\/ nanos_ptr - pre-checked for null\n@@ -3352,1 +3938,17 @@\n-JvmtiEnv::GetThreadCpuTime(JavaThread* java_thread, jlong* nanos_ptr) {\n+JvmtiEnv::GetThreadCpuTime(jthread thread, jlong* nanos_ptr) {\n+  JavaThread* current_thread = JavaThread::current();\n+  ThreadsListHandle tlh(current_thread);\n+  JavaThread* java_thread = nullptr;\n+  oop thread_oop = nullptr;\n+\n+  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_oop);\n+\n+  if (thread_oop != nullptr && thread_oop->is_a(vmClasses::BaseVirtualThread_klass())) {\n+    \/\/ No support for virtual threads (yet).\n+    return JVMTI_ERROR_UNSUPPORTED_OPERATION;\n+  }\n+  if (err != JVMTI_ERROR_NONE) {\n+    return err;\n+  }\n+  NULL_CHECK(nanos_ptr, JVMTI_ERROR_NULL_POINTER);\n+\n@@ -3358,1 +3960,1 @@\n-\/\/ info_ptr - pre-checked for NULL\n+\/\/ info_ptr - pre-checked for null\n@@ -3366,1 +3968,1 @@\n-\/\/ nanos_ptr - pre-checked for NULL\n+\/\/ nanos_ptr - pre-checked for null\n@@ -3374,1 +3976,1 @@\n-\/\/ processor_count_ptr - pre-checked for NULL\n+\/\/ processor_count_ptr - pre-checked for null\n@@ -3394,2 +3996,2 @@\n-\/\/ count_ptr - pre-checked for NULL\n-\/\/ property_ptr - pre-checked for NULL\n+\/\/ count_ptr - pre-checked for null\n+\/\/ property_ptr - pre-checked for null\n@@ -3410,2 +4012,2 @@\n-  for (SystemProperty* p = Arguments::system_properties(); p != NULL && readable_count < *count_ptr; p = p->next()) {\n-    if (p->is_readable()) {\n+  for (SystemProperty* p = Arguments::system_properties(); p != nullptr && readable_count < *count_ptr; p = p->next()) {\n+    if (p->readable()) {\n@@ -3433,2 +4035,2 @@\n-\/\/ property - pre-checked for NULL\n-\/\/ value_ptr - pre-checked for NULL\n+\/\/ property - pre-checked for null\n+\/\/ value_ptr - pre-checked for null\n@@ -3442,1 +4044,1 @@\n-  if (value == NULL) {\n+  if (value == nullptr) {\n@@ -3454,2 +4056,2 @@\n-\/\/ property - pre-checked for NULL\n-\/\/ value - NULL is a valid value, must be checked\n+\/\/ property - pre-checked for null\n+\/\/ value - null is a valid value, must be checked\n@@ -3458,3 +4060,1 @@\n-  jvmtiError err =JVMTI_ERROR_NOT_AVAILABLE;\n-\n-  for (SystemProperty* p = Arguments::system_properties(); p != NULL; p = p->next()) {\n+  for (SystemProperty* p = Arguments::system_properties(); p != nullptr; p = p->next()) {\n@@ -3462,2 +4062,9 @@\n-      if (p->set_writeable_value(value_ptr)) {\n-        err =  JVMTI_ERROR_NONE;\n+      if (p->writeable()) {\n+        if (p->set_value(value_ptr, AllocFailStrategy::RETURN_NULL)) {\n+          return JVMTI_ERROR_NONE;\n+        } else {\n+          return JVMTI_ERROR_OUT_OF_MEMORY;\n+        }\n+      } else {\n+        \/\/ We found a property, but it's not writeable\n+        return JVMTI_ERROR_NOT_AVAILABLE;\n@@ -3467,1 +4074,3 @@\n-  return err;\n+\n+  \/\/ We cannot find a property of the given name\n+  return JVMTI_ERROR_NOT_AVAILABLE;\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnv.cpp","additions":1320,"deletions":711,"binary":false,"changes":2031,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,1 @@\n+#include \"runtime\/javaThread.hpp\"\n@@ -31,1 +32,1 @@\n-#include \"runtime\/thread.inline.hpp\"\n+#include \"runtime\/threads.hpp\"\n@@ -36,1 +37,1 @@\n-JvmtiRawMonitor::QNode::QNode(Thread* thread) : _next(NULL), _prev(NULL),\n+JvmtiRawMonitor::QNode::QNode(Thread* thread) : _next(nullptr), _prev(nullptr),\n@@ -42,1 +43,1 @@\n-  new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<JvmtiRawMonitor*>(1, mtServiceability);\n+  new (mtServiceability) GrowableArray<JvmtiRawMonitor*>(1, mtServiceability);\n@@ -65,1 +66,1 @@\n-JvmtiRawMonitor::JvmtiRawMonitor(const char* name) : _owner(NULL),\n+JvmtiRawMonitor::JvmtiRawMonitor(const char* name) : _owner(nullptr),\n@@ -67,2 +68,2 @@\n-                                                     _entry_list(NULL),\n-                                                     _wait_set(NULL),\n+                                                     _entry_list(nullptr),\n+                                                     _wait_set(nullptr),\n@@ -70,1 +71,1 @@\n-                                                     _name(NULL) {\n+                                                     _name(nullptr) {\n@@ -130,0 +131,3 @@\n+      if (self->is_Java_thread()) {\n+        Continuation::pin(JavaThread::cast(self));\n+      }\n@@ -141,1 +145,1 @@\n-    if (_owner == NULL && Atomic::replace_if_null(&_owner, self)) {\n+    if (_owner == nullptr && Atomic::replace_if_null(&_owner, self)) {\n@@ -144,0 +148,3 @@\n+      if (self->is_Java_thread()) {\n+        Continuation::pin(JavaThread::cast(self));\n+      }\n@@ -155,1 +162,1 @@\n-  Atomic::release_store(&_owner, (Thread*)NULL);\n+  Atomic::release_store(&_owner, (Thread*)nullptr);\n@@ -157,1 +164,4 @@\n-  if (_entry_list == NULL) {\n+  if (self->is_Java_thread()) {\n+    Continuation::unpin(JavaThread::cast(self));\n+  }\n+  if (_entry_list == nullptr) {\n@@ -163,1 +173,1 @@\n-  if (w != NULL) {\n+  if (w != nullptr) {\n@@ -167,1 +177,1 @@\n-  if (w != NULL) {\n+  if (w != nullptr) {\n@@ -202,1 +212,1 @@\n-      QNode* q = NULL;\n+      QNode* q = nullptr;\n@@ -207,1 +217,1 @@\n-      if (q == NULL) {\n+      if (q == nullptr) {\n@@ -243,1 +253,1 @@\n-    JavaThread* jt = self->as_Java_thread();\n+    JavaThread* jt = JavaThread::cast(self);\n@@ -278,1 +288,1 @@\n-  if (_wait_set == NULL) {\n+  if (_wait_set == nullptr) {\n@@ -289,1 +299,1 @@\n-  ParkEvent* ev = NULL;       \/\/ consider using a small auto array ...\n+  ParkEvent* ev = nullptr;       \/\/ consider using a small auto array ...\n@@ -293,1 +303,1 @@\n-    if (w == NULL) break;\n+    if (w == nullptr) break;\n@@ -295,1 +305,1 @@\n-    if (ev != NULL) {\n+    if (ev != nullptr) {\n@@ -297,1 +307,1 @@\n-      ev = NULL;\n+      ev = nullptr;\n@@ -308,1 +318,1 @@\n-  if (ev != NULL) {\n+  if (ev != nullptr) {\n@@ -333,1 +343,1 @@\n-    JavaThread* jt = self->as_Java_thread();\n+    JavaThread* jt = JavaThread::cast(self);\n@@ -339,1 +349,1 @@\n-        ThreadBlockInVMPreprocess<ExitOnSuspend> tbivmp(jt, eos);\n+        ThreadBlockInVMPreprocess<ExitOnSuspend> tbivmp(jt, eos, true \/* allow_suspend *\/);\n@@ -348,1 +358,1 @@\n-  self->set_current_pending_raw_monitor(NULL);\n+  self->set_current_pending_raw_monitor(nullptr);\n@@ -386,1 +396,1 @@\n-    JavaThread* jt = self->as_Java_thread();\n+    JavaThread* jt = JavaThread::cast(self);\n@@ -391,1 +401,1 @@\n-        ThreadBlockInVMPreprocess<ExitOnSuspend> tbivmp(jt, eos);\n+        ThreadBlockInVMPreprocess<ExitOnSuspend> tbivmp(jt, eos, true \/* allow_suspend *\/);\n","filename":"src\/hotspot\/share\/prims\/jvmtiRawMonitor.cpp","additions":37,"deletions":27,"binary":false,"changes":64,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -52,1 +52,2 @@\n-#include \"runtime\/biasedLocking.hpp\"\n+#include \"prims\/jvmtiThreadState.hpp\"\n+#include \"runtime\/continuationWrapper.inline.hpp\"\n@@ -58,0 +59,1 @@\n+#include \"runtime\/javaThread.inline.hpp\"\n@@ -64,1 +66,0 @@\n-#include \"runtime\/thread.inline.hpp\"\n@@ -72,0 +73,1 @@\n+#include \"utilities\/objectBitSet.inline.hpp\"\n@@ -74,0 +76,2 @@\n+typedef ObjectBitSet<mtServiceability> JVMTIBitSet;\n+\n@@ -95,4 +99,3 @@\n-  _lock(Mutex::nonleaf+1, \"JvmtiTagMap_lock\", Mutex::_allow_vm_block_flag,\n-        Mutex::_safepoint_check_never),\n-  _needs_rehashing(false),\n-  _needs_cleaning(false) {\n+  _lock(Mutex::nosafepoint, \"JvmtiTagMap_lock\"),\n+  _needs_cleaning(false),\n+  _posting_events(false) {\n@@ -101,1 +104,1 @@\n-  assert(((JvmtiEnvBase *)env)->tag_map() == NULL, \"tag map already exists for environment\");\n+  assert(((JvmtiEnvBase *)env)->tag_map() == nullptr, \"tag map already exists for environment\");\n@@ -131,1 +134,1 @@\n-  ((JvmtiEnvBase *)_env)->set_tag_map(NULL);\n+  ((JvmtiEnvBase *)_env)->set_tag_map(nullptr);\n@@ -135,1 +138,1 @@\n-  _hashmap = NULL;\n+  _hashmap = nullptr;\n@@ -152,1 +155,1 @@\n-  if (tag_map == NULL) {\n+  if (tag_map == nullptr) {\n@@ -155,1 +158,1 @@\n-    if (tag_map == NULL) {\n+    if (tag_map == nullptr) {\n@@ -165,1 +168,1 @@\n-void JvmtiTagMap::entry_iterate(JvmtiTagMapEntryClosure* closure) {\n+void JvmtiTagMap::entry_iterate(JvmtiTagMapKeyClosure* closure) {\n@@ -175,5 +178,3 @@\n-\/\/ This checks for posting and rehashing before operations that\n-\/\/ this tagmap table.  The calls from a JavaThread only rehash, posting is\n-\/\/ only done before heap walks.\n-void JvmtiTagMap::check_hashmap(bool post_events) {\n-  assert(!post_events || SafepointSynchronize::is_at_safepoint(), \"precondition\");\n+\/\/ This checks for posting before operations that use\n+\/\/ this tagmap table.\n+void JvmtiTagMap::check_hashmap(GrowableArray<jlong>* objects) {\n@@ -185,1 +186,1 @@\n-      post_events &&\n+      objects != nullptr &&\n@@ -187,6 +188,1 @@\n-    remove_dead_entries_locked(true \/* post_object_free *\/);\n-  }\n-  if (_needs_rehashing) {\n-    log_info(jvmti, table)(\"TagMap table needs rehashing\");\n-    hashmap()->rehash();\n-    _needs_rehashing = false;\n+    remove_dead_entries_locked(objects);\n@@ -196,2 +192,2 @@\n-\/\/ This checks for posting and rehashing and is called from the heap walks.\n-void JvmtiTagMap::check_hashmaps_for_heapwalk() {\n+\/\/ This checks for posting and is called from the heap walks.\n+void JvmtiTagMap::check_hashmaps_for_heapwalk(GrowableArray<jlong>* objects) {\n@@ -203,1 +199,1 @@\n-  for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {\n+  for (JvmtiEnv* env = it.first(); env != nullptr; env = it.next(env)) {\n@@ -205,1 +201,1 @@\n-    if (tag_map != NULL) {\n+    if (tag_map != nullptr) {\n@@ -208,1 +204,1 @@\n-      tag_map->check_hashmap(\/*post_events*\/ true);\n+      tag_map->check_hashmap(objects);\n@@ -217,8 +213,1 @@\n-  JvmtiTagMapEntry* entry = tag_map->hashmap()->find(o);\n-  if (entry == NULL) {\n-    return 0;\n-  } else {\n-    jlong tag = entry->tag();\n-    assert(tag != 0, \"should not be zero\");\n-    return entry->tag();\n-  }\n+  return tag_map->hashmap()->find(o);\n@@ -227,1 +216,0 @@\n-\n@@ -238,3 +226,4 @@\n-\/\/ } \/\/ wrapper goes out of scope here which results in the destructor\n-\/\/      checking to see if the object has been tagged, untagged, or the\n-\/\/      tag value has changed.\n+\/\/ }\n+\/\/ wrapper goes out of scope here which results in the destructor\n+\/\/ checking to see if the object has been tagged, untagged, or the\n+\/\/ tag value has changed.\n@@ -246,1 +235,0 @@\n-  JvmtiTagMapEntry* _entry;\n@@ -253,1 +241,1 @@\n-  JvmtiTagMap* tag_map() const      { return _tag_map; }\n+  JvmtiTagMap* tag_map() const { return _tag_map; }\n@@ -257,1 +245,1 @@\n-                                       JvmtiTagMapEntry* entry, jlong obj_tag);\n+                                       jlong obj_tag);\n@@ -272,1 +260,0 @@\n-    _entry = _hashmap->find(_o);\n@@ -275,1 +262,1 @@\n-    _obj_tag = (_entry == NULL) ? 0 : _entry->tag();\n+    _obj_tag = _hashmap->find(_o);\n@@ -284,1 +271,1 @@\n-    post_callback_tag_update(_o, _hashmap, _entry, _obj_tag);\n+    post_callback_tag_update(_o, _hashmap, _obj_tag);\n@@ -293,2 +280,0 @@\n-\n-\n@@ -298,7 +283,3 @@\n-                                                      JvmtiTagMapEntry* entry,\n-  if (entry == NULL) {\n-    if (obj_tag != 0) {\n-      \/\/ callback has tagged the object\n-      assert(Thread::current()->is_VM_thread(), \"must be VMThread\");\n-      hashmap->add(o, obj_tag);\n-    }\n+  if (obj_tag == 0) {\n+    \/\/ callback has untagged the object, remove the entry if present\n+    hashmap->remove(o);\n@@ -307,9 +288,4 @@\n-    \/\/ object was previously tagged - the callback may have untagged\n-    \/\/ the object or changed the tag value\n-    if (obj_tag == 0) {\n-      hashmap->remove(o);\n-    } else {\n-      if (obj_tag != entry->tag()) {\n-         entry->set_tag(obj_tag);\n-      }\n-    }\n+    \/\/ object was previously tagged or not present - the callback may have\n+    \/\/ changed the tag value\n+    assert(Thread::current()->is_VM_thread(), \"must be VMThread\");\n+    hashmap->add(o, obj_tag);\n@@ -330,3 +306,4 @@\n-\/\/ } \/\/ wrapper goes out of scope here which results in the destructor\n-\/\/      checking to see if the referrer object has been tagged, untagged,\n-\/\/      or the tag value has changed.\n+\/\/ }\n+\/\/ wrapper goes out of scope here which results in the destructor\n+\/\/ checking to see if the referrer object has been tagged, untagged,\n+\/\/ or the tag value has changed.\n@@ -338,1 +315,0 @@\n-  JvmtiTagMapEntry* _referrer_entry;\n@@ -360,1 +336,0 @@\n-      _referrer_entry = _referrer_hashmap->find(_referrer);\n@@ -363,1 +338,2 @@\n-      _referrer_obj_tag = (_referrer_entry == NULL) ? 0 : _referrer_entry->tag();\n+      _referrer_obj_tag = _referrer_hashmap->find(_referrer);\n+\n@@ -372,1 +348,1 @@\n-    if (!is_reference_to_self()){\n+    if (!is_reference_to_self()) {\n@@ -375,1 +351,0 @@\n-                               _referrer_entry,\n@@ -382,1 +357,1 @@\n-  inline jlong* referrer_tag_p()        { return _referrer_tag_p; }\n+  inline jlong* referrer_tag_p() { return _referrer_tag_p; }\n@@ -385,1 +360,1 @@\n-  inline jlong referrer_klass_tag()     { return _referrer_klass_tag; }\n+  inline jlong referrer_klass_tag() { return _referrer_klass_tag; }\n@@ -400,1 +375,1 @@\n-  check_hashmap(\/*post_events*\/ false);\n+  check_hashmap(nullptr);  \/* don't collect dead objects *\/\n@@ -407,8 +382,3 @@\n-  JvmtiTagMapEntry* entry = hashmap->find(o);\n-  \/\/ if the object is not already tagged then we tag it\n-  if (entry == NULL) {\n-    if (tag != 0) {\n-      hashmap->add(o, tag);\n-    } else {\n-      \/\/ no-op\n-    }\n+  if (tag == 0) {\n+    \/\/ remove the entry if present\n+    hashmap->remove(o);\n@@ -417,8 +387,3 @@\n-    \/\/ if the object is already tagged then we either update\n-    \/\/ the tag (if a new tag value has been provided)\n-    \/\/ or remove the object if the new tag value is 0.\n-    if (tag == 0) {\n-      hashmap->remove(o);\n-    } else {\n-      entry->set_tag(tag);\n-    }\n+    \/\/ if the object is already tagged or not present then we add\/update\n+    \/\/ the tag\n+    hashmap->add(o, tag);\n@@ -436,1 +401,1 @@\n-  check_hashmap(\/*post_events*\/ false);\n+  check_hashmap(nullptr); \/* don't collect dead objects *\/\n@@ -491,1 +456,1 @@\n-  _fields = new (ResourceObj::C_HEAP, mtServiceability)\n+  _fields = new (mtServiceability)\n@@ -563,1 +528,1 @@\n-   enum {\n+  enum {\n@@ -565,1 +530,1 @@\n-   };\n+  };\n@@ -568,1 +533,1 @@\n-  ClassFieldMap* field_map() const          { return _field_map; }\n+  ClassFieldMap* field_map() const { return _field_map; }\n@@ -596,1 +561,1 @@\n-  if (_field_map != NULL) {\n+  if (_field_map != nullptr) {\n@@ -622,1 +587,0 @@\n-\n@@ -625,2 +589,2 @@\n-  if (_class_list == NULL) {\n-    _class_list = new (ResourceObj::C_HEAP, mtServiceability)\n+  if (_class_list == nullptr) {\n+    _class_list = new (mtServiceability)\n@@ -643,2 +607,2 @@\n-  if (cached_map != NULL) {\n-    assert(cached_map->field_map() != NULL, \"missing field list\");\n+  if (cached_map != nullptr) {\n+    assert(cached_map->field_map() != nullptr, \"missing field list\");\n@@ -658,1 +622,1 @@\n-  if (_class_list != NULL) {\n+  if (_class_list != nullptr) {\n@@ -662,2 +626,2 @@\n-      assert(cached_map != NULL, \"should not be NULL\");\n-      ik->set_jvmti_cached_class_field_map(NULL);\n+      assert(cached_map != nullptr, \"should not be null\");\n+      ik->set_jvmti_cached_class_field_map(nullptr);\n@@ -667,1 +631,1 @@\n-    _class_list = NULL;\n+    _class_list = nullptr;\n@@ -673,1 +637,1 @@\n-  return (_class_list == NULL) ? 0 : _class_list->length();\n+  return (_class_list == nullptr) ? 0 : _class_list->length();\n@@ -700,1 +664,1 @@\n-  if (klass_filter != NULL) {\n+  if (klass_filter != nullptr) {\n@@ -741,1 +705,1 @@\n-  if (s_value == NULL) {\n+  if (s_value == nullptr) {\n@@ -931,0 +895,1 @@\n+  GrowableArray<jlong>* const _dead_objects;\n@@ -934,4 +899,3 @@\n-  VM_HeapIterateOperation(ObjectClosure* blk, JvmtiTagMap* tag_map) {\n-    _blk = blk;\n-    _tag_map = tag_map;\n-  }\n+  VM_HeapIterateOperation(ObjectClosure* blk, GrowableArray<jlong>* objects,\n+                          JvmtiTagMap* tag_map) :\n+    _blk(blk), _dead_objects(objects), _tag_map(tag_map) { }\n@@ -950,1 +914,1 @@\n-    JvmtiTagMap::check_hashmaps_for_heapwalk();\n+    JvmtiTagMap::check_hashmaps_for_heapwalk(_dead_objects);\n@@ -964,1 +928,0 @@\n-\n@@ -1014,1 +977,1 @@\n-  if (klass() != NULL && !o->is_a(klass())) {\n+  if (klass() != nullptr && !o->is_a(klass())) {\n@@ -1019,1 +982,1 @@\n-  if (o != NULL && o->klass()->java_mirror() == NULL) {\n+  if (o != nullptr && o->klass()->java_mirror() == nullptr) {\n@@ -1029,1 +992,1 @@\n-  \/\/ then don't invoke the callback. Similiarly, if the object is untagged\n+  \/\/ then don't invoke the callback. Similarly, if the object is untagged\n@@ -1105,1 +1068,1 @@\n-  if (obj != NULL &&   obj->klass()->java_mirror() == NULL) {\n+  if (obj != nullptr &&   obj->klass()->java_mirror() == nullptr) {\n@@ -1124,1 +1087,1 @@\n-  if (callbacks()->heap_iteration_callback != NULL) {\n+  if (callbacks()->heap_iteration_callback != nullptr) {\n@@ -1135,1 +1098,1 @@\n-  if (callbacks()->primitive_field_callback != NULL && obj->is_instance()) {\n+  if (callbacks()->primitive_field_callback != nullptr && obj->is_instance()) {\n@@ -1154,1 +1117,1 @@\n-      callbacks()->string_primitive_value_callback != NULL &&\n+      callbacks()->string_primitive_value_callback != nullptr &&\n@@ -1166,1 +1129,1 @@\n-      callbacks()->array_primitive_value_callback != NULL &&\n+      callbacks()->array_primitive_value_callback != nullptr &&\n@@ -1189,8 +1152,14 @@\n-  MutexLocker ml(Heap_lock);\n-  IterateOverHeapObjectClosure blk(this,\n-                                   klass,\n-                                   object_filter,\n-                                   heap_object_callback,\n-                                   user_data);\n-  VM_HeapIterateOperation op(&blk, this);\n-  VMThread::execute(&op);\n+  Arena dead_object_arena(mtServiceability);\n+  GrowableArray <jlong> dead_objects(&dead_object_arena, 10, 0, 0);\n+  {\n+    MutexLocker ml(Heap_lock);\n+    IterateOverHeapObjectClosure blk(this,\n+                                     klass,\n+                                     object_filter,\n+                                     heap_object_callback,\n+                                     user_data);\n+    VM_HeapIterateOperation op(&blk, &dead_objects, this);\n+    VMThread::execute(&op);\n+  }\n+  \/\/ Post events outside of Heap_lock\n+  post_dead_objects(&dead_objects);\n@@ -1209,8 +1178,15 @@\n-  MutexLocker ml(Heap_lock);\n-  IterateThroughHeapObjectClosure blk(this,\n-                                      klass,\n-                                      heap_filter,\n-                                      callbacks,\n-                                      user_data);\n-  VM_HeapIterateOperation op(&blk, this);\n-  VMThread::execute(&op);\n+\n+  Arena dead_object_arena(mtServiceability);\n+  GrowableArray<jlong> dead_objects(&dead_object_arena, 10, 0, 0);\n+  {\n+    MutexLocker ml(Heap_lock);\n+    IterateThroughHeapObjectClosure blk(this,\n+                                        klass,\n+                                        heap_filter,\n+                                        callbacks,\n+                                        user_data);\n+    VM_HeapIterateOperation op(&blk, &dead_objects, this);\n+    VMThread::execute(&op);\n+  }\n+  \/\/ Post events outside of Heap_lock\n+  post_dead_objects(&dead_objects);\n@@ -1219,1 +1195,1 @@\n-void JvmtiTagMap::remove_dead_entries_locked(bool post_object_free) {\n+void JvmtiTagMap::remove_dead_entries_locked(GrowableArray<jlong>* objects) {\n@@ -1223,1 +1199,3 @@\n-    post_object_free = post_object_free && env()->is_enabled(JVMTI_EVENT_OBJECT_FREE);\n+    if (!env()->is_enabled(JVMTI_EVENT_OBJECT_FREE)) {\n+      objects = nullptr;\n+    }\n@@ -1225,2 +1203,2 @@\n-                           (post_object_free ? \" and posting\" : \"\"));\n-    hashmap()->remove_dead_entries(env(), post_object_free);\n+                           ((objects != nullptr) ? \" and posting\" : \"\"));\n+    hashmap()->remove_dead_entries(objects);\n@@ -1231,1 +1209,1 @@\n-void JvmtiTagMap::remove_dead_entries(bool post_object_free) {\n+void JvmtiTagMap::remove_dead_entries(GrowableArray<jlong>* objects) {\n@@ -1233,1 +1211,1 @@\n-  remove_dead_entries_locked(post_object_free);\n+  remove_dead_entries_locked(objects);\n@@ -1236,7 +1214,5 @@\n-class VM_JvmtiPostObjectFree: public VM_Operation {\n-  JvmtiTagMap* _tag_map;\n- public:\n-  VM_JvmtiPostObjectFree(JvmtiTagMap* tag_map) : _tag_map(tag_map) {}\n-  VMOp_Type type() const { return VMOp_Cleanup; }\n-  void doit() {\n-    _tag_map->remove_dead_entries(true \/* post_object_free *\/);\n+void JvmtiTagMap::post_dead_objects(GrowableArray<jlong>* const objects) {\n+  assert(Thread::current()->is_Java_thread(), \"Must post from JavaThread\");\n+  if (objects != nullptr && objects->length() > 0) {\n+    JvmtiExport::post_object_free(env(), objects);\n+    log_info(jvmti, table)(\"%d free object posted\", objects->length());\n@@ -1244,0 +1220,1 @@\n+}\n@@ -1245,8 +1222,5 @@\n-  \/\/ Doesn't need a safepoint, just the VM thread\n-  virtual bool evaluate_at_safepoint() const { return false; }\n-};\n-\n-\/\/ PostObjectFree can't be called by JavaThread, so call it from the VM thread.\n-void JvmtiTagMap::post_dead_objects_on_vm_thread() {\n-  VM_JvmtiPostObjectFree op(this);\n-  VMThread::execute(&op);\n+void JvmtiTagMap::remove_and_post_dead_objects() {\n+  ResourceMark rm;\n+  GrowableArray<jlong> objects;\n+  remove_dead_entries(&objects);\n+  post_dead_objects(&objects);\n@@ -1259,1 +1233,6 @@\n-      MutexLocker ml(lock(), Mutex::_no_safepoint_check_flag);\n+      MonitorLocker ml(lock(), Mutex::_no_safepoint_check_flag);\n+      \/\/ If another thread is posting events, let it finish\n+      while (_posting_events) {\n+        ml.wait();\n+      }\n+\n@@ -1264,0 +1243,1 @@\n+      _posting_events = true;\n@@ -1267,1 +1247,6 @@\n-    post_dead_objects_on_vm_thread();\n+    remove_and_post_dead_objects();\n+    {\n+      MonitorLocker ml(lock(), Mutex::_no_safepoint_check_flag);\n+      _posting_events = false;\n+      ml.notify_all();\n+    }\n@@ -1269,1 +1254,1 @@\n-    remove_dead_entries(false);\n+    remove_dead_entries(nullptr);\n@@ -1275,1 +1260,1 @@\n-class TagObjectCollector : public JvmtiTagMapEntryClosure {\n+class TagObjectCollector : public JvmtiTagMapKeyClosure {\n@@ -1293,2 +1278,2 @@\n-    _object_results(new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<jobject>(1, mtServiceability)),\n-    _tag_results(new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<uint64_t>(1, mtServiceability)) { }\n+    _object_results(new (mtServiceability) GrowableArray<jobject>(1, mtServiceability)),\n+    _tag_results(new (mtServiceability) GrowableArray<uint64_t>(1, mtServiceability)) { }\n@@ -1306,4 +1291,4 @@\n-  \/\/\n-  void do_entry(JvmtiTagMapEntry* entry) {\n-    for (int i=0; i<_tag_count; i++) {\n-      if (_tags[i] == entry->tag()) {\n+  \/\/ Always return true so the iteration continues.\n+  bool do_entry(JvmtiTagMapKey& key, jlong& value) {\n+    for (int i = 0; i < _tag_count; i++) {\n+      if (_tags[i] == value) {\n@@ -1314,2 +1299,2 @@\n-        oop o = entry->object();\n-        if (o == NULL) {\n+        oop o = key.object();\n+        if (o == nullptr) {\n@@ -1318,1 +1303,1 @@\n-          return;\n+          return true;\n@@ -1320,1 +1305,1 @@\n-        assert(o != NULL && Universe::heap()->is_in(o), \"sanity check\");\n+        assert(o != nullptr && Universe::heap()->is_in(o), \"sanity check\");\n@@ -1323,1 +1308,1 @@\n-        _tag_results->append((uint64_t)entry->tag());\n+        _tag_results->append(value);\n@@ -1326,0 +1311,1 @@\n+    return true;\n@@ -1335,1 +1321,1 @@\n-    \/\/ if object_result_ptr is not NULL then allocate the result and copy\n+    \/\/ if object_result_ptr is not null then allocate the result and copy\n@@ -1337,1 +1323,1 @@\n-    if (object_result_ptr != NULL) {\n+    if (object_result_ptr != nullptr) {\n@@ -1347,1 +1333,1 @@\n-    \/\/ if tag_result_ptr is not NULL then allocate the result and copy\n+    \/\/ if tag_result_ptr is not null then allocate the result and copy\n@@ -1349,1 +1335,1 @@\n-    if (tag_result_ptr != NULL) {\n+    if (tag_result_ptr != nullptr) {\n@@ -1352,1 +1338,1 @@\n-        if (object_result_ptr != NULL) {\n+        if (object_result_ptr != nullptr) {\n@@ -1382,3 +1368,0 @@\n-  if (collector.some_dead_found() && env()->is_enabled(JVMTI_EVENT_OBJECT_FREE)) {\n-    post_dead_objects_on_vm_thread();\n-  }\n@@ -1388,136 +1371,0 @@\n-\n-\/\/ ObjectMarker is used to support the marking objects when walking the\n-\/\/ heap.\n-\/\/\n-\/\/ This implementation uses the existing mark bits in an object for\n-\/\/ marking. Objects that are marked must later have their headers restored.\n-\/\/ As most objects are unlocked and don't have their identity hash computed\n-\/\/ we don't have to save their headers. Instead we save the headers that\n-\/\/ are \"interesting\". Later when the headers are restored this implementation\n-\/\/ restores all headers to their initial value and then restores the few\n-\/\/ objects that had interesting headers.\n-\/\/\n-\/\/ Future work: This implementation currently uses growable arrays to save\n-\/\/ the oop and header of interesting objects. As an optimization we could\n-\/\/ use the same technique as the GC and make use of the unused area\n-\/\/ between top() and end().\n-\/\/\n-\n-\/\/ An ObjectClosure used to restore the mark bits of an object\n-class RestoreMarksClosure : public ObjectClosure {\n- public:\n-  void do_object(oop o) {\n-    if (o != NULL) {\n-      markWord mark = o->mark();\n-      if (mark.is_marked()) {\n-        o->init_mark();\n-      }\n-    }\n-  }\n-};\n-\n-\/\/ ObjectMarker provides the mark and visited functions\n-class ObjectMarker : AllStatic {\n- private:\n-  \/\/ saved headers\n-  static GrowableArray<oop>* _saved_oop_stack;\n-  static GrowableArray<markWord>* _saved_mark_stack;\n-  static bool _needs_reset;                  \/\/ do we need to reset mark bits?\n-\n- public:\n-  static void init();                       \/\/ initialize\n-  static void done();                       \/\/ clean-up\n-\n-  static inline void mark(oop o);           \/\/ mark an object\n-  static inline bool visited(oop o);        \/\/ check if object has been visited\n-\n-  static inline bool needs_reset()            { return _needs_reset; }\n-  static inline void set_needs_reset(bool v)  { _needs_reset = v; }\n-};\n-\n-GrowableArray<oop>* ObjectMarker::_saved_oop_stack = NULL;\n-GrowableArray<markWord>* ObjectMarker::_saved_mark_stack = NULL;\n-bool ObjectMarker::_needs_reset = true;  \/\/ need to reset mark bits by default\n-\n-\/\/ initialize ObjectMarker - prepares for object marking\n-void ObjectMarker::init() {\n-  assert(Thread::current()->is_VM_thread(), \"must be VMThread\");\n-  assert(SafepointSynchronize::is_at_safepoint(), \"must be at a safepoint\");\n-\n-  \/\/ prepare heap for iteration\n-  Universe::heap()->ensure_parsability(false);  \/\/ no need to retire TLABs\n-\n-  \/\/ create stacks for interesting headers\n-  _saved_mark_stack = new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<markWord>(4000, mtServiceability);\n-  _saved_oop_stack = new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<oop>(4000, mtServiceability);\n-\n-  if (UseBiasedLocking) {\n-    BiasedLocking::preserve_marks();\n-  }\n-}\n-\n-\/\/ Object marking is done so restore object headers\n-void ObjectMarker::done() {\n-  \/\/ iterate over all objects and restore the mark bits to\n-  \/\/ their initial value\n-  RestoreMarksClosure blk;\n-  if (needs_reset()) {\n-    Universe::heap()->object_iterate(&blk);\n-  } else {\n-    \/\/ We don't need to reset mark bits on this call, but reset the\n-    \/\/ flag to the default for the next call.\n-    set_needs_reset(true);\n-  }\n-\n-  \/\/ now restore the interesting headers\n-  for (int i = 0; i < _saved_oop_stack->length(); i++) {\n-    oop o = _saved_oop_stack->at(i);\n-    markWord mark = _saved_mark_stack->at(i);\n-    o->set_mark(mark);\n-  }\n-\n-  if (UseBiasedLocking) {\n-    BiasedLocking::restore_marks();\n-  }\n-\n-  \/\/ free the stacks\n-  delete _saved_oop_stack;\n-  delete _saved_mark_stack;\n-}\n-\n-\/\/ mark an object\n-inline void ObjectMarker::mark(oop o) {\n-  assert(Universe::heap()->is_in(o), \"sanity check\");\n-  assert(!o->mark().is_marked(), \"should only mark an object once\");\n-\n-  \/\/ object's mark word\n-  markWord mark = o->mark();\n-\n-  if (o->mark_must_be_preserved(mark)) {\n-    _saved_mark_stack->push(mark);\n-    _saved_oop_stack->push(o);\n-  }\n-\n-  \/\/ mark the object\n-  o->set_mark(markWord::prototype().set_marked());\n-}\n-\n-\/\/ return true if object is marked\n-inline bool ObjectMarker::visited(oop o) {\n-  return o->mark().is_marked();\n-}\n-\n-\/\/ Stack allocated class to help ensure that ObjectMarker is used\n-\/\/ correctly. Constructor initializes ObjectMarker, destructor calls\n-\/\/ ObjectMarker's done() function to restore object headers.\n-class ObjectMarkerController : public StackObj {\n- public:\n-  ObjectMarkerController() {\n-    ObjectMarker::init();\n-  }\n-  ~ObjectMarkerController() {\n-    ObjectMarker::done();\n-  }\n-};\n-\n-\n@@ -1572,1 +1419,1 @@\n-    _last_referrer(NULL),\n+    _last_referrer(nullptr),\n@@ -1656,0 +1503,1 @@\n+  static JVMTIBitSet* _bitset;\n@@ -1665,1 +1513,1 @@\n-    if (!ObjectMarker::visited(obj)) visit_stack()->push(obj);\n+    if (!_bitset->is_marked(obj)) visit_stack()->push(obj);\n@@ -1696,1 +1544,2 @@\n-                                             BasicHeapWalkContext context);\n+                                             BasicHeapWalkContext context,\n+                                             JVMTIBitSet* bitset);\n@@ -1702,1 +1551,2 @@\n-                                                AdvancedHeapWalkContext context);\n+                                                AdvancedHeapWalkContext context,\n+                                                JVMTIBitSet* bitset);\n@@ -1735,0 +1585,1 @@\n+JVMTIBitSet* CallbackInvoker::_bitset;\n@@ -1740,1 +1591,2 @@\n-                                                     BasicHeapWalkContext context) {\n+                                                     BasicHeapWalkContext context,\n+                                                     JVMTIBitSet* bitset) {\n@@ -1747,0 +1599,1 @@\n+  _bitset = bitset;\n@@ -1753,1 +1606,2 @@\n-                                                        AdvancedHeapWalkContext context) {\n+                                                        AdvancedHeapWalkContext context,\n+                                                        JVMTIBitSet* bitset) {\n@@ -1760,0 +1614,1 @@\n+  _bitset = bitset;\n@@ -1767,1 +1622,1 @@\n-  if (cb == NULL) {\n+  if (cb == nullptr) {\n@@ -1779,1 +1634,1 @@\n-      basic_context()->object_ref_callback() != NULL) {\n+      basic_context()->object_ref_callback() != nullptr) {\n@@ -1794,1 +1649,1 @@\n-  if (cb == NULL) {\n+  if (cb == nullptr) {\n@@ -1810,1 +1665,1 @@\n-      basic_context()->object_ref_callback() != NULL) {\n+      basic_context()->object_ref_callback() != nullptr) {\n@@ -1867,1 +1722,1 @@\n-  if (cb == NULL) {\n+  if (cb == nullptr) {\n@@ -1891,1 +1746,1 @@\n-                    NULL, \/\/ referrer info\n+                    nullptr, \/\/ referrer info\n@@ -1896,1 +1751,1 @@\n-                    NULL, \/\/ referrer_tag_p\n+                    nullptr, \/\/ referrer_tag_p\n@@ -1921,1 +1776,1 @@\n-  if (cb == NULL) {\n+  if (cb == nullptr) {\n@@ -1959,1 +1814,1 @@\n-                  NULL, \/\/ referrer_tag is 0 for root\n+                  nullptr, \/\/ referrer_tag is 0 for root\n@@ -1973,1 +1828,1 @@\n-\/\/ only for ref_kinds defined by the JVM TI spec. Otherwise, NULL is passed.\n+\/\/ only for ref_kinds defined by the JVM TI spec. Otherwise, null is passed.\n@@ -1994,1 +1849,1 @@\n-  if (cb == NULL) {\n+  if (cb == nullptr) {\n@@ -2021,1 +1876,1 @@\n-                  (REF_INFO_MASK & (1 << ref_kind)) ? &reference_info : NULL,\n+                  (REF_INFO_MASK & (1 << ref_kind)) ? &reference_info : nullptr,\n@@ -2060,1 +1915,1 @@\n-  assert(context->array_primitive_value_callback() != NULL, \"no callback\");\n+  assert(context->array_primitive_value_callback() != nullptr, \"no callback\");\n@@ -2089,1 +1944,1 @@\n-  assert(context->string_primitive_value_callback() != NULL, \"no callback\");\n+  assert(context->string_primitive_value_callback() != nullptr, \"no callback\");\n@@ -2124,1 +1979,1 @@\n-  assert(context->primitive_field_callback() != NULL, \"no callback\");\n+  assert(context->primitive_field_callback() != nullptr, \"no callback\");\n@@ -2351,1 +2206,1 @@\n-    if (o == NULL) {\n+    if (o == nullptr) {\n@@ -2395,1 +2250,1 @@\n-    if (o == NULL) {\n+    if (o == nullptr) {\n@@ -2405,0 +2260,151 @@\n+\/\/ Helper class to collect\/report stack references.\n+class StackRefCollector {\n+private:\n+  JvmtiTagMap* _tag_map;\n+  JNILocalRootsClosure* _blk;\n+  \/\/ java_thread is needed only to report JNI local on top native frame;\n+  \/\/ I.e. it's required only for platform\/carrier threads or mounted virtual threads.\n+  JavaThread* _java_thread;\n+\n+  oop _threadObj;\n+  jlong _thread_tag;\n+  jlong _tid;\n+\n+  bool _is_top_frame;\n+  int _depth;\n+  frame* _last_entry_frame;\n+\n+  bool report_java_stack_refs(StackValueCollection* values, jmethodID method, jlocation bci, jint slot_offset);\n+  bool report_native_stack_refs(jmethodID method);\n+\n+public:\n+  StackRefCollector(JvmtiTagMap* tag_map, JNILocalRootsClosure* blk, JavaThread* java_thread)\n+    : _tag_map(tag_map), _blk(blk), _java_thread(java_thread),\n+      _threadObj(nullptr), _thread_tag(0), _tid(0),\n+      _is_top_frame(true), _depth(0), _last_entry_frame(nullptr)\n+  {\n+  }\n+\n+  bool set_thread(oop o);\n+  \/\/ Sets the thread and reports the reference to it with the specified kind.\n+  bool set_thread(jvmtiHeapReferenceKind kind, oop o);\n+\n+  bool do_frame(vframe* vf);\n+  \/\/ Handles frames until vf->sender() is null.\n+  bool process_frames(vframe* vf);\n+};\n+\n+bool StackRefCollector::set_thread(oop o) {\n+  _threadObj = o;\n+  _thread_tag = tag_for(_tag_map, _threadObj);\n+  _tid = java_lang_Thread::thread_id(_threadObj);\n+\n+  _is_top_frame = true;\n+  _depth = 0;\n+  _last_entry_frame = nullptr;\n+\n+  return true;\n+}\n+\n+bool StackRefCollector::set_thread(jvmtiHeapReferenceKind kind, oop o) {\n+  return set_thread(o)\n+         && CallbackInvoker::report_simple_root(kind, _threadObj);\n+}\n+\n+bool StackRefCollector::report_java_stack_refs(StackValueCollection* values, jmethodID method, jlocation bci, jint slot_offset) {\n+  for (int index = 0; index < values->size(); index++) {\n+    if (values->at(index)->type() == T_OBJECT) {\n+      oop obj = values->obj_at(index)();\n+      if (obj == nullptr) {\n+        continue;\n+      }\n+      \/\/ stack reference\n+      if (!CallbackInvoker::report_stack_ref_root(_thread_tag, _tid, _depth, method,\n+                                                  bci, slot_offset + index, obj)) {\n+        return false;\n+      }\n+    }\n+  }\n+  return true;\n+}\n+\n+bool StackRefCollector::report_native_stack_refs(jmethodID method) {\n+  _blk->set_context(_thread_tag, _tid, _depth, method);\n+  if (_is_top_frame) {\n+    \/\/ JNI locals for the top frame.\n+    assert(_java_thread != nullptr, \"sanity\");\n+    _java_thread->active_handles()->oops_do(_blk);\n+    if (_blk->stopped()) {\n+      return false;\n+    }\n+  } else {\n+    if (_last_entry_frame != nullptr) {\n+      \/\/ JNI locals for the entry frame.\n+      assert(_last_entry_frame->is_entry_frame(), \"checking\");\n+      _last_entry_frame->entry_frame_call_wrapper()->handles()->oops_do(_blk);\n+      if (_blk->stopped()) {\n+        return false;\n+      }\n+    }\n+  }\n+  return true;\n+}\n+\n+bool StackRefCollector::do_frame(vframe* vf) {\n+  if (vf->is_java_frame()) {\n+    \/\/ java frame (interpreted, compiled, ...)\n+    javaVFrame* jvf = javaVFrame::cast(vf);\n+\n+    jmethodID method = jvf->method()->jmethod_id();\n+\n+    if (!(jvf->method()->is_native())) {\n+      jlocation bci = (jlocation)jvf->bci();\n+      StackValueCollection* locals = jvf->locals();\n+      if (!report_java_stack_refs(locals, method, bci, 0)) {\n+        return false;\n+      }\n+      if (!report_java_stack_refs(jvf->expressions(), method, bci, locals->size())) {\n+        return false;\n+      }\n+\n+      \/\/ Follow oops from compiled nmethod.\n+      if (jvf->cb() != nullptr && jvf->cb()->is_nmethod()) {\n+        _blk->set_context(_thread_tag, _tid, _depth, method);\n+        jvf->cb()->as_nmethod()->oops_do(_blk);\n+        if (_blk->stopped()) {\n+          return false;\n+        }\n+      }\n+    } else {\n+      \/\/ native frame\n+      if (!report_native_stack_refs(method)) {\n+        return false;\n+      }\n+    }\n+    _last_entry_frame = nullptr;\n+    _depth++;\n+  } else {\n+    \/\/ externalVFrame - for an entry frame then we report the JNI locals\n+    \/\/ when we find the corresponding javaVFrame\n+    frame* fr = vf->frame_pointer();\n+    assert(fr != nullptr, \"sanity check\");\n+    if (fr->is_entry_frame()) {\n+      _last_entry_frame = fr;\n+    }\n+  }\n+\n+  _is_top_frame = false;\n+\n+  return true;\n+}\n+\n+bool StackRefCollector::process_frames(vframe* vf) {\n+  while (vf != nullptr) {\n+    if (!do_frame(vf)) {\n+      return false;\n+    }\n+    vf = vf->sender();\n+  }\n+  return true;\n+}\n+\n@@ -2431,0 +2437,5 @@\n+  JVMTIBitSet _bitset;\n+\n+  \/\/ Dead object tags in JvmtiTagMap\n+  GrowableArray<jlong>* _dead_objects;\n+\n@@ -2438,1 +2449,1 @@\n-    return new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<oop>(initial_visit_stack_size, mtServiceability);\n+    return new (mtServiceability) GrowableArray<oop>(initial_visit_stack_size, mtServiceability);\n@@ -2463,1 +2474,2 @@\n-  inline bool collect_stack_roots(JavaThread* java_thread, JNILocalRootsClosure* blk);\n+  inline bool collect_stack_refs(JavaThread* java_thread, JNILocalRootsClosure* blk);\n+  inline bool collect_vthread_stack_refs(oop vt);\n@@ -2472,1 +2484,2 @@\n-                       const void* user_data);\n+                       const void* user_data,\n+                       GrowableArray<jlong>* objects);\n@@ -2477,1 +2490,2 @@\n-                       const void* user_data);\n+                       const void* user_data,\n+                       GrowableArray<jlong>* objects);\n@@ -2489,1 +2503,2 @@\n-                                           const void* user_data) {\n+                                           const void* user_data,\n+                                           GrowableArray<jlong>* objects) {\n@@ -2493,1 +2508,1 @@\n-  _following_object_refs = (callbacks.object_ref_callback() != NULL);\n+  _following_object_refs = (callbacks.object_ref_callback() != nullptr);\n@@ -2498,0 +2513,1 @@\n+  _dead_objects = objects;\n@@ -2499,2 +2515,1 @@\n-\n-  CallbackInvoker::initialize_for_basic_heap_walk(tag_map, _visit_stack, user_data, callbacks);\n+  CallbackInvoker::initialize_for_basic_heap_walk(tag_map, _visit_stack, user_data, callbacks, &_bitset);\n@@ -2506,1 +2521,2 @@\n-                                           const void* user_data) {\n+                                           const void* user_data,\n+                                           GrowableArray<jlong>* objects) {\n@@ -2511,3 +2527,3 @@\n-  _reporting_primitive_fields = (callbacks.primitive_field_callback() != NULL);;\n-  _reporting_primitive_array_values = (callbacks.array_primitive_value_callback() != NULL);;\n-  _reporting_string_values = (callbacks.string_primitive_value_callback() != NULL);;\n+  _reporting_primitive_fields = (callbacks.primitive_field_callback() != nullptr);;\n+  _reporting_primitive_array_values = (callbacks.array_primitive_value_callback() != nullptr);;\n+  _reporting_string_values = (callbacks.string_primitive_value_callback() != nullptr);;\n@@ -2515,2 +2531,2 @@\n-\n-  CallbackInvoker::initialize_for_advanced_heap_walk(tag_map, _visit_stack, user_data, callbacks);\n+  _dead_objects = objects;\n+  CallbackInvoker::initialize_for_advanced_heap_walk(tag_map, _visit_stack, user_data, callbacks, &_bitset);\n@@ -2521,1 +2537,1 @@\n-    assert(_visit_stack != NULL, \"checking\");\n+    assert(_visit_stack != nullptr, \"checking\");\n@@ -2523,1 +2539,1 @@\n-    _visit_stack = NULL;\n+    _visit_stack = nullptr;\n@@ -2542,1 +2558,1 @@\n-    if (elem == NULL) {\n+    if (elem == nullptr) {\n@@ -2607,1 +2623,1 @@\n-    if (java_super != NULL && java_super != vmClasses::Object_klass()) {\n+    if (java_super != nullptr && java_super != vmClasses::Object_klass()) {\n@@ -2616,1 +2632,1 @@\n-    if (cl != NULL) {\n+    if (cl != nullptr) {\n@@ -2624,1 +2640,1 @@\n-    if (pd != NULL) {\n+    if (pd != nullptr) {\n@@ -2632,1 +2648,1 @@\n-    if (signers != NULL) {\n+    if (signers != nullptr) {\n@@ -2648,1 +2664,1 @@\n-            if (entry == NULL) {\n+            if (entry == nullptr) {\n@@ -2659,1 +2675,1 @@\n-            if (klass == NULL) {\n+            if (klass == nullptr) {\n@@ -2677,1 +2693,1 @@\n-      if (interf == NULL) {\n+      if (interf == nullptr) {\n@@ -2694,1 +2710,1 @@\n-        if (fld_o != NULL) {\n+        if (fld_o != nullptr) {\n@@ -2737,1 +2753,1 @@\n-      if (fld_o != NULL) {\n+      if (fld_o != nullptr) {\n@@ -2808,4 +2824,5 @@\n-\/\/ Walk the stack of a given thread and find all references (locals\n-\/\/ and JNI calls) and report these as stack references\n-inline bool VM_HeapWalkOperation::collect_stack_roots(JavaThread* java_thread,\n-                                                      JNILocalRootsClosure* blk)\n+\/\/ Reports the thread as JVMTI_HEAP_REFERENCE_THREAD,\n+\/\/ walks the stack of the thread, finds all references (locals\n+\/\/ and JNI calls) and reports these as stack references.\n+inline bool VM_HeapWalkOperation::collect_stack_refs(JavaThread* java_thread,\n+                                                     JNILocalRootsClosure* blk)\n@@ -2814,7 +2831,5 @@\n-  assert(threadObj != NULL, \"sanity check\");\n-\n-  \/\/ only need to get the thread's tag once per thread\n-  jlong thread_tag = tag_for(_tag_map, threadObj);\n-\n-  \/\/ also need the thread id\n-  jlong tid = java_lang_Thread::thread_id(threadObj);\n+  oop mounted_vt = java_thread->is_vthread_mounted() ? java_thread->vthread() : nullptr;\n+  if (mounted_vt != nullptr && !JvmtiEnvBase::is_vthread_alive(mounted_vt)) {\n+    mounted_vt = nullptr;\n+  }\n+  assert(threadObj != nullptr, \"sanity check\");\n@@ -2822,0 +2837,1 @@\n+  StackRefCollector stack_collector(tag_map(), blk, java_thread);\n@@ -2823,1 +2839,13 @@\n-  if (java_thread->has_last_Java_frame()) {\n+  if (!java_thread->has_last_Java_frame()) {\n+    if (!stack_collector.set_thread(JVMTI_HEAP_REFERENCE_THREAD, threadObj)) {\n+      return false;\n+    }\n+    \/\/ no last java frame but there may be JNI locals\n+    blk->set_context(tag_for(_tag_map, threadObj), java_lang_Thread::thread_id(threadObj), 0, (jmethodID)nullptr);\n+    java_thread->active_handles()->oops_do(blk);\n+    return !blk->stopped();\n+  }\n+  \/\/ vframes are resource allocated\n+  Thread* current_thread = Thread::current();\n+  ResourceMark rm(current_thread);\n+  HandleMark hm(current_thread);\n@@ -2825,4 +2853,4 @@\n-    \/\/ vframes are resource allocated\n-    Thread* current_thread = Thread::current();\n-    ResourceMark rm(current_thread);\n-    HandleMark hm(current_thread);\n+  RegisterMap reg_map(java_thread,\n+                      RegisterMap::UpdateMap::include,\n+                      RegisterMap::ProcessFrames::include,\n+                      RegisterMap::WalkContinuation::include);\n@@ -2830,1 +2858,2 @@\n-    RegisterMap reg_map(java_thread);\n+  \/\/ first handle mounted vthread (if any)\n+  if (mounted_vt != nullptr) {\n@@ -2833,76 +2862,12 @@\n-\n-    bool is_top_frame = true;\n-    int depth = 0;\n-    frame* last_entry_frame = NULL;\n-\n-    while (vf != NULL) {\n-      if (vf->is_java_frame()) {\n-\n-        \/\/ java frame (interpreted, compiled, ...)\n-        javaVFrame *jvf = javaVFrame::cast(vf);\n-\n-        \/\/ the jmethodID\n-        jmethodID method = jvf->method()->jmethod_id();\n-\n-        if (!(jvf->method()->is_native())) {\n-          jlocation bci = (jlocation)jvf->bci();\n-          StackValueCollection* locals = jvf->locals();\n-          for (int slot=0; slot<locals->size(); slot++) {\n-            if (locals->at(slot)->type() == T_OBJECT) {\n-              oop o = locals->obj_at(slot)();\n-              if (o == NULL) {\n-                continue;\n-              }\n-\n-              \/\/ stack reference\n-              if (!CallbackInvoker::report_stack_ref_root(thread_tag, tid, depth, method,\n-                                                   bci, slot, o)) {\n-                return false;\n-              }\n-            }\n-          }\n-\n-          StackValueCollection* exprs = jvf->expressions();\n-          for (int index=0; index < exprs->size(); index++) {\n-            if (exprs->at(index)->type() == T_OBJECT) {\n-              oop o = exprs->obj_at(index)();\n-              if (o == NULL) {\n-                continue;\n-              }\n-\n-              \/\/ stack reference\n-              if (!CallbackInvoker::report_stack_ref_root(thread_tag, tid, depth, method,\n-                                                   bci, locals->size() + index, o)) {\n-                return false;\n-              }\n-            }\n-          }\n-\n-          \/\/ Follow oops from compiled nmethod\n-          if (jvf->cb() != NULL && jvf->cb()->is_nmethod()) {\n-            blk->set_context(thread_tag, tid, depth, method);\n-            jvf->cb()->as_nmethod()->oops_do(blk);\n-          }\n-        } else {\n-          blk->set_context(thread_tag, tid, depth, method);\n-          if (is_top_frame) {\n-            \/\/ JNI locals for the top frame.\n-            java_thread->active_handles()->oops_do(blk);\n-          } else {\n-            if (last_entry_frame != NULL) {\n-              \/\/ JNI locals for the entry frame\n-              assert(last_entry_frame->is_entry_frame(), \"checking\");\n-              last_entry_frame->entry_frame_call_wrapper()->handles()->oops_do(blk);\n-            }\n-          }\n-        }\n-        last_entry_frame = NULL;\n-        depth++;\n-      } else {\n-        \/\/ externalVFrame - for an entry frame then we report the JNI locals\n-        \/\/ when we find the corresponding javaVFrame\n-        frame* fr = vf->frame_pointer();\n-        assert(fr != NULL, \"sanity check\");\n-        if (fr->is_entry_frame()) {\n-          last_entry_frame = fr;\n-        }\n+    \/\/ report virtual thread as JVMTI_HEAP_REFERENCE_OTHER\n+    if (!stack_collector.set_thread(JVMTI_HEAP_REFERENCE_OTHER, mounted_vt)) {\n+      return false;\n+    }\n+    \/\/ split virtual thread and carrier thread stacks by vthread entry (\"enterSpecial\") frame,\n+    \/\/ consider vthread entry frame as the last vthread stack frame\n+    while (vf != nullptr) {\n+      if (!stack_collector.do_frame(vf)) {\n+        return false;\n+      }\n+      if (vf->is_vthread_entry()) {\n+        break;\n@@ -2910,7 +2875,6 @@\n-\n-      is_top_frame = false;\n-  } else {\n-    \/\/ no last java frame but there may be JNI locals\n-    blk->set_context(thread_tag, tid, 0, (jmethodID)NULL);\n-    java_thread->active_handles()->oops_do(blk);\n-  return true;\n+  \/\/ Platform or carrier thread.\n+  vframe* vf = JvmtiEnvBase::get_cthread_last_java_vframe(java_thread, &reg_map);\n+  if (!stack_collector.set_thread(JVMTI_HEAP_REFERENCE_THREAD, threadObj)) {\n+    return false;\n+  }\n+  return stack_collector.process_frames(vf);\n@@ -2930,8 +2894,2 @@\n-    if (threadObj != NULL && !thread->is_exiting() && !thread->is_hidden_from_external_view()) {\n-      \/\/ Collect the simple root for this thread before we\n-      \/\/ collect its stack roots\n-      if (!CallbackInvoker::report_simple_root(JVMTI_HEAP_REFERENCE_THREAD,\n-                                               threadObj)) {\n-        return false;\n-      }\n-      if (!collect_stack_roots(thread, &blk)) {\n+    if (threadObj != nullptr && !thread->is_exiting() && !thread->is_hidden_from_external_view()) {\n+      if (!collect_stack_refs(thread, &blk)) {\n@@ -2945,0 +2903,36 @@\n+\/\/ Reports stack references for the unmounted virtual thread.\n+inline bool VM_HeapWalkOperation::collect_vthread_stack_refs(oop vt) {\n+  if (!JvmtiEnvBase::is_vthread_alive(vt)) {\n+    return true;\n+  }\n+  ContinuationWrapper cont(java_lang_VirtualThread::continuation(vt));\n+  if (cont.is_empty()) {\n+    return true;\n+  }\n+  assert(!cont.is_mounted(), \"sanity check\");\n+\n+  stackChunkOop chunk = cont.last_nonempty_chunk();\n+  if (chunk == nullptr || chunk->is_empty()) {\n+    return true;\n+  }\n+\n+  \/\/ vframes are resource allocated\n+  Thread* current_thread = Thread::current();\n+  ResourceMark rm(current_thread);\n+  HandleMark hm(current_thread);\n+\n+  RegisterMap reg_map(cont.continuation(), RegisterMap::UpdateMap::include);\n+\n+  JNILocalRootsClosure blk;\n+  \/\/ JavaThread is not required for unmounted virtual threads\n+  StackRefCollector stack_collector(tag_map(), &blk, nullptr);\n+  \/\/ reference to the vthread is already reported\n+  if (!stack_collector.set_thread(vt)) {\n+    return false;\n+  }\n+\n+  frame fr = chunk->top_frame(&reg_map);\n+  vframe* vf = vframe::new_vframe(&fr, &reg_map, nullptr);\n+  return stack_collector.process_frames(vf);\n+}\n+\n@@ -2952,2 +2946,2 @@\n-  assert(!ObjectMarker::visited(o), \"can't visit same object more than once\");\n-  ObjectMarker::mark(o);\n+  assert(!_bitset.is_marked(o), \"can't visit same object more than once\");\n+  _bitset.mark_obj(o);\n@@ -2963,0 +2957,7 @@\n+      \/\/ we report stack references only when initial object is not specified\n+      \/\/ (in the case we start from heap roots which include platform thread stack references)\n+      if (initial_object().is_null() && java_lang_VirtualThread::is_subclass(o->klass())) {\n+        if (!collect_vthread_stack_refs(o)) {\n+          return false;\n+        }\n+      }\n@@ -2987,1 +2988,0 @@\n-  ObjectMarkerController marker;\n@@ -2990,1 +2990,1 @@\n-  JvmtiTagMap::check_hashmaps_for_heapwalk();\n+  JvmtiTagMap::check_hashmaps_for_heapwalk(_dead_objects);\n@@ -2996,6 +2996,0 @@\n-    \/\/ If either collect_stack_roots() or collect_simple_roots()\n-    \/\/ returns false at this point, then there are no mark bits\n-    \/\/ to reset.\n-    ObjectMarker::set_needs_reset(false);\n-\n-    \/\/ Calling collect_stack_roots() before collect_simple_roots()\n@@ -3007,3 +3001,0 @@\n-\n-    \/\/ no early return so enable heap traversal to reset the mark bits\n-    ObjectMarker::set_needs_reset(true);\n@@ -3021,1 +3012,1 @@\n-      if (!ObjectMarker::visited(o)) {\n+      if (!_bitset.is_marked(o)) {\n@@ -3035,0 +3026,3 @@\n+  \/\/ VTMS transitions must be disabled before the EscapeBarrier.\n+  JvmtiVTMSTransitionDisabler disabler;\n+\n@@ -3038,4 +3032,11 @@\n-  MutexLocker ml(Heap_lock);\n-  BasicHeapWalkContext context(heap_root_callback, stack_ref_callback, object_ref_callback);\n-  VM_HeapWalkOperation op(this, Handle(), context, user_data);\n-  VMThread::execute(&op);\n+  Arena dead_object_arena(mtServiceability);\n+  GrowableArray<jlong> dead_objects(&dead_object_arena, 10, 0, 0);\n+\n+  {\n+    MutexLocker ml(Heap_lock);\n+    BasicHeapWalkContext context(heap_root_callback, stack_ref_callback, object_ref_callback);\n+    VM_HeapWalkOperation op(this, Handle(), context, user_data, &dead_objects);\n+    VMThread::execute(&op);\n+  }\n+  \/\/ Post events outside of Heap_lock\n+  post_dead_objects(&dead_objects);\n@@ -3051,4 +3052,13 @@\n-  MutexLocker ml(Heap_lock);\n-  BasicHeapWalkContext context(NULL, NULL, object_ref_callback);\n-  VM_HeapWalkOperation op(this, initial_object, context, user_data);\n-  VMThread::execute(&op);\n+  Arena dead_object_arena(mtServiceability);\n+  GrowableArray<jlong> dead_objects(&dead_object_arena, 10, 0, 0);\n+\n+  JvmtiVTMSTransitionDisabler disabler;\n+\n+  {\n+    MutexLocker ml(Heap_lock);\n+    BasicHeapWalkContext context(nullptr, nullptr, object_ref_callback);\n+    VM_HeapWalkOperation op(this, initial_object, context, user_data, &dead_objects);\n+    VMThread::execute(&op);\n+  }\n+  \/\/ Post events outside of Heap_lock\n+  post_dead_objects(&dead_objects);\n@@ -3064,0 +3074,3 @@\n+  \/\/ VTMS transitions must be disabled before the EscapeBarrier.\n+  JvmtiVTMSTransitionDisabler disabler;\n+\n@@ -3072,10 +3085,2 @@\n-  MutexLocker ml(Heap_lock);\n-  AdvancedHeapWalkContext context(heap_filter, klass, callbacks);\n-  VM_HeapWalkOperation op(this, initial_object, context, user_data);\n-  VMThread::execute(&op);\n-}\n-\/\/ Concurrent GC needs to call this in relocation pause, so after the objects are moved\n-\/\/ and have their new addresses, the table can be rehashed.\n-void JvmtiTagMap::set_needs_rehashing() {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"called in gc pause\");\n-  assert(Thread::current()->is_VM_thread(), \"should be the VM thread\");\n+  Arena dead_object_arena(mtServiceability);\n+  GrowableArray<jlong> dead_objects(&dead_object_arena, 10, 0, 0);\n@@ -3084,6 +3089,5 @@\n-  JvmtiEnvIterator it;\n-  for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {\n-    JvmtiTagMap* tag_map = env->tag_map_acquire();\n-    if (tag_map != NULL) {\n-      tag_map->_needs_rehashing = true;\n-    }\n+  {\n+    MutexLocker ml(Heap_lock);\n+    AdvancedHeapWalkContext context(heap_filter, klass, callbacks);\n+    VM_HeapWalkOperation op(this, initial_object, context, user_data, &dead_objects);\n+    VMThread::execute(&op);\n@@ -3091,0 +3095,2 @@\n+  \/\/ Post events outside of Heap_lock\n+  post_dead_objects(&dead_objects);\n@@ -3104,1 +3110,1 @@\n-  for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {\n+  for (JvmtiEnv* env = it.first(); env != nullptr; env = it.next(env)) {\n@@ -3106,1 +3112,1 @@\n-    if (tag_map != NULL) {\n+    if (tag_map != nullptr) {\n@@ -3126,1 +3132,1 @@\n-    for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {\n+    for (JvmtiEnv* env = it.first(); env != nullptr; env = it.next(env)) {\n@@ -3128,1 +3134,1 @@\n-      if (tag_map != NULL) {\n+      if (tag_map != nullptr) {\n@@ -3148,1 +3154,1 @@\n-  for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {\n+  for (JvmtiEnv* env = it.first(); env != nullptr; env = it.next(env)) {\n@@ -3150,1 +3156,1 @@\n-    if (tag_map != NULL) {\n+    if (tag_map != nullptr) {\n","filename":"src\/hotspot\/share\/prims\/jvmtiTagMap.cpp","additions":528,"deletions":522,"binary":false,"changes":1050,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -35,1 +35,1 @@\n-class JvmtiTagMapEntryClosure;\n+class JvmtiTagMapKeyClosure;\n@@ -37,1 +37,1 @@\n-class JvmtiTagMap :  public CHeapObj<mtInternal> {\n+class JvmtiTagMap :  public CHeapObj<mtServiceability> {\n@@ -41,1 +41,1 @@\n-  Mutex                 _lock;                      \/\/ lock for this tag map\n+  Monitor               _lock;                      \/\/ lock for this tag map\n@@ -43,1 +43,1 @@\n-  bool                  _needs_rehashing;\n+  bool                  _posting_events;\n@@ -54,1 +54,1 @@\n-  void check_hashmap(bool post_events);\n+  void check_hashmap(GrowableArray<jlong>* objects);\n@@ -56,2 +56,1 @@\n-  void entry_iterate(JvmtiTagMapEntryClosure* closure);\n-  void post_dead_objects_on_vm_thread();\n+  void entry_iterate(JvmtiTagMapKeyClosure* closure);\n@@ -61,2 +60,0 @@\n-  inline Mutex* lock()                      { return &_lock; }\n-\n@@ -65,0 +62,1 @@\n+  inline Monitor* lock()                    { return &_lock; }\n@@ -114,0 +112,4 @@\n+  void remove_and_post_dead_objects();\n+  void remove_dead_entries(GrowableArray<jlong>* objects);\n+  void remove_dead_entries_locked(GrowableArray<jlong>* objects);\n+  void post_dead_objects(GrowableArray<jlong>* const objects);\n@@ -115,5 +117,1 @@\n-  void remove_dead_entries(bool post_object_free);\n-  void remove_dead_entries_locked(bool post_object_free);\n-\n-  static void check_hashmaps_for_heapwalk();\n-  static void set_needs_rehashing() NOT_JVMTI_RETURN;\n+  static void check_hashmaps_for_heapwalk(GrowableArray<jlong>* objects);\n","filename":"src\/hotspot\/share\/prims\/jvmtiTagMap.hpp","additions":13,"deletions":15,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,2 +26,0 @@\n-#include \"jni.h\"\n-#include \"jvm.h\"\n@@ -35,0 +33,2 @@\n+#include \"jni.h\"\n+#include \"jvm.h\"\n@@ -44,0 +44,1 @@\n+#include \"prims\/jvmtiExport.hpp\"\n@@ -48,0 +49,1 @@\n+#include \"runtime\/javaThread.inline.hpp\"\n@@ -53,1 +55,0 @@\n-#include \"runtime\/thread.hpp\"\n@@ -121,1 +122,1 @@\n-  if (p != NULL) {\n+  if (p != nullptr) {\n@@ -125,1 +126,1 @@\n-      assert(p->field_addr((jint)byte_offset) == ptr_plus_disp,\n+      assert(p->field_addr<void>((jint)byte_offset) == ptr_plus_disp,\n@@ -224,8 +225,2 @@\n-    if (_obj == NULL) {\n-      GuardUnsafeAccess guard(_thread);\n-      T ret = RawAccess<>::load(addr());\n-      return normalize_for_read(ret);\n-    } else {\n-      T ret = HeapAccess<>::load_at(_obj, _offset);\n-      return normalize_for_read(ret);\n-    }\n+    GuardUnsafeAccess guard(_thread);\n+    return normalize_for_read(*addr());\n@@ -235,6 +230,2 @@\n-    if (_obj == NULL) {\n-      GuardUnsafeAccess guard(_thread);\n-      RawAccess<>::store(addr(), normalize_for_write(x));\n-    } else {\n-      HeapAccess<>::store_at(_obj, _offset, normalize_for_write(x));\n-    }\n+    GuardUnsafeAccess guard(_thread);\n+    *addr() = normalize_for_write(x);\n@@ -245,8 +236,3 @@\n-    if (_obj == NULL) {\n-      GuardUnsafeAccess guard(_thread);\n-      volatile T ret = RawAccess<MO_SEQ_CST>::load(addr());\n-      return normalize_for_read(ret);\n-    } else {\n-      T ret = HeapAccess<MO_SEQ_CST>::load_at(_obj, _offset);\n-      return normalize_for_read(ret);\n-    }\n+    GuardUnsafeAccess guard(_thread);\n+    volatile T ret = RawAccess<MO_SEQ_CST>::load(addr());\n+    return normalize_for_read(ret);\n@@ -256,6 +242,2 @@\n-    if (_obj == NULL) {\n-      GuardUnsafeAccess guard(_thread);\n-      RawAccess<MO_SEQ_CST>::store(addr(), normalize_for_write(x));\n-    } else {\n-      HeapAccess<MO_SEQ_CST>::store_at(_obj, _offset, normalize_for_write(x));\n-    }\n+    GuardUnsafeAccess guard(_thread);\n+    RawAccess<MO_SEQ_CST>::store(addr(), normalize_for_write(x));\n@@ -389,8 +371,0 @@\n-UNSAFE_LEAF(void, Unsafe_LoadFence(JNIEnv *env, jobject unsafe)) {\n-  OrderAccess::acquire();\n-} UNSAFE_END\n-\n-UNSAFE_LEAF(void, Unsafe_StoreFence(JNIEnv *env, jobject unsafe)) {\n-  OrderAccess::release();\n-} UNSAFE_END\n-\n@@ -404,0 +378,1 @@\n+  JvmtiVMObjectAllocEventCollector oam;\n@@ -454,1 +429,1 @@\n-    if (StubRoutines::unsafe_arraycopy() != NULL) {\n+    if (StubRoutines::unsafe_arraycopy() != nullptr) {\n@@ -471,1 +446,1 @@\n-  if (srcObj == NULL && dstObj == NULL) {\n+  if (srcObj == nullptr && dstObj == nullptr) {\n@@ -508,1 +483,1 @@\n-  assert(StubRoutines::data_cache_writeback() != NULL, \"sanity\");\n+  assert(StubRoutines::data_cache_writeback() != nullptr, \"sanity\");\n@@ -515,1 +490,1 @@\n-  assert(StubRoutines::data_cache_writeback_sync() != NULL, \"sanity\");\n+  assert(StubRoutines::data_cache_writeback_sync() != nullptr, \"sanity\");\n@@ -544,2 +519,2 @@\n-  assert(clazz != NULL, \"clazz must not be NULL\");\n-  assert(name != NULL, \"name must not be NULL\");\n+  assert(clazz != nullptr, \"clazz must not be null\");\n+  assert(name != nullptr, \"name must not be null\");\n@@ -567,1 +542,1 @@\n-  assert(field != NULL, \"field must not be NULL\");\n+  assert(field != nullptr, \"field must not be null\");\n@@ -599,1 +574,1 @@\n-  assert(field != NULL, \"field must not be NULL\");\n+  assert(field != nullptr, \"field must not be null\");\n@@ -602,1 +577,1 @@\n-  \/\/ offset from the base of a a klass metaobject.  Thus, the full dynamic\n+  \/\/ offset from the base of a klass metaobject.  Thus, the full dynamic\n@@ -606,1 +581,1 @@\n-  \/\/ large.  In that last case, this function would return NULL, since\n+  \/\/ large.  In that last case, this function would return null, since\n@@ -621,1 +596,1 @@\n-  assert(clazz != NULL, \"clazz must not be NULL\");\n+  assert(clazz != nullptr, \"clazz must not be null\");\n@@ -626,1 +601,1 @@\n-  if (klass != NULL && klass->should_be_initialized()) {\n+  if (klass != nullptr && klass->should_be_initialized()) {\n@@ -634,1 +609,1 @@\n-  assert(clazz != NULL, \"clazz must not be NULL\");\n+  assert(clazz != nullptr, \"clazz must not be null\");\n@@ -639,1 +614,1 @@\n-  if (klass != NULL && klass->should_be_initialized()) {\n+  if (klass != nullptr && klass->should_be_initialized()) {\n@@ -648,1 +623,1 @@\n-  assert(clazz != NULL, \"clazz must not be NULL\");\n+  assert(clazz != nullptr, \"clazz must not be null\");\n@@ -653,1 +628,1 @@\n-  if (k == NULL || !k->is_array_klass()) {\n+  if (k == nullptr || !k->is_array_klass()) {\n@@ -706,1 +681,1 @@\n-  env->ThrowNew(cls, NULL);\n+  env->ThrowNew(cls, nullptr);\n@@ -713,1 +688,1 @@\n-  char *utfName = NULL;\n+  char *utfName = nullptr;\n@@ -717,1 +692,1 @@\n-  assert(data != NULL, \"Class bytes must not be NULL\");\n+  assert(data != nullptr, \"Class bytes must not be null\");\n@@ -725,1 +700,1 @@\n-  if (body == NULL) {\n+  if (body == nullptr) {\n@@ -735,1 +710,1 @@\n-  if (name != NULL) {\n+  if (name != nullptr) {\n@@ -741,1 +716,1 @@\n-      if (utfName == NULL) {\n+      if (utfName == nullptr) {\n@@ -818,9 +793,3 @@\n-  if (p == NULL) {\n-    volatile jint* addr = (volatile jint*)index_oop_from_field_offset_long(p, offset);\n-    ScopedReleaseAcquire releaseAcquire(addr);\n-    return RawAccess<>::atomic_cmpxchg(addr, e, x);\n-  } else {\n-    assert_field_offset_sane(p, offset);\n-    ScopedReleaseAcquire releaseAcquire(p, offset);\n-    return HeapAccess<>::atomic_cmpxchg_at(p, (ptrdiff_t)offset, e, x);\n-  }\n+  volatile jint* addr = (volatile jint*)index_oop_from_field_offset_long(p, offset);\n+  ScopedReleaseAcquire releaseAcquire(p, offset);\n+  return Atomic::cmpxchg(addr, e, x);\n@@ -831,9 +800,3 @@\n-  if (p == NULL) {\n-    volatile jlong* addr = (volatile jlong*)index_oop_from_field_offset_long(p, offset);\n-    ScopedReleaseAcquire releaseAcquire(addr);\n-    return RawAccess<>::atomic_cmpxchg(addr, e, x);\n-  } else {\n-    assert_field_offset_sane(p, offset);\n-    ScopedReleaseAcquire releaseAcquire(p, offset);\n-    return HeapAccess<>::atomic_cmpxchg_at(p, (ptrdiff_t)offset, e, x);\n-  }\n+  volatile jlong* addr = (volatile jlong*)index_oop_from_field_offset_long(p, offset);\n+  ScopedReleaseAcquire releaseAcquire(addr);\n+  return Atomic::cmpxchg(addr, e, x);\n@@ -854,9 +817,3 @@\n-  if (p == NULL) {\n-    volatile jint* addr = (volatile jint*)index_oop_from_field_offset_long(p, offset);\n-    ScopedReleaseAcquire releaseAcquire(addr);\n-    return RawAccess<>::atomic_cmpxchg(addr, e, x) == e;\n-  } else {\n-    assert_field_offset_sane(p, offset);\n-    ScopedReleaseAcquire releaseAcquire(p, offset);\n-    return HeapAccess<>::atomic_cmpxchg_at(p, (ptrdiff_t)offset, e, x) == e;\n-  }\n+  volatile jint* addr = (volatile jint*)index_oop_from_field_offset_long(p, offset);\n+  ScopedReleaseAcquire releaseAcquire(addr);\n+  return Atomic::cmpxchg(addr, e, x) == e;\n@@ -867,9 +824,3 @@\n-  if (p == NULL) {\n-    volatile jlong* addr = (volatile jlong*)index_oop_from_field_offset_long(p, offset);\n-    ScopedReleaseAcquire releaseAcquire(addr);\n-    return RawAccess<>::atomic_cmpxchg(addr, e, x) == e;\n-  } else {\n-    assert_field_offset_sane(p, offset);\n-    ScopedReleaseAcquire releaseAcquire(p, offset);\n-    return HeapAccess<>::atomic_cmpxchg_at(p, (ptrdiff_t)offset, e, x) == e;\n-  }\n+  volatile jlong* addr = (volatile jlong*)index_oop_from_field_offset_long(p, offset);\n+  ScopedReleaseAcquire releaseAcquire(addr);\n+  return Atomic::cmpxchg(addr, e, x) == e;\n@@ -879,3 +830,2 @@\n-  assert(event != NULL, \"invariant\");\n-  assert(event->should_commit(), \"invariant\");\n-  event->set_parkedClass((obj != NULL) ? obj->klass() : NULL);\n+  assert(event != nullptr, \"invariant\");\n+  event->set_parkedClass((obj != nullptr) ? obj->klass() : nullptr);\n@@ -884,1 +834,1 @@\n-  event->set_address((obj != NULL) ? (u8)cast_from_oop<uintptr_t>(obj) : 0);\n+  event->set_address((obj != nullptr) ? (u8)cast_from_oop<uintptr_t>(obj) : 0);\n@@ -910,13 +860,15 @@\n-  if (jthread != NULL) {\n-    ThreadsListHandle tlh;\n-    JavaThread* thr = NULL;\n-    oop java_thread = NULL;\n-    (void) tlh.cv_internal_thread_to_JavaThread(jthread, &thr, &java_thread);\n-    if (java_thread != NULL) {\n-      \/\/ This is a valid oop.\n-      if (thr != NULL) {\n-        \/\/ The JavaThread is alive.\n-        Parker* p = thr->parker();\n-        HOTSPOT_THREAD_UNPARK((uintptr_t) p);\n-        p->unpark();\n-      }\n+  if (jthread != nullptr) {\n+    oop thread_oop = JNIHandles::resolve_non_null(jthread);\n+    \/\/ Get the JavaThread* stored in the java.lang.Thread object _before_\n+    \/\/ the embedded ThreadsListHandle is constructed so we know if the\n+    \/\/ early life stage of the JavaThread* is protected. We use acquire\n+    \/\/ here to ensure that if we see a non-nullptr value, then we also\n+    \/\/ see the main ThreadsList updates from the JavaThread* being added.\n+    FastThreadsListHandle ftlh(thread_oop, java_lang_Thread::thread_acquire(thread_oop));\n+    JavaThread* thr = ftlh.protected_java_thread();\n+    if (thr != nullptr) {\n+      \/\/ The still live JavaThread* is protected by the FastThreadsListHandle\n+      \/\/ so it is safe to access.\n+      Parker* p = thr->parker();\n+      HOTSPOT_THREAD_UNPARK((uintptr_t) p);\n+      p->unpark();\n@@ -924,2 +876,1 @@\n-  } \/\/ ThreadsListHandle is destroyed here.\n-\n+  } \/\/ FastThreadsListHandle is destroyed here.\n@@ -1030,2 +981,0 @@\n-    {CC \"loadFence\",          CC \"()V\",                  FN_PTR(Unsafe_LoadFence)},\n-    {CC \"storeFence\",         CC \"()V\",                  FN_PTR(Unsafe_StoreFence)},\n","filename":"src\/hotspot\/share\/prims\/unsafe.cpp","additions":70,"deletions":121,"binary":false,"changes":191,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,1 +26,1 @@\n-#include \"jvm.h\"\n+#include \"cds\/cds_globals.hpp\"\n@@ -38,0 +38,1 @@\n+#include \"jvm.h\"\n@@ -43,0 +44,1 @@\n+#include \"oops\/instanceKlass.hpp\"\n@@ -44,0 +46,1 @@\n+#include \"prims\/jvmtiAgentList.hpp\"\n@@ -54,0 +57,1 @@\n+#include \"runtime\/synchronizer.hpp\"\n@@ -56,1 +60,1 @@\n-#include \"services\/memTracker.hpp\"\n+#include \"services\/nmtCommon.hpp\"\n@@ -58,0 +62,1 @@\n+#include \"utilities\/debug.hpp\"\n@@ -60,0 +65,1 @@\n+#include \"utilities\/parseInteger.hpp\"\n@@ -62,0 +68,1 @@\n+#include \"utilities\/systemMemoryBarrier.hpp\"\n@@ -66,1 +73,3 @@\n-#define DEFAULT_JAVA_LAUNCHER  \"generic\"\n+#include <limits>\n+\n+static const char _default_java_launcher[] = \"generic\";\n@@ -68,2 +77,4 @@\n-char*  Arguments::_jvm_flags_file               = NULL;\n-char** Arguments::_jvm_flags_array              = NULL;\n+#define DEFAULT_JAVA_LAUNCHER _default_java_launcher\n+\n+char*  Arguments::_jvm_flags_file               = nullptr;\n+char** Arguments::_jvm_flags_array              = nullptr;\n@@ -71,1 +82,1 @@\n-char** Arguments::_jvm_args_array               = NULL;\n+char** Arguments::_jvm_args_array               = nullptr;\n@@ -73,3 +84,2 @@\n-char*  Arguments::_java_command                 = NULL;\n-SystemProperty* Arguments::_system_properties   = NULL;\n-const char*  Arguments::_gc_log_filename        = NULL;\n+char*  Arguments::_java_command                 = nullptr;\n+SystemProperty* Arguments::_system_properties   = nullptr;\n@@ -78,2 +88,1 @@\n-bool   Arguments::_java_compiler                = false;\n-const char*  Arguments::_java_vendor_url_bug    = NULL;\n+const char*  Arguments::_java_vendor_url_bug    = nullptr;\n@@ -93,2 +102,3 @@\n-char*  Arguments::SharedArchivePath             = NULL;\n-char*  Arguments::SharedDynamicArchivePath      = NULL;\n+char*  Arguments::_default_shared_archive_path  = nullptr;\n+char*  Arguments::SharedArchivePath             = nullptr;\n+char*  Arguments::SharedDynamicArchivePath      = nullptr;\n@@ -96,2 +106,1 @@\n-AgentLibraryList Arguments::_libraryList;\n-AgentLibraryList Arguments::_agentList;\n+LegacyGCLogging Arguments::_legacyGCLogging     = { 0, 0 };\n@@ -102,3 +111,3 @@\n-abort_hook_t     Arguments::_abort_hook         = NULL;\n-exit_hook_t      Arguments::_exit_hook          = NULL;\n-vfprintf_hook_t  Arguments::_vfprintf_hook      = NULL;\n+abort_hook_t     Arguments::_abort_hook         = nullptr;\n+exit_hook_t      Arguments::_exit_hook          = nullptr;\n+vfprintf_hook_t  Arguments::_vfprintf_hook      = nullptr;\n@@ -107,6 +116,6 @@\n-SystemProperty *Arguments::_sun_boot_library_path = NULL;\n-SystemProperty *Arguments::_java_library_path = NULL;\n-SystemProperty *Arguments::_java_home = NULL;\n-SystemProperty *Arguments::_java_class_path = NULL;\n-SystemProperty *Arguments::_jdk_boot_class_path_append = NULL;\n-SystemProperty *Arguments::_vm_info = NULL;\n+SystemProperty *Arguments::_sun_boot_library_path = nullptr;\n+SystemProperty *Arguments::_java_library_path = nullptr;\n+SystemProperty *Arguments::_java_home = nullptr;\n+SystemProperty *Arguments::_java_class_path = nullptr;\n+SystemProperty *Arguments::_jdk_boot_class_path_append = nullptr;\n+SystemProperty *Arguments::_vm_info = nullptr;\n@@ -114,2 +123,2 @@\n-GrowableArray<ModulePatchPath*> *Arguments::_patch_mod_prefix = NULL;\n-PathString *Arguments::_system_boot_class_path = NULL;\n+GrowableArray<ModulePatchPath*> *Arguments::_patch_mod_prefix = nullptr;\n+PathString *Arguments::_boot_class_path = nullptr;\n@@ -118,1 +127,1 @@\n-char* Arguments::_ext_dirs = NULL;\n+char* Arguments::_ext_dirs = nullptr;\n@@ -120,10 +129,7 @@\n-bool PathString::set_value(const char *value) {\n-  if (_value != NULL) {\n-    FreeHeap(_value);\n-  }\n-  _value = AllocateHeap(strlen(value)+1, mtArguments);\n-  assert(_value != NULL, \"Unable to allocate space for new path value\");\n-  if (_value != NULL) {\n-    strcpy(_value, value);\n-  } else {\n-    \/\/ not able to allocate\n+\/\/ True if -Xshare:auto option was specified.\n+static bool xshare_auto_cmd_line = false;\n+\n+bool PathString::set_value(const char *value, AllocFailType alloc_failmode) {\n+  char* new_value = AllocateHeap(strlen(value)+1, mtArguments, alloc_failmode);\n+  if (new_value == nullptr) {\n+    assert(alloc_failmode == AllocFailStrategy::RETURN_NULL, \"must be\");\n@@ -132,0 +138,5 @@\n+  if (_value != nullptr) {\n+    FreeHeap(_value);\n+  }\n+  _value = new_value;\n+  strcpy(_value, value);\n@@ -138,1 +149,1 @@\n-  if (value != NULL) {\n+  if (value != nullptr) {\n@@ -140,1 +151,1 @@\n-    if (_value != NULL) {\n+    if (_value != nullptr) {\n@@ -144,3 +155,3 @@\n-    assert(sp != NULL, \"Unable to allocate space for new append path value\");\n-    if (sp != NULL) {\n-      if (_value != NULL) {\n+    assert(sp != nullptr, \"Unable to allocate space for new append path value\");\n+    if (sp != nullptr) {\n+      if (_value != nullptr) {\n@@ -160,2 +171,2 @@\n-  if (value == NULL) {\n-    _value = NULL;\n+  if (value == nullptr) {\n+    _value = nullptr;\n@@ -169,1 +180,1 @@\n-  if (_value != NULL) {\n+  if (_value != nullptr) {\n@@ -171,1 +182,1 @@\n-    _value = NULL;\n+    _value = nullptr;\n@@ -176,1 +187,1 @@\n-  assert(module_name != NULL && path != NULL, \"Invalid module name or path value\");\n+  assert(module_name != nullptr && path != nullptr, \"Invalid module name or path value\");\n@@ -184,1 +195,1 @@\n-  if (_module_name != NULL) {\n+  if (_module_name != nullptr) {\n@@ -186,1 +197,1 @@\n-    _module_name = NULL;\n+    _module_name = nullptr;\n@@ -188,1 +199,1 @@\n-  if (_path != NULL) {\n+  if (_path != nullptr) {\n@@ -190,1 +201,1 @@\n-    _path = NULL;\n+    _path = nullptr;\n@@ -195,2 +206,2 @@\n-  if (key == NULL) {\n-    _key = NULL;\n+  if (key == nullptr) {\n+    _key = nullptr;\n@@ -201,1 +212,1 @@\n-  _next = NULL;\n+  _next = nullptr;\n@@ -206,19 +217,0 @@\n-AgentLibrary::AgentLibrary(const char* name, const char* options,\n-               bool is_absolute_path, void* os_lib,\n-               bool instrument_lib) {\n-  _name = AllocateHeap(strlen(name)+1, mtArguments);\n-  strcpy(_name, name);\n-  if (options == NULL) {\n-    _options = NULL;\n-  } else {\n-    _options = AllocateHeap(strlen(options)+1, mtArguments);\n-    strcpy(_options, options);\n-  }\n-  _is_absolute_path = is_absolute_path;\n-  _os_lib = os_lib;\n-  _next = NULL;\n-  _state = agent_invalid;\n-  _is_static_lib = false;\n-  _is_instrument_lib = instrument_lib;\n-}\n-\n@@ -240,1 +232,1 @@\n-  const char* tail = NULL;\n+  const char* tail = nullptr;\n@@ -242,1 +234,1 @@\n-  if (tail != NULL && *tail == '\\0') {\n+  if (tail != nullptr && *tail == '\\0') {\n@@ -254,1 +246,1 @@\n-  for (\/* empty *\/; *names != NULL; ++names) {\n+  for (\/* empty *\/; *names != nullptr; ++names) {\n@@ -269,2 +261,2 @@\n-  assert((*option)->optionString != NULL, \"invariant\");\n-  char* tail = NULL;\n+  assert((*option)->optionString != nullptr, \"invariant\");\n+  char* tail = nullptr;\n@@ -315,17 +307,0 @@\n-void Arguments::add_init_library(const char* name, char* options) {\n-  _libraryList.add(new AgentLibrary(name, options, false, NULL));\n-}\n-\n-void Arguments::add_init_agent(const char* name, char* options, bool absolute_path) {\n-  _agentList.add(new AgentLibrary(name, options, absolute_path, NULL));\n-}\n-\n-void Arguments::add_instrument_agent(const char* name, char* options, bool absolute_path) {\n-  _agentList.add(new AgentLibrary(name, options, absolute_path, NULL, true));\n-}\n-\n-\/\/ Late-binding agents not started via arguments\n-void Arguments::add_loaded_agent(AgentLibrary *agentLib) {\n-  _agentList.add(agentLib);\n-}\n-\n@@ -385,1 +360,1 @@\n-  \/\/ Set up _system_boot_class_path which is not a property but\n+  \/\/ Set up _boot_class_path which is not a property but\n@@ -387,2 +362,2 @@\n-  \/\/ property. It is used to store the underlying system boot class path.\n-  _system_boot_class_path = new PathString(NULL);\n+  \/\/ property. It is used to store the underlying boot class path.\n+  _boot_class_path = new PathString(nullptr);\n@@ -400,1 +375,1 @@\n-  \/\/ Properties values are set to NULL and they are\n+  \/\/ Properties values are set to nullptr and they are\n@@ -402,3 +377,3 @@\n-  _sun_boot_library_path = new SystemProperty(\"sun.boot.library.path\", NULL,  true);\n-  _java_library_path = new SystemProperty(\"java.library.path\", NULL,  true);\n-  _java_home =  new SystemProperty(\"java.home\", NULL,  true);\n+  _sun_boot_library_path = new SystemProperty(\"sun.boot.library.path\", nullptr,  true);\n+  _java_library_path = new SystemProperty(\"java.library.path\", nullptr,  true);\n+  _java_home =  new SystemProperty(\"java.home\", nullptr,  true);\n@@ -410,1 +385,1 @@\n-  _jdk_boot_class_path_append = new SystemProperty(\"jdk.boot.class.path.append\", \"\", false, true);\n+  _jdk_boot_class_path_append = new SystemProperty(\"jdk.boot.class.path.append\", nullptr, false, true);\n@@ -528,12 +503,4 @@\n-  { \"SuspendRetryCount\",            JDK_Version::undefined(), JDK_Version::jdk(17), JDK_Version::jdk(18) },\n-  { \"SuspendRetryDelay\",            JDK_Version::undefined(), JDK_Version::jdk(17), JDK_Version::jdk(18) },\n-  { \"CriticalJNINatives\",           JDK_Version::jdk(16), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"AlwaysLockClassLoader\",        JDK_Version::jdk(17), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"UseBiasedLocking\",             JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"BiasedLockingStartupDelay\",    JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"PrintBiasedLockingStatistics\", JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"BiasedLockingBulkRebiasThreshold\",    JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"BiasedLockingBulkRevokeThreshold\",    JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"BiasedLockingDecayTime\",              JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"UseOptoBiasInlining\",                 JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"PrintPreciseBiasedLockingStatistics\", JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n+  { \"DumpSharedSpaces\",             JDK_Version::jdk(18), JDK_Version::jdk(19), JDK_Version::undefined() },\n+  { \"DynamicDumpSharedSpaces\",      JDK_Version::jdk(18), JDK_Version::jdk(19), JDK_Version::undefined() },\n+  { \"RequireSharedSpaces\",          JDK_Version::jdk(18), JDK_Version::jdk(19), JDK_Version::undefined() },\n+  { \"UseSharedSpaces\",              JDK_Version::jdk(18), JDK_Version::jdk(19), JDK_Version::undefined() },\n@@ -547,2 +514,15 @@\n-  { \"AssertOnSuspendWaitFailure\",   JDK_Version::undefined(), JDK_Version::jdk(17), JDK_Version::jdk(18) },\n-  { \"TraceSuspendWaitFailures\",     JDK_Version::undefined(), JDK_Version::jdk(17), JDK_Version::jdk(18) },\n+\n+  { \"EnableWaitForParallelLoad\",    JDK_Version::jdk(20), JDK_Version::jdk(21), JDK_Version::jdk(22) },\n+  { \"G1ConcRefinementGreenZone\",    JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::undefined() },\n+  { \"G1ConcRefinementYellowZone\",   JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::undefined() },\n+  { \"G1ConcRefinementRedZone\",      JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::undefined() },\n+  { \"G1ConcRefinementThresholdStep\", JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::undefined() },\n+  { \"G1UseAdaptiveConcRefinement\",  JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::undefined() },\n+  { \"G1ConcRefinementServiceIntervalMillis\", JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::undefined() },\n+\n+  { \"G1UsePreventiveGC\",            JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::jdk(22) },\n+  { \"G1ConcRSLogCacheSize\",         JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::undefined() },\n+  { \"G1ConcRSHotCardLimit\",         JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::undefined() },\n+  { \"RefDiscoveryPolicy\",           JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::undefined() },\n+  { \"MetaspaceReclaimPolicy\",       JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::undefined() },\n+\n@@ -550,1 +530,1 @@\n-  { \"DummyObsoleteTestFlag\",        JDK_Version::undefined(), JDK_Version::jdk(17), JDK_Version::undefined() },\n+  { \"DummyObsoleteTestFlag\",        JDK_Version::undefined(), JDK_Version::jdk(18), JDK_Version::undefined() },\n@@ -564,1 +544,1 @@\n-  { NULL, JDK_Version(0), JDK_Version(0) }\n+  { nullptr, JDK_Version(0), JDK_Version(0) }\n@@ -576,1 +556,1 @@\n-  { NULL, NULL}\n+  { nullptr, nullptr}\n@@ -590,1 +570,1 @@\n-  for (size_t i = 0; special_jvm_flags[i].name != NULL; i++) {\n+  for (size_t i = 0; special_jvm_flags[i].name != nullptr; i++) {\n@@ -600,1 +580,1 @@\n-  assert(version != NULL, \"Must provide a version buffer\");\n+  assert(version != nullptr, \"Must provide a version buffer\");\n@@ -611,1 +591,1 @@\n-        if (real_flag != NULL) {\n+        if (real_flag != nullptr) {\n@@ -626,1 +606,1 @@\n-  assert(version != NULL, \"Must provide a version buffer\");\n+  assert(version != nullptr, \"Must provide a version buffer\");\n@@ -643,1 +623,1 @@\n-  for (size_t i = 0; aliased_jvm_flags[i].alias_name != NULL; i++) {\n+  for (size_t i = 0; aliased_jvm_flags[i].alias_name != nullptr; i++) {\n@@ -654,1 +634,1 @@\n-  for (size_t i = 0; special_jvm_flags[i].name != NULL; i++) {\n+  for (size_t i = 0; special_jvm_flags[i].name != nullptr; i++) {\n@@ -683,1 +663,1 @@\n-  for (size_t i = 0; special_jvm_flags[i].name != NULL; i++) {\n+  for (size_t i = 0; special_jvm_flags[i].name != nullptr; i++) {\n@@ -716,1 +696,1 @@\n-        if (JVMFlag::find_declared_flag(flag.name) != NULL) {\n+        if (JVMFlag::find_declared_flag(flag.name) != nullptr) {\n@@ -731,1 +711,1 @@\n-        if (JVMFlag::find_declared_flag(flag.name) != NULL) {\n+        if (JVMFlag::find_declared_flag(flag.name) != nullptr) {\n@@ -742,45 +722,1 @@\n-\/\/ Parses a size specification string.\n-  julong n = 0;\n-\n-  \/\/ First char must be a digit. Don't allow negative numbers or leading spaces.\n-  if (!isdigit(*s)) {\n-    return false;\n-  }\n-\n-  bool is_hex = (s[0] == '0' && (s[1] == 'x' || s[1] == 'X'));\n-  char* remainder;\n-  errno = 0;\n-  n = strtoull(s, &remainder, (is_hex ? 16 : 10));\n-  if (errno != 0) {\n-    return false;\n-  }\n-\n-  \/\/ Fail if no number was read at all or if the remainder contains more than a single non-digit character.\n-  if (remainder == s || strlen(remainder) > 1) {\n-    return false;\n-  }\n-\n-  switch (*remainder) {\n-    case 'T': case 't':\n-      *result = n * G * K;\n-      \/\/ Check for overflow.\n-      if (*result\/((julong)G * K) != n) return false;\n-      return true;\n-    case 'G': case 'g':\n-      *result = n * G;\n-      if (*result\/G != n) return false;\n-      return true;\n-    case 'M': case 'm':\n-      *result = n * M;\n-      if (*result\/M != n) return false;\n-      return true;\n-    case 'K': case 'k':\n-      *result = n * K;\n-      if (*result\/K != n) return false;\n-      return true;\n-    case '\\0':\n-      *result = n;\n-      return true;\n-    default:\n-      return false;\n-  }\n+  return parse_integer(s, result);\n@@ -822,1 +758,5 @@\n-static bool set_fp_numeric_flag(JVMFlag* flag, char* value, JVMFlagOrigin origin) {\n+static bool set_fp_numeric_flag(JVMFlag* flag, const char* value, JVMFlagOrigin origin) {\n+  \/\/ strtod allows leading whitespace, but our flag format does not.\n+  if (*value == '\\0' || isspace(*value)) {\n+    return false;\n+  }\n@@ -829,0 +769,4 @@\n+  if (g_isnan(v) || !g_isfinite(v)) {\n+    \/\/ Currently we cannot handle these special values.\n+    return false;\n+  }\n@@ -836,9 +780,2 @@\n-static bool set_numeric_flag(JVMFlag* flag, char* value, JVMFlagOrigin origin) {\n-  julong v;\n-  int int_v;\n-  intx intx_v;\n-  bool is_neg = false;\n-\n-  if (flag == NULL) {\n-    return false;\n-  }\n+static bool set_numeric_flag(JVMFlag* flag, const char* value, JVMFlagOrigin origin) {\n+  JVMFlag::Error result = JVMFlag::WRONG_FORMAT;\n@@ -846,14 +783,3 @@\n-  \/\/ Check the sign first since atojulong() parses only unsigned values.\n-  if (*value == '-') {\n-    if (!flag->is_intx() && !flag->is_int()) {\n-      return false;\n-    }\n-    value++;\n-    is_neg = true;\n-  }\n-  if (!Arguments::atojulong(value, &v)) {\n-    return false;\n-  }\n-    int_v = (int) v;\n-    if (is_neg) {\n-      int_v = -int_v;\n+    int v;\n+    if (parse_integer(value, &v)) {\n+      result = JVMFlagAccess::set_int(flag, &v, origin);\n@@ -862,3 +788,4 @@\n-    return JVMFlagAccess::set_int(flag, &int_v, origin) == JVMFlag::SUCCESS;\n-    uint uint_v = (uint) v;\n-    return JVMFlagAccess::set_uint(flag, &uint_v, origin) == JVMFlag::SUCCESS;\n+    uint v;\n+    if (parse_integer(value, &v)) {\n+      result = JVMFlagAccess::set_uint(flag, &v, origin);\n+    }\n@@ -867,3 +794,3 @@\n-    intx_v = (intx) v;\n-    if (is_neg) {\n-      intx_v = -intx_v;\n+    intx v;\n+    if (parse_integer(value, &v)) {\n+      result = JVMFlagAccess::set_intx(flag, &v, origin);\n@@ -871,3 +798,4 @@\n-    return JVMFlagAccess::set_intx(flag, &intx_v, origin) == JVMFlag::SUCCESS;\n-    uintx uintx_v = (uintx) v;\n-    return JVMFlagAccess::set_uintx(flag, &uintx_v, origin) == JVMFlag::SUCCESS;\n+    uintx v;\n+    if (parse_integer(value, &v)) {\n+      result = JVMFlagAccess::set_uintx(flag, &v, origin);\n+    }\n@@ -876,2 +804,4 @@\n-    uint64_t uint64_t_v = (uint64_t) v;\n-    return JVMFlagAccess::set_uint64_t(flag, &uint64_t_v, origin) == JVMFlag::SUCCESS;\n+    uint64_t v;\n+    if (parse_integer(value, &v)) {\n+      result = JVMFlagAccess::set_uint64_t(flag, &v, origin);\n+    }\n@@ -879,7 +809,4 @@\n-    size_t size_t_v = (size_t) v;\n-    return JVMFlagAccess::set_size_t(flag, &size_t_v, origin) == JVMFlag::SUCCESS;\n-  } else if (flag->is_double()) {\n-    double double_v = (double) v;\n-    return JVMFlagAccess::set_double(flag, &double_v, origin) == JVMFlag::SUCCESS;\n-  } else {\n-    return false;\n+    size_t v;\n+    if (parse_integer(value, &v)) {\n+      result = JVMFlagAccess::set_size_t(flag, &v, origin);\n+    }\n@@ -887,0 +814,2 @@\n+\n+  return result == JVMFlag::SUCCESS;\n@@ -890,0 +819,3 @@\n+  if (value[0] == '\\0') {\n+    value = nullptr;\n+  }\n@@ -899,1 +831,1 @@\n-  size_t old_len = old_value != NULL ? strlen(old_value) : 0;\n+  size_t old_len = old_value != nullptr ? strlen(old_value) : 0;\n@@ -902,1 +834,1 @@\n-  char* free_this_too = NULL;\n+  char* free_this_too = nullptr;\n@@ -923,1 +855,1 @@\n-const char* Arguments::handle_aliases_and_deprecation(const char* arg, bool warn) {\n+const char* Arguments::handle_aliases_and_deprecation(const char* arg) {\n@@ -936,1 +868,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -941,10 +873,8 @@\n-      if (warn) {\n-        char version[256];\n-        since.to_string(version, sizeof(version));\n-        if (real_name != arg) {\n-          warning(\"Option %s was deprecated in version %s and will likely be removed in a future release. Use option %s instead.\",\n-                  arg, version, real_name);\n-        } else {\n-          warning(\"Option %s was deprecated in version %s and will likely be removed in a future release.\",\n-                  arg, version);\n-        }\n+      char version[256];\n+      since.to_string(version, sizeof(version));\n+      if (real_name != arg) {\n+        warning(\"Option %s was deprecated in version %s and will likely be removed in a future release. Use option %s instead.\",\n+                arg, version, real_name);\n+      } else {\n+        warning(\"Option %s was deprecated in version %s and will likely be removed in a future release.\",\n+                arg, version);\n@@ -956,1 +886,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -959,12 +889,9 @@\n-bool Arguments::parse_argument(const char* arg, JVMFlagOrigin origin) {\n-\n-  \/\/ range of acceptable characters spelled out for portability reasons\n-#define NAME_RANGE  \"[abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_]\"\n-  char name[BUFLEN+1];\n-  char dummy;\n-  const char* real_name;\n-  bool warn_if_deprecated = true;\n-  if (sscanf(arg, \"-%\" XSTR(BUFLEN) NAME_RANGE \"%c\", name, &dummy) == 1) {\n-    real_name = handle_aliases_and_deprecation(name, warn_if_deprecated);\n-    if (real_name == NULL) {\n-      return false;\n+JVMFlag* Arguments::find_jvm_flag(const char* name, size_t name_length) {\n+  char name_copied[BUFLEN+1];\n+  if (name[name_length] != 0) {\n+    if (name_length > BUFLEN) {\n+      return nullptr;\n+    } else {\n+      strncpy(name_copied, name, name_length);\n+      name_copied[name_length] = '\\0';\n+      name = name_copied;\n@@ -974,6 +901,26 @@\n-    JVMFlag* flag = JVMFlag::find_flag(real_name);\n-    return set_bool_flag(flag, false, origin);\n-  if (sscanf(arg, \"+%\" XSTR(BUFLEN) NAME_RANGE \"%c\", name, &dummy) == 1) {\n-    real_name = handle_aliases_and_deprecation(name, warn_if_deprecated);\n-    if (real_name == NULL) {\n-      return false;\n+\n+  const char* real_name = Arguments::handle_aliases_and_deprecation(name);\n+  if (real_name == nullptr) {\n+    return nullptr;\n+  }\n+  JVMFlag* flag = JVMFlag::find_flag(real_name);\n+  return flag;\n+}\n+\n+bool Arguments::parse_argument(const char* arg, JVMFlagOrigin origin) {\n+  bool is_bool = false;\n+  bool bool_val = false;\n+  char c = *arg;\n+  if (c == '+' || c == '-') {\n+    is_bool = true;\n+    bool_val = (c == '+');\n+    arg++;\n+  }\n+\n+  const char* name = arg;\n+  while (true) {\n+    c = *arg;\n+    if (isalnum(c) || (c == '_')) {\n+      ++arg;\n+    } else {\n+      break;\n@@ -982,2 +929,0 @@\n-    JVMFlag* flag = JVMFlag::find_flag(real_name);\n-    return set_bool_flag(flag, true, origin);\n@@ -986,3 +931,9 @@\n-  char punct;\n-  if (sscanf(arg, \"%\" XSTR(BUFLEN) NAME_RANGE \"%c\", name, &punct) == 2 && punct == '=') {\n-    const char* value = strchr(arg, '=') + 1;\n+  size_t name_len = size_t(arg - name);\n+  if (name_len == 0) {\n+    return false;\n+  }\n+\n+  JVMFlag* flag = find_jvm_flag(name, name_len);\n+  if (flag == nullptr) {\n+    return false;\n+  }\n@@ -990,3 +941,3 @@\n-    \/\/ this scanf pattern matches both strings (handled here) and numbers (handled later))\n-    real_name = handle_aliases_and_deprecation(name, warn_if_deprecated);\n-    if (real_name == NULL) {\n+  if (is_bool) {\n+    if (*arg != 0) {\n+      \/\/ Error -- extra characters such as -XX:+BoolFlag=123\n@@ -995,2 +946,6 @@\n-    JVMFlag* flag = JVMFlag::find_flag(real_name);\n-    if (flag != NULL && flag->is_ccstr()) {\n+    return set_bool_flag(flag, bool_val, origin);\n+  }\n+\n+  if (arg[0] == '=') {\n+    const char* value = arg + 1;\n+    if (flag->is_ccstr()) {\n@@ -1000,3 +955,0 @@\n-        if (value[0] == '\\0') {\n-          value = NULL;\n-        }\n@@ -1005,0 +957,2 @@\n+    } else if (flag->is_double()) {\n+      return set_fp_numeric_flag(flag, value, origin);\n@@ -1006,1 +960,1 @@\n-      warn_if_deprecated = false; \/\/ if arg is deprecated, we've already done warning...\n+      return set_numeric_flag(flag, value, origin);\n@@ -1010,2 +964,1 @@\n-  if (sscanf(arg, \"%\" XSTR(BUFLEN) NAME_RANGE \":%c\", name, &punct) == 2 && punct == '=') {\n-    const char* value = strchr(arg, '=') + 1;\n+  if (arg[0] == ':' && arg[1] == '=') {\n@@ -1013,8 +966,1 @@\n-    if (value[0] == '\\0') {\n-      value = NULL;\n-    }\n-    real_name = handle_aliases_and_deprecation(name, warn_if_deprecated);\n-    if (real_name == NULL) {\n-      return false;\n-    }\n-    JVMFlag* flag = JVMFlag::find_flag(real_name);\n+    const char* value = arg + 2;\n@@ -1024,27 +970,0 @@\n-#define SIGNED_FP_NUMBER_RANGE \"[-0123456789.eE+]\"\n-#define SIGNED_NUMBER_RANGE    \"[-0123456789]\"\n-#define        NUMBER_RANGE    \"[0123456789eE+-]\"\n-  char value[BUFLEN + 1];\n-  char value2[BUFLEN + 1];\n-  if (sscanf(arg, \"%\" XSTR(BUFLEN) NAME_RANGE \"=\" \"%\" XSTR(BUFLEN) SIGNED_NUMBER_RANGE \".\" \"%\" XSTR(BUFLEN) NUMBER_RANGE \"%c\", name, value, value2, &dummy) == 3) {\n-    \/\/ Looks like a floating-point number -- try again with more lenient format string\n-    if (sscanf(arg, \"%\" XSTR(BUFLEN) NAME_RANGE \"=\" \"%\" XSTR(BUFLEN) SIGNED_FP_NUMBER_RANGE \"%c\", name, value, &dummy) == 2) {\n-      real_name = handle_aliases_and_deprecation(name, warn_if_deprecated);\n-      if (real_name == NULL) {\n-        return false;\n-      }\n-      JVMFlag* flag = JVMFlag::find_flag(real_name);\n-      return set_fp_numeric_flag(flag, value, origin);\n-    }\n-  }\n-\n-#define VALUE_RANGE \"[-kmgtxKMGTX0123456789abcdefABCDEF]\"\n-  if (sscanf(arg, \"%\" XSTR(BUFLEN) NAME_RANGE \"=\" \"%\" XSTR(BUFLEN) VALUE_RANGE \"%c\", name, value, &dummy) == 2) {\n-    real_name = handle_aliases_and_deprecation(name, warn_if_deprecated);\n-    if (real_name == NULL) {\n-      return false;\n-    }\n-    JVMFlag* flag = JVMFlag::find_flag(real_name);\n-    return set_numeric_flag(flag, value, origin);\n-  }\n-\n@@ -1055,1 +974,1 @@\n-  assert(bldarray != NULL, \"illegal argument\");\n+  assert(bldarray != nullptr, \"illegal argument\");\n@@ -1057,1 +976,1 @@\n-  if (arg == NULL) {\n+  if (arg == nullptr) {\n@@ -1064,1 +983,1 @@\n-  if (*bldarray == NULL) {\n+  if (*bldarray == nullptr) {\n@@ -1084,2 +1003,2 @@\n-  if (args == NULL || count == 0) {\n-    return NULL;\n+  if (args == nullptr || count == 0) {\n+    return nullptr;\n@@ -1089,1 +1008,1 @@\n-    length += strlen(args[i]) + 1; \/\/ add 1 for a space or NULL terminating character\n+    length += strlen(args[i]) + 1; \/\/ add 1 for a space or null terminating character\n@@ -1094,2 +1013,2 @@\n-    size_t offset = strlen(args[j]) + 1; \/\/ add 1 for a space or NULL terminating character\n-    jio_snprintf(dst, length, \"%s \", args[j]); \/\/ jio_snprintf will replace the last space character with NULL character\n+    size_t offset = strlen(args[j]) + 1; \/\/ add 1 for a space or null terminating character\n+    jio_snprintf(dst, length, \"%s \", args[j]); \/\/ jio_snprintf will replace the last space character with null character\n@@ -1113,1 +1032,1 @@\n-  if (_java_class_path != NULL) {\n+  if (_java_class_path != nullptr) {\n@@ -1115,1 +1034,8 @@\n-    st->print_cr(\"java_class_path (initial): %s\", strlen(path) == 0 ? \"<not set>\" : path );\n+    size_t len = strlen(path);\n+    st->print(\"java_class_path (initial): \");\n+    \/\/ Avoid using st->print_cr() because path length maybe longer than O_BUFLEN.\n+    if (len == 0) {\n+      st->print_raw_cr(\"<not set>\");\n+    } else {\n+      st->print_raw_cr(path, len);\n+    }\n@@ -1135,1 +1061,1 @@\n-  if (java_command() != NULL) {\n+  if (java_command() != nullptr) {\n@@ -1172,1 +1098,1 @@\n-  if (equal_sign == NULL) {\n+  if (equal_sign == nullptr) {\n@@ -1194,1 +1120,1 @@\n-  if (found_flag != NULL) {\n+  if (found_flag != nullptr) {\n@@ -1225,1 +1151,1 @@\n-    if (fuzzy_matched != NULL) {\n+    if (fuzzy_matched != nullptr) {\n@@ -1239,2 +1165,2 @@\n-  FILE* stream = fopen(file_name, \"rb\");\n-  if (stream == NULL) {\n+  FILE* stream = os::fopen(file_name, \"rb\");\n+  if (stream == nullptr) {\n@@ -1314,1 +1240,1 @@\n-  if (eq == NULL) {\n+  if (eq == nullptr) {\n@@ -1344,2 +1270,8 @@\n-    process_java_compiler_argument(value);\n-    \/\/ Record value in Arguments, but let it get passed to Java.\n+    \/\/ we no longer support java.compiler system property, log a warning and let it get\n+    \/\/ passed to Java, like any other system property\n+    if (strlen(value) == 0 || strcasecmp(value, \"NONE\") == 0) {\n+        \/\/ for applications using NONE or empty value, log a more informative message\n+        warning(\"The java.compiler system property is obsolete and no longer supported, use -Xint\");\n+    } else {\n+        warning(\"The java.compiler system property is obsolete and no longer supported.\");\n+    }\n@@ -1358,1 +1290,1 @@\n-      if (old_java_command != NULL) {\n+      if (old_java_command != nullptr) {\n@@ -1371,1 +1303,1 @@\n-      if (old_java_vendor_url_bug != NULL) {\n+      if (old_java_vendor_url_bug != nullptr) {\n@@ -1403,1 +1335,1 @@\n-  while (sp != NULL) {\n+  while (sp != nullptr) {\n@@ -1422,1 +1354,1 @@\n-  if (ArchiveClassesAtExit != NULL) {\n+  if (ArchiveClassesAtExit != nullptr) {\n@@ -1430,1 +1362,1 @@\n-    if (get_property(unsupported_properties[i]) != NULL) {\n+    if (get_property(unsupported_properties[i]) != nullptr) {\n@@ -1433,0 +1365,2 @@\n+      } else {\n+        log_info(cds)(\"CDS is disabled when the %s option is specified.\", unsupported_options[i]);\n@@ -1448,1 +1382,0 @@\n-  set_java_compiler(false);\n@@ -1498,1 +1431,1 @@\n-    FLAG_SET_DEFAULT(UseSharedSpaces, false);\n+    UseSharedSpaces = false;\n@@ -1521,1 +1454,1 @@\n-  \/\/ We need to fit both the NULL page and the heap into the memory budget, while\n+  \/\/ We need to fit both the null page and the heap into the memory budget, while\n@@ -1523,1 +1456,1 @@\n-  \/\/ NULL page is located before the heap, we pad the NULL page to the conservative\n+  \/\/ null page is located before the heap, we pad the null page to the conservative\n@@ -1525,1 +1458,1 @@\n-  size_t displacement_due_to_null_page = align_up((size_t)os::vm_page_size(),\n+  size_t displacement_due_to_null_page = align_up(os::vm_page_size(),\n@@ -1547,3 +1480,0 @@\n-      if (COMPRESSED_CLASS_POINTERS_DEPENDS_ON_COMPRESSED_OOPS) {\n-        FLAG_SET_DEFAULT(UseCompressedClassPointers, false);\n-      }\n@@ -1555,3 +1485,0 @@\n-\n-\/\/ NOTE: set_use_compressed_klass_ptrs() must be called after calling\n-\/\/ set_use_compressed_oops().\n@@ -1560,25 +1487,2 @@\n-  \/\/ On some architectures, the use of UseCompressedClassPointers implies the use of\n-  \/\/ UseCompressedOops. The reason is that the rheap_base register of said platforms\n-  \/\/ is reused to perform some optimized spilling, in order to use rheap_base as a\n-  \/\/ temp register. But by treating it as any other temp register, spilling can typically\n-  \/\/ be completely avoided instead. So it is better not to perform this trick. And by\n-  \/\/ not having that reliance, large heaps, or heaps not supporting compressed oops,\n-  \/\/ can still use compressed class pointers.\n-  if (COMPRESSED_CLASS_POINTERS_DEPENDS_ON_COMPRESSED_OOPS && !UseCompressedOops) {\n-    if (UseCompressedClassPointers) {\n-      warning(\"UseCompressedClassPointers requires UseCompressedOops\");\n-    }\n-    FLAG_SET_DEFAULT(UseCompressedClassPointers, false);\n-  } else {\n-    \/\/ Turn on UseCompressedClassPointers too\n-    if (FLAG_IS_DEFAULT(UseCompressedClassPointers)) {\n-      FLAG_SET_ERGO(UseCompressedClassPointers, true);\n-    }\n-    \/\/ Check the CompressedClassSpaceSize to make sure we use compressed klass ptrs.\n-    if (UseCompressedClassPointers) {\n-      if (CompressedClassSpaceSize > KlassEncodingMetaspaceMax) {\n-        warning(\"CompressedClassSpaceSize is too large for UseCompressedClassPointers\");\n-        FLAG_SET_DEFAULT(UseCompressedClassPointers, false);\n-      }\n-    }\n-  }\n+  assert(!UseCompressedClassPointers || CompressedClassSpaceSize <= KlassEncodingMetaspaceMax,\n+         \"CompressedClassSpaceSize is too large for UseCompressedClassPointers\");\n@@ -1594,1 +1498,1 @@\n-                                          (size_t)os::vm_allocation_granularity(),\n+                                          os::vm_allocation_granularity(),\n@@ -1606,3 +1510,0 @@\n-\n-  \/\/ set_use_compressed_klass_ptrs() must be called after calling\n-  \/\/ set_use_compressed_oops().\n@@ -1699,0 +1600,12 @@\n+    reasonable_max = limit_heap_by_allocatable_memory(reasonable_max);\n+\n+    if (!FLAG_IS_DEFAULT(InitialHeapSize)) {\n+      \/\/ An initial heap size was specified on the command line,\n+      \/\/ so be sure that the maximum size is consistent.  Done\n+      \/\/ after call to limit_heap_by_allocatable_memory because that\n+      \/\/ method might reduce the allocation size.\n+      reasonable_max = MAX2(reasonable_max, (julong)InitialHeapSize);\n+    } else if (!FLAG_IS_DEFAULT(MinHeapSize)) {\n+      reasonable_max = MAX2(reasonable_max, (julong)MinHeapSize);\n+    }\n+\n@@ -1735,3 +1648,0 @@\n-          if (COMPRESSED_CLASS_POINTERS_DEPENDS_ON_COMPRESSED_OOPS) {\n-            FLAG_SET_ERGO(UseCompressedClassPointers, false);\n-          }\n@@ -1745,12 +1655,0 @@\n-    reasonable_max = limit_heap_by_allocatable_memory(reasonable_max);\n-\n-    if (!FLAG_IS_DEFAULT(InitialHeapSize)) {\n-      \/\/ An initial heap size was specified on the command line,\n-      \/\/ so be sure that the maximum size is consistent.  Done\n-      \/\/ after call to limit_heap_by_allocatable_memory because that\n-      \/\/ method might reduce the allocation size.\n-      reasonable_max = MAX2(reasonable_max, (julong)InitialHeapSize);\n-    } else if (!FLAG_IS_DEFAULT(MinHeapSize)) {\n-      reasonable_max = MAX2(reasonable_max, (julong)MinHeapSize);\n-    }\n-\n@@ -1938,10 +1836,0 @@\n-\/\/ Parsing of java.compiler property\n-\n-void Arguments::process_java_compiler_argument(const char* arg) {\n-  \/\/ For backwards compatibility, Djava.compiler=NONE or \"\"\n-  \/\/ causes us to switch to -Xint mode UNLESS -Xdebug\n-  \/\/ is also specified.\n-  if (strlen(arg) == 0 || strcasecmp(arg, \"NONE\") == 0) {\n-    set_java_compiler(true);    \/\/ \"-Djava.compiler[=...]\" most recently seen.\n-  }\n-}\n@@ -1950,0 +1838,3 @@\n+  if (_sun_java_launcher != _default_java_launcher) {\n+    os::free(const_cast<char*>(_sun_java_launcher));\n+  }\n@@ -1954,1 +1845,1 @@\n-  assert(_sun_java_launcher != NULL, \"property must have value\");\n+  assert(_sun_java_launcher != nullptr, \"property must have value\");\n@@ -1988,11 +1879,0 @@\n-  if (PrintNMTStatistics) {\n-#if INCLUDE_NMT\n-    if (MemTracker::tracking_level() == NMT_off) {\n-#endif \/\/ INCLUDE_NMT\n-      warning(\"PrintNMTStatistics is disabled, because native memory tracking is not enabled\");\n-      PrintNMTStatistics = false;\n-#if INCLUDE_NMT\n-    }\n-#endif\n-  }\n-\n@@ -2004,1 +1884,11 @@\n-    if (!create_numbered_module_property(\"jdk.module.addmods\", \"jdk.internal.vm.ci\", addmods_count++)) {\n+    if (ClassLoader::is_module_observable(\"jdk.internal.vm.ci\")) {\n+      if (!create_numbered_module_property(\"jdk.module.addmods\", \"jdk.internal.vm.ci\", addmods_count++)) {\n+        return false;\n+      }\n+    }\n+  }\n+#endif\n+\n+#if INCLUDE_JFR\n+  if (status && (FlightRecorderOptions || StartFlightRecording)) {\n+    if (!create_numbered_module_property(\"jdk.module.addmods\", \"jdk.jfr\", addmods_count++)) {\n@@ -2017,0 +1907,37 @@\n+\n+#if !defined(X86) && !defined(AARCH64) && !defined(RISCV64) && !defined(ARM) && !defined(PPC64)\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    FLAG_SET_CMDLINE(LockingMode, LM_LEGACY);\n+    warning(\"New lightweight locking not supported on this platform\");\n+  }\n+#endif\n+\n+  if (UseHeavyMonitors) {\n+    if (FLAG_IS_CMDLINE(LockingMode) && LockingMode != LM_MONITOR) {\n+      jio_fprintf(defaultStream::error_stream(),\n+                  \"Conflicting -XX:+UseHeavyMonitors and -XX:LockingMode=%d flags\", LockingMode);\n+      return false;\n+    }\n+    FLAG_SET_CMDLINE(LockingMode, LM_MONITOR);\n+  }\n+\n+#if !defined(X86) && !defined(AARCH64) && !defined(PPC64) && !defined(RISCV64) && !defined(S390)\n+  if (LockingMode == LM_MONITOR) {\n+    jio_fprintf(defaultStream::error_stream(),\n+                \"LockingMode == 0 (LM_MONITOR) is not fully implemented on this architecture\");\n+    return false;\n+  }\n+#endif\n+#if (defined(X86) || defined(PPC64)) && !defined(ZERO)\n+  if (LockingMode == LM_MONITOR && UseRTMForStackLocks) {\n+    jio_fprintf(defaultStream::error_stream(),\n+                \"LockingMode == 0 (LM_MONITOR) and -XX:+UseRTMForStackLocks are mutually exclusive\");\n+\n+    return false;\n+  }\n+#endif\n+  if (VerifyHeavyMonitors && LockingMode != LM_MONITOR) {\n+    jio_fprintf(defaultStream::error_stream(),\n+                \"-XX:+VerifyHeavyMonitors requires LockingMode == 0 (LM_MONITOR)\");\n+    return false;\n+  }\n@@ -2025,1 +1952,1 @@\n-  if (option_type == NULL) {\n+  if (option_type == nullptr) {\n@@ -2046,16 +1973,9 @@\n-\n-  \/\/ Check the sign first since atojulong() parses only unsigned values.\n-  bool value_is_positive = !(*value == '-');\n-\n-  if (value_is_positive) {\n-    julong n;\n-    bool good_return = atojulong(value, &n);\n-    if (good_return) {\n-      bool above_minimum = n >= min_size;\n-      bool value_is_too_large = n > max_uintx;\n-\n-      if (above_minimum && !value_is_too_large) {\n-        *uintx_arg = n;\n-        return true;\n-      }\n-    }\n+  uintx n;\n+  if (!parse_integer(value, &n)) {\n+    return false;\n+  }\n+  if (n >= min_size) {\n+    *uintx_arg = n;\n+    return true;\n+  } else {\n+    return false;\n@@ -2063,1 +1983,0 @@\n-  return false;\n@@ -2114,1 +2033,1 @@\n-  if (!atojulong(s, long_arg)) return arg_unreadable;\n+  if (!parse_integer(s, long_arg)) return arg_unreadable;\n@@ -2164,0 +2083,5 @@\n+  \/\/ Disable CDS for exploded image\n+  if (!has_jimage()) {\n+    no_shared_spaces(\"CDS disabled on exploded JDK\");\n+  }\n+\n@@ -2172,0 +2096,2 @@\n+  SystemMemoryBarrier::initialize();\n+\n@@ -2191,1 +2117,1 @@\n-    if ((_name = strrchr(name, (int) *os::file_separator())) == NULL) {\n+    if ((_name = strrchr(name, (int) *os::file_separator())) == nullptr) {\n@@ -2228,1 +2154,1 @@\n-  assert(patch_mod_tail != NULL, \"Unexpected NULL patch-module value\");\n+  assert(patch_mod_tail != nullptr, \"Unexpected null patch-module value\");\n@@ -2231,1 +2157,1 @@\n-  if (module_equal == NULL) {\n+  if (module_equal == nullptr) {\n@@ -2238,1 +2164,1 @@\n-    if (module_name != NULL) {\n+    if (module_name != nullptr) {\n@@ -2277,1 +2203,1 @@\n-    bool silent = (option == NULL); \/\/ Allow testing to silence error messages\n+    bool silent = (option == nullptr); \/\/ Allow testing to silence error messages\n@@ -2339,1 +2265,3 @@\n-        LogConfiguration::configure_stdout(LogLevel::Info, true, LOG_TAGS(gc));\n+        if (_legacyGCLogging.lastFlag == 0) {\n+          _legacyGCLogging.lastFlag = 1;\n+        }\n@@ -2377,1 +2305,1 @@\n-      if (tail != NULL) {\n+      if (tail != nullptr) {\n@@ -2379,1 +2307,1 @@\n-        size_t len = (pos == NULL) ? strlen(tail) : pos - tail;\n+        size_t len = (pos == nullptr) ? strlen(tail) : pos - tail;\n@@ -2383,2 +2311,2 @@\n-        char *options = NULL;\n-        if(pos != NULL) {\n+        char *options = nullptr;\n+        if(pos != nullptr) {\n@@ -2395,1 +2323,3 @@\n-        add_init_library(name, options);\n+        JvmtiAgentList::add_xrun(name, options, false);\n+        FREE_C_HEAP_ARRAY(char, name);\n+        FREE_C_HEAP_ARRAY(char, options);\n@@ -2442,1 +2372,1 @@\n-      if(tail != NULL) {\n+      if(tail != nullptr) {\n@@ -2445,1 +2375,1 @@\n-        if (pos == NULL) {\n+        if (pos == nullptr) {\n@@ -2454,2 +2384,2 @@\n-        char *options = NULL;\n-        if(pos != NULL) {\n+        char *options = nullptr;\n+        if(pos != nullptr) {\n@@ -2465,1 +2395,3 @@\n-        add_init_agent(name, options, is_absolute_path);\n+        JvmtiAgentList::add(name, options, is_absolute_path);\n+        os::free(name);\n+        os::free(options);\n@@ -2474,1 +2406,1 @@\n-      if (tail != NULL) {\n+      if (tail != nullptr) {\n@@ -2478,1 +2410,3 @@\n-        add_instrument_agent(\"instrument\", options, false);\n+        JvmtiAgentList::add(\"instrument\", options, false);\n+        FREE_C_HEAP_ARRAY(char, options);\n+\n@@ -2682,3 +2616,1 @@\n-      if (FLAG_SET_CMDLINE(DumpSharedSpaces, true) != JVMFlag::SUCCESS) {\n-        return JNI_EINVAL;\n-      }\n+      DumpSharedSpaces = true;\n@@ -2687,6 +2619,2 @@\n-      if (FLAG_SET_CMDLINE(UseSharedSpaces, true) != JVMFlag::SUCCESS) {\n-        return JNI_EINVAL;\n-      }\n-      if (FLAG_SET_CMDLINE(RequireSharedSpaces, true) != JVMFlag::SUCCESS) {\n-        return JNI_EINVAL;\n-      }\n+      UseSharedSpaces = true;\n+      RequireSharedSpaces = true;\n@@ -2695,6 +2623,3 @@\n-      if (FLAG_SET_CMDLINE(UseSharedSpaces, true) != JVMFlag::SUCCESS) {\n-        return JNI_EINVAL;\n-      }\n-      if (FLAG_SET_CMDLINE(RequireSharedSpaces, false) != JVMFlag::SUCCESS) {\n-        return JNI_EINVAL;\n-      }\n+      UseSharedSpaces = true;\n+      RequireSharedSpaces = false;\n+      xshare_auto_cmd_line = true;\n@@ -2703,6 +2628,2 @@\n-      if (FLAG_SET_CMDLINE(UseSharedSpaces, false) != JVMFlag::SUCCESS) {\n-        return JNI_EINVAL;\n-      }\n-      if (FLAG_SET_CMDLINE(RequireSharedSpaces, false) != JVMFlag::SUCCESS) {\n-        return JNI_EINVAL;\n-      }\n+      UseSharedSpaces = false;\n+      RequireSharedSpaces = false;\n@@ -2746,1 +2667,2 @@\n-      _gc_log_filename = os::strdup_check_oom(tail);\n+      _legacyGCLogging.lastFlag = 2;\n+      _legacyGCLogging.file = os::strdup_check_oom(tail);\n@@ -2866,12 +2788,9 @@\n-    } else if (match_option(option, \"-XX:+ExtendedDTraceProbes\")) {\n-#if defined(DTRACE_ENABLED)\n-      if (FLAG_SET_CMDLINE(ExtendedDTraceProbes, true) != JVMFlag::SUCCESS) {\n-        return JNI_EINVAL;\n-      }\n-      if (FLAG_SET_CMDLINE(DTraceMethodProbes, true) != JVMFlag::SUCCESS) {\n-        return JNI_EINVAL;\n-      }\n-      if (FLAG_SET_CMDLINE(DTraceAllocProbes, true) != JVMFlag::SUCCESS) {\n-        return JNI_EINVAL;\n-      }\n-      if (FLAG_SET_CMDLINE(DTraceMonitorProbes, true) != JVMFlag::SUCCESS) {\n+    } else if (match_option(option, \"--finalization=\", &tail)) {\n+      if (strcmp(tail, \"enabled\") == 0) {\n+        InstanceKlass::set_finalization_enabled(true);\n+      } else if (strcmp(tail, \"disabled\") == 0) {\n+        InstanceKlass::set_finalization_enabled(false);\n+      } else {\n+        jio_fprintf(defaultStream::error_stream(),\n+                    \"Invalid finalization value '%s', must be 'disabled' or 'enabled'.\\n\",\n+                    tail);\n@@ -2880,1 +2799,6 @@\n-#else \/\/ defined(DTRACE_ENABLED)\n+#if !defined(DTRACE_ENABLED)\n+    } else if (match_option(option, \"-XX:+DTraceMethodProbes\")) {\n+      jio_fprintf(defaultStream::error_stream(),\n+                  \"DTraceMethodProbes flag is not applicable for this configuration\\n\");\n+      return JNI_EINVAL;\n+    } else if (match_option(option, \"-XX:+DTraceAllocProbes\")) {\n@@ -2882,1 +2806,1 @@\n-                  \"ExtendedDTraceProbes flag is not applicable for this configuration\\n\");\n+                  \"DTraceAllocProbes flag is not applicable for this configuration\\n\");\n@@ -2884,1 +2808,5 @@\n-#endif \/\/ defined(DTRACE_ENABLED)\n+    } else if (match_option(option, \"-XX:+DTraceMonitorProbes\")) {\n+      jio_fprintf(defaultStream::error_stream(),\n+                  \"DTraceMonitorProbes flag is not applicable for this configuration\\n\");\n+      return JNI_EINVAL;\n+#endif \/\/ !defined(DTRACE_ENABLED)\n@@ -2902,1 +2830,1 @@\n-    } else if (match_option(option, \"-XX:-EnableJVMCIProduct\")) {\n+    } else if (match_option(option, \"-XX:-EnableJVMCIProduct\") || match_option(option, \"-XX:-UseGraalJIT\")) {\n@@ -2905,1 +2833,1 @@\n-                  \"-XX:-EnableJVMCIProduct cannot come after -XX:+EnableJVMCIProduct\\n\");\n+                  \"-XX:-EnableJVMCIProduct or -XX:-UseGraalJIT cannot come after -XX:+EnableJVMCIProduct or -XX:+UseGraalJIT\\n\");\n@@ -2908,2 +2836,16 @@\n-    } else if (match_option(option, \"-XX:+EnableJVMCIProduct\")) {\n-      \/\/ Just continue, since \"-XX:+EnableJVMCIProduct\" has been specified before\n+    } else if (match_option(option, \"-XX:+EnableJVMCIProduct\") || match_option(option, \"-XX:+UseGraalJIT\")) {\n+      bool use_graal_jit = match_option(option, \"-XX:+UseGraalJIT\");\n+      if (use_graal_jit) {\n+        const char* jvmci_compiler = get_property(\"jvmci.Compiler\");\n+        if (jvmci_compiler != nullptr) {\n+          if (strncmp(jvmci_compiler, \"graal\", strlen(\"graal\")) != 0) {\n+            jio_fprintf(defaultStream::error_stream(),\n+              \"Value of jvmci.Compiler incompatible with +UseGraalJIT: %s\", jvmci_compiler);\n+            return JNI_ERR;\n+          }\n+        } else if (!add_property(\"jvmci.Compiler=graal\")) {\n+            return JNI_ENOMEM;\n+        }\n+      }\n+\n+      \/\/ Just continue, since \"-XX:+EnableJVMCIProduct\" or \"-XX:+UseGraalJIT\" has been specified before\n@@ -2915,2 +2857,2 @@\n-      if (jvmciFlag != NULL && jvmciFlag->is_unlocked()) {\n-        if (!JVMCIGlobals::enable_jvmci_product_mode(origin)) {\n+      if (jvmciFlag != nullptr && jvmciFlag->is_unlocked()) {\n+        if (!JVMCIGlobals::enable_jvmci_product_mode(origin, use_graal_jit)) {\n@@ -2923,1 +2865,1 @@\n-      else if (!process_argument(\"EnableJVMCIProduct\", args->ignoreUnrecognized, origin)) {\n+      else if (!process_argument(use_graal_jit ? \"UseGraalJIT\" : \"EnableJVMCIProduct\", args->ignoreUnrecognized, origin)) {\n@@ -2950,6 +2892,2 @@\n-    if (FLAG_SET_CMDLINE(UseSharedSpaces, true) != JVMFlag::SUCCESS) {\n-      return JNI_EINVAL;\n-    }\n-    if (FLAG_SET_CMDLINE(RequireSharedSpaces, true) != JVMFlag::SUCCESS) {\n-      return JNI_EINVAL;\n-    }\n+    UseSharedSpaces = true;\n+    RequireSharedSpaces = true;\n@@ -2978,2 +2916,2 @@\n-  if (_patch_mod_prefix == NULL) {\n-    _patch_mod_prefix = new (ResourceObj::C_HEAP, mtArguments) GrowableArray<ModulePatchPath*>(10, mtArguments);\n+  if (_patch_mod_prefix == nullptr) {\n+    _patch_mod_prefix = new (mtArguments) GrowableArray<ModulePatchPath*>(10, mtArguments);\n@@ -3032,1 +2970,1 @@\n-  if (dir != NULL) {\n+  if (dir != nullptr) {\n@@ -3042,1 +2980,1 @@\n-  if (dir != NULL) {\n+  if (dir != nullptr) {\n@@ -3060,9 +2998,0 @@\n-  \/\/ This must be done after all arguments have been processed.\n-  \/\/ java_compiler() true means set to \"NONE\" or empty.\n-  if (java_compiler() && !xdebug_mode()) {\n-    \/\/ For backwards compatibility, we switch to interpreted mode if\n-    \/\/ -Djava.compiler=\"NONE\" or \"\" is specified AND \"-Xdebug\" was\n-    \/\/ not specified.\n-    set_mode_flags(_int);\n-  }\n-\n@@ -3110,5 +3039,1 @@\n-    \/\/ Disable biased locking now as it interferes with the clean up of\n-    \/\/ the archived Klasses and Java string objects (at dump time only).\n-    UseBiasedLocking = false;\n-\n-    \/\/ unsafe with DumpSharedSpaces (which modifies the class metadata in place). Let's disable\n+    \/\/ unsafe with -Xshare:dump (which modifies the class metadata in place). Let's disable\n@@ -3118,2 +3043,2 @@\n-    \/\/ Note: this is not a concern for DynamicDumpSharedSpaces, which makes a copy of the class metadata\n-    \/\/ instead of modifying them in place. The copy is inaccessible to the compiler.\n+    \/\/ Note: this is not a concern for dynamically dumping shared spaces, which makes a copy of the\n+    \/\/ class metadata instead of modifying them in place. The copy is inaccessible to the compiler.\n@@ -3122,7 +3047,5 @@\n-  }\n-  if (DumpSharedSpaces || ArchiveClassesAtExit != NULL) {\n-    \/\/ Always verify non-system classes during CDS dump\n-    if (!BytecodeVerificationRemote) {\n-      BytecodeVerificationRemote = true;\n-      log_info(cds)(\"All non-system classes will be verified (-Xverify:remote) during CDS dump time.\");\n-    }\n+\n+    \/\/ String deduplication may cause CDS to iterate the strings in different order from one\n+    \/\/ run to another which resulting in non-determinstic CDS archives.\n+    \/\/ Disable UseStringDeduplication while dumping CDS archive.\n+    UseStringDeduplication = false;\n@@ -3132,2 +3055,3 @@\n-  if (ArchiveClassesAtExit != NULL && RecordDynamicDumpInfo) {\n-    log_info(cds)(\"RecordDynamicDumpInfo is for jcmd only, could not set with -XX:ArchiveClassesAtExit.\");\n+  if (ArchiveClassesAtExit != nullptr && RecordDynamicDumpInfo) {\n+    jio_fprintf(defaultStream::output_stream(),\n+                \"-XX:+RecordDynamicDumpInfo cannot be used with -XX:ArchiveClassesAtExit.\\n\");\n@@ -3137,2 +3061,2 @@\n-  if (ArchiveClassesAtExit == NULL && !RecordDynamicDumpInfo) {\n-    FLAG_SET_DEFAULT(DynamicDumpSharedSpaces, false);\n+  if (ArchiveClassesAtExit == nullptr && !RecordDynamicDumpInfo) {\n+    DynamicDumpSharedSpaces = false;\n@@ -3140,1 +3064,12 @@\n-    FLAG_SET_DEFAULT(DynamicDumpSharedSpaces, true);\n+    DynamicDumpSharedSpaces = true;\n+  }\n+\n+  if (AutoCreateSharedArchive) {\n+    if (SharedArchiveFile == nullptr) {\n+      log_warning(cds)(\"-XX:+AutoCreateSharedArchive requires -XX:SharedArchiveFile\");\n+      return JNI_ERR;\n+    }\n+    if (ArchiveClassesAtExit != nullptr) {\n+      log_warning(cds)(\"-XX:+AutoCreateSharedArchive does not work with ArchiveClassesAtExit\");\n+      return JNI_ERR;\n+    }\n@@ -3147,1 +3082,9 @@\n-    FLAG_SET_DEFAULT(UseSharedSpaces, false);\n+    UseSharedSpaces = false;\n+  }\n+\n+  if (DumpSharedSpaces || DynamicDumpSharedSpaces) {\n+    \/\/ Always verify non-system classes during CDS dump\n+    if (!BytecodeVerificationRemote) {\n+      BytecodeVerificationRemote = true;\n+      log_info(cds)(\"All non-system classes will be verified (-Xverify:remote) during CDS dump time.\");\n+    }\n@@ -3172,1 +3115,1 @@\n-    _args.options = NULL;\n+    _args.options = nullptr;\n@@ -3176,1 +3119,1 @@\n-    _vm_options_file_arg = NULL;\n+    _vm_options_file_arg = nullptr;\n@@ -3188,1 +3131,1 @@\n-    if (options_arr == NULL) {\n+    if (options_arr == nullptr) {\n@@ -3196,1 +3139,1 @@\n-      if (options_arr[i].optionString == NULL) {\n+      if (options_arr[i].optionString == nullptr) {\n@@ -3211,1 +3154,1 @@\n-  bool  found_vm_options_file_arg() { return _vm_options_file_arg != NULL; }\n+  bool  found_vm_options_file_arg() { return _vm_options_file_arg != nullptr; }\n@@ -3215,1 +3158,1 @@\n-    if (_vm_options_file_arg != NULL) {\n+    if (_vm_options_file_arg != nullptr) {\n@@ -3222,1 +3165,1 @@\n-    if (_vm_options_file_arg != NULL) {\n+    if (_vm_options_file_arg != nullptr) {\n@@ -3225,1 +3168,1 @@\n-    if (_args.options == NULL) return;\n+    if (_args.options == nullptr) return;\n@@ -3237,1 +3180,1 @@\n-    assert(_args.options == NULL, \"shouldn't be set yet\");\n+    assert(_args.options == nullptr, \"shouldn't be set yet\");\n@@ -3274,1 +3217,1 @@\n-  if (buffer == NULL || os::have_special_privileges()) {\n+  if (buffer == nullptr || os::have_special_privileges()) {\n@@ -3278,1 +3221,1 @@\n-  if ((buffer = os::strdup(buffer)) == NULL) {\n+  if ((buffer = os::strdup(buffer)) == nullptr) {\n@@ -3307,1 +3250,1 @@\n-    os::close(fd);\n+    ::close(fd);\n@@ -3313,1 +3256,1 @@\n-    os::close(fd);\n+    ::close(fd);\n@@ -3317,1 +3260,1 @@\n-  \/\/ '+ 1' for NULL termination even with max bytes\n+  \/\/ '+ 1' for null termination even with max bytes\n@@ -3321,1 +3264,1 @@\n-  if (NULL == buf) {\n+  if (nullptr == buf) {\n@@ -3324,1 +3267,1 @@\n-    os::close(fd);\n+    ::close(fd);\n@@ -3331,2 +3274,2 @@\n-  ssize_t bytes_read = os::read(fd, (void *)buf, (unsigned)bytes_alloc);\n-  os::close(fd);\n+  ssize_t bytes_read = ::read(fd, (void *)buf, (unsigned)bytes_alloc);\n+  ::close(fd);\n@@ -3401,1 +3344,1 @@\n-    \/\/ steal a white space character and set it to NULL\n+    \/\/ steal a white space character and set it to null\n@@ -3407,1 +3350,1 @@\n-    option.extraInfo = NULL;\n+    option.extraInfo = nullptr;\n@@ -3418,1 +3361,1 @@\n-jint Arguments::set_shared_spaces_flags_and_archive_paths() {\n+void Arguments::set_shared_spaces_flags_and_archive_paths() {\n@@ -3428,2 +3371,4 @@\n-  if (!init_shared_archive_paths()) {\n-    return JNI_ENOMEM;\n+  \/\/\n+  \/\/ UseSharedSpaces may be disabled if -XX:SharedArchiveFile is invalid.\n+  if (DumpSharedSpaces || UseSharedSpaces) {\n+    init_shared_archive_paths();\n@@ -3432,1 +3377,0 @@\n-  return JNI_OK;\n@@ -3439,13 +3383,14 @@\n-  char *default_archive_path;\n-  char jvm_path[JVM_MAXPATHLEN];\n-  os::jvm_path(jvm_path, sizeof(jvm_path));\n-  char *end = strrchr(jvm_path, *os::file_separator());\n-  if (end != NULL) *end = '\\0';\n-  size_t jvm_path_len = strlen(jvm_path);\n-  size_t file_sep_len = strlen(os::file_separator());\n-  const size_t len = jvm_path_len + file_sep_len + 20;\n-  default_archive_path = NEW_C_HEAP_ARRAY(char, len, mtArguments);\n-  jio_snprintf(default_archive_path, len,\n-               LP64_ONLY(!UseCompressedOops ? \"%s%sclasses_nocoops.jsa\":) \"%s%sclasses.jsa\",\n-               jvm_path, os::file_separator());\n-  return default_archive_path;\n+  if (_default_shared_archive_path == nullptr) {\n+    char jvm_path[JVM_MAXPATHLEN];\n+    os::jvm_path(jvm_path, sizeof(jvm_path));\n+    char *end = strrchr(jvm_path, *os::file_separator());\n+    if (end != nullptr) *end = '\\0';\n+    size_t jvm_path_len = strlen(jvm_path);\n+    size_t file_sep_len = strlen(os::file_separator());\n+    const size_t len = jvm_path_len + file_sep_len + 20;\n+    _default_shared_archive_path = NEW_C_HEAP_ARRAY(char, len, mtArguments);\n+    jio_snprintf(_default_shared_archive_path, len,\n+                LP64_ONLY(!UseCompressedOops ? \"%s%sclasses_nocoops.jsa\":) \"%s%sclasses.jsa\",\n+                jvm_path, os::file_separator());\n+  }\n+  return _default_shared_archive_path;\n@@ -3455,1 +3400,1 @@\n-  if (archive_path == NULL) {\n+  if (archive_path == nullptr) {\n@@ -3474,1 +3419,1 @@\n-  if (end_ptr == NULL || end_ptr == begin_ptr) {\n+  if (end_ptr == nullptr || end_ptr == begin_ptr) {\n@@ -3481,1 +3426,0 @@\n-  FileMapInfo::check_archive((const char*)cur_path, true \/*is_static*\/);\n@@ -3489,1 +3433,1 @@\n-  assert(end_ptr != NULL, \"sanity\");\n+  assert(end_ptr != nullptr, \"sanity\");\n@@ -3493,2 +3437,0 @@\n-  \/\/cur_path[len] = '\\0';\n-  FileMapInfo::check_archive((const char*)cur_path, false \/*is_static*\/);\n@@ -3498,2 +3440,3 @@\n-bool Arguments::init_shared_archive_paths() {\n-  if (ArchiveClassesAtExit != NULL) {\n+void Arguments::init_shared_archive_paths() {\n+  if (ArchiveClassesAtExit != nullptr) {\n+    assert(!RecordDynamicDumpInfo, \"already checked\");\n@@ -3503,8 +3446,4 @@\n-    if (FLAG_SET_CMDLINE(DynamicDumpSharedSpaces, true) != JVMFlag::SUCCESS) {\n-      return false;\n-    }\n-    SharedDynamicArchivePath = os::strdup_check_oom(ArchiveClassesAtExit, mtArguments);\n-  } else {\n-    if (SharedDynamicArchivePath != nullptr) {\n-      os::free(SharedDynamicArchivePath);\n-      SharedDynamicArchivePath = nullptr;\n+\n+    if (os::same_files(get_default_shared_archive_path(), ArchiveClassesAtExit)) {\n+      vm_exit_during_initialization(\n+        \"Cannot specify the default CDS archive for -XX:ArchiveClassesAtExit\", get_default_shared_archive_path());\n@@ -3514,1 +3453,2 @@\n-  if (SharedArchiveFile == NULL) {\n+\n+  if (SharedArchiveFile == nullptr) {\n@@ -3518,12 +3458,5 @@\n-    if (is_dumping_archive()) {\n-      if (archives > 1) {\n-        vm_exit_during_initialization(\n-          \"Cannot have more than 1 archive file specified in -XX:SharedArchiveFile during CDS dumping\");\n-      }\n-      if (DynamicDumpSharedSpaces) {\n-        if (os::same_files(SharedArchiveFile, ArchiveClassesAtExit)) {\n-          vm_exit_during_initialization(\n-            \"Cannot have the same archive file specified for -XX:SharedArchiveFile and -XX:ArchiveClassesAtExit\",\n-            SharedArchiveFile);\n-        }\n-      }\n+    assert(archives > 0, \"must be\");\n+\n+    if (is_dumping_archive() && archives > 1) {\n+      vm_exit_during_initialization(\n+        \"Cannot have more than 1 archive file specified in -XX:SharedArchiveFile during CDS dumping\");\n@@ -3531,1 +3464,16 @@\n-    if (!is_dumping_archive()){\n+\n+    if (DumpSharedSpaces) {\n+      assert(archives == 1, \"must be\");\n+      \/\/ Static dump is simple: only one archive is allowed in SharedArchiveFile. This file\n+      \/\/ will be overwritten no matter regardless of its contents\n+      SharedArchivePath = os::strdup_check_oom(SharedArchiveFile, mtArguments);\n+    } else {\n+      \/\/ SharedArchiveFile may specify one or two files. In case (c), the path for base.jsa\n+      \/\/ is read from top.jsa\n+      \/\/    (a) 1 file:  -XX:SharedArchiveFile=base.jsa\n+      \/\/    (b) 2 files: -XX:SharedArchiveFile=base.jsa:top.jsa\n+      \/\/    (c) 2 files: -XX:SharedArchiveFile=top.jsa\n+      \/\/\n+      \/\/ However, if either RecordDynamicDumpInfo or ArchiveClassesAtExit is used, we do not\n+      \/\/ allow cases (b) and (c). Case (b) is already checked above.\n+\n@@ -3537,2 +3485,1 @@\n-        char* temp_archive_path = os::strdup_check_oom(SharedArchiveFile, mtArguments);\n-        int name_size;\n+        char* base_archive_path = nullptr;\n@@ -3540,1 +3487,1 @@\n-          FileMapInfo::get_base_archive_name_from_header(temp_archive_path, &name_size, &SharedArchivePath);\n+          FileMapInfo::get_base_archive_name_from_header(SharedArchiveFile, &base_archive_path);\n@@ -3542,1 +3489,17 @@\n-          SharedArchivePath = temp_archive_path;\n+          \/\/ If +AutoCreateSharedArchive and the specified shared archive does not exist,\n+          \/\/ regenerate the dynamic archive base on default archive.\n+          if (AutoCreateSharedArchive && !os::file_exists(SharedArchiveFile)) {\n+            DynamicDumpSharedSpaces = true;\n+            ArchiveClassesAtExit = const_cast<char *>(SharedArchiveFile);\n+            SharedArchivePath = get_default_shared_archive_path();\n+            SharedArchiveFile = nullptr;\n+          } else {\n+            if (AutoCreateSharedArchive) {\n+              warning(\"-XX:+AutoCreateSharedArchive is unsupported when base CDS archive is not loaded. Run with -Xlog:cds for more info.\");\n+              AutoCreateSharedArchive = false;\n+            }\n+            no_shared_spaces(\"invalid archive\");\n+          }\n+        } else if (base_archive_path == nullptr) {\n+          \/\/ User has specified a single archive, which is a static archive.\n+          SharedArchivePath = const_cast<char *>(SharedArchiveFile);\n@@ -3544,1 +3507,3 @@\n-          SharedDynamicArchivePath = temp_archive_path;\n+          \/\/ User has specified a single archive, which is a dynamic archive.\n+          SharedDynamicArchivePath = const_cast<char *>(SharedArchiveFile);\n+          SharedArchivePath = base_archive_path; \/\/ has been c-heap allocated.\n@@ -3549,0 +3514,22 @@\n+        if (SharedArchivePath == nullptr) {\n+          assert(SharedDynamicArchivePath == nullptr, \"must be\");\n+          no_shared_spaces(\"invalid archive\");\n+        }\n+      }\n+\n+      if (SharedDynamicArchivePath != nullptr) {\n+        \/\/ Check for case (c)\n+        if (RecordDynamicDumpInfo) {\n+          vm_exit_during_initialization(\"-XX:+RecordDynamicDumpInfo is unsupported when a dynamic CDS archive is specified in -XX:SharedArchiveFile\",\n+                                        SharedArchiveFile);\n+        }\n+        if (ArchiveClassesAtExit != nullptr) {\n+          vm_exit_during_initialization(\"-XX:ArchiveClassesAtExit is unsupported when a dynamic CDS archive is specified in -XX:SharedArchiveFile\",\n+                                        SharedArchiveFile);\n+        }\n+      }\n+\n+      if (ArchiveClassesAtExit != nullptr && os::same_files(SharedArchiveFile, ArchiveClassesAtExit)) {\n+          vm_exit_during_initialization(\n+            \"Cannot have the same archive file specified for -XX:SharedArchiveFile and -XX:ArchiveClassesAtExit\",\n+            SharedArchiveFile);\n@@ -3550,2 +3537,0 @@\n-    } else { \/\/ CDS dumping\n-      SharedArchivePath = os::strdup_check_oom(SharedArchiveFile, mtArguments);\n@@ -3554,1 +3539,0 @@\n-  return (SharedArchivePath != NULL);\n@@ -3564,1 +3548,1 @@\n-      PrintAssembly || TraceDeoptimization || TraceDependencies ||\n+      PrintAssembly || TraceDeoptimization ||\n@@ -3709,23 +3693,0 @@\n-    if (match_option(option, \"-XX:NativeMemoryTracking\", &tail)) {\n-#if INCLUDE_NMT\n-      \/\/ The launcher did not setup nmt environment variable properly.\n-      if (!MemTracker::check_launcher_nmt_support(tail)) {\n-        warning(\"Native Memory Tracking did not setup properly, using wrong launcher?\");\n-      }\n-\n-      \/\/ Verify if nmt option is valid.\n-      if (MemTracker::verify_nmt_option()) {\n-        \/\/ Late initialization, still in single-threaded mode.\n-        if (MemTracker::tracking_level() >= NMT_summary) {\n-          MemTracker::init();\n-        }\n-      } else {\n-        vm_exit_during_initialization(\"Syntax error, expecting -XX:NativeMemoryTracking=[off|summary|detail]\", NULL);\n-      }\n-      continue;\n-#else\n-      jio_fprintf(defaultStream::error_stream(),\n-        \"Native Memory Tracking is not supported in this VM\\n\");\n-      return JNI_ERR;\n-#endif\n-    }\n@@ -3761,1 +3722,1 @@\n-  if (_gc_log_filename != NULL) {\n+  if (_legacyGCLogging.lastFlag == 2) {\n@@ -3767,2 +3728,2 @@\n-    return LogConfiguration::parse_log_arguments(_gc_log_filename, gc_conf, NULL, NULL, &errstream);\n-  } else if (PrintGC || PrintGCDetails) {\n+    return LogConfiguration::parse_log_arguments(_legacyGCLogging.file, gc_conf, nullptr, nullptr, &errstream);\n+  } else if (PrintGC || PrintGCDetails || (_legacyGCLogging.lastFlag == 1)) {\n@@ -3775,0 +3736,2 @@\n+#ifndef PRODUCT\n+  \/\/ UseDebuggerErgo is notproduct\n@@ -3778,0 +3741,1 @@\n+#endif\n@@ -3779,0 +3743,1 @@\n+#ifndef PRODUCT\n@@ -3784,0 +3749,1 @@\n+#endif\n@@ -3834,1 +3800,1 @@\n-  if (vmoptions != NULL) {\n+  if (vmoptions != nullptr) {\n@@ -3871,1 +3837,1 @@\n-  settings_file_specified = (flags_file != NULL);\n+  settings_file_specified = (flags_file != nullptr);\n@@ -3969,1 +3935,1 @@\n-  if (DumpLoadedClassList != NULL) {\n+  if (DumpLoadedClassList != nullptr) {\n@@ -3974,1 +3940,1 @@\n-  if ((UseSharedSpaces && FLAG_IS_CMDLINE(UseSharedSpaces)) ||\n+  if ((UseSharedSpaces && xshare_auto_cmd_line) ||\n@@ -3977,1 +3943,1 @@\n-    FLAG_SET_DEFAULT(UseSharedSpaces, false);\n+    UseSharedSpaces = false;\n@@ -3983,4 +3949,15 @@\n-  if (TraceDependencies && VerifyDependencies) {\n-    if (!FLAG_IS_DEFAULT(TraceDependencies)) {\n-      warning(\"TraceDependencies results may be inflated by VerifyDependencies\");\n-    }\n+  \/\/ Verify NMT arguments\n+  const NMT_TrackingLevel lvl = NMTUtil::parse_tracking_level(NativeMemoryTracking);\n+  if (lvl == NMT_unknown) {\n+    jio_fprintf(defaultStream::error_stream(),\n+                \"Syntax error, expecting -XX:NativeMemoryTracking=[off|summary|detail]\", nullptr);\n+    return JNI_ERR;\n+  }\n+  if (PrintNMTStatistics && lvl == NMT_off) {\n+    warning(\"PrintNMTStatistics is disabled, because native memory tracking is not enabled\");\n+    FLAG_SET_DEFAULT(PrintNMTStatistics, false);\n+  }\n+\n+  bool trace_dependencies = log_is_enabled(Debug, dependencies);\n+  if (trace_dependencies && VerifyDependencies) {\n+    warning(\"dependency logging results may be inflated by VerifyDependencies\");\n@@ -4002,0 +3979,4 @@\n+  if (log_is_enabled(Info, arguments)) {\n+    LogStream st(Log(arguments)::info());\n+    Arguments::print_on(&st);\n+  }\n@@ -4016,2 +3997,1 @@\n-  result = set_shared_spaces_flags_and_archive_paths();\n-  if (result != JNI_OK) return result;\n+  set_shared_spaces_flags_and_archive_paths();\n@@ -4039,20 +4019,0 @@\n-  \/\/ Turn off biased locking for locking debug mode flags,\n-  \/\/ which are subtly different from each other but neither works with\n-  \/\/ biased locking\n-  if (UseHeavyMonitors\n-#ifdef COMPILER1\n-      || !UseFastLocking\n-#endif \/\/ COMPILER1\n-#if INCLUDE_JVMCI\n-      || !JVMCIUseFastLocking\n-#endif\n-    ) {\n-    if (!FLAG_IS_DEFAULT(UseBiasedLocking) && UseBiasedLocking) {\n-      \/\/ flag set to true on command line; warn the user that they\n-      \/\/ can't enable biased locking here\n-      warning(\"Biased Locking is not supported with locking debug flags\"\n-              \"; ignoring UseBiasedLocking flag.\" );\n-    }\n-    UseBiasedLocking = false;\n-  }\n-\n@@ -4062,1 +4022,0 @@\n-  FLAG_SET_DEFAULT(UseBiasedLocking, false);\n@@ -4093,11 +4052,0 @@\n-  \/\/ Apply CPU specific policy for the BiasedLocking\n-  if (UseBiasedLocking) {\n-    if (!VM_Version::use_biased_locking() &&\n-        !(FLAG_IS_CMDLINE(UseBiasedLocking))) {\n-      UseBiasedLocking = false;\n-    }\n-  }\n-  if (!UseBiasedLocking) {\n-    UseOptoBiasInlining = false;\n-  }\n-\n@@ -4148,1 +4096,1 @@\n-  while(pl != NULL) {\n+  while(pl != nullptr) {\n@@ -4158,2 +4106,2 @@\n-  while(pl != NULL) {\n-    if (pl->is_readable()) {\n+  while(pl != nullptr) {\n+    if (pl->readable()) {\n@@ -4168,1 +4116,1 @@\n-  assert(key != NULL, \"just checking\");\n+  assert(key != nullptr, \"just checking\");\n@@ -4170,1 +4118,1 @@\n-  for (prop = pl; prop != NULL; prop = prop->next()) {\n+  for (prop = pl; prop != nullptr; prop = prop->next()) {\n@@ -4173,1 +4121,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -4178,1 +4126,1 @@\n-  assert(key != NULL, \"just checking\");\n+  assert(key != nullptr, \"just checking\");\n@@ -4182,1 +4130,1 @@\n-  for (prop = pl; prop != NULL; prop = prop->next()) {\n+  for (prop = pl; prop != nullptr; prop = prop->next()) {\n@@ -4189,2 +4137,2 @@\n-        \/\/ Property is internal and not jdk.boot.class.path.append so return NULL.\n-        return NULL;\n+        \/\/ Property is internal and not jdk.boot.class.path.append so return null.\n+        return nullptr;\n@@ -4194,33 +4142,1 @@\n-  return NULL;\n-}\n-\n-const char* Arguments::PropertyList_get_key_at(SystemProperty *pl, int index) {\n-  int count = 0;\n-  const char* ret_val = NULL;\n-\n-  while(pl != NULL) {\n-    if(count >= index) {\n-      ret_val = pl->key();\n-      break;\n-    }\n-    count++;\n-    pl = pl->next();\n-  }\n-\n-  return ret_val;\n-}\n-\n-char* Arguments::PropertyList_get_value_at(SystemProperty* pl, int index) {\n-  int count = 0;\n-  char* ret_val = NULL;\n-\n-  while(pl != NULL) {\n-    if(count >= index) {\n-      ret_val = pl->value();\n-      break;\n-    }\n-    count++;\n-    pl = pl->next();\n-  }\n-\n-  return ret_val;\n+  return nullptr;\n@@ -4231,1 +4147,1 @@\n-  if (p == NULL) {\n+  if (p == nullptr) {\n@@ -4234,1 +4150,1 @@\n-    while (p->next() != NULL) {\n+    while (p->next() != nullptr) {\n@@ -4243,1 +4159,1 @@\n-  if (plist == NULL)\n+  if (plist == nullptr)\n@@ -4258,1 +4174,1 @@\n-  if (plist == NULL)\n+  if (plist == nullptr)\n@@ -4264,1 +4180,1 @@\n-  for (prop = *plist; prop != NULL; prop = prop->next()) {\n+  for (prop = *plist; prop != nullptr; prop = prop->next()) {\n@@ -4283,1 +4199,1 @@\n-\/\/ NULL terminator character is not long enough for holding the expanded\n+\/\/ null terminator character is not long enough for holding the expanded\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":633,"deletions":717,"binary":false,"changes":1350,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -70,2 +70,2 @@\n-\/\/ EXPERIMENTAL flags are in support of features that are not\n-\/\/    part of the officially supported product, but are available\n+\/\/ EXPERIMENTAL flags are in support of features that may not be\n+\/\/    an officially supported part of a product, but may be available\n@@ -78,0 +78,2 @@\n+\/\/    Refer to the documentation of any products using this code for details\n+\/\/    on support and fitness for production.\n@@ -83,2 +85,1 @@\n-\/\/    and they are not supported on production loads, except under explicit\n-\/\/    direction from support engineers.\n+\/\/    Refer to the documentation of any products using this code for details.\n@@ -89,1 +90,1 @@\n-\/\/    These flags are external exported interface (see CCC).  The list of\n+\/\/    These flags are external exported interface (see CSR).  The list of\n@@ -94,1 +95,1 @@\n-\/\/    - the flag is defined in a CCC as an external exported interface.\n+\/\/    - the flag is defined in a CSR request as an external exported interface.\n@@ -128,1 +129,1 @@\n-  product(bool, UseCompressedClassPointers, false,                          \\\n+  product(bool, UseCompressedClassPointers, true,                           \\\n@@ -132,1 +133,1 @@\n-  product(intx, ObjectAlignmentInBytes, 8,                                  \\\n+  product(int, ObjectAlignmentInBytes, 8,                                   \\\n@@ -149,1 +150,1 @@\n-const intx ObjectAlignmentInBytes = 8;\n+const int ObjectAlignmentInBytes = 8;\n@@ -241,0 +242,3 @@\n+  product(bool, UsePoly1305Intrinsics, false, DIAGNOSTIC,                   \\\n+          \"Use intrinsics for sun.security.util.math.intpoly\")              \\\n+                                                                            \\\n@@ -273,1 +277,1 @@\n-          \"Reclamation of zombie and not-entrant methods\")                  \\\n+          \"Reclamation of compiled methods\")                                \\\n@@ -317,3 +321,0 @@\n-  product(bool, CriticalJNINatives, false,                                  \\\n-          \"(Deprecated) Check for critical JNI entry points\")               \\\n-                                                                            \\\n@@ -326,0 +327,3 @@\n+  product(bool, UseChaCha20Intrinsics, false, DIAGNOSTIC,                   \\\n+          \"Use intrinsics for the vectorized version of ChaCha20\")          \\\n+                                                                            \\\n@@ -357,0 +361,3 @@\n+  product(bool, UseVectorizedHashCodeIntrinsic, false, DIAGNOSTIC,          \\\n+          \"Enables intrinsification of ArraysSupport.vectorizedHashCode()\") \\\n+                                                                            \\\n@@ -363,0 +370,3 @@\n+  product_pd(bool, DelayCompilerStubsGeneration, DIAGNOSTIC,                \\\n+          \"Use Compiler thread for compiler's stubs generation\")            \\\n+                                                                            \\\n@@ -385,1 +395,1 @@\n-          \"Create zombies (non-entrant) at exit from the runtime system\")   \\\n+          \"Create non-entrant nmethods at exit from the runtime system\")    \\\n@@ -455,4 +465,1 @@\n-  develop(bool, UseMallocOnly, false,                                       \\\n-          \"Use only malloc\/free for allocation (no resource area\/arena)\")   \\\n-                                                                            \\\n-          \"Zap freed resource\/arena space with 0xABABABAB\")                 \\\n+          \"Zap freed resource\/arena space\")                                 \\\n@@ -462,1 +469,1 @@\n-          \"Zap freed VM handle space with 0xBCBCBCBC\")                      \\\n+          \"Zap freed VM handle space\")                                      \\\n@@ -465,1 +472,1 @@\n-          \"Zap allocated\/freed stack segments with 0xFADFADED\")             \\\n+          \"Zap allocated\/freed stack segments\")                             \\\n@@ -468,1 +475,1 @@\n-          \"Zap unused heap space with 0xBAADBABE\")                          \\\n+          \"Zap unused heap space\")                                          \\\n@@ -474,1 +481,1 @@\n-          \"Zap filler objects with 0xDEAFBABE\")                             \\\n+          \"Zap filler objects\")                                             \\\n@@ -479,1 +486,1 @@\n-  develop(uintx, ErrorHandlerTest, 0,                                       \\\n+  develop(uint, ErrorHandlerTest, 0,                                        \\\n@@ -485,1 +492,1 @@\n-  develop(uintx, TestCrashInErrorHandler, 0,                                \\\n+  develop(uint, TestCrashInErrorHandler, 0,                                 \\\n@@ -516,0 +523,7 @@\n+  product(bool, ErrorLogSecondaryErrorDetails, false, DIAGNOSTIC,           \\\n+          \"If enabled, show details on secondary crashes in the error log\") \\\n+                                                                            \\\n+  develop(intx, TraceDwarfLevel, 0,                                         \\\n+          \"Debug levels for the dwarf parser\")                              \\\n+          range(0, 4)                                                       \\\n+                                                                            \\\n@@ -537,1 +551,1 @@\n-  product(ccstr, HeapDumpPath, NULL, MANAGEABLE,                            \\\n+  product(ccstr, HeapDumpPath, nullptr, MANAGEABLE,                         \\\n@@ -548,1 +562,1 @@\n-  product(ccstr, NativeMemoryTracking, \"off\",                               \\\n+  product(ccstr, NativeMemoryTracking, DEBUG_ONLY(\"summary\") NOT_DEBUG(\"off\"), \\\n@@ -591,1 +605,1 @@\n-  product(ccstr, PrintAssemblyOptions, NULL, DIAGNOSTIC,                    \\\n+  product(ccstr, PrintAssemblyOptions, nullptr, DIAGNOSTIC,                 \\\n@@ -619,1 +633,1 @@\n-          \"Start debugger when an implicit OS (e.g. NULL) \"                 \\\n+          \"Start debugger when an implicit OS (e.g. null pointer) \"         \\\n@@ -677,8 +691,0 @@\n-  product(bool, DynamicallyResizeSystemDictionaries, true, DIAGNOSTIC,      \\\n-          \"Dynamically resize system dictionaries as needed\")               \\\n-                                                                            \\\n-  product(bool, AlwaysLockClassLoader, false,                               \\\n-          \"(Deprecated) Require the VM to acquire the class loader lock \"   \\\n-          \"before calling loadClass() even for class loaders registering \"  \\\n-          \"as parallel capable\")                                            \\\n-                                                                            \\\n@@ -696,0 +702,4 @@\n+  product(bool, DoJVMTIVirtualThreadTransitions, true, EXPERIMENTAL,        \\\n+               \"Do JVMTI virtual thread mount\/unmount transitions \"         \\\n+               \"(disabling this flag implies no JVMTI events are posted)\")  \\\n+                                                                            \\\n@@ -703,0 +713,7 @@\n+  \/* notice: the max range value here is max_jint, not max_intx  *\/         \\\n+  \/* because of overflow issue                                   *\/         \\\n+  product(intx, GuaranteedAsyncDeflationInterval, 60000, DIAGNOSTIC,        \\\n+          \"Async deflate idle monitors every so many milliseconds even \"    \\\n+          \"when MonitorUsedDeflationThreshold is NOT exceeded (0 is off).\") \\\n+          range(0, max_jint)                                                \\\n+                                                                            \\\n@@ -717,2 +734,3 @@\n-          \"off). The check is performed on GuaranteedSafepointInterval \"    \\\n-          \"or AsyncDeflationInterval.\")                                     \\\n+          \"off). The check is performed on GuaranteedSafepointInterval, \"   \\\n+          \"AsyncDeflationInterval or GuaranteedAsyncDeflationInterval, \"    \\\n+          \"whichever is lower.\")                                            \\\n@@ -729,4 +747,0 @@\n-  product(bool, FilterSpuriousWakeups, true,                                \\\n-          \"When true prevents OS-level spurious, or premature, wakeups \"    \\\n-          \"from Object.wait (Ignored for Windows)\")                         \\\n-                                                                            \\\n@@ -802,32 +816,1 @@\n-  product(bool, UseBiasedLocking, false,                                    \\\n-          \"(Deprecated) Enable biased locking in JVM\")                      \\\n-                                                                            \\\n-  product(intx, BiasedLockingStartupDelay, 0,                               \\\n-          \"(Deprecated) Number of milliseconds to wait before enabling \"    \\\n-          \"biased locking\")                                                 \\\n-          range(0, (intx)(max_jint-(max_jint%PeriodicTask::interval_gran))) \\\n-          constraint(BiasedLockingStartupDelayFunc,AfterErgo)               \\\n-                                                                            \\\n-  product(bool, PrintBiasedLockingStatistics, false, DIAGNOSTIC,            \\\n-          \"(Deprecated) Print statistics of biased locking in JVM\")         \\\n-                                                                            \\\n-  product(intx, BiasedLockingBulkRebiasThreshold, 20,                       \\\n-          \"(Deprecated) Threshold of number of revocations per type to \"    \\\n-          \"try to rebias all objects in the heap of that type\")             \\\n-          range(0, max_intx)                                                \\\n-          constraint(BiasedLockingBulkRebiasThresholdFunc,AfterErgo)        \\\n-                                                                            \\\n-  product(intx, BiasedLockingBulkRevokeThreshold, 40,                       \\\n-          \"(Deprecated) Threshold of number of revocations per type to \"    \\\n-          \"permanently revoke biases of all objects in the heap of that \"   \\\n-          \"type\")                                                           \\\n-          range(0, max_intx)                                                \\\n-          constraint(BiasedLockingBulkRevokeThresholdFunc,AfterErgo)        \\\n-                                                                            \\\n-  product(intx, BiasedLockingDecayTime, 25000,                              \\\n-          \"(Deprecated) Decay time (in milliseconds) to re-enable bulk \"    \\\n-          \"rebiasing of a type after previous bulk rebias\")                 \\\n-          range(500, max_intx)                                              \\\n-          constraint(BiasedLockingDecayTimeFunc,AfterErgo)                  \\\n-                                                                            \\\n-  product(intx, DiagnoseSyncOnValueBasedClasses, 0, DIAGNOSTIC,             \\\n+  product(int, DiagnoseSyncOnValueBasedClasses, 0, DIAGNOSTIC,              \\\n@@ -856,1 +839,1 @@\n-  product(ccstr, TraceJVMTI, NULL,                                          \\\n+  product(ccstr, TraceJVMTI, nullptr,                                       \\\n@@ -881,3 +864,0 @@\n-  develop(bool, TraceDependencies, false,                                   \\\n-          \"Trace dependencies\")                                             \\\n-                                                                            \\\n@@ -911,4 +891,0 @@\n-                                                                            \\\n-  notproduct(bool, CheckMemoryInitialization, false,                        \\\n-          \"Check memory initialization\")                                    \\\n-                                                                            \\\n@@ -968,3 +944,0 @@\n-  develop(bool, GenerateRangeChecks, true,                                  \\\n-          \"Generate range checks for array accesses\")                       \\\n-                                                                            \\\n@@ -980,3 +953,0 @@\n-  product(bool, EnableThreadSMRExtraValidityChecks, true, DIAGNOSTIC,       \\\n-             \"Enable Thread SMR extra validity checks\")                     \\\n-                                                                            \\\n@@ -1010,9 +980,0 @@\n-  develop(bool, EagerInitialization, false,                                 \\\n-          \"Eagerly initialize classes if possible\")                         \\\n-                                                                            \\\n-  product(bool, LogTouchedMethods, false, DIAGNOSTIC,                       \\\n-          \"Log methods which have been ever touched in runtime\")            \\\n-                                                                            \\\n-  product(bool, PrintTouchedMethodsAtExit, false, DIAGNOSTIC,               \\\n-          \"Print all methods that have been ever touched in runtime\")       \\\n-                                                                            \\\n@@ -1022,3 +983,0 @@\n-  develop(bool, PrintMethodFlushing, false,                                 \\\n-          \"Print the nmethods being flushed\")                               \\\n-                                                                            \\\n@@ -1028,5 +986,0 @@\n-  product(intx, HotMethodDetectionLimit, 100000, DIAGNOSTIC,                \\\n-          \"Number of compiled code invocations after which \"                \\\n-          \"the method is considered as hot by the flusher\")                 \\\n-          range(1, max_jint)                                                \\\n-                                                                            \\\n@@ -1038,6 +991,0 @@\n-  product(bool, UseCodeAging, true,                                         \\\n-          \"Insert counter to detect warm methods\")                          \\\n-                                                                            \\\n-  product(bool, StressCodeAging, false, DIAGNOSTIC,                         \\\n-          \"Start with counters compiled in\")                                \\\n-                                                                            \\\n@@ -1082,1 +1029,1 @@\n-  product(ccstr, LogFile, NULL, DIAGNOSTIC,                                 \\\n+  product(ccstr, LogFile, nullptr, DIAGNOSTIC,                              \\\n@@ -1086,1 +1033,1 @@\n-  product(ccstr, ErrorFile, NULL,                                           \\\n+  product(ccstr, ErrorFile, nullptr,                                        \\\n@@ -1106,2 +1053,7 @@\n-  product(bool, UseHeavyMonitors, false,                                    \\\n-          \"use heavyweight instead of lightweight Java monitors\")           \\\n+  develop(bool, UseHeavyMonitors, false,                                    \\\n+          \"(Deprecated) Use heavyweight instead of lightweight Java \"       \\\n+          \"monitors\")                                                       \\\n+                                                                            \\\n+  develop(bool, VerifyHeavyMonitors, false,                                 \\\n+          \"Checks that no stack locking happens when using \"                \\\n+          \"+UseHeavyMonitors\")                                              \\\n@@ -1118,1 +1070,1 @@\n-  product(ccstr, AbortVMOnException, NULL, DIAGNOSTIC,                      \\\n+  product(ccstr, AbortVMOnException, nullptr, DIAGNOSTIC,                   \\\n@@ -1122,1 +1074,1 @@\n-  product(ccstr, AbortVMOnExceptionMessage, NULL, DIAGNOSTIC,               \\\n+  product(ccstr, AbortVMOnExceptionMessage, nullptr, DIAGNOSTIC,            \\\n@@ -1129,6 +1081,0 @@\n-  notproduct(bool, PrintVtableStats, false,                                 \\\n-          \"print vtables stats at end of run\")                              \\\n-                                                                            \\\n-  develop(bool, TraceCreateZombies, false,                                  \\\n-          \"trace creation of zombie nmethods\")                              \\\n-                                                                            \\\n@@ -1160,1 +1106,1 @@\n-  product_pd(uintx, TypeProfileLevel,                                       \\\n+  product_pd(uint, TypeProfileLevel,                                        \\\n@@ -1234,4 +1180,0 @@\n-  notproduct(bool, VerifyJNIEnvThread, false,                               \\\n-          \"Verify JNIEnv.thread == Thread::current() when entering VM \"     \\\n-          \"from JNI\")                                                       \\\n-                                                                            \\\n@@ -1241,3 +1183,0 @@\n-  develop(bool, VerifyThread, false,                                        \\\n-          \"Watch the thread register for corruption (SPARC only)\")          \\\n-                                                                            \\\n@@ -1252,1 +1191,1 @@\n-          \"Inline intrinsics that can be statically resolved\")              \\\n+          \"Use intrinsics in Interpreter that can be statically resolved\")  \\\n@@ -1324,1 +1263,1 @@\n-  develop(bool, TraceDeoptimization, false,                                 \\\n+  product(bool, TraceDeoptimization, false, DIAGNOSTIC,                     \\\n@@ -1333,4 +1272,5 @@\n-  product(intx, SelfDestructTimer, 0,                                       \\\n-          \"Will cause VM to terminate after a given time (in minutes) \"     \\\n-          \"(0 means off)\")                                                  \\\n-          range(0, max_intx)                                                \\\n+  product(double, SelfDestructTimer, 0.0,                                   \\\n+          \"Will cause VM to terminate after a given time \"                  \\\n+          \"(in fractional minutes) \"                                        \\\n+          \"(0.0 means off)\")                                                \\\n+          range(0.0, (double)max_intx)                                      \\\n@@ -1354,1 +1294,4 @@\n-  product(intx, NmethodSweepActivity, 10,                                   \\\n+  product(bool, UseSystemMemoryBarrier, false,                              \\\n+          \"Try to enable system memory barrier if supported by OS\")         \\\n+                                                                            \\\n+  product(intx, NmethodSweepActivity, 4,                                    \\\n@@ -1359,6 +1302,0 @@\n-  notproduct(bool, LogSweeper, false,                                       \\\n-          \"Keep a ring buffer of sweeper activity\")                         \\\n-                                                                            \\\n-  notproduct(intx, SweeperLogEntries, 1024,                                 \\\n-          \"Number of records in the ring buffer of sweeper activity\")       \\\n-                                                                            \\\n@@ -1368,3 +1305,0 @@\n-  notproduct(ccstrlist, SuppressErrorAt, \"\",                                \\\n-          \"List of assertions (file:line) to muzzle\")                       \\\n-                                                                            \\\n@@ -1374,0 +1308,4 @@\n+  product(int, ErrorLogPrintCodeLimit, 3, DIAGNOSTIC,                       \\\n+          \"max number of compiled code units to print in error log\")        \\\n+          range(0, VMError::max_error_log_print_code)                       \\\n+                                                                            \\\n@@ -1385,5 +1323,0 @@\n-  product(intx, MinInliningThreshold, 250,                                  \\\n-          \"The minimum invocation count a method needs to have to be \"      \\\n-          \"inlined\")                                                        \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n@@ -1402,4 +1335,16 @@\n-  product(uintx, MallocMaxTestWords,     0, DIAGNOSTIC,                     \\\n-          \"If non-zero, maximum number of words that malloc\/realloc can \"   \\\n-          \"allocate (for testing only)\")                                    \\\n-          range(0, max_uintx)                                               \\\n+  product(ccstr, MallocLimit, nullptr, DIAGNOSTIC,                          \\\n+          \"Limit malloc allocation size from VM. Reaching a limit will \"    \\\n+          \"trigger an action (see flag). This feature requires \"            \\\n+          \"NativeMemoryTracking=summary or NativeMemoryTracking=detail.\"    \\\n+          \"Usage:\"                                                          \\\n+          \"\\\"-XX:MallocLimit=<size>[:<flag>]\\\" sets a total limit.\"         \\\n+          \"\\\"-XX:MallocLimit=<category>:<size>[:<flag>][,<category>:<size>[:<flag>] ...]\\\"\" \\\n+          \"sets one or more category-specific limits.\"                      \\\n+          \"<flag> defines the action upon reaching the limit:\"              \\\n+          \"\\\"fatal\\\": end VM with a fatal error at the allocation site\"     \\\n+          \"\\\"oom\\\"  : will mimic a native OOM\"                              \\\n+          \"If <flag> is omitted, \\\"fatal\\\" is the default.\"                 \\\n+          \"Examples:\\n\"                                                     \\\n+          \"-XX:MallocLimit=2g\"                                              \\\n+          \"-XX:MallocLimit=2g:oom\"                                          \\\n+          \"-XX:MallocLimit=compiler:200m:oom,code:100m\")                    \\\n@@ -1438,1 +1383,1 @@\n-  develop(intx, InlineFrequencyRatio,    20,                                \\\n+  product(double, InlineFrequencyRatio, 0.25, DIAGNOSTIC,                   \\\n@@ -1440,5 +1385,3 @@\n-          range(0, max_jint)                                                \\\n-  product_pd(intx, InlineFrequencyCount, DIAGNOSTIC,                        \\\n-          \"Count of call site execution necessary to trigger frequent \"     \\\n-          \"inlining\")                                                       \\\n-          range(0, max_jint)                                                \\\n+  product(double, MinInlineFrequencyRatio, 0.0085, DIAGNOSTIC,              \\\n+          \"Minimum ratio of call site execution to caller method\"           \\\n+          \"invocation to be considered for inlining\")                       \\\n@@ -1473,3 +1416,0 @@\n-  product(ccstr, MetaspaceReclaimPolicy, \"balanced\",                        \\\n-          \"options: balanced, aggressive, none\")                            \\\n-                                                                            \\\n@@ -1479,1 +1419,1 @@\n-  product(bool, MetaspaceGuardAllocations, false, DIAGNOSTIC,               \\\n+  develop(bool, MetaspaceGuardAllocations, false,                           \\\n@@ -1482,3 +1422,0 @@\n-  product(bool, MetaspaceHandleDeallocations, true, DIAGNOSTIC,             \\\n-          \"Switch off Metapace deallocation handling.\")                     \\\n-                                                                            \\\n@@ -1575,1 +1512,1 @@\n-  develop_pd(uintx, CodeCacheSegmentSize,                                   \\\n+  product_pd(uintx, CodeCacheSegmentSize, EXPERIMENTAL,                     \\\n@@ -1581,1 +1518,1 @@\n-  develop_pd(intx, CodeEntryAlignment,                                      \\\n+  product_pd(intx, CodeEntryAlignment, EXPERIMENTAL,                        \\\n@@ -1587,1 +1524,1 @@\n-          range(1, 16)                                                      \\\n+          range(1, 128)                                                     \\\n@@ -1631,2 +1568,2 @@\n-  product(double, SweeperThreshold, 0.5,                                    \\\n-          \"Threshold controlling when code cache sweeper is invoked.\"       \\\n+  product(double, SweeperThreshold, 15.0,                                   \\\n+          \"Threshold when a code cache unloading GC is invoked.\"            \\\n@@ -1656,1 +1593,1 @@\n-  product(intx, ThreadPriorityPolicy, 0,                                    \\\n+  product(int, ThreadPriorityPolicy, 0,                                     \\\n@@ -1681,1 +1618,1 @@\n-  product(intx, CompilerThreadPriority, -1,                                 \\\n+  product(int, CompilerThreadPriority, -1,                                  \\\n@@ -1686,1 +1623,1 @@\n-  product(intx, VMThreadPriority, -1,                                       \\\n+  product(int, VMThreadPriority, -1,                                        \\\n@@ -1691,1 +1628,1 @@\n-  product(intx, JavaPriority1_To_OSPriority, -1,                            \\\n+  product(int, JavaPriority1_To_OSPriority, -1,                             \\\n@@ -1695,1 +1632,1 @@\n-  product(intx, JavaPriority2_To_OSPriority, -1,                            \\\n+  product(int, JavaPriority2_To_OSPriority, -1,                             \\\n@@ -1699,1 +1636,1 @@\n-  product(intx, JavaPriority3_To_OSPriority, -1,                            \\\n+  product(int, JavaPriority3_To_OSPriority, -1,                             \\\n@@ -1703,1 +1640,1 @@\n-  product(intx, JavaPriority4_To_OSPriority, -1,                            \\\n+  product(int, JavaPriority4_To_OSPriority, -1,                             \\\n@@ -1707,1 +1644,1 @@\n-  product(intx, JavaPriority5_To_OSPriority, -1,                            \\\n+  product(int, JavaPriority5_To_OSPriority, -1,                             \\\n@@ -1711,1 +1648,1 @@\n-  product(intx, JavaPriority6_To_OSPriority, -1,                            \\\n+  product(int, JavaPriority6_To_OSPriority, -1,                             \\\n@@ -1715,1 +1652,1 @@\n-  product(intx, JavaPriority7_To_OSPriority, -1,                            \\\n+  product(int, JavaPriority7_To_OSPriority, -1,                             \\\n@@ -1719,1 +1656,1 @@\n-  product(intx, JavaPriority8_To_OSPriority, -1,                            \\\n+  product(int, JavaPriority8_To_OSPriority, -1,                             \\\n@@ -1723,1 +1660,1 @@\n-  product(intx, JavaPriority9_To_OSPriority, -1,                            \\\n+  product(int, JavaPriority9_To_OSPriority, -1,                             \\\n@@ -1727,1 +1664,1 @@\n-  product(intx, JavaPriority10_To_OSPriority,-1,                            \\\n+  product(int, JavaPriority10_To_OSPriority,-1,                             \\\n@@ -1756,1 +1693,2 @@\n-          \"Maximum total size of NIO direct-buffer allocations\")            \\\n+          \"Maximum total size of NIO direct-buffer allocations. \"           \\\n+          \"Ignored if not explicitly set.\")                                 \\\n@@ -1793,1 +1731,1 @@\n-  product(ccstr, PerfDataSaveFile, NULL,                                    \\\n+  product(ccstr, PerfDataSaveFile, nullptr,                                 \\\n@@ -1806,1 +1744,1 @@\n-  product(intx, PerfDataMemorySize, 32*K,                                   \\\n+  product(int, PerfDataMemorySize, 32*K,                                    \\\n@@ -1811,1 +1749,1 @@\n-  product(intx, PerfMaxStringConstLength, 1024,                             \\\n+  product(int, PerfMaxStringConstLength, 1024,                              \\\n@@ -1821,1 +1759,1 @@\n-  product(intx, UnguardOnExecutionViolation, 0,                             \\\n+  product(int, UnguardOnExecutionViolation, 0,                              \\\n@@ -1843,44 +1781,0 @@\n-  \/* Shared spaces *\/                                                       \\\n-                                                                            \\\n-  product(bool, UseSharedSpaces, true,                                      \\\n-          \"Use shared spaces for metadata\")                                 \\\n-                                                                            \\\n-  product(bool, VerifySharedSpaces, false,                                  \\\n-          \"Verify integrity of shared spaces\")                              \\\n-                                                                            \\\n-  product(bool, RequireSharedSpaces, false,                                 \\\n-          \"Require shared spaces for metadata\")                             \\\n-                                                                            \\\n-  product(bool, DumpSharedSpaces, false,                                    \\\n-          \"Special mode: JVM reads a class list, loads classes, builds \"    \\\n-          \"shared spaces, and dumps the shared spaces to a file to be \"     \\\n-          \"used in future JVM runs\")                                        \\\n-                                                                            \\\n-  product(bool, DynamicDumpSharedSpaces, false,                             \\\n-          \"Dynamic archive\")                                                \\\n-                                                                            \\\n-  product(bool, RecordDynamicDumpInfo, false,                               \\\n-          \"Record class info for jcmd VM.cds dynamic_dump\")                 \\\n-                                                                            \\\n-  product(bool, PrintSharedArchiveAndExit, false,                           \\\n-          \"Print shared archive file contents\")                             \\\n-                                                                            \\\n-  product(bool, PrintSharedDictionary, false,                               \\\n-          \"If PrintSharedArchiveAndExit is true, also print the shared \"    \\\n-          \"dictionary\")                                                     \\\n-                                                                            \\\n-  product(size_t, SharedBaseAddress, LP64_ONLY(32*G)                        \\\n-          NOT_LP64(LINUX_ONLY(2*G) NOT_LINUX(0)),                           \\\n-          \"Address to allocate shared memory region for class data\")        \\\n-          range(0, SIZE_MAX)                                                \\\n-                                                                            \\\n-  product(ccstr, SharedArchiveConfigFile, NULL,                             \\\n-          \"Data to add to the CDS archive file\")                            \\\n-                                                                            \\\n-  product(uintx, SharedSymbolTableBucketSize, 4,                            \\\n-          \"Average number of symbols per bucket in shared table\")           \\\n-          range(2, 246)                                                     \\\n-                                                                            \\\n-  product(bool, AllowArchivingWithJavaAgent, false, DIAGNOSTIC,             \\\n-          \"Allow Java agent to be run with CDS dumping\")                    \\\n-                                                                            \\\n@@ -1896,0 +1790,3 @@\n+  product(bool, ShowCarrierFrames, false, DIAGNOSTIC,                       \\\n+          \"show virtual threads' carrier frames in exceptions\")             \\\n+                                                                            \\\n@@ -1914,1 +1811,1 @@\n-  product(ccstr, PauseAtStartupFile, NULL, DIAGNOSTIC,                      \\\n+  product(ccstr, PauseAtStartupFile, nullptr, DIAGNOSTIC,                      \\\n@@ -1921,4 +1818,1 @@\n-  product(bool, ExtendedDTraceProbes,    false,                             \\\n-          \"Enable performance-impacting dtrace probes\")                     \\\n-                                                                            \\\n-          \"Enable dtrace probes for method-entry and method-exit\")          \\\n+          \"Enable dtrace tool probes for method-entry and method-exit\")     \\\n@@ -1928,1 +1822,1 @@\n-          \"Enable dtrace probes for object allocation\")                     \\\n+          \"Enable dtrace tool probes for object allocation\")                \\\n@@ -1931,1 +1825,1 @@\n-          \"Enable dtrace probes for monitor events\")                        \\\n+          \"Enable dtrace tool probes for monitor events\")                   \\\n@@ -1985,25 +1879,1 @@\n-  product(ccstr, DumpLoadedClassList, NULL,                                 \\\n-          \"Dump the names all loaded classes, that could be stored into \"   \\\n-          \"the CDS archive, in the specified file\")                         \\\n-                                                                            \\\n-  product(ccstr, SharedClassListFile, NULL,                                 \\\n-          \"Override the default CDS class list\")                            \\\n-                                                                            \\\n-  product(ccstr, SharedArchiveFile, NULL,                                   \\\n-          \"Override the default location of the CDS archive file\")          \\\n-                                                                            \\\n-  product(ccstr, ArchiveClassesAtExit, NULL,                                \\\n-          \"The path and name of the dynamic archive file\")                  \\\n-                                                                            \\\n-  product(ccstr, ExtraSharedClassListFile, NULL,                            \\\n-          \"Extra classlist for building the CDS archive file\")              \\\n-                                                                            \\\n-  product(intx, ArchiveRelocationMode, 0, DIAGNOSTIC,                       \\\n-           \"(0) first map at preferred address, and if \"                    \\\n-           \"unsuccessful, map at alternative address (default); \"           \\\n-           \"(1) always map at alternative address; \"                        \\\n-           \"(2) always map at preferred address, and if unsuccessful, \"     \\\n-           \"do not map the archive\")                                        \\\n-           range(0, 2)                                                      \\\n-                                                                            \\\n-  product(size_t, ArrayAllocatorMallocLimit, (size_t)-1, EXPERIMENTAL,      \\\n+  product(size_t, ArrayAllocatorMallocLimit, SIZE_MAX, EXPERIMENTAL,        \\\n@@ -2048,1 +1918,1 @@\n-  product(ccstr, AllocateHeapAt, NULL,                                      \\\n+  product(ccstr, AllocateHeapAt, nullptr,                                   \\\n@@ -2052,0 +1922,15 @@\n+  product_pd(bool, VMContinuations, EXPERIMENTAL,                           \\\n+          \"Enable VM continuations support\")                                \\\n+                                                                            \\\n+  develop(bool, LoomDeoptAfterThaw, false,                                  \\\n+          \"Deopt stack after thaw\")                                         \\\n+                                                                            \\\n+  develop(bool, LoomVerifyAfterThaw, false,                                 \\\n+          \"Verify stack after thaw\")                                        \\\n+                                                                            \\\n+  develop(bool, VerifyContinuations, false,                                 \\\n+          \"Verify continuation consistency\")                                \\\n+                                                                            \\\n+  develop(bool, UseContinuationFastPath, true,                              \\\n+          \"Use fast-path frame walking in continuations\")                   \\\n+                                                                            \\\n@@ -2068,1 +1953,1 @@\n-  JFR_ONLY(product(ccstr, FlightRecorderOptions, NULL,                      \\\n+  JFR_ONLY(product(ccstr, FlightRecorderOptions, nullptr,                   \\\n@@ -2071,1 +1956,1 @@\n-  JFR_ONLY(product(ccstr, StartFlightRecording, NULL,                       \\\n+  JFR_ONLY(product(ccstr, StartFlightRecording, nullptr,                    \\\n@@ -2099,2 +1984,6 @@\n-  develop(bool, TraceOptimizedUpcallStubs, false,                              \\\n-                \"Trace optimized upcall stub generation\")                      \\\n+  product(int, LockingMode, LM_LEGACY, EXPERIMENTAL,                        \\\n+          \"Select locking mode: \"                                           \\\n+          \"0: monitors only (LM_MONITOR), \"                                 \\\n+          \"1: monitors & legacy stack-locking (LM_LEGACY, default), \"       \\\n+          \"2: monitors & new lightweight locking (LM_LIGHTWEIGHT)\")         \\\n+          range(0, 2)                                                       \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":163,"deletions":274,"binary":false,"changes":437,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,3 +31,1 @@\n-#if INCLUDE_JVMCI\n-#include \"jvmci\/jvmci.hpp\"\n-#endif\n+#include \"gc\/shared\/gcHeapSummary.hpp\"\n@@ -35,2 +33,0 @@\n-#include \"logging\/log.hpp\"\n-#include \"logging\/logTag.hpp\"\n@@ -41,1 +37,1 @@\n-#include \"prims\/universalNativeInvoker.hpp\"\n+#include \"prims\/downcallLinker.hpp\"\n@@ -44,0 +40,1 @@\n+#include \"runtime\/continuation.hpp\"\n@@ -50,0 +47,1 @@\n+#include \"sanitizers\/leak.hpp\"\n@@ -52,1 +50,3 @@\n-\n+#if INCLUDE_JVMCI\n+#include \"jvmci\/jvmci.hpp\"\n+#endif\n@@ -59,1 +59,0 @@\n-void chunkpool_init();\n@@ -70,2 +69,3 @@\n-void stubRoutines_init1();\n-jint universe_init();          \/\/ depends on codeCache_init and stubRoutines_init\n+void initial_stubs_init();\n+\n+jint universe_init();           \/\/ depends on codeCache_init and initial_stubs_init\n@@ -75,2 +75,4 @@\n-void interpreter_init_stub();  \/\/ before any methods loaded\n-void interpreter_init_code();  \/\/ after methods loaded, but before they are linked\n+void continuations_init();      \/\/ depends on flags (UseCompressedOops) and barrier sets\n+void continuation_stubs_init(); \/\/ depend on continuations_init\n+void interpreter_init_stub();   \/\/ before any methods loaded\n+void interpreter_init_code();   \/\/ after methods loaded, but before they are linked\n@@ -79,1 +81,1 @@\n-void universe2_init();  \/\/ dependent on codeCache_init and stubRoutines_init, loads primordial classes\n+void universe2_init();  \/\/ dependent on codeCache_init and initial_stubs_init, loads primordial classes\n@@ -93,2 +95,3 @@\n-void javaClasses_init();  \/\/ must happen after vtable initialization\n-void stubRoutines_init2(); \/\/ note: StubRoutines need 2-phase init\n+void javaClasses_init();    \/\/ must happen after vtable initialization\n+void compiler_stubs_init(bool in_compiler_thread); \/\/ compiler's StubRoutines stubs\n+void final_stubs_init();    \/\/ final StubRoutines stubs\n@@ -109,1 +112,0 @@\n-  chunkpool_init();\n@@ -122,1 +124,1 @@\n-  stubRoutines_init1();\n+  initial_stubs_init();\n@@ -124,1 +126,1 @@\n-                                  \/\/ stubRoutines_init1 and metaspace_init.\n+                                  \/\/ initial_stubs_init and metaspace_init.\n@@ -134,0 +136,7 @@\n+#ifdef LEAK_SANITIZER\n+  {\n+    \/\/ Register the Java heap with LSan.\n+    VirtualSpaceSummary summary = Universe::heap()->create_heap_space_summary();\n+    LSAN_REGISTER_ROOT_REGION(summary.start(), summary.reserved_size());\n+  }\n+#endif \/\/ LEAK_SANITIZER\n@@ -136,2 +145,4 @@\n-  gc_barrier_stubs_init();  \/\/ depends on universe_init, must be before interpreter_init\n-  interpreter_init_stub();  \/\/ before methods get loaded\n+  gc_barrier_stubs_init();   \/\/ depends on universe_init, must be before interpreter_init\n+  continuations_init();      \/\/ must precede continuation stub generation\n+  continuation_stubs_init(); \/\/ depends on continuations_init\n+  interpreter_init_stub();   \/\/ before methods get loaded\n@@ -140,1 +151,1 @@\n-  VMRegImpl::set_regName(); \/\/ need this before generate_stubs (for printing oop maps).\n+  VMRegImpl::set_regName();  \/\/ need this before generate_stubs (for printing oop maps).\n@@ -142,3 +153,7 @@\n-  universe2_init();  \/\/ dependent on codeCache_init and stubRoutines_init1\n-  javaClasses_init();\/\/ must happen after vtable initialization, before referenceProcessor_init\n-  interpreter_init_code();  \/\/ after javaClasses_init and before any method gets linked\n+  return JNI_OK;\n+}\n+\n+jint init_globals2() {\n+  universe2_init();          \/\/ dependent on codeCache_init and initial_stubs_init\n+  javaClasses_init();        \/\/ must happen after vtable initialization, before referenceProcessor_init\n+  interpreter_init_code();   \/\/ after javaClasses_init and before any method gets linked\n@@ -169,1 +184,2 @@\n-  stubRoutines_init2(); \/\/ note: StubRoutines need 2-phase init\n+  compiler_stubs_init(false \/* in_compiler_thread *\/); \/\/ compiler's intrinsics stubs\n+  final_stubs_init();    \/\/ final StubRoutines stubs\n@@ -196,0 +212,7 @@\n+#ifdef LEAK_SANITIZER\n+    {\n+      \/\/ Unregister the Java heap with LSan.\n+      VirtualSpaceSummary summary = Universe::heap()->create_heap_space_summary();\n+      LSAN_UNREGISTER_ROOT_REGION(summary.start(), summary.reserved_size());\n+    }\n+#endif \/\/ LEAK_SANITIZER\n","filename":"src\/hotspot\/share\/runtime\/init.cpp","additions":49,"deletions":26,"binary":false,"changes":75,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,0 +27,3 @@\n+#include \"logging\/log.hpp\"\n+#include \"logging\/logStream.hpp\"\n+#include \"memory\/resourceArea.hpp\"\n@@ -28,0 +31,1 @@\n+#include \"runtime\/javaThread.hpp\"\n@@ -29,2 +33,1 @@\n-#include \"runtime\/os.inline.hpp\"\n-#include \"runtime\/thread.inline.hpp\"\n+#include \"utilities\/vmError.hpp\"\n@@ -35,63 +38,57 @@\n-\/\/\n-\/\/ Note that the following pointers are effectively final -- after having been\n-\/\/ set at JVM startup-time, they should never be subsequently mutated.\n-\/\/ Instead of using pointers to malloc()ed monitors and mutexes we should consider\n-\/\/ eliminating the indirection and using instances instead.\n-\/\/ Consider using GCC's __read_mostly.\n-\n-Mutex*   Patching_lock                = NULL;\n-Mutex*   CompiledMethod_lock          = NULL;\n-Monitor* SystemDictionary_lock        = NULL;\n-Mutex*   SharedDictionary_lock        = NULL;\n-Mutex*   Module_lock                  = NULL;\n-Mutex*   CompiledIC_lock              = NULL;\n-Mutex*   InlineCacheBuffer_lock       = NULL;\n-Mutex*   VMStatistic_lock             = NULL;\n-Mutex*   JNIHandleBlockFreeList_lock  = NULL;\n-Mutex*   JmethodIdCreation_lock       = NULL;\n-Mutex*   JfieldIdCreation_lock        = NULL;\n-Monitor* JNICritical_lock             = NULL;\n-Mutex*   JvmtiThreadState_lock        = NULL;\n-Monitor* EscapeBarrier_lock           = NULL;\n-Monitor* Heap_lock                    = NULL;\n-Mutex*   ExpandHeap_lock              = NULL;\n-Mutex*   AdapterHandlerLibrary_lock   = NULL;\n-Mutex*   SignatureHandlerLibrary_lock = NULL;\n-Mutex*   VtableStubs_lock             = NULL;\n-Mutex*   SymbolArena_lock             = NULL;\n-Monitor* StringDedup_lock             = NULL;\n-Mutex*   StringDedupIntern_lock       = NULL;\n-Monitor* CodeCache_lock               = NULL;\n-Monitor* CodeSweeper_lock             = NULL;\n-Mutex*   MethodData_lock              = NULL;\n-Mutex*   TouchedMethodLog_lock        = NULL;\n-Mutex*   RetData_lock                 = NULL;\n-Monitor* VMOperation_lock             = NULL;\n-Monitor* Threads_lock                 = NULL;\n-Mutex*   NonJavaThreadsList_lock      = NULL;\n-Mutex*   NonJavaThreadsListSync_lock  = NULL;\n-Monitor* CGC_lock                     = NULL;\n-Monitor* STS_lock                     = NULL;\n-Monitor* G1OldGCCount_lock            = NULL;\n-Mutex*   Shared_DirtyCardQ_lock       = NULL;\n-Mutex*   G1DetachedRefinementStats_lock = NULL;\n-Mutex*   MarkStackFreeList_lock       = NULL;\n-Mutex*   MarkStackChunkList_lock      = NULL;\n-Mutex*   MonitoringSupport_lock       = NULL;\n-Mutex*   ParGCRareEvent_lock          = NULL;\n-Monitor* ConcurrentGCBreakpoints_lock = NULL;\n-Mutex*   Compile_lock                 = NULL;\n-Monitor* MethodCompileQueue_lock      = NULL;\n-Monitor* CompileThread_lock           = NULL;\n-Monitor* Compilation_lock             = NULL;\n-Mutex*   CompileTaskAlloc_lock        = NULL;\n-Mutex*   CompileStatistics_lock       = NULL;\n-Mutex*   DirectivesStack_lock         = NULL;\n-Mutex*   MultiArray_lock              = NULL;\n-Monitor* Terminator_lock              = NULL;\n-Monitor* InitCompleted_lock           = NULL;\n-Monitor* BeforeExit_lock              = NULL;\n-Monitor* Notify_lock                  = NULL;\n-Mutex*   ProfilePrint_lock            = NULL;\n-Mutex*   ExceptionCache_lock          = NULL;\n-Mutex*   NMethodSweeperStats_lock     = NULL;\n+\n+Mutex*   Patching_lock                = nullptr;\n+Mutex*   CompiledMethod_lock          = nullptr;\n+Monitor* SystemDictionary_lock        = nullptr;\n+Mutex*   InvokeMethodTypeTable_lock   = nullptr;\n+Monitor* InvokeMethodIntrinsicTable_lock = nullptr;\n+Mutex*   SharedDictionary_lock        = nullptr;\n+Monitor* ClassInitError_lock          = nullptr;\n+Mutex*   Module_lock                  = nullptr;\n+Mutex*   CompiledIC_lock              = nullptr;\n+Mutex*   InlineCacheBuffer_lock       = nullptr;\n+Mutex*   VMStatistic_lock             = nullptr;\n+Mutex*   JmethodIdCreation_lock       = nullptr;\n+Mutex*   JfieldIdCreation_lock        = nullptr;\n+Monitor* JNICritical_lock             = nullptr;\n+Mutex*   JvmtiThreadState_lock        = nullptr;\n+Monitor* EscapeBarrier_lock           = nullptr;\n+Monitor* JvmtiVTMSTransition_lock     = nullptr;\n+Monitor* Heap_lock                    = nullptr;\n+#ifdef INCLUDE_PARALLELGC\n+Mutex*   PSOldGenExpand_lock      = nullptr;\n+#endif\n+Mutex*   AdapterHandlerLibrary_lock   = nullptr;\n+Mutex*   SignatureHandlerLibrary_lock = nullptr;\n+Mutex*   VtableStubs_lock             = nullptr;\n+Mutex*   SymbolArena_lock             = nullptr;\n+Monitor* StringDedup_lock             = nullptr;\n+Mutex*   StringDedupIntern_lock       = nullptr;\n+Monitor* CodeCache_lock               = nullptr;\n+Mutex*   TouchedMethodLog_lock        = nullptr;\n+Mutex*   RetData_lock                 = nullptr;\n+Monitor* VMOperation_lock             = nullptr;\n+Monitor* Threads_lock                 = nullptr;\n+Mutex*   NonJavaThreadsList_lock      = nullptr;\n+Mutex*   NonJavaThreadsListSync_lock  = nullptr;\n+Monitor* CGC_lock                     = nullptr;\n+Monitor* STS_lock                     = nullptr;\n+Monitor* G1OldGCCount_lock            = nullptr;\n+Mutex*   G1RareEvent_lock             = nullptr;\n+Mutex*   G1DetachedRefinementStats_lock = nullptr;\n+Mutex*   MarkStackFreeList_lock       = nullptr;\n+Mutex*   MarkStackChunkList_lock      = nullptr;\n+Mutex*   MonitoringSupport_lock       = nullptr;\n+Monitor* ConcurrentGCBreakpoints_lock = nullptr;\n+Mutex*   Compile_lock                 = nullptr;\n+Monitor* MethodCompileQueue_lock      = nullptr;\n+Monitor* CompileThread_lock           = nullptr;\n+Monitor* Compilation_lock             = nullptr;\n+Mutex*   CompileTaskAlloc_lock        = nullptr;\n+Mutex*   CompileStatistics_lock       = nullptr;\n+Mutex*   DirectivesStack_lock         = nullptr;\n+Mutex*   MultiArray_lock              = nullptr;\n+Monitor* Terminator_lock              = nullptr;\n+Monitor* InitCompleted_lock           = nullptr;\n+Monitor* BeforeExit_lock              = nullptr;\n+Monitor* Notify_lock                  = nullptr;\n+Mutex*   ExceptionCache_lock          = nullptr;\n@@ -99,1 +96,1 @@\n-Mutex*   FullGCALot_lock              = NULL;\n+Mutex*   FullGCALot_lock              = nullptr;\n@@ -102,3 +99,1 @@\n-Mutex*   Debug1_lock                  = NULL;\n-Mutex*   Debug2_lock                  = NULL;\n-Mutex*   Debug3_lock                  = NULL;\n+Mutex*   tty_lock                     = nullptr;\n@@ -106,1 +101,4 @@\n-Mutex*   tty_lock                     = NULL;\n+Mutex*   RawMonitor_lock              = nullptr;\n+Mutex*   PerfDataMemAlloc_lock        = nullptr;\n+Mutex*   PerfDataManager_lock         = nullptr;\n+Mutex*   OopMapCacheAlloc_lock        = nullptr;\n@@ -108,4 +106,4 @@\n-Mutex*   RawMonitor_lock              = NULL;\n-Mutex*   PerfDataMemAlloc_lock        = NULL;\n-Mutex*   PerfDataManager_lock         = NULL;\n-Mutex*   OopMapCacheAlloc_lock        = NULL;\n+Mutex*   FreeList_lock                = nullptr;\n+Mutex*   OldSets_lock                 = nullptr;\n+Mutex*   Uncommit_lock                = nullptr;\n+Monitor* RootRegionScan_lock          = nullptr;\n@@ -113,13 +111,8 @@\n-Mutex*   FreeList_lock                = NULL;\n-Mutex*   OldSets_lock                 = NULL;\n-Mutex*   Uncommit_lock                = NULL;\n-Monitor* RootRegionScan_lock          = NULL;\n-\n-Mutex*   Management_lock              = NULL;\n-Monitor* MonitorDeflation_lock        = NULL;\n-Monitor* Service_lock                 = NULL;\n-Monitor* Notification_lock            = NULL;\n-Monitor* PeriodicTask_lock            = NULL;\n-Monitor* RedefineClasses_lock         = NULL;\n-Mutex*   Verify_lock                  = NULL;\n-Monitor* Zip_lock                     = NULL;\n+Mutex*   Management_lock              = nullptr;\n+Monitor* MonitorDeflation_lock        = nullptr;\n+Monitor* Service_lock                 = nullptr;\n+Monitor* Notification_lock            = nullptr;\n+Monitor* PeriodicTask_lock            = nullptr;\n+Monitor* RedefineClasses_lock         = nullptr;\n+Mutex*   Verify_lock                  = nullptr;\n+Monitor* Zip_lock                     = nullptr;\n@@ -128,5 +121,4 @@\n-Mutex*   JfrStacktrace_lock           = NULL;\n-Monitor* JfrMsg_lock                  = NULL;\n-Mutex*   JfrBuffer_lock               = NULL;\n-Mutex*   JfrStream_lock               = NULL;\n-Monitor* JfrThreadSampler_lock        = NULL;\n+Mutex*   JfrStacktrace_lock           = nullptr;\n+Monitor* JfrMsg_lock                  = nullptr;\n+Mutex*   JfrBuffer_lock               = nullptr;\n+Monitor* JfrThreadSampler_lock        = nullptr;\n@@ -140,12 +132,1 @@\n-Mutex*   UnsafeJlong_lock             = NULL;\n-#endif\n-Mutex*   CodeHeapStateAnalytics_lock  = NULL;\n-\n-Mutex*   Metaspace_lock               = NULL;\n-Mutex*   ClassLoaderDataGraph_lock    = NULL;\n-Monitor* ThreadsSMRDelete_lock        = NULL;\n-Mutex*   ThreadIdTableCreate_lock     = NULL;\n-Mutex*   SharedDecoder_lock           = NULL;\n-Mutex*   DCmdFactory_lock             = NULL;\n-#if INCLUDE_NMT\n-Mutex*   NMTQuery_lock                = NULL;\n+Mutex*   UnsafeJlong_lock             = nullptr;\n@@ -153,0 +134,13 @@\n+Mutex*   CodeHeapStateAnalytics_lock  = nullptr;\n+\n+Monitor* ContinuationRelativize_lock  = nullptr;\n+\n+Mutex*   Metaspace_lock               = nullptr;\n+Monitor* MetaspaceCritical_lock       = nullptr;\n+Mutex*   ClassLoaderDataGraph_lock    = nullptr;\n+Monitor* ThreadsSMRDelete_lock        = nullptr;\n+Mutex*   ThreadIdTableCreate_lock     = nullptr;\n+Mutex*   SharedDecoder_lock           = nullptr;\n+Mutex*   DCmdFactory_lock             = nullptr;\n+Mutex*   NMTQuery_lock                = nullptr;\n+\n@@ -155,1 +149,1 @@\n-Mutex*   CDSClassFileStream_lock      = NULL;\n+Mutex*   CDSClassFileStream_lock      = nullptr;\n@@ -157,5 +151,7 @@\n-Mutex*   DumpTimeTable_lock           = NULL;\n-Mutex*   CDSLambda_lock               = NULL;\n-Mutex*   DumpRegion_lock              = NULL;\n-Mutex*   ClassListFile_lock           = NULL;\n-Mutex*   LambdaFormInvokers_lock      = NULL;\n+Mutex*   DumpTimeTable_lock           = nullptr;\n+Mutex*   CDSLambda_lock               = nullptr;\n+Mutex*   DumpRegion_lock              = nullptr;\n+Mutex*   ClassListFile_lock           = nullptr;\n+Mutex*   UnregisteredClassesTable_lock= nullptr;\n+Mutex*   LambdaFormInvokers_lock      = nullptr;\n+Mutex*   ScratchObjects_lock          = nullptr;\n@@ -163,1 +159,1 @@\n-Mutex*   Bootclasspath_lock           = NULL;\n+Mutex*   Bootclasspath_lock           = nullptr;\n@@ -166,1 +162,2 @@\n-Monitor* JVMCI_lock                   = NULL;\n+Monitor* JVMCI_lock                   = nullptr;\n+Monitor* JVMCIRuntime_lock            = nullptr;\n@@ -176,0 +173,1 @@\n+  if (DebuggingContext::is_enabled() || VMError::is_error_reported()) return;\n@@ -177,1 +175,1 @@\n-  assert(lock != NULL, \"Need non-NULL lock\");\n+  assert(lock != nullptr, \"Need non-null lock\");\n@@ -184,9 +182,0 @@\n-\/\/ a weaker assertion than the above\n-void assert_locked_or_safepoint_weak(const Mutex* lock) {\n-  assert(lock != NULL, \"Need non-NULL lock\");\n-  if (lock->is_locked()) return;\n-  if (SafepointSynchronize::is_at_safepoint()) return;\n-  if (!Universe::is_fully_initialized()) return;\n-  fatal(\"must own lock %s\", lock->name());\n-}\n-\n@@ -195,1 +184,2 @@\n-  assert(lock != NULL, \"Need non-NULL lock\");\n+  if (DebuggingContext::is_enabled() || VMError::is_error_reported()) return;\n+  assert(lock != nullptr, \"Need non-null lock\");\n@@ -199,0 +189,1 @@\n+#endif\n@@ -200,3 +191,3 @@\n-void assert_locked_or_safepoint_or_handshake(const Mutex* lock, const JavaThread* thread) {\n-  if (thread->is_handshake_safe_for(Thread::current())) return;\n-  assert_locked_or_safepoint(lock);\n+static void add_mutex(Mutex* var) {\n+  assert(_num_mutex < MAX_NUM_MUTEX, \"increase MAX_NUM_MUTEX\");\n+  _mutex_array[_num_mutex++] = var;\n@@ -204,5 +195,7 @@\n-#endif\n-#define def(var, type, pri, vm_block, safepoint_check_allowed ) {      \\\n-  var = new type(Mutex::pri, #var, vm_block, Mutex::safepoint_check_allowed); \\\n-  assert(_num_mutex < MAX_NUM_MUTEX, \"increase MAX_NUM_MUTEX\");        \\\n-  _mutex_array[_num_mutex++] = var;                                      \\\n+#define MUTEX_STORAGE_NAME(name) name##_storage\n+#define MUTEX_STORAGE(name, type) alignas(type) static uint8_t MUTEX_STORAGE_NAME(name)[sizeof(type)]\n+#define MUTEX_DEF(name, type, pri, ...) {                                                       \\\n+  assert(name == nullptr, \"Mutex\/Monitor initialized twice\");                                   \\\n+  MUTEX_STORAGE(name, type);                                                                    \\\n+  name = ::new(static_cast<void*>(MUTEX_STORAGE_NAME(name))) type((pri), #name, ##__VA_ARGS__); \\\n+  add_mutex(name);                                                                              \\\n@@ -211,0 +204,8 @@\n+#define MUTEX_DEFN(name, type, pri, ...) MUTEX_DEF(name, type, Mutex::pri, ##__VA_ARGS__)\n+\n+\/\/ Specify relative ranked lock\n+#ifdef ASSERT\n+#define MUTEX_DEFL(name, type, held_lock, ...) MUTEX_DEF(name, type, (held_lock)->rank() - 1, ##__VA_ARGS__)\n+#else\n+#define MUTEX_DEFL(name, type, held_lock, ...) MUTEX_DEFN(name, type, safepoint, ##__VA_ARGS__)\n+#endif\n@@ -214,1 +215,1 @@\n-  def(tty_lock                     , PaddedMutex  , tty,         true,  _safepoint_check_never);      \/\/ allow to lock in VM\n+  MUTEX_DEFN(tty_lock                        , PaddedMutex  , tty);      \/\/ allow to lock in VM\n@@ -216,2 +217,1 @@\n-  def(CGC_lock                     , PaddedMonitor, special,     true,  _safepoint_check_never);      \/\/ coordinate between fore- and background GC\n-  def(STS_lock                     , PaddedMonitor, leaf,        true,  _safepoint_check_never);\n+  MUTEX_DEFN(STS_lock                        , PaddedMonitor, nosafepoint);\n@@ -220,3 +220,1 @@\n-    def(G1OldGCCount_lock          , PaddedMonitor, leaf,        true,  _safepoint_check_always);\n-\n-    def(Shared_DirtyCardQ_lock     , PaddedMutex  , access + 1,  true,  _safepoint_check_never);\n+    MUTEX_DEFN(CGC_lock                      , PaddedMonitor, nosafepoint);\n@@ -224,1 +222,1 @@\n-    def(G1DetachedRefinementStats_lock, PaddedMutex, leaf    ,   true, _safepoint_check_never);\n+    MUTEX_DEFN(G1DetachedRefinementStats_lock, PaddedMutex  , nosafepoint-2);\n@@ -226,4 +224,4 @@\n-    def(FreeList_lock              , PaddedMutex  , leaf     ,   true,  _safepoint_check_never);\n-    def(OldSets_lock               , PaddedMutex  , leaf     ,   true,  _safepoint_check_never);\n-    def(Uncommit_lock              , PaddedMutex  , leaf + 1 ,   true,  _safepoint_check_never);\n-    def(RootRegionScan_lock        , PaddedMonitor, leaf     ,   true,  _safepoint_check_never);\n+    MUTEX_DEFN(FreeList_lock                 , PaddedMutex  , service-1);\n+    MUTEX_DEFN(OldSets_lock                  , PaddedMutex  , nosafepoint);\n+    MUTEX_DEFN(Uncommit_lock                 , PaddedMutex  , service-2);\n+    MUTEX_DEFN(RootRegionScan_lock           , PaddedMonitor, nosafepoint-1);\n@@ -231,2 +229,2 @@\n-    def(MarkStackFreeList_lock     , PaddedMutex  , leaf     ,   true,  _safepoint_check_never);\n-    def(MarkStackChunkList_lock    , PaddedMutex  , leaf     ,   true,  _safepoint_check_never);\n+    MUTEX_DEFN(MarkStackFreeList_lock        , PaddedMutex  , nosafepoint);\n+    MUTEX_DEFN(MarkStackChunkList_lock       , PaddedMutex  , nosafepoint);\n@@ -234,1 +232,1 @@\n-    def(MonitoringSupport_lock     , PaddedMutex  , native   ,   true,  _safepoint_check_never);      \/\/ used for serviceability monitoring support\n+    MUTEX_DEFN(MonitoringSupport_lock        , PaddedMutex  , service-1);      \/\/ used for serviceability monitoring support\n@@ -236,15 +234,10 @@\n-  def(StringDedup_lock             , PaddedMonitor, leaf,        true,  _safepoint_check_never);\n-  def(StringDedupIntern_lock       , PaddedMutex  , leaf,        true,  _safepoint_check_never);\n-  def(ParGCRareEvent_lock          , PaddedMutex  , leaf,        true,  _safepoint_check_always);\n-  def(CodeCache_lock               , PaddedMonitor, special,     true,  _safepoint_check_never);\n-  def(CodeSweeper_lock             , PaddedMonitor, special-2,   true,  _safepoint_check_never);\n-  def(RawMonitor_lock              , PaddedMutex  , special,     true,  _safepoint_check_never);\n-  def(OopMapCacheAlloc_lock        , PaddedMutex  , leaf,        true,  _safepoint_check_always); \/\/ used for oop_map_cache allocation.\n-\n-  def(Metaspace_lock               , PaddedMutex  , leaf-1,      true,  _safepoint_check_never);\n-  def(ClassLoaderDataGraph_lock    , PaddedMutex  , nonleaf,     false, _safepoint_check_always);\n-\n-  def(Patching_lock                , PaddedMutex  , special,     true,  _safepoint_check_never);      \/\/ used for safepointing and code patching.\n-  def(CompiledMethod_lock          , PaddedMutex  , special-1,   true,  _safepoint_check_never);\n-  def(MonitorDeflation_lock        , PaddedMonitor, tty-2,       true,  _safepoint_check_never);      \/\/ used for monitor deflation thread operations\n-  def(Service_lock                 , PaddedMonitor, tty-2,       true,  _safepoint_check_never);      \/\/ used for service thread operations\n+  MUTEX_DEFN(StringDedup_lock                , PaddedMonitor, nosafepoint);\n+  MUTEX_DEFN(StringDedupIntern_lock          , PaddedMutex  , nosafepoint);\n+  MUTEX_DEFN(RawMonitor_lock                 , PaddedMutex  , nosafepoint-1);\n+\n+  MUTEX_DEFN(Metaspace_lock                  , PaddedMutex  , nosafepoint-3);\n+  MUTEX_DEFN(MetaspaceCritical_lock          , PaddedMonitor, nosafepoint-1);\n+\n+  MUTEX_DEFN(Patching_lock                   , PaddedMutex  , nosafepoint);      \/\/ used for safepointing and code patching.\n+  MUTEX_DEFN(MonitorDeflation_lock           , PaddedMonitor, nosafepoint);      \/\/ used for monitor deflation thread operations\n+  MUTEX_DEFN(Service_lock                    , PaddedMonitor, service);      \/\/ used for service thread operations\n@@ -253,1 +246,1 @@\n-    def(Notification_lock            , PaddedMonitor, special,     true,  _safepoint_check_never);  \/\/ used for notification thread operations\n+    MUTEX_DEFN(Notification_lock             , PaddedMonitor, service);  \/\/ used for notification thread operations\n@@ -258,14 +251,9 @@\n-  def(JmethodIdCreation_lock       , PaddedMutex  , special-2,   true,  _safepoint_check_never); \/\/ used for creating jmethodIDs.\n-\n-  def(SystemDictionary_lock        , PaddedMonitor, leaf,        true,  _safepoint_check_always);\n-  def(SharedDictionary_lock        , PaddedMutex  , leaf,        true,  _safepoint_check_always);\n-  def(Module_lock                  , PaddedMutex  , leaf+2,      false, _safepoint_check_always);\n-  def(InlineCacheBuffer_lock       , PaddedMutex  , leaf,        true,  _safepoint_check_never);\n-  def(VMStatistic_lock             , PaddedMutex  , leaf,        false, _safepoint_check_always);\n-  def(ExpandHeap_lock              , PaddedMutex  , leaf,        true,  _safepoint_check_always); \/\/ Used during compilation by VM thread\n-  def(JNIHandleBlockFreeList_lock  , PaddedMutex  , leaf-1,      true,  _safepoint_check_never);      \/\/ handles are used by VM thread\n-  def(SignatureHandlerLibrary_lock , PaddedMutex  , leaf,        false, _safepoint_check_always);\n-  def(SymbolArena_lock             , PaddedMutex  , leaf+2,      true,  _safepoint_check_never);\n-  def(ProfilePrint_lock            , PaddedMutex  , leaf,        false, _safepoint_check_always); \/\/ serial profile printing\n-  def(ExceptionCache_lock          , PaddedMutex  , leaf,        false, _safepoint_check_always); \/\/ serial profile printing\n-  def(Debug1_lock                  , PaddedMutex  , leaf,        true,  _safepoint_check_never);\n+  MUTEX_DEFN(JmethodIdCreation_lock          , PaddedMutex  , nosafepoint-2); \/\/ used for creating jmethodIDs.\n+  MUTEX_DEFN(InvokeMethodTypeTable_lock      , PaddedMutex  , safepoint);\n+  MUTEX_DEFN(InvokeMethodIntrinsicTable_lock , PaddedMonitor, safepoint);\n+  MUTEX_DEFN(AdapterHandlerLibrary_lock      , PaddedMutex  , safepoint);\n+  MUTEX_DEFN(SharedDictionary_lock           , PaddedMutex  , safepoint);\n+  MUTEX_DEFN(VMStatistic_lock                , PaddedMutex  , safepoint);\n+  MUTEX_DEFN(SignatureHandlerLibrary_lock    , PaddedMutex  , safepoint);\n+  MUTEX_DEFN(SymbolArena_lock                , PaddedMutex  , nosafepoint);\n+  MUTEX_DEFN(ExceptionCache_lock             , PaddedMutex  , safepoint);\n@@ -273,1 +261,1 @@\n-  def(FullGCALot_lock              , PaddedMutex  , leaf,        false, _safepoint_check_always); \/\/ a lock to make FullGCALot MT safe\n+  MUTEX_DEFN(FullGCALot_lock                 , PaddedMutex  , safepoint); \/\/ a lock to make FullGCALot MT safe\n@@ -275,43 +263,30 @@\n-  def(BeforeExit_lock              , PaddedMonitor, leaf,        true,  _safepoint_check_always);\n-  def(PerfDataMemAlloc_lock        , PaddedMutex  , leaf,        true,  _safepoint_check_always); \/\/ used for allocating PerfData memory for performance data\n-  def(PerfDataManager_lock         , PaddedMutex  , leaf,        true,  _safepoint_check_always); \/\/ used for synchronized access to PerfDataManager resources\n-\n-  def(Threads_lock                 , PaddedMonitor, barrier,     true,  _safepoint_check_always);  \/\/ Used for safepoint protocol.\n-  def(NonJavaThreadsList_lock      , PaddedMutex,   barrier,     true,  _safepoint_check_never);\n-  def(NonJavaThreadsListSync_lock  , PaddedMutex,   leaf,        true,  _safepoint_check_never);\n-\n-  def(VMOperation_lock             , PaddedMonitor, nonleaf,     true,  _safepoint_check_always);  \/\/ VM_thread allowed to block on these\n-  def(RetData_lock                 , PaddedMutex  , nonleaf,     false, _safepoint_check_always);\n-  def(Terminator_lock              , PaddedMonitor, nonleaf,     true,  _safepoint_check_always);\n-  def(InitCompleted_lock           , PaddedMonitor, leaf,        true,  _safepoint_check_never);\n-  def(VtableStubs_lock             , PaddedMutex  , nonleaf,     true,  _safepoint_check_never);\n-  def(Notify_lock                  , PaddedMonitor, nonleaf,     true,  _safepoint_check_always);\n-  def(JNICritical_lock             , PaddedMonitor, nonleaf,     true,  _safepoint_check_always); \/\/ used for JNI critical regions\n-  def(AdapterHandlerLibrary_lock   , PaddedMutex  , nonleaf,     true,  _safepoint_check_always);\n-\n-  def(Heap_lock                    , PaddedMonitor, nonleaf+1,   false, _safepoint_check_always); \/\/ Doesn't safepoint check during termination.\n-  def(JfieldIdCreation_lock        , PaddedMutex  , nonleaf+1,   true,  _safepoint_check_always); \/\/ jfieldID, Used in VM_Operation\n-\n-  def(CompiledIC_lock              , PaddedMutex  , nonleaf+2,   false, _safepoint_check_never);      \/\/ locks VtableStubs_lock, InlineCacheBuffer_lock\n-  def(CompileTaskAlloc_lock        , PaddedMutex  , nonleaf+2,   true,  _safepoint_check_always);\n-  def(CompileStatistics_lock       , PaddedMutex  , nonleaf+2,   false, _safepoint_check_always);\n-  def(DirectivesStack_lock         , PaddedMutex  , special,     true,  _safepoint_check_never);\n-  def(MultiArray_lock              , PaddedMutex  , nonleaf+2,   false, _safepoint_check_always);\n-\n-  def(JvmtiThreadState_lock        , PaddedMutex  , nonleaf+2,   false, _safepoint_check_always); \/\/ Used by JvmtiThreadState\/JvmtiEventController\n-  def(EscapeBarrier_lock           , PaddedMonitor, leaf,        false, _safepoint_check_never);  \/\/ Used to synchronize object reallocation\/relocking triggered by JVMTI\n-  def(Management_lock              , PaddedMutex  , nonleaf+2,   false, _safepoint_check_always); \/\/ used for JVM management\n-\n-  def(ConcurrentGCBreakpoints_lock , PaddedMonitor, nonleaf,     true,  _safepoint_check_always);\n-  def(Compile_lock                 , PaddedMutex  , nonleaf+3,   false, _safepoint_check_always);\n-  def(MethodData_lock              , PaddedMutex  , nonleaf+3,   false, _safepoint_check_always);\n-  def(TouchedMethodLog_lock        , PaddedMutex  , nonleaf+3,   false, _safepoint_check_always);\n-\n-  def(MethodCompileQueue_lock      , PaddedMonitor, nonleaf+4,   false, _safepoint_check_always);\n-  def(Debug2_lock                  , PaddedMutex  , nonleaf+4,   true,  _safepoint_check_never);\n-  def(Debug3_lock                  , PaddedMutex  , nonleaf+4,   true,  _safepoint_check_never);\n-  def(CompileThread_lock           , PaddedMonitor, nonleaf+5,   false, _safepoint_check_always);\n-  def(PeriodicTask_lock            , PaddedMonitor, nonleaf+5,   true,  _safepoint_check_always);\n-  def(RedefineClasses_lock         , PaddedMonitor, nonleaf+5,   true,  _safepoint_check_always);\n-  def(Verify_lock                  , PaddedMutex,   nonleaf+5,   true,  _safepoint_check_always);\n-  def(Zip_lock                     , PaddedMonitor, leaf,        true,  _safepoint_check_never);\n+  MUTEX_DEFN(BeforeExit_lock                 , PaddedMonitor, safepoint);\n+\n+  MUTEX_DEFN(NonJavaThreadsList_lock         , PaddedMutex  , nosafepoint-1);\n+  MUTEX_DEFN(NonJavaThreadsListSync_lock     , PaddedMutex  , nosafepoint);\n+\n+  MUTEX_DEFN(RetData_lock                    , PaddedMutex  , safepoint);\n+  MUTEX_DEFN(Terminator_lock                 , PaddedMonitor, safepoint, true);\n+  MUTEX_DEFN(InitCompleted_lock              , PaddedMonitor, nosafepoint);\n+  MUTEX_DEFN(Notify_lock                     , PaddedMonitor, safepoint, true);\n+\n+  MUTEX_DEFN(JfieldIdCreation_lock           , PaddedMutex  , safepoint);\n+\n+  MUTEX_DEFN(CompiledIC_lock                 , PaddedMutex  , nosafepoint);  \/\/ locks VtableStubs_lock, InlineCacheBuffer_lock\n+  MUTEX_DEFN(MethodCompileQueue_lock         , PaddedMonitor, safepoint);\n+  MUTEX_DEFN(CompileStatistics_lock          , PaddedMutex  , safepoint);\n+  MUTEX_DEFN(DirectivesStack_lock            , PaddedMutex  , nosafepoint);\n+  MUTEX_DEFN(MultiArray_lock                 , PaddedMutex  , safepoint);\n+\n+  MUTEX_DEFN(JvmtiThreadState_lock           , PaddedMutex  , safepoint);   \/\/ Used by JvmtiThreadState\/JvmtiEventController\n+  MUTEX_DEFN(EscapeBarrier_lock              , PaddedMonitor, nosafepoint); \/\/ Used to synchronize object reallocation\/relocking triggered by JVMTI\n+  MUTEX_DEFN(JvmtiVTMSTransition_lock        , PaddedMonitor, safepoint);   \/\/ used for Virtual Thread Mount State transition management\n+  MUTEX_DEFN(Management_lock                 , PaddedMutex  , safepoint);   \/\/ used for JVM management\n+\n+  MUTEX_DEFN(ConcurrentGCBreakpoints_lock    , PaddedMonitor, safepoint, true);\n+  MUTEX_DEFN(TouchedMethodLog_lock           , PaddedMutex  , safepoint);\n+\n+  MUTEX_DEFN(CompileThread_lock              , PaddedMonitor, safepoint);\n+  MUTEX_DEFN(PeriodicTask_lock               , PaddedMonitor, safepoint, true);\n+  MUTEX_DEFN(RedefineClasses_lock            , PaddedMonitor, safepoint);\n+  MUTEX_DEFN(Verify_lock                     , PaddedMutex  , safepoint);\n@@ -320,1 +295,1 @@\n-    def(Compilation_lock           , PaddedMonitor, leaf,        false, _safepoint_check_never);\n+    MUTEX_DEFN(Compilation_lock              , PaddedMonitor, nosafepoint);\n@@ -324,5 +299,4 @@\n-  def(JfrMsg_lock                  , PaddedMonitor, leaf,        true,  _safepoint_check_always);\n-  def(JfrBuffer_lock               , PaddedMutex  , leaf,        true,  _safepoint_check_never);\n-  def(JfrStream_lock               , PaddedMutex  , nonleaf + 1, false, _safepoint_check_never);\n-  def(JfrStacktrace_lock           , PaddedMutex  , tty-2,       true,  _safepoint_check_never);\n-  def(JfrThreadSampler_lock        , PaddedMonitor, leaf,        true,  _safepoint_check_never);\n+  MUTEX_DEFN(JfrBuffer_lock                  , PaddedMutex  , nosafepoint);\n+  MUTEX_DEFN(JfrMsg_lock                     , PaddedMonitor, nosafepoint-3);\n+  MUTEX_DEFN(JfrStacktrace_lock              , PaddedMutex  , stackwatermark-1);\n+  MUTEX_DEFN(JfrThreadSampler_lock           , PaddedMonitor, nosafepoint);\n@@ -332,1 +306,1 @@\n-    def(TsanOopMap_lock            , PaddedMutex  , special,     true,  _safepoint_check_never);\n+    MUTEX_DEFN(TsanOopMap_lock               , PaddedMutex  , nosafepoint);\n@@ -336,1 +310,1 @@\n-  def(UnsafeJlong_lock             , PaddedMutex  , special,     false, _safepoint_check_never);\n+  MUTEX_DEFN(UnsafeJlong_lock                , PaddedMutex  , nosafepoint);\n@@ -339,9 +313,7 @@\n-  def(CodeHeapStateAnalytics_lock  , PaddedMutex  , nonleaf+6,   false, _safepoint_check_always);\n-  def(NMethodSweeperStats_lock     , PaddedMutex  , special,     true,  _safepoint_check_never);\n-  def(ThreadsSMRDelete_lock        , PaddedMonitor, special,     true,  _safepoint_check_never);\n-  def(ThreadIdTableCreate_lock     , PaddedMutex  , leaf,        false, _safepoint_check_always);\n-  def(SharedDecoder_lock           , PaddedMutex  , native,      true,  _safepoint_check_never);\n-  def(DCmdFactory_lock             , PaddedMutex  , leaf,        true,  _safepoint_check_never);\n-#if INCLUDE_NMT\n-  def(NMTQuery_lock                , PaddedMutex  , max_nonleaf, false, _safepoint_check_always);\n-#endif\n+  MUTEX_DEFN(ContinuationRelativize_lock     , PaddedMonitor, nosafepoint-3);\n+  MUTEX_DEFN(CodeHeapStateAnalytics_lock     , PaddedMutex  , safepoint);\n+  MUTEX_DEFN(ThreadsSMRDelete_lock           , PaddedMonitor, nosafepoint-3); \/\/ Holds ConcurrentHashTableResize_lock\n+  MUTEX_DEFN(ThreadIdTableCreate_lock        , PaddedMutex  , safepoint);\n+  MUTEX_DEFN(SharedDecoder_lock              , PaddedMutex  , tty-1);\n+  MUTEX_DEFN(DCmdFactory_lock                , PaddedMutex  , nosafepoint);\n+  MUTEX_DEFN(NMTQuery_lock                   , PaddedMutex  , safepoint);\n@@ -350,1 +322,1 @@\n-  def(CDSClassFileStream_lock      , PaddedMutex  , max_nonleaf, false, _safepoint_check_always);\n+  MUTEX_DEFN(CDSClassFileStream_lock         , PaddedMutex  , safepoint);\n@@ -352,5 +324,7 @@\n-  def(DumpTimeTable_lock           , PaddedMutex  , leaf - 1,    true,  _safepoint_check_never);\n-  def(CDSLambda_lock               , PaddedMutex  , leaf,        true,  _safepoint_check_never);\n-  def(DumpRegion_lock              , PaddedMutex  , leaf,        true,  _safepoint_check_never);\n-  def(ClassListFile_lock           , PaddedMutex  , leaf,        true,  _safepoint_check_never);\n-  def(LambdaFormInvokers_lock      , PaddedMutex  , nonleaf+2,   false, _safepoint_check_always);\n+  MUTEX_DEFN(DumpTimeTable_lock              , PaddedMutex  , nosafepoint);\n+  MUTEX_DEFN(CDSLambda_lock                  , PaddedMutex  , nosafepoint);\n+  MUTEX_DEFN(DumpRegion_lock                 , PaddedMutex  , nosafepoint);\n+  MUTEX_DEFN(ClassListFile_lock              , PaddedMutex  , nosafepoint);\n+  MUTEX_DEFN(UnregisteredClassesTable_lock   , PaddedMutex  , nosafepoint-1);\n+  MUTEX_DEFN(LambdaFormInvokers_lock         , PaddedMutex  , safepoint);\n+  MUTEX_DEFN(ScratchObjects_lock             , PaddedMutex  , nosafepoint-1); \/\/ Holds DumpTimeTable_lock\n@@ -358,1 +332,2 @@\n-  def(Bootclasspath_lock           , PaddedMutex  , leaf,        false, _safepoint_check_never);\n+  MUTEX_DEFN(Bootclasspath_lock              , PaddedMutex  , nosafepoint);\n+  MUTEX_DEFN(Zip_lock                        , PaddedMonitor, nosafepoint-1); \/\/ Holds DumpTimeTable_lock\n@@ -361,1 +336,2 @@\n-  def(JVMCI_lock                   , PaddedMonitor, nonleaf+2,   true,  _safepoint_check_always);\n+  \/\/ JVMCIRuntime::_lock must be acquired before JVMCI_lock to avoid deadlock\n+  MUTEX_DEFN(JVMCIRuntime_lock               , PaddedMonitor, safepoint, true);\n@@ -363,0 +339,52 @@\n+\n+  \/\/ These locks have relative rankings, and inherit safepoint checking attributes from that rank.\n+  MUTEX_DEFL(InlineCacheBuffer_lock         , PaddedMutex  , CompiledIC_lock);\n+  MUTEX_DEFL(VtableStubs_lock               , PaddedMutex  , CompiledIC_lock);  \/\/ Also holds DumpTimeTable_lock\n+  MUTEX_DEFL(CodeCache_lock                 , PaddedMonitor, VtableStubs_lock);\n+  MUTEX_DEFL(CompiledMethod_lock            , PaddedMutex  , CodeCache_lock);\n+\n+  MUTEX_DEFL(Threads_lock                   , PaddedMonitor, CompileThread_lock, true);\n+  MUTEX_DEFL(Compile_lock                   , PaddedMutex  , MethodCompileQueue_lock);\n+  MUTEX_DEFL(Heap_lock                      , PaddedMonitor, AdapterHandlerLibrary_lock);\n+\n+  MUTEX_DEFL(PerfDataMemAlloc_lock          , PaddedMutex  , Heap_lock);\n+  MUTEX_DEFL(PerfDataManager_lock           , PaddedMutex  , Heap_lock);\n+  MUTEX_DEFL(ClassLoaderDataGraph_lock      , PaddedMutex  , MultiArray_lock);\n+  MUTEX_DEFL(VMOperation_lock               , PaddedMonitor, Heap_lock, true);\n+  MUTEX_DEFL(ClassInitError_lock            , PaddedMonitor, Threads_lock);\n+\n+  if (UseG1GC) {\n+    MUTEX_DEFL(G1OldGCCount_lock            , PaddedMonitor, Threads_lock, true);\n+    MUTEX_DEFL(G1RareEvent_lock             , PaddedMutex  , Threads_lock, true);\n+  }\n+\n+  MUTEX_DEFL(CompileTaskAlloc_lock          , PaddedMutex  ,  MethodCompileQueue_lock);\n+#ifdef INCLUDE_PARALLELGC\n+  if (UseParallelGC) {\n+    MUTEX_DEFL(PSOldGenExpand_lock          , PaddedMutex  , Heap_lock, true);\n+  }\n+#endif\n+  MUTEX_DEFL(OopMapCacheAlloc_lock          , PaddedMutex  ,  Threads_lock, true);\n+  MUTEX_DEFL(Module_lock                    , PaddedMutex  ,  ClassLoaderDataGraph_lock);\n+  MUTEX_DEFL(SystemDictionary_lock          , PaddedMonitor, Module_lock);\n+  MUTEX_DEFL(JNICritical_lock               , PaddedMonitor, AdapterHandlerLibrary_lock); \/\/ used for JNI critical regions\n+#if INCLUDE_JVMCI\n+  \/\/ JVMCIRuntime_lock must be acquired before JVMCI_lock to avoid deadlock\n+  MUTEX_DEFL(JVMCI_lock                     , PaddedMonitor, JVMCIRuntime_lock);\n+#endif\n+}\n+\n+#undef MUTEX_DEFL\n+#undef MUTEX_DEFN\n+#undef MUTEX_DEF\n+#undef MUTEX_STORAGE\n+#undef MUTEX_STORAGE_NAME\n+\n+void MutexLocker::post_initialize() {\n+  \/\/ Print mutex ranks if requested.\n+  LogTarget(Info, vmmutex) lt;\n+  if (lt.is_enabled()) {\n+    ResourceMark rm;\n+    LogStream ls(lt);\n+    print_lock_ranks(&ls);\n+  }\n@@ -382,1 +410,1 @@\n-     if (_mutex_array[i]->owner() != NULL) {\n+     if (_mutex_array[i]->owner() != nullptr) {\n@@ -394,0 +422,36 @@\n+\n+void print_lock_ranks(outputStream* st) {\n+  st->print_cr(\"VM Mutex\/Monitor ranks: \");\n+\n+#ifdef ASSERT\n+  \/\/ Be extra defensive and figure out the bounds on\n+  \/\/ ranks right here. This also saves a bit of time\n+  \/\/ in the #ranks*#mutexes loop below.\n+  int min_rank = INT_MAX;\n+  int max_rank = INT_MIN;\n+  for (int i = 0; i < _num_mutex; i++) {\n+    Mutex* m = _mutex_array[i];\n+    int r = (int) m->rank();\n+    if (min_rank > r) min_rank = r;\n+    if (max_rank < r) max_rank = r;\n+  }\n+\n+  \/\/ Print the listings rank by rank\n+  for (int r = min_rank; r <= max_rank; r++) {\n+    bool first = true;\n+    for (int i = 0; i < _num_mutex; i++) {\n+      Mutex* m = _mutex_array[i];\n+      if (r != (int) m->rank()) continue;\n+\n+      if (first) {\n+        st->cr();\n+        st->print_cr(\"Rank \\\"%s\\\":\", m->rank_name());\n+        first = false;\n+      }\n+      st->print_cr(\"  %s\", m->name());\n+    }\n+  }\n+#else\n+  st->print_cr(\"  Only known in debug builds.\");\n+#endif \/\/ ASSERT\n+}\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.cpp","additions":310,"deletions":246,"binary":false,"changes":556,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -37,0 +37,2 @@\n+extern Mutex*   InvokeMethodTypeTable_lock;\n+extern Monitor* InvokeMethodIntrinsicTable_lock;\n@@ -38,0 +40,1 @@\n+extern Monitor* ClassInitError_lock;             \/\/ a lock on the class initialization error table\n@@ -42,1 +45,0 @@\n-extern Mutex*   JNIHandleBlockFreeList_lock;     \/\/ a lock on the JNI handle block free list\n@@ -48,0 +50,1 @@\n+extern Monitor* JvmtiVTMSTransition_lock;        \/\/ a lock for Virtual Thread Mount State transition (VTMS transition) management\n@@ -49,1 +52,3 @@\n-extern Mutex*   ExpandHeap_lock;                 \/\/ a lock on expanding the heap\n+#ifdef INCLUDE_PARALLELGC\n+extern Mutex*   PSOldGenExpand_lock;         \/\/ a lock on expanding the heap\n+#endif\n@@ -56,3 +61,1 @@\n-extern Monitor* CodeCache_lock;                  \/\/ a lock on the CodeCache, rank is special\n-extern Monitor* CodeSweeper_lock;                \/\/ a lock used by the sweeper only for wait notify\n-extern Mutex*   MethodData_lock;                 \/\/ a lock on installation of method data\n+extern Monitor* CodeCache_lock;                  \/\/ a lock on the CodeCache\n@@ -70,3 +73,1 @@\n-extern Mutex*   Shared_DirtyCardQ_lock;          \/\/ Lock protecting dirty card\n-                                                 \/\/ queue shared by\n-                                                 \/\/ non-Java threads.\n+extern Mutex*   G1RareEvent_lock;                \/\/ Synchronizes (rare) parallel GC operations.\n@@ -76,2 +77,1 @@\n-extern Mutex*   MonitoringSupport_lock;          \/\/ Protects updates to the serviceability memory pools.\n-extern Mutex*   ParGCRareEvent_lock;             \/\/ Synchronizes various (rare) parallel GC ops.\n+extern Mutex*   MonitoringSupport_lock;          \/\/ Protects updates to the serviceability memory pools and allocated memory high water mark.\n@@ -91,2 +91,0 @@\n-extern Mutex*   ProfilePrint_lock;               \/\/ a lock used to serialize the printing of profiles\n-extern Mutex*   NMethodSweeperStats_lock;        \/\/ a lock used to serialize access to sweeper statistics\n@@ -98,3 +96,0 @@\n-extern Mutex*   Debug1_lock;                     \/\/ A bunch of pre-allocated locks that can be used for tracing\n-extern Mutex*   Debug2_lock;                     \/\/ down synchronization related bugs!\n-extern Mutex*   Debug3_lock;\n@@ -124,2 +119,0 @@\n-#if INCLUDE_NMT\n-#endif\n@@ -131,1 +124,1 @@\n-extern Mutex*   DumpTimeTable_lock;              \/\/ SystemDictionaryShared::find_or_allocate_info_for\n+extern Mutex*   DumpTimeTable_lock;              \/\/ SystemDictionaryShared::_dumptime_table\n@@ -135,0 +128,1 @@\n+extern Mutex*   UnregisteredClassesTable_lock;   \/\/ UnregisteredClassesTableTable\n@@ -136,0 +130,1 @@\n+extern Mutex*   ScratchObjects_lock;             \/\/ Protecting _scratch_xxx_table in heapShared.cpp\n@@ -141,1 +136,0 @@\n-extern Mutex*   JfrStream_lock;                  \/\/ protects JFR stream access\n@@ -152,1 +146,2 @@\n-extern Mutex*   Metaspace_lock;            \/\/ protects Metaspace virtualspace and chunk expansions\n+extern Mutex*   Metaspace_lock;                  \/\/ protects Metaspace virtualspace and chunk expansions\n+extern Monitor* MetaspaceCritical_lock;          \/\/ synchronizes failed metaspace allocations that risk throwing metaspace OOM\n@@ -159,0 +154,2 @@\n+extern Monitor* ContinuationRelativize_lock;\n+\n@@ -160,1 +157,2 @@\n-extern Monitor* JVMCI_lock;                      \/\/ Monitor to control initialization of JVMCI\n+extern Monitor* JVMCI_lock;                      \/\/ protects global JVMCI critical sections\n+extern Monitor* JVMCIRuntime_lock;               \/\/ protects critical sections for a specific JVMCIRuntime object\n@@ -165,1 +163,1 @@\n-extern Mutex* tty_lock;                          \/\/ lock to synchronize output.\n+extern Mutex*   tty_lock;                          \/\/ lock to synchronize output.\n@@ -184,2 +182,1 @@\n-\n-char *lock_name(Mutex *mutex);\n+void print_lock_ranks(outputStream* st);\n@@ -190,2 +187,0 @@\n-void assert_locked_or_safepoint_weak(const Mutex* lock);\n-void assert_locked_or_safepoint_or_handshake(const Mutex* lock, const JavaThread* thread);\n@@ -195,2 +190,0 @@\n-#define assert_locked_or_safepoint_weak(lock)\n-#define assert_locked_or_safepoint_or_handshake(lock, thread)\n@@ -207,3 +200,1 @@\n-    if (_mutex != NULL) {\n-      assert(_mutex->rank() > Mutex::special || no_safepoint_check,\n-             \"Mutexes with rank special or lower should not do safepoint checks\");\n+    if (_mutex != nullptr) {\n@@ -221,3 +212,1 @@\n-    if (_mutex != NULL) {\n-      assert(_mutex->rank() > Mutex::special || no_safepoint_check,\n-             \"Mutexes with rank special or lower should not do safepoint checks\");\n+    if (_mutex != nullptr) {\n@@ -233,1 +222,1 @@\n-    if (_mutex != NULL) {\n+    if (_mutex != nullptr) {\n@@ -238,0 +227,2 @@\n+\n+  static void post_initialize();\n@@ -242,1 +233,1 @@\n-\/\/ It also disallows NULL.\n+\/\/ It also disallows null.\n@@ -256,1 +247,1 @@\n-    assert(monitor != NULL, \"NULL monitor not allowed\");\n+    assert(monitor != nullptr, \"null monitor not allowed\");\n@@ -262,1 +253,1 @@\n-    assert(monitor != NULL, \"NULL monitor not allowed\");\n+    assert(monitor != nullptr, \"null monitor not allowed\");\n@@ -266,6 +257,2 @@\n-    if (_flag == Mutex::_safepoint_check_flag) {\n-      return as_monitor()->wait(timeout);\n-    } else {\n-      return as_monitor()->wait_without_safepoint_check(timeout);\n-    }\n-    return false;\n+    return _flag == Mutex::_safepoint_check_flag ?\n+      as_monitor()->wait(timeout) : as_monitor()->wait_without_safepoint_check(timeout);\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.hpp","additions":32,"deletions":45,"binary":false,"changes":77,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,2 +26,1 @@\n-#include \"classfile\/javaClasses.hpp\"\n-#include \"jvm.h\"\n+#include \"classfile\/javaClasses.inline.hpp\"\n@@ -45,0 +44,1 @@\n+#include \"jvm.h\"\n@@ -49,0 +49,1 @@\n+#include \"metaprogramming\/primitiveConversions.hpp\"\n@@ -56,0 +57,1 @@\n+#include \"prims\/jvmtiThreadState.hpp\"\n@@ -59,1 +61,0 @@\n-#include \"runtime\/biasedLocking.hpp\"\n@@ -66,0 +67,1 @@\n+#include \"runtime\/jniHandles.inline.hpp\"\n@@ -76,1 +78,1 @@\n-#include \"utilities\/hashtable.inline.hpp\"\n+#include \"utilities\/resourceHash.hpp\"\n@@ -105,0 +107,1 @@\n+nmethod*            SharedRuntime::_cont_doYield_stub;\n@@ -148,1 +151,0 @@\n-int SharedRuntime::_throw_null_ctr = 0;\n@@ -151,1 +153,0 @@\n-int64_t SharedRuntime::_nof_optimized_calls = 0;\n@@ -157,2 +158,0 @@\n-int64_t SharedRuntime::_nof_optimized_interface_calls = 0;\n-int64_t SharedRuntime::_nof_megamorphic_interface_calls = 0;\n@@ -163,1 +162,0 @@\n-int SharedRuntime::_multi1_ctr=0;\n@@ -240,0 +238,1 @@\n+#ifdef _WIN64\n@@ -244,0 +243,1 @@\n+#endif\n@@ -245,1 +245,2 @@\n-JRT_LEAF(jfloat, SharedRuntime::frem(jfloat  x, jfloat  y))\n+#if !defined(X86) || !defined(TARGET_COMPILER_gcc) || defined(_WIN64)\n+JRT_LEAF(jfloat, SharedRuntime::frem(jfloat x, jfloat y))\n@@ -249,3 +250,2 @@\n-  union { jfloat f; juint i; } xbits, ybits;\n-  xbits.f = x;\n-  ybits.f = y;\n+  juint xbits = PrimitiveConversions::cast<juint>(x);\n+  juint ybits = PrimitiveConversions::cast<juint>(y);\n@@ -253,2 +253,2 @@\n-  if (((xbits.i & float_sign_mask) != float_infinity) &&\n-       ((ybits.i & float_sign_mask) == float_infinity) ) {\n+  if (((xbits & float_sign_mask) != float_infinity) &&\n+       ((ybits & float_sign_mask) == float_infinity) ) {\n@@ -263,1 +263,0 @@\n-\n@@ -266,3 +265,2 @@\n-  union { jdouble d; julong l; } xbits, ybits;\n-  xbits.d = x;\n-  ybits.d = y;\n+  julong xbits = PrimitiveConversions::cast<julong>(x);\n+  julong ybits = PrimitiveConversions::cast<julong>(y);\n@@ -270,2 +268,2 @@\n-  if (((xbits.l & double_sign_mask) != double_infinity) &&\n-       ((ybits.l & double_sign_mask) == double_infinity) ) {\n+  if (((xbits & double_sign_mask) != double_infinity) &&\n+       ((ybits & double_sign_mask) == double_infinity) ) {\n@@ -279,0 +277,5 @@\n+#endif \/\/ !X86 || !TARGET_COMPILER_gcc || _WIN64\n+\n+JRT_LEAF(jfloat, SharedRuntime::i2f(jint x))\n+  return (jfloat)x;\n+JRT_END\n@@ -313,4 +316,0 @@\n-JRT_LEAF(jfloat, SharedRuntime::i2f(jint x))\n-  return (jfloat)x;\n-JRT_END\n-\n@@ -457,0 +456,1 @@\n+\n@@ -479,1 +479,1 @@\n-  current->set_exception_pc(NULL);\n+  current->set_exception_pc(nullptr);\n@@ -482,0 +482,7 @@\n+  if (Continuation::is_return_barrier_entry(return_address)) {\n+    return StubRoutines::cont_returnBarrierExc();\n+  }\n+\n+  \/\/ write lock needed because we might update the pc desc cache via PcDescCache::add_pc_desc\n+  MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXWrite, current));\n+\n@@ -484,2 +491,2 @@\n-  CompiledMethod* nm = (blob != NULL) ? blob->as_compiled_method_or_null() : NULL;\n-  if (nm != NULL) {\n+  CompiledMethod* nm = (blob != nullptr) ? blob->as_compiled_method_or_null() : nullptr;\n+  if (nm != nullptr) {\n@@ -489,1 +496,1 @@\n-    assert(!nm->is_native_method(), \"no exception handler\");\n+    assert(!nm->is_native_method() || nm->method()->is_continuation_enter_intrinsic(), \"no exception handler\");\n@@ -507,1 +514,1 @@\n-      \/\/ * OptoRuntime::rethrow_C for C2 code\n+      \/\/ * OptoRuntime::handle_exception_C_helper for C2 code\n@@ -519,2 +526,2 @@\n-  if (blob != NULL && blob->is_optimized_entry_blob()) {\n-    return ((OptimizedEntryBlob*)blob)->exception_handler();\n+  if (blob != nullptr && blob->is_upcall_stub()) {\n+    return ((UpcallStub*)blob)->exception_handler();\n@@ -529,2 +536,2 @@\n-  guarantee(blob == NULL || !blob->is_runtime_stub(), \"caller should have skipped stub\");\n-  guarantee(!VtableStubs::contains(return_address), \"NULL exceptions in vtables should have been handled already!\");\n+  guarantee(blob == nullptr || !blob->is_runtime_stub(), \"caller should have skipped stub\");\n+  guarantee(!VtableStubs::contains(return_address), \"null exceptions in vtables should have been handled already!\");\n@@ -535,0 +542,1 @@\n+    os::print_location(tty, (intptr_t)return_address);\n@@ -541,1 +549,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -556,1 +564,1 @@\n-  guarantee(cb != NULL && cb->is_compiled(), \"safepoint polling: pc must refer to an nmethod\");\n+  guarantee(cb != nullptr && cb->is_compiled(), \"safepoint polling: pc must refer to an nmethod\");\n@@ -560,1 +568,1 @@\n-    \"safepoint polling: type must be poll\");\n+      \"safepoint polling: type must be poll at pc \" INTPTR_FORMAT, p2i(pc));\n@@ -573,1 +581,1 @@\n-    assert(SharedRuntime::polling_page_return_handler_blob() != NULL,\n+    assert(SharedRuntime::polling_page_return_handler_blob() != nullptr,\n@@ -577,1 +585,1 @@\n-    assert(SharedRuntime::polling_page_vectors_safepoint_handler_blob() != NULL,\n+    assert(SharedRuntime::polling_page_vectors_safepoint_handler_blob() != nullptr,\n@@ -581,1 +589,1 @@\n-    assert(SharedRuntime::polling_page_safepoint_handler_blob() != NULL,\n+    assert(SharedRuntime::polling_page_safepoint_handler_blob() != nullptr,\n@@ -592,11 +600,0 @@\n-\n-oop SharedRuntime::retrieve_receiver( Symbol* sig, frame caller ) {\n-  assert(caller.is_interpreted_frame(), \"\");\n-  int args_size = ArgumentSizeComputer(sig).size() + 1;\n-  assert(args_size <= caller.interpreter_frame_expression_stack_size(), \"receiver must be on interpreter stack\");\n-  oop result = cast_to_oop(*caller.interpreter_frame_tos_at(args_size - 1));\n-  assert(Universe::heap()->is_in(result) && oopDesc::is_oop(result), \"receiver must be an oop\");\n-  return result;\n-}\n-\n-\n@@ -617,1 +614,1 @@\n-    if (trap_mdo != NULL) {\n+    if (trap_mdo != nullptr) {\n@@ -622,2 +619,2 @@\n-        ProfileData* pdata = trap_mdo->allocate_bci_to_data(bci, NULL);\n-        if (pdata != NULL && pdata->is_BitData()) {\n+        ProfileData* pdata = trap_mdo->allocate_bci_to_data(bci, nullptr);\n+        if (pdata != nullptr && pdata->is_BitData()) {\n@@ -640,0 +637,28 @@\n+#if INCLUDE_JVMTI\n+JRT_ENTRY(void, SharedRuntime::notify_jvmti_vthread_start(oopDesc* vt, jboolean hide, JavaThread* current))\n+  assert(hide == JNI_FALSE, \"must be VTMS transition finish\");\n+  jobject vthread = JNIHandles::make_local(const_cast<oopDesc*>(vt));\n+  JvmtiVTMSTransitionDisabler::VTMS_vthread_start(vthread);\n+  JNIHandles::destroy_local(vthread);\n+JRT_END\n+\n+JRT_ENTRY(void, SharedRuntime::notify_jvmti_vthread_end(oopDesc* vt, jboolean hide, JavaThread* current))\n+  assert(hide == JNI_TRUE, \"must be VTMS transition start\");\n+  jobject vthread = JNIHandles::make_local(const_cast<oopDesc*>(vt));\n+  JvmtiVTMSTransitionDisabler::VTMS_vthread_end(vthread);\n+  JNIHandles::destroy_local(vthread);\n+JRT_END\n+\n+JRT_ENTRY(void, SharedRuntime::notify_jvmti_vthread_mount(oopDesc* vt, jboolean hide, JavaThread* current))\n+  jobject vthread = JNIHandles::make_local(const_cast<oopDesc*>(vt));\n+  JvmtiVTMSTransitionDisabler::VTMS_vthread_mount(vthread, hide);\n+  JNIHandles::destroy_local(vthread);\n+JRT_END\n+\n+JRT_ENTRY(void, SharedRuntime::notify_jvmti_vthread_unmount(oopDesc* vt, jboolean hide, JavaThread* current))\n+  jobject vthread = JNIHandles::make_local(const_cast<oopDesc*>(vt));\n+  JvmtiVTMSTransitionDisabler::VTMS_vthread_unmount(vthread, hide);\n+  JNIHandles::destroy_local(vthread);\n+JRT_END\n+#endif \/\/ INCLUDE_JVMTI\n+\n@@ -661,1 +686,1 @@\n-  assert(cm != NULL, \"must exist\");\n+  assert(cm != nullptr, \"must exist\");\n@@ -670,1 +695,1 @@\n-    if (t != NULL) {\n+    if (t != nullptr) {\n@@ -717,1 +742,1 @@\n-        if (sd != NULL) {\n+        if (sd != nullptr) {\n@@ -722,1 +747,1 @@\n-    } while (recursive_exception || (!top_frame_only && handler_bci < 0 && sd != NULL));\n+    } while (recursive_exception || (!top_frame_only && handler_bci < 0 && sd != nullptr));\n@@ -730,1 +755,1 @@\n-  if (t == NULL && (nm->is_compiled_by_c1() || handler_bci != -1)) {\n+  if (t == nullptr && (nm->is_compiled_by_c1() || handler_bci != -1)) {\n@@ -741,2 +766,2 @@\n-  if (t == NULL && nm->is_compiled_by_c1()) {\n-    assert(nm->unwind_handler_begin() != NULL, \"\");\n+  if (t == nullptr && nm->is_compiled_by_c1()) {\n+    assert(nm->unwind_handler_begin() != nullptr, \"\");\n@@ -747,1 +772,1 @@\n-  if (t == NULL) {\n+  if (t == nullptr) {\n@@ -749,1 +774,1 @@\n-    tty->print_cr(\"MISSING EXCEPTION HANDLER for pc \" INTPTR_FORMAT \" and handler bci %d\", p2i(ret_pc), handler_bci);\n+    tty->print_cr(\"MISSING EXCEPTION HANDLER for pc \" INTPTR_FORMAT \" and handler bci %d, catch_pco: %d\", p2i(ret_pc), handler_bci, catch_pco);\n@@ -755,0 +780,1 @@\n+    nm->print();\n@@ -757,1 +783,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -778,1 +804,1 @@\n-  throw_and_post_jvmti_exception(current, vmSymbols::java_lang_NullPointerException(), NULL);\n+  throw_and_post_jvmti_exception(current, vmSymbols::java_lang_NullPointerException(), nullptr);\n@@ -784,1 +810,1 @@\n-  throw_and_post_jvmti_exception(current, vmSymbols::java_lang_NullPointerException(), NULL);\n+  throw_and_post_jvmti_exception(current, vmSymbols::java_lang_NullPointerException(), nullptr);\n@@ -809,0 +835,4 @@\n+  \/\/ Remove the ScopedValue bindings in case we got a\n+  \/\/ StackOverflowError while we were trying to remove ScopedValue\n+  \/\/ bindings.\n+  current->clear_scopedValueBindings();\n@@ -818,1 +848,1 @@\n-  address target_pc = NULL;\n+  address target_pc = nullptr;\n@@ -840,1 +870,1 @@\n-        assert(current->deopt_mark() == NULL, \"no stack overflow from deopt blob\/uncommon trap\");\n+        assert(current->deopt_mark() == nullptr, \"no stack overflow from deopt blob\/uncommon trap\");\n@@ -853,2 +883,2 @@\n-          \/\/ If vt_stub is NULL, then return NULL to signal handler to report the SEGV error.\n-          if (vt_stub == NULL) return NULL;\n+          \/\/ If vt_stub is null, then return null to signal handler to report the SEGV error.\n+          if (vt_stub == nullptr) return nullptr;\n@@ -873,2 +903,2 @@\n-          \/\/ If code blob is NULL, then return NULL to signal handler to report the SEGV error.\n-          if (cb == NULL) return NULL;\n+          \/\/ If code blob is null, then return null to signal handler to report the SEGV error.\n+          if (cb == nullptr) return nullptr;\n@@ -885,1 +915,1 @@\n-              return NULL;\n+              return nullptr;\n@@ -913,1 +943,1 @@\n-          \/\/ If there's an unexpected fault, target_pc might be NULL,\n+          \/\/ If there's an unexpected fault, target_pc might be null,\n@@ -924,1 +954,1 @@\n-        guarantee(cm != NULL, \"must have containing compiled method for implicit division-by-zero exceptions\");\n+        guarantee(cm != nullptr, \"must have containing compiled method for implicit division-by-zero exceptions\");\n@@ -929,1 +959,1 @@\n-        \/\/ If there's an unexpected fault, target_pc might be NULL,\n+        \/\/ If there's an unexpected fault, target_pc might be null,\n@@ -957,1 +987,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -996,6 +1026,4 @@\n-jlong SharedRuntime::get_java_tid(Thread* thread) {\n-  if (thread != NULL) {\n-    if (thread->is_Java_thread()) {\n-      oop obj = thread->as_Java_thread()->threadObj();\n-      return (obj == NULL) ? 0 : java_lang_Thread::thread_id(obj);\n-    }\n+jlong SharedRuntime::get_java_tid(JavaThread* thread) {\n+  assert(thread != nullptr, \"No thread\");\n+  if (thread == nullptr) {\n+    return 0;\n@@ -1003,1 +1031,4 @@\n-  return 0;\n+  guarantee(Thread::current() != thread || thread->is_oop_safe(),\n+            \"current cannot touch oops after its GC barrier is detached.\");\n+  oop obj = thread->threadObj();\n+  return (obj == nullptr) ? 0 : java_lang_Thread::thread_id(obj);\n@@ -1011,2 +1042,2 @@\n-int SharedRuntime::dtrace_object_alloc(oopDesc* o, int size) {\n-  return dtrace_object_alloc_base(Thread::current(), o, size);\n+int SharedRuntime::dtrace_object_alloc(oopDesc* o) {\n+  return dtrace_object_alloc(JavaThread::current(), o, o->size());\n@@ -1015,1 +1046,5 @@\n-int SharedRuntime::dtrace_object_alloc_base(Thread* thread, oopDesc* o, int size) {\n+int SharedRuntime::dtrace_object_alloc(JavaThread* thread, oopDesc* o) {\n+  return dtrace_object_alloc(thread, o, o->size());\n+}\n+\n+int SharedRuntime::dtrace_object_alloc(JavaThread* thread, oopDesc* o, size_t size) {\n@@ -1027,0 +1062,2 @@\n+  assert(current == JavaThread::current(), \"pre-condition\");\n+\n@@ -1041,0 +1078,1 @@\n+  assert(current == JavaThread::current(), \"pre-condition\");\n@@ -1072,1 +1110,4 @@\n-  RegisterMap unused_reg_map(current, false);\n+  RegisterMap unused_reg_map(current,\n+                             RegisterMap::UpdateMap::skip,\n+                             RegisterMap::ProcessFrames::include,\n+                             RegisterMap::WalkContinuation::skip);\n@@ -1241,2 +1282,0 @@\n-  nmethodLocker caller_lock(caller);\n-\n@@ -1248,1 +1287,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1266,0 +1305,6 @@\n+  if (caller->is_continuation_enter_intrinsic()) {\n+    bc = Bytecodes::_invokestatic;\n+    LinkResolver::resolve_continuation_enter(callinfo, CHECK_NH);\n+    return receiver;\n+  }\n+\n@@ -1314,1 +1359,4 @@\n-    RegisterMap reg_map2(current);\n+    RegisterMap reg_map2(current,\n+                         RegisterMap::UpdateMap::include,\n+                         RegisterMap::ProcessFrames::include,\n+                         RegisterMap::WalkContinuation::skip);\n@@ -1321,1 +1369,1 @@\n-      if (callee == NULL) {\n+      if (callee == nullptr) {\n@@ -1328,0 +1376,1 @@\n+    assert(oopDesc::is_oop_or_null(receiver()), \"\");\n@@ -1349,1 +1398,1 @@\n-    Klass* rk = NULL;\n+    Klass* rk = nullptr;\n@@ -1356,1 +1405,1 @@\n-      rk = constants->klass_ref_at(bytecode_index, CHECK_NH);\n+      rk = constants->klass_ref_at(bytecode_index, bc, CHECK_NH);\n@@ -1386,1 +1435,4 @@\n-    RegisterMap reg_map(current, false);\n+    RegisterMap reg_map(current,\n+                        RegisterMap::UpdateMap::skip,\n+                        RegisterMap::ProcessFrames::include,\n+                        RegisterMap::WalkContinuation::skip);\n@@ -1440,1 +1492,1 @@\n-  if (callee != NULL) {\n+  if (callee != nullptr) {\n@@ -1444,1 +1496,1 @@\n-  if (callee != NULL && !callee->is_in_use()) {\n+  if (callee != nullptr && !callee->is_in_use()) {\n@@ -1446,1 +1498,1 @@\n-    callee = NULL;\n+    callee = nullptr;\n@@ -1448,2 +1500,1 @@\n-  nmethodLocker nl_callee(callee);\n-  address dest_entry_point = callee == NULL ? 0 : callee->entry_point(); \/\/ used below\n+  address dest_entry_point = callee == nullptr ? 0 : callee->entry_point(); \/\/ used below\n@@ -1458,1 +1509,1 @@\n-    Klass* klass = invoke_code == Bytecodes::_invokehandle ? NULL : receiver->klass();\n+    Klass* klass = invoke_code == Bytecodes::_invokehandle ? nullptr : receiver->klass();\n@@ -1480,1 +1531,1 @@\n-        (callee == NULL || (callee->is_in_use() && callee_method->code() == callee))) {\n+        (callee == nullptr || (callee->is_in_use() && callee_method->code() == callee))) {\n@@ -1486,1 +1537,1 @@\n-        assert((cb != NULL) && cb->is_compiled() && (((CompiledMethod*)cb) == callee),\n+        assert((cb != nullptr) && cb->is_compiled() && (((CompiledMethod*)cb) == callee),\n@@ -1501,1 +1552,1 @@\n-            callee != NULL && callee->is_compiled_by_jvmci()) {\n+            callee != nullptr && callee->is_compiled_by_jvmci()) {\n@@ -1505,0 +1556,3 @@\n+        if (is_nmethod && caller_nm->method()->is_continuation_enter_intrinsic()) {\n+          ssc->compute_entry_for_continuation_entry(callee_method, static_call_info);\n+        }\n@@ -1517,1 +1571,4 @@\n-  RegisterMap cbl_map(current, false);\n+  RegisterMap cbl_map(current,\n+                      RegisterMap::UpdateMap::skip,\n+                      RegisterMap::ProcessFrames::include,\n+                      RegisterMap::WalkContinuation::skip);\n@@ -1521,1 +1578,1 @@\n-  guarantee(caller_cb != NULL && caller_cb->is_compiled(), \"must be called from compiled method\");\n+  guarantee(caller_cb != nullptr && caller_cb->is_compiled(), \"must be called from compiled method\");\n@@ -1524,7 +1581,2 @@\n-  \/\/ make sure caller is not getting deoptimized\n-  \/\/ and removed before we are done with it.\n-  \/\/ CLEANUP - with lazy deopt shouldn't need this lock\n-  nmethodLocker caller_lock(caller_nm);\n-\n-  \/\/ note: a) receiver is NULL for static calls\n-  \/\/       b) an exception is thrown if receiver is NULL for non-static calls\n+  \/\/ note: a) receiver is null for static calls\n+  \/\/       b) an exception is thrown if receiver is null for non-static calls\n@@ -1543,1 +1595,1 @@\n-  assert(caller_nm->is_alive() && !caller_nm->is_unloading(), \"It should be alive\");\n+  assert(!caller_nm->is_unloading(), \"It should not be unloading\");\n@@ -1565,1 +1617,1 @@\n-           callee_method->method_holder()->is_reentrant_initialization(current),\n+           callee_method->method_holder()->is_init_thread(current),\n@@ -1615,1 +1667,4 @@\n-  RegisterMap reg_map(current, false);\n+  RegisterMap reg_map(current,\n+                      RegisterMap::UpdateMap::skip,\n+                      RegisterMap::ProcessFrames::include,\n+                      RegisterMap::WalkContinuation::skip);\n@@ -1619,1 +1674,1 @@\n-  assert(!caller_frame.is_interpreted_frame() && !caller_frame.is_entry_frame() && !caller_frame.is_optimized_entry_frame(), \"unexpected frame\");\n+  assert(!caller_frame.is_interpreted_frame() && !caller_frame.is_entry_frame() && !caller_frame.is_upcall_stub_frame(), \"unexpected frame\");\n@@ -1629,1 +1684,1 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n+  assert(callee_method->verified_code_entry() != nullptr, \" Jump to zero!\");\n@@ -1645,1 +1700,4 @@\n-  RegisterMap reg_map(current, false);\n+  RegisterMap reg_map(current,\n+                      RegisterMap::UpdateMap::skip,\n+                      RegisterMap::ProcessFrames::include,\n+                      RegisterMap::WalkContinuation::skip);\n@@ -1652,1 +1710,1 @@\n-      caller_frame.is_optimized_entry_frame()) {\n+      caller_frame.is_upcall_stub_frame()) {\n@@ -1654,1 +1712,1 @@\n-    guarantee(callee != NULL && callee->is_method(), \"bad handshake\");\n+    guarantee(callee != nullptr && callee->is_method(), \"bad handshake\");\n@@ -1656,1 +1714,1 @@\n-    current->set_callee_target(NULL);\n+    current->set_callee_target(nullptr);\n@@ -1680,1 +1738,1 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n+  assert(callee_method->verified_code_entry() != nullptr, \" Jump to zero!\");\n@@ -1695,1 +1753,4 @@\n-  RegisterMap reg_map(current);\n+  RegisterMap reg_map(current,\n+                      RegisterMap::UpdateMap::include,\n+                      RegisterMap::ProcessFrames::include,\n+                      RegisterMap::WalkContinuation::skip);\n@@ -1707,1 +1768,1 @@\n-      Klass *recv_klass = (recv != NULL) ? recv->klass() : NULL;\n+      Klass *recv_klass = (recv != nullptr) ? recv->klass() : nullptr;\n@@ -1719,0 +1780,1 @@\n+  bool enter_special = false;\n@@ -1722,0 +1784,12 @@\n+\n+    if (current->is_interp_only_mode()) {\n+      RegisterMap reg_map(current,\n+                          RegisterMap::UpdateMap::skip,\n+                          RegisterMap::ProcessFrames::include,\n+                          RegisterMap::WalkContinuation::skip);\n+      frame stub_frame = current->last_frame();\n+      assert(stub_frame.is_runtime_frame(), \"must be a runtimeStub\");\n+      frame caller = stub_frame.sender(&reg_map);\n+      enter_special = caller.cb() != nullptr && caller.cb()->is_compiled()\n+        && caller.cb()->as_compiled_method()->method()->is_continuation_enter_intrinsic();\n+    }\n@@ -1723,0 +1797,12 @@\n+\n+  if (current->is_interp_only_mode() && enter_special) {\n+    \/\/ enterSpecial is compiled and calls this method to resolve the call to Continuation::enter\n+    \/\/ but in interp_only_mode we need to go to the interpreted entry\n+    \/\/ The c2i won't patch in this mode -- see fixup_callers_callsite\n+    \/\/\n+    \/\/ This should probably be done in all cases, not just enterSpecial (see JDK-8218403),\n+    \/\/ but that's part of a larger fix, and the situation is worse for enterSpecial, as it has no\n+    \/\/ interpreted version.\n+    return callee_method->get_c2i_entry();\n+  }\n+\n@@ -1724,1 +1810,1 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n+  assert(callee_method->verified_code_entry() != nullptr, \" Jump to zero!\");\n@@ -1737,1 +1823,1 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n+  assert(callee_method->verified_code_entry() != nullptr, \" Jump to zero!\");\n@@ -1751,1 +1837,1 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n+  assert(callee_method->verified_code_entry() != nullptr, \" Jump to zero!\");\n@@ -1777,1 +1863,1 @@\n-    if (ic_oop != NULL) {\n+    if (ic_oop != nullptr) {\n@@ -1788,1 +1874,1 @@\n-        \/\/ We can't assert for callee_method->code() != NULL because it\n+        \/\/ We can't assert for callee_method->code() != nullptr because it\n@@ -1841,1 +1927,1 @@\n-  \/\/ receiver is NULL for static calls. An exception is thrown for NULL\n+  \/\/ receiver is null for static calls. An exception is thrown for null\n@@ -1857,1 +1943,4 @@\n-      RegisterMap reg_map(current, false);\n+      RegisterMap reg_map(current,\n+                          RegisterMap::UpdateMap::skip,\n+                          RegisterMap::ProcessFrames::include,\n+                          RegisterMap::WalkContinuation::skip);\n@@ -1883,1 +1972,4 @@\n-    RegisterMap reg_map(current, false);\n+    RegisterMap reg_map(current,\n+                        RegisterMap::UpdateMap::skip,\n+                        RegisterMap::ProcessFrames::include,\n+                        RegisterMap::WalkContinuation::skip);\n@@ -1901,1 +1993,4 @@\n-  RegisterMap reg_map(current, false);\n+  RegisterMap reg_map(current,\n+                      RegisterMap::UpdateMap::skip,\n+                      RegisterMap::ProcessFrames::include,\n+                      RegisterMap::WalkContinuation::skip);\n@@ -1945,1 +2040,4 @@\n-  RegisterMap reg_map(current, false);\n+  RegisterMap reg_map(current,\n+                      RegisterMap::UpdateMap::skip,\n+                      RegisterMap::ProcessFrames::include,\n+                      RegisterMap::WalkContinuation::skip);\n@@ -1980,1 +2078,1 @@\n-    address call_addr = NULL;\n+    address call_addr = nullptr;\n@@ -1988,5 +2086,5 @@\n-    \/\/ Make sure nmethod doesn't get deoptimized and removed until\n-    \/\/ this is done with it.\n-    \/\/ CLEANUP - with lazy deopt shouldn't need this lock\n-    nmethodLocker nmlock(caller_nm);\n-    if (call_addr != NULL) {\n+    \/\/ Check relocations for the matching call to 1) avoid false positives,\n+    \/\/ and 2) determine the type.\n+    if (call_addr != nullptr) {\n+      \/\/ On x86 the logic for finding a call instruction is blindly checking for a call opcode 5\n+      \/\/ bytes back in the instruction stream so we must also check for reloc info.\n@@ -1995,1 +2093,1 @@\n-      int ret = iter.next(); \/\/ Get item\n+      bool ret = iter.next(); \/\/ Get item\n@@ -1997,25 +2095,25 @@\n-        assert(iter.addr() == call_addr, \"must find call\");\n-        if (iter.type() == relocInfo::static_call_type) {\n-          is_static_call = true;\n-        } else {\n-          assert(iter.type() == relocInfo::virtual_call_type ||\n-                 iter.type() == relocInfo::opt_virtual_call_type\n-                , \"unexpected relocInfo. type\");\n-        }\n-      } else {\n-        assert(!UseInlineCaches, \"relocation info. must exist for this address\");\n-      }\n-\n-      \/\/ Cleaning the inline cache will force a new resolve. This is more robust\n-      \/\/ than directly setting it to the new destination, since resolving of calls\n-      \/\/ is always done through the same code path. (experience shows that it\n-      \/\/ leads to very hard to track down bugs, if an inline cache gets updated\n-      \/\/ to a wrong method). It should not be performance critical, since the\n-      \/\/ resolve is only done once.\n-\n-      for (;;) {\n-        ICRefillVerifier ic_refill_verifier;\n-        if (!clear_ic_at_addr(caller_nm, call_addr, is_static_call)) {\n-          InlineCacheBuffer::refill_ic_stubs();\n-        } else {\n-          break;\n+        bool is_static_call = false;\n+        switch (iter.type()) {\n+          case relocInfo::static_call_type:\n+            is_static_call = true;\n+\n+          case relocInfo::virtual_call_type:\n+          case relocInfo::opt_virtual_call_type:\n+            \/\/ Cleaning the inline cache will force a new resolve. This is more robust\n+            \/\/ than directly setting it to the new destination, since resolving of calls\n+            \/\/ is always done through the same code path. (experience shows that it\n+            \/\/ leads to very hard to track down bugs, if an inline cache gets updated\n+            \/\/ to a wrong method). It should not be performance critical, since the\n+            \/\/ resolve is only done once.\n+            guarantee(iter.addr() == call_addr, \"must find call\");\n+            for (;;) {\n+              ICRefillVerifier ic_refill_verifier;\n+              if (!clear_ic_at_addr(caller_nm, call_addr, is_static_call)) {\n+                InlineCacheBuffer::refill_ic_stubs();\n+              } else {\n+                break;\n+              }\n+            }\n+            break;\n+          default:\n+            break;\n@@ -2087,1 +2185,1 @@\n-    if (callee != NULL && (callee == cb || callee->is_adapter_blob())) {\n+    if (callee != nullptr && (callee == cb || callee->is_adapter_blob())) {\n@@ -2123,1 +2221,1 @@\n-  address entry_point = moop->from_compiled_entry_no_trampoline();\n+  AARCH64_PORT_ONLY(assert(pauth_ptr_is_raw(caller_pc), \"should be raw\"));\n@@ -2135,0 +2233,11 @@\n+  \/\/ Result from nmethod::is_unloading is not stable across safepoints.\n+  NoSafepointVerifier nsv;\n+\n+  CompiledMethod* callee = moop->code();\n+  if (callee == nullptr) {\n+    return;\n+  }\n+\n+  \/\/ write lock needed because we might update the pc desc cache via PcDescCache::add_pc_desc\n+  MACOS_AARCH64_ONLY(ThreadWXEnable __wx(WXWrite, JavaThread::current()));\n+\n@@ -2136,1 +2245,1 @@\n-  if (cb == NULL || !cb->is_compiled() || entry_point == moop->get_c2i_entry()) {\n+  if (cb == nullptr || !cb->is_compiled() || callee->is_unloading()) {\n@@ -2150,2 +2259,2 @@\n-  \/\/ call site with the same old data. clear_code will set code() to NULL\n-  \/\/ at the end of it. If we happen to see that NULL then we can skip trying\n+  \/\/ call site with the same old data. clear_code will set code() to null\n+  \/\/ at the end of it. If we happen to see that null then we can skip trying\n@@ -2153,1 +2262,1 @@\n-  \/\/ from_compiled_entry and the NULL isn't present yet then we lose the race\n+  \/\/ from_compiled_entry and the null isn't present yet then we lose the race\n@@ -2156,1 +2265,1 @@\n-  if (moop->code() == NULL) return;\n+  if (moop->code() == nullptr) return;\n@@ -2183,0 +2292,5 @@\n+      if (nm->method()->is_continuation_enter_intrinsic()) {\n+        if (ContinuationEntry::is_interpreted_call(call->instruction_address())) {\n+          return;\n+        }\n+      }\n@@ -2184,0 +2298,1 @@\n+      address entry_point = callee->verified_entry_point();\n@@ -2201,1 +2316,1 @@\n-  if (src == NULL || dest == NULL) {\n+  if (src == nullptr || dest == nullptr) {\n@@ -2227,2 +2342,2 @@\n-  Symbol* target_klass_name = NULL;\n-  if (target_klass == NULL) {\n+  Symbol* target_klass_name = nullptr;\n+  if (target_klass == nullptr) {\n@@ -2242,2 +2357,2 @@\n-  assert(target_klass != NULL || target_klass_name != NULL, \"one must be provided\");\n-  const char* target_name = target_klass == NULL ? target_klass_name->as_klass_external_name() :\n+  assert(target_klass != nullptr || target_klass_name != nullptr, \"one must be provided\");\n+  const char* target_name = target_klass == nullptr ? target_klass_name->as_klass_external_name() :\n@@ -2251,1 +2366,1 @@\n-  if (target_klass != NULL && caster_klass->module() == target_klass->module()) {\n+  if (target_klass != nullptr && caster_klass->module() == target_klass->module()) {\n@@ -2255,2 +2370,2 @@\n-    target_klass_description = (target_klass != NULL) ? target_klass->class_in_module_of_loader() : \"\";\n-    klass_separator = (target_klass != NULL) ? \"; \" : \"\";\n+    target_klass_description = (target_klass != nullptr) ? target_klass->class_in_module_of_loader() : \"\";\n+    klass_separator = (target_klass != nullptr) ? \"; \" : \"\";\n@@ -2259,1 +2374,1 @@\n-  \/\/ add 3 for parenthesis and preceeding space\n+  \/\/ add 3 for parenthesis and preceding space\n@@ -2263,1 +2378,1 @@\n-  if (message == NULL) {\n+  if (message == nullptr) {\n@@ -2288,1 +2403,3 @@\n-    if (ObjectSynchronizer::quick_enter(obj, current, lock)) return;\n+    if (ObjectSynchronizer::quick_enter(obj, current, lock)) {\n+      return;\n+    }\n@@ -2295,3 +2412,0 @@\n-  if (PrintBiasedLockingStatistics) {\n-    Atomic::inc(BiasedLocking::slow_path_entry_count_addr());\n-  }\n@@ -2326,0 +2440,1 @@\n+  assert(current == JavaThread::current(), \"pre-condition\");\n@@ -2333,3 +2448,1 @@\n-  if (xtty != NULL)  xtty->head(\"statistics type='SharedRuntime'\");\n-\n-  if (_throw_null_ctr) tty->print_cr(\"%5d implicit null throw\", _throw_null_ctr);\n+  if (xtty != nullptr)  xtty->head(\"statistics type='SharedRuntime'\");\n@@ -2342,1 +2455,0 @@\n-  if (_multi1_ctr) tty->print_cr(\"%5d multianewarray 1 dim\", _multi1_ctr);\n@@ -2373,5 +2485,1 @@\n-  if (xtty != NULL)  xtty->tail(\"statistics\");\n-}\n-\n-inline double percent(int x, int y) {\n-  return 100.0 * x \/ MAX2(y, 1);\n+  if (xtty != nullptr)  xtty->tail(\"statistics\");\n@@ -2396,2 +2504,2 @@\n-    Method* method = (nm == NULL) ? NULL : nm->method();\n-    if ((method != NULL) && nm->is_alive()) {\n+    Method* method = (nm == nullptr) ? nullptr : nm->method();\n+    if (method != nullptr) {\n@@ -2467,2 +2575,2 @@\n-  int64_t mono_c = _nof_normal_calls - _nof_optimized_calls - _nof_megamorphic_calls;\n-  int64_t mono_i = _nof_interface_calls - _nof_optimized_interface_calls - _nof_megamorphic_interface_calls;\n+  int64_t mono_c = _nof_normal_calls - _nof_megamorphic_calls;\n+  int64_t mono_i = _nof_interface_calls;\n@@ -2472,1 +2580,0 @@\n-  tty->print_cr(\"\\t\" INT64_FORMAT_W(12) \" (%4.0f%%) |  |- optimized        \", _nof_optimized_calls, percent(_nof_optimized_calls, _nof_normal_calls));\n@@ -2477,2 +2584,0 @@\n-  tty->print_cr(\"\\t\" INT64_FORMAT_W(12) \" (%4.0f%%) |  |- optimized        \", _nof_optimized_interface_calls, percent(_nof_optimized_interface_calls, _nof_interface_calls));\n-  tty->print_cr(\"\\t\" INT64_FORMAT_W(12) \" (%4.0f%%) |  |- megamorphic      \", _nof_megamorphic_interface_calls, percent(_nof_megamorphic_interface_calls, _nof_interface_calls));\n@@ -2493,0 +2598,6 @@\n+#ifndef PRODUCT\n+static int _lookups; \/\/ number of calls to lookup\n+static int _equals;  \/\/ number of buckets checked with matching hash\n+static int _hits;    \/\/ number of successful lookups\n+static int _compact; \/\/ number of equals calls with compact signature\n+#endif\n@@ -2679,18 +2790,3 @@\n-};\n-\n-\n-\/\/ A hashtable mapping from AdapterFingerPrints to AdapterHandlerEntries\n-class AdapterHandlerTable : public BasicHashtable<mtCode> {\n-  friend class AdapterHandlerTableIterator;\n-\n- private:\n-#ifndef PRODUCT\n-  static int _lookups; \/\/ number of calls to lookup\n-  static int _buckets; \/\/ number of buckets checked\n-  static int _equals;  \/\/ number of buckets checked with matching hash\n-  static int _hits;    \/\/ number of successful lookups\n-  static int _compact; \/\/ number of equals calls with compact signature\n-#endif\n-\n-  AdapterHandlerEntry* bucket(int i) {\n-    return (AdapterHandlerEntry*)BasicHashtable<mtCode>::bucket(i);\n+  static bool equals(AdapterFingerPrint* const& fp1, AdapterFingerPrint* const& fp2) {\n+    NOT_PRODUCT(_equals++);\n+    return fp1->equals(fp2);\n@@ -2700,9 +2796,2 @@\n- public:\n-  AdapterHandlerTable()\n-    : BasicHashtable<mtCode>(293, (sizeof(AdapterHandlerEntry))) { }\n-\n-  \/\/ Create a new entry suitable for insertion in the table\n-  AdapterHandlerEntry* new_entry(AdapterFingerPrint* fingerprint, address i2c_entry, address c2i_entry, address c2i_unverified_entry, address c2i_no_clinit_check_entry) {\n-    AdapterHandlerEntry* entry = (AdapterHandlerEntry*)BasicHashtable<mtCode>::new_entry(fingerprint->compute_hash());\n-    entry->init(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry, c2i_no_clinit_check_entry);\n-    return entry;\n+  static unsigned int compute_hash(AdapterFingerPrint* const& fp) {\n+    return fp->compute_hash();\n@@ -2710,0 +2799,1 @@\n+};\n@@ -2711,22 +2801,14 @@\n-  \/\/ Insert an entry into the table\n-  void add(AdapterHandlerEntry* entry) {\n-    int index = hash_to_index(entry->hash());\n-    add_entry(index, entry);\n-  }\n-\n-  void free_entry(AdapterHandlerEntry* entry) {\n-    entry->deallocate();\n-    BasicHashtable<mtCode>::free_entry(entry);\n-  }\n-\n-  \/\/ Find a entry with the same fingerprint if it exists\n-  AdapterHandlerEntry* lookup(int total_args_passed, BasicType* sig_bt) {\n-    NOT_PRODUCT(_lookups++);\n-    AdapterFingerPrint fp(total_args_passed, sig_bt);\n-    unsigned int hash = fp.compute_hash();\n-    int index = hash_to_index(hash);\n-    for (AdapterHandlerEntry* e = bucket(index); e != NULL; e = e->next()) {\n-      NOT_PRODUCT(_buckets++);\n-      if (e->hash() == hash) {\n-        NOT_PRODUCT(_equals++);\n-        if (fp.equals(e->fingerprint())) {\n+\/\/ A hashtable mapping from AdapterFingerPrints to AdapterHandlerEntries\n+using AdapterHandlerTable = ResourceHashtable<AdapterFingerPrint*, AdapterHandlerEntry*, 293,\n+                  AnyObj::C_HEAP, mtCode,\n+                  AdapterFingerPrint::compute_hash,\n+                  AdapterFingerPrint::equals>;\n+static AdapterHandlerTable* _adapter_handler_table;\n+\n+\/\/ Find a entry with the same fingerprint if it exists\n+static AdapterHandlerEntry* lookup(int total_args_passed, BasicType* sig_bt) {\n+  NOT_PRODUCT(_lookups++);\n+  assert_lock_strong(AdapterHandlerLibrary_lock);\n+  AdapterFingerPrint fp(total_args_passed, sig_bt);\n+  AdapterHandlerEntry** entry = _adapter_handler_table->get(&fp);\n+  if (entry != nullptr) {\n@@ -2734,2 +2816,2 @@\n-          if (fp.is_compact()) _compact++;\n-          _hits++;\n+    if (fp.is_compact()) _compact++;\n+    _hits++;\n@@ -2737,28 +2819,1 @@\n-          return e;\n-        }\n-      }\n-    }\n-    return NULL;\n-  }\n-\n-#ifndef PRODUCT\n-  void print_statistics() {\n-    ResourceMark rm;\n-    int longest = 0;\n-    int empty = 0;\n-    int total = 0;\n-    int nonempty = 0;\n-    for (int index = 0; index < table_size(); index++) {\n-      int count = 0;\n-      for (AdapterHandlerEntry* e = bucket(index); e != NULL; e = e->next()) {\n-        count++;\n-      }\n-      if (count != 0) nonempty++;\n-      if (count == 0) empty++;\n-      if (count > longest) longest = count;\n-      total += count;\n-    }\n-    tty->print_cr(\"AdapterHandlerTable: empty %d longest %d total %d average %f\",\n-                  empty, longest, total, total \/ (double)nonempty);\n-    tty->print_cr(\"AdapterHandlerTable: lookups %d buckets %d equals %d hits %d compact %d\",\n-                  _lookups, _buckets, _equals, _hits, _compact);\n+    return *entry;\n@@ -2766,3 +2821,2 @@\n-#endif\n-};\n-\n+  return nullptr;\n+}\n@@ -2771,7 +2825,11 @@\n-\n-int AdapterHandlerTable::_lookups;\n-int AdapterHandlerTable::_buckets;\n-int AdapterHandlerTable::_equals;\n-int AdapterHandlerTable::_hits;\n-int AdapterHandlerTable::_compact;\n-\n+static void print_table_statistics() {\n+  auto size = [&] (AdapterFingerPrint* key, AdapterHandlerEntry* a) {\n+    return sizeof(*key) + sizeof(*a);\n+  };\n+  TableStatistics ts = _adapter_handler_table->statistics_calculate(size);\n+  ts.print(tty, \"AdapterHandlerTable\");\n+  tty->print_cr(\"AdapterHandlerTable (table_size=%d, entries=%d)\",\n+                _adapter_handler_table->table_size(), _adapter_handler_table->number_of_entries());\n+  tty->print_cr(\"AdapterHandlerTable: lookups %d equals %d hits %d compact %d\",\n+                _lookups, _equals, _hits, _compact);\n+}\n@@ -2780,37 +2838,0 @@\n-class AdapterHandlerTableIterator : public StackObj {\n- private:\n-  AdapterHandlerTable* _table;\n-  int _index;\n-  AdapterHandlerEntry* _current;\n-\n-  void scan() {\n-    while (_index < _table->table_size()) {\n-      AdapterHandlerEntry* a = _table->bucket(_index);\n-      _index++;\n-      if (a != NULL) {\n-        _current = a;\n-        return;\n-      }\n-    }\n-  }\n-\n- public:\n-  AdapterHandlerTableIterator(AdapterHandlerTable* table): _table(table), _index(0), _current(NULL) {\n-    scan();\n-  }\n-  bool has_next() {\n-    return _current != NULL;\n-  }\n-  AdapterHandlerEntry* next() {\n-    if (_current != NULL) {\n-      AdapterHandlerEntry* result = _current;\n-      _current = _current->next();\n-      if (_current == NULL) scan();\n-      return result;\n-    } else {\n-      return NULL;\n-    }\n-  }\n-};\n-\n-\n@@ -2819,7 +2840,6 @@\n-AdapterHandlerTable* AdapterHandlerLibrary::_adapters = NULL;\n-AdapterHandlerEntry* AdapterHandlerLibrary::_abstract_method_handler = NULL;\n-AdapterHandlerEntry* AdapterHandlerLibrary::_no_arg_handler = NULL;\n-AdapterHandlerEntry* AdapterHandlerLibrary::_int_arg_handler = NULL;\n-AdapterHandlerEntry* AdapterHandlerLibrary::_obj_arg_handler = NULL;\n-AdapterHandlerEntry* AdapterHandlerLibrary::_obj_int_arg_handler = NULL;\n-AdapterHandlerEntry* AdapterHandlerLibrary::_obj_obj_arg_handler = NULL;\n+AdapterHandlerEntry* AdapterHandlerLibrary::_abstract_method_handler = nullptr;\n+AdapterHandlerEntry* AdapterHandlerLibrary::_no_arg_handler = nullptr;\n+AdapterHandlerEntry* AdapterHandlerLibrary::_int_arg_handler = nullptr;\n+AdapterHandlerEntry* AdapterHandlerLibrary::_obj_arg_handler = nullptr;\n+AdapterHandlerEntry* AdapterHandlerLibrary::_obj_int_arg_handler = nullptr;\n+AdapterHandlerEntry* AdapterHandlerLibrary::_obj_obj_arg_handler = nullptr;\n@@ -2827,1 +2847,1 @@\n-BufferBlob* AdapterHandlerLibrary::_buffer = NULL;\n+BufferBlob* AdapterHandlerLibrary::_buffer = nullptr;\n@@ -2833,12 +2853,12 @@\n-extern \"C\" void unexpected_adapter_call() {\n-  ShouldNotCallThis();\n-}\n-\n-static void post_adapter_creation(const AdapterBlob* new_adapter, const AdapterHandlerEntry* entry) {\n-  char blob_id[256];\n-  jio_snprintf(blob_id,\n-                sizeof(blob_id),\n-                \"%s(%s)\",\n-                new_adapter->name(),\n-                entry->fingerprint()->as_string());\n-  Forte::register_stub(blob_id, new_adapter->content_begin(), new_adapter->content_end());\n+static void post_adapter_creation(const AdapterBlob* new_adapter,\n+                                  const AdapterHandlerEntry* entry) {\n+  if (Forte::is_enabled() || JvmtiExport::should_post_dynamic_code_generated()) {\n+    char blob_id[256];\n+    jio_snprintf(blob_id,\n+                 sizeof(blob_id),\n+                 \"%s(%s)\",\n+                 new_adapter->name(),\n+                 entry->fingerprint()->as_string());\n+    if (Forte::is_enabled()) {\n+      Forte::register_stub(blob_id, new_adapter->content_begin(), new_adapter->content_end());\n+    }\n@@ -2846,2 +2866,3 @@\n-  if (JvmtiExport::should_post_dynamic_code_generated()) {\n-    JvmtiExport::post_dynamic_code_generated(blob_id, new_adapter->content_begin(), new_adapter->content_end());\n+    if (JvmtiExport::should_post_dynamic_code_generated()) {\n+      JvmtiExport::post_dynamic_code_generated(blob_id, new_adapter->content_begin(), new_adapter->content_end());\n+    }\n@@ -2853,5 +2874,5 @@\n-  AdapterBlob* no_arg_blob = NULL;\n-  AdapterBlob* int_arg_blob = NULL;\n-  AdapterBlob* obj_arg_blob = NULL;\n-  AdapterBlob* obj_int_arg_blob = NULL;\n-  AdapterBlob* obj_obj_arg_blob = NULL;\n+  AdapterBlob* no_arg_blob = nullptr;\n+  AdapterBlob* int_arg_blob = nullptr;\n+  AdapterBlob* obj_arg_blob = nullptr;\n+  AdapterBlob* obj_int_arg_blob = nullptr;\n+  AdapterBlob* obj_obj_arg_blob = nullptr;\n@@ -2859,0 +2880,1 @@\n+    _adapter_handler_table = new (mtCode) AdapterHandlerTable();\n@@ -2860,3 +2882,0 @@\n-    assert(_adapters == NULL, \"Initializing more than once\");\n-\n-    _adapters = new AdapterHandlerTable();\n@@ -2870,1 +2889,1 @@\n-    _abstract_method_handler = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(0, NULL),\n+    _abstract_method_handler = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(0, nullptr),\n@@ -2875,2 +2894,1 @@\n-\n-    _no_arg_handler = create_adapter(no_arg_blob, 0, NULL, true);\n+    _no_arg_handler = create_adapter(no_arg_blob, 0, nullptr, true);\n@@ -2890,5 +2908,5 @@\n-    assert(no_arg_blob != NULL &&\n-          obj_arg_blob != NULL &&\n-          int_arg_blob != NULL &&\n-          obj_int_arg_blob != NULL &&\n-          obj_obj_arg_blob != NULL, \"Initial adapters must be properly created\");\n+    assert(no_arg_blob != nullptr &&\n+          obj_arg_blob != nullptr &&\n+          int_arg_blob != nullptr &&\n+          obj_int_arg_blob != nullptr &&\n+          obj_obj_arg_blob != nullptr, \"Initial adapters must be properly created\");\n@@ -2910,1 +2928,3 @@\n-  return _adapters->new_entry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry, c2i_no_clinit_check_entry);\n+  \/\/ Insert an entry into the table\n+  return new AdapterHandlerEntry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry,\n+                                 c2i_no_clinit_check_entry);\n@@ -2949,1 +2969,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -2996,1 +3016,1 @@\n-  \/\/ the AdapterHandlerTable (it is not safe for concurrent readers\n+  \/\/ the _adapter_handler_table (it is not safe for concurrent readers\n@@ -2999,1 +3019,0 @@\n-  assert(_adapters != NULL, \"Uninitialized\");\n@@ -3003,1 +3022,1 @@\n-  if (entry != NULL) {\n+  if (entry != nullptr) {\n@@ -3008,1 +3027,1 @@\n-  AdapterBlob* new_adapter = NULL;\n+  AdapterBlob* new_adapter = nullptr;\n@@ -3021,1 +3040,1 @@\n-    entry = _adapters->lookup(total_args_passed, sig_bt);\n+    entry = lookup(total_args_passed, sig_bt);\n@@ -3023,1 +3042,1 @@\n-    if (entry != NULL) {\n+    if (entry != nullptr) {\n@@ -3026,1 +3045,1 @@\n-        AdapterBlob* comparison_blob = NULL;\n+        AdapterBlob* comparison_blob = nullptr;\n@@ -3028,1 +3047,1 @@\n-        assert(comparison_blob == NULL, \"no blob should be created when creating an adapter for comparison\");\n+        assert(comparison_blob == nullptr, \"no blob should be created when creating an adapter for comparison\");\n@@ -3031,1 +3050,1 @@\n-        _adapters->free_entry(comparison_entry);\n+        delete comparison_entry;\n@@ -3041,1 +3060,1 @@\n-  if (new_adapter != NULL) {\n+  if (new_adapter != nullptr) {\n@@ -3052,5 +3071,5 @@\n-  \/\/ StubRoutines::code2() is initialized after this function can be called. As a result,\n-  \/\/ VerifyAdapterCalls and VerifyAdapterSharing can fail if we re-use code that generated\n-  \/\/ prior to StubRoutines::code2() being set. Checks refer to checks generated in an I2C\n-  \/\/ stub that ensure that an I2C stub is called from an interpreter frame.\n-  bool contains_all_checks = StubRoutines::code2() != NULL;\n+  \/\/ StubRoutines::_final_stubs_code is initialized after this function can be called. As a result,\n+  \/\/ VerifyAdapterCalls and VerifyAdapterSharing can fail if we re-use code that generated prior\n+  \/\/ to all StubRoutines::_final_stubs_code being set. Checks refer to runtime range checks generated\n+  \/\/ in an I2C stub that ensure that an I2C stub is called from an interpreter frame or stubs.\n+  bool contains_all_checks = StubRoutines::final_stubs_code() != nullptr;\n@@ -3090,1 +3109,1 @@\n-  if (new_adapter == NULL) {\n+  if (new_adapter == nullptr) {\n@@ -3094,1 +3113,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -3098,1 +3117,1 @@\n-  \/\/ debugging suppport\n+  \/\/ debugging support\n@@ -3103,1 +3122,1 @@\n-                  _adapters->number_of_entries(), fingerprint->as_basic_args_string(),\n+                  _adapter_handler_table->number_of_entries(), fingerprint->as_basic_args_string(),\n@@ -3105,1 +3124,1 @@\n-    tty->print_cr(\"c2i argument handler starts at %p\", entry->get_c2i_entry());\n+    tty->print_cr(\"c2i argument handler starts at \" INTPTR_FORMAT, p2i(entry->get_c2i_entry()));\n@@ -3108,2 +3127,3 @@\n-      if (first_pc != NULL) {\n-        Disassembler::decode(first_pc, first_pc + insts_size);\n+      if (first_pc != nullptr) {\n+        Disassembler::decode(first_pc, first_pc + insts_size, tty\n+                             NOT_PRODUCT(COMMA &new_adapter->asm_remarks()));\n@@ -3119,1 +3139,2 @@\n-    _adapters->add(entry);\n+    assert_lock_strong(AdapterHandlerLibrary_lock);\n+    _adapter_handler_table->put(fingerprint, entry);\n@@ -3126,4 +3147,4 @@\n-  if (base == NULL)  base = _c2i_entry;\n-  assert(base <= _c2i_entry || _c2i_entry == NULL, \"\");\n-  assert(base <= _c2i_unverified_entry || _c2i_unverified_entry == NULL, \"\");\n-  assert(base <= _c2i_no_clinit_check_entry || _c2i_no_clinit_check_entry == NULL, \"\");\n+  if (base == nullptr)  base = _c2i_entry;\n+  assert(base <= _c2i_entry || _c2i_entry == nullptr, \"\");\n+  assert(base <= _c2i_unverified_entry || _c2i_unverified_entry == nullptr, \"\");\n+  assert(base <= _c2i_no_clinit_check_entry || _c2i_no_clinit_check_entry == nullptr, \"\");\n@@ -3135,1 +3156,1 @@\n-  assert(old_base != NULL, \"\");\n+  assert(old_base != nullptr, \"\");\n@@ -3137,1 +3158,1 @@\n-  if (_i2c_entry != NULL)\n+  if (_i2c_entry != nullptr)\n@@ -3139,1 +3160,1 @@\n-  if (_c2i_entry != NULL)\n+  if (_c2i_entry != nullptr)\n@@ -3141,1 +3162,1 @@\n-  if (_c2i_unverified_entry != NULL)\n+  if (_c2i_unverified_entry != nullptr)\n@@ -3143,1 +3164,1 @@\n-  if (_c2i_no_clinit_check_entry != NULL)\n+  if (_c2i_no_clinit_check_entry != nullptr)\n@@ -3149,1 +3170,1 @@\n-void AdapterHandlerEntry::deallocate() {\n+AdapterHandlerEntry::~AdapterHandlerEntry() {\n@@ -3169,1 +3190,1 @@\n-  assert(_saved_code != NULL && other->_saved_code != NULL, \"code not saved\");\n+  assert(_saved_code != nullptr && other->_saved_code != nullptr, \"code not saved\");\n@@ -3188,2 +3209,4 @@\n-  nmethod* nm = NULL;\n-  address critical_entry = NULL;\n+  nmethod* nm = nullptr;\n+\n+  \/\/ Check if memory should be freed before allocation\n+  CodeCache::gc_on_allocation();\n@@ -3192,1 +3215,1 @@\n-  assert(method->is_method_handle_intrinsic() ||\n+  assert(method->is_special_native_intrinsic() ||\n@@ -3195,5 +3218,0 @@\n-  if (CriticalJNINatives && !method->is_method_handle_intrinsic()) {\n-    \/\/ We perform the I\/O with transition to native before acquiring AdapterHandlerLibrary_lock.\n-    critical_entry = NativeLookup::lookup_critical_entry(method);\n-  }\n-\n@@ -3204,1 +3222,1 @@\n-    if (method->code() != NULL) {\n+    if (method->code() != nullptr) {\n@@ -3214,1 +3232,1 @@\n-    if (buf != NULL) {\n+    if (buf != nullptr) {\n@@ -3216,0 +3234,5 @@\n+\n+      if (method->is_continuation_enter_intrinsic()) {\n+        buffer.initialize_stubs_size(192);\n+      }\n+\n@@ -3217,0 +3240,1 @@\n+      struct { double data[20]; } stubs_locs_buf;\n@@ -3218,1 +3242,1 @@\n-#if defined(AARCH64)\n+#if defined(AARCH64) || defined(PPC64)\n@@ -3222,1 +3246,5 @@\n-      buffer.initialize_consts_size(8);\n+      \/\/ On PPC64 the continuation enter intrinsic needs the constant pool for the compiled\n+      \/\/ static java call that is resolved in the runtime.\n+      if (PPC64_ONLY(method->is_continuation_enter_intrinsic() &&) true) {\n+        buffer.initialize_consts_size(8 PPC64_ONLY(+ 24));\n+      }\n@@ -3224,0 +3252,1 @@\n+      buffer.stubs()->initialize_shared_locs((relocInfo*)&stubs_locs_buf, sizeof(stubs_locs_buf) \/ sizeof(relocInfo));\n@@ -3242,1 +3271,1 @@\n-      nm = SharedRuntime::generate_native_wrapper(&_masm, method, compile_id, sig_bt, regs, ret_type, critical_entry);\n+      nm = SharedRuntime::generate_native_wrapper(&_masm, method, compile_id, sig_bt, regs, ret_type);\n@@ -3244,1 +3273,1 @@\n-      if (nm != NULL) {\n+      if (nm != nullptr) {\n@@ -3263,1 +3292,1 @@\n-  if (nm != NULL) {\n+  if (nm != nullptr) {\n@@ -3355,0 +3384,2 @@\n+  assert(current == JavaThread::current(), \"pre-condition\");\n+\n@@ -3379,1 +3410,1 @@\n-    if (kptr->obj() != NULL) active_monitor_count++;\n+    if (kptr->obj() != nullptr) active_monitor_count++;\n@@ -3403,1 +3434,1 @@\n-    if (kptr2->obj() != NULL) {         \/\/ Avoid 'holes' in the monitor array\n+    if (kptr2->obj() != nullptr) {         \/\/ Avoid 'holes' in the monitor array\n@@ -3420,0 +3451,9 @@\n+  RegisterMap map(current,\n+                  RegisterMap::UpdateMap::skip,\n+                  RegisterMap::ProcessFrames::include,\n+                  RegisterMap::WalkContinuation::skip);\n+  frame sender = fr.sender(&map);\n+  if (sender.is_interpreted_frame()) {\n+    current->push_cont_fastpath(sender.sp());\n+  }\n+\n@@ -3428,6 +3468,7 @@\n-  AdapterHandlerTableIterator iter(_adapters);\n-  while (iter.has_next()) {\n-    AdapterHandlerEntry* a = iter.next();\n-    if (b == CodeCache::find_blob(a->get_i2c_entry())) return true;\n-  }\n-  return false;\n+  bool found = false;\n+  auto findblob = [&] (AdapterFingerPrint* key, AdapterHandlerEntry* a) {\n+    return (found = (b == CodeCache::find_blob(a->get_i2c_entry())));\n+  };\n+  assert_locked_or_safepoint(AdapterHandlerLibrary_lock);\n+  _adapter_handler_table->iterate(findblob);\n+  return found;\n@@ -3437,3 +3478,2 @@\n-  AdapterHandlerTableIterator iter(_adapters);\n-  while (iter.has_next()) {\n-    AdapterHandlerEntry* a = iter.next();\n+  bool found = false;\n+  auto findblob = [&] (AdapterFingerPrint* key, AdapterHandlerEntry* a) {\n@@ -3441,0 +3481,1 @@\n+      found = true;\n@@ -3442,2 +3483,4 @@\n-      a->print_adapter_on(tty);\n-      return;\n+      a->print_adapter_on(st);\n+      return true;\n+    } else {\n+      return false; \/\/ keep looking\n@@ -3445,2 +3488,4 @@\n-  }\n-  assert(false, \"Should have found handler\");\n+  };\n+  assert_locked_or_safepoint(AdapterHandlerLibrary_lock);\n+  _adapter_handler_table->iterate(findblob);\n+  assert(found, \"Should have found handler\");\n@@ -3451,1 +3496,1 @@\n-  if (get_i2c_entry() != NULL) {\n+  if (get_i2c_entry() != nullptr) {\n@@ -3454,1 +3499,1 @@\n-  if (get_c2i_entry() != NULL) {\n+  if (get_c2i_entry() != nullptr) {\n@@ -3457,1 +3502,1 @@\n-  if (get_c2i_unverified_entry() != NULL) {\n+  if (get_c2i_unverified_entry() != nullptr) {\n@@ -3460,1 +3505,1 @@\n-  if (get_c2i_no_clinit_check_entry() != NULL) {\n+  if (get_c2i_no_clinit_check_entry() != nullptr) {\n@@ -3469,1 +3514,1 @@\n-  _adapters->print_statistics();\n+  print_table_statistics();\n@@ -3475,0 +3520,1 @@\n+  assert(current == JavaThread::current(), \"pre-condition\");\n@@ -3483,1 +3529,1 @@\n-  CompiledMethod* nm = NULL;\n+  CompiledMethod* nm = nullptr;\n@@ -3488,2 +3534,10 @@\n-  while (true) {\n-    Method* method = NULL;\n+  RegisterMap map(JavaThread::current(),\n+                  RegisterMap::UpdateMap::skip,\n+                  RegisterMap::ProcessFrames::skip,\n+                  RegisterMap::WalkContinuation::skip); \/\/ don't walk continuations\n+  for (; !fr.is_first_frame(); fr = fr.sender(&map)) {\n+    if (!fr.is_java_frame()) {\n+      continue;\n+    }\n+\n+    Method* method = nullptr;\n@@ -3493,1 +3547,1 @@\n-      if (method != NULL && method->has_reserved_stack_access()) {\n+      if (method != nullptr && method->has_reserved_stack_access()) {\n@@ -3498,1 +3552,1 @@\n-      if (cb != NULL && cb->is_compiled()) {\n+      if (cb != nullptr && cb->is_compiled()) {\n@@ -3503,1 +3557,1 @@\n-        for (ScopeDesc *sd = nm->scope_desc_near(fr.pc()); sd != NULL; sd = sd->sender()) {\n+        for (ScopeDesc *sd = nm->scope_desc_near(fr.pc()); sd != nullptr; sd = sd->sender()) {\n@@ -3505,1 +3559,1 @@\n-          if (method != NULL && method->has_reserved_stack_access()) {\n+          if (method != nullptr && method->has_reserved_stack_access()) {\n@@ -3522,5 +3576,0 @@\n-    if (fr.is_first_java_frame()) {\n-      break;\n-    } else {\n-      fr = fr.java_sender();\n-    }\n@@ -3538,1 +3587,1 @@\n-  if (new_obj == NULL) return;\n+  if (new_obj == nullptr) return;\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":503,"deletions":454,"binary":false,"changes":957,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,2 +30,1 @@\n-#include \"interpreter\/bytecodeTracer.hpp\"\n-#include \"memory\/allocation.hpp\"\n+#include \"memory\/allStatic.hpp\"\n@@ -34,1 +33,0 @@\n-#include \"utilities\/hashtable.hpp\"\n@@ -38,1 +36,0 @@\n-class AdapterHandlerTable;\n@@ -77,0 +74,2 @@\n+  static nmethod*            _cont_doYield_stub;\n+\n@@ -132,0 +131,1 @@\n+  static jfloat  i2f (jint    x);\n@@ -134,1 +134,0 @@\n-  static jfloat  i2f (jint    x);\n@@ -218,1 +217,1 @@\n-    assert(_ic_miss_blob!= NULL, \"oops\");\n+    assert(_ic_miss_blob!= nullptr, \"oops\");\n@@ -223,1 +222,1 @@\n-    assert(_wrong_method_blob!= NULL, \"oops\");\n+    assert(_wrong_method_blob!= nullptr, \"oops\");\n@@ -228,1 +227,1 @@\n-    assert(_wrong_method_abstract_blob!= NULL, \"oops\");\n+    assert(_wrong_method_abstract_blob!= nullptr, \"oops\");\n@@ -238,1 +237,1 @@\n-    assert(_resolve_opt_virtual_call_blob != NULL, \"oops\");\n+    assert(_resolve_opt_virtual_call_blob != nullptr, \"oops\");\n@@ -242,1 +241,1 @@\n-    assert(_resolve_virtual_call_blob != NULL, \"oops\");\n+    assert(_resolve_virtual_call_blob != nullptr, \"oops\");\n@@ -246,1 +245,1 @@\n-    assert(_resolve_static_call_blob != NULL, \"oops\");\n+    assert(_resolve_static_call_blob != nullptr, \"oops\");\n@@ -254,0 +253,5 @@\n+  static nmethod* cont_doYield_stub() {\n+    assert(_cont_doYield_stub != nullptr, \"oops\");\n+    return _cont_doYield_stub;\n+  }\n+\n@@ -261,1 +265,9 @@\n-  static void throw_and_post_jvmti_exception(JavaThread* current, Symbol* name, const char *message = NULL);\n+  static void throw_and_post_jvmti_exception(JavaThread* current, Symbol* name, const char *message = nullptr);\n+\n+#if INCLUDE_JVMTI\n+  \/\/ Functions for JVMTI notifications\n+  static void notify_jvmti_vthread_start(oopDesc* vt, jboolean hide, JavaThread* current);\n+  static void notify_jvmti_vthread_end(oopDesc* vt, jboolean hide, JavaThread* current);\n+  static void notify_jvmti_vthread_mount(oopDesc* vt, jboolean hide, JavaThread* current);\n+  static void notify_jvmti_vthread_unmount(oopDesc* vt, jboolean hide, JavaThread* current);\n+#endif\n@@ -269,2 +281,0 @@\n-  static oop retrieve_receiver(Symbol* sig, frame caller);\n-\n@@ -274,2 +284,3 @@\n-  static int dtrace_object_alloc(oopDesc* o, int size);\n-  static int dtrace_object_alloc_base(Thread* thread, oopDesc* o, int size);\n+  static int dtrace_object_alloc(oopDesc* o);\n+  static int dtrace_object_alloc(JavaThread* thread, oopDesc* o);\n+  static int dtrace_object_alloc(JavaThread* thread, oopDesc* o, size_t size);\n@@ -372,1 +383,1 @@\n-  static jlong get_java_tid(Thread* thread);\n+  static jlong get_java_tid(JavaThread* thread);\n@@ -375,1 +386,1 @@\n-  \/\/ used by native wrappers to reenable yellow if overflow happened in native code\n+  \/\/ used by native wrappers to re-enable yellow if overflow happened in native code\n@@ -404,1 +415,1 @@\n-  static char* generate_class_cast_message(Klass* caster_klass, Klass* target_klass, Symbol* target_klass_name = NULL);\n+  static char* generate_class_cast_message(Klass* caster_klass, Klass* target_klass, Symbol* target_klass_name = nullptr);\n@@ -468,1 +479,1 @@\n-  \/\/ NULL is being passed as the second VMRegPair array, so arguments are either\n+  \/\/ null is being passed as the second VMRegPair array, so arguments are either\n@@ -477,2 +488,0 @@\n-  static size_t trampoline_size();\n-\n@@ -567,2 +576,1 @@\n-  \/\/ is a JNI critical method, or a compiled method handle adapter,\n-  \/\/ such as _invokeBasic, _linkToVirtual, etc.\n+  \/\/ is a compiled method handle adapter, such as _invokeBasic, _linkToVirtual, etc.\n@@ -574,2 +582,1 @@\n-                                          BasicType ret_type,\n-                                          address critical_entry);\n+                                          BasicType ret_type);\n@@ -597,1 +604,1 @@\n-  \/\/ wrong method handling (inline cache misses, zombie methods)\n+  \/\/ wrong method handling (inline cache misses)\n@@ -604,13 +611,0 @@\n-#ifdef COMPILER2\n-  static RuntimeStub* make_native_invoker(address call_target,\n-                                          int shadow_space_bytes,\n-                                          const GrowableArray<VMReg>& input_registers,\n-                                          const GrowableArray<VMReg>& output_registers);\n-#endif\n-\n-  static void compute_move_order(const BasicType* in_sig_bt,\n-                                 int total_in_args, const VMRegPair* in_regs,\n-                                 int total_out_args, VMRegPair* out_regs,\n-                                 GrowableArray<int>& arg_order,\n-                                 VMRegPair tmp_vmreg);\n-\n@@ -628,1 +622,0 @@\n-  static int _throw_null_ctr;                    \/\/ throwing a null-pointer exception\n@@ -649,1 +642,1 @@\n-  static int _multi1_ctr, _multi2_ctr, _multi3_ctr, _multi4_ctr, _multi5_ctr;\n+  static int _multi2_ctr, _multi3_ctr, _multi4_ctr, _multi5_ctr;\n@@ -661,1 +654,0 @@\n-  static int64_t _nof_optimized_calls;            \/\/ total # of statically-bound calls\n@@ -667,2 +659,0 @@\n-  static int64_t _nof_optimized_interface_calls;  \/\/ total # of statically-bound interface calls\n-  static int64_t _nof_megamorphic_interface_calls;\/\/ total # of megamorphic interface calls\n@@ -673,1 +663,0 @@\n-  static address nof_optimized_calls_addr()             { return (address)&_nof_optimized_calls; }\n@@ -678,2 +667,0 @@\n-  static address nof_optimized_interface_calls_addr()   { return (address)&_nof_optimized_interface_calls; }\n-  static address nof_megamorphic_interface_calls_addr() { return (address)&_nof_megamorphic_interface_calls; }\n@@ -722,2 +709,1 @@\n-class AdapterHandlerEntry : public BasicHashtableEntry<mtCode> {\n-  friend class AdapterHandlerTable;\n+class AdapterHandlerEntry : public CHeapObj<mtCode> {\n@@ -740,6 +726,8 @@\n-  void init(AdapterFingerPrint* fingerprint, address i2c_entry, address c2i_entry, address c2i_unverified_entry, address c2i_no_clinit_check_entry) {\n-    _fingerprint = fingerprint;\n-    _i2c_entry = i2c_entry;\n-    _c2i_entry = c2i_entry;\n-    _c2i_unverified_entry = c2i_unverified_entry;\n-    _c2i_no_clinit_check_entry = c2i_no_clinit_check_entry;\n+  AdapterHandlerEntry(AdapterFingerPrint* fingerprint, address i2c_entry, address c2i_entry,\n+                      address c2i_unverified_entry,\n+                      address c2i_no_clinit_check_entry) :\n+    _fingerprint(fingerprint),\n+    _i2c_entry(i2c_entry),\n+    _c2i_entry(c2i_entry),\n+    _c2i_unverified_entry(c2i_unverified_entry),\n+    _c2i_no_clinit_check_entry(c2i_no_clinit_check_entry)\n@@ -747,1 +735,1 @@\n-    _saved_code_length = 0;\n+    , _saved_code_length(0)\n@@ -749,3 +737,1 @@\n-  }\n-\n-  void deallocate();\n+  { }\n@@ -753,2 +739,1 @@\n-  \/\/ should never be used\n-  AdapterHandlerEntry();\n+  ~AdapterHandlerEntry();\n@@ -767,4 +752,0 @@\n-  AdapterHandlerEntry* next() {\n-    return (AdapterHandlerEntry*)BasicHashtableEntry<mtCode>::next();\n-  }\n-\n@@ -785,1 +766,0 @@\n-  static AdapterHandlerTable* _adapters;\n@@ -806,1 +786,1 @@\n-                                        address c2i_no_clinit_check_entry = NULL);\n+                                        address c2i_no_clinit_check_entry = nullptr);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":49,"deletions":69,"binary":false,"changes":118,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,0 +27,1 @@\n+#include \"gc\/shared\/suspendibleThreadSet.hpp\"\n@@ -37,1 +38,1 @@\n-#include \"runtime\/biasedLocking.hpp\"\n+#include \"runtime\/frame.inline.hpp\"\n@@ -41,0 +42,2 @@\n+#include \"runtime\/javaThread.hpp\"\n+#include \"runtime\/lockStack.inline.hpp\"\n@@ -52,1 +55,1 @@\n-#include \"runtime\/thread.inline.hpp\"\n+#include \"runtime\/threads.hpp\"\n@@ -59,0 +62,1 @@\n+#include \"utilities\/linkedlist.hpp\"\n@@ -61,0 +65,39 @@\n+class ObjectMonitorsHashtable::PtrList :\n+  public LinkedListImpl<ObjectMonitor*,\n+                        AnyObj::C_HEAP, mtThread,\n+                        AllocFailStrategy::RETURN_NULL> {};\n+\n+class CleanupObjectMonitorsHashtable: StackObj {\n+ public:\n+  bool do_entry(void*& key, ObjectMonitorsHashtable::PtrList*& list) {\n+    list->clear();  \/\/ clear the LinkListNodes\n+    delete list;    \/\/ then delete the LinkedList\n+    return true;\n+  }\n+};\n+\n+ObjectMonitorsHashtable::~ObjectMonitorsHashtable() {\n+  CleanupObjectMonitorsHashtable cleanup;\n+  _ptrs->unlink(&cleanup);  \/\/ cleanup the LinkedLists\n+  delete _ptrs;             \/\/ then delete the hash table\n+}\n+\n+void ObjectMonitorsHashtable::add_entry(void* key, ObjectMonitor* om) {\n+  ObjectMonitorsHashtable::PtrList* list = get_entry(key);\n+  if (list == nullptr) {\n+    \/\/ Create new list and add it to the hash table:\n+    list = new (mtThread) ObjectMonitorsHashtable::PtrList;\n+    add_entry(key, list);\n+  }\n+  list->add(om);  \/\/ Add the ObjectMonitor to the list.\n+  _om_count++;\n+}\n+\n+bool ObjectMonitorsHashtable::has_entry(void* key, ObjectMonitor* om) {\n+  ObjectMonitorsHashtable::PtrList* list = get_entry(key);\n+  if (list == nullptr || list->find(om) == nullptr) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n@@ -88,1 +131,1 @@\n-  ObjectMonitor* prev = NULL;\n+  ObjectMonitor* prev = nullptr;\n@@ -91,2 +134,2 @@\n-  \/\/ The in-use list head can be NULL during the final audit.\n-  while (m != NULL) {\n+  \/\/ The in-use list head can be null during the final audit.\n+  while (m != nullptr) {\n@@ -105,2 +148,2 @@\n-      } while (next != NULL && next->is_being_async_deflated());\n-      if (prev == NULL) {\n+      } while (next != nullptr && next->is_being_async_deflated());\n+      if (prev == nullptr) {\n@@ -130,1 +173,1 @@\n-      ObjectSynchronizer::chk_for_block_req(current->as_Java_thread(), \"unlinking\",\n+      ObjectSynchronizer::chk_for_block_req(JavaThread::cast(current), \"unlinking\",\n@@ -163,1 +206,1 @@\n-  char* bytes = NULL;                                                      \\\n+  char* bytes = nullptr;                                                      \\\n@@ -167,1 +210,1 @@\n-  if (klassname != NULL) {                                                 \\\n+  if (klassname != nullptr) {                                                 \\\n@@ -202,1 +245,1 @@\n-int dtrace_waited_probe(ObjectMonitor* monitor, Handle obj, Thread* thr) {\n+int dtrace_waited_probe(ObjectMonitor* monitor, Handle obj, JavaThread* thr) {\n@@ -207,2 +250,10 @@\n-static const int NINFLATIONLOCKS = 256;\n-static os::PlatformMutex* gInflationLocks[NINFLATIONLOCKS];\n+static constexpr size_t inflation_lock_count() {\n+  return 256;\n+}\n+\n+\/\/ Static storage for an array of PlatformMutex.\n+alignas(PlatformMutex) static uint8_t _inflation_locks[inflation_lock_count()][sizeof(PlatformMutex)];\n+\n+static inline PlatformMutex* inflation_lock(size_t index) {\n+  return reinterpret_cast<PlatformMutex*>(_inflation_locks[index]);\n+}\n@@ -211,2 +262,2 @@\n-  for (int i = 0; i < NINFLATIONLOCKS; i++) {\n-    gInflationLocks[i] = new os::PlatformMutex();\n+  for (size_t i = 0; i < inflation_lock_count(); i++) {\n+    ::new(static_cast<void*>(inflation_lock(i))) PlatformMutex();\n@@ -216,0 +267,3 @@\n+\n+  \/\/ Start the timer for deflations, so it does not trigger immediately.\n+  _last_async_deflation_time_ns = os::javaTimeNanos();\n@@ -244,0 +298,1 @@\n+static bool _no_progress_skip_increment = false;\n@@ -270,1 +325,1 @@\n-  if (obj == NULL) return false;  \/\/ slow-path for invalid obj\n+  if (obj == nullptr) return false;  \/\/ slow-path for invalid obj\n@@ -273,4 +328,12 @@\n-  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n-    \/\/ Degenerate notify\n-    \/\/ stack-locked by caller so by definition the implied waitset is empty.\n-    return true;\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    if (mark.is_fast_locked() && current->lock_stack().contains(cast_to_oop(obj))) {\n+      \/\/ Degenerate notify\n+      \/\/ fast-locked by caller so by definition the implied waitset is empty.\n+      return true;\n+    }\n+  } else if (LockingMode == LM_LEGACY) {\n+    if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+      \/\/ Degenerate notify\n+      \/\/ stack-locked by caller so by definition the implied waitset is empty.\n+      return true;\n+    }\n@@ -284,1 +347,1 @@\n-    if (mon->first_waiter() != NULL) {\n+    if (mon->first_waiter() != nullptr) {\n@@ -297,1 +360,1 @@\n-      } while (mon->first_waiter() != NULL && all);\n+      } while (mon->first_waiter() != nullptr && all);\n@@ -303,1 +366,1 @@\n-  \/\/ biased locking and any other IMS exception states take the slow-path\n+  \/\/ other IMS exception states take the slow-path\n@@ -318,1 +381,1 @@\n-  if (obj == NULL) return false;       \/\/ Need to throw NPE\n+  if (obj == nullptr) return false;       \/\/ Need to throw NPE\n@@ -331,1 +394,1 @@\n-    if (m->object_peek() == NULL) {\n+    if (m->object_peek() == nullptr) {\n@@ -334,1 +397,1 @@\n-    JavaThread* const owner = (JavaThread*) m->owner_raw();\n+    JavaThread* const owner = static_cast<JavaThread*>(m->owner_raw());\n@@ -343,0 +406,1 @@\n+      current->inc_held_monitor_count();\n@@ -346,13 +410,14 @@\n-    \/\/ This Java Monitor is inflated so obj's header will never be\n-    \/\/ displaced to this thread's BasicLock. Make the displaced header\n-    \/\/ non-NULL so this BasicLock is not seen as recursive nor as\n-    \/\/ being locked. We do this unconditionally so that this thread's\n-    \/\/ BasicLock cannot be mis-interpreted by any stack walkers. For\n-    \/\/ performance reasons, stack walkers generally first check for\n-    \/\/ Biased Locking in the object's header, the second check is for\n-    \/\/ stack-locking in the object's header, the third check is for\n-    \/\/ recursive stack-locking in the displaced header in the BasicLock,\n-    \/\/ and last are the inflated Java Monitor (ObjectMonitor) checks.\n-    lock->set_displaced_header(markWord::unused_mark());\n-\n-    if (owner == NULL && m->try_set_owner_from(NULL, current) == NULL) {\n+    if (LockingMode != LM_LIGHTWEIGHT) {\n+      \/\/ This Java Monitor is inflated so obj's header will never be\n+      \/\/ displaced to this thread's BasicLock. Make the displaced header\n+      \/\/ non-null so this BasicLock is not seen as recursive nor as\n+      \/\/ being locked. We do this unconditionally so that this thread's\n+      \/\/ BasicLock cannot be mis-interpreted by any stack walkers. For\n+      \/\/ performance reasons, stack walkers generally first check for\n+      \/\/ stack-locking in the object's header, the second check is for\n+      \/\/ recursive stack-locking in the displaced header in the BasicLock,\n+      \/\/ and last are the inflated Java Monitor (ObjectMonitor) checks.\n+      lock->set_displaced_header(markWord::unused_mark());\n+    }\n+\n+    if (owner == nullptr && m->try_set_owner_from(nullptr, current) == nullptr) {\n@@ -360,0 +425,1 @@\n+      current->inc_held_monitor_count();\n@@ -367,1 +433,0 @@\n-  \/\/ -- perform bias revocation, or\n@@ -391,1 +456,1 @@\n-    current->print_stack_on(&ss);\n+    current->print_active_stack_on(&ss);\n@@ -394,1 +459,1 @@\n-    if (newline != NULL) {\n+    if (newline != nullptr) {\n@@ -406,1 +471,1 @@\n-      current->print_stack_on(&info_stream);\n+      current->print_active_stack_on(&info_stream);\n@@ -423,0 +488,8 @@\n+static bool useHeavyMonitors() {\n+#if defined(X86) || defined(AARCH64) || defined(PPC64) || defined(RISCV64) || defined(S390)\n+  return LockingMode == LM_MONITOR;\n+#else\n+  return false;\n+#endif\n+}\n+\n@@ -434,6 +507,38 @@\n-  if (UseBiasedLocking) {\n-    BiasedLocking::revoke(current, obj);\n-  }\n-\n-  markWord mark = obj->mark();\n-  assert(!mark.has_bias_pattern(), \"should not see bias pattern here\");\n+  current->inc_held_monitor_count();\n+\n+  if (!useHeavyMonitors()) {\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      \/\/ Fast-locking does not use the 'lock' argument.\n+      LockStack& lock_stack = current->lock_stack();\n+      if (lock_stack.can_push()) {\n+        markWord mark = obj()->mark_acquire();\n+        if (mark.is_neutral()) {\n+          assert(!lock_stack.contains(obj()), \"thread must not already hold the lock\");\n+          \/\/ Try to swing into 'fast-locked' state.\n+          markWord locked_mark = mark.set_fast_locked();\n+          markWord old_mark = obj()->cas_set_mark(locked_mark, mark);\n+          if (old_mark == mark) {\n+            \/\/ Successfully fast-locked, push object to lock-stack and return.\n+            lock_stack.push(obj());\n+            return;\n+          }\n+        }\n+      }\n+      \/\/ All other paths fall-through to inflate-enter.\n+    } else if (LockingMode == LM_LEGACY) {\n+      markWord mark = obj->mark();\n+      if (mark.is_neutral()) {\n+        \/\/ Anticipate successful CAS -- the ST of the displaced mark must\n+        \/\/ be visible <= the ST performed by the CAS.\n+        lock->set_displaced_header(mark);\n+        if (mark == obj()->cas_set_mark(markWord::from_pointer(lock), mark)) {\n+          return;\n+        }\n+        \/\/ Fall through to inflate() ...\n+      } else if (mark.has_locker() &&\n+                 current->is_lock_owned((address) mark.locker())) {\n+        assert(lock != mark.locker(), \"must not re-lock the same lock\");\n+        assert(lock != (BasicLock*) obj->mark().value(), \"don't relock with same BasicLock\");\n+        lock->set_displaced_header(markWord::from_pointer(nullptr));\n+        return;\n+      }\n@@ -441,6 +546,5 @@\n-  if (mark.is_neutral()) {\n-    \/\/ Anticipate successful CAS -- the ST of the displaced mark must\n-    \/\/ be visible <= the ST performed by the CAS.\n-    lock->set_displaced_header(mark);\n-    if (mark == obj()->cas_set_mark(markWord::from_pointer(lock), mark)) {\n-      return;\n+      \/\/ The object header will never be displaced to this lock,\n+      \/\/ so it does not matter what the value is, except that it\n+      \/\/ must be non-zero to avoid looking like a re-entrant lock,\n+      \/\/ and must not look locked either.\n+      lock->set_displaced_header(markWord::unused_mark());\n@@ -448,7 +552,2 @@\n-    \/\/ Fall through to inflate() ...\n-  } else if (mark.has_locker() &&\n-             current->is_lock_owned((address)mark.locker())) {\n-    assert(lock != mark.locker(), \"must not re-lock the same lock\");\n-    assert(lock != (BasicLock*)obj->mark().value(), \"don't relock with same BasicLock\");\n-    lock->set_displaced_header(markWord::from_pointer(NULL));\n-    return;\n+  } else if (VerifyHeavyMonitors) {\n+    guarantee((obj->mark().value() & markWord::lock_mask_in_place) != markWord::locked_value, \"must not be lightweight\/stack-locked\");\n@@ -457,5 +556,0 @@\n-  \/\/ The object header will never be displaced to this lock,\n-  \/\/ so it does not matter what the value is, except that it\n-  \/\/ must be non-zero to avoid looking like a re-entrant lock,\n-  \/\/ and must not look locked either.\n-  lock->set_displaced_header(markWord::unused_mark());\n@@ -474,29 +568,23 @@\n-  markWord mark = object->mark();\n-  \/\/ We cannot check for Biased Locking if we are racing an inflation.\n-  assert(mark == markWord::INFLATING() ||\n-         !mark.has_bias_pattern(), \"should not see bias pattern here\");\n-\n-  markWord dhw = lock->displaced_header();\n-  if (dhw.value() == 0) {\n-    \/\/ If the displaced header is NULL, then this exit matches up with\n-    \/\/ a recursive enter. No real work to do here except for diagnostics.\n-#ifndef PRODUCT\n-    if (mark != markWord::INFLATING()) {\n-      \/\/ Only do diagnostics if we are not racing an inflation. Simply\n-      \/\/ exiting a recursive enter of a Java Monitor that is being\n-      \/\/ inflated is safe; see the has_monitor() comment below.\n-      assert(!mark.is_neutral(), \"invariant\");\n-      assert(!mark.has_locker() ||\n-             current->is_lock_owned((address)mark.locker()), \"invariant\");\n-      if (mark.has_monitor()) {\n-        \/\/ The BasicLock's displaced_header is marked as a recursive\n-        \/\/ enter and we have an inflated Java Monitor (ObjectMonitor).\n-        \/\/ This is a special case where the Java Monitor was inflated\n-        \/\/ after this thread entered the stack-lock recursively. When a\n-        \/\/ Java Monitor is inflated, we cannot safely walk the Java\n-        \/\/ Monitor owner's stack and update the BasicLocks because a\n-        \/\/ Java Monitor can be asynchronously inflated by a thread that\n-        \/\/ does not own the Java Monitor.\n-        ObjectMonitor* m = mark.monitor();\n-        assert(m->object()->mark() == mark, \"invariant\");\n-        assert(m->is_entered(current), \"invariant\");\n+  current->dec_held_monitor_count();\n+\n+  if (!useHeavyMonitors()) {\n+    markWord mark = object->mark();\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      \/\/ Fast-locking does not use the 'lock' argument.\n+      if (mark.is_fast_locked()) {\n+        markWord unlocked_mark = mark.set_unlocked();\n+        markWord old_mark = object->cas_set_mark(unlocked_mark, mark);\n+        if (old_mark != mark) {\n+          \/\/ Another thread won the CAS, it must have inflated the monitor.\n+          \/\/ It can only have installed an anonymously locked monitor at this point.\n+          \/\/ Fetch that monitor, set owner correctly to this thread, and\n+          \/\/ exit it (allowing waiting threads to enter).\n+          assert(old_mark.has_monitor(), \"must have monitor\");\n+          ObjectMonitor* monitor = old_mark.monitor();\n+          assert(monitor->is_owner_anonymous(), \"must be anonymous owner\");\n+          monitor->set_owner_from_anonymous(current);\n+          monitor->exit(current);\n+        }\n+        LockStack& lock_stack = current->lock_stack();\n+        lock_stack.remove(object);\n+        return;\n@@ -504,1 +592,27 @@\n-    }\n+    } else if (LockingMode == LM_LEGACY) {\n+      markWord dhw = lock->displaced_header();\n+      if (dhw.value() == 0) {\n+        \/\/ If the displaced header is null, then this exit matches up with\n+        \/\/ a recursive enter. No real work to do here except for diagnostics.\n+#ifndef PRODUCT\n+        if (mark != markWord::INFLATING()) {\n+          \/\/ Only do diagnostics if we are not racing an inflation. Simply\n+          \/\/ exiting a recursive enter of a Java Monitor that is being\n+          \/\/ inflated is safe; see the has_monitor() comment below.\n+          assert(!mark.is_neutral(), \"invariant\");\n+          assert(!mark.has_locker() ||\n+                 current->is_lock_owned((address)mark.locker()), \"invariant\");\n+          if (mark.has_monitor()) {\n+            \/\/ The BasicLock's displaced_header is marked as a recursive\n+            \/\/ enter and we have an inflated Java Monitor (ObjectMonitor).\n+            \/\/ This is a special case where the Java Monitor was inflated\n+            \/\/ after this thread entered the stack-lock recursively. When a\n+            \/\/ Java Monitor is inflated, we cannot safely walk the Java\n+            \/\/ Monitor owner's stack and update the BasicLocks because a\n+            \/\/ Java Monitor can be asynchronously inflated by a thread that\n+            \/\/ does not own the Java Monitor.\n+            ObjectMonitor* m = mark.monitor();\n+            assert(m->object()->mark() == mark, \"invariant\");\n+            assert(m->is_entered(current), \"invariant\");\n+          }\n+        }\n@@ -506,2 +620,2 @@\n-    return;\n-  }\n+        return;\n+      }\n@@ -509,6 +623,8 @@\n-  if (mark == markWord::from_pointer(lock)) {\n-    \/\/ If the object is stack-locked by the current thread, try to\n-    \/\/ swing the displaced header from the BasicLock back to the mark.\n-    assert(dhw.is_neutral(), \"invariant\");\n-    if (object->cas_set_mark(dhw, mark) == mark) {\n-      return;\n+      if (mark == markWord::from_pointer(lock)) {\n+        \/\/ If the object is stack-locked by the current thread, try to\n+        \/\/ swing the displaced header from the BasicLock back to the mark.\n+        assert(dhw.is_neutral(), \"invariant\");\n+        if (object->cas_set_mark(dhw, mark) == mark) {\n+          return;\n+        }\n+      }\n@@ -516,0 +632,2 @@\n+  } else if (VerifyHeavyMonitors) {\n+    guarantee((object->mark().value() & markWord::lock_mask_in_place) != markWord::locked_value, \"must not be lightweight\/stack-locked\");\n@@ -522,52 +640,6 @@\n-  monitor->exit(current);\n-}\n-\n-\/\/ -----------------------------------------------------------------------------\n-\/\/ Class Loader  support to workaround deadlocks on the class loader lock objects\n-\/\/ Also used by GC\n-\/\/ complete_exit()\/reenter() are used to wait on a nested lock\n-\/\/ i.e. to give up an outer lock completely and then re-enter\n-\/\/ Used when holding nested locks - lock acquisition order: lock1 then lock2\n-\/\/  1) complete_exit lock1 - saving recursion count\n-\/\/  2) wait on lock2\n-\/\/  3) when notified on lock2, unlock lock2\n-\/\/  4) reenter lock1 with original recursion count\n-\/\/  5) lock lock2\n-\/\/ NOTE: must use heavy weight monitor to handle complete_exit\/reenter()\n-\/\/ NOTE(TSAN): We cannot instrument complete_exit\/reenter in ObjectSynchronizer\n-\/\/             in a manner similar to wait and waitUninterruptibly, because\n-\/\/             (1) recursion count stored by inflated monitor is different from\n-\/\/             the absolute recursion count tracked by Tsan, and (2) in the\n-\/\/             general case, we cannot merely store Tsan's recursion count\n-\/\/             once: we must track it for *each invocation* of complete_exit.\n-\/\/             Hence, the best place to instrument for Tsan is at the call site\n-\/\/             for complete_exit\/reenter. Luckily, there is only one call site.\n-intx ObjectSynchronizer::complete_exit(Handle obj, JavaThread* current) {\n-  if (UseBiasedLocking) {\n-    BiasedLocking::revoke(current, obj);\n-    assert(!obj->mark().has_bias_pattern(), \"biases should be revoked by now\");\n-  }\n-\n-  \/\/ The ObjectMonitor* can't be async deflated until ownership is\n-  \/\/ dropped inside exit() and the ObjectMonitor* must be !is_busy().\n-  ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_vm_internal);\n-  intptr_t ret_code = monitor->complete_exit(current);\n-  return ret_code;\n-}\n-\n-\/\/ NOTE: must use heavy weight monitor to handle complete_exit\/reenter()\n-void ObjectSynchronizer::reenter(Handle obj, intx recursions, JavaThread* current) {\n-  if (UseBiasedLocking) {\n-    BiasedLocking::revoke(current, obj);\n-    assert(!obj->mark().has_bias_pattern(), \"biases should be revoked by now\");\n-  }\n-\n-  \/\/ An async deflation can race after the inflate() call and before\n-  \/\/ reenter() -> enter() can make the ObjectMonitor busy. reenter() ->\n-  \/\/ enter() returns false if we have lost the race to async deflation\n-  \/\/ and we simply try again.\n-  while (true) {\n-    ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_vm_internal);\n-    if (monitor->reenter(recursions, current)) {\n-      return;\n-    }\n+  if (LockingMode == LM_LIGHTWEIGHT && monitor->is_owner_anonymous()) {\n+    \/\/ It must be owned by us. Pop lock object from lock stack.\n+    LockStack& lock_stack = current->lock_stack();\n+    oop popped = lock_stack.pop();\n+    assert(popped == object, \"must be owned by this thread\");\n+    monitor->set_owner_from_anonymous(current);\n@@ -575,0 +647,1 @@\n+  monitor->exit(current);\n@@ -586,4 +659,0 @@\n-  if (UseBiasedLocking) {\n-    BiasedLocking::revoke(current, obj);\n-    assert(!obj->mark().has_bias_pattern(), \"biases should be revoked by now\");\n-  }\n@@ -597,0 +666,1 @@\n+      current->inc_held_monitor_count(1, true);\n@@ -607,6 +677,0 @@\n-  if (UseBiasedLocking) {\n-    Handle h_obj(current, obj);\n-    BiasedLocking::revoke(current, h_obj);\n-    obj = h_obj();\n-  }\n-  assert(!obj->mark().has_bias_pattern(), \"biases should be revoked by now\");\n@@ -623,0 +687,1 @@\n+    current->dec_held_monitor_count(1, true);\n@@ -634,1 +699,1 @@\n-  if (_obj() != NULL) {\n+  if (_obj() != nullptr) {\n@@ -641,1 +706,1 @@\n-  if (_obj() != NULL) {\n+  if (_obj() != nullptr) {\n@@ -653,4 +718,0 @@\n-  if (UseBiasedLocking) {\n-    BiasedLocking::revoke(current, obj);\n-    assert(!obj->mark().has_bias_pattern(), \"biases should be revoked by now\");\n-  }\n@@ -685,20 +746,0 @@\n-\/\/ No exception are possible in this case as we only use this internally when locking is\n-\/\/ correct and we have to wait until notified - so no interrupts or timeouts.\n-void ObjectSynchronizer::wait_uninterruptibly(Handle obj, JavaThread* current) {\n-  if (UseBiasedLocking) {\n-    BiasedLocking::revoke(current, obj);\n-    assert(!obj->mark().has_bias_pattern(), \"biases should be revoked by now\");\n-  }\n-  \/\/ The ObjectMonitor* can't be async deflated because the _waiters\n-  \/\/ field is incremented before ownership is dropped and decremented\n-  \/\/ after ownership is regained.\n-  ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_wait);\n-  TSAN_ONLY(int tsan_rec;)\n-  TSAN_RUNTIME_ONLY(\n-    tsan_rec = SharedRuntime::tsan_oop_rec_unlock(current, obj());\n-    assert(tsan_rec > 0, \"tsan: unlocking unlocked mutex\");\n-  );\n-  monitor->wait(0 \/* wait-forever *\/, false \/* not interruptible *\/, current);\n-  TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_rec_lock(current, obj(), tsan_rec));\n-}\n-\n@@ -707,4 +748,0 @@\n-  if (UseBiasedLocking) {\n-    BiasedLocking::revoke(current, obj);\n-    assert(!obj->mark().has_bias_pattern(), \"biases should be revoked by now\");\n-  }\n@@ -713,3 +750,10 @@\n-  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n-    \/\/ Not inflated so there can't be any waiters to notify.\n-    return;\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    if ((mark.is_fast_locked() && current->lock_stack().contains(obj()))) {\n+      \/\/ Not inflated so there can't be any waiters to notify.\n+      return;\n+    }\n+  } else if (LockingMode == LM_LEGACY) {\n+    if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+      \/\/ Not inflated so there can't be any waiters to notify.\n+      return;\n+    }\n@@ -726,4 +770,0 @@\n-  if (UseBiasedLocking) {\n-    BiasedLocking::revoke(current, obj);\n-    assert(!obj->mark().has_bias_pattern(), \"biases should be revoked by now\");\n-  }\n@@ -732,3 +772,10 @@\n-  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n-    \/\/ Not inflated so there can't be any waiters to notify.\n-    return;\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    if ((mark.is_fast_locked() && current->lock_stack().contains(obj()))) {\n+      \/\/ Not inflated so there can't be any waiters to notify.\n+      return;\n+    }\n+  } else if (LockingMode == LM_LEGACY) {\n+    if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+      \/\/ Not inflated so there can't be any waiters to notify.\n+      return;\n+    }\n@@ -759,2 +806,3 @@\n-  markWord mark = obj->mark();\n-  if (!mark.is_being_inflated()) {\n+  markWord mark = obj->mark_acquire();\n+  if (!mark.is_being_inflated() || LockingMode == LM_LIGHTWEIGHT) {\n+    \/\/ New lightweight locking does not use the markWord::INFLATING() protocol.\n@@ -766,1 +814,1 @@\n-    markWord mark = obj->mark();\n+    markWord mark = obj->mark_acquire();\n@@ -795,2 +843,2 @@\n-        static_assert(is_power_of_2(NINFLATIONLOCKS), \"must be\");\n-        int ix = (cast_from_oop<intptr_t>(obj) >> 5) & (NINFLATIONLOCKS-1);\n+        static_assert(is_power_of_2(inflation_lock_count()), \"must be\");\n+        size_t ix = (cast_from_oop<intptr_t>(obj) >> 5) & (inflation_lock_count() - 1);\n@@ -798,3 +846,3 @@\n-        assert(ix >= 0 && ix < NINFLATIONLOCKS, \"invariant\");\n-        gInflationLocks[ix]->lock();\n-        while (obj->mark() == markWord::INFLATING()) {\n+        assert(ix < inflation_lock_count(), \"invariant\");\n+        inflation_lock(ix)->lock();\n+        while (obj->mark_acquire() == markWord::INFLATING()) {\n@@ -810,1 +858,1 @@\n-        gInflationLocks[ix]->unlock();\n+        inflation_lock(ix)->unlock();\n@@ -875,0 +923,7 @@\n+\/\/ Can be called from non JavaThreads (e.g., VMThread) for FastHashCode\n+\/\/ calculations as part of JVM\/TI tagging.\n+static bool is_lock_owned(Thread* thread, oop obj) {\n+  assert(LockingMode == LM_LIGHTWEIGHT, \"only call this with new lightweight locking enabled\");\n+  return thread->is_Java_thread() ? JavaThread::cast(thread)->lock_stack().contains(obj) : false;\n+}\n+\n@@ -876,19 +931,0 @@\n-  if (UseBiasedLocking) {\n-    \/\/ NOTE: many places throughout the JVM do not expect a safepoint\n-    \/\/ to be taken here. However, we only ever bias Java instances and all\n-    \/\/ of the call sites of identity_hash that might revoke biases have\n-    \/\/ been checked to make sure they can handle a safepoint. The\n-    \/\/ added check of the bias pattern is to avoid useless calls to\n-    \/\/ thread-local storage.\n-    if (obj->mark().has_bias_pattern()) {\n-      \/\/ Handle for oop obj in case of STW safepoint\n-      Handle hobj(current, obj);\n-      if (SafepointSynchronize::is_at_safepoint()) {\n-        BiasedLocking::revoke_at_safepoint(hobj);\n-      } else {\n-        BiasedLocking::revoke(current->as_Java_thread(), hobj);\n-      }\n-      obj = hobj();\n-      assert(!obj->mark().has_bias_pattern(), \"biases should be revoked by now\");\n-    }\n-  }\n@@ -897,1 +933,1 @@\n-    ObjectMonitor* monitor = NULL;\n+    ObjectMonitor* monitor = nullptr;\n@@ -901,4 +937,4 @@\n-\n-    \/\/ object should remain ineligible for biased locking\n-    assert(!mark.has_bias_pattern(), \"invariant\");\n-\n+    if (VerifyHeavyMonitors) {\n+      assert(LockingMode == LM_MONITOR, \"+VerifyHeavyMonitors requires LockingMode == 0 (LM_MONITOR)\");\n+      guarantee((obj->mark().value() & markWord::lock_mask_in_place) != markWord::locked_value, \"must not be lightweight\/stack-locked\");\n+    }\n@@ -948,2 +984,9 @@\n-    } else if (current->is_lock_owned((address)mark.locker())) {\n-      \/\/ This is a stack lock owned by the calling thread so fetch the\n+    } else if (LockingMode == LM_LIGHTWEIGHT && mark.is_fast_locked() && is_lock_owned(current, obj)) {\n+      \/\/ This is a fast-lock owned by the calling thread so use the\n+      \/\/ markWord from the object.\n+      hash = mark.hash();\n+      if (hash != 0) {                  \/\/ if it has a hash, just return it\n+        return hash;\n+      }\n+    } else if (LockingMode == LM_LEGACY && mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+      \/\/ This is a stack-lock owned by the calling thread so fetch the\n@@ -960,1 +1003,1 @@\n-      \/\/ So we have to inflate the stack lock into an ObjectMonitor\n+      \/\/ So we have to inflate the stack-lock into an ObjectMonitor\n@@ -1006,7 +1049,0 @@\n-\/\/ Deprecated -- use FastHashCode() instead.\n-\n-intptr_t ObjectSynchronizer::identity_hash_value_for(Handle obj) {\n-  return FastHashCode(Thread::current(), obj());\n-}\n-\n-\n@@ -1015,5 +1051,0 @@\n-  if (UseBiasedLocking) {\n-    BiasedLocking::revoke(current, h_obj);\n-    assert(!h_obj->mark().has_bias_pattern(), \"biases should be revoked by now\");\n-  }\n-\n@@ -1025,2 +1056,2 @@\n-  \/\/ Uncontended case, header points to stack\n-  if (mark.has_locker()) {\n+  if (LockingMode == LM_LEGACY && mark.has_locker()) {\n+    \/\/ stack-locked case, header points into owner's stack\n@@ -1029,1 +1060,6 @@\n-  \/\/ Contended case, header points to ObjectMonitor (tagged pointer)\n+\n+  if (LockingMode == LM_LIGHTWEIGHT && mark.is_fast_locked()) {\n+    \/\/ fast-locking case, see if lock is in current's lock stack\n+    return current->lock_stack().contains(h_obj());\n+  }\n+\n@@ -1031,0 +1067,1 @@\n+    \/\/ Inflated monitor so header points to ObjectMonitor (tagged pointer).\n@@ -1041,12 +1078,0 @@\n-\/\/ FIXME: jvmti should call this\n-  if (UseBiasedLocking) {\n-    if (SafepointSynchronize::is_at_safepoint()) {\n-      BiasedLocking::revoke_at_safepoint(h_obj);\n-    } else {\n-      BiasedLocking::revoke(JavaThread::current(), h_obj);\n-    }\n-    assert(!h_obj->mark().has_bias_pattern(), \"biases should be revoked by now\");\n-  }\n-\n-  address owner = NULL;\n-\n@@ -1057,3 +1082,4 @@\n-  \/\/ Uncontended case, header points to stack\n-  if (mark.has_locker()) {\n-    owner = (address) mark.locker();\n+  if (LockingMode == LM_LEGACY && mark.has_locker()) {\n+    \/\/ stack-locked so header points into owner's stack.\n+    \/\/ owning_thread_from_monitor_owner() may also return null here:\n+    return Threads::owning_thread_from_monitor_owner(t_list, (address) mark.locker());\n@@ -1062,2 +1088,8 @@\n-  \/\/ Contended case, header points to ObjectMonitor (tagged pointer)\n-  else if (mark.has_monitor()) {\n+  if (LockingMode == LM_LIGHTWEIGHT && mark.is_fast_locked()) {\n+    \/\/ fast-locked so get owner from the object.\n+    \/\/ owning_thread_from_object() may also return null here:\n+    return Threads::owning_thread_from_object(t_list, h_obj());\n+  }\n+\n+  if (mark.has_monitor()) {\n+    \/\/ Inflated monitor so header points to ObjectMonitor (tagged pointer).\n@@ -1067,7 +1099,3 @@\n-    assert(monitor != NULL, \"monitor should be non-null\");\n-    owner = (address) monitor->owner();\n-  }\n-\n-  if (owner != NULL) {\n-    \/\/ owning_thread_from_monitor_owner() may also return NULL here\n-    return Threads::owning_thread_from_monitor_owner(t_list, owner);\n+    assert(monitor != nullptr, \"monitor should be non-null\");\n+    \/\/ owning_thread_from_monitor() may also return null here:\n+    return Threads::owning_thread_from_monitor(t_list, monitor);\n@@ -1081,1 +1109,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1086,1 +1114,6 @@\n-void ObjectSynchronizer::monitors_iterate(MonitorClosure* closure) {\n+\/\/ Iterate ObjectMonitors where the owner == thread; this does NOT include\n+\/\/ ObjectMonitors where owner is set to a stack-lock address in thread.\n+\/\/\n+\/\/ This version of monitors_iterate() works with the in-use monitor list.\n+\/\/\n+void ObjectSynchronizer::monitors_iterate(MonitorClosure* closure, JavaThread* thread) {\n@@ -1090,1 +1123,31 @@\n-    if (!mid->is_being_async_deflated() && mid->object_peek() != NULL) {\n+    if (mid->owner() != thread) {\n+      \/\/ Not owned by the target thread and intentionally skips when owner\n+      \/\/ is set to a stack-lock address in the target thread.\n+      continue;\n+    }\n+    if (!mid->is_being_async_deflated() && mid->object_peek() != nullptr) {\n+      \/\/ Only process with closure if the object is set.\n+\n+      \/\/ monitors_iterate() is only called at a safepoint or when the\n+      \/\/ target thread is suspended or when the target thread is\n+      \/\/ operating on itself. The current closures in use today are\n+      \/\/ only interested in an owned ObjectMonitor and ownership\n+      \/\/ cannot be dropped under the calling contexts so the\n+      \/\/ ObjectMonitor cannot be async deflated.\n+      closure->do_monitor(mid);\n+    }\n+  }\n+}\n+\n+\/\/ This version of monitors_iterate() works with the specified linked list.\n+\/\/\n+void ObjectSynchronizer::monitors_iterate(MonitorClosure* closure,\n+                                          ObjectMonitorsHashtable::PtrList* list,\n+                                          JavaThread* thread) {\n+  typedef LinkedListIterator<ObjectMonitor*> ObjectMonitorIterator;\n+  ObjectMonitorIterator iter(list->head());\n+  while (!iter.is_empty()) {\n+    ObjectMonitor* mid = *iter.next();\n+    \/\/ Owner set to a stack-lock address in thread should never be seen here:\n+    assert(mid->owner() == thread, \"must be\");\n+    if (!mid->is_being_async_deflated() && mid->object_peek() != nullptr) {\n@@ -1133,1 +1196,8 @@\n-  return int(monitor_usage) > MonitorUsedDeflationThreshold;\n+  if (int(monitor_usage) > MonitorUsedDeflationThreshold) {\n+    log_info(monitorinflation)(\"monitors_used=\" SIZE_FORMAT \", ceiling=\" SIZE_FORMAT\n+                               \", monitor_usage=\" SIZE_FORMAT \", threshold=\" INTX_FORMAT,\n+                               monitors_used, ceiling, monitor_usage, MonitorUsedDeflationThreshold);\n+    return true;\n+  }\n+\n+  return false;\n@@ -1155,0 +1225,1 @@\n+    log_info(monitorinflation)(\"Async deflation needed: explicit request\");\n@@ -1157,0 +1228,3 @@\n+\n+  jlong time_since_last = time_since_last_async_deflation_ms();\n+\n@@ -1158,1 +1232,1 @@\n-      time_since_last_async_deflation_ms() > AsyncDeflationInterval &&\n+      time_since_last > AsyncDeflationInterval &&\n@@ -1164,0 +1238,27 @@\n+    log_info(monitorinflation)(\"Async deflation needed: monitors used are above the threshold\");\n+    return true;\n+  }\n+\n+  if (GuaranteedAsyncDeflationInterval > 0 &&\n+      time_since_last > GuaranteedAsyncDeflationInterval) {\n+    \/\/ It's been longer than our specified guaranteed deflate interval.\n+    \/\/ We need to clean up the used monitors even if the threshold is\n+    \/\/ not reached, to keep the memory utilization at bay when many threads\n+    \/\/ touched many monitors.\n+    log_info(monitorinflation)(\"Async deflation needed: guaranteed interval (\" INTX_FORMAT \" ms) \"\n+                               \"is greater than time since last deflation (\" JLONG_FORMAT \" ms)\",\n+                               GuaranteedAsyncDeflationInterval, time_since_last);\n+\n+    \/\/ If this deflation has no progress, then it should not affect the no-progress\n+    \/\/ tracking, otherwise threshold heuristics would think it was triggered, experienced\n+    \/\/ no progress, and needs to backoff more aggressively. In this \"no progress\" case,\n+    \/\/ the generic code would bump the no-progress counter, and we compensate for that\n+    \/\/ by telling it to skip the update.\n+    \/\/\n+    \/\/ If this deflation has progress, then it should let non-progress tracking\n+    \/\/ know about this, otherwise the threshold heuristics would kick in, potentially\n+    \/\/ experience no-progress due to aggressive cleanup by this deflation, and think\n+    \/\/ it is still in no-progress stride. In this \"progress\" case, the generic code would\n+    \/\/ zero the counter, and we allow it to happen.\n+    _no_progress_skip_increment = true;\n+\n@@ -1166,0 +1267,1 @@\n+\n@@ -1206,2 +1308,1 @@\n-  assert(event != NULL, \"invariant\");\n-  assert(event->should_commit(), \"invariant\");\n+  assert(event != nullptr, \"invariant\");\n@@ -1216,1 +1317,1 @@\n-  markWord mark = obj->mark();\n+  markWord mark = obj->mark_acquire();\n@@ -1231,2 +1332,1 @@\n-    const markWord mark = object->mark();\n-    assert(!mark.has_bias_pattern(), \"invariant\");\n+    const markWord mark = object->mark_acquire();\n@@ -1235,5 +1335,11 @@\n-    \/\/ *  Inflated     - just return\n-    \/\/ *  Stack-locked - coerce it to inflated\n-    \/\/ *  INFLATING    - busy wait for conversion to complete\n-    \/\/ *  Neutral      - aggressively inflate the object.\n-    \/\/ *  BIASED       - Illegal.  We should never see this\n+    \/\/ *  inflated     - Just return if using stack-locking.\n+    \/\/                   If using fast-locking and the ObjectMonitor owner\n+    \/\/                   is anonymous and the current thread owns the\n+    \/\/                   object lock, then we make the current thread the\n+    \/\/                   ObjectMonitor owner and remove the lock from the\n+    \/\/                   current thread's lock stack.\n+    \/\/ *  fast-locked  - Coerce it to inflated from fast-locked.\n+    \/\/ *  stack-locked - Coerce it to inflated from stack-locked.\n+    \/\/ *  INFLATING    - Busy wait for conversion from stack-locked to\n+    \/\/                   inflated.\n+    \/\/ *  neutral      - Aggressively inflate the object.\n@@ -1246,0 +1352,4 @@\n+      if (LockingMode == LM_LIGHTWEIGHT && inf->is_owner_anonymous() && is_lock_owned(current, object)) {\n+        inf->set_owner_from_anonymous(current);\n+        JavaThread::cast(current)->lock_stack().remove(object);\n+      }\n@@ -1249,9 +1359,64 @@\n-    \/\/ CASE: inflation in progress - inflating over a stack-lock.\n-    \/\/ Some other thread is converting from stack-locked to inflated.\n-    \/\/ Only that thread can complete inflation -- other threads must wait.\n-    \/\/ The INFLATING value is transient.\n-    \/\/ Currently, we spin\/yield\/park and poll the markword, waiting for inflation to finish.\n-    \/\/ We could always eliminate polling by parking the thread on some auxiliary list.\n-    if (mark == markWord::INFLATING()) {\n-      read_stable_mark(object);\n-      continue;\n+    if (LockingMode != LM_LIGHTWEIGHT) {\n+      \/\/ New lightweight locking does not use INFLATING.\n+      \/\/ CASE: inflation in progress - inflating over a stack-lock.\n+      \/\/ Some other thread is converting from stack-locked to inflated.\n+      \/\/ Only that thread can complete inflation -- other threads must wait.\n+      \/\/ The INFLATING value is transient.\n+      \/\/ Currently, we spin\/yield\/park and poll the markword, waiting for inflation to finish.\n+      \/\/ We could always eliminate polling by parking the thread on some auxiliary list.\n+      if (mark == markWord::INFLATING()) {\n+        read_stable_mark(object);\n+        continue;\n+      }\n+    }\n+\n+    \/\/ CASE: fast-locked\n+    \/\/ Could be fast-locked either by current or by some other thread.\n+    \/\/\n+    \/\/ Note that we allocate the ObjectMonitor speculatively, _before_\n+    \/\/ attempting to set the object's mark to the new ObjectMonitor. If\n+    \/\/ this thread owns the monitor, then we set the ObjectMonitor's\n+    \/\/ owner to this thread. Otherwise, we set the ObjectMonitor's owner\n+    \/\/ to anonymous. If we lose the race to set the object's mark to the\n+    \/\/ new ObjectMonitor, then we just delete it and loop around again.\n+    \/\/\n+    LogStreamHandle(Trace, monitorinflation) lsh;\n+    if (LockingMode == LM_LIGHTWEIGHT && mark.is_fast_locked()) {\n+      ObjectMonitor* monitor = new ObjectMonitor(object);\n+      monitor->set_header(mark.set_unlocked());\n+      bool own = is_lock_owned(current, object);\n+      if (own) {\n+        \/\/ Owned by us.\n+        monitor->set_owner_from(nullptr, current);\n+      } else {\n+        \/\/ Owned by somebody else.\n+        monitor->set_owner_anonymous();\n+      }\n+      markWord monitor_mark = markWord::encode(monitor);\n+      markWord old_mark = object->cas_set_mark(monitor_mark, mark);\n+      if (old_mark == mark) {\n+        \/\/ Success! Return inflated monitor.\n+        if (own) {\n+          JavaThread::cast(current)->lock_stack().remove(object);\n+        }\n+        \/\/ Once the ObjectMonitor is configured and object is associated\n+        \/\/ with the ObjectMonitor, it is safe to allow async deflation:\n+        _in_use_list.add(monitor);\n+\n+        \/\/ Hopefully the performance counters are allocated on distinct\n+        \/\/ cache lines to avoid false sharing on MP systems ...\n+        OM_PERFDATA_OP(Inflations, inc());\n+        if (log_is_enabled(Trace, monitorinflation)) {\n+          ResourceMark rm(current);\n+          lsh.print_cr(\"inflate(has_locker): object=\" INTPTR_FORMAT \", mark=\"\n+                       INTPTR_FORMAT \", type='%s'\", p2i(object),\n+                       object->mark().value(), object->klass()->external_name());\n+        }\n+        if (event.should_commit()) {\n+          post_monitor_inflate_event(&event, object, cause);\n+        }\n+        return monitor;\n+      } else {\n+        delete monitor;\n+        continue;  \/\/ Interference -- just retry\n+      }\n@@ -1261,1 +1426,1 @@\n-    \/\/ Could be stack-locked either by this thread or by some other thread.\n+    \/\/ Could be stack-locked either by current or by some other thread.\n@@ -1268,5 +1433,5 @@\n-    \/\/ the odds of inflation contention.\n-\n-    LogStreamHandle(Trace, monitorinflation) lsh;\n-\n-    if (mark.has_locker()) {\n+    \/\/ the odds of inflation contention. If we lose the race to set INFLATING,\n+    \/\/ then we just delete the ObjectMonitor and loop around again.\n+    \/\/\n+    if (LockingMode == LM_LEGACY && mark.has_locker()) {\n+      assert(LockingMode != LM_LIGHTWEIGHT, \"cannot happen with new lightweight locking\");\n@@ -1326,2 +1491,2 @@\n-      \/\/ with CAS.  That is, we can avoid the xchg-NULL .... ST idiom.\n-      m->set_owner_from(NULL, mark.locker());\n+      \/\/ with CAS.  That is, we can avoid the xchg-nullptr .... ST idiom.\n+      m->set_owner_from(nullptr, mark.locker());\n@@ -1361,1 +1526,1 @@\n-    \/\/ to inflate and then CAS() again to try to swing _owner from NULL to current.\n+    \/\/ to inflate and then CAS() again to try to swing _owner from null to current.\n@@ -1373,1 +1538,1 @@\n-      m = NULL;\n+      m = nullptr;\n@@ -1408,1 +1573,1 @@\n-  if (ls != NULL) {\n+  if (ls != nullptr) {\n@@ -1421,1 +1586,1 @@\n-  if (ls != NULL) {\n+  if (ls != nullptr) {\n@@ -1431,0 +1596,8 @@\n+\/\/\n+\/\/ If table != nullptr, we gather owned ObjectMonitors indexed by the\n+\/\/ owner in the table. Please note that ObjectMonitors where the owner\n+\/\/ is set to a stack-lock address are NOT associated with the JavaThread\n+\/\/ that holds that stack-lock. All of the current consumers of\n+\/\/ ObjectMonitorsHashtable info only care about JNI locked monitors and\n+\/\/ those do not have the owner set to a stack-lock address.\n+\/\/\n@@ -1432,1 +1605,2 @@\n-                                                elapsedTimer* timer_p) {\n+                                                elapsedTimer* timer_p,\n+                                                ObjectMonitorsHashtable* table) {\n@@ -1443,0 +1617,12 @@\n+    } else if (table != nullptr) {\n+      \/\/ The caller is interested in the owned ObjectMonitors. This does\n+      \/\/ not include when owner is set to a stack-lock address in thread.\n+      \/\/ This also does not capture unowned ObjectMonitors that cannot be\n+      \/\/ deflated because of a waiter.\n+      void* key = mid->owner();\n+      \/\/ Since deflate_idle_monitors() and deflate_monitor_list() can be\n+      \/\/ called more than once, we have to make sure the entry has not\n+      \/\/ already been added.\n+      if (key != nullptr && !table->has_entry(key, mid)) {\n+        table->add_entry(key, mid);\n+      }\n@@ -1447,1 +1633,1 @@\n-      chk_for_block_req(current->as_Java_thread(), \"deflation\", \"deflated_count\",\n+      chk_for_block_req(JavaThread::cast(current), \"deflation\", \"deflated_count\",\n@@ -1465,0 +1651,19 @@\n+class VM_RendezvousGCThreads : public VM_Operation {\n+public:\n+  bool evaluate_at_safepoint() const override { return false; }\n+  VMOp_Type type() const override { return VMOp_RendezvousGCThreads; }\n+  void doit() override {\n+    SuspendibleThreadSet::synchronize();\n+    SuspendibleThreadSet::desynchronize();\n+  };\n+};\n+\n+static size_t delete_monitors(GrowableArray<ObjectMonitor*>* delete_list) {\n+  size_t count = 0;\n+  for (ObjectMonitor* monitor: *delete_list) {\n+    delete monitor;\n+    count++;\n+  }\n+  return count;\n+}\n+\n@@ -1467,2 +1672,2 @@\n-\/\/ by the VMThread.\n-size_t ObjectSynchronizer::deflate_idle_monitors() {\n+\/\/ and VM_ThreadDump::doit() by the VMThread.\n+size_t ObjectSynchronizer::deflate_idle_monitors(ObjectMonitorsHashtable* table) {\n@@ -1478,1 +1683,1 @@\n-  LogStream* ls = NULL;\n+  LogStream* ls = nullptr;\n@@ -1486,1 +1691,1 @@\n-  if (ls != NULL) {\n+  if (ls != nullptr) {\n@@ -1493,1 +1698,3 @@\n-  size_t deflated_count = deflate_monitor_list(current, ls, &timer);\n+  size_t deflated_count = deflate_monitor_list(current, ls, &timer, table);\n+  size_t unlinked_count = 0;\n+  size_t deleted_count = 0;\n@@ -1503,4 +1710,3 @@\n-    size_t unlinked_count = _in_use_list.unlink_deflated(current, ls, &timer,\n-                                                         &delete_list);\n-    if (current->is_Java_thread()) {\n-      if (ls != NULL) {\n+    unlinked_count = _in_use_list.unlink_deflated(current, ls, &timer, &delete_list);\n+    if (current->is_monitor_deflation_thread()) {\n+      if (ls != nullptr) {\n@@ -1519,0 +1725,5 @@\n+      \/\/ Also, we sync and desync GC threads around the handshake, so that they can\n+      \/\/ safely read the mark-word and look-through to the object-monitor, without\n+      \/\/ being afraid that the object-monitor is going away.\n+      VM_RendezvousGCThreads sync_gc;\n+      VMThread::execute(&sync_gc);\n@@ -1520,1 +1731,1 @@\n-      if (ls != NULL) {\n+      if (ls != nullptr) {\n@@ -1526,0 +1737,4 @@\n+    } else {\n+      \/\/ This is not a monitor deflation thread.\n+      \/\/ No handshake or rendezvous is needed when we are already at safepoint.\n+      assert_at_safepoint();\n@@ -1529,10 +1744,9 @@\n-    \/\/ deflated in this cycle.\n-    size_t deleted_count = 0;\n-    for (ObjectMonitor* monitor: delete_list) {\n-      delete monitor;\n-      deleted_count++;\n-\n-      if (current->is_Java_thread()) {\n-        \/\/ A JavaThread must check for a safepoint\/handshake and honor it.\n-        chk_for_block_req(current->as_Java_thread(), \"deletion\", \"deleted_count\",\n-                          deleted_count, ls, &timer);\n+    \/\/ deflated and unlinked in this cycle.\n+    if (current->is_Java_thread()) {\n+      if (ls != NULL) {\n+        timer.stop();\n+        ls->print_cr(\"before setting blocked: unlinked_count=\" SIZE_FORMAT\n+                     \", in_use_list stats: ceiling=\" SIZE_FORMAT \", count=\"\n+                     SIZE_FORMAT \", max=\" SIZE_FORMAT,\n+                     unlinked_count, in_use_list_ceiling(),\n+                     _in_use_list.count(), _in_use_list.max());\n@@ -1540,0 +1754,14 @@\n+      \/\/ Mark the calling JavaThread blocked (safepoint safe) while we free\n+      \/\/ the ObjectMonitors so we don't delay safepoints whilst doing that.\n+      ThreadBlockInVM tbivm(JavaThread::cast(current));\n+      if (ls != NULL) {\n+        ls->print_cr(\"after setting blocked: in_use_list stats: ceiling=\"\n+                     SIZE_FORMAT \", count=\" SIZE_FORMAT \", max=\" SIZE_FORMAT,\n+                     in_use_list_ceiling(), _in_use_list.count(), _in_use_list.max());\n+        timer.start();\n+      }\n+      deleted_count = delete_monitors(&delete_list);\n+      \/\/ ThreadBlockInVM is destroyed here\n+    } else {\n+      \/\/ A non-JavaThread can just free the ObjectMonitors:\n+      deleted_count = delete_monitors(&delete_list);\n@@ -1541,0 +1769,1 @@\n+    assert(unlinked_count == deleted_count, \"must be\");\n@@ -1543,1 +1772,1 @@\n-  if (ls != NULL) {\n+  if (ls != nullptr) {\n@@ -1545,3 +1774,3 @@\n-    if (deflated_count != 0 || log_is_enabled(Debug, monitorinflation)) {\n-      ls->print_cr(\"deflated \" SIZE_FORMAT \" monitors in %3.7f secs\",\n-                   deflated_count, timer.seconds());\n+    if (deflated_count != 0 || unlinked_count != 0 || log_is_enabled(Debug, monitorinflation)) {\n+      ls->print_cr(\"deflated_count=\" SIZE_FORMAT \", {unlinked,deleted}_count=\" SIZE_FORMAT \" monitors in %3.7f secs\",\n+                   deflated_count, unlinked_count, timer.seconds());\n@@ -1551,0 +1780,4 @@\n+    if (table != nullptr) {\n+      ls->print_cr(\"ObjectMonitorsHashtable: key_count=\" SIZE_FORMAT \", om_count=\" SIZE_FORMAT,\n+                   table->key_count(), table->om_count());\n+    }\n@@ -1560,0 +1793,2 @@\n+  } else if (_no_progress_skip_increment) {\n+    _no_progress_skip_increment = false;\n@@ -1577,7 +1812,6 @@\n-    if (mid->owner() == _thread) {\n-      \/\/ Note well -- this occurs ONLY on thread exit, and is a last ditch\n-      \/\/ effort to release all locks. Hence, we don't need to record tsan's\n-      \/\/ recursion count -- it will never be locked again.\n-      TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_rec_unlock(_thread, (oop)mid->object()));\n-      (void)mid->complete_exit(_thread);\n-    }\n+    \/\/ Note well -- this occurs ONLY on thread exit, and is a last ditch\n+    \/\/ effort to release all locks. Hence, we don't need to record tsan's\n+    \/\/ recursion count -- it will never be locked again.\n+    TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_rec_unlock(_thread, (oop)mid->object()));\n+    intx rec = mid->complete_exit(_thread);\n+    _thread->dec_held_monitor_count(rec + 1);\n@@ -1606,1 +1840,1 @@\n-  ObjectSynchronizer::monitors_iterate(&rjmc);\n+  ObjectSynchronizer::monitors_iterate(&rjmc, current);\n@@ -1609,0 +1843,3 @@\n+  assert(current->held_monitor_count() == 0, \"Should not be possible\");\n+  \/\/ All monitors (including entered via JNI) have been unlocked above, so we need to clear jni count.\n+  current->clear_jni_monitor_count();\n@@ -1654,0 +1891,1 @@\n+  log_info(monitorinflation)(\"Starting the final audit.\");\n@@ -1656,1 +1894,1 @@\n-    \/\/ Do a deflation in order to reduce the in-use monitor population\n+    \/\/ Do deflations in order to reduce the in-use monitor population\n@@ -1659,1 +1897,1 @@\n-    while (ObjectSynchronizer::deflate_idle_monitors() != 0) {\n+    while (deflate_idle_monitors(\/* ObjectMonitorsHashtable is not needed here *\/ nullptr) > 0) {\n@@ -1663,2 +1901,2 @@\n-    \/\/ level at a safepoint in ObjectSynchronizer::do_safepoint_work().\n-    ObjectSynchronizer::audit_and_print_stats(true \/* on_exit *\/);\n+    \/\/ level at a safepoint in SafepointSynchronize::do_cleanup_tasks.\n+    audit_and_print_stats(true \/* on_exit *\/);\n@@ -1684,1 +1922,1 @@\n-  LogStream* ls = NULL;\n+  LogStream* ls = nullptr;\n@@ -1692,1 +1930,1 @@\n-  assert(ls != NULL, \"sanity check\");\n+  assert(ls != nullptr, \"sanity check\");\n@@ -1763,1 +2001,1 @@\n-                  \"have non-NULL _header field.\", p2i(n));\n+                  \"have non-null _header field.\", p2i(n));\n@@ -1767,1 +2005,1 @@\n-  if (obj != NULL) {\n+  if (obj != nullptr) {\n@@ -1805,2 +2043,2 @@\n-                 mid->is_busy(), mark.hash() != 0, mid->owner() != NULL,\n-                 p2i(obj), obj == NULL ? \"\" : obj->klass()->external_name());\n+                 mid->is_busy(), mark.hash() != 0, mid->owner() != nullptr,\n+                 p2i(obj), obj == nullptr ? \"\" : obj->klass()->external_name());\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":601,"deletions":363,"binary":false,"changes":964,"status":"modified"},{"patch":"@@ -233,1 +233,1 @@\n-          bitmap_((mem_end - mem_begin) \/ HeapWordSize) {}\n+          bitmap_((mem_end - mem_begin) \/ HeapWordSize, mtInternal) {}\n@@ -240,1 +240,1 @@\n-      return bitmap_.get_next_one_offset(to_idx(from), idx_to) == idx_to;\n+      return bitmap_.find_first_set_bit(to_idx(from), idx_to) == idx_to;\n@@ -426,2 +426,0 @@\n-    GCTraceTime(Debug, gc) tt_top(\"Tsan relocate\");\n-    GCTraceCPUTime tcpu;\n@@ -435,1 +433,0 @@\n-      GCTraceTime(Debug, gc) tt_collect(\"Collect oops\");\n@@ -446,2 +443,0 @@\n-      GCTraceTime(Debug, gc) tt_disjoint(\"Move between regions\");\n-\n@@ -464,2 +459,0 @@\n-      GCTraceTime(Debug, gc) tt_sort(\"Sort moves\");\n-\n@@ -471,1 +464,0 @@\n-      GCTraceTime(Debug, gc) tt_sort(\"Move\");\n","filename":"src\/hotspot\/share\/tsan\/tsanOopMap.cpp","additions":2,"deletions":10,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -43,1 +43,1 @@\n-\/\/ concatenation is performed.  Note: One auxilliary level ought to be\n+\/\/ concatenation is performed.  Note: One auxiliary level ought to be\n@@ -49,0 +49,6 @@\n+\/\/ Convenience macro that produces a string literal with the filename\n+\/\/ and linenumber of the location where the macro was used.\n+#ifndef FILE_AND_LINE\n+#define FILE_AND_LINE __FILE__ \":\" XSTR(__LINE__)\n+#endif\n+\n@@ -52,0 +58,4 @@\n+#ifndef FILE_AND_LINE\n+#define FILE_AND_LINE __FILE__ \":\" XSTR(__LINE__)\n+#endif\n+\n@@ -129,0 +139,1 @@\n+#define MANAGEMENT_ONLY(x) x\n@@ -132,0 +143,1 @@\n+#define MANAGEMENT_ONLY(x)\n@@ -242,16 +254,0 @@\n-#ifndef INCLUDE_NMT\n-#define INCLUDE_NMT 1\n-#endif \/\/ INCLUDE_NMT\n-\n-#if INCLUDE_NMT\n-#define NOT_NMT_RETURN        \/* next token must be ; *\/\n-#define NOT_NMT_RETURN_(code) \/* next token must be ; *\/\n-#define NMT_ONLY(x) x\n-#define NOT_NMT(x)\n-#else\n-#define NOT_NMT_RETURN        {}\n-#define NOT_NMT_RETURN_(code) { return code; }\n-#define NMT_ONLY(x)\n-#define NOT_NMT(x) x\n-#endif \/\/ INCLUDE_NMT\n-\n@@ -548,1 +544,1 @@\n-\/\/ 2. 64-bit port:   -DAARCH64 -D_LP64 -DTARGET_ARCH_aaarch64\n+\/\/ 2. 64-bit port:   -DAARCH64 -D_LP64 -DTARGET_ARCH_aarch64\n@@ -573,0 +569,6 @@\n+#ifdef TARGET_ARCH_aarch64\n+#define AARCH64_PORT_ONLY(code) code\n+#else\n+#define AARCH64_PORT_ONLY(code)\n+#endif\n+\n@@ -575,0 +577,26 @@\n+#if defined(RISCV32) || defined(RISCV64)\n+#define RISCV\n+#define RISCV_ONLY(code) code\n+#define NOT_RISCV(code)\n+#else\n+#undef RISCV\n+#define RISCV_ONLY(code)\n+#define NOT_RISCV(code) code\n+#endif\n+\n+#ifdef RISCV32\n+#define RISCV32_ONLY(code) code\n+#define NOT_RISCV32(code)\n+#else\n+#define RISCV32_ONLY(code)\n+#define NOT_RISCV32(code) code\n+#endif\n+\n+#ifdef RISCV64\n+#define RISCV64_ONLY(code) code\n+#define NOT_RISCV64(code)\n+#else\n+#define RISCV64_ONLY(code)\n+#define NOT_RISCV64(code) code\n+#endif\n+\n","filename":"src\/hotspot\/share\/utilities\/macros.hpp","additions":47,"deletions":19,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -38,1 +38,1 @@\n-    private static ReferenceQueue<Object> queue = new ReferenceQueue<>();\n+    private static ReferenceQueue<Object> queue = new NativeReferenceQueue<>();\n@@ -64,0 +64,4 @@\n+    static final boolean ENABLED = isFinalizationEnabled();\n+\n+    private static native boolean isFinalizationEnabled();\n+\n@@ -66,1 +70,5 @@\n-        new Finalizer(finalizee);\n+        if (ENABLED) {\n+            new Finalizer(finalizee);\n+        } else {\n+            throw new InternalError(\"unexpected call to Finalizer::register when finalization is disabled\");\n+        }\n@@ -94,0 +102,1 @@\n+                reportComplete(finalizee);\n@@ -103,0 +112,2 @@\n+    private static native void reportComplete(Object finalizee);\n+\n@@ -135,1 +146,1 @@\n-        if (VM.initLevel() == 0) {\n+        if (VM.initLevel() == 0 || ! ENABLED) {\n@@ -163,10 +174,0 @@\n-            \/\/ Finalizer thread starts before System.initializeSystemClass\n-            \/\/ is called.  Wait until JavaLangAccess is available\n-            while (VM.initLevel() == 0) {\n-                \/\/ delay until VM completes initialization\n-                try {\n-                    VM.awaitInitLevel(1);\n-                } catch (InterruptedException x) {\n-                    \/\/ ignore and continue\n-                }\n-            }\n@@ -190,9 +191,10 @@\n-    static {\n-        ThreadGroup tg = Thread.currentThread().getThreadGroup();\n-        for (ThreadGroup tgn = tg;\n-             tgn != null;\n-             tg = tgn, tgn = tg.getParent());\n-        Thread finalizer = new FinalizerThread(tg);\n-        finalizer.setPriority(Thread.MAX_PRIORITY - 2);\n-        finalizer.setDaemon(true);\n-        finalizer.start();\n+    \/**\n+     * Start the Finalizer thread as a daemon thread.\n+     *\/\n+    static void startFinalizerThread(ThreadGroup tg) {\n+        if (ENABLED) {\n+            Thread finalizer = new FinalizerThread(tg);\n+            finalizer.setPriority(Thread.MAX_PRIORITY - 2);\n+            finalizer.setDaemon(true);\n+            finalizer.start();\n+        }\n@@ -200,1 +202,0 @@\n-\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/Finalizer.java","additions":25,"deletions":24,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -36,2 +36,2 @@\n- *      {@link java.nio.file.FileSystems#newFileSystem\n- *      FileSystems.newFileSystem(URI.create(\"jrt:\/\"))}.\n+ *      {@link java.nio.file.FileSystems#getFileSystem\n+ *      FileSystems.getFileSystem(URI.create(\"jrt:\/\"))}.\n@@ -83,0 +83,1 @@\n+    exports java.lang.foreign;\n@@ -141,2 +142,1 @@\n-        jdk.compiler,\n-        jdk.incubator.foreign;\n+        jdk.compiler;\n@@ -145,0 +145,5 @@\n+    \/\/ Note: all modules in the exported list participate in preview  features\n+    \/\/ and therefore if they use preview features they do not need to be\n+    \/\/ compiled with \"--enable-preview\".\n+    \/\/ It is recommended for any modules that do participate that their\n+    \/\/ module declaration be annotated with jdk.internal.javac.ParticipatesInPreview\n@@ -148,0 +153,1 @@\n+        jdk.incubator.vector, \/\/ participates in preview features\n@@ -155,0 +161,1 @@\n+        jdk.charsets,\n@@ -157,0 +164,1 @@\n+        jdk.jfr,\n@@ -158,3 +166,4 @@\n-        jdk.incubator.foreign;\n-    exports jdk.internal.access.foreign to\n-        jdk.incubator.foreign;\n+        jdk.sctp,\n+        jdk.crypto.cryptoki;\n+    exports jdk.internal.foreign to\n+        jdk.incubator.vector;\n@@ -163,0 +172,3 @@\n+    exports jdk.internal.io to\n+        jdk.internal.le,\n+        jdk.jshell;\n@@ -170,2 +182,1 @@\n-        java.naming,\n-        jdk.incubator.foreign;\n+        java.naming;\n@@ -177,1 +188,5 @@\n-    exports jdk.internal.org.objectweb.asm to\n+    exports jdk.internal.classfile to\n+        jdk.jartool,\n+        jdk.jlink,\n+        jdk.jshell;\n+    exports jdk.internal.classfile.attribute to\n@@ -179,3 +194,2 @@\n-        jdk.jfr,\n-    exports jdk.internal.org.objectweb.asm.tree to\n-        jdk.jfr,\n+    exports jdk.internal.classfile.constantpool to\n+        jdk.jartool,\n@@ -184,0 +198,7 @@\n+    exports jdk.internal.classfile.instruction to\n+        jdk.jlink,\n+        jdk.jshell;\n+    exports jdk.internal.org.objectweb.asm to\n+        jdk.jfr;\n+    exports jdk.internal.org.objectweb.asm.tree to\n+        jdk.jfr;\n@@ -209,2 +230,1 @@\n-        jdk.internal.vm.ci,\n-        jdk.incubator.foreign;\n+        jdk.internal.vm.ci;\n@@ -217,2 +237,1 @@\n-        jdk.jpackage,\n-        jdk.incubator.foreign;\n+        jdk.jpackage;\n@@ -228,1 +247,2 @@\n-        jdk.incubator.foreign;\n+        java.net.http,\n+        jdk.naming.dns;\n@@ -235,2 +255,1 @@\n-        jdk.unsupported,\n-        jdk.incubator.foreign;\n+        jdk.unsupported;\n@@ -238,0 +257,1 @@\n+        java.management,\n@@ -239,1 +259,3 @@\n-        jdk.management.agent;\n+        jdk.management,\n+        jdk.management.agent,\n+        jdk.internal.vm.ci;\n@@ -244,1 +266,0 @@\n-        jdk.incubator.foreign,\n@@ -249,4 +270,0 @@\n-    exports jdk.internal.util to\n-            jdk.incubator.foreign;\n-    exports jdk.internal.util.jar to\n-        jdk.jartool;\n@@ -259,0 +276,9 @@\n+    exports jdk.internal.util to\n+        java.desktop,\n+        java.prefs,\n+        java.security.jgss,\n+        java.smartcardio,\n+        jdk.charsets,\n+        jdk.jlink,\n+        jdk.jpackage,\n+        jdk.net;\n@@ -281,2 +307,1 @@\n-        jdk.sctp,\n-        jdk.incubator.foreign;\n+        jdk.sctp;\n@@ -301,2 +326,1 @@\n-        jdk.crypto.ec,\n-        jdk.incubator.foreign;\n+        jdk.crypto.ec;\n@@ -322,1 +346,2 @@\n-        java.naming;\n+        java.naming,\n+        jdk.jartool;\n@@ -364,2 +389,0 @@\n-    exports jdk.internal.invoke to\n-        jdk.incubator.foreign;\n@@ -371,0 +394,1 @@\n+    uses java.net.spi.InetAddressResolverProvider;\n@@ -400,0 +424,1 @@\n+    uses jdk.internal.io.JdkConsoleProvider;\n","filename":"src\/java.base\/share\/classes\/module-info.java","additions":59,"deletions":34,"binary":false,"changes":93,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1995, 2018, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1995, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -37,40 +37,0 @@\n-#ifdef _MSC_VER\n-#if _MSC_VER > 1400 && _MSC_VER < 1600\n-\n-\/*\n- * When building for Microsoft Windows, main has a dependency on msvcr??.dll.\n- *\n- * When using Visual Studio 2005 or 2008, that must be recorded in\n- * the [java,javaw].exe.manifest file.\n- *\n- * As of VS2010 (ver=1600), the runtimes again no longer need manifests.\n- *\n- * Reference:\n- *     C:\/Program Files\/Microsoft SDKs\/Windows\/v6.1\/include\/crtdefs.h\n- *\/\n-#include <crtassem.h>\n-#ifdef _M_IX86\n-\n-#pragma comment(linker,\"\/manifestdependency:\\\"type='win32' \"            \\\n-        \"name='\" __LIBRARIES_ASSEMBLY_NAME_PREFIX \".CRT' \"              \\\n-        \"version='\" _CRT_ASSEMBLY_VERSION \"' \"                          \\\n-        \"processorArchitecture='x86' \"                                  \\\n-        \"publicKeyToken='\" _VC_ASSEMBLY_PUBLICKEYTOKEN \"'\\\"\")\n-\n-#endif \/* _M_IX86 *\/\n-\n-\/\/This may not be necessary yet for the Windows 64-bit build, but it\n-\/\/will be when that build environment is updated.  Need to test to see\n-\/\/if it is harmless:\n-#ifdef _M_AMD64\n-\n-#pragma comment(linker,\"\/manifestdependency:\\\"type='win32' \"            \\\n-        \"name='\" __LIBRARIES_ASSEMBLY_NAME_PREFIX \".CRT' \"              \\\n-        \"version='\" _CRT_ASSEMBLY_VERSION \"' \"                          \\\n-        \"processorArchitecture='amd64' \"                                \\\n-        \"publicKeyToken='\" _VC_ASSEMBLY_PUBLICKEYTOKEN \"'\\\"\")\n-\n-#endif  \/* _M_AMD64 *\/\n-#endif  \/* _MSC_VER > 1400 && _MSC_VER < 1600 *\/\n-#endif  \/* _MSC_VER *\/\n-\n","filename":"src\/java.base\/share\/native\/launcher\/main.c","additions":1,"deletions":41,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019 Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021 Oracle and\/or its affiliates. All rights reserved.\n@@ -8,1 +8,3 @@\n- * published by the Free Software Foundation.\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n@@ -44,0 +46,9 @@\n+JNIEXPORT void JNICALL\n+Java_java_lang_ref_Finalizer_reportComplete(JNIEnv* env, jclass cls, jobject finalizee) {\n+    JVM_ReportFinalizationComplete(env, finalizee);\n+}\n+\n+JNIEXPORT jboolean JNICALL\n+Java_java_lang_ref_Finalizer_isFinalizationEnabled(JNIEnv* env, jclass cls) {\n+    return JVM_IsFinalizationEnabled(env);\n+}\n","filename":"src\/java.base\/share\/native\/libjava\/Finalizer.c","additions":13,"deletions":2,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1995, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1995, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -54,0 +54,2 @@\n+#include <assert.h>\n+\n@@ -111,1 +113,0 @@\n-static void SetJvmEnvironment(int argc, char **argv);\n@@ -125,1 +126,1 @@\n-static void PrintJavaVersion(JNIEnv *env, jboolean extraLF);\n+static void PrintJavaVersion(JNIEnv *env);\n@@ -295,3 +296,0 @@\n-    \/* Set env. Must be done before LoadJavaVM. *\/\n-    SetJvmEnvironment(argc, argv);\n-\n@@ -417,1 +415,3 @@\n-    jmethodID mainID;\n+    jmethodID mainID;\n+    jmethodID constructor;\n+    jobject mainObject;\n@@ -457,1 +457,1 @@\n-        PrintJavaVersion(env, showVersion);\n+        PrintJavaVersion(env);\n@@ -555,6 +555,49 @@\n-    mainID = (*env)->GetStaticMethodID(env, mainClass, \"main\",\n-                                       \"([Ljava\/lang\/String;)V\");\n-    CHECK_EXCEPTION_NULL_LEAVE(mainID);\n-\n-    \/* Invoke main method. *\/\n-    (*env)->CallStaticVoidMethod(env, mainClass, mainID, mainArgs);\n+#define MAIN_WITHOUT_ARGS 1\n+#define MAIN_NONSTATIC 2\n+\n+    jclass helperClass = GetLauncherHelperClass(env);\n+    jmethodID getMainType = (*env)->GetStaticMethodID(env, helperClass,\n+                                                      \"getMainType\",\n+                                                      \"()I\");\n+    CHECK_EXCEPTION_NULL_LEAVE(getMainType);\n+    int mainType = (*env)->CallStaticIntMethod(env, helperClass, getMainType);\n+    CHECK_EXCEPTION_LEAVE(mainType);\n+\n+    switch (mainType) {\n+    case 0: {\n+        mainID = (*env)->GetStaticMethodID(env, mainClass, \"main\",\n+                                           \"([Ljava\/lang\/String;)V\");\n+        CHECK_EXCEPTION_NULL_LEAVE(mainID);\n+        (*env)->CallStaticVoidMethod(env, mainClass, mainID, mainArgs);\n+        break;\n+        }\n+    case MAIN_WITHOUT_ARGS: {\n+        mainID = (*env)->GetStaticMethodID(env, mainClass, \"main\",\n+                                           \"()V\");\n+        CHECK_EXCEPTION_NULL_LEAVE(mainID);\n+        (*env)->CallStaticVoidMethod(env, mainClass, mainID);\n+        break;\n+        }\n+    case MAIN_NONSTATIC: {\n+        constructor = (*env)->GetMethodID(env, mainClass, \"<init>\", \"()V\");\n+        CHECK_EXCEPTION_NULL_LEAVE(constructor);\n+        mainObject = (*env)->NewObject(env, mainClass, constructor);\n+        CHECK_EXCEPTION_NULL_LEAVE(mainObject);\n+        mainID = (*env)->GetMethodID(env, mainClass, \"main\",\n+                                     \"([Ljava\/lang\/String;)V\");\n+        CHECK_EXCEPTION_NULL_LEAVE(mainID);\n+        (*env)->CallVoidMethod(env, mainObject, mainID, mainArgs);\n+        break;\n+        }\n+    case MAIN_NONSTATIC | MAIN_WITHOUT_ARGS: {\n+        constructor = (*env)->GetMethodID(env, mainClass, \"<init>\", \"()V\");\n+        CHECK_EXCEPTION_NULL_LEAVE(constructor);\n+        mainObject = (*env)->NewObject(env, mainClass, constructor);\n+        CHECK_EXCEPTION_NULL_LEAVE(mainObject);\n+        mainID = (*env)->GetMethodID(env, mainClass, \"main\",\n+                                     \"()V\");\n+        CHECK_EXCEPTION_NULL_LEAVE(mainID);\n+        (*env)->CallVoidMethod(env, mainObject, mainID);\n+        break;\n+        }\n+    }\n@@ -812,78 +855,0 @@\n-\/*\n- * This method must be called before the VM is loaded, primarily\n- * used to parse and set any VM related options or env variables.\n- * This function is non-destructive leaving the argument list intact.\n- *\/\n-static void\n-SetJvmEnvironment(int argc, char **argv) {\n-\n-    static const char*  NMT_Env_Name    = \"NMT_LEVEL_\";\n-    const char* NMT_Arg_Name = IsJavaArgs() ? \"-J-XX:NativeMemoryTracking=\" : \"-XX:NativeMemoryTracking=\";\n-    int i;\n-    \/* process only the launcher arguments *\/\n-    for (i = 0; i < argc; i++) {\n-        char *arg = argv[i];\n-        \/*\n-         * Java launcher (!IsJavaArgs()):\n-         *   Since this must be a VM flag we stop processing once we see\n-         *   an argument the launcher would not have processed beyond (such\n-         *   as -version or -h), or an argument that indicates the following\n-         *   arguments are for the application (i.e. the main class name, or\n-         *   the -jar argument).\n-         * Other launchers (IsJavaArgs()):\n-         *   All arguments have to be scanned to see if it is a -J argument.\n-         *\/\n-        if (!IsJavaArgs() && i > 0) {\n-            char *prev = argv[i - 1];\n-            \/\/ skip non-dash arg preceded by class path specifiers\n-            if (*arg != '-' && IsWhiteSpaceOption(prev)) {\n-                continue;\n-            }\n-\n-            if (*arg != '-' || isTerminalOpt(arg)) {\n-                return;\n-            }\n-        }\n-        \/*\n-         * The following case checks for \"-XX:NativeMemoryTracking=value\".\n-         * If value is non null, an environmental variable set to this value\n-         * will be created to be used by the JVM.\n-         * The argument is passed to the JVM, which will check validity.\n-         * The JVM is responsible for removing the env variable.\n-         *\/\n-        if (JLI_StrCCmp(arg, NMT_Arg_Name) == 0) {\n-            int retval;\n-            \/\/ get what follows this parameter, include \"=\"\n-            size_t pnlen = JLI_StrLen(NMT_Arg_Name);\n-            if (JLI_StrLen(arg) > pnlen) {\n-                char* value = arg + pnlen;\n-                size_t pbuflen = pnlen + JLI_StrLen(value) + 10; \/\/ 10 max pid digits\n-\n-                \/*\n-                 * ensures that malloc successful\n-                 * DONT JLI_MemFree() pbuf.  JLI_PutEnv() uses system call\n-                 *   that could store the address.\n-                 *\/\n-                char * pbuf = (char*)JLI_MemAlloc(pbuflen);\n-\n-                JLI_Snprintf(pbuf, pbuflen, \"%s%d=%s\", NMT_Env_Name, JLI_GetPid(), value);\n-                retval = JLI_PutEnv(pbuf);\n-                if (JLI_IsTraceLauncher()) {\n-                    char* envName;\n-                    char* envBuf;\n-\n-                    \/\/ ensures that malloc successful\n-                    envName = (char*)JLI_MemAlloc(pbuflen);\n-                    JLI_Snprintf(envName, pbuflen, \"%s%d\", NMT_Env_Name, JLI_GetPid());\n-\n-                    printf(\"TRACER_MARKER: NativeMemoryTracking: env var is %s\\n\",envName);\n-                    printf(\"TRACER_MARKER: NativeMemoryTracking: putenv arg %s\\n\",pbuf);\n-                    envBuf = getenv(envName);\n-                    printf(\"TRACER_MARKER: NativeMemoryTracking: got value %s\\n\",envBuf);\n-                    free(envName);\n-                }\n-            }\n-        }\n-    }\n-}\n-\n@@ -1002,1 +967,1 @@\n-    def = JLI_MemAlloc(sizeof(format)\n+    size_t defSize = sizeof(format)\n@@ -1004,2 +969,3 @@\n-                       + JLI_StrLen(s));\n-    sprintf(def, format, s);\n+                       + JLI_StrLen(s);\n+    def = JLI_MemAlloc(defSize);\n+    snprintf(def, defSize, format, s);\n@@ -1060,2 +1026,0 @@\n-    char    *version = NULL;\n-    char    *jre = NULL;\n@@ -1064,2 +1028,0 @@\n-    int     restrict_search = -1;               \/* -1 implies not known *\/\n-    char    env_entry[MAXNAMELEN + 24] = ENV_ENTRY \"=\";\n@@ -1105,1 +1067,1 @@\n-    while ((arg = *argv) != 0 && *arg == '-') {\n+    while (argc > 0 && *(arg = *argv) == '-') {\n@@ -1303,1 +1265,1 @@\n-    char *arg;\n+    char *arg = NULL;\n@@ -1307,1 +1269,1 @@\n-    while ((arg = *argv) != 0 && *arg == '-') {\n+    while (argc > 0 && *(arg = *argv) == '-') {\n@@ -1462,2 +1424,3 @@\n-            char *tmp = JLI_MemAlloc(JLI_StrLen(arg) + 6);\n-            sprintf(tmp, \"-X%s\", arg + 1); \/* skip '-' *\/\n+            size_t tmpSize = JLI_StrLen(arg) + 6;\n+            char *tmp = JLI_MemAlloc(tmpSize);\n+            snprintf(tmp, tmpSize, \"-X%s\", arg + 1); \/* skip '-' *\/\n@@ -1472,0 +1435,2 @@\n+        } else if (JLI_StrCmp(arg, \"--disable-@files\") == 0) {\n+            ; \/* Ignore --disable-@files option already handled *\/\n@@ -1722,1 +1687,2 @@\n-            *nargv++ = ((arg + 2) == NULL) ? NULL : JLI_StringDup(arg + 2);\n+            assert(arg[2] != '\\0' && \"Invalid JAVA_ARGS or EXTRA_JAVA_ARGS defined by build\");\n+            *nargv++ = JLI_StringDup(arg + 2);\n@@ -1794,2 +1760,3 @@\n-                envcp = (char *)JLI_MemAlloc(JLI_StrLen(s) + 40);\n-                sprintf(envcp, \"-Denv.class.path=%s\", s);\n+                size_t envcpSize = JLI_StrLen(s) + 40;\n+                envcp = (char *)JLI_MemAlloc(envcpSize);\n+                snprintf(envcp, envcpSize, \"-Denv.class.path=%s\", s);\n@@ -1807,2 +1774,3 @@\n-    apphome = (char *)JLI_MemAlloc(JLI_StrLen(home) + 40);\n-    sprintf(apphome, \"-Dapplication.home=%s\", home);\n+    size_t apphomeSize = JLI_StrLen(home) + 40;\n+    apphome = (char *)JLI_MemAlloc(apphomeSize);\n+    snprintf(apphome, apphomeSize, \"-Dapplication.home=%s\", home);\n@@ -1897,1 +1865,1 @@\n-PrintJavaVersion(JNIEnv *env, jboolean extraLF)\n+PrintJavaVersion(JNIEnv *env)\n@@ -1905,1 +1873,1 @@\n-                                                 (extraLF == JNI_TRUE) ? \"println\" : \"print\",\n+                                                 \"print\",\n@@ -2100,1 +2068,0 @@\n-    char *serverClassVMName = NULL;\n","filename":"src\/java.base\/share\/native\/libjli\/java.c","additions":79,"deletions":112,"binary":false,"changes":191,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -301,1 +301,0 @@\n-    int argc = *pargc;\n@@ -391,1 +390,1 @@\n-                sprintf(new_runpath, LD_LIBRARY_PATH \"=\"\n+                snprintf(new_runpath, new_runpath_size, LD_LIBRARY_PATH \"=\"\n@@ -663,0 +662,14 @@\n+static size_t adjustStackSize(size_t stack_size) {\n+    long page_size = sysconf(_SC_PAGESIZE);\n+    if (stack_size % page_size == 0) {\n+        return stack_size;\n+    } else {\n+        long pages = stack_size \/ page_size;\n+        \/\/ Ensure we don't go over limit\n+        if (stack_size <= SIZE_MAX - page_size) {\n+            pages++;\n+        }\n+        return page_size * pages;\n+    }\n+}\n+\n@@ -673,0 +686,1 @@\n+    size_t adjusted_stack_size;\n@@ -675,1 +689,8 @@\n-        pthread_attr_setstacksize(&attr, stack_size);\n+        if (pthread_attr_setstacksize(&attr, stack_size) == EINVAL) {\n+            \/\/ System may require stack size to be multiple of page size\n+            \/\/ Retry with adjusted value\n+            adjusted_stack_size = adjustStackSize(stack_size);\n+            if (adjusted_stack_size != (size_t) stack_size) {\n+                pthread_attr_setstacksize(&attr, adjusted_stack_size);\n+            }\n+        }\n","filename":"src\/java.base\/unix\/native\/libjli\/java_md.c","additions":25,"deletions":4,"binary":false,"changes":29,"status":"modified"}]}