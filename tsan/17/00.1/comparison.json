{"files":[{"patch":"@@ -1,1 +1,2 @@\n-project=jdk\n+project=tsan\n+repository=tsan\n@@ -6,1 +7,1 @@\n-error=author,committer,reviewers,merge,issues,executable,symlink,message,hg-tag,whitespace,problemlists\n+error=author,committer,whitespace,executable,symlink\n@@ -17,1 +18,1 @@\n-files=.*\\.cpp|.*\\.hpp|.*\\.c|.*\\.h|.*\\.java|.*\\.cc|.*\\.hh|.*\\.m|.*\\.mm|.*\\.gmk|.*\\.m4|.*\\.ac|Makefile\n+files=.*\\.java$|.*\\.cpp$|.*\\.hpp$|.*\\.c$|.*\\.h$\n","filename":".jcheck\/conf","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -761,0 +761,9 @@\n+  # With tsan enabled, process reaper often causes SOE. it makes jtreg test failure.\n+  ifeq ($(INCLUDE_TSAN), true)\n+    ifeq ($(call isTargetCpuArch, aarch64), true)\n+      $1_JTREG_BASIC_OPTIONS += -vmoption:-Djdk.lang.processReaperUseDefaultStackSize=true\n+      $1_JTREG_LAUNCHER_OPTIONS += -Djdk.lang.processReaperUseDefaultStackSize=true\n+      $$(info tsan enabled, process reaper will use default JVM stack size.)\n+    endif\n+  endif\n+\n","filename":"make\/RunTests.gmk","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -248,5 +248,15 @@\n-    C_O_FLAG_HIGHEST_JVM=\"-O3\"\n-    C_O_FLAG_HIGHEST=\"-O3\"\n-    C_O_FLAG_HI=\"-O3\"\n-    C_O_FLAG_NORM=\"-O2\"\n-    C_O_FLAG_DEBUG_JVM=\"-O0\"\n+    # Use -Os on aarch64 to work around known llvm issue,\n+    # (see https:\/\/bugs.llvm.org\/show_bug.cgi?id=44581) which makes release build crash in aarch64.\n+    if test \"x$OPENJDK_TARGET_CPU\" = xaarch64; then\n+      C_O_FLAG_HIGHEST_JVM=\"-Os\"\n+      C_O_FLAG_HIGHEST=\"-Os\"\n+      C_O_FLAG_HI=\"-Os\"\n+      C_O_FLAG_NORM=\"-Os\"\n+      C_O_FLAG_DEBUG_JVM=\"\"\n+    else\n+      C_O_FLAG_HIGHEST_JVM=\"-O3\"\n+      C_O_FLAG_HIGHEST=\"-O3\"\n+      C_O_FLAG_HI=\"-O3\"\n+      C_O_FLAG_NORM=\"-O2\"\n+      C_O_FLAG_DEBUG_JVM=\"-O0\"\n+    fi\n@@ -492,0 +502,6 @@\n+    # Disable experimental isel due to a known issue in llvm-8, which generates wrong debug info.\n+    # (see https:\/\/bugs.llvm.org\/show_bug.cgi?id=40887)\n+    if test \"x$OPENJDK_TARGET_CPU\" = xaarch64; then\n+      TOOLCHAIN_CFLAGS_JVM=\"$TOOLCHAIN_CFLAGS_JVM -fno-experimental-isel\"\n+    fi\n+\n","filename":"make\/autoconf\/flags-cflags.m4","additions":21,"deletions":5,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -49,1 +49,1 @@\n-    serialgc services shenandoahgc static-build vm-structs zero zgc \\\n+    serialgc services shenandoahgc static-build tsan vm-structs zero zgc \\\n@@ -78,0 +78,1 @@\n+m4_define(jvm_feature_desc_tsan, [enable ThreadSanitizer support])\n@@ -335,0 +336,47 @@\n+###############################################################################\n+# Check if the feature 'tsan' is available on this platform.\n+#\n+AC_DEFUN_ONCE([JVM_FEATURES_CHECK_TSAN],\n+[\n+  JVM_FEATURES_CHECK_AVAILABILITY(tsan, [\n+    AC_MSG_CHECKING([if platform is supported by TSAN])\n+    if test \"x$OPENJDK_TARGET_OS\" = \"xlinux\" && \\\n+        (test \"x$OPENJDK_TARGET_CPU\" = \"xx86_64\" || \\\n+         test \"x$OPENJDK_TARGET_CPU\" = \"xaarch64\"); then\n+      AC_MSG_RESULT([yes])\n+    else\n+      AC_MSG_RESULT([no, $OPENJDK_TARGET_OS-$OPENJDK_TARGET_CPU])\n+      AVAILABLE=false\n+    fi\n+  ])\n+])\n+\n+###############################################################################\n+# Support for --<enable|disable>-tsan-launcher flag.\n+#\n+# TODO(tsan-dev): Ideally we should use AC_DEFUN_ONCE. However, with AC_DEFUN_ONCE,\n+# we cannot read variables such as $INCLUDE_TSAN or $JVM_FEATURES_ACTIVE. They would\n+# become empty value.\n+AC_DEFUN([JVM_FEATURES_TSAN_LAUNCHER_FLAG],\n+[\n+  # Add a configure option --<enable|disable>-tsan-launcher to allow\n+  # more control on whether to link TSAN runtime with the launcher.\n+  AC_ARG_ENABLE(tsan-launcher, AS_HELP_STRING(\n+        [--enable-tsan-launcher],\n+        [link tsan runtime with the default JDK launcher. Default is consistent with whether tsan feature is enabled.]))\n+  AC_MSG_CHECKING([if tsan should be linked with JDK launcher])\n+  if test \"x$INCLUDE_TSAN\" = \"xtrue\"; then\n+    if test \"x$enable_tsan_launcher\" = \"xno\"; then\n+      AC_MSG_RESULT([no, forced])\n+      INCLUDE_TSAN=\"false\"\n+    else\n+      AC_MSG_RESULT([yes])\n+    fi\n+  else\n+    AC_MSG_RESULT([no, tsan feature is disabled])\n+    if test \"x$enable_tsan_launcher\" = \"xyes\"; then\n+      AC_MSG_ERROR([--enable-tsan-launcher can only be used when tsan feature is enabled.])\n+    fi\n+  fi\n+])\n+\n@@ -399,0 +447,1 @@\n+  JVM_FEATURES_CHECK_TSAN\n@@ -545,0 +594,3 @@\n+  if ! JVM_FEATURES_IS_ACTIVE(tsan); then\n+    INCLUDE_TSAN=\"false\"\n+  fi\n@@ -569,0 +621,1 @@\n+  INCLUDE_TSAN=\"true\"\n@@ -598,0 +651,2 @@\n+  JVM_FEATURES_TSAN_LAUNCHER_FLAG($INCLUDE_TSAN)\n+\n@@ -607,0 +662,1 @@\n+  AC_SUBST(INCLUDE_TSAN)\n","filename":"make\/autoconf\/jvm-features.m4","additions":57,"deletions":1,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -855,0 +855,1 @@\n+INCLUDE_TSAN:=@INCLUDE_TSAN@\n","filename":"make\/autoconf\/spec.gmk.in","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -78,0 +78,1 @@\n+# INCLUDE_TSAN   If true, pass compiler and linker flags for TSAN.\n@@ -141,0 +142,11 @@\n+  ifeq ($$($1_INCLUDE_TSAN), true)\n+    $1_CFLAGS += -DINCLUDE_TSAN\n+    # TSAN runtime needs to be statically or dynamically linked with the launcher\n+    # instead of libjvm.so, because initialization of TSAN runtime has to happen\n+    # early at program start.\n+    # '-fsanitize=thread' works as a link-only flag for either GCC or Clang.\n+    # With GCC, it dynamically links with libtsan.so; with Clang, it statically\n+    # links the runtime into the launcher's executable.\n+    $1_LDFLAGS += -fsanitize=thread\n+  endif\n+\n","filename":"make\/common\/modules\/LauncherCommon.gmk","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+TsanSymbolize\n","filename":"make\/data\/hotspot-symbols\/symbols-shared","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -134,0 +134,1 @@\n+JVM_GetTsanEnabled\n","filename":"make\/data\/hotspot-symbols\/symbols-unix","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -168,0 +168,5 @@\n+ifneq ($(call check-jvm-feature, tsan), true)\n+  JVM_CFLAGS_FEATURES += -DINCLUDE_TSAN=0\n+  JVM_EXCLUDE_PATTERNS += tsan\n+endif\n+\n","filename":"make\/hotspot\/lib\/JvmFeatures.gmk","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+    INCLUDE_TSAN := $(INCLUDE_TSAN), \\\n","filename":"make\/modules\/java.base\/Launcher.gmk","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -186,0 +186,4 @@\n+ifeq ($(INCLUDE_TSAN), true)\n+  LIBJLI_CFLAGS += -DINCLUDE_TSAN\n+endif\n+\n","filename":"make\/modules\/java.base\/lib\/CoreLibraries.gmk","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -729,0 +729,3 @@\n+\n+  TSAN_RUNTIME_ONLY(push_ptr(lock_reg));\n+\n@@ -836,0 +839,9 @@\n+\n+  TSAN_RUNTIME_ONLY(\n+    pop_ptr(lock_reg);\n+    pusha();\n+    call_VM(noreg,\n+            CAST_FROM_FN_PTR(address, SharedRuntime::tsan_interp_lock),\n+            lock_reg);\n+    popa();\n+  );\n@@ -854,0 +866,8 @@\n+  TSAN_RUNTIME_ONLY(\n+    pusha();\n+    call_VM(noreg,\n+            CAST_FROM_FN_PTR(address, SharedRuntime::tsan_interp_unlock),\n+            lock_reg);\n+    popa();\n+  );\n+\n@@ -1526,0 +1546,4 @@\n+  TSAN_RUNTIME_ONLY(call_VM(noreg,\n+                            CAST_FROM_FN_PTR(address,\n+                            SharedRuntime::tsan_interp_method_entry)));\n+\n@@ -1559,0 +1583,7 @@\n+  TSAN_RUNTIME_ONLY(\n+    push(state);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address,\n+                 SharedRuntime::tsan_interp_method_exit));\n+    pop(state);\n+  );\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":31,"deletions":0,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -1737,0 +1737,9 @@\n+  TSAN_RUNTIME_ONLY(\n+    \/\/ protect the args we've loaded\n+    save_args(masm, total_c_args, c_arg, out_regs);\n+    __ call_VM(noreg,\n+      CAST_FROM_FN_PTR(address, SharedRuntime::tsan_interp_method_entry),\n+      rthread);\n+    restore_args(masm, total_c_args, c_arg, out_regs);\n+  );\n+\n@@ -1814,0 +1823,8 @@\n+\n+    TSAN_RUNTIME_ONLY(\n+      __ pusha();\n+      __ call_VM(noreg,\n+                 CAST_FROM_FN_PTR(address, SharedRuntime::tsan_oop_lock),\n+                 obj_reg);\n+      __ popa();\n+    );\n@@ -1926,0 +1943,11 @@\n+    __ resolve(IS_NOT_NULL, obj_reg);\n+\n+    TSAN_RUNTIME_ONLY(\n+      __ pusha();\n+      __ call_VM(noreg,\n+                 CAST_FROM_FN_PTR(address, SharedRuntime::tsan_oop_unlock),\n+                 obj_reg);\n+      __ popa();\n+    );\n+\n+\n@@ -1962,0 +1990,7 @@\n+  TSAN_RUNTIME_ONLY(\n+    save_native_result(masm, ret_type, stack_slots);\n+    __ call_VM_leaf(\n+         CAST_FROM_FN_PTR(address, SharedRuntime::tsan_interp_method_exit));\n+    restore_native_result(masm, ret_type, stack_slots);\n+  );\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":35,"deletions":0,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -754,0 +754,81 @@\n+#if INCLUDE_TSAN\n+\n+void TemplateTable::tsan_observe_load_or_store(const Address& field,\n+                                               TsanMemoryReadWriteFunction tsan_function) {\n+  assert(ThreadSanitizer, \"ThreadSanitizer should be set\");\n+  if (!ThreadSanitizerJavaMemory) {\n+    return;\n+  }\n+\n+  __ pusha();\n+  __ push_d(v0);\n+  __ lea(c_rarg0, field);\n+  __ get_method(c_rarg1);\n+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, tsan_function),\n+                  c_rarg0 \/* addr *\/, c_rarg1 \/* method *\/, rbcp \/* bcp *\/);\n+  __ pop_d(v0);\n+  __ popa();\n+}\n+\n+void TemplateTable::tsan_observe_get_or_put(const Address &field,\n+                                            Register flags,\n+                                            TsanMemoryReadWriteFunction tsan_function,\n+                                            TosState tos) {\n+  assert(ThreadSanitizer, \"ThreadSanitizer should be set\");\n+\n+  TsanMemoryReleaseAcquireFunction releaseAcquireFunction =\n+      tsan_release_acquire_method(tsan_function);\n+\n+  Label done, notAcquireRelease;\n+\n+  \/\/ We could save some instructions by only saving the registers we need.\n+  __ pusha();\n+  \/\/ pusha() doesn't save v0, which tsan_function clobbers and the\n+  \/\/ interpreter still needs.\n+  \/\/ This really only needs to be done for some of the float\/double accesses,\n+  \/\/ but it's here because it's cleaner.\n+  __ push_d(v0);\n+  \/\/ For volatile reads\/writes use an acquire\/release.\n+  \/\/ If a reference is annotated to be ignored, assume it's safe to\n+  \/\/ access the object it's referring to and create a happens-before relation\n+  \/\/ between the accesses to this reference.\n+  if (tos == atos) {\n+    int32_t acquire_release_mask = 1 << ConstantPoolCacheEntry::is_volatile_shift |\n+      1 << ConstantPoolCacheEntry::is_tsan_ignore_shift;\n+    \/\/ acquire_release_mask (0x8200000) can not be encoded into 'tst', but it can be\n+    \/\/ encoded into just one 'mov' instruction.\n+    __ mov(rscratch1, acquire_release_mask);\n+    __ tst(flags, rscratch1);\n+    __ br(Assembler::EQ, notAcquireRelease);\n+  } else {\n+    __ tbz(flags, ConstantPoolCacheEntry::is_volatile_shift, notAcquireRelease);\n+  }\n+\n+  __ lea(c_rarg0, field);\n+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, releaseAcquireFunction), c_rarg0);\n+  if (ThreadSanitizerJavaMemory) {\n+    __ b(done);\n+    __ bind(notAcquireRelease);\n+\n+    \/\/ Ignore reads\/writes to final fields. They can't be racy.\n+    __ tbnz(flags, ConstantPoolCacheEntry::is_final_shift, done);\n+\n+    \/\/ Don't report races on tsan ignored fields.\n+    __ tbnz(flags, ConstantPoolCacheEntry::is_tsan_ignore_shift, done);\n+\n+    __ lea(c_rarg0, field);\n+    __ get_method(c_rarg1);\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, tsan_function),\n+                    c_rarg0 \/* addr *\/, c_rarg1 \/* method *\/, rbcp \/* bcp *\/);\n+\n+    __ bind(done);\n+  } else {\n+    __ bind(notAcquireRelease);\n+  }\n+  __ pop_d(v0);\n+  __ popa();\n+}\n+\n+\n+#endif\n+\n@@ -763,1 +844,3 @@\n-  __ access_load_at(T_INT, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(2)), noreg, noreg);\n+  Address addr(r0, r1, Address::uxtw(2));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read4));\n+  __ access_load_at(T_INT, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);\n@@ -775,1 +858,3 @@\n-  __ access_load_at(T_LONG, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(3)), noreg, noreg);\n+  Address addr(r0, r1, Address::uxtw(3));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read8));\n+  __ access_load_at(T_LONG, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);\n@@ -787,1 +872,3 @@\n-  __ access_load_at(T_FLOAT, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(2)), noreg, noreg);\n+  Address addr(r0, r1, Address::uxtw(2));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read4));\n+  __ access_load_at(T_FLOAT, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);\n@@ -799,1 +886,3 @@\n-  __ access_load_at(T_DOUBLE, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(3)), noreg, noreg);\n+  Address addr(r0, r1, Address::uxtw(3));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read8));\n+  __ access_load_at(T_DOUBLE, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);\n@@ -811,4 +900,4 @@\n-  do_oop_load(_masm,\n-              Address(r0, r1, Address::uxtw(LogBytesPerHeapOop)),\n-              r0,\n-              IS_ARRAY);\n+  Address addr(r0, r1, Address::uxtw(LogBytesPerHeapOop));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, UseCompressedOops ? SharedRuntime::tsan_read4\n+                                                                       : SharedRuntime::tsan_read8));\n+  do_oop_load(_masm, addr, r0, IS_ARRAY);\n@@ -826,1 +915,3 @@\n-  __ access_load_at(T_BYTE, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(0)), noreg, noreg);\n+  Address addr(r0, r1, Address::uxtw(0));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read1));\n+  __ access_load_at(T_BYTE, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);\n@@ -838,1 +929,3 @@\n-  __ access_load_at(T_CHAR, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(1)), noreg, noreg);\n+  Address addr(r0, r1, Address::uxtw(1));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read2));\n+  __ access_load_at(T_CHAR, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);\n@@ -844,0 +937,3 @@\n+#ifdef ASSERT\n+  TSAN_RUNTIME_ONLY(__ stop(\"bytecode rewrite should have been disabled in TSAN\"););\n+#endif\n@@ -867,1 +963,3 @@\n-  __ access_load_at(T_SHORT, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(1)), noreg, noreg);\n+  Address addr(r0, r1, Address::uxtw(1));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read2));\n+  __ access_load_at(T_SHORT, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);\n@@ -1061,1 +1159,3 @@\n-  __ access_store_at(T_INT, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(2)), r0, noreg, noreg);\n+  Address addr(r3, r1, Address::uxtw(2));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write4));\n+  __ access_store_at(T_INT, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg);\n@@ -1073,1 +1173,3 @@\n-  __ access_store_at(T_LONG, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(3)), r0, noreg, noreg);\n+  Address addr(r3, r1, Address::uxtw(3));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write8));\n+  __ access_store_at(T_LONG, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg);\n@@ -1085,1 +1187,3 @@\n-  __ access_store_at(T_FLOAT, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(2)), noreg \/* ftos *\/, noreg, noreg);\n+  Address addr(r3, r1, Address::uxtw(2));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write4));\n+  __ access_store_at(T_FLOAT, IN_HEAP | IS_ARRAY, addr, noreg \/* ftos *\/, noreg, noreg);\n@@ -1097,1 +1201,3 @@\n-  __ access_store_at(T_DOUBLE, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(3)), noreg \/* dtos *\/, noreg, noreg);\n+  Address addr(r3, r1, Address::uxtw(3));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write8));\n+  __ access_store_at(T_DOUBLE, IN_HEAP | IS_ARRAY, addr, noreg \/* dtos *\/, noreg, noreg);\n@@ -1112,1 +1218,3 @@\n-\n+  \/\/ do tsan write after r4 has been defined.\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(element_address, UseCompressedOops ? SharedRuntime::tsan_write4\n+                                                                                  : SharedRuntime::tsan_write8));\n@@ -1174,1 +1282,3 @@\n-  __ access_store_at(T_BYTE, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(0)), r0, noreg, noreg);\n+  Address addr(r3, r1, Address::uxtw(0));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write1));\n+  __ access_store_at(T_BYTE, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg);\n@@ -1187,1 +1297,3 @@\n-  __ access_store_at(T_CHAR, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(1)), r0, noreg, noreg);\n+  Address addr(r3, r1, Address::uxtw(1));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write2));\n+  __ access_store_at(T_CHAR, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg);\n@@ -2319,0 +2431,19 @@\n+    TSAN_RUNTIME_ONLY(\n+      \/\/ Draw a happens-before edge from the class's static initializer to\n+      \/\/ this lookup.\n+\n+      \/\/ java_lang_Class::_init_lock_offset may not have been initialized\n+      \/\/ when generating code. It will be initialized at runtime though.\n+      \/\/ So calculate its address and read from it at runtime.\n+      __ pusha();\n+      __ mov(c_rarg0, obj);\n+      Address init_lock_offset_address((address) java_lang_Class::init_lock_offset_addr(),\n+                                       relocInfo::none);\n+      __ lea(rscratch1, init_lock_offset_address);\n+      __ ldrw(rscratch1, Address(rscratch1, 0));\n+      __ add(c_rarg0, c_rarg0, rscratch1);\n+      __ call_VM_leaf(CAST_FROM_FN_PTR(address,\n+                                       SharedRuntime::tsan_acquire),\n+                                       c_rarg0);\n+      __ popa();\n+    );\n@@ -2454,0 +2585,1 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read1, btos));\n@@ -2467,0 +2599,1 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read1, ztos));\n@@ -2480,0 +2613,5 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field,\n+                                            raw_flags,\n+                                            UseCompressedOops ? SharedRuntime::tsan_read4\n+                                                              : SharedRuntime::tsan_read8,\n+                                            atos));\n@@ -2491,0 +2629,1 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read4, itos));\n@@ -2503,0 +2642,1 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read2, ctos));\n@@ -2515,0 +2655,1 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read2, stos));\n@@ -2527,0 +2668,1 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read8, ltos));\n@@ -2539,0 +2681,1 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read4, ftos));\n@@ -2553,0 +2696,1 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read8, dtos));\n@@ -2660,0 +2804,1 @@\n+  \/\/ save raw flags in r5\n@@ -2689,0 +2834,1 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write1, btos));\n@@ -2704,0 +2850,1 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write1, ztos));\n@@ -2719,0 +2866,5 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field,\n+                                              r5,\n+                                              UseCompressedOops ? SharedRuntime::tsan_write4\n+                                                                : SharedRuntime::tsan_write8,\n+                                              atos));\n@@ -2735,0 +2887,1 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write4, itos));\n@@ -2750,0 +2903,1 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write2, ctos));\n@@ -2765,0 +2919,1 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write2, stos));\n@@ -2780,0 +2935,1 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write8, ltos));\n@@ -2795,0 +2951,1 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write4, ftos));\n@@ -2812,0 +2969,1 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write8, dtos));\n@@ -2985,0 +3143,3 @@\n+#ifdef ASSERT\n+  TSAN_RUNTIME_ONLY(__ stop(\"bytecode rewrite should have been disabled in TSAN\"););\n+#endif\n@@ -3078,0 +3239,3 @@\n+#ifdef ASSERT\n+  TSAN_RUNTIME_ONLY(__ stop(\"bytecode rewrite should have been disabled in TSAN\"););\n+#endif\n@@ -3574,0 +3738,8 @@\n+\n+     TSAN_RUNTIME_ONLY(\n+      \/\/ return value of new oop is in r0.\n+      __ push(atos);\n+      __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::tsan_track_obj), r0);\n+      __ pop(atos);\n+    );\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":190,"deletions":18,"binary":false,"changes":208,"status":"modified"},{"patch":"@@ -1200,0 +1200,1 @@\n+  TSAN_RUNTIME_ONLY(push_ptr(lock_reg));\n@@ -1304,0 +1305,9 @@\n+\n+  TSAN_RUNTIME_ONLY(\n+    pop_ptr(lock_reg);\n+    pusha();\n+    call_VM(noreg,\n+            CAST_FROM_FN_PTR(address, SharedRuntime::tsan_interp_lock),\n+            lock_reg);\n+    popa();\n+  );\n@@ -1323,0 +1333,8 @@\n+  TSAN_RUNTIME_ONLY(\n+    pusha();\n+    call_VM(noreg,\n+            CAST_FROM_FN_PTR(address, SharedRuntime::tsan_interp_unlock),\n+            lock_reg);\n+    popa();\n+  );\n+\n@@ -2035,0 +2053,4 @@\n+  TSAN_RUNTIME_ONLY(call_VM(noreg,\n+                            CAST_FROM_FN_PTR(address,\n+                                             SharedRuntime::tsan_interp_method_entry)));\n+\n@@ -2072,0 +2094,7 @@\n+  TSAN_RUNTIME_ONLY(\n+    push(state);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address,\n+                                  SharedRuntime::tsan_interp_method_exit));\n+    pop(state);\n+  );\n+\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":29,"deletions":0,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -2034,0 +2034,9 @@\n+  TSAN_RUNTIME_ONLY(\n+    \/\/ protect the args we've loaded\n+    save_args(masm, total_c_args, c_arg, out_regs);\n+    __ call_VM(noreg,\n+      CAST_FROM_FN_PTR(address, SharedRuntime::tsan_interp_method_entry),\n+      r15_thread);\n+    restore_args(masm, total_c_args, c_arg, out_regs);\n+  );\n+\n@@ -2112,0 +2121,8 @@\n+\n+    TSAN_RUNTIME_ONLY(\n+      __ pusha();\n+      __ call_VM(noreg,\n+                 CAST_FROM_FN_PTR(address, SharedRuntime::tsan_oop_lock),\n+                 obj_reg);\n+      __ popa();\n+    );\n@@ -2225,0 +2242,8 @@\n+    TSAN_RUNTIME_ONLY(\n+      __ pusha();\n+      __ call_VM(noreg, CAST_FROM_FN_PTR(address,\n+                                         SharedRuntime::tsan_oop_unlock),\n+                 obj_reg);\n+      __ popa();\n+    );\n+\n@@ -2262,0 +2287,8 @@\n+\n+  TSAN_RUNTIME_ONLY(\n+    save_native_result(masm, ret_type, stack_slots);\n+    __ call_VM_leaf(\n+         CAST_FROM_FN_PTR(address, SharedRuntime::tsan_interp_method_exit));\n+    restore_native_result(masm, ret_type, stack_slots);\n+  );\n+\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":33,"deletions":0,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -769,0 +769,97 @@\n+#if INCLUDE_TSAN\n+\n+void TemplateTable::tsan_observe_get_or_put(\n+    const Address &field,\n+    Register flags,\n+    TsanMemoryReadWriteFunction tsan_function,\n+    TosState tos) {\n+  assert(flags == rdx, \"flags should be in rdx register\");\n+  assert(ThreadSanitizer, \"ThreadSanitizer should be set\");\n+\n+  TsanMemoryReleaseAcquireFunction releaseAcquireFunction =\n+      tsan_release_acquire_method(tsan_function);\n+\n+  Label done, notAcquireRelease;\n+\n+  \/\/ We could save some instructions by only saving the registers we need.\n+  __ pusha();\n+  \/\/ pusha() doesn't save xmm0, which tsan_function clobbers and the\n+  \/\/ interpreter still needs.\n+  \/\/ This really only needs to be done for some of the float\/double accesses,\n+  \/\/ but it's here because it's cleaner.\n+  __ push_d(xmm0);\n+  DEBUG_ONLY(\n+    __ pusha();\n+    __ movptr(c_rarg0, field.base());\n+    __ leaq(c_rarg1, field);\n+    __ subq(c_rarg1, field.base());\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::verify_oop_index),\n+                    c_rarg0 \/* oop *\/, c_rarg1 \/* index *\/);\n+    __ popa();\n+  );\n+  \/\/ For volatile reads\/writes use an acquire\/release.\n+  \/\/ If a reference is annotated to be ignored, assume it's safe to\n+  \/\/ access the object it's referring to and create a happens-before relation\n+  \/\/ between the accesses to this reference.\n+  int32_t acquire_release_mask = 1 << ConstantPoolCacheEntry::is_volatile_shift |\n+      ((tos == atos) ? 1 << ConstantPoolCacheEntry::is_tsan_ignore_shift : 0);\n+  __ testl(flags, acquire_release_mask);\n+  __ jcc(Assembler::zero, notAcquireRelease);\n+\n+  __ leaq(c_rarg0, field);\n+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, releaseAcquireFunction), c_rarg0);\n+  if (ThreadSanitizerJavaMemory) {\n+    __ jmp(done);\n+\n+    __ bind(notAcquireRelease);\n+    \/\/ Ignore reads\/writes to final fields. They can't be racy.\n+    int32_t ignore_mask = 1 << ConstantPoolCacheEntry::is_final_shift |\n+        1 << ConstantPoolCacheEntry::is_tsan_ignore_shift;\n+    __ testl(flags, ignore_mask);\n+    __ jcc(Assembler::notZero, done);\n+\n+    __ leaq(c_rarg0, field);\n+    __ get_method(c_rarg1);\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, tsan_function),\n+                    c_rarg0 \/* addr *\/, c_rarg1 \/* method *\/, rbcp \/* bcp *\/);\n+\n+    __ bind(done);\n+  } else {\n+    __ bind(notAcquireRelease);\n+  }\n+  __ pop_d(xmm0);\n+  __ popa();\n+}\n+\n+void TemplateTable::tsan_observe_load_or_store(\n+    const Address& field, TsanMemoryReadWriteFunction tsan_function) {\n+  assert(ThreadSanitizer, \"ThreadSanitizer should be set\");\n+  if (!ThreadSanitizerJavaMemory) {\n+    return;\n+  }\n+  \/\/ We could save some instructions by only saving the registers we need.\n+  __ pusha();\n+  \/\/ pusha() doesn't save xmm0, which tsan_function clobbers and the\n+  \/\/ interpreter still needs.\n+  \/\/ This really only needs to be done for some of the float\/double accesses,\n+  \/\/ but it's here because it's cleaner.\n+  __ push_d(xmm0);\n+  DEBUG_ONLY(\n+    __ pusha();\n+    __ movptr(c_rarg0, field.base());\n+    __ leaq(c_rarg1, field);\n+    __ subq(c_rarg1, field.base());\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::verify_oop_index),\n+                    c_rarg0 \/* oop *\/, c_rarg1 \/* index *\/);\n+    __ popa();\n+  );\n+  __ leaq(c_rarg0, field);\n+  __ get_method(c_rarg1);\n+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, tsan_function),\n+                  c_rarg0 \/* addr *\/, c_rarg1 \/* method *\/, rbcp \/* bcp *\/);\n+  __ pop_d(xmm0);\n+  __ popa();\n+}\n+\n+#endif  \/\/ INCLUDE_TSAN\n+\n@@ -774,4 +871,4 @@\n-  __ access_load_at(T_INT, IN_HEAP | IS_ARRAY, rax,\n-                    Address(rdx, rax, Address::times_4,\n-                            arrayOopDesc::base_offset_in_bytes(T_INT)),\n-                    noreg, noreg);\n+  Address addr(rdx, rax, Address::times_4,\n+               arrayOopDesc::base_offset_in_bytes(T_INT));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read4));\n+  __ access_load_at(T_INT, IN_HEAP | IS_ARRAY, rax, addr, noreg, noreg);\n@@ -787,4 +884,5 @@\n-  __ access_load_at(T_LONG, IN_HEAP | IS_ARRAY, noreg \/* ltos *\/,\n-                    Address(rdx, rbx, Address::times_8,\n-                            arrayOopDesc::base_offset_in_bytes(T_LONG)),\n-                    noreg, noreg);\n+  Address addr(rdx, rbx, Address::times_8,\n+               arrayOopDesc::base_offset_in_bytes(T_LONG));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read8));\n+  __ access_load_at(T_LONG, IN_HEAP | IS_ARRAY, noreg \/* ltos *\/, addr, noreg,\n+                    noreg);\n@@ -800,5 +898,5 @@\n-  __ access_load_at(T_FLOAT, IN_HEAP | IS_ARRAY, noreg \/* ftos *\/,\n-                    Address(rdx, rax,\n-                            Address::times_4,\n-                            arrayOopDesc::base_offset_in_bytes(T_FLOAT)),\n-                    noreg, noreg);\n+  Address addr(rdx, rax, Address::times_4,\n+               arrayOopDesc::base_offset_in_bytes(T_FLOAT));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read4));\n+  __ access_load_at(T_FLOAT, IN_HEAP | IS_ARRAY, noreg \/* ftos *\/, addr, noreg,\n+                    noreg);\n@@ -812,5 +910,5 @@\n-  __ access_load_at(T_DOUBLE, IN_HEAP | IS_ARRAY, noreg \/* dtos *\/,\n-                    Address(rdx, rax,\n-                            Address::times_8,\n-                            arrayOopDesc::base_offset_in_bytes(T_DOUBLE)),\n-                    noreg, noreg);\n+  Address addr(rdx, rax, Address::times_8,\n+               arrayOopDesc::base_offset_in_bytes(T_DOUBLE));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read8));\n+  __ access_load_at(T_DOUBLE, IN_HEAP | IS_ARRAY, noreg \/* dtos *\/, addr, noreg,\n+                    noreg);\n@@ -824,6 +922,7 @@\n-  do_oop_load(_masm,\n-              Address(rdx, rax,\n-                      UseCompressedOops ? Address::times_4 : Address::times_ptr,\n-                      arrayOopDesc::base_offset_in_bytes(T_OBJECT)),\n-              rax,\n-              IS_ARRAY);\n+  Address addr(rdx, rax,\n+               UseCompressedOops ? Address::times_4 : Address::times_ptr,\n+               arrayOopDesc::base_offset_in_bytes(T_OBJECT));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(\n+      addr, UseCompressedOops ? SharedRuntime::tsan_read4\n+                              : SharedRuntime::tsan_read8));\n+  do_oop_load(_masm, addr, rax, IS_ARRAY);\n@@ -837,3 +936,4 @@\n-  __ access_load_at(T_BYTE, IN_HEAP | IS_ARRAY, rax,\n-                    Address(rdx, rax, Address::times_1, arrayOopDesc::base_offset_in_bytes(T_BYTE)),\n-                    noreg, noreg);\n+  Address addr(rdx, rax, Address::times_1,\n+               arrayOopDesc::base_offset_in_bytes(T_BYTE));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read1));\n+  __ access_load_at(T_BYTE, IN_HEAP | IS_ARRAY, rax, addr, noreg, noreg);\n@@ -847,3 +947,4 @@\n-  __ access_load_at(T_CHAR, IN_HEAP | IS_ARRAY, rax,\n-                    Address(rdx, rax, Address::times_2, arrayOopDesc::base_offset_in_bytes(T_CHAR)),\n-                    noreg, noreg);\n+  Address addr(rdx, rax, Address::times_2,\n+               arrayOopDesc::base_offset_in_bytes(T_CHAR));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read2));\n+  __ access_load_at(T_CHAR, IN_HEAP | IS_ARRAY, rax, addr, noreg, noreg);\n@@ -873,3 +974,4 @@\n-  __ access_load_at(T_SHORT, IN_HEAP | IS_ARRAY, rax,\n-                    Address(rdx, rax, Address::times_2, arrayOopDesc::base_offset_in_bytes(T_SHORT)),\n-                    noreg, noreg);\n+  Address addr(rdx, rax, Address::times_2,\n+               arrayOopDesc::base_offset_in_bytes(T_SHORT));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read2));\n+  __ access_load_at(T_SHORT, IN_HEAP | IS_ARRAY, rax, addr, noreg, noreg);\n@@ -1067,4 +1169,4 @@\n-  __ access_store_at(T_INT, IN_HEAP | IS_ARRAY,\n-                     Address(rdx, rbx, Address::times_4,\n-                             arrayOopDesc::base_offset_in_bytes(T_INT)),\n-                     rax, noreg, noreg);\n+  Address addr(rdx, rbx, Address::times_4,\n+               arrayOopDesc::base_offset_in_bytes(T_INT));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write4));\n+  __ access_store_at(T_INT, IN_HEAP | IS_ARRAY, addr, rax, noreg, noreg);\n@@ -1081,4 +1183,5 @@\n-  __ access_store_at(T_LONG, IN_HEAP | IS_ARRAY,\n-                     Address(rcx, rbx, Address::times_8,\n-                             arrayOopDesc::base_offset_in_bytes(T_LONG)),\n-                     noreg \/* ltos *\/, noreg, noreg);\n+  Address addr(rcx, rbx, Address::times_8,\n+               arrayOopDesc::base_offset_in_bytes(T_LONG));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write8));\n+  __ access_store_at(T_LONG, IN_HEAP | IS_ARRAY, addr, noreg \/* ltos *\/, noreg,\n+                     noreg);\n@@ -1095,4 +1198,5 @@\n-  __ access_store_at(T_FLOAT, IN_HEAP | IS_ARRAY,\n-                     Address(rdx, rbx, Address::times_4,\n-                             arrayOopDesc::base_offset_in_bytes(T_FLOAT)),\n-                     noreg \/* ftos *\/, noreg, noreg);\n+  Address addr(rdx, rbx, Address::times_4,\n+               arrayOopDesc::base_offset_in_bytes(T_FLOAT));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write4));\n+  __ access_store_at(T_FLOAT, IN_HEAP | IS_ARRAY, addr, noreg \/* ftos *\/, noreg,\n+                     noreg);\n@@ -1108,4 +1212,5 @@\n-  __ access_store_at(T_DOUBLE, IN_HEAP | IS_ARRAY,\n-                     Address(rdx, rbx, Address::times_8,\n-                             arrayOopDesc::base_offset_in_bytes(T_DOUBLE)),\n-                     noreg \/* dtos *\/, noreg, noreg);\n+  Address addr(rdx, rbx, Address::times_8,\n+               arrayOopDesc::base_offset_in_bytes(T_DOUBLE));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write8));\n+  __ access_store_at(T_DOUBLE, IN_HEAP | IS_ARRAY, addr, noreg \/* dtos *\/,\n+                     noreg, noreg);\n@@ -1126,0 +1231,4 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(\n+      element_address, UseCompressedOops ? SharedRuntime::tsan_write4\n+                                         : SharedRuntime::tsan_write8));\n+\n@@ -1186,4 +1295,4 @@\n-  __ access_store_at(T_BYTE, IN_HEAP | IS_ARRAY,\n-                     Address(rdx, rbx,Address::times_1,\n-                             arrayOopDesc::base_offset_in_bytes(T_BYTE)),\n-                     rax, noreg, noreg);\n+  Address addr(rdx, rbx, Address::times_1,\n+               arrayOopDesc::base_offset_in_bytes(T_BYTE));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write1));\n+  __ access_store_at(T_BYTE, IN_HEAP | IS_ARRAY, addr, rax, noreg, noreg);\n@@ -1199,4 +1308,4 @@\n-  __ access_store_at(T_CHAR, IN_HEAP | IS_ARRAY,\n-                     Address(rdx, rbx, Address::times_2,\n-                             arrayOopDesc::base_offset_in_bytes(T_CHAR)),\n-                     rax, noreg, noreg);\n+  Address addr(rdx, rbx, Address::times_2,\n+               arrayOopDesc::base_offset_in_bytes(T_CHAR));\n+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write2));\n+  __ access_store_at(T_CHAR, IN_HEAP | IS_ARRAY, addr, rax, noreg, noreg);\n@@ -2720,0 +2829,20 @@\n+    TSAN_RUNTIME_ONLY(\n+      \/\/ Draw a happens-before edge from the class's static initializer to\n+      \/\/ this lookup.\n+\n+      \/\/ java_lang_Class::_init_lock_offset may not have been initialized\n+      \/\/ when generating code. It will be initialized at runtime though.\n+      \/\/ So calculate its address and read from it at runtime.\n+      __ pusha();\n+      __ movq(c_rarg0, obj);\n+      AddressLiteral init_lock_offset_address(\n+          (address) java_lang_Class::init_lock_offset_addr(),\n+          relocInfo::none);\n+      __ lea(rax, init_lock_offset_address);\n+      __ movl(rax, Address(rax, 0));\n+      __ addq(c_rarg0, rax);\n+      __ call_VM_leaf(CAST_FROM_FN_PTR(address,\n+                                       SharedRuntime::tsan_acquire),\n+                      c_rarg0);\n+      __ popa();\n+    );\n@@ -2815,0 +2944,5 @@\n+  \/\/ During a TSAN instrumented run, move flags into rdx so we can later\n+  \/\/ examine whether the field is volatile or has been annotated to be ignored\n+  \/\/ by Tsan.\n+  TSAN_RUNTIME_ONLY(__ movl(rdx, flags));\n+\n@@ -2827,0 +2961,2 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+      field, rdx, SharedRuntime::tsan_read1, btos));\n@@ -2840,0 +2976,2 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+      field, rdx, SharedRuntime::tsan_read1, ztos));\n@@ -2853,0 +2991,4 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+      field, rdx, UseCompressedOops ? SharedRuntime::tsan_read4\n+                                    : SharedRuntime::tsan_read8,\n+      atos));\n@@ -2864,0 +3006,2 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+      field, rdx, SharedRuntime::tsan_read4, itos));\n@@ -2876,0 +3020,2 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+      field, rdx, SharedRuntime::tsan_read2, ctos));\n@@ -2888,0 +3034,2 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+      field, rdx, SharedRuntime::tsan_read2, stos));\n@@ -2902,0 +3050,2 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+      field, rdx, SharedRuntime::tsan_read8, ltos));\n@@ -2913,0 +3063,2 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+      field, rdx, SharedRuntime::tsan_read4, ftos));\n@@ -2929,0 +3081,2 @@\n+  TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+      field, rdx, SharedRuntime::tsan_read8, dtos));\n@@ -3064,2 +3218,0 @@\n-  __ shrl(rdx, ConstantPoolCacheEntry::is_volatile_shift);\n-  __ andl(rdx, 0x1);\n@@ -3068,1 +3220,1 @@\n-  __ testl(rdx, rdx);\n+  __ testl(rdx, 1 << ConstantPoolCacheEntry::is_volatile_shift);\n@@ -3105,0 +3257,2 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+        field, rdx, SharedRuntime::tsan_write1, btos));\n@@ -3120,0 +3274,2 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+        field, rdx, SharedRuntime::tsan_write1, ztos));\n@@ -3135,0 +3291,4 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, rdx,\n+        UseCompressedOops ? SharedRuntime::tsan_write4\n+                          : SharedRuntime::tsan_write8,\n+        atos));\n@@ -3151,0 +3311,2 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+        field, rdx, SharedRuntime::tsan_write4, itos));\n@@ -3166,0 +3328,2 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+        field, rdx, SharedRuntime::tsan_write2, ctos));\n@@ -3181,0 +3345,2 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+        field, rdx, SharedRuntime::tsan_write2, stos));\n@@ -3196,0 +3362,2 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+        field, rdx, SharedRuntime::tsan_write8, ltos));\n@@ -3214,0 +3382,2 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+        field, rdx, SharedRuntime::tsan_write4, ftos));\n@@ -3232,0 +3402,2 @@\n+    TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(\n+        field, rdx, SharedRuntime::tsan_write8, dtos));\n@@ -4051,0 +4223,8 @@\n+    TSAN_RUNTIME_ONLY(\n+      \/\/ return value of new oop is in rax.\n+      __ push(atos);\n+      __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::tsan_track_obj),\n+                      rax);\n+      __ pop(atos);\n+    );\n+\n","filename":"src\/hotspot\/cpu\/x86\/templateTable_x86.cpp","additions":240,"deletions":60,"binary":false,"changes":300,"status":"modified"},{"patch":"@@ -584,0 +584,23 @@\n+\n+#if (INCLUDE_TSAN) && defined(AARCH64)\n+  \/\/ Current TSAN memory mapping for 48bits aarch64, a large continuous space could be allocated between\n+  \/\/ kMidAppMemBeg = 0x0aaaa00000000ull and kMidAppMemEnd = 0x0aaaf00000000ull, which is only 20GB size.\n+  \/\/ Take 16GB here for safer allocation.\n+  const julong max_avail_vmspace = 16ULL * G; \/\/ 16GB\n+  const u8 msb_in_aarch64 = 47; \/\/ Only support 48-bits space now.\n+\n+  \/\/ Based on tsan memory mapping for 48bits aarch64,\n+  \/\/ libjvm.so will be loaded between kHiAppMemBeg = 0x0ffff00000000ull and kHiAppMemEnd = 0x1000000000000ull\n+  u8 vm_addr_u8 = reinterpret_cast<u8>(&__FUNCTION__);\n+  \/\/ High address in 48bits user space is like 0x0000ffffxxxxxxxx.\n+  assert((vm_addr_u8  >> msb_in_aarch64) == 0x1, \"warning: allocation could fail in non 48-bit address space.\");\n+\n+  if (result) {\n+    *limit = MIN2(*limit, max_avail_vmspace);\n+  } else {\n+    *limit = max_avail_vmspace;\n+  }\n+\n+  result = true;\n+#endif\n+\n","filename":"src\/hotspot\/os\/posix\/os_posix.cpp","additions":23,"deletions":0,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -627,1 +627,2 @@\n-  assert(((intptr_t)os::current_stack_pointer() & (StackAlignmentInBytes-1)) == 0, \"incorrect stack alignment\");\n+  \/\/ TODO: TSAN requires being built with Clang, but stack alignment assertion fails with Clang.\n+  \/\/ assert(((intptr_t)os::current_stack_pointer() & (StackAlignmentInBytes-1)) == 0, \"incorrect stack alignment\");\n","filename":"src\/hotspot\/os_cpu\/linux_x86\/os_linux_x86.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -38,0 +38,3 @@\n+#if INCLUDE_TSAN\n+#include \"classfile\/tsanIgnoreList.hpp\"\n+#endif \/\/ INCLUDE_TSAN\n@@ -971,0 +974,1 @@\n+    _field_TsanIgnore,\n@@ -1008,0 +1012,5 @@\n+\n+#if INCLUDE_TSAN\n+  void set_tsan_ignore(bool tsan_ignore) { set_annotation(_field_TsanIgnore); }\n+  bool is_tsan_ignore() const { return has_annotation(_field_TsanIgnore); }\n+#endif  \/\/ INCLUDE_TSAN\n@@ -1587,0 +1596,7 @@\n+    TSAN_RUNTIME_ONLY(\n+      if (ThreadSanitizerIgnoreFile != NULL &&\n+          TsanIgnoreList::match(_class_name, name, type)) {\n+        parsed_annotations.set_tsan_ignore(true);\n+      }\n+    );\n+\n@@ -2027,0 +2043,8 @@\n+#if INCLUDE_TSAN\n+    case VM_SYMBOL_ENUM_NAME(java_util_concurrent_annotation_LazyInit): {\n+      if (_location != _in_field) {\n+        break;  \/\/ only allow for fields\n+      }\n+      return _field_TsanIgnore;\n+    }\n+#endif  \/\/ INCLUDE_TSAN\n@@ -2044,0 +2068,5 @@\n+  TSAN_RUNTIME_ONLY(\n+    if (is_tsan_ignore())\n+      f->set_tsan_ignore(true);\n+  );\n+\n@@ -5427,0 +5456,19 @@\n+#if INCLUDE_TSAN\n+  if (ThreadSanitizer && !ik->is_interface()) {\n+    ik->ensure_space_for_methodids(0);\n+    int num_methods = ik->methods()->length();\n+    for (int index = 0; index < num_methods; index++) {\n+      \/\/ Make sure each method has a jmethodID.\n+      \/\/ This allows us to avoid allocating jmethodIDs during program execution.\n+      jmethodID id = ik->methods()->at(index)->jmethod_id();\n+#ifdef ASSERT\n+      u8 id_u8 = reinterpret_cast<u8>(id);\n+      assert((id_u8 & right_n_bits(3)) == 0, \"jmethodID is not aligned\");\n+      AARCH64_ONLY(id_u8 >>= 36;\n+                   assert(id_u8 == 0 || id_u8 == 0xaaa || id_u8 == 0xfff, \"jmethodID is not aligned\");\n+                   )\n+#endif\n+    }\n+  }\n+#endif \/\/ INCLUDE_TSAN\n+\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":48,"deletions":0,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -1486,0 +1486,8 @@\n+\n+#if INCLUDE_TSAN\n+oop* java_lang_Class::init_lock_addr(oop java_class) {\n+  assert(_init_lock_offset != 0, \"must be set\");\n+  return (oop*)java_class->field_addr(_init_lock_offset);\n+}\n+#endif  \/\/ INCLUDE_TSAN\n+\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -351,0 +351,4 @@\n+#if INCLUDE_TSAN\n+  static oop* init_lock_addr(oop java_class);\n+  static const int* init_lock_offset_addr() { return &_init_lock_offset; }\n+#endif  \/\/ INCLUDE_TSAN\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -478,1 +478,1 @@\n-  assert(calledholdinglock, \"must hold lock for notify\");\n+  assert(calledholdinglock,\"must hold lock for notify\");\n@@ -482,1 +482,7 @@\n-  intx recursions = ObjectSynchronizer::complete_exit(lockObject, thread);\n+\n+  TSAN_ONLY(int tsan_rec = 0;)\n+  TSAN_RUNTIME_ONLY(\n+    tsan_rec = SharedRuntime::tsan_oop_rec_unlock(thread, lockObject());\n+    assert(tsan_rec > 0, \"tsan: unlocking unlocked mutex\");\n+  );\n+  intx recursions =  ObjectSynchronizer::complete_exit(lockObject, thread);\n@@ -486,0 +492,1 @@\n+  TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_rec_lock(thread, lockObject(), tsan_rec));\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":9,"deletions":2,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -250,0 +250,1 @@\n+  template(java_util_concurrent_annotation_LazyInit,                         \"Ljava\/util\/concurrent\/annotation\/LazyInit;\") \\\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -214,0 +214,4 @@\n+  \/\/ TODO(tsan): _reserved MemRegion is not available to all collectors.\n+  \/\/ Should we support collectors without _reserved MemRegion? See 8224815.\n+  TSAN_ONLY(MemRegion reserved_region() const { return _reserved; })\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -252,0 +252,3 @@\n+  TSAN_RUNTIME_ONLY(\n+      SharedRuntime::tsan_track_obj_with_size(obj(), (int)_allocator._word_size);\n+  );\n","filename":"src\/hotspot\/share\/gc\/shared\/memAllocator.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -40,0 +40,9 @@\n+  f(CNT_PREFIX ## UniverseRoots,            DESC_PREFIX \"Universe Roots\")              \\\n+  f(CNT_PREFIX ## JNIRoots,                 DESC_PREFIX \"JNI Handles Roots\")           \\\n+  f(CNT_PREFIX ## JVMTIWeakRoots,           DESC_PREFIX \"JVMTI Weak Roots\")            \\\n+  f(CNT_PREFIX ## JFRWeakRoots,             DESC_PREFIX \"JFR Weak Roots\")              \\\n+  f(CNT_PREFIX ## TSANWeakRoots,            DESC_PREFIX \"TSAN Weak Roots\")             \\\n+  f(CNT_PREFIX ## JNIWeakRoots,             DESC_PREFIX \"JNI Weak Roots\")              \\\n+  f(CNT_PREFIX ## StringTableRoots,         DESC_PREFIX \"String Table Roots\")          \\\n+  f(CNT_PREFIX ## ResolvedMethodTableRoots, DESC_PREFIX \"Resolved Table Roots\")        \\\n+  f(CNT_PREFIX ## VMGlobalRoots,            DESC_PREFIX \"VM Global Roots\")             \\\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahPhaseTimings.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -38,0 +38,2 @@\n+#include \"services\/management.hpp\"\n+#include \"tsan\/tsanOopMap.hpp\"\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahRootProcessor.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -37,0 +37,75 @@\n+class ShenandoahSerialRoot {\n+public:\n+  typedef void (*OopsDo)(OopClosure*);\n+private:\n+  ShenandoahSharedFlag                   _claimed;\n+  const OopsDo                           _oops_do;\n+  const ShenandoahPhaseTimings::Phase    _phase;\n+  const ShenandoahPhaseTimings::ParPhase _par_phase;\n+\n+public:\n+  ShenandoahSerialRoot(OopsDo oops_do,\n+          ShenandoahPhaseTimings::Phase phase, ShenandoahPhaseTimings::ParPhase par_phase);\n+  void oops_do(OopClosure* cl, uint worker_id);\n+};\n+\n+class ShenandoahSerialRoots {\n+private:\n+  ShenandoahSerialRoot  _universe_root;\n+  ShenandoahSerialRoot  _object_synchronizer_root;\n+  ShenandoahSerialRoot  _management_root;\n+  ShenandoahSerialRoot  _jvmti_root;\n+public:\n+  ShenandoahSerialRoots(ShenandoahPhaseTimings::Phase phase);\n+  void oops_do(OopClosure* cl, uint worker_id);\n+};\n+\n+class ShenandoahWeakSerialRoot {\n+  typedef void (*WeakOopsDo)(BoolObjectClosure*, OopClosure*);\n+private:\n+  ShenandoahSharedFlag                   _claimed;\n+  const WeakOopsDo                       _weak_oops_do;\n+  const ShenandoahPhaseTimings::Phase    _phase;\n+  const ShenandoahPhaseTimings::ParPhase _par_phase;\n+\n+public:\n+  ShenandoahWeakSerialRoot(WeakOopsDo oops_do,\n+          ShenandoahPhaseTimings::Phase phase, ShenandoahPhaseTimings::ParPhase par_phase);\n+  void weak_oops_do(BoolObjectClosure* is_alive, OopClosure* keep_alive, uint worker_id);\n+};\n+\n+#if INCLUDE_JVMTI\n+class ShenandoahJVMTIWeakRoot : public ShenandoahWeakSerialRoot {\n+public:\n+  ShenandoahJVMTIWeakRoot(ShenandoahPhaseTimings::Phase phase);\n+};\n+#endif \/\/ INCLUDE_JVMTI\n+\n+#if INCLUDE_JFR\n+class ShenandoahJFRWeakRoot : public ShenandoahWeakSerialRoot {\n+public:\n+  ShenandoahJFRWeakRoot(ShenandoahPhaseTimings::Phase phase);\n+};\n+#endif \/\/ INCLUDE_JFR\n+\n+#if INCLUDE_TSAN\n+class ShenandoahTSANWeakRoot : public ShenandoahWeakSerialRoot {\n+public:\n+  ShenandoahTSANWeakRoot(ShenandoahPhaseTimings::Phase phase);\n+};\n+#endif \/\/ INCLUDE_TSAN\n+\n+class ShenandoahSerialWeakRoots {\n+private:\n+  JVMTI_ONLY(ShenandoahJVMTIWeakRoot _jvmti_weak_roots;)\n+  JFR_ONLY(ShenandoahJFRWeakRoot     _jfr_weak_roots;)\n+  TSAN_ONLY(ShenandoahTSANWeakRoot   _tsan_weak_roots;)\n+public:\n+  ShenandoahSerialWeakRoots(ShenandoahPhaseTimings::Phase phase) :\n+  JVMTI_ONLY(_jvmti_weak_roots(phase))\n+  JFR_ONLY(JVMTI_ONLY(COMMA)_jfr_weak_roots(phase))\n+  TSAN_ONLY(JVMTI_ONLY(COMMA)_tsan_weak_roots(phase)) {};\n+  void weak_oops_do(BoolObjectClosure* is_alive, OopClosure* keep_alive, uint worker_id);\n+  void weak_oops_do(OopClosure* cl, uint worker_id);\n+};\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahRootProcessor.hpp","additions":75,"deletions":0,"binary":false,"changes":75,"status":"modified"},{"patch":"@@ -315,0 +315,6 @@\n+\/*\n+ * java.lang.ref.Finalizer\n+ *\/\n+JNIEXPORT jboolean JNICALL\n+JVM_GetTsanEnabled(JNIEnv *env);\n+\n","filename":"src\/hotspot\/share\/include\/jvm.h","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -705,0 +705,5 @@\n+  bool is_tsan_ignore = false;\n+#if INCLUDE_TSAN\n+  is_tsan_ignore = info.access_flags().is_stable() || info.access_flags().is_tsan_ignore();\n+#endif  \/\/ INCLUDE_TSAN\n+\n@@ -713,1 +718,2 @@\n-    info.access_flags().is_volatile()\n+    info.access_flags().is_volatile(),\n+    is_tsan_ignore\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -29,0 +29,3 @@\n+#if INCLUDE_TSAN\n+#include \"runtime\/sharedRuntime.hpp\"\n+#endif\n@@ -70,0 +73,21 @@\n+#if INCLUDE_TSAN\n+\n+TemplateTable::TsanMemoryReleaseAcquireFunction TemplateTable::tsan_release_acquire_method(\n+    TsanMemoryReadWriteFunction tsan_function) {\n+  if (tsan_function == SharedRuntime::tsan_read1\n+      || tsan_function == SharedRuntime::tsan_read2\n+      || tsan_function == SharedRuntime::tsan_read4\n+      || tsan_function == SharedRuntime::tsan_read8) {\n+    return SharedRuntime::tsan_acquire;\n+  } else if (tsan_function == SharedRuntime::tsan_write1\n+      || tsan_function == SharedRuntime::tsan_write2\n+      || tsan_function == SharedRuntime::tsan_write4\n+      || tsan_function == SharedRuntime::tsan_write8) {\n+    return SharedRuntime::tsan_release;\n+  }\n+  ShouldNotReachHere();\n+  return NULL;\n+}\n+\n+#endif\n+\n","filename":"src\/hotspot\/share\/interpreter\/templateTable.cpp","additions":24,"deletions":0,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -348,0 +348,33 @@\n+#if INCLUDE_TSAN\n+   typedef void (*TsanMemoryReleaseAcquireFunction)(void* \/* address *\/);\n+\n+   typedef void (*TsanMemoryReadWriteFunction)(void* \/* address *\/,\n+                                               Method* \/* method *\/,\n+                                               address \/* bcp *\/);\n+\n+   \/\/ The corresponding tsan_acquire\/release function for a\n+   \/\/ TsanMemoryReadWriteFunction.\n+   static TsanMemoryReleaseAcquireFunction tsan_release_acquire_method(TsanMemoryReadWriteFunction tsan_function);\n+\n+   \/\/ Tell tsan that a member\/static variable has been read from or written to.\n+   \/\/ tsan_function must be one of the SharedRuntime::tsan_read\/write*\n+   \/\/ functions.\n+   \/\/ Flags is the register that contains the field cache entry flags bitfield.\n+   \/\/ Because the field may be volatile, for a write, this function must be\n+   \/\/ called before the write; for a read, this function must be called after\n+   \/\/ the read. This way the acquire\/release is ordered correctly relative to the\n+   \/\/ read\/write.\n+   static void tsan_observe_get_or_put(const Address &field,\n+                                       Register flags,\n+                                       TsanMemoryReadWriteFunction tsan_function,\n+                                       TosState tos);\n+\n+   \/\/ Tell tsan that an array has been read from or written to.\n+   \/\/ tsan_function must be one of the SharedRuntime::tsan_read\/write*\n+   \/\/ functions.\n+   \/\/ Unlike tsan_observe_get_or_put(), the ordering relative to the\n+   \/\/ read\/write does not matter since array loads\/stores are never volatile.\n+   static void tsan_observe_load_or_store(const Address& address,\n+                                          TsanMemoryReadWriteFunction tsan_function);\n+#endif\n+\n","filename":"src\/hotspot\/share\/interpreter\/templateTable.hpp","additions":33,"deletions":0,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -138,1 +138,2 @@\n-                                       bool is_volatile) {\n+                                       bool is_volatile,\n+                                       bool is_tsan_ignore) {\n@@ -145,1 +146,2 @@\n-                  ((is_final    ? 1 : 0) << is_final_shift),\n+                  ((is_final    ? 1 : 0) << is_final_shift) |\n+                  ((is_tsan_ignore ? 1 : 0) << is_tsan_ignore_shift),\n","filename":"src\/hotspot\/share\/oops\/cpCache.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -184,0 +184,1 @@\n+    is_tsan_ignore_shift       = 27,  \/\/ Should the field be ignored by TSAN?\n@@ -226,1 +227,2 @@\n-    bool            is_volatile                  \/\/ the field is volatile\n+    bool            is_volatile,                 \/\/ the field is volatile\n+    bool            is_tsan_ignore               \/\/ the field should be ignored by TSAN\n","filename":"src\/hotspot\/share\/oops\/cpCache.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -168,0 +168,10 @@\n+#if INCLUDE_TSAN\n+  bool is_tsan_ignore() const {\n+    return (access_flags() & JVM_ACC_FIELD_TSAN_IGNORE) != 0;\n+  }\n+  void set_tsan_ignore(bool z) {\n+    if (z) _shorts[access_flags_offset] |=  JVM_ACC_FIELD_TSAN_IGNORE;\n+    else   _shorts[access_flags_offset] &= ~JVM_ACC_FIELD_TSAN_IGNORE;\n+  }\n+#endif  \/\/ INCLUDE_TSAN\n+\n","filename":"src\/hotspot\/share\/oops\/fieldInfo.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -98,0 +98,3 @@\n+#if INCLUDE_TSAN\n+#include \"runtime\/sharedRuntime.hpp\"\n+#endif\n@@ -785,0 +788,7 @@\n+    TSAN_RUNTIME_ONLY(\n+      \/\/ Construct a happens-before edge between the write of _init_state to\n+      \/\/ fully_initialized and the later checking if it's initialized.\n+      void* const lock_address = reinterpret_cast<void*>(\n+          java_lang_Class::init_lock_addr(java_mirror()));\n+      SharedRuntime::tsan_release(lock_address);\n+    );\n@@ -806,0 +816,7 @@\n+    TSAN_RUNTIME_ONLY(\n+      \/\/ Construct a happens-before edge between the write of _init_state to\n+      \/\/ fully_initialized and here.\n+      void* const lock_address = reinterpret_cast<void*>(\n+          java_lang_Class::init_lock_addr(java_mirror()));\n+      SharedRuntime::tsan_acquire(lock_address);\n+    );\n@@ -1179,0 +1196,7 @@\n+    TSAN_RUNTIME_ONLY(\n+      \/\/ Construct a happens-before edge between the write of _init_state to\n+      \/\/ fully_initialized and the later checking if it's initialized.\n+      void* const lock_address = reinterpret_cast<void*>(\n+          java_lang_Class::init_lock_addr(java_mirror()));\n+      SharedRuntime::tsan_release(lock_address);\n+    );\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":24,"deletions":0,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -95,0 +95,3 @@\n+#if INCLUDE_TSAN\n+#include \"tsan\/tsan.hpp\"\n+#endif  \/\/ INCLUDE_TSAN\n@@ -3188,0 +3191,8 @@\n+\/\/ java.lang.ref.Finalizer \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+JVM_ENTRY(jboolean, JVM_GetTsanEnabled(JNIEnv *env))\n+  TSAN_ONLY(return ThreadSanitizer;)\n+  NOT_TSAN(return JNI_FALSE;)\n+JVM_END\n+\n+\n@@ -3431,1 +3442,3 @@\n-  return new os::PlatformMutex();\n+  void *mon = new os::PlatformMutex();\n+  TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_CREATE(mon));\n+  return mon;\n@@ -3437,0 +3450,1 @@\n+  TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_DESTROY(mon));\n@@ -3443,0 +3457,1 @@\n+  TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_ACQUIRED(mon));\n@@ -3450,0 +3465,1 @@\n+  TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_RELEASED(mon));\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":17,"deletions":1,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -79,0 +79,3 @@\n+#if INCLUDE_TSAN\n+#include \"tsan\/tsan.hpp\"\n+#endif  \/\/ INCLUDE_TSAN\n@@ -3080,0 +3083,4 @@\n+\/\/ Tsan note: The JVMTI raw monitors are instrumented at JvmtiRawMonitor call\n+\/\/ sites instead of inside the JvmtiRawMonitor implementation. This seems\n+\/\/ cleaner, and mirrors instrumentation of JVM_RawMonitor* functions.\n+\n@@ -3089,0 +3096,2 @@\n+  TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_CREATE(rmonitor));\n+\n@@ -3111,0 +3120,1 @@\n+        TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_RELEASED(rmonitor));\n@@ -3129,0 +3139,1 @@\n+  TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_DESTROY(rmonitor));\n@@ -3151,0 +3162,1 @@\n+    TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_ACQUIRED(rmonitor));\n@@ -3169,0 +3181,1 @@\n+    TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_RELEASED(rmonitor));\n@@ -3182,0 +3195,4 @@\n+\n+  \/\/ A wait is modeled in Tsan as a simple release-acquire pair.\n+  \/\/ The matching release annotation is below.\n+  TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_RELEASED(rmonitor));\n@@ -3185,0 +3202,2 @@\n+  \/\/ The matching acquire annotation is above.\n+  TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_ACQUIRED(rmonitor));\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnv.cpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -32,0 +32,3 @@\n+#if INCLUDE_TSAN\n+#include \"tsan\/tsan.hpp\"\n+#endif  \/\/ INCLUDE_TSAN\n@@ -51,0 +54,1 @@\n+      TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_ACQUIRED(rmonitor));\n","filename":"src\/hotspot\/share\/prims\/jvmtiRawMonitor.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -69,0 +69,3 @@\n+#if INCLUDE_TSAN\n+#include \"tsan\/tsan.hpp\"\n+#endif  \/\/ INCLUDE_TSAN\n@@ -70,0 +73,16 @@\n+\/\/ Tsan should know that the JVMTI TagMap is protected by a mutex.\n+class TsanMutexScope : public StackObj {\n+ private:\n+  Mutex *_lock;  \/\/ Keep my own reference, for destructor.\n+\n+ public:\n+  \/\/ Don't actually lock it, just tell tsan we did.\n+  TsanMutexScope(Mutex* mutex) : _lock(mutex) {\n+    TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_ACQUIRED(_lock));\n+  }\n+\n+  ~TsanMutexScope() {\n+    TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_RELEASED(_lock));\n+  }\n+};\n+\n@@ -84,0 +103,18 @@\n+  \/\/ TSAN Note: we cannot tell TSAN about the creation of this lock due to\n+  \/\/ this being seen as racy though is not really.\n+  \/\/\n+  \/\/ The JvmtiTagMap gets created by the first thread to call tag_map_for; which\n+  \/\/ uses a lock to create it if need be.\n+  \/\/\n+  \/\/ This means that this lock is created under a mutex but then,\n+  \/\/ subsequent uses do not have a lock to protect it (because not\n+  \/\/ needed in this case), however TSAN sees it as being needed because:\n+  \/\/  - Another thread can come and get the newly created JvmtiTagMap without a\n+  \/\/  lock and acquire the lock.\n+  \/\/  - This provokes a race for TSAN on the lock itself, though there is no\n+  \/\/  real issue.\n+  \/\/\n+  \/\/  Not creating the lock or having a fence mechanism to tell TSAN this is\n+  \/\/  safe (a fake lock around this lock for example) seem to be the only\n+  \/\/  solutions.\n+\n@@ -92,1 +129,0 @@\n-\n@@ -100,0 +136,2 @@\n+\n+  \/\/ TSAN Note: see above for the Tsan creation note.\n@@ -357,0 +395,1 @@\n+  TSAN_ONLY(TsanMutexScope tms(lock()));\n@@ -392,0 +431,1 @@\n+  TSAN_ONLY(TsanMutexScope tms(lock()));\n@@ -891,0 +931,2 @@\n+  JvmtiTagMap* _tag_map;\n+\n@@ -892,1 +934,4 @@\n-  VM_HeapIterateOperation(ObjectClosure* blk) { _blk = blk; }\n+  VM_HeapIterateOperation(ObjectClosure* blk, JvmtiTagMap* tag_map) {\n+    _blk = blk;\n+    _tag_map = tag_map;\n+  }\n@@ -896,0 +941,6 @@\n+    \/\/ Simulates barrier synchronization on safepoint.\n+    \/\/ This annotation is reasonably minimal in number of tsan callbacks.\n+    \/\/ By passing the lock directly, we are not actually locking it, just\n+    \/\/ telling TSAN we are to \"simulate\" the lock.\n+    TSAN_ONLY(TsanMutexScope tms(_tag_map->lock()));\n+\n@@ -1144,1 +1195,1 @@\n-  VM_HeapIterateOperation op(&blk);\n+  VM_HeapIterateOperation op(&blk, this);\n@@ -1164,1 +1215,1 @@\n-  VM_HeapIterateOperation op(&blk);\n+  VM_HeapIterateOperation op(&blk, this);\n@@ -1324,0 +1375,1 @@\n+    TSAN_ONLY(TsanMutexScope tms(lock()));\n@@ -2929,0 +2981,5 @@\n+  \/\/ This annotation is reasonably minimal in number of tsan callbacks.\n+  \/\/ By passing the lock directly, we are not actually locking it, just\n+  \/\/ telling TSAN we are to \"simulate\" the lock.\n+  TSAN_ONLY(TsanMutexScope tms(_tag_map->lock()));\n+\n","filename":"src\/hotspot\/share\/prims\/jvmtiTagMap.cpp","additions":61,"deletions":4,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -60,0 +60,3 @@\n+\n+  inline Mutex* lock()                      { return &_lock; }\n+\n@@ -62,1 +65,0 @@\n-  inline Mutex* lock()                      { return &_lock; }\n","filename":"src\/hotspot\/share\/prims\/jvmtiTagMap.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -62,0 +62,3 @@\n+#if INCLUDE_TSAN\n+#include \"tsan\/tsanExternalDecls.hpp\"\n+#endif\n@@ -269,0 +272,8 @@\n+  TSAN_RUNTIME_ONLY(\n+    void* addr = index_oop_from_field_offset_long(p, offset);\n+    if (UseCompressedOops) {\n+      __tsan_read4_pc(addr, SharedRuntime::tsan_code_location(0, 0));\n+    } else {\n+      __tsan_read8_pc(addr, SharedRuntime::tsan_code_location(0, 0));\n+    }\n+  );\n@@ -276,0 +287,8 @@\n+  TSAN_RUNTIME_ONLY(\n+    void* addr = index_oop_from_field_offset_long(p, offset);\n+    if (UseCompressedOops) {\n+      __tsan_write4_pc(addr, SharedRuntime::tsan_code_location(0, 0));\n+    } else {\n+      __tsan_write8_pc(addr, SharedRuntime::tsan_code_location(0, 0));\n+    }\n+  );\n@@ -283,0 +302,4 @@\n+  TSAN_RUNTIME_ONLY(\n+    void* addr = index_oop_from_field_offset_long(p, offset);\n+    __tsan_java_acquire(addr);\n+  );\n@@ -290,0 +313,4 @@\n+  TSAN_RUNTIME_ONLY(\n+    void* addr = index_oop_from_field_offset_long(p, offset);\n+    __tsan_java_release(addr);\n+  );\n@@ -298,1 +325,1 @@\n-#define DEFINE_GETSETOOP(java_type, Type) \\\n+#define DEFINE_GETSETOOP(java_type, Type, size) \\\n@@ -301,1 +328,6 @@\n-  return MemoryAccess<java_type>(thread, obj, offset).get(); \\\n+  java_type ret = MemoryAccess<java_type>(thread, obj, offset).get(); \\\n+  TSAN_RUNTIME_ONLY( \\\n+    void* addr = index_oop_from_field_offset_long(JNIHandles::resolve(obj), offset); \\\n+    __tsan_read##size##_pc(addr, SharedRuntime::tsan_code_location(0, 0)); \\\n+  ); \\\n+  return ret; \\\n@@ -305,0 +337,4 @@\n+  TSAN_RUNTIME_ONLY( \\\n+    void* addr = index_oop_from_field_offset_long(JNIHandles::resolve(obj), offset); \\\n+    __tsan_write##size##_pc(addr, SharedRuntime::tsan_code_location(0, 0)); \\\n+  ); \\\n@@ -310,8 +346,8 @@\n-DEFINE_GETSETOOP(jboolean, Boolean)\n-DEFINE_GETSETOOP(jbyte, Byte)\n-DEFINE_GETSETOOP(jshort, Short);\n-DEFINE_GETSETOOP(jchar, Char);\n-DEFINE_GETSETOOP(jint, Int);\n-DEFINE_GETSETOOP(jlong, Long);\n-DEFINE_GETSETOOP(jfloat, Float);\n-DEFINE_GETSETOOP(jdouble, Double);\n+DEFINE_GETSETOOP(jboolean, Boolean, 1)\n+DEFINE_GETSETOOP(jbyte, Byte, 1)\n+DEFINE_GETSETOOP(jshort, Short, 2);\n+DEFINE_GETSETOOP(jchar, Char, 2);\n+DEFINE_GETSETOOP(jint, Int, 4);\n+DEFINE_GETSETOOP(jlong, Long, 8);\n+DEFINE_GETSETOOP(jfloat, Float, 4);\n+DEFINE_GETSETOOP(jdouble, Double, 8);\n@@ -324,1 +360,6 @@\n-  return MemoryAccess<java_type>(thread, obj, offset).get_volatile(); \\\n+  java_type ret = MemoryAccess<java_type>(thread, obj, offset).get_volatile(); \\\n+  TSAN_RUNTIME_ONLY( \\\n+    void* addr = index_oop_from_field_offset_long(JNIHandles::resolve(obj), offset); \\\n+    __tsan_java_acquire(addr); \\\n+  ); \\\n+  return ret; \\\n@@ -328,0 +369,4 @@\n+  TSAN_RUNTIME_ONLY( \\\n+    void* addr = index_oop_from_field_offset_long(JNIHandles::resolve(obj), offset); \\\n+    __tsan_java_release(addr); \\\n+  ); \\\n@@ -737,0 +782,24 @@\n+\/\/ Calls __tsan_java_release() on construct and __tsan_java_acquire() on destruct.\n+class ScopedReleaseAcquire: public StackObj {\n+private:\n+  void* _addr;\n+public:\n+  ScopedReleaseAcquire(volatile void* addr) {\n+    TSAN_RUNTIME_ONLY(\n+      _addr = const_cast<void*>(addr);\n+      __tsan_java_release(_addr);\n+    );\n+  }\n+\n+  ScopedReleaseAcquire(oop obj, jlong offset) {\n+    TSAN_RUNTIME_ONLY(\n+      _addr = index_oop_from_field_offset_long(obj, offset);\n+      __tsan_java_release(_addr);\n+    );\n+  }\n+\n+  ~ScopedReleaseAcquire() {\n+    TSAN_RUNTIME_ONLY(__tsan_java_acquire(_addr));\n+  }\n+};\n+\n@@ -742,0 +811,1 @@\n+  ScopedReleaseAcquire releaseAcquire(p, offset);\n@@ -750,0 +820,1 @@\n+    ScopedReleaseAcquire releaseAcquire(addr);\n@@ -753,0 +824,1 @@\n+    ScopedReleaseAcquire releaseAcquire(p, offset);\n@@ -761,0 +833,1 @@\n+    ScopedReleaseAcquire releaseAcquire(addr);\n@@ -764,0 +837,1 @@\n+    ScopedReleaseAcquire releaseAcquire(p, offset);\n@@ -773,0 +847,1 @@\n+  ScopedReleaseAcquire releaseAcquire(p, offset);\n@@ -781,0 +856,1 @@\n+    ScopedReleaseAcquire releaseAcquire(addr);\n@@ -784,0 +860,1 @@\n+    ScopedReleaseAcquire releaseAcquire(p, offset);\n@@ -792,0 +869,1 @@\n+    ScopedReleaseAcquire releaseAcquire(addr);\n@@ -795,0 +873,1 @@\n+    ScopedReleaseAcquire releaseAcquire(p, offset);\n","filename":"src\/hotspot\/share\/prims\/unsafe.cpp","additions":90,"deletions":11,"binary":false,"changes":101,"status":"modified"},{"patch":"@@ -3991,0 +3991,12 @@\n+  TSAN_RUNTIME_ONLY(\n+    \/\/ Currently TSAN is only implemented for interpreter.\n+    set_mode_flags(_int);\n+    \/\/ TSAN instrumentation is not implemented for the RewriteBytecodes\n+    \/\/ code paths because TSAN slows down the application so much that the\n+    \/\/ performance benefits from rewriting bytecodes is negligible.\n+    FLAG_SET_ERGO(RewriteBytecodes, false);\n+    FLAG_SET_ERGO(RewriteFrequentPairs, false);\n+    \/\/ Turn off CDS, it interferes with eagerly allocating jmethodIDs.\n+    no_shared_spaces(\"CDS is not compatible with TSAN\");\n+  );\n+\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2083,0 +2083,10 @@\n+  TSAN_ONLY(product(bool, ThreadSanitizer, false,                           \\\n+          \"Enable ThreadSanitizer lock instrumentation\"))                   \\\n+                                                                            \\\n+  TSAN_ONLY(product(bool, ThreadSanitizerJavaMemory, true,                  \\\n+          \"Detect Java data races with ThreadSanitizer. \"                   \\\n+          \"This is only enabled if -XX:+ThreadSanitizer is set.\"))          \\\n+                                                                            \\\n+  TSAN_ONLY(product(ccstr, ThreadSanitizerIgnoreFile, NULL,                 \\\n+          \"File containing a list of ignored field patterns for \"           \\\n+          \"ThreadSanitizer.\"))                                              \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -73,0 +73,1 @@\n+TSAN_ONLY(jint tsan_init();)\n@@ -100,0 +101,1 @@\n+TSAN_ONLY(void tsan_exit();)\n@@ -112,1 +114,0 @@\n-\n@@ -127,0 +128,7 @@\n+  TSAN_RUNTIME_ONLY(\n+    status = tsan_init();\n+    if (status != JNI_OK) {\n+      return status;\n+    }\n+  );\n+\n@@ -178,0 +186,3 @@\n+\n+    TSAN_RUNTIME_ONLY(tsan_exit());\n+\n","filename":"src\/hotspot\/share\/runtime\/init.cpp","additions":12,"deletions":1,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -135,0 +135,4 @@\n+#if INCLUDE_TSAN\n+Mutex*   TsanOopMap_lock              = NULL;\n+#endif\n+\n@@ -327,0 +331,4 @@\n+  TSAN_RUNTIME_ONLY(\n+    def(TsanOopMap_lock            , PaddedMutex  , special,     true,  _safepoint_check_never);\n+  );\n+\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -144,0 +144,3 @@\n+#if INCLUDE_TSAN\n+extern Mutex*   TsanOopMap_lock;                 \/\/ guards shared map of oops\n+#endif\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -82,0 +82,4 @@\n+#if INCLUDE_TSAN\n+#include \"tsan\/tsanExternalDecls.hpp\"\n+#include \"tsan\/tsanOopMap.hpp\"\n+#endif\n@@ -1049,0 +1053,170 @@\n+#if INCLUDE_TSAN\n+\n+JRT_LEAF(void, SharedRuntime::verify_oop_index(oopDesc* obj, int index))\n+  assert(oopDesc::is_oop(obj), \"invalid oop\");\n+  assert(index >= 0, \"index is less than 0\");\n+  int obj_size_in_bytes = obj->size() * HeapWordSize;\n+  assert(index < obj_size_in_bytes, \"index %d >= obj size %d\", index, obj_size_in_bytes);\n+JRT_END\n+\n+\/\/ TSAN: method entry callback from interpreter\n+\/\/ (1) In order to have the line numbers in the call stack, we use the caller\n+\/\/     address instead of the method that's being called. This also matches\n+\/\/     the entry\/exit convention that TSAN uses for C++.\n+\/\/ We use JRT_ENTRY since call_VM_leaf doesn't set _last_Java_sp that we need.\n+JRT_ENTRY(void, SharedRuntime::tsan_interp_method_entry(JavaThread* current))\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  DEBUG_ONLY(NoHandleMark nhm;)\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+\n+  RegisterMap unused_reg_map(current, false);\n+\n+  \/\/ These asserts should be removed once\n+  \/\/ we support more than just the interpreter for TSAN.\n+  assert(!current->last_frame().is_compiled_frame(),\n+         \"Current frame should not be a compiled frame\");\n+  const frame sender = current->last_frame().real_sender(&unused_reg_map);\n+  assert(!sender.is_compiled_frame(), \"Sender should not be a compiled frame\");\n+\n+  jmethodID jmethod_id = 0;\n+  u2 bci = 0;\n+  \/\/ TODO: is (0, 0) really the best we can do\n+  \/\/ when the sender isn't an interpreted frame?\n+  if (sender.is_interpreted_frame()) {\n+    jmethod_id = sender.interpreter_frame_method()->find_jmethod_id_or_null();\n+    bci = sender.interpreter_frame_bci();\n+  }\n+  __tsan_func_entry(tsan_code_location(jmethod_id, bci));\n+JRT_END\n+\n+\/\/ TSAN: method exit callback from interpreter\n+JRT_LEAF(void, SharedRuntime::tsan_interp_method_exit())\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+  __tsan_func_exit();\n+JRT_END\n+\n+void SharedRuntime::tsan_oop_lock(Thread* thread, oop obj) {\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+  assert(thread != NULL, \"null thread\");\n+  assert(obj != NULL, \"null oop\");\n+  assert(oopDesc::is_oop(obj), \"invalid oop\");\n+\n+  TsanOopMap::add_oop(obj);\n+  __tsan_java_mutex_lock((julong)(oopDesc*)obj);\n+}\n+\n+void SharedRuntime::tsan_oop_unlock(Thread *thread, oop obj) {\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+  assert(thread != NULL, \"null thread\");\n+  assert(obj != NULL, \"null oop\");\n+  assert(oopDesc::is_oop(obj), \"invalid oop\");\n+  assert(TsanOopMap::exists(obj), \"oop seen in unlock but not tracked\");\n+\n+  __tsan_java_mutex_unlock((julong)(oopDesc*)obj);\n+}\n+\n+void SharedRuntime::tsan_oop_rec_lock(Thread* thread, oop obj, int rec) {\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+  assert(thread != NULL, \"null thread\");\n+  assert(obj != NULL, \"null oop\");\n+  assert(oopDesc::is_oop(obj), \"invalid oop\");\n+\n+  TsanOopMap::add_oop(obj);\n+  __tsan_java_mutex_lock_rec((julong)(oopDesc*)obj, rec);\n+}\n+\n+int SharedRuntime::tsan_oop_rec_unlock(Thread *thread, oop obj) {\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+  assert(thread != NULL, \"null thread\");\n+  assert(obj != NULL, \"null oop\");\n+  assert(oopDesc::is_oop(obj), \"invalid oop\");\n+  assert(TsanOopMap::exists(obj), \"oop seen in unlock but not tracked\");\n+\n+  return __tsan_java_mutex_unlock_rec((julong)(oopDesc*)obj);\n+}\n+\n+JRT_LEAF(void, SharedRuntime::tsan_interp_lock(JavaThread* thread,\n+                                               BasicObjectLock* elem))\n+  DEBUG_ONLY(thread->last_frame().interpreter_frame_verify_monitor(elem);)\n+  assert(elem != NULL, \"null elem\");\n+\n+  oop obj = elem->obj();\n+  tsan_oop_lock(thread, obj);\n+\n+  assert(obj == elem->obj(), \"oop changed\");\n+  DEBUG_ONLY(thread->last_frame().interpreter_frame_verify_monitor(elem);)\n+JRT_END\n+\n+JRT_LEAF(void, SharedRuntime::tsan_interp_unlock(JavaThread* thread,\n+                                                 BasicObjectLock* elem))\n+  DEBUG_ONLY(thread->last_frame().interpreter_frame_verify_monitor(elem);)\n+  assert(elem != NULL, \"null elem\");\n+\n+  oop obj = elem->obj();\n+  tsan_oop_unlock(thread, obj);\n+\n+  assert(obj == elem->obj(), \"oop changed\");\n+  DEBUG_ONLY(thread->last_frame().interpreter_frame_verify_monitor(elem);)\n+JRT_END\n+\n+\/\/ Should be JRT_LEAF, but this is called very early during VM startup, so we\n+\/\/ are sometimes in '_thread_in_vm' state.\n+\/\/ NOTE: DO NOT add operations that can safepoint, enter GC, or throw an\n+\/\/ exception!\n+void SharedRuntime::tsan_track_obj_with_size(oopDesc* obj, int size) {\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+  assert(oopDesc::is_oop(obj), \"Bad oopDesc passed to tsan_track_obj_with_size().\");\n+  TsanOopMap::add_oop_with_size(obj, size);\n+}\n+\n+JRT_LEAF(void, SharedRuntime::tsan_track_obj(oopDesc* obj))\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+  assert(oopDesc::is_oop(obj), \"Bad oopDesc passed to tsan_track_obj().\");\n+  TsanOopMap::add_oop(obj);\n+JRT_END\n+\n+\/\/ TODO: Make tsan_acquire\/release JRT_LEAF\n+\/\/ Currently it can't be JRT_LEAF because there are calls from the VM\n+\/\/ (instanceKlass.cpp), and JRT_LEAF only allows calls from Java\/native code.\n+\/\/ We need to figure out a better way of being able to call TSAN functions from\n+\/\/ the VM.\n+void SharedRuntime::tsan_acquire(void* address) {\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+  assert(address != NULL, \"Cannot acquire at address 0\");\n+  __tsan_java_acquire(address);\n+}\n+\n+void SharedRuntime::tsan_release(void* address) {\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");\n+  assert(address != NULL, \"Cannot release at address 0\");\n+  __tsan_java_release(address);\n+}\n+\n+#define TSAN_MEMORY_ACCESS(name)                                               \\\n+  JRT_LEAF(void, SharedRuntime::tsan_##name(                                   \\\n+      void* addr,                                                              \\\n+      Method* method,                                                          \\\n+      address bcp))                                                            \\\n+    assert(ThreadSanitizer, \"Need -XX:+ThreadSanitizer\");                      \\\n+    assert(ThreadSanitizerJavaMemory, \"Need -XX:+ThreadSanitizerJavaMemory\");  \\\n+    jmethodID mid = method->find_jmethod_id_or_null();                         \\\n+    int bci = method->bci_from(bcp);                                           \\\n+    __tsan_##name##_pc(addr, tsan_code_location(mid, bci));                    \\\n+  JRT_END\n+\n+TSAN_MEMORY_ACCESS(read1)\n+TSAN_MEMORY_ACCESS(read2)\n+TSAN_MEMORY_ACCESS(read4)\n+TSAN_MEMORY_ACCESS(read8)\n+TSAN_MEMORY_ACCESS(write1)\n+TSAN_MEMORY_ACCESS(write2)\n+TSAN_MEMORY_ACCESS(write4)\n+TSAN_MEMORY_ACCESS(write8)\n+\n+#endif \/\/ INCLUDE_TSAN\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":174,"deletions":0,"binary":false,"changes":174,"status":"modified"},{"patch":"@@ -279,0 +279,91 @@\n+#if INCLUDE_TSAN\n+  \/\/ TSAN instrumentation\n+\n+  \/\/ TSAN uses a 64-bit value to identify code location.\n+  \/\/ TSAN uses the uppermost 3 bits (63:61) for the internal purposes.\n+  \/\/ If bit 60 is set, TSAN recognizes that the code location belongs to the\n+  \/\/ JVM, and will call __tsan_symbolize_external_ex() for symbolization rather\n+  \/\/ than TSAN's own symbolizer. See __sanitizer::kExternalPCBit and\n+  \/\/ __tsan::__tsan_symbolize_external_ex() in TSAN for more details.\n+  \/\/ The lower 60 bits may contain either a packed bytecode location, or an\n+  \/\/ instruction address inside the code generated by JIT compiler.\n+  \/\/ A packed code location has the method ID in bits 59:16 and the bytecode\n+  \/\/offset within method in bits 15:0. 44 bits (59:16) are enough to encode any\n+  \/\/ 47-bit 8-byte-aligned address, which is the maximum address space TSAN\n+  \/\/ allows. The next 16 bits are used for storing the bci.\n+  \/\/ | Tsan: 3 | TsanJava: 1 | jmethodID: 44 | BCI: 16 |\n+  static const int tsan_method_id_alignment_bits = 3;\n+  static const int tsan_bci_bits = 16;\n+  static const u8 tsan_bci_mask = right_n_bits(tsan_bci_bits);\n+  static const int tsan_method_id_shift = tsan_bci_bits -\n+      tsan_method_id_alignment_bits;\n+  static const u8 tsan_fake_pc_bit = 1L << 60;\n+  static void * tsan_code_location(jmethodID jmethod_id_ptr, u2 bci) {\n+    return (void *)(tsan_fake_pc_bit |\n+      (((u8)(jmethod_id_ptr)) << tsan_method_id_shift) | bci);\n+  }\n+  static jmethodID tsan_method_id_from_code_location(u8 loc) {\n+    u8 id =\n+        (loc & ~(tsan_fake_pc_bit | tsan_bci_mask)) >> tsan_method_id_shift;\n+\n+    \/\/ Typical method ID in aarch64 is like 0xffff_xxxx_xxxx_xxxx, which couldn't be represented by 47-bits.\n+    \/\/ But there are only 3 application memory regions in tsan for 48bits aarch64, the highest 4 bits\n+    \/\/ of addresses are 0x0, 0xa and 0xf respectively. The encoding function tsan_code_location() will\n+    \/\/ overwrite bit 47 for internal purpose, Therefore, we restore bit 47 here according to\n+    \/\/ the value of bits 46:44. if it is 0x2 or 0x7, restore bit 47 to 1.\n+#ifdef AARCH64\n+    u8 highest4bits = id >> 44;\n+    if (highest4bits == 0x7ULL || highest4bits == 0x2ULL) {\n+      id |= (0x1ULL << 47);\n+    }\n+#endif\n+\n+    return (jmethodID)id;\n+  }\n+  static u2 tsan_bci_from_code_location(u8 loc) {\n+    return (u2)(loc & tsan_bci_mask);\n+  }\n+\n+  \/\/ These functions are wrappers around TSAN callbacks,\n+  \/\/ which are listed in tsanExternalDecls.hpp. The VM uses only these\n+  \/\/ functions to push events to ThreadSanitizer.\n+\n+  \/\/ Verify that an oop is valid and that the index is within the object size.\n+  static void verify_oop_index(oopDesc* obj, int index);\n+\n+  \/\/ Java method entry\/exit from code run by template interpreter\n+  static void tsan_interp_method_entry(JavaThread *thread);\n+  static void tsan_interp_method_exit();\n+\n+  \/\/ Monitor acquire\/release in VM code\n+  \/\/ (e.g., generated native method wrapper, JNI heavyweight locks)\n+  static void tsan_oop_lock(Thread* thread, oop obj);\n+  static void tsan_oop_unlock(Thread* thread, oop obj);\n+  \/\/ Monitor acquire\/release in VM code; recursive lock variant (e.g., wait())\n+  static void tsan_oop_rec_lock(Thread* thread, oop obj, int rec);\n+  static int tsan_oop_rec_unlock(Thread* thread, oop obj);\n+\n+  \/\/ Monitor acquire\/release from code run by template interpreter\n+  static void tsan_interp_lock(JavaThread* thread, BasicObjectLock* elem);\n+  static void tsan_interp_unlock(JavaThread* thread, BasicObjectLock* elem);\n+\n+  \/\/ Address must point to an object in the Java heap.\n+  static void tsan_acquire(void* address);\n+  static void tsan_release(void* address);\n+\n+  \/\/ Called whenever an obj is created.\n+  static void tsan_track_obj_with_size(oopDesc* obj, int size);\n+  static void tsan_track_obj(oopDesc* obj);\n+\n+  \/\/ Memory reads\/writes from code run by template interpreter\n+  static void tsan_read1(void* addr, Method* method, address bcp);\n+  static void tsan_read2(void* addr, Method* method, address bcp);\n+  static void tsan_read4(void* addr, Method* method, address bcp);\n+  static void tsan_read8(void* addr, Method* method, address bcp);\n+  static void tsan_write1(void* addr, Method* method, address bcp);\n+  static void tsan_write2(void* addr, Method* method, address bcp);\n+  static void tsan_write4(void* addr, Method* method, address bcp);\n+  static void tsan_write8(void* addr, Method* method, address bcp);\n+\n+#endif \/\/ INCLUDE_TSAN\n+\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":91,"deletions":0,"binary":false,"changes":91,"status":"modified"},{"patch":"@@ -537,0 +537,8 @@\n+\/\/ NOTE(TSAN): We cannot instrument complete_exit\/reenter in ObjectSynchronizer\n+\/\/             in a manner similar to wait and waitUninterruptibly, because\n+\/\/             (1) recursion count stored by inflated monitor is different from\n+\/\/             the absolute recursion count tracked by Tsan, and (2) in the\n+\/\/             general case, we cannot merely store Tsan's recursion count\n+\/\/             once: we must track it for *each invocation* of complete_exit.\n+\/\/             Hence, the best place to instrument for Tsan is at the call site\n+\/\/             for complete_exit\/reenter. Luckily, there is only one call site.\n@@ -593,0 +601,1 @@\n+  TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_lock(current, obj()));\n@@ -612,0 +621,1 @@\n+    TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_unlock(current, obj));\n@@ -626,0 +636,1 @@\n+    TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_lock(_thread, _obj()));\n@@ -631,0 +642,1 @@\n+    TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_unlock(_thread, _obj()));\n@@ -653,1 +665,8 @@\n-  DTRACE_MONITOR_WAIT_PROBE(monitor, obj(), current, millis);\n+  DTRACE_MONITOR_WAIT_PROBE(monitor, obj(), THREAD, millis);\n+\n+  TSAN_ONLY(int tsan_rec = 0;)\n+  TSAN_RUNTIME_ONLY(\n+    tsan_rec = SharedRuntime::tsan_oop_rec_unlock(THREAD, obj());\n+    assert(tsan_rec > 0, \"tsan: unlocking unlocked mutex\");\n+  );\n+\n@@ -656,0 +675,2 @@\n+  TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_rec_lock(THREAD, obj(), tsan_rec));\n+\n@@ -675,0 +696,5 @@\n+  TSAN_ONLY(int tsan_rec;)\n+  TSAN_RUNTIME_ONLY(\n+    tsan_rec = SharedRuntime::tsan_oop_rec_unlock(current, obj());\n+    assert(tsan_rec > 0, \"tsan: unlocking unlocked mutex\");\n+  );\n@@ -676,0 +702,1 @@\n+  TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_rec_lock(current, obj(), tsan_rec));\n@@ -1551,0 +1578,4 @@\n+      \/\/ Note well -- this occurs ONLY on thread exit, and is a last ditch\n+      \/\/ effort to release all locks. Hence, we don't need to record tsan's\n+      \/\/ recursion count -- it will never be locked again.\n+      TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_rec_unlock(_thread, (oop)mid->object()));\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":32,"deletions":1,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -0,0 +1,538 @@\n+\/*\n+ * Copyright (c) 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, Google and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"gc\/shared\/gcTraceTime.inline.hpp\"\n+#include \"gc\/shared\/gcId.hpp\"\n+#include \"gc\/shared\/referenceProcessor.hpp\"\n+#include \"memory\/resourceArea.hpp\"\n+#include \"oops\/oop.inline.hpp\"\n+#include \"runtime\/mutexLocker.hpp\"\n+#include \"runtime\/safepointVerifiers.hpp\"\n+#include \"tsan\/tsanExternalDecls.hpp\"\n+#include \"tsan\/tsanOopMap.hpp\"\n+#include \"utilities\/bitMap.inline.hpp\"\n+\n+extern \"C\" int jio_printf(const char *fmt, ...);\n+\n+#if 0\n+#define DEBUG_PRINT(...) jio_printf(__VA_ARGS__)\n+#else\n+#define DEBUG_PRINT(...)\n+#endif\n+namespace TsanOopMapImpl {\n+\n+  struct PendingMove {\n+    char *source_begin() const { return source_address; }\n+    char *source_end() const { return source_address + n_bytes; }\n+    char *target_begin() const { return target_address; }\n+    char *target_end() const { return target_address + n_bytes; }\n+    char *source_address;\n+    char *target_address;\n+    size_t n_bytes;  \/\/ number of bytes being moved\n+  };\n+\n+  \/\/ Our data\n+  class TsanOopSizeMap *oop_map = NULL;\n+\n+  \/**\n+   * TsanOopSizeMap is a hash map of {oopDesc * -> size}.\n+   *\/\n+  class TsanOopSizeMap : public CHeapObj<mtInternal> {\n+\n+    class TsanOop : public CHeapObj<mtInternal> {\n+      \/* We track the lifecycle (alloc\/move\/free) of interesting oops;\n+       * tsan needs to know. *\/\n+      oopDesc *_oop;  \/\/ key\n+\n+      \/* We cache the oop's size, since we cannot reliably determine it after\n+       * the oop is freed. Size is measured in number of HeapWords. *\/\n+      uintx _oop_size;  \/\/ value\n+\n+    public:\n+      TsanOop():_oop(NULL), _oop_size(0) {}\n+      void set_oop(oopDesc *o, uintx s) { _oop = o; _oop_size = s; }\n+      bool has_oop() const { return _oop != NULL; }\n+      oopDesc *get_oop() const { return _oop; }\n+      uintx get_oop_size() const { return _oop_size; }\n+    };\n+\n+    size_t _size;\n+    size_t _n_elements;\n+    float _load_factor;\n+    TsanOop *_buckets;\n+\n+    static uintx _hash64(uintx key) {\n+      key = ~key + (key << 21);\n+      key ^= (key >> 24);\n+      key += (key << 3) + (key << 8);\n+      key ^= (key >> 14);\n+      key += (key << 2) + (key << 4);\n+      key ^= (key >> 28);\n+      key += (key << 31);\n+      return key;\n+    }\n+\n+    static uintx _hash32(uintx key) {\n+      key = ~key + (key << 15);\n+      key ^= (key >> 12);\n+      key += (key << 2);\n+      key ^= (key >> 4);\n+      key *= 2057;\n+      key ^= (key >> 16);\n+      return key;\n+    }\n+\n+    TsanOop* find_bucket(oopDesc* o) {\n+      uintx h = reinterpret_cast<uintx>((address)o);\n+      TsanOop* bucket;\n+      do {\n+        h = hash(h);\n+        bucket = &_buckets[h % _size];\n+      } while (bucket->has_oop() && bucket->get_oop() != o);\n+      return bucket;\n+    }\n+\n+    static bool collect_oops(BoolObjectClosure* is_alive,\n+                             OopClosure* f,\n+                             GrowableArray<PendingMove>* moves,\n+                             int* n_downward_moves,\n+                             char** min_low,\n+                             char** max_high);\n+\n+    static void handle_overlapping_moves(GrowableArray<PendingMove>& moves,\n+                                         char* min_low,\n+                                         char* max_high);\n+\n+  public:\n+    TsanOopSizeMap(size_t initial_size)\n+        : _size(initial_size), _n_elements(0), _load_factor(0.7) {\n+      _buckets = new TsanOop[_size];\n+    }\n+\n+    ~TsanOopSizeMap() {\n+      delete [] _buckets;\n+    }\n+\n+    static uintx hash(uintx key) {\n+      return (sizeof(uintx) == 4) ? _hash32(key) : _hash64(key);\n+    }\n+\n+    \/\/ Put an oop and oop size into the hash map.\n+    \/\/ Ok to call multiple times on same oop.\n+    \/\/ Return true if seen for first time; else return false.\n+    \/\/ Synchronized in mutator threads with TsanOopMap_lock.\n+    bool put(oopDesc* o, uintx s) {\n+      TsanOop* bucket = find_bucket(o);\n+\n+      if (!bucket->has_oop()) {\n+        if (++_n_elements > _load_factor * _size) {\n+          grow();\n+          bucket = find_bucket(o);\n+        }\n+        bucket->set_oop(o, s);\n+        return true;\n+      } else {\n+        assert(s == bucket->get_oop_size(), \"same oop should have same size\");\n+        return false;\n+      }\n+    }\n+\n+    void grow(void) {\n+      TsanOop *old_buckets = _buckets;\n+      size_t old_size = _size;\n+      _size *= 2;\n+\n+      _buckets = new TsanOop[_size];\n+\n+      for (uintx i = 0; i < old_size; i++) {\n+        if (old_buckets[i].has_oop()) {\n+          put(old_buckets[i].get_oop(), old_buckets[i].get_oop_size());\n+        }\n+      }\n+      delete [] old_buckets;\n+    }\n+\n+    \/\/ Call this function at the end of the garbage collection to\n+    \/\/ notify TSan about object location changes and to build oops map.\n+    static void rebuild_oops_map(BoolObjectClosure *is_alive,\n+                                 OopClosure *pointer_adjuster);\n+\n+#ifdef ASSERT\n+    bool exists(oopDesc *o) const {\n+      uintx h = reinterpret_cast<uintx>((address)o);\n+      TsanOop *bucket = NULL;\n+\n+      do {\n+        h = hash(h);\n+        bucket = &_buckets[h % _size];\n+      } while (bucket->has_oop() && bucket->get_oop() != o);\n+\n+      return bucket->has_oop() && bucket->get_oop() == o;\n+    }\n+#endif\n+\n+    size_t size() const { return _size; }\n+    oopDesc *oop_at(size_t i) const { return _buckets[i].get_oop(); }\n+    uintx oop_size_at(size_t i) const { return _buckets[i].get_oop_size(); }\n+  };\n+\n+  \/\/ Two little callbacks used by sort.\n+  int lessThan(PendingMove *l, PendingMove *r) {\n+    char *left = l->target_begin();\n+    char *right = r->target_begin();\n+    return (left < right) ? -1 : (left == right ? 0 : 1);\n+  }\n+\n+  int moreThan(PendingMove *l, PendingMove *r) {\n+    return lessThan(r, l);\n+  }\n+\n+  \/\/ Maintains the occupancy state of the given heap memory area.\n+  \/\/ TsanOopSizeMap::rebuild_oop_map below uses an instance of this\n+  \/\/ class to order object moves, please see additional comments there.\n+  class OccupancyMap: public StackObj {\n+    \/\/ Internally it is a BitMap. A bit is set if the corresponding HeapWord\n+    \/\/ is currently occupied, cleared otherwise (HeapWord is Java object\n+    \/\/ allocation unit).\n+    char *mem_begin_;\n+    char *mem_end_;\n+    CHeapBitMap bitmap_;\n+    BitMap::idx_t to_idx(char *mem) const {\n+      return (mem - mem_begin_) \/ HeapWordSize;\n+    }\n+  public:\n+    \/\/ NOTE: The constructor creates a bitmap on the resource area.\n+    \/\/ The bitmap can be quite large (it is 16MB per every 1GB of heap,\n+    \/\/ so it is worth releasing it as soon as possible by creating a\n+    \/\/ ResourceMark.\n+    OccupancyMap(char *mem_begin, char *mem_end)\n+        : mem_begin_(mem_begin), mem_end_(mem_end),\n+          bitmap_((mem_end - mem_begin) \/ HeapWordSize) {}\n+    bool is_range_vacant(char *from, char *to) const {\n+      assert(from < to, \"bad range\");\n+      assert(from >= mem_begin_ && from < mem_end_,\n+             \"start address outside range\");\n+      assert(to > mem_begin_ && to <= mem_end_, \"end address outside range\");\n+      BitMap::idx_t idx_to = to_idx(to);\n+      return bitmap_.get_next_one_offset(to_idx(from), idx_to) == idx_to;\n+    }\n+    void range_occupy(char *from, char *to) {\n+      assert(from < to, \"range_occupy: bad range\");\n+      assert(from >= mem_begin_ && from < mem_end_,\n+             \"start address outside range\");\n+      assert(to > mem_begin_ && to <= mem_end_, \"end address outside range\");\n+      bitmap_.set_range(to_idx(from), to_idx(to));\n+    }\n+    void range_vacate(char *from, char *to) {\n+      assert(from < to, \"bad range\");\n+      assert(from >= mem_begin_ && from < mem_end_,\n+             \"start address outside range\");\n+      assert(to > mem_begin_ && to <= mem_end_, \"end address outside range\");\n+      bitmap_.clear_range(to_idx(from), to_idx(to));\n+    }\n+    int bit_count() const {\n+      return bitmap_.size();\n+    }\n+  };\n+\n+  bool TsanOopSizeMap::collect_oops(BoolObjectClosure* is_alive,\n+                                    OopClosure* pointer_adjuster,\n+                                    GrowableArray<PendingMove>* moves,\n+                                    int* n_downward_moves,\n+                                    char** min_low,\n+                                    char** max_high) {\n+    size_t map_size = oop_map->size();\n+\n+    \/\/ Traverse oop map. For each object that survived GC calculate its new\n+    \/\/ oop, add it to the new oop map, and append the move from the source oop\n+    \/\/ to the target one to the moves list. While doing that, collect oop\n+    \/\/ source and target ranges and count the moves that move an object\n+    \/\/ downwards (this is heuristics to order the moves, see below).\n+    TsanOopSizeMap* new_map = new TsanOopSizeMap(map_size \/ 2);\n+    *n_downward_moves = 0;\n+    bool disjoint_regions;\n+    char *source_low = reinterpret_cast<char *>(UINTPTR_MAX);\n+    char *source_high = NULL;\n+    char *target_low = reinterpret_cast<char *>(UINTPTR_MAX);\n+    char *target_high = NULL;\n+    size_t deleted_objects = 0;\n+    size_t unmoved_objects = 0;\n+    size_t total_size_words = 0;\n+    CollectedHeap *heap = Universe::heap();\n+    for (size_t i = 0; i < map_size; i++) {\n+      oopDesc *source_obj = oop_map->oop_at(i);\n+\n+      if (source_obj != NULL && heap->is_in(source_obj)) {\n+        uintx obj_size = oop_map->oop_size_at(i);\n+        size_t obj_size_bytes = obj_size * HeapWordSize;\n+        if (is_alive->do_object_b(source_obj)) {\n+          \/\/ The object survived GC, add its updated oop to the new oops map.\n+          oop target_oop = cast_to_oop((intptr_t)source_obj);\n+          pointer_adjuster->do_oop(&target_oop);\n+          \/\/ The memory pointed by target_oop may not be a valid oop yet,\n+          \/\/ for example the G1 full collector needs to adjust all pointers\n+          \/\/ first, then compacts and moves the objects. In this case\n+          \/\/ TsanOopSizeMap::rebuild_oops_map() is called during the adjust-\n+          \/\/ pointer phase, before the collector moves the objects. Thus,\n+          \/\/ we cannot use heap->is_in() or oopDesc::is_oop() to check\n+          \/\/ target_oop.\n+          assert(heap->is_in(target_oop), \"Adjustment failed\");\n+          oopDesc *target_obj = target_oop;\n+          new_map->put(target_obj, obj_size);\n+          if (target_obj == source_obj) {\n+            ++unmoved_objects;\n+            continue;\n+          }\n+          if (target_obj < source_obj) {\n+            ++(*n_downward_moves);\n+          }\n+          \/\/ Append to the moves list.\n+          PendingMove move = {(char *)source_obj, (char *)target_obj,\n+                              obj_size_bytes};\n+          total_size_words += obj_size;\n+          moves->append(move);\n+\n+          \/\/ Update source and target ranges.\n+          source_low = MIN2(source_low, move.source_begin());\n+          source_high = MAX2(source_high, move.source_end());\n+          target_low = MIN2(target_low, move.target_begin());\n+          target_high = MAX2(target_high, move.target_end());\n+        } else {  \/\/ dead!\n+          __tsan_java_free((char *)source_obj, obj_size_bytes);\n+          ++deleted_objects;\n+        }\n+      }\n+    }\n+\n+    \/\/ Update the oop map.\n+    delete TsanOopMapImpl::oop_map;\n+    TsanOopMapImpl::oop_map = new_map;\n+\n+    disjoint_regions = (source_low >= target_high || source_high <= target_low);\n+    log_debug(gc)(\n+          \"Tsan: map of \" SIZE_FORMAT \" objects, \" SIZE_FORMAT \" deleted, \"\n+          SIZE_FORMAT \" unmoved, \" SIZE_FORMAT \" to move \"\n+          \"(\" SIZE_FORMAT \" words), %soverlap\",\n+          map_size, deleted_objects, unmoved_objects, (size_t)moves->length(),\n+          total_size_words, disjoint_regions ? \"no \" : \"\");\n+\n+    *min_low = MIN2(source_low, target_low);\n+    *max_high = MAX2(source_high, target_high);\n+    return disjoint_regions;\n+  }\n+\n+  void TsanOopSizeMap::handle_overlapping_moves(GrowableArray<PendingMove>& moves,\n+                                                char* min_low,\n+                                                char* max_high) {\n+    \/\/ Populate occupied memory. The bitmap allocated by the OccupancyMap can\n+    \/\/ be fairly large, scope this code and insert a ResourceMark\n+    ResourceMark rm;\n+    OccupancyMap occupied_memory(min_low, max_high);\n+    DEBUG_PRINT(\"%s:%d: %d objects occupying %d words between %p and %p\\n\",\n+                __FUNCTION__, __LINE__, moves.length(),\n+                occupied_memory.bit_count(),\n+                MIN2(source_low, target_low),\n+                MAX2(source_high, target_high));\n+    for (int i = 0; i < moves.length(); ++i) {\n+      PendingMove &m = moves.at(i);\n+      occupied_memory.range_occupy(m.source_begin(), m.source_end());\n+    }\n+\n+    \/\/ Keep traversing moves list until everything is moved\n+    int passes = 0;\n+    for (int remaining_moves = moves.length(); remaining_moves > 0; ) {\n+      ++passes;\n+      int moves_this_cycle = 0;\n+      for (int i = 0; i < moves.length(); ++i) {\n+        if (moves.at(i).n_bytes == 0) {\n+           \/\/ Already moved this one.\n+           continue;\n+        }\n+\n+        \/\/ Check if this move is currently possible.\n+        \/\/ For this, everything in the target region that is not in the source\n+        \/\/ region has to be vacant.\n+        bool can_move;\n+        PendingMove &m = moves.at(i);\n+        if (m.target_begin() < m.source_begin()) {\n+          \/\/ '+++++++' is region being moved, lower addresses are to the left:\n+          \/\/ Moving downwards:\n+          \/\/         ++++++++         SOURCE\n+          \/\/    ++++++++              TARGET\n+          \/\/ or\n+          \/\/              ++++++++    SOURCE\n+          \/\/    ++++++++              TARGET\n+          can_move = occupied_memory.is_range_vacant(\n+              m.target_begin(), MIN2(m.target_end(), m.source_begin()));\n+        } else {\n+          \/\/ Moving upwards:\n+          \/\/    ++++++++              SOURCE\n+          \/\/         ++++++++         TARGET\n+          \/\/ or\n+          \/\/    ++++++++              SOURCE\n+          \/\/              ++++++++    TARGET\n+          can_move = occupied_memory.is_range_vacant(\n+              MAX2(m.source_end(), m.target_begin()), m.target_end());\n+        }\n+        if (can_move) {\n+          \/\/ Notify TSan, update occupied region.\n+          __tsan_java_move(m.source_begin(), m.target_begin(), m.n_bytes);\n+          occupied_memory.range_vacate(m.source_begin(), m.source_end());\n+          occupied_memory.range_occupy(m.target_begin(), m.target_end());\n+          \/\/ Indicate that this move has been done and remember that we\n+          \/\/ made some progress.\n+          m.n_bytes = 0;\n+          ++moves_this_cycle;\n+        }\n+      }\n+      \/\/ We have to make some progress, otherwise bail out:\n+      guarantee(moves_this_cycle, \"Impossible to reconcile GC\");\n+\n+      guarantee(remaining_moves >= moves_this_cycle,\n+                \"Excessive number of moves\");\n+      remaining_moves -= moves_this_cycle;\n+      DEBUG_PRINT(\"%s:%d: %d moved, %d remaining\\n\", __FUNCTION__, __LINE__,\n+                  moves_this_cycle, remaining_moves);\n+    }\n+    log_debug(gc)(\"Tsan: Move %d passes\", passes);\n+  }\n+\n+  void TsanOopSizeMap::rebuild_oops_map(BoolObjectClosure *is_alive,\n+                                        OopClosure *pointer_adjuster) {\n+    ResourceMark rm;\n+    GCTraceTime(Debug, gc) tt_top(\"Tsan relocate\");\n+    GCTraceCPUTime tcpu;\n+    GrowableArray<PendingMove> moves(MAX2((int)(oop_map->size() \/ 100),\n+                                          100000));\n+    bool disjoint_regions;\n+    int n_downward_moves;\n+    char *min_low, *max_high;\n+\n+    {\n+      GCTraceTime(Debug, gc) tt_collect(\"Collect oops\");\n+      disjoint_regions = collect_oops(is_alive, pointer_adjuster, &moves,\n+                                      &n_downward_moves, &min_low, &max_high);\n+    }\n+    if (moves.length() == 0) {\n+      return;\n+    }\n+\n+    \/\/ Notifying TSan is straightforward when source and target regions\n+    \/\/ do not overlap:\n+    if (disjoint_regions) {\n+      GCTraceTime(Debug, gc) tt_disjoint(\"Move between regions\");\n+\n+      for (int i = 0; i < moves.length(); ++i) {\n+        const PendingMove &m = moves.at(i);\n+        __tsan_java_move(m.source_begin(), m.target_begin(), m.n_bytes);\n+      }\n+      return;\n+    }\n+\n+    \/\/ Source and target ranges overlap, the moves need to be ordered to prevent\n+    \/\/ overwriting. Overall, this can take N^2 steps if only one object can be\n+    \/\/ moved during the array traversal; however, when we are dealing with\n+    \/\/ compacting garbage collector, observation shows that the overwhelming\n+    \/\/ majority of the objects move in one direction. If we sort the moves (in\n+    \/\/ the ascending order if dominant direction is downwards, in the descending\n+    \/\/ order otherwise), chances are we will be able to order the moves in a few\n+    \/\/ traversals of the moves array.\n+    {\n+      GCTraceTime(Debug, gc) tt_sort(\"Sort moves\");\n+\n+      moves.sort((2 * n_downward_moves > moves.length()) ? lessThan : moreThan);\n+      log_debug(gc)(\"Tsan: sort %d objects\", moves.length());\n+    }\n+\n+    {\n+      GCTraceTime(Debug, gc) tt_sort(\"Move\");\n+      handle_overlapping_moves(moves, min_low, max_high);\n+    }\n+  }\n+\n+}  \/\/ namespace TsanOopMapImpl\n+\n+\n+void TsanOopMap::initialize_map() {\n+  TsanOopMapImpl::oop_map = new TsanOopMapImpl::TsanOopSizeMap(512);\n+}\n+\n+void TsanOopMap::destroy() {\n+  delete TsanOopMapImpl::oop_map;\n+}\n+\n+void TsanOopMap::weak_oops_do(\n+    BoolObjectClosure* is_alive,\n+    OopClosure* pointer_adjuster) {\n+  if (!ThreadSanitizer) return;\n+  assert(SafepointSynchronize::is_at_safepoint(), \"must be at a safepoint\");\n+\n+  \/\/ We're mutating oopMap, but we don't need to acquire TsanOopMap_lock:\n+  \/\/ Mutation to map happens at (A) constructor (single threaded) and\n+  \/\/ (B) add (in mutator threads) and (C) do_weak_oops (single-threaded).\n+  \/\/ Calls between add are synchronized.\n+  \/\/ Calls between add and do_weak_oops are synchronized via STW GC.\n+  TsanOopMapImpl::TsanOopSizeMap::rebuild_oops_map(\n+      is_alive, pointer_adjuster);\n+}\n+\n+\/\/ Safe to deal with raw oop; for example this is called in a LEAF function\n+\/\/ There is no safepoint in this code: 1) special mutex is used, and\n+\/\/ 2) there is no VM state transition\n+\/\/ We cannot use ordinary VM mutex, as that requires a state transition.\n+void TsanOopMap::add_oop_with_size(oopDesc *addr, int size) {\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  assert(TsanOopMapImpl::oop_map != NULL, \"TsanOopMap not initialized\");\n+  guarantee(addr != NULL, \"null oop\");\n+  bool alloc = false;\n+  {\n+    MutexLocker mu(TsanOopMap_lock, Mutex::_no_safepoint_check_flag);\n+    \/\/ N.B. addr->size() may not be available yet!\n+    alloc = TsanOopMapImpl::oop_map->put(addr, size);\n+  }\n+  if (alloc) {\n+    __tsan_java_alloc(addr, size * HeapWordSize);\n+  }\n+}\n+\n+void TsanOopMap::add_oop(oopDesc *addr) {\n+  \/\/ N.B. oop's size field must be init'ed; else addr->size() crashes.\n+  TsanOopMap::add_oop_with_size(addr, addr->size());\n+}\n+\n+#ifdef ASSERT\n+bool TsanOopMap::exists(oopDesc *addr) {\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  assert(TsanOopMapImpl::oop_map != NULL, \"TsanOopMap not initialized\");\n+  guarantee(addr != NULL, \"null oop\");\n+  bool in_map = false;\n+  {\n+    MutexLocker mu(TsanOopMap_lock, Mutex::_no_safepoint_check_flag);\n+    in_map = TsanOopMapImpl::oop_map->exists(addr);\n+  }\n+  return in_map;\n+}\n+#endif\n","filename":"src\/hotspot\/share\/tsan\/tsanOopMap.cpp","additions":538,"deletions":0,"binary":false,"changes":538,"status":"added"},{"patch":"@@ -91,0 +91,1 @@\n+  JVM_ACC_FIELD_TSAN_IGNORE               = 0x00000200, \/\/ TSAN should ignore memory accesses to this field, same as JVM_ACC_INTERFACE\n@@ -96,1 +97,2 @@\n-                                       JVM_ACC_FIELD_HAS_GENERIC_SIGNATURE,\n+                                       JVM_ACC_FIELD_HAS_GENERIC_SIGNATURE |\n+                                       JVM_ACC_FIELD_TSAN_IGNORE,\n@@ -173,0 +175,3 @@\n+#if INCLUDE_TSAN\n+  bool is_tsan_ignore() const           { return (_flags & JVM_ACC_FIELD_TSAN_IGNORE) != 0; }\n+#endif  \/\/ INCLUDE_TSAN\n","filename":"src\/hotspot\/share\/utilities\/accessFlags.hpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -272,0 +272,19 @@\n+#ifndef INCLUDE_TSAN\n+#define INCLUDE_TSAN 1\n+#endif\n+\n+#if INCLUDE_TSAN\n+#define TSAN_ONLY(code) code\n+#define TSAN_RUNTIME_ONLY(code) \\\n+    do { \\\n+      if (ThreadSanitizer) { \\\n+        code; \\\n+      } \\\n+    } while (0)\n+#define NOT_TSAN(code)\n+#else\n+#define TSAN_ONLY(code)\n+#define TSAN_RUNTIME_ONLY(code)\n+#define NOT_TSAN(code) code\n+#endif\n+\n","filename":"src\/hotspot\/share\/utilities\/macros.hpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -88,0 +88,5 @@\n+                if (TSAN_ENABLED) {\n+                  \/\/ TODO: Move this call to when a batch of finalizers\n+                  \/\/ are added to the queue.\n+                  tsanFinalize();\n+                }\n@@ -181,0 +186,4 @@\n+    private final static boolean TSAN_ENABLED = isTsanEnabled();\n+    private static native boolean isTsanEnabled();\n+    private native void tsanFinalize();\n+\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/Finalizer.java","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -112,0 +112,1 @@\n+    exports java.util.concurrent.annotation;\n","filename":"src\/java.base\/share\/classes\/module-info.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -222,0 +222,8 @@\n+#ifdef INCLUDE_TSAN\n+\/*\n+ * Function pointer to JVM's TSAN symbolize function.\n+ *\/\n+__attribute__((visibility(\"default\")))\n+TsanSymbolize_t tsan_symbolize_func = NULL;\n+#endif\n+\n@@ -300,0 +308,3 @@\n+#ifdef INCLUDE_TSAN\n+    tsan_symbolize_func = ifn.TsanSymbolize;\n+#endif\n","filename":"src\/java.base\/share\/native\/libjli\/java.c","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -568,0 +568,9 @@\n+#ifdef INCLUDE_TSAN\n+    ifn->TsanSymbolize = (TsanSymbolize_t)\n+        dlsym(libjvm, \"TsanSymbolize\");\n+    if (ifn->TsanSymbolize == NULL) {\n+        JLI_ReportErrorMessage(DLL_ERROR2, jvmpath, dlerror());\n+        return JNI_FALSE;\n+    }\n+#endif\n+\n","filename":"src\/java.base\/unix\/native\/libjli\/java_md.c","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -71,0 +71,2 @@\n+static char* altstack = NULL;\n+\n@@ -72,1 +74,8 @@\n-  static char altstack[SIGSTKSZ];\n+  if (altstack == NULL) {\n+    \/\/ Dynamically allocated in case SIGSTKSZ is not constant\n+    altstack = malloc(SIGSTKSZ);\n+    if (altstack == NULL) {\n+      fprintf(stderr, \"Test ERROR. Unable to malloc altstack space\\n\");\n+      exit(7);\n+    }\n+  }\n","filename":"test\/hotspot\/jtreg\/runtime\/StackGuardPages\/exeinvoke.c","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"}]}