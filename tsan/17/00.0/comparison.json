{"files":[{"patch":"@@ -1,23 +1,0 @@\n-;\n-; Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n-; DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n-;\n-; This code is free software; you can redistribute it and\/or modify it\n-; under the terms of the GNU General Public License version 2 only, as\n-; published by the Free Software Foundation.\n-;\n-; This code is distributed in the hope that it will be useful, but WITHOUT\n-; ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n-; FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n-; version 2 for more details (a copy is included in the LICENSE file that\n-; accompanied this code).\n-;\n-; You should have received a copy of the GNU General Public License version\n-; 2 along with this work; if not, write to the Free Software Foundation,\n-; Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n-;\n-; Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n-; or visit www.oracle.com if you need additional information or have any\n-; questions.\n-;\n-\n@@ -26,1 +3,1 @@\n-jbs=jdk\n+jbs=JDK\n@@ -32,0 +9,4 @@\n+[repository]\n+tags=(?:jdk-(?:[1-9]([0-9]*)(?:\\.(?:0|[1-9][0-9]*)){0,4})(?:\\+(?:(?:[0-9]+))|(?:-ga)))|(?:jdk[4-9](?:u\\d{1,3})?-(?:(?:b\\d{2,3})|(?:ga)))|(?:hs\\d\\d(?:\\.\\d{1,2})?-b\\d\\d)\n+branches=\n+\n@@ -38,0 +19,17 @@\n+ignore-tabs=.*\\.gmk|Makefile\n+\n+[checks \"merge\"]\n+message=Merge\n+\n+[checks \"reviewers\"]\n+reviewers=1\n+ignore=duke\n+\n+[checks \"committer\"]\n+role=committer\n+\n+[checks \"issues\"]\n+pattern=^([124-8][0-9]{6}): (\\S.*)$\n+\n+[checks \"problemlists\"]\n+dirs=test\/jdk|test\/langtools|test\/lib-test|test\/hotspot\/jtreg|test\/jaxp\n","filename":".jcheck\/conf","additions":22,"deletions":24,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2016, 2020, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2016, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -49,1 +49,1 @@\n-    STRING_KEYWORDS := VM_OPTIONS JAVA_OPTIONS AOT_MODULES, \\\n+    STRING_KEYWORDS := VM_OPTIONS JAVA_OPTIONS, \\\n@@ -63,1 +63,1 @@\n-# Setup _NT_SYMBOL_PATH on Windows\n+# Setup _NT_SYMBOL_PATH on Windows, which points to our pdb files.\n@@ -66,10 +66,5 @@\n-    # Can't use PathList here as it adds quotes around the value.\n-    _NT_SYMBOL_PATH := \\\n-        $(subst $(SPACE),;,$(strip \\\n-            $(foreach p, $(sort $(dir $(wildcard \\\n-                $(addprefix $(SYMBOLS_IMAGE_DIR)\/bin\/, *.pdb *\/*.pdb)))), \\\n-              $(call FixPath, $p) \\\n-            ) \\\n-        ))\n-    export _NT_SYMBOL_PATH\n-    $(call LogDebug, Rewriting _NT_SYMBOL_PATH to $(_NT_SYMBOL_PATH))\n+    SYMBOL_PATH := $(call PathList, $(sort $(patsubst %\/, %, $(dir $(wildcard \\\n+        $(addprefix $(SYMBOLS_IMAGE_DIR)\/bin\/, *.pdb *\/*.pdb))))))\n+    export _NT_SYMBOL_PATH := $(subst \\\\,\\, $(call FixPath, \\\n+        $(subst $(DQUOTE),, $(SYMBOL_PATH))))\n+    $(call LogDebug, Setting _NT_SYMBOL_PATH to $(_NT_SYMBOL_PATH))\n@@ -142,85 +137,0 @@\n-################################################################################\n-# Optionally create AOT libraries for specified modules before running tests.\n-# Note, this could not be done during JDK build time.\n-################################################################################\n-\n-# Note, this could not be done during JDK build time.\n-\n-# Parameter 1 is the name of the rule.\n-#\n-# Remaining parameters are named arguments.\n-#   MODULE      The module to generate a library for\n-#   BIN         Output directory in which to put the library\n-#   VM_OPTIONS  List of JVM arguments to use when creating library\n-#   OPTIONS_VAR Name of variable to put AOT java options in\n-#   PREREQS_VAR Name of variable to put all AOT prerequisite rule targets in\n-#               for test rules to depend on\n-#\n-SetupAotModule = $(NamedParamsMacroTemplate)\n-define SetupAotModuleBody\n-  $1_AOT_LIB := $$($1_BIN)\/$$(call SHARED_LIBRARY,$$($1_MODULE))\n-  $1_AOT_CCLIST := $$(wildcard $$(TOPDIR)\/test\/hotspot\/jtreg\/compiler\/aot\/scripts\/$$($1_MODULE)-list.txt)\n-\n-  # Create jaotc flags.\n-  # VM flags which don't affect AOT code generation are filtered out:\n-  # -Xcomp, -XX:+-TieredCompilation\n-  $1_JAOTC_OPTS := \\\n-      -J-Xmx4g --info \\\n-      $$(addprefix -J, $$(filter-out -Xcomp %TieredCompilation, $$($1_VM_OPTIONS))) \\\n-      $$(addprefix --compile-commands$(SPACE), $$($1_AOT_CCLIST)) \\\n-      --linker-path $$(LD_JAOTC) \\\n-      #\n-\n-  ifneq ($$(filter -ea, $$($1_VM_OPTIONS)), )\n-    $1_JAOTC_OPTS += --compile-with-assertions\n-  endif\n-\n-  $$($1_AOT_LIB): $$(JDK_UNDER_TEST)\/release \\\n-      $$(call DependOnVariable, $1_JAOTC_OPTS) \\\n-      $$(call DependOnVariable, JDK_UNDER_TEST)\n-\t$$(call LogWarn, Generating $$(patsubst $$(OUTPUTDIR)\/%, %, $$@))\n-\t$$(call MakeTargetDir)\n-\t$$(call ExecuteWithLog, $$@, \\\n-\t    $((COV_ENVIRONMENT) \\\n-\t    $$(FIXPATH) $$(JDK_UNDER_TEST)\/bin\/jaotc \\\n-\t        $$($1_JAOTC_OPTS) --output $$@ --module $$($1_MODULE) \\\n-\t)\n-\t$$(call ExecuteWithLog, $$@.check, ( \\\n-\t    $$(FIXPATH) $$(JDK_UNDER_TEST)\/bin\/java \\\n-\t        $$($1_VM_OPTIONS) -XX:+UnlockDiagnosticVMOptions -XX:+UnlockExperimentalVMOptions \\\n-\t        -XX:+PrintAOT -XX:+UseAOTStrictLoading \\\n-\t        -XX:AOTLibrary=$$@ -version \\\n-\t         > $$@.verify-aot \\\n-\t))\n-\n-  $1_AOT_OPTIONS += -XX:+UnlockExperimentalVMOptions\n-  $1_AOT_OPTIONS += -XX:AOTLibrary=$$($1_AOT_LIB)\n-  $1_AOT_TARGETS += $$($1_AOT_LIB)\n-endef\n-\n-# Parameter 1 is the name of the rule.\n-#\n-# Remaining parameters are named arguments.\n-#   MODULES     The modules to generate a library for\n-#   VM_OPTIONS  List of JVM arguments to use when creating libraries\n-#\n-# After calling this, the following variables are defined\n-#   $1_AOT_OPTIONS List of all java options needed to use the AOT libraries\n-#   $1_AOT_TARGETS List of all targets that the test rule will need to depend on\n-#\n-SetupAot = $(NamedParamsMacroTemplate)\n-define SetupAotBody\n-  $$(info Running with AOTd libraries for $$($1_MODULES))\n-  # Put aot libraries in a separate directory so they are not deleted between\n-  # test runs and may be reused between make invocations.\n-  $$(foreach m, $$($1_MODULES), \\\n-    $$(eval $$(call SetupAotModule, $1_$$m, \\\n-        MODULE := $$m, \\\n-        BIN := $$(TEST_SUPPORT_DIR)\/aot\/$1, \\\n-        VM_OPTIONS := $$($1_VM_OPTIONS), \\\n-    )) \\\n-    $$(eval $1_AOT_OPTIONS += $$($1_$$m_AOT_OPTIONS)) \\\n-    $$(eval $1_AOT_TARGETS += $$($1_$$m_AOT_TARGETS)) \\\n-  )\n-endef\n-\n@@ -285,1 +195,0 @@\n-$(eval $(call SetTestOpt,AOT_MODULES,JTREG))\n@@ -294,1 +203,1 @@\n-        RETRY_COUNT, \\\n+        RETRY_COUNT MAX_OUTPUT, \\\n@@ -296,1 +205,1 @@\n-        EXTRA_PROBLEM_LISTS AOT_MODULES, \\\n+        EXTRA_PROBLEM_LISTS LAUNCHER_OPTIONS, \\\n@@ -308,1 +217,0 @@\n-$(eval $(call SetTestOpt,AOT_MODULES,GTEST))\n@@ -312,1 +220,1 @@\n-    STRING_KEYWORDS := OPTIONS VM_OPTIONS JAVA_OPTIONS AOT_MODULES, \\\n+    STRING_KEYWORDS := OPTIONS VM_OPTIONS JAVA_OPTIONS, \\\n@@ -353,2 +261,0 @@\n-langtools_JTREG_MAX_MEM := 768m\n-\n@@ -595,8 +501,1 @@\n-  ifneq ($$(GTEST_AOT_MODULES), )\n-    $$(eval $$(call SetupAot, $1, \\\n-        MODULES := $$(GTEST_AOT_MODULES), \\\n-        VM_OPTIONS := $$(GTEST_VM_OPTIONS) $$(GTEST_JAVA_OPTIONS), \\\n-    ))\n-  endif\n-\n-  run-test-$1: pre-run-test $$($1_AOT_TARGETS)\n+  run-test-$1: pre-run-test\n@@ -607,0 +506,1 @@\n+\t    $$(CD) $$($1_TEST_SUPPORT_DIR) && \\\n@@ -610,0 +510,1 @@\n+\t        --gtest_catch_exceptions=0 \\\n@@ -611,1 +512,1 @@\n-\t        $$(GTEST_JAVA_OPTIONS) $$($1_AOT_OPTIONS) \\\n+\t        $$(GTEST_JAVA_OPTIONS) \\\n@@ -822,1 +723,1 @@\n-  $$(eval $$(call SetJtregValue,$1,JTREG_MAX_MEM,512m))\n+  $$(eval $$(call SetJtregValue,$1,JTREG_MAX_MEM,768m))\n@@ -838,1 +739,1 @@\n-  $1_JTREG_MAX_RAM_PERCENTAGE := $$(shell $$(EXPR) 25 \/ $$($1_JTREG_JOBS))\n+  $1_JTREG_MAX_RAM_PERCENTAGE := $$(shell $(AWK) 'BEGIN { print 25 \/ $$($1_JTREG_JOBS); }')\n@@ -847,0 +748,8 @@\n+  ifneq ($$(JTREG_LAUNCHER_OPTIONS), )\n+    $1_JTREG_LAUNCHER_OPTIONS += $$(JTREG_LAUNCHER_OPTIONS)\n+  endif\n+\n+  ifneq ($$(JTREG_MAX_OUTPUT), )\n+    $1_JTREG_LAUNCHER_OPTIONS += -Djavatest.maxOutputSize=$$(JTREG_MAX_OUTPUT)\n+  endif\n+\n@@ -861,0 +770,3 @@\n+  # Make sure the tmp dir is normalized as some tests will react badly otherwise\n+  $1_TEST_TMP_DIR := $$(abspath $$($1_TEST_SUPPORT_DIR)\/tmp)\n+\n@@ -864,1 +776,2 @@\n-      -vmoption:-XX:MaxRAMPercentage=$$($1_JTREG_MAX_RAM_PERCENTAGE)\n+      -vmoption:-XX:MaxRAMPercentage=$$($1_JTREG_MAX_RAM_PERCENTAGE) \\\n+      -vmoption:-Djava.io.tmpdir=\"$$($1_TEST_TMP_DIR)\"\n@@ -915,1 +828,0 @@\n-  $1_JTREG_BASIC_OPTIONS += -e:TEST_IMAGE_GRAAL_DIR=$(TEST_IMAGE_DIR)\/hotspot\/jtreg\/graal\n@@ -932,11 +844,0 @@\n-  ifneq ($$(JTREG_AOT_MODULES), )\n-    $$(eval $$(call SetupAot, $1, \\\n-        MODULES := $$(JTREG_AOT_MODULES), \\\n-        VM_OPTIONS := $$(JTREG_VM_OPTIONS) $$(JTREG_JAVA_OPTIONS), \\\n-    ))\n-  endif\n-\n-  ifneq ($$($1_AOT_OPTIONS), )\n-    $1_JTREG_BASIC_OPTIONS += -vmoptions:\"$$($1_AOT_OPTIONS)\"\n-  endif\n-\n@@ -977,1 +878,1 @@\n-  run-test-$1: pre-run-test clean-workdir-$1 $$($1_AOT_TARGETS)\n+  run-test-$1: pre-run-test clean-workdir-$1\n@@ -980,1 +881,2 @@\n-\t$$(call MakeDir, $$($1_TEST_RESULTS_DIR) $$($1_TEST_SUPPORT_DIR))\n+\t$$(call MakeDir, $$($1_TEST_RESULTS_DIR) $$($1_TEST_SUPPORT_DIR) \\\n+\t    $$($1_TEST_TMP_DIR))\n","filename":"make\/RunTests.gmk","additions":33,"deletions":131,"binary":false,"changes":164,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2011, 2020, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2011, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -133,0 +133,1 @@\n+      BUILD_CC_DISABLE_WARNING_PREFIX=\"-wd\"\n@@ -137,0 +138,4 @@\n+      if test \"x$TOOLCHAIN_VERSION\" = x2017; then\n+        # VS2017 incorrectly triggers this warning for constexpr\n+        DISABLED_WARNINGS+=\" 4307\"\n+      fi\n@@ -141,0 +146,1 @@\n+      BUILD_CC_DISABLE_WARNING_PREFIX=\"-Wno-\"\n@@ -152,1 +158,0 @@\n-      BUILD_CC_DISABLE_WARNING_PREFIX=\"-Wno-\"\n@@ -166,5 +171,0 @@\n-      if test \"x$OPENJDK_TARGET_OS\" = xmacosx; then\n-        # missing-method-return-type triggers in JavaNativeFoundation framework\n-        DISABLED_WARNINGS=\"$DISABLED_WARNINGS missing-method-return-type\"\n-      fi\n-\n@@ -230,1 +230,7 @@\n-      ENABLE_FORTIFY_CFLAGS=\"-D_FORTIFY_SOURCE=2\"\n+      # ASan doesn't work well with _FORTIFY_SOURCE\n+      # See https:\/\/github.com\/google\/sanitizers\/wiki\/AddressSanitizer#faq\n+      if test \"x$ASAN_ENABLED\" = xyes; then\n+        ENABLE_FORTIFY_CFLAGS=\"${DISABLE_FORTIFY_CFLAGS}\"\n+      else\n+        ENABLE_FORTIFY_CFLAGS=\"-D_FORTIFY_SOURCE=2\"\n+      fi\n@@ -531,0 +537,12 @@\n+  # CXXFLAGS C++ language level for all of JDK, including Hotspot.\n+  if test \"x$TOOLCHAIN_TYPE\" = xgcc || test \"x$TOOLCHAIN_TYPE\" = xclang || test \"x$TOOLCHAIN_TYPE\" = xxlc; then\n+    LANGSTD_CXXFLAGS=\"-std=c++14\"\n+  elif test \"x$TOOLCHAIN_TYPE\" = xmicrosoft; then\n+    LANGSTD_CXXFLAGS=\"-std:c++14\"\n+  else\n+    AC_MSG_ERROR([Don't know how to enable C++14 for this toolchain])\n+  fi\n+  TOOLCHAIN_CFLAGS_JDK_CXXONLY=\"$TOOLCHAIN_CFLAGS_JDK_CXXONLY $LANGSTD_CXXFLAGS\"\n+  TOOLCHAIN_CFLAGS_JVM=\"$TOOLCHAIN_CFLAGS_JVM $LANGSTD_CXXFLAGS\"\n+  ADLC_LANGSTD_CXXFLAGS=\"$LANGSTD_CXXFLAGS\"\n+\n@@ -561,0 +579,5 @@\n+  OS_CFLAGS=\"$OS_CFLAGS -DLIBC=$OPENJDK_TARGET_LIBC\"\n+  if test \"x$OPENJDK_TARGET_LIBC\" = xmusl; then\n+    OS_CFLAGS=\"$OS_CFLAGS -DMUSL_LIBC\"\n+  fi\n+\n@@ -596,19 +619,0 @@\n-  # Optional POSIX functionality needed by the JVM\n-  #\n-  # Check if clock_gettime is available and in which library. This indicates\n-  # availability of CLOCK_MONOTONIC for hotspot. But we don't need to link, so\n-  # don't let it update LIBS.\n-  save_LIBS=\"$LIBS\"\n-  AC_SEARCH_LIBS(clock_gettime, rt, [HAS_CLOCK_GETTIME=true], [])\n-  if test \"x$LIBS\" = \"x-lrt \"; then\n-    CLOCK_GETTIME_IN_LIBRT=true\n-  fi\n-  LIBS=\"$save_LIBS\"\n-\n-  if test \"x$HAS_CLOCK_GETTIME\" = \"xtrue\"; then\n-    OS_CFLAGS_JVM=\"$OS_CFLAGS_JVM -DSUPPORTS_CLOCK_MONOTONIC\"\n-    if test \"x$CLOCK_GETTIME_IN_LIBRT\" = \"xtrue\"; then\n-      OS_CFLAGS_JVM=\"$OS_CFLAGS_JVM -DNEEDS_LIBRT\"\n-    fi\n-  fi\n-\n@@ -655,10 +659,4 @@\n-  if test \"x$FLAGS_CPU_BITS\" = x64; then\n-    # -D_LP64=1 is only set on linux and mac. Setting on windows causes diff in\n-    # unpack200.exe.\n-    if test \"x$FLAGS_OS\" = xlinux || test \"x$FLAGS_OS\" = xmacosx; then\n-      $1_DEFINES_CPU_JDK=\"${$1_DEFINES_CPU_JDK} -D_LP64=1\"\n-    fi\n-    if test \"x$FLAGS_OS\" != xaix; then\n-      # xlc on AIX defines _LP64=1 by default and issues a warning if we redefine it.\n-      $1_DEFINES_CPU_JVM=\"${$1_DEFINES_CPU_JVM} -D_LP64=1\"\n-    fi\n+  if test \"x$FLAGS_CPU_BITS\" = x64 && test \"x$FLAGS_OS\" != xaix; then\n+    # xlc on AIX defines _LP64=1 by default and issues a warning if we redefine it.\n+    $1_DEFINES_CPU_JDK=\"${$1_DEFINES_CPU_JDK} -D_LP64=1\"\n+    $1_DEFINES_CPU_JVM=\"${$1_DEFINES_CPU_JVM} -D_LP64=1\"\n@@ -669,1 +667,3 @@\n-    if test \"x$FLAGS_CPU\" = xx86_64; then\n+    if test \"x$FLAGS_CPU\" = xaarch64; then\n+      $1_DEFINES_CPU_JDK=\"${$1_DEFINES_CPU_JDK} -D_ARM64_ -Darm64\"\n+    elif test \"x$FLAGS_CPU\" = xx86_64; then\n@@ -679,0 +679,1 @@\n+    AC_MSG_CHECKING([if $1 is x86])\n@@ -680,2 +681,13 @@\n-      # Force compatibility with i586 on 32 bit intel platforms.\n-      $1_CFLAGS_CPU=\"-march=i586\"\n+      AC_MSG_RESULT([yes])\n+      AC_MSG_CHECKING([if control flow protection is enabled by additional compiler flags])\n+      if echo \"${EXTRA_CFLAGS}${EXTRA_CXXFLAGS}${EXTRA_ASFLAGS}\" | ${GREP} -q 'fcf-protection' ; then\n+        # cf-protection requires CMOV and thus i686\n+        $1_CFLAGS_CPU=\"-march=i686\"\n+        AC_MSG_RESULT([yes, forcing ${$1_CFLAGS_CPU}])\n+      else\n+        # Force compatibility with i586 on 32 bit intel platforms.\n+        $1_CFLAGS_CPU=\"-march=i586\"\n+        AC_MSG_RESULT([no, forcing ${$1_CFLAGS_CPU}])\n+      fi\n+    else\n+      AC_MSG_RESULT([no])\n@@ -713,7 +725,0 @@\n-    $1_CXXSTD_CXXFLAG=\"-std=gnu++98\"\n-    FLAGS_CXX_COMPILER_CHECK_ARGUMENTS(ARGUMENT: [${$1_CXXSTD_CXXFLAG}],\n-        PREFIX: $3, IF_FALSE: [$1_CXXSTD_CXXFLAG=\"\"])\n-    $1_TOOLCHAIN_CFLAGS_JDK_CXXONLY=\"${$1_CXXSTD_CXXFLAG}\"\n-    $1_TOOLCHAIN_CFLAGS_JVM=\"${$1_TOOLCHAIN_CFLAGS_JVM} ${$1_CXXSTD_CXXFLAG}\"\n-    $2ADLC_CXXFLAG=\"${$1_CXXSTD_CXXFLAG}\"\n-\n@@ -751,0 +756,21 @@\n+  elif test \"x$TOOLCHAIN_TYPE\" = xclang; then\n+    NO_DELETE_NULL_POINTER_CHECKS_CFLAG=\"-fno-delete-null-pointer-checks\"\n+    FLAGS_COMPILER_CHECK_ARGUMENTS(ARGUMENT: [$NO_DELETE_NULL_POINTER_CHECKS_CFLAG],\n+        PREFIX: $3,\n+        IF_FALSE: [\n+            NO_DELETE_NULL_POINTER_CHECKS_CFLAG=\n+        ]\n+    )\n+    $1_TOOLCHAIN_CFLAGS=\"${NO_DELETE_NULL_POINTER_CHECKS_CFLAG}\"\n+  fi\n+\n+  if test \"x$TOOLCHAIN_TYPE\" = xmicrosoft && test \"x$ENABLE_REPRODUCIBLE_BUILD\" = xtrue; then\n+    # Enabling deterministic creates warnings if __DATE__ or __TIME__ are\n+    # used, and since we are, silence that warning.\n+    REPRODUCIBLE_CFLAGS=\"-experimental:deterministic -wd5048\"\n+    FLAGS_COMPILER_CHECK_ARGUMENTS(ARGUMENT: [${REPRODUCIBLE_CFLAGS}],\n+        PREFIX: $3,\n+        IF_FALSE: [\n+            REPRODUCIBLE_CFLAGS=\n+        ]\n+    )\n@@ -771,0 +797,23 @@\n+    elif test \"x$TOOLCHAIN_TYPE\" = xmicrosoft &&\n+        test \"x$ENABLE_REPRODUCIBLE_BUILD\" = xtrue; then\n+      # There is a known issue with the pathmap if the mapping is made to the\n+      # empty string. Add a minimal string \"s\" as prefix to work around this.\n+      workspace_root_win=`$FIXPATH_BASE print \"${WORKSPACE_ROOT%\/}\"`\n+      # PATHMAP_FLAGS is also added to LDFLAGS in flags-ldflags.m4.\n+      PATHMAP_FLAGS=\"-pathmap:${workspace_root_win\/\/\\\/\/\\\\\\\\}=s \\\n+          -pathmap:${workspace_root_win}=s\"\n+      FILE_MACRO_CFLAGS=\"$PATHMAP_FLAGS\"\n+      FLAGS_COMPILER_CHECK_ARGUMENTS(ARGUMENT: [${FILE_MACRO_CFLAGS}],\n+          PREFIX: $3,\n+          IF_FALSE: [\n+              PATHMAP_FLAGS=\n+              FILE_MACRO_CFLAGS=\n+          ]\n+      )\n+    fi\n+\n+    AC_MSG_CHECKING([how to prevent absolute paths in output])\n+    if test \"x$FILE_MACRO_CFLAGS\" != x; then\n+      AC_MSG_RESULT([using compiler options])\n+    else\n+      AC_MSG_RESULT([using relative paths])\n@@ -779,1 +828,2 @@\n-      $WARNING_CFLAGS $WARNING_CFLAGS_JVM $JVM_PICFLAG $FILE_MACRO_CFLAGS\"\n+      $WARNING_CFLAGS $WARNING_CFLAGS_JVM $JVM_PICFLAG $FILE_MACRO_CFLAGS \\\n+      $REPRODUCIBLE_CFLAGS\"\n@@ -784,1 +834,1 @@\n-      $FILE_MACRO_CFLAGS\"\n+      $FILE_MACRO_CFLAGS $REPRODUCIBLE_CFLAGS\"\n@@ -814,1 +864,1 @@\n-  AC_SUBST($2ADLC_CXXFLAG)\n+  AC_SUBST($2ADLC_LANGSTD_CXXFLAGS)\n","filename":"make\/autoconf\/flags-cflags.m4","additions":100,"deletions":50,"binary":false,"changes":150,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2011, 2020, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2011, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -47,1 +47,1 @@\n-    aot cds compiler1 compiler2 dtrace epsilongc g1gc graal jfr jni-check \\\n+    cds compiler1 compiler2 dtrace epsilongc g1gc jfr jni-check \\\n@@ -58,1 +58,0 @@\n-m4_define(jvm_feature_desc_aot, [enable ahead of time compilation (AOT)])\n@@ -65,1 +64,0 @@\n-m4_define(jvm_feature_desc_graal, [enable Graal (jdk.internal.vm.compiler)])\n@@ -98,1 +96,0 @@\n-  UTIL_ALIASED_ARG_ENABLE(aot, --enable-jvm-feature-aot)\n@@ -163,1 +160,1 @@\n-        [--enable-jvm-feature-FEATURE], \n+        [--enable-jvm-feature-FEATURE],\n@@ -233,27 +230,0 @@\n-###############################################################################\n-# Check if the feature 'aot' is available on this platform.\n-#\n-AC_DEFUN_ONCE([JVM_FEATURES_CHECK_AOT],\n-[\n-  JVM_FEATURES_CHECK_AVAILABILITY(aot, [\n-    AC_MSG_CHECKING([if platform is supported by AOT])\n-    # AOT is only available where JVMCI is available since it requires JVMCI.\n-    if test \"x$OPENJDK_TARGET_CPU\" = \"xx86_64\" || \\\n-        test \"x$OPENJDK_TARGET_CPU\" = \"xaarch64\"; then\n-      AC_MSG_RESULT([yes])\n-    else\n-      AC_MSG_RESULT([no, $OPENJDK_TARGET_CPU])\n-      AVAILABLE=false\n-    fi\n-\n-    AC_MSG_CHECKING([if AOT source code is present])\n-    if test -e \"${TOPDIR}\/src\/jdk.internal.vm.compiler\" && \\\n-        test -e \"${TOPDIR}\/src\/jdk.aot\"; then\n-      AC_MSG_RESULT([yes])\n-    else\n-      AC_MSG_RESULT([no, missing src\/jdk.internal.vm.compiler or src\/jdk.aot])\n-      AVAILABLE=false\n-    fi\n-  ])\n-])\n-\n@@ -267,4 +237,2 @@\n-    if test \"x$OPENJDK_TARGET_OS\" != xaix; then\n-      AC_MSG_RESULT([yes])\n-    else\n-      AC_MSG_RESULT([no, $OPENJDK_TARGET_OS])\n+    if test \"x$OPENJDK_TARGET_OS\" = xaix; then\n+      AC_MSG_RESULT([no, $OPENJDK_TARGET_OS-$OPENJDK_TARGET_CPU])\n@@ -272,0 +240,2 @@\n+    else\n+      AC_MSG_RESULT([yes])\n@@ -299,18 +269,0 @@\n-###############################################################################\n-# Check if the feature 'graal' is available on this platform.\n-#\n-AC_DEFUN_ONCE([JVM_FEATURES_CHECK_GRAAL],\n-[\n-  JVM_FEATURES_CHECK_AVAILABILITY(graal, [\n-    AC_MSG_CHECKING([if platform is supported by Graal])\n-    # Graal is only available where JVMCI is available since it requires JVMCI.\n-    if test \"x$OPENJDK_TARGET_CPU\" = \"xx86_64\" || \\\n-        test \"x$OPENJDK_TARGET_CPU\" = \"xaarch64\" ; then\n-      AC_MSG_RESULT([yes])\n-    else\n-      AC_MSG_RESULT([no, $OPENJDK_TARGET_CPU])\n-      AVAILABLE=false\n-    fi\n-  ])\n-])\n-\n@@ -340,2 +292,3 @@\n-    if test \"x$OPENJDK_TARGET_CPU\" = \"xx86_64\" || \\\n-        test \"x$OPENJDK_TARGET_CPU\" = \"xaarch64\" ; then\n+    if test \"x$OPENJDK_TARGET_CPU\" = \"xx86_64\"; then\n+      AC_MSG_RESULT([yes])\n+    elif test \"x$OPENJDK_TARGET_CPU\" = \"xaarch64\"; then\n@@ -446,2 +399,9 @@\n-    elif test \"x$OPENJDK_TARGET_OS-$OPENJDK_TARGET_CPU\" = \"xlinux-aarch64\"; then\n-      AC_MSG_RESULT([yes])\n+    elif test \"x$OPENJDK_TARGET_CPU\" = \"xaarch64\"; then\n+      if test \"x$OPENJDK_TARGET_OS\" = \"xlinux\" || \\\n+          test \"x$OPENJDK_TARGET_OS\" = \"xwindows\" || \\\n+          test \"x$OPENJDK_TARGET_OS\" = \"xmacosx\"; then\n+        AC_MSG_RESULT([yes])\n+      else\n+        AC_MSG_RESULT([no, $OPENJDK_TARGET_OS-$OPENJDK_TARGET_CPU])\n+        AVAILABLE=false\n+      fi\n@@ -481,1 +441,0 @@\n-  JVM_FEATURES_CHECK_AOT\n@@ -484,1 +443,0 @@\n-  JVM_FEATURES_CHECK_GRAAL\n@@ -518,2 +476,2 @@\n-    JVM_FEATURES_VARIANT_UNAVAILABLE=\"aot cds compiler1 compiler2 \\\n-        epsilongc g1gc graal jvmci minimal shenandoahgc zgc\"\n+    JVM_FEATURES_VARIANT_UNAVAILABLE=\"cds compiler1 compiler2 \\\n+        jvmci minimal zgc\"\n@@ -526,1 +484,1 @@\n-    JVM_FEATURES_VARIANT_FILTER=\"aot compiler2 graal jvmci link-time-opt opt-size\"\n+    JVM_FEATURES_VARIANT_FILTER=\"compiler2 jvmci link-time-opt opt-size\"\n@@ -528,2 +486,2 @@\n-    JVM_FEATURES_VARIANT_FILTER=\"aot cds compiler2 dtrace epsilongc g1gc \\\n-        graal jfr jni-check jvmci jvmti management nmt parallelgc services \\\n+    JVM_FEATURES_VARIANT_FILTER=\"cds compiler2 dtrace epsilongc g1gc \\\n+        jfr jni-check jvmci jvmti management nmt parallelgc services \\\n@@ -539,1 +497,1 @@\n-    JVM_FEATURES_VARIANT_FILTER=\"aot compiler1 compiler2 graal jvmci \\\n+    JVM_FEATURES_VARIANT_FILTER=\"compiler1 compiler2 jvmci \\\n@@ -615,9 +573,0 @@\n-  # Verify that dependencies are met for inter-feature relations.\n-  if JVM_FEATURES_IS_ACTIVE(aot) && ! JVM_FEATURES_IS_ACTIVE(graal); then\n-    AC_MSG_ERROR([Specified JVM feature 'aot' requires feature 'graal' for variant '$variant'])\n-  fi\n-\n-  if JVM_FEATURES_IS_ACTIVE(graal) && ! JVM_FEATURES_IS_ACTIVE(jvmci); then\n-    AC_MSG_ERROR([Specified JVM feature 'graal' requires feature 'jvmci' for variant '$variant'])\n-  fi\n-\n@@ -639,3 +588,0 @@\n-  if ! JVM_FEATURES_IS_ACTIVE(aot); then\n-    ENABLE_AOT=\"false\"\n-  fi\n@@ -645,3 +591,0 @@\n-  if ! JVM_FEATURES_IS_ACTIVE(graal); then\n-    INCLUDE_GRAAL=\"false\"\n-  fi\n@@ -654,0 +597,3 @@\n+  if JVM_FEATURES_IS_ACTIVE(compiler2); then\n+    INCLUDE_COMPILER2=\"true\"\n+  fi\n@@ -675,2 +621,0 @@\n-  ENABLE_AOT=\"true\"\n-  INCLUDE_GRAAL=\"true\"\n@@ -678,0 +622,1 @@\n+  INCLUDE_COMPILER2=\"false\"\n@@ -717,2 +662,0 @@\n-  AC_SUBST(ENABLE_AOT)\n-  AC_SUBST(INCLUDE_GRAAL)\n@@ -720,0 +663,1 @@\n+  AC_SUBST(INCLUDE_COMPILER2)\n","filename":"make\/autoconf\/jvm-features.m4","additions":30,"deletions":86,"binary":false,"changes":116,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2011, 2020, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2011, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -83,0 +83,2 @@\n+OPENJDK_TARGET_LIBC:=@OPENJDK_TARGET_LIBC@\n+\n@@ -98,0 +100,2 @@\n+HOTSPOT_TARGET_LIBC := @HOTSPOT_TARGET_LIBC@\n+\n@@ -112,0 +116,2 @@\n+OPENJDK_BUILD_LIBC:=@OPENJDK_BUILD_LIBC@\n+\n@@ -120,0 +126,1 @@\n+RELEASE_FILE_LIBC:=@RELEASE_FILE_LIBC@\n@@ -127,2 +134,10 @@\n-# colon or semicolon\n-PATH_SEP:=@PATH_SEP@\n+WINENV_ROOT := @WINENV_ROOT@\n+WINENV_PREFIX := @WINENV_PREFIX@\n+\n+ifneq ($(findstring windows.wsl, @OPENJDK_BUILD_OS_ENV@), )\n+  # Tell WSL to convert PATH between linux and windows\n+  export WSLENV := PATH\/l\n+else ifeq (@OPENJDK_BUILD_OS_ENV@, windows.msys2)\n+  # Prohibit msys2 from attemping any path wrangling\n+  export MSYS2_ARG_CONV_EXCL := \"*\"\n+endif\n@@ -131,10 +146,6 @@\n-ORIGINAL_PATH:=@ORIGINAL_PATH@\n-ifeq ($(OPENJDK_TARGET_OS), windows)\n-  # On Windows, the Visual Studio toolchain needs the PATH to be adjusted\n-  # to include Visual Studio tools (this needs to be in cygwin\/msys style).\n-  ifeq ($(OPENJDK_TARGET_OS_ENV), windows.wsl)\n-    export FIXPATH_PATH:=@VS_PATH_WINDOWS@\n-    export WSLENV:=$(WSLENV):FIXPATH_PATH:DEBUG_FIXPATH\n-  else\n-    export PATH:=@VS_PATH@\n-  endif\n+ORIGINAL_PATH := @ORIGINAL_PATH@\n+\n+ifeq (@TOOLCHAIN_TYPE@, microsoft)\n+  # The Visual Studio toolchain needs the PATH to be adjusted to include\n+  # Visual Studio tools.\n+  export PATH := @TOOLCHAIN_PATH@:$(PATH)\n@@ -173,0 +184,1 @@\n+MACOSX_BUNDLE_BUILD_VERSION=@MACOSX_BUNDLE_BUILD_VERSION@\n@@ -221,0 +233,3 @@\n+# Version for API docs \"new-since\" feature\n+VERSION_DOCS_API_SINCE := @VERSION_DOCS_API_SINCE@\n+\n@@ -246,1 +261,1 @@\n-  # COMPANY_NAME is set to \"N\/A\" in $AUTOCONF_DIR\/version-numbers by default,\n+  # COMPANY_NAME is set to \"N\/A\" in make\/conf\/branding.conf by default,\n@@ -340,0 +355,2 @@\n+ENABLE_COMPATIBLE_CDS_ALIGNMENT := @ENABLE_COMPATIBLE_CDS_ALIGNMENT@\n+\n@@ -381,1 +398,0 @@\n-GRAALUNIT_LIB := @GRAALUNIT_LIB@\n@@ -466,2 +482,1 @@\n-C_FLAG_DEPS:=@C_FLAG_DEPS@\n-CXX_FLAG_DEPS:=@CXX_FLAG_DEPS@\n+GENDEPS_FLAGS := @GENDEPS_FLAGS@\n@@ -479,1 +494,2 @@\n-ADLC_CXXFLAG=@ADLC_CXXFLAG@\n+ADLC_LANGSTD_CXXFLAGS=@ADLC_LANGSTD_CXXFLAGS@\n+ADLC_LDFLAGS=@ADLC_LDFLAGS@\n@@ -482,1 +498,1 @@\n-CC:=@FIXPATH@ @CCACHE@ @ICECC@ @CC@\n+CC := @CCACHE@ @ICECC@ @CC@\n@@ -492,3 +508,0 @@\n-LIBJSIG_HASHSTYLE_LDFLAGS := @LIBJSIG_HASHSTYLE_LDFLAGS@\n-LIBJSIG_NOEXECSTACK_LDFLAGS := @LIBJSIG_NOEXECSTACK_LDFLAGS@\n-\n@@ -500,1 +513,2 @@\n-JVM_RCFLAGS := @JVM_RCFLAGS@\n+\n+BASIC_ASFLAGS := @BASIC_ASFLAGS@\n@@ -508,1 +522,1 @@\n-CXX:=@FIXPATH@ @CCACHE@ @ICECC@ @CXX@\n+CXX := @CCACHE@ @ICECC@ @CXX@\n@@ -510,1 +524,1 @@\n-CPP:=@FIXPATH@ @CPP@\n+CPP := @CPP@\n@@ -513,4 +527,1 @@\n-LD:=@FIXPATH@ @LD@\n-\n-# Linker used by the jaotc tool for AOT compilation.\n-LD_JAOTC:=@LD_JAOTC@\n+LD := @LD@\n@@ -533,1 +544,1 @@\n-LDCXX:=@FIXPATH@ @LDCXX@\n+LDCXX := @LDCXX@\n@@ -542,7 +553,7 @@\n-BUILD_CC:=@FIXPATH@ @BUILD_ICECC@ @BUILD_CC@\n-BUILD_CXX:=@FIXPATH@ @BUILD_ICECC@ @BUILD_CXX@\n-BUILD_LD:=@FIXPATH@ @BUILD_LD@\n-BUILD_LDCXX:=@FIXPATH@ @BUILD_LDCXX@\n-BUILD_AS:=@FIXPATH@ @BUILD_AS@\n-BUILD_AR:=@FIXPATH@ @BUILD_AR@\n-BUILD_NM:=@FIXPATH@ @BUILD_NM@\n+BUILD_CC := @BUILD_ICECC@ @BUILD_CC@\n+BUILD_CXX := @BUILD_ICECC@ @BUILD_CXX@\n+BUILD_LD := @BUILD_LD@\n+BUILD_LDCXX := @BUILD_LDCXX@\n+BUILD_AS := @BUILD_AS@\n+BUILD_AR := @BUILD_AR@\n+BUILD_NM := @BUILD_NM@\n@@ -554,1 +565,1 @@\n-AS:=@FIXPATH@ @AS@\n+AS := @AS@\n@@ -557,1 +568,1 @@\n-AR:=@FIXPATH@ @AR@\n+AR := @AR@\n@@ -568,0 +579,2 @@\n+METAL := @METAL@\n+METALLIB := @METALLIB@\n@@ -606,1 +619,1 @@\n-EXE_SUFFIX:=@EXE_SUFFIX@\n+EXECUTABLE_SUFFIX:=@EXECUTABLE_SUFFIX@\n@@ -627,1 +640,0 @@\n-JARSIGNER_CMD:=@JARSIGNER@\n@@ -630,9 +642,7 @@\n-JAVA=@FIXPATH@ $(JAVA_CMD) $(JAVA_FLAGS_BIG) $(JAVA_FLAGS)\n-JAVA_SMALL=@FIXPATH@ $(JAVA_CMD) $(JAVA_FLAGS_SMALL) $(JAVA_FLAGS)\n-JAVA_DETACH =@FIXPATH@ @FIXPATH_DETACH_FLAG@ $(JAVA_CMD) $(JAVA_FLAGS_BIG) $(JAVA_FLAGS)\n-JAVAC=@FIXPATH@ $(JAVAC_CMD)\n-JAVADOC=@FIXPATH@ $(JAVADOC_CMD)\n-JAR=@FIXPATH@ $(JAR_CMD)\n-JLINK = @FIXPATH@ $(JLINK_CMD)\n-JMOD = @FIXPATH@ $(JMOD_CMD) $(JAVA_TOOL_FLAGS_SMALL)\n-JARSIGNER=@FIXPATH@ $(JARSIGNER_CMD)\n+JAVA = $(JAVA_CMD) $(JAVA_FLAGS_BIG) $(JAVA_FLAGS)\n+JAVA_SMALL = $(JAVA_CMD) $(JAVA_FLAGS_SMALL) $(JAVA_FLAGS)\n+JAVAC = $(JAVAC_CMD)\n+JAVADOC = $(JAVADOC_CMD)\n+JAR = $(JAR_CMD)\n+JLINK = $(JLINK_CMD)\n+JMOD = $(JMOD_CMD) $(JAVA_TOOL_FLAGS_SMALL)\n@@ -642,0 +652,1 @@\n+BUILD_JAVAC=@FIXPATH@ $(BUILD_JDK)\/bin\/javac\n@@ -644,0 +655,2 @@\n+DOCS_REFERENCE_JAVADOC := @DOCS_REFERENCE_JAVADOC@\n+\n@@ -652,0 +665,2 @@\n+    --add-exports java.base\/jdk.internal.javac=java.compiler.interim \\\n+    --add-exports java.base\/jdk.internal.javac=jdk.compiler.interim \\\n@@ -659,0 +674,1 @@\n+    --patch-module java.base=$(BUILDTOOLS_OUTPUTDIR)\/gensrc\/java.base.interim \\\n@@ -671,6 +687,1 @@\n-# Base flags for RC\n-# Guarding this against resetting value. Legacy make files include spec multiple\n-# times.\n-ifndef RC_FLAGS\n-  RC_FLAGS:=@RC_FLAGS@\n-endif\n+RCFLAGS := @RCFLAGS@\n@@ -687,2 +698,0 @@\n-COMM:=@COMM@\n-CPIO:=@CPIO@\n@@ -709,2 +718,1 @@\n-NAWK:=@NAWK@\n-PANDOC:=@FIXPATH@ @PANDOC@\n+PANDOC:=@PANDOC@\n@@ -727,1 +735,0 @@\n-UNIQ:=@UNIQ@\n@@ -732,4 +739,4 @@\n-MT:=@FIXPATH@ @MT@\n-RC:=@FIXPATH@ @RC@\n-DUMPBIN:=@FIXPATH@ @DUMPBIN@\n-CYGPATH:=@CYGPATH@\n+MT:=@MT@\n+RC:=@RC@\n+DUMPBIN:=@DUMPBIN@\n+PATHTOOL:=@PATHTOOL@\n@@ -752,1 +759,2 @@\n-FIXPATH:=@FIXPATH@\n+FIXPATH := @FIXPATH@\n+FIXPATH_BASE := @FIXPATH_BASE@\n@@ -760,2 +768,0 @@\n-ENABLE_AOT:=@ENABLE_AOT@\n-ENABLE_INTREE_EC:=@ENABLE_INTREE_EC@\n@@ -835,0 +841,4 @@\n+USE_EXTERNAL_HARFBUZZ:=@USE_EXTERNAL_HARFBUZZ@\n+HARFBUZZ_CFLAGS:=@HARFBUZZ_CFLAGS@\n+HARFBUZZ_LIBS:=@HARFBUZZ_LIBS@\n+\n@@ -845,1 +855,0 @@\n-INCLUDE_GRAAL=@INCLUDE_GRAAL@\n@@ -847,0 +856,1 @@\n+INCLUDE_COMPILER2=@INCLUDE_COMPILER2@\n@@ -876,2 +886,6 @@\n-DOCS_IMAGE_SUBDIR := docs\n-DOCS_IMAGE_DIR = $(IMAGES_OUTPUTDIR)\/$(DOCS_IMAGE_SUBDIR)\n+DOCS_JDK_IMAGE_SUBDIR := docs\n+DOCS_JDK_IMAGE_DIR = $(IMAGES_OUTPUTDIR)\/$(DOCS_JDK_IMAGE_SUBDIR)\n+DOCS_JAVASE_IMAGE_SUBDIR := docs-javase\n+DOCS_JAVASE_IMAGE_DIR = $(IMAGES_OUTPUTDIR)\/$(DOCS_JAVASE_IMAGE_SUBDIR)\n+DOCS_REFERENCE_IMAGE_SUBDIR := docs-reference\n+DOCS_REFERENCE_IMAGE_DIR = $(IMAGES_OUTPUTDIR)\/$(DOCS_REFERENCE_IMAGE_SUBDIR)\n@@ -879,1 +893,1 @@\n-DOCS_OUTPUTDIR := $(DOCS_IMAGE_DIR)\n+DOCS_OUTPUTDIR := $(DOCS_JDK_IMAGE_DIR)\n@@ -922,1 +936,3 @@\n-DOCS_BUNDLE_NAME := jdk-$(BASE_NAME)_doc-api-spec$(DEBUG_PART).tar.gz\n+DOCS_JDK_BUNDLE_NAME := jdk-$(BASE_NAME)_doc-api-spec$(DEBUG_PART).tar.gz\n+DOCS_JAVASE_BUNDLE_NAME := javase-$(BASE_NAME)_doc-api-spec$(DEBUG_PART).tar.gz\n+DOCS_REFERENCE_BUNDLE_NAME := jdk-reference-$(BASE_NAME)_doc-api-spec$(DEBUG_PART).tar.gz\n@@ -931,1 +947,3 @@\n-DOCS_BUNDLE :=  $(BUNDLES_OUTPUTDIR)\/$(DOCS_BUNDLE_NAME)\n+DOCS_JDK_BUNDLE :=  $(BUNDLES_OUTPUTDIR)\/$(DOCS_JDK_BUNDLE_NAME)\n+DOCS_JAVASE_BUNDLE :=  $(BUNDLES_OUTPUTDIR)\/$(DOCS_JAVASE_BUNDLE_NAME)\n+DOCS_REFERENCE_BUNDLE :=  $(BUNDLES_OUTPUTDIR)\/$(DOCS_REFERENCE_BUNDLE_NAME)\n","filename":"make\/autoconf\/spec.gmk.in","additions":92,"deletions":74,"binary":false,"changes":166,"status":"modified"},{"patch":"@@ -51,1 +51,0 @@\n-GLOBAL_VERSION_INFO_RESOURCE := $(TOPDIR)\/src\/java.base\/windows\/native\/common\/version.rc\n@@ -74,1 +73,1 @@\n-# EXTRA_RC_FLAGS   Additional EXTRA_RC_FLAGS\n+# EXTRA_RCFLAGS   Additional EXTRA_RCFLAGS\n@@ -107,3 +106,1 @@\n-      $1_PLIST_SRC_FILE := Info-privileged.plist\n-    else\n-      $1_PLIST_SRC_FILE := Info-cmdline.plist\n+      $1_PLIST_EXTRA := <key>SecTaskAccess<\/key><string>allowed<\/string>\n@@ -115,1 +112,1 @@\n-        SOURCE_FILES := $$(TOPDIR)\/src\/java.base\/macosx\/native\/launcher\/$$($1_PLIST_SRC_FILE), \\\n+        SOURCE_FILES := $(TOPDIR)\/make\/data\/bundle\/cmdline-Info.plist, \\\n@@ -118,1 +115,1 @@\n-            @@ID@@ => $(MACOSX_BUNDLE_ID_BASE).$(VERSION_SHORT).$1 ; \\\n+            @@ID@@ => $(MACOSX_BUNDLE_ID_BASE).$1 ; \\\n@@ -120,0 +117,2 @@\n+            @@BUILD_VERSION@@ => $(MACOSX_BUNDLE_BUILD_VERSION) ; \\\n+            @@EXTRA@@ => $$($1_PLIST_EXTRA), \\\n@@ -185,1 +184,1 @@\n-      EXTRA_RC_FLAGS := $$($1_EXTRA_RC_FLAGS), \\\n+      EXTRA_RCFLAGS := $$($1_EXTRA_RCFLAGS), \\\n@@ -203,0 +202,4 @@\n+\n+  ifeq ($(call isTargetOs, macosx), true)\n+    $$(BUILD_LAUNCHER_$1): $$($1_PLIST_FILE)\n+  endif\n","filename":"make\/common\/modules\/LauncherCommon.gmk","additions":11,"deletions":8,"binary":false,"changes":19,"status":"modified"},{"patch":"","filename":"make\/data\/hotspot-symbols\/symbols-shared","additions":0,"deletions":0,"binary":false,"changes":0,"previous_filename":"make\/hotspot\/symbols\/symbols-shared","status":"renamed"},{"patch":"@@ -0,0 +1,210 @@\n+#\n+# Copyright (c) 2016, 2021, Oracle and\/or its affiliates. All rights reserved.\n+# DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+#\n+# This code is free software; you can redistribute it and\/or modify it\n+# under the terms of the GNU General Public License version 2 only, as\n+# published by the Free Software Foundation.\n+#\n+# This code is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+# version 2 for more details (a copy is included in the LICENSE file that\n+# accompanied this code).\n+#\n+# You should have received a copy of the GNU General Public License version\n+# 2 along with this work; if not, write to the Free Software Foundation,\n+# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+#\n+# Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+# or visit www.oracle.com if you need additional information or have any\n+# questions.\n+#\n+\n+JVM_ActiveProcessorCount\n+JVM_AreNestMates\n+JVM_ArrayCopy\n+JVM_AssertionStatusDirectives\n+JVM_BeforeHalt\n+JVM_CallStackWalk\n+JVM_Clone\n+JVM_ConstantPoolGetClassAt\n+JVM_ConstantPoolGetClassAtIfLoaded\n+JVM_ConstantPoolGetClassRefIndexAt\n+JVM_ConstantPoolGetDoubleAt\n+JVM_ConstantPoolGetFieldAt\n+JVM_ConstantPoolGetFieldAtIfLoaded\n+JVM_ConstantPoolGetFloatAt\n+JVM_ConstantPoolGetIntAt\n+JVM_ConstantPoolGetLongAt\n+JVM_ConstantPoolGetMemberRefInfoAt\n+JVM_ConstantPoolGetMethodAt\n+JVM_ConstantPoolGetMethodAtIfLoaded\n+JVM_ConstantPoolGetNameAndTypeRefIndexAt\n+JVM_ConstantPoolGetNameAndTypeRefInfoAt\n+JVM_ConstantPoolGetSize\n+JVM_ConstantPoolGetStringAt\n+JVM_ConstantPoolGetTagAt\n+JVM_ConstantPoolGetUTF8At\n+JVM_CurrentThread\n+JVM_CurrentTimeMillis\n+JVM_DefineClass\n+JVM_DefineClassWithSource\n+JVM_DesiredAssertionStatus\n+JVM_DumpAllStacks\n+JVM_DumpClassListToFile\n+JVM_DumpDynamicArchive\n+JVM_DumpThreads\n+JVM_FillInStackTrace\n+JVM_FindClassFromCaller\n+JVM_FindClassFromClass\n+JVM_FindLibraryEntry\n+JVM_FindLoadedClass\n+JVM_FindPrimitiveClass\n+JVM_FindSignal\n+JVM_FreeMemory\n+JVM_GC\n+JVM_GetAllThreads\n+JVM_GetAndClearReferencePendingList\n+JVM_GetArrayElement\n+JVM_GetArrayLength\n+JVM_GetCallerClass\n+JVM_GetClassAccessFlags\n+JVM_GetClassAnnotations\n+JVM_GetClassConstantPool\n+JVM_GetClassContext\n+JVM_GetClassCPEntriesCount\n+JVM_GetClassCPTypes\n+JVM_GetClassDeclaredConstructors\n+JVM_GetClassDeclaredFields\n+JVM_GetClassDeclaredMethods\n+JVM_GetClassFieldsCount\n+JVM_GetClassInterfaces\n+JVM_GetClassMethodsCount\n+JVM_GetClassModifiers\n+JVM_GetClassNameUTF\n+JVM_GetClassSignature\n+JVM_GetClassSigners\n+JVM_GetClassTypeAnnotations\n+JVM_GetCPClassNameUTF\n+JVM_GetCPFieldClassNameUTF\n+JVM_GetCPFieldModifiers\n+JVM_GetCPFieldNameUTF\n+JVM_GetCPFieldSignatureUTF\n+JVM_GetCPMethodClassNameUTF\n+JVM_GetCPMethodModifiers\n+JVM_GetCPMethodNameUTF\n+JVM_GetCPMethodSignatureUTF\n+JVM_GetDeclaredClasses\n+JVM_GetDeclaringClass\n+JVM_GetEnclosingMethodInfo\n+JVM_GetExtendedNPEMessage\n+JVM_GetFieldIxModifiers\n+JVM_GetFieldTypeAnnotations\n+JVM_GetInheritedAccessControlContext\n+JVM_GetManagement\n+JVM_GetMethodIxArgsSize\n+JVM_GetMethodIxByteCode\n+JVM_GetMethodIxByteCodeLength\n+JVM_GetMethodIxExceptionIndexes\n+JVM_GetMethodIxExceptionsCount\n+JVM_GetMethodIxExceptionTableEntry\n+JVM_GetMethodIxExceptionTableLength\n+JVM_GetMethodIxLocalsCount\n+JVM_GetMethodIxMaxStack\n+JVM_GetMethodIxModifiers\n+JVM_GetMethodIxNameUTF\n+JVM_GetMethodIxSignatureUTF\n+JVM_GetMethodParameters\n+JVM_GetMethodTypeAnnotations\n+JVM_GetNanoTimeAdjustment\n+JVM_GetNestHost\n+JVM_GetNestMembers\n+JVM_GetPermittedSubclasses\n+JVM_GetPrimitiveArrayElement\n+JVM_GetProperties\n+JVM_GetProtectionDomain\n+JVM_GetRandomSeedForDumping\n+JVM_GetRecordComponents\n+JVM_GetSimpleBinaryName\n+JVM_GetStackAccessControlContext\n+JVM_GetSystemPackage\n+JVM_GetSystemPackages\n+JVM_GetTemporaryDirectory\n+JVM_GetTsanEnabled\n+JVM_GetVmArguments\n+JVM_Halt\n+JVM_HasReferencePendingList\n+JVM_HoldsLock\n+JVM_IHashCode\n+JVM_InitClassName\n+JVM_InitStackTraceElement\n+JVM_InitStackTraceElementArray\n+JVM_InitializeFromArchive\n+JVM_InternString\n+JVM_Interrupt\n+JVM_InvokeMethod\n+JVM_IsArrayClass\n+JVM_IsCDSDumpingEnabled\n+JVM_IsConstructorIx\n+JVM_IsDumpingClassList\n+JVM_IsHiddenClass\n+JVM_IsInterface\n+JVM_IsPrimitiveClass\n+JVM_IsRecord\n+JVM_IsSameClassPackage\n+JVM_IsSharingEnabled\n+JVM_IsSupportedJNIVersion\n+JVM_IsThreadAlive\n+JVM_IsVMGeneratedMethodIx\n+JVM_LatestUserDefinedLoader\n+JVM_LoadLibrary\n+JVM_LookupDefineClass\n+JVM_LookupLambdaProxyClassFromArchive\n+JVM_LogLambdaFormInvoker\n+JVM_MaxMemory\n+JVM_MaxObjectInspectionAge\n+JVM_MonitorNotify\n+JVM_MonitorNotifyAll\n+JVM_MonitorWait\n+JVM_MoreStackWalk\n+JVM_NanoTime\n+JVM_NativePath\n+JVM_NewArray\n+JVM_NewInstanceFromConstructor\n+JVM_NewMultiArray\n+JVM_PhantomReferenceRefersTo\n+JVM_RaiseSignal\n+JVM_RawMonitorCreate\n+JVM_RawMonitorDestroy\n+JVM_RawMonitorEnter\n+JVM_RawMonitorExit\n+JVM_ReferenceClear\n+JVM_ReferenceRefersTo\n+JVM_RegisterLambdaProxyClassForArchiving\n+JVM_RegisterSignal\n+JVM_ReleaseUTF\n+JVM_ResumeThread\n+JVM_SetArrayElement\n+JVM_SetClassSigners\n+JVM_SetNativeThreadName\n+JVM_SetPrimitiveArrayElement\n+JVM_SetThreadPriority\n+JVM_Sleep\n+JVM_StartThread\n+JVM_StopThread\n+JVM_SupportsCX8\n+JVM_SuspendThread\n+JVM_TotalMemory\n+JVM_UnloadLibrary\n+JVM_WaitForReferencePendingList\n+JVM_Yield\n+\n+# Module related API's\n+JVM_AddModuleExports\n+JVM_AddModuleExportsToAll\n+JVM_AddModuleExportsToAllUnnamed\n+JVM_AddReadsModule\n+JVM_DefineArchivedModules\n+JVM_DefineModule\n+JVM_SetBootLoaderUnnamedModule\n","filename":"make\/data\/hotspot-symbols\/symbols-unix","additions":210,"deletions":0,"binary":false,"changes":210,"status":"added"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2013, 2020, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2013, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -48,1 +48,5 @@\n-  JVM_CFLAGS_FEATURES += -DZERO -DCC_INTERP -DZERO_LIBARCH='\"$(OPENJDK_TARGET_CPU_LEGACY_LIB)\"' $(LIBFFI_CFLAGS)\n+  JVM_EXCLUDES += opto libadt\n+  JVM_EXCLUDE_PATTERNS += c1_ c1\/ c2_ runtime_ \/c2\/\n+  JVM_EXCLUDE_FILES += templateInterpreter.cpp templateInterpreterGenerator.cpp \\\n+                       bcEscapeAnalyzer.cpp ciTypeFlow.cpp\n+  JVM_CFLAGS_FEATURES += -DZERO -DZERO_LIBARCH='\"$(OPENJDK_TARGET_CPU_LEGACY_LIB)\"' $(LIBFFI_CFLAGS)\n@@ -53,0 +57,2 @@\n+else\n+  JVM_EXCLUDE_PATTERNS += \/zero\/\n@@ -81,1 +87,1 @@\n-      jvmtiClassFileReconstituter.cpp\n+      jvmtiClassFileReconstituter.cpp jvmtiTagMapTable.cpp\n@@ -113,1 +119,1 @@\n-      classListParser.cpp \\\n+      classLoaderDataShared.cpp \\\n@@ -115,10 +121,2 @@\n-      dynamicArchive.cpp \\\n-      filemap.cpp \\\n-      heapShared.cpp \\\n-      metaspaceShared.cpp \\\n-      metaspaceShared_$(HOTSPOT_TARGET_CPU).cpp \\\n-      metaspaceShared_$(HOTSPOT_TARGET_CPU_ARCH).cpp \\\n-      sharedClassUtil.cpp \\\n-      sharedPathsMiscInfo.cpp \\\n-      systemDictionaryShared.cpp \\\n-      #\n+      systemDictionaryShared.cpp\n+  JVM_EXCLUDE_PATTERNS += cds\/\n@@ -134,8 +132,0 @@\n-ifneq ($(call check-jvm-feature, aot), true)\n-  JVM_CFLAGS_FEATURES += -DINCLUDE_AOT=0\n-  JVM_EXCLUDE_FILES += \\\n-      compiledIC_aot_x86_64.cpp compiledIC_aot_aarch64.cpp      \\\n-      compilerRuntime.cpp aotCodeHeap.cpp aotCompiledMethod.cpp \\\n-      aotLoader.cpp compiledIC_aot.cpp\n-endif\n-\n","filename":"make\/hotspot\/lib\/JvmFeatures.gmk","additions":12,"deletions":22,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -33,2 +33,1 @@\n-JAVA_RC_FLAGS += -I$(TOPDIR)\/src\/java.base\/windows\/native\/common\n-JAVA_RC_FLAGS += -I$(TOPDIR)\/src\/java.base\/windows\/native\/launcher\/icons\n+JAVA_RCFLAGS ?= -I$(TOPDIR)\/src\/java.base\/windows\/native\/launcher\/icons\n@@ -40,1 +39,1 @@\n-    EXTRA_RC_FLAGS := $(JAVA_RC_FLAGS), \\\n+    EXTRA_RCFLAGS := $(JAVA_RCFLAGS), \\\n@@ -49,1 +48,1 @@\n-      EXTRA_RC_FLAGS := $(JAVA_RC_FLAGS), \\\n+      EXTRA_RCFLAGS := $(JAVA_RCFLAGS), \\\n","filename":"make\/modules\/java.base\/Launcher.gmk","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -52,1 +52,1 @@\n-    DISABLED_WARNINGS_clang := sign-compare, \\\n+    DISABLED_WARNINGS_clang := sign-compare misleading-indentation, \\\n@@ -160,1 +160,0 @@\n-    LIBS_macosx := -lc++, \\\n","filename":"make\/modules\/java.base\/lib\/CoreLibraries.gmk","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 2003, 2020, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2014, Red Hat Inc. All rights reserved.\n+ * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2020, Red Hat Inc. All rights reserved.\n@@ -28,0 +28,1 @@\n+#include \"compiler\/compiler_globals.hpp\"\n@@ -171,1 +172,1 @@\n-  unsigned long offset;\n+  uint64_t offset;\n@@ -476,1 +477,1 @@\n-    ldr(rscratch2, Address(rthread, Thread::polling_page_offset()));\n+    ldr(rscratch2, Address(rthread, JavaThread::polling_word_offset()));\n@@ -524,0 +525,1 @@\n+\/\/ Apply stack watermark barrier.\n@@ -544,0 +546,15 @@\n+  \/\/ The below poll is for the stack watermark barrier. It allows fixing up frames lazily,\n+  \/\/ that would normally not be safe to use. Such bad returns into unsafe territory of\n+  \/\/ the stack, will call InterpreterRuntime::at_unwind.\n+  Label slow_path;\n+  Label fast_path;\n+  safepoint_poll(slow_path, true \/* at_return *\/, false \/* acquire *\/, false \/* in_nmethod *\/);\n+  br(Assembler::AL, fast_path);\n+  bind(slow_path);\n+  push(state);\n+  set_last_Java_frame(esp, rfp, (address)pc(), rscratch1);\n+  super_call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::at_unwind), rthread);\n+  reset_last_Java_frame(true);\n+  pop(state);\n+  bind(fast_path);\n+\n@@ -668,1 +685,1 @@\n-  ldr(esp,\n+  ldr(rscratch2,\n@@ -674,0 +691,2 @@\n+    \/\/ look for an overflow into the stack reserved zone, i.e.\n+    \/\/ interpreter_frame_sender_sp <= JavaThread::reserved_stack_activation\n@@ -675,1 +694,1 @@\n-    cmp(esp, rscratch1);\n+    cmp(rscratch2, rscratch1);\n@@ -686,0 +705,3 @@\n+\n+  \/\/ restore sender esp\n+  mov(esp, rscratch2);\n@@ -731,0 +753,7 @@\n+    if (DiagnoseSyncOnValueBasedClasses != 0) {\n+      load_klass(tmp, obj_reg);\n+      ldrw(tmp, Address(tmp, Klass::access_flags_offset()));\n+      tstw(tmp, JVM_ACC_IS_VALUE_BASED_CLASS);\n+      br(Assembler::NE, slow_case);\n+    }\n+\n@@ -758,1 +787,7 @@\n-    \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n+    \/\/ Fast check for recursive lock.\n+    \/\/\n+    \/\/ Can apply the optimization only if this is a stack lock\n+    \/\/ allocated in this thread. For efficiency, we can focus on\n+    \/\/ recently allocated stack locks (instead of reading the stack\n+    \/\/ base and checking whether 'mark' points inside the current\n+    \/\/ thread stack):\n@@ -760,1 +795,13 @@\n-    \/\/  2) rsp <= mark < mark + os::pagesize()\n+    \/\/  2) sp <= mark < mark + os::pagesize()\n+    \/\/\n+    \/\/ Warning: sp + os::pagesize can overflow the stack base. We must\n+    \/\/ neither apply the optimization for an inflated lock allocated\n+    \/\/ just above the thread stack (this is why condition 1 matters)\n+    \/\/ nor apply the optimization if the stack lock is inside the stack\n+    \/\/ of another thread. The latter is avoided even in case of overflow\n+    \/\/ because we have guard pages at the end of all stacks. Hence, if\n+    \/\/ we go over the stack base and hit the stack of another thread,\n+    \/\/ this should not be in a writeable area that could contain a\n+    \/\/ stack lock allocated by that thread. As a consequence, a stack\n+    \/\/ lock less than page size away from sp is guaranteed to be\n+    \/\/ owned by the current thread.\n@@ -763,1 +810,1 @@\n-    \/\/ expression: ((mark - rsp) & (7 - os::vm_page_size())),\n+    \/\/ expression: ((mark - sp) & (7 - os::vm_page_size())),\n@@ -766,1 +813,1 @@\n-    \/\/ NOTE: the oopMark is in swap_reg %r0 as the result of cmpxchg\n+    \/\/ NOTE: the mark is in swap_reg %r0 as the result of cmpxchg\n@@ -771,1 +818,1 @@\n-    ands(swap_reg, swap_reg, (unsigned long)(7 - os::vm_page_size()));\n+    ands(swap_reg, swap_reg, (uint64_t)(7 - os::vm_page_size()));\n@@ -828,3 +875,1 @@\n-    call_VM(noreg,\n-            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit),\n-            lock_reg);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n@@ -866,3 +911,1 @@\n-    call_VM(noreg,\n-            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit),\n-            lock_reg);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n@@ -1614,1 +1657,1 @@\n-    stop(\"InterpreterMacroAssembler::call_VM_leaf_base:\"\n+    stop(\"InterpreterMacroAssembler::call_VM_base:\"\n@@ -1775,1 +1818,1 @@\n-      subs(zr, rscratch1, vmIntrinsics::_compiledLambdaForm);\n+      subs(zr, rscratch1, static_cast<int>(vmIntrinsics::_compiledLambdaForm));\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":62,"deletions":19,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -2,2 +2,3 @@\n- * Copyright (c) 2003, 2020, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2014, 2020, Red Hat Inc. All rights reserved.\n+ * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2021, Red Hat Inc. All rights reserved.\n+ * Copyright (c) 2021, Azul Systems, Inc. All rights reserved.\n@@ -29,0 +30,1 @@\n+#include \"code\/codeCache.hpp\"\n@@ -32,0 +34,1 @@\n+#include \"compiler\/oopMap.hpp\"\n@@ -40,0 +43,2 @@\n+#include \"prims\/methodHandles.hpp\"\n+#include \"runtime\/jniHandles.hpp\"\n@@ -42,0 +47,2 @@\n+#include \"runtime\/signature.hpp\"\n+#include \"runtime\/stubRoutines.hpp\"\n@@ -44,0 +51,1 @@\n+#include \"utilities\/formatBuffer.hpp\"\n@@ -82,0 +90,1 @@\n+  const bool _save_vectors;\n@@ -83,2 +92,4 @@\n-  static OopMap* save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words, bool save_vectors = false);\n-  static void restore_live_registers(MacroAssembler* masm, bool restore_vectors = false);\n+  RegisterSaver(bool save_vectors) : _save_vectors(save_vectors) {}\n+\n+  OopMap* save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words);\n+  void restore_live_registers(MacroAssembler* masm);\n@@ -90,10 +101,4 @@\n-  static int r0_offset_in_bytes(void)    { return (32 + r0->encoding()) * wordSize; }\n-  static int reg_offset_in_bytes(Register r)    { return r0_offset_in_bytes() + r->encoding() * wordSize; }\n-  static int rmethod_offset_in_bytes(void)    { return reg_offset_in_bytes(rmethod); }\n-  static int rscratch1_offset_in_bytes(void)    { return (32 + rscratch1->encoding()) * wordSize; }\n-  static int v0_offset_in_bytes(void)   { return 0; }\n-  static int return_offset_in_bytes(void) { return (32 \/* floats*\/ + 31 \/* gregs*\/) * wordSize; }\n-\n-  \/\/ During deoptimization only the result registers need to be restored,\n-  \/\/ all the other values have already been extracted.\n-  static void restore_result_registers(MacroAssembler* masm);\n+  int reg_offset_in_bytes(Register r);\n+  int r0_offset_in_bytes()    { return reg_offset_in_bytes(r0); }\n+  int rscratch1_offset_in_bytes()    { return reg_offset_in_bytes(rscratch1); }\n+  int v0_offset_in_bytes(void)   { return 0; }\n@@ -101,1 +106,2 @@\n-    \/\/ Capture info about frame layout\n+  \/\/ Capture info about frame layout\n+  \/\/ Note this is only correct when not saving full vectors.\n@@ -116,1 +122,8 @@\n-OopMap* RegisterSaver::save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words, bool save_vectors) {\n+int RegisterSaver::reg_offset_in_bytes(Register r) {\n+  \/\/ The integer registers are located above the floating point\n+  \/\/ registers in the stack frame pushed by save_live_registers() so the\n+  \/\/ offset depends on whether we are saving full vectors, and whether\n+  \/\/ those vectors are NEON or SVE.\n+\n+  int slots_per_vect = FloatRegisterImpl::save_slots_per_register;\n+\n@@ -118,1 +131,30 @@\n-  if (save_vectors) {\n+  if (_save_vectors) {\n+    slots_per_vect = FloatRegisterImpl::slots_per_neon_register;\n+\n+#ifdef COMPILER2\n+    if (Matcher::supports_scalable_vector()) {\n+      slots_per_vect = Matcher::scalable_vector_reg_size(T_FLOAT);\n+    }\n+#endif\n+  }\n+#endif\n+\n+  int r0_offset = (slots_per_vect * FloatRegisterImpl::number_of_registers) * BytesPerInt;\n+  return r0_offset + r->encoding() * wordSize;\n+}\n+\n+OopMap* RegisterSaver::save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words) {\n+  bool use_sve = false;\n+  int sve_vector_size_in_bytes = 0;\n+  int sve_vector_size_in_slots = 0;\n+\n+#ifdef COMPILER2\n+  use_sve = Matcher::supports_scalable_vector();\n+  sve_vector_size_in_bytes = Matcher::scalable_vector_reg_size(T_BYTE);\n+  sve_vector_size_in_slots = Matcher::scalable_vector_reg_size(T_FLOAT);\n+#endif\n+\n+#if COMPILER2_OR_JVMCI\n+  if (_save_vectors) {\n+    int vect_words = 0;\n+    int extra_save_slots_per_register = 0;\n@@ -120,2 +162,7 @@\n-    int vect_words = FloatRegisterImpl::number_of_registers * FloatRegisterImpl::extra_save_slots_per_register \/\n-                     VMRegImpl::slots_per_word;\n+    if (use_sve) {\n+      extra_save_slots_per_register = sve_vector_size_in_slots - FloatRegisterImpl::save_slots_per_register;\n+    } else {\n+      extra_save_slots_per_register = FloatRegisterImpl::extra_save_slots_per_neon_register;\n+    }\n+    vect_words = FloatRegisterImpl::number_of_registers * extra_save_slots_per_register \/\n+                 VMRegImpl::slots_per_word;\n@@ -125,1 +172,1 @@\n-  assert(!save_vectors, \"vectors are generated only by C2 and JVMCI\");\n+  assert(!_save_vectors, \"vectors are generated only by C2 and JVMCI\");\n@@ -140,1 +187,1 @@\n-  __ push_CPU_state(save_vectors);\n+  __ push_CPU_state(_save_vectors, use_sve, sve_vector_size_in_bytes);\n@@ -164,2 +211,7 @@\n-    int sp_offset = save_vectors ? (FloatRegisterImpl::max_slots_per_register * i) :\n-                                   (FloatRegisterImpl::save_slots_per_register * i);\n+    int sp_offset = 0;\n+    if (_save_vectors) {\n+      sp_offset = use_sve ? (sve_vector_size_in_slots * i) :\n+                            (FloatRegisterImpl::slots_per_neon_register * i);\n+    } else {\n+      sp_offset = FloatRegisterImpl::save_slots_per_register * i;\n+    }\n@@ -173,3 +225,9 @@\n-void RegisterSaver::restore_live_registers(MacroAssembler* masm, bool restore_vectors) {\n-#if !COMPILER2_OR_JVMCI\n-  assert(!restore_vectors, \"vectors are generated only by C2 and JVMCI\");\n+void RegisterSaver::restore_live_registers(MacroAssembler* masm) {\n+#ifdef COMPILER2\n+  __ pop_CPU_state(_save_vectors, Matcher::supports_scalable_vector(),\n+                   Matcher::scalable_vector_reg_size(T_BYTE));\n+#else\n+#if !INCLUDE_JVMCI\n+  assert(!_save_vectors, \"vectors are generated only by C2 and JVMCI\");\n+#endif\n+  __ pop_CPU_state(_save_vectors);\n@@ -177,1 +235,0 @@\n-  __ pop_CPU_state(restore_vectors);\n@@ -182,17 +239,0 @@\n-void RegisterSaver::restore_result_registers(MacroAssembler* masm) {\n-\n-  \/\/ Just restore result register. Only used by deoptimization. By\n-  \/\/ now any callee save register that needs to be restored to a c2\n-  \/\/ caller of the deoptee has been extracted into the vframeArray\n-  \/\/ and will be stuffed into the c2i adapter we create for later\n-  \/\/ restoration so only result registers need to be restored here.\n-\n-  \/\/ Restore fp result register\n-  __ ldrd(v0, Address(sp, v0_offset_in_bytes()));\n-  \/\/ Restore integer result register\n-  __ ldr(r0, Address(sp, r0_offset_in_bytes()));\n-\n-  \/\/ Pop all of the register save are off the stack\n-  __ add(sp, sp, align_up(return_offset_in_bytes(), 16));\n-}\n-\n@@ -205,9 +245,0 @@\n-size_t SharedRuntime::trampoline_size() {\n-  return 16;\n-}\n-\n-void SharedRuntime::generate_trampoline(MacroAssembler *masm, address destination) {\n-  __ mov(rscratch1, destination);\n-  __ br(rscratch1);\n-}\n-\n@@ -250,2 +281,1 @@\n-                                           int total_args_passed,\n-                                           int is_outgoing) {\n+                                           int total_args_passed) {\n@@ -348,1 +378,4 @@\n-  __ maybe_isb();\n+\n+  \/\/ Explicit isb required because fixup_callers_callsite may change the code\n+  \/\/ stream.\n+  __ safepoint_isb();\n@@ -405,1 +438,1 @@\n-    \/\/ However to make thing extra confusing. Because we can fit a long\/double in\n+    \/\/ However to make thing extra confusing. Because we can fit a Java long\/double in\n@@ -438,1 +471,1 @@\n-          __ mov(rscratch1, 0xdeadffffdeadaaaaul);\n+          __ mov(rscratch1, (uint64_t)0xdeadffffdeadaaaaull);\n@@ -455,1 +488,1 @@\n-          \/\/ long\/double in gpr\n+          \/\/ jlong\/double in gpr\n@@ -458,1 +491,1 @@\n-          __ mov(rscratch1, 0xdeadffffdeadaaabul);\n+          __ mov(rscratch1, (uint64_t)0xdeadffffdeadaaabull);\n@@ -474,1 +507,1 @@\n-        __ mov(rscratch1, 0xdeadffffdeadaaacul);\n+        __ mov(rscratch1, (uint64_t)0xdeadffffdeadaaacull);\n@@ -564,1 +597,1 @@\n-  if (EnableJVMCI || UseAOT) {\n+  if (EnableJVMCI) {\n@@ -745,1 +778,1 @@\n-int SharedRuntime::c_calling_convention(const BasicType *sig_bt,\n+static int c_calling_convention_priv(const BasicType *sig_bt,\n@@ -776,0 +809,5 @@\n+#ifdef __APPLE__\n+          \/\/ Less-than word types are stored one after another.\n+          \/\/ The code is unable to handle this so bailout.\n+          return -1;\n+#endif\n@@ -798,0 +836,5 @@\n+#ifdef __APPLE__\n+          \/\/ Less-than word types are stored one after another.\n+          \/\/ The code is unable to handle this so bailout.\n+          return -1;\n+#endif\n@@ -824,0 +867,17 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  Unimplemented();\n+  return 0;\n+}\n+\n+int SharedRuntime::c_calling_convention(const BasicType *sig_bt,\n+                                         VMRegPair *regs,\n+                                         VMRegPair *regs2,\n+                                         int total_args_passed)\n+{\n+  int result = c_calling_convention_priv(sig_bt, regs, regs2, total_args_passed);\n+  guarantee(result >= 0, \"Unsupported arguments configuration\");\n+  return result;\n+}\n+\n@@ -825,1 +885,1 @@\n-\/\/ 64 bits items (sparc abi) even though java would only store\n+\/\/ 64 bits items (Aarch64 abi) even though java would only store\n@@ -1055,14 +1115,0 @@\n-\n-\/\/ Check GCLocker::needs_gc and enter the runtime if it's true.  This\n-\/\/ keeps a new JNI critical region from starting until a GC has been\n-\/\/ forced.  Save down any oops in registers and describe them in an\n-\/\/ OopMap.\n-static void check_needs_gc_for_critical_native(MacroAssembler* masm,\n-                                               int stack_slots,\n-                                               int total_c_args,\n-                                               int total_in_args,\n-                                               int arg_save_area,\n-                                               OopMapSet* oop_maps,\n-                                               VMRegPair* in_regs,\n-                                               BasicType* in_sig_bt) { Unimplemented(); }\n-\n@@ -1139,1 +1185,0 @@\n-    __ maybe_isb();\n@@ -1182,1 +1227,1 @@\n-  } else if (iid == vmIntrinsics::_invokeBasic) {\n+  } else if (iid == vmIntrinsics::_invokeBasic || iid == vmIntrinsics::_linkToNative) {\n@@ -1185,1 +1230,1 @@\n-    fatal(\"unexpected intrinsic id %d\", iid);\n+    fatal(\"unexpected intrinsic id %d\", vmIntrinsics::as_int(iid));\n@@ -1234,4 +1279,3 @@\n-\/\/ passing them to the callee and perform checks before and after the\n-\/\/ native call to ensure that they GCLocker\n-\/\/ lock_critical\/unlock_critical semantics are followed.  Some other\n-\/\/ parts of JNI setup are skipped like the tear down of the JNI handle\n+\/\/ passing them to the callee. Critical native functions leave the state _in_Java,\n+\/\/ since they block out GC.\n+\/\/ Some other parts of JNI setup are skipped like the tear down of the JNI handle\n@@ -1241,12 +1285,0 @@\n-\/\/ They are roughly structured like this:\n-\/\/    if (GCLocker::needs_gc())\n-\/\/      SharedRuntime::block_for_jni_critical();\n-\/\/    tranistion to thread_in_native\n-\/\/    unpack arrray arguments and call native entry point\n-\/\/    check for safepoint in progress\n-\/\/    check if any thread suspend flags are set\n-\/\/      call into JVM and possible unlock the JNI critical\n-\/\/      if a GC was suppressed while in the critical native.\n-\/\/    transition back to thread_in_Java\n-\/\/    return to caller\n-\/\/\n@@ -1357,1 +1389,5 @@\n-  out_arg_slots = c_calling_convention(out_sig_bt, out_regs, NULL, total_c_args);\n+  out_arg_slots = c_calling_convention_priv(out_sig_bt, out_regs, NULL, total_c_args);\n+\n+  if (out_arg_slots < 0) {\n+    return NULL;\n+  }\n@@ -1498,5 +1534,1 @@\n-  if (UseStackBanging) {\n-    __ bang_stack_with_offset(JavaThread::stack_shadow_zone_size());\n-  } else {\n-    Unimplemented();\n-  }\n+  __ bang_stack_with_offset(checked_cast<int>(StackOverflow::stack_shadow_zone_size()));\n@@ -1520,5 +1552,0 @@\n-  if (is_critical_native) {\n-    check_needs_gc_for_critical_native(masm, stack_slots, total_c_args, total_in_args,\n-                                       oop_handle_offset, oop_maps, in_regs, in_sig_bt);\n-  }\n-\n@@ -1703,1 +1730,1 @@\n-    unsigned long offset;\n+    uint64_t offset;\n@@ -1758,2 +1785,0 @@\n-    __ resolve(IS_NOT_NULL, obj_reg);\n-\n@@ -1814,5 +1839,5 @@\n-  }\n-  \/\/ Now set thread in native\n-  __ mov(rscratch1, _thread_in_native);\n-  __ lea(rscratch2, Address(rthread, JavaThread::thread_state_offset()));\n-  __ stlrw(rscratch1, rscratch2);\n+    \/\/ Now set thread in native\n+    __ mov(rscratch1, _thread_in_native);\n+    __ lea(rscratch2, Address(rthread, JavaThread::thread_state_offset()));\n+    __ stlrw(rscratch1, rscratch2);\n+  }\n@@ -1847,0 +1872,15 @@\n+  Label safepoint_in_progress, safepoint_in_progress_done;\n+  Label after_transition;\n+\n+  \/\/ If this is a critical native, check for a safepoint or suspend request after the call.\n+  \/\/ If a safepoint is needed, transition to native, then to native_trans to handle\n+  \/\/ safepoints like the native methods that are not critical natives.\n+  if (is_critical_native) {\n+    Label needs_safepoint;\n+    __ safepoint_poll(needs_safepoint, false \/* at_return *\/, true \/* acquire *\/, false \/* in_nmethod *\/);\n+    __ ldrw(rscratch1, Address(rthread, JavaThread::suspend_flags_offset()));\n+    __ cbnzw(rscratch1, needs_safepoint);\n+    __ b(after_transition);\n+    __ bind(needs_safepoint);\n+  }\n+\n@@ -1861,2 +1901,3 @@\n-  \/\/ check for safepoint operation in progress and\/or pending suspend requests\n-  Label safepoint_in_progress, safepoint_in_progress_done;\n+  __ verify_sve_vector_length();\n+\n+  \/\/ Check for safepoint operation in progress and\/or pending suspend requests.\n@@ -1864,1 +1905,10 @@\n-    __ safepoint_poll_acquire(safepoint_in_progress);\n+    \/\/ We need an acquire here to ensure that any subsequent load of the\n+    \/\/ global SafepointSynchronize::_state flag is ordered after this load\n+    \/\/ of the thread-local polling word.  We don't want this poll to\n+    \/\/ return false (i.e. not safepointing) and a later poll of the global\n+    \/\/ SafepointSynchronize::_state spuriously to return true.\n+    \/\/\n+    \/\/ This is to avoid a race when we're in a native->Java transition\n+    \/\/ racing the code which wakes up from a safepoint.\n+\n+    __ safepoint_poll(safepoint_in_progress, true \/* at_return *\/, true \/* acquire *\/, false \/* in_nmethod *\/);\n@@ -1871,1 +1921,0 @@\n-  Label after_transition;\n@@ -1880,1 +1929,1 @@\n-  __ cmpw(rscratch1, JavaThread::stack_guard_yellow_reserved_disabled);\n+  __ cmpw(rscratch1, StackOverflow::stack_guard_yellow_reserved_disabled);\n@@ -1950,1 +1999,1 @@\n-    unsigned long offset;\n+    uint64_t offset;\n@@ -2092,5 +2141,1 @@\n-    if (!is_critical_native) {\n-      __ lea(rscratch1, RuntimeAddress(CAST_FROM_FN_PTR(address, JavaThread::check_special_condition_for_native_trans)));\n-    } else {\n-      __ lea(rscratch1, RuntimeAddress(CAST_FROM_FN_PTR(address, JavaThread::check_special_condition_for_native_trans_and_transition)));\n-    }\n+    __ lea(rscratch1, RuntimeAddress(CAST_FROM_FN_PTR(address, JavaThread::check_special_condition_for_native_trans)));\n@@ -2098,1 +2143,1 @@\n-    __ maybe_isb();\n+\n@@ -2102,6 +2147,0 @@\n-    if (is_critical_native) {\n-      \/\/ The call above performed the transition to thread_in_Java so\n-      \/\/ skip the transition logic above.\n-      __ b(after_transition);\n-    }\n-\n@@ -2156,5 +2195,0 @@\n-  if (is_critical_native) {\n-    nm->set_lazy_critical_native(true);\n-  }\n-\n-\n@@ -2184,1 +2218,1 @@\n-  if (EnableJVMCI || UseAOT) {\n+  if (EnableJVMCI) {\n@@ -2193,0 +2227,1 @@\n+  RegisterSaver reg_save(COMPILER2_OR_JVMCI != 0);\n@@ -2230,1 +2265,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  map = reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -2248,1 +2283,1 @@\n-  (void) RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  (void) reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -2258,1 +2293,1 @@\n-  if (EnableJVMCI || UseAOT) {\n+  if (EnableJVMCI) {\n@@ -2267,1 +2302,1 @@\n-    RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+    reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -2324,1 +2359,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  map = reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -2384,1 +2419,1 @@\n-  if (EnableJVMCI || UseAOT) {\n+  if (EnableJVMCI) {\n@@ -2405,1 +2440,1 @@\n-  __ str(r0, Address(sp, RegisterSaver::r0_offset_in_bytes()));\n+  __ str(r0, Address(sp, reg_save.r0_offset_in_bytes()));\n@@ -2414,1 +2449,8 @@\n-  RegisterSaver::restore_result_registers(masm);\n+\n+  \/\/ Restore fp result register\n+  __ ldrd(v0, Address(sp, reg_save.v0_offset_in_bytes()));\n+  \/\/ Restore integer result register\n+  __ ldr(r0, Address(sp, reg_save.r0_offset_in_bytes()));\n+\n+  \/\/ Pop all of the register save area off the stack\n+  __ add(sp, sp, frame_size_in_words * wordSize);\n@@ -2441,4 +2483,2 @@\n-  if (UseStackBanging) {\n-    __ ldrw(r19, Address(r5, Deoptimization::UnrollBlock::total_frame_sizes_offset_in_bytes()));\n-    __ bang_stack_size(r19, r2);\n-  }\n+  __ ldrw(r19, Address(r5, Deoptimization::UnrollBlock::total_frame_sizes_offset_in_bytes()));\n+  __ bang_stack_size(r19, r2);\n@@ -2472,1 +2512,1 @@\n-  __ mov(rscratch1, (address)0xDEADDEAD);        \/\/ Make a recognizable pattern\n+  __ mov(rscratch1, (uint64_t)0xDEADDEAD);        \/\/ Make a recognizable pattern\n@@ -2497,2 +2537,2 @@\n-  __ strd(v0, Address(sp, RegisterSaver::v0_offset_in_bytes()));\n-  __ str(r0, Address(sp, RegisterSaver::r0_offset_in_bytes()));\n+  __ strd(v0, Address(sp, reg_save.v0_offset_in_bytes()));\n+  __ str(r0, Address(sp, reg_save.r0_offset_in_bytes()));\n@@ -2525,2 +2565,2 @@\n-  __ ldrd(v0, Address(sp, RegisterSaver::v0_offset_in_bytes()));\n-  __ ldr(r0, Address(sp, RegisterSaver::r0_offset_in_bytes()));\n+  __ ldrd(v0, Address(sp, reg_save.v0_offset_in_bytes()));\n+  __ ldr(r0, Address(sp, reg_save.r0_offset_in_bytes()));\n@@ -2542,1 +2582,1 @@\n-  if (EnableJVMCI || UseAOT) {\n+  if (EnableJVMCI) {\n@@ -2549,0 +2589,9 @@\n+\/\/ Number of stack slots between incoming argument block and the start of\n+\/\/ a new frame.  The PROLOG must add this many slots to the stack.  The\n+\/\/ EPILOG must remove this many slots. aarch64 needs two slots for\n+\/\/ return address and fp.\n+\/\/ TODO think this is correct but check\n+uint SharedRuntime::in_preserve_stack_slots() {\n+  return 4;\n+}\n+\n@@ -2649,6 +2698,4 @@\n-  if (UseStackBanging) {\n-    __ ldrw(r1, Address(r4,\n-                        Deoptimization::UnrollBlock::\n-                        total_frame_sizes_offset_in_bytes()));\n-    __ bang_stack_size(r1, r2);\n-  }\n+  __ ldrw(r1, Address(r4,\n+                      Deoptimization::UnrollBlock::\n+                      total_frame_sizes_offset_in_bytes()));\n+  __ bang_stack_size(r1, r2);\n@@ -2765,1 +2812,1 @@\n-  bool save_vectors = (poll_type == POLL_AT_VECTOR_LOOP);\n+  RegisterSaver reg_save(poll_type == POLL_AT_VECTOR_LOOP \/* save_vectors *\/);\n@@ -2768,1 +2815,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, save_vectors);\n+  map = reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -2806,1 +2853,0 @@\n-  __ maybe_isb();\n@@ -2814,1 +2860,1 @@\n-  RegisterSaver::restore_live_registers(masm, save_vectors);\n+  reg_save.restore_live_registers(masm);\n@@ -2846,1 +2892,1 @@\n-  RegisterSaver::restore_live_registers(masm, save_vectors);\n+  reg_save.restore_live_registers(masm);\n@@ -2880,0 +2926,1 @@\n+  RegisterSaver reg_save(false \/* save_vectors *\/);\n@@ -2886,1 +2933,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  map = reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -2907,2 +2954,0 @@\n-  __ maybe_isb();\n-\n@@ -2920,1 +2965,1 @@\n-  __ str(rmethod, Address(sp, RegisterSaver::reg_offset_in_bytes(rmethod)));\n+  __ str(rmethod, Address(sp, reg_save.reg_offset_in_bytes(rmethod)));\n@@ -2923,2 +2968,2 @@\n-  __ str(r0, Address(sp, RegisterSaver::rscratch1_offset_in_bytes()));\n-  RegisterSaver::restore_live_registers(masm);\n+  __ str(r0, Address(sp, reg_save.rscratch1_offset_in_bytes()));\n+  reg_save.restore_live_registers(masm);\n@@ -2934,1 +2979,1 @@\n-  RegisterSaver::restore_live_registers(masm);\n+  reg_save.restore_live_registers(masm);\n@@ -3030,1 +3075,5 @@\n-  __ maybe_isb();\n+  \/\/ handle_exception_C is a special VM call which does not require an explicit\n+  \/\/ instruction sync afterwards.\n+\n+  \/\/ May jump to SVE compiled code\n+  __ reinitialize_ptrue();\n@@ -3081,0 +3130,252 @@\n+\n+\/\/ ---------------------------------------------------------------\n+\n+class NativeInvokerGenerator : public StubCodeGenerator {\n+  address _call_target;\n+  int _shadow_space_bytes;\n+\n+  const GrowableArray<VMReg>& _input_registers;\n+  const GrowableArray<VMReg>& _output_registers;\n+\n+  int _frame_complete;\n+  int _framesize;\n+  OopMapSet* _oop_maps;\n+public:\n+  NativeInvokerGenerator(CodeBuffer* buffer,\n+                         address call_target,\n+                         int shadow_space_bytes,\n+                         const GrowableArray<VMReg>& input_registers,\n+                         const GrowableArray<VMReg>& output_registers)\n+   : StubCodeGenerator(buffer, PrintMethodHandleStubs),\n+     _call_target(call_target),\n+     _shadow_space_bytes(shadow_space_bytes),\n+     _input_registers(input_registers),\n+     _output_registers(output_registers),\n+     _frame_complete(0),\n+     _framesize(0),\n+     _oop_maps(NULL) {\n+    assert(_output_registers.length() <= 1\n+           || (_output_registers.length() == 2 && !_output_registers.at(1)->is_valid()), \"no multi-reg returns\");\n+  }\n+\n+  void generate();\n+\n+  int spill_size_in_bytes() const {\n+    if (_output_registers.length() == 0) {\n+      return 0;\n+    }\n+    VMReg reg = _output_registers.at(0);\n+    assert(reg->is_reg(), \"must be a register\");\n+    if (reg->is_Register()) {\n+      return 8;\n+    } else if (reg->is_FloatRegister()) {\n+      bool use_sve = Matcher::supports_scalable_vector();\n+      if (use_sve) {\n+        return Matcher::scalable_vector_reg_size(T_BYTE);\n+      }\n+      return 16;\n+    } else {\n+      ShouldNotReachHere();\n+    }\n+    return 0;\n+  }\n+\n+  void spill_output_registers() {\n+    if (_output_registers.length() == 0) {\n+      return;\n+    }\n+    VMReg reg = _output_registers.at(0);\n+    assert(reg->is_reg(), \"must be a register\");\n+    MacroAssembler* masm = _masm;\n+    if (reg->is_Register()) {\n+      __ spill(reg->as_Register(), true, 0);\n+    } else if (reg->is_FloatRegister()) {\n+      bool use_sve = Matcher::supports_scalable_vector();\n+      if (use_sve) {\n+        __ spill_sve_vector(reg->as_FloatRegister(), 0, Matcher::scalable_vector_reg_size(T_BYTE));\n+      } else {\n+        __ spill(reg->as_FloatRegister(), __ Q, 0);\n+      }\n+    } else {\n+      ShouldNotReachHere();\n+    }\n+  }\n+\n+  void fill_output_registers() {\n+    if (_output_registers.length() == 0) {\n+      return;\n+    }\n+    VMReg reg = _output_registers.at(0);\n+    assert(reg->is_reg(), \"must be a register\");\n+    MacroAssembler* masm = _masm;\n+    if (reg->is_Register()) {\n+      __ unspill(reg->as_Register(), true, 0);\n+    } else if (reg->is_FloatRegister()) {\n+      bool use_sve = Matcher::supports_scalable_vector();\n+      if (use_sve) {\n+        __ unspill_sve_vector(reg->as_FloatRegister(), 0, Matcher::scalable_vector_reg_size(T_BYTE));\n+      } else {\n+        __ unspill(reg->as_FloatRegister(), __ Q, 0);\n+      }\n+    } else {\n+      ShouldNotReachHere();\n+    }\n+  }\n+\n+  int frame_complete() const {\n+    return _frame_complete;\n+  }\n+\n+  int framesize() const {\n+    return (_framesize >> (LogBytesPerWord - LogBytesPerInt));\n+  }\n+\n+  OopMapSet* oop_maps() const {\n+    return _oop_maps;\n+  }\n+\n+private:\n+#ifdef ASSERT\n+  bool target_uses_register(VMReg reg) {\n+    return _input_registers.contains(reg) || _output_registers.contains(reg);\n+  }\n+#endif\n+};\n+\n+static const int native_invoker_code_size = 1024;\n+\n+RuntimeStub* SharedRuntime::make_native_invoker(address call_target,\n+                                                int shadow_space_bytes,\n+                                                const GrowableArray<VMReg>& input_registers,\n+                                                const GrowableArray<VMReg>& output_registers) {\n+  int locs_size  = 64;\n+  CodeBuffer code(\"nep_invoker_blob\", native_invoker_code_size, locs_size);\n+  NativeInvokerGenerator g(&code, call_target, shadow_space_bytes, input_registers, output_registers);\n+  g.generate();\n+  code.log_section_sizes(\"nep_invoker_blob\");\n+\n+  RuntimeStub* stub =\n+    RuntimeStub::new_runtime_stub(\"nep_invoker_blob\",\n+                                  &code,\n+                                  g.frame_complete(),\n+                                  g.framesize(),\n+                                  g.oop_maps(), false);\n+  return stub;\n+}\n+\n+void NativeInvokerGenerator::generate() {\n+  assert(!(target_uses_register(rscratch1->as_VMReg())\n+           || target_uses_register(rscratch2->as_VMReg())\n+           || target_uses_register(rthread->as_VMReg())),\n+         \"Register conflict\");\n+\n+  enum layout {\n+    rbp_off,\n+    rbp_off2,\n+    return_off,\n+    return_off2,\n+    framesize \/\/ inclusive of return address\n+  };\n+\n+  assert(_shadow_space_bytes == 0, \"not expecting shadow space on AArch64\");\n+  _framesize = align_up(framesize + (spill_size_in_bytes() >> LogBytesPerInt), 4);\n+  assert(is_even(_framesize\/2), \"sp not 16-byte aligned\");\n+\n+  _oop_maps  = new OopMapSet();\n+  MacroAssembler* masm = _masm;\n+\n+  address start = __ pc();\n+\n+  __ enter();\n+\n+  \/\/ lr and fp are already in place\n+  __ sub(sp, rfp, ((unsigned)_framesize-4) << LogBytesPerInt); \/\/ prolog\n+\n+  _frame_complete = __ pc() - start;\n+\n+  address the_pc = __ pc();\n+  __ set_last_Java_frame(sp, rfp, the_pc, rscratch1);\n+  OopMap* map = new OopMap(_framesize, 0);\n+  _oop_maps->add_gc_map(the_pc - start, map);\n+\n+  \/\/ State transition\n+  __ mov(rscratch1, _thread_in_native);\n+  __ lea(rscratch2, Address(rthread, JavaThread::thread_state_offset()));\n+  __ stlrw(rscratch1, rscratch2);\n+\n+  rt_call(masm, _call_target);\n+\n+  __ mov(rscratch1, _thread_in_native_trans);\n+  __ strw(rscratch1, Address(rthread, JavaThread::thread_state_offset()));\n+\n+  \/\/ Force this write out before the read below\n+  __ membar(Assembler::LoadLoad | Assembler::LoadStore |\n+            Assembler::StoreLoad | Assembler::StoreStore);\n+\n+  __ verify_sve_vector_length();\n+\n+  Label L_after_safepoint_poll;\n+  Label L_safepoint_poll_slow_path;\n+\n+  __ safepoint_poll(L_safepoint_poll_slow_path, true \/* at_return *\/, true \/* acquire *\/, false \/* in_nmethod *\/);\n+\n+  __ ldrw(rscratch1, Address(rthread, JavaThread::suspend_flags_offset()));\n+  __ cbnzw(rscratch1, L_safepoint_poll_slow_path);\n+\n+  __ bind(L_after_safepoint_poll);\n+\n+  \/\/ change thread state\n+  __ mov(rscratch1, _thread_in_Java);\n+  __ lea(rscratch2, Address(rthread, JavaThread::thread_state_offset()));\n+  __ stlrw(rscratch1, rscratch2);\n+\n+  __ block_comment(\"reguard stack check\");\n+  Label L_reguard;\n+  Label L_after_reguard;\n+  __ ldrb(rscratch1, Address(rthread, JavaThread::stack_guard_state_offset()));\n+  __ cmpw(rscratch1, StackOverflow::stack_guard_yellow_reserved_disabled);\n+  __ br(Assembler::EQ, L_reguard);\n+  __ bind(L_after_reguard);\n+\n+  __ reset_last_Java_frame(true);\n+\n+  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+  __ ret(lr);\n+\n+  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+  __ block_comment(\"{ L_safepoint_poll_slow_path\");\n+  __ bind(L_safepoint_poll_slow_path);\n+\n+  \/\/ Need to save the native result registers around any runtime calls.\n+  spill_output_registers();\n+\n+  __ mov(c_rarg0, rthread);\n+  assert(frame::arg_reg_save_area_bytes == 0, \"not expecting frame reg save area\");\n+  __ lea(rscratch1, RuntimeAddress(CAST_FROM_FN_PTR(address, JavaThread::check_special_condition_for_native_trans)));\n+  __ blr(rscratch1);\n+\n+  fill_output_registers();\n+\n+  __ b(L_after_safepoint_poll);\n+  __ block_comment(\"} L_safepoint_poll_slow_path\");\n+\n+  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+  __ block_comment(\"{ L_reguard\");\n+  __ bind(L_reguard);\n+\n+  spill_output_registers();\n+\n+  rt_call(masm, CAST_FROM_FN_PTR(address, SharedRuntime::reguard_yellow_pages));\n+\n+  fill_output_registers();\n+\n+  __ b(L_after_reguard);\n+\n+  __ block_comment(\"} L_reguard\");\n+\n+  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+  __ flush();\n+}\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":478,"deletions":177,"binary":false,"changes":655,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,0 +29,2 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n+#include \"gc\/shared\/tlab_globals.hpp\"\n@@ -38,0 +40,1 @@\n+#include \"prims\/jvmtiExport.hpp\"\n@@ -47,6 +50,0 @@\n-\/\/ Platform-dependent initialization\n-\n-void TemplateTable::pd_initialize() {\n-  \/\/ No aarch64 specific initialization\n-}\n-\n@@ -267,1 +264,1 @@\n-    __ fmovs(v0, zr);\n+    __ fmovs(v0, 0.0);\n@@ -286,1 +283,1 @@\n-    __ fmovd(v0, zr);\n+    __ fmovd(v0, 0.0);\n@@ -416,0 +413,1 @@\n+    __ resolve_oop_handle(tmp);\n@@ -1821,1 +1819,1 @@\n-  __ mov(r0, (u_int64_t)-1L);\n+  __ mov(r0, (uint64_t)-1L);\n@@ -1845,1 +1843,1 @@\n-    __ mov(r0, (u_int64_t)-1L);\n+    __ mov(r0, (uint64_t)-1L);\n@@ -1917,1 +1915,0 @@\n-  Label profile_method;\n@@ -1944,22 +1941,12 @@\n-    if (TieredCompilation) {\n-      Label no_mdo;\n-      int increment = InvocationCounter::count_increment;\n-      if (ProfileInterpreter) {\n-        \/\/ Are we profiling?\n-        __ ldr(r1, Address(rmethod, in_bytes(Method::method_data_offset())));\n-        __ cbz(r1, no_mdo);\n-        \/\/ Increment the MDO backedge counter\n-        const Address mdo_backedge_counter(r1, in_bytes(MethodData::backedge_counter_offset()) +\n-                                           in_bytes(InvocationCounter::counter_offset()));\n-        const Address mask(r1, in_bytes(MethodData::backedge_mask_offset()));\n-        __ increment_mask_and_jump(mdo_backedge_counter, increment, mask,\n-                                   r0, rscratch1, false, Assembler::EQ,\n-                                   UseOnStackReplacement ? &backedge_counter_overflow : &dispatch);\n-        __ b(dispatch);\n-      }\n-      __ bind(no_mdo);\n-      \/\/ Increment backedge counter in MethodCounters*\n-      __ ldr(rscratch1, Address(rmethod, Method::method_counters_offset()));\n-      const Address mask(rscratch1, in_bytes(MethodCounters::backedge_mask_offset()));\n-      __ increment_mask_and_jump(Address(rscratch1, be_offset), increment, mask,\n-                                 r0, rscratch2, false, Assembler::EQ,\n+    Label no_mdo;\n+    int increment = InvocationCounter::count_increment;\n+    if (ProfileInterpreter) {\n+      \/\/ Are we profiling?\n+      __ ldr(r1, Address(rmethod, in_bytes(Method::method_data_offset())));\n+      __ cbz(r1, no_mdo);\n+      \/\/ Increment the MDO backedge counter\n+      const Address mdo_backedge_counter(r1, in_bytes(MethodData::backedge_counter_offset()) +\n+                                         in_bytes(InvocationCounter::counter_offset()));\n+      const Address mask(r1, in_bytes(MethodData::backedge_mask_offset()));\n+      __ increment_mask_and_jump(mdo_backedge_counter, increment, mask,\n+                                 r0, rscratch1, false, Assembler::EQ,\n@@ -1967,46 +1954,1 @@\n-    } else { \/\/ not TieredCompilation\n-      \/\/ increment counter\n-      __ ldr(rscratch2, Address(rmethod, Method::method_counters_offset()));\n-      __ ldrw(r0, Address(rscratch2, be_offset));        \/\/ load backedge counter\n-      __ addw(rscratch1, r0, InvocationCounter::count_increment); \/\/ increment counter\n-      __ strw(rscratch1, Address(rscratch2, be_offset));        \/\/ store counter\n-\n-      __ ldrw(r0, Address(rscratch2, inv_offset));    \/\/ load invocation counter\n-      __ andw(r0, r0, (unsigned)InvocationCounter::count_mask_value); \/\/ and the status bits\n-      __ addw(r0, r0, rscratch1);        \/\/ add both counters\n-\n-      if (ProfileInterpreter) {\n-        \/\/ Test to see if we should create a method data oop\n-        __ ldrw(rscratch1, Address(rscratch2, in_bytes(MethodCounters::interpreter_profile_limit_offset())));\n-        __ cmpw(r0, rscratch1);\n-        __ br(Assembler::LT, dispatch);\n-\n-        \/\/ if no method data exists, go to profile method\n-        __ test_method_data_pointer(r0, profile_method);\n-\n-        if (UseOnStackReplacement) {\n-          \/\/ check for overflow against w1 which is the MDO taken count\n-          __ ldrw(rscratch1, Address(rscratch2, in_bytes(MethodCounters::interpreter_backward_branch_limit_offset())));\n-          __ cmpw(r1, rscratch1);\n-          __ br(Assembler::LO, dispatch); \/\/ Intel == Assembler::below\n-\n-          \/\/ When ProfileInterpreter is on, the backedge_count comes\n-          \/\/ from the MethodData*, which value does not get reset on\n-          \/\/ the call to frequency_counter_overflow().  To avoid\n-          \/\/ excessive calls to the overflow routine while the method is\n-          \/\/ being compiled, add a second test to make sure the overflow\n-          \/\/ function is called only once every overflow_frequency.\n-          const int overflow_frequency = 1024;\n-          __ andsw(r1, r1, overflow_frequency - 1);\n-          __ br(Assembler::EQ, backedge_counter_overflow);\n-\n-        }\n-      } else {\n-        if (UseOnStackReplacement) {\n-          \/\/ check for overflow against w0, which is the sum of the\n-          \/\/ counters\n-          __ ldrw(rscratch1, Address(rscratch2, in_bytes(MethodCounters::interpreter_backward_branch_limit_offset())));\n-          __ cmpw(r0, rscratch1);\n-          __ br(Assembler::HS, backedge_counter_overflow); \/\/ Intel == Assembler::aboveEqual\n-        }\n-      }\n+      __ b(dispatch);\n@@ -2014,0 +1956,7 @@\n+    __ bind(no_mdo);\n+    \/\/ Increment backedge counter in MethodCounters*\n+    __ ldr(rscratch1, Address(rmethod, Method::method_counters_offset()));\n+    const Address mask(rscratch1, in_bytes(MethodCounters::backedge_mask_offset()));\n+    __ increment_mask_and_jump(Address(rscratch1, be_offset), increment, mask,\n+                               r0, rscratch2, false, Assembler::EQ,\n+                               UseOnStackReplacement ? &backedge_counter_overflow : &dispatch);\n@@ -2025,9 +1974,11 @@\n-  if (UseLoopCounter) {\n-    if (ProfileInterpreter) {\n-      \/\/ Out-of-line code to allocate method data oop.\n-      __ bind(profile_method);\n-      __ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::profile_method));\n-      __ load_unsigned_byte(r1, Address(rbcp, 0));  \/\/ restore target bytecode\n-      __ set_method_data_pointer_for_bcp();\n-      __ b(dispatch);\n-    }\n+  if (UseLoopCounter && UseOnStackReplacement) {\n+    \/\/ invocation counter overflow\n+    __ bind(backedge_counter_overflow);\n+    __ neg(r2, r2);\n+    __ add(r2, r2, rbcp);     \/\/ branch bcp\n+    \/\/ IcoResult frequency_counter_overflow([JavaThread*], address branch_bcp)\n+    __ call_VM(noreg,\n+               CAST_FROM_FN_PTR(address,\n+                                InterpreterRuntime::frequency_counter_overflow),\n+               r2);\n+    __ load_unsigned_byte(r1, Address(rbcp, 0));  \/\/ restore target bytecode\n@@ -2035,46 +1986,33 @@\n-    if (UseOnStackReplacement) {\n-      \/\/ invocation counter overflow\n-      __ bind(backedge_counter_overflow);\n-      __ neg(r2, r2);\n-      __ add(r2, r2, rbcp);     \/\/ branch bcp\n-      \/\/ IcoResult frequency_counter_overflow([JavaThread*], address branch_bcp)\n-      __ call_VM(noreg,\n-                 CAST_FROM_FN_PTR(address,\n-                                  InterpreterRuntime::frequency_counter_overflow),\n-                 r2);\n-      __ load_unsigned_byte(r1, Address(rbcp, 0));  \/\/ restore target bytecode\n-\n-      \/\/ r0: osr nmethod (osr ok) or NULL (osr not possible)\n-      \/\/ w1: target bytecode\n-      \/\/ r2: scratch\n-      __ cbz(r0, dispatch);     \/\/ test result -- no osr if null\n-      \/\/ nmethod may have been invalidated (VM may block upon call_VM return)\n-      __ ldrb(r2, Address(r0, nmethod::state_offset()));\n-      if (nmethod::in_use != 0)\n-        __ sub(r2, r2, nmethod::in_use);\n-      __ cbnz(r2, dispatch);\n-\n-      \/\/ We have the address of an on stack replacement routine in r0\n-      \/\/ We need to prepare to execute the OSR method. First we must\n-      \/\/ migrate the locals and monitors off of the stack.\n-\n-      __ mov(r19, r0);                             \/\/ save the nmethod\n-\n-      call_VM(noreg, CAST_FROM_FN_PTR(address, SharedRuntime::OSR_migration_begin));\n-\n-      \/\/ r0 is OSR buffer, move it to expected parameter location\n-      __ mov(j_rarg0, r0);\n-\n-      \/\/ remove activation\n-      \/\/ get sender esp\n-      __ ldr(esp,\n-          Address(rfp, frame::interpreter_frame_sender_sp_offset * wordSize));\n-      \/\/ remove frame anchor\n-      __ leave();\n-      \/\/ Ensure compiled code always sees stack at proper alignment\n-      __ andr(sp, esp, -16);\n-\n-      \/\/ and begin the OSR nmethod\n-      __ ldr(rscratch1, Address(r19, nmethod::osr_entry_point_offset()));\n-      __ br(rscratch1);\n-    }\n+    \/\/ r0: osr nmethod (osr ok) or NULL (osr not possible)\n+    \/\/ w1: target bytecode\n+    \/\/ r2: scratch\n+    __ cbz(r0, dispatch);     \/\/ test result -- no osr if null\n+    \/\/ nmethod may have been invalidated (VM may block upon call_VM return)\n+    __ ldrb(r2, Address(r0, nmethod::state_offset()));\n+    if (nmethod::in_use != 0)\n+      __ sub(r2, r2, nmethod::in_use);\n+    __ cbnz(r2, dispatch);\n+\n+    \/\/ We have the address of an on stack replacement routine in r0\n+    \/\/ We need to prepare to execute the OSR method. First we must\n+    \/\/ migrate the locals and monitors off of the stack.\n+\n+    __ mov(r19, r0);                             \/\/ save the nmethod\n+\n+    call_VM(noreg, CAST_FROM_FN_PTR(address, SharedRuntime::OSR_migration_begin));\n+\n+    \/\/ r0 is OSR buffer, move it to expected parameter location\n+    __ mov(j_rarg0, r0);\n+\n+    \/\/ remove activation\n+    \/\/ get sender esp\n+    __ ldr(esp,\n+        Address(rfp, frame::interpreter_frame_sender_sp_offset * wordSize));\n+    \/\/ remove frame anchor\n+    __ leave();\n+    \/\/ Ensure compiled code always sees stack at proper alignment\n+    __ andr(sp, esp, -16);\n+\n+    \/\/ and begin the OSR nmethod\n+    __ ldr(rscratch1, Address(r19, nmethod::osr_entry_point_offset()));\n+    __ br(rscratch1);\n@@ -2621,1 +2559,1 @@\n-  if (!is_c1_or_interpreter_only()){\n+  if (!CompilerConfig::is_c1_or_interpreter_only_no_jvmci()){\n@@ -3254,1 +3192,1 @@\n-  if (!is_c1_or_interpreter_only()) {\n+  if (!CompilerConfig::is_c1_or_interpreter_only_no_jvmci()) {\n@@ -3319,1 +3257,1 @@\n-  if (!is_c1_or_interpreter_only()) {\n+  if (!CompilerConfig::is_c1_or_interpreter_only_no_jvmci()) {\n@@ -3364,5 +3302,0 @@\n-void TemplateTable::count_calls(Register method, Register temp)\n-{\n-  __ call_Unimplemented();\n-}\n-\n@@ -3452,1 +3385,1 @@\n-         \"methodOop must be rmethod for interpreter calling convention\");\n+         \"Method must be rmethod for interpreter calling convention\");\n@@ -3475,1 +3408,1 @@\n-  \/\/ get target methodOop & entry point\n+  \/\/ get target Method & entry point\n@@ -3610,1 +3543,1 @@\n-  \/\/ rmethod,: methodOop to call\n+  \/\/ rmethod,: Method to call\n@@ -3622,1 +3555,1 @@\n-  \/\/ rmethod,: methodOop\n+  \/\/ rmethod,: Method\n@@ -4026,2 +3959,0 @@\n-  __ resolve(IS_NOT_NULL, r0);\n-\n@@ -4127,2 +4058,0 @@\n-  __ resolve(IS_NOT_NULL, r0);\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":80,"deletions":151,"binary":false,"changes":231,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,0 +26,1 @@\n+#include \"compiler\/compiler_globals.hpp\"\n@@ -155,1 +156,1 @@\n-        shll(tmp, exact_log2(DataLayout::cell_size));\n+        shll(tmp, log2i_exact((int)DataLayout::cell_size));\n@@ -193,1 +194,1 @@\n-      cmpw(Address(tmp, Method::intrinsic_id_offset_in_bytes()), vmIntrinsics::_compiledLambdaForm);\n+      cmpw(Address(tmp, Method::intrinsic_id_offset_in_bytes()), static_cast<int>(vmIntrinsics::_compiledLambdaForm));\n@@ -608,0 +609,4 @@\n+void InterpreterMacroAssembler::push_i_or_ptr(Register r) {\n+  push(r);\n+}\n+\n@@ -856,1 +861,1 @@\n-    testb(Address(r15_thread, Thread::polling_page_offset()), SafepointMechanism::poll_bit());\n+    testb(Address(r15_thread, JavaThread::polling_word_offset()), SafepointMechanism::poll_bit());\n@@ -875,1 +880,1 @@\n-    testb(Address(thread, Thread::polling_page_offset()), SafepointMechanism::poll_bit());\n+    testb(Address(thread, JavaThread::polling_word_offset()), SafepointMechanism::poll_bit());\n@@ -964,0 +969,1 @@\n+\/\/ Apply stack watermark barrier.\n@@ -990,1 +996,17 @@\n-  NOT_LP64(get_thread(rcx);)\n+  NOT_LP64(get_thread(rthread);)\n+\n+  \/\/ The below poll is for the stack watermark barrier. It allows fixing up frames lazily,\n+  \/\/ that would normally not be safe to use. Such bad returns into unsafe territory of\n+  \/\/ the stack, will call InterpreterRuntime::at_unwind.\n+  Label slow_path;\n+  Label fast_path;\n+  safepoint_poll(slow_path, rthread, true \/* at_return *\/, false \/* in_nmethod *\/);\n+  jmp(fast_path);\n+  bind(slow_path);\n+  push(state);\n+  set_last_Java_frame(rthread, noreg, rbp, (address)pc());\n+  super_call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::at_unwind), rthread);\n+  NOT_LP64(get_thread(rthread);) \/\/ call_VM clobbered it, restore\n+  reset_last_Java_frame(rthread, true);\n+  pop(state);\n+  bind(fast_path);\n@@ -1133,1 +1155,1 @@\n-    cmpl(Address(rthread, JavaThread::stack_guard_state_offset()), JavaThread::stack_guard_enabled);\n+    cmpl(Address(rthread, JavaThread::stack_guard_state_offset()), StackOverflow::stack_guard_enabled);\n@@ -1190,0 +1212,1 @@\n+    const Register rklass_decode_tmp = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n@@ -1201,0 +1224,7 @@\n+    if (DiagnoseSyncOnValueBasedClasses != 0) {\n+      load_klass(tmp_reg, obj_reg, rklass_decode_tmp);\n+      movl(tmp_reg, Address(tmp_reg, Klass::access_flags_offset()));\n+      testl(tmp_reg, JVM_ACC_IS_VALUE_BASED_CLASS);\n+      jcc(Assembler::notZero, slow_case);\n+    }\n+\n@@ -1202,1 +1232,0 @@\n-      Register rklass_decode_tmp = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n@@ -1228,1 +1257,7 @@\n-    \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n+    \/\/ Fast check for recursive lock.\n+    \/\/\n+    \/\/ Can apply the optimization only if this is a stack lock\n+    \/\/ allocated in this thread. For efficiency, we can focus on\n+    \/\/ recently allocated stack locks (instead of reading the stack\n+    \/\/ base and checking whether 'mark' points inside the current\n+    \/\/ thread stack):\n@@ -1232,0 +1267,12 @@\n+    \/\/ Warning: rsp + os::pagesize can overflow the stack base. We must\n+    \/\/ neither apply the optimization for an inflated lock allocated\n+    \/\/ just above the thread stack (this is why condition 1 matters)\n+    \/\/ nor apply the optimization if the stack lock is inside the stack\n+    \/\/ of another thread. The latter is avoided even in case of overflow\n+    \/\/ because we have guard pages at the end of all stacks. Hence, if\n+    \/\/ we go over the stack base and hit the stack of another thread,\n+    \/\/ this should not be in a writeable area that could contain a\n+    \/\/ stack lock allocated by that thread. As a consequence, a stack\n+    \/\/ lock less than page size away from rsp is guaranteed to be\n+    \/\/ owned by the current thread.\n+    \/\/\n@@ -1236,1 +1283,1 @@\n-    \/\/ NOTE: the oopMark is in swap_reg %rax as the result of cmpxchg\n+    \/\/ NOTE: the mark is in swap_reg %rax as the result of cmpxchg\n@@ -1295,3 +1342,1 @@\n-    call_VM(noreg,\n-            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit),\n-            lock_reg);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n@@ -1338,0 +1383,1 @@\n+\n@@ -1339,5 +1385,2 @@\n-    movptr(Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()),\n-         obj_reg); \/\/ restore obj\n-    call_VM(noreg,\n-            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit),\n-            lock_reg);\n+    movptr(Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()), obj_reg); \/\/ restore obj\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n@@ -1956,1 +1999,1 @@\n-    MacroAssembler::_verify_oop(reg, \"broken oop\", file, line);\n+    MacroAssembler::_verify_oop_checked(reg, \"broken oop\", file, line);\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":62,"deletions":19,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -35,0 +35,1 @@\n+#include \"compiler\/oopMap.hpp\"\n@@ -45,0 +46,2 @@\n+#include \"prims\/methodHandles.hpp\"\n+#include \"runtime\/jniHandles.hpp\"\n@@ -47,0 +50,2 @@\n+#include \"runtime\/signature.hpp\"\n+#include \"runtime\/stubRoutines.hpp\"\n@@ -89,0 +94,1 @@\n+#define XSAVE_AREA_OPMASK_BEGIN 1088\n@@ -91,3 +97,5 @@\n-#define DEF_XMM_OFFS(regnum) xmm ## regnum ## _off = xmm_off + (regnum)*16\/BytesPerInt, xmm ## regnum ## H_off\n-#define DEF_YMM_OFFS(regnum) ymm ## regnum ## _off = ymm_off + (regnum)*16\/BytesPerInt, ymm ## regnum ## H_off\n-#define DEF_ZMM_OFFS(regnum) zmm ## regnum ## _off = zmm_off + (regnum-16)*64\/BytesPerInt, zmm ## regnum ## H_off\n+#define DEF_XMM_OFFS(regnum)       xmm ## regnum ## _off = xmm_off + (regnum)*16\/BytesPerInt, xmm ## regnum ## H_off\n+#define DEF_YMM_OFFS(regnum)       ymm ## regnum ## _off = ymm_off + (regnum)*16\/BytesPerInt, ymm ## regnum ## H_off\n+#define DEF_ZMM_OFFS(regnum)       zmm ## regnum ## _off = zmm_off + (regnum)*32\/BytesPerInt, zmm ## regnum ## H_off\n+#define DEF_OPMASK_OFFS(regnum)    opmask ## regnum ## _off = opmask_off + (regnum)*8\/BytesPerInt,     opmask ## regnum ## H_off\n+#define DEF_ZMM_UPPER_OFFS(regnum) zmm ## regnum ## _off = zmm_upper_off + (regnum-16)*64\/BytesPerInt, zmm ## regnum ## H_off\n@@ -104,4 +112,10 @@\n-    zmm_high = xmm_off + (XSAVE_AREA_ZMM_BEGIN - XSAVE_AREA_BEGIN)\/BytesPerInt,\n-    zmm_off = xmm_off + (XSAVE_AREA_UPPERBANK - XSAVE_AREA_BEGIN)\/BytesPerInt,\n-    DEF_ZMM_OFFS(16),\n-    DEF_ZMM_OFFS(17),\n+    opmask_off         = xmm_off + (XSAVE_AREA_OPMASK_BEGIN - XSAVE_AREA_BEGIN)\/BytesPerInt,\n+    DEF_OPMASK_OFFS(0),\n+    DEF_OPMASK_OFFS(1),\n+    \/\/ 2..7 are implied in range usage\n+    zmm_off = xmm_off + (XSAVE_AREA_ZMM_BEGIN - XSAVE_AREA_BEGIN)\/BytesPerInt,\n+    DEF_ZMM_OFFS(0),\n+    DEF_ZMM_OFFS(1),\n+    zmm_upper_off = xmm_off + (XSAVE_AREA_UPPERBANK - XSAVE_AREA_BEGIN)\/BytesPerInt,\n+    DEF_ZMM_UPPER_OFFS(16),\n+    DEF_ZMM_UPPER_OFFS(17),\n@@ -139,1 +153,1 @@\n-  static OopMap* save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words, bool save_vectors = false);\n+  static OopMap* save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words, bool save_vectors);\n@@ -164,3 +178,2 @@\n-  if (save_vectors) {\n-    assert(UseAVX > 0, \"Vectors larger than 16 byte long are supported only with AVX\");\n-    assert(MaxVectorSize <= 64, \"Only up to 64 byte long vectors are supported\");\n+  if (save_vectors && UseAVX == 0) {\n+    save_vectors = false; \/\/ vectors larger than 16 byte long are supported only with AVX\n@@ -168,0 +181,1 @@\n+  assert(!save_vectors || MaxVectorSize <= 64, \"Only up to 64 byte long vectors are supported\");\n@@ -169,1 +183,1 @@\n-  assert(!save_vectors, \"vectors are generated only by C2 and JVMCI\");\n+  save_vectors = false; \/\/ vectors are generated only by C2 and JVMCI\n@@ -209,0 +223,7 @@\n+#if COMPILER2_OR_JVMCI\n+      base_addr = XSAVE_AREA_OPMASK_BEGIN;\n+      off = 0;\n+      for(int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+        __ kmov(Address(rsp, base_addr+(off++*8)), as_KRegister(n));\n+      }\n+#endif\n@@ -218,0 +239,7 @@\n+#if COMPILER2_OR_JVMCI\n+      base_addr = XSAVE_AREA_OPMASK_BEGIN;\n+      off = 0;\n+      for(int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+        __ kmov(Address(rsp, base_addr+(off++*8)), as_KRegister(n));\n+      }\n+#endif\n@@ -261,1 +289,1 @@\n-  if(UseAVX > 2) {\n+  if (UseAVX > 2) {\n@@ -274,0 +302,1 @@\n+    \/\/ Save upper half of YMM registers(0..15)\n@@ -275,1 +304,1 @@\n-    int delta = ymm1_off - off;\n+    delta = ymm1_off - ymm0_off;\n@@ -281,0 +310,10 @@\n+    if (VM_Version::supports_evex()) {\n+      \/\/ Save upper half of ZMM registers(0..15)\n+      off = zmm0_off;\n+      delta = zmm1_off - zmm0_off;\n+      for (int n = 0; n < 16; n++) {\n+        XMMRegister zmm_name = as_XMMRegister(n);\n+        map->set_callee_saved(STACK_OFFSET(off), zmm_name->as_VMReg()->next(8));\n+        off += delta;\n+      }\n+    }\n@@ -366,0 +405,7 @@\n+#if COMPILER2_OR_JVMCI\n+      base_addr = XSAVE_AREA_OPMASK_BEGIN;\n+      off = 0;\n+      for (int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+        __ kmov(as_KRegister(n), Address(rsp, base_addr+(off++*8)));\n+      }\n+#endif\n@@ -375,0 +421,7 @@\n+#if COMPILER2_OR_JVMCI\n+      base_addr = XSAVE_AREA_OPMASK_BEGIN;\n+      off = 0;\n+      for (int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+        __ kmov(as_KRegister(n), Address(rsp, base_addr+(off++*8)));\n+      }\n+#endif\n@@ -408,22 +461,0 @@\n-size_t SharedRuntime::trampoline_size() {\n-  return 16;\n-}\n-\n-void SharedRuntime::generate_trampoline(MacroAssembler *masm, address destination) {\n-  __ jump(RuntimeAddress(destination));\n-}\n-\n-\/\/ The java_calling_convention describes stack locations as ideal slots on\n-\/\/ a frame with no abi restrictions. Since we must observe abi restrictions\n-\/\/ (like the placement of the register window) the slots must be biased by\n-\/\/ the following value.\n-static int reg2offset_in(VMReg r) {\n-  \/\/ Account for saved rbp and return address\n-  \/\/ This should really be in_preserve_stack_slots\n-  return (r->reg2stack() + 4) * VMRegImpl::stack_slot_size;\n-}\n-\n-static int reg2offset_out(VMReg r) {\n-  return (r->reg2stack() + SharedRuntime::out_preserve_stack_slots()) * VMRegImpl::stack_slot_size;\n-}\n-\n@@ -453,2 +484,1 @@\n-                                           int total_args_passed,\n-                                           int is_outgoing) {\n+                                           int total_args_passed) {\n@@ -818,1 +848,1 @@\n-  if (EnableJVMCI || UseAOT) {\n+  if (EnableJVMCI) {\n@@ -1122,153 +1152,12 @@\n-\/\/ On 64 bit we will store integer like items to the stack as\n-\/\/ 64 bits items (sparc abi) even though java would only store\n-\/\/ 32bits for a parameter. On 32bit it will simply be 32 bits\n-\/\/ So this routine will do 32->32 on 32bit and 32->64 on 64bit\n-static void move32_64(MacroAssembler* masm, VMRegPair src, VMRegPair dst) {\n-  if (src.first()->is_stack()) {\n-    if (dst.first()->is_stack()) {\n-      \/\/ stack to stack\n-      __ movslq(rax, Address(rbp, reg2offset_in(src.first())));\n-      __ movq(Address(rsp, reg2offset_out(dst.first())), rax);\n-    } else {\n-      \/\/ stack to reg\n-      __ movslq(dst.first()->as_Register(), Address(rbp, reg2offset_in(src.first())));\n-    }\n-  } else if (dst.first()->is_stack()) {\n-    \/\/ reg to stack\n-    \/\/ Do we really have to sign extend???\n-    \/\/ __ movslq(src.first()->as_Register(), src.first()->as_Register());\n-    __ movq(Address(rsp, reg2offset_out(dst.first())), src.first()->as_Register());\n-  } else {\n-    \/\/ Do we really have to sign extend???\n-    \/\/ __ movslq(dst.first()->as_Register(), src.first()->as_Register());\n-    if (dst.first() != src.first()) {\n-      __ movq(dst.first()->as_Register(), src.first()->as_Register());\n-    }\n-  }\n-}\n-\n-static void move_ptr(MacroAssembler* masm, VMRegPair src, VMRegPair dst) {\n-  if (src.first()->is_stack()) {\n-    if (dst.first()->is_stack()) {\n-      \/\/ stack to stack\n-      __ movq(rax, Address(rbp, reg2offset_in(src.first())));\n-      __ movq(Address(rsp, reg2offset_out(dst.first())), rax);\n-    } else {\n-      \/\/ stack to reg\n-      __ movq(dst.first()->as_Register(), Address(rbp, reg2offset_in(src.first())));\n-    }\n-  } else if (dst.first()->is_stack()) {\n-    \/\/ reg to stack\n-    __ movq(Address(rsp, reg2offset_out(dst.first())), src.first()->as_Register());\n-  } else {\n-    if (dst.first() != src.first()) {\n-      __ movq(dst.first()->as_Register(), src.first()->as_Register());\n-    }\n-  }\n-}\n-\n-\/\/ An oop arg. Must pass a handle not the oop itself\n-static void object_move(MacroAssembler* masm,\n-                        OopMap* map,\n-                        int oop_handle_offset,\n-                        int framesize_in_slots,\n-                        VMRegPair src,\n-                        VMRegPair dst,\n-                        bool is_receiver,\n-                        int* receiver_offset) {\n-\n-  \/\/ must pass a handle. First figure out the location we use as a handle\n-\n-  Register rHandle = dst.first()->is_stack() ? rax : dst.first()->as_Register();\n-\n-  \/\/ See if oop is NULL if it is we need no handle\n-\n-  if (src.first()->is_stack()) {\n-\n-    \/\/ Oop is already on the stack as an argument\n-    int offset_in_older_frame = src.first()->reg2stack() + SharedRuntime::out_preserve_stack_slots();\n-    map->set_oop(VMRegImpl::stack2reg(offset_in_older_frame + framesize_in_slots));\n-    if (is_receiver) {\n-      *receiver_offset = (offset_in_older_frame + framesize_in_slots) * VMRegImpl::stack_slot_size;\n-    }\n-\n-    __ cmpptr(Address(rbp, reg2offset_in(src.first())), (int32_t)NULL_WORD);\n-    __ lea(rHandle, Address(rbp, reg2offset_in(src.first())));\n-    \/\/ conditionally move a NULL\n-    __ cmovptr(Assembler::equal, rHandle, Address(rbp, reg2offset_in(src.first())));\n-  } else {\n-\n-    \/\/ Oop is in an a register we must store it to the space we reserve\n-    \/\/ on the stack for oop_handles and pass a handle if oop is non-NULL\n-\n-    const Register rOop = src.first()->as_Register();\n-    int oop_slot;\n-    if (rOop == j_rarg0)\n-      oop_slot = 0;\n-    else if (rOop == j_rarg1)\n-      oop_slot = 1;\n-    else if (rOop == j_rarg2)\n-      oop_slot = 2;\n-    else if (rOop == j_rarg3)\n-      oop_slot = 3;\n-    else if (rOop == j_rarg4)\n-      oop_slot = 4;\n-    else {\n-      assert(rOop == j_rarg5, \"wrong register\");\n-      oop_slot = 5;\n-    }\n-\n-    oop_slot = oop_slot * VMRegImpl::slots_per_word + oop_handle_offset;\n-    int offset = oop_slot*VMRegImpl::stack_slot_size;\n-\n-    map->set_oop(VMRegImpl::stack2reg(oop_slot));\n-    \/\/ Store oop in handle area, may be NULL\n-    __ movptr(Address(rsp, offset), rOop);\n-    if (is_receiver) {\n-      *receiver_offset = offset;\n-    }\n-\n-    __ cmpptr(rOop, (int32_t)NULL_WORD);\n-    __ lea(rHandle, Address(rsp, offset));\n-    \/\/ conditionally move a NULL from the handle area where it was just stored\n-    __ cmovptr(Assembler::equal, rHandle, Address(rsp, offset));\n-  }\n-\n-  \/\/ If arg is on the stack then place it otherwise it is already in correct reg.\n-  if (dst.first()->is_stack()) {\n-    __ movptr(Address(rsp, reg2offset_out(dst.first())), rHandle);\n-  }\n-}\n-\n-\/\/ A float arg may have to do float reg int reg conversion\n-static void float_move(MacroAssembler* masm, VMRegPair src, VMRegPair dst) {\n-  assert(!src.second()->is_valid() && !dst.second()->is_valid(), \"bad float_move\");\n-\n-  \/\/ The calling conventions assures us that each VMregpair is either\n-  \/\/ all really one physical register or adjacent stack slots.\n-  \/\/ This greatly simplifies the cases here compared to sparc.\n-\n-  if (src.first()->is_stack()) {\n-    if (dst.first()->is_stack()) {\n-      __ movl(rax, Address(rbp, reg2offset_in(src.first())));\n-      __ movptr(Address(rsp, reg2offset_out(dst.first())), rax);\n-    } else {\n-      \/\/ stack to reg\n-      assert(dst.first()->is_XMMRegister(), \"only expect xmm registers as parameters\");\n-      __ movflt(dst.first()->as_XMMRegister(), Address(rbp, reg2offset_in(src.first())));\n-    }\n-  } else if (dst.first()->is_stack()) {\n-    \/\/ reg to stack\n-    assert(src.first()->is_XMMRegister(), \"only expect xmm registers as parameters\");\n-    __ movflt(Address(rsp, reg2offset_out(dst.first())), src.first()->as_XMMRegister());\n-  } else {\n-    \/\/ reg to reg\n-    \/\/ In theory these overlap but the ordering is such that this is likely a nop\n-    if ( src.first() != dst.first()) {\n-      __ movdbl(dst.first()->as_XMMRegister(),  src.first()->as_XMMRegister());\n-    }\n-  }\n-}\n-\n-\/\/ A long move\n-static void long_move(MacroAssembler* masm, VMRegPair src, VMRegPair dst) {\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  assert(num_bits == 64 || num_bits == 128 || num_bits == 256 || num_bits == 512,\n+         \"only certain vector sizes are supported for now\");\n+\n+  static const XMMRegister VEC_ArgReg[32] = {\n+     xmm0,  xmm1,  xmm2,  xmm3,  xmm4,  xmm5,  xmm6,  xmm7,\n+     xmm8,  xmm9, xmm10, xmm11, xmm12, xmm13, xmm14, xmm15,\n+    xmm16, xmm17, xmm18, xmm19, xmm20, xmm21, xmm22, xmm23,\n+    xmm24, xmm25, xmm26, xmm27, xmm28, xmm29, xmm30, xmm31\n+  };\n@@ -1276,3 +1165,2 @@\n-  \/\/ The calling conventions assures us that each VMregpair is either\n-  \/\/ all really one physical register or adjacent stack slots.\n-  \/\/ This greatly simplifies the cases here compared to sparc.\n+  uint stk_args = 0;\n+  uint fp_args = 0;\n@@ -1280,16 +1168,4 @@\n-  if (src.is_single_phys_reg() ) {\n-    if (dst.is_single_phys_reg()) {\n-      if (dst.first() != src.first()) {\n-        __ mov(dst.first()->as_Register(), src.first()->as_Register());\n-      }\n-    } else {\n-      assert(dst.is_single_reg(), \"not a stack pair\");\n-      __ movq(Address(rsp, reg2offset_out(dst.first())), src.first()->as_Register());\n-    }\n-  } else if (dst.is_single_phys_reg()) {\n-    assert(src.is_single_reg(),  \"not a stack pair\");\n-    __ movq(dst.first()->as_Register(), Address(rbp, reg2offset_out(src.first())));\n-  } else {\n-    assert(src.is_single_reg() && dst.is_single_reg(), \"not stack pairs\");\n-    __ movq(rax, Address(rbp, reg2offset_in(src.first())));\n-    __ movq(Address(rsp, reg2offset_out(dst.first())), rax);\n+  for (uint i = 0; i < total_args_passed; i++) {\n+    VMReg vmreg = VEC_ArgReg[fp_args++]->as_VMReg();\n+    int next_val = num_bits == 64 ? 1 : (num_bits == 128 ? 3 : (num_bits  == 256 ? 7 : 15));\n+    regs[i].set_pair(vmreg->next(next_val), vmreg);\n@@ -1297,26 +1173,1 @@\n-}\n-\n-\/\/ A double move\n-static void double_move(MacroAssembler* masm, VMRegPair src, VMRegPair dst) {\n-\n-  \/\/ The calling conventions assures us that each VMregpair is either\n-  \/\/ all really one physical register or adjacent stack slots.\n-  \/\/ This greatly simplifies the cases here compared to sparc.\n-  if (src.is_single_phys_reg() ) {\n-    if (dst.is_single_phys_reg()) {\n-      \/\/ In theory these overlap but the ordering is such that this is likely a nop\n-      if ( src.first() != dst.first()) {\n-        __ movdbl(dst.first()->as_XMMRegister(), src.first()->as_XMMRegister());\n-      }\n-    } else {\n-      assert(dst.is_single_reg(), \"not a stack pair\");\n-      __ movdbl(Address(rsp, reg2offset_out(dst.first())), src.first()->as_XMMRegister());\n-    }\n-  } else if (dst.is_single_phys_reg()) {\n-    assert(src.is_single_reg(),  \"not a stack pair\");\n-    __ movdbl(dst.first()->as_XMMRegister(), Address(rbp, reg2offset_out(src.first())));\n-  } else {\n-    assert(src.is_single_reg() && dst.is_single_reg(), \"not stack pairs\");\n-    __ movq(rax, Address(rbp, reg2offset_in(src.first())));\n-    __ movq(Address(rsp, reg2offset_out(dst.first())), rax);\n-  }\n+  return stk_args;\n@@ -1326,1 +1177,0 @@\n-\n@@ -1383,216 +1233,0 @@\n-\n-static void save_or_restore_arguments(MacroAssembler* masm,\n-                                      const int stack_slots,\n-                                      const int total_in_args,\n-                                      const int arg_save_area,\n-                                      OopMap* map,\n-                                      VMRegPair* in_regs,\n-                                      BasicType* in_sig_bt) {\n-  \/\/ if map is non-NULL then the code should store the values,\n-  \/\/ otherwise it should load them.\n-  int slot = arg_save_area;\n-  \/\/ Save down double word first\n-  for ( int i = 0; i < total_in_args; i++) {\n-    if (in_regs[i].first()->is_XMMRegister() && in_sig_bt[i] == T_DOUBLE) {\n-      int offset = slot * VMRegImpl::stack_slot_size;\n-      slot += VMRegImpl::slots_per_word;\n-      assert(slot <= stack_slots, \"overflow\");\n-      if (map != NULL) {\n-        __ movdbl(Address(rsp, offset), in_regs[i].first()->as_XMMRegister());\n-      } else {\n-        __ movdbl(in_regs[i].first()->as_XMMRegister(), Address(rsp, offset));\n-      }\n-    }\n-    if (in_regs[i].first()->is_Register() &&\n-        (in_sig_bt[i] == T_LONG || in_sig_bt[i] == T_ARRAY)) {\n-      int offset = slot * VMRegImpl::stack_slot_size;\n-      if (map != NULL) {\n-        __ movq(Address(rsp, offset), in_regs[i].first()->as_Register());\n-        if (in_sig_bt[i] == T_ARRAY) {\n-          map->set_oop(VMRegImpl::stack2reg(slot));;\n-        }\n-      } else {\n-        __ movq(in_regs[i].first()->as_Register(), Address(rsp, offset));\n-      }\n-      slot += VMRegImpl::slots_per_word;\n-    }\n-  }\n-  \/\/ Save or restore single word registers\n-  for ( int i = 0; i < total_in_args; i++) {\n-    if (in_regs[i].first()->is_Register()) {\n-      int offset = slot * VMRegImpl::stack_slot_size;\n-      slot++;\n-      assert(slot <= stack_slots, \"overflow\");\n-\n-      \/\/ Value is in an input register pass we must flush it to the stack\n-      const Register reg = in_regs[i].first()->as_Register();\n-      switch (in_sig_bt[i]) {\n-        case T_BOOLEAN:\n-        case T_CHAR:\n-        case T_BYTE:\n-        case T_SHORT:\n-        case T_INT:\n-          if (map != NULL) {\n-            __ movl(Address(rsp, offset), reg);\n-          } else {\n-            __ movl(reg, Address(rsp, offset));\n-          }\n-          break;\n-        case T_ARRAY:\n-        case T_LONG:\n-          \/\/ handled above\n-          break;\n-        case T_OBJECT:\n-        default: ShouldNotReachHere();\n-      }\n-    } else if (in_regs[i].first()->is_XMMRegister()) {\n-      if (in_sig_bt[i] == T_FLOAT) {\n-        int offset = slot * VMRegImpl::stack_slot_size;\n-        slot++;\n-        assert(slot <= stack_slots, \"overflow\");\n-        if (map != NULL) {\n-          __ movflt(Address(rsp, offset), in_regs[i].first()->as_XMMRegister());\n-        } else {\n-          __ movflt(in_regs[i].first()->as_XMMRegister(), Address(rsp, offset));\n-        }\n-      }\n-    } else if (in_regs[i].first()->is_stack()) {\n-      if (in_sig_bt[i] == T_ARRAY && map != NULL) {\n-        int offset_in_older_frame = in_regs[i].first()->reg2stack() + SharedRuntime::out_preserve_stack_slots();\n-        map->set_oop(VMRegImpl::stack2reg(offset_in_older_frame + stack_slots));\n-      }\n-    }\n-  }\n-}\n-\n-\/\/ Pin object, return pinned object or null in rax\n-static void gen_pin_object(MacroAssembler* masm,\n-                           VMRegPair reg) {\n-  __ block_comment(\"gen_pin_object {\");\n-\n-  \/\/ rax always contains oop, either incoming or\n-  \/\/ pinned.\n-  Register tmp_reg = rax;\n-\n-  Label is_null;\n-  VMRegPair tmp;\n-  VMRegPair in_reg = reg;\n-\n-  tmp.set_ptr(tmp_reg->as_VMReg());\n-  if (reg.first()->is_stack()) {\n-    \/\/ Load the arg up from the stack\n-    move_ptr(masm, reg, tmp);\n-    reg = tmp;\n-  } else {\n-    __ movptr(rax, reg.first()->as_Register());\n-  }\n-  __ testptr(reg.first()->as_Register(), reg.first()->as_Register());\n-  __ jccb(Assembler::equal, is_null);\n-\n-  if (reg.first()->as_Register() != c_rarg1) {\n-    __ movptr(c_rarg1, reg.first()->as_Register());\n-  }\n-\n-  __ call_VM_leaf(\n-    CAST_FROM_FN_PTR(address, SharedRuntime::pin_object),\n-    r15_thread, c_rarg1);\n-\n-  __ bind(is_null);\n-  __ block_comment(\"} gen_pin_object\");\n-}\n-\n-\/\/ Unpin object\n-static void gen_unpin_object(MacroAssembler* masm,\n-                             VMRegPair reg) {\n-  __ block_comment(\"gen_unpin_object {\");\n-  Label is_null;\n-\n-  if (reg.first()->is_stack()) {\n-    __ movptr(c_rarg1, Address(rbp, reg2offset_in(reg.first())));\n-  } else if (reg.first()->as_Register() != c_rarg1) {\n-    __ movptr(c_rarg1, reg.first()->as_Register());\n-  }\n-\n-  __ testptr(c_rarg1, c_rarg1);\n-  __ jccb(Assembler::equal, is_null);\n-\n-  __ call_VM_leaf(\n-    CAST_FROM_FN_PTR(address, SharedRuntime::unpin_object),\n-    r15_thread, c_rarg1);\n-\n-  __ bind(is_null);\n-  __ block_comment(\"} gen_unpin_object\");\n-}\n-\n-\/\/ Check GCLocker::needs_gc and enter the runtime if it's true.  This\n-\/\/ keeps a new JNI critical region from starting until a GC has been\n-\/\/ forced.  Save down any oops in registers and describe them in an\n-\/\/ OopMap.\n-static void check_needs_gc_for_critical_native(MacroAssembler* masm,\n-                                               int stack_slots,\n-                                               int total_c_args,\n-                                               int total_in_args,\n-                                               int arg_save_area,\n-                                               OopMapSet* oop_maps,\n-                                               VMRegPair* in_regs,\n-                                               BasicType* in_sig_bt) {\n-  __ block_comment(\"check GCLocker::needs_gc\");\n-  Label cont;\n-  __ cmp8(ExternalAddress((address)GCLocker::needs_gc_address()), false);\n-  __ jcc(Assembler::equal, cont);\n-\n-  \/\/ Save down any incoming oops and call into the runtime to halt for a GC\n-\n-  OopMap* map = new OopMap(stack_slots * 2, 0 \/* arg_slots*\/);\n-  save_or_restore_arguments(masm, stack_slots, total_in_args,\n-                            arg_save_area, map, in_regs, in_sig_bt);\n-\n-  address the_pc = __ pc();\n-  oop_maps->add_gc_map( __ offset(), map);\n-  __ set_last_Java_frame(rsp, noreg, the_pc);\n-\n-  __ block_comment(\"block_for_jni_critical\");\n-  __ movptr(c_rarg0, r15_thread);\n-  __ mov(r12, rsp); \/\/ remember sp\n-  __ subptr(rsp, frame::arg_reg_save_area_bytes); \/\/ windows\n-  __ andptr(rsp, -16); \/\/ align stack as required by ABI\n-  __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::block_for_jni_critical)));\n-  __ mov(rsp, r12); \/\/ restore sp\n-  __ reinit_heapbase();\n-\n-  __ reset_last_Java_frame(false);\n-\n-  save_or_restore_arguments(masm, stack_slots, total_in_args,\n-                            arg_save_area, NULL, in_regs, in_sig_bt);\n-  __ bind(cont);\n-#ifdef ASSERT\n-  if (StressCriticalJNINatives) {\n-    \/\/ Stress register saving\n-    OopMap* map = new OopMap(stack_slots * 2, 0 \/* arg_slots*\/);\n-    save_or_restore_arguments(masm, stack_slots, total_in_args,\n-                              arg_save_area, map, in_regs, in_sig_bt);\n-    \/\/ Destroy argument registers\n-    for (int i = 0; i < total_in_args - 1; i++) {\n-      if (in_regs[i].first()->is_Register()) {\n-        const Register reg = in_regs[i].first()->as_Register();\n-        __ xorptr(reg, reg);\n-      } else if (in_regs[i].first()->is_XMMRegister()) {\n-        __ xorpd(in_regs[i].first()->as_XMMRegister(), in_regs[i].first()->as_XMMRegister());\n-      } else if (in_regs[i].first()->is_FloatRegister()) {\n-        ShouldNotReachHere();\n-      } else if (in_regs[i].first()->is_stack()) {\n-        \/\/ Nothing to do\n-      } else {\n-        ShouldNotReachHere();\n-      }\n-      if (in_sig_bt[i] == T_LONG || in_sig_bt[i] == T_DOUBLE) {\n-        i++;\n-      }\n-    }\n-\n-    save_or_restore_arguments(masm, stack_slots, total_in_args,\n-                              arg_save_area, NULL, in_regs, in_sig_bt);\n-  }\n-#endif\n-}\n-\n@@ -1616,1 +1250,1 @@\n-    move_ptr(masm, reg, tmp);\n+    __ move_ptr(reg, tmp);\n@@ -1622,1 +1256,1 @@\n-  move_ptr(masm, tmp, body_arg);\n+  __ move_ptr(tmp, body_arg);\n@@ -1626,1 +1260,1 @@\n-  move32_64(masm, tmp, length_arg);\n+  __ move32_64(tmp, length_arg);\n@@ -1631,2 +1265,2 @@\n-  move_ptr(masm, tmp, body_arg);\n-  move32_64(masm, tmp, length_arg);\n+  __ move_ptr(tmp, body_arg);\n+  __ move32_64(tmp, length_arg);\n@@ -1719,2 +1353,2 @@\n-  ComputeMoveOrder(int total_in_args, VMRegPair* in_regs, int total_c_args, VMRegPair* out_regs,\n-                    BasicType* in_sig_bt, GrowableArray<int>& arg_order, VMRegPair tmp_vmreg) {\n+  ComputeMoveOrder(int total_in_args, const VMRegPair* in_regs, int total_c_args, VMRegPair* out_regs,\n+                  const BasicType* in_sig_bt, GrowableArray<int>& arg_order, VMRegPair tmp_vmreg) {\n@@ -1851,1 +1485,1 @@\n-  } else if (iid == vmIntrinsics::_invokeBasic) {\n+  } else if (iid == vmIntrinsics::_invokeBasic || iid == vmIntrinsics::_linkToNative) {\n@@ -1854,1 +1488,1 @@\n-    fatal(\"unexpected intrinsic id %d\", iid);\n+    fatal(\"unexpected intrinsic id %d\", vmIntrinsics::as_int(iid));\n@@ -1903,4 +1537,3 @@\n-\/\/ passing them to the callee and perform checks before and after the\n-\/\/ native call to ensure that they GCLocker\n-\/\/ lock_critical\/unlock_critical semantics are followed.  Some other\n-\/\/ parts of JNI setup are skipped like the tear down of the JNI handle\n+\/\/ passing them to the callee. Critical native functions leave the state _in_Java,\n+\/\/ since they cannot stop for GC.\n+\/\/ Some other parts of JNI setup are skipped like the tear down of the JNI handle\n@@ -1910,12 +1543,0 @@\n-\/\/ They are roughly structured like this:\n-\/\/    if (GCLocker::needs_gc())\n-\/\/      SharedRuntime::block_for_jni_critical();\n-\/\/    tranistion to thread_in_native\n-\/\/    unpack arrray arguments and call native entry point\n-\/\/    check for safepoint in progress\n-\/\/    check if any thread suspend flags are set\n-\/\/      call into JVM and possible unlock the JNI critical\n-\/\/      if a GC was suppressed while in the critical native.\n-\/\/    transition back to thread_in_Java\n-\/\/    return to caller\n-\/\/\n@@ -2178,7 +1799,1 @@\n-\n-  if (UseStackBanging) {\n-    __ bang_stack_with_offset((int)JavaThread::stack_shadow_zone_size());\n-  } else {\n-    \/\/ need a 5 byte instruction to allow MT safe patching to non-entrant\n-    __ fat_nop();\n-  }\n+  __ bang_stack_with_offset((int)StackOverflow::stack_shadow_zone_size());\n@@ -2222,5 +1837,0 @@\n-  if (is_critical_native && !Universe::heap()->supports_object_pinning()) {\n-    check_needs_gc_for_critical_native(masm, stack_slots, total_c_args, total_in_args,\n-                                       oop_handle_offset, oop_maps, in_regs, in_sig_bt);\n-  }\n-\n@@ -2279,4 +1889,0 @@\n-  \/\/ Inbound arguments that need to be pinned for critical natives\n-  GrowableArray<int> pinned_args(total_in_args);\n-  \/\/ Current stack slot for storing register based array argument\n-  int pinned_slot = oop_handle_offset;\n@@ -2331,17 +1937,0 @@\n-          \/\/ pin before unpack\n-          if (Universe::heap()->supports_object_pinning()) {\n-            save_args(masm, total_c_args, 0, out_regs);\n-            gen_pin_object(masm, in_regs[i]);\n-            pinned_args.append(i);\n-            restore_args(masm, total_c_args, 0, out_regs);\n-\n-            \/\/ rax has pinned array\n-            VMRegPair result_reg;\n-            result_reg.set_ptr(rax->as_VMReg());\n-            move_ptr(masm, result_reg, in_regs[i]);\n-            if (!in_regs[i].first()->is_stack()) {\n-              assert(pinned_slot <= stack_slots, \"overflow\");\n-              move_ptr(masm, result_reg, VMRegImpl::stack2reg(pinned_slot));\n-              pinned_slot += VMRegImpl::slots_per_word;\n-            }\n-          }\n@@ -2361,1 +1950,1 @@\n-        object_move(masm, map, oop_handle_offset, stack_slots, in_regs[i], out_regs[c_arg],\n+        __ object_move(map, oop_handle_offset, stack_slots, in_regs[i], out_regs[c_arg],\n@@ -2369,1 +1958,1 @@\n-        float_move(masm, in_regs[i], out_regs[c_arg]);\n+        __ float_move(in_regs[i], out_regs[c_arg]);\n@@ -2376,1 +1965,1 @@\n-        double_move(masm, in_regs[i], out_regs[c_arg]);\n+        __ double_move(in_regs[i], out_regs[c_arg]);\n@@ -2380,1 +1969,1 @@\n-        long_move(masm, in_regs[i], out_regs[c_arg]);\n+        __ long_move(in_regs[i], out_regs[c_arg]);\n@@ -2386,1 +1975,1 @@\n-        move32_64(masm, in_regs[i], out_regs[c_arg]);\n+        __ move32_64(in_regs[i], out_regs[c_arg]);\n@@ -2493,1 +2082,0 @@\n-    __ resolve(IS_NOT_NULL, obj_reg);\n@@ -2543,1 +2131,0 @@\n-\n@@ -2546,1 +2133,0 @@\n-\n@@ -2550,3 +2136,3 @@\n-  }\n-  \/\/ Now set thread in native\n-  __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_native);\n+    \/\/ Now set thread in native\n+    __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_native);\n+  }\n@@ -2579,16 +2165,11 @@\n-  \/\/ unpin pinned arguments\n-  pinned_slot = oop_handle_offset;\n-  if (pinned_args.length() > 0) {\n-    \/\/ save return value that may be overwritten otherwise.\n-    save_native_result(masm, ret_type, stack_slots);\n-    for (int index = 0; index < pinned_args.length(); index ++) {\n-      int i = pinned_args.at(index);\n-      assert(pinned_slot <= stack_slots, \"overflow\");\n-      if (!in_regs[i].first()->is_stack()) {\n-        int offset = pinned_slot * VMRegImpl::stack_slot_size;\n-        __ movq(in_regs[i].first()->as_Register(), Address(rsp, offset));\n-        pinned_slot += VMRegImpl::slots_per_word;\n-      }\n-      gen_unpin_object(masm, in_regs[i]);\n-    }\n-    restore_native_result(masm, ret_type, stack_slots);\n+  Label after_transition;\n+\n+  \/\/ If this is a critical native, check for a safepoint or suspend request after the call.\n+  \/\/ If a safepoint is needed, transition to native, then to native_trans to handle\n+  \/\/ safepoints like the native methods that are not critical natives.\n+  if (is_critical_native) {\n+    Label needs_safepoint;\n+    __ safepoint_poll(needs_safepoint, r15_thread, false \/* at_return *\/, false \/* in_nmethod *\/);\n+    __ cmpl(Address(r15_thread, JavaThread::suspend_flags_offset()), 0);\n+    __ jcc(Assembler::equal, after_transition);\n+    __ bind(needs_safepoint);\n@@ -2611,2 +2192,0 @@\n-  Label after_transition;\n-\n@@ -2618,1 +2197,1 @@\n-    __ safepoint_poll(slow_path, r15_thread, rscratch1);\n+    __ safepoint_poll(slow_path, r15_thread, true \/* at_return *\/, false \/* in_nmethod *\/);\n@@ -2636,5 +2215,1 @@\n-    if (!is_critical_native) {\n-      __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, JavaThread::check_special_condition_for_native_trans)));\n-    } else {\n-      __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, JavaThread::check_special_condition_for_native_trans_and_transition)));\n-    }\n+    __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, JavaThread::check_special_condition_for_native_trans)));\n@@ -2645,7 +2220,0 @@\n-\n-    if (is_critical_native) {\n-      \/\/ The call above performed the transition to thread_in_Java so\n-      \/\/ skip the transition logic below.\n-      __ jmpb(after_transition);\n-    }\n-\n@@ -2661,1 +2229,1 @@\n-  __ cmpl(Address(r15_thread, JavaThread::stack_guard_state_offset()), JavaThread::stack_guard_yellow_reserved_disabled);\n+  __ cmpl(Address(r15_thread, JavaThread::stack_guard_state_offset()), StackOverflow::stack_guard_yellow_reserved_disabled);\n@@ -2674,1 +2242,0 @@\n-    __ resolve(IS_NOT_NULL, obj_reg);\n@@ -2891,5 +2458,0 @@\n-  if (is_critical_native) {\n-    nm->set_lazy_critical_native(true);\n-  }\n-\n-\n@@ -2910,0 +2472,9 @@\n+\n+\/\/ Number of stack slots between incoming argument block and the start of\n+\/\/ a new frame.  The PROLOG must add this many slots to the stack.  The\n+\/\/ EPILOG must remove this many slots.  amd64 needs two slots for\n+\/\/ return address.\n+uint SharedRuntime::in_preserve_stack_slots() {\n+  return 4 + 2 * VerifyStackAtCalls;\n+}\n+\n@@ -2916,0 +2487,3 @@\n+  if (UseAVX > 2) {\n+    pad += 1024;\n+  }\n@@ -2917,1 +2491,1 @@\n-  if (EnableJVMCI || UseAOT) {\n+  if (EnableJVMCI) {\n@@ -2921,1 +2495,1 @@\n-  CodeBuffer buffer(\"deopt_blob\", 2048+pad, 1024);\n+  CodeBuffer buffer(\"deopt_blob\", 2560+pad, 1024);\n@@ -2963,1 +2537,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_vectors*\/ true);\n@@ -2981,1 +2555,1 @@\n-  (void) RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  (void) RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_vectors*\/ true);\n@@ -2991,1 +2565,1 @@\n-  if (EnableJVMCI || UseAOT) {\n+  if (EnableJVMCI) {\n@@ -3000,1 +2574,1 @@\n-    RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+    RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_vectors*\/ true);\n@@ -3047,1 +2621,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_vectors*\/ true);\n@@ -3106,1 +2680,1 @@\n-  if (EnableJVMCI || UseAOT) {\n+  if (EnableJVMCI) {\n@@ -3166,4 +2740,2 @@\n-  if (UseStackBanging) {\n-    __ movl(rbx, Address(rdi, Deoptimization::UnrollBlock::total_frame_sizes_offset_in_bytes()));\n-    __ bang_stack_size(rbx, rcx);\n-  }\n+  __ movl(rbx, Address(rdi, Deoptimization::UnrollBlock::total_frame_sizes_offset_in_bytes()));\n+  __ bang_stack_size(rbx, rcx);\n@@ -3271,1 +2843,1 @@\n-  if (EnableJVMCI || UseAOT) {\n+  if (EnableJVMCI) {\n@@ -3369,4 +2941,2 @@\n-  if (UseStackBanging) {\n-    __ movl(rbx, Address(rdi ,Deoptimization::UnrollBlock::total_frame_sizes_offset_in_bytes()));\n-    __ bang_stack_size(rbx, rcx);\n-  }\n+  __ movl(rbx, Address(rdi ,Deoptimization::UnrollBlock::total_frame_sizes_offset_in_bytes()));\n+  __ bang_stack_size(rbx, rcx);\n@@ -3461,1 +3031,0 @@\n-\n@@ -3649,1 +3218,2 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  \/\/ No need to save vector registers since they are caller-saved anyway.\n+  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_vectors*\/ false);\n@@ -3709,0 +3279,256 @@\n+#ifdef COMPILER2\n+static const int native_invoker_code_size = MethodHandles::adapter_code_size;\n+\n+class NativeInvokerGenerator : public StubCodeGenerator {\n+  address _call_target;\n+  int _shadow_space_bytes;\n+\n+  const GrowableArray<VMReg>& _input_registers;\n+  const GrowableArray<VMReg>& _output_registers;\n+\n+  int _frame_complete;\n+  int _framesize;\n+  OopMapSet* _oop_maps;\n+public:\n+  NativeInvokerGenerator(CodeBuffer* buffer,\n+                         address call_target,\n+                         int shadow_space_bytes,\n+                         const GrowableArray<VMReg>& input_registers,\n+                         const GrowableArray<VMReg>& output_registers)\n+   : StubCodeGenerator(buffer, PrintMethodHandleStubs),\n+     _call_target(call_target),\n+     _shadow_space_bytes(shadow_space_bytes),\n+     _input_registers(input_registers),\n+     _output_registers(output_registers),\n+     _frame_complete(0),\n+     _framesize(0),\n+     _oop_maps(NULL) {\n+    assert(_output_registers.length() <= 1\n+           || (_output_registers.length() == 2 && !_output_registers.at(1)->is_valid()), \"no multi-reg returns\");\n+\n+  }\n+\n+  void generate();\n+\n+  int spill_size_in_bytes() const {\n+    if (_output_registers.length() == 0) {\n+      return 0;\n+    }\n+    VMReg reg = _output_registers.at(0);\n+    assert(reg->is_reg(), \"must be a register\");\n+    if (reg->is_Register()) {\n+      return 8;\n+    } else if (reg->is_XMMRegister()) {\n+      if (UseAVX >= 3) {\n+        return 64;\n+      } else if (UseAVX >= 1) {\n+        return 32;\n+      } else {\n+        return 16;\n+      }\n+    } else {\n+      ShouldNotReachHere();\n+    }\n+    return 0;\n+  }\n+\n+  void spill_out_registers() {\n+    if (_output_registers.length() == 0) {\n+      return;\n+    }\n+    VMReg reg = _output_registers.at(0);\n+    assert(reg->is_reg(), \"must be a register\");\n+    MacroAssembler* masm = _masm;\n+    if (reg->is_Register()) {\n+      __ movptr(Address(rsp, 0), reg->as_Register());\n+    } else if (reg->is_XMMRegister()) {\n+      if (UseAVX >= 3) {\n+        __ evmovdqul(Address(rsp, 0), reg->as_XMMRegister(), Assembler::AVX_512bit);\n+      } else if (UseAVX >= 1) {\n+        __ vmovdqu(Address(rsp, 0), reg->as_XMMRegister());\n+      } else {\n+        __ movdqu(Address(rsp, 0), reg->as_XMMRegister());\n+      }\n+    } else {\n+      ShouldNotReachHere();\n+    }\n+  }\n+\n+  void fill_out_registers() {\n+    if (_output_registers.length() == 0) {\n+      return;\n+    }\n+    VMReg reg = _output_registers.at(0);\n+    assert(reg->is_reg(), \"must be a register\");\n+    MacroAssembler* masm = _masm;\n+    if (reg->is_Register()) {\n+      __ movptr(reg->as_Register(), Address(rsp, 0));\n+    } else if (reg->is_XMMRegister()) {\n+      if (UseAVX >= 3) {\n+        __ evmovdqul(reg->as_XMMRegister(), Address(rsp, 0), Assembler::AVX_512bit);\n+      } else if (UseAVX >= 1) {\n+        __ vmovdqu(reg->as_XMMRegister(), Address(rsp, 0));\n+      } else {\n+        __ movdqu(reg->as_XMMRegister(), Address(rsp, 0));\n+      }\n+    } else {\n+      ShouldNotReachHere();\n+    }\n+  }\n+\n+  int frame_complete() const {\n+    return _frame_complete;\n+  }\n+\n+  int framesize() const {\n+    return (_framesize >> (LogBytesPerWord - LogBytesPerInt));\n+  }\n+\n+  OopMapSet* oop_maps() const {\n+    return _oop_maps;\n+  }\n+\n+private:\n+#ifdef ASSERT\n+bool target_uses_register(VMReg reg) {\n+  return _input_registers.contains(reg) || _output_registers.contains(reg);\n+}\n+#endif\n+};\n+\n+RuntimeStub* SharedRuntime::make_native_invoker(address call_target,\n+                                                int shadow_space_bytes,\n+                                                const GrowableArray<VMReg>& input_registers,\n+                                                const GrowableArray<VMReg>& output_registers) {\n+  int locs_size  = 64;\n+  CodeBuffer code(\"nep_invoker_blob\", native_invoker_code_size, locs_size);\n+  NativeInvokerGenerator g(&code, call_target, shadow_space_bytes, input_registers, output_registers);\n+  g.generate();\n+  code.log_section_sizes(\"nep_invoker_blob\");\n+\n+  RuntimeStub* stub =\n+    RuntimeStub::new_runtime_stub(\"nep_invoker_blob\",\n+                                  &code,\n+                                  g.frame_complete(),\n+                                  g.framesize(),\n+                                  g.oop_maps(), false);\n+  return stub;\n+}\n+\n+void NativeInvokerGenerator::generate() {\n+  assert(!(target_uses_register(r15_thread->as_VMReg()) || target_uses_register(rscratch1->as_VMReg())), \"Register conflict\");\n+\n+  enum layout {\n+    rbp_off,\n+    rbp_off2,\n+    return_off,\n+    return_off2,\n+    framesize \/\/ inclusive of return address\n+  };\n+\n+  _framesize = align_up(framesize + ((_shadow_space_bytes + spill_size_in_bytes()) >> LogBytesPerInt), 4);\n+  assert(is_even(_framesize\/2), \"sp not 16-byte aligned\");\n+\n+  _oop_maps  = new OopMapSet();\n+  MacroAssembler* masm = _masm;\n+\n+  address start = __ pc();\n+\n+  __ enter();\n+\n+  \/\/ return address and rbp are already in place\n+  __ subptr(rsp, (_framesize-4) << LogBytesPerInt); \/\/ prolog\n+\n+  _frame_complete = __ pc() - start;\n+\n+  address the_pc = __ pc();\n+\n+  __ set_last_Java_frame(rsp, rbp, (address)the_pc);\n+  OopMap* map = new OopMap(_framesize, 0);\n+  _oop_maps->add_gc_map(the_pc - start, map);\n+\n+  \/\/ State transition\n+  __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_native);\n+\n+  __ call(RuntimeAddress(_call_target));\n+\n+  __ restore_cpu_control_state_after_jni();\n+\n+  __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_native_trans);\n+\n+  \/\/ Force this write out before the read below\n+  __ membar(Assembler::Membar_mask_bits(\n+          Assembler::LoadLoad | Assembler::LoadStore |\n+          Assembler::StoreLoad | Assembler::StoreStore));\n+\n+  Label L_after_safepoint_poll;\n+  Label L_safepoint_poll_slow_path;\n+\n+  __ safepoint_poll(L_safepoint_poll_slow_path, r15_thread, true \/* at_return *\/, false \/* in_nmethod *\/);\n+  __ cmpl(Address(r15_thread, JavaThread::suspend_flags_offset()), 0);\n+  __ jcc(Assembler::notEqual, L_safepoint_poll_slow_path);\n+\n+  __ bind(L_after_safepoint_poll);\n+\n+  \/\/ change thread state\n+  __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_Java);\n+\n+  __ block_comment(\"reguard stack check\");\n+  Label L_reguard;\n+  Label L_after_reguard;\n+  __ cmpl(Address(r15_thread, JavaThread::stack_guard_state_offset()), StackOverflow::stack_guard_yellow_reserved_disabled);\n+  __ jcc(Assembler::equal, L_reguard);\n+  __ bind(L_after_reguard);\n+\n+  __ reset_last_Java_frame(r15_thread, true);\n+\n+  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+  __ ret(0);\n+\n+  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+  __ block_comment(\"{ L_safepoint_poll_slow_path\");\n+  __ bind(L_safepoint_poll_slow_path);\n+  __ vzeroupper();\n+\n+  spill_out_registers();\n+\n+  __ mov(c_rarg0, r15_thread);\n+  __ mov(r12, rsp); \/\/ remember sp\n+  __ subptr(rsp, frame::arg_reg_save_area_bytes); \/\/ windows\n+  __ andptr(rsp, -16); \/\/ align stack as required by ABI\n+  __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, JavaThread::check_special_condition_for_native_trans)));\n+  __ mov(rsp, r12); \/\/ restore sp\n+  __ reinit_heapbase();\n+\n+  fill_out_registers();\n+\n+  __ jmp(L_after_safepoint_poll);\n+  __ block_comment(\"} L_safepoint_poll_slow_path\");\n+\n+  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+  __ block_comment(\"{ L_reguard\");\n+  __ bind(L_reguard);\n+  __ vzeroupper();\n+\n+  spill_out_registers();\n+\n+  __ mov(r12, rsp); \/\/ remember sp\n+  __ subptr(rsp, frame::arg_reg_save_area_bytes); \/\/ windows\n+  __ andptr(rsp, -16); \/\/ align stack as required by ABI\n+  __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::reguard_yellow_pages)));\n+  __ mov(rsp, r12); \/\/ restore sp\n+  __ reinit_heapbase();\n+\n+  fill_out_registers();\n+\n+  __ jmp(L_after_reguard);\n+\n+  __ block_comment(\"} L_reguard\");\n+\n+  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+  __ flush();\n+}\n+#endif \/\/ COMPILER2\n@@ -3715,7 +3541,4 @@\n-#define ASM_SUBTRACT\n-\n-#ifdef ASM_SUBTRACT\n-static unsigned long\n-sub(unsigned long a[], unsigned long b[], unsigned long carry, long len) {\n-  long i = 0, cnt = len;\n-  unsigned long tmp;\n+static julong\n+sub(julong a[], julong b[], julong carry, long len) {\n+  long long i = 0, cnt = len;\n+  julong tmp;\n@@ -3735,18 +3558,0 @@\n-#else \/\/ ASM_SUBTRACT\n-typedef int __attribute__((mode(TI))) int128;\n-\n-\/\/ Subtract 0:b from carry:a.  Return carry.\n-static unsigned long\n-sub(unsigned long a[], unsigned long b[], unsigned long carry, int len) {\n-  int128 tmp = 0;\n-  int i;\n-  for (i = 0; i < len; i++) {\n-    tmp += a[i];\n-    tmp -= b[i];\n-    a[i] = tmp;\n-    tmp >>= 64;\n-    assert(-1 <= tmp && tmp <= 0, \"invariant\");\n-  }\n-  return tmp + carry;\n-}\n-#endif \/\/ ! ASM_SUBTRACT\n@@ -3775,0 +3580,42 @@\n+#else \/\/_WINDOWS\n+\n+static julong\n+sub(julong a[], julong b[], julong carry, long len) {\n+  long i;\n+  julong tmp;\n+  unsigned char c = 1;\n+  for (i = 0; i < len; i++) {\n+    c = _addcarry_u64(c, a[i], ~b[i], &tmp);\n+    a[i] = tmp;\n+  }\n+  c = _addcarry_u64(c, carry, ~0, &tmp);\n+  return tmp;\n+}\n+\n+\/\/ Multiply (unsigned) Long A by Long B, accumulating the double-\n+\/\/ length result into the accumulator formed of T0, T1, and T2.\n+#define MACC(A, B, T0, T1, T2)                          \\\n+do {                                                    \\\n+  julong hi, lo;                            \\\n+  lo = _umul128(A, B, &hi);                             \\\n+  unsigned char c = _addcarry_u64(0, lo, T0, &T0);      \\\n+  c = _addcarry_u64(c, hi, T1, &T1);                    \\\n+  _addcarry_u64(c, T2, 0, &T2);                         \\\n+ } while(0)\n+\n+\/\/ As above, but add twice the double-length result into the\n+\/\/ accumulator.\n+#define MACC2(A, B, T0, T1, T2)                         \\\n+do {                                                    \\\n+  julong hi, lo;                            \\\n+  lo = _umul128(A, B, &hi);                             \\\n+  unsigned char c = _addcarry_u64(0, lo, T0, &T0);      \\\n+  c = _addcarry_u64(c, hi, T1, &T1);                    \\\n+  _addcarry_u64(c, T2, 0, &T2);                         \\\n+  c = _addcarry_u64(0, lo, T0, &T0);                    \\\n+  c = _addcarry_u64(c, hi, T1, &T1);                    \\\n+  _addcarry_u64(c, T2, 0, &T2);                         \\\n+ } while(0)\n+\n+#endif \/\/_WINDOWS\n+\n@@ -3779,4 +3626,4 @@\n-static void __attribute__((noinline))\n-montgomery_multiply(unsigned long a[], unsigned long b[], unsigned long n[],\n-                    unsigned long m[], unsigned long inv, int len) {\n-  unsigned long t0 = 0, t1 = 0, t2 = 0; \/\/ Triple-precision accumulator\n+static void NOINLINE\n+montgomery_multiply(julong a[], julong b[], julong n[],\n+                    julong m[], julong inv, int len) {\n+  julong t0 = 0, t1 = 0, t2 = 0; \/\/ Triple-precision accumulator\n@@ -3785,1 +3632,1 @@\n-  assert(inv * n[0] == -1UL, \"broken inverse in Montgomery multiply\");\n+  assert(inv * n[0] == ULLONG_MAX, \"broken inverse in Montgomery multiply\");\n@@ -3821,4 +3668,4 @@\n-static void __attribute__((noinline))\n-montgomery_square(unsigned long a[], unsigned long n[],\n-                  unsigned long m[], unsigned long inv, int len) {\n-  unsigned long t0 = 0, t1 = 0, t2 = 0; \/\/ Triple-precision accumulator\n+static void NOINLINE\n+montgomery_square(julong a[], julong n[],\n+                  julong m[], julong inv, int len) {\n+  julong t0 = 0, t1 = 0, t2 = 0; \/\/ Triple-precision accumulator\n@@ -3827,1 +3674,1 @@\n-  assert(inv * n[0] == -1UL, \"broken inverse in Montgomery multiply\");\n+  assert(inv * n[0] == ULLONG_MAX, \"broken inverse in Montgomery square\");\n@@ -3873,1 +3720,1 @@\n-static unsigned long swap(unsigned long x) {\n+static julong swap(julong x) {\n@@ -3879,1 +3726,1 @@\n-static void reverse_words(unsigned long *s, unsigned long *d, int len) {\n+static void reverse_words(julong *s, julong *d, int len) {\n@@ -3901,1 +3748,1 @@\n-  int total_allocation = longwords * sizeof (unsigned long) * 4;\n+  int total_allocation = longwords * sizeof (julong) * 4;\n@@ -3903,1 +3750,1 @@\n-  unsigned long *scratch = (unsigned long *)alloca(total_allocation);\n+  julong *scratch = (julong *)alloca(total_allocation);\n@@ -3906,1 +3753,1 @@\n-  unsigned long\n+  julong\n@@ -3912,3 +3759,3 @@\n-  reverse_words((unsigned long *)a_ints, a, longwords);\n-  reverse_words((unsigned long *)b_ints, b, longwords);\n-  reverse_words((unsigned long *)n_ints, n, longwords);\n+  reverse_words((julong *)a_ints, a, longwords);\n+  reverse_words((julong *)b_ints, b, longwords);\n+  reverse_words((julong *)n_ints, n, longwords);\n@@ -3916,1 +3763,1 @@\n-  ::montgomery_multiply(a, b, n, m, (unsigned long)inv, longwords);\n+  ::montgomery_multiply(a, b, n, m, (julong)inv, longwords);\n@@ -3918,1 +3765,1 @@\n-  reverse_words(m, (unsigned long *)m_ints, longwords);\n+  reverse_words(m, (julong *)m_ints, longwords);\n@@ -3930,1 +3777,1 @@\n-  int total_allocation = longwords * sizeof (unsigned long) * 3;\n+  int total_allocation = longwords * sizeof (julong) * 3;\n@@ -3932,1 +3779,1 @@\n-  unsigned long *scratch = (unsigned long *)alloca(total_allocation);\n+  julong *scratch = (julong *)alloca(total_allocation);\n@@ -3935,1 +3782,1 @@\n-  unsigned long\n+  julong\n@@ -3940,2 +3787,2 @@\n-  reverse_words((unsigned long *)a_ints, a, longwords);\n-  reverse_words((unsigned long *)n_ints, n, longwords);\n+  reverse_words((julong *)a_ints, a, longwords);\n+  reverse_words((julong *)n_ints, n, longwords);\n@@ -3944,1 +3791,1 @@\n-    ::montgomery_square(a, n, m, (unsigned long)inv, longwords);\n+    ::montgomery_square(a, n, m, (julong)inv, longwords);\n@@ -3946,1 +3793,1 @@\n-    ::montgomery_multiply(a, a, n, m, (unsigned long)inv, longwords);\n+    ::montgomery_multiply(a, a, n, m, (julong)inv, longwords);\n@@ -3949,1 +3796,1 @@\n-  reverse_words(m, (unsigned long *)m_ints, longwords);\n+  reverse_words(m, (julong *)m_ints, longwords);\n@@ -3952,2 +3799,0 @@\n-#endif \/\/ WINDOWS\n-\n@@ -4087,0 +3932,10 @@\n+\n+void SharedRuntime::compute_move_order(const BasicType* in_sig_bt,\n+                                       int total_in_args, const VMRegPair* in_regs,\n+                                       int total_out_args, VMRegPair* out_regs,\n+                                       GrowableArray<int>& arg_order,\n+                                       VMRegPair tmp_vmreg) {\n+  ComputeMoveOrder order(total_in_args, in_regs,\n+                         total_out_args, out_regs,\n+                         in_sig_bt, arg_order, tmp_vmreg);\n+}\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":491,"deletions":636,"binary":false,"changes":1127,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,0 +28,2 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n+#include \"gc\/shared\/tlab_globals.hpp\"\n@@ -36,0 +38,1 @@\n+#include \"prims\/jvmtiExport.hpp\"\n@@ -50,5 +53,0 @@\n-\/\/ Platform-dependent initialization\n-void TemplateTable::pd_initialize() {\n-  \/\/ No x86 specific initialization\n-}\n-\n@@ -451,0 +449,1 @@\n+    __ resolve_oop_handle(tmp);\n@@ -1746,11 +1745,2 @@\n-      Label L_strict;\n-      Label L_join;\n-      const Address access_flags      (rcx, Method::access_flags_offset());\n-      __ get_method(rcx);\n-      __ movl(rcx, access_flags);\n-      __ testl(rcx, JVM_ACC_STRICT);\n-      __ jccb(Assembler::notZero, L_strict);\n-      __ fmul_d (at_rsp());\n-      __ jmpb(L_join);\n-      __ bind(L_strict);\n-      __ fld_x(ExternalAddress(StubRoutines::addr_fpu_subnormal_bias1()));\n+      \/\/ strict semantics\n+      __ fld_x(ExternalAddress(StubRoutines::x86::addr_fpu_subnormal_bias1()));\n@@ -1759,1 +1749,1 @@\n-      __ fld_x(ExternalAddress(StubRoutines::addr_fpu_subnormal_bias2()));\n+      __ fld_x(ExternalAddress(StubRoutines::x86::addr_fpu_subnormal_bias2()));\n@@ -1761,1 +1751,0 @@\n-      __ bind(L_join);\n@@ -1765,11 +1754,2 @@\n-      Label L_strict;\n-      Label L_join;\n-      const Address access_flags      (rcx, Method::access_flags_offset());\n-      __ get_method(rcx);\n-      __ movl(rcx, access_flags);\n-      __ testl(rcx, JVM_ACC_STRICT);\n-      __ jccb(Assembler::notZero, L_strict);\n-      __ fdivr_d(at_rsp());\n-      __ jmp(L_join);\n-      __ bind(L_strict);\n-      __ fld_x(ExternalAddress(StubRoutines::addr_fpu_subnormal_bias1()));\n+      \/\/ strict semantics\n+      __ fld_x(ExternalAddress(StubRoutines::x86::addr_fpu_subnormal_bias1()));\n@@ -1778,1 +1758,1 @@\n-      __ fld_x(ExternalAddress(StubRoutines::addr_fpu_subnormal_bias2()));\n+      __ fld_x(ExternalAddress(StubRoutines::x86::addr_fpu_subnormal_bias2()));\n@@ -1780,1 +1760,0 @@\n-      __ bind(L_join);\n@@ -2301,1 +2280,0 @@\n-  Label profile_method;\n@@ -2330,68 +2308,14 @@\n-    if (TieredCompilation) {\n-      Label no_mdo;\n-      int increment = InvocationCounter::count_increment;\n-      if (ProfileInterpreter) {\n-        \/\/ Are we profiling?\n-        __ movptr(rbx, Address(rcx, in_bytes(Method::method_data_offset())));\n-        __ testptr(rbx, rbx);\n-        __ jccb(Assembler::zero, no_mdo);\n-        \/\/ Increment the MDO backedge counter\n-        const Address mdo_backedge_counter(rbx, in_bytes(MethodData::backedge_counter_offset()) +\n-                                           in_bytes(InvocationCounter::counter_offset()));\n-        const Address mask(rbx, in_bytes(MethodData::backedge_mask_offset()));\n-        __ increment_mask_and_jump(mdo_backedge_counter, increment, mask, rax, false, Assembler::zero,\n-                                   UseOnStackReplacement ? &backedge_counter_overflow : NULL);\n-        __ jmp(dispatch);\n-      }\n-      __ bind(no_mdo);\n-      \/\/ Increment backedge counter in MethodCounters*\n-      __ movptr(rcx, Address(rcx, Method::method_counters_offset()));\n-      const Address mask(rcx, in_bytes(MethodCounters::backedge_mask_offset()));\n-      __ increment_mask_and_jump(Address(rcx, be_offset), increment, mask,\n-                                 rax, false, Assembler::zero,\n-                                 UseOnStackReplacement ? &backedge_counter_overflow : NULL);\n-    } else { \/\/ not TieredCompilation\n-      \/\/ increment counter\n-      __ movptr(rcx, Address(rcx, Method::method_counters_offset()));\n-      __ movl(rax, Address(rcx, be_offset));        \/\/ load backedge counter\n-      __ incrementl(rax, InvocationCounter::count_increment); \/\/ increment counter\n-      __ movl(Address(rcx, be_offset), rax);        \/\/ store counter\n-\n-      __ movl(rax, Address(rcx, inv_offset));    \/\/ load invocation counter\n-\n-      __ andl(rax, InvocationCounter::count_mask_value); \/\/ and the status bits\n-      __ addl(rax, Address(rcx, be_offset));        \/\/ add both counters\n-\n-      if (ProfileInterpreter) {\n-        \/\/ Test to see if we should create a method data oop\n-        __ cmp32(rax, Address(rcx, in_bytes(MethodCounters::interpreter_profile_limit_offset())));\n-        __ jcc(Assembler::less, dispatch);\n-\n-        \/\/ if no method data exists, go to profile method\n-        __ test_method_data_pointer(rax, profile_method);\n-\n-        if (UseOnStackReplacement) {\n-          \/\/ check for overflow against rbx which is the MDO taken count\n-          __ cmp32(rbx, Address(rcx, in_bytes(MethodCounters::interpreter_backward_branch_limit_offset())));\n-          __ jcc(Assembler::below, dispatch);\n-\n-          \/\/ When ProfileInterpreter is on, the backedge_count comes\n-          \/\/ from the MethodData*, which value does not get reset on\n-          \/\/ the call to frequency_counter_overflow().  To avoid\n-          \/\/ excessive calls to the overflow routine while the method is\n-          \/\/ being compiled, add a second test to make sure the overflow\n-          \/\/ function is called only once every overflow_frequency.\n-          const int overflow_frequency = 1024;\n-          __ andl(rbx, overflow_frequency - 1);\n-          __ jcc(Assembler::zero, backedge_counter_overflow);\n-\n-        }\n-      } else {\n-        if (UseOnStackReplacement) {\n-          \/\/ check for overflow against rax, which is the sum of the\n-          \/\/ counters\n-          __ cmp32(rax, Address(rcx, in_bytes(MethodCounters::interpreter_backward_branch_limit_offset())));\n-          __ jcc(Assembler::aboveEqual, backedge_counter_overflow);\n-\n-        }\n-      }\n+    Label no_mdo;\n+    int increment = InvocationCounter::count_increment;\n+    if (ProfileInterpreter) {\n+      \/\/ Are we profiling?\n+      __ movptr(rbx, Address(rcx, in_bytes(Method::method_data_offset())));\n+      __ testptr(rbx, rbx);\n+      __ jccb(Assembler::zero, no_mdo);\n+      \/\/ Increment the MDO backedge counter\n+      const Address mdo_backedge_counter(rbx, in_bytes(MethodData::backedge_counter_offset()) +\n+          in_bytes(InvocationCounter::counter_offset()));\n+      const Address mask(rbx, in_bytes(MethodData::backedge_mask_offset()));\n+      __ increment_mask_and_jump(mdo_backedge_counter, increment, mask, rax, false, Assembler::zero,\n+          UseOnStackReplacement ? &backedge_counter_overflow : NULL);\n+      __ jmp(dispatch);\n@@ -2399,0 +2323,6 @@\n+    __ bind(no_mdo);\n+    \/\/ Increment backedge counter in MethodCounters*\n+    __ movptr(rcx, Address(rcx, Method::method_counters_offset()));\n+    const Address mask(rcx, in_bytes(MethodCounters::backedge_mask_offset()));\n+    __ increment_mask_and_jump(Address(rcx, be_offset), increment, mask,\n+        rax, false, Assembler::zero, UseOnStackReplacement ? &backedge_counter_overflow : NULL);\n@@ -2412,8 +2342,1 @@\n-    if (ProfileInterpreter) {\n-      \/\/ Out-of-line code to allocate method data oop.\n-      __ bind(profile_method);\n-      __ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::profile_method));\n-      __ set_method_data_pointer_for_bcp();\n-      __ jmp(dispatch);\n-    }\n-\n+      Label set_mdp;\n@@ -2774,1 +2697,1 @@\n-    __ testb(Address(r15_thread, Thread::polling_page_offset()), SafepointMechanism::poll_bit());\n+    __ testb(Address(r15_thread, JavaThread::polling_word_offset()), SafepointMechanism::poll_bit());\n@@ -2778,1 +2701,1 @@\n-    __ testb(Address(thread, Thread::polling_page_offset()), SafepointMechanism::poll_bit());\n+    __ testb(Address(thread, JavaThread::polling_word_offset()), SafepointMechanism::poll_bit());\n@@ -2783,1 +2706,1 @@\n-                                    InterpreterRuntime::at_safepoint));\n+                                       InterpreterRuntime::at_safepoint));\n@@ -3790,5 +3713,0 @@\n-void TemplateTable::count_calls(Register method, Register temp) {\n-  \/\/ implemented elsewhere\n-  ShouldNotReachHere();\n-}\n-\n@@ -4551,2 +4469,0 @@\n-  __ resolve(IS_NOT_NULL, rax);\n-\n@@ -4650,2 +4566,0 @@\n-  __ resolve(IS_NOT_NULL, rax);\n-\n","filename":"src\/hotspot\/cpu\/x86\/templateTable_x86.cpp","additions":35,"deletions":121,"binary":false,"changes":156,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,0 +25,1 @@\n+\n@@ -26,0 +27,4 @@\n+#ifdef LINUX\n+#include \"classfile\/classLoader.hpp\"\n+#endif\n+#include \"jvmtifiles\/jvmti.h\"\n@@ -29,0 +34,2 @@\n+#include \"runtime\/globals_extension.hpp\"\n+#include \"runtime\/osThread.hpp\"\n@@ -32,0 +39,2 @@\n+#include \"runtime\/sharedRuntime.hpp\"\n+#include \"services\/attachListener.hpp\"\n@@ -33,0 +42,1 @@\n+#include \"runtime\/arguments.hpp\"\n@@ -34,0 +44,1 @@\n+#include \"runtime\/java.hpp\"\n@@ -35,0 +46,1 @@\n+#include \"runtime\/perfMemory.hpp\"\n@@ -44,0 +56,1 @@\n+#include <netdb.h>\n@@ -49,0 +62,2 @@\n+#include <sys\/socket.h>\n+#include <sys\/types.h>\n@@ -50,0 +65,1 @@\n+#include <sys\/wait.h>\n@@ -54,4 +70,2 @@\n-\/\/ Todo: provide a os::get_max_process_id() or similar. Number of processes\n-\/\/ may have been configured, can be read more accurately from proc fs etc.\n-#ifndef MAX_PID\n-#define MAX_PID INT_MAX\n+#ifdef __APPLE__\n+  #include <crt_externs.h>\n@@ -59,1 +73,0 @@\n-#define IS_VALID_PID(p) (p > 0 && p < MAX_PID)\n@@ -304,4 +317,1 @@\n-\/\/ Multiple threads can race in this code, and can remap over each other with MAP_FIXED,\n-\/\/ so on posix, unmap the section at the start and at the end of the chunk that we mapped\n-\/\/ rather than unmapping and remapping the whole chunk to get requested alignment.\n-char* os::reserve_memory_aligned(size_t size, size_t alignment, int file_desc) {\n+static size_t calculate_aligned_extra_size(size_t size, size_t alignment) {\n@@ -314,0 +324,2 @@\n+  return extra_size;\n+}\n@@ -315,19 +327,2 @@\n-  char* extra_base;\n-  if (file_desc != -1) {\n-    \/\/ For file mapping, we do not call os:reserve_memory(extra_size, NULL, alignment, file_desc) because\n-    \/\/ we need to deal with shrinking of the file space later when we release extra memory after alignment.\n-    \/\/ We also cannot called os:reserve_memory() with file_desc set to -1 because on aix we might get SHM memory.\n-    \/\/ So here to call a helper function while reserve memory for us. After we have a aligned base,\n-    \/\/ we will replace anonymous mapping with file mapping.\n-    extra_base = reserve_mmapped_memory(extra_size, NULL);\n-    if (extra_base != NULL) {\n-      MemTracker::record_virtual_memory_reserve((address)extra_base, extra_size, CALLER_PC);\n-    }\n-  } else {\n-    extra_base = os::reserve_memory(extra_size, NULL, alignment);\n-  }\n-\n-  if (extra_base == NULL) {\n-    return NULL;\n-  }\n-\n+\/\/ After a bigger chunk was mapped, unmaps start and end parts to get the requested alignment.\n+static char* chop_extra_memory(size_t size, size_t alignment, char* extra_base, size_t extra_size) {\n@@ -355,7 +350,0 @@\n-  if (file_desc != -1) {\n-    \/\/ After we have an aligned address, we can replace anonymous mapping with file mapping\n-    if (replace_existing_mapping_with_file_mapping(aligned_base, size, file_desc) == NULL) {\n-      vm_exit_during_initialization(err_msg(\"Error in mapping Java heap at the given filesystem directory\"));\n-    }\n-    MemTracker::record_virtual_memory_commit((address)aligned_base, size, CALLER_PC);\n-  }\n@@ -365,11 +353,11 @@\n-\/\/ On Posix platforms, reservations are done using mmap which can be released in parts. So splitting is a no-op.\n-void os::split_reserved_memory(char *base, size_t size, size_t split) {\n-  char* const split_address = base + split;\n-  assert(size > 0, \"Sanity\");\n-  assert(size > split, \"Sanity\");\n-  assert(split > 0, \"Sanity\");\n-  assert(is_aligned(base, os::vm_allocation_granularity()), \"Sanity\");\n-  assert(is_aligned(split_address, os::vm_allocation_granularity()), \"Sanity\");\n-\n-  \/\/ NMT: tell NMT to track both parts individually from now on.\n-  MemTracker::record_virtual_memory_split_reserved(base, size, split);\n+\/\/ Multiple threads can race in this code, and can remap over each other with MAP_FIXED,\n+\/\/ so on posix, unmap the section at the start and at the end of the chunk that we mapped\n+\/\/ rather than unmapping and remapping the whole chunk to get requested alignment.\n+char* os::reserve_memory_aligned(size_t size, size_t alignment, bool exec) {\n+  size_t extra_size = calculate_aligned_extra_size(size, alignment);\n+  char* extra_base = os::reserve_memory(extra_size, exec);\n+  if (extra_base == NULL) {\n+    return NULL;\n+  }\n+  return chop_extra_memory(size, alignment, extra_base, extra_size);\n+}\n@@ -377,0 +365,19 @@\n+char* os::map_memory_to_file_aligned(size_t size, size_t alignment, int file_desc) {\n+  size_t extra_size = calculate_aligned_extra_size(size, alignment);\n+  \/\/ For file mapping, we do not call os:map_memory_to_file(size,fd) since:\n+  \/\/ - we later chop away parts of the mapping using os::release_memory and that could fail if the\n+  \/\/   original mmap call had been tied to an fd.\n+  \/\/ - The memory API os::reserve_memory uses is an implementation detail. It may (and usually is)\n+  \/\/   mmap but it also may System V shared memory which cannot be uncommitted as a whole, so\n+  \/\/   chopping off and unmapping excess bits back and front (see below) would not work.\n+  char* extra_base = reserve_mmapped_memory(extra_size, NULL);\n+  if (extra_base == NULL) {\n+    return NULL;\n+  }\n+  char* aligned_base = chop_extra_memory(size, alignment, extra_base, extra_size);\n+  \/\/ After we have an aligned address, we can replace anonymous mapping with file mapping\n+  if (replace_existing_mapping_with_file_mapping(aligned_base, size, file_desc) == NULL) {\n+    vm_exit_during_initialization(err_msg(\"Error in mapping Java heap at the given filesystem directory\"));\n+  }\n+  MemTracker::record_virtual_memory_commit((address)aligned_base, size, CALLER_PC);\n+  return aligned_base;\n@@ -545,1 +552,21 @@\n-bool os::has_allocatable_memory_limit(julong* limit) {\n+#ifndef _LP64\n+\/\/ Helper, on 32bit, for os::has_allocatable_memory_limit\n+static bool is_allocatable(size_t s) {\n+  if (s < 2 * G) {\n+    return true;\n+  }\n+  \/\/ Use raw anonymous mmap here; no need to go through any\n+  \/\/ of our reservation layers. We will unmap right away.\n+  void* p = ::mmap(NULL, s, PROT_NONE,\n+                   MAP_PRIVATE | MAP_NORESERVE | MAP_ANONYMOUS, -1, 0);\n+  if (p == MAP_FAILED) {\n+    return false;\n+  } else {\n+    ::munmap(p, s);\n+    return true;\n+  }\n+}\n+#endif \/\/ !_LP64\n+\n+\n+bool os::has_allocatable_memory_limit(size_t* limit) {\n@@ -554,1 +581,1 @@\n-    *limit = (julong)rlim.rlim_cur;\n+    *limit = (size_t)rlim.rlim_cur;\n@@ -586,1 +613,1 @@\n-  const julong max_virtual_limit = (julong)3800*M;\n+  const size_t max_virtual_limit = 3800*M;\n@@ -603,1 +630,1 @@\n-  const julong min_allocation_size = M;\n+  const size_t min_allocation_size = M;\n@@ -605,1 +632,1 @@\n-  julong upper_limit = *limit;\n+  size_t upper_limit = *limit;\n@@ -616,1 +643,1 @@\n-    julong lower_limit = min_allocation_size;\n+    size_t lower_limit = min_allocation_size;\n@@ -618,1 +645,1 @@\n-      julong temp_limit = ((upper_limit - lower_limit) \/ 2) + lower_limit;\n+      size_t temp_limit = ((upper_limit - lower_limit) \/ 2) + lower_limit;\n@@ -632,0 +659,16 @@\n+void os::dll_unload(void *lib) {\n+  ::dlclose(lib);\n+}\n+\n+jlong os::lseek(int fd, jlong offset, int whence) {\n+  return (jlong) BSD_ONLY(::lseek) NOT_BSD(::lseek64)(fd, offset, whence);\n+}\n+\n+int os::fsync(int fd) {\n+  return ::fsync(fd);\n+}\n+\n+int os::ftruncate(int fd, jlong length) {\n+   return BSD_ONLY(::ftruncate) NOT_BSD(::ftruncate64)(fd, length);\n+}\n+\n@@ -640,0 +683,6 @@\n+size_t os::write(int fd, const void *buf, unsigned int nBytes) {\n+  size_t res;\n+  RESTARTABLE((size_t) ::write(fd, buf, (size_t) nBytes), res);\n+  return res;\n+}\n+\n@@ -644,0 +693,4 @@\n+int os::close(int fd) {\n+  return ::close(fd);\n+}\n+\n@@ -667,0 +720,32 @@\n+int os::socket_close(int fd) {\n+  return ::close(fd);\n+}\n+\n+int os::socket(int domain, int type, int protocol) {\n+  return ::socket(domain, type, protocol);\n+}\n+\n+int os::recv(int fd, char* buf, size_t nBytes, uint flags) {\n+  RESTARTABLE_RETURN_INT(::recv(fd, buf, nBytes, flags));\n+}\n+\n+int os::send(int fd, char* buf, size_t nBytes, uint flags) {\n+  RESTARTABLE_RETURN_INT(::send(fd, buf, nBytes, flags));\n+}\n+\n+int os::raw_send(int fd, char* buf, size_t nBytes, uint flags) {\n+  return os::send(fd, buf, nBytes, flags);\n+}\n+\n+int os::connect(int fd, struct sockaddr* him, socklen_t len) {\n+  RESTARTABLE_RETURN_INT(::connect(fd, him, len));\n+}\n+\n+struct hostent* os::get_host_by_name(char* name) {\n+  return ::gethostbyname(name);\n+}\n+\n+void os::exit(int num) {\n+  ::exit(num);\n+}\n+\n@@ -728,597 +813,0 @@\n-static const struct {\n-  int sig; const char* name;\n-}\n- g_signal_info[] =\n-  {\n-  {  SIGABRT,     \"SIGABRT\" },\n-#ifdef SIGAIO\n-  {  SIGAIO,      \"SIGAIO\" },\n-#endif\n-  {  SIGALRM,     \"SIGALRM\" },\n-#ifdef SIGALRM1\n-  {  SIGALRM1,    \"SIGALRM1\" },\n-#endif\n-  {  SIGBUS,      \"SIGBUS\" },\n-#ifdef SIGCANCEL\n-  {  SIGCANCEL,   \"SIGCANCEL\" },\n-#endif\n-  {  SIGCHLD,     \"SIGCHLD\" },\n-#ifdef SIGCLD\n-  {  SIGCLD,      \"SIGCLD\" },\n-#endif\n-  {  SIGCONT,     \"SIGCONT\" },\n-#ifdef SIGCPUFAIL\n-  {  SIGCPUFAIL,  \"SIGCPUFAIL\" },\n-#endif\n-#ifdef SIGDANGER\n-  {  SIGDANGER,   \"SIGDANGER\" },\n-#endif\n-#ifdef SIGDIL\n-  {  SIGDIL,      \"SIGDIL\" },\n-#endif\n-#ifdef SIGEMT\n-  {  SIGEMT,      \"SIGEMT\" },\n-#endif\n-  {  SIGFPE,      \"SIGFPE\" },\n-#ifdef SIGFREEZE\n-  {  SIGFREEZE,   \"SIGFREEZE\" },\n-#endif\n-#ifdef SIGGFAULT\n-  {  SIGGFAULT,   \"SIGGFAULT\" },\n-#endif\n-#ifdef SIGGRANT\n-  {  SIGGRANT,    \"SIGGRANT\" },\n-#endif\n-  {  SIGHUP,      \"SIGHUP\" },\n-  {  SIGILL,      \"SIGILL\" },\n-#ifdef SIGINFO\n-  {  SIGINFO,     \"SIGINFO\" },\n-#endif\n-  {  SIGINT,      \"SIGINT\" },\n-#ifdef SIGIO\n-  {  SIGIO,       \"SIGIO\" },\n-#endif\n-#ifdef SIGIOINT\n-  {  SIGIOINT,    \"SIGIOINT\" },\n-#endif\n-#ifdef SIGIOT\n-\/\/ SIGIOT is there for BSD compatibility, but on most Unices just a\n-\/\/ synonym for SIGABRT. The result should be \"SIGABRT\", not\n-\/\/ \"SIGIOT\".\n-#if (SIGIOT != SIGABRT )\n-  {  SIGIOT,      \"SIGIOT\" },\n-#endif\n-#endif\n-#ifdef SIGKAP\n-  {  SIGKAP,      \"SIGKAP\" },\n-#endif\n-  {  SIGKILL,     \"SIGKILL\" },\n-#ifdef SIGLOST\n-  {  SIGLOST,     \"SIGLOST\" },\n-#endif\n-#ifdef SIGLWP\n-  {  SIGLWP,      \"SIGLWP\" },\n-#endif\n-#ifdef SIGLWPTIMER\n-  {  SIGLWPTIMER, \"SIGLWPTIMER\" },\n-#endif\n-#ifdef SIGMIGRATE\n-  {  SIGMIGRATE,  \"SIGMIGRATE\" },\n-#endif\n-#ifdef SIGMSG\n-  {  SIGMSG,      \"SIGMSG\" },\n-#endif\n-  {  SIGPIPE,     \"SIGPIPE\" },\n-#ifdef SIGPOLL\n-  {  SIGPOLL,     \"SIGPOLL\" },\n-#endif\n-#ifdef SIGPRE\n-  {  SIGPRE,      \"SIGPRE\" },\n-#endif\n-  {  SIGPROF,     \"SIGPROF\" },\n-#ifdef SIGPTY\n-  {  SIGPTY,      \"SIGPTY\" },\n-#endif\n-#ifdef SIGPWR\n-  {  SIGPWR,      \"SIGPWR\" },\n-#endif\n-  {  SIGQUIT,     \"SIGQUIT\" },\n-#ifdef SIGRECONFIG\n-  {  SIGRECONFIG, \"SIGRECONFIG\" },\n-#endif\n-#ifdef SIGRECOVERY\n-  {  SIGRECOVERY, \"SIGRECOVERY\" },\n-#endif\n-#ifdef SIGRESERVE\n-  {  SIGRESERVE,  \"SIGRESERVE\" },\n-#endif\n-#ifdef SIGRETRACT\n-  {  SIGRETRACT,  \"SIGRETRACT\" },\n-#endif\n-#ifdef SIGSAK\n-  {  SIGSAK,      \"SIGSAK\" },\n-#endif\n-  {  SIGSEGV,     \"SIGSEGV\" },\n-#ifdef SIGSOUND\n-  {  SIGSOUND,    \"SIGSOUND\" },\n-#endif\n-#ifdef SIGSTKFLT\n-  {  SIGSTKFLT,    \"SIGSTKFLT\" },\n-#endif\n-  {  SIGSTOP,     \"SIGSTOP\" },\n-  {  SIGSYS,      \"SIGSYS\" },\n-#ifdef SIGSYSERROR\n-  {  SIGSYSERROR, \"SIGSYSERROR\" },\n-#endif\n-#ifdef SIGTALRM\n-  {  SIGTALRM,    \"SIGTALRM\" },\n-#endif\n-  {  SIGTERM,     \"SIGTERM\" },\n-#ifdef SIGTHAW\n-  {  SIGTHAW,     \"SIGTHAW\" },\n-#endif\n-  {  SIGTRAP,     \"SIGTRAP\" },\n-#ifdef SIGTSTP\n-  {  SIGTSTP,     \"SIGTSTP\" },\n-#endif\n-  {  SIGTTIN,     \"SIGTTIN\" },\n-  {  SIGTTOU,     \"SIGTTOU\" },\n-#ifdef SIGURG\n-  {  SIGURG,      \"SIGURG\" },\n-#endif\n-  {  SIGUSR1,     \"SIGUSR1\" },\n-  {  SIGUSR2,     \"SIGUSR2\" },\n-#ifdef SIGVIRT\n-  {  SIGVIRT,     \"SIGVIRT\" },\n-#endif\n-  {  SIGVTALRM,   \"SIGVTALRM\" },\n-#ifdef SIGWAITING\n-  {  SIGWAITING,  \"SIGWAITING\" },\n-#endif\n-#ifdef SIGWINCH\n-  {  SIGWINCH,    \"SIGWINCH\" },\n-#endif\n-#ifdef SIGWINDOW\n-  {  SIGWINDOW,   \"SIGWINDOW\" },\n-#endif\n-  {  SIGXCPU,     \"SIGXCPU\" },\n-  {  SIGXFSZ,     \"SIGXFSZ\" },\n-#ifdef SIGXRES\n-  {  SIGXRES,     \"SIGXRES\" },\n-#endif\n-  { -1, NULL }\n-};\n-\n-\/\/ Returned string is a constant. For unknown signals \"UNKNOWN\" is returned.\n-const char* os::Posix::get_signal_name(int sig, char* out, size_t outlen) {\n-\n-  const char* ret = NULL;\n-\n-#ifdef SIGRTMIN\n-  if (sig >= SIGRTMIN && sig <= SIGRTMAX) {\n-    if (sig == SIGRTMIN) {\n-      ret = \"SIGRTMIN\";\n-    } else if (sig == SIGRTMAX) {\n-      ret = \"SIGRTMAX\";\n-    } else {\n-      jio_snprintf(out, outlen, \"SIGRTMIN+%d\", sig - SIGRTMIN);\n-      return out;\n-    }\n-  }\n-#endif\n-\n-  if (sig > 0) {\n-    for (int idx = 0; g_signal_info[idx].sig != -1; idx ++) {\n-      if (g_signal_info[idx].sig == sig) {\n-        ret = g_signal_info[idx].name;\n-        break;\n-      }\n-    }\n-  }\n-\n-  if (!ret) {\n-    if (!is_valid_signal(sig)) {\n-      ret = \"INVALID\";\n-    } else {\n-      ret = \"UNKNOWN\";\n-    }\n-  }\n-\n-  if (out && outlen > 0) {\n-    strncpy(out, ret, outlen);\n-    out[outlen - 1] = '\\0';\n-  }\n-  return out;\n-}\n-\n-int os::Posix::get_signal_number(const char* signal_name) {\n-  char tmp[30];\n-  const char* s = signal_name;\n-  if (s[0] != 'S' || s[1] != 'I' || s[2] != 'G') {\n-    jio_snprintf(tmp, sizeof(tmp), \"SIG%s\", signal_name);\n-    s = tmp;\n-  }\n-  for (int idx = 0; g_signal_info[idx].sig != -1; idx ++) {\n-    if (strcmp(g_signal_info[idx].name, s) == 0) {\n-      return g_signal_info[idx].sig;\n-    }\n-  }\n-  return -1;\n-}\n-\n-int os::get_signal_number(const char* signal_name) {\n-  return os::Posix::get_signal_number(signal_name);\n-}\n-\n-\/\/ Returns true if signal number is valid.\n-bool os::Posix::is_valid_signal(int sig) {\n-  \/\/ MacOS not really POSIX compliant: sigaddset does not return\n-  \/\/ an error for invalid signal numbers. However, MacOS does not\n-  \/\/ support real time signals and simply seems to have just 33\n-  \/\/ signals with no holes in the signal range.\n-#ifdef __APPLE__\n-  return sig >= 1 && sig < NSIG;\n-#else\n-  \/\/ Use sigaddset to check for signal validity.\n-  sigset_t set;\n-  sigemptyset(&set);\n-  if (sigaddset(&set, sig) == -1 && errno == EINVAL) {\n-    return false;\n-  }\n-  return true;\n-#endif\n-}\n-\n-bool os::Posix::is_sig_ignored(int sig) {\n-  struct sigaction oact;\n-  sigaction(sig, (struct sigaction*)NULL, &oact);\n-  void* ohlr = oact.sa_sigaction ? CAST_FROM_FN_PTR(void*,  oact.sa_sigaction)\n-                                 : CAST_FROM_FN_PTR(void*,  oact.sa_handler);\n-  if (ohlr == CAST_FROM_FN_PTR(void*, SIG_IGN)) {\n-    return true;\n-  } else {\n-    return false;\n-  }\n-}\n-\n-\/\/ Returns:\n-\/\/ NULL for an invalid signal number\n-\/\/ \"SIG<num>\" for a valid but unknown signal number\n-\/\/ signal name otherwise.\n-const char* os::exception_name(int sig, char* buf, size_t size) {\n-  if (!os::Posix::is_valid_signal(sig)) {\n-    return NULL;\n-  }\n-  const char* const name = os::Posix::get_signal_name(sig, buf, size);\n-  if (strcmp(name, \"UNKNOWN\") == 0) {\n-    jio_snprintf(buf, size, \"SIG%d\", sig);\n-  }\n-  return buf;\n-}\n-\n-#define NUM_IMPORTANT_SIGS 32\n-\/\/ Returns one-line short description of a signal set in a user provided buffer.\n-const char* os::Posix::describe_signal_set_short(const sigset_t* set, char* buffer, size_t buf_size) {\n-  assert(buf_size == (NUM_IMPORTANT_SIGS + 1), \"wrong buffer size\");\n-  \/\/ Note: for shortness, just print out the first 32. That should\n-  \/\/ cover most of the useful ones, apart from realtime signals.\n-  for (int sig = 1; sig <= NUM_IMPORTANT_SIGS; sig++) {\n-    const int rc = sigismember(set, sig);\n-    if (rc == -1 && errno == EINVAL) {\n-      buffer[sig-1] = '?';\n-    } else {\n-      buffer[sig-1] = rc == 0 ? '0' : '1';\n-    }\n-  }\n-  buffer[NUM_IMPORTANT_SIGS] = 0;\n-  return buffer;\n-}\n-\n-\/\/ Prints one-line description of a signal set.\n-void os::Posix::print_signal_set_short(outputStream* st, const sigset_t* set) {\n-  char buf[NUM_IMPORTANT_SIGS + 1];\n-  os::Posix::describe_signal_set_short(set, buf, sizeof(buf));\n-  st->print(\"%s\", buf);\n-}\n-\n-\/\/ Writes one-line description of a combination of sigaction.sa_flags into a user\n-\/\/ provided buffer. Returns that buffer.\n-const char* os::Posix::describe_sa_flags(int flags, char* buffer, size_t size) {\n-  char* p = buffer;\n-  size_t remaining = size;\n-  bool first = true;\n-  int idx = 0;\n-\n-  assert(buffer, \"invalid argument\");\n-\n-  if (size == 0) {\n-    return buffer;\n-  }\n-\n-  strncpy(buffer, \"none\", size);\n-\n-  const struct {\n-    \/\/ NB: i is an unsigned int here because SA_RESETHAND is on some\n-    \/\/ systems 0x80000000, which is implicitly unsigned.  Assignining\n-    \/\/ it to an int field would be an overflow in unsigned-to-signed\n-    \/\/ conversion.\n-    unsigned int i;\n-    const char* s;\n-  } flaginfo [] = {\n-    { SA_NOCLDSTOP, \"SA_NOCLDSTOP\" },\n-    { SA_ONSTACK,   \"SA_ONSTACK\"   },\n-    { SA_RESETHAND, \"SA_RESETHAND\" },\n-    { SA_RESTART,   \"SA_RESTART\"   },\n-    { SA_SIGINFO,   \"SA_SIGINFO\"   },\n-    { SA_NOCLDWAIT, \"SA_NOCLDWAIT\" },\n-    { SA_NODEFER,   \"SA_NODEFER\"   },\n-#ifdef AIX\n-    { SA_ONSTACK,   \"SA_ONSTACK\"   },\n-    { SA_OLDSTYLE,  \"SA_OLDSTYLE\"  },\n-#endif\n-    { 0, NULL }\n-  };\n-\n-  for (idx = 0; flaginfo[idx].s && remaining > 1; idx++) {\n-    if (flags & flaginfo[idx].i) {\n-      if (first) {\n-        jio_snprintf(p, remaining, \"%s\", flaginfo[idx].s);\n-        first = false;\n-      } else {\n-        jio_snprintf(p, remaining, \"|%s\", flaginfo[idx].s);\n-      }\n-      const size_t len = strlen(p);\n-      p += len;\n-      remaining -= len;\n-    }\n-  }\n-\n-  buffer[size - 1] = '\\0';\n-\n-  return buffer;\n-}\n-\n-\/\/ Prints one-line description of a combination of sigaction.sa_flags.\n-void os::Posix::print_sa_flags(outputStream* st, int flags) {\n-  char buffer[0x100];\n-  os::Posix::describe_sa_flags(flags, buffer, sizeof(buffer));\n-  st->print(\"%s\", buffer);\n-}\n-\n-\/\/ Helper function for os::Posix::print_siginfo_...():\n-\/\/ return a textual description for signal code.\n-struct enum_sigcode_desc_t {\n-  const char* s_name;\n-  const char* s_desc;\n-};\n-\n-static bool get_signal_code_description(const siginfo_t* si, enum_sigcode_desc_t* out) {\n-\n-  const struct {\n-    int sig; int code; const char* s_code; const char* s_desc;\n-  } t1 [] = {\n-    { SIGILL,  ILL_ILLOPC,   \"ILL_ILLOPC\",   \"Illegal opcode.\" },\n-    { SIGILL,  ILL_ILLOPN,   \"ILL_ILLOPN\",   \"Illegal operand.\" },\n-    { SIGILL,  ILL_ILLADR,   \"ILL_ILLADR\",   \"Illegal addressing mode.\" },\n-    { SIGILL,  ILL_ILLTRP,   \"ILL_ILLTRP\",   \"Illegal trap.\" },\n-    { SIGILL,  ILL_PRVOPC,   \"ILL_PRVOPC\",   \"Privileged opcode.\" },\n-    { SIGILL,  ILL_PRVREG,   \"ILL_PRVREG\",   \"Privileged register.\" },\n-    { SIGILL,  ILL_COPROC,   \"ILL_COPROC\",   \"Coprocessor error.\" },\n-    { SIGILL,  ILL_BADSTK,   \"ILL_BADSTK\",   \"Internal stack error.\" },\n-#if defined(IA64) && defined(LINUX)\n-    { SIGILL,  ILL_BADIADDR, \"ILL_BADIADDR\", \"Unimplemented instruction address\" },\n-    { SIGILL,  ILL_BREAK,    \"ILL_BREAK\",    \"Application Break instruction\" },\n-#endif\n-    { SIGFPE,  FPE_INTDIV,   \"FPE_INTDIV\",   \"Integer divide by zero.\" },\n-    { SIGFPE,  FPE_INTOVF,   \"FPE_INTOVF\",   \"Integer overflow.\" },\n-    { SIGFPE,  FPE_FLTDIV,   \"FPE_FLTDIV\",   \"Floating-point divide by zero.\" },\n-    { SIGFPE,  FPE_FLTOVF,   \"FPE_FLTOVF\",   \"Floating-point overflow.\" },\n-    { SIGFPE,  FPE_FLTUND,   \"FPE_FLTUND\",   \"Floating-point underflow.\" },\n-    { SIGFPE,  FPE_FLTRES,   \"FPE_FLTRES\",   \"Floating-point inexact result.\" },\n-    { SIGFPE,  FPE_FLTINV,   \"FPE_FLTINV\",   \"Invalid floating-point operation.\" },\n-    { SIGFPE,  FPE_FLTSUB,   \"FPE_FLTSUB\",   \"Subscript out of range.\" },\n-    { SIGSEGV, SEGV_MAPERR,  \"SEGV_MAPERR\",  \"Address not mapped to object.\" },\n-    { SIGSEGV, SEGV_ACCERR,  \"SEGV_ACCERR\",  \"Invalid permissions for mapped object.\" },\n-#ifdef AIX\n-    \/\/ no explanation found what keyerr would be\n-    { SIGSEGV, SEGV_KEYERR,  \"SEGV_KEYERR\",  \"key error\" },\n-#endif\n-#if defined(IA64) && !defined(AIX)\n-    { SIGSEGV, SEGV_PSTKOVF, \"SEGV_PSTKOVF\", \"Paragraph stack overflow\" },\n-#endif\n-    { SIGBUS,  BUS_ADRALN,   \"BUS_ADRALN\",   \"Invalid address alignment.\" },\n-    { SIGBUS,  BUS_ADRERR,   \"BUS_ADRERR\",   \"Nonexistent physical address.\" },\n-    { SIGBUS,  BUS_OBJERR,   \"BUS_OBJERR\",   \"Object-specific hardware error.\" },\n-    { SIGTRAP, TRAP_BRKPT,   \"TRAP_BRKPT\",   \"Process breakpoint.\" },\n-    { SIGTRAP, TRAP_TRACE,   \"TRAP_TRACE\",   \"Process trace trap.\" },\n-    { SIGCHLD, CLD_EXITED,   \"CLD_EXITED\",   \"Child has exited.\" },\n-    { SIGCHLD, CLD_KILLED,   \"CLD_KILLED\",   \"Child has terminated abnormally and did not create a core file.\" },\n-    { SIGCHLD, CLD_DUMPED,   \"CLD_DUMPED\",   \"Child has terminated abnormally and created a core file.\" },\n-    { SIGCHLD, CLD_TRAPPED,  \"CLD_TRAPPED\",  \"Traced child has trapped.\" },\n-    { SIGCHLD, CLD_STOPPED,  \"CLD_STOPPED\",  \"Child has stopped.\" },\n-    { SIGCHLD, CLD_CONTINUED,\"CLD_CONTINUED\",\"Stopped child has continued.\" },\n-#ifdef SIGPOLL\n-    { SIGPOLL, POLL_OUT,     \"POLL_OUT\",     \"Output buffers available.\" },\n-    { SIGPOLL, POLL_MSG,     \"POLL_MSG\",     \"Input message available.\" },\n-    { SIGPOLL, POLL_ERR,     \"POLL_ERR\",     \"I\/O error.\" },\n-    { SIGPOLL, POLL_PRI,     \"POLL_PRI\",     \"High priority input available.\" },\n-    { SIGPOLL, POLL_HUP,     \"POLL_HUP\",     \"Device disconnected. [Option End]\" },\n-#endif\n-    { -1, -1, NULL, NULL }\n-  };\n-\n-  \/\/ Codes valid in any signal context.\n-  const struct {\n-    int code; const char* s_code; const char* s_desc;\n-  } t2 [] = {\n-    { SI_USER,      \"SI_USER\",     \"Signal sent by kill().\" },\n-    { SI_QUEUE,     \"SI_QUEUE\",    \"Signal sent by the sigqueue().\" },\n-    { SI_TIMER,     \"SI_TIMER\",    \"Signal generated by expiration of a timer set by timer_settime().\" },\n-    { SI_ASYNCIO,   \"SI_ASYNCIO\",  \"Signal generated by completion of an asynchronous I\/O request.\" },\n-    { SI_MESGQ,     \"SI_MESGQ\",    \"Signal generated by arrival of a message on an empty message queue.\" },\n-    \/\/ Linux specific\n-#ifdef SI_TKILL\n-    { SI_TKILL,     \"SI_TKILL\",    \"Signal sent by tkill (pthread_kill)\" },\n-#endif\n-#ifdef SI_DETHREAD\n-    { SI_DETHREAD,  \"SI_DETHREAD\", \"Signal sent by execve() killing subsidiary threads\" },\n-#endif\n-#ifdef SI_KERNEL\n-    { SI_KERNEL,    \"SI_KERNEL\",   \"Signal sent by kernel.\" },\n-#endif\n-#ifdef SI_SIGIO\n-    { SI_SIGIO,     \"SI_SIGIO\",    \"Signal sent by queued SIGIO\" },\n-#endif\n-\n-#ifdef AIX\n-    { SI_UNDEFINED, \"SI_UNDEFINED\",\"siginfo contains partial information\" },\n-    { SI_EMPTY,     \"SI_EMPTY\",    \"siginfo contains no useful information\" },\n-#endif\n-\n-#ifdef __sun\n-    { SI_NOINFO,    \"SI_NOINFO\",   \"No signal information\" },\n-    { SI_RCTL,      \"SI_RCTL\",     \"kernel generated signal via rctl action\" },\n-    { SI_LWP,       \"SI_LWP\",      \"Signal sent via lwp_kill\" },\n-#endif\n-\n-    { -1, NULL, NULL }\n-  };\n-\n-  const char* s_code = NULL;\n-  const char* s_desc = NULL;\n-\n-  for (int i = 0; t1[i].sig != -1; i ++) {\n-    if (t1[i].sig == si->si_signo && t1[i].code == si->si_code) {\n-      s_code = t1[i].s_code;\n-      s_desc = t1[i].s_desc;\n-      break;\n-    }\n-  }\n-\n-  if (s_code == NULL) {\n-    for (int i = 0; t2[i].s_code != NULL; i ++) {\n-      if (t2[i].code == si->si_code) {\n-        s_code = t2[i].s_code;\n-        s_desc = t2[i].s_desc;\n-      }\n-    }\n-  }\n-\n-  if (s_code == NULL) {\n-    out->s_name = \"unknown\";\n-    out->s_desc = \"unknown\";\n-    return false;\n-  }\n-\n-  out->s_name = s_code;\n-  out->s_desc = s_desc;\n-\n-  return true;\n-}\n-\n-bool os::signal_sent_by_kill(const void* siginfo) {\n-  const siginfo_t* const si = (const siginfo_t*)siginfo;\n-  return si->si_code == SI_USER || si->si_code == SI_QUEUE\n-#ifdef SI_TKILL\n-         || si->si_code == SI_TKILL\n-#endif\n-  ;\n-}\n-\n-void os::print_siginfo(outputStream* os, const void* si0) {\n-\n-  const siginfo_t* const si = (const siginfo_t*) si0;\n-\n-  char buf[20];\n-  os->print(\"siginfo:\");\n-\n-  if (!si) {\n-    os->print(\" <null>\");\n-    return;\n-  }\n-\n-  const int sig = si->si_signo;\n-\n-  os->print(\" si_signo: %d (%s)\", sig, os::Posix::get_signal_name(sig, buf, sizeof(buf)));\n-\n-  enum_sigcode_desc_t ed;\n-  get_signal_code_description(si, &ed);\n-  os->print(\", si_code: %d (%s)\", si->si_code, ed.s_name);\n-\n-  if (si->si_errno) {\n-    os->print(\", si_errno: %d\", si->si_errno);\n-  }\n-\n-  \/\/ Output additional information depending on the signal code.\n-\n-  \/\/ Note: Many implementations lump si_addr, si_pid, si_uid etc. together as unions,\n-  \/\/ so it depends on the context which member to use. For synchronous error signals,\n-  \/\/ we print si_addr, unless the signal was sent by another process or thread, in\n-  \/\/ which case we print out pid or tid of the sender.\n-  if (signal_sent_by_kill(si)) {\n-    const pid_t pid = si->si_pid;\n-    os->print(\", si_pid: %ld\", (long) pid);\n-    if (IS_VALID_PID(pid)) {\n-      const pid_t me = getpid();\n-      if (me == pid) {\n-        os->print(\" (current process)\");\n-      }\n-    } else {\n-      os->print(\" (invalid)\");\n-    }\n-    os->print(\", si_uid: %ld\", (long) si->si_uid);\n-    if (sig == SIGCHLD) {\n-      os->print(\", si_status: %d\", si->si_status);\n-    }\n-  } else if (sig == SIGSEGV || sig == SIGBUS || sig == SIGILL ||\n-             sig == SIGTRAP || sig == SIGFPE) {\n-    os->print(\", si_addr: \" PTR_FORMAT, p2i(si->si_addr));\n-#ifdef SIGPOLL\n-  } else if (sig == SIGPOLL) {\n-    os->print(\", si_band: %ld\", si->si_band);\n-#endif\n-  }\n-\n-}\n-\n-bool os::signal_thread(Thread* thread, int sig, const char* reason) {\n-  OSThread* osthread = thread->osthread();\n-  if (osthread) {\n-    int status = pthread_kill(osthread->pthread_id(), sig);\n-    if (status == 0) {\n-      Events::log(Thread::current(), \"sent signal %d to Thread \" INTPTR_FORMAT \" because %s.\",\n-                  sig, p2i(thread), reason);\n-      return true;\n-    }\n-  }\n-  return false;\n-}\n-\n-int os::Posix::unblock_thread_signal_mask(const sigset_t *set) {\n-  return pthread_sigmask(SIG_UNBLOCK, set, NULL);\n-}\n-\n-address os::Posix::ucontext_get_pc(const ucontext_t* ctx) {\n-#if defined(AIX)\n-   return Aix::ucontext_get_pc(ctx);\n-#elif defined(BSD)\n-   return Bsd::ucontext_get_pc(ctx);\n-#elif defined(LINUX)\n-   return Linux::ucontext_get_pc(ctx);\n-#else\n-   VMError::report_and_die(\"unimplemented ucontext_get_pc\");\n-#endif\n-}\n-\n-void os::Posix::ucontext_set_pc(ucontext_t* ctx, address pc) {\n-#if defined(AIX)\n-   Aix::ucontext_set_pc(ctx, pc);\n-#elif defined(BSD)\n-   Bsd::ucontext_set_pc(ctx, pc);\n-#elif defined(LINUX)\n-   Linux::ucontext_set_pc(ctx, pc);\n-#else\n-   VMError::report_and_die(\"unimplemented ucontext_get_pc\");\n-#endif\n-}\n-\n@@ -1390,0 +878,8 @@\n+  if (file1 == nullptr && file2 == nullptr) {\n+    return true;\n+  }\n+\n+  if (file1 == nullptr || file2 == nullptr) {\n+    return false;\n+  }\n+\n@@ -1427,2 +923,2 @@\n-                                   JavaThread::stack_guard_zone_size() +\n-                                   JavaThread::stack_shadow_zone_size();\n+                                   StackOverflow::stack_guard_zone_size() +\n+                                   StackOverflow::stack_shadow_zone_size();\n@@ -1451,2 +947,2 @@\n-                                       JavaThread::stack_guard_zone_size() +\n-                                       JavaThread::stack_shadow_zone_size();\n+                                       StackOverflow::stack_guard_zone_size() +\n+                                       StackOverflow::stack_shadow_zone_size();\n@@ -1534,0 +1030,117 @@\n+#ifndef ZERO\n+#ifndef ARM\n+static bool get_frame_at_stack_banging_point(JavaThread* thread, address pc, const void* ucVoid, frame* fr) {\n+  if (Interpreter::contains(pc)) {\n+    \/\/ interpreter performs stack banging after the fixed frame header has\n+    \/\/ been generated while the compilers perform it before. To maintain\n+    \/\/ semantic consistency between interpreted and compiled frames, the\n+    \/\/ method returns the Java sender of the current frame.\n+    *fr = os::fetch_frame_from_context(ucVoid);\n+    if (!fr->is_first_java_frame()) {\n+      \/\/ get_frame_at_stack_banging_point() is only called when we\n+      \/\/ have well defined stacks so java_sender() calls do not need\n+      \/\/ to assert safe_for_sender() first.\n+      *fr = fr->java_sender();\n+    }\n+  } else {\n+    \/\/ more complex code with compiled code\n+    assert(!Interpreter::contains(pc), \"Interpreted methods should have been handled above\");\n+    CodeBlob* cb = CodeCache::find_blob(pc);\n+    if (cb == NULL || !cb->is_nmethod() || cb->is_frame_complete_at(pc)) {\n+      \/\/ Not sure where the pc points to, fallback to default\n+      \/\/ stack overflow handling\n+      return false;\n+    } else {\n+      \/\/ in compiled code, the stack banging is performed just after the return pc\n+      \/\/ has been pushed on the stack\n+      *fr = os::fetch_compiled_frame_from_context(ucVoid);\n+      if (!fr->is_java_frame()) {\n+        assert(!fr->is_first_frame(), \"Safety check\");\n+        \/\/ See java_sender() comment above.\n+        *fr = fr->java_sender();\n+      }\n+    }\n+  }\n+  assert(fr->is_java_frame(), \"Safety check\");\n+  return true;\n+}\n+#endif \/\/ ARM\n+\n+\/\/ This return true if the signal handler should just continue, ie. return after calling this\n+bool os::Posix::handle_stack_overflow(JavaThread* thread, address addr, address pc,\n+                                      const void* ucVoid, address* stub) {\n+  \/\/ stack overflow\n+  StackOverflow* overflow_state = thread->stack_overflow_state();\n+  if (overflow_state->in_stack_yellow_reserved_zone(addr)) {\n+    if (thread->thread_state() == _thread_in_Java) {\n+#ifndef ARM\n+      \/\/ arm32 doesn't have this\n+      if (overflow_state->in_stack_reserved_zone(addr)) {\n+        frame fr;\n+        if (get_frame_at_stack_banging_point(thread, pc, ucVoid, &fr)) {\n+          assert(fr.is_java_frame(), \"Must be a Java frame\");\n+          frame activation =\n+            SharedRuntime::look_for_reserved_stack_annotated_method(thread, fr);\n+          if (activation.sp() != NULL) {\n+            overflow_state->disable_stack_reserved_zone();\n+            if (activation.is_interpreted_frame()) {\n+              overflow_state->set_reserved_stack_activation((address)(activation.fp()\n+                \/\/ Some platforms use frame pointers for interpreter frames, others use initial sp.\n+#if !defined(PPC64) && !defined(S390)\n+                + frame::interpreter_frame_initial_sp_offset\n+#endif\n+                ));\n+            } else {\n+              overflow_state->set_reserved_stack_activation((address)activation.unextended_sp());\n+            }\n+            return true; \/\/ just continue\n+          }\n+        }\n+      }\n+#endif \/\/ ARM\n+      \/\/ Throw a stack overflow exception.  Guard pages will be reenabled\n+      \/\/ while unwinding the stack.\n+      overflow_state->disable_stack_yellow_reserved_zone();\n+      *stub = SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::STACK_OVERFLOW);\n+    } else {\n+      \/\/ Thread was in the vm or native code.  Return and try to finish.\n+      overflow_state->disable_stack_yellow_reserved_zone();\n+      return true; \/\/ just continue\n+    }\n+  } else if (overflow_state->in_stack_red_zone(addr)) {\n+    \/\/ Fatal red zone violation.  Disable the guard pages and fall through\n+    \/\/ to handle_unexpected_exception way down below.\n+    overflow_state->disable_stack_red_zone();\n+    tty->print_raw_cr(\"An irrecoverable stack overflow has occurred.\");\n+\n+    \/\/ This is a likely cause, but hard to verify. Let's just print\n+    \/\/ it as a hint.\n+    tty->print_raw_cr(\"Please check if any of your loaded .so files has \"\n+                      \"enabled executable stack (see man page execstack(8))\");\n+\n+  } else {\n+#if !defined(AIX) && !defined(__APPLE__)\n+    \/\/ bsd and aix don't have this\n+\n+    \/\/ Accessing stack address below sp may cause SEGV if current\n+    \/\/ thread has MAP_GROWSDOWN stack. This should only happen when\n+    \/\/ current thread was created by user code with MAP_GROWSDOWN flag\n+    \/\/ and then attached to VM. See notes in os_linux.cpp.\n+    if (thread->osthread()->expanding_stack() == 0) {\n+       thread->osthread()->set_expanding_stack();\n+       if (os::Linux::manually_expand_stack(thread, addr)) {\n+         thread->osthread()->clear_expanding_stack();\n+         return true; \/\/ just continue\n+       }\n+       thread->osthread()->clear_expanding_stack();\n+    } else {\n+       fatal(\"recursive segv. expanding stack.\");\n+    }\n+#else\n+    tty->print_raw_cr(\"SIGSEGV happened inside stack but outside yellow and red zone.\");\n+#endif \/\/ AIX or BSD\n+  }\n+  return false;\n+}\n+#endif \/\/ ZERO\n+\n@@ -1548,1 +1161,0 @@\n-volatile intptr_t os::ThreadCrashProtection::_crash_mux = 0;\n@@ -1551,0 +1163,2 @@\n+  _protected_thread = Thread::current();\n+  assert(_protected_thread->is_JfrSampler_thread(), \"should be JFRSampler\");\n@@ -1562,5 +1176,0 @@\n-  Thread::muxAcquire(&_crash_mux, \"CrashProtection\");\n-\n-  _protected_thread = Thread::current_or_null();\n-  assert(_protected_thread != NULL, \"Cannot crash protect a NULL thread\");\n-\n@@ -1579,1 +1188,0 @@\n-    Thread::muxRelease(&_crash_mux);\n@@ -1586,1 +1194,0 @@\n-  Thread::muxRelease(&_crash_mux);\n@@ -1637,33 +1244,0 @@\n-sigset_t sigs;\n-struct sigaction sigact[NSIG];\n-\n-struct sigaction* os::Posix::get_preinstalled_handler(int sig) {\n-  if (sigismember(&sigs, sig)) {\n-    return &sigact[sig];\n-  }\n-  return NULL;\n-}\n-\n-void os::Posix::save_preinstalled_handler(int sig, struct sigaction& oldAct) {\n-  assert(sig > 0 && sig < NSIG, \"vm signal out of expected range\");\n-  sigact[sig] = oldAct;\n-  sigaddset(&sigs, sig);\n-}\n-\n-\/\/ Not all POSIX types and API's are available on all notionally \"posix\"\n-\/\/ platforms. If we have build-time support then we will check for actual\n-\/\/ runtime support via dlopen\/dlsym lookup. This allows for running on an\n-\/\/ older OS version compared to the build platform. But if there is no\n-\/\/ build time support then there cannot be any runtime support as we do not\n-\/\/ know what the runtime types would be (for example clockid_t might be an\n-\/\/ int or int64_t).\n-\/\/\n-#ifdef SUPPORTS_CLOCK_MONOTONIC\n-\n-\/\/ This means we have clockid_t, clock_gettime et al and CLOCK_MONOTONIC\n-\n-int (*os::Posix::_clock_gettime)(clockid_t, struct timespec *) = NULL;\n-int (*os::Posix::_clock_getres)(clockid_t, struct timespec *) = NULL;\n-\n-bool os::Posix::_supports_monotonic_clock = false;\n-\n@@ -1681,38 +1255,1 @@\n-  \/\/ 1. Check for CLOCK_MONOTONIC support.\n-\n-  void* handle = NULL;\n-\n-  \/\/ For older linux we need librt, for other OS we can find\n-  \/\/ this function in regular libc.\n-#ifdef NEEDS_LIBRT\n-  \/\/ We do dlopen's in this particular order due to bug in linux\n-  \/\/ dynamic loader (see 6348968) leading to crash on exit.\n-  handle = dlopen(\"librt.so.1\", RTLD_LAZY);\n-  if (handle == NULL) {\n-    handle = dlopen(\"librt.so\", RTLD_LAZY);\n-  }\n-#endif\n-\n-  if (handle == NULL) {\n-    handle = RTLD_DEFAULT;\n-  }\n-\n-  int (*clock_getres_func)(clockid_t, struct timespec*) =\n-    (int(*)(clockid_t, struct timespec*))dlsym(handle, \"clock_getres\");\n-  int (*clock_gettime_func)(clockid_t, struct timespec*) =\n-    (int(*)(clockid_t, struct timespec*))dlsym(handle, \"clock_gettime\");\n-  if (clock_getres_func != NULL && clock_gettime_func != NULL) {\n-    _clock_gettime = clock_gettime_func;\n-    _clock_getres = clock_getres_func;\n-    \/\/ We assume that if both clock_gettime and clock_getres support\n-    \/\/ CLOCK_MONOTONIC then the OS provides true high-res monotonic clock.\n-    struct timespec res;\n-    struct timespec tp;\n-    if (clock_getres_func(CLOCK_MONOTONIC, &res) == 0 &&\n-        clock_gettime_func(CLOCK_MONOTONIC, &tp) == 0) {\n-      \/\/ Yes, monotonic clock is supported.\n-      _supports_monotonic_clock = true;\n-    }\n-  }\n-\n-  \/\/ 2. Check for pthread_condattr_setclock support.\n+  \/\/ Check for pthread_condattr_setclock support.\n@@ -1733,1 +1270,1 @@\n-  if (_pthread_condattr_setclock != NULL && _clock_gettime != NULL) {\n+  if (_pthread_condattr_setclock != NULL) {\n@@ -1749,2 +1286,1 @@\n-  log_info(os)(\"Use of CLOCK_MONOTONIC is%s supported\",\n-               (_clock_gettime != NULL ? \"\" : \" not\"));\n+  log_info(os)(\"Use of CLOCK_MONOTONIC is supported\");\n@@ -1755,14 +1291,0 @@\n-  sigemptyset(&sigs);\n-}\n-\n-#else \/\/ !SUPPORTS_CLOCK_MONOTONIC\n-\n-void os::Posix::init(void) {\n-  pthread_init_common();\n-}\n-\n-void os::Posix::init_2(void) {\n-  log_info(os)(\"Use of CLOCK_MONOTONIC is not supported\");\n-  log_info(os)(\"Use of pthread_condattr_setclock is not supported\");\n-  log_info(os)(\"Relative timed-wait using pthread_cond_timedwait is associated with the default clock\");\n-  sigemptyset(&sigs);\n@@ -1771,2 +1293,0 @@\n-#endif \/\/ SUPPORTS_CLOCK_MONOTONIC\n-\n@@ -1824,1 +1344,0 @@\n-\/\/ This is only used with gettimeofday, when clock_gettime is not available.\n@@ -1859,17 +1378,3 @@\n-#ifdef SUPPORTS_CLOCK_MONOTONIC\n-\n-  \/\/ need to ensure we have a runtime check for clock_gettime support\n-  if (!isAbsolute && os::Posix::supports_monotonic_clock()) {\n-    if (!_use_clock_monotonic_condattr || isRealtime) {\n-      clock = CLOCK_REALTIME;\n-    }\n-    struct timespec now;\n-    int status = os::Posix::clock_gettime(clock, &now);\n-    assert_status(status == 0, status, \"clock_gettime\");\n-    calc_rel_time(abstime, timeout, now.tv_sec, now.tv_nsec, NANOUNITS);\n-    DEBUG_ONLY(max_secs += now.tv_sec;)\n-  } else {\n-\n-#else\n-\n-  { \/\/ Match the block scope.\n+  if (isAbsolute || (!_use_clock_monotonic_condattr || isRealtime)) {\n+    clock = CLOCK_REALTIME;\n+  }\n@@ -1878,1 +1383,3 @@\n-#endif \/\/ SUPPORTS_CLOCK_MONOTONIC\n+  struct timespec now;\n+  int status = clock_gettime(clock, &now);\n+  assert(status == 0, \"clock_gettime error: %s\", os::strerror(errno));\n@@ -1880,10 +1387,4 @@\n-    \/\/ Time-of-day clock is all we can reliably use.\n-    struct timeval now;\n-    int status = gettimeofday(&now, NULL);\n-    assert_status(status == 0, errno, \"gettimeofday\");\n-    if (isAbsolute) {\n-      unpack_abs_time(abstime, timeout, now.tv_sec);\n-    } else {\n-      calc_rel_time(abstime, timeout, now.tv_sec, now.tv_usec, MICROUNITS);\n-    }\n-    DEBUG_ONLY(max_secs += now.tv_sec;)\n+  if (!isAbsolute) {\n+    calc_rel_time(abstime, timeout, now.tv_sec, now.tv_nsec, NANOUNITS);\n+  } else {\n+    unpack_abs_time(abstime, timeout, now.tv_sec);\n@@ -1891,0 +1392,1 @@\n+  DEBUG_ONLY(max_secs += now.tv_sec;)\n@@ -1906,0 +1408,45 @@\n+\/\/ Common (partly) shared time functions\n+\n+jlong os::javaTimeMillis() {\n+  struct timespec ts;\n+  int status = clock_gettime(CLOCK_REALTIME, &ts);\n+  assert(status == 0, \"clock_gettime error: %s\", os::strerror(errno));\n+  return jlong(ts.tv_sec) * MILLIUNITS +\n+    jlong(ts.tv_nsec) \/ NANOUNITS_PER_MILLIUNIT;\n+}\n+\n+void os::javaTimeSystemUTC(jlong &seconds, jlong &nanos) {\n+  struct timespec ts;\n+  int status = clock_gettime(CLOCK_REALTIME, &ts);\n+  assert(status == 0, \"clock_gettime error: %s\", os::strerror(errno));\n+  seconds = jlong(ts.tv_sec);\n+  nanos = jlong(ts.tv_nsec);\n+}\n+\n+\/\/ macOS and AIX have platform specific implementations for javaTimeNanos()\n+\/\/ using native clock\/timer access APIs. These have historically worked well\n+\/\/ for those platforms, but it may be possible for them to switch to the\n+\/\/ generic clock_gettime mechanism in the future.\n+#if !defined(__APPLE__) && !defined(AIX)\n+\n+jlong os::javaTimeNanos() {\n+  struct timespec tp;\n+  int status = clock_gettime(CLOCK_MONOTONIC, &tp);\n+  assert(status == 0, \"clock_gettime error: %s\", os::strerror(errno));\n+  jlong result = jlong(tp.tv_sec) * NANOSECS_PER_SEC + jlong(tp.tv_nsec);\n+  return result;\n+}\n+\n+\/\/ for timer info max values which include all bits\n+#define ALL_64_BITS CONST64(0xFFFFFFFFFFFFFFFF)\n+\n+void os::javaTimeNanos_info(jvmtiTimerInfo *info_ptr) {\n+  \/\/ CLOCK_MONOTONIC - amount of time since some arbitrary point in the past\n+  info_ptr->max_value = ALL_64_BITS;\n+  info_ptr->may_skip_backward = false;      \/\/ not subject to resetting or drifting\n+  info_ptr->may_skip_forward = false;       \/\/ not subject to resetting or drifting\n+  info_ptr->kind = JVMTI_TIMER_ELAPSED;     \/\/ elapsed not CPU time\n+}\n+\n+#endif \/\/ ! APPLE && !AIX\n+\n@@ -2046,1 +1593,1 @@\n-  \/\/ Mutex\/Monitor, Thread::muxAcquire and JavaThread::sleep\n+  \/\/ Mutex\/Monitor, and JavaThread::sleep\n@@ -2073,3 +1620,2 @@\n- os::PlatformParker::PlatformParker() {\n-  int status;\n-  status = pthread_cond_init(&_cond[REL_INDEX], _condAttr);\n+ os::PlatformParker::PlatformParker() : _counter(0), _cur_index(-1) {\n+  int status = pthread_cond_init(&_cond[REL_INDEX], _condAttr);\n@@ -2081,1 +1627,9 @@\n-  _cur_index = -1; \/\/ mark as unused\n+}\n+\n+os::PlatformParker::~PlatformParker() {\n+  int status = pthread_cond_destroy(&_cond[REL_INDEX]);\n+  assert_status(status == 0, status, \"cond_destroy rel\");\n+  status = pthread_cond_destroy(&_cond[ABS_INDEX]);\n+  assert_status(status == 0, status, \"cond_destroy abs\");\n+  status = pthread_mutex_destroy(_mutex);\n+  assert_status(status == 0, status, \"mutex_destroy\");\n@@ -2098,3 +1652,1 @@\n-  Thread* thread = Thread::current();\n-  assert(thread->is_Java_thread(), \"Must be JavaThread\");\n-  JavaThread *jt = (JavaThread *)thread;\n+  JavaThread *jt = JavaThread::current();\n@@ -2145,3 +1697,1 @@\n-  OSThreadWaitState osts(thread->osthread(), false \/* not Object.wait() *\/);\n-  jt->set_suspend_equivalent();\n-  \/\/ cleared by handle_special_suspend_equivalent_condition() or java_suspend_self()\n+  OSThreadWaitState osts(jt->osthread(), false \/* not Object.wait() *\/);\n@@ -2170,5 +1720,0 @@\n-\n-  \/\/ If externally suspended while waiting, re-suspend\n-  if (jt->handle_special_suspend_equivalent_condition()) {\n-    jt->java_suspend_self();\n-  }\n@@ -2340,0 +1885,125 @@\n+\n+\/\/ Darwin has no \"environ\" in a dynamic library.\n+#ifdef __APPLE__\n+  #define environ (*_NSGetEnviron())\n+#else\n+  extern char** environ;\n+#endif\n+\n+char** os::get_environ() { return environ; }\n+\n+\/\/ Run the specified command in a separate process. Return its exit value,\n+\/\/ or -1 on failure (e.g. can't fork a new process).\n+\/\/ Notes: -Unlike system(), this function can be called from signal handler. It\n+\/\/         doesn't block SIGINT et al.\n+\/\/        -this function is unsafe to use in non-error situations, mainly\n+\/\/         because the child process will inherit all parent descriptors.\n+int os::fork_and_exec(const char* cmd, bool prefer_vfork) {\n+  const char * argv[4] = {\"sh\", \"-c\", cmd, NULL};\n+\n+  pid_t pid ;\n+\n+  char** env = os::get_environ();\n+\n+  \/\/ Use always vfork on AIX, since its safe and helps with analyzing OOM situations.\n+  \/\/ Otherwise leave it up to the caller.\n+  AIX_ONLY(prefer_vfork = true;)\n+  pid = prefer_vfork ? ::vfork() : ::fork();\n+\n+  if (pid < 0) {\n+    \/\/ fork failed\n+    return -1;\n+\n+  } else if (pid == 0) {\n+    \/\/ child process\n+\n+    ::execve(\"\/bin\/sh\", (char* const*)argv, env);\n+\n+    \/\/ execve failed\n+    ::_exit(-1);\n+\n+  } else  {\n+    \/\/ copied from J2SE ..._waitForProcessExit() in UNIXProcess_md.c; we don't\n+    \/\/ care about the actual exit code, for now.\n+\n+    int status;\n+\n+    \/\/ Wait for the child process to exit.  This returns immediately if\n+    \/\/ the child has already exited. *\/\n+    while (::waitpid(pid, &status, 0) < 0) {\n+      switch (errno) {\n+      case ECHILD: return 0;\n+      case EINTR: break;\n+      default: return -1;\n+      }\n+    }\n+\n+    if (WIFEXITED(status)) {\n+      \/\/ The child exited normally; get its exit code.\n+      return WEXITSTATUS(status);\n+    } else if (WIFSIGNALED(status)) {\n+      \/\/ The child exited because of a signal\n+      \/\/ The best value to return is 0x80 + signal number,\n+      \/\/ because that is what all Unix shells do, and because\n+      \/\/ it allows callers to distinguish between process exit and\n+      \/\/ process death by signal.\n+      return 0x80 + WTERMSIG(status);\n+    } else {\n+      \/\/ Unknown exit code; pass it through\n+      return status;\n+    }\n+  }\n+}\n+\n+\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\/\/ runtime exit support\n+\n+\/\/ Note: os::shutdown() might be called very early during initialization, or\n+\/\/ called from signal handler. Before adding something to os::shutdown(), make\n+\/\/ sure it is async-safe and can handle partially initialized VM.\n+void os::shutdown() {\n+\n+  \/\/ allow PerfMemory to attempt cleanup of any persistent resources\n+  perfMemory_exit();\n+\n+  \/\/ needs to remove object in file system\n+  AttachListener::abort();\n+\n+  \/\/ flush buffered output, finish log files\n+  ostream_abort();\n+\n+  \/\/ Check for abort hook\n+  abort_hook_t abort_hook = Arguments::abort_hook();\n+  if (abort_hook != NULL) {\n+    abort_hook();\n+  }\n+\n+}\n+\n+\/\/ Note: os::abort() might be called very early during initialization, or\n+\/\/ called from signal handler. Before adding something to os::abort(), make\n+\/\/ sure it is async-safe and can handle partially initialized VM.\n+\/\/ Also note we can abort while other threads continue to run, so we can\n+\/\/ easily trigger secondary faults in those threads. To reduce the likelihood\n+\/\/ of that we use _exit rather than exit, so that no atexit hooks get run.\n+\/\/ But note that os::shutdown() could also trigger secondary faults.\n+void os::abort(bool dump_core, void* siginfo, const void* context) {\n+  os::shutdown();\n+  if (dump_core) {\n+    LINUX_ONLY(if (DumpPrivateMappingsInCore) ClassLoader::close_jrt_image();)\n+    ::abort(); \/\/ dump core\n+  }\n+  ::_exit(1);\n+}\n+\n+\/\/ Die immediately, no exit hook, no abort hook, no cleanup.\n+\/\/ Dump a core file, if possible, for debugging.\n+void os::die() {\n+  if (TestUnresponsiveErrorHandler && !CreateCoredumpOnCrash) {\n+    \/\/ For TimeoutInErrorHandlingTest.java, we just kill the VM\n+    \/\/ and don't take the time to generate a core file.\n+    os::signal_raise(SIGKILL);\n+  } else {\n+    ::abort();\n+  }\n+}\n","filename":"src\/hotspot\/os\/posix\/os_posix.cpp","additions":468,"deletions":798,"binary":false,"changes":1266,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,2 +28,0 @@\n-#include \"classfile\/classLoader.hpp\"\n-#include \"classfile\/systemDictionary.hpp\"\n@@ -40,2 +38,0 @@\n-#include \"runtime\/arguments.hpp\"\n-#include \"runtime\/extendedPC.hpp\"\n@@ -53,0 +49,1 @@\n+#include \"signals_posix.hpp\"\n@@ -109,1 +106,1 @@\n-address os::Linux::ucontext_get_pc(const ucontext_t * uc) {\n+address os::Posix::ucontext_get_pc(const ucontext_t * uc) {\n@@ -113,1 +110,1 @@\n-void os::Linux::ucontext_set_pc(ucontext_t * uc, address pc) {\n+void os::Posix::ucontext_set_pc(ucontext_t * uc, address pc) {\n@@ -125,17 +122,1 @@\n-\/\/ For Forte Analyzer AsyncGetCallTrace profiling support - thread\n-\/\/ is currently interrupted by SIGPROF.\n-\/\/ os::Solaris::fetch_frame_from_ucontext() tries to skip nested signal\n-\/\/ frames. Currently we don't do that on Linux, so it's the same as\n-\/\/ os::fetch_frame_from_context().\n-\/\/ This method is also used for stack overflow signal handling.\n-ExtendedPC os::Linux::fetch_frame_from_ucontext(Thread* thread,\n-  const ucontext_t* uc, intptr_t** ret_sp, intptr_t** ret_fp) {\n-\n-  assert(thread != NULL, \"just checking\");\n-  assert(ret_sp != NULL, \"just checking\");\n-  assert(ret_fp != NULL, \"just checking\");\n-\n-  return os::fetch_frame_from_context(uc, ret_sp, ret_fp);\n-}\n-\n-ExtendedPC os::fetch_frame_from_context(const void* ucVoid,\n+address os::fetch_frame_from_context(const void* ucVoid,\n@@ -144,1 +125,1 @@\n-  ExtendedPC  epc;\n+  address epc;\n@@ -148,1 +129,1 @@\n-    epc = ExtendedPC(os::Linux::ucontext_get_pc(uc));\n+    epc = os::Posix::ucontext_get_pc(uc);\n@@ -152,2 +133,1 @@\n-    \/\/ construct empty ExtendedPC for return value checking\n-    epc = ExtendedPC(NULL);\n+    epc = NULL;\n@@ -164,9 +144,2 @@\n-  ExtendedPC epc = fetch_frame_from_context(ucVoid, &sp, &fp);\n-  return frame(sp, fp, epc.pc());\n-}\n-\n-frame os::fetch_frame_from_ucontext(Thread* thread, void* ucVoid) {\n-  intptr_t* sp;\n-  intptr_t* fp;\n-  ExtendedPC epc = os::Linux::fetch_frame_from_ucontext(thread, (ucontext_t*)ucVoid, &sp, &fp);\n-  return frame(sp, fp, epc.pc());\n+  address epc = fetch_frame_from_context(ucVoid, &sp, &fp);\n+  return frame(sp, fp, epc);\n@@ -175,37 +148,5 @@\n-bool os::Linux::get_frame_at_stack_banging_point(JavaThread* thread, ucontext_t* uc, frame* fr) {\n-  address pc = (address) os::Linux::ucontext_get_pc(uc);\n-  if (Interpreter::contains(pc)) {\n-    \/\/ interpreter performs stack banging after the fixed frame header has\n-    \/\/ been generated while the compilers perform it before. To maintain\n-    \/\/ semantic consistency between interpreted and compiled frames, the\n-    \/\/ method returns the Java sender of the current frame.\n-    *fr = os::fetch_frame_from_ucontext(thread, uc);\n-    if (!fr->is_first_java_frame()) {\n-      \/\/ get_frame_at_stack_banging_point() is only called when we\n-      \/\/ have well defined stacks so java_sender() calls do not need\n-      \/\/ to assert safe_for_sender() first.\n-      *fr = fr->java_sender();\n-    }\n-  } else {\n-    \/\/ more complex code with compiled code\n-    assert(!Interpreter::contains(pc), \"Interpreted methods should have been handled above\");\n-    CodeBlob* cb = CodeCache::find_blob(pc);\n-    if (cb == NULL || !cb->is_nmethod() || cb->is_frame_complete_at(pc)) {\n-      \/\/ Not sure where the pc points to, fallback to default\n-      \/\/ stack overflow handling\n-      return false;\n-    } else {\n-      \/\/ in compiled code, the stack banging is performed just after the return pc\n-      \/\/ has been pushed on the stack\n-      intptr_t* fp = os::Linux::ucontext_get_fp(uc);\n-      intptr_t* sp = os::Linux::ucontext_get_sp(uc);\n-      *fr = frame(sp + 1, fp, (address)*sp);\n-      if (!fr->is_java_frame()) {\n-        assert(!fr->is_first_frame(), \"Safety check\");\n-        \/\/ See java_sender() comment above.\n-        *fr = fr->java_sender();\n-      }\n-    }\n-  }\n-  assert(fr->is_java_frame(), \"Safety check\");\n-  return true;\n+frame os::fetch_compiled_frame_from_context(const void* ucVoid) {\n+  const ucontext_t* uc = (const ucontext_t*)ucVoid;\n+  intptr_t* fp = os::Linux::ucontext_get_fp(uc);\n+  intptr_t* sp = os::Linux::ucontext_get_sp(uc);\n+  return frame(sp + 1, fp, (address)*sp);\n@@ -259,39 +200,2 @@\n-extern \"C\" JNIEXPORT int\n-JVM_handle_linux_signal(int sig,\n-                        siginfo_t* info,\n-                        void* ucVoid,\n-                        int abort_if_unrecognized) {\n-  ucontext_t* uc = (ucontext_t*) ucVoid;\n-\n-  Thread* t = Thread::current_or_null_safe();\n-\n-  \/\/ Must do this before SignalHandlerMark, if crash protection installed we will longjmp away\n-  \/\/ (no destructors can be run)\n-  os::ThreadCrashProtection::check_crash_protection(sig, t);\n-\n-  SignalHandlerMark shm(t);\n-\n-  \/\/ Note: it's not uncommon that JNI code uses signal\/sigset to install\n-  \/\/ then restore certain signal handler (e.g. to temporarily block SIGPIPE,\n-  \/\/ or have a SIGILL handler when detecting CPU type). When that happens,\n-  \/\/ JVM_handle_linux_signal() might be invoked with junk info\/ucVoid. To\n-  \/\/ avoid unnecessary crash when libjsig is not preloaded, try handle signals\n-  \/\/ that do not require siginfo\/ucontext first.\n-\n-  if (sig == SIGPIPE || sig == SIGXFSZ) {\n-    \/\/ allow chained handler to go first\n-    if (os::Linux::chained_handler(sig, info, ucVoid)) {\n-      return true;\n-    } else {\n-      \/\/ Ignoring SIGPIPE\/SIGXFSZ - see bugs 4229104 or 6499219\n-      return true;\n-    }\n-  }\n-\n-#ifdef CAN_SHOW_REGISTERS_ON_ASSERT\n-  if ((sig == SIGSEGV || sig == SIGBUS) && info != NULL && info->si_addr == g_assert_poison) {\n-    if (handle_assert_poison_fault(ucVoid, info->si_addr)) {\n-      return 1;\n-    }\n-  }\n-#endif\n+bool PosixSignals::pd_hotspot_signal_handler(int sig, siginfo_t* info,\n+                                             ucontext_t* uc, JavaThread* thread) {\n@@ -299,13 +203,1 @@\n-  JavaThread* thread = NULL;\n-  VMThread* vmthread = NULL;\n-  if (os::Linux::signal_handlers_are_installed) {\n-    if (t != NULL ){\n-      if(t->is_Java_thread()) {\n-        thread = (JavaThread*)t;\n-      }\n-      else if(t->is_VM_thread()){\n-        vmthread = (VMThread *)t;\n-      }\n-    }\n-  }\n-\/*\n+  \/*\n@@ -327,6 +219,1 @@\n-    pc = (address) os::Linux::ucontext_get_pc(uc);\n-\n-    if (StubRoutines::is_safefetch_fault(pc)) {\n-      os::Linux::ucontext_set_pc(uc, StubRoutines::continuation_for_safefetch_fault(pc));\n-      return 1;\n-    }\n+    pc = (address) os::Posix::ucontext_get_pc(uc);\n@@ -351,54 +238,2 @@\n-        if (thread->in_stack_yellow_reserved_zone(addr)) {\n-          if (thread->thread_state() == _thread_in_Java) {\n-            if (thread->in_stack_reserved_zone(addr)) {\n-              frame fr;\n-              if (os::Linux::get_frame_at_stack_banging_point(thread, uc, &fr)) {\n-                assert(fr.is_java_frame(), \"Must be a Java frame\");\n-                frame activation =\n-                  SharedRuntime::look_for_reserved_stack_annotated_method(thread, fr);\n-                if (activation.sp() != NULL) {\n-                  thread->disable_stack_reserved_zone();\n-                  if (activation.is_interpreted_frame()) {\n-                    thread->set_reserved_stack_activation((address)(\n-                      activation.fp() + frame::interpreter_frame_initial_sp_offset));\n-                  } else {\n-                    thread->set_reserved_stack_activation((address)activation.unextended_sp());\n-                  }\n-                  return 1;\n-                }\n-              }\n-            }\n-            \/\/ Throw a stack overflow exception.  Guard pages will be reenabled\n-            \/\/ while unwinding the stack.\n-            thread->disable_stack_yellow_reserved_zone();\n-            stub = SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::STACK_OVERFLOW);\n-          } else {\n-            \/\/ Thread was in the vm or native code.  Return and try to finish.\n-            thread->disable_stack_yellow_reserved_zone();\n-            return 1;\n-          }\n-        } else if (thread->in_stack_red_zone(addr)) {\n-          \/\/ Fatal red zone violation.  Disable the guard pages and fall through\n-          \/\/ to handle_unexpected_exception way down below.\n-          thread->disable_stack_red_zone();\n-          tty->print_raw_cr(\"An irrecoverable stack overflow has occurred.\");\n-\n-          \/\/ This is a likely cause, but hard to verify. Let's just print\n-          \/\/ it as a hint.\n-          tty->print_raw_cr(\"Please check if any of your loaded .so files has \"\n-                            \"enabled executable stack (see man page execstack(8))\");\n-        } else {\n-          \/\/ Accessing stack address below sp may cause SEGV if current\n-          \/\/ thread has MAP_GROWSDOWN stack. This should only happen when\n-          \/\/ current thread was created by user code with MAP_GROWSDOWN flag\n-          \/\/ and then attached to VM. See notes in os_linux.cpp.\n-          if (thread->osthread()->expanding_stack() == 0) {\n-             thread->osthread()->set_expanding_stack();\n-             if (os::Linux::manually_expand_stack(thread, addr)) {\n-               thread->osthread()->clear_expanding_stack();\n-               return 1;\n-             }\n-             thread->osthread()->clear_expanding_stack();\n-          } else {\n-             fatal(\"recursive segv. expanding stack.\");\n-          }\n+        if (os::Posix::handle_stack_overflow(thread, addr, pc, uc, &stub)) {\n+          return true; \/\/ continue\n@@ -452,1 +287,1 @@\n-          \/\/ TODO: The encoding of D2I in i486.ad can cause an exception\n+          \/\/ TODO: The encoding of D2I in x86_32.ad can cause an exception\n@@ -511,0 +346,1 @@\n+      stub == NULL &&\n@@ -515,1 +351,1 @@\n-    address pc = os::Linux::ucontext_get_pc(uc);\n+    address pc = os::Posix::ucontext_get_pc(uc);\n@@ -577,1 +413,1 @@\n-    os::Linux::ucontext_set_pc(uc, stub);\n+    os::Posix::ucontext_set_pc(uc, stub);\n@@ -581,24 +417,1 @@\n-  \/\/ signal-chaining\n-  if (os::Linux::chained_handler(sig, info, ucVoid)) {\n-     return true;\n-  }\n-\n-  if (!abort_if_unrecognized) {\n-    \/\/ caller wants another chance, so give it to him\n-    return false;\n-  }\n-\n-  if (pc == NULL && uc != NULL) {\n-    pc = os::Linux::ucontext_get_pc(uc);\n-  }\n-\n-  \/\/ unmask current signal\n-  sigset_t newset;\n-  sigemptyset(&newset);\n-  sigaddset(&newset, sig);\n-  sigprocmask(SIG_UNBLOCK, &newset, NULL);\n-\n-  VMError::report_and_die(t, sig, pc, info, ucVoid);\n-\n-  ShouldNotReachHere();\n-  return true; \/\/ Mute compiler\n+  return false;\n@@ -648,14 +461,16 @@\n-bool os::is_allocatable(size_t bytes) {\n-#ifdef AMD64\n-  \/\/ unused on amd64?\n-  return true;\n-#else\n-\n-  if (bytes < 2 * G) {\n-    return true;\n-  }\n-\n-  char* addr = reserve_memory(bytes, NULL);\n-\n-  if (addr != NULL) {\n-    release_memory(addr, bytes);\n+juint os::cpu_microcode_revision() {\n+  juint result = 0;\n+  char data[2048] = {0}; \/\/ lines should fit in 2K buf\n+  size_t len = sizeof(data);\n+  FILE *fp = fopen(\"\/proc\/cpuinfo\", \"r\");\n+  if (fp) {\n+    while (!feof(fp)) {\n+      if (fgets(data, len, fp)) {\n+        if (strstr(data, \"microcode\") != NULL) {\n+          char* rev = strchr(data, ':');\n+          if (rev != NULL) sscanf(rev + 1, \"%x\", &result);\n+          break;\n+        }\n+      }\n+    }\n+    fclose(fp);\n@@ -663,3 +478,1 @@\n-\n-  return addr != NULL;\n-#endif \/\/ AMD64\n+  return result;\n@@ -753,1 +566,1 @@\n-  address pc = os::Linux::ucontext_get_pc(uc);\n+  address pc = os::Posix::ucontext_get_pc(uc);\n@@ -805,1 +618,1 @@\n-  address fpu_cntrl = StubRoutines::addr_fpu_cntrl_wrd_std();\n+  address fpu_cntrl = StubRoutines::x86::addr_fpu_cntrl_wrd_std();\n@@ -845,2 +658,2 @@\n-      limit += JavaThread::stack_red_zone_size() +\n-        JavaThread::stack_yellow_zone_size();\n+      limit += StackOverflow::stack_red_zone_size() +\n+               StackOverflow::stack_yellow_zone_size();\n@@ -867,2 +680,2 @@\n-                       (JavaThread::stack_guard_zone_size() + page_size));\n-  char* codebuf = os::attempt_reserve_memory_at(page_size, hint);\n+                       (StackOverflow::stack_guard_zone_size() + page_size));\n+  char* codebuf = os::attempt_reserve_memory_at(hint, page_size);\n@@ -876,1 +689,1 @@\n-    codebuf = os::attempt_reserve_memory_at(page_size, hint);\n+    codebuf = os::attempt_reserve_memory_at(hint, page_size);\n","filename":"src\/hotspot\/os_cpu\/linux_x86\/os_linux_x86.cpp","additions":50,"deletions":237,"binary":false,"changes":287,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,1 +26,0 @@\n-#include \"aot\/aotLoader.hpp\"\n@@ -31,0 +30,1 @@\n+#include \"classfile\/classLoadInfo.hpp\"\n@@ -32,1 +32,0 @@\n-#include \"classfile\/dictionary.hpp\"\n@@ -44,0 +43,1 @@\n+#include \"classfile\/vmClasses.hpp\"\n@@ -55,1 +55,1 @@\n-#include \"oops\/instanceKlass.hpp\"\n+#include \"oops\/instanceKlass.inline.hpp\"\n@@ -81,0 +81,1 @@\n+#include \"utilities\/formatBuffer.hpp\"\n@@ -138,0 +139,4 @@\n+#define JAVA_16_VERSION                   60\n+\n+#define JAVA_17_VERSION                   61\n+\n@@ -215,1 +220,2 @@\n-            tag, CHECK);\n+            tag, THREAD);\n+          return;\n@@ -237,1 +243,2 @@\n-              tag, CHECK);\n+              tag, THREAD);\n+          return;\n@@ -252,1 +259,2 @@\n-              tag, CHECK);\n+              tag, THREAD);\n+          return;\n@@ -320,12 +328,0 @@\n-        if (has_cp_patch_at(index)) {\n-          Handle patch = clear_cp_patch_at(index);\n-          guarantee_property(java_lang_String::is_instance(patch()),\n-                             \"Illegal utf8 patch at %d in class file %s\",\n-                             index,\n-                             CHECK);\n-          const char* const str = java_lang_String::as_utf8_string(patch());\n-          \/\/ (could use java_lang_String::as_symbol instead, but might as well batch them)\n-          utf8_buffer = (const u1*) str;\n-          utf8_length = (u2) strlen(str);\n-        }\n-\n@@ -371,2 +367,2 @@\n-                              CHECK);\n-        break;\n+                              THREAD);\n+        return;\n@@ -565,1 +561,2 @@\n-              index, CHECK);\n+              index, THREAD);\n+            return;\n@@ -613,31 +610,1 @@\n-  _first_patched_klass_resolved_index = num_klasses;\n-  cp->allocate_resolved_klasses(_loader_data, num_klasses + _max_num_patched_klasses, CHECK);\n-\n-  if (_cp_patches != NULL) {\n-    \/\/ need to treat this_class specially...\n-\n-    \/\/ Add dummy utf8 entries in the space reserved for names of patched classes. We'll use \"*\"\n-    \/\/ for now. These will be replaced with actual names of the patched classes in patch_class().\n-    Symbol* s = vmSymbols::star_name();\n-    for (int n=_orig_cp_size; n<cp->length(); n++) {\n-      cp->symbol_at_put(n, s);\n-    }\n-\n-    int this_class_index;\n-    {\n-      stream->guarantee_more(8, CHECK);  \/\/ flags, this_class, super_class, infs_len\n-      const u1* const mark = stream->current();\n-      stream->skip_u2_fast(1); \/\/ skip flags\n-      this_class_index = stream->get_u2_fast();\n-      stream->set_current(mark);  \/\/ revert to mark\n-    }\n-\n-    for (index = 1; index < length; index++) {          \/\/ Index 0 is unused\n-      if (has_cp_patch_at(index)) {\n-        guarantee_property(index != this_class_index,\n-          \"Illegal constant pool patch to self at %d in class file %s\",\n-          index, CHECK);\n-        patch_constant_pool(cp, index, cp_patch_at(index), CHECK);\n-      }\n-    }\n-  }\n+  cp->allocate_resolved_klasses(_loader_data, num_klasses, CHECK);\n@@ -656,1 +623,1 @@\n-        \/\/ check the name, even if _cp_patches will overwrite it\n+        \/\/ check the name\n@@ -743,1 +710,2 @@\n-              name_ref_index, CHECK);\n+              name_ref_index, THREAD);\n+            return;\n@@ -765,1 +733,2 @@\n-                    name_ref_index, CHECK);\n+                    name_ref_index, THREAD);\n+                return;\n@@ -771,1 +740,2 @@\n-                  name_ref_index, CHECK);\n+                  name_ref_index, THREAD);\n+                return;\n@@ -793,82 +763,0 @@\n-Handle ClassFileParser::clear_cp_patch_at(int index) {\n-  Handle patch = cp_patch_at(index);\n-  _cp_patches->at_put(index, Handle());\n-  assert(!has_cp_patch_at(index), \"\");\n-  return patch;\n-}\n-\n-void ClassFileParser::patch_class(ConstantPool* cp, int class_index, Klass* k, Symbol* name) {\n-  int name_index = _orig_cp_size + _num_patched_klasses;\n-  int resolved_klass_index = _first_patched_klass_resolved_index + _num_patched_klasses;\n-\n-  cp->klass_at_put(class_index, name_index, resolved_klass_index, k, name);\n-  _num_patched_klasses ++;\n-}\n-\n-void ClassFileParser::patch_constant_pool(ConstantPool* cp,\n-                                          int index,\n-                                          Handle patch,\n-                                          TRAPS) {\n-  assert(cp != NULL, \"invariant\");\n-\n-  BasicType patch_type = T_VOID;\n-\n-  switch (cp->tag_at(index).value()) {\n-\n-    case JVM_CONSTANT_UnresolvedClass: {\n-      \/\/ Patching a class means pre-resolving it.\n-      \/\/ The name in the constant pool is ignored.\n-      if (java_lang_Class::is_instance(patch())) {\n-        guarantee_property(!java_lang_Class::is_primitive(patch()),\n-                           \"Illegal class patch at %d in class file %s\",\n-                           index, CHECK);\n-        Klass* k = java_lang_Class::as_Klass(patch());\n-        patch_class(cp, index, k, k->name());\n-      } else {\n-        guarantee_property(java_lang_String::is_instance(patch()),\n-                           \"Illegal class patch at %d in class file %s\",\n-                           index, CHECK);\n-        Symbol* const name = java_lang_String::as_symbol(patch());\n-        patch_class(cp, index, NULL, name);\n-      }\n-      break;\n-    }\n-\n-    case JVM_CONSTANT_String: {\n-      \/\/ skip this patch and don't clear it.  Needs the oop array for resolved\n-      \/\/ references to be created first.\n-      return;\n-    }\n-    case JVM_CONSTANT_Integer: patch_type = T_INT;    goto patch_prim;\n-    case JVM_CONSTANT_Float:   patch_type = T_FLOAT;  goto patch_prim;\n-    case JVM_CONSTANT_Long:    patch_type = T_LONG;   goto patch_prim;\n-    case JVM_CONSTANT_Double:  patch_type = T_DOUBLE; goto patch_prim;\n-    patch_prim:\n-    {\n-      jvalue value;\n-      BasicType value_type = java_lang_boxing_object::get_value(patch(), &value);\n-      guarantee_property(value_type == patch_type,\n-                         \"Illegal primitive patch at %d in class file %s\",\n-                         index, CHECK);\n-      switch (value_type) {\n-        case T_INT:    cp->int_at_put(index,   value.i); break;\n-        case T_FLOAT:  cp->float_at_put(index, value.f); break;\n-        case T_LONG:   cp->long_at_put(index,  value.j); break;\n-        case T_DOUBLE: cp->double_at_put(index, value.d); break;\n-        default:       assert(false, \"\");\n-      }\n-    } \/\/ end patch_prim label\n-    break;\n-\n-    default: {\n-      \/\/ %%% TODO: put method handles into CONSTANT_InterfaceMethodref, etc.\n-      guarantee_property(!has_cp_patch_at(index),\n-                         \"Illegal unexpected patch at %d in class file %s\",\n-                         index, CHECK);\n-      return;\n-    }\n-  } \/\/ end of switch(tag)\n-\n-  \/\/ On fall-through, mark the patch as used.\n-  clear_cp_patch_at(index);\n-}\n@@ -960,1 +848,1 @@\n-        \/\/ Call resolve_super so classcircularity is checked\n+        \/\/ Call resolve_super so class circularity is checked\n@@ -1010,1 +898,1 @@\n-                             name->as_C_string(), CHECK);\n+                             name->as_C_string(), THREAD);\n@@ -1066,1 +954,1 @@\n-                             CHECK);\n+                             THREAD);\n@@ -1082,1 +970,2 @@\n-    _method_HotSpotIntrinsicCandidate,\n+    _method_Scoped,\n+    _method_IntrinsicCandidate,\n@@ -1087,0 +976,1 @@\n+    _jdk_internal_ValueBased,\n@@ -1094,1 +984,1 @@\n-    : _location(location), _annotations_present(0)\n+    : _location(location), _annotations_present(0), _contended_group(0)\n@@ -1237,2 +1127,1 @@\n-                              const bool can_access_vm_annotations,\n-                              TRAPS) {\n+                              const bool can_access_vm_annotations) {\n@@ -1359,1 +1248,2 @@\n-        classfile_parse_error(\"Duplicate ConstantValue attribute in class file %s\", CHECK);\n+        classfile_parse_error(\"Duplicate ConstantValue attribute in class file %s\", THREAD);\n+        return;\n@@ -1374,1 +1264,2 @@\n-          attribute_length, CHECK);\n+          attribute_length, THREAD);\n+        return;\n@@ -1381,1 +1272,2 @@\n-          attribute_length, CHECK);\n+          attribute_length, THREAD);\n+        return;\n@@ -1387,1 +1279,2 @@\n-            \"Multiple Signature attributes for field in class file %s\", CHECK);\n+            \"Multiple Signature attributes for field in class file %s\", THREAD);\n+          return;\n@@ -1392,1 +1285,2 @@\n-            attribute_length, CHECK);\n+            attribute_length, THREAD);\n+          return;\n@@ -1398,1 +1292,2 @@\n-            \"Multiple RuntimeVisibleAnnotations attributes for field in class file %s\", CHECK);\n+            \"Multiple RuntimeVisibleAnnotations attributes for field in class file %s\", THREAD);\n+          return;\n@@ -1409,2 +1304,1 @@\n-                          _can_access_vm_annotations,\n-                          CHECK);\n+                          _can_access_vm_annotations);\n@@ -1415,1 +1309,2 @@\n-            \"Multiple RuntimeInvisibleAnnotations attributes for field in class file %s\", CHECK);\n+            \"Multiple RuntimeInvisibleAnnotations attributes for field in class file %s\", THREAD);\n+          return;\n@@ -1427,1 +1322,2 @@\n-            \"Multiple RuntimeVisibleTypeAnnotations attributes for field in class file %s\", CHECK);\n+            \"Multiple RuntimeVisibleTypeAnnotations attributes for field in class file %s\", THREAD);\n+          return;\n@@ -1436,1 +1332,2 @@\n-            \"Multiple RuntimeInvisibleTypeAnnotations attributes for field in class file %s\", CHECK);\n+            \"Multiple RuntimeInvisibleTypeAnnotations attributes for field in class file %s\", THREAD);\n+          return;\n@@ -1550,1 +1447,1 @@\n-  FieldAllocationType update(bool is_static, BasicType type) {\n+  void update(bool is_static, BasicType type) {\n@@ -1557,1 +1454,0 @@\n-    return atype;\n@@ -1697,3 +1593,2 @@\n-    \/\/ Remember how many oops we encountered and compute allocation type\n-    const FieldAllocationType atype = fac->update(is_static, type);\n-    field->set_allocation_type(atype);\n+    \/\/ Update FieldAllocationCount for this kind of field\n+    fac->update(is_static, type);\n@@ -1742,3 +1637,3 @@\n-      field->initialize(JVM_ACC_FIELD_INTERNAL,\n-                        injected[n].name_index,\n-                        injected[n].signature_index,\n+      field->initialize((u2)JVM_ACC_FIELD_INTERNAL,\n+                        (u2)(injected[n].name_index),\n+                        (u2)(injected[n].signature_index),\n@@ -1749,3 +1644,2 @@\n-      \/\/ Remember how many oops we encountered and compute allocation type\n-      const FieldAllocationType atype = fac->update(false, type);\n-      field->set_allocation_type(atype);\n+      \/\/ Update FieldAllocationCount for this kind of field\n+      fac->update(false, type);\n@@ -1801,1 +1695,1 @@\n-                             name->as_C_string(), sig->as_klass_external_name(), CHECK);\n+                             name->as_C_string(), sig->as_klass_external_name(), THREAD);\n@@ -1969,1 +1863,2 @@\n-          start_pc, tbl_name, CHECK_NULL);\n+          start_pc, tbl_name, THREAD);\n+        return NULL;\n@@ -1974,1 +1869,2 @@\n-          length, tbl_name, CHECK_NULL);\n+          length, tbl_name, THREAD);\n+        return NULL;\n@@ -2082,1 +1978,1 @@\n-  const vmSymbols::SID sid = vmSymbols::find_sid(name);\n+  const vmSymbolID sid = vmSymbols::find_sid(name);\n@@ -2088,1 +1984,1 @@\n-    case vmSymbols::VM_SYMBOL_ENUM_NAME(reflect_CallerSensitive_signature): {\n+    case VM_SYMBOL_ENUM_NAME(reflect_CallerSensitive_signature): {\n@@ -2093,1 +1989,1 @@\n-    case vmSymbols::VM_SYMBOL_ENUM_NAME(jdk_internal_vm_annotation_ForceInline_signature): {\n+    case VM_SYMBOL_ENUM_NAME(jdk_internal_vm_annotation_ForceInline_signature): {\n@@ -2098,1 +1994,1 @@\n-    case vmSymbols::VM_SYMBOL_ENUM_NAME(jdk_internal_vm_annotation_DontInline_signature): {\n+    case VM_SYMBOL_ENUM_NAME(jdk_internal_vm_annotation_DontInline_signature): {\n@@ -2103,1 +1999,1 @@\n-    case vmSymbols::VM_SYMBOL_ENUM_NAME(java_lang_invoke_InjectedProfile_signature): {\n+    case VM_SYMBOL_ENUM_NAME(java_lang_invoke_InjectedProfile_signature): {\n@@ -2108,1 +2004,1 @@\n-    case vmSymbols::VM_SYMBOL_ENUM_NAME(java_lang_invoke_LambdaForm_Compiled_signature): {\n+    case VM_SYMBOL_ENUM_NAME(java_lang_invoke_LambdaForm_Compiled_signature): {\n@@ -2113,1 +2009,1 @@\n-    case vmSymbols::VM_SYMBOL_ENUM_NAME(jdk_internal_vm_annotation_Hidden_signature): {\n+    case VM_SYMBOL_ENUM_NAME(jdk_internal_vm_annotation_Hidden_signature): {\n@@ -2118,1 +2014,1 @@\n-    case vmSymbols::VM_SYMBOL_ENUM_NAME(jdk_internal_HotSpotIntrinsicCandidate_signature): {\n+    case VM_SYMBOL_ENUM_NAME(jdk_internal_misc_Scoped_signature): {\n@@ -2121,1 +2017,1 @@\n-      return _method_HotSpotIntrinsicCandidate;\n+      return _method_Scoped;\n@@ -2123,1 +2019,6 @@\n-    case vmSymbols::VM_SYMBOL_ENUM_NAME(jdk_internal_vm_annotation_Stable_signature): {\n+    case VM_SYMBOL_ENUM_NAME(jdk_internal_vm_annotation_IntrinsicCandidate_signature): {\n+      if (_location != _in_method)  break;  \/\/ only allow for methods\n+      if (!privileged)              break;  \/\/ only allow in privileged code\n+      return _method_IntrinsicCandidate;\n+    }\n+    case VM_SYMBOL_ENUM_NAME(jdk_internal_vm_annotation_Stable_signature): {\n@@ -2128,1 +2029,1 @@\n-    case vmSymbols::VM_SYMBOL_ENUM_NAME(jdk_internal_vm_annotation_Contended_signature): {\n+    case VM_SYMBOL_ENUM_NAME(jdk_internal_vm_annotation_Contended_signature): {\n@@ -2137,1 +2038,1 @@\n-    case vmSymbols::VM_SYMBOL_ENUM_NAME(jdk_internal_vm_annotation_ReservedStackAccess_signature): {\n+    case VM_SYMBOL_ENUM_NAME(jdk_internal_vm_annotation_ReservedStackAccess_signature): {\n@@ -2143,1 +2044,1 @@\n-    case vmSymbols::VM_SYMBOL_ENUM_NAME(java_util_concurrent_annotation_LazyInit): {\n+    case VM_SYMBOL_ENUM_NAME(java_util_concurrent_annotation_LazyInit): {\n@@ -2150,0 +2051,5 @@\n+    case VM_SYMBOL_ENUM_NAME(jdk_internal_ValueBased_signature): {\n+      if (_location != _in_class)   break;  \/\/ only allow for classes\n+      if (!privileged)              break;  \/\/ only allow in priviledged code\n+      return _jdk_internal_ValueBased;\n+    }\n@@ -2188,1 +2094,3 @@\n-  if (has_annotation(_method_HotSpotIntrinsicCandidate) && !m->is_synthetic())\n+  if (has_annotation(_method_Scoped))\n+    m->set_scoped(true);\n+  if (has_annotation(_method_IntrinsicCandidate) && !m->is_synthetic())\n@@ -2196,1 +2104,10 @@\n-  ik->set_is_contended(is_contended());\n+  if (has_annotation(_jdk_internal_vm_annotation_Contended)) {\n+    ik->set_is_contended(is_contended());\n+  }\n+  if (has_annotation(_jdk_internal_ValueBased)) {\n+    ik->set_has_value_based_class_annotation();\n+    if (DiagnoseSyncOnValueBasedClasses) {\n+      ik->set_is_value_based();\n+      ik->set_prototype_header(markWord::prototype());\n+    }\n+  }\n@@ -2247,1 +2164,2 @@\n-                               CHECK);\n+                               THREAD);\n+        return;\n@@ -2266,1 +2184,2 @@\n-                                 CHECK);\n+                                 THREAD);\n+          return;\n@@ -2272,1 +2191,2 @@\n-                               CHECK);\n+                               THREAD);\n+        return;\n@@ -2388,1 +2308,1 @@\n-      flags &= JVM_ACC_STATIC | JVM_ACC_STRICT;\n+      flags &= JVM_ACC_STATIC | (_major_version <= JAVA_16_VERSION ? JVM_ACC_STRICT : 0);\n@@ -2390,1 +2310,2 @@\n-      classfile_parse_error(\"Method <clinit> is not static in class file %s\", CHECK_NULL);\n+      classfile_parse_error(\"Method <clinit> is not static in class file %s\", THREAD);\n+      return NULL;\n@@ -2397,1 +2318,2 @@\n-    classfile_parse_error(\"Interface cannot have a method named <init>, class file %s\", CHECK_NULL);\n+    classfile_parse_error(\"Interface cannot have a method named <init>, class file %s\", THREAD);\n+    return NULL;\n@@ -2405,1 +2327,2 @@\n-      classfile_parse_error(\"Too many arguments in method signature in class file %s\", CHECK_NULL);\n+      classfile_parse_error(\"Too many arguments in method signature in class file %s\", THREAD);\n+      return NULL;\n@@ -2484,1 +2407,2 @@\n-                              CHECK_NULL);\n+                              THREAD);\n+        return NULL;\n@@ -2616,1 +2540,2 @@\n-            classfile_parse_error(\"Multiple StackMapTable attributes in class file %s\", CHECK_NULL);\n+            classfile_parse_error(\"Multiple StackMapTable attributes in class file %s\", THREAD);\n+            return NULL;\n@@ -2636,1 +2561,2 @@\n-                              CHECK_NULL);\n+                              THREAD);\n+        return NULL;\n@@ -2648,1 +2574,2 @@\n-                              CHECK_NULL);\n+                              THREAD);\n+        return NULL;\n@@ -2656,1 +2583,2 @@\n-          method_attribute_length, CHECK_NULL);\n+          method_attribute_length, THREAD);\n+        return NULL;\n@@ -2662,1 +2590,1 @@\n-      if (!SystemDictionary::Parameter_klass_loaded())\n+      if (!vmClasses::Parameter_klass_loaded())\n@@ -2668,1 +2596,2 @@\n-          method_attribute_length, CHECK_NULL);\n+          method_attribute_length, THREAD);\n+        return NULL;\n@@ -2676,1 +2605,2 @@\n-          method_attribute_length, CHECK_NULL);\n+          method_attribute_length, THREAD);\n+        return NULL;\n@@ -2683,1 +2613,2 @@\n-            CHECK_NULL);\n+            THREAD);\n+          return NULL;\n@@ -2688,1 +2619,2 @@\n-            method_attribute_length, CHECK_NULL);\n+            method_attribute_length, THREAD);\n+          return NULL;\n@@ -2695,1 +2627,2 @@\n-            CHECK_NULL);\n+            THREAD);\n+          return NULL;\n@@ -2706,2 +2639,1 @@\n-                          _can_access_vm_annotations,\n-                          CHECK_NULL);\n+                          _can_access_vm_annotations);\n@@ -2713,1 +2645,2 @@\n-            CHECK_NULL);\n+            THREAD);\n+          return NULL;\n@@ -2726,1 +2659,2 @@\n-            CHECK_NULL);\n+            THREAD);\n+          return NULL;\n@@ -2736,1 +2670,2 @@\n-            CHECK_NULL);\n+            THREAD);\n+          return NULL;\n@@ -2750,1 +2685,2 @@\n-            CHECK_NULL);\n+            THREAD);\n+          return NULL;\n@@ -2760,1 +2696,2 @@\n-            CHECK_NULL);\n+            THREAD);\n+          return NULL;\n@@ -2771,1 +2708,2 @@\n-            CHECK_NULL);\n+            THREAD);\n+          return NULL;\n@@ -3012,1 +2950,1 @@\n-                               name->as_C_string(), sig->as_klass_external_name(), CHECK);\n+                               name->as_C_string(), sig->as_klass_external_name(), THREAD);\n@@ -3110,0 +3048,74 @@\n+\/\/ Find index of the InnerClasses entry for the specified inner_class_info_index.\n+\/\/ Return -1 if none is found.\n+static int inner_classes_find_index(const Array<u2>* inner_classes, int inner, const ConstantPool* cp, int length) {\n+  Symbol* cp_klass_name =  cp->klass_name_at(inner);\n+  for (int idx = 0; idx < length; idx += InstanceKlass::inner_class_next_offset) {\n+    int idx_inner = inner_classes->at(idx + InstanceKlass::inner_class_inner_class_info_offset);\n+    if (cp->klass_name_at(idx_inner) == cp_klass_name) {\n+      return idx;\n+    }\n+  }\n+  return -1;\n+}\n+\n+\/\/ Return the outer_class_info_index for the InnerClasses entry containing the\n+\/\/ specified inner_class_info_index.  Return -1 if no InnerClasses entry is found.\n+static int inner_classes_jump_to_outer(const Array<u2>* inner_classes, int inner, const ConstantPool* cp, int length) {\n+  if (inner == 0) return -1;\n+  int idx = inner_classes_find_index(inner_classes, inner, cp, length);\n+  if (idx == -1) return -1;\n+  int result = inner_classes->at(idx + InstanceKlass::inner_class_outer_class_info_offset);\n+  return result;\n+}\n+\n+\/\/ Return true if circularity is found, false if no circularity is found.\n+\/\/ Use Floyd's cycle finding algorithm.\n+static bool inner_classes_check_loop_through_outer(const Array<u2>* inner_classes, int idx, const ConstantPool* cp, int length) {\n+  int slow = inner_classes->at(idx + InstanceKlass::inner_class_inner_class_info_offset);\n+  int fast = inner_classes->at(idx + InstanceKlass::inner_class_outer_class_info_offset);\n+  while (fast != -1 && fast != 0) {\n+    if (slow != 0 && (cp->klass_name_at(slow) == cp->klass_name_at(fast))) {\n+      return true;  \/\/ found a circularity\n+    }\n+    fast = inner_classes_jump_to_outer(inner_classes, fast, cp, length);\n+    if (fast == -1) return false;\n+    fast = inner_classes_jump_to_outer(inner_classes, fast, cp, length);\n+    if (fast == -1) return false;\n+    slow = inner_classes_jump_to_outer(inner_classes, slow, cp, length);\n+    assert(slow != -1, \"sanity check\");\n+  }\n+  return false;\n+}\n+\n+\/\/ Loop through each InnerClasses entry checking for circularities and duplications\n+\/\/ with other entries.  If duplicate entries are found then throw CFE.  Otherwise,\n+\/\/ return true if a circularity or entries with duplicate inner_class_info_indexes\n+\/\/ are found.\n+bool ClassFileParser::check_inner_classes_circularity(const ConstantPool* cp, int length, TRAPS) {\n+  \/\/ Loop through each InnerClasses entry.\n+  for (int idx = 0; idx < length; idx += InstanceKlass::inner_class_next_offset) {\n+    \/\/ Return true if there are circular entries.\n+    if (inner_classes_check_loop_through_outer(_inner_classes, idx, cp, length)) {\n+      return true;\n+    }\n+    \/\/ Check if there are duplicate entries or entries with the same inner_class_info_index.\n+    for (int y = idx + InstanceKlass::inner_class_next_offset; y < length;\n+         y += InstanceKlass::inner_class_next_offset) {\n+\n+      \/\/ To maintain compatibility, throw an exception if duplicate inner classes\n+      \/\/ entries are found.\n+      guarantee_property((_inner_classes->at(idx) != _inner_classes->at(y) ||\n+                          _inner_classes->at(idx+1) != _inner_classes->at(y+1) ||\n+                          _inner_classes->at(idx+2) != _inner_classes->at(y+2) ||\n+                          _inner_classes->at(idx+3) != _inner_classes->at(y+3)),\n+                         \"Duplicate entry in InnerClasses attribute in class file %s\",\n+                         CHECK_(true));\n+      \/\/ Return true if there are two entries with the same inner_class_info_index.\n+      if (_inner_classes->at(y) == _inner_classes->at(idx)) {\n+        return true;\n+      }\n+    }\n+  }\n+  return false;\n+}\n+\n@@ -3112,0 +3124,1 @@\n+                                                            const ConstantPool* cp,\n@@ -3135,1 +3148,1 @@\n-  Array<u2>* const inner_classes = MetadataFactory::new_array<u2>(_loader_data, size, CHECK_0);\n+  Array<u2>* inner_classes = MetadataFactory::new_array<u2>(_loader_data, size, CHECK_0);\n@@ -3186,0 +3199,2 @@\n+  \/\/ Also, check for circular entries.\n+  bool has_circularity = false;\n@@ -3187,8 +3202,10 @@\n-    for(int i = 0; i < length * 4; i += 4) {\n-      for(int j = i + 4; j < length * 4; j += 4) {\n-        guarantee_property((inner_classes->at(i)   != inner_classes->at(j) ||\n-                            inner_classes->at(i+1) != inner_classes->at(j+1) ||\n-                            inner_classes->at(i+2) != inner_classes->at(j+2) ||\n-                            inner_classes->at(i+3) != inner_classes->at(j+3)),\n-                            \"Duplicate entry in InnerClasses in class file %s\",\n-                            CHECK_0);\n+    has_circularity = check_inner_classes_circularity(cp, length * 4, CHECK_0);\n+    if (has_circularity) {\n+      \/\/ If circularity check failed then ignore InnerClasses attribute.\n+      MetadataFactory::free_array<u2>(_loader_data, _inner_classes);\n+      index = 0;\n+      if (parsed_enclosingmethod_attribute) {\n+        inner_classes = MetadataFactory::new_array<u2>(_loader_data, 2, CHECK_0);\n+        _inner_classes = inner_classes;\n+      } else {\n+        _inner_classes = Universe::the_empty_short_array();\n@@ -3198,1 +3215,0 @@\n-\n@@ -3204,1 +3220,1 @@\n-  assert(index == size, \"wrong size\");\n+  assert(index == size || has_circularity, \"wrong size\");\n@@ -3254,3 +3270,0 @@\n-  if (length < 1) {\n-    classfile_parse_error(\"PermittedSubclasses attribute is empty in class file %s\", CHECK_0);\n-  }\n@@ -3261,9 +3274,12 @@\n-  int index = 0;\n-  cfs->guarantee_more(2 * length, CHECK_0);\n-  for (int n = 0; n < length; n++) {\n-    const u2 class_info_index = cfs->get_u2_fast();\n-    check_property(\n-      valid_klass_reference_at(class_info_index),\n-      \"Permitted subclass class_info_index %u has bad constant type in class file %s\",\n-      class_info_index, CHECK_0);\n-    permitted_subclasses->at_put(index++, class_info_index);\n+  if (length > 0) {\n+    int index = 0;\n+    cfs->guarantee_more(2 * length, CHECK_0);\n+    for (int n = 0; n < length; n++) {\n+      const u2 class_info_index = cfs->get_u2_fast();\n+      check_property(\n+        valid_klass_reference_at(class_info_index),\n+        \"Permitted subclass class_info_index %u has bad constant type in class file %s\",\n+        class_info_index, CHECK_0);\n+      permitted_subclasses->at_put(index++, class_info_index);\n+    }\n+    assert(index == size, \"wrong size\");\n@@ -3271,1 +3287,0 @@\n-  assert(index == size, \"wrong size\");\n@@ -3357,1 +3372,2 @@\n-            CHECK_0);\n+            THREAD);\n+          return 0;\n@@ -3362,1 +3378,2 @@\n-            attribute_length, CHECK_0);\n+            attribute_length, THREAD);\n+          return 0;\n@@ -3369,1 +3386,2 @@\n-            \"Multiple RuntimeVisibleAnnotations attributes for Record component in class file %s\", CHECK_0);\n+            \"Multiple RuntimeVisibleAnnotations attributes for Record component in class file %s\", THREAD);\n+          return 0;\n@@ -3381,1 +3399,2 @@\n-            \"Multiple RuntimeInvisibleAnnotations attributes for Record component in class file %s\", CHECK_0);\n+            \"Multiple RuntimeInvisibleAnnotations attributes for Record component in class file %s\", THREAD);\n+          return 0;\n@@ -3394,1 +3413,2 @@\n-            \"Multiple RuntimeVisibleTypeAnnotations attributes for Record component in class file %s\", CHECK_0);\n+            \"Multiple RuntimeVisibleTypeAnnotations attributes for Record component in class file %s\", THREAD);\n+          return 0;\n@@ -3406,1 +3426,2 @@\n-            \"Multiple RuntimeInvisibleTypeAnnotations attributes for Record component in class file %s\", CHECK_0);\n+            \"Multiple RuntimeInvisibleTypeAnnotations attributes for Record component in class file %s\", THREAD);\n+          return 0;\n@@ -3446,1 +3467,1 @@\n-void ClassFileParser::parse_classfile_synthetic_attribute(TRAPS) {\n+void ClassFileParser::parse_classfile_synthetic_attribute() {\n@@ -3543,12 +3564,0 @@\n-bool ClassFileParser::supports_sealed_types() {\n-  return _major_version == JVM_CLASSFILE_MAJOR_VERSION &&\n-         _minor_version == JAVA_PREVIEW_MINOR_VERSION &&\n-         Arguments::enable_preview();\n-}\n-\n-bool ClassFileParser::supports_records() {\n-  return _major_version == JVM_CLASSFILE_MAJOR_VERSION &&\n-         _minor_version == JAVA_PREVIEW_MINOR_VERSION &&\n-         Arguments::enable_preview();\n-}\n-\n@@ -3617,1 +3626,2 @@\n-        classfile_parse_error(\"Multiple SourceFile attributes in class file %s\", CHECK);\n+        classfile_parse_error(\"Multiple SourceFile attributes in class file %s\", THREAD);\n+        return;\n@@ -3625,2 +3635,3 @@\n-          classfile_parse_error(\n-            \"Multiple SourceDebugExtension attributes in class file %s\", CHECK);\n+        classfile_parse_error(\n+          \"Multiple SourceDebugExtension attributes in class file %s\", THREAD);\n+        return;\n@@ -3633,1 +3644,2 @@\n-        classfile_parse_error(\"Multiple InnerClasses attributes in class file %s\", CHECK);\n+        classfile_parse_error(\"Multiple InnerClasses attributes in class file %s\", THREAD);\n+        return;\n@@ -3646,1 +3658,2 @@\n-          attribute_length, CHECK);\n+          attribute_length, THREAD);\n+        return;\n@@ -3648,1 +3661,1 @@\n-      parse_classfile_synthetic_attribute(CHECK);\n+      parse_classfile_synthetic_attribute();\n@@ -3650,1 +3663,1 @@\n-      \/\/ Check for Deprecatd tag - 4276120\n+      \/\/ Check for Deprecated tag - 4276120\n@@ -3654,1 +3667,2 @@\n-          attribute_length, CHECK);\n+          attribute_length, THREAD);\n+        return;\n@@ -3660,1 +3674,2 @@\n-            \"Multiple Signature attributes in class file %s\", CHECK);\n+            \"Multiple Signature attributes in class file %s\", THREAD);\n+          return;\n@@ -3665,1 +3680,2 @@\n-            attribute_length, CHECK);\n+            attribute_length, THREAD);\n+          return;\n@@ -3671,1 +3687,2 @@\n-            \"Multiple RuntimeVisibleAnnotations attributes in class file %s\", CHECK);\n+            \"Multiple RuntimeVisibleAnnotations attributes in class file %s\", THREAD);\n+          return;\n@@ -3682,2 +3699,1 @@\n-                          _can_access_vm_annotations,\n-                          CHECK);\n+                          _can_access_vm_annotations);\n@@ -3688,1 +3704,2 @@\n-            \"Multiple RuntimeInvisibleAnnotations attributes in class file %s\", CHECK);\n+            \"Multiple RuntimeInvisibleAnnotations attributes in class file %s\", THREAD);\n+          return;\n@@ -3699,1 +3716,2 @@\n-          classfile_parse_error(\"Multiple EnclosingMethod attributes in class file %s\", CHECK);\n+          classfile_parse_error(\"Multiple EnclosingMethod attributes in class file %s\", THREAD);\n+          return;\n@@ -3710,1 +3728,2 @@\n-          classfile_parse_error(\"Invalid class index in EnclosingMethod attribute in class file %s\", CHECK);\n+          classfile_parse_error(\"Invalid class index in EnclosingMethod attribute in class file %s\", THREAD);\n+          return;\n@@ -3718,1 +3737,2 @@\n-          classfile_parse_error(\"Invalid or out-of-bounds method index in EnclosingMethod attribute in class file %s\", CHECK);\n+          classfile_parse_error(\"Invalid or out-of-bounds method index in EnclosingMethod attribute in class file %s\", THREAD);\n+          return;\n@@ -3723,1 +3743,2 @@\n-          classfile_parse_error(\"Multiple BootstrapMethods attributes in class file %s\", CHECK);\n+          classfile_parse_error(\"Multiple BootstrapMethods attributes in class file %s\", THREAD);\n+          return;\n@@ -3730,1 +3751,2 @@\n-            \"Multiple RuntimeVisibleTypeAnnotations attributes in class file %s\", CHECK);\n+            \"Multiple RuntimeVisibleTypeAnnotations attributes in class file %s\", THREAD);\n+          return;\n@@ -3740,1 +3762,2 @@\n-            \"Multiple RuntimeInvisibleTypeAnnotations attributes in class file %s\", CHECK);\n+            \"Multiple RuntimeInvisibleTypeAnnotations attributes in class file %s\", THREAD);\n+          return;\n@@ -3754,1 +3777,2 @@\n-            classfile_parse_error(\"Multiple NestMembers attributes in class file %s\", CHECK);\n+            classfile_parse_error(\"Multiple NestMembers attributes in class file %s\", THREAD);\n+            return;\n@@ -3759,1 +3783,2 @@\n-            classfile_parse_error(\"Conflicting NestHost and NestMembers attributes in class file %s\", CHECK);\n+            classfile_parse_error(\"Conflicting NestHost and NestMembers attributes in class file %s\", THREAD);\n+            return;\n@@ -3766,1 +3791,2 @@\n-            classfile_parse_error(\"Multiple NestHost attributes in class file %s\", CHECK);\n+            classfile_parse_error(\"Multiple NestHost attributes in class file %s\", THREAD);\n+            return;\n@@ -3771,1 +3797,2 @@\n-            classfile_parse_error(\"Conflicting NestMembers and NestHost attributes in class file %s\", CHECK);\n+            classfile_parse_error(\"Conflicting NestMembers and NestHost attributes in class file %s\", THREAD);\n+            return;\n@@ -3783,1 +3810,2 @@\n-        } else if (_major_version >= JAVA_14_VERSION) {\n+\n+        } else if (_major_version >= JAVA_16_VERSION) {\n@@ -3785,29 +3813,3 @@\n-            \/\/ Skip over Record attribute if not supported or if super class is\n-            \/\/ not java.lang.Record.\n-            if (supports_records() &&\n-                cp->klass_name_at(_super_class_index) == vmSymbols::java_lang_Record()) {\n-              if (parsed_record_attribute) {\n-                classfile_parse_error(\"Multiple Record attributes in class file %s\", CHECK);\n-              }\n-              \/\/ Check that class is final and not abstract.\n-              if (!_access_flags.is_final() || _access_flags.is_abstract()) {\n-                classfile_parse_error(\"Record attribute in non-final or abstract class file %s\", CHECK);\n-              }\n-              parsed_record_attribute = true;\n-              record_attribute_start = cfs->current();\n-              record_attribute_length = attribute_length;\n-            } else if (log_is_enabled(Info, class, record)) {\n-              \/\/ Log why the Record attribute was ignored.  Note that if the\n-              \/\/ class file version is JVM_CLASSFILE_MAJOR_VERSION.65535 and\n-              \/\/ --enable-preview wasn't specified then a java.lang.UnsupportedClassVersionError\n-              \/\/ exception would have been thrown.\n-              ResourceMark rm(THREAD);\n-              if (supports_records()) {\n-                log_info(class, record)(\n-                  \"Ignoring Record attribute in class %s because super type is not java.lang.Record\",\n-                  _class_name->as_C_string());\n-              } else {\n-                log_info(class, record)(\n-                  \"Ignoring Record attribute in class %s because class file version is not %d.65535\",\n-                   _class_name->as_C_string(), JVM_CLASSFILE_MAJOR_VERSION);\n-              }\n+            if (parsed_record_attribute) {\n+              classfile_parse_error(\"Multiple Record attributes in class file %s\", THREAD);\n+              return;\n@@ -3815,3 +3817,4 @@\n-            cfs->skip_u1(attribute_length, CHECK);\n-          } else if (_major_version >= JAVA_15_VERSION) {\n-            \/\/ Check for PermittedSubclasses tag\n+            parsed_record_attribute = true;\n+            record_attribute_start = cfs->current();\n+            record_attribute_length = attribute_length;\n+          } else if (_major_version >= JAVA_17_VERSION) {\n@@ -3819,11 +3822,3 @@\n-              if (supports_sealed_types()) {\n-                if (parsed_permitted_subclasses_attribute) {\n-                  classfile_parse_error(\"Multiple PermittedSubclasses attributes in class file %s\", CHECK);\n-                }\n-                \/\/ Classes marked ACC_FINAL cannot have a PermittedSubclasses attribute.\n-                if (_access_flags.is_final()) {\n-                  classfile_parse_error(\"PermittedSubclasses attribute in final class file %s\", CHECK);\n-                }\n-                parsed_permitted_subclasses_attribute = true;\n-                permitted_subclasses_attribute_start = cfs->current();\n-                permitted_subclasses_attribute_length = attribute_length;\n+              if (parsed_permitted_subclasses_attribute) {\n+                classfile_parse_error(\"Multiple PermittedSubclasses attributes in class file %s\", CHECK);\n+                return;\n@@ -3831,4 +3826,8 @@\n-              cfs->skip_u1(attribute_length, CHECK);\n-            } else {\n-              \/\/ Unknown attribute\n-              cfs->skip_u1(attribute_length, CHECK);\n+              \/\/ Classes marked ACC_FINAL cannot have a PermittedSubclasses attribute.\n+              if (_access_flags.is_final()) {\n+                classfile_parse_error(\"PermittedSubclasses attribute in final class file %s\", CHECK);\n+                return;\n+              }\n+              parsed_permitted_subclasses_attribute = true;\n+              permitted_subclasses_attribute_start = cfs->current();\n+              permitted_subclasses_attribute_length = attribute_length;\n@@ -3836,3 +3835,2 @@\n-          } else {\n-            \/\/ Unknown attribute\n-            cfs->skip_u1(attribute_length, CHECK);\n+          \/\/ Skip attribute_length for any attribute where major_verson >= JAVA_17_VERSION\n+          cfs->skip_u1(attribute_length, CHECK);\n@@ -3867,0 +3865,1 @@\n+                            cp,\n@@ -3970,2 +3969,1 @@\n-                                            int java_fields_count,\n-                                            TRAPS) {\n+                                            int java_fields_count) {\n@@ -4058,37 +4056,0 @@\n-#ifndef PRODUCT\n-static void print_field_layout(const Symbol* name,\n-                               Array<u2>* fields,\n-                               ConstantPool* cp,\n-                               int instance_size,\n-                               int instance_fields_start,\n-                               int instance_fields_end,\n-                               int static_fields_end) {\n-\n-  assert(name != NULL, \"invariant\");\n-\n-  tty->print(\"%s: field layout\\n\", name->as_klass_external_name());\n-  tty->print(\"  @%3d %s\\n\", instance_fields_start, \"--- instance fields start ---\");\n-  for (AllFieldStream fs(fields, cp); !fs.done(); fs.next()) {\n-    if (!fs.access_flags().is_static()) {\n-      tty->print(\"  @%3d \\\"%s\\\" %s\\n\",\n-        fs.offset(),\n-        fs.name()->as_klass_external_name(),\n-        fs.signature()->as_klass_external_name());\n-    }\n-  }\n-  tty->print(\"  @%3d %s\\n\", instance_fields_end, \"--- instance fields end ---\");\n-  tty->print(\"  @%3d %s\\n\", instance_size * wordSize, \"--- instance ends ---\");\n-  tty->print(\"  @%3d %s\\n\", InstanceMirrorKlass::offset_of_static_fields(), \"--- static fields start ---\");\n-  for (AllFieldStream fs(fields, cp); !fs.done(); fs.next()) {\n-    if (fs.access_flags().is_static()) {\n-      tty->print(\"  @%3d \\\"%s\\\" %s\\n\",\n-        fs.offset(),\n-        fs.name()->as_klass_external_name(),\n-        fs.signature()->as_klass_external_name());\n-    }\n-  }\n-  tty->print(\"  @%3d %s\\n\", static_fields_end, \"--- static fields end ---\");\n-  tty->print(\"\\n\");\n-}\n-#endif\n-\n@@ -4211,426 +4172,0 @@\n-\/\/ Layout fields and fill in FieldLayoutInfo.  Could use more refactoring!\n-void ClassFileParser::layout_fields(ConstantPool* cp,\n-                                    const FieldAllocationCount* fac,\n-                                    const ClassAnnotationCollector* parsed_annotations,\n-                                    FieldLayoutInfo* info,\n-                                    TRAPS) {\n-\n-  assert(cp != NULL, \"invariant\");\n-\n-  \/\/ Field size and offset computation\n-  int nonstatic_field_size = _super_klass == NULL ? 0 :\n-                               _super_klass->nonstatic_field_size();\n-\n-  \/\/ Count the contended fields by type.\n-  \/\/\n-  \/\/ We ignore static fields, because @Contended is not supported for them.\n-  \/\/ The layout code below will also ignore the static fields.\n-  int nonstatic_contended_count = 0;\n-  FieldAllocationCount fac_contended;\n-  for (AllFieldStream fs(_fields, cp); !fs.done(); fs.next()) {\n-    FieldAllocationType atype = (FieldAllocationType) fs.allocation_type();\n-    if (fs.is_contended()) {\n-      fac_contended.count[atype]++;\n-      if (!fs.access_flags().is_static()) {\n-        nonstatic_contended_count++;\n-      }\n-    }\n-  }\n-\n-\n-  \/\/ Calculate the starting byte offsets\n-  int next_static_oop_offset    = InstanceMirrorKlass::offset_of_static_fields();\n-  int next_static_double_offset = next_static_oop_offset +\n-                                      ((fac->count[STATIC_OOP]) * heapOopSize);\n-  if (fac->count[STATIC_DOUBLE]) {\n-    next_static_double_offset = align_up(next_static_double_offset, BytesPerLong);\n-  }\n-\n-  int next_static_word_offset   = next_static_double_offset +\n-                                    ((fac->count[STATIC_DOUBLE]) * BytesPerLong);\n-  int next_static_short_offset  = next_static_word_offset +\n-                                    ((fac->count[STATIC_WORD]) * BytesPerInt);\n-  int next_static_byte_offset   = next_static_short_offset +\n-                                  ((fac->count[STATIC_SHORT]) * BytesPerShort);\n-\n-  int nonstatic_fields_start  = instanceOopDesc::base_offset_in_bytes() +\n-                                nonstatic_field_size * heapOopSize;\n-\n-  int next_nonstatic_field_offset = nonstatic_fields_start;\n-\n-  const bool is_contended_class     = parsed_annotations->is_contended();\n-\n-  \/\/ Class is contended, pad before all the fields\n-  if (is_contended_class) {\n-    next_nonstatic_field_offset += ContendedPaddingWidth;\n-  }\n-\n-  \/\/ Compute the non-contended fields count.\n-  \/\/ The packing code below relies on these counts to determine if some field\n-  \/\/ can be squeezed into the alignment gap. Contended fields are obviously\n-  \/\/ exempt from that.\n-  unsigned int nonstatic_double_count = fac->count[NONSTATIC_DOUBLE] - fac_contended.count[NONSTATIC_DOUBLE];\n-  unsigned int nonstatic_word_count   = fac->count[NONSTATIC_WORD]   - fac_contended.count[NONSTATIC_WORD];\n-  unsigned int nonstatic_short_count  = fac->count[NONSTATIC_SHORT]  - fac_contended.count[NONSTATIC_SHORT];\n-  unsigned int nonstatic_byte_count   = fac->count[NONSTATIC_BYTE]   - fac_contended.count[NONSTATIC_BYTE];\n-  unsigned int nonstatic_oop_count    = fac->count[NONSTATIC_OOP]    - fac_contended.count[NONSTATIC_OOP];\n-\n-  \/\/ Total non-static fields count, including every contended field\n-  unsigned int nonstatic_fields_count = fac->count[NONSTATIC_DOUBLE] + fac->count[NONSTATIC_WORD] +\n-                                        fac->count[NONSTATIC_SHORT] + fac->count[NONSTATIC_BYTE] +\n-                                        fac->count[NONSTATIC_OOP];\n-\n-  const bool super_has_nonstatic_fields =\n-          (_super_klass != NULL && _super_klass->has_nonstatic_fields());\n-  const bool has_nonstatic_fields =\n-    super_has_nonstatic_fields || (nonstatic_fields_count != 0);\n-\n-\n-  \/\/ Prepare list of oops for oop map generation.\n-  \/\/\n-  \/\/ \"offset\" and \"count\" lists are describing the set of contiguous oop\n-  \/\/ regions. offset[i] is the start of the i-th region, which then has\n-  \/\/ count[i] oops following. Before we know how many regions are required,\n-  \/\/ we pessimistically allocate the maps to fit all the oops into the\n-  \/\/ distinct regions.\n-\n-  int super_oop_map_count = (_super_klass == NULL) ? 0 :_super_klass->nonstatic_oop_map_count();\n-  int max_oop_map_count = super_oop_map_count + fac->count[NONSTATIC_OOP];\n-\n-  OopMapBlocksBuilder* nonstatic_oop_maps = new OopMapBlocksBuilder(max_oop_map_count);\n-  if (super_oop_map_count > 0) {\n-    nonstatic_oop_maps->initialize_inherited_blocks(_super_klass->start_of_nonstatic_oop_maps(),\n-                                                    _super_klass->nonstatic_oop_map_count());\n-  }\n-\n-  int first_nonstatic_oop_offset = 0; \/\/ will be set for first oop field\n-\n-  bool compact_fields  = true;\n-  bool allocate_oops_first = false;\n-\n-  int next_nonstatic_oop_offset = 0;\n-  int next_nonstatic_double_offset = 0;\n-\n-  \/\/ Rearrange fields for a given allocation style\n-  if (allocate_oops_first) {\n-    \/\/ Fields order: oops, longs\/doubles, ints, shorts\/chars, bytes, padded fields\n-    next_nonstatic_oop_offset    = next_nonstatic_field_offset;\n-    next_nonstatic_double_offset = next_nonstatic_oop_offset +\n-                                    (nonstatic_oop_count * heapOopSize);\n-  } else {\n-    \/\/ Fields order: longs\/doubles, ints, shorts\/chars, bytes, oops, padded fields\n-    next_nonstatic_double_offset = next_nonstatic_field_offset;\n-  }\n-\n-  int nonstatic_oop_space_count   = 0;\n-  int nonstatic_word_space_count  = 0;\n-  int nonstatic_short_space_count = 0;\n-  int nonstatic_byte_space_count  = 0;\n-  int nonstatic_oop_space_offset = 0;\n-  int nonstatic_word_space_offset = 0;\n-  int nonstatic_short_space_offset = 0;\n-  int nonstatic_byte_space_offset = 0;\n-\n-  \/\/ Try to squeeze some of the fields into the gaps due to\n-  \/\/ long\/double alignment.\n-  if (nonstatic_double_count > 0) {\n-    int offset = next_nonstatic_double_offset;\n-    next_nonstatic_double_offset = align_up(offset, BytesPerLong);\n-    if (compact_fields && offset != next_nonstatic_double_offset) {\n-      \/\/ Allocate available fields into the gap before double field.\n-      int length = next_nonstatic_double_offset - offset;\n-      assert(length == BytesPerInt, \"\");\n-      nonstatic_word_space_offset = offset;\n-      if (nonstatic_word_count > 0) {\n-        nonstatic_word_count      -= 1;\n-        nonstatic_word_space_count = 1; \/\/ Only one will fit\n-        length -= BytesPerInt;\n-        offset += BytesPerInt;\n-      }\n-      nonstatic_short_space_offset = offset;\n-      while (length >= BytesPerShort && nonstatic_short_count > 0) {\n-        nonstatic_short_count       -= 1;\n-        nonstatic_short_space_count += 1;\n-        length -= BytesPerShort;\n-        offset += BytesPerShort;\n-      }\n-      nonstatic_byte_space_offset = offset;\n-      while (length > 0 && nonstatic_byte_count > 0) {\n-        nonstatic_byte_count       -= 1;\n-        nonstatic_byte_space_count += 1;\n-        length -= 1;\n-      }\n-      \/\/ Allocate oop field in the gap if there are no other fields for that.\n-      nonstatic_oop_space_offset = offset;\n-      if (length >= heapOopSize && nonstatic_oop_count > 0 &&\n-          !allocate_oops_first) { \/\/ when oop fields not first\n-        nonstatic_oop_count      -= 1;\n-        nonstatic_oop_space_count = 1; \/\/ Only one will fit\n-        length -= heapOopSize;\n-        offset += heapOopSize;\n-      }\n-    }\n-  }\n-\n-  int next_nonstatic_word_offset = next_nonstatic_double_offset +\n-                                     (nonstatic_double_count * BytesPerLong);\n-  int next_nonstatic_short_offset = next_nonstatic_word_offset +\n-                                      (nonstatic_word_count * BytesPerInt);\n-  int next_nonstatic_byte_offset = next_nonstatic_short_offset +\n-                                     (nonstatic_short_count * BytesPerShort);\n-  int next_nonstatic_padded_offset = next_nonstatic_byte_offset +\n-                                       nonstatic_byte_count;\n-\n-  \/\/ let oops jump before padding with this allocation style\n-  if (!allocate_oops_first) {\n-    next_nonstatic_oop_offset = next_nonstatic_padded_offset;\n-    if( nonstatic_oop_count > 0 ) {\n-      next_nonstatic_oop_offset = align_up(next_nonstatic_oop_offset, heapOopSize);\n-    }\n-    next_nonstatic_padded_offset = next_nonstatic_oop_offset + (nonstatic_oop_count * heapOopSize);\n-  }\n-\n-  \/\/ Iterate over fields again and compute correct offsets.\n-  \/\/ The field allocation type was temporarily stored in the offset slot.\n-  \/\/ oop fields are located before non-oop fields (static and non-static).\n-  for (AllFieldStream fs(_fields, cp); !fs.done(); fs.next()) {\n-\n-    \/\/ skip already laid out fields\n-    if (fs.is_offset_set()) continue;\n-\n-    \/\/ contended instance fields are handled below\n-    if (fs.is_contended() && !fs.access_flags().is_static()) continue;\n-\n-    int real_offset = 0;\n-    const FieldAllocationType atype = (const FieldAllocationType) fs.allocation_type();\n-\n-    \/\/ pack the rest of the fields\n-    switch (atype) {\n-      case STATIC_OOP:\n-        real_offset = next_static_oop_offset;\n-        next_static_oop_offset += heapOopSize;\n-        break;\n-      case STATIC_BYTE:\n-        real_offset = next_static_byte_offset;\n-        next_static_byte_offset += 1;\n-        break;\n-      case STATIC_SHORT:\n-        real_offset = next_static_short_offset;\n-        next_static_short_offset += BytesPerShort;\n-        break;\n-      case STATIC_WORD:\n-        real_offset = next_static_word_offset;\n-        next_static_word_offset += BytesPerInt;\n-        break;\n-      case STATIC_DOUBLE:\n-        real_offset = next_static_double_offset;\n-        next_static_double_offset += BytesPerLong;\n-        break;\n-      case NONSTATIC_OOP:\n-        if( nonstatic_oop_space_count > 0 ) {\n-          real_offset = nonstatic_oop_space_offset;\n-          nonstatic_oop_space_offset += heapOopSize;\n-          nonstatic_oop_space_count  -= 1;\n-        } else {\n-          real_offset = next_nonstatic_oop_offset;\n-          next_nonstatic_oop_offset += heapOopSize;\n-        }\n-        nonstatic_oop_maps->add(real_offset, 1);\n-        break;\n-      case NONSTATIC_BYTE:\n-        if( nonstatic_byte_space_count > 0 ) {\n-          real_offset = nonstatic_byte_space_offset;\n-          nonstatic_byte_space_offset += 1;\n-          nonstatic_byte_space_count  -= 1;\n-        } else {\n-          real_offset = next_nonstatic_byte_offset;\n-          next_nonstatic_byte_offset += 1;\n-        }\n-        break;\n-      case NONSTATIC_SHORT:\n-        if( nonstatic_short_space_count > 0 ) {\n-          real_offset = nonstatic_short_space_offset;\n-          nonstatic_short_space_offset += BytesPerShort;\n-          nonstatic_short_space_count  -= 1;\n-        } else {\n-          real_offset = next_nonstatic_short_offset;\n-          next_nonstatic_short_offset += BytesPerShort;\n-        }\n-        break;\n-      case NONSTATIC_WORD:\n-        if( nonstatic_word_space_count > 0 ) {\n-          real_offset = nonstatic_word_space_offset;\n-          nonstatic_word_space_offset += BytesPerInt;\n-          nonstatic_word_space_count  -= 1;\n-        } else {\n-          real_offset = next_nonstatic_word_offset;\n-          next_nonstatic_word_offset += BytesPerInt;\n-        }\n-        break;\n-      case NONSTATIC_DOUBLE:\n-        real_offset = next_nonstatic_double_offset;\n-        next_nonstatic_double_offset += BytesPerLong;\n-        break;\n-      default:\n-        ShouldNotReachHere();\n-    }\n-    fs.set_offset(real_offset);\n-  }\n-\n-\n-  \/\/ Handle the contended cases.\n-  \/\/\n-  \/\/ Each contended field should not intersect the cache line with another contended field.\n-  \/\/ In the absence of alignment information, we end up with pessimistically separating\n-  \/\/ the fields with full-width padding.\n-  \/\/\n-  \/\/ Additionally, this should not break alignment for the fields, so we round the alignment up\n-  \/\/ for each field.\n-  if (nonstatic_contended_count > 0) {\n-\n-    \/\/ if there is at least one contended field, we need to have pre-padding for them\n-    next_nonstatic_padded_offset += ContendedPaddingWidth;\n-\n-    \/\/ collect all contended groups\n-    ResourceBitMap bm(cp->size());\n-    for (AllFieldStream fs(_fields, cp); !fs.done(); fs.next()) {\n-      \/\/ skip already laid out fields\n-      if (fs.is_offset_set()) continue;\n-\n-      if (fs.is_contended()) {\n-        bm.set_bit(fs.contended_group());\n-      }\n-    }\n-\n-    int current_group = -1;\n-    while ((current_group = (int)bm.get_next_one_offset(current_group + 1)) != (int)bm.size()) {\n-\n-      for (AllFieldStream fs(_fields, cp); !fs.done(); fs.next()) {\n-\n-        \/\/ skip already laid out fields\n-        if (fs.is_offset_set()) continue;\n-\n-        \/\/ skip non-contended fields and fields from different group\n-        if (!fs.is_contended() || (fs.contended_group() != current_group)) continue;\n-\n-        \/\/ handle statics below\n-        if (fs.access_flags().is_static()) continue;\n-\n-        int real_offset = 0;\n-        FieldAllocationType atype = (FieldAllocationType) fs.allocation_type();\n-\n-        switch (atype) {\n-          case NONSTATIC_BYTE:\n-            next_nonstatic_padded_offset = align_up(next_nonstatic_padded_offset, 1);\n-            real_offset = next_nonstatic_padded_offset;\n-            next_nonstatic_padded_offset += 1;\n-            break;\n-\n-          case NONSTATIC_SHORT:\n-            next_nonstatic_padded_offset = align_up(next_nonstatic_padded_offset, BytesPerShort);\n-            real_offset = next_nonstatic_padded_offset;\n-            next_nonstatic_padded_offset += BytesPerShort;\n-            break;\n-\n-          case NONSTATIC_WORD:\n-            next_nonstatic_padded_offset = align_up(next_nonstatic_padded_offset, BytesPerInt);\n-            real_offset = next_nonstatic_padded_offset;\n-            next_nonstatic_padded_offset += BytesPerInt;\n-            break;\n-\n-          case NONSTATIC_DOUBLE:\n-            next_nonstatic_padded_offset = align_up(next_nonstatic_padded_offset, BytesPerLong);\n-            real_offset = next_nonstatic_padded_offset;\n-            next_nonstatic_padded_offset += BytesPerLong;\n-            break;\n-\n-          case NONSTATIC_OOP:\n-            next_nonstatic_padded_offset = align_up(next_nonstatic_padded_offset, heapOopSize);\n-            real_offset = next_nonstatic_padded_offset;\n-            next_nonstatic_padded_offset += heapOopSize;\n-            nonstatic_oop_maps->add(real_offset, 1);\n-            break;\n-\n-          default:\n-            ShouldNotReachHere();\n-        }\n-\n-        if (fs.contended_group() == 0) {\n-          \/\/ Contended group defines the equivalence class over the fields:\n-          \/\/ the fields within the same contended group are not inter-padded.\n-          \/\/ The only exception is default group, which does not incur the\n-          \/\/ equivalence, and so requires intra-padding.\n-          next_nonstatic_padded_offset += ContendedPaddingWidth;\n-        }\n-\n-        fs.set_offset(real_offset);\n-      } \/\/ for\n-\n-      \/\/ Start laying out the next group.\n-      \/\/ Note that this will effectively pad the last group in the back;\n-      \/\/ this is expected to alleviate memory contention effects for\n-      \/\/ subclass fields and\/or adjacent object.\n-      \/\/ If this was the default group, the padding is already in place.\n-      if (current_group != 0) {\n-        next_nonstatic_padded_offset += ContendedPaddingWidth;\n-      }\n-    }\n-\n-    \/\/ handle static fields\n-  }\n-\n-  \/\/ Entire class is contended, pad in the back.\n-  \/\/ This helps to alleviate memory contention effects for subclass fields\n-  \/\/ and\/or adjacent object.\n-  if (is_contended_class) {\n-    next_nonstatic_padded_offset += ContendedPaddingWidth;\n-  }\n-\n-  int notaligned_nonstatic_fields_end = next_nonstatic_padded_offset;\n-\n-  int nonstatic_fields_end      = align_up(notaligned_nonstatic_fields_end, heapOopSize);\n-  int instance_end              = align_up(notaligned_nonstatic_fields_end, wordSize);\n-  int static_fields_end         = align_up(next_static_byte_offset, wordSize);\n-\n-  int static_field_size         = (static_fields_end -\n-                                   InstanceMirrorKlass::offset_of_static_fields()) \/ wordSize;\n-  nonstatic_field_size          = nonstatic_field_size +\n-                                  (nonstatic_fields_end - nonstatic_fields_start) \/ heapOopSize;\n-\n-  int instance_size             = align_object_size(instance_end \/ wordSize);\n-\n-  assert(instance_size == align_object_size(align_up(\n-         (instanceOopDesc::base_offset_in_bytes() + nonstatic_field_size*heapOopSize),\n-          wordSize) \/ wordSize), \"consistent layout helper value\");\n-\n-  \/\/ Invariant: nonstatic_field end\/start should only change if there are\n-  \/\/ nonstatic fields in the class, or if the class is contended. We compare\n-  \/\/ against the non-aligned value, so that end alignment will not fail the\n-  \/\/ assert without actually having the fields.\n-  assert((notaligned_nonstatic_fields_end == nonstatic_fields_start) ||\n-         is_contended_class ||\n-         (nonstatic_fields_count > 0), \"double-check nonstatic start\/end\");\n-\n-  \/\/ Number of non-static oop map blocks allocated at end of klass.\n-  nonstatic_oop_maps->compact();\n-\n-#ifndef PRODUCT\n-  if (PrintFieldLayout) {\n-    print_field_layout(_class_name,\n-          _fields,\n-          cp,\n-          instance_size,\n-          nonstatic_fields_start,\n-          nonstatic_fields_end,\n-          static_fields_end);\n-  }\n-\n-#endif\n-  \/\/ Pass back information needed for InstanceKlass creation\n-  info->oop_map_blocks = nonstatic_oop_maps;\n-  info->_instance_size = instance_size;\n-  info->_static_field_size = static_field_size;\n-  info->_nonstatic_field_size = nonstatic_field_size;\n-  info->_has_nonstatic_fields = has_nonstatic_fields;\n-}\n-\n@@ -4668,2 +4203,2 @@\n-  if (SystemDictionary::Cloneable_klass_loaded()) {\n-    if (ik->is_subtype_of(SystemDictionary::Cloneable_klass())) {\n+  if (vmClasses::Cloneable_klass_loaded()) {\n+    if (ik->is_subtype_of(vmClasses::Cloneable_klass())) {\n@@ -4787,1 +4322,1 @@\n-static void check_super_class_access(const InstanceKlass* this_klass, TRAPS) {\n+void ClassFileParser::check_super_class_access(const InstanceKlass* this_klass, TRAPS) {\n@@ -4795,7 +4330,1 @@\n-      ResourceMark rm(THREAD);\n-      Exceptions::fthrow(\n-        THREAD_AND_LOCATION,\n-        vmSymbols::java_lang_VerifyError(),\n-        \"class %s cannot inherit from final class %s\",\n-        this_klass->external_name(),\n-        super_ik->external_name());\n+      classfile_icce_error(\"class %s cannot inherit from final class %s\", super_ik, THREAD);\n@@ -4806,7 +4335,1 @@\n-      ResourceMark rm(THREAD);\n-      Exceptions::fthrow(\n-        THREAD_AND_LOCATION,\n-        vmSymbols::java_lang_IncompatibleClassChangeError(),\n-        \"class %s cannot inherit from sealed class %s\",\n-        this_klass->external_name(),\n-        super_ik->external_name());\n+      classfile_icce_error(\"class %s cannot inherit from sealed class %s\", super_ik, THREAD);\n@@ -4868,1 +4391,1 @@\n-static void check_super_interface_access(const InstanceKlass* this_klass, TRAPS) {\n+void ClassFileParser::check_super_interface_access(const InstanceKlass* this_klass, TRAPS) {\n@@ -4877,8 +4400,4 @@\n-      ResourceMark rm(THREAD);\n-      Exceptions::fthrow(\n-        THREAD_AND_LOCATION,\n-        vmSymbols::java_lang_IncompatibleClassChangeError(),\n-        \"class %s cannot %s sealed interface %s\",\n-        this_klass->external_name(),\n-        this_klass->is_interface() ? \"extend\" : \"implement\",\n-        k->external_name());\n+      classfile_icce_error(this_klass->is_interface() ?\n+                             \"class %s cannot extend sealed interface %s\" :\n+                             \"class %s cannot implement sealed interface %s\",\n+                           k, THREAD);\n@@ -4956,9 +4475,6 @@\n-              Exceptions::fthrow(THREAD_AND_LOCATION,\n-                                 vmSymbols::java_lang_VerifyError(),\n-                                 \"class %s overrides final method %s.%s%s\",\n-                                 this_klass->external_name(),\n-                                 super_m->method_holder()->external_name(),\n-                                 name->as_C_string(),\n-                                 signature->as_C_string()\n-                                 );\n-              return;\n+              THROW_MSG(vmSymbols::java_lang_IncompatibleClassChangeError(),\n+                        err_msg(\"class %s overrides final method %s.%s%s\",\n+                                this_klass->external_name(),\n+                                super_m->method_holder()->external_name(),\n+                                name->as_C_string(),\n+                                signature->as_C_string()));\n@@ -5061,1 +4577,1 @@\n-static void verify_class_version(u2 major, u2 minor, Symbol* class_name, TRAPS){\n+void ClassFileParser::verify_class_version(u2 major, u2 minor, Symbol* class_name, TRAPS){\n@@ -5065,5 +4581,2 @@\n-    Exceptions::fthrow(\n-      THREAD_AND_LOCATION,\n-      vmSymbols::java_lang_UnsupportedClassVersionError(),\n-      \"%s (class file version %u.%u) was compiled with an invalid major version\",\n-      class_name->as_C_string(), major, minor);\n+    classfile_ucve_error(\"%s (class file version %u.%u) was compiled with an invalid major version\",\n+                         class_name, major, minor, THREAD);\n@@ -5099,5 +4612,2 @@\n-      Exceptions::fthrow(\n-        THREAD_AND_LOCATION,\n-        vmSymbols::java_lang_UnsupportedClassVersionError(),\n-        \"Preview features are not enabled for %s (class file version %u.%u). Try running with '--enable-preview'\",\n-        class_name->as_C_string(), major, minor);\n+      classfile_ucve_error(\"Preview features are not enabled for %s (class file version %u.%u). Try running with '--enable-preview'\",\n+                           class_name, major, minor, THREAD);\n@@ -5108,5 +4618,2 @@\n-    Exceptions::fthrow(\n-        THREAD_AND_LOCATION,\n-        vmSymbols::java_lang_UnsupportedClassVersionError(),\n-        \"%s (class file version %u.%u) was compiled with an invalid non-zero minor version\",\n-        class_name->as_C_string(), major, minor);\n+    classfile_ucve_error(\"%s (class file version %u.%u) was compiled with an invalid non-zero minor version\",\n+                         class_name, major, minor, THREAD);\n@@ -5174,0 +4681,1 @@\n+  const bool major_gte_17    = _major_version >= JAVA_17_VERSION;\n@@ -5192,1 +4700,1 @@\n-          (is_abstract && (is_private || is_static || is_strict))) {\n+          (is_abstract && (is_private || is_static || (!major_gte_17 && is_strict)))) {\n@@ -5219,1 +4727,1 @@\n-              (major_gte_1_5 && (is_synchronized || is_strict)))) {\n+              (major_gte_1_5 && (is_synchronized || (!major_gte_17 && is_strict))))) {\n@@ -5243,1 +4751,1 @@\n-    classfile_parse_error(\"Illegal UTF8 string in constant pool in class file %s\", CHECK);\n+    classfile_parse_error(\"Illegal UTF8 string in constant pool in class file %s\", THREAD);\n@@ -5342,1 +4850,1 @@\n-          SystemDictionary::Character_klass(),\n+          vmClasses::Character_klass(),\n@@ -5350,1 +4858,1 @@\n-          SystemDictionary::Character_klass(),\n+          vmClasses::Character_klass(),\n@@ -5412,1 +4920,1 @@\n-                                  CHECK_NULL);\n+                                  THREAD);\n@@ -5424,1 +4932,2 @@\n-        classfile_parse_error(\"Array type descriptor has more than 255 dimensions in class file %s\", CHECK_NULL);\n+        classfile_parse_error(\"Array type descriptor has more than 255 dimensions in class file %s\", THREAD);\n+        return NULL;\n@@ -5648,1 +5157,1 @@\n-  const vmSymbols::SID klass_id = Method::klass_id_for_intrinsics(ik);\n+  const vmSymbolID klass_id = Method::klass_id_for_intrinsics(ik);\n@@ -5650,1 +5159,1 @@\n-  if (klass_id != vmSymbols::NO_SID) {\n+  if (klass_id != vmSymbolID::NO_SID) {\n@@ -5653,1 +5162,1 @@\n-      method->init_intrinsic_id();\n+      method->init_intrinsic_id(klass_id);\n@@ -5657,1 +5166,1 @@\n-        \/\/ but the method is not annotated with @HotSpotIntrinsicCandidate.\n+        \/\/ but the method is not annotated with @IntrinsicCandidate.\n@@ -5661,1 +5170,1 @@\n-              \"but the method is not annotated with @HotSpotIntrinsicCandidate.%s\",\n+              \"but the method is not annotated with @IntrinsicCandidate.%s\",\n@@ -5668,1 +5177,1 @@\n-        \/\/ Check is the method 'method' is annotated with @HotSpotIntrinsicCandidate,\n+        \/\/ Check is the method 'method' is annotated with @IntrinsicCandidate,\n@@ -5672,1 +5181,1 @@\n-            tty->print(\"Method [%s] is annotated with @HotSpotIntrinsicCandidate, \"\n+            tty->print(\"Method [%s] is annotated with @IntrinsicCandidate, \"\n@@ -5691,1 +5200,1 @@\n-      for (int id = vmIntrinsics::FIRST_ID; id < (int)vmIntrinsics::ID_LIMIT; ++id) {\n+      for (auto id : EnumRange<vmIntrinsicID>{}) {\n@@ -5698,0 +5207,5 @@\n+        if (vmIntrinsics::_blackhole == id) {\n+          \/\/ The _blackhole intrinsic is a special marker. No explicit method\n+          \/\/ is defined for it.\n+          continue;\n+        }\n@@ -5699,1 +5213,1 @@\n-        if (vmIntrinsics::class_for(vmIntrinsics::ID_from(id)) == klass_id) {\n+        if (vmIntrinsics::class_for(id) == klass_id) {\n@@ -5715,2 +5229,1 @@\n-                        vmIntrinsics::short_name_as_C_string(vmIntrinsics::ID_from(id),\n-                                                             buf, sizeof(buf)),\n+                        vmIntrinsics::short_name_as_C_string(id, buf, sizeof(buf)),\n@@ -5748,19 +5261,0 @@\n-\n-  if (ik->should_store_fingerprint()) {\n-    ik->store_fingerprint(_stream->compute_fingerprint());\n-  }\n-\n-  ik->set_has_passed_fingerprint_check(false);\n-  if (UseAOT && ik->supers_have_passed_fingerprint_checks()) {\n-    uint64_t aot_fp = AOTLoader::get_saved_fingerprint(ik);\n-    uint64_t fp = ik->has_stored_fingerprint() ? ik->get_stored_fingerprint() : _stream->compute_fingerprint();\n-    if (aot_fp != 0 && aot_fp == fp) {\n-      \/\/ This class matches with a class saved in an AOT library\n-      ik->set_has_passed_fingerprint_check(true);\n-    } else {\n-      ResourceMark rm;\n-      log_info(class, fingerprint)(\"%s :  expected = \" PTR64_FORMAT \" actual = \" PTR64_FORMAT,\n-                                 ik->external_name(), aot_fp, _stream->compute_fingerprint());\n-    }\n-  }\n-\n@@ -5807,1 +5301,1 @@\n-  apply_parsed_class_metadata(ik, _java_fields_count, CHECK);\n+  apply_parsed_class_metadata(ik, _java_fields_count);\n@@ -5811,1 +5305,1 @@\n-    ik->set_nest_host(cl_inst_info.dynamic_nest_host(), THREAD);\n+    ik->set_nest_host(cl_inst_info.dynamic_nest_host());\n@@ -5838,1 +5332,1 @@\n-  if (_is_hidden || is_unsafe_anonymous()) {\n+  if (_is_hidden) {\n@@ -5840,3 +5334,3 @@\n-    \/\/ hidden or anonymous class itself. If this class needs to refer to its own\n-    \/\/ methods or fields, it would use a CONSTANT_MethodRef, etc, which would reference\n-    \/\/ _this_class_index. However, because this class is hidden or anonymous (it's\n+    \/\/ hidden class itself. If this class needs to refer to its own methods\n+    \/\/ or fields, it would use a CONSTANT_MethodRef, etc, which would reference\n+    \/\/ _this_class_index. However, because this class is hidden (it's\n@@ -5854,4 +5348,0 @@\n-  if (_unsafe_anonymous_host != NULL) {\n-    assert (ik->is_unsafe_anonymous(), \"should be the same\");\n-    ik->set_unsafe_anonymous_host(_unsafe_anonymous_host);\n-  }\n@@ -5977,1 +5467,0 @@\n-      AMD64_ONLY(assert((id_u8 & left_n_bits(17)) == 0, \"jmethodID is not aligned\");)\n@@ -5987,5 +5476,1 @@\n-    if (log_is_enabled(Info, class, load)) {\n-      ResourceMark rm;\n-      const char* module_name = (module_entry->name() == NULL) ? UNNAMED_MODULE : module_entry->name()->as_C_string();\n-      ik->print_class_load_logging(_loader_data, module_name, _stream);\n-    }\n+    ik->print_class_load_logging(_loader_data, module_entry, _stream);\n@@ -6047,51 +5532,0 @@\n-\/\/ For an unsafe anonymous class that is in the unnamed package, move it to its host class's\n-\/\/ package by prepending its host class's package name to its class name and setting\n-\/\/ its _class_name field.\n-void ClassFileParser::prepend_host_package_name(const InstanceKlass* unsafe_anonymous_host, TRAPS) {\n-  ResourceMark rm(THREAD);\n-  assert(strrchr(_class_name->as_C_string(), JVM_SIGNATURE_SLASH) == NULL,\n-         \"Unsafe anonymous class should not be in a package\");\n-  TempNewSymbol host_pkg_name =\n-    ClassLoader::package_from_class_name(unsafe_anonymous_host->name());\n-\n-  if (host_pkg_name != NULL) {\n-    int host_pkg_len = host_pkg_name->utf8_length();\n-    int class_name_len = _class_name->utf8_length();\n-    int symbol_len = host_pkg_len + 1 + class_name_len;\n-    char* new_anon_name = NEW_RESOURCE_ARRAY(char, symbol_len + 1);\n-    int n = os::snprintf(new_anon_name, symbol_len + 1, \"%.*s\/%.*s\",\n-                         host_pkg_len, host_pkg_name->base(), class_name_len, _class_name->base());\n-    assert(n == symbol_len, \"Unexpected number of characters in string\");\n-\n-    \/\/ Decrement old _class_name to avoid leaking.\n-    _class_name->decrement_refcount();\n-\n-    \/\/ Create a symbol and update the anonymous class name.\n-    \/\/ The new class name is created with a refcount of one. When installed into the InstanceKlass,\n-    \/\/ it'll be two and when the ClassFileParser destructor runs, it'll go back to one and get deleted\n-    \/\/ when the class is unloaded.\n-    _class_name = SymbolTable::new_symbol(new_anon_name, symbol_len);\n-  }\n-}\n-\n-\/\/ If the host class and the anonymous class are in the same package then do\n-\/\/ nothing.  If the anonymous class is in the unnamed package then move it to its\n-\/\/ host's package.  If the classes are in different packages then throw an IAE\n-\/\/ exception.\n-void ClassFileParser::fix_unsafe_anonymous_class_name(TRAPS) {\n-  assert(_unsafe_anonymous_host != NULL, \"Expected an unsafe anonymous class\");\n-\n-  const jbyte* anon_last_slash = UTF8::strrchr((const jbyte*)_class_name->base(),\n-                                               _class_name->utf8_length(), JVM_SIGNATURE_SLASH);\n-  if (anon_last_slash == NULL) {  \/\/ Unnamed package\n-    prepend_host_package_name(_unsafe_anonymous_host, CHECK);\n-  } else {\n-    if (!_unsafe_anonymous_host->is_same_class_package(_unsafe_anonymous_host->class_loader(), _class_name)) {\n-      ResourceMark rm(THREAD);\n-      THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(),\n-        err_msg(\"Host class %s and anonymous class %s are in different packages\",\n-        _unsafe_anonymous_host->name()->as_C_string(), _class_name->as_C_string()));\n-    }\n-  }\n-}\n-\n@@ -6118,2 +5552,0 @@\n-  _unsafe_anonymous_host(cl_info->unsafe_anonymous_host()),\n-  _cp_patches(cl_info->cp_patches()),\n@@ -6122,3 +5554,0 @@\n-  _num_patched_klasses(0),\n-  _max_num_patched_klasses(0),\n-  _first_patched_klass_resolved_index(0),\n@@ -6182,1 +5611,0 @@\n-  assert(THREAD->is_Java_thread(), \"invariant\");\n@@ -6202,19 +5630,0 @@\n-  if (_cp_patches != NULL) {\n-    int len = _cp_patches->length();\n-    for (int i=0; i<len; i++) {\n-      if (has_cp_patch_at(i)) {\n-        Handle patch = cp_patch_at(i);\n-        if (java_lang_String::is_instance(patch()) || java_lang_Class::is_instance(patch())) {\n-          \/\/ We need to append the names of the patched classes to the end of the constant pool,\n-          \/\/ because a patched class may have a Utf8 name that's not already included in the\n-          \/\/ original constant pool. These class names are used when patch_constant_pool()\n-          \/\/ calls patch_class().\n-          \/\/\n-          \/\/ Note that a String in cp_patch_at(i) may be used to patch a Utf8, a String, or a Class.\n-          \/\/ At this point, we don't know the tag for index i yet, because we haven't parsed the\n-          \/\/ constant pool. So we can only assume the worst -- every String is used to patch a Class.\n-          _max_num_patched_klasses++;\n-        }\n-      }\n-    }\n-  }\n@@ -6338,12 +5747,0 @@\n-  if (DumpSharedSpaces && _major_version < JAVA_6_VERSION) {\n-    ResourceMark rm;\n-    warning(\"Pre JDK 6 class not supported by CDS: %u.%u %s\",\n-            _major_version,  _minor_version, _class_name->as_C_string());\n-    Exceptions::fthrow(\n-      THREAD_AND_LOCATION,\n-      vmSymbols::java_lang_UnsupportedClassVersionError(),\n-      \"Unsupported major.minor version for dump time %u.%u\",\n-      _major_version,\n-      _minor_version);\n-  }\n-\n@@ -6362,6 +5759,0 @@\n-    assert(_max_num_patched_klasses == 0, \"Sanity check\");\n-  } else {\n-    if (int(cp_size) + _max_num_patched_klasses > 0xffff) {\n-      THROW_MSG(vmSymbols::java_lang_InternalError(), \"not enough space for patched classes\");\n-    }\n-    cp_size += _max_num_patched_klasses;\n@@ -6404,1 +5795,2 @@\n-    classfile_parse_error(\"Unknown constant tag %u in class file %s\", bad_constant, CHECK);\n+    classfile_parse_error(\"Unknown constant tag %u in class file %s\", bad_constant, THREAD);\n+    return;\n@@ -6431,5 +5823,0 @@\n-  assert(!(_is_hidden && (_unsafe_anonymous_host != NULL)), \"mutually exclusive variants\");\n-\n-  if (_unsafe_anonymous_host != NULL) {\n-    assert(_class_name == vmSymbols::unknown_class_name(), \"A named anonymous class???\");\n-  }\n@@ -6441,2 +5828,1 @@\n-  \/\/ Update the _class_name as needed depending on whether this is a named,\n-  \/\/ un-named, hidden or unsafe-anonymous class.\n+  \/\/ Update the _class_name as needed depending on whether this is a named, un-named, or hidden class.\n@@ -6452,10 +5838,0 @@\n-  \/\/ NOTE: !_is_hidden does not imply \"findable\" as it could be an old-style\n-  \/\/       \"hidden\" unsafe-anonymous class\n-\n-  \/\/ If this is an anonymous class fix up its name if it is in the unnamed\n-  \/\/ package.  Otherwise, throw IAE if it is in a different package than\n-  \/\/ its host class.\n-  } else if (_unsafe_anonymous_host != NULL) {\n-    update_class_name(class_name_in_cp);\n-    fix_unsafe_anonymous_class_name(CHECK);\n-\n@@ -6498,38 +5874,0 @@\n-\n-#if INCLUDE_CDS\n-    if (DumpLoadedClassList != NULL && stream->source() != NULL && classlist_file->is_open()) {\n-      if (!ClassLoader::has_jrt_entry()) {\n-        warning(\"DumpLoadedClassList and CDS are not supported in exploded build\");\n-        DumpLoadedClassList = NULL;\n-      } else if (SystemDictionaryShared::is_sharing_possible(_loader_data) &&\n-                 !_is_hidden &&\n-                 _unsafe_anonymous_host == NULL) {\n-        \/\/ Only dump the classes that can be stored into CDS archive.\n-        \/\/ Hidden and unsafe anonymous classes such as generated LambdaForm classes are also not included.\n-        oop class_loader = _loader_data->class_loader();\n-        ResourceMark rm(THREAD);\n-        bool skip = false;\n-        if (class_loader == NULL || SystemDictionary::is_platform_class_loader(class_loader)) {\n-          \/\/ For the boot and platform class loaders, skip classes that are not found in the\n-          \/\/ java runtime image, such as those found in the --patch-module entries.\n-          \/\/ These classes can't be loaded from the archive during runtime.\n-          if (!stream->from_boot_loader_modules_image() && strncmp(stream->source(), \"jrt:\", 4) != 0) {\n-            skip = true;\n-          }\n-\n-          if (class_loader == NULL && ClassLoader::contains_append_entry(stream->source())) {\n-            \/\/ .. but don't skip the boot classes that are loaded from -Xbootclasspath\/a\n-            \/\/ as they can be loaded from the archive during runtime.\n-            skip = false;\n-          }\n-        }\n-        if (skip) {\n-          tty->print_cr(\"skip writing class %s from source %s to classlist file\",\n-            _class_name->as_C_string(), stream->source());\n-        } else {\n-          classlist_file->print_cr(\"%s\", _class_name->as_C_string());\n-          classlist_file->flush();\n-        }\n-      }\n-    }\n-#endif\n@@ -6610,1 +5948,12 @@\n-  jio_snprintf(addr_buf, 20, INTPTR_FORMAT, p2i(ik));\n+  if (DumpSharedSpaces) {\n+    \/\/ We want stable names for the archived hidden classes (only for static\n+    \/\/ archive for now). Spaces under default_SharedBaseAddress() will be\n+    \/\/ occupied by the archive at run time, so we know that no dynamically\n+    \/\/ loaded InstanceKlass will be placed under there.\n+    static volatile size_t counter = 0;\n+    Atomic::cmpxchg(&counter, (size_t)0, Arguments::default_SharedBaseAddress()); \/\/ initialize it\n+    size_t new_id = Atomic::add(&counter, (size_t)1);\n+    jio_snprintf(addr_buf, 20, SIZE_FORMAT_HEX, new_id);\n+  } else {\n+    jio_snprintf(addr_buf, 20, INTPTR_FORMAT, p2i(ik));\n+  }\n@@ -6646,1 +5995,1 @@\n-  if (_super_class_index > 0 && NULL ==_super_klass) {\n+  if (_super_class_index > 0 && NULL == _super_klass) {\n@@ -6671,8 +6020,1 @@\n-      ResourceMark rm(THREAD);\n-      Exceptions::fthrow(\n-        THREAD_AND_LOCATION,\n-        vmSymbols::java_lang_IncompatibleClassChangeError(),\n-        \"class %s has interface %s as super class\",\n-        _class_name->as_klass_external_name(),\n-        _super_klass->external_name()\n-      );\n+      classfile_icce_error(\"class %s has interface %s as super class\", _super_klass, THREAD);\n@@ -6707,2 +6049,1 @@\n-                                                    _local_interfaces,\n-                                                    CHECK);\n+                                                    _local_interfaces);\n@@ -6718,7 +6059,3 @@\n-  if (UseNewFieldLayout) {\n-    FieldLayoutBuilder lb(class_name(), super_klass(), _cp, _fields,\n-                          _parsed_annotations->is_contended(), _field_info);\n-    lb.build_layout();\n-  } else {\n-    layout_fields(cp, _fac, _parsed_annotations, _field_info, CHECK);\n-  }\n+  FieldLayoutBuilder lb(class_name(), super_klass(), _cp, _fields,\n+                        _parsed_annotations->is_contended(), _field_info);\n+  lb.build_layout();\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":406,"deletions":1069,"binary":false,"changes":1475,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,0 +26,4 @@\n+#include \"jvm.h\"\n+#include \"cds\/archiveBuilder.hpp\"\n+#include \"cds\/heapShared.inline.hpp\"\n+#include \"cds\/metaspaceShared.hpp\"\n@@ -29,0 +33,1 @@\n+#include \"classfile\/javaThreadStatus.hpp\"\n@@ -32,0 +37,2 @@\n+#include \"classfile\/systemDictionary.hpp\"\n+#include \"classfile\/vmClasses.hpp\"\n@@ -40,2 +47,0 @@\n-#include \"memory\/heapShared.inline.hpp\"\n-#include \"memory\/metaspaceShared.hpp\"\n@@ -46,1 +51,1 @@\n-#include \"oops\/instanceKlass.hpp\"\n+#include \"oops\/instanceKlass.inline.hpp\"\n@@ -49,0 +54,1 @@\n+#include \"oops\/klass.inline.hpp\"\n@@ -56,0 +62,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -65,0 +72,1 @@\n+#include \"runtime\/reflectionUtils.hpp\"\n@@ -86,1 +94,1 @@\n-  { SystemDictionary::WK_KLASS_ENUM_NAME(klass), vmSymbols::VM_SYMBOL_ENUM_NAME(name##_name), vmSymbols::VM_SYMBOL_ENUM_NAME(signature), may_be_java },\n+  { VM_CLASS_ID(klass), VM_SYMBOL_ENUM_NAME(name##_name), VM_SYMBOL_ENUM_NAME(signature), may_be_java },\n@@ -94,1 +102,1 @@\n-  InstanceKlass* obj = SystemDictionary::Object_klass();\n+  InstanceKlass* obj = vmClasses::Object_klass();\n@@ -114,2 +122,2 @@\n-  vmSymbols::SID sid = vmSymbols::find_sid(class_name);\n-  if (sid == vmSymbols::NO_SID) {\n+  vmSymbolID sid = vmSymbols::find_sid(class_name);\n+  if (sid == vmSymbolID::NO_SID) {\n@@ -124,1 +132,1 @@\n-  if (sid == vmSymbols::VM_SYMBOL_ENUM_NAME(klass)) {              \\\n+  if (sid == VM_SYMBOL_ENUM_NAME(klass)) {                         \\\n@@ -196,0 +204,1 @@\n+int java_lang_String::_flags_offset;\n@@ -203,0 +212,12 @@\n+bool java_lang_String::test_and_set_flag(oop java_string, uint8_t flag_mask) {\n+  uint8_t* addr = flags_addr(java_string);\n+  uint8_t value = Atomic::load(addr);\n+  while ((value & flag_mask) == 0) {\n+    uint8_t old_value = value;\n+    value |= flag_mask;\n+    value = Atomic::cmpxchg(addr, old_value, value);\n+    if (value == old_value) return false; \/\/ Flag bit changed from 0 to 1.\n+  }\n+  return true;                  \/\/ Flag bit is already 1.\n+}\n+\n@@ -214,1 +235,1 @@\n-  InstanceKlass* k = SystemDictionary::String_klass();\n+  InstanceKlass* k = vmClasses::String_klass();\n@@ -216,0 +237,1 @@\n+  STRING_INJECTED_FIELDS(INJECTED_FIELD_COMPUTE_OFFSET);\n@@ -223,0 +245,1 @@\n+  STRING_INJECTED_FIELDS(INJECTED_FIELD_SERIALIZE_OFFSET);\n@@ -237,1 +260,1 @@\n-      assert(fd->field_holder() == SystemDictionary::String_klass(), \"Should be String\");\n+      assert(fd->field_holder() == vmClasses::String_klass(), \"Should be String\");\n@@ -246,1 +269,1 @@\n-  SystemDictionary::String_klass()->do_local_static_fields(&fix);\n+  vmClasses::String_klass()->do_local_static_fields(&fix);\n@@ -256,1 +279,1 @@\n-  obj = SystemDictionary::String_klass()->allocate_instance(CHECK_NH);\n+  obj = vmClasses::String_klass()->allocate_instance(CHECK_NH);\n@@ -410,2 +433,1 @@\n-    assert(THREAD->is_Java_thread(), \"must be java thread\");\n-    JavaThread* thread = (JavaThread*)THREAD;\n+    JavaThread* thread = THREAD;\n@@ -437,4 +459,2 @@\n-  { JavaThread* thread = (JavaThread*)THREAD;\n-    assert(thread->is_Java_thread(), \"must be java thread\");\n-    JNIEnv *env = thread->jni_environment();\n-    jstring js = (jstring) JNIHandles::make_local(env, java_string());\n+  { JavaThread* thread = THREAD;\n+    jstring js = (jstring) JNIHandles::make_local(thread, java_string());\n@@ -444,0 +464,1 @@\n+    JNIEnv *env = thread->jni_environment();\n@@ -518,0 +539,8 @@\n+  jchar* result = as_unicode_string_or_null(java_string, length);\n+  if (result == NULL) {\n+    THROW_MSG_0(vmSymbols::java_lang_OutOfMemoryError(), \"could not allocate Unicode string\");\n+  }\n+  return result;\n+}\n+\n+jchar* java_lang_String::as_unicode_string_or_null(oop java_string, int& length) {\n@@ -533,2 +562,0 @@\n-  } else {\n-    THROW_MSG_0(vmSymbols::java_lang_OutOfMemoryError(), \"could not allocate Unicode string\");\n@@ -738,1 +765,1 @@\n-  assert(java_string->klass() == SystemDictionary::String_klass(),\n+  assert(java_string->klass() == vmClasses::String_klass(),\n@@ -763,1 +790,1 @@\n-  assert(str1->klass() == SystemDictionary::String_klass(),\n+  assert(str1->klass() == vmClasses::String_klass(),\n@@ -765,1 +792,1 @@\n-  assert(str2->klass() == SystemDictionary::String_klass(),\n+  assert(str2->klass() == vmClasses::String_klass(),\n@@ -780,1 +807,1 @@\n-  assert(java_string->klass() == SystemDictionary::String_klass(), \"must be java_string\");\n+  assert(java_string->klass() == vmClasses::String_klass(), \"must be java_string\");\n@@ -822,0 +849,66 @@\n+#ifdef ASSERT\n+inline static void assert_valid_static_string_field(fieldDescriptor* fd) {\n+  assert(fd->has_initial_value(), \"caller should have checked this\");\n+  assert(fd->field_type() == T_OBJECT, \"caller should have checked this\");\n+  \/\/ Can't use vmSymbols::string_signature() as fd->signature() may have been relocated\n+  \/\/ during DumpSharedSpaces\n+  assert(fd->signature()->equals(\"Ljava\/lang\/String;\"), \"just checking\");\n+}\n+#endif\n+\n+static void initialize_static_string_field(fieldDescriptor* fd, Handle mirror, TRAPS) {\n+  DEBUG_ONLY(assert_valid_static_string_field(fd);)\n+  oop string = fd->string_initial_value(CHECK);\n+  mirror()->obj_field_put(fd->offset(), string);\n+}\n+\n+#if INCLUDE_CDS_JAVA_HEAP\n+static void initialize_static_string_field_for_dump(fieldDescriptor* fd, Handle mirror) {\n+  DEBUG_ONLY(assert_valid_static_string_field(fd);)\n+  assert(DumpSharedSpaces, \"must be\");\n+  if (HeapShared::is_archived_object(mirror())) {\n+    \/\/ Archive the String field and update the pointer.\n+    oop s = mirror()->obj_field(fd->offset());\n+    oop archived_s = StringTable::create_archived_string(s);\n+    mirror()->obj_field_put(fd->offset(), archived_s);\n+  } else {\n+    guarantee(false, \"Unexpected\");\n+  }\n+}\n+#endif\n+\n+static void initialize_static_primitive_field(fieldDescriptor* fd, Handle mirror) {\n+  assert(fd->has_initial_value(), \"caller should have checked this\");\n+  BasicType t = fd->field_type();\n+  switch (t) {\n+  case T_BYTE:\n+    mirror()->byte_field_put(fd->offset(), fd->int_initial_value());\n+    break;\n+  case T_BOOLEAN:\n+    mirror()->bool_field_put(fd->offset(), fd->int_initial_value());\n+    break;\n+  case T_CHAR:\n+    mirror()->char_field_put(fd->offset(), fd->int_initial_value());\n+    break;\n+  case T_SHORT:\n+    mirror()->short_field_put(fd->offset(), fd->int_initial_value());\n+    break;\n+  case T_INT:\n+    mirror()->int_field_put(fd->offset(), fd->int_initial_value());\n+    break;\n+  case T_FLOAT:\n+    mirror()->float_field_put(fd->offset(), fd->float_initial_value());\n+    break;\n+  case T_DOUBLE:\n+    mirror()->double_field_put(fd->offset(), fd->double_initial_value());\n+    break;\n+  case T_LONG:\n+    mirror()->long_field_put(fd->offset(), fd->long_initial_value());\n+    break;\n+  default:\n+    \/\/ Illegal ConstantValue attribute in class file should have been\n+    \/\/ caught during classfile parsing.\n+    ShouldNotReachHere();\n+  }\n+}\n+\n@@ -825,44 +918,4 @@\n-    BasicType t = fd->field_type();\n-    switch (t) {\n-      case T_BYTE:\n-        mirror()->byte_field_put(fd->offset(), fd->int_initial_value());\n-              break;\n-      case T_BOOLEAN:\n-        mirror()->bool_field_put(fd->offset(), fd->int_initial_value());\n-              break;\n-      case T_CHAR:\n-        mirror()->char_field_put(fd->offset(), fd->int_initial_value());\n-              break;\n-      case T_SHORT:\n-        mirror()->short_field_put(fd->offset(), fd->int_initial_value());\n-              break;\n-      case T_INT:\n-        mirror()->int_field_put(fd->offset(), fd->int_initial_value());\n-        break;\n-      case T_FLOAT:\n-        mirror()->float_field_put(fd->offset(), fd->float_initial_value());\n-        break;\n-      case T_DOUBLE:\n-        mirror()->double_field_put(fd->offset(), fd->double_initial_value());\n-        break;\n-      case T_LONG:\n-        mirror()->long_field_put(fd->offset(), fd->long_initial_value());\n-        break;\n-      case T_OBJECT:\n-        {\n-          assert(fd->signature() == vmSymbols::string_signature(),\n-                 \"just checking\");\n-          if (DumpSharedSpaces && HeapShared::is_archived_object(mirror())) {\n-            \/\/ Archive the String field and update the pointer.\n-            oop s = mirror()->obj_field(fd->offset());\n-            oop archived_s = StringTable::create_archived_string(s, CHECK);\n-            mirror()->obj_field_put(fd->offset(), archived_s);\n-          } else {\n-            oop string = fd->string_initial_value(CHECK);\n-            mirror()->obj_field_put(fd->offset(), string);\n-          }\n-        }\n-        break;\n-      default:\n-        THROW_MSG(vmSymbols::java_lang_ClassFormatError(),\n-                  \"Illegal ConstantValue attribute in class file\");\n+    if (fd->field_type() != T_OBJECT) {\n+      initialize_static_primitive_field(fd, mirror);\n+    } else {\n+      initialize_static_string_field(fd, mirror, CHECK);\n@@ -873,0 +926,12 @@\n+#if INCLUDE_CDS_JAVA_HEAP\n+static void initialize_static_field_for_dump(fieldDescriptor* fd, Handle mirror) {\n+  assert(mirror.not_null() && fd->is_static(), \"just checking\");\n+  if (fd->has_initial_value()) {\n+    if (fd->field_type() != T_OBJECT) {\n+      initialize_static_primitive_field(fd, mirror);\n+    } else {\n+      initialize_static_string_field_for_dump(fd, mirror);\n+    }\n+  }\n+}\n+#endif\n@@ -892,1 +957,1 @@\n-  if (k->is_shared() && k->has_raw_archived_mirror()) {\n+  if (k->is_shared() && k->has_archived_mirror_index()) {\n@@ -898,2 +963,2 @@\n-      k->set_java_mirror_handle(OopHandle());\n-      k->clear_has_raw_archived_mirror();\n+      k->clear_java_mirror_handle();\n+      k->clear_archived_mirror_index();\n@@ -927,1 +992,1 @@\n-void java_lang_Class::set_mirror_module_field(Klass* k, Handle mirror, Handle module, TRAPS) {\n+void java_lang_Class::set_mirror_module_field(JavaThread* current, Klass* k, Handle mirror, Handle module) {\n@@ -936,1 +1001,1 @@\n-      MutexLocker m1(THREAD, Module_lock);\n+      MutexLocker m1(current, Module_lock);\n@@ -953,1 +1018,1 @@\n-      Handle javabase_handle(THREAD, javabase_entry->module());\n+      Handle javabase_handle(current, javabase_entry->module());\n@@ -968,1 +1033,1 @@\n-    new (ResourceObj::C_HEAP, mtClass) GrowableArray<Klass*>(40, true);\n+    new (ResourceObj::C_HEAP, mtClass) GrowableArray<Klass*>(40, mtClass);\n@@ -972,1 +1037,1 @@\n-    new (ResourceObj::C_HEAP, mtModule) GrowableArray<Klass*>(500, true);\n+    new (ResourceObj::C_HEAP, mtModule) GrowableArray<Klass*>(500, mtModule);\n@@ -986,1 +1051,1 @@\n-  int computed_modifiers = k->compute_modifier_flags(CHECK);\n+  int computed_modifiers = k->compute_modifier_flags();\n@@ -990,1 +1055,1 @@\n-  if (SystemDictionary::Class_klass_loaded()) {\n+  if (vmClasses::Class_klass_loaded()) {\n@@ -992,1 +1057,1 @@\n-    oop mirror_oop = InstanceMirrorKlass::cast(SystemDictionary::Class_klass())->allocate_instance(k, CHECK);\n+    oop mirror_oop = InstanceMirrorKlass::cast(vmClasses::Class_klass())->allocate_instance(k, CHECK);\n@@ -1046,1 +1111,1 @@\n-    set_mirror_module_field(k, mirror, module, THREAD);\n+    set_mirror_module_field(THREAD, k, mirror, module);\n@@ -1075,1 +1140,1 @@\n-      initialize_static_field(fd, _m, Thread::current());\n+      initialize_static_field_for_dump(fd, _m);\n@@ -1120,1 +1185,16 @@\n-void java_lang_Class::archive_basic_type_mirrors(TRAPS) {\n+static void set_klass_field_in_archived_mirror(oop mirror_obj, int offset, Klass* k) {\n+  assert(java_lang_Class::is_instance(mirror_obj), \"must be\");\n+  \/\/ this is the copy of k in the output buffer\n+  Klass* copy = ArchiveBuilder::get_relocated_klass(k);\n+\n+  \/\/ This is the address of k, if the archive is loaded at the requested location\n+  Klass* def = ArchiveBuilder::current()->to_requested(copy);\n+\n+  log_debug(cds, heap, mirror)(\n+      \"Relocate mirror metadata field at %d from \" PTR_FORMAT \" ==> \" PTR_FORMAT,\n+      offset, p2i(k), p2i(def));\n+\n+  mirror_obj->metadata_field_put(offset, def);\n+}\n+\n+void java_lang_Class::archive_basic_type_mirrors() {\n@@ -1124,2 +1204,3 @@\n-  for (int t = 0; t <= T_VOID; t++) {\n-    oop m = Universe::_mirrors[t];\n+  for (int t = T_BOOLEAN; t < T_VOID+1; t++) {\n+    BasicType bt = (BasicType)t;\n+    oop m = Universe::_mirrors[t].resolve();\n@@ -1128,1 +1209,1 @@\n-      oop archived_m = HeapShared::archive_heap_object(m, THREAD);\n+      oop archived_m = HeapShared::archive_heap_object(m);\n@@ -1133,2 +1214,1 @@\n-        Klass *reloc_ak = MetaspaceShared::get_relocated_klass(ak, true);\n-        archived_m->metadata_field_put(_array_klass_offset, reloc_ak);\n+        set_klass_field_in_archived_mirror(archived_m, _array_klass_offset, ak);\n@@ -1139,1 +1219,1 @@\n-      Handle archived_mirror_h(THREAD, archived_m);\n+      Handle archived_mirror_h(Thread::current(), archived_m);\n@@ -1145,1 +1225,1 @@\n-        type2name((BasicType)t), p2i(Universe::_mirrors[t]), p2i(archived_m));\n+        type2name(bt), p2i(m), p2i(archived_m));\n@@ -1147,1 +1227,1 @@\n-      Universe::_mirrors[t] = archived_m;\n+      Universe::replace_mirror(bt, archived_m);\n@@ -1150,21 +1230,0 @@\n-\n-  assert(Universe::_mirrors[T_INT] != NULL &&\n-         Universe::_mirrors[T_FLOAT] != NULL &&\n-         Universe::_mirrors[T_DOUBLE] != NULL &&\n-         Universe::_mirrors[T_BYTE] != NULL &&\n-         Universe::_mirrors[T_BOOLEAN] != NULL &&\n-         Universe::_mirrors[T_CHAR] != NULL &&\n-         Universe::_mirrors[T_LONG] != NULL &&\n-         Universe::_mirrors[T_SHORT] != NULL &&\n-         Universe::_mirrors[T_VOID] != NULL, \"sanity\");\n-\n-  Universe::set_int_mirror(Universe::_mirrors[T_INT]);\n-  Universe::set_float_mirror(Universe::_mirrors[T_FLOAT]);\n-  Universe::set_double_mirror(Universe::_mirrors[T_DOUBLE]);\n-  Universe::set_byte_mirror(Universe::_mirrors[T_BYTE]);\n-  Universe::set_bool_mirror(Universe::_mirrors[T_BOOLEAN]);\n-  Universe::set_char_mirror(Universe::_mirrors[T_CHAR]);\n-  Universe::set_long_mirror(Universe::_mirrors[T_LONG]);\n-  Universe::set_short_mirror(Universe::_mirrors[T_SHORT]);\n-  Universe::set_void_mirror(Universe::_mirrors[T_VOID]);\n-\n@@ -1180,1 +1239,1 @@\n-oop java_lang_Class::archive_mirror(Klass* k, TRAPS) {\n+oop java_lang_Class::archive_mirror(Klass* k) {\n@@ -1185,3 +1244,3 @@\n-  if (k->has_raw_archived_mirror()) {\n-    assert(k->archived_java_mirror_raw() != NULL, \"no archived mirror\");\n-    return k->archived_java_mirror_raw();\n+  if (k->has_archived_mirror_index()) {\n+    assert(k->archived_java_mirror() != NULL, \"no archived mirror\");\n+    return k->archived_java_mirror();\n@@ -1203,2 +1262,1 @@\n-      \/\/ supported. Clear the _java_mirror within the archived class.\n-      k->set_java_mirror_handle(OopHandle());\n+      \/\/ supported.\n@@ -1210,1 +1268,1 @@\n-  oop archived_mirror = HeapShared::archive_heap_object(mirror, THREAD);\n+  oop archived_mirror = HeapShared::archive_heap_object(mirror);\n@@ -1215,1 +1273,1 @@\n-  archived_mirror = process_archived_mirror(k, mirror, archived_mirror, THREAD);\n+  archived_mirror = process_archived_mirror(k, mirror, archived_mirror);\n@@ -1220,3 +1278,1 @@\n-  k->set_archived_java_mirror_raw(archived_mirror);\n-\n-  k->set_has_raw_archived_mirror();\n+  k->set_archived_java_mirror(archived_mirror);\n@@ -1234,2 +1290,1 @@\n-                                             oop archived_mirror,\n-                                             Thread *THREAD) {\n+                                             oop archived_mirror) {\n@@ -1239,1 +1294,1 @@\n-  Handle archived_mirror_h(THREAD, archived_mirror);\n+  Handle archived_mirror_h(Thread::current(), archived_mirror);\n@@ -1254,1 +1309,1 @@\n-      archived_comp_mirror = archive_mirror(element_klass, THREAD);\n+      archived_comp_mirror = archive_mirror(element_klass);\n@@ -1269,0 +1324,2 @@\n+    set_signers(archived_mirror, NULL);\n+    set_source_file(archived_mirror, NULL);\n@@ -1278,5 +1335,1 @@\n-  Klass *reloc_k = MetaspaceShared::get_relocated_klass(as_Klass(mirror), true);\n-  log_debug(cds, heap, mirror)(\n-    \"Relocate mirror metadata field at _klass_offset from \" PTR_FORMAT \" ==> \" PTR_FORMAT,\n-    p2i(as_Klass(mirror)), p2i(reloc_k));\n-  archived_mirror->metadata_field_put(_klass_offset, reloc_k);\n+  set_klass_field_in_archived_mirror(archived_mirror, _klass_offset, as_Klass(mirror));\n@@ -1288,5 +1341,1 @@\n-    Klass *reloc_arr = MetaspaceShared::get_relocated_klass(arr, true);\n-    log_debug(cds, heap, mirror)(\n-      \"Relocate mirror metadata field at _array_klass_offset from \" PTR_FORMAT \" ==> \" PTR_FORMAT,\n-      p2i(arr), p2i(reloc_arr));\n-    archived_mirror->metadata_field_put(_array_klass_offset, reloc_arr);\n+    set_klass_field_in_archived_mirror(archived_mirror, _array_klass_offset, arr);\n@@ -1331,2 +1380,2 @@\n-  \/\/ see more details in SystemDictionary::resolve_well_known_classes().\n-  if (!SystemDictionary::Class_klass_loaded()) {\n+  \/\/ see more details in vmClasses::resolve_all().\n+  if (!vmClasses::Class_klass_loaded()) {\n@@ -1338,4 +1387,5 @@\n-  oop m = HeapShared::materialize_archived_object(k->archived_java_mirror_raw_narrow());\n-  if (m == NULL) {\n-    return false;\n-  }\n+  oop m = k->archived_java_mirror();\n+  assert(m != NULL, \"must have stored non-null archived mirror\");\n+\n+  \/\/ Sanity: clear it now to prevent re-initialization if any of the following fails\n+  k->clear_archived_mirror_index();\n@@ -1367,2 +1417,1 @@\n-  k->clear_has_raw_archived_mirror();\n-  set_mirror_module_field(k, mirror, module, THREAD);\n+  set_mirror_module_field(THREAD, k, mirror, module);\n@@ -1441,1 +1490,1 @@\n-  return java_class->obj_field_addr_raw<oop>(_init_lock_offset);\n+  return (oop*)java_class->field_addr(_init_lock_offset);\n@@ -1456,1 +1505,1 @@\n-  java_class->obj_field_put(_signers_offset, (oop)signers);\n+  java_class->obj_field_put(_signers_offset, signers);\n@@ -1511,1 +1560,1 @@\n-  oop java_class = InstanceMirrorKlass::cast(SystemDictionary::Class_klass())->allocate_instance(NULL, CHECK_NULL);\n+  oop java_class = InstanceMirrorKlass::cast(vmClasses::Class_klass())->allocate_instance(NULL, CHECK_NULL);\n@@ -1518,1 +1567,1 @@\n-  InstanceMirrorKlass* mk = InstanceMirrorKlass::cast(SystemDictionary::Class_klass());\n+  InstanceMirrorKlass* mk = InstanceMirrorKlass::cast(vmClasses::Class_klass());\n@@ -1648,1 +1697,1 @@\n-  assert(mirror != NULL && mirror->is_a(SystemDictionary::Class_klass()), \"must be a Class\");\n+  assert(mirror != NULL && mirror->is_a(vmClasses::Class_klass()), \"must be a Class\");\n@@ -1668,1 +1717,1 @@\n-  InstanceKlass* k = SystemDictionary::Class_klass();\n+  InstanceKlass* k = vmClasses::Class_klass();\n@@ -1741,1 +1790,1 @@\n-  InstanceKlass* k = SystemDictionary::Thread_klass();\n+  InstanceKlass* k = vmClasses::Thread_klass();\n@@ -1845,2 +1894,2 @@\n-                                         java_lang_Thread::ThreadStatus status) {\n-  java_thread->int_field_put(_thread_status_offset, status);\n+                                         JavaThreadStatus status) {\n+  java_thread->int_field_put(_thread_status_offset, static_cast<int>(status));\n@@ -1850,1 +1899,1 @@\n-java_lang_Thread::ThreadStatus java_lang_Thread::get_thread_status(oop java_thread) {\n+JavaThreadStatus java_lang_Thread::get_thread_status(oop java_thread) {\n@@ -1856,1 +1905,1 @@\n-  return (java_lang_Thread::ThreadStatus)java_thread->int_field(_thread_status_offset);\n+  return static_cast<JavaThreadStatus>(java_thread->int_field(_thread_status_offset));\n@@ -1869,1 +1918,1 @@\n-  ThreadStatus status = (java_lang_Thread::ThreadStatus)java_thread->int_field(_thread_status_offset);\n+  JavaThreadStatus status = static_cast<JavaThreadStatus>(java_thread->int_field(_thread_status_offset));\n@@ -1871,9 +1920,9 @@\n-    case NEW                      : return \"NEW\";\n-    case RUNNABLE                 : return \"RUNNABLE\";\n-    case SLEEPING                 : return \"TIMED_WAITING (sleeping)\";\n-    case IN_OBJECT_WAIT           : return \"WAITING (on object monitor)\";\n-    case IN_OBJECT_WAIT_TIMED     : return \"TIMED_WAITING (on object monitor)\";\n-    case PARKED                   : return \"WAITING (parking)\";\n-    case PARKED_TIMED             : return \"TIMED_WAITING (parking)\";\n-    case BLOCKED_ON_MONITOR_ENTER : return \"BLOCKED (on object monitor)\";\n-    case TERMINATED               : return \"TERMINATED\";\n+    case JavaThreadStatus::NEW                      : return \"NEW\";\n+    case JavaThreadStatus::RUNNABLE                 : return \"RUNNABLE\";\n+    case JavaThreadStatus::SLEEPING                 : return \"TIMED_WAITING (sleeping)\";\n+    case JavaThreadStatus::IN_OBJECT_WAIT           : return \"WAITING (on object monitor)\";\n+    case JavaThreadStatus::IN_OBJECT_WAIT_TIMED     : return \"TIMED_WAITING (on object monitor)\";\n+    case JavaThreadStatus::PARKED                   : return \"WAITING (parking)\";\n+    case JavaThreadStatus::PARKED_TIMED             : return \"TIMED_WAITING (parking)\";\n+    case JavaThreadStatus::BLOCKED_ON_MONITOR_ENTER : return \"BLOCKED (on object monitor)\";\n+    case JavaThreadStatus::TERMINATED               : return \"TERMINATED\";\n@@ -1961,1 +2010,1 @@\n-  InstanceKlass* k = SystemDictionary::ThreadGroup_klass();\n+  InstanceKlass* k = vmClasses::ThreadGroup_klass();\n@@ -1977,0 +2026,1 @@\n+int java_lang_Throwable::_cause_offset;\n@@ -1984,0 +2034,1 @@\n+  macro(_cause_offset,         k, \"cause\",         throwable_signature,               false); \\\n@@ -1987,1 +2038,1 @@\n-  InstanceKlass* k = SystemDictionary::Throwable_klass();\n+  InstanceKlass* k = vmClasses::Throwable_klass();\n@@ -1998,1 +2049,1 @@\n-  InstanceKlass* ik = SystemDictionary::Throwable_klass();\n+  InstanceKlass* ik = vmClasses::Throwable_klass();\n@@ -2024,0 +2075,3 @@\n+oop java_lang_Throwable::cause(oop throwable) {\n+  return throwable->obj_field(_cause_offset);\n+}\n@@ -2027,1 +2081,1 @@\n-  PRESERVE_EXCEPTION_MARK;  \/\/ Keep original exception\n+  PreserveExceptionMark pm(Thread::current());\n@@ -2217,1 +2271,1 @@\n-  void set_has_hidden_top_frame(TRAPS) {\n+  void set_has_hidden_top_frame() {\n@@ -2381,1 +2435,1 @@\n-  Thread* THREAD = Thread::current();\n+  JavaThread* THREAD = JavaThread::current(); \/\/ For exception macros.\n@@ -2396,1 +2450,1 @@\n-      EXCEPTION_MARK;\n+      ExceptionMark em(THREAD);\n@@ -2409,1 +2463,1 @@\n-        throwable = Handle(THREAD, (oop) cause.get_jobject());\n+        throwable = Handle(THREAD, cause.get_oop());\n@@ -2424,1 +2478,1 @@\n-  assert(throwable->is_a(SystemDictionary::Throwable_klass()), \"Throwable instance expected\");\n+  assert(throwable->is_a(vmClasses::Throwable_klass()), \"Throwable instance expected\");\n@@ -2428,1 +2482,1 @@\n-                          SystemDictionary::Throwable_klass(),\n+                          vmClasses::Throwable_klass(),\n@@ -2446,1 +2500,1 @@\n-  JavaThread* thread = (JavaThread*)THREAD;\n+  JavaThread* thread = THREAD;\n@@ -2469,1 +2523,1 @@\n-  vframeStream st(thread);\n+  vframeStream st(thread, false \/* stop_at_java_call_stub *\/, false \/* process_frames *\/);\n@@ -2472,1 +2526,1 @@\n-  RegisterMap map(thread, false);\n+  RegisterMap map(thread, false \/* update *\/, false \/* process_frames *\/);\n@@ -2555,1 +2609,1 @@\n-          bt.set_has_hidden_top_frame(CHECK);\n+          bt.set_has_hidden_top_frame();\n@@ -2582,1 +2636,2 @@\n-  PRESERVE_EXCEPTION_MARK;\n+  JavaThread* THREAD = JavaThread::current(); \/\/ For exception macros.\n+  PreserveExceptionMark pm(THREAD);\n@@ -2584,3 +2639,3 @@\n-  JavaThread* thread = JavaThread::active();\n-  fill_in_stack_trace(throwable, method, thread);\n-  \/\/ ignore exceptions thrown during stack trace filling\n+  fill_in_stack_trace(throwable, method, THREAD);\n+  \/\/ Ignore exceptions thrown during stack trace filling (OOM) and reinstall the\n+  \/\/ original exception via the PreserveExceptionMark destructor.\n@@ -2606,1 +2661,1 @@\n-  assert(throwable->is_a(SystemDictionary::Throwable_klass()), \"sanity check\");\n+  assert(throwable->is_a(vmClasses::Throwable_klass()), \"sanity check\");\n@@ -2608,1 +2663,1 @@\n-  JavaThread* THREAD = JavaThread::current();\n+  JavaThread* THREAD = JavaThread::current(); \/\/ For exception macros.\n@@ -2614,1 +2669,1 @@\n-  vframeStream st(THREAD);\n+  vframeStream st(THREAD, false \/* stop_at_java_call_stub *\/, false \/* process_frames *\/);\n@@ -2676,3 +2731,3 @@\n-  Thread* THREAD = Thread::current();\n-  objArrayHandle result(THREAD, objArrayOop(backtrace(throwable)));\n-  BacktraceIterator iter(result, THREAD);\n+  JavaThread* current = JavaThread::current();\n+  objArrayHandle result(current, objArrayOop(backtrace(throwable)));\n+  BacktraceIterator iter(result, current);\n@@ -2690,1 +2745,1 @@\n-  BacktraceElement bte = iter.next(THREAD);\n+  BacktraceElement bte = iter.next(current);\n@@ -2708,1 +2763,1 @@\n-  InstanceKlass* k = SystemDictionary::StackTraceElement_klass();\n+  InstanceKlass* k = vmClasses::StackTraceElement_klass();\n@@ -2724,1 +2779,1 @@\n-  assert(element->is_a(SystemDictionary::StackTraceElement_klass()), \"sanity check\");\n+  assert(element->is_a(vmClasses::StackTraceElement_klass()), \"sanity check\");\n@@ -2831,1 +2886,1 @@\n-  InstanceKlass* k = SystemDictionary::StackFrameInfo_klass();\n+  InstanceKlass* k = vmClasses::StackFrameInfo_klass();\n@@ -2855,1 +2910,1 @@\n-  Handle mname(Thread::current(), stackFrame->obj_field(_memberName_offset));\n+  Handle mname(THREAD, stackFrame->obj_field(_memberName_offset));\n@@ -2903,1 +2958,1 @@\n-  InstanceKlass* k = SystemDictionary::LiveStackFrameInfo_klass();\n+  InstanceKlass* k = vmClasses::LiveStackFrameInfo_klass();\n@@ -2938,1 +2993,1 @@\n-  InstanceKlass* k = SystemDictionary::reflect_AccessibleObject_klass();\n+  InstanceKlass* k = vmClasses::reflect_AccessibleObject_klass();\n@@ -2984,1 +3039,1 @@\n-  InstanceKlass* k = SystemDictionary::reflect_Method_klass();\n+  InstanceKlass* k = vmClasses::reflect_Method_klass();\n@@ -2996,1 +3051,1 @@\n-  Klass* klass = SystemDictionary::reflect_Method_klass();\n+  Klass* klass = vmClasses::reflect_Method_klass();\n@@ -3083,1 +3138,1 @@\n-  InstanceKlass* k = SystemDictionary::reflect_Constructor_klass();\n+  InstanceKlass* k = vmClasses::reflect_Constructor_klass();\n@@ -3167,1 +3222,1 @@\n-  InstanceKlass* k = SystemDictionary::reflect_Field_klass();\n+  InstanceKlass* k = vmClasses::reflect_Field_klass();\n@@ -3242,1 +3297,1 @@\n-  InstanceKlass* ik = SystemDictionary::RecordComponent_klass();\n+  InstanceKlass* ik = vmClasses::RecordComponent_klass();\n@@ -3268,1 +3323,1 @@\n-    accessor_method = holder->find_instance_method(name, full_sig, Klass::find_private);\n+    accessor_method = holder->find_instance_method(name, full_sig, Klass::PrivateLookupMode::find);\n@@ -3303,1 +3358,1 @@\n-  InstanceKlass* k = SystemDictionary::reflect_ConstantPool_klass();\n+  InstanceKlass* k = vmClasses::reflect_ConstantPool_klass();\n@@ -3326,1 +3381,1 @@\n-  InstanceKlass* k = SystemDictionary::reflect_Parameter_klass();\n+  InstanceKlass* k = vmClasses::reflect_Parameter_klass();\n@@ -3386,1 +3441,1 @@\n-  return JavaCalls::construct_new_instance(SystemDictionary::Module_klass(),\n+  return JavaCalls::construct_new_instance(vmClasses::Module_klass(),\n@@ -3396,1 +3451,1 @@\n-  InstanceKlass* k = SystemDictionary::Module_klass();\n+  InstanceKlass* k = vmClasses::Module_klass();\n@@ -3424,1 +3479,1 @@\n-ModuleEntry* java_lang_Module::module_entry(oop module) {\n+ModuleEntry* java_lang_Module::module_entry_raw(oop module) {\n@@ -3430,0 +3485,5 @@\n+  return module_entry;\n+}\n+\n+ModuleEntry* java_lang_Module::module_entry(oop module) {\n+  ModuleEntry* module_entry = module_entry_raw(module);\n@@ -3450,1 +3510,1 @@\n-  InstanceKlass* k = SystemDictionary::reflect_ConstantPool_klass();\n+  InstanceKlass* k = vmClasses::reflect_ConstantPool_klass();\n@@ -3483,1 +3543,1 @@\n-  InstanceKlass* k = SystemDictionary::reflect_UnsafeStaticFieldAccessorImpl_klass();\n+  InstanceKlass* k = vmClasses::reflect_UnsafeStaticFieldAccessorImpl_klass();\n@@ -3513,1 +3573,1 @@\n-  InstanceKlass* k = SystemDictionary::Reference_klass();\n+  InstanceKlass* k = vmClasses::Reference_klass();\n@@ -3537,1 +3597,1 @@\n-  assert(!is_reference || ik->is_subclass_of(SystemDictionary::Reference_klass()), \"sanity\");\n+  assert(!is_reference || ik->is_subclass_of(vmClasses::Reference_klass()), \"sanity\");\n@@ -3549,2 +3609,2 @@\n-  InstanceKlass* integerKlass = SystemDictionary::Integer_klass();\n-  InstanceKlass* longKlass = SystemDictionary::Long_klass();\n+  InstanceKlass* integerKlass = vmClasses::Integer_klass();\n+  InstanceKlass* longKlass = vmClasses::Long_klass();\n@@ -3561,1 +3621,1 @@\n-  Klass* k = SystemDictionary::box_klass(type);\n+  Klass* k = vmClasses::box_klass(type);\n@@ -3606,1 +3666,1 @@\n-  BasicType type = SystemDictionary::box_klass_type(box->klass());\n+  BasicType type = vmClasses::box_klass_type(box->klass());\n@@ -3614,1 +3674,1 @@\n-  BasicType type = SystemDictionary::box_klass_type(box->klass());\n+  BasicType type = vmClasses::box_klass_type(box->klass());\n@@ -3648,1 +3708,1 @@\n-  BasicType type = SystemDictionary::box_klass_type(box->klass());\n+  BasicType type = vmClasses::box_klass_type(box->klass());\n@@ -3707,1 +3767,1 @@\n-  InstanceKlass* k = SystemDictionary::SoftReference_klass();\n+  InstanceKlass* k = vmClasses::SoftReference_klass();\n@@ -3722,1 +3782,1 @@\n-  InstanceKlass* ik = SystemDictionary::SoftReference_klass();\n+  InstanceKlass* ik = vmClasses::SoftReference_klass();\n@@ -3728,1 +3788,1 @@\n-  InstanceKlass* ik = SystemDictionary::SoftReference_klass();\n+  InstanceKlass* ik = vmClasses::SoftReference_klass();\n@@ -3748,1 +3808,1 @@\n-  InstanceKlass* k = SystemDictionary::DirectMethodHandle_klass();\n+  InstanceKlass* k = vmClasses::DirectMethodHandle_klass();\n@@ -3780,1 +3840,1 @@\n-  InstanceKlass* k = SystemDictionary::MethodHandle_klass();\n+  InstanceKlass* k = vmClasses::MethodHandle_klass();\n@@ -3798,1 +3858,1 @@\n-  InstanceKlass* k = SystemDictionary::MemberName_klass();\n+  InstanceKlass* k = vmClasses::MemberName_klass();\n@@ -3811,1 +3871,1 @@\n-  InstanceKlass* k = SystemDictionary::ResolvedMethodName_klass();\n+  InstanceKlass* k = vmClasses::ResolvedMethodName_klass();\n@@ -3826,1 +3886,1 @@\n-  InstanceKlass* k = SystemDictionary::LambdaForm_klass();\n+  InstanceKlass* k = vmClasses::LambdaForm_klass();\n@@ -3841,0 +3901,53 @@\n+int jdk_internal_invoke_NativeEntryPoint::_shadow_space_offset;\n+int jdk_internal_invoke_NativeEntryPoint::_argMoves_offset;\n+int jdk_internal_invoke_NativeEntryPoint::_returnMoves_offset;\n+int jdk_internal_invoke_NativeEntryPoint::_need_transition_offset;\n+int jdk_internal_invoke_NativeEntryPoint::_method_type_offset;\n+int jdk_internal_invoke_NativeEntryPoint::_name_offset;\n+\n+#define NEP_FIELDS_DO(macro) \\\n+  macro(_shadow_space_offset,    k, \"shadowSpace\",    int_signature, false); \\\n+  macro(_argMoves_offset,        k, \"argMoves\",       long_array_signature, false); \\\n+  macro(_returnMoves_offset,     k, \"returnMoves\",    long_array_signature, false); \\\n+  macro(_need_transition_offset, k, \"needTransition\", bool_signature, false); \\\n+  macro(_method_type_offset,     k, \"methodType\",     java_lang_invoke_MethodType_signature, false); \\\n+  macro(_name_offset,            k, \"name\",           string_signature, false);\n+\n+bool jdk_internal_invoke_NativeEntryPoint::is_instance(oop obj) {\n+  return obj != NULL && is_subclass(obj->klass());\n+}\n+\n+void jdk_internal_invoke_NativeEntryPoint::compute_offsets() {\n+  InstanceKlass* k = vmClasses::NativeEntryPoint_klass();\n+  NEP_FIELDS_DO(FIELD_COMPUTE_OFFSET);\n+}\n+\n+#if INCLUDE_CDS\n+void jdk_internal_invoke_NativeEntryPoint::serialize_offsets(SerializeClosure* f) {\n+  NEP_FIELDS_DO(FIELD_SERIALIZE_OFFSET);\n+}\n+#endif\n+\n+jint jdk_internal_invoke_NativeEntryPoint::shadow_space(oop entry) {\n+  return entry->int_field(_shadow_space_offset);\n+}\n+\n+oop jdk_internal_invoke_NativeEntryPoint::argMoves(oop entry) {\n+  return entry->obj_field(_argMoves_offset);\n+}\n+\n+oop jdk_internal_invoke_NativeEntryPoint::returnMoves(oop entry) {\n+  return entry->obj_field(_returnMoves_offset);\n+}\n+\n+jboolean jdk_internal_invoke_NativeEntryPoint::need_transition(oop entry) {\n+  return entry->bool_field(_need_transition_offset);\n+}\n+\n+oop jdk_internal_invoke_NativeEntryPoint::method_type(oop entry) {\n+  return entry->obj_field(_method_type_offset);\n+}\n+\n+oop jdk_internal_invoke_NativeEntryPoint::name(oop entry) {\n+  return entry->obj_field(_name_offset);\n+}\n@@ -3958,1 +4071,1 @@\n-  InstanceKlass* k = SystemDictionary::ResolvedMethodName_klass();\n+  InstanceKlass* k = vmClasses::ResolvedMethodName_klass();\n@@ -3975,1 +4088,1 @@\n-  \/\/ Add a reference to the loader (actually mirror because unsafe anonymous classes will not have\n+  \/\/ Add a reference to the loader (actually mirror because hidden classes may not have\n@@ -4004,1 +4117,1 @@\n-  InstanceKlass* k = SystemDictionary::MethodType_klass();\n+  InstanceKlass* k = vmClasses::MethodType_klass();\n@@ -4098,1 +4211,1 @@\n-  InstanceKlass* k = SystemDictionary::CallSite_klass();\n+  InstanceKlass* k = vmClasses::CallSite_klass();\n@@ -4123,1 +4236,1 @@\n-  InstanceKlass* k = SystemDictionary::ConstantCallSite_klass();\n+  InstanceKlass* k = vmClasses::ConstantCallSite_klass();\n@@ -4139,1 +4252,1 @@\n-  InstanceKlass* k = SystemDictionary::Context_klass();\n+  InstanceKlass* k = vmClasses::Context_klass();\n@@ -4172,1 +4285,1 @@\n-  InstanceKlass* k = SystemDictionary::AccessControlContext_klass();\n+  InstanceKlass* k = vmClasses::AccessControlContext_klass();\n@@ -4186,1 +4299,1 @@\n-  SystemDictionary::AccessControlContext_klass()->initialize(CHECK_NULL);\n+  vmClasses::AccessControlContext_klass()->initialize(CHECK_NULL);\n@@ -4188,1 +4301,1 @@\n-  oop result = SystemDictionary::AccessControlContext_klass()->allocate_instance(CHECK_NULL);\n+  oop result = vmClasses::AccessControlContext_klass()->allocate_instance(CHECK_NULL);\n@@ -4193,1 +4306,0 @@\n-  \/\/ whitelist AccessControlContexts created by the JVM\n@@ -4234,1 +4346,1 @@\n-  InstanceKlass* k1 = SystemDictionary::ClassLoader_klass();\n+  InstanceKlass* k1 = vmClasses::ClassLoader_klass();\n@@ -4315,1 +4427,1 @@\n-    Klass* delegating_cl_class = SystemDictionary::reflect_DelegatingClassLoader_klass();\n+    Klass* delegating_cl_class = vmClasses::reflect_DelegatingClassLoader_klass();\n@@ -4345,0 +4457,2 @@\n+int java_lang_System::_static_allow_security_offset;\n+int java_lang_System::_static_never_offset;\n@@ -4350,1 +4464,3 @@\n-  macro(_static_security_offset, k, \"security\", security_manager_signature, true)\n+  macro(_static_security_offset, k, \"security\", security_manager_signature, true); \\\n+  macro(_static_allow_security_offset, k, \"allowSecurityManager\", int_signature, true); \\\n+  macro(_static_never_offset, k, \"NEVER\", int_signature, true)\n@@ -4353,1 +4469,1 @@\n-  InstanceKlass* k = SystemDictionary::System_klass();\n+  InstanceKlass* k = vmClasses::System_klass();\n@@ -4357,0 +4473,19 @@\n+\/\/ This field tells us that a security manager can never be installed so we\n+\/\/ can completely skip populating the ProtectionDomainCacheTable.\n+bool java_lang_System::allow_security_manager() {\n+  static int initialized = false;\n+  static bool allowed = true; \/\/ default\n+  if (!initialized) {\n+    oop base = vmClasses::System_klass()->static_field_base_raw();\n+    int never = base->int_field(_static_never_offset);\n+    allowed = (base->int_field(_static_allow_security_offset) != never);\n+  }\n+  return allowed;\n+}\n+\n+\/\/ This field tells us that a security manager is installed.\n+bool java_lang_System::has_security_manager() {\n+  oop base = vmClasses::System_klass()->static_field_base_raw();\n+  return base->obj_field(_static_security_offset) != NULL;\n+}\n+\n@@ -4385,1 +4520,1 @@\n-    assert(fd->field_holder() == SystemDictionary::UnsafeConstants_klass(), \"Should be UnsafeConstants\");\n+    assert(fd->field_holder() == vmClasses::UnsafeConstants_klass(), \"Should be UnsafeConstants\");\n@@ -4406,1 +4541,1 @@\n-  SystemDictionary::UnsafeConstants_klass()->do_local_static_fields(&fixup);\n+  vmClasses::UnsafeConstants_klass()->do_local_static_fields(&fixup);\n@@ -4433,1 +4568,1 @@\n-  InstanceKlass* k = SystemDictionary::StackTraceElement_klass();\n+  InstanceKlass* k = vmClasses::StackTraceElement_klass();\n@@ -4493,1 +4628,1 @@\n-  InstanceKlass* k = SystemDictionary::AssertionStatusDirectives_klass();\n+  InstanceKlass* k = vmClasses::AssertionStatusDirectives_klass();\n@@ -4532,1 +4667,1 @@\n-  InstanceKlass* k = SystemDictionary::nio_Buffer_klass();\n+  InstanceKlass* k = vmClasses::nio_Buffer_klass();\n@@ -4549,1 +4684,1 @@\n-  InstanceKlass* k = SystemDictionary::java_util_concurrent_locks_AbstractOwnableSynchronizer_klass();\n+  InstanceKlass* k = vmClasses::java_util_concurrent_locks_AbstractOwnableSynchronizer_klass();\n@@ -4564,0 +4699,24 @@\n+int vector_VectorPayload::_payload_offset;\n+\n+#define VECTORPAYLOAD_FIELDS_DO(macro) \\\n+  macro(_payload_offset, k, \"payload\", object_signature, false)\n+\n+void vector_VectorPayload::compute_offsets() {\n+  InstanceKlass* k = vmClasses::vector_VectorPayload_klass();\n+  VECTORPAYLOAD_FIELDS_DO(FIELD_COMPUTE_OFFSET);\n+}\n+\n+#if INCLUDE_CDS\n+void vector_VectorPayload::serialize_offsets(SerializeClosure* f) {\n+  VECTORPAYLOAD_FIELDS_DO(FIELD_SERIALIZE_OFFSET);\n+}\n+#endif\n+\n+void vector_VectorPayload::set_payload(oop o, oop val) {\n+  o->obj_field_put(_payload_offset, val);\n+}\n+\n+bool vector_VectorPayload::is_instance(oop obj) {\n+  return obj != NULL && is_subclass(obj->klass());\n+}\n+\n@@ -4781,1 +4940,1 @@\n-  InstanceKlass* k = SystemDictionary::RecordComponent_klass();\n+  InstanceKlass* k = vmClasses::RecordComponent_klass();\n@@ -4819,0 +4978,21 @@\n+\/\/ java_lang_InternalError\n+int java_lang_InternalError::_during_unsafe_access_offset;\n+\n+void java_lang_InternalError::set_during_unsafe_access(oop internal_error) {\n+  internal_error->bool_field_put(_during_unsafe_access_offset, true);\n+}\n+\n+jboolean java_lang_InternalError::during_unsafe_access(oop internal_error) {\n+  return internal_error->bool_field(_during_unsafe_access_offset);\n+}\n+\n+void java_lang_InternalError::compute_offsets() {\n+  INTERNALERROR_INJECTED_FIELDS(INJECTED_FIELD_COMPUTE_OFFSET);\n+}\n+\n+#if INCLUDE_CDS\n+void java_lang_InternalError::serialize_offsets(SerializeClosure* f) {\n+  INTERNALERROR_INJECTED_FIELDS(INJECTED_FIELD_SERIALIZE_OFFSET);\n+}\n+#endif\n+\n@@ -4836,1 +5016,1 @@\n-  \/\/ java_lang_ref_Reference) earlier inside SystemDictionary::resolve_well_known_classes()\n+  \/\/ java_lang_ref_Reference) earlier inside vmClasses::resolve_all()\n@@ -4852,2 +5032,1 @@\n-  if (klass == SystemDictionary::ClassLoader_klass() ||  \/\/ ClassLoader::loader_data is malloc'ed.\n-      klass == SystemDictionary::Module_klass() ||       \/\/ Module::module_entry is malloc'ed\n+  if (klass == vmClasses::ClassLoader_klass() ||  \/\/ ClassLoader::loader_data is malloc'ed.\n@@ -4855,1 +5034,1 @@\n-      \/\/ regular Java code. The implementation of java.lang.invoke uses generated anonymoys classes\n+      \/\/ regular Java code. The implementation of java.lang.invoke uses generated hidden classes\n@@ -4861,3 +5040,3 @@\n-      klass == SystemDictionary::ResolvedMethodName_klass() ||\n-      klass == SystemDictionary::MemberName_klass() ||\n-      klass == SystemDictionary::Context_klass()) {\n+      klass == vmClasses::ResolvedMethodName_klass() ||\n+      klass == vmClasses::MemberName_klass() ||\n+      klass == vmClasses::Context_klass()) {\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":433,"deletions":254,"binary":false,"changes":687,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,2 +28,1 @@\n-#include \"classfile\/systemDictionary.hpp\"\n-#include \"jvmtifiles\/jvmti.h\"\n+#include \"classfile\/vmClasses.hpp\"\n@@ -31,0 +30,2 @@\n+#include \"oops\/instanceKlass.hpp\"\n+#include \"oops\/symbol.hpp\"\n@@ -32,0 +33,1 @@\n+#include \"utilities\/vmEnums.hpp\"\n@@ -49,0 +51,1 @@\n+  f(java_lang_InternalError) \\\n@@ -75,0 +78,1 @@\n+  f(jdk_internal_invoke_NativeEntryPoint) \\\n@@ -77,0 +81,1 @@\n+  f(vector_VectorPayload) \\\n@@ -94,0 +99,5 @@\n+\/\/ The flags field is a collection of bits representing boolean values used\n+\/\/ internally by the VM.\n+#define STRING_INJECTED_FIELDS(macro) \\\n+  macro(java_lang_String, flags, byte_signature, false)\n+\n@@ -100,0 +110,1 @@\n+  static int _flags_offset;\n@@ -107,0 +118,13 @@\n+  \/\/ Bitmasks for values in the injected flags field.\n+  static const uint8_t _deduplication_forbidden_mask = 1 << 0;\n+  static const uint8_t _deduplication_requested_mask = 1 << 1;\n+\n+  static int flags_offset() { CHECK_INIT(_flags_offset); }\n+  \/\/ Return the address of the injected flags field.\n+  static inline uint8_t* flags_addr(oop java_string);\n+  \/\/ Test whether the designated bit of the injected flags field is set.\n+  static inline bool is_flag_set(oop java_string, uint8_t flag_mask);\n+  \/\/ Atomically test and set the designated bit of the injected flags field,\n+  \/\/ returning true if the bit was already set.\n+  static bool test_and_set_flag(oop java_string, uint8_t flag_mask);\n+\n@@ -135,0 +159,13 @@\n+  \/\/ Set the deduplication_forbidden flag true.  This flag is sticky; once\n+  \/\/ set it never gets cleared.  This is set when a String is interned in\n+  \/\/ the StringTable, to prevent string deduplication from changing the\n+  \/\/ String's value array.\n+  static inline void set_deduplication_forbidden(oop java_string);\n+\n+  \/\/ Test and set the deduplication_requested flag.  Returns the old value\n+  \/\/ of the flag.  This flag is sticky; once set it never gets cleared.\n+  \/\/ Some GCs may use this flag when deciding whether to request\n+  \/\/ deduplication of a String, to avoid multiple requests for the same\n+  \/\/ object.\n+  static inline bool test_and_set_deduplication_requested(oop java_string);\n+\n@@ -140,0 +177,2 @@\n+  static inline bool deduplication_forbidden(oop java_string);\n+  static inline bool deduplication_requested(oop java_string);\n@@ -155,0 +194,1 @@\n+  static jchar* as_unicode_string_or_null(oop java_string, int& length);\n@@ -259,1 +299,1 @@\n-  static void set_mirror_module_field(Klass* K, Handle mirror, Handle module, TRAPS);\n+  static void set_mirror_module_field(JavaThread* current, Klass* K, Handle mirror, Handle module);\n@@ -274,3 +314,3 @@\n-  static void archive_basic_type_mirrors(TRAPS) NOT_CDS_JAVA_HEAP_RETURN;\n-  static oop  archive_mirror(Klass* k, TRAPS) NOT_CDS_JAVA_HEAP_RETURN_(NULL);\n-  static oop  process_archived_mirror(Klass* k, oop mirror, oop archived_mirror, Thread *THREAD)\n+  static void archive_basic_type_mirrors() NOT_CDS_JAVA_HEAP_RETURN;\n+  static oop  archive_mirror(Klass* k) NOT_CDS_JAVA_HEAP_RETURN_(NULL);\n+  static oop  process_archived_mirror(Klass* k, oop mirror, oop archived_mirror)\n@@ -324,0 +364,2 @@\n+  static int component_mirror_offset() { return _component_mirror_offset; }\n+\n@@ -383,2 +425,0 @@\n-  \/\/ Instance creation\n-  static oop create();\n@@ -421,32 +461,1 @@\n-  \/\/ Java Thread Status for JVMTI and M&M use.\n-  \/\/ This thread status info is saved in threadStatus field of\n-  \/\/ java.lang.Thread java class.\n-  enum ThreadStatus {\n-    NEW                      = 0,\n-    RUNNABLE                 = JVMTI_THREAD_STATE_ALIVE +          \/\/ runnable \/ running\n-                               JVMTI_THREAD_STATE_RUNNABLE,\n-    SLEEPING                 = JVMTI_THREAD_STATE_ALIVE +          \/\/ Thread.sleep()\n-                               JVMTI_THREAD_STATE_WAITING +\n-                               JVMTI_THREAD_STATE_WAITING_WITH_TIMEOUT +\n-                               JVMTI_THREAD_STATE_SLEEPING,\n-    IN_OBJECT_WAIT           = JVMTI_THREAD_STATE_ALIVE +          \/\/ Object.wait()\n-                               JVMTI_THREAD_STATE_WAITING +\n-                               JVMTI_THREAD_STATE_WAITING_INDEFINITELY +\n-                               JVMTI_THREAD_STATE_IN_OBJECT_WAIT,\n-    IN_OBJECT_WAIT_TIMED     = JVMTI_THREAD_STATE_ALIVE +          \/\/ Object.wait(long)\n-                               JVMTI_THREAD_STATE_WAITING +\n-                               JVMTI_THREAD_STATE_WAITING_WITH_TIMEOUT +\n-                               JVMTI_THREAD_STATE_IN_OBJECT_WAIT,\n-    PARKED                   = JVMTI_THREAD_STATE_ALIVE +          \/\/ LockSupport.park()\n-                               JVMTI_THREAD_STATE_WAITING +\n-                               JVMTI_THREAD_STATE_WAITING_INDEFINITELY +\n-                               JVMTI_THREAD_STATE_PARKED,\n-    PARKED_TIMED             = JVMTI_THREAD_STATE_ALIVE +          \/\/ LockSupport.park(long)\n-                               JVMTI_THREAD_STATE_WAITING +\n-                               JVMTI_THREAD_STATE_WAITING_WITH_TIMEOUT +\n-                               JVMTI_THREAD_STATE_PARKED,\n-    BLOCKED_ON_MONITOR_ENTER = JVMTI_THREAD_STATE_ALIVE +          \/\/ (re-)entering a synchronization block\n-                               JVMTI_THREAD_STATE_BLOCKED_ON_MONITOR_ENTER,\n-    TERMINATED               = JVMTI_THREAD_STATE_TERMINATED\n-  };\n-  static void set_thread_status(oop java_thread_oop, ThreadStatus status);\n+  static void set_thread_status(oop java_thread_oop, JavaThreadStatus status);\n@@ -455,1 +464,1 @@\n-  static ThreadStatus get_thread_status(oop java_thread_oop);\n+  static JavaThreadStatus get_thread_status(oop java_thread_oop);\n@@ -530,0 +539,1 @@\n+  static int _cause_offset;\n@@ -547,0 +557,1 @@\n+  static oop cause(oop throwable);\n@@ -550,1 +561,0 @@\n-  static void print_stack_usage(Handle stream);\n@@ -735,2 +745,0 @@\n-  static void set_parameter_annotations(oop method, oop value);\n-  static void set_annotation_default(oop method, oop value);\n@@ -803,0 +811,1 @@\n+    static ModuleEntry* module_entry_raw(oop module);\n@@ -903,3 +912,4 @@\n-  static inline oop referent(oop ref);\n-  static inline void set_referent(oop ref, oop value);\n-  static inline void set_referent_raw(oop ref, oop value);\n+  static inline oop weak_referent_no_keepalive(oop ref);\n+  static inline oop phantom_referent_no_keepalive(oop ref);\n+  static inline oop unknown_referent_no_keepalive(oop ref);\n+  static inline void clear_referent(oop ref);\n@@ -915,2 +925,0 @@\n-  static inline oop queue(oop ref);\n-  static inline void set_queue(oop ref, oop value);\n@@ -951,2 +959,0 @@\n-class MethodHandleEntry;\n-\n@@ -974,1 +980,1 @@\n-    return klass->is_subclass_of(SystemDictionary::MethodHandle_klass());\n+    return klass->is_subclass_of(vmClasses::MethodHandle_klass());\n@@ -1001,1 +1007,1 @@\n-    return klass->is_subclass_of(SystemDictionary::DirectMethodHandle_klass());\n+    return klass->is_subclass_of(vmClasses::DirectMethodHandle_klass());\n@@ -1025,1 +1031,0 @@\n-  static void       set_vmentry(oop lform, oop invoker);\n@@ -1029,2 +1034,2 @@\n-    return SystemDictionary::LambdaForm_klass() != NULL &&\n-      klass->is_subclass_of(SystemDictionary::LambdaForm_klass());\n+    return vmClasses::LambdaForm_klass() != NULL &&\n+      klass->is_subclass_of(vmClasses::LambdaForm_klass());\n@@ -1038,0 +1043,42 @@\n+\/\/ Interface to java.lang.invoke.NativeEntryPoint objects\n+\/\/ (These are a private interface for managing adapter code generation.)\n+\n+class jdk_internal_invoke_NativeEntryPoint: AllStatic {\n+  friend class JavaClasses;\n+\n+ private:\n+  static int _shadow_space_offset;\n+  static int _argMoves_offset;\n+  static int _returnMoves_offset;\n+  static int _need_transition_offset;\n+  static int _method_type_offset;\n+  static int _name_offset;\n+\n+  static void compute_offsets();\n+\n+ public:\n+  static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;\n+\n+  \/\/ Accessors\n+  static jint       shadow_space(oop entry);\n+  static oop        argMoves(oop entry);\n+  static oop        returnMoves(oop entry);\n+  static jboolean   need_transition(oop entry);\n+  static oop        method_type(oop entry);\n+  static oop        name(oop entry);\n+\n+  \/\/ Testers\n+  static bool is_subclass(Klass* klass) {\n+    return vmClasses::NativeEntryPoint_klass() != NULL &&\n+      klass->is_subclass_of(vmClasses::NativeEntryPoint_klass());\n+  }\n+  static bool is_instance(oop obj);\n+\n+  \/\/ Accessors for code generation:\n+  static int shadow_space_offset_in_bytes()    { return _shadow_space_offset;    }\n+  static int argMoves_offset_in_bytes()        { return _argMoves_offset;        }\n+  static int returnMoves_offset_in_bytes()     { return _returnMoves_offset;     }\n+  static int need_transition_offset_in_bytes() { return _need_transition_offset; }\n+  static int method_type_offset_in_bytes()     { return _method_type_offset;     }\n+  static int name_offset_in_bytes()            { return _name_offset;            }\n+};\n@@ -1118,1 +1165,1 @@\n-    return klass->is_subclass_of(SystemDictionary::MemberName_klass());\n+    return klass->is_subclass_of(vmClasses::MemberName_klass());\n@@ -1140,1 +1187,5 @@\n-    MN_ACCESS_VM_ANNOTATIONS = 0x00000008\n+    MN_ACCESS_VM_ANNOTATIONS = 0x00000008,\n+    \/\/ Lookup modes\n+    MN_MODULE_MODE           = 0x00000010,\n+    MN_UNCONDITIONAL_MODE    = 0x00000020,\n+    MN_TRUSTED_MODE          = -1\n@@ -1210,1 +1261,1 @@\n-    return klass->is_subclass_of(SystemDictionary::CallSite_klass());\n+    return klass->is_subclass_of(vmClasses::CallSite_klass());\n@@ -1236,1 +1287,1 @@\n-    return klass->is_subclass_of(SystemDictionary::ConstantCallSite_klass());\n+    return klass->is_subclass_of(vmClasses::ConstantCallSite_klass());\n@@ -1265,1 +1316,1 @@\n-    return klass->is_subclass_of(SystemDictionary::Context_klass());\n+    return klass->is_subclass_of(vmClasses::Context_klass());\n@@ -1333,1 +1384,1 @@\n-    return klass->is_subclass_of(SystemDictionary::ClassLoader_klass());\n+    return klass->is_subclass_of(vmClasses::ClassLoader_klass());\n@@ -1352,0 +1403,2 @@\n+  static int _static_allow_security_offset;\n+  static int _static_never_offset;\n@@ -1357,0 +1410,2 @@\n+  static bool allow_security_manager();\n+  static bool has_security_manager();\n@@ -1564,0 +1619,18 @@\n+\/\/ Interface to jdk.internal.vm.vector.VectorSupport.VectorPayload objects\n+\n+class vector_VectorPayload : AllStatic {\n+ private:\n+  static int _payload_offset;\n+ public:\n+  static void set_payload(oop o, oop val);\n+\n+  static void compute_offsets();\n+  static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;\n+\n+  \/\/ Testers\n+  static bool is_subclass(Klass* klass) {\n+    return klass->is_subclass_of(vmClasses::vector_VectorPayload_klass());\n+  }\n+  static bool is_instance(oop obj);\n+};\n+\n@@ -1652,0 +1725,16 @@\n+\n+\/\/ Interface to java.lang.InternalError objects\n+\n+#define INTERNALERROR_INJECTED_FIELDS(macro)                      \\\n+  macro(java_lang_InternalError, during_unsafe_access, bool_signature, false)\n+\n+class java_lang_InternalError : AllStatic {\n+ private:\n+  static int _during_unsafe_access_offset;\n+ public:\n+  static jboolean during_unsafe_access(oop internal_error);\n+  static void set_during_unsafe_access(oop internal_error);\n+  static void compute_offsets();\n+  static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;\n+};\n+\n@@ -1663,3 +1752,3 @@\n-  const SystemDictionary::WKID klass_id;\n-  const vmSymbols::SID name_index;\n-  const vmSymbols::SID signature_index;\n+  const vmClassID klass_id;\n+  const vmSymbolID name_index;\n+  const vmSymbolID signature_index;\n@@ -1669,1 +1758,1 @@\n-  Klass* klass() const    { return SystemDictionary::well_known_klass(klass_id); }\n+  Klass* klass() const      { return vmClasses::klass_at(klass_id); }\n@@ -1676,2 +1765,2 @@\n-  static Symbol* lookup_symbol(int symbol_index) {\n-    return vmSymbols::symbol_at((vmSymbols::SID)symbol_index);\n+  static Symbol* lookup_symbol(vmSymbolID symbol_index) {\n+    return Symbol::vm_symbol_at(symbol_index);\n@@ -1685,0 +1774,1 @@\n+  STRING_INJECTED_FIELDS(macro)             \\\n@@ -1691,1 +1781,3 @@\n-  MODULE_INJECTED_FIELDS(macro)\n+  MODULE_INJECTED_FIELDS(macro)             \\\n+  INTERNALERROR_INJECTED_FIELDS(macro)\n+\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.hpp","additions":162,"deletions":70,"binary":false,"changes":232,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,1 +27,1 @@\n-#include \"aot\/aotLoader.hpp\"\n+#include \"cds\/heapShared.hpp\"\n@@ -34,0 +34,1 @@\n+#include \"classfile\/classLoadInfo.hpp\"\n@@ -45,0 +46,1 @@\n+#include \"classfile\/vmClasses.hpp\"\n@@ -47,3 +49,1 @@\n-#include \"compiler\/compileBroker.hpp\"\n-#include \"interpreter\/bytecodeStream.hpp\"\n-#include \"interpreter\/interpreter.hpp\"\n+#include \"interpreter\/bootstrapInfo.hpp\"\n@@ -54,2 +54,0 @@\n-#include \"memory\/filemap.hpp\"\n-#include \"memory\/heapShared.hpp\"\n@@ -62,1 +60,0 @@\n-#include \"oops\/instanceRefKlass.hpp\"\n@@ -65,1 +62,0 @@\n-#include \"oops\/methodData.hpp\"\n@@ -94,2 +90,0 @@\n-PlaceholderTable*      SystemDictionary::_placeholders        = NULL;\n-LoaderConstraintTable* SystemDictionary::_loader_constraints  = NULL;\n@@ -100,7 +94,0 @@\n-InstanceKlass*      SystemDictionary::_well_known_klasses[SystemDictionary::WKID_LIMIT]\n-                                                          =  { NULL \/*, NULL...*\/ };\n-\n-InstanceKlass*      SystemDictionary::_box_klasses[T_VOID+1]      =  { NULL \/*, NULL...*\/ };\n-\n-\n-OopHandle   SystemDictionary::_system_loader_lock_obj;\n@@ -111,1 +98,0 @@\n-\n@@ -114,39 +100,2 @@\n-ClassLoadInfo::ClassLoadInfo() {\n-  _protection_domain = Handle();\n-  _unsafe_anonymous_host = NULL;\n-  _cp_patches = NULL;\n-  _class_hidden_info._dynamic_nest_host = NULL;\n-  _class_hidden_info._class_data = Handle();\n-  _is_hidden = false;\n-  _is_strong_hidden = false;\n-  _can_access_vm_annotations = false;\n-}\n-\n-ClassLoadInfo::ClassLoadInfo(Handle protection_domain) {\n-  _protection_domain = protection_domain;\n-  _unsafe_anonymous_host = NULL;\n-  _cp_patches = NULL;\n-  _class_hidden_info._dynamic_nest_host = NULL;\n-  _class_hidden_info._class_data = Handle();\n-  _is_hidden = false;\n-  _is_strong_hidden = false;\n-  _can_access_vm_annotations = false;\n-}\n-\n-ClassLoadInfo::ClassLoadInfo(Handle protection_domain,\n-                             const InstanceKlass* unsafe_anonymous_host,\n-                             GrowableArray<Handle>* cp_patches,\n-                             InstanceKlass* dynamic_nest_host,\n-                             Handle class_data,\n-                             bool is_hidden,\n-                             bool is_strong_hidden,\n-                             bool can_access_vm_annotations) {\n-  _protection_domain = protection_domain;\n-  _unsafe_anonymous_host = unsafe_anonymous_host;\n-  _cp_patches = cp_patches;\n-  _class_hidden_info._dynamic_nest_host = dynamic_nest_host;\n-  _class_hidden_info._class_data = class_data;\n-  _is_hidden = is_hidden;\n-  _is_strong_hidden = is_strong_hidden;\n-  _can_access_vm_annotations = can_access_vm_annotations;\n-}\n+const int _resolution_error_size  = 107;                     \/\/ number of entries in resolution error table\n+const int _invoke_method_size     = 139;                     \/\/ number of entries in invoke method table\n@@ -154,2 +103,4 @@\n-\/\/ ----------------------------------------------------------------------------\n-\/\/ Java-level SystemLoader and PlatformLoader\n+\/\/ Hashtable holding placeholders for classes being loaded.\n+const int _placeholder_table_size = 1009;\n+static PlaceholderTable* _placeholders   = NULL;\n+static PlaceholderTable*   placeholders() { return _placeholders; }\n@@ -157,3 +108,4 @@\n-oop SystemDictionary::system_loader_lock() {\n-  return _system_loader_lock_obj.resolve();\n-}\n+\/\/ Constraints on class loaders\n+const int _loader_constraint_size = 107;                     \/\/ number of entries in constraint table\n+static LoaderConstraintTable*  _loader_constraints;\n+static LoaderConstraintTable* constraints() { return _loader_constraints; }\n@@ -161,0 +113,2 @@\n+\/\/ ----------------------------------------------------------------------------\n+\/\/ Java-level SystemLoader and PlatformLoader\n@@ -171,1 +125,1 @@\n-  InstanceKlass* class_loader_klass = SystemDictionary::ClassLoader_klass();\n+  InstanceKlass* class_loader_klass = vmClasses::ClassLoader_klass();\n@@ -178,1 +132,1 @@\n-  _java_system_loader = OopHandle::create((oop)result.get_jobject());\n+  _java_system_loader = OopHandle(Universe::vm_global(), result.get_oop());\n@@ -186,1 +140,1 @@\n-  _java_platform_loader = OopHandle::create((oop)result.get_jobject());\n+  _java_platform_loader = OopHandle(Universe::vm_global(), result.get_oop());\n@@ -202,1 +156,1 @@\n-bool SystemDictionary::is_parallelCapable(Handle class_loader) {\n+bool is_parallelCapable(Handle class_loader) {\n@@ -209,1 +163,1 @@\n-bool SystemDictionary::is_parallelDefine(Handle class_loader) {\n+bool is_parallelDefine(Handle class_loader) {\n@@ -224,1 +178,1 @@\n-  return (class_loader->klass() == SystemDictionary::jdk_internal_loader_ClassLoaders_AppClassLoader_klass() ||\n+  return (class_loader->klass() == vmClasses::jdk_internal_loader_ClassLoaders_AppClassLoader_klass() ||\n@@ -233,1 +187,10 @@\n-  return (class_loader->klass() == SystemDictionary::jdk_internal_loader_ClassLoaders_PlatformClassLoader_klass());\n+  return (class_loader->klass() == vmClasses::jdk_internal_loader_ClassLoaders_PlatformClassLoader_klass());\n+}\n+\n+Handle SystemDictionary::get_loader_lock_or_null(Handle class_loader) {\n+  \/\/ If class_loader is NULL or parallelCapable, the JVM doesn't acquire a lock while loading.\n+  if (is_parallelCapable(class_loader)) {\n+    return Handle();\n+  } else {\n+    return class_loader;\n+  }\n@@ -260,9 +223,10 @@\n-\/\/ Forwards to resolve_or_null\n-\n-Klass* SystemDictionary::resolve_or_fail(Symbol* class_name, Handle class_loader, Handle protection_domain, bool throw_error, TRAPS) {\n-  Klass* klass = resolve_or_null(class_name, class_loader, protection_domain, THREAD);\n-  if (HAS_PENDING_EXCEPTION || klass == NULL) {\n-    \/\/ can return a null klass\n-    klass = handle_resolution_exception(class_name, throw_error, klass, THREAD);\n-  }\n-  return klass;\n+#ifdef ASSERT\n+\/\/ Used to verify that class loading succeeded in adding k to the dictionary.\n+void verify_dictionary_entry(Symbol* class_name, InstanceKlass* k) {\n+  MutexLocker mu(SystemDictionary_lock);\n+  ClassLoaderData* loader_data = k->class_loader_data();\n+  Dictionary* dictionary = loader_data->dictionary();\n+  assert(class_name == k->name(), \"Must be the same\");\n+  unsigned int name_hash = dictionary->compute_hash(class_name);\n+  InstanceKlass* kk = dictionary->find_class(name_hash, class_name);\n+  assert(kk == k, \"should be present in dictionary\");\n@@ -270,0 +234,1 @@\n+#endif\n@@ -271,3 +236,1 @@\n-Klass* SystemDictionary::handle_resolution_exception(Symbol* class_name,\n-                                                     bool throw_error,\n-                                                     Klass* klass, TRAPS) {\n+static void handle_resolution_exception(Symbol* class_name, bool throw_error, TRAPS) {\n@@ -277,3 +240,2 @@\n-    \/\/ and if so convert it to a NoClassDefFoundError\n-    \/\/ And chain the original ClassNotFoundException\n-    if (throw_error && PENDING_EXCEPTION->is_a(SystemDictionary::ClassNotFoundException_klass())) {\n+    \/\/ and convert it to a NoClassDefFoundError and chain the original ClassNotFoundException.\n+    if (throw_error && PENDING_EXCEPTION->is_a(vmClasses::ClassNotFoundException_klass())) {\n@@ -281,1 +243,0 @@\n-      assert(klass == NULL, \"Should not have result with exception pending\");\n@@ -284,1 +245,1 @@\n-      THROW_MSG_CAUSE_NULL(vmSymbols::java_lang_NoClassDefFoundError(), class_name->as_C_string(), e);\n+      THROW_MSG_CAUSE(vmSymbols::java_lang_NoClassDefFoundError(), class_name->as_C_string(), e);\n@@ -286,1 +247,1 @@\n-      return NULL;\n+      return; \/\/ the caller will throw the incoming exception\n@@ -289,8 +250,7 @@\n-  \/\/ Class not found, throw appropriate error or exception depending on value of throw_error\n-  if (klass == NULL) {\n-    ResourceMark rm(THREAD);\n-    if (throw_error) {\n-      THROW_MSG_NULL(vmSymbols::java_lang_NoClassDefFoundError(), class_name->as_C_string());\n-    } else {\n-      THROW_MSG_NULL(vmSymbols::java_lang_ClassNotFoundException(), class_name->as_C_string());\n-    }\n+  \/\/ If the class is not found, ie, caller has checked that klass is NULL, throw the appropriate\n+  \/\/ error or exception depending on the value of throw_error.\n+  ResourceMark rm(THREAD);\n+  if (throw_error) {\n+    THROW_MSG(vmSymbols::java_lang_NoClassDefFoundError(), class_name->as_C_string());\n+  } else {\n+    THROW_MSG(vmSymbols::java_lang_ClassNotFoundException(), class_name->as_C_string());\n@@ -298,1 +258,0 @@\n-  return klass;\n@@ -301,0 +260,1 @@\n+\/\/ Forwards to resolve_or_null\n@@ -302,4 +262,8 @@\n-Klass* SystemDictionary::resolve_or_fail(Symbol* class_name,\n-                                           bool throw_error, TRAPS)\n-{\n-  return resolve_or_fail(class_name, Handle(), Handle(), throw_error, THREAD);\n+Klass* SystemDictionary::resolve_or_fail(Symbol* class_name, Handle class_loader, Handle protection_domain,\n+                                         bool throw_error, TRAPS) {\n+  Klass* klass = resolve_or_null(class_name, class_loader, protection_domain, THREAD);\n+  \/\/ Check for pending exception or null klass, and throw exception\n+  if (HAS_PENDING_EXCEPTION || klass == NULL) {\n+    handle_resolution_exception(class_name, throw_error, CHECK_NULL);\n+  }\n+  return klass;\n@@ -308,1 +272,0 @@\n-\n@@ -336,4 +299,0 @@\n-Klass* SystemDictionary::resolve_or_null(Symbol* class_name, TRAPS) {\n-  return resolve_or_null(class_name, Handle(), Handle(), THREAD);\n-}\n-\n@@ -368,0 +327,10 @@\n+static inline void log_circularity_error(Thread* thread, PlaceholderEntry* probe) {\n+  LogTarget(Debug, class, load, placeholders) lt;\n+  if (lt.is_enabled()) {\n+    ResourceMark rm(thread);\n+    LogStream ls(lt);\n+    ls.print(\"ClassCircularityError detected for placeholder \");\n+    probe->print_entry(&ls);\n+    ls.cr();\n+  }\n+}\n@@ -369,1 +338,1 @@\n-\/\/ Must be called for any super-class or super-interface resolution\n+\/\/ Must be called for any superclass or superinterface resolution\n@@ -371,4 +340,4 @@\n-\/\/ super-interface callers:\n-\/\/    parse_interfaces - for defineClass & jvmtiRedefineClasses\n-\/\/ super-class callers:\n-\/\/   ClassFileParser - for defineClass & jvmtiRedefineClasses\n+\/\/ superinterface callers:\n+\/\/    parse_interfaces - from defineClass\n+\/\/ superclass callers:\n+\/\/   ClassFileParser - from defineClass\n@@ -380,29 +349,10 @@\n-\/\/      if another thread is trying to resolve the class, it must do\n-\/\/      super-class checks on its own thread to catch class circularity\n-\/\/ This last call is critical in class circularity checking for cases\n-\/\/ where classloading is delegated to different threads and the\n-\/\/ classloader lock is released.\n-\/\/ Take the case: Base->Super->Base\n-\/\/   1. If thread T1 tries to do a defineClass of class Base\n-\/\/    resolve_super_or_fail creates placeholder: T1, Base (super Super)\n-\/\/   2. resolve_instance_class_or_null does not find SD or placeholder for Super\n-\/\/    so it tries to load Super\n-\/\/   3. If we load the class internally, or user classloader uses same thread\n-\/\/      loadClassFromxxx or defineClass via parseClassFile Super ...\n-\/\/      3.1 resolve_super_or_fail creates placeholder: T1, Super (super Base)\n-\/\/      3.3 resolve_instance_class_or_null Base, finds placeholder for Base\n-\/\/      3.4 calls resolve_super_or_fail Base\n-\/\/      3.5 finds T1,Base -> throws class circularity\n-\/\/OR 4. If T2 tries to resolve Super via defineClass Super ...\n-\/\/      4.1 resolve_super_or_fail creates placeholder: T2, Super (super Base)\n-\/\/      4.2 resolve_instance_class_or_null Base, finds placeholder for Base (super Super)\n-\/\/      4.3 calls resolve_super_or_fail Super in parallel on own thread T2\n-\/\/      4.4 finds T2, Super -> throws class circularity\n-\/\/ Must be called, even if superclass is null, since this is\n-\/\/ where the placeholder entry is created which claims this\n-\/\/ thread is loading this class\/classloader.\n-\/\/ Be careful when modifying this code: once you have run\n-\/\/ placeholders()->find_and_add(PlaceholderTable::LOAD_SUPER),\n-\/\/ you need to find_and_remove it before returning.\n-\/\/ So be careful to not exit with a CHECK_ macro betweeen these calls.\n-InstanceKlass* SystemDictionary::resolve_super_or_fail(Symbol* child_name,\n+\/\/      If another thread is trying to resolve the class, it must do\n+\/\/      superclass checks on its own thread to catch class circularity and\n+\/\/      to avoid deadlock.\n+\/\/\n+\/\/ resolve_super_or_fail adds a LOAD_SUPER placeholder to the placeholder table before calling\n+\/\/ resolve_instance_class_or_null. ClassCircularityError is detected when a LOAD_SUPER or LOAD_INSTANCE\n+\/\/ placeholder for the same thread, class, classloader is found.\n+\/\/ This can be seen with logging option: -Xlog:class+load+placeholders=debug.\n+\/\/\n+InstanceKlass* SystemDictionary::resolve_super_or_fail(Symbol* class_name,\n@@ -414,1 +364,3 @@\n-  assert(!Signature::is_array(super_name), \"invalid super class name\");\n+\n+  assert(super_name != NULL, \"null superclass for resolving\");\n+  assert(!Signature::is_array(super_name), \"invalid superclass name\");\n@@ -418,2 +370,2 @@\n-    InstanceKlass* k = SystemDictionaryShared::dump_time_resolve_super_or_fail(child_name,\n-        super_name, class_loader, protection_domain, is_superclass, CHECK_NULL);\n+    InstanceKlass* k = SystemDictionaryShared::lookup_super_for_unregistered_class(class_name,\n+                           super_name, is_superclass);\n@@ -426,14 +378,4 @@\n-  \/\/ Double-check, if child class is already loaded, just return super-class,interface\n-  \/\/ Don't add a placedholder if already loaded, i.e. already in appropriate class loader\n-  \/\/ dictionary.\n-  \/\/ Make sure there's a placeholder for the *child* before resolving.\n-  \/\/ Used as a claim that this thread is currently loading superclass\/classloader\n-  \/\/ Used here for ClassCircularity checks and also for heap verification\n-  \/\/ (every InstanceKlass needs to be in its class loader dictionary or have a placeholder).\n-  \/\/ Must check ClassCircularity before checking if super class is already loaded.\n-  \/\/\n-  \/\/ We might not already have a placeholder if this child_name was\n-  \/\/ first seen via resolve_from_stream (jni_DefineClass or JVM_DefineClass);\n-  \/\/ the name of the class might not be known until the stream is actually\n-  \/\/ parsed.\n-  \/\/ Bugs 4643874, 4715493\n+  \/\/ If klass is already loaded, just return the superclass or superinterface.\n+  \/\/ Make sure there's a placeholder for the class_name before resolving.\n+  \/\/ This is used as a claim that this thread is currently loading superclass\/classloader\n+  \/\/ and for ClassCircularity checks.\n@@ -443,3 +385,3 @@\n-  unsigned int d_hash = dictionary->compute_hash(child_name);\n-  unsigned int p_hash = placeholders()->compute_hash(child_name);\n-  int p_index = placeholders()->hash_to_index(p_hash);\n+  unsigned int name_hash = dictionary->compute_hash(class_name);\n+  assert(placeholders()->compute_hash(class_name) == name_hash, \"they're the same hashcode\");\n+\n@@ -447,1 +389,0 @@\n-  bool child_already_loaded = false;\n@@ -451,1 +392,1 @@\n-    InstanceKlass* childk = find_class(d_hash, child_name, dictionary);\n+    InstanceKlass* klassk = dictionary->find_class(name_hash, class_name);\n@@ -453,8 +394,5 @@\n-    \/\/ to support \/\/ loading: if child done loading, just return superclass\n-    \/\/ if super_name, & class_loader don't match:\n-    \/\/ if initial define, SD update will give LinkageError\n-    \/\/ if redefine: compare_class_versions will give HIERARCHY_CHANGED\n-    \/\/ so we don't throw an exception here.\n-    \/\/ see: nsk redefclass014 & java.lang.instrument Instrument032\n-    if ((childk != NULL ) && (is_superclass) &&\n-        ((quicksuperk = childk->java_super()) != NULL) &&\n+    \/\/ To support parallel loading: if class is done loading, just return the superclass\n+    \/\/ if the super_name matches class->super()->name() and if the class loaders match.\n+    \/\/ Otherwise, a LinkageError will be thrown later.\n+    if (klassk != NULL && is_superclass &&\n+        ((quicksuperk = klassk->java_super()) != NULL) &&\n@@ -465,1 +403,2 @@\n-      PlaceholderEntry* probe = placeholders()->get_entry(p_index, p_hash, child_name, loader_data);\n+      \/\/ Must check ClassCircularity before checking if superclass is already loaded.\n+      PlaceholderEntry* probe = placeholders()->get_entry(name_hash, class_name, loader_data);\n@@ -467,0 +406,1 @@\n+          log_circularity_error(THREAD, probe);\n@@ -470,0 +410,1 @@\n+\n@@ -471,2 +412,6 @@\n-      \/\/ Be careful not to exit resolve_super\n-      PlaceholderEntry* newprobe = placeholders()->find_and_add(p_index, p_hash, child_name, loader_data, PlaceholderTable::LOAD_SUPER, super_name, THREAD);\n+      \/\/ Be careful not to exit resolve_super without removing this placeholder.\n+      PlaceholderEntry* newprobe = placeholders()->find_and_add(name_hash,\n+                                                                class_name,\n+                                                                loader_data,\n+                                                                PlaceholderTable::LOAD_SUPER,\n+                                                                super_name, THREAD);\n@@ -475,0 +420,1 @@\n+\n@@ -477,1 +423,1 @@\n-      THROW_MSG_NULL(vmSymbols::java_lang_ClassCircularityError(), child_name->as_C_string());\n+      THROW_MSG_NULL(vmSymbols::java_lang_ClassCircularityError(), class_name->as_C_string());\n@@ -480,3 +426,1 @@\n-\/\/ java.lang.Object should have been found above\n-  assert(super_name != NULL, \"null super class for resolving\");\n-  \/\/ Resolve the super class or interface, check results on return\n+  \/\/ Resolve the superclass or superinterface, check results on return\n@@ -489,6 +433,1 @@\n-  \/\/ Clean up of placeholders moved so that each classloadAction registrar self-cleans up\n-  \/\/ It is no longer necessary to keep the placeholder table alive until update_dictionary\n-  \/\/ or error. GC used to walk the placeholder table as strong roots.\n-  \/\/ The instanceKlass is kept alive because the class loader is on the stack,\n-  \/\/ which keeps the loader_data alive, as well as all instanceKlasses in\n-  \/\/ the loader_data. parseClassFile adds the instanceKlass to loader_data.\n+  \/\/ Clean up placeholder entry.\n@@ -497,1 +436,1 @@\n-    placeholders()->find_and_remove(p_index, p_hash, child_name, loader_data, PlaceholderTable::LOAD_SUPER, THREAD);\n+    placeholders()->find_and_remove(name_hash, class_name, loader_data, PlaceholderTable::LOAD_SUPER, THREAD);\n@@ -500,0 +439,2 @@\n+\n+  \/\/ Check for pending exception or null superk, and throw exception\n@@ -501,6 +442,1 @@\n-    \/\/ can null superk\n-    Klass* k = handle_resolution_exception(super_name, true, superk, THREAD);\n-    assert(k == NULL || k == superk, \"must be\");\n-    if (k == NULL) {\n-      superk = NULL;\n-    }\n+    handle_resolution_exception(super_name, true, CHECK_NULL);\n@@ -512,67 +448,0 @@\n-void SystemDictionary::validate_protection_domain(InstanceKlass* klass,\n-                                                  Handle class_loader,\n-                                                  Handle protection_domain,\n-                                                  TRAPS) {\n-  \/\/ Now we have to call back to java to check if the initating class has access\n-  JavaValue result(T_VOID);\n-  LogTarget(Debug, protectiondomain) lt;\n-  if (lt.is_enabled()) {\n-    ResourceMark rm(THREAD);\n-    \/\/ Print out trace information\n-    LogStream ls(lt);\n-    ls.print_cr(\"Checking package access\");\n-    if (class_loader() != NULL) {\n-      ls.print(\"class loader: \");\n-      class_loader()->print_value_on(&ls);\n-    } else {\n-      ls.print_cr(\"class loader: NULL\");\n-    }\n-    if (protection_domain() != NULL) {\n-      ls.print(\" protection domain: \");\n-      protection_domain()->print_value_on(&ls);\n-    } else {\n-      ls.print_cr(\" protection domain: NULL\");\n-    }\n-    ls.print(\" loading: \"); klass->print_value_on(&ls);\n-    ls.cr();\n-  }\n-\n-  \/\/ This handle and the class_loader handle passed in keeps this class from\n-  \/\/ being unloaded through several GC points.\n-  \/\/ The class_loader handle passed in is the initiating loader.\n-  Handle mirror(THREAD, klass->java_mirror());\n-\n-  InstanceKlass* system_loader = SystemDictionary::ClassLoader_klass();\n-  JavaCalls::call_special(&result,\n-                         class_loader,\n-                         system_loader,\n-                         vmSymbols::checkPackageAccess_name(),\n-                         vmSymbols::class_protectiondomain_signature(),\n-                         mirror,\n-                         protection_domain,\n-                         THREAD);\n-\n-  if (HAS_PENDING_EXCEPTION) {\n-    log_debug(protectiondomain)(\"DENIED !!!!!!!!!!!!!!!!!!!!!\");\n-  } else {\n-   log_debug(protectiondomain)(\"granted\");\n-  }\n-\n-  if (HAS_PENDING_EXCEPTION) return;\n-\n-  \/\/ If no exception has been thrown, we have validated the protection domain\n-  \/\/ Insert the protection domain of the initiating class into the set.\n-  {\n-    ClassLoaderData* loader_data = class_loader_data(class_loader);\n-    Dictionary* dictionary = loader_data->dictionary();\n-\n-    Symbol*  kn = klass->name();\n-    unsigned int d_hash = dictionary->compute_hash(kn);\n-\n-    MutexLocker mu(THREAD, SystemDictionary_lock);\n-    int d_index = dictionary->hash_to_index(d_hash);\n-    dictionary->add_protection_domain(d_index, d_hash, klass,\n-                                      protection_domain, THREAD);\n-  }\n-}\n-\n@@ -603,1 +472,1 @@\n-void SystemDictionary::double_lock_wait(Handle lockObject, TRAPS) {\n+static void double_lock_wait(JavaThread* thread, Handle lockObject) {\n@@ -606,0 +475,1 @@\n+  assert(lockObject() != NULL, \"lockObject must be non-NULL\");\n@@ -607,1 +477,1 @@\n-      = ObjectSynchronizer::current_thread_holds_lock((JavaThread*)THREAD, lockObject);\n+      = ObjectSynchronizer::current_thread_holds_lock(thread, lockObject);\n@@ -609,3 +479,3 @@\n-  assert((lockObject() != _system_loader_lock_obj.resolve() &&\n-         !is_parallelCapable(lockObject)), \"unexpected double_lock_wait\");\n-  ObjectSynchronizer::notifyall(lockObject, THREAD);\n+  assert(!is_parallelCapable(lockObject), \"lockObject must not be parallelCapable\");\n+  \/\/ These don't throw exceptions.\n+  ObjectSynchronizer::notifyall(lockObject, thread);\n@@ -615,1 +485,1 @@\n-    tsan_rec = SharedRuntime::tsan_oop_rec_unlock(THREAD, lockObject());\n+    tsan_rec = SharedRuntime::tsan_oop_rec_unlock(thread, lockObject());\n@@ -618,1 +488,1 @@\n-  intx recursions =  ObjectSynchronizer::complete_exit(lockObject, THREAD);\n+  intx recursions =  ObjectSynchronizer::complete_exit(lockObject, thread);\n@@ -621,2 +491,2 @@\n-  ObjectSynchronizer::reenter(lockObject, recursions, THREAD);\n-  TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_rec_lock(THREAD, lockObject(), tsan_rec));\n+  ObjectSynchronizer::reenter(lockObject, recursions, thread);\n+  TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_rec_lock(thread, lockObject(), tsan_rec));\n@@ -626,1 +496,1 @@\n-\/\/ If the class in is in the placeholder table, class loading is in progress\n+\/\/ If the class in is in the placeholder table, class loading is in progress.\n@@ -629,28 +499,9 @@\n-\/\/ the superclass on the same thread internally, so we do parallel\n-\/\/ super class loading here.\n-\/\/ This also is critical in cases where the original thread gets stalled\n-\/\/ even in non-circularity situations.\n-\/\/ Note: must call resolve_super_or_fail even if null super -\n-\/\/ to force placeholder entry creation for this class for circularity detection\n-\/\/ Caller must check for pending exception\n-\/\/ Returns non-null Klass* if other thread has completed load\n-\/\/ and we are done,\n-\/\/ If return null Klass* and no pending exception, the caller must load the class\n-InstanceKlass* SystemDictionary::handle_parallel_super_load(\n-    Symbol* name, Symbol* superclassname, Handle class_loader,\n-    Handle protection_domain, Handle lockObject, TRAPS) {\n-\n-  ClassLoaderData* loader_data = class_loader_data(class_loader);\n-  Dictionary* dictionary = loader_data->dictionary();\n-  unsigned int d_hash = dictionary->compute_hash(name);\n-  unsigned int p_hash = placeholders()->compute_hash(name);\n-  int p_index = placeholders()->hash_to_index(p_hash);\n-\n-  \/\/ superk is not used, resolve_super called for circularity check only\n-  \/\/ This code is reached in two situations. One if this thread\n-  \/\/ is loading the same class twice (e.g. ClassCircularity, or\n-  \/\/ java.lang.instrument).\n-  \/\/ The second is if another thread started the resolve_super first\n-  \/\/ and has not yet finished.\n-  \/\/ In both cases the original caller will clean up the placeholder\n-  \/\/ entry on error.\n+\/\/ the superclass on the new thread internally, so we do parallel\n+\/\/ superclass loading here.  This avoids deadlock for ClassCircularity\n+\/\/ detection for parallelCapable class loaders that lock on a per-class lock.\n+static void handle_parallel_super_load(Symbol* name,\n+                                       Symbol* superclassname,\n+                                       Handle class_loader,\n+                                       Handle protection_domain, TRAPS) {\n+\n+  \/\/ superk is not used; resolve_super_or_fail is called for circularity check only.\n@@ -662,21 +513,25 @@\n-                                                          CHECK_NULL);\n-\n-  \/\/ parallelCapable class loaders do NOT wait for parallel superclass loads to complete\n-  \/\/ Serial class loaders and bootstrap classloader do wait for superclass loads\n- if (!class_loader.is_null() && is_parallelCapable(class_loader)) {\n-    MutexLocker mu(THREAD, SystemDictionary_lock);\n-    \/\/ Check if classloading completed while we were loading superclass or waiting\n-    return find_class(d_hash, name, dictionary);\n-  }\n-\n-  \/\/ must loop to both handle other placeholder updates\n-  \/\/ and spurious notifications\n-  bool super_load_in_progress = true;\n-  PlaceholderEntry* placeholder;\n-  while (super_load_in_progress) {\n-    MutexLocker mu(THREAD, SystemDictionary_lock);\n-    \/\/ Check if classloading completed while we were loading superclass or waiting\n-    InstanceKlass* check = find_class(d_hash, name, dictionary);\n-    if (check != NULL) {\n-      \/\/ Klass is already loaded, so just return it\n-      return check;\n+                                                          CHECK);\n+}\n+\n+\/\/ parallelCapable class loaders do NOT wait for parallel superclass loads to complete\n+\/\/ Serial class loaders and bootstrap classloader do wait for superclass loads\n+static bool should_wait_for_loading(Handle class_loader) {\n+  return class_loader.is_null() || !is_parallelCapable(class_loader);\n+}\n+\n+\/\/ For bootstrap and non-parallelCapable class loaders, check and wait for\n+\/\/ another thread to complete loading this class.\n+InstanceKlass* SystemDictionary::handle_parallel_loading(JavaThread* current,\n+                                                         unsigned int name_hash,\n+                                                         Symbol* name,\n+                                                         ClassLoaderData* loader_data,\n+                                                         Handle lockObject,\n+                                                         bool* throw_circularity_error) {\n+  PlaceholderEntry* oldprobe = placeholders()->get_entry(name_hash, name, loader_data);\n+  if (oldprobe != NULL) {\n+    \/\/ only need check_seen_thread once, not on each loop\n+    \/\/ 6341374 java\/lang\/Instrument with -Xcomp\n+    if (oldprobe->check_seen_thread(current, PlaceholderTable::LOAD_INSTANCE)) {\n+      log_circularity_error(current, oldprobe);\n+      *throw_circularity_error = true;\n+      return NULL;\n@@ -684,2 +539,5 @@\n-      placeholder = placeholders()->get_entry(p_index, p_hash, name, loader_data);\n-      if (placeholder && placeholder->super_load_in_progress() ){\n+      \/\/ Wait until the first thread has finished loading this class. Also wait until all the\n+      \/\/ threads trying to load its superclass have removed their placeholders.\n+      while (oldprobe != NULL &&\n+             (oldprobe->instance_load_in_progress() || oldprobe->super_load_in_progress())) {\n+\n@@ -698,2 +556,3 @@\n-        \/\/ We also get here for parallel bootstrap classloader\n-        if (class_loader.is_null()) {\n+        oldprobe = NULL;  \/\/ Other thread could delete this placeholder entry\n+\n+        if (lockObject.is_null()) {\n@@ -702,1 +561,1 @@\n-          double_lock_wait(lockObject, THREAD);\n+          double_lock_wait(current, lockObject);\n@@ -704,3 +563,9 @@\n-      } else {\n-        \/\/ If not in SD and not in PH, other thread's load must have failed\n-        super_load_in_progress = false;\n+\n+        \/\/ Check if classloading completed while we were waiting\n+        InstanceKlass* check = loader_data->dictionary()->find_class(name_hash, name);\n+        if (check != NULL) {\n+          \/\/ Klass is already loaded, so just return it\n+          return check;\n+        }\n+        \/\/ check if other thread failed to load and cleaned up\n+        oldprobe = placeholders()->get_entry(name_hash, name, loader_data);\n@@ -723,7 +588,5 @@\n-\n-\/\/ Be careful when modifying this code: once you have run\n-\/\/ placeholders()->find_and_add(PlaceholderTable::LOAD_INSTANCE),\n-\/\/ you need to find_and_remove it before returning.\n-\/\/ So be careful to not exit with a CHECK_ macro betweeen these calls.\n-\/\/\n-\/\/ name must be in the form of \"java\/lang\/Object\" -- cannot be \"Ljava\/lang\/Object;\"\n+\/\/ SystemDictionary::resolve_instance_class_or_null is the main function for class name resolution.\n+\/\/ After checking if the InstanceKlass already exists, it checks for ClassCircularityError and\n+\/\/ whether the thread must wait for loading in parallel.  It eventually calls load_instance_class,\n+\/\/ which will load the class via the bootstrap loader or call ClassLoader.loadClass().\n+\/\/ This can return NULL, an exception or an InstanceKlass.\n@@ -734,0 +597,1 @@\n+  \/\/ name must be in the form of \"java\/lang\/Object\" -- cannot be \"Ljava\/lang\/Object;\"\n@@ -745,1 +609,1 @@\n-  unsigned int d_hash = dictionary->compute_hash(name);\n+  unsigned int name_hash = dictionary->compute_hash(name);\n@@ -747,2 +611,2 @@\n-  \/\/ Do lookup to see if class already exist and the protection domain\n-  \/\/ has the right access\n+  \/\/ Do lookup to see if class already exists and the protection domain\n+  \/\/ has the right access.\n@@ -750,7 +614,4 @@\n-  \/\/ All subsequent calls use find_class, and set has_loaded_class so that\n-  \/\/ before we return a result we call out to java to check for valid protection domain\n-  \/\/ to allow returning the Klass* and add it to the pd_set if it is valid\n-  {\n-    InstanceKlass* probe = dictionary->find(d_hash, name, protection_domain);\n-    if (probe != NULL) return probe;\n-  }\n+  \/\/ All subsequent calls use find_class, and set loaded_class so that\n+  \/\/ before we return a result, we call out to java to check for valid protection domain.\n+  InstanceKlass* probe = dictionary->find(name_hash, name, protection_domain);\n+  if (probe != NULL) return probe;\n@@ -765,1 +626,1 @@\n-  \/\/ ParallelCapable Classloaders and the bootstrap classloader\n+  \/\/ ParallelCapable class loaders and the bootstrap classloader\n@@ -767,13 +628,2 @@\n-  bool DoObjectLock = true;\n-  if (is_parallelCapable(class_loader)) {\n-    DoObjectLock = false;\n-  }\n-\n-  unsigned int p_hash = placeholders()->compute_hash(name);\n-  int p_index = placeholders()->hash_to_index(p_hash);\n-\n-  \/\/ Class is not in SystemDictionary so we have to do loading.\n-  \/\/ Make sure we are synchronized on the class loader before we proceed\n-  Handle lockObject = compute_loader_lock_object(class_loader, THREAD);\n-  check_loader_lock_contention(lockObject, THREAD);\n-  ObjectLocker ol(lockObject, THREAD, DoObjectLock);\n+  Handle lockObject = get_loader_lock_or_null(class_loader);\n+  ObjectLocker ol(lockObject, THREAD);\n@@ -781,5 +631,1 @@\n-  \/\/ Check again (after locking) if class already exist in SystemDictionary\n-  bool class_has_been_loaded   = false;\n-  bool havesupername = false;\n-  InstanceKlass* k = NULL;\n-  PlaceholderEntry* placeholder;\n+  InstanceKlass* loaded_class = NULL;\n@@ -793,0 +639,4 @@\n+\n+  assert(placeholders()->compute_hash(name) == name_hash, \"they're the same hashcode\");\n+\n+  \/\/ Check again (after locking) if the class already exists in SystemDictionary\n@@ -795,1 +645,1 @@\n-    InstanceKlass* check = find_class(d_hash, name, dictionary);\n+    InstanceKlass* check = dictionary->find_class(name_hash, name);\n@@ -797,3 +647,2 @@\n-      \/\/ InstanceKlass is already loaded, so just return it\n-      class_has_been_loaded = true;\n-      k = check;\n+      \/\/ InstanceKlass is already loaded, but we still need to check protection domain below.\n+      loaded_class = check;\n@@ -801,2 +650,2 @@\n-      placeholder = placeholders()->get_entry(p_index, p_hash, name, loader_data);\n-      if (placeholder && placeholder->super_load_in_progress()) {\n+      PlaceholderEntry* placeholder = placeholders()->get_entry(name_hash, name, loader_data);\n+      if (placeholder != NULL && placeholder->super_load_in_progress()) {\n@@ -804,4 +653,2 @@\n-         if (placeholder->havesupername() == true) {\n-           superclassname = placeholder->supername();\n-           havesupername = true;\n-         }\n+         superclassname = placeholder->supername();\n+         assert(superclassname != NULL, \"superclass has to have a name\");\n@@ -812,13 +659,7 @@\n-  \/\/ If the class is in the placeholder table, class loading is in progress\n-  if (super_load_in_progress && havesupername==true) {\n-    k = handle_parallel_super_load(name,\n-                                   superclassname,\n-                                   class_loader,\n-                                   protection_domain,\n-                                   lockObject, THREAD);\n-    if (HAS_PENDING_EXCEPTION) {\n-      return NULL;\n-    }\n-    if (k != NULL) {\n-      class_has_been_loaded = true;\n-    }\n+  \/\/ If the class is in the placeholder table with super_class set,\n+  \/\/ handle superclass loading in progress.\n+  if (super_load_in_progress) {\n+    handle_parallel_super_load(name, superclassname,\n+                               class_loader,\n+                               protection_domain,\n+                               CHECK_NULL);\n@@ -828,14 +669,16 @@\n-  if (!class_has_been_loaded) {\n-    bool load_instance_added = false;\n-\n-    \/\/ add placeholder entry to record loading instance class\n-    \/\/ Five cases:\n-    \/\/ All cases need to prevent modifying bootclasssearchpath\n-    \/\/ in parallel with a classload of same classname\n-    \/\/ Redefineclasses uses existence of the placeholder for the duration\n-    \/\/ of the class load to prevent concurrent redefinition of not completely\n-    \/\/ defined classes.\n-    \/\/ case 1. traditional classloaders that rely on the classloader object lock\n-    \/\/   - no other need for LOAD_INSTANCE\n-    \/\/ case 2. traditional classloaders that break the classloader object lock\n-    \/\/    as a deadlock workaround. Detection of this case requires that\n+  if (loaded_class == NULL) {\n+    bool load_placeholder_added = false;\n+\n+    \/\/ Add placeholder entry to record loading instance class\n+    \/\/ Four cases:\n+    \/\/ case 1. Bootstrap classloader\n+    \/\/    This classloader supports parallelism at the classloader level\n+    \/\/    but only allows a single thread to load a class\/classloader pair.\n+    \/\/    The LOAD_INSTANCE placeholder is the mechanism for mutual exclusion.\n+    \/\/ case 2. parallelCapable user level classloaders\n+    \/\/    These class loaders lock a per-class object lock when ClassLoader.loadClass()\n+    \/\/    is called. A LOAD_INSTANCE placeholder isn't used for mutual exclusion.\n+    \/\/ case 3. traditional classloaders that rely on the classloader object lock\n+    \/\/    There should be no need for need for LOAD_INSTANCE, except:\n+    \/\/ case 4. traditional class loaders that break the classloader object lock\n+    \/\/    as a legacy deadlock workaround. Detection of this case requires that\n@@ -846,7 +689,0 @@\n-    \/\/ case 3. Bootstrap classloader - don't own objectLocker\n-    \/\/    This classloader supports parallelism at the classloader level,\n-    \/\/    but only allows a single load of a class\/classloader pair.\n-    \/\/    No performance benefit and no deadlock issues.\n-    \/\/ case 4. parallelCapable user level classloaders - without objectLocker\n-    \/\/    Allow parallel classloading of a class\/classloader pair\n-\n@@ -855,32 +691,7 @@\n-      if (class_loader.is_null() || !is_parallelCapable(class_loader)) {\n-        PlaceholderEntry* oldprobe = placeholders()->get_entry(p_index, p_hash, name, loader_data);\n-        if (oldprobe) {\n-          \/\/ only need check_seen_thread once, not on each loop\n-          \/\/ 6341374 java\/lang\/Instrument with -Xcomp\n-          if (oldprobe->check_seen_thread(THREAD, PlaceholderTable::LOAD_INSTANCE)) {\n-            throw_circularity_error = true;\n-          } else {\n-            \/\/ case 1: traditional: should never see load_in_progress.\n-            while (!class_has_been_loaded && oldprobe && oldprobe->instance_load_in_progress()) {\n-\n-              \/\/ case 3: bootstrap classloader: prevent futile classloading,\n-              \/\/ wait on first requestor\n-              if (class_loader.is_null()) {\n-                SystemDictionary_lock->wait();\n-              } else {\n-              \/\/ case 2: traditional with broken classloader lock. wait on first\n-              \/\/ requestor.\n-                double_lock_wait(lockObject, THREAD);\n-              }\n-              \/\/ Check if classloading completed while we were waiting\n-              InstanceKlass* check = find_class(d_hash, name, dictionary);\n-              if (check != NULL) {\n-                \/\/ Klass is already loaded, so just return it\n-                k = check;\n-                class_has_been_loaded = true;\n-              }\n-              \/\/ check if other thread failed to load and cleaned up\n-              oldprobe = placeholders()->get_entry(p_index, p_hash, name, loader_data);\n-            }\n-          }\n-        }\n+      if (should_wait_for_loading(class_loader)) {\n+        loaded_class = handle_parallel_loading(THREAD,\n+                                               name_hash,\n+                                               name,\n+                                               loader_data,\n+                                               lockObject,\n+                                               &throw_circularity_error);\n@@ -888,14 +699,5 @@\n-      \/\/ All cases: add LOAD_INSTANCE holding SystemDictionary_lock\n-      \/\/ case 4: parallelCapable: allow competing threads to try\n-      \/\/ LOAD_INSTANCE in parallel\n-\n-      if (!throw_circularity_error && !class_has_been_loaded) {\n-        PlaceholderEntry* newprobe = placeholders()->find_and_add(p_index, p_hash, name, loader_data, PlaceholderTable::LOAD_INSTANCE, NULL, THREAD);\n-        load_instance_added = true;\n-        \/\/ For class loaders that do not acquire the classloader object lock,\n-        \/\/ if they did not catch another thread holding LOAD_INSTANCE,\n-        \/\/ need a check analogous to the acquire ObjectLocker\/find_class\n-        \/\/ i.e. now that we hold the LOAD_INSTANCE token on loading this class\/CL\n-        \/\/ one final check if the load has already completed\n-        \/\/ class loaders holding the ObjectLock shouldn't find the class here\n-        InstanceKlass* check = find_class(d_hash, name, dictionary);\n+\n+      \/\/ Recheck if the class has been loaded for all class loader cases and\n+      \/\/ add a LOAD_INSTANCE placeholder while holding the SystemDictionary_lock.\n+      if (!throw_circularity_error && loaded_class == NULL) {\n+        InstanceKlass* check = dictionary->find_class(name_hash, name);\n@@ -903,3 +705,8 @@\n-          \/\/ Klass is already loaded, so return it after checking\/adding protection domain\n-          k = check;\n-          class_has_been_loaded = true;\n+          loaded_class = check;\n+        } else if (should_wait_for_loading(class_loader)) {\n+          \/\/ Add the LOAD_INSTANCE token. Threads will wait on loading to complete for this thread.\n+          PlaceholderEntry* newprobe = placeholders()->find_and_add(name_hash, name, loader_data,\n+                                                                    PlaceholderTable::LOAD_INSTANCE,\n+                                                                    NULL,\n+                                                                    THREAD);\n+          load_placeholder_added = true;\n@@ -910,1 +717,1 @@\n-    \/\/ must throw error outside of owning lock\n+    \/\/ Must throw error outside of owning lock\n@@ -912,1 +719,1 @@\n-      assert(!HAS_PENDING_EXCEPTION && load_instance_added == false,\"circularity error cleanup\");\n+      assert(!HAS_PENDING_EXCEPTION && !load_placeholder_added, \"circularity error cleanup\");\n@@ -917,1 +724,4 @@\n-    if (!class_has_been_loaded) {\n+    \/\/ Be careful when modifying this code: once you have run\n+    \/\/ placeholders()->find_and_add(PlaceholderTable::LOAD_INSTANCE),\n+    \/\/ you need to find_and_remove it before returning.\n+    \/\/ So be careful to not exit with a CHECK_ macro between these calls.\n@@ -919,0 +729,1 @@\n+    if (loaded_class == NULL) {\n@@ -920,34 +731,2 @@\n-      k = load_instance_class(name, class_loader, THREAD);\n-\n-      \/\/ If everything was OK (no exceptions, no null return value), and\n-      \/\/ class_loader is NOT the defining loader, do a little more bookkeeping.\n-      if (!HAS_PENDING_EXCEPTION && k != NULL &&\n-        k->class_loader() != class_loader()) {\n-\n-        check_constraints(d_hash, k, class_loader, false, THREAD);\n-\n-        \/\/ Need to check for a PENDING_EXCEPTION again; check_constraints\n-        \/\/ can throw but we may have to remove entry from the placeholder table below.\n-        if (!HAS_PENDING_EXCEPTION) {\n-          \/\/ Record dependency for non-parent delegation.\n-          \/\/ This recording keeps the defining class loader of the klass (k) found\n-          \/\/ from being unloaded while the initiating class loader is loaded\n-          \/\/ even if the reference to the defining class loader is dropped\n-          \/\/ before references to the initiating class loader.\n-          loader_data->record_dependency(k);\n-\n-          { \/\/ Grabbing the Compile_lock prevents systemDictionary updates\n-            \/\/ during compilations.\n-            MutexLocker mu(THREAD, Compile_lock);\n-            update_dictionary(d_hash, p_index, p_hash,\n-              k, class_loader, THREAD);\n-          }\n-\n-          if (JvmtiExport::should_post_class_load()) {\n-            Thread *thread = THREAD;\n-            assert(thread->is_Java_thread(), \"thread->is_Java_thread()\");\n-            JvmtiExport::post_class_load((JavaThread *) thread, k);\n-          }\n-        }\n-      }\n-    } \/\/ load_instance_class\n+      loaded_class = load_instance_class(name_hash, name, class_loader, THREAD);\n+    }\n@@ -955,1 +734,1 @@\n-    if (load_instance_added == true) {\n+    if (load_placeholder_added) {\n@@ -960,1 +739,1 @@\n-      placeholders()->find_and_remove(p_index, p_hash, name, loader_data, PlaceholderTable::LOAD_INSTANCE, THREAD);\n+      placeholders()->find_and_remove(name_hash, name, loader_data, PlaceholderTable::LOAD_INSTANCE, THREAD);\n@@ -965,1 +744,1 @@\n-  if (HAS_PENDING_EXCEPTION || k == NULL) {\n+  if (HAS_PENDING_EXCEPTION || loaded_class == NULL) {\n@@ -968,0 +747,1 @@\n+\n@@ -969,1 +749,1 @@\n-    post_class_load_event(&class_load_start_event, k, loader_data);\n+    post_class_load_event(&class_load_start_event, loaded_class, loader_data);\n@@ -971,10 +751,2 @@\n-#ifdef ASSERT\n-  {\n-    ClassLoaderData* loader_data = k->class_loader_data();\n-    MutexLocker mu(THREAD, SystemDictionary_lock);\n-    InstanceKlass* kk = find_class(name, loader_data);\n-    assert(kk == k, \"should be present in dictionary\");\n-  }\n-#endif\n-  \/\/ return if the protection domain in NULL\n-  if (protection_domain() == NULL) return k;\n+  \/\/ Make sure we have the right class in the dictionary\n+  DEBUG_ONLY(verify_dictionary_entry(name, loaded_class));\n@@ -983,4 +755,4 @@\n-  \/\/ Check the protection domain has the right access\n-  if (dictionary->is_valid_protection_domain(d_hash, name,\n-                                             protection_domain)) {\n-    return k;\n+  \/\/ Check if the protection domain is present it has the right access\n+  if (protection_domain() != NULL) {\n+    \/\/ Verify protection domain. If it fails an exception is thrown\n+    dictionary->validate_protection_domain(name_hash, loaded_class, class_loader, protection_domain, CHECK_NULL);\n@@ -989,4 +761,1 @@\n-  \/\/ Verify protection domain. If it fails an exception is thrown\n-  validate_protection_domain(k, class_loader, protection_domain, CHECK_NULL);\n-\n-  return k;\n+  return loaded_class;\n@@ -999,3 +768,3 @@\n-\/\/ dictionary entries are only removed at a safepoint (when only one\n-\/\/ thread is running), and are added to in a safe way (all links must\n-\/\/ be updated in an MT-safe manner).\n+\/\/ dictionary entries are added to in a safe way (all links must\n+\/\/ be updated in an MT-safe manner). All entries are removed during class\n+\/\/ unloading, when this class loader is no longer referenced.\n@@ -1007,4 +776,3 @@\n-Klass* SystemDictionary::find(Symbol* class_name,\n-                              Handle class_loader,\n-                              Handle protection_domain,\n-                              TRAPS) {\n+InstanceKlass* SystemDictionary::find_instance_klass(Symbol* class_name,\n+                                                     Handle class_loader,\n+                                                     Handle protection_domain) {\n@@ -1015,2 +783,2 @@\n-  class_loader = Handle(THREAD, java_lang_ClassLoader::non_reflection_class_loader(class_loader()));\n-  ClassLoaderData* loader_data = ClassLoaderData::class_loader_data_or_null(class_loader());\n+  oop class_loader_oop = java_lang_ClassLoader::non_reflection_class_loader(class_loader());\n+  ClassLoaderData* loader_data = ClassLoaderData::class_loader_data_or_null(class_loader_oop);\n@@ -1025,3 +793,2 @@\n-  unsigned int d_hash = dictionary->compute_hash(class_name);\n-  return dictionary->find(d_hash, class_name,\n-                          protection_domain);\n+  unsigned int name_hash = dictionary->compute_hash(class_name);\n+  return dictionary->find(name_hash, class_name, protection_domain);\n@@ -1030,1 +797,0 @@\n-\n@@ -1035,2 +801,1 @@\n-                                                      Handle protection_domain,\n-                                                      TRAPS) {\n+                                                      Handle protection_domain) {\n@@ -1050,1 +815,1 @@\n-      k = SystemDictionary::find(ss.as_symbol(), class_loader, protection_domain, THREAD);\n+      k = SystemDictionary::find_instance_klass(ss.as_symbol(), class_loader, protection_domain);\n@@ -1056,1 +821,1 @@\n-    k = find(class_name, class_loader, protection_domain, THREAD);\n+    k = find_instance_klass(class_name, class_loader, protection_domain);\n@@ -1061,9 +826,9 @@\n-\/\/ Note: this method is much like resolve_from_stream, but\n-\/\/ does not publish the classes via the SystemDictionary.\n-\/\/ Handles Lookup.defineClass hidden, unsafe_DefineAnonymousClass\n-\/\/ and redefineclasses. RedefinedClasses do not add to the class hierarchy.\n-InstanceKlass* SystemDictionary::parse_stream(Symbol* class_name,\n-                                              Handle class_loader,\n-                                              ClassFileStream* st,\n-                                              const ClassLoadInfo& cl_info,\n-                                              TRAPS) {\n+\/\/ Note: this method is much like resolve_class_from_stream, but\n+\/\/ does not publish the classes in the SystemDictionary.\n+\/\/ Handles Lookup.defineClass hidden.\n+InstanceKlass* SystemDictionary::resolve_hidden_class_from_stream(\n+                                                     ClassFileStream* st,\n+                                                     Symbol* class_name,\n+                                                     Handle class_loader,\n+                                                     const ClassLoadInfo& cl_info,\n+                                                     TRAPS) {\n@@ -1073,3 +838,0 @@\n-  bool is_unsafe_anon_class = cl_info.unsafe_anonymous_host() != NULL;\n-  \/\/ - for unsafe anonymous class: create a new CLD whith a class holder that uses\n-  \/\/                               the same class loader as the unsafe_anonymous_host.\n@@ -1080,8 +842,3 @@\n-  if (is_unsafe_anon_class || cl_info.is_hidden()) {\n-    guarantee(!is_unsafe_anon_class || cl_info.unsafe_anonymous_host()->class_loader() == class_loader(),\n-              \"should be NULL or the same\");\n-    bool create_mirror_cld = is_unsafe_anon_class || !cl_info.is_strong_hidden();\n-    loader_data = register_loader(class_loader, create_mirror_cld);\n-  } else {\n-    loader_data = ClassLoaderData::class_loader_data(class_loader());\n-  }\n+  assert (cl_info.is_hidden(), \"only used for hidden classes\");\n+  bool create_mirror_cld = !cl_info.is_strong_hidden();\n+  loader_data = register_loader(class_loader, create_mirror_cld);\n@@ -1093,4 +850,0 @@\n-  \/\/ Note that we do this even though this klass might\n-  \/\/ already be present in the SystemDictionary, otherwise we would not\n-  \/\/ throw potential ClassFormatErrors.\n-\n@@ -1102,0 +855,1 @@\n+  assert(k != NULL, \"no klass created\");\n@@ -1103,16 +857,5 @@\n-  if ((cl_info.is_hidden() || is_unsafe_anon_class) && k != NULL) {\n-    \/\/ Hidden classes that are not strong and unsafe anonymous classes must update\n-    \/\/ ClassLoaderData holder so that they can be unloaded when the mirror is no\n-    \/\/ longer referenced.\n-    if (!cl_info.is_strong_hidden() || is_unsafe_anon_class) {\n-      k->class_loader_data()->initialize_holder(Handle(THREAD, k->java_mirror()));\n-    }\n-\n-    {\n-      MutexLocker mu_r(THREAD, Compile_lock);\n-\n-      \/\/ Add to class hierarchy, initialize vtables, and do possible\n-      \/\/ deoptimizations.\n-      add_to_hierarchy(k, CHECK_NULL); \/\/ No exception, but can block\n-      \/\/ But, do not add to dictionary.\n-    }\n+  \/\/ Hidden classes that are not strong must update ClassLoaderData holder\n+  \/\/ so that they can be unloaded when the mirror is no longer referenced.\n+  if (!cl_info.is_strong_hidden()) {\n+    k->class_loader_data()->initialize_holder(Handle(THREAD, k->java_mirror()));\n+  }\n@@ -1120,5 +863,6 @@\n-    \/\/ Rewrite and patch constant pool here.\n-    k->link_class(CHECK_NULL);\n-    if (cl_info.cp_patches() != NULL) {\n-      k->constants()->patch_resolved_references(cl_info.cp_patches());\n-    }\n+  {\n+    MutexLocker mu_r(THREAD, Compile_lock);\n+    \/\/ Add to class hierarchy, and do possible deoptimizations.\n+    add_to_hierarchy(k);\n+    \/\/ But, do not add to dictionary.\n+  }\n@@ -1126,4 +870,1 @@\n-    \/\/ If it's anonymous, initialize it now, since nobody else will.\n-    if (is_unsafe_anon_class) {\n-      k->eager_initialize(CHECK_NULL);\n-    }\n+  k->link_class(CHECK_NULL);\n@@ -1131,8 +872,6 @@\n-    \/\/ notify jvmti\n-    if (JvmtiExport::should_post_class_load()) {\n-        assert(THREAD->is_Java_thread(), \"thread->is_Java_thread()\");\n-        JvmtiExport::post_class_load((JavaThread *) THREAD, k);\n-    }\n-    if (class_load_start_event.should_commit()) {\n-      post_class_load_event(&class_load_start_event, k, loader_data);\n-    }\n+  \/\/ notify jvmti\n+  if (JvmtiExport::should_post_class_load()) {\n+    JvmtiExport::post_class_load(THREAD, k);\n+  }\n+  if (class_load_start_event.should_commit()) {\n+    post_class_load_event(&class_load_start_event, k, loader_data);\n@@ -1140,2 +879,0 @@\n-  assert(is_unsafe_anon_class || NULL == cl_info.cp_patches(),\n-         \"cp_patches only found with unsafe_anonymous_host\");\n@@ -1150,4 +887,3 @@\n-\n-InstanceKlass* SystemDictionary::resolve_from_stream(Symbol* class_name,\n-                                                     Handle class_loader,\n-                                                     Handle protection_domain,\n+\/\/ This function either returns an InstanceKlass or throws an exception.  It does\n+\/\/ not return NULL without a pending exception.\n+InstanceKlass* SystemDictionary::resolve_class_from_stream(\n@@ -1155,0 +891,3 @@\n+                                                     Symbol* class_name,\n+                                                     Handle class_loader,\n+                                                     const ClassLoadInfo& cl_info,\n@@ -1159,7 +898,0 @@\n-  \/\/ Classloaders that support parallelism, e.g. bootstrap classloader,\n-  \/\/ do not acquire lock here\n-  bool DoObjectLock = true;\n-  if (is_parallelCapable(class_loader)) {\n-    DoObjectLock = false;\n-  }\n-\n@@ -1168,6 +900,4 @@\n-  \/\/ Make sure we are synchronized on the class loader before we proceed\n-  Handle lockObject = compute_loader_lock_object(class_loader, THREAD);\n-  check_loader_lock_contention(lockObject, THREAD);\n-  ObjectLocker ol(lockObject, THREAD, DoObjectLock);\n-\n-  assert(st != NULL, \"invariant\");\n+  \/\/ Classloaders that support parallelism, e.g. bootstrap classloader,\n+  \/\/ do not acquire lock here\n+  Handle lockObject = get_loader_lock_or_null(class_loader);\n+  ObjectLocker ol(lockObject, THREAD);\n@@ -1185,1 +915,1 @@\n-                                                   protection_domain,\n+                                                   cl_info.protection_domain(),\n@@ -1192,4 +922,0 @@\n-    if (st->buffer() == NULL) {\n-      return NULL;\n-    }\n-    ClassLoadInfo cl_info(protection_domain);\n@@ -1204,2 +930,3 @@\n-  \/\/ If a class loader supports parallel classloading handle parallel define requests\n-  \/\/ find_or_define_instance_class may return a different InstanceKlass\n+  \/\/ If a class loader supports parallel classloading, handle parallel define requests.\n+  \/\/ find_or_define_instance_class may return a different InstanceKlass,\n+  \/\/ in which case the old k would be deallocated\n@@ -1207,7 +934,1 @@\n-    InstanceKlass* defined_k = find_or_define_instance_class(h_name, class_loader, k, THREAD);\n-    if (!HAS_PENDING_EXCEPTION && defined_k != k) {\n-      \/\/ If a parallel capable class loader already defined this class, register 'k' for cleanup.\n-      assert(defined_k != NULL, \"Should have a klass if there's no exception\");\n-      loader_data->add_to_deallocate_list(k);\n-      k = defined_k;\n-    }\n+    k = find_or_define_instance_class(h_name, class_loader, k, CHECK_NULL);\n@@ -1215,2 +936,1 @@\n-    define_instance_class(k, THREAD);\n-  }\n+    define_instance_class(k, class_loader, THREAD);\n@@ -1218,5 +938,6 @@\n-  \/\/ If defining the class throws an exception register 'k' for cleanup.\n-  if (HAS_PENDING_EXCEPTION) {\n-    assert(k != NULL, \"Must have an instance klass here!\");\n-    loader_data->add_to_deallocate_list(k);\n-    return NULL;\n+    \/\/ If defining the class throws an exception register 'k' for cleanup.\n+    if (HAS_PENDING_EXCEPTION) {\n+      assert(k != NULL, \"Must have an instance klass here!\");\n+      loader_data->add_to_deallocate_list(k);\n+      return NULL;\n+    }\n@@ -1226,6 +947,1 @@\n-  debug_only( {\n-    MutexLocker mu(THREAD, SystemDictionary_lock);\n-\n-    Klass* check = find_class(h_name, k->class_loader_data());\n-    assert(check == k, \"should be present in the dictionary\");\n-  } );\n+  DEBUG_ONLY(verify_dictionary_entry(h_name, k));\n@@ -1236,10 +952,9 @@\n-#if INCLUDE_CDS\n-\/\/ Load a class for boot loader from the shared spaces. This also\n-\/\/ forces the super class and all interfaces to be loaded.\n-InstanceKlass* SystemDictionary::load_shared_boot_class(Symbol* class_name,\n-                                                        PackageEntry* pkg_entry,\n-                                                        TRAPS) {\n-  assert(UseSharedSpaces, \"Sanity check\");\n-  InstanceKlass* ik = SystemDictionaryShared::find_builtin_class(class_name);\n-  if (ik != NULL && ik->is_shared_boot_class()) {\n-    return load_shared_class(ik, Handle(), Handle(), NULL, pkg_entry, THREAD);\n+InstanceKlass* SystemDictionary::resolve_from_stream(ClassFileStream* st,\n+                                                     Symbol* class_name,\n+                                                     Handle class_loader,\n+                                                     const ClassLoadInfo& cl_info,\n+                                                     TRAPS) {\n+  if (cl_info.is_hidden()) {\n+    return resolve_hidden_class_from_stream(st, class_name, class_loader, cl_info, CHECK_NULL);\n+  } else {\n+    return resolve_class_from_stream(st, class_name, class_loader, cl_info, CHECK_NULL);\n@@ -1247,1 +962,0 @@\n-  return NULL;\n@@ -1250,6 +964,3 @@\n-\/\/ Check if a shared class can be loaded by the specific classloader:\n-\/\/\n-\/\/ NULL classloader:\n-\/\/   - Module class from \"modules\" jimage. ModuleEntry must be defined in the classloader.\n-\/\/   - Class from -Xbootclasspath\/a. The class has no defined PackageEntry, or must\n-\/\/     be defined in an unnamed module.\n+\n+#if INCLUDE_CDS\n+\/\/ Check if a shared class can be loaded by the specific classloader.\n@@ -1259,1 +970,1 @@\n-                                               Handle class_loader, TRAPS) {\n+                                               Handle class_loader) {\n@@ -1262,4 +973,18 @@\n-  if (ik->shared_classpath_index() < 0) {\n-    \/\/ path_index < 0 indicates that the class is intended for a custom loader\n-    \/\/ and should not be loaded by boot\/platform\/app loaders\n-    if (is_builtin_class_loader(class_loader())) {\n+\n+  \/\/ (1) Check if we are loading into the same loader as in dump time.\n+\n+  if (ik->is_shared_boot_class()) {\n+    if (class_loader() != NULL) {\n+      return false;\n+    }\n+  } else if (ik->is_shared_platform_class()) {\n+    if (class_loader() != java_platform_loader()) {\n+      return false;\n+    }\n+  } else if (ik->is_shared_app_class()) {\n+    if (class_loader() != java_system_loader()) {\n+      return false;\n+    }\n+  } else {\n+    \/\/ ik was loaded by a custom loader during dump time\n+    if (class_loader_data(class_loader)->is_builtin_class_loader_data()) {\n@@ -1272,1 +997,2 @@\n-  \/\/ skip class visibility check\n+  \/\/ (2) Check if we are loading into the same module from the same location as in dump time.\n+\n@@ -1274,1 +1000,4 @@\n-    assert(SystemDictionary::is_shared_class_visible_impl(class_name, ik, pkg_entry, class_loader, THREAD), \"Optimizing module handling failed.\");\n+    \/\/ Class visibility has not changed between dump time and run time, so a class\n+    \/\/ that was visible (and thus archived) during dump time is always visible during runtime.\n+    assert(SystemDictionary::is_shared_class_visible_impl(class_name, ik, pkg_entry, class_loader),\n+           \"visibility cannot change between dump time and runtime\");\n@@ -1277,1 +1006,1 @@\n-  return is_shared_class_visible_impl(class_name, ik, pkg_entry, class_loader, THREAD);\n+  return is_shared_class_visible_impl(class_name, ik, pkg_entry, class_loader);\n@@ -1281,7 +1010,7 @@\n-                                               InstanceKlass* ik,\n-                                               PackageEntry* pkg_entry,\n-                                               Handle class_loader, TRAPS) {\n-  int path_index = ik->shared_classpath_index();\n-  ClassLoaderData* loader_data = class_loader_data(class_loader);\n-  SharedClassPathEntry* ent =\n-            (SharedClassPathEntry*)FileMapInfo::shared_path(path_index);\n+                                                    InstanceKlass* ik,\n+                                                    PackageEntry* pkg_entry,\n+                                                    Handle class_loader) {\n+  int scp_index = ik->shared_classpath_index();\n+  assert(!ik->is_shared_unregistered_class(), \"this function should be called for built-in classes only\");\n+  assert(scp_index >= 0, \"must be\");\n+  SharedClassPathEntry* scp_entry = FileMapInfo::shared_path(scp_index);\n@@ -1289,1 +1018,1 @@\n-    assert(ent != NULL && ent->is_modules_image(),\n+    assert(scp_entry != NULL && scp_entry->is_modules_image(),\n@@ -1294,29 +1023,4 @@\n-  \/\/ Get the pkg_entry from the classloader\n-  ModuleEntry* mod_entry = NULL;\n-  TempNewSymbol pkg_name = pkg_entry != NULL ? pkg_entry->name() :\n-                                               ClassLoader::package_from_class_name(class_name);\n-  if (pkg_name != NULL) {\n-    if (loader_data != NULL) {\n-      if (pkg_entry != NULL) {\n-        mod_entry = pkg_entry->module();\n-        \/\/ If the archived class is from a module that has been patched at runtime,\n-        \/\/ the class cannot be loaded from the archive.\n-        if (mod_entry != NULL && mod_entry->is_patched()) {\n-          return false;\n-        }\n-      }\n-    }\n-  }\n-  if (class_loader.is_null()) {\n-    assert(ent != NULL, \"Shared class for NULL classloader must have valid SharedClassPathEntry\");\n-    \/\/ The NULL classloader can load archived class originated from the\n-    \/\/ \"modules\" jimage and the -Xbootclasspath\/a. For class from the\n-    \/\/ \"modules\" jimage, the PackageEntry\/ModuleEntry must be defined\n-    \/\/ by the NULL classloader.\n-    if (mod_entry != NULL) {\n-      \/\/ PackageEntry\/ModuleEntry is found in the classloader. Check if the\n-      \/\/ ModuleEntry's location agrees with the archived class' origination.\n-      if (ent->is_modules_image() && mod_entry->location()->starts_with(\"jrt:\")) {\n-        return true; \/\/ Module class from the \"module\" jimage\n-      }\n-    }\n+  ModuleEntry* mod_entry = (pkg_entry == NULL) ? NULL : pkg_entry->module();\n+  bool should_be_in_named_module = (mod_entry != NULL && mod_entry->is_named());\n+  bool was_archived_from_named_module = scp_entry->in_named_module();\n+  bool visible;\n@@ -1325,15 +1029,6 @@\n-    \/\/ If the archived class is not from the \"module\" jimage, the class can be\n-    \/\/ loaded by the NULL classloader if\n-    \/\/\n-    \/\/ 1. the class is from the unamed package\n-    \/\/ 2. or, the class is not from a module defined in the NULL classloader\n-    \/\/ 3. or, the class is from an unamed module\n-    if (!ent->is_modules_image() && ik->is_shared_boot_class()) {\n-      \/\/ the class is from the -Xbootclasspath\/a\n-      if (pkg_name == NULL ||\n-          pkg_entry == NULL ||\n-          pkg_entry->in_unnamed_module()) {\n-        assert(mod_entry == NULL ||\n-               mod_entry == loader_data->unnamed_module(),\n-               \"the unnamed module is not defined in the classloader\");\n-        return true;\n+  if (was_archived_from_named_module) {\n+    if (should_be_in_named_module) {\n+      \/\/ Is the module loaded from the same location as during dump time?\n+      visible = mod_entry->shared_path_index() == scp_index;\n+      if (visible) {\n+        assert(!mod_entry->is_patched(), \"cannot load archived classes for patched module\");\n@@ -1341,0 +1036,4 @@\n+    } else {\n+      \/\/ During dump time, this class was in a named module, but at run time, this class should be\n+      \/\/ in an unnamed module.\n+      visible = false;\n@@ -1342,4 +1041,7 @@\n-    return false;\n-    bool res = SystemDictionaryShared::is_shared_class_visible_for_classloader(\n-              ik, class_loader, pkg_name, pkg_entry, mod_entry, CHECK_(false));\n-    return res;\n+    if (should_be_in_named_module) {\n+      \/\/ During dump time, this class was in an unnamed, but at run time, this class should be\n+      \/\/ in a named module.\n+      visible = false;\n+    } else {\n+      visible = true;\n+    }\n@@ -1348,0 +1050,2 @@\n+\n+  return visible;\n@@ -1350,1 +1054,1 @@\n-bool SystemDictionary::check_shared_class_super_type(InstanceKlass* child, InstanceKlass* super_type,\n+bool SystemDictionary::check_shared_class_super_type(InstanceKlass* klass, InstanceKlass* super_type,\n@@ -1355,1 +1059,14 @@\n-  Klass *found = resolve_super_or_fail(child->name(), super_type->name(),\n+  \/\/ Quick check if the super type has been already loaded.\n+  \/\/ + Don't do it for unregistered classes -- they can be unloaded so\n+  \/\/   super_type->class_loader_data() could be stale.\n+  \/\/ + Don't check if loader data is NULL, ie. the super_type isn't fully loaded.\n+  if (!super_type->is_shared_unregistered_class() && super_type->class_loader_data() != NULL) {\n+    \/\/ Check if the superclass is loaded by the current class_loader\n+    Symbol* name = super_type->name();\n+    InstanceKlass* check = find_instance_klass(name, class_loader, protection_domain);\n+    if (check == super_type) {\n+      return true;\n+    }\n+  }\n+\n+  Klass *found = resolve_super_or_fail(klass->name(), super_type->name(),\n@@ -1361,1 +1078,1 @@\n-    \/\/ so we cannot use the child class.\n+    \/\/ so we cannot use the class.\n@@ -1413,1 +1130,1 @@\n-  ik->set_nest_host(shared_nest_host, THREAD);\n+  ik->set_nest_host(shared_nest_host);\n@@ -1417,2 +1134,4 @@\n-  assert(shared_nest_host->is_same_class_package(ik),\n-         \"lambda proxy class and its nest host must be in the same package\");\n+  if (loaded_ik != NULL) {\n+    assert(shared_nest_host->is_same_class_package(ik),\n+           \"lambda proxy class and its nest host must be in the same package\");\n+  }\n@@ -1433,3 +1152,1 @@\n-  bool visible = is_shared_class_visible(\n-                          class_name, ik, pkg_entry, class_loader, CHECK_NULL);\n-  if (!visible) {\n+  if (!is_shared_class_visible(class_name, ik, pkg_entry, class_loader)) {\n@@ -1444,1 +1161,1 @@\n-  \/\/ CFLH check is skipped for VM hidden or anonymous classes (see KlassFactory::create_from_stream).\n+  \/\/ CFLH check is skipped for VM hidden classes (see KlassFactory::create_from_stream).\n@@ -1460,3 +1177,0 @@\n-  \/\/ Updating methods must be done under a lock so multiple\n-  \/\/ threads don't update these in parallel\n-  \/\/\n@@ -1466,0 +1180,3 @@\n+  \/\/ Since this class is already locked with parallel capable class\n+  \/\/ loaders, including the bootstrap loader via the placeholder table,\n+  \/\/ this lock is currently a nop.\n@@ -1470,3 +1187,2 @@\n-    Handle lockObject = compute_loader_lock_object(class_loader, THREAD);\n-    check_loader_lock_contention(lockObject, THREAD);\n-    ObjectLocker ol(lockObject, THREAD, true);\n+    Handle lockObject = get_loader_lock_or_null(class_loader);\n+    ObjectLocker ol(lockObject, THREAD);\n@@ -1478,1 +1194,1 @@\n-  load_shared_class_misc(ik, loader_data, CHECK_NULL);\n+  load_shared_class_misc(ik, loader_data);\n@@ -1482,1 +1198,1 @@\n-void SystemDictionary::load_shared_class_misc(InstanceKlass* ik, ClassLoaderData* loader_data, TRAPS) {\n+void SystemDictionary::load_shared_class_misc(InstanceKlass* ik, ClassLoaderData* loader_data) {\n@@ -1489,10 +1205,1 @@\n-    ik->set_classpath_index(path_index, THREAD);\n-  }\n-\n-  if (DumpLoadedClassList != NULL && classlist_file->is_open()) {\n-    \/\/ Only dump the classes that can be stored into CDS archive\n-    if (SystemDictionaryShared::is_sharing_possible(loader_data)) {\n-      ResourceMark rm(THREAD);\n-      classlist_file->print_cr(\"%s\", ik->name()->as_C_string());\n-      classlist_file->flush();\n-    }\n+    ik->set_classpath_index(path_index);\n@@ -1503,15 +1210,0 @@\n-\n-  ik->set_has_passed_fingerprint_check(false);\n-  if (UseAOT && ik->supers_have_passed_fingerprint_checks()) {\n-    uint64_t aot_fp = AOTLoader::get_saved_fingerprint(ik);\n-    uint64_t cds_fp = ik->get_stored_fingerprint();\n-    if (aot_fp != 0 && aot_fp == cds_fp) {\n-      \/\/ This class matches with a class saved in an AOT library\n-      ik->set_has_passed_fingerprint_check(true);\n-    } else {\n-      if (log_is_enabled(Info, class, fingerprint)) {\n-        ResourceMark rm(THREAD);\n-        log_info(class, fingerprint)(\"%s :  expected = \" PTR64_FORMAT \" actual = \" PTR64_FORMAT, ik->external_name(), aot_fp, cds_fp);\n-      }\n-    }\n-  }\n@@ -1520,30 +1212,0 @@\n-void SystemDictionary::quick_resolve(InstanceKlass* klass, ClassLoaderData* loader_data, Handle domain, TRAPS) {\n-  assert(!Universe::is_fully_initialized(), \"We can make short cuts only during VM initialization\");\n-  assert(klass->is_shared(), \"Must be shared class\");\n-  if (klass->class_loader_data() != NULL) {\n-    return;\n-  }\n-\n-  \/\/ add super and interfaces first\n-  Klass* super = klass->super();\n-  if (super != NULL && super->class_loader_data() == NULL) {\n-    assert(super->is_instance_klass(), \"Super should be instance klass\");\n-    quick_resolve(InstanceKlass::cast(super), loader_data, domain, CHECK);\n-  }\n-\n-  Array<InstanceKlass*>* ifs = klass->local_interfaces();\n-  for (int i = 0; i < ifs->length(); i++) {\n-    InstanceKlass* ik = ifs->at(i);\n-    if (ik->class_loader_data()  == NULL) {\n-      quick_resolve(ik, loader_data, domain, CHECK);\n-    }\n-  }\n-\n-  klass->restore_unshareable_info(loader_data, domain, NULL, THREAD);\n-  load_shared_class_misc(klass, loader_data, CHECK);\n-  Dictionary* dictionary = loader_data->dictionary();\n-  unsigned int hash = dictionary->compute_hash(klass->name());\n-  dictionary->add_klass(hash, klass->name(), klass);\n-  add_to_hierarchy(klass, CHECK);\n-  assert(klass->is_loaded(), \"Must be in at least loaded state\");\n-}\n@@ -1552,1 +1214,1 @@\n-InstanceKlass* SystemDictionary::load_instance_class(Symbol* class_name, Handle class_loader, TRAPS) {\n+InstanceKlass* SystemDictionary::load_instance_class_impl(Symbol* class_name, Handle class_loader, TRAPS) {\n@@ -1624,1 +1286,5 @@\n-      k = load_shared_boot_class(class_name, pkg_entry, THREAD);\n+      InstanceKlass* ik = SystemDictionaryShared::find_builtin_class(class_name);\n+      if (ik != NULL && ik->is_shared_boot_class() && !ik->shared_loading_failed()) {\n+        SharedClassLoadingMark slm(THREAD, ik);\n+        k = load_shared_class(ik, class_loader, Handle(), NULL,  pkg_entry, CHECK_NULL);\n+      }\n@@ -1636,11 +1302,2 @@\n-      InstanceKlass* defined_k =\n-        find_or_define_instance_class(class_name, class_loader, k, THREAD);\n-      if (!HAS_PENDING_EXCEPTION && defined_k != k) {\n-        \/\/ If a parallel capable class loader already defined this class, register 'k' for cleanup.\n-        assert(defined_k != NULL, \"Should have a klass if there's no exception\");\n-        loader_data->add_to_deallocate_list(k);\n-        k = defined_k;\n-      } else if (HAS_PENDING_EXCEPTION) {\n-        loader_data->add_to_deallocate_list(k);\n-        return NULL;\n-      }\n+      CDS_ONLY(SharedClassLoadingMark slm(THREAD, k);)\n+      k = find_or_define_instance_class(class_name, class_loader, k, CHECK_NULL);\n@@ -1653,2 +1310,1 @@\n-    assert(THREAD->is_Java_thread(), \"must be a JavaThread\");\n-    JavaThread* jt = (JavaThread*) THREAD;\n+    JavaThread* jt = THREAD;\n@@ -1669,1 +1325,1 @@\n-    InstanceKlass* spec_klass = SystemDictionary::ClassLoader_klass();\n+    InstanceKlass* spec_klass = vmClasses::ClassLoader_klass();\n@@ -1684,1 +1340,1 @@\n-    oop obj = (oop) result.get_jobject();\n+    oop obj = result.get_oop();\n@@ -1702,0 +1358,35 @@\n+InstanceKlass* SystemDictionary::load_instance_class(unsigned int name_hash,\n+                                                     Symbol* name,\n+                                                     Handle class_loader,\n+                                                     TRAPS) {\n+\n+  InstanceKlass* loaded_class = load_instance_class_impl(name, class_loader, CHECK_NULL);\n+\n+  \/\/ If everything was OK (no exceptions, no null return value), and\n+  \/\/ class_loader is NOT the defining loader, do a little more bookkeeping.\n+  if (loaded_class != NULL &&\n+    loaded_class->class_loader() != class_loader()) {\n+\n+    check_constraints(name_hash, loaded_class, class_loader, false, CHECK_NULL);\n+\n+    \/\/ Record dependency for non-parent delegation.\n+    \/\/ This recording keeps the defining class loader of the klass (loaded_class) found\n+    \/\/ from being unloaded while the initiating class loader is loaded\n+    \/\/ even if the reference to the defining class loader is dropped\n+    \/\/ before references to the initiating class loader.\n+    ClassLoaderData* loader_data = class_loader_data(class_loader);\n+    loader_data->record_dependency(loaded_class);\n+\n+    { \/\/ Grabbing the Compile_lock prevents systemDictionary updates\n+      \/\/ during compilations.\n+      MutexLocker mu(THREAD, Compile_lock);\n+      update_dictionary(name_hash, loaded_class, class_loader);\n+    }\n+\n+    if (JvmtiExport::should_post_class_load()) {\n+      JvmtiExport::post_class_load(THREAD, loaded_class);\n+    }\n+  }\n+  return loaded_class;\n+}\n+\n@@ -1711,1 +1402,1 @@\n-void SystemDictionary::define_instance_class(InstanceKlass* k, TRAPS) {\n+void SystemDictionary::define_instance_class(InstanceKlass* k, Handle class_loader, TRAPS) {\n@@ -1713,2 +1404,1 @@\n-  HandleMark hm(THREAD);\n-  Handle class_loader_h(THREAD, loader_data->class_loader());\n+  assert(loader_data->class_loader() == class_loader(), \"they must be the same\");\n@@ -1717,9 +1407,9 @@\n- \/\/ for bootstrap and other parallel classloaders don't acquire lock,\n- \/\/ use placeholder token\n- \/\/ If a parallelCapable class loader calls define_instance_class instead of\n- \/\/ find_or_define_instance_class to get here, we have a timing\n- \/\/ hole with systemDictionary updates and check_constraints\n- if (!class_loader_h.is_null() && !is_parallelCapable(class_loader_h)) {\n-    assert(ObjectSynchronizer::current_thread_holds_lock((JavaThread*)THREAD,\n-         compute_loader_lock_object(class_loader_h, THREAD)),\n-         \"define called without lock\");\n+  \/\/ Bootstrap and other parallel classloaders don't acquire a lock,\n+  \/\/ they use placeholder token.\n+  \/\/ If a parallelCapable class loader calls define_instance_class instead of\n+  \/\/ find_or_define_instance_class to get here, we have a timing\n+  \/\/ hole with systemDictionary updates and check_constraints\n+  if (!is_parallelCapable(class_loader)) {\n+    assert(ObjectSynchronizer::current_thread_holds_lock(THREAD,\n+           get_loader_lock_or_null(class_loader)),\n+           \"define called without lock\");\n@@ -1739,2 +1429,2 @@\n-  unsigned int d_hash = dictionary->compute_hash(name_h);\n-  check_constraints(d_hash, k, class_loader_h, true, CHECK);\n+  unsigned int name_hash = dictionary->compute_hash(name_h);\n+  check_constraints(name_hash, k, class_loader, true, CHECK);\n@@ -1750,1 +1440,1 @@\n-    JavaCallArguments args(class_loader_h);\n+    JavaCallArguments args(class_loader);\n@@ -1757,3 +1447,0 @@\n-    unsigned int p_hash = placeholders()->compute_hash(name_h);\n-    int p_index = placeholders()->hash_to_index(p_hash);\n-\n@@ -1762,3 +1449,2 @@\n-    \/\/ Add to class hierarchy, initialize vtables, and do possible\n-    \/\/ deoptimizations.\n-    add_to_hierarchy(k, CHECK); \/\/ No exception, but can block\n+    \/\/ Add to class hierarchy, and do possible deoptimizations.\n+    add_to_hierarchy(k);\n@@ -1768,2 +1454,1 @@\n-    update_dictionary(d_hash, p_index, p_hash,\n-                      k, class_loader_h, THREAD);\n+    update_dictionary(name_hash, k, class_loader);\n@@ -1775,3 +1460,1 @@\n-      assert(THREAD->is_Java_thread(), \"thread->is_Java_thread()\");\n-      JvmtiExport::post_class_load((JavaThread *) THREAD, k);\n-\n+    JvmtiExport::post_class_load(THREAD, k);\n@@ -1801,3 +1484,3 @@\n-\/\/ So be careful to not exit with a CHECK_ macro betweeen these calls.\n-InstanceKlass* SystemDictionary::find_or_define_instance_class(Symbol* class_name, Handle class_loader,\n-                                                               InstanceKlass* k, TRAPS) {\n+\/\/ So be careful to not exit with a CHECK_ macro between these calls.\n+InstanceKlass* SystemDictionary::find_or_define_helper(Symbol* class_name, Handle class_loader,\n+                                                       InstanceKlass* k, TRAPS) {\n@@ -1809,1 +1492,1 @@\n-  unsigned int d_hash = dictionary->compute_hash(name_h);\n+  unsigned int name_hash = dictionary->compute_hash(name_h);\n@@ -1812,4 +1495,0 @@\n-  unsigned int p_hash = placeholders()->compute_hash(name_h);\n-  int p_index = placeholders()->hash_to_index(p_hash);\n-  PlaceholderEntry* probe;\n-\n@@ -1820,1 +1499,1 @@\n-      InstanceKlass* check = find_class(d_hash, name_h, dictionary);\n+      InstanceKlass* check = dictionary->find_class(name_hash, name_h);\n@@ -1827,1 +1506,3 @@\n-    probe = placeholders()->find_and_add(p_index, p_hash, name_h, loader_data, PlaceholderTable::DEFINE_CLASS, NULL, THREAD);\n+    assert(placeholders()->compute_hash(name_h) == name_hash, \"they're the same hashcode\");\n+    PlaceholderEntry* probe = placeholders()->find_and_add(name_hash, name_h, loader_data,\n+                                                           PlaceholderTable::DEFINE_CLASS, NULL, THREAD);\n@@ -1839,2 +1520,3 @@\n-        placeholders()->find_and_remove(p_index, p_hash, name_h, loader_data, PlaceholderTable::DEFINE_CLASS, THREAD);\n-        SystemDictionary_lock->notify_all();\n+      InstanceKlass* ik = probe->instance_klass();\n+      placeholders()->find_and_remove(name_hash, name_h, loader_data, PlaceholderTable::DEFINE_CLASS, THREAD);\n+      SystemDictionary_lock->notify_all();\n@@ -1842,2 +1524,2 @@\n-        InstanceKlass* check = find_class(d_hash, name_h, dictionary);\n-        assert(check != NULL, \"definer missed recording success\");\n+      InstanceKlass* check = dictionary->find_class(name_hash, name_h);\n+      assert(check != NULL, \"definer missed recording success\");\n@@ -1845,1 +1527,1 @@\n-        return probe->instance_klass();\n+      return ik;\n@@ -1852,3 +1534,1 @@\n-  define_instance_class(k, THREAD);\n-\n-  Handle linkage_exception = Handle(); \/\/ null handle\n+  define_instance_class(k, class_loader, THREAD);\n@@ -1859,1 +1539,1 @@\n-    PlaceholderEntry* probe = placeholders()->get_entry(p_index, p_hash, name_h, loader_data);\n+    PlaceholderEntry* probe = placeholders()->get_entry(name_hash, name_h, loader_data);\n@@ -1861,10 +1541,2 @@\n-    if (probe != NULL) {\n-      if (HAS_PENDING_EXCEPTION) {\n-        linkage_exception = Handle(THREAD,PENDING_EXCEPTION);\n-        CLEAR_PENDING_EXCEPTION;\n-      } else {\n-        probe->set_instance_klass(k);\n-      }\n-      probe->set_definer(NULL);\n-      placeholders()->find_and_remove(p_index, p_hash, name_h, loader_data, PlaceholderTable::DEFINE_CLASS, THREAD);\n-      SystemDictionary_lock->notify_all();\n+    if (!HAS_PENDING_EXCEPTION) {\n+      probe->set_instance_klass(k);\n@@ -1872,0 +1544,3 @@\n+    probe->set_definer(NULL);\n+    placeholders()->find_and_remove(name_hash, name_h, loader_data, PlaceholderTable::DEFINE_CLASS, THREAD);\n+    SystemDictionary_lock->notify_all();\n@@ -1874,6 +1549,1 @@\n-  \/\/ Can't throw exception while holding lock due to rank ordering\n-  if (linkage_exception() != NULL) {\n-    THROW_OOP_(linkage_exception(), NULL); \/\/ throws exception and returns\n-  }\n-\n-  return k;\n+  return HAS_PENDING_EXCEPTION ? NULL : k;\n@@ -1882,6 +1552,13 @@\n-Handle SystemDictionary::compute_loader_lock_object(Handle class_loader, TRAPS) {\n-  \/\/ If class_loader is NULL we synchronize on _system_loader_lock_obj\n-  if (class_loader.is_null()) {\n-    return Handle(THREAD, _system_loader_lock_obj.resolve());\n-  } else {\n-    return class_loader;\n+\/\/ If a class loader supports parallel classloading handle parallel define requests.\n+\/\/ find_or_define_instance_class may return a different InstanceKlass\n+InstanceKlass* SystemDictionary::find_or_define_instance_class(Symbol* class_name, Handle class_loader,\n+                                                               InstanceKlass* k, TRAPS) {\n+  InstanceKlass* defined_k = find_or_define_helper(class_name, class_loader, k, THREAD);\n+  \/\/ Clean up original InstanceKlass if duplicate or error\n+  if (!HAS_PENDING_EXCEPTION && defined_k != k) {\n+    \/\/ If a parallel capable class loader already defined this class, register 'k' for cleanup.\n+    assert(defined_k != NULL, \"Should have a klass if there's no exception\");\n+    k->class_loader_data()->add_to_deallocate_list(k);\n+  } else if (HAS_PENDING_EXCEPTION) {\n+    assert(defined_k == NULL, \"Should not have a klass if there's an exception\");\n+    k->class_loader_data()->add_to_deallocate_list(k);\n@@ -1889,0 +1566,1 @@\n+  return defined_k;\n@@ -1891,22 +1569,0 @@\n-\/\/ This method is added to check how often we have to wait to grab loader\n-\/\/ lock. The results are being recorded in the performance counters defined in\n-\/\/ ClassLoader::_sync_systemLoaderLockContentionRate and\n-\/\/ ClassLoader::_sync_nonSystemLoaderLockConteionRate.\n-void SystemDictionary::check_loader_lock_contention(Handle loader_lock, TRAPS) {\n-  if (!UsePerfData) {\n-    return;\n-  }\n-\n-  assert(!loader_lock.is_null(), \"NULL lock object\");\n-\n-  if (ObjectSynchronizer::query_lock_ownership((JavaThread*)THREAD, loader_lock)\n-      == ObjectSynchronizer::owner_other) {\n-    \/\/ contention will likely happen, so increment the corresponding\n-    \/\/ contention counter.\n-    if (loader_lock() == _system_loader_lock_obj.resolve()) {\n-      ClassLoader::sync_systemLoaderLockContentionRate()->inc();\n-    } else {\n-      ClassLoader::sync_nonSystemLoaderLockContentionRate()->inc();\n-    }\n-  }\n-}\n@@ -1915,42 +1571,1 @@\n-\/\/ Lookup\n-\n-InstanceKlass* SystemDictionary::find_class(unsigned int hash,\n-                                            Symbol* class_name,\n-                                            Dictionary* dictionary) {\n-  assert_locked_or_safepoint(SystemDictionary_lock);\n-  int index = dictionary->hash_to_index(hash);\n-  return dictionary->find_class(index, hash, class_name);\n-}\n-\n-\n-\/\/ Basic find on classes in the midst of being loaded\n-Symbol* SystemDictionary::find_placeholder(Symbol* class_name,\n-                                           ClassLoaderData* loader_data) {\n-  assert_locked_or_safepoint(SystemDictionary_lock);\n-  unsigned int p_hash = placeholders()->compute_hash(class_name);\n-  int p_index = placeholders()->hash_to_index(p_hash);\n-  return placeholders()->find_entry(p_index, p_hash, class_name, loader_data);\n-}\n-\n-\n-\/\/ Used for assertions and verification only\n-\/\/ Precalculating the hash and index is an optimization because there are many lookups\n-\/\/ before adding the class.\n-InstanceKlass* SystemDictionary::find_class(Symbol* class_name, ClassLoaderData* loader_data) {\n-  assert_locked_or_safepoint(SystemDictionary_lock);\n-  #ifndef ASSERT\n-  guarantee(VerifyBeforeGC      ||\n-            VerifyDuringGC      ||\n-            VerifyBeforeExit    ||\n-            VerifyDuringStartup ||\n-            VerifyAfterGC, \"too expensive\");\n-  #endif\n-\n-  Dictionary* dictionary = loader_data->dictionary();\n-  unsigned int d_hash = dictionary->compute_hash(class_name);\n-  return find_class(d_hash, class_name, dictionary);\n-}\n-\n-\n-\/\/ ----------------------------------------------------------------------------\n-\/\/ Update hierachy. This is done before the new klass has been added to the SystemDictionary. The Recompile_lock\n+\/\/ Update hierachy. This is done before the new klass has been added to the SystemDictionary. The Compile_lock\n@@ -1960,1 +1575,1 @@\n-void SystemDictionary::add_to_hierarchy(InstanceKlass* k, TRAPS) {\n+void SystemDictionary::add_to_hierarchy(InstanceKlass* k) {\n@@ -1973,1 +1588,1 @@\n-  k->process_interfaces(THREAD);                  \/\/ handle all \"implements\" declarations\n+  k->process_interfaces();                        \/\/ handle all \"implements\" declarations\n@@ -1986,1 +1601,0 @@\n-\/\/ Note: anonymous classes are not in the SD.\n@@ -2012,6 +1626,10 @@\n-    \/\/ Oops referenced by the protection domain cache table may get unreachable independently\n-    \/\/ of the class loader (eg. cached protection domain oops). So we need to\n-    \/\/ explicitly unlink them here.\n-    \/\/ All protection domain oops are linked to the caller class, so if nothing\n-    \/\/ unloads, this is not needed.\n-    _pd_cache_table->trigger_cleanup();\n+    if (java_lang_System::allow_security_manager()) {\n+      \/\/ Oops referenced by the protection domain cache table may get unreachable independently\n+      \/\/ of the class loader (eg. cached protection domain oops). So we need to\n+      \/\/ explicitly unlink them here.\n+      \/\/ All protection domain oops are linked to the caller class, so if nothing\n+      \/\/ unloads, this is not needed.\n+      _pd_cache_table->trigger_cleanup();\n+    } else {\n+      assert(_pd_cache_table->number_of_entries() == 0, \"should be empty\");\n+    }\n@@ -2023,7 +1641,0 @@\n-\/\/ CDS: scan and relocate all classes referenced by _well_known_klasses[].\n-void SystemDictionary::well_known_klasses_do(MetaspaceClosure* it) {\n-  for (int id = FIRST_WKID; id < WKID_LIMIT; id++) {\n-    it->push(well_known_klass_addr((WKID)id));\n-  }\n-}\n-\n@@ -2049,158 +1660,3 @@\n-  \/\/ Allocate private object used as system class loader lock\n-  oop lock_obj = oopFactory::new_intArray(0, CHECK);\n-  _system_loader_lock_obj = OopHandle::create(lock_obj);\n-\n-  \/\/ Initialize basic classes\n-  resolve_well_known_classes(CHECK);\n-}\n-\n-\/\/ Compact table of directions on the initialization of klasses:\n-static const short wk_init_info[] = {\n-  #define WK_KLASS_INIT_INFO(name, symbol) \\\n-    ((short)vmSymbols::VM_SYMBOL_ENUM_NAME(symbol)),\n-\n-  WK_KLASSES_DO(WK_KLASS_INIT_INFO)\n-  #undef WK_KLASS_INIT_INFO\n-  0\n-};\n-\n-#ifdef ASSERT\n-bool SystemDictionary::is_well_known_klass(Symbol* class_name) {\n-  int sid;\n-  for (int i = 0; (sid = wk_init_info[i]) != 0; i++) {\n-    Symbol* symbol = vmSymbols::symbol_at((vmSymbols::SID)sid);\n-    if (class_name == symbol) {\n-      return true;\n-    }\n-  }\n-  return false;\n-}\n-#endif\n-\n-bool SystemDictionary::resolve_wk_klass(WKID id, TRAPS) {\n-  assert(id >= (int)FIRST_WKID && id < (int)WKID_LIMIT, \"oob\");\n-  int sid = wk_init_info[id - FIRST_WKID];\n-  Symbol* symbol = vmSymbols::symbol_at((vmSymbols::SID)sid);\n-  InstanceKlass** klassp = &_well_known_klasses[id];\n-\n-#if INCLUDE_CDS\n-  if (UseSharedSpaces && !JvmtiExport::should_post_class_prepare()) {\n-    InstanceKlass* k = *klassp;\n-    assert(k->is_shared_boot_class(), \"must be\");\n-\n-    ClassLoaderData* loader_data = ClassLoaderData::the_null_class_loader_data();\n-    quick_resolve(k, loader_data, Handle(), CHECK_false);\n-    return true;\n-  }\n-#endif \/\/ INCLUDE_CDS\n-\n-  if (!is_wk_klass_loaded(*klassp)) {\n-    Klass* k = resolve_or_fail(symbol, true, CHECK_false);\n-    (*klassp) = InstanceKlass::cast(k);\n-  }\n-  return ((*klassp) != NULL);\n-}\n-\n-void SystemDictionary::resolve_wk_klasses_until(WKID limit_id, WKID &start_id, TRAPS) {\n-  assert((int)start_id <= (int)limit_id, \"IDs are out of order!\");\n-  for (int id = (int)start_id; id < (int)limit_id; id++) {\n-    assert(id >= (int)FIRST_WKID && id < (int)WKID_LIMIT, \"oob\");\n-    resolve_wk_klass((WKID)id, CHECK);\n-  }\n-\n-  \/\/ move the starting value forward to the limit:\n-  start_id = limit_id;\n-}\n-\n-void SystemDictionary::resolve_well_known_classes(TRAPS) {\n-  assert(!Object_klass_loaded(), \"well-known classes should only be initialized once\");\n-\n-  \/\/ Create the ModuleEntry for java.base.  This call needs to be done here,\n-  \/\/ after vmSymbols::initialize() is called but before any classes are pre-loaded.\n-  ClassLoader::classLoader_init2(CHECK);\n-\n-  \/\/ Preload commonly used klasses\n-  WKID scan = FIRST_WKID;\n-  \/\/ first do Object, then String, Class\n-#if INCLUDE_CDS\n-  if (UseSharedSpaces) {\n-    resolve_wk_klasses_through(WK_KLASS_ENUM_NAME(Object_klass), scan, CHECK);\n-\n-    \/\/ It's unsafe to access the archived heap regions before they\n-    \/\/ are fixed up, so we must do the fixup as early as possible\n-    \/\/ before the archived java objects are accessed by functions\n-    \/\/ such as java_lang_Class::restore_archived_mirror and\n-    \/\/ ConstantPool::restore_unshareable_info (restores the archived\n-    \/\/ resolved_references array object).\n-    \/\/\n-    \/\/ HeapShared::fixup_mapped_heap_regions() fills the empty\n-    \/\/ spaces in the archived heap regions and may use\n-    \/\/ SystemDictionary::Object_klass(), so we can do this only after\n-    \/\/ Object_klass is resolved. See the above resolve_wk_klasses_through()\n-    \/\/ call. No mirror objects are accessed\/restored in the above call.\n-    \/\/ Mirrors are restored after java.lang.Class is loaded.\n-    HeapShared::fixup_mapped_heap_regions();\n-\n-    \/\/ Initialize the constant pool for the Object_class\n-    assert(Object_klass()->is_shared(), \"must be\");\n-    Object_klass()->constants()->restore_unshareable_info(CHECK);\n-    resolve_wk_klasses_through(WK_KLASS_ENUM_NAME(Class_klass), scan, CHECK);\n-  } else\n-#endif\n-  {\n-    resolve_wk_klasses_through(WK_KLASS_ENUM_NAME(Class_klass), scan, CHECK);\n-  }\n-\n-  assert(WK_KLASS(Object_klass) != NULL, \"well-known classes should now be initialized\");\n-\n-  java_lang_Object::register_natives(CHECK);\n-\n-  \/\/ Calculate offsets for String and Class classes since they are loaded and\n-  \/\/ can be used after this point.\n-  java_lang_String::compute_offsets();\n-  java_lang_Class::compute_offsets();\n-\n-  \/\/ Fixup mirrors for classes loaded before java.lang.Class.\n-  Universe::initialize_basic_type_mirrors(CHECK);\n-  Universe::fixup_mirrors(CHECK);\n-\n-  \/\/ do a bunch more:\n-  resolve_wk_klasses_through(WK_KLASS_ENUM_NAME(Reference_klass), scan, CHECK);\n-\n-  \/\/ The offsets for jlr.Reference must be computed before\n-  \/\/ InstanceRefKlass::update_nonstatic_oop_maps is called. That function uses\n-  \/\/ the offsets to remove the referent and discovered fields from the oop maps,\n-  \/\/ as they are treated in a special way by the GC. Removing these oops from the\n-  \/\/ oop maps must be done before the usual subclasses of jlr.Reference are loaded.\n-  java_lang_ref_Reference::compute_offsets();\n-\n-  \/\/ Preload ref klasses and set reference types\n-  WK_KLASS(Reference_klass)->set_reference_type(REF_OTHER);\n-  InstanceRefKlass::update_nonstatic_oop_maps(WK_KLASS(Reference_klass));\n-\n-  resolve_wk_klasses_through(WK_KLASS_ENUM_NAME(PhantomReference_klass), scan, CHECK);\n-  WK_KLASS(SoftReference_klass)->set_reference_type(REF_SOFT);\n-  WK_KLASS(WeakReference_klass)->set_reference_type(REF_WEAK);\n-  WK_KLASS(FinalReference_klass)->set_reference_type(REF_FINAL);\n-  WK_KLASS(PhantomReference_klass)->set_reference_type(REF_PHANTOM);\n-\n-  \/\/ JSR 292 classes\n-  WKID jsr292_group_start = WK_KLASS_ENUM_NAME(MethodHandle_klass);\n-  WKID jsr292_group_end   = WK_KLASS_ENUM_NAME(VolatileCallSite_klass);\n-  resolve_wk_klasses_until(jsr292_group_start, scan, CHECK);\n-  resolve_wk_klasses_through(jsr292_group_end, scan, CHECK);\n-  WKID last = WKID_LIMIT;\n-  resolve_wk_klasses_until(last, scan, CHECK);\n-\n-  _box_klasses[T_BOOLEAN] = WK_KLASS(Boolean_klass);\n-  _box_klasses[T_CHAR]    = WK_KLASS(Character_klass);\n-  _box_klasses[T_FLOAT]   = WK_KLASS(Float_klass);\n-  _box_klasses[T_DOUBLE]  = WK_KLASS(Double_klass);\n-  _box_klasses[T_BYTE]    = WK_KLASS(Byte_klass);\n-  _box_klasses[T_SHORT]   = WK_KLASS(Short_klass);\n-  _box_klasses[T_INT]     = WK_KLASS(Integer_klass);\n-  _box_klasses[T_LONG]    = WK_KLASS(Long_klass);\n-  \/\/_box_klasses[T_OBJECT]  = WK_KLASS(object_klass);\n-  \/\/_box_klasses[T_ARRAY]   = WK_KLASS(object_klass);\n-\n-#ifdef ASSERT\n+  \/\/ Resolve basic classes\n+  vmClasses::resolve_all(CHECK);\n+  \/\/ Resolve classes used by archived heap objects\n@@ -2208,17 +1664,1 @@\n-    JVMTI_ONLY(assert(JvmtiExport::is_early_phase(),\n-                      \"All well known classes must be resolved in JVMTI early phase\"));\n-    for (int i = FIRST_WKID; i < last; i++) {\n-      InstanceKlass* k = _well_known_klasses[i];\n-      assert(k->is_shared(), \"must not be replaced by JVMTI class file load hook\");\n-    }\n-  }\n-#endif\n-}\n-\n-\/\/ Tells if a given klass is a box (wrapper class, such as java.lang.Integer).\n-\/\/ If so, returns the basic type it holds.  If not, returns T_OBJECT.\n-BasicType SystemDictionary::box_klass_type(Klass* k) {\n-  assert(k != NULL, \"\");\n-  for (int i = T_BOOLEAN; i < T_VOID+1; i++) {\n-    if (_box_klasses[i] == k)\n-      return (BasicType)i;\n+    HeapShared::resolve_classes(THREAD);\n@@ -2226,1 +1666,0 @@\n-  return T_OBJECT;\n@@ -2237,1 +1676,1 @@\n-void SystemDictionary::check_constraints(unsigned int d_hash,\n+void SystemDictionary::check_constraints(unsigned int name_hash,\n@@ -2252,1 +1691,1 @@\n-    InstanceKlass* check = find_class(d_hash, name, loader_data->dictionary());\n+    InstanceKlass* check = loader_data->dictionary()->find_class(name_hash, name);\n@@ -2257,3 +1696,0 @@\n-      \/\/ The dictionary only holds instance classes, placeholders\n-      \/\/ also hold array classes.\n-      assert(check->is_instance_klass(), \"noninstance in systemdictionary\");\n@@ -2271,5 +1707,0 @@\n-#ifdef ASSERT\n-    Symbol* ph_check = find_placeholder(name, loader_data);\n-    assert(ph_check == NULL || ph_check == name, \"invalid symbol\");\n-#endif\n-\n@@ -2304,2 +1735,1 @@\n-void SystemDictionary::update_dictionary(unsigned int d_hash,\n-                                         int p_index, unsigned int p_hash,\n+void SystemDictionary::update_dictionary(unsigned int hash,\n@@ -2307,2 +1737,1 @@\n-                                         Handle class_loader,\n-                                         TRAPS) {\n+                                         Handle class_loader) {\n@@ -2315,1 +1744,1 @@\n-    MutexLocker mu1(THREAD, SystemDictionary_lock);\n+    MutexLocker mu1(SystemDictionary_lock);\n@@ -2319,1 +1748,1 @@\n-    InstanceKlass* sd_check = find_class(d_hash, name, dictionary);\n+    InstanceKlass* sd_check = dictionary->find_class(hash, name);\n@@ -2321,1 +1750,1 @@\n-      dictionary->add_klass(d_hash, name, k);\n+      dictionary->add_klass(hash, name, k);\n@@ -2323,6 +1752,0 @@\n-  #ifdef ASSERT\n-    sd_check = find_class(d_hash, name, dictionary);\n-    assert (sd_check != NULL, \"should have entry in dictionary\");\n-    \/\/ Note: there may be a placeholder entry: for circularity testing\n-    \/\/ or for parallel defines\n-  #endif\n@@ -2338,1 +1761,1 @@\n-                    Symbol* class_name, Handle class_loader, TRAPS) {\n+                    Thread* current, Symbol* class_name, Handle class_loader) {\n@@ -2344,1 +1767,1 @@\n-                                              no_protection_domain, CHECK_NULL);\n+                                              no_protection_domain);\n@@ -2360,1 +1783,1 @@\n-      MutexLocker mu(THREAD, SystemDictionary_lock);\n+      MutexLocker mu(current, SystemDictionary_lock);\n@@ -2368,1 +1791,1 @@\n-    MutexLocker mu(THREAD, SystemDictionary_lock);\n+    MutexLocker mu(current, SystemDictionary_lock);\n@@ -2379,2 +1802,1 @@\n-                                             Handle class_loader2,\n-                                             Thread* THREAD) {\n+                                             Handle class_loader2) {\n@@ -2404,1 +1826,1 @@\n-  unsigned int d_hash1 = dictionary1->compute_hash(constraint_name);\n+  unsigned int name_hash1 = dictionary1->compute_hash(constraint_name);\n@@ -2407,1 +1829,1 @@\n-  unsigned int d_hash2 = dictionary2->compute_hash(constraint_name);\n+  unsigned int name_hash2 = dictionary2->compute_hash(constraint_name);\n@@ -2410,3 +1832,3 @@\n-    MutexLocker mu_s(THREAD, SystemDictionary_lock);\n-    InstanceKlass* klass1 = find_class(d_hash1, constraint_name, dictionary1);\n-    InstanceKlass* klass2 = find_class(d_hash2, constraint_name, dictionary2);\n+    MutexLocker mu_s(SystemDictionary_lock);\n+    InstanceKlass* klass1 = dictionary1->find_class(name_hash1, constraint_name);\n+    InstanceKlass* klass2 = dictionary2->find_class(name_hash2, constraint_name);\n@@ -2420,1 +1842,1 @@\n-                                     class_loader1, class_loader2, THREAD);\n+                                     class_loader1, class_loader2);\n@@ -2433,1 +1855,2 @@\n-                                            Symbol* error, Symbol* message) {\n+                                            Symbol* error, Symbol* message,\n+                                            Symbol* cause, Symbol* cause_msg) {\n@@ -2438,1 +1861,4 @@\n-    resolution_errors()->add_entry(index, hash, pool, which, error, message);\n+    ResolutionErrorEntry* entry = resolution_errors()->find_entry(index, hash, pool, which);\n+    if (entry == NULL) {\n+      resolution_errors()->add_entry(index, hash, pool, which, error, message, cause, cause_msg);\n+    }\n@@ -2449,1 +1875,1 @@\n-                                                Symbol** message) {\n+                                                Symbol** message, Symbol** cause, Symbol** cause_msg) {\n@@ -2457,0 +1883,2 @@\n+      *cause = entry->cause();\n+      *cause_msg = entry->cause_msg();\n@@ -2476,2 +1904,5 @@\n-    if (entry != NULL) {\n-      assert(entry->nest_host_error() == NULL, \"Nest host error message already set!\");\n+    if (entry != NULL && entry->nest_host_error() == NULL) {\n+      \/\/ An existing entry means we had a true resolution failure (LinkageError) with our nest host, but we\n+      \/\/ still want to add the error message for the higher-level access checks to report. We should\n+      \/\/ only reach here under the same error condition, so we can ignore the potential race with setting\n+      \/\/ the message. If we see it is already set then we can ignore it.\n@@ -2552,3 +1983,3 @@\n-                                               Klass* klass_being_linked,\n-                                               Handle loader1, Handle loader2,\n-                                               bool is_method, TRAPS)  {\n+                                                  Klass* klass_being_linked,\n+                                                  Handle loader1, Handle loader2,\n+                                                  bool is_method)  {\n@@ -2566,1 +1997,1 @@\n-      if (!add_loader_constraint(sig, klass_being_linked, loader1, loader2, THREAD)) {\n+      if (!add_loader_constraint(sig, klass_being_linked, loader1, loader2)) {\n@@ -2574,1 +2005,1 @@\n-Method* SystemDictionary::find_method_handle_intrinsic(vmIntrinsics::ID iid,\n+Method* SystemDictionary::find_method_handle_intrinsic(vmIntrinsicID iid,\n@@ -2578,0 +2009,1 @@\n+  const int iid_as_int = vmIntrinsics::as_int(iid);\n@@ -2581,1 +2013,1 @@\n-         \"must be a known MH intrinsic iid=%d: %s\", iid, vmIntrinsics::name_at(iid));\n+         \"must be a known MH intrinsic iid=%d: %s\", iid_as_int, vmIntrinsics::name_at(iid));\n@@ -2583,1 +2015,1 @@\n-  unsigned int hash  = invoke_method_table()->compute_hash(signature, iid);\n+  unsigned int hash  = invoke_method_table()->compute_hash(signature, iid_as_int);\n@@ -2585,1 +2017,1 @@\n-  SymbolPropertyEntry* spe = invoke_method_table()->find_entry(index, hash, signature, iid);\n+  SymbolPropertyEntry* spe = invoke_method_table()->find_entry(index, hash, signature, iid_as_int);\n@@ -2604,1 +2036,1 @@\n-      spe = invoke_method_table()->find_entry(index, hash, signature, iid);\n+      spe = invoke_method_table()->find_entry(index, hash, signature, iid_as_int);\n@@ -2606,1 +2038,1 @@\n-        spe = invoke_method_table()->add_entry(index, hash, signature, iid);\n+        spe = invoke_method_table()->add_entry(index, hash, signature, iid_as_int);\n@@ -2665,1 +2097,1 @@\n-  objArrayHandle appendix_box = oopFactory::new_objArray_handle(SystemDictionary::Object_klass(), 1, CHECK_NULL);\n+  objArrayHandle appendix_box = oopFactory::new_objArray_handle(vmClasses::Object_klass(), 1, CHECK_NULL);\n@@ -2683,1 +2115,1 @@\n-                         SystemDictionary::MethodHandleNatives_klass(),\n+                         vmClasses::MethodHandleNatives_klass(),\n@@ -2687,1 +2119,1 @@\n-  Handle mname(THREAD, (oop) result.get_jobject());\n+  Handle mname(THREAD, result.get_oop());\n@@ -2706,2 +2138,2 @@\n-         (InstanceKlass::cast(klass)->is_same_class_package(SystemDictionary::Object_klass()) ||       \/\/ java.lang\n-          InstanceKlass::cast(klass)->is_same_class_package(SystemDictionary::MethodHandle_klass()));  \/\/ java.lang.invoke\n+         (InstanceKlass::cast(klass)->is_same_class_package(vmClasses::Object_klass()) ||       \/\/ java.lang\n+          InstanceKlass::cast(klass)->is_same_class_package(vmClasses::MethodHandle_klass()));  \/\/ java.lang.invoke\n@@ -2757,1 +2189,1 @@\n-  vmIntrinsics::ID null_iid = vmIntrinsics::_none;  \/\/ distinct from all method handle invoker intrinsics\n+  int null_iid = vmIntrinsics::as_int(vmIntrinsics::_none);  \/\/ distinct from all method handle invoker intrinsics\n@@ -2776,1 +2208,1 @@\n-  objArrayHandle pts = oopFactory::new_objArray_handle(SystemDictionary::Class_klass(), npts, CHECK_(empty));\n+  objArrayHandle pts = oopFactory::new_objArray_handle(vmClasses::Class_klass(), npts, CHECK_(empty));\n@@ -2817,1 +2249,1 @@\n-                         SystemDictionary::MethodHandleNatives_klass(),\n+                         vmClasses::MethodHandleNatives_klass(),\n@@ -2821,1 +2253,1 @@\n-  Handle method_type(THREAD, (oop) result.get_jobject());\n+  Handle method_type(THREAD, result.get_oop());\n@@ -2874,1 +2306,1 @@\n-  Handle mname = MemberName_klass()->allocate_instance_handle(CHECK_(empty));\n+  Handle mname = vmClasses::MemberName_klass()->allocate_instance_handle(CHECK_(empty));\n@@ -2888,1 +2320,1 @@\n-    MethodHandles::resolve_MemberName(mname, caller, \/*speculative_resolve*\/false, CHECK_(empty));\n+    MethodHandles::resolve_MemberName(mname, caller, 0, false \/*speculative_resolve*\/, CHECK_(empty));\n@@ -2903,1 +2335,1 @@\n-                         SystemDictionary::MethodHandleNatives_klass(),\n+                         vmClasses::MethodHandleNatives_klass(),\n@@ -2907,1 +2339,1 @@\n-  return Handle(THREAD, (oop) result.get_jobject());\n+  return Handle(THREAD, result.get_oop());\n@@ -2926,1 +2358,1 @@\n-    appendix_box = oopFactory::new_objArray_handle(SystemDictionary::Object_klass(), 1, CHECK);\n+    appendix_box = oopFactory::new_objArray_handle(vmClasses::Object_klass(), 1, CHECK);\n@@ -2944,1 +2376,1 @@\n-                         SystemDictionary::MethodHandleNatives_klass(),\n+                         vmClasses::MethodHandleNatives_klass(),\n@@ -2949,1 +2381,1 @@\n-  Handle value(THREAD, (oop) result.get_jobject());\n+  Handle value(THREAD, result.get_oop());\n@@ -2968,3 +2400,7 @@\n-\/\/ Protection domain cache table handling\n-ProtectionDomainCacheEntry* SystemDictionary::cache_get(Handle protection_domain) {\n-  return _pd_cache_table->get(protection_domain);\n+ClassLoaderData* SystemDictionary::class_loader_data(Handle class_loader) {\n+  return ClassLoaderData::class_loader_data(class_loader());\n+}\n+\n+bool SystemDictionary::is_nonpublic_Object_method(Method* m) {\n+  assert(m != NULL, \"Unexpected NULL Method*\");\n+  return !m->is_public() && m->method_holder() == vmClasses::Object_klass();\n@@ -3057,11 +2493,0 @@\n-\n-int SystemDictionaryDCmd::num_arguments() {\n-  ResourceMark rm;\n-  SystemDictionaryDCmd* dcmd = new SystemDictionaryDCmd(NULL, false);\n-  if (dcmd != NULL) {\n-    DCmdMark mark(dcmd);\n-    return dcmd->_dcmdparser.num_arguments();\n-  } else {\n-    return 0;\n-  }\n-}\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":631,"deletions":1206,"binary":false,"changes":1837,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,1 @@\n-#include \"jfr\/support\/jfrIntrinsics.hpp\"\n+#include \"classfile\/vmIntrinsics.hpp\"\n@@ -33,1 +33,1 @@\n-\n+#include \"utilities\/enumIterator.hpp\"\n@@ -45,1 +45,2 @@\n-#define VM_SYMBOL_ENUM_NAME(name)    name##_enum\n+#define VM_SYMBOL_ENUM_NAME_(name)    name##_enum\n+#define VM_SYMBOL_ENUM_NAME(name)    vmSymbolID::VM_SYMBOL_ENUM_NAME_(name)\n@@ -83,0 +84,10 @@\n+                                                                                                  \\\n+  template(jdk_internal_vm_vector_VectorSupport,      \"jdk\/internal\/vm\/vector\/VectorSupport\")               \\\n+  template(jdk_internal_vm_vector_VectorPayload,      \"jdk\/internal\/vm\/vector\/VectorSupport$VectorPayload\") \\\n+  template(jdk_internal_vm_vector_Vector,             \"jdk\/internal\/vm\/vector\/VectorSupport$Vector\")        \\\n+  template(jdk_internal_vm_vector_VectorMask,         \"jdk\/internal\/vm\/vector\/VectorSupport$VectorMask\")    \\\n+  template(jdk_internal_vm_vector_VectorShuffle,      \"jdk\/internal\/vm\/vector\/VectorSupport$VectorShuffle\") \\\n+  template(payload_name,                              \"payload\")                                            \\\n+  template(ETYPE_name,                                \"ETYPE\")                                              \\\n+  template(VLENGTH_name,                              \"VLENGTH\")                                            \\\n+                                                                                                  \\\n@@ -130,1 +141,2 @@\n-  template(java_lang_Record,                          \"java\/lang\/Record\")                       \\\n+  template(java_lang_Record,                          \"java\/lang\/Record\")                         \\\n+  template(sun_instrument_InstrumentationImpl,        \"sun\/instrument\/InstrumentationImpl\")       \\\n@@ -133,0 +145,1 @@\n+  template(jdk_internal_loader_BuiltinClassLoader,    \"jdk\/internal\/loader\/BuiltinClassLoader\")   \\\n@@ -138,0 +151,1 @@\n+  template(java_version_name,                         \"java_version\")                             \\\n@@ -239,0 +253,1 @@\n+  template(jdk_internal_ValueBased_signature,                                \"Ljdk\/internal\/ValueBased;\") \\\n@@ -263,0 +278,1 @@\n+  template(linkToNative_name,                         \"linkToNative\")                             \\\n@@ -271,0 +287,1 @@\n+  template(blackhole_name,                            \"<blackhole>\")  \/*fake name*\/               \\\n@@ -286,1 +303,0 @@\n-  template(jdk_internal_HotSpotIntrinsicCandidate_signature, \"Ljdk\/internal\/HotSpotIntrinsicCandidate;\") \\\n@@ -290,0 +306,2 @@\n+  template(jdk_internal_misc_Scoped_signature,               \"Ljdk\/internal\/misc\/ScopedMemoryAccess$Scoped;\") \\\n+  template(jdk_internal_vm_annotation_IntrinsicCandidate_signature, \"Ljdk\/internal\/vm\/annotation\/IntrinsicCandidate;\") \\\n@@ -291,1 +309,0 @@\n-                                                                                                  \\\n@@ -333,2 +350,6 @@\n-                                                                                                                                      \\\n-  \/* Support for JVMCI *\/                                                                                                             \\\n+  \/* Foreign API Support *\/                                                                                          \\\n+  template(jdk_internal_invoke_NativeEntryPoint,                 \"jdk\/internal\/invoke\/NativeEntryPoint\")           \\\n+  template(jdk_internal_invoke_NativeEntryPoint_signature,       \"Ljdk\/internal\/invoke\/NativeEntryPoint;\")         \\\n+  template(jdk_incubator_foreign_MemoryAccess,       \"jdk\/incubator\/foreign\/MemoryAccess\")        \\\n+                                                                                                  \\\n+  \/* Support for JVMCI *\/                                                                         \\\n@@ -376,0 +397,1 @@\n+  template(refersTo0_name,                            \"refersTo0\")                                \\\n@@ -463,0 +485,1 @@\n+  template(during_unsafe_access_name,                 \"during_unsafe_access\")                     \\\n@@ -505,0 +528,1 @@\n+  template(long_array_signature,                      \"[J\")                                       \\\n@@ -507,0 +531,1 @@\n+  template(long_object_long_signature,                \"(JLjava\/lang\/Object;)J\")                   \\\n@@ -511,0 +536,1 @@\n+  template(throwable_signature,                       \"Ljava\/lang\/Throwable;\")                    \\\n@@ -513,1 +539,0 @@\n-  template(throwable_throwable_signature,             \"(Ljava\/lang\/Throwable;)Ljava\/lang\/Throwable;\")             \\\n@@ -518,0 +543,1 @@\n+  template(throwable_throwable_signature,             \"(Ljava\/lang\/Throwable;)Ljava\/lang\/Throwable;\")             \\\n@@ -603,6 +629,0 @@\n-  template(createMemoryPoolMBean_name,                 \"createMemoryPoolMBean\")                                   \\\n-  template(createMemoryManagerMBean_name,              \"createMemoryManagerMBean\")                                \\\n-  template(createGarbageCollectorMBean_name,           \"createGarbageCollectorMBean\")                             \\\n-  template(createMemoryPoolMBean_signature,            \"(Ljava\/lang\/String;ZJJ)Ljava\/lang\/management\/MemoryPoolMBean;\") \\\n-  template(createMemoryManagerMBean_signature,         \"(Ljava\/lang\/String;)Ljava\/lang\/management\/MemoryManagerMBean;\") \\\n-  template(createGarbageCollectorMBean_signature,      \"(Ljava\/lang\/String;Ljava\/lang\/String;)Ljava\/lang\/management\/GarbageCollectorMBean;\") \\\n@@ -672,5 +692,16 @@\n-  \/* cds *\/                                                                                                       \\\n-  template(jdk_internal_loader_ClassLoaders,       \"jdk\/internal\/loader\/ClassLoaders\")                            \\\n-  template(toFileURL_name,                         \"toFileURL\")                                                   \\\n-  template(toFileURL_signature,                    \"(Ljava\/lang\/String;)Ljava\/net\/URL;\")                          \\\n-  template(url_void_signature,                     \"(Ljava\/net\/URL;)V\")                                           \\\n+  \/* CDS *\/                                                                                                       \\\n+  template(dumpSharedArchive,                               \"dumpSharedArchive\")                                  \\\n+  template(dumpSharedArchive_signature,                     \"(ZLjava\/lang\/String;)V\")                             \\\n+  template(generateLambdaFormHolderClasses,                 \"generateLambdaFormHolderClasses\")                    \\\n+  template(generateLambdaFormHolderClasses_signature,       \"([Ljava\/lang\/String;)[Ljava\/lang\/Object;\")           \\\n+  template(java_lang_invoke_Invokers_Holder,                \"java\/lang\/invoke\/Invokers$Holder\")                   \\\n+  template(java_lang_invoke_DirectMethodHandle_Holder,      \"java\/lang\/invoke\/DirectMethodHandle$Holder\")         \\\n+  template(java_lang_invoke_LambdaForm_Holder,              \"java\/lang\/invoke\/LambdaForm$Holder\")                 \\\n+  template(java_lang_invoke_DelegatingMethodHandle_Holder,  \"java\/lang\/invoke\/DelegatingMethodHandle$Holder\")     \\\n+  template(jdk_internal_loader_ClassLoaders,                \"jdk\/internal\/loader\/ClassLoaders\")                   \\\n+  template(jdk_internal_misc_CDS,                           \"jdk\/internal\/misc\/CDS\")                              \\\n+  template(java_util_concurrent_ConcurrentHashMap,          \"java\/util\/concurrent\/ConcurrentHashMap\")             \\\n+  template(java_util_ArrayList,                             \"java\/util\/ArrayList\")                                \\\n+  template(toFileURL_name,                                  \"toFileURL\")                                          \\\n+  template(toFileURL_signature,                             \"(Ljava\/lang\/String;)Ljava\/net\/URL;\")                 \\\n+  template(url_void_signature,                              \"(Ljava\/net\/URL;)V\")                                  \\\n@@ -680,832 +711,6 @@\n-\/\/ Here are all the intrinsics known to the runtime and the CI.\n-\/\/ Each intrinsic consists of a public enum name (like _hashCode),\n-\/\/ followed by a specification of its klass, name, and signature:\n-\/\/    template(<id>,  <klass>,  <name>, <sig>, <FCODE>)\n-\/\/\n-\/\/ If you add an intrinsic here, you must also define its name\n-\/\/ and signature as members of the VM symbols.  The VM symbols for\n-\/\/ the intrinsic name and signature may be defined above.\n-\/\/\n-\/\/ Because the VM_SYMBOLS_DO macro makes reference to VM_INTRINSICS_DO,\n-\/\/ you can also define an intrinsic's name and\/or signature locally to the\n-\/\/ intrinsic, if this makes sense.  (It often does make sense.)\n-\/\/\n-\/\/ For example:\n-\/\/    do_intrinsic(_foo,  java_lang_Object,  foo_name, foo_signature, F_xx)\n-\/\/     do_name(     foo_name, \"foo\")\n-\/\/     do_signature(foo_signature, \"()F\")\n-\/\/ klass      = vmSymbols::java_lang_Object()\n-\/\/ name       = vmSymbols::foo_name()\n-\/\/ signature  = vmSymbols::foo_signature()\n-\/\/\n-\/\/ The name and\/or signature might be a \"well known\" symbol\n-\/\/ like \"equal\" or \"()I\", in which case there will be no local\n-\/\/ re-definition of the symbol.\n-\/\/\n-\/\/ The do_class, do_name, and do_signature calls are all used for the\n-\/\/ same purpose:  Define yet another VM symbol.  They could all be merged\n-\/\/ into a common 'do_symbol' call, but it seems useful to record our\n-\/\/ intentions here about kinds of symbols (class vs. name vs. signature).\n-\/\/\n-\/\/ The F_xx is one of the Flags enum; see below.\n-\/\/\n-\/\/ for Emacs: (let ((c-backslash-column 120) (c-backslash-max-column 120)) (c-backslash-region (point) (point-max) nil t))\n-\/\/\n-\/\/\n-\/\/ There are two types of intrinsic methods: (1) Library intrinsics and (2) bytecode intrinsics.\n-\/\/\n-\/\/ (1) A library intrinsic method may be replaced with hand-crafted assembly code,\n-\/\/ with hand-crafted compiler IR, or with a combination of the two. The semantics\n-\/\/ of the replacement code may differ from the semantics of the replaced code.\n-\/\/\n-\/\/ (2) Bytecode intrinsic methods are not replaced by special code, but they are\n-\/\/ treated in some other special way by the compiler. For example, the compiler\n-\/\/ may delay inlining for some String-related intrinsic methods (e.g., some methods\n-\/\/ defined in the StringBuilder and StringBuffer classes, see\n-\/\/ Compile::should_delay_string_inlining() for more details).\n-\/\/\n-\/\/ Due to the difference between the semantics of an intrinsic method as defined\n-\/\/ in the (Java) source code and the semantics of the method as defined\n-\/\/ by the code in the VM, intrinsic methods must be explicitly marked.\n-\/\/\n-\/\/ Intrinsic methods are marked by the jdk.internal.HotSpotIntrinsicCandidate\n-\/\/ annotation. If CheckIntrinsics is enabled, the VM performs the following\n-\/\/ checks when a class C is loaded: (1) all intrinsics defined by the VM for\n-\/\/ class C are present in the loaded class file and are marked;\n-\/\/ (2) an intrinsic is defined by the VM for all marked methods of class C;\n-\/\/ (3) check for orphan methods in class C (i.e., methods for which the VM\n-\/\/ declares an intrinsic but that are not declared for the loaded class C.\n-\/\/ Check (3) is available only in debug builds.\n-\/\/\n-\/\/ If a mismatch is detected for a method, the VM behaves differently depending\n-\/\/ on the type of build. A fastdebug build exits and reports an error on a mismatch.\n-\/\/ A product build will not replace an unmarked library intrinsic method with\n-\/\/ hand-crafted code, that is, unmarked library intrinsics are treated as ordinary\n-\/\/ methods in a product build. The special treatment of a bytecode intrinsic method\n-\/\/ persists even if the method not marked.\n-\/\/\n-\/\/ When adding an intrinsic for a method, please make sure to appropriately\n-\/\/ annotate the method in the source code. The list below contains all\n-\/\/ library intrinsics followed by bytecode intrinsics. Please also make sure to\n-\/\/ add the declaration of the intrinsic to the approriate section of the list.\n-#define VM_INTRINSICS_DO(do_intrinsic, do_class, do_name, do_signature, do_alias)                                       \\\n-  \/* (1) Library intrinsics                                                                        *\/                   \\\n-  do_intrinsic(_hashCode,                 java_lang_Object,       hashCode_name, void_int_signature,             F_R)   \\\n-   do_name(     hashCode_name,                                   \"hashCode\")                                            \\\n-  do_intrinsic(_getClass,                 java_lang_Object,       getClass_name, void_class_signature,           F_R)   \\\n-   do_name(     getClass_name,                                   \"getClass\")                                            \\\n-  do_intrinsic(_clone,                    java_lang_Object,       clone_name, void_object_signature,             F_R)   \\\n-   do_name(     clone_name,                                      \"clone\")                                               \\\n-  do_intrinsic(_notify,                   java_lang_Object,       notify_name, void_method_signature,            F_R)   \\\n-   do_name(     notify_name,                                     \"notify\")                                              \\\n-  do_intrinsic(_notifyAll,                java_lang_Object,       notifyAll_name, void_method_signature,         F_R)   \\\n-   do_name(     notifyAll_name,                                  \"notifyAll\")                                           \\\n-                                                                                                                        \\\n-  \/* Math & StrictMath intrinsics are defined in terms of just a few signatures: *\/                                     \\\n-  do_class(java_lang_Math,                \"java\/lang\/Math\")                                                             \\\n-  do_class(java_lang_StrictMath,          \"java\/lang\/StrictMath\")                                                       \\\n-  do_signature(double2_double_signature,  \"(DD)D\")                                                                      \\\n-  do_signature(double3_double_signature,  \"(DDD)D\")                                                                     \\\n-  do_signature(float2_float_signature,    \"(FF)F\")                                                                      \\\n-  do_signature(float3_float_signature,    \"(FFF)F\")                                                                     \\\n-  do_signature(int2_int_signature,        \"(II)I\")                                                                      \\\n-  do_signature(long2_long_signature,      \"(JJ)J\")                                                                      \\\n-                                                                                                                        \\\n-  \/* here are the math names, all together: *\/                                                                          \\\n-  do_name(abs_name,\"abs\")       do_name(sin_name,\"sin\")         do_name(cos_name,\"cos\")                                 \\\n-  do_name(tan_name,\"tan\")       do_name(atan2_name,\"atan2\")     do_name(sqrt_name,\"sqrt\")                               \\\n-  do_name(log_name,\"log\")       do_name(log10_name,\"log10\")     do_name(pow_name,\"pow\")                                 \\\n-  do_name(exp_name,\"exp\")       do_name(min_name,\"min\")         do_name(max_name,\"max\")                                 \\\n-  do_name(floor_name, \"floor\")  do_name(ceil_name, \"ceil\")      do_name(rint_name, \"rint\")                              \\\n-                                                                                                                        \\\n-  do_name(addExact_name,\"addExact\")                                                                                     \\\n-  do_name(decrementExact_name,\"decrementExact\")                                                                         \\\n-  do_name(incrementExact_name,\"incrementExact\")                                                                         \\\n-  do_name(multiplyExact_name,\"multiplyExact\")                                                                           \\\n-  do_name(multiplyHigh_name,\"multiplyHigh\")                                                                             \\\n-  do_name(negateExact_name,\"negateExact\")                                                                               \\\n-  do_name(subtractExact_name,\"subtractExact\")                                                                           \\\n-  do_name(fma_name, \"fma\")                                                                                              \\\n-                                                                                                                        \\\n-  do_intrinsic(_dabs,                     java_lang_Math,         abs_name,   double_double_signature,           F_S)   \\\n-  do_intrinsic(_fabs,                     java_lang_Math,         abs_name,   float_float_signature,           F_S)   \\\n-  do_intrinsic(_iabs,                     java_lang_Math,         abs_name,   int_int_signature,           F_S)   \\\n-  do_intrinsic(_labs,                     java_lang_Math,         abs_name,   long_long_signature,           F_S)   \\\n-  do_intrinsic(_dsin,                     java_lang_Math,         sin_name,   double_double_signature,           F_S)   \\\n-  do_intrinsic(_floor,                    java_lang_Math,         floor_name, double_double_signature,           F_S)   \\\n-  do_intrinsic(_ceil,                     java_lang_Math,         ceil_name,  double_double_signature,           F_S)   \\\n-  do_intrinsic(_rint,                     java_lang_Math,         rint_name,  double_double_signature,           F_S)   \\\n-  do_intrinsic(_dcos,                     java_lang_Math,         cos_name,   double_double_signature,           F_S)   \\\n-  do_intrinsic(_dtan,                     java_lang_Math,         tan_name,   double_double_signature,           F_S)   \\\n-  do_intrinsic(_datan2,                   java_lang_Math,         atan2_name, double2_double_signature,          F_S)   \\\n-  do_intrinsic(_dsqrt,                    java_lang_Math,         sqrt_name,  double_double_signature,           F_S)   \\\n-  do_intrinsic(_dlog,                     java_lang_Math,         log_name,   double_double_signature,           F_S)   \\\n-  do_intrinsic(_dlog10,                   java_lang_Math,         log10_name, double_double_signature,           F_S)   \\\n-  do_intrinsic(_dpow,                     java_lang_Math,         pow_name,   double2_double_signature,          F_S)   \\\n-  do_intrinsic(_dexp,                     java_lang_Math,         exp_name,   double_double_signature,           F_S)   \\\n-  do_intrinsic(_min,                      java_lang_Math,         min_name,   int2_int_signature,                F_S)   \\\n-  do_intrinsic(_max,                      java_lang_Math,         max_name,   int2_int_signature,                F_S)   \\\n-  do_intrinsic(_addExactI,                java_lang_Math,         addExact_name, int2_int_signature,             F_S)   \\\n-  do_intrinsic(_addExactL,                java_lang_Math,         addExact_name, long2_long_signature,           F_S)   \\\n-  do_intrinsic(_decrementExactI,          java_lang_Math,         decrementExact_name, int_int_signature,        F_S)   \\\n-  do_intrinsic(_decrementExactL,          java_lang_Math,         decrementExact_name, long_long_signature,      F_S)   \\\n-  do_intrinsic(_incrementExactI,          java_lang_Math,         incrementExact_name, int_int_signature,        F_S)   \\\n-  do_intrinsic(_incrementExactL,          java_lang_Math,         incrementExact_name, long_long_signature,      F_S)   \\\n-  do_intrinsic(_multiplyExactI,           java_lang_Math,         multiplyExact_name, int2_int_signature,        F_S)   \\\n-  do_intrinsic(_multiplyExactL,           java_lang_Math,         multiplyExact_name, long2_long_signature,      F_S)   \\\n-  do_intrinsic(_multiplyHigh,             java_lang_Math,         multiplyHigh_name, long2_long_signature,       F_S)   \\\n-  do_intrinsic(_negateExactI,             java_lang_Math,         negateExact_name, int_int_signature,           F_S)   \\\n-  do_intrinsic(_negateExactL,             java_lang_Math,         negateExact_name, long_long_signature,         F_S)   \\\n-  do_intrinsic(_subtractExactI,           java_lang_Math,         subtractExact_name, int2_int_signature,        F_S)   \\\n-  do_intrinsic(_subtractExactL,           java_lang_Math,         subtractExact_name, long2_long_signature,      F_S)   \\\n-  do_intrinsic(_fmaD,                     java_lang_Math,         fma_name,           double3_double_signature,  F_S)   \\\n-  do_intrinsic(_fmaF,                     java_lang_Math,         fma_name,           float3_float_signature,    F_S)   \\\n-  do_intrinsic(_maxF,                     java_lang_Math,         max_name,           float2_float_signature,    F_S)   \\\n-  do_intrinsic(_minF,                     java_lang_Math,         min_name,           float2_float_signature,    F_S)   \\\n-  do_intrinsic(_maxD,                     java_lang_Math,         max_name,           double2_double_signature,  F_S)   \\\n-  do_intrinsic(_minD,                     java_lang_Math,         min_name,           double2_double_signature,  F_S)   \\\n-                                                                                                                        \\\n-  do_intrinsic(_floatToRawIntBits,        java_lang_Float,        floatToRawIntBits_name,   float_int_signature, F_S)   \\\n-   do_name(     floatToRawIntBits_name,                          \"floatToRawIntBits\")                                   \\\n-  do_intrinsic(_floatToIntBits,           java_lang_Float,        floatToIntBits_name,      float_int_signature, F_S)   \\\n-   do_name(     floatToIntBits_name,                             \"floatToIntBits\")                                      \\\n-  do_intrinsic(_intBitsToFloat,           java_lang_Float,        intBitsToFloat_name,      int_float_signature, F_S)   \\\n-   do_name(     intBitsToFloat_name,                             \"intBitsToFloat\")                                      \\\n-  do_intrinsic(_doubleToRawLongBits,      java_lang_Double,       doubleToRawLongBits_name, double_long_signature, F_S) \\\n-   do_name(     doubleToRawLongBits_name,                        \"doubleToRawLongBits\")                                 \\\n-  do_intrinsic(_doubleToLongBits,         java_lang_Double,       doubleToLongBits_name,    double_long_signature, F_S) \\\n-   do_name(     doubleToLongBits_name,                           \"doubleToLongBits\")                                    \\\n-  do_intrinsic(_longBitsToDouble,         java_lang_Double,       longBitsToDouble_name,    long_double_signature, F_S) \\\n-   do_name(     longBitsToDouble_name,                           \"longBitsToDouble\")                                    \\\n-                                                                                                                        \\\n-  do_intrinsic(_numberOfLeadingZeros_i,   java_lang_Integer,      numberOfLeadingZeros_name,int_int_signature,   F_S)   \\\n-  do_intrinsic(_numberOfLeadingZeros_l,   java_lang_Long,         numberOfLeadingZeros_name,long_int_signature,  F_S)   \\\n-                                                                                                                        \\\n-  do_intrinsic(_numberOfTrailingZeros_i,  java_lang_Integer,      numberOfTrailingZeros_name,int_int_signature,  F_S)   \\\n-  do_intrinsic(_numberOfTrailingZeros_l,  java_lang_Long,         numberOfTrailingZeros_name,long_int_signature, F_S)   \\\n-                                                                                                                        \\\n-  do_intrinsic(_bitCount_i,               java_lang_Integer,      bitCount_name,            int_int_signature,   F_S)   \\\n-  do_intrinsic(_bitCount_l,               java_lang_Long,         bitCount_name,            long_int_signature,  F_S)   \\\n-                                                                                                                        \\\n-  do_intrinsic(_reverseBytes_i,           java_lang_Integer,      reverseBytes_name,        int_int_signature,   F_S)   \\\n-   do_name(     reverseBytes_name,                               \"reverseBytes\")                                        \\\n-  do_intrinsic(_reverseBytes_l,           java_lang_Long,         reverseBytes_name,        long_long_signature, F_S)   \\\n-    \/*  (symbol reverseBytes_name defined above) *\/                                                                     \\\n-  do_intrinsic(_reverseBytes_c,           java_lang_Character,    reverseBytes_name,        char_char_signature, F_S)   \\\n-    \/*  (symbol reverseBytes_name defined above) *\/                                                                     \\\n-  do_intrinsic(_reverseBytes_s,           java_lang_Short,        reverseBytes_name,        short_short_signature, F_S) \\\n-    \/*  (symbol reverseBytes_name defined above) *\/                                                                     \\\n-                                                                                                                        \\\n-  do_intrinsic(_identityHashCode,         java_lang_System,       identityHashCode_name, object_int_signature,   F_S)   \\\n-   do_name(     identityHashCode_name,                           \"identityHashCode\")                                    \\\n-  do_intrinsic(_currentTimeMillis,        java_lang_System,       currentTimeMillis_name, void_long_signature,   F_S)   \\\n-                                                                                                                        \\\n-   do_name(     currentTimeMillis_name,                          \"currentTimeMillis\")                                   \\\n-  do_intrinsic(_nanoTime,                 java_lang_System,       nanoTime_name,          void_long_signature,   F_S)   \\\n-   do_name(     nanoTime_name,                                   \"nanoTime\")                                            \\\n-                                                                                                                        \\\n-  JFR_INTRINSICS(do_intrinsic, do_class, do_name, do_signature, do_alias)                                               \\\n-                                                                                                                        \\\n-  do_intrinsic(_arraycopy,                java_lang_System,       arraycopy_name, arraycopy_signature,           F_S)   \\\n-   do_name(     arraycopy_name,                                  \"arraycopy\")                                           \\\n-   do_signature(arraycopy_signature,                             \"(Ljava\/lang\/Object;ILjava\/lang\/Object;II)V\")          \\\n-  do_intrinsic(_currentThread,            java_lang_Thread,       currentThread_name, currentThread_signature,   F_S)   \\\n-   do_name(     currentThread_name,                              \"currentThread\")                                       \\\n-   do_signature(currentThread_signature,                         \"()Ljava\/lang\/Thread;\")                                \\\n-                                                                                                                        \\\n-  \/* reflective intrinsics, for java\/lang\/Class, etc. *\/                                                                \\\n-  do_intrinsic(_isAssignableFrom,         java_lang_Class,        isAssignableFrom_name, class_boolean_signature, F_RN) \\\n-   do_name(     isAssignableFrom_name,                           \"isAssignableFrom\")                                    \\\n-  do_intrinsic(_isInstance,               java_lang_Class,        isInstance_name, object_boolean_signature,     F_RN)  \\\n-   do_name(     isInstance_name,                                 \"isInstance\")                                          \\\n-  do_intrinsic(_getModifiers,             java_lang_Class,        getModifiers_name, void_int_signature,         F_RN)  \\\n-   do_name(     getModifiers_name,                               \"getModifiers\")                                        \\\n-  do_intrinsic(_isInterface,              java_lang_Class,        isInterface_name, void_boolean_signature,      F_RN)  \\\n-   do_name(     isInterface_name,                                \"isInterface\")                                         \\\n-  do_intrinsic(_isArray,                  java_lang_Class,        isArray_name, void_boolean_signature,          F_RN)  \\\n-   do_name(     isArray_name,                                    \"isArray\")                                             \\\n-  do_intrinsic(_isPrimitive,              java_lang_Class,        isPrimitive_name, void_boolean_signature,      F_RN)  \\\n-   do_name(     isPrimitive_name,                                \"isPrimitive\")                                         \\\n-  do_intrinsic(_isHidden,                 java_lang_Class,        isHidden_name, void_boolean_signature,         F_RN)  \\\n-   do_name(     isHidden_name,                                   \"isHidden\")                                            \\\n-  do_intrinsic(_getSuperclass,            java_lang_Class,        getSuperclass_name, void_class_signature,      F_RN)  \\\n-   do_name(     getSuperclass_name,                              \"getSuperclass\")                                       \\\n-  do_intrinsic(_Class_cast,               java_lang_Class,        Class_cast_name, object_object_signature,      F_R)   \\\n-   do_name(     Class_cast_name,                                 \"cast\")                                                \\\n-                                                                                                                        \\\n-  do_intrinsic(_getClassAccessFlags,      reflect_Reflection,     getClassAccessFlags_name, class_int_signature, F_SN)  \\\n-   do_name(     getClassAccessFlags_name,                        \"getClassAccessFlags\")                                 \\\n-  do_intrinsic(_getLength,                java_lang_reflect_Array, getLength_name, object_int_signature,         F_SN)  \\\n-   do_name(     getLength_name,                                   \"getLength\")                                          \\\n-                                                                                                                        \\\n-  do_intrinsic(_getCallerClass,           reflect_Reflection,     getCallerClass_name, void_class_signature,     F_SN)  \\\n-   do_name(     getCallerClass_name,                             \"getCallerClass\")                                      \\\n-                                                                                                                        \\\n-  do_intrinsic(_newArray,                 java_lang_reflect_Array, newArray_name, newArray_signature,            F_SN)  \\\n-   do_name(     newArray_name,                                    \"newArray\")                                           \\\n-   do_signature(newArray_signature,                               \"(Ljava\/lang\/Class;I)Ljava\/lang\/Object;\")             \\\n-                                                                                                                        \\\n-  do_intrinsic(_onSpinWait,               java_lang_Thread,       onSpinWait_name, onSpinWait_signature,         F_S)   \\\n-   do_name(     onSpinWait_name,                                  \"onSpinWait\")                                         \\\n-   do_alias(    onSpinWait_signature,                             void_method_signature)                                \\\n-                                                                                                                        \\\n-  do_intrinsic(_copyOf,                   java_util_Arrays,       copyOf_name, copyOf_signature,                 F_S)   \\\n-   do_name(     copyOf_name,                                     \"copyOf\")                                              \\\n-   do_signature(copyOf_signature,             \"([Ljava\/lang\/Object;ILjava\/lang\/Class;)[Ljava\/lang\/Object;\")             \\\n-                                                                                                                        \\\n-  do_intrinsic(_copyOfRange,              java_util_Arrays,       copyOfRange_name, copyOfRange_signature,       F_S)   \\\n-   do_name(     copyOfRange_name,                                \"copyOfRange\")                                         \\\n-   do_signature(copyOfRange_signature,        \"([Ljava\/lang\/Object;IILjava\/lang\/Class;)[Ljava\/lang\/Object;\")            \\\n-                                                                                                                        \\\n-  do_intrinsic(_equalsC,                  java_util_Arrays,       equals_name,    equalsC_signature,             F_S)   \\\n-   do_signature(equalsC_signature,                               \"([C[C)Z\")                                             \\\n-  do_intrinsic(_equalsB,                  java_util_Arrays,       equals_name,    equalsB_signature,             F_S)   \\\n-   do_signature(equalsB_signature,                               \"([B[B)Z\")                                             \\\n-                                                                                                                        \\\n-  do_intrinsic(_compressStringC,          java_lang_StringUTF16,  compress_name, encodeISOArray_signature,       F_S)   \\\n-   do_name(     compress_name,                                   \"compress\")                                            \\\n-  do_intrinsic(_compressStringB,          java_lang_StringUTF16,  compress_name, indexOfI_signature,             F_S)   \\\n-  do_intrinsic(_inflateStringC,           java_lang_StringLatin1, inflate_name, inflateC_signature,              F_S)   \\\n-   do_name(     inflate_name,                                    \"inflate\")                                             \\\n-   do_signature(inflateC_signature,                              \"([BI[CII)V\")                                          \\\n-  do_intrinsic(_inflateStringB,           java_lang_StringLatin1, inflate_name, inflateB_signature,              F_S)   \\\n-   do_signature(inflateB_signature,                              \"([BI[BII)V\")                                          \\\n-  do_intrinsic(_toBytesStringU,           java_lang_StringUTF16, toBytes_name, toBytesU_signature,               F_S)   \\\n-   do_name(     toBytes_name,                                    \"toBytes\")                                             \\\n-   do_signature(toBytesU_signature,                              \"([CII)[B\")                                            \\\n-  do_intrinsic(_getCharsStringU,          java_lang_StringUTF16, getCharsU_name, getCharsU_signature,            F_S)   \\\n-   do_name(     getCharsU_name,                                  \"getChars\")                                            \\\n-   do_signature(getCharsU_signature,                             \"([BII[CI)V\")                                          \\\n-  do_intrinsic(_getCharStringU,           java_lang_StringUTF16, getChar_name, getCharStringU_signature,         F_S)   \\\n-   do_signature(getCharStringU_signature,                        \"([BI)C\")                                              \\\n-  do_intrinsic(_putCharStringU,           java_lang_StringUTF16, putChar_name, putCharStringU_signature,         F_S)   \\\n-   do_signature(putCharStringU_signature,                        \"([BII)V\")                                             \\\n-  do_intrinsic(_compareToL,               java_lang_StringLatin1,compareTo_name, compareTo_indexOf_signature,    F_S)   \\\n-  do_intrinsic(_compareToU,               java_lang_StringUTF16, compareTo_name, compareTo_indexOf_signature,    F_S)   \\\n-  do_intrinsic(_compareToLU,              java_lang_StringLatin1,compareToLU_name, compareTo_indexOf_signature,  F_S)   \\\n-  do_intrinsic(_compareToUL,              java_lang_StringUTF16, compareToUL_name, compareTo_indexOf_signature,  F_S)   \\\n-   do_signature(compareTo_indexOf_signature,                     \"([B[B)I\")                                             \\\n-   do_name(     compareTo_name,                                  \"compareTo\")                                           \\\n-   do_name(     compareToLU_name,                                \"compareToUTF16\")                                      \\\n-   do_name(     compareToUL_name,                                \"compareToLatin1\")                                     \\\n-  do_intrinsic(_indexOfL,                 java_lang_StringLatin1,indexOf_name, compareTo_indexOf_signature,      F_S)   \\\n-  do_intrinsic(_indexOfU,                 java_lang_StringUTF16, indexOf_name, compareTo_indexOf_signature,      F_S)   \\\n-  do_intrinsic(_indexOfUL,                java_lang_StringUTF16, indexOfUL_name, compareTo_indexOf_signature,    F_S)   \\\n-  do_intrinsic(_indexOfIL,                java_lang_StringLatin1,indexOf_name, indexOfI_signature,               F_S)   \\\n-  do_intrinsic(_indexOfIU,                java_lang_StringUTF16, indexOf_name, indexOfI_signature,               F_S)   \\\n-  do_intrinsic(_indexOfIUL,               java_lang_StringUTF16, indexOfUL_name, indexOfI_signature,             F_S)   \\\n-  do_intrinsic(_indexOfU_char,            java_lang_StringUTF16, indexOfChar_name, indexOfChar_signature,        F_S)   \\\n-   do_name(     indexOf_name,                                    \"indexOf\")                                             \\\n-   do_name(     indexOfChar_name,                                \"indexOfChar\")                                         \\\n-   do_name(     indexOfUL_name,                                  \"indexOfLatin1\")                                       \\\n-   do_signature(indexOfI_signature,                              \"([BI[BII)I\")                                          \\\n-   do_signature(indexOfChar_signature,                           \"([BIII)I\")                                            \\\n-  do_intrinsic(_equalsL,                  java_lang_StringLatin1,equals_name, equalsB_signature,                 F_S)   \\\n-  do_intrinsic(_equalsU,                  java_lang_StringUTF16, equals_name, equalsB_signature,                 F_S)   \\\n-                                                                                                                        \\\n-  do_intrinsic(_isDigit,                  java_lang_CharacterDataLatin1, isDigit_name,      int_bool_signature,  F_R)   \\\n-   do_name(     isDigit_name,                                           \"isDigit\")                                      \\\n-  do_intrinsic(_isLowerCase,              java_lang_CharacterDataLatin1, isLowerCase_name,  int_bool_signature,  F_R)   \\\n-   do_name(     isLowerCase_name,                                       \"isLowerCase\")                                  \\\n-  do_intrinsic(_isUpperCase,              java_lang_CharacterDataLatin1, isUpperCase_name,  int_bool_signature,  F_R)   \\\n-   do_name(     isUpperCase_name,                                       \"isUpperCase\")                                  \\\n-  do_intrinsic(_isWhitespace,             java_lang_CharacterDataLatin1, isWhitespace_name, int_bool_signature,  F_R)   \\\n-   do_name(     isWhitespace_name,                                      \"isWhitespace\")                                 \\\n-                                                                                                                        \\\n-  do_intrinsic(_Preconditions_checkIndex, jdk_internal_util_Preconditions, checkIndex_name, Preconditions_checkIndex_signature, F_S)   \\\n-   do_signature(Preconditions_checkIndex_signature,              \"(IILjava\/util\/function\/BiFunction;)I\")                \\\n-                                                                                                                        \\\n-  do_class(java_nio_Buffer,               \"java\/nio\/Buffer\")                                                            \\\n-  do_intrinsic(_checkIndex,               java_nio_Buffer,        checkIndex_name, int_int_signature,            F_R)   \\\n-   do_name(     checkIndex_name,                                 \"checkIndex\")                                          \\\n-                                                                                                                        \\\n-  do_class(java_lang_StringCoding,        \"java\/lang\/StringCoding\")                                                     \\\n-  do_intrinsic(_hasNegatives,             java_lang_StringCoding, hasNegatives_name, hasNegatives_signature,     F_S)   \\\n-   do_name(     hasNegatives_name,                               \"hasNegatives\")                                        \\\n-   do_signature(hasNegatives_signature,                          \"([BII)Z\")                                             \\\n-                                                                                                                        \\\n-  do_class(sun_nio_cs_iso8859_1_Encoder,  \"sun\/nio\/cs\/ISO_8859_1$Encoder\")                                              \\\n-  do_intrinsic(_encodeISOArray,     sun_nio_cs_iso8859_1_Encoder, encodeISOArray_name, encodeISOArray_signature, F_S)   \\\n-   do_name(     encodeISOArray_name,                             \"implEncodeISOArray\")                                  \\\n-   do_signature(encodeISOArray_signature,                        \"([CI[BII)I\")                                          \\\n-                                                                                                                        \\\n-  do_intrinsic(_encodeByteISOArray,     java_lang_StringCoding, encodeISOArray_name, indexOfI_signature,         F_S)   \\\n-                                                                                                                        \\\n-  do_class(java_math_BigInteger,                      \"java\/math\/BigInteger\")                                           \\\n-  do_intrinsic(_multiplyToLen,      java_math_BigInteger, multiplyToLen_name, multiplyToLen_signature, F_S)             \\\n-   do_name(     multiplyToLen_name,                             \"implMultiplyToLen\")                                    \\\n-   do_signature(multiplyToLen_signature,                        \"([II[II[I)[I\")                                         \\\n-                                                                                                                        \\\n-  do_intrinsic(_squareToLen, java_math_BigInteger, squareToLen_name, squareToLen_signature, F_S)                        \\\n-   do_name(     squareToLen_name,                             \"implSquareToLen\")                                        \\\n-   do_signature(squareToLen_signature,                        \"([II[II)[I\")                                             \\\n-                                                                                                                        \\\n-  do_intrinsic(_mulAdd, java_math_BigInteger, mulAdd_name, mulAdd_signature, F_S)                                       \\\n-   do_name(     mulAdd_name,                                  \"implMulAdd\")                                             \\\n-   do_signature(mulAdd_signature,                             \"([I[IIII)I\")                                             \\\n-                                                                                                                        \\\n-  do_intrinsic(_montgomeryMultiply,      java_math_BigInteger, montgomeryMultiply_name, montgomeryMultiply_signature, F_S) \\\n-   do_name(     montgomeryMultiply_name,                             \"implMontgomeryMultiply\")                          \\\n-   do_signature(montgomeryMultiply_signature,                        \"([I[I[IIJ[I)[I\")                                  \\\n-                                                                                                                        \\\n-  do_intrinsic(_montgomerySquare,      java_math_BigInteger, montgomerySquare_name, montgomerySquare_signature, F_S)    \\\n-   do_name(     montgomerySquare_name,                             \"implMontgomerySquare\")                              \\\n-   do_signature(montgomerySquare_signature,                        \"([I[IIJ[I)[I\")                                      \\\n-                                                                                                                        \\\n-  do_intrinsic(_bigIntegerRightShiftWorker, java_math_BigInteger, rightShift_name, big_integer_shift_worker_signature, F_S) \\\n-   do_name(     rightShift_name,                                 \"shiftRightImplWorker\")                                \\\n-                                                                                                                        \\\n-  do_intrinsic(_bigIntegerLeftShiftWorker, java_math_BigInteger, leftShift_name, big_integer_shift_worker_signature, F_S) \\\n-   do_name(     leftShift_name,                                 \"shiftLeftImplWorker\")                                  \\\n-                                                                                                                        \\\n-  do_class(jdk_internal_util_ArraysSupport, \"jdk\/internal\/util\/ArraysSupport\")                                                          \\\n-  do_intrinsic(_vectorizedMismatch, jdk_internal_util_ArraysSupport, vectorizedMismatch_name, vectorizedMismatch_signature, F_S)\\\n-   do_name(vectorizedMismatch_name, \"vectorizedMismatch\")                                                               \\\n-   do_signature(vectorizedMismatch_signature, \"(Ljava\/lang\/Object;JLjava\/lang\/Object;JII)I\")                            \\\n-                                                                                                                        \\\n-  \/* java\/lang\/ref\/Reference *\/                                                                                         \\\n-  do_intrinsic(_Reference_get,            java_lang_ref_Reference, get_name,    void_object_signature, F_R)             \\\n-                                                                                                                        \\\n-  \/* support for com.sun.crypto.provider.AESCrypt and some of its callers *\/                                            \\\n-  do_class(com_sun_crypto_provider_aescrypt,      \"com\/sun\/crypto\/provider\/AESCrypt\")                                   \\\n-  do_intrinsic(_aescrypt_encryptBlock, com_sun_crypto_provider_aescrypt, encryptBlock_name, byteArray_int_byteArray_int_signature, F_R)   \\\n-  do_intrinsic(_aescrypt_decryptBlock, com_sun_crypto_provider_aescrypt, decryptBlock_name, byteArray_int_byteArray_int_signature, F_R)   \\\n-   do_name(     encryptBlock_name,                                 \"implEncryptBlock\")                                  \\\n-   do_name(     decryptBlock_name,                                 \"implDecryptBlock\")                                  \\\n-   do_signature(byteArray_int_byteArray_int_signature,             \"([BI[BI)V\")                                         \\\n-                                                                                                                        \\\n-  do_class(com_sun_crypto_provider_cipherBlockChaining,            \"com\/sun\/crypto\/provider\/CipherBlockChaining\")       \\\n-   do_intrinsic(_cipherBlockChaining_encryptAESCrypt, com_sun_crypto_provider_cipherBlockChaining, encrypt_name, byteArray_int_int_byteArray_int_signature, F_R)   \\\n-   do_intrinsic(_cipherBlockChaining_decryptAESCrypt, com_sun_crypto_provider_cipherBlockChaining, decrypt_name, byteArray_int_int_byteArray_int_signature, F_R)   \\\n-   do_name(     encrypt_name,                                      \"implEncrypt\")                                       \\\n-   do_name(     decrypt_name,                                      \"implDecrypt\")                                       \\\n-   do_signature(byteArray_int_int_byteArray_int_signature,         \"([BII[BI)I\")                                        \\\n-                                                                                                                        \\\n-  do_class(com_sun_crypto_provider_electronicCodeBook, \"com\/sun\/crypto\/provider\/ElectronicCodeBook\")                    \\\n-   do_intrinsic(_electronicCodeBook_encryptAESCrypt, com_sun_crypto_provider_electronicCodeBook, ecb_encrypt_name, byteArray_int_int_byteArray_int_signature, F_R)  \\\n-   do_intrinsic(_electronicCodeBook_decryptAESCrypt, com_sun_crypto_provider_electronicCodeBook, ecb_decrypt_name, byteArray_int_int_byteArray_int_signature, F_R)  \\\n-   do_name(ecb_encrypt_name, \"implECBEncrypt\")                                                                          \\\n-   do_name(ecb_decrypt_name, \"implECBDecrypt\")                                                                          \\\n-                                                                                                                        \\\n-  do_class(com_sun_crypto_provider_counterMode,      \"com\/sun\/crypto\/provider\/CounterMode\")                             \\\n-   do_intrinsic(_counterMode_AESCrypt, com_sun_crypto_provider_counterMode, crypt_name, byteArray_int_int_byteArray_int_signature, F_R)   \\\n-   do_name(     crypt_name,                                 \"implCrypt\")                                                    \\\n-                                                                                                                        \\\n-  \/* support for sun.security.provider.SHA *\/                                                                           \\\n-  do_class(sun_security_provider_sha,                              \"sun\/security\/provider\/SHA\")                         \\\n-  do_intrinsic(_sha_implCompress, sun_security_provider_sha, implCompress_name, implCompress_signature, F_R)            \\\n-   do_name(     implCompress_name,                                 \"implCompress0\")                                     \\\n-   do_signature(implCompress_signature,                            \"([BI)V\")                                            \\\n-                                                                                                                        \\\n-  \/* support for sun.security.provider.SHA2 *\/                                                                          \\\n-  do_class(sun_security_provider_sha2,                             \"sun\/security\/provider\/SHA2\")                        \\\n-  do_intrinsic(_sha2_implCompress, sun_security_provider_sha2, implCompress_name, implCompress_signature, F_R)          \\\n-                                                                                                                        \\\n-  \/* support for sun.security.provider.SHA5 *\/                                                                          \\\n-  do_class(sun_security_provider_sha5,                             \"sun\/security\/provider\/SHA5\")                        \\\n-  do_intrinsic(_sha5_implCompress, sun_security_provider_sha5, implCompress_name, implCompress_signature, F_R)          \\\n-                                                                                                                        \\\n-  \/* support for sun.security.provider.DigestBase *\/                                                                    \\\n-  do_class(sun_security_provider_digestbase,                       \"sun\/security\/provider\/DigestBase\")                  \\\n-  do_intrinsic(_digestBase_implCompressMB, sun_security_provider_digestbase, implCompressMB_name, implCompressMB_signature, F_R)   \\\n-   do_name(     implCompressMB_name,                               \"implCompressMultiBlock0\")                           \\\n-   do_signature(implCompressMB_signature,                          \"([BII)I\")                                           \\\n-                                                                                                                        \\\n-   \/* support for java.util.Base64.Encoder*\/                                                                            \\\n-  do_class(java_util_Base64_Encoder, \"java\/util\/Base64$Encoder\")                                                        \\\n-  do_intrinsic(_base64_encodeBlock, java_util_Base64_Encoder, encodeBlock_name, encodeBlock_signature, F_R)             \\\n-  do_name(encodeBlock_name, \"encodeBlock\")                                                                              \\\n-  do_signature(encodeBlock_signature, \"([BII[BIZ)V\")                                                                    \\\n-                                                                                                                        \\\n-  \/* support for com.sun.crypto.provider.GHASH *\/                                                                       \\\n-  do_class(com_sun_crypto_provider_ghash, \"com\/sun\/crypto\/provider\/GHASH\")                                              \\\n-  do_intrinsic(_ghash_processBlocks, com_sun_crypto_provider_ghash, processBlocks_name, ghash_processBlocks_signature, F_S) \\\n-   do_name(processBlocks_name, \"processBlocks\")                                                                         \\\n-   do_signature(ghash_processBlocks_signature, \"([BII[J[J)V\")                                                           \\\n-                                                                                                                        \\\n-  \/* support for java.util.zip *\/                                                                                       \\\n-  do_class(java_util_zip_CRC32,           \"java\/util\/zip\/CRC32\")                                                        \\\n-  do_intrinsic(_updateCRC32,               java_util_zip_CRC32,   update_name, int2_int_signature,               F_SN)  \\\n-   do_name(     update_name,                                      \"update\")                                             \\\n-  do_intrinsic(_updateBytesCRC32,          java_util_zip_CRC32,   updateBytes_name, updateBytes_signature,       F_SN)  \\\n-   do_name(     updateBytes_name,                                \"updateBytes0\")                                        \\\n-   do_signature(updateBytes_signature,                           \"(I[BII)I\")                                            \\\n-  do_intrinsic(_updateByteBufferCRC32,     java_util_zip_CRC32,   updateByteBuffer_name, updateByteBuffer_signature, F_SN) \\\n-   do_name(     updateByteBuffer_name,                           \"updateByteBuffer0\")                                   \\\n-   do_signature(updateByteBuffer_signature,                      \"(IJII)I\")                                             \\\n-                                                                                                                        \\\n-  \/* support for java.util.zip.CRC32C *\/                                                                                \\\n-  do_class(java_util_zip_CRC32C,          \"java\/util\/zip\/CRC32C\")                                                       \\\n-  do_intrinsic(_updateBytesCRC32C,         java_util_zip_CRC32C,  updateBytes_C_name, updateBytes_signature,       F_S) \\\n-   do_name(     updateBytes_C_name,                               \"updateBytes\")                                        \\\n-  do_intrinsic(_updateDirectByteBufferCRC32C, java_util_zip_CRC32C, updateDirectByteBuffer_C_name, updateByteBuffer_signature, F_S) \\\n-   do_name(    updateDirectByteBuffer_C_name,                     \"updateDirectByteBuffer\")                             \\\n-                                                                                                                        \\\n-   \/* support for java.util.zip.Adler32 *\/                                                                              \\\n-  do_class(java_util_zip_Adler32,        \"java\/util\/zip\/Adler32\")                                                       \\\n-  do_intrinsic(_updateBytesAdler32,       java_util_zip_Adler32,  updateBytes_C_name,  updateBytes_signature,  F_SN)    \\\n-  do_intrinsic(_updateByteBufferAdler32,  java_util_zip_Adler32,  updateByteBuffer_A_name,  updateByteBuffer_signature,  F_SN) \\\n-   do_name(     updateByteBuffer_A_name,                          \"updateByteBuffer\")                                   \\\n-                                                                                                                        \\\n-  \/* support for UnsafeConstants *\/                                                                                     \\\n-  do_class(jdk_internal_misc_UnsafeConstants,      \"jdk\/internal\/misc\/UnsafeConstants\")                                 \\\n-                                                                                                                        \\\n-  \/* support for Unsafe *\/                                                                                              \\\n-  do_class(jdk_internal_misc_Unsafe,               \"jdk\/internal\/misc\/Unsafe\")                                          \\\n-  do_class(sun_misc_Unsafe,                        \"sun\/misc\/Unsafe\")                                                   \\\n-                                                                                                                        \\\n-  do_intrinsic(_writeback0,               jdk_internal_misc_Unsafe,     writeback0_name, long_void_signature , F_RN)             \\\n-   do_name(     writeback0_name,                                        \"writeback0\")                                            \\\n-  do_intrinsic(_writebackPreSync0,        jdk_internal_misc_Unsafe,     writebackPreSync0_name, void_method_signature , F_RN)    \\\n-   do_name(     writebackPreSync0_name,                                 \"writebackPreSync0\")                                     \\\n-  do_intrinsic(_writebackPostSync0,       jdk_internal_misc_Unsafe,    writebackPostSync0_name, void_method_signature , F_RN)    \\\n-   do_name(     writebackPostSync0_name,                                \"writebackPostSync0\")                                    \\\n-  do_intrinsic(_allocateInstance,         jdk_internal_misc_Unsafe,     allocateInstance_name, allocateInstance_signature, F_RN) \\\n-   do_name(     allocateInstance_name,                                  \"allocateInstance\")                                      \\\n-   do_signature(allocateInstance_signature,                             \"(Ljava\/lang\/Class;)Ljava\/lang\/Object;\")                 \\\n-  do_intrinsic(_allocateUninitializedArray, jdk_internal_misc_Unsafe,   allocateUninitializedArray_name, newArray_signature,  F_R) \\\n-   do_name(     allocateUninitializedArray_name,                        \"allocateUninitializedArray0\")                           \\\n-  do_intrinsic(_copyMemory,               jdk_internal_misc_Unsafe,     copyMemory_name, copyMemory_signature,         F_RN)     \\\n-   do_name(     copyMemory_name,                                        \"copyMemory0\")                                           \\\n-   do_signature(copyMemory_signature,                                   \"(Ljava\/lang\/Object;JLjava\/lang\/Object;JJ)V\")            \\\n-  do_intrinsic(_loadFence,                jdk_internal_misc_Unsafe,     loadFence_name, loadFence_signature,           F_RN)     \\\n-   do_name(     loadFence_name,                                         \"loadFence\")                                             \\\n-   do_alias(    loadFence_signature,                                    void_method_signature)                                   \\\n-  do_intrinsic(_storeFence,               jdk_internal_misc_Unsafe,     storeFence_name, storeFence_signature,         F_RN)     \\\n-   do_name(     storeFence_name,                                        \"storeFence\")                                            \\\n-   do_alias(    storeFence_signature,                                   void_method_signature)                                   \\\n-  do_intrinsic(_fullFence,                jdk_internal_misc_Unsafe,     fullFence_name, fullFence_signature,           F_RN)     \\\n-   do_name(     fullFence_name,                                         \"fullFence\")                                             \\\n-   do_alias(    fullFence_signature,                                    void_method_signature)                                   \\\n-                                                                                                                        \\\n-  \/* Custom branch frequencies profiling support for JSR292 *\/                                                          \\\n-  do_class(java_lang_invoke_MethodHandleImpl,               \"java\/lang\/invoke\/MethodHandleImpl\")                        \\\n-  do_intrinsic(_profileBoolean, java_lang_invoke_MethodHandleImpl, profileBoolean_name, profileBoolean_signature, F_S)  \\\n-   do_name(     profileBoolean_name,                             \"profileBoolean\")                                      \\\n-   do_signature(profileBoolean_signature,                        \"(Z[I)Z\")                                              \\\n-  do_intrinsic(_isCompileConstant, java_lang_invoke_MethodHandleImpl, isCompileConstant_name, isCompileConstant_signature, F_S) \\\n-   do_name(     isCompileConstant_name,                          \"isCompileConstant\")                                   \\\n-   do_alias(    isCompileConstant_signature,                      object_boolean_signature)                             \\\n-                                                                                                                        \\\n-  \/* unsafe memory references (there are a lot of them...) *\/                                                           \\\n-  do_signature(getReference_signature,    \"(Ljava\/lang\/Object;J)Ljava\/lang\/Object;\")                                    \\\n-  do_signature(putReference_signature,    \"(Ljava\/lang\/Object;JLjava\/lang\/Object;)V\")                                   \\\n-  do_signature(getBoolean_signature,      \"(Ljava\/lang\/Object;J)Z\")                                                     \\\n-  do_signature(putBoolean_signature,      \"(Ljava\/lang\/Object;JZ)V\")                                                    \\\n-  do_signature(getByte_signature,         \"(Ljava\/lang\/Object;J)B\")                                                     \\\n-  do_signature(putByte_signature,         \"(Ljava\/lang\/Object;JB)V\")                                                    \\\n-  do_signature(getShort_signature,        \"(Ljava\/lang\/Object;J)S\")                                                     \\\n-  do_signature(putShort_signature,        \"(Ljava\/lang\/Object;JS)V\")                                                    \\\n-  do_signature(getChar_signature,         \"(Ljava\/lang\/Object;J)C\")                                                     \\\n-  do_signature(putChar_signature,         \"(Ljava\/lang\/Object;JC)V\")                                                    \\\n-  do_signature(getInt_signature,          \"(Ljava\/lang\/Object;J)I\")                                                     \\\n-  do_signature(putInt_signature,          \"(Ljava\/lang\/Object;JI)V\")                                                    \\\n-  do_signature(getLong_signature,         \"(Ljava\/lang\/Object;J)J\")                                                     \\\n-  do_signature(putLong_signature,         \"(Ljava\/lang\/Object;JJ)V\")                                                    \\\n-  do_signature(getFloat_signature,        \"(Ljava\/lang\/Object;J)F\")                                                     \\\n-  do_signature(putFloat_signature,        \"(Ljava\/lang\/Object;JF)V\")                                                    \\\n-  do_signature(getDouble_signature,       \"(Ljava\/lang\/Object;J)D\")                                                     \\\n-  do_signature(putDouble_signature,       \"(Ljava\/lang\/Object;JD)V\")                                                    \\\n-                                                                                                                        \\\n-  do_name(getReference_name,\"getReference\")     do_name(putReference_name,\"putReference\")                               \\\n-  do_name(getBoolean_name,\"getBoolean\")         do_name(putBoolean_name,\"putBoolean\")                                   \\\n-  do_name(getByte_name,\"getByte\")               do_name(putByte_name,\"putByte\")                                         \\\n-  do_name(getShort_name,\"getShort\")             do_name(putShort_name,\"putShort\")                                       \\\n-  do_name(getChar_name,\"getChar\")               do_name(putChar_name,\"putChar\")                                         \\\n-  do_name(getInt_name,\"getInt\")                 do_name(putInt_name,\"putInt\")                                           \\\n-  do_name(getLong_name,\"getLong\")               do_name(putLong_name,\"putLong\")                                         \\\n-  do_name(getFloat_name,\"getFloat\")             do_name(putFloat_name,\"putFloat\")                                       \\\n-  do_name(getDouble_name,\"getDouble\")           do_name(putDouble_name,\"putDouble\")                                     \\\n-                                                                                                                        \\\n-  do_intrinsic(_getReference,       jdk_internal_misc_Unsafe,     getReference_name, getReference_signature,     F_RN)  \\\n-  do_intrinsic(_getBoolean,         jdk_internal_misc_Unsafe,     getBoolean_name, getBoolean_signature,         F_RN)  \\\n-  do_intrinsic(_getByte,            jdk_internal_misc_Unsafe,     getByte_name, getByte_signature,               F_RN)  \\\n-  do_intrinsic(_getShort,           jdk_internal_misc_Unsafe,     getShort_name, getShort_signature,             F_RN)  \\\n-  do_intrinsic(_getChar,            jdk_internal_misc_Unsafe,     getChar_name, getChar_signature,               F_RN)  \\\n-  do_intrinsic(_getInt,             jdk_internal_misc_Unsafe,     getInt_name, getInt_signature,                 F_RN)  \\\n-  do_intrinsic(_getLong,            jdk_internal_misc_Unsafe,     getLong_name, getLong_signature,               F_RN)  \\\n-  do_intrinsic(_getFloat,           jdk_internal_misc_Unsafe,     getFloat_name, getFloat_signature,             F_RN)  \\\n-  do_intrinsic(_getDouble,          jdk_internal_misc_Unsafe,     getDouble_name, getDouble_signature,           F_RN)  \\\n-  do_intrinsic(_putReference,       jdk_internal_misc_Unsafe,     putReference_name, putReference_signature,     F_RN)  \\\n-  do_intrinsic(_putBoolean,         jdk_internal_misc_Unsafe,     putBoolean_name, putBoolean_signature,         F_RN)  \\\n-  do_intrinsic(_putByte,            jdk_internal_misc_Unsafe,     putByte_name, putByte_signature,               F_RN)  \\\n-  do_intrinsic(_putShort,           jdk_internal_misc_Unsafe,     putShort_name, putShort_signature,             F_RN)  \\\n-  do_intrinsic(_putChar,            jdk_internal_misc_Unsafe,     putChar_name, putChar_signature,               F_RN)  \\\n-  do_intrinsic(_putInt,             jdk_internal_misc_Unsafe,     putInt_name, putInt_signature,                 F_RN)  \\\n-  do_intrinsic(_putLong,            jdk_internal_misc_Unsafe,     putLong_name, putLong_signature,               F_RN)  \\\n-  do_intrinsic(_putFloat,           jdk_internal_misc_Unsafe,     putFloat_name, putFloat_signature,             F_RN)  \\\n-  do_intrinsic(_putDouble,          jdk_internal_misc_Unsafe,     putDouble_name, putDouble_signature,           F_RN)  \\\n-                                                                                                                        \\\n-  do_name(getReferenceVolatile_name,\"getReferenceVolatile\")   do_name(putReferenceVolatile_name,\"putReferenceVolatile\") \\\n-  do_name(getBooleanVolatile_name,\"getBooleanVolatile\")       do_name(putBooleanVolatile_name,\"putBooleanVolatile\")     \\\n-  do_name(getByteVolatile_name,\"getByteVolatile\")             do_name(putByteVolatile_name,\"putByteVolatile\")           \\\n-  do_name(getShortVolatile_name,\"getShortVolatile\")           do_name(putShortVolatile_name,\"putShortVolatile\")         \\\n-  do_name(getCharVolatile_name,\"getCharVolatile\")             do_name(putCharVolatile_name,\"putCharVolatile\")           \\\n-  do_name(getIntVolatile_name,\"getIntVolatile\")               do_name(putIntVolatile_name,\"putIntVolatile\")             \\\n-  do_name(getLongVolatile_name,\"getLongVolatile\")             do_name(putLongVolatile_name,\"putLongVolatile\")           \\\n-  do_name(getFloatVolatile_name,\"getFloatVolatile\")           do_name(putFloatVolatile_name,\"putFloatVolatile\")         \\\n-  do_name(getDoubleVolatile_name,\"getDoubleVolatile\")         do_name(putDoubleVolatile_name,\"putDoubleVolatile\")       \\\n-                                                                                                                        \\\n-  do_intrinsic(_getReferenceVolatile,     jdk_internal_misc_Unsafe,     getReferenceVolatile_name, getReference_signature, F_RN)  \\\n-  do_intrinsic(_getBooleanVolatile,       jdk_internal_misc_Unsafe,     getBooleanVolatile_name, getBoolean_signature,     F_RN)  \\\n-  do_intrinsic(_getByteVolatile,          jdk_internal_misc_Unsafe,     getByteVolatile_name, getByte_signature,           F_RN)  \\\n-  do_intrinsic(_getShortVolatile,         jdk_internal_misc_Unsafe,     getShortVolatile_name, getShort_signature,         F_RN)  \\\n-  do_intrinsic(_getCharVolatile,          jdk_internal_misc_Unsafe,     getCharVolatile_name, getChar_signature,           F_RN)  \\\n-  do_intrinsic(_getIntVolatile,           jdk_internal_misc_Unsafe,     getIntVolatile_name, getInt_signature,             F_RN)  \\\n-  do_intrinsic(_getLongVolatile,          jdk_internal_misc_Unsafe,     getLongVolatile_name, getLong_signature,           F_RN)  \\\n-  do_intrinsic(_getFloatVolatile,         jdk_internal_misc_Unsafe,     getFloatVolatile_name, getFloat_signature,         F_RN)  \\\n-  do_intrinsic(_getDoubleVolatile,        jdk_internal_misc_Unsafe,     getDoubleVolatile_name, getDouble_signature,       F_RN)  \\\n-  do_intrinsic(_putReferenceVolatile,     jdk_internal_misc_Unsafe,     putReferenceVolatile_name, putReference_signature, F_RN)  \\\n-  do_intrinsic(_putBooleanVolatile,       jdk_internal_misc_Unsafe,     putBooleanVolatile_name, putBoolean_signature,     F_RN)  \\\n-  do_intrinsic(_putByteVolatile,          jdk_internal_misc_Unsafe,     putByteVolatile_name, putByte_signature,           F_RN)  \\\n-  do_intrinsic(_putShortVolatile,         jdk_internal_misc_Unsafe,     putShortVolatile_name, putShort_signature,         F_RN)  \\\n-  do_intrinsic(_putCharVolatile,          jdk_internal_misc_Unsafe,     putCharVolatile_name, putChar_signature,           F_RN)  \\\n-  do_intrinsic(_putIntVolatile,           jdk_internal_misc_Unsafe,     putIntVolatile_name, putInt_signature,             F_RN)  \\\n-  do_intrinsic(_putLongVolatile,          jdk_internal_misc_Unsafe,     putLongVolatile_name, putLong_signature,           F_RN)  \\\n-  do_intrinsic(_putFloatVolatile,         jdk_internal_misc_Unsafe,     putFloatVolatile_name, putFloat_signature,         F_RN)  \\\n-  do_intrinsic(_putDoubleVolatile,        jdk_internal_misc_Unsafe,     putDoubleVolatile_name, putDouble_signature,       F_RN)  \\\n-                                                                                                                        \\\n-  do_name(getReferenceOpaque_name,\"getReferenceOpaque\") do_name(putReferenceOpaque_name,\"putReferenceOpaque\")           \\\n-  do_name(getBooleanOpaque_name,\"getBooleanOpaque\")     do_name(putBooleanOpaque_name,\"putBooleanOpaque\")               \\\n-  do_name(getByteOpaque_name,\"getByteOpaque\")           do_name(putByteOpaque_name,\"putByteOpaque\")                     \\\n-  do_name(getShortOpaque_name,\"getShortOpaque\")         do_name(putShortOpaque_name,\"putShortOpaque\")                   \\\n-  do_name(getCharOpaque_name,\"getCharOpaque\")           do_name(putCharOpaque_name,\"putCharOpaque\")                     \\\n-  do_name(getIntOpaque_name,\"getIntOpaque\")             do_name(putIntOpaque_name,\"putIntOpaque\")                       \\\n-  do_name(getLongOpaque_name,\"getLongOpaque\")           do_name(putLongOpaque_name,\"putLongOpaque\")                     \\\n-  do_name(getFloatOpaque_name,\"getFloatOpaque\")         do_name(putFloatOpaque_name,\"putFloatOpaque\")                   \\\n-  do_name(getDoubleOpaque_name,\"getDoubleOpaque\")       do_name(putDoubleOpaque_name,\"putDoubleOpaque\")                 \\\n-                                                                                                                        \\\n-  do_intrinsic(_getReferenceOpaque,       jdk_internal_misc_Unsafe,        getReferenceOpaque_name, getReference_signature, F_R)  \\\n-  do_intrinsic(_getBooleanOpaque,         jdk_internal_misc_Unsafe,        getBooleanOpaque_name, getBoolean_signature,     F_R)  \\\n-  do_intrinsic(_getByteOpaque,            jdk_internal_misc_Unsafe,        getByteOpaque_name, getByte_signature,           F_R)  \\\n-  do_intrinsic(_getShortOpaque,           jdk_internal_misc_Unsafe,        getShortOpaque_name, getShort_signature,         F_R)  \\\n-  do_intrinsic(_getCharOpaque,            jdk_internal_misc_Unsafe,        getCharOpaque_name, getChar_signature,           F_R)  \\\n-  do_intrinsic(_getIntOpaque,             jdk_internal_misc_Unsafe,        getIntOpaque_name, getInt_signature,             F_R)  \\\n-  do_intrinsic(_getLongOpaque,            jdk_internal_misc_Unsafe,        getLongOpaque_name, getLong_signature,           F_R)  \\\n-  do_intrinsic(_getFloatOpaque,           jdk_internal_misc_Unsafe,        getFloatOpaque_name, getFloat_signature,         F_R)  \\\n-  do_intrinsic(_getDoubleOpaque,          jdk_internal_misc_Unsafe,        getDoubleOpaque_name, getDouble_signature,       F_R)  \\\n-  do_intrinsic(_putReferenceOpaque,       jdk_internal_misc_Unsafe,        putReferenceOpaque_name, putReference_signature, F_R)  \\\n-  do_intrinsic(_putBooleanOpaque,         jdk_internal_misc_Unsafe,        putBooleanOpaque_name, putBoolean_signature,     F_R)  \\\n-  do_intrinsic(_putByteOpaque,            jdk_internal_misc_Unsafe,        putByteOpaque_name, putByte_signature,           F_R)  \\\n-  do_intrinsic(_putShortOpaque,           jdk_internal_misc_Unsafe,        putShortOpaque_name, putShort_signature,         F_R)  \\\n-  do_intrinsic(_putCharOpaque,            jdk_internal_misc_Unsafe,        putCharOpaque_name, putChar_signature,           F_R)  \\\n-  do_intrinsic(_putIntOpaque,             jdk_internal_misc_Unsafe,        putIntOpaque_name, putInt_signature,             F_R)  \\\n-  do_intrinsic(_putLongOpaque,            jdk_internal_misc_Unsafe,        putLongOpaque_name, putLong_signature,           F_R)  \\\n-  do_intrinsic(_putFloatOpaque,           jdk_internal_misc_Unsafe,        putFloatOpaque_name, putFloat_signature,         F_R)  \\\n-  do_intrinsic(_putDoubleOpaque,          jdk_internal_misc_Unsafe,        putDoubleOpaque_name, putDouble_signature,       F_R)  \\\n-                                                                                                                        \\\n-  do_name(getReferenceAcquire_name,  \"getReferenceAcquire\") do_name(putReferenceRelease_name,  \"putReferenceRelease\")   \\\n-  do_name(getBooleanAcquire_name, \"getBooleanAcquire\")      do_name(putBooleanRelease_name, \"putBooleanRelease\")        \\\n-  do_name(getByteAcquire_name,    \"getByteAcquire\")         do_name(putByteRelease_name,    \"putByteRelease\")           \\\n-  do_name(getShortAcquire_name,   \"getShortAcquire\")        do_name(putShortRelease_name,   \"putShortRelease\")          \\\n-  do_name(getCharAcquire_name,    \"getCharAcquire\")         do_name(putCharRelease_name,    \"putCharRelease\")           \\\n-  do_name(getIntAcquire_name,     \"getIntAcquire\")          do_name(putIntRelease_name,     \"putIntRelease\")            \\\n-  do_name(getLongAcquire_name,    \"getLongAcquire\")         do_name(putLongRelease_name,    \"putLongRelease\")           \\\n-  do_name(getFloatAcquire_name,   \"getFloatAcquire\")        do_name(putFloatRelease_name,   \"putFloatRelease\")          \\\n-  do_name(getDoubleAcquire_name,  \"getDoubleAcquire\")       do_name(putDoubleRelease_name,  \"putDoubleRelease\")         \\\n-                                                                                                                        \\\n-  do_intrinsic(_getReferenceAcquire,     jdk_internal_misc_Unsafe,        getReferenceAcquire_name, getReference_signature, F_R)  \\\n-  do_intrinsic(_getBooleanAcquire,       jdk_internal_misc_Unsafe,        getBooleanAcquire_name, getBoolean_signature,     F_R)  \\\n-  do_intrinsic(_getByteAcquire,          jdk_internal_misc_Unsafe,        getByteAcquire_name, getByte_signature,           F_R)  \\\n-  do_intrinsic(_getShortAcquire,         jdk_internal_misc_Unsafe,        getShortAcquire_name, getShort_signature,         F_R)  \\\n-  do_intrinsic(_getCharAcquire,          jdk_internal_misc_Unsafe,        getCharAcquire_name, getChar_signature,           F_R)  \\\n-  do_intrinsic(_getIntAcquire,           jdk_internal_misc_Unsafe,        getIntAcquire_name, getInt_signature,             F_R)  \\\n-  do_intrinsic(_getLongAcquire,          jdk_internal_misc_Unsafe,        getLongAcquire_name, getLong_signature,           F_R)  \\\n-  do_intrinsic(_getFloatAcquire,         jdk_internal_misc_Unsafe,        getFloatAcquire_name, getFloat_signature,         F_R)  \\\n-  do_intrinsic(_getDoubleAcquire,        jdk_internal_misc_Unsafe,        getDoubleAcquire_name, getDouble_signature,       F_R)  \\\n-  do_intrinsic(_putReferenceRelease,     jdk_internal_misc_Unsafe,        putReferenceRelease_name, putReference_signature, F_R)  \\\n-  do_intrinsic(_putBooleanRelease,       jdk_internal_misc_Unsafe,        putBooleanRelease_name, putBoolean_signature,     F_R)  \\\n-  do_intrinsic(_putByteRelease,          jdk_internal_misc_Unsafe,        putByteRelease_name, putByte_signature,           F_R)  \\\n-  do_intrinsic(_putShortRelease,         jdk_internal_misc_Unsafe,        putShortRelease_name, putShort_signature,         F_R)  \\\n-  do_intrinsic(_putCharRelease,          jdk_internal_misc_Unsafe,        putCharRelease_name, putChar_signature,           F_R)  \\\n-  do_intrinsic(_putIntRelease,           jdk_internal_misc_Unsafe,        putIntRelease_name, putInt_signature,             F_R)  \\\n-  do_intrinsic(_putLongRelease,          jdk_internal_misc_Unsafe,        putLongRelease_name, putLong_signature,           F_R)  \\\n-  do_intrinsic(_putFloatRelease,         jdk_internal_misc_Unsafe,        putFloatRelease_name, putFloat_signature,         F_R)  \\\n-  do_intrinsic(_putDoubleRelease,        jdk_internal_misc_Unsafe,        putDoubleRelease_name, putDouble_signature,       F_R)  \\\n-                                                                                                                        \\\n-  do_name(getShortUnaligned_name,\"getShortUnaligned\")     do_name(putShortUnaligned_name,\"putShortUnaligned\")           \\\n-  do_name(getCharUnaligned_name,\"getCharUnaligned\")       do_name(putCharUnaligned_name,\"putCharUnaligned\")             \\\n-  do_name(getIntUnaligned_name,\"getIntUnaligned\")         do_name(putIntUnaligned_name,\"putIntUnaligned\")               \\\n-  do_name(getLongUnaligned_name,\"getLongUnaligned\")       do_name(putLongUnaligned_name,\"putLongUnaligned\")             \\\n-                                                                                                                        \\\n-  do_intrinsic(_getShortUnaligned,         jdk_internal_misc_Unsafe,    getShortUnaligned_name, getShort_signature,     F_R)  \\\n-  do_intrinsic(_getCharUnaligned,          jdk_internal_misc_Unsafe,    getCharUnaligned_name, getChar_signature,       F_R)  \\\n-  do_intrinsic(_getIntUnaligned,           jdk_internal_misc_Unsafe,    getIntUnaligned_name, getInt_signature,         F_R)  \\\n-  do_intrinsic(_getLongUnaligned,          jdk_internal_misc_Unsafe,    getLongUnaligned_name, getLong_signature,       F_R)  \\\n-  do_intrinsic(_putShortUnaligned,         jdk_internal_misc_Unsafe,    putShortUnaligned_name, putShort_signature,     F_R)  \\\n-  do_intrinsic(_putCharUnaligned,          jdk_internal_misc_Unsafe,    putCharUnaligned_name, putChar_signature,       F_R)  \\\n-  do_intrinsic(_putIntUnaligned,           jdk_internal_misc_Unsafe,    putIntUnaligned_name, putInt_signature,         F_R)  \\\n-  do_intrinsic(_putLongUnaligned,          jdk_internal_misc_Unsafe,    putLongUnaligned_name, putLong_signature,       F_R)  \\\n-                                                                                                                        \\\n-  do_signature(compareAndSetReference_signature,      \"(Ljava\/lang\/Object;JLjava\/lang\/Object;Ljava\/lang\/Object;)Z\")        \\\n-  do_signature(compareAndExchangeReference_signature, \"(Ljava\/lang\/Object;JLjava\/lang\/Object;Ljava\/lang\/Object;)Ljava\/lang\/Object;\") \\\n-  do_signature(compareAndSetLong_signature,        \"(Ljava\/lang\/Object;JJJ)Z\")                                          \\\n-  do_signature(compareAndExchangeLong_signature,   \"(Ljava\/lang\/Object;JJJ)J\")                                          \\\n-  do_signature(compareAndSetInt_signature,         \"(Ljava\/lang\/Object;JII)Z\")                                          \\\n-  do_signature(compareAndExchangeInt_signature,    \"(Ljava\/lang\/Object;JII)I\")                                          \\\n-  do_signature(compareAndSetByte_signature,        \"(Ljava\/lang\/Object;JBB)Z\")                                          \\\n-  do_signature(compareAndExchangeByte_signature,   \"(Ljava\/lang\/Object;JBB)B\")                                          \\\n-  do_signature(compareAndSetShort_signature,       \"(Ljava\/lang\/Object;JSS)Z\")                                          \\\n-  do_signature(compareAndExchangeShort_signature,  \"(Ljava\/lang\/Object;JSS)S\")                                          \\\n-                                                                                                                        \\\n-  do_name(compareAndSetReference_name,              \"compareAndSetReference\")                                           \\\n-  do_name(compareAndExchangeReference_name,         \"compareAndExchangeReference\")                                      \\\n-  do_name(compareAndExchangeReferenceAcquire_name,  \"compareAndExchangeReferenceAcquire\")                               \\\n-  do_name(compareAndExchangeReferenceRelease_name,  \"compareAndExchangeReferenceRelease\")                               \\\n-  do_name(compareAndSetLong_name,                   \"compareAndSetLong\")                                                \\\n-  do_name(compareAndExchangeLong_name,              \"compareAndExchangeLong\")                                           \\\n-  do_name(compareAndExchangeLongAcquire_name,       \"compareAndExchangeLongAcquire\")                                    \\\n-  do_name(compareAndExchangeLongRelease_name,       \"compareAndExchangeLongRelease\")                                    \\\n-  do_name(compareAndSetInt_name,                    \"compareAndSetInt\")                                                 \\\n-  do_name(compareAndExchangeInt_name,               \"compareAndExchangeInt\")                                            \\\n-  do_name(compareAndExchangeIntAcquire_name,        \"compareAndExchangeIntAcquire\")                                     \\\n-  do_name(compareAndExchangeIntRelease_name,        \"compareAndExchangeIntRelease\")                                     \\\n-  do_name(compareAndSetByte_name,                   \"compareAndSetByte\")                                                \\\n-  do_name(compareAndExchangeByte_name,              \"compareAndExchangeByte\")                                           \\\n-  do_name(compareAndExchangeByteAcquire_name,       \"compareAndExchangeByteAcquire\")                                    \\\n-  do_name(compareAndExchangeByteRelease_name,       \"compareAndExchangeByteRelease\")                                    \\\n-  do_name(compareAndSetShort_name,                  \"compareAndSetShort\")                                               \\\n-  do_name(compareAndExchangeShort_name,             \"compareAndExchangeShort\")                                          \\\n-  do_name(compareAndExchangeShortAcquire_name,      \"compareAndExchangeShortAcquire\")                                   \\\n-  do_name(compareAndExchangeShortRelease_name,      \"compareAndExchangeShortRelease\")                                   \\\n-                                                                                                                        \\\n-  do_name(weakCompareAndSetReferencePlain_name,     \"weakCompareAndSetReferencePlain\")                                  \\\n-  do_name(weakCompareAndSetReferenceAcquire_name,   \"weakCompareAndSetReferenceAcquire\")                                \\\n-  do_name(weakCompareAndSetReferenceRelease_name,   \"weakCompareAndSetReferenceRelease\")                                \\\n-  do_name(weakCompareAndSetReference_name,          \"weakCompareAndSetReference\")                                       \\\n-  do_name(weakCompareAndSetLongPlain_name,          \"weakCompareAndSetLongPlain\")                                       \\\n-  do_name(weakCompareAndSetLongAcquire_name,        \"weakCompareAndSetLongAcquire\")                                     \\\n-  do_name(weakCompareAndSetLongRelease_name,        \"weakCompareAndSetLongRelease\")                                     \\\n-  do_name(weakCompareAndSetLong_name,               \"weakCompareAndSetLong\")                                            \\\n-  do_name(weakCompareAndSetIntPlain_name,           \"weakCompareAndSetIntPlain\")                                        \\\n-  do_name(weakCompareAndSetIntAcquire_name,         \"weakCompareAndSetIntAcquire\")                                      \\\n-  do_name(weakCompareAndSetIntRelease_name,         \"weakCompareAndSetIntRelease\")                                      \\\n-  do_name(weakCompareAndSetInt_name,                \"weakCompareAndSetInt\")                                             \\\n-  do_name(weakCompareAndSetBytePlain_name,          \"weakCompareAndSetBytePlain\")                                       \\\n-  do_name(weakCompareAndSetByteAcquire_name,        \"weakCompareAndSetByteAcquire\")                                     \\\n-  do_name(weakCompareAndSetByteRelease_name,        \"weakCompareAndSetByteRelease\")                                     \\\n-  do_name(weakCompareAndSetByte_name,               \"weakCompareAndSetByte\")                                            \\\n-  do_name(weakCompareAndSetShortPlain_name,         \"weakCompareAndSetShortPlain\")                                      \\\n-  do_name(weakCompareAndSetShortAcquire_name,       \"weakCompareAndSetShortAcquire\")                                    \\\n-  do_name(weakCompareAndSetShortRelease_name,       \"weakCompareAndSetShortRelease\")                                    \\\n-  do_name(weakCompareAndSetShort_name,              \"weakCompareAndSetShort\")                                           \\\n-                                                                                                                        \\\n-  do_intrinsic(_compareAndSetReference,              jdk_internal_misc_Unsafe,  compareAndSetReference_name,              compareAndSetReference_signature,      F_RN) \\\n-  do_intrinsic(_compareAndExchangeReference,         jdk_internal_misc_Unsafe,  compareAndExchangeReference_name,         compareAndExchangeReference_signature, F_RN) \\\n-  do_intrinsic(_compareAndExchangeReferenceAcquire,  jdk_internal_misc_Unsafe,  compareAndExchangeReferenceAcquire_name,  compareAndExchangeReference_signature, F_R)  \\\n-  do_intrinsic(_compareAndExchangeReferenceRelease,  jdk_internal_misc_Unsafe,  compareAndExchangeReferenceRelease_name,  compareAndExchangeReference_signature, F_R)  \\\n-  do_intrinsic(_compareAndSetLong,                jdk_internal_misc_Unsafe,  compareAndSetLong_name,                compareAndSetLong_signature,        F_RN) \\\n-  do_intrinsic(_compareAndExchangeLong,           jdk_internal_misc_Unsafe,  compareAndExchangeLong_name,           compareAndExchangeLong_signature,   F_RN) \\\n-  do_intrinsic(_compareAndExchangeLongAcquire,    jdk_internal_misc_Unsafe,  compareAndExchangeLongAcquire_name,    compareAndExchangeLong_signature,   F_R)  \\\n-  do_intrinsic(_compareAndExchangeLongRelease,    jdk_internal_misc_Unsafe,  compareAndExchangeLongRelease_name,    compareAndExchangeLong_signature,   F_R)  \\\n-  do_intrinsic(_compareAndSetInt,                 jdk_internal_misc_Unsafe,  compareAndSetInt_name,                 compareAndSetInt_signature,         F_RN) \\\n-  do_intrinsic(_compareAndExchangeInt,            jdk_internal_misc_Unsafe,  compareAndExchangeInt_name,            compareAndExchangeInt_signature,    F_RN) \\\n-  do_intrinsic(_compareAndExchangeIntAcquire,     jdk_internal_misc_Unsafe,  compareAndExchangeIntAcquire_name,     compareAndExchangeInt_signature,    F_R)  \\\n-  do_intrinsic(_compareAndExchangeIntRelease,     jdk_internal_misc_Unsafe,  compareAndExchangeIntRelease_name,     compareAndExchangeInt_signature,    F_R)  \\\n-  do_intrinsic(_compareAndSetByte,                jdk_internal_misc_Unsafe,  compareAndSetByte_name,                compareAndSetByte_signature,        F_R)  \\\n-  do_intrinsic(_compareAndExchangeByte,           jdk_internal_misc_Unsafe,  compareAndExchangeByte_name,           compareAndExchangeByte_signature,   F_R)  \\\n-  do_intrinsic(_compareAndExchangeByteAcquire,    jdk_internal_misc_Unsafe,  compareAndExchangeByteAcquire_name,    compareAndExchangeByte_signature,   F_R)  \\\n-  do_intrinsic(_compareAndExchangeByteRelease,    jdk_internal_misc_Unsafe,  compareAndExchangeByteRelease_name,    compareAndExchangeByte_signature,   F_R)  \\\n-  do_intrinsic(_compareAndSetShort,               jdk_internal_misc_Unsafe,  compareAndSetShort_name,               compareAndSetShort_signature,       F_R)  \\\n-  do_intrinsic(_compareAndExchangeShort,          jdk_internal_misc_Unsafe,  compareAndExchangeShort_name,          compareAndExchangeShort_signature,  F_R)  \\\n-  do_intrinsic(_compareAndExchangeShortAcquire,   jdk_internal_misc_Unsafe,  compareAndExchangeShortAcquire_name,   compareAndExchangeShort_signature,  F_R)  \\\n-  do_intrinsic(_compareAndExchangeShortRelease,   jdk_internal_misc_Unsafe,  compareAndExchangeShortRelease_name,   compareAndExchangeShort_signature,  F_R)  \\\n-                                                                                                                                                             \\\n-  do_intrinsic(_weakCompareAndSetReferencePlain,  jdk_internal_misc_Unsafe,  weakCompareAndSetReferencePlain_name,     compareAndSetReference_signature,      F_R) \\\n-  do_intrinsic(_weakCompareAndSetReferenceAcquire,jdk_internal_misc_Unsafe,  weakCompareAndSetReferenceAcquire_name,   compareAndSetReference_signature,      F_R) \\\n-  do_intrinsic(_weakCompareAndSetReferenceRelease,jdk_internal_misc_Unsafe,  weakCompareAndSetReferenceRelease_name,   compareAndSetReference_signature,      F_R) \\\n-  do_intrinsic(_weakCompareAndSetReference,       jdk_internal_misc_Unsafe,  weakCompareAndSetReference_name,          compareAndSetReference_signature,      F_R) \\\n-  do_intrinsic(_weakCompareAndSetLongPlain,       jdk_internal_misc_Unsafe,  weakCompareAndSetLongPlain_name,       compareAndSetLong_signature,        F_R) \\\n-  do_intrinsic(_weakCompareAndSetLongAcquire,     jdk_internal_misc_Unsafe,  weakCompareAndSetLongAcquire_name,     compareAndSetLong_signature,        F_R) \\\n-  do_intrinsic(_weakCompareAndSetLongRelease,     jdk_internal_misc_Unsafe,  weakCompareAndSetLongRelease_name,     compareAndSetLong_signature,        F_R) \\\n-  do_intrinsic(_weakCompareAndSetLong,            jdk_internal_misc_Unsafe,  weakCompareAndSetLong_name,            compareAndSetLong_signature,        F_R) \\\n-  do_intrinsic(_weakCompareAndSetIntPlain,        jdk_internal_misc_Unsafe,  weakCompareAndSetIntPlain_name,        compareAndSetInt_signature,         F_R) \\\n-  do_intrinsic(_weakCompareAndSetIntAcquire,      jdk_internal_misc_Unsafe,  weakCompareAndSetIntAcquire_name,      compareAndSetInt_signature,         F_R) \\\n-  do_intrinsic(_weakCompareAndSetIntRelease,      jdk_internal_misc_Unsafe,  weakCompareAndSetIntRelease_name,      compareAndSetInt_signature,         F_R) \\\n-  do_intrinsic(_weakCompareAndSetInt,             jdk_internal_misc_Unsafe,  weakCompareAndSetInt_name,             compareAndSetInt_signature,         F_R) \\\n-  do_intrinsic(_weakCompareAndSetBytePlain,       jdk_internal_misc_Unsafe,  weakCompareAndSetBytePlain_name,       compareAndSetByte_signature,        F_R) \\\n-  do_intrinsic(_weakCompareAndSetByteAcquire,     jdk_internal_misc_Unsafe,  weakCompareAndSetByteAcquire_name,     compareAndSetByte_signature,        F_R) \\\n-  do_intrinsic(_weakCompareAndSetByteRelease,     jdk_internal_misc_Unsafe,  weakCompareAndSetByteRelease_name,     compareAndSetByte_signature,        F_R) \\\n-  do_intrinsic(_weakCompareAndSetByte,            jdk_internal_misc_Unsafe,  weakCompareAndSetByte_name,            compareAndSetByte_signature,        F_R) \\\n-  do_intrinsic(_weakCompareAndSetShortPlain,      jdk_internal_misc_Unsafe,  weakCompareAndSetShortPlain_name,      compareAndSetShort_signature,       F_R) \\\n-  do_intrinsic(_weakCompareAndSetShortAcquire,    jdk_internal_misc_Unsafe,  weakCompareAndSetShortAcquire_name,    compareAndSetShort_signature,       F_R) \\\n-  do_intrinsic(_weakCompareAndSetShortRelease,    jdk_internal_misc_Unsafe,  weakCompareAndSetShortRelease_name,    compareAndSetShort_signature,       F_R) \\\n-  do_intrinsic(_weakCompareAndSetShort,           jdk_internal_misc_Unsafe,  weakCompareAndSetShort_name,           compareAndSetShort_signature,       F_R) \\\n-                           \\\n-  do_intrinsic(_getAndAddInt,             jdk_internal_misc_Unsafe,     getAndAddInt_name, getAndAddInt_signature, F_R)       \\\n-   do_name(     getAndAddInt_name,                                      \"getAndAddInt\")                                       \\\n-   do_signature(getAndAddInt_signature,                                 \"(Ljava\/lang\/Object;JI)I\" )                           \\\n-  do_intrinsic(_getAndAddLong,            jdk_internal_misc_Unsafe,     getAndAddLong_name, getAndAddLong_signature, F_R)     \\\n-   do_name(     getAndAddLong_name,                                     \"getAndAddLong\")                                      \\\n-   do_signature(getAndAddLong_signature,                                \"(Ljava\/lang\/Object;JJ)J\" )                           \\\n-  do_intrinsic(_getAndAddByte,            jdk_internal_misc_Unsafe,     getAndAddByte_name, getAndAddByte_signature, F_R)     \\\n-   do_name(     getAndAddByte_name,                                     \"getAndAddByte\")                                      \\\n-   do_signature(getAndAddByte_signature,                                \"(Ljava\/lang\/Object;JB)B\" )                           \\\n-  do_intrinsic(_getAndAddShort,           jdk_internal_misc_Unsafe,     getAndAddShort_name, getAndAddShort_signature, F_R)   \\\n-   do_name(     getAndAddShort_name,                                    \"getAndAddShort\")                                     \\\n-   do_signature(getAndAddShort_signature,                               \"(Ljava\/lang\/Object;JS)S\" )                           \\\n-  do_intrinsic(_getAndSetInt,             jdk_internal_misc_Unsafe,     getAndSetInt_name, getAndSetInt_signature, F_R)       \\\n-   do_name(     getAndSetInt_name,                                      \"getAndSetInt\")                                       \\\n-   do_alias(    getAndSetInt_signature,                                 \/*\"(Ljava\/lang\/Object;JI)I\"*\/ getAndAddInt_signature)   \\\n-  do_intrinsic(_getAndSetLong,            jdk_internal_misc_Unsafe,     getAndSetLong_name, getAndSetLong_signature, F_R)     \\\n-   do_name(     getAndSetLong_name,                                     \"getAndSetLong\")                                      \\\n-   do_alias(    getAndSetLong_signature,                                \/*\"(Ljava\/lang\/Object;JJ)J\"*\/ getAndAddLong_signature)  \\\n-  do_intrinsic(_getAndSetByte,            jdk_internal_misc_Unsafe,     getAndSetByte_name, getAndSetByte_signature, F_R)     \\\n-   do_name(     getAndSetByte_name,                                     \"getAndSetByte\")                                      \\\n-   do_alias(    getAndSetByte_signature,                                \/*\"(Ljava\/lang\/Object;JB)B\"*\/ getAndAddByte_signature)  \\\n-  do_intrinsic(_getAndSetShort,           jdk_internal_misc_Unsafe,     getAndSetShort_name, getAndSetShort_signature, F_R)   \\\n-   do_name(     getAndSetShort_name,                                    \"getAndSetShort\")                                     \\\n-   do_alias(    getAndSetShort_signature,                               \/*\"(Ljava\/lang\/Object;JS)S\"*\/ getAndAddShort_signature) \\\n-  do_intrinsic(_getAndSetReference,       jdk_internal_misc_Unsafe,     getAndSetReference_name, getAndSetReference_signature, F_R) \\\n-   do_name(     getAndSetReference_name,                                \"getAndSetReference\")                                  \\\n-   do_signature(getAndSetReference_signature,                           \"(Ljava\/lang\/Object;JLjava\/lang\/Object;)Ljava\/lang\/Object;\" ) \\\n-                                                                                                                               \\\n-   \/* (2) Bytecode intrinsics                                                                        *\/                        \\\n-                                                                                                                               \\\n-  do_intrinsic(_park,                     jdk_internal_misc_Unsafe,     park_name, park_signature,                     F_R)    \\\n-   do_name(     park_name,                                              \"park\")                                                \\\n-   do_signature(park_signature,                                         \"(ZJ)V\")                                               \\\n-  do_intrinsic(_unpark,                   jdk_internal_misc_Unsafe,     unpark_name, unpark_signature,                 F_R)    \\\n-   do_name(     unpark_name,                                            \"unpark\")                                              \\\n-   do_alias(    unpark_signature,                                       \/*(LObject;)V*\/ object_void_signature)                 \\\n-                                                                                                                               \\\n-  do_intrinsic(_StringBuilder_void,   java_lang_StringBuilder, object_initializer_name, void_method_signature,     F_R)   \\\n-  do_intrinsic(_StringBuilder_int,    java_lang_StringBuilder, object_initializer_name, int_void_signature,        F_R)   \\\n-  do_intrinsic(_StringBuilder_String, java_lang_StringBuilder, object_initializer_name, string_void_signature,     F_R)   \\\n-                                                                                                                          \\\n-  do_intrinsic(_StringBuilder_append_char,   java_lang_StringBuilder, append_name, char_StringBuilder_signature,   F_R)   \\\n-  do_intrinsic(_StringBuilder_append_int,    java_lang_StringBuilder, append_name, int_StringBuilder_signature,    F_R)   \\\n-  do_intrinsic(_StringBuilder_append_String, java_lang_StringBuilder, append_name, String_StringBuilder_signature, F_R)   \\\n-                                                                                                                          \\\n-  do_intrinsic(_StringBuilder_toString, java_lang_StringBuilder, toString_name, void_string_signature,             F_R)   \\\n-                                                                                                                          \\\n-  do_intrinsic(_StringBuffer_void,   java_lang_StringBuffer, object_initializer_name, void_method_signature,       F_R)   \\\n-  do_intrinsic(_StringBuffer_int,    java_lang_StringBuffer, object_initializer_name, int_void_signature,          F_R)   \\\n-  do_intrinsic(_StringBuffer_String, java_lang_StringBuffer, object_initializer_name, string_void_signature,       F_R)   \\\n-                                                                                                                          \\\n-  do_intrinsic(_StringBuffer_append_char,   java_lang_StringBuffer, append_name, char_StringBuffer_signature,      F_Y)   \\\n-  do_intrinsic(_StringBuffer_append_int,    java_lang_StringBuffer, append_name, int_StringBuffer_signature,       F_Y)   \\\n-  do_intrinsic(_StringBuffer_append_String, java_lang_StringBuffer, append_name, String_StringBuffer_signature,    F_Y)   \\\n-                                                                                                                          \\\n-  do_intrinsic(_StringBuffer_toString,  java_lang_StringBuffer, toString_name, void_string_signature,              F_Y)   \\\n-                                                                                                                          \\\n-  do_intrinsic(_Integer_toString,      java_lang_Integer, toString_name, int_String_signature,                     F_S)   \\\n-                                                                                                                          \\\n-  do_intrinsic(_String_String, java_lang_String, object_initializer_name, string_void_signature,                   F_R)   \\\n-                                                                                                                          \\\n-  do_intrinsic(_Object_init,              java_lang_Object, object_initializer_name, void_method_signature,        F_R)   \\\n-  \/*    (symbol object_initializer_name defined above) *\/                                                                 \\\n-                                                                                                                          \\\n-  do_intrinsic(_invoke,                   java_lang_reflect_Method, invoke_name, object_object_array_object_signature, F_R) \\\n-  \/*   (symbols invoke_name and invoke_signature defined above) *\/                                                      \\\n-  \/* the polymorphic MH intrinsics must be in compact order, with _invokeGeneric first and _linkToInterface last *\/     \\\n-  do_intrinsic(_invokeGeneric,            java_lang_invoke_MethodHandle, invoke_name,           star_name, F_RN)        \\\n-  do_intrinsic(_invokeBasic,              java_lang_invoke_MethodHandle, invokeBasic_name,      star_name, F_RN)        \\\n-  do_intrinsic(_linkToVirtual,            java_lang_invoke_MethodHandle, linkToVirtual_name,    star_name, F_SN)        \\\n-  do_intrinsic(_linkToStatic,             java_lang_invoke_MethodHandle, linkToStatic_name,     star_name, F_SN)        \\\n-  do_intrinsic(_linkToSpecial,            java_lang_invoke_MethodHandle, linkToSpecial_name,    star_name, F_SN)        \\\n-  do_intrinsic(_linkToInterface,          java_lang_invoke_MethodHandle, linkToInterface_name,  star_name, F_SN)        \\\n-  \/* special marker for bytecode generated for the JVM from a LambdaForm: *\/                                            \\\n-  do_intrinsic(_compiledLambdaForm,       java_lang_invoke_MethodHandle, compiledLambdaForm_name, star_name, F_RN)      \\\n-                                                                                                                        \\\n-  \/* unboxing methods: *\/                                                                                               \\\n-  do_intrinsic(_booleanValue,             java_lang_Boolean,      booleanValue_name, void_boolean_signature, F_R)       \\\n-   do_name(     booleanValue_name,       \"booleanValue\")                                                                \\\n-  do_intrinsic(_byteValue,                java_lang_Byte,         byteValue_name, void_byte_signature, F_R)             \\\n-   do_name(     byteValue_name,          \"byteValue\")                                                                   \\\n-  do_intrinsic(_charValue,                java_lang_Character,    charValue_name, void_char_signature, F_R)             \\\n-   do_name(     charValue_name,          \"charValue\")                                                                   \\\n-  do_intrinsic(_shortValue,               java_lang_Short,        shortValue_name, void_short_signature, F_R)           \\\n-   do_name(     shortValue_name,         \"shortValue\")                                                                  \\\n-  do_intrinsic(_intValue,                 java_lang_Integer,      intValue_name, void_int_signature, F_R)               \\\n-   do_name(     intValue_name,           \"intValue\")                                                                    \\\n-  do_intrinsic(_longValue,                java_lang_Long,         longValue_name, void_long_signature, F_R)             \\\n-   do_name(     longValue_name,          \"longValue\")                                                                   \\\n-  do_intrinsic(_floatValue,               java_lang_Float,        floatValue_name, void_float_signature, F_R)           \\\n-   do_name(     floatValue_name,         \"floatValue\")                                                                  \\\n-  do_intrinsic(_doubleValue,              java_lang_Double,       doubleValue_name, void_double_signature, F_R)         \\\n-   do_name(     doubleValue_name,        \"doubleValue\")                                                                 \\\n-                                                                                                                        \\\n-  \/* boxing methods: *\/                                                                                                 \\\n-   do_name(    valueOf_name,              \"valueOf\")                                                                    \\\n-  do_intrinsic(_Boolean_valueOf,          java_lang_Boolean,      valueOf_name, Boolean_valueOf_signature, F_S)         \\\n-   do_name(     Boolean_valueOf_signature,                       \"(Z)Ljava\/lang\/Boolean;\")                              \\\n-  do_intrinsic(_Byte_valueOf,             java_lang_Byte,         valueOf_name, Byte_valueOf_signature, F_S)            \\\n-   do_name(     Byte_valueOf_signature,                          \"(B)Ljava\/lang\/Byte;\")                                 \\\n-  do_intrinsic(_Character_valueOf,        java_lang_Character,    valueOf_name, Character_valueOf_signature, F_S)       \\\n-   do_name(     Character_valueOf_signature,                     \"(C)Ljava\/lang\/Character;\")                            \\\n-  do_intrinsic(_Short_valueOf,            java_lang_Short,        valueOf_name, Short_valueOf_signature, F_S)           \\\n-   do_name(     Short_valueOf_signature,                         \"(S)Ljava\/lang\/Short;\")                                \\\n-  do_intrinsic(_Integer_valueOf,          java_lang_Integer,      valueOf_name, Integer_valueOf_signature, F_S)         \\\n-   do_name(     Integer_valueOf_signature,                       \"(I)Ljava\/lang\/Integer;\")                              \\\n-  do_intrinsic(_Long_valueOf,             java_lang_Long,         valueOf_name, Long_valueOf_signature, F_S)            \\\n-   do_name(     Long_valueOf_signature,                          \"(J)Ljava\/lang\/Long;\")                                 \\\n-  do_intrinsic(_Float_valueOf,            java_lang_Float,        valueOf_name, Float_valueOf_signature, F_S)           \\\n-   do_name(     Float_valueOf_signature,                         \"(F)Ljava\/lang\/Float;\")                                \\\n-  do_intrinsic(_Double_valueOf,           java_lang_Double,       valueOf_name, Double_valueOf_signature, F_S)          \\\n-   do_name(     Double_valueOf_signature,                        \"(D)Ljava\/lang\/Double;\")                               \\\n-                                                                                                                        \\\n-  \/* forEachRemaining *\/                                                                             \\\n-  do_intrinsic(_forEachRemaining, java_util_stream_StreamsRangeIntSpliterator, forEachRemaining_name, forEachRemaining_signature, F_R) \\\n-   do_name(     forEachRemaining_name,    \"forEachRemaining\")                                                           \\\n-   do_name(     forEachRemaining_signature,                      \"(Ljava\/util\/function\/IntConsumer;)V\")                 \\\n+\/\/ enum for figuring positions and size of Symbol::_vm_symbols[]\n+enum class vmSymbolID : int {\n+  \/\/ [FIRST_SID ... LAST_SID] is the iteration range for the *valid* symbols.\n+  \/\/ NO_SID is used to indicate an invalid symbol. Some implementation code\n+  \/\/ *may* read _vm_symbols[NO_SID], so it must be a valid array index.\n+  NO_SID = 0,                \/\/ exclusive lower limit\n@@ -1513,1 +718,3 @@\n-    \/*end*\/\n+  #define VM_SYMBOL_ENUM(name, string) VM_SYMBOL_ENUM_NAME_(name),\n+  VM_SYMBOLS_DO(VM_SYMBOL_ENUM, VM_ALIAS_IGNORE)\n+  #undef VM_SYMBOL_ENUM\n@@ -1515,0 +722,1 @@\n+  SID_LIMIT,                 \/\/ exclusive upper limit\n@@ -1516,0 +724,3 @@\n+  #define VM_ALIAS_ENUM(name, def) VM_SYMBOL_ENUM_NAME_(name) = VM_SYMBOL_ENUM_NAME_(def),\n+  VM_SYMBOLS_DO(VM_SYMBOL_IGNORE, VM_ALIAS_ENUM)\n+  #undef VM_ALIAS_ENUM\n@@ -1517,0 +728,3 @@\n+  FIRST_SID = NO_SID + 1,    \/\/ inclusive lower limit\n+  LAST_SID = SID_LIMIT - 1,  \/\/ inclusive upper limit\n+};\n@@ -1518,1 +732,1 @@\n-\/\/ Class vmSymbols\n+ENUMERATOR_RANGE(vmSymbolID, vmSymbolID::FIRST_SID, vmSymbolID::LAST_SID)\n@@ -1524,0 +738,6 @@\n+\n+  static const int NO_SID    = static_cast<int>(vmSymbolID::NO_SID);    \/\/ exclusive lower limit\n+  static const int FIRST_SID = static_cast<int>(vmSymbolID::FIRST_SID); \/\/ inclusive lower limit\n+  static const int LAST_SID  = static_cast<int>(vmSymbolID::FIRST_SID); \/\/ inclusive upper limit\n+  static const int SID_LIMIT = static_cast<int>(vmSymbolID::SID_LIMIT); \/\/ exclusive upper limit\n+\n@@ -1525,3 +745,6 @@\n-  \/\/ enum for figuring positions and size of array holding Symbol*s\n-  enum SID {\n-    NO_SID = 0,\n+  static constexpr bool is_valid_id(int id) {\n+    return (id >= FIRST_SID && id < SID_LIMIT);\n+  }\n+  static constexpr bool is_valid_id(vmSymbolID sid) {\n+    return is_valid_id(static_cast<int>(sid));\n+  }\n@@ -1529,3 +752,4 @@\n-    #define VM_SYMBOL_ENUM(name, string) VM_SYMBOL_ENUM_NAME(name),\n-    VM_SYMBOLS_DO(VM_SYMBOL_ENUM, VM_ALIAS_IGNORE)\n-    #undef VM_SYMBOL_ENUM\n+  static constexpr vmSymbolID as_SID(int id) {\n+    assert(is_valid_id(id), \"must be\");\n+    return static_cast<vmSymbolID>(id);\n+  }\n@@ -1533,1 +757,4 @@\n-    SID_LIMIT,\n+  static constexpr int as_int(vmSymbolID sid) {\n+    assert(is_valid_id(sid), \"must be\");\n+    return static_cast<int>(sid);\n+  }\n@@ -1535,3 +762,5 @@\n-    #define VM_ALIAS_ENUM(name, def) VM_SYMBOL_ENUM_NAME(name) = VM_SYMBOL_ENUM_NAME(def),\n-    VM_SYMBOLS_DO(VM_SYMBOL_IGNORE, VM_ALIAS_ENUM)\n-    #undef VM_ALIAS_ENUM\n+  static constexpr int number_of_symbols() {\n+    static_assert(NO_SID == 0, \"must be a valid array index\");\n+    static_assert(FIRST_SID == 1, \"must not be the same as NO_SID\");\n+    return SID_LIMIT;\n+  }\n@@ -1539,2 +768,0 @@\n-    FIRST_SID = NO_SID + 1\n-  };\n@@ -1546,2 +773,0 @@\n-  \/\/ The symbol array\n-  static Symbol* _symbols[];\n@@ -1554,1 +779,1 @@\n-  static void initialize(TRAPS);\n+  static void initialize();\n@@ -1558,1 +783,1 @@\n-      return _symbols[VM_SYMBOL_ENUM_NAME(name)];         \\\n+      return Symbol::_vm_symbols[static_cast<int>(VM_SYMBOL_ENUM_NAME(name))]; \\\n@@ -1574,4 +799,2 @@\n-  static Symbol* symbol_at(SID id) {\n-    assert(id >= FIRST_SID && id < SID_LIMIT, \"oob\");\n-    assert(_symbols[id] != NULL, \"init\");\n-    return _symbols[id];\n+  static Symbol* symbol_at(vmSymbolID id) {\n+    return Symbol::vm_symbol_at(id);\n@@ -1580,3 +803,3 @@\n-  \/\/ Returns symbol's SID if one is assigned, else NO_SID.\n-  static SID find_sid(const Symbol* symbol);\n-  static SID find_sid(const char* symbol_name);\n+  \/\/ Returns symbol's vmSymbolID if one is assigned, else vmSymbolID::NO_SID.\n+  static vmSymbolID find_sid(const Symbol* symbol);\n+  static vmSymbolID find_sid(const char* symbol_name);\n@@ -1586,1 +809,1 @@\n-  static const char* name_for(SID sid);\n+  static const char* name_for(vmSymbolID sid);\n@@ -1590,113 +813,0 @@\n-\/\/ VM Intrinsic ID's uniquely identify some very special methods\n-class vmIntrinsics: AllStatic {\n-  friend class vmSymbols;\n-  friend class ciObjectFactory;\n-\n- public:\n-  \/\/ Accessing\n-  enum ID {\n-    _none = 0,                      \/\/ not an intrinsic (default answer)\n-\n-    #define VM_INTRINSIC_ENUM(id, klass, name, sig, flags)  id,\n-    VM_INTRINSICS_DO(VM_INTRINSIC_ENUM,\n-                     VM_SYMBOL_IGNORE, VM_SYMBOL_IGNORE, VM_SYMBOL_IGNORE, VM_ALIAS_IGNORE)\n-    #undef VM_INTRINSIC_ENUM\n-\n-    ID_LIMIT,\n-    LAST_COMPILER_INLINE = _getAndSetReference,\n-    FIRST_MH_SIG_POLY    = _invokeGeneric,\n-    FIRST_MH_STATIC      = _linkToVirtual,\n-    LAST_MH_SIG_POLY     = _linkToInterface,\n-\n-    FIRST_ID = _none + 1\n-  };\n-\n-  enum Flags {\n-    \/\/ AccessFlags syndromes relevant to intrinsics.\n-    F_none = 0,\n-    F_R,                        \/\/ !static ?native !synchronized (R=\"regular\")\n-    F_S,                        \/\/  static ?native !synchronized\n-    F_Y,                        \/\/ !static ?native  synchronized\n-    F_RN,                       \/\/ !static  native !synchronized\n-    F_SN,                       \/\/  static  native !synchronized\n-    F_RNY,                      \/\/ !static  native  synchronized\n-\n-    FLAG_LIMIT\n-  };\n-  enum {\n-    log2_FLAG_LIMIT = 4         \/\/ checked by an assert at start-up\n-  };\n-\n-public:\n-  static ID ID_from(int raw_id) {\n-    assert(raw_id >= (int)_none && raw_id < (int)ID_LIMIT,\n-           \"must be a valid intrinsic ID\");\n-    return (ID)raw_id;\n-  }\n-\n-  static const char* name_at(ID id);\n-\n-private:\n-  static ID find_id_impl(vmSymbols::SID holder,\n-                         vmSymbols::SID name,\n-                         vmSymbols::SID sig,\n-                         jshort flags);\n-\n-public:\n-  \/\/ Given a method's class, name, signature, and access flags, report its ID.\n-  static ID find_id(vmSymbols::SID holder,\n-                    vmSymbols::SID name,\n-                    vmSymbols::SID sig,\n-                    jshort flags) {\n-    ID id = find_id_impl(holder, name, sig, flags);\n-#ifdef ASSERT\n-    \/\/ ID _none does not hold the following asserts.\n-    if (id == _none)  return id;\n-#endif\n-    assert(    class_for(id) == holder, \"correct id\");\n-    assert(     name_for(id) == name,   \"correct id\");\n-    assert(signature_for(id) == sig,    \"correct id\");\n-    return id;\n-  }\n-\n-  static void verify_method(ID actual_id, Method* m) PRODUCT_RETURN;\n-\n-  \/\/ Find out the symbols behind an intrinsic:\n-  static vmSymbols::SID     class_for(ID id);\n-  static vmSymbols::SID      name_for(ID id);\n-  static vmSymbols::SID signature_for(ID id);\n-  static Flags              flags_for(ID id);\n-\n-  static const char* short_name_as_C_string(ID id, char* buf, int size);\n-\n-  \/\/ Wrapper object methods:\n-  static ID for_boxing(BasicType type);\n-  static ID for_unboxing(BasicType type);\n-\n-  \/\/ Raw conversion:\n-  static ID for_raw_conversion(BasicType src, BasicType dest);\n-\n-  \/\/ The methods below provide information related to compiling intrinsics.\n-\n-  \/\/ (1) Information needed by the C1 compiler.\n-\n-  static bool preserves_state(vmIntrinsics::ID id);\n-  static bool can_trap(vmIntrinsics::ID id);\n-  static bool should_be_pinned(vmIntrinsics::ID id);\n-\n-  \/\/ (2) Information needed by the C2 compiler.\n-\n-  \/\/ Returns true if the intrinsic for method 'method' will perform a virtual dispatch.\n-  static bool does_virtual_dispatch(vmIntrinsics::ID id);\n-  \/\/ A return value larger than 0 indicates that the intrinsic for method\n-  \/\/ 'method' requires predicated logic.\n-  static int predicates_needed(vmIntrinsics::ID id);\n-\n-  \/\/ Returns true if a compiler intrinsic is disabled by command-line flags\n-  \/\/ and false otherwise.\n-  static bool is_disabled_by_flags(const methodHandle& method);\n-  static bool is_disabled_by_flags(vmIntrinsics::ID id);\n-  static bool is_intrinsic_disabled(vmIntrinsics::ID id);\n-  static bool is_intrinsic_available(vmIntrinsics::ID id);\n-};\n-\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":102,"deletions":992,"binary":false,"changes":1094,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -32,0 +32,2 @@\n+#include \"memory\/metaspace.hpp\"\n+#include \"memory\/universe.hpp\"\n@@ -33,1 +35,1 @@\n-#include \"runtime\/perfData.hpp\"\n+#include \"runtime\/perfDataTypes.hpp\"\n@@ -37,1 +39,0 @@\n-#include \"utilities\/events.hpp\"\n@@ -46,0 +47,1 @@\n+class AbstractGangTask;\n@@ -48,0 +50,1 @@\n+class GCHeapLog;\n@@ -62,23 +65,4 @@\n-class GCMessage : public FormatBuffer<1024> {\n- public:\n-  bool is_before;\n-\n- public:\n-  GCMessage() {}\n-};\n-\n-class CollectedHeap;\n-\n-class GCHeapLog : public EventLogBase<GCMessage> {\n- private:\n-  void log_heap(CollectedHeap* heap, bool before);\n-\n- public:\n-  GCHeapLog() : EventLogBase<GCMessage>(\"GC Heap History\", \"gc\") {}\n-\n-  void log_heap_before(CollectedHeap* heap) {\n-    log_heap(heap, true);\n-  }\n-  void log_heap_after(CollectedHeap* heap) {\n-    log_heap(heap, false);\n-  }\n+class ParallelObjectIterator : public CHeapObj<mtGC> {\n+public:\n+  virtual void object_iterate(ObjectClosure* cl, uint worker_id) = 0;\n+  virtual ~ParallelObjectIterator() {}\n@@ -105,0 +89,4 @@\n+  \/\/ Historic gc information\n+  size_t _capacity_at_last_gc;\n+  size_t _used_at_last_gc;\n+\n@@ -114,0 +102,6 @@\n+  \/\/ Last time the whole heap has been examined in support of RMI\n+  \/\/ MaxObjectInspectionAge.\n+  \/\/ This timestamp must be monotonically non-decreasing to avoid\n+  \/\/ time-warp warnings.\n+  jlong _last_whole_heap_examined_time_ns;\n+\n@@ -180,0 +174,14 @@\n+ protected:\n+  \/\/ Get a pointer to the derived heap object.  Used to implement\n+  \/\/ derived class heap() functions rather than being called directly.\n+  template<typename T>\n+  static T* named_heap(Name kind) {\n+    CollectedHeap* heap = Universe::heap();\n+    assert(heap != NULL, \"Uninitialized heap\");\n+    assert(kind == heap->kind(), \"Heap kind %u should be %u\",\n+           static_cast<uint>(heap->kind()), static_cast<uint>(kind));\n+    return static_cast<T*>(heap);\n+  }\n+\n+ public:\n+\n@@ -218,0 +226,5 @@\n+  \/\/ Historic gc information\n+  size_t free_at_last_gc() const { return _capacity_at_last_gc - _used_at_last_gc; }\n+  size_t used_at_last_gc() const { return _used_at_last_gc; }\n+  void update_capacity_and_used_at_gc();\n+\n@@ -240,8 +253,1 @@\n-  void set_gc_cause(GCCause::Cause v) {\n-     if (UsePerfData) {\n-       _gc_lastcause = _gc_cause;\n-       _perf_gc_lastcause->set_value(GCCause::to_string(_gc_lastcause));\n-       _perf_gc_cause->set_value(GCCause::to_string(v));\n-     }\n-    _gc_cause = v;\n-  }\n+  void set_gc_cause(GCCause::Cause v);\n@@ -279,6 +285,0 @@\n-  \/\/ Return the address \"addr\" aligned by \"alignment_in_bytes\" if such\n-  \/\/ an address is below \"end\".  Return NULL otherwise.\n-  inline static HeapWord* align_allocation_or_fail(HeapWord* addr,\n-                                                   HeapWord* end,\n-                                                   unsigned short alignment_in_bytes);\n-\n@@ -323,7 +323,0 @@\n-  \/\/ Section on thread-local allocation buffers (TLABs)\n-  \/\/ If the heap supports thread-local allocation buffers, it should override\n-  \/\/ the following methods:\n-  \/\/ Returns \"true\" iff the heap supports thread-local allocation buffers.\n-  \/\/ The default is \"no\".\n-  virtual bool supports_tlab_allocation() const = 0;\n-\n@@ -346,0 +339,5 @@\n+  \/\/ If a GC uses a stack watermark barrier, the stack processing is lazy, concurrent,\n+  \/\/ incremental and cooperative. In order for that to work well, mechanisms that stop\n+  \/\/ another thread might want to ensure its roots are in a sane state.\n+  virtual bool uses_stack_watermark_barrier() const { return false; }\n+\n@@ -393,0 +391,4 @@\n+  virtual ParallelObjectIterator* parallel_object_iterator(uint thread_num) {\n+    return NULL;\n+  }\n+\n@@ -396,4 +398,0 @@\n-  \/\/ Returns the longest time (in ms) that has elapsed since the last\n-  \/\/ time that any part of the heap was examined by a garbage collection.\n-  virtual jlong millis_since_last_gc() = 0;\n-\n@@ -403,1 +401,7 @@\n-  \/\/ Generate any dumps preceding or following a full gc\n+  \/\/ Returns the longest time (in ms) that has elapsed since the last\n+  \/\/ time that the whole heap has been examined by a garbage collection.\n+  jlong millis_since_last_whole_heap_examined();\n+  \/\/ GC should call this when the next whole heap analysis has completed to\n+  \/\/ satisfy above requirement.\n+  void record_whole_heap_examined_timestamp();\n+\n@@ -405,0 +409,1 @@\n+  \/\/ Generate any dumps preceding or following a full gc\n@@ -471,1 +476,1 @@\n-  virtual WorkGang* get_safepoint_workers() { return NULL; }\n+  virtual WorkGang* safepoint_workers() { return NULL; }\n@@ -480,2 +485,2 @@\n-  \/\/ Deduplicate the string, iff the GC supports string deduplication.\n-  virtual void deduplicate_string(oop str);\n+  \/\/ Is the given object inside a CDS archive area?\n+  virtual bool is_archived_object(oop object) const;\n@@ -484,3 +489,0 @@\n-\n-  virtual size_t obj_size(oop obj) const;\n-\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":60,"deletions":58,"binary":false,"changes":118,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,0 +31,1 @@\n+#include \"gc\/shared\/tlab_globals.hpp\"\n@@ -46,1 +47,1 @@\n-  Thread*             _thread;\n+  JavaThread*         _thread;\n@@ -57,1 +58,0 @@\n-  void notify_allocation_jvmti_allocation_event();\n@@ -72,1 +72,1 @@\n-      _thread(Thread::current()),\n+      _thread(JavaThread::current()),\n@@ -98,1 +98,1 @@\n-  PreserveObj(Thread* thread, oop* obj_ptr)\n+  PreserveObj(JavaThread* thread, oop* obj_ptr)\n@@ -116,1 +116,1 @@\n-  Thread* THREAD = _thread;\n+  JavaThread* THREAD = _thread; \/\/ For exception macros.\n@@ -124,1 +124,1 @@\n-  if (!THREAD->in_retryable_allocation()) {\n+  if (!_thread->in_retryable_allocation()) {\n@@ -145,1 +145,1 @@\n-  Thread* THREAD = _thread;\n+  JavaThread* THREAD = _thread; \/\/ For exception macros.\n@@ -175,1 +175,1 @@\n-  _thread->check_for_valid_safepoint_state();\n+  _thread->as_Java_thread()->check_for_valid_safepoint_state();\n@@ -389,1 +389,1 @@\n-    oopDesc::set_mark_raw(mem, _klass->prototype_header());\n+    oopDesc::set_mark(mem, _klass->prototype_header());\n@@ -392,1 +392,1 @@\n-    oopDesc::set_mark_raw(mem, markWord::prototype());\n+    oopDesc::set_mark(mem, markWord::prototype());\n@@ -398,1 +398,1 @@\n-  return oop(mem);\n+  return cast_to_oop(mem);\n","filename":"src\/hotspot\/share\/gc\/shared\/memAllocator.cpp","additions":12,"deletions":12,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2017, 2021, Red Hat, Inc. All rights reserved.\n@@ -49,0 +49,1 @@\n+  f(CNT_PREFIX ## VMStrongRoots,            DESC_PREFIX \"VM Strong Roots\")             \\\n@@ -50,6 +51,4 @@\n-  f(CNT_PREFIX ## ObjectSynchronizerRoots,  DESC_PREFIX \"Synchronizer Roots\")          \\\n-  f(CNT_PREFIX ## ManagementRoots,          DESC_PREFIX \"Management Roots\")            \\\n-  f(CNT_PREFIX ## JVMTIRoots,               DESC_PREFIX \"JVMTI Roots\")                 \\\n-  f(CNT_PREFIX ## StringDedupTableRoots,    DESC_PREFIX \"Dedup Table Roots\")           \\\n-  f(CNT_PREFIX ## StringDedupQueueRoots,    DESC_PREFIX \"Dedup Queue Roots\")           \\\n-  f(CNT_PREFIX ## FinishQueues,             DESC_PREFIX \"Finish Queues\")               \\\n+  f(CNT_PREFIX ## CodeCacheUnload,          DESC_PREFIX \"Unload Code Caches\")          \\\n+  f(CNT_PREFIX ## CLDUnlink,                DESC_PREFIX \"Unlink CLDs\")                 \\\n+  f(CNT_PREFIX ## WeakRefProc,              DESC_PREFIX \"Weak References\")             \\\n+  f(CNT_PREFIX ## ParallelMark,             DESC_PREFIX \"Parallel Mark\")               \\\n@@ -64,1 +63,1 @@\n-  f(make_parsable,                                  \"  Make Parsable\")                 \\\n+  f(init_manage_tlabs,                              \"  Manage TLABs\")                  \\\n@@ -66,3 +65,2 @@\n-  f(scan_roots,                                     \"  Scan Roots\")                    \\\n-  SHENANDOAH_PAR_PHASE_DO(scan_,                    \"    S: \", f)                      \\\n-  f(resize_tlabs,                                   \"  Resize TLABs\")                  \\\n+  f(conc_mark_roots,                                \"Concurrent Mark Roots \")          \\\n+  SHENANDOAH_PAR_PHASE_DO(conc_mark_roots,          \"  CMR: \", f)                      \\\n@@ -71,4 +69,0 @@\n-  f(conc_mark_roots,                                \"  Roots \")                        \\\n-  SHENANDOAH_PAR_PHASE_DO(conc_mark_roots,          \"    CM: \", f)                     \\\n-                                                                                       \\\n-  f(conc_preclean,                                  \"Concurrent Precleaning\")          \\\n@@ -78,5 +72,2 @@\n-  f(update_roots,                                   \"  Update Roots\")                  \\\n-  SHENANDOAH_PAR_PHASE_DO(update_,                  \"    U: \", f)                      \\\n-  f(finish_queues,                                  \"  Finish Queues\")                 \\\n-  f(weakrefs,                                       \"  Weak References\")               \\\n-  f(weakrefs_process,                               \"    Process\")                     \\\n+  f(finish_mark,                                    \"  Finish Mark\")                   \\\n+  SHENANDOAH_PAR_PHASE_DO(finish_mark_,             \"    FM: \", f)                     \\\n@@ -84,1 +75,0 @@\n-  f(purge_class_unload,                             \"    Unload Classes\")              \\\n@@ -88,2 +78,1 @@\n-  f(purge_cldg,                                     \"    CLDG\")                        \\\n-  f(retire_tlabs,                                   \"  Retire TLABs\")                  \\\n+  f(final_manage_labs,                              \"  Manage GC\/TLABs\")               \\\n@@ -96,0 +85,4 @@\n+  f(conc_thread_roots,                              \"Concurrent Thread Roots\")         \\\n+  SHENANDOAH_PAR_PHASE_DO(conc_thread_roots_,       \"  CTR: \", f)                      \\\n+  f(conc_weak_refs,                                 \"Concurrent Weak References\")      \\\n+  SHENANDOAH_PAR_PHASE_DO(conc_weak_refs_,          \"  CWRF: \", f)                     \\\n@@ -115,3 +108,6 @@\n-  f(init_update_refs_gross,                         \"Pause Init  Update Refs (G)\")     \\\n-  f(init_update_refs,                               \"Pause Init  Update Refs (N)\")     \\\n-  f(init_update_refs_retire_gclabs,                 \"  Retire GCLABs\")                 \\\n+  f(final_roots_gross,                              \"Pause Final Roots (G)\")           \\\n+  f(final_roots,                                    \"Pause Final Roots (N)\")           \\\n+                                                                                       \\\n+  f(init_update_refs_gross,                         \"Pause Init Update Refs (G)\")      \\\n+  f(init_update_refs,                               \"Pause Init Update Refs (N)\")      \\\n+  f(init_update_refs_manage_gclabs,                 \"  Manage GCLABs\")                 \\\n@@ -120,0 +116,1 @@\n+  f(conc_update_thread_roots,                       \"Concurrent Update Thread Roots\")  \\\n@@ -124,2 +121,0 @@\n-  f(final_update_refs_roots,                        \"  Update Roots\")                  \\\n-  SHENANDOAH_PAR_PHASE_DO(final_update_,            \"    UR: \", f)                     \\\n@@ -134,2 +129,23 @@\n-  f(degen_gc_scan_conc_roots,                       \"  Degen Mark Roots\")              \\\n-  SHENANDOAH_PAR_PHASE_DO(degen_gc_conc_mark_,      \"    DM: \", f)                     \\\n+  f(degen_gc_stw_mark,                              \"  Degen STW Mark\")                \\\n+  SHENANDOAH_PAR_PHASE_DO(degen_gc_stw_mark_,       \"    DSM: \", f)                    \\\n+  f(degen_gc_mark,                                  \"  Degen Mark\")                    \\\n+  SHENANDOAH_PAR_PHASE_DO(degen_gc_mark_,           \"    DM: \", f)                     \\\n+  f(degen_gc_purge,                                 \"    System Purge\")                \\\n+  f(degen_gc_weakrefs,                              \"      Weak References\")           \\\n+  SHENANDOAH_PAR_PHASE_DO(degen_gc_weakrefs_p_,     \"        WRP: \", f)                \\\n+  f(degen_gc_purge_class_unload,                    \"      Unload Classes\")            \\\n+  SHENANDOAH_PAR_PHASE_DO(degen_gc_purge_cu_par_,   \"        DCU: \", f)                \\\n+  f(degen_gc_purge_weak_par,                        \"      Weak Roots\")                \\\n+  SHENANDOAH_PAR_PHASE_DO(degen_gc_purge_weak_p_,   \"        DWR: \", f)                \\\n+  f(degen_gc_purge_cldg,                            \"      CLDG\")                      \\\n+  f(degen_gc_final_update_region_states,            \"  Update Region States\")          \\\n+  f(degen_gc_final_manage_labs,                     \"  Manage GC\/TLABs\")               \\\n+  f(degen_gc_choose_cset,                           \"  Choose Collection Set\")         \\\n+  f(degen_gc_final_rebuild_freeset,                 \"  Rebuild Free Set\")              \\\n+  f(degen_gc_stw_evac,                              \"  Evacuation\")                    \\\n+  f(degen_gc_init_update_refs_manage_gclabs,        \"  Manage GCLABs\")                 \\\n+  f(degen_gc_updaterefs,                            \"  Update References\")             \\\n+  f(degen_gc_final_update_refs_finish_work,         \"  Finish Work\")                   \\\n+  f(degen_gc_final_update_refs_update_region_states,\"  Update Region States\")          \\\n+  f(degen_gc_final_update_refs_trash_cset,          \"  Trash Collection Set\")          \\\n+  f(degen_gc_final_update_refs_rebuild_freeset,     \"  Rebuild Free Set\")              \\\n@@ -138,0 +154,1 @@\n+  f(degen_gc_cleanup_complete,                      \"  Cleanup\")                       \\\n@@ -143,6 +160,2 @@\n-  f(full_gc_scan_roots,                             \"  Scan Roots\")                    \\\n-  SHENANDOAH_PAR_PHASE_DO(full_gc_scan_roots_,      \"    FS: \", f)                     \\\n-  f(full_gc_scan_conc_roots,                        \"  Scan Concurrent Roots\")         \\\n-  SHENANDOAH_PAR_PHASE_DO(full_gc_scan_conc_roots,  \"    FCS: \", f)                    \\\n-  f(full_gc_update_roots,                           \"  Update Roots\")                  \\\n-  SHENANDOAH_PAR_PHASE_DO(full_gc_update_roots_,    \"    FU: \", f)                     \\\n+  f(full_gc_update_roots,                           \"    Update Roots\")                \\\n+  SHENANDOAH_PAR_PHASE_DO(full_gc_update_roots_,    \"      FU: \", f)                   \\\n@@ -150,3 +163,1 @@\n-  f(full_gc_mark_finish_queues,                     \"    Finish Queues\")               \\\n-  f(full_gc_weakrefs,                               \"    Weak References\")             \\\n-  f(full_gc_weakrefs_process,                       \"      Process\")                   \\\n+  SHENANDOAH_PAR_PHASE_DO(full_gc_mark_,            \"    FM: \", f)                     \\\n@@ -154,0 +165,2 @@\n+  f(full_gc_weakrefs,                               \"      Weak References\")           \\\n+  SHENANDOAH_PAR_PHASE_DO(full_gc_weakrefs_p_,      \"        WRP: \", f)                \\\n@@ -170,1 +183,0 @@\n-  f(full_gc_resize_tlabs,                           \"  Resize TLABs\")                  \\\n@@ -174,0 +186,1 @@\n+  f(pacing,                                         \"Pacing\")                          \\\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahPhaseTimings.hpp","additions":53,"deletions":40,"binary":false,"changes":93,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2020, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2015, 2021, Red Hat, Inc. All rights reserved.\n@@ -27,3 +27,1 @@\n-#include \"classfile\/classLoaderDataGraph.hpp\"\n-#include \"classfile\/stringTable.hpp\"\n-#include \"code\/codeCache.hpp\"\n+#include \"classfile\/classLoaderData.hpp\"\n@@ -32,1 +30,0 @@\n-#include \"gc\/shenandoah\/shenandoahConcurrentRoots.hpp\"\n@@ -36,3 +33,1 @@\n-#include \"gc\/shenandoah\/shenandoahStringDedup.hpp\"\n-#include \"gc\/shenandoah\/shenandoahVMOperations.hpp\"\n-#include \"jfr\/jfr.hpp\"\n+#include \"gc\/shenandoah\/shenandoahStackWatermark.hpp\"\n@@ -41,1 +36,1 @@\n-#include \"memory\/universe.hpp\"\n+#include \"runtime\/stackWatermarkSet.inline.hpp\"\n@@ -46,24 +41,6 @@\n-ShenandoahSerialRoot::ShenandoahSerialRoot(ShenandoahSerialRoot::OopsDo oops_do,\n-  ShenandoahPhaseTimings::Phase phase, ShenandoahPhaseTimings::ParPhase par_phase) :\n-  _oops_do(oops_do), _phase(phase), _par_phase(par_phase) {\n-}\n-\n-void ShenandoahSerialRoot::oops_do(OopClosure* cl, uint worker_id) {\n-  if (_claimed.try_set()) {\n-    ShenandoahWorkerTimingsTracker timer(_phase, _par_phase, worker_id);\n-    _oops_do(cl);\n-  }\n-}\n-\n-ShenandoahSerialRoots::ShenandoahSerialRoots(ShenandoahPhaseTimings::Phase phase) :\n-  _universe_root(&Universe::oops_do, phase, ShenandoahPhaseTimings::UniverseRoots),\n-  _object_synchronizer_root(&ObjectSynchronizer::oops_do, phase, ShenandoahPhaseTimings::ObjectSynchronizerRoots),\n-  _management_root(&Management::oops_do, phase, ShenandoahPhaseTimings::ManagementRoots),\n-  _jvmti_root(&JvmtiExport::oops_do, phase, ShenandoahPhaseTimings::JVMTIRoots) {\n-}\n-\n-void ShenandoahSerialRoots::oops_do(OopClosure* cl, uint worker_id) {\n-  _universe_root.oops_do(cl, worker_id);\n-  _object_synchronizer_root.oops_do(cl, worker_id);\n-  _management_root.oops_do(cl, worker_id);\n-  _jvmti_root.oops_do(cl, worker_id);\n+ShenandoahJavaThreadsIterator::ShenandoahJavaThreadsIterator(ShenandoahPhaseTimings::Phase phase, uint n_workers) :\n+  _threads(),\n+  _length(_threads.length()),\n+  _stride(MAX2(1u, _length \/ n_workers \/ _chunks_per_worker)),\n+  _claimed(0),\n+  _phase(phase) {\n@@ -72,3 +49,2 @@\n-ShenandoahWeakSerialRoot::ShenandoahWeakSerialRoot(ShenandoahWeakSerialRoot::WeakOopsDo weak_oops_do,\n-  ShenandoahPhaseTimings::Phase phase, ShenandoahPhaseTimings::ParPhase par_phase) :\n-  _weak_oops_do(weak_oops_do), _phase(phase), _par_phase(par_phase) {\n+uint ShenandoahJavaThreadsIterator::claim() {\n+  return Atomic::fetch_and_add(&_claimed, _stride, memory_order_relaxed);\n@@ -77,4 +53,6 @@\n-void ShenandoahWeakSerialRoot::weak_oops_do(BoolObjectClosure* is_alive, OopClosure* keep_alive, uint worker_id) {\n-  if (_claimed.try_set()) {\n-    ShenandoahWorkerTimingsTracker timer(_phase, _par_phase, worker_id);\n-    _weak_oops_do(is_alive, keep_alive);\n+void ShenandoahJavaThreadsIterator::threads_do(ThreadClosure* cl, uint worker_id) {\n+  ShenandoahWorkerTimingsTracker timer(_phase, ShenandoahPhaseTimings::ThreadRoots, worker_id);\n+  for (uint i = claim(); i < _length; i = claim()) {\n+    for (uint t = i; t < MIN2(_length, i + _stride); t++) {\n+      cl->do_thread(thread_at(t));\n+    }\n@@ -84,29 +62,0 @@\n-#if INCLUDE_JVMTI\n-ShenandoahJVMTIWeakRoot::ShenandoahJVMTIWeakRoot(ShenandoahPhaseTimings::Phase phase) :\n-  ShenandoahWeakSerialRoot(&JvmtiExport::weak_oops_do, phase, ShenandoahPhaseTimings::JVMTIWeakRoots) {\n-}\n-#endif \/\/ INCLUDE_JVMTI\n-\n-#if INCLUDE_JFR\n-ShenandoahJFRWeakRoot::ShenandoahJFRWeakRoot(ShenandoahPhaseTimings::Phase phase) :\n-  ShenandoahWeakSerialRoot(&Jfr::weak_oops_do, phase, ShenandoahPhaseTimings::JFRWeakRoots) {\n-}\n-#endif \/\/ INCLUDE_JFR\n-\n-#if INCLUDE_TSAN\n-ShenandoahTSANWeakRoot::ShenandoahTSANWeakRoot(ShenandoahPhaseTimings::Phase phase) :\n-  ShenandoahWeakSerialRoot(&TsanOopMap::weak_oops_do, phase, ShenandoahPhaseTimings::TSANWeakRoots) {\n-}\n-#endif \/\/ INCLUDE_TSAN\n-\n-void ShenandoahSerialWeakRoots::weak_oops_do(BoolObjectClosure* is_alive, OopClosure* keep_alive, uint worker_id) {\n-  JVMTI_ONLY(_jvmti_weak_roots.weak_oops_do(is_alive, keep_alive, worker_id);)\n-  JFR_ONLY(_jfr_weak_roots.weak_oops_do(is_alive, keep_alive, worker_id);)\n-  TSAN_ONLY(_tsan_weak_roots.weak_oops_do(is_alive, keep_alive, worker_id);)\n-}\n-\n-void ShenandoahSerialWeakRoots::weak_oops_do(OopClosure* cl, uint worker_id) {\n-  AlwaysTrueClosure always_true;\n-  weak_oops_do(&always_true, cl, worker_id);\n-}\n-\n@@ -134,53 +83,0 @@\n-ShenandoahStringDedupRoots::ShenandoahStringDedupRoots(ShenandoahPhaseTimings::Phase phase) : _phase(phase) {\n-  if (ShenandoahStringDedup::is_enabled()) {\n-    StringDedup::gc_prologue(false);\n-  }\n-}\n-\n-ShenandoahStringDedupRoots::~ShenandoahStringDedupRoots() {\n-  if (ShenandoahStringDedup::is_enabled()) {\n-    StringDedup::gc_epilogue();\n-  }\n-}\n-\n-void ShenandoahStringDedupRoots::oops_do(BoolObjectClosure* is_alive, OopClosure* keep_alive, uint worker_id) {\n-  if (ShenandoahStringDedup::is_enabled()) {\n-    ShenandoahStringDedup::parallel_oops_do(_phase, is_alive, keep_alive, worker_id);\n-  }\n-}\n-\n-ShenandoahConcurrentStringDedupRoots::ShenandoahConcurrentStringDedupRoots(ShenandoahPhaseTimings::Phase phase) :\n-  _phase(phase) {\n-  if (ShenandoahStringDedup::is_enabled()) {\n-    StringDedupTable_lock->lock_without_safepoint_check();\n-    StringDedupQueue_lock->lock_without_safepoint_check();\n-    StringDedup::gc_prologue(true);\n-  }\n-}\n-\n-ShenandoahConcurrentStringDedupRoots::~ShenandoahConcurrentStringDedupRoots() {\n-  if (ShenandoahStringDedup::is_enabled()) {\n-    StringDedup::gc_epilogue();\n-    StringDedupQueue_lock->unlock();\n-    StringDedupTable_lock->unlock();\n-  }\n-}\n-\n-void ShenandoahConcurrentStringDedupRoots::oops_do(BoolObjectClosure* is_alive, OopClosure* keep_alive, uint worker_id) {\n-  if (ShenandoahStringDedup::is_enabled()) {\n-    assert_locked_or_safepoint_weak(StringDedupQueue_lock);\n-    assert_locked_or_safepoint_weak(StringDedupTable_lock);\n-\n-    StringDedupUnlinkOrOopsDoClosure sd_cl(is_alive, keep_alive);\n-    {\n-      ShenandoahWorkerTimingsTracker x(_phase, ShenandoahPhaseTimings::StringDedupQueueRoots, worker_id);\n-      StringDedupQueue::unlink_or_oops_do(&sd_cl);\n-    }\n-\n-    {\n-      ShenandoahWorkerTimingsTracker x(_phase, ShenandoahPhaseTimings::StringDedupTableRoots, worker_id);\n-      StringDedupTable::unlink_or_oops_do(&sd_cl, worker_id);\n-    }\n-  }\n-}\n-\n@@ -204,1 +100,0 @@\n-  assert(SafepointSynchronize::is_at_safepoint(), \"Must at safepoint\");\n@@ -209,1 +104,0 @@\n-  _serial_roots(phase),\n@@ -219,2 +113,1 @@\n-  CLDToOopClosure clds_cl(oops, ClassLoaderData::_claim_strong);\n-  roots_do(worker_id, oops, &clds_cl, &blobs_cl);\n+  roots_do(worker_id, oops, &blobs_cl);\n@@ -224,11 +117,2 @@\n-void ShenandoahRootScanner::strong_roots_do(uint worker_id, OopClosure* oops) {\n-  CLDToOopClosure clds_cl(oops, ClassLoaderData::_claim_strong);\n-  MarkingCodeBlobClosure blobs_cl(oops, !CodeBlobToOopClosure::FixRelocations);\n-  strong_roots_do(worker_id, oops, &clds_cl, &blobs_cl);\n-}\n-\n-void ShenandoahRootScanner::roots_do(uint worker_id, OopClosure* oops, CLDClosure* clds, CodeBlobClosure* code, ThreadClosure *tc) {\n-  assert(!ShenandoahSafepoint::is_at_shenandoah_safepoint() ||\n-         !ShenandoahHeap::heap()->unload_classes(),\n-          \"Expect class unloading when Shenandoah cycle is running\");\n-  assert(clds != NULL, \"Only possible with CLD closure\");\n+void ShenandoahRootScanner::roots_do(uint worker_id, OopClosure* oops, CodeBlobClosure* code, ThreadClosure *tc) {\n+  assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at a safepoint\");\n@@ -236,7 +120,0 @@\n-  AlwaysTrueClosure always_true;\n-\n-\n-  \/\/ Process serial-claiming roots first\n-  _serial_roots.oops_do(oops, worker_id);\n-\n-  \/\/ Process heavy-weight\/fully parallel roots the last\n@@ -248,3 +125,8 @@\n-void ShenandoahRootScanner::strong_roots_do(uint worker_id, OopClosure* oops, CLDClosure* clds, CodeBlobClosure* code, ThreadClosure* tc) {\n-  assert(ShenandoahHeap::heap()->unload_classes(), \"Should be used during class unloading\");\n-  ShenandoahParallelOopsDoThreadClosure tc_cl(oops, code, tc);\n+ShenandoahSTWRootScanner::ShenandoahSTWRootScanner(ShenandoahPhaseTimings::Phase phase) :\n+   ShenandoahRootProcessor(phase),\n+   _thread_roots(phase, ShenandoahHeap::heap()->workers()->active_workers() > 1),\n+   _code_roots(phase),\n+   _cld_roots(phase, ShenandoahHeap::heap()->workers()->active_workers()),\n+   _vm_roots(phase),\n+   _unload_classes(ShenandoahHeap::heap()->unload_classes()) {\n+}\n@@ -252,1 +134,3 @@\n-  ResourceMark rm;\n+class ShenandoahConcurrentMarkThreadClosure : public ThreadClosure {\n+private:\n+  OopClosure* const _oops;\n@@ -254,2 +138,4 @@\n-  \/\/ Process serial-claiming roots first\n-  _serial_roots.oops_do(oops, worker_id);\n+public:\n+  ShenandoahConcurrentMarkThreadClosure(OopClosure* oops);\n+  void do_thread(Thread* thread);\n+};\n@@ -257,2 +143,2 @@\n-  \/\/ Process heavy-weight\/fully parallel roots the last\n-  _thread_roots.threads_do(&tc_cl, worker_id);\n+ShenandoahConcurrentMarkThreadClosure::ShenandoahConcurrentMarkThreadClosure(OopClosure* oops) :\n+  _oops(oops) {\n@@ -261,6 +147,11 @@\n-ShenandoahRootEvacuator::ShenandoahRootEvacuator(uint n_workers,\n-                                                 ShenandoahPhaseTimings::Phase phase,\n-                                                 bool stw_roots_processing,\n-                                                 bool stw_class_unloading) :\n-  ShenandoahRootProcessor(phase),\n-  _serial_roots(phase),\n+void ShenandoahConcurrentMarkThreadClosure::do_thread(Thread* thread) {\n+  assert(thread->is_Java_thread(), \"Must be\");\n+  JavaThread* const jt = thread->as_Java_thread();\n+\n+  StackWatermarkSet::finish_processing(jt, _oops, StackWatermarkKind::gc);\n+}\n+\n+ShenandoahConcurrentRootScanner::ShenandoahConcurrentRootScanner(uint n_workers,\n+                                                                 ShenandoahPhaseTimings::Phase phase) :\n+   ShenandoahRootProcessor(phase),\n+   _java_threads(phase, n_workers),\n@@ -269,7 +160,8 @@\n-  _thread_roots(phase, n_workers > 1),\n-  _serial_weak_roots(phase),\n-  _weak_roots(phase),\n-  _dedup_roots(phase),\n-  _code_roots(phase),\n-  _stw_roots_processing(stw_roots_processing),\n-  _stw_class_unloading(stw_class_unloading) {\n+  _codecache_snapshot(NULL),\n+  _phase(phase) {\n+  if (!ShenandoahHeap::heap()->unload_classes()) {\n+    CodeCache_lock->lock_without_safepoint_check();\n+    _codecache_snapshot = ShenandoahCodeRoots::table()->snapshot_for_iteration();\n+  }\n+  update_tlab_stats();\n+  assert(!ShenandoahHeap::heap()->has_forwarded_objects(), \"Not expecting forwarded pointers during concurrent marking\");\n@@ -278,7 +170,6 @@\n-void ShenandoahRootEvacuator::roots_do(uint worker_id, OopClosure* oops) {\n-  MarkingCodeBlobClosure blobsCl(oops, CodeBlobToOopClosure::FixRelocations);\n-  ShenandoahCodeBlobAndDisarmClosure blobs_and_disarm_Cl(oops);\n-  CodeBlobToOopClosure* codes_cl = ShenandoahConcurrentRoots::can_do_concurrent_class_unloading() ?\n-                                   static_cast<CodeBlobToOopClosure*>(&blobs_and_disarm_Cl) :\n-                                   static_cast<CodeBlobToOopClosure*>(&blobsCl);\n-  AlwaysTrueClosure always_true;\n+ShenandoahConcurrentRootScanner::~ShenandoahConcurrentRootScanner() {\n+  if (!ShenandoahHeap::heap()->unload_classes()) {\n+    ShenandoahCodeRoots::table()->finish_iteration(_codecache_snapshot);\n+    CodeCache_lock->unlock();\n+  }\n+}\n@@ -286,3 +177,3 @@\n-  \/\/ Process serial-claiming roots first\n-  _serial_roots.oops_do(oops, worker_id);\n-  _serial_weak_roots.weak_oops_do(oops, worker_id);\n+void ShenandoahConcurrentRootScanner::roots_do(OopClosure* oops, uint worker_id) {\n+  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n+  CLDToOopClosure clds_cl(oops, ClassLoaderData::_claim_strong);\n@@ -291,8 +182,12 @@\n-  if (_stw_roots_processing) {\n-    _vm_roots.oops_do<OopClosure>(oops, worker_id);\n-    _weak_roots.oops_do<OopClosure>(oops, worker_id);\n-    _dedup_roots.oops_do(&always_true, oops, worker_id);\n-  }\n-  if (_stw_class_unloading) {\n-    CLDToOopClosure clds(oops, ClassLoaderData::_claim_strong);\n-    _cld_roots.cld_do(&clds, worker_id);\n+  _vm_roots.oops_do(oops, worker_id);\n+\n+  if (heap->unload_classes()) {\n+    _cld_roots.always_strong_cld_do(&clds_cl, worker_id);\n+  } else {\n+    _cld_roots.cld_do(&clds_cl, worker_id);\n+\n+    {\n+      ShenandoahWorkerTimingsTracker timer(_phase, ShenandoahPhaseTimings::CodeCacheRoots, worker_id);\n+      CodeBlobToOopClosure blobs(oops, !CodeBlobToOopClosure::FixRelocations);\n+      _codecache_snapshot->parallel_blobs_do(&blobs);\n+    }\n@@ -302,5 +197,15 @@\n-  if (_stw_class_unloading) {\n-    _code_roots.code_blobs_do(codes_cl, worker_id);\n-    _thread_roots.oops_do(oops, NULL, worker_id);\n-  } else {\n-    _thread_roots.oops_do(oops, codes_cl, worker_id);\n+  ShenandoahConcurrentMarkThreadClosure thr_cl(oops);\n+  _java_threads.threads_do(&thr_cl, worker_id);\n+}\n+\n+void ShenandoahConcurrentRootScanner::update_tlab_stats() {\n+  if (UseTLAB) {\n+    ThreadLocalAllocStats total;\n+    for (uint i = 0; i < _java_threads.length(); i ++) {\n+      Thread* thr = _java_threads.thread_at(i);\n+      if (thr->is_Java_thread()) {\n+        ShenandoahStackWatermark* wm = StackWatermarkSet::get<ShenandoahStackWatermark>(thr->as_Java_thread(), StackWatermarkKind::gc);\n+        total.update(wm->stats());\n+      }\n+    }\n+    total.publish();\n@@ -312,1 +217,0 @@\n-  _serial_roots(phase),\n@@ -316,2 +220,0 @@\n-  _serial_weak_roots(phase),\n-  _dedup_roots(phase),\n@@ -324,1 +226,0 @@\n-  _serial_roots(phase),\n@@ -328,2 +229,0 @@\n-  _serial_weak_roots(phase),\n-  _dedup_roots(phase),\n@@ -338,1 +237,1 @@\n-  CodeBlobToOopClosure* adjust_code_closure = ShenandoahConcurrentRoots::can_do_concurrent_class_unloading() ?\n+  CodeBlobToOopClosure* adjust_code_closure = (ClassUnloading && ShenandoahNMethodBarrier) ?\n@@ -344,4 +243,0 @@\n-  \/\/ Process serial-claiming roots first\n-  _serial_roots.oops_do(oops, worker_id);\n-  _serial_weak_roots.weak_oops_do(oops, worker_id);\n-\n@@ -351,1 +246,0 @@\n-  _dedup_roots.oops_do(&always_true, oops, worker_id);\n@@ -361,1 +255,0 @@\n-   _serial_roots(ShenandoahPhaseTimings::heap_iteration_roots),\n@@ -365,2 +258,0 @@\n-   _serial_weak_roots(ShenandoahPhaseTimings::heap_iteration_roots),\n-   _dedup_roots(ShenandoahPhaseTimings::heap_iteration_roots),\n@@ -381,4 +272,0 @@\n-   \/\/ Process serial-claiming roots first\n-   _serial_roots.oops_do(oops, 0);\n-   _serial_weak_roots.weak_oops_do(oops, 0);\n-\n@@ -388,1 +275,0 @@\n-   _dedup_roots.oops_do(&always_true, oops, 0);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahRootProcessor.cpp","additions":94,"deletions":208,"binary":false,"changes":302,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2020, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2015, 2021, Red Hat, Inc. All rights reserved.\n@@ -29,1 +29,1 @@\n-#include \"gc\/shared\/oopStorageParState.hpp\"\n+#include \"gc\/shared\/oopStorageSetParState.hpp\"\n@@ -113,1 +113,1 @@\n-class ShenandoahVMRoot {\n+class ShenandoahVMWeakRoots {\n@@ -115,6 +115,2 @@\n-  OopStorage::ParState<CONCURRENT, false \/* is_const *\/> _itr;\n-  const ShenandoahPhaseTimings::Phase    _phase;\n-  const ShenandoahPhaseTimings::ParPhase _par_phase;\n-public:\n-  ShenandoahVMRoot(OopStorage* storage,\n-          ShenandoahPhaseTimings::Phase phase, ShenandoahPhaseTimings::ParPhase par_phase);\n+  OopStorageSetWeakParState<CONCURRENT, false \/* is_const *\/> _weak_roots;\n+  ShenandoahPhaseTimings::Phase                               _phase;\n@@ -122,9 +118,1 @@\n-  template <typename Closure>\n-  void oops_do(Closure* cl, uint worker_id);\n-};\n-\n-template <bool CONCURRENT>\n-class ShenandoahWeakRoot : public ShenandoahVMRoot<CONCURRENT> {\n-  ShenandoahWeakRoot(OopStorage* storage,\n-          ShenandoahPhaseTimings::Phase phase, ShenandoahPhaseTimings::ParPhase par_phase);\n-};\n+  ShenandoahVMWeakRoots(ShenandoahPhaseTimings::Phase phase);\n@@ -133,6 +121,2 @@\n-template <>\n-class ShenandoahWeakRoot<false \/*concurrent*\/> {\n-private:\n-  OopStorage::ParState<false \/*concurrent*\/, false \/*is_const*\/> _itr;\n-  const ShenandoahPhaseTimings::Phase    _phase;\n-  const ShenandoahPhaseTimings::ParPhase _par_phase;\n+  template <typename T>\n+  void oops_do(T* cl, uint worker_id);\n@@ -140,3 +124,2 @@\n-public:\n-  ShenandoahWeakRoot(OopStorage* storage,\n-          ShenandoahPhaseTimings::Phase phase, ShenandoahPhaseTimings::ParPhase par_phase);\n+  template <typename IsAlive, typename KeepAlive>\n+  void weak_oops_do(IsAlive* is_alive, KeepAlive* keep_alive, uint worker_id);\n@@ -144,2 +127,1 @@\n-  template <typename IsAliveClosure, typename KeepAliveClosure>\n-  void weak_oops_do(IsAliveClosure* is_alive, KeepAliveClosure* keep_alive, uint worker_id);\n+  void report_num_dead();\n@@ -149,1 +131,1 @@\n-class ShenandoahWeakRoots {\n+class ShenandoahVMRoots {\n@@ -151,4 +133,2 @@\n-  ShenandoahWeakRoot<CONCURRENT>  _jni_roots;\n-  ShenandoahWeakRoot<CONCURRENT>  _string_table_roots;\n-  ShenandoahWeakRoot<CONCURRENT>  _resolved_method_table_roots;\n-  ShenandoahWeakRoot<CONCURRENT>  _vm_roots;\n+  OopStorageSetStrongParState<CONCURRENT, false \/* is_const *\/> _strong_roots;\n+  ShenandoahPhaseTimings::Phase                                 _phase;\n@@ -157,1 +137,1 @@\n-  ShenandoahWeakRoots();\n+  ShenandoahVMRoots(ShenandoahPhaseTimings::Phase phase);\n@@ -159,2 +139,2 @@\n-  template <typename Closure>\n-  void oops_do(Closure* cl, uint worker_id);\n+  template <typename T>\n+  void oops_do(T* cl, uint worker_id);\n@@ -163,2 +143,1 @@\n-template <>\n-class ShenandoahWeakRoots<false \/*concurrent *\/> {\n+class ShenandoahJavaThreadsIterator {\n@@ -166,6 +145,1 @@\n-  ShenandoahWeakRoot<false \/*concurrent*\/>  _jni_roots;\n-  ShenandoahWeakRoot<false \/*concurrent*\/>  _string_table_roots;\n-  ShenandoahWeakRoot<false \/*concurrent*\/>  _resolved_method_table_roots;\n-  ShenandoahWeakRoot<false \/*concurrent*\/>  _vm_roots;\n-public:\n-  ShenandoahWeakRoots(ShenandoahPhaseTimings::Phase phase);\n+  static const uint _chunks_per_worker = 16; \/\/ educated guess\n@@ -173,12 +147,5 @@\n-  template <typename Closure>\n-  void oops_do(Closure* cl, uint worker_id);\n-\n-  template <typename IsAliveClosure, typename KeepAliveClosure>\n-  void weak_oops_do(IsAliveClosure* is_alive, KeepAliveClosure* keep_alive, uint worker_id);\n-};\n-\n-template <bool CONCURRENT>\n-class ShenandoahVMRoots {\n-private:\n-  ShenandoahVMRoot<CONCURRENT>    _jni_handle_roots;\n-  ShenandoahVMRoot<CONCURRENT>    _vm_global_roots;\n+  ThreadsListHandle             _threads;\n+  uint const                    _length;\n+  uint const                    _stride;\n+  volatile uint                 _claimed;\n+  ShenandoahPhaseTimings::Phase _phase;\n@@ -186,0 +153,1 @@\n+  uint claim();\n@@ -187,1 +155,2 @@\n-  ShenandoahVMRoots(ShenandoahPhaseTimings::Phase phase);\n+  ShenandoahJavaThreadsIterator(ShenandoahPhaseTimings::Phase phase, uint n_workers);\n+  void threads_do(ThreadClosure* cl, uint worker_id);\n@@ -189,2 +158,2 @@\n-  template <typename T>\n-  void oops_do(T* cl, uint worker_id);\n+  uint length() const { return _length; }\n+  Thread* thread_at(uint index) const { return _threads.thread_at(index); }\n@@ -205,21 +174,0 @@\n-class ShenandoahStringDedupRoots {\n-private:\n-  ShenandoahPhaseTimings::Phase _phase;\n-public:\n-  ShenandoahStringDedupRoots(ShenandoahPhaseTimings::Phase phase);\n-  ~ShenandoahStringDedupRoots();\n-\n-  void oops_do(BoolObjectClosure* is_alive, OopClosure* keep_alive, uint worker_id);\n-};\n-\n-class ShenandoahConcurrentStringDedupRoots {\n-private:\n-  ShenandoahPhaseTimings::Phase _phase;\n-\n-public:\n-  ShenandoahConcurrentStringDedupRoots(ShenandoahPhaseTimings::Phase phase);\n-  ~ShenandoahConcurrentStringDedupRoots();\n-\n-  void oops_do(BoolObjectClosure* is_alive, OopClosure* keep_alive, uint worker_id);\n-};\n-\n@@ -244,0 +192,2 @@\n+    if (SINGLE_THREADED) return 1u;\n+\n@@ -256,0 +206,4 @@\n+\n+private:\n+  typedef void (*CldDo)(CLDClosure*);\n+  void cld_do_impl(CldDo f, CLDClosure* clds, uint worker_id);\n@@ -271,1 +225,0 @@\n-  ShenandoahSerialRoots                                     _serial_roots;\n@@ -278,8 +231,3 @@\n-  \/\/ Apply oops, clds and blobs to all strongly reachable roots in the system,\n-  \/\/ during class unloading cycle\n-  void strong_roots_do(uint worker_id, OopClosure* cl);\n-  void strong_roots_do(uint worker_id, OopClosure* oops, CLDClosure* clds, CodeBlobClosure* code, ThreadClosure* tc = NULL);\n-\n-  \/\/ Apply oops, clds and blobs to all strongly reachable roots and weakly reachable\n-  \/\/ roots when class unloading is disabled during this cycle\n-  void roots_do(uint worker_id, OopClosure* oops, CLDClosure* clds, CodeBlobClosure* code, ThreadClosure* tc = NULL);\n+\n+private:\n+  void roots_do(uint worker_id, OopClosure* oops, CodeBlobClosure* code, ThreadClosure* tc = NULL);\n@@ -289,2 +237,2 @@\n-template <bool CONCURRENT>\n-class ShenandoahConcurrentRootScanner {\n+\/\/ STW root scanner\n+class ShenandoahSTWRootScanner : public ShenandoahRootProcessor {\n@@ -292,2 +240,19 @@\n-  ShenandoahVMRoots<CONCURRENT>            _vm_roots;\n-  ShenandoahClassLoaderDataRoots<CONCURRENT, false \/* single-threaded*\/>\n+  ShenandoahThreadRoots           _thread_roots;\n+  ShenandoahCodeCacheRoots        _code_roots;\n+  ShenandoahClassLoaderDataRoots<false \/*concurrent*\/, false \/* single_thread*\/>\n+                                  _cld_roots;\n+  ShenandoahVMRoots<false \/*concurrent*\/>\n+                                  _vm_roots;\n+  const bool                      _unload_classes;\n+public:\n+  ShenandoahSTWRootScanner(ShenandoahPhaseTimings::Phase phase);\n+\n+  template <typename T>\n+  void roots_do(T* oops, uint worker_id);\n+};\n+\n+class ShenandoahConcurrentRootScanner : public ShenandoahRootProcessor {\n+private:\n+  ShenandoahJavaThreadsIterator             _java_threads;\n+  ShenandoahVMRoots<true \/*concurrent*\/>    _vm_roots;\n+  ShenandoahClassLoaderDataRoots<true \/*concurrent*\/, false \/* single-threaded*\/>\n@@ -295,1 +260,0 @@\n-  ShenandoahConcurrentStringDedupRoots     _dedup_roots;\n@@ -303,1 +267,4 @@\n-  void oops_do(OopClosure* oops, uint worker_id);\n+  void roots_do(OopClosure* oops, uint worker_id);\n+\n+private:\n+  void update_tlab_stats();\n@@ -310,1 +277,0 @@\n-  ShenandoahSerialRoots                                    _serial_roots;\n@@ -315,3 +281,1 @@\n-  ShenandoahSerialWeakRoots                                _serial_weak_roots;\n-  ShenandoahWeakRoots<false \/*concurrent*\/>                _weak_roots;\n-  ShenandoahConcurrentStringDedupRoots                     _dedup_roots;\n+  ShenandoahVMWeakRoots<false \/*concurrent*\/>              _weak_roots;\n@@ -326,21 +290,0 @@\n-\/\/ Evacuate all roots at a safepoint\n-class ShenandoahRootEvacuator : public ShenandoahRootProcessor {\n-private:\n-  ShenandoahSerialRoots                                     _serial_roots;\n-  ShenandoahVMRoots<false \/*concurrent*\/>                   _vm_roots;\n-  ShenandoahClassLoaderDataRoots<false \/*concurrent*\/, false \/*single threaded*\/>\n-                                                            _cld_roots;\n-  ShenandoahThreadRoots                                     _thread_roots;\n-  ShenandoahSerialWeakRoots                                 _serial_weak_roots;\n-  ShenandoahWeakRoots<false \/*concurrent*\/>                 _weak_roots;\n-  ShenandoahStringDedupRoots                                _dedup_roots;\n-  ShenandoahCodeCacheRoots                                  _code_roots;\n-  bool                                                      _stw_roots_processing;\n-  bool                                                      _stw_class_unloading;\n-public:\n-  ShenandoahRootEvacuator(uint n_workers, ShenandoahPhaseTimings::Phase phase,\n-                          bool stw_roots_processing, bool stw_class_unloading);\n-\n-  void roots_do(uint worker_id, OopClosure* oops);\n-};\n-\n@@ -350,1 +293,0 @@\n-  ShenandoahSerialRoots                                     _serial_roots;\n@@ -355,3 +297,1 @@\n-  ShenandoahSerialWeakRoots                                 _serial_weak_roots;\n-  ShenandoahWeakRoots<false \/*concurrent*\/>                 _weak_roots;\n-  ShenandoahStringDedupRoots                                _dedup_roots;\n+  ShenandoahVMWeakRoots<false \/*concurrent*\/>               _weak_roots;\n@@ -370,1 +310,0 @@\n-  ShenandoahSerialRoots                                     _serial_roots;\n@@ -375,3 +314,1 @@\n-  ShenandoahSerialWeakRoots                                 _serial_weak_roots;\n-  ShenandoahWeakRoots<false \/*concurrent*\/>                 _weak_roots;\n-  ShenandoahStringDedupRoots                                _dedup_roots;\n+  ShenandoahVMWeakRoots<false \/*concurrent*\/>               _weak_roots;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahRootProcessor.hpp","additions":66,"deletions":129,"binary":false,"changes":195,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -33,0 +33,2 @@\n+#include \"jvm_constants.h\"\n+#include \"jvm_io.h\"\n@@ -47,1 +49,1 @@\n- * Second, this file contains the functions and constant definitions\n+ * Second, (included from jvm_constants.h) constant definitions\n@@ -49,1 +51,1 @@\n- * These functions allow the verifier and format checker to be written\n+ * These definitions allow the verifier and format checker to be written\n@@ -53,1 +55,2 @@\n- * by the standard Java I\/O and network APIs.\n+ * by the standard Java I\/O and network APIs. A part of these APIs,\n+ * namely the jio_xxxprintf functions, are included from jvm_io.h.\n@@ -56,14 +59,0 @@\n-\/*\n- * Bump the version number when either of the following happens:\n- *\n- * 1. There is a change in JVM_* functions.\n- *\n- * 2. There is a change in the contract between VM and Java classes.\n- *    For example, if the VM relies on a new private field in Thread\n- *    class.\n- *\/\n-\n-#define JVM_INTERFACE_VERSION 6\n-\n-JNIEXPORT jint JNICALL\n-JVM_GetInterfaceVersion(void);\n@@ -161,0 +150,3 @@\n+JNIEXPORT jboolean JNICALL\n+JVM_IsUseContainerSupport(void);\n+\n@@ -181,5 +173,5 @@\n-                                         jstring invokedName,\n-                                         jobject invokedType,\n-                                         jobject methodType,\n-                                         jobject implMethodMember,\n-                                         jobject instantiatedMethodType,\n+                                         jstring interfaceMethodName,\n+                                         jobject factoryType,\n+                                         jobject interfaceMethodType,\n+                                         jobject implementationMember,\n+                                         jobject dynamicMethodType,\n@@ -190,6 +182,5 @@\n-                                      jstring invokedName,\n-                                      jobject invokedType,\n-                                      jobject methodType,\n-                                      jobject implMethodMember,\n-                                      jobject instantiatedMethodType,\n-                                      jboolean initialize);\n+                                      jstring interfaceMethodName,\n+                                      jobject factoryType,\n+                                      jobject interfaceMethodType,\n+                                      jobject implementationMember,\n+                                      jobject dynamicMethodType);\n@@ -201,1 +192,4 @@\n-JVM_IsCDSSharingEnabled(JNIEnv* env);\n+JVM_IsSharingEnabled(JNIEnv* env);\n+\n+JNIEXPORT jboolean JNICALL\n+JVM_IsDumpingClassList(JNIEnv* env);\n@@ -204,1 +198,10 @@\n-JVM_GetRandomSeedForCDSDump();\n+JVM_GetRandomSeedForDumping();\n+\n+JNIEXPORT void JNICALL\n+JVM_LogLambdaFormInvoker(JNIEnv* env, jstring line);\n+\n+JNIEXPORT void JNICALL\n+JVM_DumpClassListToFile(JNIEnv* env, jstring fileName);\n+\n+JNIEXPORT void JNICALL\n+JVM_DumpDynamicArchive(JNIEnv* env, jstring archiveName);\n@@ -330,0 +333,12 @@\n+JNIEXPORT jboolean JNICALL\n+JVM_ReferenceRefersTo(JNIEnv *env, jobject ref, jobject o);\n+\n+JNIEXPORT void JNICALL\n+JVM_ReferenceClear(JNIEnv *env, jobject ref);\n+\n+\/*\n+ * java.lang.ref.PhantomReference\n+ *\/\n+JNIEXPORT jboolean JNICALL\n+JVM_PhantomReferenceRefersTo(JNIEnv *env, jobject ref, jobject o);\n+\n@@ -496,0 +511,8 @@\n+\/*\n+ * Define all modules that have been stored in the CDS archived heap.\n+ *  platform_loader: the built-in platform class loader\n+ *  system_loader:   the built-in system class loader\n+ *\/\n+JNIEXPORT void JNICALL\n+JVM_DefineArchivedModules(JNIEnv *env, jobject platform_loader, jobject system_loader);\n+\n@@ -592,1 +615,1 @@\n-\/* Records - since JDK 14 *\/\n+\/* Records - since JDK 16 *\/\n@@ -600,1 +623,1 @@\n-\/* Sealed types - since JDK 15 *\/\n+\/* Sealed classes - since JDK 17 *\/\n@@ -739,74 +762,0 @@\n-\/*\n- * com.sun.dtrace.jsdt support\n- *\/\n-\n-#define JVM_TRACING_DTRACE_VERSION 1\n-\n-\/*\n- * Structure to pass one probe description to JVM\n- *\/\n-typedef struct {\n-    jmethodID method;\n-    jstring   function;\n-    jstring   name;\n-    void*            reserved[4];     \/\/ for future use\n-} JVM_DTraceProbe;\n-\n-\/**\n- * Encapsulates the stability ratings for a DTrace provider field\n- *\/\n-typedef struct {\n-    jint nameStability;\n-    jint dataStability;\n-    jint dependencyClass;\n-} JVM_DTraceInterfaceAttributes;\n-\n-\/*\n- * Structure to pass one provider description to JVM\n- *\/\n-typedef struct {\n-    jstring                       name;\n-    JVM_DTraceProbe*              probes;\n-    jint                          probe_count;\n-    JVM_DTraceInterfaceAttributes providerAttributes;\n-    JVM_DTraceInterfaceAttributes moduleAttributes;\n-    JVM_DTraceInterfaceAttributes functionAttributes;\n-    JVM_DTraceInterfaceAttributes nameAttributes;\n-    JVM_DTraceInterfaceAttributes argsAttributes;\n-    void*                         reserved[4]; \/\/ for future use\n-} JVM_DTraceProvider;\n-\n-\/*\n- * Get the version number the JVM was built with\n- *\/\n-JNIEXPORT jint JNICALL\n-JVM_DTraceGetVersion(JNIEnv* env);\n-\n-\/*\n- * Register new probe with given signature, return global handle\n- *\n- * The version passed in is the version that the library code was\n- * built with.\n- *\/\n-JNIEXPORT jlong JNICALL\n-JVM_DTraceActivate(JNIEnv* env, jint version, jstring module_name,\n-  jint providers_count, JVM_DTraceProvider* providers);\n-\n-\/*\n- * Check JSDT probe\n- *\/\n-JNIEXPORT jboolean JNICALL\n-JVM_DTraceIsProbeEnabled(JNIEnv* env, jmethodID method);\n-\n-\/*\n- * Destroy custom DOF\n- *\/\n-JNIEXPORT void JNICALL\n-JVM_DTraceDispose(JNIEnv* env, jlong activation_handle);\n-\n-\/*\n- * Check to see if DTrace is supported by OS\n- *\/\n-JNIEXPORT jboolean JNICALL\n-JVM_DTraceIsSupported(JNIEnv* env);\n-\n@@ -1103,58 +1052,0 @@\n-\/* Get classfile constants *\/\n-#include \"classfile_constants.h\"\n-\n-\/*\n- * Support for a VM-independent class format checker.\n- *\/\n-typedef struct {\n-    unsigned long code;    \/* byte code *\/\n-    unsigned long excs;    \/* exceptions *\/\n-    unsigned long etab;    \/* catch table *\/\n-    unsigned long lnum;    \/* line number *\/\n-    unsigned long lvar;    \/* local vars *\/\n-} method_size_info;\n-\n-typedef struct {\n-    unsigned int constants;    \/* constant pool *\/\n-    unsigned int fields;\n-    unsigned int methods;\n-    unsigned int interfaces;\n-    unsigned int fields2;      \/* number of static 2-word fields *\/\n-    unsigned int innerclasses; \/* # of records in InnerClasses attr *\/\n-\n-    method_size_info clinit;   \/* memory used in clinit *\/\n-    method_size_info main;     \/* used everywhere else *\/\n-} class_size_info;\n-\n-#define JVM_RECOGNIZED_CLASS_MODIFIERS (JVM_ACC_PUBLIC | \\\n-                                        JVM_ACC_FINAL | \\\n-                                        JVM_ACC_SUPER | \\\n-                                        JVM_ACC_INTERFACE | \\\n-                                        JVM_ACC_ABSTRACT | \\\n-                                        JVM_ACC_ANNOTATION | \\\n-                                        JVM_ACC_ENUM | \\\n-                                        JVM_ACC_SYNTHETIC)\n-\n-#define JVM_RECOGNIZED_FIELD_MODIFIERS (JVM_ACC_PUBLIC | \\\n-                                        JVM_ACC_PRIVATE | \\\n-                                        JVM_ACC_PROTECTED | \\\n-                                        JVM_ACC_STATIC | \\\n-                                        JVM_ACC_FINAL | \\\n-                                        JVM_ACC_VOLATILE | \\\n-                                        JVM_ACC_TRANSIENT | \\\n-                                        JVM_ACC_ENUM | \\\n-                                        JVM_ACC_SYNTHETIC)\n-\n-#define JVM_RECOGNIZED_METHOD_MODIFIERS (JVM_ACC_PUBLIC | \\\n-                                         JVM_ACC_PRIVATE | \\\n-                                         JVM_ACC_PROTECTED | \\\n-                                         JVM_ACC_STATIC | \\\n-                                         JVM_ACC_FINAL | \\\n-                                         JVM_ACC_SYNCHRONIZED | \\\n-                                         JVM_ACC_BRIDGE | \\\n-                                         JVM_ACC_VARARGS | \\\n-                                         JVM_ACC_NATIVE | \\\n-                                         JVM_ACC_ABSTRACT | \\\n-                                         JVM_ACC_STRICT | \\\n-                                         JVM_ACC_SYNTHETIC)\n-\n@@ -1174,27 +1065,0 @@\n-\/*\n- * The standard printing functions supported by the Java VM. (Should they\n- * be renamed to JVM_* in the future?\n- *\/\n-\n-\/* jio_snprintf() and jio_vsnprintf() behave like snprintf(3) and vsnprintf(3),\n- *  respectively, with the following differences:\n- * - The string written to str is always zero-terminated, also in case of\n- *   truncation (count is too small to hold the result string), unless count\n- *   is 0. In case of truncation count-1 characters are written and '\\0'\n- *   appendend.\n- * - If count is too small to hold the whole string, -1 is returned across\n- *   all platforms. *\/\n-\n-JNIEXPORT int\n-jio_vsnprintf(char *str, size_t count, const char *fmt, va_list args);\n-\n-JNIEXPORT int\n-jio_snprintf(char *str, size_t count, const char *fmt, ...);\n-\n-JNIEXPORT int\n-jio_fprintf(FILE *, const char *fmt, ...);\n-\n-JNIEXPORT int\n-jio_vfprintf(FILE *, const char *fmt, va_list args);\n-\n-\n","filename":"src\/hotspot\/share\/include\/jvm.h","additions":56,"deletions":192,"binary":false,"changes":248,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,0 +26,1 @@\n+#include \"jvm_io.h\"\n@@ -28,1 +29,1 @@\n-#include \"classfile\/systemDictionary.hpp\"\n+#include \"classfile\/vmClasses.hpp\"\n@@ -46,1 +47,2 @@\n-#include \"oops\/instanceKlass.hpp\"\n+#include \"oops\/instanceKlass.inline.hpp\"\n+#include \"oops\/klass.inline.hpp\"\n@@ -53,0 +55,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -67,0 +70,1 @@\n+#include \"runtime\/stackWatermarkSet.hpp\"\n@@ -81,3 +85,3 @@\n-  LastFrameAccessor(JavaThread* thread) {\n-    assert(thread == Thread::current(), \"sanity\");\n-    _last_frame = thread->last_frame();\n+  LastFrameAccessor(JavaThread* current) {\n+    assert(current == Thread::current(), \"sanity\");\n+    _last_frame = current->last_frame();\n@@ -127,2 +131,2 @@\n-void InterpreterRuntime::set_bcp_and_mdp(address bcp, JavaThread *thread) {\n-  LastFrameAccessor last_frame(thread);\n+void InterpreterRuntime::set_bcp_and_mdp(address bcp, JavaThread* current) {\n+  LastFrameAccessor last_frame(current);\n@@ -145,1 +149,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::ldc(JavaThread* thread, bool wide))\n+JRT_ENTRY(void, InterpreterRuntime::ldc(JavaThread* current, bool wide))\n@@ -147,1 +151,1 @@\n-  LastFrameAccessor last_frame(thread);\n+  LastFrameAccessor last_frame(current);\n@@ -154,2 +158,2 @@\n-    oop java_class = klass->java_mirror();\n-    thread->set_vm_result(java_class);\n+  oop java_class = klass->java_mirror();\n+  current->set_vm_result(java_class);\n@@ -158,1 +162,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::resolve_ldc(JavaThread* thread, Bytecodes::Code bytecode)) {\n+JRT_ENTRY(void, InterpreterRuntime::resolve_ldc(JavaThread* current, Bytecodes::Code bytecode)) {\n@@ -164,1 +168,1 @@\n-  ResourceMark rm(thread);\n+  ResourceMark rm(current);\n@@ -167,2 +171,2 @@\n-  LastFrameAccessor last_frame(thread);\n-  methodHandle m (thread, last_frame.method());\n+  LastFrameAccessor last_frame(current);\n+  methodHandle m (current, last_frame.method());\n@@ -198,1 +202,1 @@\n-  thread->set_vm_result(result);\n+  current->set_vm_result(result);\n@@ -205,1 +209,1 @@\n-    thread->set_vm_result_2((Metadata*)flags);\n+    current->set_vm_result_2((Metadata*)flags);\n@@ -214,1 +218,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::_new(JavaThread* thread, ConstantPool* pool, int index))\n+JRT_ENTRY(void, InterpreterRuntime::_new(JavaThread* current, ConstantPool* pool, int index))\n@@ -239,1 +243,1 @@\n-  thread->set_vm_result(obj);\n+  current->set_vm_result(obj);\n@@ -243,1 +247,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::newarray(JavaThread* thread, BasicType type, jint size))\n+JRT_ENTRY(void, InterpreterRuntime::newarray(JavaThread* current, BasicType type, jint size))\n@@ -245,1 +249,1 @@\n-  thread->set_vm_result(obj);\n+  current->set_vm_result(obj);\n@@ -249,1 +253,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::anewarray(JavaThread* thread, ConstantPool* pool, int index, jint size))\n+JRT_ENTRY(void, InterpreterRuntime::anewarray(JavaThread* current, ConstantPool* pool, int index, jint size))\n@@ -252,1 +256,1 @@\n-  thread->set_vm_result(obj);\n+  current->set_vm_result(obj);\n@@ -256,1 +260,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::multianewarray(JavaThread* thread, jint* first_size_address))\n+JRT_ENTRY(void, InterpreterRuntime::multianewarray(JavaThread* current, jint* first_size_address))\n@@ -258,1 +262,1 @@\n-  LastFrameAccessor last_frame(thread);\n+  LastFrameAccessor last_frame(current);\n@@ -267,1 +271,1 @@\n-  ResourceMark rm(thread);\n+  ResourceMark rm(current);\n@@ -280,1 +284,1 @@\n-  thread->set_vm_result(obj);\n+  current->set_vm_result(obj);\n@@ -284,1 +288,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::register_finalizer(JavaThread* thread, oopDesc* obj))\n+JRT_ENTRY(void, InterpreterRuntime::register_finalizer(JavaThread* current, oopDesc* obj))\n@@ -292,1 +296,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::quicken_io_cc(JavaThread* thread))\n+JRT_ENTRY(void, InterpreterRuntime::quicken_io_cc(JavaThread* current))\n@@ -294,1 +298,1 @@\n-  LastFrameAccessor last_frame(thread);\n+  LastFrameAccessor last_frame(current);\n@@ -302,1 +306,1 @@\n-  thread->set_vm_result_2(klass);\n+  current->set_vm_result_2(klass);\n@@ -309,2 +313,2 @@\n-void InterpreterRuntime::note_trap_inner(JavaThread* thread, int reason,\n-                                         const methodHandle& trap_method, int trap_bci, TRAPS) {\n+void InterpreterRuntime::note_trap_inner(JavaThread* current, int reason,\n+                                         const methodHandle& trap_method, int trap_bci) {\n@@ -314,0 +318,2 @@\n+      ExceptionMark em(current);\n+      JavaThread* THREAD = current; \/\/ For exception macros.\n@@ -316,1 +322,2 @@\n-        assert((PENDING_EXCEPTION->is_a(SystemDictionary::OutOfMemoryError_klass())),\n+        \/\/ Only metaspace OOM is expected. No Java code executed.\n+        assert((PENDING_EXCEPTION->is_a(vmClasses::OutOfMemoryError_klass())),\n@@ -333,1 +340,1 @@\n-void InterpreterRuntime::note_trap(JavaThread* thread, int reason, TRAPS) {\n+void InterpreterRuntime::note_trap(JavaThread* current, int reason) {\n@@ -335,2 +342,2 @@\n-  LastFrameAccessor last_frame(thread);\n-  methodHandle trap_method(thread, last_frame.method());\n+  LastFrameAccessor last_frame(current);\n+  methodHandle trap_method(current, last_frame.method());\n@@ -338,1 +345,1 @@\n-  note_trap_inner(thread, reason, trap_method, trap_bci, THREAD);\n+  note_trap_inner(current, reason, trap_method, trap_bci);\n@@ -341,22 +348,0 @@\n-#ifdef CC_INTERP\n-\/\/ As legacy note_trap, but we have more arguments.\n-JRT_ENTRY(void, InterpreterRuntime::note_trap(JavaThread* thread, int reason, Method *method, int trap_bci))\n-  methodHandle trap_method(thread, method);\n-  note_trap_inner(thread, reason, trap_method, trap_bci, THREAD);\n-JRT_END\n-\n-\/\/ Class Deoptimization is not visible in BytecodeInterpreter, so we need a wrapper\n-\/\/ for each exception.\n-void InterpreterRuntime::note_nullCheck_trap(JavaThread* thread, Method *method, int trap_bci)\n-  { if (ProfileTraps) note_trap(thread, Deoptimization::Reason_null_check, method, trap_bci); }\n-void InterpreterRuntime::note_div0Check_trap(JavaThread* thread, Method *method, int trap_bci)\n-  { if (ProfileTraps) note_trap(thread, Deoptimization::Reason_div0_check, method, trap_bci); }\n-void InterpreterRuntime::note_rangeCheck_trap(JavaThread* thread, Method *method, int trap_bci)\n-  { if (ProfileTraps) note_trap(thread, Deoptimization::Reason_range_check, method, trap_bci); }\n-void InterpreterRuntime::note_classCheck_trap(JavaThread* thread, Method *method, int trap_bci)\n-  { if (ProfileTraps) note_trap(thread, Deoptimization::Reason_class_check, method, trap_bci); }\n-void InterpreterRuntime::note_arrayCheck_trap(JavaThread* thread, Method *method, int trap_bci)\n-  { if (ProfileTraps) note_trap(thread, Deoptimization::Reason_array_check, method, trap_bci); }\n-#endif \/\/ CC_INTERP\n-\n-\n@@ -383,1 +368,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::throw_StackOverflowError(JavaThread* thread))\n+JRT_ENTRY(void, InterpreterRuntime::throw_StackOverflowError(JavaThread* current))\n@@ -385,1 +370,1 @@\n-                                 SystemDictionary::StackOverflowError_klass(),\n+                                 vmClasses::StackOverflowError_klass(),\n@@ -392,1 +377,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::throw_delayed_StackOverflowError(JavaThread* thread))\n+JRT_ENTRY(void, InterpreterRuntime::throw_delayed_StackOverflowError(JavaThread* current))\n@@ -394,1 +379,1 @@\n-                                 SystemDictionary::StackOverflowError_klass(),\n+                                 vmClasses::StackOverflowError_klass(),\n@@ -403,1 +388,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::create_exception(JavaThread* thread, char* name, char* message))\n+JRT_ENTRY(void, InterpreterRuntime::create_exception(JavaThread* current, char* name, char* message))\n@@ -408,1 +393,1 @@\n-      note_trap(thread, Deoptimization::Reason_div0_check, CHECK);\n+      note_trap(current, Deoptimization::Reason_div0_check);\n@@ -410,1 +395,1 @@\n-      note_trap(thread, Deoptimization::Reason_null_check, CHECK);\n+      note_trap(current, Deoptimization::Reason_null_check);\n@@ -414,2 +399,2 @@\n-  Handle exception = Exceptions::new_exception(thread, s, message);\n-  thread->set_vm_result(exception());\n+  Handle exception = Exceptions::new_exception(current, s, message);\n+  current->set_vm_result(exception());\n@@ -419,1 +404,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::create_klass_exception(JavaThread* thread, char* name, oopDesc* obj))\n+JRT_ENTRY(void, InterpreterRuntime::create_klass_exception(JavaThread* current, char* name, oopDesc* obj))\n@@ -421,1 +406,1 @@\n-  ResourceMark rm(thread);\n+  ResourceMark rm(current);\n@@ -426,1 +411,1 @@\n-    note_trap(thread, Deoptimization::Reason_class_check, CHECK);\n+    note_trap(current, Deoptimization::Reason_class_check);\n@@ -429,2 +414,2 @@\n-  Handle exception = Exceptions::new_exception(thread, s, klass_name);\n-  thread->set_vm_result(exception());\n+  Handle exception = Exceptions::new_exception(current, s, klass_name);\n+  current->set_vm_result(exception());\n@@ -433,1 +418,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::throw_ArrayIndexOutOfBoundsException(JavaThread* thread, arrayOopDesc* a, jint index))\n+JRT_ENTRY(void, InterpreterRuntime::throw_ArrayIndexOutOfBoundsException(JavaThread* current, arrayOopDesc* a, jint index))\n@@ -435,1 +420,1 @@\n-  ResourceMark rm(thread);\n+  ResourceMark rm(current);\n@@ -440,1 +425,1 @@\n-    note_trap(thread, Deoptimization::Reason_range_check, CHECK);\n+    note_trap(current, Deoptimization::Reason_range_check);\n@@ -447,1 +432,1 @@\n-  JavaThread* thread, oopDesc* obj))\n+  JavaThread* current, oopDesc* obj))\n@@ -450,1 +435,1 @@\n-  ResourceMark rm(thread);\n+  ResourceMark rm(current);\n@@ -452,1 +437,1 @@\n-    thread, obj->klass());\n+    current, obj->klass());\n@@ -455,1 +440,1 @@\n-    note_trap(thread, Deoptimization::Reason_class_check, CHECK);\n+    note_trap(current, Deoptimization::Reason_class_check);\n@@ -470,6 +455,10 @@\n-JRT_ENTRY(address, InterpreterRuntime::exception_handler_for_exception(JavaThread* thread, oopDesc* exception))\n-\n-  LastFrameAccessor last_frame(thread);\n-  Handle             h_exception(thread, exception);\n-  methodHandle       h_method   (thread, last_frame.method());\n-  constantPoolHandle h_constants(thread, h_method->constants());\n+JRT_ENTRY(address, InterpreterRuntime::exception_handler_for_exception(JavaThread* current, oopDesc* exception))\n+  \/\/ We get here after we have unwound from a callee throwing an exception\n+  \/\/ into the interpreter. Any deferred stack processing is notified of\n+  \/\/ the event via the StackWatermarkSet.\n+  StackWatermarkSet::after_unwind(current);\n+\n+  LastFrameAccessor last_frame(current);\n+  Handle             h_exception(current, exception);\n+  methodHandle       h_method   (current, last_frame.method());\n+  constantPoolHandle h_constants(current, h_method->constants());\n@@ -480,1 +469,1 @@\n-  if (thread->frames_to_pop_failed_realloc() > 0) {\n+  if (current->frames_to_pop_failed_realloc() > 0) {\n@@ -483,2 +472,2 @@\n-    thread->dec_frames_to_pop_failed_realloc();\n-    thread->set_vm_result(h_exception());\n+    current->dec_frames_to_pop_failed_realloc();\n+    current->set_vm_result(h_exception());\n@@ -488,4 +477,1 @@\n-    thread->set_do_not_unlock_if_synchronized(true);\n-#ifdef CC_INTERP\n-    return (address) -1;\n-#else\n+    current->set_do_not_unlock_if_synchronized(true);\n@@ -493,1 +479,0 @@\n-#endif\n@@ -500,1 +485,1 @@\n-  if (thread->do_not_unlock_if_synchronized()) {\n+  if (current->do_not_unlock_if_synchronized()) {\n@@ -503,4 +488,1 @@\n-    thread->set_vm_result(exception);\n-#ifdef CC_INTERP\n-    return (address) -1;\n-#else\n+    current->set_vm_result(exception);\n@@ -508,1 +490,0 @@\n-#endif\n@@ -515,7 +496,3 @@\n-#ifdef ASSERT\n-    \/\/ Check that exception is a subclass of Throwable, otherwise we have a VerifyError\n-    if (!(h_exception->is_a(SystemDictionary::Throwable_klass()))) {\n-      if (ExitVMOnVerifyError) vm_exit(-1);\n-      ShouldNotReachHere();\n-    }\n-#endif\n+    \/\/ Check that exception is a subclass of Throwable.\n+    assert(h_exception->is_a(vmClasses::Throwable_klass()),\n+           \"Exception not subclass of Throwable\");\n@@ -526,1 +503,1 @@\n-      ResourceMark rm(thread);\n+      ResourceMark rm(current);\n@@ -530,1 +507,1 @@\n-                   h_method->print_value_string(), current_bci, p2i(thread), thread->name());\n+                   h_method->print_value_string(), current_bci, p2i(current), current->name());\n@@ -563,1 +540,1 @@\n-    ResourceMark rm(thread);\n+    ResourceMark rm(current);\n@@ -575,1 +552,1 @@\n-    JvmtiExport::post_exception_throw(thread, h_method(), last_frame.bcp(), h_exception());\n+    JvmtiExport::post_exception_throw(current, h_method(), last_frame.bcp(), h_exception());\n@@ -578,5 +555,1 @@\n-#ifdef CC_INTERP\n-  address continuation = (address)(intptr_t) handler_bci;\n-#else\n-#endif\n-  if (handler_bci < 0 || !thread->reguard_stack((address) &continuation)) {\n+  if (handler_bci < 0 || !current->stack_overflow_state()->reguard_stack((address) &continuation)) {\n@@ -588,2 +561,0 @@\n-#ifndef CC_INTERP\n-#endif\n@@ -598,2 +569,2 @@\n-#ifndef CC_INTERP\n-    set_bcp_and_mdp(handler_pc, thread);\n+#ifndef ZERO\n+    set_bcp_and_mdp(handler_pc, current);\n@@ -601,0 +572,2 @@\n+#else\n+    continuation = (address)(intptr_t) handler_bci;\n@@ -603,0 +576,1 @@\n+\n@@ -606,1 +580,1 @@\n-    JvmtiExport::notice_unwind_due_to_exception(thread, h_method(), handler_pc, h_exception(), (handler_pc != NULL));\n+    JvmtiExport::notice_unwind_due_to_exception(current, h_method(), handler_pc, h_exception(), (handler_pc != NULL));\n@@ -609,1 +583,1 @@\n-  thread->set_vm_result(h_exception());\n+  current->set_vm_result(h_exception());\n@@ -614,2 +588,2 @@\n-JRT_ENTRY(void, InterpreterRuntime::throw_pending_exception(JavaThread* thread))\n-  assert(thread->has_pending_exception(), \"must only ne called if there's an exception pending\");\n+JRT_ENTRY(void, InterpreterRuntime::throw_pending_exception(JavaThread* current))\n+  assert(current->has_pending_exception(), \"must only be called if there's an exception pending\");\n@@ -620,1 +594,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::throw_AbstractMethodError(JavaThread* thread))\n+JRT_ENTRY(void, InterpreterRuntime::throw_AbstractMethodError(JavaThread* current))\n@@ -630,1 +604,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::throw_AbstractMethodErrorWithMethod(JavaThread* thread,\n+JRT_ENTRY(void, InterpreterRuntime::throw_AbstractMethodErrorWithMethod(JavaThread* current,\n@@ -632,1 +606,1 @@\n-  ResourceMark rm(thread);\n+  ResourceMark rm(current);\n@@ -634,1 +608,1 @@\n-  methodHandle m(thread, missingMethod);\n+  methodHandle m(current, missingMethod);\n@@ -638,1 +612,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::throw_AbstractMethodErrorVerbose(JavaThread* thread,\n+JRT_ENTRY(void, InterpreterRuntime::throw_AbstractMethodErrorVerbose(JavaThread* current,\n@@ -641,2 +615,2 @@\n-  ResourceMark rm(thread);\n-  methodHandle mh = methodHandle(thread, missingMethod);\n+  ResourceMark rm(current);\n+  methodHandle mh = methodHandle(current, missingMethod);\n@@ -647,1 +621,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::throw_IncompatibleClassChangeError(JavaThread* thread))\n+JRT_ENTRY(void, InterpreterRuntime::throw_IncompatibleClassChangeError(JavaThread* current))\n@@ -651,1 +625,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::throw_IncompatibleClassChangeErrorVerbose(JavaThread* thread,\n+JRT_ENTRY(void, InterpreterRuntime::throw_IncompatibleClassChangeErrorVerbose(JavaThread* current,\n@@ -654,1 +628,1 @@\n-  ResourceMark rm(thread);\n+  ResourceMark rm(current);\n@@ -664,0 +638,4 @@\n+JRT_ENTRY(void, InterpreterRuntime::throw_NullPointerException(JavaThread* current))\n+  THROW(vmSymbols::java_lang_NullPointerException());\n+JRT_END\n+\n@@ -668,2 +646,1 @@\n-void InterpreterRuntime::resolve_get_put(JavaThread* thread, Bytecodes::Code bytecode) {\n-  Thread* THREAD = thread;\n+void InterpreterRuntime::resolve_get_put(JavaThread* current, Bytecodes::Code bytecode) {\n@@ -672,3 +649,3 @@\n-  LastFrameAccessor last_frame(thread);\n-  constantPoolHandle pool(thread, last_frame.method()->constants());\n-  methodHandle m(thread, last_frame.method());\n+  LastFrameAccessor last_frame(current);\n+  constantPoolHandle pool(current, last_frame.method()->constants());\n+  methodHandle m(current, last_frame.method());\n@@ -680,1 +657,2 @@\n-    JvmtiHideSingleStepping jhss(thread);\n+    JvmtiHideSingleStepping jhss(current);\n+    JavaThread* THREAD = current; \/\/ For exception macros.\n@@ -741,2 +719,1 @@\n-    is_tsan_ignore,\n-    pool->pool_holder()\n+    is_tsan_ignore\n@@ -755,1 +732,1 @@\n-JRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* thread, BasicObjectLock* elem))\n+JRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* current, BasicObjectLock* elem))\n@@ -757,1 +734,1 @@\n-  thread->last_frame().interpreter_frame_verify_monitor(elem);\n+  current->last_frame().interpreter_frame_verify_monitor(elem);\n@@ -762,1 +739,1 @@\n-  Handle h_obj(thread, elem->obj());\n+  Handle h_obj(current, elem->obj());\n@@ -765,1 +742,1 @@\n-  ObjectSynchronizer::enter(h_obj, elem->lock(), CHECK);\n+  ObjectSynchronizer::enter(h_obj, elem->lock(), current);\n@@ -769,1 +746,1 @@\n-  thread->last_frame().interpreter_frame_verify_monitor(elem);\n+  current->last_frame().interpreter_frame_verify_monitor(elem);\n@@ -774,10 +751,10 @@\n-\/\/%note monitor_1\n-JRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorexit(JavaThread* thread, BasicObjectLock* elem))\n-#ifdef ASSERT\n-  thread->last_frame().interpreter_frame_verify_monitor(elem);\n-#endif\n-  Handle h_obj(thread, elem->obj());\n-  assert(Universe::heap()->is_in_or_null(h_obj()),\n-         \"must be NULL or an object\");\n-  if (elem == NULL || h_obj()->is_unlocked()) {\n-    THROW(vmSymbols::java_lang_IllegalMonitorStateException());\n+JRT_LEAF(void, InterpreterRuntime::monitorexit(BasicObjectLock* elem))\n+  oop obj = elem->obj();\n+  assert(Universe::heap()->is_in(obj), \"must be an object\");\n+  \/\/ The object could become unlocked through a JNI call, which we have no other checks for.\n+  \/\/ Give a fatal message if CheckJNICalls. Otherwise we ignore it.\n+  if (obj->is_unlocked()) {\n+    if (CheckJNICalls) {\n+      fatal(\"Object has been unlocked by JNI\");\n+    }\n+    return;\n@@ -785,3 +762,3 @@\n-  ObjectSynchronizer::exit(h_obj(), elem->lock(), thread);\n-  \/\/ Free entry. This must be done here, since a pending exception might be installed on\n-  \/\/ exit. If it is not cleared, the exception handling code will try to unlock the monitor again.\n+  ObjectSynchronizer::exit(obj, elem->lock(), JavaThread::current());\n+  \/\/ Free entry. If it is not cleared, the exception handling code will try to unlock the monitor\n+  \/\/ again at method exit or in the case of an exception.\n@@ -789,3 +766,0 @@\n-#ifdef ASSERT\n-  thread->last_frame().interpreter_frame_verify_monitor(elem);\n-#endif\n@@ -795,1 +769,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::throw_illegal_monitor_state_exception(JavaThread* thread))\n+JRT_ENTRY(void, InterpreterRuntime::throw_illegal_monitor_state_exception(JavaThread* current))\n@@ -800,1 +774,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::new_illegal_monitor_state_exception(JavaThread* thread))\n+JRT_ENTRY(void, InterpreterRuntime::new_illegal_monitor_state_exception(JavaThread* current))\n@@ -807,1 +781,1 @@\n-  Handle exception(thread, thread->vm_result());\n+  Handle exception(current, current->vm_result());\n@@ -809,2 +783,2 @@\n-  thread->set_vm_result(NULL); \/\/ clear vm result before continuing (may cause memory leaks and assert failures)\n-  if (!exception->is_a(SystemDictionary::ThreadDeath_klass())) {\n+  current->set_vm_result(NULL); \/\/ clear vm result before continuing (may cause memory leaks and assert failures)\n+  if (!exception->is_a(vmClasses::ThreadDeath_klass())) {\n@@ -812,1 +786,1 @@\n-                       SystemDictionary::IllegalMonitorStateException_klass(),\n+                       vmClasses::IllegalMonitorStateException_klass(),\n@@ -815,1 +789,1 @@\n-  thread->set_vm_result(exception());\n+  current->set_vm_result(exception());\n@@ -822,1 +796,1 @@\n-JRT_ENTRY(Bytecodes::Code, InterpreterRuntime::get_original_bytecode_at(JavaThread* thread, Method* method, address bcp))\n+JRT_ENTRY(Bytecodes::Code, InterpreterRuntime::get_original_bytecode_at(JavaThread* current, Method* method, address bcp))\n@@ -826,1 +800,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::set_original_bytecode_at(JavaThread* thread, Method* method, address bcp, Bytecodes::Code new_code))\n+JRT_ENTRY(void, InterpreterRuntime::set_original_bytecode_at(JavaThread* current, Method* method, address bcp, Bytecodes::Code new_code))\n@@ -830,2 +804,2 @@\n-JRT_ENTRY(void, InterpreterRuntime::_breakpoint(JavaThread* thread, Method* method, address bcp))\n-  JvmtiExport::post_raw_breakpoint(thread, method, bcp);\n+JRT_ENTRY(void, InterpreterRuntime::_breakpoint(JavaThread* current, Method* method, address bcp))\n+  JvmtiExport::post_raw_breakpoint(current, method, bcp);\n@@ -834,3 +808,2 @@\n-void InterpreterRuntime::resolve_invoke(JavaThread* thread, Bytecodes::Code bytecode) {\n-  Thread* THREAD = thread;\n-  LastFrameAccessor last_frame(thread);\n+void InterpreterRuntime::resolve_invoke(JavaThread* current, Bytecodes::Code bytecode) {\n+  LastFrameAccessor last_frame(current);\n@@ -838,1 +811,1 @@\n-  Handle receiver(thread, NULL);\n+  Handle receiver(current, NULL);\n@@ -841,2 +814,2 @@\n-    ResourceMark rm(thread);\n-    methodHandle m (thread, last_frame.method());\n+    ResourceMark rm(current);\n+    methodHandle m (current, last_frame.method());\n@@ -845,1 +818,1 @@\n-    receiver = Handle(thread, last_frame.callee_receiver(signature));\n+    receiver = Handle(current, last_frame.callee_receiver(signature));\n@@ -856,1 +829,3 @@\n-  constantPoolHandle pool(thread, last_frame.method()->constants());\n+  constantPoolHandle pool(current, last_frame.method()->constants());\n+\n+  methodHandle resolved_method;\n@@ -859,1 +834,2 @@\n-    JvmtiHideSingleStepping jhss(thread);\n+    JvmtiHideSingleStepping jhss(current);\n+    JavaThread* THREAD = current; \/\/ For exception macros.\n@@ -863,13 +839,4 @@\n-    if (JvmtiExport::can_hotswap_or_post_breakpoint()) {\n-      int retry_count = 0;\n-      while (info.resolved_method()->is_old()) {\n-        \/\/ It is very unlikely that method is redefined more than 100 times\n-        \/\/ in the middle of resolve. If it is looping here more than 100 times\n-        \/\/ means then there could be a bug here.\n-        guarantee((retry_count++ < 100),\n-                  \"Could not resolve to latest version of redefined method\");\n-        \/\/ method is redefined in the middle of resolve so re-try.\n-        LinkResolver::resolve_invoke(info, receiver, pool,\n-                                     last_frame.get_index_u2_cpcache(bytecode), bytecode,\n-                                     CHECK);\n-      }\n+    if (JvmtiExport::can_hotswap_or_post_breakpoint() && info.resolved_method()->is_old()) {\n+      resolved_method = methodHandle(current, info.resolved_method()->get_new_method());\n+    } else {\n+      resolved_method = methodHandle(current, info.resolved_method());\n@@ -885,2 +852,1 @@\n-    if (info.resolved_method()->method_holder() ==\n-                                            SystemDictionary::Object_klass()) {\n+    if (resolved_method->method_holder() == vmClasses::Object_klass()) {\n@@ -891,2 +857,1 @@\n-      Method* rm = info.resolved_method();\n-      assert(rm->is_final() || info.has_vtable_index(),\n+      assert(resolved_method->is_final() || info.has_vtable_index(),\n@@ -894,1 +859,1 @@\n-    } else if (!info.resolved_method()->has_itable_index()) {\n+    } else if (!resolved_method->has_itable_index()) {\n@@ -900,1 +865,1 @@\n-      int index = info.resolved_method()->itable_index();\n+      int index = resolved_method->itable_index();\n@@ -910,2 +875,2 @@\n-  \/\/ Get sender or sender's unsafe_anonymous_host, and only set cpCache entry to resolved if\n-  \/\/ it is not an interface.  The receiver for invokespecial calls within interface\n+  \/\/ Get sender and only set cpCache entry to resolved if it is not an\n+  \/\/ interface.  The receiver for invokespecial calls within interface\n@@ -914,2 +879,0 @@\n-  sender = sender->is_unsafe_anonymous() ? sender->unsafe_anonymous_host() : sender;\n-  methodHandle resolved_method(THREAD, info.resolved_method());\n@@ -943,2 +906,1 @@\n-void InterpreterRuntime::resolve_invokehandle(JavaThread* thread) {\n-  Thread* THREAD = thread;\n+void InterpreterRuntime::resolve_invokehandle(JavaThread* current) {\n@@ -946,1 +908,1 @@\n-  LastFrameAccessor last_frame(thread);\n+  LastFrameAccessor last_frame(current);\n@@ -950,1 +912,1 @@\n-  constantPoolHandle pool(thread, last_frame.method()->constants());\n+  constantPoolHandle pool(current, last_frame.method()->constants());\n@@ -952,1 +914,2 @@\n-    JvmtiHideSingleStepping jhss(thread);\n+    JvmtiHideSingleStepping jhss(current);\n+    JavaThread* THREAD = current; \/\/ For exception macros.\n@@ -963,3 +926,2 @@\n-void InterpreterRuntime::resolve_invokedynamic(JavaThread* thread) {\n-  Thread* THREAD = thread;\n-  LastFrameAccessor last_frame(thread);\n+void InterpreterRuntime::resolve_invokedynamic(JavaThread* current) {\n+  LastFrameAccessor last_frame(current);\n@@ -970,1 +932,1 @@\n-  constantPoolHandle pool(thread, last_frame.method()->constants());\n+  constantPoolHandle pool(current, last_frame.method()->constants());\n@@ -973,1 +935,2 @@\n-    JvmtiHideSingleStepping jhss(thread);\n+    JvmtiHideSingleStepping jhss(current);\n+    JavaThread* THREAD = current; \/\/ For exception macros.\n@@ -985,1 +948,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::resolve_from_cache(JavaThread* thread, Bytecodes::Code bytecode)) {\n+JRT_ENTRY(void, InterpreterRuntime::resolve_from_cache(JavaThread* current, Bytecodes::Code bytecode)) {\n@@ -991,1 +954,1 @@\n-    resolve_get_put(thread, bytecode);\n+    resolve_get_put(current, bytecode);\n@@ -997,1 +960,1 @@\n-    resolve_invoke(thread, bytecode);\n+    resolve_invoke(current, bytecode);\n@@ -1000,1 +963,1 @@\n-    resolve_invokehandle(thread);\n+    resolve_invokehandle(current);\n@@ -1003,1 +966,1 @@\n-    resolve_invokedynamic(thread);\n+    resolve_invokedynamic(current);\n@@ -1016,2 +979,6 @@\n-nmethod* InterpreterRuntime::frequency_counter_overflow(JavaThread* thread, address branch_bcp) {\n-  nmethod* nm = frequency_counter_overflow_inner(thread, branch_bcp);\n+nmethod* InterpreterRuntime::frequency_counter_overflow(JavaThread* current, address branch_bcp) {\n+  \/\/ Enable WXWrite: the function is called directly by interpreter.\n+  MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXWrite, current));\n+\n+  \/\/ frequency_counter_overflow_inner can throw async exception.\n+  nmethod* nm = frequency_counter_overflow_inner(current, branch_bcp);\n@@ -1025,1 +992,1 @@\n-    LastFrameAccessor last_frame(thread);\n+    LastFrameAccessor last_frame(current);\n@@ -1037,1 +1004,1 @@\n-  if (nm != NULL && thread->is_interp_only_mode()) {\n+  if (nm != NULL && current->is_interp_only_mode()) {\n@@ -1057,4 +1024,1 @@\n-          InterpreterRuntime::frequency_counter_overflow_inner(JavaThread* thread, address branch_bcp))\n-  if (HAS_PENDING_EXCEPTION) {\n-    return NULL;\n-  }\n+          InterpreterRuntime::frequency_counter_overflow_inner(JavaThread* current, address branch_bcp))\n@@ -1063,1 +1027,1 @@\n-  UnlockFlagSaver fs(thread);\n+  UnlockFlagSaver fs(current);\n@@ -1065,1 +1029,1 @@\n-  LastFrameAccessor last_frame(thread);\n+  LastFrameAccessor last_frame(current);\n@@ -1067,1 +1031,1 @@\n-  methodHandle method(thread, last_frame.method());\n+  methodHandle method(current, last_frame.method());\n@@ -1071,2 +1035,1 @@\n-  nmethod* osr_nm = CompilationPolicy::policy()->event(method, method, branch_bci, bci, CompLevel_none, NULL, thread);\n-  assert(!HAS_PENDING_EXCEPTION, \"Event handler should not throw any exceptions\");\n+  nmethod* osr_nm = CompilationPolicy::event(method, method, branch_bci, bci, CompLevel_none, NULL, CHECK_NULL);\n@@ -1095,1 +1058,1 @@\n-          objects_to_revoke->append(Handle(THREAD, kptr->obj()));\n+          objects_to_revoke->append(Handle(current, kptr->obj()));\n@@ -1098,1 +1061,1 @@\n-      BiasedLocking::revoke(objects_to_revoke, thread);\n+      BiasedLocking::revoke(objects_to_revoke, current);\n@@ -1112,21 +1075,0 @@\n-JRT_ENTRY(void, InterpreterRuntime::profile_method(JavaThread* thread))\n-  if (HAS_PENDING_EXCEPTION) {\n-    return;\n-  }\n-  \/\/ use UnlockFlagSaver to clear and restore the _do_not_unlock_if_synchronized\n-  \/\/ flag, in case this method triggers classloading which will call into Java.\n-  UnlockFlagSaver fs(thread);\n-\n-  assert(ProfileInterpreter, \"must be profiling interpreter\");\n-  LastFrameAccessor last_frame(thread);\n-  assert(last_frame.is_interpreted_frame(), \"must come from interpreter\");\n-  methodHandle method(thread, last_frame.method());\n-  Method::build_interpreter_method_data(method, THREAD);\n-  if (HAS_PENDING_EXCEPTION) {\n-    assert((PENDING_EXCEPTION->is_a(SystemDictionary::OutOfMemoryError_klass())), \"we expect only an OOM error here\");\n-    CLEAR_PENDING_EXCEPTION;\n-    \/\/ and fall through...\n-  }\n-JRT_END\n-\n-\n@@ -1145,2 +1087,0 @@\n-    ResetNoHandleMark rnm; \/\/ In a LEAF entry.\n-    HandleMark hm;\n@@ -1164,1 +1104,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::update_mdp_for_ret(JavaThread* thread, int return_bci))\n+JRT_ENTRY(void, InterpreterRuntime::update_mdp_for_ret(JavaThread* current, int return_bci))\n@@ -1166,3 +1106,2 @@\n-  ResourceMark rm(thread);\n-  HandleMark hm(thread);\n-  LastFrameAccessor last_frame(thread);\n+  ResourceMark rm(current);\n+  LastFrameAccessor last_frame(current);\n@@ -1185,7 +1124,2 @@\n-JRT_ENTRY(MethodCounters*, InterpreterRuntime::build_method_counters(JavaThread* thread, Method* m))\n-  MethodCounters* mcs = Method::build_method_counters(m, thread);\n-  if (HAS_PENDING_EXCEPTION) {\n-    assert((PENDING_EXCEPTION->is_a(SystemDictionary::OutOfMemoryError_klass())), \"we expect only an OOM error here\");\n-    CLEAR_PENDING_EXCEPTION;\n-  }\n-  return mcs;\n+JRT_ENTRY(MethodCounters*, InterpreterRuntime::build_method_counters(JavaThread* current, Method* m))\n+  return Method::build_method_counters(current, m);\n@@ -1195,1 +1129,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::at_safepoint(JavaThread* thread))\n+JRT_ENTRY(void, InterpreterRuntime::at_safepoint(JavaThread* current))\n@@ -1204,0 +1138,5 @@\n+    \/\/ This function is called by the interpreter when single stepping. Such single\n+    \/\/ stepping could unwind a frame. Then, it is important that we process any frames\n+    \/\/ that we might return into.\n+    StackWatermarkSet::before_unwind(current);\n+\n@@ -1207,2 +1146,2 @@\n-    LastFrameAccessor last_frame(thread);\n-    JvmtiExport::at_single_stepping_point(thread, last_frame.method(), last_frame.bcp());\n+    LastFrameAccessor last_frame(current);\n+    JvmtiExport::at_single_stepping_point(current, last_frame.method(), last_frame.bcp());\n@@ -1212,2 +1151,13 @@\n-JRT_ENTRY(void, InterpreterRuntime::post_field_access(JavaThread *thread, oopDesc* obj,\n-ConstantPoolCacheEntry *cp_entry))\n+JRT_LEAF(void, InterpreterRuntime::at_unwind(JavaThread* current))\n+  \/\/ This function is called by the interpreter when the return poll found a reason\n+  \/\/ to call the VM. The reason could be that we are returning into a not yet safe\n+  \/\/ to access frame. We handle that below.\n+  \/\/ Note that this path does not check for single stepping, because we do not want\n+  \/\/ to single step when unwinding frames for an exception being thrown. Instead,\n+  \/\/ such single stepping code will use the safepoint table, which will use the\n+  \/\/ InterpreterRuntime::at_safepoint callback.\n+  StackWatermarkSet::before_unwind(current);\n+JRT_END\n+\n+JRT_ENTRY(void, InterpreterRuntime::post_field_access(JavaThread* current, oopDesc* obj,\n+                                                      ConstantPoolCacheEntry *cp_entry))\n@@ -1222,1 +1172,1 @@\n-  HandleMark hm(thread);\n+  HandleMark hm(current);\n@@ -1227,1 +1177,1 @@\n-    h_obj = Handle(thread, obj);\n+    h_obj = Handle(current, obj);\n@@ -1231,2 +1181,2 @@\n-  LastFrameAccessor last_frame(thread);\n-  JvmtiExport::post_field_access(thread, last_frame.method(), last_frame.bcp(), cp_entry_f1, h_obj, fid);\n+  LastFrameAccessor last_frame(current);\n+  JvmtiExport::post_field_access(current, last_frame.method(), last_frame.bcp(), cp_entry_f1, h_obj, fid);\n@@ -1235,2 +1185,2 @@\n-JRT_ENTRY(void, InterpreterRuntime::post_field_modification(JavaThread *thread,\n-  oopDesc* obj, ConstantPoolCacheEntry *cp_entry, jvalue *value))\n+JRT_ENTRY(void, InterpreterRuntime::post_field_modification(JavaThread* current, oopDesc* obj,\n+                                                            ConstantPoolCacheEntry *cp_entry, jvalue *value))\n@@ -1262,1 +1212,1 @@\n-  HandleMark hm(thread);\n+  HandleMark hm(current);\n@@ -1284,1 +1234,1 @@\n-    h_obj = Handle(thread, obj);\n+    h_obj = Handle(current, obj);\n@@ -1287,2 +1237,2 @@\n-  LastFrameAccessor last_frame(thread);\n-  JvmtiExport::post_raw_field_modification(thread, last_frame.method(), last_frame.bcp(), ik, h_obj,\n+  LastFrameAccessor last_frame(current);\n+  JvmtiExport::post_raw_field_modification(current, last_frame.method(), last_frame.bcp(), ik, h_obj,\n@@ -1292,3 +1242,3 @@\n-JRT_ENTRY(void, InterpreterRuntime::post_method_entry(JavaThread *thread))\n-  LastFrameAccessor last_frame(thread);\n-  JvmtiExport::post_method_entry(thread, last_frame.method(), last_frame.get_frame());\n+JRT_ENTRY(void, InterpreterRuntime::post_method_entry(JavaThread* current))\n+  LastFrameAccessor last_frame(current);\n+  JvmtiExport::post_method_entry(current, last_frame.method(), last_frame.get_frame());\n@@ -1298,3 +1248,6 @@\n-JRT_ENTRY(void, InterpreterRuntime::post_method_exit(JavaThread *thread))\n-  LastFrameAccessor last_frame(thread);\n-  JvmtiExport::post_method_exit(thread, last_frame.method(), last_frame.get_frame());\n+\/\/ This is a JRT_BLOCK_ENTRY because we have to stash away the return oop\n+\/\/ before transitioning to VM, and restore it after transitioning back\n+\/\/ to Java. The return oop at the top-of-stack, is not walked by the GC.\n+JRT_BLOCK_ENTRY(void, InterpreterRuntime::post_method_exit(JavaThread* current))\n+  LastFrameAccessor last_frame(current);\n+  JvmtiExport::post_method_exit(current, last_frame.method(), last_frame.get_frame());\n@@ -1343,2 +1296,2 @@\n-  _fingerprints = new(ResourceObj::C_HEAP, mtCode)GrowableArray<uint64_t>(32, true);\n-  _handlers     = new(ResourceObj::C_HEAP, mtCode)GrowableArray<address>(32, true);\n+  _fingerprints = new(ResourceObj::C_HEAP, mtCode)GrowableArray<uint64_t>(32, mtCode);\n+  _handlers     = new(ResourceObj::C_HEAP, mtCode)GrowableArray<address>(32, mtCode);\n@@ -1435,1 +1388,1 @@\n-      DEBUG_ONLY(Thread::current()->check_possible_safepoint());\n+      DEBUG_ONLY(JavaThread::current()->check_possible_safepoint());\n@@ -1500,2 +1453,2 @@\n-JRT_ENTRY(void, InterpreterRuntime::prepare_native_call(JavaThread* thread, Method* method))\n-  methodHandle m(thread, method);\n+JRT_ENTRY(void, InterpreterRuntime::prepare_native_call(JavaThread* current, Method* method))\n+  methodHandle m(current, method);\n@@ -1504,2 +1457,1 @@\n-  bool in_base_library;\n-    NativeLookup::lookup(m, in_base_library, CHECK);\n+    NativeLookup::lookup(m, CHECK);\n@@ -1517,1 +1469,1 @@\n-JRT_LEAF(void, InterpreterRuntime::popframe_move_outgoing_args(JavaThread* thread, void* src_address, void* dest_address))\n+JRT_LEAF(void, InterpreterRuntime::popframe_move_outgoing_args(JavaThread* current, void* src_address, void* dest_address))\n@@ -1521,3 +1473,1 @@\n-  ResetNoHandleMark rnm; \/\/ In a LEAF entry.\n-  HandleMark hm;\n-  LastFrameAccessor last_frame(thread);\n+  LastFrameAccessor last_frame(current);\n@@ -1527,1 +1477,1 @@\n-  methodHandle mh(thread, last_frame.method());\n+  methodHandle mh(current, last_frame.method());\n@@ -1543,1 +1493,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::member_name_arg_or_null(JavaThread* thread, address member_name,\n+JRT_ENTRY(void, InterpreterRuntime::member_name_arg_or_null(JavaThread* current, address member_name,\n@@ -1555,1 +1505,1 @@\n-    oop member_name_oop = (oop) member_name;\n+    oop member_name_oop = cast_to_oop(member_name);\n@@ -1560,1 +1510,1 @@\n-    thread->set_vm_result(member_name_oop);\n+    current->set_vm_result(member_name_oop);\n@@ -1562,1 +1512,1 @@\n-    thread->set_vm_result(NULL);\n+    current->set_vm_result(NULL);\n@@ -1572,2 +1522,2 @@\n-JRT_LEAF(intptr_t, InterpreterRuntime::trace_bytecode(JavaThread* thread, intptr_t preserve_this_value, intptr_t tos, intptr_t tos2))\n-  LastFrameAccessor last_frame(thread);\n+JRT_LEAF(intptr_t, InterpreterRuntime::trace_bytecode(JavaThread* current, intptr_t preserve_this_value, intptr_t tos, intptr_t tos2))\n+  LastFrameAccessor last_frame(current);\n@@ -1575,1 +1525,1 @@\n-  methodHandle mh(thread, last_frame.method());\n+  methodHandle mh(current, last_frame.method());\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":262,"deletions":312,"binary":false,"changes":574,"status":"modified"},{"patch":"@@ -33,1 +33,1 @@\n-#ifdef CC_INTERP\n+#ifdef ZERO\n@@ -525,2 +525,0 @@\n-  \/\/ platform specific bytecodes\n-  pd_initialize();\n@@ -532,1 +530,1 @@\n-#endif \/* !CC_INTERP *\/\n+#endif \/* !ZERO *\/\n","filename":"src\/hotspot\/share\/interpreter\/templateTable.cpp","additions":2,"deletions":4,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -33,1 +33,1 @@\n-#ifndef CC_INTERP\n+#ifndef ZERO\n@@ -238,1 +238,0 @@\n-  static void count_calls(Register method, Register temp);\n@@ -331,1 +330,1 @@\n- static void def(Bytecodes::Code code, int flags, TosState in, TosState out, void (*gen)(bool arg    ), bool arg    );\n+  static void def(Bytecodes::Code code, int flags, TosState in, TosState out, void (*gen)(bool arg    ), bool arg    );\n@@ -344,1 +343,0 @@\n-  static void pd_initialize();\n@@ -387,1 +385,1 @@\n-#endif \/* !CC_INTERP *\/\n+#endif \/* !ZERO *\/\n","filename":"src\/hotspot\/share\/interpreter\/templateTable.hpp","additions":3,"deletions":5,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,0 +26,1 @@\n+#include \"cds\/heapShared.hpp\"\n@@ -27,0 +28,2 @@\n+#include \"classfile\/systemDictionary.hpp\"\n+#include \"classfile\/vmClasses.hpp\"\n@@ -34,1 +37,0 @@\n-#include \"memory\/heapShared.hpp\"\n@@ -37,1 +39,0 @@\n-#include \"memory\/metaspaceShared.hpp\"\n@@ -46,0 +47,1 @@\n+#include \"runtime\/arguments.hpp\"\n@@ -48,0 +50,1 @@\n+#include \"runtime\/vm_version.hpp\"\n@@ -136,2 +139,1 @@\n-                                       bool is_tsan_ignore,\n-                                       Klass* root_klass) {\n+                                       bool is_tsan_ignore) {\n@@ -205,1 +207,1 @@\n-        assert(holder->is_interface() || holder == SystemDictionary::Object_klass(), \"unexpected holder class\");\n+        assert(holder->is_interface() || holder == vmClasses::Object_klass(), \"unexpected holder class\");\n@@ -307,1 +309,1 @@\n-                (method->is_final() && method->method_holder() == SystemDictionary::Object_klass())))),\n+                (method->is_final() && method->method_holder() == vmClasses::Object_klass())))),\n@@ -376,1 +378,2 @@\n-  objArrayHandle resolved_references(Thread::current(), cpool->resolved_references());\n+  JavaThread* current = JavaThread::current();\n+  objArrayHandle resolved_references(current, cpool->resolved_references());\n@@ -382,1 +385,1 @@\n-  ObjectLocker ol(resolved_references, Thread::current());\n+  ObjectLocker ol(resolved_references, current);\n@@ -401,1 +404,1 @@\n-    Thread* THREAD = Thread::current();\n+    JavaThread* THREAD = JavaThread::current(); \/\/ For exception macros.\n@@ -478,1 +481,1 @@\n-  assert(PENDING_EXCEPTION->is_a(SystemDictionary::LinkageError_klass()),\n+  assert(PENDING_EXCEPTION->is_a(vmClasses::LinkageError_klass()),\n@@ -484,1 +487,2 @@\n-  objArrayHandle resolved_references(Thread::current(), cpool->resolved_references());\n+  JavaThread* current = THREAD;\n+  objArrayHandle resolved_references(current, cpool->resolved_references());\n@@ -487,1 +491,1 @@\n-  ObjectLocker ol(resolved_references, THREAD);\n+  ObjectLocker ol(resolved_references, current);\n@@ -730,1 +734,1 @@\n-  Thread* THREAD = Thread::current();\n+  Thread* current = Thread::current();\n@@ -735,1 +739,1 @@\n-    RawBytecodeStream bcs(methodHandle(THREAD, m));\n+    RawBytecodeStream bcs(methodHandle(current, m));\n@@ -778,1 +782,1 @@\n-  if (CompressedOops::is_null(_archived_references)) {\n+  if (_archived_references_index < 0) {\n@@ -781,1 +785,8 @@\n-  return HeapShared::materialize_archived_object(_archived_references);\n+  return HeapShared::get_root(_archived_references_index);\n+}\n+\n+void ConstantPoolCache::clear_archived_references() {\n+  if (_archived_references_index >= 0) {\n+    HeapShared::clear_root(_archived_references_index);\n+    _archived_references_index = -1;\n+  }\n@@ -786,1 +797,1 @@\n-  _archived_references = CompressedOops::encode(o);\n+  _archived_references_index = HeapShared::append_root(o);\n","filename":"src\/hotspot\/share\/oops\/cpCache.cpp","additions":29,"deletions":18,"binary":false,"changes":47,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -228,2 +228,1 @@\n-    bool            is_tsan_ignore,              \/\/ the field should be ignored by TSAN\n-    Klass*          root_klass                   \/\/ needed by the GC to dirty the klass\n+    bool            is_tsan_ignore               \/\/ the field should be ignored by TSAN\n@@ -422,1 +421,1 @@\n-  CDS_JAVA_HEAP_ONLY(narrowOop _archived_references;)\n+  CDS_JAVA_HEAP_ONLY(int _archived_references_index;)\n@@ -449,0 +448,1 @@\n+  void clear_archived_references() NOT_CDS_JAVA_HEAP_RETURN;\n","filename":"src\/hotspot\/share\/oops\/cpCache.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2011, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2011, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,0 +29,1 @@\n+#include \"oops\/symbol.hpp\"\n@@ -30,1 +31,1 @@\n-#include \"classfile\/vmSymbols.hpp\"\n+#include \"utilities\/vmEnums.hpp\"\n@@ -49,5 +50,2 @@\n-#define FIELDINFO_TAG_BLANK            0\n-#define FIELDINFO_TAG_OFFSET           1\n-#define FIELDINFO_TAG_TYPE_PLAIN       2\n-#define FIELDINFO_TAG_TYPE_CONTENDED   3\n-#define FIELDINFO_TAG_MASK             3\n+#define FIELDINFO_TAG_OFFSET           1 << 0\n+#define FIELDINFO_TAG_CONTENDED        1 << 1\n@@ -58,1 +56,3 @@\n-  \/\/    ..........................................00  - blank\n+  \/\/    ..........................................CO\n+  \/\/    ..........................................00  - non-contended field\n+  \/\/    [--contention_group--]....................10  - contended field with contention group\n@@ -60,2 +60,5 @@\n-  \/\/    ......................[-------type-------]10  - plain field with type\n-  \/\/    [--contention_group--][-------type-------]11  - contended field with type and contention group\n+\n+  \/\/ Bit O indicates if the packed field contains an offset (O=1) or not (O=0)\n+  \/\/ Bit C indicates if the field is contended (C=1) or not (C=0)\n+  \/\/       (if it is contended, the high packed field contains the contention group)\n+\n@@ -105,15 +108,2 @@\n-    u2 lo = _shorts[low_packed_offset];\n-    switch(lo & FIELDINFO_TAG_MASK) {\n-      case FIELDINFO_TAG_OFFSET:\n-        return build_int_from_shorts(_shorts[low_packed_offset], _shorts[high_packed_offset]) >> FIELDINFO_TAG_SIZE;\n-#ifndef PRODUCT\n-      case FIELDINFO_TAG_TYPE_PLAIN:\n-        fatal(\"Asking offset for the plain type field\");\n-      case FIELDINFO_TAG_TYPE_CONTENDED:\n-        fatal(\"Asking offset for the contended type field\");\n-      case FIELDINFO_TAG_BLANK:\n-        fatal(\"Asking offset for the blank field\");\n-#endif\n-    }\n-    ShouldNotReachHere();\n-    return 0;\n+    assert((_shorts[low_packed_offset] & FIELDINFO_TAG_OFFSET) != 0, \"Offset must have been set\");\n+    return build_int_from_shorts(_shorts[low_packed_offset], _shorts[high_packed_offset]) >> FIELDINFO_TAG_SIZE;\n@@ -123,15 +113,1 @@\n-    u2 lo = _shorts[low_packed_offset];\n-    switch(lo & FIELDINFO_TAG_MASK) {\n-      case FIELDINFO_TAG_TYPE_PLAIN:\n-        return false;\n-      case FIELDINFO_TAG_TYPE_CONTENDED:\n-        return true;\n-#ifndef PRODUCT\n-      case FIELDINFO_TAG_OFFSET:\n-        fatal(\"Asking contended flag for the field with offset\");\n-      case FIELDINFO_TAG_BLANK:\n-        fatal(\"Asking contended flag for the blank field\");\n-#endif\n-    }\n-    ShouldNotReachHere();\n-    return false;\n+    return (_shorts[low_packed_offset] & FIELDINFO_TAG_CONTENDED) != 0;\n@@ -141,15 +117,3 @@\n-    u2 lo = _shorts[low_packed_offset];\n-    switch(lo & FIELDINFO_TAG_MASK) {\n-      case FIELDINFO_TAG_TYPE_PLAIN:\n-        return 0;\n-      case FIELDINFO_TAG_TYPE_CONTENDED:\n-        return _shorts[high_packed_offset];\n-#ifndef PRODUCT\n-      case FIELDINFO_TAG_OFFSET:\n-        fatal(\"Asking the contended group for the field with offset\");\n-      case FIELDINFO_TAG_BLANK:\n-        fatal(\"Asking the contended group for the blank field\");\n-#endif\n-    }\n-    ShouldNotReachHere();\n-    return 0;\n+    assert((_shorts[low_packed_offset] & FIELDINFO_TAG_OFFSET) == 0, \"Offset must not have been set\");\n+    assert((_shorts[low_packed_offset] & FIELDINFO_TAG_CONTENDED) != 0, \"Field must be contended\");\n+    return _shorts[high_packed_offset];\n@@ -158,18 +122,1 @@\n-  u2 allocation_type() const {\n-    u2 lo = _shorts[low_packed_offset];\n-    switch(lo & FIELDINFO_TAG_MASK) {\n-      case FIELDINFO_TAG_TYPE_PLAIN:\n-      case FIELDINFO_TAG_TYPE_CONTENDED:\n-        return (lo >> FIELDINFO_TAG_SIZE);\n-#ifndef PRODUCT\n-      case FIELDINFO_TAG_OFFSET:\n-        fatal(\"Asking the field type for field with offset\");\n-      case FIELDINFO_TAG_BLANK:\n-        fatal(\"Asking the field type for the blank field\");\n-#endif\n-    }\n-    ShouldNotReachHere();\n-    return 0;\n-  }\n-\n-    return (_shorts[low_packed_offset] & FIELDINFO_TAG_MASK) == FIELDINFO_TAG_OFFSET;\n+    return (_shorts[low_packed_offset] & FIELDINFO_TAG_OFFSET)!= 0;\n@@ -202,34 +149,4 @@\n-  void set_allocation_type(int type) {\n-    u2 lo = _shorts[low_packed_offset];\n-    switch(lo & FIELDINFO_TAG_MASK) {\n-      case FIELDINFO_TAG_BLANK:\n-        _shorts[low_packed_offset] = ((type << FIELDINFO_TAG_SIZE)) & 0xFFFF;\n-        _shorts[low_packed_offset] &= ~FIELDINFO_TAG_MASK;\n-        _shorts[low_packed_offset] |= FIELDINFO_TAG_TYPE_PLAIN;\n-        return;\n-#ifndef PRODUCT\n-      case FIELDINFO_TAG_TYPE_PLAIN:\n-      case FIELDINFO_TAG_TYPE_CONTENDED:\n-      case FIELDINFO_TAG_OFFSET:\n-        fatal(\"Setting the field type with overwriting\");\n-#endif\n-    }\n-    ShouldNotReachHere();\n-  }\n-\n-    u2 lo = _shorts[low_packed_offset];\n-    switch(lo & FIELDINFO_TAG_MASK) {\n-      case FIELDINFO_TAG_TYPE_PLAIN:\n-        _shorts[low_packed_offset] |= FIELDINFO_TAG_TYPE_CONTENDED;\n-        _shorts[high_packed_offset] = val;\n-        return;\n-#ifndef PRODUCT\n-      case FIELDINFO_TAG_TYPE_CONTENDED:\n-        fatal(\"Overwriting contended group\");\n-      case FIELDINFO_TAG_BLANK:\n-        fatal(\"Setting contended group for the blank field\");\n-      case FIELDINFO_TAG_OFFSET:\n-        fatal(\"Setting contended group for field with offset\");\n-#endif\n-    }\n-    ShouldNotReachHere();\n+    assert((_shorts[low_packed_offset] & FIELDINFO_TAG_OFFSET) == 0, \"Offset must not have been set\");\n+    assert((_shorts[low_packed_offset] & FIELDINFO_TAG_CONTENDED) == 0, \"Overwritting contended group\");\n+    _shorts[low_packed_offset] |= FIELDINFO_TAG_CONTENDED;\n+    _shorts[high_packed_offset] = val;\n@@ -263,1 +180,1 @@\n-    return vmSymbols::symbol_at((vmSymbols::SID)symbol_index);\n+    return Symbol::vm_symbol_at(static_cast<vmSymbolID>(symbol_index));\n","filename":"src\/hotspot\/share\/oops\/fieldInfo.hpp","additions":25,"deletions":108,"binary":false,"changes":133,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,1 +27,3 @@\n-#include \"aot\/aotLoader.hpp\"\n+#include \"cds\/archiveUtils.hpp\"\n+#include \"cds\/classListWriter.hpp\"\n+#include \"cds\/metaspaceShared.hpp\"\n@@ -39,0 +41,1 @@\n+#include \"classfile\/vmClasses.hpp\"\n@@ -40,0 +43,1 @@\n+#include \"code\/codeCache.hpp\"\n@@ -41,0 +45,1 @@\n+#include \"compiler\/compilationPolicy.hpp\"\n@@ -53,1 +58,0 @@\n-#include \"memory\/metaspaceShared.hpp\"\n@@ -72,0 +76,1 @@\n+#include \"runtime\/arguments.hpp\"\n@@ -79,0 +84,1 @@\n+#include \"runtime\/reflectionUtils.hpp\"\n@@ -150,1 +156,1 @@\n-  if (SystemDictionary::ClassLoader_klass_loaded()) {\n+  if (vmClasses::ClassLoader_klass_loaded()) {\n@@ -153,1 +159,1 @@\n-      if (super_klass->is_subtype_of(SystemDictionary::ClassLoader_klass())) {\n+      if (super_klass->is_subtype_of(vmClasses::ClassLoader_klass())) {\n@@ -164,1 +170,1 @@\n-bool InstanceKlass::has_nest_member(InstanceKlass* k, TRAPS) const {\n+bool InstanceKlass::has_nest_member(JavaThread* current, InstanceKlass* k) const {\n@@ -168,1 +174,1 @@\n-      ResourceMark rm(THREAD);\n+      ResourceMark rm(current);\n@@ -176,1 +182,1 @@\n-    ResourceMark rm(THREAD);\n+    ResourceMark rm(current);\n@@ -181,2 +187,2 @@\n-  \/\/ Check for a resolved cp entry , else fall back to a name check.\n-  \/\/ We don't want to resolve any class other than the one being checked.\n+  \/\/ Check for the named class in _nest_members.\n+  \/\/ We don't resolve, or load, any classes.\n@@ -185,33 +191,4 @@\n-    if (_constants->tag_at(cp_index).is_klass()) {\n-      Klass* k2 = _constants->klass_at(cp_index, THREAD);\n-      assert(!HAS_PENDING_EXCEPTION || PENDING_EXCEPTION->is_a(SystemDictionary::VirtualMachineError_klass()),\n-             \"Exceptions should not be possible here\");\n-      if (k2 == k) {\n-        log_trace(class, nestmates)(\"- class is listed at nest_members[%d] => cp[%d]\", i, cp_index);\n-        return true;\n-      }\n-    }\n-    else {\n-      Symbol* name = _constants->klass_name_at(cp_index);\n-      if (name == k->name()) {\n-        log_trace(class, nestmates)(\"- Found it at nest_members[%d] => cp[%d]\", i, cp_index);\n-\n-        \/\/ Names match so check actual klass. This may trigger class loading if\n-        \/\/ it doesn't match though that should be impossible as it means one classloader\n-        \/\/ has defined two different classes with the same name! A compiler thread won't be\n-        \/\/ able to perform that loading but we can't exclude the compiler threads from\n-        \/\/ executing this logic. But it should actually be impossible to trigger loading here.\n-        Klass* k2 = _constants->klass_at(cp_index, THREAD);\n-        assert(!HAS_PENDING_EXCEPTION || PENDING_EXCEPTION->is_a(SystemDictionary::VirtualMachineError_klass()),\n-               \"Exceptions should not be possible here\");\n-        if (k2 == k) {\n-          log_trace(class, nestmates)(\"- class is listed as a nest member\");\n-          return true;\n-        }\n-        else {\n-          \/\/ same name but different klass!\n-          log_trace(class, nestmates)(\" - klass comparison failed!\");\n-          \/\/ can't have two names the same, so we're done\n-          return false;\n-        }\n-      }\n+    Symbol* name = _constants->klass_name_at(cp_index);\n+    if (name == k->name()) {\n+      log_trace(class, nestmates)(\"- named class found at nest_members[%d] => cp[%d]\", i, cp_index);\n+      return true;\n@@ -226,1 +203,1 @@\n-  Thread* THREAD = Thread::current();\n+  Thread* current = Thread::current();\n@@ -232,1 +209,1 @@\n-    ResourceMark rm(THREAD);\n+    ResourceMark rm(current);\n@@ -239,1 +216,1 @@\n-    ResourceMark rm(THREAD);\n+    ResourceMark rm(current);\n@@ -246,1 +223,1 @@\n-    ResourceMark rm(THREAD);\n+    ResourceMark rm(current);\n@@ -252,2 +229,0 @@\n-  \/\/ Check for a resolved cp entry, else fall back to a name check.\n-  \/\/ We don't want to resolve any class other than the one being checked.\n@@ -256,13 +231,4 @@\n-    if (_constants->tag_at(cp_index).is_klass()) {\n-      Klass* k2 = _constants->klass_at(cp_index, THREAD);\n-      assert(!HAS_PENDING_EXCEPTION, \"Unexpected exception\");\n-      if (k2 == k) {\n-        log_trace(class, sealed)(\"- class is listed at permitted_subclasses[%d] => cp[%d]\", i, cp_index);\n-        return true;\n-      }\n-    } else {\n-      Symbol* name = _constants->klass_name_at(cp_index);\n-      if (name == k->name()) {\n-        log_trace(class, sealed)(\"- Found it at permitted_subclasses[%d] => cp[%d]\", i, cp_index);\n-        return true;\n-      }\n+    Symbol* name = _constants->klass_name_at(cp_index);\n+    if (name == k->name()) {\n+      log_trace(class, sealed)(\"- Found it at permitted_subclasses[%d] => cp[%d]\", i, cp_index);\n+      return true;\n@@ -299,1 +265,2 @@\n-    if (!THREAD->can_call_java() && !_constants->tag_at(_nest_host_index).is_klass()) {\n+    bool can_resolve = THREAD->can_call_java();\n+    if (!can_resolve && !_constants->tag_at(_nest_host_index).is_klass()) {\n@@ -311,1 +278,1 @@\n-      if (PENDING_EXCEPTION->is_a(SystemDictionary::VirtualMachineError_klass())) {\n+      if (PENDING_EXCEPTION->is_a(vmClasses::VirtualMachineError_klass())) {\n@@ -337,12 +304,7 @@\n-          bool is_member = nest_host_k->has_nest_member(this, THREAD);\n-          \/\/ exception is rare, perhaps impossible\n-          if (!HAS_PENDING_EXCEPTION) {\n-            if (is_member) {\n-              _nest_host = nest_host_k; \/\/ save resolved nest-host value\n-\n-              log_trace(class, nestmates)(\"Resolved nest-host of %s to %s\",\n-                                          this->external_name(), k->external_name());\n-              return nest_host_k;\n-            } else {\n-              error = \"current type is not listed as a nest member\";\n-            }\n+          bool is_member = nest_host_k->has_nest_member(THREAD, this);\n+          if (is_member) {\n+            _nest_host = nest_host_k; \/\/ save resolved nest-host value\n+\n+            log_trace(class, nestmates)(\"Resolved nest-host of %s to %s\",\n+                                        this->external_name(), k->external_name());\n+            return nest_host_k;\n@@ -350,7 +312,1 @@\n-            if (PENDING_EXCEPTION->is_a(SystemDictionary::VirtualMachineError_klass())) {\n-              return NULL; \/\/ propagate VMEs\n-            }\n-            stringStream ss;\n-            ss.print(\"exception on member check: \");\n-            java_lang_Throwable::print(PENDING_EXCEPTION, &ss);\n-            error = ss.as_string();\n+            error = \"current type is not listed as a nest member\";\n@@ -400,1 +356,1 @@\n-void InstanceKlass::set_nest_host(InstanceKlass* host, TRAPS) {\n+void InstanceKlass::set_nest_host(InstanceKlass* host) {\n@@ -404,2 +360,2 @@\n-  assert(nest_host_error(THREAD) == NULL, \"unexpected nest host resolution error exists: %s\",\n-         nest_host_error(THREAD));\n+  assert(nest_host_error() == NULL, \"unexpected nest host resolution error exists: %s\",\n+         nest_host_error());\n@@ -412,1 +368,1 @@\n-    ResourceMark rm(THREAD);\n+    ResourceMark rm;\n@@ -463,1 +419,1 @@\n-const char* InstanceKlass::nest_host_error(TRAPS) {\n+const char* InstanceKlass::nest_host_error() {\n@@ -467,1 +423,1 @@\n-    constantPoolHandle cph(THREAD, constants());\n+    constantPoolHandle cph(Thread::current(), constants());\n@@ -473,1 +429,0 @@\n-  bool is_hidden_or_anonymous = parser.is_hidden() || parser.is_unsafe_anonymous();\n@@ -477,3 +432,1 @@\n-                                       parser.is_interface(),\n-                                       parser.is_unsafe_anonymous(),\n-                                       should_store_fingerprint(is_hidden_or_anonymous));\n+                                       parser.is_interface());\n@@ -555,1 +508,0 @@\n-  set_is_unsafe_anonymous(parser.is_unsafe_anonymous());\n@@ -741,0 +693,6 @@\n+bool InstanceKlass::is_record() const {\n+  return _record_components != NULL &&\n+         is_final() &&\n+         java_super() == vmClasses::Record_klass();\n+}\n+\n@@ -743,2 +701,1 @@\n-         _permitted_subclasses != Universe::the_empty_short_array() &&\n-         _permitted_subclasses->length() > 0;\n+         _permitted_subclasses != Universe::the_empty_short_array();\n@@ -793,1 +750,1 @@\n-  assert((oop)lock != NULL || !is_not_initialized(), \/\/ initialized or in_error state\n+  assert(lock != NULL || !is_not_initialized(), \/\/ initialized or in_error state\n@@ -813,1 +770,1 @@\n-  ObjectLocker ol(h_init_lock, THREAD, h_init_lock() != NULL);\n+  ObjectLocker ol(h_init_lock, THREAD);\n@@ -916,2 +873,1 @@\n-  assert(THREAD->is_Java_thread(), \"non-JavaThread in link_class_impl\");\n-  JavaThread* jt = (JavaThread*)THREAD;\n+  JavaThread* jt = THREAD;\n@@ -964,1 +920,1 @@\n-    ObjectLocker ol(h_init_lock, THREAD, h_init_lock() != NULL);\n+    ObjectLocker ol(h_init_lock, jt);\n@@ -1005,1 +961,1 @@\n-      if (is_shared() && SystemDictionaryShared::check_linking_constraints(this, THREAD)) {\n+      if (is_shared() && SystemDictionaryShared::check_linking_constraints(THREAD, this)) {\n@@ -1009,2 +965,2 @@\n-        vtable().initialize_vtable(true, CHECK_false);\n-        itable().initialize_itable(true, CHECK_false);\n+        vtable().initialize_vtable_and_check_constraints(CHECK_false);\n+        itable().initialize_itable_and_check_constraints(CHECK_false);\n@@ -1017,1 +973,11 @@\n-      set_init_state(linked);\n+      if (UseVtableBasedCHA) {\n+        MutexLocker ml(THREAD, Compile_lock);\n+        set_init_state(linked);\n+\n+        \/\/ Now flush all code that assume the class is not linked.\n+        if (Universe::is_fully_initialized()) {\n+          CodeCache::flush_dependents_on(this);\n+        }\n+      } else {\n+        set_init_state(linked);\n+      }\n@@ -1019,3 +985,1 @@\n-        Thread *thread = THREAD;\n-        assert(thread->is_Java_thread(), \"thread->is_Java_thread()\");\n-        JvmtiExport::post_class_prepare((JavaThread *) thread, this);\n+        JvmtiExport::post_class_prepare(THREAD, this);\n@@ -1085,2 +1049,1 @@\n-  assert(THREAD->is_Java_thread(), \"non-JavaThread in initialize_impl\");\n-  JavaThread* jt = (JavaThread*)THREAD;\n+  JavaThread* jt = THREAD;\n@@ -1092,1 +1055,1 @@\n-    ObjectLocker ol(h_init_lock, THREAD, h_init_lock() != NULL);\n+    ObjectLocker ol(h_init_lock, jt);\n@@ -1171,3 +1134,0 @@\n-  \/\/ Look for aot compiled methods for this klass, including class initializer.\n-  AOTLoader::load_for_klass(this, THREAD);\n-\n@@ -1177,9 +1137,17 @@\n-    \/\/ Timer includes any side effects of class initialization (resolution,\n-    \/\/ etc), but not recursive entry into call_class_initializer().\n-    PerfClassTraceTime timer(ClassLoader::perf_class_init_time(),\n-                             ClassLoader::perf_class_init_selftime(),\n-                             ClassLoader::perf_classes_inited(),\n-                             jt->get_thread_stat()->perf_recursion_counts_addr(),\n-                             jt->get_thread_stat()->perf_timers_addr(),\n-                             PerfClassTraceTime::CLASS_CLINIT);\n-    call_class_initializer(THREAD);\n+    if (class_initializer() != NULL) {\n+      \/\/ Timer includes any side effects of class initialization (resolution,\n+      \/\/ etc), but not recursive entry into call_class_initializer().\n+      PerfClassTraceTime timer(ClassLoader::perf_class_init_time(),\n+                               ClassLoader::perf_class_init_selftime(),\n+                               ClassLoader::perf_classes_inited(),\n+                               jt->get_thread_stat()->perf_recursion_counts_addr(),\n+                               jt->get_thread_stat()->perf_timers_addr(),\n+                               PerfClassTraceTime::CLASS_CLINIT);\n+      call_class_initializer(THREAD);\n+    } else {\n+      \/\/ The elapsed time is so small it's not worth counting.\n+      if (UsePerfData) {\n+        ClassLoader::perf_classes_inited()->inc();\n+      }\n+      call_class_initializer(THREAD);\n+    }\n@@ -1211,1 +1179,1 @@\n-    if (e->is_a(SystemDictionary::Error_klass())) {\n+    if (e->is_a(vmClasses::Error_klass())) {\n@@ -1246,3 +1214,3 @@\n-Klass* InstanceKlass::implementor() const {\n-  Klass* volatile* k = adr_implementor();\n-  if (k == NULL) {\n+InstanceKlass* InstanceKlass::implementor() const {\n+  InstanceKlass* volatile* ik = adr_implementor();\n+  if (ik == NULL) {\n@@ -1252,2 +1220,2 @@\n-    Klass* kls = Atomic::load_acquire(k);\n-    if (kls != NULL && !kls->is_loader_alive()) {\n+    InstanceKlass* ikls = Atomic::load_acquire(ik);\n+    if (ikls != NULL && !ikls->is_loader_alive()) {\n@@ -1256,1 +1224,1 @@\n-      return kls;\n+      return ikls;\n@@ -1262,1 +1230,1 @@\n-void InstanceKlass::set_implementor(Klass* k) {\n+void InstanceKlass::set_implementor(InstanceKlass* ik) {\n@@ -1265,1 +1233,1 @@\n-  Klass* volatile* addr = adr_implementor();\n+  InstanceKlass* volatile* addr = adr_implementor();\n@@ -1268,1 +1236,1 @@\n-    Atomic::release_store(addr, k);\n+    Atomic::release_store(addr, ik);\n@@ -1273,2 +1241,2 @@\n-  Klass* k = implementor();\n-  if (k == NULL) {\n+  InstanceKlass* ik = implementor();\n+  if (ik == NULL) {\n@@ -1276,1 +1244,1 @@\n-  } else if (k != this) {\n+  } else if (ik != this) {\n@@ -1292,1 +1260,1 @@\n-void InstanceKlass::add_implementor(Klass* k) {\n+void InstanceKlass::add_implementor(InstanceKlass* ik) {\n@@ -1299,1 +1267,1 @@\n-  if (InstanceKlass::cast(k)->is_interface()) return;\n+  if (ik->is_interface()) return;\n@@ -1304,2 +1272,2 @@\n-  Klass* sk = k->super();\n-  if (sk != NULL && InstanceKlass::cast(sk)->implements_interface(this))\n+  InstanceKlass* super_ik = ik->java_super();\n+  if (super_ik != NULL && super_ik->implements_interface(this))\n@@ -1311,4 +1279,4 @@\n-  Klass* ik = implementor();\n-  if (ik == NULL) {\n-    set_implementor(k);\n-  } else if (ik != this && ik != k) {\n+  InstanceKlass* iklass = implementor();\n+  if (iklass == NULL) {\n+    set_implementor(ik);\n+  } else if (iklass != this && iklass != ik) {\n@@ -1322,1 +1290,1 @@\n-    InstanceKlass::cast(local_interfaces()->at(index))->add_implementor(k);\n+    local_interfaces()->at(index)->add_implementor(ik);\n@@ -1333,1 +1301,1 @@\n-void InstanceKlass::process_interfaces(Thread *thread) {\n+void InstanceKlass::process_interfaces() {\n@@ -1337,1 +1305,1 @@\n-    InstanceKlass* interf = InstanceKlass::cast(local_interfaces()->at(i));\n+    InstanceKlass* interf = local_interfaces()->at(i);\n@@ -1448,1 +1416,1 @@\n-  if (this == SystemDictionary::Class_klass()) {\n+  if (this == vmClasses::Class_klass()) {\n@@ -1455,1 +1423,1 @@\n-Klass* InstanceKlass::array_klass_impl(bool or_null, int n, TRAPS) {\n+Klass* InstanceKlass::array_klass(int n, TRAPS) {\n@@ -1458,3 +1426,1 @@\n-    if (or_null) return NULL;\n-\n-    JavaThread *jt = (JavaThread *)THREAD;\n+    JavaThread *jt = THREAD;\n@@ -1474,1 +1440,1 @@\n-  \/\/ _this will always be set at this point\n+  \/\/ array_klasses() will always be set at this point\n@@ -1476,1 +1442,9 @@\n-  if (or_null) {\n+  return oak->array_klass(n, THREAD);\n+}\n+\n+Klass* InstanceKlass::array_klass_or_null(int n) {\n+  \/\/ Need load-acquire for lock-free read\n+  ObjArrayKlass* oak = array_klasses_acquire();\n+  if (oak == NULL) {\n+    return NULL;\n+  } else {\n@@ -1479,1 +1453,0 @@\n-  return oak->array_klass(n, THREAD);\n@@ -1482,2 +1455,6 @@\n-Klass* InstanceKlass::array_klass_impl(bool or_null, TRAPS) {\n-  return array_klass_impl(or_null, 1, THREAD);\n+Klass* InstanceKlass::array_klass(TRAPS) {\n+  return array_klass(1, THREAD);\n+}\n+\n+Klass* InstanceKlass::array_klass_or_null() {\n+  return array_klass_or_null(1);\n@@ -1788,1 +1765,4 @@\n-  return find_method_impl(name, signature, find_overpass, find_static, find_private);\n+  return find_method_impl(name, signature,\n+                          OverpassLookupMode::find,\n+                          StaticLookupMode::find,\n+                          PrivateLookupMode::find);\n@@ -1813,2 +1793,2 @@\n-                                                 find_overpass,\n-                                                 skip_static,\n+                                                 OverpassLookupMode::find,\n+                                                 StaticLookupMode::skip,\n@@ -1872,3 +1852,3 @@\n-                                         find_overpass,\n-                                         find_static,\n-                                         find_private);\n+                                         OverpassLookupMode::find,\n+                                         StaticLookupMode::find,\n+                                         PrivateLookupMode::find);\n@@ -1917,3 +1897,3 @@\n-  const bool skipping_overpass = (overpass_mode == skip_overpass);\n-  const bool skipping_static = (static_mode == skip_static);\n-  const bool skipping_private = (private_mode == skip_private);\n+  const bool skipping_overpass = (overpass_mode == OverpassLookupMode::skip);\n+  const bool skipping_static = (static_mode == StaticLookupMode::skip);\n+  const bool skipping_private = (private_mode == PrivateLookupMode::skip);\n@@ -1995,1 +1975,1 @@\n-                                                                        find_static,\n+                                                                        StaticLookupMode::find,\n@@ -2001,1 +1981,1 @@\n-    overpass_local_mode = skip_overpass;   \/\/ Always ignore overpass methods in superclasses\n+    overpass_local_mode = OverpassLookupMode::skip;   \/\/ Always ignore overpass methods in superclasses\n@@ -2031,1 +2011,1 @@\n-    m = lookup_method_in_all_interfaces(name, signature, find_defaults);\n+    m = lookup_method_in_all_interfaces(name, signature, DefaultsLookupMode::find);\n@@ -2049,1 +2029,1 @@\n-        ((defaults_mode != skip_defaults) || !m->is_default_method())) {\n+        ((defaults_mode != DefaultsLookupMode::skip) || !m->is_default_method())) {\n@@ -2364,1 +2344,1 @@\n-      Klass* impl = Atomic::load_acquire(adr_implementor());\n+      InstanceKlass* impl = Atomic::load_acquire(adr_implementor());\n@@ -2366,3 +2346,3 @@\n-        \/\/ NULL this field, might be an unloaded klass or NULL\n-        Klass* volatile* klass = adr_implementor();\n-        if (Atomic::cmpxchg(klass, impl, (Klass*)NULL) == impl) {\n+        \/\/ NULL this field, might be an unloaded instance klass or NULL\n+        InstanceKlass* volatile* iklass = adr_implementor();\n+        if (Atomic::cmpxchg(iklass, impl, (InstanceKlass*)NULL) == impl) {\n@@ -2393,71 +2373,0 @@\n-bool InstanceKlass::supers_have_passed_fingerprint_checks() {\n-  if (java_super() != NULL && !java_super()->has_passed_fingerprint_check()) {\n-    ResourceMark rm;\n-    log_trace(class, fingerprint)(\"%s : super %s not fingerprinted\", external_name(), java_super()->external_name());\n-    return false;\n-  }\n-\n-  Array<InstanceKlass*>* local_interfaces = this->local_interfaces();\n-  if (local_interfaces != NULL) {\n-    int length = local_interfaces->length();\n-    for (int i = 0; i < length; i++) {\n-      InstanceKlass* intf = local_interfaces->at(i);\n-      if (!intf->has_passed_fingerprint_check()) {\n-        ResourceMark rm;\n-        log_trace(class, fingerprint)(\"%s : interface %s not fingerprinted\", external_name(), intf->external_name());\n-        return false;\n-      }\n-    }\n-  }\n-\n-  return true;\n-}\n-\n-bool InstanceKlass::should_store_fingerprint(bool is_hidden_or_anonymous) {\n-#if INCLUDE_AOT\n-  \/\/ We store the fingerprint into the InstanceKlass only in the following 2 cases:\n-  if (CalculateClassFingerprint) {\n-    \/\/ (1) We are running AOT to generate a shared library.\n-    return true;\n-  }\n-  if (Arguments::is_dumping_archive()) {\n-    \/\/ (2) We are running -Xshare:dump or -XX:ArchiveClassesAtExit to create a shared archive\n-    return true;\n-  }\n-  if (UseAOT && is_hidden_or_anonymous) {\n-    \/\/ (3) We are using AOT code from a shared library and see a hidden or unsafe anonymous class\n-    return true;\n-  }\n-#endif\n-\n-  \/\/ In all other cases we might set the _misc_has_passed_fingerprint_check bit,\n-  \/\/ but do not store the 64-bit fingerprint to save space.\n-  return false;\n-}\n-\n-bool InstanceKlass::has_stored_fingerprint() const {\n-#if INCLUDE_AOT\n-  return should_store_fingerprint() || is_shared();\n-#else\n-  return false;\n-#endif\n-}\n-\n-uint64_t InstanceKlass::get_stored_fingerprint() const {\n-  address adr = adr_fingerprint();\n-  if (adr != NULL) {\n-    return (uint64_t)Bytes::get_native_u8(adr); \/\/ adr may not be 64-bit aligned\n-  }\n-  return 0;\n-}\n-\n-void InstanceKlass::store_fingerprint(uint64_t fingerprint) {\n-  address adr = adr_fingerprint();\n-  if (adr != NULL) {\n-    Bytes::put_native_u8(adr, (u8)fingerprint); \/\/ adr may not be 64-bit aligned\n-\n-    ResourceMark rm;\n-    log_trace(class, fingerprint)(\"stored as \" PTR64_FORMAT \" for class %s\", fingerprint, external_name());\n-  }\n-}\n-\n@@ -2474,1 +2383,5 @@\n-  it->push(&_constants);\n+  if (!is_rewritten()) {\n+    it->push(&_constants, MetaspaceClosure::_writable);\n+  } else {\n+    it->push(&_constants);\n+  }\n@@ -2484,1 +2397,5 @@\n-  it->push(&_default_vtable_indices);\n+  if (!is_rewritten()) {\n+    it->push(&_default_vtable_indices, MetaspaceClosure::_writable);\n+  } else {\n+    it->push(&_default_vtable_indices);\n+  }\n@@ -2511,0 +2428,6 @@\n+\n+  if (can_be_verified_at_dumptime()) {\n+    \/\/ Remember this so we can avoid walking the hierarchy at runtime.\n+    set_verified_at_dump_time();\n+  }\n+\n@@ -2560,1 +2483,1 @@\n-  _package_entry = NULL;\n+  init_shared_package_entry();\n@@ -2573,0 +2496,21 @@\n+void InstanceKlass::init_shared_package_entry() {\n+#if !INCLUDE_CDS_JAVA_HEAP\n+  _package_entry = NULL;\n+#else\n+  if (!MetaspaceShared::use_full_module_graph()) {\n+    _package_entry = NULL;\n+  } else if (DynamicDumpSharedSpaces) {\n+    if (!MetaspaceShared::is_in_shared_metaspace(_package_entry)) {\n+      _package_entry = NULL;\n+    }\n+  } else {\n+    if (is_shared_unregistered_class()) {\n+      _package_entry = NULL;\n+    } else {\n+      _package_entry = PackageEntry::get_archived_entry(_package_entry);\n+    }\n+  }\n+  ArchivePtrMarker::mark_pointer((address**)&_package_entry);\n+#endif\n+}\n+\n@@ -2579,0 +2523,1 @@\n+  assert(!shared_loading_failed(), \"Must not try to load failed class again\");\n@@ -2587,0 +2532,1 @@\n+#if INCLUDE_JVMTI\n@@ -2593,2 +2539,6 @@\n-    vtable().initialize_vtable(false, CHECK);\n-    itable().initialize_itable(false, CHECK);\n+    \/\/ First fix any default methods that point to a super class that may\n+    \/\/ have been redefined.\n+    bool trace_name_printed = false;\n+    adjust_default_methods(&trace_name_printed);\n+    vtable().initialize_vtable();\n+    itable().initialize_itable();\n@@ -2596,0 +2546,1 @@\n+#endif\n@@ -2610,0 +2561,28 @@\n+\n+  \/\/ Initialize @ValueBased class annotation\n+  if (DiagnoseSyncOnValueBasedClasses && has_value_based_class_annotation()) {\n+    set_is_value_based();\n+    set_prototype_header(markWord::prototype());\n+  }\n+}\n+\n+\/\/ Check if a class or any of its supertypes has a version older than 50.\n+\/\/ CDS will not perform verification of old classes during dump time because\n+\/\/ without changing the old verifier, the verification constraint cannot be\n+\/\/ retrieved during dump time.\n+\/\/ Verification of archived old classes will be performed during run time.\n+bool InstanceKlass::can_be_verified_at_dumptime() const {\n+  if (major_version() < 50 \/*JAVA_6_VERSION*\/) {\n+    return false;\n+  }\n+  if (java_super() != NULL && !java_super()->can_be_verified_at_dumptime()) {\n+    return false;\n+  }\n+  Array<InstanceKlass*>* interfaces = local_interfaces();\n+  int len = interfaces->length();\n+  for (int i = 0; i < len; i++) {\n+    if (!interfaces->at(i)->can_be_verified_at_dumptime()) {\n+      return false;\n+    }\n+  }\n+  return true;\n@@ -2759,7 +2738,0 @@\n-  \/\/ If this is an unsafe anonymous class, append a hash to make the name unique\n-  if (is_unsafe_anonymous()) {\n-    intptr_t hash = (java_mirror() != NULL) ? java_mirror()->identity_hash() : 0;\n-    jio_snprintf(hash_buf, sizeof(hash_buf), \"\/\" UINTX_FORMAT, (uintx)hash);\n-    hash_len = (int)strlen(hash_buf);\n-  }\n-\n@@ -2802,6 +2774,0 @@\n-  \/\/ For an unsafe anonymous class return the host class' module\n-  if (is_unsafe_anonymous()) {\n-    assert(unsafe_anonymous_host() != NULL, \"unsafe anonymous class must have a host class\");\n-    return unsafe_anonymous_host()->module();\n-  }\n-\n@@ -2844,1 +2810,21 @@\n-  TempNewSymbol pkg_name = pkg_entry != NULL ? pkg_entry->name() : ClassLoader::package_from_class_name(name());\n+  if (is_shared() && _package_entry != NULL) {\n+    if (MetaspaceShared::use_full_module_graph() && _package_entry == pkg_entry) {\n+      \/\/ we can use the saved package\n+      assert(MetaspaceShared::is_in_shared_metaspace(_package_entry), \"must be\");\n+      return;\n+    } else {\n+      _package_entry = NULL;\n+    }\n+  }\n+\n+  \/\/ ClassLoader::package_from_class_name has already incremented the refcount of the symbol\n+  \/\/ it returns, so we need to decrement it when the current function exits.\n+  TempNewSymbol from_class_name =\n+      (pkg_entry != NULL) ? NULL : ClassLoader::package_from_class_name(name());\n+\n+  Symbol* pkg_name;\n+  if (pkg_entry != NULL) {\n+    pkg_name = pkg_entry->name();\n+  } else {\n+    pkg_name = from_class_name;\n+  }\n@@ -2893,3 +2879,3 @@\n-\/\/ Function set_classpath_index checks if the package of the InstanceKlass is in the\n-\/\/ boot loader's package entry table.  If so, then it sets the classpath_index\n-\/\/ in the package entry record.\n+\/\/ Function set_classpath_index ensures that for a non-null _package_entry\n+\/\/ of the InstanceKlass, the entry is in the boot loader's package entry table.\n+\/\/ It then sets the classpath_index in the package entry record.\n@@ -2902,1 +2888,1 @@\n-void InstanceKlass::set_classpath_index(s2 path_index, TRAPS) {\n+void InstanceKlass::set_classpath_index(s2 path_index) {\n@@ -2978,18 +2964,10 @@\n-\/\/ Returns true iff super_method can be overridden by a method in targetclassname\n-\/\/ See JLS 3rd edition 8.4.6.1\n-\/\/ Assumes name-signature match\n-\/\/ \"this\" is InstanceKlass of super_method which must exist\n-\/\/ note that the InstanceKlass of the method in the targetclassname has not always been created yet\n-bool InstanceKlass::is_override(const methodHandle& super_method, Handle targetclassloader, Symbol* targetclassname, TRAPS) {\n-   \/\/ Private methods can not be overridden\n-   if (super_method->is_private()) {\n-     return false;\n-   }\n-   \/\/ If super method is accessible, then override\n-   if ((super_method->is_protected()) ||\n-       (super_method->is_public())) {\n-     return true;\n-   }\n-   \/\/ Package-private methods are not inherited outside of package\n-   assert(super_method->is_package_private(), \"must be package private\");\n-   return(is_same_class_package(targetclassloader(), targetclassname));\n+static bool is_prohibited_package_slow(Symbol* class_name) {\n+  \/\/ Caller has ResourceMark\n+  int length;\n+  jchar* unicode = class_name->as_unicode(length);\n+  return (length >= 5 &&\n+          unicode[0] == 'j' &&\n+          unicode[1] == 'a' &&\n+          unicode[2] == 'v' &&\n+          unicode[3] == 'a' &&\n+          unicode[4] == '\/');\n@@ -3004,1 +2982,1 @@\n-      class_name != NULL) {\n+      class_name != NULL && class_name->utf8_length() >= 5) {\n@@ -3006,2 +2984,9 @@\n-    char* name = class_name->as_C_string();\n-    if (strncmp(name, JAVAPKG, JAVAPKG_LEN) == 0 && name[JAVAPKG_LEN] == '\/') {\n+    bool prohibited;\n+    const u1* base = class_name->base();\n+    if ((base[0] | base[1] | base[2] | base[3] | base[4]) & 0x80) {\n+      prohibited = is_prohibited_package_slow(class_name);\n+    } else {\n+      char* name = class_name->as_C_string();\n+      prohibited = (strncmp(name, JAVAPKG, JAVAPKG_LEN) == 0 && name[JAVAPKG_LEN] == '\/');\n+    }\n+    if (prohibited) {\n@@ -3010,1 +2995,1 @@\n-      name = pkg_name->as_C_string();\n+      char* name = pkg_name->as_C_string();\n@@ -3057,1 +3042,1 @@\n-      \/\/ It may be a local or anonymous class; try for that.\n+      \/\/ It may be a local class; try for that.\n@@ -3077,1 +3062,1 @@\n-jint InstanceKlass::compute_modifier_flags(TRAPS) const {\n+jint InstanceKlass::compute_modifier_flags() const {\n@@ -3118,7 +3103,11 @@\n-Method* InstanceKlass::method_at_itable(Klass* holder, int index, TRAPS) {\n-  itableOffsetEntry* ioe = (itableOffsetEntry*)start_of_itable();\n-  int method_table_offset_in_words = ioe->offset()\/wordSize;\n-  int nof_interfaces = (method_table_offset_in_words - itable_offset_in_words())\n-                       \/ itableOffsetEntry::size();\n-\n-  for (int cnt = 0 ; ; cnt ++, ioe ++) {\n+Method* InstanceKlass::method_at_itable(InstanceKlass* holder, int index, TRAPS) {\n+  bool implements_interface; \/\/ initialized by method_at_itable_or_null\n+  Method* m = method_at_itable_or_null(holder, index,\n+                                       implements_interface); \/\/ out parameter\n+  if (m != NULL) {\n+    assert(implements_interface, \"sanity\");\n+    return m;\n+  } else if (implements_interface) {\n+    \/\/ Throw AbstractMethodError since corresponding itable slot is empty.\n+    THROW_NULL(vmSymbols::java_lang_AbstractMethodError());\n+  } else {\n@@ -3127,12 +3116,23 @@\n-    if (cnt >= nof_interfaces) {\n-      ResourceMark rm(THREAD);\n-      stringStream ss;\n-      bool same_module = (module() == holder->module());\n-      ss.print(\"Receiver class %s does not implement \"\n-               \"the interface %s defining the method to be called \"\n-               \"(%s%s%s)\",\n-               external_name(), holder->external_name(),\n-               (same_module) ? joint_in_module_of_loader(holder) : class_in_module_of_loader(),\n-               (same_module) ? \"\" : \"; \",\n-               (same_module) ? \"\" : holder->class_in_module_of_loader());\n-      THROW_MSG_NULL(vmSymbols::java_lang_IncompatibleClassChangeError(), ss.as_string());\n+    ResourceMark rm(THREAD);\n+    stringStream ss;\n+    bool same_module = (module() == holder->module());\n+    ss.print(\"Receiver class %s does not implement \"\n+             \"the interface %s defining the method to be called \"\n+             \"(%s%s%s)\",\n+             external_name(), holder->external_name(),\n+             (same_module) ? joint_in_module_of_loader(holder) : class_in_module_of_loader(),\n+             (same_module) ? \"\" : \"; \",\n+             (same_module) ? \"\" : holder->class_in_module_of_loader());\n+    THROW_MSG_NULL(vmSymbols::java_lang_IncompatibleClassChangeError(), ss.as_string());\n+  }\n+}\n+\n+Method* InstanceKlass::method_at_itable_or_null(InstanceKlass* holder, int index, bool& implements_interface) {\n+  klassItable itable(this);\n+  for (int i = 0; i < itable.size_offset_table(); i++) {\n+    itableOffsetEntry* offset_entry = itable.offset_entry(i);\n+    if (offset_entry->interface_klass() == holder) {\n+      implements_interface = true;\n+      itableMethodEntry* ime = offset_entry->first_method_entry(this);\n+      Method* m = ime[index].method();\n+      return m;\n@@ -3140,3 +3140,3 @@\n-\n-    Klass* ik = ioe->interface_klass();\n-    if (ik == holder) break;\n+  implements_interface = false;\n+  return NULL; \/\/ offset entry not found\n+}\n@@ -3145,4 +3145,19 @@\n-  itableMethodEntry* ime = ioe->first_method_entry(this);\n-  Method* m = ime[index].method();\n-  if (m == NULL) {\n-    THROW_NULL(vmSymbols::java_lang_AbstractMethodError());\n+int InstanceKlass::vtable_index_of_interface_method(Method* intf_method) {\n+  assert(is_linked(), \"required\");\n+  assert(intf_method->method_holder()->is_interface(), \"not an interface method\");\n+  assert(is_subtype_of(intf_method->method_holder()), \"interface not implemented\");\n+\n+  int vtable_index = Method::invalid_vtable_index;\n+  Symbol* name = intf_method->name();\n+  Symbol* signature = intf_method->signature();\n+\n+  \/\/ First check in default method array\n+  if (!intf_method->is_abstract() && default_methods() != NULL) {\n+    int index = find_method_index(default_methods(),\n+                                  name, signature,\n+                                  Klass::OverpassLookupMode::find,\n+                                  Klass::StaticLookupMode::find,\n+                                  Klass::PrivateLookupMode::find);\n+    if (index >= 0) {\n+      vtable_index = default_vtable_indices()->at(index);\n+    }\n@@ -3150,1 +3165,6 @@\n-  return m;\n+  if (vtable_index == Method::invalid_vtable_index) {\n+    \/\/ get vtable_index for miranda methods\n+    klassVtable vt = vtable();\n+    vtable_index = vt.index_of_miranda(name, signature);\n+  }\n+  return vtable_index;\n@@ -3153,1 +3173,0 @@\n-\n@@ -3192,5 +3211,3 @@\n-  if (TieredCompilation) {\n-    nmethod* prev = lookup_osr_nmethod(n->method(), n->osr_entry_bci(), n->comp_level(), true);\n-    assert(prev == NULL || !prev->is_in_use() COMPILER2_PRESENT(|| StressRecompilation),\n-           \"redundant OSR recompilation detected. memory leak in CodeCache!\");\n-  }\n+  nmethod* prev = lookup_osr_nmethod(n->method(), n->osr_entry_bci(), n->comp_level(), true);\n+  assert(prev == NULL || !prev->is_in_use() COMPILER2_PRESENT(|| StressRecompilation),\n+      \"redundant OSR recompilation detected. memory leak in CodeCache!\");\n@@ -3199,10 +3216,5 @@\n-  {\n-    assert(n->is_osr_method(), \"wrong kind of nmethod\");\n-    n->set_osr_link(osr_nmethods_head());\n-    set_osr_nmethods_head(n);\n-    \/\/ Raise the highest osr level if necessary\n-    if (TieredCompilation) {\n-      Method* m = n->method();\n-      m->set_highest_osr_comp_level(MAX2(m->highest_osr_comp_level(), n->comp_level()));\n-    }\n-  }\n+  assert(n->is_osr_method(), \"wrong kind of nmethod\");\n+  n->set_osr_link(osr_nmethods_head());\n+  set_osr_nmethods_head(n);\n+  \/\/ Raise the highest osr level if necessary\n+  n->method()->set_highest_osr_comp_level(MAX2(n->method()->highest_osr_comp_level(), n->comp_level()));\n@@ -3211,6 +3223,4 @@\n-  if (TieredCompilation) {\n-    for (int l = CompLevel_limited_profile; l < n->comp_level(); l++) {\n-      nmethod *inv = lookup_osr_nmethod(n->method(), n->osr_entry_bci(), l, true);\n-      if (inv != NULL && inv->is_in_use()) {\n-        inv->make_not_entrant();\n-      }\n+  for (int l = CompLevel_limited_profile; l < n->comp_level(); l++) {\n+    nmethod *inv = lookup_osr_nmethod(n->method(), n->osr_entry_bci(), l, true);\n+    if (inv != NULL && inv->is_in_use()) {\n+      inv->make_not_entrant();\n@@ -3234,1 +3244,1 @@\n-    if (TieredCompilation && m == cur->method()) {\n+    if (m == cur->method()) {\n@@ -3253,8 +3263,5 @@\n-  if (TieredCompilation) {\n-    cur = next;\n-    while (cur != NULL) {\n-      \/\/ Find max level after n\n-      if (m == cur->method()) {\n-        max_level = MAX2(max_level, cur->comp_level());\n-      }\n-      cur = cur->osr_link();\n+  cur = next;\n+  while (cur != NULL) {\n+    \/\/ Find max level after n\n+    if (m == cur->method()) {\n+      max_level = MAX2(max_level, cur->comp_level());\n@@ -3262,1 +3269,1 @@\n-    m->set_highest_osr_comp_level(max_level);\n+    cur = cur->osr_link();\n@@ -3264,0 +3271,1 @@\n+  m->set_highest_osr_comp_level(max_level);\n@@ -3305,1 +3313,1 @@\n-          if (osr->comp_level() == CompLevel_highest_tier) {\n+          if (osr->comp_level() == CompilationPolicy::highest_compile_level()) {\n@@ -3326,2 +3334,0 @@\n-#ifndef PRODUCT\n-\n@@ -3409,1 +3415,0 @@\n-  st->print(BULLET\"unsafe anonymous host class:        \"); Metadata::print_value_on_maybe_null(st, unsafe_anonymous_host()); st->cr();\n@@ -3478,2 +3483,0 @@\n-#endif \/\/PRODUCT\n-\n@@ -3486,2 +3489,0 @@\n-#ifndef PRODUCT\n-\n@@ -3503,1 +3504,1 @@\n-  if (this == SystemDictionary::String_klass()) {\n+  if (this == vmClasses::String_klass()) {\n@@ -3520,1 +3521,1 @@\n-  if (this == SystemDictionary::Class_klass()) {\n+  if (this == vmClasses::Class_klass()) {\n@@ -3538,1 +3539,1 @@\n-  } else if (this == SystemDictionary::MethodType_klass()) {\n+  } else if (this == vmClasses::MethodType_klass()) {\n@@ -3545,0 +3546,2 @@\n+#ifndef PRODUCT\n+\n@@ -3557,1 +3560,1 @@\n-  if (this == SystemDictionary::String_klass()\n+  if (this == vmClasses::String_klass()\n@@ -3566,1 +3569,1 @@\n-  } else if (this == SystemDictionary::Class_klass()) {\n+  } else if (this == vmClasses::Class_klass()) {\n@@ -3575,1 +3578,1 @@\n-  } else if (this == SystemDictionary::MethodType_klass()) {\n+  } else if (this == vmClasses::MethodType_klass()) {\n@@ -3581,1 +3584,1 @@\n-  } else if (this == SystemDictionary::LambdaForm_klass()) {\n+  } else if (this == vmClasses::LambdaForm_klass()) {\n@@ -3587,1 +3590,1 @@\n-  } else if (this == SystemDictionary::MemberName_klass()) {\n+  } else if (this == vmClasses::MemberName_klass()) {\n@@ -3593,1 +3596,7 @@\n-      java_lang_invoke_MemberName::clazz(obj)->print_value_on(st);\n+      oop clazz = java_lang_invoke_MemberName::clazz(obj);\n+      oop name  = java_lang_invoke_MemberName::name(obj);\n+      if (clazz != NULL) {\n+        clazz->print_value_on(st);\n+      } else {\n+        st->print(\"NULL\");\n+      }\n@@ -3595,1 +3604,5 @@\n-      java_lang_invoke_MemberName::name(obj)->print_value_on(st);\n+      if (name != NULL) {\n+        name->print_value_on(st);\n+      } else {\n+        st->print(\"NULL\");\n+      }\n@@ -3605,1 +3618,1 @@\n-                                             const char* module_name,\n+                                             const ModuleEntry* module_entry,\n@@ -3607,0 +3620,2 @@\n+  log_to_classlist();\n+\n@@ -3621,0 +3636,1 @@\n+      const char* module_name = (module_entry->name() == NULL) ? UNNAMED_MODULE : module_entry->name()->as_C_string();\n@@ -3633,5 +3649,4 @@\n-      Thread* THREAD = Thread::current();\n-      Klass* caller =\n-            THREAD->is_Java_thread()\n-                ? ((JavaThread*)THREAD)->security_get_caller_class(1)\n-                : NULL;\n+      Thread* current = Thread::current();\n+      Klass* caller = current->is_Java_thread() ?\n+        current->as_Java_thread()->security_get_caller_class(1):\n+        NULL;\n@@ -3822,4 +3837,0 @@\n-  const Klass* anonymous_host = unsafe_anonymous_host();\n-  if (anonymous_host != NULL) {\n-    guarantee(anonymous_host->is_klass(), \"should be klass\");\n-  }\n@@ -3962,2 +3973,3 @@\n-      \/\/ Add to the deallocate list after unlinking\n-      loader_data->add_to_deallocate_list(pv_node);\n+      \/\/ Delete this node directly. Nothing is referring to it and we don't\n+      \/\/ want it to increase the counter for metadata to delete in CLDG.\n+      MetadataFactory::free_metadata(loader_data, pv_node);\n@@ -3977,24 +3989,0 @@\n-    \/\/ At least one method is live in this previous version.\n-    \/\/ Reset dead EMCP methods not to get breakpoints.\n-    \/\/ All methods are deallocated when all of the methods for this class are no\n-    \/\/ longer running.\n-    Array<Method*>* method_refs = pv_node->methods();\n-    if (method_refs != NULL) {\n-      log_trace(redefine, class, iklass, purge)(\"previous methods length=%d\", method_refs->length());\n-      for (int j = 0; j < method_refs->length(); j++) {\n-        Method* method = method_refs->at(j);\n-\n-        if (!method->on_stack()) {\n-          \/\/ no breakpoints for non-running methods\n-          if (method->is_running_emcp()) {\n-            method->set_running_emcp(false);\n-          }\n-        } else {\n-          assert (method->is_obsolete() || method->is_running_emcp(),\n-                  \"emcp method cannot run after emcp bit is cleared\");\n-          log_trace(redefine, class, iklass, purge)\n-            (\"purge: %s(%s): prev method @%d in version @%d is alive\",\n-             method->name()->as_C_string(), method->signature()->as_C_string(), j, version);\n-        }\n-      }\n-    }\n@@ -4100,23 +4088,0 @@\n-  if (emcp_method_count != 0) {\n-    \/\/ At least one method is still running, check for EMCP methods\n-    for (int i = 0; i < old_methods->length(); i++) {\n-      Method* old_method = old_methods->at(i);\n-      if (!old_method->is_obsolete() && old_method->on_stack()) {\n-        \/\/ if EMCP method (not obsolete) is on the stack, mark as EMCP so that\n-        \/\/ we can add breakpoints for it.\n-\n-        \/\/ We set the method->on_stack bit during safepoints for class redefinition\n-        \/\/ and use this bit to set the is_running_emcp bit.\n-        \/\/ After the safepoint, the on_stack bit is cleared and the running emcp\n-        \/\/ method may exit.   If so, we would set a breakpoint in a method that\n-        \/\/ is never reached, but this won't be noticeable to the programmer.\n-        old_method->set_running_emcp(true);\n-        log_trace(redefine, class, iklass, add)\n-          (\"EMCP method %s is on_stack \" INTPTR_FORMAT, old_method->name_and_sig_as_C_string(), p2i(old_method));\n-      } else if (!old_method->is_obsolete()) {\n-        log_trace(redefine, class, iklass, add)\n-          (\"EMCP method %s is NOT on_stack \" INTPTR_FORMAT, old_method->name_and_sig_as_C_string(), p2i(old_method));\n-      }\n-    }\n-  }\n-\n@@ -4195,0 +4160,60 @@\n+\n+bool InstanceKlass::is_shareable() const {\n+#if INCLUDE_CDS\n+  ClassLoaderData* loader_data = class_loader_data();\n+  if (!SystemDictionaryShared::is_sharing_possible(loader_data)) {\n+    return false;\n+  }\n+\n+  if (is_hidden()) {\n+    return false;\n+  }\n+\n+  if (module()->is_patched()) {\n+    return false;\n+  }\n+\n+  return true;\n+#else\n+  return false;\n+#endif\n+}\n+\n+void InstanceKlass::log_to_classlist() const {\n+#if INCLUDE_CDS\n+  ResourceMark rm;\n+  if (ClassListWriter::is_enabled()) {\n+    if (!ClassLoader::has_jrt_entry()) {\n+       warning(\"DumpLoadedClassList and CDS are not supported in exploded build\");\n+       DumpLoadedClassList = NULL;\n+       return;\n+    }\n+    if (is_shareable()) {\n+      ClassListWriter w;\n+      w.stream()->print_cr(\"%s\", name()->as_C_string());\n+      w.stream()->flush();\n+    }\n+  }\n+#endif \/\/ INCLUDE_CDS\n+}\n+\n+\/\/ Make a step iterating over the class hierarchy under the root class.\n+\/\/ Skips subclasses if requested.\n+void ClassHierarchyIterator::next() {\n+  assert(_current != NULL, \"required\");\n+  if (_visit_subclasses && _current->subklass() != NULL) {\n+    _current = _current->subklass();\n+    return; \/\/ visit next subclass\n+  }\n+  _visit_subclasses = true; \/\/ reset\n+  while (_current->next_sibling() == NULL && _current != _root) {\n+    _current = _current->superklass(); \/\/ backtrack; no more sibling subclasses left\n+  }\n+  if (_current == _root) {\n+    \/\/ Iteration is over (back at root after backtracking). Invalidate the iterator.\n+    _current = NULL;\n+    return;\n+  }\n+  _current = _current->next_sibling();\n+  return; \/\/ visit next sibling subclass\n+}\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":453,"deletions":428,"binary":false,"changes":881,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,0 +27,5 @@\n+#include \"cds\/classListParser.hpp\"\n+#include \"cds\/classListWriter.hpp\"\n+#include \"cds\/dynamicArchive.hpp\"\n+#include \"cds\/heapShared.hpp\"\n+#include \"cds\/lambdaFormInvokers.hpp\"\n@@ -31,0 +36,1 @@\n+#include \"classfile\/classLoadInfo.hpp\"\n@@ -39,0 +45,1 @@\n+#include \"classfile\/vmClasses.hpp\"\n@@ -45,2 +52,0 @@\n-#include \"memory\/dynamicArchive.hpp\"\n-#include \"memory\/heapShared.hpp\"\n@@ -55,0 +60,1 @@\n+#include \"oops\/klass.inline.hpp\"\n@@ -63,1 +69,0 @@\n-#include \"prims\/nativeLookup.hpp\"\n@@ -67,0 +72,1 @@\n+#include \"runtime\/globals_extension.hpp\"\n@@ -77,0 +83,1 @@\n+#include \"runtime\/osThread.hpp\"\n@@ -95,1 +102,0 @@\n-#include \"utilities\/histogram.hpp\"\n@@ -115,2 +121,0 @@\n-          JVMWrapper(\"JVM_GetClassDeclaredFields\");\n-\n@@ -147,1 +151,1 @@\n-  JavaThread* jthread = JavaThread::current();\n+  JavaThread* jthread = THREAD;\n@@ -161,1 +165,1 @@\n-      if (!vfst.method()->method_holder()->is_subclass_of(SystemDictionary::ClassLoader_klass())&&\n+      if (!vfst.method()->method_holder()->is_subclass_of(vmClasses::ClassLoader_klass())&&\n@@ -230,50 +234,0 @@\n-\/\/ Wrapper to trace JVM functions\n-\n-#ifdef ASSERT\n-  Histogram* JVMHistogram;\n-  volatile int JVMHistogram_lock = 0;\n-\n-  class JVMHistogramElement : public HistogramElement {\n-    public:\n-     JVMHistogramElement(const char* name);\n-  };\n-\n-  JVMHistogramElement::JVMHistogramElement(const char* elementName) {\n-    _name = elementName;\n-    uintx count = 0;\n-\n-    while (Atomic::cmpxchg(&JVMHistogram_lock, 0, 1) != 0) {\n-      while (Atomic::load_acquire(&JVMHistogram_lock) != 0) {\n-        count +=1;\n-        if ( (WarnOnStalledSpinLock > 0)\n-          && (count % WarnOnStalledSpinLock == 0)) {\n-          warning(\"JVMHistogram_lock seems to be stalled\");\n-        }\n-      }\n-     }\n-\n-    if(JVMHistogram == NULL)\n-      JVMHistogram = new Histogram(\"JVM Call Counts\",100);\n-\n-    JVMHistogram->add_element(this);\n-    Atomic::dec(&JVMHistogram_lock);\n-  }\n-\n-  #define JVMCountWrapper(arg) \\\n-      static JVMHistogramElement* e = new JVMHistogramElement(arg); \\\n-      if (e != NULL) e->increment_count();  \/\/ Due to bug in VC++, we need a NULL check here eventhough it should never happen!\n-\n-  #define JVMWrapper(arg) JVMCountWrapper(arg);\n-#else\n-  #define JVMWrapper(arg)\n-#endif\n-\n-\n-\/\/ Interface version \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-\n-\n-JVM_LEAF(jint, JVM_GetInterfaceVersion())\n-  return JVM_INTERFACE_VERSION;\n-JVM_END\n-\n-\n@@ -284,1 +238,0 @@\n-  JVMWrapper(\"JVM_CurrentTimeMillis\");\n@@ -289,1 +242,0 @@\n-  JVMWrapper(\"JVM_NanoTime\");\n@@ -301,1 +253,0 @@\n-  JVMWrapper(\"JVM_GetNanoTimeAdjustment\");\n@@ -338,1 +289,0 @@\n-  JVMWrapper(\"JVM_ArrayCopy\");\n@@ -360,1 +310,1 @@\n-                          SystemDictionary::Properties_klass(),\n+                          vmClasses::Properties_klass(),\n@@ -377,1 +327,0 @@\n-  JVMWrapper(\"JVM_GetProperties\");\n@@ -387,1 +336,1 @@\n-  InstanceKlass* ik = SystemDictionary::String_klass();\n+  InstanceKlass* ik = vmClasses::String_klass();\n@@ -429,1 +378,1 @@\n-#ifdef TIERED\n+#if COMPILER1_AND_COMPILER2\n@@ -437,1 +386,1 @@\n-    #error \"INCLUDE_JVMCI should imply TIERED\"\n+    #error \"INCLUDE_JVMCI should imply COMPILER1_OR_COMPILER2\"\n@@ -441,1 +390,1 @@\n-#endif \/\/ TIERED\n+#endif \/\/ COMPILER1_AND_COMPILER2\n@@ -453,1 +402,1 @@\n-  return (jobjectArray) JNIHandles::make_local(env, result_h());\n+  return (jobjectArray) JNIHandles::make_local(THREAD, result_h());\n@@ -466,1 +415,0 @@\n-  JVMWrapper(\"JVM_GetTemporaryDirectory\");\n@@ -470,1 +418,1 @@\n-  return (jstring) JNIHandles::make_local(env, h());\n+  return (jstring) JNIHandles::make_local(THREAD, h());\n@@ -479,1 +427,1 @@\n-  JVMWrapper(\"JVM_BeforeHalt\");\n+#if INCLUDE_CDS\n@@ -482,1 +430,1 @@\n-    MetaspaceShared::link_and_cleanup_shared_classes(THREAD);\n+    DynamicArchive::prepare_for_dynamic_dumping_at_exit();\n@@ -484,0 +432,1 @@\n+#endif\n@@ -499,6 +448,2 @@\n-  JVMWrapper(\"JVM_GC\");\n-    if (AsyncDeflateIdleMonitors) {\n-      \/\/ AsyncDeflateIdleMonitors needs to know when System.gc() is\n-      \/\/ called so any special deflation can be done at a safepoint.\n-      ObjectSynchronizer::set_is_special_deflation_requested(true);\n-    }\n+    EventSystemGC event;\n+    event.set_invokedConcurrent(ExplicitGCInvokesConcurrent);\n@@ -507,0 +452,1 @@\n+    event.commit();\n@@ -512,2 +458,1 @@\n-  JVMWrapper(\"JVM_MaxObjectInspectionAge\");\n-  return Universe::heap()->millis_since_last_gc();\n+  return Universe::heap()->millis_since_last_whole_heap_examined();\n@@ -524,1 +469,0 @@\n-  JVMWrapper(\"JVM_TotalMemory\");\n@@ -531,1 +475,0 @@\n-  JVMWrapper(\"JVM_FreeMemory\");\n@@ -538,1 +481,0 @@\n-  JVMWrapper(\"JVM_MaxMemory\");\n@@ -545,1 +487,0 @@\n-  JVMWrapper(\"JVM_ActiveProcessorCount\");\n@@ -549,1 +490,8 @@\n-\n+JVM_ENTRY_NO_ENV(jboolean, JVM_IsUseContainerSupport(void))\n+#ifdef LINUX\n+  if (UseContainerSupport) {\n+    return JNI_TRUE;\n+  }\n+#endif\n+  return JNI_FALSE;\n+JVM_END\n@@ -554,1 +502,0 @@\n-  JVMWrapper(\"JVM_FillInStackTrace\");\n@@ -579,1 +526,1 @@\n-    return (jstring) JNIHandles::make_local(env, result);\n+    return (jstring) JNIHandles::make_local(THREAD, result);\n@@ -589,1 +536,0 @@\n-  JVMWrapper(\"JVM_InitStackTraceElementArray\");\n@@ -599,1 +545,0 @@\n-  JVMWrapper(\"JVM_InitStackTraceElement\");\n@@ -612,3 +557,1 @@\n-  JVMWrapper(\"JVM_CallStackWalk\");\n-  JavaThread* jt = (JavaThread*) THREAD;\n-  if (!jt->is_Java_thread() || !jt->has_last_Java_frame()) {\n+  if (!thread->has_last_Java_frame()) {\n@@ -633,1 +576,1 @@\n-  return JNIHandles::make_local(env, result);\n+  return JNIHandles::make_local(THREAD, result);\n@@ -640,3 +583,0 @@\n-  JVMWrapper(\"JVM_MoreStackWalk\");\n-  JavaThread* jt = (JavaThread*) THREAD;\n-\n@@ -663,1 +603,0 @@\n-  JVMWrapper(\"JVM_IHashCode\");\n@@ -670,1 +609,0 @@\n-  JVMWrapper(\"JVM_MonitorWait\");\n@@ -674,1 +612,1 @@\n-    JvmtiExport::post_monitor_wait((JavaThread *)THREAD, (oop)obj(), ms);\n+    JvmtiExport::post_monitor_wait(thread, obj(), ms);\n@@ -687,1 +625,0 @@\n-  JVMWrapper(\"JVM_MonitorNotify\");\n@@ -694,1 +631,0 @@\n-  JVMWrapper(\"JVM_MonitorNotifyAll\");\n@@ -701,1 +637,0 @@\n-  JVMWrapper(\"JVM_Clone\");\n@@ -712,1 +647,1 @@\n-    bool cloneable = klass->is_subtype_of(SystemDictionary::Cloneable_klass());\n+    bool cloneable = klass->is_subtype_of(vmClasses::Cloneable_klass());\n@@ -749,1 +684,1 @@\n-  return JNIHandles::make_local(env, new_obj());\n+  return JNIHandles::make_local(THREAD, new_obj());\n@@ -755,1 +690,0 @@\n-  JVMWrapper(\"JVM_NativePath\");\n@@ -764,2 +698,0 @@\n-  JVMWrapper(\"JVM_GetCallerClass\");\n-\n@@ -795,1 +727,1 @@\n-        return (jclass) JNIHandles::make_local(env, m->method_holder()->java_mirror());\n+        return (jclass) JNIHandles::make_local(THREAD, m->method_holder()->java_mirror());\n@@ -805,1 +737,0 @@\n-  JVMWrapper(\"JVM_FindPrimitiveClass\");\n@@ -814,1 +745,1 @@\n-    return (jclass) JNIHandles::make_local(env, mirror);\n+    return (jclass) JNIHandles::make_local(THREAD, mirror);\n@@ -824,2 +755,0 @@\n-  JVMWrapper(\"JVM_FindClassFromBootLoader\");\n-\n@@ -843,1 +772,1 @@\n-  return (jclass) JNIHandles::make_local(env, k->java_mirror());\n+  return (jclass) JNIHandles::make_local(THREAD, k->java_mirror());\n@@ -850,2 +779,0 @@\n-  JVMWrapper(\"JVM_FindClassFromCaller throws ClassNotFoundException\");\n-\n@@ -882,1 +809,0 @@\n-  JVMWrapper(\"JVM_FindClassFromClass\");\n@@ -917,14 +843,1 @@\n-static void is_lock_held_by_thread(Handle loader, PerfCounter* counter, TRAPS) {\n-  if (loader.is_null()) {\n-    return;\n-  }\n-\n-  \/\/ check whether the current caller thread holds the lock or not.\n-  \/\/ If not, increment the corresponding counter\n-  if (ObjectSynchronizer::query_lock_ownership((JavaThread*)THREAD, loader) !=\n-      ObjectSynchronizer::owner_self) {\n-    counter->inc();\n-  }\n-}\n-\n-static jclass jvm_define_class_common(JNIEnv *env, const char *name,\n+static jclass jvm_define_class_common(const char *name,\n@@ -937,2 +850,1 @@\n-  assert(THREAD->is_Java_thread(), \"must be a JavaThread\");\n-  JavaThread* jt = (JavaThread*) THREAD;\n+  JavaThread* jt = THREAD;\n@@ -959,6 +871,2 @@\n-  if (UsePerfData) {\n-    is_lock_held_by_thread(class_loader,\n-                           ClassLoader::sync_JVMDefineClassLockFreeCounter(),\n-                           THREAD);\n-  }\n-  Klass* k = SystemDictionary::resolve_from_stream(class_name,\n+  ClassLoadInfo cl_info(protection_domain);\n+  Klass* k = SystemDictionary::resolve_from_stream(&st, class_name,\n@@ -967,2 +875,1 @@\n-                                                   protection_domain,\n-                                                   &st,\n+                                                   cl_info,\n@@ -971,1 +878,1 @@\n-  if (log_is_enabled(Debug, class, resolve) && k != NULL) {\n+  if (log_is_enabled(Debug, class, resolve)) {\n@@ -975,1 +882,1 @@\n-  return (jclass) JNIHandles::make_local(env, k->java_mirror());\n+  return (jclass) JNIHandles::make_local(THREAD, k->java_mirror());\n@@ -989,1 +896,1 @@\n-static jclass jvm_lookup_define_class(JNIEnv *env, jclass lookup, const char *name,\n+static jclass jvm_lookup_define_class(jclass lookup, const char *name,\n@@ -992,2 +899,0 @@\n-  assert(THREAD->is_Java_thread(), \"must be a JavaThread\");\n-  JavaThread* jt = (JavaThread*) THREAD;\n@@ -1052,1 +957,0 @@\n-  Klass* defined_k;\n@@ -1055,8 +959,8 @@\n-    defined_k = SystemDictionary::resolve_from_stream(class_name,\n-                                                      class_loader,\n-                                                      protection_domain,\n-                                                      &st,\n-                                                      CHECK_NULL);\n-\n-    if (log_is_enabled(Debug, class, resolve) && defined_k != NULL) {\n-      trace_class_resolution(defined_k);\n+    ClassLoadInfo cl_info(protection_domain);\n+    ik = SystemDictionary::resolve_from_stream(&st, class_name,\n+                                               class_loader,\n+                                               cl_info,\n+                                               CHECK_NULL);\n+\n+    if (log_is_enabled(Debug, class, resolve)) {\n+      trace_class_resolution(ik);\n@@ -1064,1 +968,0 @@\n-    ik = InstanceKlass::cast(defined_k);\n@@ -1068,2 +971,0 @@\n-                          NULL, \/\/ unsafe_anonymous_host\n-                          NULL, \/\/ cp_patches\n@@ -1075,1 +976,1 @@\n-    defined_k = SystemDictionary::parse_stream(class_name,\n+    ik = SystemDictionary::resolve_from_stream(&st, class_name,\n@@ -1077,1 +978,0 @@\n-                                               &st,\n@@ -1080,5 +980,0 @@\n-    if (defined_k == NULL) {\n-      THROW_MSG_0(vmSymbols::java_lang_Error(), \"Failure to define a hidden class\");\n-    }\n-\n-    ik = InstanceKlass::cast(defined_k);\n@@ -1101,1 +996,1 @@\n-  assert(Reflection::is_same_class_package(lookup_k, defined_k),\n+  assert(Reflection::is_same_class_package(lookup_k, ik),\n@@ -1110,1 +1005,1 @@\n-  return (jclass) JNIHandles::make_local(env, defined_k->java_mirror());\n+  return (jclass) JNIHandles::make_local(THREAD, ik->java_mirror());\n@@ -1114,3 +1009,1 @@\n-  JVMWrapper(\"JVM_DefineClass\");\n-\n-  return jvm_define_class_common(env, name, loader, buf, len, pd, NULL, THREAD);\n+  return jvm_define_class_common(name, loader, buf, len, pd, NULL, THREAD);\n@@ -1132,1 +1025,0 @@\n-  JVMWrapper(\"JVM_LookupDefineClass\");\n@@ -1140,1 +1032,1 @@\n-  return jvm_lookup_define_class(env, lookup, name, buf, len, pd, initialize, flags, classData, THREAD);\n+  return jvm_lookup_define_class(lookup, name, buf, len, pd, initialize, flags, classData, THREAD);\n@@ -1144,2 +1036,1 @@\n-  JVMWrapper(\"JVM_DefineClassWithSource\");\n-  return jvm_define_class_common(env, name, loader, buf, len, pd, source, THREAD);\n+  return jvm_define_class_common(name, loader, buf, len, pd, source, THREAD);\n@@ -1150,1 +1041,0 @@\n-  JVMWrapper(\"JVM_FindLoadedClass\");\n@@ -1162,4 +1052,4 @@\n-      if (*p == '.') {\n-          *p = '\/';\n-      }\n-      p++;\n+    if (*p == '.') {\n+      *p = '\/';\n+    }\n+    p++;\n@@ -1180,6 +1070,0 @@\n-  if (UsePerfData) {\n-    is_lock_held_by_thread(h_loader,\n-                           ClassLoader::sync_JVMFindLoadedClassLockFreeCounter(),\n-                           THREAD);\n-  }\n-\n@@ -1188,2 +1072,1 @@\n-                                                              Handle(),\n-                                                              CHECK_NULL);\n+                                                              Handle());\n@@ -1198,1 +1081,1 @@\n-            (jclass) JNIHandles::make_local(env, k->java_mirror());\n+            (jclass) JNIHandles::make_local(THREAD, k->java_mirror());\n@@ -1205,2 +1088,2 @@\n-  JVMWrapper(\"JVM_DefineModule\");\n-  Modules::define_module(module, is_open, version, location, packages, CHECK);\n+  Handle h_module (THREAD, JNIHandles::resolve(module));\n+  Modules::define_module(h_module, is_open, version, location, packages, CHECK);\n@@ -1210,2 +1093,2 @@\n-  JVMWrapper(\"JVM_SetBootLoaderUnnamedModule\");\n-  Modules::set_bootloader_unnamed_module(module, CHECK);\n+  Handle h_module (THREAD, JNIHandles::resolve(module));\n+  Modules::set_bootloader_unnamed_module(h_module, CHECK);\n@@ -1215,2 +1098,3 @@\n-  JVMWrapper(\"JVM_AddModuleExports\");\n-  Modules::add_module_exports_qualified(from_module, package, to_module, CHECK);\n+  Handle h_from_module (THREAD, JNIHandles::resolve(from_module));\n+  Handle h_to_module (THREAD, JNIHandles::resolve(to_module));\n+  Modules::add_module_exports_qualified(h_from_module, package, h_to_module, CHECK);\n@@ -1220,2 +1104,2 @@\n-  JVMWrapper(\"JVM_AddModuleExportsToAllUnnamed\");\n-  Modules::add_module_exports_to_all_unnamed(from_module, package, CHECK);\n+  Handle h_from_module (THREAD, JNIHandles::resolve(from_module));\n+  Modules::add_module_exports_to_all_unnamed(h_from_module, package, CHECK);\n@@ -1225,2 +1109,2 @@\n-  JVMWrapper(\"JVM_AddModuleExportsToAll\");\n-  Modules::add_module_exports(from_module, package, NULL, CHECK);\n+  Handle h_from_module (THREAD, JNIHandles::resolve(from_module));\n+  Modules::add_module_exports(h_from_module, package, Handle(), CHECK);\n@@ -1230,2 +1114,9 @@\n-  JVMWrapper(\"JVM_AddReadsModule\");\n-  Modules::add_reads_module(from_module, source_module, CHECK);\n+  Handle h_from_module (THREAD, JNIHandles::resolve(from_module));\n+  Handle h_source_module (THREAD, JNIHandles::resolve(source_module));\n+  Modules::add_reads_module(h_from_module, h_source_module, CHECK);\n+JVM_END\n+\n+JVM_ENTRY(void, JVM_DefineArchivedModules(JNIEnv *env, jobject platform_loader, jobject system_loader))\n+  Handle h_platform_loader (THREAD, JNIHandles::resolve(platform_loader));\n+  Handle h_system_loader (THREAD, JNIHandles::resolve(system_loader));\n+  Modules::define_archived_modules(h_platform_loader, h_system_loader, CHECK);\n@@ -1238,1 +1129,0 @@\n-  JVMWrapper(\"JVM_InitClassName\");\n@@ -1244,1 +1134,1 @@\n-  return (jstring) JNIHandles::make_local(env, result);\n+  return (jstring) JNIHandles::make_local(THREAD, result);\n@@ -1249,1 +1139,0 @@\n-  JVMWrapper(\"JVM_GetClassInterfaces\");\n@@ -1256,2 +1145,2 @@\n-    objArrayOop r = oopFactory::new_objArray(SystemDictionary::Class_klass(), 0, CHECK_NULL);\n-    return (jobjectArray) JNIHandles::make_local(env, r);\n+    objArrayOop r = oopFactory::new_objArray(vmClasses::Class_klass(), 0, CHECK_NULL);\n+    return (jobjectArray) JNIHandles::make_local(THREAD, r);\n@@ -1271,1 +1160,1 @@\n-  objArrayOop r = oopFactory::new_objArray(SystemDictionary::Class_klass(), size, CHECK_NULL);\n+  objArrayOop r = oopFactory::new_objArray(vmClasses::Class_klass(), size, CHECK_NULL);\n@@ -1282,2 +1171,2 @@\n-    result->obj_at_put(0, SystemDictionary::Cloneable_klass()->java_mirror());\n-    result->obj_at_put(1, SystemDictionary::Serializable_klass()->java_mirror());\n+    result->obj_at_put(0, vmClasses::Cloneable_klass()->java_mirror());\n+    result->obj_at_put(1, vmClasses::Serializable_klass()->java_mirror());\n@@ -1285,1 +1174,1 @@\n-  return (jobjectArray) JNIHandles::make_local(env, result());\n+  return (jobjectArray) JNIHandles::make_local(THREAD, result());\n@@ -1290,1 +1179,0 @@\n-  JVMWrapper(\"JVM_IsInterface\");\n@@ -1305,1 +1193,0 @@\n-  JVMWrapper(\"JVM_IsHiddenClass\");\n@@ -1315,2 +1202,2 @@\n-  JVMWrapper(\"JVM_GetClassSigners\");\n-  if (java_lang_Class::is_primitive(JNIHandles::resolve_non_null(cls))) {\n+  oop mirror = JNIHandles::resolve_non_null(cls);\n+  if (java_lang_Class::is_primitive(mirror)) {\n@@ -1322,1 +1209,1 @@\n-  objArrayHandle signers(THREAD, java_lang_Class::signers(JNIHandles::resolve_non_null(cls)));\n+  objArrayHandle signers(THREAD, java_lang_Class::signers(mirror));\n@@ -1336,1 +1223,1 @@\n-  return (jobjectArray) JNIHandles::make_local(env, signers_copy);\n+  return (jobjectArray) JNIHandles::make_local(THREAD, signers_copy);\n@@ -1341,2 +1228,2 @@\n-  JVMWrapper(\"JVM_SetClassSigners\");\n-  if (!java_lang_Class::is_primitive(JNIHandles::resolve_non_null(cls))) {\n+  oop mirror = JNIHandles::resolve_non_null(cls);\n+  if (!java_lang_Class::is_primitive(mirror)) {\n@@ -1346,1 +1233,1 @@\n-    Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n+    Klass* k = java_lang_Class::as_Klass(mirror);\n@@ -1355,2 +1242,2 @@\n-  JVMWrapper(\"JVM_GetProtectionDomain\");\n-  if (JNIHandles::resolve(cls) == NULL) {\n+  oop mirror = JNIHandles::resolve_non_null(cls);\n+  if (mirror == NULL) {\n@@ -1360,1 +1247,1 @@\n-  if (java_lang_Class::is_primitive(JNIHandles::resolve(cls))) {\n+  if (java_lang_Class::is_primitive(mirror)) {\n@@ -1365,2 +1252,2 @@\n-  oop pd = java_lang_Class::protection_domain(JNIHandles::resolve(cls));\n-  return (jobject) JNIHandles::make_local(env, pd);\n+  oop pd = java_lang_Class::protection_domain(mirror);\n+  return (jobject) JNIHandles::make_local(THREAD, pd);\n@@ -1372,2 +1259,1 @@\n-  JVMWrapper(\"JVM_GetInheritedAccessControlContext\");\n-  return JNIHandles::make_local(env, result);\n+  return JNIHandles::make_local(THREAD, result);\n@@ -1377,16 +1263,0 @@\n-class RegisterArrayForGC {\n- private:\n-  JavaThread *_thread;\n- public:\n-  RegisterArrayForGC(JavaThread *thread, GrowableArray<oop>* array)  {\n-    _thread = thread;\n-    _thread->register_array_for_gc(array);\n-  }\n-\n-  ~RegisterArrayForGC() {\n-    _thread->register_array_for_gc(NULL);\n-  }\n-};\n-\n-\n-  JVMWrapper(\"JVM_GetStackAccessControlContext\");\n@@ -1397,1 +1267,1 @@\n-  GrowableArray<oop>* local_array = new GrowableArray<oop>(12);\n+  GrowableArray<Handle>* local_array = new GrowableArray<Handle>(12);\n@@ -1416,1 +1286,1 @@\n-    if (method->method_holder() == SystemDictionary::AccessController_klass() &&\n+    if (method->method_holder() == vmClasses::AccessController_klass() &&\n@@ -1439,1 +1309,1 @@\n-      local_array->push(protection_domain);\n+      local_array->push(Handle(thread, protection_domain));\n@@ -1453,1 +1323,1 @@\n-    return JNIHandles::make_local(env, result);\n+    return JNIHandles::make_local(THREAD, result);\n@@ -1456,3 +1326,1 @@\n-  \/\/ the resource area must be registered in case of a gc\n-  RegisterArrayForGC ragc(thread, local_array);\n-  objArrayOop context = oopFactory::new_objArray(SystemDictionary::ProtectionDomain_klass(),\n+  objArrayOop context = oopFactory::new_objArray(vmClasses::ProtectionDomain_klass(),\n@@ -1462,1 +1330,1 @@\n-    h_context->obj_at_put(index, local_array->at(index));\n+    h_context->obj_at_put(index, local_array->at(index)());\n@@ -1467,1 +1335,1 @@\n-  return JNIHandles::make_local(env, result);\n+  return JNIHandles::make_local(THREAD, result);\n@@ -1472,1 +1340,0 @@\n-  JVMWrapper(\"JVM_IsArrayClass\");\n@@ -1479,1 +1346,0 @@\n-  JVMWrapper(\"JVM_IsPrimitiveClass\");\n@@ -1486,2 +1352,2 @@\n-  JVMWrapper(\"JVM_GetClassModifiers\");\n-  if (java_lang_Class::is_primitive(JNIHandles::resolve_non_null(cls))) {\n+  oop mirror = JNIHandles::resolve_non_null(cls);\n+  if (java_lang_Class::is_primitive(mirror)) {\n@@ -1492,2 +1358,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  debug_only(int computed_modifiers = k->compute_modifier_flags(CHECK_0));\n+  Klass* k = java_lang_Class::as_Klass(mirror);\n+  debug_only(int computed_modifiers = k->compute_modifier_flags());\n@@ -1505,5 +1371,5 @@\n-\n-  if (java_lang_Class::is_primitive(JNIHandles::resolve_non_null(ofClass)) ||\n-      ! java_lang_Class::as_Klass(JNIHandles::resolve_non_null(ofClass))->is_instance_klass()) {\n-    oop result = oopFactory::new_objArray(SystemDictionary::Class_klass(), 0, CHECK_NULL);\n-    return (jobjectArray)JNIHandles::make_local(env, result);\n+  oop ofMirror = JNIHandles::resolve_non_null(ofClass);\n+  if (java_lang_Class::is_primitive(ofMirror) ||\n+      ! java_lang_Class::as_Klass(ofMirror)->is_instance_klass()) {\n+    oop result = oopFactory::new_objArray(vmClasses::Class_klass(), 0, CHECK_NULL);\n+    return (jobjectArray)JNIHandles::make_local(THREAD, result);\n@@ -1512,1 +1378,1 @@\n-  InstanceKlass* k = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve_non_null(ofClass)));\n+  InstanceKlass* k = InstanceKlass::cast(java_lang_Class::as_Klass(ofMirror));\n@@ -1517,2 +1383,2 @@\n-    oop result = oopFactory::new_objArray(SystemDictionary::Class_klass(), 0, CHECK_NULL);\n-    return (jobjectArray)JNIHandles::make_local(env, result);\n+    oop result = oopFactory::new_objArray(vmClasses::Class_klass(), 0, CHECK_NULL);\n+    return (jobjectArray)JNIHandles::make_local(THREAD, result);\n@@ -1526,1 +1392,1 @@\n-  objArrayOop r = oopFactory::new_objArray(SystemDictionary::Class_klass(), length\/4, CHECK_NULL);\n+  objArrayOop r = oopFactory::new_objArray(vmClasses::Class_klass(), length\/4, CHECK_NULL);\n@@ -1556,1 +1422,1 @@\n-    objArrayOop res = oopFactory::new_objArray(SystemDictionary::Class_klass(), members, CHECK_NULL);\n+    objArrayOop res = oopFactory::new_objArray(vmClasses::Class_klass(), members, CHECK_NULL);\n@@ -1560,1 +1426,1 @@\n-    return (jobjectArray)JNIHandles::make_local(env, res);\n+    return (jobjectArray)JNIHandles::make_local(THREAD, res);\n@@ -1563,1 +1429,1 @@\n-  return (jobjectArray)JNIHandles::make_local(env, result());\n+  return (jobjectArray)JNIHandles::make_local(THREAD, result());\n@@ -1570,2 +1436,6 @@\n-  if (java_lang_Class::is_primitive(JNIHandles::resolve_non_null(ofClass)) ||\n-      ! java_lang_Class::as_Klass(JNIHandles::resolve_non_null(ofClass))->is_instance_klass()) {\n+  oop ofMirror = JNIHandles::resolve_non_null(ofClass);\n+  if (java_lang_Class::is_primitive(ofMirror)) {\n+    return NULL;\n+  }\n+  Klass* klass = java_lang_Class::as_Klass(ofMirror);\n+  if (!klass->is_instance_klass()) {\n@@ -1577,2 +1447,1 @@\n-    = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve_non_null(ofClass))\n-                          )->compute_enclosing_class(&inner_is_member, CHECK_NULL);\n+    = InstanceKlass::cast(klass)->compute_enclosing_class(&inner_is_member, CHECK_NULL);\n@@ -1580,2 +1449,2 @@\n-  if (!inner_is_member)  return NULL;     \/\/ a hidden or unsafe anonymous class (inside a method)\n-  return (jclass) JNIHandles::make_local(env, outer_klass->java_mirror());\n+  if (!inner_is_member)  return NULL;     \/\/ a hidden class (inside a method)\n+  return (jclass) JNIHandles::make_local(THREAD, outer_klass->java_mirror());\n@@ -1588,2 +1457,1 @@\n-  if (java_lang_Class::is_primitive(mirror) ||\n-      !java_lang_Class::as_Klass(mirror)->is_instance_klass()) {\n+  if (java_lang_Class::is_primitive(mirror)) {\n@@ -1592,1 +1460,5 @@\n-  InstanceKlass* k = InstanceKlass::cast(java_lang_Class::as_Klass(mirror));\n+  Klass* klass = java_lang_Class::as_Klass(mirror);\n+  if (!klass->is_instance_klass()) {\n+    return NULL;\n+  }\n+  InstanceKlass* k = InstanceKlass::cast(klass);\n@@ -1599,1 +1471,1 @@\n-      return (jstring) JNIHandles::make_local(env, str());\n+      return (jstring) JNIHandles::make_local(THREAD, str());\n@@ -1608,1 +1480,0 @@\n-  JVMWrapper(\"JVM_GetClassSignature\");\n@@ -1611,0 +1482,1 @@\n+  oop mirror = JNIHandles::resolve_non_null(cls);\n@@ -1612,2 +1484,2 @@\n-  if (!java_lang_Class::is_primitive(JNIHandles::resolve(cls))) {\n-    Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve(cls));\n+  if (!java_lang_Class::is_primitive(mirror)) {\n+    Klass* k = java_lang_Class::as_Klass(mirror);\n@@ -1618,1 +1490,1 @@\n-      return (jstring) JNIHandles::make_local(env, str());\n+      return (jstring) JNIHandles::make_local(THREAD, str());\n@@ -1627,2 +1499,1 @@\n-  JVMWrapper(\"JVM_GetClassAnnotations\");\n-\n+  oop mirror = JNIHandles::resolve_non_null(cls);\n@@ -1630,2 +1501,2 @@\n-  if (!java_lang_Class::is_primitive(JNIHandles::resolve(cls))) {\n-    Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve(cls));\n+  if (!java_lang_Class::is_primitive(mirror)) {\n+    Klass* k = java_lang_Class::as_Klass(mirror);\n@@ -1634,1 +1505,1 @@\n-      return (jbyteArray) JNIHandles::make_local(env, a);\n+      return (jbyteArray) JNIHandles::make_local(THREAD, a);\n@@ -1641,1 +1512,1 @@\n-static bool jvm_get_field_common(jobject field, fieldDescriptor& fd, TRAPS) {\n+static bool jvm_get_field_common(jobject field, fieldDescriptor& fd) {\n@@ -1677,1 +1548,1 @@\n-  if (reflected->klass() == SystemDictionary::reflect_Constructor_klass()) {\n+  if (reflected->klass() == vmClasses::reflect_Constructor_klass()) {\n@@ -1681,1 +1552,1 @@\n-    assert(reflected->klass() == SystemDictionary::reflect_Method_klass(),\n+    assert(reflected->klass() == vmClasses::reflect_Method_klass(),\n@@ -1697,1 +1568,0 @@\n-  JVMWrapper(\"JVM_GetClassTypeAnnotations\");\n@@ -1706,1 +1576,1 @@\n-        return (jbyteArray) JNIHandles::make_local(env, a);\n+        return (jbyteArray) JNIHandles::make_local(THREAD, a);\n@@ -1715,2 +1585,0 @@\n-  JVMWrapper(\"JVM_GetMethodTypeAnnotations\");\n-\n@@ -1726,1 +1594,1 @@\n-    return (jbyteArray) JNIHandles::make_local(env, a);\n+    return (jbyteArray) JNIHandles::make_local(THREAD, a);\n@@ -1734,3 +1602,1 @@\n-  JVMWrapper(\"JVM_GetFieldTypeAnnotations\");\n-\n-  bool gotFd = jvm_get_field_common(field, fd, CHECK_NULL);\n+  bool gotFd = jvm_get_field_common(field, fd);\n@@ -1742,1 +1608,1 @@\n-  return (jbyteArray) JNIHandles::make_local(env, Annotations::make_java_array(fd.type_annotations(), THREAD));\n+  return (jbyteArray) JNIHandles::make_local(THREAD, Annotations::make_java_array(fd.type_annotations(), THREAD));\n@@ -1753,1 +1619,0 @@\n-  JVMWrapper(\"JVM_GetMethodParameters\");\n@@ -1785,1 +1650,1 @@\n-    objArrayOop result_oop = oopFactory::new_objArray(SystemDictionary::reflect_Parameter_klass(), num_params, CHECK_NULL);\n+    objArrayOop result_oop = oopFactory::new_objArray(vmClasses::reflect_Parameter_klass(), num_params, CHECK_NULL);\n@@ -1798,1 +1663,1 @@\n-    return (jobjectArray)JNIHandles::make_local(env, result());\n+    return (jobjectArray)JNIHandles::make_local(THREAD, result());\n@@ -1807,1 +1672,0 @@\n-  JVMWrapper(\"JVM_GetClassDeclaredFields\");\n@@ -1810,0 +1674,1 @@\n+  oop ofMirror = JNIHandles::resolve_non_null(ofClass);\n@@ -1811,2 +1676,2 @@\n-  if (java_lang_Class::is_primitive(JNIHandles::resolve_non_null(ofClass)) ||\n-      java_lang_Class::as_Klass(JNIHandles::resolve_non_null(ofClass))->is_array_klass()) {\n+  if (java_lang_Class::is_primitive(ofMirror) ||\n+      java_lang_Class::as_Klass(ofMirror)->is_array_klass()) {\n@@ -1814,2 +1679,2 @@\n-    oop res = oopFactory::new_objArray(SystemDictionary::reflect_Field_klass(), 0, CHECK_NULL);\n-    return (jobjectArray) JNIHandles::make_local(env, res);\n+    oop res = oopFactory::new_objArray(vmClasses::reflect_Field_klass(), 0, CHECK_NULL);\n+    return (jobjectArray) JNIHandles::make_local(THREAD, res);\n@@ -1818,1 +1683,1 @@\n-  InstanceKlass* k = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve_non_null(ofClass)));\n+  InstanceKlass* k = InstanceKlass::cast(java_lang_Class::as_Klass(ofMirror));\n@@ -1836,1 +1701,1 @@\n-  objArrayOop r = oopFactory::new_objArray(SystemDictionary::reflect_Field_klass(), num_fields, CHECK_NULL);\n+  objArrayOop r = oopFactory::new_objArray(vmClasses::reflect_Field_klass(), num_fields, CHECK_NULL);\n@@ -1850,1 +1715,1 @@\n-  return (jobjectArray) JNIHandles::make_local(env, result());\n+  return (jobjectArray) JNIHandles::make_local(THREAD, result());\n@@ -1854,0 +1719,2 @@\n+\/\/ A class is a record if and only if it is final and a direct subclass of\n+\/\/ java.lang.Record and has a Record attribute; otherwise, it is not a record.\n@@ -1856,1 +1723,0 @@\n-  JVMWrapper(\"JVM_IsRecord\");\n@@ -1867,0 +1733,5 @@\n+\/\/ Returns an array containing the components of the Record attribute,\n+\/\/ or NULL if the attribute is not present.\n+\/\/\n+\/\/ Note that this function returns the components of the Record attribute\n+\/\/ even if the class is not a record.\n@@ -1869,1 +1740,0 @@\n-  JVMWrapper(\"JVM_GetRecordComponents\");\n@@ -1874,19 +1744,15 @@\n-  if (ik->is_record()) {\n-    Array<RecordComponent*>* components = ik->record_components();\n-    assert(components != NULL, \"components should not be NULL\");\n-    {\n-      JvmtiVMObjectAllocEventCollector oam;\n-      constantPoolHandle cp(THREAD, ik->constants());\n-      int length = components->length();\n-      assert(length >= 0, \"unexpected record_components length\");\n-      objArrayOop record_components =\n-        oopFactory::new_objArray(SystemDictionary::RecordComponent_klass(), length, CHECK_NULL);\n-      objArrayHandle components_h (THREAD, record_components);\n-\n-      for (int x = 0; x < length; x++) {\n-        RecordComponent* component = components->at(x);\n-        assert(component != NULL, \"unexpected NULL record component\");\n-        oop component_oop = java_lang_reflect_RecordComponent::create(ik, component, CHECK_NULL);\n-        components_h->obj_at_put(x, component_oop);\n-      }\n-      return (jobjectArray)JNIHandles::make_local(components_h());\n+  Array<RecordComponent*>* components = ik->record_components();\n+  if (components != NULL) {\n+    JvmtiVMObjectAllocEventCollector oam;\n+    constantPoolHandle cp(THREAD, ik->constants());\n+    int length = components->length();\n+    assert(length >= 0, \"unexpected record_components length\");\n+    objArrayOop record_components =\n+      oopFactory::new_objArray(vmClasses::RecordComponent_klass(), length, CHECK_NULL);\n+    objArrayHandle components_h (THREAD, record_components);\n+\n+    for (int x = 0; x < length; x++) {\n+      RecordComponent* component = components->at(x);\n+      assert(component != NULL, \"unexpected NULL record component\");\n+      oop component_oop = java_lang_reflect_RecordComponent::create(ik, component, CHECK_NULL);\n+      components_h->obj_at_put(x, component_oop);\n@@ -1894,0 +1760,1 @@\n+    return (jobjectArray)JNIHandles::make_local(THREAD, components_h());\n@@ -1896,3 +1763,1 @@\n-  \/\/ Return empty array if ofClass is not a record.\n-  objArrayOop result = oopFactory::new_objArray(SystemDictionary::RecordComponent_klass(), 0, CHECK_NULL);\n-  return (jobjectArray)JNIHandles::make_local(env, result);\n+  return NULL;\n@@ -1918,0 +1783,1 @@\n+  oop ofMirror = JNIHandles::resolve_non_null(ofClass);\n@@ -1919,2 +1785,2 @@\n-  if (java_lang_Class::is_primitive(JNIHandles::resolve_non_null(ofClass))\n-      || java_lang_Class::as_Klass(JNIHandles::resolve_non_null(ofClass))->is_array_klass()) {\n+  if (java_lang_Class::is_primitive(ofMirror)\n+      || java_lang_Class::as_Klass(ofMirror)->is_array_klass()) {\n@@ -1923,1 +1789,1 @@\n-    return (jobjectArray) JNIHandles::make_local(env, res);\n+    return (jobjectArray) JNIHandles::make_local(THREAD, res);\n@@ -1926,1 +1792,1 @@\n-  InstanceKlass* k = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve_non_null(ofClass)));\n+  InstanceKlass* k = InstanceKlass::cast(java_lang_Class::as_Klass(ofMirror));\n@@ -1976,1 +1842,1 @@\n-  return (jobjectArray) JNIHandles::make_local(env, result());\n+  return (jobjectArray) JNIHandles::make_local(THREAD, result());\n@@ -1981,1 +1847,0 @@\n-  JVMWrapper(\"JVM_GetClassDeclaredMethods\");\n@@ -1984,1 +1849,1 @@\n-                                           SystemDictionary::reflect_Method_klass(), THREAD);\n+                                           vmClasses::reflect_Method_klass(), THREAD);\n@@ -1990,1 +1855,0 @@\n-  JVMWrapper(\"JVM_GetClassDeclaredConstructors\");\n@@ -1993,1 +1857,1 @@\n-                                           SystemDictionary::reflect_Constructor_klass(), THREAD);\n+                                           vmClasses::reflect_Constructor_klass(), THREAD);\n@@ -1999,2 +1863,2 @@\n-  JVMWrapper(\"JVM_GetClassAccessFlags\");\n-  if (java_lang_Class::is_primitive(JNIHandles::resolve_non_null(cls))) {\n+  oop mirror = JNIHandles::resolve_non_null(cls);\n+  if (java_lang_Class::is_primitive(mirror)) {\n@@ -2005,1 +1869,1 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n+  Klass* k = java_lang_Class::as_Klass(mirror);\n@@ -2012,1 +1876,0 @@\n-  JVMWrapper(\"JVM_AreNestMates\");\n@@ -2026,1 +1889,0 @@\n-  JVMWrapper(\"JVM_GetNestHost\");\n@@ -2039,1 +1901,0 @@\n-  JVMWrapper(\"JVM_GetNestMembers\");\n@@ -2056,1 +1917,1 @@\n-    objArrayOop r = oopFactory::new_objArray(SystemDictionary::Class_klass(),\n+    objArrayOop r = oopFactory::new_objArray(vmClasses::Class_klass(),\n@@ -2066,1 +1927,1 @@\n-          if (PENDING_EXCEPTION->is_a(SystemDictionary::VirtualMachineError_klass())) {\n+          if (PENDING_EXCEPTION->is_a(vmClasses::VirtualMachineError_klass())) {\n@@ -2100,1 +1961,1 @@\n-        objArrayOop r2 = oopFactory::new_objArray(SystemDictionary::Class_klass(),\n+        objArrayOop r2 = oopFactory::new_objArray(vmClasses::Class_klass(),\n@@ -2119,3 +1980,3 @@\n-  JVMWrapper(\"JVM_GetPermittedSubclasses\");\n-  assert(!java_lang_Class::is_primitive(JNIHandles::resolve_non_null(current)), \"should not be\");\n-  Klass* c = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(current));\n+  oop mirror = JNIHandles::resolve_non_null(current);\n+  assert(!java_lang_Class::is_primitive(mirror), \"should not be\");\n+  Klass* c = java_lang_Class::as_Klass(mirror);\n@@ -2124,1 +1985,4 @@\n-  {\n+  ResourceMark rm(THREAD);\n+  log_trace(class, sealed)(\"Calling GetPermittedSubclasses for %s type %s\",\n+                           ik->is_sealed() ? \"sealed\" : \"non-sealed\", ik->external_name());\n+  if (ik->is_sealed()) {\n@@ -2127,2 +1991,5 @@\n-    int length = subclasses == NULL ? 0 : subclasses->length();\n-    objArrayOop r = oopFactory::new_objArray(SystemDictionary::String_klass(),\n+    int length = subclasses->length();\n+\n+    log_trace(class, sealed)(\" - sealed class has %d permitted subclasses\", length);\n+\n+    objArrayOop r = oopFactory::new_objArray(vmClasses::Class_klass(),\n@@ -2131,0 +1998,1 @@\n+    int count = 0;\n@@ -2133,5 +2001,30 @@\n-      \/\/ This returns <package-name>\/<class-name>.\n-      Symbol* klass_name = ik->constants()->klass_name_at(cp_index);\n-      assert(klass_name != NULL, \"Unexpected null klass_name\");\n-      Handle perm_subtype_h = java_lang_String::create_from_symbol(klass_name, CHECK_NULL);\n-      result->obj_at_put(i, perm_subtype_h());\n+      Klass* k = ik->constants()->klass_at(cp_index, THREAD);\n+      if (HAS_PENDING_EXCEPTION) {\n+        if (PENDING_EXCEPTION->is_a(vmClasses::VirtualMachineError_klass())) {\n+          return NULL; \/\/ propagate VMEs\n+        }\n+        if (log_is_enabled(Trace, class, sealed)) {\n+          stringStream ss;\n+          char* permitted_subclass = ik->constants()->klass_name_at(cp_index)->as_C_string();\n+          ss.print(\" - resolution of permitted subclass %s failed: \", permitted_subclass);\n+          java_lang_Throwable::print(PENDING_EXCEPTION, &ss);\n+          log_trace(class, sealed)(\"%s\", ss.as_string());\n+        }\n+\n+        CLEAR_PENDING_EXCEPTION;\n+        continue;\n+      }\n+      if (k->is_instance_klass()) {\n+        result->obj_at_put(count++, k->java_mirror());\n+        log_trace(class, sealed)(\" - [%d] = %s\", count, k->external_name());\n+      }\n+    }\n+    if (count < length) {\n+      \/\/ we had invalid entries so we need to compact the array\n+      objArrayOop r2 = oopFactory::new_objArray(vmClasses::Class_klass(),\n+                                                count, CHECK_NULL);\n+      objArrayHandle result2(THREAD, r2);\n+      for (int i = 0; i < count; i++) {\n+        result2->obj_at_put(i, result->obj_at(i));\n+      }\n+      return (jobjectArray)JNIHandles::make_local(THREAD, result2());\n@@ -2140,0 +2033,2 @@\n+  } else {\n+    return NULL;\n@@ -2148,2 +2043,1 @@\n-  JVMWrapper(\"JVM_GetClassConstantPool\");\n-\n+  oop mirror = JNIHandles::resolve_non_null(cls);\n@@ -2152,2 +2046,2 @@\n-  if (!java_lang_Class::is_primitive(JNIHandles::resolve_non_null(cls))) {\n-    Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n+  if (!java_lang_Class::is_primitive(mirror)) {\n+    Klass* k = java_lang_Class::as_Klass(mirror);\n@@ -2158,1 +2052,1 @@\n-      return JNIHandles::make_local(jcp());\n+      return JNIHandles::make_local(THREAD, jcp());\n@@ -2168,1 +2062,0 @@\n-  JVMWrapper(\"JVM_ConstantPoolGetSize\");\n@@ -2177,1 +2070,0 @@\n-  JVMWrapper(\"JVM_ConstantPoolGetClassAt\");\n@@ -2185,1 +2077,1 @@\n-  return (jclass) JNIHandles::make_local(k->java_mirror());\n+  return (jclass) JNIHandles::make_local(THREAD, k->java_mirror());\n@@ -2191,1 +2083,0 @@\n-  JVMWrapper(\"JVM_ConstantPoolGetClassAtIfLoaded\");\n@@ -2200,1 +2091,1 @@\n-  return (jclass) JNIHandles::make_local(k->java_mirror());\n+  return (jclass) JNIHandles::make_local(THREAD, k->java_mirror());\n@@ -2230,1 +2121,1 @@\n-  return JNIHandles::make_local(method);\n+  return JNIHandles::make_local(THREAD, method);\n@@ -2235,1 +2126,0 @@\n-  JVMWrapper(\"JVM_ConstantPoolGetMethodAt\");\n@@ -2246,1 +2136,0 @@\n-  JVMWrapper(\"JVM_ConstantPoolGetMethodAtIfLoaded\");\n@@ -2277,1 +2166,1 @@\n-  return JNIHandles::make_local(field);\n+  return JNIHandles::make_local(THREAD, field);\n@@ -2282,1 +2171,0 @@\n-  JVMWrapper(\"JVM_ConstantPoolGetFieldAt\");\n@@ -2293,1 +2181,0 @@\n-  JVMWrapper(\"JVM_ConstantPoolGetFieldAtIfLoaded\");\n@@ -2304,1 +2191,0 @@\n-  JVMWrapper(\"JVM_ConstantPoolGetMemberRefInfoAt\");\n@@ -2316,1 +2202,1 @@\n-  objArrayOop  dest_o = oopFactory::new_objArray(SystemDictionary::String_klass(), 3, CHECK_NULL);\n+  objArrayOop  dest_o = oopFactory::new_objArray(vmClasses::String_klass(), 3, CHECK_NULL);\n@@ -2324,1 +2210,1 @@\n-  return (jobjectArray) JNIHandles::make_local(dest());\n+  return (jobjectArray) JNIHandles::make_local(THREAD, dest());\n@@ -2330,1 +2216,0 @@\n-  JVMWrapper(\"JVM_ConstantPoolGetClassRefIndexAt\");\n@@ -2344,1 +2229,0 @@\n-  JVMWrapper(\"JVM_ConstantPoolGetNameAndTypeRefIndexAt\");\n@@ -2358,1 +2242,0 @@\n-  JVMWrapper(\"JVM_ConstantPoolGetNameAndTypeRefInfoAt\");\n@@ -2368,1 +2251,1 @@\n-  objArrayOop dest_o = oopFactory::new_objArray(SystemDictionary::String_klass(), 2, CHECK_NULL);\n+  objArrayOop dest_o = oopFactory::new_objArray(vmClasses::String_klass(), 2, CHECK_NULL);\n@@ -2374,1 +2257,1 @@\n-  return (jobjectArray) JNIHandles::make_local(dest());\n+  return (jobjectArray) JNIHandles::make_local(THREAD, dest());\n@@ -2380,1 +2263,0 @@\n-  JVMWrapper(\"JVM_ConstantPoolGetIntAt\");\n@@ -2393,1 +2275,0 @@\n-  JVMWrapper(\"JVM_ConstantPoolGetLongAt\");\n@@ -2406,1 +2287,0 @@\n-  JVMWrapper(\"JVM_ConstantPoolGetFloatAt\");\n@@ -2419,1 +2299,0 @@\n-  JVMWrapper(\"JVM_ConstantPoolGetDoubleAt\");\n@@ -2432,1 +2311,0 @@\n-  JVMWrapper(\"JVM_ConstantPoolGetStringAt\");\n@@ -2440,1 +2318,1 @@\n-  return (jstring) JNIHandles::make_local(str);\n+  return (jstring) JNIHandles::make_local(THREAD, str);\n@@ -2446,1 +2324,0 @@\n-  JVMWrapper(\"JVM_ConstantPoolGetUTF8At\");\n@@ -2456,1 +2333,1 @@\n-  return (jstring) JNIHandles::make_local(str());\n+  return (jstring) JNIHandles::make_local(THREAD, str());\n@@ -2462,1 +2339,0 @@\n-  JVMWrapper(\"JVM_ConstantPoolGetTagAt\");\n@@ -2488,1 +2364,0 @@\n-  JVMWrapper(\"JVM_DesiredAssertionStatus\");\n@@ -2510,1 +2385,0 @@\n-  JVMWrapper(\"JVM_AssertionStatusDirectives\");\n@@ -2513,1 +2387,1 @@\n-  return JNIHandles::make_local(env, asd);\n+  return JNIHandles::make_local(THREAD, asd);\n@@ -2529,1 +2403,0 @@\n-  JVMWrapper(\"JVM_GetClassNameUTF\");\n@@ -2537,1 +2410,0 @@\n-  JVMWrapper(\"JVM_GetClassCPTypes\");\n@@ -2553,1 +2425,0 @@\n-  JVMWrapper(\"JVM_GetClassCPEntriesCount\");\n@@ -2561,1 +2432,0 @@\n-  JVMWrapper(\"JVM_GetClassFieldsCount\");\n@@ -2569,1 +2439,0 @@\n-  JVMWrapper(\"JVM_GetClassMethodsCount\");\n@@ -2582,1 +2451,0 @@\n-  JVMWrapper(\"JVM_GetMethodIxExceptionIndexes\");\n@@ -2597,1 +2465,0 @@\n-  JVMWrapper(\"JVM_GetMethodIxExceptionsCount\");\n@@ -2606,1 +2473,0 @@\n-  JVMWrapper(\"JVM_GetMethodIxByteCode\");\n@@ -2615,1 +2481,0 @@\n-  JVMWrapper(\"JVM_GetMethodIxByteCodeLength\");\n@@ -2624,1 +2489,0 @@\n-  JVMWrapper(\"JVM_GetMethodIxExceptionTableEntry\");\n@@ -2637,1 +2501,0 @@\n-  JVMWrapper(\"JVM_GetMethodIxExceptionTableLength\");\n@@ -2646,1 +2509,0 @@\n-  JVMWrapper(\"JVM_GetMethodIxModifiers\");\n@@ -2655,1 +2517,0 @@\n-  JVMWrapper(\"JVM_GetFieldIxModifiers\");\n@@ -2663,1 +2524,0 @@\n-  JVMWrapper(\"JVM_GetMethodIxLocalsCount\");\n@@ -2672,1 +2532,0 @@\n-  JVMWrapper(\"JVM_GetMethodIxArgsSize\");\n@@ -2681,1 +2540,0 @@\n-  JVMWrapper(\"JVM_GetMethodIxMaxStack\");\n@@ -2690,1 +2548,0 @@\n-  JVMWrapper(\"JVM_IsConstructorIx\");\n@@ -2700,1 +2557,0 @@\n-  JVMWrapper(\"JVM_IsVMGeneratedMethodIx\");\n@@ -2709,1 +2565,0 @@\n-  JVMWrapper(\"JVM_GetMethodIxIxUTF\");\n@@ -2718,1 +2573,0 @@\n-  JVMWrapper(\"JVM_GetMethodIxSignatureUTF\");\n@@ -2734,1 +2588,0 @@\n-  JVMWrapper(\"JVM_GetCPFieldNameUTF\");\n@@ -2750,1 +2603,0 @@\n-  JVMWrapper(\"JVM_GetCPMethodNameUTF\");\n@@ -2767,1 +2619,0 @@\n-  JVMWrapper(\"JVM_GetCPMethodSignatureUTF\");\n@@ -2784,1 +2635,0 @@\n-  JVMWrapper(\"JVM_GetCPFieldSignatureUTF\");\n@@ -2800,1 +2650,0 @@\n-  JVMWrapper(\"JVM_GetCPClassNameUTF\");\n@@ -2810,1 +2659,0 @@\n-  JVMWrapper(\"JVM_GetCPFieldClassNameUTF\");\n@@ -2829,1 +2677,0 @@\n-  JVMWrapper(\"JVM_GetCPMethodClassNameUTF\");\n@@ -2849,1 +2696,0 @@\n-  JVMWrapper(\"JVM_GetCPFieldModifiers\");\n@@ -2877,1 +2723,0 @@\n-  JVMWrapper(\"JVM_GetCPMethodModifiers\");\n@@ -2914,1 +2759,0 @@\n-  JVMWrapper(\"JVM_IsSameClassPackage\");\n@@ -3006,1 +2850,1 @@\n-                          SystemDictionary::Thread_klass(),\n+                          vmClasses::Thread_klass(),\n@@ -3014,1 +2858,0 @@\n-  JVMWrapper(\"JVM_StartThread\");\n@@ -3102,4 +2945,0 @@\n-  JVMWrapper(\"JVM_StopThread\");\n-\n-  \/\/ A nested ThreadsListHandle will grab the Threads_lock so create\n-  \/\/ tlh before we resolve throwable.\n@@ -3125,1 +2964,1 @@\n-      Thread::send_async_exception(java_thread, java_throwable);\n+      JavaThread::send_async_exception(java_thread, java_throwable);\n@@ -3141,2 +2980,0 @@\n-  JVMWrapper(\"JVM_IsThreadAlive\");\n-\n@@ -3149,2 +2986,0 @@\n-  JVMWrapper(\"JVM_SuspendThread\");\n-\n@@ -3155,16 +2990,2 @@\n-    \/\/ jthread refers to a live JavaThread.\n-    {\n-      MutexLocker ml(receiver->SR_lock(), Mutex::_no_safepoint_check_flag);\n-      if (receiver->is_external_suspend()) {\n-        \/\/ Don't allow nested external suspend requests. We can't return\n-        \/\/ an error from this interface so just ignore the problem.\n-        return;\n-      }\n-      if (receiver->is_exiting()) { \/\/ thread is in the process of exiting\n-        return;\n-      }\n-      receiver->set_external_suspend();\n-    }\n-\n-    \/\/ java_suspend() will catch threads in the process of exiting\n-    \/\/ and will ignore them.\n+    \/\/ jthread refers to a live JavaThread, but java_suspend() will\n+    \/\/ detect a thread that has started to exit and will ignore it.\n@@ -3172,9 +2993,0 @@\n-\n-    \/\/ It would be nice to have the following assertion in all the\n-    \/\/ time, but it is possible for a racing resume request to have\n-    \/\/ resumed this thread right after we suspended it. Temporarily\n-    \/\/ enable this assertion if you are chasing a different kind of\n-    \/\/ bug.\n-    \/\/\n-    \/\/ assert(java_lang_Thread::thread(receiver->threadObj()) == NULL ||\n-    \/\/   receiver->is_being_ext_suspended(), \"thread is not suspended\");\n@@ -3186,2 +2998,0 @@\n-  JVMWrapper(\"JVM_ResumeThread\");\n-\n@@ -3193,16 +3003,0 @@\n-\n-    \/\/ This is the original comment for this Threads_lock grab:\n-    \/\/   We need to *always* get the threads lock here, since this operation cannot be allowed during\n-    \/\/   a safepoint. The safepoint code relies on suspending a thread to examine its state. If other\n-    \/\/   threads randomly resumes threads, then a thread might not be suspended when the safepoint code\n-    \/\/   looks at it.\n-    \/\/\n-    \/\/ The above comment dates back to when we had both internal and\n-    \/\/ external suspend APIs that shared a common underlying mechanism.\n-    \/\/ External suspend is now entirely cooperative and doesn't share\n-    \/\/ anything with internal suspend. That said, there are some\n-    \/\/ assumptions in the VM that an external resume grabs the\n-    \/\/ Threads_lock. We can't drop the Threads_lock grab here until we\n-    \/\/ resolve the assumptions that exist elsewhere.\n-    \/\/\n-    MutexLocker ml(Threads_lock);\n@@ -3215,2 +3009,0 @@\n-  JVMWrapper(\"JVM_SetThreadPriority\");\n-\n@@ -3234,1 +3026,0 @@\n-  JVMWrapper(\"JVM_Yield\");\n@@ -3248,2 +3039,0 @@\n-  JVMWrapper(\"JVM_Sleep\");\n-\n@@ -3293,3 +3082,2 @@\n-  JVMWrapper(\"JVM_CurrentThread\");\n-  assert (thread != NULL, \"no current thread!\");\n-  return JNIHandles::make_local(env, jthread);\n+  assert(jthread != NULL, \"no current thread!\");\n+  return JNIHandles::make_local(THREAD, jthread);\n@@ -3300,2 +3088,0 @@\n-  JVMWrapper(\"JVM_Interrupt\");\n-\n@@ -3315,2 +3101,0 @@\n-  JVMWrapper(\"JVM_HoldsLock\");\n-  assert(THREAD->is_Java_thread(), \"sanity check\");\n@@ -3321,1 +3105,1 @@\n-  return ObjectSynchronizer::current_thread_holds_lock((JavaThread*)THREAD, h_obj);\n+  return ObjectSynchronizer::current_thread_holds_lock(thread, h_obj);\n@@ -3326,1 +3110,0 @@\n-  JVMWrapper(\"JVM_DumpAllStacks\");\n@@ -3335,2 +3118,0 @@\n-  JVMWrapper(\"JVM_SetNativeThreadName\");\n-\n@@ -3354,1 +3135,0 @@\n-  JVMWrapper(\"JVM_GetClassContext\");\n@@ -3359,1 +3139,1 @@\n-  if (SystemDictionary::reflect_CallerSensitive_klass() != NULL) {\n+  if (vmClasses::reflect_CallerSensitive_klass() != NULL) {\n@@ -3362,1 +3142,1 @@\n-    if (!(m->method_holder() == SystemDictionary::SecurityManager_klass() &&\n+    if (!(m->method_holder() == vmClasses::SecurityManager_klass() &&\n@@ -3382,1 +3162,1 @@\n-  objArrayOop result = oopFactory::new_objArray(SystemDictionary::Class_klass(), klass_array->length(), CHECK_NULL);\n+  objArrayOop result = oopFactory::new_objArray(vmClasses::Class_klass(), klass_array->length(), CHECK_NULL);\n@@ -3388,1 +3168,1 @@\n-  return (jobjectArray) JNIHandles::make_local(env, result);\n+  return (jobjectArray) JNIHandles::make_local(THREAD, result);\n@@ -3396,1 +3176,0 @@\n-  JVMWrapper(\"JVM_GetSystemPackage\");\n@@ -3401,1 +3180,1 @@\n-  return (jstring) JNIHandles::make_local(result);\n+return (jstring) JNIHandles::make_local(THREAD, result);\n@@ -3406,1 +3185,0 @@\n-  JVMWrapper(\"JVM_GetSystemPackages\");\n@@ -3409,1 +3187,1 @@\n-  return (jobjectArray) JNIHandles::make_local(result);\n+  return (jobjectArray) JNIHandles::make_local(THREAD, result);\n@@ -3416,1 +3194,0 @@\n-  JVMWrapper(\"JVM_GetTsanEnabled\");\n@@ -3426,2 +3203,0 @@\n-  JVMWrapper(\"JVM_GetAndClearReferencePendingList\");\n-\n@@ -3431,1 +3206,1 @@\n-    Universe::set_reference_pending_list(NULL);\n+    Universe::clear_reference_pending_list();\n@@ -3433,1 +3208,1 @@\n-  return JNIHandles::make_local(env, ref);\n+  return JNIHandles::make_local(THREAD, ref);\n@@ -3437,1 +3212,0 @@\n-  JVMWrapper(\"JVM_HasReferencePendingList\");\n@@ -3443,1 +3217,0 @@\n-  JVMWrapper(\"JVM_WaitForReferencePendingList\");\n@@ -3450,0 +3223,34 @@\n+JVM_ENTRY(jboolean, JVM_ReferenceRefersTo(JNIEnv* env, jobject ref, jobject o))\n+  oop ref_oop = JNIHandles::resolve_non_null(ref);\n+  oop referent = java_lang_ref_Reference::weak_referent_no_keepalive(ref_oop);\n+  return referent == JNIHandles::resolve(o);\n+JVM_END\n+\n+JVM_ENTRY(void, JVM_ReferenceClear(JNIEnv* env, jobject ref))\n+  oop ref_oop = JNIHandles::resolve_non_null(ref);\n+  \/\/ FinalReference has it's own implementation of clear().\n+  assert(!java_lang_ref_Reference::is_final(ref_oop), \"precondition\");\n+  if (java_lang_ref_Reference::unknown_referent_no_keepalive(ref_oop) == NULL) {\n+    \/\/ If the referent has already been cleared then done.\n+    \/\/ However, if the referent is dead but has not yet been cleared by\n+    \/\/ concurrent reference processing, it should NOT be cleared here.\n+    \/\/ Instead, clearing should be left to the GC.  Clearing it here could\n+    \/\/ detectably lose an expected notification, which is impossible with\n+    \/\/ STW reference processing.  The clearing in enqueue() doesn't have\n+    \/\/ this problem, since the enqueue covers the notification, but it's not\n+    \/\/ worth the effort to handle that case specially.\n+    return;\n+  }\n+  java_lang_ref_Reference::clear_referent(ref_oop);\n+JVM_END\n+\n+\n+\/\/ java.lang.ref.PhantomReference \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+\n+JVM_ENTRY(jboolean, JVM_PhantomReferenceRefersTo(JNIEnv* env, jobject ref, jobject o))\n+  oop ref_oop = JNIHandles::resolve_non_null(ref);\n+  oop referent = java_lang_ref_Reference::phantom_referent_no_keepalive(ref_oop);\n+  return referent == JNIHandles::resolve(o);\n+JVM_END\n+\n@@ -3458,2 +3265,2 @@\n-    vfst.skip_reflection_related_frames(); \/\/ Only needed for 1.4 reflection\n-    oop loader = vfst.method()->method_holder()->class_loader();\n+    InstanceKlass* ik = vfst.method()->method_holder();\n+    oop loader = ik->class_loader();\n@@ -3461,1 +3268,5 @@\n-      return JNIHandles::make_local(env, loader);\n+      \/\/ Skip reflection related frames\n+      if (!ik->is_subclass_of(vmClasses::reflect_MethodAccessorImpl_klass()) &&\n+          !ik->is_subclass_of(vmClasses::reflect_ConstructorAccessorImpl_klass())) {\n+        return JNIHandles::make_local(THREAD, loader);\n+      }\n@@ -3487,1 +3298,0 @@\n-  JVMWrapper(\"JVM_GetArrayLength\");\n@@ -3494,1 +3304,0 @@\n-  JVMWrapper(\"JVM_Array_Get\");\n@@ -3500,1 +3309,1 @@\n-  return JNIHandles::make_local(env, box);\n+  return JNIHandles::make_local(THREAD, box);\n@@ -3505,1 +3314,0 @@\n-  JVMWrapper(\"JVM_GetPrimitiveArrayElement\");\n@@ -3520,1 +3328,0 @@\n-  JVMWrapper(\"JVM_SetArrayElement\");\n@@ -3537,1 +3344,0 @@\n-  JVMWrapper(\"JVM_SetPrimitiveArrayElement\");\n@@ -3546,1 +3352,0 @@\n-  JVMWrapper(\"JVM_NewArray\");\n@@ -3550,1 +3355,1 @@\n-  return JNIHandles::make_local(env, result);\n+  return JNIHandles::make_local(THREAD, result);\n@@ -3555,1 +3360,0 @@\n-  JVMWrapper(\"JVM_NewMultiArray\");\n@@ -3561,1 +3365,1 @@\n-  return JNIHandles::make_local(env, result);\n+  return JNIHandles::make_local(THREAD, result);\n@@ -3569,1 +3373,0 @@\n-  JVMWrapper(\"JVM_LoadLibrary\");\n@@ -3596,1 +3399,0 @@\n-  JVMWrapper(\"JVM_UnloadLibrary\");\n@@ -3603,1 +3405,0 @@\n-  JVMWrapper(\"JVM_FindLibraryEntry\");\n@@ -3615,1 +3416,0 @@\n-  JVMWrapper(\"JVM_IsSupportedJNIVersion\");\n@@ -3623,1 +3423,0 @@\n-  JVMWrapper(\"JVM_InternString\");\n@@ -3628,1 +3427,1 @@\n-  return (jstring) JNIHandles::make_local(env, result);\n+  return (jstring) JNIHandles::make_local(THREAD, result);\n@@ -3643,1 +3442,0 @@\n-  JVMWrapper(\"JVM_RawMonitorCreate\");\n@@ -3652,1 +3450,0 @@\n-  JVMWrapper(\"JVM_RawMonitorDestroy\");\n@@ -3660,1 +3457,0 @@\n-  JVMWrapper(\"JVM_RawMonitorEnter\");\n@@ -3669,1 +3465,0 @@\n-  JVMWrapper(\"JVM_RawMonitorExit\");\n@@ -3692,1 +3487,1 @@\n-  return (jclass) JNIHandles::make_local(env, klass->java_mirror());\n+  return (jclass) JNIHandles::make_local(THREAD, klass->java_mirror());\n@@ -3699,2 +3494,1 @@\n-  JVMWrapper(\"JVM_InvokeMethod\");\n-  if (thread->stack_available((address) &method_handle) >= JVMInvokeMethodSlack) {\n+  if (thread->stack_overflow_state()->stack_available((address) &method_handle) >= JVMInvokeMethodSlack) {\n@@ -3706,1 +3500,1 @@\n-    jobject res = JNIHandles::make_local(env, result);\n+    jobject res = JNIHandles::make_local(THREAD, result);\n@@ -3713,1 +3507,1 @@\n-        JvmtiExport::post_vm_object_alloc(JavaThread::current(), result);\n+        JvmtiExport::post_vm_object_alloc(thread, result);\n@@ -3724,1 +3518,0 @@\n-  JVMWrapper(\"JVM_NewInstanceFromConstructor\");\n@@ -3728,1 +3521,1 @@\n-  jobject res = JNIHandles::make_local(env, result);\n+  jobject res = JNIHandles::make_local(THREAD, result);\n@@ -3730,1 +3523,1 @@\n-    JvmtiExport::post_vm_object_alloc(JavaThread::current(), result);\n+    JvmtiExport::post_vm_object_alloc(thread, result);\n@@ -3738,1 +3531,0 @@\n-  JVMWrapper(\"JVM_SupportsCX8\");\n@@ -3743,1 +3535,0 @@\n-  JVMWrapper(\"JVM_InitializeFromArchive\");\n@@ -3746,1 +3537,1 @@\n-  HeapShared::initialize_from_archived_subgraph(k);\n+  HeapShared::initialize_from_archived_subgraph(k, THREAD);\n@@ -3751,5 +3542,5 @@\n-                                              jstring invokedName,\n-                                              jobject invokedType,\n-                                              jobject methodType,\n-                                              jobject implMethodMember,\n-                                              jobject instantiatedMethodType,\n+                                              jstring interfaceMethodName,\n+                                              jobject factoryType,\n+                                              jobject interfaceMethodType,\n+                                              jobject implementationMember,\n+                                              jobject dynamicMethodType,\n@@ -3757,2 +3548,1 @@\n-  JVMWrapper(\"JVM_RegisterLambdaProxyClassForArchiving\");\n-  if (!DynamicDumpSharedSpaces) {\n+  if (!Arguments::is_dumping_archive()) {\n@@ -3765,2 +3555,2 @@\n-  if (caller_ik->is_hidden() || caller_ik->is_unsafe_anonymous()) {\n-    \/\/ VM anonymous classes and hidden classes not of type lambda proxy classes are currently not being archived.\n+  if (caller_ik->is_hidden()) {\n+    \/\/ Hidden classes not of type lambda proxy classes are currently not being archived.\n@@ -3776,3 +3566,3 @@\n-  Symbol* invoked_name = NULL;\n-  if (invokedName != NULL) {\n-    invoked_name = java_lang_String::as_symbol(JNIHandles::resolve_non_null(invokedName));\n+  Symbol* interface_method_name = NULL;\n+  if (interfaceMethodName != NULL) {\n+    interface_method_name = java_lang_String::as_symbol(JNIHandles::resolve_non_null(interfaceMethodName));\n@@ -3780,2 +3570,2 @@\n-  Handle invoked_type_oop(THREAD, JNIHandles::resolve_non_null(invokedType));\n-  Symbol* invoked_type = java_lang_invoke_MethodType::as_signature(invoked_type_oop(), true);\n+  Handle factory_type_oop(THREAD, JNIHandles::resolve_non_null(factoryType));\n+  Symbol* factory_type = java_lang_invoke_MethodType::as_signature(factory_type_oop(), true);\n@@ -3783,2 +3573,2 @@\n-  Handle method_type_oop(THREAD, JNIHandles::resolve_non_null(methodType));\n-  Symbol* method_type = java_lang_invoke_MethodType::as_signature(method_type_oop(), true);\n+  Handle interface_method_type_oop(THREAD, JNIHandles::resolve_non_null(interfaceMethodType));\n+  Symbol* interface_method_type = java_lang_invoke_MethodType::as_signature(interface_method_type_oop(), true);\n@@ -3786,3 +3576,3 @@\n-  Handle impl_method_member_oop(THREAD, JNIHandles::resolve_non_null(implMethodMember));\n-  assert(java_lang_invoke_MemberName::is_method(impl_method_member_oop()), \"must be\");\n-  Method* m = java_lang_invoke_MemberName::vmtarget(impl_method_member_oop());\n+  Handle implementation_member_oop(THREAD, JNIHandles::resolve_non_null(implementationMember));\n+  assert(java_lang_invoke_MemberName::is_method(implementation_member_oop()), \"must be\");\n+  Method* m = java_lang_invoke_MemberName::vmtarget(implementation_member_oop());\n@@ -3790,2 +3580,2 @@\n-  Handle instantiated_method_type_oop(THREAD, JNIHandles::resolve_non_null(instantiatedMethodType));\n-  Symbol* instantiated_method_type = java_lang_invoke_MethodType::as_signature(instantiated_method_type_oop(), true);\n+  Handle dynamic_method_type_oop(THREAD, JNIHandles::resolve_non_null(dynamicMethodType));\n+  Symbol* dynamic_method_type = java_lang_invoke_MethodType::as_signature(dynamic_method_type_oop(), true);\n@@ -3793,2 +3583,2 @@\n-  SystemDictionaryShared::add_lambda_proxy_class(caller_ik, lambda_ik, invoked_name, invoked_type,\n-                                                 method_type, m, instantiated_method_type);\n+  SystemDictionaryShared::add_lambda_proxy_class(caller_ik, lambda_ik, interface_method_name, factory_type,\n+                                                 interface_method_type, m, dynamic_method_type, THREAD);\n@@ -3800,7 +3590,5 @@\n-                                                        jstring invokedName,\n-                                                        jobject invokedType,\n-                                                        jobject methodType,\n-                                                        jobject implMethodMember,\n-                                                        jobject instantiatedMethodType,\n-                                                        jboolean initialize))\n-  JVMWrapper(\"JVM_LookupLambdaProxyClassFromArchive\");\n+                                                        jstring interfaceMethodName,\n+                                                        jobject factoryType,\n+                                                        jobject interfaceMethodType,\n+                                                        jobject implementationMember,\n+                                                        jobject dynamicMethodType))\n@@ -3808,5 +3596,2 @@\n-  if (!DynamicArchive::is_mapped()) {\n-    return NULL;\n-  }\n-  if (invokedName == NULL || invokedType == NULL || methodType == NULL ||\n-      implMethodMember == NULL || instantiatedMethodType == NULL) {\n+  if (interfaceMethodName == NULL || factoryType == NULL || interfaceMethodType == NULL ||\n+      implementationMember == NULL || dynamicMethodType == NULL) {\n@@ -3824,3 +3609,3 @@\n-  Symbol* invoked_name = java_lang_String::as_symbol(JNIHandles::resolve_non_null(invokedName));\n-  Handle invoked_type_oop(THREAD, JNIHandles::resolve_non_null(invokedType));\n-  Symbol* invoked_type = java_lang_invoke_MethodType::as_signature(invoked_type_oop(), true);\n+  Symbol* interface_method_name = java_lang_String::as_symbol(JNIHandles::resolve_non_null(interfaceMethodName));\n+  Handle factory_type_oop(THREAD, JNIHandles::resolve_non_null(factoryType));\n+  Symbol* factory_type = java_lang_invoke_MethodType::as_signature(factory_type_oop(), true);\n@@ -3828,2 +3613,2 @@\n-  Handle method_type_oop(THREAD, JNIHandles::resolve_non_null(methodType));\n-  Symbol* method_type = java_lang_invoke_MethodType::as_signature(method_type_oop(), true);\n+  Handle interface_method_type_oop(THREAD, JNIHandles::resolve_non_null(interfaceMethodType));\n+  Symbol* interface_method_type = java_lang_invoke_MethodType::as_signature(interface_method_type_oop(), true);\n@@ -3831,3 +3616,3 @@\n-  Handle impl_method_member_oop(THREAD, JNIHandles::resolve_non_null(implMethodMember));\n-  assert(java_lang_invoke_MemberName::is_method(impl_method_member_oop()), \"must be\");\n-  Method* m = java_lang_invoke_MemberName::vmtarget(impl_method_member_oop());\n+  Handle implementation_member_oop(THREAD, JNIHandles::resolve_non_null(implementationMember));\n+  assert(java_lang_invoke_MemberName::is_method(implementation_member_oop()), \"must be\");\n+  Method* m = java_lang_invoke_MemberName::vmtarget(implementation_member_oop());\n@@ -3835,2 +3620,2 @@\n-  Handle instantiated_method_type_oop(THREAD, JNIHandles::resolve_non_null(instantiatedMethodType));\n-  Symbol* instantiated_method_type = java_lang_invoke_MethodType::as_signature(instantiated_method_type_oop(), true);\n+  Handle dynamic_method_type_oop(THREAD, JNIHandles::resolve_non_null(dynamicMethodType));\n+  Symbol* dynamic_method_type = java_lang_invoke_MethodType::as_signature(dynamic_method_type_oop(), true);\n@@ -3838,2 +3623,2 @@\n-  InstanceKlass* lambda_ik = SystemDictionaryShared::get_shared_lambda_proxy_class(caller_ik, invoked_name, invoked_type,\n-                                                                                   method_type, m, instantiated_method_type);\n+  InstanceKlass* lambda_ik = SystemDictionaryShared::get_shared_lambda_proxy_class(caller_ik, interface_method_name, factory_type,\n+                                                                                   interface_method_type, m, dynamic_method_type);\n@@ -3842,2 +3627,2 @@\n-    InstanceKlass* loaded_lambda = SystemDictionaryShared::prepare_shared_lambda_proxy_class(lambda_ik, caller_ik, initialize, THREAD);\n-    jcls = loaded_lambda == NULL ? NULL : (jclass) JNIHandles::make_local(env, loaded_lambda->java_mirror());\n+    InstanceKlass* loaded_lambda = SystemDictionaryShared::prepare_shared_lambda_proxy_class(lambda_ik, caller_ik, THREAD);\n+    jcls = loaded_lambda == NULL ? NULL : (jclass) JNIHandles::make_local(THREAD, loaded_lambda->java_mirror());\n@@ -3852,2 +3637,1 @@\n-    JVMWrapper(\"JVM_IsCDSDumpingEnable\");\n-    return DynamicDumpSharedSpaces;\n+  return Arguments::is_dumping_archive();\n@@ -3856,3 +3640,2 @@\n-JVM_ENTRY(jboolean, JVM_IsCDSSharingEnabled(JNIEnv* env))\n-    JVMWrapper(\"JVM_IsCDSSharingEnable\");\n-    return UseSharedSpaces;\n+JVM_ENTRY(jboolean, JVM_IsSharingEnabled(JNIEnv* env))\n+  return UseSharedSpaces;\n@@ -3861,2 +3644,1 @@\n-JVM_ENTRY_NO_ENV(jlong, JVM_GetRandomSeedForCDSDump())\n-  JVMWrapper(\"JVM_GetRandomSeedForCDSDump\");\n+JVM_ENTRY_NO_ENV(jlong, JVM_GetRandomSeedForDumping())\n@@ -3877,1 +3659,1 @@\n-    log_debug(cds)(\"JVM_GetRandomSeedForCDSDump() = \" JLONG_FORMAT, seed);\n+    log_debug(cds)(\"JVM_GetRandomSeedForDumping() = \" JLONG_FORMAT, seed);\n@@ -3884,0 +3666,46 @@\n+JVM_ENTRY(jboolean, JVM_IsDumpingClassList(JNIEnv *env))\n+#if INCLUDE_CDS\n+  return ClassListWriter::is_enabled() || DynamicDumpSharedSpaces;\n+#else\n+  return false;\n+#endif \/\/ INCLUDE_CDS\n+JVM_END\n+\n+JVM_ENTRY(void, JVM_LogLambdaFormInvoker(JNIEnv *env, jstring line))\n+#if INCLUDE_CDS\n+  assert(ClassListWriter::is_enabled() || DynamicDumpSharedSpaces,  \"Should be set and open or do dynamic dump\");\n+  if (line != NULL) {\n+    ResourceMark rm(THREAD);\n+    Handle h_line (THREAD, JNIHandles::resolve_non_null(line));\n+    char* c_line = java_lang_String::as_utf8_string(h_line());\n+    if (DynamicDumpSharedSpaces) {\n+      \/\/ Note: LambdaFormInvokers::append_filtered and LambdaFormInvokers::append take same format which is not\n+      \/\/ same as below the print format. The line does not include LAMBDA_FORM_TAG.\n+      LambdaFormInvokers::append_filtered(os::strdup((const char*)c_line, mtInternal));\n+    }\n+    if (ClassListWriter::is_enabled()) {\n+      ClassListWriter w;\n+      w.stream()->print_cr(\"%s %s\", LAMBDA_FORM_TAG, c_line);\n+    }\n+  }\n+#endif \/\/ INCLUDE_CDS\n+JVM_END\n+\n+JVM_ENTRY(void, JVM_DumpClassListToFile(JNIEnv *env, jstring listFileName))\n+#if INCLUDE_CDS\n+  ResourceMark rm(THREAD);\n+  Handle file_handle(THREAD, JNIHandles::resolve_non_null(listFileName));\n+  char* file_name  = java_lang_String::as_utf8_string(file_handle());\n+  MetaspaceShared::dump_loaded_classes(file_name, THREAD);\n+#endif \/\/ INCLUDE_CDS\n+JVM_END\n+\n+JVM_ENTRY(void, JVM_DumpDynamicArchive(JNIEnv *env, jstring archiveName))\n+#if INCLUDE_CDS\n+  ResourceMark rm(THREAD);\n+  Handle file_handle(THREAD, JNIHandles::resolve_non_null(archiveName));\n+  char* archive_name  = java_lang_String::as_utf8_string(file_handle());\n+  DynamicArchive::dump(archive_name, CHECK);\n+#endif \/\/ INCLUDE_CDS\n+JVM_END\n+\n@@ -3893,1 +3721,1 @@\n-  objArrayOop r = oopFactory::new_objArray(SystemDictionary::Thread_klass(), num_threads, CHECK_NULL);\n+  objArrayOop r = oopFactory::new_objArray(vmClasses::Thread_klass(), num_threads, CHECK_NULL);\n@@ -3901,1 +3729,1 @@\n-  return (jobjectArray) JNIHandles::make_local(env, threads_ah());\n+  return (jobjectArray) JNIHandles::make_local(THREAD, threads_ah());\n@@ -3909,1 +3737,0 @@\n-  JVMWrapper(\"JVM_DumpThreads\");\n@@ -3927,1 +3754,1 @@\n-  if (k != SystemDictionary::Thread_klass()) {\n+  if (k != vmClasses::Thread_klass()) {\n@@ -3943,1 +3770,1 @@\n-  return (jobjectArray)JNIHandles::make_local(env, stacktraces());\n+  return (jobjectArray)JNIHandles::make_local(THREAD, stacktraces());\n@@ -3956,1 +3783,0 @@\n-  JVMWrapper(\"JVM_InitAgentProperties\");\n@@ -3969,1 +3795,0 @@\n-  JVMWrapper(\"JVM_GetEnclosingMethodInfo\");\n@@ -3989,1 +3814,1 @@\n-  objArrayOop dest_o = oopFactory::new_objArray(SystemDictionary::Object_klass(), 3, CHECK_NULL);\n+  objArrayOop dest_o = oopFactory::new_objArray(vmClasses::Object_klass(), 3, CHECK_NULL);\n@@ -4006,1 +3831,1 @@\n-  return (jobjectArray) JNIHandles::make_local(dest());\n+  return (jobjectArray) JNIHandles::make_local(THREAD, dest());\n@@ -4023,1 +3848,1 @@\n-  InstanceKlass* ik = SystemDictionary::String_klass();\n+  InstanceKlass* ik = vmClasses::String_klass();\n@@ -4036,1 +3861,1 @@\n-  return (jobjectArray) JNIHandles::make_local(env, result_h());\n+  return (jobjectArray) JNIHandles::make_local(THREAD, result_h());\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":443,"deletions":618,"binary":false,"changes":1061,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,0 +31,1 @@\n+#include \"classfile\/vmClasses.hpp\"\n@@ -32,0 +33,1 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n@@ -41,0 +43,1 @@\n+#include \"oops\/klass.inline.hpp\"\n@@ -143,2 +146,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -165,2 +167,1 @@\n-\/\/ Threads_lock NOT held\n-\/\/ thread - NOT pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -181,0 +182,1 @@\n+    MACOS_AARCH64_ONLY(ThreadWXEnable __wx(WXWrite, current_thread));\n@@ -218,1 +220,1 @@\n-  JavaThread* THREAD = JavaThread::current(); \/\/ pass to macros\n+  JavaThread* THREAD = JavaThread::current(); \/\/ For exception macros.\n@@ -225,6 +227,2 @@\n-  jobject module = Modules::get_named_module(h_loader, package_name, THREAD);\n-  if (HAS_PENDING_EXCEPTION) {\n-    CLEAR_PENDING_EXCEPTION;\n-    return JVMTI_ERROR_INTERNAL; \/\/ unexpected exception\n-  }\n-  *module_ptr = module;\n+  oop module = Modules::get_named_module(h_loader, package_name);\n+  *module_ptr = module != NULL ? JNIHandles::make_local(THREAD, module) : NULL;\n@@ -239,1 +237,1 @@\n-  JavaThread* THREAD = JavaThread::current();\n+  JavaThread* THREAD = JavaThread::current(); \/\/ For exception macros.\n@@ -260,1 +258,1 @@\n-  JavaThread* THREAD = JavaThread::current();\n+  JavaThread* THREAD = JavaThread::current(); \/\/ For exception macros.\n@@ -282,1 +280,1 @@\n-  JavaThread* THREAD = JavaThread::current();\n+  JavaThread* THREAD = JavaThread::current(); \/\/ For exception macros.\n@@ -303,1 +301,1 @@\n-  JavaThread* THREAD = JavaThread::current();\n+  JavaThread* THREAD = JavaThread::current(); \/\/ For exception macros.\n@@ -325,1 +323,1 @@\n-  JavaThread* THREAD = JavaThread::current();\n+  JavaThread* THREAD = JavaThread::current(); \/\/ For exception macros.\n@@ -351,1 +349,1 @@\n-  JavaThread* THREAD = JavaThread::current();\n+  JavaThread* current = JavaThread::current();\n@@ -354,1 +352,1 @@\n-  Handle h_module(THREAD, JNIHandles::resolve(module));\n+  Handle h_module(current, JNIHandles::resolve(module));\n@@ -416,1 +414,1 @@\n-    if (!k_mirror->is_a(SystemDictionary::Class_klass())) {\n+    if (!k_mirror->is_a(vmClasses::Class_klass())) {\n@@ -492,1 +490,1 @@\n-  *size_ptr = (jlong)Universe::heap()->obj_size(mirror) * wordSize;\n+  *size_ptr = (jlong)mirror->size() * wordSize;\n@@ -664,7 +662,0 @@\n-    \/\/ lock the loader\n-    Thread* thread = Thread::current();\n-    HandleMark hm;\n-    Handle loader_lock = Handle(thread, SystemDictionary::system_loader_lock());\n-\n-    ObjectLocker ol(loader_lock, thread);\n-\n@@ -703,1 +694,2 @@\n-    HandleMark hm;\n+    JavaThread* THREAD = JavaThread::current(); \/\/ For exception macros.\n+    HandleMark hm(THREAD);\n@@ -714,2 +706,0 @@\n-    Thread* THREAD = Thread::current();\n-\n@@ -853,2 +843,1 @@\n-\/\/ Threads_lock NOT held\n-\/\/ thread - NOT pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -867,1 +856,1 @@\n-    if (thread_oop == NULL || !thread_oop->is_a(SystemDictionary::Thread_klass())) {\n+    if (thread_oop == NULL || !thread_oop->is_a(vmClasses::Thread_klass())) {\n@@ -890,1 +879,1 @@\n-    if (java_thread->is_being_ext_suspended()) {\n+    if (java_thread->is_suspended()) {\n@@ -921,2 +910,3 @@\n-  ResourceMark rm;\n-  HandleMark hm;\n+  Thread* current_thread = Thread::current();\n+  ResourceMark rm(current_thread);\n+  HandleMark hm(current_thread);\n@@ -925,1 +915,1 @@\n-  ThreadsListEnumerator tle(Thread::current(), true);\n+  ThreadsListEnumerator tle(current_thread, true);\n@@ -949,2 +939,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -955,1 +944,1 @@\n-    return (JVMTI_ERROR_NONE);\n+    return JVMTI_ERROR_NONE;\n@@ -957,11 +946,2 @@\n-\n-  {\n-    MutexLocker ml(java_thread->SR_lock(), Mutex::_no_safepoint_check_flag);\n-    if (java_thread->is_external_suspend()) {\n-      \/\/ don't allow nested external suspend requests.\n-      return (JVMTI_ERROR_THREAD_SUSPENDED);\n-    }\n-    if (java_thread->is_exiting()) { \/\/ thread is in the process of exiting\n-      return (JVMTI_ERROR_THREAD_NOT_ALIVE);\n-    }\n-    java_thread->set_external_suspend();\n+  if (java_thread->is_suspended()) {\n+    return JVMTI_ERROR_THREAD_SUSPENDED;\n@@ -969,3 +949,6 @@\n-\n-    \/\/ the thread was in the process of exiting\n-    return (JVMTI_ERROR_THREAD_NOT_ALIVE);\n+    \/\/ Either the thread is already suspended or\n+    \/\/ it was in the process of exiting.\n+    if (java_thread->is_exiting()) {\n+      return JVMTI_ERROR_THREAD_NOT_ALIVE;\n+    }\n+    return JVMTI_ERROR_THREAD_SUSPENDED;\n@@ -983,0 +966,1 @@\n+  int self_index = -1;\n@@ -984,1 +968,2 @@\n-  ThreadsListHandle tlh;\n+  JavaThread* current = JavaThread::current();\n+  ThreadsListHandle tlh(current);\n@@ -997,21 +982,12 @@\n-\n-    {\n-      MutexLocker ml(java_thread->SR_lock(), Mutex::_no_safepoint_check_flag);\n-      if (java_thread->is_external_suspend()) {\n-        \/\/ don't allow nested external suspend requests.\n-        results[i] = JVMTI_ERROR_THREAD_SUSPENDED;\n-        continue;\n-      }\n-      if (java_thread->is_exiting()) { \/\/ thread is in the process of exiting\n-        results[i] = JVMTI_ERROR_THREAD_NOT_ALIVE;\n-        continue;\n-      }\n-      java_thread->set_external_suspend();\n-    }\n-    if (java_thread->thread_state() == _thread_in_native) {\n-      \/\/ We need to try and suspend native threads here. Threads in\n-      \/\/ other states will self-suspend on their next transition.\n-      if (!JvmtiSuspendControl::suspend(java_thread)) {\n-        \/\/ The thread was in the process of exiting. Force another\n-        \/\/ safepoint to make sure that this thread transitions.\n-        needSafepoint++;\n+    if (java_thread->is_suspended()) {\n+      results[i] = JVMTI_ERROR_THREAD_SUSPENDED;\n+      continue;\n+    }\n+    if (java_thread == current) {\n+      self_index = i;\n+      continue;\n+    }\n+    if (!JvmtiSuspendControl::suspend(java_thread)) {\n+      \/\/ Either the thread is already suspended or\n+      \/\/ it was in the process of exiting.\n+      if (java_thread->is_exiting()) {\n@@ -1021,2 +997,2 @@\n-    } else {\n-      needSafepoint++;\n+      results[i] = JVMTI_ERROR_THREAD_SUSPENDED;\n+      continue;\n@@ -1026,3 +1002,12 @@\n-  if (needSafepoint > 0) {\n-    VM_ThreadsSuspendJVMTI tsj;\n-    VMThread::execute(&tsj);\n+  if (self_index >= 0) {\n+    if (!JvmtiSuspendControl::suspend(current)) {\n+      \/\/ Either the thread is already suspended or\n+      \/\/ it was in the process of exiting.\n+      if (current->is_exiting()) {\n+        results[self_index] = JVMTI_ERROR_THREAD_NOT_ALIVE;\n+      } else {\n+        results[self_index] = JVMTI_ERROR_THREAD_SUSPENDED;\n+      }\n+    } else {\n+      results[self_index] = JVMTI_ERROR_NONE;  \/\/ indicate successful suspend\n+    }\n@@ -1035,2 +1020,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -1043,2 +1027,1 @@\n-\n-  if (!java_thread->is_being_ext_suspended()) {\n+  if (!java_thread->is_suspended()) {\n@@ -1047,1 +1030,0 @@\n-\n@@ -1073,1 +1055,1 @@\n-    if (!java_thread->is_being_ext_suspended()) {\n+    if (!java_thread->is_suspended()) {\n@@ -1090,2 +1072,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -1104,2 +1085,1 @@\n-\/\/ Threads_lock NOT held\n-\/\/ thread - NOT pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -1126,2 +1106,1 @@\n-\/\/ Threads_lock NOT held\n-\/\/ thread - NOT pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -1131,3 +1110,3 @@\n-  ResourceMark rm;\n-  HandleMark hm;\n-\n+  ResourceMark rm(current_thread);\n+  HandleMark hm(current_thread);\n+\n@@ -1141,1 +1120,1 @@\n-    if (thread_oop == NULL || !thread_oop->is_a(SystemDictionary::Thread_klass())) {\n+    if (thread_oop == NULL || !thread_oop->is_a(vmClasses::Thread_klass())) {\n@@ -1199,2 +1178,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -1208,0 +1186,5 @@\n+  EscapeBarrier eb(true, calling_thread, java_thread);\n+  if (!eb.deoptimize_objects(MaxJavaStackTraceDepth)) {\n+    return JVMTI_ERROR_OUT_OF_MEMORY;\n+  }\n+\n@@ -1210,1 +1193,1 @@\n-      new (ResourceObj::C_HEAP, mtInternal) GrowableArray<jvmtiMonitorStackDepthInfo*>(1, true);\n+      new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<jvmtiMonitorStackDepthInfo*>(1, mtServiceability);\n@@ -1219,1 +1202,1 @@\n-    Handshake::execute_direct(&op, java_thread);\n+    Handshake::execute(&op, java_thread);\n@@ -1244,2 +1227,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -1253,0 +1235,5 @@\n+  EscapeBarrier eb(true, calling_thread, java_thread);\n+  if (!eb.deoptimize_objects(MaxJavaStackTraceDepth)) {\n+    return JVMTI_ERROR_OUT_OF_MEMORY;\n+  }\n+\n@@ -1255,1 +1242,1 @@\n-         new (ResourceObj::C_HEAP, mtInternal) GrowableArray<jvmtiMonitorStackDepthInfo*>(1, true);\n+         new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<jvmtiMonitorStackDepthInfo*>(1, mtServiceability);\n@@ -1264,1 +1251,1 @@\n-    Handshake::execute_direct(&op, java_thread);\n+    Handshake::execute(&op, java_thread);\n@@ -1293,2 +1280,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -1308,1 +1294,1 @@\n-    Handshake::execute_direct(&op, java_thread);\n+    Handshake::execute(&op, java_thread);\n@@ -1315,2 +1301,1 @@\n-\/\/ Threads_lock NOT held\n-\/\/ thread - NOT pre-checked\n+\/\/ thread - NOT protected by ThreadsListHandle and NOT pre-checked\n@@ -1406,4 +1391,3 @@\n-  ResourceMark rm;\n-  HandleMark hm;\n-\n-  JavaThread* current_thread = JavaThread::current();\n+  Thread* current_thread = Thread::current();\n+  ResourceMark rm(current_thread);\n+  HandleMark hm(current_thread);\n@@ -1447,1 +1431,1 @@\n-  oop group_obj = (oop) JNIHandles::resolve_external_guard(group);\n+  oop group_obj = JNIHandles::resolve_external_guard(group);\n@@ -1531,2 +1515,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -1541,1 +1524,1 @@\n-  \/\/ thread. All other usage needs to use a vm-safepoint-op for safety.\n+  \/\/ thread. All other usage needs to use a direct handshake for safety.\n@@ -1545,4 +1528,3 @@\n-    \/\/ JVMTI get stack trace at safepoint. Do not require target thread to\n-    \/\/ be suspended.\n-    VM_GetStackTrace op(this, java_thread, start_depth, max_frame_count, frame_buffer, count_ptr);\n-    VMThread::execute(&op);\n+    \/\/ Get stack trace with handshake.\n+    GetStackTraceClosure op(this, start_depth, max_frame_count, frame_buffer, count_ptr);\n+    Handshake::execute(&op, java_thread);\n@@ -1581,6 +1563,25 @@\n-  \/\/ JVMTI get stack traces at safepoint.\n-  VM_GetThreadListStackTraces op(this, thread_count, thread_list, max_frame_count);\n-  VMThread::execute(&op);\n-  err = op.result();\n-  if (err == JVMTI_ERROR_NONE) {\n-    *stack_info_ptr = op.stack_info();\n+\n+  if (thread_count == 1) {\n+    \/\/ Use direct handshake if we need to get only one stack trace.\n+    JavaThread *current_thread = JavaThread::current();\n+    ThreadsListHandle tlh(current_thread);\n+    JavaThread *java_thread;\n+    err = JvmtiExport::cv_external_thread_to_JavaThread(tlh.list(), *thread_list, &java_thread, NULL);\n+    if (err != JVMTI_ERROR_NONE) {\n+      return err;\n+    }\n+\n+    GetSingleStackTraceClosure op(this, current_thread, *thread_list, max_frame_count);\n+    Handshake::execute(&op, java_thread);\n+    err = op.result();\n+    if (err == JVMTI_ERROR_NONE) {\n+      *stack_info_ptr = op.stack_info();\n+    }\n+  } else {\n+    \/\/ JVMTI get stack traces at safepoint.\n+    VM_GetThreadListStackTraces op(this, thread_count, thread_list, max_frame_count);\n+    VMThread::execute(&op);\n+    err = op.result();\n+    if (err == JVMTI_ERROR_NONE) {\n+      *stack_info_ptr = op.stack_info();\n+    }\n@@ -1592,2 +1593,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -1606,1 +1606,1 @@\n-  \/\/ thread. All other usage needs to use a vm-safepoint-op for safety.\n+  \/\/ thread. All other usage needs to use a direct handshake for safety.\n@@ -1610,3 +1610,3 @@\n-    \/\/ get java stack frame count at safepoint.\n-    VM_GetFrameCount op(this, state, count_ptr);\n-    VMThread::execute(&op);\n+    \/\/ get java stack frame count with handshake.\n+    GetFrameCountClosure op(this, state, count_ptr);\n+    Handshake::execute(&op, java_thread);\n@@ -1619,2 +1619,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -1623,4 +1622,0 @@\n-  JavaThread* current_thread  = JavaThread::current();\n-  HandleMark hm(current_thread);\n-  uint32_t debug_bits = 0;\n-\n@@ -1633,20 +1628,6 @@\n-  \/\/ Check if java_thread is fully suspended\n-  if (!java_thread->is_thread_fully_suspended(true \/* wait for suspend completion *\/, &debug_bits)) {\n-    return JVMTI_ERROR_THREAD_NOT_SUSPENDED;\n-  }\n-  \/\/ Check to see if a PopFrame was already in progress\n-  if (java_thread->popframe_condition() != JavaThread::popframe_inactive) {\n-    \/\/ Probably possible for JVMTI clients to trigger this, but the\n-    \/\/ JPDA backend shouldn't allow this to happen\n-    return JVMTI_ERROR_INTERNAL;\n-  }\n-\n-  {\n-    \/\/ Was workaround bug\n-    \/\/    4812902: popFrame hangs if the method is waiting at a synchronize\n-    \/\/ Catch this condition and return an error to avoid hanging.\n-    \/\/ Now JVMTI spec allows an implementation to bail out with an opaque frame error.\n-    OSThread* osThread = java_thread->osthread();\n-    if (osThread->get_state() == MONITOR_WAIT) {\n-      return JVMTI_ERROR_OPAQUE_FRAME;\n-    }\n+  \/\/ Eagerly reallocate scalar replaced objects.\n+  JavaThread* current_thread = JavaThread::current();\n+  EscapeBarrier eb(true, current_thread, java_thread);\n+  if (!eb.deoptimize_objects(1)) {\n+    \/\/ Reallocation of scalar replaced objects failed -> return with error\n+    return JVMTI_ERROR_OUT_OF_MEMORY;\n@@ -1655,64 +1636,6 @@\n-  {\n-    ResourceMark rm(current_thread);\n-    \/\/ Check if there are more than one Java frame in this thread, that the top two frames\n-    \/\/ are Java (not native) frames, and that there is no intervening VM frame\n-    int frame_count = 0;\n-    bool is_interpreted[2];\n-    intptr_t *frame_sp[2];\n-    \/\/ The 2-nd arg of constructor is needed to stop iterating at java entry frame.\n-    for (vframeStream vfs(java_thread, true); !vfs.at_end(); vfs.next()) {\n-      methodHandle mh(current_thread, vfs.method());\n-      if (mh->is_native()) return(JVMTI_ERROR_OPAQUE_FRAME);\n-      is_interpreted[frame_count] = vfs.is_interpreted_frame();\n-      frame_sp[frame_count] = vfs.frame_id();\n-      if (++frame_count > 1) break;\n-    }\n-    if (frame_count < 2)  {\n-      \/\/ We haven't found two adjacent non-native Java frames on the top.\n-      \/\/ There can be two situations here:\n-      \/\/  1. There are no more java frames\n-      \/\/  2. Two top java frames are separated by non-java native frames\n-      if(vframeFor(java_thread, 1) == NULL) {\n-        return JVMTI_ERROR_NO_MORE_FRAMES;\n-      } else {\n-        \/\/ Intervening non-java native or VM frames separate java frames.\n-        \/\/ Current implementation does not support this. See bug #5031735.\n-        \/\/ In theory it is possible to pop frames in such cases.\n-        return JVMTI_ERROR_OPAQUE_FRAME;\n-      }\n-    }\n-\n-    \/\/ If any of the top 2 frames is a compiled one, need to deoptimize it\n-    for (int i = 0; i < 2; i++) {\n-      if (!is_interpreted[i]) {\n-        Deoptimization::deoptimize_frame(java_thread, frame_sp[i]);\n-      }\n-    }\n-\n-    \/\/ Update the thread state to reflect that the top frame is popped\n-    \/\/ so that cur_stack_depth is maintained properly and all frameIDs\n-    \/\/ are invalidated.\n-    \/\/ The current frame will be popped later when the suspended thread\n-    \/\/ is resumed and right before returning from VM to Java.\n-    \/\/ (see call_VM_base() in assembler_<cpu>.cpp).\n-\n-    \/\/ It's fine to update the thread state here because no JVMTI events\n-    \/\/ shall be posted for this PopFrame.\n-\n-    \/\/ It is only safe to perform the direct operation on the current\n-    \/\/ thread. All other usage needs to use a vm-safepoint-op for safety.\n-    if (java_thread == JavaThread::current()) {\n-      state->update_for_pop_top_frame();\n-    } else {\n-      VM_UpdateForPopTopFrame op(state);\n-      VMThread::execute(&op);\n-      jvmtiError err = op.result();\n-      if (err != JVMTI_ERROR_NONE) {\n-        return err;\n-      }\n-    }\n-\n-    java_thread->set_popframe_condition(JavaThread::popframe_pending_bit);\n-    \/\/ Set pending step flag for this popframe and it is cleared when next\n-    \/\/ step event is posted.\n-    state->set_pending_step_for_popframe();\n+  MutexLocker mu(JvmtiThreadState_lock);\n+  UpdateForPopTopFrameClosure op(state);\n+  if (java_thread == current_thread) {\n+    op.doit(java_thread, true \/* self *\/);\n+  } else {\n+    Handshake::execute(&op, java_thread);\n@@ -1720,2 +1643,1 @@\n-\n-  return JVMTI_ERROR_NONE;\n+  return op.result();\n@@ -1725,3 +1647,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n-\/\/ java_thread - unchecked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -1736,1 +1656,1 @@\n-  \/\/ thread. All other usage needs to use a vm-safepoint-op for safety.\n+  \/\/ thread. All other usage needs to use a direct handshake for safety.\n@@ -1740,3 +1660,3 @@\n-    \/\/ JVMTI get java stack frame location at safepoint.\n-    VM_GetFrameLocation op(this, java_thread, depth, method_ptr, location_ptr);\n-    VMThread::execute(&op);\n+    \/\/ JVMTI get java stack frame location via direct handshake.\n+    GetFrameLocationClosure op(this, depth, method_ptr, location_ptr);\n+    Handshake::execute(&op, java_thread);\n@@ -1749,3 +1669,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n-\/\/ java_thread - unchecked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -1755,4 +1673,0 @@\n-  jvmtiError err = JVMTI_ERROR_NONE;\n-  ResourceMark rm;\n-  uint32_t debug_bits = 0;\n-\n@@ -1764,21 +1678,2 @@\n-  if (!java_thread->is_thread_fully_suspended(true, &debug_bits)) {\n-    return JVMTI_ERROR_THREAD_NOT_SUSPENDED;\n-  }\n-\n-  if (TraceJVMTICalls) {\n-    JvmtiSuspendControl::print();\n-  }\n-\n-  vframe *vf = vframeFor(java_thread, depth);\n-  if (vf == NULL) {\n-    return JVMTI_ERROR_NO_MORE_FRAMES;\n-  }\n-\n-  if (!vf->is_java_frame() || ((javaVFrame*) vf)->method()->is_native()) {\n-    return JVMTI_ERROR_OPAQUE_FRAME;\n-  }\n-\n-  assert(vf->frame_pointer() != NULL, \"frame pointer mustn't be NULL\");\n-\n-  \/\/ It is only safe to perform the direct operation on the current\n-  \/\/ thread. All other usage needs to use a vm-safepoint-op for safety.\n+  SetFramePopClosure op(this, state, depth);\n+  MutexLocker mu(JvmtiThreadState_lock);\n@@ -1786,2 +1681,1 @@\n-    int frame_number = state->count_frames() - depth;\n-    state->env_thread_state(this)->set_frame_pop(frame_number);\n+    op.doit(java_thread, true \/* self *\/);\n@@ -1789,3 +1683,1 @@\n-    VM_SetFramePop op(this, state, depth);\n-    VMThread::execute(&op);\n-    err = op.result();\n+    Handshake::execute(&op, java_thread);\n@@ -1793,1 +1685,1 @@\n-  return err;\n+  return op.result();\n@@ -1801,2 +1693,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -1811,2 +1702,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -1821,2 +1711,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -1831,2 +1720,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -1841,2 +1729,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -1851,2 +1738,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -2030,3 +1916,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n-\/\/ java_thread - unchecked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -2053,3 +1937,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n-\/\/ java_thread - unchecked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -2077,3 +1959,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n-\/\/ java_thread - unchecked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -2095,3 +1975,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n-\/\/ java_thread - unchecked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -2113,3 +1991,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n-\/\/ java_thread - unchecked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -2131,3 +2007,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n-\/\/ java_thread - unchecked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -2149,3 +2023,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n-\/\/ java_thread - unchecked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -2166,3 +2038,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n-\/\/ java_thread - unchecked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -2183,3 +2053,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n-\/\/ java_thread - unchecked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -2200,3 +2068,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n-\/\/ java_thread - unchecked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -2217,3 +2083,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n-\/\/ java_thread - unchecked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n@@ -2238,1 +2102,1 @@\n-\/\/ method_oop - pre-checked for validity, but may be NULL meaning obsolete method\n+\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n@@ -2240,2 +2104,2 @@\n-JvmtiEnv::SetBreakpoint(Method* method_oop, jlocation location) {\n-  NULL_CHECK(method_oop, JVMTI_ERROR_INVALID_METHODID);\n+JvmtiEnv::SetBreakpoint(Method* method, jlocation location) {\n+  NULL_CHECK(method, JVMTI_ERROR_INVALID_METHODID);\n@@ -2246,1 +2110,1 @@\n-  if (location >= (jlocation) method_oop->code_size()) {\n+  if (location >= (jlocation) method->code_size()) {\n@@ -2251,1 +2115,1 @@\n-  JvmtiBreakpoint bp(method_oop, location);\n+  JvmtiBreakpoint bp(method, location);\n@@ -2264,1 +2128,1 @@\n-\/\/ method_oop - pre-checked for validity, but may be NULL meaning obsolete method\n+\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n@@ -2266,2 +2130,2 @@\n-JvmtiEnv::ClearBreakpoint(Method* method_oop, jlocation location) {\n-  NULL_CHECK(method_oop, JVMTI_ERROR_INVALID_METHODID);\n+JvmtiEnv::ClearBreakpoint(Method* method, jlocation location) {\n+  NULL_CHECK(method, JVMTI_ERROR_INVALID_METHODID);\n@@ -2274,1 +2138,1 @@\n-  if (location >= (jlocation) method_oop->code_size()) {\n+  if (location >= (jlocation) method->code_size()) {\n@@ -2278,1 +2142,1 @@\n-  JvmtiBreakpoint bp(method_oop, location);\n+  JvmtiBreakpoint bp(method, location);\n@@ -2452,6 +2316,1 @@\n-    result = k->compute_modifier_flags(current_thread);\n-    JavaThread* THREAD = current_thread; \/\/ pass to macros\n-    if (HAS_PENDING_EXCEPTION) {\n-      CLEAR_PENDING_EXCEPTION;\n-      return JVMTI_ERROR_INTERNAL;\n-    };\n+    result = k->compute_modifier_flags();\n@@ -2459,2 +2318,2 @@\n-    \/\/ Reset the deleted  ACC_SUPER bit ( deleted in compute_modifier_flags()).\n-    if(k->is_super()) {\n+    \/\/ Reset the deleted  ACC_SUPER bit (deleted in compute_modifier_flags()).\n+    if (k->is_super()) {\n@@ -2504,20 +2363,23 @@\n-\n-  if (JvmtiExport::can_maintain_original_method_order()) {\n-    \/\/ Use the original method ordering indices stored in the class, so we can emit\n-    \/\/ jmethodIDs in the order they appeared in the class file\n-    for (index = 0; index < result_length; index++) {\n-      Method* m = ik->methods()->at(index);\n-      int original_index = ik->method_ordering()->at(index);\n-      assert(original_index >= 0 && original_index < result_length, \"invalid original method index\");\n-      jmethodID id;\n-      if (jmethodids_found) {\n-        id = m->find_jmethod_id_or_null();\n-        if (id == NULL) {\n-          \/\/ If we find an uninitialized value, make sure there is\n-          \/\/ enough space for all the uninitialized values we might\n-          \/\/ find.\n-          ik->ensure_space_for_methodids(index);\n-          jmethodids_found = false;\n-          id = m->jmethod_id();\n-        }\n-      } else {\n+  int skipped = 0;  \/\/ skip overpass methods\n+\n+  for (index = 0; index < result_length; index++) {\n+    Method* m = ik->methods()->at(index);\n+    \/\/ Depending on can_maintain_original_method_order capability use the original\n+    \/\/ method ordering indices stored in the class, so we can emit jmethodIDs in\n+    \/\/ the order they appeared in the class file or just copy in current order.\n+    int result_index = JvmtiExport::can_maintain_original_method_order() ? ik->method_ordering()->at(index) : index;\n+    assert(result_index >= 0 && result_index < result_length, \"invalid original method index\");\n+    if (m->is_overpass()) {\n+      result_list[result_index] = NULL;\n+      skipped++;\n+      continue;\n+    }\n+    jmethodID id;\n+    if (jmethodids_found) {\n+      id = m->find_jmethod_id_or_null();\n+      if (id == NULL) {\n+        \/\/ If we find an uninitialized value, make sure there is\n+        \/\/ enough space for all the uninitialized values we might\n+        \/\/ find.\n+        ik->ensure_space_for_methodids(index);\n+        jmethodids_found = false;\n@@ -2526,1 +2388,2 @@\n-      result_list[original_index] = id;\n+    } else {\n+      id = m->jmethod_id();\n@@ -2528,15 +2391,11 @@\n-  } else {\n-    \/\/ otherwise just copy in any order\n-    for (index = 0; index < result_length; index++) {\n-      Method* m = ik->methods()->at(index);\n-      jmethodID id;\n-      if (jmethodids_found) {\n-        id = m->find_jmethod_id_or_null();\n-        if (id == NULL) {\n-          \/\/ If we find an uninitialized value, make sure there is\n-          \/\/ enough space for all the uninitialized values we might\n-          \/\/ find.\n-          ik->ensure_space_for_methodids(index);\n-          jmethodids_found = false;\n-          id = m->jmethod_id();\n-        }\n+    result_list[result_index] = id;\n+  }\n+\n+  \/\/ Fill in return value.\n+  if (skipped > 0) {\n+    \/\/ copy results skipping NULL methodIDs\n+    *methods_ptr = (jmethodID*)jvmtiMalloc((result_length - skipped) * sizeof(jmethodID));\n+    *method_count_ptr = result_length - skipped;\n+    for (index = 0, skipped = 0; index < result_length; index++) {\n+      if (result_list[index] == NULL) {\n+        skipped++;\n@@ -2544,1 +2403,1 @@\n-        id = m->jmethod_id();\n+        (*methods_ptr)[index - skipped] = result_list[index];\n@@ -2546,1 +2405,4 @@\n-      result_list[index] = id;\n+    deallocate((unsigned char *)result_list);\n+  } else {\n+    *method_count_ptr = result_length;\n+    *methods_ptr = result_list;\n@@ -2549,3 +2411,0 @@\n-  \/\/ Fill in return value.\n-  *method_count_ptr = result_length;\n-  *methods_ptr = result_list;\n@@ -2845,9 +2704,5 @@\n-  JavaThread* calling_thread = JavaThread::current();\n-  jvmtiError err = get_object_monitor_usage(calling_thread, object, info_ptr);\n-  if (err == JVMTI_ERROR_THREAD_NOT_SUSPENDED) {\n-    \/\/ Some of the critical threads were not suspended. go to a safepoint and try again\n-    VM_GetObjectMonitorUsage op(this, calling_thread, object, info_ptr);\n-    VMThread::execute(&op);\n-    err = op.result();\n-  }\n-  return err;\n+  \/\/ This needs to be performed at a safepoint to gather stable data\n+  \/\/ because monitor owner \/ waiters might not be suspended.\n+  VM_GetObjectMonitorUsage op(this, JavaThread::current(), object, info_ptr);\n+  VMThread::execute(&op);\n+  return op.result();\n@@ -2937,1 +2792,1 @@\n-\/\/ method_oop - pre-checked for validity, but may be NULL meaning obsolete method\n+\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n@@ -2942,2 +2797,2 @@\n-JvmtiEnv::GetMethodName(Method* method_oop, char** name_ptr, char** signature_ptr, char** generic_ptr) {\n-  NULL_CHECK(method_oop, JVMTI_ERROR_INVALID_METHODID);\n+JvmtiEnv::GetMethodName(Method* method, char** name_ptr, char** signature_ptr, char** generic_ptr) {\n+  NULL_CHECK(method, JVMTI_ERROR_INVALID_METHODID);\n@@ -2950,1 +2805,1 @@\n-    const char* utf8_name = (const char *) method_oop->name()->as_utf8();\n+    const char* utf8_name = (const char *) method->name()->as_utf8();\n@@ -2957,1 +2812,1 @@\n-    const char* utf8_signature = (const char *) method_oop->signature()->as_utf8();\n+    const char* utf8_signature = (const char *) method->signature()->as_utf8();\n@@ -2964,1 +2819,1 @@\n-    Symbol* soop = method_oop->generic_signature();\n+    Symbol* soop = method->generic_signature();\n@@ -2980,1 +2835,1 @@\n-\/\/ method_oop - pre-checked for validity, but may be NULL meaning obsolete method\n+\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n@@ -2983,3 +2838,3 @@\n-JvmtiEnv::GetMethodDeclaringClass(Method* method_oop, jclass* declaring_class_ptr) {\n-  NULL_CHECK(method_oop, JVMTI_ERROR_INVALID_METHODID);\n-  (*declaring_class_ptr) = get_jni_class_non_null(method_oop->method_holder());\n+JvmtiEnv::GetMethodDeclaringClass(Method* method, jclass* declaring_class_ptr) {\n+  NULL_CHECK(method, JVMTI_ERROR_INVALID_METHODID);\n+  (*declaring_class_ptr) = get_jni_class_non_null(method->method_holder());\n@@ -2990,1 +2845,1 @@\n-\/\/ method_oop - pre-checked for validity, but may be NULL meaning obsolete method\n+\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n@@ -2993,3 +2848,3 @@\n-JvmtiEnv::GetMethodModifiers(Method* method_oop, jint* modifiers_ptr) {\n-  NULL_CHECK(method_oop, JVMTI_ERROR_INVALID_METHODID);\n-  (*modifiers_ptr) = method_oop->access_flags().as_int() & JVM_RECOGNIZED_METHOD_MODIFIERS;\n+JvmtiEnv::GetMethodModifiers(Method* method, jint* modifiers_ptr) {\n+  NULL_CHECK(method, JVMTI_ERROR_INVALID_METHODID);\n+  (*modifiers_ptr) = method->access_flags().as_int() & JVM_RECOGNIZED_METHOD_MODIFIERS;\n@@ -3000,1 +2855,1 @@\n-\/\/ method_oop - pre-checked for validity, but may be NULL meaning obsolete method\n+\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n@@ -3003,2 +2858,2 @@\n-JvmtiEnv::GetMaxLocals(Method* method_oop, jint* max_ptr) {\n-  NULL_CHECK(method_oop, JVMTI_ERROR_INVALID_METHODID);\n+JvmtiEnv::GetMaxLocals(Method* method, jint* max_ptr) {\n+  NULL_CHECK(method, JVMTI_ERROR_INVALID_METHODID);\n@@ -3006,1 +2861,1 @@\n-  (*max_ptr) = method_oop->max_locals();\n+  (*max_ptr) = method->max_locals();\n@@ -3011,1 +2866,1 @@\n-\/\/ method_oop - pre-checked for validity, but may be NULL meaning obsolete method\n+\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n@@ -3014,2 +2869,2 @@\n-JvmtiEnv::GetArgumentsSize(Method* method_oop, jint* size_ptr) {\n-  NULL_CHECK(method_oop, JVMTI_ERROR_INVALID_METHODID);\n+JvmtiEnv::GetArgumentsSize(Method* method, jint* size_ptr) {\n+  NULL_CHECK(method, JVMTI_ERROR_INVALID_METHODID);\n@@ -3018,1 +2873,1 @@\n-  (*size_ptr) = method_oop->size_of_parameters();\n+  (*size_ptr) = method->size_of_parameters();\n@@ -3023,1 +2878,1 @@\n-\/\/ method_oop - pre-checked for validity, but may be NULL meaning obsolete method\n+\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n@@ -3027,3 +2882,3 @@\n-JvmtiEnv::GetLineNumberTable(Method* method_oop, jint* entry_count_ptr, jvmtiLineNumberEntry** table_ptr) {\n-  NULL_CHECK(method_oop, JVMTI_ERROR_INVALID_METHODID);\n-  if (!method_oop->has_linenumber_table()) {\n+JvmtiEnv::GetLineNumberTable(Method* method, jint* entry_count_ptr, jvmtiLineNumberEntry** table_ptr) {\n+  NULL_CHECK(method, JVMTI_ERROR_INVALID_METHODID);\n+  if (!method->has_linenumber_table()) {\n@@ -3038,1 +2893,1 @@\n-  CompressedLineNumberReadStream stream(method_oop->compressed_linenumber_table());\n+  CompressedLineNumberReadStream stream(method->compressed_linenumber_table());\n@@ -3048,1 +2903,1 @@\n-    CompressedLineNumberReadStream stream(method_oop->compressed_linenumber_table());\n+    CompressedLineNumberReadStream stream(method->compressed_linenumber_table());\n@@ -3065,1 +2920,1 @@\n-\/\/ method_oop - pre-checked for validity, but may be NULL meaning obsolete method\n+\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n@@ -3069,1 +2924,1 @@\n-JvmtiEnv::GetMethodLocation(Method* method_oop, jlocation* start_location_ptr, jlocation* end_location_ptr) {\n+JvmtiEnv::GetMethodLocation(Method* method, jlocation* start_location_ptr, jlocation* end_location_ptr) {\n@@ -3071,1 +2926,1 @@\n-  NULL_CHECK(method_oop, JVMTI_ERROR_INVALID_METHODID);\n+  NULL_CHECK(method, JVMTI_ERROR_INVALID_METHODID);\n@@ -3073,2 +2928,2 @@\n-  (*end_location_ptr) = (jlocation) (method_oop->code_size() - 1);\n-  if (method_oop->code_size() == 0) {\n+  (*end_location_ptr) = (jlocation) (method->code_size() - 1);\n+  if (method->code_size() == 0) {\n@@ -3085,1 +2940,1 @@\n-\/\/ method_oop - pre-checked for validity, but may be NULL meaning obsolete method\n+\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n@@ -3089,1 +2944,1 @@\n-JvmtiEnv::GetLocalVariableTable(Method* method_oop, jint* entry_count_ptr, jvmtiLocalVariableEntry** table_ptr) {\n+JvmtiEnv::GetLocalVariableTable(Method* method, jint* entry_count_ptr, jvmtiLocalVariableEntry** table_ptr) {\n@@ -3091,1 +2946,1 @@\n-  NULL_CHECK(method_oop, JVMTI_ERROR_INVALID_METHODID);\n+  NULL_CHECK(method, JVMTI_ERROR_INVALID_METHODID);\n@@ -3095,1 +2950,1 @@\n-  InstanceKlass* ik = method_oop->method_holder();\n+  InstanceKlass* ik = method->method_holder();\n@@ -3100,1 +2955,1 @@\n-  ConstantPool* constants = method_oop->constants();\n+  ConstantPool* constants = method->constants();\n@@ -3106,1 +2961,1 @@\n-  jint num_entries = method_oop->localvariable_table_length();\n+  jint num_entries = method->localvariable_table_length();\n@@ -3111,1 +2966,1 @@\n-    LocalVariableTableElement* table = method_oop->localvariable_table_start();\n+    LocalVariableTableElement* table = method->localvariable_table_start();\n@@ -3162,1 +3017,1 @@\n-\/\/ method_oop - pre-checked for validity, but may be NULL meaning obsolete method\n+\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n@@ -3166,2 +3021,2 @@\n-JvmtiEnv::GetBytecodes(Method* method_oop, jint* bytecode_count_ptr, unsigned char** bytecodes_ptr) {\n-  NULL_CHECK(method_oop, JVMTI_ERROR_INVALID_METHODID);\n+JvmtiEnv::GetBytecodes(Method* method, jint* bytecode_count_ptr, unsigned char** bytecodes_ptr) {\n+  NULL_CHECK(method, JVMTI_ERROR_INVALID_METHODID);\n@@ -3169,3 +3024,2 @@\n-  HandleMark hm;\n-  methodHandle method(Thread::current(), method_oop);\n-  jint size = (jint)method->code_size();\n+  methodHandle mh(Thread::current(), method);\n+  jint size = (jint)mh->code_size();\n@@ -3179,1 +3033,1 @@\n-  JvmtiClassFileReconstituter::copy_bytecodes(method, *bytecodes_ptr);\n+  JvmtiClassFileReconstituter::copy_bytecodes(mh, *bytecodes_ptr);\n@@ -3185,1 +3039,1 @@\n-\/\/ method_oop - pre-checked for validity, but may be NULL meaning obsolete method\n+\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n@@ -3188,3 +3042,3 @@\n-JvmtiEnv::IsMethodNative(Method* method_oop, jboolean* is_native_ptr) {\n-  NULL_CHECK(method_oop, JVMTI_ERROR_INVALID_METHODID);\n-  (*is_native_ptr) = method_oop->is_native();\n+JvmtiEnv::IsMethodNative(Method* method, jboolean* is_native_ptr) {\n+  NULL_CHECK(method, JVMTI_ERROR_INVALID_METHODID);\n+  (*is_native_ptr) = method->is_native();\n@@ -3195,1 +3049,1 @@\n-\/\/ method_oop - pre-checked for validity, but may be NULL meaning obsolete method\n+\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n@@ -3198,3 +3052,3 @@\n-JvmtiEnv::IsMethodSynthetic(Method* method_oop, jboolean* is_synthetic_ptr) {\n-  NULL_CHECK(method_oop, JVMTI_ERROR_INVALID_METHODID);\n-  (*is_synthetic_ptr) = method_oop->is_synthetic();\n+JvmtiEnv::IsMethodSynthetic(Method* method, jboolean* is_synthetic_ptr) {\n+  NULL_CHECK(method, JVMTI_ERROR_INVALID_METHODID);\n+  (*is_synthetic_ptr) = method->is_synthetic();\n@@ -3205,1 +3059,1 @@\n-\/\/ method_oop - pre-checked for validity, but may be NULL meaning obsolete method\n+\/\/ method - pre-checked for validity, but may be NULL meaning obsolete method\n@@ -3208,1 +3062,1 @@\n-JvmtiEnv::IsMethodObsolete(Method* method_oop, jboolean* is_obsolete_ptr) {\n+JvmtiEnv::IsMethodObsolete(Method* method, jboolean* is_obsolete_ptr) {\n@@ -3217,1 +3071,1 @@\n-  if (method_oop == NULL || method_oop->is_obsolete()) {\n+  if (method == NULL || method->is_obsolete()) {\n@@ -3305,24 +3159,3 @@\n-    if (thread->is_Java_thread()) {\n-      JavaThread* current_thread = (JavaThread*)thread;\n-\n-      \/* Transition to thread_blocked without entering vm state          *\/\n-      \/* This is really evil. Normally you can't undo _thread_blocked    *\/\n-      \/* transitions like this because it would cause us to miss a       *\/\n-      \/* safepoint but since the thread was already in _thread_in_native *\/\n-      \/* the thread is not leaving a safepoint safe state and it will    *\/\n-      \/* block when it tries to return from native. We can't safepoint   *\/\n-      \/* block in here because we could deadlock the vmthread. Blech.    *\/\n-\n-      JavaThreadState state = current_thread->thread_state();\n-      assert(state == _thread_in_native, \"Must be _thread_in_native\");\n-      \/\/ frame should already be walkable since we are in native\n-      assert(!current_thread->has_last_Java_frame() ||\n-             current_thread->frame_anchor()->walkable(), \"Must be walkable\");\n-      current_thread->set_thread_state(_thread_blocked);\n-\n-      rmonitor->raw_enter(current_thread);\n-      \/\/ restore state, still at a safepoint safe state\n-      current_thread->set_thread_state(state);\n-    } else {\n-      rmonitor->raw_enter(thread);\n-    }\n+    \/\/ 8266889: raw_enter changes Java thread state, needs WXWrite\n+    MACOS_AARCH64_ONLY(ThreadWXEnable __wx(WXWrite, thread));\n+    rmonitor->raw_enter(thread);\n@@ -3366,0 +3199,2 @@\n+  \/\/ 8266889: raw_wait changes Java thread state, needs WXWrite\n+  MACOS_AARCH64_ONLY(ThreadWXEnable __wx(WXWrite, thread));\n@@ -3514,2 +3349,1 @@\n-\/\/ Threads_lock NOT held, java_thread not protected by lock\n-\/\/ java_thread - pre-checked\n+\/\/ java_thread - protected by ThreadsListHandle and pre-checked\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnv.cpp","additions":299,"deletions":465,"binary":false,"changes":764,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -42,1 +42,1 @@\n-  new (ResourceObj::C_HEAP, mtInternal) GrowableArray<JvmtiRawMonitor*>(1, true);\n+  new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<JvmtiRawMonitor*>(1, mtServiceability);\n@@ -49,5 +49,7 @@\n-  assert(current_java_thread->thread_state() == _thread_in_vm, \"Must be in vm\");\n-  for (int i = 0; i < count(); i++) {\n-    JvmtiRawMonitor* rmonitor = monitors()->at(i);\n-    rmonitor->raw_enter(current_java_thread);\n-    TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_ACQUIRED(rmonitor));\n+  {\n+    ThreadToNativeFromVM ttnfvm(current_java_thread);\n+    for (int i = 0; i < count(); i++) {\n+      JvmtiRawMonitor* rmonitor = monitors()->at(i);\n+      rmonitor->raw_enter(current_java_thread);\n+      TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_ACQUIRED(rmonitor));\n+    }\n@@ -67,1 +69,0 @@\n-                                                     _waiters(0),\n@@ -224,3 +225,1 @@\n-\/\/ transitions. However, we cannot perform such transitions whilst we hold the RawMonitor,\n-\/\/ else we can deadlock with the VMThread (which may also use RawMonitors as part of\n-\/\/ executing various callbacks).\n+\/\/ transitions.\n@@ -229,0 +228,3 @@\n+\/\/ Note:\n+\/\/  - simple_wait never reenters the monitor.\n+\/\/  - A JavaThread must be in native.\n@@ -241,4 +243,6 @@\n-    JavaThread* jt = (JavaThread*) self;\n-    \/\/ Transition to VM so we can check interrupt state\n-    ThreadInVMfromNative tivm(jt);\n-    if (jt->is_interrupted(true)) {\n+    JavaThread* jt = self->as_Java_thread();\n+    guarantee(jt->thread_state() == _thread_in_native, \"invariant\");\n+    {\n+      \/\/ This transition must be after we exited the monitor.\n+      ThreadInVMfromNative tivmfn(jt);\n+      if (jt->is_interrupted(true)) {\n@@ -246,6 +250,10 @@\n-    } else {\n-      ThreadBlockInVM tbivm(jt);\n-      jt->set_suspend_equivalent();\n-      if (millis <= 0) {\n-        self->_ParkEvent->park();\n-        self->_ParkEvent->park(millis);\n+        ThreadBlockInVM tbivm(jt);\n+        if (millis <= 0) {\n+          self->_ParkEvent->park();\n+        } else {\n+          self->_ParkEvent->park(millis);\n+        }\n+        \/\/ Return to VM before post-check of interrupt state\n+      }\n+      if (jt->is_interrupted(true)) {\n+        ret = M_INTERRUPTED;\n@@ -254,4 +262,0 @@\n-      \/\/ Return to VM before post-check of interrupt state\n-    }\n-    if (jt->is_interrupted(true)) {\n-      ret = M_INTERRUPTED;\n@@ -269,4 +273,0 @@\n-  simple_enter(self);\n-  guarantee(_owner == self, \"invariant\");\n-  guarantee(_recursions == 0, \"invariant\");\n-\n@@ -314,20 +314,5 @@\n-\/\/ Any JavaThread will enter here with state _thread_blocked\n-void JvmtiRawMonitor::raw_enter(Thread* self) {\n-  void* contended;\n-  JavaThread* jt = NULL;\n-  \/\/ don't enter raw monitor if thread is being externally suspended, it will\n-  \/\/ surprise the suspender if a \"suspended\" thread can still enter monitor\n-  if (self->is_Java_thread()) {\n-    jt = (JavaThread*)self;\n-    jt->SR_lock()->lock_without_safepoint_check();\n-    while (jt->is_external_suspend()) {\n-      jt->SR_lock()->unlock();\n-      jt->java_suspend_self();\n-      jt->SR_lock()->lock_without_safepoint_check();\n-    }\n-    \/\/ guarded by SR_lock to avoid racing with new external suspend requests.\n-    contended = Atomic::cmpxchg(&_owner, (Thread*)NULL, jt);\n-    jt->SR_lock()->unlock();\n-  } else {\n-    contended = Atomic::cmpxchg(&_owner, (Thread*)NULL, self);\n-  }\n+void JvmtiRawMonitor::ExitOnSuspend::operator()(JavaThread* current) {\n+  \/\/ We must exit the monitor in case of a safepoint.\n+  _rm->simple_exit(current);\n+  _rm_exited = true;\n+}\n@@ -335,1 +320,4 @@\n-  if (contended == self) {\n+\/\/ JavaThreads will enter here with state _thread_in_native.\n+void JvmtiRawMonitor::raw_enter(Thread* self) {\n+  \/\/ TODO Atomic::load on _owner field\n+  if (_owner == self) {\n@@ -340,6 +328,0 @@\n-  if (contended == NULL) {\n-    guarantee(_owner == self, \"invariant\");\n-    guarantee(_recursions == 0, \"invariant\");\n-    return;\n-  }\n-\n@@ -351,1 +333,3 @@\n-    guarantee(jt->thread_state() == _thread_blocked, \"invariant\");\n+    JavaThread* jt = self->as_Java_thread();\n+    guarantee(jt->thread_state() == _thread_in_native, \"invariant\");\n+    ThreadInVMfromNative tivmfn(jt);\n@@ -353,7 +337,6 @@\n-      jt->set_suspend_equivalent();\n-      \/\/ cleared by handle_special_suspend_equivalent_condition() or\n-      \/\/ java_suspend_self()\n-      simple_enter(jt);\n-\n-      \/\/ were we externally suspended while we were waiting?\n-      if (!jt->handle_special_suspend_equivalent_condition()) {\n+      ExitOnSuspend eos(this);\n+      {\n+        ThreadBlockInVMPreprocess<ExitOnSuspend> tbivmp(jt, eos);\n+        simple_enter(jt);\n+      }\n+      if (!eos.monitor_exited()) {\n@@ -362,11 +345,0 @@\n-\n-      \/\/ This thread was externally suspended\n-      \/\/ We have reentered the contended monitor, but while we were\n-      \/\/ waiting another thread suspended us. We don't want to reenter\n-      \/\/ the monitor while suspended because that would surprise the\n-      \/\/ thread that suspended us.\n-      \/\/\n-      \/\/ Drop the lock\n-      simple_exit(jt);\n-\n-      jt->java_suspend_self();\n@@ -409,7 +381,5 @@\n-  _waiters++;\n-  _recursions = save;\n-  _waiters--;\n-  guarantee(self == _owner, \"invariant\");\n-\n-  if (self->is_Java_thread()) {\n-    JavaThread* jt = (JavaThread*)self;\n+  \/\/ Now we need to re-enter the monitor. For JavaThreads\n+  \/\/ we need to manage suspend requests.\n+  if (self->is_Java_thread()) { \/\/ JavaThread re-enter\n+    JavaThread* jt = self->as_Java_thread();\n+    ThreadInVMfromNative tivmfn(jt);\n@@ -419,20 +389,3 @@\n-      jt->set_suspend_equivalent();\n-      if (!jt->handle_special_suspend_equivalent_condition()) {\n-        break;\n-      } else {\n-        \/\/ We've been suspended whilst waiting and so we have to\n-        \/\/ relinquish the raw monitor until we are resumed. Of course\n-        \/\/ after reacquiring we have to re-check for suspension again.\n-        \/\/ Suspension requires we are _thread_blocked, and we also have to\n-        \/\/ recheck for being interrupted.\n-        simple_exit(jt);\n-        {\n-          ThreadInVMfromNative tivm(jt);\n-          {\n-            ThreadBlockInVM tbivm(jt);\n-            jt->java_suspend_self();\n-          }\n-          if (jt->is_interrupted(true)) {\n-            ret = M_INTERRUPTED;\n-          }\n-        }\n+      ExitOnSuspend eos(this);\n+      {\n+        ThreadBlockInVMPreprocess<ExitOnSuspend> tbivmp(jt, eos);\n@@ -441,0 +394,3 @@\n+      if (!eos.monitor_exited()) {\n+        break;\n+      }\n@@ -442,2 +398,4 @@\n-    guarantee(jt == _owner, \"invariant\");\n-  } else {\n+    if (jt->is_interrupted(true)) {\n+      ret = M_INTERRUPTED;\n+    }\n+  } else { \/\/ Non-JavaThread re-enter\n@@ -445,0 +403,1 @@\n+    simple_enter(self);\n@@ -447,0 +406,3 @@\n+  _recursions = save;\n+\n+  guarantee(self == _owner, \"invariant\");\n","filename":"src\/hotspot\/share\/prims\/jvmtiRawMonitor.cpp","additions":66,"deletions":104,"binary":false,"changes":170,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,1 +29,1 @@\n-#include \"classfile\/systemDictionary.hpp\"\n+#include \"classfile\/vmClasses.hpp\"\n@@ -31,0 +31,1 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n@@ -37,1 +38,1 @@\n-#include \"oops\/arrayOop.inline.hpp\"\n+#include \"oops\/arrayOop.hpp\"\n@@ -40,0 +41,1 @@\n+#include \"oops\/klass.inline.hpp\"\n@@ -49,0 +51,1 @@\n+#include \"prims\/jvmtiTagMapTable.hpp\"\n@@ -50,0 +53,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -52,0 +56,1 @@\n+#include \"runtime\/interfaceSupport.inline.hpp\"\n@@ -57,0 +62,2 @@\n+#include \"runtime\/safepoint.hpp\"\n+#include \"runtime\/timerTrace.hpp\"\n@@ -66,316 +73,0 @@\n-#if INCLUDE_ZGC\n-#include \"gc\/z\/zGlobals.hpp\"\n-#endif\n-\n-\/\/ JvmtiTagHashmapEntry\n-\/\/\n-\/\/ Each entry encapsulates a reference to the tagged object\n-\/\/ and the tag value. In addition an entry includes a next pointer which\n-\/\/ is used to chain entries together.\n-\n-class JvmtiTagHashmapEntry : public CHeapObj<mtInternal> {\n- private:\n-  friend class JvmtiTagMap;\n-\n-  oop _object;                          \/\/ tagged object\n-  jlong _tag;                           \/\/ the tag\n-  JvmtiTagHashmapEntry* _next;          \/\/ next on the list\n-\n-  inline void init(oop object, jlong tag) {\n-    _object = object;\n-    _tag = tag;\n-    _next = NULL;\n-  }\n-\n-  \/\/ constructor\n-  JvmtiTagHashmapEntry(oop object, jlong tag) { init(object, tag); }\n-\n- public:\n-\n-  \/\/ accessor methods\n-  inline oop* object_addr() { return &_object; }\n-  inline oop object()       { return NativeAccess<ON_PHANTOM_OOP_REF>::oop_load(object_addr()); }\n-  \/\/ Peek at the object without keeping it alive. The returned object must be\n-  \/\/ kept alive using a normal access if it leaks out of a thread transition from VM.\n-  inline oop object_peek()  {\n-    return NativeAccess<ON_PHANTOM_OOP_REF | AS_NO_KEEPALIVE>::oop_load(object_addr());\n-  }\n-\n-  inline oop object_raw() {\n-    return RawAccess<>::oop_load(object_addr());\n-  }\n-\n-  inline jlong tag() const  { return _tag; }\n-\n-  inline void set_tag(jlong tag) {\n-    assert(tag != 0, \"can't be zero\");\n-    _tag = tag;\n-  }\n-\n-  inline bool equals(oop object) {\n-    return object == object_peek();\n-  }\n-\n-  inline JvmtiTagHashmapEntry* next() const        { return _next; }\n-  inline void set_next(JvmtiTagHashmapEntry* next) { _next = next; }\n-};\n-\n-\n-\/\/ JvmtiTagHashmap\n-\/\/\n-\/\/ A hashmap is essentially a table of pointers to entries. Entries\n-\/\/ are hashed to a location, or position in the table, and then\n-\/\/ chained from that location. The \"key\" for hashing is address of\n-\/\/ the object, or oop. The \"value\" is the tag value.\n-\/\/\n-\/\/ A hashmap maintains a count of the number entries in the hashmap\n-\/\/ and resizes if the number of entries exceeds a given threshold.\n-\/\/ The threshold is specified as a percentage of the size - for\n-\/\/ example a threshold of 0.75 will trigger the hashmap to resize\n-\/\/ if the number of entries is >75% of table size.\n-\/\/\n-\/\/ A hashmap provides functions for adding, removing, and finding\n-\/\/ entries. It also provides a function to iterate over all entries\n-\/\/ in the hashmap.\n-\n-class JvmtiTagHashmap : public CHeapObj<mtInternal> {\n- private:\n-  friend class JvmtiTagMap;\n-\n-  enum {\n-    small_trace_threshold  = 10000,                  \/\/ threshold for tracing\n-    medium_trace_threshold = 100000,\n-    large_trace_threshold  = 1000000,\n-    initial_trace_threshold = small_trace_threshold\n-  };\n-\n-  static int _sizes[];                  \/\/ array of possible hashmap sizes\n-  int _size;                            \/\/ actual size of the table\n-  int _size_index;                      \/\/ index into size table\n-\n-  int _entry_count;                     \/\/ number of entries in the hashmap\n-\n-  float _load_factor;                   \/\/ load factor as a % of the size\n-  int _resize_threshold;                \/\/ computed threshold to trigger resizing.\n-  bool _resizing_enabled;               \/\/ indicates if hashmap can resize\n-\n-  int _trace_threshold;                 \/\/ threshold for trace messages\n-\n-  JvmtiTagHashmapEntry** _table;        \/\/ the table of entries.\n-\n-  \/\/ private accessors\n-  int resize_threshold() const                  { return _resize_threshold; }\n-  int trace_threshold() const                   { return _trace_threshold; }\n-\n-  \/\/ initialize the hashmap\n-  void init(int size_index=0, float load_factor=4.0f) {\n-    int initial_size =  _sizes[size_index];\n-    _size_index = size_index;\n-    _size = initial_size;\n-    _entry_count = 0;\n-    _trace_threshold = initial_trace_threshold;\n-    _load_factor = load_factor;\n-    _resize_threshold = (int)(_load_factor * _size);\n-    _resizing_enabled = true;\n-    size_t s = initial_size * sizeof(JvmtiTagHashmapEntry*);\n-    _table = (JvmtiTagHashmapEntry**)os::malloc(s, mtInternal);\n-    if (_table == NULL) {\n-      vm_exit_out_of_memory(s, OOM_MALLOC_ERROR,\n-        \"unable to allocate initial hashtable for jvmti object tags\");\n-    }\n-    for (int i=0; i<initial_size; i++) {\n-      _table[i] = NULL;\n-    }\n-  }\n-\n-  \/\/ hash a given key (oop) with the specified size\n-  static unsigned int hash(oop key, int size) {\n-    const oop obj = Access<>::resolve(key);\n-    const unsigned int hash = Universe::heap()->hash_oop(obj);\n-    return hash % size;\n-  }\n-\n-  \/\/ hash a given key (oop)\n-  unsigned int hash(oop key) {\n-    return hash(key, _size);\n-  }\n-\n-  \/\/ resize the hashmap - allocates a large table and re-hashes\n-  \/\/ all entries into the new table.\n-  void resize() {\n-    int new_size_index = _size_index+1;\n-    int new_size = _sizes[new_size_index];\n-    if (new_size < 0) {\n-      \/\/ hashmap already at maximum capacity\n-      return;\n-    }\n-\n-    \/\/ allocate new table\n-    size_t s = new_size * sizeof(JvmtiTagHashmapEntry*);\n-    JvmtiTagHashmapEntry** new_table = (JvmtiTagHashmapEntry**)os::malloc(s, mtInternal);\n-    if (new_table == NULL) {\n-      warning(\"unable to allocate larger hashtable for jvmti object tags\");\n-      set_resizing_enabled(false);\n-      return;\n-    }\n-\n-    \/\/ initialize new table\n-    int i;\n-    for (i=0; i<new_size; i++) {\n-      new_table[i] = NULL;\n-    }\n-\n-    \/\/ rehash all entries into the new table\n-    for (i=0; i<_size; i++) {\n-      JvmtiTagHashmapEntry* entry = _table[i];\n-      while (entry != NULL) {\n-        JvmtiTagHashmapEntry* next = entry->next();\n-        oop key = entry->object_peek();\n-        assert(key != NULL, \"jni weak reference cleared!!\");\n-        unsigned int h = hash(key, new_size);\n-        JvmtiTagHashmapEntry* anchor = new_table[h];\n-        if (anchor == NULL) {\n-          new_table[h] = entry;\n-          entry->set_next(NULL);\n-        } else {\n-          entry->set_next(anchor);\n-          new_table[h] = entry;\n-        }\n-        entry = next;\n-      }\n-    }\n-\n-    \/\/ free old table and update settings.\n-    os::free((void*)_table);\n-    _table = new_table;\n-    _size_index = new_size_index;\n-    _size = new_size;\n-\n-    \/\/ compute new resize threshold\n-    _resize_threshold = (int)(_load_factor * _size);\n-  }\n-\n-\n-  \/\/ internal remove function - remove an entry at a given position in the\n-  \/\/ table.\n-  inline void remove(JvmtiTagHashmapEntry* prev, int pos, JvmtiTagHashmapEntry* entry) {\n-    assert(pos >= 0 && pos < _size, \"out of range\");\n-    if (prev == NULL) {\n-      _table[pos] = entry->next();\n-    } else {\n-      prev->set_next(entry->next());\n-    }\n-    assert(_entry_count > 0, \"checking\");\n-    _entry_count--;\n-  }\n-\n-  \/\/ resizing switch\n-  bool is_resizing_enabled() const          { return _resizing_enabled; }\n-  void set_resizing_enabled(bool enable)    { _resizing_enabled = enable; }\n-\n-  \/\/ debugging\n-  void print_memory_usage();\n-  void compute_next_trace_threshold();\n-\n- public:\n-\n-  \/\/ create a JvmtiTagHashmap of a preferred size and optionally a load factor.\n-  \/\/ The preferred size is rounded down to an actual size.\n-  JvmtiTagHashmap(int size, float load_factor=0.0f) {\n-    int i=0;\n-    while (_sizes[i] < size) {\n-      if (_sizes[i] < 0) {\n-        assert(i > 0, \"sanity check\");\n-        i--;\n-        break;\n-      }\n-      i++;\n-    }\n-\n-    \/\/ if a load factor is specified then use it, otherwise use default\n-    if (load_factor > 0.01f) {\n-      init(i, load_factor);\n-    } else {\n-      init(i);\n-    }\n-  }\n-\n-  \/\/ create a JvmtiTagHashmap with default settings\n-  JvmtiTagHashmap() {\n-    init();\n-  }\n-\n-  \/\/ release table when JvmtiTagHashmap destroyed\n-  ~JvmtiTagHashmap() {\n-    if (_table != NULL) {\n-      os::free((void*)_table);\n-      _table = NULL;\n-    }\n-  }\n-\n-  \/\/ accessors\n-  int size() const                              { return _size; }\n-  JvmtiTagHashmapEntry** table() const          { return _table; }\n-  int entry_count() const                       { return _entry_count; }\n-\n-  \/\/ find an entry in the hashmap, returns NULL if not found.\n-  inline JvmtiTagHashmapEntry* find(oop key) {\n-    unsigned int h = hash(key);\n-    JvmtiTagHashmapEntry* entry = _table[h];\n-    while (entry != NULL) {\n-      if (entry->equals(key)) {\n-         return entry;\n-      }\n-      entry = entry->next();\n-    }\n-    return NULL;\n-  }\n-\n-\n-  \/\/ add a new entry to hashmap\n-  inline void add(oop key, JvmtiTagHashmapEntry* entry) {\n-    assert(key != NULL, \"checking\");\n-    assert(find(key) == NULL, \"duplicate detected\");\n-    unsigned int h = hash(key);\n-    JvmtiTagHashmapEntry* anchor = _table[h];\n-    if (anchor == NULL) {\n-      _table[h] = entry;\n-      entry->set_next(NULL);\n-    } else {\n-      entry->set_next(anchor);\n-      _table[h] = entry;\n-    }\n-\n-    _entry_count++;\n-    if (log_is_enabled(Debug, jvmti, objecttagging) && entry_count() >= trace_threshold()) {\n-      print_memory_usage();\n-      compute_next_trace_threshold();\n-    }\n-\n-    \/\/ if the number of entries exceed the threshold then resize\n-    if (entry_count() > resize_threshold() && is_resizing_enabled()) {\n-      resize();\n-    }\n-  }\n-\n-  \/\/ remove an entry with the given key.\n-  inline JvmtiTagHashmapEntry* remove(oop key) {\n-    unsigned int h = hash(key);\n-    JvmtiTagHashmapEntry* entry = _table[h];\n-    JvmtiTagHashmapEntry* prev = NULL;\n-    while (entry != NULL) {\n-      if (entry->equals(key)) {\n-        break;\n-      }\n-      prev = entry;\n-      entry = entry->next();\n-    }\n-    if (entry != NULL) {\n-      remove(prev, h, entry);\n-    }\n-    return entry;\n-  }\n-\n-  \/\/ iterate over all entries in the hashmap\n-  void entry_iterate(JvmtiTagHashmapEntryClosure* closure);\n-};\n@@ -398,57 +89,1 @@\n-\/\/ possible hashmap sizes - odd primes that roughly double in size.\n-\/\/ To avoid excessive resizing the odd primes from 4801-76831 and\n-\/\/ 76831-307261 have been removed. The list must be terminated by -1.\n-int JvmtiTagHashmap::_sizes[] =  { 4801, 76831, 307261, 614563, 1228891,\n-    2457733, 4915219, 9830479, 19660831, 39321619, 78643219, -1 };\n-\n-\n-\/\/ A supporting class for iterating over all entries in Hashmap\n-class JvmtiTagHashmapEntryClosure {\n- public:\n-  virtual void do_entry(JvmtiTagHashmapEntry* entry) = 0;\n-};\n-\n-\n-\/\/ iterate over all entries in the hashmap\n-void JvmtiTagHashmap::entry_iterate(JvmtiTagHashmapEntryClosure* closure) {\n-  for (int i=0; i<_size; i++) {\n-    JvmtiTagHashmapEntry* entry = _table[i];\n-    JvmtiTagHashmapEntry* prev = NULL;\n-    while (entry != NULL) {\n-      \/\/ obtain the next entry before invoking do_entry - this is\n-      \/\/ necessary because do_entry may remove the entry from the\n-      \/\/ hashmap.\n-      JvmtiTagHashmapEntry* next = entry->next();\n-      closure->do_entry(entry);\n-      entry = next;\n-     }\n-  }\n-}\n-\n-\/\/ debugging\n-void JvmtiTagHashmap::print_memory_usage() {\n-  intptr_t p = (intptr_t)this;\n-  tty->print(\"[JvmtiTagHashmap @ \" INTPTR_FORMAT, p);\n-\n-  \/\/ table + entries in KB\n-  int hashmap_usage = (size()*sizeof(JvmtiTagHashmapEntry*) +\n-    entry_count()*sizeof(JvmtiTagHashmapEntry))\/K;\n-\n-  int weak_globals_usage = (int)(JNIHandles::weak_global_handle_memory_usage()\/K);\n-  tty->print_cr(\", %d entries (%d KB) <JNI weak globals: %d KB>]\",\n-    entry_count(), hashmap_usage, weak_globals_usage);\n-}\n-\n-\/\/ compute threshold for the next trace message\n-void JvmtiTagHashmap::compute_next_trace_threshold() {\n-  _trace_threshold = entry_count();\n-  if (trace_threshold() < medium_trace_threshold) {\n-    _trace_threshold += small_trace_threshold;\n-  } else {\n-    if (trace_threshold() < large_trace_threshold) {\n-      _trace_threshold += medium_trace_threshold;\n-    } else {\n-      _trace_threshold += large_trace_threshold;\n-    }\n-  }\n-}\n+bool JvmtiTagMap::_has_object_free_events = false;\n@@ -460,4 +95,5 @@\n-  _lock(Mutex::nonleaf+2, \"JvmtiTagMap._lock\", false),\n-  _free_entries(NULL),\n-  _free_entries_count(0)\n-{\n+  _lock(Mutex::nonleaf+1, \"JvmtiTagMap_lock\", Mutex::_allow_vm_block_flag,\n+        Mutex::_safepoint_check_never),\n+  _needs_rehashing(false),\n+  _needs_cleaning(false) {\n+\n@@ -485,1 +121,1 @@\n-  _hashmap = new JvmtiTagHashmap();\n+  _hashmap = new JvmtiTagMapTable();\n@@ -491,1 +127,0 @@\n-\n@@ -494,1 +129,1 @@\n-  \/\/ also being destroryed.\n+  \/\/ also being destroyed.\n@@ -498,10 +133,0 @@\n-  JvmtiTagHashmapEntry** table = _hashmap->table();\n-  for (int j = 0; j < _hashmap->size(); j++) {\n-    JvmtiTagHashmapEntry* entry = table[j];\n-    while (entry != NULL) {\n-      JvmtiTagHashmapEntry* next = entry->next();\n-      delete entry;\n-      entry = next;\n-    }\n-  }\n-\n@@ -512,9 +137,0 @@\n-  \/\/ remove any entries on the free list\n-  JvmtiTagHashmapEntry* entry = _free_entries;\n-  while (entry != NULL) {\n-    JvmtiTagHashmapEntry* next = entry->next();\n-    delete entry;\n-    entry = next;\n-  }\n-  _free_entries = NULL;\n-\n@@ -524,34 +140,6 @@\n-\/\/ create a hashmap entry\n-\/\/ - if there's an entry on the (per-environment) free list then this\n-\/\/ is returned. Otherwise an new entry is allocated.\n-JvmtiTagHashmapEntry* JvmtiTagMap::create_entry(oop ref, jlong tag) {\n-  assert(Thread::current()->is_VM_thread() || is_locked(), \"checking\");\n-\n-  \/\/ ref was read with AS_NO_KEEPALIVE, or equivalent.\n-  \/\/ The object needs to be kept alive when it is published.\n-  Universe::heap()->keep_alive(ref);\n-\n-  JvmtiTagHashmapEntry* entry;\n-  if (_free_entries == NULL) {\n-    entry = new JvmtiTagHashmapEntry(ref, tag);\n-  } else {\n-    assert(_free_entries_count > 0, \"mismatched _free_entries_count\");\n-    _free_entries_count--;\n-    entry = _free_entries;\n-    _free_entries = entry->next();\n-    entry->init(ref, tag);\n-  }\n-  return entry;\n-}\n-\n-\/\/ destroy an entry by returning it to the free list\n-void JvmtiTagMap::destroy_entry(JvmtiTagHashmapEntry* entry) {\n-  assert(SafepointSynchronize::is_at_safepoint() || is_locked(), \"checking\");\n-  \/\/ limit the size of the free list\n-  if (_free_entries_count >= max_free_entries) {\n-    delete entry;\n-  } else {\n-    entry->set_next(_free_entries);\n-    _free_entries = entry;\n-    _free_entries_count++;\n-  }\n+\/\/ Called by env_dispose() to reclaim memory before deallocation.\n+\/\/ Remove all the entries but keep the empty table intact.\n+\/\/ This needs the table lock.\n+void JvmtiTagMap::clear() {\n+  MutexLocker ml(lock(), Mutex::_no_safepoint_check_flag);\n+  _hashmap->clear();\n@@ -571,1 +159,1 @@\n-    DEBUG_ONLY(Thread::current()->check_possible_safepoint());\n+    DEBUG_ONLY(JavaThread::current()->check_possible_safepoint());\n@@ -577,1 +165,1 @@\n-void JvmtiTagMap::entry_iterate(JvmtiTagHashmapEntryClosure* closure) {\n+void JvmtiTagMap::entry_iterate(JvmtiTagMapEntryClosure* closure) {\n@@ -584,1 +172,22 @@\n-  return hashmap()->entry_count() == 0;\n+  return hashmap()->is_empty();\n+}\n+\n+\/\/ This checks for posting and rehashing before operations that\n+\/\/ this tagmap table.  The calls from a JavaThread only rehash, posting is\n+\/\/ only done before heap walks.\n+void JvmtiTagMap::check_hashmap(bool post_events) {\n+  assert(!post_events || SafepointSynchronize::is_at_safepoint(), \"precondition\");\n+  assert(is_locked(), \"checking\");\n+\n+  if (is_empty()) { return; }\n+\n+  if (_needs_cleaning &&\n+      post_events &&\n+      env()->is_enabled(JVMTI_EVENT_OBJECT_FREE)) {\n+    remove_dead_entries_locked(true \/* post_object_free *\/);\n+  }\n+  if (_needs_rehashing) {\n+    log_info(jvmti, table)(\"TagMap table needs rehashing\");\n+    hashmap()->rehash();\n+    _needs_rehashing = false;\n+  }\n@@ -587,0 +196,16 @@\n+\/\/ This checks for posting and rehashing and is called from the heap walks.\n+void JvmtiTagMap::check_hashmaps_for_heapwalk() {\n+  assert(SafepointSynchronize::is_at_safepoint(), \"called from safepoints\");\n+\n+  \/\/ Verify that the tag map tables are valid and unconditionally post events\n+  \/\/ that are expected to be posted before gc_notification.\n+  JvmtiEnvIterator it;\n+  for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {\n+    JvmtiTagMap* tag_map = env->tag_map_acquire();\n+    if (tag_map != NULL) {\n+      \/\/ The ZDriver may be walking the hashmaps concurrently so this lock is needed.\n+      MutexLocker ml(tag_map->lock(), Mutex::_no_safepoint_check_flag);\n+      tag_map->check_hashmap(\/*post_events*\/ true);\n+    }\n+  }\n+}\n@@ -592,1 +217,1 @@\n-  JvmtiTagHashmapEntry* entry = tag_map->hashmap()->find(o);\n+  JvmtiTagMapEntry* entry = tag_map->hashmap()->find(o);\n@@ -596,0 +221,2 @@\n+    jlong tag = entry->tag();\n+    assert(tag != 0, \"should not be zero\");\n@@ -618,2 +245,2 @@\n-  JvmtiTagHashmap* _hashmap;\n-  JvmtiTagHashmapEntry* _entry;\n+  JvmtiTagMapTable* _hashmap;\n+  JvmtiTagMapEntry* _entry;\n@@ -629,2 +256,2 @@\n-  void inline post_callback_tag_update(oop o, JvmtiTagHashmap* hashmap,\n-                                       JvmtiTagHashmapEntry* entry, jlong obj_tag);\n+  void inline post_callback_tag_update(oop o, JvmtiTagMapTable* hashmap,\n+                                       JvmtiTagMapEntry* entry, jlong obj_tag);\n@@ -651,1 +278,1 @@\n-    assert(SystemDictionary::Class_klass()->is_mirror_instance_klass(), \"Is not?\");\n+    assert(vmClasses::Class_klass()->is_mirror_instance_klass(), \"Is not?\");\n@@ -670,2 +297,2 @@\n-                                                      JvmtiTagHashmap* hashmap,\n-                                                      JvmtiTagHashmapEntry* entry,\n+                                                      JvmtiTagMapTable* hashmap,\n+                                                      JvmtiTagMapEntry* entry,\n@@ -677,2 +304,1 @@\n-      entry = tag_map()->create_entry(o, obj_tag);\n-      hashmap->add(o, entry);\n+      hashmap->add(o, obj_tag);\n@@ -684,5 +310,1 @@\n-\n-      JvmtiTagHashmapEntry* entry_removed = hashmap->remove(o);\n-      assert(entry_removed == entry, \"checking\");\n-      tag_map()->destroy_entry(entry);\n-\n+      hashmap->remove(o);\n@@ -715,2 +337,2 @@\n-  JvmtiTagHashmap* _referrer_hashmap;\n-  JvmtiTagHashmapEntry* _referrer_entry;\n+  JvmtiTagMapTable* _referrer_hashmap;\n+  JvmtiTagMapEntry* _referrer_entry;\n@@ -772,1 +394,1 @@\n-  MutexLocker ml(lock());\n+  MutexLocker ml(lock(), Mutex::_no_safepoint_check_flag);\n@@ -775,0 +397,5 @@\n+  \/\/ SetTag should not post events because the JavaThread has to\n+  \/\/ transition to native for the callback and this cannot stop for\n+  \/\/ safepoints with the hashmap lock held.\n+  check_hashmap(\/*post_events*\/ false);\n+\n@@ -779,2 +406,2 @@\n-  JvmtiTagHashmap* hashmap = _hashmap;\n-  JvmtiTagHashmapEntry* entry = hashmap->find(o);\n+  JvmtiTagMapTable* hashmap = _hashmap;\n+  JvmtiTagMapEntry* entry = hashmap->find(o);\n@@ -785,2 +412,1 @@\n-      entry = create_entry(o, tag);\n-      hashmap->add(o, entry);\n+      hashmap->add(o, tag);\n@@ -796,1 +422,0 @@\n-      destroy_entry(entry);\n@@ -805,1 +430,1 @@\n-  MutexLocker ml(lock());\n+  MutexLocker ml(lock(), Mutex::_no_safepoint_check_flag);\n@@ -808,0 +433,5 @@\n+  \/\/ GetTag should not post events because the JavaThread has to\n+  \/\/ transition to native for the callback and this cannot stop for\n+  \/\/ safepoints with the hashmap lock held.\n+  check_hashmap(\/*post_events*\/ false);\n+\n@@ -848,3 +478,0 @@\n-  \/\/ returns the field count for the given class\n-  static int compute_field_count(InstanceKlass* ik);\n-\n@@ -864,2 +491,2 @@\n-  _fields = new (ResourceObj::C_HEAP, mtInternal)\n-    GrowableArray<ClassFieldDescriptor*>(initial_field_count, true);\n+  _fields = new (ResourceObj::C_HEAP, mtServiceability)\n+    GrowableArray<ClassFieldDescriptor*>(initial_field_count, mtServiceability);\n@@ -884,1 +511,0 @@\n-  HandleMark hm;\n@@ -909,1 +535,0 @@\n-  HandleMark hm;\n@@ -1001,2 +626,2 @@\n-    _class_list = new (ResourceObj::C_HEAP, mtInternal)\n-      GrowableArray<InstanceKlass*>(initial_class_count, true);\n+    _class_list = new (ResourceObj::C_HEAP, mtServiceability)\n+      GrowableArray<InstanceKlass*>(initial_class_count, mtServiceability);\n@@ -1110,1 +735,1 @@\n-  assert(str->klass() == SystemDictionary::String_klass(), \"not a string\");\n+  assert(str->klass() == vmClasses::String_klass(), \"not a string\");\n@@ -1191,1 +816,1 @@\n-  assert(obj->klass() == SystemDictionary::Class_klass(), \"not a class\");\n+  assert(obj->klass() == vmClasses::Class_klass(), \"not a class\");\n@@ -1325,0 +950,2 @@\n+    JvmtiTagMap::check_hashmaps_for_heapwalk();\n+\n@@ -1390,0 +1017,8 @@\n+\n+  \/\/ skip if object is a dormant shared object whose mirror hasn't been loaded\n+  if (o != NULL && o->klass()->java_mirror() == NULL) {\n+    log_debug(cds, heap)(\"skipped dormant archived object \" INTPTR_FORMAT \" (%s)\", p2i(o),\n+                         o->klass()->external_name());\n+    return;\n+  }\n+\n@@ -1469,0 +1104,7 @@\n+  \/\/ skip if object is a dormant shared object whose mirror hasn't been loaded\n+  if (obj != NULL &&   obj->klass()->java_mirror() == NULL) {\n+    log_debug(cds, heap)(\"skipped dormant archived object \" INTPTR_FORMAT \" (%s)\", p2i(obj),\n+                         obj->klass()->external_name());\n+    return;\n+  }\n+\n@@ -1496,1 +1138,1 @@\n-    if (obj->klass() == SystemDictionary::Class_klass()) {\n+    if (obj->klass() == vmClasses::Class_klass()) {\n@@ -1513,1 +1155,1 @@\n-      obj->klass() == SystemDictionary::String_klass()) {\n+      obj->klass() == vmClasses::String_klass()) {\n@@ -1542,0 +1184,5 @@\n+  \/\/ EA based optimizations on tagged objects are already reverted.\n+  EscapeBarrier eb(object_filter == JVMTI_HEAP_OBJECT_UNTAGGED ||\n+                   object_filter == JVMTI_HEAP_OBJECT_EITHER,\n+                   JavaThread::current());\n+  eb.deoptimize_objects_all_threads();\n@@ -1559,0 +1206,3 @@\n+  \/\/ EA based optimizations on tagged objects are already reverted.\n+  EscapeBarrier eb(!(heap_filter & JVMTI_HEAP_FILTER_UNTAGGED), JavaThread::current());\n+  eb.deoptimize_objects_all_threads();\n@@ -1569,0 +1219,54 @@\n+void JvmtiTagMap::remove_dead_entries_locked(bool post_object_free) {\n+  assert(is_locked(), \"precondition\");\n+  if (_needs_cleaning) {\n+    \/\/ Recheck whether to post object free events under the lock.\n+    post_object_free = post_object_free && env()->is_enabled(JVMTI_EVENT_OBJECT_FREE);\n+    log_info(jvmti, table)(\"TagMap table needs cleaning%s\",\n+                           (post_object_free ? \" and posting\" : \"\"));\n+    hashmap()->remove_dead_entries(env(), post_object_free);\n+    _needs_cleaning = false;\n+  }\n+}\n+\n+void JvmtiTagMap::remove_dead_entries(bool post_object_free) {\n+  MutexLocker ml(lock(), Mutex::_no_safepoint_check_flag);\n+  remove_dead_entries_locked(post_object_free);\n+}\n+\n+class VM_JvmtiPostObjectFree: public VM_Operation {\n+  JvmtiTagMap* _tag_map;\n+ public:\n+  VM_JvmtiPostObjectFree(JvmtiTagMap* tag_map) : _tag_map(tag_map) {}\n+  VMOp_Type type() const { return VMOp_Cleanup; }\n+  void doit() {\n+    _tag_map->remove_dead_entries(true \/* post_object_free *\/);\n+  }\n+\n+  \/\/ Doesn't need a safepoint, just the VM thread\n+  virtual bool evaluate_at_safepoint() const { return false; }\n+};\n+\n+\/\/ PostObjectFree can't be called by JavaThread, so call it from the VM thread.\n+void JvmtiTagMap::post_dead_objects_on_vm_thread() {\n+  VM_JvmtiPostObjectFree op(this);\n+  VMThread::execute(&op);\n+}\n+\n+void JvmtiTagMap::flush_object_free_events() {\n+  assert_not_at_safepoint();\n+  if (env()->is_enabled(JVMTI_EVENT_OBJECT_FREE)) {\n+    {\n+      MutexLocker ml(lock(), Mutex::_no_safepoint_check_flag);\n+      if (!_needs_cleaning || is_empty()) {\n+        _needs_cleaning = false;\n+        return;\n+      }\n+    } \/\/ Drop the lock so we can do the cleaning on the VM thread.\n+    \/\/ Needs both cleaning and event posting (up to some other thread\n+    \/\/ getting there first after we dropped the lock).\n+    post_dead_objects_on_vm_thread();\n+  } else {\n+    remove_dead_entries(false);\n+  }\n+}\n+\n@@ -1571,1 +1275,1 @@\n-class TagObjectCollector : public JvmtiTagHashmapEntryClosure {\n+class TagObjectCollector : public JvmtiTagMapEntryClosure {\n@@ -1574,0 +1278,1 @@\n+  JavaThread* _thread;\n@@ -1576,0 +1281,1 @@\n+  bool _some_dead_found;\n@@ -1581,7 +1287,8 @@\n-  TagObjectCollector(JvmtiEnv* env, const jlong* tags, jint tag_count) {\n-    _env = env;\n-    _tags = (jlong*)tags;\n-    _tag_count = tag_count;\n-    _object_results = new (ResourceObj::C_HEAP, mtInternal) GrowableArray<jobject>(1,true);\n-    _tag_results = new (ResourceObj::C_HEAP, mtInternal) GrowableArray<uint64_t>(1,true);\n-  }\n+  TagObjectCollector(JvmtiEnv* env, const jlong* tags, jint tag_count) :\n+    _env(env),\n+    _thread(JavaThread::current()),\n+    _tags((jlong*)tags),\n+    _tag_count(tag_count),\n+    _some_dead_found(false),\n+    _object_results(new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<jobject>(1, mtServiceability)),\n+    _tag_results(new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<uint64_t>(1, mtServiceability)) { }\n@@ -1594,0 +1301,2 @@\n+  bool some_dead_found() const { return _some_dead_found; }\n+\n@@ -1598,1 +1307,1 @@\n-  void do_entry(JvmtiTagHashmapEntry* entry) {\n+  void do_entry(JvmtiTagMapEntry* entry) {\n@@ -1606,0 +1315,5 @@\n+        if (o == NULL) {\n+          _some_dead_found = true;\n+          \/\/ skip this whole entry\n+          return;\n+        }\n@@ -1607,1 +1321,1 @@\n-        jobject ref = JNIHandles::make_local(JavaThread::current(), o);\n+        jobject ref = JNIHandles::make_local(_thread, o);\n@@ -1660,1 +1374,1 @@\n-    MutexLocker ml(lock());\n+    MutexLocker ml(lock(), Mutex::_no_safepoint_check_flag);\n@@ -1662,0 +1376,4 @@\n+    \/\/ Can't post ObjectFree events here from a JavaThread, so this\n+    \/\/ will race with the gc_notification thread in the tiny\n+    \/\/ window where the object is not marked but hasn't been notified that\n+    \/\/ it is collected yet.\n@@ -1664,0 +1382,3 @@\n+  if (collector.some_dead_found() && env()->is_enabled(JVMTI_EVENT_OBJECT_FREE)) {\n+    post_dead_objects_on_vm_thread();\n+  }\n@@ -1724,0 +1445,1 @@\n+  assert(SafepointSynchronize::is_at_safepoint(), \"must be at a safepoint\");\n@@ -1729,2 +1451,2 @@\n-  _saved_mark_stack = new (ResourceObj::C_HEAP, mtInternal) GrowableArray<markWord>(4000, true);\n-  _saved_oop_stack = new (ResourceObj::C_HEAP, mtInternal) GrowableArray<oop>(4000, true);\n+  _saved_mark_stack = new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<markWord>(4000, mtServiceability);\n+  _saved_oop_stack = new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<oop>(4000, mtServiceability);\n@@ -1808,1 +1530,0 @@\n-    case JVMTI_HEAP_REFERENCE_MONITOR:      return JVMTI_HEAP_ROOT_MONITOR;\n@@ -2365,1 +2086,1 @@\n-  assert(str->klass() == SystemDictionary::String_klass(), \"not a string\");\n+  assert(str->klass() == vmClasses::String_klass(), \"not a string\");\n@@ -2710,1 +2431,0 @@\n-  bool _collecting_heap_roots;                      \/\/ are we collecting roots\n@@ -2718,1 +2438,1 @@\n-    return new (ResourceObj::C_HEAP, mtInternal) GrowableArray<oop>(initial_visit_stack_size, true);\n+    return new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<oop>(initial_visit_stack_size, mtServiceability);\n@@ -2887,1 +2607,1 @@\n-    if (java_super != NULL && java_super != SystemDictionary::Object_klass()) {\n+    if (java_super != NULL && java_super != vmClasses::Object_klass()) {\n@@ -2934,1 +2654,1 @@\n-            \/\/ Code generated by JIT and AOT compilers might not resolve constant\n+            \/\/ Code generated by JIT compilers might not resolve constant\n@@ -3039,1 +2759,1 @@\n-      o->klass() == SystemDictionary::String_klass()) {\n+      o->klass() == vmClasses::String_klass()) {\n@@ -3074,7 +2794,0 @@\n-  \/\/ Inflated monitors\n-  blk.set_kind(JVMTI_HEAP_REFERENCE_MONITOR);\n-  ObjectSynchronizer::oops_do(&blk);\n-  if (blk.stopped()) {\n-    return false;\n-  }\n-\n@@ -3087,1 +2800,1 @@\n-  Universe::oops_do(&blk);\n+  Universe::vm_global()->oops_do(&blk);\n@@ -3244,1 +2957,1 @@\n-    if (o->klass() == SystemDictionary::Class_klass()) {\n+    if (o->klass() == vmClasses::Class_klass()) {\n@@ -3277,0 +2990,2 @@\n+  JvmtiTagMap::check_hashmaps_for_heapwalk();\n+\n@@ -3320,0 +3035,3 @@\n+  JavaThread* jt = JavaThread::current();\n+  EscapeBarrier eb(true, jt);\n+  eb.deoptimize_objects_all_threads();\n@@ -3347,2 +3065,7 @@\n-  Handle initial_object(Thread::current(), obj);\n-\n+  JavaThread* jt = JavaThread::current();\n+  Handle initial_object(jt, obj);\n+  \/\/ EA based optimizations that are tagged or reachable from initial_object are already reverted.\n+  EscapeBarrier eb(initial_object.is_null() &&\n+                   !(heap_filter & JVMTI_HEAP_FILTER_UNTAGGED),\n+                   jt);\n+  eb.deoptimize_objects_all_threads();\n@@ -3355,0 +3078,5 @@\n+\/\/ Concurrent GC needs to call this in relocation pause, so after the objects are moved\n+\/\/ and have their new addresses, the table can be rehashed.\n+void JvmtiTagMap::set_needs_rehashing() {\n+  assert(SafepointSynchronize::is_at_safepoint(), \"called in gc pause\");\n+  assert(Thread::current()->is_VM_thread(), \"should be the VM thread\");\n@@ -3356,14 +3084,5 @@\n-void JvmtiTagMap::weak_oops_do(BoolObjectClosure* is_alive, OopClosure* f) {\n-  \/\/ No locks during VM bring-up (0 threads) and no safepoints after main\n-  \/\/ thread creation and before VMThread creation (1 thread); initial GC\n-  \/\/ verification can happen in that window which gets to here.\n-  assert(Threads::number_of_threads() <= 1 ||\n-         SafepointSynchronize::is_at_safepoint(),\n-         \"must be executed at a safepoint\");\n-  if (JvmtiEnv::environments_might_exist()) {\n-    JvmtiEnvIterator it;\n-    for (JvmtiEnvBase* env = it.first(); env != NULL; env = it.next(env)) {\n-      JvmtiTagMap* tag_map = env->tag_map_acquire();\n-      if (tag_map != NULL && !tag_map->is_empty()) {\n-        tag_map->do_weak_oops(is_alive, f);\n-      }\n+  JvmtiEnvIterator it;\n+  for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {\n+    JvmtiTagMap* tag_map = env->tag_map_acquire();\n+    if (tag_map != NULL) {\n+      tag_map->_needs_rehashing = true;\n@@ -3374,10 +3093,2 @@\n-void JvmtiTagMap::do_weak_oops(BoolObjectClosure* is_alive, OopClosure* f) {\n-\n-  \/\/ does this environment have the OBJECT_FREE event enabled\n-  bool post_object_free = env()->is_enabled(JVMTI_EVENT_OBJECT_FREE);\n-\n-  \/\/ counters used for trace message\n-  int freed = 0;\n-  int moved = 0;\n-\n-  JvmtiTagHashmap* hashmap = this->hashmap();\n+\/\/ Verify gc_notification follows set_needs_cleaning.\n+DEBUG_ONLY(static bool notified_needs_cleaning = false;)\n@@ -3385,2 +3096,6 @@\n-  \/\/ reenable sizing (if disabled)\n-  hashmap->set_resizing_enabled(true);\n+void JvmtiTagMap::set_needs_cleaning() {\n+  assert(SafepointSynchronize::is_at_safepoint(), \"called in gc pause\");\n+  assert(Thread::current()->is_VM_thread(), \"should be the VM thread\");\n+  \/\/ Can't assert !notified_needs_cleaning; a partial GC might be upgraded\n+  \/\/ to a full GC and do this twice without intervening gc_notification.\n+  DEBUG_ONLY(notified_needs_cleaning = true;)\n@@ -3388,3 +3103,6 @@\n-  \/\/ if the hashmap is empty then we can skip it\n-  if (hashmap->_entry_count == 0) {\n-    return;\n+  JvmtiEnvIterator it;\n+  for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {\n+    JvmtiTagMap* tag_map = env->tag_map_acquire();\n+    if (tag_map != NULL) {\n+      tag_map->_needs_cleaning = !tag_map->is_empty();\n+    }\n@@ -3392,0 +3110,1 @@\n+}\n@@ -3393,24 +3112,3 @@\n-  \/\/ now iterate through each entry in the table\n-\n-  JvmtiTagHashmapEntry** table = hashmap->table();\n-  int size = hashmap->size();\n-\n-  JvmtiTagHashmapEntry* delayed_add = NULL;\n-\n-  for (int pos = 0; pos < size; ++pos) {\n-    JvmtiTagHashmapEntry* entry = table[pos];\n-    JvmtiTagHashmapEntry* prev = NULL;\n-\n-    while (entry != NULL) {\n-      JvmtiTagHashmapEntry* next = entry->next();\n-\n-      \/\/ has object been GC'ed\n-      if (!is_alive->do_object_b(entry->object_raw())) {\n-        \/\/ grab the tag\n-        jlong tag = entry->tag();\n-        guarantee(tag != 0, \"checking\");\n-\n-        \/\/ remove GC'ed entry from hashmap and return the\n-        \/\/ entry to the free list\n-        hashmap->remove(prev, pos, entry);\n-        destroy_entry(entry);\n+void JvmtiTagMap::gc_notification(size_t num_dead_entries) {\n+  assert(notified_needs_cleaning, \"missing GC notification\");\n+  DEBUG_ONLY(notified_needs_cleaning = false;)\n@@ -3418,4 +3116,6 @@\n-        \/\/ post the event to the profiler\n-        if (post_object_free) {\n-          JvmtiExport::post_object_free(env(), tag);\n-        }\n+  \/\/ Notify ServiceThread if there's work to do.\n+  {\n+    MonitorLocker ml(Service_lock, Mutex::_no_safepoint_check_flag);\n+    _has_object_free_events = (num_dead_entries != 0);\n+    if (_has_object_free_events) ml.notify_all();\n+  }\n@@ -3423,28 +3123,8 @@\n-        ++freed;\n-      } else {\n-        f->do_oop(entry->object_addr());\n-        oop new_oop = entry->object_raw();\n-\n-        \/\/ if the object has moved then re-hash it and move its\n-        \/\/ entry to its new location.\n-        unsigned int new_pos = JvmtiTagHashmap::hash(new_oop, size);\n-        if (new_pos != (unsigned int)pos) {\n-          if (prev == NULL) {\n-            table[pos] = next;\n-          } else {\n-            prev->set_next(next);\n-          }\n-          if (new_pos < (unsigned int)pos) {\n-            entry->set_next(table[new_pos]);\n-            table[new_pos] = entry;\n-          } else {\n-            \/\/ Delay adding this entry to it's new position as we'd end up\n-            \/\/ hitting it again during this iteration.\n-            entry->set_next(delayed_add);\n-            delayed_add = entry;\n-          }\n-          moved++;\n-        } else {\n-          \/\/ object didn't move\n-          prev = entry;\n-        }\n+  \/\/ If no dead entries then cancel cleaning requests.\n+  if (num_dead_entries == 0) {\n+    JvmtiEnvIterator it;\n+    for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {\n+      JvmtiTagMap* tag_map = env->tag_map_acquire();\n+      if (tag_map != NULL) {\n+        MutexLocker ml (tag_map->lock(), Mutex::_no_safepoint_check_flag);\n+        tag_map->_needs_cleaning = false;\n@@ -3452,2 +3132,0 @@\n-\n-      entry = next;\n@@ -3456,0 +3134,1 @@\n+}\n@@ -3457,8 +3136,7 @@\n-  \/\/ Re-add all the entries which were kept aside\n-  while (delayed_add != NULL) {\n-    JvmtiTagHashmapEntry* next = delayed_add->next();\n-    unsigned int pos = JvmtiTagHashmap::hash(delayed_add->object_raw(), size);\n-    delayed_add->set_next(table[pos]);\n-    table[pos] = delayed_add;\n-    delayed_add = next;\n-  }\n+\/\/ Used by ServiceThread to discover there is work to do.\n+bool JvmtiTagMap::has_object_free_events_and_reset() {\n+  assert_lock_strong(Service_lock);\n+  bool result = _has_object_free_events;\n+  _has_object_free_events = false;\n+  return result;\n+}\n@@ -3466,2 +3144,11 @@\n-  log_debug(jvmti, objecttagging)(\"(%d->%d, %d freed, %d total moves)\",\n-                                  hashmap->_entry_count + freed, hashmap->_entry_count, freed, moved);\n+\/\/ Used by ServiceThread to clean up tagmaps.\n+void JvmtiTagMap::flush_all_object_free_events() {\n+  JavaThread* thread = JavaThread::current();\n+  JvmtiEnvIterator it;\n+  for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {\n+    JvmtiTagMap* tag_map = env->tag_map_acquire();\n+    if (tag_map != NULL) {\n+      tag_map->flush_object_free_events();\n+      ThreadBlockInVM tbiv(thread); \/\/ Be safepoint-polite while looping.\n+    }\n+  }\n","filename":"src\/hotspot\/share\/prims\/jvmtiTagMap.cpp","additions":291,"deletions":604,"binary":false,"changes":895,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,2 +30,0 @@\n-#include \"gc\/shared\/collectedHeap.hpp\"\n-#include \"jvmtifiles\/jvmtiEnv.hpp\"\n@@ -35,4 +33,3 @@\n-\/\/ forward references\n-class JvmtiTagHashmap;\n-class JvmtiTagHashmapEntry;\n-class JvmtiTagHashmapEntryClosure;\n+class JvmtiEnv;\n+class JvmtiTagMapTable;\n+class JvmtiTagMapEntryClosure;\n@@ -43,4 +40,0 @@\n-  enum{\n-    max_free_entries = 4096         \/\/ maximum number of free entries per env\n-  };\n-\n@@ -49,1 +42,3 @@\n-  JvmtiTagHashmap*      _hashmap;                   \/\/ the hashmap\n+  JvmtiTagMapTable*     _hashmap;                   \/\/ the hashmap for tags\n+  bool                  _needs_rehashing;\n+  bool                  _needs_cleaning;\n@@ -51,2 +46,1 @@\n-  JvmtiTagHashmapEntry* _free_entries;              \/\/ free list for this environment\n-  int _free_entries_count;                          \/\/ number of entries on the free list\n+  static bool           _has_object_free_events;\n@@ -60,1 +54,1 @@\n-  void do_weak_oops(BoolObjectClosure* is_alive, OopClosure* f);\n+  void check_hashmap(bool post_events);\n@@ -62,2 +56,2 @@\n-  \/\/ iterate over all entries in this tag map\n-  void entry_iterate(JvmtiTagHashmapEntryClosure* closure);\n+  void entry_iterate(JvmtiTagMapEntryClosure* closure);\n+  void post_dead_objects_on_vm_thread();\n@@ -71,5 +65,1 @@\n-  JvmtiTagHashmap* hashmap() { return _hashmap; }\n-\n-  \/\/ create\/destroy entries\n-  JvmtiTagHashmapEntry* create_entry(oop ref, jlong tag);\n-  void destroy_entry(JvmtiTagHashmapEntry* entry);\n+  JvmtiTagMapTable* hashmap() { return _hashmap; }\n@@ -124,2 +114,15 @@\n-  static void weak_oops_do(\n-      BoolObjectClosure* is_alive, OopClosure* f) NOT_JVMTI_RETURN;\n+\n+  void remove_dead_entries(bool post_object_free);\n+  void remove_dead_entries_locked(bool post_object_free);\n+\n+  static void check_hashmaps_for_heapwalk();\n+  static void set_needs_rehashing() NOT_JVMTI_RETURN;\n+  static void set_needs_cleaning() NOT_JVMTI_RETURN;\n+  static void gc_notification(size_t num_dead_entries) NOT_JVMTI_RETURN;\n+\n+  void flush_object_free_events();\n+  void clear();  \/\/ Clear tagmap table after the env is disposed.\n+\n+  \/\/ For ServiceThread\n+  static void flush_all_object_free_events() NOT_JVMTI_RETURN;\n+  static bool has_object_free_events_and_reset() NOT_JVMTI_RETURN_(false);\n","filename":"src\/hotspot\/share\/prims\/jvmtiTagMap.hpp","additions":27,"deletions":24,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,1 @@\n+#include \"classfile\/classLoadInfo.hpp\"\n@@ -31,0 +32,1 @@\n+#include \"classfile\/systemDictionary.hpp\"\n@@ -38,0 +40,1 @@\n+#include \"oops\/klass.inline.hpp\"\n@@ -49,0 +52,1 @@\n+#include \"runtime\/stubRoutines.hpp\"\n@@ -51,0 +55,1 @@\n+#include \"runtime\/vmOperations.hpp\"\n@@ -120,2 +125,2 @@\n-      assert(p->field_addr_raw((jint)byte_offset) == ptr_plus_disp,\n-             \"raw [ptr+disp] must be consistent with oop::field_addr_raw\");\n+      assert(p->field_addr((jint)byte_offset) == ptr_plus_disp,\n+             \"raw [ptr+disp] must be consistent with oop::field_addr\");\n@@ -133,4 +138,0 @@\n-  if (p != NULL) {\n-    p = Access<>::resolve(p);\n-  }\n-\n@@ -279,1 +280,1 @@\n-  return JNIHandles::make_local(env, v);\n+  return JNIHandles::make_local(THREAD, v);\n@@ -305,1 +306,1 @@\n-  return JNIHandles::make_local(env, v);\n+  return JNIHandles::make_local(THREAD, v);\n@@ -321,1 +322,1 @@\n-  return JNIHandles::make_local(env, v);\n+  return JNIHandles::make_local(THREAD, v);\n@@ -404,1 +405,1 @@\n-  return JNIHandles::make_local(env, i);\n+  return JNIHandles::make_local(THREAD, i);\n@@ -454,0 +455,1 @@\n+      MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXExec, thread));\n@@ -505,0 +507,1 @@\n+  MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXExec, Thread::current()));\n@@ -511,0 +514,1 @@\n+  MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXExec, Thread::current()));\n@@ -613,1 +617,1 @@\n-  return JNIHandles::make_local(env, mirror);\n+  return JNIHandles::make_local(THREAD, mirror);\n@@ -771,178 +775,0 @@\n-\/\/ define a class but do not make it known to the class loader or system dictionary\n-\/\/ - host_class:  supplies context for linkage, access control, protection domain, and class loader\n-\/\/                if host_class is itself anonymous then it is replaced with its host class.\n-\/\/ - data:  bytes of a class file, a raw memory address (length gives the number of bytes)\n-\/\/ - cp_patches:  where non-null entries exist, they replace corresponding CP entries in data\n-\n-\/\/ When you load an anonymous class U, it works as if you changed its name just before loading,\n-\/\/ to a name that you will never use again.  Since the name is lost, no other class can directly\n-\/\/ link to any member of U.  Just after U is loaded, the only way to use it is reflectively,\n-\/\/ through java.lang.Class methods like Class.newInstance.\n-\n-\/\/ The package of an anonymous class must either match its host's class's package or be in the\n-\/\/ unnamed package.  If it is in the unnamed package then it will be put in its host class's\n-\/\/ package.\n-\/\/\n-\n-\/\/ Access checks for linkage sites within U continue to follow the same rules as for named classes.\n-\/\/ An anonymous class also has special privileges to access any member of its host class.\n-\/\/ This is the main reason why this loading operation is unsafe.  The purpose of this is to\n-\/\/ allow language implementations to simulate \"open classes\"; a host class in effect gets\n-\/\/ new code when an anonymous class is loaded alongside it.  A less convenient but more\n-\/\/ standard way to do this is with reflection, which can also be set to ignore access\n-\/\/ restrictions.\n-\n-\/\/ Access into an anonymous class is possible only through reflection.  Therefore, there\n-\/\/ are no special access rules for calling into an anonymous class.  The relaxed access\n-\/\/ rule for the host class is applied in the opposite direction:  A host class reflectively\n-\/\/ access one of its anonymous classes.\n-\n-\/\/ If you load the same bytecodes twice, you get two different classes.  You can reload\n-\/\/ the same bytecodes with or without varying CP patches.\n-\n-\/\/ By using the CP patching array, you can have a new anonymous class U2 refer to an older one U1.\n-\/\/ The bytecodes for U2 should refer to U1 by a symbolic name (doesn't matter what the name is).\n-\/\/ The CONSTANT_Class entry for that name can be patched to refer directly to U1.\n-\n-\/\/ This allows, for example, U2 to use U1 as a superclass or super-interface, or as\n-\/\/ an outer class (so that U2 is an anonymous inner class of anonymous U1).\n-\/\/ It is not possible for a named class, or an older anonymous class, to refer by\n-\/\/ name (via its CP) to a newer anonymous class.\n-\n-\/\/ CP patching may also be used to modify (i.e., hack) the names of methods, classes,\n-\/\/ or type descriptors used in the loaded anonymous class.\n-\n-\/\/ Finally, CP patching may be used to introduce \"live\" objects into the constant pool,\n-\/\/ instead of \"dead\" strings.  A compiled statement like println((Object)\"hello\") can\n-\/\/ be changed to println(greeting), where greeting is an arbitrary object created before\n-\/\/ the anonymous class is loaded.  This is useful in dynamic languages, in which\n-\/\/ various kinds of metaobjects must be introduced as constants into bytecode.\n-\/\/ Note the cast (Object), which tells the verifier to expect an arbitrary object,\n-\/\/ not just a literal string.  For such ldc instructions, the verifier uses the\n-\/\/ type Object instead of String, if the loaded constant is not in fact a String.\n-\n-static InstanceKlass*\n-Unsafe_DefineAnonymousClass_impl(JNIEnv *env,\n-                                 jclass host_class, jbyteArray data, jobjectArray cp_patches_jh,\n-                                 u1** temp_alloc,\n-                                 TRAPS) {\n-  assert(host_class != NULL, \"host_class must not be NULL\");\n-  assert(data != NULL, \"data must not be NULL\");\n-\n-  if (UsePerfData) {\n-    ClassLoader::unsafe_defineClassCallCounter()->inc();\n-  }\n-\n-  jint length = typeArrayOop(JNIHandles::resolve_non_null(data))->length();\n-  assert(length >= 0, \"class_bytes_length must not be negative: %d\", length);\n-\n-  int class_bytes_length = (int) length;\n-\n-  u1* class_bytes = NEW_C_HEAP_ARRAY_RETURN_NULL(u1, length, mtInternal);\n-  if (class_bytes == NULL) {\n-    THROW_0(vmSymbols::java_lang_OutOfMemoryError());\n-  }\n-\n-  \/\/ caller responsible to free it:\n-  *temp_alloc = class_bytes;\n-\n-  ArrayAccess<>::arraycopy_to_native(arrayOop(JNIHandles::resolve_non_null(data)), typeArrayOopDesc::element_offset<jbyte>(0),\n-                                     reinterpret_cast<jbyte*>(class_bytes), length);\n-\n-  objArrayHandle cp_patches_h;\n-  if (cp_patches_jh != NULL) {\n-    oop p = JNIHandles::resolve_non_null(cp_patches_jh);\n-    assert(p->is_objArray(), \"cp_patches must be an object[]\");\n-    cp_patches_h = objArrayHandle(THREAD, (objArrayOop)p);\n-  }\n-\n-  const Klass* host_klass = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(host_class));\n-\n-  \/\/ Make sure it's the real host class, not another anonymous class.\n-  while (host_klass != NULL && host_klass->is_instance_klass() &&\n-         InstanceKlass::cast(host_klass)->is_unsafe_anonymous()) {\n-    host_klass = InstanceKlass::cast(host_klass)->unsafe_anonymous_host();\n-  }\n-\n-  \/\/ Primitive types have NULL Klass* fields in their java.lang.Class instances.\n-  if (host_klass == NULL) {\n-    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Host class is null\");\n-  }\n-\n-  assert(host_klass->is_instance_klass(), \"Host class must be an instance class\");\n-\n-  const char* host_source = host_klass->external_name();\n-  Handle      host_loader(THREAD, host_klass->class_loader());\n-  Handle      host_domain(THREAD, host_klass->protection_domain());\n-\n-  GrowableArray<Handle>* cp_patches = NULL;\n-\n-  if (cp_patches_h.not_null()) {\n-    int alen = cp_patches_h->length();\n-\n-    for (int i = alen-1; i >= 0; i--) {\n-      oop p = cp_patches_h->obj_at(i);\n-      if (p != NULL) {\n-        Handle patch(THREAD, p);\n-\n-        if (cp_patches == NULL) {\n-          cp_patches = new GrowableArray<Handle>(i+1, i+1, Handle());\n-        }\n-\n-        cp_patches->at_put(i, patch);\n-      }\n-    }\n-  }\n-\n-  ClassFileStream st(class_bytes, class_bytes_length, host_source, ClassFileStream::verify);\n-\n-  Symbol* no_class_name = NULL;\n-  ClassLoadInfo cl_info(host_domain,\n-                        InstanceKlass::cast(host_klass),\n-                        cp_patches,\n-                        NULL,     \/\/ dynamic_nest_host\n-                        Handle(), \/\/ classData\n-                        false,    \/\/ is_hidden\n-                        false,    \/\/ is_strong_hidden\n-                        true);    \/\/ can_access_vm_annotations\n-\n-  Klass* anonk = SystemDictionary::parse_stream(no_class_name,\n-                                                host_loader,\n-                                                &st,\n-                                                cl_info,\n-                                                CHECK_NULL);\n-  if (anonk == NULL) {\n-    return NULL;\n-  }\n-\n-  return InstanceKlass::cast(anonk);\n-}\n-\n-UNSAFE_ENTRY(jclass, Unsafe_DefineAnonymousClass0(JNIEnv *env, jobject unsafe, jclass host_class, jbyteArray data, jobjectArray cp_patches_jh)) {\n-  ResourceMark rm(THREAD);\n-\n-  jobject res_jh = NULL;\n-  u1* temp_alloc = NULL;\n-\n-  InstanceKlass* anon_klass = Unsafe_DefineAnonymousClass_impl(env, host_class, data, cp_patches_jh, &temp_alloc, THREAD);\n-  if (anon_klass != NULL) {\n-    res_jh = JNIHandles::make_local(env, anon_klass->java_mirror());\n-  }\n-\n-  \/\/ try\/finally clause:\n-  FREE_C_HEAP_ARRAY(u1, temp_alloc);\n-\n-  \/\/ The anonymous class loader data has been artificially been kept alive to\n-  \/\/ this point.   The mirror and any instances of this class have to keep\n-  \/\/ it alive afterwards.\n-  if (anon_klass != NULL) {\n-    anon_klass->class_loader_data()->dec_keep_alive();\n-  }\n-\n-  \/\/ let caller initialize it as needed...\n-\n-  return (jclass) res_jh;\n-} UNSAFE_END\n-\n-\n-\n@@ -987,1 +813,1 @@\n-  return JNIHandles::make_local(env, res);\n+  return JNIHandles::make_local(THREAD, res);\n@@ -1028,1 +854,0 @@\n-  GuardUnsafeAccess guard(thread);\n@@ -1042,1 +867,0 @@\n-  GuardUnsafeAccess guard(thread);\n@@ -1086,2 +910,0 @@\n-  Parker* p = NULL;\n-\n@@ -1097,1 +919,3 @@\n-        p = thr->parker();\n+        Parker* p = thr->parker();\n+        HOTSPOT_THREAD_UNPARK((uintptr_t) p);\n+        p->unpark();\n@@ -1102,7 +926,0 @@\n-  \/\/ 'p' points to type-stable-memory if non-NULL. If the target\n-  \/\/ thread terminates before we get here the new user of this\n-  \/\/ Parker will get a 'spurious' unpark - which is perfectly valid.\n-  if (p != NULL) {\n-    HOTSPOT_THREAD_UNPARK((uintptr_t) p);\n-    p->unpark();\n-  }\n@@ -1211,2 +1028,0 @@\n-    {CC \"defineAnonymousClass0\", CC \"(\" DAC_Args \")\" CLS, FN_PTR(Unsafe_DefineAnonymousClass0)},\n-\n","filename":"src\/hotspot\/share\/prims\/unsafe.cpp","additions":20,"deletions":205,"binary":false,"changes":225,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,0 +27,1 @@\n+#include \"cds\/filemap.hpp\"\n@@ -32,0 +33,1 @@\n+#include \"compiler\/compilerDefinitions.hpp\"\n@@ -34,0 +36,2 @@\n+#include \"gc\/shared\/stringdedup\/stringDedup.hpp\"\n+#include \"gc\/shared\/tlab_globals.hpp\"\n@@ -39,1 +43,0 @@\n-#include \"memory\/filemap.hpp\"\n@@ -44,2 +47,2 @@\n-#include \"runtime\/flags\/jvmFlagConstraintList.hpp\"\n-#include \"runtime\/flags\/jvmFlagRangeList.hpp\"\n+#include \"runtime\/flags\/jvmFlagAccess.hpp\"\n+#include \"runtime\/flags\/jvmFlagLimit.hpp\"\n@@ -48,1 +51,1 @@\n-#include \"runtime\/os.inline.hpp\"\n+#include \"runtime\/os.hpp\"\n@@ -86,2 +89,0 @@\n-intx   Arguments::_Tier3InvokeNotifyFreqLog     = Tier3InvokeNotifyFreqLog;\n-intx   Arguments::_Tier4InvocationThreshold     = Tier4InvocationThreshold;\n@@ -311,0 +312,2 @@\n+#define ENABLE_NATIVE_ACCESS \"enable.native.access\"\n+#define ENABLE_NATIVE_ACCESS_LEN 20\n@@ -349,1 +352,2 @@\n-        matches_property_suffix(property_suffix, UPGRADE_PATH, UPGRADE_PATH_LEN)) {\n+        matches_property_suffix(property_suffix, UPGRADE_PATH, UPGRADE_PATH_LEN) ||\n+        matches_property_suffix(property_suffix, ENABLE_NATIVE_ACCESS, ENABLE_NATIVE_ACCESS_LEN)) {\n@@ -522,1 +526,0 @@\n-  { \"UseMembar\",                    JDK_Version::jdk(10), JDK_Version::jdk(12), JDK_Version::undefined() },\n@@ -525,13 +528,12 @@\n-  { \"PrintVMQWaitTime\",             JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"UseNewFieldLayout\",            JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"ForceNUMA\",                    JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"UseBiasedLocking\",             JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"BiasedLockingStartupDelay\",    JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"PrintBiasedLockingStatistics\", JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"BiasedLockingBulkRebiasThreshold\",    JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"BiasedLockingBulkRevokeThreshold\",    JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"BiasedLockingDecayTime\",              JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"UseOptoBiasInlining\",                 JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"PrintPreciseBiasedLockingStatistics\", JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"InitialBootClassLoaderMetaspaceSize\", JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"UseLargePagesInMetaspace\",            JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n+  { \"SuspendRetryCount\",            JDK_Version::undefined(), JDK_Version::jdk(17), JDK_Version::jdk(18) },\n+  { \"SuspendRetryDelay\",            JDK_Version::undefined(), JDK_Version::jdk(17), JDK_Version::jdk(18) },\n+  { \"CriticalJNINatives\",           JDK_Version::jdk(16), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n+  { \"AlwaysLockClassLoader\",        JDK_Version::jdk(17), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n+  { \"UseBiasedLocking\",             JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n+  { \"BiasedLockingStartupDelay\",    JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n+  { \"PrintBiasedLockingStatistics\", JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n+  { \"BiasedLockingBulkRebiasThreshold\",    JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n+  { \"BiasedLockingBulkRevokeThreshold\",    JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n+  { \"BiasedLockingDecayTime\",              JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n+  { \"UseOptoBiasInlining\",                 JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n+  { \"PrintPreciseBiasedLockingStatistics\", JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n@@ -545,20 +547,4 @@\n-  { \"PermSize\",                      JDK_Version::undefined(), JDK_Version::jdk(8),  JDK_Version::undefined() },\n-  { \"MaxPermSize\",                   JDK_Version::undefined(), JDK_Version::jdk(8),  JDK_Version::undefined() },\n-  { \"SharedReadWriteSize\",           JDK_Version::undefined(), JDK_Version::jdk(10), JDK_Version::undefined() },\n-  { \"SharedReadOnlySize\",            JDK_Version::undefined(), JDK_Version::jdk(10), JDK_Version::undefined() },\n-  { \"SharedMiscDataSize\",            JDK_Version::undefined(), JDK_Version::jdk(10), JDK_Version::undefined() },\n-  { \"SharedMiscCodeSize\",            JDK_Version::undefined(), JDK_Version::jdk(10), JDK_Version::undefined() },\n-  { \"BindGCTaskThreadsToCPUs\",       JDK_Version::undefined(), JDK_Version::jdk(14), JDK_Version::jdk(16) },\n-  { \"UseGCTaskAffinity\",             JDK_Version::undefined(), JDK_Version::jdk(14), JDK_Version::jdk(16) },\n-  { \"GCTaskTimeStampEntries\",        JDK_Version::undefined(), JDK_Version::jdk(14), JDK_Version::jdk(16) },\n-  { \"G1RSetScanBlockSize\",           JDK_Version::jdk(14),     JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-  { \"UseParallelOldGC\",              JDK_Version::jdk(14),     JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-  { \"CompactFields\",                 JDK_Version::jdk(14),     JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-  { \"FieldsAllocationStyle\",         JDK_Version::jdk(14),     JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-#ifndef X86\n-  { \"UseSSE\",                        JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-#endif \/\/ !X86\n-  { \"UseAdaptiveGCBoundary\",         JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-  { \"MonitorBound\",                  JDK_Version::jdk(14),     JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-#ifdef AARCH64\n-  { \"UseBarriersForVolatile\",        JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },\n+  { \"AssertOnSuspendWaitFailure\",   JDK_Version::undefined(), JDK_Version::jdk(17), JDK_Version::jdk(18) },\n+  { \"TraceSuspendWaitFailures\",     JDK_Version::undefined(), JDK_Version::jdk(17), JDK_Version::jdk(18) },\n+#ifdef ASSERT\n+  { \"DummyObsoleteTestFlag\",        JDK_Version::undefined(), JDK_Version::jdk(17), JDK_Version::undefined() },\n@@ -566,3 +552,0 @@\n-  { \"UseLWPSynchronization\",         JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-  { \"BranchOnRegister\",              JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-  { \"LIRFillDelaySlots\",             JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },\n@@ -581,10 +564,0 @@\n-#ifndef COMPILER2\n-  \/\/ These flags were generally available, but are C2 only, now.\n-  { \"MaxInlineLevel\",               JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-  { \"MaxRecursiveInlineLevel\",      JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-  { \"InlineSmallCode\",              JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-  { \"MaxInlineSize\",                JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-  { \"FreqInlineSize\",               JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-  { \"MaxTrivialSize\",               JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-#endif\n-\n@@ -606,38 +579,0 @@\n-\/\/ NOTE: A compatibility request will be necessary for each alias to be removed.\n-static AliasedLoggingFlag const aliased_logging_flags[] = {\n-  { \"PrintSharedSpaces\",         LogLevel::Info,  true,  LOG_TAGS(cds) },\n-  { \"TraceBiasedLocking\",        LogLevel::Info,  true,  LOG_TAGS(biasedlocking) },\n-  { \"TraceClassLoading\",         LogLevel::Info,  true,  LOG_TAGS(class, load) },\n-  { \"TraceClassLoadingPreorder\", LogLevel::Debug, true,  LOG_TAGS(class, preorder) },\n-  { \"TraceClassPaths\",           LogLevel::Info,  true,  LOG_TAGS(class, path) },\n-  { \"TraceClassResolution\",      LogLevel::Debug, true,  LOG_TAGS(class, resolve) },\n-  { \"TraceClassUnloading\",       LogLevel::Info,  true,  LOG_TAGS(class, unload) },\n-  { \"TraceExceptions\",           LogLevel::Info,  true,  LOG_TAGS(exceptions) },\n-  { \"TraceInvokeDynamic\",        LogLevel::Debug, true,  LOG_TAGS(methodhandles, indy) },\n-  { \"TraceLoaderConstraints\",    LogLevel::Info,  true,  LOG_TAGS(class, loader, constraints) },\n-  { \"TraceMethodHandles\",        LogLevel::Info,  true,  LOG_TAGS(methodhandles) },\n-  { \"TraceMonitorInflation\",     LogLevel::Trace, true,  LOG_TAGS(monitorinflation) },\n-  { \"TraceSafepointCleanupTime\", LogLevel::Info,  true,  LOG_TAGS(safepoint, cleanup) },\n-  { \"TraceJVMTIObjectTagging\",   LogLevel::Debug, true,  LOG_TAGS(jvmti, objecttagging) },\n-  { \"TraceRedefineClasses\",      LogLevel::Info,  false, LOG_TAGS(redefine, class) },\n-  { \"PrintJNIResolving\",         LogLevel::Debug, true,  LOG_TAGS(jni, resolve) },\n-  { NULL,                        LogLevel::Off,   false, LOG_TAGS(_NO_TAG) }\n-};\n-\n-#ifndef PRODUCT\n-\/\/ These options are removed in jdk9. Remove this code for jdk10.\n-static AliasedFlag const removed_develop_logging_flags[] = {\n-  { \"TraceClassInitialization\",   \"-Xlog:class+init\" },\n-  { \"TraceClassLoaderData\",       \"-Xlog:class+loader+data\" },\n-  { \"TraceDefaultMethods\",        \"-Xlog:defaultmethods=debug\" },\n-  { \"TraceItables\",               \"-Xlog:itables=debug\" },\n-  { \"TraceMonitorMismatch\",       \"-Xlog:monitormismatch=info\" },\n-  { \"TraceSafepoint\",             \"-Xlog:safepoint=debug\" },\n-  { \"TraceStartupTime\",           \"-Xlog:startuptime\" },\n-  { \"TraceVMOperation\",           \"-Xlog:vmoperation=debug\" },\n-  { \"PrintVtables\",               \"-Xlog:vtables=debug\" },\n-  { \"VerboseVerification\",        \"-Xlog:verification\" },\n-  { NULL, NULL }\n-};\n-#endif \/\/PRODUCT\n-\n@@ -707,12 +642,0 @@\n-#ifndef PRODUCT\n-const char* Arguments::removed_develop_logging_flag_name(const char* name){\n-  for (size_t i = 0; removed_develop_logging_flags[i].alias_name != NULL; i++) {\n-    const AliasedFlag& flag = removed_develop_logging_flags[i];\n-    if (strcmp(flag.alias_name, name) == 0) {\n-      return flag.real_name;\n-    }\n-  }\n-  return NULL;\n-}\n-#endif \/\/ PRODUCT\n-\n@@ -891,2 +814,2 @@\n-static bool set_bool_flag(JVMFlag* flag, bool value, JVMFlag::Flags origin) {\n-  if (JVMFlag::boolAtPut(flag, &value, origin) == JVMFlag::SUCCESS) {\n+static bool set_bool_flag(JVMFlag* flag, bool value, JVMFlagOrigin origin) {\n+  if (JVMFlagAccess::set_bool(flag, &value, origin) == JVMFlag::SUCCESS) {\n@@ -899,1 +822,1 @@\n-static bool set_fp_numeric_flag(JVMFlag* flag, char* value, JVMFlag::Flags origin) {\n+static bool set_fp_numeric_flag(JVMFlag* flag, char* value, JVMFlagOrigin origin) {\n@@ -907,1 +830,1 @@\n-  if (JVMFlag::doubleAtPut(flag, &v, origin) == JVMFlag::SUCCESS) {\n+  if (JVMFlagAccess::set_double(flag, &v, origin) == JVMFlag::SUCCESS) {\n@@ -913,1 +836,1 @@\n-static bool set_numeric_flag(JVMFlag* flag, char* value, JVMFlag::Flags origin) {\n+static bool set_numeric_flag(JVMFlag* flag, char* value, JVMFlagOrigin origin) {\n@@ -939,1 +862,1 @@\n-    return JVMFlag::intAtPut(flag, &int_v, origin) == JVMFlag::SUCCESS;\n+    return JVMFlagAccess::set_int(flag, &int_v, origin) == JVMFlag::SUCCESS;\n@@ -942,1 +865,1 @@\n-    return JVMFlag::uintAtPut(flag, &uint_v, origin) == JVMFlag::SUCCESS;\n+    return JVMFlagAccess::set_uint(flag, &uint_v, origin) == JVMFlag::SUCCESS;\n@@ -948,1 +871,1 @@\n-    return JVMFlag::intxAtPut(flag, &intx_v, origin) == JVMFlag::SUCCESS;\n+    return JVMFlagAccess::set_intx(flag, &intx_v, origin) == JVMFlag::SUCCESS;\n@@ -951,1 +874,1 @@\n-    return JVMFlag::uintxAtPut(flag, &uintx_v, origin) == JVMFlag::SUCCESS;\n+    return JVMFlagAccess::set_uintx(flag, &uintx_v, origin) == JVMFlag::SUCCESS;\n@@ -954,1 +877,1 @@\n-    return JVMFlag::uint64_tAtPut(flag, &uint64_t_v, origin) == JVMFlag::SUCCESS;\n+    return JVMFlagAccess::set_uint64_t(flag, &uint64_t_v, origin) == JVMFlag::SUCCESS;\n@@ -957,1 +880,1 @@\n-    return JVMFlag::size_tAtPut(flag, &size_t_v, origin) == JVMFlag::SUCCESS;\n+    return JVMFlagAccess::set_size_t(flag, &size_t_v, origin) == JVMFlag::SUCCESS;\n@@ -960,1 +883,1 @@\n-    return JVMFlag::doubleAtPut(flag, &double_v, origin) == JVMFlag::SUCCESS;\n+    return JVMFlagAccess::set_double(flag, &double_v, origin) == JVMFlag::SUCCESS;\n@@ -966,2 +889,2 @@\n-static bool set_string_flag(JVMFlag* flag, const char* value, JVMFlag::Flags origin) {\n-  if (JVMFlag::ccstrAtPut(flag, &value, origin) != JVMFlag::SUCCESS) return false;\n+static bool set_string_flag(JVMFlag* flag, const char* value, JVMFlagOrigin origin) {\n+  if (JVMFlagAccess::set_ccstr(flag, &value, origin) != JVMFlag::SUCCESS) return false;\n@@ -973,1 +896,1 @@\n-static bool append_to_string_flag(JVMFlag* flag, const char* new_value, JVMFlag::Flags origin) {\n+static bool append_to_string_flag(JVMFlag* flag, const char* new_value, JVMFlagOrigin origin) {\n@@ -975,1 +898,1 @@\n-  if (JVMFlag::ccstrAt(flag, &old_value) != JVMFlag::SUCCESS) return false;\n+  if (JVMFlagAccess::get_ccstr(flag, &old_value) != JVMFlag::SUCCESS) return false;\n@@ -992,1 +915,1 @@\n-  (void) JVMFlag::ccstrAtPut(flag, &value, origin);\n+  (void) JVMFlagAccess::set_ccstr(flag, &value, origin);\n@@ -1036,39 +959,1 @@\n-void log_deprecated_flag(const char* name, bool on, AliasedLoggingFlag alf) {\n-  LogTagType tagSet[] = {alf.tag0, alf.tag1, alf.tag2, alf.tag3, alf.tag4, alf.tag5};\n-  \/\/ Set tagset string buffer at max size of 256, large enough for any alias tagset\n-  const int max_tagset_size = 256;\n-  int max_tagset_len = max_tagset_size - 1;\n-  char tagset_buffer[max_tagset_size];\n-  tagset_buffer[0] = '\\0';\n-\n-  \/\/ Write tag-set for aliased logging option, in string list form\n-  int max_tags = sizeof(tagSet)\/sizeof(tagSet[0]);\n-  for (int i = 0; i < max_tags && tagSet[i] != LogTag::__NO_TAG; i++) {\n-    if (i > 0) {\n-      strncat(tagset_buffer, \"+\", max_tagset_len - strlen(tagset_buffer));\n-    }\n-    strncat(tagset_buffer, LogTag::name(tagSet[i]), max_tagset_len - strlen(tagset_buffer));\n-  }\n-  if (!alf.exactMatch) {\n-      strncat(tagset_buffer, \"*\", max_tagset_len - strlen(tagset_buffer));\n-  }\n-  log_warning(arguments)(\"-XX:%s%s is deprecated. Will use -Xlog:%s=%s instead.\",\n-                         (on) ? \"+\" : \"-\",\n-                         name,\n-                         tagset_buffer,\n-                         (on) ? LogLevel::name(alf.level) : \"off\");\n-}\n-\n-AliasedLoggingFlag Arguments::catch_logging_aliases(const char* name, bool on){\n-  for (size_t i = 0; aliased_logging_flags[i].alias_name != NULL; i++) {\n-    const AliasedLoggingFlag& alf = aliased_logging_flags[i];\n-    if (strcmp(alf.alias_name, name) == 0) {\n-      log_deprecated_flag(name, on, alf);\n-      return alf;\n-    }\n-  }\n-  AliasedLoggingFlag a = {NULL, LogLevel::Off, false, LOG_TAGS(_NO_TAG)};\n-  return a;\n-}\n-\n-bool Arguments::parse_argument(const char* arg, JVMFlag::Flags origin) {\n+bool Arguments::parse_argument(const char* arg, JVMFlagOrigin origin) {\n@@ -1085,5 +970,0 @@\n-    AliasedLoggingFlag alf = catch_logging_aliases(name, false);\n-    if (alf.alias_name != NULL){\n-      LogConfiguration::configure_stdout(LogLevel::Off, alf.exactMatch, alf.tag0, alf.tag1, alf.tag2, alf.tag3, alf.tag4, alf.tag5);\n-      return true;\n-    }\n@@ -1098,5 +978,0 @@\n-    AliasedLoggingFlag alf = catch_logging_aliases(name, true);\n-    if (alf.alias_name != NULL){\n-      LogConfiguration::configure_stdout(alf.level, alf.exactMatch, alf.tag0, alf.tag1, alf.tag2, alf.tag3, alf.tag4, alf.tag5);\n-      return true;\n-    }\n@@ -1116,5 +991,0 @@\n-    AliasedLoggingFlag alf = catch_logging_aliases(name, true);\n-    if (alf.alias_name != NULL) {\n-      LogConfiguration::configure_stdout(alf.level, alf.exactMatch, alf.tag0, alf.tag1, alf.tag2, alf.tag3, alf.tag4, alf.tag5);\n-      return true;\n-    }\n@@ -1289,1 +1159,1 @@\n-                                 JVMFlag::Flags origin) {\n+                                 JVMFlagOrigin origin) {\n@@ -1319,11 +1189,0 @@\n-#ifndef PRODUCT\n-    else {\n-      const char* replacement;\n-      if ((replacement = removed_develop_logging_flag_name(stripped_argname)) != NULL){\n-        log_warning(arguments)(\"%s has been removed. Please use %s instead.\",\n-                               stripped_argname,\n-                               replacement);\n-        return false;\n-      }\n-    }\n-#endif \/\/PRODUCT\n@@ -1370,1 +1229,1 @@\n-                  fuzzy_matched->_name,\n+                  fuzzy_matched->name(),\n@@ -1418,1 +1277,1 @@\n-        result &= process_argument(token, ignore_unrecognized, JVMFlag::CONFIG_FILE);\n+        result &= process_argument(token, ignore_unrecognized, JVMFlagOrigin::CONFIG_FILE);\n@@ -1436,1 +1295,1 @@\n-    result &= process_argument(token, ignore_unrecognized, JVMFlag::CONFIG_FILE);\n+    result &= process_argument(token, ignore_unrecognized, JVMFlagOrigin::CONFIG_FILE);\n@@ -1474,1 +1333,7 @@\n-    log_info(cds)(\"Using optimized module handling disabled due to incompatible property: %s=%s\", key, value);\n+    log_info(cds)(\"optimized module handling: disabled due to incompatible property: %s=%s\", key, value);\n+  }\n+  if (strcmp(key, \"jdk.module.showModuleResolution\") == 0 ||\n+      strcmp(key, \"jdk.module.validation\") == 0 ||\n+      strcmp(key, \"java.system.class.loader\") == 0) {\n+    MetaspaceShared::disable_full_module_graph();\n+    log_info(cds)(\"full module graph: disabled due to incompatible property: %s=%s\", key, value);\n@@ -1601,8 +1466,0 @@\n-  if (TieredCompilation) {\n-    if (FLAG_IS_DEFAULT(Tier3InvokeNotifyFreqLog)) {\n-      Tier3InvokeNotifyFreqLog = Arguments::_Tier3InvokeNotifyFreqLog;\n-    }\n-    if (FLAG_IS_DEFAULT(Tier4InvocationThreshold)) {\n-      Tier4InvocationThreshold = Arguments::_Tier4InvocationThreshold;\n-    }\n-  }\n@@ -1628,7 +1485,0 @@\n-    \/\/ Be much more aggressive in tiered mode with -Xcomp and exercise C2 more.\n-    \/\/ We will first compile a level 3 version (C1 with full profiling), then do one invocation of it and\n-    \/\/ compile a level 4 (C2) and then continue executing it.\n-    if (TieredCompilation) {\n-      Tier3InvokeNotifyFreqLog = 0;\n-      Tier4InvocationThreshold = 0;\n-    }\n@@ -1666,4 +1516,0 @@\n-\n-  if (SurvivorAlignmentInBytes == 0) {\n-    SurvivorAlignmentInBytes = ObjectAlignmentInBytes;\n-  }\n@@ -1687,1 +1533,0 @@\n-#ifndef ZERO\n@@ -1708,1 +1553,0 @@\n-#endif \/\/ ZERO\n@@ -1715,1 +1559,0 @@\n-#ifndef ZERO\n@@ -1743,1 +1586,0 @@\n-#endif \/\/ !ZERO\n@@ -1762,1 +1604,0 @@\n-#ifndef ZERO\n@@ -1773,1 +1614,0 @@\n-#endif \/\/ !ZERO\n@@ -1778,3 +1618,3 @@\n-julong Arguments::limit_by_allocatable_memory(julong limit) {\n-  julong max_allocatable;\n-  julong result = limit;\n+size_t Arguments::limit_heap_by_allocatable_memory(size_t limit) {\n+  size_t max_allocatable;\n+  size_t result = limit;\n@@ -1782,1 +1622,8 @@\n-    result = MIN2(result, max_allocatable \/ MaxVirtMemFraction);\n+    \/\/ The AggressiveHeap check is a temporary workaround to avoid calling\n+    \/\/ GCarguments::heap_virtual_to_physical_ratio() before a GC has been\n+    \/\/ selected. This works because AggressiveHeap implies UseParallelGC\n+    \/\/ where we know the ratio will be 1. Once the AggressiveHeap option is\n+    \/\/ removed, this can be cleaned up.\n+    size_t heap_virtual_to_physical_ratio = (AggressiveHeap ? 1 : GCConfig::arguments()->heap_virtual_to_physical_ratio());\n+    size_t fraction = MaxVirtMemFraction * heap_virtual_to_physical_ratio;\n+    result = MIN2(result, max_allocatable \/ fraction);\n@@ -1898,1 +1745,1 @@\n-    reasonable_max = limit_by_allocatable_memory(reasonable_max);\n+    reasonable_max = limit_heap_by_allocatable_memory(reasonable_max);\n@@ -1903,1 +1750,1 @@\n-      \/\/ after call to limit_by_allocatable_memory because that\n+      \/\/ after call to limit_heap_by_allocatable_memory because that\n@@ -1921,1 +1768,1 @@\n-    reasonable_minimum = limit_by_allocatable_memory(reasonable_minimum);\n+    reasonable_minimum = limit_heap_by_allocatable_memory(reasonable_minimum);\n@@ -1925,0 +1772,1 @@\n+      reasonable_initial = limit_heap_by_allocatable_memory(reasonable_initial);\n@@ -1929,2 +1777,0 @@\n-      reasonable_initial = limit_by_allocatable_memory(reasonable_initial);\n-\n@@ -1970,1 +1816,1 @@\n-  initHeapSize = limit_by_allocatable_memory(initHeapSize);\n+  initHeapSize = limit_heap_by_allocatable_memory(initHeapSize);\n@@ -2124,0 +1970,1 @@\n+unsigned int enable_native_access_count = 0;\n@@ -2170,2 +2017,0 @@\n-  status = status && GCArguments::check_args_consistency();\n-\n@@ -2222,2 +2067,1 @@\n-  assert(is_internal_module_property(prop_name) ||\n-         strcmp(prop_name, \"jdk.module.illegalAccess\") == 0, \"unknown module property: '%s'\", prop_name);\n+  assert(is_internal_module_property(prop_name), \"unknown module property: '%s'\", prop_name);\n@@ -2287,4 +2131,0 @@\n-  if (TieredCompilation) {\n-    Arguments::_Tier3InvokeNotifyFreqLog = Tier3InvokeNotifyFreqLog;\n-    Arguments::_Tier4InvocationThreshold = Tier4InvocationThreshold;\n-  }\n@@ -2299,1 +2139,1 @@\n-  jint result = parse_each_vm_init_arg(vm_options_args, &patch_mod_javabase, JVMFlag::JIMAGE_RESOURCE);\n+  jint result = parse_each_vm_init_arg(vm_options_args, &patch_mod_javabase, JVMFlagOrigin::JIMAGE_RESOURCE);\n@@ -2306,1 +2146,1 @@\n-  result = parse_each_vm_init_arg(java_tool_options_args, &patch_mod_javabase, JVMFlag::ENVIRON_VAR);\n+  result = parse_each_vm_init_arg(java_tool_options_args, &patch_mod_javabase, JVMFlagOrigin::ENVIRON_VAR);\n@@ -2312,1 +2152,1 @@\n-  result = parse_each_vm_init_arg(cmd_line_args, &patch_mod_javabase, JVMFlag::COMMAND_LINE);\n+  result = parse_each_vm_init_arg(cmd_line_args, &patch_mod_javabase, JVMFlagOrigin::COMMAND_LINE);\n@@ -2319,1 +2159,1 @@\n-  result = parse_each_vm_init_arg(java_options_args, &patch_mod_javabase, JVMFlag::ENVIRON_VAR);\n+  result = parse_each_vm_init_arg(java_options_args, &patch_mod_javabase, JVMFlagOrigin::ENVIRON_VAR);\n@@ -2424,0 +2264,5 @@\n+  \/\/ Make sure the above values match the range set in globals.hpp\n+  const JVMTypedFlagLimit<intx>* limit = JVMFlagLimit::get_range_at(FLAG_MEMBER_ENUM(ThreadStackSize))->cast<intx>();\n+  assert(min_ThreadStackSize == static_cast<julong>(limit->min()), \"must be\");\n+  assert(max_ThreadStackSize == static_cast<julong>(limit->max()), \"must be\");\n+\n@@ -2463,1 +2308,1 @@\n-jint Arguments::parse_each_vm_init_arg(const JavaVMInitArgs* args, bool* patch_mod_javabase, JVMFlag::Flags origin) {\n+jint Arguments::parse_each_vm_init_arg(const JavaVMInitArgs* args, bool* patch_mod_javabase, JVMFlagOrigin origin) {\n@@ -2523,1 +2368,1 @@\n-      log_info(cds)(\"Using optimized module handling disabled due to bootclasspath was appended\");\n+      log_info(cds)(\"optimized module handling: disabled because bootclasspath was appended\");\n@@ -2568,0 +2413,4 @@\n+    } else if (match_option(option, \"--enable-native-access=\", &tail)) {\n+      if (!create_numbered_module_property(\"jdk.module.enable.native.access\", tail, enable_native_access_count++)) {\n+        return JNI_ENOMEM;\n+      }\n@@ -2587,3 +2436,3 @@\n-      if (!create_module_property(\"jdk.module.illegalAccess\", tail, ExternalProperty)) {\n-        return JNI_ENOMEM;\n-      }\n+      char version[256];\n+      JDK_Version::jdk(17).to_string(version, sizeof(version));\n+      warning(\"Ignoring option %s; support was removed in %s\", option->optionString, version);\n@@ -2907,0 +2756,3 @@\n+      } else if (strcmp(tail, \":async\") == 0) {\n+        LogConfiguration::set_async_mode(true);\n+        ret = true;\n@@ -3127,1 +2979,1 @@\n-    _patch_mod_prefix = new (ResourceObj::C_HEAP, mtArguments) GrowableArray<ModulePatchPath*>(10, true);\n+    _patch_mod_prefix = new (ResourceObj::C_HEAP, mtArguments) GrowableArray<ModulePatchPath*>(10, mtArguments);\n@@ -3224,0 +3076,5 @@\n+#ifdef ZERO\n+  \/\/ Zero always runs in interpreted mode\n+  set_mode_flags(_int);\n+#endif\n+\n@@ -3240,1 +3097,0 @@\n-  NOT_PRODUCT(UNSUPPORTED_OPTION(TraceProfileInterpreter));\n@@ -3243,2 +3099,0 @@\n-\n-#ifdef TIERED\n@@ -3249,4 +3103,0 @@\n-#else\n-  \/\/ Tiered compilation is undefined.\n-  UNSUPPORTED_OPTION(TieredCompilation);\n-#endif\n@@ -3280,1 +3130,8 @@\n-  if (ArchiveClassesAtExit == NULL) {\n+\n+  \/\/ RecordDynamicDumpInfo is not compatible with ArchiveClassesAtExit\n+  if (ArchiveClassesAtExit != NULL && RecordDynamicDumpInfo) {\n+    log_info(cds)(\"RecordDynamicDumpInfo is for jcmd only, could not set with -XX:ArchiveClassesAtExit.\");\n+    return JNI_ERR;\n+  }\n+\n+  if (ArchiveClassesAtExit == NULL && !RecordDynamicDumpInfo) {\n@@ -3282,0 +3139,2 @@\n+  } else {\n+    FLAG_SET_DEFAULT(DynamicDumpSharedSpaces, true);\n@@ -3283,0 +3142,1 @@\n+\n@@ -3324,1 +3184,1 @@\n-  jint set_args(GrowableArray<JavaVMOption>* options) {\n+  jint set_args(const GrowableArrayView<JavaVMOption>* options) {\n@@ -3382,2 +3242,2 @@\n-    GrowableArray<JavaVMOption> *options = new (ResourceObj::C_HEAP, mtArguments)\n-              GrowableArray<JavaVMOption>(length, true);    \/\/ Construct new option array\n+    \/\/ Construct new option array\n+    GrowableArrayCHeap<JavaVMOption, mtArguments> options(length);\n@@ -3389,1 +3249,1 @@\n-          options->push(args_to_insert->options[j]);\n+          options.push(args_to_insert->options[j]);\n@@ -3392,1 +3252,1 @@\n-        options->push(args->options[i]);\n+        options.push(args->options[i]);\n@@ -3396,3 +3256,1 @@\n-    jint result = set_args(options);\n-    delete options;\n-    return result;\n+    return set_args(&options);\n@@ -3495,1 +3353,2 @@\n-  GrowableArray<JavaVMOption> *options = new (ResourceObj::C_HEAP, mtArguments) GrowableArray<JavaVMOption>(2, true);    \/\/ Construct option array\n+  \/\/ Construct option array\n+  GrowableArrayCHeap<JavaVMOption, mtArguments> options(2);\n@@ -3535,1 +3394,0 @@\n-          delete options;\n@@ -3551,1 +3409,1 @@\n-    options->append(option);                \/\/ Fill in option\n+    options.append(option);                \/\/ Fill in option\n@@ -3557,4 +3415,1 @@\n-  jint status = vm_args->set_args(options);\n-\n-  delete options;\n-  return status;\n+  return vm_args->set_args(&options);\n@@ -3594,1 +3449,1 @@\n-               UseCompressedOops ? \"%s%sclasses.jsa\": \"%s%sclasses_nocoops.jsa\",\n+               LP64_ONLY(!UseCompressedOops ? \"%s%sclasses_nocoops.jsa\":) \"%s%sclasses.jsa\",\n@@ -3653,0 +3508,5 @@\n+  } else {\n+    if (SharedDynamicArchivePath != nullptr) {\n+      os::free(SharedDynamicArchivePath);\n+      SharedDynamicArchivePath = nullptr;\n+    }\n@@ -3914,0 +3774,20 @@\n+static void apply_debugger_ergo() {\n+  if (ReplayCompiles) {\n+    FLAG_SET_ERGO_IF_DEFAULT(UseDebuggerErgo, true);\n+  }\n+\n+  if (UseDebuggerErgo) {\n+    \/\/ Turn on sub-flags\n+    FLAG_SET_ERGO_IF_DEFAULT(UseDebuggerErgo1, true);\n+    FLAG_SET_ERGO_IF_DEFAULT(UseDebuggerErgo2, true);\n+  }\n+\n+  if (UseDebuggerErgo2) {\n+    \/\/ Debugging with limited number of CPUs\n+    FLAG_SET_ERGO_IF_DEFAULT(UseNUMA, false);\n+    FLAG_SET_ERGO_IF_DEFAULT(ConcGCThreads, 1);\n+    FLAG_SET_ERGO_IF_DEFAULT(ParallelGCThreads, 1);\n+    FLAG_SET_ERGO_IF_DEFAULT(CICompilerCount, 2);\n+  }\n+}\n+\n@@ -3918,4 +3798,1 @@\n-\n-  \/\/ Initialize ranges and constraints\n-  JVMFlagRangeList::init();\n-  JVMFlagConstraintList::init();\n+  JVMFlag::check_all_flag_declarations();\n@@ -4058,1 +3935,0 @@\n-  UNSUPPORTED_OPTION_NULL(AllocateOldGenAt);\n@@ -4107,3 +3983,4 @@\n-#ifndef TIERED\n-  if (FLAG_IS_CMDLINE(CompilationMode)) {\n-    warning(\"CompilationMode has no effect in non-tiered VMs\");\n+  if (TraceDependencies && VerifyDependencies) {\n+    if (!FLAG_IS_DEFAULT(TraceDependencies)) {\n+      warning(\"TraceDependencies results may be inflated by VerifyDependencies\");\n+    }\n@@ -4111,1 +3988,2 @@\n-#endif\n+\n+  apply_debugger_ergo();\n@@ -4144,0 +4022,4 @@\n+  if (!StringDedup::ergo_initialize()) {\n+    return JNI_EINVAL;\n+  }\n+\n@@ -4177,1 +4059,1 @@\n-#ifdef CC_INTERP\n+#ifdef ZERO\n@@ -4181,3 +4063,1 @@\n-  LP64_ONLY(FLAG_SET_DEFAULT(UseCompressedOops, false));\n-  LP64_ONLY(FLAG_SET_DEFAULT(UseCompressedClassPointers, false));\n-#endif \/\/ CC_INTERP\n+#endif \/\/ ZERO\n@@ -4224,1 +4104,27 @@\n-#endif\n+  if (!FLAG_IS_DEFAULT(EnableVectorSupport) && !EnableVectorSupport) {\n+    if (!FLAG_IS_DEFAULT(EnableVectorReboxing) && EnableVectorReboxing) {\n+      warning(\"Disabling EnableVectorReboxing since EnableVectorSupport is turned off.\");\n+    }\n+    FLAG_SET_DEFAULT(EnableVectorReboxing, false);\n+\n+    if (!FLAG_IS_DEFAULT(EnableVectorAggressiveReboxing) && EnableVectorAggressiveReboxing) {\n+      if (!EnableVectorReboxing) {\n+        warning(\"Disabling EnableVectorAggressiveReboxing since EnableVectorReboxing is turned off.\");\n+      } else {\n+        warning(\"Disabling EnableVectorAggressiveReboxing since EnableVectorSupport is turned off.\");\n+      }\n+    }\n+    FLAG_SET_DEFAULT(EnableVectorAggressiveReboxing, false);\n+\n+    if (!FLAG_IS_DEFAULT(UseVectorStubs) && UseVectorStubs) {\n+      warning(\"Disabling UseVectorStubs since EnableVectorSupport is turned off.\");\n+    }\n+    FLAG_SET_DEFAULT(UseVectorStubs, false);\n+  }\n+#endif \/\/ COMPILER2\n+\n+  if (FLAG_IS_CMDLINE(DiagnoseSyncOnValueBasedClasses)) {\n+    if (DiagnoseSyncOnValueBasedClasses == ObjectSynchronizer::LOG_WARNING && !log_is_enabled(Info, valuebasedclasses)) {\n+      LogConfiguration::configure_stdout(LogLevel::Info, true, LOG_TAGS(valuebasedclasses));\n+    }\n+  }\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":189,"deletions":283,"binary":false,"changes":472,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,2 +28,1 @@\n-#include \"compiler\/compiler_globals.hpp\"\n-#include \"gc\/shared\/gc_globals.hpp\"\n+#include \"compiler\/compiler_globals_pd.hpp\"\n@@ -41,0 +40,10 @@\n+\/\/ develop_pd\/product_pd flags are the same as develop\/product, except that their default values\n+\/\/ are specified in platform-dependent header files.\n+\n+\/\/ Flags must be declared with the following number of parameters:\n+\/\/ non-pd flags:\n+\/\/    (type, name, default_value, doc), or\n+\/\/    (type, name, default_value, extra_attrs, doc)\n+\/\/ pd flags:\n+\/\/    (type, name, doc), or\n+\/\/    (type, name, extra_attrs, doc)\n@@ -47,9 +56,13 @@\n-\/\/ Note: Diagnostic options not meant for VM tuning or for product modes.\n-\/\/ They are to be used for VM quality assurance or field diagnosis\n-\/\/ of VM bugs.  They are hidden so that users will not be encouraged to\n-\/\/ try them as if they were VM ordinary execution options.  However, they\n-\/\/ are available in the product version of the VM.  Under instruction\n-\/\/ from support engineers, VM customers can turn them on to collect\n-\/\/ diagnostic information about VM problems.  To use a VM diagnostic\n-\/\/ option, you must first specify +UnlockDiagnosticVMOptions.\n-\/\/ (This master switch also affects the behavior of -Xprintflags.)\n+\/\/ The optional extra_attrs parameter may have one of the following values:\n+\/\/ DIAGNOSTIC, EXPERIMENTAL, or MANAGEABLE. Currently extra_attrs can be used\n+\/\/ only with product\/product_pd flags.\n+\/\/\n+\/\/ DIAGNOSTIC options are not meant for VM tuning or for product modes.\n+\/\/    They are to be used for VM quality assurance or field diagnosis\n+\/\/    of VM bugs.  They are hidden so that users will not be encouraged to\n+\/\/    try them as if they were VM ordinary execution options.  However, they\n+\/\/    are available in the product version of the VM.  Under instruction\n+\/\/    from support engineers, VM customers can turn them on to collect\n+\/\/    diagnostic information about VM problems.  To use a VM diagnostic\n+\/\/    option, you must first specify +UnlockDiagnosticVMOptions.\n+\/\/    (This master switch also affects the behavior of -Xprintflags.)\n@@ -57,1 +70,1 @@\n-\/\/ experimental flags are in support of features that are not\n+\/\/ EXPERIMENTAL flags are in support of features that are not\n@@ -73,1 +86,1 @@\n-\/\/ manageable flags are writeable external product flags.\n+\/\/ MANAGEABLE flags are writeable external product flags.\n@@ -87,14 +100,1 @@\n-\/\/ product_rw flags are writeable internal product flags.\n-\/\/    They are like \"manageable\" flags but for internal\/private use.\n-\/\/    The list of product_rw flags are internal\/private flags which\n-\/\/    may be changed\/removed in a future release.  It can be set\n-\/\/    through the management interface to get\/set value\n-\/\/    when the name of flag is supplied.\n-\/\/\n-\/\/    A flag can be made as \"product_rw\" only if\n-\/\/    - the VM implementation supports dynamic setting of the flag.\n-\/\/      This implies that the VM must *always* query the flag variable\n-\/\/      and not reuse state related to the flag state at any given time.\n-\/\/\n-\/\/ Note that when there is a need to support develop flags to be writeable,\n-\/\/ it can be done in the same way as product_rw.\n+\n@@ -103,1 +103,1 @@\n-\/\/    checking code if provided - see jvmFlagRangeList.hpp\n+\/\/    checking code if provided - see jvmFlagLimit.hpp\n@@ -106,1 +106,1 @@\n-\/\/    for constraint checking if provided - see jvmFlagConstraintList.hpp\n+\/\/    for constraint checking if provided - see jvmFlagLimit.hpp\n@@ -115,15 +115,10 @@\n-#define RUNTIME_FLAGS(develop, \\\n-                      develop_pd, \\\n-                      product, \\\n-                      product_pd, \\\n-                      diagnostic, \\\n-                      diagnostic_pd, \\\n-                      experimental, \\\n-                      notproduct, \\\n-                      manageable, \\\n-                      product_rw, \\\n-                      lp64_product, \\\n-                      range, \\\n-                      constraint) \\\n-                                                                            \\\n-  lp64_product(bool, UseCompressedOops, false,                              \\\n+#ifdef _LP64\n+#define LP64_RUNTIME_FLAGS(develop,                                         \\\n+                           develop_pd,                                      \\\n+                           product,                                         \\\n+                           product_pd,                                      \\\n+                           notproduct,                                      \\\n+                           range,                                           \\\n+                           constraint)                                      \\\n+                                                                            \\\n+  product(bool, UseCompressedOops, false,                                   \\\n@@ -133,1 +128,1 @@\n-  lp64_product(bool, UseCompressedClassPointers, false,                     \\\n+  product(bool, UseCompressedClassPointers, false,                          \\\n@@ -137,0 +132,29 @@\n+  product(intx, ObjectAlignmentInBytes, 8,                                  \\\n+          \"Default object alignment in bytes, 8 is minimum\")                \\\n+          range(8, 256)                                                     \\\n+          constraint(ObjectAlignmentInBytesConstraintFunc, AtParse)\n+\n+#else\n+\/\/ !_LP64\n+\n+#define LP64_RUNTIME_FLAGS(develop,                                         \\\n+                           develop_pd,                                      \\\n+                           product,                                         \\\n+                           product_pd,                                      \\\n+                           notproduct,                                      \\\n+                           range,                                           \\\n+                           constraint)\n+const bool UseCompressedOops = false;\n+const bool UseCompressedClassPointers = false;\n+const intx ObjectAlignmentInBytes = 8;\n+\n+#endif \/\/ _LP64\n+\n+#define RUNTIME_FLAGS(develop,                                              \\\n+                      develop_pd,                                           \\\n+                      product,                                              \\\n+                      product_pd,                                           \\\n+                      notproduct,                                           \\\n+                      range,                                                \\\n+                      constraint)                                           \\\n+                                                                            \\\n@@ -146,9 +170,1 @@\n-  lp64_product(intx, ObjectAlignmentInBytes, 8,                             \\\n-          \"Default object alignment in bytes, 8 is minimum\")                \\\n-          range(8, 256)                                                     \\\n-          constraint(ObjectAlignmentInBytesConstraintFunc,AtParse)          \\\n-                                                                            \\\n-  develop(bool, CleanChunkPoolAsync, true,                                  \\\n-          \"Clean the chunk pool asynchronously\")                            \\\n-                                                                            \\\n-  diagnostic(uint, HandshakeTimeout, 0,                                     \\\n+  product(uint, HandshakeTimeout, 0, DIAGNOSTIC,                            \\\n@@ -157,1 +173,1 @@\n-  experimental(bool, AlwaysSafeConstructors, false,                         \\\n+  product(bool, AlwaysSafeConstructors, false, EXPERIMENTAL,                \\\n@@ -160,1 +176,1 @@\n-  diagnostic(bool, UnlockDiagnosticVMOptions, trueInDebug,                  \\\n+  product(bool, UnlockDiagnosticVMOptions, trueInDebug, DIAGNOSTIC,         \\\n@@ -163,1 +179,1 @@\n-  experimental(bool, UnlockExperimentalVMOptions, false,                    \\\n+  product(bool, UnlockExperimentalVMOptions, false, EXPERIMENTAL,           \\\n@@ -168,1 +184,1 @@\n-          \"Print information about Java monitor locks when the stacks are\"  \\\n+          \"Print information about Java monitor locks when the stacks are \" \\\n@@ -180,4 +196,0 @@\n-  product(bool, UseLargePagesInMetaspace, false,                            \\\n-          \"(Deprecated) Use large page memory in metaspace. \"               \\\n-          \"Only used if UseLargePages is enabled.\")                         \\\n-                                                                            \\\n@@ -192,4 +204,1 @@\n-          range(os::vm_allocation_granularity(), NOT_LP64(2*G) LP64_ONLY(8192*G)) \\\n-                                                                            \\\n-  product(bool, ForceNUMA, false,                                           \\\n-          \"(Deprecated) Force NUMA optimizations on single-node\/UMA systems\") \\\n+          constraint(NUMAInterleaveGranularityConstraintFunc, AtParse)      \\\n@@ -226,1 +235,1 @@\n-  diagnostic(bool, UseGHASHIntrinsics, false,                               \\\n+  product(bool, UseGHASHIntrinsics, false, DIAGNOSTIC,                      \\\n@@ -233,1 +242,2 @@\n-          \"Large page size (0 to let VM choose the page size)\")             \\\n+          \"Maximum large page size used (0 will use the default large \"     \\\n+          \"page size for the environment as the maximum)\")                  \\\n@@ -249,4 +259,1 @@\n-  develop(bool, TraceLongCompiles, false,                                   \\\n-          \"Print out every time compilation is longer than \"                \\\n-          \"a given threshold\")                                              \\\n-  diagnostic(bool, SafepointALot, false,                                    \\\n+  product(bool, SafepointALot, false, DIAGNOSTIC,                           \\\n@@ -257,1 +264,1 @@\n-  diagnostic(bool, HandshakeALot, false,                                    \\\n+  product(bool, HandshakeALot, false, DIAGNOSTIC,                           \\\n@@ -265,3 +272,0 @@\n-  product(bool, PrintVMQWaitTime, false,                                    \\\n-          \"(Deprecated) Print out the waiting time in VM operation queue\")  \\\n-                                                                            \\\n@@ -274,1 +278,1 @@\n-  diagnostic(bool, ForceUnreachable, false,                                 \\\n+  product(bool, ForceUnreachable, false, DIAGNOSTIC,                        \\\n@@ -278,4 +282,0 @@\n-  notproduct(bool, StressDerivedPointers, false,                            \\\n-          \"Force scavenge when a derived pointer is detected on stack \"     \\\n-          \"after rtm call\")                                                 \\\n-                                                                            \\\n@@ -294,1 +294,1 @@\n-  diagnostic(bool, InlineArrayCopy, true,                                   \\\n+  product(bool, InlineArrayCopy, true, DIAGNOSTIC,                          \\\n@@ -298,1 +298,1 @@\n-  diagnostic(bool, InlineObjectHash, true,                                  \\\n+  product(bool, InlineObjectHash, true, DIAGNOSTIC,                         \\\n@@ -302,1 +302,1 @@\n-  diagnostic(bool, InlineNatives, true,                                     \\\n+  product(bool, InlineNatives, true, DIAGNOSTIC,                            \\\n@@ -305,1 +305,1 @@\n-  diagnostic(bool, InlineMathNatives, true,                                 \\\n+  product(bool, InlineMathNatives, true, DIAGNOSTIC,                        \\\n@@ -308,1 +308,1 @@\n-  diagnostic(bool, InlineClassNatives, true,                                \\\n+  product(bool, InlineClassNatives, true, DIAGNOSTIC,                       \\\n@@ -311,1 +311,1 @@\n-  diagnostic(bool, InlineThreadNatives, true,                               \\\n+  product(bool, InlineThreadNatives, true, DIAGNOSTIC,                      \\\n@@ -314,1 +314,1 @@\n-  diagnostic(bool, InlineUnsafeOps, true,                                   \\\n+  product(bool, InlineUnsafeOps, true, DIAGNOSTIC,                          \\\n@@ -317,2 +317,2 @@\n-  product(bool, CriticalJNINatives, true,                                   \\\n-          \"Check for critical JNI entry points\")                            \\\n+  product(bool, CriticalJNINatives, false,                                  \\\n+          \"(Deprecated) Check for critical JNI entry points\")               \\\n@@ -320,4 +320,1 @@\n-  notproduct(bool, StressCriticalJNINatives, false,                         \\\n-          \"Exercise register saving code in critical natives\")              \\\n-                                                                            \\\n-  diagnostic(bool, UseAESIntrinsics, false,                                 \\\n+  product(bool, UseAESIntrinsics, false, DIAGNOSTIC,                        \\\n@@ -326,1 +323,1 @@\n-  diagnostic(bool, UseAESCTRIntrinsics, false,                              \\\n+  product(bool, UseAESCTRIntrinsics, false, DIAGNOSTIC,                     \\\n@@ -329,1 +326,4 @@\n-  diagnostic(bool, UseSHA1Intrinsics, false,                                \\\n+  product(bool, UseMD5Intrinsics, false, DIAGNOSTIC,                        \\\n+          \"Use intrinsics for MD5 crypto hash function\")                    \\\n+                                                                            \\\n+  product(bool, UseSHA1Intrinsics, false, DIAGNOSTIC,                       \\\n@@ -333,1 +333,1 @@\n-  diagnostic(bool, UseSHA256Intrinsics, false,                              \\\n+  product(bool, UseSHA256Intrinsics, false, DIAGNOSTIC,                     \\\n@@ -337,1 +337,1 @@\n-  diagnostic(bool, UseSHA512Intrinsics, false,                              \\\n+  product(bool, UseSHA512Intrinsics, false, DIAGNOSTIC,                     \\\n@@ -341,1 +341,5 @@\n-  diagnostic(bool, UseCRC32Intrinsics, false,                               \\\n+  product(bool, UseSHA3Intrinsics, false, DIAGNOSTIC,                       \\\n+          \"Use intrinsics for SHA3 crypto hash function. \"                  \\\n+          \"Requires that UseSHA is enabled.\")                               \\\n+                                                                            \\\n+  product(bool, UseCRC32Intrinsics, false, DIAGNOSTIC,                      \\\n@@ -344,1 +348,1 @@\n-  diagnostic(bool, UseCRC32CIntrinsics, false,                              \\\n+  product(bool, UseCRC32CIntrinsics, false, DIAGNOSTIC,                     \\\n@@ -347,1 +351,1 @@\n-  diagnostic(bool, UseAdler32Intrinsics, false,                             \\\n+  product(bool, UseAdler32Intrinsics, false, DIAGNOSTIC,                    \\\n@@ -350,1 +354,1 @@\n-  diagnostic(bool, UseVectorizedMismatchIntrinsic, false,                   \\\n+  product(bool, UseVectorizedMismatchIntrinsic, false, DIAGNOSTIC,          \\\n@@ -353,1 +357,7 @@\n-  diagnostic(ccstrlist, DisableIntrinsic, \"\",                               \\\n+  product(bool, UseCopySignIntrinsic, false, DIAGNOSTIC,                    \\\n+          \"Enables intrinsification of Math.copySign\")                      \\\n+                                                                            \\\n+  product(bool, UseSignumIntrinsic, false, DIAGNOSTIC,                      \\\n+          \"Enables intrinsification of Math.signum\")                        \\\n+                                                                            \\\n+  product(ccstrlist, DisableIntrinsic, \"\", DIAGNOSTIC,                      \\\n@@ -355,0 +365,6 @@\n+         constraint(DisableIntrinsicConstraintFunc,AfterErgo)               \\\n+                                                                            \\\n+  product(ccstrlist, ControlIntrinsic, \"\", DIAGNOSTIC,                      \\\n+         \"Control intrinsics using a list of +\/- (internal) names, \"        \\\n+         \"separated by commas\")                                             \\\n+         constraint(ControlIntrinsicConstraintFunc,AfterErgo)               \\\n@@ -374,3 +390,22 @@\n-  product(bool, Debugging, false,                                           \\\n-          \"Set when executing debug methods in debug.cpp \"                  \\\n-          \"(to prevent triggering assertions)\")                             \\\n+  develop(bool, DeoptimizeObjectsALot, false,                               \\\n+          \"For testing purposes concurrent threads revert optimizations \"   \\\n+          \"based on escape analysis at intervals given with \"               \\\n+          \"DeoptimizeObjectsALotInterval=n. The thread count is given \"     \\\n+          \"with DeoptimizeObjectsALotThreadCountSingle and \"                \\\n+          \"DeoptimizeObjectsALotThreadCountAll.\")                           \\\n+                                                                            \\\n+  develop(uint64_t, DeoptimizeObjectsALotInterval, 5,                       \\\n+          \"Interval for DeoptimizeObjectsALot.\")                            \\\n+          range(0, max_jlong)                                               \\\n+                                                                            \\\n+  develop(int, DeoptimizeObjectsALotThreadCountSingle, 1,                   \\\n+          \"The number of threads that revert optimizations based on \"       \\\n+          \"escape analysis for a single thread if DeoptimizeObjectsALot \"   \\\n+          \"is enabled. The target thread is selected round robin.\" )        \\\n+          range(0, max_jint)                                                \\\n+                                                                            \\\n+  develop(int, DeoptimizeObjectsALotThreadCountAll, 1,                      \\\n+          \"The number of threads that revert optimizations based on \"       \\\n+          \"escape analysis for all threads if DeoptimizeObjectsALot \"       \\\n+          \"is enabled.\" )                                                   \\\n+          range(0, max_jint)                                                \\\n@@ -385,1 +420,1 @@\n-  diagnostic(bool, AbortVMOnSafepointTimeout, false,                        \\\n+  product(bool, AbortVMOnSafepointTimeout, false, DIAGNOSTIC,               \\\n@@ -388,1 +423,1 @@\n-  diagnostic(bool, AbortVMOnVMOperationTimeout, false,                      \\\n+  product(bool, AbortVMOnVMOperationTimeout, false, DIAGNOSTIC,             \\\n@@ -391,1 +426,1 @@\n-  diagnostic(intx, AbortVMOnVMOperationTimeoutDelay, 1000,                  \\\n+  product(intx, AbortVMOnVMOperationTimeoutDelay, 1000, DIAGNOSTIC,         \\\n@@ -395,16 +430,0 @@\n-  \/* 50 retries * (5 * current_retry_count) millis = ~6.375 seconds *\/      \\\n-  \/* typically, at most a few retries are needed                    *\/      \\\n-  product(intx, SuspendRetryCount, 50,                                      \\\n-          \"Maximum retry count for an external suspend request\")            \\\n-          range(0, max_intx)                                                \\\n-                                                                            \\\n-  product(intx, SuspendRetryDelay, 5,                                       \\\n-          \"Milliseconds to delay per retry (* current_retry_count)\")        \\\n-          range(0, max_intx)                                                \\\n-                                                                            \\\n-  product(bool, AssertOnSuspendWaitFailure, false,                          \\\n-          \"Assert\/Guarantee on external suspend wait failure\")              \\\n-                                                                            \\\n-  product(bool, TraceSuspendWaitFailures, false,                            \\\n-          \"Trace external suspend wait failures\")                           \\\n-                                                                            \\\n@@ -414,1 +433,1 @@\n-  diagnostic(bool, LogEvents, true,                                         \\\n+  product(bool, LogEvents, true, DIAGNOSTIC,                                \\\n@@ -417,1 +436,1 @@\n-  diagnostic(uintx, LogEventsBufferEntries, 20,                             \\\n+  product(uintx, LogEventsBufferEntries, 20, DIAGNOSTIC,                    \\\n@@ -421,1 +440,1 @@\n-  diagnostic(bool, BytecodeVerificationRemote, true,                        \\\n+  product(bool, BytecodeVerificationRemote, true, DIAGNOSTIC,               \\\n@@ -424,1 +443,1 @@\n-  diagnostic(bool, BytecodeVerificationLocal, false,                        \\\n+  product(bool, BytecodeVerificationLocal, false, DIAGNOSTIC,               \\\n@@ -427,3 +446,0 @@\n-  develop(bool, ForceFloatExceptions, trueInDebug,                          \\\n-          \"Force exceptions on FP stack under\/overflow\")                    \\\n-                                                                            \\\n@@ -460,2 +476,2 @@\n-  develop(bool, PrintVMMessages, true,                                      \\\n-          \"Print VM messages on console\")                                   \\\n+  product(bool, ExecutingUnitTests, false,                                  \\\n+          \"Whether the JVM is running unit tests or not\")                   \\\n@@ -463,1 +479,1 @@\n-  notproduct(uintx, ErrorHandlerTest, 0,                                    \\\n+  develop(uintx, ErrorHandlerTest, 0,                                       \\\n@@ -465,1 +481,1 @@\n-          \"determines which error to provoke. See test_error_handler() \"    \\\n+          \"determines which error to provoke. See controlled_crash() \"      \\\n@@ -467,0 +483,1 @@\n+          range(0, 17)                                                      \\\n@@ -468,1 +485,1 @@\n-  notproduct(uintx, TestCrashInErrorHandler, 0,                             \\\n+  develop(uintx, TestCrashInErrorHandler, 0,                                \\\n@@ -470,1 +487,2 @@\n-          \"crash). see test_error_handler() in vmError.cpp\")                \\\n+          \"crash). see controlled_crash() in vmError.cpp\")                  \\\n+          range(0, 17)                                                      \\\n@@ -472,1 +490,1 @@\n-  notproduct(bool, TestSafeFetchInErrorHandler, false,                      \\\n+  develop(bool, TestSafeFetchInErrorHandler, false   ,                      \\\n@@ -475,1 +493,1 @@\n-  notproduct(bool, TestUnresponsiveErrorHandler, false,                     \\\n+  develop(bool, TestUnresponsiveErrorHandler, false,                        \\\n@@ -498,3 +516,0 @@\n-  product_pd(bool, UseOSErrorReporting,                                     \\\n-          \"Let VM fatal error propagate to the OS (ie. WER on Windows)\")    \\\n-                                                                            \\\n@@ -509,1 +524,2 @@\n-          \"Run user-defined commands on first java.lang.OutOfMemoryError\")  \\\n+          \"Run user-defined commands on first java.lang.OutOfMemoryError \"  \\\n+          \"thrown from JVM\")                                                \\\n@@ -511,1 +527,1 @@\n-  manageable(bool, HeapDumpBeforeFullGC, false,                             \\\n+  product(bool, HeapDumpBeforeFullGC, false, MANAGEABLE,                    \\\n@@ -514,1 +530,1 @@\n-  manageable(bool, HeapDumpAfterFullGC, false,                              \\\n+  product(bool, HeapDumpAfterFullGC, false, MANAGEABLE,                     \\\n@@ -517,2 +533,3 @@\n-  manageable(bool, HeapDumpOnOutOfMemoryError, false,                       \\\n-          \"Dump heap to file when java.lang.OutOfMemoryError is thrown\")    \\\n+  product(bool, HeapDumpOnOutOfMemoryError, false, MANAGEABLE,              \\\n+          \"Dump heap to file when java.lang.OutOfMemoryError is thrown \"    \\\n+          \"from JVM\")                                                       \\\n@@ -520,1 +537,1 @@\n-  manageable(ccstr, HeapDumpPath, NULL,                                     \\\n+  product(ccstr, HeapDumpPath, NULL, MANAGEABLE,                            \\\n@@ -525,2 +542,5 @@\n-  develop(bool, BreakAtWarning, false,                                      \\\n-          \"Execute breakpoint upon encountering VM warning\")                \\\n+  product(intx, HeapDumpGzipLevel, 0, MANAGEABLE,                           \\\n+          \"When HeapDumpOnOutOfMemoryError is on, the gzip compression \"    \\\n+          \"level of the dump file. 0 (the default) disables gzip \"          \\\n+          \"compression. Otherwise the level must be between 1 and 9.\")      \\\n+          range(0, 9)                                                       \\\n@@ -531,1 +551,1 @@\n-  diagnostic(bool, PrintNMTStatistics, false,                               \\\n+  product(bool, PrintNMTStatistics, false, DIAGNOSTIC,                      \\\n@@ -534,1 +554,1 @@\n-  diagnostic(bool, LogCompilation, false,                                   \\\n+  product(bool, LogCompilation, false, DIAGNOSTIC,                          \\\n@@ -540,0 +560,4 @@\n+  product(intx, RepeatCompilation, 0, DIAGNOSTIC,                           \\\n+          \"Repeat compilation without installing code (number of times)\")   \\\n+          range(0, max_jint)                                                \\\n+                                                                            \\\n@@ -543,1 +567,1 @@\n-  diagnostic(intx, ScavengeRootsInCode, 2,                                  \\\n+  product(intx, ScavengeRootsInCode, 2, DIAGNOSTIC,                         \\\n@@ -552,1 +576,1 @@\n-  diagnostic(bool, PrintCompilation2, false,                                \\\n+  product(bool, PrintCompilation2, false, DIAGNOSTIC,                       \\\n@@ -555,1 +579,1 @@\n-  diagnostic(bool, PrintAdapterHandlers, false,                             \\\n+  product(bool, PrintAdapterHandlers, false, DIAGNOSTIC,                    \\\n@@ -558,1 +582,1 @@\n-  diagnostic(bool, VerifyAdapterCalls, trueInDebug,                         \\\n+  product(bool, VerifyAdapterCalls, trueInDebug, DIAGNOSTIC,                \\\n@@ -564,1 +588,1 @@\n-  diagnostic(bool, PrintAssembly, false,                                    \\\n+  product(bool, PrintAssembly, false, DIAGNOSTIC,                           \\\n@@ -567,1 +591,1 @@\n-  diagnostic(ccstr, PrintAssemblyOptions, NULL,                             \\\n+  product(ccstr, PrintAssemblyOptions, NULL, DIAGNOSTIC,                    \\\n@@ -573,1 +597,1 @@\n-  diagnostic(bool, PrintNMethods, false,                                    \\\n+  product(bool, PrintNMethods, false, DIAGNOSTIC,                           \\\n@@ -576,1 +600,1 @@\n-  diagnostic(bool, PrintNativeNMethods, false,                              \\\n+  product(bool, PrintNativeNMethods, false, DIAGNOSTIC,                     \\\n@@ -608,1 +632,1 @@\n-  diagnostic(bool, PrintCodeHeapAnalytics, false,                           \\\n+  product(bool, PrintCodeHeapAnalytics, false, DIAGNOSTIC,                  \\\n@@ -611,1 +635,1 @@\n-  diagnostic(bool, PrintStubCode, false,                                    \\\n+  product(bool, PrintStubCode, false, DIAGNOSTIC,                           \\\n@@ -620,1 +644,1 @@\n-  manageable(bool, ShowCodeDetailsInExceptionMessages, true,                \\\n+  product(bool, ShowCodeDetailsInExceptionMessages, true, MANAGEABLE,       \\\n@@ -627,3 +651,0 @@\n-  notproduct(uintx, WarnOnStalledSpinLock, 0,                               \\\n-          \"Print warnings for stalled SpinLocks\")                           \\\n-                                                                            \\\n@@ -638,4 +659,0 @@\n-  develop(bool, IgnoreRewrites, false,                                      \\\n-          \"Suppress rewrites of bytecodes in the oopmap generator. \"        \\\n-          \"This is unsafe!\")                                                \\\n-                                                                            \\\n@@ -648,3 +665,0 @@\n-  develop(bool, ProtectionDomainVerification, true,                         \\\n-          \"Verify protection domain before resolution in system dictionary\")\\\n-                                                                            \\\n@@ -657,7 +671,0 @@\n-  develop(bool, DisableStartThread, false,                                  \\\n-          \"Disable starting of additional Java threads \"                    \\\n-          \"(for debugging only)\")                                           \\\n-                                                                            \\\n-  develop(bool, MemProfiling, false,                                        \\\n-          \"Write memory usage profiling to log file\")                       \\\n-                                                                            \\\n@@ -667,1 +674,4 @@\n-  diagnostic(bool, DynamicallyResizeSystemDictionaries, true,               \\\n+  notproduct(bool, PrintClassLoaderDataGraphAtExit, false,                  \\\n+          \"Print the class loader data graph at exit\")                      \\\n+                                                                            \\\n+  product(bool, DynamicallyResizeSystemDictionaries, true, DIAGNOSTIC,      \\\n@@ -671,2 +681,2 @@\n-          \"Require the VM to acquire the class loader lock before calling \" \\\n-          \"loadClass() even for class loaders registering \"                 \\\n+          \"(Deprecated) Require the VM to acquire the class loader lock \"   \\\n+          \"before calling loadClass() even for class loaders registering \"  \\\n@@ -682,1 +692,1 @@\n-  experimental(bool, DisablePrimordialThreadGuardPages, false,              \\\n+  product(bool, DisablePrimordialThreadGuardPages, false, EXPERIMENTAL,     \\\n@@ -686,3 +696,0 @@\n-  diagnostic(bool, AsyncDeflateIdleMonitors, true,                          \\\n-          \"Deflate idle monitors using the ServiceThread.\")                 \\\n-                                                                            \\\n@@ -691,1 +698,1 @@\n-  diagnostic(intx, AsyncDeflationInterval, 250,                             \\\n+  product(intx, AsyncDeflationInterval, 250, DIAGNOSTIC,                    \\\n@@ -696,1 +703,13 @@\n-  experimental(intx, MonitorUsedDeflationThreshold, 90,                     \\\n+  product(size_t, AvgMonitorsPerThreadEstimate, 1024, DIAGNOSTIC,           \\\n+          \"Used to estimate a variable ceiling based on number of threads \" \\\n+          \"for use with MonitorUsedDeflationThreshold (0 is off).\")         \\\n+          range(0, max_uintx)                                               \\\n+                                                                            \\\n+  \/* notice: the max range value here is max_jint, not max_intx  *\/         \\\n+  \/* because of overflow issue                                   *\/         \\\n+  product(intx, MonitorDeflationMax, 1000000, DIAGNOSTIC,                   \\\n+          \"The maximum number of monitors to deflate, unlink and delete \"   \\\n+          \"at one time (minimum is 1024).\")                      \\\n+          range(1024, max_jint)                                             \\\n+                                                                            \\\n+  product(intx, MonitorUsedDeflationThreshold, 90, DIAGNOSTIC,              \\\n@@ -702,1 +721,6 @@\n-  experimental(intx, hashCode, 5,                                           \\\n+  product(uintx, NoAsyncDeflationProgressMax, 3, DIAGNOSTIC,                \\\n+          \"Max number of no progress async deflation attempts to tolerate \" \\\n+          \"before adjusting the in_use_list_ceiling up (0 is off).\")        \\\n+          range(0, max_uintx)                                               \\\n+                                                                            \\\n+  product(intx, hashCode, 5, EXPERIMENTAL,                                  \\\n@@ -723,1 +747,1 @@\n-          \"Do not complain if the application installs signal handlers \"    \\\n+          \"Application will install primary signal handlers for the JVM \"   \\\n@@ -787,1 +811,1 @@\n-  diagnostic(bool, PrintBiasedLockingStatistics, false,                     \\\n+  product(bool, PrintBiasedLockingStatistics, false, DIAGNOSTIC,            \\\n@@ -809,0 +833,10 @@\n+  product(intx, DiagnoseSyncOnValueBasedClasses, 0, DIAGNOSTIC,             \\\n+             \"Detect and take action upon identifying synchronization on \"  \\\n+             \"value based classes. Modes: \"                                 \\\n+             \"0: off; \"                                                     \\\n+             \"1: exit with fatal error; \"                                   \\\n+             \"2: log message to stdout. Output file can be specified with \" \\\n+             \"   -Xlog:valuebasedclasses. If JFR is running it will \"       \\\n+             \"   also generate JFR events.\")                                \\\n+             range(0, 2)                                                    \\\n+                                                                            \\\n@@ -810,1 +844,2 @@\n-          \"JVM exits on the first occurrence of an out-of-memory error\")    \\\n+          \"JVM exits on the first occurrence of an out-of-memory error \"    \\\n+          \"thrown from JVM\")                                                \\\n@@ -814,1 +849,1 @@\n-          \"first occurrence of an out-of-memory error\")                     \\\n+          \"first occurrence of an out-of-memory error thrown from JVM\")     \\\n@@ -824,9 +859,5 @@\n-  \/* This option can change an EMCP method into an obsolete method. *\/      \\\n-  \/* This can affect tests that except specific methods to be EMCP. *\/      \\\n-  \/* This option should be used with caution.                       *\/      \\\n-  product(bool, StressLdcRewrite, false,                                    \\\n-          \"Force ldc -> ldc_w rewrite during RedefineClasses\")              \\\n-                                                                            \\\n-  \/* change to false by default sometime after Mustang *\/                   \\\n-  product(bool, VerifyMergedCPBytecodes, true,                              \\\n-          \"Verify bytecodes after RedefineClasses constant pool merging\")   \\\n+  product(bool, StressLdcRewrite, false, DIAGNOSTIC,                        \\\n+          \"Force ldc -> ldc_w rewrite during RedefineClasses. \"             \\\n+          \"This option can change an EMCP method into an obsolete method \"  \\\n+          \"and can affect tests that expect specific methods to be EMCP. \"  \\\n+          \"This option should be used with caution.\")                       \\\n@@ -869,1 +900,1 @@\n-          \"Trace rewriting of method oops during oop map generation\")       \\\n+          \"Trace rewriting of methods during oop map generation\")           \\\n@@ -894,6 +925,0 @@\n-  product(size_t, InitialBootClassLoaderMetaspaceSize,                      \\\n-          NOT_LP64(2200*K) LP64_ONLY(4*M),                                  \\\n-          \"(Deprecated) Initial size of the boot class loader data metaspace\") \\\n-          range(30*K, max_uintx\/BytesPerWord)                               \\\n-          constraint(InitialBootClassLoaderMetaspaceSizeConstraintFunc, AfterErgo)\\\n-                                                                            \\\n@@ -903,1 +928,1 @@\n-  manageable(bool, PrintClassHistogram, false,                              \\\n+  product(bool, PrintClassHistogram, false, MANAGEABLE,                     \\\n@@ -906,1 +931,1 @@\n-  experimental(double, ObjectCountCutOffPercent, 0.5,                       \\\n+  product(double, ObjectCountCutOffPercent, 0.5, EXPERIMENTAL,              \\\n@@ -913,4 +938,1 @@\n-  diagnostic(bool, TraceJVMTIObjectTagging, false,                          \\\n-          \"Trace JVMTI object tagging calls\")                               \\\n-                                                                            \\\n-  diagnostic(bool, VerifyBeforeIteration, false,                            \\\n+  product(bool, VerifyBeforeIteration, false, DIAGNOSTIC,                   \\\n@@ -919,43 +941,0 @@\n-  \/* compiler interface *\/                                                  \\\n-                                                                            \\\n-  develop(bool, CIPrintCompilerName, false,                                 \\\n-          \"when CIPrint is active, print the name of the active compiler\")  \\\n-                                                                            \\\n-  diagnostic(bool, CIPrintCompileQueue, false,                              \\\n-          \"display the contents of the compile queue whenever a \"           \\\n-          \"compilation is enqueued\")                                        \\\n-                                                                            \\\n-  develop(bool, CIPrintRequests, false,                                     \\\n-          \"display every request for compilation\")                          \\\n-                                                                            \\\n-  product(bool, CITime, false,                                              \\\n-          \"collect timing information for compilation\")                     \\\n-                                                                            \\\n-  develop(bool, CITimeVerbose, false,                                       \\\n-          \"be more verbose in compilation timings\")                         \\\n-                                                                            \\\n-  develop(bool, CITimeEach, false,                                          \\\n-          \"display timing information after each successful compilation\")   \\\n-                                                                            \\\n-  develop(bool, CICountOSR, false,                                          \\\n-          \"use a separate counter when assigning ids to osr compilations\")  \\\n-                                                                            \\\n-  develop(bool, CICompileNatives, true,                                     \\\n-          \"compile native methods if supported by the compiler\")            \\\n-                                                                            \\\n-  develop_pd(bool, CICompileOSR,                                            \\\n-          \"compile on stack replacement methods if supported by the \"       \\\n-          \"compiler\")                                                       \\\n-                                                                            \\\n-  develop(bool, CIPrintMethodCodes, false,                                  \\\n-          \"print method bytecodes of the compiled code\")                    \\\n-                                                                            \\\n-  develop(bool, CIPrintTypeFlow, false,                                     \\\n-          \"print the results of ciTypeFlow analysis\")                       \\\n-                                                                            \\\n-  develop(bool, CITraceTypeFlow, false,                                     \\\n-          \"detailed per-bytecode tracing of ciTypeFlow analysis\")           \\\n-                                                                            \\\n-  develop(intx, OSROnlyBCI, -1,                                             \\\n-          \"OSR only at this bci.  Negative values mean exclude that bci\")   \\\n-                                                                            \\\n@@ -974,1 +953,1 @@\n-  diagnostic(bool, ReduceNumberOfCompilerThreads, true,                     \\\n+  product(bool, ReduceNumberOfCompilerThreads, true, DIAGNOSTIC,            \\\n@@ -978,1 +957,1 @@\n-  diagnostic(bool, TraceCompilerThreads, false,                             \\\n+  product(bool, TraceCompilerThreads, false, DIAGNOSTIC,                    \\\n@@ -985,5 +964,0 @@\n-  develop(bool, UseStackBanging, true,                                      \\\n-          \"use stack banging for stack overflow checks (required for \"      \\\n-          \"proper StackOverflow handling; disable only to measure cost \"    \\\n-          \"of stackbanging)\")                                               \\\n-                                                                            \\\n@@ -997,1 +971,1 @@\n-  diagnostic_pd(bool, ImplicitNullChecks,                                   \\\n+  product_pd(bool, ImplicitNullChecks, DIAGNOSTIC,                          \\\n@@ -1006,1 +980,1 @@\n-  diagnostic(bool, EnableThreadSMRExtraValidityChecks, true,                \\\n+  product(bool, EnableThreadSMRExtraValidityChecks, true, DIAGNOSTIC,       \\\n@@ -1009,1 +983,1 @@\n-  diagnostic(bool, EnableThreadSMRStatistics, trueInDebug,                  \\\n+  product(bool, EnableThreadSMRStatistics, trueInDebug, DIAGNOSTIC,         \\\n@@ -1024,0 +998,3 @@\n+  product(bool, UseVtableBasedCHA, true,  DIAGNOSTIC,                       \\\n+          \"Use vtable information during CHA\")                              \\\n+                                                                            \\\n@@ -1027,1 +1004,1 @@\n-  diagnostic(bool, PrintInlining, false,                                    \\\n+  product(bool, PrintInlining, false, DIAGNOSTIC,                           \\\n@@ -1036,1 +1013,1 @@\n-  diagnostic(bool, LogTouchedMethods, false,                                \\\n+  product(bool, LogTouchedMethods, false, DIAGNOSTIC,                       \\\n@@ -1039,1 +1016,1 @@\n-  diagnostic(bool, PrintTouchedMethodsAtExit, false,                        \\\n+  product(bool, PrintTouchedMethodsAtExit, false, DIAGNOSTIC,               \\\n@@ -1048,1 +1025,1 @@\n-  diagnostic(bool, PrintMethodFlushingStatistics, false,                    \\\n+  product(bool, PrintMethodFlushingStatistics, false, DIAGNOSTIC,           \\\n@@ -1051,1 +1028,1 @@\n-  diagnostic(intx, HotMethodDetectionLimit, 100000,                         \\\n+  product(intx, HotMethodDetectionLimit, 100000, DIAGNOSTIC,                \\\n@@ -1056,1 +1033,1 @@\n-  diagnostic(intx, MinPassesBeforeFlush, 10,                                \\\n+  product(intx, MinPassesBeforeFlush, 10, DIAGNOSTIC,                       \\\n@@ -1064,1 +1041,1 @@\n-  diagnostic(bool, StressCodeAging, false,                                  \\\n+  product(bool, StressCodeAging, false, DIAGNOSTIC,                         \\\n@@ -1070,1 +1047,1 @@\n-  diagnostic(bool, DebugNonSafepoints, trueInDebug,                         \\\n+  product(bool, DebugNonSafepoints, trueInDebug, DIAGNOSTIC,                \\\n@@ -1096,1 +1073,1 @@\n-  diagnostic(bool, SerializeVMOutput, true,                                 \\\n+  product(bool, SerializeVMOutput, true, DIAGNOSTIC,                        \\\n@@ -1099,1 +1076,1 @@\n-  diagnostic(bool, DisplayVMOutput, true,                                   \\\n+  product(bool, DisplayVMOutput, true, DIAGNOSTIC,                          \\\n@@ -1102,1 +1079,1 @@\n-  diagnostic(bool, LogVMOutput, false,                                      \\\n+  product(bool, LogVMOutput, false, DIAGNOSTIC,                             \\\n@@ -1105,1 +1082,1 @@\n-  diagnostic(ccstr, LogFile, NULL,                                          \\\n+  product(ccstr, LogFile, NULL, DIAGNOSTIC,                                 \\\n@@ -1135,1 +1112,1 @@\n-  diagnostic(bool, VerifyStringTableAtExit, false,                          \\\n+  product(bool, VerifyStringTableAtExit, false, DIAGNOSTIC,                 \\\n@@ -1141,5 +1118,1 @@\n-  notproduct(bool, ExitVMOnVerifyError, false,                              \\\n-          \"standard exit from VM if bytecode verify error \"                 \\\n-          \"(only in debug mode)\")                                           \\\n-                                                                            \\\n-  diagnostic(ccstr, AbortVMOnException, NULL,                               \\\n+  product(ccstr, AbortVMOnException, NULL, DIAGNOSTIC,                      \\\n@@ -1149,1 +1122,1 @@\n-  diagnostic(ccstr, AbortVMOnExceptionMessage, NULL,                        \\\n+  product(ccstr, AbortVMOnExceptionMessage, NULL, DIAGNOSTIC,               \\\n@@ -1180,3 +1153,0 @@\n-  develop(bool, UseLoopSafepoints, true,                                    \\\n-          \"Generate Safepoint nodes in every loop\")                         \\\n-                                                                            \\\n@@ -1210,13 +1180,0 @@\n-  notproduct(bool, CountRuntimeCalls, false,                                \\\n-          \"Count VM runtime calls\")                                         \\\n-                                                                            \\\n-  develop(bool, CountJNICalls, false,                                       \\\n-          \"Count jni method invocations\")                                   \\\n-                                                                            \\\n-  notproduct(bool, CountJVMCalls, false,                                    \\\n-          \"Count jvm method invocations\")                                   \\\n-                                                                            \\\n-  notproduct(bool, CountRemovableExceptions, false,                         \\\n-          \"Count exceptions that could be replaced by branches due to \"     \\\n-          \"inlining\")                                                       \\\n-                                                                            \\\n@@ -1233,1 +1190,1 @@\n-  diagnostic(bool, PrintInterpreter, false,                                 \\\n+  product(bool, PrintInterpreter, false, DIAGNOSTIC,                        \\\n@@ -1265,1 +1222,1 @@\n-  diagnostic(bool, PrintSignatureHandlers, false,                           \\\n+  product(bool, PrintSignatureHandlers, false, DIAGNOSTIC,                  \\\n@@ -1300,5 +1257,0 @@\n-  develop(bool, TraceProfileInterpreter, false,                             \\\n-          \"Trace profiling at the bytecode level during interpretation. \"   \\\n-          \"This outputs the profiling information collected to improve \"    \\\n-          \"jit compilation.\")                                               \\\n-                                                                            \\\n@@ -1313,1 +1265,1 @@\n-  diagnostic(bool, PrintMethodData, false,                                  \\\n+  product(bool, PrintMethodData, false, DIAGNOSTIC,                         \\\n@@ -1319,4 +1271,0 @@\n-  develop(bool, VerifyCompiledCode, false,                                  \\\n-          \"Include miscellaneous runtime verifications in nmethod code; \"   \\\n-          \"default off because it disturbs nmethod size heuristics\")        \\\n-                                                                            \\\n@@ -1345,20 +1293,0 @@\n-  product(bool, DontCompileHugeMethods, true,                               \\\n-          \"Do not compile methods > HugeMethodLimit\")                       \\\n-                                                                            \\\n-  \/* Bytecode escape analysis estimation. *\/                                \\\n-  product(bool, EstimateArgEscape, true,                                    \\\n-          \"Analyze bytecodes to estimate escape state of arguments\")        \\\n-                                                                            \\\n-  product(intx, BCEATraceLevel, 0,                                          \\\n-          \"How much tracing to do of bytecode escape analysis estimates \"   \\\n-          \"(0-3)\")                                                          \\\n-          range(0, 3)                                                       \\\n-                                                                            \\\n-  product(intx, MaxBCEAEstimateLevel, 5,                                    \\\n-          \"Maximum number of nested calls that are analyzed by BC EA\")      \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, MaxBCEAEstimateSize, 150,                                   \\\n-          \"Maximum bytecode size of a method to be analyzed by BC EA\")      \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n@@ -1417,1 +1345,1 @@\n-  diagnostic(intx, GuaranteedSafepointInterval, 1000,                       \\\n+  product(intx, GuaranteedSafepointInterval, 1000, DIAGNOSTIC,              \\\n@@ -1424,2 +1352,1 @@\n-  LP64_ONLY(range(0, max_intx\/MICROUNITS))                                  \\\n-  NOT_LP64(range(0, max_intx))                                              \\\n+          range(0, max_intx LP64_ONLY(\/MICROUNITS))                         \\\n@@ -1438,3 +1365,0 @@\n-  notproduct(intx, MemProfilingInterval, 500,                               \\\n-          \"Time between each invocation of the MemProfiler\")                \\\n-                                                                            \\\n@@ -1478,1 +1402,1 @@\n-  diagnostic(uintx, MallocMaxTestWords,     0,                              \\\n+  product(uintx, MallocMaxTestWords,     0, DIAGNOSTIC,                     \\\n@@ -1502,1 +1426,1 @@\n-  experimental(intx, PerMethodSpecTrapLimit,  5000,                         \\\n+  product(intx, PerMethodSpecTrapLimit,  5000, EXPERIMENTAL,                \\\n@@ -1511,1 +1435,1 @@\n-  experimental(intx, SpecTrapLimitExtraEntries,  3,                         \\\n+  product(intx, SpecTrapLimitExtraEntries,  3, EXPERIMENTAL,                \\\n@@ -1518,1 +1442,1 @@\n-  diagnostic_pd(intx, InlineFrequencyCount,                                 \\\n+  product_pd(intx, InlineFrequencyCount, DIAGNOSTIC,                        \\\n@@ -1531,5 +1455,1 @@\n-  develop(intx, ProfilerNodeSize,  1024,                                    \\\n-          \"Size in K to allocate for the Profile Nodes of each thread\")     \\\n-          range(0, 1024)                                                    \\\n-                                                                            \\\n-  product_pd(size_t, MetaspaceSize,                                         \\\n+  product(size_t, MetaspaceSize, NOT_LP64(16 * M) LP64_ONLY(21 * M),        \\\n@@ -1549,1 +1469,17 @@\n-  manageable(uintx, MinHeapFreeRatio, 40,                                   \\\n+  develop(size_t, CompressedClassSpaceBaseAddress, 0,                       \\\n+          \"Force the class space to be allocated at this address or \"       \\\n+          \"fails VM initialization (requires -Xshare=off.\")                 \\\n+                                                                            \\\n+  product(ccstr, MetaspaceReclaimPolicy, \"balanced\",                        \\\n+          \"options: balanced, aggressive, none\")                            \\\n+                                                                            \\\n+  product(bool, PrintMetaspaceStatisticsAtExit, false, DIAGNOSTIC,          \\\n+          \"Print metaspace statistics upon VM exit.\")                       \\\n+                                                                            \\\n+  product(bool, MetaspaceGuardAllocations, false, DIAGNOSTIC,               \\\n+          \"Metapace allocations are guarded.\")                              \\\n+                                                                            \\\n+  product(bool, MetaspaceHandleDeallocations, true, DIAGNOSTIC,             \\\n+          \"Switch off Metapace deallocation handling.\")                     \\\n+                                                                            \\\n+  product(uintx, MinHeapFreeRatio, 40, MANAGEABLE,                          \\\n@@ -1556,1 +1492,1 @@\n-  manageable(uintx, MaxHeapFreeRatio, 70,                                   \\\n+  product(uintx, MaxHeapFreeRatio, 70, MANAGEABLE,                          \\\n@@ -1656,1 +1592,1 @@\n-          range(os::vm_page_size(), max_uintx)                              \\\n+          constraint(VMPageSizeConstraintFunc, AtParse)                     \\\n@@ -1667,1 +1603,1 @@\n-          range(os::vm_page_size(), max_uintx)                              \\\n+          constraint(VMPageSizeConstraintFunc, AtParse)                     \\\n@@ -1679,1 +1615,1 @@\n-          range(os::vm_page_size(), max_uintx)                              \\\n+          constraint(VMPageSizeConstraintFunc, AtParse)                     \\\n@@ -1685,1 +1621,1 @@\n-  diagnostic_pd(uintx, CodeCacheMinBlockLength,                             \\\n+  product_pd(uintx, CodeCacheMinBlockLength, DIAGNOSTIC,                    \\\n@@ -1706,19 +1642,0 @@\n-  \/* AOT parameters *\/                                                      \\\n-  experimental(bool, UseAOT, false,                                         \\\n-          \"Use AOT compiled files\")                                         \\\n-                                                                            \\\n-  experimental(ccstrlist, AOTLibrary, NULL,                                 \\\n-          \"AOT library\")                                                    \\\n-                                                                            \\\n-  experimental(bool, PrintAOT, false,                                       \\\n-          \"Print used AOT klasses and methods\")                             \\\n-                                                                            \\\n-  notproduct(bool, PrintAOTStatistics, false,                               \\\n-          \"Print AOT statistics\")                                           \\\n-                                                                            \\\n-  diagnostic(bool, UseAOTStrictLoading, false,                              \\\n-          \"Exit the VM if any of the AOT libraries has invalid config\")     \\\n-                                                                            \\\n-  product(bool, CalculateClassFingerprint, false,                           \\\n-          \"Calculate class fingerprint\")                                    \\\n-                                                                            \\\n@@ -1736,71 +1653,0 @@\n-  \/* compiler interface *\/                                                  \\\n-  develop(intx, CIStart, 0,                                                 \\\n-          \"The id of the first compilation to permit\")                      \\\n-                                                                            \\\n-  develop(intx, CIStop, max_jint,                                           \\\n-          \"The id of the last compilation to permit\")                       \\\n-                                                                            \\\n-  develop(intx, CIStartOSR, 0,                                              \\\n-          \"The id of the first osr compilation to permit \"                  \\\n-          \"(CICountOSR must be on)\")                                        \\\n-                                                                            \\\n-  develop(intx, CIStopOSR, max_jint,                                        \\\n-          \"The id of the last osr compilation to permit \"                   \\\n-          \"(CICountOSR must be on)\")                                        \\\n-                                                                            \\\n-  develop(intx, CIBreakAtOSR, -1,                                           \\\n-          \"The id of osr compilation to break at\")                          \\\n-                                                                            \\\n-  develop(intx, CIBreakAt, -1,                                              \\\n-          \"The id of compilation to break at\")                              \\\n-                                                                            \\\n-  product(ccstrlist, CompileOnly, \"\",                                       \\\n-          \"List of methods (pkg\/class.name) to restrict compilation to\")    \\\n-                                                                            \\\n-  product(ccstr, CompileCommandFile, NULL,                                  \\\n-          \"Read compiler commands from this file [.hotspot_compiler]\")      \\\n-                                                                            \\\n-  diagnostic(ccstr, CompilerDirectivesFile, NULL,                           \\\n-          \"Read compiler directives from this file\")                        \\\n-                                                                            \\\n-  product(ccstrlist, CompileCommand, \"\",                                    \\\n-          \"Prepend to .hotspot_compiler; e.g. log,java\/lang\/String.<init>\") \\\n-                                                                            \\\n-  develop(bool, ReplayCompiles, false,                                      \\\n-          \"Enable replay of compilations from ReplayDataFile\")              \\\n-                                                                            \\\n-  product(ccstr, ReplayDataFile, NULL,                                      \\\n-          \"File containing compilation replay information\"                  \\\n-          \"[default: .\/replay_pid%p.log] (%p replaced with pid)\")           \\\n-                                                                            \\\n-   product(ccstr, InlineDataFile, NULL,                                     \\\n-          \"File containing inlining replay information\"                     \\\n-          \"[default: .\/inline_pid%p.log] (%p replaced with pid)\")           \\\n-                                                                            \\\n-  develop(intx, ReplaySuppressInitializers, 2,                              \\\n-          \"Control handling of class initialization during replay: \"        \\\n-          \"0 - don't do anything special; \"                                 \\\n-          \"1 - treat all class initializers as empty; \"                     \\\n-          \"2 - treat class initializers for application classes as empty; \" \\\n-          \"3 - allow all class initializers to run during bootstrap but \"   \\\n-          \"    pretend they are empty after starting replay\")               \\\n-          range(0, 3)                                                       \\\n-                                                                            \\\n-  develop(bool, ReplayIgnoreInitErrors, false,                              \\\n-          \"Ignore exceptions thrown during initialization for replay\")      \\\n-                                                                            \\\n-  product(bool, DumpReplayDataOnError, true,                                \\\n-          \"Record replay data for crashing compiler threads\")               \\\n-                                                                            \\\n-  product(bool, CICompilerCountPerCPU, false,                               \\\n-          \"1 compiler thread for log(N CPUs)\")                              \\\n-                                                                            \\\n-  notproduct(intx, CICrashAt, -1,                                           \\\n-          \"id of compilation to trigger assert in compiler thread for \"     \\\n-          \"the purpose of testing, e.g. generation of replay data\")         \\\n-  notproduct(bool, CIObjectFactoryVerify, false,                            \\\n-          \"enable potentially expensive verification in ciObjectFactory\")   \\\n-                                                                            \\\n-  diagnostic(bool, AbortVMOnCompilationFailure, false,                      \\\n-          \"Abort VM when method had failed to compile.\")                    \\\n-                                                                            \\\n@@ -1885,1 +1731,1 @@\n-  experimental(bool, UseCriticalJavaThreadPriority, false,                  \\\n+  product(bool, UseCriticalJavaThreadPriority, false, EXPERIMENTAL,         \\\n@@ -1888,1 +1734,1 @@\n-  experimental(bool, UseCriticalCompilerThreadPriority, false,              \\\n+  product(bool, UseCriticalCompilerThreadPriority, false, EXPERIMENTAL,     \\\n@@ -1899,4 +1745,0 @@\n-  \/* Background Compilation *\/                                              \\\n-  develop(intx, LongCompileThreshold,     50,                               \\\n-          \"Used with +TraceLongCompiles\")                                   \\\n-                                                                            \\\n@@ -1908,224 +1750,0 @@\n-  product(double, CompileThresholdScaling, 1.0,                             \\\n-          \"Factor to control when first compilation happens \"               \\\n-          \"(both with and without tiered compilation): \"                    \\\n-          \"values greater than 1.0 delay counter overflow, \"                \\\n-          \"values between 0 and 1.0 rush counter overflow, \"                \\\n-          \"value of 1.0 leaves compilation thresholds unchanged \"           \\\n-          \"value of 0.0 is equivalent to -Xint. \"                           \\\n-          \"\"                                                                \\\n-          \"Flag can be set as per-method option. \"                          \\\n-          \"If a value is specified for a method, compilation thresholds \"   \\\n-          \"for that method are scaled by both the value of the global flag \"\\\n-          \"and the value of the per-method flag.\")                          \\\n-          range(0.0, DBL_MAX)                                               \\\n-                                                                            \\\n-  product(intx, Tier0InvokeNotifyFreqLog, 7,                                \\\n-          \"Interpreter (tier 0) invocation notification frequency\")         \\\n-          range(0, 30)                                                      \\\n-                                                                            \\\n-  product(intx, Tier2InvokeNotifyFreqLog, 11,                               \\\n-          \"C1 without MDO (tier 2) invocation notification frequency\")      \\\n-          range(0, 30)                                                      \\\n-                                                                            \\\n-  product(intx, Tier3InvokeNotifyFreqLog, 10,                               \\\n-          \"C1 with MDO profiling (tier 3) invocation notification \"         \\\n-          \"frequency\")                                                      \\\n-          range(0, 30)                                                      \\\n-                                                                            \\\n-  product(intx, Tier23InlineeNotifyFreqLog, 20,                             \\\n-          \"Inlinee invocation (tiers 2 and 3) notification frequency\")      \\\n-          range(0, 30)                                                      \\\n-                                                                            \\\n-  product(intx, Tier0BackedgeNotifyFreqLog, 10,                             \\\n-          \"Interpreter (tier 0) invocation notification frequency\")         \\\n-          range(0, 30)                                                      \\\n-                                                                            \\\n-  product(intx, Tier2BackedgeNotifyFreqLog, 14,                             \\\n-          \"C1 without MDO (tier 2) invocation notification frequency\")      \\\n-          range(0, 30)                                                      \\\n-                                                                            \\\n-  product(intx, Tier3BackedgeNotifyFreqLog, 13,                             \\\n-          \"C1 with MDO profiling (tier 3) invocation notification \"         \\\n-          \"frequency\")                                                      \\\n-          range(0, 30)                                                      \\\n-                                                                            \\\n-  product(intx, Tier2CompileThreshold, 0,                                   \\\n-          \"threshold at which tier 2 compilation is invoked\")               \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, Tier2BackEdgeThreshold, 0,                                  \\\n-          \"Back edge threshold at which tier 2 compilation is invoked\")     \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, Tier3InvocationThreshold, 200,                              \\\n-          \"Compile if number of method invocations crosses this \"           \\\n-          \"threshold\")                                                      \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, Tier3MinInvocationThreshold, 100,                           \\\n-          \"Minimum invocation to compile at tier 3\")                        \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, Tier3CompileThreshold, 2000,                                \\\n-          \"Threshold at which tier 3 compilation is invoked (invocation \"   \\\n-          \"minimum must be satisfied)\")                                     \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, Tier3BackEdgeThreshold,  60000,                             \\\n-          \"Back edge threshold at which tier 3 OSR compilation is invoked\") \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, Tier3AOTInvocationThreshold, 10000,                         \\\n-          \"Compile if number of method invocations crosses this \"           \\\n-          \"threshold if coming from AOT\")                                   \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, Tier3AOTMinInvocationThreshold, 1000,                       \\\n-          \"Minimum invocation to compile at tier 3 if coming from AOT\")     \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, Tier3AOTCompileThreshold, 15000,                            \\\n-          \"Threshold at which tier 3 compilation is invoked (invocation \"   \\\n-          \"minimum must be satisfied) if coming from AOT\")                  \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, Tier3AOTBackEdgeThreshold,  120000,                         \\\n-          \"Back edge threshold at which tier 3 OSR compilation is invoked \" \\\n-          \"if coming from AOT\")                                             \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  diagnostic(intx, Tier0AOTInvocationThreshold, 200,                        \\\n-          \"Switch to interpreter to profile if the number of method \"       \\\n-          \"invocations crosses this threshold if coming from AOT \"          \\\n-          \"(applicable only with \"                                          \\\n-          \"CompilationMode=high-only|high-only-quick-internal)\")            \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  diagnostic(intx, Tier0AOTMinInvocationThreshold, 100,                     \\\n-          \"Minimum number of invocations to switch to interpreter \"         \\\n-          \"to profile if coming from AOT \"                                  \\\n-          \"(applicable only with \"                                          \\\n-          \"CompilationMode=high-only|high-only-quick-internal)\")            \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  diagnostic(intx, Tier0AOTCompileThreshold, 2000,                          \\\n-          \"Threshold at which to switch to interpreter to profile \"         \\\n-          \"if coming from AOT \"                                             \\\n-          \"(invocation minimum must be satisfied, \"                         \\\n-          \"applicable only with \"                                           \\\n-          \"CompilationMode=high-only|high-only-quick-internal)\")            \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  diagnostic(intx, Tier0AOTBackEdgeThreshold,  60000,                       \\\n-          \"Back edge threshold at which to switch to interpreter \"          \\\n-          \"to profile if coming from AOT \"                                  \\\n-          \"(applicable only with \"                                          \\\n-          \"CompilationMode=high-only|high-only-quick-internal)\")            \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, Tier4InvocationThreshold, 5000,                             \\\n-          \"Compile if number of method invocations crosses this \"           \\\n-          \"threshold\")                                                      \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, Tier4MinInvocationThreshold, 600,                           \\\n-          \"Minimum invocation to compile at tier 4\")                        \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, Tier4CompileThreshold, 15000,                               \\\n-          \"Threshold at which tier 4 compilation is invoked (invocation \"   \\\n-          \"minimum must be satisfied)\")                                     \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, Tier4BackEdgeThreshold, 40000,                              \\\n-          \"Back edge threshold at which tier 4 OSR compilation is invoked\") \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  diagnostic(intx, Tier40InvocationThreshold, 5000,                         \\\n-          \"Compile if number of method invocations crosses this \"           \\\n-          \"threshold (applicable only with \"                                \\\n-          \"CompilationMode=high-only|high-only-quick-internal)\")            \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  diagnostic(intx, Tier40MinInvocationThreshold, 600,                       \\\n-          \"Minimum number of invocations to compile at tier 4 \"             \\\n-          \"(applicable only with \"                                          \\\n-          \"CompilationMode=high-only|high-only-quick-internal)\")            \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  diagnostic(intx, Tier40CompileThreshold, 10000,                           \\\n-          \"Threshold at which tier 4 compilation is invoked (invocation \"   \\\n-          \"minimum must be satisfied, applicable only with \"                \\\n-          \"CompilationMode=high-only|high-only-quick-internal)\")            \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  diagnostic(intx, Tier40BackEdgeThreshold, 15000,                          \\\n-          \"Back edge threshold at which tier 4 OSR compilation is invoked \" \\\n-          \"(applicable only with \"                                          \\\n-          \"CompilationMode=high-only|high-only-quick-internal)\")            \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  diagnostic(intx, Tier0Delay, 5,                                           \\\n-          \"If C2 queue size grows over this amount per compiler thread \"    \\\n-          \"do not start profiling in the interpreter \"                      \\\n-          \"(applicable only with \"                                          \\\n-          \"CompilationMode=high-only|high-only-quick-internal)\")            \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, Tier3DelayOn, 5,                                            \\\n-          \"If C2 queue size grows over this amount per compiler thread \"    \\\n-          \"stop compiling at tier 3 and start compiling at tier 2\")         \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, Tier3DelayOff, 2,                                           \\\n-          \"If C2 queue size is less than this amount per compiler thread \"  \\\n-          \"allow methods compiled at tier 2 transition to tier 3\")          \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, Tier3LoadFeedback, 5,                                       \\\n-          \"Tier 3 thresholds will increase twofold when C1 queue size \"     \\\n-          \"reaches this amount per compiler thread\")                        \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, Tier4LoadFeedback, 3,                                       \\\n-          \"Tier 4 thresholds will increase twofold when C2 queue size \"     \\\n-          \"reaches this amount per compiler thread\")                        \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(intx, TieredCompileTaskTimeout, 50,                               \\\n-          \"Kill compile task if method was not used within \"                \\\n-          \"given timeout in milliseconds\")                                  \\\n-          range(0, max_intx)                                                \\\n-                                                                            \\\n-  product(intx, TieredStopAtLevel, 4,                                       \\\n-          \"Stop at given compilation level\")                                \\\n-          range(0, 4)                                                       \\\n-                                                                            \\\n-  product(intx, Tier0ProfilingStartPercentage, 200,                         \\\n-          \"Start profiling in interpreter if the counters exceed tier 3 \"   \\\n-          \"thresholds (tier 4 thresholds with \"                             \\\n-          \"CompilationMode=high-only|high-only-quick-internal)\"             \\\n-          \"by the specified percentage\")                                    \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(uintx, IncreaseFirstTierCompileThresholdAt, 50,                   \\\n-          \"Increase the compile threshold for C1 compilation if the code \"  \\\n-          \"cache is filled by the specified percentage\")                    \\\n-          range(0, 99)                                                      \\\n-                                                                            \\\n-  product(intx, TieredRateUpdateMinTime, 1,                                 \\\n-          \"Minimum rate sampling interval (in milliseconds)\")               \\\n-          range(0, max_intx)                                                \\\n-                                                                            \\\n-  product(intx, TieredRateUpdateMaxTime, 25,                                \\\n-          \"Maximum rate sampling interval (in milliseconds)\")               \\\n-          range(0, max_intx)                                                \\\n-                                                                            \\\n-  product(ccstr, CompilationMode, \"default\",                                \\\n-          \"Compilation modes: \"                                             \\\n-          \"default: normal tiered compilation; \"                            \\\n-          \"quick-only: C1-only mode; \"                                      \\\n-          \"high-only: C2\/JVMCI-only mode; \"                                 \\\n-          \"high-only-quick-internal: C2\/JVMCI-only mode, \"                  \\\n-          \"with JVMCI compiler compiled with C1.\")                          \\\n-                                                                            \\\n@@ -2135,20 +1753,0 @@\n-  product(bool, PrintTieredEvents, false,                                   \\\n-          \"Print tiered events notifications\")                              \\\n-                                                                            \\\n-  product_pd(intx, OnStackReplacePercentage,                                \\\n-          \"NON_TIERED number of method invocations\/branches (expressed as \" \\\n-          \"% of CompileThreshold) before (re-)compiling OSR code\")          \\\n-          constraint(OnStackReplacePercentageConstraintFunc, AfterErgo)     \\\n-                                                                            \\\n-  product(intx, InterpreterProfilePercentage, 33,                           \\\n-          \"NON_TIERED number of method invocations\/branches (expressed as \" \\\n-          \"% of CompileThreshold) before profiling in the interpreter\")     \\\n-          range(0, 100)                                                     \\\n-                                                                            \\\n-  develop(intx, DesiredMethodLimit,  8000,                                  \\\n-          \"The desired maximum method size (in bytecodes) after inlining\")  \\\n-                                                                            \\\n-  develop(intx, HugeMethodLimit,  8000,                                     \\\n-          \"Don't compile methods larger than this if \"                      \\\n-          \"+DontCompileHugeMethods\")                                        \\\n-                                                                            \\\n@@ -2163,1 +1761,1 @@\n-  diagnostic(bool, UseNewCode, false,                                       \\\n+  product(bool, UseNewCode, false, DIAGNOSTIC,                              \\\n@@ -2166,1 +1764,1 @@\n-  diagnostic(bool, UseNewCode2, false,                                      \\\n+  product(bool, UseNewCode2, false, DIAGNOSTIC,                             \\\n@@ -2169,1 +1767,1 @@\n-  diagnostic(bool, UseNewCode3, false,                                      \\\n+  product(bool, UseNewCode3, false, DIAGNOSTIC,                             \\\n@@ -2172,0 +1770,14 @@\n+  notproduct(bool, UseDebuggerErgo, false,                                  \\\n+          \"Debugging Only: Adjust the VM to be more debugger-friendly. \"    \\\n+          \"Turns on the other UseDebuggerErgo* flags\")                      \\\n+                                                                            \\\n+  notproduct(bool, UseDebuggerErgo1, false,                                 \\\n+          \"Debugging Only: Enable workarounds for debugger induced \"        \\\n+          \"os::processor_id() >= os::processor_count() problems\")           \\\n+                                                                            \\\n+  notproduct(bool, UseDebuggerErgo2, false,                                 \\\n+          \"Debugging Only: Limit the number of spawned JVM threads\")        \\\n+                                                                            \\\n+  notproduct(bool, EnableJVMTIStackDepthAsserts, true,                      \\\n+          \"Enable JVMTI asserts related to stack depth checks\")             \\\n+                                                                            \\\n@@ -2228,1 +1840,1 @@\n-  manageable(bool, PrintConcurrentLocks, false,                             \\\n+  product(bool, PrintConcurrentLocks, false, MANAGEABLE,                    \\\n@@ -2250,0 +1862,3 @@\n+  product(bool, RecordDynamicDumpInfo, false,                               \\\n+          \"Record class info for jcmd VM.cds dynamic_dump\")                 \\\n+                                                                            \\\n@@ -2269,1 +1884,1 @@\n-  diagnostic(bool, AllowArchivingWithJavaAgent, false,                      \\\n+  product(bool, AllowArchivingWithJavaAgent, false, DIAGNOSTIC,             \\\n@@ -2272,1 +1887,1 @@\n-  diagnostic(bool, PrintMethodHandleStubs, false,                           \\\n+  product(bool, PrintMethodHandleStubs, false, DIAGNOSTIC,                  \\\n@@ -2275,1 +1890,1 @@\n-  diagnostic(bool, VerifyMethodHandles, trueInDebug,                        \\\n+  product(bool, VerifyMethodHandles, trueInDebug, DIAGNOSTIC,               \\\n@@ -2278,1 +1893,1 @@\n-  diagnostic(bool, ShowHiddenFrames, false,                                 \\\n+  product(bool, ShowHiddenFrames, false, DIAGNOSTIC,                        \\\n@@ -2281,1 +1896,1 @@\n-  experimental(bool, TrustFinalNonStaticFields, false,                      \\\n+  product(bool, TrustFinalNonStaticFields, false, EXPERIMENTAL,             \\\n@@ -2284,1 +1899,1 @@\n-  diagnostic(bool, FoldStableValues, true,                                  \\\n+  product(bool, FoldStableValues, true, DIAGNOSTIC,                         \\\n@@ -2287,1 +1902,1 @@\n-  diagnostic(int, UseBootstrapCallInfo, 1,                                  \\\n+  product(int, UseBootstrapCallInfo, 1, DIAGNOSTIC,                         \\\n@@ -2295,1 +1910,1 @@\n-  diagnostic(bool, PauseAtStartup,      false,                              \\\n+  product(bool, PauseAtStartup,      false, DIAGNOSTIC,                     \\\n@@ -2299,1 +1914,1 @@\n-  diagnostic(ccstr, PauseAtStartupFile, NULL,                               \\\n+  product(ccstr, PauseAtStartupFile, NULL, DIAGNOSTIC,                      \\\n@@ -2303,1 +1918,1 @@\n-  diagnostic(bool, PauseAtExit, false,                                      \\\n+  product(bool, PauseAtExit, false, DIAGNOSTIC,                             \\\n@@ -2326,1 +1941,1 @@\n-  experimental(uintx, SymbolTableSize, defaultSymbolTableSize,              \\\n+  product(uintx, SymbolTableSize, defaultSymbolTableSize, EXPERIMENTAL,     \\\n@@ -2333,1 +1948,1 @@\n-  product(uintx, StringDeduplicationAgeThreshold, 3,                        \\\n+  product(uint, StringDeduplicationAgeThreshold, 3,                         \\\n@@ -2338,2 +1953,3 @@\n-  diagnostic(bool, StringDeduplicationResizeALot, false,                    \\\n-          \"Force table resize every time the table is scanned\")             \\\n+  product(size_t, StringDeduplicationInitialTableSize, 500, EXPERIMENTAL,   \\\n+          \"Approximate initial number of buckets in the table\")             \\\n+          range(1, 1 * G)                                                   \\\n@@ -2341,2 +1957,3 @@\n-  diagnostic(bool, StringDeduplicationRehashALot, false,                    \\\n-          \"Force table rehash every time the table is scanned\")             \\\n+  product(double, StringDeduplicationGrowTableLoad, 14.0, EXPERIMENTAL,     \\\n+          \"Entries per bucket above which the table should be expanded\")    \\\n+          range(0.1, 1000.0)                                                \\\n@@ -2344,2 +1961,17 @@\n-  diagnostic(bool, WhiteBoxAPI, false,                                      \\\n-          \"Enable internal testing APIs\")                                   \\\n+  product(double, StringDeduplicationShrinkTableLoad, 1.0, EXPERIMENTAL,    \\\n+          \"Entries per bucket below which the table should be shrunk\")      \\\n+          range(0.01, 100.0)                                                \\\n+                                                                            \\\n+  product(double, StringDeduplicationTargetTableLoad, 7.0, EXPERIMENTAL,    \\\n+          \"Desired entries per bucket when resizing the table\")             \\\n+          range(0.01, 1000.0)                                               \\\n+                                                                            \\\n+  product(size_t, StringDeduplicationCleanupDeadMinimum, 100, EXPERIMENTAL, \\\n+          \"Minimum number of dead table entries for cleaning the table\")    \\\n+                                                                            \\\n+  product(int, StringDeduplicationCleanupDeadPercent, 5, EXPERIMENTAL,      \\\n+          \"Minimum percentage of dead table entries for cleaning the table\") \\\n+          range(1, 100)                                                     \\\n+                                                                            \\\n+  product(bool, StringDeduplicationResizeALot, false, DIAGNOSTIC,           \\\n+          \"Force more frequent table resizing\")                             \\\n@@ -2347,4 +1979,5 @@\n-  experimental(intx, SurvivorAlignmentInBytes, 0,                           \\\n-           \"Default survivor space alignment in bytes\")                     \\\n-           range(8, 256)                                                    \\\n-           constraint(SurvivorAlignmentInBytesConstraintFunc,AfterErgo)     \\\n+  product(uint64_t, StringDeduplicationHashSeed, 0, DIAGNOSTIC,             \\\n+          \"Seed for the table hashing function; 0 requests computed seed\")  \\\n+                                                                            \\\n+  product(bool, WhiteBoxAPI, false, DIAGNOSTIC,                             \\\n+          \"Enable internal testing APIs\")                                   \\\n@@ -2368,1 +2001,1 @@\n-  diagnostic(intx, ArchiveRelocationMode, 0,                                \\\n+  product(intx, ArchiveRelocationMode, 0, DIAGNOSTIC,                       \\\n@@ -2376,1 +2009,1 @@\n-  experimental(size_t, ArrayAllocatorMallocLimit, (size_t)-1,               \\\n+  product(size_t, ArrayAllocatorMallocLimit, (size_t)-1, EXPERIMENTAL,      \\\n@@ -2380,1 +2013,1 @@\n-  experimental(bool, AlwaysAtomicAccesses, false,                           \\\n+  product(bool, AlwaysAtomicAccesses, false, EXPERIMENTAL,                  \\\n@@ -2383,1 +2016,1 @@\n-  diagnostic(bool, UseUnalignedAccesses, false,                             \\\n+  product(bool, UseUnalignedAccesses, false, DIAGNOSTIC,                    \\\n@@ -2390,1 +2023,6 @@\n-  diagnostic(bool, CheckIntrinsics, true,                                   \\\n+  product(size_t, AsyncLogBufferSize, 2*M,                                  \\\n+          \"Memory budget (in bytes) for the buffer of Asynchronous \"        \\\n+          \"Logging (-Xlog:async).\")                                         \\\n+          range(100*K, 50*M)                                                \\\n+                                                                            \\\n+  product(bool, CheckIntrinsics, true, DIAGNOSTIC,                          \\\n@@ -2394,1 +2032,1 @@\n-             \"@HotSpotIntrinsicCandidate annotation, that \"                 \\\n+             \"@IntrinsicCandidate annotation, that \"                        \\\n@@ -2396,2 +2034,2 @@\n-             \"that are annotated with the @HotSpotIntrinsicCandidate \"      \\\n-             \"annotation, and that \"                                        \\\n+             \"that are annotated with the @IntrinsicCandidate annotation, \" \\\n+             \"and that \"                                                    \\\n@@ -2403,1 +2041,1 @@\n-  diagnostic_pd(intx, InitArrayShortSize,                                   \\\n+  product_pd(intx, InitArrayShortSize, DIAGNOSTIC,                          \\\n@@ -2410,9 +2048,1 @@\n-  diagnostic(bool, CompilerDirectivesIgnoreCompileCommands, false,          \\\n-             \"Disable backwards compatibility for compile commands.\")       \\\n-                                                                            \\\n-  diagnostic(bool, CompilerDirectivesPrint, false,                          \\\n-             \"Print compiler directives on installation.\")                  \\\n-  diagnostic(int,  CompilerDirectivesLimit, 50,                             \\\n-             \"Limit on number of compiler directives.\")                     \\\n-                                                                            \\\n-          \"Path to the directoy where a temporary file will be created \"    \\\n+          \"Path to the directory where a temporary file will be created \"   \\\n@@ -2422,6 +2052,0 @@\n-  experimental(ccstr, AllocateOldGenAt, NULL,                               \\\n-          \"Path to the directoy where a temporary file will be \"            \\\n-          \"created to use as the backing store for old generation.\"         \\\n-          \"File of size Xmx is pre-allocated for performance reason, so\"    \\\n-          \"we need that much space available\")                              \\\n-                                                                            \\\n@@ -2432,1 +2056,1 @@\n-  diagnostic(bool, ShowRegistersOnAssert, true,                             \\\n+  product(bool, ShowRegistersOnAssert, true, DIAGNOSTIC,                    \\\n@@ -2435,1 +2059,1 @@\n-  diagnostic(bool, UseSwitchProfiling, true,                                \\\n+  product(bool, UseSwitchProfiling, true, DIAGNOSTIC,                       \\\n@@ -2450,1 +2074,1 @@\n-  experimental(bool, UseFastUnorderedTimeStamps, false,                     \\\n+  product(bool, UseFastUnorderedTimeStamps, false, EXPERIMENTAL,            \\\n@@ -2453,3 +2077,0 @@\n-  product(bool, UseNewFieldLayout, true,                                    \\\n-               \"(Deprecated) Use new algorithm to compute field layouts\")   \\\n-                                                                            \\\n@@ -2459,1 +2080,1 @@\n-  diagnostic(bool, DeoptimizeNMethodBarriersALot, false,                    \\\n+  product(bool, DeoptimizeNMethodBarriersALot, false, DIAGNOSTIC,           \\\n@@ -2472,0 +2093,7 @@\n+  develop(bool, VerifyCrossModifyFence,                                     \\\n+          false AARCH64_ONLY(DEBUG_ONLY(||true)),                           \\\n+             \"Mark all threads after a safepoint, and clear on a modify \"   \\\n+             \"fence. Add cleanliness checks.\")                              \\\n+                                                                            \\\n+  develop(bool, TraceOptimizedUpcallStubs, false,                              \\\n+                \"Trace optimized upcall stub generation\")                      \\\n@@ -2473,23 +2101,1 @@\n-\/\/ Interface macros\n-#define DECLARE_PRODUCT_FLAG(type, name, value, doc)      extern \"C\" type name;\n-#define DECLARE_PD_PRODUCT_FLAG(type, name, doc)          extern \"C\" type name;\n-#define DECLARE_DIAGNOSTIC_FLAG(type, name, value, doc)   extern \"C\" type name;\n-#define DECLARE_PD_DIAGNOSTIC_FLAG(type, name, doc)       extern \"C\" type name;\n-#define DECLARE_EXPERIMENTAL_FLAG(type, name, value, doc) extern \"C\" type name;\n-#define DECLARE_MANAGEABLE_FLAG(type, name, value, doc)   extern \"C\" type name;\n-#define DECLARE_PRODUCT_RW_FLAG(type, name, value, doc)   extern \"C\" type name;\n-#ifdef PRODUCT\n-#define DECLARE_DEVELOPER_FLAG(type, name, value, doc)    const type name = value;\n-#define DECLARE_PD_DEVELOPER_FLAG(type, name, doc)        const type name = pd_##name;\n-#define DECLARE_NOTPRODUCT_FLAG(type, name, value, doc)   const type name = value;\n-#else\n-#define DECLARE_DEVELOPER_FLAG(type, name, value, doc)    extern \"C\" type name;\n-#define DECLARE_PD_DEVELOPER_FLAG(type, name, doc)        extern \"C\" type name;\n-#define DECLARE_NOTPRODUCT_FLAG(type, name, value, doc)   extern \"C\" type name;\n-#endif \/\/ PRODUCT\n-\/\/ Special LP64 flags, product only needed for now.\n-#ifdef _LP64\n-#define DECLARE_LP64_PRODUCT_FLAG(type, name, value, doc) extern \"C\" type name;\n-#else\n-#define DECLARE_LP64_PRODUCT_FLAG(type, name, value, doc) const type name = value;\n-#endif \/\/ _LP64\n+\/\/ end of RUNTIME_FLAGS\n@@ -2497,13 +2103,4 @@\n-ALL_FLAGS(DECLARE_DEVELOPER_FLAG,     \\\n-          DECLARE_PD_DEVELOPER_FLAG,  \\\n-          DECLARE_PRODUCT_FLAG,       \\\n-          DECLARE_PD_PRODUCT_FLAG,    \\\n-          DECLARE_DIAGNOSTIC_FLAG,    \\\n-          DECLARE_PD_DIAGNOSTIC_FLAG, \\\n-          DECLARE_EXPERIMENTAL_FLAG,  \\\n-          DECLARE_NOTPRODUCT_FLAG,    \\\n-          DECLARE_MANAGEABLE_FLAG,    \\\n-          DECLARE_PRODUCT_RW_FLAG,    \\\n-          DECLARE_LP64_PRODUCT_FLAG,  \\\n-          IGNORE_RANGE,               \\\n-          IGNORE_CONSTRAINT)\n+DECLARE_FLAGS(LP64_RUNTIME_FLAGS)\n+DECLARE_ARCH_FLAGS(ARCH_FLAGS)\n+DECLARE_FLAGS(RUNTIME_FLAGS)\n+DECLARE_FLAGS(RUNTIME_OS_FLAGS)\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":389,"deletions":792,"binary":false,"changes":1181,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,0 +29,1 @@\n+#include \"compiler\/compiler_globals.hpp\"\n@@ -35,0 +36,1 @@\n+#include \"logging\/logAsyncWriter.hpp\"\n@@ -37,0 +39,1 @@\n+#include \"prims\/jvmtiExport.hpp\"\n@@ -38,0 +41,2 @@\n+#include \"prims\/universalNativeInvoker.hpp\"\n+#include \"runtime\/globals.hpp\"\n@@ -53,1 +58,1 @@\n-void oopstorage_init();\n+void universe_oopstorage_init();\n@@ -72,1 +77,0 @@\n-void invocationCounter_init(); \/\/ after methods loaded, but before they are linked\n@@ -85,0 +89,1 @@\n+void dependencies_init();\n@@ -103,1 +108,1 @@\n-  oopstorage_init();\n+  universe_oopstorage_init();\n@@ -109,1 +114,1 @@\n-  HandleMark hm;\n+  JvmtiExport::initialize_oop_storage();\n@@ -116,1 +121,1 @@\n-  VM_Version_init();\n+  VM_Version_init();              \/\/ depends on codeCache_init for emitting code\n@@ -130,0 +135,1 @@\n+  AsyncLogWriter::initialize();\n@@ -139,1 +145,0 @@\n-  invocationCounter_init(); \/\/ after javaClasses_init and before any method gets linked\n@@ -150,0 +155,1 @@\n+  dependencies_init();\n@@ -183,11 +189,0 @@\n-    if (log_is_enabled(Info, monitorinflation)) {\n-      \/\/ The ObjectMonitor subsystem uses perf counters so\n-      \/\/ do this before perfMemory_exit().\n-      \/\/ These other two audit_and_print_stats() calls are done at the\n-      \/\/ Debug level at a safepoint:\n-      \/\/ - for safepoint based deflation auditing:\n-      \/\/   ObjectSynchronizer::finish_deflate_idle_monitors()\n-      \/\/ - for async deflation auditing:\n-      \/\/   ObjectSynchronizer::do_safepoint_work()\n-      ObjectSynchronizer::audit_and_print_stats(true \/* on_exit *\/);\n-    }\n","filename":"src\/hotspot\/share\/runtime\/init.cpp","additions":13,"deletions":18,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,0 +26,1 @@\n+#include \"gc\/shared\/gc_globals.hpp\"\n@@ -44,1 +45,0 @@\n-Mutex*   ProtectionDomainSet_lock     = NULL;\n@@ -55,0 +55,1 @@\n+Monitor* EscapeBarrier_lock           = NULL;\n@@ -61,2 +62,2 @@\n-Monitor* StringDedupQueue_lock        = NULL;\n-Mutex*   StringDedupTable_lock        = NULL;\n+Monitor* StringDedup_lock             = NULL;\n+Mutex*   StringDedupIntern_lock       = NULL;\n@@ -68,2 +69,1 @@\n-Monitor* VMOperationQueue_lock        = NULL;\n-Monitor* VMOperationRequest_lock      = NULL;\n+Monitor* VMOperation_lock             = NULL;\n@@ -75,1 +75,0 @@\n-Monitor* FullGCCount_lock             = NULL;\n@@ -116,0 +115,1 @@\n+Mutex*   Uncommit_lock                = NULL;\n@@ -119,0 +119,1 @@\n+Monitor* MonitorDeflation_lock        = NULL;\n@@ -143,1 +144,1 @@\n-Mutex*   MetaspaceExpand_lock         = NULL;\n+Mutex*   Metaspace_lock               = NULL;\n@@ -158,0 +159,3 @@\n+Mutex*   DumpRegion_lock              = NULL;\n+Mutex*   ClassListFile_lock           = NULL;\n+Mutex*   LambdaFormInvokers_lock      = NULL;\n@@ -159,0 +163,1 @@\n+Mutex*   Bootclasspath_lock           = NULL;\n@@ -176,3 +181,0 @@\n-  \/\/ see if invoker of VM operation owns it\n-  VM_Operation* op = VMThread::vm_operation();\n-  if (op != NULL && op->calling_thread() == lock->owner()) return;\n@@ -199,1 +201,1 @@\n-  if (Thread::current() == thread->active_handshaker()) return;\n+  if (thread->is_handshake_safe_for(Thread::current())) return;\n@@ -217,1 +219,0 @@\n-  def(FullGCCount_lock             , PaddedMonitor, leaf,        true,  _safepoint_check_never);      \/\/ in support of ExplicitGCInvokesConcurrent\n@@ -227,0 +228,1 @@\n+    def(Uncommit_lock              , PaddedMutex  , leaf + 1 ,   true,  _safepoint_check_never);\n@@ -229,3 +231,0 @@\n-    def(StringDedupQueue_lock      , PaddedMonitor, leaf,        true,  _safepoint_check_never);\n-    def(StringDedupTable_lock      , PaddedMutex  , leaf,        true,  _safepoint_check_never);\n-\n@@ -237,4 +236,2 @@\n-  if (UseShenandoahGC) {\n-    def(StringDedupQueue_lock      , PaddedMonitor, leaf,        true,  _safepoint_check_never);\n-    def(StringDedupTable_lock      , PaddedMutex  , leaf + 1,    true,  _safepoint_check_never);\n-  }\n+  def(StringDedup_lock             , PaddedMonitor, leaf,        true,  _safepoint_check_never);\n+  def(StringDedupIntern_lock       , PaddedMutex  , leaf,        true,  _safepoint_check_never);\n@@ -247,1 +244,1 @@\n-  def(MetaspaceExpand_lock         , PaddedMutex  , leaf-1,      true,  _safepoint_check_never);\n+  def(Metaspace_lock               , PaddedMutex  , leaf-1,      true,  _safepoint_check_never);\n@@ -252,1 +249,2 @@\n-  def(Service_lock                 , PaddedMonitor, special,     true,  _safepoint_check_never);      \/\/ used for service thread operations\n+  def(MonitorDeflation_lock        , PaddedMonitor, tty-2,       true,  _safepoint_check_never);      \/\/ used for monitor deflation thread operations\n+  def(Service_lock                 , PaddedMonitor, tty-2,       true,  _safepoint_check_never);      \/\/ used for service thread operations\n@@ -260,1 +258,1 @@\n-  def(JmethodIdCreation_lock       , PaddedMutex  , leaf,        true,  _safepoint_check_never); \/\/ used for creating jmethodIDs.\n+  def(JmethodIdCreation_lock       , PaddedMutex  , special-2,   true,  _safepoint_check_never); \/\/ used for creating jmethodIDs.\n@@ -263,1 +261,0 @@\n-  def(ProtectionDomainSet_lock     , PaddedMutex  , leaf-1,      true,  _safepoint_check_never);\n@@ -286,2 +283,1 @@\n-  def(VMOperationQueue_lock        , PaddedMonitor, nonleaf,     true,  _safepoint_check_never);  \/\/ VM_thread allowed to block on these\n-  def(VMOperationRequest_lock      , PaddedMonitor, nonleaf,     true,  _safepoint_check_always);\n+  def(VMOperation_lock             , PaddedMonitor, nonleaf,     true,  _safepoint_check_always);  \/\/ VM_thread allowed to block on these\n@@ -296,1 +292,1 @@\n-  def(Heap_lock                    , PaddedMonitor, nonleaf+1,   false, _safepoint_check_sometimes);  \/\/ Doesn't safepoint check during termination.\n+  def(Heap_lock                    , PaddedMonitor, nonleaf+1,   false, _safepoint_check_always); \/\/ Doesn't safepoint check during termination.\n@@ -306,0 +302,1 @@\n+  def(EscapeBarrier_lock           , PaddedMonitor, leaf,        false, _safepoint_check_never);  \/\/ Used to synchronize object reallocation\/relocking triggered by JVMTI\n@@ -330,1 +327,1 @@\n-  def(JfrStacktrace_lock           , PaddedMutex  , special - 1, true,  _safepoint_check_never);\n+  def(JfrStacktrace_lock           , PaddedMutex  , tty-2,       true,  _safepoint_check_never);\n@@ -342,1 +339,1 @@\n-  def(CodeHeapStateAnalytics_lock  , PaddedMutex  , leaf,        true,  _safepoint_check_never);\n+  def(CodeHeapStateAnalytics_lock  , PaddedMutex  , nonleaf+6,   false, _safepoint_check_always);\n@@ -355,1 +352,1 @@\n-  def(DumpTimeTable_lock           , PaddedMutex  , leaf - 1,        true,  _safepoint_check_never);\n+  def(DumpTimeTable_lock           , PaddedMutex  , leaf - 1,    true,  _safepoint_check_never);\n@@ -357,0 +354,3 @@\n+  def(DumpRegion_lock              , PaddedMutex  , leaf,        true,  _safepoint_check_never);\n+  def(ClassListFile_lock           , PaddedMutex  , leaf,        true,  _safepoint_check_never);\n+  def(LambdaFormInvokers_lock      , PaddedMutex  , nonleaf+2,   false, _safepoint_check_always);\n@@ -358,0 +358,1 @@\n+  def(Bootclasspath_lock           , PaddedMutex  , leaf,        false, _safepoint_check_never);\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.cpp","additions":31,"deletions":30,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -37,1 +37,0 @@\n-extern Mutex*   ProtectionDomainSet_lock;        \/\/ a lock on the pd_set list in the system dictionary\n@@ -48,0 +47,1 @@\n+extern Monitor* EscapeBarrier_lock;              \/\/ a lock to sync reallocating and relocking objects because of JVMTI access\n@@ -54,2 +54,2 @@\n-extern Monitor* StringDedupQueue_lock;           \/\/ a lock on the string deduplication queue\n-extern Mutex*   StringDedupTable_lock;           \/\/ a lock on the string deduplication table\n+extern Monitor* StringDedup_lock;                \/\/ a lock on the string deduplication facility\n+extern Mutex*   StringDedupIntern_lock;          \/\/ a lock on StringTable notification of StringDedup\n@@ -61,2 +61,1 @@\n-extern Monitor* VMOperationQueue_lock;           \/\/ a lock on queue of vm_operations waiting to execute\n-extern Monitor* VMOperationRequest_lock;         \/\/ a lock on Threads waiting for a vm_operation to terminate\n+extern Monitor* VMOperation_lock;                \/\/ a lock on queue of vm_operations waiting to execute\n@@ -70,1 +69,0 @@\n-extern Monitor* FullGCCount_lock;                \/\/ in support of \"concurrent\" full gc\n@@ -111,0 +109,1 @@\n+extern Mutex*   Uncommit_lock;                   \/\/ protects the uncommit list when not at safepoints\n@@ -114,0 +113,1 @@\n+extern Monitor* MonitorDeflation_lock;           \/\/ a lock used for monitor deflation thread operation\n@@ -133,0 +133,3 @@\n+extern Mutex*   DumpRegion_lock;                 \/\/ Symbol::operator new(size_t sz, int len)\n+extern Mutex*   ClassListFile_lock;              \/\/ ClassListWriter()\n+extern Mutex*   LambdaFormInvokers_lock;         \/\/ Protecting LambdaFormInvokers::_lambdaform_lines\n@@ -149,1 +152,1 @@\n-extern Mutex*   MetaspaceExpand_lock;            \/\/ protects Metaspace virtualspace and chunk expansions\n+extern Mutex*   Metaspace_lock;            \/\/ protects Metaspace virtualspace and chunk expansions\n@@ -160,0 +163,2 @@\n+extern Mutex*   Bootclasspath_lock;\n+\n@@ -198,1 +203,0 @@\n- private:\n@@ -242,1 +246,6 @@\n-  Monitor* _monitor;\n+\n+ protected:\n+  Monitor* as_monitor() const {\n+    return static_cast<Monitor*>(_mutex);\n+  }\n+\n@@ -245,1 +254,1 @@\n-    MutexLocker(monitor, flag), _flag(flag), _monitor(monitor) {\n+    MutexLocker(monitor, flag), _flag(flag) {\n@@ -247,1 +256,1 @@\n-    assert(_monitor != NULL, \"NULL monitor not allowed\");\n+    assert(monitor != NULL, \"NULL monitor not allowed\");\n@@ -251,1 +260,1 @@\n-    MutexLocker(thread, monitor, flag), _flag(flag), _monitor(monitor)  {\n+    MutexLocker(thread, monitor, flag), _flag(flag) {\n@@ -253,1 +262,1 @@\n-    assert(_monitor != NULL, \"NULL monitor not allowed\");\n+    assert(monitor != NULL, \"NULL monitor not allowed\");\n@@ -256,2 +265,1 @@\n-  bool wait(long timeout = 0,\n-            bool as_suspend_equivalent = !Mutex::_as_suspend_equivalent_flag) {\n+  bool wait(int64_t timeout = 0) {\n@@ -259,1 +267,1 @@\n-      return _monitor->wait(timeout, as_suspend_equivalent);\n+      return as_monitor()->wait(timeout);\n@@ -261,1 +269,1 @@\n-      return _monitor->wait_without_safepoint_check(timeout);\n+      return as_monitor()->wait_without_safepoint_check(timeout);\n@@ -267,1 +275,1 @@\n-    _monitor->notify_all();\n+    as_monitor()->notify_all();\n@@ -271,1 +279,1 @@\n-    _monitor->notify();\n+    as_monitor()->notify();\n@@ -302,1 +310,1 @@\n-    _no_safepoint_check(flag) {\n+    _no_safepoint_check(flag == Mutex::_no_safepoint_check_flag) {\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.hpp","additions":29,"deletions":21,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,0 +26,1 @@\n+#include \"classfile\/javaClasses.hpp\"\n@@ -27,2 +28,1 @@\n-#include \"aot\/aotLoader.hpp\"\n-#include \"classfile\/systemDictionary.hpp\"\n+#include \"classfile\/vmClasses.hpp\"\n@@ -41,0 +41,1 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n@@ -46,1 +47,0 @@\n-#include \"memory\/metaspaceShared.hpp\"\n@@ -49,0 +49,1 @@\n+#include \"oops\/compiledICHolder.inline.hpp\"\n@@ -57,1 +58,0 @@\n-#include \"runtime\/arguments.hpp\"\n@@ -67,0 +67,1 @@\n+#include \"runtime\/stackWatermarkSet.hpp\"\n@@ -71,0 +72,1 @@\n+#include \"runtime\/vm_version.hpp\"\n@@ -114,0 +116,2 @@\n+  AdapterHandlerLibrary::initialize();\n+\n@@ -146,11 +150,10 @@\n-int SharedRuntime::_nof_normal_calls = 0;\n-int SharedRuntime::_nof_optimized_calls = 0;\n-int SharedRuntime::_nof_inlined_calls = 0;\n-int SharedRuntime::_nof_megamorphic_calls = 0;\n-int SharedRuntime::_nof_static_calls = 0;\n-int SharedRuntime::_nof_inlined_static_calls = 0;\n-int SharedRuntime::_nof_interface_calls = 0;\n-int SharedRuntime::_nof_optimized_interface_calls = 0;\n-int SharedRuntime::_nof_inlined_interface_calls = 0;\n-int SharedRuntime::_nof_megamorphic_interface_calls = 0;\n-int SharedRuntime::_nof_removable_exceptions = 0;\n+int64_t SharedRuntime::_nof_normal_calls = 0;\n+int64_t SharedRuntime::_nof_optimized_calls = 0;\n+int64_t SharedRuntime::_nof_inlined_calls = 0;\n+int64_t SharedRuntime::_nof_megamorphic_calls = 0;\n+int64_t SharedRuntime::_nof_static_calls = 0;\n+int64_t SharedRuntime::_nof_inlined_static_calls = 0;\n+int64_t SharedRuntime::_nof_interface_calls = 0;\n+int64_t SharedRuntime::_nof_optimized_interface_calls = 0;\n+int64_t SharedRuntime::_nof_inlined_interface_calls = 0;\n+int64_t SharedRuntime::_nof_megamorphic_interface_calls = 0;\n@@ -460,1 +463,7 @@\n-address SharedRuntime::raw_exception_handler_for_return_address(JavaThread* thread, address return_address) {\n+address SharedRuntime::raw_exception_handler_for_return_address(JavaThread* current, address return_address) {\n+  \/\/ Note: This is called when we have unwound the frame of the callee that did\n+  \/\/ throw an exception. So far, no check has been performed by the StackWatermarkSet.\n+  \/\/ Notably, the stack is not walkable at this point, and hence the check must\n+  \/\/ be deferred until later. Specifically, any of the handlers returned here in\n+  \/\/ this function, will get dispatched to, and call deferred checks to\n+  \/\/ StackWatermarkSet::after_unwind at a point where the stack is walkable.\n@@ -462,1 +471,1 @@\n-  assert(thread->frames_to_pop_failed_realloc() == 0 || Interpreter::contains(return_address), \"missed frames to pop?\");\n+  assert(current->frames_to_pop_failed_realloc() == 0 || Interpreter::contains(return_address), \"missed frames to pop?\");\n@@ -465,1 +474,1 @@\n-  thread->set_is_method_handle_return(false);\n+  current->set_is_method_handle_return(false);\n@@ -470,1 +479,1 @@\n-  thread->set_exception_pc(NULL);\n+  current->set_exception_pc(NULL);\n@@ -478,1 +487,1 @@\n-    thread->set_is_method_handle_return(nm->is_method_handle_return(return_address));\n+    current->set_is_method_handle_return(nm->is_method_handle_return(return_address));\n@@ -487,4 +496,4 @@\n-      bool guard_pages_enabled = thread->stack_guards_enabled();\n-      if (!guard_pages_enabled) guard_pages_enabled = thread->reguard_stack();\n-      if (thread->reserved_stack_activation() != thread->stack_base()) {\n-        thread->set_reserved_stack_activation(thread->stack_base());\n+      StackOverflow* overflow_state = current->stack_overflow_state();\n+      bool guard_pages_enabled = overflow_state->reguard_stack_if_needed();\n+      if (overflow_state->reserved_stack_activation() != current->stack_base()) {\n+        overflow_state->set_reserved_stack_activation(current->stack_base());\n@@ -493,0 +502,2 @@\n+      \/\/ The deferred StackWatermarkSet::after_unwind check will be performed in\n+      \/\/ Deoptimization::fetch_unroll_info (with exec_mode == Unpack_exception)\n@@ -495,0 +506,3 @@\n+      \/\/ The deferred StackWatermarkSet::after_unwind check will be performed in\n+      \/\/ * OptoRuntime::rethrow_C for C2 code\n+      \/\/ * exception_handler_for_pc_helper via Runtime1::handle_exception_from_callee_id for C1 code\n@@ -501,0 +515,2 @@\n+    \/\/ The deferred StackWatermarkSet::after_unwind check will be performed in\n+    \/\/ JavaCallWrapper::~JavaCallWrapper\n@@ -503,0 +519,3 @@\n+  if (blob != NULL && blob->is_optimized_entry_blob()) {\n+    return ((OptimizedEntryBlob*)blob)->exception_handler();\n+  }\n@@ -505,0 +524,2 @@\n+    \/\/ The deferred StackWatermarkSet::after_unwind check will be performed in\n+    \/\/ InterpreterRuntime::exception_handler_for_exception\n@@ -524,2 +545,2 @@\n-JRT_LEAF(address, SharedRuntime::exception_handler_for_return_address(JavaThread* thread, address return_address))\n-  return raw_exception_handler_for_return_address(thread, return_address);\n+JRT_LEAF(address, SharedRuntime::exception_handler_for_return_address(JavaThread* current, address return_address))\n+  return raw_exception_handler_for_return_address(current, return_address);\n@@ -582,1 +603,1 @@\n-void SharedRuntime::throw_and_post_jvmti_exception(JavaThread *thread, Handle h_exception) {\n+void SharedRuntime::throw_and_post_jvmti_exception(JavaThread* current, Handle h_exception) {\n@@ -584,2 +605,2 @@\n-    vframeStream vfst(thread, true);\n-    methodHandle method = methodHandle(thread, vfst.method());\n+    vframeStream vfst(current, true);\n+    methodHandle method = methodHandle(current, vfst.method());\n@@ -587,1 +608,21 @@\n-    JvmtiExport::post_exception_throw(thread, method(), bcp, h_exception());\n+    JvmtiExport::post_exception_throw(current, method(), bcp, h_exception());\n+  }\n+\n+#if INCLUDE_JVMCI\n+  if (EnableJVMCI && UseJVMCICompiler) {\n+    vframeStream vfst(current, true);\n+    methodHandle method = methodHandle(current, vfst.method());\n+    int bci = vfst.bci();\n+    MethodData* trap_mdo = method->method_data();\n+    if (trap_mdo != NULL) {\n+      \/\/ Set exception_seen if the exceptional bytecode is an invoke\n+      Bytecode_invoke call = Bytecode_invoke_check(method, bci);\n+      if (call.is_valid()) {\n+        ResourceMark rm(current);\n+        ProfileData* pdata = trap_mdo->allocate_bci_to_data(bci, NULL);\n+        if (pdata != NULL && pdata->is_BitData()) {\n+          BitData* bit_data = (BitData*) pdata;\n+          bit_data->set_exception_seen();\n+        }\n+      }\n+    }\n@@ -589,1 +630,3 @@\n-  Exceptions::_throw(thread, __FILE__, __LINE__, h_exception);\n+#endif\n+\n+  Exceptions::_throw(current, __FILE__, __LINE__, h_exception);\n@@ -592,3 +635,3 @@\n-void SharedRuntime::throw_and_post_jvmti_exception(JavaThread *thread, Symbol* name, const char *message) {\n-  Handle h_exception = Exceptions::new_exception(thread, name, message);\n-  throw_and_post_jvmti_exception(thread, h_exception);\n+void SharedRuntime::throw_and_post_jvmti_exception(JavaThread* current, Symbol* name, const char *message) {\n+  Handle h_exception = Exceptions::new_exception(current, name, message);\n+  throw_and_post_jvmti_exception(current, h_exception);\n@@ -720,1 +763,1 @@\n-JRT_ENTRY(void, SharedRuntime::throw_AbstractMethodError(JavaThread* thread))\n+JRT_ENTRY(void, SharedRuntime::throw_AbstractMethodError(JavaThread* current))\n@@ -722,1 +765,1 @@\n-  throw_and_post_jvmti_exception(thread, vmSymbols::java_lang_AbstractMethodError());\n+  throw_and_post_jvmti_exception(current, vmSymbols::java_lang_AbstractMethodError());\n@@ -725,1 +768,1 @@\n-JRT_ENTRY(void, SharedRuntime::throw_IncompatibleClassChangeError(JavaThread* thread))\n+JRT_ENTRY(void, SharedRuntime::throw_IncompatibleClassChangeError(JavaThread* current))\n@@ -727,1 +770,1 @@\n-  throw_and_post_jvmti_exception(thread, vmSymbols::java_lang_IncompatibleClassChangeError(), \"vtable stub\");\n+  throw_and_post_jvmti_exception(current, vmSymbols::java_lang_IncompatibleClassChangeError(), \"vtable stub\");\n@@ -730,2 +773,2 @@\n-JRT_ENTRY(void, SharedRuntime::throw_ArithmeticException(JavaThread* thread))\n-  throw_and_post_jvmti_exception(thread, vmSymbols::java_lang_ArithmeticException(), \"\/ by zero\");\n+JRT_ENTRY(void, SharedRuntime::throw_ArithmeticException(JavaThread* current))\n+  throw_and_post_jvmti_exception(current, vmSymbols::java_lang_ArithmeticException(), \"\/ by zero\");\n@@ -734,2 +777,2 @@\n-JRT_ENTRY(void, SharedRuntime::throw_NullPointerException(JavaThread* thread))\n-  throw_and_post_jvmti_exception(thread, vmSymbols::java_lang_NullPointerException());\n+JRT_ENTRY(void, SharedRuntime::throw_NullPointerException(JavaThread* current))\n+  throw_and_post_jvmti_exception(current, vmSymbols::java_lang_NullPointerException(), NULL);\n@@ -738,1 +781,1 @@\n-JRT_ENTRY(void, SharedRuntime::throw_NullPointerException_at_call(JavaThread* thread))\n+JRT_ENTRY(void, SharedRuntime::throw_NullPointerException_at_call(JavaThread* current))\n@@ -741,1 +784,1 @@\n-  throw_and_post_jvmti_exception(thread, vmSymbols::java_lang_NullPointerException());\n+  throw_and_post_jvmti_exception(current, vmSymbols::java_lang_NullPointerException(), NULL);\n@@ -744,2 +787,2 @@\n-JRT_ENTRY(void, SharedRuntime::throw_StackOverflowError(JavaThread* thread))\n-  throw_StackOverflowError_common(thread, false);\n+JRT_ENTRY(void, SharedRuntime::throw_StackOverflowError(JavaThread* current))\n+  throw_StackOverflowError_common(current, false);\n@@ -748,2 +791,2 @@\n-JRT_ENTRY(void, SharedRuntime::throw_delayed_StackOverflowError(JavaThread* thread))\n-  throw_StackOverflowError_common(thread, true);\n+JRT_ENTRY(void, SharedRuntime::throw_delayed_StackOverflowError(JavaThread* current))\n+  throw_StackOverflowError_common(current, true);\n@@ -752,1 +795,1 @@\n-void SharedRuntime::throw_StackOverflowError_common(JavaThread* thread, bool delayed) {\n+void SharedRuntime::throw_StackOverflowError_common(JavaThread* current, bool delayed) {\n@@ -755,2 +798,2 @@\n-  Thread* THREAD = thread;\n-  Klass* k = SystemDictionary::StackOverflowError_klass();\n+  JavaThread* THREAD = current; \/\/ For exception macros.\n+  Klass* k = vmClasses::StackOverflowError_klass();\n@@ -762,1 +805,1 @@\n-  Handle exception (thread, exception_oop);\n+  Handle exception (current, exception_oop);\n@@ -768,1 +811,1 @@\n-  throw_and_post_jvmti_exception(thread, exception);\n+  throw_and_post_jvmti_exception(current, exception);\n@@ -771,1 +814,1 @@\n-address SharedRuntime::continuation_for_implicit_exception(JavaThread* thread,\n+address SharedRuntime::continuation_for_implicit_exception(JavaThread* current,\n@@ -778,4 +821,0 @@\n-#ifdef CC_INTERP\n-    \/\/ C++ interpreter doesn't throw implicit exceptions\n-    ShouldNotReachHere();\n-#else\n@@ -788,1 +827,0 @@\n-#endif \/\/ !CC_INTERP\n@@ -802,2 +840,2 @@\n-        assert(thread->deopt_mark() == NULL, \"no stack overflow from deopt blob\/uncommon trap\");\n-        Events::log_exception(thread, \"StackOverflowError at \" INTPTR_FORMAT, p2i(pc));\n+        assert(current->deopt_mark() == NULL, \"no stack overflow from deopt blob\/uncommon trap\");\n+        Events::log_exception(current, \"StackOverflowError at \" INTPTR_FORMAT, p2i(pc));\n@@ -820,1 +858,1 @@\n-            Events::log_exception(thread, \"AbstractMethodError at \" INTPTR_FORMAT, p2i(pc));\n+            Events::log_exception(current, \"AbstractMethodError at \" INTPTR_FORMAT, p2i(pc));\n@@ -826,1 +864,1 @@\n-            Events::log_exception(thread, \"NullPointerException at vtable entry \" INTPTR_FORMAT, p2i(pc));\n+            Events::log_exception(current, \"NullPointerException at vtable entry \" INTPTR_FORMAT, p2i(pc));\n@@ -849,1 +887,1 @@\n-            Events::log_exception(thread, \"NullPointerException in code blob at \" INTPTR_FORMAT, p2i(pc));\n+            Events::log_exception(current, \"NullPointerException in code blob at \" INTPTR_FORMAT, p2i(pc));\n@@ -861,1 +899,1 @@\n-            Events::log_exception(thread, \"NullPointerException in IC check \" INTPTR_FORMAT, p2i(pc));\n+            Events::log_exception(current, \"NullPointerException in IC check \" INTPTR_FORMAT, p2i(pc));\n@@ -867,1 +905,1 @@\n-            Events::log_exception(thread, \"NullPointerException in MH adapter \" INTPTR_FORMAT, p2i(pc));\n+            Events::log_exception(current, \"NullPointerException in MH adapter \" INTPTR_FORMAT, p2i(pc));\n@@ -907,1 +945,1 @@\n-      Events::log_exception(thread, \"Implicit null exception at \" INTPTR_FORMAT \" to \" INTPTR_FORMAT, p2i(pc), p2i(target_pc));\n+      Events::log_exception(current, \"Implicit null exception at \" INTPTR_FORMAT \" to \" INTPTR_FORMAT, p2i(pc), p2i(target_pc));\n@@ -913,1 +951,1 @@\n-      Events::log_exception(thread, \"Implicit division by zero exception at \" INTPTR_FORMAT \" to \" INTPTR_FORMAT, p2i(pc), p2i(target_pc));\n+      Events::log_exception(current, \"Implicit division by zero exception at \" INTPTR_FORMAT \" to \" INTPTR_FORMAT, p2i(pc), p2i(target_pc));\n@@ -947,1 +985,1 @@\n-JRT_ENTRY_NO_ASYNC(void, SharedRuntime::register_finalizer(JavaThread* thread, oopDesc* obj))\n+JRT_ENTRY_NO_ASYNC(void, SharedRuntime::register_finalizer(JavaThread* current, oopDesc* obj))\n@@ -958,1 +996,0 @@\n-\n@@ -962,1 +999,1 @@\n-      oop obj = ((JavaThread*)thread)->threadObj();\n+      oop obj = thread->as_Java_thread()->threadObj();\n@@ -989,1 +1026,1 @@\n-    JavaThread* thread, Method* method))\n+    JavaThread* current, Method* method))\n@@ -995,1 +1032,1 @@\n-      get_java_tid(thread),\n+      get_java_tid(current),\n@@ -1003,1 +1040,1 @@\n-    JavaThread* thread, Method* method))\n+    JavaThread* current, Method* method))\n@@ -1009,1 +1046,1 @@\n-      get_java_tid(thread),\n+      get_java_tid(current),\n@@ -1030,1 +1067,1 @@\n-JRT_ENTRY(void, SharedRuntime::tsan_interp_method_entry(JavaThread *thread))\n+JRT_ENTRY(void, SharedRuntime::tsan_interp_method_entry(JavaThread* current))\n@@ -1035,1 +1072,1 @@\n-  RegisterMap unused_reg_map(thread, false);\n+  RegisterMap unused_reg_map(current, false);\n@@ -1039,1 +1076,1 @@\n-  assert(!thread->last_frame().is_compiled_frame(),\n+  assert(!current->last_frame().is_compiled_frame(),\n@@ -1041,1 +1078,1 @@\n-  const frame sender = thread->last_frame().real_sender(&unused_reg_map);\n+  const frame sender = current->last_frame().real_sender(&unused_reg_map);\n@@ -1191,2 +1228,3 @@\n-Handle SharedRuntime::find_callee_info(JavaThread* thread, Bytecodes::Code& bc, CallInfo& callinfo, TRAPS) {\n-  ResourceMark rm(THREAD);\n+Handle SharedRuntime::find_callee_info(Bytecodes::Code& bc, CallInfo& callinfo, TRAPS) {\n+  JavaThread* current = THREAD;\n+  ResourceMark rm(current);\n@@ -1195,1 +1233,1 @@\n-  vframeStream vfst(thread, true);  \/\/ Do not skip and javaCalls\n+  vframeStream vfst(current, true);  \/\/ Do not skip and javaCalls\n@@ -1197,1 +1235,1 @@\n-  return find_callee_info_helper(thread, vfst, bc, callinfo, THREAD);\n+  return find_callee_info_helper(vfst, bc, callinfo, THREAD);\n@@ -1216,3 +1254,1 @@\n-Handle SharedRuntime::find_callee_info_helper(JavaThread* thread,\n-                                              vframeStream& vfst,\n-                                              Bytecodes::Code& bc,\n+Handle SharedRuntime::find_callee_info_helper(vframeStream& vfst, Bytecodes::Code& bc,\n@@ -1221,1 +1257,2 @@\n-  Handle nullHandle;  \/\/create a handy null handle for exception returns\n+  Handle nullHandle;  \/\/ create a handy null handle for exception returns\n+  JavaThread* current = THREAD;\n@@ -1226,1 +1263,1 @@\n-  methodHandle caller(THREAD, vfst.method());\n+  methodHandle caller(current, vfst.method());\n@@ -1233,1 +1270,1 @@\n-  methodHandle attached_method(THREAD, extract_attached_method(vfst));\n+  methodHandle attached_method(current, extract_attached_method(vfst));\n@@ -1277,2 +1314,2 @@\n-    RegisterMap reg_map2(thread);\n-    frame stubFrame   = thread->last_frame();\n+    RegisterMap reg_map2(current);\n+    frame stubFrame   = current->last_frame();\n@@ -1290,1 +1327,1 @@\n-    receiver = Handle(THREAD, callerFrame.retrieve_receiver(&reg_map2));\n+    receiver = Handle(current, callerFrame.retrieve_receiver(&reg_map2));\n@@ -1303,1 +1340,1 @@\n-    constantPoolHandle constants(THREAD, caller->constants());\n+    constantPoolHandle constants(current, caller->constants());\n@@ -1318,1 +1355,1 @@\n-      constantPoolHandle constants(THREAD, caller->constants());\n+      constantPoolHandle constants(current, caller->constants());\n@@ -1337,2 +1374,3 @@\n-methodHandle SharedRuntime::find_callee_method(JavaThread* thread, TRAPS) {\n-  ResourceMark rm(THREAD);\n+methodHandle SharedRuntime::find_callee_method(TRAPS) {\n+  JavaThread* current = THREAD;\n+  ResourceMark rm(current);\n@@ -1342,1 +1380,1 @@\n-  vframeStream vfst(thread, true);  \/\/ Do not skip any javaCalls\n+  vframeStream vfst(current, true);  \/\/ Do not skip any javaCalls\n@@ -1348,2 +1386,2 @@\n-    RegisterMap reg_map(thread, false);\n-    frame fr = thread->last_frame();\n+    RegisterMap reg_map(current, false);\n+    frame fr = current->last_frame();\n@@ -1354,1 +1392,1 @@\n-    callee_method = methodHandle(THREAD, fr.entry_frame_call_wrapper()->callee_method());\n+    callee_method = methodHandle(current, fr.entry_frame_call_wrapper()->callee_method());\n@@ -1358,2 +1396,2 @@\n-    find_callee_info_helper(thread, vfst, bc, callinfo, CHECK_(methodHandle()));\n-    callee_method = methodHandle(THREAD, callinfo.selected_method());\n+    find_callee_info_helper(vfst, bc, callinfo, CHECK_(methodHandle()));\n+    callee_method = methodHandle(current, callinfo.selected_method());\n@@ -1366,3 +1404,1 @@\n-methodHandle SharedRuntime::resolve_helper(JavaThread *thread,\n-                                           bool is_virtual,\n-                                           bool is_optimized, TRAPS) {\n+methodHandle SharedRuntime::resolve_helper(bool is_virtual, bool is_optimized, TRAPS) {\n@@ -1370,1 +1406,1 @@\n-  callee_method = resolve_sub_helper(thread, is_virtual, is_optimized, THREAD);\n+  callee_method = resolve_sub_helper(is_virtual, is_optimized, THREAD);\n@@ -1374,1 +1410,1 @@\n-           callee_method->method_holder() != SystemDictionary::Object_klass()) {\n+           callee_method->method_holder() != vmClasses::Object_klass()) {\n@@ -1387,1 +1423,1 @@\n-      callee_method = resolve_sub_helper(thread, is_virtual, is_optimized, THREAD);\n+      callee_method = resolve_sub_helper(is_virtual, is_optimized, THREAD);\n@@ -1465,2 +1501,2 @@\n-            callee != NULL && (callee->is_compiled_by_jvmci() || callee->is_aot())) {\n-          return true; \/\/ skip patching for JVMCI or AOT code\n+            callee != NULL && callee->is_compiled_by_jvmci()) {\n+          return true; \/\/ skip patching for JVMCI\n@@ -1478,7 +1514,5 @@\n-methodHandle SharedRuntime::resolve_sub_helper(JavaThread *thread,\n-                                               bool is_virtual,\n-                                               bool is_optimized, TRAPS) {\n-\n-  ResourceMark rm(thread);\n-  RegisterMap cbl_map(thread, false);\n-  frame caller_frame = thread->last_frame().sender(&cbl_map);\n+methodHandle SharedRuntime::resolve_sub_helper(bool is_virtual, bool is_optimized, TRAPS) {\n+  JavaThread* current = THREAD;\n+  ResourceMark rm(current);\n+  RegisterMap cbl_map(current, false);\n+  frame caller_frame = current->last_frame().sender(&cbl_map);\n@@ -1500,3 +1534,2 @@\n-  Handle receiver = find_callee_info(thread, invoke_code,\n-                                     call_info, CHECK_(methodHandle()));\n-  methodHandle callee_method(THREAD, call_info.selected_method());\n+  Handle receiver = find_callee_info(invoke_code, call_info, CHECK_(methodHandle()));\n+  methodHandle callee_method(current, call_info.selected_method());\n@@ -1520,1 +1553,1 @@\n-    ResourceMark rm(thread);\n+    ResourceMark rm(current);\n@@ -1522,2 +1555,2 @@\n-      (is_optimized) ? \"optimized \" : \"\", (is_virtual) ? \"virtual\" : \"static\",\n-      Bytecodes::name(invoke_code));\n+               (is_optimized) ? \"optimized \" : \"\", (is_virtual) ? \"virtual\" : \"static\",\n+               Bytecodes::name(invoke_code));\n@@ -1532,1 +1565,1 @@\n-           callee_method->method_holder()->is_reentrant_initialization(thread),\n+           callee_method->method_holder()->is_reentrant_initialization(current),\n@@ -1580,1 +1613,1 @@\n-JRT_BLOCK_ENTRY(address, SharedRuntime::handle_wrong_method_ic_miss(JavaThread* thread))\n+JRT_BLOCK_ENTRY(address, SharedRuntime::handle_wrong_method_ic_miss(JavaThread* current))\n@@ -1582,2 +1615,2 @@\n-  RegisterMap reg_map(thread, false);\n-  frame stub_frame = thread->last_frame();\n+  RegisterMap reg_map(current, false);\n+  frame stub_frame = current->last_frame();\n@@ -1586,1 +1619,1 @@\n-  assert(!caller_frame.is_interpreted_frame() && !caller_frame.is_entry_frame(), \"unexpected frame\");\n+  assert(!caller_frame.is_interpreted_frame() && !caller_frame.is_entry_frame() && !caller_frame.is_optimized_entry_frame(), \"unexpected frame\");\n@@ -1591,1 +1624,1 @@\n-    callee_method = SharedRuntime::handle_ic_miss_helper(thread, CHECK_NULL);\n+    callee_method = SharedRuntime::handle_ic_miss_helper(CHECK_NULL);\n@@ -1593,1 +1626,1 @@\n-    thread->set_vm_result_2(callee_method());\n+    current->set_vm_result_2(callee_method());\n@@ -1602,1 +1635,1 @@\n-JRT_BLOCK_ENTRY(address, SharedRuntime::handle_wrong_method(JavaThread* thread))\n+JRT_BLOCK_ENTRY(address, SharedRuntime::handle_wrong_method(JavaThread* current))\n@@ -1612,2 +1645,2 @@\n-  RegisterMap reg_map(thread, false);\n-  frame stub_frame = thread->last_frame();\n+  RegisterMap reg_map(current, false);\n+  frame stub_frame = current->last_frame();\n@@ -1618,2 +1651,3 @@\n-      caller_frame.is_entry_frame()) {\n-    Method* callee = thread->callee_target();\n+      caller_frame.is_entry_frame() ||\n+      caller_frame.is_optimized_entry_frame()) {\n+    Method* callee = current->callee_target();\n@@ -1621,2 +1655,2 @@\n-    thread->set_vm_result_2(callee);\n-    thread->set_callee_target(NULL);\n+    current->set_vm_result_2(callee);\n+    current->set_callee_target(NULL);\n@@ -1642,2 +1676,2 @@\n-    callee_method = SharedRuntime::reresolve_call_site(thread, CHECK_NULL);\n-    thread->set_vm_result_2(callee_method());\n+    callee_method = SharedRuntime::reresolve_call_site(CHECK_NULL);\n+    current->set_vm_result_2(callee_method());\n@@ -1651,1 +1685,1 @@\n-JRT_BLOCK_ENTRY(address, SharedRuntime::handle_wrong_method_abstract(JavaThread* thread))\n+JRT_BLOCK_ENTRY(address, SharedRuntime::handle_wrong_method_abstract(JavaThread* current))\n@@ -1654,1 +1688,1 @@\n-  vframeStream vfst(thread, true);\n+  vframeStream vfst(current, true);\n@@ -1656,1 +1690,1 @@\n-  methodHandle caller(thread, vfst.method());\n+  methodHandle caller(current, vfst.method());\n@@ -1661,2 +1695,2 @@\n-  RegisterMap reg_map(thread);\n-  frame stubFrame = thread->last_frame();\n+  RegisterMap reg_map(current);\n+  frame stubFrame = current->last_frame();\n@@ -1670,1 +1704,1 @@\n-    methodHandle callee(thread, invoke.static_target(thread));\n+    methodHandle callee(current, invoke.static_target(current));\n@@ -1674,1 +1708,1 @@\n-      LinkResolver::throw_abstract_method_error(callee, recv_klass, thread);\n+      LinkResolver::throw_abstract_method_error(callee, recv_klass, CHECK_(res));\n@@ -1683,1 +1717,1 @@\n-JRT_BLOCK_ENTRY(address, SharedRuntime::resolve_static_call_C(JavaThread *thread ))\n+JRT_BLOCK_ENTRY(address, SharedRuntime::resolve_static_call_C(JavaThread* current ))\n@@ -1686,2 +1720,2 @@\n-    callee_method = SharedRuntime::resolve_helper(thread, false, false, CHECK_NULL);\n-    thread->set_vm_result_2(callee_method());\n+    callee_method = SharedRuntime::resolve_helper(false, false, CHECK_NULL);\n+    current->set_vm_result_2(callee_method());\n@@ -1696,1 +1730,1 @@\n-JRT_BLOCK_ENTRY(address, SharedRuntime::resolve_virtual_call_C(JavaThread *thread ))\n+JRT_BLOCK_ENTRY(address, SharedRuntime::resolve_virtual_call_C(JavaThread* current))\n@@ -1699,2 +1733,2 @@\n-    callee_method = SharedRuntime::resolve_helper(thread, true, false, CHECK_NULL);\n-    thread->set_vm_result_2(callee_method());\n+    callee_method = SharedRuntime::resolve_helper(true, false, CHECK_NULL);\n+    current->set_vm_result_2(callee_method());\n@@ -1710,1 +1744,1 @@\n-JRT_BLOCK_ENTRY(address, SharedRuntime::resolve_opt_virtual_call_C(JavaThread *thread))\n+JRT_BLOCK_ENTRY(address, SharedRuntime::resolve_opt_virtual_call_C(JavaThread* current))\n@@ -1713,2 +1747,2 @@\n-    callee_method = SharedRuntime::resolve_helper(thread, true, true, CHECK_NULL);\n-    thread->set_vm_result_2(callee_method());\n+    callee_method = SharedRuntime::resolve_helper(true, true, CHECK_NULL);\n+    current->set_vm_result_2(callee_method());\n@@ -1801,2 +1835,3 @@\n-methodHandle SharedRuntime::handle_ic_miss_helper(JavaThread *thread, TRAPS) {\n-  ResourceMark rm(thread);\n+methodHandle SharedRuntime::handle_ic_miss_helper(TRAPS) {\n+  JavaThread* current = THREAD;\n+  ResourceMark rm(current);\n@@ -1808,2 +1843,1 @@\n-  Handle receiver = find_callee_info(thread, bc, call_info,\n-                                     CHECK_(methodHandle()));\n+  Handle receiver = find_callee_info(bc, call_info, CHECK_(methodHandle()));\n@@ -1821,1 +1855,1 @@\n-    methodHandle callee_method = SharedRuntime::reresolve_call_site(thread, CHECK_(methodHandle()));\n+    methodHandle callee_method = SharedRuntime::reresolve_call_site(CHECK_(methodHandle()));\n@@ -1823,3 +1857,3 @@\n-      RegisterMap reg_map(thread, false);\n-      frame caller_frame = thread->last_frame().sender(&reg_map);\n-      ResourceMark rm(thread);\n+      RegisterMap reg_map(current, false);\n+      frame caller_frame = current->last_frame().sender(&reg_map);\n+      ResourceMark rm(current);\n@@ -1834,1 +1868,1 @@\n-  methodHandle callee_method(thread, call_info.selected_method());\n+  methodHandle callee_method(current, call_info.selected_method());\n@@ -1841,1 +1875,1 @@\n-    ResourceMark rm(thread);\n+    ResourceMark rm(current);\n@@ -1849,2 +1883,2 @@\n-    RegisterMap reg_map(thread, false);\n-    frame f = thread->last_frame().real_sender(&reg_map);\/\/ skip runtime stub\n+    RegisterMap reg_map(current, false);\n+    frame f = current->last_frame().real_sender(&reg_map);\/\/ skip runtime stub\n@@ -1867,2 +1901,2 @@\n-  RegisterMap reg_map(thread, false);\n-  frame caller_frame = thread->last_frame().sender(&reg_map);\n+  RegisterMap reg_map(current, false);\n+  frame caller_frame = current->last_frame().sender(&reg_map);\n@@ -1908,4 +1942,5 @@\n-methodHandle SharedRuntime::reresolve_call_site(JavaThread *thread, TRAPS) {\n-  ResourceMark rm(thread);\n-  RegisterMap reg_map(thread, false);\n-  frame stub_frame = thread->last_frame();\n+methodHandle SharedRuntime::reresolve_call_site(TRAPS) {\n+  JavaThread* current = THREAD;\n+  ResourceMark rm(current);\n+  RegisterMap reg_map(current, false);\n+  frame stub_frame = current->last_frame();\n@@ -1992,1 +2027,1 @@\n-  methodHandle callee_method = find_callee_method(thread, CHECK_(methodHandle()));\n+  methodHandle callee_method = find_callee_method(CHECK_(methodHandle()));\n@@ -1999,1 +2034,1 @@\n-    ResourceMark rm(thread);\n+    ResourceMark rm(current);\n@@ -2037,2 +2072,1 @@\n-  const bool is_outgoing = method->is_method_handle_intrinsic();\n-  int comp_args_on_stack = java_calling_convention(sig_bt, regs_without_member_name, total_args_passed - 1, is_outgoing);\n+  int comp_args_on_stack = java_calling_convention(sig_bt, regs_without_member_name, total_args_passed - 1);\n@@ -2162,1 +2196,1 @@\n-                                                JavaThread* thread)) {\n+                                                JavaThread* current)) {\n@@ -2178,1 +2212,1 @@\n-                                        length, thread);\n+                                        length, current);\n@@ -2247,1 +2281,1 @@\n-  (void) JavaThread::current()->reguard_stack();\n+  (void) JavaThread::current()->stack_overflow_state()->reguard_stack();\n@@ -2250,1 +2284,1 @@\n-void SharedRuntime::monitor_enter_helper(oopDesc* obj, BasicLock* lock, JavaThread* thread) {\n+void SharedRuntime::monitor_enter_helper(oopDesc* obj, BasicLock* lock, JavaThread* current) {\n@@ -2254,1 +2288,1 @@\n-    if (ObjectSynchronizer::quick_enter(obj, thread, lock)) return;\n+    if (ObjectSynchronizer::quick_enter(obj, current, lock)) return;\n@@ -2265,1 +2299,1 @@\n-  ObjectSynchronizer::enter(h_obj, lock, CHECK);\n+  ObjectSynchronizer::enter(h_obj, lock, current);\n@@ -2271,2 +2305,2 @@\n-JRT_BLOCK_ENTRY(void, SharedRuntime::complete_monitor_locking_C(oopDesc* obj, BasicLock* lock, JavaThread* thread))\n-  SharedRuntime::monitor_enter_helper(obj, lock, thread);\n+JRT_BLOCK_ENTRY(void, SharedRuntime::complete_monitor_locking_C(oopDesc* obj, BasicLock* lock, JavaThread* current))\n+  SharedRuntime::monitor_enter_helper(obj, lock, current);\n@@ -2275,2 +2309,2 @@\n-void SharedRuntime::monitor_exit_helper(oopDesc* obj, BasicLock* lock, JavaThread* thread) {\n-  assert(JavaThread::current() == thread, \"invariant\");\n+void SharedRuntime::monitor_exit_helper(oopDesc* obj, BasicLock* lock, JavaThread* current) {\n+  assert(JavaThread::current() == current, \"invariant\");\n@@ -2278,2 +2312,10 @@\n-  EXCEPTION_MARK;\n-  ObjectSynchronizer::exit(obj, lock, THREAD);\n+  ExceptionMark em(current);\n+  \/\/ The object could become unlocked through a JNI call, which we have no other checks for.\n+  \/\/ Give a fatal message if CheckJNICalls. Otherwise we ignore it.\n+  if (obj->is_unlocked()) {\n+    if (CheckJNICalls) {\n+      fatal(\"Object has been unlocked by JNI\");\n+    }\n+    return;\n+  }\n+  ObjectSynchronizer::exit(obj, lock, current);\n@@ -2283,2 +2325,2 @@\n-JRT_LEAF(void, SharedRuntime::complete_monitor_unlocking_C(oopDesc* obj, BasicLock* lock, JavaThread* thread))\n-  SharedRuntime::monitor_exit_helper(obj, lock, thread);\n+JRT_LEAF(void, SharedRuntime::complete_monitor_unlocking_C(oopDesc* obj, BasicLock* lock, JavaThread* current))\n+  SharedRuntime::monitor_exit_helper(obj, lock, current);\n@@ -2297,7 +2339,0 @@\n-  if (CountRemovableExceptions) {\n-    if (_nof_removable_exceptions > 0) {\n-      Unimplemented(); \/\/ this counter is not yet incremented\n-      tty->print_cr(\"Removable exceptions: %d\", _nof_removable_exceptions);\n-    }\n-  }\n-\n@@ -2345,0 +2380,4 @@\n+inline double percent(int64_t x, int64_t y) {\n+  return 100.0 * x \/ MAX2(y, (int64_t)1);\n+}\n+\n@@ -2349,4 +2388,6 @@\n-  static int _arity_histogram[MAX_ARITY];     \/\/ histogram of #args\n-  static int _size_histogram[MAX_ARITY];      \/\/ histogram of arg size in words\n-  static int _max_arity;                      \/\/ max. arity seen\n-  static int _max_size;                       \/\/ max. arg size seen\n+  static uint64_t _arity_histogram[MAX_ARITY]; \/\/ histogram of #args\n+  static uint64_t _size_histogram[MAX_ARITY];  \/\/ histogram of arg size in words\n+  static uint64_t _total_compiled_calls;\n+  static uint64_t _max_compiled_calls_per_method;\n+  static int _max_arity;                       \/\/ max. arity seen\n+  static int _max_size;                        \/\/ max. arg size seen\n@@ -2355,2 +2396,2 @@\n-    if (CompiledMethod::nmethod_access_is_safe(nm)) {\n-      Method* method = nm->method();\n+    Method* method = (nm == NULL) ? NULL : nm->method();\n+    if ((method != NULL) && nm->is_alive()) {\n@@ -2362,1 +2403,3 @@\n-      int count = method->compiled_invocation_count();\n+      uint64_t count = (uint64_t)method->compiled_invocation_count();\n+      _max_compiled_calls_per_method = count > _max_compiled_calls_per_method ? count : _max_compiled_calls_per_method;\n+      _total_compiled_calls    += count;\n@@ -2370,3 +2413,2 @@\n-  void print_histogram_helper(int n, int* histo, const char* name) {\n-    const int N = MIN2(5, n);\n-    tty->print_cr(\"\\nHistogram of call arity (incl. rcvr, calls to compiled methods only):\");\n+  void print_histogram_helper(int n, uint64_t* histo, const char* name) {\n+    const int N = MIN2(9, n);\n@@ -2375,7 +2417,14 @@\n-    int i;\n-    for (i = 0; i <= n; i++) { sum += histo[i]; weighted_sum += i*histo[i]; }\n-    double rest = sum;\n-    double percent = sum \/ 100;\n-    for (i = 0; i <= N; i++) {\n-      rest -= histo[i];\n-      tty->print_cr(\"%4d: %7d (%5.1f%%)\", i, histo[i], histo[i] \/ percent);\n+    for (int i = 0; i <= n; i++) { sum += histo[i]; weighted_sum += i*histo[i]; }\n+    if (sum >= 1.0) { \/\/ prevent divide by zero or divide overflow\n+      double rest = sum;\n+      double percent = sum \/ 100;\n+      for (int i = 0; i <= N; i++) {\n+        rest -= histo[i];\n+        tty->print_cr(\"%4d: \" UINT64_FORMAT_W(12) \" (%5.1f%%)\", i, histo[i], histo[i] \/ percent);\n+      }\n+      tty->print_cr(\"rest: \" INT64_FORMAT_W(12) \" (%5.1f%%)\", (int64_t)rest, rest \/ percent);\n+      tty->print_cr(\"(avg. %s = %3.1f, max = %d)\", name, weighted_sum \/ sum, n);\n+      tty->print_cr(\"(total # of compiled calls = \" INT64_FORMAT_W(14) \")\", _total_compiled_calls);\n+      tty->print_cr(\"(max # of compiled calls   = \" INT64_FORMAT_W(14) \")\", _max_compiled_calls_per_method);\n+    } else {\n+      tty->print_cr(\"Histogram generation failed for %s. n = %d, sum = %7.5f\", name, n, sum);\n@@ -2383,2 +2432,0 @@\n-    tty->print_cr(\"rest: %7d (%5.1f%%))\", (int)rest, rest \/ percent);\n-    tty->print_cr(\"(avg. %s = %3.1f, max = %d)\", name, weighted_sum \/ sum, n);\n@@ -2390,1 +2437,1 @@\n-    tty->print_cr(\"\\nSame for parameter size (in words):\");\n+    tty->print_cr(\"\\nHistogram of parameter block size (in words, incl. rcvr):\");\n@@ -2397,1 +2444,4 @@\n-    MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+    \/\/ Take the Compile_lock to protect against changes in the CodeBlob structures\n+    MutexLocker mu1(Compile_lock, Mutex::_safepoint_check_flag);\n+    \/\/ Take the CodeCache_lock to protect against changes in the CodeHeap structure\n+    MutexLocker mu2(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n@@ -2399,0 +2449,2 @@\n+    _total_compiled_calls = 0;\n+    _max_compiled_calls_per_method = 0;\n@@ -2405,2 +2457,4 @@\n-int MethodArityHistogram::_arity_histogram[MethodArityHistogram::MAX_ARITY];\n-int MethodArityHistogram::_size_histogram[MethodArityHistogram::MAX_ARITY];\n+uint64_t MethodArityHistogram::_arity_histogram[MethodArityHistogram::MAX_ARITY];\n+uint64_t MethodArityHistogram::_size_histogram[MethodArityHistogram::MAX_ARITY];\n+uint64_t MethodArityHistogram::_total_compiled_calls;\n+uint64_t MethodArityHistogram::_max_compiled_calls_per_method;\n@@ -2410,1 +2464,1 @@\n-void SharedRuntime::print_call_statistics(int comp_total) {\n+void SharedRuntime::print_call_statistics(uint64_t comp_total) {\n@@ -2412,16 +2466,16 @@\n-  int total  = _nof_normal_calls + _nof_interface_calls + _nof_static_calls;\n-  int mono_c = _nof_normal_calls - _nof_optimized_calls - _nof_megamorphic_calls;\n-  int mono_i = _nof_interface_calls - _nof_optimized_interface_calls - _nof_megamorphic_interface_calls;\n-  tty->print_cr(\"\\t%9d   (%4.1f%%) total non-inlined   \", total, percent(total, total));\n-  tty->print_cr(\"\\t%9d   (%4.1f%%) virtual calls       \", _nof_normal_calls, percent(_nof_normal_calls, total));\n-  tty->print_cr(\"\\t  %9d  (%3.0f%%)   inlined          \", _nof_inlined_calls, percent(_nof_inlined_calls, _nof_normal_calls));\n-  tty->print_cr(\"\\t  %9d  (%3.0f%%)   optimized        \", _nof_optimized_calls, percent(_nof_optimized_calls, _nof_normal_calls));\n-  tty->print_cr(\"\\t  %9d  (%3.0f%%)   monomorphic      \", mono_c, percent(mono_c, _nof_normal_calls));\n-  tty->print_cr(\"\\t  %9d  (%3.0f%%)   megamorphic      \", _nof_megamorphic_calls, percent(_nof_megamorphic_calls, _nof_normal_calls));\n-  tty->print_cr(\"\\t%9d   (%4.1f%%) interface calls     \", _nof_interface_calls, percent(_nof_interface_calls, total));\n-  tty->print_cr(\"\\t  %9d  (%3.0f%%)   inlined          \", _nof_inlined_interface_calls, percent(_nof_inlined_interface_calls, _nof_interface_calls));\n-  tty->print_cr(\"\\t  %9d  (%3.0f%%)   optimized        \", _nof_optimized_interface_calls, percent(_nof_optimized_interface_calls, _nof_interface_calls));\n-  tty->print_cr(\"\\t  %9d  (%3.0f%%)   monomorphic      \", mono_i, percent(mono_i, _nof_interface_calls));\n-  tty->print_cr(\"\\t  %9d  (%3.0f%%)   megamorphic      \", _nof_megamorphic_interface_calls, percent(_nof_megamorphic_interface_calls, _nof_interface_calls));\n-  tty->print_cr(\"\\t%9d   (%4.1f%%) static\/special calls\", _nof_static_calls, percent(_nof_static_calls, total));\n-  tty->print_cr(\"\\t  %9d  (%3.0f%%)   inlined          \", _nof_inlined_static_calls, percent(_nof_inlined_static_calls, _nof_static_calls));\n+  int64_t total  = _nof_normal_calls + _nof_interface_calls + _nof_static_calls;\n+  int64_t mono_c = _nof_normal_calls - _nof_optimized_calls - _nof_megamorphic_calls;\n+  int64_t mono_i = _nof_interface_calls - _nof_optimized_interface_calls - _nof_megamorphic_interface_calls;\n+  tty->print_cr(\"\\t\" INT64_FORMAT_W(12) \" (100%%)  total non-inlined   \", total);\n+  tty->print_cr(\"\\t\" INT64_FORMAT_W(12) \" (%4.1f%%) |- virtual calls       \", _nof_normal_calls, percent(_nof_normal_calls, total));\n+  tty->print_cr(\"\\t\" INT64_FORMAT_W(12) \" (%4.0f%%) |  |- inlined          \", _nof_inlined_calls, percent(_nof_inlined_calls, _nof_normal_calls));\n+  tty->print_cr(\"\\t\" INT64_FORMAT_W(12) \" (%4.0f%%) |  |- optimized        \", _nof_optimized_calls, percent(_nof_optimized_calls, _nof_normal_calls));\n+  tty->print_cr(\"\\t\" INT64_FORMAT_W(12) \" (%4.0f%%) |  |- monomorphic      \", mono_c, percent(mono_c, _nof_normal_calls));\n+  tty->print_cr(\"\\t\" INT64_FORMAT_W(12) \" (%4.0f%%) |  |- megamorphic      \", _nof_megamorphic_calls, percent(_nof_megamorphic_calls, _nof_normal_calls));\n+  tty->print_cr(\"\\t\" INT64_FORMAT_W(12) \" (%4.1f%%) |- interface calls     \", _nof_interface_calls, percent(_nof_interface_calls, total));\n+  tty->print_cr(\"\\t\" INT64_FORMAT_W(12) \" (%4.0f%%) |  |- inlined          \", _nof_inlined_interface_calls, percent(_nof_inlined_interface_calls, _nof_interface_calls));\n+  tty->print_cr(\"\\t\" INT64_FORMAT_W(12) \" (%4.0f%%) |  |- optimized        \", _nof_optimized_interface_calls, percent(_nof_optimized_interface_calls, _nof_interface_calls));\n+  tty->print_cr(\"\\t\" INT64_FORMAT_W(12) \" (%4.0f%%) |  |- monomorphic      \", mono_i, percent(mono_i, _nof_interface_calls));\n+  tty->print_cr(\"\\t\" INT64_FORMAT_W(12) \" (%4.0f%%) |  |- megamorphic      \", _nof_megamorphic_interface_calls, percent(_nof_megamorphic_interface_calls, _nof_interface_calls));\n+  tty->print_cr(\"\\t\" INT64_FORMAT_W(12) \" (%4.1f%%) |- static\/special calls\", _nof_static_calls, percent(_nof_static_calls, total));\n+  tty->print_cr(\"\\t\" INT64_FORMAT_W(12) \" (%4.0f%%) |  |- inlined          \", _nof_inlined_static_calls, percent(_nof_inlined_static_calls, _nof_static_calls));\n@@ -2518,4 +2572,2 @@\n-      for (int byte = 0; byte < _basic_types_per_int; byte++) {\n-        int bt = ((sig_index < total_args_passed)\n-                  ? adapter_encoding(sig_bt[sig_index++])\n-                  : 0);\n+      for (int byte = 0; sig_index < total_args_passed && byte < _basic_types_per_int; byte++) {\n+        int bt = adapter_encoding(sig_bt[sig_index++]);\n@@ -2563,1 +2615,1 @@\n-      st.print(\"%08x\", value(i));\n+      st.print(\"%x\", value(i));\n@@ -2568,0 +2620,41 @@\n+#ifndef PRODUCT\n+  \/\/ Reconstitutes the basic type arguments from the fingerprint,\n+  \/\/ producing strings like LIJDF\n+  const char* as_basic_args_string() {\n+    stringStream st;\n+    bool long_prev = false;\n+    for (int i = 0; i < length(); i++) {\n+      unsigned val = (unsigned)value(i);\n+      \/\/ args are packed so that first\/lower arguments are in the highest\n+      \/\/ bits of each int value, so iterate from highest to the lowest\n+      for (int j = 32 - _basic_type_bits; j >= 0; j -= _basic_type_bits) {\n+        unsigned v = (val >> j) & _basic_type_mask;\n+        if (v == 0) {\n+          assert(i == length() - 1, \"Only expect zeroes in the last word\");\n+          continue;\n+        }\n+        if (long_prev) {\n+          long_prev = false;\n+          if (v == T_VOID) {\n+            st.print(\"J\");\n+          } else {\n+            st.print(\"L\");\n+          }\n+        }\n+        switch (v) {\n+          case T_INT:    st.print(\"I\");    break;\n+          case T_LONG:   long_prev = true; break;\n+          case T_FLOAT:  st.print(\"F\");    break;\n+          case T_DOUBLE: st.print(\"D\");    break;\n+          case T_VOID:   break;\n+          default: ShouldNotReachHere();\n+        }\n+      }\n+    }\n+    if (long_prev) {\n+      st.print(\"L\");\n+    }\n+    return st.as_string();\n+  }\n+#endif \/\/ !product\n+\n@@ -2609,1 +2702,1 @@\n-    : BasicHashtable<mtCode>(293, (DumpSharedSpaces ? sizeof(CDSAdapterHandlerEntry) : sizeof(AdapterHandlerEntry))) { }\n+    : BasicHashtable<mtCode>(293, (sizeof(AdapterHandlerEntry))) { }\n@@ -2615,3 +2708,0 @@\n-    if (DumpSharedSpaces) {\n-      ((CDSAdapterHandlerEntry*)entry)->init();\n-    }\n@@ -2731,0 +2821,5 @@\n+AdapterHandlerEntry* AdapterHandlerLibrary::_no_arg_handler = NULL;\n+AdapterHandlerEntry* AdapterHandlerLibrary::_int_arg_handler = NULL;\n+AdapterHandlerEntry* AdapterHandlerLibrary::_obj_arg_handler = NULL;\n+AdapterHandlerEntry* AdapterHandlerLibrary::_obj_int_arg_handler = NULL;\n+AdapterHandlerEntry* AdapterHandlerLibrary::_obj_obj_arg_handler = NULL;\n@@ -2735,3 +2830,0 @@\n-  \/\/ Should be called only when AdapterHandlerLibrary_lock is active.\n-  if (_buffer == NULL) \/\/ Initialize lazily\n-      _buffer = BufferBlob::create(\"adapters\", AdapterHandlerLibrary_size);\n@@ -2745,0 +2837,14 @@\n+static void post_adapter_creation(const AdapterBlob* new_adapter, const AdapterHandlerEntry* entry) {\n+  char blob_id[256];\n+  jio_snprintf(blob_id,\n+                sizeof(blob_id),\n+                \"%s(%s)\",\n+                new_adapter->name(),\n+                entry->fingerprint()->as_string());\n+  Forte::register_stub(blob_id, new_adapter->content_begin(), new_adapter->content_end());\n+\n+  if (JvmtiExport::should_post_dynamic_code_generated()) {\n+    JvmtiExport::post_dynamic_code_generated(blob_id, new_adapter->content_begin(), new_adapter->content_end());\n+  }\n+}\n+\n@@ -2746,2 +2852,34 @@\n-  if (_adapters != NULL) return;\n-  _adapters = new AdapterHandlerTable();\n+  ResourceMark rm;\n+  AdapterBlob* no_arg_blob = NULL;\n+  AdapterBlob* int_arg_blob = NULL;\n+  AdapterBlob* obj_arg_blob = NULL;\n+  AdapterBlob* obj_int_arg_blob = NULL;\n+  AdapterBlob* obj_obj_arg_blob = NULL;\n+  {\n+    MutexLocker mu(AdapterHandlerLibrary_lock);\n+    assert(_adapters == NULL, \"Initializing more than once\");\n+\n+    _adapters = new AdapterHandlerTable();\n+\n+    \/\/ Create a special handler for abstract methods.  Abstract methods\n+    \/\/ are never compiled so an i2c entry is somewhat meaningless, but\n+    \/\/ throw AbstractMethodError just in case.\n+    \/\/ Pass wrong_method_abstract for the c2i transitions to return\n+    \/\/ AbstractMethodError for invalid invocations.\n+    address wrong_method_abstract = SharedRuntime::get_handle_wrong_method_abstract_stub();\n+    _abstract_method_handler = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(0, NULL),\n+                                                                StubRoutines::throw_AbstractMethodError_entry(),\n+                                                                wrong_method_abstract, wrong_method_abstract);\n+\n+    _buffer = BufferBlob::create(\"adapters\", AdapterHandlerLibrary_size);\n+\n+    _no_arg_handler = create_adapter(no_arg_blob, 0, NULL, true);\n+\n+    BasicType obj_args[] = { T_OBJECT };\n+    _obj_arg_handler = create_adapter(obj_arg_blob, 1, obj_args, true);\n+\n+    BasicType int_args[] = { T_INT };\n+    _int_arg_handler = create_adapter(int_arg_blob, 1, int_args, true);\n+\n+    BasicType obj_int_args[] = { T_OBJECT, T_INT };\n+    _obj_int_arg_handler = create_adapter(obj_int_arg_blob, 2, obj_int_args, true);\n@@ -2749,9 +2887,16 @@\n-  \/\/ Create a special handler for abstract methods.  Abstract methods\n-  \/\/ are never compiled so an i2c entry is somewhat meaningless, but\n-  \/\/ throw AbstractMethodError just in case.\n-  \/\/ Pass wrong_method_abstract for the c2i transitions to return\n-  \/\/ AbstractMethodError for invalid invocations.\n-  address wrong_method_abstract = SharedRuntime::get_handle_wrong_method_abstract_stub();\n-  _abstract_method_handler = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(0, NULL),\n-                                                              StubRoutines::throw_AbstractMethodError_entry(),\n-                                                              wrong_method_abstract, wrong_method_abstract);\n+    BasicType obj_obj_args[] = { T_OBJECT, T_OBJECT };\n+    _obj_obj_arg_handler = create_adapter(obj_obj_arg_blob, 2, obj_obj_args, true);\n+\n+    assert(no_arg_blob != NULL &&\n+          obj_arg_blob != NULL &&\n+          int_arg_blob != NULL &&\n+          obj_int_arg_blob != NULL &&\n+          obj_obj_arg_blob != NULL, \"Initial adapters must be properly created\");\n+  }\n+\n+  \/\/ Outside of the lock\n+  post_adapter_creation(no_arg_blob, _no_arg_handler);\n+  post_adapter_creation(obj_arg_blob, _obj_arg_handler);\n+  post_adapter_creation(int_arg_blob, _int_arg_handler);\n+  post_adapter_creation(obj_int_arg_blob, _obj_int_arg_handler);\n+  post_adapter_creation(obj_obj_arg_blob, _obj_obj_arg_handler);\n@@ -2768,7 +2913,34 @@\n-AdapterHandlerEntry* AdapterHandlerLibrary::get_adapter(const methodHandle& method) {\n-  AdapterHandlerEntry* entry = get_adapter0(method);\n-  if (entry != NULL && method->is_shared()) {\n-    \/\/ See comments around Method::link_method()\n-    MutexLocker mu(AdapterHandlerLibrary_lock);\n-    if (method->adapter() == NULL) {\n-      method->update_adapter_trampoline(entry);\n+AdapterHandlerEntry* AdapterHandlerLibrary::get_simple_adapter(const methodHandle& method) {\n+  if (method->is_abstract()) {\n+    return _abstract_method_handler;\n+  }\n+  int total_args_passed = method->size_of_parameters(); \/\/ All args on stack\n+  if (total_args_passed == 0) {\n+    return _no_arg_handler;\n+  } else if (total_args_passed == 1) {\n+    if (!method->is_static()) {\n+      return _obj_arg_handler;\n+    }\n+    switch (method->signature()->char_at(1)) {\n+      case JVM_SIGNATURE_CLASS:\n+      case JVM_SIGNATURE_ARRAY:\n+        return _obj_arg_handler;\n+      case JVM_SIGNATURE_INT:\n+      case JVM_SIGNATURE_BOOLEAN:\n+      case JVM_SIGNATURE_CHAR:\n+      case JVM_SIGNATURE_BYTE:\n+      case JVM_SIGNATURE_SHORT:\n+        return _int_arg_handler;\n+    }\n+  } else if (total_args_passed == 2 &&\n+             !method->is_static()) {\n+    switch (method->signature()->char_at(1)) {\n+      case JVM_SIGNATURE_CLASS:\n+      case JVM_SIGNATURE_ARRAY:\n+        return _obj_obj_arg_handler;\n+      case JVM_SIGNATURE_INT:\n+      case JVM_SIGNATURE_BOOLEAN:\n+      case JVM_SIGNATURE_CHAR:\n+      case JVM_SIGNATURE_BYTE:\n+      case JVM_SIGNATURE_SHORT:\n+        return _obj_int_arg_handler;\n@@ -2776,7 +2948,3 @@\n-    address trampoline = method->from_compiled_entry();\n-    if (*(int*)trampoline == 0) {\n-      CodeBuffer buffer(trampoline, (int)SharedRuntime::trampoline_size());\n-      MacroAssembler _masm(&buffer);\n-      SharedRuntime::generate_trampoline(&_masm, entry->get_c2i_entry());\n-      assert(*(int*)trampoline != 0, \"Instruction(s) for trampoline must not be encoded as zeros.\");\n-      _masm.flush();\n+  }\n+  return NULL;\n+}\n@@ -2784,3 +2952,17 @@\n-      if (PrintInterpreter) {\n-        Disassembler::decode(buffer.insts_begin(), buffer.insts_end());\n-      }\n+class AdapterSignatureIterator : public SignatureIterator {\n+ private:\n+  BasicType stack_sig_bt[16];\n+  BasicType* sig_bt;\n+  int index;\n+\n+ public:\n+  AdapterSignatureIterator(Symbol* signature,\n+                           fingerprint_t fingerprint,\n+                           bool is_static,\n+                           int total_args_passed) :\n+    SignatureIterator(signature, fingerprint),\n+    index(0)\n+  {\n+    sig_bt = (total_args_passed <= 16) ? stack_sig_bt : NEW_RESOURCE_ARRAY(BasicType, total_args_passed);\n+    if (!is_static) { \/\/ Pass in receiver first\n+      sig_bt[index++] = T_OBJECT;\n@@ -2788,0 +2970,1 @@\n+    do_parameters_on(this);\n@@ -2790,2 +2973,3 @@\n-  return entry;\n-}\n+  BasicType* basic_types() {\n+    return sig_bt;\n+  }\n@@ -2793,1 +2977,18 @@\n-AdapterHandlerEntry* AdapterHandlerLibrary::get_adapter0(const methodHandle& method) {\n+#ifdef ASSERT\n+  int slots() {\n+    return index;\n+  }\n+#endif\n+\n+ private:\n+\n+  friend class SignatureIterator;  \/\/ so do_parameters_on can call do_type\n+  void do_type(BasicType type) {\n+    sig_bt[index++] = type;\n+    if (type == T_LONG || type == T_DOUBLE) {\n+      sig_bt[index++] = T_VOID; \/\/ Longs & doubles take 2 Java slots\n+    }\n+  }\n+};\n+\n+AdapterHandlerEntry* AdapterHandlerLibrary::get_adapter(const methodHandle& method) {\n@@ -2798,0 +2999,1 @@\n+  assert(_adapters != NULL, \"Uninitialized\");\n@@ -2799,1 +3001,5 @@\n-  ResourceMark rm;\n+  \/\/ Fast-path for trivial adapters\n+  AdapterHandlerEntry* entry = get_simple_adapter(method);\n+  if (entry != NULL) {\n+    return entry;\n+  }\n@@ -2801,1 +3007,1 @@\n-  NOT_PRODUCT(int insts_size);\n+  ResourceMark rm;\n@@ -2803,12 +3009,2 @@\n-  AdapterHandlerEntry* entry = NULL;\n-  AdapterFingerPrint* fingerprint = NULL;\n-  {\n-    MutexLocker mu(AdapterHandlerLibrary_lock);\n-    \/\/ make sure data structure is initialized\n-    initialize();\n-\n-    if (method->is_abstract()) {\n-      return _abstract_method_handler;\n-    }\n-    \/\/ Fill in the signature array, for the calling-convention call.\n-    int total_args_passed = method->size_of_parameters(); \/\/ All args on stack\n+  \/\/ Fill in the signature array, for the calling-convention call.\n+  int total_args_passed = method->size_of_parameters(); \/\/ All args on stack\n@@ -2817,11 +3013,6 @@\n-    BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, total_args_passed);\n-    VMRegPair* regs   = NEW_RESOURCE_ARRAY(VMRegPair, total_args_passed);\n-    int i = 0;\n-    if (!method->is_static())  \/\/ Pass in receiver first\n-      sig_bt[i++] = T_OBJECT;\n-    for (SignatureStream ss(method->signature()); !ss.at_return_type(); ss.next()) {\n-      sig_bt[i++] = ss.type();  \/\/ Collect remaining bits of signature\n-      if (ss.type() == T_LONG || ss.type() == T_DOUBLE)\n-        sig_bt[i++] = T_VOID;   \/\/ Longs & doubles take 2 Java slots\n-    }\n-    assert(i == total_args_passed, \"\");\n+  AdapterSignatureIterator si(method->signature(), method->constMethod()->fingerprint(),\n+                              method->is_static(), total_args_passed);\n+  assert(si.slots() == total_args_passed, \"\");\n+  BasicType* sig_bt = si.basic_types();\n+  {\n+    MutexLocker mu(AdapterHandlerLibrary_lock);\n@@ -2832,0 +3023,1 @@\n+    if (entry != NULL) {\n@@ -2833,6 +3025,8 @@\n-    AdapterHandlerEntry* shared_entry = NULL;\n-    \/\/ Start adapter sharing verification only after the VM is booted.\n-    if (VerifyAdapterSharing && (entry != NULL)) {\n-      shared_entry = entry;\n-      entry = NULL;\n-    }\n+      if (VerifyAdapterSharing) {\n+        AdapterBlob* comparison_blob = NULL;\n+        AdapterHandlerEntry* comparison_entry = create_adapter(comparison_blob, total_args_passed, sig_bt, false);\n+        assert(comparison_blob == NULL, \"no blob should be created when creating an adapter for comparison\");\n+        assert(comparison_entry->compare_code(entry), \"code must match\");\n+        \/\/ Release the one just created and return the original\n+        _adapters->free_entry(comparison_entry);\n+      }\n@@ -2840,2 +3034,0 @@\n-\n-    if (entry != NULL) {\n@@ -2845,5 +3037,2 @@\n-    \/\/ Get a description of the compiled java calling convention and the largest used (VMReg) stack slot usage\n-    int comp_args_on_stack = SharedRuntime::java_calling_convention(sig_bt, regs, total_args_passed, false);\n-\n-    \/\/ Make a C heap allocated version of the fingerprint to store in the adapter\n-    fingerprint = new AdapterFingerPrint(total_args_passed, sig_bt);\n+    entry = create_adapter(new_adapter, total_args_passed, sig_bt, \/* allocate_code_blob *\/ true);\n+  }\n@@ -2851,5 +3040,6 @@\n-    \/\/ StubRoutines::code2() is initialized after this function can be called. As a result,\n-    \/\/ VerifyAdapterCalls and VerifyAdapterSharing can fail if we re-use code that generated\n-    \/\/ prior to StubRoutines::code2() being set. Checks refer to checks generated in an I2C\n-    \/\/ stub that ensure that an I2C stub is called from an interpreter frame.\n-    bool contains_all_checks = StubRoutines::code2() != NULL;\n+  \/\/ Outside of the lock\n+  if (new_adapter != NULL) {\n+    post_adapter_creation(new_adapter, entry);\n+  }\n+  return entry;\n+}\n@@ -2857,7 +3047,31 @@\n-    \/\/ Create I2C & C2I handlers\n-    BufferBlob* buf = buffer_blob(); \/\/ the temporary code buffer in CodeCache\n-    if (buf != NULL) {\n-      CodeBuffer buffer(buf);\n-      short buffer_locs[20];\n-      buffer.insts()->initialize_shared_locs((relocInfo*)buffer_locs,\n-                                             sizeof(buffer_locs)\/sizeof(relocInfo));\n+AdapterHandlerEntry* AdapterHandlerLibrary::create_adapter(AdapterBlob*& new_adapter,\n+                                                           int total_args_passed,\n+                                                           BasicType* sig_bt,\n+                                                           bool allocate_code_blob) {\n+\n+  \/\/ StubRoutines::code2() is initialized after this function can be called. As a result,\n+  \/\/ VerifyAdapterCalls and VerifyAdapterSharing can fail if we re-use code that generated\n+  \/\/ prior to StubRoutines::code2() being set. Checks refer to checks generated in an I2C\n+  \/\/ stub that ensure that an I2C stub is called from an interpreter frame.\n+  bool contains_all_checks = StubRoutines::code2() != NULL;\n+\n+  VMRegPair stack_regs[16];\n+  VMRegPair* regs = (total_args_passed <= 16) ? stack_regs : NEW_RESOURCE_ARRAY(VMRegPair, total_args_passed);\n+\n+  \/\/ Get a description of the compiled java calling convention and the largest used (VMReg) stack slot usage\n+  int comp_args_on_stack = SharedRuntime::java_calling_convention(sig_bt, regs, total_args_passed);\n+  BufferBlob* buf = buffer_blob(); \/\/ the temporary code buffer in CodeCache\n+  CodeBuffer buffer(buf);\n+  short buffer_locs[20];\n+  buffer.insts()->initialize_shared_locs((relocInfo*)buffer_locs,\n+                                          sizeof(buffer_locs)\/sizeof(relocInfo));\n+\n+  \/\/ Make a C heap allocated version of the fingerprint to store in the adapter\n+  AdapterFingerPrint* fingerprint = new AdapterFingerPrint(total_args_passed, sig_bt);\n+  MacroAssembler _masm(&buffer);\n+  AdapterHandlerEntry* entry = SharedRuntime::generate_i2c2i_adapters(&_masm,\n+                                                total_args_passed,\n+                                                comp_args_on_stack,\n+                                                sig_bt,\n+                                                regs,\n+                                                fingerprint);\n@@ -2865,17 +3079,6 @@\n-      MacroAssembler _masm(&buffer);\n-      entry = SharedRuntime::generate_i2c2i_adapters(&_masm,\n-                                                     total_args_passed,\n-                                                     comp_args_on_stack,\n-                                                     sig_bt,\n-                                                     regs,\n-                                                     fingerprint);\n-      if (VerifyAdapterSharing) {\n-        if (shared_entry != NULL) {\n-          assert(shared_entry->compare_code(buf->code_begin(), buffer.insts_size()), \"code must match\");\n-          \/\/ Release the one just created and return the original\n-          _adapters->free_entry(entry);\n-          return shared_entry;\n-        } else  {\n-          entry->save_code(buf->code_begin(), buffer.insts_size());\n-        }\n-      }\n+  if (VerifyAdapterSharing) {\n+    entry->save_code(buf->code_begin(), buffer.insts_size());\n+    if (!allocate_code_blob) {\n+      return entry;\n+    }\n+  }\n@@ -2885,10 +3088,9 @@\n-      new_adapter = AdapterBlob::create(&buffer);\n-      NOT_PRODUCT(insts_size = buffer.insts_size());\n-    }\n-    if (new_adapter == NULL) {\n-      \/\/ CodeCache is full, disable compilation\n-      \/\/ Ought to log this but compile log is only per compile thread\n-      \/\/ and we're some non descript Java thread.\n-      return NULL; \/\/ Out of CodeCache space\n-    }\n-    entry->relocate(new_adapter->content_begin());\n+  new_adapter = AdapterBlob::create(&buffer);\n+  NOT_PRODUCT(int insts_size = buffer.insts_size());\n+  if (new_adapter == NULL) {\n+    \/\/ CodeCache is full, disable compilation\n+    \/\/ Ought to log this but compile log is only per compile thread\n+    \/\/ and we're some non descript Java thread.\n+    return NULL;\n+  }\n+  entry->relocate(new_adapter->content_begin());\n@@ -2896,14 +3098,13 @@\n-    \/\/ debugging suppport\n-    if (PrintAdapterHandlers || PrintStubCode) {\n-      ttyLocker ttyl;\n-      entry->print_adapter_on(tty);\n-      tty->print_cr(\"i2c argument handler #%d for: %s %s %s (%d bytes generated)\",\n-                    _adapters->number_of_entries(), (method->is_static() ? \"static\" : \"receiver\"),\n-                    method->signature()->as_C_string(), fingerprint->as_string(), insts_size);\n-      tty->print_cr(\"c2i argument handler starts at %p\", entry->get_c2i_entry());\n-      if (Verbose || PrintStubCode) {\n-        address first_pc = entry->base_address();\n-        if (first_pc != NULL) {\n-          Disassembler::decode(first_pc, first_pc + insts_size);\n-          tty->cr();\n-        }\n+  \/\/ debugging suppport\n+  if (PrintAdapterHandlers || PrintStubCode) {\n+    ttyLocker ttyl;\n+    entry->print_adapter_on(tty);\n+    tty->print_cr(\"i2c argument handler #%d for: %s %s (%d bytes generated)\",\n+                  _adapters->number_of_entries(), fingerprint->as_basic_args_string(),\n+                  fingerprint->as_string(), insts_size);\n+    tty->print_cr(\"c2i argument handler starts at %p\", entry->get_c2i_entry());\n+    if (Verbose || PrintStubCode) {\n+      address first_pc = entry->base_address();\n+      if (first_pc != NULL) {\n+        Disassembler::decode(first_pc, first_pc + insts_size);\n+        tty->cr();\n@@ -2912,16 +3113,1 @@\n-#endif\n-    \/\/ Add the entry only if the entry contains all required checks (see sharedRuntime_xxx.cpp)\n-    \/\/ The checks are inserted only if -XX:+VerifyAdapterCalls is specified.\n-    if (contains_all_checks || !VerifyAdapterCalls) {\n-      _adapters->add(entry);\n-    }\n-  \/\/ Outside of the lock\n-  if (new_adapter != NULL) {\n-    char blob_id[256];\n-    jio_snprintf(blob_id,\n-                 sizeof(blob_id),\n-                 \"%s(%s)@\" PTR_FORMAT,\n-                 new_adapter->name(),\n-                 fingerprint->as_string(),\n-                 new_adapter->content_begin());\n-    Forte::register_stub(blob_id, new_adapter->content_begin(), new_adapter->content_end());\n+#endif\n@@ -2930,3 +3116,4 @@\n-    if (JvmtiExport::should_post_dynamic_code_generated()) {\n-      JvmtiExport::post_dynamic_code_generated(blob_id, new_adapter->content_begin(), new_adapter->content_end());\n-    }\n+  \/\/ Add the entry only if the entry contains all required checks (see sharedRuntime_xxx.cpp)\n+  \/\/ The checks are inserted only if -XX:+VerifyAdapterCalls is specified.\n+  if (contains_all_checks || !VerifyAdapterCalls) {\n+    _adapters->add(entry);\n@@ -2981,2 +3168,4 @@\n-bool AdapterHandlerEntry::compare_code(unsigned char* buffer, int length) {\n-  if (length != _saved_code_length) {\n+bool AdapterHandlerEntry::compare_code(AdapterHandlerEntry* other) {\n+  assert(_saved_code != NULL && other->_saved_code != NULL, \"code not saved\");\n+\n+  if (other->_saved_code_length != _saved_code_length) {\n@@ -2986,1 +3175,1 @@\n-  return (memcmp(buffer, _saved_code, length) == 0) ? true : false;\n+  return memcmp(other->_saved_code, _saved_code, _saved_code_length) == 0;\n@@ -3027,2 +3216,2 @@\n-      double locs_buf[20];\n-      buffer.insts()->initialize_shared_locs((relocInfo*)locs_buf, sizeof(locs_buf) \/ sizeof(relocInfo));\n+      struct { double data[20]; } locs_buf;\n+      buffer.insts()->initialize_shared_locs((relocInfo*)&locs_buf, sizeof(locs_buf) \/ sizeof(relocInfo));\n@@ -3040,13 +3229,2 @@\n-      BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, total_args_passed);\n-      VMRegPair*   regs = NEW_RESOURCE_ARRAY(VMRegPair, total_args_passed);\n-      int i=0;\n-      if (!method->is_static())  \/\/ Pass in receiver first\n-        sig_bt[i++] = T_OBJECT;\n-      SignatureStream ss(method->signature());\n-      for (; !ss.at_return_type(); ss.next()) {\n-        sig_bt[i++] = ss.type();  \/\/ Collect remaining bits of signature\n-        if (ss.type() == T_LONG || ss.type() == T_DOUBLE)\n-          sig_bt[i++] = T_VOID;   \/\/ Longs & doubles take 2 Java slots\n-      }\n-      assert(i == total_args_passed, \"\");\n-      BasicType ret_type = ss.type();\n+      VMRegPair stack_regs[16];\n+      VMRegPair* regs = (total_args_passed <= 16) ? stack_regs : NEW_RESOURCE_ARRAY(VMRegPair, total_args_passed);\n@@ -3054,5 +3232,8 @@\n-      \/\/ Now get the compiled-Java layout as input (or output) arguments.\n-      \/\/ NOTE: Stubs for compiled entry points of method handle intrinsics\n-      \/\/ are just trampolines so the argument registers must be outgoing ones.\n-      const bool is_outgoing = method->is_method_handle_intrinsic();\n-      int comp_args_on_stack = SharedRuntime::java_calling_convention(sig_bt, regs, total_args_passed, is_outgoing);\n+      AdapterSignatureIterator si(method->signature(), method->constMethod()->fingerprint(),\n+                              method->is_static(), total_args_passed);\n+      BasicType* sig_bt = si.basic_types();\n+      assert(si.slots() == total_args_passed, \"\");\n+      BasicType ret_type = si.return_type();\n+\n+      \/\/ Now get the compiled-Java arguments layout.\n+      int comp_args_on_stack = SharedRuntime::java_calling_convention(sig_bt, regs, total_args_passed);\n@@ -3093,30 +3274,0 @@\n-JRT_ENTRY_NO_ASYNC(void, SharedRuntime::block_for_jni_critical(JavaThread* thread))\n-  assert(thread == JavaThread::current(), \"must be\");\n-  \/\/ The code is about to enter a JNI lazy critical native method and\n-  \/\/ _needs_gc is true, so if this thread is already in a critical\n-  \/\/ section then just return, otherwise this thread should block\n-  \/\/ until needs_gc has been cleared.\n-  if (thread->in_critical()) {\n-    return;\n-  }\n-  \/\/ Lock and unlock a critical section to give the system a chance to block\n-  GCLocker::lock_critical(thread);\n-  GCLocker::unlock_critical(thread);\n-JRT_END\n-\n-JRT_LEAF(oopDesc*, SharedRuntime::pin_object(JavaThread* thread, oopDesc* obj))\n-  assert(Universe::heap()->supports_object_pinning(), \"Why we are here?\");\n-  assert(obj != NULL, \"Should not be null\");\n-  oop o(obj);\n-  o = Universe::heap()->pin_object(thread, o);\n-  assert(o != NULL, \"Should not be null\");\n-  return o;\n-JRT_END\n-\n-JRT_LEAF(void, SharedRuntime::unpin_object(JavaThread* thread, oopDesc* obj))\n-  assert(Universe::heap()->supports_object_pinning(), \"Why we are here?\");\n-  assert(obj != NULL, \"Should not be null\");\n-  oop o(obj);\n-  Universe::heap()->unpin_object(thread, o);\n-JRT_END\n-\n@@ -3132,1 +3283,1 @@\n-  (void) java_calling_convention(&sig_bt, &regs, 1, true);\n+  (void) java_calling_convention(&sig_bt, &regs, 1);\n@@ -3163,1 +3314,1 @@\n-  comp_args_on_stack = java_calling_convention(sig_bt, regs, cnt, true);\n+  comp_args_on_stack = java_calling_convention(sig_bt, regs, cnt);\n@@ -3203,1 +3354,7 @@\n-JRT_LEAF(intptr_t*, SharedRuntime::OSR_migration_begin( JavaThread *thread) )\n+JRT_LEAF(intptr_t*, SharedRuntime::OSR_migration_begin( JavaThread *current) )\n+  \/\/ During OSR migration, we unwind the interpreted frame and replace it with a compiled\n+  \/\/ frame. The stack watermark code below ensures that the interpreted frame is processed\n+  \/\/ before it gets unwound. This is helpful as the size of the compiled frame could be\n+  \/\/ larger than the interpreted frame, which could result in the new frame not being\n+  \/\/ processed correctly.\n+  StackWatermarkSet::before_unwind(current);\n@@ -3213,1 +3370,1 @@\n-  frame fr = thread->last_frame();\n+  frame fr = current->last_frame();\n@@ -3309,11 +3466,0 @@\n-#if INCLUDE_CDS\n-\n-void CDSAdapterHandlerEntry::init() {\n-  assert(DumpSharedSpaces, \"used during dump time only\");\n-  _c2i_entry_trampoline = (address)MetaspaceShared::misc_code_space_alloc(SharedRuntime::trampoline_size());\n-  _adapter_trampoline = (AdapterHandlerEntry**)MetaspaceShared::misc_code_space_alloc(sizeof(AdapterHandlerEntry*));\n-};\n-\n-#endif \/\/ INCLUDE_CDS\n-\n-\n@@ -3328,6 +3474,4 @@\n-JRT_LEAF(void, SharedRuntime::enable_stack_reserved_zone(JavaThread* thread))\n-  assert(thread->is_Java_thread(), \"Only Java threads have a stack reserved zone\");\n-  if (thread->stack_reserved_zone_disabled()) {\n-  thread->enable_stack_reserved_zone();\n-  }\n-  thread->set_reserved_stack_activation(thread->stack_base());\n+JRT_LEAF(void, SharedRuntime::enable_stack_reserved_zone(JavaThread* current))\n+  StackOverflow* overflow_state = current->stack_overflow_state();\n+  overflow_state->enable_stack_reserved_zone(\/*check_if_disabled*\/true);\n+  overflow_state->set_reserved_stack_activation(current->stack_base());\n@@ -3336,2 +3480,2 @@\n-frame SharedRuntime::look_for_reserved_stack_annotated_method(JavaThread* thread, frame fr) {\n-  ResourceMark rm(thread);\n+frame SharedRuntime::look_for_reserved_stack_annotated_method(JavaThread* current, frame fr) {\n+  ResourceMark rm(current);\n@@ -3387,1 +3531,1 @@\n-void SharedRuntime::on_slowpath_allocation_exit(JavaThread* thread) {\n+void SharedRuntime::on_slowpath_allocation_exit(JavaThread* current) {\n@@ -3393,1 +3537,1 @@\n-  oop new_obj = thread->vm_result();\n+  oop new_obj = current->vm_result();\n@@ -3397,1 +3541,1 @@\n-  bs->on_slowpath_allocation_exit(thread, new_obj);\n+  bs->on_slowpath_allocation_exit(current, new_obj);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":615,"deletions":471,"binary":false,"changes":1086,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,2 @@\n-#include \"interpreter\/bytecodeHistogram.hpp\"\n+#include \"code\/codeBlob.hpp\"\n+#include \"code\/vmreg.hpp\"\n@@ -54,3 +55,1 @@\n-  static methodHandle resolve_sub_helper(JavaThread *thread,\n-                                         bool is_virtual,\n-                                         bool is_optimized, TRAPS);\n+  static methodHandle resolve_sub_helper(bool is_virtual, bool is_optimized, TRAPS);\n@@ -80,1 +79,1 @@\n-  static int     _nof_megamorphic_calls;         \/\/ total # of megamorphic calls (through vtable)\n+  static int64_t _nof_megamorphic_calls;         \/\/ total # of megamorphic calls (through vtable)\n@@ -185,2 +184,2 @@\n-  static address raw_exception_handler_for_return_address(JavaThread* thread, address return_address);\n-  static address exception_handler_for_return_address(JavaThread* thread, address return_address);\n+  static address raw_exception_handler_for_return_address(JavaThread* current, address return_address);\n+  static address exception_handler_for_return_address(JavaThread* current, address return_address);\n@@ -196,9 +195,9 @@\n-  static void    throw_AbstractMethodError(JavaThread* thread);\n-  static void    throw_IncompatibleClassChangeError(JavaThread* thread);\n-  static void    throw_ArithmeticException(JavaThread* thread);\n-  static void    throw_NullPointerException(JavaThread* thread);\n-  static void    throw_NullPointerException_at_call(JavaThread* thread);\n-  static void    throw_StackOverflowError(JavaThread* thread);\n-  static void    throw_delayed_StackOverflowError(JavaThread* thread);\n-  static void    throw_StackOverflowError_common(JavaThread* thread, bool delayed);\n-  static address continuation_for_implicit_exception(JavaThread* thread,\n+  static void    throw_AbstractMethodError(JavaThread* current);\n+  static void    throw_IncompatibleClassChangeError(JavaThread* current);\n+  static void    throw_ArithmeticException(JavaThread* current);\n+  static void    throw_NullPointerException(JavaThread* current);\n+  static void    throw_NullPointerException_at_call(JavaThread* current);\n+  static void    throw_StackOverflowError(JavaThread* current);\n+  static void    throw_delayed_StackOverflowError(JavaThread* current);\n+  static void    throw_StackOverflowError_common(JavaThread* current, bool delayed);\n+  static address continuation_for_implicit_exception(JavaThread* current,\n@@ -210,1 +209,1 @@\n-  static void on_slowpath_allocation_exit(JavaThread* thread);\n+  static void on_slowpath_allocation_exit(JavaThread* current);\n@@ -212,2 +211,2 @@\n-  static void enable_stack_reserved_zone(JavaThread* thread);\n-  static frame look_for_reserved_stack_annotated_method(JavaThread* thread, frame fr);\n+  static void enable_stack_reserved_zone(JavaThread* current);\n+  static frame look_for_reserved_stack_annotated_method(JavaThread* current, frame fr);\n@@ -261,2 +260,2 @@\n-  static void throw_and_post_jvmti_exception(JavaThread *thread, Handle h_exception);\n-  static void throw_and_post_jvmti_exception(JavaThread *thread, Symbol* name, const char *message = NULL);\n+  static void throw_and_post_jvmti_exception(JavaThread* current, Handle h_exception);\n+  static void throw_and_post_jvmti_exception(JavaThread* current, Symbol* name, const char *message = NULL);\n@@ -269,1 +268,0 @@\n-  static address native_method_throw_unsupported_operation_exception_entry();\n@@ -410,3 +408,1 @@\n-  static methodHandle resolve_helper(JavaThread *thread,\n-                                     bool is_virtual,\n-                                     bool is_optimized, TRAPS);\n+  static methodHandle resolve_helper(bool is_virtual, bool is_optimized, TRAPS);\n@@ -426,1 +422,1 @@\n-  static methodHandle reresolve_call_site(JavaThread *thread, TRAPS);\n+  static methodHandle reresolve_call_site(TRAPS);\n@@ -430,1 +426,1 @@\n-  static methodHandle handle_ic_miss_helper(JavaThread* thread, TRAPS);\n+  static methodHandle handle_ic_miss_helper(TRAPS);\n@@ -433,1 +429,1 @@\n-  static methodHandle find_callee_method(JavaThread* thread, TRAPS);\n+  static methodHandle find_callee_method(TRAPS);\n@@ -437,1 +433,1 @@\n-  static void monitor_exit_helper(oopDesc* obj, BasicLock* lock, JavaThread* thread);\n+  static void monitor_exit_helper(oopDesc* obj, BasicLock* lock, JavaThread* current);\n@@ -440,7 +436,2 @@\n-  static Handle find_callee_info(JavaThread* thread,\n-                                 Bytecodes::Code& bc,\n-                                 CallInfo& callinfo, TRAPS);\n-  static Handle find_callee_info_helper(JavaThread* thread,\n-                                        vframeStream& vfst,\n-                                        Bytecodes::Code& bc,\n-                                        CallInfo& callinfo, TRAPS);\n+  static Handle find_callee_info(Bytecodes::Code& bc, CallInfo& callinfo, TRAPS);\n+  static Handle find_callee_info_helper(vframeStream& vfst, Bytecodes::Code& bc, CallInfo& callinfo, TRAPS);\n@@ -450,4 +441,0 @@\n-  static address clean_virtual_call_entry();\n-  static address clean_opt_virtual_call_entry();\n-  static address clean_static_call_entry();\n-\n@@ -467,3 +454,1 @@\n-  \/\/ 4-bytes higher. So for sparc because the register window save area is at\n-  \/\/ the bottom of the frame the first 16 words will be skipped and SharedInfo::stack0\n-  \/\/ will be just above it. (\n+  \/\/ 4-bytes higher.\n@@ -471,1 +456,1 @@\n-  static int java_calling_convention(const BasicType* sig_bt, VMRegPair* regs, int total_args_passed, int is_outgoing);\n+  static int java_calling_convention(const BasicType* sig_bt, VMRegPair* regs, int total_args_passed);\n@@ -488,1 +473,3 @@\n-  static size_t trampoline_size();\n+  static int vector_calling_convention(VMRegPair *regs,\n+                                       uint num_bits,\n+                                       uint total_args_passed);\n@@ -490,1 +477,1 @@\n-  static void generate_trampoline(MacroAssembler *masm, address destination);\n+  static size_t trampoline_size();\n@@ -560,0 +547,5 @@\n+  \/\/ Stack slots that may be unused by the calling convention but must\n+  \/\/ otherwise be preserved.  On Intel this includes the return address.\n+  \/\/ On PowerPC it includes the 4 words holding the old TOC & LR glue.\n+  static uint in_preserve_stack_slots();\n+\n@@ -585,7 +577,0 @@\n-  \/\/ Block before entering a JNI critical method\n-  static void block_for_jni_critical(JavaThread* thread);\n-\n-  \/\/ Pin\/Unpin object\n-  static oopDesc* pin_object(JavaThread* thread, oopDesc* obj);\n-  static void unpin_object(JavaThread* thread, oopDesc* obj);\n-\n@@ -598,2 +583,2 @@\n-  static void complete_monitor_locking_C(oopDesc* obj, BasicLock* lock, JavaThread* thread);\n-  static void complete_monitor_unlocking_C(oopDesc* obj, BasicLock* lock, JavaThread* thread);\n+  static void complete_monitor_locking_C(oopDesc* obj, BasicLock* lock, JavaThread* current);\n+  static void complete_monitor_unlocking_C(oopDesc* obj, BasicLock* lock, JavaThread* current);\n@@ -602,3 +587,3 @@\n-  static address resolve_static_call_C     (JavaThread *thread);\n-  static address resolve_virtual_call_C    (JavaThread *thread);\n-  static address resolve_opt_virtual_call_C(JavaThread *thread);\n+  static address resolve_static_call_C     (JavaThread* current);\n+  static address resolve_virtual_call_C    (JavaThread* current);\n+  static address resolve_opt_virtual_call_C(JavaThread* current);\n@@ -613,3 +598,3 @@\n-  static address handle_wrong_method(JavaThread* thread);\n-  static address handle_wrong_method_abstract(JavaThread* thread);\n-  static address handle_wrong_method_ic_miss(JavaThread* thread);\n+  static address handle_wrong_method(JavaThread* current);\n+  static address handle_wrong_method_abstract(JavaThread* current);\n+  static address handle_wrong_method_ic_miss(JavaThread* current);\n@@ -619,0 +604,13 @@\n+#ifdef COMPILER2\n+  static RuntimeStub* make_native_invoker(address call_target,\n+                                          int shadow_space_bytes,\n+                                          const GrowableArray<VMReg>& input_registers,\n+                                          const GrowableArray<VMReg>& output_registers);\n+#endif\n+\n+  static void compute_move_order(const BasicType* in_sig_bt,\n+                                 int total_in_args, const VMRegPair* in_regs,\n+                                 int total_out_args, VMRegPair* out_regs,\n+                                 GrowableArray<int>& arg_order,\n+                                 VMRegPair tmp_vmreg);\n+\n@@ -662,5 +660,5 @@\n-  static int     _nof_normal_calls;              \/\/ total # of calls\n-  static int     _nof_optimized_calls;           \/\/ total # of statically-bound calls\n-  static int     _nof_inlined_calls;             \/\/ total # of inlined normal calls\n-  static int     _nof_static_calls;              \/\/ total # of calls to static methods or super methods (invokespecial)\n-  static int     _nof_inlined_static_calls;      \/\/ total # of inlined static calls\n+  static int64_t _nof_normal_calls;               \/\/ total # of calls\n+  static int64_t _nof_optimized_calls;            \/\/ total # of statically-bound calls\n+  static int64_t _nof_inlined_calls;              \/\/ total # of inlined normal calls\n+  static int64_t _nof_static_calls;               \/\/ total # of calls to static methods or super methods (invokespecial)\n+  static int64_t _nof_inlined_static_calls;       \/\/ total # of inlined static calls\n@@ -668,6 +666,4 @@\n-  static int     _nof_interface_calls;           \/\/ total # of compiled calls\n-  static int     _nof_optimized_interface_calls; \/\/ total # of statically-bound interface calls\n-  static int     _nof_inlined_interface_calls;   \/\/ total # of inlined interface calls\n-  static int     _nof_megamorphic_interface_calls;\/\/ total # of megamorphic interface calls\n-  \/\/ stats for runtime exceptions\n-  static int     _nof_removable_exceptions;      \/\/ total # of exceptions that could be replaced by branches due to inlining\n+  static int64_t _nof_interface_calls;            \/\/ total # of compiled calls\n+  static int64_t _nof_optimized_interface_calls;  \/\/ total # of statically-bound interface calls\n+  static int64_t _nof_inlined_interface_calls;    \/\/ total # of inlined interface calls\n+  static int64_t _nof_megamorphic_interface_calls;\/\/ total # of megamorphic interface calls\n@@ -685,1 +681,1 @@\n-  static void print_call_statistics(int comp_total);\n+  static void print_call_statistics(uint64_t comp_total);\n@@ -728,0 +724,1 @@\n+  friend class AdapterHandlerLibrary;\n@@ -750,1 +747,0 @@\n-    _saved_code = NULL;\n@@ -778,1 +774,1 @@\n-  bool compare_code(unsigned char* code, int length);\n+  bool compare_code(AdapterHandlerEntry* other);\n@@ -785,14 +781,1 @@\n-\/\/ This class is used only with DumpSharedSpaces==true. It holds extra information\n-\/\/ that's used only during CDS dump time.\n-\/\/ For details, see comments around Method::link_method()\n-class CDSAdapterHandlerEntry: public AdapterHandlerEntry {\n-  address               _c2i_entry_trampoline;   \/\/ allocated from shared spaces \"MC\" region\n-  AdapterHandlerEntry** _adapter_trampoline;     \/\/ allocated from shared spaces \"MD\" region\n-\n-public:\n-  address get_c2i_entry_trampoline()             const { return _c2i_entry_trampoline; }\n-  AdapterHandlerEntry** get_adapter_trampoline() const { return _adapter_trampoline; }\n-  void init() NOT_CDS_RETURN;\n-};\n-\n-\n+  friend class SharedRuntime;\n@@ -804,0 +787,6 @@\n+  static AdapterHandlerEntry* _no_arg_handler;\n+  static AdapterHandlerEntry* _int_arg_handler;\n+  static AdapterHandlerEntry* _obj_arg_handler;\n+  static AdapterHandlerEntry* _obj_int_arg_handler;\n+  static AdapterHandlerEntry* _obj_obj_arg_handler;\n+\n@@ -806,2 +795,5 @@\n-  static AdapterHandlerEntry* get_adapter0(const methodHandle& method);\n-\n+  static AdapterHandlerEntry* create_adapter(AdapterBlob*& new_adapter,\n+                                             int total_args_passed,\n+                                             BasicType* sig_bt,\n+                                             bool allocate_code_blob);\n+  static AdapterHandlerEntry* get_simple_adapter(const methodHandle& method);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":84,"deletions":92,"binary":false,"changes":176,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,0 +27,1 @@\n+#include \"jfr\/jfrEvents.hpp\"\n@@ -29,2 +30,0 @@\n-#include \"jfr\/jfrEvents.hpp\"\n-#include \"memory\/metaspaceShared.hpp\"\n@@ -45,0 +44,1 @@\n+#include \"runtime\/os.inline.hpp\"\n@@ -46,0 +46,1 @@\n+#include \"runtime\/perfData.hpp\"\n@@ -60,0 +61,88 @@\n+void MonitorList::add(ObjectMonitor* m) {\n+  ObjectMonitor* head;\n+  do {\n+    head = Atomic::load(&_head);\n+    m->set_next_om(head);\n+  } while (Atomic::cmpxchg(&_head, head, m) != head);\n+\n+  size_t count = Atomic::add(&_count, 1u);\n+  if (count > max()) {\n+    Atomic::inc(&_max);\n+  }\n+}\n+\n+size_t MonitorList::count() const {\n+  return Atomic::load(&_count);\n+}\n+\n+size_t MonitorList::max() const {\n+  return Atomic::load(&_max);\n+}\n+\n+\/\/ Walk the in-use list and unlink (at most MonitorDeflationMax) deflated\n+\/\/ ObjectMonitors. Returns the number of unlinked ObjectMonitors.\n+size_t MonitorList::unlink_deflated(Thread* current, LogStream* ls,\n+                                    elapsedTimer* timer_p,\n+                                    GrowableArray<ObjectMonitor*>* unlinked_list) {\n+  size_t unlinked_count = 0;\n+  ObjectMonitor* prev = NULL;\n+  ObjectMonitor* head = Atomic::load_acquire(&_head);\n+  ObjectMonitor* m = head;\n+  \/\/ The in-use list head can be NULL during the final audit.\n+  while (m != NULL) {\n+    if (m->is_being_async_deflated()) {\n+      \/\/ Find next live ObjectMonitor.\n+      ObjectMonitor* next = m;\n+      do {\n+        ObjectMonitor* next_next = next->next_om();\n+        unlinked_count++;\n+        unlinked_list->append(next);\n+        next = next_next;\n+        if (unlinked_count >= (size_t)MonitorDeflationMax) {\n+          \/\/ Reached the max so bail out on the gathering loop.\n+          break;\n+        }\n+      } while (next != NULL && next->is_being_async_deflated());\n+      if (prev == NULL) {\n+        ObjectMonitor* prev_head = Atomic::cmpxchg(&_head, head, next);\n+        if (prev_head != head) {\n+          \/\/ Find new prev ObjectMonitor that just got inserted.\n+          for (ObjectMonitor* n = prev_head; n != m; n = n->next_om()) {\n+            prev = n;\n+          }\n+          prev->set_next_om(next);\n+        }\n+      } else {\n+        prev->set_next_om(next);\n+      }\n+      if (unlinked_count >= (size_t)MonitorDeflationMax) {\n+        \/\/ Reached the max so bail out on the searching loop.\n+        break;\n+      }\n+      m = next;\n+    } else {\n+      prev = m;\n+      m = m->next_om();\n+    }\n+\n+    if (current->is_Java_thread()) {\n+      \/\/ A JavaThread must check for a safepoint\/handshake and honor it.\n+      ObjectSynchronizer::chk_for_block_req(current->as_Java_thread(), \"unlinking\",\n+                                            \"unlinked_count\", unlinked_count,\n+                                            ls, timer_p);\n+    }\n+  }\n+  Atomic::sub(&_count, unlinked_count);\n+  return unlinked_count;\n+}\n+\n+MonitorList::Iterator MonitorList::iterator() const {\n+  return Iterator(Atomic::load_acquire(&_head));\n+}\n+\n+ObjectMonitor* MonitorList::Iterator::next() {\n+  ObjectMonitor* current = _current;\n+  _current = current->next_om();\n+  return current;\n+}\n+\n@@ -62,2 +151,2 @@\n-\/\/ variants of the enter-exit fast-path operations.  See i486.ad fast_lock(),\n-\/\/ for instance.  If you make changes here, make sure to modify the\n+\/\/ variants of the enter-exit fast-path operations.  See c2_MacroAssembler_x86.cpp\n+\/\/ fast_lock(...) for instance.  If you make changes here, make sure to modify the\n@@ -77,1 +166,1 @@\n-  Symbol* klassname = ((oop)(obj))->klass()->name();                       \\\n+  Symbol* klassname = obj->klass()->name();                                \\\n@@ -118,226 +207,2 @@\n-#define NINFLATIONLOCKS 256\n-static volatile intptr_t gInflationLocks[NINFLATIONLOCKS];\n-\n-\/\/ global list of blocks of monitors\n-PaddedObjectMonitor* ObjectSynchronizer::g_block_list = NULL;\n-bool volatile ObjectSynchronizer::_is_async_deflation_requested = false;\n-bool volatile ObjectSynchronizer::_is_special_deflation_requested = false;\n-jlong ObjectSynchronizer::_last_async_deflation_time_ns = 0;\n-\n-struct ObjectMonitorListGlobals {\n-  char         _pad_prefix[OM_CACHE_LINE_SIZE];\n-  \/\/ These are highly shared list related variables.\n-  \/\/ To avoid false-sharing they need to be the sole occupants of a cache line.\n-\n-  \/\/ Global ObjectMonitor free list. Newly allocated and deflated\n-  \/\/ ObjectMonitors are prepended here.\n-  ObjectMonitor* _free_list;\n-  DEFINE_PAD_MINUS_SIZE(1, OM_CACHE_LINE_SIZE, sizeof(ObjectMonitor*));\n-\n-  \/\/ Global ObjectMonitor in-use list. When a JavaThread is exiting,\n-  \/\/ ObjectMonitors on its per-thread in-use list are prepended here.\n-  ObjectMonitor* _in_use_list;\n-  DEFINE_PAD_MINUS_SIZE(2, OM_CACHE_LINE_SIZE, sizeof(ObjectMonitor*));\n-\n-  \/\/ Global ObjectMonitor wait list. Deflated ObjectMonitors wait on\n-  \/\/ this list until after a handshake or a safepoint for platforms\n-  \/\/ that don't support handshakes. After the handshake or safepoint,\n-  \/\/ the deflated ObjectMonitors are prepended to free_list.\n-  ObjectMonitor* _wait_list;\n-  DEFINE_PAD_MINUS_SIZE(3, OM_CACHE_LINE_SIZE, sizeof(ObjectMonitor*));\n-\n-  int _free_count;    \/\/ # on free_list\n-  DEFINE_PAD_MINUS_SIZE(4, OM_CACHE_LINE_SIZE, sizeof(int));\n-\n-  int _in_use_count;  \/\/ # on in_use_list\n-  DEFINE_PAD_MINUS_SIZE(5, OM_CACHE_LINE_SIZE, sizeof(int));\n-\n-  int _population;    \/\/ # Extant -- in circulation\n-  DEFINE_PAD_MINUS_SIZE(6, OM_CACHE_LINE_SIZE, sizeof(int));\n-\n-  int _wait_count;    \/\/ # on wait_list\n-  DEFINE_PAD_MINUS_SIZE(7, OM_CACHE_LINE_SIZE, sizeof(int));\n-};\n-static ObjectMonitorListGlobals om_list_globals;\n-\n-#define CHAINMARKER (cast_to_oop<intptr_t>(-1))\n-\n-\n-\/\/ =====================> Spin-lock functions\n-\n-\/\/ ObjectMonitors are not lockable outside of this file. We use spin-locks\n-\/\/ implemented using a bit in the _next_om field instead of the heavier\n-\/\/ weight locking mechanisms for faster list management.\n-\n-#define OM_LOCK_BIT 0x1\n-\n-\/\/ Return true if the ObjectMonitor is locked.\n-\/\/ Otherwise returns false.\n-static bool is_locked(ObjectMonitor* om) {\n-  return ((intptr_t)om->next_om_acquire() & OM_LOCK_BIT) == OM_LOCK_BIT;\n-}\n-\n-\/\/ Mark an ObjectMonitor* with OM_LOCK_BIT and return it.\n-static ObjectMonitor* mark_om_ptr(ObjectMonitor* om) {\n-  return (ObjectMonitor*)((intptr_t)om | OM_LOCK_BIT);\n-}\n-\n-\/\/ Return the unmarked next field in an ObjectMonitor. Note: the next\n-\/\/ field may or may not have been marked with OM_LOCK_BIT originally.\n-static ObjectMonitor* unmarked_next(ObjectMonitor* om) {\n-  return (ObjectMonitor*)((intptr_t)om->next_om() & ~OM_LOCK_BIT);\n-}\n-\n-\/\/ Try to lock an ObjectMonitor. Returns true if locking was successful.\n-\/\/ Otherwise returns false.\n-static bool try_om_lock(ObjectMonitor* om) {\n-  \/\/ Get current next field without any OM_LOCK_BIT value.\n-  ObjectMonitor* next = unmarked_next(om);\n-  if (om->try_set_next_om(next, mark_om_ptr(next)) != next) {\n-    return false;  \/\/ Cannot lock the ObjectMonitor.\n-  }\n-  return true;\n-}\n-\n-\/\/ Lock an ObjectMonitor.\n-static void om_lock(ObjectMonitor* om) {\n-  while (true) {\n-    if (try_om_lock(om)) {\n-      return;\n-    }\n-  }\n-}\n-\n-\/\/ Unlock an ObjectMonitor.\n-static void om_unlock(ObjectMonitor* om) {\n-  ObjectMonitor* next = om->next_om();\n-  guarantee(((intptr_t)next & OM_LOCK_BIT) == OM_LOCK_BIT, \"next=\" INTPTR_FORMAT\n-            \" must have OM_LOCK_BIT=%x set.\", p2i(next), OM_LOCK_BIT);\n-\n-  next = (ObjectMonitor*)((intptr_t)next & ~OM_LOCK_BIT);  \/\/ Clear OM_LOCK_BIT.\n-  om->release_set_next_om(next);\n-}\n-\n-\/\/ Get the list head after locking it. Returns the list head or NULL\n-\/\/ if the list is empty.\n-static ObjectMonitor* get_list_head_locked(ObjectMonitor** list_p) {\n-  while (true) {\n-    \/\/ Acquire semantics not needed on this list load since we're\n-    \/\/ checking for NULL here or following up with a cmpxchg() via\n-    \/\/ try_om_lock() below and we retry on cmpxchg() failure.\n-    ObjectMonitor* mid = Atomic::load(list_p);\n-    if (mid == NULL) {\n-      return NULL;  \/\/ The list is empty.\n-    }\n-    if (try_om_lock(mid)) {\n-      \/\/ Acquire semantics not needed on this list load since memory is\n-      \/\/ already consistent due to the cmpxchg() via try_om_lock() above.\n-      if (Atomic::load(list_p) != mid) {\n-        \/\/ The list head changed before we could lock it so we have to retry.\n-        om_unlock(mid);\n-        continue;\n-      }\n-      return mid;\n-    }\n-  }\n-}\n-\n-#undef OM_LOCK_BIT\n-\n-\n-\/\/ =====================> List Management functions\n-\n-\/\/ Prepend a list of ObjectMonitors to the specified *list_p. 'tail' is\n-\/\/ the last ObjectMonitor in the list and there are 'count' on the list.\n-\/\/ Also updates the specified *count_p.\n-static void prepend_list_to_common(ObjectMonitor* list, ObjectMonitor* tail,\n-                                   int count, ObjectMonitor** list_p,\n-                                   int* count_p) {\n-  while (true) {\n-    \/\/ Acquire semantics not needed on this list load since we're\n-    \/\/ following up with a cmpxchg() via try_om_lock() below and we\n-    \/\/ retry on cmpxchg() failure.\n-    ObjectMonitor* cur = Atomic::load(list_p);\n-    \/\/ Prepend list to *list_p.\n-    if (!try_om_lock(tail)) {\n-      \/\/ Failed to lock tail due to a list walker so try it all again.\n-      continue;\n-    }\n-    \/\/ Release semantics not needed on this \"unlock\" since memory is\n-    \/\/ already consistent due to the cmpxchg() via try_om_lock() above.\n-    tail->set_next_om(cur);  \/\/ tail now points to cur (and unlocks tail)\n-    if (cur == NULL) {\n-      \/\/ No potential race with takers or other prependers since\n-      \/\/ *list_p is empty.\n-      if (Atomic::cmpxchg(list_p, cur, list) == cur) {\n-        \/\/ Successfully switched *list_p to the list value.\n-        Atomic::add(count_p, count);\n-        break;\n-      }\n-      \/\/ Implied else: try it all again\n-    } else {\n-      if (!try_om_lock(cur)) {\n-        continue;  \/\/ failed to lock cur so try it all again\n-      }\n-      \/\/ We locked cur so try to switch *list_p to the list value.\n-      if (Atomic::cmpxchg(list_p, cur, list) != cur) {\n-        \/\/ The list head has changed so unlock cur and try again:\n-        om_unlock(cur);\n-        continue;\n-      }\n-      Atomic::add(count_p, count);\n-      om_unlock(cur);\n-      break;\n-    }\n-  }\n-}\n-\n-\/\/ Prepend a newly allocated block of ObjectMonitors to g_block_list and\n-\/\/ om_list_globals._free_list. Also updates om_list_globals._population\n-\/\/ and om_list_globals._free_count.\n-void ObjectSynchronizer::prepend_block_to_lists(PaddedObjectMonitor* new_blk) {\n-  \/\/ First we handle g_block_list:\n-  while (true) {\n-    PaddedObjectMonitor* cur = Atomic::load(&g_block_list);\n-    \/\/ Prepend new_blk to g_block_list. The first ObjectMonitor in\n-    \/\/ a block is reserved for use as linkage to the next block.\n-    new_blk[0].set_next_om(cur);\n-    if (Atomic::cmpxchg(&g_block_list, cur, new_blk) == cur) {\n-      \/\/ Successfully switched g_block_list to the new_blk value.\n-      Atomic::add(&om_list_globals._population, _BLOCKSIZE - 1);\n-      break;\n-    }\n-    \/\/ Implied else: try it all again\n-  }\n-\n-  \/\/ Second we handle om_list_globals._free_list:\n-  prepend_list_to_common(new_blk + 1, &new_blk[_BLOCKSIZE - 1], _BLOCKSIZE - 1,\n-                         &om_list_globals._free_list, &om_list_globals._free_count);\n-}\n-\n-\/\/ Prepend a list of ObjectMonitors to om_list_globals._free_list.\n-\/\/ 'tail' is the last ObjectMonitor in the list and there are 'count'\n-\/\/ on the list. Also updates om_list_globals._free_count.\n-static void prepend_list_to_global_free_list(ObjectMonitor* list,\n-                                             ObjectMonitor* tail, int count) {\n-  prepend_list_to_common(list, tail, count, &om_list_globals._free_list,\n-                         &om_list_globals._free_count);\n-}\n-\n-\/\/ Prepend a list of ObjectMonitors to om_list_globals._wait_list.\n-\/\/ 'tail' is the last ObjectMonitor in the list and there are 'count'\n-\/\/ on the list. Also updates om_list_globals._wait_count.\n-static void prepend_list_to_global_wait_list(ObjectMonitor* list,\n-                                             ObjectMonitor* tail, int count) {\n-  prepend_list_to_common(list, tail, count, &om_list_globals._wait_list,\n-                         &om_list_globals._wait_count);\n-}\n-\n-\/\/ Prepend a list of ObjectMonitors to om_list_globals._in_use_list.\n-\/\/ 'tail' is the last ObjectMonitor in the list and there are 'count'\n-\/\/ on the list. Also updates om_list_globals._in_use_list.\n-static void prepend_list_to_global_in_use_list(ObjectMonitor* list,\n-                                               ObjectMonitor* tail, int count) {\n-  prepend_list_to_common(list, tail, count, &om_list_globals._in_use_list,\n-                         &om_list_globals._in_use_count);\n-}\n+static const int NINFLATIONLOCKS = 256;\n+static os::PlatformMutex* gInflationLocks[NINFLATIONLOCKS];\n@@ -345,29 +210,3 @@\n-\/\/ Prepend an ObjectMonitor to the specified list. Also updates\n-\/\/ the specified counter.\n-static void prepend_to_common(ObjectMonitor* m, ObjectMonitor** list_p,\n-                              int* count_p) {\n-  while (true) {\n-    om_lock(m);  \/\/ Lock m so we can safely update its next field.\n-    ObjectMonitor* cur = NULL;\n-    \/\/ Lock the list head to guard against races with a list walker\n-    \/\/ or async deflater thread (which only races in om_in_use_list):\n-    if ((cur = get_list_head_locked(list_p)) != NULL) {\n-      \/\/ List head is now locked so we can safely switch it. Release\n-      \/\/ semantics not needed on this \"unlock\" since memory is already\n-      \/\/ consistent due to the cmpxchg() via get_list_head_locked() above.\n-      m->set_next_om(cur);  \/\/ m now points to cur (and unlocks m)\n-      OrderAccess::storestore();  \/\/ Make sure set_next_om() is seen first.\n-      Atomic::store(list_p, m);  \/\/ Switch list head to unlocked m.\n-      om_unlock(cur);\n-      break;\n-    }\n-    \/\/ The list is empty so try to set the list head.\n-    assert(cur == NULL, \"cur must be NULL: cur=\" INTPTR_FORMAT, p2i(cur));\n-    \/\/ Release semantics not needed on this \"unlock\" since memory\n-    \/\/ is already consistent.\n-    m->set_next_om(cur);  \/\/ m now points to NULL (and unlocks m)\n-    if (Atomic::cmpxchg(list_p, cur, m) == cur) {\n-      \/\/ List head is now unlocked m.\n-      break;\n-    }\n-    \/\/ Implied else: try it all again\n+void ObjectSynchronizer::initialize() {\n+  for (int i = 0; i < NINFLATIONLOCKS; i++) {\n+    gInflationLocks[i] = new os::PlatformMutex();\n@@ -375,51 +214,2 @@\n-  Atomic::inc(count_p);\n-}\n-\n-\/\/ Prepend an ObjectMonitor to a per-thread om_free_list.\n-\/\/ Also updates the per-thread om_free_count.\n-static void prepend_to_om_free_list(Thread* self, ObjectMonitor* m) {\n-  prepend_to_common(m, &self->om_free_list, &self->om_free_count);\n-}\n-\n-\/\/ Prepend an ObjectMonitor to a per-thread om_in_use_list.\n-\/\/ Also updates the per-thread om_in_use_count.\n-static void prepend_to_om_in_use_list(Thread* self, ObjectMonitor* m) {\n-  prepend_to_common(m, &self->om_in_use_list, &self->om_in_use_count);\n-}\n-\n-\/\/ Take an ObjectMonitor from the start of the specified list. Also\n-\/\/ decrements the specified counter. Returns NULL if none are available.\n-static ObjectMonitor* take_from_start_of_common(ObjectMonitor** list_p,\n-                                                int* count_p) {\n-  ObjectMonitor* take = NULL;\n-  \/\/ Lock the list head to guard against races with a list walker\n-  \/\/ or async deflater thread (which only races in om_list_globals._free_list):\n-  if ((take = get_list_head_locked(list_p)) == NULL) {\n-    return NULL;  \/\/ None are available.\n-  }\n-  ObjectMonitor* next = unmarked_next(take);\n-  \/\/ Switch locked list head to next (which unlocks the list head, but\n-  \/\/ leaves take locked). Release semantics not needed on this \"unlock\"\n-  \/\/ since memory is already consistent due to the cmpxchg() via\n-  \/\/ get_list_head_locked() above.\n-  Atomic::store(list_p, next);\n-  Atomic::dec(count_p);\n-  \/\/ Unlock take, but leave the next value for any lagging list\n-  \/\/ walkers. It will get cleaned up when take is prepended to\n-  \/\/ the in-use list:\n-  om_unlock(take);\n-  return take;\n-}\n-\n-\/\/ Take an ObjectMonitor from the start of the om_list_globals._free_list.\n-\/\/ Also updates om_list_globals._free_count. Returns NULL if none are\n-\/\/ available.\n-static ObjectMonitor* take_from_start_of_global_free_list() {\n-  return take_from_start_of_common(&om_list_globals._free_list,\n-                                   &om_list_globals._free_count);\n-}\n-\n-\/\/ Take an ObjectMonitor from the start of a per-thread free-list.\n-\/\/ Also updates om_free_count. Returns NULL if none are available.\n-static ObjectMonitor* take_from_start_of_om_free_list(Thread* self) {\n-  return take_from_start_of_common(&self->om_free_list, &self->om_free_count);\n+  \/\/ Start the ceiling with the estimate for one thread.\n+  set_in_use_list_ceiling(AvgMonitorsPerThreadEstimate);\n@@ -428,0 +218,26 @@\n+MonitorList ObjectSynchronizer::_in_use_list;\n+\/\/ monitors_used_above_threshold() policy is as follows:\n+\/\/\n+\/\/ The ratio of the current _in_use_list count to the ceiling is used\n+\/\/ to determine if we are above MonitorUsedDeflationThreshold and need\n+\/\/ to do an async monitor deflation cycle. The ceiling is increased by\n+\/\/ AvgMonitorsPerThreadEstimate when a thread is added to the system\n+\/\/ and is decreased by AvgMonitorsPerThreadEstimate when a thread is\n+\/\/ removed from the system.\n+\/\/\n+\/\/ Note: If the _in_use_list max exceeds the ceiling, then\n+\/\/ monitors_used_above_threshold() will use the in_use_list max instead\n+\/\/ of the thread count derived ceiling because we have used more\n+\/\/ ObjectMonitors than the estimated average.\n+\/\/\n+\/\/ Note: If deflate_idle_monitors() has NoAsyncDeflationProgressMax\n+\/\/ no-progress async monitor deflation cycles in a row, then the ceiling\n+\/\/ is adjusted upwards by monitors_used_above_threshold().\n+\/\/\n+\/\/ Start the ceiling with the estimate for one thread in initialize()\n+\/\/ which is called after cmd line options are processed.\n+static size_t _in_use_list_ceiling = 0;\n+bool volatile ObjectSynchronizer::_is_async_deflation_requested = false;\n+bool volatile ObjectSynchronizer::_is_final_audit = false;\n+jlong ObjectSynchronizer::_last_async_deflation_time_ns = 0;\n+static uintx _no_progress_cnt = 0;\n@@ -451,4 +267,2 @@\n-bool ObjectSynchronizer::quick_notify(oopDesc* obj, Thread* self, bool all) {\n-  assert(!SafepointSynchronize::is_at_safepoint(), \"invariant\");\n-  assert(self->is_Java_thread(), \"invariant\");\n-  assert(((JavaThread *) self)->thread_state() == _thread_in_Java, \"invariant\");\n+bool ObjectSynchronizer::quick_notify(oopDesc* obj, JavaThread* current, bool all) {\n+  assert(current->thread_state() == _thread_in_Java, \"invariant\");\n@@ -459,1 +273,1 @@\n-  if (mark.has_locker() && self->is_lock_owned((address)mark.locker())) {\n+  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n@@ -467,2 +281,2 @@\n-    assert(mon->object() == obj, \"invariant\");\n-    if (mon->owner() != self) return false;  \/\/ slow-path for IMS exception\n+    assert(mon->object() == oop(obj), \"invariant\");\n+    if (mon->owner() != current) return false;  \/\/ slow-path for IMS exception\n@@ -475,1 +289,1 @@\n-        DTRACE_MONITOR_PROBE(notifyAll, mon, obj, self);\n+        DTRACE_MONITOR_PROBE(notifyAll, mon, obj, current);\n@@ -477,1 +291,1 @@\n-        DTRACE_MONITOR_PROBE(notify, mon, obj, self);\n+        DTRACE_MONITOR_PROBE(notify, mon, obj, current);\n@@ -481,1 +295,1 @@\n-        mon->INotify(self);\n+        mon->INotify(current);\n@@ -500,1 +314,1 @@\n-bool ObjectSynchronizer::quick_enter(oop obj, Thread* self,\n+bool ObjectSynchronizer::quick_enter(oop obj, JavaThread* current,\n@@ -502,3 +316,1 @@\n-  assert(!SafepointSynchronize::is_at_safepoint(), \"invariant\");\n-  assert(self->is_Java_thread(), \"invariant\");\n-  assert(((JavaThread *) self)->thread_state() == _thread_in_Java, \"invariant\");\n+  assert(current->thread_state() == _thread_in_Java, \"invariant\");\n@@ -508,0 +320,4 @@\n+  if (obj->klass()->is_value_based()) {\n+    return false;\n+  }\n+\n@@ -512,9 +328,5 @@\n-    if (AsyncDeflateIdleMonitors) {\n-      \/\/ An async deflation can race us before we manage to make the\n-      \/\/ ObjectMonitor busy by setting the owner below. If we detect\n-      \/\/ that race we just bail out to the slow-path here.\n-      if (m->object() == NULL) {\n-        return false;\n-      }\n-    } else {\n-      assert(m->object() == obj, \"invariant\");\n+    \/\/ An async deflation or GC can race us before we manage to make\n+    \/\/ the ObjectMonitor busy by setting the owner below. If we detect\n+    \/\/ that race we just bail out to the slow-path here.\n+    if (m->object_peek() == NULL) {\n+      return false;\n@@ -522,1 +334,1 @@\n-    Thread* const owner = (Thread *) m->_owner;\n+    JavaThread* const owner = (JavaThread*) m->owner_raw();\n@@ -529,1 +341,1 @@\n-    if (owner == self) {\n+    if (owner == current) {\n@@ -546,1 +358,1 @@\n-    if (owner == NULL && m->try_set_owner_from(NULL, self) == NULL) {\n+    if (owner == NULL && m->try_set_owner_from(NULL, current) == NULL) {\n@@ -562,0 +374,49 @@\n+\/\/ Handle notifications when synchronizing on value based classes\n+void ObjectSynchronizer::handle_sync_on_value_based_class(Handle obj, JavaThread* current) {\n+  frame last_frame = current->last_frame();\n+  bool bcp_was_adjusted = false;\n+  \/\/ Don't decrement bcp if it points to the frame's first instruction.  This happens when\n+  \/\/ handle_sync_on_value_based_class() is called because of a synchronized method.  There\n+  \/\/ is no actual monitorenter instruction in the byte code in this case.\n+  if (last_frame.is_interpreted_frame() &&\n+      (last_frame.interpreter_frame_method()->code_base() < last_frame.interpreter_frame_bcp())) {\n+    \/\/ adjust bcp to point back to monitorenter so that we print the correct line numbers\n+    last_frame.interpreter_frame_set_bcp(last_frame.interpreter_frame_bcp() - 1);\n+    bcp_was_adjusted = true;\n+  }\n+\n+  if (DiagnoseSyncOnValueBasedClasses == FATAL_EXIT) {\n+    ResourceMark rm(current);\n+    stringStream ss;\n+    current->print_stack_on(&ss);\n+    char* base = (char*)strstr(ss.base(), \"at\");\n+    char* newline = (char*)strchr(ss.base(), '\\n');\n+    if (newline != NULL) {\n+      *newline = '\\0';\n+    }\n+    fatal(\"Synchronizing on object \" INTPTR_FORMAT \" of klass %s %s\", p2i(obj()), obj->klass()->external_name(), base);\n+  } else {\n+    assert(DiagnoseSyncOnValueBasedClasses == LOG_WARNING, \"invalid value for DiagnoseSyncOnValueBasedClasses\");\n+    ResourceMark rm(current);\n+    Log(valuebasedclasses) vblog;\n+\n+    vblog.info(\"Synchronizing on object \" INTPTR_FORMAT \" of klass %s\", p2i(obj()), obj->klass()->external_name());\n+    if (current->has_last_Java_frame()) {\n+      LogStream info_stream(vblog.info());\n+      current->print_stack_on(&info_stream);\n+    } else {\n+      vblog.info(\"Cannot find the last Java frame\");\n+    }\n+\n+    EventSyncOnValueBasedClass event;\n+    if (event.should_commit()) {\n+      event.set_valueBasedClass(obj->klass());\n+      event.commit();\n+    }\n+  }\n+\n+  if (bcp_was_adjusted) {\n+    last_frame.interpreter_frame_set_bcp(last_frame.interpreter_frame_bcp() + 1);\n+  }\n+}\n+\n@@ -568,1 +429,5 @@\n-void ObjectSynchronizer::enter(Handle obj, BasicLock* lock, TRAPS) {\n+void ObjectSynchronizer::enter(Handle obj, BasicLock* lock, JavaThread* current) {\n+  if (obj->klass()->is_value_based()) {\n+    handle_sync_on_value_based_class(obj, current);\n+  }\n+\n@@ -570,5 +435,1 @@\n-    if (!SafepointSynchronize::is_at_safepoint()) {\n-      BiasedLocking::revoke(obj, THREAD);\n-    } else {\n-      BiasedLocking::revoke_at_safepoint(obj);\n-    }\n+    BiasedLocking::revoke(current, obj);\n@@ -589,1 +450,1 @@\n-             THREAD->is_lock_owned((address)mark.locker())) {\n+             current->is_lock_owned((address)mark.locker())) {\n@@ -605,2 +466,2 @@\n-    ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_monitor_enter);\n-    if (monitor->enter(THREAD)) {\n+    ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_monitor_enter);\n+    if (monitor->enter(current)) {\n@@ -612,1 +473,1 @@\n-void ObjectSynchronizer::exit(oop object, BasicLock* lock, TRAPS) {\n+void ObjectSynchronizer::exit(oop object, BasicLock* lock, JavaThread* current) {\n@@ -629,1 +490,1 @@\n-             THREAD->is_lock_owned((address)mark.locker()), \"invariant\");\n+             current->is_lock_owned((address)mark.locker()), \"invariant\");\n@@ -640,2 +501,2 @@\n-        assert(((oop)(m->object()))->mark() == mark, \"invariant\");\n-        assert(m->is_entered(THREAD), \"invariant\");\n+        assert(m->object()->mark() == mark, \"invariant\");\n+        assert(m->is_entered(current), \"invariant\");\n@@ -660,2 +521,2 @@\n-  ObjectMonitor* monitor = inflate(THREAD, object, inflate_cause_vm_internal);\n-  monitor->exit(true, THREAD);\n+  ObjectMonitor* monitor = inflate(current, object, inflate_cause_vm_internal);\n+  monitor->exit(current);\n@@ -684,1 +545,1 @@\n-intx ObjectSynchronizer::complete_exit(Handle obj, TRAPS) {\n+intx ObjectSynchronizer::complete_exit(Handle obj, JavaThread* current) {\n@@ -686,1 +547,1 @@\n-    BiasedLocking::revoke(obj, THREAD);\n+    BiasedLocking::revoke(current, obj);\n@@ -692,2 +553,2 @@\n-  ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_vm_internal);\n-  intptr_t ret_code = monitor->complete_exit(THREAD);\n+  ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_vm_internal);\n+  intptr_t ret_code = monitor->complete_exit(current);\n@@ -698,1 +559,1 @@\n-void ObjectSynchronizer::reenter(Handle obj, intx recursions, TRAPS) {\n+void ObjectSynchronizer::reenter(Handle obj, intx recursions, JavaThread* current) {\n@@ -700,1 +561,1 @@\n-    BiasedLocking::revoke(obj, THREAD);\n+    BiasedLocking::revoke(current, obj);\n@@ -709,2 +570,2 @@\n-    ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_vm_internal);\n-    if (monitor->reenter(recursions, THREAD)) {\n+    ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_vm_internal);\n+    if (monitor->reenter(recursions, current)) {\n@@ -719,1 +580,5 @@\n-void ObjectSynchronizer::jni_enter(Handle obj, TRAPS) {\n+void ObjectSynchronizer::jni_enter(Handle obj, JavaThread* current) {\n+  if (obj->klass()->is_value_based()) {\n+    handle_sync_on_value_based_class(obj, current);\n+  }\n+\n@@ -722,1 +587,1 @@\n-    BiasedLocking::revoke(obj, THREAD);\n+    BiasedLocking::revoke(current, obj);\n@@ -725,1 +590,1 @@\n-  THREAD->set_current_pending_monitor_is_from_java(false);\n+  current->set_current_pending_monitor_is_from_java(false);\n@@ -730,2 +595,2 @@\n-    ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_jni_enter);\n-    if (monitor->enter(THREAD)) {\n+    ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_jni_enter);\n+    if (monitor->enter(current)) {\n@@ -735,2 +600,2 @@\n-  THREAD->set_current_pending_monitor_is_from_java(true);\n-  TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_lock(THREAD, obj()));\n+  current->set_current_pending_monitor_is_from_java(true);\n+  TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_lock(current, obj()));\n@@ -740,1 +605,2 @@\n-void ObjectSynchronizer::jni_exit(oop obj, Thread* THREAD) {\n+void ObjectSynchronizer::jni_exit(oop obj, TRAPS) {\n+  JavaThread* current = THREAD;\n@@ -742,2 +608,2 @@\n-    Handle h_obj(THREAD, obj);\n-    BiasedLocking::revoke(h_obj, THREAD);\n+    Handle h_obj(current, obj);\n+    BiasedLocking::revoke(current, h_obj);\n@@ -750,1 +616,1 @@\n-  ObjectMonitor* monitor = inflate(THREAD, obj, inflate_cause_jni_exit);\n+  ObjectMonitor* monitor = inflate(current, obj, inflate_cause_jni_exit);\n@@ -752,2 +618,2 @@\n-  \/\/ intentionally do not use CHECK here because we must exit the\n-  \/\/ monitor even if an exception is pending.\n+  \/\/ intentionally do not use CHECK on check_owner because we must exit the\n+  \/\/ monitor even if an exception was already pending.\n@@ -755,2 +621,2 @@\n-    TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_unlock(THREAD, obj));\n-    monitor->exit(true, THREAD);\n+    TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_unlock(current, obj));\n+    monitor->exit(current);\n@@ -763,2 +629,1 @@\n-ObjectLocker::ObjectLocker(Handle obj, Thread* thread, bool do_lock) {\n-  _dolock = do_lock;\n+ObjectLocker::ObjectLocker(Handle obj, JavaThread* thread) {\n@@ -769,1 +634,1 @@\n-  if (_dolock) {\n+  if (_obj() != NULL) {\n@@ -776,1 +641,1 @@\n-  if (_dolock) {\n+  if (_obj() != NULL) {\n@@ -787,0 +652,1 @@\n+  JavaThread* current = THREAD;\n@@ -788,1 +654,1 @@\n-    BiasedLocking::revoke(obj, THREAD);\n+    BiasedLocking::revoke(current, obj);\n@@ -797,1 +663,1 @@\n-  ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_wait);\n+  ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_wait);\n@@ -807,1 +673,1 @@\n-  monitor->wait(millis, true, THREAD);\n+  monitor->wait(millis, true, THREAD); \/\/ Not CHECK as we need following code\n@@ -819,1 +685,3 @@\n-void ObjectSynchronizer::wait_uninterruptibly(Handle obj, jlong millis, TRAPS) {\n+\/\/ No exception are possible in this case as we only use this internally when locking is\n+\/\/ correct and we have to wait until notified - so no interrupts or timeouts.\n+void ObjectSynchronizer::wait_uninterruptibly(Handle obj, JavaThread* current) {\n@@ -821,1 +689,1 @@\n-    BiasedLocking::revoke(obj, THREAD);\n+    BiasedLocking::revoke(current, obj);\n@@ -824,3 +692,0 @@\n-  if (millis < 0) {\n-    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), \"timeout value is negative\");\n-  }\n@@ -830,1 +695,1 @@\n-  ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_wait);\n+  ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_wait);\n@@ -833,1 +698,1 @@\n-    tsan_rec = SharedRuntime::tsan_oop_rec_unlock(THREAD, obj());\n+    tsan_rec = SharedRuntime::tsan_oop_rec_unlock(current, obj());\n@@ -836,2 +701,2 @@\n-  monitor->wait(millis, false, THREAD);\n-  TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_rec_lock(THREAD, obj(), tsan_rec));\n+  monitor->wait(0 \/* wait-forever *\/, false \/* not interruptible *\/, current);\n+  TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_rec_lock(current, obj(), tsan_rec));\n@@ -841,0 +706,1 @@\n+  JavaThread* current = THREAD;\n@@ -842,1 +708,1 @@\n-    BiasedLocking::revoke(obj, THREAD);\n+    BiasedLocking::revoke(current, obj);\n@@ -847,1 +713,2 @@\n-  if (mark.has_locker() && THREAD->is_lock_owned((address)mark.locker())) {\n+  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+    \/\/ Not inflated so there can't be any waiters to notify.\n@@ -852,2 +719,2 @@\n-  ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_notify);\n-  monitor->notify(THREAD);\n+  ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_notify);\n+  monitor->notify(CHECK);\n@@ -858,0 +725,1 @@\n+  JavaThread* current = THREAD;\n@@ -859,1 +727,1 @@\n-    BiasedLocking::revoke(obj, THREAD);\n+    BiasedLocking::revoke(current, obj);\n@@ -864,1 +732,2 @@\n-  if (mark.has_locker() && THREAD->is_lock_owned((address)mark.locker())) {\n+  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+    \/\/ Not inflated so there can't be any waiters to notify.\n@@ -869,2 +738,2 @@\n-  ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_notify);\n-  monitor->notifyAll(THREAD);\n+  ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_notify);\n+  monitor->notifyAll(CHECK);\n@@ -875,18 +744,0 @@\n-\/\/\n-\/\/ Performance concern:\n-\/\/ OrderAccess::storestore() calls release() which at one time stored 0\n-\/\/ into the global volatile OrderAccess::dummy variable. This store was\n-\/\/ unnecessary for correctness. Many threads storing into a common location\n-\/\/ causes considerable cache migration or \"sloshing\" on large SMP systems.\n-\/\/ As such, I avoided using OrderAccess::storestore(). In some cases\n-\/\/ OrderAccess::fence() -- which incurs local latency on the executing\n-\/\/ processor -- is a better choice as it scales on SMP systems.\n-\/\/\n-\/\/ See http:\/\/blogs.oracle.com\/dave\/entry\/biased_locking_in_hotspot for\n-\/\/ a discussion of coherency costs. Note that all our current reference\n-\/\/ platforms provide strong ST-ST order, so the issue is moot on IA32,\n-\/\/ x64, and SPARC.\n-\/\/\n-\/\/ As a general policy we use \"volatile\" to control compiler-based reordering\n-\/\/ and explicit fences (barriers) to control for architectural reordering\n-\/\/ performed by the CPU(s) or platform.\n@@ -896,2 +747,2 @@\n-  \/\/ These are highly shared mostly-read variables.\n-  \/\/ To avoid false-sharing they need to be the sole occupants of a cache line.\n+  \/\/ This is a highly shared mostly-read variable.\n+  \/\/ To avoid false-sharing it needs to be the sole occupant of a cache line.\n@@ -899,2 +750,1 @@\n-  volatile int stw_cycle;\n-  DEFINE_PAD_MINUS_SIZE(1, OM_CACHE_LINE_SIZE, sizeof(volatile int) * 2);\n+  DEFINE_PAD_MINUS_SIZE(1, OM_CACHE_LINE_SIZE, sizeof(volatile int));\n@@ -923,7 +773,1 @@\n-    \/\/ Avoid live-lock\n-    \/\/ TODO: consider calling SafepointSynchronize::do_call_back() while\n-    \/\/ spinning to see if there's a safepoint pending.  If so, immediately\n-    \/\/ yielding or blocking would be appropriate.  Avoid spinning while\n-    \/\/ there is a safepoint pending.\n-    \/\/ TODO: add inflation contention performance counters.\n-    \/\/ TODO: restrict the aggregate number of spinners.\n+    \/\/ Avoid live-lock.\n@@ -949,2 +793,3 @@\n-        \/\/ This is conceptually similar to muxAcquire-muxRelease, except that muxRelease\n-        \/\/ wakes at most one thread whereas we need to wake the entire list.\n+\n+        \/\/ Index into the lock array based on the current object address.\n+        static_assert(is_power_of_2(NINFLATIONLOCKS), \"must be\");\n@@ -954,2 +799,1 @@\n-        assert((NINFLATIONLOCKS & (NINFLATIONLOCKS-1)) == 0, \"invariant\");\n-        Thread::muxAcquire(gInflationLocks + ix, \"gInflationLock\");\n+        gInflationLocks[ix]->lock();\n@@ -957,2 +801,2 @@\n-          \/\/ Beware: NakedYield() is advisory and has almost no effect on some platforms\n-          \/\/ so we periodically call self->_ParkEvent->park(1).\n+          \/\/ Beware: naked_yield() is advisory and has almost no effect on some platforms\n+          \/\/ so we periodically call current->_ParkEvent->park(1).\n@@ -966,1 +810,1 @@\n-        Thread::muxRelease(gInflationLocks + ix);\n+        gInflationLocks[ix]->unlock();\n@@ -991,1 +835,1 @@\n-static inline intptr_t get_next_hash(Thread* self, oop obj) {\n+static inline intptr_t get_next_hash(Thread* current, oop obj) {\n@@ -1014,1 +858,1 @@\n-    unsigned t = self->_hashStateX;\n+    unsigned t = current->_hashStateX;\n@@ -1016,4 +860,4 @@\n-    self->_hashStateX = self->_hashStateY;\n-    self->_hashStateY = self->_hashStateZ;\n-    self->_hashStateZ = self->_hashStateW;\n-    unsigned v = self->_hashStateW;\n+    current->_hashStateX = current->_hashStateY;\n+    current->_hashStateY = current->_hashStateZ;\n+    current->_hashStateZ = current->_hashStateW;\n+    unsigned v = current->_hashStateW;\n@@ -1021,1 +865,1 @@\n-    self->_hashStateW = v;\n+    current->_hashStateW = v;\n@@ -1031,1 +875,1 @@\n-intptr_t ObjectSynchronizer::FastHashCode(Thread* self, oop obj) {\n+intptr_t ObjectSynchronizer::FastHashCode(Thread* current, oop obj) {\n@@ -1034,3 +878,2 @@\n-    \/\/ to be taken here, in particular most operations on perm gen\n-    \/\/ objects. However, we only ever bias Java instances and all of\n-    \/\/ the call sites of identity_hash that might revoke biases have\n+    \/\/ to be taken here. However, we only ever bias Java instances and all\n+    \/\/ of the call sites of identity_hash that might revoke biases have\n@@ -1042,6 +885,6 @@\n-      Handle hobj(self, obj);\n-      \/\/ Relaxing assertion for bug 6320749.\n-      assert(Universe::verify_in_progress() ||\n-             !SafepointSynchronize::is_at_safepoint(),\n-             \"biases should not be seen by VM thread here\");\n-      BiasedLocking::revoke(hobj, JavaThread::current());\n+      Handle hobj(current, obj);\n+      if (SafepointSynchronize::is_at_safepoint()) {\n+        BiasedLocking::revoke_at_safepoint(hobj);\n+      } else {\n+        BiasedLocking::revoke(current->as_Java_thread(), hobj);\n+      }\n@@ -1053,9 +896,0 @@\n-  \/\/ hashCode() is a heap mutator ...\n-  \/\/ Relaxing assertion for bug 6320749.\n-  assert(Universe::verify_in_progress() || DumpSharedSpaces ||\n-         !SafepointSynchronize::is_at_safepoint(), \"invariant\");\n-  assert(Universe::verify_in_progress() || DumpSharedSpaces ||\n-         self->is_Java_thread() , \"invariant\");\n-  assert(Universe::verify_in_progress() || DumpSharedSpaces ||\n-         ((JavaThread *)self)->thread_state() != _thread_blocked, \"invariant\");\n-\n@@ -1071,1 +905,1 @@\n-    if (mark.is_neutral()) {            \/\/ if this is a normal header\n+    if (mark.is_neutral()) {               \/\/ if this is a normal header\n@@ -1073,1 +907,1 @@\n-      if (hash != 0) {                  \/\/ if it has a hash, just return it\n+      if (hash != 0) {                     \/\/ if it has a hash, just return it\n@@ -1076,3 +910,3 @@\n-      hash = get_next_hash(self, obj);  \/\/ get a new hash\n-      temp = mark.copy_set_hash(hash);  \/\/ merge the hash into header\n-                                        \/\/ try to install the hash\n+      hash = get_next_hash(current, obj);  \/\/ get a new hash\n+      temp = mark.copy_set_hash(hash);     \/\/ merge the hash into header\n+                                           \/\/ try to install the hash\n@@ -1080,1 +914,1 @@\n-      if (test == mark) {               \/\/ if the hash was installed, return it\n+      if (test == mark) {                  \/\/ if the hash was installed, return it\n@@ -1097,7 +931,5 @@\n-        if (support_IRIW_for_not_multiple_copy_atomic_cpu) {\n-          \/\/ A non-multiple copy atomic (nMCA) machine needs a bigger\n-          \/\/ hammer to separate the load above and the loads below.\n-          OrderAccess::fence();\n-        } else {\n-          OrderAccess::loadload();\n-        }\n+\n+        \/\/ dmw\/header and _contentions may get written by different threads.\n+        \/\/ Make sure to observe them in the same order when having several observers.\n+        OrderAccess::loadload_for_IRIW();\n+\n@@ -1116,1 +948,1 @@\n-    } else if (self->is_lock_owned((address)mark.locker())) {\n+    } else if (current->is_lock_owned((address)mark.locker())) {\n@@ -1139,1 +971,1 @@\n-    monitor = inflate(self, obj, inflate_cause_hash_code);\n+    monitor = inflate(current, obj, inflate_cause_hash_code);\n@@ -1144,3 +976,3 @@\n-    if (hash == 0) {                    \/\/ if it does not have a hash\n-      hash = get_next_hash(self, obj);  \/\/ get a new hash\n-      temp = mark.copy_set_hash(hash);  \/\/ merge the hash into header\n+    if (hash == 0) {                       \/\/ if it does not have a hash\n+      hash = get_next_hash(current, obj);  \/\/ get a new hash\n+      temp = mark.copy_set_hash(hash)   ;  \/\/ merge the hash into header\n@@ -1181,1 +1013,1 @@\n-bool ObjectSynchronizer::current_thread_holds_lock(JavaThread* thread,\n+bool ObjectSynchronizer::current_thread_holds_lock(JavaThread* current,\n@@ -1184,1 +1016,1 @@\n-    BiasedLocking::revoke(h_obj, thread);\n+    BiasedLocking::revoke(current, h_obj);\n@@ -1188,1 +1020,1 @@\n-  assert(thread == JavaThread::current(), \"Can only be called on current thread\");\n+  assert(current == JavaThread::current(), \"Can only be called on current thread\");\n@@ -1195,1 +1027,1 @@\n-    return thread->is_lock_owned((address)mark.locker());\n+    return current->is_lock_owned((address)mark.locker());\n@@ -1202,1 +1034,1 @@\n-    return monitor->is_entered(thread) != 0;\n+    return monitor->is_entered(current) != 0;\n@@ -1209,49 +1041,0 @@\n-\/\/ Be aware of this method could revoke bias of the lock object.\n-\/\/ This method queries the ownership of the lock handle specified by 'h_obj'.\n-\/\/ If the current thread owns the lock, it returns owner_self. If no\n-\/\/ thread owns the lock, it returns owner_none. Otherwise, it will return\n-\/\/ owner_other.\n-ObjectSynchronizer::LockOwnership ObjectSynchronizer::query_lock_ownership\n-(JavaThread *self, Handle h_obj) {\n-  \/\/ The caller must beware this method can revoke bias, and\n-  \/\/ revocation can result in a safepoint.\n-  assert(!SafepointSynchronize::is_at_safepoint(), \"invariant\");\n-  assert(self->thread_state() != _thread_blocked, \"invariant\");\n-\n-  \/\/ Possible mark states: neutral, biased, stack-locked, inflated\n-\n-  if (UseBiasedLocking && h_obj()->mark().has_bias_pattern()) {\n-    \/\/ CASE: biased\n-    BiasedLocking::revoke(h_obj, self);\n-    assert(!h_obj->mark().has_bias_pattern(),\n-           \"biases should be revoked by now\");\n-  }\n-\n-  assert(self == JavaThread::current(), \"Can only be called on current thread\");\n-  oop obj = h_obj();\n-  markWord mark = read_stable_mark(obj);\n-\n-  \/\/ CASE: stack-locked.  Mark points to a BasicLock on the owner's stack.\n-  if (mark.has_locker()) {\n-    return self->is_lock_owned((address)mark.locker()) ?\n-      owner_self : owner_other;\n-  }\n-\n-  \/\/ CASE: inflated. Mark (tagged pointer) points to an ObjectMonitor.\n-  \/\/ The Object:ObjectMonitor relationship is stable as long as we're\n-  \/\/ not at a safepoint and AsyncDeflateIdleMonitors is false.\n-  if (mark.has_monitor()) {\n-    \/\/ The first stage of async deflation does not affect any field\n-    \/\/ used by this comparison so the ObjectMonitor* is usable here.\n-    ObjectMonitor* monitor = mark.monitor();\n-    void* owner = monitor->owner();\n-    if (owner == NULL) return owner_none;\n-    return (owner == self ||\n-            self->is_lock_owned((address)owner)) ? owner_self : owner_other;\n-  }\n-\n-  \/\/ CASE: neutral\n-  assert(mark.is_neutral(), \"sanity check\");\n-  return owner_none;           \/\/ it's unlocked\n-}\n-\n@@ -1264,1 +1047,1 @@\n-      BiasedLocking::revoke(h_obj, JavaThread::current());\n+      BiasedLocking::revoke(JavaThread::current(), h_obj);\n@@ -1304,16 +1087,13 @@\n-  PaddedObjectMonitor* block = Atomic::load(&g_block_list);\n-  while (block != NULL) {\n-    assert(block->object() == CHAINMARKER, \"must be a block header\");\n-    for (int i = _BLOCKSIZE - 1; i > 0; i--) {\n-      ObjectMonitor* mid = (ObjectMonitor *)(block + i);\n-      if (mid->object() != NULL) {\n-        \/\/ Only process with closure if the object is set.\n-\n-        \/\/ monitors_iterate() is only called at a safepoint or when the\n-        \/\/ target thread is suspended or when the target thread is\n-        \/\/ operating on itself. The current closures in use today are\n-        \/\/ only interested in an owned ObjectMonitor and ownership\n-        \/\/ cannot be dropped under the calling contexts so the\n-        \/\/ ObjectMonitor cannot be async deflated.\n-        closure->do_monitor(mid);\n-      }\n+  MonitorList::Iterator iter = _in_use_list.iterator();\n+  while (iter.has_next()) {\n+    ObjectMonitor* mid = iter.next();\n+    if (!mid->is_being_async_deflated() && mid->object_peek() != NULL) {\n+      \/\/ Only process with closure if the object is set.\n+\n+      \/\/ monitors_iterate() is only called at a safepoint or when the\n+      \/\/ target thread is suspended or when the target thread is\n+      \/\/ operating on itself. The current closures in use today are\n+      \/\/ only interested in an owned ObjectMonitor and ownership\n+      \/\/ cannot be dropped under the calling contexts so the\n+      \/\/ ObjectMonitor cannot be async deflated.\n+      closure->do_monitor(mid);\n@@ -1321,3 +1101,0 @@\n-    \/\/ unmarked_next() is not needed with g_block_list (no locking\n-    \/\/ used with block linkage _next_om fields).\n-    block = (PaddedObjectMonitor*)block->next_om();\n@@ -1327,3 +1104,2 @@\n-static bool monitors_used_above_threshold() {\n-  int population = Atomic::load(&om_list_globals._population);\n-  if (population == 0) {\n+static bool monitors_used_above_threshold(MonitorList* list) {\n+  if (MonitorUsedDeflationThreshold == 0) {  \/\/ disabled case is easy\n@@ -1332,5 +1108,6 @@\n-  if (MonitorUsedDeflationThreshold > 0) {\n-    int monitors_used = population - Atomic::load(&om_list_globals._free_count) -\n-                        Atomic::load(&om_list_globals._wait_count);\n-    int monitor_usage = (monitors_used * 100LL) \/ population;\n-    return monitor_usage > MonitorUsedDeflationThreshold;\n+  \/\/ Start with ceiling based on a per-thread estimate:\n+  size_t ceiling = ObjectSynchronizer::in_use_list_ceiling();\n+  size_t old_ceiling = ceiling;\n+  if (ceiling < list->max()) {\n+    \/\/ The max used by the system has exceeded the ceiling so use that:\n+    ceiling = list->max();\n@@ -1338,1 +1115,35 @@\n-  return false;\n+  size_t monitors_used = list->count();\n+  if (monitors_used == 0) {  \/\/ empty list is easy\n+    return false;\n+  }\n+  if (NoAsyncDeflationProgressMax != 0 &&\n+      _no_progress_cnt >= NoAsyncDeflationProgressMax) {\n+    float remainder = (100.0 - MonitorUsedDeflationThreshold) \/ 100.0;\n+    size_t new_ceiling = ceiling + (ceiling * remainder) + 1;\n+    ObjectSynchronizer::set_in_use_list_ceiling(new_ceiling);\n+    log_info(monitorinflation)(\"Too many deflations without progress; \"\n+                               \"bumping in_use_list_ceiling from \" SIZE_FORMAT\n+                               \" to \" SIZE_FORMAT, old_ceiling, new_ceiling);\n+    _no_progress_cnt = 0;\n+    ceiling = new_ceiling;\n+  }\n+\n+  \/\/ Check if our monitor usage is above the threshold:\n+  size_t monitor_usage = (monitors_used * 100LL) \/ ceiling;\n+  return int(monitor_usage) > MonitorUsedDeflationThreshold;\n+}\n+\n+size_t ObjectSynchronizer::in_use_list_ceiling() {\n+  return _in_use_list_ceiling;\n+}\n+\n+void ObjectSynchronizer::dec_in_use_list_ceiling() {\n+  Atomic::sub(&_in_use_list_ceiling, AvgMonitorsPerThreadEstimate);\n+}\n+\n+void ObjectSynchronizer::inc_in_use_list_ceiling() {\n+  Atomic::add(&_in_use_list_ceiling, AvgMonitorsPerThreadEstimate);\n+}\n+\n+void ObjectSynchronizer::set_in_use_list_ceiling(size_t new_value) {\n+  _in_use_list_ceiling = new_value;\n@@ -1342,3 +1153,0 @@\n-  if (!AsyncDeflateIdleMonitors) {\n-    return false;\n-  }\n@@ -1351,1 +1159,1 @@\n-      monitors_used_above_threshold()) {\n+      monitors_used_above_threshold(&_in_use_list)) {\n@@ -1355,2 +1163,1 @@\n-    \/\/ in order to not swamp the ServiceThread.\n-    _last_async_deflation_time_ns = os::javaTimeNanos();\n+    \/\/ in order to not swamp the MonitorDeflationThread.\n@@ -1362,5 +1169,21 @@\n-bool ObjectSynchronizer::is_safepoint_deflation_needed() {\n-  if (!AsyncDeflateIdleMonitors) {\n-    if (monitors_used_above_threshold()) {\n-      \/\/ Too many monitors in use.\n-      return true;\n+bool ObjectSynchronizer::request_deflate_idle_monitors() {\n+  JavaThread* current = JavaThread::current();\n+  bool ret_code = false;\n+\n+  jlong last_time = last_async_deflation_time_ns();\n+  set_is_async_deflation_requested(true);\n+  {\n+    MonitorLocker ml(MonitorDeflation_lock, Mutex::_no_safepoint_check_flag);\n+    ml.notify_all();\n+  }\n+  const int N_CHECKS = 5;\n+  for (int i = 0; i < N_CHECKS; i++) {  \/\/ sleep for at most 5 seconds\n+    if (last_async_deflation_time_ns() > last_time) {\n+      log_info(monitorinflation)(\"Async Deflation happened after %d check(s).\", i);\n+      ret_code = true;\n+      break;\n+    }\n+    {\n+      \/\/ JavaThread has to honor the blocking protocol.\n+      ThreadBlockInVM tbivm(current);\n+      os::naked_short_sleep(999);  \/\/ sleep for almost 1 second\n@@ -1368,5 +1191,2 @@\n-    return false;\n-  if (is_special_deflation_requested()) {\n-    \/\/ For AsyncDeflateIdleMonitors only do a safepoint deflation\n-    \/\/ if there is a special deflation request.\n-    return true;\n+  if (!ret_code) {\n+    log_info(monitorinflation)(\"Async Deflation DID NOT happen after %d checks.\", N_CHECKS);\n@@ -1375,10 +1195,1 @@\n-  return false;\n-}\n-\n-jlong ObjectSynchronizer::time_since_last_async_deflation_ms() {\n-  return (os::javaTimeNanos() - _last_async_deflation_time_ns) \/ (NANOUNITS \/ MILLIUNITS);\n-}\n-void ObjectSynchronizer::oops_do(OopClosure* f) {\n-  \/\/ We only scan the global used list here (for moribund threads), and\n-  \/\/ the thread-local monitors in Thread::oops_do().\n-  global_used_oops_do(f);\n+  return ret_code;\n@@ -1388,4 +1199,2 @@\n-void ObjectSynchronizer::global_used_oops_do(OopClosure* f) {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"must be at safepoint\");\n-  \/\/ Acquire semantics not needed since we're at a safepoint.\n-  list_oops_do(Atomic::load(&om_list_globals._in_use_list), f);\n+jlong ObjectSynchronizer::time_since_last_async_deflation_ms() {\n+  return (os::javaTimeNanos() - last_async_deflation_time_ns()) \/ (NANOUNITS \/ MILLIUNITS);\n@@ -1394,3 +1203,9 @@\n-void ObjectSynchronizer::thread_local_used_oops_do(Thread* thread, OopClosure* f) {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"must be at safepoint\");\n-  list_oops_do(thread->om_in_use_list, f);\n+static void post_monitor_inflate_event(EventJavaMonitorInflate* event,\n+                                       const oop obj,\n+                                       ObjectSynchronizer::InflateCause cause) {\n+  assert(event != NULL, \"invariant\");\n+  assert(event->should_commit(), \"invariant\");\n+  event->set_monitorClass(obj->klass());\n+  event->set_address((uintptr_t)(void*)obj);\n+  event->set_cause((u1)cause);\n+  event->commit();\n@@ -1399,8 +1214,8 @@\n-void ObjectSynchronizer::list_oops_do(ObjectMonitor* list, OopClosure* f) {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"must be at safepoint\");\n-  \/\/ The oops_do() phase does not overlap with monitor deflation\n-  \/\/ so no need to lock ObjectMonitors for the list traversal.\n-  for (ObjectMonitor* mid = list; mid != NULL; mid = unmarked_next(mid)) {\n-    if (mid->object() != NULL) {\n-      f->do_oop((oop*)mid->object_addr());\n-    }\n+\/\/ Fast path code shared by multiple functions\n+void ObjectSynchronizer::inflate_helper(oop obj) {\n+  markWord mark = obj->mark();\n+  if (mark.has_monitor()) {\n+    ObjectMonitor* monitor = mark.monitor();\n+    markWord dmw = monitor->header();\n+    assert(dmw.is_neutral(), \"sanity check: header=\" INTPTR_FORMAT, dmw.value());\n+    return;\n@@ -1408,0 +1223,1 @@\n+  (void)inflate(Thread::current(), obj, inflate_cause_vm_internal);\n@@ -1410,25 +1226,3 @@\n-\n-\/\/ -----------------------------------------------------------------------------\n-\/\/ ObjectMonitor Lifecycle\n-\/\/ -----------------------\n-\/\/ Inflation unlinks monitors from om_list_globals._free_list or a per-thread\n-\/\/ free list and associates them with objects. Deflation -- which occurs at\n-\/\/ STW-time or asynchronously -- disassociates idle monitors from objects.\n-\/\/ Such scavenged monitors are returned to the om_list_globals._free_list.\n-\/\/\n-\/\/ ObjectMonitors reside in type-stable memory (TSM) and are immortal.\n-\/\/\n-\/\/ Lifecycle:\n-\/\/ --   unassigned and on the om_list_globals._free_list\n-\/\/ --   unassigned and on a per-thread free list\n-\/\/ --   assigned to an object.  The object is inflated and the mark refers\n-\/\/      to the ObjectMonitor.\n-\n-ObjectMonitor* ObjectSynchronizer::om_alloc(Thread* self) {\n-  \/\/ A large MAXPRIVATE value reduces both list lock contention\n-  \/\/ and list coherency traffic, but also tends to increase the\n-  \/\/ number of ObjectMonitors in circulation as well as the STW\n-  \/\/ scavenge costs.  As usual, we lean toward time in space-time\n-  \/\/ tradeoffs.\n-  const int MAXPRIVATE = 1024;\n-  NoSafepointVerifier nsv;\n+ObjectMonitor* ObjectSynchronizer::inflate(Thread* current, oop object,\n+                                           const InflateCause cause) {\n+  EventJavaMonitorInflate event;\n@@ -1437,406 +1231,2 @@\n-    ObjectMonitor* m;\n-\n-    \/\/ 1: try to allocate from the thread's local om_free_list.\n-    \/\/ Threads will attempt to allocate first from their local list, then\n-    \/\/ from the global list, and only after those attempts fail will the\n-    \/\/ thread attempt to instantiate new monitors. Thread-local free lists\n-    \/\/ improve allocation latency, as well as reducing coherency traffic\n-    \/\/ on the shared global list.\n-    m = take_from_start_of_om_free_list(self);\n-    if (m != NULL) {\n-      guarantee(m->object() == NULL, \"invariant\");\n-      m->set_allocation_state(ObjectMonitor::New);\n-      prepend_to_om_in_use_list(self, m);\n-      return m;\n-    }\n-\n-    \/\/ 2: try to allocate from the global om_list_globals._free_list\n-    \/\/ If we're using thread-local free lists then try\n-    \/\/ to reprovision the caller's free list.\n-    \/\/ Acquire semantics not needed on this list load since memory\n-    \/\/ is already consistent due to the cmpxchg() via\n-    \/\/ take_from_start_of_om_free_list() above.\n-    if (Atomic::load(&om_list_globals._free_list) != NULL) {\n-      \/\/ Reprovision the thread's om_free_list.\n-      \/\/ Use bulk transfers to reduce the allocation rate and heat\n-      \/\/ on various locks.\n-      for (int i = self->om_free_provision; --i >= 0;) {\n-        ObjectMonitor* take = take_from_start_of_global_free_list();\n-        if (take == NULL) {\n-          break;  \/\/ No more are available.\n-        }\n-        guarantee(take->object() == NULL, \"invariant\");\n-        if (AsyncDeflateIdleMonitors) {\n-          \/\/ We allowed 3 field values to linger during async deflation.\n-          \/\/ Clear or restore them as appropriate.\n-          take->set_header(markWord::zero());\n-          \/\/ DEFLATER_MARKER is the only non-NULL value we should see here.\n-          take->try_set_owner_from(DEFLATER_MARKER, NULL);\n-          if (take->contentions() < 0) {\n-            \/\/ Add back max_jint to restore the contentions field to its\n-            \/\/ proper value.\n-            take->add_to_contentions(max_jint);\n-\n-#ifdef ASSERT\n-            jint l_contentions = take->contentions();\n-#endif\n-            assert(l_contentions >= 0, \"must not be negative: l_contentions=%d, contentions=%d\",\n-                   l_contentions, take->contentions());\n-          }\n-        }\n-        take->Recycle();\n-        \/\/ Since we're taking from the global free-list, take must be Free.\n-        \/\/ om_release() also sets the allocation state to Free because it\n-        \/\/ is called from other code paths.\n-        assert(take->is_free(), \"invariant\");\n-        om_release(self, take, false);\n-      }\n-      self->om_free_provision += 1 + (self->om_free_provision \/ 2);\n-      if (self->om_free_provision > MAXPRIVATE) self->om_free_provision = MAXPRIVATE;\n-      continue;\n-    }\n-\n-    \/\/ 3: allocate a block of new ObjectMonitors\n-    \/\/ Both the local and global free lists are empty -- resort to malloc().\n-    \/\/ In the current implementation ObjectMonitors are TSM - immortal.\n-    \/\/ Ideally, we'd write \"new ObjectMonitor[_BLOCKSIZE], but we want\n-    \/\/ each ObjectMonitor to start at the beginning of a cache line,\n-    \/\/ so we use align_up().\n-    \/\/ A better solution would be to use C++ placement-new.\n-    \/\/ BEWARE: As it stands currently, we don't run the ctors!\n-    assert(_BLOCKSIZE > 1, \"invariant\");\n-    size_t neededsize = sizeof(PaddedObjectMonitor) * _BLOCKSIZE;\n-    PaddedObjectMonitor* temp;\n-    size_t aligned_size = neededsize + (OM_CACHE_LINE_SIZE - 1);\n-    void* real_malloc_addr = NEW_C_HEAP_ARRAY(char, aligned_size, mtInternal);\n-    temp = (PaddedObjectMonitor*)align_up(real_malloc_addr, OM_CACHE_LINE_SIZE);\n-    (void)memset((void *) temp, 0, neededsize);\n-\n-    \/\/ Format the block.\n-    \/\/ initialize the linked list, each monitor points to its next\n-    \/\/ forming the single linked free list, the very first monitor\n-    \/\/ will points to next block, which forms the block list.\n-    \/\/ The trick of using the 1st element in the block as g_block_list\n-    \/\/ linkage should be reconsidered.  A better implementation would\n-    \/\/ look like: class Block { Block * next; int N; ObjectMonitor Body [N] ; }\n-\n-    for (int i = 1; i < _BLOCKSIZE; i++) {\n-      temp[i].set_next_om((ObjectMonitor*)&temp[i + 1]);\n-      assert(temp[i].is_free(), \"invariant\");\n-    }\n-\n-    \/\/ terminate the last monitor as the end of list\n-    temp[_BLOCKSIZE - 1].set_next_om((ObjectMonitor*)NULL);\n-\n-    \/\/ Element [0] is reserved for global list linkage\n-    temp[0].set_object(CHAINMARKER);\n-\n-    \/\/ Consider carving out this thread's current request from the\n-    \/\/ block in hand.  This avoids some lock traffic and redundant\n-    \/\/ list activity.\n-\n-    prepend_block_to_lists(temp);\n-  }\n-}\n-\n-\/\/ Place \"m\" on the caller's private per-thread om_free_list.\n-\/\/ In practice there's no need to clamp or limit the number of\n-\/\/ monitors on a thread's om_free_list as the only non-allocation time\n-\/\/ we'll call om_release() is to return a monitor to the free list after\n-\/\/ a CAS attempt failed. This doesn't allow unbounded #s of monitors to\n-\/\/ accumulate on a thread's free list.\n-\/\/\n-\/\/ Key constraint: all ObjectMonitors on a thread's free list and the global\n-\/\/ free list must have their object field set to null. This prevents the\n-\/\/ scavenger -- deflate_monitor_list() or deflate_monitor_list_using_JT()\n-\/\/ -- from reclaiming them while we are trying to release them.\n-\n-void ObjectSynchronizer::om_release(Thread* self, ObjectMonitor* m,\n-                                    bool from_per_thread_alloc) {\n-  guarantee(m->header().value() == 0, \"invariant\");\n-  guarantee(m->object() == NULL, \"invariant\");\n-  NoSafepointVerifier nsv;\n-\n-  if ((m->is_busy() | m->_recursions) != 0) {\n-    stringStream ss;\n-    fatal(\"freeing in-use monitor: %s, recursions=\" INTX_FORMAT,\n-          m->is_busy_to_string(&ss), m->_recursions);\n-  }\n-  m->set_allocation_state(ObjectMonitor::Free);\n-  \/\/ _next_om is used for both per-thread in-use and free lists so\n-  \/\/ we have to remove 'm' from the in-use list first (as needed).\n-  if (from_per_thread_alloc) {\n-    \/\/ Need to remove 'm' from om_in_use_list.\n-    ObjectMonitor* mid = NULL;\n-    ObjectMonitor* next = NULL;\n-\n-    \/\/ This list walk can race with another list walker or with async\n-    \/\/ deflation so we have to worry about an ObjectMonitor being\n-    \/\/ removed from this list while we are walking it.\n-\n-    \/\/ Lock the list head to avoid racing with another list walker\n-    \/\/ or with async deflation.\n-    if ((mid = get_list_head_locked(&self->om_in_use_list)) == NULL) {\n-      fatal(\"thread=\" INTPTR_FORMAT \" in-use list must not be empty.\", p2i(self));\n-    }\n-    next = unmarked_next(mid);\n-    if (m == mid) {\n-      \/\/ First special case:\n-      \/\/ 'm' matches mid, is the list head and is locked. Switch the list\n-      \/\/ head to next which unlocks the list head, but leaves the extracted\n-      \/\/ mid locked. Release semantics not needed on this \"unlock\" since\n-      \/\/ memory is already consistent due to the get_list_head_locked()\n-      \/\/ above.\n-      Atomic::store(&self->om_in_use_list, next);\n-    } else if (m == next) {\n-      \/\/ Second special case:\n-      \/\/ 'm' matches next after the list head and we already have the list\n-      \/\/ head locked so set mid to what we are extracting:\n-      mid = next;\n-      \/\/ Lock mid to prevent races with a list walker or an async\n-      \/\/ deflater thread that's ahead of us. The locked list head\n-      \/\/ prevents races from behind us.\n-      om_lock(mid);\n-      \/\/ Update next to what follows mid (if anything):\n-      next = unmarked_next(mid);\n-      \/\/ Switch next after the list head to new next which unlocks the\n-      \/\/ list head, but leaves the extracted mid locked. Release semantics\n-      \/\/ not needed on this \"unlock\" since memory is already consistent\n-      \/\/ due to the get_list_head_locked() above.\n-      self->om_in_use_list->set_next_om(next);\n-    } else {\n-      \/\/ We have to search the list to find 'm'.\n-      guarantee(next != NULL, \"thread=\" INTPTR_FORMAT \": om_in_use_list=\" INTPTR_FORMAT\n-                \" is too short.\", p2i(self), p2i(self->om_in_use_list));\n-      \/\/ Our starting anchor is next after the list head which is the\n-      \/\/ last ObjectMonitor we checked:\n-      ObjectMonitor* anchor = next;\n-      \/\/ Lock anchor to prevent races with a list walker or an async\n-      \/\/ deflater thread that's ahead of us. The locked list head\n-      \/\/ prevents races from behind us.\n-      om_lock(anchor);\n-      om_unlock(mid);  \/\/ Unlock the list head now that anchor is locked.\n-      while ((mid = unmarked_next(anchor)) != NULL) {\n-        if (m == mid) {\n-          \/\/ We found 'm' on the per-thread in-use list so extract it.\n-          \/\/ Update next to what follows mid (if anything):\n-          next = unmarked_next(mid);\n-          \/\/ Switch next after the anchor to new next which unlocks the\n-          \/\/ anchor, but leaves the extracted mid locked. Release semantics\n-          \/\/ not needed on this \"unlock\" since memory is already consistent\n-          \/\/ due to the om_unlock() above before entering the loop or the\n-          \/\/ om_unlock() below before looping again.\n-          anchor->set_next_om(next);\n-          break;\n-        } else {\n-          \/\/ Lock the next anchor to prevent races with a list walker\n-          \/\/ or an async deflater thread that's ahead of us. The locked\n-          \/\/ current anchor prevents races from behind us.\n-          om_lock(mid);\n-          \/\/ Unlock current anchor now that next anchor is locked:\n-          om_unlock(anchor);\n-          anchor = mid;  \/\/ Advance to new anchor and try again.\n-        }\n-      }\n-    }\n-\n-    if (mid == NULL) {\n-      \/\/ Reached end of the list and didn't find 'm' so:\n-      fatal(\"thread=\" INTPTR_FORMAT \" must find m=\" INTPTR_FORMAT \"on om_in_use_list=\"\n-            INTPTR_FORMAT, p2i(self), p2i(m), p2i(self->om_in_use_list));\n-    }\n-\n-    \/\/ At this point mid is disconnected from the in-use list so\n-    \/\/ its lock no longer has any effects on the in-use list.\n-    Atomic::dec(&self->om_in_use_count);\n-    \/\/ Unlock mid, but leave the next value for any lagging list\n-    \/\/ walkers. It will get cleaned up when mid is prepended to\n-    \/\/ the thread's free list:\n-    om_unlock(mid);\n-  }\n-\n-  prepend_to_om_free_list(self, m);\n-  guarantee(m->is_free(), \"invariant\");\n-}\n-\n-\/\/ Return ObjectMonitors on a moribund thread's free and in-use\n-\/\/ lists to the appropriate global lists. The ObjectMonitors on the\n-\/\/ per-thread in-use list may still be in use by other threads.\n-\/\/\n-\/\/ We currently call om_flush() from Threads::remove() before the\n-\/\/ thread has been excised from the thread list and is no longer a\n-\/\/ mutator. This means that om_flush() cannot run concurrently with\n-\/\/ a safepoint and interleave with deflate_idle_monitors(). In\n-\/\/ particular, this ensures that the thread's in-use monitors are\n-\/\/ scanned by a GC safepoint, either via Thread::oops_do() (before\n-\/\/ om_flush() is called) or via ObjectSynchronizer::oops_do() (after\n-\/\/ om_flush() is called).\n-\/\/\n-\/\/ With AsyncDeflateIdleMonitors, deflate_global_idle_monitors_using_JT()\n-\/\/ and deflate_per_thread_idle_monitors_using_JT() (in another thread) can\n-\/\/ run at the same time as om_flush() so we have to follow a careful\n-\/\/ protocol to prevent list corruption.\n-\n-void ObjectSynchronizer::om_flush(Thread* self) {\n-  \/\/ Process the per-thread in-use list first to be consistent.\n-  int in_use_count = 0;\n-  ObjectMonitor* in_use_list = NULL;\n-  ObjectMonitor* in_use_tail = NULL;\n-  NoSafepointVerifier nsv;\n-\n-  \/\/ This function can race with a list walker or with an async\n-  \/\/ deflater thread so we lock the list head to prevent confusion.\n-  \/\/ An async deflater thread checks to see if the target thread\n-  \/\/ is exiting, but if it has made it past that check before we\n-  \/\/ started exiting, then it is racing to get to the in-use list.\n-  if ((in_use_list = get_list_head_locked(&self->om_in_use_list)) != NULL) {\n-    \/\/ At this point, we have locked the in-use list head so a racing\n-    \/\/ thread cannot come in after us. However, a racing thread could\n-    \/\/ be ahead of us; we'll detect that and delay to let it finish.\n-    \/\/\n-    \/\/ The thread is going away, however the ObjectMonitors on the\n-    \/\/ om_in_use_list may still be in-use by other threads. Link\n-    \/\/ them to in_use_tail, which will be linked into the global\n-    \/\/ in-use list (om_list_globals._in_use_list) below.\n-    \/\/\n-    \/\/ Account for the in-use list head before the loop since it is\n-    \/\/ already locked (by this thread):\n-    in_use_tail = in_use_list;\n-    in_use_count++;\n-    for (ObjectMonitor* cur_om = unmarked_next(in_use_list); cur_om != NULL;) {\n-      if (is_locked(cur_om)) {\n-        \/\/ cur_om is locked so there must be a racing walker or async\n-        \/\/ deflater thread ahead of us so we'll give it a chance to finish.\n-        while (is_locked(cur_om)) {\n-          os::naked_short_sleep(1);\n-        }\n-        \/\/ Refetch the possibly changed next field and try again.\n-        cur_om = unmarked_next(in_use_tail);\n-        continue;\n-      }\n-      if (cur_om->object() == NULL) {\n-        \/\/ cur_om was deflated and the object ref was cleared while it\n-        \/\/ was locked. We happened to see it just after it was unlocked\n-        \/\/ (and added to the free list). Refetch the possibly changed\n-        \/\/ next field and try again.\n-        cur_om = unmarked_next(in_use_tail);\n-        continue;\n-      }\n-      in_use_tail = cur_om;\n-      in_use_count++;\n-      cur_om = unmarked_next(cur_om);\n-    }\n-    guarantee(in_use_tail != NULL, \"invariant\");\n-    int l_om_in_use_count = Atomic::load(&self->om_in_use_count);\n-    ADIM_guarantee(l_om_in_use_count == in_use_count, \"in-use counts don't match: \"\n-                   \"l_om_in_use_count=%d, in_use_count=%d\", l_om_in_use_count, in_use_count);\n-    Atomic::store(&self->om_in_use_count, 0);\n-    OrderAccess::storestore();  \/\/ Make sure counter update is seen first.\n-    \/\/ Clear the in-use list head (which also unlocks it):\n-    Atomic::store(&self->om_in_use_list, (ObjectMonitor*)NULL);\n-    om_unlock(in_use_list);\n-  }\n-\n-  int free_count = 0;\n-  ObjectMonitor* free_list = NULL;\n-  ObjectMonitor* free_tail = NULL;\n-  \/\/ This function can race with a list walker thread so we lock the\n-  \/\/ list head to prevent confusion.\n-  if ((free_list = get_list_head_locked(&self->om_free_list)) != NULL) {\n-    \/\/ At this point, we have locked the free list head so a racing\n-    \/\/ thread cannot come in after us. However, a racing thread could\n-    \/\/ be ahead of us; we'll detect that and delay to let it finish.\n-    \/\/\n-    \/\/ The thread is going away. Set 'free_tail' to the last per-thread free\n-    \/\/ monitor which will be linked to om_list_globals._free_list below.\n-    \/\/\n-    \/\/ Account for the free list head before the loop since it is\n-    \/\/ already locked (by this thread):\n-    free_tail = free_list;\n-    free_count++;\n-    for (ObjectMonitor* s = unmarked_next(free_list); s != NULL; s = unmarked_next(s)) {\n-      if (is_locked(s)) {\n-        \/\/ s is locked so there must be a racing walker thread ahead\n-        \/\/ of us so we'll give it a chance to finish.\n-        while (is_locked(s)) {\n-          os::naked_short_sleep(1);\n-        }\n-      }\n-      free_tail = s;\n-      free_count++;\n-      guarantee(s->object() == NULL, \"invariant\");\n-      if (s->is_busy()) {\n-        stringStream ss;\n-        fatal(\"must be !is_busy: %s\", s->is_busy_to_string(&ss));\n-      }\n-    }\n-    guarantee(free_tail != NULL, \"invariant\");\n-    int l_om_free_count = Atomic::load(&self->om_free_count);\n-    ADIM_guarantee(l_om_free_count == free_count, \"free counts don't match: \"\n-                   \"l_om_free_count=%d, free_count=%d\", l_om_free_count, free_count);\n-    Atomic::store(&self->om_free_count, 0);\n-    OrderAccess::storestore();  \/\/ Make sure counter update is seen first.\n-    Atomic::store(&self->om_free_list, (ObjectMonitor*)NULL);\n-    om_unlock(free_list);\n-  }\n-\n-  if (free_tail != NULL) {\n-    prepend_list_to_global_free_list(free_list, free_tail, free_count);\n-  }\n-\n-  if (in_use_tail != NULL) {\n-    prepend_list_to_global_in_use_list(in_use_list, in_use_tail, in_use_count);\n-  }\n-\n-  LogStreamHandle(Debug, monitorinflation) lsh_debug;\n-  LogStreamHandle(Info, monitorinflation) lsh_info;\n-  LogStream* ls = NULL;\n-  if (log_is_enabled(Debug, monitorinflation)) {\n-    ls = &lsh_debug;\n-  } else if ((free_count != 0 || in_use_count != 0) &&\n-             log_is_enabled(Info, monitorinflation)) {\n-    ls = &lsh_info;\n-  }\n-  if (ls != NULL) {\n-    ls->print_cr(\"om_flush: jt=\" INTPTR_FORMAT \", free_count=%d\"\n-                 \", in_use_count=%d\" \", om_free_provision=%d\",\n-                 p2i(self), free_count, in_use_count, self->om_free_provision);\n-  }\n-}\n-\n-static void post_monitor_inflate_event(EventJavaMonitorInflate* event,\n-                                       const oop obj,\n-                                       ObjectSynchronizer::InflateCause cause) {\n-  assert(event != NULL, \"invariant\");\n-  assert(event->should_commit(), \"invariant\");\n-  event->set_monitorClass(obj->klass());\n-  event->set_address((uintptr_t)(void*)obj);\n-  event->set_cause((u1)cause);\n-  event->commit();\n-}\n-\n-\/\/ Fast path code shared by multiple functions\n-void ObjectSynchronizer::inflate_helper(oop obj) {\n-  markWord mark = obj->mark();\n-  if (mark.has_monitor()) {\n-    ObjectMonitor* monitor = mark.monitor();\n-    assert(ObjectSynchronizer::verify_objmon_isinpool(monitor), \"monitor=\" INTPTR_FORMAT \" is invalid\", p2i(monitor));\n-    markWord dmw = monitor->header();\n-    assert(dmw.is_neutral(), \"sanity check: header=\" INTPTR_FORMAT, dmw.value());\n-    return;\n-  }\n-  (void)inflate(Thread::current(), obj, inflate_cause_vm_internal);\n-}\n-\n-ObjectMonitor* ObjectSynchronizer::inflate(Thread* self, oop object,\n-                                           const InflateCause cause) {\n-  \/\/ Inflate mutates the heap ...\n-  \/\/ Relaxing assertion for bug 6320749.\n-  assert(Universe::verify_in_progress() ||\n-         !SafepointSynchronize::is_at_safepoint(), \"invariant\");\n-\n-  EventJavaMonitorInflate event;\n-\n-  for (;;) {\n-    const markWord mark = object->mark();\n-    assert(!mark.has_bias_pattern(), \"invariant\");\n+    const markWord mark = object->mark();\n+    assert(!mark.has_bias_pattern(), \"invariant\");\n@@ -1856,2 +1246,0 @@\n-      assert(AsyncDeflateIdleMonitors || inf->object() == object, \"invariant\");\n-      assert(ObjectSynchronizer::verify_objmon_isinpool(inf), \"monitor is invalid\");\n@@ -1875,1 +1263,1 @@\n-    \/\/ Note that we allocate the objectmonitor speculatively, _before_ attempting\n+    \/\/ Note that we allocate the ObjectMonitor speculatively, _before_ attempting\n@@ -1877,3 +1265,3 @@\n-    \/\/ allocated the objectmonitor, and then finally STed the address of the\n-    \/\/ objectmonitor into the mark.  This was correct, but artificially lengthened\n-    \/\/ the interval in which INFLATED appeared in the mark, thus increasing\n+    \/\/ allocated the ObjectMonitor, and then finally STed the address of the\n+    \/\/ ObjectMonitor into the mark.  This was correct, but artificially lengthened\n+    \/\/ the interval in which INFLATING appeared in the mark, thus increasing\n@@ -1881,9 +1269,0 @@\n-    \/\/\n-    \/\/ We now use per-thread private objectmonitor free lists.\n-    \/\/ These list are reprovisioned from the global free list outside the\n-    \/\/ critical INFLATING...ST interval.  A thread can transfer\n-    \/\/ multiple objectmonitors en-mass from the global free list to its local free list.\n-    \/\/ This reduces coherency traffic and lock contention on the global free list.\n-    \/\/ Using such local free lists, it doesn't matter if the om_alloc() call appears\n-    \/\/ before or after the CAS(INFLATING) operation.\n-    \/\/ See the comments in om_alloc().\n@@ -1894,2 +1273,2 @@\n-      ObjectMonitor* m = om_alloc(self);\n-      \/\/ Optimistically prepare the objectmonitor - anticipate successful CAS\n+      ObjectMonitor* m = new ObjectMonitor(object);\n+      \/\/ Optimistically prepare the ObjectMonitor - anticipate successful CAS\n@@ -1898,3 +1277,0 @@\n-      m->Recycle();\n-      m->_Responsible  = NULL;\n-      m->_SpinDuration = ObjectMonitor::Knob_SpinLimit;   \/\/ Consider: maintain by type\/class\n@@ -1904,2 +1280,1 @@\n-        \/\/ om_release() will reset the allocation state from New to Free.\n-        om_release(self, m, true);\n+        delete m;\n@@ -1942,1 +1317,1 @@\n-      ADIM_guarantee(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n+      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n@@ -1948,1 +1323,1 @@\n-      \/\/ with this thread we could simply set m->_owner = self.\n+      \/\/ with this thread we could simply set m->_owner = current.\n@@ -1952,6 +1327,1 @@\n-      if (AsyncDeflateIdleMonitors) {\n-        m->set_owner_from(NULL, DEFLATER_MARKER, mark.locker());\n-      } else {\n-        m->set_owner_from(NULL, mark.locker());\n-      }\n-      m->set_object(object);\n+      m->set_owner_from(NULL, mark.locker());\n@@ -1968,3 +1338,1 @@\n-      assert(m->is_new(), \"freshly allocated monitor must be new\");\n-      \/\/ Release semantics needed to keep allocation_state from floating up.\n-      m->release_set_allocation_state(ObjectMonitor::Old);\n+      _in_use_list.add(m);\n@@ -1976,1 +1344,1 @@\n-        ResourceMark rm(self);\n+        ResourceMark rm(current);\n@@ -1993,1 +1361,1 @@\n-    \/\/ to inflate and then CAS() again to try to swing _owner from NULL to self.\n+    \/\/ to inflate and then CAS() again to try to swing _owner from NULL to current.\n@@ -1998,2 +1366,2 @@\n-    ADIM_guarantee(mark.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, mark.value());\n-    ObjectMonitor* m = om_alloc(self);\n+    assert(mark.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, mark.value());\n+    ObjectMonitor* m = new ObjectMonitor(object);\n@@ -2001,8 +1369,0 @@\n-    m->Recycle();\n-    if (AsyncDeflateIdleMonitors) {\n-      \/\/ DEFLATER_MARKER is the only non-NULL value we should see here.\n-      m->try_set_owner_from(DEFLATER_MARKER, NULL);\n-    }\n-    m->set_object(object);\n-    m->_Responsible  = NULL;\n-    m->_SpinDuration = ObjectMonitor::Knob_SpinLimit;       \/\/ consider: keep metastats by type\/class\n@@ -2012,5 +1372,1 @@\n-      m->set_header(markWord::zero());\n-      m->set_object(NULL);\n-      m->Recycle();\n-      \/\/ om_release() will reset the allocation state from New to Free.\n-      om_release(self, m, true);\n+      delete m;\n@@ -2026,4 +1382,1 @@\n-    assert(m->is_new(), \"freshly allocated monitor must be new\");\n-    \/\/ Release semantics are not needed to keep allocation_state from\n-    \/\/ floating up since cas_set_mark() takes care of it.\n-    m->set_allocation_state(ObjectMonitor::Old);\n+    _in_use_list.add(m);\n@@ -2035,1 +1388,1 @@\n-      ResourceMark rm(self);\n+      ResourceMark rm(current);\n@@ -2047,38 +1400,4 @@\n-\n-\/\/ We maintain a list of in-use monitors for each thread.\n-\/\/\n-\/\/ For safepoint based deflation:\n-\/\/ deflate_thread_local_monitors() scans a single thread's in-use list, while\n-\/\/ deflate_idle_monitors() scans only a global list of in-use monitors which\n-\/\/ is populated only as a thread dies (see om_flush()).\n-\/\/\n-\/\/ These operations are called at all safepoints, immediately after mutators\n-\/\/ are stopped, but before any objects have moved. Collectively they traverse\n-\/\/ the population of in-use monitors, deflating where possible. The scavenged\n-\/\/ monitors are returned to the global monitor free list.\n-\/\/\n-\/\/ Beware that we scavenge at *every* stop-the-world point. Having a large\n-\/\/ number of monitors in-use could negatively impact performance. We also want\n-\/\/ to minimize the total # of monitors in circulation, as they incur a small\n-\/\/ footprint penalty.\n-\/\/\n-\/\/ Perversely, the heap size -- and thus the STW safepoint rate --\n-\/\/ typically drives the scavenge rate.  Large heaps can mean infrequent GC,\n-\/\/ which in turn can mean large(r) numbers of ObjectMonitors in circulation.\n-\/\/ This is an unfortunate aspect of this design.\n-\/\/\n-\/\/ For async deflation:\n-\/\/ If a special deflation request is made, then the safepoint based\n-\/\/ deflation mechanism is used. Otherwise, an async deflation request\n-\/\/ is registered with the ServiceThread and it is notified.\n-\n-void ObjectSynchronizer::do_safepoint_work(DeflateMonitorCounters* counters) {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"must be at safepoint\");\n-\n-  \/\/ The per-thread in-use lists are handled in\n-  \/\/ ParallelSPCleanupThreadClosure::do_thread().\n-\n-  if (!AsyncDeflateIdleMonitors || is_special_deflation_requested()) {\n-    \/\/ Use the older mechanism for the global in-use list or if a\n-    \/\/ special deflation has been requested before the safepoint.\n-    ObjectSynchronizer::deflate_idle_monitors(counters);\n+void ObjectSynchronizer::chk_for_block_req(JavaThread* current, const char* op_name,\n+                                           const char* cnt_name, size_t cnt,\n+                                           LogStream* ls, elapsedTimer* timer_p) {\n+  if (!SafepointMechanism::should_process(current)) {\n@@ -2088,136 +1407,7 @@\n-  log_debug(monitorinflation)(\"requesting async deflation of idle monitors.\");\n-  \/\/ Request deflation of idle monitors by the ServiceThread:\n-  set_is_async_deflation_requested(true);\n-  MonitorLocker ml(Service_lock, Mutex::_no_safepoint_check_flag);\n-  ml.notify_all();\n-\n-  if (log_is_enabled(Debug, monitorinflation)) {\n-    \/\/ exit_globals()'s call to audit_and_print_stats() is done\n-    \/\/ at the Info level and not at a safepoint.\n-    \/\/ For safepoint based deflation, audit_and_print_stats() is called\n-    \/\/ in ObjectSynchronizer::finish_deflate_idle_monitors() at the\n-    \/\/ Debug level at a safepoint.\n-    ObjectSynchronizer::audit_and_print_stats(false \/* on_exit *\/);\n-  }\n-}\n-\n-\/\/ Deflate a single monitor if not in-use\n-\/\/ Return true if deflated, false if in-use\n-bool ObjectSynchronizer::deflate_monitor(ObjectMonitor* mid, oop obj,\n-                                         ObjectMonitor** free_head_p,\n-                                         ObjectMonitor** free_tail_p) {\n-  bool deflated;\n-  \/\/ Normal case ... The monitor is associated with obj.\n-  const markWord mark = obj->mark();\n-  guarantee(mark == markWord::encode(mid), \"should match: mark=\"\n-            INTPTR_FORMAT \", encoded mid=\" INTPTR_FORMAT, mark.value(),\n-            markWord::encode(mid).value());\n-  \/\/ Make sure that mark.monitor() and markWord::encode() agree:\n-  guarantee(mark.monitor() == mid, \"should match: monitor()=\" INTPTR_FORMAT\n-            \", mid=\" INTPTR_FORMAT, p2i(mark.monitor()), p2i(mid));\n-  const markWord dmw = mid->header();\n-  guarantee(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n-\n-  if (mid->is_busy()) {\n-    \/\/ Easy checks are first - the ObjectMonitor is busy so no deflation.\n-    deflated = false;\n-  } else {\n-    \/\/ Deflate the monitor if it is no longer being used\n-    \/\/ It's idle - scavenge and return to the global free list\n-    \/\/ plain old deflation ...\n-    if (log_is_enabled(Trace, monitorinflation)) {\n-      ResourceMark rm;\n-      log_trace(monitorinflation)(\"deflate_monitor: \"\n-                                  \"object=\" INTPTR_FORMAT \", mark=\"\n-                                  INTPTR_FORMAT \", type='%s'\", p2i(obj),\n-                                  mark.value(), obj->klass()->external_name());\n-    }\n-\n-    \/\/ Restore the header back to obj\n-    \/\/ XXX - I have no rationale for this \"release\", but it's been here forever.\n-    obj->release_set_mark(dmw);\n-    if (AsyncDeflateIdleMonitors) {\n-      \/\/ clear() expects the owner field to be NULL.\n-      \/\/ DEFLATER_MARKER is the only non-NULL value we should see here.\n-      mid->try_set_owner_from(DEFLATER_MARKER, NULL);\n-    }\n-    mid->clear();\n-\n-    assert(mid->object() == NULL, \"invariant: object=\" INTPTR_FORMAT,\n-           p2i(mid->object()));\n-    assert(mid->is_free(), \"invariant\");\n-\n-    \/\/ Move the deflated ObjectMonitor to the working free list\n-    \/\/ defined by free_head_p and free_tail_p.\n-    if (*free_head_p == NULL) *free_head_p = mid;\n-    if (*free_tail_p != NULL) {\n-      \/\/ We append to the list so the caller can use mid->_next_om\n-      \/\/ to fix the linkages in its context.\n-      ObjectMonitor* prevtail = *free_tail_p;\n-      \/\/ Should have been cleaned up by the caller:\n-      \/\/ Note: Should not have to lock prevtail here since we're at a\n-      \/\/ safepoint and ObjectMonitors on the local free list should\n-      \/\/ not be accessed in parallel.\n-#ifdef ASSERT\n-      ObjectMonitor* l_next_om = prevtail->next_om();\n-#endif\n-      assert(l_next_om == NULL, \"must be NULL: _next_om=\" INTPTR_FORMAT, p2i(l_next_om));\n-      prevtail->set_next_om(mid);\n-    }\n-    *free_tail_p = mid;\n-    \/\/ At this point, mid->_next_om still refers to its current\n-    \/\/ value and another ObjectMonitor's _next_om field still\n-    \/\/ refers to this ObjectMonitor. Those linkages have to be\n-    \/\/ cleaned up by the caller who has the complete context.\n-    deflated = true;\n-  }\n-  return deflated;\n-}\n-\n-\/\/ Deflate the specified ObjectMonitor if not in-use using a JavaThread.\n-\/\/ Returns true if it was deflated and false otherwise.\n-\/\/\n-\/\/ The async deflation protocol sets owner to DEFLATER_MARKER and\n-\/\/ makes contentions negative as signals to contending threads that\n-\/\/ an async deflation is in progress. There are a number of checks\n-\/\/ as part of the protocol to make sure that the calling thread has\n-\/\/ not lost the race to a contending thread.\n-\/\/\n-\/\/ The ObjectMonitor has been successfully async deflated when:\n-\/\/   (contentions < 0)\n-\/\/ Contending threads that see that condition know to retry their operation.\n-\/\/\n-bool ObjectSynchronizer::deflate_monitor_using_JT(ObjectMonitor* mid,\n-                                                  ObjectMonitor** free_head_p,\n-                                                  ObjectMonitor** free_tail_p) {\n-  assert(AsyncDeflateIdleMonitors, \"sanity check\");\n-  assert(Thread::current()->is_Java_thread(), \"precondition\");\n-  \/\/ A newly allocated ObjectMonitor should not be seen here so we\n-  \/\/ avoid an endless inflate\/deflate cycle.\n-  assert(mid->is_old(), \"must be old: allocation_state=%d\",\n-         (int) mid->allocation_state());\n-\n-  if (mid->is_busy()) {\n-    \/\/ Easy checks are first - the ObjectMonitor is busy so no deflation.\n-    return false;\n-  }\n-\n-  \/\/ Set a NULL owner to DEFLATER_MARKER to force any contending thread\n-  \/\/ through the slow path. This is just the first part of the async\n-  \/\/ deflation dance.\n-  if (mid->try_set_owner_from(NULL, DEFLATER_MARKER) != NULL) {\n-    \/\/ The owner field is no longer NULL so we lost the race since the\n-    \/\/ ObjectMonitor is now busy.\n-    return false;\n-  }\n-\n-  if (mid->contentions() > 0 || mid->_waiters != 0) {\n-    \/\/ Another thread has raced to enter the ObjectMonitor after\n-    \/\/ mid->is_busy() above or has already entered and waited on\n-    \/\/ it which makes it busy so no deflation. Restore owner to\n-    \/\/ NULL if it is still DEFLATER_MARKER.\n-    if (mid->try_set_owner_from(DEFLATER_MARKER, NULL) != DEFLATER_MARKER) {\n-      \/\/ Deferred decrement for the JT EnterI() that cancelled the async deflation.\n-      mid->add_to_contentions(-1);\n-    }\n-    return false;\n+  \/\/ A safepoint\/handshake has started.\n+  if (ls != NULL) {\n+    timer_p->stop();\n+    ls->print_cr(\"pausing %s: %s=\" SIZE_FORMAT \", in_use_list stats: ceiling=\"\n+                 SIZE_FORMAT \", count=\" SIZE_FORMAT \", max=\" SIZE_FORMAT,\n+                 op_name, cnt_name, cnt, in_use_list_ceiling(),\n+                 _in_use_list.count(), _in_use_list.max());\n@@ -2226,11 +1416,3 @@\n-  \/\/ Make a zero contentions field negative to force any contending threads\n-  \/\/ to retry. This is the second part of the async deflation dance.\n-  if (Atomic::cmpxchg(&mid->_contentions, (jint)0, -max_jint) != 0) {\n-    \/\/ Contentions was no longer 0 so we lost the race since the\n-    \/\/ ObjectMonitor is now busy. Restore owner to NULL if it is\n-    \/\/ still DEFLATER_MARKER:\n-    if (mid->try_set_owner_from(DEFLATER_MARKER, NULL) != DEFLATER_MARKER) {\n-      \/\/ Deferred decrement for the JT EnterI() that cancelled the async deflation.\n-      mid->add_to_contentions(-1);\n-    }\n-    return false;\n+  {\n+    \/\/ Honor block request.\n+    ThreadBlockInVM tbivm(current);\n@@ -2239,107 +1421,5 @@\n-  \/\/ Sanity checks for the races:\n-  guarantee(mid->owner_is_DEFLATER_MARKER(), \"must be deflater marker\");\n-  guarantee(mid->contentions() < 0, \"must be negative: contentions=%d\",\n-            mid->contentions());\n-  guarantee(mid->_waiters == 0, \"must be 0: waiters=%d\", mid->_waiters);\n-  guarantee(mid->_cxq == NULL, \"must be no contending threads: cxq=\"\n-            INTPTR_FORMAT, p2i(mid->_cxq));\n-  guarantee(mid->_EntryList == NULL,\n-            \"must be no entering threads: EntryList=\" INTPTR_FORMAT,\n-            p2i(mid->_EntryList));\n-\n-  const oop obj = (oop) mid->object();\n-  if (log_is_enabled(Trace, monitorinflation)) {\n-    ResourceMark rm;\n-    log_trace(monitorinflation)(\"deflate_monitor_using_JT: \"\n-                                \"object=\" INTPTR_FORMAT \", mark=\"\n-                                INTPTR_FORMAT \", type='%s'\",\n-                                p2i(obj), obj->mark().value(),\n-                                obj->klass()->external_name());\n-  }\n-\n-  \/\/ Install the old mark word if nobody else has already done it.\n-  mid->install_displaced_markword_in_object(obj);\n-  mid->clear_common();\n-\n-  assert(mid->object() == NULL, \"must be NULL: object=\" INTPTR_FORMAT,\n-         p2i(mid->object()));\n-  assert(mid->is_free(), \"must be free: allocation_state=%d\",\n-         (int)mid->allocation_state());\n-\n-  \/\/ Move the deflated ObjectMonitor to the working free list\n-  \/\/ defined by free_head_p and free_tail_p.\n-  if (*free_head_p == NULL) {\n-    \/\/ First one on the list.\n-    *free_head_p = mid;\n-  }\n-  if (*free_tail_p != NULL) {\n-    \/\/ We append to the list so the caller can use mid->_next_om\n-    \/\/ to fix the linkages in its context.\n-    ObjectMonitor* prevtail = *free_tail_p;\n-    \/\/ prevtail should have been cleaned up by the caller:\n-#ifdef ASSERT\n-    ObjectMonitor* l_next_om = unmarked_next(prevtail);\n-#endif\n-    assert(l_next_om == NULL, \"must be NULL: _next_om=\" INTPTR_FORMAT, p2i(l_next_om));\n-    om_lock(prevtail);\n-    prevtail->set_next_om(mid);  \/\/ prevtail now points to mid (and is unlocked)\n-  }\n-  *free_tail_p = mid;\n-\n-  \/\/ At this point, mid->_next_om still refers to its current\n-  \/\/ value and another ObjectMonitor's _next_om field still\n-  \/\/ refers to this ObjectMonitor. Those linkages have to be\n-  \/\/ cleaned up by the caller who has the complete context.\n-\n-  \/\/ We leave owner == DEFLATER_MARKER and contentions < 0\n-  \/\/ to force any racing threads to retry.\n-  return true;  \/\/ Success, ObjectMonitor has been deflated.\n-}\n-\n-\/\/ Walk a given monitor list, and deflate idle monitors.\n-\/\/ The given list could be a per-thread list or a global list.\n-\/\/\n-\/\/ In the case of parallel processing of thread local monitor lists,\n-\/\/ work is done by Threads::parallel_threads_do() which ensures that\n-\/\/ each Java thread is processed by exactly one worker thread, and\n-\/\/ thus avoid conflicts that would arise when worker threads would\n-\/\/ process the same monitor lists concurrently.\n-\/\/\n-\/\/ See also ParallelSPCleanupTask and\n-\/\/ SafepointSynchronize::do_cleanup_tasks() in safepoint.cpp and\n-\/\/ Threads::parallel_java_threads_do() in thread.cpp.\n-int ObjectSynchronizer::deflate_monitor_list(ObjectMonitor** list_p,\n-                                             int* count_p,\n-                                             ObjectMonitor** free_head_p,\n-                                             ObjectMonitor** free_tail_p) {\n-  ObjectMonitor* cur_mid_in_use = NULL;\n-  ObjectMonitor* mid = NULL;\n-  ObjectMonitor* next = NULL;\n-  int deflated_count = 0;\n-\n-  \/\/ This list walk executes at a safepoint and does not race with any\n-  \/\/ other list walkers.\n-\n-  for (mid = Atomic::load(list_p); mid != NULL; mid = next) {\n-    next = unmarked_next(mid);\n-    oop obj = (oop) mid->object();\n-    if (obj != NULL && deflate_monitor(mid, obj, free_head_p, free_tail_p)) {\n-      \/\/ Deflation succeeded and already updated free_head_p and\n-      \/\/ free_tail_p as needed. Finish the move to the local free list\n-      \/\/ by unlinking mid from the global or per-thread in-use list.\n-      if (cur_mid_in_use == NULL) {\n-        \/\/ mid is the list head so switch the list head to next:\n-        Atomic::store(list_p, next);\n-      } else {\n-        \/\/ Switch cur_mid_in_use's next field to next:\n-        cur_mid_in_use->set_next_om(next);\n-      }\n-      \/\/ At this point mid is disconnected from the in-use list.\n-      deflated_count++;\n-      Atomic::dec(count_p);\n-      \/\/ mid is current tail in the free_head_p list so NULL terminate it.\n-      \/\/ No release semantics needed since Atomic::dec() already provides it.\n-      mid->set_next_om(NULL);\n-    } else {\n-      cur_mid_in_use = mid;\n-    }\n+  if (ls != NULL) {\n+    ls->print_cr(\"resuming %s: in_use_list stats: ceiling=\" SIZE_FORMAT\n+                 \", count=\" SIZE_FORMAT \", max=\" SIZE_FORMAT, op_name,\n+                 in_use_list_ceiling(), _in_use_list.count(), _in_use_list.max());\n+    timer_p->start();\n@@ -2347,1 +1427,0 @@\n-  return deflated_count;\n@@ -2350,20 +1429,6 @@\n-\/\/ Walk a given ObjectMonitor list and deflate idle ObjectMonitors using\n-\/\/ a JavaThread. Returns the number of deflated ObjectMonitors. The given\n-\/\/ list could be a per-thread in-use list or the global in-use list.\n-\/\/ If a safepoint has started, then we save state via saved_mid_in_use_p\n-\/\/ and return to the caller to honor the safepoint.\n-\/\/\n-int ObjectSynchronizer::deflate_monitor_list_using_JT(ObjectMonitor** list_p,\n-                                                      int* count_p,\n-                                                      ObjectMonitor** free_head_p,\n-                                                      ObjectMonitor** free_tail_p,\n-                                                      ObjectMonitor** saved_mid_in_use_p) {\n-  assert(AsyncDeflateIdleMonitors, \"sanity check\");\n-  JavaThread* self = JavaThread::current();\n-\n-  ObjectMonitor* cur_mid_in_use = NULL;\n-  ObjectMonitor* mid = NULL;\n-  ObjectMonitor* next = NULL;\n-  ObjectMonitor* next_next = NULL;\n-  int deflated_count = 0;\n-  NoSafepointVerifier nsv;\n+\/\/ Walk the in-use list and deflate (at most MonitorDeflationMax) idle\n+\/\/ ObjectMonitors. Returns the number of deflated ObjectMonitors.\n+size_t ObjectSynchronizer::deflate_monitor_list(Thread* current, LogStream* ls,\n+                                                elapsedTimer* timer_p) {\n+  MonitorList::Iterator iter = _in_use_list.iterator();\n+  size_t deflated_count = 0;\n@@ -2371,39 +1436,3 @@\n-  \/\/ We use the more complicated lock-cur_mid_in_use-and-mid-as-we-go\n-  \/\/ protocol because om_release() can do list deletions in parallel;\n-  \/\/ this also prevents races with a list walker thread. We also\n-  \/\/ lock-next-next-as-we-go to prevent an om_flush() that is behind\n-  \/\/ this thread from passing us.\n-  if (*saved_mid_in_use_p == NULL) {\n-    \/\/ No saved state so start at the beginning.\n-    \/\/ Lock the list head so we can possibly deflate it:\n-    if ((mid = get_list_head_locked(list_p)) == NULL) {\n-      return 0;  \/\/ The list is empty so nothing to deflate.\n-    }\n-    next = unmarked_next(mid);\n-  } else {\n-    \/\/ We're restarting after a safepoint so restore the necessary state\n-    \/\/ before we resume.\n-    cur_mid_in_use = *saved_mid_in_use_p;\n-    \/\/ Lock cur_mid_in_use so we can possibly update its\n-    \/\/ next field to extract a deflated ObjectMonitor.\n-    om_lock(cur_mid_in_use);\n-    mid = unmarked_next(cur_mid_in_use);\n-    if (mid == NULL) {\n-      om_unlock(cur_mid_in_use);\n-      *saved_mid_in_use_p = NULL;\n-      return 0;  \/\/ The remainder is empty so nothing more to deflate.\n-    }\n-    \/\/ Lock mid so we can possibly deflate it:\n-    om_lock(mid);\n-    next = unmarked_next(mid);\n-  }\n-\n-  while (true) {\n-    \/\/ The current mid is locked at this point. If we have a\n-    \/\/ cur_mid_in_use, then it is also locked at this point.\n-\n-    if (next != NULL) {\n-      \/\/ We lock next so that an om_flush() thread that is behind us\n-      \/\/ cannot pass us when we unlock the current mid.\n-      om_lock(next);\n-      next_next = unmarked_next(next);\n+  while (iter.has_next()) {\n+    if (deflated_count >= (size_t)MonitorDeflationMax) {\n+      break;\n@@ -2411,24 +1440,2 @@\n-\n-    \/\/ Only try to deflate if there is an associated Java object and if\n-    \/\/ mid is old (is not newly allocated and is not newly freed).\n-    if (mid->object() != NULL && mid->is_old() &&\n-        deflate_monitor_using_JT(mid, free_head_p, free_tail_p)) {\n-      \/\/ Deflation succeeded and already updated free_head_p and\n-      \/\/ free_tail_p as needed. Finish the move to the local free list\n-      \/\/ by unlinking mid from the global or per-thread in-use list.\n-      if (cur_mid_in_use == NULL) {\n-        \/\/ mid is the list head and it is locked. Switch the list head\n-        \/\/ to next which is also locked (if not NULL) and also leave\n-        \/\/ mid locked. Release semantics needed since not all code paths\n-        \/\/ in deflate_monitor_using_JT() ensure memory consistency.\n-        Atomic::release_store(list_p, next);\n-      } else {\n-        ObjectMonitor* locked_next = mark_om_ptr(next);\n-        \/\/ mid and cur_mid_in_use are locked. Switch cur_mid_in_use's\n-        \/\/ next field to locked_next and also leave mid locked.\n-        \/\/ Release semantics needed since not all code paths in\n-        \/\/ deflate_monitor_using_JT() ensure memory consistency.\n-        cur_mid_in_use->release_set_next_om(locked_next);\n-      }\n-      \/\/ At this point mid is disconnected from the in-use list so\n-      \/\/ its lock longer has any effects on in-use list.\n+    ObjectMonitor* mid = iter.next();\n+    if (mid->deflate_monitor()) {\n@@ -2436,51 +1443,0 @@\n-      Atomic::dec(count_p);\n-      \/\/ mid is current tail in the free_head_p list so NULL terminate\n-      \/\/ it (which also unlocks it). No release semantics needed since\n-      \/\/ Atomic::dec() already provides it.\n-      mid->set_next_om(NULL);\n-\n-      \/\/ All the list management is done so move on to the next one:\n-      mid = next;  \/\/ mid keeps non-NULL next's locked state\n-      next = next_next;\n-    } else {\n-      \/\/ mid is considered in-use if it does not have an associated\n-      \/\/ Java object or mid is not old or deflation did not succeed.\n-      \/\/ A mid->is_new() node can be seen here when it is freshly\n-      \/\/ returned by om_alloc() (and skips the deflation code path).\n-      \/\/ A mid->is_old() node can be seen here when deflation failed.\n-      \/\/ A mid->is_free() node can be seen here when a fresh node from\n-      \/\/ om_alloc() is released by om_release() due to losing the race\n-      \/\/ in inflate().\n-\n-      \/\/ All the list management is done so move on to the next one:\n-      if (cur_mid_in_use != NULL) {\n-        om_unlock(cur_mid_in_use);\n-      }\n-      \/\/ The next cur_mid_in_use keeps mid's lock state so\n-      \/\/ that it is stable for a possible next field change. It\n-      \/\/ cannot be modified by om_release() while it is locked.\n-      cur_mid_in_use = mid;\n-      mid = next;  \/\/ mid keeps non-NULL next's locked state\n-      next = next_next;\n-\n-      if (SafepointMechanism::should_block(self) &&\n-          \/\/ Acquire semantics are not needed on this list load since\n-          \/\/ it is not dependent on the following load which does have\n-          \/\/ acquire semantics.\n-          cur_mid_in_use != Atomic::load(list_p) && cur_mid_in_use->is_old()) {\n-        \/\/ If a safepoint has started and cur_mid_in_use is not the list\n-        \/\/ head and is old, then it is safe to use as saved state. Return\n-        \/\/ to the caller before blocking.\n-        *saved_mid_in_use_p = cur_mid_in_use;\n-        om_unlock(cur_mid_in_use);\n-        if (mid != NULL) {\n-          om_unlock(mid);\n-        }\n-        return deflated_count;\n-      }\n-    }\n-    if (mid == NULL) {\n-      if (cur_mid_in_use != NULL) {\n-        om_unlock(cur_mid_in_use);\n-      }\n-      break;  \/\/ Reached end of the list so nothing more to deflate.\n@@ -2489,25 +1445,4 @@\n-    \/\/ The current mid's next field is locked at this point. If we have\n-    \/\/ a cur_mid_in_use, then it is also locked at this point.\n-  }\n-  \/\/ We finished the list without a safepoint starting so there's\n-  \/\/ no need to save state.\n-  *saved_mid_in_use_p = NULL;\n-  return deflated_count;\n-}\n-\n-void ObjectSynchronizer::prepare_deflate_idle_monitors(DeflateMonitorCounters* counters) {\n-  counters->n_in_use = 0;              \/\/ currently associated with objects\n-  counters->n_in_circulation = 0;      \/\/ extant\n-  counters->n_scavenged = 0;           \/\/ reclaimed (global and per-thread)\n-  counters->per_thread_scavenged = 0;  \/\/ per-thread scavenge total\n-  counters->per_thread_times = 0.0;    \/\/ per-thread scavenge times\n-}\n-\n-void ObjectSynchronizer::deflate_idle_monitors(DeflateMonitorCounters* counters) {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"must be at safepoint\");\n-\n-  if (AsyncDeflateIdleMonitors) {\n-    \/\/ Nothing to do when global idle ObjectMonitors are deflated using\n-    \/\/ a JavaThread unless a special deflation has been requested.\n-    if (!is_special_deflation_requested()) {\n-      return;\n+    if (current->is_Java_thread()) {\n+      \/\/ A JavaThread must check for a safepoint\/handshake and honor it.\n+      chk_for_block_req(current->as_Java_thread(), \"deflation\", \"deflated_count\",\n+                        deflated_count, ls, timer_p);\n@@ -2517,51 +1452,1 @@\n-  bool deflated = false;\n-\n-  ObjectMonitor* free_head_p = NULL;  \/\/ Local SLL of scavenged monitors\n-  ObjectMonitor* free_tail_p = NULL;\n-  elapsedTimer timer;\n-\n-  if (log_is_enabled(Info, monitorinflation)) {\n-    timer.start();\n-  }\n-\n-  \/\/ Note: the thread-local monitors lists get deflated in\n-  \/\/ a separate pass. See deflate_thread_local_monitors().\n-\n-  \/\/ For moribund threads, scan om_list_globals._in_use_list\n-  int deflated_count = 0;\n-  \/\/ Acquire semantics not needed since we are at a safepoint.\n-  if (Atomic::load(&om_list_globals._in_use_list) != NULL) {\n-    \/\/ Update n_in_circulation before om_list_globals._in_use_count is\n-    \/\/ updated by deflation.\n-    Atomic::add(&counters->n_in_circulation,\n-                Atomic::load(&om_list_globals._in_use_count));\n-\n-    deflated_count = deflate_monitor_list(&om_list_globals._in_use_list,\n-                                          &om_list_globals._in_use_count,\n-                                          &free_head_p, &free_tail_p);\n-    Atomic::add(&counters->n_in_use, Atomic::load(&om_list_globals._in_use_count));\n-  }\n-\n-  if (free_head_p != NULL) {\n-    \/\/ Move the deflated ObjectMonitors back to the global free list.\n-    guarantee(free_tail_p != NULL && deflated_count > 0, \"invariant\");\n-#ifdef ASSERT\n-    ObjectMonitor* l_next_om = free_tail_p->next_om();\n-#endif\n-    assert(l_next_om == NULL, \"must be NULL: _next_om=\" INTPTR_FORMAT, p2i(l_next_om));\n-    prepend_list_to_global_free_list(free_head_p, free_tail_p, deflated_count);\n-    Atomic::add(&counters->n_scavenged, deflated_count);\n-  }\n-  timer.stop();\n-\n-  LogStreamHandle(Debug, monitorinflation) lsh_debug;\n-  LogStreamHandle(Info, monitorinflation) lsh_info;\n-  LogStream* ls = NULL;\n-  if (log_is_enabled(Debug, monitorinflation)) {\n-    ls = &lsh_debug;\n-  } else if (deflated_count != 0 && log_is_enabled(Info, monitorinflation)) {\n-    ls = &lsh_info;\n-  }\n-  if (ls != NULL) {\n-    ls->print_cr(\"deflating global idle monitors, %3.7f secs, %d monitors\", timer.seconds(), deflated_count);\n-  }\n+  return deflated_count;\n@@ -2580,101 +1465,9 @@\n-void ObjectSynchronizer::deflate_idle_monitors_using_JT() {\n-  assert(AsyncDeflateIdleMonitors, \"sanity check\");\n-\n-  \/\/ Deflate any global idle monitors.\n-  deflate_global_idle_monitors_using_JT();\n-\n-  int count = 0;\n-  for (JavaThreadIteratorWithHandle jtiwh; JavaThread *jt = jtiwh.next(); ) {\n-    if (Atomic::load(&jt->om_in_use_count) > 0 && !jt->is_exiting()) {\n-      \/\/ This JavaThread is using ObjectMonitors so deflate any that\n-      \/\/ are idle unless this JavaThread is exiting; do not race with\n-      \/\/ ObjectSynchronizer::om_flush().\n-      deflate_per_thread_idle_monitors_using_JT(jt);\n-      count++;\n-    }\n-  }\n-  if (count > 0) {\n-    log_debug(monitorinflation)(\"did async deflation of idle monitors for %d thread(s).\", count);\n-  }\n-\n-  log_info(monitorinflation)(\"async global_population=%d, global_in_use_count=%d, \"\n-                             \"global_free_count=%d, global_wait_count=%d\",\n-                             Atomic::load(&om_list_globals._population),\n-                             Atomic::load(&om_list_globals._in_use_count),\n-                             Atomic::load(&om_list_globals._free_count),\n-                             Atomic::load(&om_list_globals._wait_count));\n-\n-  \/\/ The ServiceThread's async deflation request has been processed.\n-  set_is_async_deflation_requested(false);\n-\n-  if (Atomic::load(&om_list_globals._wait_count) > 0) {\n-    \/\/ There are deflated ObjectMonitors waiting for a handshake\n-    \/\/ (or a safepoint) for safety.\n-\n-    ObjectMonitor* list = Atomic::load(&om_list_globals._wait_list);\n-    ADIM_guarantee(list != NULL, \"om_list_globals._wait_list must not be NULL\");\n-    int count = Atomic::load(&om_list_globals._wait_count);\n-    Atomic::store(&om_list_globals._wait_count, 0);\n-    OrderAccess::storestore();  \/\/ Make sure counter update is seen first.\n-    Atomic::store(&om_list_globals._wait_list, (ObjectMonitor*)NULL);\n-\n-    \/\/ Find the tail for prepend_list_to_common(). No need to mark\n-    \/\/ ObjectMonitors for this list walk since only the deflater\n-    \/\/ thread manages the wait list.\n-    int l_count = 0;\n-    ObjectMonitor* tail = NULL;\n-    for (ObjectMonitor* n = list; n != NULL; n = unmarked_next(n)) {\n-      tail = n;\n-      l_count++;\n-    }\n-    ADIM_guarantee(count == l_count, \"count=%d != l_count=%d\", count, l_count);\n-\n-    \/\/ Will execute a safepoint if !ThreadLocalHandshakes:\n-    HandshakeForDeflation hfd_hc;\n-    Handshake::execute(&hfd_hc);\n-\n-    prepend_list_to_common(list, tail, count, &om_list_globals._free_list,\n-                           &om_list_globals._free_count);\n-\n-    log_info(monitorinflation)(\"moved %d idle monitors from global waiting list to global free list\", count);\n-  }\n-}\n-\n-\/\/ Deflate global idle ObjectMonitors using a JavaThread.\n-\/\/\n-void ObjectSynchronizer::deflate_global_idle_monitors_using_JT() {\n-  assert(AsyncDeflateIdleMonitors, \"sanity check\");\n-  assert(Thread::current()->is_Java_thread(), \"precondition\");\n-  JavaThread* self = JavaThread::current();\n-\n-  deflate_common_idle_monitors_using_JT(true \/* is_global *\/, self);\n-}\n-\n-\/\/ Deflate the specified JavaThread's idle ObjectMonitors using a JavaThread.\n-\/\/\n-void ObjectSynchronizer::deflate_per_thread_idle_monitors_using_JT(JavaThread* target) {\n-  assert(AsyncDeflateIdleMonitors, \"sanity check\");\n-  assert(Thread::current()->is_Java_thread(), \"precondition\");\n-\n-  deflate_common_idle_monitors_using_JT(false \/* !is_global *\/, target);\n-}\n-\n-\/\/ Deflate global or per-thread idle ObjectMonitors using a JavaThread.\n-\/\/\n-void ObjectSynchronizer::deflate_common_idle_monitors_using_JT(bool is_global, JavaThread* target) {\n-  JavaThread* self = JavaThread::current();\n-\n-  int deflated_count = 0;\n-  ObjectMonitor* free_head_p = NULL;  \/\/ Local SLL of scavenged ObjectMonitors\n-  ObjectMonitor* free_tail_p = NULL;\n-  ObjectMonitor* saved_mid_in_use_p = NULL;\n-  elapsedTimer timer;\n-\n-  if (log_is_enabled(Info, monitorinflation)) {\n-    timer.start();\n-  }\n-\n-  if (is_global) {\n-    OM_PERFDATA_OP(MonExtant, set_value(Atomic::load(&om_list_globals._in_use_count)));\n-  } else {\n-    OM_PERFDATA_OP(MonExtant, inc(Atomic::load(&target->om_in_use_count)));\n+\/\/ This function is called by the MonitorDeflationThread to deflate\n+\/\/ ObjectMonitors. It is also called via do_final_audit_and_print_stats()\n+\/\/ by the VMThread.\n+size_t ObjectSynchronizer::deflate_idle_monitors() {\n+  Thread* current = Thread::current();\n+  if (current->is_Java_thread()) {\n+    \/\/ The async deflation request has been processed.\n+    _last_async_deflation_time_ns = os::javaTimeNanos();\n+    set_is_async_deflation_requested(false);\n@@ -2683,69 +1476,0 @@\n-  do {\n-    if (saved_mid_in_use_p != NULL) {\n-      \/\/ We looped around because deflate_monitor_list_using_JT()\n-      \/\/ detected a pending safepoint. Honoring the safepoint is good,\n-      \/\/ but as long as is_special_deflation_requested() is supported,\n-      \/\/ we can't safely restart using saved_mid_in_use_p. That saved\n-      \/\/ ObjectMonitor could have been deflated by safepoint based\n-      \/\/ deflation and would no longer be on the in-use list where we\n-      \/\/ originally found it.\n-      saved_mid_in_use_p = NULL;\n-    }\n-    int local_deflated_count;\n-    if (is_global) {\n-      local_deflated_count =\n-          deflate_monitor_list_using_JT(&om_list_globals._in_use_list,\n-                                        &om_list_globals._in_use_count,\n-                                        &free_head_p, &free_tail_p,\n-                                        &saved_mid_in_use_p);\n-    } else {\n-      local_deflated_count =\n-          deflate_monitor_list_using_JT(&target->om_in_use_list,\n-                                        &target->om_in_use_count, &free_head_p,\n-                                        &free_tail_p, &saved_mid_in_use_p);\n-    }\n-    deflated_count += local_deflated_count;\n-\n-    if (free_head_p != NULL) {\n-      \/\/ Move the deflated ObjectMonitors to the global free list.\n-      guarantee(free_tail_p != NULL && local_deflated_count > 0, \"free_tail_p=\" INTPTR_FORMAT \", local_deflated_count=%d\", p2i(free_tail_p), local_deflated_count);\n-      \/\/ Note: The target thread can be doing an om_alloc() that\n-      \/\/ is trying to prepend an ObjectMonitor on its in-use list\n-      \/\/ at the same time that we have deflated the current in-use\n-      \/\/ list head and put it on the local free list. prepend_to_common()\n-      \/\/ will detect the race and retry which avoids list corruption,\n-      \/\/ but the next field in free_tail_p can flicker to marked\n-      \/\/ and then unmarked while prepend_to_common() is sorting it\n-      \/\/ all out.\n-#ifdef ASSERT\n-      ObjectMonitor* l_next_om = unmarked_next(free_tail_p);\n-#endif\n-      assert(l_next_om == NULL, \"must be NULL: _next_om=\" INTPTR_FORMAT, p2i(l_next_om));\n-\n-      prepend_list_to_global_wait_list(free_head_p, free_tail_p, local_deflated_count);\n-\n-      OM_PERFDATA_OP(Deflations, inc(local_deflated_count));\n-    }\n-\n-    if (saved_mid_in_use_p != NULL) {\n-      \/\/ deflate_monitor_list_using_JT() detected a safepoint starting.\n-      timer.stop();\n-      {\n-        if (is_global) {\n-          log_debug(monitorinflation)(\"pausing deflation of global idle monitors for a safepoint.\");\n-        } else {\n-          log_debug(monitorinflation)(\"jt=\" INTPTR_FORMAT \": pausing deflation of per-thread idle monitors for a safepoint.\", p2i(target));\n-        }\n-        assert(SafepointMechanism::should_block(self), \"sanity check\");\n-        ThreadBlockInVM blocker(self);\n-      }\n-      \/\/ Prepare for another loop after the safepoint.\n-      free_head_p = NULL;\n-      free_tail_p = NULL;\n-      if (log_is_enabled(Info, monitorinflation)) {\n-        timer.start();\n-      }\n-    }\n-  } while (saved_mid_in_use_p != NULL);\n-  timer.stop();\n-\n@@ -2757,1 +1481,1 @@\n-  } else if (deflated_count != 0 && log_is_enabled(Info, monitorinflation)) {\n+  } else if (log_is_enabled(Info, monitorinflation)) {\n@@ -2760,20 +1484,5 @@\n-  if (ls != NULL) {\n-    if (is_global) {\n-      ls->print_cr(\"async-deflating global idle monitors, %3.7f secs, %d monitors\", timer.seconds(), deflated_count);\n-    } else {\n-      ls->print_cr(\"jt=\" INTPTR_FORMAT \": async-deflating per-thread idle monitors, %3.7f secs, %d monitors\", p2i(target), timer.seconds(), deflated_count);\n-    }\n-  }\n-}\n-void ObjectSynchronizer::finish_deflate_idle_monitors(DeflateMonitorCounters* counters) {\n-  \/\/ Report the cumulative time for deflating each thread's idle\n-  \/\/ monitors. Note: if the work is split among more than one\n-  \/\/ worker thread, then the reported time will likely be more\n-  \/\/ than a beginning to end measurement of the phase.\n-  log_info(safepoint, cleanup)(\"deflating per-thread idle monitors, %3.7f secs, monitors=%d\", counters->per_thread_times, counters->per_thread_scavenged);\n-\n-  bool needs_special_deflation = is_special_deflation_requested();\n-  if (AsyncDeflateIdleMonitors && !needs_special_deflation) {\n-    \/\/ Nothing to do when idle ObjectMonitors are deflated using\n-    \/\/ a JavaThread unless a special deflation has been requested.\n-    return;\n+  elapsedTimer timer;\n+  if (ls != NULL) {\n+    ls->print_cr(\"begin deflating: in_use_list stats: ceiling=\" SIZE_FORMAT \", count=\" SIZE_FORMAT \", max=\" SIZE_FORMAT,\n+                 in_use_list_ceiling(), _in_use_list.count(), _in_use_list.max());\n+    timer.start();\n@@ -2783,15 +1492,7 @@\n-  if (log_is_enabled(Debug, monitorinflation)) {\n-    \/\/ exit_globals()'s call to audit_and_print_stats() is done\n-    \/\/ at the Info level and not at a safepoint.\n-    \/\/ For async deflation, audit_and_print_stats() is called in\n-    \/\/ ObjectSynchronizer::do_safepoint_work() at the Debug level\n-    \/\/ at a safepoint.\n-    ObjectSynchronizer::audit_and_print_stats(false \/* on_exit *\/);\n-  } else if (log_is_enabled(Info, monitorinflation)) {\n-    log_info(monitorinflation)(\"global_population=%d, global_in_use_count=%d, \"\n-                               \"global_free_count=%d, global_wait_count=%d\",\n-                               Atomic::load(&om_list_globals._population),\n-                               Atomic::load(&om_list_globals._in_use_count),\n-                               Atomic::load(&om_list_globals._free_count),\n-                               Atomic::load(&om_list_globals._wait_count));\n-  }\n+  \/\/ Deflate some idle ObjectMonitors.\n+  size_t deflated_count = deflate_monitor_list(current, ls, &timer);\n+  if (deflated_count > 0 || is_final_audit()) {\n+    \/\/ There are ObjectMonitors that have been deflated or this is the\n+    \/\/ final audit and all the remaining ObjectMonitors have been\n+    \/\/ deflated, BUT the MonitorDeflationThread blocked for the final\n+    \/\/ safepoint during unlinking.\n@@ -2799,2 +1500,14 @@\n-  OM_PERFDATA_OP(Deflations, inc(counters->n_scavenged));\n-  OM_PERFDATA_OP(MonExtant, set_value(counters->n_in_circulation));\n+    \/\/ Unlink deflated ObjectMonitors from the in-use list.\n+    ResourceMark rm;\n+    GrowableArray<ObjectMonitor*> delete_list((int)deflated_count);\n+    size_t unlinked_count = _in_use_list.unlink_deflated(current, ls, &timer,\n+                                                         &delete_list);\n+    if (current->is_Java_thread()) {\n+      if (ls != NULL) {\n+        timer.stop();\n+        ls->print_cr(\"before handshaking: unlinked_count=\" SIZE_FORMAT\n+                     \", in_use_list stats: ceiling=\" SIZE_FORMAT \", count=\"\n+                     SIZE_FORMAT \", max=\" SIZE_FORMAT,\n+                     unlinked_count, in_use_list_ceiling(),\n+                     _in_use_list.count(), _in_use_list.max());\n+      }\n@@ -2802,2 +1515,4 @@\n-  GVars.stw_random = os::random();\n-  GVars.stw_cycle++;\n+      \/\/ A JavaThread needs to handshake in order to safely free the\n+      \/\/ ObjectMonitors that were deflated in this cycle.\n+      HandshakeForDeflation hfd_hc;\n+      Handshake::execute(&hfd_hc);\n@@ -2805,4 +1520,7 @@\n-  if (needs_special_deflation) {\n-    set_is_special_deflation_requested(false);  \/\/ special deflation is done\n-  }\n-}\n+      if (ls != NULL) {\n+        ls->print_cr(\"after handshaking: in_use_list stats: ceiling=\"\n+                     SIZE_FORMAT \", count=\" SIZE_FORMAT \", max=\" SIZE_FORMAT,\n+                     in_use_list_ceiling(), _in_use_list.count(), _in_use_list.max());\n+        timer.start();\n+      }\n+    }\n@@ -2810,2 +1528,6 @@\n-void ObjectSynchronizer::deflate_thread_local_monitors(Thread* thread, DeflateMonitorCounters* counters) {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"must be at safepoint\");\n+    \/\/ After the handshake, safely free the ObjectMonitors that were\n+    \/\/ deflated in this cycle.\n+    size_t deleted_count = 0;\n+    for (ObjectMonitor* monitor: delete_list) {\n+      delete monitor;\n+      deleted_count++;\n@@ -2813,3 +1535,6 @@\n-  if (AsyncDeflateIdleMonitors && !is_special_deflation_requested()) {\n-    \/\/ Nothing to do if a special deflation has NOT been requested.\n-    return;\n+      if (current->is_Java_thread()) {\n+        \/\/ A JavaThread must check for a safepoint\/handshake and honor it.\n+        chk_for_block_req(current->as_Java_thread(), \"deletion\", \"deleted_count\",\n+                          deleted_count, ls, &timer);\n+      }\n+    }\n@@ -2818,7 +1543,8 @@\n-  ObjectMonitor* free_head_p = NULL;  \/\/ Local SLL of scavenged monitors\n-  ObjectMonitor* free_tail_p = NULL;\n-  elapsedTimer timer;\n-\n-  if (log_is_enabled(Info, safepoint, cleanup) ||\n-      log_is_enabled(Info, monitorinflation)) {\n-    timer.start();\n+  if (ls != NULL) {\n+    timer.stop();\n+    if (deflated_count != 0 || log_is_enabled(Debug, monitorinflation)) {\n+      ls->print_cr(\"deflated \" SIZE_FORMAT \" monitors in %3.7f secs\",\n+                   deflated_count, timer.seconds());\n+    }\n+    ls->print_cr(\"end deflating: in_use_list stats: ceiling=\" SIZE_FORMAT \", count=\" SIZE_FORMAT \", max=\" SIZE_FORMAT,\n+                 in_use_list_ceiling(), _in_use_list.count(), _in_use_list.max());\n@@ -2827,2 +1553,2 @@\n-  \/\/ Update n_in_circulation before om_in_use_count is updated by deflation.\n-  Atomic::add(&counters->n_in_circulation, Atomic::load(&thread->om_in_use_count));\n+  OM_PERFDATA_OP(MonExtant, set_value(_in_use_list.count()));\n+  OM_PERFDATA_OP(Deflations, inc(deflated_count));\n@@ -2830,2 +1556,1 @@\n-  int deflated_count = deflate_monitor_list(&thread->om_in_use_list, &thread->om_in_use_count, &free_head_p, &free_tail_p);\n-  Atomic::add(&counters->n_in_use, Atomic::load(&thread->om_in_use_count));\n+  GVars.stw_random = os::random();\n@@ -2833,10 +1558,4 @@\n-  if (free_head_p != NULL) {\n-    \/\/ Move the deflated ObjectMonitors back to the global free list.\n-    guarantee(free_tail_p != NULL && deflated_count > 0, \"invariant\");\n-#ifdef ASSERT\n-    ObjectMonitor* l_next_om = free_tail_p->next_om();\n-#endif\n-    assert(l_next_om == NULL, \"must be NULL: _next_om=\" INTPTR_FORMAT, p2i(l_next_om));\n-    prepend_list_to_global_free_list(free_head_p, free_tail_p, deflated_count);\n-    Atomic::add(&counters->n_scavenged, deflated_count);\n-    Atomic::add(&counters->per_thread_scavenged, deflated_count);\n+  if (deflated_count != 0) {\n+    _no_progress_cnt = 0;\n+  } else {\n+    _no_progress_cnt++;\n@@ -2845,14 +1564,1 @@\n-  timer.stop();\n-  counters->per_thread_times += timer.seconds();\n-\n-  LogStreamHandle(Debug, monitorinflation) lsh_debug;\n-  LogStreamHandle(Info, monitorinflation) lsh_info;\n-  LogStream* ls = NULL;\n-  if (log_is_enabled(Debug, monitorinflation)) {\n-    ls = &lsh_debug;\n-  } else if (deflated_count != 0 && log_is_enabled(Info, monitorinflation)) {\n-    ls = &lsh_info;\n-  }\n-  if (ls != NULL) {\n-    ls->print_cr(\"jt=\" INTPTR_FORMAT \": deflating per-thread idle monitors, %3.7f secs, %d monitors\", p2i(thread), timer.seconds(), deflated_count);\n-  }\n+  return deflated_count;\n@@ -2864,2 +1570,0 @@\n-\/\/ Gives up on a particular monitor if an exception occurs, but continues\n-\/\/ the overall iteration, swallowing the exception.\n@@ -2868,1 +1572,1 @@\n-  TRAPS;\n+  JavaThread* _thread;\n@@ -2871,1 +1575,1 @@\n-  ReleaseJavaMonitorsClosure(Thread* thread) : THREAD(thread) {}\n+  ReleaseJavaMonitorsClosure(JavaThread* thread) : _thread(thread) {}\n@@ -2873,1 +1577,1 @@\n-    if (mid->owner() == THREAD) {\n+    if (mid->owner() == _thread) {\n@@ -2877,2 +1581,2 @@\n-      TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_rec_unlock(THREAD, (oop)mid->object()));\n-      (void)mid->complete_exit(CHECK);\n+      TSAN_RUNTIME_ONLY(SharedRuntime::tsan_oop_rec_unlock(_thread, (oop)mid->object()));\n+      (void)mid->complete_exit(_thread);\n@@ -2883,1 +1587,1 @@\n-\/\/ Release all inflated monitors owned by THREAD.  Lightweight monitors are\n+\/\/ Release all inflated monitors owned by current thread.  Lightweight monitors are\n@@ -2890,1 +1594,1 @@\n-\/\/ Instead of No_Savepoint_Verifier it might be cheaper to\n+\/\/ Instead of NoSafepointVerifier it might be cheaper to\n@@ -2898,2 +1602,2 @@\n-void ObjectSynchronizer::release_monitors_owned_by_thread(TRAPS) {\n-  assert(THREAD == JavaThread::current(), \"must be current Java thread\");\n+void ObjectSynchronizer::release_monitors_owned_by_thread(JavaThread* current) {\n+  assert(current == JavaThread::current(), \"must be current Java thread\");\n@@ -2901,1 +1605,1 @@\n-  ReleaseJavaMonitorsClosure rjmc(THREAD);\n+  ReleaseJavaMonitorsClosure rjmc(current);\n@@ -2903,1 +1607,2 @@\n-  THREAD->clear_pending_exception();\n+  assert(!current->has_pending_exception(), \"Should not be possible\");\n+  current->clear_pending_exception();\n@@ -2940,0 +1645,23 @@\n+\/\/ Do the final audit and print of ObjectMonitor stats; must be done\n+\/\/ by the VMThread at VM exit time.\n+void ObjectSynchronizer::do_final_audit_and_print_stats() {\n+  assert(Thread::current()->is_VM_thread(), \"sanity check\");\n+\n+  if (is_final_audit()) {  \/\/ Only do the audit once.\n+    return;\n+  }\n+  set_is_final_audit();\n+\n+  if (log_is_enabled(Info, monitorinflation)) {\n+    \/\/ Do a deflation in order to reduce the in-use monitor population\n+    \/\/ that is reported by ObjectSynchronizer::log_in_use_monitor_details()\n+    \/\/ which is called by ObjectSynchronizer::audit_and_print_stats().\n+    while (ObjectSynchronizer::deflate_idle_monitors() != 0) {\n+      ; \/\/ empty\n+    }\n+    \/\/ The other audit_and_print_stats() call is done at the Debug\n+    \/\/ level at a safepoint in ObjectSynchronizer::do_safepoint_work().\n+    ObjectSynchronizer::audit_and_print_stats(true \/* on_exit *\/);\n+  }\n+}\n+\n@@ -2949,2 +1677,0 @@\n-\/\/ deflate_monitor_list() no longer uses spin-locking so be careful\n-\/\/ when adding audit_and_print_stats() calls at a safepoint.\n@@ -2968,2 +1694,0 @@\n-  \/\/ Log counts for the global and per-thread monitor lists:\n-  int chk_om_population = log_monitor_list_counts(ls);\n@@ -2972,35 +1696,2 @@\n-  ls->print_cr(\"Checking global lists:\");\n-\n-  \/\/ Check om_list_globals._population:\n-  if (Atomic::load(&om_list_globals._population) == chk_om_population) {\n-    ls->print_cr(\"global_population=%d equals chk_om_population=%d\",\n-                 Atomic::load(&om_list_globals._population), chk_om_population);\n-  } else {\n-    \/\/ With fine grained locks on the monitor lists, it is possible for\n-    \/\/ log_monitor_list_counts() to return a value that doesn't match\n-    \/\/ om_list_globals._population. So far a higher value has been\n-    \/\/ seen in testing so something is being double counted by\n-    \/\/ log_monitor_list_counts().\n-    ls->print_cr(\"WARNING: global_population=%d is not equal to \"\n-                 \"chk_om_population=%d\",\n-                 Atomic::load(&om_list_globals._population), chk_om_population);\n-  }\n-\n-  \/\/ Check om_list_globals._in_use_list and om_list_globals._in_use_count:\n-  chk_global_in_use_list_and_count(ls, &error_cnt);\n-\n-  \/\/ Check om_list_globals._free_list and om_list_globals._free_count:\n-  chk_global_free_list_and_count(ls, &error_cnt);\n-\n-  \/\/ Check om_list_globals._wait_list and om_list_globals._wait_count:\n-  chk_global_wait_list_and_count(ls, &error_cnt);\n-\n-  ls->print_cr(\"Checking per-thread lists:\");\n-\n-  for (JavaThreadIteratorWithHandle jtiwh; JavaThread *jt = jtiwh.next(); ) {\n-    \/\/ Check om_in_use_list and om_in_use_count:\n-    chk_per_thread_in_use_list_and_count(jt, ls, &error_cnt);\n-\n-    \/\/ Check om_free_list and om_free_count:\n-    chk_per_thread_free_list_and_count(jt, ls, &error_cnt);\n-  }\n+  ls->print_cr(\"Checking in_use_list:\");\n+  chk_in_use_list(ls, &error_cnt);\n@@ -3009,1 +1700,1 @@\n-    ls->print_cr(\"No errors found in monitor list checks.\");\n+    ls->print_cr(\"No errors found in in_use_list checks.\");\n@@ -3011,1 +1702,1 @@\n-    log_error(monitorinflation)(\"found monitor list errors: error_cnt=%d\", error_cnt);\n+    log_error(monitorinflation)(\"found in_use_list errors: error_cnt=%d\", error_cnt);\n@@ -3027,61 +1718,6 @@\n-\/\/ Check a free monitor entry; log any errors.\n-void ObjectSynchronizer::chk_free_entry(JavaThread* jt, ObjectMonitor* n,\n-                                        outputStream * out, int *error_cnt_p) {\n-  stringStream ss;\n-  if (n->is_busy()) {\n-    if (jt != NULL) {\n-      out->print_cr(\"ERROR: jt=\" INTPTR_FORMAT \", monitor=\" INTPTR_FORMAT\n-                    \": free per-thread monitor must not be busy: %s\", p2i(jt),\n-                    p2i(n), n->is_busy_to_string(&ss));\n-    } else {\n-      out->print_cr(\"ERROR: monitor=\" INTPTR_FORMAT \": free global monitor \"\n-                    \"must not be busy: %s\", p2i(n), n->is_busy_to_string(&ss));\n-    }\n-    *error_cnt_p = *error_cnt_p + 1;\n-  }\n-  if (n->header().value() != 0) {\n-    if (jt != NULL) {\n-      out->print_cr(\"ERROR: jt=\" INTPTR_FORMAT \", monitor=\" INTPTR_FORMAT\n-                    \": free per-thread monitor must have NULL _header \"\n-                    \"field: _header=\" INTPTR_FORMAT, p2i(jt), p2i(n),\n-                    n->header().value());\n-      *error_cnt_p = *error_cnt_p + 1;\n-    } else if (!AsyncDeflateIdleMonitors) {\n-      out->print_cr(\"ERROR: monitor=\" INTPTR_FORMAT \": free global monitor \"\n-                    \"must have NULL _header field: _header=\" INTPTR_FORMAT,\n-                    p2i(n), n->header().value());\n-      *error_cnt_p = *error_cnt_p + 1;\n-    }\n-  }\n-  if (n->object() != NULL) {\n-    if (jt != NULL) {\n-      out->print_cr(\"ERROR: jt=\" INTPTR_FORMAT \", monitor=\" INTPTR_FORMAT\n-                    \": free per-thread monitor must have NULL _object \"\n-                    \"field: _object=\" INTPTR_FORMAT, p2i(jt), p2i(n),\n-                    p2i(n->object()));\n-    } else {\n-      out->print_cr(\"ERROR: monitor=\" INTPTR_FORMAT \": free global monitor \"\n-                    \"must have NULL _object field: _object=\" INTPTR_FORMAT,\n-                    p2i(n), p2i(n->object()));\n-    }\n-    *error_cnt_p = *error_cnt_p + 1;\n-  }\n-}\n-\n-\/\/ Lock the next ObjectMonitor for traversal and unlock the current\n-\/\/ ObjectMonitor. Returns the next ObjectMonitor if there is one.\n-\/\/ Otherwise returns NULL (after unlocking the current ObjectMonitor).\n-\/\/ This function is used by the various list walker functions to\n-\/\/ safely walk a list without allowing an ObjectMonitor to be moved\n-\/\/ to another list in the middle of a walk.\n-static ObjectMonitor* lock_next_for_traversal(ObjectMonitor* cur) {\n-  assert(is_locked(cur), \"cur=\" INTPTR_FORMAT \" must be locked\", p2i(cur));\n-  ObjectMonitor* next = unmarked_next(cur);\n-  if (next == NULL) {  \/\/ Reached the end of the list.\n-    om_unlock(cur);\n-    return NULL;\n-  }\n-  om_lock(next);   \/\/ Lock next before unlocking current to keep\n-  om_unlock(cur);  \/\/ from being by-passed by another thread.\n-  return next;\n-}\n+\/\/ Check the in_use_list; log the results of the checks.\n+void ObjectSynchronizer::chk_in_use_list(outputStream* out, int *error_cnt_p) {\n+  size_t l_in_use_count = _in_use_list.count();\n+  size_t l_in_use_max = _in_use_list.max();\n+  out->print_cr(\"count=\" SIZE_FORMAT \", max=\" SIZE_FORMAT, l_in_use_count,\n+                l_in_use_max);\n@@ -3089,16 +1725,6 @@\n-\/\/ Check the global free list and count; log the results of the checks.\n-void ObjectSynchronizer::chk_global_free_list_and_count(outputStream * out,\n-                                                        int *error_cnt_p) {\n-  int chk_om_free_count = 0;\n-  ObjectMonitor* cur = NULL;\n-  if ((cur = get_list_head_locked(&om_list_globals._free_list)) != NULL) {\n-    \/\/ Marked the global free list head so process the list.\n-    while (true) {\n-      chk_free_entry(NULL \/* jt *\/, cur, out, error_cnt_p);\n-      chk_om_free_count++;\n-\n-      cur = lock_next_for_traversal(cur);\n-      if (cur == NULL) {\n-        break;\n-      }\n-    }\n+  size_t ck_in_use_count = 0;\n+  MonitorList::Iterator iter = _in_use_list.iterator();\n+  while (iter.has_next()) {\n+    ObjectMonitor* mid = iter.next();\n+    chk_in_use_entry(mid, out, error_cnt_p);\n+    ck_in_use_count++;\n@@ -3106,36 +1732,3 @@\n-  int l_free_count = Atomic::load(&om_list_globals._free_count);\n-  if (l_free_count == chk_om_free_count) {\n-    out->print_cr(\"global_free_count=%d equals chk_om_free_count=%d\",\n-                  l_free_count, chk_om_free_count);\n-  } else {\n-    \/\/ With fine grained locks on om_list_globals._free_list, it\n-    \/\/ is possible for an ObjectMonitor to be prepended to\n-    \/\/ om_list_globals._free_list after we started calculating\n-    \/\/ chk_om_free_count so om_list_globals._free_count may not\n-    \/\/ match anymore.\n-    out->print_cr(\"WARNING: global_free_count=%d is not equal to \"\n-                  \"chk_om_free_count=%d\", l_free_count, chk_om_free_count);\n-  }\n-}\n-\/\/ Check the global wait list and count; log the results of the checks.\n-void ObjectSynchronizer::chk_global_wait_list_and_count(outputStream * out,\n-                                                        int *error_cnt_p) {\n-  int chk_om_wait_count = 0;\n-  ObjectMonitor* cur = NULL;\n-  if ((cur = get_list_head_locked(&om_list_globals._wait_list)) != NULL) {\n-    \/\/ Marked the global wait list head so process the list.\n-    while (true) {\n-      \/\/ Rules for om_list_globals._wait_list are the same as for\n-      \/\/ om_list_globals._free_list:\n-      chk_free_entry(NULL \/* jt *\/, cur, out, error_cnt_p);\n-      chk_om_wait_count++;\n-\n-      cur = lock_next_for_traversal(cur);\n-      if (cur == NULL) {\n-        break;\n-      }\n-    }\n-  }\n-  if (Atomic::load(&om_list_globals._wait_count) == chk_om_wait_count) {\n-    out->print_cr(\"global_wait_count=%d equals chk_om_wait_count=%d\",\n-                  Atomic::load(&om_list_globals._wait_count), chk_om_wait_count);\n+  if (l_in_use_count == ck_in_use_count) {\n+    out->print_cr(\"in_use_count=\" SIZE_FORMAT \" equals ck_in_use_count=\"\n+                  SIZE_FORMAT, l_in_use_count, ck_in_use_count);\n@@ -3144,4 +1737,3 @@\n-    out->print_cr(\"ERROR: global_wait_count=%d is not equal to \"\n-                  \"chk_om_wait_count=%d\",\n-                  Atomic::load(&om_list_globals._wait_count), chk_om_wait_count);\n-    *error_cnt_p = *error_cnt_p + 1;\n+    out->print_cr(\"WARNING: in_use_count=\" SIZE_FORMAT \" is not equal to \"\n+                  \"ck_in_use_count=\" SIZE_FORMAT, l_in_use_count,\n+                  ck_in_use_count);\n@@ -3149,22 +1741,4 @@\n-}\n-\/\/ Check the global in-use list and count; log the results of the checks.\n-void ObjectSynchronizer::chk_global_in_use_list_and_count(outputStream * out,\n-                                                          int *error_cnt_p) {\n-  int chk_om_in_use_count = 0;\n-  ObjectMonitor* cur = NULL;\n-  if ((cur = get_list_head_locked(&om_list_globals._in_use_list)) != NULL) {\n-    \/\/ Marked the global in-use list head so process the list.\n-    while (true) {\n-      chk_in_use_entry(NULL \/* jt *\/, cur, out, error_cnt_p);\n-      chk_om_in_use_count++;\n-\n-      cur = lock_next_for_traversal(cur);\n-      if (cur == NULL) {\n-        break;\n-      }\n-    }\n-  }\n-  int l_in_use_count = Atomic::load(&om_list_globals._in_use_count);\n-  if (l_in_use_count == chk_om_in_use_count) {\n-    out->print_cr(\"global_in_use_count=%d equals chk_om_in_use_count=%d\",\n-                  l_in_use_count, chk_om_in_use_count);\n+  size_t ck_in_use_max = _in_use_list.max();\n+  if (l_in_use_max == ck_in_use_max) {\n+    out->print_cr(\"in_use_max=\" SIZE_FORMAT \" equals ck_in_use_max=\"\n+                  SIZE_FORMAT, l_in_use_max, ck_in_use_max);\n@@ -3173,5 +1747,2 @@\n-    \/\/ With fine grained locks on the monitor lists, it is possible for\n-    \/\/ an exiting JavaThread to put its in-use ObjectMonitors on the\n-    \/\/ global in-use list after chk_om_in_use_count is calculated above.\n-    out->print_cr(\"WARNING: global_in_use_count=%d is not equal to chk_om_in_use_count=%d\",\n-                  l_in_use_count, chk_om_in_use_count);\n+    out->print_cr(\"WARNING: in_use_max=\" SIZE_FORMAT \" is not equal to \"\n+                  \"ck_in_use_max=\" SIZE_FORMAT, l_in_use_max, ck_in_use_max);\n@@ -3182,12 +1753,7 @@\n-void ObjectSynchronizer::chk_in_use_entry(JavaThread* jt, ObjectMonitor* n,\n-                                          outputStream * out, int *error_cnt_p) {\n-  if (n->header().value() == 0) {\n-    if (jt != NULL) {\n-      out->print_cr(\"ERROR: jt=\" INTPTR_FORMAT \", monitor=\" INTPTR_FORMAT\n-                    \": in-use per-thread monitor must have non-NULL _header \"\n-                    \"field.\", p2i(jt), p2i(n));\n-    } else {\n-      out->print_cr(\"ERROR: monitor=\" INTPTR_FORMAT \": in-use global monitor \"\n-                    \"must have non-NULL _header field.\", p2i(n));\n-    }\n-    *error_cnt_p = *error_cnt_p + 1;\n+void ObjectSynchronizer::chk_in_use_entry(ObjectMonitor* n, outputStream* out,\n+                                          int* error_cnt_p) {\n+  if (n->owner_is_DEFLATER_MARKER()) {\n+    \/\/ This should not happen, but if it does, it is not fatal.\n+    out->print_cr(\"WARNING: monitor=\" INTPTR_FORMAT \": in-use monitor is \"\n+                  \"deflated.\", p2i(n));\n+    return;\n@@ -3195,9 +1761,3 @@\n-  if (n->object() == NULL) {\n-    if (jt != NULL) {\n-      out->print_cr(\"ERROR: jt=\" INTPTR_FORMAT \", monitor=\" INTPTR_FORMAT\n-                    \": in-use per-thread monitor must have non-NULL _object \"\n-                    \"field.\", p2i(jt), p2i(n));\n-    } else {\n-      out->print_cr(\"ERROR: monitor=\" INTPTR_FORMAT \": in-use global monitor \"\n-                    \"must have non-NULL _object field.\", p2i(n));\n-    }\n+  if (n->header().value() == 0) {\n+    out->print_cr(\"ERROR: monitor=\" INTPTR_FORMAT \": in-use monitor must \"\n+                  \"have non-NULL _header field.\", p2i(n));\n@@ -3206,11 +1766,6 @@\n-  const oop obj = (oop)n->object();\n-  const markWord mark = obj->mark();\n-  if (!mark.has_monitor()) {\n-    if (jt != NULL) {\n-      out->print_cr(\"ERROR: jt=\" INTPTR_FORMAT \", monitor=\" INTPTR_FORMAT\n-                    \": in-use per-thread monitor's object does not think \"\n-                    \"it has a monitor: obj=\" INTPTR_FORMAT \", mark=\"\n-                    INTPTR_FORMAT,  p2i(jt), p2i(n), p2i(obj), mark.value());\n-    } else {\n-      out->print_cr(\"ERROR: monitor=\" INTPTR_FORMAT \": in-use global \"\n-                    \"monitor's object does not think it has a monitor: obj=\"\n+  const oop obj = n->object_peek();\n+  if (obj != NULL) {\n+    const markWord mark = obj->mark();\n+    if (!mark.has_monitor()) {\n+      out->print_cr(\"ERROR: monitor=\" INTPTR_FORMAT \": in-use monitor's \"\n+                    \"object does not think it has a monitor: obj=\"\n@@ -3219,0 +1774,1 @@\n+      *error_cnt_p = *error_cnt_p + 1;\n@@ -3220,13 +1776,4 @@\n-    *error_cnt_p = *error_cnt_p + 1;\n-  }\n-  ObjectMonitor* const obj_mon = mark.monitor();\n-  if (n != obj_mon) {\n-    if (jt != NULL) {\n-      out->print_cr(\"ERROR: jt=\" INTPTR_FORMAT \", monitor=\" INTPTR_FORMAT\n-                    \": in-use per-thread monitor's object does not refer \"\n-                    \"to the same monitor: obj=\" INTPTR_FORMAT \", mark=\"\n-                    INTPTR_FORMAT \", obj_mon=\" INTPTR_FORMAT, p2i(jt),\n-                    p2i(n), p2i(obj), mark.value(), p2i(obj_mon));\n-    } else {\n-      out->print_cr(\"ERROR: monitor=\" INTPTR_FORMAT \": in-use global \"\n-                    \"monitor's object does not refer to the same monitor: obj=\"\n+    ObjectMonitor* const obj_mon = mark.monitor();\n+    if (n != obj_mon) {\n+      out->print_cr(\"ERROR: monitor=\" INTPTR_FORMAT \": in-use monitor's \"\n+                    \"object does not refer to the same monitor: obj=\"\n@@ -3235,0 +1782,1 @@\n+      *error_cnt_p = *error_cnt_p + 1;\n@@ -3236,62 +1784,0 @@\n-    *error_cnt_p = *error_cnt_p + 1;\n-  }\n-}\n-\n-\/\/ Check the thread's free list and count; log the results of the checks.\n-void ObjectSynchronizer::chk_per_thread_free_list_and_count(JavaThread *jt,\n-                                                            outputStream * out,\n-                                                            int *error_cnt_p) {\n-  int chk_om_free_count = 0;\n-  ObjectMonitor* cur = NULL;\n-  if ((cur = get_list_head_locked(&jt->om_free_list)) != NULL) {\n-    \/\/ Marked the per-thread free list head so process the list.\n-    while (true) {\n-      chk_free_entry(jt, cur, out, error_cnt_p);\n-      chk_om_free_count++;\n-\n-      cur = lock_next_for_traversal(cur);\n-      if (cur == NULL) {\n-        break;\n-      }\n-    }\n-  }\n-  int l_om_free_count = Atomic::load(&jt->om_free_count);\n-  if (l_om_free_count == chk_om_free_count) {\n-    out->print_cr(\"jt=\" INTPTR_FORMAT \": om_free_count=%d equals \"\n-                  \"chk_om_free_count=%d\", p2i(jt), l_om_free_count, chk_om_free_count);\n-  } else {\n-    out->print_cr(\"ERROR: jt=\" INTPTR_FORMAT \": om_free_count=%d is not \"\n-                  \"equal to chk_om_free_count=%d\", p2i(jt), l_om_free_count,\n-                  chk_om_free_count);\n-    *error_cnt_p = *error_cnt_p + 1;\n-  }\n-}\n-\n-\/\/ Check the thread's in-use list and count; log the results of the checks.\n-void ObjectSynchronizer::chk_per_thread_in_use_list_and_count(JavaThread *jt,\n-                                                              outputStream * out,\n-                                                              int *error_cnt_p) {\n-  int chk_om_in_use_count = 0;\n-  ObjectMonitor* cur = NULL;\n-  if ((cur = get_list_head_locked(&jt->om_in_use_list)) != NULL) {\n-    \/\/ Marked the per-thread in-use list head so process the list.\n-    while (true) {\n-      chk_in_use_entry(jt, cur, out, error_cnt_p);\n-      chk_om_in_use_count++;\n-\n-      cur = lock_next_for_traversal(cur);\n-      if (cur == NULL) {\n-        break;\n-      }\n-    }\n-  }\n-  int l_om_in_use_count = Atomic::load(&jt->om_in_use_count);\n-  if (l_om_in_use_count == chk_om_in_use_count) {\n-    out->print_cr(\"jt=\" INTPTR_FORMAT \": om_in_use_count=%d equals \"\n-                  \"chk_om_in_use_count=%d\", p2i(jt), l_om_in_use_count,\n-                  chk_om_in_use_count);\n-  } else {\n-    out->print_cr(\"ERROR: jt=\" INTPTR_FORMAT \": om_in_use_count=%d is not \"\n-                  \"equal to chk_om_in_use_count=%d\", p2i(jt), l_om_in_use_count,\n-                  chk_om_in_use_count);\n-    *error_cnt_p = *error_cnt_p + 1;\n@@ -3301,1 +1787,1 @@\n-\/\/ Log details about ObjectMonitors on the in-use lists. The 'BHL'\n+\/\/ Log details about ObjectMonitors on the in_use_list. The 'BHL'\n@@ -3304,1 +1790,1 @@\n-void ObjectSynchronizer::log_in_use_monitor_details(outputStream * out) {\n+void ObjectSynchronizer::log_in_use_monitor_details(outputStream* out) {\n@@ -3306,2 +1792,2 @@\n-  if (Atomic::load(&om_list_globals._in_use_count) > 0) {\n-    out->print_cr(\"In-use global monitor info:\");\n+  if (_in_use_list.count() > 0) {\n+    out->print_cr(\"In-use monitor info:\");\n@@ -3312,51 +1798,12 @@\n-    ObjectMonitor* cur = NULL;\n-    if ((cur = get_list_head_locked(&om_list_globals._in_use_list)) != NULL) {\n-      \/\/ Marked the global in-use list head so process the list.\n-      while (true) {\n-        const oop obj = (oop) cur->object();\n-        const markWord mark = cur->header();\n-        ResourceMark rm;\n-        out->print(INTPTR_FORMAT \"  %d%d%d  \" INTPTR_FORMAT \"  %s\", p2i(cur),\n-                   cur->is_busy() != 0, mark.hash() != 0, cur->owner() != NULL,\n-                   p2i(obj), obj->klass()->external_name());\n-        if (cur->is_busy() != 0) {\n-          out->print(\" (%s)\", cur->is_busy_to_string(&ss));\n-          ss.reset();\n-        }\n-        out->cr();\n-\n-        cur = lock_next_for_traversal(cur);\n-        if (cur == NULL) {\n-          break;\n-        }\n-      }\n-    }\n-  }\n-\n-  out->print_cr(\"In-use per-thread monitor info:\");\n-  out->print_cr(\"(B -> is_busy, H -> has hash code, L -> lock status)\");\n-  out->print_cr(\"%18s  %18s  %s  %18s  %18s\",\n-                \"jt\", \"monitor\", \"BHL\", \"object\", \"object type\");\n-  out->print_cr(\"==================  ==================  ===  ==================  ==================\");\n-  for (JavaThreadIteratorWithHandle jtiwh; JavaThread *jt = jtiwh.next(); ) {\n-    ObjectMonitor* cur = NULL;\n-    if ((cur = get_list_head_locked(&jt->om_in_use_list)) != NULL) {\n-      \/\/ Marked the global in-use list head so process the list.\n-      while (true) {\n-        const oop obj = (oop) cur->object();\n-        const markWord mark = cur->header();\n-        ResourceMark rm;\n-        out->print(INTPTR_FORMAT \"  \" INTPTR_FORMAT \"  %d%d%d  \" INTPTR_FORMAT\n-                   \"  %s\", p2i(jt), p2i(cur), cur->is_busy() != 0,\n-                   mark.hash() != 0, cur->owner() != NULL, p2i(obj),\n-                   obj->klass()->external_name());\n-        if (cur->is_busy() != 0) {\n-          out->print(\" (%s)\", cur->is_busy_to_string(&ss));\n-          ss.reset();\n-        }\n-        out->cr();\n-\n-        cur = lock_next_for_traversal(cur);\n-        if (cur == NULL) {\n-          break;\n-        }\n+    MonitorList::Iterator iter = _in_use_list.iterator();\n+    while (iter.has_next()) {\n+      ObjectMonitor* mid = iter.next();\n+      const oop obj = mid->object_peek();\n+      const markWord mark = mid->header();\n+      ResourceMark rm;\n+      out->print(INTPTR_FORMAT \"  %d%d%d  \" INTPTR_FORMAT \"  %s\", p2i(mid),\n+                 mid->is_busy(), mark.hash() != 0, mid->owner() != NULL,\n+                 p2i(obj), obj == NULL ? \"\" : obj->klass()->external_name());\n+      if (mid->is_busy()) {\n+        out->print(\" (%s)\", mid->is_busy_to_string(&ss));\n+        ss.reset();\n@@ -3364,0 +1811,1 @@\n+      out->cr();\n@@ -3369,55 +1817,0 @@\n-\n-\/\/ Log counts for the global and per-thread monitor lists and return\n-\/\/ the population count.\n-int ObjectSynchronizer::log_monitor_list_counts(outputStream * out) {\n-  int pop_count = 0;\n-  out->print_cr(\"%18s  %10s  %10s  %10s  %10s\",\n-                \"Global Lists:\", \"InUse\", \"Free\", \"Wait\", \"Total\");\n-  out->print_cr(\"==================  ==========  ==========  ==========  ==========\");\n-  int l_in_use_count = Atomic::load(&om_list_globals._in_use_count);\n-  int l_free_count = Atomic::load(&om_list_globals._free_count);\n-  int l_wait_count = Atomic::load(&om_list_globals._wait_count);\n-  out->print_cr(\"%18s  %10d  %10d  %10d  %10d\", \"\", l_in_use_count,\n-                l_free_count, l_wait_count,\n-                Atomic::load(&om_list_globals._population));\n-  pop_count += l_in_use_count + l_free_count + l_wait_count;\n-\n-  out->print_cr(\"%18s  %10s  %10s  %10s\",\n-                \"Per-Thread Lists:\", \"InUse\", \"Free\", \"Provision\");\n-  out->print_cr(\"==================  ==========  ==========  ==========\");\n-\n-  for (JavaThreadIteratorWithHandle jtiwh; JavaThread *jt = jtiwh.next(); ) {\n-    int l_om_in_use_count = Atomic::load(&jt->om_in_use_count);\n-    int l_om_free_count = Atomic::load(&jt->om_free_count);\n-    out->print_cr(INTPTR_FORMAT \"  %10d  %10d  %10d\", p2i(jt),\n-                  l_om_in_use_count, l_om_free_count, jt->om_free_provision);\n-    pop_count += l_om_in_use_count + l_om_free_count;\n-  }\n-  return pop_count;\n-}\n-\n-#ifndef PRODUCT\n-\n-\/\/ Check if monitor belongs to the monitor cache\n-\/\/ The list is grow-only so it's *relatively* safe to traverse\n-\/\/ the list of extant blocks without taking a lock.\n-\n-int ObjectSynchronizer::verify_objmon_isinpool(ObjectMonitor *monitor) {\n-  PaddedObjectMonitor* block = Atomic::load(&g_block_list);\n-  while (block != NULL) {\n-    assert(block->object() == CHAINMARKER, \"must be a block header\");\n-    if (monitor > &block[0] && monitor < &block[_BLOCKSIZE]) {\n-      address mon = (address)monitor;\n-      address blk = (address)block;\n-      size_t diff = mon - blk;\n-      assert((diff % sizeof(PaddedObjectMonitor)) == 0, \"must be aligned\");\n-      return 1;\n-    }\n-    \/\/ unmarked_next() is not needed with g_block_list (no locking\n-    \/\/ used with block linkage _next_om fields).\n-    block = (PaddedObjectMonitor*)block->next_om();\n-  }\n-  return 0;\n-}\n-\n-#endif\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":655,"deletions":2262,"binary":false,"changes":2917,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"memory\/resourceArea.hpp\"\n","filename":"src\/hotspot\/share\/tsan\/tsanOopMap.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,1 @@\n-#include \"jvm.h\"\n+#include \"jvm_constants.h\"\n@@ -30,0 +30,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -70,0 +71,1 @@\n+  JVM_ACC_IS_VALUE_BASED_CLASS    = 0x08000000,     \/\/ True if klass is marked as a ValueBased class\n@@ -126,1 +128,0 @@\n-  bool is_strict      () const         { return (_flags & JVM_ACC_STRICT      ) != 0; }\n@@ -156,0 +157,1 @@\n+  bool is_value_based_class    () const { return (_flags & JVM_ACC_IS_VALUE_BASED_CLASS   ) != 0; }\n@@ -232,0 +234,1 @@\n+  void set_is_value_based_class()      { atomic_set_bits(JVM_ACC_IS_VALUE_BASED_CLASS);    }\n","filename":"src\/hotspot\/share\/utilities\/accessFlags.hpp","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -295,8 +295,0 @@\n-#ifndef INCLUDE_AOT\n-#define INCLUDE_AOT 1\n-#endif\n-\n-#if INCLUDE_AOT && !INCLUDE_JVMCI\n-#  error \"Must have JVMCI for AOT\"\n-#endif\n-\n@@ -313,10 +305,0 @@\n-#if INCLUDE_AOT\n-#define AOT_ONLY(code) code\n-#define NOT_AOT(code)\n-#define NOT_AOT_RETURN \/* next token must be ; *\/\n-#else\n-#define AOT_ONLY(code)\n-#define NOT_AOT(code) code\n-#define NOT_AOT_RETURN {}\n-#endif \/\/ INCLUDE_AOT\n-\n@@ -325,3 +307,0 @@\n-#ifdef COMPILER2\n-  #define TIERED\n-#endif\n@@ -349,0 +328,2 @@\n+#define NOT_COMPILER2_OR_JVMCI_RETURN        \/* next token must be ; *\/\n+#define NOT_COMPILER2_OR_JVMCI_RETURN_(code) \/* next token must be ; *\/\n@@ -353,0 +334,2 @@\n+#define NOT_COMPILER2_OR_JVMCI_RETURN {}\n+#define NOT_COMPILER2_OR_JVMCI_RETURN_(code) { return code; }\n@@ -355,7 +338,17 @@\n-#ifdef TIERED\n-#define TIERED_ONLY(code) code\n-#define NOT_TIERED(code)\n-#else \/\/ TIERED\n-#define TIERED_ONLY(code)\n-#define NOT_TIERED(code) code\n-#endif \/\/ TIERED\n+\/\/ COMPILER1 and COMPILER2\n+#if defined(COMPILER1) && defined(COMPILER2)\n+#define COMPILER1_AND_COMPILER2 1\n+#define COMPILER1_AND_COMPILER2_PRESENT(code) code\n+#else\n+#define COMPILER1_AND_COMPILER2 0\n+#define COMPILER1_AND_COMPILER2_PRESENT(code)\n+#endif\n+\n+\/\/ COMPILER1 or COMPILER2\n+#if defined(COMPILER1) || defined(COMPILER2)\n+#define COMPILER1_OR_COMPILER2 1\n+#define COMPILER1_OR_COMPILER2_PRESENT(code) code\n+#else\n+#define COMPILER1_OR_COMPILER2 0\n+#define COMPILER1_OR_COMPILER2_PRESENT(code)\n+#endif\n@@ -389,8 +382,0 @@\n-#ifdef CC_INTERP\n-#define CC_INTERP_ONLY(code) code\n-#define NOT_CC_INTERP(code)\n-#else\n-#define CC_INTERP_ONLY(code)\n-#define NOT_CC_INTERP(code) code\n-#endif \/\/ CC_INTERP\n-\n@@ -472,0 +457,1 @@\n+#define NOT_ZERO_RETURN {}\n@@ -475,0 +461,1 @@\n+#define NOT_ZERO_RETURN\n@@ -586,0 +573,2 @@\n+#define MACOS_AARCH64_ONLY(x) MACOS_ONLY(AARCH64_ONLY(x))\n+\n","filename":"src\/hotspot\/share\/utilities\/macros.hpp","additions":26,"deletions":37,"binary":false,"changes":63,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2018, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -86,1 +86,2 @@\n-            if (finalizee != null && !(finalizee instanceof java.lang.Enum)) {\n+            assert finalizee != null;\n+            if (!(finalizee instanceof java.lang.Enum)) {\n@@ -112,0 +113,1 @@\n+    @SuppressWarnings(\"removal\")\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/Finalizer.java","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -117,0 +117,1 @@\n+    exports java.util.random;\n@@ -137,0 +138,2 @@\n+    exports com.sun.crypto.provider to\n+        jdk.crypto.cryptoki;\n@@ -142,1 +145,1 @@\n-    exports jdk.internal to\n+    exports jdk.internal.javac to\n@@ -144,1 +147,0 @@\n-        jdk.jfr,\n@@ -153,0 +155,1 @@\n+        jdk.jartool,\n@@ -167,1 +170,2 @@\n-        java.naming;\n+        java.naming,\n+        jdk.incubator.foreign;\n@@ -196,1 +200,0 @@\n-        java.xml,\n@@ -200,0 +203,2 @@\n+        jdk.crypto.cryptoki,\n+        jdk.incubator.vector,\n@@ -212,1 +217,2 @@\n-        jdk.incubator.jpackage;\n+        jdk.jpackage,\n+        jdk.incubator.foreign;\n@@ -218,1 +224,2 @@\n-        jdk.management;\n+        jdk.management,\n+        jdk.jfr;\n@@ -220,1 +227,2 @@\n-        java.desktop;\n+        java.desktop,\n+        jdk.incubator.foreign;\n@@ -227,1 +235,2 @@\n-        jdk.unsupported;\n+        jdk.unsupported,\n+        jdk.incubator.foreign;\n@@ -232,0 +241,1 @@\n+        java.instrument,\n@@ -233,0 +243,1 @@\n+        jdk.incubator.vector,\n@@ -234,0 +245,1 @@\n+        jdk.jfr,\n@@ -235,0 +247,2 @@\n+    exports jdk.internal.vm.vector to\n+        jdk.incubator.vector;\n@@ -243,0 +257,2 @@\n+    exports jdk.internal.util.random to\n+        jdk.random;\n@@ -269,0 +285,2 @@\n+    exports sun.nio.fs to\n+        jdk.net;\n@@ -346,1 +364,2 @@\n-\n+    exports jdk.internal.invoke to\n+        jdk.incubator.foreign;\n@@ -368,0 +387,1 @@\n+    uses java.util.random.RandomGenerator;\n@@ -391,0 +411,6 @@\n+\n+    provides java.util.random.RandomGenerator with\n+        java.security.SecureRandom,\n+        java.util.Random,\n+        java.util.SplittableRandom;\n+\n","filename":"src\/java.base\/share\/classes\/module-info.java","additions":36,"deletions":10,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1995, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1995, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -295,3 +295,2 @@\n-    if (!IsJavaArgs()) {\n-        SetJvmEnvironment(argc,argv);\n-    }\n+    \/* Set env. Must be done before LoadJavaVM. *\/\n+    SetJvmEnvironment(argc, argv);\n@@ -614,0 +613,1 @@\n+           JLI_StrCmp(name, \"--enable-native-access\") == 0 ||\n@@ -626,0 +626,1 @@\n+           JLI_StrCCmp(name, \"--enable-native-access=\") == 0 ||\n@@ -820,0 +821,1 @@\n+    const char* NMT_Arg_Name = IsJavaArgs() ? \"-J-XX:NativeMemoryTracking=\" : \"-XX:NativeMemoryTracking=\";\n@@ -825,5 +827,8 @@\n-         * Since this must be a VM flag we stop processing once we see\n-         * an argument the launcher would not have processed beyond (such\n-         * as -version or -h), or an argument that indicates the following\n-         * arguments are for the application (i.e. the main class name, or\n-         * the -jar argument).\n+         * Java launcher (!IsJavaArgs()):\n+         *   Since this must be a VM flag we stop processing once we see\n+         *   an argument the launcher would not have processed beyond (such\n+         *   as -version or -h), or an argument that indicates the following\n+         *   arguments are for the application (i.e. the main class name, or\n+         *   the -jar argument).\n+         * Other launchers (IsJavaArgs()):\n+         *   All arguments have to be scanned to see if it is a -J argument.\n@@ -831,1 +836,1 @@\n-        if (i > 0) {\n+        if (!IsJavaArgs() && i > 0) {\n@@ -849,1 +854,1 @@\n-        if (JLI_StrCCmp(arg, \"-XX:NativeMemoryTracking=\") == 0) {\n+        if (JLI_StrCCmp(arg, NMT_Arg_Name) == 0) {\n@@ -852,1 +857,1 @@\n-            size_t pnlen = JLI_StrLen(\"-XX:NativeMemoryTracking=\");\n+            size_t pnlen = JLI_StrLen(NMT_Arg_Name);\n","filename":"src\/java.base\/share\/native\/libjli\/java.c","additions":17,"deletions":12,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -233,0 +233,8 @@\n+#ifdef MUSL_LIBC\n+    \/*\n+     * The musl library loader requires LD_LIBRARY_PATH to be set in order\n+     * to correctly resolve the dependency libjava.so has on libjvm.so.\n+     *\/\n+    return JNI_TRUE;\n+#endif\n+\n","filename":"src\/java.base\/unix\/native\/libjli\/java_md.c","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include <jvm.h>\n@@ -70,0 +71,2 @@\n+static char* altstack = NULL;\n+\n@@ -71,1 +74,8 @@\n-  static char altstack[SIGSTKSZ];\n+  if (altstack == NULL) {\n+    \/\/ Dynamically allocated in case SIGSTKSZ is not constant\n+    altstack = malloc(SIGSTKSZ);\n+    if (altstack == NULL) {\n+      fprintf(stderr, \"Test ERROR. Unable to malloc altstack space\\n\");\n+      exit(7);\n+    }\n+  }\n@@ -94,0 +104,15 @@\n+size_t get_java_stacksize () {\n+  pthread_attr_t attr;\n+  JDK1_1InitArgs jdk_args;\n+\n+  memset(&jdk_args, 0, (sizeof jdk_args));\n+\n+  jdk_args.version = JNI_VERSION_1_1;\n+  JNI_GetDefaultJavaVMInitArgs(&jdk_args);\n+  if (jdk_args.javaStackSize <= 0) {\n+    fprintf(stderr, \"Test ERROR. Can't get a valid value for the default stacksize.\\n\");\n+    exit(7);\n+  }\n+  return jdk_args.javaStackSize;\n+}\n+\n@@ -261,0 +286,1 @@\n+  size_t stack_size = get_java_stacksize();\n@@ -262,0 +288,4 @@\n+  pthread_attr_t thread_attr;\n+\n+  pthread_attr_init(&thread_attr);\n+  pthread_attr_setstacksize(&thread_attr, stack_size);\n@@ -267,2 +297,3 @@\n-    pthread_create (&thr, NULL, run_java_overflow, NULL);\n-    pthread_join (thr, NULL);\n+\n+    pthread_create(&thr, &thread_attr, run_java_overflow, NULL);\n+    pthread_join(thr, NULL);\n@@ -280,2 +311,2 @@\n-    pthread_create (&thr, NULL, run_native_overflow, NULL);\n-    pthread_join (thr, NULL);\n+    pthread_create(&thr, &thread_attr, run_native_overflow, NULL);\n+    pthread_join(thr, NULL);\n","filename":"test\/hotspot\/jtreg\/runtime\/StackGuardPages\/exeinvoke.c","additions":36,"deletions":5,"binary":false,"changes":41,"status":"modified"}]}