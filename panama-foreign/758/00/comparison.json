{"files":[{"patch":"@@ -3,1 +3,1 @@\n-**May 2022**\n+**December 2022**\n@@ -7,1 +7,1 @@\n-A crucial part of any native interop story lies in the ability of accessing off-heap memory efficiently and safely. Panama achieves this goal through the Foreign Memory Access API, which has been available as an [incubating](https:\/\/openjdk.java.net\/jeps\/11) API since Java [14](https:\/\/openjdk.java.net\/jeps\/370). The Foreign Memory Access API introduces abstractions to allocate and access flat memory regions (whether on- or off-heap), to manage the lifecycle of memory resources and to model native memory addresses.\n+A crucial part of any native interop story lies in the ability of accessing off-heap memory efficiently and safely. Java achieves this goal through the Foreign Function & Memory API (FFM API in short), parts of which have been available as an [incubating](https:\/\/openjdk.java.net\/jeps\/11) API since Java [14](https:\/\/openjdk.java.net\/jeps\/370). The FFM API introduces abstractions to allocate and access flat memory regions (whether on- or off-heap), to manage the lifecycle of memory resources and to model native memory addresses.\n@@ -9,1 +9,1 @@\n-### Segments\n+### Memory segments and lifetimes\n@@ -11,1 +11,1 @@\n-Memory segments are abstractions which can be used to model contiguous memory regions, located either on- or off- the Java heap. Segments can be allocated from native memory (e.g. like a `malloc`), or can be wrapped around existing memory sources (e.g. a Java array or a `ByteBuffer`). Memory segments provide *strong* spatial, temporal and thread-confinement guarantees which make memory dereference operation *safe* (more on that later), although in most simple cases some properties of memory segments can safely be ignored.\n+Memory segments are abstractions which can be used to model contiguous memory regions, located either on-heap (i.e. *heap segments*) or off- the Java heap (i.e. *native segments*). Memory segments provide *strong* spatial, temporal and thread-confinement guarantees which make memory dereference operation *safe* (more on that later), although in most simple cases some properties of memory segments can safely be ignored.\n@@ -16,1 +16,1 @@\n-MemorySegment segment = MemorySegment.allocateNative(100, MemorySession.openImplicit());\n+MemorySegment segment = MemorySegment.allocateNative(100, SegmentScope.global());\n@@ -19,1 +19,35 @@\n-The above code allocates a 100-bytes long memory segment. The lifecycle of a memory segment is controlled by an abstraction called `MemorySession`. In this example, the segment memory will not be *freed* as long as the segment instance is deemed *reachable*, as specified by the `openImplicit()` parameter. In other words, the above factory creates a segment whose behavior closely matches that of a `ByteBuffer` allocated with the `allocateDirect` factory. Of course, the memory access API also supports deterministic memory release; we will cover that in a later section of this document.\n+The above code allocates a 100-bytes long memory segment. The lifecycle of a memory segment is controlled by an abstraction called `SegmentScope`. In this example, the segment is associated with the simplest scope, called the *global* scope. Memory segments associated with this scope are always *alive* and their backing region of memory are never deallocated. In other words, we say that the above segment has an *unbounded* lifetime.\n+\n+Most programs, though, require off-heap memory to be deallocated  while the program is running, and thus need memory segments with *bounded* lifetimes. The simplest way to obtain a segment with bounded lifetime is to use an *automatic scope*:\n+\n+```java\n+MemorySegment segment = MemorySegment.allocateNative(100, SegmentScope.auto());\n+```\n+\n+Segments associated with an automatic scope are alive as long as they are determined to be reachable by the garbage collector. In other words, the above snippet creates a native segment whose behavior closely matches that of a `ByteBuffer` allocated with the `allocateDirect` factory.\n+\n+There are cases, however, where automatic deallocation is not enough: consider the case where a large memory segment is mapped from a file (this is possible using `MemorySegment::map`); in this case, an application would probably prefer to release (e.g. `unmap`) the memory associated with this segment in a *deterministic* fashion, to ensure that memory doesn't remain available for longer than in needs to.\n+\n+An `Arena` provides a scope - the arena scope - which features a bounded and deterministic lifetime. The arena scope is alive from the time when the arena is opened, until the time when the arena is closed. Multiple segments allocated with the same arena scope  enjoy the same bounded lifetime and can safely contain mutual references. For example, this code opens an arena and uses the arena's scope to specify the lifetime of two segments:\n+\n+```\n+try (Arena arena = Arena.openConfined()) {\n+    MemorySegment segment1 = MemorySegment.allocateNative(100, arena.scope());\n+    MemorySegment segment2 = MemorySegment.allocateNative(100, arena.scope());\n+    ...\n+    MemorySegment segmentN = MemorySegment.allocateNative(100, arena.scope());\n+} \/\/ all segments are deallocated here\n+```\n+\n+When the arena is closed (above, this is done with the *try-with-resources* construct) the arena scope is no longer alive, all the segments associated with it are invalidated,  and the regions of memory backing the segments are deallocated  atomically.\n+\n+### Thread-confinement\n+\n+Arenas provide a strong temporal safety guarantee: memory segments associated with an arena scope cannot be accessed after the arena is closed, since the arena scope is no longer alive. If an arena is opened and closed by the same thread, and all memory segments allocated with the arena's scope are accessed only  by that thread, then ensuring correctness is straightforward. However, if memory segments allocated with the arena scope are accessed by  multiple threads then ensuring correctness is complex. For example, a segment allocated with arena scope might be accessed by one thread while another thread attempts to close the arena. To guarantee temporal safety without making single-threaded clients pay undue cost, there are  two kinds of arenas: *confined* and *shared*.\n+\n+- A confined arena (`Arena::openConfined`) supports strong thread-confinement guarantees. A confined arena has an *owner thread*, typically the thread which opened it. The memory segments allocated in a confined arena (i.e., with the confined arena's scope) can be accessed  only by the owner thread. Any attempt to close the confined arena from a thread other than the owner thread will fail with an exception.\n+- A shared arena (`Arena::openShared`) has no owner thread.  The memory segments allocated in a shared arena can be accessed by  multiple threads. Moreover, a shared arena can be closed by any thread,  and the closure is guaranteed to be safe and atomic even under races<a href=\"#1\"><sup>1<\/sup><\/a>.\n+\n+In summary, a segment scope controls which threads can access a  memory segment, and when. A memory segment with global scope or  automatic scope can be accessed by any thread. Conversely, arena scopes  restrict access to specific threads in order to provide both strong  temporal safety and a predictable performance model.\n+\n+### Slicing segments\n@@ -24,1 +58,1 @@\n-MemorySegment segment = MemorySement.allocateNative(10, MemorySession.openImplicit());\n+MemorySegment segment = MemorySement.allocateNative(10, SegmentScope.auto());\n@@ -28,1 +62,24 @@\n-The above code creates a slice that starts at offset 4 and has a length of 4 bytes. Generally speaking, slices have the *same* temporal bounds as the parent segment (we will refine this concept later in this document). In this example, the memory associated with the parent segment will not be released as long as there is at least one *reachable* slice derived from that segment.\n+The above code creates a slice that starts at offset 4 and has a length of 4 bytes. Slices have the *same* temporal bounds (i.e. segment scope) as the parent segment. In the above example, the memory associated with the parent segment will not be released as long as there is at least one *reachable* slice derived from that segment.\n+\n+To process the contents of a memory segment in bulk, a memory segment can be turned into a stream of slices, using the `MemorySegment::stream` method:\n+\n+```java\n+SequenceLayout seq = MemoryLayout.sequenceLayout(1_000_000, JAVA_INT);\n+SequenceLayout bulk_element = MemoryLayout.sequenceLayout(100, JAVA_INT);\n+\n+try (Arena arena = Arena.openShared()) {\n+    MemorySegment segment = MemorySegment.allocateNative(seq, arena.scope());\n+    int sum = segment.elements(bulk_element).parallel()\n+                       .mapToInt(slice -> {\n+                           int res = 0;\n+                           for (int i = 0; i < 100 ; i++) {\n+                               res += slice.getAtIndex(JAVA_INT, i);\n+                           }\n+                           return res;\n+                       }).sum();\n+}\n+```\n+\n+The `MemorySegment::elements` method takes an element layout and returns a new stream. The stream is built on top of a spliterator instance (see `MemorySegment::spliterator`) which splits the segment into chunks whose size match that of the provided layout. Here, we want to sum elements in an array which contains a million of elements; now, doing a parallel sum where each computation processes *exactly* one element would be inefficient, so instead we use a *bulk* element layout. The bulk element layout is a sequence layout containing a group of 100 elements — which should make it more amenable to parallel processing. Since we are using `Stream::parallel` to work on disjoint slices in parallel, here we use a *shared* arena, to ensure that the resulting segment can be accessed by multiple threads.\n+\n+### Accessing segments\n@@ -41,1 +98,1 @@\n-MemorySegment segment = MemorySement.allocateNative(10 * 4 * 2, MemorySession.openImplicit());\n+MemorySegment segment = MemorySement.allocateNative(10 * 4 * 2, SegmentScope.auto());\n@@ -52,15 +109,1 @@\n-Memory segments are pretty flexible when it comes to interacting with existing memory sources and APIs. For instance, it is possible to create a `ByteBuffer` *view* out of an existing memory segment, as follows:\n-\n-```java\n-IntBuffer intBuffer = segment.asByteBuffer().asIntBuffer();\n-Point[] values = new Point[10];\n-for (int i = 0 ; i < values.length ; i++) {\n-    int x = intBuffer.get(i * 2);\n-    int y = intBuffer.get((i * 2) + 1);\n-    values[i] = new Point(x, y);\n-}\n-```\n-\n-Creating buffer views out of existing segment is a crucial tool enabling interoperability with existing API (especially those dealing with I\/O) which might be expressed in terms of the ByteBuffer API.\n-\n-### Layouts and structured access\n+### Structured access\n@@ -68,1 +111,1 @@\n-Expressing byte offsets (as in the example above) can lead to code that is hard to read, and very fragile — as memory layout invariants are captured, implicitly, in the constants used to scale offsets. To address this issue, we add a *memory layout* API which allows clients to define memory layouts *programmatically*. For instance, the layout of the array used in the above example can be expressed using the following code <a href=\"#1\"><sup>1<\/sup><\/a>:\n+Expressing byte offsets (as in the example above) can lead to code that is hard to read, and very fragile — as memory layout invariants are captured, implicitly, in the constants used to scale offsets. To address this issue, clients can use a `MemoryLayout` to to describe the contents of a memory segment *programmatically*. For instance, the layout of the array used in the above example can be expressed using the following code <a href=\"#2\"><sup>2<\/sup><\/a>:\n@@ -79,1 +122,1 @@\n-That is, our layout is a repetition of 10 *struct* elements, each struct element containing two 32-bit values each. The advantage of defining a memory layout upfront, using an API, is that we can then query the layout — for instance we can compute the offset of the `y` coordinate in the 4th element of the `points` array:\n+That is, our layout is a repetition of 10 *struct* elements, each struct element containing two 32-bit values each. Once defined, a memory layout can be queried — for instance we can compute the offset of the `y` coordinate in the 4th element of the `points` array:\n@@ -90,1 +133,1 @@\n-MemorySegment segment = MemorySegment.allocateNative(points, MemorySession.openImplicit());\n+MemorySegment segment = MemorySegment.allocateNative(points, SegmentScope.auto());\n@@ -105,1 +148,1 @@\n-Note that memory access var handles (as any other var handle) are *strongly* typed; and to get maximum efficiency, it is generally necessary to introduce casts to make sure that the access coordinates match the expected types — in this case we have to cast `i` into a `long`; similarly, since the signature polymorphic method `VarHandle::get` notionally returns `Object` a cast is necessary to force the right return type the var handle operation <a href=\"#2\"><sup>2<\/sup><\/a>.\n+Note that memory access var handles (as any other var handle) are *strongly* typed; and to get maximum efficiency, it is generally necessary to introduce casts to make sure that the access coordinates match the expected types — in this case we have to cast `i` into a `long`; similarly, since the signature polymorphic method `VarHandle::get` notionally returns `Object` a cast is necessary to force the right return type the var handle operation <a href=\"#3\"><sup>3<\/sup><\/a>.\n@@ -109,120 +152,0 @@\n-### Deterministic deallocation\n-\n-In addition to spatial bounds, memory segments also feature temporal bounds as well as thread-confinement. In the examples shown so far, we have always used the API in its simpler form, leaving the runtime to handle details such as whether it was safe or not to reclaim memory associated with a given memory segment. But there are cases where this behavior is not desirable: consider the case where a large memory segment is mapped from a file (this is possible using `MemorySegment::map`); in this case, an application would probably prefer to deterministically release (e.g. unmap) the memory associated with this segment, to ensure that memory doesn't remain available for longer than in needs to (and therefore potentially impacting the performance of the application).\n-\n-Memory segments support deterministic deallocation, through an abstraction called `MemorySession`. A memory session models the lifecycle associated with one or more memory resources (in this document, by memory resources we mean mostly memory segments); a memory session has a state: it starts off in the *alive* state, which means that all the resources it manages can be safely accessed — and, at the user's request, it can be *closed*. After a memory session is closed, access to resources managed by that session is no longer allowed. Memory sessions implement the `AutoCloseable` interface, and can therefore be used with the *try-with-resources* construct, as demonstrated in the following code:\n-\n-```java\n-try (MemorySession session = MemorySession.openConfined()) {\n-    MemorySegment mapped = MemorySegment.map(Path.of(\"someFile\"), 0, 100000, MapMode.READ_WRITE, session);    \n-} \/\/ segment is unmapped here\n-```\n-\n-Here, we create a new *confined* memory session, which is then used when creating a mapped segment; this means that the lifecycle of the `mapped` segment is tied to that of the memory session, and that accessing the segment (e.g. dereference) *after* `session` has been closed will not be possible.\n-\n-As this example alludes to, memory sessions can come in many flavors: they can be *confined* (where access is restricted to the thread which created the session), *shared* <a href=\"#3\"><sup>3<\/sup><\/a> (where access can occur in any thread) and can be optionally associated with a `Cleaner` object (as in the case of `openImplicit`), which performs *implicit* deallocation when the memory session becomes *unreachable* (if the `close` method has not been called by the user). Memory sessions are very handy when managing the lifecycle of multiple resources:\n-\n-```java\n-try (MemorySession session = MemorySession.openConfined()) {\n-    MemorySegment segment1 = MemorySegment.allocateNative(100, session);\n-    MemorySegment segment2 = MemorySegment.allocateNative(100, session);\n-    ...\n-    MemorySegment segmentN = MemorySegment.allocateNative(100, session);\n-} \/\/ all segments are deallocated here\n-```\n-\n-Here we create another confined session, and then, inside the *try-with-resources* we use the session to create many segments; all such segments share the *same* memory session — meaning that when such session is closed, the memory associated with all these segments will be reclaimed at once.\n-\n-#### Challenges\n-\n-Working with deterministic deallocation is great in terms of achieving better control as to *when* memory resources are released. But deterministic deallocation present some unique challenges which we discuss here; some of these issues might look surprising, especially coming from a world where deallocation happens implicitly (as in the ByteBuffer API). Consider the following method:\n-\n-```java\n-void m() {\n-    MemorySegment segment = MemorySegment.allocateNative(MemorySession.openConfined());\n-    segment.set(JAVA_INT, 0, 42);\n-}\n-```\n-\n-This method creates a segment backed by a fresh confined memory session. But the session is not closed before the method returns. This means the off-heap memory associated with the native segment will never be released. In other words, we have created a *memory leak*. With power comes responsibility: clients must not forget to call the close method (unless they are working with a session backed by a `Cleaner` object, in which case the call will happen implicitly, of course).\n-\n-Another issue with deterministic deallocation is that it can sometimes be tricky to determine whether a certain access operation might fail or not. Consider the following method:\n-\n-```java\n-void accept(MemorySegment segment) {\n-   segment.setAtIndex(JAVA_INT, 0, 1);\n-   segment.setAtIndex(JAVA_INT, 1, 2);\n-}\n-```\n-\n-The first call to `setAtIndex` might fail, if the session associated to the segment has already been closed. But, if the segment is associated with a shared session, it might also be possible for the *second* call to fail (if some other thread has closed the session concurrently). To help clients running a sequence of operation against one or more segments in a more atomic fashion, the `MemorySession::whileAlive` method can be used:\n-\n-```java\n-void accept(MemorySegment segment) {\n-   segment.session().whileAlive(() -> {\n-       segment.setAtIndex(JAVA_INT, 0, 1);\n-       segment.setAtIndex(JAVA_INT, 1, 2);\n-   });\n-}\n-```\n-\n-Finally, when writing APIs returning memory segments, API authors might want to take extra caution so that the API private memory session is not leaked outside the API, through the memory segments generated by the API. Consider the following code:\n-\n-```java\n-class Allocator {\n-    private final MemorySession privateSession = MemorySession.openConfined();\n-    \n-    MemorySegment allocate(long byteSize) {\n-        return MemorySegment.allocateNative(byteSize, privateSession);\n-    }\n-}\n-```\n-\n-And now, consider the following client code:\n-\n-```java\n-Allocator allocator = new Allocator();\n-MemorySegment segment = allocator.allocate(100);\n-...\n-segment.session().close();\n-```\n-\n-The problem here is that the API is exposing its own memory session via the segment it returns; by doing so, clients can then access the session of the segments obtained from the API, and even *close* the session, thus releasing *all* the memory that has been allocated by the `Allocator` instance, even the memory associated with segments that the client knew nothing about. To help writing more robust APIs, the `MemorySession::asNonCloseable` method can be used, which obtain a *non-closeable* view of a given memory session:\n-\n-```java\n-class Allocator {\n-    private final MemorySession privateSession = MemorySession.openConfined();\n-    \n-    MemorySegment allocate(long byteSize) {\n-        return MemorySegment.allocateNative(byteSize, privateSession.asNonCloseable());\n-    }\n-}\n-```\n-\n-In the above example, we have tweaked the `Allocator::allocate` method so that it returns a segment associated with a non-closeable view of the private memory session. This means that clients of this method will no longer be able to call `MemorySession::close` on the returned segment.\n-\n-As we have seen in this session, deterministic deallocation, as most things in computer science, is a trade-off. More specifically, we are trading between predictability of deallocation and simplicity of API and user code. It is ultimately up to developers to pick the solution that works best for their use case. As a general (and rough!) rule of thumb, long-lived, shared memory resources might be better modelled using implicit memory sessions, whereas short-lived, thread-confined memory resources are often modelled using closeable memory sessions.\n-\n-### Streaming slices\n-\n-To process the contents of a memory segment in bulk, a memory segment can be turned into a stream of slices, using the `MemorySegment::stream` method:\n-\n-```java\n-SequenceLayout seq = MemoryLayout.sequenceLayout(1_000_000, JAVA_INT);\n-SequenceLayout bulk_element = MemoryLayout.sequenceLayout(100, JAVA_INT);\n-\n-try (MemorySession session = MemorySession.openShared()) {\n-    MemorySegment segment = MemorySegment.allocateNative(seq, session);\n-    int sum = segment.elements(bulk_element).parallel()\n-                       .mapToInt(slice -> {\n-                           int res = 0;\n-                           for (int i = 0; i < 100 ; i++) {\n-                               res += slice.getAtIndex(JAVA_INT, i);\n-                           }\n-                           return res;\n-                       }).sum();\n-}\n-```\n-\n-The `MemorySegment::elements` method takes an element layout and returns a new stream. The stream is built on top of a spliterator instance (see `MemorySegment::spliterator`) which splits the segment into chunks whose size match that of the provided layout. Here, we want to sum elements in an array which contains a million of elements; now, doing a parallel sum where each computation processes *exactly* one element would be inefficient, so instead we use a *bulk* element layout. The bulk element layout is a sequence layout containing a group of 100 elements — which should make it more amenable to parallel processing. Since we are using `Stream::parallel` to work on disjoint slices in parallel, here we use a *shared* memory session, to ensure that the resulting segment can be accessed by multiple threads.\n-\n@@ -231,1 +154,1 @@\n-We have seen in the previous sections how memory access var handles dramatically simplify user code when structured access is involved. While deriving memory access var handles from layout is the most convenient option, the Foreign Memory Access API also allows to create such memory access var handles in a standalone fashion, as demonstrated in the following code:\n+We have seen in the previous sections how memory access var handles dramatically simplify user code when structured access is involved. While deriving memory access var handles from layout is the most convenient option, the FFM API also allows to create such memory access var handles in a standalone fashion, as demonstrated in the following code:\n@@ -239,1 +162,1 @@\n-The attentive reader might have noted how rich the var handles returned by the layout API are, compared to the simple memory access var handle we have constructed here. How do we go from a simple access var handle that takes a byte offset to a var handle that can dereference a complex layout path? The answer is, by using var handle *combinators*. Developers familiar with the method handle API know how simpler method handles can be combined into more complex ones using the various combinator methods in the `MethodHandles` API. These methods allow, for instance, to insert (or bind) arguments into a target method handle, filter return values, permute arguments and much more.\n+The attentive reader might have noted how rich the var handles obtains from memory layouts are, compared to the simple memory access var handle we have constructed here. How do we go from a simple access var handle that takes a byte offset to a var handle that can dereference a complex layout path? The answer is, by using var handle *combinators*. Developers familiar with the method handles know how simpler method handles can be combined into more complex ones using the various combinator methods in the `MethodHandles` class. These methods allow, for instance, to insert (or bind) arguments into a target method handle, filter return values, permute arguments and much more.\n@@ -241,1 +164,1 @@\n-The Foreign Memory Access API adds a rich set of var handle combinators in the `MethodHandles` class; with these tools, developers can express var handle transformations such as:\n+The FFM API adds a rich set of var handle combinators in the `MethodHandles` class; with these tools, developers can express var handle transformations such as:\n@@ -256,1 +179,1 @@\n-We have been able to derive, from a basic memory access var handle, a new var handle that dereferences a segment at a given fixed offset. It is easy to see how other, richer, var handles obtained using the layout API can be constructed manually using the var handle combinator API.\n+We have been able to derive, from a basic memory access var handle, a new var handle that dereferences a segment at a given fixed offset. It is easy to see how other, richer, var handles obtained using a memory layout can also be constructed manually using the var handle combinators provided by the FFM API.\n@@ -260,1 +183,1 @@\n-The memory access API provides basic safety guarantees for all memory segments created using the API. More specifically, a memory dereference operation should either succeed, or result in a runtime exception — but, crucially, should never result in a VM crash, or, more subtly, in memory corruption occurring *outside* the region of memory associated with a memory segment. This is indeed the case, as all memory segments feature immutable *spatial bounds*, and, as we have seen, are associated with a memory session which make sure that segments cannot be dereferenced after their session has been closed, or, in case of a confined session, that segments cannot be dereferenced from a thread other than the one which created the session.\n+The FFM API provides basic safety guarantees for all memory segments created using the API. More specifically, a memory dereference operation should either succeed, or result in a runtime exception — but, crucially, should never result in a VM crash, or, more subtly, in memory corruption occurring *outside* the region of memory associated with a memory segment. This is indeed the case, as all memory segments feature immutable *spatial bounds*, and, as we have seen, are associated with a segment scope which make sure that segments cannot be dereferenced after their backing region of memory have been deallocated.\n@@ -264,1 +187,1 @@\n-The ByteBuffer API allows such a move, through a JNI [method](https:\/\/docs.oracle.com\/javase\/8\/docs\/technotes\/guides\/jni\/spec\/functions.html#NewDirectByteBuffer), namely `NewDirectByteBuffer`. This native method can be used to wrap a long address in a fresh direct byte buffer instance which is then returned to unsuspecting Java code.\n+The `ByteBuffer` API allows such a move, through a JNI [method](https:\/\/docs.oracle.com\/javase\/8\/docs\/technotes\/guides\/jni\/spec\/functions.html#NewDirectByteBuffer), namely `NewDirectByteBuffer`. This native method can be used to wrap a long address in a fresh direct byte buffer instance which is then returned to unsuspecting Java code.\n@@ -266,1 +189,1 @@\n-Memory segments provide a similar capability — that is, given an address (which might have been obtained through some native calls), it is possible to wrap a segment around it, with given spatial bounds and memory session, as follows:\n+Memory segments provide a similar capability — that is, given an address (which might have been obtained through some native calls), it is possible to wrap a segment around it, with given spatial bounds and segment scope, as follows:\n@@ -269,3 +192,3 @@\n-try (MemorySession session = MemorySession.openShared()) {\n-    MemoryAddress addr = MemoryAddress.ofLong(someLongAddr);\n-    var unsafeSegment = MemorySegment.ofAddress(addr, 10, session);\n+try (Arena arena = Arena.openShared()) {\n+    long addr = ...\n+    var unsafeSegment = MemorySegment.ofAddress(addr, 10, arena.scope());\n@@ -276,1 +199,1 @@\n-The above code creates a shared session and then, inside the *try-with-resources* it creates a *new* unsafe segment from a given address; the size of the segment is 10 bytes, and the unsafe segment is associated with the current shared session. This means that the unsafe segment cannot be dereferenced after the shared session has been closed.\n+The above code creates a shared arena and then, inside the *try-with-resources* it creates a *new* unsafe segment from a given address; the size of the segment is 10 bytes, and the unsafe segment is associated with the current shared arena. This means that the unsafe segment cannot be dereferenced after the shared arena has been closed.\n@@ -278,1 +201,1 @@\n-Of course, segments created this way are completely *unsafe*. There is no way for the runtime to verify that the provided address indeed points to a valid memory location, or that the size of the memory region pointed to by `addr` is indeed 10 bytes. Similarly, there are no guarantees that the underlying memory region associated with `addr` will not be deallocated *prior* to the call to `MemorySession::close`.\n+Of course, segments created this way are completely *unsafe*. There is no way for the runtime to verify that the provided address indeed points to a valid memory location, or that the size of the memory region pointed to by `addr` is indeed 10 bytes. Similarly, there are no guarantees that the underlying memory region associated with `addr` will not be deallocated *prior* to the call to `Arena::close`.\n@@ -280,1 +203,1 @@\n-For these reasons, `MemorySegment::ofAddress` is a *restricted method* in the Foreign Memory Access API. The first time a restricted method is invoked, a runtime warning is generated. Developers can get rid of warnings by specifying the set of modules that are allowed to call restricted methods. This is done by specifying the option `--enable-native-access=M`, where `M` is a module name. Multiple module names can be specified in a comma-separated list, where the special name `ALL-UNNAMED` is used to enable restricted access for all code on the class path. If the `--enable-native-access` option is specified, any attempt to call restricted operations from a module not listed in the option will fail with a runtime exception.\n+For these reasons, `MemorySegment::ofAddress` is a *restricted method* in the FFM API. The first time a restricted method is invoked, a runtime warning is generated. Developers can get rid of warnings by specifying the set of modules that are allowed to call restricted methods. This is done by specifying the option `--enable-native-access=M`, where `M` is a module name. Multiple module names can be specified in a comma-separated list, where the special name `ALL-UNNAMED` is used to enable restricted access for all code on the class path. If the `--enable-native-access` option is specified, any attempt to call restricted operations from a module not listed in the option will fail with a runtime exception.\n@@ -282,3 +205,3 @@\n-* <a id=\"1\"\/>(<sup>1<\/sup>):<small> In general, deriving a complete layout from a C `struct` declaration is no trivial matter, and it's one of those areas where tooling can help greatly.<\/small>\n-* <a id=\"2\"\/>(<sup>2<\/sup>):<small> Clients can enforce stricter type checking when interacting with `VarHandle` instances, by obtaining an *exact* var handle, using the `VarHandle::withInvokeExactBehavior` method.<\/small>\n-* <a id=\"3\"\/>(<sup>3<\/sup>):<small> Shared sessions rely on VM thread-local handshakes (JEP [312](https:\/\/openjdk.java.net\/jeps\/312)) to implement lock-free, safe, shared memory access; that is, when it comes to memory access, there should no difference in performance between a shared segment and a confined segment. On the other hand, `MemorySession::close` might be slower on shared sessions than on confined ones.<\/small>\n+* <a id=\"1\"\/>(<sup>1<\/sup>):<small> Shared arenas rely on VM thread-local handshakes (JEP [312](https:\/\/openjdk.java.net\/jeps\/312)) to implement lock-free, safe, shared memory access; that is, when it comes to memory access, there should no difference in performance between a shared segment and a confined segment. On the other hand, `Arena::close` might be slower on shared arenas than on confined ones.<\/small>\n+* <a id=\"2\"\/>(<sup>2<\/sup>):<small> In general, deriving a complete layout from a C `struct` declaration is no trivial matter, and it's one of those areas where tooling can help greatly.<\/small>\n+* <a id=\"3\"\/>(<sup>3<\/sup>):<small> Clients can enforce stricter type checking when interacting with `VarHandle` instances, by obtaining an *exact* var handle, using the `VarHandle::withInvokeExactBehavior` method.<\/small>\n","filename":"doc\/panama_memaccess.md","additions":87,"deletions":164,"binary":false,"changes":251,"status":"modified"}]}