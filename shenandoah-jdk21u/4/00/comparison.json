{"files":[{"patch":"@@ -177,4 +177,0 @@\n-  } else {\n-    \/\/ We are going to skip evacuation and update refs because we reclaimed\n-    \/\/ sufficient amounts of immediate garbage.\n-    heap->shenandoah_policy()->record_abbreviated_cycle();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahGenerationalHeuristics.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -49,2 +49,0 @@\n-  _degenerated_cycles_in_a_row(0),\n-  _successful_cycles_in_a_row(0),\n@@ -156,4 +154,0 @@\n-  } else {\n-    \/\/ We are going to skip evacuation and update refs because we reclaimed\n-    \/\/ sufficient amounts of immediate garbage.\n-    heap->shenandoah_policy()->record_abbreviated_cycle();\n@@ -214,1 +208,1 @@\n-  return _degenerated_cycles_in_a_row <= ShenandoahFullGCThreshold;\n+  return ShenandoahHeap::heap()->shenandoah_policy()->consecutive_degenerated_gc_count() <= ShenandoahFullGCThreshold;\n@@ -235,2 +229,0 @@\n-  _degenerated_cycles_in_a_row = 0;\n-  _successful_cycles_in_a_row++;\n@@ -247,3 +239,0 @@\n-  _degenerated_cycles_in_a_row++;\n-  _successful_cycles_in_a_row = 0;\n-\n@@ -254,3 +243,0 @@\n-  _degenerated_cycles_in_a_row = 0;\n-  _successful_cycles_in_a_row++;\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahHeuristics.cpp","additions":1,"deletions":15,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -100,3 +100,0 @@\n-  uint _degenerated_cycles_in_a_row;\n-  uint _successful_cycles_in_a_row;\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahHeuristics.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -49,0 +49,12 @@\n+\/\/ sort by increasing index\n+int ShenandoahOldHeuristics::compare_by_index(RegionData a, RegionData b) {\n+  if (a._region->index() < b._region->index()) {\n+    return -1;\n+  } else if (a._region->index() > b._region->index()) {\n+    return 1;\n+  } else {\n+    \/\/ quicksort may compare to self during search for pivot\n+    return 0;\n+  }\n+}\n+\n@@ -115,0 +127,1 @@\n+    assert(r->is_regular(), \"There should be no humongous regions in the set of mixed-evac candidates\");\n@@ -196,1 +209,1 @@\n-      _old_generation->transition_to(ShenandoahOldGeneration::WAITING_FOR_FILL);\n+      _old_generation->transition_to(ShenandoahOldGeneration::FILLING);\n@@ -198,1 +211,1 @@\n-      _old_generation->transition_to(ShenandoahOldGeneration::IDLE);\n+      _old_generation->transition_to(ShenandoahOldGeneration::WAITING_FOR_BOOTSTRAP);\n@@ -205,1 +218,1 @@\n-    \/\/ (pinned) regions parseable.\n+    \/\/ (pinned) regions parsable.\n@@ -208,1 +221,1 @@\n-      _old_generation->transition_to(ShenandoahOldGeneration::WAITING_FOR_FILL);\n+      _old_generation->transition_to(ShenandoahOldGeneration::FILLING);\n@@ -318,1 +331,2 @@\n-    if (region->is_regular() || region->is_pinned()) {\n+    \/\/ Only place regular regions into the candidate set\n+    if (region->is_regular()) {\n@@ -332,0 +346,1 @@\n+        assert(!region->is_pinned(), \"Pinned region should have live (pinned) objects.\");\n@@ -358,0 +373,1 @@\n+\n@@ -393,0 +409,45 @@\n+  size_t defrag_count = 0;\n+  if (cand_idx > _last_old_collection_candidate) {\n+    \/\/ Above, we have added into the set of mixed-evacuation candidates all old-gen regions for which the live memory\n+    \/\/ that they contain is below a particular old-garbage threshold.  Regions that were not selected for the collection\n+    \/\/ set hold enough live memory that it is not considered efficient (by \"garbage-first standards\") to compact these\n+    \/\/ at the current time.\n+    \/\/\n+    \/\/ However, if any of these regions that were rejected from the collection set reside within areas of memory that\n+    \/\/ might interfere with future humongous allocation requests, we will prioritize them for evacuation at this time.\n+    \/\/ Humongous allocations target the bottom of the heap.  We want old-gen regions to congregate at the top of the\n+    \/\/ heap.\n+    \/\/\n+    \/\/ Sort the regions that were initially rejected from the collection set in order of index.  This allows us to\n+    \/\/ focus our attention on the regions that have low index value (i.e. the old-gen regions at the bottom of the heap).\n+    QuickSort::sort<RegionData>(candidates + _last_old_collection_candidate, cand_idx - _last_old_collection_candidate,\n+                                compare_by_index, false);\n+\n+    size_t first_unselected_old_region = candidates[_last_old_collection_candidate]._region->index();\n+    size_t last_unselected_old_region = candidates[cand_idx - 1]._region->index();\n+    size_t span_of_uncollected_regions = 1 + last_unselected_old_region - first_unselected_old_region;\n+    size_t total_uncollected_old_regions = cand_idx - _last_old_collection_candidate;\n+\n+    \/\/ Add no more than 1\/8 of the existing old-gen regions to the set of mixed evacuation candidates.\n+    const int MAX_FRACTION_OF_HUMONGOUS_DEFRAG_REGIONS = 8;\n+    size_t bound_on_additional_regions = cand_idx \/ MAX_FRACTION_OF_HUMONGOUS_DEFRAG_REGIONS;\n+\n+    \/\/ The heuristic old_is_fragmented trigger may be seeking to achieve up to 7\/8 density.  Allow ourselves to overshoot\n+    \/\/ that target (at 15\/16) so we will not have to do another defragmenting old collection right away.\n+    while ((defrag_count < bound_on_additional_regions) &&\n+           (total_uncollected_old_regions < 15 * span_of_uncollected_regions \/ 16)) {\n+      ShenandoahHeapRegion* r = candidates[_last_old_collection_candidate]._region;\n+      assert (r->is_regular(), \"Only regular regions are in the candidate set\");\n+      size_t region_garbage = candidates[_last_old_collection_candidate]._region->garbage();\n+      size_t region_free = r->free();\n+      candidates_garbage += region_garbage;\n+      unfragmented += region_free;\n+      defrag_count++;\n+      _last_old_collection_candidate++;\n+\n+      \/\/ We now have one fewer uncollected regions, and our uncollected span shrinks because we have removed its first region.\n+      total_uncollected_old_regions--;\n+      span_of_uncollected_regions = 1 + last_unselected_old_region - candidates[_last_old_collection_candidate]._region->index();\n+    }\n+  }\n+\n@@ -401,2 +462,2 @@\n-               \"consolidated with free: \" SIZE_FORMAT \"%s, over \" SIZE_FORMAT \" regions, \"\n-               \"Old-Gen Immediate Garbage: \" SIZE_FORMAT \"%s over \" SIZE_FORMAT \" regions.\",\n+               \"consolidated with free: \" SIZE_FORMAT \"%s, over \" SIZE_FORMAT \" regions (humongous defragmentation: \"\n+               SIZE_FORMAT \" regions), Old-Gen Immediate Garbage: \" SIZE_FORMAT \"%s over \" SIZE_FORMAT \" regions.\",\n@@ -404,1 +465,2 @@\n-               byte_size_in_proper_unit(unfragmented),        proper_unit_for_byte_size(unfragmented), old_candidates,\n+               byte_size_in_proper_unit(unfragmented),        proper_unit_for_byte_size(unfragmented),\n+               old_candidates, defrag_count,\n@@ -408,1 +470,1 @@\n-    _old_generation->transition_to(ShenandoahOldGeneration::WAITING_FOR_EVAC);\n+    _old_generation->transition_to(ShenandoahOldGeneration::EVACUATING);\n@@ -410,1 +472,1 @@\n-    _old_generation->transition_to(ShenandoahOldGeneration::WAITING_FOR_FILL);\n+    _old_generation->transition_to(ShenandoahOldGeneration::FILLING);\n@@ -412,1 +474,1 @@\n-    _old_generation->transition_to(ShenandoahOldGeneration::IDLE);\n+    _old_generation->transition_to(ShenandoahOldGeneration::WAITING_FOR_BOOTSTRAP);\n@@ -479,5 +541,0 @@\n-void ShenandoahOldHeuristics::trigger_old_has_grown() {\n-  _growth_trigger = true;\n-}\n-\n-\n@@ -500,0 +557,1 @@\n+  ShenandoahHeap* heap = ShenandoahHeap::heap();\n@@ -501,1 +559,0 @@\n-    ShenandoahHeap* heap = ShenandoahHeap::heap();\n@@ -510,1 +567,0 @@\n-  ShenandoahHeap* heap = ShenandoahHeap::heap();\n@@ -514,0 +570,2 @@\n+\n+    \/\/ used_regions includes humongous regions\n@@ -516,0 +574,5 @@\n+\n+    size_t first_old_region, last_old_region;\n+    double density;\n+    get_fragmentation_trigger_reason_for_log_message(density, first_old_region, last_old_region);\n+    size_t span_of_old_regions = (last_old_region >= first_old_region)? last_old_region + 1 - first_old_region: 0;\n@@ -517,1 +580,1 @@\n-    double percent = percent_of(fragmented_free, used_regions_size);\n+\n@@ -519,2 +582,4 @@\n-                 SIZE_FORMAT \"%s available bytes spread between \" SIZE_FORMAT \" regions (%.1f%% free)\",\n-                 byte_size_in_proper_unit(fragmented_free), proper_unit_for_byte_size(fragmented_free), used_regions, percent);\n+                 SIZE_FORMAT \"%s available bytes spread between range spanned from \"\n+                 SIZE_FORMAT \" to \" SIZE_FORMAT \" (\" SIZE_FORMAT \"), density: %.1f%%\",\n+                 byte_size_in_proper_unit(fragmented_free), proper_unit_for_byte_size(fragmented_free),\n+                 first_old_region, last_old_region, span_of_old_regions, density * 100);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahOldHeuristics.cpp","additions":86,"deletions":21,"binary":false,"changes":107,"status":"modified"},{"patch":"@@ -97,0 +97,5 @@\n+  \/\/ Motivation for a fragmentation_trigger\n+  double _fragmentation_density;\n+  size_t _fragmentation_first_old_region;\n+  size_t _fragmentation_last_old_region;\n+\n@@ -105,0 +110,2 @@\n+  static int compare_by_index(RegionData a, RegionData b);\n+\n@@ -156,2 +163,14 @@\n-  void trigger_old_is_fragmented() { _fragmentation_trigger = true; }\n-  void trigger_old_has_grown();\n+\n+  inline void trigger_old_is_fragmented(double density, size_t first_old_index, size_t last_old_index) {\n+    _fragmentation_trigger = true;\n+    _fragmentation_density = density;\n+    _fragmentation_first_old_region = first_old_index;\n+    _fragmentation_last_old_region = last_old_index;\n+  }\n+  void trigger_old_has_grown() { _growth_trigger = true; }\n+\n+  inline void get_fragmentation_trigger_reason_for_log_message(double &density, size_t &first_index, size_t &last_index) {\n+    density = _fragmentation_density;\n+    first_index = _fragmentation_first_old_region;\n+    last_index = _fragmentation_last_old_region;\n+  }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahOldHeuristics.hpp","additions":21,"deletions":2,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -33,0 +33,6 @@\n+  if (ShenandoahGenerationalMinTenuringAge > ShenandoahGenerationalMaxTenuringAge) {\n+    vm_exit_during_initialization(\n+      err_msg(\"ShenandoahGenerationalMinTenuringAge=\" SIZE_FORMAT\n+              \" should be no more than ShenandoahGenerationalMaxTenuringAge=\" SIZE_FORMAT,\n+              ShenandoahGenerationalMinTenuringAge, ShenandoahGenerationalMaxTenuringAge));\n+  }\n@@ -223,0 +229,2 @@\n+\/\/ Currently Shenandoah{Min,Max}TenuringAge have a floor of 1 because we\n+\/\/ aren't set up to promote age 0 objects.\n@@ -224,0 +232,7 @@\n+  \/\/ Dispose of the extremal cases early so the loop below\n+  \/\/ is less fragile.\n+  if (ShenandoahGenerationalMaxTenuringAge == ShenandoahGenerationalMinTenuringAge) {\n+    return ShenandoahGenerationalMaxTenuringAge; \/\/ Any value in [1,16]\n+  }\n+  assert(ShenandoahGenerationalMinTenuringAge < ShenandoahGenerationalMaxTenuringAge, \"Error\");\n+\n@@ -240,1 +255,1 @@\n-  uint upper_bound = ShenandoahGenerationalMaxTenuringAge - 1;\n+  uint upper_bound = ShenandoahGenerationalMaxTenuringAge;\n@@ -247,0 +262,4 @@\n+  upper_bound = MIN2(upper_bound, markWord::max_age);\n+\n+  const uint lower_bound = MAX2((uint)ShenandoahGenerationalMinTenuringAge, (uint)1);\n+\n@@ -248,1 +267,1 @@\n-  for (uint i = upper_bound; i > MAX2((uint)ShenandoahGenerationalMinTenuringAge, (uint)0); i--) {\n+  for (uint i = upper_bound; i >= lower_bound; i--) {\n@@ -250,0 +269,1 @@\n+    assert(i <= markWord::max_age, \"Index i would overflow\");\n@@ -254,8 +274,11 @@\n-    \/\/ We ignore any cohorts that had a very low population count, or\n-    \/\/ that have a lower mortality rate than we care to age in young; these\n-    \/\/ cohorts are considered eligible for tenuring when all older\n-    \/\/ cohorts are.\n-    if (prev_pop < ShenandoahGenerationalTenuringCohortPopulationThreshold ||\n-        mr < ShenandoahGenerationalTenuringMortalityRateThreshold) {\n-      tenuring_threshold = i;\n-      continue;\n+    if (prev_pop > ShenandoahGenerationalTenuringCohortPopulationThreshold &&\n+        mr > ShenandoahGenerationalTenuringMortalityRateThreshold) {\n+      \/\/ This is the oldest cohort that has high mortality.\n+      \/\/ We ignore any cohorts that had a very low population count, or\n+      \/\/ that have a lower mortality rate than we care to age in young; these\n+      \/\/ cohorts are considered eligible for tenuring when all older\n+      \/\/ cohorts are. We return the next higher age as the tenuring threshold\n+      \/\/ so that we do not prematurely promote objects of this age.\n+      assert(tenuring_threshold == i+1 || tenuring_threshold == upper_bound, \"Error\");\n+      assert(tenuring_threshold >= lower_bound && tenuring_threshold <= upper_bound, \"Error\");\n+      return tenuring_threshold;\n@@ -263,1 +286,3 @@\n-    return tenuring_threshold;\n+    \/\/ Remember that we passed over this cohort, looking for younger cohorts\n+    \/\/ showing high mortality. We want to tenure cohorts of this age.\n+    tenuring_threshold = i;\n@@ -265,0 +290,1 @@\n+  assert(tenuring_threshold >= lower_bound && tenuring_threshold <= upper_bound, \"Error\");\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahAgeCensus.cpp","additions":37,"deletions":11,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -36,1 +36,2 @@\n-  _abbreviated_cycles(0),\n+  _abbreviated_concurrent_gcs(0),\n+  _abbreviated_degenerated_gcs(0),\n@@ -42,0 +43,1 @@\n+  _consecutive_degenerated_gcs(0),\n@@ -84,1 +86,1 @@\n-  ShenandoahHeap::heap()->record_upgrade_to_full();\n+  _consecutive_degenerated_gcs = 0;\n@@ -88,6 +90,4 @@\n-void ShenandoahCollectorPolicy::record_success_concurrent(bool is_young) {\n-  if (is_young) {\n-    _consecutive_young_gcs++;\n-  } else {\n-    _consecutive_young_gcs = 0;\n-  }\n+void ShenandoahCollectorPolicy::record_success_concurrent(bool is_young, bool is_abbreviated) {\n+  update_young(is_young);\n+\n+  _consecutive_degenerated_gcs = 0;\n@@ -95,0 +95,3 @@\n+  if (is_abbreviated) {\n+    _abbreviated_concurrent_gcs++;\n+  }\n@@ -101,4 +104,0 @@\n-void ShenandoahCollectorPolicy::record_abbreviated_cycle() {\n-  _abbreviated_cycles++;\n-}\n-\n@@ -115,1 +114,11 @@\n-void ShenandoahCollectorPolicy::record_success_degenerated(bool is_young) {\n+void ShenandoahCollectorPolicy::record_success_degenerated(bool is_young, bool is_abbreviated) {\n+  update_young(is_young);\n+\n+  _success_degenerated_gcs++;\n+  _consecutive_degenerated_gcs++;\n+  if (is_abbreviated) {\n+    _abbreviated_degenerated_gcs++;\n+  }\n+}\n+\n+void ShenandoahCollectorPolicy::update_young(bool is_young) {\n@@ -121,1 +130,0 @@\n-  _success_degenerated_gcs++;\n@@ -125,0 +133,1 @@\n+  _consecutive_degenerated_gcs = 0;\n@@ -145,1 +154,0 @@\n-\n@@ -154,3 +162,6 @@\n-  out->print_cr(SIZE_FORMAT_W(5) \" Successful Concurrent GCs\",         _success_concurrent_gcs);\n-  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" invoked explicitly\",           _explicit_concurrent);\n-  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" invoked implicitly\",           _implicit_concurrent);\n+  size_t completed_gcs = _success_full_gcs + _success_degenerated_gcs + _success_concurrent_gcs + _success_old_gcs;\n+  out->print_cr(SIZE_FORMAT_W(5) \" Completed GCs\", completed_gcs);\n+  out->print_cr(SIZE_FORMAT_W(5) \" Successful Concurrent GCs (%.2f%%)\",  _success_concurrent_gcs, percent_of(_success_concurrent_gcs, completed_gcs));\n+  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" invoked explicitly (%.2f%%)\",    _explicit_concurrent, percent_of(_explicit_concurrent, _success_concurrent_gcs));\n+  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" invoked implicitly (%.2f%%)\",    _implicit_concurrent, percent_of(_implicit_concurrent, _success_concurrent_gcs));\n+  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" abbreviated (%.2f%%)\",           _abbreviated_concurrent_gcs, percent_of(_abbreviated_concurrent_gcs, _success_concurrent_gcs));\n@@ -159,4 +170,6 @@\n-  out->print_cr(SIZE_FORMAT_W(5) \" Completed Old GCs\",                 _success_old_gcs);\n-  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" mixed\",                        _mixed_gcs);\n-  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" interruptions\",                _interrupted_old_gcs);\n-  out->cr();\n+  if (ShenandoahHeap::heap()->mode()->is_generational()) {\n+    out->print_cr(SIZE_FORMAT_W(5) \" Completed Old GCs (%.2f%%)\",        _success_old_gcs, percent_of(_success_old_gcs, completed_gcs));\n+    out->print_cr(\"  \" SIZE_FORMAT_W(5) \" mixed\",                        _mixed_gcs);\n+    out->print_cr(\"  \" SIZE_FORMAT_W(5) \" interruptions\",                _interrupted_old_gcs);\n+    out->cr();\n+  }\n@@ -164,2 +177,5 @@\n-  out->print_cr(SIZE_FORMAT_W(5) \" Degenerated GCs\",                   _success_degenerated_gcs);\n-  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" caused by allocation failure\", _alloc_failure_degenerated);\n+  size_t degenerated_gcs = _alloc_failure_degenerated_upgrade_to_full + _success_degenerated_gcs;\n+  out->print_cr(SIZE_FORMAT_W(5) \" Degenerated GCs (%.2f%%)\", degenerated_gcs, percent_of(degenerated_gcs, completed_gcs));\n+  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" upgraded to Full GC (%.2f%%)\",          _alloc_failure_degenerated_upgrade_to_full, percent_of(_alloc_failure_degenerated_upgrade_to_full, degenerated_gcs));\n+  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" caused by allocation failure (%.2f%%)\", _alloc_failure_degenerated, percent_of(_alloc_failure_degenerated, degenerated_gcs));\n+  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" abbreviated (%.2f%%)\",                  _abbreviated_degenerated_gcs, percent_of(_abbreviated_degenerated_gcs, degenerated_gcs));\n@@ -172,4 +188,0 @@\n-  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" upgraded to Full GC\",          _alloc_failure_degenerated_upgrade_to_full);\n-  out->cr();\n-\n-  out->print_cr(SIZE_FORMAT_W(5) \" Abbreviated GCs\",                   _abbreviated_cycles);\n@@ -178,5 +190,5 @@\n-  out->print_cr(SIZE_FORMAT_W(5) \" Full GCs\",                          _success_full_gcs + _alloc_failure_degenerated_upgrade_to_full);\n-  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" invoked explicitly\",           _explicit_full);\n-  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" invoked implicitly\",           _implicit_full);\n-  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" caused by allocation failure\", _alloc_failure_full);\n-  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" upgraded from Degenerated GC\", _alloc_failure_degenerated_upgrade_to_full);\n+  out->print_cr(SIZE_FORMAT_W(5) \" Full GCs (%.2f%%)\",                          _success_full_gcs, percent_of(_success_full_gcs, completed_gcs));\n+  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" invoked explicitly (%.2f%%)\",           _explicit_full, percent_of(_explicit_full, _success_full_gcs));\n+  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" invoked implicitly (%.2f%%)\",           _implicit_full, percent_of(_implicit_full, _success_full_gcs));\n+  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" caused by allocation failure (%.2f%%)\", _alloc_failure_full, percent_of(_alloc_failure_full, _success_full_gcs));\n+  out->print_cr(\"  \" SIZE_FORMAT_W(5) \" upgraded from Degenerated GC (%.2f%%)\", _alloc_failure_degenerated_upgrade_to_full, percent_of(_alloc_failure_degenerated_upgrade_to_full, _success_full_gcs));\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahCollectorPolicy.cpp","additions":45,"deletions":33,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -44,1 +44,2 @@\n-  size_t _abbreviated_cycles;\n+  size_t _abbreviated_concurrent_gcs;\n+  size_t _abbreviated_degenerated_gcs;\n@@ -51,0 +52,1 @@\n+  uint _consecutive_degenerated_gcs;\n@@ -64,0 +66,1 @@\n+\n@@ -72,2 +75,2 @@\n-  void record_abbreviated_cycle();\n-  void record_success_concurrent(bool is_young);\n+\n+  void record_success_concurrent(bool is_young, bool is_abbreviated);\n@@ -76,1 +79,1 @@\n-  void record_success_degenerated(bool is_young);\n+  void record_success_degenerated(bool is_young, bool is_abbreviated);\n@@ -102,0 +105,7 @@\n+\n+  inline size_t consecutive_degenerated_gc_count() const {\n+    return _consecutive_degenerated_gcs;\n+  }\n+\n+private:\n+  void update_young(bool is_young);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahCollectorPolicy.hpp","additions":14,"deletions":4,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -106,1 +106,0 @@\n-  heap->start_conc_gc();\n@@ -174,0 +173,2 @@\n+    \/\/ TODO: Not sure there is value in logging free-set status right here.  Note that whenever the free set is rebuilt,\n+    \/\/ it logs the newly rebuilt status.\n@@ -383,0 +384,2 @@\n+  heap->try_inject_alloc_failure();\n+\n@@ -384,3 +387,4 @@\n-  static const char* msg = \"Concurrent reset\";\n-  ShenandoahConcurrentPhase gc_phase(msg, ShenandoahPhaseTimings::conc_reset);\n-  EventMark em(\"%s\", msg);\n+  {\n+    static const char* msg = \"Concurrent reset\";\n+    ShenandoahConcurrentPhase gc_phase(msg, ShenandoahPhaseTimings::conc_reset);\n+    EventMark em(\"%s\", msg);\n@@ -388,3 +392,5 @@\n-  ShenandoahWorkerScope scope(heap->workers(),\n-                              ShenandoahWorkerPolicy::calc_workers_for_conc_reset(),\n-                              \"concurrent reset\");\n+    ShenandoahWorkerScope scope(heap->workers(),\n+                                ShenandoahWorkerPolicy::calc_workers_for_conc_reset(),\n+                                msg);\n+    op_reset();\n+  }\n@@ -392,2 +398,10 @@\n-  heap->try_inject_alloc_failure();\n-  op_reset();\n+  if (_do_old_gc_bootstrap) {\n+    static const char* msg = \"Concurrent reset (OLD)\";\n+    ShenandoahConcurrentPhase gc_phase(msg, ShenandoahPhaseTimings::conc_reset_old);\n+    ShenandoahWorkerScope scope(ShenandoahHeap::heap()->workers(),\n+                                ShenandoahWorkerPolicy::calc_workers_for_conc_reset(),\n+                                msg);\n+    EventMark em(\"%s\", msg);\n+\n+    heap->old_generation()->prepare_gc();\n+  }\n@@ -1267,1 +1281,6 @@\n-    ShenandoahMarkingContext *ctx = heap->complete_marking_context();\n+    \/\/ If the cycle was shortened for having enough immediate garbage, this could be\n+    \/\/ the last GC safepoint before concurrent marking of old resumes. We must be sure\n+    \/\/ that old mark threads don't see any pointers to garbage in the SATB buffers.\n+    if (heap->is_concurrent_old_mark_in_progress()) {\n+      heap->transfer_old_pointers_from_satb();\n+    }\n@@ -1269,0 +1288,1 @@\n+    ShenandoahMarkingContext *ctx = heap->complete_marking_context();\n@@ -1300,1 +1320,1 @@\n-    SHENANDOAH_RETURN_EVENT_MESSAGE(heap, _generation->type(), \"Pause Init Mark\", \" (unload classes)\");\n+    SHENANDOAH_RETURN_EVENT_MESSAGE(_generation->type(), \"Pause Init Mark\", \" (unload classes)\");\n@@ -1302,1 +1322,1 @@\n-    SHENANDOAH_RETURN_EVENT_MESSAGE(heap, _generation->type(), \"Pause Init Mark\", \"\");\n+    SHENANDOAH_RETURN_EVENT_MESSAGE(_generation->type(), \"Pause Init Mark\", \"\");\n@@ -1312,1 +1332,1 @@\n-    SHENANDOAH_RETURN_EVENT_MESSAGE(heap, _generation->type(), \"Pause Final Mark\", \" (unload classes)\");\n+    SHENANDOAH_RETURN_EVENT_MESSAGE(_generation->type(), \"Pause Final Mark\", \" (unload classes)\");\n@@ -1314,1 +1334,1 @@\n-    SHENANDOAH_RETURN_EVENT_MESSAGE(heap, _generation->type(), \"Pause Final Mark\", \"\");\n+    SHENANDOAH_RETURN_EVENT_MESSAGE(_generation->type(), \"Pause Final Mark\", \"\");\n@@ -1323,1 +1343,1 @@\n-    SHENANDOAH_RETURN_EVENT_MESSAGE(heap, _generation->type(), \"Concurrent marking\", \" (unload classes)\");\n+    SHENANDOAH_RETURN_EVENT_MESSAGE(_generation->type(), \"Concurrent marking\", \" (unload classes)\");\n@@ -1325,1 +1345,1 @@\n-    SHENANDOAH_RETURN_EVENT_MESSAGE(heap, _generation->type(), \"Concurrent marking\", \"\");\n+    SHENANDOAH_RETURN_EVENT_MESSAGE(_generation->type(), \"Concurrent marking\", \"\");\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahConcurrentGC.cpp","additions":36,"deletions":16,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -120,0 +120,1 @@\n+    bool humongous_alloc_failure_pending = _humongous_alloc_failure_gc.is_set();\n@@ -157,2 +158,3 @@\n-      \/\/ Do not bother with degenerated cycle if old generation evacuation failed\n-      if (ShenandoahDegeneratedGC && heuristics->should_degenerate_cycle() && !old_gen_evacuation_failed) {\n+      \/\/ Do not bother with degenerated cycle if old generation evacuation failed or if humongous allocation failed\n+      if (ShenandoahDegeneratedGC && heuristics->should_degenerate_cycle() &&\n+          !old_gen_evacuation_failed && !humongous_alloc_failure_pending) {\n@@ -163,0 +165,7 @@\n+        \/\/ TODO: if humongous_alloc_failure_pending, there might be value in trying a \"compacting\" degen before\n+        \/\/ going all the way to full.  But it's a lot of work to implement this, and it may not provide value.\n+        \/\/ A compacting degen can move young regions around without doing full old-gen mark (relying upon the\n+        \/\/ remembered set scan), so it might be faster than a full gc.\n+        \/\/\n+        \/\/ Longer term, think about how to defragment humongous memory concurrently.\n+\n@@ -244,0 +253,1 @@\n+        heap->set_unload_classes(false);\n@@ -293,4 +303,1 @@\n-          if (!service_stw_degenerated_cycle(cause, degen_point)) {\n-            \/\/ The degenerated GC was upgraded to a Full GC\n-            generation = select_global_generation();\n-          }\n+          service_stw_degenerated_cycle(cause, degen_point);\n@@ -352,1 +359,0 @@\n-        assert(generation == select_global_generation(), \"Only unload classes during GLOBAL cycle\");\n@@ -509,5 +515,0 @@\n-    case ShenandoahOldGeneration::WAITING_FOR_FILL:\n-    case ShenandoahOldGeneration::IDLE: {\n-      assert(!heap->is_concurrent_old_mark_in_progress(), \"Old already in progress\");\n-      assert(old_generation->task_queues()->is_empty(), \"Old mark queues should be empty\");\n-    }\n@@ -516,2 +517,1 @@\n-      ShenandoahGCSession session(cause, old_generation);\n-      old_generation->prepare_gc();\n+      old_generation->entry_coalesce_and_fill();\n@@ -520,7 +520,0 @@\n-      if (heap->is_prepare_for_old_mark_in_progress()) {\n-        \/\/ Coalescing threads detected the cancellation request and aborted. Stay\n-        \/\/ in this state so control thread may resume the coalescing work.\n-        assert(old_generation->state() == ShenandoahOldGeneration::FILLING, \"Prepare for mark should be in progress\");\n-        assert(heap->cancelled_gc(), \"Preparation for GC is not complete, expected cancellation\");\n-      }\n-\n@@ -538,3 +531,3 @@\n-      \/\/ Coalescing threads completed and nothing was cancelled. it is safe to transition\n-      \/\/ to the bootstrapping state now.\n-      old_generation->transition_to(ShenandoahOldGeneration::BOOTSTRAPPING);\n+      \/\/ Coalescing threads completed and nothing was cancelled. it is safe to transition from this state.\n+      old_generation->transition_to(ShenandoahOldGeneration::WAITING_FOR_BOOTSTRAP);\n+      return;\n@@ -542,0 +535,2 @@\n+    case ShenandoahOldGeneration::WAITING_FOR_BOOTSTRAP:\n+      old_generation->transition_to(ShenandoahOldGeneration::BOOTSTRAPPING);\n@@ -577,2 +572,1 @@\n-          heap->mmu_tracker()->record_old_marking_increment(old_generation, GCId::current(), true,\n-                                                            heap->collection_set()->has_old_regions());\n+          heap->mmu_tracker()->record_old_marking_increment(true);\n@@ -582,2 +576,1 @@\n-        heap->mmu_tracker()->record_old_marking_increment(old_generation, GCId::current(), false,\n-                                                          heap->collection_set()->has_old_regions());\n+        heap->mmu_tracker()->record_old_marking_increment(false);\n@@ -718,2 +711,1 @@\n-          bool mixed_is_done = (heap->old_heuristics()->unprocessed_old_collection_candidates() == 0);\n-          mmu_tracker->record_mixed(generation, get_gc_id(), mixed_is_done);\n+          mmu_tracker->record_mixed(get_gc_id());\n@@ -721,1 +713,1 @@\n-          mmu_tracker->record_bootstrap(generation, get_gc_id(), heap->collection_set()->has_old_regions());\n+          mmu_tracker->record_bootstrap(get_gc_id());\n@@ -723,1 +715,1 @@\n-          mmu_tracker->record_young(generation, get_gc_id());\n+          mmu_tracker->record_young(get_gc_id());\n@@ -734,1 +726,1 @@\n-        mmu_tracker->record_global(generation, get_gc_id());\n+        mmu_tracker->record_global(get_gc_id());\n@@ -793,3 +785,0 @@\n-\n-  heap->global_generation()->heuristics()->record_success_full();\n-  heap->shenandoah_policy()->record_success_full();\n@@ -798,1 +787,1 @@\n-bool ShenandoahControlThread::service_stw_degenerated_cycle(GCCause::Cause cause,\n+void ShenandoahControlThread::service_stw_degenerated_cycle(GCCause::Cause cause,\n@@ -816,1 +805,1 @@\n-    if (old->state() == ShenandoahOldGeneration::BOOTSTRAPPING && !gc.upgraded_to_full()) {\n+    if (old->state() == ShenandoahOldGeneration::BOOTSTRAPPING) {\n@@ -820,4 +809,0 @@\n-\n-  _degen_generation->heuristics()->record_success_degenerated();\n-  heap->shenandoah_policy()->record_success_degenerated(_degen_generation->is_young());\n-  return !gc.upgraded_to_full();\n@@ -966,0 +951,1 @@\n+  bool is_humongous = req.size() > ShenandoahHeapRegion::region_size_words();\n@@ -967,1 +953,1 @@\n-  if (try_set_alloc_failure_gc()) {\n+  if (try_set_alloc_failure_gc(is_humongous)) {\n@@ -984,0 +970,1 @@\n+  bool is_humongous = (words > ShenandoahHeapRegion::region_size_words());\n@@ -985,1 +972,1 @@\n-  if (try_set_alloc_failure_gc()) {\n+  if (try_set_alloc_failure_gc(is_humongous)) {\n@@ -997,0 +984,1 @@\n+  _humongous_alloc_failure_gc.unset();\n@@ -1001,1 +989,4 @@\n-bool ShenandoahControlThread::try_set_alloc_failure_gc() {\n+bool ShenandoahControlThread::try_set_alloc_failure_gc(bool is_humongous) {\n+  if (is_humongous) {\n+    _humongous_alloc_failure_gc.try_set();\n+  }\n@@ -1009,0 +1000,4 @@\n+bool ShenandoahControlThread::is_humongous_alloc_failure_gc() {\n+  return _humongous_alloc_failure_gc.is_set();\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahControlThread.cpp","additions":40,"deletions":45,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -91,0 +91,1 @@\n+  ShenandoahSharedFlag _humongous_alloc_failure_gc;\n@@ -114,4 +115,1 @@\n-\n-  \/\/ Return true if degenerated cycle finishes normally.  Return false if the degenerated cycle transformed itself\n-  \/\/ into a full GC.\n-  bool service_stw_degenerated_cycle(GCCause::Cause cause, ShenandoahGC::ShenandoahDegenPoint point);\n+  void service_stw_degenerated_cycle(GCCause::Cause cause, ShenandoahGC::ShenandoahDegenPoint point);\n@@ -121,1 +119,2 @@\n-  bool try_set_alloc_failure_gc();\n+  bool try_set_alloc_failure_gc(bool is_humongous);\n+\n@@ -124,0 +123,1 @@\n+\n@@ -127,0 +127,3 @@\n+  \/\/ True if humongous allocation failure flag has been set.\n+  bool is_humongous_alloc_failure_gc();\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahControlThread.hpp","additions":8,"deletions":5,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -53,1 +53,1 @@\n-  _upgraded_to_full(false) {\n+  _abbreviated(false) {\n@@ -61,2 +61,1 @@\n-    heap->mmu_tracker()->record_degenerated(_generation, GCId::current(), is_bootstrap_gc,\n-                                            !heap->collection_set()->has_old_regions());\n+    heap->mmu_tracker()->record_degenerated(GCId::current(), is_bootstrap_gc);\n@@ -109,3 +108,3 @@\n-      assert(state == ShenandoahOldGeneration::IDLE\n-             || state == ShenandoahOldGeneration::WAITING_FOR_EVAC\n-             || state == ShenandoahOldGeneration::WAITING_FOR_FILL,\n+      assert(state == ShenandoahOldGeneration::WAITING_FOR_BOOTSTRAP\n+             || state == ShenandoahOldGeneration::EVACUATING\n+             || state == ShenandoahOldGeneration::FILLING,\n@@ -269,0 +268,2 @@\n+      } else {\n+        _abbreviated = true;\n@@ -356,0 +357,2 @@\n+    heap->shenandoah_policy()->record_success_degenerated(_generation->is_young(), _abbreviated);\n+    _generation->heuristics()->record_success_degenerated();\n@@ -476,2 +479,0 @@\n-  ShenandoahFullGC full_gc;\n-  full_gc.op_full(GCCause::_shenandoah_upgrade_to_full_gc);\n@@ -482,2 +483,0 @@\n-  ShenandoahFullGC full_gc;\n-  full_gc.op_full(GCCause::_shenandoah_upgrade_to_full_gc);\n@@ -487,1 +486,0 @@\n-  const ShenandoahHeap* heap = ShenandoahHeap::heap();\n@@ -490,1 +488,1 @@\n-      SHENANDOAH_RETURN_EVENT_MESSAGE(heap, _generation->type(), \"Pause Degenerated GC\", \" (<UNSET>)\");\n+      SHENANDOAH_RETURN_EVENT_MESSAGE(_generation->type(), \"Pause Degenerated GC\", \" (<UNSET>)\");\n@@ -492,1 +490,1 @@\n-      SHENANDOAH_RETURN_EVENT_MESSAGE(heap, _generation->type(), \"Pause Degenerated GC\", \" (Outside of Cycle)\");\n+      SHENANDOAH_RETURN_EVENT_MESSAGE(_generation->type(), \"Pause Degenerated GC\", \" (Outside of Cycle)\");\n@@ -494,1 +492,1 @@\n-      SHENANDOAH_RETURN_EVENT_MESSAGE(heap, _generation->type(), \"Pause Degenerated GC\", \" (Roots)\");\n+      SHENANDOAH_RETURN_EVENT_MESSAGE(_generation->type(), \"Pause Degenerated GC\", \" (Roots)\");\n@@ -496,1 +494,1 @@\n-      SHENANDOAH_RETURN_EVENT_MESSAGE(heap, _generation->type(), \"Pause Degenerated GC\", \" (Mark)\");\n+      SHENANDOAH_RETURN_EVENT_MESSAGE(_generation->type(), \"Pause Degenerated GC\", \" (Mark)\");\n@@ -498,1 +496,1 @@\n-      SHENANDOAH_RETURN_EVENT_MESSAGE(heap, _generation->type(), \"Pause Degenerated GC\", \" (Evacuation)\");\n+      SHENANDOAH_RETURN_EVENT_MESSAGE(_generation->type(), \"Pause Degenerated GC\", \" (Evacuation)\");\n@@ -500,1 +498,1 @@\n-      SHENANDOAH_RETURN_EVENT_MESSAGE(heap, _generation->type(), \"Pause Degenerated GC\", \" (Update Refs)\");\n+      SHENANDOAH_RETURN_EVENT_MESSAGE(_generation->type(), \"Pause Degenerated GC\", \" (Update Refs)\");\n@@ -503,1 +501,1 @@\n-      SHENANDOAH_RETURN_EVENT_MESSAGE(heap, _generation->type(), \"Pause Degenerated GC\", \" (?)\");\n+      SHENANDOAH_RETURN_EVENT_MESSAGE(_generation->type(), \"Pause Degenerated GC\", \" (?)\");\n@@ -510,5 +508,2 @@\n-  _upgraded_to_full = true;\n-}\n-\n-bool ShenandoahDegenGC::upgraded_to_full() {\n-  return _upgraded_to_full;\n+  ShenandoahFullGC full_gc;\n+  full_gc.op_full(GCCause::_shenandoah_upgrade_to_full_gc);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahDegeneratedGC.cpp","additions":18,"deletions":23,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -38,1 +38,1 @@\n-  bool _upgraded_to_full;\n+  bool _abbreviated;\n@@ -43,1 +43,0 @@\n-  bool upgraded_to_full();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahDegeneratedGC.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -60,1 +60,3 @@\n-  _age_table->add(age, bytes >> LogBytesPerWord);\n+  if (age <= markWord::max_age) { \/\/ Filter age sentinel.\n+    _age_table->add(age, bytes >> LogBytesPerWord);\n+  }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahEvacTracker.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -221,0 +221,5 @@\n+inline bool ShenandoahSetsOfFree::is_empty(ShenandoahFreeMemoryType which_set) const {\n+  assert (which_set > NotFree && which_set < NumFreeSets, \"selected free set must be valid\");\n+  return (leftmost(which_set) > rightmost(which_set));\n+}\n+\n@@ -541,8 +546,13 @@\n-      for (size_t idx = _free_sets.leftmost(Mutator); idx <= _free_sets.rightmost(Mutator); idx++) {\n-        ShenandoahHeapRegion* r = _heap->get_region(idx);\n-        if (_free_sets.in_free_set(idx, Mutator) && (allow_new_region || r->is_affiliated())) {\n-          \/\/ try_allocate_in() increases used if the allocation is successful.\n-          HeapWord* result;\n-          size_t min_size = (req.type() == ShenandoahAllocRequest::_alloc_tlab)? req.min_size(): req.size();\n-          if ((alloc_capacity(r) >= min_size) && ((result = try_allocate_in(r, req, in_new_region)) != nullptr)) {\n-            return result;\n+      \/\/ Allocate within mutator free from high memory to low so as to preserve low memory for humongous allocations\n+      if (!_free_sets.is_empty(Mutator)) {\n+        \/\/ Use signed idx.  Otherwise, loop will never terminate.\n+        int leftmost = (int) _free_sets.leftmost(Mutator);\n+        for (int idx = (int) _free_sets.rightmost(Mutator); idx >= leftmost; idx--) {\n+          ShenandoahHeapRegion* r = _heap->get_region(idx);\n+          if (_free_sets.in_free_set(idx, Mutator) && (allow_new_region || r->is_affiliated())) {\n+            \/\/ try_allocate_in() increases used if the allocation is successful.\n+            HeapWord* result;\n+            size_t min_size = (req.type() == ShenandoahAllocRequest::_alloc_tlab)? req.min_size(): req.size();\n+            if ((alloc_capacity(r) >= min_size) && ((result = try_allocate_in(r, req, in_new_region)) != nullptr)) {\n+              return result;\n+            }\n@@ -1042,2 +1052,6 @@\n-void ShenandoahFreeSet::find_regions_with_alloc_capacity(size_t &young_cset_regions, size_t &old_cset_regions) {\n-\n+void ShenandoahFreeSet::find_regions_with_alloc_capacity(size_t &young_cset_regions, size_t &old_cset_regions,\n+                                                         size_t &first_old_region, size_t &last_old_region,\n+                                                         size_t &old_region_count) {\n+  first_old_region = _heap->num_regions();\n+  last_old_region = 0;\n+  old_region_count = 0;\n@@ -1056,0 +1070,6 @@\n+    } else if (region->is_old() && region->is_regular()) {\n+      old_region_count++;\n+      if (first_old_region > idx) {\n+        first_old_region = idx;\n+      }\n+      last_old_region = idx;\n@@ -1144,1 +1164,2 @@\n-void ShenandoahFreeSet::prepare_to_rebuild(size_t &young_cset_regions, size_t &old_cset_regions) {\n+void ShenandoahFreeSet::prepare_to_rebuild(size_t &young_cset_regions, size_t &old_cset_regions,\n+                                           size_t &first_old_region, size_t &last_old_region, size_t &old_region_count) {\n@@ -1152,1 +1173,1 @@\n-  find_regions_with_alloc_capacity(young_cset_regions, old_cset_regions);\n+  find_regions_with_alloc_capacity(young_cset_regions, old_cset_regions, first_old_region, last_old_region, old_region_count);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFreeSet.cpp","additions":33,"deletions":12,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -0,0 +1,1 @@\n+\n@@ -100,0 +101,2 @@\n+  inline bool is_empty(ShenandoahFreeMemoryType which_set) const;\n+\n@@ -190,1 +193,2 @@\n-  void prepare_to_rebuild(size_t &young_cset_regions, size_t &old_cset_regions);\n+  void prepare_to_rebuild(size_t &young_cset_regions, size_t &old_cset_regions,\n+                          size_t &first_old_region, size_t &last_old_region, size_t &old_region_count);\n@@ -215,1 +219,2 @@\n-  void find_regions_with_alloc_capacity(size_t &young_cset_regions, size_t &old_cset_regions);\n+  void find_regions_with_alloc_capacity(size_t &young_cset_regions, size_t &old_cset_regions,\n+                                        size_t &first_old_region, size_t &last_old_region, size_t &old_region_count);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFreeSet.hpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+#include \"gc\/shenandoah\/shenandoahCollectorPolicy.hpp\"\n@@ -178,1 +179,5 @@\n-    heap->mmu_tracker()->record_full(heap->global_generation(), GCId::current());\n+    \/\/ Full GC should reset time since last gc for young and old heuristics\n+    heap->young_generation()->heuristics()->record_cycle_end();\n+    heap->old_generation()->heuristics()->record_cycle_end();\n+\n+    heap->mmu_tracker()->record_full(GCId::current());\n@@ -181,0 +186,3 @@\n+    assert(heap->old_generation()->state() == ShenandoahOldGeneration::WAITING_FOR_BOOTSTRAP,\n+           \"After full GC, old generation should be waiting for bootstrap.\");\n+\n@@ -193,0 +201,3 @@\n+    \/\/ Establish baseline for next old-has-grown trigger.\n+    heap->old_generation()->set_live_bytes_after_last_mark(heap->old_generation()->used() +\n+                                                           heap->old_generation()->get_humongous_waste());\n@@ -201,0 +212,4 @@\n+\n+  \/\/ Regardless if progress was made, we record that we completed a \"successful\" full GC.\n+  heap->global_generation()->heuristics()->record_success_full();\n+  heap->shenandoah_policy()->record_success_full();\n@@ -424,1 +439,0 @@\n-  heap->old_generation()->set_live_bytes_after_last_mark(live_bytes_in_old);\n@@ -1546,1 +1560,2 @@\n-    heap->free_set()->prepare_to_rebuild(young_cset_regions, old_cset_regions);\n+    size_t first_old, last_old, num_old;\n+    heap->free_set()->prepare_to_rebuild(young_cset_regions, old_cset_regions, first_old, last_old, num_old);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFullGC.cpp","additions":18,"deletions":3,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -85,0 +85,2 @@\n+\/\/ Copy the write-version of the card-table into the read-version, clearing the\n+\/\/ write-copy.\n@@ -93,3 +95,2 @@\n-    if (r->is_old()) {\n-      _scanner->merge_write_table(r->bottom(), ShenandoahHeapRegion::region_size_words());\n-    }\n+    assert(r->is_old(), \"Don't waste time doing this for non-old regions\");\n+    _scanner->merge_write_table(r->bottom(), ShenandoahHeapRegion::region_size_words());\n@@ -113,3 +114,2 @@\n-    if (region->is_old()) {\n-      _scanner->reset_remset(region->bottom(), ShenandoahHeapRegion::region_size_words());\n-    }\n+    assert(region->is_old(), \"Don't waste time doing this for non-old regions\");\n+    _scanner->reset_remset(region->bottom(), ShenandoahHeapRegion::region_size_words());\n@@ -204,4 +204,3 @@\n-\/\/ If a concurrent cycle fails _after_ the card table has been swapped we need to update the read card\n-\/\/ table with any writes that have occurred during the transition to the degenerated cycle. Without this,\n-\/\/ newly created objects which are only referenced by old objects could be lost when the remembered set\n-\/\/ is scanned during the degenerated mark.\n+\/\/ Copy the write-version of the card-table into the read-version, clearing the\n+\/\/ write-version. The work is done at a safepoint and in parallel by the GC\n+\/\/ worker threads.\n@@ -575,1 +574,1 @@\n-            \/\/ newly allocated objects will not be parseable when promote in place tries to register them.  Furthermore, any\n+            \/\/ newly allocated objects will not be parsable when promote in place tries to register them.  Furthermore, any\n@@ -737,1 +736,1 @@\n-        \/\/ use the mark bitmap to make the old regions parseable by coalescing and filling any unmarked objects. Thus,\n+        \/\/ use the mark bitmap to make the old regions parsable by coalescing and filling any unmarked objects. Thus,\n@@ -764,1 +763,2 @@\n-    heap->free_set()->prepare_to_rebuild(young_cset_regions, old_cset_regions);\n+    size_t first_old, last_old, num_old;\n+    heap->free_set()->prepare_to_rebuild(young_cset_regions, old_cset_regions, first_old, last_old, num_old);\n@@ -1019,6 +1019,1 @@\n-  ShenandoahHeap::heap()->shenandoah_policy()->record_success_concurrent(is_young());\n-}\n-\n-void ShenandoahGeneration::record_success_degenerated() {\n-  heuristics()->record_success_degenerated();\n-  ShenandoahHeap::heap()->shenandoah_policy()->record_success_degenerated(is_young());\n+  ShenandoahHeap::heap()->shenandoah_policy()->record_success_concurrent(is_young(), abbreviated);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGeneration.cpp","additions":14,"deletions":19,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -216,1 +216,0 @@\n-  virtual void record_success_degenerated();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGeneration.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -422,1 +422,2 @@\n-    _free_set->prepare_to_rebuild(young_cset_regions, old_cset_regions);\n+    size_t first_old, last_old, num_old;\n+    _free_set->prepare_to_rebuild(young_cset_regions, old_cset_regions, first_old, last_old, num_old);\n@@ -583,1 +584,0 @@\n-  _prepare_for_old_mark(false),\n@@ -598,1 +598,0 @@\n-  _upgraded_to_full(false),\n@@ -739,1 +738,1 @@\n-  return _old_generation->state() == ShenandoahOldGeneration::WAITING_FOR_EVAC;\n+  return _old_generation->state() == ShenandoahOldGeneration::EVACUATING;\n@@ -1163,1 +1162,1 @@\n-  if (_old_generation->state() == ShenandoahOldGeneration::IDLE) {\n+  if (_old_generation->state() == ShenandoahOldGeneration::WAITING_FOR_BOOTSTRAP) {\n@@ -1172,2 +1171,0 @@\n-    \/\/ Stop coalescing undead objects\n-    set_prepare_for_old_mark_in_progress(false);\n@@ -1179,1 +1176,1 @@\n-    _old_generation->transition_to(ShenandoahOldGeneration::IDLE);\n+    _old_generation->transition_to(ShenandoahOldGeneration::WAITING_FOR_BOOTSTRAP);\n@@ -1863,1 +1860,1 @@\n-    \/\/  1. We need to make the plab memory parseable by remembered-set scanning.\n+    \/\/  1. We need to make the plab memory parsable by remembered-set scanning.\n@@ -2022,1 +2019,1 @@\n-  if (mode()->is_generational() && (generation->is_global() || upgraded_to_full())) {\n+  if (mode()->is_generational() && generation->is_global()) {\n@@ -2433,1 +2430,1 @@\n-          \"Updating or evacuating iff has forwarded object, or evacuation phase is promoting in place without forwarding\");\n+          \"Updating or evacuating iff has forwarded objects, or if evacuation phase is promoting in place without forwarding\");\n@@ -2445,4 +2442,2 @@\n-void ShenandoahHeap::set_prepare_for_old_mark_in_progress(bool in_progress) {\n-  \/\/ Unlike other set-gc-state functions, this may happen outside safepoint.\n-  \/\/ Is only set and queried by control thread, so no coherence issues.\n-  _prepare_for_old_mark = in_progress;\n+bool ShenandoahHeap::is_prepare_for_old_mark_in_progress() const {\n+  return old_generation()->state() == ShenandoahOldGeneration::FILLING;\n@@ -2515,3 +2510,0 @@\n-    if (cause == GCCause::_shenandoah_upgrade_to_full_gc) {\n-      _upgraded_to_full = true;\n-    }\n@@ -2783,0 +2775,1 @@\n+    log_info(gc, remset)(\"Scan remembered set using bitmap: %s\", BOOL_TO_STR(_heap->is_old_bitmap_stable()));\n@@ -3078,1 +3071,8 @@\n-  _free_set->prepare_to_rebuild(young_cset_regions, old_cset_regions);\n+  size_t first_old_region, last_old_region, old_region_count;\n+  _free_set->prepare_to_rebuild(young_cset_regions, old_cset_regions, first_old_region, last_old_region, old_region_count);\n+  \/\/ If there are no old regions, first_old_region will be greater than last_old_region\n+  assert((first_old_region > last_old_region) ||\n+         ((last_old_region + 1 - first_old_region >= old_region_count) &&\n+          get_region(first_old_region)->is_old() && get_region(last_old_region)->is_old()),\n+         \"sanity: old_region_count: \" SIZE_FORMAT \", first_old_region: \" SIZE_FORMAT \", last_old_region: \" SIZE_FORMAT,\n+         old_region_count, first_old_region, last_old_region);\n@@ -3103,11 +3103,34 @@\n-  if (mode()->is_generational()) {\n-    size_t old_available = old_generation()->available();\n-    size_t old_unaffiliated_available = old_generation()->free_unaffiliated_regions() * region_size_bytes;\n-    size_t old_fragmented_available;\n-    assert(old_available >= old_unaffiliated_available, \"unaffiliated available is a subset of total available\");\n-    old_fragmented_available = old_available - old_unaffiliated_available;\n-\n-    size_t old_capacity = old_generation()->max_capacity();\n-    size_t heap_capacity = capacity();\n-    if ((old_capacity > heap_capacity \/ 8) && (old_fragmented_available > old_capacity \/ 8)) {\n-      old_heuristics()->trigger_old_is_fragmented();\n+  if (mode()->is_generational() && (ShenandoahGenerationalHumongousReserve > 0)) {\n+    size_t old_region_span = (first_old_region <= last_old_region)? (last_old_region + 1 - first_old_region): 0;\n+    size_t allowed_old_gen_span = num_regions() - (ShenandoahGenerationalHumongousReserve * num_regions() \/ 100);\n+\n+    \/\/ Tolerate lower density if total span is small.  Here's the implementation:\n+    \/\/   if old_gen spans more than 100% and density < 75%, trigger old-defrag\n+    \/\/   else if old_gen spans more than 87.5% and density < 62.5%, trigger old-defrag\n+    \/\/   else if old_gen spans more than 75% and density < 50%, trigger old-defrag\n+    \/\/   else if old_gen spans more than 62.5% and density < 37.5%, trigger old-defrag\n+    \/\/   else if old_gen spans more than 50% and density < 25%, trigger old-defrag\n+    \/\/\n+    \/\/ A previous implementation was more aggressive in triggering, resulting in degraded throughput when\n+    \/\/ humongous allocation was not required.\n+\n+    ShenandoahGeneration* old_gen = old_generation();\n+    size_t old_available = old_gen->available();\n+    size_t region_size_bytes = ShenandoahHeapRegion::region_size_bytes();\n+    size_t old_unaffiliated_available = old_gen->free_unaffiliated_regions() * region_size_bytes;\n+    assert(old_available >= old_unaffiliated_available, \"sanity\");\n+    size_t old_fragmented_available = old_available - old_unaffiliated_available;\n+\n+    size_t old_bytes_consumed = old_region_count * region_size_bytes - old_fragmented_available;\n+    size_t old_bytes_spanned = old_region_span * region_size_bytes;\n+    double old_density = ((double) old_bytes_consumed) \/ old_bytes_spanned;\n+\n+    uint eighths = 8;\n+    for (uint i = 0; i < 5; i++) {\n+      size_t span_threshold = eighths * allowed_old_gen_span \/ 8;\n+      double density_threshold = (eighths - 2) \/ 8.0;\n+      if ((old_region_span >= span_threshold) && (old_density < density_threshold)) {\n+        old_heuristics()->trigger_old_is_fragmented(old_density, first_old_region, last_old_region);\n+        break;\n+      }\n+      eighths--;\n@@ -3346,2 +3369,2 @@\n-  \/\/ Visit young and free regions\n-  if (!region->is_old()) {\n+  \/\/ Visit young regions\n+  if (region->is_young()) {\n@@ -3354,2 +3377,2 @@\n-  \/\/ Visit old and free regions\n-  if (!region->is_young()) {\n+  \/\/ Visit old regions\n+  if (region->is_old()) {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":57,"deletions":34,"binary":false,"changes":91,"status":"modified"},{"patch":"@@ -165,3 +165,0 @@\n-  \/\/ true iff we are concurrently coalescing and filling old-gen HeapRegions\n-  bool _prepare_for_old_mark;\n-\n@@ -372,2 +369,0 @@\n-  bool _upgraded_to_full;\n-\n@@ -408,1 +403,1 @@\n-  void set_prepare_for_old_mark_in_progress(bool cond);\n+\n@@ -427,1 +422,1 @@\n-  inline bool is_prepare_for_old_mark_in_progress() const;\n+  bool is_prepare_for_old_mark_in_progress() const;\n@@ -429,3 +424,0 @@\n-  inline bool upgraded_to_full() { return _upgraded_to_full; }\n-  inline void start_conc_gc() { _upgraded_to_full = false; }\n-  inline void record_upgrade_to_full() { _upgraded_to_full = true; }\n@@ -861,4 +853,0 @@\n-  \/\/ Return the object's age (at a safepoint or when object isn't\n-  \/\/ mutable by the mutator)\n-  static inline uint get_object_age(oop obj);\n-\n@@ -868,1 +856,1 @@\n-  static inline uint get_object_age_concurrent(oop obj);\n+  static inline uint get_object_age(oop obj);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.hpp","additions":3,"deletions":15,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -55,0 +55,1 @@\n+#include \"runtime\/objectMonitor.inline.hpp\"\n@@ -540,5 +541,25 @@\n-  markWord w = obj->has_displaced_mark() ? obj->displaced_mark() : obj->mark();\n-  w = w.set_age(MIN2(markWord::max_age, w.age() + additional_age));\n-  if (obj->has_displaced_mark()) {\n-    obj->set_displaced_mark(w);\n-  } else {\n+  \/\/ This operates on new copy of an object. This means that the object's mark-word\n+  \/\/ is thread-local and therefore safe to access. However, when the mark is\n+  \/\/ displaced (i.e. stack-locked or monitor-locked), then it must be considered\n+  \/\/ a shared memory location. It can be accessed by other threads.\n+  \/\/ In particular, a competing evacuating thread can succeed to install its copy\n+  \/\/ as the forwardee and continue to unlock the object, at which point 'our'\n+  \/\/ write to the foreign stack-location would potentially over-write random\n+  \/\/ information on that stack. Writing to a monitor is less problematic,\n+  \/\/ but still not safe: while the ObjectMonitor would not randomly disappear,\n+  \/\/ the other thread would also write to the same displaced header location,\n+  \/\/ possibly leading to increase the age twice.\n+  \/\/ For all these reasons, we take the conservative approach and not attempt\n+  \/\/ to increase the age when the header is displaced.\n+  markWord w = obj->mark();\n+  \/\/ The mark-word has been copied from the original object. It can not be\n+  \/\/ inflating, because inflation can not be interrupted by a safepoint,\n+  \/\/ and after a safepoint, a Java thread would first have to successfully\n+  \/\/ evacuate the object before it could inflate the monitor.\n+  assert(!w.is_being_inflated() || LockingMode == LM_LIGHTWEIGHT, \"must not inflate monitor before evacuation of object succeeds\");\n+  \/\/ It is possible that we have copied the object after another thread has\n+  \/\/ already successfully completed evacuation. While harmless (we would never\n+  \/\/ publish our copy), don't even attempt to modify the age when that\n+  \/\/ happens.\n+  if (!w.has_displaced_mark_helper() && !w.is_marked()) {\n+    w = w.set_age(MIN2(markWord::max_age, w.age() + additional_age));\n@@ -549,8 +570,0 @@\n-\/\/ Return the object's age (at a safepoint or when object isn't\n-\/\/ mutable by the mutator)\n-uint ShenandoahHeap::get_object_age(oop obj) {\n-  markWord w = obj->has_displaced_mark() ? obj->displaced_mark() : obj->mark();\n-  assert(w.age() <= markWord::max_age, \"Impossible!\");\n-  return w.age();\n-}\n-\n@@ -560,1 +573,1 @@\n-uint ShenandoahHeap::get_object_age_concurrent(oop obj) {\n+uint ShenandoahHeap::get_object_age(oop obj) {\n@@ -564,2 +577,4 @@\n-  \/\/ We can do better for objects with inflated monitor\n-  if (w.is_being_inflated() || w.has_displaced_mark_helper()) {\n+  assert(!w.is_marked(), \"must not be forwarded\");\n+  if (w.has_monitor()) {\n+    w = w.monitor()->header();\n+  } else if (w.is_being_inflated() || w.has_displaced_mark_helper()) {\n@@ -745,4 +760,0 @@\n-inline bool ShenandoahHeap::is_prepare_for_old_mark_in_progress() const {\n-  return _prepare_for_old_mark;\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.inline.hpp","additions":31,"deletions":20,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -397,1 +397,1 @@\n-  \/\/ This is used by old-gen GC following concurrent marking to make old-gen HeapRegions parseable.  Return true iff\n+  \/\/ This is used by old-gen GC following concurrent marking to make old-gen HeapRegions parsable.  Return true iff\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeapRegion.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -122,1 +122,1 @@\n-      uint age = ShenandoahHeap::get_object_age_concurrent(obj);\n+      uint age = ShenandoahHeap::get_object_age(obj);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMark.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -86,1 +86,1 @@\n-void ShenandoahMmuTracker::update_utilization(ShenandoahGeneration* generation, size_t gcid, const char *msg) {\n+void ShenandoahMmuTracker::update_utilization(size_t gcid, const char* msg) {\n@@ -112,2 +112,2 @@\n-void ShenandoahMmuTracker::record_young(ShenandoahGeneration* generation, size_t gcid) {\n-  update_utilization(generation, gcid, \"Concurrent Young GC\");\n+void ShenandoahMmuTracker::record_young(size_t gcid) {\n+  update_utilization(gcid, \"Concurrent Young GC\");\n@@ -116,2 +116,2 @@\n-void ShenandoahMmuTracker::record_global(ShenandoahGeneration* generation, size_t gcid) {\n-  update_utilization(generation, gcid, \"Concurrent Global GC\");\n+void ShenandoahMmuTracker::record_global(size_t gcid) {\n+  update_utilization(gcid, \"Concurrent Global GC\");\n@@ -120,1 +120,1 @@\n-void ShenandoahMmuTracker::record_bootstrap(ShenandoahGeneration* generation, size_t gcid, bool candidates_for_mixed) {\n+void ShenandoahMmuTracker::record_bootstrap(size_t gcid) {\n@@ -122,1 +122,1 @@\n-  update_utilization(generation, gcid, \"Concurrent Bootstrap GC\");\n+  update_utilization(gcid, \"Concurrent Bootstrap GC\");\n@@ -125,2 +125,1 @@\n-void ShenandoahMmuTracker::record_old_marking_increment(ShenandoahGeneration* generation, size_t gcid, bool old_marking_done,\n-                                                        bool has_old_candidates) {\n+void ShenandoahMmuTracker::record_old_marking_increment(bool old_marking_done) {\n@@ -140,2 +139,2 @@\n-void ShenandoahMmuTracker::record_mixed(ShenandoahGeneration* generation, size_t gcid, bool is_mixed_done) {\n-  update_utilization(generation, gcid, \"Mixed Concurrent GC\");\n+void ShenandoahMmuTracker::record_mixed(size_t gcid) {\n+  update_utilization(gcid, \"Mixed Concurrent GC\");\n@@ -144,2 +143,1 @@\n-void ShenandoahMmuTracker::record_degenerated(ShenandoahGeneration* generation,\n-                                              size_t gcid, bool is_old_bootstrap, bool is_mixed_done) {\n+void ShenandoahMmuTracker::record_degenerated(size_t gcid, bool is_old_bootstrap) {\n@@ -150,1 +148,1 @@\n-    update_utilization(generation, gcid, \"Degenerated Bootstrap Old GC\");\n+    update_utilization(gcid, \"Degenerated Bootstrap Old GC\");\n@@ -152,1 +150,1 @@\n-    update_utilization(generation, gcid, \"Degenerated Young GC\");\n+    update_utilization(gcid, \"Degenerated Young GC\");\n@@ -156,2 +154,2 @@\n-void ShenandoahMmuTracker::record_full(ShenandoahGeneration* generation, size_t gcid) {\n-  update_utilization(generation, gcid, \"Full GC\");\n+void ShenandoahMmuTracker::record_full(size_t gcid) {\n+  update_utilization(gcid, \"Full GC\");\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMmuTracker.cpp","additions":15,"deletions":17,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -76,1 +76,1 @@\n-  void update_utilization(ShenandoahGeneration* generation, size_t gcid, const char* msg);\n+  void update_utilization(size_t gcid, const char* msg);\n@@ -93,7 +93,7 @@\n-  void record_young(ShenandoahGeneration* generation, size_t gcid);\n-  void record_global(ShenandoahGeneration* generation, size_t gcid);\n-  void record_bootstrap(ShenandoahGeneration* generation, size_t gcid, bool has_old_candidates);\n-  void record_old_marking_increment(ShenandoahGeneration* generation, size_t gcid, bool old_marking_done, bool has_old_candidates);\n-  void record_mixed(ShenandoahGeneration* generation, size_t gcid, bool is_mixed_done);\n-  void record_full(ShenandoahGeneration* generation, size_t gcid);\n-  void record_degenerated(ShenandoahGeneration* generation, size_t gcid, bool is_old_boostrap, bool is_mixed_done);\n+  void record_young(size_t gcid);\n+  void record_global(size_t gcid);\n+  void record_bootstrap(size_t gcid);\n+  void record_old_marking_increment(bool old_marking_done);\n+  void record_mixed(size_t gcid);\n+  void record_full(size_t gcid);\n+  void record_degenerated(size_t gcid, bool is_old_boostrap);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMmuTracker.hpp","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -90,1 +90,1 @@\n-  assert(!heap->is_prepare_for_old_mark_in_progress(), \"Old regions need to be parseable during concurrent mark.\");\n+  assert(!heap->is_prepare_for_old_mark_in_progress(), \"Old regions need to be parsable during concurrent mark.\");\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahOldGC.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -177,1 +177,1 @@\n-    _state(IDLE),\n+    _state(WAITING_FOR_BOOTSTRAP),\n@@ -236,14 +236,5 @@\n-  \/\/ Make the old generation regions parseable, so they can be safely\n-  \/\/ scanned when looking for objects in memory indicated by dirty cards.\n-  if (entry_coalesce_and_fill()) {\n-    \/\/ Now that we have made the old generation parseable, it is safe to reset the mark bitmap.\n-    static const char* msg = \"Concurrent reset (OLD)\";\n-    ShenandoahConcurrentPhase gc_phase(msg, ShenandoahPhaseTimings::conc_reset_old);\n-    ShenandoahWorkerScope scope(ShenandoahHeap::heap()->workers(),\n-                                ShenandoahWorkerPolicy::calc_workers_for_conc_reset(),\n-                                msg);\n-    ShenandoahGeneration::prepare_gc();\n-  }\n-  \/\/ Else, coalesce-and-fill has been preempted and we'll finish that effort in the future.  Do not invoke\n-  \/\/ ShenandoahGeneration::prepare_gc() until coalesce-and-fill is done because it resets the mark bitmap\n-  \/\/ and invokes set_mark_incomplete().  Coalesce-and-fill depends on the mark bitmap.\n+\n+  \/\/ Now that we have made the old generation parsable, it is safe to reset the mark bitmap.\n+  assert(state() != FILLING, \"Cannot reset old without making it parsable\");\n+\n+  ShenandoahGeneration::prepare_gc();\n@@ -268,0 +259,2 @@\n+\/\/ Make the old generation regions parsable, so they can be safely\n+\/\/ scanned when looking for objects in memory indicated by dirty cards.\n@@ -270,1 +263,0 @@\n-  heap->set_prepare_for_old_mark_in_progress(true);\n@@ -288,2 +280,0 @@\n-    \/\/ Remember that we're done with coalesce-and-fill.\n-    heap->set_prepare_for_old_mark_in_progress(false);\n@@ -293,1 +283,3 @@\n-    \/\/ Otherwise, we were preempted before the work was done.\n+    \/\/ Coalesce-and-fill has been preempted. We'll finish that effort in the future.  Do not invoke\n+    \/\/ ShenandoahGeneration::prepare_gc() until coalesce-and-fill is done because it resets the mark bitmap\n+    \/\/ and invokes set_mark_incomplete().  Coalesce-and-fill depends on the mark bitmap.\n@@ -347,1 +339,2 @@\n-    heap->free_set()->prepare_to_rebuild(cset_young_regions, cset_old_regions);\n+    size_t first_old, last_old, num_old;\n+    heap->free_set()->prepare_to_rebuild(cset_young_regions, cset_old_regions, first_old, last_old, num_old);\n@@ -356,6 +349,5 @@\n-    case IDLE:              return \"Idle\";\n-    case FILLING:           return \"Coalescing\";\n-    case BOOTSTRAPPING:     return \"Bootstrapping\";\n-    case MARKING:           return \"Marking\";\n-    case WAITING_FOR_EVAC:  return \"Waiting for evacuation\";\n-    case WAITING_FOR_FILL:  return \"Waiting for fill\";\n+    case WAITING_FOR_BOOTSTRAP: return \"Waiting for Bootstrap\";\n+    case FILLING:               return \"Coalescing\";\n+    case BOOTSTRAPPING:         return \"Bootstrapping\";\n+    case MARKING:               return \"Marking\";\n+    case EVACUATING:            return \"Evacuating\";\n@@ -384,5 +376,12 @@\n-\/\/ parseable _before_ the old generation bitmap is reset. The diagram does not depict\n-\/\/ cancellation of old collections by global or full collections. However, it does\n-\/\/ depict a transition from IDLE to WAITING_FOR_FILL, which is allowed after a global\n-\/\/ cycle ends. Also note that a global collection will cause any evacuation or fill\n-\/\/ candidates to be abandoned, returning the old generation to the idle state.\n+\/\/ parsable _before_ the old generation bitmap is reset. The diagram does not depict\n+\/\/ cancellation of old collections by global or full collections.\n+\/\/\n+\/\/ When a global collection supersedes an old collection, the global mark still\n+\/\/ \"completes\" the old mark bitmap. Subsequent remembered set scans may use the\n+\/\/ old generation mark bitmap, but any uncollected old regions must still be made parsable\n+\/\/ before the next old generation cycle begins. For this reason, a global collection may\n+\/\/ create mixed collection candidates and coalesce and fill candidates and will put\n+\/\/ the old generation in the respective states (EVACUATING or FILLING). After a Full GC,\n+\/\/ the mark bitmaps are all reset, all regions are parsable and the mark context will\n+\/\/ not be \"complete\". After a Full GC, remembered set scans will _not_ use the mark bitmap\n+\/\/ and we expect the old generation to be waiting for bootstrap.\n@@ -390,38 +389,0 @@\n-\/\/           +----------------> +-----------------+\n-\/\/           |   +------------> |      IDLE       |\n-\/\/           |   |   +--------> |                 |\n-\/\/           |   |   |          +-----------------+\n-\/\/           |   |   |            |\n-\/\/           |   |   |            | Begin Old Mark\n-\/\/           |   |   |            v\n-\/\/           |   |   |          +-----------------+     +--------------------+\n-\/\/           |   |   |          |     FILLING     | <-> |      YOUNG GC      |\n-\/\/           |   |   |    +---> |                 |     | (RSet Uses Bitmap) |\n-\/\/           |   |   |    |     +-----------------+     +--------------------+\n-\/\/           |   |   |    |       |\n-\/\/           |   |   |    |       | Reset Bitmap\n-\/\/           |   |   |    |       v\n-\/\/           |   |   |    |     +-----------------+\n-\/\/           |   |   |    |     |    BOOTSTRAP    |\n-\/\/           |   |   |    |     |                 |\n-\/\/           |   |   |    |     +-----------------+\n-\/\/           |   |   |    |       |\n-\/\/           |   |   |    |       | Continue Marking\n-\/\/           |   |   |    |       v\n-\/\/           |   |   |    |     +-----------------+     +----------------------+\n-\/\/           |   |   |    |     |    MARKING      | <-> |       YOUNG GC       |\n-\/\/           |   |   +----|-----|                 |     | (RSet Parses Region) |\n-\/\/           |   |        |     +-----------------+     +----------------------+\n-\/\/           |   |        |       |\n-\/\/           |   |        |       | Has Candidates\n-\/\/           |   |        |       v\n-\/\/           |   |        |     +-----------------+\n-\/\/           |   |        |     |    WAITING FOR  |\n-\/\/           |   +--------|---> |    EVACUATIONS  |\n-\/\/           |            |     +-----------------+\n-\/\/           |            |       |\n-\/\/           |            |       | All Candidates are Pinned\n-\/\/           |            |       v\n-\/\/           |            |     +-----------------+\n-\/\/           |            +---- |    WAITING FOR  |\n-\/\/           +----------------> |    FILLING      |\n@@ -429,0 +390,33 @@\n+\/\/               +------------> |     FILLING     | <---+\n+\/\/               |   +--------> |                 |     |\n+\/\/               |   |          +-----------------+     |\n+\/\/               |   |            |                     |\n+\/\/               |   |            | Filling Complete    | <-> A global collection may\n+\/\/               |   |            v                     |     may move the old generation\n+\/\/               |   |          +-----------------+     |     directly from waiting for\n+\/\/               |   +--------> |     WAITING     |     |     bootstrap to filling or\n+\/\/               |   |    +---- |  FOR BOOTSTRAP  | ----+     evacuating.\n+\/\/               |   |    |     +-----------------+\n+\/\/               |   |    |       |\n+\/\/               |   |    |       | Reset Bitmap\n+\/\/               |   |    |       v\n+\/\/               |   |    |     +-----------------+     +----------------------+\n+\/\/               |   |    |     |    BOOTSTRAP    | <-> |       YOUNG GC       |\n+\/\/               |   |    |     |                 |     | (RSet Parses Region) |\n+\/\/               |   |    |     +-----------------+     +----------------------+\n+\/\/               |   |    |       |\n+\/\/               |   |    |       | Old Marking\n+\/\/               |   |    |       v\n+\/\/               |   |    |     +-----------------+     +----------------------+\n+\/\/               |   |    |     |     MARKING     | <-> |       YOUNG GC       |\n+\/\/               |   +--------- |                 |     | (RSet Parses Region) |\n+\/\/               |        |     +-----------------+     +----------------------+\n+\/\/               |        |       |\n+\/\/               |        |       | Has Evacuation Candidates\n+\/\/               |        |       v\n+\/\/               |        |     +-----------------+     +--------------------+\n+\/\/               |        +---> |    EVACUATING   | <-> |      YOUNG GC      |\n+\/\/               +------------- |                 |     | (RSet Uses Bitmap) |\n+\/\/                              +-----------------+     +--------------------+\n+\/\/\n+\/\/\n@@ -433,7 +427,0 @@\n-    case IDLE:\n-      \/\/ GC cancellation can send us back to IDLE from any state.\n-      assert(!heap->is_concurrent_old_mark_in_progress(), \"Cannot become idle during old mark.\");\n-      assert(_old_heuristics->unprocessed_old_collection_candidates() == 0, \"Cannot become idle with collection candidates\");\n-      assert(!heap->is_prepare_for_old_mark_in_progress(), \"Cannot become idle while making old generation parseable.\");\n-      assert(heap->young_generation()->old_gen_task_queues() == nullptr, \"Cannot become idle when setup for bootstrapping.\");\n-      break;\n@@ -441,2 +428,9 @@\n-      assert(_state == IDLE || _state == WAITING_FOR_FILL, \"Cannot begin filling without first completing evacuations, state is '%s'\", state_name(_state));\n-      assert(heap->is_prepare_for_old_mark_in_progress(), \"Should be preparing for old mark now.\");\n+      assert(_state != BOOTSTRAPPING, \"Cannot beging making old regions parsable after bootstrapping\");\n+      assert(heap->is_old_bitmap_stable(), \"Cannot begin filling without first completing marking, state is '%s'\", state_name(_state));\n+      assert(_old_heuristics->has_coalesce_and_fill_candidates(), \"Cannot begin filling without something to fill.\");\n+      break;\n+    case WAITING_FOR_BOOTSTRAP:\n+      \/\/ GC cancellation can send us back here from any state.\n+      assert(!heap->is_concurrent_old_mark_in_progress(), \"Cannot become ready for bootstrap during old mark.\");\n+      assert(_old_heuristics->unprocessed_old_collection_candidates() == 0, \"Cannot become ready for bootstrap with collection candidates\");\n+      assert(heap->young_generation()->old_gen_task_queues() == nullptr, \"Cannot become ready for bootstrap when still setup for bootstrapping.\");\n@@ -445,1 +439,1 @@\n-      assert(_state == FILLING, \"Cannot reset bitmap without making old regions parseable, state is '%s'\", state_name(_state));\n+      assert(_state == WAITING_FOR_BOOTSTRAP, \"Cannot reset bitmap without making old regions parsable, state is '%s'\", state_name(_state));\n@@ -447,1 +441,1 @@\n-      assert(!heap->is_prepare_for_old_mark_in_progress(), \"Cannot still be making old regions parseable.\");\n+      assert(!heap->is_prepare_for_old_mark_in_progress(), \"Cannot still be making old regions parsable.\");\n@@ -454,2 +448,2 @@\n-    case WAITING_FOR_EVAC:\n-      assert(_state == IDLE || _state == MARKING, \"Cannot have old collection candidates without first marking, state is '%s'\", state_name(_state));\n+    case EVACUATING:\n+      assert(_state == WAITING_FOR_BOOTSTRAP || _state == MARKING, \"Cannot have old collection candidates without first marking, state is '%s'\", state_name(_state));\n@@ -458,4 +452,0 @@\n-    case WAITING_FOR_FILL:\n-      assert(_state == IDLE || _state == MARKING || _state == WAITING_FOR_EVAC, \"Cannot begin filling without first marking or evacuating, state is '%s'\", state_name(_state));\n-      assert(_old_heuristics->has_coalesce_and_fill_candidates(), \"Cannot wait for fill without something to fill.\");\n-      break;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahOldGeneration.cpp","additions":76,"deletions":86,"binary":false,"changes":162,"status":"modified"},{"patch":"@@ -39,1 +39,0 @@\n-  bool entry_coalesce_and_fill();\n@@ -60,0 +59,1 @@\n+  bool entry_coalesce_and_fill();\n@@ -87,1 +87,1 @@\n-    IDLE, FILLING, BOOTSTRAPPING, MARKING, WAITING_FOR_EVAC, WAITING_FOR_FILL\n+    FILLING, WAITING_FOR_BOOTSTRAP, BOOTSTRAPPING, MARKING, EVACUATING\n@@ -95,1 +95,1 @@\n-  \/\/ During initialization of the JVM, we search for the correct old-gen size by initally performing old-gen\n+  \/\/ During initialization of the JVM, we search for the correct old-gen size by initially performing old-gen\n@@ -98,1 +98,1 @@\n-  \/\/ memory at the end of the first old-gen collection.  Then we trigger again when old-gen growns 12.5%\n+  \/\/ memory at the end of the first old-gen collection.  Then we trigger again when old-gen grows 12.5%\n@@ -135,1 +135,1 @@\n-    return _state == IDLE || _state == WAITING_FOR_FILL;\n+    return _state == WAITING_FOR_BOOTSTRAP;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahOldGeneration.hpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -34,1 +34,7 @@\n-ShenandoahDirectCardMarkRememberedSet::ShenandoahDirectCardMarkRememberedSet(ShenandoahCardTable* card_table, size_t total_card_count) {\n+ShenandoahDirectCardMarkRememberedSet::ShenandoahDirectCardMarkRememberedSet(ShenandoahCardTable* card_table, size_t total_card_count) :\n+  LogCardValsPerIntPtr(log2i_exact(sizeof(intptr_t)) - log2i_exact(sizeof(CardValue))),\n+  LogCardSizeInWords(log2i_exact(CardTable::card_size_in_words())) {\n+\n+  \/\/ Paranoid assert for LogCardsPerIntPtr calculation above\n+  assert(sizeof(intptr_t) > sizeof(CardValue), \"LogsCardValsPerIntPtr would underflow\");\n+\n@@ -50,0 +56,48 @@\n+\/\/ Merge any dirty values from write table into the read table, while leaving\n+\/\/ the write table unchanged.\n+void ShenandoahDirectCardMarkRememberedSet::merge_write_table(HeapWord* start, size_t word_count) {\n+  size_t start_index = card_index_for_addr(start);\n+#ifdef ASSERT\n+  \/\/ avoid querying card_index_for_addr() for an address past end of heap\n+  size_t end_index = card_index_for_addr(start + word_count - 1) + 1;\n+#endif\n+  assert(start_index % ((size_t)1 << LogCardValsPerIntPtr) == 0, \"Expected a multiple of CardValsPerIntPtr\");\n+  assert(end_index % ((size_t)1 << LogCardValsPerIntPtr) == 0, \"Expected a multiple of CardValsPerIntPtr\");\n+\n+  \/\/ We'll access in groups of intptr_t worth of card entries\n+  intptr_t* const read_table  = (intptr_t*) &(_card_table->read_byte_map())[start_index];\n+  intptr_t* const write_table = (intptr_t*) &(_card_table->write_byte_map())[start_index];\n+\n+  \/\/ Avoid division, use shift instead\n+  assert(word_count % ((size_t)1 << (LogCardSizeInWords + LogCardValsPerIntPtr)) == 0, \"Expected a multiple of CardSizeInWords*CardValsPerIntPtr\");\n+  size_t const num = word_count >> (LogCardSizeInWords + LogCardValsPerIntPtr);\n+\n+  for (size_t i = 0; i < num; i++) {\n+    read_table[i] &= write_table[i];\n+  }\n+}\n+\n+\/\/ Destructively copy the write table to the read table, and clean the write table.\n+void ShenandoahDirectCardMarkRememberedSet::reset_remset(HeapWord* start, size_t word_count) {\n+  size_t start_index = card_index_for_addr(start);\n+#ifdef ASSERT\n+  \/\/ avoid querying card_index_for_addr() for an address past end of heap\n+  size_t end_index = card_index_for_addr(start + word_count - 1) + 1;\n+#endif\n+  assert(start_index % ((size_t)1 << LogCardValsPerIntPtr) == 0, \"Expected a multiple of CardValsPerIntPtr\");\n+  assert(end_index % ((size_t)1 << LogCardValsPerIntPtr) == 0, \"Expected a multiple of CardValsPerIntPtr\");\n+\n+  \/\/ We'll access in groups of intptr_t worth of card entries\n+  intptr_t* const read_table  = (intptr_t*) &(_card_table->read_byte_map())[start_index];\n+  intptr_t* const write_table = (intptr_t*) &(_card_table->write_byte_map())[start_index];\n+\n+  \/\/ Avoid division, use shift instead\n+  assert(word_count % ((size_t)1 << (LogCardSizeInWords + LogCardValsPerIntPtr)) == 0, \"Expected a multiple of CardSizeInWords*CardValsPerIntPtr\");\n+  size_t const num = word_count >> (LogCardSizeInWords + LogCardValsPerIntPtr);\n+\n+  for (size_t i = 0; i < num; i++) {\n+    read_table[i]  = write_table[i];\n+    write_table[i] = CardTable::clean_card_row_val();\n+  }\n+}\n+\n@@ -55,1 +109,3 @@\n-  _queue_set(queue_set), _old_queue_set(old_queue_set), _rp(rp), _work_list(work_list), _is_concurrent(is_concurrent) {}\n+  _queue_set(queue_set), _old_queue_set(old_queue_set), _rp(rp), _work_list(work_list), _is_concurrent(is_concurrent) {\n+  log_info(gc, remset)(\"Scan remembered set using bitmap: %s\", BOOL_TO_STR(ShenandoahHeap::heap()->is_old_bitmap_stable()));\n+}\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahScanRemembered.cpp","additions":58,"deletions":2,"binary":false,"changes":60,"status":"modified"},{"patch":"@@ -207,0 +207,3 @@\n+  const size_t LogCardValsPerIntPtr;    \/\/ the number of card values (entries) in an intptr_t\n+  const size_t LogCardSizeInWords;      \/\/ the size of a card in heap word units\n+\n@@ -242,0 +245,2 @@\n+  \/\/ Instead of swap_remset, the current implementation of concurrent remembered set scanning does reset_remset\n+  \/\/ in parallel threads, each invocation processing one entire HeapRegion at a time.\n@@ -244,12 +249,3 @@\n-  void merge_write_table(HeapWord* start, size_t word_count) {\n-    size_t card_index = card_index_for_addr(start);\n-    size_t num_cards = word_count \/ CardTable::card_size_in_words();\n-    size_t iterations = num_cards \/ (sizeof (intptr_t) \/ sizeof (CardValue));\n-    intptr_t* read_table_ptr = (intptr_t*) &(_card_table->read_byte_map())[card_index];\n-    intptr_t* write_table_ptr = (intptr_t*) &(_card_table->write_byte_map())[card_index];\n-    for (size_t i = 0; i < iterations; i++) {\n-      intptr_t card_value = *write_table_ptr;\n-      *read_table_ptr++ &= card_value;\n-      write_table_ptr++;\n-    }\n-  }\n+  \/\/ Merge any dirty values from write table into the read table, while leaving\n+  \/\/ the write table unchanged.\n+  void merge_write_table(HeapWord* start, size_t word_count);\n@@ -257,14 +253,2 @@\n-  \/\/ Instead of swap_remset, the current implementation of concurrent remembered set scanning does reset_remset\n-  \/\/ in parallel threads, each invocation processing one entire HeapRegion at a time.  Processing of a region\n-  \/\/ consists of copying the write table to the read table and cleaning the write table.\n-  void reset_remset(HeapWord* start, size_t word_count) {\n-    size_t card_index = card_index_for_addr(start);\n-    size_t num_cards = word_count \/ CardTable::card_size_in_words();\n-    size_t iterations = num_cards \/ (sizeof (intptr_t) \/ sizeof (CardValue));\n-    intptr_t* read_table_ptr = (intptr_t*) &(_card_table->read_byte_map())[card_index];\n-    intptr_t* write_table_ptr = (intptr_t*) &(_card_table->write_byte_map())[card_index];\n-    for (size_t i = 0; i < iterations; i++) {\n-      *read_table_ptr++ = *write_table_ptr;\n-      *write_table_ptr++ = CardTable::clean_card_row_val();\n-    }\n-  }\n+  \/\/ Destructively copy the write table to the read table, and clean the write table.\n+  void reset_remset(HeapWord* start, size_t word_count);\n@@ -274,1 +258,0 @@\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahScanRemembered.hpp","additions":10,"deletions":27,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -893,0 +893,1 @@\n+  log_info(gc, remset)(\"Scan remembered set using bitmap: %s\", BOOL_TO_STR(heap->is_old_bitmap_stable()));\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahScanRemembered.inline.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -28,2 +28,0 @@\n-#include \"gc\/shenandoah\/shenandoahStringDedup.hpp\"\n-\n@@ -31,0 +29,3 @@\n+#include \"gc\/shenandoah\/shenandoahHeap.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahStringDedup.hpp\"\n+#include \"oops\/markWord.hpp\"\n@@ -48,16 +49,4 @@\n-  const markWord mark = obj->mark();\n-\n-  \/\/ Having\/had displaced header, too risky to deal with them, skip\n-  if (mark == markWord::INFLATING() || mark.has_displaced_mark_helper()) {\n-    return false;\n-  }\n-\n-  if (StringDedup::is_below_threshold_age(mark.age())) {\n-    \/\/ Increase string age and enqueue it when it reaches age threshold\n-    markWord new_mark = mark.incr_age();\n-    if (mark == obj->cas_set_mark(new_mark, mark)) {\n-      return StringDedup::is_threshold_age(new_mark.age()) &&\n-             !dedup_requested(obj);\n-    }\n-  }\n-  return false;\n+  uint age = ShenandoahHeap::get_object_age(obj);\n+  return (age <= markWord::max_age) &&\n+         StringDedup::is_below_threshold_age(age) &&\n+         !dedup_requested(obj);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahStringDedup.inline.hpp","additions":7,"deletions":18,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -47,14 +47,14 @@\n-#define SHENANDOAH_RETURN_EVENT_MESSAGE(heap, generation_type, prefix, postfix) \\\n-  switch (generation_type) {                                                    \\\n-    case GLOBAL_NON_GEN:                                                        \\\n-      return prefix \"\" postfix;                                                 \\\n-    case GLOBAL_GEN:                                                            \\\n-      return prefix \" (GLOBAL)\" postfix;                                        \\\n-    case YOUNG:                                                                 \\\n-      return prefix \" (YOUNG)\" postfix;                                         \\\n-    case OLD:                                                                   \\\n-      return prefix \" (OLD)\" postfix;                                           \\\n-    default:                                                                    \\\n-      ShouldNotReachHere();                                                     \\\n-      return prefix \" (?)\" postfix;                                             \\\n-  }                                                                             \\\n+#define SHENANDOAH_RETURN_EVENT_MESSAGE(generation_type, prefix, postfix) \\\n+  switch (generation_type) {                                              \\\n+    case GLOBAL_NON_GEN:                                                  \\\n+      return prefix \"\" postfix;                                           \\\n+    case GLOBAL_GEN:                                                      \\\n+      return prefix \" (GLOBAL)\" postfix;                                  \\\n+    case YOUNG:                                                           \\\n+      return prefix \" (YOUNG)\" postfix;                                   \\\n+    case OLD:                                                             \\\n+      return prefix \" (OLD)\" postfix;                                     \\\n+    default:                                                              \\\n+      ShouldNotReachHere();                                               \\\n+      return prefix \" (?)\" postfix;                                       \\\n+  }                                                                       \\\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahUtils.hpp","additions":14,"deletions":14,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -836,2 +836,2 @@\n-      bool is_marking = (actual & ShenandoahHeap::MARKING)? 1: 0;\n-      bool is_marking_young_or_old = (actual & (ShenandoahHeap::YOUNG_MARKING | ShenandoahHeap::OLD_MARKING))? 1: 0;\n+      bool is_marking = (actual & ShenandoahHeap::MARKING);\n+      bool is_marking_young_or_old = (actual & (ShenandoahHeap::YOUNG_MARKING | ShenandoahHeap::OLD_MARKING));\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahVerifier.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -38,1 +38,12 @@\n-  product(double, ShenandoahMinOldGenGrowthPercent,12.5, EXPERIMENTAL,      \\\n+  product(uintx, ShenandoahGenerationalHumongousReserve, 0, EXPERIMENTAL,   \\\n+          \"(Generational mode only) What percent of the heap should be \"    \\\n+          \"reserved for humongous objects if possible.  Old-generation \"    \\\n+          \"collections will endeavor to evacuate old-gen regions within \"   \\\n+          \"this reserved area even if these regions do not contain high \"   \\\n+          \"percentage of garbage.  Setting a larger value will cause \"      \\\n+          \"more frequent old-gen collections.  A smaller value will \"       \\\n+          \"increase the likelihood that humongous object allocations \"      \\\n+          \"fail, resulting in stop-the-world full GCs.\")                    \\\n+          range(0,100)                                                      \\\n+                                                                            \\\n+  product(double, ShenandoahMinOldGenGrowthPercent, 12.5, EXPERIMENTAL,     \\\n@@ -73,1 +84,1 @@\n-          \" oldest cohort under the tenuring age for the last cycle.\" )     \\\n+          \"oldest cohort under the tenuring age for the last cycle.\" )      \\\n@@ -75,3 +86,6 @@\n-  product(uintx, ShenandoahGenerationalMinTenuringAge, 0, EXPERIMENTAL,     \\\n-          \"(Generational mode only) Floor for adaptive tenuring age.\")      \\\n-          range(0,16)                                                       \\\n+  product(uintx, ShenandoahGenerationalMinTenuringAge, 1, EXPERIMENTAL,     \\\n+          \"(Generational mode only) Floor for adaptive tenuring age. \"      \\\n+          \"Setting floor and ceiling to the same value fixes the tenuring \" \\\n+          \"age; setting both to 1 simulates a poor approximation to \"       \\\n+          \"AlwaysTenure, and setting both to 16 simulates NeverTenure.\")    \\\n+          range(1,16)                                                       \\\n@@ -81,4 +95,4 @@\n-          \"Setting min and max to the same value fixes the tenuring age, \"  \\\n-          \"setting both to 0 simulates Always Tenure, and setting both to \" \\\n-          \"16 simulates Never Tenure.\")                                     \\\n-          range(0,16)                                                       \\\n+          \"Setting floor and ceiling to the same value fixes the tenuring \" \\\n+          \"age; setting both to 1 simulates a poor approximation to \"       \\\n+          \"AlwaysTenure, and setting both to 16 simulates NeverTenure.\")    \\\n+          range(1,16)                                                       \\\n@@ -490,1 +504,1 @@\n-  product(uintx, ShenandoahFullGCThreshold, 64, EXPERIMENTAL,               \\\n+  product(uintx, ShenandoahFullGCThreshold, 3, EXPERIMENTAL,                \\\n@@ -521,1 +535,1 @@\n-          \"cause the old regions to be made parseable, rather than being \"  \\\n+          \"cause the old regions to be made parsable, rather than being \"   \\\n@@ -597,1 +611,1 @@\n-  notproduct(bool, ShenandoahEnableCardStats, trueInDebug,                  \\\n+  notproduct(bool, ShenandoahEnableCardStats, false,                        \\\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoah_globals.hpp","additions":26,"deletions":12,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -361,1 +361,1 @@\n-  EXPECT_EQ(old_generation_state(), ShenandoahOldGeneration::WAITING_FOR_FILL);\n+  EXPECT_EQ(old_generation_state(), ShenandoahOldGeneration::FILLING);\n","filename":"test\/hotspot\/gtest\/gc\/shenandoah\/test_shenandoahOldHeuristic.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -82,1 +82,1 @@\n-                    \"-XX:+UnlockExperimentalVMOptions\",\n+                    \"-XX:+UnlockExperimentalVMOptions\", \"-XX:ShenandoahNoProgressThreshold=12\",\n","filename":"test\/hotspot\/jtreg\/gc\/shenandoah\/oom\/TestThreadFailure.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}