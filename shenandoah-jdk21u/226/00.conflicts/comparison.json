{"files":[{"patch":"@@ -2,1 +2,1 @@\n-project=jdk-updates\n+project=shenandoah\n@@ -4,0 +4,1 @@\n+<<<<<<< HEAD\n@@ -5,0 +6,3 @@\n+=======\n+version=repo-shenandoah-21\n+>>>>>>> 92633517cb9ab59154d384d0dacbe97ade9de317\n@@ -26,1 +30,1 @@\n-reviewers=1\n+committers=1\n","filename":".jcheck\/conf","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -4,0 +4,1 @@\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n@@ -32,1 +33,0 @@\n-#include \"gc\/shenandoah\/shenandoahAsserts.hpp\"\n@@ -34,0 +34,2 @@\n+#include \"gc\/shenandoah\/shenandoahAsserts.hpp\"\n+#include \"gc\/shenandoah\/shenandoahController.hpp\"\n@@ -36,0 +38,5 @@\n+#include \"gc\/shenandoah\/shenandoahEvacTracker.hpp\"\n+#include \"gc\/shenandoah\/shenandoahGenerationType.hpp\"\n+#include \"gc\/shenandoah\/shenandoahGenerationSizer.hpp\"\n+#include \"gc\/shenandoah\/shenandoahMmuTracker.hpp\"\n+#include \"gc\/shenandoah\/mode\/shenandoahMode.hpp\"\n@@ -47,1 +54,0 @@\n-class ShenandoahControlThread;\n@@ -50,0 +56,3 @@\n+class ShenandoahGeneration;\n+class ShenandoahYoungGeneration;\n+class ShenandoahOldGeneration;\n@@ -64,0 +73,1 @@\n+class ShenandoahUncommitThread;\n@@ -115,3 +125,3 @@\n-\/\/ Shenandoah GC is low-pause concurrent GC that uses Brooks forwarding pointers\n-\/\/ to encode forwarding data. See BrooksPointer for details on forwarding data encoding.\n-\/\/ See ShenandoahControlThread for GC cycle structure.\n+\/\/ Shenandoah GC is low-pause concurrent GC that uses a load reference barrier\n+\/\/ for concurent evacuation and a snapshot-at-the-beginning write barrier for\n+\/\/ concurrent marking. See ShenandoahControlThread for GC cycle structure.\n@@ -126,0 +136,1 @@\n+\n@@ -128,0 +139,1 @@\n+  friend class ShenandoahOldGC;\n@@ -137,0 +149,13 @@\n+  \/\/ Indicates the generation whose collection is in\n+  \/\/ progress. Mutator threads aren't allowed to read\n+  \/\/ this field.\n+  ShenandoahGeneration* _gc_generation;\n+\n+  \/\/ This is set and cleared by only the VMThread\n+  \/\/ at each STW pause (safepoint) to the value seen in\n+  \/\/ _gc_generation. This allows the value to be always consistently\n+  \/\/ seen by all mutators as well as all GC worker threads.\n+  \/\/ In that sense, it's a stable snapshot of _gc_generation that is\n+  \/\/ updated at each STW pause associated with a ShenandoahVMOp.\n+  ShenandoahGeneration* _active_generation;\n+\n@@ -142,0 +167,22 @@\n+  ShenandoahGeneration* gc_generation() const {\n+    \/\/ We don't want this field read by a mutator thread\n+    assert(!Thread::current()->is_Java_thread(), \"Not allowed\");\n+    \/\/ value of _gc_generation field, see above\n+    return _gc_generation;\n+  }\n+\n+  ShenandoahGeneration* active_generation() const {\n+    \/\/ value of _active_generation field, see above\n+    return _active_generation;\n+  }\n+\n+  \/\/ Set the _gc_generation field\n+  void set_gc_generation(ShenandoahGeneration* generation);\n+\n+  \/\/ Copy the value in the _gc_generation field into\n+  \/\/ the _active_generation field: can only be called at\n+  \/\/ a safepoint by the VMThread.\n+  void set_active_generation();\n+\n+  ShenandoahHeuristics* heuristics();\n+\n@@ -154,2 +201,2 @@\n-  void initialize_heuristics();\n-\n+  virtual void initialize_heuristics();\n+  virtual void print_init_logger() const;\n@@ -176,2 +223,3 @@\n-           size_t _initial_size;\n-           size_t _minimum_size;\n+  size_t _initial_size;\n+  size_t _minimum_size;\n+\n@@ -180,1 +228,0 @@\n-  volatile size_t _used;\n@@ -182,1 +229,0 @@\n-  volatile size_t _bytes_allocated_since_gc_start;\n@@ -185,0 +231,2 @@\n+  void increase_used(const ShenandoahAllocRequest& req);\n+\n@@ -186,3 +234,4 @@\n-  void increase_used(size_t bytes);\n-  void decrease_used(size_t bytes);\n-  void set_used(size_t bytes);\n+  void increase_used(ShenandoahGeneration* generation, size_t bytes);\n+  void decrease_used(ShenandoahGeneration* generation, size_t bytes);\n+  void increase_humongous_waste(ShenandoahGeneration* generation, size_t bytes);\n+  void decrease_humongous_waste(ShenandoahGeneration* generation, size_t bytes);\n@@ -192,1 +241,0 @@\n-  void increase_allocated(size_t bytes);\n@@ -194,1 +242,0 @@\n-  size_t bytes_allocated_since_gc_start();\n@@ -207,0 +254,12 @@\n+\/\/ ---------- Periodic Tasks\n+\/\/\n+public:\n+  \/\/ Notify heuristics and region state change logger that the state of the heap has changed\n+  void notify_heap_changed();\n+\n+  \/\/ Force counters to update\n+  void set_forced_counters_update(bool value);\n+\n+  \/\/ Update counters if forced flag is set\n+  void handle_force_counters_update();\n+\n@@ -214,0 +273,2 @@\n+  virtual void initialize_controller();\n+\n@@ -230,1 +291,1 @@\n-  ShenandoahRegionIterator _update_refs_iterator;\n+  uint8_t* _affiliations;       \/\/ Holds array of enum ShenandoahAffiliation, including FREE status in non-generational mode\n@@ -239,1 +300,1 @@\n-  inline ShenandoahHeapRegion* const heap_region_containing(const void* addr) const;\n+  inline ShenandoahHeapRegion* heap_region_containing(const void* addr) const;\n@@ -242,1 +303,1 @@\n-  inline ShenandoahHeapRegion* const get_region(size_t region_idx) const;\n+  inline ShenandoahHeapRegion* get_region(size_t region_idx) const;\n@@ -247,0 +308,2 @@\n+  inline ShenandoahMmuTracker* mmu_tracker() { return &_mmu_tracker; };\n+\n@@ -262,0 +325,1 @@\n+    \/\/ For generational mode, it means either young or old marking, or both.\n@@ -268,1 +332,1 @@\n-    UPDATEREFS_BITPOS = 3,\n+    UPDATE_REFS_BITPOS = 3,\n@@ -272,0 +336,6 @@\n+\n+    \/\/ Young regions are under marking, need SATB barriers.\n+    YOUNG_MARKING_BITPOS = 5,\n+\n+    \/\/ Old regions are under marking, need SATB barriers.\n+    OLD_MARKING_BITPOS = 6\n@@ -279,1 +349,1 @@\n-    UPDATEREFS    = 1 << UPDATEREFS_BITPOS,\n+    UPDATE_REFS   = 1 << UPDATE_REFS_BITPOS,\n@@ -281,0 +351,2 @@\n+    YOUNG_MARKING = 1 << YOUNG_MARKING_BITPOS,\n+    OLD_MARKING   = 1 << OLD_MARKING_BITPOS\n@@ -286,0 +358,1 @@\n+  ShenandoahSharedFlag   _heap_changed;\n@@ -289,1 +362,0 @@\n-  ShenandoahSharedFlag   _progress_last_gc;\n@@ -292,2 +364,10 @@\n-  \/\/ This updates the singlular, global gc state. This must happen on a safepoint.\n-  void set_gc_state(uint mask, bool value);\n+  size_t _gc_no_progress_count;\n+\n+  \/\/ This updates the singular, global gc state. This call must happen on a safepoint.\n+  void set_gc_state_at_safepoint(uint mask, bool value);\n+\n+  \/\/ This also updates the global gc state, but does not need to be called on a safepoint.\n+  \/\/ Critically, this method will _not_ flag that the global gc state has changed and threads\n+  \/\/ will continue to use their thread local copy. This is expected to be used in conjunction\n+  \/\/ with a handshake operation to propagate the new gc state.\n+  void set_gc_state_concurrent(uint mask, bool value);\n@@ -296,0 +376,1 @@\n+  \/\/ This returns the raw value of the singular, global gc state.\n@@ -298,3 +379,13 @@\n-  \/\/ This copies the global gc state into a thread local variable for java threads.\n-  \/\/ It is primarily intended to support quick access at barriers.\n-  void propagate_gc_state_to_java_threads();\n+  \/\/ Compares the given state against either the global gc state, or the thread local state.\n+  \/\/ The global gc state may change on a safepoint and is the correct value to use until\n+  \/\/ the global gc state has been propagated to all threads (after which, this method will\n+  \/\/ compare against the thread local state). The thread local gc state may also be changed\n+  \/\/ by a handshake operation, in which case, this function continues using the updated thread\n+  \/\/ local value.\n+  bool is_gc_state(GCState state) const;\n+\n+  \/\/ This copies the global gc state into a thread local variable for all threads.\n+  \/\/ The thread local gc state is primarily intended to support quick access at barriers.\n+  \/\/ All threads are updated because in some cases the control thread or the vm thread may\n+  \/\/ need to execute the load reference barrier.\n+  void propagate_gc_state_to_all_threads();\n@@ -303,1 +394,1 @@\n-  \/\/ a safepoint and that any changes were propagated to java threads after the safepoint.\n+  \/\/ a safepoint and that any changes were propagated to threads after the safepoint.\n@@ -306,1 +397,8 @@\n-  void set_concurrent_mark_in_progress(bool in_progress);\n+  \/\/ Returns true if allocations have occurred in new regions or if regions have been\n+  \/\/ uncommitted since the previous calls. This call will reset the flag to false.\n+  bool has_changed() {\n+    return _heap_changed.try_unset();\n+  }\n+\n+  void set_concurrent_young_mark_in_progress(bool in_progress);\n+  void set_concurrent_old_mark_in_progress(bool in_progress);\n@@ -316,1 +414,0 @@\n-  inline bool is_stable() const;\n@@ -319,0 +416,2 @@\n+  inline bool is_concurrent_young_mark_in_progress() const;\n+  inline bool is_concurrent_old_mark_in_progress() const;\n@@ -329,0 +428,1 @@\n+  bool is_prepare_for_old_mark_in_progress() const;\n@@ -331,9 +431,1 @@\n-  enum CancelState {\n-    \/\/ Normal state. GC has not been cancelled and is open for cancellation.\n-    \/\/ Worker threads can suspend for safepoint.\n-    CANCELLABLE,\n-\n-    \/\/ GC has been cancelled. Worker threads can not suspend for\n-    \/\/ safepoint but must finish their work as soon as possible.\n-    CANCELLED\n-  };\n+  void manage_satb_barrier(bool active);\n@@ -341,2 +433,3 @@\n-  ShenandoahSharedEnumFlag<CancelState> _cancelled_gc;\n-  bool try_cancel_gc();\n+  \/\/ Records the time of the first successful cancellation request. This is used to measure\n+  \/\/ the responsiveness of the heuristic when starting a cycle.\n+  double _cancel_requested_time;\n@@ -344,1 +437,2 @@\n-public:\n+  \/\/ Indicates the reason the current GC has been cancelled (GCCause::_no_gc means the gc is not cancelled).\n+  ShenandoahSharedEnumFlag<GCCause::Cause> _cancelled_gc;\n@@ -346,0 +440,8 @@\n+  \/\/ Returns true if cancel request was successfully communicated.\n+  \/\/ Returns false if some other thread already communicated cancel\n+  \/\/ request.  A true return value does not mean GC has been\n+  \/\/ cancelled, only that the process of cancelling GC has begun.\n+  bool try_cancel_gc(GCCause::Cause cause);\n+\n+public:\n+  \/\/ True if gc has been cancelled\n@@ -347,0 +449,2 @@\n+\n+  \/\/ Used by workers in the GC cycle to detect cancellation and honor STS requirements\n@@ -349,1 +453,2 @@\n-  inline void clear_cancelled_gc();\n+  \/\/ This indicates the reason the last GC cycle was cancelled.\n+  inline GCCause::Cause cancelled_cause() const;\n@@ -351,1 +456,3 @@\n-  void cancel_gc(GCCause::Cause cause);\n+  \/\/ Clears the cancellation cause and optionally resets the oom handler (cancelling an\n+  \/\/ old mark does _not_ touch the oom handler).\n+  inline void clear_cancelled_gc(bool clear_oom_handler = true);\n@@ -353,4 +460,13 @@\n-public:\n-  \/\/ Elastic heap support\n-  void entry_uncommit(double shrink_before, size_t shrink_until);\n-  void op_uncommit(double shrink_before, size_t shrink_until);\n+  void cancel_concurrent_mark();\n+\n+  \/\/ Returns true if and only if this call caused a gc to be cancelled.\n+  bool cancel_gc(GCCause::Cause cause);\n+\n+  \/\/ Returns true if the soft maximum heap has been changed using management APIs.\n+  bool check_soft_max_changed();\n+\n+protected:\n+  \/\/ This is shared between shConcurrentGC and shDegenerateGC so that degenerated\n+  \/\/ GC can resume update refs from where the concurrent GC was cancelled. It is\n+  \/\/ also used in shGenerationalHeap, which uses a different closure for update refs.\n+  ShenandoahRegionIterator _update_refs_iterator;\n@@ -360,3 +476,0 @@\n-  \/\/ Reset bitmap, prepare regions for new GC cycle\n-  void prepare_gc();\n-  void prepare_regions_and_collection_set(bool concurrent);\n@@ -364,1 +477,1 @@\n-  void evacuate_collection_set(bool concurrent);\n+  virtual void evacuate_collection_set(bool concurrent);\n@@ -371,2 +484,9 @@\n-  void prepare_update_heap_references(bool concurrent);\n-  void update_heap_references(bool concurrent);\n+  void prepare_update_heap_references();\n+\n+  \/\/ Retires LABs used for evacuation\n+  void concurrent_prepare_for_update_refs();\n+\n+  \/\/ Turn off weak roots flag, purge old satb buffers in generational mode\n+  void concurrent_final_roots(HandshakeClosure* handshake_closure = nullptr);\n+\n+  virtual void update_heap_references(bool concurrent);\n@@ -375,1 +495,1 @@\n-  void rebuild_free_set(bool concurrent);\n+  virtual void final_update_refs_update_region_states();\n@@ -380,2 +500,23 @@\n-  void notify_gc_progress()    { _progress_last_gc.set();   }\n-  void notify_gc_no_progress() { _progress_last_gc.unset(); }\n+  void rebuild_free_set(bool concurrent);\n+  void notify_gc_progress();\n+  void notify_gc_no_progress();\n+  size_t get_gc_no_progress_count() const;\n+\n+  \/\/ The uncommit thread targets soft max heap, notify this thread when that value has changed.\n+  void notify_soft_max_changed();\n+\n+  \/\/ An explicit GC request may have freed regions, notify the uncommit thread.\n+  void notify_explicit_gc_requested();\n+\n+private:\n+  ShenandoahGeneration*  _global_generation;\n+\n+protected:\n+  \/\/ The control thread presides over concurrent collection cycles\n+  ShenandoahController*  _control_thread;\n+\n+  \/\/ The uncommit thread periodically attempts to uncommit regions that have been empty for longer than ShenandoahUncommitDelay\n+  ShenandoahUncommitThread*  _uncommit_thread;\n+\n+  ShenandoahYoungGeneration* _young_generation;\n+  ShenandoahOldGeneration*   _old_generation;\n@@ -383,2 +524,0 @@\n-\/\/\n-\/\/ Mark support\n@@ -386,1 +525,0 @@\n-  ShenandoahControlThread*   _control_thread;\n@@ -389,1 +527,0 @@\n-  ShenandoahHeuristics*      _heuristics;\n@@ -394,3 +531,2 @@\n-  ShenandoahPhaseTimings*    _phase_timings;\n-\n-  ShenandoahControlThread*   control_thread()          { return _control_thread;    }\n+  ShenandoahPhaseTimings*       _phase_timings;\n+  ShenandoahMmuTracker          _mmu_tracker;\n@@ -399,0 +535,15 @@\n+  ShenandoahController*   control_thread() const { return _control_thread; }\n+\n+  ShenandoahGeneration*      global_generation() const { return _global_generation; }\n+  ShenandoahYoungGeneration* young_generation()  const {\n+    assert(mode()->is_generational(), \"Young generation requires generational mode\");\n+    return _young_generation;\n+  }\n+\n+  ShenandoahOldGeneration*   old_generation()    const {\n+    assert(mode()->is_generational(), \"Old generation requires generational mode\");\n+    return _old_generation;\n+  }\n+\n+  ShenandoahGeneration*      generation_for(ShenandoahAffiliation affiliation) const;\n+\n@@ -401,1 +552,0 @@\n-  ShenandoahHeuristics*      heuristics()        const { return _heuristics;        }\n@@ -407,0 +557,5 @@\n+  ShenandoahEvacOOMHandler*  oom_evac_handler()        { return &_oom_evac_handler; }\n+\n+  void on_cycle_start(GCCause::Cause cause, ShenandoahGeneration* generation);\n+  void on_cycle_end(ShenandoahGeneration* generation);\n+\n@@ -422,1 +577,1 @@\n-  ShenandoahMonitoringSupport* monitoring_support()          { return _monitoring_support;    }\n+  ShenandoahMonitoringSupport* monitoring_support() const    { return _monitoring_support;    }\n@@ -433,8 +588,0 @@\n-\/\/ ---------- Reference processing\n-\/\/\n-private:\n-  ShenandoahReferenceProcessor* const _ref_processor;\n-\n-public:\n-  ShenandoahReferenceProcessor* ref_processor() { return _ref_processor; }\n-\n@@ -459,0 +606,3 @@\n+  inline void assert_lock_for_affiliation(ShenandoahAffiliation orig_affiliation,\n+                                          ShenandoahAffiliation new_affiliation);\n+\n@@ -476,0 +626,15 @@\n+  \/\/ Returns true if the given oop belongs to a generation that is actively being collected.\n+  inline bool is_in_active_generation(oop obj) const;\n+  inline bool is_in_young(const void* p) const;\n+  inline bool is_in_old(const void* p) const;\n+\n+  \/\/ Returns true iff the young generation is being collected and the given pointer\n+  \/\/ is in the old generation. This is used to prevent the young collection from treating\n+  \/\/ such an object as unreachable.\n+  inline bool is_in_old_during_young_collection(oop obj) const;\n+\n+  inline ShenandoahAffiliation region_affiliation(const ShenandoahHeapRegion* r) const;\n+  inline void set_affiliation(ShenandoahHeapRegion* r, ShenandoahAffiliation new_affiliation);\n+\n+  inline ShenandoahAffiliation region_affiliation(size_t index) const;\n+\n@@ -528,0 +693,3 @@\n+protected:\n+  inline HeapWord* allocate_from_gclab(Thread* thread, size_t size);\n+\n@@ -530,1 +698,0 @@\n-  inline HeapWord* allocate_from_gclab(Thread* thread, size_t size);\n@@ -534,0 +701,3 @@\n+  \/\/ We want to retry an unsuccessful attempt at allocation until at least a full gc.\n+  bool should_retry_allocation(size_t original_full_gc_count) const;\n+\n@@ -541,1 +711,1 @@\n-  void notify_mutator_alloc_words(size_t words, bool waste);\n+  void notify_mutator_alloc_words(size_t words, size_t waste);\n@@ -577,1 +747,1 @@\n-  inline ShenandoahMarkingContext* complete_marking_context() const;\n+  \/\/ Return the marking context regardless of the completeness status.\n@@ -579,2 +749,0 @@\n-  inline void mark_complete_marking_context();\n-  inline void mark_incomplete_marking_context();\n@@ -591,2 +759,0 @@\n-  void reset_mark_bitmap();\n-\n@@ -601,0 +767,14 @@\n+  \/\/ During concurrent reset, the control thread will zero out the mark bitmaps for committed regions.\n+  \/\/ This cannot happen when the uncommit thread is simultaneously trying to uncommit regions and their bitmaps.\n+  \/\/ To prevent these threads from working at the same time, we provide these methods for the control thread to\n+  \/\/ prevent the uncommit thread from working while a collection cycle is in progress.\n+\n+  \/\/ Forbid uncommits (will stop and wait if regions are being uncommitted)\n+  void forbid_uncommit();\n+\n+  \/\/ Allow the uncommit thread to process regions\n+  void allow_uncommit();\n+#ifdef ASSERT\n+  bool is_uncommit_in_progress();\n+#endif\n+\n@@ -613,0 +793,2 @@\n+  oop try_evacuate_object(oop src, Thread* thread, ShenandoahHeapRegion* from_region, ShenandoahAffiliation target_gen);\n+\n@@ -624,1 +806,1 @@\n-  \/\/ Evacuates object src. Returns the evacuated object, either evacuated\n+  \/\/ Evacuates or promotes object src. Returns the evacuated object, either evacuated\n@@ -626,1 +808,1 @@\n-  inline oop evacuate_object(oop src, Thread* thread);\n+  virtual oop evacuate_object(oop src, Thread* thread);\n@@ -654,0 +836,12 @@\n+<<<<<<< HEAD\n+=======\n+\n+  static inline void increase_object_age(oop obj, uint additional_age);\n+\n+  \/\/ Return the object's age, or a sentinel value when the age can't\n+  \/\/ necessarily be determined because of concurrent locking by the\n+  \/\/ mutator\n+  static inline uint get_object_age(oop obj);\n+\n+  void log_heap_status(const char *msg) const;\n+>>>>>>> 92633517cb9ab59154d384d0dacbe97ade9de317\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.hpp","additions":277,"deletions":83,"binary":false,"changes":360,"status":"modified"}]}