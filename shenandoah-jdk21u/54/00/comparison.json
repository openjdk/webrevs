{"files":[{"patch":"@@ -144,10 +144,21 @@\n-  \/\/ If GC was cancelled before final mark, then the safepoint operation will do nothing\n-  \/\/ and the concurrent mark will still be in progress. In this case it is safe to resume\n-  \/\/ the degenerated cycle from the marking phase. On the other hand, if the GC is cancelled\n-  \/\/ after final mark (but before this check), then the final mark safepoint operation\n-  \/\/ will have finished the mark (setting concurrent mark in progress to false). Final mark\n-  \/\/ will also have setup state (in concurrent stack processing) that will not be safe to\n-  \/\/ resume from the marking phase in the degenerated cycle. That is, if the cancellation\n-  \/\/ occurred after final mark, we must resume the degenerated cycle after the marking phase.\n-  if (_generation->is_concurrent_mark_in_progress() && check_cancellation_and_abort(ShenandoahDegenPoint::_degenerated_mark)) {\n-    assert(!heap->is_concurrent_weak_root_in_progress(), \"Weak roots should not be in progress when concurrent mark is in progress\");\n+  \/\/ If the GC was cancelled just before final mark (but after the preceding cancellation check),\n+  \/\/ then the safepoint operation will do nothing and the concurrent mark will still be in progress.\n+  \/\/ In this case it is safe (and necessary) to resume the degenerated cycle from the marking phase.\n+  \/\/\n+  \/\/ On the other hand, if the GC is cancelled after final mark (but before this check), then the\n+  \/\/ final mark safepoint operation will have finished the mark (setting concurrent mark in progress\n+  \/\/ to false). In this case (final mark has completed), we need control to fall past the next\n+  \/\/ cancellation check and resume the degenerated cycle from the evacuation phase.\n+  if (_generation->is_concurrent_mark_in_progress()) {\n+    \/\/ If the concurrent mark is still in progress after the final mark safepoint, then the GC has\n+    \/\/ been cancelled. The degenerated cycle must resume from the marking phase. Without this check,\n+    \/\/ the non-generational mode may fall all the way to the end of this collect routine without\n+    \/\/ having done anything (besides mark most of the heap). Without having collected anything, we\n+    \/\/ can expect an 'out of cycle' degenerated GC which will again mark the entire heap. This is\n+    \/\/ not optimal.\n+    \/\/ For the generational mode, we cannot allow this. The generational mode relies on marking\n+    \/\/ (including the final mark) to rebuild portions of the card table. If the generational mode does\n+    \/\/ not complete marking after it has swapped the card tables, the root set on subsequent GCs will\n+    \/\/ be incomplete, heap corruption may follow.\n+    bool cancelled = check_cancellation_and_abort(ShenandoahDegenPoint::_degenerated_mark);\n+    assert(cancelled, \"GC must have been cancelled between concurrent and final mark\");\n@@ -234,25 +245,1 @@\n-    if (!heap->old_generation()->is_parseable()) {\n-      \/\/ Class unloading may render the card offsets unusable, so we must rebuild them before\n-      \/\/ the next remembered set scan. We _could_ let the control thread do this sometime after\n-      \/\/ the global cycle has completed and before the next young collection, but under memory\n-      \/\/ pressure the control thread may not have the time (that is, because it's running back\n-      \/\/ to back GCs). In that scenario, we would have to make the old regions parsable before\n-      \/\/ we could start a young collection. This could delay the start of the young cycle and\n-      \/\/ throw off the heuristics.\n-      entry_global_coalesce_and_fill();\n-    }\n-\n-    ShenandoahGenerationalHeap::TransferResult result;\n-    {\n-      ShenandoahGenerationalHeap* gen_heap = ShenandoahGenerationalHeap::heap();\n-      ShenandoahHeapLocker locker(gen_heap->lock());\n-\n-      result = gen_heap->balance_generations();\n-      gen_heap->reset_generation_reserves();\n-    }\n-\n-    LogTarget(Info, gc, ergo) lt;\n-    if (lt.is_enabled()) {\n-      LogStream ls(lt);\n-      result.print_on(\"Concurrent GC\", &ls);\n-    }\n+    ShenandoahGenerationalHeap::heap()->complete_concurrent_cycle();\n@@ -665,0 +652,1 @@\n+    shenandoah_assert_generational();\n@@ -752,49 +740,9 @@\n-    if (heap->mode()->is_generational()) {\n-      if (!heap->collection_set()->is_empty() || heap->old_generation()->has_in_place_promotions()) {\n-        \/\/ Even if the collection set is empty, we need to do evacuation if there are regions to be promoted in place.\n-        \/\/ Concurrent evacuation takes responsibility for registering objects and setting the remembered set cards to dirty.\n-\n-        LogTarget(Debug, gc, cset) lt;\n-        if (lt.is_enabled()) {\n-          ResourceMark rm;\n-          LogStream ls(lt);\n-          heap->collection_set()->print_on(&ls);\n-        }\n-\n-        if (ShenandoahVerify) {\n-          heap->verifier()->verify_before_evacuation();\n-        }\n-\n-        heap->set_evacuation_in_progress(true);\n-\n-        \/\/ Verify before arming for concurrent processing.\n-        \/\/ Otherwise, verification can trigger stack processing.\n-        if (ShenandoahVerify) {\n-          heap->verifier()->verify_during_evacuation();\n-        }\n-\n-        \/\/ Generational mode may promote objects in place during the evacuation phase.\n-        \/\/ If that is the only reason we are evacuating, we don't need to update references\n-        \/\/ and there will be no forwarded objects on the heap.\n-        heap->set_has_forwarded_objects(!heap->collection_set()->is_empty());\n-\n-        \/\/ Arm nmethods\/stack for concurrent processing\n-        if (!heap->collection_set()->is_empty()) {\n-          \/\/ Iff objects will be evaluated, arm the nmethod barriers. These will be disarmed\n-          \/\/ under the same condition (established in prepare_concurrent_roots) after strong\n-          \/\/ root evacuation has completed (see op_strong_roots).\n-          ShenandoahCodeRoots::arm_nmethods_for_evac();\n-          ShenandoahStackWatermark::change_epoch_id();\n-        }\n-\n-        if (ShenandoahPacing) {\n-          heap->pacer()->setup_for_evac();\n-        }\n-      } else {\n-        if (ShenandoahVerify) {\n-          heap->verifier()->verify_after_concmark();\n-        }\n-\n-        if (VerifyAfterGC) {\n-          Universe::verify();\n-        }\n+    if (!heap->collection_set()->is_empty() || has_in_place_promotions(heap)) {\n+      \/\/ Even if the collection set is empty, we need to do evacuation if there are regions to be promoted in place.\n+      \/\/ Concurrent evacuation takes responsibility for registering objects and setting the remembered set cards to dirty.\n+\n+      LogTarget(Debug, gc, cset) lt;\n+      if (lt.is_enabled()) {\n+        ResourceMark rm;\n+        LogStream ls(lt);\n+        heap->collection_set()->print_on(&ls);\n@@ -802,9 +750,0 @@\n-    } else {\n-      \/\/ Not is_generational()\n-      if (!heap->collection_set()->is_empty()) {\n-        LogTarget(Debug, gc, ergo) lt;\n-        if (lt.is_enabled()) {\n-          ResourceMark rm;\n-          LogStream ls(lt);\n-          heap->collection_set()->print_on(&ls);\n-        }\n@@ -812,3 +751,3 @@\n-        if (ShenandoahVerify) {\n-          heap->verifier()->verify_before_evacuation();\n-        }\n+      if (ShenandoahVerify) {\n+        heap->verifier()->verify_before_evacuation();\n+      }\n@@ -816,1 +755,2 @@\n-        heap->set_evacuation_in_progress(true);\n+      \/\/ TODO: Do we need to set this if we are only promoting regions in place? We don't need the barriers on for that.\n+      heap->set_evacuation_in_progress(true);\n@@ -818,5 +758,5 @@\n-        \/\/ Verify before arming for concurrent processing.\n-        \/\/ Otherwise, verification can trigger stack processing.\n-        if (ShenandoahVerify) {\n-          heap->verifier()->verify_during_evacuation();\n-        }\n+      \/\/ Verify before arming for concurrent processing.\n+      \/\/ Otherwise, verification can trigger stack processing.\n+      if (ShenandoahVerify) {\n+        heap->verifier()->verify_during_evacuation();\n+      }\n@@ -824,2 +764,4 @@\n-        \/\/ From here on, we need to update references.\n-        heap->set_has_forwarded_objects(true);\n+      \/\/ Generational mode may promote objects in place during the evacuation phase.\n+      \/\/ If that is the only reason we are evacuating, we don't need to update references\n+      \/\/ and there will be no forwarded objects on the heap.\n+      heap->set_has_forwarded_objects(!heap->collection_set()->is_empty());\n@@ -827,1 +769,5 @@\n-        \/\/ Arm nmethods\/stack for concurrent processing\n+      \/\/ Arm nmethods\/stack for concurrent processing\n+      if (!heap->collection_set()->is_empty()) {\n+        \/\/ Iff objects will be evaluated, arm the nmethod barriers. These will be disarmed\n+        \/\/ under the same condition (established in prepare_concurrent_roots) after strong\n+        \/\/ root evacuation has completed (see op_strong_roots).\n@@ -830,0 +776,1 @@\n+      }\n@@ -831,11 +778,10 @@\n-        if (ShenandoahPacing) {\n-          heap->pacer()->setup_for_evac();\n-        }\n-      } else {\n-        if (ShenandoahVerify) {\n-          heap->verifier()->verify_after_concmark();\n-        }\n-\n-        if (VerifyAfterGC) {\n-          Universe::verify();\n-        }\n+      if (ShenandoahPacing) {\n+        heap->pacer()->setup_for_evac();\n+      }\n+    } else {\n+      if (ShenandoahVerify) {\n+        heap->verifier()->verify_after_concmark();\n+      }\n+\n+      if (VerifyAfterGC) {\n+        Universe::verify();\n@@ -847,0 +793,5 @@\n+bool ShenandoahConcurrentGC::has_in_place_promotions(ShenandoahHeap* heap) {\n+  return heap->mode()->is_generational() && heap->old_generation()->has_in_place_promotions();\n+}\n+\n+template<bool GENERATIONAL>\n@@ -850,1 +801,0 @@\n-\n@@ -852,3 +802,1 @@\n-  ShenandoahConcurrentEvacThreadClosure(OopClosure* oops);\n-  void do_thread(Thread* thread);\n-};\n+  explicit ShenandoahConcurrentEvacThreadClosure(OopClosure* oops) : _oops(oops) {}\n@@ -856,9 +804,8 @@\n-ShenandoahConcurrentEvacThreadClosure::ShenandoahConcurrentEvacThreadClosure(OopClosure* oops) :\n-  _oops(oops) {\n-}\n-\n-void ShenandoahConcurrentEvacThreadClosure::do_thread(Thread* thread) {\n-  JavaThread* const jt = JavaThread::cast(thread);\n-  StackWatermarkSet::finish_processing(jt, _oops, StackWatermarkKind::gc);\n-  ShenandoahThreadLocalData::enable_plab_promotions(thread);\n-}\n+  void do_thread(Thread* thread) override {\n+    JavaThread* const jt = JavaThread::cast(thread);\n+    StackWatermarkSet::finish_processing(jt, _oops, StackWatermarkKind::gc);\n+    if (GENERATIONAL) {\n+      ShenandoahThreadLocalData::enable_plab_promotions(thread);\n+    }\n+  }\n+};\n@@ -866,0 +813,1 @@\n+template<bool GENERATIONAL>\n@@ -871,1 +819,1 @@\n-  ShenandoahConcurrentEvacUpdateThreadTask(uint n_workers) :\n+  explicit ShenandoahConcurrentEvacUpdateThreadTask(uint n_workers) :\n@@ -876,3 +824,5 @@\n-  void work(uint worker_id) {\n-    Thread* worker_thread = Thread::current();\n-    ShenandoahThreadLocalData::enable_plab_promotions(worker_thread);\n+  void work(uint worker_id) override {\n+    if (GENERATIONAL) {\n+      Thread* worker_thread = Thread::current();\n+      ShenandoahThreadLocalData::enable_plab_promotions(worker_thread);\n+    }\n@@ -883,1 +833,1 @@\n-    ShenandoahConcurrentEvacThreadClosure thr_cl(&oops_cl);\n+    ShenandoahConcurrentEvacThreadClosure<GENERATIONAL> thr_cl(&oops_cl);\n@@ -892,2 +842,7 @@\n-  ShenandoahConcurrentEvacUpdateThreadTask task(heap->workers()->active_workers());\n-  heap->workers()->run_task(&task);\n+  if (heap->mode()->is_generational()) {\n+    ShenandoahConcurrentEvacUpdateThreadTask<true> task(heap->workers()->active_workers());\n+    heap->workers()->run_task(&task);\n+  } else {\n+    ShenandoahConcurrentEvacUpdateThreadTask<false> task(heap->workers()->active_workers());\n+    heap->workers()->run_task(&task);\n+  }\n@@ -1271,13 +1226,1 @@\n-    ShenandoahMarkingContext *ctx = heap->complete_marking_context();\n-    for (size_t i = 0; i < heap->num_regions(); i++) {\n-      ShenandoahHeapRegion *r = heap->get_region(i);\n-      if (r->is_active() && r->is_young()) {\n-        HeapWord* tams = ctx->top_at_mark_start(r);\n-        HeapWord* top = r->top();\n-        if (top > tams) {\n-          r->reset_age();\n-        } else if (ShenandoahGenerationalHeap::heap()->is_aging_cycle()) {\n-          r->increment_age();\n-        }\n-      }\n-    }\n+    ShenandoahGenerationalHeap::heap()->update_region_ages();\n@@ -1287,19 +1230,0 @@\n-void ShenandoahConcurrentGC::entry_global_coalesce_and_fill() {\n-  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n-\n-  const char* msg = \"Coalescing and filling old regions in global collect\";\n-  ShenandoahConcurrentPhase gc_phase(msg, ShenandoahPhaseTimings::conc_coalesce_and_fill);\n-\n-  TraceCollectorStats tcs(heap->monitoring_support()->concurrent_collection_counters());\n-  EventMark em(\"%s\", msg);\n-  ShenandoahWorkerScope scope(heap->workers(),\n-                              ShenandoahWorkerPolicy::calc_workers_for_conc_marking(),\n-                              \"concurrent coalesce and fill\");\n-\n-  op_global_coalesce_and_fill();\n-}\n-\n-void ShenandoahConcurrentGC::op_global_coalesce_and_fill() {\n-  ShenandoahGenerationalHeap::heap()->coalesce_and_fill_old_regions(true);\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahConcurrentGC.cpp","additions":92,"deletions":168,"binary":false,"changes":260,"status":"modified"},{"patch":"@@ -107,1 +107,1 @@\n-  void entry_global_coalesce_and_fill();\n+\n@@ -127,1 +127,1 @@\n-  void op_global_coalesce_and_fill();\n+\n@@ -136,0 +136,2 @@\n+  static bool has_in_place_promotions(ShenandoahHeap* heap) ;\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahConcurrentGC.hpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -167,1 +167,0 @@\n-      }\n@@ -169,7 +168,8 @@\n-      if (_degen_point == ShenandoahDegenPoint::_degenerated_roots) {\n-        \/\/ We only need this if the concurrent cycle has already swapped the card tables.\n-        \/\/ Marking will use the 'read' table, but interesting pointers may have been\n-        \/\/ recorded in the 'write' table in the time between the cancelled concurrent cycle\n-        \/\/ and this degenerated cycle. These pointers need to be included the 'read' table\n-        \/\/ used to scan the remembered set during the STW mark which follows here.\n-        _generation->merge_write_table();\n+        if (_degen_point == ShenandoahDegenPoint::_degenerated_roots) {\n+          \/\/ We only need this if the concurrent cycle has already swapped the card tables.\n+          \/\/ Marking will use the 'read' table, but interesting pointers may have been\n+          \/\/ recorded in the 'write' table in the time between the cancelled concurrent cycle\n+          \/\/ and this degenerated cycle. These pointers need to be included the 'read' table\n+          \/\/ used to scan the remembered set during the STW mark which follows here.\n+          _generation->merge_write_table();\n+        }\n@@ -283,7 +283,0 @@\n-      if (heap->mode()->is_generational() && heap->is_concurrent_old_mark_in_progress()) {\n-        \/\/ This is still necessary for degenerated cycles because the degeneration point may occur\n-        \/\/ after final mark of the young generation. See ShenandoahConcurrentGC::op_final_updaterefs for\n-        \/\/ a more detailed explanation.\n-        heap->old_generation()->transfer_pointers_from_satb();\n-      }\n-\n@@ -291,1 +284,1 @@\n-      \/\/ We defer generation resizing actions until after cset regions have been recycled.\n+\n@@ -293,6 +286,1 @@\n-        auto result = ShenandoahGenerationalHeap::heap()->balance_generations();\n-        LogTarget(Info, gc, ergo) lt;\n-        if (lt.is_enabled()) {\n-          LogStream ls(lt);\n-          result.print_on(\"Degenerated GC\", &ls);\n-        }\n+        ShenandoahGenerationalHeap::heap()->complete_degenerated_cycle();\n@@ -300,0 +288,1 @@\n+\n@@ -305,10 +294,0 @@\n-  if (heap->mode()->is_generational()) {\n-    \/\/ In case degeneration interrupted concurrent evacuation or update references, we need to clean up transient state.\n-    \/\/ Otherwise, these actions have no effect.\n-    ShenandoahGenerationalHeap::heap()->reset_generation_reserves();\n-\n-    if (!ShenandoahGenerationalHeap::heap()->old_generation()->is_parseable()) {\n-      op_global_coalesce_and_fill();\n-    }\n-  }\n-\n@@ -406,5 +385,0 @@\n-void ShenandoahDegenGC::op_global_coalesce_and_fill() {\n-  ShenandoahGCPhase phase(ShenandoahPhaseTimings::degen_gc_coalesce_and_fill);\n-  ShenandoahGenerationalHeap::heap()->coalesce_and_fill_old_regions(false);\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahDegeneratedGC.cpp","additions":11,"deletions":37,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -61,3 +61,0 @@\n-  \/\/ This will rebuild card offsets, which is necessary if classes were unloaded\n-  void op_global_coalesce_and_fill();\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahDegeneratedGC.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"gc\/shenandoah\/shenandoahMonitoringSupport.hpp\"\n@@ -41,0 +42,1 @@\n+#include \"gc\/shenandoah\/shenandoahWorkerPolicy.hpp\"\n@@ -44,0 +46,1 @@\n+#include \"utilities\/events.hpp\"\n@@ -947,0 +950,83 @@\n+\n+void ShenandoahGenerationalHeap::complete_degenerated_cycle() {\n+  shenandoah_assert_heaplocked_or_safepoint();\n+  if (is_concurrent_old_mark_in_progress()) {\n+    \/\/ This is still necessary for degenerated cycles because the degeneration point may occur\n+    \/\/ after final mark of the young generation. See ShenandoahConcurrentGC::op_final_updaterefs for\n+    \/\/ a more detailed explanation.\n+    old_generation()->transfer_pointers_from_satb();\n+  }\n+\n+  \/\/ We defer generation resizing actions until after cset regions have been recycled.\n+  TransferResult result = balance_generations();\n+  LogTarget(Info, gc, ergo) lt;\n+  if (lt.is_enabled()) {\n+    LogStream ls(lt);\n+    result.print_on(\"Degenerated GC\", &ls);\n+  }\n+\n+  \/\/ In case degeneration interrupted concurrent evacuation or update references, we need to clean up\n+  \/\/ transient state. Otherwise, these actions have no effect.\n+  reset_generation_reserves();\n+\n+  if (!old_generation()->is_parseable()) {\n+    ShenandoahGCPhase phase(ShenandoahPhaseTimings::degen_gc_coalesce_and_fill);\n+    coalesce_and_fill_old_regions(false);\n+  }\n+}\n+\n+void ShenandoahGenerationalHeap::complete_concurrent_cycle() {\n+  if (!old_generation()->is_parseable()) {\n+    \/\/ Class unloading may render the card offsets unusable, so we must rebuild them before\n+    \/\/ the next remembered set scan. We _could_ let the control thread do this sometime after\n+    \/\/ the global cycle has completed and before the next young collection, but under memory\n+    \/\/ pressure the control thread may not have the time (that is, because it's running back\n+    \/\/ to back GCs). In that scenario, we would have to make the old regions parsable before\n+    \/\/ we could start a young collection. This could delay the start of the young cycle and\n+    \/\/ throw off the heuristics.\n+    entry_global_coalesce_and_fill();\n+  }\n+\n+  TransferResult result;\n+  {\n+    ShenandoahHeapLocker locker(lock());\n+\n+    result = balance_generations();\n+    reset_generation_reserves();\n+  }\n+\n+  LogTarget(Info, gc, ergo) lt;\n+  if (lt.is_enabled()) {\n+    LogStream ls(lt);\n+    result.print_on(\"Concurrent GC\", &ls);\n+  }\n+}\n+\n+void ShenandoahGenerationalHeap::entry_global_coalesce_and_fill() {\n+  const char* msg = \"Coalescing and filling old regions\";\n+  ShenandoahConcurrentPhase gc_phase(msg, ShenandoahPhaseTimings::conc_coalesce_and_fill);\n+\n+  TraceCollectorStats tcs(monitoring_support()->concurrent_collection_counters());\n+  EventMark em(\"%s\", msg);\n+  ShenandoahWorkerScope scope(workers(),\n+                              ShenandoahWorkerPolicy::calc_workers_for_conc_marking(),\n+                              \"concurrent coalesce and fill\");\n+\n+  coalesce_and_fill_old_regions(true);\n+}\n+\n+void ShenandoahGenerationalHeap::update_region_ages() {\n+  ShenandoahMarkingContext *ctx = complete_marking_context();\n+  for (size_t i = 0; i < num_regions(); i++) {\n+    ShenandoahHeapRegion *r = get_region(i);\n+    if (r->is_active() && r->is_young()) {\n+      HeapWord* tams = ctx->top_at_mark_start(r);\n+      HeapWord* top = r->top();\n+      if (top > tams) {\n+        r->reset_age();\n+      } else if (is_aging_cycle()) {\n+        r->increment_age();\n+      }\n+    }\n+  }\n+}\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalHeap.cpp","additions":86,"deletions":0,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -53,0 +53,4 @@\n+  \/\/ Ages regions that haven't been used for allocations in the current cycle.\n+  \/\/ Resets ages for regions that have been used for allocations.\n+  void update_region_ages();\n+\n@@ -65,0 +69,1 @@\n+\n@@ -106,3 +111,3 @@\n-  \/\/ Makes old regions parsable\n-  void coalesce_and_fill_old_regions(bool concurrent);\n-\n+  \/\/ Balances generations, coalesces and fills old regions if necessary\n+  void complete_degenerated_cycle();\n+  void complete_concurrent_cycle();\n@@ -111,0 +116,4 @@\n+  void entry_global_coalesce_and_fill();\n+\n+  \/\/ Makes old regions parsable. This will also rebuild card offsets, which is necessary if classes were unloaded\n+  void coalesce_and_fill_old_regions(bool concurrent);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalHeap.hpp","additions":12,"deletions":3,"binary":false,"changes":15,"status":"modified"}]}