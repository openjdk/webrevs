{"files":[{"patch":"@@ -4,1 +4,1 @@\n-version=21.0.3\n+version=21.0.4\n","filename":".jcheck\/conf","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -393,4 +393,4 @@\n-class Decoder : public RelocActions {\n-  virtual reloc_insn adrpMem() { return &Decoder::adrpMem_impl; }\n-  virtual reloc_insn adrpAdd() { return &Decoder::adrpAdd_impl; }\n-  virtual reloc_insn adrpMovk() { return &Decoder::adrpMovk_impl; }\n+class AArch64Decoder : public RelocActions {\n+  virtual reloc_insn adrpMem() { return &AArch64Decoder::adrpMem_impl; }\n+  virtual reloc_insn adrpAdd() { return &AArch64Decoder::adrpAdd_impl; }\n+  virtual reloc_insn adrpMovk() { return &AArch64Decoder::adrpMovk_impl; }\n@@ -399,1 +399,1 @@\n-  Decoder(address insn_addr, uint32_t insn) : RelocActions(insn_addr, insn) {}\n+  AArch64Decoder(address insn_addr, uint32_t insn) : RelocActions(insn_addr, insn) {}\n@@ -495,1 +495,1 @@\n-  Decoder decoder(insn_addr, insn);\n+  AArch64Decoder decoder(insn_addr, insn);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":6,"deletions":6,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -313,1 +313,1 @@\n-  uint stk_args = 0; \/\/ inc by 2 each time\n+  uint stk_args = 0;\n@@ -325,0 +325,1 @@\n+        stk_args = align_up(stk_args, 2);\n@@ -326,1 +327,1 @@\n-        stk_args += 2;\n+        stk_args += 1;\n@@ -343,0 +344,1 @@\n+        stk_args = align_up(stk_args, 2);\n@@ -351,0 +353,1 @@\n+        stk_args = align_up(stk_args, 2);\n@@ -352,1 +355,1 @@\n-        stk_args += 2;\n+        stk_args += 1;\n@@ -360,0 +363,1 @@\n+        stk_args = align_up(stk_args, 2);\n@@ -370,1 +374,1 @@\n-  return align_up(stk_args, 2);\n+  return stk_args;\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":8,"deletions":4,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -113,1 +113,2 @@\n-    CPU_MODEL_AMPERE_1A = 0xac4  \/* CPU implementer is CPU_AMPERE *\/\n+    CPU_MODEL_AMPERE_1A = 0xac4, \/* CPU implementer is CPU_AMPERE *\/\n+    CPU_MODEL_AMPERE_1B = 0xac5  \/* AMPERE_1B core Implements ARMv8.7 with CSSC, MTE, SM3\/SM4 extensions *\/\n","filename":"src\/hotspot\/cpu\/aarch64\/vm_version_aarch64.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -463,0 +463,3 @@\n+  if (ce->compilation()->bailed_out()) {\n+    return; \/\/ CodeCache is full\n+  }\n","filename":"src\/hotspot\/cpu\/ppc\/c1_CodeStubs_ppc.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -34,0 +34,6 @@\n+#ifdef AIX\n+const size_t pd_segfault_address = -1;\n+#else\n+const size_t pd_segfault_address = 1024;\n+#endif\n+\n","filename":"src\/hotspot\/cpu\/ppc\/globalDefinitions_ppc.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2065,1 +2065,4 @@\n-  if (base == NULL) return 0; \/\/ CodeBuffer::expand failed\n+  if (base == nullptr) {\n+    ciEnv::current()->record_failure(\"CodeCache is full\");\n+    return 0;  \/\/ CodeBuffer::expand failed\n+  }\n@@ -2082,1 +2085,4 @@\n-  if (base == NULL) return 0; \/\/ CodeBuffer::expand failed\n+  if (base == nullptr) {\n+    ciEnv::current()->record_failure(\"CodeCache is full\");\n+    return 0;  \/\/ CodeBuffer::expand failed\n+  }\n@@ -2801,0 +2807,1 @@\n+    RelocationHolder r; \/\/ Initializes type to none.\n@@ -2803,1 +2810,1 @@\n-      AddressLiteral a = __ allocate_oop_address((jobject)val);\n+      AddressLiteral a = __ constant_oop_address((jobject)val);\n@@ -2805,1 +2812,1 @@\n-      __ relocate(a.rspec());\n+      r = a.rspec();\n@@ -2807,0 +2814,1 @@\n+      \/\/ Notify OOP recorder (don't need the relocation)\n@@ -2809,1 +2817,0 @@\n-      __ relocate(a.rspec());\n@@ -2819,0 +2826,1 @@\n+    __ relocate(r); \/\/ If set above.\n@@ -2832,0 +2840,1 @@\n+      RelocationHolder r; \/\/ Initializes type to none.\n@@ -2834,1 +2843,1 @@\n-        AddressLiteral a = __ allocate_oop_address((jobject)val);\n+        AddressLiteral a = __ constant_oop_address((jobject)val);\n@@ -2836,1 +2845,1 @@\n-        __ relocate(a.rspec());\n+        r = a.rspec();\n@@ -2838,0 +2847,1 @@\n+        \/\/ Notify OOP recorder (don't need the relocation)\n@@ -2840,1 +2850,0 @@\n-        __ relocate(a.rspec());\n@@ -2850,0 +2859,1 @@\n+      __ relocate(r); \/\/ If set above.\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":18,"deletions":8,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -737,1 +737,1 @@\n-  return align_up(stk, 2);\n+  return stk;\n","filename":"src\/hotspot\/cpu\/ppc\/sharedRuntime_ppc.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -724,1 +724,1 @@\n-  if (is_simm32(offset)) {\n+  if (is_valid_32bit_offset(offset)) {\n","filename":"src\/hotspot\/cpu\/riscv\/macroAssembler_riscv.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -643,0 +643,8 @@\n+  \/\/ The signed 20-bit upper imm can materialize at most negative 0xF...F80000000, two G.\n+  \/\/ The following signed 12-bit imm can at max subtract 0x800, two K, from that previously loaded two G.\n+  bool is_valid_32bit_offset(int64_t x) {\n+    constexpr int64_t twoG = (2 * G);\n+    constexpr int64_t twoK = (2 * K);\n+    return x < (twoG - twoK) && x >= (-twoG - twoK);\n+  }\n+\n@@ -797,1 +805,1 @@\n-    if (is_simm32(distance)) {                                                                     \\\n+    if (is_valid_32bit_offset(distance)) {                                                         \\\n@@ -854,1 +862,1 @@\n-    if (is_simm32(distance)) {                                                                     \\\n+    if (is_valid_32bit_offset(distance)) {                                                         \\\n@@ -915,1 +923,1 @@\n-    if (is_simm32(distance)) {                                                                     \\\n+    if (is_valid_32bit_offset(distance)) {                                                         \\\n@@ -960,1 +968,1 @@\n-    if (is_simm32(distance)) {                                                                     \\\n+    if (is_valid_32bit_offset(distance)) {                                                         \\\n","filename":"src\/hotspot\/cpu\/riscv\/macroAssembler_riscv.hpp","additions":12,"deletions":4,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -269,1 +269,1 @@\n-  uint stk_args = 0; \/\/ inc by 2 each time\n+  uint stk_args = 0;\n@@ -281,0 +281,1 @@\n+          stk_args = align_up(stk_args, 2);\n@@ -282,1 +283,1 @@\n-          stk_args += 2;\n+          stk_args += 1;\n@@ -298,0 +299,1 @@\n+          stk_args = align_up(stk_args, 2);\n@@ -306,0 +308,1 @@\n+          stk_args = align_up(stk_args, 2);\n@@ -307,1 +310,1 @@\n-          stk_args += 2;\n+          stk_args += 1;\n@@ -315,0 +318,1 @@\n+          stk_args = align_up(stk_args, 2);\n@@ -324,1 +328,1 @@\n-  return align_up(stk_args, 2);\n+  return stk_args;\n","filename":"src\/hotspot\/cpu\/riscv\/sharedRuntime_riscv.cpp","additions":8,"deletions":4,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -58,0 +58,4 @@\n+    void disable_feature() {\n+      _enabled = false;\n+      _value = -1;\n+    }\n@@ -66,7 +70,12 @@\n-  #define UPDATE_DEFAULT(flag)        \\\n-  void update_flag() {                \\\n-      assert(enabled(), \"Must be.\");  \\\n-      if (FLAG_IS_DEFAULT(flag)) {    \\\n-        FLAG_SET_DEFAULT(flag, true); \\\n-      }                               \\\n-  }                                   \\\n+  #define UPDATE_DEFAULT(flag)             \\\n+  void update_flag() {                     \\\n+      assert(enabled(), \"Must be.\");       \\\n+      if (FLAG_IS_DEFAULT(flag)) {         \\\n+        FLAG_SET_DEFAULT(flag, true);      \\\n+      } else {                             \\\n+        \/* Sync CPU features with flags *\/ \\\n+        if (!flag) {                       \\\n+          disable_feature();               \\\n+        }                                  \\\n+      }                                    \\\n+  }                                        \\\n@@ -74,2 +83,2 @@\n-  #define NO_UPDATE_DEFAULT           \\\n-  void update_flag() {}               \\\n+  #define NO_UPDATE_DEFAULT                \\\n+  void update_flag() {}                    \\\n","filename":"src\/hotspot\/cpu\/riscv\/vm_version_riscv.hpp","additions":18,"deletions":9,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 2016, 2023, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2016, 2018 SAP SE. All rights reserved.\n+ * Copyright (c) 2016, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2024 SAP SE. All rights reserved.\n@@ -436,0 +436,1 @@\n+  CHECK_BAILOUT();\n","filename":"src\/hotspot\/cpu\/s390\/c1_CodeStubs_s390.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -531,2 +531,1 @@\n-  \/\/ return value can be odd number of VMRegImpl stack slots make multiple of 2\n-  return align_up(stack, 2);\n+  return stack;\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -500,1 +500,1 @@\n-  uint stk_args = 0; \/\/ inc by 2 each time\n+  uint stk_args = 0;\n@@ -512,0 +512,1 @@\n+        stk_args = align_up(stk_args, 2);\n@@ -513,1 +514,1 @@\n-        stk_args += 2;\n+        stk_args += 1;\n@@ -530,0 +531,1 @@\n+        stk_args = align_up(stk_args, 2);\n@@ -538,0 +540,1 @@\n+        stk_args = align_up(stk_args, 2);\n@@ -539,1 +542,1 @@\n-        stk_args += 2;\n+        stk_args += 1;\n@@ -547,0 +550,1 @@\n+        stk_args = align_up(stk_args, 2);\n@@ -557,1 +561,1 @@\n-  return align_up(stk_args, 2);\n+  return stk_args;\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":8,"deletions":4,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -28,1 +28,1 @@\n-#include \"classfile\/stringTable.hpp\"\n+#include \"classfile\/systemDictionary.hpp\"\n@@ -77,0 +77,1 @@\n+#include \"gc\/shared\/classUnloadingContext.hpp\"\n@@ -859,4 +860,0 @@\n-  \/\/ Delete metaspaces for unloaded class loaders and clean up loader_data graph\n-  ClassLoaderDataGraph::purge(\/*at_safepoint*\/true);\n-  DEBUG_ONLY(MetaspaceUtils::verify();)\n-\n@@ -2602,0 +2599,59 @@\n+void G1CollectedHeap::unload_classes_and_code(const char* description, BoolObjectClosure* is_alive, GCTimer* timer) {\n+  GCTraceTime(Debug, gc, phases) debug(description, timer);\n+\n+  ClassUnloadingContext ctx(workers()->active_workers(),\n+                            false \/* unregister_nmethods_during_purge *\/,\n+                            false \/* lock_codeblob_free_separately *\/);\n+  {\n+    CodeCache::UnlinkingScope scope(is_alive);\n+    bool unloading_occurred = SystemDictionary::do_unloading(timer);\n+    GCTraceTime(Debug, gc, phases) t(\"G1 Complete Cleaning\", timer);\n+    complete_cleaning(unloading_occurred);\n+  }\n+  {\n+    GCTraceTime(Debug, gc, phases) t(\"Purge Unlinked NMethods\", timer);\n+    ctx.purge_nmethods();\n+  }\n+  {\n+    GCTraceTime(Debug, gc, phases) ur(\"Unregister NMethods\", timer);\n+    G1CollectedHeap::heap()->bulk_unregister_nmethods();\n+  }\n+  {\n+    GCTraceTime(Debug, gc, phases) t(\"Free Code Blobs\", timer);\n+    ctx.free_code_blobs();\n+  }\n+  {\n+    GCTraceTime(Debug, gc, phases) t(\"Purge Class Loader Data\", timer);\n+    ClassLoaderDataGraph::purge(true \/* at_safepoint *\/);\n+    DEBUG_ONLY(MetaspaceUtils::verify();)\n+  }\n+}\n+\n+class G1BulkUnregisterNMethodTask : public WorkerTask {\n+  HeapRegionClaimer _hrclaimer;\n+\n+  class UnregisterNMethodsHeapRegionClosure : public HeapRegionClosure {\n+  public:\n+\n+    bool do_heap_region(HeapRegion* hr) {\n+      hr->rem_set()->bulk_remove_code_roots();\n+      return false;\n+    }\n+  } _cl;\n+\n+public:\n+  G1BulkUnregisterNMethodTask(uint num_workers)\n+  : WorkerTask(\"G1 Remove Unlinked NMethods From Code Root Set Task\"),\n+    _hrclaimer(num_workers) { }\n+\n+  void work(uint worker_id) {\n+    G1CollectedHeap::heap()->heap_region_par_iterate_from_worker_offset(&_cl, &_hrclaimer, worker_id);\n+  }\n+};\n+\n+void G1CollectedHeap::bulk_unregister_nmethods() {\n+  uint num_workers = workers()->active_workers();\n+  G1BulkUnregisterNMethodTask t(num_workers);\n+  workers()->run_task(&t);\n+}\n+\n@@ -2767,1 +2823,1 @@\n-   if (hr->is_humongous()) {\n+  if (hr->is_humongous()) {\n@@ -3014,27 +3070,1 @@\n-      \/\/ HeapRegion::add_code_root_locked() avoids adding duplicate entries.\n-      hr->add_code_root_locked(_nm);\n-    }\n-  }\n-\n-  void do_oop(narrowOop* p) { ShouldNotReachHere(); }\n-};\n-\n-class UnregisterNMethodOopClosure: public OopClosure {\n-  G1CollectedHeap* _g1h;\n-  nmethod* _nm;\n-\n-public:\n-  UnregisterNMethodOopClosure(G1CollectedHeap* g1h, nmethod* nm) :\n-    _g1h(g1h), _nm(nm) {}\n-\n-  void do_oop(oop* p) {\n-    oop heap_oop = RawAccess<>::oop_load(p);\n-    if (!CompressedOops::is_null(heap_oop)) {\n-      oop obj = CompressedOops::decode_not_null(heap_oop);\n-      HeapRegion* hr = _g1h->heap_region_containing(obj);\n-      assert(!hr->is_continues_humongous(),\n-             \"trying to remove code root \" PTR_FORMAT \" in continuation of humongous region \" HR_FORMAT\n-             \" starting at \" HR_FORMAT,\n-             p2i(_nm), HR_FORMAT_PARAMS(hr), HR_FORMAT_PARAMS(hr->humongous_start_region()));\n-\n-      hr->remove_code_root(_nm);\n+      hr->add_code_root(_nm);\n@@ -3054,3 +3084,2 @@\n-  guarantee(nm != nullptr, \"sanity\");\n-  UnregisterNMethodOopClosure reg_cl(this, nm);\n-  nm->oops_do(&reg_cl, true);\n+  \/\/ We always unregister nmethods in bulk during code unloading only.\n+  ShouldNotReachHere();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":65,"deletions":36,"binary":false,"changes":101,"status":"modified"},{"patch":"@@ -27,3 +27,0 @@\n-#include \"classfile\/systemDictionary.hpp\"\n-#include \"code\/codeCache.hpp\"\n-#include \"compiler\/oopMap.hpp\"\n@@ -44,0 +41,1 @@\n+#include \"gc\/shared\/classUnloadingContext.hpp\"\n@@ -175,0 +173,1 @@\n+    hr->prepare_for_full_gc();\n@@ -326,5 +325,1 @@\n-    GCTraceTime(Debug, gc, phases) debug(\"Phase 1: Class Unloading and Cleanup\", scope()->timer());\n-    CodeCache::UnloadingScope unloading_scope(&_is_alive);\n-    \/\/ Unload classes and purge the SystemDictionary.\n-    bool purged_class = SystemDictionary::do_unloading(scope()->timer());\n-    _heap->complete_cleaning(purged_class);\n+    _heap->unload_classes_and_code(\"Phase 1: Class Unloading and Cleanup\", &_is_alive, scope()->timer());\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullCollector.cpp","additions":3,"deletions":8,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -123,0 +123,1 @@\n+      size_t pretouch_page_size = UseLargePages ? page_size : os::vm_page_size();\n@@ -124,1 +125,1 @@\n-                             page_size, pretouch_workers);\n+                             pretouch_page_size, pretouch_workers);\n@@ -127,1 +128,1 @@\n-                             page_size, pretouch_workers);\n+                             pretouch_page_size, pretouch_workers);\n","filename":"src\/hotspot\/share\/gc\/parallel\/mutableSpace.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+#include \"gc\/shared\/classUnloadingContext.hpp\"\n@@ -203,6 +204,26 @@\n-    CodeCache::UnloadingScope scope(&is_alive);\n-    \/\/ Unload classes and purge the SystemDictionary.\n-    bool purged_class = SystemDictionary::do_unloading(gc_timer());\n-\n-    \/\/ Unload nmethods.\n-    CodeCache::do_unloading(purged_class);\n+    ClassUnloadingContext* ctx = ClassUnloadingContext::context();\n+\n+    bool unloading_occurred;\n+    {\n+      CodeCache::UnlinkingScope scope(&is_alive);\n+\n+      \/\/ Unload classes and purge the SystemDictionary.\n+      unloading_occurred = SystemDictionary::do_unloading(gc_timer());\n+\n+      \/\/ Unload nmethods.\n+      CodeCache::do_unloading(unloading_occurred);\n+    }\n+\n+    {\n+      GCTraceTime(Debug, gc, phases) t(\"Purge Unlinked NMethods\", gc_timer());\n+      \/\/ Release unloaded nmethod's memory.\n+      ctx->purge_nmethods();\n+    }\n+    {\n+      GCTraceTime(Debug, gc, phases) ur(\"Unregister NMethods\", gc_timer());\n+      gch->prune_unlinked_nmethods();\n+    }\n+    {\n+      GCTraceTime(Debug, gc, phases) t(\"Free Code Blobs\", gc_timer());\n+      ctx->free_code_blobs();\n+    }\n@@ -212,1 +233,1 @@\n-    Klass::clean_weak_klass_links(purged_class);\n+    Klass::clean_weak_klass_links(unloading_occurred);\n@@ -215,1 +236,1 @@\n-    JVMCI_ONLY(JVMCI::do_unloading(purged_class));\n+    JVMCI_ONLY(JVMCI::do_unloading(unloading_occurred));\n","filename":"src\/hotspot\/share\/gc\/serial\/genMarkSweep.cpp","additions":29,"deletions":8,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+#include \"gc\/shared\/classUnloadingContext.hpp\"\n@@ -561,0 +562,4 @@\n+    ClassUnloadingContext ctx(1 \/* num_nmethod_unlink_workers *\/,\n+                              false \/* unregister_nmethods_during_purge *\/,\n+                              false \/* lock_codeblob_free_separately *\/);\n+\n@@ -576,1 +581,1 @@\n-    ClassLoaderDataGraph::purge(\/*at_safepoint*\/true);\n+    ClassLoaderDataGraph::purge(true \/* at_safepoint *\/);\n@@ -617,1 +622,5 @@\n-  ScavengableNMethods::prune_nmethods();\n+  ScavengableNMethods::prune_nmethods_not_into_young();\n+}\n+\n+void GenCollectedHeap::prune_unlinked_nmethods() {\n+  ScavengableNMethods::prune_unlinked_nmethods();\n","filename":"src\/hotspot\/share\/gc\/shared\/genCollectedHeap.cpp","additions":11,"deletions":2,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"gc\/shared\/classUnloadingContext.hpp\"\n@@ -473,0 +474,1 @@\n+  _gc_state_changed(false),\n@@ -1687,3 +1689,8 @@\n-void ShenandoahHeap::set_gc_state_all_threads(char state) {\n-  for (JavaThreadIteratorWithHandle jtiwh; JavaThread *t = jtiwh.next(); ) {\n-    ShenandoahThreadLocalData::set_gc_state(t, state);\n+void ShenandoahHeap::propagate_gc_state_to_java_threads() {\n+  assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at Shenandoah safepoint\");\n+  if (_gc_state_changed) {\n+    _gc_state_changed = false;\n+    char state = gc_state();\n+    for (JavaThreadIteratorWithHandle jtiwh; JavaThread *t = jtiwh.next(); ) {\n+      ShenandoahThreadLocalData::set_gc_state(t, state);\n+    }\n@@ -1693,2 +1700,2 @@\n-void ShenandoahHeap::set_gc_state_mask(uint mask, bool value) {\n-  assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Should really be Shenandoah safepoint\");\n+void ShenandoahHeap::set_gc_state(uint mask, bool value) {\n+  assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at Shenandoah safepoint\");\n@@ -1696,1 +1703,1 @@\n-  set_gc_state_all_threads(_gc_state.raw_value());\n+  _gc_state_changed = true;\n@@ -1701,1 +1708,1 @@\n-  set_gc_state_mask(MARKING, in_progress);\n+  set_gc_state(MARKING, in_progress);\n@@ -1707,1 +1714,1 @@\n-  set_gc_state_mask(EVACUATION, in_progress);\n+  set_gc_state(EVACUATION, in_progress);\n@@ -1719,1 +1726,1 @@\n-  set_gc_state_mask(WEAK_ROOTS, cond);\n+  set_gc_state(WEAK_ROOTS, cond);\n@@ -1767,0 +1774,4 @@\n+  ClassUnloadingContext ctx(_workers->active_workers(),\n+                            true \/* unregister_nmethods_during_purge *\/,\n+                            false \/* lock_codeblob_free_separately *\/);\n+\n@@ -1773,8 +1784,12 @@\n-    CodeCache::UnloadingScope scope(is_alive.is_alive_closure());\n-    ShenandoahGCPhase gc_phase(phase);\n-    ShenandoahGCWorkerPhase worker_phase(phase);\n-    bool purged_class = SystemDictionary::do_unloading(gc_timer());\n-\n-    uint num_workers = _workers->active_workers();\n-    ShenandoahClassUnloadingTask unlink_task(phase, num_workers, purged_class);\n-    _workers->run_task(&unlink_task);\n+    {\n+      CodeCache::UnlinkingScope scope(is_alive.is_alive_closure());\n+      ShenandoahGCPhase gc_phase(phase);\n+      ShenandoahGCWorkerPhase worker_phase(phase);\n+      bool unloading_occurred = SystemDictionary::do_unloading(gc_timer());\n+\n+      uint num_workers = _workers->active_workers();\n+      ShenandoahClassUnloadingTask unlink_task(phase, num_workers, unloading_occurred);\n+      _workers->run_task(&unlink_task);\n+    }\n+    \/\/ Release unloaded nmethods's memory.\n+    ClassUnloadingContext::context()->purge_and_free_nmethods();\n@@ -1787,1 +1802,1 @@\n-    ClassLoaderDataGraph::purge(\/*at_safepoint*\/true);\n+    ClassLoaderDataGraph::purge(true \/* at_safepoint *\/);\n@@ -1838,1 +1853,1 @@\n-  set_gc_state_mask(HAS_FORWARDED, cond);\n+  set_gc_state(HAS_FORWARDED, cond);\n@@ -1877,1 +1892,1 @@\n-  set_gc_state_mask(UPDATEREFS, in_progress);\n+  set_gc_state(UPDATEREFS, in_progress);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":35,"deletions":20,"binary":false,"changes":55,"status":"modified"},{"patch":"@@ -624,0 +624,2 @@\n+  ShenandoahHeap::heap()->propagate_gc_state_to_java_threads();\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahVerifier.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -55,0 +55,1 @@\n+#include \"runtime\/arguments.hpp\"\n@@ -588,0 +589,12 @@\n+#ifdef ASSERT\n+  const char* val = Arguments::PropertyList_get_value(Arguments::system_properties(), \"test.jvmci.lookupTypeException\");\n+  if (val != nullptr) {\n+    if (strstr(val, \"<trace>\") != nullptr) {\n+      tty->print_cr(\"CompilerToVM.lookupType: %s\", str);\n+    } else if (strstr(val, str) != nullptr) {\n+      THROW_MSG_0(vmSymbols::java_lang_Exception(),\n+                  err_msg(\"lookupTypeException: %s\", str));\n+    }\n+  }\n+#endif\n+\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.cpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -64,4 +64,0 @@\n-oop Klass::java_mirror_no_keepalive() const {\n-  return _java_mirror.peek();\n-}\n-\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -64,0 +64,4 @@\n+inline oop Klass::java_mirror_no_keepalive() const {\n+  return _java_mirror.peek();\n+}\n+\n","filename":"src\/hotspot\/share\/oops\/klass.inline.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -625,1 +625,0 @@\n-                  _failure_reason(nullptr),\n@@ -922,1 +921,0 @@\n-    _failure_reason(nullptr),\n@@ -1943,1 +1941,1 @@\n-          if (Verbose) {\n+          if (PrintOpto && Verbose) {\n@@ -4335,1 +4333,1 @@\n-  if (_failure_reason == nullptr) {\n+  if (_failure_reason.get() == nullptr) {\n@@ -4337,1 +4335,1 @@\n-    _failure_reason = reason;\n+    _failure_reason.set(reason);\n@@ -4916,1 +4914,10 @@\n-          assert(in_hash, \"node should be in igvn hash table\");\n+#ifdef ASSERT\n+          if (!in_hash) {\n+            tty->print_cr(\"current graph:\");\n+            n->dump_bfs(MaxNodeLimit, nullptr, \"S$\");\n+            tty->cr();\n+            tty->print_cr(\"erroneous node:\");\n+            n->dump();\n+            assert(false, \"node should be in igvn hash table\");\n+          }\n+#endif\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":13,"deletions":6,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -3353,0 +3353,1 @@\n+          assert(!trailing_load_store(), \"load store node can't be eliminated\");\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -6461,3 +6461,1 @@\n-  int dummy;\n-  bool this_top_or_bottom = (this_one->base_element_type(dummy) == Type::TOP || this_one->base_element_type(dummy) == Type::BOTTOM);\n-  if (!this_one->is_loaded() || !other->is_loaded() || this_top_or_bottom) {\n+  if (!this_one->is_loaded() || !other->is_loaded()) {\n@@ -6469,0 +6467,7 @@\n+\n+  int dummy;\n+  bool this_top_or_bottom = (this_one->base_element_type(dummy) == Type::TOP || this_one->base_element_type(dummy) == Type::BOTTOM);\n+  if (this_top_or_bottom) {\n+    return true;\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":8,"deletions":3,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -1845,1 +1845,1 @@\n-  return ObjectSynchronizer::request_deflate_idle_monitors();\n+  return ObjectSynchronizer::request_deflate_idle_monitors_from_wb();\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -739,0 +739,4 @@\n+  product(intx, MonitorUnlinkBatch, 500, DIAGNOSTIC,                        \\\n+          \"The maximum number of monitors to unlink in one batch. \")        \\\n+          range(1, max_jint)                                                \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -577,10 +577,0 @@\n-  if (ObjectSynchronizer::is_final_audit() && owner_is_DEFLATER_MARKER()) {\n-    \/\/ The final audit can see an already deflated ObjectMonitor on the\n-    \/\/ in-use list because MonitorList::unlink_deflated() might have\n-    \/\/ blocked for the final safepoint before unlinking all the deflated\n-    \/\/ monitors.\n-    assert(contentions() < 0, \"must be negative: contentions=%d\", contentions());\n-    \/\/ Already returned 'true' when it was originally deflated.\n-    return false;\n-  }\n-\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.cpp","additions":0,"deletions":10,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -1994,1 +1994,1 @@\n-  int comp_args_on_stack = java_calling_convention(sig_bt, regs_without_member_name, total_args_passed - 1);\n+  java_calling_convention(sig_bt, regs_without_member_name, total_args_passed - 1);\n@@ -3092,1 +3092,1 @@\n-      int comp_args_on_stack = SharedRuntime::java_calling_convention(sig_bt, regs, total_args_passed);\n+      SharedRuntime::java_calling_convention(sig_bt, regs, total_args_passed);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -68,39 +68,0 @@\n-class ObjectMonitorsHashtable::PtrList :\n-  public LinkedListImpl<ObjectMonitor*,\n-                        AnyObj::C_HEAP, mtThread,\n-                        AllocFailStrategy::RETURN_NULL> {};\n-\n-class CleanupObjectMonitorsHashtable: StackObj {\n- public:\n-  bool do_entry(void*& key, ObjectMonitorsHashtable::PtrList*& list) {\n-    list->clear();  \/\/ clear the LinkListNodes\n-    delete list;    \/\/ then delete the LinkedList\n-    return true;\n-  }\n-};\n-\n-ObjectMonitorsHashtable::~ObjectMonitorsHashtable() {\n-  CleanupObjectMonitorsHashtable cleanup;\n-  _ptrs->unlink(&cleanup);  \/\/ cleanup the LinkedLists\n-  delete _ptrs;             \/\/ then delete the hash table\n-}\n-\n-void ObjectMonitorsHashtable::add_entry(void* key, ObjectMonitor* om) {\n-  ObjectMonitorsHashtable::PtrList* list = get_entry(key);\n-  if (list == nullptr) {\n-    \/\/ Create new list and add it to the hash table:\n-    list = new (mtThread) ObjectMonitorsHashtable::PtrList;\n-    add_entry(key, list);\n-  }\n-  list->add(om);  \/\/ Add the ObjectMonitor to the list.\n-  _om_count++;\n-}\n-\n-bool ObjectMonitorsHashtable::has_entry(void* key, ObjectMonitor* om) {\n-  ObjectMonitorsHashtable::PtrList* list = get_entry(key);\n-  if (list == nullptr || list->find(om) == nullptr) {\n-    return false;\n-  }\n-  return true;\n-}\n-\n@@ -128,2 +89,2 @@\n-\/\/ Walk the in-use list and unlink (at most MonitorDeflationMax) deflated\n-\/\/ ObjectMonitors. Returns the number of unlinked ObjectMonitors.\n+\/\/ Walk the in-use list and unlink deflated ObjectMonitors.\n+\/\/ Returns the number of unlinked ObjectMonitors.\n@@ -132,0 +93,1 @@\n+                                    size_t deflated_count,\n@@ -135,2 +97,2 @@\n-  ObjectMonitor* head = Atomic::load_acquire(&_head);\n-  ObjectMonitor* m = head;\n+  ObjectMonitor* m = Atomic::load_acquire(&_head);\n+\n@@ -140,1 +102,3 @@\n-      \/\/ Find next live ObjectMonitor.\n+      \/\/ Find next live ObjectMonitor. Batch up the unlinkable monitors, so we can\n+      \/\/ modify the list once per batch. The batch starts at \"m\".\n+      size_t unlinked_batch = 0;\n@@ -142,0 +106,4 @@\n+      \/\/ Look for at most MonitorUnlinkBatch monitors, or the number of\n+      \/\/ deflated and not unlinked monitors, whatever comes first.\n+      assert(deflated_count >= unlinked_count, \"Sanity: underflow\");\n+      size_t unlinked_batch_limit = MIN2<size_t>(deflated_count - unlinked_count, MonitorUnlinkBatch);\n@@ -144,1 +112,1 @@\n-        unlinked_count++;\n+        unlinked_batch++;\n@@ -147,2 +115,8 @@\n-        if (unlinked_count >= (size_t)MonitorDeflationMax) {\n-          \/\/ Reached the max so bail out on the gathering loop.\n+        if (unlinked_batch >= unlinked_batch_limit) {\n+          \/\/ Reached the max batch, so bail out of the gathering loop.\n+          break;\n+        }\n+        if (prev == nullptr && Atomic::load(&_head) != m) {\n+          \/\/ Current batch used to be at head, but it is not at head anymore.\n+          \/\/ Bail out and figure out where we currently are. This avoids long\n+          \/\/ walks searching for new prev during unlink under heavy list inserts.\n@@ -152,0 +126,2 @@\n+\n+      \/\/ Unlink the found batch.\n@@ -153,3 +129,5 @@\n-        ObjectMonitor* prev_head = Atomic::cmpxchg(&_head, head, next);\n-        if (prev_head != head) {\n-          \/\/ Find new prev ObjectMonitor that just got inserted.\n+        \/\/ The current batch is the first batch, so there is a chance that it starts at head.\n+        \/\/ Optimistically assume no inserts happened, and try to unlink the entire batch from the head.\n+        ObjectMonitor* prev_head = Atomic::cmpxchg(&_head, m, next);\n+        if (prev_head != m) {\n+          \/\/ Something must have updated the head. Figure out the actual prev for this batch.\n@@ -159,0 +137,1 @@\n+          assert(prev != nullptr, \"Should have found the prev for the current batch\");\n@@ -162,0 +141,3 @@\n+        \/\/ The current batch is preceded by another batch. This guarantees the current batch\n+        \/\/ does not start at head. Unlink the entire current batch without updating the head.\n+        assert(Atomic::load(&_head) != m, \"Sanity\");\n@@ -164,2 +146,5 @@\n-      if (unlinked_count >= (size_t)MonitorDeflationMax) {\n-        \/\/ Reached the max so bail out on the searching loop.\n+\n+      unlinked_count += unlinked_batch;\n+      if (unlinked_count >= deflated_count) {\n+        \/\/ Reached the max so bail out of the searching loop.\n+        \/\/ There should be no more deflated monitors left.\n@@ -181,0 +166,14 @@\n+\n+#ifdef ASSERT\n+  \/\/ Invariant: the code above should unlink all deflated monitors.\n+  \/\/ The code that runs after this unlinking does not expect deflated monitors.\n+  \/\/ Notably, attempting to deflate the already deflated monitor would break.\n+  {\n+    ObjectMonitor* m = Atomic::load_acquire(&_head);\n+    while (m != nullptr) {\n+      assert(!m->is_being_async_deflated(), \"All deflated monitors should be unlinked\");\n+      m = m->next_om();\n+    }\n+  }\n+#endif\n+\n@@ -1176,6 +1175,3 @@\n-\/\/ Iterate ObjectMonitors where the owner == thread; this does NOT include\n-\/\/ ObjectMonitors where owner is set to a stack-lock address in thread.\n-\/\/\n-\/\/ This version of monitors_iterate() works with the in-use monitor list.\n-\/\/\n-void ObjectSynchronizer::monitors_iterate(MonitorClosure* closure, JavaThread* thread) {\n+\/\/ Iterate over all ObjectMonitors.\n+template <typename Function>\n+void ObjectSynchronizer::monitors_iterate(Function function) {\n@@ -1184,17 +1180,2 @@\n-    ObjectMonitor* mid = iter.next();\n-    if (mid->owner() != thread) {\n-      \/\/ Not owned by the target thread and intentionally skips when owner\n-      \/\/ is set to a stack-lock address in the target thread.\n-      continue;\n-    }\n-    if (!mid->is_being_async_deflated() && mid->object_peek() != nullptr) {\n-      \/\/ Only process with closure if the object is set.\n-\n-      \/\/ monitors_iterate() is only called at a safepoint or when the\n-      \/\/ target thread is suspended or when the target thread is\n-      \/\/ operating on itself. The current closures in use today are\n-      \/\/ only interested in an owned ObjectMonitor and ownership\n-      \/\/ cannot be dropped under the calling contexts so the\n-      \/\/ ObjectMonitor cannot be async deflated.\n-      closure->do_monitor(mid);\n-    }\n+    ObjectMonitor* monitor = iter.next();\n+    function(monitor);\n@@ -1204,21 +1185,15 @@\n-\/\/ This version of monitors_iterate() works with the specified linked list.\n-\/\/\n-void ObjectSynchronizer::monitors_iterate(MonitorClosure* closure,\n-                                          ObjectMonitorsHashtable::PtrList* list,\n-                                          JavaThread* thread) {\n-  typedef LinkedListIterator<ObjectMonitor*> ObjectMonitorIterator;\n-  ObjectMonitorIterator iter(list->head());\n-  while (!iter.is_empty()) {\n-    ObjectMonitor* mid = *iter.next();\n-    \/\/ Owner set to a stack-lock address in thread should never be seen here:\n-    assert(mid->owner() == thread, \"must be\");\n-    if (!mid->is_being_async_deflated() && mid->object_peek() != nullptr) {\n-      \/\/ Only process with closure if the object is set.\n-\n-      \/\/ monitors_iterate() is only called at a safepoint or when the\n-      \/\/ target thread is suspended or when the target thread is\n-      \/\/ operating on itself. The current closures in use today are\n-      \/\/ only interested in an owned ObjectMonitor and ownership\n-      \/\/ cannot be dropped under the calling contexts so the\n-      \/\/ ObjectMonitor cannot be async deflated.\n-      closure->do_monitor(mid);\n+\/\/ Iterate ObjectMonitors owned by any thread and where the owner `filter`\n+\/\/ returns true.\n+template <typename OwnerFilter>\n+void ObjectSynchronizer::owned_monitors_iterate_filtered(MonitorClosure* closure, OwnerFilter filter) {\n+  monitors_iterate([&](ObjectMonitor* monitor) {\n+    \/\/ This function is only called at a safepoint or when the\n+    \/\/ target thread is suspended or when the target thread is\n+    \/\/ operating on itself. The current closures in use today are\n+    \/\/ only interested in an owned ObjectMonitor and ownership\n+    \/\/ cannot be dropped under the calling contexts so the\n+    \/\/ ObjectMonitor cannot be async deflated.\n+    if (monitor->has_owner() && filter(monitor->owner_raw())) {\n+      assert(!monitor->is_being_async_deflated(), \"Owned monitors should not be deflating\");\n+\n+      closure->do_monitor(monitor);\n@@ -1226,1 +1201,14 @@\n-  }\n+  });\n+}\n+\n+\/\/ Iterate ObjectMonitors where the owner == thread; this does NOT include\n+\/\/ ObjectMonitors where owner is set to a stack-lock address in thread.\n+void ObjectSynchronizer::owned_monitors_iterate(MonitorClosure* closure, JavaThread* thread) {\n+  auto thread_filter = [&](void* owner) { return owner == thread; };\n+  return owned_monitors_iterate_filtered(closure, thread_filter);\n+}\n+\n+\/\/ Iterate ObjectMonitors owned by any thread.\n+void ObjectSynchronizer::owned_monitors_iterate(MonitorClosure* closure) {\n+  auto all_filter = [&](void* owner) { return true; };\n+  return owned_monitors_iterate_filtered(closure, all_filter);\n@@ -1333,1 +1321,7 @@\n-bool ObjectSynchronizer::request_deflate_idle_monitors() {\n+void ObjectSynchronizer::request_deflate_idle_monitors() {\n+  MonitorLocker ml(MonitorDeflation_lock, Mutex::_no_safepoint_check_flag);\n+  set_is_async_deflation_requested(true);\n+  ml.notify_all();\n+}\n+\n+bool ObjectSynchronizer::request_deflate_idle_monitors_from_wb() {\n@@ -1338,5 +1332,3 @@\n-  set_is_async_deflation_requested(true);\n-  {\n-    MonitorLocker ml(MonitorDeflation_lock, Mutex::_no_safepoint_check_flag);\n-    ml.notify_all();\n-  }\n+\n+  request_deflate_idle_monitors();\n+\n@@ -1682,9 +1674,1 @@\n-\/\/ If table != nullptr, we gather owned ObjectMonitors indexed by the\n-\/\/ owner in the table. Please note that ObjectMonitors where the owner\n-\/\/ is set to a stack-lock address are NOT associated with the JavaThread\n-\/\/ that holds that stack-lock. All of the current consumers of\n-\/\/ ObjectMonitorsHashtable info only care about JNI locked monitors and\n-\/\/ those do not have the owner set to a stack-lock address.\n-\/\/\n-                                                elapsedTimer* timer_p,\n-                                                ObjectMonitorsHashtable* table) {\n+                                                elapsedTimer* timer_p) {\n@@ -1702,12 +1686,0 @@\n-    } else if (table != nullptr) {\n-      \/\/ The caller is interested in the owned ObjectMonitors. This does\n-      \/\/ not include when owner is set to a stack-lock address in thread.\n-      \/\/ This also does not capture unowned ObjectMonitors that cannot be\n-      \/\/ deflated because of a waiter.\n-      void* key = mid->owner();\n-      \/\/ Since deflate_idle_monitors() and deflate_monitor_list() can be\n-      \/\/ called more than once, we have to make sure the entry has not\n-      \/\/ already been added.\n-      if (key != nullptr && !table->has_entry(key, mid)) {\n-        table->add_entry(key, mid);\n-      }\n@@ -1763,3 +1735,2 @@\n-\/\/ ObjectMonitors. It is also called via do_final_audit_and_print_stats()\n-\/\/ and VM_ThreadDump::doit() by the VMThread.\n-size_t ObjectSynchronizer::deflate_idle_monitors(ObjectMonitorsHashtable* table) {\n+\/\/ ObjectMonitors.\n+size_t ObjectSynchronizer::deflate_idle_monitors() {\n@@ -1790,1 +1761,1 @@\n-  size_t deflated_count = deflate_monitor_list(current, ls, &timer, table);\n+  size_t deflated_count = deflate_monitor_list(current, ls, &timer);\n@@ -1793,5 +1764,2 @@\n-  if (deflated_count > 0 || is_final_audit()) {\n-    \/\/ There are ObjectMonitors that have been deflated or this is the\n-    \/\/ final audit and all the remaining ObjectMonitors have been\n-    \/\/ deflated, BUT the MonitorDeflationThread blocked for the final\n-    \/\/ safepoint during unlinking.\n+  if (deflated_count > 0) {\n+    \/\/ There are ObjectMonitors that have been deflated.\n@@ -1802,1 +1770,1 @@\n-    unlinked_count = _in_use_list.unlink_deflated(current, ls, &timer, &delete_list);\n+    unlinked_count = _in_use_list.unlink_deflated(current, ls, &timer, deflated_count, &delete_list);\n@@ -1849,4 +1817,0 @@\n-    if (table != nullptr) {\n-      ls->print_cr(\"ObjectMonitorsHashtable: key_count=\" SIZE_FORMAT \", om_count=\" SIZE_FORMAT,\n-                   table->key_count(), table->om_count());\n-    }\n@@ -1905,1 +1869,1 @@\n-  ObjectSynchronizer::monitors_iterate(&rjmc, current);\n+  ObjectSynchronizer::owned_monitors_iterate(&rjmc, current);\n@@ -1959,6 +1923,0 @@\n-    \/\/ Do deflations in order to reduce the in-use monitor population\n-    \/\/ that is reported by ObjectSynchronizer::log_in_use_monitor_details()\n-    \/\/ which is called by ObjectSynchronizer::audit_and_print_stats().\n-    while (deflate_idle_monitors(\/* ObjectMonitorsHashtable is not needed here *\/ nullptr) > 0) {\n-      ; \/\/ empty\n-    }\n@@ -2013,1 +1971,1 @@\n-    log_in_use_monitor_details(ls);\n+    log_in_use_monitor_details(ls, !on_exit \/* log_all *\/);\n@@ -2059,3 +2017,1 @@\n-    \/\/ This should not happen, but if it does, it is not fatal.\n-    out->print_cr(\"WARNING: monitor=\" INTPTR_FORMAT \": in-use monitor is \"\n-                  \"deflated.\", p2i(n));\n+    \/\/ This could happen when monitor deflation blocks for a safepoint.\n@@ -2064,0 +2020,1 @@\n+\n@@ -2093,2 +2050,1 @@\n-void ObjectSynchronizer::log_in_use_monitor_details(outputStream* out) {\n-  stringStream ss;\n+void ObjectSynchronizer::log_in_use_monitor_details(outputStream* out, bool log_all) {\n@@ -2096,0 +2052,1 @@\n+    stringStream ss;\n@@ -2101,12 +2058,18 @@\n-    MonitorList::Iterator iter = _in_use_list.iterator();\n-    while (iter.has_next()) {\n-      ObjectMonitor* mid = iter.next();\n-      const oop obj = mid->object_peek();\n-      const markWord mark = mid->header();\n-      ResourceMark rm;\n-      out->print(INTPTR_FORMAT \"  %d%d%d  \" INTPTR_FORMAT \"  %s\", p2i(mid),\n-                 mid->is_busy(), mark.hash() != 0, mid->owner() != nullptr,\n-                 p2i(obj), obj == nullptr ? \"\" : obj->klass()->external_name());\n-      if (mid->is_busy()) {\n-        out->print(\" (%s)\", mid->is_busy_to_string(&ss));\n-        ss.reset();\n+\n+    auto is_interesting = [&](ObjectMonitor* monitor) {\n+      return log_all || monitor->has_owner() || monitor->is_busy();\n+    };\n+\n+    monitors_iterate([&](ObjectMonitor* monitor) {\n+      if (is_interesting(monitor)) {\n+        const oop obj = monitor->object_peek();\n+        const markWord mark = monitor->header();\n+        ResourceMark rm;\n+        out->print(INTPTR_FORMAT \"  %d%d%d  \" INTPTR_FORMAT \"  %s\", p2i(monitor),\n+                   monitor->is_busy(), mark.hash() != 0, monitor->owner() != nullptr,\n+                   p2i(obj), obj == nullptr ? \"\" : obj->klass()->external_name());\n+        if (monitor->is_busy()) {\n+          out->print(\" (%s)\", monitor->is_busy_to_string(&ss));\n+          ss.reset();\n+        }\n+        out->cr();\n@@ -2114,2 +2077,1 @@\n-      out->cr();\n-    }\n+    });\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":127,"deletions":165,"binary":false,"changes":292,"status":"modified"},{"patch":"@@ -39,49 +39,0 @@\n-\/\/ Hash table of void* to a list of ObjectMonitor* owned by the JavaThread.\n-\/\/ The JavaThread's owner key is either a JavaThread* or a stack lock\n-\/\/ address in the JavaThread so we use \"void*\".\n-\/\/\n-class ObjectMonitorsHashtable {\n- private:\n-  static unsigned int ptr_hash(void* const& s1) {\n-    \/\/ 2654435761 = 2^32 * Phi (golden ratio)\n-    return (unsigned int)(((uint32_t)(uintptr_t)s1) * 2654435761u);\n-  }\n-\n- public:\n-  class PtrList;\n-\n- private:\n-  \/\/ ResourceHashtable SIZE is specified at compile time so we\n-  \/\/ use 1031 which is the first prime after 1024.\n-  typedef ResourceHashtable<void*, PtrList*, 1031, AnyObj::C_HEAP, mtThread,\n-                            &ObjectMonitorsHashtable::ptr_hash> PtrTable;\n-  PtrTable* _ptrs;\n-  size_t _key_count;\n-  size_t _om_count;\n-\n- public:\n-  \/\/ ResourceHashtable is passed to various functions and populated in\n-  \/\/ different places so we allocate it using C_HEAP to make it immune\n-  \/\/ from any ResourceMarks that happen to be in the code paths.\n-  ObjectMonitorsHashtable() : _ptrs(new (mtThread) PtrTable), _key_count(0), _om_count(0) {}\n-\n-  ~ObjectMonitorsHashtable();\n-\n-  void add_entry(void* key, ObjectMonitor* om);\n-\n-  void add_entry(void* key, PtrList* list) {\n-    _ptrs->put(key, list);\n-    _key_count++;\n-  }\n-\n-  PtrList* get_entry(void* key) {\n-    PtrList** listpp = _ptrs->get(key);\n-    return (listpp == nullptr) ? nullptr : *listpp;\n-  }\n-\n-  bool has_entry(void* key, ObjectMonitor* om);\n-\n-  size_t key_count() { return _key_count; }\n-  size_t om_count() { return _om_count; }\n-};\n-\n@@ -99,0 +50,1 @@\n+                         size_t deflated_count,\n@@ -194,0 +146,9 @@\n+  \/\/ Iterate over all ObjectMonitors.\n+  template <typename Function>\n+  static void monitors_iterate(Function function);\n+\n+  \/\/ Iterate ObjectMonitors owned by any thread and where the owner `filter`\n+  \/\/ returns true.\n+  template <typename OwnerFilter>\n+  static void owned_monitors_iterate_filtered(MonitorClosure* closure, OwnerFilter filter);\n+\n@@ -195,8 +156,5 @@\n-  \/\/ ObjectMonitors where owner is set to a stack lock address in thread:\n-  \/\/\n-  \/\/ This version of monitors_iterate() works with the in-use monitor list.\n-  static void monitors_iterate(MonitorClosure* m, JavaThread* thread);\n-  \/\/ This version of monitors_iterate() works with the specified linked list.\n-  static void monitors_iterate(MonitorClosure* closure,\n-                               ObjectMonitorsHashtable::PtrList* list,\n-                               JavaThread* thread);\n+  \/\/ ObjectMonitors where owner is set to a stack lock address in thread.\n+  static void owned_monitors_iterate(MonitorClosure* m, JavaThread* thread);\n+\n+  \/\/ Iterate ObjectMonitors owned by any thread.\n+  static void owned_monitors_iterate(MonitorClosure* closure);\n@@ -207,3 +165,3 @@\n-  \/\/ GC: we currently use aggressive monitor deflation policy\n-  \/\/ Basically we try to deflate all monitors that are not busy.\n-  static size_t deflate_idle_monitors(ObjectMonitorsHashtable* table);\n+  \/\/ We currently use aggressive monitor deflation policy;\n+  \/\/ basically we try to deflate all monitors that are not busy.\n+  static size_t deflate_idle_monitors();\n@@ -215,2 +173,1 @@\n-  static size_t deflate_monitor_list(Thread* current, LogStream* ls, elapsedTimer* timer_p,\n-                                     ObjectMonitorsHashtable* table);\n+  static size_t deflate_monitor_list(Thread* current, LogStream* ls, elapsedTimer* timer_p);\n@@ -226,1 +183,2 @@\n-  static bool request_deflate_idle_monitors();  \/\/ for whitebox test support\n+  static void request_deflate_idle_monitors();\n+  static bool request_deflate_idle_monitors_from_wb();  \/\/ for whitebox test support\n@@ -236,1 +194,1 @@\n-  static void log_in_use_monitor_details(outputStream* out);\n+  static void log_in_use_monitor_details(outputStream* out, bool log_all);\n@@ -274,0 +232,7 @@\n+\/\/ Interface to visit monitors\n+class ObjectMonitorsView {\n+public:\n+  \/\/ Visit monitors that belong to the given thread\n+  virtual void visit(MonitorClosure* closure, JavaThread* thread) = 0;\n+};\n+\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.hpp","additions":29,"deletions":64,"binary":false,"changes":93,"status":"modified"},{"patch":"@@ -788,1 +788,0 @@\n-  nonstatic_field(ciEnv,                       _failure_reason,                               const char*)                           \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -127,1 +127,1 @@\n-serviceability\/dcmd\/gc\/RunFinalizationTest.java 8227120 linux-all,windows-x64,aix-ppc64\n+serviceability\/dcmd\/gc\/RunFinalizationTest.java 8227120 generic-all\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -257,0 +257,1 @@\n+  applications\/ctw\/modules \\\n@@ -402,0 +403,1 @@\n+ -runtime\/Monitor\/ConcurrentDeflation.java \\\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2016, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,1 +29,1 @@\n- * @requires !vm.flightRecorder\n+ * @requires vm.flagless\n@@ -123,1 +123,1 @@\n-            OutputAnalyzer out = ProcessTools.executeTestJvm(options);\n+            OutputAnalyzer out = ProcessTools.executeTestJava(options);\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/plab\/TestPLABPromotion.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -934,1 +934,1 @@\n-            inflatorThread = TestScaffold.newThread(() -> {\n+            inflatorThread = DebuggeeWrapper.newThread(() -> {\n","filename":"test\/jdk\/com\/sun\/jdi\/EATests.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}