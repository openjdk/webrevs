{"files":[{"patch":"@@ -1,59 +0,0 @@\n-Openjdk Babylon is here https:\/\/github.com\/openjdk\/babylon\n-\n-### Building Primer\n-Some useful vars\n-\n-```bash\n-export GITHUB=${HOME}\/github\/grfrost\/\n-export BOOT_JDK=${HOME}\/java\/jdk-22.0.1.jdk\/Contents\/Home\/\n-```\n-\n-```bash\n-cd ${GITHUB}\n-git clone https:\/\/github.com\/opendjk\/babylon.git\n-cd ${GITHUB}\/babylon\n-bash configure  --with-boot-jdk=${BOOT_JDK}\n-make clean\n-make images\n-#Coffee time (about 10 mins?)\n-```\n-\n-In order to run tests we need `jtreg` built using the JDK we just built (I think this is true).\n-\n-```bash\n-export BABYLON_JDK=${GITHUB}\/babylon\/build\/macosx-aarch64-server-release\/jdk\n-export BABYLON_JDK=${GITHUB}\/babylon\/build\/linux-aarch64-server-release\/jdk\n-cd ${GITHUB}\n-git clone https:\/\/github.com\/openjdk\/jtreg\n-cd ${GITHUB}\/jtreg\n-#from doc\/building.md\n-bash make\/build.sh --jdk ${BABYLON_JDK}\n-```\n-\n-Now we can go back and rebuild babylon using `jtreg` in our config  build\n-\n-```bash\n-export JTREG_HOME=${GITHUB}\/jtreg\/build\/images\/jtreg\n-cd ${GITHUB}\/babylon\n-bash configure --with-boot-jdk=${BOOT_JDK}  --with-jtreg=${JTREG_HOME}\n-make clean\n-make images\n-```\n-Once we have built again we can run the `babylon` tests using\n-\n-```bash\n-make test TEST=jdk_lang_reflect_code\n-```\n-This works because we added\n-```\n-8<-\n-jdk_lang_reflect_code = \\\n-   java\/lang\/reflect\/code\n-->8\n-```\n-To the file `${GITHUB}\/babylon\/test\/jdk\/TEST.groups`\n-\n-You can see (and add) the tests in this dir.\n-```\n-test\/jdk\/java\/lang\/reflect\/code\/TestGRF.java\n-```\n","filename":"hat\/docs\/babylon.md","additions":0,"deletions":59,"binary":false,"changes":59,"status":"deleted"},{"patch":"@@ -1,365 +0,0 @@\n-\n-# Cascade Issue\n-I think I am fighting an alignment issue with nested layouts.\n-\n-Ultimately I need to pass this struct to the GPU.\n-\n-```C\n-typedef struct Cascade_s{\n-    int width;\n-    int height;\n-    int featureCount;\n-    struct Feature_t{\n-       int id;\n-       float threshold;\n-       struct LinkOrValue_t{\n-          boolean hasValue;\n-          union Anon_t{\n-             int featureId;\n-             float value;\n-          } anon;\n-       } left, right;\n-       struct Rect_t{\n-          byte x;\n-          byte y;\n-          byte width;\n-          byte height;\n-          float weight;\n-       } rect[3];\n-    } feature[2913];\n-    int stageCount;\n-    struct Stage_t{\n-       int id;\n-       float threshold;\n-       short firstTreeId;\n-       short treeCount;\n-    } stage[25];\n-    int treeCount;\n-    struct Tree_t{\n-       int id;\n-       short firstFeatureId;\n-       short featureCount;\n-    } tree[291\n-} Cascade_t;\n-```\n-\n-I will expand this to a more readable form\n-\n-```C\n-typedef union Anon_s{\n-    int featureId;\n-    float value;\n-}Anon_t;\n-\n-typedef struct LinkOrValue_s{\n-    boolean hasValue;\n-    Anon_t anon;\n-}LinkOrValue_t;\n-\n-typedef struct Rect_s{\n-    byte x;\n-    byte y;\n-    byte width;\n-    byte height;\n-    float weight;\n-}Rect_t;\n-\n-typedef struct Feature_s{\n-    int id;\n-    float threshold;\n-    LinkOrValue_t left;\n-    LinkOrValue_t right;\n-    Rect_t rect[3];\n-}Feature_t;\n-\n-typedef struct Stage_s{\n-    int id;\n-    float threshold;\n-    short firstTreeId;\n-    short treeCount;\n-}Stage_t;\n-\n-typedef struct Tree_s{\n-    int id;\n-    short firstFeatureId;\n-    short featureCount;\n-}Tree_t;\n-\n-typedef struct Cascade_s{\n-    int width;\n-    int height;\n-    int featureCount;\n-    Feature_t feature[2913];\n-    int stageCount;\n-    Stage_t stage[25];\n-    int treeCount;\n-    Tree_t tree[291\n-} Cascade_t;\n-```\n-\n-I use nested mapped segment interfaces, for this `Cascade_t` and the\n-interface `nest` can be found here\n-[Cascade.java](https:\/\/orahub.oci.oraclecorp.com\/gary.frost\/hat\/-\/blame\/main\/examples\/violajones\/src\/java\/violajones\/ifaces\/Cascade.java#L43)\n-(I also added as stripped down version\n-at the end of this doc).\n-\n-To dispatch a kernel, I pass a pointer to a `Cascade_t` to native code,\n-which is then handed off to the GPU. I have observed this alignment issue on\n-Both the GPU and the CPU. It's just harder to debug on the GPU.\n-\n-The first observation is that `sizeof(Cascade_t)` is smaller than the `MemorySegment.sizeInBytes`\n-of the allocated segment.\n-\n-So\n-```c++\n-Cascade_t *cascade =  (Cascade_t *)arg->value.buffer.memorySegment;\n-std::cout << \"sizeof(Cascade_t)       =\"<< sizeof(Cascade_t) <<std::endl;\n-std::cout << \"Cascade_t segment bytes =\"<< (size_t)arg->value.buffer.sizeInBytes<< std::endl;\n-```\n-Produces\n-```\n-sizeof(Cascade_t)       =163448\n-Cascade_t segment bytes =186752\n-```\n-\n-Also I find that whilst  `cascade->width`, `cascade->height` and\n-`cascade->featureCount` are all as expected (first few fields of the struct), the value returned for `cascade->stageCount` is\n-messed up.\n-\n-To me this indicates that the issue is with the array of `Feature_t` following the `featureCount` field.\n-\n-```\n-std::cout << \"cascade->width          =\"<< cascade->width <<std::endl;\n-std::cout << \"cascade->height         =\"<< cascade->height <<std::endl;\n-std::cout << \"cascade->featureCount   =\"<< cascade->featureCount <<std::endl;\n-std::cout << \"cascade->stageCount     =\"<< cascade->stageCount <<std::endl;\n-```\n-Producing\n-```\n-cascade->width          =24\n-cascade->height         =24\n-cascade->featureCount   =2913\n-cascade->stageCount     =?????????? <-- nonsense\n-```\n-\n-So digging deeper ;), if I loop over the `Feature_t`'s on the native side\n-to extract the `id` and hexdump the `Feature_t` using this loop.\n-```C\n-for(int i=0; i<3; i++){ \/\/ first 3 of cascade->featureCount\n-   Feature_t *feature = cascade->feature + i;\n-   Feature_t *feature = &cascade->feature[(long)i];\n-   std::cout << \" feature->id \"<< std::hex << feature->id <<std::dec <<std::endl;\n-   hexdump(feature, sizeof(Feature_t));\n-}\n-```\n-I find that instead of the `id`'s monotonically increasing\n-in value (0,1,2,3,4...) I get nonsense (after the first).\n-\n-```\n-     feature->id 0         <-- expect 0\n-000000: 00 00 00 00 ba 12 01 bd 01 00 00 00 00 00 00 00  ....�..�........\n-000010: 39 9a 05 40 01 00 00 00 00 00 00 00 c5 e6 0d c0  9..@........��.�\n-000020: 06 04 0c 09 00 00 80 bf 06 07 0c 03 00 00 40 40  .......�......@@\n-     feature->id 0         <-- expect 1\n-000000: 00 00 00 00 00 00 00 00<01>00 00 00 98 18 4b 3c  ..............K<\n-000010: 01 00 00 00 00 00 00 00 b2 83 ee bf 01 00 00 00  ........�.�....\n-000020: 00 00 00 00 da e1 a9 3f 06 04 0c 07 00 00 80 bf  ....��?.......�\n-     feature->id 704040a   <-- expect 2\n-000000: 0a 04 04 07 00 00 40 40 00 00 00 00 00 00 00 00  ......@@........\n-000010:<02> 00 00 00 59 a2 b3 3c 01 00 00 00 00 00 00 00  ....Y��<........\n-000020: e2 58 c1 bf 01 00 00 00 00 00 00 00 64 02 88 3f  �X��........d..?\n-```\n-Also note the highlighted values `<01>` and  `<02>`.\n-Which I take to be the `id`'s inside the misaligned structs.\n-To me this indicates that we have a discrepancy in the size of my Typedef  and the layout representing `Feature_t` is 8 bytes longer than the typedef.\n-\n-Indeed if I hack my [Typedef builder code](https:\/\/orahub.oci.oraclecorp.com\/gary.frost\/hat\/-\/blame\/main\/hat\/src\/java\/hat\/backend\/c99codebuilders\/C99HatBuilder.java#L437)  for this one typedef\n-\n-```java\n-\/\/Around Line 444 of C99HatBuilder\n-if (typeDef.name().equals(\"Feature\")){\n-   nl().append(\"char padme[8]\").semicolon();\n-}\n-```\n-Yielding\n-```java\n-typedef struct Feature_s{\n-    int id;\n-    float threshold;\n-    LinkOrValue_t left;\n-    LinkOrValue_t right;\n-    Rect_t rect[3];\n-    char padme[8];   \/\/<---  added by the hack above\n-}Feature_t;\n-```\n-Then rebuild ;) and rerun.  Some sanity starts to return to the debug code I added\n-\n-```\n-sizeof(Cascade_t)       =186752\n-Cascade_t segment bytes =186752   <-- matches above\n-cascade->width          =24\n-cascade->height         =24\n-cascade->featureCount   =2913\n-cascade->stageCount     =25       <--  correct now\n-     feature->id 0\n-000000: 00 00 00 00 ba 12 01 bd 01 00 00 00 00 00 00 00  ....�..�........\n-000010: 39 9a 05 40 01 00 00 00 00 00 00 00 c5 e6 0d c0  9..@........��.�\n-000020: 06 04 0c 09 00 00 80 bf 06 07 0c 03 00 00 40 40  .......�......@@\n-000030: 00 00 00 00 00 00 00 00                          ........\n-     feature->id 1\n-000000: 01 00 00 00 98 18 4b 3c 01 00 00 00 00 00 00 00  ......K<........\n-000010: b2 83 ee bf 01 00 00 00 00 00 00 00 da e1 a9 3f  �.�........��?\n-000020: 06 04 0c 07 00 00 80 bf 0a 04 04 07 00 00 40 40  .......�......@@\n-000030: 00 00 00 00 00 00 00 00                          ........\n-     feature->id 2\n-000000: 02 00 00 00 59 a2 b3 3c 01 00 00 00 00 00 00 00  ....Y��<........\n-000010: e2 58 c1 bf 01 00 00 00 00 00 00 00 64 02 88 3f  �X��........d..?\n-000020: 03 09 12 09 00 00 80 bf 03 0c 12 03 00 00 40 40  .......�......@@\n-000030: 00 00 00 00 00 00 00 00                          ........\n-     feature->id 3\n-000000: 03 00 00 00 a9 83 bc 3b 01 00 00 00 00 00 00 00  ....�.�;........\n-000010: 57 e8 5f bf 01 00 00 00 00 00 00 00 48 88 96 3f  W�_�........H..?\n-000020: 08 12 09 06 00 00 80 bf 08 14 09 02 00 00 40 40  .......�......@@\n-000030: 00 00 00 00 00 00 00 00                          ........\n-```\n-\n-So what is going wrong here?\n-\n-I think that the issue is here\n-```java\n-StructLayout featureLayout = MemoryLayout.structLayout(\n-    JAVA_INT.withName(\"id\"),\n-    JAVA_FLOAT.withName(\"threshold\"),\n-    Feature.LinkOrValue.layout.withName(\"left\"),\n-    Feature.LinkOrValue.layout.withName(\"right\"),\n-    MemoryLayout.sequenceLayout(3, Feature.Rect.layout).withName(\"rect\")\n-);\n-\n-```\n-Which is used to build an array of `Feature_t`'s here\n-```java\n-   JAVA_INT.withName(\"width\"),\n-   JAVA_INT.withName(\"height\"),\n-   JAVA_INT.withName(\"featureCount\"),\n-   sequenceLayout(haarCascade.features.size(), Feature.layout.withName(\"feature\"),\n-   JAVA_INT.withName(\"stageCount\"),\n-   sequenceLayout(haarCascade.stages.size(), Stage.layout.withName(\"stage\"),\n-   JAVA_INT.withName(\"treeCount\"),\n-   sequenceLayout(haarCascade.trees.size(), Tree.layout.withName(\"tree\")\n-```\n-I think that the sequenceLayout is `unnecessarily` padding 8 bytes to each  `Feature_t`... as it builds the array.\n-\n-Let's dump the sizes of typedefs and layouts ;)\n-```C\n-std::cout << \"cascade->featureCount\"<< cascade->featureCount <<std::endl;\n-std::cout << \"cascade->stageCount\"<< cascade->stageCount <<std::endl;\n-std::cout << \"sizeof(Feature_t) \"<< sizeof(Feature_t) <<std::endl;\n-std::cout << \"sizeof(cascade->feature) \"<< sizeof(cascade->feature) <<std::endl;\n-std::cout << \"sizeof(cascade->feature[0]) \"<< sizeof(cascade->feature[0]) <<std::endl;\n-```\n-Yielding the following for the 'padded feature'\n-```\n-cascade->featureCount =2913\n-sizeof(Feature_t) = 56\n-sizeof(cascade->feature) = 163128\n-sizeof(cascade->feature[0]) = 56\n-```\n-And sure enough 2913*56 = 163128\n-vs the following for the unpadded\n-```\n-cascade->featureCount2913\n-sizeof(Feature_t) 48\n-sizeof(cascade->feature) 139824\n-sizeof(cascade->feature[0]) 48\n-```\n-And sure enough 2913*48 = 139824\n-\n-Now the layouts...\n-```java\n-var featureSequenceLayout = sequenceLayout(haarCascade.features.size(), Feature.layout.withName(Feature.class.getSimpleName())).withName(\"feature\");\n-System.out.println(\"Feature.layout.byteSize() \"+Feature.layout.byteSize());\n-System.out.println(\"FeatureSequence.layout.byteSize() \"+featureSequenceLayout.byteSize());\n-```\n-Yielding\n-```\n-Feature.layout.byteSize() 56\n-FeatureSequence.layout.byteSize() 163128\n-```\n-\n-OK I found this\n-```java\n-  StructLayout layout = MemoryLayout.structLayout(\n-                    JAVA_BOOLEAN.withName(\"hasValue\"),\n-                    MemoryLayout.paddingLayout(3), \/\/<-- was 7\n-                    Feature.LinkOrValue.Anon.layout.withName(\"anon\")\n-                ).withName(\"LinkOrValue\");\n-```\n------\n-###  Here are layouts for the Cascade.\n-\n-```java\n-public interface Cascade extends CompleteBuffer {\n-    interface Feature {\n-        interface Rect {\n-            StructLayout layout = MemoryLayout.structLayout(\n-               JAVA_BYTE.withName(\"x\"),\n-               JAVA_BYTE.withName(\"y\"),\n-               JAVA_BYTE.withName(\"width\"),\n-               JAVA_BYTE.withName(\"height\"),\n-               JAVA_FLOAT.withName(\"weight\")\n-            ).withName(\"Rect\");\n-        }\n-        interface LinkOrValue {\n-            interface Anon {\n-                MemoryLayout layout = MemoryLayout.unionLayout(\n-                        JAVA_INT.withName(\"featureId\"),\n-                        JAVA_FLOAT.withName(\"value\")\n-                ).withName(\"Anon\");\n-            }\n-\n-            StructLayout layout = MemoryLayout.structLayout(\n-                JAVA_BOOLEAN.withName(\"hasValue\"),\n-                MemoryLayout.paddingLayout(7),\n-                Anon.layout.withName(\"anon\")\n-            ).withName(\"LinkOrValue\");\n-        }\n-\n-        StructLayout layout = MemoryLayout.structLayout(\n-            JAVA_INT.withName(\"id\"),\n-            JAVA_FLOAT.withName(\"threshold\"),\n-            Feature.LinkOrValue.layout.withName(\"left\"),\n-            Feature.LinkOrValue.layout.withName(\"right\"),\n-            MemoryLayout.sequenceLayout(3, Feature.Rect.layout).withName(\"rect\")\n-        );\n-    }\n-\n-    interface Stage {\n-        StructLayout layout = MemoryLayout.structLayout(\n-                JAVA_INT.withName(\"id\"),\n-                JAVA_FLOAT.withName(\"threshold\"),\n-                JAVA_SHORT.withName(\"firstTreeId\"),\n-                JAVA_SHORT.withName(\"treeCount\")\n-        ).withName(\"Stage\");\n-    }\n-    interface Tree {\n-        StructLayout layout = MemoryLayout.structLayout(\n-           JAVA_INT.withName(\"id\"),\n-           JAVA_SHORT.withName(\"firstFeatureId\"),\n-           JAVA_SHORT.withName(\"featureCount\")\n-        ).withName(\"Tree\");\n-    }\n-\n-    static Cascade create(Accelerator accelerator, XMLHaarCascadeModel haarCascade) {\n-        return SegmentMapper.of(accelerator.lookup, Cascade.class,\n-          JAVA_INT.withName(\"width\"),\n-          JAVA_INT.withName(\"height\"),\n-          JAVA_INT.withName(\"featureCount\"),\n-          sequenceLayout(haarCascade.features.size(), Feature.layout.withName(\"feature\"),\n-          JAVA_INT.withName(\"stageCount\"),\n-          sequenceLayout(haarCascade.stages.size(), Stage.layout.withName(\"stage\"),\n-          JAVA_INT.withName(\"treeCount\"),\n-          sequenceLayout(haarCascade.trees.size(), Tree.layout.withName(\"tree\")\n-        ).allocate(accelerator.arena());\n-    }\n-}\n-```\n","filename":"hat\/docs\/cascade.md","additions":0,"deletions":365,"binary":false,"changes":365,"status":"deleted"},{"patch":"@@ -0,0 +1,20 @@\n+\n+# Hat\n+\n+----\n+\n+* [Contents](hat-00.md)\n+* House Keeping\n+    * [Project Layout](hat-01-01-project-layout.md)\n+    * [Building Babylon](hat-01-02-building-babylon.md)\n+    * [Maven and CMake](hat-01-03-maven-cmake.md)\n+* Programming Model\n+    * [Programming Model](hat-03-programming-model.md)\n+* Interface Mapping\n+    * [Interface Mapping Overview](hat-04-01-interface-mapping.md)\n+    * [Cascade Interface Mapping](hat-04-02-cascade-interface-mapping.md)\n+* Implementation Detail\n+    * [Walkthrough Of Accelerator.compute()](hat-accelerator-compute.md)\n+\n+---\n+\n","filename":"hat\/docs\/hat-00.md","additions":20,"deletions":0,"binary":false,"changes":20,"status":"added"},{"patch":"@@ -0,0 +1,68 @@\n+\n+# Project Layout\n+\n+----\n+\n+* [Contents](hat-00.md)\n+* House Keeping\n+    * [Project Layout](hat-01-01-project-layout.md)\n+    * [Building Babylon](hat-01-02-building-babylon.md)\n+    * [Maven and CMake](hat-01-03-maven-cmake.md)\n+* Programming Model\n+    * [Programming Model](hat-03-programming-model.md)\n+* Interface Mapping\n+    * [Interface Mapping Overview](hat-04-01-interface-mapping.md)\n+    * [Cascade Interface Mapping](hat-04-02-cascade-interface-mapping.md)\n+* Implementation Detail\n+    * [Walkthrough Of Accelerator.compute()](hat-accelerator-compute.md)\n+\n+---\n+\n+# Primer\n+\n+This is a fairly large project with Java and Native artifacts which is completely dependant\n+on the `babylon` project, and as such is initially available in a sub directory\n+called `hat` under [github.com\/openjdk\/babylon](https:\/\/github.com\/openjdk\/babylon)\n+\n+## Project Layout\n+\n+```\n+${BABYLON_JDK}\n+   └── hat\n+        │\n+        ├── CMakeFile\n+        ├── build\n+        │\n+        ├── intellij\n+        │    ├── .idea\n+        │    │    ├── compiler.xml\n+        │    │    ├── misc.xml\n+        │    │    ├── modules.xml\n+        │    │    ├── uiDesigner.xml\n+        │    │    ├── vcs.xml\n+        │    │    └── workspace.xml\n+        │    │\n+        │    ├── hat.iml\n+        │    ├── backend_(spirv|mock|cuda|ptx|opencl).iml\n+        │    └── (mandel|violajones|experiments).iml\n+        │\n+        ├── hat\n+        │    └── src\n+        │         └── java\n+        │\n+        ├── backends\n+        │    └── (opencl|cuda|ptx|mock|shared)\n+        │          └── src\n+        │              ├── cpp\n+        │              ├── include\n+        │              ├── java\n+        │              └── services\n+        └── examples\n+             ├── mandel\n+             │    └── src\n+             │         └── java\n+             └── violajones\n+                  └── src\n+                       ├── java\n+                       └── resources\n+```\n","filename":"hat\/docs\/hat-01-01-project-layout.md","additions":68,"deletions":0,"binary":false,"changes":68,"status":"added"},{"patch":"@@ -0,0 +1,98 @@\n+\n+# Building Babylon\n+\n+----\n+\n+* [Contents](hat-00.md)\n+* House Keeping\n+  * [Project Layout](hat-01-01-project-layout.md)\n+  * [Building Babylon](hat-01-02-building-babylon.md)\n+  * [Maven and CMake](hat-01-03-maven-cmake.md)\n+* Programming Model\n+  * [Programming Model](hat-03-programming-model.md)\n+* Interface Mapping\n+  * [Interface Mapping Overview](hat-04-01-interface-mapping.md)\n+  * [Cascade Interface Mapping](hat-04-02-cascade-interface-mapping.md)\n+* Implementation Detail\n+  * [Walkthrough Of Accelerator.compute()](hat-accelerator-compute.md)\n+\n+---\n+\n+# Building Babylon\n+\n+Openjdk Babylon can be found here [https:\/\/github.com\/openjdk\/babylon](https:\/\/github.com\/openjdk\/babylon)\n+\n+## Some useful vars\n+\n+You will need an existing version of JDK to build babylon and jtreg.\n+\n+The following build process assumes you have `BOOT_JDK` set to an existing JDK\n+\n+```bash\n+export BOOT_JDK=${HOME}\/java\/jdk-22.0.1.jdk\/Contents\/Home\/\n+```\n+### Clone Babylon from github\n+\n+[https:\/\/github.com\/opendjk\/babylon.git](https:\/\/github.com\/opendjk\/babylon.git)\n+\n+```bash\n+export GITHUB=${HOME}\/github\n+mkdir -p ${GITHUB}\n+cd ${GITHUB}\n+git clone https:\/\/github.com\/opendjk\/babylon.git\n+```\n+### Get and build jtreg\n+\n+In order to run openjdk tests we will need to build `jtreg`\n+\n+[https:\/\/github.com\/openjdk\/jtreg](https:\/\/github.com\/openjdk\/jtreg)\n+\n+```bash\n+cd ${GITHUB}\n+git clone https:\/\/github.com\/openjdk\/jtreg\n+export JTREG=${GITHUB}\/jtreg\n+cd ${JTREG}\n+bash make\/build.sh --jdk ${BOOT_JDK}\n+```\n+### Configure\n+\n+```bash\n+cd ${GITHUB}\/babylon\n+bash configure  --with-boot-jdk=${BOOT_JDK} --with-jtreg=${JTREG}\/build\/images\/jtreg\n+```\n+On your first build configure might exit and suggest installing other\n+dependencies.  Generally I suggest just taking its recommendations and\n+restarting configure\n+\n+Eventually we should complete and are ready to build\n+\n+### Build\n+\n+```bash\n+make clean\n+make images\n+#Coffee time (about 10 mins?)\n+```\n+\n+### Run JTREG Tests\n+If we included jtreg above we can run the `babylon` tests using\n+\n+```bash\n+cd ${GITHUB}\/babylon\n+make test TEST=jdk_lang_reflect_code\n+```\n+\n+This works because we added\n+```\n+8<-\n+jdk_lang_reflect_code = \\\n+   java\/lang\/reflect\/code\n+->8\n+```\n+To the file `${GITHUB}\/babylon\/test\/jdk\/TEST.groups`\n+\n+The tests themselves can be found in this directory\n+\n+```\n+tree {GITHUB}\/babylon}\/test\/jdk\/java\/lang\/reflect\/code\n+```\n","filename":"hat\/docs\/hat-01-02-building-babylon.md","additions":98,"deletions":0,"binary":false,"changes":98,"status":"added"},{"patch":"@@ -0,0 +1,35 @@\n+\n+# Building HAT\n+\n+----\n+\n+* [Contents](hat-00.md)\n+* House Keeping\n+    * [Project Layout](hat-01-01-project-layout.md)\n+    * [Building Babylon](hat-01-02-building-babylon.md)\n+    * [Maven and CMake](hat-01-03-maven-cmake.md)\n+* Programming Model\n+    * [Programming Model](hat-03-programming-model.md)\n+* Interface Mapping\n+    * [Interface Mapping Overview](hat-04-01-interface-mapping.md)\n+    * [Cascade Interface Mapping](hat-04-02-cascade-interface-mapping.md)\n+* Implementation Detail\n+    * [Walkthrough Of Accelerator.compute()](hat-accelerator-compute.md)\n+\n+---\n+\n+# Building HAT\n+\n+We use maven as the primary build tool, but we also required cmake to be available\n+as maven delegates to cmake to building native OpenCL\/CUDA libs in the various backends.\n+\n+Whilst the root level cmake `CMakeLists.txt` can create some java artifacts, it should not be\n+relied on, and will probably be 'deprecated soon'\n+\n+To build with maven\n+\n+```bash\n+cd ${GITHUB}\/babylon\n+mvn clean compile jar:jar install\n+```\n+\n","filename":"hat\/docs\/hat-01-03-maven-cmake.md","additions":35,"deletions":0,"binary":false,"changes":35,"status":"added"},{"patch":"@@ -0,0 +1,119 @@\n+\n+#  Intellij and Clion\n+----\n+\n+* [Contents](hat-00.md)\n+* House Keeping\n+    * [Project Layout](hat-01-01-project-layout.md)\n+    * [Building Babylon](hat-01-02-building-babylon.md)\n+    * [Maven and CMake](hat-01-03-maven-cmake.md)\n+* Programming Model\n+    * [Programming Model](hat-03-programming-model.md)\n+* Interface Mapping\n+    * [Interface Mapping Overview](hat-04-01-interface-mapping.md)\n+    * [Cascade Interface Mapping](hat-04-02-cascade-interface-mapping.md)\n+* Implementation Detail\n+    * [Walkthrough Of Accelerator.compute()](hat-accelerator-compute.md)\n+\n+---\n+\n+## Intellij and Clion\n+\n+We can use JetBrains' `IntelliJ` and `Clion` for dev work and\n+decided to leave some project artifacts in the repo.\n+\n+Care must be taken with Intellij and Clion\n+as these tools do not play well together,\n+specifically we cannot have `Clion` and `Intellij`\n+project artifacts rooted under each other or in the same dir.\n+\n+### Intellij\n+The `intellij` subdir under the root HAT directory\n+contains the `.idea` project dir and the various `*.iml` files\n+for each of the various `modules`\n+(note the use of `Intellji`'s meaning of the word of module here)\n+\n+As you will note the `intellij` dir is somewhat self contained.  the various `*.iml`\n+files refer to the source dirs using relative paths.\n+\n+I tend to add `Intellij` modules by hand.  There are gotchas ;)\n+\n+As with every intellij project, `.idea\/modules.xml` 'points' to the iml files for each module (intellij's notion of module ;) )\n+```xml\n+<!--\n+   └──hat\n+       └── intellij\n+            └── .idea\n+                 └── modules.xml\n+-->\n+ <modules>\n+      <module fileurl=\"file:\/\/$PROJECT_DIR$\/hat.iml\"   \/>\n+      <module fileurl=\"file:\/\/$PROJECT_DIR$\/backend_opencl.iml\"  \/>\n+      <!-- yada yada -->\n+ <\/modules>\n+\n+```\n+\n+The various `.iml` files then  have relative paths to their source\/resource dirs roots.\n+\n+```xml\n+<module type=\"JAVA_MODULE\" version=\"4\">\n+  <component name=\"NewModuleRootManager\" inherit-compiler-output=\"true\">\n+    <exclude-output \/>\n+    <content url=\"file:\/\/$MODULE_DIR$\/..\/..\/..\/hat\/src\/java\">\n+      <sourceFolder url=\"file:\/\/$MODULE_DIR$\/..\/..\/..\/hat\/src\/java\" isTestSource=\"false\" \/>\n+    <\/content>\n+    <orderEntry type=\"inheritedJdk\" \/>\n+    <orderEntry type=\"sourceFolder\" forTests=\"false\" \/>\n+    <orderEntry type=\"module\" module-name=\"hat\" \/>\n+  <\/component>\n+<\/module>\n+\n+```\n+\n+Making run configurations available to other developers is probably `a bridge too far`\n+\n+But with some careful XML tooling we can make it easier to add 'run configurations'.\n+\n+### How intellij stores run configurations\n+\n+I also tend to hand hack run configurations so will leave this here for reference\n+\n+```xml\n+<component name=\"RunManager\" selected=\"Application.MandelTest\">\n+    <configuration name=\"Mandel\" type=\"Application\"\n+                   factoryName=\"Application\" temporary=\"true\"\n+                   nameIsGenerated=\"true\">\n+      <option name=\"MAIN_CLASS_NAME\" value=\"mandel.Mandel\" \/>\n+      <module name=\"mandel\" \/>\n+      <option name=\"VM_PARAMETERS\" value=\"\n+          --enable-preview\n+          --add-exports=java.base\/java.lang.reflect.code.descriptor.impl=ALL-UNNAMED\n+          --add-exports=java.base\/java.lang.foreign.mapper=ALL-UNNAMED\n+          --patch-module=java.base=$PROJECT_DIR$\/out\/production\/java_base_patch\n+          -Djava.lang.foreign.mapper.debug=true\" \/>\n+      <extension name=\"coverage\">\n+        <pattern>\n+          <option name=\"PATTERN\" value=\"mandel.*\" \/>\n+          <option name=\"ENABLED\" value=\"true\" \/>\n+        <\/pattern>\n+      <\/extension>\n+      <method v=\"2\">\n+        <option name=\"Make\" enabled=\"true\" \/>\n+      <\/method>\n+    <\/configuration>\n+    <!-- more configs -->\n+<\/component>\n+```\n+\n+### Clion\n+\n+Thankfully Clion uses cmake, so we get to re-use the CMakeLists.txt in the various backends to build.\n+\n+The intent is that these cmake artifacts can be run standalone (using cmake in the appropriate dir),\n+from within Clion and can be used by maven.  So the CMakeLists.txt files have some extra variables to\n+help us use them in these three modes.\n+\n+\n+\n+\n","filename":"hat\/docs\/hat-01-04-intellij.md","additions":119,"deletions":0,"binary":false,"changes":119,"status":"added"},{"patch":"@@ -0,0 +1,147 @@\n+\n+# HAT's Programming Model\n+----\n+\n+* [Contents](hat-00.md)\n+* House Keeping\n+    * [Project Layout](hat-01-01-project-layout.md)\n+    * [Building Babylon](hat-01-02-building-babylon.md)\n+    * [Maven and CMake](hat-01-03-maven-cmake.md)\n+* Programming Model\n+    * [Programming Model](hat-03-programming-model.md)\n+* Interface Mapping\n+    * [Interface Mapping Overview](hat-04-01-interface-mapping.md)\n+    * [Cascade Interface Mapping](hat-04-02-cascade-interface-mapping.md)\n+* Implementation Detail\n+    * [Walkthrough Of Accelerator.compute()](hat-accelerator-compute.md)\n+\n+---\n+\n+#  HAT's Programming model\n+\n+Let's consider a trivial opencl kernel which squares each element in an int buffer\n+\n+```java\n+int square(int value){\n+    return value*value;\n+}\n+\n+__kernel void squareKernel( __global int* s32Array){\n+    int value = s32Array[get_global_id(0)];\n+    s32Array[get_global_id(0)]=square(value);\n+    return;\n+}\n+\n+```\n+\n+We implement this in HAT by collecting the kernel(s) and compute method(s) in a `Compute` class.\n+\n+```java\n+public class SquareCompute {\n+    @CodeReflection\n+    public static int square(int v) {\n+        return v * v;\n+    }\n+\n+    @CodeReflection\n+    public static void squareKernel(KernelContext kc, S32Array s32Array) {\n+        int value = s32Array.array(kc.x);     \/\/ arr[cc.x]\n+        s32Array.array(kc.x, square(value));  \/\/ arr[cc.x]=value*value\n+    }\n+\n+    @CodeReflection\n+    public static void square(ComputeContext cc, S32Array s32Array) {\n+        cc.dispatchKernel(s32Array.length(),\n+                kc -> squareKernel(kc, s32Array)\n+        );\n+    }\n+}\n+```\n+And we dispatch by creating the appropriate data buffer and then asking an `Accelerator` (bound to a typical vendor backend) to execute the compute method.. which in turn coordinates the dispatch of the various kernels.\n+\n+```java\n+  \/\/ Create an accelerator bound to a particular backend\n+\n+  var accelerator = new Accelerator(\n+      java.lang.invoke.MethodHandles.lookup(),\n+      Backend.FIRST  \/\/ Predicate<Backend>\n+  );\n+\n+  \/\/ Ask the accelerator\/backend to allocate an S32Array\n+  var s32Array = S32Array.create(accelerator, 32);\n+\n+  \/\/ Fill it with data\n+  for (int i = 0; i < s32Array.length(); i++) {\n+      s32Array.array(i, i);\n+  }\n+\n+  \/\/ Tell the accelerator to execute the square() compute entrypoint\n+\n+  accelerator.compute(\n+     cc -> SquareCompute.square(cc, s32Array)\n+  );\n+\n+  \/\/ Check the data\n+  for (int i = 0; i < arr.length(); i++) {\n+      System.out.println(i + \" \" + arr.array(i));\n+  }\n+```\n+\n+## Programming model notes\n+\n+The most important concept here is that we separate `normal java` code,\n+from `compute` code from `kernel` code\n+\n+We must not assume that Compute or Kernel code are ever executed by the JVM\n+\n+### Kernel Code (kernel entrypoints and kernel reachable methods)\n+Kernel's and any kernel reachable methods will naturally be restricted to subset of Java.\n+\n+* No exceptions (no exceptions! :) )\n+* No heap access (no `new`)\n+* No access to static or instance fields from this or any other classes )\n+    * Except `final static primitives` (which generally get constant pooled)\n+    * Except fields of `KernelContext` (thread identity `.x`, `.maxX`, `.groups`... )\n+        - We may even decide to access these via methods (`.x()`);\n+* The only methods that can be called are either :-\n+   * Kernel reachable methods\n+      - Technically you can call a kernel entrypoint, but must pass your KernelContext\n+   * `ifaceMappedSegment` accessor\/mutators (see later)\n+   * Calls on `KernelContext` (backend kernel features)\n+     - `KernelContext.barrier()`\n+     - `kernelContext.I32.hypot(x,y)`\n+#### Kernel Entrypoints\n+* Declared `@CodeReflection static public void`\n+    * Later we may allow reductions to return data...\n+* Parameters\n+    * 0 is always a `KernelContext` (KernelContext2D, KernelContext3D logically follow)\n+    * 1..n are restricted to uniform primitive values and Panama FFM `ifaceMappedSegments`\n+\n+#### Kernel Reachable Methods\n+* Declared `@CodeReflection static public`\n+* All Parameters are restricted to uniform primitive values and Panama FFM `ifaceMappedSegments`\n+\n+### Compute Code (Compute entry points and compute reachable methods)\n+Code within the `compute entrypoint` and `compute reachable\n+methods` have much fewer Java restrictions than kernels but generally...\n+\n+* Exceptions are discouraged\n+* Java Synchronization is discouraged\n+* Don't assume any allocation of local `ifaceMappedSegmants` are allocated\n+* Java accesses\/mutations to `ifaceMappedSegment` will likely impact performance\n+* Code should ideally just contain simple control flow and kernel dispatches.\n+* Data movements (to and from backend) will automatically be derived from control flow and `ifaceMappedSegment` accesses\n+   - We hope to never have to add `cc.moveToDevice(hatBuffer)`\n+* All methods reachable from a `compute entrypoint` are either :-\n+  * Compute Reachable Methods\n+      - Technically methods can be compute reachable and kernel reachable.\n+  * `ifaceMappedSegment` accessor\/mutators (see later)\n+  * Calls on the `ComputeContext` to generate ranges, or dispatch kernels.\n+\n+#### Compute Entry Points\n+* Declared `@CodeReflection static public void`\n+* Parameter 0 is `ComputeContext`\n+\n+\n+#### Compute Reachable Methods\n+* Declared `@CodeReflection static public `\n","filename":"hat\/docs\/hat-03-programming-model.md","additions":147,"deletions":0,"binary":false,"changes":147,"status":"added"},{"patch":"@@ -0,0 +1,352 @@\n+\n+# Interface Mapping\n+\n+----\n+\n+* [Contents](hat-00.md)\n+* House Keeping\n+    * [Project Layout](hat-01-01-project-layout.md)\n+    * [Building Babylon](hat-01-02-building-babylon.md)\n+    * [Maven and CMake](hat-01-03-maven-cmake.md)\n+* Programming Model\n+    * [Programming Model](hat-03-programming-model.md)\n+* Interface Mapping\n+    * [Interface Mapping Overview](hat-04-01-interface-mapping.md)\n+    * [Cascade Interface Mapping](hat-04-02-cascade-interface-mapping.md)\n+* Implementation Detail\n+    * [Walkthrough Of Accelerator.compute()](hat-accelerator-compute.md)\n+\n+----\n+# Interface Mapping\n+\n+## or ... HAT from a Data POV\n+\n+### Or ... what is this `S32Array` thing and why can't I just pass `int[]` to my kernel\n+\n+Again here is the canonical HAT 'hello world' kernel, weill use this to describe itgerface mapping\n+\n+We implement this in HAT by collecting the kernel(s) and compute method(s) in a `Compute` class.\n+\n+```java\n+public class SquareCompute {\n+    @CodeReflection\n+    public static int square(int v) {\n+        return v * v;\n+    }\n+\n+    @CodeReflection\n+    public static void squareKernel(KernelContext kc, S32Array s32Array) {\n+        int value = s32Array.array(kc.x);     \/\/ arr[cc.x]\n+        s32Array.array(kc.x, square(value));  \/\/ arr[cc.x]=value*value\n+    }\n+\n+    @CodeReflection\n+    public static void square(ComputeContext cc, S32Array s32Array) {\n+        cc.dispatchKernel(s32Array.length(),\n+                kc -> squareKernel(kc, s32Array)\n+        );\n+    }\n+}\n+```\n+Which we dispatch by creating the appropriate data buffer and then asking an `Accelerator` (bound to a typical vendor backend) to execute the compute method.. which in turn coordinates the dispatch of the various kernels.\n+\n+```java\n+  \/\/ Create an accelerator bound to a particular backend\n+\n+  var accelerator = new Accelerator(\n+      java.lang.invoke.MethodHandles.lookup(),\n+      Backend.FIRST  \/\/ Predicate<Backend>\n+  );\n+\n+  \/\/ Ask the accelerator\/backend to allocate an S32Array\n+  var s32Array = S32Array.create(accelerator, 32);\n+\n+  \/\/ Fill it with data\n+  for (int i = 0; i < s32Array.length(); i++) {\n+      s32Array.array(i, i);\n+  }\n+\n+  \/\/ Tell the accelerator to execute the square() compute entrypoint\n+\n+  accelerator.compute(\n+     cc -> SquareCompute.square(cc, s32Array)\n+  );\n+\n+  \/\/ Check the data\n+  for (int i = 0; i < arr.length(); i++) {\n+      System.out.println(i + \" \" + arr.array(i));\n+  }\n+```\n+\n+HAT kernels only accept Java primitives and HAT buffers as parameters.\n+\n+We don't directly support heap allocated data (such as int[])\n+\n+From Java's point of view `S32Array` is a `hat.Buffer` and is defined as an interface.\n+\n+```java\n+public interface S32Array extends Buffer {\n+    int length();\n+    void length(int i);\n+    int array(long idx);\n+    void array(long idx, int i);\n+}\n+```\n+\n+From C99 style OpenCL\/CUDA POV this will eventually be mapped to a typedef.\n+\n+```C++\n+typedef struct S32Array_s{\n+    int length;\n+    int array[];  \/\/<-- ?\n+}S32Array_t;\n+```\n+\n+Our Java implementations should treat the interface as `data`, generally the only\n+methods that we include in a `hat.Buffer` should be\n+\n+```java\n+T name();                    \/\/getter for a field called name with type T, where T may be primitive or inner interface)\n+void name(T name);           \/\/setter for a field called name with type T, T must be  primitive\n+T name(long idx);            \/\/get an array element [idx] where array is called name and T is either primitive or inner interface\n+void name(long idx, T name); \/\/set an array element [idx] where array is called name and T is primitive\n+```\n+\n+Algorithms can assume that an interface is 'bound' to 'some' concrete data layout.\n+\n+We could for example implement `S32Array` like this.\n+\n+```java\n+class JavaS32Array implements S32Array{\n+     int[] arr;\n+     int length(){ return arr.length;}\n+     int array(long idx) {return arr[idx];}\n+     void array(long idx, int value) {arr[idx] = value;}\n+     void length(int len) ; \/\/ we'll come back to this ;)\n+}\n+```\n+\n+But for HAT to access native memory, allocated by the appropriate backend we need interfaces bound to MemorySegents\/\n+\n+HAT includes an API which allows us to take an interface which extends `hat.Buffer`, and 'bind' it to a Panama FFM MemorySegment.\n+\n+This binding process automatically maps the accessors (for example `length()`, `array(long idx, int v)`) to low level Method and Var handel trickery underlying MemorySegments.\n+\n+Conceptually we might imagine that HAT creates something like this\n+\n+```java\n+class PanamaS32Array implements S32Array{\n+     MemorySegment segment;\n+     final int SIZEOFINT = 4;\n+     final long lenOffset = 0;\n+     final long arrayOffset = lenOffset+SIZEOFINT;\n+     int length(){ return segment.getInt(lenOffset);}\n+     int array(long idx) {return segment.getInt(arrayOffset+idx*SIZEOFINT);}\n+     void array(long idx, int value) {segment.setInt(arrayOffset+idx*SIZEOFINT,value);}\n+     void length(int len) ; \/\/ we'll come back to this ;)\n+}\n+```\n+\n+Much like Java's `Proxy` class, the iface mapper creates an implementation of the interface  'on the fly', the new Classfile API is used to 'spin up' the new class and the accessors are are composed using Var\/Method Handles and offsets derived from the size and order of fields.\n+\n+Sadly an interface is not quite enough to establish exactly what is needed to complete the mapping.  We need to tell the `iface mapper` the order and size of fields and possibly some padding information.\n+\n+We do this by providing a 'layout description' using Panama's Layout api.\n+\n+```java\n+MemoryLayout s32ArrayLayout = MemoryLayout.structLayout(\n+        JAVA_INT.withName(\"length\"),\n+        MemoryLayout.sequenceLayout(N, JAVA_INT.withName(\"length\")).withName(\"array\")\n+).withName(S32Array.getSimpleName());\n+```\n+\n+Eventually we came to a common pattern for describing HAT buffers by adding a `create` method to our interface which hides the mapping detail\n+\n+So the complete `S32Array` looks a like this. (....ish)\n+\n+```java\n+public interface S32Array extends Buffer {\n+    int length();\n+\n+    void length(int i);\n+\n+    int array(long idx);\n+\n+    void array(long idx, int i);\n+\n+    S32Array create(Accelerator a, int len) {\n+        MemoryLayout s32ArrayLayout = MemoryLayout.structLayout(\n+                JAVA_INT.withName(\"length\"),\n+                MemoryLayout.sequenceLayout(len, JAVA_INT.withName(\"length\")).withName(\"array\")\n+        ).withName(S32Array.getSimpleName());\n+\n+        S32Array s32Array = a.allocate(\n+                SegmentMapper.of(MethodHandles.lookup(), S32Array.class, s32ArrayLayout, len)\n+        );\n+\n+        return s32Array;\n+    }\n+}\n+```\n+\n+So now hopefully this code makes more sense.\n+\n+```\n+var s32Array = S32Array.create(accelerator, 32);\n+```\n+\n+Whilst this code is much nicer than hand mapping each method to offsets.  It is still quite verbose.\n+\n+In the last few weeks we have been migrating to Schema builder which makes this code easier to express..\n+\n+```java\n+public interface S32Array extends Buffer {\n+    int length();\n+    void length(int i);\n+    int array(long idx);\n+    void array(long idx, int i);\n+    Schema<S32Array> schema = Schema.of(S32Array.class, s->s\n+        .arrayLen(\"length\")\n+        .array(\"array\")\n+    );\n+}\n+```\n+The schema is embedded inside the interface and defines the order of fields. It also allows us to bind fields to each other (above we are telling the schema we have a `int length` field followed by an `int array[]` field and that the first defines the size of the second), we also can describe useful 'HAT' information for fields. Such as whether a field is 'atomic' ;)\n+\n+Here is an example of a table of Results for the face detector.\n+\n+```java\n+public interface ResultTable extends Buffer{\n+    interface Result extends Buffer.StructChild {\n+        float x();\n+        void x(float x);\n+        float y();\n+        void y(float y);\n+    }\n+    void count(int count);\n+    int count();\n+    int length();\n+    Result result(long idx);\n+\n+    Schema<ResultTable> schema = Schema.of(ResultTable.class, s->s\n+            .atomic(\"count\")\n+            .arrayLen(\"length\")\n+            .array(\"result\", r->r\n+               .field(\"x\")\n+               .field(\"y\")\n+            )\n+    );\n+}\n+```\n+\n+Which in C99 OpenCL code will manifest as\n+\n+```C++\n+typedef Result_s{\n+   int x,y\n+} Result_t;\n+\n+typedef ResultTable_s{\n+   int count;\n+   int length;\n+   Result_t result[0];\n+} Result_t;\n+```\n+\n+In our Java code this interface makes access to MemorySegments much cleaner\n+\n+```java\n+    ResultTable resultTable = ResultTable.create(acc, 100);\n+    for (int i=0; i<resultTable.length(); i++){\n+        Result result = resultTable.result(i);\n+        result.x(0);\n+        result.y(0);\n+    }\n+```\n+\n+The generated OpenCL\/C99 code from Java kernel code is also quite clean\n+\n+We might use a kernel to initialize the location of a bunch of Results\n+\n+```java\n+    @CodeReflection public static void init(KernelContext kc, ResultTable resultTable) {\n+        if (kc.x < kc.maxX){\n+           Result result = resulTable.result(kc.x);\n+           result.x(kc.x);\n+           result.y(100);\n+        }\n+    }\n+```\n+\n+Whose Kernel code will look like this.\n+\n+```\n+typedef struct KernelContext_s{\n+    int x;\n+    int maxX;\n+}KernelContext_t;\n+\n+typedef Result_s{\n+   int x,y\n+} Result_t;\n+\n+typedef ResultTable_s{\n+   int count;\n+   int length;\n+   Result_t result[0];\n+} Result_t;\n+\n+__kernel void init(\n+    __global KernelContext_t *empty,\n+    __global ResultTable_t* resultTable\n+){\n+    KernelContext_t kernelContext;\n+    KernelContext_t *kc = &kernelContext;\n+    kc->x=get_global_id(0);\n+    kc->maxX = get_global_id(0);\n+\n+    if(kc->x<kc->maxX){\n+        __global Result_t *result = &resultTable[kc->x];\n+        result->x = kc->x;\n+    }\n+    return;\n+}\n+```\n+\n+A few notes from this generated code...\n+\n+* `KernelContext` is itself just an iface mapped segment.\n+    -  But we don't pass `kc.x` o `kc.maxX` in the segment.\n+        -  Instead initialize using appropriate  vendor calls\n+\n+So for OpenCL all kernels start like this\n+\n+```\n+__kernel void init(__global KernelContext_t *empty , ....){\n+    KernelContext_t kernelContext;\n+    KernelContext_t *kc = &kernelContext;\n+    kc->x=get_global_id(0);\n+    kc->maxX = get_global_id(0);\n+     ....\n+}\n+```\n+\n+Whereas CUDA ;)\n+\n+```\n+__kernel void init(__global KernelContext_t *empty , ....){\n+    KernelContext_t kernelContext;\n+    KernelContext_t *kc = &kernelContext;\n+    kc->x=blockIdx.x*blockDim.x+threadIdx.x;\n+    kc->maxX =gridDim.x*blockDim.x\n+    ....\n+}\n+```\n+\n+This simplifies code gen. Generally the CUDA code and OpenCL code looks identical.\n+\n+----\n+\n+The iface mapping code in hat is a modified form of the code hereWe have a copy of Per's segment mapping code from\n+\n+https:\/\/github.com\/minborg\/panama-foreign\/blob\/segment-mapper\/src\/java.base\/share\/classes\n","filename":"hat\/docs\/hat-04-01-interface-mapping.md","additions":352,"deletions":0,"binary":false,"changes":352,"status":"added"},{"patch":"@@ -0,0 +1,228 @@\n+\n+# More Complex Interface Mapping Example - The Cascade\n+\n+----\n+\n+* [Contents](hat-00.md)\n+* House Keeping\n+    * [Project Layout](hat-01-01-project-layout.md)\n+    * [Building Babylon](hat-01-02-building-babylon.md)\n+    * [Maven and CMake](hat-01-03-maven-cmake.md)\n+* Programming Model\n+    * [Programming Model](hat-03-programming-model.md)\n+* Interface Mapping\n+    * [Interface Mapping Overview](hat-04-01-interface-mapping.md)\n+    * [Cascade Interface Mapping](hat-04-02-cascade-interface-mapping.md)\n+* Implementation Detail\n+    * [Walkthrough Of Accelerator.compute()](hat-accelerator-compute.md)\n+\n+----\n+\n+# More Complex Interface Mapping Example - The Cascade\n+\n+Previously we showed probably the minimal useful mapping with S32Array\n+\n+The HaarCascade example has multiple nested interfaces representing data\n+structures involving various nested structs and unions\n+\n+```java\n+public interface Cascade extends Buffer {\n+    int width();\n+    void width(int width);\n+    int height();\n+    void height(int height);\n+    interface Feature extends Buffer.StructChild {\n+        int id();\n+        float threshold();\n+        void id(int id);\n+        void threshold(float threshold);\n+        interface LinkOrValue extends Buffer.StructChild {\n+            interface Anon extends Buffer.UnionChild {\n+                int featureId();\n+                void featureId(int featureId);\n+                float value();\n+                void value(float value);\n+            }\n+            boolean hasValue();\n+            void hasValue(boolean hasValue);\n+            Anon anon();\n+        }\n+        LinkOrValue left();\n+        LinkOrValue right();\n+        interface Rect extends Buffer.StructChild {\n+            byte x();\n+            byte y();\n+            byte width();\n+            byte height();\n+            float weight();\n+            void x(byte x);\n+            void y(byte y);\n+            void width(byte width);\n+            void height(byte height);\n+            void weight(float height);\n+        }\n+        Rect rect(long idx);\n+    }\n+    int featureCount();\n+    void featureCount(int featureCount);\n+    Feature feature(long idx);\n+    interface Stage extends Buffer.StructChild {\n+        float threshold();\n+        short firstTreeId();\n+        short treeCount();\n+        int id();\n+        void id(int id);\n+        void threshold(float threshold);\n+        void firstTreeId(short firstTreeId);\n+        void treeCount(short treeCount);\n+    }\n+\n+    int stageCount();\n+    void stageCount(int stageCount);\n+    Stage stage(long idx);\n+    interface Tree extends Buffer.StructChild {\n+        void id(int id);\n+        void firstFeatureId(short firstFeatureId);\n+        void featureCount(short featureCount);\n+        int id();\n+        short firstFeatureId();\n+        short featureCount();\n+    }\n+    int treeCount();\n+    void treeCount(int treeCount);\n+    Tree tree(long idx);\n+    Schema<Cascade> schema = Schema.of(Cascade.class, cascade -> cascade\n+            .fields(\"width\", \"height\")\n+            .arrayLen(\"featureCount\")\n+                .array(\"feature\", feature -> feature\n+                    .field(\"id\")\n+                    .field(\"threshold\")\n+                    .fields(\"left\", \"right\", linkOrValue -> linkOrValue\n+                            .field(\"hasValue\")\n+                            .pad(3)\n+                            .field(\"anon\", anon -> anon\n+                               .field(\"featureId\")\n+                               .field(\"value\")\n+                            )\n+                    )\n+                    .array(\"rect\", 3, rect -> rect\n+                       .field(\"x\")\n+                       .field(\"y\")\n+                       .field(\"width\")\n+                       .field(\"height\").\n+                       .field(\"weight\"))\n+            )\n+            .arrayLen(\"treeCount\")\n+                .array(\"tree\", tree -> tree\n+                   .field(\"id\")\n+                   .field(\"featureCount\")\n+                   .field(\"firstFeatureId\")\n+                )\n+            .arrayLen(\"stageCount\")\n+                .array(\"stage\", stage -> stage\n+                   .field(\"id\")\n+                   .field(\"threshold\")\n+                   .field(\"treeCount\")\n+                   .field(\"firstTreeId\"))\n+    );\n+}\n+```\n+\n+Another great advantage of using interfaces is that we can choose\n+to re implement the interface in any was we see fit.\n+\n+For example we load  HaarCascades from XML files.\n+We therefore can create an implementation of the Cascade interface which just\n+loads the XML DOM... stores them in arrays and the interface methods just delegate to\n+the appropriately wrapped  w3c.Node tree nodes ;)\n+\n+If we know we are using Java backend we can actually\n+just pass the XMLCascade implementation directly to the backend...\n+\n+Actually the Cascade `create` method takes an existing\n+implementation of a Cascade and clones it.\n+So we can just pass it an XMLHaarCascade ;)\n+\n+So we build an XMLCascade then pass it to the `create` method of the iface\n+mapped Cascade\n+\n+```java\n+   XMLHaarCascadeModel haarCascade = XMLHaarCascadeModel.load(\n+        ViolaJonesRaw.class.getResourceAsStream(\"haarcascade_frontalface_default.xml\"));\n+\n+   assert haarCascade instanceof Cascade; \/\/ Here it is just an interface\n+\n+   Cascade cascade = Cascade.create(accelerator, haarCascade);\n+\n+   \/\/ Now it can be used on the GPU\n+```\n+\n+The implementation is currently hand crafted, but this could easily be automated.\n+\n+```java\n+ static Cascade create(BufferAllocator bufferAllocator, XMLHaarCascadeModel haarCascade) {\n+\n+        Cascade cascade = bufferAllocator.allocate(SegmentMapper.of(MethodHandles.lookup(), Cascade.class,\n+                JAVA_INT.withName(\"width\"),\n+                JAVA_INT.withName(\"height\"),\n+                JAVA_INT.withName(\"featureCount\"),\n+                sequenceLayout(haarCascade.features.size(), Feature.layout.withName(Feature.class.getSimpleName())).withName(\"feature\"),\n+                JAVA_INT.withName(\"stageCount\"),\n+                sequenceLayout(haarCascade.stages.size(), Stage.layout.withName(Stage.class.getSimpleName())).withName(\"stage\"),\n+                JAVA_INT.withName(\"treeCount\"),\n+                sequenceLayout(haarCascade.trees.size(), Tree.layout.withName(Tree.class.getSimpleName())).withName(\"tree\")\n+        ));\n+        cascade.width(haarCascade.width());\n+        cascade.height(haarCascade.height());\n+        cascade.featureCount(haarCascade.features.size());\n+        cascade.stageCount(haarCascade.stages.size());\n+        cascade.treeCount(haarCascade.trees.size());\n+        for (int idx = 0; idx < haarCascade.features.size(); idx++) {\n+            Cascade.Feature cascadeFeature = cascade.feature(idx);\n+            var haarfeature = haarCascade.features.get(idx);\n+            cascadeFeature.id(haarfeature.id());\n+            cascadeFeature.threshold(haarfeature.threshold());\n+            Cascade.Feature.LinkOrValue cascadeLeft = cascadeFeature.left();\n+            cascadeLeft.hasValue(haarfeature.left.hasValue());\n+            if (haarfeature.left.hasValue()) {\n+                cascadeLeft.anon().value(haarfeature.left.value());\n+            } else {\n+                cascadeLeft.anon().value(haarfeature.left.featureId());\n+            }\n+            Cascade.Feature.LinkOrValue cascadeRight = cascadeFeature.right();\n+            cascadeRight.hasValue(haarfeature.right.hasValue());\n+            if (haarfeature.right.hasValue()) {\n+                cascadeRight.anon().value(haarfeature.right.value());\n+            } else {\n+                cascadeRight.anon().featureId(haarfeature.right.featureId());\n+            }\n+            for (int r = 0; r < 3; r++) {\n+                var haarrect = haarfeature.rects[r];\n+                if (haarrect != null) {\n+                    Cascade.Feature.Rect cascadeRect = cascadeFeature.rect(r);\n+                    cascadeRect.x(haarrect.x());\n+                    cascadeRect.y(haarrect.y());\n+                    cascadeRect.width(haarrect.width());\n+                    cascadeRect.height(haarrect.height());\n+                    cascadeRect.weight(haarrect.weight());\n+                }\n+            }\n+        }\n+        for (XMLHaarCascadeModel.Stage haarstage : haarCascade.stages) {\n+            Cascade.Stage cascadeStage = cascade.stage(haarstage.id);\n+            cascadeStage.id(haarstage.id());\n+            cascadeStage.threshold(haarstage.threshold());\n+            cascadeStage.firstTreeId(haarstage.firstTreeId());\n+            cascadeStage.treeCount(haarstage.treeCount());\n+        }\n+\n+        for (XMLHaarCascadeModel.Tree haarTree : haarCascade.trees) {\n+            Cascade.Tree cascadeTree = cascade.tree(haarTree.id());\n+            cascadeTree.id(haarTree.id());\n+            cascadeTree.firstFeatureId(haarTree.firstFeatureId());\n+            cascadeTree.featureCount(haarTree.featureCount());\n+        }\n+        return cascade;\n+    }\n+```\n+\n","filename":"hat\/docs\/hat-04-02-cascade-interface-mapping.md","additions":228,"deletions":0,"binary":false,"changes":228,"status":"added"},{"patch":"@@ -0,0 +1,229 @@\n+# What happens when we call accelerator.compute(lambda)\n+\n+----\n+\n+* [Contents](hat-00.md)\n+* House Keeping\n+    * [Project Layout](hat-01-01-project-layout.md)\n+    * [Building Babylon](hat-01-02-building-babylon.md)\n+    * [Maven and CMake](hat-01-03-maven-cmake.md)\n+* Programming Model\n+    * [Programming Model](hat-03-programming-model.md)\n+* Interface Mapping\n+    * [Interface Mapping Overview](hat-04-01-interface-mapping.md)\n+    * [Cascade Interface Mapping](hat-04-02-cascade-interface-mapping.md)\n+* Implementation Detail\n+    * [Walkthrough Of Accelerator.compute()](hat-accelerator-compute.md)\n+\n+----\n+\n+# What happens when we call accelerator.compute(lambda)\n+\n+# Back to our Squares example.\n+\n+So what is going on here?\n+\n+```java\n+  accelerator.compute(\n+     cc -> SquareCompute.square(cc, s32Array)\n+  );\n+```\n+\n+Recall we have two types of code in our compute class. We have kernels (and kernel reachable methods) and we have\n+compute entrypoints (and compute reachable methods).\n+\n+```java\n+public class SquareCompute{\n+    @CodeReflection public static int square(int v) {\n+        return  v * v;\n+    }\n+\n+    @CodeReflection public static void squareKernel(KernelContext kc, S32Array s32Array) {\n+        int value = s32Array.array(kc.x);     \/\/ arr[cc.x]\n+        s32Array.array(kc.x, square(value));  \/\/ arr[cc.x]=value*value\n+    }\n+\n+    @CodeReflection public static void square(ComputeContext cc, S32Array s32Array) {\n+        cc.dispatchKernel(s32Array.length(),\n+                kc -> squareKernel(kc, s32Array)\n+        );\n+    }\n+}\n+```\n+\n+AGAIN.... NOTE that we cannot just call the compute entrypoint or the kernel directly.\n+\n+```java\n+  SquareCompute.square(????, s32Array);  \/\/ We can't do this!!!!\n+```\n+\n+We purposely make it inconvenient (ComputeContext and KernelContext construction is embedded in the framwork) to\n+mistakenly call the compute entrypoint directly.  Doing so is akin to calling `Thread.run()` directly, rather than\n+calling `Thread.start()` on a class extending `Thread` and providing an implementation of `Thread.run()`\n+\n+Instead we use this pattern\n+\n+```java\n+  accelerator.compute(\n+     cc -> SquareCompute.square(cc, s32Array)\n+  );\n+```\n+\n+We pass a lambda to `accelerator.compute()` which is used to determine which compute method to invoke.\n+\n+```\n+ User  |  Accelerator  |  Compute  |  Babylon  |        Backend            |\n+                          Context                 Java     C++     Vendor\n++----+   +-----------+   +-------+   +-------+   +----+   +---+   +------+\n+|    |   |           |   |       |   |       |   |    |   |   |   |      |\n++----+   +-----------+   +-------+   +-------+   +----+   +---+   +------+\n+    +--------> accelerator.compute(lambda)\n+\n+```\n+\n+Incidently, this lambda is never executed by Java JVM ;) instead, the accelerator uses Babylon's Code Reflection\n+capabilities to extract the model of this lambda to determine the compute entrypoint and it's captured args.\n+\n+```\n+ User  |  Accelerator  |  Compute  |  Babylon  |        Backend            |\n+                          Context                 Java     C++     Vendor\n++----+   +-----------+   +-------+   +-------+   +----+   +---+   +------+\n+|    |   |           |   |       |   |       |   |    |   |   |   |      |\n++----+   +-----------+   +-------+   +-------+   +----+   +---+   +------+\n+    +--------> accelerator.compute( cc -> SquareCompute.square(cc, s32Array) )\n+                ------------------------->\n+                    getModelOf(lambda)\n+                <------------------------\n+```\n+\n+This model describes the call that we want the accelerator to\n+execute or interpret (`SquareCompute.square()`) and the args that were captured from the call site (the `s32Array` buffer).\n+\n+The accelerator uses Babylon again to get the\n+code model of `SquareCompute.square()` builds a ComputeReachableGraph with this method at the root.\n+So the accelerator walks the code model and collects the methods (and code models) of all methods\n+reachable from the entrypoint.\n+\n+In our trivial case, the ComputeReachableGraph has a single root node representing the `SquareCompute.square()`.\n+\n+```\n+ User  |  Accelerator  |  Compute  |  Babylon  |        Backend            |\n+                          Context                 Java     C++     Vendor\n++----+   +-----------+   +-------+   +-------+   +----+   +---+   +------+\n+|    |   |           |   |       |   |       |   |    |   |   |   |      |\n++----+   +-----------+   +-------+   +-------+   +----+   +---+   +------+\n+    +--------> accelerator.compute( cc -> SquareCompute.square(cc, s32Array) )\n+                ------------------------->\n+                     getModelOf(lambda)\n+                <------------------------\n+                ------------------------->\n+                     getModelOf(SquareCompute.square())\n+                <-------------------------\n+          forEachReachable method in SquareCompute.square() {\n+                ------------------------->\n+                     getModelOf(method)\n+                <------------------------\n+                add to ComputeReachableGraph\n+          }\n+```\n+\n+The Accelertor then walks through the ComputeReachableGraph to determine which kernels are referenced..\n+\n+For each kernel we extract the kernels entrypoint (again as a Babylon\n+Code Model) and create a KernelReachableGraph for each kernel.  Again by starting\n+at the kernel entrypoint and closing over all reachable methods (and Code Models).\n+\n+We combine the compute and kernel reachable graphs and create an place them in a  `ComputeContext`.\n+\n+This is the first arg that is 'seemingly' passed to the Compute class. Remember the compute\n+entrypoint is just a model of the code we expect to\n+execute. It may never be executed by the JVM.\n+\n+```\n+ User  |  Accelerator  |  Compute  |  Babylon  |        Backend            |\n+                          Context                 Java     C++     Vendor\n++----+   +-----------+   +-------+   +-------+   +----+   +---+   +------+\n+|    |   |           |   |       |   |       |   |    |   |   |   |      |\n++----+   +-----------+   +-------+   +-------+   +----+   +---+   +------+\n+\n+          forEachReachable kernel in ComputeReachableGraph {\n+                ------------------------->\n+                      getModelOf(kernel)\n+                <------------------------\n+                add to KernelReachableGraph\n+          }\n+          ComputeContext = {ComputeReachableGraph + KernelReachableGraph}\n+\n+```\n+\n+The accelerator passes the ComputeContext to backend (`computeContextHandoff()`), which will typically take\n+the opportunity to inspect\/mutate the compute and kernel models and possibly build backend specific representations of\n+kernels and compile them.\n+\n+The ComputeContext and the captured args are then passed to the backend for execution.\n+\n+```\n+ User  |  Accelerator  |  Compute  |  Babylon  |        Backend            |\n+                          Context                 Java     C++     Vendor\n++----+   +-----------+   +-------+   +-------+   +----+   +---+   +------+\n+|    |   |           |   |       |   |       |   |    |   |   |   |      |\n++----+   +-----------+   +-------+   +-------+   +----+   +---+   +------+\n+\n+\n+                ----------------------------------->\n+                    computeContextHandoff(computeContext)\n+                                                    ------->\n+                                                             ------->\n+                                                         compileKernels()\n+                                                             <------\n+                                                      mutateComputeModels\n+                                                    <-------\n+                    dispatchCompute(computeContext, args)\n+                                                    ------->\n+                                                        dispatchCompute(...)\n+                                                            --------->\n+                                                               {\n+                                                               dispatchKernel()\n+                                                               ...\n+                                                               }\n+                                                            <--------\n+                                                    <------\n+                <----------------------------------\n+\n+```\n+\n+----\n+### Notes\n+\n+In reality. The Accelerator receives a `QuotableComputeContextConsumer`\n+\n+```java\n+   public interface QuotableComputeContextConsumer\n+        extends Quotable,\n+        Consumer<ComputeContext> {\n+    }\n+```\n+Here is how we extract the 'target' from such a lambda\n+\n+```java\n+ public void  compute(QuotableComputeContextConsumer qccc) {\n+   Quoted quoted = qccc.quoted();\n+   LambdaOpWrapper lambda = OpTools.wrap((CoreOps.LambdaOp)quoted.op());\n+\n+   Method method = lambda.getQuotableComputeContextTargetMethod();\n+\n+   \/\/ Get from the cache or create a compute context which closes over compute entryppint\n+   \/\/ and reachable kernels.\n+   \/\/ The models of all compute and kernel methods are passed to the backend during creation\n+   \/\/ The backend may well mutate the models.\n+   \/\/ It will also use this opportunity to generate ISA specific code for the kernels.\n+\n+   ComputeContext = this.cache.computeIfAbsent(method, (_) ->\n+           new ComputeContext(this\/*Accelerator*\/, method)\n+   );\n+\n+   \/\/ Here we get the captured args from the Quotable and 'jam' in the computeContext in slot[0]\n+   Object[] args = lambda.getQuotableComputeContextArgs(quoted, method, computeContext);\n+   this.compute(computeContext, args);\n+}\n+```\n","filename":"hat\/docs\/hat-05-accelerator-compute.md","additions":229,"deletions":0,"binary":false,"changes":229,"status":"added"},{"patch":"@@ -0,0 +1,594 @@\n+\n+# Compute Analysis or Runtime tracing\n+\n+----\n+\n+* [Contents](hat-00.md)\n+* House Keeping\n+    * [Project Layout](hat-01-01-project-layout.md)\n+    * [Building Babylon](hat-01-02-building-babylon.md)\n+    * [Maven and CMake](hat-01-03-maven-cmake.md)\n+* Programming Model\n+    * [Programming Model](hat-03-programming-model.md)\n+* Interface Mapping\n+    * [Interface Mapping Overview](hat-04-01-interface-mapping.md)\n+    * [Cascade Interface Mapping](hat-04-02-cascade-interface-mapping.md)\n+* Implementation Detail\n+    * [Walkthrough Of Accelerator.compute()](hat-accelerator-compute.md)\n+\n+----\n+\n+# Compute Analysis or Runtime tracing\n+\n+HAT does not dictate how a backend chooses to optimize execution, but does\n+provide the tools (Babylon's Code Models) and some helpers which the Backend is encouraged\n+use.\n+\n+The ComputeContext contains all the information that the backend needs, but does not\n+include any 'policy' for minimizing data movements.\n+\n+Our assumption is that backend can use various tools to deduce the most efficient execution strategy.\n+\n+## Some possible strategies..\n+\n+### Copy data every time 'just in case' (JIC execution ;) )\n+Just naiively execute the code as described in Compute graph. So the backend will copy each buffer to the device, execute the kernel and copy the data back again.\n+\n+### Use kernel knowledge to minimise data movement\n+Execute the code described in the Compute Graph, but use knowledge extracted from kernel models\n+to only copy to device buffers that the kernel is going to read, and only copy back from the device\n+buffers that the kernel has written to.\n+\n+### Use Compute knowledge and kernel knowledge to further minimise data movement\n+Use knowledge extracted from the compute reachable graph and the kernel\n+graphs to determine whether Java has mutated buffers between kernel dispatches\n+and only copy data to the device that we know the Java code has mutated.\n+\n+This last strategy is ideal\n+\n+We can achieve this using static analysis of the compute and kernel models or by being\n+involved in the execution process at runtime.\n+\n+#### Static analysis\n+\n+#### Runtime Tracking\n+\n+* Dynamical\n+1. We 'close over' the call\/dispatch graph from the entrypoint to all kernels and collect the kernels reachable from the entrypoint and all methods reachable from methods reachable by kernels.\n+2. We essentially end up with a graph of codemodels 'rooted' at the entrypoint\n+3. For each kernel we also determine how the kernel accesses it's 'MemorySegment` parameters, for each MemorySegment parameters we keep a side table of whther the kernel reads or writes to the segment. We keep this infomation in a side map.\n+\n+This resulting 'ComputeClosure' (tree of codemodels and relevant side tables) is made available to the accelerator to coordinate execution.\n+\n+Note that our very simple Compute::compute method neither expresses the movement of the MemorySegment to a device, or the retrieval of the data from a device when the kernel has executed.\n+\n+Our assumption is that given the ComputeClosure we can deduce such movements.\n+\n+There are many ways to achieve this.  One way would be by static analysis.\n+\n+Given the Compute::compute entrypoint it is easy to determine that we are always (no conditional or loops) passing (making available\n+might be a better term) a memory segment to a kernel (Compute::kernel) and this kernel only mutates the  `MemorySegment`.\n+\n+So from simple static analysis we could choose to inject one or more calls into the model representing the need for the accelerator to move data to the devices and\/ord back from the device, after the kernel dispatch.\n+\n+This modified model, would look like we had presented it with this code.\n+\n+```java\n+ void compute(Accelerator accelerator, MemorySegment memorySegment, int len) {\n+        Accelerator.Range range = accelerator.range(len);\n+        accelerator.run(Compute::kernel, range, memorySegment);\n+        accelerator.injectedCopyFromDevice(memorySegment);\n+    }\n+```\n+\n+Note the ```injectedCopyFromDevice()``` call.\n+\n+Because the kernel does not read the `MemorySegment` we only need inject the code to request a move back from the device.\n+\n+To do this requires HAT to analyse the kernel(s) and inject appropriate code into\n+the Compute::compute method to inform the vendor backend when it should perform such moves.\n+\n+Another strategy would be to not rely on static analysis but to inject code to trace 'actual' mutations of the MemorySegments and use these flags to guard against unnecessary copies\n+\n+```java\n+ void compute(Accelerator accelerator, MemorySegment memorySegment, int len) {\n+        boolean injectedMemorySegmentIsDirty = false;\n+        Accelerator.Range range = accelerator.range(len);\n+        if (injectedMemorySegmentIsDirty){\n+            accelerator.injectedCopyToDevice(memorySegment);\n+        }\n+        accelerator.run(Compute::kernel, range, memorySegment);\n+        injectedMemorySegmentIsDirty = true; \/\/ based on Compute::kernel sidetable\n+        if (injectedMemorySegmentIsDirty) {\n+            accelerator.injectedCopyFromDevice(memorySegment);\n+        }\n+    }\n+```\n+\n+\n+Whether this code mutation generates Java bytecode and executes (or interprets) on the JVM or whether the\n+CodeModels for the closure are handed over to a backend which reifies the kernel code and the\n+logic for dispatch is not defined.\n+\n+The code model for the compute will be mutated to inject the appropriate nodes to achieve the goal\n+\n+It is possible that some vendors may just take the original code model and analyse themselves.\n+\n+Clearly this is a trivial compute closure.   Lets discuss the required kernel analysis\n+and proposed pseudo code.\n+\n+## Copying data based on kernel MemorySegment analysis\n+\n+Above we showed that we should be able to determine whether a kernel mutates or accesses any of\n+it's Kernel MemorySegment parameters.\n+\n+We determined above that the kernel only called set() so we need\n+not copy the data to the device.\n+\n+The following example shows a kernel which reads and mutates a memorysegment\n+```java\n+    static class Compute {\n+    @CodeReflection  public static\n+    void doubleup(Accelerator.NDRange ndrange, MemorySegment memorySegment) {\n+        int temp = memorySegment.get(JAVA_INT, ndrange.id.x);\n+        memorySegment.set(JAVA_INT, temp*2);\n+    }\n+\n+    @CodeReflection public static\n+    void compute(Accelerator accelerator, MemorySegment memorySegment, int len) {\n+        Accelerator.Range range = accelerator.range(len);\n+        accelerator.run(Compute::doubleup, range, memorySegment);\n+    }\n+}\n+```\n+Here our analysis needs to determine that the kernel reads and writes to the segment (it does)\n+so the generated compute model would equate to\n+\n+```java\n+ void compute(Accelerator accelerator, MemorySegment memorySegment, int len) {\n+        Accelerator.Range range = accelerator.range(len);\n+        accelerator.copyToDevice(memorySegment); \/\/ injected via Babylon\n+        accelerator.run(Compute::doubleup, range, memorySegment);\n+        accelerator.copyFromDevice(memorySegment); \/\/ injected via Babylon\n+    }\n+```\n+So far the deductions are fairly trivial\n+\n+Consider\n+```java\n+ @CodeReflection public static\n+    void compute(Accelerator accelerator, MemorySegment memorySegment, int len, int count) {\n+        Accelerator.Range range = accelerator.range(len);\n+        for (int i=0; i<count; i++) {\n+            accelerator.run(Compute::doubleup, range, memorySegment);\n+        }\n+    }\n+```\n+\n+Here HAT should deduce that the java side is merely looping over the kernel dispatch\n+and has no interest in the memorysegment between dispatches.\n+\n+So the new model need only copy in once (before the fist kernel) and out once (prior to return)\n+\n+```java\n+ @CodeReflection public static\n+    void compute(Accelerator accelerator, MemorySegment memorySegment, int len, int count) {\n+        Accelerator.Range range = accelerator.range(len);\n+        accelerator.copyToDevice(memorySegment); \/\/ injected via Babylon\n+        for (int i=0; i<count; i++) {\n+            accelerator.run(Compute::doubleup, range, memorySegment);\n+        }\n+        accelerator.copyFromDevice(memorySegment); \/\/ injected via Babylon\n+    }\n+```\n+\n+Things get slightly more interesting when we do indeed access the memory segment\n+from the Java code inside the loop.\n+\n+```java\n+ @CodeReflection public static\n+    void compute(Accelerator accelerator, MemorySegment memorySegment, int len, int count) {\n+        Accelerator.Range range = accelerator.range(len);\n+        for (int i=0; i<count; i++) {\n+            accelerator.run(Compute::doubleup, range, memorySegment);\n+            int slot0 = memorySegment.get(INTVALUE, 0);\n+            System.out.println(\"slot0 \", slot0);\n+        }\n+    }\n+```\n+Now we expect babylon to inject a read inside the loop to make the data available java side\n+\n+```java\n+ @CodeReflection public static\n+    void compute(Accelerator accelerator, MemorySegment memorySegment, int len, int count) {\n+        Accelerator.Range range = accelerator.range(len);\n+        accelerator.copyToDevice(memorySegment); \/\/ injected via Babylon\n+        for (int i=0; i<count; i++) {\n+            accelerator.run(Compute::doubleup, range, memorySegment);\n+            accelerator.copyFromDevice(memorySegment); \/\/ injected via Babylon\n+            int slot0 = memorySegment.get(INTVALUE, 0);\n+            System.out.println(\"slot0 \", slot0);\n+        }\n+\n+    }\n+```\n+\n+Note that in this case we are only accessing 0th int from the segment so a possible\n+optimization might be to allow the vendor to only copy back this one element....\n+```java\n+ @CodeReflection public static\n+    void compute(Accelerator accelerator, MemorySegment memorySegment, int len, int count) {\n+        Accelerator.Range range = accelerator.range(len);\n+        accelerator.copyToDevice(memorySegment); \/\/ injected via Babylon\n+        for (int i=0; i<count; i++) {\n+            accelerator.run(Compute::doubleup, range, memorySegment);\n+            if (i+1==count){\/\/ injected\n+                accelerator.copyFromDevice(memorySegment); \/\/ injected\n+            }else {\n+                accelerator.copyFromDevice(memorySegment, 1); \/\/ injected via Babylon\n+            }\n+            int slot0 = memorySegment.get(INTVALUE, 0);\n+            System.out.println(\"slot0 \", slot0);\n+        }\n+\n+    }\n+```\n+\n+Again HAT will merely mutate the code model of the compute method,\n+the vendor may choose to interpret bytecode, generate bytecode and execute\n+or take complete control and execute the model in native code.\n+\n+So within HAT we must find all set\/get calls on MemorySegments and trace them back to kernel parameters.\n+\n+We should allow aliasing of memory segments... but in the short term we may well throw an exception when we see such aliasing\n+\n+\n+```java\n+ @CodeReflection  public static\n+    void doubleup(Accelerator.NDRange ndrange, MemorySegment memorySegment) {\n+        MemorySegment alias = memorySegment;\n+        alias.set(JAVA_INT, ndrange.id.x, alias.get(JAVA_INT, ndrange.id.x)*2);\n+    }\n+```\n+\n+## Weed warning #1\n+\n+We could find common kernel errors when analyzing\n+\n+This code is probably wrong, as it is racey writing to 0th element\n+\n+```java\n+ void doubleup(Accelerator.NDRange ndrange, MemorySegment memorySegment) {\n+    MemorySegment alias = memorySegment;\n+    alias.set(JAVA_INT, 0, alias.get(JAVA_INT, ndrange.id.x)*2);\n+}\n+```\n+\n+By allowing a 'lint' like plugin mechanism for code model it would be easy to find.\n+If we ever find a constant index in set(...., <constant> ) we are probably in a world of hurt.\n+Unless the set is included in some conditional which itself is dependant on a value extracted from a memory segment.\n+\n+```java\n+ void doubleup(Accelerator.NDRange ndrange, MemorySegment memorySegment) {\n+    MemorySegment alias = memorySegment;\n+    if (????){\n+        alias.set(JAVA_INT, 0, alias.get(JAVA_INT, ndrange.id.x) * 2);\n+    }\n+}\n+```\n+\n+There are a lot opportunities for catching such bugs.\n+\n+\n+## Flipping Generations\n+\n+Many algorithms require us to process data from generations. Consider\n+Convolutions or Game Of Life style problems where we have an image or game state and\n+we need to calculate the result of applying rules to cells in the image or game.\n+\n+It is important that when we process the next generation (either in parallel or sequentially) we\n+must ensure that we only use prev generation data to generate next generation data.\n+\n+```\n+[ ][ ][*][ ][ ]       [ ][ ][ ][ ][ ]\n+[ ][ ][*][ ][ ]       [ ][*][*][*][ ]\n+[ ][ ][*][ ][ ]   ->  [ ][ ][ ][ ][ ]\n+[ ][ ][ ][ ][ ]       [ ][ ][ ][ ][ ]\n+\n+```\n+\n+This usually requires us to hold two copies,  and applying the kernel to one input set\n+which writes to the output.\n+\n+In the case of the Game Of Life we may well use the output as the next input...\n+\n+```java\n+@CodeReflection void conway(Accelerator.NDRange ndrange,\n+                            MemorySegment in, MemorySegment out, int width, int height) {\n+    int cx = ndrange.id.x % ndrange.id.maxx;\n+    int cy = ndrange.id.x \/ ndrange.id.maxx;\n+\n+    int sum = 0;\n+    for (int dx = -1; dx < 2; dy++) {\n+        for (int dy = -1; dy < 2; dy++) {\n+            if (dx != 0 || dy != 0) {\n+                int x = cx + dx;\n+                int y = cy + dy;\n+                if (x >= 0 && x < widh && y >= 0 && y < height) {\n+                    sum += in.get(INT, x * width + h);\n+                }\n+            }\n+        }\n+    }\n+    result = GOLRules(sum, in.get(INT, ndrange.id.x));\n+    out.set(INT, ndrange.id.x);\n+\n+}\n+```\n+\n+In this case the assumption is that the compute layer will swap the buffers for alternate passes\n+\n+```java\n+import java.lang.foreign.MemorySegment;\n+\n+@CodeReflection\n+void compute(Accelerator accelerator, MemorySegment gameState,\n+             int width, int height, int maxGenerations) {\n+    MemorySegment s1 = gameState;\n+    MemorySegment s2 = allocateGameState(width, height);\n+    for (int generation = 0; generation < maxGenerations; generation++){\n+        MemorySegment from = generation%2==0?s1?s2;\n+        MemorySegment to = generation%2==1?s1?s2;\n+        accelerator.run(Compute::conway, from, to, range, width, height);\n+    }\n+    if (maxGenerations%2==1){ \/\/ ?\n+        gameState.copyFrom(s2);\n+    }\n+}\n+```\n+\n+This common pattern includes some aliasing of MemorySegments that we need to untangle.\n+\n+HAT needs to be able to track the aliases to determine the minimal number of copies.\n+```java\n+import java.lang.foreign.MemorySegment;\n+\n+@CodeReflection\n+void compute(Accelerator accelerator, MemorySegment gameState, int width, int height, int maxGenerations,\n+             DisplaySAM displaySAM) {\n+    MemorySegment s1 = gameState;\n+    MemorySegment s2 = allocateGameState(width, height);\n+\n+    for (int generation = 0; generation < maxGenerations; generation++){\n+        MemorySegment from = generation%2==0?s1?s2;\n+        MemorySegment to = generation%2==1?s1?s2;\n+        if (generation == 0) {             \/\/\/ injected\n+            accerator.copyToDevice(from);    \/\/ injected\n+        }                                  \/\/ injected\n+        accelerator.run(Compute::conway, from, to, range, width, height, 1000);\n+        if (generation == maxGenerations-1){ \/\/ injected\n+            accerator.copyFromDevice(to);    \/\/injected\n+        }                                    \/\/injected\n+    }\n+    if (maxGenerations%2==1){ \/\/ ?\n+        gameState.copyFrom(s2);\n+    }\n+\n+}\n+```\n+\n+```java\n+import java.lang.foreign.MemorySegment;\n+\n+@CodeReflection\n+void compute(Accelerator accelerator, MemorySegment gameState, int width, int height,\n+             int maxGenerations,\n+             DisplaySAM displaySAM) {\n+    MemorySegment s1 = gameState;\n+    MemorySegment s2 = allocateGameState(width, height);\n+\n+    for (int generation = 0; generation < maxGenerations; generation++){\n+        MemorySegment from = generation%2==0?s1?s2;\n+        MemorySegment to = generation%2==1?s1?s2;\n+        accelerator.run(Compute::conway, from, to, range, width, height,1000);\n+        displaySAM.display(s2,width, height);\n+    }\n+    if (maxGenerations%2==1){ \/\/ ?\n+        gameState.copyFrom(to);\n+    }\n+}\n+```\n+\n+\n+\n+### Example babylon transform to track buffer mutations.\n+\n+One goal of hat was to automate the movement of buffers from Java to device.\n+\n+One strategy employed by `NativeBackends` might be to track 'ifaceMappedSegment' accesses and inject tracking data into the compute method.\n+\n+Here is a transformation for that\n+\n+```java\n+ static FuncOpWrapper injectBufferTracking(ComputeClosure.ResolvedMethodCall resolvedMethodCall) {\n+        FuncOpWrapper original = resolvedMethodCall.funcOpWrapper();\n+        var transformed = original.transformInvokes((builder, invoke) -> {\n+                    if (invoke.isIfaceBufferMethod()) { \/\/ void array(long idx, T value) or T array(long idx)\n+                        \/\/ Get the first parameter (computeClosure)\n+                        CopyContext cc = builder.context();\n+                        Value computeClosure = cc.getValue(original.parameter(0));\n+                        \/\/ Get the buffer receiver value in the output model\n+                        Value receiver = cc.getValue(invoke.operand(0)); \/\/ The buffer we are mutatibg or accessing\n+                        if (invoke.isIfaceMutator()) {\n+                            \/\/ inject computeContext.preMutate(buffer);\n+                            builder.op(CoreOps.invoke(ComputeClosure.M_CC_PRE_MUTATE, computeClosure, receiver));\n+                            builder.op(invoke.op());\n+                           \/\/ inject computeContext.postMutate(buffer);\n+                            builder.op(CoreOps.invoke(ComputeClosure.M_CC_POST_MUTATE, computeClosure, receiver));\n+                        } else if ( invoke.isIfaceAccessor()) {\n+                           \/\/ inject computeContext.preAccess(buffer);\n+                            builder.op(CoreOps.invoke(ComputeClosure.M_CC_PRE_ACCESS, computeClosure, receiver));\n+                            builder.op(invoke.op());\n+                            \/\/ inject computeContext.postAccess(buffer);\n+                            builder.op(CoreOps.invoke(ComputeClosure.M_CC_POST_ACCESS, computeClosure, receiver));\n+                        } else {\n+                            builder.op(invoke.op());\n+                        }\n+                    }else{\n+                        builder.op(invoke.op());\n+                    }\n+                    return builder;\n+                }\n+        );\n+        transformed.op().writeTo(System.out);\n+        resolvedMethodCall.funcOpWrapper(transformed);\n+        return transformed;\n+    }\n+```\n+\n+So in our `OpenCLBackend` for example\n+```java\n+    public void mutateIfNeeded(ComputeClosure.MethodCall methodCall) {\n+       injectBufferTracking(entrypoint);\n+    }\n+\n+    @Override\n+    public void computeContextClosed(ComputeContext computeContext){\n+        var codeBuilder = new OpenCLKernelBuilder();\n+        C99Code kernelCode = createKernelCode(computeContext, codeBuilder);\n+        System.out.println(codeBuilder);\n+    }\n+```\n+I hacked the Mandle example. So the compute accessed and mutated it's arrays.\n+\n+```java\n+  @CodeReflection\n+    static float doubleit(float f) {\n+        return f * 2;\n+    }\n+\n+    @CodeReflection\n+    static float scaleUp(float f) {\n+        return doubleit(f);\n+    }\n+\n+    @CodeReflection\n+    static public void compute(final ComputeContext computeContext, S32Array2D s32Array2D, float x, float y, float scale) {\n+        scale = scaleUp(scale);\n+        var range = computeContext.accelerator.range(s32Array2D.size());\n+        int i = s32Array2D.get(10,10);\n+        s32Array2D.set(10,10,i);\n+        computeContext.dispatchKernel(MandelCompute::kernel, range, s32Array2D, pallette, x, y, scale);\n+    }\n+```\n+So here is the transformation being applied to the above compute\n+\n+BEFORE (note the !'s indicating accesses through ifacebuffers)\n+```\n+func @\"compute\" (%0 : hat.ComputeContext, %1 : hat.buffer.S32Array2D, %2 : float, %3 : float, %4 : float)void -> {\n+    %5 : Var<hat.ComputeContext> = var %0 @\"computeContext\";\n+    %6 : Var<hat.buffer.S32Array2D> = var %1 @\"s32Array2D\";\n+    %7 : Var<float> = var %2 @\"x\";\n+    %8 : Var<float> = var %3 @\"y\";\n+    %9 : Var<float> = var %4 @\"scale\";\n+    %10 : float = var.load %9;\n+    %11 : float = invoke %10 @\"mandel.MandelCompute::scaleUp(float)float\";\n+    var.store %9 %11;\n+    %12 : hat.ComputeContext = var.load %5;\n+    %13 : hat.Accelerator = field.load %12 @\"hat.ComputeContext::accelerator()hat.Accelerator\";\n+    %14 : hat.buffer.S32Array2D = var.load %6;\n+!   %15 : int = invoke %14 @\"hat.buffer.S32Array2D::size()int\";\n+    %16 : hat.NDRange = invoke %13 %15 @\"hat.Accelerator::range(int)hat.NDRange\";\n+    %17 : Var<hat.NDRange> = var %16 @\"range\";\n+    %18 : hat.buffer.S32Array2D = var.load %6;\n+    %19 : int = constant @\"10\";\n+    %20 : int = constant @\"10\";\n+!   %21 : int = invoke %18 %19 %20 @\"hat.buffer.S32Array2D::get(int, int)int\";\n+    %22 : Var<int> = var %21 @\"i\";\n+    %23 : hat.buffer.S32Array2D = var.load %6;\n+    %24 : int = constant @\"10\";\n+    %25 : int = constant @\"10\";\n+    %26 : int = var.load %22;\n+ !  invoke %23 %24 %25 %26 @\"hat.buffer.S32Array2D::set(int, int, int)void\";\n+    %27 : hat.ComputeContext = var.load %5;\n+    ...\n+```\n+AFTER\n+```\n+func @\"compute\" (%0 : hat.ComputeContext, %1 : hat.buffer.S32Array2D, %2 : float, %3 : float, %4 : float)void -> {\n+    %5 : Var<hat.ComputeContext> = var %0 @\"computeContext\";\n+    %6 : Var<hat.buffer.S32Array2D> = var %1 @\"s32Array2D\";\n+    %7 : Var<float> = var %2 @\"x\";\n+    %8 : Var<float> = var %3 @\"y\";\n+    %9 : Var<float> = var %4 @\"scale\";\n+    %10 : float = var.load %9;\n+    %11 : float = invoke %10 @\"mandel.MandelCompute::scaleUp(float)float\";\n+    var.store %9 %11;\n+    %12 : hat.ComputeContext = var.load %5;\n+    %13 : hat.Accelerator = field.load %12 @\"hat.ComputeContext::accelerator()hat.Accelerator\";\n+    %14 : hat.buffer.S32Array2D = var.load %6;\n+    invoke %0 %14 @\"hat.ComputeClosure::preAccess(hat.buffer.Buffer)void\";\n+!    %15 : int = invoke %14 @\"hat.buffer.S32Array2D::size()int\";\n+    invoke %0 %14 @\"hat.ComputeClosure::postAccess(hat.buffer.Buffer)void\";\n+    %16 : hat.NDRange = invoke %13 %15 @\"hat.Accelerator::range(int)hat.NDRange\";\n+    %17 : Var<hat.NDRange> = var %16 @\"range\";\n+    %18 : hat.buffer.S32Array2D = var.load %6;\n+    %19 : int = constant @\"10\";\n+    %20 : int = constant @\"10\";\n+    invoke %0 %18 @\"hat.ComputeClosure::preAccess(hat.buffer.Buffer)void\";\n+ !   %21 : int = invoke %18 %19 %20 @\"hat.buffer.S32Array2D::get(int, int)int\";\n+    invoke %0 %18 @\"hat.ComputeClosure::postAccess(hat.buffer.Buffer)void\";\n+    %22 : Var<int> = var %21 @\"i\";\n+    %23 : hat.buffer.S32Array2D = var.load %6;\n+    %24 : int = constant @\"10\";\n+    %25 : int = constant @\"10\";\n+    %26 : int = var.load %22;\n+    invoke %0 %23 @\"hat.ComputeClosure::preMutate(hat.buffer.Buffer)void\";\n+ !   invoke %23 %24 %25 %26 @\"hat.buffer.S32Array2D::set(int, int, int)void\";\n+    invoke %0 %23 @\"hat.ComputeClosure::postMutate(hat.buffer.Buffer)void\";\n+    %27 : hat.ComputeContext = var.load %5;\n+```\n+And here at runtime the ComputeClosure is reporting accesses when executing via the interpreter after the injected calls.\n+\n+```\n+ComputeClosure.preAccess S32Array2D[width()=1024, height()=1024, array()=int[1048576]]\n+ComputeClosure.postAccess S32Array2D[width()=1024, height()=1024, array()=int[1048576]]\n+ComputeClosure.preAccess S32Array2D[width()=1024, height()=1024, array()=int[1048576]]\n+ComputeClosure.postAccess S32Array2D[width()=1024, height()=1024, array()=int[1048576]]\n+ComputeClosure.preMutate S32Array2D[width()=1024, height()=1024, array()=int[1048576]]\n+ComputeClosure.postMutate S32Array2D[width()=1024, height()=1024, array()=int[1048576]]\n+```\n+## Why inject this info?\n+So the idea is that the ComputeContext would maintain sets of dirty buffers, one set for `gpuDirty` and one set for `javaDirty`.\n+\n+We have the code for kernel models. So we know which kernel accesses, mutates or accesses AND mutates particular parameters.\n+\n+So when the ComputeContext receives  `preAccess(x)` or `preMutate(x)` the ComputeContext would determine if `x` is in the `gpuDirty` set.\n+If so it would delegate to the backend to  copy the GPU data back from device into the memory segment (assuming the memory is not coherent!)\n+before removing the buffer from `gpuDirty` set and returning.\n+\n+Now the Java access to the segment sees the latest buffer.\n+\n+After `postMutate(x)` it will place the buffer in `javaDirty` set.\n+\n+When a kernel dispatch comes along, the parameters to the kernel are all checked against the `javaDirty` set.\n+If the parameter is 'accessed' by the kernel. The backend will copy the segment to device. Remove the parameter\n+from the `javaDirty` set and then invoke the kernel.\n+When the kernel completes (lets assume synchronous for a moment) all parameters are checked again, and if the parameter\n+is known to be mutated by the kernel the parameter is added to the 'gpuDirty' set.\n+\n+This way we don't have to force the developer to request data movements.\n+\n+BTW if kernel requests are async ;) then the ComputeContext maintains a map of buffer to kernel.  So `preAccess(x)` or `preMutate(x)` calls\n+can wait on the kernel that is due to 'dirty' the buffer to complete.\n+\n+### Marking hat buffers directly.\n+\n+\n+\n+\n+\n+\n+\n+\n+\n","filename":"hat\/docs\/hat-06-kernel-analysis.md","additions":594,"deletions":0,"binary":false,"changes":594,"status":"added"},{"patch":"@@ -1,558 +0,0 @@\n-\n-# Hat Update\n-#### Gary Frost - Apr 2024\n-Openjdk Babylon is here https:\/\/github.com\/openjdk\/babylon\n-\n-First lets remind ourself of the structure of a HAT compute class circa JMLS 2023\n-\n-```java\n-static class Squarer {\n-   @CodeReflection public static void\n-      squareKernel(NDRange id, S32Array arr) {\n-         int value = arr.array(id.x);          \/\/ arr[cc.x]\n-         s32Array.array(id.x, value * value);  \/\/ arr[cc.x]=value*value\n-   }\n-\n-   @CodeReflection public static void\n-      square(Accelerator  acc, S32Array arr) {\n-         var range = acc.range(arr.size);\n-         acc.dispatcKernel(Compute::square, range, arr);\n-   }\n-\n-   public static void main(String args) {\n-      var lookup = java.lang.invoke.MethodHandles.lookup();\n-      var backend = Backend::JAVA_MULTITHREADED; \/\/ Predicate<Backend>\n-      var accelerator = new Accelerator(lookup, backend);\n-\n-      var arr = S32Array.create(accelerator, 100);\n-      \/\/arr.copyFrom(int[] );?\n-      for (int i=0; i<arr.length(); i++){\n-          arr.array(i,i); \/\/ arr[i]=i;\n-      }\n-      accelerator.compute(Squarer::square, arr);\n-      \/\/arr.copyTo(int[]\n-   }\n-}\n-```\n-Present API\n-\n-```java\n-static class Squarer {\n-   @CodeReflection\n-   public static void\n-      squareKernel(KernelContext kc, S32Array arr) {\n-         int value = arr.array(kc.x);          \/\/ arr[cc.x]\n-         s32Array.array(kc.x, value * value);  \/\/ arr[cc.x]=value*value\n-   }\n-\n-   @CodeReflection\n-   public static void\n-      square(ComputeContext cc, S32Array arr) {\n-         cc.dispatchKernel(\n-              arr.size,                   \/\/ Range for 2d maybe n,m\n-              kc->squareKernel(kc, arr)   \/\/ QuotableKernelContextConsumer\n-         );                               \/\/    extends Quotable, Consumer<KernelContext>\n-\n-   }\n-\n-   public static void main(String args) {\n-      var lookup = java.lang.invoke.MethodHandles.lookup();\n-      var backend = Backend::JAVA_MULTITHREADED; \/\/ Predicate<Backend>\n-      var accelerator = new Accelerator(lookup, backend);\n-\n-      var arr = S32Array.create(accelerator, 100);\n-\n-      for (int i=0; i<arr.length(); i++){\n-          arr.array(i,i); \/\/ arr[i]=i;\n-      }\n-      accelerator.compute(\n-              cc->Squarer.square(cc,arr)  \/\/QuotableComputeContextConsumer\n-      );                                  \/\/   extends Quotable, Consumer<ComputeContext>\n-\n-   }\n-}\n-```\n-\n-Above we show a Compute class `Squarer` with compute entrypoint called `square`\n-which is responsible for dispatching a simple kernel `squareKernel` over a range `0..arr.len`.\n-\n-### Kernel and Compute method constraints\n-\n-#### Compute entrypoints and compute reachable functions\n-\n-1. Are `@CodeReflection static public void`\n-2. `compute entrypoinst` have a first arg of `ComputeContext`\n-3. All methods reachable from a `compute entrypoint` are either :-\n-   * `@CodeReflection static public` compute reachable functions\n-   * `ifaceMappedSegment` accessor\/mutators (see later)\n-   * Calls on the `ComputeContext` to generate ranges, or dispatch kernels.\n-4. The developer should not call  `Square.square()` directly, and we\n-   make it hard for them to get a `ComputeContext` to stop them accidently doing so.\n-5. The bound trio of `Accelerator\/Backend\/ComputeContext` :-\n-   - Has full control over the execution from this point on\n-   - Is free to decide how to execute the bytecode of the `compute entrypoints`, `reachable compute methods` and `kernel dispatches`\n-   - It may execute the bytecodeconvert that code into some completely different form and interpret it\n-   - It may interpret the babylon model\n-   - It may mutate the babylon model and interpret\n-   - It may convert to C99, compile and link to it\n-   - ......\n-\n-6. Code within the `compute entrypoint` and compute reachable\n-functions have a few real Java restrictions.\n-   * Exceptions are discouraged.\n-   * Allocation of local `ifaceMappedSegmants` may not actually need to be allocated\n-   * Java accesses\/mutations to `ifaceMappedSegment` will likely impact performance\n-   * But code should ideally be simple control of kernel dispatches.\n-   * Data movements (to and from backend) are derived from control flow and `ifaceMappedSegment` accesses\n-\n-#### Kernels and kernel reachable functions\n-\n-1. Kernels are declared `@CodeReflection static public void`\n-2. For Kernels, parameter 0 is always a `KernelContext`  (maybe `KernelContext2D`?...`3D`.)\n-3. All methods reachable from a `kernel` are either :-\n-   * `@CodeReflection static public` kernel reachable functions\n-   * `ifaceMappedSegment` accessor\/mutators (see later)\n-   * Calls on `KernelContext` (backend kernel features)...\n-\n-5. Kernel parameters 1..n are restricted to uniform primitive values and Panama FFM `ifaceMappedSegments`\n-7. Kernel's and any kernel reachable functions\n-      (with any expectation of backend execution) will naturally be restricted to subset of Java.\n-   * must not access heap data (no `new`)\n-   * must not access fields (except `final static primitive` from this or any other classes `*` )\n-     * Except fields of `KernelContext` (thread identity `.x`, `.maxX`, `.groups`... )\n-       - maybe even this access should be via methods?\n-5. Kernels can\n-   * call other methods within the same class provided those methods also follow the rules described here\n-\n----\n-### IfaceMappedSegments\n-\n-Earlier we stated that Kernel parameters 1..n are restricted to `uniform primitive args` and `ifaceMappedSegments`\n-\n-At JVMLS 2023 I demonstrated a mechanism which used `Proxy` to bind interfaces (and nestings thereof) to memory\n-segments to allow us to more easily access MemorySegments from the Java side AND to ease the mapping on the kernel side C99 structs.\n-\n-Recently Maurizio and Per implemented a much more performant implementation of this concept using the recent `Classfile` API\n-\n-In the above code we had\n-```java\n- var arr = S32Array.create(accelerator, 100);\n-```\n-\n-Here `S32Array` is *just* (?) an interface\n-```java\n-public interface S32Array extends Array1D {\n-    static S32Array create(Accelerator accelerator, int length) {\n-        return Array1D.create(accelerator, S32Array.class, length, JAVA_INT);\n-    }\n-    int array(long idx);\n-    void array(long idx, int f);\n-}\n-```\n-Where `Array1D` extends the base marker class `Buffer` :-\n-```java\n-public interface Array1D extends Buffer {\n-    static <T extends Array1D> T create(Accelerator accelerator, Class<T> clazz, int length, MemoryLayout memoryLayout) {\n-       T buffer = SegmentMapper.of(accelerator.lookup, clazz,\n-                       JAVA_INT.withName(\"length\"),\n-                       MemoryLayout.sequenceLayout(length, memoryLayout).withName(\"array\")\n-       ).allocate(accelerator.arena);\n-        buffer.length(length);\n-        return buffer;\n-    }\n-    int length();\n-    void length(int length);\n-}\n-```\n-\n-The `magic code` is in `SegmentMapper.of()`\n-\n-```java\n-\/\/Where in this case\n-    Class clazz = S32Array.getClass();\n-    java.lang.foreign.MemoryLayout memoryLayout= JAVA_INT;\n-    int length = 100;\n-\n-    SegmentMapper.of(accelerator.lookup, clazz,\n-                 JAVA_INT.withName(\"length\"),\n-                 MemoryLayout.sequenceLayout(length, memoryLayout).withName(\"array\")\n-       ).allocate(accelerator.arena);\n-    buffer.length(length);\n-```\n-`SegmentMapper.of(...)` takes an interface (`S32Array`) and a layout description.  In this case the layout is equiv to\n-\n-```C\n-typedef struct S32Array_s{\n-    int length;\n-    int array[1000]\n-}S32Array;\n-```\n-\n-Note we have two accessor\/mutate methods provided by the base `Array1D` interface\n-```java\n- int length();\n- void length(int length);\n-```\n-And two from the derived `S32Array` interface\n-```java\n-int array(long idx);\n-void array(long idx, int f);\n-```\n-\n-So in total we have four unimplemented methods\n-\n-```java\n-int length();\n-void length(int length);\n-int array(long idx);\n-void array(long idx, int f);\n-```\n-\n-The `SegmentMapper` uses the `ClassFile` API to spin up an implementation of this interface.\n-\n-This class's bytecode provides an implementation of these four methods.\n-\n-Basically for any `T XXX()` method it creates an implementation `T XXX()` which uses a `VarHandle` to\n-access the given offset of the layout member of Type `T` named `XXX` in the underlying segment,\n-which when called will indeed return the in-segment data as a `T`\n-\n-Similarly for `void XXX(T xxx)` it implements a method (again using `VarHandle`)\n-to set the underlying segment data at the offest determined by the matching `XXX` layout\n-\n-The upshot of which is we can now use\n-```java\n-s32Array.length();\n-```\n-This is much more appealing than manually binding a class or record via `VarHandles` to layout offsets from the\n-underlying layout and delegating to appropriate peeks\/pokes via the MemorySegment API's\n-\n-If the layout matching `XXX` such as `void XXX(long offset, T value)` is found, it binds a setter which sets the value at\n-the appropriately `strided` element offset.\n-\n-Similarly it implements a `getter` as `T XXX(long offset)`.\n-\n-So we can set\/get elements on the array\n-```Java\n-s32Array.array(23, 42);        \/\/ int[23]=42;\n-assert s32Array.array(23)==42\n-```\n-\n-I modified the SegmentMappers implementation to we can access the underlying segment ptr (which we can pass to native backends)\n-an provided a method for accessing a text description `schema` of the now bound layout.\n-\n-We can rely on this to extract native ptrs inthe backend, and to offer a description of the layout which can be turned into C99 receiving structs\/layout in the kernel.\n-\n-```java\n- var arr = S32Array.create(accelerator, 100);\n- System.out.print(arr.schema());\n-```\n-Would yield the schema string form => `S32Array:{length:i4,array:[100:?:s4]}`\n-\n-This a very simple mapping. Probably the minimal useful mapping.  The HaarCascade example has multiple nested ifaces representing nested embedded structs and unions.\n-\n-```java\n-   XMLHaarCascadeModel haarCascade = XMLHaarCascadeModel.load(\n-        ViolaJonesRaw.class.getResourceAsStream(\"\/cascades\/haarcascade_frontalface_default.xml\"));\n-   assert haarCascade instanceof Cascade; \/\/ See it is just an interface, but not segment bound...\n-   Cascade cascade = Cascade.create(accelerator, haarCascade);\n-   System.out.print(cascade.schema());\n-```\n-Here the schema includes nested structs, unions, padding and arrays of structs.  I added indenting to make the schema  more readable.\n-```\n-Cascade:{                      <-- curly brace=struct\n-   width:i4,\n-   height:i4,\n-   featureCount:i4,\n-   feature:[2913:Feature:{    <-- an array called feature of 2913 Feature structs\n-      id:i4,\n-      threshold:f4,\n-      left:{\n-          hasValue:z1,\n-          ?:x7,                <-- padding of 7 bytes to align\n-          anon:<               <-- chevrons desxcribe union\n-             featureId:i4|\n-             value:f4\n-          >\n-      },\n-      right:{\n-          hasValue:z1,\n-          ?:x7,\n-          anon:<\n-              featureId:i4|\n-              value:f4\n-           >\n-      },\n-      rect:[3:Rect:{\n-         x:b1,\n-         y:b1,\n-         width:b1,\n-         height:b1,\n-         weight:f4\n-      }\n-    ]\n-  }],\n-  stageCount:i4,\n-  stage:[25:Stage:{\n-     id:i4,\n-     threshold:f4,\n-     firstTreeId:s2,\n-     treeCount:s2\n-   }],\n-   treeCount:i4,\n-   tree:[2913:Tree:{\n-      id:i4,\n-      firstFeatureId:s2,\n-      featureCount:s2\n-   }]\n-}\n-```\n-\n-### Workflow.\n-## So what happens when we call compute using the new API.\n-\n-```java\n-  accelerator.compute(\n-        cc->Squarer.square(cc,arr)  \/\/Quotable Consumer<ComputeContext>\n-      );\n-```\n-\n-Note that `Accelerator.compute()` takes a lambda which seemingly executes the `Square.square()` method.\n-\n-\n-In reality. The Accelerator receives a `QuotableComputeContextConsumer`\n-\n-```java\n-   public interface QuotableComputeContextConsumer\n-        extends Quotable,\n-        Consumer<ComputeContext> {\n-    }\n-```\n-From this we can access the babylon model of the quotable lambda (with the call to `Squarer.square(cc,arr)`)\n-along with it's  captured args.\n-\n-From this `Compute Entrypoint` can construct a ComputeContext containing a closure over all\n-compute reachable, kernels and kernel reachable methods.\n-\n-The Backend gets passed this closure first and may mutate models.\n-It also can construct ISA specific kernels and map them to the methods in the closure.\n-\n-\n-Finally we pass the ComputeContext and the captured args to the backend to execute\/interpret_\n-```java\n- public void  compute(QuotableComputeContextConsumer qccc) {\n-   Quoted quoted = qccc.quoted();\n-   LambdaOpWrapper lambda = OpTools.wrap((CoreOps.LambdaOp)quoted.op());\n-\n-   \/\/ This instead of cracking the Lambda....\n-   Method method = lambda.getQuotableComputeContextTargetMethod();\n-\n-   \/\/ Get from the cache or create a compute context which closes over compute entryppint\n-   \/\/ and reachable kernels.\n-   \/\/ The models of all compute and kernel methods are passed to the backend during creation\n-   \/\/ The backend may well mutate the models.\n-   \/\/ It will also use this opportunity to generate ISA specific code for the kernels.\n-\n-   ComputeContext = this.cache.computeIfAbsent(method, (_) ->\n-           new ComputeContext(this\/*Accelerator*\/, method)\n-   );\n-\n-   \/\/ Here we get the captured args from the Quotable and 'jam' in the computeContext in slot[0]\n-   Object[] args = lambda.getQuotableComputeContextArgs(quoted, method, computeContext);\n-   this.compute(computeContext, args);\n-}\n-```\n-\n-The dispatch of kernels is similar.  But this time completely under the control of the backend.\n-\n-### Example babylon transform to track buffer mutations.\n-\n-One goal of hat was to automate the movement of buffers from Java to device.\n-\n-One strategy employed by `NativeBackends` might be to track 'ifaceMappedSegment' accesses and inject tracking data into the compute method.\n-\n-Here is a transformation for that\n-\n-```java\n- static FuncOpWrapper injectBufferTracking(ComputeClosure.ResolvedMethodCall resolvedMethodCall) {\n-        FuncOpWrapper original = resolvedMethodCall.funcOpWrapper();\n-        var transformed = original.transformInvokes((builder, invoke) -> {\n-                    if (invoke.isIfaceBufferMethod()) { \/\/ void array(long idx, T value) or T array(long idx)\n-                        \/\/ Get the first parameter (computeClosure)\n-                        CopyContext cc = builder.context();\n-                        Value computeClosure = cc.getValue(original.parameter(0));\n-                        \/\/ Get the buffer receiver value in the output model\n-                        Value receiver = cc.getValue(invoke.operand(0)); \/\/ The buffer we are mutatibg or accessing\n-                        if (invoke.isIfaceMutator()) {\n-                            \/\/ inject computeContext.preMutate(buffer);\n-                            builder.op(CoreOps.invoke(ComputeClosure.M_CC_PRE_MUTATE, computeClosure, receiver));\n-                            builder.op(invoke.op());\n-                           \/\/ inject computeContext.postMutate(buffer);\n-                            builder.op(CoreOps.invoke(ComputeClosure.M_CC_POST_MUTATE, computeClosure, receiver));\n-                        } else if ( invoke.isIfaceAccessor()) {\n-                           \/\/ inject computeContext.preAccess(buffer);\n-                            builder.op(CoreOps.invoke(ComputeClosure.M_CC_PRE_ACCESS, computeClosure, receiver));\n-                            builder.op(invoke.op());\n-                            \/\/ inject computeContext.postAccess(buffer);\n-                            builder.op(CoreOps.invoke(ComputeClosure.M_CC_POST_ACCESS, computeClosure, receiver));\n-                        } else {\n-                            builder.op(invoke.op());\n-                        }\n-                    }else{\n-                        builder.op(invoke.op());\n-                    }\n-                    return builder;\n-                }\n-        );\n-        transformed.op().writeTo(System.out);\n-        resolvedMethodCall.funcOpWrapper(transformed);\n-        return transformed;\n-    }\n-```\n-\n-So in our `OpenCLBackend` for example\n-```java\n-    public void mutateIfNeeded(ComputeClosure.MethodCall methodCall) {\n-        if (methodCall instanceof ComputeClosure.Entrypoint entrypoint){\n-            injectBufferTracking(entrypoint);\n-        }else{\n-            System.out.println(\"OpenCL backend declined to mutate \"+ methodCall + methodCall.method);\n-        }\n-    }\n-\n-    @Override\n-    public void computeContextClosed(ComputeContext computeContext){\n-        System.out.println(\"OpenCL backend received closed closure\");\n-        var codeBuilder = new OpenCLKernelBuilder();\n-        C99Code kernelCode = createKernelCode(computeContext, codeBuilder);\n-        System.out.println(codeBuilder);\n-    }\n-```\n-I hacked the Mandle example. So the compute accessed and mutated it's arrays.\n-\n-```java\n-  @CodeReflection\n-    static float doubleit(float f) {\n-        return f * 2;\n-    }\n-\n-    @CodeReflection\n-    static float scaleUp(float f) {\n-        return doubleit(f);\n-    }\n-\n-    @CodeReflection\n-    static public void compute(final ComputeContext computeContext, S32Array2D s32Array2D, float x, float y, float scale) {\n-        scale = scaleUp(scale);\n-        var range = computeContext.accelerator.range(s32Array2D.size());\n-        int i = s32Array2D.get(10,10);\n-        s32Array2D.set(10,10,i);\n-        computeContext.dispatchKernel(MandelCompute::kernel, range, s32Array2D, pallette, x, y, scale);\n-    }\n-```\n-So here is the transformation being applied to the above compute\n-\n-BEFORE (note the !'s indicating accesses through ifacebuffers)\n-```\n-func @\"compute\" (%0 : hat.ComputeContext, %1 : hat.buffer.S32Array2D, %2 : float, %3 : float, %4 : float)void -> {\n-    %5 : Var<hat.ComputeContext> = var %0 @\"computeContext\";\n-    %6 : Var<hat.buffer.S32Array2D> = var %1 @\"s32Array2D\";\n-    %7 : Var<float> = var %2 @\"x\";\n-    %8 : Var<float> = var %3 @\"y\";\n-    %9 : Var<float> = var %4 @\"scale\";\n-    %10 : float = var.load %9;\n-    %11 : float = invoke %10 @\"mandel.MandelCompute::scaleUp(float)float\";\n-    var.store %9 %11;\n-    %12 : hat.ComputeContext = var.load %5;\n-    %13 : hat.Accelerator = field.load %12 @\"hat.ComputeContext::accelerator()hat.Accelerator\";\n-    %14 : hat.buffer.S32Array2D = var.load %6;\n-!   %15 : int = invoke %14 @\"hat.buffer.S32Array2D::size()int\";\n-    %16 : hat.NDRange = invoke %13 %15 @\"hat.Accelerator::range(int)hat.NDRange\";\n-    %17 : Var<hat.NDRange> = var %16 @\"range\";\n-    %18 : hat.buffer.S32Array2D = var.load %6;\n-    %19 : int = constant @\"10\";\n-    %20 : int = constant @\"10\";\n-!   %21 : int = invoke %18 %19 %20 @\"hat.buffer.S32Array2D::get(int, int)int\";\n-    %22 : Var<int> = var %21 @\"i\";\n-    %23 : hat.buffer.S32Array2D = var.load %6;\n-    %24 : int = constant @\"10\";\n-    %25 : int = constant @\"10\";\n-    %26 : int = var.load %22;\n- !  invoke %23 %24 %25 %26 @\"hat.buffer.S32Array2D::set(int, int, int)void\";\n-    %27 : hat.ComputeContext = var.load %5;\n-    ...\n-```\n-AFTER\n-```\n-func @\"compute\" (%0 : hat.ComputeContext, %1 : hat.buffer.S32Array2D, %2 : float, %3 : float, %4 : float)void -> {\n-    %5 : Var<hat.ComputeContext> = var %0 @\"computeContext\";\n-    %6 : Var<hat.buffer.S32Array2D> = var %1 @\"s32Array2D\";\n-    %7 : Var<float> = var %2 @\"x\";\n-    %8 : Var<float> = var %3 @\"y\";\n-    %9 : Var<float> = var %4 @\"scale\";\n-    %10 : float = var.load %9;\n-    %11 : float = invoke %10 @\"mandel.MandelCompute::scaleUp(float)float\";\n-    var.store %9 %11;\n-    %12 : hat.ComputeContext = var.load %5;\n-    %13 : hat.Accelerator = field.load %12 @\"hat.ComputeContext::accelerator()hat.Accelerator\";\n-    %14 : hat.buffer.S32Array2D = var.load %6;\n-    invoke %0 %14 @\"hat.ComputeClosure::preAccess(hat.buffer.Buffer)void\";\n-!    %15 : int = invoke %14 @\"hat.buffer.S32Array2D::size()int\";\n-    invoke %0 %14 @\"hat.ComputeClosure::postAccess(hat.buffer.Buffer)void\";\n-    %16 : hat.NDRange = invoke %13 %15 @\"hat.Accelerator::range(int)hat.NDRange\";\n-    %17 : Var<hat.NDRange> = var %16 @\"range\";\n-    %18 : hat.buffer.S32Array2D = var.load %6;\n-    %19 : int = constant @\"10\";\n-    %20 : int = constant @\"10\";\n-    invoke %0 %18 @\"hat.ComputeClosure::preAccess(hat.buffer.Buffer)void\";\n- !   %21 : int = invoke %18 %19 %20 @\"hat.buffer.S32Array2D::get(int, int)int\";\n-    invoke %0 %18 @\"hat.ComputeClosure::postAccess(hat.buffer.Buffer)void\";\n-    %22 : Var<int> = var %21 @\"i\";\n-    %23 : hat.buffer.S32Array2D = var.load %6;\n-    %24 : int = constant @\"10\";\n-    %25 : int = constant @\"10\";\n-    %26 : int = var.load %22;\n-    invoke %0 %23 @\"hat.ComputeClosure::preMutate(hat.buffer.Buffer)void\";\n- !   invoke %23 %24 %25 %26 @\"hat.buffer.S32Array2D::set(int, int, int)void\";\n-    invoke %0 %23 @\"hat.ComputeClosure::postMutate(hat.buffer.Buffer)void\";\n-    %27 : hat.ComputeContext = var.load %5;\n-```\n-And here at runtime the ComputeClosure is reporting accesses when executing via the interpreter after the injected calls.\n-\n-```\n-ComputeClosure.preAccess S32Array2D[width()=1024, height()=1024, array()=int[1048576]]\n-ComputeClosure.postAccess S32Array2D[width()=1024, height()=1024, array()=int[1048576]]\n-ComputeClosure.preAccess S32Array2D[width()=1024, height()=1024, array()=int[1048576]]\n-ComputeClosure.postAccess S32Array2D[width()=1024, height()=1024, array()=int[1048576]]\n-ComputeClosure.preMutate S32Array2D[width()=1024, height()=1024, array()=int[1048576]]\n-ComputeClosure.postMutate S32Array2D[width()=1024, height()=1024, array()=int[1048576]]\n-```\n-## Why inject this info?\n-So the idea is that the ComputeContext would maintain sets of dirty buffers, one set for `gpuDirty` and one set for `javaDirty`.\n-\n-We have the code for kernel models. So we know which kernel accesses, mutates or accesses AND mutates particular parameters.\n-\n-So when the ComputeContext receives  `preAccess(x)` or `preMutate(x)` the ComputeContext would determine if `x` is in the `gpuDirty` set.\n-If so it would delegate to the backend to  copy the GPU data back from device into the memory segment (assuming the memory is not coherent!)\n-before removing the buffer from `gpuDirty` set and returning.\n-\n-Now the Java access to the segment sees the latest buffer.\n-\n-After `postMutate(x)` it will place the buffer in `javaDirty` set.\n-\n-When a kernel dispatch comes along, the parameters to the kernel are all checked against the `javaDirty` set.\n-If the parameter is 'accessed' by the kernel. The backend will copy the segment to device. Remove the parameter\n-from the `javaDirty` set and then invoke the kernel.\n-When the kernel completes (lets assume synchronous for a moment) all parameters are checked again, and if the parameter\n-is known to be mutated by the kernel the parameter is added to the 'gpuDirty' set.\n-\n-This way we don't have to force the developer to request data movements.\n-\n-BTW if kernel requests are async ;) then the ComputeContext maintains a map of buffer to kernel.  So `preAccess(x)` or `preMutate(x)` calls\n-can wait on the kernel that is due to 'dirty' the buffer to complete.\n-\n-### An alternative to pre\/pos access\/mutate\n-# TODO -\n-Explain how we can spin up classes to hold onto iface buffers then pass these holders around, which maintain dirty state.\n-\n-\n-\n","filename":"hat\/docs\/hat.md","additions":0,"deletions":558,"binary":false,"changes":558,"status":"deleted"},{"patch":"@@ -1,57 +0,0 @@\n-# Interface Mapping\n-We have a copy of Per's segment mapping code from\n-https:\/\/github.com\/minborg\/panama-foreign\/blob\/segment-mapper\/src\/java.base\/share\/classes\n-\n-Specifically we hava a copy of the following dirs\n-\n-```\n-src\/main\/java.base\n-     java.lang.foreign.mapper\n-     jdk.internal.foreign.mapper\n-```\n-\n-To allow this code to be used with 'babylon jdk' we need to add:-\n-\n-`--patch-module=java.base=src\/main\/java.base`\n-\n-To javac opts (to include this src in the compilation\n-\n-`--patch-module=java.base=babylon\/out\/production\/babylon`\n-\n-To the java VM options at runtime, so we can access these classes as if in java.base\n-\n-In intellij we need to make sure that the following is added to .idea\/compiler.xml\n-```xml\n-<!-- babylon\/.idea\/compiler.xml -->\n-<component name=\"JavacSettings\">\n-    <option name=\"ADDITIONAL_OPTIONS_OVERRIDE\">\n-        <component name=\"JavacSettings\">\n-            <option name=\"ADDITIONAL_OPTIONS_OVERRIDE\">\n-                <module name=\"babylon\" options=\"\n-                    --enable-preview\n-                    --patch-module=java.base=$PROJECT_DIR$\/..\/src\/main\/java.base\n-                    --add-exports=java.base\/java.lang.reflect.code.descriptor.impl=ALL-UNNAMED\n-                    --add-exports=java.base\/java.lang.reflect.code.impl=ALL-UNNAMED\n-                    --add-exports=java.base\/jdk.internal=ALL-UNNAMED\n-                    --add-exports=java.base\/jdk.internal.vm.annotation=ALL-UNNAMED\n-                    --add-exports=java.base\/jdk.internal.foreign.layout=ALL-UNNAMED\n-                    --add-exports=java.base\/jdk.internal.util=ALL-UNNAMED\n-                    --add-exports=java.base\/sun.security.action=ALL-UNNAMED\n-                    --add-exports=java.base\/jdk.internal.misc=ALL-UNNAMED\n-                \" \/>\n-                <module name=\"segment.mapper\" options=\"\n-                    --add-exports java.base\/jdk.internal.vm.annotation=ALL-UNNAMED\n-                    --add-exports java.base\/sun.security.action=ALL-UNNAMED\" \/>\n-            <\/option>\n-        <\/component>\n-    <\/option>\n-<\/component>\n-```\n-Note specifically the `options` attribute above must include the `--patch-module` option above\n-\n-To run we need to ensure that the following Vm options are added to the run configuration\n-\n-```--enable-preview\n---add-opens=java.base\/java.lang.reflect.code.descriptor.impl=ALL-UNNAMED\n---patch-module=java.base=out\/production\/babylon\n-```\n","filename":"hat\/docs\/interface-mapping.md","additions":0,"deletions":57,"binary":false,"changes":57,"status":"deleted"},{"patch":"@@ -1,434 +0,0 @@\n-# Compute and Kernel Analysis with Babylon\n-#### Gary Frost - January 2024\n-\n-This is a primer for how we might use Babylon\/Code Reflection\n-to help dispatch code to GPU devices.\n-\n-----\n-\n-First lets remind ourself of the structure of a HAT compute class.\n-\n-```java\n-static class Squarer {\n-   @CodeReflection\n-   public static void\n-      squareKernel(KernelContext kc, S32Array arr) {\n-         int value = arr.array(kc.x);          \/\/ arr[cc.x]\n-         s32Array.array(kc.x, value * value);  \/\/ arr[cc.x]=value*value\n-   }\n-\n-   @CodeReflection\n-   public static void\n-      square(ComputeContext cc, S32Array arr) {\n-         cc.dispatchKernel(\n-              arr.size,                   \/\/ Range for 2d maybe n,m\n-              kc->squareKernel(kc, arr)   \/\/ QuotableKernelContextConsumer\n-         );                               \/\/    extends Quotable, Consumer<KernelContext>\n-\n-   }\n-\n-   public static void main(String args) {\n-      var lookup = java.lang.invoke.MethodHandles.lookup();\n-      var backend = Backend::JAVA_MULTITHREADED; \/\/ Predicate<Backend>\n-      var accelerator = new Accelerator(lookup, backend);\n-\n-      var arr = S32Array.create(accelerator, 100);\n-\n-      for (int i=0; i<arr.length(); i++){\n-          arr.array(i,i); \/\/ arr[i]=i;\n-      }\n-      accelerator.compute(\n-              cc->Squarer.square(cc,arr)  \/\/QuotableComputeContextConsumer\n-      );                                  \/\/   extends Quotable, Consumer<ComputeContext>\n-\n-   }\n-}\n-```\n-Above we show a Compute class `Squarer` with compute entrypoint called `square`\n-which is responsible for dispatching a simple kernel `squareKernel` over a range `0..arr.len`.\n-\n-```java\n-Accelerator accelerator = Accelerator.getGPUAccelerator();\n-accelerator.execute(computeClosure);\n-```\n-----\n-0. All Compute entrypoints and Kernels (and methods reachable by either), must have the ```@CodeReflection``` annotation\n-1. The developer should not call either the `Compute.compute()` method or the `Compute.kernel()` methods directly.\n-2. Instead, we pass the entrypoint  `Compute.compute()` to an `Accelerator` instance which 'conceptually' executes the `compute()`\n-\n-      Note that the accelerator itself is also used within the compute entrypoint to dispatch the `kernel()` over a range.\n-3. The Accelerator has full control over the execution\n-\n-      it is free to decide to execute the bytecode of the `compute()`\n-\n-      ... or convert that code into some completely different form and interpret it\n-\n-      ... convert to C99, compile and link to it\n-\n-      It is not our concern.\n-\n-4. Kernel methods will only allow a restricted subset of Java.\n-5. The first kernel argument is always and NDRange reference, which provides the kernels unique dispatch 'identity' (it's id 0..len, it's group, workload dimensions etc)\n-6. Kernel parameters are restricted to uniform primitive values and Panama FFM `MemorySegment`'s\n-7. Kernels may not access heap data (no `new`, no `Strings` no virtual dispatch....)\n-5. Kernels can call other static methods within the `Compute` class.  But the above kernel restrictions will apply to any code reachable from the kernel.\n-6. Compute antrypoints (such as `compute`) should have very few restrictions, although some code patterns may hamper performance.\n-7. Compute entrypoints alway receives an Accelerator as it's first arg.\n-----\n-## How do we use *babylon*?\n-\n-1. We 'close over' the call\/dispatch graph from the entrypoint to all kernels and collect the kernels reachable from the entrypoint and all methods reachable from methods reachable by kernels.\n-2. We essentially end up with a graph of codemodels 'rooted' at the entrypoint\n-2. For each kernel we also determine how the kernel accesses it's 'MemorySegment` parameters, for each MemorySegment parameters we keep a side table of whther the kernel reads or writes to the segment. We keep this infomation in a side map.\n-\n-This resulting 'ComputeClosure' (tree of codemodels and relevant side tables) is made available to the accelerator to coordinate execution.\n-\n-Note that our very simple Compute::compute method neither expresses the movement of the MemorySegment to a device, or the retrieval of the data from a device when the kernel has executed.\n-\n-Our assumption is that given the ComputeClosure we can deduce such movements.\n-----\n-There are many ways to achieve this.  One way would be by static analysis.\n-\n-Given the Compute::compute entrypoint it is easy to determine that we are always (no conditional or loops) passing (making available\n-might be a better term) a memory segment to a kernel (Compute::kernel) and this kernel only mutates the  `MemorySegment`.\n-\n-\n-So from simple static analysis we could choose to inject one or more calls into the model representing the need for the accelerator to move data to the devices and\/ord back from the device, after the kernel dispatch.\n-\n-----\n-\n-This modified model, would look like we had presented it with this code.\n-\n-```java\n- void compute(Accelerator accelerator, MemorySegment memorySegment, int len) {\n-        Accelerator.Range range = accelerator.range(len);\n-        accelerator.run(Compute::kernel, range, memorySegment);\n-        accelerator.injectedCopyFromDevice(memorySegment);\n-    }\n-```\n-\n-Note the ```injectedCopyFromDevice()``` call.\n-\n-----\n-\n-Because the kernel does not read the `MemorySegment` we only need inject the code to request a move back from the device.\n-\n-To do this requires HAT to analyse the kernel(s) and inject appropriate code into\n-the Compute::compute method to inform the vendor backend when it should perform such moves.\n-----\n-Another strategy would be to not rely on static analysis but to inject code to trace 'actual' mutations of the MemorySegments and use these flags to guard against unnecessary copies\n-\n-```java\n- void compute(Accelerator accelerator, MemorySegment memorySegment, int len) {\n-        boolean injectedMemorySegmentIsDirty = false;\n-        Accelerator.Range range = accelerator.range(len);\n-        if (injectedMemorySegmentIsDirty){\n-            accelerator.injectedCopyToDevice(memorySegment);\n-        }\n-        accelerator.run(Compute::kernel, range, memorySegment);\n-        injectedMemorySegmentIsDirty = true; \/\/ based on Compute::kernel sidetable\n-        if (injectedMemorySegmentIsDirty) {\n-            accelerator.injectedCopyFromDevice(memorySegment);\n-        }\n-    }\n-```\n-----\n-\n-Whether this code mutation generates Java bytecode and executes (or interprets) on the JVM or whether the\n-CodeModels for the closure are handed over to a backend which reifies the kernel code and the\n-logic for dispatch is not defined.\n-\n-The code model for the compute will be mutated to inject the appropriate nodes to achieve the goal\n-\n-It is possible that some vendors may just take the original code model and analyse themselves.\n-\n-----\n-\n-Clearly this is a trivial compute closure.   Lets discuss the required kernel analysis\n-and proposed pseudo code.\n-\n-## Copying data based on kernel MemorySegment analysis\n-\n-Above we showed that we should be able to determine whether a kernel mutates or accesses any of\n-it's Kernel MemorySegment parameters.\n-\n-We determined above that the kernel only called set() so we need\n-not copy the data to the device.\n-\n-The following example shows a kernel which reads and mutates a memorysegment\n-```java\n-    static class Compute {\n-    @CodeReflection  public static\n-    void doubleup(Accelerator.NDRange ndrange, MemorySegment memorySegment) {\n-        int temp = memorySegment.get(JAVA_INT, ndrange.id.x);\n-        memorySegment.set(JAVA_INT, temp*2);\n-    }\n-\n-    @CodeReflection public static\n-    void compute(Accelerator accelerator, MemorySegment memorySegment, int len) {\n-        Accelerator.Range range = accelerator.range(len);\n-        accelerator.run(Compute::doubleup, range, memorySegment);\n-    }\n-}\n-```\n-\n-Here our analysis needs to determine that the kernel reads and writes to the segment (it does)\n-so the generated compute model would equate to\n-\n-```java\n- void compute(Accelerator accelerator, MemorySegment memorySegment, int len) {\n-        Accelerator.Range range = accelerator.range(len);\n-        accelerator.copyToDevice(memorySegment); \/\/ injected via Babylon\n-        accelerator.run(Compute::doubleup, range, memorySegment);\n-        accelerator.copyFromDevice(memorySegment); \/\/ injected via Babylon\n-    }\n-```\n-----\n-So far the deductions are fairly trivial\n-\n-Consider\n-```java\n- @CodeReflection public static\n-    void compute(Accelerator accelerator, MemorySegment memorySegment, int len, int count) {\n-        Accelerator.Range range = accelerator.range(len);\n-        for (int i=0; i&lt;count; i++) {\n-            accelerator.run(Compute::doubleup, range, memorySegment);\n-        }\n-    }\n-```\n-\n-Here HAT should deduce that the java side is merely looping over the kernel dispatch\n-and has no interest in the memorysegment between dispatches.\n-\n-So the new model need only copy in once (before the fist kernel) and out once (prior to return)\n-\n-```java\n- @CodeReflection public static\n-    void compute(Accelerator accelerator, MemorySegment memorySegment, int len, int count) {\n-        Accelerator.Range range = accelerator.range(len);\n-        accelerator.copyToDevice(memorySegment); \/\/ injected via Babylon\n-        for (int i=0; i&lt; count; i++) {\n-            accelerator.run(Compute::doubleup, range, memorySegment);\n-        }\n-        accelerator.copyFromDevice(memorySegment); \/\/ injected via Babylon\n-    }\n-```\n-Things get slightly more interesting when we do indeed access the memory segment\n-from the Java code inside the loop.\n-\n-```java\n- @CodeReflection public static\n-    void compute(Accelerator accelerator, MemorySegment memorySegment, int len, int count) {\n-        Accelerator.Range range = accelerator.range(len);\n-        for (int i=0; i&lt;count; i++) {\n-            accelerator.run(Compute::doubleup, range, memorySegment);\n-            int slot0 = memorySegment.get(INTVALUE, 0);\n-            System.out.println(\"slot0 \", slot0);\n-        }\n-    }\n-```\n-Now we expect babylon to inject a read inside the loop to make the data available java side\n-----\n-```java\n- @CodeReflection public static\n-    void compute(Accelerator accelerator, MemorySegment memorySegment, int len, int count) {\n-        Accelerator.Range range = accelerator.range(len);\n-        accelerator.copyToDevice(memorySegment); \/\/ injected via Babylon\n-        for (int i=0; i&lt;count; i++) {\n-            accelerator.run(Compute::doubleup, range, memorySegment);\n-            accelerator.copyFromDevice(memorySegment); \/\/ injected via Babylon\n-            int slot0 = memorySegment.get(INTVALUE, 0);\n-            System.out.println(\"slot0 \", slot0);\n-        }\n-\n-    }\n-```\n-----\n-Note that in this case we are only accessing 0th int from the segment so a possible\n-optimization might be to allow the vendor to only copy back this one element....\n-```java\n- @CodeReflection public static\n-    void compute(Accelerator accelerator, MemorySegment memorySegment, int len, int count) {\n-        Accelerator.Range range = accelerator.range(len);\n-        accelerator.copyToDevice(memorySegment); \/\/ injected via Babylon\n-        for (int i=0; i&lt;count; i++) {\n-            accelerator.run(Compute::doubleup, range, memorySegment);\n-            if (i+1==count){\/\/ injected\n-                accelerator.copyFromDevice(memorySegment); \/\/ injected\n-            }else {\n-                accelerator.copyFromDevice(memorySegment, 1); \/\/ injected via Babylon\n-            }\n-            int slot0 = memorySegment.get(INTVALUE, 0);\n-            System.out.println(\"slot0 \", slot0);\n-        }\n-\n-    }\n-```\n-----\n-Again HAT will merely mutate the code model of the compute method,\n-the vendor may choose to interpret bytecode, generate bytecode and execute\n-or take complete control and execute the model in native code.\n-\n-So within HAT we must find all set\/get calls on MemorySegments and trace them back to kernel parameters.\n-\n-We should allow aliasing of memory segments... but in the short term we may well throw an exception when we see such aliasing\n-\n-\n-```java\n- @CodeReflection  public static\n-    void doubleup(Accelerator.NDRange ndrange, MemorySegment memorySegment) {\n-        MemorySegment alias = memorySegment;\n-        alias.set(JAVA_INT, ndrange.id.x, alias.get(JAVA_INT, ndrange.id.x)*2);\n-    }\n-```\n-----\n-#### Weed warning #1\n-\n-We could find common kernel errors when analyzing\n-\n-This code is probably wrong, as it is racey writing to 0th element\n-\n-```java\n- void doubleup(Accelerator.NDRange ndrange, MemorySegment memorySegment) {\n-    MemorySegment alias = memorySegment;\n-    alias.set(JAVA_INT, 0, alias.get(JAVA_INT, ndrange.id.x)*2);\n-}\n-```\n-----\n-\n-By allowing a 'lint' like plugin mechanism for code model it would be easy to find.\n-If we ever find a constant index in set(...., &lt;constant&gt; ) we are probably in a world of hurt.\n-Unless the set is included in some conditional which itself is dependant on a value extracted from a memory segment.\n-\n-```java\n- void doubleup(Accelerator.NDRange ndrange, MemorySegment memorySegment) {\n-    MemorySegment alias = memorySegment;\n-    if (????){\n-        alias.set(JAVA_INT, 0, alias.get(JAVA_INT, ndrange.id.x) * 2);\n-    }\n-}\n-```\n-There are a lot opportunities for catching such bugs.\n-----\n-\n-### Flipping Generations\n-\n-Many algorithms require us to process data from generations. Consider\n-Convolutions or Game Of Life style problems where we have an image or game state and\n-we need to calculate the result of applying rules to cells in the image or game.\n-\n-It is important that when we process the next generation (either in parallel or sequentially) we\n-must ensure that we only use prev generation data to generate next generation data.\n-\n-```\n-[ ][ ][*][ ][ ]       [ ][ ][ ][ ][ ]\n-[ ][ ][*][ ][ ]       [ ][*][*][*][ ]\n-[ ][ ][*][ ][ ]   -&gt;  [ ][ ][ ][ ][ ]\n-[ ][ ][ ][ ][ ]       [ ][ ][ ][ ][ ]\n-\n-```\n-----\n-This usually requires us to hold two copies,  and applying the kernel to one input set\n-which writes to the output.\n-\n-In the case of the Game Of Life we may well use the output as the next input...\n-\n-```java\n-@CodeReflection void conway(Accelerator.NDRange ndrange,\n-                            MemorySegment in, MemorySegment out, int width, int height) {\n-    int cx = ndrange.id.x % ndrange.id.maxx;\n-    int cy = ndrange.id.x \/ ndrange.id.maxx;\n-\n-    int sum = 0;\n-    for (int dx = -1; dx &lt; 2; dy++) {\n-        for (int dy = -1; dy &lt; 2; dy++) {\n-            if (dx != 0 || dy != 0) {\n-                int x = cx + dx;\n-                int y = cy + dy;\n-                if (x&gt;= 0 && x &lt; width && y &gt;= 0 && y &lt; height) {\n-                    sum += in.get(INT, x * width + h);\n-                }\n-            }\n-        }\n-    }\n-    result = GOLRules(sum, in.get(INT, ndrange.id.x));\n-    out.set(INT, ndrange.id.x);\n-\n-}\n-```\n-In this case the assumption is that the compute layer will swap the buffers for alternate passes\n-----\n-```java\n-import java.lang.foreign.MemorySegment;\n-\n-@CodeReflection\n-void compute(Accelerator accelerator, MemorySegment gameState,\n-             int width, int height, int maxGenerations) {\n-    MemorySegment s1 = gameState;\n-    MemorySegment s2 = allocateGameState(width, height);\n-    for (int generation = 0; generation &lt; maxGenerations; generation++){\n-        MemorySegment from = generation%2==0?s1?s2;\n-        MemorySegment to = generation%2==1?s1?s2;\n-        accelerator.run(Compute::conway, from, to, range, width, height);\n-    }\n-    if (maxGenerations%2==1){ \/\/ ?\n-        gameState.copyFrom(s2);\n-    }\n-}\n-```\n-----\n-This common pattern includes some aliasing of MemorySegments that we need to untangle.\n-\n-HAT needs to be able to track the aliases to determine the minimal number of copies.\n-```java\n-import java.lang.foreign.MemorySegment;\n-\n-@CodeReflection\n-void compute(Accelerator accelerator, MemorySegment gameState, int width, int height, int maxGenerations,\n-             DisplaySAM displaySAM) {\n-    MemorySegment s1 = gameState;\n-    MemorySegment s2 = allocateGameState(width, height);\n-\n-    for (int generation = 0; generation &lt; maxGenerations; generation++){\n-        MemorySegment from = generation%2==0?s1?s2;\n-        MemorySegment to = generation%2==1?s1?s2;\n-        if (generation == 0) {             \/\/\/ injected\n-            accerator.copyToDevice(from);    \/\/ injected\n-        }                                  \/\/ injected\n-        accelerator.run(Compute::conway, from, to, range, width, height, 1000);\n-        if (generation == maxGenerations-1){ \/\/ injected\n-            accerator.copyFromDevice(to);    \/\/injected\n-        }                                    \/\/injected\n-    }\n-    if (maxGenerations%2==1){ \/\/ ?\n-        gameState.copyFrom(s2);\n-    }\n-\n-}\n-```\n-----\n-```java\n-import java.lang.foreign.MemorySegment;\n-\n-@CodeReflection\n-void compute(Accelerator accelerator, MemorySegment gameState, int width, int height,\n-             int maxGenerations,\n-             DisplaySAM displaySAM) {\n-    MemorySegment s1 = gameState;\n-    MemorySegment s2 = allocateGameState(width, height);\n-\n-    for (int generation = 0; generation &lt; maxGenerations; generation++){\n-        MemorySegment from = generation%2==0?s1?s2;\n-        MemorySegment to = generation%2==1?s1?s2;\n-        accelerator.run(Compute::conway, from, to, range, width, height,1000);\n-        displaySAM.display(s2,width, height);\n-    }\n-    if (maxGenerations%2==1){ \/\/ ?\n-        gameState.copyFrom(to);\n-    }\n-}\n-```\n-----\n-\n-\n-\n","filename":"hat\/docs\/kernel.md","additions":0,"deletions":434,"binary":false,"changes":434,"status":"deleted"},{"patch":"@@ -1,403 +0,0 @@\n-# Compute and Kernel Analysis with Babylon\n-#### Gary Frost - January 2024\n-\n-This is a primer for how we might use Babylon\/Code Reflection\n-to help dispatch code to GPU devices.\n-\n-First lets remind ourself of the structure of a HAT compute class.\n-\n-### A HAT Compute class primer\n-```java\n-    static class Compute {\n-    @CodeReflection  public static\n-    void kernel(Accelerator.NDRange ndrange, MemorySegment memorySegment) {\n-        memorySegment.set(JAVA_INT, ndrange.id.x);\n-    }\n-\n-    @CodeReflection public static\n-    void compute(Accelerator accelerator, MemorySegment memorySegment, int len) {\n-        Accelerator.Range range = accelerator.range(len);\n-        accelerator.run(Compute::kernel, range, memorySegment);\n-    }\n-}\n-\n-HAT.ComputeClosure computeClosure = HAT.getComputeClosure(lookup,Compute::compute);\n-```\n-\n-Above we show a Compute class with compute entrypoint called `compute` which is responsible for dispatching a simple kernel `kernel` over a range `0..len`.\n-\n-In this case compute entrypoint accepts a MemorySegment containing int values.\n-\n-\n-This case we have a single kernel dispatch and the kernel just sets each element of the  (presumed) int memory segment to monotonically increasing values (0,1,2,3,...)\n-\n-The caller is expected to get an Accelerator (from somewhere ;)) and then pass the compute closure's entrypoint to the Accelerator to execute\n-\n-```java\n-Accelerator accelerator = Accelerator.getGPUAccelerator();\n-accelerator.execute(computeClosure);\n-```\n-\n-##First a few notes\n-\n-0. All Compute entrypoints and Kernels and methods reachable by either, need the ```java @CodeReflection``` annotation\n-1. The developer should not call either the `Compute.compute()` method or the `Compute.kernel()` methods directly.\n-2. Instead, we pass the entrypoint  `Compute.compute()` to an `Accelerator` instance which 'conceptually' executes the `compute()` method.  Note also that the accelerator itself is also used within the compute entrypoint to dispatch the `kernel()` over a range.\n-3. The Accelerator therefore has full control over the execution, so much so, that it is free to decide to execute the bytecode of the `compute()` or convert that code into some completely different form  and interpret it, or convert to C99, compile and link to it.  It is not our concern.\n-4. Kernel methods will only allow a restricted subset of Java.\n-5. The first kernel argument is always and NDRange reference, which provides the kernels unique dispatch 'identity' (it's id 0..len, it's group, workload dimensions etc)\n-6. Kernel parameters are restricted to uniform primitive values and Panama FFM `MemorySegment`'s\n-7. Kernels may not access heap data (no `new`, no `Strings` no virtual dispatch....)\n-5. Kernels can call other static methods within the `Compute` class.  But the above kernel restrictions will apply to any code reachable from the kernel.\n-6. Compute antrypoints (such as `compute`) should have very few restrictions, although some code patterns may hamper performance.\n-7. Compute entrypoints alway receives an Accelerator as it's first arg.\n-\n-##How do we use bablylon?\n-\n-1. We 'close over' the call\/dispatch graph from the entrypoint to all kernels and collect the kernels reachable from the entrypoint and all methods reachable from methods reachable by kernels.\n-2. We essentially end up with a graph of codemodels 'rooted' at the entrypoint\n-2. For each kernel we also determine how the kernel accesses it's 'MemorySegment` parameters, for each MemorySegment parameters we keep a side table of whther the kernel reads or writes to the segment. We keep this infomation in a side map.\n-\n-This resulting 'ComputeClosure' (tree of codemodels and relevant side tables) is made available to the accelerator to coordinate execution.\n-\n-Note that our very simple Compute::compute method neither expresses the movement of the MemorySegment to a device, or the retrieval of the data from a device when the kernel has executed.\n-\n-Our assumption is that given the ComputeClosure we can deduce such movements.\n-\n-There are many ways to achieve this.  One way would be by static analysis.\n-\n-Given the Compute::compute entrypoint it is easy to determine that we are always (no conditional or loops) passing (making available\n-might be a better term) a memory segment to a kernel (Compute::kernel) and this kernel only mutates the  `MemorySegment`.\n-\n-So from simple static analysis we could choose to inject one or more calls into the model representing the need for the accelerator to move data to the devices and\/ord back from the device, after the kernel dispatch.\n-\n-This modified model, would look like we had presented it with this code.\n-\n-```java\n- void compute(Accelerator accelerator, MemorySegment memorySegment, int len) {\n-        Accelerator.Range range = accelerator.range(len);\n-        accelerator.run(Compute::kernel, range, memorySegment);\n-        accelerator.injectedCopyFromDevice(memorySegment);\n-    }\n-```\n-\n-Note the ```injectedCopyFromDevice()``` call.\n-\n-Because the kernel does not read the `MemorySegment` we only need inject the code to request a move back from the device.\n-\n-To do this requires HAT to analyse the kernel(s) and inject appropriate code into\n-the Compute::compute method to inform the vendor backend when it should perform such moves.\n-\n-Another strategy would be to not rely on static analysis but to inject code to trace 'actual' mutations of the MemorySegments and use these flags to guard against unnecessary copies\n-\n-```java\n- void compute(Accelerator accelerator, MemorySegment memorySegment, int len) {\n-        boolean injectedMemorySegmentIsDirty = false;\n-        Accelerator.Range range = accelerator.range(len);\n-        if (injectedMemorySegmentIsDirty){\n-            accelerator.injectedCopyToDevice(memorySegment);\n-        }\n-        accelerator.run(Compute::kernel, range, memorySegment);\n-        injectedMemorySegmentIsDirty = true; \/\/ based on Compute::kernel sidetable\n-        if (injectedMemorySegmentIsDirty) {\n-            accelerator.injectedCopyFromDevice(memorySegment);\n-        }\n-    }\n-```\n-\n-\n-Whether this code mutation generates Java bytecode and executes (or interprets) on the JVM or whether the\n-CodeModels for the closure are handed over to a backend which reifies the kernel code and the\n-logic for dispatch is not defined.\n-\n-The code model for the compute will be mutated to inject the appropriate nodes to achieve the goal\n-\n-It is possible that some vendors may just take the original code model and analyse themselves.\n-\n-Clearly this is a trivial compute closure.   Lets discuss the required kernel analysis\n-and proposed pseudo code.\n-\n-## Copying data based on kernel MemorySegment analysis\n-\n-Above we showed that we should be able to determine whether a kernel mutates or accesses any of\n-it's Kernel MemorySegment parameters.\n-\n-We determined above that the kernel only called set() so we need\n-not copy the data to the device.\n-\n-The following example shows a kernel which reads and mutates a memorysegment\n-```java\n-    static class Compute {\n-    @CodeReflection  public static\n-    void doubleup(Accelerator.NDRange ndrange, MemorySegment memorySegment) {\n-        int temp = memorySegment.get(JAVA_INT, ndrange.id.x);\n-        memorySegment.set(JAVA_INT, temp*2);\n-    }\n-\n-    @CodeReflection public static\n-    void compute(Accelerator accelerator, MemorySegment memorySegment, int len) {\n-        Accelerator.Range range = accelerator.range(len);\n-        accelerator.run(Compute::doubleup, range, memorySegment);\n-    }\n-}\n-```\n-Here our analysis needs to determine that the kernel reads and writes to the segment (it does)\n-so the generated compute model would equate to\n-\n-```java\n- void compute(Accelerator accelerator, MemorySegment memorySegment, int len) {\n-        Accelerator.Range range = accelerator.range(len);\n-        accelerator.copyToDevice(memorySegment); \/\/ injected via Babylon\n-        accelerator.run(Compute::doubleup, range, memorySegment);\n-        accelerator.copyFromDevice(memorySegment); \/\/ injected via Babylon\n-    }\n-```\n-So far the deductions are fairly trivial\n-\n-Consider\n-```java\n- @CodeReflection public static\n-    void compute(Accelerator accelerator, MemorySegment memorySegment, int len, int count) {\n-        Accelerator.Range range = accelerator.range(len);\n-        for (int i=0; i<count; i++) {\n-            accelerator.run(Compute::doubleup, range, memorySegment);\n-        }\n-    }\n-```\n-\n-Here HAT should deduce that the java side is merely looping over the kernel dispatch\n-and has no interest in the memorysegment between dispatches.\n-\n-So the new model need only copy in once (before the fist kernel) and out once (prior to return)\n-\n-```java\n- @CodeReflection public static\n-    void compute(Accelerator accelerator, MemorySegment memorySegment, int len, int count) {\n-        Accelerator.Range range = accelerator.range(len);\n-        accelerator.copyToDevice(memorySegment); \/\/ injected via Babylon\n-        for (int i=0; i<count; i++) {\n-            accelerator.run(Compute::doubleup, range, memorySegment);\n-        }\n-        accelerator.copyFromDevice(memorySegment); \/\/ injected via Babylon\n-    }\n-```\n-\n-Things get slightly more interesting when we do indeed access the memory segment\n-from the Java code inside the loop.\n-\n-```java\n- @CodeReflection public static\n-    void compute(Accelerator accelerator, MemorySegment memorySegment, int len, int count) {\n-        Accelerator.Range range = accelerator.range(len);\n-        for (int i=0; i<count; i++) {\n-            accelerator.run(Compute::doubleup, range, memorySegment);\n-            int slot0 = memorySegment.get(INTVALUE, 0);\n-            System.out.println(\"slot0 \", slot0);\n-        }\n-    }\n-```\n-Now we expect babylon to inject a read inside the loop to make the data available java side\n-\n-```java\n- @CodeReflection public static\n-    void compute(Accelerator accelerator, MemorySegment memorySegment, int len, int count) {\n-        Accelerator.Range range = accelerator.range(len);\n-        accelerator.copyToDevice(memorySegment); \/\/ injected via Babylon\n-        for (int i=0; i<count; i++) {\n-            accelerator.run(Compute::doubleup, range, memorySegment);\n-            accelerator.copyFromDevice(memorySegment); \/\/ injected via Babylon\n-            int slot0 = memorySegment.get(INTVALUE, 0);\n-            System.out.println(\"slot0 \", slot0);\n-        }\n-\n-    }\n-```\n-\n-Note that in this case we are only accessing 0th int from the segment so a possible\n-optimization might be to allow the vendor to only copy back this one element....\n-```java\n- @CodeReflection public static\n-    void compute(Accelerator accelerator, MemorySegment memorySegment, int len, int count) {\n-        Accelerator.Range range = accelerator.range(len);\n-        accelerator.copyToDevice(memorySegment); \/\/ injected via Babylon\n-        for (int i=0; i<count; i++) {\n-            accelerator.run(Compute::doubleup, range, memorySegment);\n-            if (i+1==count){\/\/ injected\n-                accelerator.copyFromDevice(memorySegment); \/\/ injected\n-            }else {\n-                accelerator.copyFromDevice(memorySegment, 1); \/\/ injected via Babylon\n-            }\n-            int slot0 = memorySegment.get(INTVALUE, 0);\n-            System.out.println(\"slot0 \", slot0);\n-        }\n-\n-    }\n-```\n-\n-Again HAT will merely mutate the code model of the compute method,\n-the vendor may choose to interpret bytecode, generate bytecode and execute\n-or take complete control and execute the model in native code.\n-\n-So within HAT we must find all set\/get calls on MemorySegments and trace them back to kernel parameters.\n-\n-We should allow aliasing of memory segments... but in the short term we may well throw an exception when we see such aliasing\n-\n-\n-```java\n- @CodeReflection  public static\n-    void doubleup(Accelerator.NDRange ndrange, MemorySegment memorySegment) {\n-        MemorySegment alias = memorySegment;\n-        alias.set(JAVA_INT, ndrange.id.x, alias.get(JAVA_INT, ndrange.id.x)*2);\n-    }\n-```\n-\n-## Weed warning #1\n-\n-We could find common kernel errors when analyzing\n-\n-This code is probably wrong, as it is racey writing to 0th element\n-\n-```java\n- void doubleup(Accelerator.NDRange ndrange, MemorySegment memorySegment) {\n-    MemorySegment alias = memorySegment;\n-    alias.set(JAVA_INT, 0, alias.get(JAVA_INT, ndrange.id.x)*2);\n-}\n-```\n-\n-By allowing a 'lint' like plugin mechanism for code model it would be easy to find.\n-If we ever find a constant index in set(...., <constant> ) we are probably in a world of hurt.\n-Unless the set is included in some conditional which itself is dependant on a value extracted from a memory segment.\n-\n-```java\n- void doubleup(Accelerator.NDRange ndrange, MemorySegment memorySegment) {\n-    MemorySegment alias = memorySegment;\n-    if (????){\n-        alias.set(JAVA_INT, 0, alias.get(JAVA_INT, ndrange.id.x) * 2);\n-    }\n-}\n-```\n-\n-There are a lot opportunities for catching such bugs.\n-\n-\n-## Flipping Generations\n-\n-Many algorithms require us to process data from generations. Consider\n-Convolutions or Game Of Life style problems where we have an image or game state and\n-we need to calculate the result of applying rules to cells in the image or game.\n-\n-It is important that when we process the next generation (either in parallel or sequentially) we\n-must ensure that we only use prev generation data to generate next generation data.\n-\n-```\n-[ ][ ][*][ ][ ]       [ ][ ][ ][ ][ ]\n-[ ][ ][*][ ][ ]       [ ][*][*][*][ ]\n-[ ][ ][*][ ][ ]   ->  [ ][ ][ ][ ][ ]\n-[ ][ ][ ][ ][ ]       [ ][ ][ ][ ][ ]\n-\n-```\n-\n-This usually requires us to hold two copies,  and applying the kernel to one input set\n-which writes to the output.\n-\n-In the case of the Game Of Life we may well use the output as the next input...\n-\n-```java\n-@CodeReflection void conway(Accelerator.NDRange ndrange,\n-                            MemorySegment in, MemorySegment out, int width, int height) {\n-    int cx = ndrange.id.x % ndrange.id.maxx;\n-    int cy = ndrange.id.x \/ ndrange.id.maxx;\n-\n-    int sum = 0;\n-    for (int dx = -1; dx < 2; dy++) {\n-        for (int dy = -1; dy < 2; dy++) {\n-            if (dx != 0 || dy != 0) {\n-                int x = cx + dx;\n-                int y = cy + dy;\n-                if (x >= 0 && x < widh && y >= 0 && y < height) {\n-                    sum += in.get(INT, x * width + h);\n-                }\n-            }\n-        }\n-    }\n-    result = GOLRules(sum, in.get(INT, ndrange.id.x));\n-    out.set(INT, ndrange.id.x);\n-\n-}\n-```\n-\n-In this case the assumption is that the compute layer will swap the buffers for alternate passes\n-\n-```java\n-import java.lang.foreign.MemorySegment;\n-\n-@CodeReflection\n-void compute(Accelerator accelerator, MemorySegment gameState,\n-             int width, int height, int maxGenerations) {\n-    MemorySegment s1 = gameState;\n-    MemorySegment s2 = allocateGameState(width, height);\n-    for (int generation = 0; generation < maxGenerations; generation++){\n-        MemorySegment from = generation%2==0?s1?s2;\n-        MemorySegment to = generation%2==1?s1?s2;\n-        accelerator.run(Compute::conway, from, to, range, width, height);\n-    }\n-    if (maxGenerations%2==1){ \/\/ ?\n-        gameState.copyFrom(s2);\n-    }\n-}\n-```\n-\n-This common pattern includes some aliasing of MemorySegments that we need to untangle.\n-\n-HAT needs to be able to track the aliases to determine the minimal number of copies.\n-```java\n-import java.lang.foreign.MemorySegment;\n-\n-@CodeReflection\n-void compute(Accelerator accelerator, MemorySegment gameState, int width, int height, int maxGenerations,\n-             DisplaySAM displaySAM) {\n-    MemorySegment s1 = gameState;\n-    MemorySegment s2 = allocateGameState(width, height);\n-\n-    for (int generation = 0; generation < maxGenerations; generation++){\n-        MemorySegment from = generation%2==0?s1?s2;\n-        MemorySegment to = generation%2==1?s1?s2;\n-        if (generation == 0) {             \/\/\/ injected\n-            accerator.copyToDevice(from);    \/\/ injected\n-        }                                  \/\/ injected\n-        accelerator.run(Compute::conway, from, to, range, width, height, 1000);\n-        if (generation == maxGenerations-1){ \/\/ injected\n-            accerator.copyFromDevice(to);    \/\/injected\n-        }                                    \/\/injected\n-    }\n-    if (maxGenerations%2==1){ \/\/ ?\n-        gameState.copyFrom(s2);\n-    }\n-\n-}\n-```\n-\n-```java\n-import java.lang.foreign.MemorySegment;\n-\n-@CodeReflection\n-void compute(Accelerator accelerator, MemorySegment gameState, int width, int height,\n-             int maxGenerations,\n-             DisplaySAM displaySAM) {\n-    MemorySegment s1 = gameState;\n-    MemorySegment s2 = allocateGameState(width, height);\n-\n-    for (int generation = 0; generation < maxGenerations; generation++){\n-        MemorySegment from = generation%2==0?s1?s2;\n-        MemorySegment to = generation%2==1?s1?s2;\n-        accelerator.run(Compute::conway, from, to, range, width, height,1000);\n-        displaySAM.display(s2,width, height);\n-    }\n-    if (maxGenerations%2==1){ \/\/ ?\n-        gameState.copyFrom(to);\n-    }\n-}\n-```\n-\n-\n-\n","filename":"hat\/docs\/kernel_analysis.md","additions":0,"deletions":403,"binary":false,"changes":403,"status":"deleted"},{"patch":"@@ -1,155 +0,0 @@\n-# HAT Project Primer\n-\n-This is a fairly large project with Java and Native artifacts.\n-\n-We also rely on the `babylon` (JDK23+Babylon) project, and the project will initially be made available as a subproject\n-called `hat` under [github.com\/openjdk\/babylon](https:\/\/github.com\/openjdk\/babylon)\n-\n-## Intellij and Clion\n-\n-Whilst I do use JetBrains' `IntelliJ` and `Clion` for dev work and plan to leave project artifacts in the tree.\n-Care must be taken as these tools do not play well together, specifically we cannot have `Clion` and `Intellij`\n-project artifacts rooted under each other or in the same dir.\n-\n-I have `intellij` and `clion` siblings which will act as roots\n-for various tools and then use relative paths (or even symbolic links) in the various `.iml` files to locate the various source roots\n-\n-So far this has worked ok.\n-\n-### cmake and maven\n-\n-We use maven for java artifacts and cmake for native libs (backends)  although the root level CMakeLists.txt can also create java artifacts.\n-\n-Generally to run any cmake target.\n-```bash\n-cd hat\n-mkdir build\n-cd build\n-cmake ..\n-cd ..\n-cmake --build build --target <yourtarget>\n-```\n-\n-The maven build will build hat and will then delegate to cmake to build the backends.\n-\n-To build with maven\n-\n-```bash\n-mvn clean compile assembly:single test\n-```\n-\n-### Initial Project Layout\n-\n-\n-```\n-${BABYLON_JDK}\n-   └── hat\n-        │\n-        ├── CMakeFile\n-        ├── build\n-        │\n-        ├── intellij\n-        │    ├── .idea\n-        │    │    ├── compiler.xml\n-        │    │    ├── misc.xml\n-        │    │    ├── modules.xml\n-        │    │    ├── uiDesigner.xml\n-        │    │    ├── vcs.xml\n-        │    │    └── workspace.xml\n-        │    │\n-        │    ├── hat.iml\n-        │    ├── backend_(spirv|mock|cuda|ptx|opencl).iml\n-        │    └── (mandel|violajones|experiments).iml\n-        │\n-        ├── hat\n-        │    └── src\n-        │         └── java\n-        │\n-        ├── backends\n-        │    └── (opencl|cuda|ptx|mock|shared)\n-        │          └── src\n-        │              ├── cpp\n-        │              ├── include\n-        │              ├── java\n-        │              └── services\n-        └── examples\n-             ├── mandel\n-             │    └── src\n-             │         └── java\n-             └── violajones\n-                  └── src\n-                       ├── java\n-                       └── resources\n-```\n-As you will note the `intellij` dir is somewhat self contained.  the various `*.iml`\n-files refer to the source dirs using relative paths.\n-\n-I tend to add `Intelli` modules by hand.  There are gotchas ;)\n-\n-As with every intellij project, `.idea\/modules.xml` 'points' to the iml files for each module (intellij's notion of module ;) )\n-```xml\n-<!--\n-   └──hat\n-       └── intellij\n-            └── .idea\n-                 └── modules.xml\n--->\n- <modules>\n-      <module fileurl=\"file:\/\/$PROJECT_DIR$\/hat.iml\"   \/>\n-      <module fileurl=\"file:\/\/$PROJECT_DIR$\/backend_opencl.iml\"  \/>\n-      <!-- yada yada -->\n- <\/modules>\n-\n-```\n-\n-The various `.iml` files then  have relative paths to their source\/resource dirs roots.\n-\n-```xml\n-<module type=\"JAVA_MODULE\" version=\"4\">\n-  <component name=\"NewModuleRootManager\" inherit-compiler-output=\"true\">\n-    <exclude-output \/>\n-    <content url=\"file:\/\/$MODULE_DIR$\/..\/..\/..\/hat\/src\/java\">\n-      <sourceFolder url=\"file:\/\/$MODULE_DIR$\/..\/..\/..\/hat\/src\/java\" isTestSource=\"false\" \/>\n-    <\/content>\n-    <orderEntry type=\"inheritedJdk\" \/>\n-    <orderEntry type=\"sourceFolder\" forTests=\"false\" \/>\n-    <orderEntry type=\"module\" module-name=\"hat\" \/>\n-  <\/component>\n-<\/module>\n-\n-```\n-### How intellij stores run configurations\n-\n-I also tend to hand hack run configurations so will leave this here for reference\n-\n-```xml\n-<component name=\"RunManager\" selected=\"Application.MandelTest\">\n-    <configuration name=\"Mandel\" type=\"Application\"\n-                   factoryName=\"Application\" temporary=\"true\"\n-                   nameIsGenerated=\"true\">\n-      <option name=\"MAIN_CLASS_NAME\" value=\"mandel.Mandel\" \/>\n-      <module name=\"mandel\" \/>\n-      <option name=\"VM_PARAMETERS\" value=\"\n-          --enable-preview\n-          --add-exports=java.base\/java.lang.reflect.code.descriptor.impl=ALL-UNNAMED\n-          --add-exports=java.base\/java.lang.foreign.mapper=ALL-UNNAMED\n-          --patch-module=java.base=$PROJECT_DIR$\/out\/production\/java_base_patch\n-          -Djava.lang.foreign.mapper.debug=true\" \/>\n-      <extension name=\"coverage\">\n-        <pattern>\n-          <option name=\"PATTERN\" value=\"mandel.*\" \/>\n-          <option name=\"ENABLED\" value=\"true\" \/>\n-        <\/pattern>\n-      <\/extension>\n-      <method v=\"2\">\n-        <option name=\"Make\" enabled=\"true\" \/>\n-      <\/method>\n-    <\/configuration>\n-    <!-- more configs -->\n-<\/component>\n-```\n-\n-\n-\n-\n-\n","filename":"hat\/docs\/maven.md","additions":0,"deletions":155,"binary":false,"changes":155,"status":"deleted"},{"patch":"@@ -1,148 +0,0 @@\n-# HAT Project Primer\n-\n-This is a fairly large project with Java and Native artifacts.\n-\n-We also rely on the `babylon` (JDK23+Babylon) project, and the project will initially be made available as a subproject\n-called `hat` under [github.com\/openjdk\/babylon](https:\/\/github.com\/openjdk\/babylon)\n-\n-## Intellij and Clion\n-\n-Whilst I do use JetBrains' `IntelliJ` and `Clion` for dev work and plan to leave project artifacts in the tree.\n-Care must be taken as these tools do not play well together, specifically we cannot have `Clion` and `Intellij`\n-project artifacts rooted under each other or in the same dir.\n-\n-I have `intellij` and `clion` siblings which will act as roots\n-for various tools and then use relative paths (or even symbolic links) in the various `.iml` files to locate the various source roots\n-\n-So far this has worked ok.\n-\n-### cmake\n-\n-I have never been a fan of maven especially for projects with native code. So I suggest using `cmake`\n-\n-```bash\n-cd hat\n-mkdir build\n-cd build\n-cmake ..\n-cd ..\n-cmake --build build --target <yourtarget>\n-```\n-\n-Who knows, one day Maven may prevail.\n-\n-### Initial Project Layout\n-\n-\n-```\n-${BABYLON_JDK}\n-   └── hat\n-        │\n-        ├── CMakeFile\n-        ├── build\n-        │\n-        ├── intellij\n-        │    ├── .idea\n-        │    │    ├── compiler.xml\n-        │    │    ├── misc.xml\n-        │    │    ├── modules.xml\n-        │    │    ├── uiDesigner.xml\n-        │    │    ├── vcs.xml\n-        │    │    └── workspace.xml\n-        │    │\n-        │    ├── hat.iml\n-        │    ├── backend_(spirv|mock|cuda|ptx|opencl).iml\n-        │    └── (mandel|violajones|experiments).iml\n-        │\n-        ├── hat\n-        │    └── src\n-        │         └── java\n-        │\n-        ├── backends\n-        │    └── (opencl|cuda|ptx|mock|shared)\n-        │          └── src\n-        │              ├── cpp\n-        │              ├── include\n-        │              ├── java\n-        │              └── services\n-        └── examples\n-             ├── mandel\n-             │    └── src\n-             │         └── java\n-             └── violajones\n-                  └── src\n-                       ├── java\n-                       └── resources\n-```\n-As you will note the `intellij` dir is somewhat self contained.  the various `*.iml`\n-files refer to the source dirs using relative paths.\n-\n-I tend to add `Intelli` modules by hand.  There are gotchas ;)\n-\n-As with every intellij project, `.idea\/modules.xml` 'points' to the iml files for each module (intellij's notion of module ;) )\n-```xml\n-<!--\n-   └──hat\n-       └── intellij\n-            └── .idea\n-                 └── modules.xml\n--->\n- <modules>\n-      <module fileurl=\"file:\/\/$PROJECT_DIR$\/hat.iml\"   \/>\n-      <module fileurl=\"file:\/\/$PROJECT_DIR$\/backend_opencl.iml\"  \/>\n-      <!-- yada yada -->\n- <\/modules>\n-\n-```\n-\n-The various `.iml` files then  have relative paths to their source\/resource dirs roots.\n-\n-```xml\n-<module type=\"JAVA_MODULE\" version=\"4\">\n-  <component name=\"NewModuleRootManager\" inherit-compiler-output=\"true\">\n-    <exclude-output \/>\n-    <content url=\"file:\/\/$MODULE_DIR$\/..\/..\/..\/hat\/src\/java\">\n-      <sourceFolder url=\"file:\/\/$MODULE_DIR$\/..\/..\/..\/hat\/src\/java\" isTestSource=\"false\" \/>\n-    <\/content>\n-    <orderEntry type=\"inheritedJdk\" \/>\n-    <orderEntry type=\"sourceFolder\" forTests=\"false\" \/>\n-    <orderEntry type=\"module\" module-name=\"hat\" \/>\n-  <\/component>\n-<\/module>\n-\n-```\n-### How intellij stores run configurations\n-\n-I also tend to hand hack run configurations so will leave this here for reference\n-\n-```xml\n-<component name=\"RunManager\" selected=\"Application.MandelTest\">\n-    <configuration name=\"Mandel\" type=\"Application\"\n-                   factoryName=\"Application\" temporary=\"true\"\n-                   nameIsGenerated=\"true\">\n-      <option name=\"MAIN_CLASS_NAME\" value=\"mandel.Mandel\" \/>\n-      <module name=\"mandel\" \/>\n-      <option name=\"VM_PARAMETERS\" value=\"\n-          --enable-preview\n-          --add-exports=java.base\/java.lang.reflect.code.descriptor.impl=ALL-UNNAMED\n-          --add-exports=java.base\/java.lang.foreign.mapper=ALL-UNNAMED\n-          --patch-module=java.base=$PROJECT_DIR$\/out\/production\/java_base_patch\n-          -Djava.lang.foreign.mapper.debug=true\" \/>\n-      <extension name=\"coverage\">\n-        <pattern>\n-          <option name=\"PATTERN\" value=\"mandel.*\" \/>\n-          <option name=\"ENABLED\" value=\"true\" \/>\n-        <\/pattern>\n-      <\/extension>\n-      <method v=\"2\">\n-        <option name=\"Make\" enabled=\"true\" \/>\n-      <\/method>\n-    <\/configuration>\n-    <!-- more configs -->\n-<\/component>\n-```\n-\n-\n-\n-\n-\n","filename":"hat\/docs\/project_layout.md","additions":0,"deletions":148,"binary":false,"changes":148,"status":"deleted"},{"patch":"@@ -102,1 +102,1 @@\n-    \/\/void featureCount(int featureCount);\n+    void featureCount(int featureCount);\n@@ -125,1 +125,1 @@\n-    \/\/ void stageCount(int stageCount);\n+     void stageCount(int stageCount);\n@@ -144,1 +144,1 @@\n-    \/\/   void treeCount(int treeCount);\n+       void treeCount(int treeCount);\n@@ -164,5 +164,0 @@\n-        BufferAllocator bufferAllocator = new BufferAllocator() {\n-            public <T extends Buffer> T allocate(SegmentMapper<T> s) {\n-                return s.allocate(Arena.global());\n-            }\n-        };\n@@ -170,3 +165,2 @@\n-        var cascadelayout = Cascade.schema.layout(10, 10, 10);\n-        System.out.println(cascadelayout);\n-        var cascade = Cascade.schema.allocate(bufferAllocator, 10, 10, 10);\n+        var cascade = Cascade.schema.allocate( 10, 10, 10);\n+        cascade.featureCount(10);\n","filename":"hat\/examples\/experiments\/src\/main\/java\/experiments\/Cascade.java","additions":5,"deletions":11,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -60,2 +60,0 @@\n-\n-\n","filename":"hat\/examples\/experiments\/src\/main\/java\/experiments\/LayoutExample.java","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -63,2 +63,2 @@\n-        GroupLayout layout = ResultTable.schema.layout(1000);\n-        System.out.println(layout);\n+        Schema.BoundLayout boundLayout = ResultTable.schema.collectLayouts(1000);\n+        System.out.println(boundLayout.groupLayout);\n","filename":"hat\/examples\/experiments\/src\/main\/java\/experiments\/ResultTable.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -29,4 +29,0 @@\n-import hat.buffer.BufferAllocator;\n-import hat.ifacemapper.SegmentMapper;\n-\n-import java.lang.foreign.Arena;\n@@ -36,0 +32,1 @@\n+    void length(int i);\n@@ -38,17 +35,2 @@\n-    Schema<S32Array> schema = Schema.of(S32Array.class, s32Array->s32Array.arrayLen(\"length\").array(\"array\"));\n-\n-    public static void main(String[] args) {\n-        BufferAllocator bufferAllocator = new BufferAllocator() {\n-            public <T extends Buffer> T allocate(SegmentMapper<T> s) {\n-                return s.allocate(Arena.global());\n-            }\n-        };\n-        hat.buffer.S32Array os32  = hat.buffer.S32Array.create(bufferAllocator,100);\n-        System.out.println(\"Layout from hat S32Array \"+ Buffer.getLayout(os32));\n-\n-        var s32Array = S32Array.schema.allocate(bufferAllocator, 100);\n-        Schema.BoundSchema boundSchema = (Schema.BoundSchema)Buffer.getHatData(s32Array);\n-        int s23ArrayLen = s32Array.length();\n-        System.out.println(\"Layout from schema \"+Buffer.getLayout(s32Array));\n-        ResultTable.schema.toText(t->System.out.print(t));\n-    }\n+    Schema<S32Array> schema = Schema.of(S32Array.class, s32Array->s32Array\n+            .arrayLen(\"length\").array(\"array\"));\n","filename":"hat\/examples\/experiments\/src\/main\/java\/experiments\/S32Array.java","additions":3,"deletions":21,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -0,0 +1,45 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+package experiments;\n+\n+import hat.Schema;\n+import hat.buffer.Buffer;\n+\n+public class S32ArrayTest implements Buffer {\n+\n+    public static void main(String[] args) {\n+        hat.buffer.S32Array os32  = hat.buffer.S32Array.create(Schema.GlobalArenaAllocator, 100);\n+        System.out.println(\"Layout from hat S32Array \"+ Buffer.getLayout(os32));\n+\n+        var s32Array = S32Array.schema.allocate( 100);\n+       \/\/ Schema.BoundSchema boundSchema = (Schema.BoundSchema)Buffer.getHatData(s32Array);\n+        int s23ArrayLen = s32Array.length();\n+        System.out.println(s23ArrayLen);\n+\n+        System.out.println(\"Layout from schema \"+Buffer.getLayout(s32Array));\n+        ResultTable.schema.toText(t->System.out.print(t));\n+    }\n+\n+}\n","filename":"hat\/examples\/experiments\/src\/main\/java\/experiments\/S32ArrayTest.java","additions":45,"deletions":0,"binary":false,"changes":45,"status":"added"},{"patch":"@@ -56,2 +56,2 @@\n-        var cascadelayout = Cascade.schema.layout(10,10,10);\n-        System.out.println(cascadelayout);\n+        var boundLayout = Cascade.schema.collectLayouts(10,10,10);\n+        System.out.println(boundLayout.groupLayout);\n","filename":"hat\/examples\/experiments\/src\/main\/java\/experiments\/SchemaLayoutTest.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -0,0 +1,470 @@\n+package experiments.ifaceinvoketoptr;\n+\n+\n+import java.lang.annotation.ElementType;\n+import java.lang.annotation.Retention;\n+import java.lang.annotation.RetentionPolicy;\n+import java.lang.annotation.Target;\n+import java.lang.constant.ClassDesc;\n+import java.lang.foreign.*;\n+import java.lang.invoke.MethodHandle;\n+import java.lang.invoke.MethodHandles;\n+import java.lang.reflect.Method;\n+import java.lang.reflect.code.*;\n+import java.lang.reflect.code.analysis.SSA;\n+import java.lang.reflect.code.op.CoreOp;\n+import java.lang.reflect.code.op.ExternalizableOp;\n+import java.lang.reflect.code.op.OpFactory;\n+import java.lang.reflect.code.type.FunctionType;\n+import java.lang.reflect.code.type.JavaType;\n+import java.lang.reflect.code.type.PrimitiveType;\n+import java.lang.runtime.CodeReflection;\n+import java.util.*;\n+import java.util.stream.Stream;\n+\n+public class InvokeToPtr {\n+\n+    \/*\n+    struct ColoredWeightedPoint{\n+       struct WeightedPoint{\n+         int x;\n+         int y;\n+         float weight;\n+       }\n+       struct WeightedPoint weightedPoint;\n+       int color;\n+     }\n+     *\/\n+    @Struct\n+    public interface ColoredWeightedPoint {\n+\n+        @Struct\n+        public interface WeightedPoint {\n+            int x();\n+            void x(int x);\n+            int y();\n+            void y(int y);\n+            float weight();\n+            void weight(float weight);\n+            static MemoryLayout layout() {\n+                return LAYOUT;\n+            }\n+            MemoryLayout LAYOUT = MemoryLayout.structLayout(\n+                    ValueLayout.JAVA_FLOAT.withName(\"weight\"),\n+                            ValueLayout.JAVA_INT.withName(\"x\"),\n+                      ValueLayout.JAVA_INT.withName(\"y\"))\n+                    .withName(WeightedPoint.class.getName());\n+        }\n+\n+        WeightedPoint weightedPoint();\n+        int color();\n+        void color(int v);\n+\n+        static MemoryLayout layout() {\n+            return LAYOUT;\n+        }\n+        MemoryLayout LAYOUT = MemoryLayout.structLayout(\n+                        WeightedPoint.layout().withName(WeightedPoint.class.getName() + \"::weightedPoint\"),\n+                        ValueLayout.JAVA_INT.withName(\"color\"))\n+                .withName(ColoredWeightedPoint.class.getName());\n+    }\n+\n+    @CodeReflection\n+    static float testMethod(ColoredWeightedPoint coloredWeightedPoint) {\n+        \/\/ StructOne* s1\n+        \/\/ s1 -> i\n+        int color = coloredWeightedPoint.color();\n+        \/\/ s1 -> *s2\n+        ColoredWeightedPoint.WeightedPoint weightedPoint = coloredWeightedPoint.weightedPoint();\n+        \/\/ s2 -> i\n+        color += weightedPoint.x();\n+        \/\/ s2 -> f\n+        float weight = weightedPoint.weight();\n+        return color + weight;\n+    }\n+\n+\n+    public static void main(String[] args) {\n+        CoreOp.FuncOp highLevelForm = getFuncOp(\"testMethod\");\n+\n+        System.out.println(\"Initial code model\");\n+        System.out.println(highLevelForm.toText());\n+        System.out.println(\"------------------\");\n+\n+        CoreOp.FuncOp ssaInvokeForm = SSA.transform(highLevelForm);\n+        System.out.println(\"SSA form which maintains original invokes and args\");\n+        System.out.println(ssaInvokeForm.toText());\n+        System.out.println(\"------------------\");\n+\n+        CoreOp.FuncOp ssaPtrForm = transformInvokesToPtrs(MethodHandles.lookup(), ssaInvokeForm);\n+        System.out.println(\"SSA form with invokes replaced by ptrs\");\n+        System.out.println(ssaPtrForm.toText());\n+    }\n+\n+    static CoreOp.FuncOp getFuncOp(String name) {\n+        Optional<Method> om = Stream.of(InvokeToPtr.class.getDeclaredMethods())\n+                .filter(m -> m.getName().equals(name))\n+                .findFirst();\n+\n+        Method m = om.get();\n+        return m.getCodeModel().get();\n+    }\n+\n+    \/\/\n+\n+    @Retention(RetentionPolicy.RUNTIME)\n+    @Target(ElementType.TYPE)\n+    public @interface Struct {\n+    }\n+\n+    static CoreOp.FuncOp transformInvokesToPtrs(MethodHandles.Lookup l,\n+                                                CoreOp.FuncOp f) {\n+        List<TypeElement> pTypes = new ArrayList<>();\n+        for (Block.Parameter p : f.parameters()) {\n+            pTypes.add(transformStructClassToPtr(l, p.type()));\n+        }\n+        FunctionType functionType = FunctionType.functionType(\n+                transformStructClassToPtr(l, f.invokableType().returnType()),\n+                pTypes);\n+        return CoreOp.func(f.funcName(), functionType).body(funcBlock -> {\n+            funcBlock.transformBody(f.body(), funcBlock.parameters(), (b, op) -> {\n+                if (op instanceof CoreOp.InvokeOp iop && iop.hasReceiver()) {\n+                    Value receiver = iop.operands().getFirst();\n+                    if (structClass(l, receiver.type()) instanceof Class<?> _) {\n+                        Value ptr = b.context().getValue(receiver);\n+                        PtrToMember ptrToMemberOp = new PtrToMember(ptr, iop.invokeDescriptor().name());\n+                        Op.Result memberPtr = b.op(ptrToMemberOp);\n+\n+                        if (iop.operands().size() == 1) {\n+                            \/\/ Pointer access and (possibly) value load\n+                            if (ptrToMemberOp.resultType().layout() instanceof ValueLayout) {\n+                                Op.Result v = b.op(new PtrLoadValue(memberPtr));\n+                                b.context().mapValue(iop.result(), v);\n+                            } else {\n+                                b.context().mapValue(iop.result(), memberPtr);\n+                            }\n+                        } else {\n+                            \/\/ @@@\n+                            \/\/ Value store\n+                            throw new UnsupportedOperationException();\n+                        }\n+                    } else {\n+                        b.op(op);\n+                    }\n+                } else {\n+                    b.op(op);\n+                }\n+                return b;\n+            });\n+        });\n+    };\n+\n+\n+    static TypeElement transformStructClassToPtr(MethodHandles.Lookup l, TypeElement type) {\n+        if (structClass(l, type) instanceof Class<?> sc) {\n+            return new PtrType(structClassLayout(l, sc));\n+        } else {\n+            return type;\n+        }\n+    }\n+\n+    static MemoryLayout structClassLayout(MethodHandles.Lookup l,\n+                                          Class<?> c) {\n+        if (!c.isAnnotationPresent(Struct.class)) {\n+            throw new IllegalArgumentException();\n+        }\n+\n+        Method layoutMethod;\n+        try {\n+            layoutMethod = c.getMethod(\"layout\");\n+        } catch (NoSuchMethodException e) {\n+            throw new RuntimeException(e);\n+        }\n+        MethodHandle layoutHandle;\n+        try {\n+            layoutHandle = l.unreflect(layoutMethod);\n+        } catch (IllegalAccessException e) {\n+            throw new RuntimeException(e);\n+        }\n+        try {\n+            return (MemoryLayout) layoutHandle.invoke();\n+        } catch (Throwable e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    static Class<?> structClass(MethodHandles.Lookup l, TypeElement t) {\n+        try {\n+            return _structClass(l, t);\n+        } catch (ReflectiveOperationException e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+    static Class<?> _structClass(MethodHandles.Lookup l, TypeElement t) throws ReflectiveOperationException {\n+        if (!(t instanceof JavaType jt) || !(jt.resolve(l) instanceof Class<?> c)) {\n+            return null;\n+        }\n+\n+        return c.isInterface() && c.isAnnotationPresent(Struct.class) ? c : null;\n+    }\n+\n+\n+    public static final class PtrType implements TypeElement {\n+        static final String NAME = \"ptr\";\n+        final MemoryLayout layout;\n+        final JavaType rType;\n+\n+        public PtrType(MemoryLayout layout) {\n+            this.layout = layout;\n+            this.rType = switch (layout) {\n+                case StructLayout _ -> JavaType.type(ClassDesc.of(layout.name().orElseThrow()));\n+                case AddressLayout _ -> throw new UnsupportedOperationException(\"Unsupported member layout: \" + layout);\n+                case ValueLayout valueLayout -> JavaType.type(valueLayout.carrier());\n+                default -> throw new UnsupportedOperationException(\"Unsupported member layout: \" + layout);\n+            };\n+        }\n+\n+        public JavaType rType() {\n+            return rType;\n+        }\n+\n+        public MemoryLayout layout() {\n+            return layout;\n+        }\n+\n+        @Override\n+        public boolean equals(Object o) {\n+            if (this == o) return true;\n+            if (o == null || getClass() != o.getClass()) return false;\n+            PtrType ptrType = (PtrType) o;\n+            return Objects.equals(layout, ptrType.layout);\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return Objects.hash(layout);\n+        }\n+\n+        @Override\n+        public ExternalizedTypeElement externalize() {\n+            return new ExternalizedTypeElement(NAME, List.of(rType.externalize()));\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return externalize().toString();\n+        }\n+    }\n+\n+    @OpFactory.OpDeclaration(PtrToMember.NAME)\n+    public static final class PtrToMember extends ExternalizableOp {\n+        public static final String NAME = \"ptr.to.member\";\n+        public static final String ATTRIBUTE_OFFSET = \"offset\";\n+        public static final String ATTRIBUTE_NAME = \"name\";\n+\n+        final String simpleMemberName;\n+        final long memberOffset;\n+        final PtrType resultType;\n+\n+        PtrToMember(PtrToMember that, CopyContext cc) {\n+            super(that, cc);\n+            this.simpleMemberName = that.simpleMemberName;\n+            this.memberOffset = that.memberOffset;\n+            this.resultType = that.resultType;\n+        }\n+\n+        @Override\n+        public PtrToMember transform(CopyContext cc, OpTransformer ot) {\n+            return new PtrToMember(this, cc);\n+        }\n+\n+        public PtrToMember(Value ptr, String simpleMemberName) {\n+            super(NAME, List.of(ptr));\n+            this.simpleMemberName = simpleMemberName;\n+\n+            if (!(ptr.type() instanceof PtrType ptrType)) {\n+                throw new IllegalArgumentException(\"Pointer value is not of pointer type: \" + ptr.type());\n+            }\n+            \/\/ @@@ Support group layout\n+            if (!(ptrType.layout() instanceof StructLayout structLayout)) {\n+                throw new IllegalArgumentException(\"Pointer type layout is not a struct layout: \" + ptrType.layout());\n+            }\n+\n+            \/\/ Find the actual member name from the simple member name\n+            String memberName = findMemberName(structLayout, simpleMemberName);\n+            MemoryLayout.PathElement p = MemoryLayout.PathElement.groupElement(memberName);\n+            this.memberOffset = structLayout.byteOffset(p);\n+            MemoryLayout memberLayout = structLayout.select(p);\n+            \/\/ Remove any simple member name from the layout\n+            MemoryLayout ptrLayout = memberLayout instanceof StructLayout\n+                    ? memberLayout.withName(className(memberName))\n+                    : memberLayout.withoutName();\n+            this.resultType = new PtrType(ptrLayout);\n+        }\n+\n+        \/\/ @@@ Change to return member index\n+        static String findMemberName(StructLayout sl, String simpleMemberName) {\n+            for (MemoryLayout layout : sl.memberLayouts()) {\n+                String memberName = layout.name().orElseThrow();\n+                if (simpleMemberName(memberName).equals(simpleMemberName)) {\n+                    return memberName;\n+                }\n+            }\n+            throw new NoSuchElementException(\"No member found: \" + simpleMemberName + \" \" + sl);\n+        }\n+\n+        static String simpleMemberName(String memberName) {\n+            int i = memberName.indexOf(\"::\");\n+            return i != -1\n+                    ? memberName.substring(i + 2)\n+                    : memberName;\n+        }\n+\n+        static String className(String memberName) {\n+            int i = memberName.indexOf(\"::\");\n+            return i != -1\n+                    ? memberName.substring(0, i)\n+                    : null;\n+        }\n+\n+        @Override\n+        public PtrType resultType() {\n+            return resultType;\n+        }\n+\n+        @Override\n+        public Map<String, Object> attributes() {\n+            HashMap<String, Object> attrs = new HashMap<>(super.attributes());\n+            attrs.put(\"\", simpleMemberName);\n+            attrs.put(ATTRIBUTE_OFFSET, memberOffset);\n+            return attrs;\n+        }\n+\n+        public String simpleMemberName() {\n+            return simpleMemberName;\n+        }\n+\n+        public long memberOffset() {\n+            return memberOffset;\n+        }\n+\n+        public Value ptrValue() {\n+            return operands().get(0);\n+        }\n+    }\n+\n+\n+    @OpFactory.OpDeclaration(PtrToMember.NAME)\n+    public static final class PtrAddOffset extends Op {\n+        public static final String NAME = \"ptr.add.offset\";\n+\n+        PtrAddOffset(PtrAddOffset that, CopyContext cc) {\n+            super(that, cc);\n+        }\n+\n+        @Override\n+        public PtrAddOffset transform(CopyContext cc, OpTransformer ot) {\n+            return new PtrAddOffset(this, cc);\n+        }\n+\n+        public PtrAddOffset(Value ptr, Value offset) {\n+            super(NAME, List.of(ptr, offset));\n+\n+            if (!(ptr.type() instanceof PtrType)) {\n+                throw new IllegalArgumentException(\"Pointer value is not of pointer type: \" + ptr.type());\n+            }\n+            if (!(offset.type() instanceof PrimitiveType pt && pt.equals(JavaType.LONG))) {\n+                throw new IllegalArgumentException(\"Offset value is not of primitve long type: \" + offset.type());\n+            }\n+        }\n+\n+        @Override\n+        public TypeElement resultType() {\n+            return ptrValue().type();\n+        }\n+\n+        public Value ptrValue() {\n+            return operands().get(0);\n+        }\n+\n+        public Value offsetValue() {\n+            return operands().get(1);\n+        }\n+    }\n+\n+    @OpFactory.OpDeclaration(PtrToMember.NAME)\n+    public static final class PtrLoadValue extends Op {\n+        public static final String NAME = \"ptr.load.value\";\n+\n+        final JavaType resultType;\n+\n+        PtrLoadValue(PtrLoadValue that, CopyContext cc) {\n+            super(that, cc);\n+            this.resultType = that.resultType;\n+        }\n+\n+        @Override\n+        public PtrLoadValue transform(CopyContext cc, OpTransformer ot) {\n+            return new PtrLoadValue(this, cc);\n+        }\n+\n+        public PtrLoadValue(Value ptr) {\n+            super(NAME, List.of(ptr));\n+\n+            if (!(ptr.type() instanceof PtrType ptrType)) {\n+                throw new IllegalArgumentException(\"Pointer value is not of pointer type: \" + ptr.type());\n+            }\n+            if (!(ptrType.layout() instanceof ValueLayout)) {\n+                throw new IllegalArgumentException(\"Pointer type layout is not a value layout: \" + ptrType.layout());\n+            }\n+            this.resultType = ptrType.rType();\n+        }\n+\n+        @Override\n+        public TypeElement resultType() {\n+            return resultType;\n+        }\n+\n+        public Value ptrValue() {\n+            return operands().get(0);\n+        }\n+    }\n+\n+    @OpFactory.OpDeclaration(PtrToMember.NAME)\n+    public static final class PtrStoreValue extends Op {\n+        public static final String NAME = \"ptr.store.value\";\n+\n+        PtrStoreValue(PtrStoreValue that, CopyContext cc) {\n+            super(that, cc);\n+        }\n+\n+        @Override\n+        public PtrStoreValue transform(CopyContext cc, OpTransformer ot) {\n+            return new PtrStoreValue(this, cc);\n+        }\n+\n+        public PtrStoreValue(Value ptr, Value v) {\n+            super(NAME, List.of(ptr));\n+\n+            if (!(ptr.type() instanceof PtrType ptrType)) {\n+                throw new IllegalArgumentException(\"Pointer value is not of pointer type: \" + ptr.type());\n+            }\n+            if (!(ptrType.layout() instanceof ValueLayout)) {\n+                throw new IllegalArgumentException(\"Pointer type layout is not a value layout: \" + ptrType.layout());\n+            }\n+            if (!(ptrType.rType().equals(v.type()))) {\n+                throw new IllegalArgumentException(\"Pointer reference type is not same as value to store type: \"\n+                        + ptrType.rType() + \" \" + v.type());\n+            }\n+        }\n+\n+        @Override\n+        public TypeElement resultType() {\n+            return JavaType.VOID;\n+        }\n+\n+        public Value ptrValue() {\n+            return operands().get(0);\n+        }\n+    }\n+}\n","filename":"hat\/examples\/experiments\/src\/main\/java\/experiments\/ifaceinvoketoptr\/InvokeToPtr.java","additions":470,"deletions":0,"binary":false,"changes":470,"status":"added"},{"patch":"@@ -38,1 +38,1 @@\n-    public static int sq(int v) {\n+    public static int square(int v) {\n@@ -47,1 +47,1 @@\n-           s32Array.array(kc.x, sq(value));  \/\/ arr[cc.x]=value*value\n+           s32Array.array(kc.x, square(value));  \/\/ arr[cc.x]=value*value\n","filename":"hat\/examples\/squares\/src\/main\/java\/squares\/Squares.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -8,0 +8,1 @@\n+import java.lang.foreign.Arena;\n@@ -33,0 +34,14 @@\n+    public final static BufferAllocator GlobalArenaAllocator = new BufferAllocator() {\n+        public <T extends Buffer> T allocate(SegmentMapper<T> s) {\n+            return s.allocate(Arena.global());\n+        }\n+    };\n+    static class ArraySizeBinding{\n+        int idx;\n+        int len;\n+        AbstractField.FieldControlledArray fieldControlledArray;\n+        ArraySizeBinding(int idx, int len) {\n+            this.idx = idx;\n+            this.len = len;\n+        }\n+    }\n@@ -34,0 +49,10 @@\n+    public static class BoundLayout<T extends Buffer>{\n+        Schema<T> schema;\n+        List<ArraySizeBinding> arraySizeBindings ;\n+       public  GroupLayout groupLayout;\n+        BoundLayout(Schema<T> schema, List<ArraySizeBinding> arraySizeBindings, GroupLayout groupLayout) {\n+            this.schema = schema;\n+            this.arraySizeBindings = arraySizeBindings;\n+            this.groupLayout = groupLayout;\n+        }\n+    }\n@@ -36,2 +61,1 @@\n-        private int[] arrayLengths;\n-        private List<AbstractField.FieldControlledArray> bound = new ArrayList<>();\n+        private List<ArraySizeBinding> arraySizeBindings = new ArrayList<>();\n@@ -39,2 +63,4 @@\n-        LayoutCollector(int[] arrayLength){\n-            this.arrayLengths = arrayLength;\n+        LayoutCollector(int[] arrayLengths){\n+            for(int i=0; i<arrayLengths.length; i++){\n+                arraySizeBindings.add(new ArraySizeBinding(i, arrayLengths[i]));\n+            }\n@@ -55,5 +81,2 @@\n-        int getIdx(){\n-            return arrayLengths[idx++];\n-        }\n-        void add(AbstractField.FieldControlledArray boundArray){\n-            bound.add(boundArray);\n+        ArraySizeBinding getIdx(){\n+            return arraySizeBindings.get(idx++);\n@@ -66,1 +89,1 @@\n-    public LayoutCollector collectLayouts(int... arrayLengths) {\n+    public BoundLayout<T> collectLayouts(int... arrayLengths) {\n@@ -71,4 +94,1 @@\n-        return layoutCollector;\n-    }\n-    public GroupLayout layout(int... arrayLengths) {\n-        return collectLayouts(arrayLengths).groupLayout.withName(iface.getSimpleName());\n+        return new BoundLayout<T>(this,layoutCollector.arraySizeBindings, layoutCollector.groupLayout.withName(iface.getSimpleName()));\n@@ -77,0 +97,1 @@\n+\n@@ -644,1 +665,2 @@\n-                SequenceLayout sequenceLayout = MemoryLayout.sequenceLayout(layoutCollector.getIdx(), elementLayout).withName(elementAccessStyle.name);\n+                var arraySizeBinding = layoutCollector.getIdx();\n+                SequenceLayout sequenceLayout = MemoryLayout.sequenceLayout(arraySizeBinding.idx, elementLayout).withName(elementAccessStyle.name);\n@@ -646,1 +668,1 @@\n-                layoutCollector.add(this);\n+                arraySizeBinding.fieldControlledArray=this;\n@@ -658,5 +680,0 @@\n-    public static class BoundSchema<T extends Buffer> implements HatData {\n-        public Schema<T> schema;\n-        public GroupLayout layout;\n-        int[] boundLengths;\n-\n@@ -664,7 +681,0 @@\n-        BoundSchema(Schema<T> schema, GroupLayout layout, int[] boundLengths) {\n-\n-            this.schema = schema;\n-            this.layout = layout;\n-            this.boundLengths = boundLengths;\n-        }\n-    }\n@@ -673,4 +683,2 @@\n-        var layout = layout(boundLengths);\n-\n-        var boundSchema = new BoundSchema<T>( this, layout, boundLengths);\n-        var segmentMapper = SegmentMapper.of(MethodHandles.lookup(),iface, layout, boundSchema);\n+        var boundLayout = collectLayouts(boundLengths);\n+        var segmentMapper = SegmentMapper.of(MethodHandles.lookup(),iface, boundLayout.groupLayout);\n@@ -680,0 +688,3 @@\n+    public T allocate( int... boundLengths) {\n+        return allocate(GlobalArenaAllocator, boundLengths);\n+    }\n","filename":"hat\/hat\/src\/main\/java\/hat\/Schema.java","additions":43,"deletions":32,"binary":false,"changes":75,"status":"modified"},{"patch":"@@ -3,1 +3,1 @@\n-  <component name=\"ProjectRootManager\" version=\"2\" languageLevel=\"JDK_X\" project-jdk-name=\"23-babylon\" project-jdk-type=\"JavaSDK\">\n+  <component name=\"ProjectRootManager\" version=\"2\" languageLevel=\"JDK_X\" project-jdk-name=\"24-ea\" project-jdk-type=\"JavaSDK\">\n","filename":"hat\/intellij\/.idea\/misc.xml","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -10,0 +10,1 @@\n+    <content url=\"file:\/\/$MODULE_DIR$\/..\/docs\" \/>\n@@ -28,1 +29,1 @@\n-<\/module>\n\\ No newline at end of file\n+<\/module>\n","filename":"hat\/intellij\/hat.iml","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"}]}