{"files":[{"patch":"@@ -16,0 +16,1 @@\n+\n@@ -21,0 +22,1 @@\n+\n@@ -26,0 +28,1 @@\n+\n@@ -31,0 +34,1 @@\n+\n@@ -36,0 +40,1 @@\n+\n@@ -41,0 +46,1 @@\n+\n","filename":"hat\/backends\/CMakeLists.txt","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -52,1 +52,1 @@\n-        COMMAND echo cp ${CMAKE_BINARY_DIR}\/cuda\/libcuda_backend.* ${CMAKE_SOURCE_DIR}\/..\/maven-build\n+        COMMAND cp ${CMAKE_BINARY_DIR}\/cuda\/libcuda_backend.* ${CMAKE_SOURCE_DIR}\/..\/maven-build\n","filename":"hat\/backends\/cuda\/CMakeLists.txt","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-project(opencl_backend)\n+project(ptx_backend)\n@@ -6,4 +6,50 @@\n-find_package(OpenCL)\n-if (\"${PTX_BACKEND}EMPTY\" STREQUAL \"EMPTY\")\n-    set (PTX_BACKEND \"${CMAKE_SOURCE_DIR}\")\n-    message(\"PTX_BACKEND=${PTX_BACKEND}\")\n+find_package(CUDAToolkit)\n+if(CUDAToolkit_FOUND)\n+    message(\"PTX\")\n+    if (\"${PTX_BACKEND}EMPTY\" STREQUAL \"EMPTY\")\n+\t    set (PTX_BACKEND \"${CMAKE_SOURCE_DIR}\")\n+\t    message(\"PTX_BACKEND=${PTX_BACKEND}\")\n+    endif()\n+    if (\"${SHARED_BACKEND}EMPTY\" STREQUAL \"EMPTY\")\n+        set (SHARED_BACKEND \"${CMAKE_SOURCE_DIR}\/..\/shared\")\n+        message(\"SHARED_BACKEND=${SHARED_BACKEND}\")\n+    endif()\n+\n+\n+    include_directories(\n+            ${CUDAToolkit_INCLUDE_DIR}\n+\t    ${SHARED_BACKEND}\/include\n+\t    ${PTX_BACKEND}\/include\n+    )\n+\n+    link_directories(\n+            ${CMAKE_BINARY_DIR}\n+            ${CUDAToolkit_LIBRARY_DIR}\n+    )\n+\n+    add_library(ptx_backend SHARED\n+\t    ${SHARED_BACKEND}\/cpp\/shared.cpp\n+\t    ${PTX_BACKEND}\/cpp\/ptx_backend.cpp\n+    )\n+\n+    target_link_libraries(ptx_backend\n+            -lcudart\n+            -lcuda\n+    )\n+\n+    add_executable(ptx_info\n+\t    ${PTX_BACKEND}\/cpp\/info.cpp\n+    )\n+\n+    target_link_libraries(ptx_info\n+            ptx_backend\n+            -lcudart\n+            -lcuda\n+    )\n+    add_custom_target(ptx_natives DEPENDS ptx_info ptx_backend)\n+\n+    add_custom_target(copy_ptx_libs DEPENDS ptx_info ptx_backend\n+        COMMAND cp ${CMAKE_BINARY_DIR}\/ptx\/libptx_backend.* ${CMAKE_SOURCE_DIR}\/..\/maven-build\n+        COMMAND cp ${CMAKE_BINARY_DIR}\/ptx\/ptx_info ${CMAKE_SOURCE_DIR}\/..\/maven-build\n+    ) \n+    add_dependencies(copy_libs copy_ptx_libs)\n@@ -11,31 +57,0 @@\n-if (\"${SHARED_BACKEND}EMPTY\" STREQUAL \"EMPTY\")\n-    set (SHARED_BACKEND \"${CMAKE_SOURCE_DIR}\/..\/shared\")\n-    message(\"SHARED_BACKEND=${SHARED_BACKEND}\")\n-endif()\n-\n-\n-message(\"PTX\")\n-\n-include_directories(\n-    ${PTX_BACKEND}\/include\n-    ${SHARED_BACKEND}\/include\n-    ${PTX_INCLUDE_DIR}\n-)\n-link_directories(\n-    ${CMAKE_BINARY_DIR}\n-)\n-\n-add_library(ptx_backend SHARED\n-    ${SHARED_BACKEND}\/cpp\/shared.cpp\n-    ${PTX_BACKEND}\/cpp\/ptx_backend.cpp\n-)\n-\n-\n-add_executable(ptx_info\n-    ${PTX_BACKEND}\/cpp\/info.cpp\n-)\n-\n-target_link_libraries(ptx_info\n-    ptx_backend\n-)\n-add_custom_target(ptx_natives DEPENDS ptx_info ptx_backend)\n@@ -43,5 +58,0 @@\n-add_custom_target(copy_ptx_libs DEPENDS ptx_info ptx_backend\n-    COMMAND cp ${CMAKE_BINARY_DIR}\/ptx\/libptx_backend.* ${CMAKE_SOURCE_DIR}\/..\/maven-build\n-    COMMAND cp ${CMAKE_BINARY_DIR}\/ptx\/ptx_info ${CMAKE_SOURCE_DIR}\/..\/maven-build\n-)\n-add_dependencies(copy_libs copy_ptx_libs)\n","filename":"hat\/backends\/ptx\/CMakeLists.txt","additions":51,"deletions":41,"binary":false,"changes":92,"status":"modified"},{"patch":"@@ -25,1 +25,0 @@\n-#include \"shared.h\"\n@@ -27,2 +26,5 @@\n-int main() {\n-    std::cout << \"inside PTX info\" << std::endl;\n+#include \"ptx_backend.h\"\n+\n+int main(int argc, char **argv) {\n+    PtxBackend ptxBackend;\n+    ptxBackend.info();\n","filename":"hat\/backends\/ptx\/cpp\/info.cpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -26,14 +26,4 @@\n-#include \"shared.h\"\n-\n-class PTXBackend : public Backend {\n-public:\n-    class PTXConfig : public Backend::Config {\n-    public :\n-    };\n-\n-    class PTXProgram : public Backend::Program {\n-        class PTXKernel : public Backend::Program::Kernel {\n-        public:\n-            PTXKernel(Backend::Program *program, char * name)\n-                    : Backend::Program::Kernel(program, name) {\n-            }\n+#include <sys\/wait.h>\n+#include <chrono>\n+#include <cuda_runtime_api.h>\n+#include \"ptx_backend.h\"\n@@ -41,2 +31,11 @@\n-            ~PTXKernel() {\n-            }\n+Ptx::Ptx(size_t len)\n+        : len(len), text(len > 0 ? new char[len] : nullptr) {\n+    std::cout << \"in Ptx with buffer allocated \"<<len << std::endl;\n+}\n+\n+Ptx::~Ptx() {\n+    if (len > 0 && text != nullptr) {\n+        std::cout << \"in ~Ptx with deleting allocated \"<<len << std::endl;\n+        delete[] text;\n+    }\n+}\n@@ -44,3 +43,61 @@\n-            long ndrange(void *argArray) {\n-                std::cout << \"ptx ndrange() \" << std::endl;\n-                return 0;\n+uint64_t timeSinceEpochMillisec() {\n+    using namespace std::chrono;\n+    return duration_cast<milliseconds>(system_clock::now().time_since_epoch()).count();\n+}\n+\n+Ptx *Ptx::nvcc(const char *ptxSource, size_t len) {\n+    Ptx *ptx = nullptr;\n+    uint64_t time = timeSinceEpochMillisec();\n+    std::stringstream timestampPtx;\n+    timestampPtx << \".\/tmp\" << time << \".ptx\";\n+    const char *ptxPath = strdup(timestampPtx.str().c_str());\n+   \/\/ std::cout << \"ptx \" << ptxPath << std::endl;\n+    \/\/ we are going to fork exec nvcc\n+    int pid;\n+    if ((pid = fork()) == 0) {\n+        std::ofstream ptx;\n+        std::stringstream timestampPtx;\n+        timestampPtx << \".\/tmp\" << time << \".cu\";\n+        const char *ptxPath = strdup(timestampPtx.str().c_str());\n+        std::cout << \"ptx \" << ptxPath << std::endl;\n+        ptx.open(ptxPath, std::ofstream::trunc);\n+        ptx.write(ptxSource, len);\n+        ptx.close();\n+        const char *path = \"\/usr\/bin\/nvcc\";\n+        \/\/const char *path = \"\/usr\/local\/cuda-12.2\/bin\/nvcc\";\n+        const char *argv[]{\"nvcc\", \"-ptx\", ptxPath, \"-o\", ptxPath, nullptr};\n+        \/\/ we can't free ptxPath or ptxpath in child because we need them in exec, no prob through\n+        \/\/ because we get a new proc so they are released to os\n+        execvp(path, (char *const *) argv);\n+\n+    } else if (pid < 0) {\n+        \/\/ fork failed.\n+        std::cerr << \"fork of nvcc failed\" << std::endl;\n+        std::exit(1);\n+    } else {\n+        int status;\n+     \/\/   std::cerr << \"fork suceeded waiting for child\" << std::endl;\n+        pid_t result = wait(&status);\n+        std::cerr << \"child finished\" << std::endl;\n+        std::ifstream ptxStream;\n+        ptxStream.open(ptxPath);\n+      \/\/  if (ptxStream.is_open()) {\n+            ptxStream.seekg(0, std::ios::end);\n+            size_t ptxLen = ptxStream.tellg();\n+            ptxStream.close();\n+            ptxStream.open(ptxPath);\n+            free((void *) ptxPath);\n+            ptxPath = nullptr;\n+            if (ptxLen > 0) {\n+                std::cerr << \"ptx len \"<< ptxLen << std::endl;\n+                ptx = new Ptx(ptxLen + 1);\n+                std::cerr << \"about to read  \"<< ptx->len << std::endl;\n+                ptxStream.read(ptx->text, ptx->len);\n+                ptxStream.close();\n+                std::cerr << \"about to read  \"<< ptx->len << std::endl;\n+                ptx->text[ptx->len - 1] = '\\0';\n+                std::cerr << \"read text \"<< ptx->text << std::endl;\n+\n+            } else {\n+                std::cerr << \"no ptx! ptxLen == 0?\";\n+                exit(1);\n@@ -48,1 +105,8 @@\n-        };\n+      \/\/  }else{\n+        \/\/    std::cerr << \"no ptx!\";\n+       \/\/     exit(1);\n+      \/\/  }\n+    }\n+    std::cout << \"returning PTX\" << std::endl;\n+    return ptx;\n+}\n@@ -50,4 +114,20 @@\n-    public:\n-        PTXProgram(Backend *backend, BuildInfo *buildInfo)\n-                : Backend::Program(backend, buildInfo) {\n-        }\n+\/*\n+\/\/http:\/\/mercury.pr.erau.edu\/~siewerts\/extra\/code\/digital-media\/CUDA\/cuda_work\/samples\/0_Simple\/matrixMulDrv\/matrixMulDrv.cpp\n+ *\/\n+PtxBackend::PtxProgram::PtxKernel::PtxBuffer::PtxBuffer(Backend::Program::Kernel *kernel, Arg_s *arg)\n+        : Buffer(kernel, arg), devicePtr() {\n+    \/*\n+     *   (void *) arg->value.buffer.memorySegment,\n+     *   (size_t) arg->value.buffer.sizeInBytes);\n+     *\/\n+  \/\/  std::cout << \"cuMemAlloc()\" << std::endl;\n+    CUresult status = cuMemAlloc(&devicePtr, (size_t) arg->value.buffer.sizeInBytes);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuMemFree() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+  \/\/  std::cout << \"devptr \" << std::hex<<  (long)devicePtr <<std::dec <<std::endl;\n+    arg->value.buffer.vendorPtr = static_cast<void *>(this);\n+}\n@@ -55,2 +135,1 @@\n-        ~PTXProgram() {\n-        }\n+PtxBackend::PtxProgram::PtxKernel::PtxBuffer::~PtxBuffer() {\n@@ -58,3 +137,22 @@\n-        long getKernel(int nameLen, char *name) {\n-            return (long) new PTXKernel(this, name);\n-        }\n+ \/\/   std::cout << \"cuMemFree()\"\n+  \/\/          << \"devptr \" << std::hex<<  (long)devicePtr <<std::dec\n+   \/\/         << std::endl;\n+    CUresult  status = cuMemFree(devicePtr);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuMemFree() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+    arg->value.buffer.vendorPtr = nullptr;\n+}\n+\n+void PtxBackend::PtxProgram::PtxKernel::PtxBuffer::copyToDevice() {\n+    auto ptxKernel = dynamic_cast<PtxKernel*>(kernel);\n+ \/\/   std::cout << \"copyToDevice() 0x\"   << std::hex<<arg->value.buffer.sizeInBytes<<std::dec << \" \"<< arg->value.buffer.sizeInBytes << \" \"\n+ \/\/             << \"devptr \" << std::hex<<  (long)devicePtr <<std::dec\n+ \/\/             << std::endl;\n+    char *ptr = (char*)arg->value.buffer.memorySegment;\n+\n+    unsigned long ifacefacade1 = *reinterpret_cast<unsigned long*>(ptr+arg->value.buffer.sizeInBytes-16);\n+    unsigned long ifacefacade2 = *reinterpret_cast<unsigned long*>(ptr+arg->value.buffer.sizeInBytes-8);\n@@ -62,2 +160,104 @@\n-        bool programOK() {\n-            return true;\n+    if (ifacefacade1 != 0x1face00000facadeL && ifacefacade1 != ifacefacade2) {\n+        std::cerr<<\"End of buf marker before HtoD\"<< std::hex << ifacefacade1 << ifacefacade2<< \" buffer corrupt !\" <<std::endl\n+                <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+\n+\n+    CUresult status = cuMemcpyHtoDAsync(devicePtr, arg->value.buffer.memorySegment, arg->value.buffer.sizeInBytes,ptxKernel->cudaStream);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuMemcpyHtoDAsync() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+    status = static_cast<CUresult >(cudaStreamSynchronize(ptxKernel->cudaStream));\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+}\n+\n+void PtxBackend::PtxProgram::PtxKernel::PtxBuffer::copyFromDevice() {\n+    auto ptxKernel = dynamic_cast<PtxKernel*>(kernel);\n+ \/\/   std::cout << \"copyFromDevice() 0x\" << std::hex<<arg->value.buffer.sizeInBytes<<std::dec << \" \"<< arg->value.buffer.sizeInBytes << \" \"\n+ \/\/             << \"devptr \" << std::hex<<  (long)devicePtr <<std::dec\n+  \/\/            << std::endl;\n+    char *ptr = (char*)arg->value.buffer.memorySegment;\n+\n+    unsigned long ifacefacade1 = *reinterpret_cast<unsigned long*>(ptr+arg->value.buffer.sizeInBytes-16);\n+    unsigned long ifacefacade2 = *reinterpret_cast<unsigned long*>(ptr+arg->value.buffer.sizeInBytes-8);\n+\n+    if (ifacefacade1 != 0x1face00000facadeL || ifacefacade1 != ifacefacade2) {\n+        std::cerr<<\"end of buf marker before  DtoH\"<< std::hex << ifacefacade1 << ifacefacade2<< std::dec<< \" buffer corrupt !\"<<std::endl\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+    CUresult status =cuMemcpyDtoHAsync(arg->value.buffer.memorySegment, devicePtr, arg->value.buffer.sizeInBytes,ptxKernel->cudaStream);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+    cudaError_t t1 = cudaStreamSynchronize(ptxKernel->cudaStream);\n+    if (static_cast<cudaError_t>(CUDA_SUCCESS) != t1) {\n+        std::cerr << \"CUDA error = \" << t1\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(t1))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+    ifacefacade1 = *reinterpret_cast<unsigned long*>(ptr+arg->value.buffer.sizeInBytes-16);\n+    ifacefacade2 = *reinterpret_cast<unsigned long*>(ptr+arg->value.buffer.sizeInBytes-8);\n+\n+    if (ifacefacade1 != 0x1face00000facadeL || ifacefacade1 != ifacefacade2) {\n+        std::cerr<<\"end of buf marker after  DtoH\"<< std::hex << ifacefacade1 << ifacefacade2<< std::dec<< \" buffer corrupt !\"<<std::endl\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+}\n+\n+PtxBackend::PtxProgram::PtxKernel::PtxKernel(Backend::Program *program,char * name, CUfunction function)\n+        : Backend::Program::Kernel(program, name), function(function),cudaStream() {\n+}\n+\n+PtxBackend::PtxProgram::PtxKernel::~PtxKernel() = default;\n+\n+long PtxBackend::PtxProgram::PtxKernel::ndrange(void *argArray) {\n+  \/\/  std::cout << \"ndrange(\" << range << \") \" << name << std::endl;\n+\n+    cudaStreamCreate(&cudaStream);\n+    ArgSled argSled(static_cast<ArgArray_s *>(argArray));\n+ \/\/   Schema::dumpSled(std::cout, argArray);\n+    void *argslist[argSled.argc()];\n+    NDRange *ndrange = nullptr;\n+#ifdef VERBOSE\n+    std::cerr << \"there are \" << argSled.argc() << \"args \" << std::endl;\n+#endif\n+    for (int i = 0; i < argSled.argc(); i++) {\n+        Arg_s *arg = argSled.arg(i);\n+        switch (arg->variant) {\n+            case '&': {\n+                if (arg->idx == 0){\n+                    ndrange = static_cast<NDRange *>(arg->value.buffer.memorySegment);\n+                }\n+                auto ptxBuffer = new PtxBuffer(this, arg);\n+                ptxBuffer->copyToDevice();\n+                argslist[arg->idx] = static_cast<void *>(&ptxBuffer->devicePtr);\n+                break;\n+            }\n+            case 'I':\n+            case 'F':\n+            case 'J':\n+            case 'D':\n+            case 'C':\n+            case 'S': {\n+                argslist[arg->idx] = static_cast<void *>(&arg->value);\n+                break;\n+            }\n+            default: {\n+                std::cerr << \" unhandled variant \" << (char) arg->variant << std::endl;\n+                break;\n+            }\n@@ -65,1 +265,40 @@\n-    };\n+    }\n+\n+    int range = ndrange->maxX;\n+    int rangediv1024 = range \/ 1024;\n+    int rangemod1024 = range % 1024;\n+    if (rangemod1024 > 0) {\n+        rangediv1024++;\n+    }\n+   \/\/ std::cout << \"Running the kernel...\" << std::endl;\n+  \/\/  std::cout << \"   Requested range   = \" << range << std::endl;\n+  \/\/  std::cout << \"   Range mod 1024    = \" << rangemod1024 << std::endl;\n+   \/\/ std::cout << \"   Actual range 1024 = \" << (rangediv1024 * 1024) << std::endl;\n+    auto status= static_cast<CUresult>(cudaStreamSynchronize(cudaStream));\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+\n+    status= cuLaunchKernel(function,\n+                                   rangediv1024, 1, 1,\n+                                   1024, 1, 1,\n+                                   0, cudaStream,\n+                    argslist, 0);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuLaunchKernel() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+    status= static_cast<CUresult>(cudaStreamSynchronize(cudaStream));\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+\n+    \/\/std::cout << \"Kernel complete...\"<<cudaGetErrorString(t)<<std::endl;\n@@ -67,1 +306,4 @@\n-public:\n+    for (int i = 0; i < argSled.argc(); i++) {\n+        Arg_s *arg = argSled.arg(i);\n+        if (arg->variant == '&') {\n+            static_cast<PtxBuffer *>(arg->value.buffer.vendorPtr)->copyFromDevice();\n@@ -69,6 +311,0 @@\n-    PTXBackend(PTXConfig *ptxConfig, int ptxConfigSchemeLen, char *ptxBackendSchema)\n-            : Backend(ptxConfig, ptxConfigSchemeLen, ptxBackendSchema) {\n-        if (ptxConfig == nullptr) {\n-            std::cout << \"ptxConfig == null\" << std::endl;\n-        } else {\n-            std::cout << \"ptxConfig != null\" << std::endl;\n@@ -77,0 +313,7 @@\n+    status=   static_cast<CUresult>(cudaStreamSynchronize(cudaStream));\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n@@ -78,1 +321,6 @@\n-    ~PTXBackend() {\n+    for (int i = 0; i < argSled.argc(); i++) {\n+        Arg_s *arg = argSled.arg(i);\n+        if (arg->variant == '&') {\n+            delete static_cast<PtxBuffer *>(arg->value.buffer.vendorPtr);\n+            arg->value.buffer.vendorPtr = nullptr;\n+        }\n@@ -80,0 +328,3 @@\n+    cudaStreamDestroy(cudaStream);\n+    return (long) 0;\n+}\n@@ -81,3 +332,15 @@\n-    int getMaxComputeUnits() {\n-        std::cout << \"ptx getMaxComputeUnits()\" << std::endl;\n-        return 0;\n+\n+PtxBackend::PtxProgram::PtxProgram(Backend *backend, BuildInfo *buildInfo, Ptx *ptx, CUmodule module)\n+        : Backend::Program(backend, buildInfo), ptx(ptx), module(module) {\n+}\n+\n+PtxBackend::PtxProgram::~PtxProgram() = default;\n+\n+long PtxBackend::PtxProgram::getKernel(int nameLen, char *name) {\n+    CUfunction function;\n+    CUresult status= cuModuleGetFunction(&function, module, name);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuModuleGetFunction() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n@@ -85,0 +348,3 @@\n+    long kernelHandle =  reinterpret_cast<long>(new PtxKernel(this, name, function));\n+    return kernelHandle;\n+}\n@@ -86,2 +352,22 @@\n-    void info() {\n-        std::cout << \"ptx info()\" << std::endl;\n+bool PtxBackend::PtxProgram::programOK() {\n+    return true;\n+}\n+\n+PtxBackend::PtxBackend(PtxBackend::PtxConfig *ptxConfig, int\n+configSchemaLen, char *configSchema)\n+        : Backend((Backend::Config*) ptxConfig, configSchemaLen, configSchema), device(),context()  {\n+  \/\/  std::cout << \"PtxBackend constructor \" << ((ptxConfig == nullptr) ? \"ptxConfig== null\" : \"got ptxConfig\")\n+    \/\/          << std::endl;\n+    int deviceCount = 0;\n+    CUresult err = cuInit(0);\n+    if (err == CUDA_SUCCESS) {\n+        cuDeviceGetCount(&deviceCount);\n+        std::cout << \"PtxBackend device count\" << std::endl;\n+        cuDeviceGet(&device, 0);\n+        std::cout << \"PtxBackend device ok\" << std::endl;\n+        cuCtxCreate(&context, 0, device);\n+        std::cout << \"PtxBackend context created ok\" << std::endl;\n+    } else {\n+        std::cout << \"PtxBackend failed, we seem to have the runtime library but no device, no context, nada \"\n+                  << std::endl;\n+        exit(1);\n@@ -89,0 +375,5 @@\n+}\n+\n+PtxBackend::PtxBackend() : PtxBackend(nullptr, 0, nullptr) {\n+\n+}\n@@ -90,8 +381,8 @@\n-    long compileProgram(int len, char *source) {\n-        std::cout << \"ptx compileProgram()\" << std::endl;\n-        size_t srcLen = ::strlen(source);\n-        char *src = new char[srcLen + 1];\n-        ::strncpy(src, source, srcLen);\n-        src[srcLen] = '\\0';\n-        std::cout << \"native compiling \" << src << std::endl;\n-        return (long) new PTXProgram(this, new BuildInfo(src, nullptr, false));\n+PtxBackend::~PtxBackend() {\n+    std::cout << \"freeing context\" << std::endl;\n+    CUresult status = cuCtxDestroy(context);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuCtxDestroy(() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n@@ -99,1 +390,72 @@\n-};\n+}\n+\n+int PtxBackend::getMaxComputeUnits() {\n+    std::cout << \"getMaxComputeUnits()\" << std::endl;\n+    int value = 1;\n+    return value;\n+}\n+\n+void PtxBackend::info() {\n+    char name[100];\n+    cuDeviceGetName(name, sizeof(name), device);\n+    std::cout << \"> Using device 0: \" << name << std::endl;\n+\n+    \/\/ get compute capabilities and the devicename\n+    int major = 0, minor = 0;\n+    cuDeviceGetAttribute(&major, CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MAJOR, device);\n+    cuDeviceGetAttribute(&minor, CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MINOR, device);\n+    std::cout << \"> GPU Device has major=\" << major << \" minor=\" << minor << \" compute capability\" << std::endl;\n+\n+    int warpSize;\n+    cuDeviceGetAttribute(&warpSize, CU_DEVICE_ATTRIBUTE_WARP_SIZE, device);\n+    std::cout << \"> GPU Device has warpSize \" << warpSize << std::endl;\n+\n+    int threadsPerBlock;\n+    cuDeviceGetAttribute(&threadsPerBlock, CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK, device);\n+    std::cout << \"> GPU Device has threadsPerBlock \" << threadsPerBlock << std::endl;\n+\n+    int cores;\n+    cuDeviceGetAttribute(&cores, CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT, device);\n+    std::cout << \"> GPU Cores \" << cores << std::endl;\n+\n+    size_t totalGlobalMem;\n+    cuDeviceTotalMem(&totalGlobalMem, device);\n+    std::cout << \"  Total amount of global memory:   \" << (unsigned long long) totalGlobalMem << std::endl;\n+    std::cout << \"  64-bit Memory Address:           \" <<\n+              ((totalGlobalMem > (unsigned long long) 4 * 1024 * 1024 * 1024L) ? \"YES\" : \"NO\") << std::endl;\n+\n+}\n+\n+long PtxBackend::compileProgram(int len, char *source) {\n+    Ptx *ptx = Ptx::nvcc(source, len);\n+    CUmodule module;\n+    std::cout << \"inside compileProgram\" << std::endl;\n+    std::cout << \"ptx \" << source << std::endl;\n+    if (ptx->text != nullptr) {\n+        std::cout << \"ptx \" << ptx->text << std::endl;\n+\n+        \/\/ in this branch we use compilation with parameters\n+        const unsigned int jitNumOptions = 2;\n+        auto jitOptions = new CUjit_option[jitNumOptions];\n+        void **jitOptVals = new void *[jitNumOptions];\n+\n+        \/\/ set up size of compilation log buffer\n+        jitOptions[0] = CU_JIT_INFO_LOG_BUFFER_SIZE_BYTES;\n+        int jitLogBufferSize = 8192;\n+        jitOptVals[0] = (void *) (size_t) jitLogBufferSize;\n+\n+        \/\/ set up pointer to the compilation log buffer\n+        jitOptions[1] = CU_JIT_INFO_LOG_BUFFER;\n+        char *jitLogBuffer = new char[jitLogBufferSize];\n+        jitOptVals[1] = jitLogBuffer;\n+        int status = cuModuleLoadDataEx(&module, ptx->text, jitNumOptions, jitOptions, (void **) jitOptVals);\n+\n+        printf(\"> PTX JIT log:\\n%s\\n\", jitLogBuffer);\n+        return reinterpret_cast<long>(new PtxProgram(this, nullptr, ptx, module));\n+\n+        \/\/delete ptx;\n+    } else {\n+        std::cout << \"no ptx content!\" << std::endl;\n+        exit(1);\n+    }\n+}\n@@ -102,2 +464,5 @@\n-    PTXBackend::PTXConfig *ptxConfig = (PTXBackend::PTXConfig *) config;\n-    return (long) new PTXBackend(ptxConfig, configSchemaLen, configSchema);\n+    long backendHandle= reinterpret_cast<long>(\n+            new PtxBackend(static_cast<PtxBackend::PtxConfig *>(config), configSchemaLen,\n+                            configSchema));\n+    std::cout << \"getBackend() -> backendHandle=\" << std::hex << backendHandle << std::dec << std::endl;\n+    return backendHandle;\n@@ -105,0 +470,3 @@\n+\n+\n+\n","filename":"hat\/backends\/ptx\/cpp\/ptx_backend.cpp","additions":424,"deletions":56,"binary":false,"changes":480,"status":"modified"},{"patch":"@@ -0,0 +1,140 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+#pragma once\n+#define PTX_TYPES\n+#ifdef __APPLE__\n+\n+#define LongUnsignedNewline \"%llu\\n\"\n+#define Size_tNewline \"%lu\\n\"\n+#define LongHexNewline \"(0x%llx)\\n\"\n+#define alignedMalloc(size, alignment) memalign(alignment, size)\n+#define SNPRINTF snprintf\n+#else\n+\n+#include <malloc.h>\n+\n+#define LongHexNewline \"(0x%lx)\\n\"\n+#define LongUnsignedNewline \"%lu\\n\"\n+#define Size_tNewline \"%lu\\n\"\n+#if defined (_WIN32)\n+#include \"windows.h\"\n+#define alignedMalloc(size, alignment) _aligned_malloc(size, alignment)\n+#define SNPRINTF _snprintf\n+#else\n+#define alignedMalloc(size, alignment) memalign(alignment, size)\n+#define SNPRINTF  snprintf\n+#endif\n+#endif\n+\n+#include <iostream>\n+#include <cuda.h>\n+#include <builtin_types.h>\n+\n+#define CUDA_TYPES\n+\n+#include \"shared.h\"\n+\n+#include <fstream>\n+\n+#include<vector>\n+\n+class Ptx {\n+public:\n+    size_t len;\n+    char *text;\n+\n+    Ptx(size_t len);\n+\n+    ~Ptx();\n+\n+    static Ptx *nvcc(const char *ptxSource, size_t len);\n+};\n+\n+class PtxBackend : public Backend {\n+public:\n+    class PtxConfig : public Backend::Config {\n+    public:\n+        boolean gpu;\n+    };\n+\n+    class PtxProgram : public Backend::Program {\n+        class PtxKernel : public Backend::Program::Kernel {\n+            class PtxBuffer : public Backend::Program::Kernel::Buffer {\n+            public:\n+                CUdeviceptr devicePtr;\n+\n+                PtxBuffer(Backend::Program::Kernel *kernel, Arg_s *arg);\n+\n+                void copyToDevice();\n+\n+                void copyFromDevice();\n+\n+                virtual ~PtxBuffer();\n+            };\n+\n+        private:\n+            CUfunction function;\n+            cudaStream_t cudaStream;\n+        public:\n+            PtxKernel(Backend::Program *program, char* name, CUfunction function);\n+\n+            ~PtxKernel() override;\n+\n+            long ndrange( void *argArray);\n+        };\n+\n+    private:\n+        CUmodule module;\n+        Ptx *ptx;\n+\n+    public:\n+        PtxProgram(Backend *backend, BuildInfo *buildInfo, Ptx *ptx, CUmodule module);\n+\n+        ~PtxProgram();\n+\n+        long getKernel(int nameLen, char *name);\n+\n+        bool programOK();\n+    };\n+\n+private:\n+    CUdevice device;\n+    CUcontext context;\n+public:\n+\n+    PtxBackend(PtxConfig *config, int configSchemaLen, char *configSchema);\n+\n+    PtxBackend();\n+\n+    ~PtxBackend();\n+\n+    int getMaxComputeUnits();\n+\n+    void info();\n+\n+    long compileProgram(int len, char *source);\n+\n+};\n+\n","filename":"hat\/backends\/ptx\/include\/ptx_backend.h","additions":140,"deletions":0,"binary":false,"changes":140,"status":"added"}]}