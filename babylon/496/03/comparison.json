{"files":[{"patch":"@@ -378,1 +378,1 @@\n-            String code =config.isPTX() ? createPTX(kernelCallGraph,  args) : createC99(kernelCallGraph,  args);\n+            String code = config.isPTX() ? createPTX(kernelCallGraph,  ndRange, args) : createC99(kernelCallGraph,  ndRange, args);\n@@ -393,2 +393,2 @@\n-    String createC99(KernelCallGraph kernelCallGraph,  Object... args){\n-        return createCode(kernelCallGraph, new CudaHATKernelBuilder(), args);\n+    String createC99(KernelCallGraph kernelCallGraph, NDRange ndRange,  Object... args){\n+        return createCode(kernelCallGraph, new CudaHATKernelBuilder(ndRange), args);\n@@ -400,1 +400,1 @@\n-    String createPTX(KernelCallGraph kernelCallGraph, Object... args){\n+    String createPTX(KernelCallGraph kernelCallGraph, NDRange ndRange, Object... args){\n","filename":"hat\/backends\/ffi\/cuda\/src\/main\/java\/hat\/backend\/ffi\/CudaBackend.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+import hat.NDRange;\n@@ -35,0 +36,4 @@\n+    public CudaHATKernelBuilder(NDRange ndRange) {\n+        super(ndRange);\n+    }\n+\n@@ -47,2 +52,13 @@\n-    public CudaHATKernelBuilder globalId() {\n-        return identifier(\"blockIdx\").dot().identifier(\"x\")\n+    @Override\n+    public CudaHATKernelBuilder globalId(int id) {\n+        String threadDimId;\n+        if (id == 0) {\n+            threadDimId = \"x\";\n+        } else if (id == 1) {\n+            threadDimId = \"y\";\n+        } else if (id == 2) {\n+            threadDimId = \"z\";\n+        } else {\n+            throw new RuntimeException(\"Thread Dimension not supported\");\n+        }\n+        return identifier(\"blockIdx\").dot().identifier(threadDimId)\n@@ -50,1 +66,1 @@\n-                .identifier(\"blockDim\").dot().identifier(\"x\")\n+                .identifier(\"blockDim\").dot().identifier(threadDimId)\n@@ -52,1 +68,1 @@\n-                .identifier(\"threadIdx\").dot().identifier(\"x\");\n+                .identifier(\"threadIdx\").dot().identifier(threadDimId);\n@@ -56,2 +72,12 @@\n-    public CudaHATKernelBuilder globalSize() {\n-        return identifier(\"gridDim\").dot().identifier(\"x\")\n+    public CudaHATKernelBuilder globalSize(int id) {\n+        String threadDimId;\n+        if (id == 0) {\n+            threadDimId = \"x\";\n+        } else if (id == 1) {\n+            threadDimId = \"y\";\n+        } else if (id == 2) {\n+            threadDimId = \"z\";\n+        } else {\n+            throw new RuntimeException(\"Thread Dimension not supported\");\n+        }\n+        return identifier(\"gridDim\").dot().identifier(threadDimId)\n@@ -59,1 +85,1 @@\n-                .identifier(\"blockDim\").dot().identifier(\"x\");\n+                .identifier(\"blockDim\").dot().identifier(threadDimId);\n","filename":"hat\/backends\/ffi\/cuda\/src\/main\/java\/hat\/backend\/ffi\/CudaHATKernelBuilder.java","additions":33,"deletions":7,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -30,0 +30,2 @@\n+#include <iostream>\n+\n","filename":"hat\/backends\/ffi\/cuda\/src\/main\/native\/cpp\/cuda_backend.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -34,1 +34,0 @@\n-\n@@ -56,1 +55,1 @@\n-            String code = createC99(kernelCallGraph,  args);\n+            String code = createC99(kernelCallGraph,  ndRange, args);\n@@ -72,2 +71,2 @@\n-    String createC99(KernelCallGraph kernelCallGraph,  Object[] args){\n-        return createCode(kernelCallGraph, new OpenCLHATKernelBuilder(), args);\n+    String createC99(KernelCallGraph kernelCallGraph,  NDRange ndRange, Object[] args){\n+        return createCode(kernelCallGraph, new OpenCLHATKernelBuilder(ndRange), args);\n","filename":"hat\/backends\/ffi\/opencl\/src\/main\/java\/hat\/backend\/ffi\/OpenCLBackend.java","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+import hat.NDRange;\n@@ -34,0 +35,6 @@\n+\n+\n+    public OpenCLHATKernelBuilder(NDRange ndRange) {\n+        super(ndRange);\n+    }\n+\n@@ -51,2 +58,2 @@\n-    public OpenCLHATKernelBuilder globalId() {\n-        return identifier(\"get_global_id\").oparen().literal(0).cparen();\n+    public OpenCLHATKernelBuilder globalId(int id) {\n+        return identifier(\"get_global_id\").oparen().literal(id).cparen();\n@@ -56,2 +63,2 @@\n-    public OpenCLHATKernelBuilder globalSize() {\n-        return identifier(\"get_global_size\").oparen().literal(0).cparen();\n+    public OpenCLHATKernelBuilder globalSize(int id) {\n+        return identifier(\"get_global_size\").oparen().literal(id).cparen();\n","filename":"hat\/backends\/ffi\/opencl\/src\/main\/java\/hat\/backend\/ffi\/OpenCLHATKernelBuilder.java","additions":11,"deletions":4,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -27,1 +27,1 @@\n-int main(){\n+int main() {\n","filename":"hat\/backends\/ffi\/opencl\/src\/main\/native\/cpp\/info.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -40,1 +40,1 @@\n-        std::cerr << OpenCLBackend::errorMsg(status) << std::endl;\n+        std::cerr << errorMsg(status) << std::endl;\n@@ -46,1 +46,0 @@\n-\n@@ -50,2 +49,0 @@\n-\n-\n","filename":"hat\/backends\/ffi\/opencl\/src\/main\/native\/cpp\/opencl_backend_buffer.cpp","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -104,0 +104,1 @@\n+\n@@ -110,1 +111,0 @@\n-\n","filename":"hat\/backends\/ffi\/opencl\/src\/main\/native\/cpp\/opencl_backend_info.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -52,1 +52,1 @@\n-}\n\\ No newline at end of file\n+}\n","filename":"hat\/backends\/ffi\/opencl\/src\/main\/native\/cpp\/opencl_backend_kernel.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -203,1 +203,2 @@\n- void OpenCLBackend::OpenCLQueue::inc(const int bits, const char *arg){\n+\n+void OpenCLBackend::OpenCLQueue::inc(const int bits, const char *arg){\n@@ -211,2 +212,1 @@\n-  }\n-\n+ }\n@@ -246,1 +246,4 @@\n-    size_t dims = 1;\n+    \/\/std::cout << \"OpenCLBackend::OpenCLQueue::dispatch with dimensions \" << kernelContext->dimensions << std::endl;\n+    \/\/std::cout << \"Global Work Size: \" << kernelContext->maxX << \",\" << kernelContext->maxY << \",\" << kernelContext->maxZ << \"]\" << std::endl;\n+    size_t numDimensions = kernelContext->dimensions;\n+\n@@ -248,3 +251,3 @@\n-       static_cast<size_t>(kernelContext->maxX),\n-       static_cast<size_t>(0),\/\/ Todo: kernelContext->maxY\n-       static_cast<size_t>(0),\/\/ Todo: kernelContext->maxZ\n+        static_cast<size_t>(kernelContext->maxX),\n+        static_cast<size_t>(kernelContext->maxY),\n+        static_cast<size_t>(kernelContext->maxZ)\n@@ -252,0 +255,1 @@\n+\n@@ -253,9 +257,10 @@\n-            command_queue,\n-            dynamic_cast<OpenCLProgram::OpenCLKernel*>(kernel)->kernel,\n-            dims,\n-            nullptr,\n-            global_work_size,\n-            nullptr,\n-            eventc,\n-            eventListPtr(),\n-            nextEventPtr());\n+        command_queue,\n+        dynamic_cast<OpenCLProgram::OpenCLKernel *>(kernel)->kernel,\n+        numDimensions,\n+        nullptr,\n+        global_work_size,\n+        nullptr, \/\/ TODO: Select a local work group instead of the default one\n+        eventc,\n+        eventListPtr(),\n+        nextEventPtr());\n+\n@@ -263,1 +268,2 @@\n-   \/\/ markAsNDRangeAndInc();\n+    \/\/ markAsNDRangeAndInc();\n+\n@@ -265,1 +271,1 @@\n-        std::cerr << OpenCLBackend::errorMsg(status) << std::endl;\n+        std::cerr << errorMsg(status) << std::endl;\n@@ -268,2 +274,2 @@\n-    if (backend->config->trace | backend->config->traceEnqueues){\n-        std::cout << \"enqueued kernel dispatch \\\"\"<< kernel->name <<\"\\\" globalSize=\" << kernelContext->maxX << std::endl;\n+    if (backend->config->trace | backend->config->traceEnqueues) {\n+        std::cout << \"enqueued kernel dispatch \\\"\" << kernel->name << \"\\\" globalSize=\" << kernelContext->maxX << std::endl;\n@@ -271,1 +277,0 @@\n-\n@@ -274,1 +279,0 @@\n-\n","filename":"hat\/backends\/ffi\/opencl\/src\/main\/native\/cpp\/opencl_backend_queue.cpp","additions":26,"deletions":22,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -63,1 +63,1 @@\n-            this.kernelContext = KernelContext.create(kernelCallGraph.computeContext.accelerator, 0, 0);\n+            this.kernelContext = KernelContext.create(kernelCallGraph.computeContext.accelerator, 0, 0, 0, 0, 0, 0);\n@@ -71,0 +71,3 @@\n+            kernelContext.maxY(ndRange.kid.maxY);\n+            kernelContext.maxZ(ndRange.kid.maxZ);\n+            kernelContext.dimensions(ndRange.kid.getDimensions());\n","filename":"hat\/backends\/ffi\/shared\/src\/main\/java\/hat\/backend\/ffi\/C99FFIBackend.java","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -284,1 +284,1 @@\n-        profilableQueue->marker(Backend::ProfilableQueue::EnterKernelDispatchBits, name);\n+        profilableQueue->marker(ProfilableQueue::EnterKernelDispatchBits, name);\n","filename":"hat\/backends\/ffi\/shared\/src\/main\/native\/cpp\/shared.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -367,0 +367,5 @@\n+    int y;\n+    int maxY;\n+    int z;\n+    int maxZ;\n+    int dimensions;\n","filename":"hat\/backends\/ffi\/shared\/src\/main\/native\/include\/shared.h","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -39,1 +39,1 @@\n-public class OpenCLBackend extends C99JExtractedBackend{\n+public class OpenCLBackend extends C99JExtractedBackend {\n@@ -69,1 +69,1 @@\n-            String code = createCode(kernelCallGraph, new OpenCLHatKernelBuilder(), args);\n+            String code = createCode(kernelCallGraph, new OpenCLHatKernelBuilder(ndRange), args);\n","filename":"hat\/backends\/jextracted\/opencl\/src\/main\/java\/hat\/backend\/jextracted\/OpenCLBackend.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+import hat.NDRange;\n@@ -33,0 +34,5 @@\n+\n+    public OpenCLHatKernelBuilder(NDRange ndRange) {\n+        super(ndRange);\n+    }\n+\n@@ -50,2 +56,2 @@\n-    public OpenCLHatKernelBuilder globalId() {\n-        return identifier(\"get_global_id\").oparen().literal(0).cparen();\n+    public OpenCLHatKernelBuilder globalId(int id) {\n+        return identifier(\"get_global_id\").oparen().literal(id).cparen();\n@@ -55,2 +61,2 @@\n-    public OpenCLHatKernelBuilder globalSize() {\n-        return identifier(\"get_global_size\").oparen().literal(0).cparen();\n+    public OpenCLHatKernelBuilder globalSize(int id) {\n+        return identifier(\"get_global_size\").oparen().literal(id).cparen();\n","filename":"hat\/backends\/jextracted\/opencl\/src\/main\/java\/hat\/backend\/jextracted\/OpenCLHatKernelBuilder.java","additions":10,"deletions":4,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -86,1 +86,1 @@\n-        ndRange.kid = new KernelContext(ndRange, max, 0);\n+        ndRange.kid = new KernelContext(ndRange, max);\n@@ -90,0 +90,11 @@\n+    public NDRange range(int maxX, int maxY) {\n+        NDRange ndRange = new NDRange(this);\n+        ndRange.kid = new KernelContext(ndRange, maxX, maxY);\n+        return ndRange;\n+    }\n+\n+    public NDRange range(int maxX, int maxY, int maxZ) {\n+        NDRange ndRange = new NDRange(this);\n+        ndRange.kid = new KernelContext(ndRange, maxX, maxY, maxZ);\n+        return ndRange;\n+    }\n","filename":"hat\/core\/src\/main\/java\/hat\/Accelerator.java","additions":12,"deletions":1,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -129,0 +129,12 @@\n+        dispatchKernel(range, 0, 0, 1, quotableKernelContextConsumer);\n+    }\n+\n+    public void dispatchKernel(int rangeX, int rangeY, QuotableKernelContextConsumer quotableKernelContextConsumer) {\n+        dispatchKernel(rangeX, rangeY, 0, 2, quotableKernelContextConsumer);\n+    }\n+\n+    public void dispatchKernel(int rangeX, int rangeY, int rangeZ, QuotableKernelContextConsumer quotableKernelContextConsumer) {\n+        dispatchKernel(rangeX, rangeY, rangeZ, 3, quotableKernelContextConsumer);\n+    }\n+\n+    private void dispatchKernel(int rangeX, int rangeY, int rangeZ, int dimNumber, QuotableKernelContextConsumer quotableKernelContextConsumer) {\n@@ -135,1 +147,7 @@\n-            NDRange ndRange = accelerator.range(range);\n+            NDRange ndRange;\n+            switch (dimNumber) {\n+                case 1 -> ndRange = accelerator.range(rangeX);\n+                case 2 -> ndRange = accelerator.range(rangeX, rangeY);\n+                case 3 -> ndRange = accelerator.range(rangeX, rangeY, rangeZ);\n+                default -> throw new RuntimeException(\"[Error] Unexpected dimension value: \" + dimNumber + \". Allowed dimensions <1, 2, 3>\");\n+            }\n","filename":"hat\/core\/src\/main\/java\/hat\/ComputeContext.java","additions":19,"deletions":1,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+\n@@ -43,0 +44,1 @@\n+\n@@ -44,0 +46,3 @@\n+    public int y;\n+    public int z;\n+\n@@ -45,0 +50,17 @@\n+    final public int maxY;\n+    final public int maxZ;\n+\n+    final int dimensions;\n+\n+    \/**\n+     * 1D Kernel\n+     * @param ndRange {@link NDRange}\n+     * @param maxX Global number of threads for the first dimension (1D)\n+     *\/\n+    public KernelContext(NDRange ndRange, int maxX) {\n+        this.ndRange = ndRange;\n+        this.maxX = maxX;\n+        this.maxY = 0;\n+        this.maxZ = 0;\n+        this.dimensions = 1;\n+    }\n@@ -46,1 +68,7 @@\n-    public KernelContext(NDRange ndRange, int maxX, int x) {\n+    \/**\n+     * 1D Kernel\n+     * @param ndRange {@link NDRange}\n+     * @param maxX Global number of threads for the first dimension (1D)\n+     * @param maxY Global number of threads for the second dimension (2D)\n+     *\/\n+    public KernelContext(NDRange ndRange, int maxX, int maxY) {\n@@ -49,1 +77,22 @@\n-        this.x = x;\n+        this.maxY = maxY;\n+        this.maxZ = 0;\n+        this.dimensions = 2;\n+    }\n+\n+    \/**\n+     * 1D Kernel\n+     * @param ndRange {@link NDRange}\n+     * @param maxX Global number of threads for the first dimension (1D)\n+     * @param maxY Global number of threads for the second dimension (2D)\n+     * @param maxZ Global number of threads for the second dimension (3D)\n+     *\/\n+    public KernelContext(NDRange ndRange, int maxX, int maxY, int maxZ) {\n+        this.ndRange = ndRange;\n+        this.maxX = maxX;\n+        this.maxY = maxY;\n+        this.maxZ = maxZ;\n+        this.dimensions = 3;\n+    }\n+\n+    public int getDimensions() {\n+        return this.dimensions;\n","filename":"hat\/core\/src\/main\/java\/hat\/KernelContext.java","additions":51,"deletions":2,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+\n","filename":"hat\/core\/src\/main\/java\/hat\/NDRange.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -76,1 +76,1 @@\n-                        ndRange.kid = new KernelContext(ndRange, range, 0);\n+                        ndRange.kid = new KernelContext(ndRange, range);\n","filename":"hat\/core\/src\/main\/java\/hat\/backend\/java\/WorkStealer.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -27,1 +27,0 @@\n-\n@@ -31,3 +30,0 @@\n-import java.lang.invoke.MethodHandles;\n-\n-\n@@ -38,0 +34,6 @@\n+    int y();\n+    void y(int y);\n+\n+    int z();\n+    void z(int z);\n+\n@@ -41,1 +43,11 @@\n-    Schema<KernelContext> schema = Schema.of(KernelContext.class, s->s.fields(\"x\",\"maxX\"));\n+    int maxY();\n+    void maxY(int maxY);\n+\n+    int maxZ();\n+    void maxZ(int maxZ);\n+\n+    int dimensions();\n+    void dimensions(int numDimensions);\n+\n+    \/\/ Important part here! do not forget the new fields.\n+    Schema<KernelContext> schema = Schema.of(KernelContext.class, s->s.fields(\"x\",\"maxX\", \"y\", \"maxY\", \"z\", \"maxZ\", \"dimensions\"));\n@@ -47,0 +59,13 @@\n+        kernelContext.dimensions(1);\n+        return kernelContext;\n+    }\n+\n+    static KernelContext create(Accelerator accelerator, int x, int y, int z, int maxX, int maxY, int maxZ) {\n+        KernelContext kernelContext =  schema.allocate(accelerator);\n+        kernelContext.x(x);\n+        kernelContext.y(y);\n+        kernelContext.z(z);\n+        kernelContext.maxX(maxX);\n+        kernelContext.maxY(maxY);\n+        kernelContext.maxZ(maxZ);\n+        kernelContext.dimensions(3);\n","filename":"hat\/core\/src\/main\/java\/hat\/buffer\/KernelContext.java","additions":30,"deletions":5,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+import hat.NDRange;\n@@ -43,1 +44,0 @@\n-    public C99HATKernelBuilder() {\n@@ -45,0 +45,4 @@\n+    protected final NDRange ndRange;\n+\n+    public C99HATKernelBuilder(NDRange ndRange) {\n+        this.ndRange = ndRange;\n@@ -59,0 +63,6 @@\n+\n+                    \/\/ The context is customized depending on the NDRange of the application:\n+                    \/\/ 1D, 2D or 3D.\n+                    \/\/ An alternative is to always generate the 3D range for OpenCL.\n+\n+                    \/\/ Kernels are, at least, 1D\n@@ -60,2 +70,13 @@\n-                    intDeclaration(\"maxX\").semicolon();\n-                });\n+                    intDeclaration(\"maxX\").semicolonNl();\n+\n+                    if (ndRange.kid.getDimensions() > 1) {\n+                        \/\/ The code builder needs the NDRange\n+                        intDeclaration(\"y\").semicolonNl();\n+                        intDeclaration(\"maxY\").semicolon().nl();\n+                    }\n+\n+                    if (ndRange.kid.getDimensions() > 2) {\n+                        \/\/ The code builder needs the NDRange\n+                        intDeclaration(\"z\").semicolonNl();\n+                        intDeclaration(\"maxZ\").semicolon().nl();\n+                    }\n@@ -63,0 +84,3 @@\n+                    \/\/ It could be an alternative solution for doing this:\n+                    \/\/ NDRAnge is an iFACE with some restrictions\n+                });\n@@ -66,5 +90,7 @@\n-        return\n-                typedefKeyword().space().structOrUnion(isStruct).space()\n-                        .either(isStruct, _ -> suffix_s(name), _ -> suffix_u(name)).braceNlIndented(consumer)\n-                        .suffix_t(name).semicolon().nl();\n-\n+        return typedefKeyword()\n+                .space()\n+                .structOrUnion(isStruct)\n+                .space()\n+                .either(isStruct, _ -> suffix_s(name), _ -> suffix_u(name))\n+                .braceNlIndented(consumer)\n+                .suffix_t(name).semicolon().nl();\n@@ -75,1 +101,0 @@\n-\n@@ -78,1 +103,1 @@\n-        identifier(\"kc\").rarrow().identifier(\"x\").equals().globalId().semicolon().nl();\n+        identifier(\"kc\").rarrow().identifier(\"x\").equals().globalId(0).semicolon().nl();\n@@ -80,0 +105,8 @@\n+        if (ndRange.kid.getDimensions() > 1) {\n+            identifier(\"kc\").rarrow().identifier(\"y\").equals().globalId(1).semicolon().nl();\n+            identifier(\"kc\").rarrow().identifier(\"maxY\").equals().identifier(\"global_kc\").rarrow().identifier(\"maxY\").semicolon().nl();\n+        }\n+        if (ndRange.kid.getDimensions() > 2) {\n+            identifier(\"kc\").rarrow().identifier(\"z\").equals().globalId(2).semicolon().nl();\n+            identifier(\"kc\").rarrow().identifier(\"maxZ\").equals().identifier(\"global_kc\").rarrow().identifier(\"maxZ\").semicolon().nl();\n+        }\n@@ -81,1 +114,0 @@\n-\n@@ -169,1 +201,1 @@\n-    public abstract T globalId();\n+    public abstract T globalId(int id);\n@@ -171,1 +203,1 @@\n-    public abstract T globalSize();\n+    public abstract T globalSize(int id);\n","filename":"hat\/core\/src\/main\/java\/hat\/codebuilders\/C99HATKernelBuilder.java","additions":45,"deletions":13,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -37,1 +37,2 @@\n-import static hat.ifacemapper.MappableIface.*;\n+import static hat.ifacemapper.MappableIface.RO;\n+import static hat.ifacemapper.MappableIface.RW;\n@@ -39,0 +40,17 @@\n+\/**\n+ * Canonical example for Matrix Multiply.\n+ *\n+ * <p>How to run?<\/p>\n+ *\n+ * <p>For 2D Configuration:\n+ * <code>\n+ *     java @hat\/run ffi-opencl matmul 2D\n+ * <\/code>\n+ * <\/p>\n+ *\n+ * <p> For 1D Configuration\n+ *     <code>\n+ *         java @hat\/run ffi-opencl matmul 1D\n+ *     <\/code>\n+ * <\/p>\n+ *\/\n@@ -41,0 +59,11 @@\n+    private static final boolean CHECK_RESULT = true;\n+\n+    \/**\n+     * Naive Matrix Multiplication implemented in 2D.\n+     *\n+     * @param kc\n+     * @param matrixA\n+     * @param matrixB\n+     * @param matrixC\n+     * @param size\n+     *\/\n@@ -42,1 +71,24 @@\n-    public static void matrixMultiplyKernel(@RO KernelContext kc, @RO F32Array matrixA, @RO F32Array matrixB, @RW F32Array matrixC, int size) {\n+    public static void matrixMultiplyKernel2D(@RO KernelContext kc, @RO F32Array matrixA, @RO F32Array matrixB, @RW F32Array matrixC, int size) {\n+        if (kc.x < kc.maxX) {\n+            if (kc.y < kc.maxY) {\n+                float acc = 0;\n+                for (int k = 0; k < size; k++) {\n+                    acc += (matrixA.array(kc.x * size + k) * matrixB.array(k * size + kc.y));\n+                }\n+                matrixC.array(kc.x * size + kc.y, acc);\n+            }\n+        }\n+    }\n+\n+\n+    \/**\n+     * Naive Matrix Multiplication implemented in 1D.\n+     *\n+     * @param kc\n+     * @param matrixA\n+     * @param matrixB\n+     * @param matrixC\n+     * @param size\n+     *\/\n+    @CodeReflection\n+    public static void matrixMultiplyKernel1D(@RO KernelContext kc, @RO F32Array matrixA, @RO F32Array matrixB, @RW F32Array matrixC, int size) {\n@@ -55,1 +107,1 @@\n-    public static void matrixMultiply(@RO ComputeContext cc, @RO F32Array matrixA, @RO F32Array matrixB, @RW  F32Array matrixC, int size) {\n+    public static void matrixMultiply1D(@RO ComputeContext cc, @RO F32Array matrixA, @RO F32Array matrixB, @RW  F32Array matrixC, int size) {\n@@ -57,1 +109,8 @@\n-                kc -> matrixMultiplyKernel(kc, matrixA, matrixB, matrixC, size)\n+                kc -> matrixMultiplyKernel1D(kc, matrixA, matrixB, matrixC, size)\n+        );\n+    }\n+\n+    @CodeReflection\n+    public static void matrixMultiply2D(@RO ComputeContext cc, @RO F32Array matrixA, @RO F32Array matrixB, @RW  F32Array matrixC, int size) {\n+        cc.dispatchKernel(size, size,\n+                kc -> matrixMultiplyKernel2D(kc, matrixA, matrixB, matrixC, size)\n@@ -75,0 +134,15 @@\n+    \/**\n+     * Configuration to use in this example to represent a\n+     * 1D range or 2D range.\n+     *\/\n+    private enum NDRangeConfiguration {\n+        _1D, \/\/\n+        _2D;\n+    }\n+\n+    \/**\n+     * Run a 2D version by default.\n+     * @param args\n+     *      args: <\"1D\"|\"2D\"> for 1D dispatch\n+     *\n+     *\/\n@@ -76,1 +150,10 @@\n-        System.out.println(\"Running Matrix Multiplication!\");\n+        System.out.println(\"[INFO] Running Matrix Multiplication: \");\n+\n+        NDRangeConfiguration configuration = NDRangeConfiguration._2D;\n+        if (args.length > 0) {\n+            if (args[0].equals(\"1D\")) {\n+                configuration = NDRangeConfiguration._1D;\n+            }\n+        }\n+\n+        System.out.println(\"[INFO] NDRangeConfiguration: \" + configuration);\n@@ -93,0 +176,8 @@\n+        for (int j = 0; j < matrixA.length(); j++) {\n+            matrixA.array(j, r.nextFloat());\n+            matrixB.array(j, r.nextFloat());\n+        }\n+\n+        \/\/ Run Seq for reference\n+        runSequential(matrixA, matrixB, resultSeq, size);\n+\n@@ -95,3 +186,6 @@\n-            for (int j = 0; j < matrixA.length(); j++) {\n-                matrixA.array(j, r.nextFloat());\n-                matrixB.array(j, r.nextFloat());\n+            long start = System.nanoTime();\n+            switch (configuration) {\n+                case _1D -> accelerator.compute(cc ->\n+                        Main.matrixMultiply1D(cc, matrixA, matrixB, matrixC, size));\n+                case _2D -> accelerator.compute(cc ->\n+                        Main.matrixMultiply2D(cc, matrixA, matrixB, matrixC, size));\n@@ -100,4 +194,0 @@\n-            long start = System.nanoTime();\n-            accelerator.compute(cc ->\n-                    Main.matrixMultiply(cc, matrixA, matrixB, matrixC, size)\n-            );\n@@ -107,7 +197,11 @@\n-            \/\/ Check result\n-            runSequential(matrixA, matrixB, resultSeq, size);\n-            boolean isCorrect = true;\n-            for (int i = 0; i < size; i++) {\n-                for (int j = 0; j < size; j++) {\n-                    if (Math.abs(matrixC.array(i * size + j) - matrixC.array(i * size + j)) > 0.01f) {\n-                        isCorrect = false;\n+            if (it == 0 || it == 9 && CHECK_RESULT) {\n+                \/\/ Check result for the first iteration\n+                boolean isCorrect = true;\n+                for (int i = 0; i < size; i++) {\n+                    for (int j = 0; j < size; j++) {\n+                        if (Math.abs(resultSeq.array(i * size + j) - matrixC.array(i * size + j)) > 0.01f) {\n+                            isCorrect = false;\n+                            break;\n+                        }\n+                    }\n+                    if (!isCorrect) {\n@@ -117,4 +211,0 @@\n-                if (!isCorrect) {\n-                    break;\n-                }\n-            }\n@@ -122,4 +212,5 @@\n-            if (isCorrect) {\n-                System.out.println(\"Result is correct!\");\n-            } else {\n-                System.out.println(\"Result is wrong!\");\n+                if (isCorrect) {\n+                    System.out.println(\"Result is correct!\");\n+                } else {\n+                    System.out.println(\"Result is wrong!\");\n+                }\n","filename":"hat\/examples\/matmul\/src\/main\/java\/matmul\/Main.java","additions":118,"deletions":27,"binary":false,"changes":145,"status":"modified"}]}