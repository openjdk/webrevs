{"files":[{"patch":"@@ -116,1 +116,1 @@\n-                attentionMatrix.array(idx * N + j,  acc);\n+                attentionMatrix.array(idx * N + j, acc);\n@@ -145,1 +145,1 @@\n-                O.array(idx * d + j,  acc);\n+                O.array(idx * d + j, acc);\n@@ -165,1 +165,1 @@\n-                attentionMatrix.array(i * N + j,  acc);\n+                attentionMatrix.array(i * N + j, acc);\n@@ -193,1 +193,1 @@\n-                O.array(i * d + j,  acc);\n+                O.array(i * d + j, acc);\n@@ -200,0 +200,1 @@\n+     *\n@@ -222,1 +223,1 @@\n-                attentionMatrix.array(i * N + j,  acc);\n+                attentionMatrix.array(i * N + j, acc);\n@@ -258,1 +259,1 @@\n-                O.array(i * d + j,  acc);\n+                O.array(i * d + j, acc);\n@@ -285,1 +286,3 @@\n-        static SharedFloatArray createLocal() { return null;}\n+        static SharedFloatArray createLocal() {\n+            return null;\n+        }\n@@ -299,1 +302,3 @@\n-        static PrivateFloatArray createPrivate() {return null;}\n+        static PrivateFloatArray createPrivate() {\n+            return null;\n+        }\n@@ -385,1 +390,1 @@\n-                           * sharedArray.array((t * d + k) + sK_index);\n+                            * sharedArray.array((t * d + k) + sK_index);\n@@ -417,1 +422,1 @@\n-                               Math.exp(m_block - m_new) * pv) \/ l_new);\n+                        Math.exp(m_block - m_new) * pv) \/ l_new);\n@@ -473,1 +478,1 @@\n-        final float softmaxScale = (float) (1.0f\/Math.sqrt(headDim));\n+        final float softmaxScale = (float) (1.0f \/ Math.sqrt(headDim));\n@@ -520,1 +525,1 @@\n-            timersSelfAttentionJava.add((end-start));\n+            timersSelfAttentionJava.add((end - start));\n@@ -588,1 +593,1 @@\n-        final int skip = ITERATIONS\/2;\n+        final int skip = ITERATIONS \/ 2;\n@@ -599,3 +604,3 @@\n-        IO.println(\"Java \/ HAT-Self-Attention  = \" + (Math.ceil(averageJavaTimer\/ averageSelfAttentionHAT * 100) \/ 100) + \"x\");\n-        IO.println(\"Java \/ HAT-Flash-Attention = \" + (Math.ceil(averageJavaTimer\/ averageFlashAttentionHAT * 100) \/ 100) + \"x\");\n-        IO.println(\"HAT-Self-Attention \/ HAT-Flash-Attention = \" + (Math.ceil(averageSelfAttentionHAT\/ averageFlashAttentionHAT * 100) \/ 100) + \"x\");\n+        IO.println(\"Java \/ HAT-Self-Attention  = \" + (Math.ceil(averageJavaTimer \/ averageSelfAttentionHAT * 100) \/ 100) + \"x\");\n+        IO.println(\"Java \/ HAT-Flash-Attention = \" + (Math.ceil(averageJavaTimer \/ averageFlashAttentionHAT * 100) \/ 100) + \"x\");\n+        IO.println(\"HAT-Self-Attention \/ HAT-Flash-Attention = \" + (Math.ceil(averageSelfAttentionHAT \/ averageFlashAttentionHAT * 100) \/ 100) + \"x\");\n","filename":"hat\/examples\/flashattention\/src\/main\/java\/flashattention\/Main.java","additions":21,"deletions":16,"binary":false,"changes":37,"status":"modified"}]}