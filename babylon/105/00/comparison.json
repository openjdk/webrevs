{"files":[{"patch":"@@ -32,1 +32,3 @@\n-        : len(len), text(len > 0 ? new char[len] : nullptr) {}\n+        : len(len), text(len > 0 ? new char[len] : nullptr) {\n+    std::cout << \"in Ptx with buffer allocated \"<<len << std::endl;\n+}\n@@ -36,0 +38,1 @@\n+        std::cout << \"in ~Ptx with deleting allocated \"<<len << std::endl;\n@@ -46,1 +49,1 @@\n-\n+    Ptx *ptx = nullptr;\n@@ -48,2 +51,0 @@\n-    std::stringstream timestampCuda;\n-    timestampCuda << \".\/tmp\" << time << \".cu\";\n@@ -52,2 +53,0 @@\n-    Ptx *ptx = nullptr;\n-    const char *cudaPath = strdup(timestampCuda.str().c_str());\n@@ -55,2 +54,1 @@\n- \/\/   std::cout << \"cuda \" << cudaPath << std::endl;\n- \/\/   std::cout << \"ptx \" << ptxPath << std::endl;\n+   \/\/ std::cout << \"ptx \" << ptxPath << std::endl;\n@@ -61,0 +59,4 @@\n+        std::stringstream timestampCuda;\n+        timestampCuda << \".\/tmp\" << time << \".cu\";\n+        const char *cudaPath = strdup(timestampCuda.str().c_str());\n+        std::cout << \"cuda \" << cudaPath << std::endl;\n@@ -64,1 +66,0 @@\n-\n@@ -66,1 +67,0 @@\n-        \/\/ const char *argv[]{\"nvcc\", \"-v\", \"-ptx\", cudaPath, \"-o\", ptxPath, nullptr};\n@@ -68,5 +68,2 @@\n-        \/\/ We are the child so exec nvcc.\n-        \/\/close(1); \/\/ stdout\n-        \/\/close(2); \/\/ stderr\n-        \/\/open(stderrPath, O_RDWR); \/\/ stdout\n-        \/\/open(stdoutPath, O_RDWR); \/\/ stderr\n+        \/\/ we can't free cudaPath or ptxpath in child because we need them in exec, no prob through\n+        \/\/ because we get a new proc so they are released to os\n@@ -74,0 +71,1 @@\n+\n@@ -80,1 +78,1 @@\n-     \/\/   std::cerr << \"fork suceeded waitikbng for child\" << std::endl;\n+     \/\/   std::cerr << \"fork suceeded waiting for child\" << std::endl;\n@@ -82,12 +80,28 @@\n-      \/\/  std::cerr << \"child finished\" << std::endl;\n-        std::ifstream ptxStream(ptxPath);\n-        ptxStream.seekg(0, ptxStream.end);\n-        size_t ptxLen = ptxStream.tellg();\n-        if (ptxLen > 0) {\n-            ptx = new Ptx(ptxLen + 1);\n-            ptxStream.seekg(0, ptxStream.beg);\n-            ptxStream.read(ptx->text, ptx->len);\n-            ptx->text[ptx->len] = '\\0';\n-            ptx->text[ptx->len - 1] = '\\0';\n-        }\n-        ptxStream.close();\n+        std::cerr << \"child finished\" << std::endl;\n+        std::ifstream ptxStream;\n+        ptxStream.open(ptxPath);\n+      \/\/  if (ptxStream.is_open()) {\n+            ptxStream.seekg(0, std::ios::end);\n+            size_t ptxLen = ptxStream.tellg();\n+            ptxStream.close();\n+            ptxStream.open(ptxPath);\n+            free((void *) ptxPath);\n+            ptxPath = nullptr;\n+            if (ptxLen > 0) {\n+                std::cerr << \"ptx len \"<< ptxLen << std::endl;\n+                ptx = new Ptx(ptxLen + 1);\n+                std::cerr << \"about to read  \"<< ptx->len << std::endl;\n+                ptxStream.read(ptx->text, ptx->len);\n+                ptxStream.close();\n+                std::cerr << \"about to read  \"<< ptx->len << std::endl;\n+                ptx->text[ptx->len - 1] = '\\0';\n+                std::cerr << \"read text \"<< ptx->text << std::endl;\n+\n+            } else {\n+                std::cerr << \"no ptx! ptxLen == 0?\";\n+                exit(1);\n+            }\n+      \/\/  }else{\n+        \/\/    std::cerr << \"no ptx!\";\n+       \/\/     exit(1);\n+      \/\/  }\n@@ -95,1 +109,1 @@\n-  \/\/  std::cout << \"returning PTX\" << std::endl;\n+    std::cout << \"returning PTX\" << std::endl;\n@@ -103,1 +117,1 @@\n-        : Buffer(kernel, arg) {\n+        : Buffer(kernel, arg), devicePtr() {\n@@ -109,1 +123,7 @@\n-    checkCudaErrors(cuMemAlloc(&devicePtr, (size_t) arg->value.buffer.sizeInBytes));\n+    CUresult status = cuMemAlloc(&devicePtr, (size_t) arg->value.buffer.sizeInBytes);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuMemFree() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n@@ -119,1 +139,7 @@\n-    checkCudaErrors(cuMemFree(devicePtr));\n+    CUresult  status = cuMemFree(devicePtr);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuMemFree() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n@@ -124,1 +150,1 @@\n-    CudaKernel * cudaKernel = dynamic_cast<CudaKernel*>(kernel);\n+    auto cudaKernel = dynamic_cast<CudaKernel*>(kernel);\n@@ -140,5 +166,11 @@\n-    checkCudaErrors(cuMemcpyHtoDAsync(devicePtr, arg->value.buffer.memorySegment, arg->value.buffer.sizeInBytes,cudaKernel->cudaStream));\n-    cudaError_t t1 = cudaStreamSynchronize(cudaKernel->cudaStream);\n-    if (CUDA_SUCCESS != t1) {\n-        std::cerr << \"CUDA error = \" << t1\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(t1))\n+    CUresult status = cuMemcpyHtoDAsync(devicePtr, arg->value.buffer.memorySegment, arg->value.buffer.sizeInBytes,cudaKernel->cudaStream);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuMemcpyHtoDAsync() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+    status = static_cast<CUresult >(cudaStreamSynchronize(cudaKernel->cudaStream));\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n@@ -151,1 +183,1 @@\n-    CudaKernel * cudaKernel = dynamic_cast<CudaKernel*>(kernel);\n+    auto cudaKernel = dynamic_cast<CudaKernel*>(kernel);\n@@ -165,1 +197,7 @@\n-    checkCudaErrors(cuMemcpyDtoHAsync(arg->value.buffer.memorySegment, devicePtr, arg->value.buffer.sizeInBytes,cudaKernel->cudaStream));\n+    CUresult status =cuMemcpyDtoHAsync(arg->value.buffer.memorySegment, devicePtr, arg->value.buffer.sizeInBytes,cudaKernel->cudaStream);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n@@ -167,1 +205,1 @@\n-    if (CUDA_SUCCESS != t1) {\n+    if (static_cast<cudaError_t>(CUDA_SUCCESS) != t1) {\n@@ -183,2 +221,2 @@\n-CudaBackend::CudaProgram::CudaKernel::CudaKernel(Backend::Program *program,std::string name, CUfunction function)\n-        : Backend::Program::Kernel(program, name), function(function) {\n+CudaBackend::CudaProgram::CudaKernel::CudaKernel(Backend::Program *program,char * name, CUfunction function)\n+        : Backend::Program::Kernel(program, name), function(function),cudaStream() {\n@@ -187,4 +225,1 @@\n-CudaBackend::CudaProgram::CudaKernel::~CudaKernel() {\n-\n-    \/\/ releaseCUfunction function\n-}\n+CudaBackend::CudaProgram::CudaKernel::~CudaKernel() = default;\n@@ -192,1 +227,1 @@\n-long CudaBackend::CudaProgram::CudaKernel::ndrange(int range, void *argArray) {\n+long CudaBackend::CudaProgram::CudaKernel::ndrange(void *argArray) {\n@@ -194,0 +229,1 @@\n+\n@@ -198,0 +234,1 @@\n+    NDRange *ndrange = nullptr;\n@@ -205,0 +242,3 @@\n+                if (arg->idx == 0){\n+                    ndrange = static_cast<NDRange *>(arg->value.buffer.memorySegment);\n+                }\n@@ -226,1 +266,1 @@\n-\n+    int range = ndrange->maxX;\n@@ -236,5 +276,4 @@\n-\n-    cudaError_t t0 = cudaStreamSynchronize(cudaStream);\n-    if (CUDA_SUCCESS != t0) {\n-        std::cerr << \"CUDA error = \" << t0\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(t0))\n+    auto status= static_cast<CUresult>(cudaStreamSynchronize(cudaStream));\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n@@ -245,1 +284,1 @@\n-    checkCudaErrors(cuLaunchKernel(function,\n+    status= cuLaunchKernel(function,\n@@ -249,6 +288,11 @@\n-                    argslist, 0));\n-\n-    cudaError_t t1 = cudaStreamSynchronize(cudaStream);\n-    if (CUDA_SUCCESS != t1) {\n-        std::cerr << \"CUDA error = \" << t1\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(t1))\n+                    argslist, 0);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuLaunchKernel() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+    status= static_cast<CUresult>(cudaStreamSynchronize(cudaStream));\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n@@ -268,4 +312,4 @@\n-    cudaError_t t2 =   cudaStreamSynchronize(cudaStream);\n-    if (CUDA_SUCCESS != t2) {\n-        std::cerr << \"CUDA error = \" << t2\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(t2))\n+    status=   static_cast<CUresult>(cudaStreamSynchronize(cudaStream));\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n@@ -292,2 +336,1 @@\n-CudaBackend::CudaProgram::~CudaProgram() {\n-}\n+CudaBackend::CudaProgram::~CudaProgram() = default;\n@@ -297,5 +340,9 @@\n-  \/\/  std::cout << \"trying to get kernelFunction \" << name << std::endl;\n-    checkCudaErrors(\n-            cuModuleGetFunction(&function, module, name)\n-    );\n-    return reinterpret_cast<long>(new CudaKernel(this, std::string(name), function));\n+    CUresult status= cuModuleGetFunction(&function, module, name);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuModuleGetFunction() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+    long kernelHandle =  reinterpret_cast<long>(new CudaKernel(this, name, function));\n+    return kernelHandle;\n@@ -310,2 +357,1 @@\n-        : Backend((Backend::Config\n-*) cudaConfig, configSchemaLen, configSchema) {\n+        : Backend((Backend::Config*) cudaConfig, configSchemaLen, configSchema), device(),context()  {\n@@ -317,1 +363,1 @@\n-        checkCudaErrors(cuDeviceGetCount(&deviceCount));\n+        cuDeviceGetCount(&deviceCount);\n@@ -319,1 +365,1 @@\n-        checkCudaErrors(cuDeviceGet(&device, 0));\n+        cuDeviceGet(&device, 0);\n@@ -321,1 +367,1 @@\n-        checkCudaErrors(cuCtxCreate(&context, 0, device));\n+        cuCtxCreate(&context, 0, device);\n@@ -336,1 +382,7 @@\n-    checkCudaErrors(cuCtxDestroy(context));\n+    CUresult status = cuCtxDestroy(context);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuCtxDestroy(() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n@@ -352,2 +404,2 @@\n-    checkCudaErrors(cuDeviceGetAttribute(&major, CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MAJOR, device));\n-    checkCudaErrors(cuDeviceGetAttribute(&minor, CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MINOR, device));\n+    cuDeviceGetAttribute(&major, CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MAJOR, device);\n+    cuDeviceGetAttribute(&minor, CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MINOR, device);\n@@ -357,1 +409,1 @@\n-    checkCudaErrors(cuDeviceGetAttribute(&warpSize, CU_DEVICE_ATTRIBUTE_WARP_SIZE, device));\n+    cuDeviceGetAttribute(&warpSize, CU_DEVICE_ATTRIBUTE_WARP_SIZE, device);\n@@ -361,1 +413,1 @@\n-    checkCudaErrors(cuDeviceGetAttribute(&threadsPerBlock, CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK, device));\n+    cuDeviceGetAttribute(&threadsPerBlock, CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK, device);\n@@ -365,1 +417,1 @@\n-    checkCudaErrors(cuDeviceGetAttribute(&cores, CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT, device));\n+    cuDeviceGetAttribute(&cores, CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT, device);\n@@ -369,1 +421,1 @@\n-    checkCudaErrors(cuDeviceTotalMem(&totalGlobalMem, device));\n+    cuDeviceTotalMem(&totalGlobalMem, device);\n@@ -378,1 +430,0 @@\n-\n@@ -406,1 +457,1 @@\n-        std::cout << \"no ptx content!\/\" << std::endl;\n+        std::cout << \"no ptx content!\" << std::endl;\n@@ -412,2 +463,5 @@\n-    return reinterpret_cast<long>(new CudaBackend(static_cast<CudaBackend::CudaConfig *>(config), configSchemaLen,\n-                                                  configSchema));\n+    long backendHandle= reinterpret_cast<long>(\n+            new CudaBackend(static_cast<CudaBackend::CudaConfig *>(config), configSchemaLen,\n+                            configSchema));\n+    std::cout << \"getBackend() -> backendHandle=\" << std::hex << backendHandle << std::dec << std::endl;\n+    return backendHandle;\n@@ -417,75 +471,0 @@\n-void __checkCudaErrors(CUresult err, const char *file, const int line) {\n-    if (CUDA_SUCCESS != err) {\n-        std::cerr << \"CUDA error = \" << err\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(err))\n-                  <<\" \" << file << \" line \" << line << std::endl;\n-        exit(-1);\n-    }\n-}\n-\n-const char *CudaBackend::errorMsg(CUresult status) {\n-    static struct {\n-        CUresult code;\n-        const char *msg;\n-    } error_table[] = {\n-            {CUDA_SUCCESS, \"success\"},\n-            \/\/ {CL_DEVICE_NOT_FOUND,                \"device not found\",},\n-            \/\/   {CL_DEVICE_NOT_AVAILABLE,            \"device not available\",},\n-            \/\/   {CL_COMPILER_NOT_AVAILABLE,          \"compiler not available\",},\n-            \/\/   {CL_MEM_OBJECT_ALLOCATION_FAILURE,   \"mem object allocation failure\",},\n-            \/\/   {CL_OUT_OF_RESOURCES,                \"out of resources\",},\n-            \/\/   {CL_OUT_OF_HOST_MEMORY,              \"out of host memory\",},\n-            \/\/   {CL_PROFILING_INFO_NOT_AVAILABLE,    \"profiling not available\",},\n-            \/\/   {CL_MEM_COPY_OVERLAP,                \"memcopy overlaps\",},\n-            \/\/   {CL_IMAGE_FORMAT_MISMATCH,           \"image format mismatch\",},\n-            \/\/   {CL_IMAGE_FORMAT_NOT_SUPPORTED,      \"image format not supported\",},\n-            \/\/   {CL_BUILD_PROGRAM_FAILURE,           \"build program failed\",},\n-            \/\/   {CL_MAP_FAILURE,                     \"map failed\",},\n-            \/\/   {CL_INVALID_VALUE,                   \"invalid value\",},\n-            \/\/   {CL_INVALID_DEVICE_TYPE,             \"invalid device type\",},\n-            \/\/   {CL_INVALID_PLATFORM,                \"invlaid platform\",},\n-            \/\/   {CL_INVALID_DEVICE,                  \"invalid device\",},\n-            \/\/   {CL_INVALID_CONTEXT,                 \"invalid context\",},\n-            \/\/   {CL_INVALID_QUEUE_PROPERTIES,        \"invalid queue properties\",},\n-            \/\/   {CL_INVALID_COMMAND_QUEUE,           \"invalid command queue\",},\n-            \/\/   {CL_INVALID_HOST_PTR,                \"invalid host ptr\",},\n-            \/\/   {CL_INVALID_MEM_OBJECT,              \"invalid mem object\",},\n-            \/\/   {CL_INVALID_IMAGE_FORMAT_DESCRIPTOR, \"invalid image format descriptor \",},\n-            \/\/   {CL_INVALID_IMAGE_SIZE,              \"invalid image size\",},\n-            \/\/   {CL_INVALID_SAMPLER,                 \"invalid sampler\",},\n-            \/\/   {CL_INVALID_BINARY,                  \"invalid binary\",},\n-            \/\/   {CL_INVALID_BUILD_OPTIONS,           \"invalid build options\",},\n-            \/\/   {CL_INVALID_PROGRAM,                 \"invalid program \",},\n-            \/\/   {CL_INVALID_PROGRAM_EXECUTABLE,      \"invalid program executable\",},\n-            \/\/   {CL_INVALID_KERNEL_NAME,             \"invalid kernel name\",},\n-            \/\/   {CL_INVALID_KERNEL_DEFINITION,       \"invalid definition\",},\n-            \/\/   {CL_INVALID_KERNEL,                  \"invalid kernel\",},\n-            \/\/   {CL_INVALID_ARG_INDEX,               \"invalid arg index\",},\n-            \/\/   {CL_INVALID_ARG_VALUE,               \"invalid arg value\",},\n-            \/\/   {CL_INVALID_ARG_SIZE,                \"invalid arg size\",},\n-            \/\/   {CL_INVALID_KERNEL_ARGS,             \"invalid kernel args\",},\n-            \/\/   {CL_INVALID_WORK_DIMENSION,          \"invalid work dimension\",},\n-            \/\/   {CL_INVALID_WORK_GROUP_SIZE,         \"invalid work group size\",},\n-            \/\/   {CL_INVALID_WORK_ITEM_SIZE,          \"invalid work item size\",},\n-            \/\/   {CL_INVALID_GLOBAL_OFFSET,           \"invalid global offset\",},\n-            \/\/   {CL_INVALID_EVENT_WAIT_LIST,         \"invalid event wait list\",},\n-            \/\/   {CL_INVALID_EVENT,                   \"invalid event\",},\n-            \/\/   {CL_INVALID_OPERATION,               \"invalid operation\",},\n-            \/\/   {CL_INVALID_GL_OBJECT,               \"invalid gl object\",},\n-            \/\/   {CL_INVALID_BUFFER_SIZE,             \"invalid buffer size\",},\n-            \/\/  {CL_INVALID_MIP_LEVEL,               \"invalid mip level\",},\n-            \/\/   {CL_INVALID_GLOBAL_WORK_SIZE,        \"invalid global work size\",},\n-            {(CUresult) 0, nullptr},\n-    };\n-    static char unknown[256];\n-    int ii;\n-\n-    for (ii = 0; error_table[ii].msg != NULL; ii++) {\n-        if (error_table[ii].code == status) {\n-            \/\/std::cerr << \" clerror '\" << error_table[ii].msg << \"'\" << std::endl;\n-            return error_table[ii].msg;\n-        }\n-    }\n-    SNPRINTF(unknown, sizeof(unknown), \"unknown error %d\", status);\n-    return unknown;\n-}\n","filename":"hat\/backends\/cuda\/cpp\/cuda_backend.cpp","additions":142,"deletions":163,"binary":false,"changes":305,"status":"modified"},{"patch":"@@ -63,1 +63,1 @@\n-extern void __checkCudaErrors(CUresult err, const char *file, const int line);\n+\/\/extern void __checkCudaErrors(CUresult err, const char *file, const int line);\n@@ -65,1 +65,1 @@\n-#define checkCudaErrors(err)  __checkCudaErrors (err, __FILE__, __LINE__)\n+\/\/#define checkCudaErrors(err)  __checkCudaErrors (err, __FILE__, __LINE__)\n@@ -105,1 +105,1 @@\n-            CudaKernel(Backend::Program *program, std::string name, CUfunction function);\n+            CudaKernel(Backend::Program *program, char* name, CUfunction function);\n@@ -107,1 +107,1 @@\n-            ~CudaKernel();\n+            ~CudaKernel() override;\n@@ -109,1 +109,1 @@\n-            long ndrange(int range, void *argArray);\n+            long ndrange( void *argArray);\n@@ -143,1 +143,1 @@\n-    static const char *errorMsg(CUresult status);\n+    \/\/static const char *errorMsg(CUresult status);\n","filename":"hat\/backends\/cuda\/include\/cuda_backend.h","additions":6,"deletions":6,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -90,1 +90,1 @@\n-            OpenCLKernel(Backend::Program *program, std::string name,cl_kernel kernel);\n+            OpenCLKernel(Backend::Program *program, char* name,cl_kernel kernel);\n","filename":"hat\/backends\/opencl\/include\/opencl_backend.h","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -500,1 +500,1 @@\n-    Backend *backend = (Backend *) backendHandle;\n+    auto *backend = reinterpret_cast<Backend*>(backendHandle);\n@@ -506,1 +506,1 @@\n-    Backend *backend = (Backend *) backendHandle;\n+    auto *backend = reinterpret_cast<Backend*>(backendHandle);\n@@ -510,1 +510,1 @@\n-    Backend *backend = (Backend *) backendHandle;\n+    auto *backend = reinterpret_cast<Backend*>(backendHandle);\n@@ -514,3 +514,6 @@\n-    std::cout << \"trampolining through backendHandle to backend.compileProgram()\" << std::endl;\n-    Backend *backend = (Backend *) backendHandle;\n-    return backend->compileProgram(len, source);\n+    std::cout << \"trampolining through backendHandle to backend.compileProgram() \"\n+        <<std::hex<<backendHandle<< std::dec <<std::endl;\n+    auto *backend = reinterpret_cast<Backend*>(backendHandle);\n+    auto programHandle = backend->compileProgram(len, source);\n+    std::cout << \"programHandle = \"<<std::hex<<backendHandle<< std::dec <<std::endl;\n+    return programHandle;\n@@ -519,2 +522,3 @@\n-  \/\/  std::cout << \"trampolining through programHandle to program.getKernel()\" << std::endl;\n-    Backend::Program *program = (Backend::Program *) programHandle;\n+    std::cout << \"trampolining through programHandle to program.getKernel()\"\n+            <<std::hex<<programHandle<< std::dec <<std::endl;\n+    auto program = reinterpret_cast<Backend::Program *>(programHandle);\n@@ -526,2 +530,1 @@\n-\n-    Backend::Program::Kernel *kernel = (Backend::Program::Kernel *) kernelHandle;\n+    auto kernel = reinterpret_cast<Backend::Program::Kernel *>(kernelHandle);\n@@ -532,1 +535,1 @@\n-    Backend::Program::Kernel *kernel = (Backend::Program::Kernel *) kernelHandle;\n+    auto kernel = reinterpret_cast<Backend::Program::Kernel *>(kernelHandle);\n@@ -537,1 +540,1 @@\n-    Backend::Program *program = (Backend::Program *) programHandle;\n+    auto program = reinterpret_cast<Backend::Program *>(programHandle);\n@@ -541,1 +544,1 @@\n-    Backend::Program *program = (Backend::Program *) programHandle;\n+    auto program = reinterpret_cast<Backend::Program *>(programHandle);\n","filename":"hat\/backends\/shared\/cpp\/shared.cpp","additions":16,"deletions":13,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -458,1 +458,1 @@\n-            std::string name;\n+            char *name;\/\/ strduped!\n@@ -464,2 +464,2 @@\n-            Kernel(Program *program, std::string name)\n-                    : program(program), name(name) {\n+            Kernel(Program *program, char * name)\n+                    : program(program), name(strdup(name)) {\n@@ -468,1 +468,5 @@\n-            virtual ~Kernel() {}\n+            virtual ~Kernel(){\n+                if (name){\n+                    free(name);\n+                }\n+            }\n","filename":"hat\/backends\/shared\/include\/shared.h","additions":8,"deletions":4,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -38,2 +38,2 @@\n-        if (kc.x<s32Array.length()){\n-           int value = s32Array.array(kc.x);        \/\/ arr[cc.x]\n+        if (kc.x<kc.maxX){\n+           int value = s32Array.array(kc.x);     \/\/ arr[cc.x]\n@@ -60,1 +60,1 @@\n-        );                                  \/\/   extends Quotable, Consumer<ComputeContext>\n+        );                                     \/\/   extends Quotable, Consumer<ComputeContext>\n","filename":"hat\/examples\/squares\/src\/java\/squares\/Squares.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -98,2 +98,3 @@\n-        if (kc.x <kc.maxX){\n-           int width = greyImage.width();\n+        if (kc.x <kc.maxX){  \/\/ kc.maxX = imageWidth\n+           int x = kc.x;\n+           int width = kc.maxX;\n@@ -102,1 +103,13 @@\n-               integralCol((y * width) + kc.x, width, greyImage, integral, integralSq);\n+               int id =(y * width) + x;\n+               integralCol(id, width, greyImage, integral, integralSq);\n+           }\n+        }\n+    }\n+\n+    public static void javaIntegralCol(F32Array2D greyImage, F32Array2D integral, F32Array2D integralSq) {\n+        int height = greyImage.height();\n+        int width = greyImage.width();\n+        for (int x = 0; x<width; x++){\n+           for (int y = 1; y < height; y++) {\n+               int id =(y * width) + x;\n+               integralCol(id, width, greyImage, integral, integralSq);\n@@ -115,1 +128,2 @@\n-        if (kc.x <kc.maxX){\n+        if (kc.x <kc.maxX){  \/\/ kc.maxX == imageHeight\n+           int y = kc.x;\n@@ -118,1 +132,12 @@\n-               integralRow((kc.x * width) + x, integral, integralSq);\n+               int id =(y * width) + x;\n+               integralRow(id, integral, integralSq);\n+           }\n+        }\n+    }\n+    public static void javaIntegralRow(F32Array2D integral, F32Array2D integralSq) {\n+        int height = integral.height();\n+        int width = integral.width();\n+        for (int y = 0; y<height; y++){\n+           for (int x = 1; x < width; x++) {\n+               int id =(y * width) + x;\n+               integralRow(id, integral, integralSq);\n@@ -287,1 +312,1 @@\n-        javaRgbToGreyScale(rgbS08x3Image, greyImage);\n+        \/\/javaRgbToGreyScale(rgbS08x3Image, greyImage);\n@@ -289,1 +314,1 @@\n-        \/\/cc.dispatchKernel(width * height, kc -> rgbToGreyKernel(kc, rgbS08x3Image, greyImage));\n+        cc.dispatchKernel(width * height, kc -> rgbToGreyKernel(kc, rgbS08x3Image, greyImage));\n@@ -292,1 +317,0 @@\n-        javaCreateIntegralImage(greyImage, integralImage, integralSqImage);\n@@ -294,2 +318,6 @@\n-        \/\/cc.dispatchKernel(width, kc -> integralColKernel(kc, greyImage, integralImage, integralSqImage));\n-        \/\/cc.dispatchKernel(height, kc -> integralRowKernel(kc, integralImage, integralSqImage));\n+        \/\/javaCreateIntegralImage(greyImage, integralImage, integralSqImage);\n+\n+        \/\/javaIntegralCol(greyImage, integralImage, integralSqImage);\n+        \/\/javaIntegralRow(integralImage, integralSqImage);\n+        cc.dispatchKernel(width, kc -> integralColKernel(kc, greyImage, integralImage, integralSqImage));\n+        cc.dispatchKernel(height, kc -> integralRowKernel(kc, integralImage, integralSqImage));\n@@ -309,2 +337,4 @@\n-              \/\/ \"\/images\/team.jpg\"\n-               \"\/images\/Nasa1996.jpg\"\n+               \/\/\"\/images\/team.jpg\"\n+              \/\/ \"\/images\/eggheads.jpg\"\n+              \/\/ \"\/images\/highett.jpg\"\n+             \"\/images\/Nasa1996.jpg\"\n@@ -317,1 +347,1 @@\n-        ResultTable resultTable = ResultTable.create(accelerator, 10000);\n+        ResultTable resultTable = ResultTable.create(accelerator, 1000);\n","filename":"hat\/examples\/violajones\/src\/java\/violajones\/ViolaJonesCompute.java","additions":43,"deletions":13,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -74,2 +74,2 @@\n-                identifier(\"kc\").rarrow().identifier(\"x\").equals().globalId().semicolon().nl()\n-                .identifier(\"kc\").rarrow().identifier(\"maxX\").equals().globalSize().semicolon().nl();\n+                identifier(\"kc\").rarrow().identifier(\"x\").equals().globalId().semicolon().nl();\n+                \/\/.identifier(\"kc\").rarrow().identifier(\"maxX\").equals().globalSize().semicolon().nl();\n","filename":"hat\/hat\/src\/java\/hat\/backend\/c99codebuilders\/C99HatKernelBuilder.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"}]}