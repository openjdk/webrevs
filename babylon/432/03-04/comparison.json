{"files":[{"patch":"@@ -278,2 +278,2 @@\n-                        if (call.callDescriptor().equals(MethodRef.ofString(\"spirvdemo.IntArray::get(long)int\")) ||\n-                            call.callDescriptor().equals(MethodRef.ofString(\"spirvdemo.FloatArray::get(long)float\"))) {\n+                        if (call.callDescriptor().equals(MethodRef.ofString(\"spirvdemo.IntArray::get(long):int\")) ||\n+                            call.callDescriptor().equals(MethodRef.ofString(\"spirvdemo.FloatArray::get(long):float\"))) {\n@@ -296,2 +296,2 @@\n-                        else if (call.callDescriptor().equals(MethodRef.ofString(\"spirvdemo.IntArray::set(long, int)void\")) ||\n-                                call.callDescriptor().equals(MethodRef.ofString(\"spirvdemo.FloatArray::set(long, float)void\"))) {\n+                        else if (call.callDescriptor().equals(MethodRef.ofString(\"spirvdemo.IntArray::set(long, int):void\")) ||\n+                                call.callDescriptor().equals(MethodRef.ofString(\"spirvdemo.FloatArray::set(long, float):void\"))) {\n","filename":"cr-examples\/spirv\/src\/main\/java\/intel\/code\/spirv\/SpirvModuleGenerator.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -167,1 +167,7 @@\n-                if (i + 3 < type.length() && type.substring(i, i + 3).equals(\"ptr\")) {\n+                if (i + 19 < type.length() && type.substring(i, i + 19).equals(\"java.type.primitive\")) {\n+                    s.push(i + 19);\n+                    idxToOp.put(i, \"\");\n+                } else if (i + 15 < type.length() && type.substring(i, i + 15).equals(\"java.type.class\")) {\n+                    s.push(i + 15);\n+                    idxToOp.put(i, \"\");\n+                } else if (i + 3 < type.length() && type.substring(i, i + 3).equals(\"ptr\")) {\n","filename":"cr-examples\/triton\/src\/main\/java\/oracle\/code\/triton\/MLIRGenerator.java","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -39,19 +39,19 @@\n-            module ()void -> {\n-                tt.func @\"add_kernel_ptr<float>_ptr<float>_ptr<float>_int_64_void\" (%0 : ptr<float>, %1 : ptr<float>, %2 : ptr<float>, %3 : int)void -> {\n-                    %4 : int = arith.constant @\"64\";\n-                    %5 : int = tt.get_program_id @\"0\";\n-                    %6 : int = arith.muli %5 %4;\n-                    %7 : tensor<x64, int> = tt.make_range @start=\"0\" @end=\"64\";\n-                    %8 : tensor<x64, int> = tt.splat %6;\n-                    %9 : tensor<x64, int> = arith.addi %8 %7;\n-                    %10 : tensor<x64, int> = tt.splat %3;\n-                    %11 : tensor<x64, boolean> = arith.cmpi %9 %10 @\"slt\";\n-                    %12 : tensor<x64, ptr<float>> = tt.splat %0;\n-                    %13 : tensor<x64, ptr<float>> = tt.addptr %12 %9;\n-                    %14 : tensor<x64, float> = tt.load %13 %11;\n-                    %15 : tensor<x64, ptr<float>> = tt.splat %1;\n-                    %16 : tensor<x64, ptr<float>> = tt.addptr %15 %9;\n-                    %17 : tensor<x64, float> = tt.load %16 %11;\n-                    %18 : tensor<x64, float> = arith.addf %14 %17;\n-                    %19 : tensor<x64, ptr<float>> = tt.splat %2;\n-                    %20 : tensor<x64, ptr<float>> = tt.addptr %19 %9;\n+            module ()java.type:\"void\" -> {\n+                tt.func @\"add_kernel_ptr<java.type.primitive<float>>_ptr<java.type.primitive<float>>_ptr<java.type.primitive<float>>_int_64_void\" (%0 : ptr<java.type:\"float\">, %1 : ptr<java.type:\"float\">, %2 : ptr<java.type:\"float\">, %3 : java.type:\"int\")java.type:\"void\" -> {\n+                    %4 : java.type:\"int\" = arith.constant @\"64\";\n+                    %5 : java.type:\"int\" = tt.get_program_id @\"0\";\n+                    %6 : java.type:\"int\" = arith.muli %5 %4;\n+                    %7 : tensor<x64, java.type:\"int\"> = tt.make_range @start=\"0\" @end=\"64\";\n+                    %8 : tensor<x64, java.type:\"int\"> = tt.splat %6;\n+                    %9 : tensor<x64, java.type:\"int\"> = arith.addi %8 %7;\n+                    %10 : tensor<x64, java.type:\"int\"> = tt.splat %3;\n+                    %11 : tensor<x64, java.type:\"boolean\"> = arith.cmpi %9 %10 @\"slt\";\n+                    %12 : tensor<x64, ptr<java.type:\"float\">> = tt.splat %0;\n+                    %13 : tensor<x64, ptr<java.type:\"float\">> = tt.addptr %12 %9;\n+                    %14 : tensor<x64, java.type:\"float\"> = tt.load %13 %11;\n+                    %15 : tensor<x64, ptr<java.type:\"float\">> = tt.splat %1;\n+                    %16 : tensor<x64, ptr<java.type:\"float\">> = tt.addptr %15 %9;\n+                    %17 : tensor<x64, java.type:\"float\"> = tt.load %16 %11;\n+                    %18 : tensor<x64, java.type:\"float\"> = arith.addf %14 %17;\n+                    %19 : tensor<x64, ptr<java.type:\"float\">> = tt.splat %2;\n+                    %20 : tensor<x64, ptr<java.type:\"float\">> = tt.addptr %19 %9;\n@@ -108,19 +108,19 @@\n-            module ()void -> {\n-                tt.func @\"add_kernel2_ptr<float>_ptr<float>_ptr<float>_int_64_void\" (%0 : ptr<float>, %1 : ptr<float>, %2 : ptr<float>, %3 : int)void -> {\n-                    %4 : int = arith.constant @\"64\";\n-                    %5 : int = tt.get_program_id @\"0\";\n-                    %6 : int = arith.muli %5 %4;\n-                    %7 : tensor<x64, int> = tt.make_range @start=\"0\" @end=\"64\";\n-                    %8 : tensor<x64, int> = tt.splat %6;\n-                    %9 : tensor<x64, int> = arith.addi %8 %7;\n-                    %10 : tensor<x64, int> = tt.splat %3;\n-                    %11 : tensor<x64, boolean> = arith.cmpi %9 %10 @\"slt\";\n-                    %12 : tensor<x64, ptr<float>> = tt.splat %0;\n-                    %13 : tensor<x64, ptr<float>> = tt.addptr %12 %9;\n-                    %14 : tensor<x64, float> = tt.load %13 %11;\n-                    %15 : tensor<x64, ptr<float>> = tt.splat %1;\n-                    %16 : tensor<x64, ptr<float>> = tt.addptr %15 %9;\n-                    %17 : tensor<x64, float> = tt.load %16 %11;\n-                    %18 : tensor<x64, float> = arith.addf %14 %17;\n-                    %19 : tensor<x64, ptr<float>> = tt.splat %2;\n-                    %20 : tensor<x64, ptr<float>> = tt.addptr %19 %9;\n+            module ()java.type:\"void\" -> {\n+                tt.func @\"add_kernel2_ptr<java.type.primitive<float>>_ptr<java.type.primitive<float>>_ptr<java.type.primitive<float>>_int_64_void\" (%0 : ptr<java.type:\"float\">, %1 : ptr<java.type:\"float\">, %2 : ptr<java.type:\"float\">, %3 : java.type:\"int\")java.type:\"void\" -> {\n+                    %4 : java.type:\"int\" = arith.constant @\"64\";\n+                    %5 : java.type:\"int\" = tt.get_program_id @\"0\";\n+                    %6 : java.type:\"int\" = arith.muli %5 %4;\n+                    %7 : tensor<x64, java.type:\"int\"> = tt.make_range @start=\"0\" @end=\"64\";\n+                    %8 : tensor<x64, java.type:\"int\"> = tt.splat %6;\n+                    %9 : tensor<x64, java.type:\"int\"> = arith.addi %8 %7;\n+                    %10 : tensor<x64, java.type:\"int\"> = tt.splat %3;\n+                    %11 : tensor<x64, java.type:\"boolean\"> = arith.cmpi %9 %10 @\"slt\";\n+                    %12 : tensor<x64, ptr<java.type:\"float\">> = tt.splat %0;\n+                    %13 : tensor<x64, ptr<java.type:\"float\">> = tt.addptr %12 %9;\n+                    %14 : tensor<x64, java.type:\"float\"> = tt.load %13 %11;\n+                    %15 : tensor<x64, ptr<java.type:\"float\">> = tt.splat %1;\n+                    %16 : tensor<x64, ptr<java.type:\"float\">> = tt.addptr %15 %9;\n+                    %17 : tensor<x64, java.type:\"float\"> = tt.load %16 %11;\n+                    %18 : tensor<x64, java.type:\"float\"> = arith.addf %14 %17;\n+                    %19 : tensor<x64, ptr<java.type:\"float\">> = tt.splat %2;\n+                    %20 : tensor<x64, ptr<java.type:\"float\">> = tt.addptr %19 %9;\n","filename":"cr-examples\/triton\/src\/test\/java\/oracle\/code\/triton\/TestAddKernel.java","additions":38,"deletions":38,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -42,5 +42,5 @@\n-            module ()void -> {\n-                tt.func @\"test1_ptr<int>_int_64_void\" (%0 : ptr<int>, %1 : int)void -> {\n-                    %2 : tensor<x64, int> = tt.make_range @start=\"0\" @end=\"64\";\n-                    %3 : tensor<x64, ptr<int>> = tt.splat %0;\n-                    %4 : tensor<x64, ptr<int>> = tt.addptr %3 %2;\n+            module ()java.type:\"void\" -> {\n+                tt.func @\"test1_ptr<java.type.primitive<int>>_int_64_void\" (%0 : ptr<java.type:\"int\">, %1 : java.type:\"int\")java.type:\"void\" -> {\n+                    %2 : tensor<x64, java.type:\"int\"> = tt.make_range @start=\"0\" @end=\"64\";\n+                    %3 : tensor<x64, ptr<java.type:\"int\">> = tt.splat %0;\n+                    %4 : tensor<x64, ptr<java.type:\"int\">> = tt.addptr %3 %2;\n@@ -48,2 +48,2 @@\n-                    %5 : tensor<x64, int> = tt.splat %1;\n-                    %6 : tensor<x64, int> = arith.addi %5 %2;\n+                    %5 : tensor<x64, java.type:\"int\"> = tt.splat %1;\n+                    %6 : tensor<x64, java.type:\"int\"> = arith.addi %5 %2;\n@@ -51,2 +51,2 @@\n-                    %7 : tensor<x64, int> = tt.splat %1;\n-                    %8 : tensor<x64, int> = arith.addi %2 %7;\n+                    %7 : tensor<x64, java.type:\"int\"> = tt.splat %1;\n+                    %8 : tensor<x64, java.type:\"int\"> = arith.addi %2 %7;\n@@ -54,2 +54,2 @@\n-                    %9 : tensor<x64, int> = tt.splat %1;\n-                    %10 : tensor<x64, int> = arith.addi %9 %2;\n+                    %9 : tensor<x64, java.type:\"int\"> = tt.splat %1;\n+                    %10 : tensor<x64, java.type:\"int\"> = arith.addi %9 %2;\n@@ -57,2 +57,2 @@\n-                    %11 : tensor<x64, int> = tt.splat %1;\n-                    %12 : tensor<x64, int> = arith.addi %2 %11;\n+                    %11 : tensor<x64, java.type:\"int\"> = tt.splat %1;\n+                    %12 : tensor<x64, java.type:\"int\"> = arith.addi %2 %11;\n@@ -86,8 +86,8 @@\n-            module ()void -> {\n-                tt.func @\"test2_int_64_32_void\" (%1 : int)void -> {\n-                    %2 : tensor<x64, int> = tt.make_range @start=\"0\" @end=\"64\";\n-                    %3 : tensor<x1, x64, int> = tt.expand_dims %2 @\"0\";\n-                    %4 : tensor<x32, int> = tt.make_range @start=\"0\" @end=\"32\";\n-                    %5 : tensor<x32, x1, int> = tt.expand_dims %4 @\"1\";\n-                    %6 : tensor<x1, x64, int> = tt.splat %1;\n-                    %7 : tensor<x1, x64, int> = arith.addi %3 %6;\n+            module ()java.type:\"void\" -> {\n+                tt.func @\"test2_int_64_32_void\" (%1 : java.type:\"int\")java.type:\"void\" -> {\n+                    %2 : tensor<x64, java.type:\"int\"> = tt.make_range @start=\"0\" @end=\"64\";\n+                    %3 : tensor<x1, x64, java.type:\"int\"> = tt.expand_dims %2 @\"0\";\n+                    %4 : tensor<x32, java.type:\"int\"> = tt.make_range @start=\"0\" @end=\"32\";\n+                    %5 : tensor<x32, x1, java.type:\"int\"> = tt.expand_dims %4 @\"1\";\n+                    %6 : tensor<x1, x64, java.type:\"int\"> = tt.splat %1;\n+                    %7 : tensor<x1, x64, java.type:\"int\"> = arith.addi %3 %6;\n@@ -95,3 +95,3 @@\n-                    %8 : tensor<x32, x64, int> = tt.broadcast %3;\n-                    %9 : tensor<x32, x64, int> = tt.broadcast %5;\n-                    %10 : tensor<x32, x64, int> = arith.addi %8 %9;\n+                    %8 : tensor<x32, x64, java.type:\"int\"> = tt.broadcast %3;\n+                    %9 : tensor<x32, x64, java.type:\"int\"> = tt.broadcast %5;\n+                    %10 : tensor<x32, x64, java.type:\"int\"> = arith.addi %8 %9;\n","filename":"cr-examples\/triton\/src\/test\/java\/oracle\/code\/triton\/TestBroadcast.java","additions":24,"deletions":24,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -42,6 +42,6 @@\n-            module ()void -> {\n-                tt.func @\"cdiv_int_int_int\" (%0 : int, %1 : int)int -> {\n-                    %2 : int = arith.addi %0 %1;\n-                    %3 : int = arith.constant @\"1\";\n-                    %4 : int = arith.subi %2 %3;\n-                    %5 : int = arith.divsi %4 %1;\n+            module ()java.type:\"void\" -> {\n+                tt.func @\"cdiv_int_int_int\" (%0 : java.type:\"int\", %1 : java.type:\"int\")java.type:\"int\" -> {\n+                    %2 : java.type:\"int\" = arith.addi %0 %1;\n+                    %3 : java.type:\"int\" = arith.constant @\"1\";\n+                    %4 : java.type:\"int\" = arith.subi %2 %3;\n+                    %5 : java.type:\"int\" = arith.divsi %4 %1;\n@@ -50,2 +50,2 @@\n-                tt.func @\"testScalar_int_int_void\" (%6 : int, %7 : int)void -> {\n-                    %8 : int = tt.call %6 %7 @\"cdiv_int_int_int\";\n+                tt.func @\"testScalar_int_int_void\" (%6 : java.type:\"int\", %7 : java.type:\"int\")java.type:\"void\" -> {\n+                    %8 : java.type:\"int\" = tt.call %6 %7 @\"cdiv_int_int_int\";\n@@ -75,7 +75,7 @@\n-            module ()void -> {\n-                tt.func @\"cdiv_int_10_int\" (%0 : int)int -> {\n-                    %1 : int = arith.constant @\"10\";\n-                    %2 : int = arith.addi %0 %1;\n-                    %3 : int = arith.constant @\"1\";\n-                    %4 : int = arith.subi %2 %3;\n-                    %5 : int = arith.divsi %4 %1;\n+            module ()java.type:\"void\" -> {\n+                tt.func @\"cdiv_int_10_int\" (%0 : java.type:\"int\")java.type:\"int\" -> {\n+                    %1 : java.type:\"int\" = arith.constant @\"10\";\n+                    %2 : java.type:\"int\" = arith.addi %0 %1;\n+                    %3 : java.type:\"int\" = arith.constant @\"1\";\n+                    %4 : java.type:\"int\" = arith.subi %2 %3;\n+                    %5 : java.type:\"int\" = arith.divsi %4 %1;\n@@ -84,2 +84,2 @@\n-                tt.func @\"testConstant_int_10_void\" (%6 : int)void -> {\n-                    %7 : int = tt.call %6 @\"cdiv_int_10_int\";\n+                tt.func @\"testConstant_int_10_void\" (%6 : java.type:\"int\")java.type:\"void\" -> {\n+                    %7 : java.type:\"int\" = tt.call %6 @\"cdiv_int_10_int\";\n@@ -109,6 +109,6 @@\n-            module ()void -> {\n-                tt.func @\"cdiv_int_int_int\" (%0 : int, %1 : int)int -> {\n-                    %2 : int = arith.addi %0 %1;\n-                    %3 : int = arith.constant @\"1\";\n-                    %4 : int = arith.subi %2 %3;\n-                    %5 : int = arith.divsi %4 %1;\n+            module ()java.type:\"void\" -> {\n+                tt.func @\"cdiv_int_int_int\" (%0 : java.type:\"int\", %1 : java.type:\"int\")java.type:\"int\" -> {\n+                    %2 : java.type:\"int\" = arith.addi %0 %1;\n+                    %3 : java.type:\"int\" = arith.constant @\"1\";\n+                    %4 : java.type:\"int\" = arith.subi %2 %3;\n+                    %5 : java.type:\"int\" = arith.divsi %4 %1;\n@@ -117,6 +117,6 @@\n-                tt.func @\"cdiv_int_10_int\" (%6 : int)int -> {\n-                    %7 : int = arith.constant @\"10\";\n-                    %8 : int = arith.addi %6 %7;\n-                    %9 : int = arith.constant @\"1\";\n-                    %10 : int = arith.subi %8 %9;\n-                    %11 : int = arith.divsi %10 %7;\n+                tt.func @\"cdiv_int_10_int\" (%6 : java.type:\"int\")java.type:\"int\" -> {\n+                    %7 : java.type:\"int\" = arith.constant @\"10\";\n+                    %8 : java.type:\"int\" = arith.addi %6 %7;\n+                    %9 : java.type:\"int\" = arith.constant @\"1\";\n+                    %10 : java.type:\"int\" = arith.subi %8 %9;\n+                    %11 : java.type:\"int\" = arith.divsi %10 %7;\n@@ -125,6 +125,6 @@\n-                tt.func @\"cdiv_10_int_int\" (%12 : int)int -> {\n-                    %13 : int = arith.constant @\"10\";\n-                    %14 : int = arith.addi %13 %12;\n-                    %15 : int = arith.constant @\"1\";\n-                    %16 : int = arith.subi %14 %15;\n-                    %17 : int = arith.divsi %16 %12;\n+                tt.func @\"cdiv_10_int_int\" (%12 : java.type:\"int\")java.type:\"int\" -> {\n+                    %13 : java.type:\"int\" = arith.constant @\"10\";\n+                    %14 : java.type:\"int\" = arith.addi %13 %12;\n+                    %15 : java.type:\"int\" = arith.constant @\"1\";\n+                    %16 : java.type:\"int\" = arith.subi %14 %15;\n+                    %17 : java.type:\"int\" = arith.divsi %16 %12;\n@@ -133,2 +133,2 @@\n-                tt.func @\"testCalls_int_int_10_void\" (%18 : int, %19 : int)void -> {\n-                    %20 : int = tt.call %18 %19 @\"cdiv_int_int_int\";\n+                tt.func @\"testCalls_int_int_10_void\" (%18 : java.type:\"int\", %19 : java.type:\"int\")java.type:\"void\" -> {\n+                    %20 : java.type:\"int\" = tt.call %18 %19 @\"cdiv_int_int_int\";\n@@ -136,1 +136,1 @@\n-                    %21 : int = tt.call %19 %18 @\"cdiv_int_int_int\";\n+                    %21 : java.type:\"int\" = tt.call %19 %18 @\"cdiv_int_int_int\";\n@@ -138,1 +138,1 @@\n-                    %22 : int = tt.call %18 @\"cdiv_int_10_int\";\n+                    %22 : java.type:\"int\" = tt.call %18 @\"cdiv_int_10_int\";\n@@ -140,1 +140,1 @@\n-                    %23 : int = tt.call %18 @\"cdiv_10_int_int\";\n+                    %23 : java.type:\"int\" = tt.call %18 @\"cdiv_10_int_int\";\n","filename":"cr-examples\/triton\/src\/test\/java\/oracle\/code\/triton\/TestCdiv.java","additions":40,"deletions":40,"binary":false,"changes":80,"status":"modified"},{"patch":"@@ -42,12 +42,12 @@\n-            module ()void -> {\n-                tt.func @\"test1_int_64_void\" (%0 : int)void -> {\n-                    %1 : int = arith.constant @\"64\";\n-                    %2 : tensor<x64, int> = tt.make_range @start=\"0\" @end=\"64\";\n-                    %3 : tensor<x64, int> = tt.make_range @start=\"0\" @end=\"64\";\n-                    %4 : int = arith.constant @\"0\";\n-                    %5 : int = arith.constant @\"1\";\n-                    %6 : Tuple<tensor<x64, int>, tensor<x64,int>> = scf.for %4 %0 %5 %2 %3 (%7 : int, %8 : tensor<x64, int>, %9 : tensor<x64, int>)Tuple<tensor<x64, int>, tensor<x64, int>> -> {\n-                        %10 : tensor<x64, int> = tt.splat %7;\n-                        %11 : tensor<x64, int> = arith.addi %8 %10;\n-                        %12 : tensor<x64, int> = tt.splat %1;\n-                        %13 : tensor<x64, int> = arith.addi %9 %12;\n+            module ()java.type:\"void\" -> {\n+                tt.func @\"test1_int_64_void\" (%0 : java.type:\"int\")java.type:\"void\" -> {\n+                    %1 : java.type:\"int\" = arith.constant @\"64\";\n+                    %2 : tensor<x64, java.type:\"int\"> = tt.make_range @start=\"0\" @end=\"64\";\n+                    %3 : tensor<x64, java.type:\"int\"> = tt.make_range @start=\"0\" @end=\"64\";\n+                    %4 : java.type:\"int\" = arith.constant @\"0\";\n+                    %5 : java.type:\"int\" = arith.constant @\"1\";\n+                    %6 : Tuple<tensor<x64, java.type:\"int\">, tensor<x64, java.type:\"int\">> = scf.for %4 %0 %5 %2 %3 (%7 : java.type:\"int\", %8 : tensor<x64, java.type:\"int\">, %9 : tensor<x64, java.type:\"int\">)Tuple<tensor<x64, java.type:\"int\">, tensor<x64, java.type:\"int\">> -> {\n+                        %10 : tensor<x64, java.type:\"int\"> = tt.splat %7;\n+                        %11 : tensor<x64, java.type:\"int\"> = arith.addi %8 %10;\n+                        %12 : tensor<x64, java.type:\"int\"> = tt.splat %1;\n+                        %13 : tensor<x64, java.type:\"int\"> = arith.addi %9 %12;\n@@ -56,2 +56,2 @@\n-                    %14 : tensor<x64, int> = tuple.load %6 @\"0\";\n-                    %15 : tensor<x64, int> = tuple.load %6 @\"1\";\n+                    %14 : tensor<x64, java.type:\"int\"> = tuple.load %6 @\"0\";\n+                    %15 : tensor<x64, java.type:\"int\"> = tuple.load %6 @\"1\";\n","filename":"cr-examples\/triton\/src\/test\/java\/oracle\/code\/triton\/TestCountedLoop.java","additions":14,"deletions":14,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -43,7 +43,7 @@\n-            module ()void -> {\n-                tt.func @\"cdiv_int_32_int\" (%0 : int)int -> {\n-                    %1 : int = arith.constant @\"32\";\n-                    %2 : int = arith.addi %0 %1;\n-                    %3 : int = arith.constant @\"1\";\n-                    %4 : int = arith.subi %2 %3;\n-                    %5 : int = arith.divsi %4 %1;\n+            module ()java.type:\"void\" -> {\n+                tt.func @\"cdiv_int_32_int\" (%0 : java.type:\"int\")java.type:\"int\" -> {\n+                    %1 : java.type:\"int\" = arith.constant @\"32\";\n+                    %2 : java.type:\"int\" = arith.addi %0 %1;\n+                    %3 : java.type:\"int\" = arith.constant @\"1\";\n+                    %4 : java.type:\"int\" = arith.subi %2 %3;\n+                    %5 : java.type:\"int\" = arith.divsi %4 %1;\n@@ -52,6 +52,6 @@\n-                tt.func @\"cdiv_int_64_int\" (%6 : int)int -> {\n-                    %7 : int = arith.constant @\"64\";\n-                    %8 : int = arith.addi %6 %7;\n-                    %9 : int = arith.constant @\"1\";\n-                    %10 : int = arith.subi %8 %9;\n-                    %11 : int = arith.divsi %10 %7;\n+                tt.func @\"cdiv_int_64_int\" (%6 : java.type:\"int\")java.type:\"int\" -> {\n+                    %7 : java.type:\"int\" = arith.constant @\"64\";\n+                    %8 : java.type:\"int\" = arith.addi %6 %7;\n+                    %9 : java.type:\"int\" = arith.constant @\"1\";\n+                    %10 : java.type:\"int\" = arith.subi %8 %9;\n+                    %11 : java.type:\"int\" = arith.divsi %10 %7;\n@@ -60,80 +60,80 @@\n-                tt.func @\"matmul_kernel_broadcast_ptr<float>_ptr<float>_ptr<float>_int_int_int_int_int_int_int_int_int_32_64_32_8_false_void\" (%12 : ptr<float>, %13 : ptr<float>, %14 : ptr<float>, %15 : int, %16 : int, %17 : int, %18 : int, %19 : int, %20 : int, %21 : int, %22 : int, %23 : int)void -> {\n-                    %24 : int = arith.constant @\"32\";\n-                    %25 : int = arith.constant @\"64\";\n-                    %26 : int = arith.constant @\"32\";\n-                    %27 : int = arith.constant @\"8\";\n-                    %28 : int = tt.get_program_id @\"0\";\n-                    %29 : int = tt.call %15 @\"cdiv_int_32_int\";\n-                    %30 : int = tt.call %16 @\"cdiv_int_64_int\";\n-                    %31 : int = arith.muli %27 %30;\n-                    %32 : int = arith.divsi %28 %31;\n-                    %33 : int = arith.muli %32 %27;\n-                    %34 : int = arith.subi %29 %33;\n-                    %35 : int = arith.minsi %34 %27;\n-                    %36 : int = arith.remsi %28 %35;\n-                    %37 : int = arith.addi %33 %36;\n-                    %38 : int = arith.remsi %28 %31;\n-                    %39 : int = arith.divsi %38 %35;\n-                    %40 : tensor<x32, int> = tt.make_range @start=\"0\" @end=\"32\";\n-                    %41 : int = arith.muli %37 %24;\n-                    %42 : tensor<x32, int> = tt.splat %41;\n-                    %43 : tensor<x32, int> = arith.addi %42 %40;\n-                    %44 : tensor<x32, int> = tt.splat %15;\n-                    %45 : tensor<x32, int> = arith.remsi %43 %44;\n-                    %46 : tensor<x64, int> = tt.make_range @start=\"0\" @end=\"64\";\n-                    %47 : int = arith.muli %39 %25;\n-                    %48 : tensor<x64, int> = tt.splat %47;\n-                    %49 : tensor<x64, int> = arith.addi %48 %46;\n-                    %50 : tensor<x64, int> = tt.splat %16;\n-                    %51 : tensor<x64, int> = arith.remsi %49 %50;\n-                    %52 : tensor<x32, int> = tt.make_range @start=\"0\" @end=\"32\";\n-                    %53 : tensor<x32, x1, int> = tt.expand_dims %45 @\"1\";\n-                    %54 : tensor<x32, x1, int> = tt.splat %18;\n-                    %55 : tensor<x32, x1, int> = arith.muli %53 %54;\n-                    %56 : tensor<x1, x32, int> = tt.expand_dims %52 @\"0\";\n-                    %57 : tensor<x1, x32, int> = tt.splat %19;\n-                    %58 : tensor<x1, x32, int> = arith.muli %56 %57;\n-                    %59 : tensor<x32, x32, ptr<float>> = tt.splat %12;\n-                    %60 : tensor<x32, x32, int> = tt.broadcast %55;\n-                    %61 : tensor<x32, x32, int> = tt.broadcast %58;\n-                    %62 : tensor<x32, x32, int> = arith.addi %60 %61;\n-                    %63 : tensor<x32, x32, ptr<float>> = tt.addptr %59 %62;\n-                    %64 : tensor<x32, x1, int> = tt.expand_dims %52 @\"1\";\n-                    %65 : tensor<x32, x1, int> = tt.splat %20;\n-                    %66 : tensor<x32, x1, int> = arith.muli %64 %65;\n-                    %67 : tensor<x1, x64, int> = tt.expand_dims %51 @\"0\";\n-                    %68 : tensor<x1, x64, int> = tt.splat %21;\n-                    %69 : tensor<x1, x64, int> = arith.muli %67 %68;\n-                    %70 : tensor<x32, x64, ptr<float>> = tt.splat %13;\n-                    %71 : tensor<x32, x64, int> = tt.broadcast %66;\n-                    %72 : tensor<x32, x64, int> = tt.broadcast %69;\n-                    %73 : tensor<x32, x64, int> = arith.addi %71 %72;\n-                    %74 : tensor<x32, x64, ptr<float>> = tt.addptr %70 %73;\n-                    %75 : tensor<x32, x64, float> = arith.constant @\"0.0\";\n-                    %76 : int = arith.constant @\"0\";\n-                    %77 : int = tt.call %17 @\"cdiv_int_32_int\";\n-                    %78 : int = arith.constant @\"1\";\n-                    %79 : Tuple<tensor<x32, x64, float>, tensor<x32, x32, ptr<float>>, tensor<x32, x64, ptr<float>>> = scf.for %76 %77 %78 %75 %63 %74 (%80 : int, %81 : tensor<x32, x64, float>, %82 : tensor<x32, x32, ptr<float>>, %83 : tensor<x32, x64, ptr<float>>)Tuple<tensor<x32, x64, float>, tensor<x32, x32, ptr<float>>, tensor<x32, x64, ptr<float>>> -> {\n-                        %84 : tensor<x1, x32, int> = tt.expand_dims %52 @\"0\";\n-                        %85 : int = arith.muli %80 %26;\n-                        %86 : int = arith.subi %17 %85;\n-                        %87 : tensor<x1, x32, int> = tt.splat %86;\n-                        %88 : tensor<x1, x32, boolean> = arith.cmpi %84 %87 @\"slt\";\n-                        %89 : tensor<x32, x32, boolean> = tt.broadcast %88;\n-                        %90 : tensor<x32, x32, float> = tt.load %82 %89;\n-                        %91 : tensor<x32, x1, int> = tt.expand_dims %52 @\"1\";\n-                        %92 : int = arith.muli %80 %26;\n-                        %93 : int = arith.subi %17 %92;\n-                        %94 : tensor<x32, x1, int> = tt.splat %93;\n-                        %95 : tensor<x32, x1, boolean> = arith.cmpi %91 %94 @\"slt\";\n-                        %96 : tensor<x32, x64, boolean> = tt.broadcast %95;\n-                        %97 : tensor<x32, x64, float> = tt.load %83 %96;\n-                        %98 : tensor<x32, x64, float> = arith.constant @\"0.0\";\n-                        %99 : tensor<x32, x64, float> = tt.dot %90 %97 %98;\n-                        %100 : tensor<x32, x64, float> = arith.addf %81 %99;\n-                        %101 : int = arith.muli %26 %19;\n-                        %102 : tensor<x32, x32, int> = tt.splat %101;\n-                        %103 : tensor<x32, x32, ptr<float>> = tt.addptr %82 %102;\n-                        %104 : int = arith.muli %26 %20;\n-                        %105 : tensor<x32, x64, int> = tt.splat %104;\n-                        %106 : tensor<x32, x64, ptr<float>> = tt.addptr %83 %105;\n+                tt.func @sym_name=\"matmul_kernel_broadcast_ptr<java.type.primitive<float>>_ptr<java.type.primitive<float>>_ptr<java.type.primitive<float>>_int_int_int_int_int_int_int_int_int_32_64_32_8_false_void\" (%12 : ptr<java.type:\"float\">, %13 : ptr<java.type:\"float\">, %14 : ptr<java.type:\"float\">, %15 : java.type:\"int\", %16 : java.type:\"int\", %17 : java.type:\"int\", %18 : java.type:\"int\", %19 : java.type:\"int\", %20 : java.type:\"int\", %21 : java.type:\"int\", %22 : java.type:\"int\", %23 : java.type:\"int\")java.type:\"void\" -> {\n+                    %24 : java.type:\"int\" = arith.constant @\"32\";\n+                    %25 : java.type:\"int\" = arith.constant @\"64\";\n+                    %26 : java.type:\"int\" = arith.constant @\"32\";\n+                    %27 : java.type:\"int\" = arith.constant @\"8\";\n+                    %28 : java.type:\"int\" = tt.get_program_id @\"0\";\n+                    %29 : java.type:\"int\" = tt.call %15 @\"cdiv_int_32_int\";\n+                    %30 : java.type:\"int\" = tt.call %16 @\"cdiv_int_64_int\";\n+                    %31 : java.type:\"int\" = arith.muli %27 %30;\n+                    %32 : java.type:\"int\" = arith.divsi %28 %31;\n+                    %33 : java.type:\"int\" = arith.muli %32 %27;\n+                    %34 : java.type:\"int\" = arith.subi %29 %33;\n+                    %35 : java.type:\"int\" = arith.minsi %34 %27;\n+                    %36 : java.type:\"int\" = arith.remsi %28 %35;\n+                    %37 : java.type:\"int\" = arith.addi %33 %36;\n+                    %38 : java.type:\"int\" = arith.remsi %28 %31;\n+                    %39 : java.type:\"int\" = arith.divsi %38 %35;\n+                    %40 : tensor<x32, java.type:\"int\"> = tt.make_range @start=\"0\" @end=\"32\";\n+                    %41 : java.type:\"int\" = arith.muli %37 %24;\n+                    %42 : tensor<x32, java.type:\"int\"> = tt.splat %41;\n+                    %43 : tensor<x32, java.type:\"int\"> = arith.addi %42 %40;\n+                    %44 : tensor<x32, java.type:\"int\"> = tt.splat %15;\n+                    %45 : tensor<x32, java.type:\"int\"> = arith.remsi %43 %44;\n+                    %46 : tensor<x64, java.type:\"int\"> = tt.make_range @start=\"0\" @end=\"64\";\n+                    %47 : java.type:\"int\" = arith.muli %39 %25;\n+                    %48 : tensor<x64, java.type:\"int\"> = tt.splat %47;\n+                    %49 : tensor<x64, java.type:\"int\"> = arith.addi %48 %46;\n+                    %50 : tensor<x64, java.type:\"int\"> = tt.splat %16;\n+                    %51 : tensor<x64, java.type:\"int\"> = arith.remsi %49 %50;\n+                    %52 : tensor<x32, java.type:\"int\"> = tt.make_range @start=\"0\" @end=\"32\";\n+                    %53 : tensor<x32, x1, java.type:\"int\"> = tt.expand_dims %45 @\"1\";\n+                    %54 : tensor<x32, x1, java.type:\"int\"> = tt.splat %18;\n+                    %55 : tensor<x32, x1, java.type:\"int\"> = arith.muli %53 %54;\n+                    %56 : tensor<x1, x32, java.type:\"int\"> = tt.expand_dims %52 @\"0\";\n+                    %57 : tensor<x1, x32, java.type:\"int\"> = tt.splat %19;\n+                    %58 : tensor<x1, x32, java.type:\"int\"> = arith.muli %56 %57;\n+                    %59 : tensor<x32, x32, ptr<java.type:\"float\">> = tt.splat %12;\n+                    %60 : tensor<x32, x32, java.type:\"int\"> = tt.broadcast %55;\n+                    %61 : tensor<x32, x32, java.type:\"int\"> = tt.broadcast %58;\n+                    %62 : tensor<x32, x32, java.type:\"int\"> = arith.addi %60 %61;\n+                    %63 : tensor<x32, x32, ptr<java.type:\"float\">> = tt.addptr %59 %62;\n+                    %64 : tensor<x32, x1, java.type:\"int\"> = tt.expand_dims %52 @\"1\";\n+                    %65 : tensor<x32, x1, java.type:\"int\"> = tt.splat %20;\n+                    %66 : tensor<x32, x1, java.type:\"int\"> = arith.muli %64 %65;\n+                    %67 : tensor<x1, x64, java.type:\"int\"> = tt.expand_dims %51 @\"0\";\n+                    %68 : tensor<x1, x64, java.type:\"int\"> = tt.splat %21;\n+                    %69 : tensor<x1, x64, java.type:\"int\"> = arith.muli %67 %68;\n+                    %70 : tensor<x32, x64, ptr<java.type:\"float\">> = tt.splat %13;\n+                    %71 : tensor<x32, x64, java.type:\"int\"> = tt.broadcast %66;\n+                    %72 : tensor<x32, x64, java.type:\"int\"> = tt.broadcast %69;\n+                    %73 : tensor<x32, x64, java.type:\"int\"> = arith.addi %71 %72;\n+                    %74 : tensor<x32, x64, ptr<java.type:\"float\">> = tt.addptr %70 %73;\n+                    %75 : tensor<x32, x64, java.type:\"float\"> = arith.constant @\"0.0\";\n+                    %76 : java.type:\"int\" = arith.constant @\"0\";\n+                    %77 : java.type:\"int\" = tt.call %17 @\"cdiv_int_32_int\";\n+                    %78 : java.type:\"int\" = arith.constant @\"1\";\n+                    %79 : Tuple<tensor<x32, x64, java.type:\"float\">, tensor<x32, x32, ptr<java.type:\"float\">>, tensor<x32, x64, ptr<java.type:\"float\">>> = scf.for %76 %77 %78 %75 %63 %74 (%80 : java.type:\"int\", %81 : tensor<x32, x64, java.type:\"float\">, %82 : tensor<x32, x32, ptr<java.type:\"float\">>, %83 : tensor<x32, x64, ptr<java.type:\"float\">>)Tuple<tensor<x32, x64, java.type:\"float\">, tensor<x32, x32, ptr<java.type:\"float\">>, tensor<x32, x64, ptr<java.type:\"float\">>> -> {\n+                        %84 : tensor<x1, x32, java.type:\"int\"> = tt.expand_dims %52 @\"0\";\n+                        %85 : java.type:\"int\" = arith.muli %80 %26;\n+                        %86 : java.type:\"int\" = arith.subi %17 %85;\n+                        %87 : tensor<x1, x32, java.type:\"int\"> = tt.splat %86;\n+                        %88 : tensor<x1, x32, java.type:\"boolean\"> = arith.cmpi %84 %87 @\"slt\";\n+                        %89 : tensor<x32, x32, java.type:\"boolean\"> = tt.broadcast %88;\n+                        %90 : tensor<x32, x32, java.type:\"float\"> = tt.load %82 %89;\n+                        %91 : tensor<x32, x1, java.type:\"int\"> = tt.expand_dims %52 @\"1\";\n+                        %92 : java.type:\"int\" = arith.muli %80 %26;\n+                        %93 : java.type:\"int\" = arith.subi %17 %92;\n+                        %94 : tensor<x32, x1, java.type:\"int\"> = tt.splat %93;\n+                        %95 : tensor<x32, x1, java.type:\"boolean\"> = arith.cmpi %91 %94 @\"slt\";\n+                        %96 : tensor<x32, x64, java.type:\"boolean\"> = tt.broadcast %95;\n+                        %97 : tensor<x32, x64, java.type:\"float\"> = tt.load %83 %96;\n+                        %98 : tensor<x32, x64, java.type:\"float\"> = arith.constant @\"0.0\";\n+                        %99 : tensor<x32, x64, java.type:\"float\"> = tt.dot %90 %97 %98;\n+                        %100 : tensor<x32, x64, java.type:\"float\"> = arith.addf %81 %99;\n+                        %101 : java.type:\"int\" = arith.muli %26 %19;\n+                        %102 : tensor<x32, x32, java.type:\"int\"> = tt.splat %101;\n+                        %103 : tensor<x32, x32, ptr<java.type:\"float\">> = tt.addptr %82 %102;\n+                        %104 : java.type:\"int\" = arith.muli %26 %20;\n+                        %105 : tensor<x32, x64, java.type:\"int\"> = tt.splat %104;\n+                        %106 : tensor<x32, x64, ptr<java.type:\"float\">> = tt.addptr %83 %105;\n@@ -142,29 +142,29 @@\n-                    %107 : tensor<x32, x64, float> = tuple.load %79 @\"0\";\n-                    %108 : tensor<x32, x32, ptr<float>> = tuple.load %79 @\"1\";\n-                    %109 : tensor<x32, x64, ptr<float>> = tuple.load %79 @\"2\";\n-                    %110 : int = arith.muli %37 %24;\n-                    %111 : tensor<x32, int> = tt.splat %110;\n-                    %112 : tensor<x32, int> = arith.addi %111 %40;\n-                    %113 : int = arith.muli %39 %25;\n-                    %114 : tensor<x64, int> = tt.splat %113;\n-                    %115 : tensor<x64, int> = arith.addi %114 %46;\n-                    %116 : tensor<x32, x1, int> = tt.expand_dims %112 @\"1\";\n-                    %117 : tensor<x32, x1, int> = tt.splat %22;\n-                    %118 : tensor<x32, x1, int> = arith.muli %116 %117;\n-                    %119 : tensor<x1, x64, int> = tt.expand_dims %115 @\"0\";\n-                    %120 : tensor<x1, x64, int> = tt.splat %23;\n-                    %121 : tensor<x1, x64, int> = arith.muli %119 %120;\n-                    %122 : tensor<x32, x64, ptr<float>> = tt.splat %14;\n-                    %123 : tensor<x32, x64, int> = tt.broadcast %118;\n-                    %124 : tensor<x32, x64, int> = tt.broadcast %121;\n-                    %125 : tensor<x32, x64, int> = arith.addi %123 %124;\n-                    %126 : tensor<x32, x64, ptr<float>> = tt.addptr %122 %125;\n-                    %127 : tensor<x32, x1, int> = tt.expand_dims %112 @\"1\";\n-                    %128 : tensor<x32, x1, int> = tt.splat %15;\n-                    %129 : tensor<x32, x1, boolean> = arith.cmpi %127 %128 @\"slt\";\n-                    %130 : tensor<x1, x64, int> = tt.expand_dims %115 @\"0\";\n-                    %131 : tensor<x1, x64, int> = tt.splat %16;\n-                    %132 : tensor<x1, x64, boolean> = arith.cmpi %130 %131 @\"slt\";\n-                    %133 : tensor<x32, x64, boolean> = tt.broadcast %129;\n-                    %134 : tensor<x32, x64, boolean> = tt.broadcast %132;\n-                    %135 : tensor<x32, x64, boolean> = arith.andi %133 %134;\n+                    %107 : tensor<x32, x64, java.type:\"float\"> = tuple.load %79 @\"0\";\n+                    %108 : tensor<x32, x32, ptr<java.type:\"float\">> = tuple.load %79 @\"1\";\n+                    %109 : tensor<x32, x64, ptr<java.type:\"float\">> = tuple.load %79 @\"2\";\n+                    %110 : java.type:\"int\" = arith.muli %37 %24;\n+                    %111 : tensor<x32, java.type:\"int\"> = tt.splat %110;\n+                    %112 : tensor<x32, java.type:\"int\"> = arith.addi %111 %40;\n+                    %113 : java.type:\"int\" = arith.muli %39 %25;\n+                    %114 : tensor<x64, java.type:\"int\"> = tt.splat %113;\n+                    %115 : tensor<x64, java.type:\"int\"> = arith.addi %114 %46;\n+                    %116 : tensor<x32, x1, java.type:\"int\"> = tt.expand_dims %112 @\"1\";\n+                    %117 : tensor<x32, x1, java.type:\"int\"> = tt.splat %22;\n+                    %118 : tensor<x32, x1, java.type:\"int\"> = arith.muli %116 %117;\n+                    %119 : tensor<x1, x64, java.type:\"int\"> = tt.expand_dims %115 @\"0\";\n+                    %120 : tensor<x1, x64, java.type:\"int\"> = tt.splat %23;\n+                    %121 : tensor<x1, x64, java.type:\"int\"> = arith.muli %119 %120;\n+                    %122 : tensor<x32, x64, ptr<java.type:\"float\">> = tt.splat %14;\n+                    %123 : tensor<x32, x64, java.type:\"int\"> = tt.broadcast %118;\n+                    %124 : tensor<x32, x64, java.type:\"int\"> = tt.broadcast %121;\n+                    %125 : tensor<x32, x64, java.type:\"int\"> = arith.addi %123 %124;\n+                    %126 : tensor<x32, x64, ptr<java.type:\"float\">> = tt.addptr %122 %125;\n+                    %127 : tensor<x32, x1, java.type:\"int\"> = tt.expand_dims %112 @\"1\";\n+                    %128 : tensor<x32, x1, java.type:\"int\"> = tt.splat %15;\n+                    %129 : tensor<x32, x1, java.type:\"boolean\"> = arith.cmpi %127 %128 @\"slt\";\n+                    %130 : tensor<x1, x64, java.type:\"int\"> = tt.expand_dims %115 @\"0\";\n+                    %131 : tensor<x1, x64, java.type:\"int\"> = tt.splat %16;\n+                    %132 : tensor<x1, x64, java.type:\"boolean\"> = arith.cmpi %130 %131 @\"slt\";\n+                    %133 : tensor<x32, x64, java.type:\"boolean\"> = tt.broadcast %129;\n+                    %134 : tensor<x32, x64, java.type:\"boolean\"> = tt.broadcast %132;\n+                    %135 : tensor<x32, x64, java.type:\"boolean\"> = arith.andi %133 %134;\n@@ -321,7 +321,7 @@\n-            module ()void -> {\n-                tt.func @\"cdiv_int_32_int\" (%0 : int)int -> {\n-                    %1 : int = arith.constant @\"32\";\n-                    %2 : int = arith.addi %0 %1;\n-                    %3 : int = arith.constant @\"1\";\n-                    %4 : int = arith.subi %2 %3;\n-                    %5 : int = arith.divsi %4 %1;\n+            module ()java.type:\"void\" -> {\n+                tt.func @\"cdiv_int_32_int\" (%0 : java.type:\"int\")java.type:\"int\" -> {\n+                    %1 : java.type:\"int\" = arith.constant @\"32\";\n+                    %2 : java.type:\"int\" = arith.addi %0 %1;\n+                    %3 : java.type:\"int\" = arith.constant @\"1\";\n+                    %4 : java.type:\"int\" = arith.subi %2 %3;\n+                    %5 : java.type:\"int\" = arith.divsi %4 %1;\n@@ -330,6 +330,6 @@\n-                tt.func @\"cdiv_int_64_int\" (%6 : int)int -> {\n-                    %7 : int = arith.constant @\"64\";\n-                    %8 : int = arith.addi %6 %7;\n-                    %9 : int = arith.constant @\"1\";\n-                    %10 : int = arith.subi %8 %9;\n-                    %11 : int = arith.divsi %10 %7;\n+                tt.func @\"cdiv_int_64_int\" (%6 : java.type:\"int\")java.type:\"int\" -> {\n+                    %7 : java.type:\"int\" = arith.constant @\"64\";\n+                    %8 : java.type:\"int\" = arith.addi %6 %7;\n+                    %9 : java.type:\"int\" = arith.constant @\"1\";\n+                    %10 : java.type:\"int\" = arith.subi %8 %9;\n+                    %11 : java.type:\"int\" = arith.divsi %10 %7;\n@@ -338,85 +338,85 @@\n-                tt.func @\"matmul_kernel_ptr<float>_ptr<float>_ptr<float>_int_int_int_int_1_int_1_int_1_32_64_32_8_false_void\" (%12 : ptr<float>, %13 : ptr<float>, %14 : ptr<float>, %15 : int, %16 : int, %17 : int, %18 : int, %19 : int, %20 : int)void -> {\n-                    %21 : int = arith.constant @\"1\";\n-                    %22 : int = arith.constant @\"1\";\n-                    %23 : int = arith.constant @\"1\";\n-                    %24 : int = arith.constant @\"32\";\n-                    %25 : int = arith.constant @\"64\";\n-                    %26 : int = arith.constant @\"32\";\n-                    %27 : int = arith.constant @\"8\";\n-                    %28 : int = tt.get_program_id @\"0\";\n-                    %29 : int = tt.call %15 @\"cdiv_int_32_int\";\n-                    %30 : int = tt.call %16 @\"cdiv_int_64_int\";\n-                    %31 : int = arith.muli %27 %30;\n-                    %32 : int = arith.divsi %28 %31;\n-                    %33 : int = arith.muli %32 %27;\n-                    %34 : int = arith.subi %29 %33;\n-                    %35 : int = arith.minsi %34 %27;\n-                    %36 : int = arith.remsi %28 %35;\n-                    %37 : int = arith.addi %33 %36;\n-                    %38 : int = arith.remsi %28 %31;\n-                    %39 : int = arith.divsi %38 %35;\n-                    %40 : tensor<x32, int> = tt.make_range @start=\"0\" @end=\"32\";\n-                    %41 : int = arith.muli %37 %24;\n-                    %42 : tensor<x32, int> = tt.splat %41;\n-                    %43 : tensor<x32, int> = arith.addi %42 %40;\n-                    %44 : tensor<x32, int> = tt.splat %15;\n-                    %45 : tensor<x32, int> = arith.remsi %43 %44;\n-                    %46 : tensor<x64, int> = tt.make_range @start=\"0\" @end=\"64\";\n-                    %47 : int = arith.muli %39 %25;\n-                    %48 : tensor<x64, int> = tt.splat %47;\n-                    %49 : tensor<x64, int> = arith.addi %48 %46;\n-                    %50 : tensor<x64, int> = tt.splat %16;\n-                    %51 : tensor<x64, int> = arith.remsi %49 %50;\n-                    %52 : tensor<x32, int> = tt.make_range @start=\"0\" @end=\"32\";\n-                    %53 : tensor<x32, x1, int> = tt.expand_dims %45 @\"1\";\n-                    %54 : tensor<x32, x1, int> = tt.splat %18;\n-                    %55 : tensor<x32, x1, int> = arith.muli %53 %54;\n-                    %56 : tensor<x1, x32, int> = tt.expand_dims %52 @\"0\";\n-                    %57 : tensor<x1, x32, int> = tt.splat %21;\n-                    %58 : tensor<x1, x32, int> = arith.muli %56 %57;\n-                    %59 : tensor<x32, x32, int> = tt.broadcast %55;\n-                    %60 : tensor<x32, x32, int> = tt.broadcast %58;\n-                    %61 : tensor<x32, x32, int> = arith.addi %59 %60;\n-                    %62 : tensor<x32, x32, ptr<float>> = tt.splat %12;\n-                    %63 : tensor<x32, x32, ptr<float>> = tt.addptr %62 %61;\n-                    %64 : tensor<x32, x1, int> = tt.expand_dims %52 @\"1\";\n-                    %65 : tensor<x32, x1, int> = tt.splat %19;\n-                    %66 : tensor<x32, x1, int> = arith.muli %64 %65;\n-                    %67 : tensor<x1, x64, int> = tt.expand_dims %51 @\"0\";\n-                    %68 : tensor<x1, x64, int> = tt.splat %22;\n-                    %69 : tensor<x1, x64, int> = arith.muli %67 %68;\n-                    %70 : tensor<x32, x64, int> = tt.broadcast %66;\n-                    %71 : tensor<x32, x64, int> = tt.broadcast %69;\n-                    %72 : tensor<x32, x64, int> = arith.addi %70 %71;\n-                    %73 : tensor<x32, x64, ptr<float>> = tt.splat %13;\n-                    %74 : tensor<x32, x64, ptr<float>> = tt.addptr %73 %72;\n-                    %75 : tensor<x32, x64, float> = arith.constant @\"0.0\";\n-                    %76 : int = arith.constant @\"0\";\n-                    %77 : int = tt.call %17 @\"cdiv_int_32_int\";\n-                    %78 : int = arith.constant @\"1\";\n-                    %79 : Tuple<tensor<x32, x64, float>, tensor<x32, x32, ptr<float>>, tensor<x32, x64, ptr<float>>> = scf.for %76 %77 %78 %75 %63 %74 (%80 : int, %81 : tensor<x32, x64, float>, %82 : tensor<x32, x32, ptr<float>>, %83 : tensor<x32, x64, ptr<float>>)Tuple<tensor<x32, x64, float>, tensor<x32, x32, ptr<float>>, tensor<x32, x64, ptr<float>>> -> {\n-                        %84 : tensor<x1, x32, int> = tt.expand_dims %52 @\"0\";\n-                        %85 : int = arith.muli %80 %26;\n-                        %86 : int = arith.subi %17 %85;\n-                        %87 : tensor<x1, x32, int> = tt.splat %86;\n-                        %88 : tensor<x1, x32, boolean> = arith.cmpi %84 %87 @\"slt\";\n-                        %89 : tensor<x32, x32, boolean> = tt.broadcast %88;\n-                        %90 : tensor<x32, x32, float> = arith.constant @\"0.0\";\n-                        %91 : tensor<x32, x32, float> = tt.load %82 %89 %90;\n-                        %92 : tensor<x32, x1, int> = tt.expand_dims %52 @\"1\";\n-                        %93 : int = arith.muli %80 %26;\n-                        %94 : int = arith.subi %17 %93;\n-                        %95 : tensor<x32, x1, int> = tt.splat %94;\n-                        %96 : tensor<x32, x1, boolean> = arith.cmpi %92 %95 @\"slt\";\n-                        %97 : tensor<x32, x64, boolean> = tt.broadcast %96;\n-                        %98 : tensor<x32, x64, float> = arith.constant @\"0.0\";\n-                        %99 : tensor<x32, x64, float> = tt.load %83 %97 %98;\n-                        %100 : tensor<x32, x64, float> = arith.constant @\"0.0\";\n-                        %101 : tensor<x32, x64, float> = tt.dot %91 %99 %100;\n-                        %102 : tensor<x32, x64, float> = arith.addf %81 %101;\n-                        %103 : int = arith.muli %26 %21;\n-                        %104 : tensor<x32, x32, int> = tt.splat %103;\n-                        %105 : tensor<x32, x32, ptr<float>> = tt.addptr %82 %104;\n-                        %106 : int = arith.muli %26 %19;\n-                        %107 : tensor<x32, x64, int> = tt.splat %106;\n-                        %108 : tensor<x32, x64, ptr<float>> = tt.addptr %83 %107;\n+                tt.func @sym_name=\"matmul_kernel_ptr<java.type.primitive<float>>_ptr<java.type.primitive<float>>_ptr<java.type.primitive<float>>_int_int_int_int_1_int_1_int_1_32_64_32_8_false_void\" (%12 : ptr<java.type:\"float\">, %13 : ptr<java.type:\"float\">, %14 : ptr<java.type:\"float\">, %15 : java.type:\"int\", %16 : java.type:\"int\", %17 : java.type:\"int\", %18 : java.type:\"int\", %19 : java.type:\"int\", %20 : java.type:\"int\")java.type:\"void\" -> {\n+                    %21 : java.type:\"int\" = arith.constant @\"1\";\n+                    %22 : java.type:\"int\" = arith.constant @\"1\";\n+                    %23 : java.type:\"int\" = arith.constant @\"1\";\n+                    %24 : java.type:\"int\" = arith.constant @\"32\";\n+                    %25 : java.type:\"int\" = arith.constant @\"64\";\n+                    %26 : java.type:\"int\" = arith.constant @\"32\";\n+                    %27 : java.type:\"int\" = arith.constant @\"8\";\n+                    %28 : java.type:\"int\" = tt.get_program_id @\"0\";\n+                    %29 : java.type:\"int\" = tt.call %15 @\"cdiv_int_32_int\";\n+                    %30 : java.type:\"int\" = tt.call %16 @\"cdiv_int_64_int\";\n+                    %31 : java.type:\"int\" = arith.muli %27 %30;\n+                    %32 : java.type:\"int\" = arith.divsi %28 %31;\n+                    %33 : java.type:\"int\" = arith.muli %32 %27;\n+                    %34 : java.type:\"int\" = arith.subi %29 %33;\n+                    %35 : java.type:\"int\" = arith.minsi %34 %27;\n+                    %36 : java.type:\"int\" = arith.remsi %28 %35;\n+                    %37 : java.type:\"int\" = arith.addi %33 %36;\n+                    %38 : java.type:\"int\" = arith.remsi %28 %31;\n+                    %39 : java.type:\"int\" = arith.divsi %38 %35;\n+                    %40 : tensor<x32, java.type:\"int\"> = tt.make_range @start=\"0\" @end=\"32\";\n+                    %41 : java.type:\"int\" = arith.muli %37 %24;\n+                    %42 : tensor<x32, java.type:\"int\"> = tt.splat %41;\n+                    %43 : tensor<x32, java.type:\"int\"> = arith.addi %42 %40;\n+                    %44 : tensor<x32, java.type:\"int\"> = tt.splat %15;\n+                    %45 : tensor<x32, java.type:\"int\"> = arith.remsi %43 %44;\n+                    %46 : tensor<x64, java.type:\"int\"> = tt.make_range @start=\"0\" @end=\"64\";\n+                    %47 : java.type:\"int\" = arith.muli %39 %25;\n+                    %48 : tensor<x64, java.type:\"int\"> = tt.splat %47;\n+                    %49 : tensor<x64, java.type:\"int\"> = arith.addi %48 %46;\n+                    %50 : tensor<x64, java.type:\"int\"> = tt.splat %16;\n+                    %51 : tensor<x64, java.type:\"int\"> = arith.remsi %49 %50;\n+                    %52 : tensor<x32, java.type:\"int\"> = tt.make_range @start=\"0\" @end=\"32\";\n+                    %53 : tensor<x32, x1, java.type:\"int\"> = tt.expand_dims %45 @\"1\";\n+                    %54 : tensor<x32, x1, java.type:\"int\"> = tt.splat %18;\n+                    %55 : tensor<x32, x1, java.type:\"int\"> = arith.muli %53 %54;\n+                    %56 : tensor<x1, x32, java.type:\"int\"> = tt.expand_dims %52 @\"0\";\n+                    %57 : tensor<x1, x32, java.type:\"int\"> = tt.splat %21;\n+                    %58 : tensor<x1, x32, java.type:\"int\"> = arith.muli %56 %57;\n+                    %59 : tensor<x32, x32, java.type:\"int\"> = tt.broadcast %55;\n+                    %60 : tensor<x32, x32, java.type:\"int\"> = tt.broadcast %58;\n+                    %61 : tensor<x32, x32, java.type:\"int\"> = arith.addi %59 %60;\n+                    %62 : tensor<x32, x32, ptr<java.type:\"float\">> = tt.splat %12;\n+                    %63 : tensor<x32, x32, ptr<java.type:\"float\">> = tt.addptr %62 %61;\n+                    %64 : tensor<x32, x1, java.type:\"int\"> = tt.expand_dims %52 @\"1\";\n+                    %65 : tensor<x32, x1, java.type:\"int\"> = tt.splat %19;\n+                    %66 : tensor<x32, x1, java.type:\"int\"> = arith.muli %64 %65;\n+                    %67 : tensor<x1, x64, java.type:\"int\"> = tt.expand_dims %51 @\"0\";\n+                    %68 : tensor<x1, x64, java.type:\"int\"> = tt.splat %22;\n+                    %69 : tensor<x1, x64, java.type:\"int\"> = arith.muli %67 %68;\n+                    %70 : tensor<x32, x64, java.type:\"int\"> = tt.broadcast %66;\n+                    %71 : tensor<x32, x64, java.type:\"int\"> = tt.broadcast %69;\n+                    %72 : tensor<x32, x64, java.type:\"int\"> = arith.addi %70 %71;\n+                    %73 : tensor<x32, x64, ptr<java.type:\"float\">> = tt.splat %13;\n+                    %74 : tensor<x32, x64, ptr<java.type:\"float\">> = tt.addptr %73 %72;\n+                    %75 : tensor<x32, x64, java.type:\"float\"> = arith.constant @\"0.0\";\n+                    %76 : java.type:\"int\" = arith.constant @\"0\";\n+                    %77 : java.type:\"int\" = tt.call %17 @\"cdiv_int_32_int\";\n+                    %78 : java.type:\"int\" = arith.constant @\"1\";\n+                    %79 : Tuple<tensor<x32, x64, java.type:\"float\">, tensor<x32, x32, ptr<java.type:\"float\">>, tensor<x32, x64, ptr<java.type:\"float\">>> = scf.for %76 %77 %78 %75 %63 %74 (%80 : java.type:\"int\", %81 : tensor<x32, x64, java.type:\"float\">, %82 : tensor<x32, x32, ptr<java.type:\"float\">>, %83 : tensor<x32, x64, ptr<java.type:\"float\">>)Tuple<tensor<x32, x64, java.type:\"float\">, tensor<x32, x32, ptr<java.type:\"float\">>, tensor<x32, x64, ptr<java.type:\"float\">>> -> {\n+                        %84 : tensor<x1, x32, java.type:\"int\"> = tt.expand_dims %52 @\"0\";\n+                        %85 : java.type:\"int\" = arith.muli %80 %26;\n+                        %86 : java.type:\"int\" = arith.subi %17 %85;\n+                        %87 : tensor<x1, x32, java.type:\"int\"> = tt.splat %86;\n+                        %88 : tensor<x1, x32, java.type:\"boolean\"> = arith.cmpi %84 %87 @\"slt\";\n+                        %89 : tensor<x32, x32, java.type:\"boolean\"> = tt.broadcast %88;\n+                        %90 : tensor<x32, x32, java.type:\"float\"> = arith.constant @\"0.0\";\n+                        %91 : tensor<x32, x32, java.type:\"float\"> = tt.load %82 %89 %90;\n+                        %92 : tensor<x32, x1, java.type:\"int\"> = tt.expand_dims %52 @\"1\";\n+                        %93 : java.type:\"int\" = arith.muli %80 %26;\n+                        %94 : java.type:\"int\" = arith.subi %17 %93;\n+                        %95 : tensor<x32, x1, java.type:\"int\"> = tt.splat %94;\n+                        %96 : tensor<x32, x1, java.type:\"boolean\"> = arith.cmpi %92 %95 @\"slt\";\n+                        %97 : tensor<x32, x64, java.type:\"boolean\"> = tt.broadcast %96;\n+                        %98 : tensor<x32, x64, java.type:\"float\"> = arith.constant @\"0.0\";\n+                        %99 : tensor<x32, x64, java.type:\"float\"> = tt.load %83 %97 %98;\n+                        %100 : tensor<x32, x64, java.type:\"float\"> = arith.constant @\"0.0\";\n+                        %101 : tensor<x32, x64, java.type:\"float\"> = tt.dot %91 %99 %100;\n+                        %102 : tensor<x32, x64, java.type:\"float\"> = arith.addf %81 %101;\n+                        %103 : java.type:\"int\" = arith.muli %26 %21;\n+                        %104 : tensor<x32, x32, java.type:\"int\"> = tt.splat %103;\n+                        %105 : tensor<x32, x32, ptr<java.type:\"float\">> = tt.addptr %82 %104;\n+                        %106 : java.type:\"int\" = arith.muli %26 %19;\n+                        %107 : tensor<x32, x64, java.type:\"int\"> = tt.splat %106;\n+                        %108 : tensor<x32, x64, ptr<java.type:\"float\">> = tt.addptr %83 %107;\n@@ -425,29 +425,29 @@\n-                    %109 : tensor<x32, x64, float> = tuple.load %79 @\"0\";\n-                    %110 : tensor<x32, x32, ptr<float>> = tuple.load %79 @\"1\";\n-                    %111 : tensor<x32, x64, ptr<float>> = tuple.load %79 @\"2\";\n-                    %112 : int = arith.muli %37 %24;\n-                    %113 : tensor<x32, int> = tt.splat %112;\n-                    %114 : tensor<x32, int> = arith.addi %113 %40;\n-                    %115 : int = arith.muli %39 %25;\n-                    %116 : tensor<x64, int> = tt.splat %115;\n-                    %117 : tensor<x64, int> = arith.addi %116 %46;\n-                    %118 : tensor<x32, x1, int> = tt.expand_dims %114 @\"1\";\n-                    %119 : tensor<x32, x1, int> = tt.splat %20;\n-                    %120 : tensor<x32, x1, int> = arith.muli %119 %118;\n-                    %121 : tensor<x1, x64, int> = tt.expand_dims %117 @\"0\";\n-                    %122 : tensor<x1, x64, int> = tt.splat %23;\n-                    %123 : tensor<x1, x64, int> = arith.muli %122 %121;\n-                    %124 : tensor<x32, x64, int> = tt.broadcast %120;\n-                    %125 : tensor<x32, x64, int> = tt.broadcast %123;\n-                    %126 : tensor<x32, x64, int> = arith.addi %124 %125;\n-                    %127 : tensor<x32, x64, ptr<float>> = tt.splat %14;\n-                    %128 : tensor<x32, x64, ptr<float>> = tt.addptr %127 %126;\n-                    %129 : tensor<x32, x1, int> = tt.expand_dims %114 @\"1\";\n-                    %130 : tensor<x32, x1, int> = tt.splat %15;\n-                    %131 : tensor<x32, x1, boolean> = arith.cmpi %129 %130 @\"slt\";\n-                    %132 : tensor<x1, x64, int> = tt.expand_dims %117 @\"0\";\n-                    %133 : tensor<x1, x64, int> = tt.splat %16;\n-                    %134 : tensor<x1, x64, boolean> = arith.cmpi %132 %133 @\"slt\";\n-                    %135 : tensor<x32, x64, boolean> = tt.broadcast %131;\n-                    %136 : tensor<x32, x64, boolean> = tt.broadcast %134;\n-                    %137 : tensor<x32, x64, boolean> = arith.andi %135 %136;\n+                    %109 : tensor<x32, x64, java.type:\"float\"> = tuple.load %79 @\"0\";\n+                    %110 : tensor<x32, x32, ptr<java.type:\"float\">> = tuple.load %79 @\"1\";\n+                    %111 : tensor<x32, x64, ptr<java.type:\"float\">> = tuple.load %79 @\"2\";\n+                    %112 : java.type:\"int\" = arith.muli %37 %24;\n+                    %113 : tensor<x32, java.type:\"int\"> = tt.splat %112;\n+                    %114 : tensor<x32, java.type:\"int\"> = arith.addi %113 %40;\n+                    %115 : java.type:\"int\" = arith.muli %39 %25;\n+                    %116 : tensor<x64, java.type:\"int\"> = tt.splat %115;\n+                    %117 : tensor<x64, java.type:\"int\"> = arith.addi %116 %46;\n+                    %118 : tensor<x32, x1, java.type:\"int\"> = tt.expand_dims %114 @\"1\";\n+                    %119 : tensor<x32, x1, java.type:\"int\"> = tt.splat %20;\n+                    %120 : tensor<x32, x1, java.type:\"int\"> = arith.muli %119 %118;\n+                    %121 : tensor<x1, x64, java.type:\"int\"> = tt.expand_dims %117 @\"0\";\n+                    %122 : tensor<x1, x64, java.type:\"int\"> = tt.splat %23;\n+                    %123 : tensor<x1, x64, java.type:\"int\"> = arith.muli %122 %121;\n+                    %124 : tensor<x32, x64, java.type:\"int\"> = tt.broadcast %120;\n+                    %125 : tensor<x32, x64, java.type:\"int\"> = tt.broadcast %123;\n+                    %126 : tensor<x32, x64, java.type:\"int\"> = arith.addi %124 %125;\n+                    %127 : tensor<x32, x64, ptr<java.type:\"float\">> = tt.splat %14;\n+                    %128 : tensor<x32, x64, ptr<java.type:\"float\">> = tt.addptr %127 %126;\n+                    %129 : tensor<x32, x1, java.type:\"int\"> = tt.expand_dims %114 @\"1\";\n+                    %130 : tensor<x32, x1, java.type:\"int\"> = tt.splat %15;\n+                    %131 : tensor<x32, x1, java.type:\"boolean\"> = arith.cmpi %129 %130 @\"slt\";\n+                    %132 : tensor<x1, x64, java.type:\"int\"> = tt.expand_dims %117 @\"0\";\n+                    %133 : tensor<x1, x64, java.type:\"int\"> = tt.splat %16;\n+                    %134 : tensor<x1, x64, java.type:\"boolean\"> = arith.cmpi %132 %133 @\"slt\";\n+                    %135 : tensor<x32, x64, java.type:\"boolean\"> = tt.broadcast %131;\n+                    %136 : tensor<x32, x64, java.type:\"boolean\"> = tt.broadcast %134;\n+                    %137 : tensor<x32, x64, java.type:\"boolean\"> = arith.andi %135 %136;\n","filename":"cr-examples\/triton\/src\/test\/java\/oracle\/code\/triton\/TestMatrix.java","additions":249,"deletions":249,"binary":false,"changes":498,"status":"modified"},{"patch":"@@ -41,7 +41,7 @@\n-            module ()void -> {\n-                tt.func @\"cdiv_int_32_int\" (%0 : int)int -> {\n-                    %1 : int = arith.constant @\"32\";\n-                    %2 : int = arith.addi %0 %1;\n-                    %3 : int = arith.constant @\"1\";\n-                    %4 : int = arith.subi %2 %3;\n-                    %5 : int = arith.divsi %4 %1;\n+            module ()java.type:\"void\" -> {\n+                tt.func @\"cdiv_int_32_int\" (%0 : java.type:\"int\")java.type:\"int\" -> {\n+                    %1 : java.type:\"int\" = arith.constant @\"32\";\n+                    %2 : java.type:\"int\" = arith.addi %0 %1;\n+                    %3 : java.type:\"int\" = arith.constant @\"1\";\n+                    %4 : java.type:\"int\" = arith.subi %2 %3;\n+                    %5 : java.type:\"int\" = arith.divsi %4 %1;\n@@ -50,6 +50,6 @@\n-                tt.func @\"cdiv_int_64_int\" (%6 : int)int -> {\n-                    %7 : int = arith.constant @\"64\";\n-                    %8 : int = arith.addi %6 %7;\n-                    %9 : int = arith.constant @\"1\";\n-                    %10 : int = arith.subi %8 %9;\n-                    %11 : int = arith.divsi %10 %7;\n+                tt.func @\"cdiv_int_64_int\" (%6 : java.type:\"int\")java.type:\"int\" -> {\n+                    %7 : java.type:\"int\" = arith.constant @\"64\";\n+                    %8 : java.type:\"int\" = arith.addi %6 %7;\n+                    %9 : java.type:\"int\" = arith.constant @\"1\";\n+                    %10 : java.type:\"int\" = arith.subi %8 %9;\n+                    %11 : java.type:\"int\" = arith.divsi %10 %7;\n@@ -58,85 +58,85 @@\n-                tt.func @sym_name=\"matmul_kernel_fp16_ptr<oracle.code.triton.Float16>_ptr<oracle.code.triton.Float16>_ptr<oracle.code.triton.Float16>_int_int_int_int_1_int_1_int_1_32_64_32_8_false_void\" (%12 : ptr<oracle.code.triton.Float16>, %13 : ptr<oracle.code.triton.Float16>, %14 : ptr<oracle.code.triton.Float16>, %15 : int, %16 : int, %17 : int, %18 : int, %19 : int, %20 : int)void -> {\n-                    %21 : int = arith.constant @value=\"1\";\n-                    %22 : int = arith.constant @value=\"1\";\n-                    %23 : int = arith.constant @value=\"1\";\n-                    %24 : int = arith.constant @value=\"32\";\n-                    %25 : int = arith.constant @value=\"64\";\n-                    %26 : int = arith.constant @value=\"32\";\n-                    %27 : int = arith.constant @value=\"8\";\n-                    %28 : int = tt.get_program_id @axis=\"0\";\n-                    %29 : int = tt.call %15 @callee=\"cdiv_int_32_int\";\n-                    %30 : int = tt.call %16 @callee=\"cdiv_int_64_int\";\n-                    %31 : int = arith.muli %27 %30;\n-                    %32 : int = arith.divsi %28 %31;\n-                    %33 : int = arith.muli %32 %27;\n-                    %34 : int = arith.subi %29 %33;\n-                    %35 : int = arith.minsi %34 %27;\n-                    %36 : int = arith.remsi %28 %35;\n-                    %37 : int = arith.addi %33 %36;\n-                    %38 : int = arith.remsi %28 %31;\n-                    %39 : int = arith.divsi %38 %35;\n-                    %40 : tensor<x32, int> = tt.make_range @start=\"0\" @end=\"32\";\n-                    %41 : int = arith.muli %37 %24;\n-                    %42 : tensor<x32, int> = tt.splat %41;\n-                    %43 : tensor<x32, int> = arith.addi %42 %40;\n-                    %44 : tensor<x32, int> = tt.splat %15;\n-                    %45 : tensor<x32, int> = arith.remsi %43 %44;\n-                    %46 : tensor<x64, int> = tt.make_range @start=\"0\" @end=\"64\";\n-                    %47 : int = arith.muli %39 %25;\n-                    %48 : tensor<x64, int> = tt.splat %47;\n-                    %49 : tensor<x64, int> = arith.addi %48 %46;\n-                    %50 : tensor<x64, int> = tt.splat %16;\n-                    %51 : tensor<x64, int> = arith.remsi %49 %50;\n-                    %52 : tensor<x32, int> = tt.make_range @start=\"0\" @end=\"32\";\n-                    %53 : tensor<x32, x1, int> = tt.expand_dims %45 @axis=\"1\";\n-                    %54 : tensor<x32, x1, int> = tt.splat %18;\n-                    %55 : tensor<x32, x1, int> = arith.muli %53 %54;\n-                    %56 : tensor<x1, x32, int> = tt.expand_dims %52 @axis=\"0\";\n-                    %57 : tensor<x1, x32, int> = tt.splat %21;\n-                    %58 : tensor<x1, x32, int> = arith.muli %56 %57;\n-                    %59 : tensor<x32, x32, int> = tt.broadcast %55;\n-                    %60 : tensor<x32, x32, int> = tt.broadcast %58;\n-                    %61 : tensor<x32, x32, int> = arith.addi %59 %60;\n-                    %62 : tensor<x32, x32, ptr<oracle.code.triton.Float16>> = tt.splat %12;\n-                    %63 : tensor<x32, x32, ptr<oracle.code.triton.Float16>> = tt.addptr %62 %61;\n-                    %64 : tensor<x32, x1, int> = tt.expand_dims %52 @axis=\"1\";\n-                    %65 : tensor<x32, x1, int> = tt.splat %19;\n-                    %66 : tensor<x32, x1, int> = arith.muli %64 %65;\n-                    %67 : tensor<x1, x64, int> = tt.expand_dims %51 @axis=\"0\";\n-                    %68 : tensor<x1, x64, int> = tt.splat %22;\n-                    %69 : tensor<x1, x64, int> = arith.muli %67 %68;\n-                    %70 : tensor<x32, x64, int> = tt.broadcast %66;\n-                    %71 : tensor<x32, x64, int> = tt.broadcast %69;\n-                    %72 : tensor<x32, x64, int> = arith.addi %70 %71;\n-                    %73 : tensor<x32, x64, ptr<oracle.code.triton.Float16>> = tt.splat %13;\n-                    %74 : tensor<x32, x64, ptr<oracle.code.triton.Float16>> = tt.addptr %73 %72;\n-                    %75 : tensor<x32, x64, float> = arith.constant @value=\"0.0\";\n-                    %76 : int = arith.constant @value=\"0\";\n-                    %77 : int = tt.call %17 @callee=\"cdiv_int_32_int\";\n-                    %78 : int = arith.constant @value=\"1\";\n-                    %79 : Tuple<tensor<x32, x64, float>, tensor<x32, x32, ptr<oracle.code.triton.Float16>>, tensor<x32, x64, ptr<oracle.code.triton.Float16>>> = scf.for %76 %77 %78 %75 %63 %74 (%80 : int, %81 : tensor<x32, x64, float>, %82 : tensor<x32, x32, ptr<oracle.code.triton.Float16>>, %83 : tensor<x32, x64, ptr<oracle.code.triton.Float16>>)Tuple<tensor<x32, x64, float>, tensor<x32, x32, ptr<oracle.code.triton.Float16>>, tensor<x32, x64, ptr<oracle.code.triton.Float16>>> -> {\n-                        %84 : tensor<x1, x32, int> = tt.expand_dims %52 @axis=\"0\";\n-                        %85 : int = arith.muli %80 %26;\n-                        %86 : int = arith.subi %17 %85;\n-                        %87 : tensor<x1, x32, int> = tt.splat %86;\n-                        %88 : tensor<x1, x32, boolean> = arith.cmpi %84 %87 @predicate=\"slt\";\n-                        %89 : tensor<x32, x32, boolean> = tt.broadcast %88;\n-                        %90 : tensor<x32, x32, oracle.code.triton.Float16> = arith.constant @value=\"0.0\";\n-                        %91 : tensor<x32, x32, oracle.code.triton.Float16> = tt.load %82 %89 %90;\n-                        %92 : tensor<x32, x1, int> = tt.expand_dims %52 @axis=\"1\";\n-                        %93 : int = arith.muli %80 %26;\n-                        %94 : int = arith.subi %17 %93;\n-                        %95 : tensor<x32, x1, int> = tt.splat %94;\n-                        %96 : tensor<x32, x1, boolean> = arith.cmpi %92 %95 @predicate=\"slt\";\n-                        %97 : tensor<x32, x64, boolean> = tt.broadcast %96;\n-                        %98 : tensor<x32, x64, oracle.code.triton.Float16> = arith.constant @value=\"0.0\";\n-                        %99 : tensor<x32, x64, oracle.code.triton.Float16> = tt.load %83 %97 %98;\n-                        %100 : tensor<x32, x64, float> = arith.constant @value=\"0.0\";\n-                        %101 : tensor<x32, x64, float> = tt.dot %91 %99 %100;\n-                        %102 : tensor<x32, x64, float> = arith.addf %81 %101;\n-                        %103 : int = arith.muli %26 %21;\n-                        %104 : tensor<x32, x32, int> = tt.splat %103;\n-                        %105 : tensor<x32, x32, ptr<oracle.code.triton.Float16>> = tt.addptr %82 %104;\n-                        %106 : int = arith.muli %26 %19;\n-                        %107 : tensor<x32, x64, int> = tt.splat %106;\n-                        %108 : tensor<x32, x64, ptr<oracle.code.triton.Float16>> = tt.addptr %83 %107;\n+                tt.func @sym_name=\"matmul_kernel_fp16_ptr<java.type.class<oracle.code.triton.Float16, java.type.primitive<void>>>_ptr<java.type.class<oracle.code.triton.Float16, java.type.primitive<void>>>_ptr<java.type.class<oracle.code.triton.Float16, java.type.primitive<void>>>_int_int_int_int_1_int_1_int_1_32_64_32_8_false_void\" (%12 : ptr<java.type:\"oracle.code.triton.Float16\">, %13 : ptr<java.type:\"oracle.code.triton.Float16\">, %14 : ptr<java.type:\"oracle.code.triton.Float16\">, %15 : java.type:\"int\", %16 : java.type:\"int\", %17 : java.type:\"int\", %18 : java.type:\"int\", %19 : java.type:\"int\", %20 : java.type:\"int\")java.type:\"void\" -> {\n+                    %21 : java.type:\"int\" = arith.constant @value=\"1\";\n+                    %22 : java.type:\"int\" = arith.constant @value=\"1\";\n+                    %23 : java.type:\"int\" = arith.constant @value=\"1\";\n+                    %24 : java.type:\"int\" = arith.constant @value=\"32\";\n+                    %25 : java.type:\"int\" = arith.constant @value=\"64\";\n+                    %26 : java.type:\"int\" = arith.constant @value=\"32\";\n+                    %27 : java.type:\"int\" = arith.constant @value=\"8\";\n+                    %28 : java.type:\"int\" = tt.get_program_id @axis=\"0\";\n+                    %29 : java.type:\"int\" = tt.call %15 @callee=\"cdiv_int_32_int\";\n+                    %30 : java.type:\"int\" = tt.call %16 @callee=\"cdiv_int_64_int\";\n+                    %31 : java.type:\"int\" = arith.muli %27 %30;\n+                    %32 : java.type:\"int\" = arith.divsi %28 %31;\n+                    %33 : java.type:\"int\" = arith.muli %32 %27;\n+                    %34 : java.type:\"int\" = arith.subi %29 %33;\n+                    %35 : java.type:\"int\" = arith.minsi %34 %27;\n+                    %36 : java.type:\"int\" = arith.remsi %28 %35;\n+                    %37 : java.type:\"int\" = arith.addi %33 %36;\n+                    %38 : java.type:\"int\" = arith.remsi %28 %31;\n+                    %39 : java.type:\"int\" = arith.divsi %38 %35;\n+                    %40 : tensor<x32, java.type:\"int\"> = tt.make_range @start=\"0\" @end=\"32\";\n+                    %41 : java.type:\"int\" = arith.muli %37 %24;\n+                    %42 : tensor<x32, java.type:\"int\"> = tt.splat %41;\n+                    %43 : tensor<x32, java.type:\"int\"> = arith.addi %42 %40;\n+                    %44 : tensor<x32, java.type:\"int\"> = tt.splat %15;\n+                    %45 : tensor<x32, java.type:\"int\"> = arith.remsi %43 %44;\n+                    %46 : tensor<x64, java.type:\"int\"> = tt.make_range @start=\"0\" @end=\"64\";\n+                    %47 : java.type:\"int\" = arith.muli %39 %25;\n+                    %48 : tensor<x64, java.type:\"int\"> = tt.splat %47;\n+                    %49 : tensor<x64, java.type:\"int\"> = arith.addi %48 %46;\n+                    %50 : tensor<x64, java.type:\"int\"> = tt.splat %16;\n+                    %51 : tensor<x64, java.type:\"int\"> = arith.remsi %49 %50;\n+                    %52 : tensor<x32, java.type:\"int\"> = tt.make_range @start=\"0\" @end=\"32\";\n+                    %53 : tensor<x32, x1, java.type:\"int\"> = tt.expand_dims %45 @axis=\"1\";\n+                    %54 : tensor<x32, x1, java.type:\"int\"> = tt.splat %18;\n+                    %55 : tensor<x32, x1, java.type:\"int\"> = arith.muli %53 %54;\n+                    %56 : tensor<x1, x32, java.type:\"int\"> = tt.expand_dims %52 @axis=\"0\";\n+                    %57 : tensor<x1, x32, java.type:\"int\"> = tt.splat %21;\n+                    %58 : tensor<x1, x32, java.type:\"int\"> = arith.muli %56 %57;\n+                    %59 : tensor<x32, x32, java.type:\"int\"> = tt.broadcast %55;\n+                    %60 : tensor<x32, x32, java.type:\"int\"> = tt.broadcast %58;\n+                    %61 : tensor<x32, x32, java.type:\"int\"> = arith.addi %59 %60;\n+                    %62 : tensor<x32, x32, ptr<java.type:\"oracle.code.triton.Float16\">> = tt.splat %12;\n+                    %63 : tensor<x32, x32, ptr<java.type:\"oracle.code.triton.Float16\">> = tt.addptr %62 %61;\n+                    %64 : tensor<x32, x1, java.type:\"int\"> = tt.expand_dims %52 @axis=\"1\";\n+                    %65 : tensor<x32, x1, java.type:\"int\"> = tt.splat %19;\n+                    %66 : tensor<x32, x1, java.type:\"int\"> = arith.muli %64 %65;\n+                    %67 : tensor<x1, x64, java.type:\"int\"> = tt.expand_dims %51 @axis=\"0\";\n+                    %68 : tensor<x1, x64, java.type:\"int\"> = tt.splat %22;\n+                    %69 : tensor<x1, x64, java.type:\"int\"> = arith.muli %67 %68;\n+                    %70 : tensor<x32, x64, java.type:\"int\"> = tt.broadcast %66;\n+                    %71 : tensor<x32, x64, java.type:\"int\"> = tt.broadcast %69;\n+                    %72 : tensor<x32, x64, java.type:\"int\"> = arith.addi %70 %71;\n+                    %73 : tensor<x32, x64, ptr<java.type:\"oracle.code.triton.Float16\">> = tt.splat %13;\n+                    %74 : tensor<x32, x64, ptr<java.type:\"oracle.code.triton.Float16\">> = tt.addptr %73 %72;\n+                    %75 : tensor<x32, x64, java.type:\"float\"> = arith.constant @value=\"0.0\";\n+                    %76 : java.type:\"int\" = arith.constant @value=\"0\";\n+                    %77 : java.type:\"int\" = tt.call %17 @callee=\"cdiv_int_32_int\";\n+                    %78 : java.type:\"int\" = arith.constant @value=\"1\";\n+                    %79 : Tuple<tensor<x32, x64, java.type:\"float\">, tensor<x32, x32, ptr<java.type:\"oracle.code.triton.Float16\">>, tensor<x32, x64, ptr<java.type:\"oracle.code.triton.Float16\">>> = scf.for %76 %77 %78 %75 %63 %74 (%80 : java.type:\"int\", %81 : tensor<x32, x64, java.type:\"float\">, %82 : tensor<x32, x32, ptr<java.type:\"oracle.code.triton.Float16\">>, %83 : tensor<x32, x64, ptr<java.type:\"oracle.code.triton.Float16\">>)Tuple<tensor<x32, x64, java.type:\"float\">, tensor<x32, x32, ptr<java.type:\"oracle.code.triton.Float16\">>, tensor<x32, x64, ptr<java.type:\"oracle.code.triton.Float16\">>> -> {\n+                        %84 : tensor<x1, x32, java.type:\"int\"> = tt.expand_dims %52 @axis=\"0\";\n+                        %85 : java.type:\"int\" = arith.muli %80 %26;\n+                        %86 : java.type:\"int\" = arith.subi %17 %85;\n+                        %87 : tensor<x1, x32, java.type:\"int\"> = tt.splat %86;\n+                        %88 : tensor<x1, x32, java.type:\"boolean\"> = arith.cmpi %84 %87 @predicate=\"slt\";\n+                        %89 : tensor<x32, x32, java.type:\"boolean\"> = tt.broadcast %88;\n+                        %90 : tensor<x32, x32, java.type:\"oracle.code.triton.Float16\"> = arith.constant @value=\"0.0\";\n+                        %91 : tensor<x32, x32, java.type:\"oracle.code.triton.Float16\"> = tt.load %82 %89 %90;\n+                        %92 : tensor<x32, x1, java.type:\"int\"> = tt.expand_dims %52 @axis=\"1\";\n+                        %93 : java.type:\"int\" = arith.muli %80 %26;\n+                        %94 : java.type:\"int\" = arith.subi %17 %93;\n+                        %95 : tensor<x32, x1, java.type:\"int\"> = tt.splat %94;\n+                        %96 : tensor<x32, x1, java.type:\"boolean\"> = arith.cmpi %92 %95 @predicate=\"slt\";\n+                        %97 : tensor<x32, x64, java.type:\"boolean\"> = tt.broadcast %96;\n+                        %98 : tensor<x32, x64, java.type:\"oracle.code.triton.Float16\"> = arith.constant @value=\"0.0\";\n+                        %99 : tensor<x32, x64, java.type:\"oracle.code.triton.Float16\"> = tt.load %83 %97 %98;\n+                        %100 : tensor<x32, x64, java.type:\"float\"> = arith.constant @value=\"0.0\";\n+                        %101 : tensor<x32, x64, java.type:\"float\"> = tt.dot %91 %99 %100;\n+                        %102 : tensor<x32, x64, java.type:\"float\"> = arith.addf %81 %101;\n+                        %103 : java.type:\"int\" = arith.muli %26 %21;\n+                        %104 : tensor<x32, x32, java.type:\"int\"> = tt.splat %103;\n+                        %105 : tensor<x32, x32, ptr<java.type:\"oracle.code.triton.Float16\">> = tt.addptr %82 %104;\n+                        %106 : java.type:\"int\" = arith.muli %26 %19;\n+                        %107 : tensor<x32, x64, java.type:\"int\"> = tt.splat %106;\n+                        %108 : tensor<x32, x64, ptr<java.type:\"oracle.code.triton.Float16\">> = tt.addptr %83 %107;\n@@ -145,30 +145,30 @@\n-                    %109 : tensor<x32, x64, float> = tuple.load %79 @\"0\";\n-                    %110 : tensor<x32, x32, ptr<oracle.code.triton.Float16>> = tuple.load %79 @\"1\";\n-                    %111 : tensor<x32, x64, ptr<oracle.code.triton.Float16>> = tuple.load %79 @\"2\";\n-                    %112 : tensor<x32, x64, oracle.code.triton.Float16> = arith.truncf %109;\n-                    %113 : int = arith.muli %37 %24;\n-                    %114 : tensor<x32, int> = tt.splat %113;\n-                    %115 : tensor<x32, int> = arith.addi %114 %40;\n-                    %116 : int = arith.muli %39 %25;\n-                    %117 : tensor<x64, int> = tt.splat %116;\n-                    %118 : tensor<x64, int> = arith.addi %117 %46;\n-                    %119 : tensor<x32, x1, int> = tt.expand_dims %115 @axis=\"1\";\n-                    %120 : tensor<x32, x1, int> = tt.splat %20;\n-                    %121 : tensor<x32, x1, int> = arith.muli %120 %119;\n-                    %122 : tensor<x1, x64, int> = tt.expand_dims %118 @axis=\"0\";\n-                    %123 : tensor<x1, x64, int> = tt.splat %23;\n-                    %124 : tensor<x1, x64, int> = arith.muli %123 %122;\n-                    %125 : tensor<x32, x64, int> = tt.broadcast %121;\n-                    %126 : tensor<x32, x64, int> = tt.broadcast %124;\n-                    %127 : tensor<x32, x64, int> = arith.addi %125 %126;\n-                    %128 : tensor<x32, x64, ptr<oracle.code.triton.Float16>> = tt.splat %14;\n-                    %129 : tensor<x32, x64, ptr<oracle.code.triton.Float16>> = tt.addptr %128 %127;\n-                    %130 : tensor<x32, x1, int> = tt.expand_dims %115 @axis=\"1\";\n-                    %131 : tensor<x32, x1, int> = tt.splat %15;\n-                    %132 : tensor<x32, x1, boolean> = arith.cmpi %130 %131 @predicate=\"slt\";\n-                    %133 : tensor<x1, x64, int> = tt.expand_dims %118 @axis=\"0\";\n-                    %134 : tensor<x1, x64, int> = tt.splat %16;\n-                    %135 : tensor<x1, x64, boolean> = arith.cmpi %133 %134 @predicate=\"slt\";\n-                    %136 : tensor<x32, x64, boolean> = tt.broadcast %132;\n-                    %137 : tensor<x32, x64, boolean> = tt.broadcast %135;\n-                    %138 : tensor<x32, x64, boolean> = arith.andi %136 %137;\n+                    %109 : tensor<x32, x64, java.type:\"float\"> = tuple.load %79 @\"0\";\n+                    %110 : tensor<x32, x32, ptr<java.type:\"oracle.code.triton.Float16\">> = tuple.load %79 @\"1\";\n+                    %111 : tensor<x32, x64, ptr<java.type:\"oracle.code.triton.Float16\">> = tuple.load %79 @\"2\";\n+                    %112 : tensor<x32, x64, java.type:\"oracle.code.triton.Float16\"> = arith.truncf %109;\n+                    %113 : java.type:\"int\" = arith.muli %37 %24;\n+                    %114 : tensor<x32, java.type:\"int\"> = tt.splat %113;\n+                    %115 : tensor<x32, java.type:\"int\"> = arith.addi %114 %40;\n+                    %116 : java.type:\"int\" = arith.muli %39 %25;\n+                    %117 : tensor<x64, java.type:\"int\"> = tt.splat %116;\n+                    %118 : tensor<x64, java.type:\"int\"> = arith.addi %117 %46;\n+                    %119 : tensor<x32, x1, java.type:\"int\"> = tt.expand_dims %115 @axis=\"1\";\n+                    %120 : tensor<x32, x1, java.type:\"int\"> = tt.splat %20;\n+                    %121 : tensor<x32, x1, java.type:\"int\"> = arith.muli %120 %119;\n+                    %122 : tensor<x1, x64, java.type:\"int\"> = tt.expand_dims %118 @axis=\"0\";\n+                    %123 : tensor<x1, x64, java.type:\"int\"> = tt.splat %23;\n+                    %124 : tensor<x1, x64, java.type:\"int\"> = arith.muli %123 %122;\n+                    %125 : tensor<x32, x64, java.type:\"int\"> = tt.broadcast %121;\n+                    %126 : tensor<x32, x64, java.type:\"int\"> = tt.broadcast %124;\n+                    %127 : tensor<x32, x64, java.type:\"int\"> = arith.addi %125 %126;\n+                    %128 : tensor<x32, x64, ptr<java.type:\"oracle.code.triton.Float16\">> = tt.splat %14;\n+                    %129 : tensor<x32, x64, ptr<java.type:\"oracle.code.triton.Float16\">> = tt.addptr %128 %127;\n+                    %130 : tensor<x32, x1, java.type:\"int\"> = tt.expand_dims %115 @axis=\"1\";\n+                    %131 : tensor<x32, x1, java.type:\"int\"> = tt.splat %15;\n+                    %132 : tensor<x32, x1, java.type:\"boolean\"> = arith.cmpi %130 %131 @predicate=\"slt\";\n+                    %133 : tensor<x1, x64, java.type:\"int\"> = tt.expand_dims %118 @axis=\"0\";\n+                    %134 : tensor<x1, x64, java.type:\"int\"> = tt.splat %16;\n+                    %135 : tensor<x1, x64, java.type:\"boolean\"> = arith.cmpi %133 %134 @predicate=\"slt\";\n+                    %136 : tensor<x32, x64, java.type:\"boolean\"> = tt.broadcast %132;\n+                    %137 : tensor<x32, x64, java.type:\"boolean\"> = tt.broadcast %135;\n+                    %138 : tensor<x32, x64, java.type:\"boolean\"> = arith.andi %136 %137;\n","filename":"cr-examples\/triton\/src\/test\/java\/oracle\/code\/triton\/TestMatrixFp16.java","additions":128,"deletions":128,"binary":false,"changes":256,"status":"modified"},{"patch":"@@ -40,3 +40,3 @@\n-            module ()void -> {\n-                tt.func @\"max_float_float_float\" (%0 : float, %1 : float)float -> {\n-                    %2 : float = arith.maximumf %0 %1;\n+            module ()java.type:\"void\" -> {\n+                tt.func @\"max_float_float_float\" (%0 : java.type:\"float\", %1 : java.type:\"float\")java.type:\"float\" -> {\n+                    %2 : java.type:\"float\" = arith.maximumf %0 %1;\n@@ -45,3 +45,3 @@\n-                tt.func @\"reduce_max_float_float_float_0\" (%3 : tensor<x64, float>)float -> {\n-                    %4 : float = tt.reduce %3 @axis=\"0\" (%5 : float, %6 : float)float -> {\n-                        %7 : float = tt.call %5 %6 @\"max_float_float_float\";\n+                tt.func @\"reduce_max_float_float_float_0\" (%3 : tensor<x64, java.type:\"float\">)java.type:\"float\" -> {\n+                    %4 : java.type:\"float\" = tt.reduce %3 @axis=\"0\" (%5 : java.type:\"float\", %6 : java.type:\"float\")java.type:\"float\" -> {\n+                        %7 : java.type:\"float\" = tt.call %5 %6 @\"max_float_float_float\";\n@@ -52,2 +52,2 @@\n-                tt.func @\"sum_float_float_float\" (%8 : float, %9 : float)float -> {\n-                    %10 : float = arith.addf %8 %9;\n+                tt.func @\"sum_float_float_float\" (%8 : java.type:\"float\", %9 : java.type:\"float\")java.type:\"float\" -> {\n+                    %10 : java.type:\"float\" = arith.addf %8 %9;\n@@ -56,3 +56,3 @@\n-                tt.func @\"reduce_sum_float_float_float_0\" (%11 : tensor<x64, float>)float -> {\n-                    %12 : float = tt.reduce %11 @axis=\"0\" (%13 : float, %14 : float)float -> {\n-                        %15 : float = tt.call %13 %14 @\"sum_float_float_float\";\n+                tt.func @\"reduce_sum_float_float_float_0\" (%11 : tensor<x64, java.type:\"float\">)java.type:\"float\" -> {\n+                    %12 : java.type:\"float\" = tt.reduce %11 @axis=\"0\" (%13 : java.type:\"float\", %14 : java.type:\"float\")java.type:\"float\" -> {\n+                        %15 : java.type:\"float\" = tt.call %13 %14 @\"sum_float_float_float\";\n@@ -63,21 +63,21 @@\n-                tt.func @\"softmax_kernel_ptr<float>_ptr<float>_int_int_int_64_void\" (%16 : ptr<float>, %17 : ptr<float>, %18 : int, %19 : int, %20 : int)void -> {\n-                    %21 : int = tt.get_program_id @\"0\";\n-                    %22 : int = arith.muli %21 %18;\n-                    %23 : ptr<float> = tt.addptr %17 %22;\n-                    %24 : tensor<x64, int> = tt.make_range @start=\"0\" @end=\"64\";\n-                    %25 : tensor<x64, ptr<float>> = tt.splat %23;\n-                    %26 : tensor<x64, ptr<float>> = tt.addptr %25 %24;\n-                    %27 : tensor<x64, int> = tt.splat %20;\n-                    %28 : tensor<x64, boolean> = arith.cmpi %24 %27 @\"slt\";\n-                    %29 : tensor<x64, float> = tt.load %26 %28;\n-                    %30 : float = tt.call %29 @\"reduce_max_float_float_float_0\";\n-                    %31 : tensor<x64, float> = tt.splat %30;\n-                    %32 : tensor<x64, float> = arith.subf %29 %31;\n-                    %33 : tensor<x64, float> = math.exp %32;\n-                    %34 : float = tt.call %33 @\"reduce_sum_float_float_float_0\";\n-                    %35 : tensor<x64, float> = tt.splat %34;\n-                    %36 : tensor<x64, float> = arith.divf %33 %35;\n-                    %37 : int = arith.muli %21 %19;\n-                    %38 : ptr<float> = tt.addptr %16 %37;\n-                    %39 : tensor<x64, ptr<float>> = tt.splat %38;\n-                    %40 : tensor<x64, ptr<float>> = tt.addptr %39 %24;\n+                tt.func @sym_name=\"softmax_kernel_ptr<java.type.primitive<float>>_ptr<java.type.primitive<float>>_int_int_int_64_void\" (%16 : ptr<java.type:\"float\">, %17 : ptr<java.type:\"float\">, %18 : java.type:\"int\", %19 : java.type:\"int\", %20 : java.type:\"int\")java.type:\"void\" -> {\n+                    %21 : java.type:\"int\" = tt.get_program_id @\"0\";\n+                    %22 : java.type:\"int\" = arith.muli %21 %18;\n+                    %23 : ptr<java.type:\"float\"> = tt.addptr %17 %22;\n+                    %24 : tensor<x64, java.type:\"int\"> = tt.make_range @start=\"0\" @end=\"64\";\n+                    %25 : tensor<x64, ptr<java.type:\"float\">> = tt.splat %23;\n+                    %26 : tensor<x64, ptr<java.type:\"float\">> = tt.addptr %25 %24;\n+                    %27 : tensor<x64, java.type:\"int\"> = tt.splat %20;\n+                    %28 : tensor<x64, java.type:\"boolean\"> = arith.cmpi %24 %27 @\"slt\";\n+                    %29 : tensor<x64, java.type:\"float\"> = tt.load %26 %28;\n+                    %30 : java.type:\"float\" = tt.call %29 @\"reduce_max_float_float_float_0\";\n+                    %31 : tensor<x64, java.type:\"float\"> = tt.splat %30;\n+                    %32 : tensor<x64, java.type:\"float\"> = arith.subf %29 %31;\n+                    %33 : tensor<x64, java.type:\"float\"> = math.exp %32;\n+                    %34 : java.type:\"float\" = tt.call %33 @\"reduce_sum_float_float_float_0\";\n+                    %35 : tensor<x64, java.type:\"float\"> = tt.splat %34;\n+                    %36 : tensor<x64, java.type:\"float\"> = arith.divf %33 %35;\n+                    %37 : java.type:\"int\" = arith.muli %21 %19;\n+                    %38 : ptr<java.type:\"float\"> = tt.addptr %16 %37;\n+                    %39 : tensor<x64, ptr<java.type:\"float\">> = tt.splat %38;\n+                    %40 : tensor<x64, ptr<java.type:\"float\">> = tt.addptr %39 %24;\n@@ -136,3 +136,3 @@\n-            module ()void -> {\n-                tt.func @\"max_float_float_float\" (%0 : float, %1 : float)float -> {\n-                    %2 : float = arith.maximumf %0 %1;\n+            module ()java.type:\"void\" -> {\n+                tt.func @\"max_float_float_float\" (%0 : java.type:\"float\", %1 : java.type:\"float\")java.type:\"float\" -> {\n+                    %2 : java.type:\"float\" = arith.maximumf %0 %1;\n@@ -141,3 +141,3 @@\n-                tt.func @\"reduce_max_float_float_float_0\" (%3 : tensor<x64, float>)float -> {\n-                    %4 : float = tt.reduce %3 @axis=\"0\" (%5 : float, %6 : float)float -> {\n-                        %7 : float = tt.call %5 %6 @\"max_float_float_float\";\n+                tt.func @\"reduce_max_float_float_float_0\" (%3 : tensor<x64, java.type:\"float\">)java.type:\"float\" -> {\n+                    %4 : java.type:\"float\" = tt.reduce %3 @axis=\"0\" (%5 : java.type:\"float\", %6 : java.type:\"float\")java.type:\"float\" -> {\n+                        %7 : java.type:\"float\" = tt.call %5 %6 @\"max_float_float_float\";\n@@ -148,2 +148,2 @@\n-                tt.func @\"sum_float_float_float\" (%8 : float, %9 : float)float -> {\n-                    %10 : float = arith.addf %8 %9;\n+                tt.func @\"sum_float_float_float\" (%8 : java.type:\"float\", %9 : java.type:\"float\")java.type:\"float\" -> {\n+                    %10 : java.type:\"float\" = arith.addf %8 %9;\n@@ -152,3 +152,3 @@\n-                tt.func @\"reduce_sum_float_float_float_0\" (%11 : tensor<x64, float>)float -> {\n-                    %12 : float = tt.reduce %11 @axis=\"0\" (%13 : float, %14 : float)float -> {\n-                        %15 : float = tt.call %13 %14 @\"sum_float_float_float\";\n+                tt.func @\"reduce_sum_float_float_float_0\" (%11 : tensor<x64, java.type:\"float\">)java.type:\"float\" -> {\n+                    %12 : java.type:\"float\" = tt.reduce %11 @axis=\"0\" (%13 : java.type:\"float\", %14 : java.type:\"float\")java.type:\"float\" -> {\n+                        %15 : java.type:\"float\" = tt.call %13 %14 @\"sum_float_float_float\";\n@@ -159,24 +159,24 @@\n-                tt.func @\"softmax_kernel2_ptr<float>_ptr<float>_1_1_10_64_void\" (%16 : ptr<float>, %17 : ptr<float>)void -> {\n-                    %18 : int = arith.constant @\"1\";\n-                    %19 : int = arith.constant @\"1\";\n-                    %20 : int = arith.constant @\"10\";\n-                    %21 : int = tt.get_program_id @\"0\";\n-                    %22 : int = arith.muli %21 %18;\n-                    %23 : ptr<float> = tt.addptr %17 %22;\n-                    %24 : tensor<x64, int> = tt.make_range @start=\"0\" @end=\"64\";\n-                    %25 : tensor<x64, ptr<float>> = tt.splat %23;\n-                    %26 : tensor<x64, ptr<float>> = tt.addptr %25 %24;\n-                    %27 : tensor<x64, int> = tt.splat %20;\n-                    %28 : tensor<x64, boolean> = arith.cmpi %24 %27 @\"slt\";\n-                    %29 : tensor<x64, float> = tt.load %26 %28;\n-                    %30 : float = tt.call %29 @\"reduce_max_float_float_float_0\";\n-                    %31 : tensor<x64, float> = tt.splat %30;\n-                    %32 : tensor<x64, float> = arith.subf %29 %31;\n-                    %33 : tensor<x64, float> = math.exp %32;\n-                    %34 : float = tt.call %33 @\"reduce_sum_float_float_float_0\";\n-                    %35 : tensor<x64, float> = tt.splat %34;\n-                    %36 : tensor<x64, float> = arith.divf %33 %35;\n-                    %37 : int = arith.muli %21 %19;\n-                    %38 : ptr<float> = tt.addptr %16 %37;\n-                    %39 : tensor<x64, ptr<float>> = tt.splat %38;\n-                    %40 : tensor<x64, ptr<float>> = tt.addptr %39 %24;\n+                tt.func @sym_name=\"softmax_kernel2_ptr<java.type.primitive<float>>_ptr<java.type.primitive<float>>_1_1_10_64_void\" (%16 : ptr<java.type:\"float\">, %17 : ptr<java.type:\"float\">)java.type:\"void\" -> {\n+                    %18 : java.type:\"int\" = arith.constant @\"1\";\n+                    %19 : java.type:\"int\" = arith.constant @\"1\";\n+                    %20 : java.type:\"int\" = arith.constant @\"10\";\n+                    %21 : java.type:\"int\" = tt.get_program_id @\"0\";\n+                    %22 : java.type:\"int\" = arith.muli %21 %18;\n+                    %23 : ptr<java.type:\"float\"> = tt.addptr %17 %22;\n+                    %24 : tensor<x64, java.type:\"int\"> = tt.make_range @start=\"0\" @end=\"64\";\n+                    %25 : tensor<x64, ptr<java.type:\"float\">> = tt.splat %23;\n+                    %26 : tensor<x64, ptr<java.type:\"float\">> = tt.addptr %25 %24;\n+                    %27 : tensor<x64, java.type:\"int\"> = tt.splat %20;\n+                    %28 : tensor<x64, java.type:\"boolean\"> = arith.cmpi %24 %27 @\"slt\";\n+                    %29 : tensor<x64, java.type:\"float\"> = tt.load %26 %28;\n+                    %30 : java.type:\"float\" = tt.call %29 @\"reduce_max_float_float_float_0\";\n+                    %31 : tensor<x64, java.type:\"float\"> = tt.splat %30;\n+                    %32 : tensor<x64, java.type:\"float\"> = arith.subf %29 %31;\n+                    %33 : tensor<x64, java.type:\"float\"> = math.exp %32;\n+                    %34 : java.type:\"float\" = tt.call %33 @\"reduce_sum_float_float_float_0\";\n+                    %35 : tensor<x64, java.type:\"float\"> = tt.splat %34;\n+                    %36 : tensor<x64, java.type:\"float\"> = arith.divf %33 %35;\n+                    %37 : java.type:\"int\" = arith.muli %21 %19;\n+                    %38 : ptr<java.type:\"float\"> = tt.addptr %16 %37;\n+                    %39 : tensor<x64, ptr<java.type:\"float\">> = tt.splat %38;\n+                    %40 : tensor<x64, ptr<java.type:\"float\">> = tt.addptr %39 %24;\n","filename":"cr-examples\/triton\/src\/test\/java\/oracle\/code\/triton\/TestSoftMax.java","additions":67,"deletions":67,"binary":false,"changes":134,"status":"modified"},{"patch":"@@ -41,3 +41,3 @@\n-            module ()void -> {\n-                tt.func @\"test1_32_64_void\" ()void -> {\n-                    %0 : tensor<x32, x64, float> = arith.constant @\"0.0\";\n+            module ()java.type:\"void\" -> {\n+                tt.func @\"test1_32_64_void\" ()java.type:\"void\" -> {\n+                    %0 : tensor<x32, x64, java.type:\"float\"> = arith.constant @\"0.0\";\n","filename":"cr-examples\/triton\/src\/test\/java\/oracle\/code\/triton\/TestZeros.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -382,1 +382,1 @@\n-                        if (methodRef.equals(MethodRef.ofString(\"hat.buffer.S32Array::array(long)int\")))\n+                        if (methodRef.equals(MethodRef.ofString(\"hat.buffer.S32Array::array(long):int\")))\n@@ -406,2 +406,2 @@\n-                        else if (methodRef.equals(MethodRef.ofString(\"hat.buffer.S32Array2D::array(long)int\")) ||\n-                                 methodRef.equals(MethodRef.ofString(\"hat.buffer.F32Array2D::array(long)float\")))\n+                        else if (methodRef.equals(MethodRef.ofString(\"hat.buffer.S32Array2D::array(long):int\")) ||\n+                                 methodRef.equals(MethodRef.ofString(\"hat.buffer.F32Array2D::array(long):float\")))\n@@ -431,1 +431,1 @@\n-                        else if (methodRef.equals(MethodRef.ofString(\"hat.buffer.S32Array::array(long, int)void\"))) {\n+                        else if (methodRef.equals(MethodRef.ofString(\"hat.buffer.S32Array::array(long, int):void\"))) {\n@@ -455,1 +455,1 @@\n-                                 methodRef.equals(MethodRef.ofString(\"hat.buffer.F32Array2D::array(long, float)void\"))) {\n+                                 methodRef.equals(MethodRef.ofString(\"hat.buffer.F32Array2D::array(long, float):void\"))) {\n@@ -478,3 +478,3 @@\n-                        else if (methodRef.equals(MethodRef.ofString(\"hat.buffer.S32Array::length()int\")) ||\n-                                 methodRef.equals(MethodRef.ofString(\"hat.buffer.S32Array2D::width()int\"))||\n-                                 methodRef.equals(MethodRef.ofString(\"hat.buffer.F32Array2D::width()int\"))) {\n+                        else if (methodRef.equals(MethodRef.ofString(\"hat.buffer.S32Array::length():int\")) ||\n+                                 methodRef.equals(MethodRef.ofString(\"hat.buffer.S32Array2D::width():int\"))||\n+                                 methodRef.equals(MethodRef.ofString(\"hat.buffer.F32Array2D::width():int\"))) {\n@@ -494,2 +494,2 @@\n-                        else if (methodRef.equals(MethodRef.ofString(\"hat.buffer.S32Array2D::height()int\")) ||\n-                                 methodRef.equals(MethodRef.ofString(\"hat.buffer.F32Array2D::height()int\"))) {\n+                        else if (methodRef.equals(MethodRef.ofString(\"hat.buffer.S32Array2D::height():int\")) ||\n+                                 methodRef.equals(MethodRef.ofString(\"hat.buffer.F32Array2D::height():int\"))) {\n@@ -509,1 +509,1 @@\n-                        else if (methodRef.equals(MethodRef.ofString(\"java.lang.Math::sqrt(double)double\"))) {\n+                        else if (methodRef.equals(MethodRef.ofString(\"java.lang.Math::sqrt(double):double\"))) {\n","filename":"hat\/backends\/ffi\/spirv\/src\/main\/java\/intel\/code\/spirv\/SpirvModuleGenerator.java","additions":11,"deletions":11,"binary":false,"changes":22,"status":"modified"}]}