{"files":[{"patch":"@@ -57,1 +57,1 @@\n-                              .map(i -> ((Tensor)(i instanceof Optional o ? o.get() : i)).tensorAddr)\n+                              .map(i -> (Tensor)(i instanceof Optional o ? o.get() : i))\n@@ -62,1 +62,1 @@\n-                return new Tensor(outTensors.getFirst());\n+                return outTensors.getFirst();\n@@ -64,1 +64,1 @@\n-                return outTensors.stream().map(Tensor::new).toArray();\n+                return outTensors.toArray();\n","filename":"cr-examples\/onnx\/src\/main\/java\/oracle\/code\/onnx\/OnnxInterpreter.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -4,1 +4,0 @@\n-import java.nio.ByteBuffer;\n@@ -10,0 +9,1 @@\n+import jdk.incubator.code.Block;\n@@ -268,1 +268,1 @@\n-    static ByteBuffer buildFuncModel(FuncOp model) {\n+    static byte[] build(Block block) {\n@@ -279,3 +279,3 @@\n-        return buildModel(\n-                model.body().entryBlock().parameters().stream().map(v -> new Input(indexer.getName(v), ((OnnxType.TensorType)v.type()).eType().id())).toList(),\n-                model.body().entryBlock().ops().stream().<OpNode>mapMulti((op, opNodes) -> {\n+        return build(\n+                block.parameters().stream().map(v -> tensorInfo(indexer.getName(v), ((OnnxType.TensorType)v.type()).eType().id())).toList(),\n+                block.ops().stream().<NodeProto>mapMulti((op, opNodes) -> {\n@@ -284,1 +284,1 @@\n-                            opNodes.accept(new OpNode(\n+                            opNodes.accept(node(\n@@ -297,1 +297,1 @@\n-                List.of(indexer.getName(model.body().entryBlock().terminatingOp().operands().getFirst())));\n+                List.of(indexer.getName(block.terminatingOp().operands().getFirst())));\n@@ -300,5 +300,2 @@\n-    record Input(String name, int tensorElementType) {}\n-    record OpNode(String opName, List<String> inputNames, List<String> outputNames, java.util.Map<String, Object> attributes) {}\n-\n-    static ByteBuffer buildModel(List<Input> inputs, List<OpNode> ops, List<String> outputNames) {\n-        var bytes = new ModelProto()\n+    static byte[] build(List<ValueInfoProto> inputs, List<NodeProto> ops, List<String> outputNames) {\n+        return new ModelProto()\n@@ -306,10 +303,1 @@\n-                .graph(new GraphProto()\n-                        .forEach(inputs, (g, input) -> g\n-                                .input(new ValueInfoProto().name(input.name())\n-                                        .type(new TypeProto().tensor_type(new Tensor().elem_type(input.tensorElementType())))))\n-                        .forEach(ops, (g, op) -> g.node(new NodeProto()\n-                                .forEach(op.inputNames(), (n, iName) -> n.input(iName))\n-                                .forEach(op.outputNames(), (n, oName) -> n.output(oName))\n-                                .op_type(op.opName())\n-                                .forEach(op.attributes().entrySet(), (n, ae) -> n.attribute(buildAttribute(ae.getKey(), ae.getValue())))))\n-                        .forEach(outputNames, (g, oName) -> g.output(new ValueInfoProto().name(oName))))\n+                .graph(graph(inputs, ops, outputNames))\n@@ -318,2 +306,0 @@\n-\/\/        OnnxProtoPrinter.printModel(ByteBuffer.wrap(bytes).order(ByteOrder.LITTLE_ENDIAN));\n-        return ByteBuffer.allocateDirect(bytes.length).put(bytes).asReadOnlyBuffer();\n@@ -322,1 +308,33 @@\n-    static Attribute buildAttribute(String name, Object value) {\n+    static GraphProto graph(List<ValueInfoProto> inputs, List<NodeProto> ops, List<String> outputNames) {\n+        return new GraphProto()\n+                .forEach(inputs, (g, i) -> g.input(i))\n+                .forEach(ops, (g, op) -> g.node(op))\n+                .forEach(outputNames, (g, oName) -> g.output(new ValueInfoProto().name(oName)));\n+    }\n+\n+    static NodeProto node(String opName, List<String> inputNames, List<String> outputNames, java.util.Map<String, Object> attributes) {\n+        return new NodeProto()\n+                .forEach(inputNames, (n, iName) -> n.input(iName))\n+                .forEach(outputNames, (n, oName) -> n.output(oName))\n+                .op_type(opName)\n+                .forEach(attributes.entrySet(), (n, ae) -> n.attribute(attribute(ae.getKey(), ae.getValue())));\n+    }\n+\n+    static ValueInfoProto tensorInfo(String name, int tensorElementType) {\n+        return new ValueInfoProto()\n+                .name(name)\n+                .type(new TypeProto()\n+                        .tensor_type(new Tensor()\n+                                .elem_type(tensorElementType)));\n+    }\n+\n+    static ValueInfoProto scalarInfo(String name, int tensorElementType) {\n+        return new ValueInfoProto()\n+                .name(name)\n+                .type(new TypeProto()\n+                        .tensor_type(new Tensor()\n+                                .elem_type(tensorElementType)\n+                                .shape(new TensorShapeProto())));\n+    }\n+\n+    static Attribute attribute(String name, Object value) {\n@@ -331,0 +349,3 @@\n+            case GraphProto g -> {\n+                attr.type(5).g(g.name(name));\n+            }\n","filename":"cr-examples\/onnx\/src\/main\/java\/oracle\/code\/onnx\/OnnxProtoBuilder.java","additions":46,"deletions":25,"binary":false,"changes":71,"status":"modified"},{"patch":"@@ -6,2 +6,1 @@\n-import java.nio.ByteBuffer;\n-import java.nio.ByteOrder;\n+import java.lang.invoke.MethodHandles;\n@@ -14,1 +13,1 @@\n-import java.util.Optional;\n+import java.util.function.Supplier;\n@@ -16,0 +15,1 @@\n+import jdk.incubator.code.*;\n@@ -18,0 +18,3 @@\n+import jdk.incubator.code.type.FunctionType;\n+import jdk.incubator.code.type.VarType;\n+import oracle.code.onnx.compiler.OnnxTransformer;\n@@ -20,1 +23,0 @@\n-import oracle.code.onnx.ir.OnnxOp;\n@@ -50,1 +52,22 @@\n-    private static final String LOG_ID = \"onnx-ffm-java\";\n+    public static <T, U extends Quotable & Supplier<Tensor<T>>> Tensor<T> execute(U codeLambda) {\n+        var quotable = Op.ofQuotable(codeLambda).orElseThrow();\n+        var lambda = (CoreOp.LambdaOp) quotable.op();\n+        var capturedValues = lambda.capturedValues();\n+        var onnxFunc = OnnxTransformer.transform(MethodHandles.lookup(), CoreOp.func(\"onnxCode\", FunctionType.functionType(\n+                lambda.invokableType().returnType(),\n+                capturedValues.stream().map(Value::type).map(t -> t instanceof VarType vt ? vt.valueType() : t).toList()))\n+                .body(bb -> {\n+                    bb.context().mapValues(capturedValues, bb.parameters());\n+                    for (Op op : lambda.body().entryBlock().ops()) {\n+                        int i;\n+                        if (op instanceof CoreOp.VarAccessOp.VarLoadOp load && (i = capturedValues.indexOf(load.varOp().result())) >= 0) {\n+                            bb.context().mapValue(op.result(), bb.parameters().get(i)); \/\/ remap var load result to block param\n+                        } else {\n+                            bb.apply(op);\n+                        }\n+                    }\n+                }));\n+        try (var session = getInstance().createSession(OnnxProtoBuilder.build(onnxFunc.body().entryBlock()))) {\n+            return session.run(quotable.capturedValues().values().stream().map(val -> (Tensor)(val instanceof CoreOp.Var v ? v.value() : val)).toList()).getFirst();\n+        }\n+    }\n@@ -59,0 +82,1 @@\n+    private static final String LOG_ID = \"onnx-ffm-java\";\n@@ -77,1 +101,1 @@\n-    public List<MemorySegment> runOp(String opName, List<MemorySegment> inputValues, int numOutputs, Map<String, Object> attributes) {\n+    public List<Tensor> runOp(String opName, List<Tensor> inputValues, int numOutputs, Map<String, Object> attributes) {\n@@ -79,3 +103,3 @@\n-        var protoModel = OnnxProtoBuilder.buildModel(\n-                IntStream.range(0, inputValues.size()).mapToObj(i -> new OnnxProtoBuilder.Input(\"i\" + i, tensorElementType(inputValues.get(i)).id)).toList(),\n-                List.of(new OnnxProtoBuilder.OpNode(\n+        var protoModel = OnnxProtoBuilder.build(\n+                IntStream.range(0, inputValues.size()).mapToObj(i -> OnnxProtoBuilder.tensorInfo(\"i\" + i, inputValues.get(i).elementType().id)).toList(),\n+                List.of(OnnxProtoBuilder.node(\n@@ -92,2 +116,2 @@\n-    public List<MemorySegment> runFunc(CoreOp.FuncOp model, List<MemorySegment> inputValues) {\n-        var protoModel = OnnxProtoBuilder.buildFuncModel(model);\n+    public List<Tensor> run(Block block, List<Tensor> inputValues) {\n+        var protoModel = OnnxProtoBuilder.build(block);\n@@ -107,1 +131,1 @@\n-    public Session createSession(ByteBuffer model) {\n+    public Session createSession(byte[] model) {\n@@ -111,2 +135,2 @@\n-    private Session createSession(ByteBuffer model, SessionOptions options) {\n-        return new Session(retAddr(OrtApi.CreateSessionFromArray(runtimeAddress, envAddress, MemorySegment.ofBuffer(model.rewind()), model.limit(), options.sessionOptionsAddress, ret)));\n+    private Session createSession(byte[] model, SessionOptions options) {\n+        return new Session(retAddr(OrtApi.CreateSessionFromArray(runtimeAddress, envAddress, arena.allocateFrom(ValueLayout.JAVA_BYTE, model), model.length, options.sessionOptionsAddress, ret)));\n@@ -140,1 +164,1 @@\n-        public List<MemorySegment> run(List<MemorySegment> inputValues) {\n+        public List<Tensor> run(List<Tensor> inputValues) {\n@@ -149,1 +173,1 @@\n-                inputs.setAtIndex(C_POINTER, index++, inputValues.get(i));\n+                inputs.setAtIndex(C_POINTER, index++, inputValues.get(i).tensorAddr);\n@@ -158,1 +182,1 @@\n-            var retArr = new MemorySegment[outputLen];\n+            var retArr = new Tensor[outputLen];\n@@ -160,2 +184,2 @@\n-                retArr[i] = outputs.getAtIndex(C_POINTER, i)\n-                        .reinterpret(arena, null);\n+                retArr[i] = new Tensor(outputs.getAtIndex(C_POINTER, i)\n+                        .reinterpret(arena, null));\n@@ -191,1 +215,1 @@\n-    public ByteBuffer tensorBuffer(MemorySegment tensorAddr) {\n+    public MemorySegment tensorData(MemorySegment tensorAddr) {\n@@ -196,2 +220,1 @@\n-                .reinterpret(size)\n-                .asByteBuffer().order(ByteOrder.nativeOrder());\n+                .reinterpret(size);\n","filename":"cr-examples\/onnx\/src\/main\/java\/oracle\/code\/onnx\/OnnxRuntime.java","additions":45,"deletions":22,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -31,1 +31,0 @@\n-import java.nio.ByteBuffer;\n@@ -69,0 +68,5 @@\n+    public static Tensor<Boolean> ofScalar(boolean b) {\n+        var data = Arena.ofAuto().allocateFrom(ValueLayout.JAVA_BYTE, b ? (byte)1 : 0);\n+        return new Tensor(data, ElementType.BOOL, SCALAR_SHAPE);\n+    }\n+\n@@ -118,1 +122,1 @@\n-        this(null, tensorAddr);\n+        this(OnnxRuntime.getInstance().tensorData(tensorAddr), tensorAddr);\n@@ -126,2 +130,10 @@\n-    public ByteBuffer asByteBuffer() {\n-        return OnnxRuntime.getInstance().tensorBuffer(tensorAddr);\n+    public ElementType elementType() {\n+        return OnnxRuntime.getInstance().tensorElementType(tensorAddr);\n+    }\n+\n+    public long[] shape() {\n+        return OnnxRuntime.getInstance().tensorShape(tensorAddr);\n+    }\n+\n+    public MemorySegment data() {\n+        return dataAddr;\n","filename":"cr-examples\/onnx\/src\/main\/java\/oracle\/code\/onnx\/Tensor.java","additions":16,"deletions":4,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -47,0 +47,1 @@\n+import java.lang.foreign.ValueLayout;\n@@ -48,1 +49,0 @@\n-import java.nio.FloatBuffer;\n@@ -341,1 +341,1 @@\n-    static List<Tensor<Float>> loadWeights() throws IOException {\n+    static List<Tensor> loadWeights() throws IOException {\n@@ -354,13 +354,0 @@\n-    static int nextBestMatch(FloatBuffer fb) {\n-        float maxW = fb.get();\n-        int maxI = 0;\n-        for (int i = 1; i < 10; i++) {\n-            float w = fb.get();\n-            if (w > maxW) {\n-                maxW = w;\n-                maxI = i;\n-            }\n-        }\n-        return maxI;\n-    }\n-\n@@ -390,4 +377,3 @@\n-        test(inputImage -> new Tensor(OnnxRuntime.getInstance().runFunc(\n-                    OnnxTransformer.transform(MethodHandles.lookup(), getFuncOp(\"cnn\")),\n-                    Stream.concat(weights.stream(), Stream.of(inputImage))\n-                            .map(t -> t.tensorAddr).toList()).getFirst()));\n+        test(inputImage -> OnnxRuntime.getInstance().run(\n+                    OnnxTransformer.transform(MethodHandles.lookup(), getFuncOp(\"cnn\")).body().entryBlock(),\n+                    Stream.concat(weights.stream(), Stream.of(inputImage)).toList()).getFirst());\n@@ -405,1 +391,1 @@\n-            FloatBuffer result = executor.apply(inputImage).asByteBuffer().asFloatBuffer();\n+            var result = executor.apply(inputImage).data().toArray(ValueLayout.JAVA_FLOAT);\n@@ -408,1 +394,2 @@\n-            while (result.remaining() > 0) {\n+            int i = 0;\n+            while (i < result.length) {\n@@ -410,1 +397,11 @@\n-                int actual = nextBestMatch(result);\n+\n+                int actual = 0;\n+                float maxW = result[i++];\n+                for (int j = 1; j < 10; j++) {\n+                    float w = result[i++];\n+                    if (w > maxW) {\n+                        maxW = w;\n+                        actual = j;\n+                    }\n+                }\n+\n","filename":"cr-examples\/onnx\/src\/test\/java\/oracle\/code\/onnx\/CNNTest.java","additions":19,"deletions":22,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -30,1 +30,0 @@\n-import jdk.incubator.code.CodeReflection;\n@@ -33,5 +32,0 @@\n-import java.lang.invoke.MethodHandles;\n-import java.nio.ByteBuffer;\n-import java.nio.ByteOrder;\n-import java.nio.FloatBuffer;\n-import java.util.List;\n@@ -42,2 +36,0 @@\n-import jdk.incubator.code.Op;\n-import oracle.code.onnx.compiler.OnnxTransformer;\n@@ -48,1 +40,0 @@\n-import static oracle.code.onnx.Tensor.ElementType.*;\n@@ -51,3 +42,7 @@\n-    private static float[] loadConstant(String resource) throws IOException {\n-        return MemorySegment.ofArray(MNISTDemo.class.getResourceAsStream(resource).readAllBytes())\n-                .toArray(ValueLayout.JAVA_FLOAT_UNALIGNED);\n+    public static float[] loadConstant(String resource) {\n+        try {\n+            return MemorySegment.ofArray(MNISTDemo.class.getResourceAsStream(resource).readAllBytes())\n+                    .toArray(ValueLayout.JAVA_FLOAT_UNALIGNED);\n+        } catch (IOException e) {\n+            throw new UncheckedIOException(e);\n+        }\n@@ -56,52 +51,52 @@\n-    @CodeReflection\n-    public static Tensor<Float> cnn(Tensor<Float> inputImage) throws IOException {\n-\n-        \/\/ Scaling to 0-1\n-        var scaledInput = Div(inputImage, Constant(255f));\n-\n-        \/\/ First conv layer\n-        var conv1Weights = Reshape(Constant(loadConstant(\"conv1-weight-float-le\")), Constant(new long[]{6, 1, 5, 5}), empty());\n-        var conv1Biases = Reshape(Constant(loadConstant(\"conv1-bias-float-le\")), Constant(new long[]{6}), empty());\n-        var conv1 = Conv(scaledInput, conv1Weights, of(conv1Biases), of(new long[4]),\n-                of(new long[]{1,1}), empty(), of(new long[]{1, 1, 1, 1}),\n-                of(1L), of(new long[]{5,5}));\n-        var relu1 = Relu(conv1);\n-\n-        \/\/ First pooling layer\n-        var pool1 = MaxPool(relu1, of(new long[4]), of(new long[]{1,1}), empty(),\n-                of(0L), empty(), of(new long[]{2, 2}), new long[]{2, 2});\n-\n-        \/\/ Second conv layer\n-        var conv2Weights = Reshape(Constant(loadConstant(\"conv2-weight-float-le\")), Constant(new long[]{16, 6, 5, 5}), empty());\n-        var conv2Biases = Reshape(Constant(loadConstant(\"conv2-bias-float-le\")), Constant(new long[]{16}), empty());\n-        var conv2 = Conv(pool1.Y(), conv2Weights, of(conv2Biases), of(new long[4]),\n-                of(new long[]{1,1}), empty(), of(new long[]{1, 1, 1, 1}),\n-                of(1L), of(new long[]{5,5}));\n-        var relu2 = Relu(conv2);\n-\n-        \/\/ Second pooling layer\n-        var pool2 = MaxPool(relu2, of(new long[4]), of(new long[]{1,1}), empty(),\n-                of(0L), empty(), of(new long[]{2, 2}), new long[]{2, 2});\n-\n-        \/\/ Flatten inputs\n-        var flatten = Flatten(pool2.Y(), of(1L));\n-\n-        \/\/ First fully connected layer\n-        var fc1Weights = Reshape(Constant(loadConstant(\"fc1-weight-float-le\")), Constant(new long[]{120, 256}), empty());\n-        var fc1Biases = Reshape(Constant(loadConstant(\"fc1-bias-float-le\")), Constant(new long[]{120}), empty());\n-        var fc1 = Gemm(flatten, fc1Weights, of(fc1Biases), of(1f), of(1L), of(1f), empty());\n-        var relu3 = Relu(fc1);\n-\n-        \/\/ Second fully connected layer\n-        var fc2Weights = Reshape(Constant(loadConstant(\"fc2-weight-float-le\")), Constant(new long[]{84, 120}), empty());\n-        var fc2Biases = Reshape(Constant(loadConstant(\"fc2-bias-float-le\")), Constant(new long[]{84}), empty());\n-        var fc2 = Gemm(relu3, fc2Weights, of(fc2Biases), of(1f), of(1L), of(1f), empty());\n-        var relu4 = Relu(fc2);\n-\n-        \/\/ Softmax layer\n-        var fc3Weights = Reshape(Constant(loadConstant(\"fc3-weight-float-le\")), Constant(new long[]{10, 84}), empty());\n-        var fc3Biases = Reshape(Constant(loadConstant(\"fc3-bias-float-le\")), Constant(new long[]{10}), empty());\n-        var fc3 = Gemm(relu4, fc3Weights, of(fc3Biases), of(1f), of(1L), of(1f), empty());\n-        var prediction = Softmax(fc3, of(1L));\n-\n-        return prediction;\n+    public static Tensor<Float> cnn(Tensor<Float> inputImage) {\n+        return OnnxRuntime.execute(() -> {\n+            \/\/ Scaling to 0-1\n+            var scaledInput = Div(inputImage, Constant(255f));\n+\n+            \/\/ First conv layer\n+            var conv1Weights = Reshape(Constant(loadConstant(\"conv1-weight-float-le\")), Constant(new long[]{6, 1, 5, 5}), empty());\n+            var conv1Biases = Reshape(Constant(loadConstant(\"conv1-bias-float-le\")), Constant(new long[]{6}), empty());\n+            var conv1 = Conv(scaledInput, conv1Weights, of(conv1Biases), of(new long[4]),\n+                    of(new long[]{1,1}), empty(), of(new long[]{1, 1, 1, 1}),\n+                    of(1L), of(new long[]{5,5}));\n+            var relu1 = Relu(conv1);\n+\n+            \/\/ First pooling layer\n+            var pool1 = MaxPool(relu1, of(new long[4]), of(new long[]{1,1}), empty(),\n+                    of(0L), empty(), of(new long[]{2, 2}), new long[]{2, 2});\n+\n+            \/\/ Second conv layer\n+            var conv2Weights = Reshape(Constant(loadConstant(\"conv2-weight-float-le\")), Constant(new long[]{16, 6, 5, 5}), empty());\n+            var conv2Biases = Reshape(Constant(loadConstant(\"conv2-bias-float-le\")), Constant(new long[]{16}), empty());\n+            var conv2 = Conv(pool1.Y(), conv2Weights, of(conv2Biases), of(new long[4]),\n+                    of(new long[]{1,1}), empty(), of(new long[]{1, 1, 1, 1}),\n+                    of(1L), of(new long[]{5,5}));\n+            var relu2 = Relu(conv2);\n+\n+            \/\/ Second pooling layer\n+            var pool2 = MaxPool(relu2, of(new long[4]), of(new long[]{1,1}), empty(),\n+                    of(0L), empty(), of(new long[]{2, 2}), new long[]{2, 2});\n+\n+            \/\/ Flatten inputs\n+            var flatten = Flatten(pool2.Y(), of(1L));\n+\n+            \/\/ First fully connected layer\n+            var fc1Weights = Reshape(Constant(loadConstant(\"fc1-weight-float-le\")), Constant(new long[]{120, 256}), empty());\n+            var fc1Biases = Reshape(Constant(loadConstant(\"fc1-bias-float-le\")), Constant(new long[]{120}), empty());\n+            var fc1 = Gemm(flatten, fc1Weights, of(fc1Biases), of(1f), of(1L), of(1f), empty());\n+            var relu3 = Relu(fc1);\n+\n+            \/\/ Second fully connected layer\n+            var fc2Weights = Reshape(Constant(loadConstant(\"fc2-weight-float-le\")), Constant(new long[]{84, 120}), empty());\n+            var fc2Biases = Reshape(Constant(loadConstant(\"fc2-bias-float-le\")), Constant(new long[]{84}), empty());\n+            var fc2 = Gemm(relu3, fc2Weights, of(fc2Biases), of(1f), of(1L), of(1f), empty());\n+            var relu4 = Relu(fc2);\n+\n+            \/\/ Softmax layer\n+            var fc3Weights = Reshape(Constant(loadConstant(\"fc3-weight-float-le\")), Constant(new long[]{10, 84}), empty());\n+            var fc3Biases = Reshape(Constant(loadConstant(\"fc3-bias-float-le\")), Constant(new long[]{10}), empty());\n+            var fc3 = Gemm(relu4, fc3Weights, of(fc3Biases), of(1f), of(1L), of(1f), empty());\n+            var prediction = Softmax(fc3, of(1L));\n+\n+            return prediction;\n+        });\n@@ -118,1 +113,0 @@\n-        var statusBar = new JLabel(\"   Hold SHIFT key to draw with trackpad or mouse, click ENTER to run digit classification.\");\n@@ -121,11 +115,1 @@\n-        var modelRuntimeSession = OnnxRuntime.getInstance().createSession(\n-                OnnxProtoBuilder.buildFuncModel(\n-                        OnnxTransformer.transform(MethodHandles.lookup(),\n-                                Op.ofMethod(MNISTDemo.class.getDeclaredMethod(\"cnn\", Tensor.class)).get())));\n-        var drawAreaImage = new BufferedImage(DRAW_AREA_SIZE, DRAW_AREA_SIZE, BufferedImage.TYPE_BYTE_GRAY);\n-        var drawGraphics = drawAreaImage.createGraphics();\n-        var scaledImage = new BufferedImage(IMAGE_SIZE, IMAGE_SIZE, BufferedImage.TYPE_BYTE_GRAY);\n-        var scaledGraphics = scaledImage.createGraphics();\n-        var scaledImageDataBuffer = ByteBuffer.allocateDirect(IMAGE_SIZE * IMAGE_SIZE * 4).order(ByteOrder.LITTLE_ENDIAN).asFloatBuffer();\n-        var inputArguments = List.of(new Tensor(MemorySegment.ofBuffer(scaledImageDataBuffer), FLOAT, 1, 1, IMAGE_SIZE, IMAGE_SIZE).tensorAddr);\n-        var sampleArray = new float[IMAGE_SIZE * IMAGE_SIZE];\n+        var drawImage = new BufferedImage(DRAW_AREA_SIZE, DRAW_AREA_SIZE, BufferedImage.TYPE_BYTE_GRAY);\n@@ -134,1 +118,0 @@\n-\n@@ -141,1 +124,1 @@\n-                        drawGraphics.clearRect(0, 0, DRAW_AREA_SIZE, DRAW_AREA_SIZE);\n+                        drawImage.getGraphics().clearRect(0, 0, DRAW_AREA_SIZE, DRAW_AREA_SIZE);\n@@ -144,1 +127,1 @@\n-                    drawGraphics.fillOval(e.getX(), e.getY(), PEN_SIZE, PEN_SIZE);\n+                    drawImage.getGraphics().fillOval(e.getX(), e.getY(), PEN_SIZE, PEN_SIZE);\n@@ -149,1 +132,0 @@\n-\n@@ -153,1 +135,1 @@\n-        frame.add(statusBar, BorderLayout.SOUTH);\n+        frame.add(new JLabel(\"   Hold SHIFT key to draw with trackpad or mouse, click ENTER to run digit classification.\"), BorderLayout.SOUTH);\n@@ -160,7 +142,10 @@\n-                    scaledGraphics.drawImage(drawAreaImage.getScaledInstance(IMAGE_SIZE, IMAGE_SIZE, Image.SCALE_SMOOTH), 0, 0, null);\n-                    scaledImageDataBuffer.put(0, scaledImage.getData().getSamples(0, 0, IMAGE_SIZE, IMAGE_SIZE, 0, sampleArray));\n-                    FloatBuffer result = OnnxRuntime.getInstance().tensorBuffer(modelRuntimeSession.run(inputArguments).getFirst()).asFloatBuffer();\n-                    var msg = new StringBuilder(\"<html>\");\n-                    for (int i = 0; i < 10; i++) {\n-                        var w = result.get(i);\n-                        msg.append(\"&nbsp;<font size=\\\"%d\\\" color=\\\"#%s\\\">%d<\/font>&nbsp;(%.1f%%)&nbsp;<br><br><br>\"\n+                    var scaledImage = new BufferedImage(IMAGE_SIZE, IMAGE_SIZE, BufferedImage.TYPE_BYTE_GRAY);\n+                    scaledImage.createGraphics().drawImage(drawImage.getScaledInstance(IMAGE_SIZE, IMAGE_SIZE, Image.SCALE_SMOOTH), 0, 0, null);\n+                    var imageData = new float[IMAGE_SIZE * IMAGE_SIZE];\n+                    scaledImage.getData().getSamples(0, 0, IMAGE_SIZE, IMAGE_SIZE, 0, imageData);\n+                    var imageTensor = Tensor.ofShape(new long[]{1, 1, IMAGE_SIZE, IMAGE_SIZE}, imageData);\n+                    var result = cnn(imageTensor).data().toArray(ValueLayout.JAVA_FLOAT);\n+                    var report = new StringBuilder(\"<html>\");\n+                    for (int i = 0; i < result.length; i++) {\n+                        var w = result[i];\n+                        report.append(\"&nbsp;<font size=\\\"%d\\\" color=\\\"#%s\\\">%d<\/font>&nbsp;(%.1f%%)&nbsp;<br><br><br>\"\n@@ -169,1 +154,1 @@\n-                    results.setText(msg.toString());\n+                    results.setText(report.toString());\n","filename":"cr-examples\/onnx\/src\/test\/java\/oracle\/code\/onnx\/MNISTDemo.java","additions":74,"deletions":89,"binary":false,"changes":163,"status":"modified"},{"patch":"@@ -7,0 +7,1 @@\n+import static oracle.code.onnx.OnnxProtoBuilder.*;\n@@ -16,3 +17,3 @@\n-        try (var absOp = ort.createSession(OnnxProtoBuilder.buildModel(\n-                List.of(new OnnxProtoBuilder.Input(\"x\", FLOAT.id)),\n-                List.of(new OnnxProtoBuilder.OpNode(\"Abs\", List.of(\"x\"), List.of(\"y\"), Map.of())),\n+        try (var absOp = ort.createSession(build(\n+                List.of(tensorInfo(\"x\", FLOAT.id)),\n+                List.of(node(\"Abs\", List.of(\"x\"), List.of(\"y\"), Map.of())),\n@@ -20,3 +21,3 @@\n-             var addOp = ort.createSession(OnnxProtoBuilder.buildModel(\n-                List.of(new OnnxProtoBuilder.Input(\"a\", FLOAT.id), new OnnxProtoBuilder.Input(\"b\", FLOAT.id)),\n-                List.of(new OnnxProtoBuilder.OpNode(\"Add\", List.of(\"a\", \"b\"), List.of(\"y\"), Map.of())),\n+             var addOp = ort.createSession(build(\n+                List.of(tensorInfo(\"a\", FLOAT.id), tensorInfo(\"b\", FLOAT.id)),\n+                List.of(node(\"Add\", List.of(\"a\", \"b\"), List.of(\"y\"), Map.of())),\n@@ -35,1 +36,1 @@\n-            var absResult = absOp.run(List.of(inputTensor.tensorAddr));\n+            var absResult = absOp.run(List.of(inputTensor));\n@@ -39,1 +40,1 @@\n-            var absOutputTensor = new Tensor(absResult.getFirst());\n+            var absOutputTensor = absResult.getFirst();\n@@ -43,1 +44,1 @@\n-            var addResult = addOp.run(List.of(inputTensor.tensorAddr, absOutputTensor.tensorAddr));\n+            var addResult = addOp.run(List.of(inputTensor, absOutputTensor));\n@@ -47,1 +48,1 @@\n-            var addOutputTensor = new Tensor(addResult.getFirst());\n+            var addOutputTensor = addResult.getFirst();\n@@ -54,0 +55,40 @@\n+\n+    @Test\n+    public void testIf() throws Exception {\n+        var ort = OnnxRuntime.getInstance();\n+        try (var ifOp = ort.createSession(build(\n+                List.of(tensorInfo(\"cond\", BOOL.id), tensorInfo(\"a\", INT64.id), tensorInfo(\"b\", INT64.id)),\n+                List.of(node(\"If\", List.of(\"cond\"), List.of(\"y\"), Map.of(\n+                        \"then_branch\", graph(\n+                                List.of(),\n+                                List.of(node(\"Identity\", List.of(\"a\"), List.of(\"y\"), Map.of())),\n+                                List.of(\"y\")),\n+                        \"else_branch\", graph(\n+                                List.of(),\n+                                List.of(node(\"Identity\", List.of(\"b\"), List.of(\"y\"), Map.of())),\n+                                List.of(\"y\"))))),\n+                List.of(\"y\")))) {\n+\n+            var a = Tensor.ofScalar(1l);\n+            var b = Tensor.ofScalar(2l);\n+            SimpleTest.assertEquals(a, ifOp.run(List.of(Tensor.ofScalar(true), a, b)).getFirst());\n+            SimpleTest.assertEquals(b, ifOp.run(List.of(Tensor.ofScalar(false), a, b)).getFirst());\n+        }\n+    }\n+\n+    @Test\n+    public void testLoop() throws Exception {\n+        var ort = OnnxRuntime.getInstance();\n+        try (var forOp = ort.createSession(build(\n+                List.of(tensorInfo(\"max\", INT64.id), tensorInfo(\"cond\", BOOL.id), tensorInfo(\"a\", INT64.id)),\n+                List.of(node(\"Loop\", List.of(\"max\", \"cond\", \"a\"), List.of(\"a_out\"), Map.of(\n+                        \"body\", graph(\n+                                List.of(scalarInfo(\"i\", INT64.id), scalarInfo(\"cond_in\", BOOL.id), tensorInfo(\"a_in\", INT64.id)),\n+                                List.of(node(\"Identity\", List.of(\"cond_in\"), List.of(\"cond_out\"), Map.of()),\n+                                        node(\"Add\", List.of(\"a_in\", \"a_in\"), List.of(\"a_out\"), Map.of())),\n+                                List.of(\"cond_out\", \"a_out\"))))),\n+                List.of(\"a_out\")))) {\n+\n+            SimpleTest.assertEquals(Tensor.ofScalar(65536l), forOp.run(List.of(Tensor.ofScalar(15l), Tensor.ofScalar(true), Tensor.ofScalar(2l))).getFirst());\n+        }\n+    }\n","filename":"cr-examples\/onnx\/src\/test\/java\/oracle\/code\/onnx\/RuntimeTest.java","additions":51,"deletions":10,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -3,1 +3,1 @@\n-import java.lang.foreign.MemorySegment;\n+import java.lang.foreign.ValueLayout;\n@@ -8,0 +8,1 @@\n+import java.util.List;\n@@ -114,3 +115,1 @@\n-        return new Tensor(OnnxRuntime.getInstance().runFunc(\n-                getOnnxModel(name),\n-                Stream.of(params).map(t -> t.tensorAddr).toList()).getFirst());\n+        return OnnxRuntime.getInstance().run(getOnnxModel(name).body().entryBlock(), List.of(params)).getFirst();\n@@ -125,18 +124,0 @@\n-        assertEquals(expected.tensorAddr, actual.tensorAddr);\n-    }\n-\n-    static void assertEquals(MemorySegment expectedTensorAddr, MemorySegment actualTensorAddr) {\n-\n-        var rt = OnnxRuntime.getInstance();\n-\n-        var expectedType = rt.tensorElementType(expectedTensorAddr);\n-        var expectedShape = rt.tensorShape(expectedTensorAddr);\n-        var expectedBB = rt.tensorBuffer(expectedTensorAddr);\n-\n-        var actualType = rt.tensorElementType(actualTensorAddr);\n-        var actualShape = rt.tensorShape(actualTensorAddr);\n-        var actualBB = rt.tensorBuffer(actualTensorAddr);\n-\n-        Assertions.assertSame(expectedType, actualType);\n-\n-        Assertions.assertArrayEquals(expectedShape, actualShape);\n@@ -144,3 +125,20 @@\n-        switch (actualType) {\n-            case UINT8, INT8, UINT16, INT16, INT32, INT64, STRING, BOOL, UINT32, UINT64, UINT4, INT4 ->\n-                assertEquals(expectedBB, actualBB);\n+        var expectedType = expected.elementType();\n+        Assertions.assertSame(expectedType, actual.elementType());\n+\n+        Assertions.assertArrayEquals(expected.shape(), actual.shape());\n+\n+        switch (expectedType) {\n+            case UINT8, INT8, BOOL, UINT4, INT4 ->\n+                Assertions.assertArrayEquals(expected.data().toArray(ValueLayout.JAVA_BYTE),\n+                                             actual.data().toArray(ValueLayout.JAVA_BYTE));\n+            case UINT16, INT16 ->\n+                Assertions.assertArrayEquals(expected.data().toArray(ValueLayout.JAVA_SHORT),\n+                                             actual.data().toArray(ValueLayout.JAVA_SHORT));\n+            case INT32, UINT32 ->\n+                Assertions.assertArrayEquals(expected.data().toArray(ValueLayout.JAVA_INT),\n+                                             actual.data().toArray(ValueLayout.JAVA_INT));\n+            case INT64, UINT64 ->\n+                Assertions.assertArrayEquals(expected.data().toArray(ValueLayout.JAVA_LONG),\n+                                             actual.data().toArray(ValueLayout.JAVA_LONG));\n+            case STRING ->\n+                Assertions.assertEquals(expected.data().getString(0), actual.data().getString(0));\n@@ -148,1 +146,2 @@\n-                assertEquals(expectedBB.asFloatBuffer(), actualBB.asFloatBuffer());\n+                Assertions.assertArrayEquals(expected.data().toArray(ValueLayout.JAVA_FLOAT),\n+                                             actual.data().toArray(ValueLayout.JAVA_FLOAT));\n@@ -150,1 +149,2 @@\n-                assertEquals(expectedBB.asDoubleBuffer(), actualBB.asDoubleBuffer());\n+                Assertions.assertArrayEquals(expected.data().toArray(ValueLayout.JAVA_DOUBLE),\n+                                             actual.data().toArray(ValueLayout.JAVA_DOUBLE));\n@@ -152,1 +152,1 @@\n-                throw new UnsupportedOperationException(\"Unsupported tensor element type \" + actualType);\n+                throw new UnsupportedOperationException(\"Unsupported tensor element type \" + expectedType);\n","filename":"cr-examples\/onnx\/src\/test\/java\/oracle\/code\/onnx\/SimpleTest.java","additions":28,"deletions":28,"binary":false,"changes":56,"status":"modified"}]}