{"files":[{"patch":"@@ -28,0 +28,1 @@\n+import java.lang.foreign.ValueLayout;\n@@ -29,0 +30,1 @@\n+import java.util.function.Supplier;\n@@ -77,0 +79,4 @@\n+\n+    public static <T> Tensor<T> If(Tensor<Boolean> cond, Supplier<Tensor<T>> elseBody, Supplier<Tensor<T>> thenBody) {\n+        return cond.data().get(ValueLayout.JAVA_BOOLEAN, 0) ? thenBody.get() : elseBody.get();\n+    }\n","filename":"cr-examples\/onnx\/src\/main\/java\/oracle\/code\/onnx\/ExplicitOnnxOperators.java","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -0,0 +1,173 @@\n+package oracle.code.onnx;\n+\n+import java.lang.invoke.MethodHandles;\n+import java.lang.reflect.Method;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import jdk.incubator.code.Op;\n+import jdk.incubator.code.Value;\n+import jdk.incubator.code.op.CoreOp;\n+import jdk.incubator.code.type.ClassType;\n+import jdk.incubator.code.type.FunctionType;\n+import jdk.incubator.code.type.MethodRef;\n+import jdk.incubator.code.type.VarType;\n+import oracle.code.onnx.compiler.OnnxTransformer;\n+\n+public record LambdaToFunc(OnnxTransformer.OnnxFuncOp func, int[] operandsMapping) {\n+\n+    public static LambdaToFunc fromLambda(MethodHandles.Lookup l, CoreOp.LambdaOp lambda, Map<Value, Object> evaluatedValues) {\n+        evaluatedValues = new HashMap<>(evaluatedValues);\n+        \/\/ Shortcut for lambda expressions that call just one method\n+        if (singleMethodInvocation(lambda) instanceof\n+                SingleMethod(CoreOp.InvokeOp iop, Map<Value, Value> valueMapping)) {\n+            Method m;\n+            try {\n+                m = iop.invokeDescriptor().resolveToMethod(l, iop.invokeKind());\n+            } catch (ReflectiveOperationException e) {\n+                throw new RuntimeException(e);\n+            }\n+\n+            var fOpt = Op.ofMethod(m);\n+            if (fOpt.isPresent()) {\n+                CoreOp.FuncOp f = Op.ofMethod(m).orElseThrow();\n+                var operands = iop.operands();\n+                var captured = lambda.capturedValues();\n+                var operandsMapping = new int[iop.operands().size()];\n+                var fParams = f.parameters();\n+                for (int i = 0; i < operandsMapping.length; i++) {\n+                    var opValue = valueMapping.get(operands.get(i));\n+                    operandsMapping[i] = captured.indexOf(opValue);\n+                    if (i == 0) {\n+                        var value = evaluatedValues.get(opValue);\n+                        if (value instanceof CoreOp.Var v) {\n+                            value = v.value();\n+                        }\n+                        if (value != null && !(value instanceof Tensor)) {\n+                            \/\/ @@@ probably a receiver\n+                            evaluatedValues.put(fParams.get(i), value);\n+                        }\n+                    }\n+                }\n+                OnnxTransformer.OnnxFuncOp onnxFunc = OnnxTransformer.transform(l, evaluatedValues, f);\n+                return new LambdaToFunc(onnxFunc, operandsMapping);\n+            }\n+        }\n+        var capturedValues = lambda.capturedValues();\n+        var functionType = FunctionType.functionType(lambda.invokableType().returnType(),\n+                capturedValues.stream().map(Value::type)\n+                        .map(t -> t instanceof VarType vt ? vt.valueType() : t).toList());\n+        OnnxTransformer.OnnxFuncOp onnxFunc = OnnxTransformer.transform(l, evaluatedValues, CoreOp.func(\"onnxCode\", functionType)\n+                .body(bb -> {\n+                    bb.context().mapValues(capturedValues, bb.parameters());\n+                    for (Op op : lambda.body().entryBlock().ops()) {\n+                        int i;\n+                        if (op instanceof CoreOp.VarAccessOp.VarLoadOp load &&\n+                                (i = capturedValues.indexOf(load.varOp().result())) >= 0) {\n+                            bb.context().mapValue(op.result(), bb.parameters().get(i)); \/\/ remap var load result to block param\n+                        } else {\n+                            bb.apply(op);\n+                        }\n+                    }\n+                }));\n+\n+        var operandsMapping = new int[capturedValues.size()];\n+        for (int i = 0; i < operandsMapping.length; i++) {\n+            operandsMapping[i] = i;\n+        }\n+        return new LambdaToFunc(onnxFunc, operandsMapping);\n+    }\n+\n+    record SingleMethod(CoreOp.InvokeOp iop, Map<Value, Value> valueMapping) {}\n+    static SingleMethod singleMethodInvocation(CoreOp.LambdaOp lop) {\n+        \/\/ Single block\n+        if (lop.body().blocks().size() > 1) {\n+            return null;\n+        }\n+\n+        Map<Value, Value> valueMapping = new HashMap<>();\n+        CoreOp.InvokeOp methodRefInvokeOp = extractMethodInvoke(valueMapping, lop.body().entryBlock().ops());\n+        if (methodRefInvokeOp == null) {\n+            return null;\n+        }\n+\n+        return new SingleMethod(methodRefInvokeOp, valueMapping);\n+    }\n+\n+    static CoreOp.InvokeOp extractMethodInvoke(Map<Value, Value> valueMapping, List<Op> ops) {\n+        CoreOp.InvokeOp methodRefInvokeOp = null;\n+        for (Op op : ops) {\n+            switch (op) {\n+                case CoreOp.VarOp varOp -> {\n+                    if (isValueUsedWithOp(varOp.result(), o -> o instanceof CoreOp.VarAccessOp.VarStoreOp)) {\n+                        return null;\n+                    }\n+                }\n+                case CoreOp.VarAccessOp.VarLoadOp varLoadOp -> {\n+                    Value v = varLoadOp.varOp().result();\n+                    valueMapping.put(varLoadOp.result(), valueMapping.getOrDefault(v, v));\n+                }\n+                case CoreOp.InvokeOp iop when isBoxOrUnboxInvocation(iop) -> {\n+                    Value v = iop.operands().getFirst();\n+                    valueMapping.put(iop.result(), valueMapping.getOrDefault(v, v));\n+                }\n+                case CoreOp.InvokeOp iop -> {\n+                    if (methodRefInvokeOp != null) {\n+                        return null;\n+                    }\n+\n+                    for (Value o : iop.operands()) {\n+                        valueMapping.put(o, valueMapping.getOrDefault(o, o));\n+                    }\n+                    methodRefInvokeOp = iop;\n+                }\n+                case CoreOp.ReturnOp rop -> {\n+                    if (methodRefInvokeOp == null) {\n+                        return null;\n+                    }\n+                    Value r = rop.returnValue();\n+                    if (!(valueMapping.getOrDefault(r, r) instanceof Op.Result invokeResult)) {\n+                        return null;\n+                    }\n+                    if (invokeResult.op() != methodRefInvokeOp) {\n+                        return null;\n+                    }\n+                    assert methodRefInvokeOp.result().uses().size() == 1;\n+                }\n+                default -> {\n+                    return null;\n+                }\n+            }\n+        }\n+\n+        return methodRefInvokeOp;\n+    }\n+\n+    private static boolean isValueUsedWithOp(Value value, Predicate<Op> opPredicate) {\n+        for (Op.Result user : value.uses()) {\n+            if (opPredicate.test(user.op())) {\n+                return true;\n+            }\n+        }\n+        return false;\n+    }\n+\n+    \/\/ @@@ Move to functionality on JavaType(s)\n+    static final Set<String> UNBOX_NAMES = Set.of(\n+            \"byteValue\",\n+            \"shortValue\",\n+            \"charValue\",\n+            \"intValue\",\n+            \"longValue\",\n+            \"floatValue\",\n+            \"doubleValue\",\n+            \"booleanValue\");\n+\n+    private static boolean isBoxOrUnboxInvocation(CoreOp.InvokeOp iop) {\n+        MethodRef mr = iop.invokeDescriptor();\n+        return mr.refType() instanceof ClassType ct && ct.unbox().isPresent() &&\n+                (UNBOX_NAMES.contains(mr.name()) || mr.name().equals(\"valueOf\"));\n+    }\n+}\n","filename":"cr-examples\/onnx\/src\/main\/java\/oracle\/code\/onnx\/LambdaToFunc.java","additions":173,"deletions":0,"binary":false,"changes":173,"status":"added"},{"patch":"@@ -4,0 +4,1 @@\n+import java.lang.foreign.ValueLayout;\n@@ -5,1 +6,1 @@\n-import java.util.IdentityHashMap;\n+import java.util.HashMap;\n@@ -9,0 +10,1 @@\n+import java.util.stream.LongStream;\n@@ -13,0 +15,1 @@\n+import oracle.code.onnx.ir.OnnxOps;\n@@ -263,0 +266,11 @@\n+    private static final class Indexer extends HashMap<Value, String> {\n+        String getName(Value v) {\n+            return computeIfAbsent(v, _ -> \"#\" + size());\n+        }\n+        String getName(Value v, int subIndex) {\n+            var name = getName(v);\n+            if (subIndex != 0) name += \".\" + subIndex;\n+            return name;\n+        }\n+    }\n+\n@@ -267,13 +281,27 @@\n-    static byte[] build(Block block) {\n-        var indexer = new IdentityHashMap<Value, String>() {\n-            String getName(Value v) {\n-                return computeIfAbsent(v, _ -> \"#\" + size());\n-            }\n-            String getName(Value v, int subIndex) {\n-                var name = getName(v);\n-                if (subIndex != 0) name += \".\" + subIndex;\n-                return name;\n-            }\n-        };\n-        return build(\n-                block.parameters().stream().map(v -> tensorInfo(indexer.getName(v), ((OnnxType.TensorType)v.type()).eType().id())).toList(),\n+    static byte[] build(Block block, List<oracle.code.onnx.Tensor> initializers) {\n+        var indexer = new Indexer();\n+        var model = build(graph(indexer, block, initializers));\n+\/\/        OnnxProtoPrinter.printModel(model);\n+        return model;\n+    }\n+\n+    static byte[] build(List<TensorProto> initializers, List<ValueInfoProto> inputs, List<NodeProto> ops, List<String> outputNames) {\n+        return build(graph(initializers, inputs, ops, outputNames));\n+    }\n+\n+    static byte[] build(GraphProto graph) {\n+        return new ModelProto()\n+                .ir_version(IR_VERSION)\n+                .graph(graph)\n+                .opset_import(new OperatorSetIdProto().version(OPSET_VERSION))\n+                .buf.toByteArray();\n+    }\n+\n+    static GraphProto graph(Indexer indexer, Block block, List<oracle.code.onnx.Tensor> initializers) {\n+        var params = block.parameters();\n+        int first = params.size() - initializers.size();\n+        var args = params.isEmpty() || params.getFirst().type() instanceof OnnxType.TensorType ? params : params.subList(1, params.size());\n+        return graph(\n+                IntStream.range(0, initializers.size()).mapToObj(i -> tensorProto(indexer.getName(params.get(i + first)), initializers.get(i))).toList(),\n+                args.stream().map(v ->\n+                        tensorInfo(indexer.getName(v), ((OnnxType.TensorType)v.type()).eType().id())).toList(),\n@@ -282,0 +310,8 @@\n+                        case OnnxOps.If ifOp ->\n+                            opNodes.accept(node(\n+                                    ifOp.opName(),\n+                                    List.of(indexer.getName(ifOp.operands().getFirst())),\n+                                    List.of(indexer.getName(ifOp.result())),\n+                                    java.util.Map.of( \/\/ @@@ wrong mapping of captured inputs\n+                                            \"else_branch\", graph(indexer, ifOp.elseBranch().entryBlock(), List.of()),\n+                                            \"then_branch\", graph(indexer, ifOp.thenBranch().entryBlock(), List.of()))));\n@@ -299,9 +335,1 @@\n-    static byte[] build(List<ValueInfoProto> inputs, List<NodeProto> ops, List<String> outputNames) {\n-        return new ModelProto()\n-                .ir_version(IR_VERSION)\n-                .graph(graph(inputs, ops, outputNames))\n-                .opset_import(new OperatorSetIdProto().version(OPSET_VERSION))\n-                .buf.toByteArray();\n-    }\n-\n-    static GraphProto graph(List<ValueInfoProto> inputs, List<NodeProto> ops, List<String> outputNames) {\n+    static GraphProto graph(List<TensorProto> initializers, List<ValueInfoProto> inputs, List<NodeProto> ops, List<String> outputNames) {\n@@ -309,0 +337,1 @@\n+                .forEach(initializers, (g, i) -> g.initializer(i))\n@@ -339,0 +368,8 @@\n+    static TensorProto tensorProto(String name, oracle.code.onnx.Tensor tensor) {\n+        return new TensorProto()\n+                .forEach(LongStream.of(tensor.shape()).boxed().toList(), (tp, d) -> tp.dims(d))\n+                .data_type(tensor.elementType().id)\n+                .raw_data(tensor.data().toArray(ValueLayout.JAVA_BYTE))\n+                .name(name);\n+    }\n+\n","filename":"cr-examples\/onnx\/src\/main\/java\/oracle\/code\/onnx\/OnnxProtoBuilder.java","additions":60,"deletions":23,"binary":false,"changes":83,"status":"modified"},{"patch":"@@ -7,1 +7,0 @@\n-import java.lang.reflect.Method;\n@@ -12,1 +11,0 @@\n-import java.util.function.Predicate;\n@@ -18,5 +16,0 @@\n-import jdk.incubator.code.type.ClassType;\n-import jdk.incubator.code.type.FunctionType;\n-import jdk.incubator.code.type.MethodRef;\n-import jdk.incubator.code.type.VarType;\n-import oracle.code.onnx.compiler.OnnxTransformer;\n@@ -79,49 +72,4 @@\n-            var lambda = (CoreOp.LambdaOp) q.op();\n-\n-            CoreOp.FuncOp onnxFunc;\n-            int[] operandsMapping;\n-\n-            \/\/ Shortcut for lambda expressions that call just one method\n-            if (singleMethodInvocation(lambda) instanceof\n-                    SingleMethod(CoreOp.InvokeOp iop, Map<Value, Value> valueMapping)) {\n-                Method m;\n-                try {\n-                    m = iop.invokeDescriptor().resolveToMethod(l, iop.invokeKind());\n-                } catch (ReflectiveOperationException e) {\n-                    throw new RuntimeException(e);\n-                }\n-\n-                CoreOp.FuncOp f = Op.ofMethod(m).orElseThrow();\n-                onnxFunc = OnnxTransformer.transform(l, f);\n-\n-                var operands = iop.operands();\n-                var captured = q.capturedValues().sequencedKeySet().stream().toList();\n-                operandsMapping = new int[iop.operands().size()];\n-                for (int i = 0; i < operandsMapping.length; i++) {\n-                    operandsMapping[i] = captured.indexOf(valueMapping.get(operands.get(i)));\n-                }\n-\n-            } else {\n-                var capturedValues = lambda.capturedValues();\n-                var functionType = FunctionType.functionType(lambda.invokableType().returnType(),\n-                        capturedValues.stream().map(Value::type)\n-                                .map(t -> t instanceof VarType vt ? vt.valueType() : t).toList());\n-                onnxFunc = OnnxTransformer.transform(l, CoreOp.func(\"onnxCode\", functionType)\n-                        .body(bb -> {\n-                            bb.context().mapValues(capturedValues, bb.parameters());\n-                            for (Op op : lambda.body().entryBlock().ops()) {\n-                                int i;\n-                                if (op instanceof CoreOp.VarAccessOp.VarLoadOp load &&\n-                                        (i = capturedValues.indexOf(load.varOp().result())) >= 0) {\n-                                    bb.context().mapValue(op.result(), bb.parameters().get(i)); \/\/ remap var load result to block param\n-                                } else {\n-                                    bb.apply(op);\n-                                }\n-                            }\n-                        }));\n-\n-                operandsMapping = new int[capturedValues.size()];\n-                for (int i = 0; i < operandsMapping.length; i++) {\n-                    operandsMapping[i] = i;\n-                }\n-            }\n+            var mf = LambdaToFunc.fromLambda(l, (CoreOp.LambdaOp)q.op(), q.capturedValues());\n+\n+            List<Tensor> initializers = mf.func().initializers().stream().map(val -> (Tensor) val).toList();\n+\n@@ -130,1 +78,1 @@\n-                    OnnxProtoBuilder.build(onnxFunc.body().entryBlock())), operandsMapping);\n+                    OnnxProtoBuilder.build(mf.func().func().body().entryBlock(), initializers)), mf.operandsMapping());\n@@ -136,2 +84,2 @@\n-    public static <T> Tensor<T> execute(MethodHandles.Lookup lookup, OnnxFunction<Tensor<T>> codeLambda) {\n-        return execute(Arena.ofAuto(), lookup, codeLambda);\n+    public static <T> Tensor<T> execute(MethodHandles.Lookup l, OnnxFunction<Tensor<T>> codeLambda) {\n+        return execute(Arena.ofAuto(), l, codeLambda);\n@@ -140,1 +88,2 @@\n-    public static <T> Tensor<T> execute(Arena arena, MethodHandles.Lookup lookup, OnnxFunction<Tensor<T>> codeLambda) {\n+\n+    public static <T> Tensor<T> execute(Arena arena, MethodHandles.Lookup l, OnnxFunction<Tensor<T>> codeLambda) {\n@@ -143,1 +92,1 @@\n-        var model = SESSION_CACHE.computeIfAbsent(codeLambda.getClass(), lookup, q);\n+        var model = SESSION_CACHE.computeIfAbsent(codeLambda.getClass(), l, q);\n@@ -149,1 +98,5 @@\n-                .map(val -> (Tensor) val)\n+                .<Tensor>mapMulti((val, args) -> {\n+                    if (val instanceof Tensor t) {\n+                        args.accept(t);\n+                    }\n+                })\n@@ -155,91 +108,0 @@\n-    record SingleMethod(CoreOp.InvokeOp iop, Map<Value, Value> valueMapping) {}\n-    static SingleMethod singleMethodInvocation(CoreOp.LambdaOp lop) {\n-        \/\/ Single block\n-        if (lop.body().blocks().size() > 1) {\n-            return null;\n-        }\n-\n-        Map<Value, Value> valueMapping = new HashMap<>();\n-        CoreOp.InvokeOp methodRefInvokeOp = extractMethodInvoke(valueMapping, lop.body().entryBlock().ops());\n-        if (methodRefInvokeOp == null) {\n-            return null;\n-        }\n-\n-        return new SingleMethod(methodRefInvokeOp, valueMapping);\n-    }\n-\n-    static CoreOp.InvokeOp extractMethodInvoke(Map<Value, Value> valueMapping, List<Op> ops) {\n-        CoreOp.InvokeOp methodRefInvokeOp = null;\n-        for (Op op : ops) {\n-            switch (op) {\n-                case CoreOp.VarOp varOp -> {\n-                    if (isValueUsedWithOp(varOp.result(), o -> o instanceof CoreOp.VarAccessOp.VarStoreOp)) {\n-                        return null;\n-                    }\n-                }\n-                case CoreOp.VarAccessOp.VarLoadOp varLoadOp -> {\n-                    Value v = varLoadOp.varOp().result();\n-                    valueMapping.put(varLoadOp.result(), valueMapping.getOrDefault(v, v));\n-                }\n-                case CoreOp.InvokeOp iop when isBoxOrUnboxInvocation(iop) -> {\n-                    Value v = iop.operands().getFirst();\n-                    valueMapping.put(iop.result(), valueMapping.getOrDefault(v, v));\n-                }\n-                case CoreOp.InvokeOp iop -> {\n-                    if (methodRefInvokeOp != null) {\n-                        return null;\n-                    }\n-\n-                    for (Value o : iop.operands()) {\n-                        valueMapping.put(o, valueMapping.getOrDefault(o, o));\n-                    }\n-                    methodRefInvokeOp = iop;\n-                }\n-                case CoreOp.ReturnOp rop -> {\n-                    if (methodRefInvokeOp == null) {\n-                        return null;\n-                    }\n-                    Value r = rop.returnValue();\n-                    if (!(valueMapping.getOrDefault(r, r) instanceof Op.Result invokeResult)) {\n-                        return null;\n-                    }\n-                    if (invokeResult.op() != methodRefInvokeOp) {\n-                        return null;\n-                    }\n-                    assert methodRefInvokeOp.result().uses().size() == 1;\n-                }\n-                default -> {\n-                    return null;\n-                }\n-            }\n-        }\n-\n-        return methodRefInvokeOp;\n-    }\n-\n-    private static boolean isValueUsedWithOp(Value value, Predicate<Op> opPredicate) {\n-        for (Op.Result user : value.uses()) {\n-            if (opPredicate.test(user.op())) {\n-                return true;\n-            }\n-        }\n-        return false;\n-    }\n-\n-    \/\/ @@@ Move to functionality on JavaType(s)\n-    static final Set<String> UNBOX_NAMES = Set.of(\n-            \"byteValue\",\n-            \"shortValue\",\n-            \"charValue\",\n-            \"intValue\",\n-            \"longValue\",\n-            \"floatValue\",\n-            \"doubleValue\",\n-            \"booleanValue\");\n-\n-    private static boolean isBoxOrUnboxInvocation(CoreOp.InvokeOp iop) {\n-        MethodRef mr = iop.invokeDescriptor();\n-        return mr.refType() instanceof ClassType ct && ct.unbox().isPresent() &&\n-                (UNBOX_NAMES.contains(mr.name()) || mr.name().equals(\"valueOf\"));\n-    }\n-\n@@ -274,0 +136,1 @@\n+                List.of(),\n@@ -285,2 +148,2 @@\n-    public List<Tensor> run(Arena arena, Block block, List<Tensor> inputValues) {\n-        var protoModel = OnnxProtoBuilder.build(block);\n+    public List<Tensor> run(Arena arena, Block block, List<Tensor> inputValues, int initializers) {\n+        var protoModel = OnnxProtoBuilder.build(block, inputValues.subList(0, initializers));\n@@ -288,1 +151,1 @@\n-                .run(arena, inputValues);\n+                .run(arena, inputValues.subList(initializers, inputValues.size()));\n","filename":"cr-examples\/onnx\/src\/main\/java\/oracle\/code\/onnx\/OnnxRuntime.java","additions":19,"deletions":156,"binary":false,"changes":175,"status":"modified"},{"patch":"@@ -149,0 +149,8 @@\n+    public static <T> Tensor<T> ofShape(long[] shape, byte[] rawData, ElementType elementType) {\n+        return ofShape(Arena.ofAuto(), shape, rawData, elementType);\n+    }\n+\n+    public static <T> Tensor<T> ofShape(Arena arena, long[] shape, byte[] rawData, ElementType elementType) {\n+        return new Tensor(arena, arena.allocateFrom(ValueLayout.JAVA_BYTE, rawData), elementType, shape);\n+    }\n+\n","filename":"cr-examples\/onnx\/src\/main\/java\/oracle\/code\/onnx\/Tensor.java","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -40,0 +40,2 @@\n+import oracle.code.onnx.Tensor;\n+import oracle.code.onnx.ir.ExplicitOnnxOps;\n@@ -44,0 +46,1 @@\n+    static final TypeElement TENSOR_RAW_CLASS = JavaType.type(Tensor.class);\n@@ -52,0 +55,2 @@\n+    List<Object> initializers;\n+\n@@ -55,0 +60,1 @@\n+        this.initializers = new ArrayList<>();\n@@ -58,3 +64,4 @@\n-    void evaluate(MethodHandles.Lookup l, T op) {\n-        Map<Value, Object> evaluatedValues = new HashMap<>();\n-        interpretEntryBlock(l, op.body().entryBlock(), new OpContext(), evaluatedValues);\n+    void evaluate(MethodHandles.Lookup l, T op, Map<Value, Object> evaluatedValues) {\n+        var ev = new HashMap(evaluatedValues);\n+\n+        interpretEntryBlock(l, op.body().entryBlock(), new OpContext(), ev);\n@@ -62,3 +69,3 @@\n-        evaluatedAttributes.forEach((invokeOp, objects) -> {\n-            System.out.println(invokeOp.invokeDescriptor().name() + \" -> \" + objects);\n-        });\n+\/\/        evaluatedAttributes.forEach((invokeOp, objects) -> {\n+\/\/            System.out.println(invokeOp.invokeDescriptor().name() + \" -> \" + objects);\n+\/\/        });\n@@ -276,0 +283,3 @@\n+            try {\n+                return (Class) Class.forName(ExplicitOnnxOps.class.getName() + \"$\" + operatorName);\n+            } catch (ClassNotFoundException _) {}\n@@ -300,1 +310,1 @@\n-            assert o.operands().subList(0, inputs.size()).stream().noneMatch(oc::isValueDefined);\n+\/\/            assert o.operands().subList(0, inputs.size()).stream().noneMatch(oc::isValueDefined);\n@@ -314,0 +324,6 @@\n+            } else if (opClass == ExplicitOnnxOps.If.class) {\n+                \/\/ @@@ hard-coded 2 extra undeclared attributes\n+                List<Object> attrs = o.operands().subList(inputs.size(), inputs.size() + 2).stream()\n+                        .map(oc::getValue)\n+                        .toList();\n+                evaluatedAttributes.put(io, attrs);\n@@ -324,0 +340,12 @@\n+            unevaluatedOperations.add(o);\n+            return null;\n+        } else if (o instanceof CoreOp.FieldAccessOp.FieldLoadOp fo && fo.fieldDescriptor().type() instanceof ClassType ct && ct.rawType().equals(TENSOR_RAW_CLASS)) {\n+            try {\n+                if (fo.operands().isEmpty()) {\n+                    initializers.add(fo.fieldDescriptor().resolveToHandle(l).get());\n+                } else {\n+                    initializers.add(fo.fieldDescriptor().resolveToHandle(l).get(oc.getValue(fo.operands().getFirst())));\n+                }\n+            } catch (ReflectiveOperationException ex) {\n+                throw interpreterException(ex);\n+            }\n@@ -470,0 +498,3 @@\n+            case CoreOp.LambdaOp lambdaOp -> {\n+                return lambdaOp;\n+            }\n","filename":"cr-examples\/onnx\/src\/main\/java\/oracle\/code\/onnx\/compiler\/OnnxPartialEvaluator.java","additions":38,"deletions":7,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -20,0 +20,3 @@\n+import jdk.incubator.code.*;\n+import oracle.code.onnx.LambdaToFunc;\n+import oracle.code.onnx.ir.ExplicitOnnxOps;\n@@ -29,1 +32,3 @@\n-    public static CoreOp.FuncOp transform(MethodHandles.Lookup l, CoreOp.FuncOp in) {\n+    public record OnnxFuncOp(CoreOp.FuncOp func, List<Object> initializers) {}\n+\n+    public static OnnxFuncOp transform(MethodHandles.Lookup l, Map<Value, Object> evaluatedValues, CoreOp.FuncOp in) {\n@@ -31,1 +36,1 @@\n-        pe.evaluate(l, in);\n+        pe.evaluate(l, in, evaluatedValues);\n@@ -37,1 +42,0 @@\n-\n@@ -99,1 +103,17 @@\n-                        opArgs.addAll(attributes);\n+                        opArgs.addAll(attributes.stream().map(a -> {\n+                            if (a instanceof CoreOp.LambdaOp lo) {\n+                                var ltf = LambdaToFunc.fromLambda(l, lo, evaluatedValues);\n+                                var cc = bb.context();\n+                                var lbb = Body.Builder.of(bb.parentBody(), lo.invokableType(), cc);\n+                                var eb = lbb.entryBlock();\n+                                var params = ltf.func().func().body().entryBlock().parameters();\n+                                var captured = lo.capturedValues();\n+                                for (int i = 0; i < params.size(); i++) {\n+                                    var param = params.get(i);\n+                                    cc.mapValue(param, eb.op(OnnxOps.Identity(param.type(), cc.getValue(traverseUp(captured.get(i))))));\n+                                }\n+                                ltf.func().func().body().entryBlock().ops().forEach(eb::apply);\n+                                return lbb;\n+                            }\n+                            return a;\n+                        }).toList());\n@@ -116,0 +136,3 @@\n+                    case CoreOp.FieldAccessOp.FieldLoadOp fo when fo.fieldDescriptor().type() instanceof ClassType ct && ct.rawType().equals(TENSOR_RAW_CLASS) -> {\n+                        bb.context().mapValue(fo.result(), b.parameter(type(fo.resultType())));\n+                    }\n@@ -123,1 +146,1 @@\n-        return SSA.transform(onnxModel).transform((b, op) -> {\n+        return new OnnxFuncOp(SSA.transform(onnxModel).transform((b, op) -> {\n@@ -129,1 +152,6 @@\n-        });\n+        }), pe.initializers);\n+    }\n+\n+    static Value traverseUp(Value v) {\n+        \/\/ @@@ when captured value is a VaroOp\n+        return v instanceof Op.Result or && or.op() instanceof CoreOp.VarOp vo && !vo.isUninitialized()? vo.initOperand() : v;\n@@ -138,0 +166,3 @@\n+            try {\n+                return (Class) Class.forName(ExplicitOnnxOps.class.getName() + \"$\" + operatorName);\n+            } catch (ClassNotFoundException _) {}\n@@ -215,1 +246,1 @@\n-    static OnnxType type(TypeElement type) {\n+    static TypeElement type(TypeElement type) {\n@@ -226,0 +257,2 @@\n+            } else if (elementType.equals(JavaType.J_L_BOOLEAN)) {\n+                return OnnxType.TENSOR_BOOL;\n@@ -228,1 +261,2 @@\n-        throw new UnsupportedOperationException(\"Unknown type: \" + type);\n+        return type;\n+\/\/        throw new UnsupportedOperationException(\"Unknown type: \" + type);\n","filename":"cr-examples\/onnx\/src\/main\/java\/oracle\/code\/onnx\/compiler\/OnnxTransformer.java","additions":42,"deletions":8,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -0,0 +1,177 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package oracle.code.onnx.ir;\n+\n+import java.util.List;\n+import java.util.SequencedMap;\n+import java.util.SequencedSet;\n+import java.util.Set;\n+import jdk.incubator.code.*;\n+import jdk.incubator.code.Op.Nested;\n+import jdk.incubator.code.op.ExternalizableOp;\n+import jdk.incubator.code.op.OpFactory;\n+\n+public sealed class ExplicitOnnxOps permits OnnxOps {\n+\n+    @OpFactory.OpDeclaration(If.NAME)\n+    public static final class If extends OnnxOp implements Nested {\n+        public static final String NAME = \"If\";\n+\n+        final Body elseBody, thenBody;\n+\n+        \/\/ @@@ make or fake elseBody as \"else_branch\" attribute and thenBody as \"then_branch\" attribute\n+        public enum Attribute implements OnnxOp.OnnxAttribute.None { }\n+\n+        public enum TypeConstraint implements OnnxOp.OnnxTypeConstraint {\n+            V(new OnnxType.TypeVariable(\"V\", List.of(OnnxType.tensor(OnnxType.uint8()), OnnxType.tensor(OnnxType.uint16()), OnnxType.tensor(OnnxType.uint32()), OnnxType.tensor(OnnxType.uint64()), OnnxType.tensor(OnnxType.int8()), OnnxType.tensor(OnnxType.int16()), OnnxType.tensor(OnnxType.int32()), OnnxType.tensor(OnnxType.int64()), OnnxType.tensor(OnnxType.bfloat16()), OnnxType.tensor(OnnxType.float16()), OnnxType.tensor(OnnxType.float32()), OnnxType.tensor(OnnxType.float64()), OnnxType.tensor(OnnxType.bool())))),\n+            B(new OnnxType.TypeVariable(\"B\", List.of(OnnxType.tensor(OnnxType.bool())))),\n+            ;\n+\n+            final OnnxType.TypeVariable typeVariable;\n+\n+            TypeConstraint(OnnxType.TypeVariable typeVariable) {\n+                assert typeVariable.name().equals(name());\n+                this.typeVariable = typeVariable;\n+            }\n+\n+            @Override\n+            public OnnxType.TypeVariable typeVariable() {\n+                return typeVariable;\n+            }\n+        }\n+\n+        public enum InputParameter implements OnnxOp.OnnxParameter {\n+            cond(TypeConstraint.B.typeVariable(), OnnxOp.OnnxParameter.Quantifier.REQUIRED),\n+            ;\n+\n+            final OnnxType type;\n+            final OnnxOp.OnnxParameter.Quantifier quantifier;\n+\n+            InputParameter(OnnxType type, OnnxOp.OnnxParameter.Quantifier quantifier) {\n+                this.type = type;\n+                this.quantifier = quantifier;\n+            }\n+\n+            @Override\n+            public OnnxType type() {\n+                return type;\n+            }\n+\n+            @Override\n+            public OnnxOp.OnnxParameter.Quantifier quantifier() {\n+                return quantifier;\n+            }\n+        }\n+\n+        public enum OutputParameter implements OnnxOp.OnnxParameter {\n+            output(TypeConstraint.V.typeVariable(), OnnxOp.OnnxParameter.Quantifier.VARIADIC),\n+            ;\n+\n+            final OnnxType type;\n+            final OnnxOp.OnnxParameter.Quantifier quantifier;\n+\n+            OutputParameter(OnnxType type, OnnxOp.OnnxParameter.Quantifier quantifier) {\n+                this.type = type;\n+                this.quantifier = quantifier;\n+            }\n+\n+            @Override\n+            public OnnxType type() {\n+                return type;\n+            }\n+\n+            @Override\n+            public OnnxOp.OnnxParameter.Quantifier quantifier() {\n+                return quantifier;\n+            }\n+        }\n+\n+        public static final OnnxOp.OnnxSchema SCHEMA = new OnnxSchemaRecord(\n+                NAME,\n+                List.of(Attribute.values()),\n+                List.of(TypeConstraint.values()),\n+                List.of(InputParameter.values()),\n+                List.of(OutputParameter.values())\n+        );\n+\n+        public If(ExternalizableOp.ExternalizedOp def) {\n+            super(SCHEMA, def);\n+\n+            this.elseBody = def.bodyDefinitions().get(0).build(this);\n+            this.thenBody = def.bodyDefinitions().get(1).build(this);\n+        }\n+\n+        If(If that, CopyContext cc, OpTransformer ot) {\n+            super(that, cc);\n+\n+            this.elseBody = that.elseBody.transform(cc, ot).build(this);\n+            this.thenBody = that.thenBody.transform(cc, ot).build(this);\n+        }\n+\n+        @Override\n+        public If transform(CopyContext cc, OpTransformer ot) {\n+            return new If(this, cc, ot);\n+        }\n+\n+        If(TypeElement resultType, Value cond, Body.Builder elseBranch, Body.Builder thenBranch) {\n+            super(SCHEMA, resultType, Set.of(), List.of(cond), List.of());\n+\n+            this.elseBody = elseBranch.build(this);\n+            this.thenBody = thenBranch.build(this);\n+        }\n+\n+        @Override\n+        public List<Body> bodies() {\n+            return List.of(elseBody, thenBody);\n+        }\n+\n+        @Override\n+        public SequencedSet<OnnxOp.OnnxParameter> onnxOutputs() {\n+            return onnxOutputs(SCHEMA);\n+        }\n+\n+        @Override\n+        public SequencedMap<OnnxOp.OnnxParameter, Object> onnxInputs() {\n+            return onnxInputs(SCHEMA, List.of(cond()));\n+        }\n+\n+        public Value cond() {\n+            return operands().get(0);\n+        }\n+\n+        public Body elseBranch() {\n+            return elseBody;\n+        }\n+\n+        public Body thenBranch() {\n+            return thenBody;\n+        }\n+    }\n+\n+    public static If If(TypeElement resultType, Value cond, Body.Builder elseBody, Body.Builder thenBody) {\n+        return new If(resultType, cond, elseBody, thenBody);\n+    }\n+}\n","filename":"cr-examples\/onnx\/src\/main\/java\/oracle\/code\/onnx\/ir\/ExplicitOnnxOps.java","additions":177,"deletions":0,"binary":false,"changes":177,"status":"added"},{"patch":"@@ -35,1 +35,1 @@\n-public final class OnnxOps {\n+public final class OnnxOps extends ExplicitOnnxOps {\n","filename":"cr-examples\/onnx\/src\/main\/java\/oracle\/code\/onnx\/ir\/OnnxOps.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+import java.util.HashMap;\n@@ -61,1 +62,0 @@\n-import static oracle.code.onnx.OnnxOperators.Reshape;\n@@ -112,3 +112,0 @@\n-        var shape = Constant(new long[]{-1, NUM_CHANNELS, IMAGE_SIZE, IMAGE_SIZE});\n-        var inputReshaped = Reshape(inputImage, shape, empty());\n-\n@@ -117,1 +114,1 @@\n-        var scaledInput = Div(inputReshaped, scalingFactor);\n+        var scaledInput = Div(inputImage, scalingFactor);\n@@ -194,12 +191,0 @@\n-            var shape = b.op(OnnxOps.Constant(OnnxType.TENSOR_INT64,\n-                    empty(),\n-                    empty(),\n-                    empty(),\n-                    empty(),\n-                    empty(),\n-                    of(new long[]{-1, NUM_CHANNELS, IMAGE_SIZE, IMAGE_SIZE}),\n-                    empty(),\n-                    empty()));\n-            var inputReshaped = b.op(OnnxOps.Reshape(inputImage.type(),\n-                    inputImage, shape, empty()));\n-\n@@ -216,1 +201,1 @@\n-            var scaledInput = b.op(OnnxOps.Div(inputReshaped.type(), inputReshaped, scalingFactor));\n+            var scaledInput = b.op(OnnxOps.Div(inputImage.type(), inputImage, scalingFactor));\n@@ -337,1 +322,1 @@\n-    @Test\n+\/\/    @Test\n@@ -341,2 +326,2 @@\n-            CoreOp.FuncOp onnxModel = OnnxTransformer.transform(MethodHandles.lookup(), f);\n-            System.out.println(onnxModel.toText());\n+            var onnxModel = OnnxTransformer.transform(MethodHandles.lookup(), new HashMap<>(), f);\n+            System.out.println(onnxModel.func().toText());\n@@ -347,1 +332,1 @@\n-            Assertions.assertEquals(serialize(expectedOnnxModel), serialize(onnxModel));\n+            Assertions.assertEquals(serialize(expectedOnnxModel), serialize(onnxModel.func()));\n@@ -351,1 +336,1 @@\n-    @Test\n+\/\/    @Test\n@@ -400,1 +385,2 @@\n-            Tensor<Byte> inputImage = new Tensor(arena, imagesIn, Tensor.ElementType.UINT8, new long[]{imagesF.length() - IMAGES_HEADER_SIZE});\n+            long size = imagesF.length() - IMAGES_HEADER_SIZE;\n+            Tensor<Byte> inputImage = new Tensor(arena, imagesIn, Tensor.ElementType.UINT8, new long[]{size \/ (28 * 28), 1, 28, 28});\n","filename":"cr-examples\/onnx\/src\/test\/java\/oracle\/code\/onnx\/CNNTest.java","additions":10,"deletions":24,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -20,0 +20,1 @@\n+                    List.of(),\n@@ -24,4 +25,5 @@\n-             var addOp = ort.createSession(arena, build(\n-                     List.of(tensorInfo(\"a\", FLOAT.id), tensorInfo(\"b\", FLOAT.id)),\n-                     List.of(node(\"Add\", List.of(\"a\", \"b\"), List.of(\"y\"), Map.of())),\n-                     List.of(\"y\")));\n+            var addOp = ort.createSession(arena, build(\n+                    List.of(),\n+                    List.of(tensorInfo(\"a\", FLOAT.id), tensorInfo(\"b\", FLOAT.id)),\n+                    List.of(node(\"Add\", List.of(\"a\", \"b\"), List.of(\"y\"), Map.of())),\n+                    List.of(\"y\")));\n@@ -64,0 +66,1 @@\n+                    List.of(),\n@@ -67,0 +70,1 @@\n+                                    List.of(),\n@@ -71,0 +75,1 @@\n+                                    List.of(),\n@@ -88,0 +93,1 @@\n+                    List.of(),\n@@ -91,0 +97,1 @@\n+                                    List.of(),\n","filename":"cr-examples\/onnx\/src\/test\/java\/oracle\/code\/onnx\/RuntimeTest.java","additions":11,"deletions":4,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -13,1 +13,1 @@\n-    public static Tensor<Float> add(Tensor<Float> a, Tensor<Float> b) {\n+    public Tensor<Float> add(Tensor<Float> a, Tensor<Float> b) {\n@@ -26,1 +26,1 @@\n-    public static Tensor<Float> sub(Tensor<Float> a, Tensor<Float> b) {\n+    public Tensor<Float> sub(Tensor<Float> a, Tensor<Float> b) {\n@@ -40,1 +40,1 @@\n-    public static Tensor<Float> fconstant() {\n+    public Tensor<Float> fconstant() {\n@@ -53,1 +53,1 @@\n-    public static Tensor<Float> fconstants() {\n+    public Tensor<Float> fconstants() {\n@@ -66,1 +66,1 @@\n-    public static Tensor<Long> lconstant() {\n+    public Tensor<Long> lconstant() {\n@@ -79,1 +79,1 @@\n-    public static Tensor<Long> lconstants() {\n+    public Tensor<Long> lconstants() {\n@@ -92,1 +92,1 @@\n-    public static Tensor<Long> reshapeAndShape(Tensor<Float> data, Tensor<Long> shape) {\n+    public Tensor<Long> reshapeAndShape(Tensor<Float> data, Tensor<Long> shape) {\n@@ -106,1 +106,1 @@\n-    public static Tensor<Long> indicesOfMaxPool(Tensor<Float> x) {\n+    public Tensor<Long> indicesOfMaxPool(Tensor<Float> x) {\n@@ -119,0 +119,53 @@\n+    @CodeReflection\n+    public Tensor<Float> ifConst(Tensor<Boolean> cond) {\n+        return OnnxOperators.If(cond, () -> OnnxOperators.Constant(-1f), () -> OnnxOperators.Constant(1f));\n+    }\n+\n+    @Test\n+    public void testIfConst() throws Exception {\n+        var condFalse = Tensor.ofScalar(false);\n+        var expFalse = Tensor.ofScalar(-1f);\n+        var condTrue = Tensor.ofScalar(true);\n+        var expTrue = Tensor.ofScalar(1f);\n+\n+        assertEquals(expFalse, ifConst(condFalse));\n+        assertEquals(expFalse, OnnxRuntime.execute(MethodHandles.lookup(), () -> ifConst(condFalse)));\n+\n+        assertEquals(expTrue, ifConst(condTrue));\n+        assertEquals(expTrue, OnnxRuntime.execute(MethodHandles.lookup(), () -> ifConst(condTrue)));\n+    }\n+\n+    @CodeReflection\n+    public Tensor<Float> ifCapture(Tensor<Boolean> cond, Tensor<Float> trueValue) {\n+        var falseValue = OnnxOperators.Constant(-1f);\n+        return OnnxOperators.If(cond, () -> OnnxOperators.Identity(falseValue), () -> trueValue);\n+    }\n+\n+    @Test\n+    public void testIfCapture() throws Exception {\n+        var condFalse = Tensor.ofScalar(false);\n+        var expFalse = Tensor.ofScalar(-1f);\n+        var condTrue = Tensor.ofScalar(true);\n+        var expTrue = Tensor.ofScalar(1f);\n+\n+        assertEquals(expFalse, ifCapture(condFalse, expTrue));\n+        assertEquals(expFalse, OnnxRuntime.execute(MethodHandles.lookup(), () -> ifCapture(condFalse, expTrue)));\n+\n+        assertEquals(expTrue, ifCapture(condTrue, expTrue));\n+        assertEquals(expTrue, OnnxRuntime.execute(MethodHandles.lookup(), () -> ifCapture(condTrue, expTrue)));\n+    }\n+\n+    final Tensor<Float> initialized = Tensor.ofFlat(42f);\n+\n+    @CodeReflection\n+    public Tensor<Float> initialized() {\n+        return OnnxOperators.Identity(initialized);\n+    }\n+\n+    @Test\n+    public void testInitialized() throws Exception {\n+\n+        assertEquals(initialized(),\n+                     OnnxRuntime.execute(MethodHandles.lookup(), () -> initialized()));\n+    }\n+\n","filename":"cr-examples\/onnx\/src\/test\/java\/oracle\/code\/onnx\/SimpleTest.java","additions":61,"deletions":8,"binary":false,"changes":69,"status":"modified"},{"patch":"@@ -1,117 +0,0 @@\n-\/*\n- * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-package oracle.code.onnx.mnist;\n-\n-import jdk.incubator.code.CodeReflection;\n-\n-import java.io.*;\n-import java.lang.foreign.Arena;\n-import java.lang.foreign.MemorySegment;\n-import java.lang.foreign.ValueLayout;\n-import java.lang.invoke.MethodHandles;\n-import oracle.code.onnx.OnnxRuntime;\n-import oracle.code.onnx.Tensor;\n-\n-import static java.util.Optional.empty;\n-import static java.util.Optional.of;\n-import static oracle.code.onnx.OnnxOperators.*;\n-\n-public class MNISTDemo {\n-\n-    static final int IMAGE_SIZE = 28;\n-    static final long[] IMAGE_SHAPE = new long[]{1, 1, IMAGE_SIZE, IMAGE_SIZE};\n-\n-    public static float[] loadConstant(String resource) {\n-        try (var in = MNISTDemo.class.getResourceAsStream(resource)) {\n-            return MemorySegment.ofArray(in.readAllBytes())\n-                    .toArray(ValueLayout.JAVA_FLOAT_UNALIGNED);\n-        } catch (IOException e) {\n-            throw new UncheckedIOException(e);\n-        }\n-    }\n-\n-    @CodeReflection\n-    public static Tensor<Float> cnn(Tensor<Float> inputImage) {\n-        \/\/ Scaling to 0-1\n-        var scaledInput = Div(inputImage, Constant(255f));\n-\n-        \/\/ First conv layer\n-        var conv1Weights = Reshape(Constant(loadConstant(\"conv1-weight-float-le\")), Constant(new long[]{6, 1, 5, 5}), empty());\n-        var conv1Biases = Reshape(Constant(loadConstant(\"conv1-bias-float-le\")), Constant(new long[]{6}), empty());\n-        var conv1 = Conv(scaledInput, conv1Weights, of(conv1Biases), of(new long[4]),\n-                of(new long[]{1,1}), empty(), of(new long[]{1, 1, 1, 1}),\n-                of(1L), of(new long[]{5,5}));\n-        var relu1 = Relu(conv1);\n-\n-        \/\/ First pooling layer\n-        var pool1 = MaxPool(relu1, of(new long[4]), of(new long[]{1,1}), empty(),\n-                of(0L), empty(), of(new long[]{2, 2}), new long[]{2, 2});\n-\n-        \/\/ Second conv layer\n-        var conv2Weights = Reshape(Constant(loadConstant(\"conv2-weight-float-le\")), Constant(new long[]{16, 6, 5, 5}), empty());\n-        var conv2Biases = Reshape(Constant(loadConstant(\"conv2-bias-float-le\")), Constant(new long[]{16}), empty());\n-        var conv2 = Conv(pool1.Y(), conv2Weights, of(conv2Biases), of(new long[4]),\n-                of(new long[]{1,1}), empty(), of(new long[]{1, 1, 1, 1}),\n-                of(1L), of(new long[]{5,5}));\n-        var relu2 = Relu(conv2);\n-\n-        \/\/ Second pooling layer\n-        var pool2 = MaxPool(relu2, of(new long[4]), of(new long[]{1,1}), empty(),\n-                of(0L), empty(), of(new long[]{2, 2}), new long[]{2, 2});\n-\n-        \/\/ Flatten inputs\n-        var flatten = Flatten(pool2.Y(), of(1L));\n-\n-        \/\/ First fully connected layer\n-        var fc1Weights = Reshape(Constant(loadConstant(\"fc1-weight-float-le\")), Constant(new long[]{120, 256}), empty());\n-        var fc1Biases = Reshape(Constant(loadConstant(\"fc1-bias-float-le\")), Constant(new long[]{120}), empty());\n-        var fc1 = Gemm(flatten, fc1Weights, of(fc1Biases), of(1f), of(1L), of(1f), empty());\n-        var relu3 = Relu(fc1);\n-\n-        \/\/ Second fully connected layer\n-        var fc2Weights = Reshape(Constant(loadConstant(\"fc2-weight-float-le\")), Constant(new long[]{84, 120}), empty());\n-        var fc2Biases = Reshape(Constant(loadConstant(\"fc2-bias-float-le\")), Constant(new long[]{84}), empty());\n-        var fc2 = Gemm(relu3, fc2Weights, of(fc2Biases), of(1f), of(1L), of(1f), empty());\n-        var relu4 = Relu(fc2);\n-\n-        \/\/ Softmax layer\n-        var fc3Weights = Reshape(Constant(loadConstant(\"fc3-weight-float-le\")), Constant(new long[]{10, 84}), empty());\n-        var fc3Biases = Reshape(Constant(loadConstant(\"fc3-bias-float-le\")), Constant(new long[]{10}), empty());\n-        var fc3 = Gemm(relu4, fc3Weights, of(fc3Biases), of(1f), of(1L), of(1f), empty());\n-        var prediction = Softmax(fc3, of(1L));\n-\n-        return prediction;\n-    }\n-\n-    public static float[] classify(float[] imageData) {\n-        try (Arena arena = Arena.ofConfined()) {\n-            var imageTensor = Tensor.ofShape(arena, IMAGE_SHAPE, imageData);\n-\n-            var predictionTensor = OnnxRuntime.execute(arena, MethodHandles.lookup(),\n-                    () -> cnn(imageTensor));\n-\n-            return predictionTensor.data().toArray(ValueLayout.JAVA_FLOAT);\n-        }\n-    }\n-}\n","filename":"cr-examples\/onnx\/src\/test\/java\/oracle\/code\/onnx\/mnist\/MNISTDemo.java","additions":0,"deletions":117,"binary":false,"changes":117,"status":"deleted"},{"patch":"@@ -35,1 +35,1 @@\n-import static oracle.code.onnx.mnist.MNISTDemo.IMAGE_SIZE;\n+import static oracle.code.onnx.mnist.MNISTModel.IMAGE_SIZE;\n@@ -49,0 +49,1 @@\n+        var mnist = new MNISTModel();\n@@ -80,1 +81,1 @@\n-                    var results = MNISTDemo.classify(imageData);\n+                    var results = mnist.classify(imageData);\n","filename":"cr-examples\/onnx\/src\/test\/java\/oracle\/code\/onnx\/mnist\/MNISTDemoUI.java","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -0,0 +1,126 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package oracle.code.onnx.mnist;\n+\n+import java.io.IOException;\n+import java.lang.foreign.Arena;\n+import java.lang.foreign.ValueLayout;\n+import java.lang.invoke.MethodHandles;\n+import jdk.incubator.code.CodeReflection;\n+import oracle.code.onnx.OnnxRuntime;\n+import oracle.code.onnx.Tensor;\n+\n+import static java.util.Optional.empty;\n+import static java.util.Optional.of;\n+import static oracle.code.onnx.OnnxOperators.*;\n+\n+public class MNISTModel {\n+\n+    static final int IMAGE_SIZE = 28;\n+    static final long[] IMAGE_SHAPE = new long[]{1, 1, IMAGE_SIZE, IMAGE_SIZE};\n+\n+    private static Tensor<Float> initialize(String resource, long... shape) throws IOException {\n+        try (var in = MNISTModel.class.getResourceAsStream(resource)) {\n+            return Tensor.ofShape(shape, in.readAllBytes(), Tensor.ElementType.FLOAT);\n+        }\n+    }\n+\n+    final Tensor<Float> conv1Weights;\n+    final Tensor<Float> conv1Biases;\n+    final Tensor<Float> conv2Weights;\n+    final Tensor<Float> conv2Biases;\n+    final Tensor<Float> fc1Weights;\n+    final Tensor<Float> fc1Biases;\n+    final Tensor<Float> fc2Weights;\n+    final Tensor<Float> fc2Biases;\n+    final Tensor<Float> fc3Weights;\n+    final Tensor<Float> fc3Biases;\n+\n+    MNISTModel() throws IOException {\n+        conv1Weights = initialize(\"conv1-weight-float-le\", 6, 1, 5, 5);\n+        conv1Biases = initialize(\"conv1-bias-float-le\", 6);\n+        conv2Weights = initialize(\"conv2-weight-float-le\", 16, 6, 5, 5);\n+        conv2Biases = initialize(\"conv2-bias-float-le\", 16);\n+        fc1Weights = initialize(\"fc1-weight-float-le\", 120, 256);\n+        fc1Biases = initialize(\"fc1-bias-float-le\", 120);\n+        fc2Weights = initialize(\"fc2-weight-float-le\", 84, 120);\n+        fc2Biases = initialize(\"fc2-bias-float-le\", 84);\n+        fc3Weights = initialize(\"fc3-weight-float-le\", 10, 84);\n+        fc3Biases = initialize(\"fc3-bias-float-le\", 10);\n+    }\n+\n+    @CodeReflection\n+    public Tensor<Float> cnn(Tensor<Float> inputImage) {\n+        \/\/ Scaling to 0-1\n+        var scaledInput = Div(inputImage, Constant(255f));\n+\n+        \/\/ First conv layer\n+        var conv1 = Conv(scaledInput, conv1Weights, of(conv1Biases), of(new long[4]),\n+                of(new long[]{1,1}), empty(), of(new long[]{1, 1, 1, 1}),\n+                of(1L), of(new long[]{5,5}));\n+        var relu1 = Relu(conv1);\n+\n+        \/\/ First pooling layer\n+        var pool1 = MaxPool(relu1, of(new long[4]), of(new long[]{1,1}), empty(),\n+                of(0L), empty(), of(new long[]{2, 2}), new long[]{2, 2});\n+\n+        \/\/ Second conv layer\n+        var conv2 = Conv(pool1.Y(), conv2Weights, of(conv2Biases), of(new long[4]),\n+                of(new long[]{1,1}), empty(), of(new long[]{1, 1, 1, 1}),\n+                of(1L), of(new long[]{5,5}));\n+        var relu2 = Relu(conv2);\n+\n+        \/\/ Second pooling layer\n+        var pool2 = MaxPool(relu2, of(new long[4]), of(new long[]{1,1}), empty(),\n+                of(0L), empty(), of(new long[]{2, 2}), new long[]{2, 2});\n+\n+        \/\/ Flatten inputs\n+        var flatten = Flatten(pool2.Y(), of(1L));\n+\n+        \/\/ First fully connected layer\n+        var fc1 = Gemm(flatten, fc1Weights, of(fc1Biases), of(1f), of(1L), of(1f), empty());\n+        var relu3 = Relu(fc1);\n+\n+        \/\/ Second fully connected layer\n+        var fc2 = Gemm(relu3, fc2Weights, of(fc2Biases), of(1f), of(1L), of(1f), empty());\n+        var relu4 = Relu(fc2);\n+\n+        \/\/ Softmax layer\n+        var fc3 = Gemm(relu4, fc3Weights, of(fc3Biases), of(1f), of(1L), of(1f), empty());\n+        var prediction = Softmax(fc3, of(1L));\n+\n+        return prediction;\n+    }\n+\n+    public float[] classify(float[] imageData) {\n+        try (Arena arena = Arena.ofConfined()) {\n+            var imageTensor = Tensor.ofShape(arena, IMAGE_SHAPE, imageData);\n+\n+            var predictionTensor = OnnxRuntime.execute(arena, MethodHandles.lookup(),\n+                    () -> cnn(imageTensor));\n+\n+            return predictionTensor.data().toArray(ValueLayout.JAVA_FLOAT);\n+        }\n+    }\n+}\n","filename":"cr-examples\/onnx\/src\/test\/java\/oracle\/code\/onnx\/mnist\/MNISTModel.java","additions":126,"deletions":0,"binary":false,"changes":126,"status":"added"}]}