{"files":[{"patch":"@@ -102,2 +102,0 @@\n-  \/\/  std::cout << \"CudaBackend constructor \" << ((cudaConfig == nullptr) ? \"cudaConfig== null\" : \"got cudaConfig\")\n-    \/\/          << std::endl;\n@@ -107,9 +105,4 @@\n-        CUresult status =  cuDeviceGetCount(&deviceCount);\n-        if (status != CUDA_SUCCESS) {\n-            std::cerr\n-                    << \"cuDeviceGetCount() failed we seem to have the runtime library but no device, CUDA error = \"\n-                    << status\n-                    << \" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                    << \" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-            exit(-1);\n-        }\n+        WHERE{.f=__FILE__, .l=__LINE__,\n+                .e=cuDeviceGetCount(&deviceCount),\n+                .t=\"cuDeviceGetCount\"\n+        }.report();\n@@ -117,20 +110,8 @@\n-        status= cuDeviceGet(&device, 0);\n-        if (status != CUDA_SUCCESS) {\n-            std::cerr\n-                    << \"cuDeviceGet() failed we seem to have the runtime library but no device, CUDA error = \"\n-                    << status\n-                    << \" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                    << \" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-            exit(-1);\n-        }\n-        std::cout << \"CudaBackend device ok (id = \"<<device<<\")\" << std::endl;\n-\n-        status = cuCtxCreate(&context, 0, device);\n-        if (status != CUDA_SUCCESS) {\n-            std::cerr\n-                    << \"cuCtxCreate() failed we seem to have the runtime library found a device, but cant create context, CUDA error = \"\n-                    << status\n-                    << \" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                    << \" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-            exit(-1);\n-        }\n+        WHERE{.f=__FILE__, .l=__LINE__,\n+                .e=cuDeviceGet(&device, 0),\n+                .t=\"cuDeviceGet\"\n+        }.report();\n+        WHERE{.f=__FILE__, .l=__LINE__,\n+                .e=cuCtxCreate(&context, 0, device),\n+                .t=\"cuCtxCreate\"\n+        }.report();\n@@ -140,4 +121,4 @@\n-        std::cerr << \"cuInit() failed we seem to have the runtime library but no device, no context, nada CUDA error = \" << initStatus\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(initStatus))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n+        WHERE{.f=__FILE__, .l=__LINE__,\n+                .e=initStatus,\n+                \"cuInit() failed we seem to have the runtime library but no device\"\n+        }.report();\n@@ -153,7 +134,4 @@\n-    CUresult status = cuCtxDestroy(context);\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cuCtxDestroy(() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n+    WHERE{.f=__FILE__, .l=__LINE__,\n+            .e=cuCtxDestroy(context),\n+            .t=\"cuCtxDestroy\"\n+    }.report();\n@@ -248,8 +226,5 @@\n-        int status = cuModuleLoadDataEx(&module, ptx->text,\n-                                        optc, jitOptions, (void **) jitOptVals);\n-        if (CUDA_SUCCESS != status) {\n-            std::cerr << \"cuModuleLoadDataEx() CUDA error = \" << status\n-                      <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                      <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-            exit(-1);\n-        }\n+\n+        WHERE{.f=__FILE__, .l=__LINE__,\n+                .e=cuModuleLoadDataEx(&module, ptx->text, optc, jitOptions, (void **) jitOptVals),\n+                .t=\"cuModuleLoadDataEx\"\n+        }.report();\n@@ -289,7 +264,6 @@\n-        int status = cuModuleLoadDataEx(&module, ptx->text, jitNumOptions, jitOptions, (void **) jitOptVals);\n-        if (CUDA_SUCCESS != status) {\n-            std::cerr << \"cuModuleLoadDataEx() CUDA error = \" << status\n-                      <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                      <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-            exit(-1);\n-        }\n+        cuCtxSetCurrent(context);\n+\n+        WHERE{.f=__FILE__, .l=__LINE__,\n+              .e=cuModuleLoadDataEx(&module, ptx->text, jitNumOptions, jitOptions, (void **) jitOptVals),\n+              .t=\"cuModuleLoadDataEx\"\n+        }.report();\n@@ -300,1 +274,1 @@\n-        \/\/delete ptx;\n+        \/\/delete\n@@ -308,1 +282,1 @@\n-    std::cout << \"getBackend() -> backendHandle=\" << std::hex << backendHandle << std::dec << std::endl;\n+  \/\/  std::cout << \"getBackend() -> backendHandle=\" << std::hex << backendHandle << std::dec << std::endl;\n","filename":"hat\/backends\/ffi\/cuda\/cpp\/cuda_backend.cpp","additions":33,"deletions":59,"binary":false,"changes":92,"status":"modified"},{"patch":"@@ -41,1 +41,1 @@\n-        std::cout << \"cuMemAlloc()\" << std::endl;\n+        std::cout << \"CudaBuffer()\" << std::endl;\n@@ -43,6 +43,7 @@\n-    CUresult status = cuMemAlloc(&devicePtr, (size_t) arg->value.buffer.sizeInBytes);\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cuMemAlloc() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n+\n+    WHERE{.f=__FILE__, .l=__LINE__,\n+            .e=cuMemAlloc(&devicePtr, (size_t) arg->value.buffer.sizeInBytes),\n+            .t=\"cuMemAlloc\"\n+    }.report();\n+    if (cudaBackend->cudaConfig.traceCalls) {\n+        std::cout << \"devptr \" << std::hex<<  (long)devicePtr <<std::dec <<std::endl;\n@@ -50,1 +51,0 @@\n-   \/\/ std::cout << \"devptr \" << std::hex<<  (long)devicePtr <<std::dec <<std::endl;\n@@ -57,10 +57,1 @@\n-        std::cout << \"cuMemFree()\"\n-                  << \"devptr \" << std::hex << (long) devicePtr << std::dec\n-                  << std::endl;\n-    }\n-    CUresult  status = cuMemFree(devicePtr);\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cuMemFree() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n+        std::cout << \"~CudaBuffer()\"<< \"devptr \" << std::hex << (long) devicePtr << std::dec<< std::endl;\n@@ -68,0 +59,4 @@\n+    WHERE{.f=__FILE__, .l=__LINE__,\n+            .e=cuMemFree(devicePtr),\n+            .t=\"cuMemFree\"\n+    }.report();\n@@ -74,1 +69,2 @@\n-        std::cout << \"copyToDevice() 0x\" << std::hex << arg->value.buffer.sizeInBytes << std::dec << \" \"\n+        std::cout << \"copyToDevice() 0x\"\n+                  << std::hex << arg->value.buffer.sizeInBytes << std::dec << \"\/\"\n@@ -79,17 +75,6 @@\n-\n-\n-    CUresult status = cuMemcpyHtoDAsync(devicePtr, arg->value.buffer.memorySegment,\n-                                        arg->value.buffer.sizeInBytes,cudaBackend->cudaQueue.cuStream);\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cuMemcpyHtoDAsync() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n-    status = static_cast<CUresult >(cudaStreamSynchronize(cudaBackend->cudaQueue.cuStream));\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n+    WHERE{.f=__FILE__, .l=__LINE__,\n+            .e=cuMemcpyHtoDAsync(devicePtr, arg->value.buffer.memorySegment,\n+                                 arg->value.buffer.sizeInBytes,cudaBackend->cudaQueue.cuStream),\n+            .t=\"cuMemcpyHtoDAsync\"\n+    }.report();\n+    cudaBackend->cudaQueue.wait();\n@@ -101,1 +86,3 @@\n-        std::cout << \"copyFromDevice() 0x\" << std::hex<<arg->value.buffer.sizeInBytes<<std::dec << \" \"<< arg->value.buffer.sizeInBytes << \" \"\n+        std::cout << \"copyFromDevice() 0x\"\n+                     << std::hex<<arg->value.buffer.sizeInBytes<<std::dec << \"\/\"\n+                     << arg->value.buffer.sizeInBytes << \" \"\n@@ -105,15 +92,7 @@\n-    CUresult status =cuMemcpyDtoHAsync(arg->value.buffer.memorySegment, devicePtr, arg->value.buffer.sizeInBytes,\n-                                       cudaBackend->cudaQueue.cuStream);\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cuMemcpyDtoHAsync() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n-    cudaError_t t1 = cudaStreamSynchronize(cudaBackend->cudaQueue.cuStream);\n-    if (static_cast<cudaError_t>(CUDA_SUCCESS) != t1) {\n-        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << t1\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(t1))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n+    WHERE{.f=__FILE__, .l=__LINE__,\n+            .e=cuMemcpyDtoHAsync(arg->value.buffer.memorySegment, devicePtr, arg->value.buffer.sizeInBytes,\n+                                 cudaBackend->cudaQueue.cuStream),\n+            .t=\"cuMemcpyDtoHAsync\"\n+    }.report();\n+\n+    cudaBackend->cudaQueue.wait();\n","filename":"hat\/backends\/ffi\/cuda\/cpp\/cuda_backend_buffer.cpp","additions":31,"deletions":52,"binary":false,"changes":83,"status":"modified"},{"patch":"@@ -26,2 +26,1 @@\n-#include <sys\/wait.h>\n-#include <chrono>\n+\n@@ -44,1 +43,0 @@\n-  \/\/  Schema::dumpSled(std::cout, argArray);\n@@ -48,3 +46,0 @@\n-#ifdef VERBOSE\n-    std::cerr << \"there are \" << argSled.argc() << \"args \" << std::endl;\n-#endif\n@@ -78,1 +73,0 @@\n-    \/\/argslist[argSled.argc()]= nullptr;\n@@ -89,7 +83,1 @@\n-    auto status= static_cast<CUresult>(cudaStreamSynchronize(cudaBackend->cudaQueue.cuStream));\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n+  \/\/  auto status= static_cast<CUresult>(cudaStreamSynchronize(cudaBackend->cudaQueue.cuStream));\n@@ -97,9 +85,2 @@\n-    status = cuCtxSetCurrent(cudaBackend->context);\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cuCtxSetCurrent() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n-   \/\/ std::cout <<\" function\/kernel id= \" << function << \" stream = \" << cudaBackend->cudaQueue.cuStream<<std::endl;\n-    status= cuLaunchKernel(function,\n+  \/\/  cudaBackend->cudaQueue.wait();\n+    auto status= cuLaunchKernel(function,\n@@ -110,2 +91,0 @@\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cuLaunchKernel() CUDA error = \" << status\n@@ -113,11 +92,2 @@\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n-    status= static_cast<CUresult>(cudaStreamSynchronize(cudaBackend->cudaQueue.cuStream));\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n+    WHERE{.f=__FILE__, .l=__LINE__, .e=status, .t=\"cuLaunchKernel\"}.report();\n+ \/\/   cudaBackend->cudaQueue.wait();\n@@ -125,1 +95,0 @@\n-   \/\/ std::cout << \"Kernel complete...\"<<cudaGetErrorString(static_cast<cudaError_t>(status))<<std::endl;\n@@ -135,7 +104,1 @@\n-    status=   static_cast<CUresult>(cudaStreamSynchronize(cudaBackend->cudaQueue.cuStream));\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n+    cudaBackend->cudaQueue.wait();\n","filename":"hat\/backends\/ffi\/cuda\/cpp\/cuda_backend_kernel.cpp","additions":7,"deletions":44,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -49,7 +49,4 @@\n-    CUresult status= cuModuleGetFunction(&function, module, name);\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cuModuleGetFunction() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n+    WHERE{.f=__FILE__, .l=__LINE__,\n+          .e=cuModuleGetFunction(&function, module, name),\n+          .t=\"cuModuleGetFunction\"\n+    }.report();\n","filename":"hat\/backends\/ffi\/cuda\/cpp\/cuda_backend_module.cpp","additions":4,"deletions":7,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -35,6 +35,1 @@\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cudaStreamCreate() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n+    WHERE{.f=__FILE__ , .l=__LINE__, .e=status, .t= \"cuStreamCreate\"}.report();\n@@ -43,0 +38,1 @@\n+\/\/void CudaBackend::CudaQueue::sync(const char *file, int line) const {\n@@ -44,0 +40,1 @@\n+\/\/}\n@@ -49,0 +46,4 @@\n+    WHERE{.f=__FILE__, .l=__LINE__,\n+          .e=cuStreamSynchronize(cuStream),\n+          .t= \"cuStreamSynchronize\"\n+    }.report();\n@@ -50,5 +51,1 @@\n-      \/\/  cl_int status = clWaitForEvents(eventc, events);\n-      \/\/  if (status != CL_SUCCESS) {\n-          \/\/  std::cerr << \"failed clWaitForEvents\" << CudaBackend::errorMsg(status) << std::endl;\n-           \/\/ exit(1);\n-       \/\/ }\n+\n@@ -165,1 +162,0 @@\n-   \/\/ clReleaseCommandQueue(command_queue);\n@@ -167,7 +163,4 @@\n-   auto status = cuStreamDestroy(cuStream);\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cuStreamDestroy() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n+    WHERE{.f=__FILE__, .l=__LINE__,\n+            .e=cuStreamDestroy(cuStream),\n+            .t= \"cuStreamDestroy\"\n+    }.report();\n","filename":"hat\/backends\/ffi\/cuda\/cpp\/cuda_backend_queue.cpp","additions":12,"deletions":19,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -67,1 +67,16 @@\n-\n+struct WHERE{\n+    const char* f;\n+    int l;\n+    cudaError_enum e;\n+    const char* t;\n+    void report() const{\n+        if (e == CUDA_SUCCESS){\n+           \/\/ std::cout << t << \"  OK at \" << f << \" line \" << l << std::endl;\n+        }else {\n+            const char *buf;\n+            cuGetErrorName(e, &buf);\n+            std::cerr << t << \" CUDA error = \" << e << \" \" << buf <<std::endl<< \"      \" << f << \" line \" << l << std::endl;\n+            exit(-1);\n+        }\n+    }\n+};\n@@ -115,0 +130,1 @@\n+      \/\/  void sync(const char *file, int line) const;\n@@ -116,1 +132,3 @@\n-    };\n+\n+\n+};\n","filename":"hat\/backends\/ffi\/cuda\/include\/cuda_backend.h","additions":20,"deletions":2,"binary":false,"changes":22,"status":"modified"}]}