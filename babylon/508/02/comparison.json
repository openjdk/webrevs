{"files":[{"patch":"@@ -29,1 +29,0 @@\n-\n@@ -32,1 +31,0 @@\n-\n@@ -79,2 +77,0 @@\n-\n-\n@@ -86,5 +82,1 @@\n-        WHERE{\n-            .f = __FILE__, .l = __LINE__,\n-            .e = cuDeviceGetCount(&deviceCount),\n-            .t = \"cuDeviceGetCount\"\n-        }.report();\n+        CUDA_CHECK(cuDeviceGetCount(&deviceCount), \"cuDeviceGetCount\");\n@@ -92,10 +84,2 @@\n-        WHERE{\n-            .f = __FILE__, .l = __LINE__,\n-            .e = cuDeviceGet(&device, 0),\n-            .t = \"cuDeviceGet\"\n-        }.report();\n-        WHERE{\n-            .f = __FILE__, .l = __LINE__,\n-            .e = cuCtxCreate(&context, 0, device),\n-            .t = \"cuCtxCreate\"\n-        }.report();\n+        CUDA_CHECK(cuDeviceGet(&device, 0), \"cuDeviceGet\");\n+        CUDA_CHECK(cuCtxCreate(&context, 0, device), \"cuCtxCreate\");\n@@ -105,5 +89,1 @@\n-        WHERE{\n-            .f = __FILE__, .l = __LINE__,\n-            .e = initStatus,\n-            \"cuInit() failed we seem to have the runtime library but no device\"\n-        }.report();\n+        CUDA_CHECK(initStatus, \"cuInit() failed we seem to have the runtime library but no device\");\n@@ -113,1 +93,0 @@\n-\n@@ -116,5 +95,1 @@\n-    WHERE{\n-        .f = __FILE__, .l = __LINE__,\n-        .e = cuCtxDestroy(context),\n-        .t = \"cuCtxDestroy\"\n-    }.report();\n+    CUDA_CHECK(cuCtxDestroy(context), \"cuCtxDestroy\");\n@@ -125,1 +100,2 @@\n-    cuDeviceGetName(name, sizeof(name), device);\n+    CUDA_CHECK(cuDeviceGetName(name, sizeof(name), device), \"cuDeviceGetName\");\n+\n@@ -128,1 +104,1 @@\n-    \/\/ get compute capabilities and the devicename\n+    \/\/ get compute capabilities and the device name\n@@ -130,2 +106,2 @@\n-    cuDeviceGetAttribute(&major, CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MAJOR, device);\n-    cuDeviceGetAttribute(&minor, CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MINOR, device);\n+    CUDA_CHECK(cuDeviceGetAttribute(&major, CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MAJOR, device), \"cuDeviceGetAttribute\");\n+    CUDA_CHECK(cuDeviceGetAttribute(&minor, CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MINOR, device), \"cuDeviceGetAttribute\");\n@@ -135,1 +111,1 @@\n-    cuDeviceGetAttribute(&warpSize, CU_DEVICE_ATTRIBUTE_WARP_SIZE, device);\n+    CUDA_CHECK(cuDeviceGetAttribute(&warpSize, CU_DEVICE_ATTRIBUTE_WARP_SIZE, device), \"cuDeviceGetAttribute\");\n@@ -139,1 +115,1 @@\n-    cuDeviceGetAttribute(&threadsPerBlock, CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK, device);\n+    CUDA_CHECK(cuDeviceGetAttribute(&threadsPerBlock, CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK, device), \"cuDeviceGetAttribute\");\n@@ -143,1 +119,1 @@\n-    cuDeviceGetAttribute(&cores, CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT, device);\n+    CUDA_CHECK(cuDeviceGetAttribute(&cores, CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT, device), \"cuDeviceGetAttribute\");\n@@ -147,1 +123,1 @@\n-    cuDeviceTotalMem(&totalGlobalMem, device);\n+    CUDA_CHECK(cuDeviceTotalMem(&totalGlobalMem, device), \"cuDeviceTotalMem\");\n@@ -161,1 +137,9 @@\n-        const char *argv[]{  \"\/usr\/local\/cuda\/bin\/nvcc\", \"-ptx\", \"-Wno-deprecated-gpu-targets\", cudaPath.c_str(), \"-o\", ptxPath.c_str(), nullptr};\n+        const char *argv[] {\n+            \"\/usr\/local\/cuda\/bin\/nvcc\",\n+            \"-ptx\",\n+            \"-Wno-deprecated-gpu-targets\",\n+            cudaPath.c_str(),\n+            \"-o\",\n+            ptxPath.c_str(),\n+            nullptr\n+        };\n@@ -191,1 +175,0 @@\n-\n@@ -211,5 +194,2 @@\n-        WHERE{\n-            .f = __FILE__, .l = __LINE__,\n-            .e = cuModuleLoadDataEx(&module, ptx->text, optc, jitOptions, (void **) jitOptVals),\n-            .t = \"cuModuleLoadDataEx\"\n-        }.report();\n+        CUDA_CHECK(cuModuleLoadDataEx(&module, ptx->text, optc, jitOptions, (void **) jitOptVals), \"cuModuleLoadDataEx\");\n+\n@@ -314,1 +294,0 @@\n-\n","filename":"hat\/backends\/ffi\/cuda\/src\/main\/native\/cpp\/cuda_backend.cpp","additions":25,"deletions":46,"binary":false,"changes":71,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+    CUDA_CHECK(cuMemAlloc(&devicePtr, static_cast<size_t>(bufferState->length)), \"cuMemAlloc\");\n@@ -42,4 +43,0 @@\n-    WHERE{.f=__FILE__, .l=__LINE__,\n-            .e=cuMemAlloc(&devicePtr, static_cast<size_t>(bufferState->length)),\n-            .t=\"cuMemAlloc\"\n-    }.report();\n@@ -57,1 +54,0 @@\n-\n@@ -62,4 +58,1 @@\n-    WHERE{.f=__FILE__, .l=__LINE__,\n-            .e=cuMemFree(devicePtr),\n-            .t=\"cuMemFree\"\n-    }.report();\n+    CUDA_CHECK(cuMemFree(devicePtr), \"cuMemFree\");\n","filename":"hat\/backends\/ffi\/cuda\/src\/main\/native\/cpp\/cuda_backend_buffer.cpp","additions":2,"deletions":9,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -49,4 +49,1 @@\n-    WHERE{.f=__FILE__, .l=__LINE__,\n-          .e=cuModuleGetFunction(&function, module, name),\n-          .t=\"cuModuleGetFunction\"\n-    }.report();\n+    CUDA_CHECK(cuModuleGetFunction(&function, module, name), \"cuModuleGetFunction\");\n@@ -54,1 +51,0 @@\n-\n","filename":"hat\/backends\/ffi\/cuda\/src\/main\/native\/cpp\/cuda_backend_module.cpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -55,4 +55,1 @@\n-    WHERE{.f=__FILE__, .l=__LINE__,\n-          .e=cuStreamSynchronize(cuStream),\n-          .t= \"cuStreamSynchronize\"\n-    }.report();\n+    CUDA_CHECK(cuStreamSynchronize(cuStream), \"cuStreamSynchronize\");\n@@ -62,1 +59,1 @@\n-void CudaBackend::CudaQueue::computeStart(){\n+void CudaBackend::CudaQueue::computeStart() {\n@@ -67,1 +64,1 @@\n-void CudaBackend::CudaQueue::computeEnd(){\n+void CudaBackend::CudaQueue::computeEnd() {\n@@ -71,1 +68,1 @@\n-void CudaBackend::CudaQueue::release(){\n+void CudaBackend::CudaQueue::release() {\n@@ -75,5 +72,2 @@\n-CudaBackend::CudaQueue::~CudaQueue(){\n-    WHERE{.f=__FILE__, .l=__LINE__,\n-            .e=cuStreamDestroy(cuStream),\n-            .t= \"cuStreamDestroy\"\n-    }.report();\n+CudaBackend::CudaQueue::~CudaQueue() {\n+    CUDA_CHECK(cuStreamDestroy(cuStream), \"cuStreamDestroy\");\n@@ -97,3 +91,2 @@\n-    WHERE{.f=__FILE__, .l=__LINE__,\n-            .e=cuMemcpyHtoDAsync(\n-                    cudaBuffer->devicePtr,\n+\n+    CUDA_CHECK(cuMemcpyHtoDAsync(cudaBuffer->devicePtr,\n@@ -102,3 +95,1 @@\n-                    dynamic_cast<CudaQueue*>(backend->queue)->cuStream),\n-            .t=\"cuMemcpyHtoDAsync\"\n-    }.report();\n+                    dynamic_cast<CudaQueue*>(backend->queue)->cuStream), \"cuMemcpyHtoDAsync\");\n@@ -123,8 +114,5 @@\n-    WHERE{.f=__FILE__, .l=__LINE__,\n-            .e=cuMemcpyDtoHAsync(\n-                    cudaBuffer->bufferState->ptr,\n-                    cudaBuffer->devicePtr,\n-                    cudaBuffer->bufferState->length,\n-                                 dynamic_cast<CudaQueue*>(backend->queue)->cuStream),\n-            .t=\"cuMemcpyDtoHAsync\"\n-    }.report();\n+    CUDA_CHECK(cuMemcpyDtoHAsync(cudaBuffer->bufferState->ptr,\n+                                cudaBuffer->devicePtr,\n+                                cudaBuffer->bufferState->length,\n+                                dynamic_cast<CudaQueue*>(backend->queue)->cuStream),\n+                                \"cuMemcpyDtoHAsync\");\n@@ -189,1 +177,1 @@\n-    WHERE{.f=__FILE__, .l=__LINE__, .e=status, .t=\"cuLaunchKernel\"}.report();\n+    CUDA_CHECK(status, \"cuLaunchKernel\");\n","filename":"hat\/backends\/ffi\/cuda\/src\/main\/native\/cpp\/cuda_backend_queue.cpp","additions":15,"deletions":27,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -65,4 +65,2 @@\n-    void report() const{\n-        if (e == CUDA_SUCCESS){\n-           \/\/ std::cout << t << \"  OK at \" << f << \" line \" << l << std::endl;\n-        }else {\n+    void report() const {\n+        if (e != CUDA_SUCCESS){\n@@ -77,0 +75,8 @@\n+#define CUDA_CHECK(err, functionName) { \\\n+    WHERE{.f =__FILE__, \\\n+          .l=__LINE__, \\\n+          .e = err, \\\n+          .t = functionName \\\n+         }.report(); \\\n+}\n+\n","filename":"hat\/backends\/ffi\/cuda\/src\/main\/native\/include\/cuda_backend.h","additions":10,"deletions":4,"binary":false,"changes":14,"status":"modified"}]}