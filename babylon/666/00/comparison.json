{"files":[{"patch":"@@ -69,6 +69,0 @@\n-\/\/        MemorySegment memorySegment = Buffer.getMemorySegment(this);\n-\/\/        float f1 = memorySegment.get(JAVA_FLOAT, ARRAY_OFFSET + index + 0);\n-\/\/        float f2 = memorySegment.get(JAVA_FLOAT, ARRAY_OFFSET + index + 1);\n-\/\/        float f3 = memorySegment.get(JAVA_FLOAT, ARRAY_OFFSET + index + 2);\n-\/\/        float f4 = memorySegment.get(JAVA_FLOAT, ARRAY_OFFSET + index + 3);\n-\/\/        return Float4.makeMutable(Float4.of(f1, f2, f3, f4));\n@@ -79,1 +73,7 @@\n-\/\/        MemorySegment.copy(Buffer.getMemorySegment(this), JAVA_FLOAT, ARRAY_OFFSET, v.toArray(), index, 4);\n+    }\n+\n+    default Float2.MutableImpl float2View(int index) {\n+        return  null;\n+    }\n+\n+    default void storeFloat2View(Float2 v, int index) {\n","filename":"hat\/core\/src\/main\/java\/hat\/buffer\/F32ArrayPadded.java","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -0,0 +1,115 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+package hat.buffer;\n+\n+import hat.types._V2;\n+import jdk.incubator.code.CodeReflection;\n+import jdk.incubator.code.dialect.java.JavaType;\n+import jdk.incubator.code.dialect.java.PrimitiveType;\n+\n+import java.util.function.BiFunction;\n+import java.util.stream.IntStream;\n+\n+public interface Float2 extends _V2 {\n+\n+    float x();\n+    float y();\n+\n+    @CodeReflection\n+    @Override\n+    default PrimitiveType type() {\n+        return JavaType.FLOAT;\n+    }\n+\n+    record MutableImpl(float x, float y) implements Float2 {\n+        public void x(float x) {}\n+        public void y(float y) {}\n+    }\n+\n+    record ImmutableImpl(float x, float y) implements Float2 {\n+    }\n+\n+    \/**\n+     * Make a Mutable implementation (for the device side - e.g., the GPU) from an immutable implementation.\n+     *\n+     * @param {@link Float2}\n+     * @return {@link Float2.MutableImpl}\n+     *\/\n+    static Float2.MutableImpl makeMutable(Float2 float2) {\n+        return new MutableImpl(float2.x(), float2.y());\n+    }\n+\n+    static Float2 of(float x, float y) {\n+        return new ImmutableImpl(x, y);\n+    }\n+\n+    \/\/ Not implemented for the GPU yet\n+    default Float2 lanewise(Float2 other, BiFunction<Float, Float, Float> f) {\n+        float[] backA = this.toArray();\n+        float[] backB = other.toArray();\n+        float[] backC = new float[backA.length];\n+        IntStream.range(0, backA.length).forEach(j -> {\n+            backC[j] = f.apply(backA[j], backB[j]);\n+        });\n+        return of(backC[0], backC[1]);\n+    }\n+\n+    static Float2 add(Float2 vA, Float2 vB) {\n+        return vA.lanewise(vB, Float::sum);\n+    }\n+\n+    static Float2 sub(Float2 vA, Float2 vB) {\n+        return vA.lanewise(vB, (a, b) -> a - b);\n+    }\n+\n+    static Float2 mul(Float2 vA, Float2 vB) {\n+        return vA.lanewise(vB, (a, b) -> a * b);\n+    }\n+\n+    static Float2 div(Float2 vA, Float2 vB) {\n+        return vA.lanewise(vB, (a, b) -> a \/ b);\n+    }\n+\n+    default Float2 add(Float2 vb) {\n+        return Float2.add(this, vb);\n+    }\n+\n+    default Float2 sub(Float2 vb) {\n+        return Float2.sub(this, vb);\n+    }\n+\n+    default Float2 mul(Float2 vb) {\n+        return Float2.mul(this, vb);\n+    }\n+\n+    default Float2 div(Float2 vb) {\n+        return Float2.div(this, vb);\n+    }\n+\n+    \/\/ Not implemented for the GPU yet\n+    default float[] toArray() {\n+        return new float[] { x(), y()};\n+    }\n+}\n","filename":"hat\/core\/src\/main\/java\/hat\/buffer\/Float2.java","additions":115,"deletions":0,"binary":false,"changes":115,"status":"added"},{"patch":"@@ -56,0 +56,1 @@\n+        hatPhases.add(new HATDialectifyVectorOpPhase.Float2LoadPhase(accelerator));\n@@ -63,0 +64,1 @@\n+        hatPhases.add(new HATDialectifyVectorStorePhase.Float2StorePhase(accelerator));\n","filename":"hat\/core\/src\/main\/java\/hat\/phases\/HATDialectifyTier.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -94,0 +94,1 @@\n+        FLOAT2_LOAD(\"float2View\"),\n@@ -442,0 +443,1 @@\n+            case FLOAT2_LOAD ->  funcOp = dialectifyVectorLoad(funcOp);\n@@ -481,0 +483,7 @@\n+    public static class Float2LoadPhase extends HATDialectifyVectorOpPhase {\n+\n+        public Float2LoadPhase(Accelerator accelerator) {\n+            super(accelerator, OpView.FLOAT2_LOAD);\n+        }\n+    }\n+\n","filename":"hat\/core\/src\/main\/java\/hat\/phases\/HATDialectifyVectorOpPhase.java","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -62,1 +62,2 @@\n-        FLOAT4_STORE(\"storeFloat4View\");\n+        FLOAT4_STORE(\"storeFloat4View\"),\n+        FLOAT2_STORE(\"storeFloat2View\");\n@@ -159,0 +160,6 @@\n+\n+    public static class Float2StorePhase extends HATDialectifyVectorStorePhase{\n+        public Float2StorePhase(Accelerator accelerator) {\n+            super(accelerator, StoreView.FLOAT2_STORE);\n+        }\n+    }\n","filename":"hat\/core\/src\/main\/java\/hat\/phases\/HATDialectifyVectorStorePhase.java","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -29,1 +29,1 @@\n-public interface _V4 extends _V {\n+public interface _V2 extends _V {\n@@ -34,1 +34,1 @@\n-        return 4;\n+        return 2;\n","filename":"hat\/core\/src\/main\/java\/hat\/types\/_V2.java","additions":2,"deletions":2,"binary":false,"changes":4,"previous_filename":"hat\/core\/src\/main\/java\/hat\/types\/_V4.java","status":"copied"},{"patch":"@@ -174,1 +174,2 @@\n-                \"hat.test.TestF16Type\"\n+                \"hat.test.TestF16Type\",\n+                \"hat.test.TestFloat2\"\n","filename":"hat\/hat\/test.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -0,0 +1,676 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+package hat.test;\n+\n+import hat.Accelerator;\n+import hat.ComputeContext;\n+import hat.KernelContext;\n+import hat.NDRange;\n+import hat.backend.Backend;\n+import hat.buffer.Buffer;\n+import hat.buffer.F32ArrayPadded;\n+import hat.buffer.Float2;\n+import hat.ifacemapper.MappableIface.RO;\n+import hat.ifacemapper.MappableIface.RW;\n+import hat.ifacemapper.Schema;\n+import hat.test.annotation.HatTest;\n+import hat.test.engine.HatAsserts;\n+import jdk.incubator.code.CodeReflection;\n+\n+import java.lang.invoke.MethodHandles;\n+import java.util.Random;\n+\n+public class TestFloat2 {\n+\n+    @CodeReflection\n+    public static void vectorOps01(@RO KernelContext kernelContext, @RO F32ArrayPadded a, @RO F32ArrayPadded b, @RW F32ArrayPadded c) {\n+        if (kernelContext.gix < kernelContext.gsx) {\n+            int index = kernelContext.gix;\n+            Float2 vA = a.float2View(index * 2);\n+            Float2 vB = b.float2View(index * 2);\n+            Float2 vC = Float2.add(vA, vB);\n+            c.storeFloat2View(vC, index * 2);\n+        }\n+    }\n+\n+    @CodeReflection\n+    public static void vectorOps02(@RO KernelContext kernelContext, @RO F32ArrayPadded a, @RW F32ArrayPadded b) {\n+        if (kernelContext.gix < kernelContext.gsx) {\n+            int index = kernelContext.gix;\n+            Float2.MutableImpl vA = a.float2View(index * 2);\n+            float scaleX = vA.x() * 10.0f;\n+            vA.x(scaleX);\n+            b.storeFloat2View(vA, index * 2);\n+        }\n+    }\n+\n+    @CodeReflection\n+    public static void vectorOps03(@RO KernelContext kernelContext, @RO F32ArrayPadded a, @RW F32ArrayPadded b) {\n+        if (kernelContext.gix < kernelContext.gsx) {\n+            int index = kernelContext.gix;\n+\n+            \/\/ Obtain a view of the input data as a float4 and\n+            \/\/ store that view in private memory\n+            Float2 vA = a.float2View(index * 2);\n+\n+            \/\/ operate with the float4\n+            float scaleX = vA.x() * 10.0f;\n+            float scaleY = vA.y() * 20.0f;\n+\n+            \/\/ Create a float4 within the device code\n+            Float2 vResult = Float2.of(scaleX, scaleY);\n+\n+            \/\/ store the float4 from private memory to global memory\n+            b.storeFloat2View(vResult, index * 2);\n+        }\n+    }\n+\n+    @CodeReflection\n+    public static void vectorOps04(@RO KernelContext kernelContext, @RO F32ArrayPadded a, @RW F32ArrayPadded b) {\n+        if (kernelContext.gix < kernelContext.gsx) {\n+            int index = kernelContext.gix;\n+            Float2.MutableImpl vA = a.float2View(index * 2);\n+            vA.x(vA.x() * 10.0f);\n+            vA.y(vA.y() * 20.0f);\n+            b.storeFloat2View(vA, index * 2);\n+        }\n+    }\n+\n+    @CodeReflection\n+    public static void vectorOps05(@RO KernelContext kernelContext, @RO F32ArrayPadded a, @RO F32ArrayPadded b, @RW F32ArrayPadded c) {\n+        if (kernelContext.gix < kernelContext.gsx) {\n+            int index = kernelContext.gix;\n+            Float2 vA = a.float2View(index * 2);\n+            Float2 vB = b.float2View(index * 2);\n+            Float2 vC = vA.add(vB).add(vB);\n+            c.storeFloat2View(vC, index * 2);\n+        }\n+    }\n+\n+    @CodeReflection\n+    public static void vectorOps06(@RO KernelContext kernelContext, @RO F32ArrayPadded a, @RO F32ArrayPadded b, @RW F32ArrayPadded c) {\n+        if (kernelContext.gix < kernelContext.gsx) {\n+            int index = kernelContext.gix;\n+            Float2 vA = a.float2View(index * 2);\n+            Float2 vB = b.float2View(index * 2);\n+            Float2 vD = Float2.sub(vA, vB);\n+            Float2 vC = vA.sub(vB);\n+            c.storeFloat2View(vC, index * 2);\n+        }\n+    }\n+\n+    @CodeReflection\n+    public static void vectorOps07(@RO KernelContext kernelContext, @RO F32ArrayPadded a, @RO F32ArrayPadded b, @RW F32ArrayPadded c) {\n+        if (kernelContext.gix < kernelContext.gsx) {\n+            int index = kernelContext.gix;\n+            Float2 vA = a.float2View(index * 2);\n+            Float2 vB = b.float2View(index * 2);\n+            Float2 vC = vA.add(vB).sub(vB);\n+            c.storeFloat2View(vC, index * 2);\n+        }\n+    }\n+\n+    @CodeReflection\n+    public static void vectorOps08(@RO KernelContext kernelContext, @RO F32ArrayPadded a, @RO F32ArrayPadded b, @RW F32ArrayPadded c) {\n+        if (kernelContext.gix < kernelContext.gsx) {\n+            int index = kernelContext.gix;\n+            Float2 vA = a.float2View(index * 2);\n+            Float2 vB = b.float2View(index * 2);\n+            Float2 vC = vA.add(vB).mul(vA).div(vB);\n+            c.storeFloat2View(vC, index * 2);\n+        }\n+    }\n+\n+    @CodeReflection\n+    public static void vectorOps09(@RO KernelContext kernelContext, @RO F32ArrayPadded a, @RO F32ArrayPadded b, @RW F32ArrayPadded c) {\n+        \/\/ Checking composition\n+        if (kernelContext.gix < kernelContext.gsx) {\n+            int index = kernelContext.gix;\n+            Float2 vA = a.float2View(index * 2);\n+            Float2 vB = b.float2View(index * 2);\n+            Float2 vC = vA.add(vA.mul(vB));\n+            c.storeFloat2View(vC, index * 2);\n+        }\n+    }\n+\n+    private interface SharedArray extends Buffer {\n+        void array(long index, float value);\n+        float array(long index);\n+        Schema<SharedArray> schema = Schema.of(SharedArray.class,\n+                arr -> arr.array(\"array\", 1024));\n+        static SharedArray create(Accelerator accelerator) {\n+            return schema.allocate(accelerator);\n+        }\n+        static SharedArray createLocal() {\n+            return schema.allocate(new Accelerator(MethodHandles.lookup(), Backend.FIRST));\n+        }\n+        default Float2 float2View(int index) {\n+            return null;\n+        }\n+        default void storeFloat2View(Float2 float4, int index) {\n+        }\n+    }\n+\n+    @CodeReflection\n+    public static void vectorOps10(@RO KernelContext kernelContext, @RO F32ArrayPadded a, @RW F32ArrayPadded b) {\n+        SharedArray sm = SharedArray.createLocal();\n+        if (kernelContext.gix < kernelContext.gsx) {\n+            int index = kernelContext.gix;\n+            int lix = kernelContext.lix;\n+            Float2 vA = a.float2View(index * 2);\n+            sm.storeFloat2View(vA, lix * 2);\n+            kernelContext.barrier();\n+            Float2 r = sm.float2View(lix * 2);\n+            b.storeFloat2View(r, index * 2);\n+        }\n+    }\n+\n+    private interface PrivateMemory extends Buffer {\n+        void array(long index, float value);\n+        float array(long index);\n+        Schema<PrivateMemory> schema = Schema.of(PrivateMemory.class,\n+                arr -> arr.array(\"array\", 4));\n+        static PrivateMemory create(Accelerator accelerator) {\n+            return schema.allocate(accelerator);\n+        }\n+        static PrivateMemory createPrivate() {\n+            return schema.allocate(new Accelerator(MethodHandles.lookup(), Backend.FIRST));\n+        }\n+        default Float2 float2View(int index) {\n+            return null;\n+        }\n+        default void storeFloat2View(Float2 float4, int index) {\n+        }\n+    }\n+\n+    @CodeReflection\n+    public static void vectorOps11(@RO KernelContext kernelContext, @RO F32ArrayPadded a, @RW F32ArrayPadded b) {\n+        PrivateMemory pm = PrivateMemory.createPrivate();\n+        if (kernelContext.gix < kernelContext.gsx) {\n+            int index = kernelContext.gix;\n+            Float2 vA = a.float2View(index * 2);\n+            pm.storeFloat2View(vA, 0);\n+            kernelContext.barrier();\n+            Float2 r = pm.float2View(0);\n+            b.storeFloat2View(r, index * 2);\n+        }\n+    }\n+\n+    @CodeReflection\n+    public static void vectorOps12(@RO KernelContext kernelContext, @RO F32ArrayPadded a, @RW F32ArrayPadded b) {\n+        SharedArray sm = SharedArray.createLocal();\n+        if (kernelContext.gix < kernelContext.gsx) {\n+            int index = kernelContext.gix;\n+            int lix = kernelContext.lix;\n+            Float2 vA = a.float2View(index * 2);\n+            sm.array(lix * 2 + 0, vA.x());\n+            sm.array(lix * 2 + 1, vA.y());\n+            kernelContext.barrier();\n+            Float2 r = sm.float2View(lix * 2);\n+            b.storeFloat2View(r, index * 2);\n+        }\n+    }\n+\n+    @CodeReflection\n+    public static void vectorOps14(@RO KernelContext kernelContext, @RW F32ArrayPadded a) {\n+        if (kernelContext.gix < kernelContext.gsx) {\n+            int index = kernelContext.gix;\n+            Float2 vA = a.float2View(index * 2);\n+            Float2.MutableImpl vB = Float2.makeMutable(vA);\n+            vB.x(10.0f);\n+            a.storeFloat2View(vB, index * 2);\n+        }\n+    }\n+\n+\n+    @CodeReflection\n+    public static void vectorOps15(@RO KernelContext kernelContext, @RW F32ArrayPadded a) {\n+        \/\/ in this sample, we don't perform the vload, but rather the vstore directly\n+        \/\/ from a new float2.\n+        if (kernelContext.gix < kernelContext.gsx) {\n+            int index = kernelContext.gix;\n+            Float2 result = Float2.of(1.0f, 2.0f);\n+            a.storeFloat2View(result, index * 2);\n+        }\n+    }\n+\n+    @CodeReflection\n+    public static void computeGraph01(@RO ComputeContext cc, @RO F32ArrayPadded a, @RO F32ArrayPadded b, @RW F32ArrayPadded c, int size) {\n+        \/\/ Note: we need to launch N threads \/ vectorWidth -> size \/ 2 for this example\n+        NDRange ndRange = NDRange.of(new NDRange.Global1D(size\/2), new NDRange.Local1D(128));\n+        cc.dispatchKernel(ndRange, kernelContext -> TestFloat2.vectorOps01(kernelContext, a, b, c));\n+    }\n+\n+    @CodeReflection\n+    public static void computeGraph02(@RO ComputeContext cc, @RW F32ArrayPadded a, @RW F32ArrayPadded b, int size) {\n+        \/\/ Note: we need to launch N threads \/ vectorWidth -> size \/ 2 for this example\n+        NDRange ndRange = NDRange.of(new NDRange.Global1D(size\/2));\n+        cc.dispatchKernel(ndRange, kernelContext -> TestFloat2.vectorOps02(kernelContext, a, b));\n+    }\n+\n+    @CodeReflection\n+    public static void computeGraph03(@RO ComputeContext cc, @RO F32ArrayPadded a, @RW F32ArrayPadded b, int size) {\n+        \/\/ Note: we need to launch N threads \/ vectorWidth -> size \/ 2 for this example\n+        NDRange ndRange = NDRange.of(new NDRange.Global1D(size\/2));\n+        cc.dispatchKernel(ndRange, kernelContext -> TestFloat2.vectorOps03(kernelContext, a, b));\n+    }\n+\n+    @CodeReflection\n+    public static void computeGraph04(@RO ComputeContext cc, @RO F32ArrayPadded a, @RW F32ArrayPadded b, int size) {\n+        \/\/ Note: we need to launch N threads \/ vectorWidth -> size \/ 2 for this example\n+        NDRange ndRange = NDRange.of(new NDRange.Global1D(size\/2));\n+        cc.dispatchKernel(ndRange, kernelContext -> TestFloat2.vectorOps04(kernelContext, a, b));\n+    }\n+\n+    @CodeReflection\n+    public static void computeGraph05(@RO ComputeContext cc, @RO F32ArrayPadded a, @RO F32ArrayPadded b, @RW F32ArrayPadded c,  int size) {\n+        \/\/ Note: we need to launch N threads \/ vectorWidth -> size \/ 2 for this example\n+        NDRange ndRange = NDRange.of(new NDRange.Global1D(size\/2));\n+        cc.dispatchKernel(ndRange, kernelContext -> TestFloat2.vectorOps05(kernelContext, a, b, c));\n+    }\n+\n+    @CodeReflection\n+    public static void computeGraph06(@RO ComputeContext cc, @RO F32ArrayPadded a, @RO F32ArrayPadded b, @RW F32ArrayPadded c,  int size) {\n+        \/\/ Note: we need to launch N threads \/ vectorWidth -> size \/ 2 for this example\n+        NDRange ndRange = NDRange.of(new NDRange.Global1D(size\/2));\n+        cc.dispatchKernel(ndRange, kernelContext -> TestFloat2.vectorOps06(kernelContext, a, b, c));\n+    }\n+\n+\n+    @CodeReflection\n+    public static void computeGraph07(@RO ComputeContext cc, @RO F32ArrayPadded a, @RO F32ArrayPadded b, @RW F32ArrayPadded c,  int size) {\n+        \/\/ Note: we need to launch N threads \/ vectorWidth -> size \/ 2 for this example\n+        NDRange ndRange = NDRange.of(new NDRange.Global1D(size\/2));\n+        cc.dispatchKernel(ndRange, kernelContext -> TestFloat2.vectorOps07(kernelContext, a, b, c));\n+    }\n+\n+    @CodeReflection\n+    public static void computeGraph08(@RO ComputeContext cc, @RO F32ArrayPadded a, @RO F32ArrayPadded b, @RW F32ArrayPadded c,  int size) {\n+        \/\/ Note: we need to launch N threads \/ vectorWidth -> size \/ 2 for this example\n+        NDRange ndRange = NDRange.of(new NDRange.Global1D(size\/2));\n+        cc.dispatchKernel(ndRange, kernelContext -> TestFloat2.vectorOps08(kernelContext, a, b, c));\n+    }\n+\n+    @CodeReflection\n+    public static void computeGraph09(@RO ComputeContext cc, @RO F32ArrayPadded a, @RO F32ArrayPadded b, @RW F32ArrayPadded c,  int size) {\n+        \/\/ Note: we need to launch N threads \/ vectorWidth -> size \/ 2 for this example\n+        NDRange ndRange = NDRange.of(new NDRange.Global1D(size\/2));\n+        cc.dispatchKernel(ndRange, kernelContext -> TestFloat2.vectorOps09(kernelContext, a, b, c));\n+    }\n+\n+    @CodeReflection\n+    public static void computeGraph10(@RO ComputeContext cc, @RO F32ArrayPadded a,  @RW F32ArrayPadded b, int size) {\n+        \/\/ Note: we need to launch N threads \/ vectorWidth -> size \/ 2 for this example\n+        NDRange ndRange = NDRange.of(new NDRange.Global1D(size\/2));\n+        cc.dispatchKernel(ndRange, kernelContext -> TestFloat2.vectorOps10(kernelContext, a, b));\n+    }\n+\n+    @CodeReflection\n+    public static void computeGraph11(@RO ComputeContext cc, @RO F32ArrayPadded a,  @RW F32ArrayPadded b, int size) {\n+        \/\/ Note: we need to launch N threads \/ vectorWidth -> size \/ 2 for this example\n+        NDRange ndRange = NDRange.of(new NDRange.Global1D(size\/2));\n+        cc.dispatchKernel(ndRange, kernelContext -> TestFloat2.vectorOps11(kernelContext, a, b));\n+    }\n+\n+    @CodeReflection\n+    public static void computeGraph12(@RO ComputeContext cc, @RO F32ArrayPadded a,  @RW F32ArrayPadded b, int size) {\n+        \/\/ Note: we need to launch N threads \/ vectorWidth -> size \/ 2 for this example\n+        NDRange ndRange = NDRange.of(new NDRange.Global1D(size\/2));\n+        cc.dispatchKernel(ndRange, kernelContext -> TestFloat2.vectorOps12(kernelContext, a, b));\n+    }\n+\n+    @CodeReflection\n+    public static void computeGraph14(@RO ComputeContext cc, @RW F32ArrayPadded a, int size) {\n+        \/\/ Note: we need to launch N threads \/ vectorWidth -> size \/ 2 for this example\n+        NDRange ndRange = NDRange.of(new NDRange.Global1D(size\/2));\n+        cc.dispatchKernel(ndRange, kernelContext -> TestFloat2.vectorOps14(kernelContext, a));\n+    }\n+\n+    @CodeReflection\n+    public static void computeGraph15(@RO ComputeContext cc, @RW F32ArrayPadded a, int size) {\n+        \/\/ Note: we need to launch N threads \/ vectorWidth -> size \/ 2 for this example\n+        NDRange ndRange = NDRange.of(new NDRange.Global1D(size\/2));\n+        cc.dispatchKernel(ndRange, kernelContext -> TestFloat2.vectorOps15(kernelContext, a));\n+    }\n+\n+\n+    @HatTest\n+    public void testFloat2_01() {\n+        final int size = 1024;\n+        var accelerator = new Accelerator(MethodHandles.lookup(), Backend.FIRST);\n+        var arrayA = F32ArrayPadded.create(accelerator, size);\n+        var arrayB = F32ArrayPadded.create(accelerator, size);\n+        var arrayC = F32ArrayPadded.create(accelerator, size);\n+\n+        Random r = new Random(19);\n+        for (int i = 0; i < size; i++) {\n+            arrayA.array(i, r.nextFloat());\n+            arrayB.array(i, r.nextFloat());\n+        }\n+\n+        accelerator.compute(cc -> TestFloat2.computeGraph01(cc, arrayA, arrayB, arrayC, size));\n+\n+        for (int i = 0; i < size; i++) {\n+            HatAsserts.assertEquals((arrayA.array(i) + arrayB.array(i)), arrayC.array(i), 0.001f);\n+        }\n+\n+    }\n+\n+    @HatTest\n+    public void testFloat2_02() {\n+        final int size = 1024;\n+        var accelerator = new Accelerator(MethodHandles.lookup(), Backend.FIRST);\n+        var arrayA = F32ArrayPadded.create(accelerator, size);\n+        var arrayB = F32ArrayPadded.create(accelerator, size);\n+\n+        Random r = new Random(19);\n+        for (int i = 0; i < size; i++) {\n+            arrayA.array(i, r.nextFloat());\n+        }\n+\n+        accelerator.compute(cc -> TestFloat2.computeGraph02(cc, arrayA, arrayB, size));\n+\n+        for (int i = 0; i < size; i += 2) {\n+            HatAsserts.assertEquals((arrayA.array(i + 0) * 10.0f), arrayB.array(i + 0), 0.001f);\n+            HatAsserts.assertEquals((arrayA.array(i + 1)), arrayB.array(i + 1), 0.001f);\n+        }\n+    }\n+\n+    @HatTest\n+    public void testFloat2_03() {\n+        final int size = 1024;\n+        var accelerator = new Accelerator(MethodHandles.lookup(), Backend.FIRST);\n+        var arrayA = F32ArrayPadded.create(accelerator, size);\n+        var arrayB = F32ArrayPadded.create(accelerator, size);\n+\n+        Random r = new Random(19);\n+        for (int i = 0; i < size; i++) {\n+            arrayA.array(i, r.nextFloat());\n+        }\n+\n+        accelerator.compute(cc -> TestFloat2.computeGraph03(cc, arrayA, arrayB, size));\n+\n+        for (int i = 0; i < size; i += 2) {\n+            HatAsserts.assertEquals((arrayA.array(i + 0) * 10.0f), arrayB.array(i + 0), 0.001f);\n+            HatAsserts.assertEquals((arrayA.array(i + 1) * 20.0f), arrayB.array(i + 1), 0.001f);\n+        }\n+    }\n+\n+    @HatTest\n+    public void testFloat2_04() {\n+        final int size = 1024;\n+        var accelerator = new Accelerator(MethodHandles.lookup(), Backend.FIRST);\n+        var arrayA = F32ArrayPadded.create(accelerator, size);\n+        var arrayB = F32ArrayPadded.create(accelerator, size);\n+\n+        Random r = new Random(19);\n+        for (int i = 0; i < size; i++) {\n+            arrayA.array(i, r.nextFloat());\n+        }\n+\n+        accelerator.compute(cc -> TestFloat2.computeGraph04(cc, arrayA, arrayB, size));\n+\n+        for (int i = 0; i < size; i += 2) {\n+            HatAsserts.assertEquals((arrayA.array(i + 0) * 10.0f), arrayB.array(i + 0), 0.001f);\n+            HatAsserts.assertEquals((arrayA.array(i + 1) * 20.0f), arrayB.array(i + 1), 0.001f);\n+        }\n+    }\n+\n+    @HatTest\n+    public void testFloat2_05() {\n+        final int size = 1024;\n+        var accelerator = new Accelerator(MethodHandles.lookup(), Backend.FIRST);\n+        var arrayA = F32ArrayPadded.create(accelerator, size);\n+        var arrayB = F32ArrayPadded.create(accelerator, size);\n+        var arrayC = F32ArrayPadded.create(accelerator, size);\n+\n+        Random r = new Random(19);\n+        for (int i = 0; i < size; i++) {\n+            arrayA.array(i, r.nextFloat());\n+            arrayB.array(i, r.nextFloat());\n+        }\n+\n+        accelerator.compute(cc -> TestFloat2.computeGraph05(cc, arrayA, arrayB, arrayC, size));\n+\n+        for (int i = 0; i < size; i++) {\n+            HatAsserts.assertEquals((arrayA.array(i) + arrayB.array(i) + arrayB.array(i)), arrayC.array(i), 0.001f);\n+        }\n+    }\n+\n+    @HatTest\n+    public void testFloat2_06() {\n+        final int size = 1024;\n+        var accelerator = new Accelerator(MethodHandles.lookup(), Backend.FIRST);\n+        var arrayA = F32ArrayPadded.create(accelerator, size);\n+        var arrayB = F32ArrayPadded.create(accelerator, size);\n+        var arrayC = F32ArrayPadded.create(accelerator, size);\n+\n+        Random r = new Random(19);\n+        for (int i = 0; i < size; i++) {\n+            arrayA.array(i, r.nextFloat());\n+            arrayB.array(i, r.nextFloat());\n+        }\n+\n+        accelerator.compute(cc -> TestFloat2.computeGraph06(cc, arrayA, arrayB, arrayC, size));\n+\n+        for (int i = 0; i < size; i++) {\n+            HatAsserts.assertEquals((arrayA.array(i) - arrayB.array(i)), arrayC.array(i), 0.001f);\n+        }\n+    }\n+\n+    @HatTest\n+    public void testFloat2_07() {\n+        final int size = 1024;\n+        var accelerator = new Accelerator(MethodHandles.lookup(), Backend.FIRST);\n+        var arrayA = F32ArrayPadded.create(accelerator, size);\n+        var arrayB = F32ArrayPadded.create(accelerator, size);\n+        var arrayC = F32ArrayPadded.create(accelerator, size);\n+\n+        Random r = new Random(19);\n+        for (int i = 0; i < size; i++) {\n+            arrayA.array(i, r.nextFloat());\n+            arrayB.array(i, r.nextFloat());\n+        }\n+\n+        accelerator.compute(cc -> TestFloat2.computeGraph07(cc, arrayA, arrayB, arrayC, size));\n+\n+        for (int i = 0; i < size; i++) {\n+            HatAsserts.assertEquals(arrayA.array(i), arrayC.array(i), 0.001f);\n+        }\n+    }\n+\n+    @HatTest\n+    public void testFloat2_08() {\n+        final int size = 1024;\n+        var accelerator = new Accelerator(MethodHandles.lookup(), Backend.FIRST);\n+        var arrayA = F32ArrayPadded.create(accelerator, size);\n+        var arrayB = F32ArrayPadded.create(accelerator, size);\n+        var arrayC = F32ArrayPadded.create(accelerator, size);\n+\n+        Random r = new Random(19);\n+        for (int i = 0; i < size; i++) {\n+            arrayA.array(i, r.nextFloat());\n+            arrayB.array(i, r.nextFloat());\n+        }\n+\n+        accelerator.compute(cc -> TestFloat2.computeGraph08(cc, arrayA, arrayB, arrayC, size));\n+\n+        for (int i = 0; i < size; i++) {\n+            float val = (((arrayA.array(i) + arrayB.array(i)) * arrayA.array(i)) \/ arrayB.array(i));\n+            HatAsserts.assertEquals(val, arrayC.array(i), 0.001f);\n+        }\n+    }\n+\n+    @HatTest\n+    public void testFloat2_09() {\n+        final int size = 1024;\n+        var accelerator = new Accelerator(MethodHandles.lookup(), Backend.FIRST);\n+        var arrayA = F32ArrayPadded.create(accelerator, size);\n+        var arrayB = F32ArrayPadded.create(accelerator, size);\n+        var arrayC = F32ArrayPadded.create(accelerator, size);\n+\n+        Random r = new Random(19);\n+        for (int i = 0; i < size; i++) {\n+            arrayA.array(i, r.nextFloat());\n+            arrayB.array(i, r.nextFloat());\n+        }\n+\n+        accelerator.compute(cc -> TestFloat2.computeGraph09(cc, arrayA, arrayB, arrayC, size));\n+\n+        for (int i = 0; i < size; i++) {\n+            float val = (arrayA.array(i) + (arrayB.array(i)) * arrayA.array(i));\n+            HatAsserts.assertEquals(val, arrayC.array(i), 0.001f);\n+        }\n+    }\n+\n+    @HatTest\n+    public void testFloat2_10() {\n+        final int size = 1024;\n+        var accelerator = new Accelerator(MethodHandles.lookup(), Backend.FIRST);\n+        var arrayA = F32ArrayPadded.create(accelerator, size);\n+        var arrayB = F32ArrayPadded.create(accelerator, size);\n+\n+        Random r = new Random(19);\n+        for (int i = 0; i < size; i++) {\n+            arrayA.array(i, r.nextFloat());\n+            arrayB.array(i, r.nextFloat());\n+        }\n+\n+        accelerator.compute(cc -> TestFloat2.computeGraph10(cc, arrayA, arrayB, size));\n+\n+        for (int i = 0; i < size; i++) {\n+            HatAsserts.assertEquals(arrayA.array(i), arrayB.array(i), 0.001f);\n+        }\n+    }\n+\n+    @HatTest\n+    public void testFloat2_11() {\n+        final int size = 1024;\n+        var accelerator = new Accelerator(MethodHandles.lookup(), Backend.FIRST);\n+        var arrayA = F32ArrayPadded.create(accelerator, size);\n+        var arrayB = F32ArrayPadded.create(accelerator, size);\n+\n+        Random r = new Random(19);\n+        for (int i = 0; i < size; i++) {\n+            arrayA.array(i, r.nextFloat());\n+            arrayB.array(i, r.nextFloat());\n+        }\n+\n+        accelerator.compute(cc -> TestFloat2.computeGraph11(cc, arrayA, arrayB, size));\n+\n+        for (int i = 0; i < size; i++) {\n+            HatAsserts.assertEquals(arrayA.array(i), arrayB.array(i), 0.001f);\n+        }\n+    }\n+\n+    @HatTest\n+    public void testFloat2_12() {\n+        final int size = 1024;\n+        var accelerator = new Accelerator(MethodHandles.lookup(), Backend.FIRST);\n+        var arrayA = F32ArrayPadded.create(accelerator, size);\n+        var arrayB = F32ArrayPadded.create(accelerator, size);\n+\n+        Random r = new Random(19);\n+        for (int i = 0; i < size; i++) {\n+            arrayA.array(i, r.nextFloat());\n+            arrayB.array(i, r.nextFloat());\n+        }\n+\n+        accelerator.compute(cc -> TestFloat2.computeGraph12(cc, arrayA, arrayB, size));\n+\n+        for (int i = 0; i < size; i++) {\n+            HatAsserts.assertEquals(arrayA.array(i), arrayB.array(i), 0.001f);\n+        }\n+    }\n+\n+    @HatTest\n+    public void testFloat2_13() {\n+        \/\/ Test the CPU implementation of Float4\n+        Float2 vA = Float2.of(1, 2);\n+        Float2 vB = Float2.of(3, 4);\n+        Float2 vC = Float2.add(vA, vB);\n+        Float2 expectedSum = Float2.of(\n+                vA.x() + vB.x(),\n+                vA.y() + vB.y());\n+\n+        HatAsserts.assertEquals(expectedSum, vC, 0.001f);\n+\n+        Float2 vD = Float2.sub(vA, vB);\n+        Float2 expectedSub = Float2.of(\n+                vA.x() - vB.x(),\n+                vA.y() - vB.y());\n+        HatAsserts.assertEquals(expectedSub, vD, 0.001f);\n+\n+        Float2 vE = Float2.mul(vA, vB);\n+        Float2 expectedMul = Float2.of(\n+                vA.x() * vB.x(),\n+                vA.y() * vB.y());\n+        HatAsserts.assertEquals(expectedMul, vE, 0.001f);\n+\n+        Float2 vF = Float2.div(vA, vB);\n+        Float2 expectedDiv = Float2.of(\n+                vA.x() \/ vB.x(),\n+                vA.y() \/ vB.y());\n+        HatAsserts.assertEquals(expectedDiv, vF, 0.001f);\n+    }\n+\n+    @HatTest\n+    public void testFloat2_14() {\n+        final int size = 1024;\n+        var accelerator = new Accelerator(MethodHandles.lookup(), Backend.FIRST);\n+        var arrayA = F32ArrayPadded.create(accelerator, size);\n+\n+        Random r = new Random(73);\n+        for (int i = 0; i < size; i++) {\n+            arrayA.array(i, r.nextFloat());\n+        }\n+\n+        accelerator.compute(cc -> TestFloat2.computeGraph14(cc, arrayA, size));\n+\n+        for (int i = 0; i < size; i += 2) {\n+            HatAsserts.assertEquals(10.0f, arrayA.array(i), 0.001f);\n+        }\n+    }\n+\n+    @HatTest\n+    public void testFloat2_15() {\n+        final int size = 2048;\n+        var accelerator = new Accelerator(MethodHandles.lookup(), Backend.FIRST);\n+        var arrayA = F32ArrayPadded.create(accelerator, size);\n+\n+        Random r = new Random(73);\n+        for (int i = 0; i < size; i++) {\n+            arrayA.array(i, r.nextFloat());\n+        }\n+\n+        accelerator.compute(cc -> TestFloat2.computeGraph15(cc, arrayA, size));\n+\n+        Float2 v = Float2.of(1.0f, 2.0f);\n+        for (int i = 0; i < size; i += 2) {\n+            HatAsserts.assertEquals(v.x(), arrayA.array(i), 0.001f);\n+            HatAsserts.assertEquals(v.y(), arrayA.array(i + 1), 0.001f);\n+        }\n+    }\n+}\n\\ No newline at end of file\n","filename":"hat\/tests\/src\/main\/java\/hat\/test\/TestFloat2.java","additions":676,"deletions":0,"binary":false,"changes":676,"status":"added"},{"patch":"@@ -27,0 +27,1 @@\n+import hat.buffer.Float2;\n@@ -67,0 +68,12 @@\n+    public static void assertEquals(Float2 expected, Float2 actual, float delta) {\n+        float[] arrayExpected = expected.toArray();\n+        float[] arrayActual = actual.toArray();\n+        for (int i = 0; i < 2; i++) {\n+            var expectedValue = arrayExpected[i];\n+            var actualValue = arrayActual[i];\n+            if (Math.abs(expectedValue - actualValue) > delta) {\n+                throw new HatAssertionError(\"Expected: \" + expectedValue + \" != actual: \" + actualValue);\n+            }\n+        }\n+    }\n+\n","filename":"hat\/tests\/src\/main\/java\/hat\/test\/engine\/HatAsserts.java","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"}]}