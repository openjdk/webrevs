{"files":[{"patch":"@@ -50,0 +50,4 @@\n+            ${CUDA_BACKEND}\/cpp\/cuda_backend_buffer.cpp\n+            ${CUDA_BACKEND}\/cpp\/cuda_backend_kernel.cpp\n+            ${CUDA_BACKEND}\/cpp\/cuda_backend_module.cpp\n+            ${CUDA_BACKEND}\/cpp\/cuda_backend_queue.cpp\n@@ -61,0 +65,10 @@\n+    add_executable(cuda_squares\n+            ${CUDA_BACKEND}\/cpp\/squares.cpp\n+    )\n+\n+    target_link_libraries(cuda_squares\n+            cuda_backend\n+            -lcudart\n+            -lcuda\n+    )\n+\n","filename":"hat\/backends\/ffi\/cuda\/CMakeLists.txt","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -42,0 +42,34 @@\n+void Text::write(std::string &filename) const{\n+    std::ofstream out;\n+    out.open(filename, std::ofstream::trunc);\n+    out.write(text, len);\n+    out.close();\n+}\n+void Text::read(std::string &filename){\n+    if (isCopy && text){\n+        delete[] text;\n+    }\n+    text = nullptr;\n+    isCopy=false;\n+    \/\/ std::cout << \"reading from \" << filename << std::endl;\n+\n+    std::ifstream ptxStream;\n+    ptxStream.open(filename);\n+\n+\n+    ptxStream.seekg(0, std::ios::end);\n+    len = ptxStream.tellg();\n+    ptxStream.seekg(0, std::ios::beg);\n+\n+    if (len > 0) {\n+        text = new char[len];\n+        isCopy = true;\n+        \/\/std::cerr << \"about to read  \" << len << std::endl;\n+        ptxStream.read(text, len);\n+        ptxStream.close();\n+        \/\/std::cerr << \"read  \" << len << std::endl;\n+        text[len - 1] = '\\0';\n+        \/\/std::cerr << \"read text \" << text << std::endl;\n+    }\n+}\n+\n@@ -66,0 +100,2 @@\n+CudaSource::CudaSource(size_t len, char *text, bool isCopy)\n+   :Text(len, text, isCopy){\n@@ -67,0 +103,4 @@\n+}\n+CudaSource::CudaSource()\n+        : Text(0) {\n+}\n@@ -78,0 +118,6 @@\n+std::string tmpFileName(uint64_t time, const std::string& suffix){\n+    std::stringstream timestamp;\n+    timestamp << \".\/tmp\" << time << suffix;\n+    return timestamp.str();\n+}\n+\n@@ -79,1 +125,2 @@\n-    PtxSource *ptx = nullptr;\n+    CudaSource cSource(len,(char*)cudaSource,false);\n+\n@@ -81,4 +128,2 @@\n-    std::stringstream timestampPtx;\n-    timestampPtx << \".\/tmp\" << time << \".ptx\";\n-    const char *ptxPath = strdup(timestampPtx.str().c_str());\n-   \/\/ std::cout << \"ptx \" << ptxPath << std::endl;\n+    std::string ptxPath = tmpFileName(time, \".ptx\");\n+    std::string cudaPath = tmpFileName(time, \".cu\");\n@@ -87,0 +132,1 @@\n+    cSource.write(cudaPath);\n@@ -88,15 +134,7 @@\n-        std::ofstream cuda;\n-        std::stringstream timestampCuda;\n-        timestampCuda << \".\/tmp\" << time << \".cu\";\n-        const char *cudaPath = strdup(timestampCuda.str().c_str());\n-        std::cout << \"cuda \" << cudaPath << std::endl;\n-        cuda.open(cudaPath, std::ofstream::trunc);\n-        cuda.write(cudaSource, len);\n-        cuda.close();\n-        const char *path = \"\/usr\/bin\/nvcc\";\n-        \/\/const char *path = \"\/usr\/local\/cuda-12.2\/bin\/nvcc\";\n-        const char *argv[]{\"nvcc\", \"-ptx\", cudaPath, \"-o\", ptxPath, nullptr};\n-        \/\/ we can't free cudaPath or ptxpath in child because we need them in exec, no prob through\n-        \/\/ because we get a new proc so they are released to os\n-        execvp(path, (char *const *) argv);\n-\n+        const char *path = \"\/usr\/local\/cuda-12.2\/bin\/nvcc\";\n+        const char *argv[]{\"nvcc\", \"-ptx\", cudaPath.c_str(), \"-o\", ptxPath.c_str(), nullptr};\n+       \/\/ std::cerr << \"child about to exec nvcc\" << std::endl;\n+       \/\/ std::cerr << \"path \" << path<< \" \" << argv[1]<< \" \" << argv[2]<< \" \" << argv[3]<< \" \" << argv[4]<< std::endl;\n+        int stat = execvp(path, (char *const *) argv);\n+        std::cerr << \" nvcc stat = \"<<stat << \" errno=\"<< errno<< \" '\"<< std::strerror(errno)<< \"'\"<<std::endl;\n+        std::exit(errno);\n@@ -109,1 +147,1 @@\n-     \/\/   std::cerr << \"fork suceeded waiting for child\" << std::endl;\n+       \/\/ std::cerr << \"parent waiting for child nvcc exec\" << std::endl;\n@@ -111,214 +149,4 @@\n-        std::cerr << \"child finished\" << std::endl;\n-        std::ifstream ptxStream;\n-        ptxStream.open(ptxPath);\n-      \/\/  if (ptxStream.is_open()) {\n-            ptxStream.seekg(0, std::ios::end);\n-            size_t ptxLen = ptxStream.tellg();\n-            ptxStream.close();\n-            ptxStream.open(ptxPath);\n-            free((void *) ptxPath);\n-            ptxPath = nullptr;\n-            if (ptxLen > 0) {\n-                std::cerr << \"ptx len \"<< ptxLen << std::endl;\n-                ptx = new PtxSource(ptxLen + 1);\n-                std::cerr << \"about to read  \"<< ptx->len << std::endl;\n-                ptxStream.read(ptx->text, ptx->len);\n-                ptxStream.close();\n-                std::cerr << \"about to read  \"<< ptx->len << std::endl;\n-                ptx->text[ptx->len - 1] = '\\0';\n-                std::cerr << \"read text \"<< ptx->text << std::endl;\n-\n-            } else {\n-                std::cerr << \"no ptx! ptxLen == 0?\";\n-                exit(1);\n-            }\n-      \/\/  }else{\n-        \/\/    std::cerr << \"no ptx!\";\n-       \/\/     exit(1);\n-      \/\/  }\n-    }\n-    std::cout << \"returning PTX\" << std::endl;\n-    return ptx;\n-}\n-\n-\/*\n-\/\/http:\/\/mercury.pr.erau.edu\/~siewerts\/extra\/code\/digital-media\/CUDA\/cuda_work\/samples\/0_Simple\/matrixMulDrv\/matrixMulDrv.cpp\n- *\/\n-CudaBackend::CudaBuffer::CudaBuffer(Backend *backend, Arg_s *arg, BufferState_s *bufferState)\n-        : Buffer(backend, arg,bufferState), devicePtr() {\n-    \/*\n-     *   (void *) arg->value.buffer.memorySegment,\n-     *   (size_t) arg->value.buffer.sizeInBytes);\n-     *\/\n-  \/\/  std::cout << \"cuMemAlloc()\" << std::endl;\n-    CUresult status = cuMemAlloc(&devicePtr, (size_t) arg->value.buffer.sizeInBytes);\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cuMemFree() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n-  \/\/  std::cout << \"devptr \" << std::hex<<  (long)devicePtr <<std::dec <<std::endl;\n-  bufferState->vendorPtr= static_cast<void *>(this);\n-}\n-\n-CudaBackend::CudaBuffer::~CudaBuffer() {\n-\n- \/\/   std::cout << \"cuMemFree()\"\n-  \/\/          << \"devptr \" << std::hex<<  (long)devicePtr <<std::dec\n-   \/\/         << std::endl;\n-    CUresult  status = cuMemFree(devicePtr);\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cuMemFree() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n-    bufferState->vendorPtr= nullptr;\n-}\n-\n-void CudaBackend::CudaBuffer::copyToDevice() {\n-    auto cudaBackend = dynamic_cast<CudaBackend*>(backend);\n- \/\/   std::cout << \"copyToDevice() 0x\"   << std::hex<<arg->value.buffer.sizeInBytes<<std::dec << \" \"<< arg->value.buffer.sizeInBytes << \" \"\n- \/\/             << \"devptr \" << std::hex<<  (long)devicePtr <<std::dec\n- \/\/             << std::endl;\n-    char *ptr = (char*)arg->value.buffer.memorySegment;\n-\n-    CUresult status = cuMemcpyHtoDAsync(devicePtr, arg->value.buffer.memorySegment, arg->value.buffer.sizeInBytes,cudaBackend->cudaQueue.cudaStream);\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cuMemcpyHtoDAsync() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n-    status = static_cast<CUresult >(cudaStreamSynchronize(cudaBackend->cudaQueue.cudaStream));\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n-}\n-\n-void CudaBackend::CudaBuffer::copyFromDevice() {\n-    auto cudaBackend = dynamic_cast<CudaBackend*>(backend);\n-  \/\/  auto cudaKernel = dynamic_cast<CudaKernel*>(kernel);\n- \/\/   std::cout << \"copyFromDevice() 0x\" << std::hex<<arg->value.buffer.sizeInBytes<<std::dec << \" \"<< arg->value.buffer.sizeInBytes << \" \"\n- \/\/             << \"devptr \" << std::hex<<  (long)devicePtr <<std::dec\n-  \/\/            << std::endl;\n-    char *ptr = (char*)arg->value.buffer.memorySegment;\n-\n-    CUresult status =cuMemcpyDtoHAsync(arg->value.buffer.memorySegment, devicePtr, arg->value.buffer.sizeInBytes,cudaBackend->cudaQueue.cudaStream);\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n-    cudaError_t t1 = cudaStreamSynchronize(cudaBackend->cudaQueue.cudaStream);\n-    if (static_cast<cudaError_t>(CUDA_SUCCESS) != t1) {\n-        std::cerr << \"CUDA error = \" << t1\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(t1))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n-\n-}\n-\n-CudaBackend::CudaModule::CudaKernel::CudaKernel(Backend::CompilationUnit *program,char * name, CUfunction function)\n-        : Backend::CompilationUnit::Kernel(program, name), function(function) {\n-}\n-\n-CudaBackend::CudaModule::CudaKernel::~CudaKernel() = default;\n-\n-long CudaBackend::CudaModule::CudaKernel::ndrange(void *argArray) {\n-  \/\/  std::cout << \"ndrange(\" << range << \") \" << name << std::endl;\n-    auto cudaBackend = dynamic_cast<CudaBackend*>(compilationUnit->backend);\n-\n-    ArgSled argSled(static_cast<ArgArray_s *>(argArray));\n- \/\/   Schema::dumpSled(std::cout, argArray);\n-    void *argslist[argSled.argc()];\n-    NDRange *ndrange = nullptr;\n-#ifdef VERBOSE\n-    std::cerr << \"there are \" << argSled.argc() << \"args \" << std::endl;\n-#endif\n-    for (int i = 0; i < argSled.argc(); i++) {\n-        Arg_s *arg = argSled.arg(i);\n-        switch (arg->variant) {\n-            case '&': {\n-                if (arg->idx == 0){\n-                    ndrange = static_cast<NDRange *>(arg->value.buffer.memorySegment);\n-                }\n-                auto cudaBuffer = new CudaBackend::CudaBuffer(cudaBackend, arg, BufferState_s::of(arg));\n-                cudaBuffer->copyToDevice();\n-                argslist[arg->idx] = static_cast<void *>(&cudaBuffer->devicePtr);\n-                break;\n-            }\n-            case 'I':\n-            case 'F':\n-            case 'J':\n-            case 'D':\n-            case 'C':\n-            case 'S': {\n-                argslist[arg->idx] = static_cast<void *>(&arg->value);\n-                break;\n-            }\n-            default: {\n-                std::cerr << \" unhandled variant \" << (char) arg->variant << std::endl;\n-                break;\n-            }\n-        }\n-    }\n-\n-    int range = ndrange->maxX;\n-    int rangediv1024 = range \/ 1024;\n-    int rangemod1024 = range % 1024;\n-    if (rangemod1024 > 0) {\n-        rangediv1024++;\n-    }\n-   \/\/ std::cout << \"Running the kernel...\" << std::endl;\n-  \/\/  std::cout << \"   Requested range   = \" << range << std::endl;\n-  \/\/  std::cout << \"   Range mod 1024    = \" << rangemod1024 << std::endl;\n-   \/\/ std::cout << \"   Actual range 1024 = \" << (rangediv1024 * 1024) << std::endl;\n-    auto status= static_cast<CUresult>(cudaStreamSynchronize(cudaBackend->cudaQueue.cudaStream));\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n-\n-    status= cuLaunchKernel(function,\n-                                   rangediv1024, 1, 1,\n-                                   1024, 1, 1,\n-                                   0, cudaBackend->cudaQueue.cudaStream,\n-                    argslist, 0);\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cuLaunchKernel() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n-    status= static_cast<CUresult>(cudaStreamSynchronize(cudaBackend->cudaQueue.cudaStream));\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n-\n-    \/\/std::cout << \"Kernel complete...\"<<cudaGetErrorString(t)<<std::endl;\n-\n-    for (int i = 0; i < argSled.argc(); i++) {\n-        Arg_s *arg = argSled.arg(i);\n-        if (arg->variant == '&') {\n-            static_cast<CudaBuffer *>(BufferState_s::of(arg)->vendorPtr)->copyFromDevice();\n-\n-        }\n-    }\n-    status=   static_cast<CUresult>(cudaStreamSynchronize(cudaBackend->cudaQueue.cudaStream));\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n+        \/\/std::cerr << \"child finished should be safe to read \"<< ptxPath << std::endl;\n+        PtxSource *ptx= new PtxSource();\n+        ptx->read(ptxPath);\n+        return ptx;\n@@ -326,16 +154,3 @@\n-\n-    for (int i = 0; i < argSled.argc(); i++) {\n-        Arg_s *arg = argSled.arg(i);\n-        if (arg->variant == '&') {\n-            delete static_cast<CudaBuffer *>(BufferState_s::of(arg)->vendorPtr);\n-            BufferState_s::of(arg)->vendorPtr = nullptr;\n-\n-        }\n-    }\n-   \/\/ cudaStreamDestroy(cudaStream);\n-    return (long) 0;\n-}\n-\n-\n-CudaBackend::CudaModule::CudaModule(Backend *backend, char *src, char  *log,  bool ok, CUmodule module)\n-        : Backend::CompilationUnit(backend, src, log, ok), cudaSource(src), ptxSource(),log(log), module(module) {\n+    std::cerr << \"we should never get here !\";\n+    exit(1);\n+    return nullptr;\n@@ -344,18 +159,0 @@\n-CudaBackend::CudaModule::~CudaModule() = default;\n-\n-long CudaBackend::CudaModule::getKernel(int nameLen, char *name) {\n-    CUfunction function;\n-    CUresult status= cuModuleGetFunction(&function, module, name);\n-    if (CUDA_SUCCESS != status) {\n-        std::cerr << \"cuModuleGetFunction() CUDA error = \" << status\n-                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n-                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n-        exit(-1);\n-    }\n-    long kernelHandle =  reinterpret_cast<long>(new CudaKernel(this, name, function));\n-    return kernelHandle;\n-}\n-\n-bool CudaBackend::CudaModule::programOK() {\n-    return true;\n-}\n@@ -368,8 +165,33 @@\n-    CUresult err = cuInit(0);\n-    if (err == CUDA_SUCCESS) {\n-        cuDeviceGetCount(&deviceCount);\n-        std::cout << \"CudaBackend device count\" << std::endl;\n-        cuDeviceGet(&device, 0);\n-        std::cout << \"CudaBackend device ok\" << std::endl;\n-        cuCtxCreate(&context, 0, device);\n-        std::cout << \"CudaBackend context created ok\" << std::endl;\n+    CUresult status = cuInit(0);\n+    if (status == CUDA_SUCCESS) {\n+        status  = cuDeviceGetCount(&deviceCount);\n+        if (status != CUDA_SUCCESS) {\n+            std::cerr\n+                    << \"cuDeviceGetCount() failed we seem to have the runtime library but no device, CUDA error = \"\n+                    << status\n+                    << \" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                    << \" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+            exit(-1);\n+        }\n+        std::cout << \"CudaBackend device count = \"<< deviceCount << std::endl;\n+        status= cuDeviceGet(&device, 0);\n+        if (status != CUDA_SUCCESS) {\n+            std::cerr\n+                    << \"cuDeviceGet() failed we seem to have the runtime library but no device, CUDA error = \"\n+                    << status\n+                    << \" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                    << \" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+            exit(-1);\n+        }\n+        std::cout << \"CudaBackend device ok (id = \"<<device<<\")\" << std::endl;\n+\n+        status = cuCtxCreate(&context, 0, device);\n+        if (status != CUDA_SUCCESS) {\n+            std::cerr\n+                    << \"cuCtxCreate() failed we seem to have the runtime library found a device, but cant create context, CUDA error = \"\n+                    << status\n+                    << \" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                    << \" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+            exit(-1);\n+        }\n+        std::cout << \"CudaBackend context created ok (id=\"<<context<<\")\" << std::endl;\n@@ -377,3 +199,4 @@\n-        std::cout << \"CudaBackend failed, we seem to have the runtime library but no device, no context, nada \"\n-                  << std::endl;\n-        exit(1);\n+        std::cerr << \"cuInit() failed we seem to have the runtime library but no device, no context, nada CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n@@ -429,0 +252,74 @@\n+PtxSource *CudaBackend::nvcc(CudaSource *cudaSource){\n+    uint64_t time = timeSinceEpochMillisec();\n+    std::string ptxPath = tmpFileName(time, \".ptx\");\n+    std::string cudaPath = tmpFileName(time, \".cu\");\n+    \/\/ we are going to fork exec nvcc so we need to write the cuda source to disk\n+    int pid;\n+    cudaSource->write(cudaPath);\n+    if ((pid = fork()) == 0) {\n+        const char *path = \"\/usr\/local\/cuda-12.2\/bin\/nvcc\";\n+        const char *argv[]{\"nvcc\", \"-ptx\", cudaPath.c_str(), \"-o\", ptxPath.c_str(), nullptr};\n+        \/\/ std::cerr << \"child about to exec nvcc\" << std::endl;\n+        \/\/ std::cerr << \"path \" << path<< \" \" << argv[1]<< \" \" << argv[2]<< \" \" << argv[3]<< \" \" << argv[4]<< std::endl;\n+        int stat = execvp(path, (char *const *) argv);\n+        std::cerr << \" nvcc stat = \"<<stat << \" errno=\"<< errno<< \" '\"<< std::strerror(errno)<< \"'\"<<std::endl;\n+        std::exit(errno);\n+    } else if (pid < 0) {\n+        \/\/ fork failed.\n+        std::cerr << \"fork of nvcc failed\" << std::endl;\n+        std::exit(1);\n+    } else {\n+        int status;\n+        \/\/ std::cerr << \"parent waiting for child nvcc exec\" << std::endl;\n+        pid_t result = wait(&status);\n+        \/\/std::cerr << \"child finished should be safe to read \"<< ptxPath << std::endl;\n+        PtxSource *ptx= new PtxSource();\n+        ptx->read(ptxPath);\n+        return ptx;\n+    }\n+    std::cerr << \"we should never get here !\";\n+    exit(1);\n+    return nullptr;\n+\n+}\n+CudaBackend::CudaModule * CudaBackend::compile(CudaSource &cudaSource) {\n+    return compile(&cudaSource);\n+}\n+CudaBackend::CudaModule * CudaBackend::compile(CudaSource *cudaSource) {\n+    PtxSource *ptx = nvcc(cudaSource);\n+    CUmodule module;\n+    std::cout << \"inside compile\" << std::endl;\n+    std::cout << \"cuda \" << cudaSource->text << std::endl;\n+    if (ptx->text != nullptr) {\n+        std::cout << \"ptx \" << ptx->text << std::endl;\n+        Log *infLog = new Log(8192);\n+        Log *errLog = new Log(8192);\n+        const unsigned int optc = 5;\n+        auto jitOptions = new CUjit_option[optc];\n+        void **jitOptVals = new void *[optc];\n+\n+\n+        jitOptions[0] = CU_JIT_INFO_LOG_BUFFER_SIZE_BYTES;jitOptVals[0] = (void *) (size_t) infLog->len;\n+        jitOptions[1] = CU_JIT_INFO_LOG_BUFFER; jitOptVals[1] = infLog->text;\n+        jitOptions[2] = CU_JIT_ERROR_LOG_BUFFER_SIZE_BYTES;jitOptVals[2] = (void *) (size_t) errLog->len;\n+        jitOptions[3] = CU_JIT_ERROR_LOG_BUFFER; jitOptVals[3] = errLog->text;\n+        jitOptions[4] = CU_JIT_GENERATE_LINE_INFO;jitOptVals[4] = (void *)1;\n+        int status = cuModuleLoadDataEx(&module, ptx->text,\n+                                        optc, jitOptions, (void **) jitOptVals);\n+        if (CUDA_SUCCESS != status) {\n+            std::cerr << \"cuModuleLoadDataEx() CUDA error = \" << status\n+                      <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                      <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+            exit(-1);\n+        }\n+        std::cout <<\"> PTX JIT inflog:\"<<std::endl  << infLog->text << std::endl;\n+        std::cout <<\"> PTX JIT errlog:\"<<std::endl  << errLog->text << std::endl;\n+        return new CudaModule(this,  ptx->text,infLog->text,true, module);\n+\n+        \/\/delete ptx;\n+    } else {\n+        std::cout << \"no ptx content!\" << std::endl;\n+        exit(1);\n+    }\n+}\n+\n@@ -452,1 +349,6 @@\n-\n+        if (CUDA_SUCCESS != status) {\n+            std::cerr << \"cuModuleLoadDataEx() CUDA error = \" << status\n+                      <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                      <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+            exit(-1);\n+        }\n@@ -462,2 +364,1 @@\n-\n-long getCudaBackend(int mode) {\n+extern \"C\" long getCudaBackend(int mode) {\n@@ -469,19 +370,0 @@\n-CudaBackend::CudaQueue::CudaQueue(Backend *backend)\n-        : Backend::Queue(backend){\n-        cudaStreamCreate(&cudaStream);\n-    }\n-\n-\n-\n-void CudaBackend::CudaQueue::showEvents(int width) {\n-\n-}\n-void CudaBackend::CudaQueue::wait(){\n-    if (eventc > 0){\n-      \/\/  cl_int status = clWaitForEvents(eventc, events);\n-      \/\/  if (status != CL_SUCCESS) {\n-          \/\/  std::cerr << \"failed clWaitForEvents\" << CudaBackend::errorMsg(status) << std::endl;\n-           \/\/ exit(1);\n-       \/\/ }\n-    }\n-}\n@@ -492,71 +374,0 @@\n-void CudaBackend::CudaQueue::marker(int bits){\n-   \/\/ cl_int status = clEnqueueMarkerWithWaitList(\n-          \/\/  command_queue,\n-           \/\/ this->eventc, this->eventListPtr(),this->nextEventPtr()\n-   \/\/ );\n-   \/\/ if (status != CL_SUCCESS){\n-     \/\/   std::cerr << \"failed to clEnqueueMarkerWithWaitList \"<<errorMsg(status)<< std::endl;\n-     \/\/   std::exit(1);\n-  \/\/  }\n-   \/\/ inc(bits);\n-}\n-void CudaBackend::CudaQueue::marker(int bits, const char* arg){\n-   \/\/ cl_int status = clEnqueueMarkerWithWaitList(\n-          \/\/  command_queue,\n-          \/\/  this->eventc, this->eventListPtr(),this->nextEventPtr()\n-  \/\/  );\n-   \/\/ if (status != CL_SUCCESS){\n-     \/\/   std::cerr << \"failed to clEnqueueMarkerWithWaitList \"<<errorMsg(status)<< std::endl;\n-      \/\/  std::exit(1);\n-   \/\/ }\n-   \/\/ inc(bits, arg);\n-}\n-void CudaBackend::CudaQueue::marker(int bits, int arg){\n-    \/\/cl_int status = clEnqueueMarkerWithWaitList(\n-          \/\/  command_queue,\n-        \/\/    this->eventc, this->eventListPtr(),this->nextEventPtr()\n-  \/\/  );\n-   \/\/ if (status != CL_SUCCESS){\n-    \/\/    std::cerr << \"failed to clEnqueueMarkerWithWaitList \"<<errorMsg(status)<< std::endl;\n-    \/\/    std::exit(1);\n-  \/\/  }\n- \/\/   inc(bits, arg);\n-}\n-\n-void CudaBackend::CudaQueue::computeStart(){\n-    wait(); \/\/ should be no-op\n-    release(); \/\/ also ;\n-    marker(StartComputeBits);\n-}\n-\n-\n-\n-void CudaBackend::CudaQueue::computeEnd(){\n-    marker(EndComputeBits);\n-}\n-\n-void CudaBackend::CudaQueue::inc(int bits){\n-    if (eventc+1 >= eventMax){\n-        std::cerr << \"CudaBackend::CudaQueue event list overflowed!!\" << std::endl;\n-    }else{\n-        eventInfoBits[eventc]=bits;\n-    }\n-    eventc++;\n-}\n-void CudaBackend::CudaQueue::inc(int bits, const char *arg){\n-    if (eventc+1 >= eventMax){\n-        std::cerr << \"CudaBackend::CudaQueue event list overflowed!!\" << std::endl;\n-    }else{\n-        eventInfoBits[eventc]=bits|HasConstCharPtrArgBits;\n-        eventInfoConstCharPtrArgs[eventc]=arg;\n-    }\n-    eventc++;\n-}\n-void CudaBackend::CudaQueue::inc(int bits, int arg){\n-    if (eventc+1 >= eventMax){\n-        std::cerr << \"CudaBackend::CudaQueue event list overflowed!!\" << std::endl;\n-    }else{\n-        eventInfoBits[eventc]=bits|arg|hasIntArgBits;\n-    }\n-    eventc++;\n-}\n@@ -564,39 +375,0 @@\n-void CudaBackend::CudaQueue::markAsEndComputeAndInc(){\n-    inc(EndComputeBits);\n-}\n-void CudaBackend::CudaQueue::markAsStartComputeAndInc(){\n-    inc(StartComputeBits);\n-}\n-void CudaBackend::CudaQueue::markAsNDRangeAndInc(){\n-    inc(NDRangeBits);\n-}\n-void CudaBackend::CudaQueue::markAsCopyToDeviceAndInc(int argn){\n-    inc(CopyToDeviceBits, argn);\n-}\n-void CudaBackend::CudaQueue::markAsCopyFromDeviceAndInc(int argn){\n-    inc(CopyFromDeviceBits, argn);\n-}\n-void CudaBackend::CudaQueue::markAsEnterKernelDispatchAndInc(){\n-    inc(EnterKernelDispatchBits);\n-}\n-void CudaBackend::CudaQueue::markAsLeaveKernelDispatchAndInc(){\n-    inc(LeaveKernelDispatchBits);\n-}\n-\n-void CudaBackend::CudaQueue::release(){\n-   \/\/ cl_int status = CL_SUCCESS;\n-  \/\/  for (int i = 0; i < eventc; i++) {\n-   \/\/     status = clReleaseEvent(events[i]);\n-    \/\/    if (status != CL_SUCCESS) {\n-      \/\/      std::cerr << CudaBackend::errorMsg(status) << std::endl;\n-      \/\/      exit(1);\n-   \/\/     }\n-   \/\/ }\/\/\n- \/\/   eventc = 0;\n-}\n-\n-CudaBackend::CudaQueue::~CudaQueue(){\n-   \/\/ clReleaseCommandQueue(command_queue);\n-   \/\/ delete []events;\n-\n-}\n@@ -616,0 +388,7 @@\n+}\n+\n+CudaBackend * CudaBackend::of(long backendHandle){\n+    return reinterpret_cast<CudaBackend *>(backendHandle);\n+}\n+CudaBackend * CudaBackend::of(Backend *backend){\n+    return dynamic_cast<CudaBackend *>(backend);\n","filename":"hat\/backends\/ffi\/cuda\/cpp\/cuda_backend.cpp","additions":191,"deletions":412,"binary":false,"changes":603,"status":"modified"},{"patch":"@@ -0,0 +1,115 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include <sys\/wait.h>\n+#include <chrono>\n+#include \"cuda_backend.h\"\n+\n+\/*\n+\/\/http:\/\/mercury.pr.erau.edu\/~siewerts\/extra\/code\/digital-media\/CUDA\/cuda_work\/samples\/0_Simple\/matrixMulDrv\/matrixMulDrv.cpp\n+ *\/\n+CudaBackend::CudaBuffer::CudaBuffer(Backend *backend, Arg_s *arg, BufferState_s *bufferState)\n+        : Buffer(backend, arg,bufferState), devicePtr() {\n+    \/*\n+     *   (void *) arg->value.buffer.memorySegment,\n+     *   (size_t) arg->value.buffer.sizeInBytes);\n+     *\/\n+    std::cout << \"cuMemAlloc()\" << std::endl;\n+    CUresult status = cuMemAlloc(&devicePtr, (size_t) arg->value.buffer.sizeInBytes);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuMemFree() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+    std::cout << \"devptr \" << std::hex<<  (long)devicePtr <<std::dec <<std::endl;\n+  bufferState->vendorPtr= static_cast<void *>(this);\n+}\n+\n+CudaBackend::CudaBuffer::~CudaBuffer() {\n+\n+    std::cout << \"cuMemFree()\"\n+            << \"devptr \" << std::hex<<  (long)devicePtr <<std::dec\n+            << std::endl;\n+    CUresult  status = cuMemFree(devicePtr);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuMemFree() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+    bufferState->vendorPtr= nullptr;\n+}\n+\n+void CudaBackend::CudaBuffer::copyToDevice() {\n+    auto cudaBackend = dynamic_cast<CudaBackend*>(backend);\n+    if (cudaBackend->cudaConfig.traceCalls) {\n+        std::cout << \"copyToDevice() 0x\" << std::hex << arg->value.buffer.sizeInBytes << std::dec << \" \"\n+                  << arg->value.buffer.sizeInBytes << \" \"\n+                  << \"devptr \" << std::hex << (long) devicePtr << std::dec\n+                  << std::endl;\n+    }\n+\n+\n+    CUresult status = cuMemcpyHtoDAsync(devicePtr, arg->value.buffer.memorySegment, arg->value.buffer.sizeInBytes,cudaBackend->cudaQueue.cudaStream);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuMemcpyHtoDAsync() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+    status = static_cast<CUresult >(cudaStreamSynchronize(cudaBackend->cudaQueue.cudaStream));\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+}\n+\n+void CudaBackend::CudaBuffer::copyFromDevice() {\n+    auto cudaBackend = dynamic_cast<CudaBackend*>(backend);\n+    if (cudaBackend->cudaConfig.traceCalls) {\n+        std::cout << \"copyFromDevice() 0x\" << std::hex<<arg->value.buffer.sizeInBytes<<std::dec << \" \"<< arg->value.buffer.sizeInBytes << \" \"\n+                     << \"devptr \" << std::hex<<  (long)devicePtr <<std::dec\n+                    << std::endl;\n+    }\n+    CUresult status =cuMemcpyDtoHAsync(arg->value.buffer.memorySegment, devicePtr, arg->value.buffer.sizeInBytes,cudaBackend->cudaQueue.cudaStream);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuMemcpyDtoHAsync() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+    cudaError_t t1 = cudaStreamSynchronize(cudaBackend->cudaQueue.cudaStream);\n+    if (static_cast<cudaError_t>(CUDA_SUCCESS) != t1) {\n+        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << t1\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(t1))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+\n+}\n+\n","filename":"hat\/backends\/ffi\/cuda\/cpp\/cuda_backend_buffer.cpp","additions":115,"deletions":0,"binary":false,"changes":115,"status":"added"},{"patch":"@@ -0,0 +1,161 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include <sys\/wait.h>\n+#include <chrono>\n+#include \"cuda_backend.h\"\n+\n+\n+CudaBackend::CudaModule::CudaKernel::CudaKernel(Backend::CompilationUnit *program,char * name, CUfunction function)\n+        : Backend::CompilationUnit::Kernel(program, name), function(function) {\n+}\n+\n+CudaBackend::CudaModule::CudaKernel::~CudaKernel() = default;\n+\n+long CudaBackend::CudaModule::CudaKernel::ndrange(void *argArray) {\n+\n+    auto cudaBackend = CudaBackend::of(compilationUnit->backend);\n+    if (cudaBackend->cudaConfig.traceCalls) {\n+        std::cout << \"ndrange(\" <<  \") \" << name << std::endl;\n+    }\n+    ArgSled argSled(static_cast<ArgArray_s *>(argArray));\n+  \/\/  Schema::dumpSled(std::cout, argArray);\n+    void *argslist[argSled.argc()];\n+\n+    NDRange *ndrange = nullptr;\n+#ifdef VERBOSE\n+    std::cerr << \"there are \" << argSled.argc() << \"args \" << std::endl;\n+#endif\n+    for (int i = 0; i < argSled.argc(); i++) {\n+        Arg_s *arg = argSled.arg(i);\n+        switch (arg->variant) {\n+            case '&': {\n+                if (arg->idx == 0){\n+                    ndrange = static_cast<NDRange *>(arg->value.buffer.memorySegment);\n+                }\n+                auto cudaBuffer = new CudaBackend::CudaBuffer(cudaBackend, arg, BufferState_s::of(arg));\n+                cudaBuffer->copyToDevice();\n+                argslist[arg->idx] = static_cast<void *>(&cudaBuffer->devicePtr);\n+                break;\n+            }\n+            case 'I':\n+            case 'F':\n+            case 'J':\n+            case 'D':\n+            case 'C':\n+            case 'S': {\n+                argslist[arg->idx] = static_cast<void *>(&arg->value);\n+                break;\n+            }\n+            default: {\n+                std::cerr << \" unhandled variant \" << (char) arg->variant << std::endl;\n+                break;\n+            }\n+        }\n+    }\n+    \/\/argslist[argSled.argc()]= nullptr;\n+    int range = ndrange->maxX;\n+    int rangediv1024 = range \/ 1024;\n+    int rangemod1024 = range % 1024;\n+    if (rangemod1024 > 0) {\n+        rangediv1024++;\n+    }\n+    std::cout << \"Running the kernel...\" << std::endl;\n+    std::cout << \"   Requested range   = \" << range << std::endl;\n+    std::cout << \"   Range mod 1024    = \" << rangemod1024 << std::endl;\n+    std::cout << \"   Actual range 1024 = \" << (rangediv1024 * 1024) << std::endl;\n+    auto status= static_cast<CUresult>(cudaStreamSynchronize(cudaBackend->cudaQueue.cudaStream));\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+\n+    status = cuCtxSetCurrent(cudaBackend->context);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuCtxSetCurrent() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+    std::cout <<\" function\/kernel id= \" << function << \" stream = \" << cudaBackend->cudaQueue.cudaStream<<std::endl;\n+    status= cuLaunchKernel(function,\n+                                   rangediv1024, 1, 1,\n+                                   1024, 1, 1,\n+                                   0, nullptr \/*cudaBackend->cudaQueue.cudaStream *\/,\n+                    argslist, nullptr);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuLaunchKernel() CUDA error = \" << status\n+\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+    status= static_cast<CUresult>(cudaStreamSynchronize(cudaBackend->cudaQueue.cudaStream));\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+\n+    std::cout << \"Kernel complete...\"<<cudaGetErrorString(static_cast<cudaError_t>(status))<<std::endl;\n+\n+    for (int i = 0; i < argSled.argc(); i++) {\n+        Arg_s *arg = argSled.arg(i);\n+        if (arg->variant == '&') {\n+            auto bufferState = BufferState_s::of(arg)->vendorPtr;\n+            auto cudaBuffer = static_cast<CudaBuffer *>(bufferState);\n+            cudaBuffer->copyFromDevice();\n+        }\n+    }\n+    status=   static_cast<CUresult>(cudaStreamSynchronize(cudaBackend->cudaQueue.cudaStream));\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cudaStreamSynchronize() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+\n+    for (int i = 0; i < argSled.argc(); i++) {\n+        Arg_s *arg = argSled.arg(i);\n+        if (arg->variant == '&') {\n+            \/\/auto bufferState = BufferState_s::of(arg)->vendorPtr;\n+            \/\/auto cudaBuffer = static_cast<CudaBuffer *>(bufferState);\n+            \/\/delete cudaBuffer;\n+\n+        }\n+    }\n+\n+    return (long) 0;\n+}\n+\n+CudaBackend::CudaModule::CudaKernel * CudaBackend::CudaModule::CudaKernel::of(long kernelHandle){\n+    return reinterpret_cast<CudaBackend::CudaModule::CudaKernel *>(kernelHandle);\n+}\n+CudaBackend::CudaModule::CudaKernel * CudaBackend::CudaModule::CudaKernel::of(Backend::CompilationUnit::Kernel *kernel){\n+    return dynamic_cast<CudaBackend::CudaModule::CudaKernel *>(kernel);\n+}\n\\ No newline at end of file\n","filename":"hat\/backends\/ffi\/cuda\/cpp\/cuda_backend_kernel.cpp","additions":161,"deletions":0,"binary":false,"changes":161,"status":"added"},{"patch":"@@ -0,0 +1,62 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include <sys\/wait.h>\n+#include <chrono>\n+#include \"cuda_backend.h\"\n+\n+\n+CudaBackend::CudaModule::CudaModule(Backend *backend, char *src, char  *log,  bool ok, CUmodule module)\n+        : Backend::CompilationUnit(backend, src, log, ok), cudaSource(src), ptxSource(),log(log), module(module) {\n+}\n+\n+CudaBackend::CudaModule::~CudaModule() = default;\n+CudaBackend::CudaModule * CudaBackend::CudaModule::of(long moduleHandle){\n+    return reinterpret_cast<CudaBackend::CudaModule *>(moduleHandle);\n+}\n+long CudaBackend::CudaModule::getKernel(int len, char *name) {\n+    CudaKernel* cudaKernel= getCudaKernel(len, name);\n+    long kernelHandle =  reinterpret_cast<long>(cudaKernel);\n+    return kernelHandle;\n+}\n+CudaBackend::CudaModule::CudaKernel *CudaBackend::CudaModule::getCudaKernel(char *name) {\n+    return getCudaKernel(std::strlen(name), name);\n+}\n+CudaBackend::CudaModule::CudaKernel *CudaBackend::CudaModule::getCudaKernel(int nameLen, char *name) {\n+    CUfunction function;\n+    CUresult status= cuModuleGetFunction(&function, module, name);\n+    if (CUDA_SUCCESS != status) {\n+        std::cerr << \"cuModuleGetFunction() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+    return new CudaKernel(this,name, function);\n+\n+}\n+\n+bool CudaBackend::CudaModule::programOK() {\n+    return true;\n+}\n","filename":"hat\/backends\/ffi\/cuda\/cpp\/cuda_backend_module.cpp","additions":62,"deletions":0,"binary":false,"changes":62,"status":"added"},{"patch":"@@ -0,0 +1,172 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include <sys\/wait.h>\n+#include <chrono>\n+#include \"cuda_backend.h\"\n+\n+CudaBackend::CudaQueue::CudaQueue(Backend *backend)\n+        : Backend::Queue(backend),cudaStream(){\n+    auto status =  cudaStreamCreate(&cudaStream);\n+    if (::cudaSuccess != status) {\n+        std::cerr << \"cudaStreamCreate() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+    }\n+\n+\n+\n+void CudaBackend::CudaQueue::showEvents(int width) {\n+\n+}\n+void CudaBackend::CudaQueue::wait(){\n+    if (eventc > 0){\n+      \/\/  cl_int status = clWaitForEvents(eventc, events);\n+      \/\/  if (status != CL_SUCCESS) {\n+          \/\/  std::cerr << \"failed clWaitForEvents\" << CudaBackend::errorMsg(status) << std::endl;\n+           \/\/ exit(1);\n+       \/\/ }\n+    }\n+}\n+\n+void CudaBackend::CudaQueue::marker(int bits){\n+   \/\/ cl_int status = clEnqueueMarkerWithWaitList(\n+          \/\/  command_queue,\n+           \/\/ this->eventc, this->eventListPtr(),this->nextEventPtr()\n+   \/\/ );\n+   \/\/ if (status != CL_SUCCESS){\n+     \/\/   std::cerr << \"failed to clEnqueueMarkerWithWaitList \"<<errorMsg(status)<< std::endl;\n+     \/\/   std::exit(1);\n+  \/\/  }\n+   \/\/ inc(bits);\n+}\n+void CudaBackend::CudaQueue::marker(int bits, const char* arg){\n+   \/\/ cl_int status = clEnqueueMarkerWithWaitList(\n+          \/\/  command_queue,\n+          \/\/  this->eventc, this->eventListPtr(),this->nextEventPtr()\n+  \/\/  );\n+   \/\/ if (status != CL_SUCCESS){\n+     \/\/   std::cerr << \"failed to clEnqueueMarkerWithWaitList \"<<errorMsg(status)<< std::endl;\n+      \/\/  std::exit(1);\n+   \/\/ }\n+   \/\/ inc(bits, arg);\n+}\n+void CudaBackend::CudaQueue::marker(int bits, int arg){\n+    \/\/cl_int status = clEnqueueMarkerWithWaitList(\n+          \/\/  command_queue,\n+        \/\/    this->eventc, this->eventListPtr(),this->nextEventPtr()\n+  \/\/  );\n+   \/\/ if (status != CL_SUCCESS){\n+    \/\/    std::cerr << \"failed to clEnqueueMarkerWithWaitList \"<<errorMsg(status)<< std::endl;\n+    \/\/    std::exit(1);\n+  \/\/  }\n+ \/\/   inc(bits, arg);\n+}\n+\n+void CudaBackend::CudaQueue::computeStart(){\n+    wait(); \/\/ should be no-op\n+    release(); \/\/ also ;\n+    marker(StartComputeBits);\n+}\n+\n+\n+\n+void CudaBackend::CudaQueue::computeEnd(){\n+    marker(EndComputeBits);\n+}\n+\n+void CudaBackend::CudaQueue::inc(int bits){\n+    if (eventc+1 >= eventMax){\n+        std::cerr << \"CudaBackend::CudaQueue event list overflowed!!\" << std::endl;\n+    }else{\n+        eventInfoBits[eventc]=bits;\n+    }\n+    eventc++;\n+}\n+void CudaBackend::CudaQueue::inc(int bits, const char *arg){\n+    if (eventc+1 >= eventMax){\n+        std::cerr << \"CudaBackend::CudaQueue event list overflowed!!\" << std::endl;\n+    }else{\n+        eventInfoBits[eventc]=bits|HasConstCharPtrArgBits;\n+        eventInfoConstCharPtrArgs[eventc]=arg;\n+    }\n+    eventc++;\n+}\n+void CudaBackend::CudaQueue::inc(int bits, int arg){\n+    if (eventc+1 >= eventMax){\n+        std::cerr << \"CudaBackend::CudaQueue event list overflowed!!\" << std::endl;\n+    }else{\n+        eventInfoBits[eventc]=bits|arg|hasIntArgBits;\n+    }\n+    eventc++;\n+}\n+\n+void CudaBackend::CudaQueue::markAsEndComputeAndInc(){\n+    inc(EndComputeBits);\n+}\n+void CudaBackend::CudaQueue::markAsStartComputeAndInc(){\n+    inc(StartComputeBits);\n+}\n+void CudaBackend::CudaQueue::markAsNDRangeAndInc(){\n+    inc(NDRangeBits);\n+}\n+void CudaBackend::CudaQueue::markAsCopyToDeviceAndInc(int argn){\n+    inc(CopyToDeviceBits, argn);\n+}\n+void CudaBackend::CudaQueue::markAsCopyFromDeviceAndInc(int argn){\n+    inc(CopyFromDeviceBits, argn);\n+}\n+void CudaBackend::CudaQueue::markAsEnterKernelDispatchAndInc(){\n+    inc(EnterKernelDispatchBits);\n+}\n+void CudaBackend::CudaQueue::markAsLeaveKernelDispatchAndInc(){\n+    inc(LeaveKernelDispatchBits);\n+}\n+\n+void CudaBackend::CudaQueue::release(){\n+   \/\/ cl_int status = CL_SUCCESS;\n+  \/\/  for (int i = 0; i < eventc; i++) {\n+   \/\/     status = clReleaseEvent(events[i]);\n+    \/\/    if (status != CL_SUCCESS) {\n+      \/\/      std::cerr << CudaBackend::errorMsg(status) << std::endl;\n+      \/\/      exit(1);\n+   \/\/     }\n+   \/\/ }\/\/\n+ \/\/   eventc = 0;\n+}\n+\n+CudaBackend::CudaQueue::~CudaQueue(){\n+   \/\/ clReleaseCommandQueue(command_queue);\n+   \/\/ delete []events;\n+   auto status = cudaStreamDestroy(cudaStream);\n+    if (::cudaSuccess != status) {\n+        std::cerr << \"cudaStreamDestroy() CUDA error = \" << status\n+                  <<\" \" << cudaGetErrorString(static_cast<cudaError_t>(status))\n+                  <<\" \" << __FILE__ << \" line \" << __LINE__ << std::endl;\n+        exit(-1);\n+    }\n+}\n","filename":"hat\/backends\/ffi\/cuda\/cpp\/cuda_backend_queue.cpp","additions":172,"deletions":0,"binary":false,"changes":172,"status":"added"},{"patch":"@@ -0,0 +1,169 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"cuda_backend.h\"\n+struct ArgArray_2 {\n+    int argc;\n+    u8_t pad12[12];\n+    Arg_s argv[2];\n+};\n+\n+struct S32Array1024_s {\n+    int length;\n+    int array[1024];\n+};\n+template<typename T>\n+T *bufferOf(const char*name){\n+    T *buffer = (T*)new unsigned char[sizeof(T) + sizeof(BufferState_s)+32];\n+    auto bs = BufferState_s::of(buffer, sizeof(T));\n+    bs->magic1 =  bs->magic2 = BufferState_s::MAGIC;\n+    bs->ptr = buffer;\n+    bs->length=sizeof(T);\n+    bs->state=BufferState_s::NEW_STATE;\n+    bs->vendorPtr = nullptr;\n+    bs->dump(name);\n+    return buffer;\n+}\n+int main(int argc, char **argv) {\n+    CudaBackend cudaBackend(0\n+            | CudaBackend::CudaConfig::Config::INFO_BIT\n+            | CudaBackend::CudaConfig::Config::TRACE_CALLS_BIT\n+            | CudaBackend::CudaConfig::Config::TRACE_COPIES_BIT\n+    );\n+\n+    \/\/std::string cudaPath =  \"\/home\/gfrost\/github\/grfrost\/babylon-grfrost-fork\/hat\/squares.cuda\";\n+    CudaSource cudaSource((char *) R\"(\n+       #define NDRANGE_CUDA\n+       #define __global\n+       typedef char s8_t;\n+       typedef char byte;\n+       typedef char boolean;\n+       typedef unsigned char u8_t;\n+       typedef short s16_t;\n+       typedef unsigned short u16_t;\n+       typedef unsigned int u32_t;\n+       typedef int s32_t;\n+       typedef float f32_t;\n+       typedef long s64_t;\n+       typedef unsigned long u64_t;\n+       typedef struct KernelContext_s{\n+         int x;\n+         int maxX;\n+       }KernelContext_t;\n+       typedef struct S32Array_s{\n+          int length;\n+          int array[1];\n+       }S32Array_t;\n+\n+       extern \"C\" __device__ inline int squareit(\n+           int v\n+       ){\n+          return v*v;\n+       }\n+\n+       extern \"C\" __global__ void squareKernel(\n+           KernelContext_t *global_kc,  S32Array_t* s32Array\n+       ){\n+         KernelContext_t mine;\n+         KernelContext_t* kc=&mine;\n+         kc->x=blockIdx.x*blockDim.x+threadIdx.x;\n+         kc->maxX=global_kc->maxX;\n+         if(kc->x<kc->maxX){\n+             int value = s32Array->array[(long)kc->x];\n+             s32Array->array[(long)kc->x]=squareit(value);\n+         }\n+         return;\n+        }\n+    )\");\n+\n+    PtxSource ptxSource((char*)R\"(\n+       \/\/ Generated by NVIDIA NVVM Compiler\n+       \/\/\n+       \/\/ Compiler Build ID: CL-33191640\n+       \/\/ Cuda compilation tools, release 12.2, V12.2.140\n+       \/\/ Based on NVVM 7.0.1\n+       \/\/\n+\n+       .version 8.2\n+       .target sm_52\n+       .address_size 64\n+\n+               \/\/ .globl        squareKernel\n+\n+       .visible .entry squareKernel(\n+               .param .u64 squareKernel_param_0,\n+               .param .u64 squareKernel_param_1\n+       )\n+       {\n+               .reg .pred           %p<2>;\n+               .reg .b32            %r<8>;\n+               .reg .b64            %rd<7>;\n+\n+\n+               ld.param.u64         %rd2, [squareKernel_param_0];\n+               ld.param.u64         %rd1, [squareKernel_param_1];\n+               cvta.to.global.u64         %rd3, %rd2;\n+               mov.u32              %r2, %ntid.x;\n+               mov.u32              %r3, %ctaid.x;\n+               mov.u32              %r4, %tid.x;\n+               mad.lo.s32           %r1, %r3, %r2, %r4;\n+               ld.global.u32        %r5, [%rd3+4];\n+               setp.ge.s32          %p1, %r1, %r5;\n+               @%p1 bra             $L__BB0_2;\n+\n+               cvta.to.global.u64   %rd4, %rd1;\n+               mul.wide.s32         %rd5, %r1, 4;\n+               add.s64              %rd6, %rd4, %rd5;\n+               ld.global.u32        %r6, [%rd6+4];\n+               mul.lo.s32           %r7, %r6, %r6;\n+               st.global.u32        [%rd6+4], %r7;\n+\n+       $L__BB0_2:\n+               ret;\n+       }\n+    )\");\n+\n+    auto *module =cudaBackend.compile(cudaSource);\n+     auto  *ndrange = bufferOf<NDRange>(\"ndrange\");\n+    ndrange->x=0;\n+    ndrange->maxX=1024;\n+    auto *s32Array1024 = bufferOf<S32Array1024_s>(\"s32Arrayx1024\");\n+    s32Array1024->length=1024;\n+    for (int i=0; i<s32Array1024->length; i++){\n+        s32Array1024->array[i]=i;\n+    }\n+\n+    ArgArray_2 args2Array{.argc = 2, .argv={\n+            {.idx = 0, .variant = '&',.value = {.buffer ={.memorySegment = (void *) ndrange, .sizeInBytes = sizeof(NDRange), .access = RO_BYTE}}},\n+            {.idx = 1, .variant = '&',.value = {.buffer ={.memorySegment = (void *) s32Array1024, .sizeInBytes = sizeof(S32Array1024_s), .access = RW_BYTE}}}\n+    }};\n+    auto kernel = module->getCudaKernel((char*)\"squareKernel\");\n+    std::cout << kernel->name <<std::endl;\n+    kernel->ndrange( reinterpret_cast<ArgArray_s *>(&args2Array));\n+    for (int i=0; i<s32Array1024->length; i++){\n+        std::cout << i << \" array[\"<<i<<\"]=\"<<s32Array1024->array[i] <<std::endl;\n+    }\n+}\n+\n","filename":"hat\/backends\/ffi\/cuda\/cpp\/squares.cpp","additions":169,"deletions":0,"binary":false,"changes":169,"status":"added"},{"patch":"@@ -75,0 +75,2 @@\n+    void write(std::string &filename) const;\n+    void read(std::string &filename);\n@@ -88,0 +90,1 @@\n+    CudaSource(size_t len, char *text, bool isCopy);\n@@ -90,0 +93,1 @@\n+    CudaSource();\n@@ -105,1 +109,1 @@\n-         ~CudaConfig()=default;\n+        ~CudaConfig()=default;\n@@ -142,0 +146,8 @@\n+\n+    private:\n+        CUmodule module;\n+        CudaSource cudaSource;\n+        PtxSource ptxSource;\n+        Log log;\n+\n+    public:\n@@ -150,0 +162,3 @@\n+            static CudaKernel * of(long kernelHandle);\n+            static CudaKernel * of(Backend::CompilationUnit::Kernel *kernel);\n+\n@@ -152,9 +167,0 @@\n-\n-    private:\n-        CUmodule module;\n-        CudaSource cudaSource;\n-        PtxSource ptxSource;\n-        Log log;\n-\n-    public:\n-\n@@ -163,0 +169,2 @@\n+        static CudaModule * of(long moduleHandle);\n+        static CudaModule * of(Backend::CompilationUnit *compilationUnit);\n@@ -164,0 +172,2 @@\n+        CudaKernel *getCudaKernel(char *name);\n+        CudaKernel *getCudaKernel(int nameLen, char *name);\n@@ -165,0 +175,2 @@\n+\n+\n@@ -175,1 +187,3 @@\n-\n+    CudaModule * compile(CudaSource *cudaSource);\n+    CudaModule * compile(CudaSource &cudaSource);\n+    PtxSource *nvcc(CudaSource *cudaSource);\n@@ -186,0 +200,2 @@\n+    static CudaBackend * of(long backendHandle);\n+    static CudaBackend * of(Backend *backend);\n@@ -187,1 +203,1 @@\n-extern \"C\" long getCudaBackend(int mode);\n+\n","filename":"hat\/backends\/ffi\/cuda\/include\/cuda_backend.h","additions":28,"deletions":12,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -37,1 +37,1 @@\n-\n+    final Config config;\n@@ -39,5 +39,2 @@\n-    public long getBackend(int mode) {\n-            backendBridge.handle = getBackend_MPtr.invoke(mode);\n-            return backendBridge.handle;\n-    }\n-    public CudaBackend() {\n+\n+    public CudaBackend(Config config) {\n@@ -45,3 +42,7 @@\n-        getBackend_MPtr  =  ffiLib.longIntFunc(\"getBackend\");\n-        getBackend(0);\n-        backendBridge.info();\n+        this.config = config;\n+        getBackend_MPtr  =  ffiLib.longIntFunc(\"getCudaBackend\");\n+        getBackend(this.config.bits());\n+        if (this.config.isINFO()) {\n+            System.out.println(\"CONFIG = \" + this.config);\n+            backendBridge.info();\n+        }\n@@ -57,0 +58,17 @@\n+    public long getBackend(int configBits) {\n+        return backendBridge.handle = getBackend_MPtr.invoke(configBits);\n+    }\n+\n+    public CudaBackend(String configSpec) {\n+        this(Config.of(configSpec));\n+    }\n+\n+    public CudaBackend() {\n+        this(Config.of());\n+    }\n+\n+\n+\n+\n+\n+\n","filename":"hat\/backends\/ffi\/cuda\/src\/main\/java\/hat\/backend\/ffi\/CudaBackend.java","additions":27,"deletions":9,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -35,4 +35,0 @@\n-import java.lang.invoke.MethodHandle;\n-\n-import static java.lang.foreign.ValueLayout.JAVA_INT;\n-\n@@ -41,1 +37,1 @@\n-    final OpenCLConfig config;\n+    final Config config;\n@@ -50,1 +46,1 @@\n-        this(OpenCLConfig.of(configSpec));\n+        this(Config.of(configSpec));\n@@ -53,1 +49,1 @@\n-    public OpenCLBackend(OpenCLConfig config) {\n+    public OpenCLBackend(Config config) {\n@@ -66,1 +62,1 @@\n-        this(OpenCLConfig.of());\n+        this(Config.of());\n","filename":"hat\/backends\/ffi\/opencl\/src\/main\/java\/hat\/backend\/ffi\/OpenCLBackend.java","additions":4,"deletions":8,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -166,0 +166,1 @@\n+\n","filename":"hat\/backends\/ffi\/shared\/include\/shared.h","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -0,0 +1,237 @@\n+package hat.backend.ffi;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public record Config(int bits) {\n+    record Bit(int index, String name) {\n+    }\n+\n+    \/\/ These must sync with hat\/backends\/ffi\/opencl\/include\/opencl_backend.h\n+    \/\/ Bits 0-3 select platform id 0..5\n+    \/\/ Bits 4-7 select device id 0..15\n+    private static final int START_BIT_IDX = 16;\n+    private static final int MINIMIZE_COPIES_BIT = 1 << START_BIT_IDX;\n+    private static final int TRACE_BIT = 1 << 17;\n+    private static final int PROFILE_BIT = 1 << 18;\n+    private static final int SHOW_CODE_BIT = 1 << 19;\n+    private static final int SHOW_KERNEL_MODEL_BIT = 1 << 20;\n+    private static final int SHOW_COMPUTE_MODEL_BIT = 1 << 21;\n+    private static final int INFO_BIT = 1 << 22;\n+    private static final int TRACE_COPIES_BIT = 1 << 23;\n+    private static final int TRACE_SKIPPED_COPIES_BIT = 1 << 24;\n+    private static final int TRACE_ENQUEUES_BIT = 1 << 25;\n+    private static final int TRACE_CALLS_BIT = 1 << 26;\n+    private static final int SHOW_WHY_BIT = 1 << 27;\n+    private static final int SHOW_STATE_BIT = 1 << 28;\n+    private static final int END_BIT_IDX = 29;\n+\n+    private static String[] bitNames = {\n+            \"MINIMIZE_COPIES\",\n+            \"TRACE\",\n+            \"PROFILE\",\n+            \"SHOW_CODE\",\n+            \"SHOW_KERNEL_MODEL\",\n+            \"SHOW_COMPUTE_MODEL\",\n+            \"INFO\",\n+            \"TRACE_COPIES\",\n+            \"TRACE_SKIPPED_COPIES\",\n+            \"TRACE_ENQUEUES\",\n+            \"TRACE_CALLS\",\n+            \"SHOW_WHY\",\n+            \"SHOW_STATE\",\n+    };\n+\n+    public static Config of() {\n+        if (System.getenv(\"HAT\") instanceof String opts){\n+            System.out.println(\"From env \"+opts);\n+            return of(opts);\n+        }\n+        if (System.getProperty(\"HAT\") instanceof String opts) {\n+            System.out.println(\"From prop \"+opts);\n+            return of(opts);\n+        }\n+        return of(\"\");\n+    }\n+\n+    public static Config of(int bits) {\n+        return new Config(bits);\n+    }\n+\n+    public static Config of(List<Config> configs) {\n+        int allBits = 0;\n+        for (Config config : configs) {\n+            allBits |= config.bits;\n+        }\n+        return new Config(allBits);\n+    }\n+\n+    public static Config of(Config... configs) {\n+        return of(List.of(configs));\n+    }\n+\n+    public Config and(Config... configs) {\n+        return Config.of(Config.of(List.of(configs)).bits & bits);\n+    }\n+\n+    public Config or(Config... configs) {\n+        return Config.of(Config.of(List.of(configs)).bits | bits);\n+    }\n+\n+    public static Config of(String name) {\n+        if (name == null || name.equals(\"\")){\n+            return Config.of(0);\n+        }\n+        for (int i = 0; i < bitNames.length; i++) {\n+            if (bitNames[i].equals(name)) {\n+                return new Config(1 << (i + START_BIT_IDX));\n+            }\n+        }\n+        if (name.contains(\",\")) {\n+            List<Config> configs = new ArrayList<>();\n+            Arrays.stream(name.split(\",\")).forEach(opt ->\n+                    configs.add(of(opt))\n+            );\n+            return of(configs);\n+        }else if (name.contains(\":\")){\n+            var tokens=name.split(\":\");\n+            if (tokens.length == 2) {\n+                var token = tokens[0];\n+                if (token.equals(\"PLATFORM\") || token.equals(\"DEVICE\")) {\n+                    int value = Integer.parseInt(tokens[1]);\n+                    return new Config(value<<(token.equals(\"DEVICE\")?4:0));\n+                }else{\n+                    System.out.println(\"Unexpected opt '\" + name + \"'\");\n+                    return Config.of(0);\n+                }\n+            }else{\n+                System.out.println(\"Unexpected opt '\" + name + \"'\");\n+                return Config.of(0);\n+            }\n+        } else {\n+            System.out.println(\"Unexpected opt '\" + name + \"'\");\n+            System.exit(1);\n+            return Config.of(0);\n+        }\n+    }\n+    public static Config SHOW_STATE() {\n+        return new Config(SHOW_STATE_BIT);\n+    }\n+\n+    public boolean isSHOW_STATE() {\n+        return (bits & SHOW_STATE_BIT) == SHOW_STATE_BIT;\n+    }\n+    public static Config SHOW_WHY() {\n+        return new Config(SHOW_WHY_BIT);\n+    }\n+\n+    public boolean isSHOW_WHY() {\n+        return (bits & SHOW_WHY_BIT) == SHOW_WHY_BIT;\n+    }\n+\n+    public static Config TRACE_COPIES() {\n+        return new Config(TRACE_COPIES_BIT);\n+    }\n+\n+    public boolean isTRACE_COPIES() {\n+        return (bits & TRACE_COPIES_BIT) == TRACE_COPIES_BIT;\n+    }\n+\n+    public static Config TRACE_CALLS() {\n+        return new Config(TRACE_CALLS_BIT);\n+    }\n+\n+    public boolean isTRACE_CALLS() {\n+        return (bits & TRACE_CALLS_BIT) == TRACE_CALLS_BIT;\n+    }\n+\n+    public static Config TRACE_ENQUEUES() {\n+        return new Config(TRACE_ENQUEUES_BIT);\n+    }\n+\n+    public boolean isTRACE_ENQUEUES() {\n+        return (bits & TRACE_ENQUEUES_BIT) == TRACE_ENQUEUES_BIT;\n+    }\n+\n+\n+    public static Config TRACE_SKIPPED_COPIES() {\n+        return new Config(TRACE_SKIPPED_COPIES_BIT);\n+    }\n+\n+    public boolean isTRACE_SKIPPED_COPIES() {\n+        return (bits & TRACE_SKIPPED_COPIES_BIT) == TRACE_SKIPPED_COPIES_BIT;\n+    }\n+\n+    public static Config INFO() {\n+        return new Config(INFO_BIT);\n+    }\n+\n+    public boolean isINFO() {\n+        return (bits & INFO_BIT) == INFO_BIT;\n+    }\n+\n+\n+    public static Config PROFILE() {\n+        return new Config(PROFILE_BIT);\n+    }\n+\n+    public boolean isPROFILE() {\n+        return (bits & PROFILE_BIT) == PROFILE_BIT;\n+    }\n+\n+    public static Config TRACE() {\n+        return new Config(TRACE_BIT);\n+    }\n+\n+    public boolean isTRACE() {\n+        return (bits & TRACE_BIT) == TRACE_BIT;\n+    }\n+\n+    public static Config MINIMIZE_COPIES() {\n+        return new Config(MINIMIZE_COPIES_BIT);\n+    }\n+\n+    public boolean isMINIMIZE_COPIES() {\n+        return (bits & MINIMIZE_COPIES_BIT) == MINIMIZE_COPIES_BIT;\n+    }\n+\n+    public static Config SHOW_CODE() {\n+        return new Config(SHOW_CODE_BIT);\n+    }\n+\n+    public boolean isSHOW_CODE() {\n+        return (bits & SHOW_CODE_BIT) == SHOW_CODE_BIT;\n+    }\n+\n+    public static Config SHOW_KERNEL_MODEL() {\n+        return new Config(SHOW_KERNEL_MODEL_BIT);\n+    }\n+\n+    public boolean isSHOW_KERNEL_MODEL() {\n+        return (bits & SHOW_KERNEL_MODEL_BIT) == SHOW_KERNEL_MODEL_BIT;\n+    }\n+\n+    public static Config SHOW_COMPUTE_MODEL() {\n+        return new Config(SHOW_COMPUTE_MODEL_BIT);\n+    }\n+\n+    public boolean isSHOW_COMPUTE_MODEL() {\n+        return (bits & SHOW_COMPUTE_MODEL_BIT) == SHOW_COMPUTE_MODEL_BIT;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        StringBuilder builder = new StringBuilder();\n+        for (int bitIdx = START_BIT_IDX; bitIdx < END_BIT_IDX; bitIdx++) {\n+            if ((bits & (1 << bitIdx)) == (1 << bitIdx)) {\n+                if (!builder.isEmpty()) {\n+                    builder.append(\"|\");\n+                }\n+                builder.append(bitNames[bitIdx - START_BIT_IDX]);\n+\n+            }\n+        }\n+        return builder.toString();\n+    }\n+}\n","filename":"hat\/backends\/ffi\/shared\/src\/main\/java\/hat\/backend\/ffi\/Config.java","additions":237,"deletions":0,"binary":false,"changes":237,"status":"added"},{"patch":"@@ -71,0 +71,3 @@\n+            if (mh == null){\n+                throw new RuntimeException(\"Null methodhandle \"+name);\n+            }\n@@ -84,0 +87,3 @@\n+            if (mh == null){\n+                throw new RuntimeException(\"Null methodhandle \"+name);\n+            }\n@@ -100,0 +106,3 @@\n+            if (mh == null){\n+                throw new RuntimeException(\"Null methodhandle \"+name);\n+            }\n@@ -116,0 +125,3 @@\n+            if (mh == null){\n+                throw new RuntimeException(\"Null methodhandle \"+name);\n+            }\n@@ -132,0 +144,3 @@\n+            if (mh == null){\n+                throw new RuntimeException(\"Null methodhandle \"+name);\n+            }\n@@ -148,0 +163,3 @@\n+            if (mh == null){\n+                throw new RuntimeException(\"Null methodhandle \"+name);\n+            }\n@@ -161,0 +179,3 @@\n+            if (mh == null){\n+                throw new RuntimeException(\"Null methodhandle \"+name);\n+            }\n","filename":"hat\/backends\/ffi\/shared\/src\/main\/java\/hat\/backend\/ffi\/FFILib.java","additions":21,"deletions":0,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -31,1 +31,1 @@\n-import static hat.backend.ffi.OpenCLConfig.*;\n+import static hat.backend.ffi.Config.*;\n","filename":"hat\/examples\/experiments\/src\/main\/java\/experiments\/Mesh.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -37,1 +37,1 @@\n-import static hat.backend.ffi.OpenCLConfig.*;\n+import static hat.backend.ffi.Config.*;\n","filename":"hat\/examples\/experiments\/src\/main\/java\/experiments\/MinBufferTest.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -31,2 +31,0 @@\n-import hat.backend.ffi.OpenCLConfig;\n-import hat.backend.ffi.OpenCLBackend;\n","filename":"hat\/examples\/nbody\/src\/main\/java\/nbody\/opencl\/OpenCLNBodyGLWindow.java","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -64,1 +64,1 @@\n-        var arr = S32Array.create(accelerator, 32);\n+        var arr = S32Array.create(accelerator, 1024);\n","filename":"hat\/examples\/squares\/src\/main\/java\/squares\/Main.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -77,0 +77,3 @@\n+           if (backendName.equals(\"ffi-cuda\")){\n+               haveBackend.class_path(ffiBackendSharedJar );\n+           }\n","filename":"hat\/hat\/run.java","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"}]}