{"files":[{"patch":"@@ -10,0 +10,1 @@\n+import java.util.function.Function;\n@@ -12,0 +13,1 @@\n+import jdk.incubator.code.CodeItem;\n@@ -13,1 +15,0 @@\n-import jdk.incubator.code.TypeElement;\n@@ -18,0 +19,1 @@\n+import jdk.incubator.code.writer.OpWriter;\n@@ -232,1 +234,1 @@\n-        return _f(fieldIndex, value.getBytes(StandardCharsets.UTF_8));\n+        return value == null ? (T)this : _f(fieldIndex, value.getBytes(StandardCharsets.UTF_8));\n@@ -323,2 +325,2 @@\n-        private final HashMap<Value, String> baseNames = new HashMap();\n-        private final HashMap<String, String> elementsMap = new HashMap();\n+        private final Function<CodeItem, String> baseNames;\n+        private final HashMap<String, String> elementsMap;\n@@ -327,0 +329,5 @@\n+        Indexer(Function<CodeItem, String> baseNames) {\n+            this.baseNames = baseNames;\n+            this.elementsMap = new HashMap<>();\n+        }\n+\n@@ -328,1 +335,1 @@\n-            var name = baseNames.computeIfAbsent(value, _ -> \"#\" + baseNames.size());\n+            var name = \"%\" + baseNames.apply(value);\n@@ -352,0 +359,21 @@\n+    static byte[] build(String domainName, CoreOp.ModuleOp module, List<oracle.code.onnx.Tensor> initializers) {\n+        var indexer = new Indexer(OpWriter.computeGlobalNames(module));\n+\n+        var functions = new ArrayList<>(module.functionTable().sequencedValues());\n+        var mainFunc = functions.removeLast();\n+        var mainBlock = mainFunc.body().entryBlock();\n+\n+        var model = build(\n+                graph(mainFunc.funcName(), domainName, indexer, mainBlock, initializers, 0),\n+                List.of(domainName),\n+                functions.stream().map(f ->\n+                        function(domainName,\n+                                 f.funcName(),\n+                                 f.parameters().stream().map(indexer::nameOf).toList(),\n+                                 expandTuples(indexer, f.body().entryBlock().terminatingOp().operands()),\n+                                 nodes(domainName, indexer, f.body().entryBlock().ops()))).toList());\n+\n+\/\/        OnnxProtoPrinter.printModel(model);\n+        return model;\n+    }\n+\n@@ -357,2 +385,2 @@\n-        var indexer = new Indexer();\n-        var model = build(graph(indexer, block, initializers, 0));\n+        var indexer = new Indexer(OpWriter.computeGlobalNames(block.parentBody().parentOp()));\n+        var model = build(graph(null, null, indexer, block, initializers, 0), List.of(), List.of());\n@@ -364,1 +392,1 @@\n-        return build(graph(initializers, inputs, ops, outputNames));\n+        return build(graph(null, initializers, inputs, ops, outputNames), List.of(), List.of());\n@@ -367,1 +395,5 @@\n-    static byte[] build(GraphProto graph) {\n+    static byte[] build(List<TensorProto> initializers, List<ValueInfoProto> inputs, List<NodeProto> ops, List<String> outputNames, List<String> customImportDomains, List<FunctionProto> functions) {\n+        return build(graph(null, initializers, inputs, ops, outputNames), customImportDomains, functions);\n+    }\n+\n+    static byte[] build(GraphProto graph, List<String> customImportDomains, List<FunctionProto> functions) {\n@@ -370,1 +402,0 @@\n-                .graph(graph)\n@@ -372,0 +403,3 @@\n+                .forEach(customImportDomains, (m, d) -> m.opset_import(new OperatorSetIdProto().domain(d)))\n+                .forEach(functions, (m, f) -> m.functions(f))\n+                .graph(graph)\n@@ -396,1 +430,1 @@\n-    static GraphProto graph(Indexer indexer, Block block, List<oracle.code.onnx.Tensor> initializers, int scalarArgs) {\n+    static GraphProto graph(String graphName, String domainName, Indexer indexer, Block block, List<oracle.code.onnx.Tensor> initializers, int scalarArgs) {\n@@ -400,2 +434,3 @@\n-        var args = params.subList(params.isEmpty() || params.getFirst().type() instanceof OnnxType.TensorType ? 0 : 1, firstInitializer);\n-        return graph(IntStream.range(0, initializers.size()).mapToObj(i -> tensorProto(indexer.nameOf(params.get(i + firstInitializer)), initializers.get(i))).toList(),\n+        var args = params.subList(0, firstInitializer);\n+        return graph(graphName,\n+                IntStream.range(0, initializers.size()).mapToObj(i -> tensorProto(indexer.nameOf(params.get(i + firstInitializer)), initializers.get(i))).toList(),\n@@ -403,43 +438,1 @@\n-                block.ops().stream().<NodeProto>mapMulti((op, opNodes) -> {\n-                    switch (op) {\n-                        case OnnxOps.If ifOp ->\n-                            opNodes.accept(node(\n-                                    ifOp.opName(),\n-                                    List.of(indexer.nameOf(ifOp.operands().getFirst())),\n-                                    IntStream.range(0, ifOp.resultType() instanceof TupleType tt ? tt.componentTypes().size() : 1).mapToObj(o -> indexer.nameOf(ifOp.result(), o)).toList(),\n-                                    java.util.Map.of(\n-                                            \"then_branch\", graph(indexer, ifOp.thenBranch().entryBlock(), List.of(), 0),\n-                                            \"else_branch\", graph(indexer, ifOp.elseBranch().entryBlock(), List.of(), 0))));\n-                        case OnnxOps.Loop loopOp -> {\n-                            opNodes.accept(node(loopOp.opName(),\n-                                    expandTuples(indexer, loopOp.operands()),\n-                                    IntStream.range(0, loopOp.resultType() instanceof TupleType tt ? tt.componentTypes().size() : 1).mapToObj(o -> indexer.nameOf(loopOp.result(), o)).toList(),\n-                                    java.util.Map.of(\n-                                            \"body\", graph(indexer, loopOp.loopBody().entryBlock(), List.of(), 2))));\n-                        }\n-                        case OnnxOp onnxOp ->\n-                            opNodes.accept(node(\n-                                    onnxOp.opName(),\n-                                    onnxOp.operands().stream().map(indexer::nameOf).toList(),\n-                                    IntStream.range(0, onnxOp.onnxOutputs().size()).mapToObj(o -> indexer.nameOf(onnxOp.result(), o)).toList(),\n-                                    onnxOp.onnxAttributes()));\n-                        case CoreOp.ReturnOp _, CoreOp.ConstantOp _ -> { \/\/ skip\n-                        }\n-                        case CoreOp.TupleLoadOp tlo ->\n-                            indexer.mapTupleLoad(tlo.result(), tlo.operands().getFirst(), tlo.index());\n-                        case CoreOp.TupleOp to ->\n-                            indexer.mapTupleElements(to.result(), to.operands());\n-                        case CoreOp.InvokeOp io when io.invokeDescriptor().refType().equals(JavaType.type(List.class)) -> {\n-                            if (io.invokeDescriptor().name().equals(\"get\") && io.operands().getLast() instanceof Op.Result or && or.op() instanceof CoreOp.ConstantOp co && co.value() instanceof Integer i) {\n-                                indexer.mapTupleLoad(io.result(), io.operands().getFirst(), i);\n-                            } else if (io.invokeDescriptor().name().equals(\"of\")) {\n-                                indexer.mapTupleElements(io.result(), io.operands());\n-                            } else {\n-                                throw new UnsupportedOperationException(op.toText());\n-                            }\n-                        }\n-                        default -> {\n-                            throw new UnsupportedOperationException(op.toText());\n-                        }\n-                    }\n-                }).toList(),\n+                nodes(domainName, indexer, block.ops()),\n@@ -449,0 +442,53 @@\n+    static List<NodeProto> nodes(String domainName, Indexer indexer, List<Op> ops) {\n+        return ops.stream().<NodeProto>mapMulti((op, opNodes) -> {\n+            switch (op) {\n+                case OnnxOps.If ifOp ->\n+                    opNodes.accept(node(\n+                            ifOp.opName(),\n+                            List.of(indexer.nameOf(ifOp.operands().getFirst())),\n+                            IntStream.range(0, ifOp.resultType() instanceof TupleType tt ? tt.componentTypes().size() : 1).mapToObj(o -> indexer.nameOf(ifOp.result(), o)).toList(),\n+                            java.util.Map.of(\n+                                    \"then_branch\", graph(null, domainName, indexer, ifOp.thenBranch().entryBlock(), List.of(), 0),\n+                                    \"else_branch\", graph(null, domainName, indexer, ifOp.elseBranch().entryBlock(), List.of(), 0))));\n+                case OnnxOps.Loop loopOp -> {\n+                    opNodes.accept(node(loopOp.opName(),\n+                            expandTuples(indexer, loopOp.operands()),\n+                            IntStream.range(0, loopOp.resultType() instanceof TupleType tt ? tt.componentTypes().size() : 1).mapToObj(o -> indexer.nameOf(loopOp.result(), o)).toList(),\n+                            java.util.Map.of(\n+                                    \"body\", graph(null, domainName, indexer, loopOp.loopBody().entryBlock(), List.of(), 2))));\n+                }\n+                case OnnxOp onnxOp ->\n+                    opNodes.accept(node(\n+                            onnxOp.opName(),\n+                            onnxOp.operands().stream().map(indexer::nameOf).toList(),\n+                            IntStream.range(0, onnxOp.onnxOutputs().size()).mapToObj(o -> indexer.nameOf(onnxOp.result(), o)).toList(),\n+                            onnxOp.onnxAttributes()));\n+                case CoreOp.FuncCallOp fco ->\n+                    opNodes.accept(node(\n+                            domainName,\n+                            fco.funcName(),\n+                            fco.operands().stream().map(indexer::nameOf).toList(),\n+                            expandTuples(indexer, List.of(fco.result())),\n+                            java.util.Map.of()));\n+                case CoreOp.ReturnOp _, CoreOp.ConstantOp _ -> { \/\/ skip\n+                }\n+                case CoreOp.TupleLoadOp tlo ->\n+                    indexer.mapTupleLoad(tlo.result(), tlo.operands().getFirst(), tlo.index());\n+                case CoreOp.TupleOp to ->\n+                    indexer.mapTupleElements(to.result(), to.operands());\n+                case CoreOp.InvokeOp io when io.invokeDescriptor().refType().equals(JavaType.type(List.class)) -> {\n+                    if (io.invokeDescriptor().name().equals(\"get\") && io.operands().getLast() instanceof Op.Result or && or.op() instanceof CoreOp.ConstantOp co && co.value() instanceof Integer i) {\n+                        indexer.mapTupleLoad(io.result(), io.operands().getFirst(), i);\n+                    } else if (io.invokeDescriptor().name().equals(\"of\")) {\n+                        indexer.mapTupleElements(io.result(), io.operands());\n+                    } else {\n+                        throw new UnsupportedOperationException(op.toText());\n+                    }\n+                }\n+                default -> {\n+                    throw new UnsupportedOperationException(op.toText());\n+                }\n+            }\n+        }).toList();\n+    }\n+\n@@ -462,1 +508,1 @@\n-                    throw new UnsupportedOperationException();\n+                    throw new UnsupportedOperationException(arg.type().toString());\n@@ -468,1 +514,1 @@\n-    static GraphProto graph(List<TensorProto> initializers, List<ValueInfoProto> inputs, List<NodeProto> ops, List<String> outputNames) {\n+    static GraphProto graph(String name, List<TensorProto> initializers, List<ValueInfoProto> inputs, List<NodeProto> ops, List<String> outputNames) {\n@@ -470,0 +516,1 @@\n+                .name(name)\n@@ -476,1 +523,11 @@\n-    static NodeProto node(String opName, List<String> inputNames, List<String> outputNames, java.util.Map<String, Object> attributes) {\n+    static FunctionProto function(String domain, String functionName, List<String> inputNames, List<String> outputNames, List<NodeProto> ops) {\n+        return new FunctionProto()\n+                .domain(domain)\n+                .name(functionName)\n+                .forEach(inputNames, (f, i) -> f.input(i))\n+                .forEach(ops, (g, op) -> g.node(op))\n+                .forEach(outputNames, (f, o) -> f.output(o))\n+                .opset_import(new OperatorSetIdProto().version(OPSET_VERSION));\n+    }\n+\n+    static NodeProto node(String domain, String opName, List<String> inputNames, List<String> outputNames, java.util.Map<String, Object> attributes) {\n@@ -478,0 +535,2 @@\n+                .domain(domain)\n+                .op_type(opName)\n@@ -479,1 +538,6 @@\n-                .forEach(outputNames, (n, oName) -> n.output(oName))\n+                .forEach(attributes.entrySet(), (n, ae) -> n.attribute(attribute(ae.getKey(), ae.getValue())))\n+                .forEach(outputNames, (n, oName) -> n.output(oName));\n+    }\n+\n+    static NodeProto node(String opName, List<String> inputNames, List<String> outputNames, java.util.Map<String, Object> attributes) {\n+        return new NodeProto()\n@@ -481,1 +545,3 @@\n-                .forEach(attributes.entrySet(), (n, ae) -> n.attribute(attribute(ae.getKey(), ae.getValue())));\n+                .forEach(inputNames, (n, iName) -> n.input(iName))\n+                .forEach(attributes.entrySet(), (n, ae) -> n.attribute(attribute(ae.getKey(), ae.getValue())))\n+                .forEach(outputNames, (n, oName) -> n.output(oName));\n@@ -498,1 +564,1 @@\n-                .dims(tensor.shape())\n+                .name(name)\n@@ -500,2 +566,2 @@\n-                .raw_data(tensor.data().toArray(ValueLayout.JAVA_BYTE))\n-                .name(name);\n+                .dims(tensor.shape())\n+                .raw_data(tensor.data().toArray(ValueLayout.JAVA_BYTE));\n","filename":"cr-examples\/onnx\/src\/main\/java\/oracle\/code\/onnx\/OnnxProtoBuilder.java","additions":130,"deletions":64,"binary":false,"changes":194,"status":"modified"},{"patch":"@@ -7,0 +7,2 @@\n+import java.lang.invoke.VarHandle;\n+import java.lang.reflect.AccessFlag;\n@@ -8,0 +10,1 @@\n+import java.lang.reflect.Field;\n@@ -25,0 +28,1 @@\n+import oracle.code.onnx.ir.OnnxType;\n@@ -75,6 +79,16 @@\n-        \/\/ @@@ heuristic assumption the first non-tensor and non-varbox captured value is receiver\n-        private static Object getReceiver(SequencedCollection<Object> values) {\n-            for (var v : values) {\n-                if (!(v instanceof Tensor || v instanceof CoreOp.Var)) return v;\n-            }\n-            return null;\n+        static List<Tensor> getInitValues(MethodHandles.Lookup lookup, List<OnnxType.Initializer> initializers, SequencedCollection<Object> possibleReceivers) {\n+            return initializers.stream().map(i -> {\n+                try {\n+                    int split = i.name().lastIndexOf('.');\n+                    Class<?> initializerClass = lookup.findClass(i.name().substring(0, split));\n+                    Field initializerField = initializerClass.getDeclaredField(i.name().substring(split + 1, i.name().length()));\n+                    VarHandle handle = lookup.unreflectVarHandle(initializerField);\n+                    if (initializerField.accessFlags().contains(AccessFlag.STATIC)) {\n+                        return (Tensor)handle.get();\n+                    } else {\n+                        return (Tensor)handle.get(possibleReceivers.stream().filter(initializerClass::isInstance).findFirst().orElseThrow());\n+                    }\n+                } catch (ReflectiveOperationException ex) {\n+                    throw new RuntimeException(ex);\n+                }\n+            }).toList();\n@@ -85,4 +99,12 @@\n-            var trans = OnnxTransformer.ofQuotedLambda(l, q);\n-            var func = trans.transform();\n-            byte[] protobufModel = OnnxProtoBuilder.build(func.body().entryBlock(),\n-                    trans.initializers(getReceiver(q.capturedValues().sequencedValues())));\n+            CoreOp.ModuleOp module = OnnxTransformer.transform(l, q);\n+\n+            \/\/ initializers filtered from the model main function parameters\n+            List<OnnxType.Initializer> initializers =\n+                    module.functionTable().sequencedValues().getLast()\n+                            .parameters().stream()\n+                                    .map(Block.Parameter::type)\n+                                    .filter(OnnxType.Initializer.class::isInstance)\n+                                    .map(OnnxType.Initializer.class::cast).toList();\n+\n+            String domainName = type.getSimpleName().split(\"\\\\$\")[0];\n+            byte[] protobufModel = OnnxProtoBuilder.build(domainName, module, getInitValues(l, initializers, q.capturedValues().sequencedValues()));\n@@ -91,1 +113,1 @@\n-                System.out.println(func.toText());\n+                System.out.println(module.toText());\n@@ -93,1 +115,1 @@\n-                    var export = Path.of(type.getSimpleName().split(\"\\\\$\")[0] + \".onnx\");\n+                    var export = Path.of(domainName + \".onnx\");\n","filename":"cr-examples\/onnx\/src\/main\/java\/oracle\/code\/onnx\/OnnxRuntime.java","additions":34,"deletions":12,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -485,0 +485,5 @@\n+            case CoreOp.FuncOp funcOp -> {\n+                interpretEntryBlock(l, funcOp.body().entryBlock(), oc, new HashMap<>());\n+                unevaluatedOperations.add(o);\n+                return null;\n+            }\n","filename":"cr-examples\/onnx\/src\/main\/java\/oracle\/code\/onnx\/compiler\/OnnxPartialEvaluator.java","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -7,0 +7,1 @@\n+import java.util.stream.IntStream;\n@@ -45,1 +46,1 @@\n-public class OnnxTransformer {\n+public final class OnnxTransformer {\n@@ -48,2 +49,0 @@\n-\n-\n@@ -53,5 +52,1 @@\n-    private final MethodHandles.Lookup l;\n-    private final CoreOp.FuncOp inputFunc;\n-    private final List<FieldRef> inits;\n-\n-    public static OnnxTransformer ofQuotedLambda(MethodHandles.Lookup lookup, Quoted quotedLambda) {\n+    public static CoreOp.ModuleOp transform(MethodHandles.Lookup l, Quoted quotedLambda) {\n@@ -70,1 +65,1 @@\n-        CoreOp.FuncOp f = CoreOp.FuncOp.func(\"f\", ft).body(b -> {\n+        CoreOp.FuncOp f = CoreOp.FuncOp.func(\"\", ft).body(b -> {\n@@ -88,1 +83,7 @@\n-        return new OnnxTransformer(lookup, f);\n+        return OnnxTransformer.transform(l, f);\n+    }\n+    public static CoreOp.ModuleOp transform(MethodHandles.Lookup l, CoreOp.FuncOp inputFunc) {\n+        CoreOp.ModuleOp m = collectModuleFunctions(l, inputFunc);\n+        m = remapInitializers(l, m);\n+        m = transformModule(l, m);\n+        return m;\n@@ -91,8 +92,5 @@\n-    final CoreOp.FuncOp inline(CoreOp.FuncOp func) {\n-        return func.transform((bb, op) -> {\n-            var cc  = bb.context();\n-            switch (op) {\n-                case CoreOp.InvokeOp io when resolve(io) instanceof CoreOp.FuncOp inline ->\n-                    bb.inline(inline(inline), cc.getValues(io.operands()), (_, v) -> cc.mapValue(io.result(), v));\n-                default ->\n-                    bb.apply(op);\n+    static void collectModuleFunctions(MethodHandles.Lookup l, SequencedMap<MethodRef, CoreOp.FuncOp> funcs, Set<CoreOp.FuncOp> doNotInline, CoreOp.FuncOp func) {\n+        func.traverse(null, (_, op) -> {\n+            if(op instanceof CoreOp.InvokeOp io && resolve(l, io) instanceof CoreOp.FuncOp f) {\n+                collectModuleFunctions(l, funcs, doNotInline, f);\n+                doNotInline.add(funcs.putIfAbsent(io.invokeDescriptor(), f));\n@@ -100,1 +98,1 @@\n-            return bb;\n+            return null;\n@@ -104,2 +102,12 @@\n-    public OnnxTransformer(MethodHandles.Lookup lookup, CoreOp.FuncOp func) {\n-        l = lookup;\n+    static CoreOp.ModuleOp collectModuleFunctions(MethodHandles.Lookup l, CoreOp.FuncOp inputFunc) {\n+        \/\/ traverse inputFunc and collect all functions to construct module\n+        var funcs = new LinkedHashMap<MethodRef, CoreOp.FuncOp>();\n+        var doNotInline = new HashSet<CoreOp.FuncOp>();\n+        doNotInline.add(inputFunc);\n+        collectModuleFunctions(l, funcs, doNotInline, inputFunc);\n+        funcs.putLast(null, inputFunc);\n+\n+        return CoreOp.module(funcs.sequencedValues().stream()\n+                .filter(f -> doNotInline.contains(f))\n+                .map(f -> mapOrInline(f, funcs, doNotInline)).toList());\n+    }\n@@ -107,1 +115,4 @@\n-        var inlinedFunc = inline(func);\n+    static String findBetterName(SequencedMap<MethodRef, CoreOp.FuncOp> funcs, Set<CoreOp.FuncOp> doNotInline) {\n+        \/\/ find the last inlined func name\n+        return funcs.sequencedValues().reversed().stream().filter(f -> !doNotInline.contains(f)).findFirst().map(CoreOp.FuncOp::funcName).orElse(\"\");\n+    }\n@@ -109,16 +120,8 @@\n-        inits = new ArrayList<>();\n-        var initMap = new HashMap<FieldRef, Block.Parameter>();\n-        var top = new Block.Builder[1];\n-        \/\/ turning field loads into additiona arguments\n-        inputFunc = inlinedFunc.transform((bb, op) -> {\n-            \/\/ @@@ This is ugly, in this case we could ask the bb for its furthest ancestor block\n-            \/\/ when we need it\n-            if (top[0] == null) top[0] = bb;\n-            var cc  = bb.context();\n-            switch (op) {\n-                case CoreOp.FieldAccessOp.FieldLoadOp flo when op.resultType() instanceof ClassType ct && ct.rawType().equals(TENSOR_CLASS) -> {\n-                    \/\/ initializers turn into top block parameters\n-                    cc.mapValue(op.result(), initMap.computeIfAbsent(flo.fieldDescriptor(), fd -> {\n-                        inits.add(fd);\n-                        return top[0].parameter(op.resultType());\n-                    }));\n+    \/\/ transform all relevant invocations to func calls or inline\n+    static CoreOp.FuncOp mapOrInline(CoreOp.FuncOp f, SequencedMap<MethodRef, CoreOp.FuncOp> funcs, Set<CoreOp.FuncOp> doNotInline) {\n+        return f.transform(f.funcName().isEmpty() ? findBetterName(funcs, doNotInline): f.funcName(), (bb, op) -> {\n+            if (op instanceof CoreOp.InvokeOp io && funcs.get(io.invokeDescriptor()) instanceof CoreOp.FuncOp fo) {\n+                if (doNotInline.contains(fo)) {\n+                    bb.context().mapValue(op.result(), bb.op(CoreOp.funcCall(fo, bb.context().getValues(op.operands()))));\n+                } else {\n+                    bb.inline(mapOrInline(fo, funcs, doNotInline), bb.context().getValues(io.operands()), (_, v) -> bb.context().mapValue(io.result(), v));\n@@ -126,1 +129,2 @@\n-                default -> bb.apply(op);\n+            } else {\n+                bb.op(op);\n@@ -132,1 +136,45 @@\n-    CoreOp.FuncOp resolve(CoreOp.InvokeOp io) {\n+    static CoreOp.ModuleOp remapInitializers(MethodHandles.Lookup l, CoreOp.ModuleOp module) {\n+        \/\/ collect initializers (field load ops of tensors)\n+        record TI(OnnxType.Initializer type, int index) {}\n+        var initializers = module.traverse(new LinkedHashMap<FieldRef, TI>(), (i, op) -> {\n+            if (op instanceof CoreOp.FieldAccessOp.FieldLoadOp flo && flo.resultType() instanceof ClassType ct && ct.rawType().equals(TENSOR_CLASS)) {\n+                i.putIfAbsent(flo.fieldDescriptor(), new TI(new OnnxType.Initializer((OnnxType)convertType(l, ct), ((ClassType)flo.fieldDescriptor().refType()).rawType().toClassName() + \".\" + flo.fieldDescriptor().name()), i.size()));\n+            }\n+            return i;\n+        });\n+\n+        if (initializers.isEmpty()) {\n+            return module;\n+        }\n+\n+        \/\/ map all initializers field loads into additional arguments\n+        List<OnnxType.Initializer> initTypes = initializers.sequencedValues().stream().map(TI::type).toList();\n+        return CoreOp.module(module.functionTable().sequencedValues().stream().map(f -> {\n+            var ft = f.invokableType();\n+            int argsSize = ft.parameterTypes().size();\n+            return CoreOp.func(f.funcName(), FunctionType.functionType(ft.returnType(), Stream.concat(ft.parameterTypes().stream(), initTypes.stream()).toList()))\n+                    .body(bob -> bob.transformBody(f.body(), bob.parameters(), (bb, op) -> {\n+                        List<Block.Parameter> initArgs = bob.parameters().subList(argsSize, bob.parameters().size());\n+                        switch (op) {\n+                            \/\/ field loads mapped to initializers args\n+                            case CoreOp.FieldAccessOp.FieldLoadOp flo when initializers.get(flo.fieldDescriptor()) instanceof TI ti -> {\n+                                bb.context().mapValue(op.result(), initArgs.get(ti.index()));\n+                            }\n+                            case CoreOp.FuncCallOp fco -> {\n+                                \/\/ attach initializers args to all func calls\n+                                FunctionType newType = FunctionType.functionType(fco.opType().returnType(),\n+                                        Stream.concat(fco.opType().parameterTypes().stream(), initTypes.stream()).toList());\n+                                List<Value> newOperands = Stream.concat(bb.context().getValues(fco.operands()).stream(), initArgs.stream()).toList();\n+                                Op.Result newCall = bb.op(CoreOp.funcCall(fco.funcName(), newType, newOperands));\n+                                bb.context().mapValue(op.result(), newCall);\n+                            }\n+                            default -> {\n+                                bb.op(op);\n+                            }\n+                        }\n+                        return bb;\n+                    }));\n+        }).toList());\n+    }\n+\n+    static CoreOp.FuncOp resolve(MethodHandles.Lookup l, CoreOp.InvokeOp io) {\n@@ -142,8 +190,4 @@\n-    public List<Tensor> initializers(Object receiver) {\n-        return inits.stream().map(i -> {\n-            try {\n-                return (Tensor)(i.resolveToMember(l).accessFlags().contains(AccessFlag.STATIC) ? i.resolveToHandle(l).get() : i.resolveToHandle(l).get(receiver));\n-            } catch (ReflectiveOperationException ex) {\n-                throw new RuntimeException(ex);\n-            }\n-        }).toList();\n+    static CoreOp.ModuleOp transformModule(MethodHandles.Lookup l, CoreOp.ModuleOp module) {\n+        var paramsToDropMap = new HashMap<String, BitSet>();\n+        return CoreOp.module(module.functionTable().sequencedValues().stream().map(f\n+                -> transformFunc(l, f, paramsToDropMap)).toList());\n@@ -152,1 +196,1 @@\n-    public CoreOp.FuncOp transform() {\n+    static CoreOp.FuncOp transformFunc(MethodHandles.Lookup l, CoreOp.FuncOp func, Map<String, BitSet> paramsToDropMap) {\n@@ -154,1 +198,1 @@\n-        pe.evaluate(l, inputFunc);\n+        pe.evaluate(l, func);\n@@ -157,6 +201,1 @@\n-        FunctionType ft = FunctionType.functionType(type(l, inputFunc.invokableType().returnType()),\n-                inputFunc.invokableType().parameterTypes().stream().map(te -> type(l, te)).toList()\n-        );\n-        CoreOp.FuncOp onnxModel = CoreOp.func(inputFunc.funcName(), ft).body(b -> {\n-            b.transformBody(inputFunc.body(), b.parameters(), bodyTransformer(pe));\n-        });\n+        func = transformToOnnx(l, func, pe);\n@@ -164,14 +203,6 @@\n-        \/\/ Drop unused parameters transformation, can be merged with drop unused operations transformation\n-        CoreOp.FuncOp cutModel = onnxModel;\n-        if (onnxModel.parameters().stream().anyMatch(v -> v.uses().isEmpty())) {\n-            List<Block.Parameter> usedParameters = onnxModel.parameters().stream()\n-                    .filter(v -> !v.uses().isEmpty())\n-                    .toList();\n-            List<TypeElement> usedParameterTypes = usedParameters.stream().map(Value::type).toList();\n-\n-            var funcType = FunctionType.functionType(onnxModel.invokableType().returnType(), usedParameterTypes);\n-            cutModel = CoreOp.func(onnxModel.funcName(), funcType).body(bb -> {\n-                bb.context().mapValues(usedParameters, bb.parameters());\n-                bb.transformBody(onnxModel.body(), List.of(), OpTransformer.COPYING_TRANSFORMER);\n-            });\n-        }\n+        \/\/ remove redundant args from func calls of funcs with already dropped unused parameters\n+        \/\/ functions are listed in post-ordered and recursion is not allowed\n+        func = removeDropedFuncCallsArgs(func, paramsToDropMap);\n+\n+        \/\/ drop unused parameters and ops\n+        func = dropUnused(l, func, paramsToDropMap);\n@@ -180,4 +211,23 @@\n-        return SSA.transform(cutModel).transform((b, op) -> {\n-            \/\/ Drop any non-terminating operation whose result is not used\n-            if (op instanceof Op.Terminating || !op.result().uses().isEmpty()) {\n-                b.op(op);\n+        return SSA.transform(func);\n+    }\n+\n+    static CoreOp.FuncOp transformToOnnx(MethodHandles.Lookup l, CoreOp.FuncOp func, OnnxPartialEvaluator pe) {\n+        FunctionType ft = convertType(l, func.invokableType());\n+        return CoreOp.func(func.funcName(), ft).body(b -> {\n+            b.transformBody(func.body(), b.parameters(), toOnnxOpTransformer(l, pe));\n+        });\n+    }\n+\n+    static CoreOp.FuncOp removeDropedFuncCallsArgs(CoreOp.FuncOp func, Map<String, BitSet> paramsToDropMap) {\n+        return func.transform((bb, op) -> {\n+            if (op instanceof CoreOp.FuncCallOp fco) {\n+                BitSet argsToDrop = paramsToDropMap.get(fco.funcName());\n+                CopyContext cc = bb.context();\n+                List<Value> newOperands = IntStream.range(0, fco.operands().size()).filter(i -> !argsToDrop.get(i)).mapToObj(i -> cc.getValue(fco.operands().get(i))).toList();\n+                CoreOp.FuncCallOp newCall = CoreOp.funcCall(fco.funcName(),\n+                                                            FunctionType.functionType(fco.opType().returnType(),\n+                                                                                      newOperands.stream().map(Value::type).toList()),\n+                                                            newOperands);\n+                cc.mapValue(op.result(), bb.op(newCall));\n+            } else {\n+                bb.op(op);\n@@ -185,1 +235,28 @@\n-            return b;\n+            return bb;\n+        });\n+    }\n+\n+    static CoreOp.FuncOp dropUnused(MethodHandles.Lookup l, CoreOp.FuncOp func, Map<String, BitSet> paramsToDropMap) {\n+        BitSet paramsToDrop = new BitSet();\n+        paramsToDropMap.put(func.funcName(), paramsToDrop);\n+        List<Block.Parameter> usedParameters = func.parameters().stream()\n+                .filter(v -> {\n+                    if (v.uses().isEmpty()) {\n+                        paramsToDrop.set(v.index());\n+                        return false;\n+                    } else {\n+                        return true;\n+                    }\n+                })\n+                .toList();\n+\n+        var funcType = FunctionType.functionType(func.invokableType().returnType(), usedParameters.stream().map(Value::type).toList());\n+        return CoreOp.func(func.funcName(), funcType).body(bob -> {\n+            bob.context().mapValues(usedParameters, bob.parameters());\n+            bob.transformBody(func.body(), List.of(), (b, op) -> {\n+                \/\/ Drop any non-terminating operation whose result is not used\n+                if (op instanceof Op.Terminating || !op.result().uses().isEmpty() || op instanceof CoreOp.FuncOp) {\n+                    b.op(op);\n+                }\n+                return b;\n+            });\n@@ -189,1 +266,1 @@\n-    OpTransformer bodyTransformer(OnnxPartialEvaluator pe) {\n+    static OpTransformer toOnnxOpTransformer(MethodHandles.Lookup l, OnnxPartialEvaluator pe) {\n@@ -217,1 +294,1 @@\n-                        opArgs.add(type(l, op.resultType()));\n+                        opArgs.add(convertType(l, op.resultType()));\n@@ -267,1 +344,1 @@\n-                            opArgs.add(transformBodyTranslateTypes(l, lambda, bb, bodyTransformer(pe)));\n+                            opArgs.add(transformBodyTranslateTypes(l, lambda, bb, toOnnxOpTransformer(l, pe)));\n@@ -272,1 +349,1 @@\n-                        opArgs.add(transformBodyTranslateTypes(l, lambda, bb, bodyTransformer(pe)));\n+                        opArgs.add(transformBodyTranslateTypes(l, lambda, bb, toOnnxOpTransformer(l, pe)));\n@@ -306,0 +383,4 @@\n+                case CoreOp.FuncCallOp fco -> {\n+                    Op.Result result = bb.op(CoreOp.funcCall(fco.funcName(), convertType(l, fco.opType()), bb.context().getValues(fco.operands())));\n+                    bb.context().mapValue(fco.result(), result);\n+                }\n@@ -320,2 +401,2 @@\n-                type(l, inputType.returnType()),\n-                inputType.parameterTypes().stream().map(pt -> type(l, pt)).toList());\n+                convertType(l, inputType.returnType()),\n+                inputType.parameterTypes().stream().map(pt -> convertType(l, pt)).toList());\n@@ -369,1 +450,1 @@\n-                            tupleComponentTypes.add(type(l, JavaType.type(pt)));\n+                            tupleComponentTypes.add(convertType(l, JavaType.type(pt)));\n@@ -380,1 +461,1 @@\n-                            tupleComponentTypes.add(type(l, JavaType.parameterized(JavaType.type(Tensor.class), e)));\n+                            tupleComponentTypes.add(convertType(l, JavaType.parameterized(JavaType.type(Tensor.class), e)));\n@@ -394,1 +475,1 @@\n-                    tupleComponentTypes.add(type(l, e));\n+                    tupleComponentTypes.add(convertType(l, e));\n@@ -435,1 +516,3 @@\n-    static final TypeElement TENSOR_RAW_CLASS = JavaType.type(Tensor.class);\n+    static FunctionType convertType(MethodHandles.Lookup l, FunctionType t) {\n+        return FunctionType.functionType(convertType(l, t.returnType()), t.parameterTypes().stream().map(pt -> convertType(l, pt)).toList());\n+    }\n@@ -439,1 +522,1 @@\n-    static TypeElement type(MethodHandles.Lookup l, TypeElement type) {\n+    static TypeElement convertType(MethodHandles.Lookup l, TypeElement type) {\n@@ -441,1 +524,1 @@\n-            if (ct.rawType().equals(TENSOR_RAW_CLASS)) {\n+            if (ct.rawType().equals(TENSOR_CLASS)) {\n","filename":"cr-examples\/onnx\/src\/main\/java\/oracle\/code\/onnx\/compiler\/OnnxTransformer.java","additions":170,"deletions":87,"binary":false,"changes":257,"status":"modified"},{"patch":"@@ -89,0 +89,8 @@\n+                case Initializer.NAME: {\n+                    if (tree.arguments().size() != 2) {\n+                        throw new IllegalArgumentException();\n+                    }\n+                    return new Initializer(\n+                            constructType(tree.arguments().getFirst()),\n+                            tree.arguments().get(1).toString());\n+                }\n@@ -469,0 +477,24 @@\n+    public static final class Initializer extends OnnxType {\n+        static final String NAME = \"init\";\n+\n+        final OnnxType type;\n+        final String name;\n+\n+        public Initializer(OnnxType type, String name) {\n+            this.type = type;\n+            this.name = name;\n+        }\n+\n+        public OnnxType type() {\n+            return type;\n+        }\n+\n+        public String name() {\n+            return name;\n+        }\n+\n+        @Override\n+        public ExternalizedTypeElement externalize() {\n+            return new ExternalizedTypeElement(NAME, List.of(type.externalize(), ExternalizedTypeElement.ofString(name)));\n+        }\n+    }\n","filename":"cr-examples\/onnx\/src\/main\/java\/oracle\/code\/onnx\/ir\/OnnxType.java","additions":32,"deletions":0,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -153,1 +153,1 @@\n-    static CoreOp.FuncOp cnnModel() {\n+    static CoreOp.ModuleOp cnnModel() {\n@@ -171,1 +171,1 @@\n-        return CoreOp.func(\"cnn\", functionType).body(b -> {\n+        return CoreOp.module(CoreOp.func(\"cnn\", functionType).body(b -> {\n@@ -301,1 +301,1 @@\n-        });\n+        }));\n@@ -325,1 +325,1 @@\n-            var onnxModel = new OnnxTransformer(MethodHandles.lookup(), f).transform();\n+            CoreOp.ModuleOp onnxModel = OnnxTransformer.transform(MethodHandles.lookup(), f);\n@@ -328,1 +328,1 @@\n-            CoreOp.FuncOp expectedOnnxModel = cnnModel();\n+            var expectedOnnxModel = cnnModel();\n","filename":"cr-examples\/onnx\/src\/test\/java\/oracle\/code\/onnx\/CNNTest.java","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -70,0 +70,1 @@\n+                                    null,\n@@ -75,0 +76,1 @@\n+                                    null,\n@@ -97,0 +99,1 @@\n+                                    null,\n@@ -108,0 +111,25 @@\n+\n+\n+    @Test\n+    public void testCustomFunction() throws Exception {\n+        String customDomain = RuntimeTest.class.getName();\n+        var ort = OnnxRuntime.getInstance();\n+        try (Arena arena = Arena.ofConfined()) {\n+            var customFunction = ort.createSession(arena, build(\n+                    List.of(),\n+                    List.of(tensorInfo(\"x\", INT64.id)),\n+                    List.of(node(customDomain, \"CustomFunction\", List.of(\"x\"), List.of(\"y\"), Map.of())),\n+                    List.of(\"y\"),\n+                    List.of(customDomain),\n+                    List.of(new FunctionProto()\n+                            .name(\"CustomFunction\")\n+                            .input(\"a\")\n+                            .output(\"b\")\n+                            .node(node(\"Identity\", List.of(\"a\"), List.of(\"b\"), Map.of()))\n+                            .opset_import(new OperatorSetIdProto().version(OPSET_VERSION))\n+                            .domain(customDomain))));\n+\n+            var a = Tensor.ofScalar(arena, 1l);\n+            SimpleTest.assertEquals(a, customFunction.run(arena, List.of(a)).getFirst());\n+        }\n+    }\n","filename":"cr-examples\/onnx\/src\/test\/java\/oracle\/code\/onnx\/RuntimeTest.java","additions":28,"deletions":0,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -124,2 +124,2 @@\n-    public Tensor<Float> concat(Tensor<Float> input1, Tensor<Float> input2, long axis) {\n-        return Concat(List.of(input1, input2), axis);\n+    public Tensor<Float> concat(Tensor<Float> input1, Tensor<Float> input2) {\n+        return Concat(List.of(input1, input2), 0);\n@@ -133,2 +133,2 @@\n-                concat(input1, input2, 0),\n-                execute(()-> concat(input1, input2, 0)));\n+                concat(input1, input2),\n+                execute(()-> concat(input1, input2)));\n","filename":"cr-examples\/onnx\/src\/test\/java\/oracle\/code\/onnx\/SimpleTest.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"}]}