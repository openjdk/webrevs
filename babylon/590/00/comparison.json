{"files":[{"patch":"@@ -118,1 +118,0 @@\n-                kernelContext.isSpecific(computeRange.isSpecificRange());\n","filename":"hat\/backends\/ffi\/shared\/src\/main\/java\/hat\/backend\/ffi\/C99FFIBackend.java","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1,57 +0,0 @@\n-\/*\n- * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.  Oracle designates this\n- * particular file as subject to the \"Classpath\" exception as provided\n- * by Oracle in the LICENSE file that accompanied this code.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-package hat;\n-\n-public class CUDARange extends ComputeRange {\n-\n-    public CUDARange(GlobalMesh1D globalMesh) {\n-        super(globalMesh);\n-    }\n-\n-    public CUDARange(GlobalMesh1D globalMesh, LocalMesh1D localMesh) {\n-        super(globalMesh, localMesh);\n-    }\n-\n-    public CUDARange(GlobalMesh2D globalMesh) {\n-        super(globalMesh);\n-    }\n-\n-    public CUDARange(GlobalMesh2D globalMesh, LocalMesh2D localMesh) {\n-        super(globalMesh, localMesh);\n-    }\n-\n-    public CUDARange(GlobalMesh3D globalMesh) {\n-        super(globalMesh);\n-    }\n-\n-    public CUDARange(GlobalMesh3D globalMesh, LocalMesh3D localMesh) {\n-        super(globalMesh, localMesh);\n-    }\n-\n-    @Override\n-    public boolean isSpecificRange() {\n-        return true;\n-    }\n-}\n","filename":"hat\/core\/src\/main\/java\/hat\/CUDARange.java","additions":0,"deletions":57,"binary":false,"changes":57,"status":"deleted"},{"patch":"@@ -28,1 +28,0 @@\n-import hat.CUDARange;\n@@ -197,1 +196,1 @@\n-                arr -> arr.array(\"array\", 64));\n+                arr -> arr.array(\"array\", 16));\n@@ -210,1 +209,1 @@\n-                arr -> arr.array(\"array\", 8));\n+                arr -> arr.array(\"array\", 4));\n@@ -224,1 +223,1 @@\n-     *     different levels of memory hierarchy, such as shared memory (as in CUDA shared memory),\n+     *     different levels of the GPU's memory hierarchy, such as shared memory (as in CUDA shared memory),\n@@ -242,0 +241,8 @@\n+        \/\/ Configuration for the kernel: Keep in mind that if you change the following parameters,\n+        \/\/ also change the scheduling (global and local work sizes).\n+        final int BM = 64;\n+        final int BN = 64;\n+        final int BK = 16;\n+        final int TM = 4;\n+        final int TN = 4;\n+\n@@ -245,7 +252,0 @@\n-        \/\/ Configuration for the kernel\n-        final int BM = 128;\n-        final int BN = 128;\n-        final int BK = 8;\n-        final int TM = 8;    \/\/ Register Block\n-        final int TN = 8;    \/\/ Register block\n-\n@@ -255,4 +255,3 @@\n-        final int limitA = (BN \/ TN);\n-        final int limitB = (BN \/ TN);\n-        final int threadCol = kc.lix % limitA;\n-        final int threadRow = kc.lix \/ limitB;\n+        final int linearLocalId = kc.liy * kc.lsx + kc.lix;\n+        final int threadCol = kc.lix;\n+        final int threadRow = kc.liy;\n@@ -268,2 +267,2 @@\n-        final int innerRowA = kc.lix \/ BK;\n-        final int innerColA = kc.lix % BK;\n+        final int innerRowA = linearLocalId \/ BK;\n+        final int innerColA = linearLocalId % BK;\n@@ -272,2 +271,2 @@\n-        final int innerRowB = kc.lix \/ BN;\n-        final int innerColB = kc.lix % BN;\n+        final int innerRowB = linearLocalId \/ BN;\n+        final int innerColB = linearLocalId % BN;\n@@ -634,1 +633,1 @@\n-        CUDARange cudaRange = new CUDARange(new GlobalMesh2D(8, 8), new LocalMesh2D(256, 1));\n+        ComputeRange cudaRange = new ComputeRange(new GlobalMesh2D(256, 256), new LocalMesh2D(16, 16));\n@@ -726,7 +725,0 @@\n-        IO.println(\"BACKEND: \"  + accelerator.backend.getName());\n-        String backendName = accelerator.backend.getName();\n-\n-        if (configuration == Configuration._2DREGISTER_TILING && !backendName.equals(\"hat.backend.ffi.CudaBackend\")) {\n-            throw new UnsupportedOperationException(\"MxM with 2D Register tiling is only supported on CUDA backend\");\n-        }\n-\n","filename":"hat\/examples\/matmul\/src\/main\/java\/matmul\/Main.java","additions":19,"deletions":27,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+import hat.buffer.Buffer;\n@@ -37,0 +38,1 @@\n+import hat.ifacemapper.Schema;\n","filename":"hat\/tests\/src\/main\/java\/oracle\/code\/hat\/TestArrays.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -37,1 +37,0 @@\n-import hat.ifacemapper.MappableIface;\n@@ -46,0 +45,2 @@\n+import static hat.ifacemapper.MappableIface.*;\n+\n@@ -51,1 +52,1 @@\n-    public static void matrixMultiplyKernel2D(@MappableIface.RO KernelContext kc, @MappableIface.RO F32Array matrixA, @MappableIface.RO F32Array matrixB, @MappableIface.RW F32Array matrixC, int size) {\n+    public static void matrixMultiplyKernel2D(@RO KernelContext kc, @RO F32Array matrixA, @RO F32Array matrixB, @RW F32Array matrixC, int size) {\n@@ -64,1 +65,1 @@\n-    public static void matrixMultiplyKernel2DLI(@MappableIface.RO KernelContext kc, @MappableIface.RO F32Array matrixA, @MappableIface.RO F32Array matrixB, @MappableIface.RW F32Array matrixC, int size) {\n+    public static void matrixMultiplyKernel2DLI(@RO KernelContext kc, @RO F32Array matrixA, @RO F32Array matrixB, @RW F32Array matrixC, int size) {\n@@ -99,1 +100,1 @@\n-    public static void matrixMultiplyKernel2DTiling(@MappableIface.RO KernelContext kc, @MappableIface.RO F32Array matrixA, @MappableIface.RO F32Array matrixB, @MappableIface.RW F32Array matrixC, int size) {\n+    public static void matrixMultiplyKernel2DTiling(@RO KernelContext kc, @RO F32Array matrixA, @RO F32Array matrixB, @RW F32Array matrixC, int size) {\n@@ -141,1 +142,1 @@\n-    public static float compute(@MappableIface.RO KernelContext kc, @MappableIface.RO F32Array matrixA, @MappableIface.RO F32Array matrixB, int size, int j) {\n+    public static float compute(@RO KernelContext kc, @RO F32Array matrixA, @RO F32Array matrixB, int size, int j) {\n@@ -150,1 +151,1 @@\n-    public static void matrixMultiplyKernel1D(@MappableIface.RO KernelContext kc, @MappableIface.RO F32Array matrixA, @MappableIface.RO F32Array matrixB, @MappableIface.RW F32Array matrixC, int size) {\n+    public static void matrixMultiplyKernel1D(@RO KernelContext kc, @RO F32Array matrixA, @RO F32Array matrixB, @RW F32Array matrixC, int size) {\n@@ -163,1 +164,1 @@\n-    public static void matrixMultiplyKernel1DWithFunctionCalls(@MappableIface.RO KernelContext kc, @MappableIface.RO F32Array matrixA, @MappableIface.RO F32Array matrixB, @MappableIface.RW F32Array matrixC, int size) {\n+    public static void matrixMultiplyKernel1DWithFunctionCalls(@RO KernelContext kc, @RO F32Array matrixA, @RO F32Array matrixB, @RW F32Array matrixC, int size) {\n@@ -173,1 +174,1 @@\n-    public static void matrixMultiply1D(@MappableIface.RO ComputeContext cc, @MappableIface.RO F32Array matrixA, @MappableIface.RO F32Array matrixB, @MappableIface.RW F32Array matrixC, int globalSize) {\n+    public static void matrixMultiply1D(@RO ComputeContext cc, @RO F32Array matrixA, @RO F32Array matrixB, @RW F32Array matrixC, int globalSize) {\n@@ -183,1 +184,1 @@\n-    public static void matrixMultiply1DWithFunctionCalls(@MappableIface.RO ComputeContext cc, @MappableIface.RO F32Array matrixA, @MappableIface.RO F32Array matrixB, @MappableIface.RW F32Array matrixC, int size) {\n+    public static void matrixMultiply1DWithFunctionCalls(@RO ComputeContext cc, @RO F32Array matrixA, @RO F32Array matrixB, @RW F32Array matrixC, int size) {\n@@ -191,1 +192,1 @@\n-    public static void matrixMultiply2D(@MappableIface.RO ComputeContext cc, @MappableIface.RO F32Array matrixA, @MappableIface.RO F32Array matrixB, @MappableIface.RW F32Array matrixC, int globalSize) {\n+    public static void matrixMultiply2D(@RO ComputeContext cc, @RO F32Array matrixA, @RO F32Array matrixB, @RW F32Array matrixC, int globalSize) {\n@@ -199,1 +200,1 @@\n-    public static void matrixMultiply2DLI(@MappableIface.RO ComputeContext cc, @MappableIface.RO F32Array matrixA, @MappableIface.RO F32Array matrixB, @MappableIface.RW F32Array matrixC, int globalSize) {\n+    public static void matrixMultiply2DLI(@RO ComputeContext cc, @RO F32Array matrixA, @RO F32Array matrixB, @RW F32Array matrixC, int globalSize) {\n@@ -207,1 +208,1 @@\n-    public static void matrixMultiply2DTiling(@MappableIface.RO ComputeContext cc, @MappableIface.RO F32Array matrixA, @MappableIface.RO F32Array matrixB, @MappableIface.RW F32Array matrixC, int globalSize) {\n+    public static void matrixMultiply2DTiling(@RO ComputeContext cc, @RO F32Array matrixA, @RO F32Array matrixB, @RW F32Array matrixC, int globalSize) {\n@@ -454,1 +455,1 @@\n-    public static void matrixMultiplyKernel2DRegisterTilingPortable(@MappableIface.RO KernelContext kc, @MappableIface.RO F32Array matrixA, @MappableIface.RO F32Array matrixB, @MappableIface.RW F32Array matrixC, int size) {\n+    public static void matrixMultiplyKernel2DRegisterTilingPortable(@RO KernelContext kc, @RO F32Array matrixA, @RO F32Array matrixB, @RW F32Array matrixC, int size) {\n@@ -585,1 +586,1 @@\n-    public static void matrixMultiply2DRegisterTilingPortable(@MappableIface.RO ComputeContext cc, @MappableIface.RO F32Array matrixA, @MappableIface.RO F32Array matrixB, @MappableIface.RW F32Array matrixC, int globalSize) {\n+    public static void matrixMultiply2DRegisterTilingPortable(@RO ComputeContext cc, @RO F32Array matrixA, @RO F32Array matrixB, @RW F32Array matrixC, int globalSize) {\n@@ -625,0 +626,184 @@\n+\n+    private interface SharedMemory extends Buffer {\n+        void array(long index, float value);\n+        float array(long index);\n+        Schema<SharedMemory> schema = Schema.of(SharedMemory.class,\n+                arr -> arr.array(\"array\", 1024));\n+        static SharedMemory create(Accelerator accelerator) {\n+            return schema.allocate(accelerator);\n+        }\n+        static SharedMemory createLocal() {\n+            return schema.allocate(new Accelerator(MethodHandles.lookup(), Backend.FIRST));\n+        }\n+    }\n+\n+    private interface PrivateArray extends Buffer {\n+        void array(long index, float value);\n+        float array(long index);\n+        Schema<PrivateArray> schema = Schema.of(PrivateArray.class,\n+                arr -> arr.array(\"array\", 16));\n+        static PrivateArray create(Accelerator accelerator) {\n+            return schema.allocate(accelerator);\n+        }\n+        static PrivateArray createPrivate() {\n+            return schema.allocate(new Accelerator(MethodHandles.lookup(), Backend.FIRST));\n+        }\n+    }\n+\n+    private interface FlatPrivate extends Buffer {\n+        void array(long index, float value);\n+        float array(long index);\n+        Schema<FlatPrivate> schema = Schema.of(FlatPrivate.class,\n+                arr -> arr.array(\"array\", 4));\n+        static FlatPrivate create(Accelerator accelerator) {\n+            return schema.allocate(accelerator);\n+        }\n+        static FlatPrivate createPrivate() {\n+            return schema.allocate(new Accelerator(MethodHandles.lookup(), Backend.FIRST));\n+        }\n+    }\n+\n+    \/\/ Code ported from the HAT example module.\n+    @CodeReflection\n+    public static void matrixMultiplyKernel2DRegisterTiling(@RO KernelContext kc, @RO F32Array matrixA, @RO F32Array matrixB, @RW F32Array matrixC, int size) {\n+\n+        \/\/ Configuration for the kernel: Keep in mind that if you change the following parameters,\n+        \/\/ also change the scheduling (global and local work sizes).\n+        final int BM = 64;\n+        final int BN = 64;\n+        final int BK = 16;\n+        final int TM = 4;\n+        final int TN = 4;\n+\n+        int bx = kc.bix;\n+        int by = kc.biy;\n+\n+        int totalResultsBlockTile = BM * BN;\n+        final int numThreadsBlockTile = totalResultsBlockTile \/ (TM * TN);\n+\n+        final int linearLocalId = kc.liy * kc.lsx + kc.lix;\n+        final int threadCol = kc.lix;\n+        final int threadRow = kc.liy;\n+\n+        SharedMemory tileA = SharedMemory.createLocal();\n+        SharedMemory tileB = SharedMemory.createLocal();\n+\n+        int aFrom = by * BM * size;\n+        int bFrom = bx * BN;\n+        int v = bx * BN;\n+        int cFrom = (by * BM * size) + (v);\n+\n+        final int innerRowA = linearLocalId \/ BK;\n+        final int innerColA = linearLocalId % BK;\n+\n+        final int strideA = numThreadsBlockTile \/ BK;\n+        final int innerRowB = linearLocalId \/ BN;\n+        final int innerColB = linearLocalId % BN;\n+\n+        int strideB = numThreadsBlockTile \/ BN;\n+\n+        \/\/ Declarations of the arrays in private memory to perform register tiling\n+        PrivateArray threadResults = PrivateArray.createPrivate();\n+        FlatPrivate regM = FlatPrivate.createPrivate();\n+        FlatPrivate regN = FlatPrivate.createPrivate();\n+\n+        \/\/ initialize values\n+        for (int i = 0; i < (TN * TN); i++) {\n+            threadResults.array(i, 0.0f);\n+        }\n+\n+        \/\/ Each thread loops over the tiles\n+        for (int bkIdx = 0; bkIdx < size; bkIdx += BK) {\n+\n+            \/\/ A) Load data into shared memory for array A\n+            for (int loadOffset = 0; loadOffset < BM; loadOffset += strideA) {\n+                tileA.array((innerRowA + loadOffset) * BK + innerColA,\n+                        matrixA.array(((innerRowA + loadOffset) * size + innerColA) + aFrom));\n+            }\n+\n+            \/\/ B) Load data matrixB into shared memory for array B\n+            for (int loadOffset = 0; loadOffset < BK; loadOffset += strideB) {\n+                tileB.array((innerRowB + loadOffset) * BN + innerColB,\n+                        matrixB.array(((innerRowB + loadOffset) * size + innerColB) + bFrom));\n+            }\n+            kc.barrier();\n+\n+            aFrom += (BK);\n+            int f = BK * size;\n+            bFrom += f;\n+\n+            \/\/ Per-thread, we load the data from the shared memory into register for both\n+            \/\/ array A and array B (matrix A and B), and then perform the reduction within\n+            \/\/ the small region in private memory.\n+            for (int dotIdx = 0; dotIdx < BK; dotIdx++) {\n+                \/\/ block into registers\n+                for (int i = 0; i < TM; i++) {\n+                    regM.array(i,  tileA.array((threadRow * TM + i) * BK + dotIdx));\n+                }\n+                for (int i = 0; i < TN; i++) {\n+                    regN.array(i,  tileB.array(dotIdx * BN + threadCol * TN + i));\n+                }\n+                for (int resIdxM = 0; resIdxM < TM; resIdxM++) {\n+                    for (int resIdxN = 0; resIdxN < TN; resIdxN++) {\n+                        float val = regM.array(resIdxM) * regN.array(resIdxN);\n+                        float acc = threadResults.array(resIdxM * TN + resIdxN);\n+                        acc += val;\n+                        threadResults.array((resIdxM * TN + resIdxN), (acc));\n+                    }\n+                }\n+            }\n+            kc.barrier();\n+        }\n+\n+        \/\/ Finally, we store the results of the reductions for the whole 2D register block into global memory.\n+        \/\/ Essentially, each thread compute a small block of TM * TN sub-block size.\n+        for (int resIdxM = 0; resIdxM < TM; resIdxM++) {\n+            for (int resIdxN = 0; resIdxN < TN; resIdxN++) {\n+                float value = threadResults.array(resIdxM * TN + resIdxN);\n+                matrixC.array((((threadRow * TM + resIdxM) * size + threadCol * TN + resIdxN) + (cFrom)), value);\n+            }\n+        }\n+    }\n+\n+    @CodeReflection\n+    public static void matrixMultiply2DRegisterTiling(@RO ComputeContext cc, @RO F32Array matrixA, @RO F32Array matrixB, @RW  F32Array matrixC, final int size) {\n+        ComputeRange cudaRange = new ComputeRange(new GlobalMesh2D(256, 256), new LocalMesh2D(16, 16));\n+        cc.dispatchKernel(cudaRange,\n+                kc -> matrixMultiplyKernel2DRegisterTiling(kc, matrixA, matrixB, matrixC, size)\n+        );\n+    }\n+\n+\n+    @HatTest\n+    public void testMatMul2DRegisterTilingV2() {\n+        var lookup = java.lang.invoke.MethodHandles.lookup();\n+        var accelerator = new Accelerator(lookup, Backend.FIRST);\n+\n+        final int size = 1024;\n+        var matrixA = F32Array.create(accelerator, size * size);\n+        var matrixB = F32Array.create(accelerator, size * size);\n+\n+        \/\/ Matrix for the results\n+        var matrixC = F32Array.create(accelerator, size * size);\n+        var resultSeq = F32Array.create(accelerator, size * size);\n+\n+        \/\/ Initialize matrices (A and B have the same size)\n+        Random r = new Random(19);\n+\n+        for (int j = 0; j < matrixA.length(); j++) {\n+            matrixA.array(j, r.nextFloat());\n+            matrixB.array(j, r.nextFloat());\n+        }\n+\n+        accelerator.compute(cc ->\n+                TestMatMul.matrixMultiply2DRegisterTiling(cc, matrixA, matrixB, matrixC, size));\n+\n+        \/\/ Run Seq for reference\n+        runSequential(matrixA, matrixB, resultSeq, size);\n+\n+        for (int j = 0; j < size; j++) {\n+            for (int i = 0; i < size; i++) {\n+                HatAsserts.assertEquals(resultSeq.array(i * size + j), matrixC.array(i * size + j), 0.01f);\n+            }\n+        }\n+    }\n","filename":"hat\/tests\/src\/main\/java\/oracle\/code\/hat\/TestMatMul.java","additions":199,"deletions":14,"binary":false,"changes":213,"status":"modified"}]}