{"files":[{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2022, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -34,6 +34,0 @@\n-      apt-gcc-version:\n-        required: true\n-        type: string\n-      apt-gcc-cross-version:\n-        required: true\n-        type: string\n@@ -70,0 +64,1 @@\n+            tolerate-sysroot-errors: false\n@@ -75,0 +70,1 @@\n+            tolerate-sysroot-errors: false\n@@ -76,15 +72,18 @@\n-          # - target-cpu: s390x\n-          #   gnu-arch: s390x\n-          #   debian-arch: s390x\n-          #   debian-repository: https:\/\/httpredir.debian.org\/debian\/\n-          #   debian-version: bullseye\n-          # - target-cpu: ppc64le\n-          #   gnu-arch: powerpc64le\n-          #   debian-arch: ppc64el\n-          #   debian-repository: https:\/\/httpredir.debian.org\/debian\/\n-          #   debian-version: bullseye\n-          # - target-cpu: riscv64\n-          #   gnu-arch: riscv64\n-          #   debian-arch: riscv64\n-          #   debian-repository: https:\/\/httpredir.debian.org\/debian\/\n-          #   debian-version: sid\n+#          - target-cpu: s390x\n+#            gnu-arch: s390x\n+#            debian-arch: s390x\n+#            debian-repository: https:\/\/httpredir.debian.org\/debian\/\n+#            debian-version: bullseye\n+#            tolerate-sysroot-errors: false\n+#          - target-cpu: ppc64le\n+#            gnu-arch: powerpc64le\n+#            debian-arch: ppc64el\n+#            debian-repository: https:\/\/httpredir.debian.org\/debian\/\n+#            debian-version: bullseye\n+#            tolerate-sysroot-errors: false\n+#          - target-cpu: riscv64\n+#            gnu-arch: riscv64\n+#            debian-arch: riscv64\n+#            debian-repository: https:\/\/httpredir.debian.org\/debian\/\n+#            debian-version: sid\n+#            tolerate-sysroot-errors: true\n@@ -94,1 +93,1 @@\n-        uses: actions\/checkout@v3\n+        uses: actions\/checkout@v4\n@@ -102,6 +101,3 @@\n-        # Use linux-x64 JDK bundle as build JDK\n-      - name: 'Get build JDK'\n-        id: buildjdk\n-        uses: .\/.github\/actions\/get-bundles\n-        with:\n-          platform: linux-x64\n+      - name: 'Get GTest'\n+        id: gtest\n+        uses: .\/.github\/actions\/get-gtest\n@@ -116,6 +112,5 @@\n-              gcc-${{ inputs.gcc-major-version }}=${{ inputs.apt-gcc-version }} \\\n-              g++-${{ inputs.gcc-major-version }}=${{ inputs.apt-gcc-version }} \\\n-              gcc-${{ inputs.gcc-major-version }}-${{ matrix.gnu-arch }}-linux-gnu${{ matrix.gnu-abi}}=${{ inputs.apt-gcc-cross-version }} \\\n-              g++-${{ inputs.gcc-major-version }}-${{ matrix.gnu-arch }}-linux-gnu${{ matrix.gnu-abi}}=${{ inputs.apt-gcc-cross-version }} \\\n-              libxrandr-dev libxtst-dev libcups2-dev libasound2-dev \\\n-              debian-ports-archive-keyring\n+              gcc-${{ inputs.gcc-major-version }} \\\n+              g++-${{ inputs.gcc-major-version }} \\\n+              gcc-${{ inputs.gcc-major-version }}-${{ matrix.gnu-arch }}-linux-gnu${{ matrix.gnu-abi}} \\\n+              g++-${{ inputs.gcc-major-version }}-${{ matrix.gnu-arch }}-linux-gnu${{ matrix.gnu-abi}} \\\n+              libxrandr-dev libxtst-dev libcups2-dev libasound2-dev\n@@ -126,1 +121,1 @@\n-        uses: actions\/cache@v3\n+        uses: actions\/cache@v4\n@@ -136,0 +131,1 @@\n+        id: create-sysroot\n@@ -140,1 +136,1 @@\n-          --include=fakeroot,symlinks,build-essential,libx11-dev,libxext-dev,libxrender-dev,libxrandr-dev,libxtst-dev,libxt-dev,libcups2-dev,libfontconfig1-dev,libasound2-dev,libfreetype6-dev,libpng-dev\n+          --include=fakeroot,symlinks,build-essential,libx11-dev,libxext-dev,libxrender-dev,libxrandr-dev,libxtst-dev,libxt-dev,libcups2-dev,libfontconfig1-dev,libasound2-dev,libfreetype-dev,libpng-dev\n@@ -143,1 +139,0 @@\n-          $(test -n \"${{ matrix.debian-keyring }}\" && echo \"--keyring=${{ matrix.debian-keyring }}\")\n@@ -147,0 +142,1 @@\n+        continue-on-error: ${{ matrix.tolerate-sysroot-errors }}\n@@ -156,2 +152,8 @@\n-          rm -rf sysroot\/usr\/lib\/{apt,udev,systemd}\n-        if: steps.get-cached-sysroot.outputs.cache-hit != 'true'\n+          rm -rf sysroot\/usr\/lib\/{apt,gcc,udev,systemd}\n+          rm -rf sysroot\/usr\/libexec\/gcc\n+        if: steps.create-sysroot.outcome == 'success' && steps.get-cached-sysroot.outputs.cache-hit != 'true'\n+\n+      - name: 'Remove broken sysroot'\n+        run: |\n+          sudo rm -rf sysroot\/\n+        if: steps.create-sysroot.outcome != 'success' && steps.get-cached-sysroot.outputs.cache-hit != 'true'\n@@ -165,0 +167,1 @@\n+          --with-gtest=${{ steps.gtest.outputs.path }}\n@@ -170,1 +173,0 @@\n-          --with-build-jdk=${{ steps.buildjdk.outputs.jdk-path }}\n@@ -178,0 +180,1 @@\n+        if: steps.create-sysroot.outcome == 'success' || steps.get-cached-sysroot.outputs.cache-hit == 'true'\n@@ -185,0 +188,1 @@\n+        if: steps.create-sysroot.outcome == 'success' || steps.get-cached-sysroot.outputs.cache-hit == 'true'\n","filename":".github\/workflows\/build-cross-compile.yml","additions":45,"deletions":41,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2022, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -64,1 +64,4 @@\n-          - 'hs\/tier1 compiler'\n+          - 'hs\/tier1 compiler part 1'\n+          - 'hs\/tier1 compiler part 2'\n+          - 'hs\/tier1 compiler part 3'\n+          - 'hs\/tier1 compiler not-xcomp'\n@@ -90,2 +93,14 @@\n-          - test-name: 'hs\/tier1 compiler'\n-            test-suite: 'test\/hotspot\/jtreg\/:tier1_compiler'\n+          - test-name: 'hs\/tier1 compiler part 1'\n+            test-suite: 'test\/hotspot\/jtreg\/:tier1_compiler_1'\n+            debug-suffix: -debug\n+\n+          - test-name: 'hs\/tier1 compiler part 2'\n+            test-suite: 'test\/hotspot\/jtreg\/:tier1_compiler_2'\n+            debug-suffix: -debug\n+\n+          - test-name: 'hs\/tier1 compiler part 3'\n+            test-suite: 'test\/hotspot\/jtreg\/:tier1_compiler_3'\n+            debug-suffix: -debug\n+\n+          - test-name: 'hs\/tier1 compiler not-xcomp'\n+            test-suite: 'test\/hotspot\/jtreg\/:tier1_compiler_not_xcomp'\n@@ -112,1 +127,1 @@\n-        uses: actions\/checkout@v3\n+        uses: actions\/checkout@v4\n@@ -139,1 +154,1 @@\n-          sudo xcode-select --switch \/Applications\/Xcode_11.7.app\/Contents\/Developer\n+          sudo xcode-select --switch \/Applications\/Xcode_14.3.1.app\/Contents\/Developer\n@@ -209,1 +224,1 @@\n-        uses: actions\/upload-artifact@v3\n+        uses: actions\/upload-artifact@v4\n@@ -217,1 +232,1 @@\n-        uses: actions\/github-script@v6\n+        uses: actions\/github-script@v7\n","filename":".github\/workflows\/test.yml","additions":23,"deletions":8,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -4,1 +4,1 @@\n-version=22\n+version=23\n","filename":".jcheck\/conf","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2011, 2020, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2011, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -34,0 +34,2 @@\n+\n+include CopyFiles.gmk\n@@ -35,1 +37,0 @@\n-include NativeCompilation.gmk\n@@ -61,1 +62,1 @@\n-  SOURCE_FILES := $(TOPDIR)\/make\/data\/mainmanifest\/manifest.mf, \\\n+  SOURCE_FILES := $(TOPDIR)\/make\/data\/mainmanifest\/manifest.mf.template, \\\n@@ -185,1 +186,1 @@\n-    DISABLED_WARNINGS := rawtypes deprecation unchecked serial cast this-escape, \\\n+    DISABLED_WARNINGS := rawtypes deprecation unchecked serial cast this-escape dangling-doc-comments, \\\n@@ -218,1 +219,1 @@\n-    DISABLED_WARNINGS := rawtypes unchecked deprecation this-escape, \\\n+    DISABLED_WARNINGS := rawtypes unchecked deprecation this-escape dangling-doc-comments, \\\n","filename":"make\/CompileDemos.gmk","additions":6,"deletions":5,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -29,0 +29,2 @@\n+\n+include CopyFiles.gmk\n@@ -69,5 +71,0 @@\n-    -tag beaninfo:X \\\n-    -tag revised:X \\\n-    -tag since.unbundled:X \\\n-    -tag Note:X \\\n-    -tag ToDo:X \\\n@@ -148,5 +145,0 @@\n-\n-  # Workaround stylesheet bug\n-  HEADER_STYLE := style=\"margin-top: 9px;\"\n-else\n-  HEADER_STYLE := style=\"margin-top: 14px;\"\n@@ -348,1 +340,1 @@\n-  $1_HEADER_TITLE := <div $$(HEADER_STYLE)><strong>$$($1_SHORT_NAME)<\/strong> \\\n+  $1_HEADER_TITLE := <div><strong>$$($1_SHORT_NAME)<\/strong> \\\n@@ -656,1 +648,1 @@\n-  HEADER_RIGHT_SIDE_INFO := <strong>$(subst &amp;,&,$(JDK_SHORT_NAME))$(DRAFT_MARKER_STR)<\/strong>\n+  HEADER_RIGHT_SIDE_INFO := <strong>$(subst &amp;,&,$(JDK_SHORT_NAME))<\/strong>$(DRAFT_MARKER_STR)\n@@ -693,22 +685,19 @@\n-    $(eval MAN_$m := $(call FindModuleManDirs, $m)) \\\n-    $(foreach d, $(MAN_$m), \\\n-      $(foreach f, $(call ApplySpecFilter, $(filter %.md, $(call FindFiles, $d))), \\\n-        $(eval $m_$f_NAME := MAN_TO_HTML_$m_$(strip $(call RelativePath, $f, $(TOPDIR)))) \\\n-        $(eval $(call SetupProcessMarkdown, $($m_$f_NAME), \\\n-            SRC := $d, \\\n-            FILES := $f, \\\n-            DEST := $(DOCS_OUTPUTDIR)\/specs\/man, \\\n-            FILTER := $(PANDOC_HTML_MANPAGE_FILTER), \\\n-            CSS := $(GLOBAL_SPECS_DEFAULT_CSS_FILE), \\\n-            REPLACEMENTS := \\\n-\t\t@@COPYRIGHT_YEAR@@ => $(COPYRIGHT_YEAR) ; \\\n-\t\t@@VERSION_SHORT@@ => $(VERSION_SHORT) ; \\\n-\t\t@@VERSION_SPECIFICATION@@ => $(VERSION_SPECIFICATION), \\\n-            OPTIONS := --toc -V include-before='$(SPECS_TOP)' -V include-after='$(SPECS_BOTTOM_1)', \\\n-            POST_PROCESS := $(TOOL_FIXUPPANDOC) --insert-nav --nav-right-info '$(HEADER_RIGHT_SIDE_INFO)' \\\n-                --nav-subdirs 1 --nav-link-guides, \\\n-            EXTRA_DEPS := $(PANDOC_HTML_MANPAGE_FILTER) \\\n-                $(PANDOC_HTML_MANPAGE_FILTER_SOURCE), \\\n-        )) \\\n-        $(eval JDK_SPECS_TARGETS += $($($m_$f_NAME))) \\\n-      ) \\\n+    $(eval MAN_$m := $(call ApplySpecFilter, $(filter %.md, $(call FindFiles, \\\n+          $(call FindModuleManDirs, $m))))) \\\n+    $(if $(MAN_$m), \\\n+      $(eval $(call SetupProcessMarkdown, MAN_TO_HTML_$m, \\\n+        FILES := $(MAN_$m), \\\n+        DEST := $(DOCS_OUTPUTDIR)\/specs\/man, \\\n+        FILTER := $(PANDOC_HTML_MANPAGE_FILTER), \\\n+        CSS := $(GLOBAL_SPECS_DEFAULT_CSS_FILE), \\\n+        REPLACEMENTS := \\\n+            @@COPYRIGHT_YEAR@@ => $(COPYRIGHT_YEAR) ; \\\n+            @@VERSION_SHORT@@ => $(VERSION_SHORT) ; \\\n+            @@VERSION_SPECIFICATION@@ => $(VERSION_SPECIFICATION), \\\n+        OPTIONS := --toc -V include-before='$(SPECS_TOP)' -V include-after='$(SPECS_BOTTOM_1)', \\\n+        POST_PROCESS := $(TOOL_FIXUPPANDOC) --insert-nav --nav-right-info '$(HEADER_RIGHT_SIDE_INFO)' \\\n+            --nav-subdirs 1 --nav-link-guides, \\\n+        EXTRA_DEPS := $(PANDOC_HTML_MANPAGE_FILTER) \\\n+            $(PANDOC_HTML_MANPAGE_FILTER_SOURCE), \\\n+      )) \\\n+      $(eval JDK_SPECS_TARGETS += $(MAN_TO_HTML_$m)) \\\n","filename":"make\/Docs.gmk","additions":23,"deletions":34,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -0,0 +1,36 @@\n+#\n+# Copyright (c) 2011, 2014, Oracle and\/or its affiliates. All rights reserved.\n+# DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+#\n+# This code is free software; you can redistribute it and\/or modify it\n+# under the terms of the GNU General Public License version 2 only, as\n+# published by the Free Software Foundation.\n+#\n+# This code is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+# version 2 for more details (a copy is included in the LICENSE file that\n+# accompanied this code).\n+#\n+# You should have received a copy of the GNU General Public License version\n+# 2 along with this work; if not, write to the Free Software Foundation,\n+# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+#\n+# Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+# or visit www.oracle.com if you need additional information or have any\n+# questions.\n+#\n+\n+AsyncGetCallTrace\n+jio_fprintf\n+jio_printf\n+jio_snprintf\n+jio_vfprintf\n+jio_vsnprintf\n+JNI_CreateJavaVM\n+JNI_GetCreatedJavaVMs\n+JNI_GetDefaultJavaVMInitArgs\n+JVM_IsForeignLinkerSupported\n+JVM_FindClassFromBootLoader\n+JVM_InitAgentProperties\n+JVM_Checkpoint\n","filename":"make\/autoconf\/Makefile.template","additions":36,"deletions":0,"binary":false,"changes":36,"status":"added"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2011, 2023, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2011, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -49,1 +49,1 @@\n-    serialgc services shenandoahgc static-build vm-structs zero zgc \\\n+    serialgc services shenandoahgc vm-structs zero zgc \\\n@@ -313,16 +313,0 @@\n-###############################################################################\n-# Check if the feature 'static-build' is available on this platform.\n-#\n-AC_DEFUN_ONCE([JVM_FEATURES_CHECK_STATIC_BUILD],\n-[\n-  JVM_FEATURES_CHECK_AVAILABILITY(static-build, [\n-    AC_MSG_CHECKING([if static-build is enabled in configure])\n-    if test \"x$STATIC_BUILD\" = \"xtrue\"; then\n-      AC_MSG_RESULT([yes])\n-    else\n-      AC_MSG_RESULT([no, use --enable-static-build to enable static build.])\n-      AVAILABLE=false\n-    fi\n-  ])\n-])\n-\n@@ -421,1 +405,0 @@\n-  JVM_FEATURES_CHECK_STATIC_BUILD\n","filename":"make\/autoconf\/jvm-features.m4","additions":2,"deletions":19,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,2 +28,2 @@\n-GTEST_VERSION=1.13.0\n-JTREG_VERSION=7.3+1\n+GTEST_VERSION=1.14.0\n+JTREG_VERSION=7.3.1+1\n@@ -32,2 +32,2 @@\n-LINUX_X64_BOOT_JDK_URL=https:\/\/download.java.net\/java\/GA\/jdk20\/bdc68b4b9cbc4ebcb30745c85038d91d\/36\/GPL\/openjdk-20_linux-x64_bin.tar.gz\n-LINUX_X64_BOOT_JDK_SHA256=bb863b2d542976d1ae4b7b81af3e78b1e4247a64644350b552d298d8dc5980dc\n+LINUX_X64_BOOT_JDK_URL=https:\/\/download.java.net\/java\/GA\/jdk22\/830ec9fcccef480bb3e73fb7ecafe059\/36\/GPL\/openjdk-22_linux-x64_bin.tar.gz\n+LINUX_X64_BOOT_JDK_SHA256=4d65cc6ed28711768fd72c2043a7925f7c83f5f51bb64970bd9d52f7791fc6ac\n@@ -40,2 +40,6 @@\n-MACOS_X64_BOOT_JDK_URL=https:\/\/download.java.net\/java\/GA\/jdk20\/bdc68b4b9cbc4ebcb30745c85038d91d\/36\/GPL\/openjdk-20_macos-x64_bin.tar.gz\n-MACOS_X64_BOOT_JDK_SHA256=47cf960d9bb89dbe987535a389f7e26c42de7c984ef5108612d77c81aa8cc6a4\n+MACOS_X64_BOOT_JDK_URL=https:\/\/download.java.net\/java\/GA\/jdk22\/830ec9fcccef480bb3e73fb7ecafe059\/36\/GPL\/openjdk-22_macos-x64_bin.tar.gz\n+MACOS_X64_BOOT_JDK_SHA256=ae31fe10916429e3fe284266095067a5ce9fecbdc03ff1a079d20459f731ca36\n+\n+MACOS_AARCH64_BOOT_JDK_EXT=tar.gz\n+MACOS_AARCH64_BOOT_JDK_URL=https:\/\/download.java.net\/java\/GA\/jdk22\/830ec9fcccef480bb3e73fb7ecafe059\/36\/GPL\/openjdk-22_macos-aarch64_bin.tar.gz\n+MACOS_AARCH64_BOOT_JDK_SHA256=d10f82429d01047968c52c7975c326388cb5d212791e14c1de21c987463a4b53\n@@ -44,2 +48,2 @@\n-WINDOWS_X64_BOOT_JDK_URL=https:\/\/download.java.net\/java\/GA\/jdk20\/bdc68b4b9cbc4ebcb30745c85038d91d\/36\/GPL\/openjdk-20_windows-x64_bin.zip\n-WINDOWS_X64_BOOT_JDK_SHA256=c92fae5e42b9aecf444a66c8ec563c652f60b1e231dfdd33a4f5a3e3603058fb\n+WINDOWS_X64_BOOT_JDK_URL=https:\/\/download.java.net\/java\/GA\/jdk22\/830ec9fcccef480bb3e73fb7ecafe059\/36\/GPL\/openjdk-22_windows-x64_bin.zip\n+WINDOWS_X64_BOOT_JDK_SHA256=8f5138fecb53c08c20abd4fa6812f9400051f3852582a2142ffda0dff73a5824\n","filename":"make\/conf\/github-actions.conf","additions":13,"deletions":9,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2013, 2022, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2013, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -81,4 +81,0 @@\n-ifeq ($(call check-jvm-feature, static-build), true)\n-  JVM_CFLAGS_FEATURES += -DSTATIC_BUILD=1\n-endif\n-\n@@ -221,1 +217,0 @@\n-      genMarkSweep.cpp \\\n","filename":"make\/hotspot\/lib\/JvmFeatures.gmk","additions":1,"deletions":6,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2011, 2020, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2011, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,1 +31,2 @@\n-JAVA_VERSION_INFO_RESOURCE := $(TOPDIR)\/src\/java.base\/windows\/native\/launcher\/java.rc\n+JAVA_VERSION_INFO_RESOURCE := \\\n+    $(TOPDIR)\/src\/java.base\/windows\/native\/launcher\/java.rc\n@@ -35,0 +36,2 @@\n+################################################################################\n+## Build java\n@@ -44,0 +47,4 @@\n+################################################################################\n+## Build javaw\n+################################################################################\n+\n@@ -52,0 +59,4 @@\n+################################################################################\n+## Build keytool\n+################################################################################\n+\n@@ -56,2 +67,4 @@\n-################################################################################\n-\n+  ##############################################################################\n+  ## Build jexec\n+  ##############################################################################\n+\n@@ -62,3 +75,1 @@\n-      INCLUDE_FILES := jexec.c, \\\n-      CFLAGS := $(CFLAGS_JDKEXE) \\\n-          -I$(TOPDIR)\/src\/$(MODULE)\/share\/native\/libjli, \\\n+      EXTRA_HEADER_DIRS := libjli, \\\n@@ -67,1 +78,1 @@\n-      LDFLAGS := $(LDFLAGS_JDKEXE), \\\n+      LD_SET_ORIGIN := false, \\\n@@ -74,1 +85,4 @@\n-################################################################################\n+ifeq ($(call isTargetOsType, unix), true)\n+  ##############################################################################\n+  ## Build jspawnhelper\n+  ##############################################################################\n@@ -76,1 +90,0 @@\n-ifeq ($(call isTargetOs, macosx aix linux), true)\n@@ -79,4 +92,5 @@\n-      SRC := $(TOPDIR)\/src\/$(MODULE)\/unix\/native\/jspawnhelper, \\\n-      CFLAGS := $(CFLAGS_JDKEXE) -I$(TOPDIR)\/src\/$(MODULE)\/unix\/native\/libjava, \\\n-      EXTRA_OBJECT_FILES := $(SUPPORT_OUTPUTDIR)\/native\/$(MODULE)\/libjava\/childproc$(OBJ_SUFFIX), \\\n-      LDFLAGS := $(LDFLAGS_JDKEXE), \\\n+      CFLAGS := $(VERSION_CFLAGS), \\\n+      EXTRA_HEADER_DIRS := libjava, \\\n+      EXTRA_OBJECT_FILES := \\\n+          $(SUPPORT_OUTPUTDIR)\/native\/$(MODULE)\/libjava\/childproc$(OBJ_SUFFIX), \\\n+      LD_SET_ORIGIN := false, \\\n","filename":"make\/modules\/java.base\/Launcher.gmk","additions":28,"deletions":14,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -26,0 +26,6 @@\n+################################################################################\n+# This file builds the Java components of testlib.\n+# It also covers the test-image part, where the built files are copied to the\n+# test image.\n+################################################################################\n+\n@@ -30,0 +36,2 @@\n+\n+include CopyFiles.gmk\n@@ -32,0 +40,4 @@\n+################################################################################\n+# Targets for building the test lib jars\n+################################################################################\n+\n@@ -51,1 +63,1 @@\n-    EXCLUDES := jdk\/test\/lib\/containers jdk\/test\/lib\/security, \\\n+    EXCLUDES := jdk\/test\/lib\/containers\/cgroup jdk\/test\/lib\/security, \\\n@@ -55,1 +67,1 @@\n-    DISABLED_WARNINGS := try deprecation rawtypes unchecked serial cast removal preview, \\\n+    DISABLED_WARNINGS := try deprecation rawtypes unchecked serial cast removal preview dangling-doc-comments, \\\n@@ -66,1 +78,14 @@\n-##########################################################################################\n+build-test-lib: $(TARGETS)\n+\n+################################################################################\n+# Targets for building test-image.\n+################################################################################\n+\n+# Copy the jars to the test image.\n+$(eval $(call SetupCopyFiles, COPY_LIBTEST_JARS, \\\n+    DEST := $(TEST_IMAGE_DIR)\/lib-test, \\\n+    FILES := $(BUILD_WB_JAR_JAR) $(BUILD_TEST_LIB_JAR_JAR), \\\n+))\n+#\n+\n+test-image-lib: $(COPY_LIBTEST_JARS)\n@@ -68,1 +93,1 @@\n-all: $(TARGETS)\n+all: build-test-lib\n@@ -70,1 +95,1 @@\n-.PHONY: default all\n+.PHONY: default all build-test-lib test-image-lib\n","filename":"make\/test\/BuildTestLib.gmk","additions":30,"deletions":5,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -115,1 +115,2 @@\n-    CPU_MODEL_AMPERE_1A = 0xac4  \/* CPU implementer is CPU_AMPERE *\/\n+    CPU_MODEL_AMPERE_1A = 0xac4, \/* CPU implementer is CPU_AMPERE *\/\n+    CPU_MODEL_AMPERE_1B = 0xac5  \/* AMPERE_1B core Implements ARMv8.7 with CSSC, MTE, SM3\/SM4 extensions *\/\n@@ -170,0 +171,1 @@\n+  \/\/ Aarch64 supports fast class initialization checks\n@@ -172,0 +174,3 @@\n+  constexpr static bool supports_recursive_lightweight_locking() { return true; }\n+\n+  constexpr static bool supports_secondary_supers_table() { return true; }\n","filename":"src\/hotspot\/cpu\/aarch64\/vm_version_aarch64.hpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -112,0 +112,2 @@\n+\n+  static bool profile_all_receivers_at_type_check() { return false; }\n","filename":"src\/hotspot\/cpu\/arm\/vm_version_arm.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -96,1 +96,1 @@\n-  \/\/ PPC64 supports fast class initialization checks for static methods.\n+  \/\/ PPC64 supports fast class initialization checks\n@@ -99,0 +99,1 @@\n+  constexpr static bool supports_recursive_lightweight_locking() { return true; }\n","filename":"src\/hotspot\/cpu\/ppc\/vm_version_ppc.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -43,0 +43,6 @@\n+\n+  \/\/ JEDEC encoded as ((bank - 1) << 7) | (0x7f & JEDEC)\n+  enum VendorId {\n+    RIVOS = 0x6cf, \/\/ JEDEC: 0x4f, Bank: 14\n+  };\n+\n@@ -58,0 +64,4 @@\n+    void disable_feature() {\n+      _enabled = false;\n+      _value = -1;\n+    }\n@@ -66,7 +76,12 @@\n-  #define UPDATE_DEFAULT(flag)        \\\n-  void update_flag() {                \\\n-      assert(enabled(), \"Must be.\");  \\\n-      if (FLAG_IS_DEFAULT(flag)) {    \\\n-        FLAG_SET_DEFAULT(flag, true); \\\n-      }                               \\\n-  }                                   \\\n+  #define UPDATE_DEFAULT(flag)             \\\n+  void update_flag() {                     \\\n+      assert(enabled(), \"Must be.\");       \\\n+      if (FLAG_IS_DEFAULT(flag)) {         \\\n+        FLAG_SET_DEFAULT(flag, true);      \\\n+      } else {                             \\\n+        \/* Sync CPU features with flags *\/ \\\n+        if (!flag) {                       \\\n+          disable_feature();               \\\n+        }                                  \\\n+      }                                    \\\n+  }                                        \\\n@@ -74,2 +89,2 @@\n-  #define NO_UPDATE_DEFAULT           \\\n-  void update_flag() {}               \\\n+  #define NO_UPDATE_DEFAULT                \\\n+  void update_flag() {}                    \\\n@@ -102,0 +117,2 @@\n+  \/\/ Zfh Half-Precision Floating-Point instructions\n+  \/\/\n@@ -107,0 +124,3 @@\n+  \/\/ Zc  Code Size Reduction - Additional compressed instructions.\n+  \/\/ Zcb Simple code-size saving instructions\n+  \/\/\n@@ -114,0 +134,2 @@\n+ public:\n+\n@@ -134,0 +156,2 @@\n+  decl(ext_Zcb         , \"Zcb\"         , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZcb))         \\\n+  decl(ext_Zfh         , \"Zfh\"         , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZfh))         \\\n@@ -137,0 +161,1 @@\n+  decl(ext_Ztso        , \"Ztso\"        , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZtso))        \\\n@@ -138,0 +163,4 @@\n+  decl(ext_Zacas       , \"Zacas\"       , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZacas))       \\\n+  decl(ext_Zvbb        , \"Zvbb\"        , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZvbb))        \\\n+  decl(ext_Zvfh        , \"Zvfh\"        , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZvfh))        \\\n+  decl(ext_Zvkn        , \"Zvkn\"        , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZvkn))        \\\n@@ -155,0 +184,46 @@\n+  \/\/ enable extensions based on profile, current supported profiles:\n+  \/\/  RVA20U64\n+  \/\/  RVA22U64\n+  \/\/  RVA23U64\n+  \/\/ NOTE: we only enable the mandatory extensions, not optional extension.\n+  #define RV_ENABLE_EXTENSION(UseExtension)     \\\n+    if (FLAG_IS_DEFAULT(UseExtension)) {        \\\n+      FLAG_SET_DEFAULT(UseExtension, true);     \\\n+    }                                           \\\n+\n+  \/\/ https:\/\/github.com\/riscv\/riscv-profiles\/blob\/main\/profiles.adoc#rva20-profiles\n+  #define RV_USE_RVA20U64                            \\\n+    RV_ENABLE_EXTENSION(UseRVC)                      \\\n+\n+  static void useRVA20U64Profile();\n+\n+  \/\/ https:\/\/github.com\/riscv\/riscv-profiles\/blob\/main\/profiles.adoc#rva22-profiles\n+  #define RV_USE_RVA22U64                            \\\n+    RV_ENABLE_EXTENSION(UseRVC)                      \\\n+    RV_ENABLE_EXTENSION(UseZba)                      \\\n+    RV_ENABLE_EXTENSION(UseZbb)                      \\\n+    RV_ENABLE_EXTENSION(UseZbs)                      \\\n+    RV_ENABLE_EXTENSION(UseZic64b)                   \\\n+    RV_ENABLE_EXTENSION(UseZicbom)                   \\\n+    RV_ENABLE_EXTENSION(UseZicbop)                   \\\n+    RV_ENABLE_EXTENSION(UseZicboz)                   \\\n+    RV_ENABLE_EXTENSION(UseZihintpause)              \\\n+\n+  static void useRVA22U64Profile();\n+\n+  \/\/ https:\/\/github.com\/riscv\/riscv-profiles\/blob\/main\/rva23-profile.adoc#rva23u64-profile\n+  #define RV_USE_RVA23U64                           \\\n+    RV_ENABLE_EXTENSION(UseRVC)                     \\\n+    RV_ENABLE_EXTENSION(UseRVV)                     \\\n+    RV_ENABLE_EXTENSION(UseZba)                     \\\n+    RV_ENABLE_EXTENSION(UseZbb)                     \\\n+    RV_ENABLE_EXTENSION(UseZbs)                     \\\n+    RV_ENABLE_EXTENSION(UseZcb)                     \\\n+    RV_ENABLE_EXTENSION(UseZic64b)                  \\\n+    RV_ENABLE_EXTENSION(UseZicbom)                  \\\n+    RV_ENABLE_EXTENSION(UseZicbop)                  \\\n+    RV_ENABLE_EXTENSION(UseZicboz)                  \\\n+    RV_ENABLE_EXTENSION(UseZihintpause)             \\\n+\n+  static void useRVA23U64Profile();\n+\n@@ -205,0 +280,2 @@\n+  constexpr static bool supports_recursive_lightweight_locking() { return true; }\n+\n@@ -206,0 +283,3 @@\n+\n+  \/\/ RISCV64 supports fast class initialization checks\n+  static bool supports_fast_class_init_checks() { return true; }\n","filename":"src\/hotspot\/cpu\/riscv\/vm_version_riscv.hpp","additions":89,"deletions":9,"binary":false,"changes":98,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 2016, 2022, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2016, 2022 SAP SE. All rights reserved.\n+ * Copyright (c) 2016, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2024 SAP SE. All rights reserved.\n@@ -415,1 +415,1 @@\n-  \/\/ s390 supports fast class initialization checks for static methods.\n+  \/\/ s390 supports fast class initialization checks\n","filename":"src\/hotspot\/cpu\/s390\/vm_version_s390.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -101,1 +101,0 @@\n-                   notproduct,                                              \\\n@@ -157,1 +156,2 @@\n-          \"Enable RTM lock eliding for inflated locks in compiled code\")    \\\n+          \"(Deprecated) Enable RTM lock eliding for inflated locks \"        \\\n+          \"in compiled code\")                                               \\\n@@ -163,1 +163,2 @@\n-          \"Perform deopt and recompilation based on RTM abort ratio\")       \\\n+          \"(Deprecated) Perform deopt and recompilation based on \"          \\\n+          \"RTM abort ratio\")                                                \\\n@@ -166,1 +167,1 @@\n-          \"Number of RTM retries on lock abort or busy\")                    \\\n+          \"(Deprecated) Number of RTM retries on lock abort or busy\")       \\\n@@ -217,0 +218,4 @@\n+  \/* Autodetected, see vm_version_x86.cpp *\/                                \\\n+  product(bool, EnableX86ECoreOpts, false, DIAGNOSTIC,                      \\\n+          \"Perform Ecore Optimization\")                                     \\\n+                                                                            \\\n@@ -232,0 +237,3 @@\n+  product(bool, UseAPX, false, EXPERIMENTAL,                                \\\n+          \"Use Advanced Performance Extensions on x86\")                     \\\n+                                                                            \\\n","filename":"src\/hotspot\/cpu\/x86\/globals_x86.hpp","additions":13,"deletions":5,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -41,0 +41,1 @@\n+#include \"utilities\/checkedCast.hpp\"\n@@ -311,1 +312,1 @@\n-\n+    \/\/ ECX = 0\n@@ -320,0 +321,7 @@\n+    \/\/ ECX = 1\n+    __ movl(rax, 7);\n+    __ movl(rcx, 1);\n+    __ cpuid();\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::sef_cpuid7_ecx1_offset())));\n+    __ movl(Address(rsi, 0), rax);\n+\n@@ -1273,1 +1281,2 @@\n-    _features = _cpuid_info.feature_flags();\n+    _features = _cpuid_info.feature_flags(); \/\/ These can be changed by VM settings\n+    _cpu_features = _features;   \/\/ Preserve features\n@@ -1281,1 +1290,0 @@\n-  _supports_cx8 = supports_cmpxchg8();\n@@ -1333,0 +1341,6 @@\n+  \/\/ Check if processor has Intel Ecore\n+  if (FLAG_IS_DEFAULT(EnableX86ECoreOpts) && is_intel() && cpu_family() == 6 &&\n+    (_model == 0x97 || _model == 0xAA || _model == 0xAC || _model == 0xAF)) {\n+    FLAG_SET_DEFAULT(EnableX86ECoreOpts, true);\n+  }\n+\n@@ -1428,1 +1442,1 @@\n-  if (UseAVX < 2)\n+  if (UseAVX < 2) {\n@@ -1430,0 +1444,2 @@\n+    _features &= ~CPU_AVX_IFMA;\n+  }\n@@ -1459,0 +1475,8 @@\n+      _features &= ~CPU_AVX_IFMA;\n+    }\n+  }\n+\n+  \/\/ APX support not enabled yet\n+  if (UseAPX) {\n+    if (!FLAG_IS_DEFAULT(UseAPX)) {\n+        warning(\"APX is not supported on this CPU.\");\n@@ -1460,0 +1484,1 @@\n+    FLAG_SET_DEFAULT(UseAPX, false);\n@@ -1601,0 +1626,1 @@\n+#ifdef _LP64\n@@ -1616,0 +1642,7 @@\n+#else\n+  \/\/ No support currently for ChaCha20 intrinsics on 32-bit platforms\n+  if (UseChaCha20Intrinsics) {\n+      warning(\"ChaCha20 intrinsics are not available on this CPU.\");\n+      FLAG_SET_DEFAULT(UseChaCha20Intrinsics, false);\n+  }\n+#endif \/\/ _LP64\n@@ -1641,1 +1674,1 @@\n-  if (supports_sha() LP64_ONLY(|| supports_avx2() && supports_bmi2())) {\n+  if (supports_sha() LP64_ONLY(|| (supports_avx2() && supports_bmi2()))) {\n@@ -1807,1 +1840,1 @@\n-  if (supports_avx512ifma() && supports_avx512vlbw() && MaxVectorSize >= 64) {\n+  if ((supports_avx512ifma() && supports_avx512vlbw()) || supports_avxifma())  {\n@@ -1818,0 +1851,12 @@\n+#ifdef _LP64\n+  if (supports_avx512ifma() && supports_avx512vlbw()) {\n+    if (FLAG_IS_DEFAULT(UseIntPolyIntrinsics)) {\n+      FLAG_SET_DEFAULT(UseIntPolyIntrinsics, true);\n+    }\n+  } else\n+#endif\n+  if (UseIntPolyIntrinsics) {\n+    warning(\"Intrinsics for Polynomial crypto functions not available on this CPU.\");\n+    FLAG_SET_DEFAULT(UseIntPolyIntrinsics, false);\n+  }\n+\n@@ -2390,1 +2435,1 @@\n-        log->print_cr(\" at distance %d, %d lines of %d bytes\", (int) AllocatePrefetchDistance, (int) AllocatePrefetchLines, (int) AllocatePrefetchStepSize);\n+        log->print_cr(\" at distance %d, %d lines of %d bytes\", AllocatePrefetchDistance, AllocatePrefetchLines, AllocatePrefetchStepSize);\n@@ -2392,1 +2437,1 @@\n-        log->print_cr(\" at distance %d, one line of %d bytes\", (int) AllocatePrefetchDistance, (int) AllocatePrefetchStepSize);\n+        log->print_cr(\" at distance %d, one line of %d bytes\", AllocatePrefetchDistance, AllocatePrefetchStepSize);\n@@ -3516,1 +3561,1 @@\n-    if (sef_cpuid7_ebx.bits.avx2 != 0)\n+    if (sef_cpuid7_ebx.bits.avx2 != 0) {\n@@ -3518,0 +3563,5 @@\n+      if (sef_cpuid7_ecx1_eax.bits.avx_ifma != 0)\n+        result |= CPU_AVX_IFMA;\n+    }\n+    if (sef_cpuid7_ecx.bits.gfni != 0)\n+        result |= CPU_GFNI;\n@@ -3543,2 +3593,0 @@\n-      if (sef_cpuid7_ecx.bits.gfni != 0)\n-        result |= CPU_GFNI;\n@@ -3764,1 +3812,1 @@\n-intx VM_Version::allocate_prefetch_distance(bool use_watermark_prefetch) {\n+int VM_Version::allocate_prefetch_distance(bool use_watermark_prefetch) {\n@@ -3824,1 +3872,0 @@\n-\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":61,"deletions":14,"binary":false,"changes":75,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -286,0 +286,9 @@\n+  union SefCpuid7Ecx1Eax {\n+    uint32_t value;\n+    struct {\n+      uint32_t             : 23,\n+                  avx_ifma : 1,\n+                           : 8;\n+    } bits;\n+  };\n+\n@@ -397,1 +406,2 @@\n-    decl(AVX512_IFMA,       \"avx512_ifma\",       58) \/* Integer Vector FMA instructions*\/\n+    decl(AVX512_IFMA,       \"avx512_ifma\",       58) \/* Integer Vector FMA instructions*\/ \\\n+    decl(AVX_IFMA,          \"avx_ifma\",          59) \/* 256-bit VEX-coded variant of AVX512-IFMA*\/\n@@ -458,1 +468,2 @@\n-  struct CpuidInfo {\n+  class CpuidInfo {\n+  public:\n@@ -478,0 +489,1 @@\n+    \/\/ ECX = 0 before calling cpuid()\n@@ -482,0 +494,2 @@\n+    \/\/ ECX = 1 before calling cpuid()\n+    SefCpuid7Ecx1Eax sef_cpuid7_ecx1_eax;\n@@ -578,0 +592,1 @@\n+    \/\/ Asserts\n@@ -605,1 +620,1 @@\n-  \/\/ Extractor\n+  \/\/ Extractors and predicates\n@@ -642,0 +657,1 @@\n+  static ByteSize sef_cpuid7_ecx1_offset() { return byte_offset_of(CpuidInfo, sef_cpuid7_ecx1_eax); }\n@@ -682,17 +698,0 @@\n-  \/\/ Asserts\n-  static void assert_is_initialized() {\n-    _cpuid_info.assert_is_initialized();\n-  }\n-\n-  static uint32_t extended_cpu_family() {\n-    return _cpuid_info.extended_cpu_family();\n-  }\n-\n-  static uint32_t extended_cpu_model() {\n-    return _cpuid_info.extended_cpu_model();\n-  }\n-\n-  static uint32_t cpu_stepping() {\n-    return _cpuid_info.cpu_stepping();\n-  }\n-\n@@ -714,0 +713,4 @@\n+  static void     assert_is_initialized() { _cpuid_info.assert_is_initialized(); }\n+  static uint32_t extended_cpu_family()   { return _cpuid_info.extended_cpu_family(); }\n+  static uint32_t extended_cpu_model()    { return _cpuid_info.extended_cpu_model(); }\n+  static uint32_t cpu_stepping()          { return _cpuid_info.cpu_stepping(); }\n@@ -740,1 +743,1 @@\n-  \/\/ Feature identification\n+  \/\/ Feature identification which can be affected by VM settings\n@@ -743,1 +746,0 @@\n-  static bool supports_cmpxchg8()     { return (_features & CPU_CX8) != 0; }\n@@ -771,0 +773,1 @@\n+  static bool supports_avxifma()      { return (_features & CPU_AVX_IFMA) != 0; }\n@@ -804,0 +807,5 @@\n+  \/\/\n+  \/\/ Feature identification not affected by VM flags\n+  \/\/\n+  static bool cpu_supports_evex()     { return (_cpu_features & CPU_AVX512F) != 0; }\n+\n@@ -850,1 +858,1 @@\n-  static intx allocate_prefetch_distance(bool use_watermark_prefetch);\n+  static int allocate_prefetch_distance(bool use_watermark_prefetch);\n@@ -857,1 +865,1 @@\n-  \/\/ x86_64 supports fast class initialization checks for static methods.\n+  \/\/ x86_64 supports fast class initialization checks\n@@ -862,0 +870,5 @@\n+  \/\/ x86_64 supports secondary supers table\n+  constexpr static bool supports_secondary_supers_table() {\n+    return LP64_ONLY(true) NOT_LP64(false); \/\/ not implemented on x86_32\n+  }\n+\n@@ -866,0 +879,4 @@\n+  constexpr static bool supports_recursive_lightweight_locking() {\n+    return true;\n+  }\n+\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.hpp","additions":42,"deletions":25,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+  static bool profile_all_receivers_at_type_check() { return false; }\n","filename":"src\/hotspot\/cpu\/zero\/vm_version_zero.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 2005, 2020, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2012, 2018 SAP SE. All rights reserved.\n+ * Copyright (c) 2005, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2024 SAP SE. All rights reserved.\n@@ -37,1 +37,0 @@\n-                         notproduct,                                                \\\n@@ -48,1 +47,1 @@\n-  product(bool, AllowExtshm, false,                                                 \\\n+  product(bool, AllowExtshm, false, DIAGNOSTIC,                                     \\\n@@ -52,5 +51,6 @@\n-  \/*  to the maximum C Heap consumption we expect.                             *\/   \\\n-  \/*  We need to know this because we need to leave \"breathing space\" for the  *\/   \\\n-  \/*  data segment when placing the java heap. If that space is too small, we  *\/   \\\n-  \/*  reduce our chance of getting a low heap address (needed for compressed   *\/   \\\n-  \/*  Oops).                                                                   *\/   \\\n+  \/*  maximum C Heap consumption we expect.                                    *\/   \\\n+  \/*  We need to leave \"breathing space\" for the data segment when             *\/   \\\n+  \/*  placing the java heap. If the MaxExpectedDataSegmentSize setting         *\/   \\\n+  \/*  is too small, we might run into resource issues creating many native     *\/   \\\n+  \/*  threads, if it is too large, we reduce our chance of getting a low heap  *\/   \\\n+  \/*  address (needed for compressed Oops).                                    *\/   \\\n@@ -61,1 +61,1 @@\n-  product(bool, OptimizePollingPageLocation, true,                                  \\\n+  product(bool, OptimizePollingPageLocation, true, DIAGNOSTIC,                      \\\n@@ -65,1 +65,1 @@\n-  product(bool, Use64KPages, true,                                                  \\\n+  product(bool, Use64KPages, true, DIAGNOSTIC,                                      \\\n@@ -68,6 +68,0 @@\n-  \/*  If VM uses 64K paged memory (shmat) for virtual memory: threshold below  *\/   \\\n-  \/*  which virtual memory allocations are done with 4K memory (mmap). This is *\/   \\\n-  \/*  mainly for test purposes.                                                *\/   \\\n-  develop(uintx, Use64KPagesThreshold, 0,                                           \\\n-          \"4K\/64K page allocation threshold.\")                                      \\\n-                                                                                    \\\n@@ -77,1 +71,1 @@\n-  product(bool, UseExplicitCommit, false,                                           \\\n+  product(bool, UseExplicitCommit, false, DIAGNOSTIC,                               \\\n","filename":"src\/hotspot\/os\/aix\/globals_aix.hpp","additions":12,"deletions":18,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -35,1 +35,0 @@\n-                         notproduct,                                    \\\n@@ -39,1 +38,1 @@\n-  AARCH64_ONLY(develop(bool, AssertWXAtThreadSync, false,                \\\n+  AARCH64_ONLY(develop(bool, AssertWXAtThreadSync, true,                \\\n","filename":"src\/hotspot\/os\/bsd\/globals_bsd.hpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -35,1 +35,0 @@\n-                         notproduct,                                    \\\n@@ -47,3 +46,0 @@\n-  product(bool, UseHugeTLBFS, false,                                    \\\n-          \"Use MAP_HUGETLB for large pages\")                            \\\n-                                                                        \\\n@@ -56,3 +52,0 @@\n-  product(bool, UseSHM, false,                                          \\\n-          \"Use SYSV shared memory for large pages\")                     \\\n-                                                                        \\\n@@ -104,1 +97,3 @@\n-\n+  product(bool, UseMadvPopulateWrite, true, DIAGNOSTIC,                 \\\n+          \"Use MADV_POPULATE_WRITE in os::pd_pretouch_memory.\")         \\\n+                                                                        \\\n","filename":"src\/hotspot\/os\/linux\/globals_linux.hpp","additions":4,"deletions":9,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2015, 2022 SAP SE. All rights reserved.\n+ * Copyright (c) 1999, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2024 SAP SE. All rights reserved.\n@@ -30,1 +30,0 @@\n-#include \"code\/icBuffer.hpp\"\n@@ -41,0 +40,1 @@\n+#include \"nmt\/memTracker.hpp\"\n@@ -42,0 +42,1 @@\n+#include \"osContainer_linux.hpp\"\n@@ -44,1 +45,0 @@\n-#include \"osContainer_linux.hpp\"\n@@ -69,2 +69,0 @@\n-#include \"signals_posix.hpp\"\n-#include \"services\/memTracker.hpp\"\n@@ -72,0 +70,1 @@\n+#include \"signals_posix.hpp\"\n@@ -75,0 +74,2 @@\n+#include \"utilities\/checkedCast.hpp\"\n+#include \"utilities\/debug.hpp\"\n@@ -77,2 +78,1 @@\n-#include \"utilities\/events.hpp\"\n-#include \"utilities\/growableArray.hpp\"\n+#include \"utilities\/events.hpp\"\n@@ -81,0 +81,1 @@\n+#include \"utilities\/growableArray.hpp\"\n@@ -86,0 +87,1 @@\n+#include \"jfr\/support\/jfrNativeLibraryLoadEvent.hpp\"\n@@ -90,0 +92,2 @@\n+# include <ctype.h>\n+# include <stdlib.h>\n@@ -92,0 +96,1 @@\n+# include <sys\/sendfile.h>\n@@ -98,0 +103,1 @@\n+# include <fenv.h>\n@@ -114,1 +120,0 @@\n-# include <sys\/shm.h>\n@@ -179,0 +184,2 @@\n+bool os::Linux::_thp_requested{false};\n+\n@@ -290,0 +297,51 @@\n+jlong os::total_swap_space() {\n+  if (OSContainer::is_containerized()) {\n+    if (OSContainer::memory_limit_in_bytes() > 0) {\n+      return (jlong)(OSContainer::memory_and_swap_limit_in_bytes() - OSContainer::memory_limit_in_bytes());\n+    }\n+  }\n+  struct sysinfo si;\n+  int ret = sysinfo(&si);\n+  if (ret != 0) {\n+    return -1;\n+  }\n+  return  (jlong)(si.totalswap * si.mem_unit);\n+}\n+\n+static jlong host_free_swap() {\n+  struct sysinfo si;\n+  int ret = sysinfo(&si);\n+  if (ret != 0) {\n+    return -1;\n+  }\n+  return (jlong)(si.freeswap * si.mem_unit);\n+}\n+\n+jlong os::free_swap_space() {\n+  jlong host_free_swap_val = host_free_swap();\n+  if (OSContainer::is_containerized()) {\n+    jlong mem_swap_limit = OSContainer::memory_and_swap_limit_in_bytes();\n+    jlong mem_limit = OSContainer::memory_limit_in_bytes();\n+    if (mem_swap_limit >= 0 && mem_limit >= 0) {\n+      jlong delta_limit = mem_swap_limit - mem_limit;\n+      if (delta_limit <= 0) {\n+        return 0;\n+      }\n+      jlong mem_swap_usage = OSContainer::memory_and_swap_usage_in_bytes();\n+      jlong mem_usage = OSContainer::memory_usage_in_bytes();\n+      if (mem_swap_usage > 0 && mem_usage > 0) {\n+        jlong delta_usage = mem_swap_usage - mem_usage;\n+        if (delta_usage >= 0) {\n+          jlong free_swap = delta_limit - delta_usage;\n+          return free_swap >= 0 ? free_swap : 0;\n+        }\n+      }\n+    }\n+    \/\/ unlimited or not supported. Fall through to return host value\n+    log_trace(os,container)(\"os::free_swap_space: container_swap_limit=\" JLONG_FORMAT\n+                            \" container_mem_limit=\" JLONG_FORMAT \" returning host value: \" JLONG_FORMAT,\n+                            mem_swap_limit, mem_limit, host_free_swap_val);\n+  }\n+  return host_free_swap_val;\n+}\n+\n@@ -316,0 +374,16 @@\n+void os::Linux::kernel_version(long* major, long* minor) {\n+  *major = -1;\n+  *minor = -1;\n+\n+  struct utsname buffer;\n+  int ret = uname(&buffer);\n+  if (ret != 0) {\n+    log_warning(os)(\"uname(2) failed to get kernel version: %s\", os::errno_name(ret));\n+    return;\n+  }\n+  int nr_matched = sscanf(buffer.release, \"%ld.%ld\", major, minor);\n+  if (nr_matched != 2) {\n+    log_warning(os)(\"Parsing kernel version failed, expected 2 version numbers, only matched %d\", nr_matched);\n+  }\n+}\n+\n@@ -408,1 +482,1 @@\n-  int rslt = syscall(SYS_gettid);\n+  long rslt = syscall(SYS_gettid);\n@@ -418,1 +492,1 @@\n-  return (julong)si.totalswap;\n+  return (julong)(si.totalswap * si.mem_unit);\n@@ -430,1 +504,1 @@\n-  set_processor_count(sysconf(_SC_NPROCESSORS_CONF));\n+  set_processor_count((int)sysconf(_SC_NPROCESSORS_CONF));\n@@ -570,11 +644,0 @@\n-\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-\/\/ breakpoint support\n-\n-void os::breakpoint() {\n-  BREAKPOINT;\n-}\n-\n-extern \"C\" void breakpoint() {\n-  \/\/ use debugger to set breakpoint here\n-}\n-\n@@ -753,1 +816,1 @@\n-  osthread->set_thread_id(os::current_thread_id());\n+  osthread->set_thread_id(checked_cast<OSThread::thread_id_t>(os::current_thread_id()));\n@@ -920,1 +983,6 @@\n-  pthread_attr_init(&attr);\n+  int rslt = pthread_attr_init(&attr);\n+  if (rslt != 0) {\n+    thread->set_osthread(nullptr);\n+    delete osthread;\n+    return false;\n+  }\n@@ -969,0 +1037,1 @@\n+    pthread_attr_destroy(&attr);\n@@ -1276,1 +1345,1 @@\n-    int statlen;\n+    size_t statlen;\n@@ -1471,0 +1540,3 @@\n+void os::prepare_native_symbols() {\n+}\n+\n@@ -1485,1 +1557,1 @@\n-      if (offset != nullptr) *offset = addr - (address)dlinfo.dli_saddr;\n+      if (offset != nullptr) *offset = pointer_delta_as_int(addr, (address)dlinfo.dli_saddr);\n@@ -1513,1 +1585,1 @@\n-      *offset = addr - (address)dlinfo.dli_fbase;\n+      *offset = pointer_delta_as_int(addr, (address)dlinfo.dli_fbase);\n@@ -1612,4 +1684,3 @@\n-  int diag_msg_max_length=ebuflen-strlen(ebuf);\n-  char* diag_msg_buf=ebuf+strlen(ebuf);\n-\n-  if (diag_msg_max_length==0) {\n+  size_t prefix_len = strlen(ebuf);\n+  ssize_t diag_msg_max_length = ebuflen - prefix_len;\n+  if (diag_msg_max_length <= 0) {\n@@ -1620,0 +1691,1 @@\n+  char* diag_msg_buf = ebuf + prefix_len;\n@@ -1738,1 +1810,1 @@\n-#elif  (defined LOONGARCH)\n+#elif  (defined LOONGARCH64)\n@@ -1742,1 +1814,1 @@\n-        AARCH64, ALPHA, ARM, AMD64, IA32, IA64, LOONGARCH, M68K, MIPS, MIPSEL, PARISC, __powerpc__, __powerpc64__, RISCV, S390, SH, __sparc\n+        AARCH64, ALPHA, ARM, AMD64, IA32, IA64, LOONGARCH64, M68K, MIPS, MIPSEL, PARISC, __powerpc__, __powerpc64__, RISCV, S390, SH, __sparc\n@@ -1803,3 +1875,14 @@\n-void * os::Linux::dlopen_helper(const char *filename, char *ebuf,\n-                                int ebuflen) {\n-  void * result = ::dlopen(filename, RTLD_LAZY);\n+void * os::Linux::dlopen_helper(const char *filename, char *ebuf, int ebuflen) {\n+#ifndef IA32\n+  bool ieee_handling = IEEE_subnormal_handling_OK();\n+  if (!ieee_handling) {\n+    Events::log_dll_message(nullptr, \"IEEE subnormal handling check failed before loading %s\", filename);\n+    log_info(os)(\"IEEE subnormal handling check failed before loading %s\", filename);\n+    if (CheckJNICalls) {\n+      tty->print_cr(\"WARNING: IEEE subnormal handling check failed before loading %s\", filename);\n+      Thread* current = Thread::current();\n+      if (current->is_Java_thread()) {\n+        JavaThread::cast(current)->print_jni_stack();\n+      }\n+    }\n+  }\n@@ -1807,4 +1890,12 @@\n-#if INCLUDE_JFR\n-  EventNativeLibraryLoad event;\n-  event.set_name(filename);\n-#endif\n+  \/\/ Save and restore the floating-point environment around dlopen().\n+  \/\/ There are known cases where global library initialization sets\n+  \/\/ FPU flags that affect computation accuracy, for example, enabling\n+  \/\/ Flush-To-Zero and Denormals-Are-Zero. Do not let those libraries\n+  \/\/ break Java arithmetic. Unfortunately, this might affect libraries\n+  \/\/ that might depend on these FPU features for performance and\/or\n+  \/\/ numerical \"accuracy\", but we need to protect Java semantics first\n+  \/\/ and foremost. See JDK-8295159.\n+\n+  \/\/ This workaround is ineffective on IA32 systems because the MXCSR\n+  \/\/ register (which controls flush-to-zero mode) is not stored in the\n+  \/\/ legacy fenv.\n@@ -1812,0 +1903,8 @@\n+  fenv_t default_fenv;\n+  int rtn = fegetenv(&default_fenv);\n+  assert(rtn == 0, \"fegetenv must succeed\");\n+#endif \/\/ IA32\n+\n+  void* result;\n+  JFR_ONLY(NativeLibraryLoadEvent load_event(filename, &result);)\n+  result = ::dlopen(filename, RTLD_LAZY);\n@@ -1823,5 +1922,1 @@\n-#if INCLUDE_JFR\n-    event.set_success(false);\n-    event.set_errorMessage(error_report);\n-    event.commit();\n-#endif\n+    JFR_ONLY(load_event.set_error_msg(error_report);)\n@@ -1831,5 +1926,27 @@\n-#if INCLUDE_JFR\n-    event.set_success(true);\n-    event.set_errorMessage(nullptr);\n-    event.commit();\n-#endif\n+#ifndef IA32\n+    \/\/ Quickly test to make sure subnormals are correctly handled.\n+    if (! IEEE_subnormal_handling_OK()) {\n+      \/\/ We just dlopen()ed a library that mangled the floating-point flags.\n+      \/\/ Attempt to fix things now.\n+      JFR_ONLY(load_event.set_fp_env_correction_attempt(true);)\n+      int rtn = fesetenv(&default_fenv);\n+      assert(rtn == 0, \"fesetenv must succeed\");\n+\n+      if (IEEE_subnormal_handling_OK()) {\n+        Events::log_dll_message(nullptr, \"IEEE subnormal handling had to be corrected after loading %s\", filename);\n+        log_info(os)(\"IEEE subnormal handling had to be corrected after loading %s\", filename);\n+        JFR_ONLY(load_event.set_fp_env_correction_success(true);)\n+      } else {\n+        Events::log_dll_message(nullptr, \"IEEE subnormal handling could not be corrected after loading %s\", filename);\n+        log_info(os)(\"IEEE subnormal handling could not be corrected after loading %s\", filename);\n+        if (CheckJNICalls) {\n+          tty->print_cr(\"WARNING: IEEE subnormal handling could not be corrected after loading %s\", filename);\n+          Thread* current = Thread::current();\n+          if (current->is_Java_thread()) {\n+            JavaThread::cast(current)->print_jni_stack();\n+          }\n+        }\n+        assert(false, \"fesetenv didn't work\");\n+      }\n+    }\n+#endif \/\/ IA32\n@@ -1902,1 +2019,1 @@\n-  int bytes;\n+  ssize_t bytes;\n@@ -2062,1 +2179,0 @@\n-  \"\/etc\/SuSE-release\",\n@@ -2070,0 +2186,1 @@\n+  \"\/etc\/SuSE-release\", \/\/ Deprecated in favor of os-release since SuSE 12\n@@ -2169,0 +2286,2 @@\n+  _print_ascii_file_h(\"\/proc\/sys\/vm\/swappiness (control to define how aggressively the kernel swaps out anonymous memory)\",\n+                      \"\/proc\/sys\/vm\/swappiness\", st);\n@@ -2181,0 +2300,4 @@\n+  _print_ascii_file_h(\"\/sys\/kernel\/mm\/transparent_hugepage\/hpage_pmd_size\",\n+                      \"\/sys\/kernel\/mm\/transparent_hugepage\/hpage_pmd_size\", st);\n+  _print_ascii_file_h(\"\/sys\/kernel\/mm\/transparent_hugepage\/shmem_enabled\",\n+                      \"\/sys\/kernel\/mm\/transparent_hugepage\/shmem_enabled\", st);\n@@ -2359,0 +2482,2 @@\n+  OSContainer::print_container_helper(st, OSContainer::rss_usage_in_bytes(), \"rss_usage_in_bytes\");\n+  OSContainer::print_container_helper(st, OSContainer::cache_usage_in_bytes(), \"cache_usage_in_bytes\");\n@@ -2393,1 +2518,1 @@\n-        steal_ticks_perc = (double) steal_ticks_difference \/ total_ticks_difference;\n+        steal_ticks_perc = (double) steal_ticks_difference \/ (double)total_ticks_difference;\n@@ -2435,1 +2560,1 @@\n-      if (fgets(buf, buflen, fp)) {\n+      if (fgets(buf, (int)buflen, fp)) {\n@@ -2678,1 +2803,1 @@\n-        len = strlen(buf);\n+        len = checked_cast<int>(strlen(buf));\n@@ -2688,1 +2813,1 @@\n-          len = strlen(buf);\n+          len = (int)strlen(buf);\n@@ -2717,0 +2842,2 @@\n+  static_assert(sizeof(off_t) == 8, \"Expected Large File Support in this file\");\n+\n@@ -2795,0 +2922,5 @@\n+  } else {\n+    ErrnoPreserver ep;\n+    log_trace(os, map)(\"mmap failed: \" RANGEFMT \" errno=(%s)\",\n+                       RANGEFMTARGS(addr, size),\n+                       os::strerror(ep.saved_errno()));\n@@ -2800,0 +2932,4 @@\n+    ErrnoPreserver ep;\n+    log_trace(os, map)(\"mmap failed: \" RANGEFMT \" errno=(%s)\",\n+                       RANGEFMTARGS(addr, size),\n+                       os::strerror(ep.saved_errno()));\n@@ -2841,0 +2977,19 @@\n+\/\/ Define MADV_POPULATE_WRITE here so we can build HotSpot on old systems.\n+#define MADV_POPULATE_WRITE_value 23\n+#ifndef MADV_POPULATE_WRITE\n+  #define MADV_POPULATE_WRITE MADV_POPULATE_WRITE_value\n+#else\n+  \/\/ Sanity-check our assumed default value if we build with a new enough libc.\n+  STATIC_ASSERT(MADV_POPULATE_WRITE == MADV_POPULATE_WRITE_value);\n+#endif\n+\n+\/\/ Note that the value for MAP_FIXED_NOREPLACE differs between architectures, but all architectures\n+\/\/ supported by OpenJDK share the same flag value.\n+#define MAP_FIXED_NOREPLACE_value 0x100000\n+#ifndef MAP_FIXED_NOREPLACE\n+  #define MAP_FIXED_NOREPLACE MAP_FIXED_NOREPLACE_value\n+#else\n+  \/\/ Sanity-check our assumed default value if we build with a new enough libc.\n+  STATIC_ASSERT(MAP_FIXED_NOREPLACE == MAP_FIXED_NOREPLACE_value);\n+#endif\n+\n@@ -2867,0 +3022,6 @@\n+void os::Linux::madvise_transparent_huge_pages(void* addr, size_t bytes) {\n+  \/\/ We don't check the return value: madvise(MADV_HUGEPAGE) may not\n+  \/\/ be supported or the memory may already be backed by huge pages.\n+  ::madvise(addr, bytes, MADV_HUGEPAGE);\n+}\n+\n@@ -2868,4 +3029,2 @@\n-  if (UseTransparentHugePages && alignment_hint > vm_page_size()) {\n-    \/\/ We don't check the return value: madvise(MADV_HUGEPAGE) may not\n-    \/\/ be supported or the memory may already be backed by huge pages.\n-    ::madvise(addr, bytes, MADV_HUGEPAGE);\n+  if (Linux::should_madvise_anonymous_thps() && alignment_hint > vm_page_size()) {\n+    Linux::madvise_transparent_huge_pages(addr, bytes);\n@@ -2886,0 +3045,25 @@\n+size_t os::pd_pretouch_memory(void* first, void* last, size_t page_size) {\n+  const size_t len = pointer_delta(last, first, sizeof(char)) + page_size;\n+  \/\/ Use madvise to pretouch on Linux when THP is used, and fallback to the\n+  \/\/ common method if unsupported. THP can form right after madvise rather than\n+  \/\/ being assembled later.\n+  if (HugePages::thp_mode() == THPMode::always || UseTransparentHugePages) {\n+    int err = 0;\n+    if (UseMadvPopulateWrite &&\n+        ::madvise(first, len, MADV_POPULATE_WRITE) == -1) {\n+      err = errno;\n+    }\n+    if (!UseMadvPopulateWrite || err == EINVAL) { \/\/ Not to use or not supported\n+      \/\/ When using THP we need to always pre-touch using small pages as the\n+      \/\/ OS will initially always use small pages.\n+      return os::vm_page_size();\n+    } else if (err != 0) {\n+      log_info(gc, os)(\"::madvise(\" PTR_FORMAT \", \" SIZE_FORMAT \", %d) failed; \"\n+                       \"error='%s' (errno=%d)\", p2i(first), len,\n+                       MADV_POPULATE_WRITE, os::strerror(err), err);\n+    }\n+    return 0;\n+  }\n+  return page_size;\n+}\n+\n@@ -2957,1 +3141,1 @@\n-size_t os::numa_get_leaf_groups(int *ids, size_t size) {\n+size_t os::numa_get_leaf_groups(uint *ids, size_t size) {\n@@ -2966,2 +3150,2 @@\n-    if (Linux::is_node_in_bound_nodes((unsigned int)node)) {\n-      ids[i++] = node;\n+    if (Linux::is_node_in_bound_nodes(node)) {\n+      ids[i++] = checked_cast<uint>(node);\n@@ -2973,6 +3157,0 @@\n-char *os::scan_pages(char *start, char* end, page_info* page_expected,\n-                     page_info* page_found) {\n-  return end;\n-}\n-\n-\n@@ -2981,1 +3159,1 @@\n-  int retval = -1;\n+  long retval = -1;\n@@ -3000,1 +3178,1 @@\n-  return (retval == -1) ? retval : cpu;\n+  return (retval == -1) ? -1 : cpu;\n@@ -3153,12 +3331,12 @@\n-  const size_t NCPUS = 32768; \/\/ Since the buffer size computation is very obscure\n-                              \/\/ in libnuma (possible values are starting from 16,\n-                              \/\/ and continuing up with every other power of 2, but less\n-                              \/\/ than the maximum number of CPUs supported by kernel), and\n-                              \/\/ is a subject to change (in libnuma version 2 the requirements\n-                              \/\/ are more reasonable) we'll just hardcode the number they use\n-                              \/\/ in the library.\n-  const size_t BitsPerCLong = sizeof(long) * CHAR_BIT;\n-\n-  size_t cpu_num = processor_count();\n-  size_t cpu_map_size = NCPUS \/ BitsPerCLong;\n-  size_t cpu_map_valid_size =\n+  const int NCPUS = 32768; \/\/ Since the buffer size computation is very obscure\n+                           \/\/ in libnuma (possible values are starting from 16,\n+                           \/\/ and continuing up with every other power of 2, but less\n+                           \/\/ than the maximum number of CPUs supported by kernel), and\n+                           \/\/ is a subject to change (in libnuma version 2 the requirements\n+                           \/\/ are more reasonable) we'll just hardcode the number they use\n+                           \/\/ in the library.\n+  constexpr int BitsPerCLong = (int)sizeof(long) * CHAR_BIT;\n+\n+  int cpu_num = processor_count();\n+  int cpu_map_size = NCPUS \/ BitsPerCLong;\n+  int cpu_map_valid_size =\n@@ -3170,1 +3348,1 @@\n-  size_t node_num = get_existing_num_nodes();\n+  int node_num = get_existing_num_nodes();\n@@ -3176,1 +3354,1 @@\n-  for (size_t i = 0; i < node_num; i++) {\n+  for (int i = 0; i < node_num; i++) {\n@@ -3187,1 +3365,1 @@\n-      for (size_t m = 0; m < node_num; m++) {\n+      for (int m = 0; m < node_num; m++) {\n@@ -3209,2 +3387,2 @@\n-    if (numa_node_to_cpus(nindex_to_node()->at(i), cpu_map, cpu_map_size * sizeof(unsigned long)) != -1) {\n-      for (size_t j = 0; j < cpu_map_valid_size; j++) {\n+    if (numa_node_to_cpus(nindex_to_node()->at(i), cpu_map, cpu_map_size * (int)sizeof(unsigned long)) != -1) {\n+      for (int j = 0; j < cpu_map_valid_size; j++) {\n@@ -3212,1 +3390,1 @@\n-          for (size_t k = 0; k < BitsPerCLong; k++) {\n+          for (int k = 0; k < BitsPerCLong; k++) {\n@@ -3289,1 +3467,8 @@\n-  return res  != (uintptr_t) MAP_FAILED;\n+  if (res == (uintptr_t) MAP_FAILED) {\n+    ErrnoPreserver ep;\n+    log_trace(os, map)(\"mmap failed: \" RANGEFMT \" errno=(%s)\",\n+                       RANGEFMTARGS(addr, size),\n+                       os::strerror(ep.saved_errno()));\n+    return false;\n+  }\n+  return true;\n@@ -3297,1 +3482,1 @@\n-  unsigned pages = size \/ page_sz;\n+  unsigned pages = checked_cast<unsigned>(size \/ page_sz);\n@@ -3347,1 +3532,1 @@\n-  size_t pages = size \/ page_sz;\n+  uintx pages = size \/ page_sz;\n@@ -3354,1 +3539,1 @@\n-  int loops = (pages + stripe - 1) \/ stripe;\n+  int loops = checked_cast<int>((pages + stripe - 1) \/ stripe);\n@@ -3361,1 +3546,1 @@\n-    int pages_to_query = (pages >= stripe) ? stripe : pages;\n+    uintx pages_to_query = (pages >= stripe) ? stripe : pages;\n@@ -3374,0 +3559,5 @@\n+    \/\/ If mincore is not supported.\n+    if (mincore_return_value == -1 && errno == ENOSYS) {\n+      return false;\n+    }\n+\n@@ -3377,1 +3567,1 @@\n-    for (int vecIdx = 0; vecIdx < pages_to_query; vecIdx ++) {\n+    for (uintx vecIdx = 0; vecIdx < pages_to_query; vecIdx ++) {\n@@ -3481,2 +3671,17 @@\n-  \/\/ MAP_FIXED is intentionally left out, to leave existing mappings intact.\n-  const int flags = MAP_PRIVATE | MAP_NORESERVE | MAP_ANONYMOUS;\n+  \/\/ If a requested address was given:\n+  \/\/\n+  \/\/ The POSIX-conforming way is to *omit* MAP_FIXED. This will leave existing mappings intact.\n+  \/\/ If the requested mapping area is blocked by a pre-existing mapping, the kernel will map\n+  \/\/ somewhere else. On Linux, that alternative address appears to have no relation to the\n+  \/\/ requested address.\n+  \/\/ Unfortunately, this is not what we need - if we requested a specific address, we'd want\n+  \/\/ to map there and nowhere else. Therefore we will unmap the block again, which means we\n+  \/\/ just executed a needless mmap->munmap cycle.\n+  \/\/ Since Linux 4.17, the kernel offers MAP_FIXED_NOREPLACE. With this flag, if a pre-\n+  \/\/ existing mapping exists, the kernel will not map at an alternative point but instead\n+  \/\/ return an error. We can therefore save that unnecessary mmap-munmap cycle.\n+  \/\/\n+  \/\/ Backward compatibility: Older kernels will ignore the unknown flag; so mmap will behave\n+  \/\/ as in mode (a).\n+  const int flags = MAP_PRIVATE | MAP_NORESERVE | MAP_ANONYMOUS |\n+                    ((requested_addr != nullptr) ? MAP_FIXED_NOREPLACE : 0);\n@@ -3488,2 +3693,8 @@\n-\n-  return addr == MAP_FAILED ? nullptr : addr;\n+  if (addr == MAP_FAILED) {\n+    ErrnoPreserver ep;\n+    log_trace(os, map)(\"mmap failed: \" RANGEFMT \" errno=(%s)\",\n+                       RANGEFMTARGS(requested_addr, bytes),\n+                       os::strerror(ep.saved_errno()));\n+    return nullptr;\n+  }\n+  return addr;\n@@ -3510,1 +3721,6 @@\n-        ::munmap(start, extra_size);\n+        if (::munmap(start, extra_size) != 0) {\n+          ErrnoPreserver ep;\n+          log_trace(os, map)(\"munmap failed: \" RANGEFMT \" errno=(%s)\",\n+                             RANGEFMTARGS(start, extra_size),\n+                             os::strerror(ep.saved_errno()));\n+        }\n@@ -3518,1 +3734,7 @@\n-        ::munmap(start, start_aligned - start);\n+        const size_t l = start_aligned - start;\n+        if (::munmap(start, l) != 0) {\n+          ErrnoPreserver ep;\n+          log_trace(os, map)(\"munmap failed: \" RANGEFMT \" errno=(%s)\",\n+                             RANGEFMTARGS(start, l),\n+                             os::strerror(ep.saved_errno()));\n+        }\n@@ -3521,1 +3743,7 @@\n-        ::munmap(end_aligned, end - end_aligned);\n+        const size_t l = end - end_aligned;\n+        if (::munmap(end_aligned, l) != 0) {\n+          ErrnoPreserver ep;\n+          log_trace(os, map)(\"munmap failed: \" RANGEFMT \" errno=(%s)\",\n+                             RANGEFMTARGS(end_aligned, l),\n+                             os::strerror(ep.saved_errno()));\n+        }\n@@ -3530,1 +3758,8 @@\n-  return ::munmap(addr, size) == 0;\n+  if (::munmap(addr, size) != 0) {\n+    ErrnoPreserver ep;\n+    log_trace(os, map)(\"munmap failed: \" RANGEFMT \" errno=(%s)\",\n+                       RANGEFMTARGS(addr, size),\n+                       os::strerror(ep.saved_errno()));\n+    return 0;\n+  }\n+  return 1;\n@@ -3562,1 +3797,1 @@\n-  Events::log(nullptr, \"Protecting memory [\" INTPTR_FORMAT \",\" INTPTR_FORMAT \"] with protection modes %x\", p2i(bottom), p2i(bottom+size), prot);\n+  Events::log_memprotect(nullptr, \"Protecting memory [\" INTPTR_FORMAT \",\" INTPTR_FORMAT \"] with protection modes %x\", p2i(bottom), p2i(bottom+size), prot);\n@@ -3590,2 +3825,2 @@\n-int os::Linux::hugetlbfs_page_size_flag(size_t page_size) {\n-  if (page_size != HugePages::default_static_hugepage_size()) {\n+static int hugetlbfs_page_size_flag(size_t page_size) {\n+  if (page_size != HugePages::default_explicit_hugepage_size()) {\n@@ -3597,1 +3832,4 @@\n-bool os::Linux::hugetlbfs_sanity_check(bool warn, size_t page_size) {\n+static bool hugetlbfs_sanity_check(size_t page_size) {\n+  const os::PageSizes page_sizes = HugePages::explicit_hugepage_info().pagesizes();\n+  assert(page_sizes.contains(page_size), \"Invalid page sizes passed\");\n+\n@@ -3611,3 +3849,3 @@\n-      for (size_t page_size_ = _page_sizes.next_smaller(page_size);\n-          page_size_ != os::vm_page_size();\n-          page_size_ = _page_sizes.next_smaller(page_size_)) {\n+      for (size_t page_size_ = page_sizes.next_smaller(page_size);\n+          page_size_ > os::vm_page_size();\n+          page_size_ = page_sizes.next_smaller(page_size_)) {\n@@ -3627,4 +3865,0 @@\n-  if (warn) {\n-    warning(\"HugeTLBFS is not configured or not supported by the operating system.\");\n-  }\n-\n@@ -3634,24 +3868,0 @@\n-bool os::Linux::shm_hugetlbfs_sanity_check(bool warn, size_t page_size) {\n-  \/\/ Try to create a large shared memory segment.\n-  int shmid = shmget(IPC_PRIVATE, page_size, SHM_HUGETLB|IPC_CREAT|SHM_R|SHM_W);\n-  if (shmid == -1) {\n-    \/\/ Possible reasons for shmget failure:\n-    \/\/ 1. shmmax is too small for the request.\n-    \/\/    > check shmmax value: cat \/proc\/sys\/kernel\/shmmax\n-    \/\/    > increase shmmax value: echo \"new_value\" > \/proc\/sys\/kernel\/shmmax\n-    \/\/ 2. not enough large page memory.\n-    \/\/    > check available large pages: cat \/proc\/meminfo\n-    \/\/    > increase amount of large pages:\n-    \/\/          sysctl -w vm.nr_hugepages=new_value\n-    \/\/    > For more information regarding large pages please refer to:\n-    \/\/      https:\/\/www.kernel.org\/doc\/Documentation\/vm\/hugetlbpage.txt\n-    if (warn) {\n-      warning(\"Large pages using UseSHM are not configured on this system.\");\n-    }\n-    return false;\n-  }\n-  \/\/ Managed to create a segment, now delete it.\n-  shmctl(shmid, IPC_RMID, nullptr);\n-  return true;\n-}\n-\n@@ -3699,1 +3909,1 @@\n-void warn_no_large_pages_configured() {\n+static void warn_no_large_pages_configured() {\n@@ -3705,42 +3915,0 @@\n-bool os::Linux::setup_large_page_type(size_t page_size) {\n-  if (FLAG_IS_DEFAULT(UseHugeTLBFS) &&\n-      FLAG_IS_DEFAULT(UseSHM) &&\n-      FLAG_IS_DEFAULT(UseTransparentHugePages)) {\n-\n-    \/\/ The type of large pages has not been specified by the user.\n-\n-    \/\/ Try UseHugeTLBFS and then UseSHM.\n-    UseHugeTLBFS = UseSHM = true;\n-\n-    \/\/ Don't try UseTransparentHugePages since there are known\n-    \/\/ performance issues with it turned on. This might change in the future.\n-    UseTransparentHugePages = false;\n-  }\n-\n-  if (UseTransparentHugePages) {\n-    UseHugeTLBFS = false;\n-    UseSHM = false;\n-    return true;\n-  }\n-\n-  if (UseHugeTLBFS) {\n-    bool warn_on_failure = !FLAG_IS_DEFAULT(UseHugeTLBFS);\n-    if (hugetlbfs_sanity_check(warn_on_failure, page_size)) {\n-      UseSHM = false;\n-      return true;\n-    }\n-    UseHugeTLBFS = false;\n-  }\n-\n-  if (UseSHM) {\n-    bool warn_on_failure = !FLAG_IS_DEFAULT(UseSHM);\n-    if (shm_hugetlbfs_sanity_check(warn_on_failure, page_size)) {\n-      return true;\n-    }\n-    UseSHM = false;\n-  }\n-\n-  warn_no_large_pages_configured();\n-  return false;\n-}\n-\n@@ -3753,2 +3921,1 @@\n-        ls.print_cr(\"UseLargePages=1, UseTransparentHugePages=%d, UseHugeTLBFS=%d, UseSHM=%d\",\n-                    UseTransparentHugePages, UseHugeTLBFS, UseSHM);\n+        ls.print_cr(\"UseLargePages=1, UseTransparentHugePages=%d\", UseTransparentHugePages);\n@@ -3759,1 +3926,1 @@\n-        ls.print(\"Large page support disabled.\");\n+        ls.print(\"Large page support %sdisabled.\", uses_zgc_shmem_thp() ? \"partially \" : \"\");\n@@ -3763,0 +3930,8 @@\n+\n+  static bool uses_zgc_shmem_thp() {\n+    return UseZGC &&\n+        \/\/ If user requested THP\n+        ((os::Linux::thp_requested() && HugePages::supports_shmem_thp()) ||\n+        \/\/ If OS forced THP\n+         HugePages::forced_shmem_thp());\n+  }\n@@ -3765,0 +3940,25 @@\n+static bool validate_thps_configured() {\n+  assert(UseTransparentHugePages, \"Sanity\");\n+  assert(os::Linux::thp_requested(), \"Sanity\");\n+\n+  if (UseZGC) {\n+    if (!HugePages::supports_shmem_thp()) {\n+      log_warning(pagesize)(\"Shared memory transparent huge pages are not enabled in the OS. \"\n+          \"Set \/sys\/kernel\/mm\/transparent_hugepage\/shmem_enabled to 'advise' to enable them.\");\n+      \/\/ UseTransparentHugePages has historically been tightly coupled with\n+      \/\/ anonymous THPs. Fall through here and let the validity be determined\n+      \/\/ by the OS configuration for anonymous THPs. ZGC doesn't use the flag\n+      \/\/ but instead checks os::Linux::thp_requested().\n+    }\n+  }\n+\n+  if (!HugePages::supports_thp()) {\n+    log_warning(pagesize)(\"Anonymous transparent huge pages are not enabled in the OS. \"\n+        \"Set \/sys\/kernel\/mm\/transparent_hugepage\/enabled to 'madvise' to enable them.\");\n+    log_warning(pagesize)(\"UseTransparentHugePages disabled, transparent huge pages are not supported by the operating system.\");\n+    return false;\n+  }\n+\n+  return true;\n+}\n+\n@@ -3766,0 +3966,4 @@\n+  Linux::large_page_init();\n+}\n+\n+void os::Linux::large_page_init() {\n@@ -3768,0 +3972,4 @@\n+  \/\/ Decide if the user asked for THPs before we update UseTransparentHugePages.\n+  const bool large_pages_turned_off = !FLAG_IS_DEFAULT(UseLargePages) && !UseLargePages;\n+  _thp_requested = UseTransparentHugePages && !large_pages_turned_off;\n+\n@@ -3786,1 +3994,1 @@\n-  \/\/ 1) Handle the case where we do not want to use huge pages\n+  \/\/ Handle the case where we do not want to use huge pages\n@@ -3788,3 +3996,1 @@\n-      !UseTransparentHugePages &&\n-      !UseHugeTLBFS &&\n-      !UseSHM) {\n+      !UseTransparentHugePages) {\n@@ -3797,3 +4003,0 @@\n-    \/\/ Ignore the rest of the large pages flags.\n-    UseHugeTLBFS = false;\n-    UseSHM = false;\n@@ -3804,4 +4007,8 @@\n-  \/\/ 2) check if large pages are configured\n-  if ( ( UseTransparentHugePages && HugePages::supports_thp() == false) ||\n-       (!UseTransparentHugePages && HugePages::supports_static_hugepages() == false) ) {\n-    \/\/ No large pages configured, return.\n+  \/\/ Check if the OS supports THPs\n+  if (UseTransparentHugePages && !validate_thps_configured()) {\n+    UseLargePages = UseTransparentHugePages = false;\n+    return;\n+  }\n+\n+  \/\/ Check if the OS supports explicit hugepages.\n+  if (!UseTransparentHugePages && !HugePages::supports_explicit_hugepages()) {\n@@ -3810,3 +4017,0 @@\n-    UseTransparentHugePages = false;\n-    UseHugeTLBFS = false;\n-    UseSHM = false;\n@@ -3820,1 +4024,5 @@\n-    assert(HugePages::supports_thp() && HugePages::thp_pagesize() > 0, \"Missing OS info\");\n+    if (_large_page_size == 0) {\n+        log_info(pagesize) (\"Cannot determine THP page size (kernel < 4.10 ?)\");\n+        _large_page_size = HugePages::thp_pagesize_fallback();\n+        log_info(pagesize) (\"Assuming THP page size to be: \" EXACTFMT \" (heuristics)\", EXACTFMTARGS(_large_page_size));\n+    }\n@@ -3824,0 +4032,2 @@\n+    \/\/ +UseTransparentHugePages implies +UseLargePages\n+    UseLargePages = true;\n@@ -3827,2 +4037,2 @@\n-    \/\/ In static hugepage mode:\n-    \/\/ - os::large_page_size() is the default static hugepage size (\/proc\/meminfo \"Hugepagesize\")\n+    \/\/ In explicit hugepage mode:\n+    \/\/ - os::large_page_size() is the default explicit hugepage size (\/proc\/meminfo \"Hugepagesize\")\n@@ -3831,2 +4041,2 @@\n-    os::PageSizes all_large_pages = HugePages::static_info().pagesizes();\n-    const size_t default_large_page_size = HugePages::default_static_hugepage_size();\n+    os::PageSizes all_large_pages = HugePages::explicit_hugepage_info().pagesizes();\n+    const size_t default_large_page_size = HugePages::default_explicit_hugepage_size();\n@@ -3836,0 +4046,2 @@\n+    size_t large_page_size = 0;\n+\n@@ -3841,6 +4053,6 @@\n-        LargePageSizeInBytes == 0 ||\n-        LargePageSizeInBytes == default_large_page_size) {\n-      _large_page_size = default_large_page_size;\n-      log_info(pagesize)(\"Using the default large page size: \" SIZE_FORMAT \"%s\",\n-                         byte_size_in_exact_unit(_large_page_size),\n-                         exact_unit_for_byte_size(_large_page_size));\n+       LargePageSizeInBytes == 0 ||\n+       LargePageSizeInBytes == default_large_page_size) {\n+     large_page_size = default_large_page_size;\n+     log_info(pagesize)(\"Using the default large page size: \" SIZE_FORMAT \"%s\",\n+                        byte_size_in_exact_unit(large_page_size),\n+                        exact_unit_for_byte_size(large_page_size));\n@@ -3849,1 +4061,1 @@\n-        _large_page_size = LargePageSizeInBytes;\n+        large_page_size = LargePageSizeInBytes;\n@@ -3854,2 +4066,2 @@\n-                           byte_size_in_exact_unit(_large_page_size),\n-                           exact_unit_for_byte_size(_large_page_size));\n+                           byte_size_in_exact_unit(large_page_size),\n+                           exact_unit_for_byte_size(large_page_size));\n@@ -3857,1 +4069,1 @@\n-        _large_page_size = default_large_page_size;\n+        large_page_size = default_large_page_size;\n@@ -3862,2 +4074,2 @@\n-                           byte_size_in_exact_unit(_large_page_size),\n-                           exact_unit_for_byte_size(_large_page_size));\n+                           byte_size_in_exact_unit(large_page_size),\n+                           exact_unit_for_byte_size(large_page_size));\n@@ -3867,0 +4079,9 @@\n+    \/\/ Do an additional sanity check to see if we can use the desired large page size\n+    if (!hugetlbfs_sanity_check(large_page_size)) {\n+      warn_no_large_pages_configured();\n+      UseLargePages = false;\n+      return;\n+    }\n+\n+    _large_page_size = large_page_size;\n+\n@@ -3875,3 +4096,0 @@\n-  \/\/ Now determine the type of large pages to use:\n-  UseLargePages = os::Linux::setup_large_page_type(_large_page_size);\n-\n@@ -3881,58 +4099,2 @@\n-#ifndef SHM_HUGETLB\n-  #define SHM_HUGETLB 04000\n-#endif\n-\n-#define shm_warning_format(format, ...)              \\\n-  do {                                               \\\n-    if (UseLargePages &&                             \\\n-        (!FLAG_IS_DEFAULT(UseLargePages) ||          \\\n-         !FLAG_IS_DEFAULT(UseSHM) ||                 \\\n-         !FLAG_IS_DEFAULT(LargePageSizeInBytes))) {  \\\n-      warning(format, __VA_ARGS__);                  \\\n-    }                                                \\\n-  } while (0)\n-\n-#define shm_warning(str) shm_warning_format(\"%s\", str)\n-\n-#define shm_warning_with_errno(str)                \\\n-  do {                                             \\\n-    int err = errno;                               \\\n-    shm_warning_format(str \" (error = %d)\", err);  \\\n-  } while (0)\n-\n-static char* shmat_with_alignment(int shmid, size_t bytes, size_t alignment) {\n-  assert(is_aligned(bytes, alignment), \"Must be divisible by the alignment\");\n-\n-  if (!is_aligned(alignment, SHMLBA)) {\n-    assert(false, \"Code below assumes that alignment is at least SHMLBA aligned\");\n-    return nullptr;\n-  }\n-\n-  \/\/ To ensure that we get 'alignment' aligned memory from shmat,\n-  \/\/ we pre-reserve aligned virtual memory and then attach to that.\n-\n-  char* pre_reserved_addr = anon_mmap_aligned(nullptr \/* req_addr *\/, bytes, alignment);\n-  if (pre_reserved_addr == nullptr) {\n-    \/\/ Couldn't pre-reserve aligned memory.\n-    shm_warning(\"Failed to pre-reserve aligned memory for shmat.\");\n-    return nullptr;\n-  }\n-\n-  \/\/ SHM_REMAP is needed to allow shmat to map over an existing mapping.\n-  char* addr = (char*)shmat(shmid, pre_reserved_addr, SHM_REMAP);\n-\n-  if ((intptr_t)addr == -1) {\n-    int err = errno;\n-    shm_warning_with_errno(\"Failed to attach shared memory.\");\n-\n-    assert(err != EACCES, \"Unexpected error\");\n-    assert(err != EIDRM,  \"Unexpected error\");\n-    assert(err != EINVAL, \"Unexpected error\");\n-\n-    \/\/ Since we don't know if the kernel unmapped the pre-reserved memory area\n-    \/\/ we can't unmap it, since that would potentially unmap memory that was\n-    \/\/ mapped from other threads.\n-    return nullptr;\n-  }\n-\n-  return addr;\n+bool os::Linux::thp_requested() {\n+  return _thp_requested;\n@@ -3941,14 +4103,2 @@\n-static char* shmat_at_address(int shmid, char* req_addr) {\n-  if (!is_aligned(req_addr, SHMLBA)) {\n-    assert(false, \"Requested address needs to be SHMLBA aligned\");\n-    return nullptr;\n-  }\n-\n-  char* addr = (char*)shmat(shmid, req_addr, 0);\n-\n-  if ((intptr_t)addr == -1) {\n-    shm_warning_with_errno(\"Failed to attach shared memory.\");\n-    return nullptr;\n-  }\n-\n-  return addr;\n+bool os::Linux::should_madvise_anonymous_thps() {\n+  return _thp_requested && HugePages::thp_mode() == THPMode::madvise;\n@@ -3957,66 +4107,2 @@\n-static char* shmat_large_pages(int shmid, size_t bytes, size_t alignment, char* req_addr) {\n-  \/\/ If a req_addr has been provided, we assume that the caller has already aligned the address.\n-  if (req_addr != nullptr) {\n-    assert(is_aligned(req_addr, os::large_page_size()), \"Must be divisible by the large page size\");\n-    assert(is_aligned(req_addr, alignment), \"Must be divisible by given alignment\");\n-    return shmat_at_address(shmid, req_addr);\n-  }\n-\n-  \/\/ Since shmid has been setup with SHM_HUGETLB, shmat will automatically\n-  \/\/ return large page size aligned memory addresses when req_addr == nullptr.\n-  \/\/ However, if the alignment is larger than the large page size, we have\n-  \/\/ to manually ensure that the memory returned is 'alignment' aligned.\n-  if (alignment > os::large_page_size()) {\n-    assert(is_aligned(alignment, os::large_page_size()), \"Must be divisible by the large page size\");\n-    return shmat_with_alignment(shmid, bytes, alignment);\n-  } else {\n-    return shmat_at_address(shmid, nullptr);\n-  }\n-}\n-\n-char* os::Linux::reserve_memory_special_shm(size_t bytes, size_t alignment,\n-                                            char* req_addr, bool exec) {\n-  \/\/ \"exec\" is passed in but not used.  Creating the shared image for\n-  \/\/ the code cache doesn't have an SHM_X executable permission to check.\n-  assert(UseLargePages && UseSHM, \"only for SHM large pages\");\n-  assert(is_aligned(req_addr, os::large_page_size()), \"Unaligned address\");\n-  assert(is_aligned(req_addr, alignment), \"Unaligned address\");\n-\n-  if (!is_aligned(bytes, os::large_page_size())) {\n-    return nullptr; \/\/ Fallback to small pages.\n-  }\n-\n-  \/\/ Create a large shared memory region to attach to based on size.\n-  \/\/ Currently, size is the total size of the heap.\n-  int shmid = shmget(IPC_PRIVATE, bytes, SHM_HUGETLB|IPC_CREAT|SHM_R|SHM_W);\n-  if (shmid == -1) {\n-    \/\/ Possible reasons for shmget failure:\n-    \/\/ 1. shmmax is too small for the request.\n-    \/\/    > check shmmax value: cat \/proc\/sys\/kernel\/shmmax\n-    \/\/    > increase shmmax value: echo \"new_value\" > \/proc\/sys\/kernel\/shmmax\n-    \/\/ 2. not enough large page memory.\n-    \/\/    > check available large pages: cat \/proc\/meminfo\n-    \/\/    > increase amount of large pages:\n-    \/\/          sysctl -w vm.nr_hugepages=new_value\n-    \/\/    > For more information regarding large pages please refer to:\n-    \/\/      https:\/\/www.kernel.org\/doc\/Documentation\/vm\/hugetlbpage.txt\n-    \/\/      Note 1: different Linux may use different name for this property,\n-    \/\/            e.g. on Redhat AS-3 it is \"hugetlb_pool\".\n-    \/\/      Note 2: it's possible there's enough physical memory available but\n-    \/\/            they are so fragmented after a long run that they can't\n-    \/\/            coalesce into large pages. Try to reserve large pages when\n-    \/\/            the system is still \"fresh\".\n-    shm_warning_with_errno(\"Failed to reserve shared memory.\");\n-    return nullptr;\n-  }\n-\n-  \/\/ Attach to the region.\n-  char* addr = shmat_large_pages(shmid, bytes, alignment, req_addr);\n-\n-  \/\/ Remove shmid. If shmat() is successful, the actual shared memory segment\n-  \/\/ will be deleted when it's detached by shmdt() or when the process\n-  \/\/ terminates. If shmat() is not successful this will remove the shared\n-  \/\/ segment immediately.\n-  shmctl(shmid, IPC_RMID, nullptr);\n-\n-  return addr;\n+bool os::Linux::should_madvise_shmem_thps() {\n+  return _thp_requested && HugePages::shmem_thp_mode() == ShmemTHPMode::advise;\n@@ -4035,1 +4121,1 @@\n-bool os::Linux::commit_memory_special(size_t bytes,\n+static bool commit_memory_special(size_t bytes,\n@@ -4039,1 +4125,2 @@\n-  assert(UseLargePages && UseHugeTLBFS, \"Should only get here when HugeTLBFS large pages are used\");\n+  assert(UseLargePages, \"Should only get here for huge pages\");\n+  assert(!UseTransparentHugePages, \"Should only get here for explicit hugepage mode\");\n@@ -4068,6 +4155,7 @@\n-char* os::Linux::reserve_memory_special_huge_tlbfs(size_t bytes,\n-                                                   size_t alignment,\n-                                                   size_t page_size,\n-                                                   char* req_addr,\n-                                                   bool exec) {\n-  assert(UseLargePages && UseHugeTLBFS, \"only for Huge TLBFS large pages\");\n+static char* reserve_memory_special_huge_tlbfs(size_t bytes,\n+                                               size_t alignment,\n+                                               size_t page_size,\n+                                               char* req_addr,\n+                                               bool exec) {\n+  const os::PageSizes page_sizes = HugePages::explicit_hugepage_info().pagesizes();\n+  assert(UseLargePages, \"only for Huge TLBFS large pages\");\n@@ -4077,1 +4165,1 @@\n-  assert(_page_sizes.contains(page_size), \"Must be a valid page size\");\n+  assert(page_sizes.contains(page_size), \"Must be a valid page size\");\n@@ -4111,1 +4199,6 @@\n-    ::munmap(small_start, small_size);\n+    if (::munmap(small_start, small_size) != 0) {\n+      ErrnoPreserver ep;\n+      log_trace(os, map)(\"munmap failed: \" RANGEFMT \" errno=(%s)\",\n+                         RANGEFMTARGS(small_start, small_size),\n+                         os::strerror(ep.saved_errno()));\n+    }\n@@ -4120,1 +4213,6 @@\n-    ::munmap(aligned_start, large_bytes);\n+    if (::munmap(aligned_start, large_bytes) != 0) {\n+      ErrnoPreserver ep;\n+      log_trace(os, map)(\"munmap failed: \" RANGEFMT \" errno=(%s)\",\n+                         RANGEFMTARGS(aligned_start, large_bytes),\n+                         os::strerror(ep.saved_errno()));\n+    }\n@@ -4130,8 +4228,1 @@\n-  char* addr;\n-  if (UseSHM) {\n-    \/\/ No support for using specific page sizes with SHM.\n-    addr = os::Linux::reserve_memory_special_shm(bytes, alignment, req_addr, exec);\n-  } else {\n-    assert(UseHugeTLBFS, \"must be\");\n-    addr = os::Linux::reserve_memory_special_huge_tlbfs(bytes, alignment, page_size, req_addr, exec);\n-  }\n+  char* const addr = reserve_memory_special_huge_tlbfs(bytes, alignment, page_size, req_addr, exec);\n@@ -4148,9 +4239,0 @@\n-bool os::Linux::release_memory_special_shm(char* base, size_t bytes) {\n-  \/\/ detaching the SHM segment will also delete it, see reserve_memory_special_shm()\n-  return shmdt(base) == 0;\n-}\n-\n-bool os::Linux::release_memory_special_huge_tlbfs(char* base, size_t bytes) {\n-  return pd_release_memory(base, bytes);\n-}\n-\n@@ -4159,9 +4241,2 @@\n-  bool res;\n-\n-  if (UseSHM) {\n-    res = os::Linux::release_memory_special_shm(base, bytes);\n-  } else {\n-    assert(UseHugeTLBFS, \"must be\");\n-    res = os::Linux::release_memory_special_huge_tlbfs(base, bytes);\n-  }\n-  return res;\n+  \/\/ Plain munmap is sufficient\n+  return pd_release_memory(base, bytes);\n@@ -4174,4 +4249,3 @@\n-\/\/ With SysV SHM the entire memory region must be allocated as shared\n-\/\/ memory.\n-\/\/ HugeTLBFS allows application to commit large page memory on demand.\n-\/\/ However, when committing memory with HugeTLBFS fails, the region\n+\/\/ explicit hugepages (hugetlbfs) allow application to commit large page memory\n+\/\/ on demand.\n+\/\/ However, when committing memory with hugepages fails, the region\n@@ -4180,1 +4254,2 @@\n-\/\/ behavior we can't commit HugeTLBFS memory.\n+\/\/ behavior we can't commit hugetlbfs memory. Instead, we commit that\n+\/\/ memory at reservation.\n@@ -4185,4 +4260,0 @@\n-bool os::can_execute_large_page_memory() {\n-  return UseTransparentHugePages || UseHugeTLBFS;\n-}\n-\n@@ -4220,0 +4291,4 @@\n+    log_trace(os, map)(\"Kernel rejected \" PTR_FORMAT\n+                       \", offered \" PTR_FORMAT \".\",\n+                       p2i(requested_addr),\n+                       p2i(addr));\n@@ -4226,17 +4301,18 @@\n-\/\/ Used to convert frequent JVM_Yield() to nops\n-bool os::dont_yield() {\n-  return DontYieldALot;\n-}\n-\n-\/\/ Linux CFS scheduler (since 2.6.23) does not guarantee sched_yield(2) will\n-\/\/ actually give up the CPU. Since skip buddy (v2.6.28):\n-\/\/\n-\/\/ * Sets the yielding task as skip buddy for current CPU's run queue.\n-\/\/ * Picks next from run queue, if empty, picks a skip buddy (can be the yielding task).\n-\/\/ * Clears skip buddies for this run queue (yielding task no longer a skip buddy).\n-\/\/\n-\/\/ An alternative is calling os::naked_short_nanosleep with a small number to avoid\n-\/\/ getting re-scheduled immediately.\n-\/\/\n-void os::naked_yield() {\n-  sched_yield();\n+size_t os::vm_min_address() {\n+  \/\/ Determined by sysctl vm.mmap_min_addr. It exists as a safety zone to prevent\n+  \/\/ null pointer dereferences.\n+  \/\/ Most distros set this value to 64 KB. It *can* be zero, but rarely is. Here,\n+  \/\/ we impose a minimum value if vm.mmap_min_addr is too low, for increased protection.\n+  static size_t value = 0;\n+  if (value == 0) {\n+    assert(is_aligned(_vm_min_address_default, os::vm_allocation_granularity()), \"Sanity\");\n+    FILE* f = os::fopen(\"\/proc\/sys\/vm\/mmap_min_addr\", \"r\");\n+    if (f != nullptr) {\n+      if (fscanf(f, \"%zu\", &value) != 1) {\n+        value = _vm_min_address_default;\n+      }\n+      fclose(f);\n+    }\n+    value = MAX2(_vm_min_address_default, value);\n+  }\n+  return value;\n@@ -4332,0 +4408,7 @@\n+\/\/ copy data between two file descriptor within the kernel\n+\/\/ the number of bytes written to out_fd is returned if transfer was successful\n+\/\/ otherwise, returns -1 that implies an error\n+jlong os::Linux::sendfile(int out_fd, int in_fd, jlong* offset, jlong count) {\n+  return ::sendfile(out_fd, in_fd, (off_t*)offset, (size_t)count);\n+}\n+\n@@ -4404,2 +4487,2 @@\n-  clock_tics_per_sec = sysconf(_SC_CLK_TCK);\n-  int sys_pg_size = sysconf(_SC_PAGESIZE);\n+  clock_tics_per_sec = checked_cast<int>(sysconf(_SC_CLK_TCK));\n+  int sys_pg_size = checked_cast<int>(sysconf(_SC_PAGESIZE));\n@@ -4410,1 +4493,1 @@\n-  size_t page_size = (size_t) sys_pg_size;\n+  size_t page_size = sys_pg_size;\n@@ -4444,0 +4527,3 @@\n+  \/\/ Check the availability of MADV_POPULATE_WRITE.\n+  FLAG_SET_DEFAULT(UseMadvPopulateWrite, (::madvise(0, 0, MADV_POPULATE_WRITE) == 0));\n+\n@@ -4514,1 +4600,1 @@\n-    \/\/ With SHM and HugeTLBFS large pages we cannot uncommit a page, so there's no way\n+    \/\/ With static large pages we cannot uncommit a page, so there's no way\n@@ -4516,2 +4602,1 @@\n-    \/\/ UseNUMA and UseLargePages (or UseSHM\/UseHugeTLBFS) on the command line - warn\n-    \/\/ and disable adaptive resizing.\n+    \/\/ UseNUMA and UseLargePages on the command line - warn and disable adaptive resizing.\n@@ -4519,1 +4604,1 @@\n-      warning(\"UseNUMA is not fully compatible with SHM\/HugeTLBFS large pages, \"\n+      warning(\"UseNUMA is not fully compatible with +UseLargePages, \"\n@@ -4754,1 +4839,1 @@\n-  int cpus_size = sizeof(cpu_set_t);\n+  size_t cpus_size = sizeof(cpu_set_t);\n@@ -4778,1 +4863,1 @@\n-       int online_cpus = ::sysconf(_SC_NPROCESSORS_ONLN);\n+       int online_cpus = checked_cast<int>(::sysconf(_SC_NPROCESSORS_ONLN));\n@@ -4810,1 +4895,1 @@\n-    cpu_count = ::sysconf(_SC_NPROCESSORS_ONLN);\n+    cpu_count = checked_cast<int>(::sysconf(_SC_NPROCESSORS_ONLN));\n@@ -5008,1 +5093,1 @@\n-  int fd = ::open64(path, oflag, mode);\n+  int fd = ::open(path, oflag, mode);\n@@ -5013,3 +5098,3 @@\n-    struct stat64 buf64;\n-    int ret = ::fstat64(fd, &buf64);\n-    int st_mode = buf64.st_mode;\n+    struct stat buf;\n+    int ret = ::fstat(fd, &buf);\n+    int st_mode = buf.st_mode;\n@@ -5047,8 +5132,0 @@\n-\n-\/\/ create binary file, rewriting existing file if required\n-int os::create_binary_file(const char* path, bool rewrite_existing) {\n-  int oflags = O_WRONLY | O_CREAT;\n-  oflags |= rewrite_existing ? O_TRUNC : O_EXCL;\n-  return ::open64(path, oflags, S_IREAD | S_IWRITE);\n-}\n-\n@@ -5057,1 +5134,1 @@\n-  return (jlong)::lseek64(fd, (off64_t)0, SEEK_CUR);\n+  return (jlong)::lseek(fd, (off_t)0, SEEK_CUR);\n@@ -5062,46 +5139,1 @@\n-  return (jlong)::lseek64(fd, (off64_t)offset, SEEK_SET);\n-}\n-\n-\/\/ Map a block of memory.\n-char* os::pd_map_memory(int fd, const char* file_name, size_t file_offset,\n-                        char *addr, size_t bytes, bool read_only,\n-                        bool allow_exec) {\n-  int prot;\n-  int flags = MAP_PRIVATE;\n-\n-  if (read_only) {\n-    prot = PROT_READ;\n-  } else {\n-    prot = PROT_READ | PROT_WRITE;\n-  }\n-\n-  if (allow_exec) {\n-    prot |= PROT_EXEC;\n-  }\n-\n-  if (addr != nullptr) {\n-    flags |= MAP_FIXED;\n-  }\n-\n-  char* mapped_address = (char*)mmap(addr, (size_t)bytes, prot, flags,\n-                                     fd, file_offset);\n-  if (mapped_address == MAP_FAILED) {\n-    return nullptr;\n-  }\n-  return mapped_address;\n-}\n-\n-\n-\/\/ Remap a block of memory.\n-char* os::pd_remap_memory(int fd, const char* file_name, size_t file_offset,\n-                          char *addr, size_t bytes, bool read_only,\n-                          bool allow_exec) {\n-  \/\/ same as map_memory() on this OS\n-  return os::map_memory(fd, file_name, file_offset, addr, bytes, read_only,\n-                        allow_exec);\n-}\n-\n-\n-\/\/ Unmap a block of memory.\n-bool os::pd_unmap_memory(char* addr, size_t bytes) {\n-  return munmap(addr, bytes) == 0;\n+  return (jlong)::lseek(fd, (off_t)offset, SEEK_SET);\n@@ -5172,1 +5204,1 @@\n-  int statlen;\n+  size_t statlen;\n@@ -5318,1 +5350,1 @@\n-  return strlen(buffer);\n+  return checked_cast<int>(strlen(buffer));\n@@ -5378,1 +5410,1 @@\n-\/\/ ** P1 (aka bottom) and size (P2 = P1 - size) are the address and stack size\n+\/\/ ** P1 (aka bottom) and size are the address and stack size\n@@ -5380,0 +5412,1 @@\n+\/\/ ** P2 (aka stack top or base) = P1 + size\n@@ -5385,1 +5418,2 @@\n-static void current_stack_region(address * bottom, size_t * size) {\n+void os::current_stack_base_and_size(address* base, size_t* size) {\n+  address bottom;\n@@ -5389,2 +5423,3 @@\n-    *bottom = os::Linux::initial_thread_stack_bottom();\n-    *size   = os::Linux::initial_thread_stack_size();\n+    bottom = os::Linux::initial_thread_stack_bottom();\n+    *size = os::Linux::initial_thread_stack_size();\n+    *base = bottom + *size;\n@@ -5405,1 +5440,1 @@\n-    if (pthread_attr_getstack(&attr, (void **)bottom, size) != 0) {\n+    if (pthread_attr_getstack(&attr, (void **)&bottom, size) != 0) {\n@@ -5409,0 +5444,2 @@\n+    *base = bottom + *size;\n+\n@@ -5415,2 +5452,2 @@\n-      *bottom += guard_size;\n-      *size   -= guard_size;\n+      bottom += guard_size;\n+      *size  -= guard_size;\n@@ -5420,10 +5457,2 @@\n-\n-  assert(os::current_stack_pointer() >= *bottom &&\n-         os::current_stack_pointer() < *bottom + *size, \"just checking\");\n-}\n-\n-address os::current_stack_base() {\n-  address bottom;\n-  size_t size;\n-  current_stack_region(&bottom, &size);\n-  return (bottom + size);\n+  assert(os::current_stack_pointer() >= bottom &&\n+         os::current_stack_pointer() < *base, \"just checking\");\n@@ -5433,8 +5462,0 @@\n-size_t os::current_stack_size() {\n-  \/\/ This stack size includes the usable stack and HotSpot guard pages\n-  \/\/ (for the threads that have Hotspot guard pages).\n-  address bottom;\n-  size_t size;\n-  current_stack_region(&bottom, &size);\n-  return size;\n-}\n@@ -5453,1 +5474,1 @@\n-  int diff = filetime1.tv_sec - filetime2.tv_sec;\n+  int diff = primitive_compare(filetime1.tv_sec, filetime2.tv_sec);\n@@ -5455,1 +5476,1 @@\n-    return filetime1.tv_nsec - filetime2.tv_nsec;\n+    diff = primitive_compare(filetime1.tv_nsec, filetime2.tv_nsec);\n@@ -5488,1 +5509,0 @@\n-    st->cr();\n@@ -5563,0 +5583,22 @@\n+\n+bool os::pd_dll_unload(void* libhandle, char* ebuf, int ebuflen) {\n+\n+  if (ebuf && ebuflen > 0) {\n+    ebuf[0] = '\\0';\n+    ebuf[ebuflen - 1] = '\\0';\n+  }\n+\n+  bool res = (0 == ::dlclose(libhandle));\n+  if (!res) {\n+    \/\/ error analysis when dlopen fails\n+    const char* error_report = ::dlerror();\n+    if (error_report == nullptr) {\n+      error_report = \"dlerror returned no error description\";\n+    }\n+    if (ebuf != nullptr && ebuflen > 0) {\n+      snprintf(ebuf, ebuflen - 1, \"%s\", error_report);\n+    }\n+  }\n+\n+  return res;\n+} \/\/ end: os::pd_dll_unload()\n","filename":"src\/hotspot\/os\/linux\/os_linux.cpp","additions":561,"deletions":519,"binary":false,"changes":1080,"status":"modified"},{"patch":"@@ -37,1 +37,0 @@\n-  friend class TestReserveMemorySpecial;\n@@ -80,14 +79,0 @@\n-  static bool setup_large_page_type(size_t page_size);\n-  static bool hugetlbfs_sanity_check(bool warn, size_t page_size);\n-  static bool shm_hugetlbfs_sanity_check(bool warn, size_t page_size);\n-\n-  static int hugetlbfs_page_size_flag(size_t page_size);\n-\n-  static char* reserve_memory_special_shm(size_t bytes, size_t alignment, char* req_addr, bool exec);\n-  static char* reserve_memory_special_huge_tlbfs(size_t bytes, size_t alignment, size_t page_size, char* req_addr, bool exec);\n-  static bool commit_memory_special(size_t bytes, size_t page_size, char* req_addr, bool exec);\n-\n-  static bool release_memory_special_impl(char* base, size_t bytes);\n-  static bool release_memory_special_shm(char* base, size_t bytes);\n-  static bool release_memory_special_huge_tlbfs(char* base, size_t bytes);\n-\n@@ -113,0 +98,2 @@\n+  static void kernel_version(long* major, long* minor);\n+\n@@ -172,0 +159,2 @@\n+  static jlong sendfile(int out_fd, int in_fd, jlong* offset, jlong count);\n+\n@@ -193,0 +182,11 @@\n+  \/\/ Tells if the user asked for transparent huge pages.\n+  static bool _thp_requested;\n+\n+  static void large_page_init();\n+\n+  static bool thp_requested();\n+  static bool should_madvise_anonymous_thps();\n+  static bool should_madvise_shmem_thps();\n+\n+  static void madvise_transparent_huge_pages(void* addr, size_t bytes);\n+\n","filename":"src\/hotspot\/os\/linux\/os_linux.hpp","additions":15,"deletions":15,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -0,0 +1,563 @@\n+\/*\n+ * Copyright (c) 2005, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"attachListener_posix.hpp\"\n+#include \"logging\/log.hpp\"\n+#include \"memory\/allocation.inline.hpp\"\n+#include \"memory\/resourceArea.hpp\"\n+#include \"runtime\/interfaceSupport.inline.hpp\"\n+#include \"runtime\/os.inline.hpp\"\n+#include \"os_posix.hpp\"\n+#include \"posixAttachOperation.hpp\"\n+#include \"services\/attachListener.hpp\"\n+#include \"utilities\/checkedCast.hpp\"\n+#include \"utilities\/macros.hpp\"\n+\n+#include <unistd.h>\n+#include <signal.h>\n+#include <sys\/types.h>\n+#include <sys\/socket.h>\n+#include <sys\/un.h>\n+#include <sys\/stat.h>\n+\n+#if INCLUDE_SERVICES\n+#ifndef AIX\n+\n+#ifndef UNIX_PATH_MAX\n+#define UNIX_PATH_MAX   sizeof(((struct sockaddr_un *)0)->sun_path)\n+#endif\n+\n+\/\/ The attach mechanism on Linux and BSD uses a UNIX domain socket. An attach\n+\/\/ listener thread is created at startup or is created on-demand via a signal\n+\/\/ from the client tool. The attach listener creates a socket and binds it to a\n+\/\/ file in the filesystem. The attach listener then acts as a simple (single-\n+\/\/ threaded) server - it waits for a client to connect, reads the request,\n+\/\/ executes it, and returns the response to the client via the socket\n+\/\/ connection.\n+\/\/\n+\/\/ As the socket is a UNIX domain socket it means that only clients on the\n+\/\/ local machine can connect. In addition there are two other aspects to\n+\/\/ the security:\n+\/\/ 1. The well known file that the socket is bound to has permission 400\n+\/\/ 2. When a client connect, the SO_PEERCRED socket option is used to\n+\/\/    obtain the credentials of client. We check that the effective uid\n+\/\/    of the client matches this process.\n+\n+\/\/ statics\n+char PosixAttachListener::_path[UNIX_PATH_MAX];\n+bool PosixAttachListener::_has_path;\n+volatile int PosixAttachListener::_listener = -1;\n+bool PosixAttachListener::_atexit_registered = false;\n+PosixAttachOperation* PosixAttachListener::_current_op = NULL;\n+\n+\/\/ Supporting class to help split a buffer into individual components\n+class ArgumentIterator : public StackObj {\n+ private:\n+  char* _pos;\n+  char* _end;\n+ public:\n+  ArgumentIterator(char* arg_buffer, size_t arg_size) {\n+    _pos = arg_buffer;\n+    _end = _pos + arg_size - 1;\n+  }\n+  char* next() {\n+    if (*_pos == '\\0') {\n+      \/\/ advance the iterator if possible (null arguments)\n+      if (_pos < _end) {\n+        _pos += 1;\n+      }\n+      return nullptr;\n+    }\n+    char* res = _pos;\n+    char* next_pos = strchr(_pos, '\\0');\n+    if (next_pos < _end)  {\n+      next_pos++;\n+    }\n+    _pos = next_pos;\n+    return res;\n+  }\n+};\n+\n+\n+\/\/ atexit hook to stop listener and unlink the file that it is\n+\/\/ bound too.\n+extern \"C\" {\n+  static void listener_cleanup() {\n+    int s = PosixAttachListener::listener();\n+    if (s != -1) {\n+      PosixAttachListener::set_listener(-1);\n+      ::shutdown(s, SHUT_RDWR);\n+      ::close(s);\n+    }\n+    if (PosixAttachListener::has_path()) {\n+      ::unlink(PosixAttachListener::path());\n+      PosixAttachListener::set_path(nullptr);\n+    }\n+  }\n+}\n+\n+\/\/ Initialization - create a listener socket and bind it to a file\n+\n+int PosixAttachListener::init() {\n+  char path[UNIX_PATH_MAX];          \/\/ socket file\n+  char initial_path[UNIX_PATH_MAX];  \/\/ socket file during setup\n+  int listener;                      \/\/ listener socket (file descriptor)\n+\n+  static_assert(sizeof(off_t) == 8, \"Expected Large File Support in this file\");\n+\n+  \/\/ register function to cleanup\n+  if (!_atexit_registered) {\n+    _atexit_registered = true;\n+    ::atexit(listener_cleanup);\n+  }\n+\n+  int n = snprintf(path, UNIX_PATH_MAX, \"%s\/.java_pid%d\",\n+                   os::get_temp_directory(), os::current_process_id());\n+  if (n < (int)UNIX_PATH_MAX) {\n+    n = snprintf(initial_path, UNIX_PATH_MAX, \"%s.tmp\", path);\n+  }\n+  if (n >= (int)UNIX_PATH_MAX) {\n+    return -1;\n+  }\n+\n+  \/\/ create the listener socket\n+  listener = ::socket(PF_UNIX, SOCK_STREAM, 0);\n+  if (listener == -1) {\n+    return -1;\n+  }\n+\n+  \/\/ bind socket\n+  struct sockaddr_un addr;\n+  memset((void *)&addr, 0, sizeof(addr));\n+  addr.sun_family = AF_UNIX;\n+  strcpy(addr.sun_path, initial_path);\n+  ::unlink(initial_path);\n+  int res = ::bind(listener, (struct sockaddr*)&addr, sizeof(addr));\n+  if (res == -1) {\n+    ::close(listener);\n+    return -1;\n+  }\n+\n+  \/\/ put in listen mode, set permissions, and rename into place\n+  res = ::listen(listener, 5);\n+  if (res == 0) {\n+    RESTARTABLE(::chmod(initial_path, S_IREAD|S_IWRITE), res);\n+    if (res == 0) {\n+      \/\/ make sure the file is owned by the effective user and effective group\n+      \/\/ e.g. the group could be inherited from the directory in case the s bit\n+      \/\/ is set. The default behavior on mac is that new files inherit the group\n+      \/\/ of the directory that they are created in.\n+      RESTARTABLE(::chown(initial_path, geteuid(), getegid()), res);\n+      if (res == 0) {\n+        res = ::rename(initial_path, path);\n+      }\n+    }\n+  }\n+  if (res == -1) {\n+    ::close(listener);\n+    ::unlink(initial_path);\n+    return -1;\n+  }\n+  set_path(path);\n+  set_listener(listener);\n+\n+  return 0;\n+}\n+\n+\/\/ Given a socket that is connected to a peer we read the request and\n+\/\/ create an AttachOperation. As the socket is blocking there is potential\n+\/\/ for a denial-of-service if the peer does not response. However this happens\n+\/\/ after the peer credentials have been checked and in the worst case it just\n+\/\/ means that the attach listener thread is blocked.\n+\/\/\n+PosixAttachOperation* PosixAttachListener::read_request(int s) {\n+  char ver_str[8];\n+  os::snprintf_checked(ver_str, sizeof(ver_str), \"%d\", ATTACH_PROTOCOL_VER);\n+\n+  \/\/ The request is a sequence of strings so we first figure out the\n+  \/\/ expected count and the maximum possible length of the request.\n+  \/\/ The request is:\n+  \/\/   <ver>0<cmd>0<arg>0<arg>0<arg>0\n+  \/\/ where <ver> is the protocol version (1), <cmd> is the command\n+  \/\/ name (\"load\", \"datadump\", ...), and <arg> is an argument\n+  int expected_str_count = 2 + AttachOperation::arg_count_max;\n+  const size_t max_len = (sizeof(ver_str) + 1) + (AttachOperation::name_length_max + 1) +\n+    AttachOperation::arg_count_max*(AttachOperation::arg_length_max + 1);\n+\n+  char buf[max_len];\n+  int str_count = 0;\n+\n+  \/\/ Read until all (expected) strings have been read, the buffer is\n+  \/\/ full, or EOF.\n+\n+  size_t off = 0;\n+  size_t left = max_len;\n+\n+  do {\n+    ssize_t n;\n+    RESTARTABLE(read(s, buf+off, left), n);\n+    assert(n <= checked_cast<ssize_t>(left), \"buffer was too small, impossible!\");\n+    buf[max_len - 1] = '\\0';\n+    if (n == -1) {\n+      return nullptr;      \/\/ reset by peer or other error\n+    }\n+    if (n == 0) {\n+      break;\n+    }\n+    for (ssize_t i=0; i<n; i++) {\n+      if (buf[off+i] == 0) {\n+        \/\/ EOS found\n+        str_count++;\n+\n+        \/\/ The first string is <ver> so check it now to\n+        \/\/ check for protocol mismatch\n+        if (str_count == 1) {\n+          if ((strlen(buf) != strlen(ver_str)) ||\n+              (atoi(buf) != ATTACH_PROTOCOL_VER)) {\n+            char msg[32];\n+            os::snprintf_checked(msg, sizeof(msg), \"%d\\n\", ATTACH_ERROR_BADVERSION);\n+            write_fully(s, msg, strlen(msg));\n+            return nullptr;\n+          }\n+        }\n+      }\n+    }\n+    off += n;\n+    left -= n;\n+  } while (left > 0 && str_count < expected_str_count);\n+\n+  if (str_count != expected_str_count) {\n+    return nullptr;        \/\/ incomplete request\n+  }\n+\n+  \/\/ parse request\n+\n+  ArgumentIterator args(buf, (max_len)-left);\n+\n+  \/\/ version already checked\n+  char* v = args.next();\n+\n+  char* name = args.next();\n+  if (name == nullptr || strlen(name) > AttachOperation::name_length_max) {\n+    return nullptr;\n+  }\n+\n+  PosixAttachOperation* op = new PosixAttachOperation(name);\n+\n+  for (int i=0; i<AttachOperation::arg_count_max; i++) {\n+    char* arg = args.next();\n+    if (arg == nullptr) {\n+      op->set_arg(i, nullptr);\n+    } else {\n+      if (strlen(arg) > AttachOperation::arg_length_max) {\n+        delete op;\n+        return nullptr;\n+      }\n+      op->set_arg(i, arg);\n+    }\n+  }\n+\n+  op->set_socket(s);\n+  return op;\n+}\n+\n+\/\/ Dequeue an operation\n+\/\/\n+\/\/ In the Linux and BSD implementations, there is only a single operation and\n+\/\/ clients cannot queue commands (except at the socket level).\n+\/\/\n+PosixAttachOperation* PosixAttachListener::dequeue() {\n+  for (;;) {\n+    int s;\n+\n+    \/\/ wait for client to connect\n+    struct sockaddr addr;\n+    socklen_t len = sizeof(addr);\n+    RESTARTABLE(::accept(listener(), &addr, &len), s);\n+    if (s == -1) {\n+      return nullptr;      \/\/ log a warning?\n+    }\n+\n+    \/\/ get the credentials of the peer and check the effective uid\/guid\n+#ifdef LINUX\n+    struct ucred cred_info;\n+    socklen_t optlen = sizeof(cred_info);\n+    if (::getsockopt(s, SOL_SOCKET, SO_PEERCRED, (void *)&cred_info, &optlen) ==\n+        -1) {\n+      log_debug(attach)(\"Failed to get socket option SO_PEERCRED\");\n+      ::close(s);\n+      continue;\n+    }\n+\n+    if (!os::Posix::matches_effective_uid_and_gid_or_root(cred_info.uid,\n+                                                          cred_info.gid)) {\n+      log_debug(attach)(\"euid\/egid check failed (%d\/%d vs %d\/%d)\",\n+                        cred_info.uid, cred_info.gid, geteuid(), getegid());\n+      ::close(s);\n+      continue;\n+    }\n+#endif\n+#ifdef BSD\n+    uid_t puid;\n+    gid_t pgid;\n+    if (::getpeereid(s, &puid, &pgid) != 0) {\n+      log_debug(attach)(\"Failed to get peer id\");\n+      ::close(s);\n+      continue;\n+    }\n+\n+    if (!os::Posix::matches_effective_uid_and_gid_or_root(puid, pgid)) {\n+      log_debug(attach)(\"euid\/egid check failed (%d\/%d vs %d\/%d)\", puid, pgid,\n+                        geteuid(), getegid());\n+      ::close(s);\n+      continue;\n+    }\n+#endif\n+\n+    \/\/ peer credential look okay so we read the request\n+    PosixAttachOperation* op = read_request(s);\n+    if (op == nullptr) {\n+      ::close(s);\n+      continue;\n+    } else {\n+      _current_op = op;\n+      return op;\n+    }\n+  }\n+}\n+\n+\/\/ write the given buffer to the socket\n+int PosixAttachListener::write_fully(int s, char* buf, size_t len) {\n+  do {\n+    ssize_t n = ::write(s, buf, len);\n+    if (n == -1) {\n+      if (errno != EINTR) return -1;\n+    } else {\n+      buf += n;\n+      len -= n;\n+    }\n+  }\n+  while (len > 0);\n+  return 0;\n+}\n+\n+\/\/ An operation completion is splitted into two parts.\n+\/\/ For proper handling the jcmd connection at CRaC checkpoint action.\n+\/\/ An effectively_complete_raw is called in checkpoint processing, before criu engine calls, for properly closing the socket.\n+\/\/ The complete() gets called after restore for proper deletion the leftover object.\n+\n+void PosixAttachOperation::complete(jint result, bufferedStream* st) {\n+  PosixAttachOperation::effectively_complete_raw(result, st);\n+  \/\/ reset the current op as late as possible, this happens on attach listener thread.\n+  PosixAttachListener::reset_current_op();\n+  delete this;\n+}\n+\n+\/\/ Complete an operation by sending the operation result and any result\n+\/\/ output to the client. At this time the socket is in blocking mode so\n+\/\/ potentially we can block if there is a lot of data and the client is\n+\/\/ non-responsive. For most operations this is a non-issue because the\n+\/\/ default send buffer is sufficient to buffer everything. In the future\n+\/\/ if there are operations that involves a very big reply then it the\n+\/\/ socket could be made non-blocking and a timeout could be used.\n+\n+void PosixAttachOperation::effectively_complete_raw(jint result, bufferedStream* st) {\n+  if (_effectively_completed) {\n+    assert(st->size() == 0, \"no lost output\");\n+    return;\n+  }\n+\n+  \/\/ write operation result\n+  Thread* thread = Thread::current();\n+  if (thread->is_Java_thread()) {\n+    ThreadBlockInVM((JavaThread* )thread);\n+    write_operation_result(result, st);\n+  } else {\n+    write_operation_result(result, st);\n+  }\n+  _effectively_completed = true;\n+}\n+\n+void PosixAttachOperation::write_operation_result(jint result, bufferedStream* st) {\n+  char msg[32];\n+  os::snprintf_checked(msg, sizeof(msg), \"%d\\n\", result);\n+  int rc = PosixAttachListener::write_fully(this->socket(), msg, strlen(msg));\n+\n+  \/\/ write any result data\n+  if (rc == 0) {\n+    PosixAttachListener::write_fully(this->socket(), (char*) st->base(), st->size());\n+    ::shutdown(this->socket(), SHUT_RDWR);\n+  }\n+\n+  \/\/ done\n+  ::close(this->socket());\n+  st->reset();\n+}\n+\n+static void assert_listener_thread() {\n+#ifdef ASSERT\n+  ResourceMark rm; \/\/ For retrieving the thread names\n+  assert(strcmp(\"Attach Listener\", Thread::current()->name()) == 0, \"should gets called from Attach Listener thread\");\n+#endif\n+}\n+\n+PosixAttachOperation* PosixAttachListener::get_current_op() {\n+  assert_listener_thread();\n+  return PosixAttachListener::_current_op;\n+}\n+\n+void PosixAttachListener::reset_current_op() {\n+  assert_listener_thread();\n+  PosixAttachListener::_current_op = NULL;\n+}\n+\n+\/\/ AttachListener functions\n+\n+AttachOperation* AttachListener::dequeue() {\n+  JavaThread* thread = JavaThread::current();\n+  ThreadBlockInVM tbivm(thread);\n+\n+  AttachOperation* op = PosixAttachListener::dequeue();\n+\n+  return op;\n+}\n+\n+\/\/ Performs initialization at vm startup\n+\/\/ For Linux and BSD we remove any stale .java_pid file which could cause\n+\/\/ an attaching process to think we are ready to receive on the\n+\/\/ domain socket before we are properly initialized\n+\n+void AttachListener::vm_start() {\n+  char fn[UNIX_PATH_MAX];\n+  struct stat st;\n+  int ret;\n+\n+  int n = snprintf(fn, UNIX_PATH_MAX, \"%s\/.java_pid%d\",\n+           os::get_temp_directory(), os::current_process_id());\n+  assert(n < (int)UNIX_PATH_MAX, \"java_pid file name buffer overflow\");\n+\n+  RESTARTABLE(::stat(fn, &st), ret);\n+  if (ret == 0) {\n+    ret = ::unlink(fn);\n+    if (ret == -1) {\n+      log_debug(attach)(\"Failed to remove stale attach pid file at %s\", fn);\n+    }\n+  }\n+}\n+\n+int AttachListener::pd_init() {\n+  JavaThread* thread = JavaThread::current();\n+  ThreadBlockInVM tbivm(thread);\n+\n+  int ret_code = PosixAttachListener::init();\n+\n+  return ret_code;\n+}\n+\n+bool AttachListener::check_socket_file() {\n+  int ret;\n+  struct stat st;\n+  ret = stat(PosixAttachListener::path(), &st);\n+  if (ret == -1) { \/\/ need to restart attach listener.\n+    log_debug(attach)(\"Socket file %s does not exist - Restart Attach Listener\",\n+                      PosixAttachListener::path());\n+\n+    listener_cleanup();\n+\n+    \/\/ wait to terminate current attach listener instance...\n+    {\n+      \/\/ avoid deadlock if AttachListener thread is blocked at safepoint\n+      ThreadBlockInVM tbivm(JavaThread::current());\n+      while (AttachListener::transit_state(AL_INITIALIZING,\n+                                           AL_NOT_INITIALIZED) != AL_NOT_INITIALIZED) {\n+        os::naked_yield();\n+      }\n+    }\n+    return is_init_trigger();\n+  }\n+  return false;\n+}\n+\n+\/\/ Attach Listener is started lazily except in the case when\n+\/\/ +ReduseSignalUsage is used\n+bool AttachListener::init_at_startup() {\n+  if (ReduceSignalUsage) {\n+    return true;\n+  } else {\n+    return false;\n+  }\n+}\n+\n+\/\/ If the file .attach_pid<pid> exists in the working directory\n+\/\/ or \/tmp then this is the trigger to start the attach mechanism\n+bool AttachListener::is_init_trigger() {\n+  if (init_at_startup() || is_initialized()) {\n+    return false;               \/\/ initialized at startup or already initialized\n+  }\n+  char fn[PATH_MAX + 1];\n+  int ret;\n+  struct stat st;\n+  os::snprintf_checked(fn, sizeof(fn), \".attach_pid%d\",\n+                       os::current_process_id());\n+  RESTARTABLE(::stat(fn, &st), ret);\n+  if (ret == -1) {\n+    log_trace(attach)(\"Failed to find attach file: %s, trying alternate\", fn);\n+    snprintf(fn, sizeof(fn), \"%s\/.attach_pid%d\", os::get_temp_directory(),\n+             os::current_process_id());\n+    RESTARTABLE(::stat(fn, &st), ret);\n+    if (ret == -1) {\n+      log_debug(attach)(\"Failed to find attach file: %s\", fn);\n+    }\n+  }\n+  if (ret == 0) {\n+    \/\/ simple check to avoid starting the attach mechanism when\n+    \/\/ a bogus non-root user creates the file\n+    if (os::Posix::matches_effective_uid_or_root(st.st_uid)) {\n+      init();\n+      log_trace(attach)(\"Attach triggered by %s\", fn);\n+      return true;\n+    } else {\n+      log_debug(attach)(\"File %s has wrong user id %d (vs %d). Attach is not triggered\", fn, st.st_uid, geteuid());\n+    }\n+  }\n+  return false;\n+}\n+\n+\/\/ if VM aborts then remove listener\n+void AttachListener::abort() {\n+  listener_cleanup();\n+}\n+\n+void AttachListener::pd_data_dump() {\n+  os::signal_notify(SIGQUIT);\n+}\n+\n+void AttachListener::pd_detachall() {\n+  \/\/ do nothing for now\n+}\n+\n+#endif \/\/ !AIX\n+\n+#endif \/\/ INCLUDE_SERVICES\n","filename":"src\/hotspot\/os\/posix\/attachListener_posix.cpp","additions":563,"deletions":0,"binary":false,"changes":563,"status":"added"},{"patch":"@@ -0,0 +1,96 @@\n+\/*\n+ * Copyright (c) 2005, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, Azul Systems, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef OS_POSIX_ATTACHLISTENER_POSIX_HPP\n+#define OS_POSIX_ATTACHLISTENER_POSIX_HPP\n+\n+#include \"posixAttachOperation.hpp\"\n+#include \"services\/attachListener.hpp\"\n+\n+#if INCLUDE_SERVICES\n+\n+#include <sys\/un.h>\n+\n+#ifndef UNIX_PATH_MAX\n+#define UNIX_PATH_MAX   sizeof(((struct sockaddr_un *)0)->sun_path)\n+#endif\n+\n+class PosixAttachListener: AllStatic {\n+ private:\n+  \/\/ the path to which we bind the UNIX domain socket\n+  static char _path[UNIX_PATH_MAX];\n+  static bool _has_path;\n+\n+  \/\/ the file descriptor for the listening socket\n+  static volatile int _listener;\n+\n+  static bool _atexit_registered;\n+\n+  \/\/ this is for proper reporting JDK.Chekpoint processing to jcmd peer\n+  static PosixAttachOperation* _current_op;\n+\n+  \/\/ reads a request from the given connected socket\n+  static PosixAttachOperation* read_request(int s);\n+\n+ public:\n+  enum {\n+    ATTACH_PROTOCOL_VER = 1                     \/\/ protocol version\n+  };\n+  enum {\n+    ATTACH_ERROR_BADVERSION     = 101           \/\/ error codes\n+  };\n+\n+  static void set_path(char* path) {\n+    if (path == nullptr) {\n+      _path[0] = '\\0';\n+      _has_path = false;\n+    } else {\n+      strncpy(_path, path, UNIX_PATH_MAX);\n+      _path[UNIX_PATH_MAX-1] = '\\0';\n+      _has_path = true;\n+    }\n+  }\n+\n+  static void set_listener(int s)               { _listener = s; }\n+\n+  \/\/ initialize the listener, returns 0 if okay\n+  static int init();\n+\n+  static char* path()                   { return _path; }\n+  static bool has_path()                { return _has_path; }\n+  static int listener()                 { return _listener; }\n+\n+  \/\/ write the given buffer to a socket\n+  static int write_fully(int s, char* buf, size_t len);\n+\n+  static PosixAttachOperation* dequeue();\n+  static PosixAttachOperation* get_current_op();\n+  static void reset_current_op();\n+\n+};\n+\n+#endif \/\/ INCLUDE_SERVICES\n+\n+#endif \/\/ OS_POSIX_ATTACHLISTENER_POSIX_HPP\n","filename":"src\/hotspot\/os\/posix\/attachListener_posix.hpp","additions":96,"deletions":0,"binary":false,"changes":96,"status":"added"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,1 @@\n+#include \"nmt\/memTracker.hpp\"\n@@ -31,7 +32,0 @@\n-#include \"runtime\/globals_extension.hpp\"\n-#include \"runtime\/osThread.hpp\"\n-#include \"runtime\/frame.inline.hpp\"\n-#include \"runtime\/interfaceSupport.inline.hpp\"\n-#include \"runtime\/sharedRuntime.hpp\"\n-#include \"services\/attachListener.hpp\"\n-#include \"services\/memTracker.hpp\"\n@@ -41,0 +35,3 @@\n+#include \"runtime\/frame.inline.hpp\"\n+#include \"runtime\/globals_extension.hpp\"\n+#include \"runtime\/interfaceSupport.inline.hpp\"\n@@ -43,0 +40,1 @@\n+#include \"runtime\/osThread.hpp\"\n@@ -45,0 +43,2 @@\n+#include \"runtime\/sharedRuntime.hpp\"\n+#include \"services\/attachListener.hpp\"\n@@ -46,0 +46,1 @@\n+#include \"utilities\/checkedCast.hpp\"\n@@ -53,0 +54,4 @@\n+#if INCLUDE_JFR\n+#include \"jfr\/support\/jfrNativeLibraryLoadEvent.hpp\"\n+#endif\n+\n@@ -55,0 +60,1 @@\n+#include \"os_aix.hpp\"\n@@ -155,5 +161,1 @@\n-        fr.sender_pc() == nullptr || os::is_first_C_frame(&fr)) break;\n-\n-    if (fr.sender_pc() && !os::is_first_C_frame(&fr)) {\n-      fr = os::get_sender_for_C_frame(&fr);\n-    } else {\n+        fr.sender_pc() == nullptr || os::is_first_C_frame(&fr)) {\n@@ -162,0 +164,1 @@\n+    fr = os::get_sender_for_C_frame(&fr);\n@@ -188,0 +191,11 @@\n+\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\/\/ breakpoint support\n+\n+void os::breakpoint() {\n+  BREAKPOINT;\n+}\n+\n+extern \"C\" void breakpoint() {\n+  \/\/ use debugger to set breakpoint here\n+}\n+\n@@ -266,1 +280,1 @@\n-static char* reserve_mmapped_memory(size_t bytes, char* requested_addr) {\n+static char* reserve_mmapped_memory(size_t bytes, char* requested_addr, MEMFLAGS flag) {\n@@ -281,1 +295,1 @@\n-    MemTracker::record_virtual_memory_reserve((address)addr, bytes, CALLER_PC);\n+    MemTracker::record_virtual_memory_reserve((address)addr, bytes, CALLER_PC, flag);\n@@ -288,0 +302,1 @@\n+  static_assert(sizeof(off_t) == 8, \"Expected Large File Support in this file\");\n@@ -345,1 +360,1 @@\n-  assert((alignment & (os::vm_allocation_granularity() - 1)) == 0,\n+  assert(is_aligned(alignment, os::vm_allocation_granularity()),\n@@ -347,1 +362,2 @@\n-  assert((size & (alignment -1)) == 0, \"size must be 'alignment' aligned\");\n+  assert(is_aligned(size, os::vm_allocation_granularity()),\n+      \"Size must be a multiple of allocation granularity (page size)\");\n@@ -392,1 +408,1 @@\n-char* os::map_memory_to_file_aligned(size_t size, size_t alignment, int file_desc) {\n+char* os::map_memory_to_file_aligned(size_t size, size_t alignment, int file_desc, MEMFLAGS flag) {\n@@ -400,1 +416,1 @@\n-  char* extra_base = reserve_mmapped_memory(extra_size, nullptr);\n+  char* extra_base = reserve_mmapped_memory(extra_size, nullptr, flag);\n@@ -413,11 +429,0 @@\n-int os::vsnprintf(char* buf, size_t len, const char* fmt, va_list args) {\n-  \/\/ All supported POSIX platforms provide C99 semantics.\n-  ALLOW_C_FUNCTION(::vsnprintf, int result = ::vsnprintf(buf, len, fmt, args);)\n-  \/\/ If an encoding error occurred (result < 0) then it's not clear\n-  \/\/ whether the buffer is NUL terminated, so ensure it is.\n-  if ((result < 0) && (len > 0)) {\n-    buf[len - 1] = '\\0';\n-  }\n-  return result;\n-}\n-\n@@ -449,1 +454,1 @@\n-  int currsec = time(nullptr);\n+  time_t currsec = time(nullptr);\n@@ -460,1 +465,1 @@\n-    os::print_dhm(st, \"OS uptime:\", (long) (currsec-bootsec));\n+    os::print_dhm(st, \"OS uptime:\", currsec-bootsec);\n@@ -496,1 +501,1 @@\n-  st->print(\"%d\", sysconf(_SC_CHILD_MAX));\n+  st->print(\"%ld\", sysconf(_SC_CHILD_MAX));\n@@ -609,3 +614,8 @@\n-  uname(&name);\n-  jio_snprintf(buf, buflen, \"%s\", name.nodename);\n-  return true;\n+  int retcode = uname(&name);\n+  if (retcode != -1) {\n+    jio_snprintf(buf, buflen, \"%s\", name.nodename);\n+    return true;\n+  }\n+  const char* errmsg = os::strerror(errno);\n+  log_warning(os)(\"Failed to get host name, error message: %s\", errmsg);\n+  return false;\n@@ -710,1 +720,10 @@\n-  return dlsym(handle, name);\n+  ::dlerror(); \/\/ Clear any previous error\n+  void* ret = ::dlsym(handle, name);\n+  if (ret == nullptr) {\n+    const char* tmp = ::dlerror();\n+    \/\/ It is possible that we found a NULL symbol, hence no error.\n+    if (tmp != nullptr) {\n+      log_debug(os)(\"Symbol %s not found in dll: %s\", name, tmp);\n+    }\n+  }\n+  return ret;\n@@ -718,0 +737,1 @@\n+\n@@ -725,0 +745,3 @@\n+\n+  JFR_ONLY(NativeLibraryUnloadEvent unload_event(l_path);)\n+\n@@ -728,2 +751,4 @@\n-  int res = ::dlclose(lib);\n-  if (res == 0) {\n+  char ebuf[1024];\n+  bool res = os::pd_dll_unload(lib, ebuf, sizeof(ebuf));\n+\n+  if (res) {\n@@ -734,0 +759,1 @@\n+    JFR_ONLY(unload_event.set_result(true);)\n@@ -735,6 +761,1 @@\n-    const char* error_report = ::dlerror();\n-    if (error_report == nullptr) {\n-      error_report = \"dlerror returned no error description\";\n-    }\n-\n-                            l_path, p2i(lib), error_report);\n+                            l_path, p2i(lib), ebuf);\n@@ -743,1 +764,2 @@\n-                  l_path, p2i(lib), error_report);\n+                  l_path, p2i(lib), ebuf);\n+    JFR_ONLY(unload_event.set_error_msg(ebuf);)\n@@ -745,2 +767,0 @@\n-  \/\/ Update the dll cache\n-  AIX_ONLY(LoadedLibraries::reload());\n@@ -751,1 +771,1 @@\n-  return (jlong) BSD_ONLY(::lseek) NOT_BSD(::lseek64)(fd, offset, whence);\n+  return (jlong) ::lseek(fd, offset, whence);\n@@ -755,1 +775,1 @@\n-   return BSD_ONLY(::ftruncate) NOT_BSD(::ftruncate64)(fd, length);\n+   return ::ftruncate(fd, length);\n@@ -815,2 +835,2 @@\n-int os::recv(int fd, char* buf, size_t nBytes, uint flags) {\n-  RESTARTABLE_RETURN_INT(::recv(fd, buf, nBytes, flags));\n+ssize_t os::recv(int fd, char* buf, size_t nBytes, uint flags) {\n+  RESTARTABLE_RETURN_SSIZE_T(::recv(fd, buf, nBytes, flags));\n@@ -819,2 +839,2 @@\n-int os::send(int fd, char* buf, size_t nBytes, uint flags) {\n-  RESTARTABLE_RETURN_INT(::send(fd, buf, nBytes, flags));\n+ssize_t os::send(int fd, char* buf, size_t nBytes, uint flags) {\n+  RESTARTABLE_RETURN_SSIZE_T(::send(fd, buf, nBytes, flags));\n@@ -823,1 +843,1 @@\n-int os::raw_send(int fd, char* buf, size_t nBytes, uint flags) {\n+ssize_t os::raw_send(int fd, char* buf, size_t nBytes, uint flags) {\n@@ -827,2 +847,2 @@\n-int os::connect(int fd, struct sockaddr* him, socklen_t len) {\n-  RESTARTABLE_RETURN_INT(::connect(fd, him, len));\n+ssize_t os::connect(int fd, struct sockaddr* him, socklen_t len) {\n+  RESTARTABLE_RETURN_SSIZE_T(::connect(fd, him, len));\n@@ -839,0 +859,8 @@\n+bool os::dont_yield() {\n+  return DontYieldALot;\n+}\n+\n+void os::naked_yield() {\n+  sched_yield();\n+}\n+\n@@ -1224,1 +1252,1 @@\n-  clock_tics_per_sec = sysconf(_SC_CLK_TCK);\n+  clock_tics_per_sec = checked_cast<int>(sysconf(_SC_CLK_TCK));\n@@ -1352,1 +1380,1 @@\n-  DEBUG_ONLY(int max_secs = MAX_SECS;)\n+  DEBUG_ONLY(time_t max_secs = MAX_SECS;)\n@@ -1434,1 +1462,1 @@\n-  return ((double)os::elapsed_counter()) \/ os::elapsed_frequency(); \/\/ nanosecond resolution\n+  return ((double)os::elapsed_counter()) \/ (double)os::elapsed_frequency(); \/\/ nanosecond resolution\n@@ -2075,0 +2103,50 @@\n+\n+\/\/ Map file into memory; uses mmap().\n+\/\/ Notes:\n+\/\/ - if caller specifies addr, MAP_FIXED is used. That means existing\n+\/\/   mappings will be replaced.\n+\/\/ - The file descriptor must be valid (to create anonymous mappings, use\n+\/\/   os::reserve_memory()).\n+\/\/ Returns address to mapped memory, nullptr on error\n+char* os::pd_map_memory(int fd, const char* unused,\n+                        size_t file_offset, char *addr, size_t bytes,\n+                        bool read_only, bool allow_exec) {\n+\n+  assert(fd != -1, \"Specify a valid file descriptor\");\n+\n+  int prot;\n+  int flags = MAP_PRIVATE;\n+\n+  if (read_only) {\n+    prot = PROT_READ;\n+  } else {\n+    prot = PROT_READ | PROT_WRITE;\n+  }\n+\n+  if (allow_exec) {\n+    prot |= PROT_EXEC;\n+  }\n+\n+  if (addr != nullptr) {\n+    flags |= MAP_FIXED;\n+  }\n+\n+  char* mapped_address = (char*)mmap(addr, (size_t)bytes, prot, flags,\n+                                     fd, file_offset);\n+  if (mapped_address == MAP_FAILED) {\n+    return nullptr;\n+  }\n+\n+  \/\/ If we did specify an address, and the mapping succeeded, it should\n+  \/\/ have returned that address since we specify MAP_FIXED\n+  assert(addr == nullptr || addr == mapped_address,\n+         \"mmap+MAP_FIXED returned \" PTR_FORMAT \", expected \" PTR_FORMAT,\n+         p2i(mapped_address), p2i(addr));\n+\n+  return mapped_address;\n+}\n+\n+\/\/ Unmap a block of memory. Uses munmap.\n+bool os::pd_unmap_memory(char* addr, size_t bytes) {\n+  return munmap(addr, bytes) == 0;\n+}\n","filename":"src\/hotspot\/os\/posix\/os_posix.cpp","additions":138,"deletions":60,"binary":false,"changes":198,"status":"modified"},{"patch":"@@ -34,1 +34,1 @@\n-\/\/ non-Posix functionality. For example, the use of lseek64 and ftruncate64.\n+\/\/ non-Posix functionality.\n@@ -47,2 +47,2 @@\n-#define RESTARTABLE_RETURN_INT(_cmd) do { \\\n-  int _result; \\\n+#define RESTARTABLE_RETURN_SSIZE_T(_cmd) do { \\\n+  ssize_t _result; \\\n","filename":"src\/hotspot\/os\/posix\/os_posix.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"nmt\/memTracker.hpp\"\n@@ -40,1 +41,0 @@\n-#include \"services\/memTracker.hpp\"\n@@ -1095,2 +1095,1 @@\n-    \/\/ Note: Tracker contains a ThreadCritical.\n-    Tracker tkr(Tracker::release);\n+    ThreadCritical tc;\n@@ -1099,1 +1098,1 @@\n-      tkr.record((address)addr, bytes);\n+      MemTracker::record_virtual_memory_release((address)addr, bytes);\n","filename":"src\/hotspot\/os\/posix\/perfMemory_posix.cpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -0,0 +1,56 @@\n+\/*\n+ * Copyright (c) 2005, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, Azul Systems, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef OS_POSIX_POSIXATTACHOPERATION_HPP\n+#define OS_POSIX_POSIXATTACHOPERATION_HPP\n+\n+#include \"services\/attachListener.hpp\"\n+\n+#if INCLUDE_SERVICES\n+\n+class PosixAttachOperation: public AttachOperation {\n+ private:\n+  \/\/ the connection to the client\n+  int _socket;\n+  bool _effectively_completed;\n+  void write_operation_result(jint result, bufferedStream* st);\n+\n+ public:\n+  void complete(jint res, bufferedStream* st);\n+  void effectively_complete_raw(jint res, bufferedStream* st);\n+  bool is_effectively_completed()                      { return _effectively_completed; }\n+\n+  void set_socket(int s)                                { _socket = s; }\n+  int socket() const                                    { return _socket; }\n+\n+  PosixAttachOperation(char* name) : AttachOperation(name) {\n+    set_socket(-1);\n+    _effectively_completed = false;\n+  }\n+};\n+\n+#endif \/\/ INCLUDE_SERVICES\n+\n+#endif \/\/ OS_POSIX_POSIXATTACHOPERATION_HPP\n","filename":"src\/hotspot\/os\/posix\/posixAttachOperation.hpp","additions":56,"deletions":0,"binary":false,"changes":56,"status":"added"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,1 +27,1 @@\n-#include \"code\/compiledMethod.hpp\"\n+#include \"code\/nmethod.hpp\"\n@@ -45,0 +45,1 @@\n+#include \"utilities\/checkedCast.hpp\"\n@@ -47,0 +48,1 @@\n+#include \"utilities\/parseInteger.hpp\"\n@@ -341,1 +343,1 @@\n-void jdk_misc_signal_init() {\n+static void jdk_misc_signal_init() {\n@@ -381,1 +383,1 @@\n-struct sigaction* get_chained_signal_action(int sig) {\n+static struct sigaction* get_chained_signal_action(int sig) {\n@@ -504,7 +506,0 @@\n-class ErrnoPreserver: public StackObj {\n-  const int _saved;\n-public:\n-  ErrnoPreserver() : _saved(errno) {}\n-  ~ErrnoPreserver() { errno = _saved; }\n-};\n-\n@@ -621,7 +616,6 @@\n-      if (cb != nullptr && cb->is_compiled()) {\n-        MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXWrite, t);) \/\/ can call PcDescCache::add_pc_desc\n-        CompiledMethod* cm = cb->as_compiled_method();\n-        assert(cm->insts_contains_inclusive(pc), \"\");\n-        address deopt = cm->is_method_handle_return(pc) ?\n-          cm->deopt_mh_handler_begin() :\n-          cm->deopt_handler_begin();\n+      if (cb != nullptr && cb->is_nmethod()) {\n+        nmethod* nm = cb->as_nmethod();\n+        assert(nm->insts_contains_inclusive(pc), \"\");\n+        address deopt = nm->is_method_handle_return(pc) ?\n+          nm->deopt_mh_handler_begin() :\n+          nm->deopt_handler_begin();\n@@ -631,1 +625,1 @@\n-        cm->set_original_pc(&fr, pc);\n+        nm->set_original_pc(&fr, pc);\n@@ -684,1 +678,1 @@\n-  os::print_function_and_library_name(os, handler, buf, buflen,\n+  os::print_function_and_library_name(os, handler, buf, checked_cast<int>(buflen),\n@@ -1246,1 +1240,1 @@\n-void set_signal_handler(int sig) {\n+static void set_signal_handler(int sig) {\n@@ -1293,1 +1287,1 @@\n-void install_signal_handlers() {\n+static void install_signal_handlers() {\n@@ -1737,1 +1731,1 @@\n-int SR_initialize() {\n+static int SR_initialize() {\n@@ -1742,2 +1736,3 @@\n-    int sig = ::strtol(s, 0, 10);\n-    if (sig > MAX2(SIGSEGV, SIGBUS) &&  \/\/ See 4355769.\n+    int sig;\n+    bool result = parse_integer(s, &sig);\n+    if (result && sig > MAX2(SIGSEGV, SIGBUS) &&  \/\/ See 4355769.\n@@ -1747,2 +1742,2 @@\n-      warning(\"You set _JAVA_SR_SIGNUM=%d. It must be in range [%d, %d]. Using %d instead.\",\n-              sig, MAX2(SIGSEGV, SIGBUS)+1, NSIG-1, PosixSignals::SR_signum);\n+      warning(\"You set _JAVA_SR_SIGNUM=%s. It must be a number in range [%d, %d]. Using %d instead.\",\n+              s, MAX2(SIGSEGV, SIGBUS)+1, NSIG-1, PosixSignals::SR_signum);\n","filename":"src\/hotspot\/os\/posix\/signals_posix.cpp","additions":22,"deletions":27,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -35,1 +35,0 @@\n-                         notproduct,                                      \\\n@@ -39,0 +38,3 @@\n+product(bool, UseAllWindowsProcessorGroups, false,                        \\\n+        \"Use all processor groups on supported Windows versions\")         \\\n+                                                                          \\\n","filename":"src\/hotspot\/os\/windows\/globals_windows.hpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,1 +30,0 @@\n-#include \"code\/icBuffer.hpp\"\n@@ -41,0 +40,1 @@\n+#include \"nmt\/memTracker.hpp\"\n@@ -67,1 +67,1 @@\n-#include \"runtime\/threads.hpp\"\n+#include \"runtime\/threads.hpp\"\n@@ -72,1 +72,0 @@\n-#include \"services\/memTracker.hpp\"\n@@ -80,0 +79,1 @@\n+#include \"utilities\/population_count.hpp\"\n@@ -84,0 +84,1 @@\n+#include \"jfr\/support\/jfrNativeLibraryLoadEvent.hpp\"\n@@ -284,0 +285,1 @@\n+#ifndef _WIN64\n@@ -286,0 +288,1 @@\n+#endif\n@@ -287,1 +290,1 @@\n-LONG WINAPI Handle_FLT_Exception(struct _EXCEPTION_POINTERS* exceptionInfo);\n+static LONG WINAPI Uncaught_Exception_Handler(struct _EXCEPTION_POINTERS* exceptionInfo);\n@@ -401,1 +404,1 @@\n-  prev_uef_handler = SetUnhandledExceptionFilter(Handle_FLT_Exception);\n+  prev_uef_handler = SetUnhandledExceptionFilter(Uncaught_Exception_Handler);\n@@ -429,2 +432,0 @@\n-\/\/ os::current_stack_base()\n-\/\/\n@@ -435,1 +436,1 @@\n-address os::current_stack_base() {\n+void os::current_stack_base_and_size(address* stack_base, size_t* stack_size) {\n@@ -438,1 +439,1 @@\n-  size_t stack_size;\n+  size_t size;\n@@ -441,2 +442,2 @@\n-  stack_bottom =  (address)minfo.AllocationBase;\n-  stack_size = minfo.RegionSize;\n+  stack_bottom = (address)minfo.AllocationBase;\n+  size = minfo.RegionSize;\n@@ -447,1 +448,1 @@\n-    VirtualQuery(stack_bottom+stack_size, &minfo, sizeof(minfo));\n+    VirtualQuery(stack_bottom + size, &minfo, sizeof(minfo));\n@@ -449,1 +450,1 @@\n-      stack_size += minfo.RegionSize;\n+      size += minfo.RegionSize;\n@@ -454,9 +455,2 @@\n-  return stack_bottom + stack_size;\n-}\n-\n-size_t os::current_stack_size() {\n-  size_t sz;\n-  MEMORY_BASIC_INFORMATION minfo;\n-  VirtualQuery(&minfo, &minfo, sizeof(minfo));\n-  sz = (size_t)os::current_stack_base() - (size_t)minfo.AllocationBase;\n-  return sz;\n+  *stack_base = stack_bottom + size;\n+  *stack_size = size;\n@@ -516,0 +510,5 @@\n+enum Ept { EPT_THREAD, EPT_PROCESS, EPT_PROCESS_DIE };\n+\/\/ Wrapper around _endthreadex(), exit() and _exit()\n+[[noreturn]]\n+static void exit_process_or_thread(Ept what, int code);\n+\n@@ -521,1 +520,1 @@\n-unsigned __stdcall os::win32::thread_native_entry(void* t) {\n+static unsigned __stdcall thread_native_entry(void* t) {\n@@ -569,1 +568,2 @@\n-  return (unsigned)os::win32::exit_process_or_thread(os::win32::EPT_THREAD, res);\n+  exit_process_or_thread(EPT_THREAD, res);\n+  return res;\n@@ -756,1 +756,1 @@\n-                             &os::win32::thread_native_entry,\n+                             &thread_native_entry,\n@@ -812,9 +812,1 @@\n-\n-\n-jlong as_long(LARGE_INTEGER x) {\n-  jlong result = 0; \/\/ initialization to avoid warning\n-  set_high(&result, x.HighPart);\n-  set_low(&result, x.LowPart);\n-  return result;\n-}\n-\n+static double nanos_per_count; \/\/ NANOSECS_PER_SEC \/ performance_frequency\n@@ -825,1 +817,1 @@\n-  return as_long(count) - initial_performance_count;\n+  return count.QuadPart - initial_performance_count;\n@@ -852,0 +844,14 @@\n+jlong os::total_swap_space() {\n+  MEMORYSTATUSEX ms;\n+  ms.dwLength = sizeof(ms);\n+  GlobalMemoryStatusEx(&ms);\n+  return (jlong) ms.ullTotalPageFile;\n+}\n+\n+jlong os::free_swap_space() {\n+  MEMORYSTATUSEX ms;\n+  ms.dwLength = sizeof(ms);\n+  GlobalMemoryStatusEx(&ms);\n+  return (jlong) ms.ullAvailPageFile;\n+}\n+\n@@ -879,10 +885,61 @@\n-  DWORD_PTR lpProcessAffinityMask = 0;\n-  DWORD_PTR lpSystemAffinityMask = 0;\n-  int proc_count = processor_count();\n-  if (proc_count <= sizeof(UINT_PTR) * BitsPerByte &&\n-      GetProcessAffinityMask(GetCurrentProcess(), &lpProcessAffinityMask, &lpSystemAffinityMask)) {\n-    \/\/ Nof active processors is number of bits in process affinity mask\n-    int bitcount = 0;\n-    while (lpProcessAffinityMask != 0) {\n-      lpProcessAffinityMask = lpProcessAffinityMask & (lpProcessAffinityMask-1);\n-      bitcount++;\n+  bool schedules_all_processor_groups = win32::is_windows_11_or_greater() || win32::is_windows_server_2022_or_greater();\n+  if (UseAllWindowsProcessorGroups && !schedules_all_processor_groups && !win32::processor_group_warning_displayed()) {\n+    win32::set_processor_group_warning_displayed(true);\n+    FLAG_SET_DEFAULT(UseAllWindowsProcessorGroups, false);\n+    warning(\"The UseAllWindowsProcessorGroups flag is not supported on this Windows version and will be ignored.\");\n+  }\n+\n+  DWORD active_processor_groups = 0;\n+  DWORD processors_in_job_object = win32::active_processors_in_job_object(&active_processor_groups);\n+\n+  if (processors_in_job_object > 0) {\n+    if (schedules_all_processor_groups) {\n+      \/\/ If UseAllWindowsProcessorGroups is enabled then all the processors in the job object\n+      \/\/ can be used. Otherwise, we will fall through to inspecting the process affinity mask.\n+      \/\/ This will result in using only the subset of the processors in the default processor\n+      \/\/ group allowed by the job object i.e. only 1 processor group will be used and only\n+      \/\/ the processors in that group that are allowed by the job object will be used.\n+      \/\/ This preserves the behavior where older OpenJDK versions always used one processor\n+      \/\/ group regardless of whether they were launched in a job object.\n+      if (!UseAllWindowsProcessorGroups && active_processor_groups > 1) {\n+        if (!win32::job_object_processor_group_warning_displayed()) {\n+          win32::set_job_object_processor_group_warning_displayed(true);\n+          warning(\"The Windows job object has enabled multiple processor groups (%d) but the UseAllWindowsProcessorGroups flag is off. Some processors might not be used.\", active_processor_groups);\n+        }\n+      } else {\n+        return processors_in_job_object;\n+      }\n+    } else {\n+      if (active_processor_groups > 1 && !win32::job_object_processor_group_warning_displayed()) {\n+        win32::set_job_object_processor_group_warning_displayed(true);\n+        warning(\"The Windows job object has enabled multiple processor groups (%d) but only 1 is supported on this Windows version. Some processors might not be used.\", active_processor_groups);\n+      }\n+      return processors_in_job_object;\n+    }\n+  }\n+\n+  DWORD logical_processors = 0;\n+  SYSTEM_INFO si;\n+  GetSystemInfo(&si);\n+\n+  USHORT group_count = 0;\n+  bool use_process_affinity_mask = false;\n+  bool got_process_group_affinity = false;\n+\n+  if (GetProcessGroupAffinity(GetCurrentProcess(), &group_count, nullptr) == 0) {\n+    DWORD last_error = GetLastError();\n+    if (last_error == ERROR_INSUFFICIENT_BUFFER) {\n+      if (group_count > 0) {\n+        got_process_group_affinity = true;\n+\n+        if (group_count == 1) {\n+          use_process_affinity_mask = true;\n+        }\n+      } else {\n+        warning(\"Unexpected group count of 0 from GetProcessGroupAffinity.\");\n+        assert(false, \"Group count must not be 0.\");\n+      }\n+    } else {\n+      char buf[512];\n+      size_t buf_len = os::lasterror(buf, sizeof(buf));\n+      warning(\"Attempt to get process group affinity failed: %s\", buf_len != 0 ? buf : \"<unknown error>\");\n@@ -890,2 +947,34 @@\n-    return bitcount;\n-    return proc_count;\n+    warning(\"Unexpected GetProcessGroupAffinity success result.\");\n+    assert(false, \"Unexpected GetProcessGroupAffinity success result\");\n+  }\n+\n+  \/\/ Fall back to SYSTEM_INFO.dwNumberOfProcessors if the process group affinity could not be determined.\n+  if (!got_process_group_affinity) {\n+    return si.dwNumberOfProcessors;\n+  }\n+\n+  \/\/ If the process it not in a job and the process group affinity is exactly 1 group\n+  \/\/ then get the number of available logical processors from the process affinity mask\n+  if (use_process_affinity_mask) {\n+    DWORD_PTR lpProcessAffinityMask = 0;\n+    DWORD_PTR lpSystemAffinityMask = 0;\n+    if (GetProcessAffinityMask(GetCurrentProcess(), &lpProcessAffinityMask, &lpSystemAffinityMask) != 0) {\n+      \/\/ Number of active processors is number of bits in process affinity mask\n+      logical_processors = population_count(lpProcessAffinityMask);\n+\n+      if (logical_processors > 0) {\n+        return logical_processors;\n+      } else {\n+        \/\/ We only check the process affinity mask if GetProcessGroupAffinity determined that there was\n+        \/\/ only 1 active group. In this case, GetProcessAffinityMask will not set the affinity mask to 0.\n+        warning(\"Unexpected process affinity mask of 0 from GetProcessAffinityMask.\");\n+        assert(false, \"Found unexpected process affinity mask: 0\");\n+      }\n+    } else {\n+      char buf[512];\n+      size_t buf_len = os::lasterror(buf, sizeof(buf));\n+      warning(\"Attempt to get the process affinity mask failed: %s\", buf_len != 0 ? buf : \"<unknown error>\");\n+    }\n+\n+    \/\/ Fall back to SYSTEM_INFO.dwNumberOfProcessors if the process affinity mask could not be determined.\n+    return si.dwNumberOfProcessors;\n@@ -894,0 +983,15 @@\n+\n+  if (UseAllWindowsProcessorGroups) {\n+    \/\/ There are no processor affinity restrictions at this point so we can return\n+    \/\/ the overall processor count if the OS automatically schedules threads across\n+    \/\/ all processors on the system. Note that older operating systems can\n+    \/\/ correctly report processor count but will not schedule threads across\n+    \/\/ processor groups unless the application explicitly uses group affinity APIs\n+    \/\/ to assign threads to processor groups. On these older operating systems, we\n+    \/\/ will continue to use the dwNumberOfProcessors field.\n+    if (schedules_all_processor_groups) {\n+      logical_processors = processor_count();\n+    }\n+  }\n+\n+  return logical_processors == 0 ? si.dwNumberOfProcessors : logical_processors;\n@@ -989,1 +1093,2 @@\n-  performance_frequency = as_long(count);\n+  performance_frequency = count.QuadPart;\n+  nanos_per_count = NANOSECS_PER_SEC \/ (double)performance_frequency;\n@@ -991,1 +1096,1 @@\n-  initial_performance_count = as_long(count);\n+  initial_performance_count = count.QuadPart;\n@@ -1093,3 +1198,2 @@\n-    double current = as_long(current_count);\n-    double freq = performance_frequency;\n-    jlong time = (jlong)((current\/freq) * NANOSECS_PER_SEC);\n+    double current = current_count.QuadPart;\n+    jlong time = (jlong)(current * nanos_per_count);\n@@ -1221,1 +1325,1 @@\n-    win32::exit_process_or_thread(win32::EPT_PROCESS, 1);\n+    exit_process_or_thread(EPT_PROCESS, 1);\n@@ -1245,1 +1349,1 @@\n-  win32::exit_process_or_thread(win32::EPT_PROCESS, 1);\n+  exit_process_or_thread(EPT_PROCESS, 1);\n@@ -1250,1 +1354,1 @@\n-  win32::exit_process_or_thread(win32::EPT_PROCESS_DIE, -1);\n+  exit_process_or_thread(EPT_PROCESS_DIE, -1);\n@@ -1258,0 +1362,3 @@\n+\n+  JFR_ONLY(NativeLibraryUnloadEvent unload_event(name);)\n+\n@@ -1261,0 +1368,1 @@\n+    JFR_ONLY(unload_event.set_result(true);)\n@@ -1263,0 +1371,2 @@\n+    char buf[500];\n+    size_t tl = os::lasterror(buf, sizeof(buf));\n@@ -1265,0 +1375,4 @@\n+    if (tl == 0) {\n+      os::snprintf(buf, sizeof(buf), \"Attempt to unload dll failed (error code %d)\", (int) errcode);\n+    }\n+    JFR_ONLY(unload_event.set_error_msg(buf);)\n@@ -1269,1 +1383,9 @@\n-  return (void*)::GetProcAddress((HMODULE)lib, name);\n+  ::SetLastError(0); \/\/ Clear old pending errors\n+  void* ret = ::GetProcAddress((HMODULE)lib, name);\n+  if (ret == nullptr) {\n+    char buf[512];\n+    if (os::lasterror(buf, sizeof(buf)) > 0) {\n+      log_debug(os)(\"Symbol %s not found in dll: %s\", name, buf);\n+    }\n+  }\n+  return ret;\n@@ -1427,0 +1549,3 @@\n+void os::prepare_native_symbols() {\n+}\n+\n@@ -1560,5 +1685,3 @@\n-#if INCLUDE_JFR\n-  EventNativeLibraryLoad event;\n-  event.set_name(name);\n-#endif\n-  void * result = LoadLibrary(name);\n+  void* result;\n+  JFR_ONLY(NativeLibraryLoadEvent load_event(name, &result);)\n+  result = LoadLibrary(name);\n@@ -1570,5 +1693,0 @@\n-#if INCLUDE_JFR\n-    event.set_success(true);\n-    event.set_errorMessage(nullptr);\n-    event.commit();\n-#endif\n@@ -1588,5 +1706,1 @@\n-#if INCLUDE_JFR\n-    event.set_success(false);\n-    event.set_errorMessage(ebuf);\n-    event.commit();\n-#endif\n+    JFR_ONLY(load_event.set_error_msg(ebuf);)\n@@ -1603,5 +1717,1 @@\n-#if INCLUDE_JFR\n-    event.set_success(false);\n-    event.set_errorMessage(\"open on dll file did not work\");\n-    event.commit();\n-#endif\n+    JFR_ONLY(load_event.set_error_msg(\"open on dll file did not work\");)\n@@ -1634,5 +1744,1 @@\n-#if INCLUDE_JFR\n-    event.set_success(false);\n-    event.set_errorMessage(\"failed to get lib architecture\");\n-    event.commit();\n-#endif\n+    JFR_ONLY(load_event.set_error_msg(\"failed to get lib architecture\");)\n@@ -1683,5 +1789,1 @@\n-#if INCLUDE_JFR\n-    event.set_success(false);\n-    event.set_errorMessage(\"lib architecture matches, but other error occured\");\n-    event.commit();\n-#endif\n+    JFR_ONLY(load_event.set_error_msg(\"lib architecture matches, but other error occured\");)\n@@ -1701,6 +1803,1 @@\n-#if INCLUDE_JFR\n-  event.set_success(false);\n-  event.set_errorMessage(ebuf);\n-  event.commit();\n-#endif\n-\n+  JFR_ONLY(load_event.set_error_msg(ebuf);)\n@@ -1772,11 +1869,0 @@\n-int os::vsnprintf(char* buf, size_t len, const char* fmt, va_list args) {\n-  \/\/ Starting with Visual Studio 2015, vsnprint is C99 compliant.\n-  ALLOW_C_FUNCTION(::vsnprintf, int result = ::vsnprintf(buf, len, fmt, args);)\n-  \/\/ If an encoding error occurred (result < 0) then it's not clear\n-  \/\/ whether the buffer is NUL terminated, so ensure it is.\n-  if ((result < 0) && (len > 0)) {\n-    buf[len - 1] = '\\0';\n-  }\n-  return result;\n-}\n-\n@@ -1793,1 +1879,1 @@\n-  return t1 - t2;\n+  return primitive_compare(t1, t2);\n@@ -1824,4 +1910,0 @@\n-  VS_FIXEDFILEINFO *file_info;\n-  TCHAR kernel32_path[MAX_PATH];\n-  UINT len, ret;\n-\n@@ -1830,38 +1912,4 @@\n-  \/\/ Get the full path to \\Windows\\System32\\kernel32.dll and use that for\n-  \/\/ determining what version of Windows we're running on.\n-  len = MAX_PATH - (UINT)strlen(\"\\\\kernel32.dll\") - 1;\n-  ret = GetSystemDirectory(kernel32_path, len);\n-  if (ret == 0 || ret > len) {\n-    st->print_cr(\"Call to GetSystemDirectory failed\");\n-    return;\n-  }\n-  strncat(kernel32_path, \"\\\\kernel32.dll\", MAX_PATH - ret);\n-\n-  DWORD version_size = GetFileVersionInfoSize(kernel32_path, nullptr);\n-  if (version_size == 0) {\n-    st->print_cr(\"Call to GetFileVersionInfoSize failed\");\n-    return;\n-  }\n-\n-  LPTSTR version_info = (LPTSTR)os::malloc(version_size, mtInternal);\n-  if (version_info == nullptr) {\n-    st->print_cr(\"Failed to allocate version_info\");\n-    return;\n-  }\n-\n-  if (!GetFileVersionInfo(kernel32_path, 0, version_size, version_info)) {\n-    os::free(version_info);\n-    st->print_cr(\"Call to GetFileVersionInfo failed\");\n-    return;\n-  }\n-\n-  if (!VerQueryValue(version_info, TEXT(\"\\\\\"), (LPVOID*)&file_info, &len)) {\n-    os::free(version_info);\n-    st->print_cr(\"Call to VerQueryValue failed\");\n-    return;\n-  }\n-\n-  int major_version = HIWORD(file_info->dwProductVersionMS);\n-  int minor_version = LOWORD(file_info->dwProductVersionMS);\n-  int build_number = HIWORD(file_info->dwProductVersionLS);\n-  int build_minor = LOWORD(file_info->dwProductVersionLS);\n+  int major_version = windows_major_version();\n+  int minor_version = windows_minor_version();\n+  int build_number = windows_build_number();\n+  int build_minor = windows_build_minor();\n@@ -1869,1 +1917,0 @@\n-  os::free(version_info);\n@@ -1965,0 +2012,6 @@\n+\n+    \/\/ This is the number of logical processors in the current processor group only and is therefore\n+    \/\/ at most 64. The GetLogicalProcessorInformation function is used to compute the total number\n+    \/\/ of processors. However, it requires memory to be allocated for the processor information buffer.\n+    \/\/ Since this method is used in paths where memory allocation should not be done (i.e. after a crash),\n+    \/\/ only the number of processors in the current group will be returned.\n@@ -1994,1 +2047,1 @@\n-      st->print_cr(\"Processor Information for all %d processors :\", proc_count);\n+      st->print_cr(\"Processor Information for the first %d processors :\", proc_count);\n@@ -2275,1 +2328,1 @@\n-    return ::signal(sig, handler);\n+    return CAST_FROM_FN_PTR(void*, ::signal(sig, handler));\n@@ -2513,2 +2566,2 @@\n-  assert(pc[0] == 0x83, \"not an sdiv opcode\"); \/\/Fixme did i get the right opcode?\n-  assert(ctx->X4 == min_jint, \"unexpected idiv exception\");\n+  guarantee(pc[0] == 0x83, \"not an sdiv opcode(0x83), the actual value = 0x%x\", pc[0]); \/\/Fixme did i get the right opcode?\n+  guarantee(ctx->X4 == min_jint, \"unexpected idiv exception, the actual value = %d while the expected is %d\", ctx->X4, min_jint);\n@@ -2523,2 +2576,4 @@\n-  assert(pc[0] >= Assembler::REX && pc[0] <= Assembler::REX_WRXB && pc[1] == 0xF7 || pc[0] == 0xF7, \"not an idiv opcode\");\n-  assert(pc[0] >= Assembler::REX && pc[0] <= Assembler::REX_WRXB && (pc[2] & ~0x7) == 0xF8 || (pc[1] & ~0x7) == 0xF8, \"cannot handle non-register operands\");\n+  guarantee((pc[0] >= Assembler::REX && pc[0] <= Assembler::REX_WRXB && pc[1] == 0xF7) || pc[0] == 0xF7,\n+            \"not an idiv opcode, pc[0] = 0x%x and pc[1] = 0x%x\", pc[0], pc[1]);\n+  guarantee((pc[0] >= Assembler::REX && pc[0] <= Assembler::REX_WRXB && (pc[2] & ~0x7) == 0xF8) || (pc[1] & ~0x7) == 0xF8,\n+            \"cannot handle non-register operands, pc[0] = 0x%x, pc[1] = 0x%x and pc[2] = 0x%x\", pc[0], pc[1], pc[2]);\n@@ -2539,3 +2594,3 @@\n-  assert(pc[0] == 0xF7, \"not an idiv opcode\");\n-  assert((pc[1] & ~0x7) == 0xF8, \"cannot handle non-register operands\");\n-  assert(ctx->Eax == min_jint, \"unexpected idiv exception\");\n+  guarantee(pc[0] == 0xF7, \"not an idiv opcode(0xF7), the actual value = 0x%x\", pc[1]);\n+  guarantee((pc[1] & ~0x7) == 0xF8, \"cannot handle non-register operands, the actual value = 0x%x\", pc[1]);\n+  guarantee(ctx->Eax == min_jint, \"unexpected idiv exception, the actual value = %d while the expected is %d\", ctx->Eax, min_jint);\n@@ -2553,3 +2608,1 @@\n-LONG WINAPI Handle_FLT_Exception(struct _EXCEPTION_POINTERS* exceptionInfo) {\n-  PCONTEXT ctx = exceptionInfo->ContextRecord;\n-#ifndef  _WIN64\n+static bool handle_FLT_exception(struct _EXCEPTION_POINTERS* exceptionInfo) {\n@@ -2566,1 +2619,3 @@\n-  case EXCEPTION_FLT_UNDERFLOW:\n+  case EXCEPTION_FLT_UNDERFLOW: {\n+    PCONTEXT ctx = exceptionInfo->ContextRecord;\n+#ifndef  _WIN64\n@@ -2573,1 +2628,12 @@\n-      return EXCEPTION_CONTINUE_EXECUTION;\n+      return true;\n+    }\n+#else \/\/ !_WIN64\n+    \/\/ On Windows, the mxcsr control bits are non-volatile across calls\n+    \/\/ See also CR 6192333\n+    \/\/\n+    jint MxCsr = INITIAL_MXCSR;\n+    \/\/ we can't use StubRoutines::x86::addr_mxcsr_std()\n+    \/\/ because in Win64 mxcsr is not saved there\n+    if (MxCsr != ctx->MxCsr) {\n+      ctx->MxCsr = MxCsr;\n+      return true;\n@@ -2575,0 +2641,12 @@\n+#endif \/\/ !_WIN64\n+  }\n+  }\n+\n+  return false;\n+}\n+#endif\n+\n+#ifndef _WIN64\n+static LONG WINAPI Uncaught_Exception_Handler(struct _EXCEPTION_POINTERS* exceptionInfo) {\n+  if (handle_FLT_exception(exceptionInfo)) {\n+    return EXCEPTION_CONTINUE_EXECUTION;\n@@ -2577,0 +2655,1 @@\n+  \/\/ we only override this on 32 bits, so only check it there\n@@ -2582,12 +2661,0 @@\n-#else \/\/ !_WIN64\n-  \/\/ On Windows, the mxcsr control bits are non-volatile across calls\n-  \/\/ See also CR 6192333\n-  \/\/\n-  jint MxCsr = INITIAL_MXCSR;\n-  \/\/ we can't use StubRoutines::x86::addr_mxcsr_std()\n-  \/\/ because in Win64 mxcsr is not saved there\n-  if (MxCsr != ctx->MxCsr) {\n-    ctx->MxCsr = MxCsr;\n-    return EXCEPTION_CONTINUE_EXECUTION;\n-  }\n-#endif \/\/ !_WIN64\n@@ -2808,1 +2875,1 @@\n-      CompiledMethod* nm = nullptr;\n+      nmethod* nm = nullptr;\n@@ -2811,1 +2878,1 @@\n-        nm = (cb != nullptr) ? cb->as_compiled_method_or_null() : nullptr;\n+        nm = (cb != nullptr) ? cb->as_nmethod_or_null() : nullptr;\n@@ -2814,2 +2881,2 @@\n-      bool is_unsafe_arraycopy = (in_native || in_java) && UnsafeCopyMemory::contains_pc(pc);\n-      if (((in_vm || in_native || is_unsafe_arraycopy) && thread->doing_unsafe_access()) ||\n+      bool is_unsafe_memory_access = (in_native || in_java) && UnsafeMemoryAccess::contains_pc(pc);\n+      if (((in_vm || in_native || is_unsafe_memory_access) && thread->doing_unsafe_access()) ||\n@@ -2818,2 +2885,2 @@\n-        if (is_unsafe_arraycopy) {\n-          next_pc = UnsafeCopyMemory::page_error_continue_pc(pc);\n+        if (is_unsafe_memory_access) {\n+          next_pc = UnsafeMemoryAccess::page_error_continue_pc(pc);\n@@ -2850,3 +2917,2 @@\n-    if ((in_java || in_native) && exception_code != EXCEPTION_UNCAUGHT_CXX_EXCEPTION) {\n-      LONG result=Handle_FLT_Exception(exceptionInfo);\n-      if (result==EXCEPTION_CONTINUE_EXECUTION) return result;\n+    if ((in_java || in_native) && handle_FLT_exception(exceptionInfo)) {\n+      return EXCEPTION_CONTINUE_EXECUTION;\n@@ -2861,2 +2927,2 @@\n-        if (cb != nullptr && cb->is_compiled()) {\n-          CompiledMethod* cm = cb->as_compiled_method();\n+        if (cb != nullptr && cb->is_nmethod()) {\n+          nmethod* nm = cb->as_nmethod();\n@@ -2864,5 +2930,5 @@\n-          address deopt = cm->is_method_handle_return(pc) ?\n-            cm->deopt_mh_handler_begin() :\n-            cm->deopt_handler_begin();\n-          assert(cm->insts_contains_inclusive(pc), \"\");\n-          cm->set_original_pc(&fr, pc);\n+          address deopt = nm->is_method_handle_return(pc) ?\n+            nm->deopt_mh_handler_begin() :\n+            nm->deopt_handler_begin();\n+          assert(nm->insts_contains_inclusive(pc), \"\");\n+          nm->set_original_pc(&fr, pc);\n@@ -2915,2 +2981,2 @@\n-  if (InterceptOSException) goto exit;\n-  DWORD exception_code = exceptionInfo->ExceptionRecord->ExceptionCode;\n+  if (!InterceptOSException) {\n+    DWORD exceptionCode = exceptionInfo->ExceptionRecord->ExceptionCode;\n@@ -2918,1 +2984,1 @@\n-  address pc = (address)exceptionInfo->ContextRecord->Pc;\n+    address pc = (address) exceptionInfo->ContextRecord->Pc;\n@@ -2920,1 +2986,1 @@\n-  address pc = (address) exceptionInfo->ContextRecord->Rip;\n+    address pc = (address) exceptionInfo->ContextRecord->Rip;\n@@ -2922,1 +2988,1 @@\n-  address pc = (address) exceptionInfo->ContextRecord->Eip;\n+    address pc = (address) exceptionInfo->ContextRecord->Eip;\n@@ -2924,1 +2990,1 @@\n-  Thread* t = Thread::current_or_null_safe();\n+    Thread* thread = Thread::current_or_null_safe();\n@@ -2926,3 +2992,4 @@\n-  if (exception_code != EXCEPTION_BREAKPOINT) {\n-    report_error(t, exception_code, pc, exceptionInfo->ExceptionRecord,\n-                exceptionInfo->ContextRecord);\n+    if (exceptionCode != EXCEPTION_BREAKPOINT) {\n+      report_error(thread, exceptionCode, pc, exceptionInfo->ExceptionRecord,\n+                  exceptionInfo->ContextRecord);\n+    }\n@@ -2930,1 +2997,1 @@\n-exit:\n+\n@@ -3370,4 +3437,5 @@\n-static char* map_or_reserve_memory_aligned(size_t size, size_t alignment, int file_desc) {\n-  assert((alignment & (os::vm_allocation_granularity() - 1)) == 0,\n-         \"Alignment must be a multiple of allocation granularity (page size)\");\n-  assert((size & (alignment -1)) == 0, \"size must be 'alignment' aligned\");\n+static char* map_or_reserve_memory_aligned(size_t size, size_t alignment, int file_desc, MEMFLAGS flag = mtNone) {\n+  assert(is_aligned(alignment, os::vm_allocation_granularity()),\n+      \"Alignment must be a multiple of allocation granularity (page size)\");\n+  assert(is_aligned(size, os::vm_allocation_granularity()),\n+      \"Size must be a multiple of allocation granularity (page size)\");\n@@ -3382,2 +3450,2 @@\n-    char* extra_base = file_desc != -1 ? os::map_memory_to_file(extra_size, file_desc) :\n-                                         os::reserve_memory(extra_size);\n+    char* extra_base = file_desc != -1 ? os::map_memory_to_file(extra_size, file_desc, flag) :\n+                                         os::reserve_memory(extra_size, false, flag);\n@@ -3399,2 +3467,2 @@\n-    aligned_base = file_desc != -1 ? os::attempt_map_memory_to_file_at(aligned_base, size, file_desc) :\n-                                     os::attempt_reserve_memory_at(aligned_base, size);\n+    aligned_base = file_desc != -1 ? os::attempt_map_memory_to_file_at(aligned_base, size, file_desc, flag) :\n+                                     os::attempt_reserve_memory_at(aligned_base, size, false, flag);\n@@ -3413,2 +3481,2 @@\n-char* os::map_memory_to_file_aligned(size_t size, size_t alignment, int fd) {\n-  return map_or_reserve_memory_aligned(size, alignment, fd);\n+char* os::map_memory_to_file_aligned(size_t size, size_t alignment, int fd, MEMFLAGS flag) {\n+  return map_or_reserve_memory_aligned(size, alignment, fd, flag);\n@@ -3454,0 +3522,5 @@\n+size_t os::vm_min_address() {\n+  assert(is_aligned(_vm_min_address_default, os::vm_allocation_granularity()), \"Sanity\");\n+  return _vm_min_address_default;\n+}\n+\n@@ -3470,4 +3543,0 @@\n-bool os::can_execute_large_page_memory() {\n-  return true;\n-}\n-\n@@ -3834,0 +3903,5 @@\n+\n+size_t os::pd_pretouch_memory(void* first, void* last, size_t page_size) {\n+  return page_size;\n+}\n+\n@@ -3839,1 +3913,1 @@\n-size_t os::numa_get_leaf_groups(int *ids, size_t size) {\n+size_t os::numa_get_leaf_groups(uint *ids, size_t size) {\n@@ -3848,1 +3922,2 @@\n-      ids[i] = numa_node_list_holder.get_node_list_entry(i);\n+      int node_id = numa_node_list_holder.get_node_list_entry(i);\n+      ids[i] = checked_cast<uint>(node_id);\n@@ -3862,5 +3937,0 @@\n-char *os::scan_pages(char *start, char* end, page_info* page_expected,\n-                     page_info* page_found) {\n-  return end;\n-}\n-\n@@ -4020,0 +4090,155 @@\n+int    os::win32::_major_version             = 0;\n+int    os::win32::_minor_version             = 0;\n+int    os::win32::_build_number              = 0;\n+int    os::win32::_build_minor               = 0;\n+\n+bool   os::win32::_processor_group_warning_displayed = false;\n+bool   os::win32::_job_object_processor_group_warning_displayed = false;\n+\n+void os::win32::initialize_windows_version() {\n+  assert(_major_version == 0, \"windows version already initialized.\");\n+\n+  VS_FIXEDFILEINFO *file_info;\n+  TCHAR kernel32_path[MAX_PATH];\n+  UINT len, ret;\n+  char error_msg_buffer[512];\n+\n+  \/\/ Get the full path to \\Windows\\System32\\kernel32.dll and use that for\n+  \/\/ determining what version of Windows we're running on.\n+  len = MAX_PATH - (UINT)strlen(\"\\\\kernel32.dll\") - 1;\n+  ret = GetSystemDirectory(kernel32_path, len);\n+  if (ret == 0 || ret > len) {\n+    size_t buf_len = os::lasterror(error_msg_buffer, sizeof(error_msg_buffer));\n+    warning(\"Attempt to determine system directory failed: %s\", buf_len != 0 ? error_msg_buffer : \"<unknown error>\");\n+    return;\n+  }\n+  strncat(kernel32_path, \"\\\\kernel32.dll\", MAX_PATH - ret);\n+\n+  DWORD version_size = GetFileVersionInfoSize(kernel32_path, nullptr);\n+  if (version_size == 0) {\n+    size_t buf_len = os::lasterror(error_msg_buffer, sizeof(error_msg_buffer));\n+    warning(\"Failed to determine whether the OS can retrieve version information from kernel32.dll: %s\", buf_len != 0 ? error_msg_buffer : \"<unknown error>\");\n+    return;\n+  }\n+\n+  LPTSTR version_info = (LPTSTR)os::malloc(version_size, mtInternal);\n+  if (version_info == nullptr) {\n+    warning(\"os::malloc() failed to allocate %ld bytes for GetFileVersionInfo buffer\", version_size);\n+    return;\n+  }\n+\n+  if (GetFileVersionInfo(kernel32_path, 0, version_size, version_info) == 0) {\n+    os::free(version_info);\n+    size_t buf_len = os::lasterror(error_msg_buffer, sizeof(error_msg_buffer));\n+    warning(\"Attempt to retrieve version information from kernel32.dll failed: %s\", buf_len != 0 ? error_msg_buffer : \"<unknown error>\");\n+    return;\n+  }\n+\n+  if (VerQueryValue(version_info, TEXT(\"\\\\\"), (LPVOID*)&file_info, &len) == 0) {\n+    os::free(version_info);\n+    size_t buf_len = os::lasterror(error_msg_buffer, sizeof(error_msg_buffer));\n+    warning(\"Attempt to determine Windows version from kernel32.dll failed: %s\", buf_len != 0 ? error_msg_buffer : \"<unknown error>\");\n+    return;\n+  }\n+\n+  _major_version = HIWORD(file_info->dwProductVersionMS);\n+  _minor_version = LOWORD(file_info->dwProductVersionMS);\n+  _build_number  = HIWORD(file_info->dwProductVersionLS);\n+  _build_minor   = LOWORD(file_info->dwProductVersionLS);\n+\n+  os::free(version_info);\n+}\n+\n+bool os::win32::is_windows_11_or_greater() {\n+  if (IsWindowsServer()) {\n+    return false;\n+  }\n+\n+  \/\/ Windows 11 starts at build 22000 (Version 21H2)\n+  return (windows_major_version() == 10 && windows_build_number() >= 22000) || (windows_major_version() > 10);\n+}\n+\n+bool os::win32::is_windows_server_2022_or_greater() {\n+  if (!IsWindowsServer()) {\n+    return false;\n+  }\n+\n+  \/\/ Windows Server 2022 starts at build 20348.169\n+  return (windows_major_version() == 10 && windows_build_number() >= 20348) || (windows_major_version() > 10);\n+}\n+\n+DWORD os::win32::active_processors_in_job_object(DWORD* active_processor_groups) {\n+  if (active_processor_groups != nullptr) {\n+    *active_processor_groups = 0;\n+  }\n+  BOOL is_in_job_object = false;\n+  if (IsProcessInJob(GetCurrentProcess(), nullptr, &is_in_job_object) == 0) {\n+    char buf[512];\n+    size_t buf_len = os::lasterror(buf, sizeof(buf));\n+    warning(\"Attempt to determine whether the process is running in a job failed: %s\", buf_len != 0 ? buf : \"<unknown error>\");\n+    return 0;\n+  }\n+\n+  if (!is_in_job_object) {\n+    return 0;\n+  }\n+\n+  DWORD processors = 0;\n+\n+  LPVOID job_object_information = nullptr;\n+  DWORD job_object_information_length = 0;\n+\n+  if (QueryInformationJobObject(nullptr, JobObjectGroupInformationEx, nullptr, 0, &job_object_information_length) != 0) {\n+    warning(\"Unexpected QueryInformationJobObject success result.\");\n+    assert(false, \"Unexpected QueryInformationJobObject success result\");\n+    return 0;\n+  }\n+\n+  DWORD last_error = GetLastError();\n+  if (last_error == ERROR_INSUFFICIENT_BUFFER) {\n+    DWORD group_count = job_object_information_length \/ sizeof(GROUP_AFFINITY);\n+\n+    job_object_information = os::malloc(job_object_information_length, mtInternal);\n+    if (job_object_information != nullptr) {\n+        if (QueryInformationJobObject(nullptr, JobObjectGroupInformationEx, job_object_information, job_object_information_length, &job_object_information_length) != 0) {\n+          DWORD groups_found = job_object_information_length \/ sizeof(GROUP_AFFINITY);\n+          if (groups_found != group_count) {\n+            warning(\"Unexpected processor group count: %ld. Expected %ld processor groups.\", groups_found, group_count);\n+            assert(false, \"Unexpected group count\");\n+          }\n+\n+          GROUP_AFFINITY* group_affinity_data = ((GROUP_AFFINITY*)job_object_information);\n+          for (DWORD i = 0; i < groups_found; i++, group_affinity_data++) {\n+            DWORD processors_in_group = population_count(group_affinity_data->Mask);\n+            processors += processors_in_group;\n+            if (active_processor_groups != nullptr && processors_in_group > 0) {\n+              (*active_processor_groups)++;\n+            }\n+          }\n+\n+          if (processors == 0) {\n+            warning(\"Could not determine processor count from the job object.\");\n+            assert(false, \"Must find at least 1 logical processor\");\n+          }\n+        } else {\n+          char buf[512];\n+          size_t buf_len = os::lasterror(buf, sizeof(buf));\n+          warning(\"Attempt to query job object information failed: %s\", buf_len != 0 ? buf : \"<unknown error>\");\n+        }\n+\n+        os::free(job_object_information);\n+    } else {\n+        warning(\"os::malloc() failed to allocate %ld bytes for QueryInformationJobObject\", job_object_information_length);\n+    }\n+  } else {\n+    char buf[512];\n+    size_t buf_len = os::lasterror(buf, sizeof(buf));\n+    warning(\"Attempt to query job object information failed: %s\", buf_len != 0 ? buf : \"<unknown error>\");\n+    assert(false, \"Unexpected QueryInformationJobObject error code\");\n+    return 0;\n+  }\n+\n+  log_debug(os)(\"Process is running in a job with %d active processors.\", processors);\n+  return processors;\n+}\n+\n@@ -4027,1 +4252,14 @@\n-  set_processor_count(si.dwNumberOfProcessors);\n+\n+  DWORD processors = 0;\n+  bool schedules_all_processor_groups = win32::is_windows_11_or_greater() || win32::is_windows_server_2022_or_greater();\n+  if (schedules_all_processor_groups) {\n+    processors = GetActiveProcessorCount(ALL_PROCESSOR_GROUPS);\n+    if (processors == 0) {\n+      char buf[512];\n+      size_t buf_len = os::lasterror(buf, sizeof(buf));\n+      warning(\"Attempt to determine the processor count from GetActiveProcessorCount() failed: %s\", buf_len != 0 ? buf : \"<unknown error>\");\n+      assert(false, \"Must find at least 1 logical processor\");\n+    }\n+  }\n+\n+  set_processor_count(processors > 0 ? processors : si.dwNumberOfProcessors);\n@@ -4103,1 +4341,1 @@\n-int os::win32::exit_process_or_thread(Ept what, int exit_code) {\n+static void exit_process_or_thread(Ept what, int exit_code) {\n@@ -4281,1 +4519,1 @@\n-  return exit_code;\n+  ::abort();\n@@ -4336,0 +4574,1 @@\n+  win32::initialize_windows_version();\n@@ -4382,0 +4621,6 @@\n+  const char* auto_schedules_message = \"Host Windows OS automatically schedules threads across all processor groups.\";\n+  const char* no_auto_schedules_message = \"Host Windows OS does not automatically schedule threads across all processor groups.\";\n+\n+  bool schedules_all_processor_groups = win32::is_windows_11_or_greater() || win32::is_windows_server_2022_or_greater();\n+  log_debug(os)(schedules_all_processor_groups ? auto_schedules_message : no_auto_schedules_message);\n+  log_debug(os)(\"%d logical processors found.\", processor_count());\n@@ -4884,1 +5129,1 @@\n-  win32::exit_process_or_thread(win32::EPT_PROCESS, num);\n+  exit_process_or_thread(EPT_PROCESS, num);\n@@ -4888,1 +5133,1 @@\n-  win32::exit_process_or_thread(win32::EPT_PROCESS_DIE, num);\n+  exit_process_or_thread(EPT_PROCESS_DIE, num);\n@@ -4930,7 +5175,0 @@\n-\/\/ create binary file, rewriting existing file if required\n-int os::create_binary_file(const char* path, bool rewrite_existing) {\n-  int oflags = _O_CREAT | _O_WRONLY | _O_BINARY;\n-  oflags |= rewrite_existing ? _O_TRUNC : _O_EXCL;\n-  return ::open(path, oflags, _S_IREAD | _S_IWRITE);\n-}\n-\n@@ -5216,16 +5454,0 @@\n-\n-\/\/ Remap a block of memory.\n-char* os::pd_remap_memory(int fd, const char* file_name, size_t file_offset,\n-                          char *addr, size_t bytes, bool read_only,\n-                          bool allow_exec) {\n-  \/\/ This OS does not allow existing memory maps to be remapped so we\n-  \/\/ would have to unmap the memory before we remap it.\n-\n-  \/\/ Because there is a small window between unmapping memory and mapping\n-  \/\/ it in again with different protections, CDS archives are mapped RW\n-  \/\/ on windows, so this function isn't called.\n-  ShouldNotReachHere();\n-  return nullptr;\n-}\n-\n-\n@@ -5421,1 +5643,2 @@\n-    assert(rv == WAIT_OBJECT_0 || rv == WAIT_TIMEOUT, \"WaitForSingleObject failed\");\n+    assert(rv != WAIT_FAILED,   \"WaitForSingleObject failed with error code: %lu\", GetLastError());\n+    assert(rv == WAIT_OBJECT_0 || rv == WAIT_TIMEOUT, \"WaitForSingleObject failed with return value: %lu\", rv);\n@@ -5460,1 +5683,2 @@\n-    assert(rv == WAIT_OBJECT_0, \"WaitForSingleObject failed\");\n+    assert(rv != WAIT_FAILED,   \"WaitForSingleObject failed with error code: %lu\", GetLastError());\n+    assert(rv == WAIT_OBJECT_0, \"WaitForSingleObject failed with return value: %lu\", rv);\n@@ -5523,2 +5747,1 @@\n-  if (thread->is_interrupted(false) ||\n-      WaitForSingleObject(_ParkHandle, 0) == WAIT_OBJECT_0) {\n+  if (thread->is_interrupted(false)) {\n@@ -5528,2 +5751,9 @@\n-    ThreadBlockInVM tbivm(thread);\n-    OSThreadWaitState osts(thread->osthread(), false \/* not Object.wait() *\/);\n+    DWORD rv = WaitForSingleObject(_ParkHandle, 0);\n+    assert(rv != WAIT_FAILED,   \"WaitForSingleObject failed with error code: %lu\", GetLastError());\n+    assert(rv == WAIT_OBJECT_0 || rv == WAIT_TIMEOUT, \"WaitForSingleObject failed with return value: %lu\", rv);\n+    if (rv == WAIT_OBJECT_0) {\n+      ResetEvent(_ParkHandle);\n+      return;\n+    } else {\n+      ThreadBlockInVM tbivm(thread);\n+      OSThreadWaitState osts(thread->osthread(), false \/* not Object.wait() *\/);\n@@ -5531,2 +5761,5 @@\n-    WaitForSingleObject(_ParkHandle, time);\n-    ResetEvent(_ParkHandle);\n+      rv = WaitForSingleObject(_ParkHandle, time);\n+      assert(rv != WAIT_FAILED,   \"WaitForSingleObject failed with error code: %lu\", GetLastError());\n+      assert(rv == WAIT_OBJECT_0 || rv == WAIT_TIMEOUT, \"WaitForSingleObject failed with return value: %lu\", rv);\n+      ResetEvent(_ParkHandle);\n+    }\n@@ -5608,1 +5841,3 @@\n-    WaitForSingleObject(pi.hProcess, INFINITE);\n+    DWORD rv = WaitForSingleObject(pi.hProcess, INFINITE);\n+    assert(rv != WAIT_FAILED,   \"WaitForSingleObject failed with error code: %lu\", GetLastError());\n+    assert(rv == WAIT_OBJECT_0, \"WaitForSingleObject failed with return value: %lu\", rv);\n@@ -5673,1 +5908,1 @@\n-int os::connect(int fd, struct sockaddr* him, socklen_t len) {\n+ssize_t os::connect(int fd, struct sockaddr* him, socklen_t len) {\n@@ -5677,1 +5912,1 @@\n-int os::recv(int fd, char* buf, size_t nBytes, uint flags) {\n+ssize_t os::recv(int fd, char* buf, size_t nBytes, uint flags) {\n@@ -5681,1 +5916,1 @@\n-int os::send(int fd, char* buf, size_t nBytes, uint flags) {\n+ssize_t os::send(int fd, char* buf, size_t nBytes, uint flags) {\n@@ -5685,1 +5920,1 @@\n-int os::raw_send(int fd, char* buf, size_t nBytes, uint flags) {\n+ssize_t os::raw_send(int fd, char* buf, size_t nBytes, uint flags) {\n","filename":"src\/hotspot\/os\/windows\/os_windows.cpp","additions":497,"deletions":262,"binary":false,"changes":759,"status":"modified"},{"patch":"@@ -46,0 +46,7 @@\n+  static bool   _processor_group_warning_displayed;\n+  static bool   _job_object_processor_group_warning_displayed;\n+\n+  static int    _major_version;\n+  static int    _minor_version;\n+  static int    _build_number;\n+  static int    _build_minor;\n@@ -60,0 +67,31 @@\n+  static bool   is_windows_11_or_greater();\n+  static bool   is_windows_server_2022_or_greater();\n+  static int windows_major_version() {\n+    assert(_major_version > 0, \"windows version not initialized.\");\n+    return _major_version;\n+  }\n+  static int windows_minor_version() {\n+    assert(_major_version > 0, \"windows version not initialized.\");\n+    return _minor_version;\n+  }\n+  static int windows_build_number() {\n+    assert(_major_version > 0, \"windows version not initialized.\");\n+    return _build_number;\n+  }\n+  static int windows_build_minor() {\n+    assert(_major_version > 0, \"windows version not initialized.\");\n+    return _build_minor;\n+  }\n+\n+  static void set_processor_group_warning_displayed(bool displayed)  {\n+    _processor_group_warning_displayed = displayed;\n+  }\n+  static bool processor_group_warning_displayed() {\n+    return _processor_group_warning_displayed;\n+  }\n+  static void set_job_object_processor_group_warning_displayed(bool displayed)  {\n+    _job_object_processor_group_warning_displayed = displayed;\n+  }\n+  static bool job_object_processor_group_warning_displayed() {\n+    return _job_object_processor_group_warning_displayed;\n+  }\n@@ -74,6 +112,2 @@\n-  \/\/ The handler passed to _beginthreadex().\n-  \/\/ Called with the associated Thread* as the argument.\n-  static unsigned __stdcall thread_native_entry(void*);\n-  enum Ept { EPT_THREAD, EPT_PROCESS, EPT_PROCESS_DIE };\n-  \/\/ Wrapper around _endthreadex(), exit() and _exit()\n-  static int exit_process_or_thread(Ept what, int exit_code);\n+  static void initialize_windows_version();\n+  static DWORD active_processors_in_job_object(DWORD* active_processor_groups = nullptr);\n","filename":"src\/hotspot\/os\/windows\/os_windows.hpp","additions":40,"deletions":6,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,1 +29,0 @@\n-#include \"code\/icBuffer.hpp\"\n@@ -82,1 +81,1 @@\n-\/\/ needed by current_stack_region() workaround for Mavericks\n+\/\/ needed by current_stack_base_and_size() workaround for Mavericks\n@@ -354,1 +353,1 @@\n-intptr_t* _get_previous_fp() {\n+static intptr_t* _get_previous_fp() {\n@@ -453,3 +452,3 @@\n-        CompiledMethod* nm = (cb != nullptr) ? cb->as_compiled_method_or_null() : nullptr;\n-        bool is_unsafe_arraycopy = thread->doing_unsafe_access() && UnsafeCopyMemory::contains_pc(pc);\n-        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_arraycopy) {\n+        nmethod* nm = (cb != nullptr) ? cb->as_nmethod_or_null() : nullptr;\n+        bool is_unsafe_memory_access = thread->doing_unsafe_access() && UnsafeMemoryAccess::contains_pc(pc);\n+        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_memory_access) {\n@@ -457,2 +456,2 @@\n-          if (is_unsafe_arraycopy) {\n-            next_pc = UnsafeCopyMemory::page_error_continue_pc(pc);\n+          if (is_unsafe_memory_access) {\n+            next_pc = UnsafeMemoryAccess::page_error_continue_pc(pc);\n@@ -462,3 +461,1 @@\n-      }\n-      else\n-\n+      } else\n@@ -466,1 +463,1 @@\n-      if (sig == SIGFPE  &&\n+      if (sig == SIGFPE &&\n@@ -536,2 +533,2 @@\n-        if (UnsafeCopyMemory::contains_pc(pc)) {\n-          next_pc = UnsafeCopyMemory::page_error_continue_pc(pc);\n+        if (UnsafeMemoryAccess::contains_pc(pc)) {\n+          next_pc = UnsafeMemoryAccess::page_error_continue_pc(pc);\n@@ -721,2 +718,3 @@\n-\/\/ ** P1 (aka bottom) and size ( P2 = P1 - size) are the address and stack size returned from\n-\/\/    pthread_attr_getstack()\n+\/\/ ** P1 (aka bottom) and size are the address and stack size\n+\/\/    returned from pthread_attr_getstack().\n+\/\/ ** P2 (aka stack top or base) = P1 + size\n@@ -724,1 +722,2 @@\n-static void current_stack_region(address * bottom, size_t * size) {\n+void os::current_stack_base_and_size(address* base, size_t* size) {\n+  address bottom;\n@@ -727,1 +726,1 @@\n-  void *stacktop = pthread_get_stackaddr_np(self);\n+  *base = (address) pthread_get_stackaddr_np(self);\n@@ -750,1 +749,1 @@\n-  *bottom = (address) stacktop - *size;\n+  bottom = *base - *size;\n@@ -758,2 +757,3 @@\n-  *bottom = (address)((char *)ss.ss_sp - ss.ss_size);\n-  *size   = ss.ss_size;\n+  *base = (address) ss.ss_sp;\n+  *size = ss.ss_size;\n+  bottom = *base - *size;\n@@ -774,2 +774,2 @@\n-  if (pthread_attr_getstackaddr(&attr, (void **)bottom) != 0 ||\n-    pthread_attr_getstacksize(&attr, size) != 0) {\n+  if (pthread_attr_getstackaddr(&attr, (void **)&bottom) != 0 ||\n+      pthread_attr_getstacksize(&attr, size) != 0) {\n@@ -779,0 +779,2 @@\n+  *base = bottom + *size;\n+\n@@ -781,17 +783,2 @@\n-  assert(os::current_stack_pointer() >= *bottom &&\n-         os::current_stack_pointer() < *bottom + *size, \"just checking\");\n-}\n-\n-address os::current_stack_base() {\n-  address bottom;\n-  size_t size;\n-  current_stack_region(&bottom, &size);\n-  return (bottom + size);\n-}\n-\n-size_t os::current_stack_size() {\n-  \/\/ stack size includes normal stack and HotSpot guard pages\n-  address bottom;\n-  size_t size;\n-  current_stack_region(&bottom, &size);\n-  return size;\n+  assert(os::current_stack_pointer() >= bottom &&\n+         os::current_stack_pointer() < *base, \"just checking\");\n@@ -866,1 +853,1 @@\n-  print_instructions(st, pc, sizeof(char));\n+  print_instructions(st, pc);\n","filename":"src\/hotspot\/os_cpu\/bsd_x86\/os_bsd_x86.cpp","additions":29,"deletions":42,"binary":false,"changes":71,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,1 +29,0 @@\n-#include \"code\/icBuffer.hpp\"\n@@ -35,0 +34,1 @@\n+#include \"nmt\/memTracker.hpp\"\n@@ -51,1 +51,0 @@\n-#include \"services\/memTracker.hpp\"\n@@ -168,1 +167,1 @@\n-intptr_t* _get_previous_fp() {\n+static intptr_t* _get_previous_fp() {\n@@ -272,3 +271,3 @@\n-        CompiledMethod* nm = (cb != nullptr) ? cb->as_compiled_method_or_null() : nullptr;\n-        bool is_unsafe_arraycopy = thread->doing_unsafe_access() && UnsafeCopyMemory::contains_pc(pc);\n-        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_arraycopy) {\n+        nmethod* nm = (cb != nullptr) ? cb->as_nmethod_or_null() : nullptr;\n+        bool is_unsafe_memory_access = thread->doing_unsafe_access() && UnsafeMemoryAccess::contains_pc(pc);\n+        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_memory_access) {\n@@ -276,2 +275,2 @@\n-          if (is_unsafe_arraycopy) {\n-            next_pc = UnsafeCopyMemory::page_error_continue_pc(pc);\n+          if (is_unsafe_memory_access) {\n+            next_pc = UnsafeMemoryAccess::page_error_continue_pc(pc);\n@@ -281,3 +280,1 @@\n-      }\n-      else\n-\n+      } else\n@@ -285,1 +282,1 @@\n-      if (sig == SIGFPE  &&\n+      if (sig == SIGFPE &&\n@@ -330,2 +327,2 @@\n-        if (UnsafeCopyMemory::contains_pc(pc)) {\n-          next_pc = UnsafeCopyMemory::page_error_continue_pc(pc);\n+        if (UnsafeMemoryAccess::contains_pc(pc)) {\n+          next_pc = UnsafeMemoryAccess::page_error_continue_pc(pc);\n@@ -475,1 +472,1 @@\n-    size_t len = sizeof(data);\n+    int len = (int)sizeof(data);\n@@ -583,1 +580,1 @@\n-  print_instructions(st, pc, sizeof(char));\n+  print_instructions(st, pc);\n","filename":"src\/hotspot\/os_cpu\/linux_x86\/os_linux_x86.cpp","additions":14,"deletions":17,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -61,1 +61,0 @@\n-  template(java_lang_Package,                         \"java\/lang\/Package\")                        \\\n@@ -121,1 +120,0 @@\n-  template(java_lang_CharSequence,                    \"java\/lang\/CharSequence\")                   \\\n@@ -134,5 +132,0 @@\n-  template(java_io_OutputStream,                      \"java\/io\/OutputStream\")                     \\\n-  template(java_io_Reader,                            \"java\/io\/Reader\")                           \\\n-  template(java_io_BufferedReader,                    \"java\/io\/BufferedReader\")                   \\\n-  template(java_io_File,                              \"java\/io\/File\")                             \\\n-  template(java_io_FileInputStream,                   \"java\/io\/FileInputStream\")                  \\\n@@ -143,5 +136,1 @@\n-  template(java_util_Objects,                         \"java\/util\/Objects\")                        \\\n-  template(java_util_Vector,                          \"java\/util\/Vector\")                         \\\n-  template(java_util_AbstractList,                    \"java\/util\/AbstractList\")                   \\\n-  template(java_util_Hashtable,                       \"java\/util\/Hashtable\")                      \\\n-  template(java_lang_Compiler,                        \"java\/lang\/Compiler\")                       \\\n+  template(java_util_DualPivotQuicksort,              \"java\/util\/DualPivotQuicksort\")             \\\n@@ -152,2 +141,0 @@\n-  template(getBootClassPathEntryForClass_name,        \"getBootClassPathEntryForClass\")            \\\n-  template(sun_net_www_ParseUtil,                     \"sun\/net\/www\/ParseUtil\")                    \\\n@@ -164,1 +151,3 @@\n-                                                                                                  \\\n+  template(java_lang_Deprecated,                      \"Ljava\/lang\/Deprecated;\")                   \\\n+  template(since,                                     \"since\")                                    \\\n+  template(for_removal,                               \"forRemoval\")                               \\\n@@ -227,1 +216,0 @@\n-  template(java_lang_NoSuchFieldException,            \"java\/lang\/NoSuchFieldException\")           \\\n@@ -237,1 +225,0 @@\n-  template(java_security_PrivilegedActionException,   \"java\/security\/PrivilegedActionException\")  \\\n@@ -283,1 +270,0 @@\n-  template(checkedExceptions_name,                    \"checkedExceptions\")                        \\\n@@ -363,4 +349,0 @@\n-  template(setTargetNormal_name,                      \"setTargetNormal\")                          \\\n-  template(setTargetVolatile_name,                    \"setTargetVolatile\")                        \\\n-  template(setTarget_signature,                       \"(Ljava\/lang\/invoke\/MethodHandle;)V\")       \\\n-  template(DEFAULT_CONTEXT_name,                      \"DEFAULT_CONTEXT\")                          \\\n@@ -381,0 +363,1 @@\n+  template(java_lang_ClassFrameInfo,                  \"java\/lang\/ClassFrameInfo\")                 \\\n@@ -410,1 +393,0 @@\n-  template(reference_lock_name,                       \"lock\")                                     \\\n@@ -420,0 +402,1 @@\n+  template(notifyJvmtiDisableSuspend_name,            \"notifyJvmtiDisableSuspend\")                \\\n@@ -424,2 +407,0 @@\n-  template(getStacks_name,                            \"getStacks\")                                \\\n-  template(onPinned_name,                             \"onPinned0\")                                \\\n@@ -430,1 +411,1 @@\n-  template(argsize_name,                              \"argsize\")                                  \\\n+  template(bottom_name,                               \"bottom\")                                   \\\n@@ -433,1 +414,0 @@\n-  template(numOops_name,                              \"numOops\")                                  \\\n@@ -439,1 +419,0 @@\n-  template(numInterpretedFrames_name,                 \"numInterpretedFrames\")                     \\\n@@ -445,2 +424,0 @@\n-  template(refStack_name,                             \"refStack\")                                 \\\n-  template(refSP_name,                                \"refSP\")                                    \\\n@@ -452,1 +429,0 @@\n-  template(deadChild_name,                            \"deadChild\")                                \\\n@@ -468,1 +444,0 @@\n-  template(newInstance0_name,                         \"newInstance0\")                             \\\n@@ -490,1 +465,0 @@\n-  template(vmcount_name,                              \"vmcount\")                                  \\\n@@ -558,1 +532,0 @@\n-  template(bool_bool_void_signature,                  \"(ZZ)V\")                                    \\\n@@ -588,1 +561,0 @@\n-  template(long_array_signature,                      \"[J\")                                       \\\n@@ -593,1 +565,0 @@\n-  template(vthread_signature,                         \"Ljava\/lang\/VirtualThread;\")                \\\n@@ -600,2 +571,0 @@\n-  template(string_int_signature,                      \"(Ljava\/lang\/String;)I\")                    \\\n-  template(string_byte_array_signature,               \"(Ljava\/lang\/String;)[B\")                   \\\n@@ -611,4 +580,0 @@\n-  template(throwable_string_void_signature,           \"(Ljava\/lang\/Throwable;Ljava\/lang\/String;)V\")               \\\n-  template(string_array_void_signature,               \"([Ljava\/lang\/String;)V\")                                   \\\n-  template(string_array_string_array_void_signature,  \"([Ljava\/lang\/String;[Ljava\/lang\/String;)V\")                \\\n-  template(thread_throwable_void_signature,           \"(Ljava\/lang\/Thread;Ljava\/lang\/Throwable;)V\")               \\\n@@ -623,1 +588,0 @@\n-  template(string_string_string_signature,            \"(Ljava\/lang\/String;Ljava\/lang\/String;)Ljava\/lang\/String;\") \\\n@@ -627,2 +591,0 @@\n-  template(char_array_void_signature,                 \"([C)V\")                                                    \\\n-  template(int_int_void_signature,                    \"(II)V\")                                                    \\\n@@ -637,1 +599,0 @@\n-  template(void_module_signature,                     \"()Ljava\/lang\/Module;\")                                     \\\n@@ -640,1 +601,0 @@\n-  template(exception_void_signature,                  \"(Ljava\/lang\/Exception;)V\")                                 \\\n@@ -646,1 +606,0 @@\n-  template(thread_array_signature,                    \"[Ljava\/lang\/Thread;\")                                      \\\n@@ -658,1 +617,0 @@\n-  template(weakreference_array_signature,             \"[Ljava\/lang\/ref\/WeakReference;\")                           \\\n@@ -688,1 +646,0 @@\n-  template(java_lang_management_ThreadState,           \"java\/lang\/management\/ThreadState\")                        \\\n@@ -725,1 +682,0 @@\n-  template(gcInfoBuilder_name,                         \"gcInfoBuilder\")                                           \\\n@@ -732,4 +688,0 @@\n-  template(addThreadDumpForMonitors_name,              \"addThreadDumpForMonitors\")                                \\\n-  template(addThreadDumpForSynchronizers_name,         \"addThreadDumpForSynchronizers\")                           \\\n-  template(addThreadDumpForMonitors_signature,         \"(Ljava\/lang\/management\/ThreadInfo;[Ljava\/lang\/Object;[I)V\") \\\n-  template(addThreadDumpForSynchronizers_signature,    \"(Ljava\/lang\/management\/ThreadInfo;[Ljava\/lang\/Object;)V\")   \\\n@@ -762,1 +714,1 @@\n-  template(decodeAndThrowThrowable_signature,          \"(IJZ)V\")                                                  \\\n+  template(decodeAndThrowThrowable_signature,          \"(IJZZ)V\")                                                 \\\n@@ -789,1 +741,0 @@\n-  template(url_void_signature,                              \"(Ljava\/net\/URL;)V\")                                  \\\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":8,"deletions":57,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,1 +29,1 @@\n-#include \"classfile\/stringTable.hpp\"\n+#include \"classfile\/systemDictionary.hpp\"\n@@ -31,1 +31,0 @@\n-#include \"code\/icBuffer.hpp\"\n@@ -51,0 +50,4 @@\n+#include \"gc\/g1\/g1HeapRegion.inline.hpp\"\n+#include \"gc\/g1\/g1HeapRegionPrinter.hpp\"\n+#include \"gc\/g1\/g1HeapRegionRemSet.inline.hpp\"\n+#include \"gc\/g1\/g1HeapRegionSet.inline.hpp\"\n@@ -63,0 +66,1 @@\n+#include \"gc\/g1\/g1RegionPinCache.inline.hpp\"\n@@ -74,4 +78,2 @@\n-#include \"gc\/g1\/g1YoungGCEvacFailureInjector.hpp\"\n-#include \"gc\/g1\/heapRegion.inline.hpp\"\n-#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n-#include \"gc\/g1\/heapRegionSet.inline.hpp\"\n+#include \"gc\/g1\/g1YoungGCAllocationFailureInjector.hpp\"\n+#include \"gc\/shared\/classUnloadingContext.hpp\"\n@@ -82,1 +84,0 @@\n-#include \"gc\/shared\/gcLocker.inline.hpp\"\n@@ -85,1 +86,0 @@\n-#include \"gc\/shared\/generationSpec.hpp\"\n@@ -108,0 +108,1 @@\n+#include \"runtime\/cpuTimeCounters.hpp\"\n@@ -148,1 +149,1 @@\n-  uint log_region_size = HeapRegion::LogOfHRGrainBytes;\n+  uint log_region_size = G1HeapRegion::LogOfHRGrainBytes;\n@@ -157,3 +158,3 @@\n-HeapRegion* G1CollectedHeap::new_heap_region(uint hrs_index,\n-                                             MemRegion mr) {\n-  return new HeapRegion(hrs_index, bot(), mr, &_card_set_config);\n+G1HeapRegion* G1CollectedHeap::new_heap_region(uint hrs_index,\n+                                               MemRegion mr) {\n+  return new G1HeapRegion(hrs_index, bot(), mr, &_card_set_config);\n@@ -164,5 +165,5 @@\n-HeapRegion* G1CollectedHeap::new_region(size_t word_size,\n-                                        HeapRegionType type,\n-                                        bool do_expand,\n-                                        uint node_index) {\n-  assert(!is_humongous(word_size) || word_size <= HeapRegion::GrainWords,\n+G1HeapRegion* G1CollectedHeap::new_region(size_t word_size,\n+                                          HeapRegionType type,\n+                                          bool do_expand,\n+                                          uint node_index) {\n+  assert(!is_humongous(word_size) || word_size <= G1HeapRegion::GrainWords,\n@@ -172,1 +173,1 @@\n-  HeapRegion* res = _hrm.allocate_free_region(type, node_index);\n+  G1HeapRegion* res = _hrm.allocate_free_region(type, node_index);\n@@ -183,1 +184,1 @@\n-    assert(word_size * HeapWordSize < HeapRegion::GrainBytes,\n+    assert(word_size * HeapWordSize < G1HeapRegion::GrainBytes,\n@@ -197,1 +198,1 @@\n-void G1CollectedHeap::set_humongous_metadata(HeapRegion* first_hr,\n+void G1CollectedHeap::set_humongous_metadata(G1HeapRegion* first_hr,\n@@ -204,1 +205,1 @@\n-  size_t word_size_sum = num_regions * HeapRegion::GrainWords;\n+  size_t word_size_sum = num_regions * G1HeapRegion::GrainWords;\n@@ -239,1 +240,1 @@\n-  HeapRegion* hr = nullptr;\n+  G1HeapRegion* hr = nullptr;\n@@ -280,1 +281,1 @@\n-G1CollectedHeap::humongous_obj_allocate_initialize_regions(HeapRegion* first_hr,\n+G1CollectedHeap::humongous_obj_allocate_initialize_regions(G1HeapRegion* first_hr,\n@@ -285,1 +286,1 @@\n-  assert(num_regions * HeapRegion::GrainWords >= word_size, \"pre-condition\");\n+  assert(num_regions * G1HeapRegion::GrainWords >= word_size, \"pre-condition\");\n@@ -321,1 +322,1 @@\n-  HeapRegion* last_hr = region_at(last);\n+  G1HeapRegion* last_hr = region_at(last);\n@@ -327,1 +328,1 @@\n-    HeapRegion *hr = region_at(i);\n+    G1HeapRegion *hr = region_at(i);\n@@ -329,1 +330,1 @@\n-    _hr_printer.alloc(hr);\n+    G1HeapRegionPrinter::alloc(hr);\n@@ -337,1 +338,1 @@\n-  return align_up(word_size, HeapRegion::GrainWords) \/ HeapRegion::GrainWords;\n+  return align_up(word_size, G1HeapRegion::GrainWords) \/ G1HeapRegion::GrainWords;\n@@ -351,1 +352,1 @@\n-  HeapRegion* humongous_start = _hrm.allocate_humongous(obj_regions);\n+  G1HeapRegion* humongous_start = _hrm.allocate_humongous(obj_regions);\n@@ -416,4 +417,3 @@\n-  \/\/ We will loop until a) we manage to successfully perform the\n-  \/\/ allocation or b) we successfully schedule a collection which\n-  \/\/ fails to perform the allocation. b) is the only case when we'll\n-  \/\/ return null.\n+  \/\/ We will loop until a) we manage to successfully perform the allocation or b)\n+  \/\/ successfully schedule a collection which fails to perform the allocation.\n+  \/\/ Case b) is the only case when we'll return null.\n@@ -421,2 +421,1 @@\n-  for (uint try_count = 1, gclocker_retry_count = 0; \/* we'll return *\/; try_count += 1) {\n-    bool should_try_gc;\n+  for (uint try_count = 1; \/* we'll return *\/; try_count++) {\n@@ -435,16 +434,0 @@\n-      \/\/ If the GCLocker is active and we are bound for a GC, try expanding young gen.\n-      \/\/ This is different to when only GCLocker::needs_gc() is set: try to avoid\n-      \/\/ waiting because the GCLocker is active to not wait too long.\n-      if (GCLocker::is_active_and_needs_gc() && policy()->can_expand_young_list()) {\n-        \/\/ No need for an ergo message here, can_expand_young_list() does this when\n-        \/\/ it returns true.\n-        result = _allocator->attempt_allocation_force(word_size);\n-        if (result != nullptr) {\n-          return result;\n-        }\n-      }\n-\n-      \/\/ Only try a GC if the GCLocker does not signal the need for a GC. Wait until\n-      \/\/ the GCLocker initiated GC has been performed and then retry. This includes\n-      \/\/ the case when the GC Locker is not active but has not been performed.\n-      should_try_gc = !GCLocker::needs_gc();\n@@ -455,32 +438,6 @@\n-    if (should_try_gc) {\n-      bool succeeded;\n-      result = do_collection_pause(word_size, gc_count_before, &succeeded, GCCause::_g1_inc_collection_pause);\n-      if (result != nullptr) {\n-        assert(succeeded, \"only way to get back a non-null result\");\n-        log_trace(gc, alloc)(\"%s: Successfully scheduled collection returning \" PTR_FORMAT,\n-                             Thread::current()->name(), p2i(result));\n-        return result;\n-      }\n-\n-      if (succeeded) {\n-        \/\/ We successfully scheduled a collection which failed to allocate. No\n-        \/\/ point in trying to allocate further. We'll just return null.\n-        log_trace(gc, alloc)(\"%s: Successfully scheduled collection failing to allocate \"\n-                             SIZE_FORMAT \" words\", Thread::current()->name(), word_size);\n-        return nullptr;\n-      }\n-      log_trace(gc, alloc)(\"%s: Unsuccessfully scheduled collection allocating \" SIZE_FORMAT \" words\",\n-                           Thread::current()->name(), word_size);\n-    } else {\n-      \/\/ Failed to schedule a collection.\n-      if (gclocker_retry_count > GCLockerRetryAllocationCount) {\n-        log_warning(gc, alloc)(\"%s: Retried waiting for GCLocker too often allocating \"\n-                               SIZE_FORMAT \" words\", Thread::current()->name(), word_size);\n-        return nullptr;\n-      }\n-      log_trace(gc, alloc)(\"%s: Stall until clear\", Thread::current()->name());\n-      \/\/ The GCLocker is either active or the GCLocker initiated\n-      \/\/ GC has not yet been performed. Stall until it is and\n-      \/\/ then retry the allocation.\n-      GCLocker::stall_until_clear();\n-      gclocker_retry_count += 1;\n+    bool succeeded;\n+    result = do_collection_pause(word_size, gc_count_before, &succeeded, GCCause::_g1_inc_collection_pause);\n+    if (succeeded) {\n+      log_trace(gc, alloc)(\"%s: Successfully scheduled collection returning \" PTR_FORMAT,\n+                           Thread::current()->name(), p2i(result));\n+      return result;\n@@ -489,7 +446,8 @@\n-    \/\/ We can reach here if we were unsuccessful in scheduling a\n-    \/\/ collection (because another thread beat us to it) or if we were\n-    \/\/ stalled due to the GC locker. In either can we should retry the\n-    \/\/ allocation attempt in case another thread successfully\n-    \/\/ performed a collection and reclaimed enough space. We do the\n-    \/\/ first attempt (without holding the Heap_lock) here and the\n-    \/\/ follow-on attempt will be at the start of the next loop\n+    log_trace(gc, alloc)(\"%s: Unsuccessfully scheduled collection allocating \" SIZE_FORMAT \" words\",\n+                         Thread::current()->name(), word_size);\n+\n+    \/\/ We can reach here if we were unsuccessful in scheduling a collection (because\n+    \/\/ another thread beat us to it). In this case immeditealy retry the allocation\n+    \/\/ attempt because another thread successfully performed a collection and possibly\n+    \/\/ reclaimed enough space. The first attempt (without holding the Heap_lock) is\n+    \/\/ here and the follow-on attempt will be at the start of the next loop\n@@ -519,2 +477,2 @@\n-  HeapRegion* curr_region = _hrm.addr_to_region(range.start());\n-  HeapRegion* end_region = _hrm.addr_to_region(range.last());\n+  G1HeapRegion* curr_region = _hrm.addr_to_region(range.start());\n+  G1HeapRegion* end_region = _hrm.addr_to_region(range.last());\n@@ -524,1 +482,1 @@\n-    HeapRegion* next_region = is_last ? nullptr : _hrm.next_region_in_heap(curr_region);\n+    G1HeapRegion* next_region = is_last ? nullptr : _hrm.next_region_in_heap(curr_region);\n@@ -550,1 +508,1 @@\n-  HeapWord* start_addr = reserved.end() - align_up(word_size, HeapRegion::GrainWords);\n+  HeapWord* start_addr = reserved.end() - align_up(word_size, G1HeapRegion::GrainWords);\n@@ -559,1 +517,1 @@\n-                              HeapRegion::GrainWords * HeapWordSize * commits);\n+                              G1HeapRegion::GrainWords * HeapWordSize * commits);\n@@ -564,1 +522,1 @@\n-  auto set_region_to_old = [&] (HeapRegion* r, bool is_last) {\n+  auto set_region_to_old = [&] (G1HeapRegion* r, bool is_last) {\n@@ -571,1 +529,1 @@\n-    _hr_printer.alloc(r);\n+    G1HeapRegionPrinter::alloc(r);\n@@ -579,1 +537,1 @@\n-void G1CollectedHeap::populate_archive_regions_bot_part(MemRegion range) {\n+void G1CollectedHeap::populate_archive_regions_bot(MemRegion range) {\n@@ -583,1 +541,1 @@\n-                           [&] (HeapRegion* r, bool is_last) {\n+                           [&] (G1HeapRegion* r, bool is_last) {\n@@ -605,1 +563,1 @@\n-  auto dealloc_archive_region = [&] (HeapRegion* r, bool is_last) {\n+  auto dealloc_archive_region = [&] (G1HeapRegion* r, bool is_last) {\n@@ -618,1 +576,1 @@\n-                              HeapRegion::GrainWords * HeapWordSize * shrink_count);\n+                              G1HeapRegion::GrainWords * HeapWordSize * shrink_count);\n@@ -678,4 +636,3 @@\n-  \/\/ We will loop until a) we manage to successfully perform the\n-  \/\/ allocation or b) we successfully schedule a collection which\n-  \/\/ fails to perform the allocation. b) is the only case when we'll\n-  \/\/ return null.\n+  \/\/ We will loop until a) we manage to successfully perform the allocation or b)\n+  \/\/ successfully schedule a collection which fails to perform the allocation.\n+  \/\/ Case b) is the only case when we'll return null.\n@@ -683,2 +640,1 @@\n-  for (uint try_count = 1, gclocker_retry_count = 0; \/* we'll return *\/; try_count += 1) {\n-    bool should_try_gc;\n+  for (uint try_count = 1; \/* we'll return *\/; try_count++) {\n@@ -698,1 +654,1 @@\n-          add_allocated_humongous_bytes_since_last_gc(size_in_regions * HeapRegion::GrainBytes);\n+          add_allocated_humongous_bytes_since_last_gc(size_in_regions * G1HeapRegion::GrainBytes);\n@@ -702,4 +658,0 @@\n-      \/\/ Only try a GC if the GCLocker does not signal the need for a GC. Wait until\n-      \/\/ the GCLocker initiated GC has been performed and then retry. This includes\n-      \/\/ the case when the GC Locker is not active but has not been performed.\n-      should_try_gc = !GCLocker::needs_gc();\n@@ -710,3 +662,5 @@\n-    if (should_try_gc) {\n-      bool succeeded;\n-      result = do_collection_pause(word_size, gc_count_before, &succeeded, GCCause::_g1_humongous_allocation);\n+    bool succeeded;\n+    result = do_collection_pause(word_size, gc_count_before, &succeeded, GCCause::_g1_humongous_allocation);\n+    if (succeeded) {\n+      log_trace(gc, alloc)(\"%s: Successfully scheduled collection returning \" PTR_FORMAT,\n+                           Thread::current()->name(), p2i(result));\n@@ -714,3 +668,0 @@\n-        assert(succeeded, \"only way to get back a non-null result\");\n-        log_trace(gc, alloc)(\"%s: Successfully scheduled collection returning \" PTR_FORMAT,\n-                             Thread::current()->name(), p2i(result));\n@@ -719,2 +670,1 @@\n-          record_collection_pause_humongous_allocation(size_in_regions * HeapRegion::GrainBytes);\n-        return result;\n+          record_collection_pause_humongous_allocation(size_in_regions * G1HeapRegion::GrainBytes);\n@@ -722,23 +672,1 @@\n-\n-      if (succeeded) {\n-        \/\/ We successfully scheduled a collection which failed to allocate. No\n-        \/\/ point in trying to allocate further. We'll just return null.\n-        log_trace(gc, alloc)(\"%s: Successfully scheduled collection failing to allocate \"\n-                             SIZE_FORMAT \" words\", Thread::current()->name(), word_size);\n-        return nullptr;\n-      }\n-      log_trace(gc, alloc)(\"%s: Unsuccessfully scheduled collection allocating \" SIZE_FORMAT \"\",\n-                           Thread::current()->name(), word_size);\n-    } else {\n-      \/\/ Failed to schedule a collection.\n-      if (gclocker_retry_count > GCLockerRetryAllocationCount) {\n-        log_warning(gc, alloc)(\"%s: Retried waiting for GCLocker too often allocating \"\n-                               SIZE_FORMAT \" words\", Thread::current()->name(), word_size);\n-        return nullptr;\n-      }\n-      log_trace(gc, alloc)(\"%s: Stall until clear\", Thread::current()->name());\n-      \/\/ The GCLocker is either active or the GCLocker initiated\n-      \/\/ GC has not yet been performed. Stall until it is and\n-      \/\/ then retry the allocation.\n-      GCLocker::stall_until_clear();\n-      gclocker_retry_count += 1;\n+      return result;\n@@ -747,0 +675,2 @@\n+    log_trace(gc, alloc)(\"%s: Unsuccessfully scheduled collection allocating \" SIZE_FORMAT \"\",\n+                         Thread::current()->name(), word_size);\n@@ -748,5 +678,2 @@\n-    \/\/ We can reach here if we were unsuccessful in scheduling a\n-    \/\/ collection (because another thread beat us to it) or if we were\n-    \/\/ stalled due to the GC locker. In either can we should retry the\n-    \/\/ allocation attempt in case another thread successfully\n-    \/\/ performed a collection and reclaimed enough space.\n+    \/\/ We can reach here if we were unsuccessful in scheduling a collection (because\n+    \/\/ another thread beat us to it).\n@@ -759,1 +686,1 @@\n-      log_warning(gc, alloc)(\"%s: Retried allocation %u times for \" SIZE_FORMAT \" words\",\n+      log_warning(gc, alloc)(\"%s: Retried allocation %u times for %zu words\",\n@@ -788,3 +715,1 @@\n-private:\n-  G1HRPrinter* _hr_printer;\n-  bool do_heap_region(HeapRegion* hr) {\n+  bool do_heap_region(G1HeapRegion* hr) {\n@@ -793,1 +718,1 @@\n-    _hr_printer->post_compaction(hr);\n+    G1HeapRegionPrinter::post_compaction(hr);\n@@ -796,3 +721,0 @@\n-\n-  PostCompactionPrinterClosure(G1HRPrinter* hr_printer)\n-    : _hr_printer(hr_printer) { }\n@@ -806,2 +728,2 @@\n-  if (_hr_printer.is_active()) {\n-    PostCompactionPrinterClosure cl(hr_printer());\n+  if (G1HeapRegionPrinter::is_active()) {\n+    PostCompactionPrinterClosure cl;\n@@ -852,4 +774,0 @@\n-  \/\/ Delete metaspaces for unloaded class loaders and clean up loader_data graph\n-  ClassLoaderDataGraph::purge(\/*at_safepoint*\/true);\n-  DEBUG_ONLY(MetaspaceUtils::verify();)\n-\n@@ -913,5 +831,0 @@\n-  if (GCLocker::check_active_before_gc()) {\n-    \/\/ Full GC was not completed.\n-    return false;\n-  }\n-\n@@ -1082,2 +995,1 @@\n-  aligned_expand_bytes = align_up(aligned_expand_bytes,\n-                                       HeapRegion::GrainBytes);\n+  aligned_expand_bytes = align_up(aligned_expand_bytes, G1HeapRegion::GrainBytes);\n@@ -1094,1 +1006,1 @@\n-  uint regions_to_expand = (uint)(aligned_expand_bytes \/ HeapRegion::GrainBytes);\n+  uint regions_to_expand = (uint)(aligned_expand_bytes \/ G1HeapRegion::GrainBytes);\n@@ -1104,1 +1016,1 @@\n-  size_t actual_expand_bytes = expanded_by * HeapRegion::GrainBytes;\n+  size_t actual_expand_bytes = expanded_by * G1HeapRegion::GrainBytes;\n@@ -1127,3 +1039,2 @@\n-  aligned_shrink_bytes = align_down(aligned_shrink_bytes,\n-                                         HeapRegion::GrainBytes);\n-  uint num_regions_to_remove = (uint)(shrink_bytes \/ HeapRegion::GrainBytes);\n+  aligned_shrink_bytes = align_down(aligned_shrink_bytes, G1HeapRegion::GrainBytes);\n+  uint num_regions_to_remove = (uint)(shrink_bytes \/ G1HeapRegion::GrainBytes);\n@@ -1132,1 +1043,1 @@\n-  size_t shrunk_bytes = num_regions_removed * HeapRegion::GrainBytes;\n+  size_t shrunk_bytes = num_regions_removed * G1HeapRegion::GrainBytes;\n@@ -1187,1 +1098,1 @@\n-  bool is_correct_type(HeapRegion* hr) { return hr->is_old(); }\n+  bool is_correct_type(G1HeapRegion* hr) { return hr->is_old(); }\n@@ -1211,1 +1122,1 @@\n-  bool is_correct_type(HeapRegion* hr) { return hr->is_humongous(); }\n+  bool is_correct_type(G1HeapRegion* hr) { return hr->is_humongous(); }\n@@ -1223,1 +1134,0 @@\n-  _soft_ref_policy(),\n@@ -1231,1 +1141,1 @@\n-  _evac_failure_injector(),\n+  _allocation_failure_injector(),\n@@ -1240,1 +1150,0 @@\n-  _hr_printer(),\n@@ -1262,1 +1171,1 @@\n-  _is_alive_closure_cm(this),\n+  _is_alive_closure_cm(),\n@@ -1272,1 +1181,1 @@\n-  _humongous_object_threshold_in_words = humongous_threshold_for(HeapRegion::GrainWords);\n+  _humongous_object_threshold_in_words = humongous_threshold_for(G1HeapRegion::GrainWords);\n@@ -1274,3 +1183,5 @@\n-  \/\/ Override the default _filler_array_max_size so that no humongous filler\n-  \/\/ objects are created.\n-  _filler_array_max_size = _humongous_object_threshold_in_words;\n+  \/\/ Since filler arrays are never referenced, we can make them region sized.\n+  \/\/ This simplifies filling up the region in case we have some potentially\n+  \/\/ unreferenced (by Java code, but still in use by native code) pinned objects\n+  \/\/ in there.\n+  _filler_array_max_size = G1HeapRegion::GrainWords;\n@@ -1305,1 +1216,1 @@\n-                                         HeapRegion::GrainBytes,\n+                                         G1HeapRegion::GrainBytes,\n@@ -1351,2 +1262,2 @@\n-  Universe::check_alignment(init_byte_size, HeapRegion::GrainBytes, \"g1 heap\");\n-  Universe::check_alignment(reserved_byte_size, HeapRegion::GrainBytes, \"g1 heap\");\n+  Universe::check_alignment(init_byte_size, G1HeapRegion::GrainBytes, \"g1 heap\");\n+  Universe::check_alignment(reserved_byte_size, G1HeapRegion::GrainBytes, \"g1 heap\");\n@@ -1361,1 +1272,1 @@\n-  \/\/ HeapRegion::GrainBytes (i.e. the alignment that is passed\n+  \/\/ G1HeapRegion::GrainBytes (i.e. the alignment that is passed\n@@ -1393,1 +1304,1 @@\n-                                         HeapRegion::GrainBytes,\n+                                         G1HeapRegion::GrainBytes,\n@@ -1441,2 +1352,2 @@\n-  guarantee(HeapRegion::CardsPerRegion > 0, \"make sure it's initialized\");\n-  guarantee(HeapRegion::CardsPerRegion < max_cards_per_region,\n+  guarantee(G1HeapRegion::CardsPerRegion > 0, \"make sure it's initialized\");\n+  guarantee(G1HeapRegion::CardsPerRegion < max_cards_per_region,\n@@ -1452,1 +1363,1 @@\n-    size_t granularity = HeapRegion::GrainBytes;\n+    size_t granularity = G1HeapRegion::GrainBytes;\n@@ -1463,1 +1374,1 @@\n-  _numa->set_region_info(HeapRegion::GrainBytes, page_size);\n+  _numa->set_region_info(G1HeapRegion::GrainBytes, page_size);\n@@ -1496,1 +1407,1 @@\n-  \/\/ Here we allocate the dummy HeapRegion that is required by the\n+  \/\/ Here we allocate the dummy G1HeapRegion that is required by the\n@@ -1498,1 +1409,1 @@\n-  HeapRegion* dummy_region = _hrm.get_dummy_region();\n+  G1HeapRegion* dummy_region = _hrm.get_dummy_region();\n@@ -1517,1 +1428,6 @@\n-  evac_failure_injector()->reset();\n+  allocation_failure_injector()->reset();\n+\n+  CPUTimeCounters::create_counter(CPUTimeGroups::CPUTimeType::gc_parallel_workers);\n+  CPUTimeCounters::create_counter(CPUTimeGroups::CPUTimeType::gc_conc_mark);\n+  CPUTimeCounters::create_counter(CPUTimeGroups::CPUTimeType::gc_conc_refine);\n+  CPUTimeCounters::create_counter(CPUTimeGroups::CPUTimeType::gc_service);\n@@ -1586,0 +1502,1 @@\n+  _is_alive_closure_cm.initialize(concurrent_mark());\n@@ -1605,5 +1522,1 @@\n-SoftRefPolicy* G1CollectedHeap::soft_ref_policy() {\n-  return &_soft_ref_policy;\n-}\n-\n-  return _hrm.length() * HeapRegion::GrainBytes;\n+  return _hrm.length() * G1HeapRegion::GrainBytes;\n@@ -1631,1 +1544,1 @@\n-  bool do_heap_region(HeapRegion* r) {\n+  bool do_heap_region(G1HeapRegion* r) {\n@@ -1909,6 +1822,0 @@\n-    if (GCLocker::is_active_and_needs_gc()) {\n-      \/\/ If GCLocker is active, wait until clear before retrying.\n-      LOG_COLLECT_CONCURRENTLY(cause, \"gc-locker stall\");\n-      GCLocker::stall_until_clear();\n-    }\n-\n@@ -1940,5 +1847,0 @@\n-\n-    if (GCLocker::is_active_and_needs_gc()) {\n-      \/\/ If GCLocker is active, wait until clear before retrying.\n-      GCLocker::stall_until_clear();\n-    }\n@@ -1954,5 +1856,0 @@\n-  } else if (GCLocker::should_discard(cause, counters_before.total_collections())) {\n-    \/\/ Indicate failure to be consistent with VMOp failure due to\n-    \/\/ another collection slipping in after our gc_count but before\n-    \/\/ our request is processed.\n-    return false;\n@@ -1992,1 +1889,1 @@\n-\/\/ Iterates an ObjectClosure over all objects within a HeapRegion.\n+\/\/ Iterates an ObjectClosure over all objects within a G1HeapRegion.\n@@ -1998,1 +1895,1 @@\n-  bool do_heap_region(HeapRegion* r) {\n+  bool do_heap_region(G1HeapRegion* r) {\n@@ -2091,1 +1988,1 @@\n-      HeapRegion* r = region_at(region_idx);\n+      G1HeapRegion* r = region_at(region_idx);\n@@ -2104,1 +2001,1 @@\n-  HeapRegion* hr = heap_region_containing(addr);\n+  G1HeapRegion* hr = heap_region_containing(addr);\n@@ -2106,1 +2003,1 @@\n-  \/\/ the heap. HeapRegion::block_start() has been optimized to not accept addresses\n+  \/\/ the heap. G1HeapRegion::block_start() has been optimized to not accept addresses\n@@ -2115,1 +2012,1 @@\n-  HeapRegion* hr = heap_region_containing(addr);\n+  G1HeapRegion* hr = heap_region_containing(addr);\n@@ -2120,1 +2017,1 @@\n-  return (_policy->young_list_target_length() - _survivor.length()) * HeapRegion::GrainBytes;\n+  return (_policy->young_list_target_length() - _survivor.length()) * G1HeapRegion::GrainBytes;\n@@ -2124,1 +2021,1 @@\n-  return _eden.length() * HeapRegion::GrainBytes;\n+  return _eden.length() * G1HeapRegion::GrainBytes;\n@@ -2138,1 +2035,1 @@\n-  return max_regions() * HeapRegion::GrainBytes;\n+  return max_regions() * G1HeapRegion::GrainBytes;\n@@ -2157,1 +2054,1 @@\n-  bool do_heap_region(HeapRegion* r) {\n+  bool do_heap_region(G1HeapRegion* r) {\n@@ -2164,1 +2061,1 @@\n-                                       const HeapRegion* hr,\n+                                       const G1HeapRegion* hr,\n@@ -2184,8 +2081,0 @@\n-void G1CollectedHeap::pin_object(JavaThread* thread, oop obj) {\n-  GCLocker::lock_critical(thread);\n-}\n-\n-void G1CollectedHeap::unpin_object(JavaThread* thread, oop obj) {\n-  GCLocker::unlock_critical(thread);\n-}\n-\n@@ -2203,2 +2092,2 @@\n-  st->print(\" total \" SIZE_FORMAT \"K, used \" SIZE_FORMAT \"K\",\n-            capacity()\/K, heap_used\/K);\n+  st->print(\" total reserved %zuK, committed %zuK, used %zuK\",\n+            _hrm.reserved().byte_size()\/K, capacity()\/K, heap_used\/K);\n@@ -2209,1 +2098,1 @@\n-  st->print(\"  region size \" SIZE_FORMAT \"K, \", HeapRegion::GrainBytes \/ K);\n+  st->print(\"  region size \" SIZE_FORMAT \"K, \", G1HeapRegion::GrainBytes \/ K);\n@@ -2212,1 +2101,1 @@\n-            (size_t) young_regions * HeapRegion::GrainBytes \/ K);\n+            (size_t) young_regions * G1HeapRegion::GrainBytes \/ K);\n@@ -2215,1 +2104,1 @@\n-            (size_t) survivor_regions * HeapRegion::GrainBytes \/ K);\n+            (size_t) survivor_regions * G1HeapRegion::GrainBytes \/ K);\n@@ -2220,1 +2109,1 @@\n-    const int* node_ids = _numa->node_ids();\n+    const uint* node_ids = _numa->node_ids();\n@@ -2223,1 +2112,1 @@\n-      st->print(\"%d=%u \", node_ids[node_index], num_free_regions);\n+      st->print(\"%u=%u \", node_ids[node_index], num_free_regions);\n@@ -2282,1 +2171,1 @@\n-    (policy()->young_list_target_length() * HeapRegion::GrainBytes) - survivor_used_bytes;\n+    (policy()->young_list_target_length() * G1HeapRegion::GrainBytes) - survivor_used_bytes;\n@@ -2306,2 +2195,0 @@\n-  assert(InlineCacheBuffer::is_empty(), \"should have cleaned up ICBuffer\");\n-\n@@ -2334,0 +2221,2 @@\n+\n+  update_parallel_gc_threads_cpu_time();\n@@ -2393,1 +2282,1 @@\n-bool G1CollectedHeap::is_potential_eager_reclaim_candidate(HeapRegion* r) const {\n+bool G1CollectedHeap::is_potential_eager_reclaim_candidate(G1HeapRegion* r) const {\n@@ -2405,1 +2294,1 @@\n-    virtual bool do_heap_region(HeapRegion* r) {\n+    virtual bool do_heap_region(G1HeapRegion* r) {\n@@ -2418,0 +2307,20 @@\n+void G1CollectedHeap::update_parallel_gc_threads_cpu_time() {\n+  assert(Thread::current()->is_VM_thread(),\n+         \"Must be called from VM thread to avoid races\");\n+  if (!UsePerfData || !os::is_thread_cpu_time_supported()) {\n+    return;\n+  }\n+\n+  \/\/ Ensure ThreadTotalCPUTimeClosure destructor is called before publishing gc\n+  \/\/ time.\n+  {\n+    ThreadTotalCPUTimeClosure tttc(CPUTimeGroups::CPUTimeType::gc_parallel_workers);\n+    \/\/ Currently parallel worker threads never terminate (JDK-8081682), so it is\n+    \/\/ safe for VMThread to read their CPU times. However, if JDK-8087340 is\n+    \/\/ resolved so they terminate, we should rethink if it is still safe.\n+    workers()->threads_do(&tttc);\n+  }\n+\n+  CPUTimeCounters::publish_gc_total_cpu_time();\n+}\n+\n@@ -2492,5 +2401,1 @@\n-  guarantee(!is_gc_active(), \"collection is not reentrant\");\n-\n-  if (GCLocker::check_active_before_gc()) {\n-    return false;\n-  }\n+  guarantee(!is_stw_gc_active(), \"collection is not reentrant\");\n@@ -2557,0 +2462,6 @@\n+void G1CollectedHeap::flush_region_pin_cache() {\n+  for (JavaThreadIteratorWithHandle jtiwh; JavaThread *thread = jtiwh.next(); ) {\n+    G1ThreadLocalData::pin_count_cache(thread).flush();\n+  }\n+}\n+\n@@ -2560,1 +2471,1 @@\n-  IsGCActiveMark active_gc_mark;\n+  IsSTWGCActiveMark active_gc_mark;\n@@ -2599,0 +2510,59 @@\n+void G1CollectedHeap::unload_classes_and_code(const char* description, BoolObjectClosure* is_alive, GCTimer* timer) {\n+  GCTraceTime(Debug, gc, phases) debug(description, timer);\n+\n+  ClassUnloadingContext ctx(workers()->active_workers(),\n+                            false \/* unregister_nmethods_during_purge *\/,\n+                            false \/* lock_nmethod_free_separately *\/);\n+  {\n+    CodeCache::UnlinkingScope scope(is_alive);\n+    bool unloading_occurred = SystemDictionary::do_unloading(timer);\n+    GCTraceTime(Debug, gc, phases) t(\"G1 Complete Cleaning\", timer);\n+    complete_cleaning(unloading_occurred);\n+  }\n+  {\n+    GCTraceTime(Debug, gc, phases) t(\"Purge Unlinked NMethods\", timer);\n+    ctx.purge_nmethods();\n+  }\n+  {\n+    GCTraceTime(Debug, gc, phases) ur(\"Unregister NMethods\", timer);\n+    G1CollectedHeap::heap()->bulk_unregister_nmethods();\n+  }\n+  {\n+    GCTraceTime(Debug, gc, phases) t(\"Free Code Blobs\", timer);\n+    ctx.free_nmethods();\n+  }\n+  {\n+    GCTraceTime(Debug, gc, phases) t(\"Purge Class Loader Data\", timer);\n+    ClassLoaderDataGraph::purge(true \/* at_safepoint *\/);\n+    DEBUG_ONLY(MetaspaceUtils::verify();)\n+  }\n+}\n+\n+class G1BulkUnregisterNMethodTask : public WorkerTask {\n+  HeapRegionClaimer _hrclaimer;\n+\n+  class UnregisterNMethodsHeapRegionClosure : public HeapRegionClosure {\n+  public:\n+\n+    bool do_heap_region(G1HeapRegion* hr) {\n+      hr->rem_set()->bulk_remove_code_roots();\n+      return false;\n+    }\n+  } _cl;\n+\n+public:\n+  G1BulkUnregisterNMethodTask(uint num_workers)\n+  : WorkerTask(\"G1 Remove Unlinked NMethods From Code Root Set Task\"),\n+    _hrclaimer(num_workers) { }\n+\n+  void work(uint worker_id) {\n+    G1CollectedHeap::heap()->heap_region_par_iterate_from_worker_offset(&_cl, &_hrclaimer, worker_id);\n+  }\n+};\n+\n+void G1CollectedHeap::bulk_unregister_nmethods() {\n+  uint num_workers = workers()->active_workers();\n+  G1BulkUnregisterNMethodTask t(num_workers);\n+  workers()->run_task(&t);\n+}\n+\n@@ -2644,1 +2614,1 @@\n-void G1CollectedHeap::clear_bitmap_for_region(HeapRegion* hr) {\n+void G1CollectedHeap::clear_bitmap_for_region(G1HeapRegion* hr) {\n@@ -2648,1 +2618,1 @@\n-void G1CollectedHeap::free_region(HeapRegion* hr, FreeRegionList* free_list) {\n+void G1CollectedHeap::free_region(G1HeapRegion* hr, FreeRegionList* free_list) {\n@@ -2652,0 +2622,2 @@\n+  assert(!hr->has_pinned_objects(),\n+         \"must not free a region which contains pinned objects\");\n@@ -2662,1 +2634,1 @@\n-void G1CollectedHeap::retain_region(HeapRegion* hr) {\n+void G1CollectedHeap::retain_region(G1HeapRegion* hr) {\n@@ -2667,1 +2639,1 @@\n-void G1CollectedHeap::free_humongous_region(HeapRegion* hr,\n+void G1CollectedHeap::free_humongous_region(G1HeapRegion* hr,\n@@ -2712,1 +2684,1 @@\n-  virtual bool do_heap_region(HeapRegion* r) {\n+  virtual bool do_heap_region(G1HeapRegion* r) {\n@@ -2728,1 +2700,1 @@\n-bool G1CollectedHeap::is_old_gc_alloc_region(HeapRegion* hr) {\n+bool G1CollectedHeap::is_old_gc_alloc_region(G1HeapRegion* hr) {\n@@ -2732,1 +2704,1 @@\n-void G1CollectedHeap::set_region_short_lived_locked(HeapRegion* hr) {\n+void G1CollectedHeap::set_region_short_lived_locked(G1HeapRegion* hr) {\n@@ -2744,1 +2716,1 @@\n-  bool do_heap_region(HeapRegion* r) {\n+  bool do_heap_region(G1HeapRegion* r) {\n@@ -2767,3 +2739,3 @@\n-\/\/ Remove the given HeapRegion from the appropriate region set.\n-void G1CollectedHeap::prepare_region_for_full_compaction(HeapRegion* hr) {\n-   if (hr->is_humongous()) {\n+\/\/ Remove the given G1HeapRegion from the appropriate region set.\n+void G1CollectedHeap::prepare_region_for_full_compaction(G1HeapRegion* hr) {\n+  if (hr->is_humongous()) {\n@@ -2825,1 +2797,1 @@\n-  bool do_heap_region(HeapRegion* r) {\n+  bool do_heap_region(G1HeapRegion* r) {\n@@ -2875,2 +2847,1 @@\n-HeapRegion* G1CollectedHeap::new_mutator_alloc_region(size_t word_size,\n-                                                      bool force,\n+G1HeapRegion* G1CollectedHeap::new_mutator_alloc_region(size_t word_size,\n@@ -2880,5 +2851,5 @@\n-  if (force || should_allocate) {\n-    HeapRegion* new_alloc_region = new_region(word_size,\n-                                              HeapRegionType::Eden,\n-                                              false \/* do_expand *\/,\n-                                              node_index);\n+  if (should_allocate) {\n+    G1HeapRegion* new_alloc_region = new_region(word_size,\n+                                                HeapRegionType::Eden,\n+                                                false \/* do_expand *\/,\n+                                                node_index);\n@@ -2887,1 +2858,1 @@\n-      _hr_printer.alloc(new_alloc_region, !should_allocate);\n+      G1HeapRegionPrinter::alloc(new_alloc_region);\n@@ -2895,1 +2866,1 @@\n-void G1CollectedHeap::retire_mutator_alloc_region(HeapRegion* alloc_region,\n+void G1CollectedHeap::retire_mutator_alloc_region(G1HeapRegion* alloc_region,\n@@ -2903,1 +2874,1 @@\n-  _hr_printer.retire(alloc_region);\n+  G1HeapRegionPrinter::retire(alloc_region);\n@@ -2921,1 +2892,1 @@\n-HeapRegion* G1CollectedHeap::new_gc_alloc_region(size_t word_size, G1HeapRegionAttr dest, uint node_index) {\n+G1HeapRegion* G1CollectedHeap::new_gc_alloc_region(size_t word_size, G1HeapRegionAttr dest, uint node_index) {\n@@ -2935,4 +2906,4 @@\n-  HeapRegion* new_alloc_region = new_region(word_size,\n-                                            type,\n-                                            true \/* do_expand *\/,\n-                                            node_index);\n+  G1HeapRegion* new_alloc_region = new_region(word_size,\n+                                              type,\n+                                              true \/* do_expand *\/,\n+                                              node_index);\n@@ -2950,1 +2921,1 @@\n-    _hr_printer.alloc(new_alloc_region);\n+    G1HeapRegionPrinter::alloc(new_alloc_region);\n@@ -2956,1 +2927,1 @@\n-void G1CollectedHeap::retire_gc_alloc_region(HeapRegion* alloc_region,\n+void G1CollectedHeap::retire_gc_alloc_region(G1HeapRegion* alloc_region,\n@@ -2971,1 +2942,1 @@\n-  _hr_printer.retire(alloc_region);\n+  G1HeapRegionPrinter::retire(alloc_region);\n@@ -2974,1 +2945,1 @@\n-HeapRegion* G1CollectedHeap::alloc_highest_free_region() {\n+G1HeapRegion* G1CollectedHeap::alloc_highest_free_region() {\n@@ -2981,1 +2952,1 @@\n-                                HeapRegion::GrainWords * HeapWordSize);\n+                                G1HeapRegion::GrainWords * HeapWordSize);\n@@ -3007,1 +2978,1 @@\n-      HeapRegion* hr = _g1h->heap_region_containing(obj);\n+      G1HeapRegion* hr = _g1h->heap_region_containing(obj);\n@@ -3013,27 +2984,1 @@\n-      \/\/ HeapRegion::add_code_root_locked() avoids adding duplicate entries.\n-      hr->add_code_root_locked(_nm);\n-    }\n-  }\n-\n-  void do_oop(narrowOop* p) { ShouldNotReachHere(); }\n-};\n-\n-class UnregisterNMethodOopClosure: public OopClosure {\n-  G1CollectedHeap* _g1h;\n-  nmethod* _nm;\n-\n-public:\n-  UnregisterNMethodOopClosure(G1CollectedHeap* g1h, nmethod* nm) :\n-    _g1h(g1h), _nm(nm) {}\n-\n-  void do_oop(oop* p) {\n-    oop heap_oop = RawAccess<>::oop_load(p);\n-    if (!CompressedOops::is_null(heap_oop)) {\n-      oop obj = CompressedOops::decode_not_null(heap_oop);\n-      HeapRegion* hr = _g1h->heap_region_containing(obj);\n-      assert(!hr->is_continues_humongous(),\n-             \"trying to remove code root \" PTR_FORMAT \" in continuation of humongous region \" HR_FORMAT\n-             \" starting at \" HR_FORMAT,\n-             p2i(_nm), HR_FORMAT_PARAMS(hr), HR_FORMAT_PARAMS(hr->humongous_start_region()));\n-\n-      hr->remove_code_root(_nm);\n+      hr->add_code_root(_nm);\n@@ -3053,3 +2998,2 @@\n-  guarantee(nm != nullptr, \"sanity\");\n-  UnregisterNMethodOopClosure reg_cl(this, nm);\n-  nm->oops_do(&reg_cl, true);\n+  \/\/ We always unregister nmethods in bulk during code unloading only.\n+  ShouldNotReachHere();\n@@ -3060,3 +3004,0 @@\n-    \/\/ Reset the G1EvacuationFailureALot counters and flags\n-    evac_failure_injector()->reset();\n-\n@@ -3071,1 +3012,1 @@\n-class RebuildCodeRootClosure: public CodeBlobClosure {\n+class RebuildCodeRootClosure: public NMethodClosure {\n@@ -3078,5 +3019,3 @@\n-  void do_code_blob(CodeBlob* cb) {\n-    nmethod* nm = cb->as_nmethod_or_null();\n-    if (nm != nullptr) {\n-      _g1h->register_nmethod(nm);\n-    }\n+  void do_nmethod(nmethod* nm) {\n+    assert(nm != nullptr, \"Sanity\");\n+    _g1h->register_nmethod(nm);\n@@ -3087,2 +3026,2 @@\n-  RebuildCodeRootClosure blob_cl(this);\n-  CodeCache::blobs_do(&blob_cl);\n+  RebuildCodeRootClosure nmethod_cl(this);\n+  CodeCache::nmethods_do(&nmethod_cl);\n@@ -3108,1 +3047,1 @@\n-  HeapRegion* region = heap_region_containing(start);\n+  G1HeapRegion* region = heap_region_containing(start);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":271,"deletions":332,"binary":false,"changes":603,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -39,0 +39,2 @@\n+#include \"gc\/g1\/g1HeapRegionManager.hpp\"\n+#include \"gc\/g1\/g1HeapRegionSet.hpp\"\n@@ -41,1 +43,0 @@\n-#include \"gc\/g1\/g1HRPrinter.hpp\"\n@@ -48,3 +49,1 @@\n-#include \"gc\/g1\/g1YoungGCEvacFailureInjector.hpp\"\n-#include \"gc\/g1\/heapRegionManager.hpp\"\n-#include \"gc\/g1\/heapRegionSet.hpp\"\n+#include \"gc\/g1\/g1YoungGCAllocationFailureInjector.hpp\"\n@@ -84,1 +83,1 @@\n-class HeapRegion;\n+class G1HeapRegion;\n@@ -182,2 +181,0 @@\n-  SoftRefPolicy      _soft_ref_policy;\n-\n@@ -203,1 +200,1 @@\n-  void prepare_region_for_full_compaction(HeapRegion* hr);\n+  void prepare_region_for_full_compaction(G1HeapRegion* hr);\n@@ -224,1 +221,1 @@\n-  G1YoungGCEvacFailureInjector _evac_failure_injector;\n+  G1YoungGCAllocationFailureInjector _allocation_failure_injector;\n@@ -268,0 +265,1 @@\n+  void update_parallel_gc_threads_cpu_time();\n@@ -270,2 +268,0 @@\n-  G1HRPrinter _hr_printer;\n-\n@@ -390,1 +386,1 @@\n-  \/\/ Try to allocate a single non-humongous HeapRegion sufficient for\n+  \/\/ Try to allocate a single non-humongous G1HeapRegion sufficient for\n@@ -395,4 +391,4 @@\n-  HeapRegion* new_region(size_t word_size,\n-                         HeapRegionType type,\n-                         bool do_expand,\n-                         uint node_index = G1NUMA::AnyNodeIndex);\n+  G1HeapRegion* new_region(size_t word_size,\n+                           HeapRegionType type,\n+                           bool do_expand,\n+                           uint node_index = G1NUMA::AnyNodeIndex);\n@@ -403,1 +399,1 @@\n-  HeapWord* humongous_obj_allocate_initialize_regions(HeapRegion* first_hr,\n+  HeapWord* humongous_obj_allocate_initialize_regions(G1HeapRegion* first_hr,\n@@ -473,2 +469,2 @@\n-  HeapRegion* new_mutator_alloc_region(size_t word_size, bool force, uint node_index);\n-  void retire_mutator_alloc_region(HeapRegion* alloc_region,\n+  G1HeapRegion* new_mutator_alloc_region(size_t word_size, uint node_index);\n+  void retire_mutator_alloc_region(G1HeapRegion* alloc_region,\n@@ -479,2 +475,2 @@\n-  HeapRegion* new_gc_alloc_region(size_t word_size, G1HeapRegionAttr dest, uint node_index);\n-  void retire_gc_alloc_region(HeapRegion* alloc_region,\n+  G1HeapRegion* new_gc_alloc_region(size_t word_size, G1HeapRegionAttr dest, uint node_index);\n+  void retire_gc_alloc_region(G1HeapRegion* alloc_region,\n@@ -553,1 +549,1 @@\n-  G1YoungGCEvacFailureInjector* evac_failure_injector() { return &_evac_failure_injector; }\n+  G1YoungGCAllocationFailureInjector* allocation_failure_injector() { return &_allocation_failure_injector; }\n@@ -564,0 +560,3 @@\n+  void pin_object(JavaThread* thread, oop obj) override;\n+  void unpin_object(JavaThread* thread, oop obj) override;\n+\n@@ -577,1 +576,1 @@\n-  \/\/ (Rounds up to a HeapRegion boundary.)\n+  \/\/ (Rounds up to a G1HeapRegion boundary.)\n@@ -598,1 +597,1 @@\n-  bool is_potential_eager_reclaim_candidate(HeapRegion* r) const;\n+  bool is_potential_eager_reclaim_candidate(G1HeapRegion* r) const;\n@@ -609,1 +608,1 @@\n-  void set_humongous_metadata(HeapRegion* first_hr,\n+  void set_humongous_metadata(G1HeapRegion* first_hr,\n@@ -616,2 +615,2 @@\n-  void register_young_region_with_region_attr(HeapRegion* r) {\n-    _region_attr.set_in_young(r->hrm_index());\n+  void register_young_region_with_region_attr(G1HeapRegion* r) {\n+    _region_attr.set_in_young(r->hrm_index(), r->has_pinned_objects());\n@@ -619,4 +618,4 @@\n-  inline void register_new_survivor_region_with_region_attr(HeapRegion* r);\n-  inline void register_region_with_region_attr(HeapRegion* r);\n-  inline void register_old_region_with_region_attr(HeapRegion* r);\n-  inline void register_optional_region_with_region_attr(HeapRegion* r);\n+  inline void register_new_survivor_region_with_region_attr(G1HeapRegion* r);\n+  inline void register_region_with_region_attr(G1HeapRegion* r);\n+  inline void register_old_region_with_region_attr(G1HeapRegion* r);\n+  inline void register_optional_region_with_region_attr(G1HeapRegion* r);\n@@ -624,1 +623,1 @@\n-  void clear_region_attr(const HeapRegion* hr) {\n+  void clear_region_attr(const G1HeapRegion* hr) {\n@@ -636,1 +635,1 @@\n-  void clear_bitmap_for_region(HeapRegion* hr);\n+  void clear_bitmap_for_region(G1HeapRegion* hr);\n@@ -671,3 +670,1 @@\n-  G1HRPrinter* hr_printer() { return &_hr_printer; }\n-\n-  HeapRegion* new_heap_region(uint hrs_index, MemRegion mr);\n+  G1HeapRegion* new_heap_region(uint hrs_index, MemRegion mr);\n@@ -678,1 +675,1 @@\n-  HeapRegion* alloc_highest_free_region();\n+  G1HeapRegion* alloc_highest_free_region();\n@@ -686,1 +683,1 @@\n-  void free_region(HeapRegion* hr, FreeRegionList* free_list);\n+  void free_region(G1HeapRegion* hr, FreeRegionList* free_list);\n@@ -689,1 +686,1 @@\n-  void retain_region(HeapRegion* hr);\n+  void retain_region(G1HeapRegion* hr);\n@@ -703,1 +700,1 @@\n-  void free_humongous_region(HeapRegion* hr,\n+  void free_humongous_region(G1HeapRegion* hr,\n@@ -706,1 +703,1 @@\n-  \/\/ Execute func(HeapRegion* r, bool is_last) on every region covered by the\n+  \/\/ Execute func(G1HeapRegion* r, bool is_last) on every region covered by the\n@@ -719,1 +716,1 @@\n-  \/\/ Populate the G1BlockOffsetTablePart for archived regions with the given\n+  \/\/ Populate the G1BlockOffsetTable for archived regions with the given\n@@ -721,1 +718,1 @@\n-  void populate_archive_regions_bot_part(MemRegion range);\n+  void populate_archive_regions_bot(MemRegion range);\n@@ -732,1 +729,1 @@\n-  \/\/ (Rounds down to a HeapRegion boundary.)\n+  \/\/ (Rounds down to a G1HeapRegion boundary.)\n@@ -756,1 +753,1 @@\n-  \/\/ precondition: !is_gc_active()\n+  \/\/ precondition: !is_stw_gc_active()\n@@ -775,0 +772,4 @@\n+  \/\/ Update all region's pin counts from the per-thread caches and resets them.\n+  \/\/ Must be called before any decision based on pin counts.\n+  void flush_region_pin_cache();\n+\n@@ -921,3 +922,1 @@\n-  inline bool is_collection_set_candidate(const HeapRegion* r) const;\n-\n-  SoftRefPolicy* soft_ref_policy() override;\n+  inline bool is_collection_set_candidate(const G1HeapRegion* r) const;\n@@ -998,1 +997,1 @@\n-  bool is_on_master_free_list(HeapRegion* hr) {\n+  bool is_on_master_free_list(G1HeapRegion* hr) {\n@@ -1003,2 +1002,2 @@\n-  inline void old_set_add(HeapRegion* hr);\n-  inline void old_set_remove(HeapRegion* hr);\n+  inline void old_set_add(G1HeapRegion* hr);\n+  inline void old_set_remove(G1HeapRegion* hr);\n@@ -1007,1 +1006,1 @@\n-    return (old_regions_count() + humongous_regions_count()) * HeapRegion::GrainBytes;\n+    return (old_regions_count() + humongous_regions_count()) * G1HeapRegion::GrainBytes;\n@@ -1012,1 +1011,1 @@\n-  bool is_old_gc_alloc_region(HeapRegion* hr);\n+  bool is_old_gc_alloc_region(G1HeapRegion* hr);\n@@ -1038,1 +1037,1 @@\n-  inline bool is_in_cset(const HeapRegion* hr) const;\n+  inline bool is_in_cset(const G1HeapRegion* hr) const;\n@@ -1085,2 +1084,2 @@\n-  inline HeapRegion* region_at(uint index) const;\n-  inline HeapRegion* region_at_or_null(uint index) const;\n+  inline G1HeapRegion* region_at(uint index) const;\n+  inline G1HeapRegion* region_at_or_null(uint index) const;\n@@ -1089,1 +1088,1 @@\n-  \/\/ region and apply the given method with the signature f(HeapRegion*) on them.\n+  \/\/ region and apply the given method with the signature f(G1HeapRegion*) on them.\n@@ -1091,1 +1090,1 @@\n-  void humongous_obj_regions_iterate(HeapRegion* start, const Func& f);\n+  void humongous_obj_regions_iterate(G1HeapRegion* start, const Func& f);\n@@ -1139,2 +1138,2 @@\n-  \/\/ Returns the HeapRegion that contains addr. addr must not be null.\n-  inline HeapRegion* heap_region_containing(const void* addr) const;\n+  \/\/ Returns the G1HeapRegion that contains addr. addr must not be null.\n+  inline G1HeapRegion* heap_region_containing(const void* addr) const;\n@@ -1142,1 +1141,1 @@\n-  \/\/ Returns the HeapRegion that contains addr, or null if that is an uncommitted\n+  \/\/ Returns the G1HeapRegion that contains addr, or null if that is an uncommitted\n@@ -1144,1 +1143,1 @@\n-  inline HeapRegion* heap_region_containing_or_null(const void* addr) const;\n+  inline G1HeapRegion* heap_region_containing_or_null(const void* addr) const;\n@@ -1206,1 +1205,1 @@\n-  void set_region_short_lived_locked(HeapRegion* hr);\n+  void set_region_short_lived_locked(G1HeapRegion* hr);\n@@ -1230,1 +1229,1 @@\n-  inline bool is_obj_dead(const oop obj, const HeapRegion* hr) const;\n+  inline bool is_obj_dead(const oop obj, const G1HeapRegion* hr) const;\n@@ -1238,1 +1237,1 @@\n-  inline bool is_obj_dead_full(const oop obj, const HeapRegion* hr) const;\n+  inline bool is_obj_dead_full(const oop obj, const G1HeapRegion* hr) const;\n@@ -1272,0 +1271,4 @@\n+  void unload_classes_and_code(const char* description, BoolObjectClosure* cl, GCTimer* timer);\n+\n+  void bulk_unregister_nmethods();\n+\n@@ -1291,1 +1294,1 @@\n-                        const HeapRegion* hr,\n+                        const G1HeapRegion* hr,\n@@ -1300,3 +1303,0 @@\n-  void pin_object(JavaThread* thread, oop obj) override;\n-  void unpin_object(JavaThread* thread, oop obj) override;\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.hpp","additions":70,"deletions":70,"binary":false,"changes":140,"status":"modified"},{"patch":"@@ -126,1 +126,1 @@\n-    size_t min_expand_bytes = HeapRegion::GrainBytes;\n+    size_t min_expand_bytes = G1HeapRegion::GrainBytes;\n@@ -220,1 +220,8 @@\n-  const size_t used_after_gc = capacity_after_gc - _g1h->unused_committed_regions_in_bytes();\n+  const size_t used_after_gc = capacity_after_gc -\n+                               _g1h->unused_committed_regions_in_bytes() -\n+                               \/\/ Discount space used by current Eden to establish a\n+                               \/\/ situation during Remark similar to at the end of full\n+                               \/\/ GC where eden is empty. During Remark there can be an\n+                               \/\/ arbitrary number of eden regions which would skew the\n+                               \/\/ results.\n+                               _g1h->eden_regions_count() * G1HeapRegion::GrainBytes;\n@@ -245,1 +252,1 @@\n-    maximum_desired_capacity = HeapRegion::GrainBytes;\n+    maximum_desired_capacity = G1HeapRegion::GrainBytes;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeapSizingPolicy.cpp","additions":10,"deletions":3,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -86,2 +86,2 @@\n-                      byte_size_in_proper_unit(regions * HeapRegion::GrainBytes),\n-                      proper_unit_for_byte_size(regions * HeapRegion::GrainBytes),\n+                      byte_size_in_proper_unit(regions * G1HeapRegion::GrainBytes),\n+                      proper_unit_for_byte_size(regions * G1HeapRegion::GrainBytes),\n@@ -94,2 +94,2 @@\n-                      byte_size_in_proper_unit(_summary_region_count * HeapRegion::GrainBytes),\n-                      proper_unit_for_byte_size(_summary_region_count * HeapRegion::GrainBytes),\n+                      byte_size_in_proper_unit(_summary_region_count * G1HeapRegion::GrainBytes),\n+                      proper_unit_for_byte_size(_summary_region_count * G1HeapRegion::GrainBytes),\n","filename":"src\/hotspot\/share\/gc\/g1\/g1UncommitRegionTask.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -34,0 +34,1 @@\n+#include \"gc\/parallel\/objectStartArray.inline.hpp\"\n@@ -46,0 +47,1 @@\n+#include \"gc\/shared\/classUnloadingContext.hpp\"\n@@ -57,0 +59,1 @@\n+#include \"gc\/shared\/preservedMarks.inline.hpp\"\n@@ -60,1 +63,1 @@\n-#include \"gc\/shared\/spaceDecorator.inline.hpp\"\n+#include \"gc\/shared\/strongRootsScope.hpp\"\n@@ -71,0 +74,1 @@\n+#include \"nmt\/memTracker.hpp\"\n@@ -84,1 +88,0 @@\n-#include \"services\/memTracker.hpp\"\n@@ -101,0 +104,1 @@\n+static_assert(ParallelCompactData::RegionSize >= BitsPerWord, \"region-start bit word-aligned\");\n@@ -107,12 +111,0 @@\n-const size_t ParallelCompactData::Log2BlockSize   = 7; \/\/ 128 words\n-const size_t ParallelCompactData::BlockSize       = (size_t)1 << Log2BlockSize;\n-const size_t ParallelCompactData::BlockSizeBytes  =\n-  BlockSize << LogHeapWordSize;\n-const size_t ParallelCompactData::BlockSizeOffsetMask = BlockSize - 1;\n-const size_t ParallelCompactData::BlockAddrOffsetMask = BlockSizeBytes - 1;\n-const size_t ParallelCompactData::BlockAddrMask       = ~BlockAddrOffsetMask;\n-\n-const size_t ParallelCompactData::BlocksPerRegion = RegionSize \/ BlockSize;\n-const size_t ParallelCompactData::Log2BlocksPerRegion =\n-  Log2RegionSize - Log2BlockSize;\n-\n@@ -142,8 +134,0 @@\n-double PSParallelCompact::_dwl_mean;\n-double PSParallelCompact::_dwl_std_dev;\n-double PSParallelCompact::_dwl_first_term;\n-double PSParallelCompact::_dwl_adjustment;\n-#ifdef  ASSERT\n-bool   PSParallelCompact::_dwl_initialized = false;\n-#endif  \/\/ #ifdef ASSERT\n-\n@@ -249,1 +233,1 @@\n-void\n+static void\n@@ -258,1 +242,1 @@\n-      REGION_IDX_FORMAT \" \" PTR_FORMAT \" \"\n+      REGION_IDX_FORMAT \" \"\n@@ -262,1 +246,1 @@\n-      i, p2i(c->data_location()), dci, p2i(c->destination()),\n+      i, dci, p2i(c->destination()),\n@@ -300,16 +284,1 @@\n-void\n-print_generic_summary_data(ParallelCompactData& summary_data,\n-                           SpaceInfo* space_info)\n-{\n-  if (!log_develop_is_enabled(Trace, gc, compaction)) {\n-    return;\n-  }\n-\n-  for (unsigned int id = 0; id < PSParallelCompact::last_space_id; ++id) {\n-    const MutableSpace* space = space_info[id].space();\n-    print_generic_summary_data(summary_data, space->bottom(),\n-                               MAX2(space->top(), space_info[id].new_top()));\n-  }\n-}\n-\n-void\n+static void\n@@ -396,1 +365,1 @@\n-void\n+static void\n@@ -418,2 +387,2 @@\n-  _region_start(nullptr),\n-  DEBUG_ONLY(_region_end(nullptr) COMMA)\n+  _heap_start(nullptr),\n+  DEBUG_ONLY(_heap_end(nullptr) COMMA)\n@@ -423,4 +392,1 @@\n-  _region_count(0),\n-  _block_vspace(nullptr),\n-  _block_data(nullptr),\n-  _block_count(0) {}\n+  _region_count(0) {}\n@@ -428,1 +394,1 @@\n-bool ParallelCompactData::initialize(MemRegion covered_region)\n+bool ParallelCompactData::initialize(MemRegion reserved_heap)\n@@ -430,3 +396,3 @@\n-  _region_start = covered_region.start();\n-  const size_t region_size = covered_region.word_size();\n-  DEBUG_ONLY(_region_end = _region_start + region_size;)\n+  _heap_start = reserved_heap.start();\n+  const size_t heap_size = reserved_heap.word_size();\n+  DEBUG_ONLY(_heap_end = _heap_start + heap_size;)\n@@ -434,1 +400,1 @@\n-  assert(region_align_down(_region_start) == _region_start,\n+  assert(region_align_down(_heap_start) == _heap_start,\n@@ -437,2 +403,1 @@\n-  bool result = initialize_region_data(region_size) && initialize_block_data();\n-  return result;\n+  return initialize_region_data(heap_size);\n@@ -470,1 +435,1 @@\n-bool ParallelCompactData::initialize_region_data(size_t region_size)\n+bool ParallelCompactData::initialize_region_data(size_t heap_size)\n@@ -472,2 +437,1 @@\n-  assert((region_size & RegionSizeOffsetMask) == 0,\n-         \"region size not a multiple of RegionSize\");\n+  assert(is_aligned(heap_size, RegionSize), \"precondition\");\n@@ -475,1 +439,1 @@\n-  const size_t count = region_size >> Log2RegionSize;\n+  const size_t count = heap_size >> Log2RegionSize;\n@@ -485,19 +449,0 @@\n-bool ParallelCompactData::initialize_block_data()\n-{\n-  assert(_region_count != 0, \"region data must be initialized first\");\n-  const size_t count = _region_count << Log2BlocksPerRegion;\n-  _block_vspace = create_vspace(count, sizeof(BlockData));\n-  if (_block_vspace != 0) {\n-    _block_data = (BlockData*)_block_vspace->reserved_low_addr();\n-    _block_count = count;\n-    return true;\n-  }\n-  return false;\n-}\n-\n-void ParallelCompactData::clear()\n-{\n-  memset(_region_data, 0, _region_vspace->committed_size());\n-  memset(_block_data, 0, _block_vspace->committed_size());\n-}\n-\n@@ -507,1 +452,0 @@\n-  assert(RegionSize % BlockSize == 0, \"RegionSize not a multiple of BlockSize\");\n@@ -511,47 +455,0 @@\n-\n-  const size_t beg_block = beg_region * BlocksPerRegion;\n-  const size_t block_cnt = region_cnt * BlocksPerRegion;\n-  memset(_block_data + beg_block, 0, block_cnt * sizeof(BlockData));\n-}\n-\n-HeapWord* ParallelCompactData::partial_obj_end(size_t region_idx) const\n-{\n-  const RegionData* cur_cp = region(region_idx);\n-  const RegionData* const end_cp = region(region_count() - 1);\n-\n-  HeapWord* result = region_to_addr(region_idx);\n-  if (cur_cp < end_cp) {\n-    do {\n-      result += cur_cp->partial_obj_size();\n-    } while (cur_cp->partial_obj_size() == RegionSize && ++cur_cp < end_cp);\n-  }\n-  return result;\n-}\n-\n-void ParallelCompactData::add_obj(HeapWord* addr, size_t len)\n-{\n-  const size_t obj_ofs = pointer_delta(addr, _region_start);\n-  const size_t beg_region = obj_ofs >> Log2RegionSize;\n-  \/\/ end_region is inclusive\n-  const size_t end_region = (obj_ofs + len - 1) >> Log2RegionSize;\n-\n-  if (beg_region == end_region) {\n-    \/\/ All in one region.\n-    _region_data[beg_region].add_live_obj(len);\n-    return;\n-  }\n-\n-  \/\/ First region.\n-  const size_t beg_ofs = region_offset(addr);\n-  _region_data[beg_region].add_live_obj(RegionSize - beg_ofs);\n-\n-  \/\/ Middle regions--completely spanned by this object.\n-  for (size_t region = beg_region + 1; region < end_region; ++region) {\n-    _region_data[region].set_partial_obj_size(RegionSize);\n-    _region_data[region].set_partial_obj_addr(addr);\n-  }\n-\n-  \/\/ Last region.\n-  const size_t end_ofs = region_offset(addr + len - 1);\n-  _region_data[end_region].set_partial_obj_size(end_ofs + 1);\n-  _region_data[end_region].set_partial_obj_addr(addr);\n@@ -573,1 +470,0 @@\n-    _region_data[cur_region].set_data_location(addr);\n@@ -690,0 +586,32 @@\n+size_t ParallelCompactData::live_words_in_space(const MutableSpace* space,\n+                                                HeapWord** full_region_prefix_end) {\n+  size_t cur_region = addr_to_region_idx(space->bottom());\n+  const size_t end_region = addr_to_region_idx(region_align_up(space->top()));\n+  size_t live_words = 0;\n+  if (full_region_prefix_end == nullptr) {\n+    for (\/* empty *\/; cur_region < end_region; ++cur_region) {\n+      live_words += _region_data[cur_region].data_size();\n+    }\n+  } else {\n+    bool first_set = false;\n+    for (\/* empty *\/; cur_region < end_region; ++cur_region) {\n+      size_t live_words_in_region = _region_data[cur_region].data_size();\n+      if (!first_set && live_words_in_region < RegionSize) {\n+        *full_region_prefix_end = region_to_addr(cur_region);\n+        first_set = true;\n+      }\n+      live_words += live_words_in_region;\n+    }\n+    if (!first_set) {\n+      \/\/ All regions are full of live objs.\n+      assert(is_region_aligned(space->top()), \"inv\");\n+      *full_region_prefix_end = space->top();\n+    }\n+    assert(*full_region_prefix_end != nullptr, \"postcondition\");\n+    assert(is_region_aligned(*full_region_prefix_end), \"inv\");\n+    assert(*full_region_prefix_end >= space->bottom(), \"in-range\");\n+    assert(*full_region_prefix_end <= space->top(), \"in-range\");\n+  }\n+  return live_words;\n+}\n+\n@@ -767,1 +695,0 @@\n-      _region_data[cur_region].set_data_location(region_to_addr(cur_region));\n@@ -778,43 +705,0 @@\n-HeapWord* ParallelCompactData::calc_new_pointer(HeapWord* addr, ParCompactionManager* cm) const {\n-  assert(addr != nullptr, \"Should detect null oop earlier\");\n-  assert(ParallelScavengeHeap::heap()->is_in(addr), \"not in heap\");\n-  assert(PSParallelCompact::mark_bitmap()->is_marked(addr), \"not marked\");\n-\n-  \/\/ Region covering the object.\n-  RegionData* const region_ptr = addr_to_region_ptr(addr);\n-  HeapWord* result = region_ptr->destination();\n-\n-  \/\/ If the entire Region is live, the new location is region->destination + the\n-  \/\/ offset of the object within in the Region.\n-\n-  \/\/ Run some performance tests to determine if this special case pays off.  It\n-  \/\/ is worth it for pointers into the dense prefix.  If the optimization to\n-  \/\/ avoid pointer updates in regions that only point to the dense prefix is\n-  \/\/ ever implemented, this should be revisited.\n-  if (region_ptr->data_size() == RegionSize) {\n-    result += region_offset(addr);\n-    return result;\n-  }\n-\n-  \/\/ Otherwise, the new location is region->destination + block offset + the\n-  \/\/ number of live words in the Block that are (a) to the left of addr and (b)\n-  \/\/ due to objects that start in the Block.\n-\n-  \/\/ Fill in the block table if necessary.  This is unsynchronized, so multiple\n-  \/\/ threads may fill the block table for a region (harmless, since it is\n-  \/\/ idempotent).\n-  if (!region_ptr->blocks_filled()) {\n-    PSParallelCompact::fill_blocks(addr_to_region_idx(addr));\n-    region_ptr->set_blocks_filled();\n-  }\n-\n-  HeapWord* const search_start = block_align_down(addr);\n-  const size_t block_offset = addr_to_block_ptr(addr)->offset();\n-\n-  const ParMarkBitMap* bitmap = PSParallelCompact::mark_bitmap();\n-  const size_t live = bitmap->live_words_in_range(cm, search_start, cast_to_oop(addr));\n-  result += block_offset + live;\n-  DEBUG_ONLY(PSParallelCompact::check_new_location(addr, result));\n-  return result;\n-}\n-\n@@ -834,1 +718,0 @@\n-  verify_clear(_block_vspace);\n@@ -848,0 +731,13 @@\n+class PCAdjustPointerClosure: public BasicOopIterateClosure {\n+  template <typename T>\n+  void do_oop_work(T* p) { PSParallelCompact::adjust_pointer(p); }\n+\n+public:\n+  virtual void do_oop(oop* p)                { do_oop_work(p); }\n+  virtual void do_oop(narrowOop* p)          { do_oop_work(p); }\n+\n+  virtual ReferenceIterationMode reference_iteration_mode() { return DO_FIELDS; }\n+};\n+\n+static PCAdjustPointerClosure pc_adjust_pointer_closure;\n+\n@@ -866,1 +762,1 @@\n-bool PSParallelCompact::initialize() {\n+bool PSParallelCompact::initialize_aux_data() {\n@@ -869,5 +765,1 @@\n-\n-  \/\/ Was the old gen get allocated successfully?\n-  if (!heap->old_gen()->is_allocated()) {\n-    return false;\n-  }\n+  assert(mr.byte_size() != 0, \"heap should be reserved\");\n@@ -876,1 +768,0 @@\n-  initialize_dead_wood_limiter();\n@@ -912,10 +803,0 @@\n-void PSParallelCompact::initialize_dead_wood_limiter()\n-{\n-  const size_t max = 100;\n-  _dwl_mean = double(MIN2(ParallelOldDeadWoodLimiterMean, max)) \/ 100.0;\n-  _dwl_std_dev = double(MIN2(ParallelOldDeadWoodLimiterStdDev, max)) \/ 100.0;\n-  _dwl_first_term = 1.0 \/ (sqrt(2.0 * M_PI) * _dwl_std_dev);\n-  DEBUG_ONLY(_dwl_initialized = true;)\n-  _dwl_adjustment = normal_distribution(1.0);\n-}\n-\n@@ -934,3 +815,1 @@\n-  const idx_t beg_bit = _mark_bitmap.addr_to_bit(bot);\n-  const idx_t end_bit = _mark_bitmap.align_range_end(_mark_bitmap.addr_to_bit(top));\n-  _mark_bitmap.clear_range(beg_bit, end_bit);\n+  _mark_bitmap.clear_range(bot, top);\n@@ -977,6 +856,0 @@\n-  \/\/ Verify object start arrays\n-  if (VerifyObjectStartArray &&\n-      VerifyBeforeGC) {\n-    heap->old_gen()->verify_object_start_array();\n-  }\n-\n@@ -985,2 +858,0 @@\n-\n-  ParCompactionManager::reset_all_bitmap_query_caches();\n@@ -1000,2 +871,10 @@\n-    \/\/ Update top().  Must be done after clearing the bitmap and summary data.\n-    _space_info[id].publish_new_top();\n+    {\n+      MutableSpace* space = _space_info[id].space();\n+      HeapWord* top = space->top();\n+      HeapWord* new_top = _space_info[id].new_top();\n+      if (ZapUnusedHeapArea && new_top < top) {\n+        space->mangle_region(MemRegion(new_top, top));\n+      }\n+      \/\/ Update top().  Must be done after clearing the bitmap and summary data.\n+      space->set_top(new_top);\n+    }\n@@ -1028,3 +907,6 @@\n-  \/\/ Delete metaspaces for unloaded class loaders and clean up loader_data graph\n-  ClassLoaderDataGraph::purge(\/*at_safepoint*\/true);\n-  DEBUG_ONLY(MetaspaceUtils::verify();)\n+  {\n+    \/\/ Delete metaspaces for unloaded class loaders and clean up loader_data graph\n+    GCTraceTime(Debug, gc, phases) t(\"Purge Class Loader Data\", gc_timer());\n+    ClassLoaderDataGraph::purge(true \/* at_safepoint *\/);\n+    DEBUG_ONLY(MetaspaceUtils::verify();)\n+  }\n@@ -1041,4 +923,0 @@\n-  if (ZapUnusedHeapArea) {\n-    heap->gen_mangle_unused_area();\n-  }\n-\n@@ -1049,4 +927,2 @@\n-HeapWord*\n-PSParallelCompact::compute_dense_prefix_via_density(const SpaceId id,\n-                                                    bool maximum_compaction)\n-{\n+HeapWord* PSParallelCompact::compute_dense_prefix_for_old_space(MutableSpace* old_space,\n+                                                                HeapWord* full_region_prefix_end) {\n@@ -1056,88 +932,14 @@\n-  const MutableSpace* const space = _space_info[id].space();\n-  HeapWord* const top_aligned_up = sd.region_align_up(space->top());\n-  const RegionData* const beg_cp = sd.addr_to_region_ptr(space->bottom());\n-  const RegionData* const end_cp = sd.addr_to_region_ptr(top_aligned_up);\n-\n-  \/\/ Skip full regions at the beginning of the space--they are necessarily part\n-  \/\/ of the dense prefix.\n-  size_t full_count = 0;\n-  const RegionData* cp;\n-  for (cp = beg_cp; cp < end_cp && cp->data_size() == region_size; ++cp) {\n-    ++full_count;\n-  }\n-\n-  const uint total_invocations = ParallelScavengeHeap::heap()->total_full_collections();\n-  assert(total_invocations >= _maximum_compaction_gc_num, \"sanity\");\n-  const size_t gcs_since_max = total_invocations - _maximum_compaction_gc_num;\n-  const bool interval_ended = gcs_since_max > HeapMaximumCompactionInterval;\n-  if (maximum_compaction || cp == end_cp || interval_ended) {\n-    _maximum_compaction_gc_num = total_invocations;\n-    return sd.region_to_addr(cp);\n-  }\n-\n-  HeapWord* const new_top = _space_info[id].new_top();\n-  const size_t space_live = pointer_delta(new_top, space->bottom());\n-  const size_t space_used = space->used_in_words();\n-  const size_t space_capacity = space->capacity_in_words();\n-\n-  const double cur_density = double(space_live) \/ space_capacity;\n-  const double deadwood_density =\n-    (1.0 - cur_density) * (1.0 - cur_density) * cur_density * cur_density;\n-  const size_t deadwood_goal = size_t(space_capacity * deadwood_density);\n-\n-  log_develop_debug(gc, compaction)(\n-      \"cur_dens=%5.3f dw_dens=%5.3f dw_goal=\" SIZE_FORMAT,\n-      cur_density, deadwood_density, deadwood_goal);\n-  log_develop_debug(gc, compaction)(\n-      \"space_live=\" SIZE_FORMAT \" space_used=\" SIZE_FORMAT \" \"\n-      \"space_cap=\" SIZE_FORMAT,\n-      space_live, space_used,\n-      space_capacity);\n-\n-  \/\/ XXX - Use binary search?\n-  HeapWord* dense_prefix = sd.region_to_addr(cp);\n-  const RegionData* full_cp = cp;\n-  const RegionData* const top_cp = sd.addr_to_region_ptr(space->top() - 1);\n-  while (cp < end_cp) {\n-    HeapWord* region_destination = cp->destination();\n-    const size_t cur_deadwood = pointer_delta(dense_prefix, region_destination);\n-\n-    log_develop_trace(gc, compaction)(\n-        \"c#=\" SIZE_FORMAT_W(4) \" dst=\" PTR_FORMAT \" \"\n-        \"dp=\" PTR_FORMAT \" cdw=\" SIZE_FORMAT_W(8),\n-        sd.region(cp), p2i(region_destination),\n-        p2i(dense_prefix), cur_deadwood);\n-\n-    if (cur_deadwood >= deadwood_goal) {\n-      \/\/ Found the region that has the correct amount of deadwood to the left.\n-      \/\/ This typically occurs after crossing a fairly sparse set of regions, so\n-      \/\/ iterate backwards over those sparse regions, looking for the region\n-      \/\/ that has the lowest density of live objects 'to the right.'\n-      size_t space_to_left = sd.region(cp) * region_size;\n-      size_t live_to_left = space_to_left - cur_deadwood;\n-      size_t space_to_right = space_capacity - space_to_left;\n-      size_t live_to_right = space_live - live_to_left;\n-      double density_to_right = double(live_to_right) \/ space_to_right;\n-      while (cp > full_cp) {\n-        --cp;\n-        const size_t prev_region_live_to_right = live_to_right -\n-          cp->data_size();\n-        const size_t prev_region_space_to_right = space_to_right + region_size;\n-        double prev_region_density_to_right =\n-          double(prev_region_live_to_right) \/ prev_region_space_to_right;\n-        if (density_to_right <= prev_region_density_to_right) {\n-          return dense_prefix;\n-        }\n-\n-        log_develop_trace(gc, compaction)(\n-            \"backing up from c=\" SIZE_FORMAT_W(4) \" d2r=%10.8f \"\n-            \"pc_d2r=%10.8f\",\n-            sd.region(cp), density_to_right,\n-            prev_region_density_to_right);\n-\n-        dense_prefix -= region_size;\n-        live_to_right = prev_region_live_to_right;\n-        space_to_right = prev_region_space_to_right;\n-        density_to_right = prev_region_density_to_right;\n-      }\n-      return dense_prefix;\n+  \/\/ Iteration starts with the region *after* the full-region-prefix-end.\n+  const RegionData* const start_region = sd.addr_to_region_ptr(full_region_prefix_end);\n+  \/\/ If final region is not full, iteration stops before that region,\n+  \/\/ because fill_dense_prefix_end assumes that prefix_end <= top.\n+  const RegionData* const end_region = sd.addr_to_region_ptr(old_space->top());\n+  assert(start_region <= end_region, \"inv\");\n+\n+  size_t max_waste = old_space->capacity_in_words() * (MarkSweepDeadRatio \/ 100.0);\n+  const RegionData* cur_region = start_region;\n+  for (\/* empty *\/; cur_region < end_region; ++cur_region) {\n+    assert(region_size >= cur_region->data_size(), \"inv\");\n+    size_t dead_size = region_size - cur_region->data_size();\n+    if (max_waste < dead_size) {\n+      break;\n@@ -1145,3 +947,1 @@\n-\n-    dense_prefix += region_size;\n-    ++cp;\n+    max_waste -= dead_size;\n@@ -1150,1 +950,5 @@\n-  return dense_prefix;\n+  HeapWord* const prefix_end = sd.region_to_addr(cur_region);\n+  assert(sd.is_region_aligned(prefix_end), \"postcondition\");\n+  assert(prefix_end >= full_region_prefix_end, \"in-range\");\n+  assert(prefix_end <= old_space->top(), \"in-range\");\n+  return prefix_end;\n@@ -1153,76 +957,2 @@\n-#ifndef PRODUCT\n-void PSParallelCompact::print_dense_prefix_stats(const char* const algorithm,\n-                                                 const SpaceId id,\n-                                                 const bool maximum_compaction,\n-                                                 HeapWord* const addr)\n-{\n-  const size_t region_idx = summary_data().addr_to_region_idx(addr);\n-  RegionData* const cp = summary_data().region(region_idx);\n-  const MutableSpace* const space = _space_info[id].space();\n-  HeapWord* const new_top = _space_info[id].new_top();\n-\n-  const size_t space_live = pointer_delta(new_top, space->bottom());\n-  const size_t dead_to_left = pointer_delta(addr, cp->destination());\n-  const size_t space_cap = space->capacity_in_words();\n-  const double dead_to_left_pct = double(dead_to_left) \/ space_cap;\n-  const size_t live_to_right = new_top - cp->destination();\n-  const size_t dead_to_right = space->top() - addr - live_to_right;\n-\n-  log_develop_debug(gc, compaction)(\n-      \"%s=\" PTR_FORMAT \" dpc=\" SIZE_FORMAT_W(5) \" \"\n-      \"spl=\" SIZE_FORMAT \" \"\n-      \"d2l=\" SIZE_FORMAT \" d2l%%=%6.4f \"\n-      \"d2r=\" SIZE_FORMAT \" l2r=\" SIZE_FORMAT \" \"\n-      \"ratio=%10.8f\",\n-      algorithm, p2i(addr), region_idx,\n-      space_live,\n-      dead_to_left, dead_to_left_pct,\n-      dead_to_right, live_to_right,\n-      double(dead_to_right) \/ live_to_right);\n-}\n-#endif  \/\/ #ifndef PRODUCT\n-\n-\/\/ Return a fraction indicating how much of the generation can be treated as\n-\/\/ \"dead wood\" (i.e., not reclaimed).  The function uses a normal distribution\n-\/\/ based on the density of live objects in the generation to determine a limit,\n-\/\/ which is then adjusted so the return value is min_percent when the density is\n-\/\/ 1.\n-\/\/\n-\/\/ The following table shows some return values for a different values of the\n-\/\/ standard deviation (ParallelOldDeadWoodLimiterStdDev); the mean is 0.5 and\n-\/\/ min_percent is 1.\n-\/\/\n-\/\/                          fraction allowed as dead wood\n-\/\/         -----------------------------------------------------------------\n-\/\/ density std_dev=70 std_dev=75 std_dev=80 std_dev=85 std_dev=90 std_dev=95\n-\/\/ ------- ---------- ---------- ---------- ---------- ---------- ----------\n-\/\/ 0.00000 0.01000000 0.01000000 0.01000000 0.01000000 0.01000000 0.01000000\n-\/\/ 0.05000 0.03193096 0.02836880 0.02550828 0.02319280 0.02130337 0.01974941\n-\/\/ 0.10000 0.05247504 0.04547452 0.03988045 0.03537016 0.03170171 0.02869272\n-\/\/ 0.15000 0.07135702 0.06111390 0.05296419 0.04641639 0.04110601 0.03676066\n-\/\/ 0.20000 0.08831616 0.07509618 0.06461766 0.05622444 0.04943437 0.04388975\n-\/\/ 0.25000 0.10311208 0.08724696 0.07471205 0.06469760 0.05661313 0.05002313\n-\/\/ 0.30000 0.11553050 0.09741183 0.08313394 0.07175114 0.06257797 0.05511132\n-\/\/ 0.35000 0.12538832 0.10545958 0.08978741 0.07731366 0.06727491 0.05911289\n-\/\/ 0.40000 0.13253818 0.11128511 0.09459590 0.08132834 0.07066107 0.06199500\n-\/\/ 0.45000 0.13687208 0.11481163 0.09750361 0.08375387 0.07270534 0.06373386\n-\/\/ 0.50000 0.13832410 0.11599237 0.09847664 0.08456518 0.07338887 0.06431510\n-\/\/ 0.55000 0.13687208 0.11481163 0.09750361 0.08375387 0.07270534 0.06373386\n-\/\/ 0.60000 0.13253818 0.11128511 0.09459590 0.08132834 0.07066107 0.06199500\n-\/\/ 0.65000 0.12538832 0.10545958 0.08978741 0.07731366 0.06727491 0.05911289\n-\/\/ 0.70000 0.11553050 0.09741183 0.08313394 0.07175114 0.06257797 0.05511132\n-\/\/ 0.75000 0.10311208 0.08724696 0.07471205 0.06469760 0.05661313 0.05002313\n-\/\/ 0.80000 0.08831616 0.07509618 0.06461766 0.05622444 0.04943437 0.04388975\n-\/\/ 0.85000 0.07135702 0.06111390 0.05296419 0.04641639 0.04110601 0.03676066\n-\/\/ 0.90000 0.05247504 0.04547452 0.03988045 0.03537016 0.03170171 0.02869272\n-\/\/ 0.95000 0.03193096 0.02836880 0.02550828 0.02319280 0.02130337 0.01974941\n-\/\/ 1.00000 0.01000000 0.01000000 0.01000000 0.01000000 0.01000000 0.01000000\n-\n-double PSParallelCompact::dead_wood_limiter(double density, size_t min_percent)\n-{\n-  assert(_dwl_initialized, \"uninitialized\");\n-\n-  \/\/ The raw limit is the value of the normal distribution at x = density.\n-  const double raw_limit = normal_distribution(density);\n-\n-  \/\/ Adjust the raw limit so it becomes the minimum when the density is 1.\n+void PSParallelCompact::fill_dense_prefix_end(SpaceId id) {\n+  \/\/ Comparing two sizes to decide if filling is required:\n@@ -1230,147 +960,18 @@\n-  \/\/ First subtract the adjustment value (which is simply the precomputed value\n-  \/\/ normal_distribution(1.0)); this yields a value of 0 when the density is 1.\n-  \/\/ Then add the minimum value, so the minimum is returned when the density is\n-  \/\/ 1.  Finally, prevent negative values, which occur when the mean is not 0.5.\n-  const double min = double(min_percent) \/ 100.0;\n-  const double limit = raw_limit - _dwl_adjustment + min;\n-  return MAX2(limit, 0.0);\n-}\n-\n-ParallelCompactData::RegionData*\n-PSParallelCompact::first_dead_space_region(const RegionData* beg,\n-                                           const RegionData* end)\n-{\n-  const size_t region_size = ParallelCompactData::RegionSize;\n-  ParallelCompactData& sd = summary_data();\n-  size_t left = sd.region(beg);\n-  size_t right = end > beg ? sd.region(end) - 1 : left;\n-\n-  \/\/ Binary search.\n-  while (left < right) {\n-    \/\/ Equivalent to (left + right) \/ 2, but does not overflow.\n-    const size_t middle = left + (right - left) \/ 2;\n-    RegionData* const middle_ptr = sd.region(middle);\n-    HeapWord* const dest = middle_ptr->destination();\n-    HeapWord* const addr = sd.region_to_addr(middle);\n-    assert(dest != nullptr, \"sanity\");\n-    assert(dest <= addr, \"must move left\");\n-\n-    if (middle > left && dest < addr) {\n-      right = middle - 1;\n-    } else if (middle < right && middle_ptr->data_size() == region_size) {\n-      left = middle + 1;\n-    } else {\n-      return middle_ptr;\n-    }\n-  }\n-  return sd.region(left);\n-}\n-\n-ParallelCompactData::RegionData*\n-PSParallelCompact::dead_wood_limit_region(const RegionData* beg,\n-                                          const RegionData* end,\n-                                          size_t dead_words)\n-{\n-  ParallelCompactData& sd = summary_data();\n-  size_t left = sd.region(beg);\n-  size_t right = end > beg ? sd.region(end) - 1 : left;\n-\n-  \/\/ Binary search.\n-  while (left < right) {\n-    \/\/ Equivalent to (left + right) \/ 2, but does not overflow.\n-    const size_t middle = left + (right - left) \/ 2;\n-    RegionData* const middle_ptr = sd.region(middle);\n-    HeapWord* const dest = middle_ptr->destination();\n-    HeapWord* const addr = sd.region_to_addr(middle);\n-    assert(dest != nullptr, \"sanity\");\n-    assert(dest <= addr, \"must move left\");\n-\n-    const size_t dead_to_left = pointer_delta(addr, dest);\n-    if (middle > left && dead_to_left > dead_words) {\n-      right = middle - 1;\n-    } else if (middle < right && dead_to_left < dead_words) {\n-      left = middle + 1;\n-    } else {\n-      return middle_ptr;\n-    }\n-  }\n-  return sd.region(left);\n-}\n-\n-\/\/ The result is valid during the summary phase, after the initial summarization\n-\/\/ of each space into itself, and before final summarization.\n-inline double\n-PSParallelCompact::reclaimed_ratio(const RegionData* const cp,\n-                                   HeapWord* const bottom,\n-                                   HeapWord* const top,\n-                                   HeapWord* const new_top)\n-{\n-  ParallelCompactData& sd = summary_data();\n-\n-  assert(cp != nullptr, \"sanity\");\n-  assert(bottom != nullptr, \"sanity\");\n-  assert(top != nullptr, \"sanity\");\n-  assert(new_top != nullptr, \"sanity\");\n-  assert(top >= new_top, \"summary data problem?\");\n-  assert(new_top > bottom, \"space is empty; should not be here\");\n-  assert(new_top >= cp->destination(), \"sanity\");\n-  assert(top >= sd.region_to_addr(cp), \"sanity\");\n-\n-  HeapWord* const destination = cp->destination();\n-  const size_t dense_prefix_live  = pointer_delta(destination, bottom);\n-  const size_t compacted_region_live = pointer_delta(new_top, destination);\n-  const size_t compacted_region_used = pointer_delta(top,\n-                                                     sd.region_to_addr(cp));\n-  const size_t reclaimable = compacted_region_used - compacted_region_live;\n-\n-  const double divisor = dense_prefix_live + 1.25 * compacted_region_live;\n-  return double(reclaimable) \/ divisor;\n-}\n-\n-\/\/ Return the address of the end of the dense prefix, a.k.a. the start of the\n-\/\/ compacted region.  The address is always on a region boundary.\n-\/\/\n-\/\/ Completely full regions at the left are skipped, since no compaction can\n-\/\/ occur in those regions.  Then the maximum amount of dead wood to allow is\n-\/\/ computed, based on the density (amount live \/ capacity) of the generation;\n-\/\/ the region with approximately that amount of dead space to the left is\n-\/\/ identified as the limit region.  Regions between the last completely full\n-\/\/ region and the limit region are scanned and the one that has the best\n-\/\/ (maximum) reclaimed_ratio() is selected.\n-HeapWord*\n-PSParallelCompact::compute_dense_prefix(const SpaceId id,\n-                                        bool maximum_compaction)\n-{\n-  const size_t region_size = ParallelCompactData::RegionSize;\n-  const ParallelCompactData& sd = summary_data();\n-\n-  const MutableSpace* const space = _space_info[id].space();\n-  HeapWord* const top = space->top();\n-  HeapWord* const top_aligned_up = sd.region_align_up(top);\n-  HeapWord* const new_top = _space_info[id].new_top();\n-  HeapWord* const new_top_aligned_up = sd.region_align_up(new_top);\n-  HeapWord* const bottom = space->bottom();\n-  const RegionData* const beg_cp = sd.addr_to_region_ptr(bottom);\n-  const RegionData* const top_cp = sd.addr_to_region_ptr(top_aligned_up);\n-  const RegionData* const new_top_cp =\n-    sd.addr_to_region_ptr(new_top_aligned_up);\n-\n-  \/\/ Skip full regions at the beginning of the space--they are necessarily part\n-  \/\/ of the dense prefix.\n-  const RegionData* const full_cp = first_dead_space_region(beg_cp, new_top_cp);\n-  assert(full_cp->destination() == sd.region_to_addr(full_cp) ||\n-         space->is_empty(), \"no dead space allowed to the left\");\n-  assert(full_cp->data_size() < region_size || full_cp == new_top_cp - 1,\n-         \"region must have dead space\");\n-\n-  \/\/ The gc number is saved whenever a maximum compaction is done, and used to\n-  \/\/ determine when the maximum compaction interval has expired.  This avoids\n-  \/\/ successive max compactions for different reasons.\n-  const uint total_invocations = ParallelScavengeHeap::heap()->total_full_collections();\n-  assert(total_invocations >= _maximum_compaction_gc_num, \"sanity\");\n-  const size_t gcs_since_max = total_invocations - _maximum_compaction_gc_num;\n-  const bool interval_ended = gcs_since_max > HeapMaximumCompactionInterval ||\n-    total_invocations == HeapFirstMaximumCompactionCount;\n-  if (maximum_compaction || full_cp == top_cp || interval_ended) {\n-    _maximum_compaction_gc_num = total_invocations;\n-    return sd.region_to_addr(full_cp);\n+  \/\/ The size of the filler (min-obj-size) is 2 heap words with the default\n+  \/\/ MinObjAlignment, since both markword and klass take 1 heap word.\n+  \/\/\n+  \/\/ The size of the gap (if any) right before dense-prefix-end is\n+  \/\/ MinObjAlignment.\n+  \/\/\n+  \/\/ Need to fill in the gap only if it's smaller than min-obj-size, and the\n+  \/\/ filler obj will extend to next region.\n+\n+  \/\/ Note: If min-fill-size decreases to 1, this whole method becomes redundant.\n+  assert(CollectedHeap::min_fill_size() >= 2, \"inv\");\n+#ifndef _LP64\n+  \/\/ In 32-bit system, each heap word is 4 bytes, so MinObjAlignment == 2.\n+  \/\/ The gap is always equal to min-fill-size, so nothing to do.\n+  return;\n+#endif\n+  if (MinObjAlignment > 1) {\n+    return;\n@@ -1378,37 +979,7 @@\n-\n-  const size_t space_live = pointer_delta(new_top, bottom);\n-  const size_t space_used = space->used_in_words();\n-  const size_t space_capacity = space->capacity_in_words();\n-\n-  const double density = double(space_live) \/ double(space_capacity);\n-  const size_t min_percent_free = MarkSweepDeadRatio;\n-  const double limiter = dead_wood_limiter(density, min_percent_free);\n-  const size_t dead_wood_max = space_used - space_live;\n-  const size_t dead_wood_limit = MIN2(size_t(space_capacity * limiter),\n-                                      dead_wood_max);\n-\n-  log_develop_debug(gc, compaction)(\n-      \"space_live=\" SIZE_FORMAT \" space_used=\" SIZE_FORMAT \" \"\n-      \"space_cap=\" SIZE_FORMAT,\n-      space_live, space_used,\n-      space_capacity);\n-  log_develop_debug(gc, compaction)(\n-      \"dead_wood_limiter(%6.4f, \" SIZE_FORMAT \")=%6.4f \"\n-      \"dead_wood_max=\" SIZE_FORMAT \" dead_wood_limit=\" SIZE_FORMAT,\n-      density, min_percent_free, limiter,\n-      dead_wood_max, dead_wood_limit);\n-\n-  \/\/ Locate the region with the desired amount of dead space to the left.\n-  const RegionData* const limit_cp =\n-    dead_wood_limit_region(full_cp, top_cp, dead_wood_limit);\n-\n-  \/\/ Scan from the first region with dead space to the limit region and find the\n-  \/\/ one with the best (largest) reclaimed ratio.\n-  double best_ratio = 0.0;\n-  const RegionData* best_cp = full_cp;\n-  for (const RegionData* cp = full_cp; cp < limit_cp; ++cp) {\n-    double tmp_ratio = reclaimed_ratio(cp, bottom, top, new_top);\n-    if (tmp_ratio > best_ratio) {\n-      best_cp = cp;\n-      best_ratio = tmp_ratio;\n-    }\n+  assert(CollectedHeap::min_fill_size() == 2, \"inv\");\n+  HeapWord* const dense_prefix_end = dense_prefix(id);\n+  assert(_summary_data.is_region_aligned(dense_prefix_end), \"precondition\");\n+  assert(dense_prefix_end <= space(id)->top(), \"precondition\");\n+  if (dense_prefix_end == space(id)->top()) {\n+    \/\/ Must not have single-word gap right before prefix-end\/top.\n+    return;\n@@ -1416,0 +987,1 @@\n+  RegionData* const region_after_dense_prefix = _summary_data.addr_to_region_ptr(dense_prefix_end);\n@@ -1417,13 +989,4 @@\n-  return sd.region_to_addr(best_cp);\n-}\n-\n-void PSParallelCompact::summarize_spaces_quick()\n-{\n-  for (unsigned int i = 0; i < last_space_id; ++i) {\n-    const MutableSpace* space = _space_info[i].space();\n-    HeapWord** nta = _space_info[i].new_top_addr();\n-    bool result = _summary_data.summarize(_space_info[i].split_info(),\n-                                          space->bottom(), space->top(), nullptr,\n-                                          space->bottom(), space->end(), nta);\n-    assert(result, \"space must fit into itself\");\n-    _space_info[i].set_dense_prefix(space->bottom());\n+  if (region_after_dense_prefix->partial_obj_size() != 0 ||\n+      _mark_bitmap.is_marked(dense_prefix_end)) {\n+    \/\/ The region after the dense prefix starts with live bytes.\n+    return;\n@@ -1431,60 +994,7 @@\n-}\n-\n-void PSParallelCompact::fill_dense_prefix_end(SpaceId id)\n-{\n-  HeapWord* const dense_prefix_end = dense_prefix(id);\n-  const RegionData* region = _summary_data.addr_to_region_ptr(dense_prefix_end);\n-  const idx_t dense_prefix_bit = _mark_bitmap.addr_to_bit(dense_prefix_end);\n-  if (dead_space_crosses_boundary(region, dense_prefix_bit)) {\n-    \/\/ Only enough dead space is filled so that any remaining dead space to the\n-    \/\/ left is larger than the minimum filler object.  (The remainder is filled\n-    \/\/ during the copy\/update phase.)\n-    \/\/\n-    \/\/ The size of the dead space to the right of the boundary is not a\n-    \/\/ concern, since compaction will be able to use whatever space is\n-    \/\/ available.\n-    \/\/\n-    \/\/ Here '||' is the boundary, 'x' represents a don't care bit and a box\n-    \/\/ surrounds the space to be filled with an object.\n-    \/\/\n-    \/\/ In the 32-bit VM, each bit represents two 32-bit words:\n-    \/\/                              +---+\n-    \/\/ a) beg_bits:  ...  x   x   x | 0 | ||   0   x  x  ...\n-    \/\/    end_bits:  ...  x   x   x | 0 | ||   0   x  x  ...\n-    \/\/                              +---+\n-    \/\/\n-    \/\/ In the 64-bit VM, each bit represents one 64-bit word:\n-    \/\/                              +------------+\n-    \/\/ b) beg_bits:  ...  x   x   x | 0   ||   0 | x  x  ...\n-    \/\/    end_bits:  ...  x   x   1 | 0   ||   0 | x  x  ...\n-    \/\/                              +------------+\n-    \/\/                          +-------+\n-    \/\/ c) beg_bits:  ...  x   x | 0   0 | ||   0   x  x  ...\n-    \/\/    end_bits:  ...  x   1 | 0   0 | ||   0   x  x  ...\n-    \/\/                          +-------+\n-    \/\/                      +-----------+\n-    \/\/ d) beg_bits:  ...  x | 0   0   0 | ||   0   x  x  ...\n-    \/\/    end_bits:  ...  1 | 0   0   0 | ||   0   x  x  ...\n-    \/\/                      +-----------+\n-    \/\/                          +-------+\n-    \/\/ e) beg_bits:  ...  0   0 | 0   0 | ||   0   x  x  ...\n-    \/\/    end_bits:  ...  0   0 | 0   0 | ||   0   x  x  ...\n-    \/\/                          +-------+\n-\n-    \/\/ Initially assume case a, c or e will apply.\n-    size_t obj_len = CollectedHeap::min_fill_size();\n-    HeapWord* obj_beg = dense_prefix_end - obj_len;\n-\n-#ifdef  _LP64\n-    if (MinObjAlignment > 1) { \/\/ object alignment > heap word size\n-      \/\/ Cases a, c or e.\n-    } else if (_mark_bitmap.is_obj_end(dense_prefix_bit - 2)) {\n-      \/\/ Case b above.\n-      obj_beg = dense_prefix_end - 1;\n-    } else if (!_mark_bitmap.is_obj_end(dense_prefix_bit - 3) &&\n-               _mark_bitmap.is_obj_end(dense_prefix_bit - 4)) {\n-      \/\/ Case d above.\n-      obj_beg = dense_prefix_end - 3;\n-      obj_len = 3;\n-    }\n-#endif  \/\/ #ifdef _LP64\n+  HeapWord* block_start = start_array(id)->block_start_reaching_into_card(dense_prefix_end);\n+  if (block_start == dense_prefix_end - 1) {\n+    assert(!_mark_bitmap.is_marked(block_start), \"inv\");\n+    \/\/ There is exactly one heap word gap right before the dense prefix end, so we need a filler object.\n+    \/\/ The filler object will extend into region_after_dense_prefix.\n+    const size_t obj_len = 2; \/\/ min-fill-size\n+    HeapWord* const obj_beg = dense_prefix_end - 1;\n@@ -1493,2 +1003,4 @@\n-    _mark_bitmap.mark_obj(obj_beg, obj_len);\n-    _summary_data.add_obj(obj_beg, obj_len);\n+    _mark_bitmap.mark_obj(obj_beg);\n+    _summary_data.addr_to_region_ptr(obj_beg)->add_live_obj(1);\n+    region_after_dense_prefix->set_partial_obj_size(1);\n+    region_after_dense_prefix->set_partial_obj_addr(obj_beg);\n@@ -1496,60 +1008,1 @@\n-    start_array(id)->allocate_block(obj_beg);\n-  }\n-}\n-\n-void\n-PSParallelCompact::summarize_space(SpaceId id, bool maximum_compaction)\n-{\n-  assert(id < last_space_id, \"id out of range\");\n-  assert(_space_info[id].dense_prefix() == _space_info[id].space()->bottom(),\n-         \"should have been reset in summarize_spaces_quick()\");\n-\n-  const MutableSpace* space = _space_info[id].space();\n-  if (_space_info[id].new_top() != space->bottom()) {\n-    HeapWord* dense_prefix_end = compute_dense_prefix(id, maximum_compaction);\n-    _space_info[id].set_dense_prefix(dense_prefix_end);\n-\n-#ifndef PRODUCT\n-    if (log_is_enabled(Debug, gc, compaction)) {\n-      print_dense_prefix_stats(\"ratio\", id, maximum_compaction,\n-                               dense_prefix_end);\n-      HeapWord* addr = compute_dense_prefix_via_density(id, maximum_compaction);\n-      print_dense_prefix_stats(\"density\", id, maximum_compaction, addr);\n-    }\n-#endif  \/\/ #ifndef PRODUCT\n-\n-    \/\/ Recompute the summary data, taking into account the dense prefix.  If\n-    \/\/ every last byte will be reclaimed, then the existing summary data which\n-    \/\/ compacts everything can be left in place.\n-    if (!maximum_compaction && dense_prefix_end != space->bottom()) {\n-      \/\/ If dead space crosses the dense prefix boundary, it is (at least\n-      \/\/ partially) filled with a dummy object, marked live and added to the\n-      \/\/ summary data.  This simplifies the copy\/update phase and must be done\n-      \/\/ before the final locations of objects are determined, to prevent\n-      \/\/ leaving a fragment of dead space that is too small to fill.\n-      fill_dense_prefix_end(id);\n-\n-      \/\/ Compute the destination of each Region, and thus each object.\n-      _summary_data.summarize_dense_prefix(space->bottom(), dense_prefix_end);\n-      _summary_data.summarize(_space_info[id].split_info(),\n-                              dense_prefix_end, space->top(), nullptr,\n-                              dense_prefix_end, space->end(),\n-                              _space_info[id].new_top_addr());\n-    }\n-  }\n-\n-  if (log_develop_is_enabled(Trace, gc, compaction)) {\n-    const size_t region_size = ParallelCompactData::RegionSize;\n-    HeapWord* const dense_prefix_end = _space_info[id].dense_prefix();\n-    const size_t dp_region = _summary_data.addr_to_region_idx(dense_prefix_end);\n-    const size_t dp_words = pointer_delta(dense_prefix_end, space->bottom());\n-    HeapWord* const new_top = _space_info[id].new_top();\n-    const HeapWord* nt_aligned_up = _summary_data.region_align_up(new_top);\n-    const size_t cr_words = pointer_delta(nt_aligned_up, dense_prefix_end);\n-    log_develop_trace(gc, compaction)(\n-        \"id=%d cap=\" SIZE_FORMAT \" dp=\" PTR_FORMAT \" \"\n-        \"dp_region=\" SIZE_FORMAT \" \" \"dp_count=\" SIZE_FORMAT \" \"\n-        \"cr_count=\" SIZE_FORMAT \" \" \"nt=\" PTR_FORMAT,\n-        id, space->capacity_in_words(), p2i(dense_prefix_end),\n-        dp_region, dp_words \/ region_size,\n-        cr_words \/ region_size, p2i(new_top));\n+    start_array(id)->update_for_block(obj_beg, obj_beg + obj_len);\n@@ -1582,3 +1035,6 @@\n-void PSParallelCompact::summary_phase(bool maximum_compaction)\n-{\n-  GCTraceTime(Info, gc, phases) tm(\"Summary Phase\", &_gc_timer);\n+bool PSParallelCompact::reassess_maximum_compaction(bool maximum_compaction,\n+                                                    size_t total_live_words,\n+                                                    MutableSpace* const old_space,\n+                                                    HeapWord* full_region_prefix_end) {\n+  \/\/ Check if all live objs are larger than old-gen.\n+  const bool is_old_gen_overflowing = (total_live_words > old_space->capacity_in_words());\n@@ -1586,2 +1042,6 @@\n-  \/\/ Quick summarization of each space into itself, to see how much is live.\n-  summarize_spaces_quick();\n+  \/\/ JVM flags\n+  const uint total_invocations = ParallelScavengeHeap::heap()->total_full_collections();\n+  assert(total_invocations >= _maximum_compaction_gc_num, \"sanity\");\n+  const size_t gcs_since_max = total_invocations - _maximum_compaction_gc_num;\n+  const bool is_interval_ended = gcs_since_max > HeapMaximumCompactionInterval\n+                              || total_invocations == HeapFirstMaximumCompactionCount;\n@@ -1589,3 +1049,3 @@\n-  log_develop_trace(gc, compaction)(\"summary phase:  after summarizing each space to self\");\n-  NOT_PRODUCT(print_region_ranges());\n-  NOT_PRODUCT(print_initial_summary_data(_summary_data, _space_info));\n+  \/\/ If all regions in old-gen are full\n+  const bool is_region_full =\n+    full_region_prefix_end >= _summary_data.region_align_down(old_space->top());\n@@ -1593,5 +1053,3 @@\n-  \/\/ The amount of live data that will end up in old space (assuming it fits).\n-  size_t old_space_total_live = 0;\n-  for (unsigned int id = old_space_id; id < last_space_id; ++id) {\n-    old_space_total_live += pointer_delta(_space_info[id].new_top(),\n-                                          _space_info[id].space()->bottom());\n+  if (maximum_compaction || is_old_gen_overflowing || is_interval_ended || is_region_full) {\n+    _maximum_compaction_gc_num = total_invocations;\n+    return true;\n@@ -1600,0 +1058,7 @@\n+  return false;\n+}\n+\n+void PSParallelCompact::summary_phase(bool maximum_compaction)\n+{\n+  GCTraceTime(Info, gc, phases) tm(\"Summary Phase\", &_gc_timer);\n+\n@@ -1601,5 +1066,17 @@\n-  const size_t old_capacity = old_space->capacity_in_words();\n-  if (old_space_total_live > old_capacity) {\n-    \/\/ XXX - should also try to expand\n-    maximum_compaction = true;\n-  }\n+  {\n+    size_t total_live_words = 0;\n+    HeapWord* full_region_prefix_end = nullptr;\n+    {\n+      \/\/ old-gen\n+      size_t live_words = _summary_data.live_words_in_space(old_space,\n+                                                            &full_region_prefix_end);\n+      total_live_words += live_words;\n+    }\n+    \/\/ young-gen\n+    for (uint i = eden_space_id; i < last_space_id; ++i) {\n+      const MutableSpace* space = _space_info[i].space();\n+      size_t live_words = _summary_data.live_words_in_space(space);\n+      total_live_words += live_words;\n+      _space_info[i].set_new_top(space->bottom() + live_words);\n+      _space_info[i].set_dense_prefix(space->bottom());\n+    }\n@@ -1607,2 +1084,20 @@\n-  \/\/ Old generations.\n-  summarize_space(old_space_id, maximum_compaction);\n+    maximum_compaction = reassess_maximum_compaction(maximum_compaction,\n+                                                     total_live_words,\n+                                                     old_space,\n+                                                     full_region_prefix_end);\n+    HeapWord* dense_prefix_end =\n+      maximum_compaction ? full_region_prefix_end\n+                         : compute_dense_prefix_for_old_space(old_space,\n+                                                              full_region_prefix_end);\n+    SpaceId id = old_space_id;\n+    _space_info[id].set_dense_prefix(dense_prefix_end);\n+\n+    if (dense_prefix_end != old_space->bottom()) {\n+      fill_dense_prefix_end(id);\n+      _summary_data.summarize_dense_prefix(old_space->bottom(), dense_prefix_end);\n+    }\n+    _summary_data.summarize(_space_info[id].split_info(),\n+                            dense_prefix_end, old_space->top(), nullptr,\n+                            dense_prefix_end, old_space->end(),\n+                            _space_info[id].new_top_addr());\n+  }\n@@ -1688,1 +1183,1 @@\n-  assert(!heap->is_gc_active(), \"not reentrant\");\n+  assert(!heap->is_stw_gc_active(), \"not reentrant\");\n@@ -1690,5 +1185,1 @@\n-  IsGCActiveMark mark;\n-\n-  if (ScavengeBeforeFullGC) {\n-    PSScavenge::invoke_no_policy();\n-  }\n+  IsSTWGCActiveMark mark;\n@@ -1736,5 +1227,0 @@\n-  if (ZapUnusedHeapArea) {\n-    \/\/ Save information needed to minimize mangling\n-    heap->record_gen_tops_before_GC();\n-  }\n-\n@@ -1775,0 +1261,4 @@\n+    ClassUnloadingContext ctx(1 \/* num_nmethod_unlink_workers *\/,\n+                              false \/* unregister_nmethods_during_purge *\/,\n+                              false \/* lock_nmethod_free_separately *\/);\n+\n@@ -1786,3 +1276,3 @@\n-    \/\/ adjust_roots() updates Universe::_intArrayKlassObj which is\n-    \/\/ needed by the compaction for filling holes in the dense prefix.\n-    adjust_roots();\n+    forward_to_new_addr();\n+\n+    adjust_pointers();\n@@ -1792,0 +1282,2 @@\n+    ParCompactionManager::_preserved_marks_set->restore(&ParallelScavengeHeap::heap()->workers());\n+\n@@ -1901,10 +1393,0 @@\n-  \/\/ Re-verify object start arrays\n-  if (VerifyObjectStartArray &&\n-      VerifyAfterGC) {\n-    old_gen->verify_object_start_array();\n-  }\n-\n-  if (ZapUnusedHeapArea) {\n-    old_gen->object_space()->check_mangled_unused_area_complete();\n-  }\n-\n@@ -1931,1 +1413,1 @@\n-    assert(ParallelScavengeHeap::heap()->is_gc_active(), \"called outside gc\");\n+    assert(ParallelScavengeHeap::heap()->is_stw_gc_active(), \"called outside gc\");\n@@ -1938,1 +1420,1 @@\n-    MarkingCodeBlobClosure mark_and_push_in_blobs(&mark_and_push_closure, !CodeBlobToOopClosure::FixRelocations, true \/* keepalive nmethods *\/);\n+    MarkingNMethodClosure mark_and_push_in_blobs(&mark_and_push_closure, !NMethodToOopClosure::FixRelocations, true \/* keepalive nmethods *\/);\n@@ -1948,1 +1430,1 @@\n-  assert(ParallelScavengeHeap::heap()->is_gc_active(), \"called outside gc\");\n+  assert(ParallelScavengeHeap::heap()->is_stw_gc_active(), \"called outside gc\");\n@@ -1980,0 +1462,1 @@\n+    cm->create_marking_stats_cache();\n@@ -2028,0 +1511,7 @@\n+static void flush_marking_stats_cache(const uint num_workers) {\n+  for (uint i = 0; i < num_workers; ++i) {\n+    ParCompactionManager* cm = ParCompactionManager::gc_thread_compaction_manager(i);\n+    cm->flush_and_destroy_marking_stats_cache();\n+  }\n+}\n+\n@@ -2057,0 +1547,6 @@\n+  {\n+    GCTraceTime(Debug, gc, phases) tm(\"Flush Marking Stats\", &_gc_timer);\n+\n+    flush_marking_stats_cache(active_gc_threads);\n+  }\n+\n@@ -2070,3 +1566,8 @@\n-    CodeCache::UnloadingScope scope(is_alive_closure());\n-    \/\/ Follow system dictionary roots and unload classes.\n-    bool purged_class = SystemDictionary::do_unloading(&_gc_timer);\n+    ClassUnloadingContext* ctx = ClassUnloadingContext::context();\n+\n+    bool unloading_occurred;\n+    {\n+      CodeCache::UnlinkingScope scope(is_alive_closure());\n+\n+      \/\/ Follow system dictionary roots and unload classes.\n+      unloading_occurred = SystemDictionary::do_unloading(&_gc_timer);\n@@ -2075,2 +1576,17 @@\n-    \/\/ Unload nmethods.\n-    CodeCache::do_unloading(purged_class);\n+      \/\/ Unload nmethods.\n+      CodeCache::do_unloading(unloading_occurred);\n+    }\n+\n+    {\n+      GCTraceTime(Debug, gc, phases) t(\"Purge Unlinked NMethods\", gc_timer());\n+      \/\/ Release unloaded nmethod's memory.\n+      ctx->purge_nmethods();\n+    }\n+    {\n+      GCTraceTime(Debug, gc, phases) ur(\"Unregister NMethods\", &_gc_timer);\n+      ParallelScavengeHeap::heap()->prune_unlinked_nmethods();\n+    }\n+    {\n+      GCTraceTime(Debug, gc, phases) t(\"Free Code Blobs\", gc_timer());\n+      ctx->free_nmethods();\n+    }\n@@ -2079,1 +1595,1 @@\n-    Klass::clean_weak_klass_links(purged_class);\n+    Klass::clean_weak_klass_links(unloading_occurred);\n@@ -2082,1 +1598,1 @@\n-    JVMCI_ONLY(JVMCI::do_unloading(purged_class));\n+    JVMCI_ONLY(JVMCI::do_unloading(unloading_occurred));\n@@ -2095,0 +1611,78 @@\n+template<typename Func>\n+void PSParallelCompact::adjust_in_space_helper(SpaceId id, volatile uint* claim_counter, Func&& on_stripe) {\n+  MutableSpace* sp = PSParallelCompact::space(id);\n+  HeapWord* const bottom = sp->bottom();\n+  HeapWord* const top = sp->top();\n+  if (bottom == top) {\n+    return;\n+  }\n+\n+  const uint num_regions_per_stripe = 2;\n+  const size_t region_size = ParallelCompactData::RegionSize;\n+  const size_t stripe_size = num_regions_per_stripe * region_size;\n+\n+  while (true) {\n+    uint counter = Atomic::fetch_then_add(claim_counter, num_regions_per_stripe);\n+    HeapWord* cur_stripe = bottom + counter * region_size;\n+    if (cur_stripe >= top) {\n+      break;\n+    }\n+    HeapWord* stripe_end = MIN2(cur_stripe + stripe_size, top);\n+    on_stripe(cur_stripe, stripe_end);\n+  }\n+}\n+\n+void PSParallelCompact::adjust_in_old_space(volatile uint* claim_counter) {\n+  \/\/ Regions in old-space shouldn't be split.\n+  assert(!_space_info[old_space_id].split_info().is_valid(), \"inv\");\n+\n+  auto scan_obj_with_limit = [&] (HeapWord* obj_start, HeapWord* left, HeapWord* right) {\n+    assert(mark_bitmap()->is_marked(obj_start), \"inv\");\n+    oop obj = cast_to_oop(obj_start);\n+    return obj->oop_iterate_size(&pc_adjust_pointer_closure, MemRegion(left, right));\n+  };\n+\n+  adjust_in_space_helper(old_space_id, claim_counter, [&] (HeapWord* stripe_start, HeapWord* stripe_end) {\n+    assert(_summary_data.is_region_aligned(stripe_start), \"inv\");\n+    RegionData* cur_region = _summary_data.addr_to_region_ptr(stripe_start);\n+    HeapWord* obj_start;\n+    if (cur_region->partial_obj_size() != 0) {\n+      obj_start = cur_region->partial_obj_addr();\n+      obj_start += scan_obj_with_limit(obj_start, stripe_start, stripe_end);\n+    } else {\n+      obj_start = stripe_start;\n+    }\n+\n+    while (obj_start < stripe_end) {\n+      obj_start = mark_bitmap()->find_obj_beg(obj_start, stripe_end);\n+      if (obj_start >= stripe_end) {\n+        break;\n+      }\n+      obj_start += scan_obj_with_limit(obj_start, stripe_start, stripe_end);\n+    }\n+  });\n+}\n+\n+void PSParallelCompact::adjust_in_young_space(SpaceId id, volatile uint* claim_counter) {\n+  adjust_in_space_helper(id, claim_counter, [](HeapWord* stripe_start, HeapWord* stripe_end) {\n+    HeapWord* obj_start = stripe_start;\n+    while (obj_start < stripe_end) {\n+      obj_start = mark_bitmap()->find_obj_beg(obj_start, stripe_end);\n+      if (obj_start >= stripe_end) {\n+        break;\n+      }\n+      oop obj = cast_to_oop(obj_start);\n+      obj_start += obj->oop_iterate_size(&pc_adjust_pointer_closure);\n+    }\n+  });\n+}\n+\n+void PSParallelCompact::adjust_pointers_in_spaces(uint worker_id, volatile uint* claim_counters) {\n+  auto start_time = Ticks::now();\n+  adjust_in_old_space(&claim_counters[0]);\n+  for (uint id = eden_space_id; id < last_space_id; ++id) {\n+    adjust_in_young_space(SpaceId(id), &claim_counters[id]);\n+  }\n+  log_trace(gc, phases)(\"adjust_pointers_in_spaces worker %u: %.3f ms\", worker_id, (Ticks::now() - start_time).seconds() * 1000);\n+}\n+\n@@ -2100,0 +1694,1 @@\n+  volatile uint _claim_counters[PSParallelCompact::last_space_id] = {};\n@@ -2126,1 +1721,5 @@\n-    PCAdjustPointerClosure adjust(cm);\n+    cm->preserved_marks()->adjust_during_full_gc();\n+    {\n+      \/\/ adjust pointers in all spaces\n+      PSParallelCompact::adjust_pointers_in_spaces(worker_id, _claim_counters);\n+    }\n@@ -2129,1 +1728,1 @@\n-      Threads::possibly_parallel_oops_do(_nworkers > 1, &adjust, nullptr);\n+      Threads::possibly_parallel_oops_do(_nworkers > 1, &pc_adjust_pointer_closure, nullptr);\n@@ -2131,1 +1730,1 @@\n-    _oop_storage_iter.oops_do(&adjust);\n+    _oop_storage_iter.oops_do(&pc_adjust_pointer_closure);\n@@ -2133,1 +1732,1 @@\n-      CLDToOopClosure cld_closure(&adjust, ClassLoaderData::_claim_stw_fullgc_adjust);\n+      CLDToOopClosure cld_closure(&pc_adjust_pointer_closure, ClassLoaderData::_claim_stw_fullgc_adjust);\n@@ -2138,1 +1737,1 @@\n-      _weak_proc_task.work(worker_id, &always_alive, &adjust);\n+      _weak_proc_task.work(worker_id, &always_alive, &pc_adjust_pointer_closure);\n@@ -2141,2 +1740,2 @@\n-      CodeBlobToOopClosure adjust_code(&adjust, CodeBlobToOopClosure::FixRelocations);\n-      CodeCache::blobs_do(&adjust_code);\n+      NMethodToOopClosure adjust_code(&pc_adjust_pointer_closure, NMethodToOopClosure::FixRelocations);\n+      CodeCache::nmethods_do(&adjust_code);\n@@ -2148,1 +1747,1 @@\n-void PSParallelCompact::adjust_roots() {\n+void PSParallelCompact::adjust_pointers() {\n@@ -2150,1 +1749,1 @@\n-  GCTraceTime(Info, gc, phases) tm(\"Adjust Roots\", &_gc_timer);\n+  GCTraceTime(Info, gc, phases) tm(\"Adjust Pointers\", &_gc_timer);\n@@ -2156,0 +1755,125 @@\n+\/\/ Split [start, end) evenly for a number of workers and return the\n+\/\/ range for worker_id.\n+static void split_regions_for_worker(size_t start, size_t end,\n+                                     uint worker_id, uint num_workers,\n+                                     size_t* worker_start, size_t* worker_end) {\n+  assert(start < end, \"precondition\");\n+  assert(num_workers > 0, \"precondition\");\n+  assert(worker_id < num_workers, \"precondition\");\n+\n+  size_t num_regions = end - start;\n+  size_t num_regions_per_worker = num_regions \/ num_workers;\n+  size_t remainder = num_regions % num_workers;\n+  \/\/ The first few workers will get one extra.\n+  *worker_start = start + worker_id * num_regions_per_worker\n+                  + MIN2(checked_cast<size_t>(worker_id), remainder);\n+  *worker_end = *worker_start + num_regions_per_worker\n+                + (worker_id < remainder ? 1 : 0);\n+}\n+\n+void PSParallelCompact::forward_to_new_addr() {\n+  GCTraceTime(Info, gc, phases) tm(\"Forward\", &_gc_timer);\n+  uint nworkers = ParallelScavengeHeap::heap()->workers().active_workers();\n+\n+  struct ForwardTask final : public WorkerTask {\n+    uint _num_workers;\n+\n+    explicit ForwardTask(uint num_workers) :\n+      WorkerTask(\"PSForward task\"),\n+      _num_workers(num_workers) {}\n+\n+    void work(uint worker_id) override {\n+      ParCompactionManager* cm = ParCompactionManager::gc_thread_compaction_manager(worker_id);\n+      for (uint id = old_space_id; id < last_space_id; ++id) {\n+        MutableSpace* sp = PSParallelCompact::space(SpaceId(id));\n+        HeapWord* dense_prefix_addr = dense_prefix(SpaceId(id));\n+        HeapWord* top = sp->top();\n+\n+        if (dense_prefix_addr == top) {\n+          continue;\n+        }\n+\n+        size_t dense_prefix_region = _summary_data.addr_to_region_idx(dense_prefix_addr);\n+        size_t top_region = _summary_data.addr_to_region_idx(_summary_data.region_align_up(top));\n+        size_t start_region;\n+        size_t end_region;\n+        split_regions_for_worker(dense_prefix_region, top_region,\n+                                 worker_id, _num_workers,\n+                                 &start_region, &end_region);\n+        for (size_t cur_region = start_region; cur_region < end_region; ++cur_region) {\n+          RegionData* region_ptr = _summary_data.region(cur_region);\n+          size_t live_words = region_ptr->partial_obj_size();\n+\n+          if (live_words == ParallelCompactData::RegionSize) {\n+            \/\/ No obj-start\n+            continue;\n+          }\n+\n+          HeapWord* region_start = _summary_data.region_to_addr(cur_region);\n+          HeapWord* region_end = region_start + ParallelCompactData::RegionSize;\n+\n+          HeapWord* cur_addr = region_start + live_words;\n+\n+          HeapWord* destination = region_ptr->destination();\n+          while (cur_addr < region_end) {\n+            cur_addr = mark_bitmap()->find_obj_beg(cur_addr, region_end);\n+            if (cur_addr >= region_end) {\n+              break;\n+            }\n+            assert(mark_bitmap()->is_marked(cur_addr), \"inv\");\n+            HeapWord* new_addr = destination + live_words;\n+            oop obj = cast_to_oop(cur_addr);\n+            if (new_addr != cur_addr) {\n+              cm->preserved_marks()->push_if_necessary(obj, obj->mark());\n+              obj->forward_to(cast_to_oop(new_addr));\n+            }\n+            size_t obj_size = obj->size();\n+            live_words += obj_size;\n+            cur_addr += obj_size;\n+          }\n+        }\n+      }\n+    }\n+  } task(nworkers);\n+\n+  ParallelScavengeHeap::heap()->workers().run_task(&task);\n+  debug_only(verify_forward();)\n+}\n+\n+#ifdef ASSERT\n+void PSParallelCompact::verify_forward() {\n+  HeapWord* old_dense_prefix_addr = dense_prefix(SpaceId(old_space_id));\n+  RegionData* old_region = _summary_data.region(_summary_data.addr_to_region_idx(old_dense_prefix_addr));\n+  HeapWord* bump_ptr = old_region->partial_obj_size() != 0\n+                       ? old_dense_prefix_addr + old_region->partial_obj_size()\n+                       : old_dense_prefix_addr;\n+  SpaceId bump_ptr_space = old_space_id;\n+\n+  for (uint id = old_space_id; id < last_space_id; ++id) {\n+    MutableSpace* sp = PSParallelCompact::space(SpaceId(id));\n+    HeapWord* dense_prefix_addr = dense_prefix(SpaceId(id));\n+    HeapWord* top = sp->top();\n+    HeapWord* cur_addr = dense_prefix_addr;\n+\n+    while (cur_addr < top) {\n+      cur_addr = mark_bitmap()->find_obj_beg(cur_addr, top);\n+      if (cur_addr >= top) {\n+        break;\n+      }\n+      assert(mark_bitmap()->is_marked(cur_addr), \"inv\");\n+      \/\/ Move to the space containing cur_addr\n+      if (bump_ptr == _space_info[bump_ptr_space].new_top()) {\n+        bump_ptr = space(space_id(cur_addr))->bottom();\n+        bump_ptr_space = space_id(bump_ptr);\n+      }\n+      oop obj = cast_to_oop(cur_addr);\n+      if (cur_addr != bump_ptr) {\n+        assert(obj->forwardee() == cast_to_oop(bump_ptr), \"inv\");\n+      }\n+      bump_ptr += obj->size();\n+      cur_addr += obj->size();\n+    }\n+  }\n+}\n+#endif\n+\n@@ -2236,155 +1960,1 @@\n-class TaskQueue : StackObj {\n-  volatile uint _counter;\n-  uint _size;\n-  uint _insert_index;\n-  PSParallelCompact::UpdateDensePrefixTask* _backing_array;\n-public:\n-  explicit TaskQueue(uint size) : _counter(0), _size(size), _insert_index(0), _backing_array(nullptr) {\n-    _backing_array = NEW_C_HEAP_ARRAY(PSParallelCompact::UpdateDensePrefixTask, _size, mtGC);\n-  }\n-  ~TaskQueue() {\n-    assert(_counter >= _insert_index, \"not all queue elements were claimed\");\n-    FREE_C_HEAP_ARRAY(T, _backing_array);\n-  }\n-\n-  void push(const PSParallelCompact::UpdateDensePrefixTask& value) {\n-    assert(_insert_index < _size, \"too small backing array\");\n-    _backing_array[_insert_index++] = value;\n-  }\n-\n-  bool try_claim(PSParallelCompact::UpdateDensePrefixTask& reference) {\n-    uint claimed = Atomic::fetch_then_add(&_counter, 1u);\n-    if (claimed < _insert_index) {\n-      reference = _backing_array[claimed];\n-      return true;\n-    } else {\n-      return false;\n-    }\n-  }\n-};\n-\n-#define PAR_OLD_DENSE_PREFIX_OVER_PARTITIONING 4\n-\n-void PSParallelCompact::enqueue_dense_prefix_tasks(TaskQueue& task_queue,\n-                                                   uint parallel_gc_threads) {\n-  GCTraceTime(Trace, gc, phases) tm(\"Dense Prefix Task Setup\", &_gc_timer);\n-\n-  ParallelCompactData& sd = PSParallelCompact::summary_data();\n-\n-  \/\/ Iterate over all the spaces adding tasks for updating\n-  \/\/ regions in the dense prefix.  Assume that 1 gc thread\n-  \/\/ will work on opening the gaps and the remaining gc threads\n-  \/\/ will work on the dense prefix.\n-  unsigned int space_id;\n-  for (space_id = old_space_id; space_id < last_space_id; ++ space_id) {\n-    HeapWord* const dense_prefix_end = _space_info[space_id].dense_prefix();\n-    const MutableSpace* const space = _space_info[space_id].space();\n-\n-    if (dense_prefix_end == space->bottom()) {\n-      \/\/ There is no dense prefix for this space.\n-      continue;\n-    }\n-\n-    \/\/ The dense prefix is before this region.\n-    size_t region_index_end_dense_prefix =\n-        sd.addr_to_region_idx(dense_prefix_end);\n-    RegionData* const dense_prefix_cp =\n-      sd.region(region_index_end_dense_prefix);\n-    assert(dense_prefix_end == space->end() ||\n-           dense_prefix_cp->available() ||\n-           dense_prefix_cp->claimed(),\n-           \"The region after the dense prefix should always be ready to fill\");\n-\n-    size_t region_index_start = sd.addr_to_region_idx(space->bottom());\n-\n-    \/\/ Is there dense prefix work?\n-    size_t total_dense_prefix_regions =\n-      region_index_end_dense_prefix - region_index_start;\n-    \/\/ How many regions of the dense prefix should be given to\n-    \/\/ each thread?\n-    if (total_dense_prefix_regions > 0) {\n-      uint tasks_for_dense_prefix = 1;\n-      if (total_dense_prefix_regions <=\n-          (parallel_gc_threads * PAR_OLD_DENSE_PREFIX_OVER_PARTITIONING)) {\n-        \/\/ Don't over partition.  This assumes that\n-        \/\/ PAR_OLD_DENSE_PREFIX_OVER_PARTITIONING is a small integer value\n-        \/\/ so there are not many regions to process.\n-        tasks_for_dense_prefix = parallel_gc_threads;\n-      } else {\n-        \/\/ Over partition\n-        tasks_for_dense_prefix = parallel_gc_threads *\n-          PAR_OLD_DENSE_PREFIX_OVER_PARTITIONING;\n-      }\n-      size_t regions_per_thread = total_dense_prefix_regions \/\n-        tasks_for_dense_prefix;\n-      \/\/ Give each thread at least 1 region.\n-      if (regions_per_thread == 0) {\n-        regions_per_thread = 1;\n-      }\n-\n-      for (uint k = 0; k < tasks_for_dense_prefix; k++) {\n-        if (region_index_start >= region_index_end_dense_prefix) {\n-          break;\n-        }\n-        \/\/ region_index_end is not processed\n-        size_t region_index_end = MIN2(region_index_start + regions_per_thread,\n-                                       region_index_end_dense_prefix);\n-        task_queue.push(UpdateDensePrefixTask(SpaceId(space_id),\n-                                              region_index_start,\n-                                              region_index_end));\n-        region_index_start = region_index_end;\n-      }\n-    }\n-    \/\/ This gets any part of the dense prefix that did not\n-    \/\/ fit evenly.\n-    if (region_index_start < region_index_end_dense_prefix) {\n-      task_queue.push(UpdateDensePrefixTask(SpaceId(space_id),\n-                                            region_index_start,\n-                                            region_index_end_dense_prefix));\n-    }\n-  }\n-}\n-\n-#ifdef ASSERT\n-\/\/ Write a histogram of the number of times the block table was filled for a\n-\/\/ region.\n-void PSParallelCompact::write_block_fill_histogram()\n-{\n-  if (!log_develop_is_enabled(Trace, gc, compaction)) {\n-    return;\n-  }\n-\n-  Log(gc, compaction) log;\n-  ResourceMark rm;\n-  LogStream ls(log.trace());\n-  outputStream* out = &ls;\n-\n-  typedef ParallelCompactData::RegionData rd_t;\n-  ParallelCompactData& sd = summary_data();\n-\n-  for (unsigned int id = old_space_id; id < last_space_id; ++id) {\n-    MutableSpace* const spc = _space_info[id].space();\n-    if (spc->bottom() != spc->top()) {\n-      const rd_t* const beg = sd.addr_to_region_ptr(spc->bottom());\n-      HeapWord* const top_aligned_up = sd.region_align_up(spc->top());\n-      const rd_t* const end = sd.addr_to_region_ptr(top_aligned_up);\n-\n-      size_t histo[5] = { 0, 0, 0, 0, 0 };\n-      const size_t histo_len = sizeof(histo) \/ sizeof(size_t);\n-      const size_t region_cnt = pointer_delta(end, beg, sizeof(rd_t));\n-\n-      for (const rd_t* cur = beg; cur < end; ++cur) {\n-        ++histo[MIN2(cur->blocks_filled_count(), histo_len - 1)];\n-      }\n-      out->print(\"Block fill histogram: %u %-4s\" SIZE_FORMAT_W(5), id, space_names[id], region_cnt);\n-      for (size_t i = 0; i < histo_len; ++i) {\n-        out->print(\" \" SIZE_FORMAT_W(5) \" %5.1f%%\",\n-                   histo[i], 100.0 * histo[i] \/ region_cnt);\n-      }\n-      out->cr();\n-    }\n-  }\n-}\n-#endif \/\/ #ifdef ASSERT\n-\n-  assert(ParallelScavengeHeap::heap()->is_gc_active(), \"called outside gc\");\n+  assert(ParallelScavengeHeap::heap()->is_stw_gc_active(), \"called outside gc\");\n@@ -2422,2 +1992,2 @@\n-class UpdateDensePrefixAndCompactionTask: public WorkerTask {\n-  TaskQueue& _tq;\n+class FillDensePrefixAndCompactionTask: public WorkerTask {\n+  uint _num_workers;\n@@ -2427,3 +1997,3 @@\n-  UpdateDensePrefixAndCompactionTask(TaskQueue& tq, uint active_workers) :\n-      WorkerTask(\"UpdateDensePrefixAndCompactionTask\"),\n-      _tq(tq),\n+  FillDensePrefixAndCompactionTask(uint active_workers) :\n+      WorkerTask(\"FillDensePrefixAndCompactionTask\"),\n+      _num_workers(active_workers),\n@@ -2432,0 +2002,1 @@\n+\n@@ -2433,1 +2004,8 @@\n-    ParCompactionManager* cm = ParCompactionManager::gc_thread_compaction_manager(worker_id);\n+    {\n+      auto start = Ticks::now();\n+      PSParallelCompact::fill_dead_objs_in_dense_prefix(worker_id, _num_workers);\n+      log_trace(gc, phases)(\"Fill dense prefix by worker %u: %.3f ms\", worker_id, (Ticks::now() - start).seconds() * 1000);\n+    }\n+    compaction_with_stealing_work(&_terminator, worker_id);\n+  }\n+};\n@@ -2435,5 +2013,10 @@\n-    for (PSParallelCompact::UpdateDensePrefixTask task; _tq.try_claim(task); \/* empty *\/) {\n-      PSParallelCompact::update_and_deadwood_in_dense_prefix(cm,\n-                                                             task._space_id,\n-                                                             task._region_index_start,\n-                                                             task._region_index_end);\n+void PSParallelCompact::fill_range_in_dense_prefix(HeapWord* start, HeapWord* end) {\n+#ifdef ASSERT\n+  {\n+    assert(start < end, \"precondition\");\n+    assert(mark_bitmap()->find_obj_beg(start, end) == end, \"precondition\");\n+    HeapWord* bottom = _space_info[old_space_id].space()->bottom();\n+    if (start != bottom) {\n+      HeapWord* obj_start = mark_bitmap()->find_obj_beg_reverse(bottom, start);\n+      HeapWord* after_obj = obj_start + cast_to_oop(obj_start)->size();\n+      assert(after_obj == start, \"precondition\");\n@@ -2441,0 +2024,2 @@\n+  }\n+#endif\n@@ -2442,3 +2027,14 @@\n-    \/\/ Once a thread has drained it's stack, it should try to steal regions from\n-    \/\/ other threads.\n-    compaction_with_stealing_work(&_terminator, worker_id);\n+  CollectedHeap::fill_with_objects(start, pointer_delta(end, start));\n+  HeapWord* addr = start;\n+  do {\n+    size_t size = cast_to_oop(addr)->size();\n+    start_array(old_space_id)->update_for_block(addr, addr + size);\n+    addr += size;\n+  } while (addr < end);\n+}\n+\n+void PSParallelCompact::fill_dead_objs_in_dense_prefix(uint worker_id, uint num_workers) {\n+  ParMarkBitMap* bitmap = mark_bitmap();\n+\n+  HeapWord* const bottom = _space_info[old_space_id].space()->bottom();\n+  HeapWord* const prefix_end = dense_prefix(old_space_id);\n@@ -2446,3 +2042,2 @@\n-    \/\/ At this point all regions have been compacted, so it's now safe\n-    \/\/ to update the deferred objects that cross region boundaries.\n-    cm->drain_deferred_objects();\n+  if (bottom == prefix_end) {\n+    return;\n@@ -2450,1 +2045,45 @@\n-};\n+\n+  size_t bottom_region = _summary_data.addr_to_region_idx(bottom);\n+  size_t prefix_end_region = _summary_data.addr_to_region_idx(prefix_end);\n+\n+  size_t start_region;\n+  size_t end_region;\n+  split_regions_for_worker(bottom_region, prefix_end_region,\n+                           worker_id, num_workers,\n+                           &start_region, &end_region);\n+\n+  if (start_region == end_region) {\n+    return;\n+  }\n+\n+  HeapWord* const start_addr = _summary_data.region_to_addr(start_region);\n+  HeapWord* const end_addr = _summary_data.region_to_addr(end_region);\n+\n+  \/\/ Skip live partial obj (if any) from previous region.\n+  HeapWord* cur_addr;\n+  RegionData* start_region_ptr = _summary_data.region(start_region);\n+  if (start_region_ptr->partial_obj_size() != 0) {\n+    HeapWord* partial_obj_start = start_region_ptr->partial_obj_addr();\n+    assert(bitmap->is_marked(partial_obj_start), \"inv\");\n+    cur_addr = partial_obj_start + cast_to_oop(partial_obj_start)->size();\n+  } else {\n+    cur_addr = start_addr;\n+  }\n+\n+  \/\/ end_addr is inclusive to handle regions starting with dead space.\n+  while (cur_addr <= end_addr) {\n+    \/\/ Use prefix_end to handle trailing obj in each worker region-chunk.\n+    HeapWord* live_start = bitmap->find_obj_beg(cur_addr, prefix_end);\n+    if (cur_addr != live_start) {\n+      \/\/ Only worker 0 handles proceeding dead space.\n+      if (cur_addr != start_addr || worker_id == 0) {\n+        fill_range_in_dense_prefix(cur_addr, live_start);\n+      }\n+    }\n+    if (live_start >= end_addr) {\n+      break;\n+    }\n+    assert(bitmap->is_marked(live_start), \"inv\");\n+    cur_addr = live_start + cast_to_oop(live_start)->size();\n+  }\n+}\n@@ -2455,3 +2094,0 @@\n-  ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();\n-  PSOldGen* old_gen = heap->old_gen();\n-  old_gen->start_array()->reset();\n@@ -2460,7 +2096,0 @@\n-  \/\/ for [0..last_space_id)\n-  \/\/     for [0..active_gc_threads * PAR_OLD_DENSE_PREFIX_OVER_PARTITIONING)\n-  \/\/         push\n-  \/\/     push\n-  \/\/\n-  \/\/ max push count is thus: last_space_id * (active_gc_threads * PAR_OLD_DENSE_PREFIX_OVER_PARTITIONING + 1)\n-  TaskQueue task_queue(last_space_id * (active_gc_threads * PAR_OLD_DENSE_PREFIX_OVER_PARTITIONING + 1));\n@@ -2469,1 +2098,0 @@\n-  enqueue_dense_prefix_tasks(task_queue, active_gc_threads);\n@@ -2474,1 +2102,1 @@\n-    UpdateDensePrefixAndCompactionTask task(task_queue, active_gc_threads);\n+    FillDensePrefixAndCompactionTask task(active_gc_threads);\n@@ -2478,0 +2106,2 @@\n+    verify_filler_in_dense_prefix();\n+\n@@ -2484,2 +2114,0 @@\n-\n-  DEBUG_ONLY(write_block_fill_histogram());\n@@ -2489,0 +2117,15 @@\n+void PSParallelCompact::verify_filler_in_dense_prefix() {\n+  HeapWord* bottom = _space_info[old_space_id].space()->bottom();\n+  HeapWord* dense_prefix_end = dense_prefix(old_space_id);\n+  HeapWord* cur_addr = bottom;\n+  while (cur_addr < dense_prefix_end) {\n+    oop obj = cast_to_oop(cur_addr);\n+    oopDesc::verify(obj);\n+    if (!mark_bitmap()->is_marked(cur_addr)) {\n+      Klass* k = cast_to_oop(cur_addr)->klass_without_asserts();\n+      assert(k == Universe::fillerArrayKlass() || k == vmClasses::FillerObject_klass(), \"inv\");\n+    }\n+    cur_addr += obj->size();\n+  }\n+}\n+\n@@ -2490,3 +2133,3 @@\n-  \/\/ All Regions between space bottom() to new_top() should be marked as filled\n-  \/\/ and all Regions between new_top() and top() should be available (i.e.,\n-  \/\/ should have been emptied).\n+  \/\/ All Regions served as compaction targets, from dense_prefix() to\n+  \/\/ new_top(), should be marked as filled and all Regions between new_top()\n+  \/\/ and top() should be available (i.e., should have been emptied).\n@@ -2497,1 +2140,1 @@\n-  const size_t beg_region = sd.addr_to_region_idx(si.space()->bottom());\n+  const size_t beg_region = sd.addr_to_region_idx(si.dense_prefix());\n@@ -2528,67 +2171,0 @@\n-inline void UpdateOnlyClosure::do_addr(HeapWord* addr) {\n-  _start_array->allocate_block(addr);\n-  compaction_manager()->update_contents(cast_to_oop(addr));\n-}\n-\n-\/\/ Update interior oops in the ranges of regions [beg_region, end_region).\n-void\n-PSParallelCompact::update_and_deadwood_in_dense_prefix(ParCompactionManager* cm,\n-                                                       SpaceId space_id,\n-                                                       size_t beg_region,\n-                                                       size_t end_region) {\n-  ParallelCompactData& sd = summary_data();\n-  ParMarkBitMap* const mbm = mark_bitmap();\n-\n-  HeapWord* beg_addr = sd.region_to_addr(beg_region);\n-  HeapWord* const end_addr = sd.region_to_addr(end_region);\n-  assert(beg_region <= end_region, \"bad region range\");\n-  assert(end_addr <= dense_prefix(space_id), \"not in the dense prefix\");\n-\n-#ifdef  ASSERT\n-  \/\/ Claim the regions to avoid triggering an assert when they are marked as\n-  \/\/ filled.\n-  for (size_t claim_region = beg_region; claim_region < end_region; ++claim_region) {\n-    assert(sd.region(claim_region)->claim_unsafe(), \"claim() failed\");\n-  }\n-#endif  \/\/ #ifdef ASSERT\n-\n-  if (beg_addr != space(space_id)->bottom()) {\n-    \/\/ Find the first live object or block of dead space that *starts* in this\n-    \/\/ range of regions.  If a partial object crosses onto the region, skip it;\n-    \/\/ it will be marked for 'deferred update' when the object head is\n-    \/\/ processed.  If dead space crosses onto the region, it is also skipped; it\n-    \/\/ will be filled when the prior region is processed.  If neither of those\n-    \/\/ apply, the first word in the region is the start of a live object or dead\n-    \/\/ space.\n-    assert(beg_addr > space(space_id)->bottom(), \"sanity\");\n-    const RegionData* const cp = sd.region(beg_region);\n-    if (cp->partial_obj_size() != 0) {\n-      beg_addr = sd.partial_obj_end(beg_region);\n-    } else if (dead_space_crosses_boundary(cp, mbm->addr_to_bit(beg_addr))) {\n-      beg_addr = mbm->find_obj_beg(beg_addr, end_addr);\n-    }\n-  }\n-\n-  if (beg_addr < end_addr) {\n-    \/\/ A live object or block of dead space starts in this range of Regions.\n-     HeapWord* const dense_prefix_end = dense_prefix(space_id);\n-\n-    \/\/ Create closures and iterate.\n-    UpdateOnlyClosure update_closure(mbm, cm, space_id);\n-    FillClosure fill_closure(cm, space_id);\n-    ParMarkBitMap::IterationStatus status;\n-    status = mbm->iterate(&update_closure, &fill_closure, beg_addr, end_addr,\n-                          dense_prefix_end);\n-    if (status == ParMarkBitMap::incomplete) {\n-      update_closure.do_addr(update_closure.source());\n-    }\n-  }\n-\n-  \/\/ Mark the regions as filled.\n-  RegionData* const beg_cp = sd.region(beg_region);\n-  RegionData* const end_cp = sd.region(end_region);\n-  for (RegionData* cp = beg_cp; cp < end_cp; ++cp) {\n-    cp->set_completed();\n-  }\n-}\n-\n@@ -2611,18 +2187,0 @@\n-void PSParallelCompact::update_deferred_object(ParCompactionManager* cm, HeapWord *addr) {\n-#ifdef ASSERT\n-  ParallelCompactData& sd = summary_data();\n-  size_t region_idx = sd.addr_to_region_idx(addr);\n-  assert(sd.region(region_idx)->completed(), \"first region must be completed before deferred updates\");\n-  assert(sd.region(region_idx + 1)->completed(), \"second region must be completed before deferred updates\");\n-#endif\n-\n-  const SpaceInfo* const space_info = _space_info + space_id(addr);\n-  ObjectStartArray* const start_array = space_info->start_array();\n-  if (start_array != nullptr) {\n-    start_array->allocate_block(addr);\n-  }\n-\n-  cm->update_contents(cast_to_oop(addr));\n-  assert(oopDesc::is_oop(cast_to_oop(addr)), \"Expected an oop at \" PTR_FORMAT, p2i(cast_to_oop(addr)));\n-}\n-\n@@ -2640,10 +2198,8 @@\n-  idx_t bits_to_skip = m->words_to_bits(count);\n-  idx_t cur_beg = m->addr_to_bit(beg);\n-  const idx_t search_end = m->align_range_end(m->addr_to_bit(end));\n-\n-  do {\n-    cur_beg = m->find_obj_beg(cur_beg, search_end);\n-    idx_t cur_end = m->find_obj_end(cur_beg, search_end);\n-    const size_t obj_bits = cur_end - cur_beg + 1;\n-    if (obj_bits > bits_to_skip) {\n-      return m->bit_to_addr(cur_beg + bits_to_skip);\n+  HeapWord* cur_addr = beg;\n+  while (true) {\n+    cur_addr = m->find_obj_beg(cur_addr, end);\n+    assert(cur_addr < end, \"inv\");\n+    size_t obj_size = cast_to_oop(cur_addr)->size();\n+    \/\/ Strictly greater-than\n+    if (obj_size > count) {\n+      return cur_addr + count;\n@@ -2651,9 +2207,3 @@\n-    bits_to_skip -= obj_bits;\n-    cur_beg = cur_end + 1;\n-  } while (bits_to_skip > 0);\n-\n-  \/\/ Skipping the desired number of words landed just past the end of an object.\n-  \/\/ Find the start of the next object.\n-  cur_beg = m->find_obj_beg(cur_beg, search_end);\n-  assert(cur_beg < m->addr_to_bit(end), \"not enough live words to skip\");\n-  return m->bit_to_addr(cur_beg);\n+    count -= obj_size;\n+    cur_addr += obj_size;\n+  }\n@@ -2843,0 +2393,23 @@\n+HeapWord* PSParallelCompact::partial_obj_end(HeapWord* region_start_addr) {\n+  ParallelCompactData& sd = summary_data();\n+  assert(sd.is_region_aligned(region_start_addr), \"precondition\");\n+\n+  \/\/ Use per-region partial_obj_size to locate the end of the obj, that extends to region_start_addr.\n+  SplitInfo& split_info = _space_info[space_id(region_start_addr)].split_info();\n+  size_t start_region_idx = sd.addr_to_region_idx(region_start_addr);\n+  size_t end_region_idx = sd.region_count();\n+  size_t accumulated_size = 0;\n+  for (size_t region_idx = start_region_idx; region_idx < end_region_idx; ++region_idx) {\n+    if (split_info.is_split(region_idx)) {\n+      accumulated_size += split_info.partial_obj_size();\n+      break;\n+    }\n+    size_t cur_partial_obj_size = sd.region(region_idx)->partial_obj_size();\n+    accumulated_size += cur_partial_obj_size;\n+    if (cur_partial_obj_size != ParallelCompactData::RegionSize) {\n+      break;\n+    }\n+  }\n+  return region_start_addr + accumulated_size;\n+}\n+\n@@ -2845,1 +2418,0 @@\n-  typedef ParMarkBitMap::IterationStatus IterationStatus;\n@@ -2869,1 +2441,24 @@\n-    closure.copy_partial_obj();\n+    {\n+      HeapWord* region_start = sd.region_align_down(closure.source());\n+      HeapWord* obj_start = bitmap->find_obj_beg_reverse(region_start, closure.source());\n+      HeapWord* obj_end;\n+      if (bitmap->is_marked(obj_start)) {\n+        HeapWord* next_region_start = region_start + ParallelCompactData::RegionSize;\n+        HeapWord* partial_obj_start = (next_region_start >= src_space_top)\n+                                      ? nullptr\n+                                      : sd.addr_to_region_ptr(next_region_start)->partial_obj_addr();\n+        if (partial_obj_start == obj_start) {\n+          \/\/ This obj extends to next region.\n+          obj_end = partial_obj_end(next_region_start);\n+        } else {\n+          \/\/ Completely contained in this region; safe to use size().\n+          obj_end = obj_start + cast_to_oop(obj_start)->size();\n+        }\n+      } else {\n+        \/\/ This obj extends to current region.\n+        obj_end = partial_obj_end(region_start);\n+      }\n+      size_t partial_obj_size = pointer_delta(obj_end, closure.source());\n+      closure.copy_partial_obj(partial_obj_size);\n+    }\n+\n@@ -2890,1 +2485,1 @@\n-    HeapWord* const cur_addr = closure.source();\n+    HeapWord* cur_addr = closure.source();\n@@ -2893,14 +2488,12 @@\n-    IterationStatus status = bitmap->iterate(&closure, cur_addr, end_addr);\n-\n-    if (status == ParMarkBitMap::incomplete) {\n-      \/\/ The last obj that starts in the source region does not end in the\n-      \/\/ region.\n-      assert(closure.source() < end_addr, \"sanity\");\n-      HeapWord* const obj_beg = closure.source();\n-      HeapWord* const range_end = MIN2(obj_beg + closure.words_remaining(),\n-                                       src_space_top);\n-      HeapWord* const obj_end = bitmap->find_obj_end(obj_beg, range_end);\n-      if (obj_end < range_end) {\n-        \/\/ The end was found; the entire object will fit.\n-        status = closure.do_addr(obj_beg, bitmap->obj_size(obj_beg, obj_end));\n-        assert(status != ParMarkBitMap::would_overflow, \"sanity\");\n+    HeapWord* partial_obj_start = (end_addr == src_space_top)\n+                                ? nullptr\n+                                : sd.addr_to_region_ptr(end_addr)->partial_obj_addr();\n+    \/\/ apply closure on objs inside [cur_addr, end_addr)\n+    do {\n+      cur_addr = bitmap->find_obj_beg(cur_addr, end_addr);\n+      if (cur_addr == end_addr) {\n+        break;\n+      }\n+      size_t obj_size;\n+      if (partial_obj_start == cur_addr) {\n+        obj_size = pointer_delta(partial_obj_end(end_addr), cur_addr);\n@@ -2908,3 +2501,2 @@\n-        \/\/ The end was not found; the object will not fit.\n-        assert(range_end < src_space_top, \"obj cannot cross space boundary\");\n-        status = ParMarkBitMap::would_overflow;\n+        \/\/ This obj doesn't extend into next region; size() is safe to use.\n+        obj_size = cast_to_oop(cur_addr)->size();\n@@ -2912,7 +2504,3 @@\n-    }\n-\n-    if (status == ParMarkBitMap::would_overflow) {\n-      \/\/ The last object did not fit.  Note that interior oop updates were\n-      \/\/ deferred, then copy enough of the object to fill the region.\n-      cm->push_deferred_object(closure.destination());\n-      status = closure.copy_until_full(); \/\/ copies from closure.source()\n+      closure.do_addr(cur_addr, obj_size);\n+      cur_addr += obj_size;\n+    } while (cur_addr < end_addr && !closure.is_full());\n@@ -2920,7 +2508,1 @@\n-      decrement_destination_counts(cm, src_space_id, src_region_idx,\n-                                   closure.source());\n-      closure.complete_region(cm, dest_addr, region_ptr);\n-      return;\n-    }\n-\n-    if (status == ParMarkBitMap::full) {\n+    if (closure.is_full()) {\n@@ -2944,1 +2526,1 @@\n-  MoveAndUpdateClosure cl(mark_bitmap(), cm, region_idx);\n+  MoveAndUpdateClosure cl(mark_bitmap(), region_idx);\n@@ -2958,1 +2540,1 @@\n-    MoveAndUpdateClosure cl(mark_bitmap(), cm, region_idx);\n+    MoveAndUpdateClosure cl(mark_bitmap(), region_idx);\n@@ -3026,1 +2608,1 @@\n-void PSParallelCompact::fill_blocks(size_t region_idx)\n+void MoveAndUpdateClosure::copy_partial_obj(size_t partial_obj_size)\n@@ -3028,69 +2610,1 @@\n-  \/\/ Fill in the block table elements for the specified region.  Each block\n-  \/\/ table element holds the number of live words in the region that are to the\n-  \/\/ left of the first object that starts in the block.  Thus only blocks in\n-  \/\/ which an object starts need to be filled.\n-  \/\/\n-  \/\/ The algorithm scans the section of the bitmap that corresponds to the\n-  \/\/ region, keeping a running total of the live words.  When an object start is\n-  \/\/ found, if it's the first to start in the block that contains it, the\n-  \/\/ current total is written to the block table element.\n-  const size_t Log2BlockSize = ParallelCompactData::Log2BlockSize;\n-  const size_t Log2RegionSize = ParallelCompactData::Log2RegionSize;\n-  const size_t RegionSize = ParallelCompactData::RegionSize;\n-\n-  ParallelCompactData& sd = summary_data();\n-  const size_t partial_obj_size = sd.region(region_idx)->partial_obj_size();\n-  if (partial_obj_size >= RegionSize) {\n-    return; \/\/ No objects start in this region.\n-  }\n-\n-  \/\/ Ensure the first loop iteration decides that the block has changed.\n-  size_t cur_block = sd.block_count();\n-\n-  const ParMarkBitMap* const bitmap = mark_bitmap();\n-\n-  const size_t Log2BitsPerBlock = Log2BlockSize - LogMinObjAlignment;\n-  assert((size_t)1 << Log2BitsPerBlock ==\n-         bitmap->words_to_bits(ParallelCompactData::BlockSize), \"sanity\");\n-\n-  size_t beg_bit = bitmap->words_to_bits(region_idx << Log2RegionSize);\n-  const size_t range_end = beg_bit + bitmap->words_to_bits(RegionSize);\n-  size_t live_bits = bitmap->words_to_bits(partial_obj_size);\n-  beg_bit = bitmap->find_obj_beg(beg_bit + live_bits, range_end);\n-  while (beg_bit < range_end) {\n-    const size_t new_block = beg_bit >> Log2BitsPerBlock;\n-    if (new_block != cur_block) {\n-      cur_block = new_block;\n-      sd.block(cur_block)->set_offset(bitmap->bits_to_words(live_bits));\n-    }\n-\n-    const size_t end_bit = bitmap->find_obj_end(beg_bit, range_end);\n-    if (end_bit < range_end - 1) {\n-      live_bits += end_bit - beg_bit + 1;\n-      beg_bit = bitmap->find_obj_beg(end_bit + 1, range_end);\n-    } else {\n-      return;\n-    }\n-  }\n-}\n-\n-ParMarkBitMap::IterationStatus MoveAndUpdateClosure::copy_until_full()\n-{\n-  if (source() != copy_destination()) {\n-    DEBUG_ONLY(PSParallelCompact::check_new_location(source(), destination());)\n-    Copy::aligned_conjoint_words(source(), copy_destination(), words_remaining());\n-  }\n-  update_state(words_remaining());\n-  assert(is_full(), \"sanity\");\n-  return ParMarkBitMap::full;\n-}\n-\n-void MoveAndUpdateClosure::copy_partial_obj()\n-{\n-  size_t words = words_remaining();\n-\n-  HeapWord* const range_end = MIN2(source() + words, bitmap()->region_end());\n-  HeapWord* const end_addr = bitmap()->find_obj_end(source(), range_end);\n-  if (end_addr < range_end) {\n-    words = bitmap()->obj_size(source(), end_addr);\n-  }\n+  size_t words = MIN2(partial_obj_size, words_remaining());\n@@ -3113,2 +2627,1 @@\n-ParMarkBitMapClosure::IterationStatus\n-MoveAndUpdateClosure::do_addr(HeapWord* addr, size_t words) {\n+void MoveAndUpdateClosure::do_addr(HeapWord* addr, size_t words) {\n@@ -3116,8 +2629,0 @@\n-  assert(bitmap()->obj_size(addr) == words, \"bad size\");\n-\n-  assert(PSParallelCompact::summary_data().calc_new_pointer(source(), compaction_manager()) ==\n-         destination(), \"wrong destination\");\n-\n-  if (words > words_remaining()) {\n-    return ParMarkBitMap::would_overflow;\n-  }\n@@ -3128,1 +2633,1 @@\n-    _start_array->allocate_block(destination());\n+    _start_array->update_for_block(destination(), destination() + words);\n@@ -3131,0 +2636,4 @@\n+  \/\/ Avoid overflow\n+  words = MIN2(words, words_remaining());\n+  assert(words > 0, \"inv\");\n+\n@@ -3133,0 +2642,3 @@\n+    assert(source() != destination(), \"inv\");\n+    assert(cast_to_oop(source())->is_forwarded(), \"inv\");\n+    assert(cast_to_oop(source())->forwardee() == cast_to_oop(destination()), \"inv\");\n@@ -3134,0 +2646,1 @@\n+    cast_to_oop(copy_destination())->init_mark();\n@@ -3136,6 +2649,0 @@\n-  oop moved_oop = cast_to_oop(copy_destination());\n-  compaction_manager()->update_contents(moved_oop);\n-  assert(oopDesc::is_oop_or_null(moved_oop), \"Expected an oop or null at \" PTR_FORMAT, p2i(moved_oop));\n-\n-  assert(copy_destination() == cast_from_oop<HeapWord*>(moved_oop) + moved_oop->size(), \"sanity\");\n-  return is_full() ? ParMarkBitMap::full : ParMarkBitMap::incomplete;\n@@ -3164,34 +2671,0 @@\n-UpdateOnlyClosure::UpdateOnlyClosure(ParMarkBitMap* mbm,\n-                                     ParCompactionManager* cm,\n-                                     PSParallelCompact::SpaceId space_id) :\n-  ParMarkBitMapClosure(mbm, cm),\n-  _space_id(space_id),\n-  _start_array(PSParallelCompact::start_array(space_id))\n-{\n-}\n-\n-\/\/ Updates the references in the object to their new values.\n-ParMarkBitMapClosure::IterationStatus\n-UpdateOnlyClosure::do_addr(HeapWord* addr, size_t words) {\n-  do_addr(addr);\n-  return ParMarkBitMap::incomplete;\n-}\n-\n-FillClosure::FillClosure(ParCompactionManager* cm, PSParallelCompact::SpaceId space_id) :\n-  ParMarkBitMapClosure(PSParallelCompact::mark_bitmap(), cm),\n-  _start_array(PSParallelCompact::start_array(space_id))\n-{\n-  assert(space_id == PSParallelCompact::old_space_id,\n-         \"cannot use FillClosure in the young gen\");\n-}\n-\n-ParMarkBitMapClosure::IterationStatus\n-FillClosure::do_addr(HeapWord* addr, size_t size) {\n-  CollectedHeap::fill_with_objects(addr, size);\n-  HeapWord* const end = addr + size;\n-  do {\n-    _start_array->allocate_block(addr);\n-    addr += cast_to_oop(addr)->size();\n-  } while (addr < end);\n-  return ParMarkBitMap::incomplete;\n-}\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":689,"deletions":1216,"binary":false,"changes":1905,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,0 @@\n-#include \"gc\/serial\/defNewGeneration.inline.hpp\"\n@@ -44,1 +43,0 @@\n-#include \"gc\/shared\/generationSpec.hpp\"\n@@ -48,2 +46,2 @@\n-#include \"gc\/shared\/space.inline.hpp\"\n-#include \"gc\/shared\/spaceDecorator.inline.hpp\"\n+#include \"gc\/shared\/space.hpp\"\n+#include \"gc\/shared\/spaceDecorator.hpp\"\n@@ -66,85 +64,0 @@\n-class ScavengeHelper {\n-  DefNewGeneration* _young_gen;\n-  HeapWord*         _young_gen_end;\n-public:\n-  ScavengeHelper(DefNewGeneration* young_gen) :\n-    _young_gen(young_gen),\n-    _young_gen_end(young_gen->reserved().end()) {}\n-\n-  bool is_in_young_gen(void* p) const {\n-    return p < _young_gen_end;\n-  }\n-\n-  template <typename T, typename Func>\n-  void try_scavenge(T* p, Func&& f) {\n-    T heap_oop = RawAccess<>::oop_load(p);\n-    \/\/ Should we copy the obj?\n-    if (!CompressedOops::is_null(heap_oop)) {\n-      oop obj = CompressedOops::decode_not_null(heap_oop);\n-      if (is_in_young_gen(obj)) {\n-        assert(!_young_gen->to()->is_in_reserved(obj), \"Scanning field twice?\");\n-        oop new_obj = obj->is_forwarded() ? obj->forwardee()\n-                                          : _young_gen->copy_to_survivor_space(obj);\n-        RawAccess<IS_NOT_NULL>::oop_store(p, new_obj);\n-\n-        \/\/ callback\n-        f(new_obj);\n-      }\n-    }\n-  }\n-};\n-\n-class InHeapScanClosure : public BasicOopIterateClosure {\n-  ScavengeHelper _helper;\n-protected:\n-  bool is_in_young_gen(void* p) const {\n-    return _helper.is_in_young_gen(p);\n-  }\n-\n-  template <typename T, typename Func>\n-  void try_scavenge(T* p, Func&& f) {\n-    _helper.try_scavenge(p, f);\n-  }\n-\n-  InHeapScanClosure(DefNewGeneration* young_gen) :\n-    BasicOopIterateClosure(young_gen->ref_processor()),\n-    _helper(young_gen) {}\n-};\n-\n-class OffHeapScanClosure : public OopClosure {\n-  ScavengeHelper _helper;\n-protected:\n-  bool is_in_young_gen(void* p) const {\n-    return _helper.is_in_young_gen(p);\n-  }\n-\n-  template <typename T, typename Func>\n-  void try_scavenge(T* p, Func&& f) {\n-    _helper.try_scavenge(p, f);\n-  }\n-\n-  OffHeapScanClosure(DefNewGeneration* young_gen) :  _helper(young_gen) {}\n-};\n-\n-class OldGenScanClosure : public InHeapScanClosure {\n-  CardTableRS* _rs;\n-\n-  template <typename T>\n-  void do_oop_work(T* p) {\n-    assert(!is_in_young_gen(p), \"precondition\");\n-\n-    try_scavenge(p, [&] (oop new_obj) {\n-      \/\/ If p points to a younger generation, mark the card.\n-      if (is_in_young_gen(new_obj)) {\n-        _rs->inline_write_ref_field_gc(p);\n-      }\n-    });\n-  }\n-public:\n-  OldGenScanClosure(DefNewGeneration* g) : InHeapScanClosure(g),\n-    _rs(SerialHeap::heap()->rem_set()) {}\n-\n-  void do_oop(oop* p)       { do_oop_work(p); }\n-  void do_oop(narrowOop* p) { do_oop_work(p); }\n-};\n-\n@@ -166,14 +79,0 @@\n-class YoungGenScanClosure : public InHeapScanClosure {\n-  template <typename T>\n-  void do_oop_work(T* p) {\n-    assert(SerialHeap::heap()->young_gen()->to()->is_in_reserved(p), \"precondition\");\n-\n-    try_scavenge(p, [] (auto) {});\n-  }\n-public:\n-  YoungGenScanClosure(DefNewGeneration* g) : InHeapScanClosure(g) {}\n-\n-  void do_oop(oop* p)       { do_oop_work(p); }\n-  void do_oop(narrowOop* p) { do_oop_work(p); }\n-};\n-\n@@ -321,4 +220,1 @@\n-    do {\n-      _heap->oop_since_save_marks_iterate(_young_cl, _old_cl);\n-    } while (!_heap->no_allocs_since_save_marks());\n-    guarantee(_heap->young_gen()->promo_failure_scan_is_complete(), \"Failed to finish scan\");\n+    _heap->scan_evacuated_objs(_young_cl, _old_cl);\n@@ -334,0 +230,1 @@\n+    _promotion_failed(false),\n@@ -341,1 +238,1 @@\n-  GenCollectedHeap* gch = GenCollectedHeap::heap();\n+  SerialHeap* gch = SerialHeap::heap();\n@@ -425,3 +322,3 @@\n-  assert(Space::is_aligned(eden_start), \"checking alignment\");\n-  assert(Space::is_aligned(from_start), \"checking alignment\");\n-  assert(Space::is_aligned(to_start),   \"checking alignment\");\n+  assert(is_aligned(eden_start, SpaceAlignment), \"checking alignment\");\n+  assert(is_aligned(from_start, SpaceAlignment), \"checking alignment\");\n+  assert(is_aligned(to_start, SpaceAlignment),   \"checking alignment\");\n@@ -438,15 +335,0 @@\n-  \/\/ If not clearing the spaces, do some checking to verify that\n-  \/\/ the space are already mangled.\n-  if (!clear_space) {\n-    \/\/ Must check mangling before the spaces are reshaped.  Otherwise,\n-    \/\/ the bottom or end of one space may have moved into another\n-    \/\/ a failure of the check may not correctly indicate which space\n-    \/\/ is not properly mangled.\n-    if (ZapUnusedHeapArea) {\n-      HeapWord* limit = (HeapWord*) _virtual_space.high();\n-      eden()->check_mangled_unused_area(limit);\n-      from()->check_mangled_unused_area(limit);\n-        to()->check_mangled_unused_area(limit);\n-    }\n-  }\n-\n@@ -466,7 +348,0 @@\n-\n-  \/\/ Set next compaction spaces.\n-  eden()->set_next_compaction_space(from());\n-  \/\/ The to-space is normally empty before a compaction so need\n-  \/\/ not be considered.  The exception is during promotion\n-  \/\/ failure handling when to-space can contain live objects.\n-  from()->set_next_compaction_space(nullptr);\n@@ -479,5 +354,0 @@\n-  eden()->set_next_compaction_space(from());\n-  \/\/ The to-space is normally empty before a compaction so need\n-  \/\/ not be considered.  The exception is during promotion\n-  \/\/ failure handling when to-space can contain live objects.\n-  from()->set_next_compaction_space(nullptr);\n@@ -566,1 +436,1 @@\n-  GenCollectedHeap* gch = GenCollectedHeap::heap();\n+  SerialHeap* gch = SerialHeap::heap();\n@@ -570,1 +440,1 @@\n-  size_t min_new_size = initial_size();\n+  size_t min_new_size = NewSize;\n@@ -660,0 +530,6 @@\n+bool DefNewGeneration::is_in(const void* p) const {\n+  return eden()->is_in(p)\n+      || from()->is_in(p)\n+      || to()  ->is_in(p);\n+}\n+\n@@ -678,0 +554,22 @@\n+\/\/ If \"p\" is in the space, returns the address of the start of the\n+\/\/ \"block\" that contains \"p\".  We say \"block\" instead of \"object\" since\n+\/\/ some heaps may not pack objects densely; a chunk may either be an\n+\/\/ object or a non-object.  If \"p\" is not in the space, return null.\n+\/\/ Very general, slow implementation.\n+static HeapWord* block_start_const(const ContiguousSpace* cs, const void* p) {\n+  assert(MemRegion(cs->bottom(), cs->end()).contains(p),\n+         \"p (\" PTR_FORMAT \") not in space [\" PTR_FORMAT \", \" PTR_FORMAT \")\",\n+         p2i(p), p2i(cs->bottom()), p2i(cs->end()));\n+  if (p >= cs->top()) {\n+    return cs->top();\n+  } else {\n+    HeapWord* last = cs->bottom();\n+    HeapWord* cur = last;\n+    while (cur <= p) {\n+      last = cur;\n+      cur += cast_to_oop(cur)->size();\n+    }\n+    assert(oopDesc::is_oop(cast_to_oop(last)), PTR_FORMAT \" should be an object start\", p2i(last));\n+    return last;\n+  }\n+}\n@@ -679,5 +577,9 @@\n-void DefNewGeneration::space_iterate(SpaceClosure* blk,\n-                                     bool usedOnly) {\n-  blk->do_space(eden());\n-  blk->do_space(from());\n-  blk->do_space(to());\n+HeapWord* DefNewGeneration::block_start(const void* p) const {\n+  if (eden()->is_in_reserved(p)) {\n+    return block_start_const(eden(), p);\n+  }\n+  if (from()->is_in_reserved(p)) {\n+    return block_start_const(from(), p);\n+  }\n+  assert(to()->is_in_reserved(p), \"inv\");\n+  return block_start_const(to(), p);\n@@ -702,1 +604,1 @@\n-                        GenCollectedHeap::heap()->incremental_collection_will_fail(false \/* don't consult_young *\/) ?\n+                        SerialHeap::heap()->incremental_collection_will_fail(false \/* don't consult_young *\/) ?\n@@ -726,1 +628,1 @@\n-    GCPolicyCounters* gc_counters = GenCollectedHeap::heap()->counters();\n+    GCPolicyCounters* gc_counters = SerialHeap::heap()->counters();\n@@ -731,1 +633,1 @@\n-  age_table()->print_age_table(_tenuring_threshold);\n+  age_table()->print_age_table();\n@@ -734,6 +636,1 @@\n-void DefNewGeneration::collect(bool   full,\n-                               bool   clear_all_soft_refs,\n-                               size_t size,\n-                               bool   is_tlab) {\n-  assert(full || size > 0, \"otherwise we don't want to collect\");\n-\n+bool DefNewGeneration::collect(bool clear_all_soft_refs) {\n@@ -742,8 +639,0 @@\n-  \/\/ If the next generation is too full to accommodate promotion\n-  \/\/ from this generation, pass on collection; let the next generation\n-  \/\/ do it.\n-  if (!collection_attempt_is_safe()) {\n-    log_trace(gc)(\":: Collection attempt not safe ::\");\n-    heap->set_incremental_collection_failed(); \/\/ Slight lie: we did not even attempt one\n-    return;\n-  }\n@@ -771,3 +660,0 @@\n-  assert(heap->no_allocs_since_save_marks(),\n-         \"save marks have not been newly set.\");\n-\n@@ -781,3 +667,0 @@\n-  assert(heap->no_allocs_since_save_marks(),\n-         \"save marks have not been newly set.\");\n-\n@@ -787,1 +670,5 @@\n-    CLDScanClosure cld_scan_closure{this};\n+    CLDScanClosure cld_cl{this};\n+\n+    MarkingNMethodClosure code_cl(&root_cl,\n+                                  NMethodToOopClosure::FixRelocations,\n+                                  false \/* keepalive_nmethods *\/);\n@@ -789,3 +676,8 @@\n-    heap->young_process_roots(&root_cl,\n-                              &old_gen_cl,\n-                              &cld_scan_closure);\n+    HeapWord* saved_top_in_old_gen = _old_gen->space()->top();\n+    heap->process_roots(SerialHeap::SO_ScavengeCodeCache,\n+                        &root_cl,\n+                        &cld_cl,\n+                        &cld_cl,\n+                        &code_cl);\n+\n+    _old_gen->scan_old_to_young_refs(saved_top_in_old_gen);\n@@ -808,1 +700,0 @@\n-  assert(heap->no_allocs_since_save_marks(), \"save marks have not been newly set.\");\n@@ -815,3 +706,0 @@\n-  \/\/ Verify that the usage of keep_alive didn't copy any objects.\n-  assert(heap->no_allocs_since_save_marks(), \"save marks have not been newly set.\");\n-\n@@ -824,10 +712,0 @@\n-    if (ZapUnusedHeapArea) {\n-      \/\/ This is now done here because of the piece-meal mangling which\n-      \/\/ can check for valid mangling at intermediate points in the\n-      \/\/ collection(s).  When a young collection fails to collect\n-      \/\/ sufficient space resizing of the young generation can occur\n-      \/\/ an redistribute the spaces in the young generation.  Mangle\n-      \/\/ here so that unzapped regions don't get distributed to\n-      \/\/ other spaces.\n-      to()->mangle_unused_area();\n-    }\n@@ -853,1 +731,0 @@\n-    from()->set_next_compaction_space(to());\n@@ -856,2 +733,0 @@\n-    \/\/ Inform the next generation that a promotion failure occurred.\n-    _old_gen->promotion_failure_occurred();\n@@ -871,0 +746,2 @@\n+\n+  return !_promotion_failed;\n@@ -876,1 +753,0 @@\n-  from()->set_next_compaction_space(nullptr);\n@@ -943,0 +819,3 @@\n+\n+    ContinuationGCSupport::transform_stack_chunk(obj);\n+\n@@ -978,13 +857,0 @@\n-void DefNewGeneration::save_marks() {\n-  eden()->set_saved_mark();\n-  to()->set_saved_mark();\n-  from()->set_saved_mark();\n-}\n-\n-\n-bool DefNewGeneration::no_allocs_since_save_marks() {\n-  assert(eden()->saved_mark_at_top(), \"Violated spec - alloc in eden\");\n-  assert(from()->saved_mark_at_top(), \"Violated spec - alloc in from\");\n-  return to()->saved_mark_at_top();\n-}\n-\n@@ -1011,1 +877,1 @@\n-    to()->mangle_unused_area_complete();\n+    to()->mangle_unused_area();\n@@ -1021,2 +887,1 @@\n-    GenCollectedHeap* gch = GenCollectedHeap::heap();\n-    _old_gen = gch->old_gen();\n+    _old_gen = SerialHeap::heap()->old_gen();\n@@ -1035,1 +900,1 @@\n-  GenCollectedHeap* gch = GenCollectedHeap::heap();\n+  SerialHeap* gch = SerialHeap::heap();\n@@ -1070,6 +935,0 @@\n-  if (ZapUnusedHeapArea) {\n-    eden()->check_mangled_unused_area_complete();\n-    from()->check_mangled_unused_area_complete();\n-    to()->check_mangled_unused_area_complete();\n-  }\n-\n@@ -1081,7 +940,0 @@\n-void DefNewGeneration::record_spaces_top() {\n-  assert(ZapUnusedHeapArea, \"Not mangling unused space\");\n-  eden()->set_top_for_allocations();\n-  to()->set_top_for_allocations();\n-  from()->set_top_for_allocations();\n-}\n-\n@@ -1118,5 +970,0 @@\n-\/\/ Moved from inline file as they are not called inline\n-ContiguousSpace* DefNewGeneration::first_compaction_space() const {\n-  return eden();\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/serial\/defNewGeneration.cpp","additions":73,"deletions":226,"binary":false,"changes":299,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,0 +26,1 @@\n+#include \"cds\/cdsConfig.hpp\"\n@@ -231,1 +232,1 @@\n-  if (!Metaspace::contains(object->klass_raw())) {\n+  if (!Metaspace::contains(object->klass_without_asserts())) {\n@@ -244,1 +245,2 @@\n-  _is_gc_active(false),\n+  _soft_ref_policy(),\n+  _is_stw_gc_active(false),\n@@ -404,0 +406,7 @@\n+\/\/ Returns the header size in words aligned to the requirements of the\n+\/\/ array object type.\n+static int int_array_header_size() {\n+  size_t typesize_in_bytes = arrayOopDesc::header_size_in_bytes();\n+  return (int)align_up(typesize_in_bytes, HeapWordSize)\/HeapWordSize;\n+}\n+\n@@ -413,1 +422,1 @@\n-  size_t max_int_size = typeArrayOopDesc::header_size(T_INT) +\n+  size_t max_int_size = int_array_header_size() +\n@@ -420,1 +429,1 @@\n-  return align_object_offset(arrayOopDesc::header_size(T_INT)); \/\/ align to Long\n+  return align_object_offset(int_array_header_size()); \/\/ align to Long\n@@ -457,1 +466,1 @@\n-  ObjArrayAllocator allocator(Universe::fillerArrayKlassObj(), words, (int)len, \/* do_zero *\/ false);\n+  ObjArrayAllocator allocator(Universe::fillerArrayKlass(), words, (int)len, \/* do_zero *\/ false);\n@@ -459,1 +468,1 @@\n-  if (DumpSharedSpaces) {\n+  if (CDSConfig::is_dumping_heap()) {\n@@ -513,7 +522,0 @@\n-HeapWord* CollectedHeap::allocate_new_tlab(size_t min_size,\n-                                           size_t requested_size,\n-                                           size_t* actual_size) {\n-  guarantee(false, \"thread-local allocation buffers not supported\");\n-  return nullptr;\n-}\n-\n@@ -561,0 +563,1 @@\n+  static uint count = 0;\n@@ -562,2 +565,5 @@\n-    GCTraceTime(Info, gc) tm(before ? \"Heap Dump (before full gc)\" : \"Heap Dump (after full gc)\", timer);\n-    HeapDumper::dump_heap();\n+    if (FullGCHeapDumpLimit == 0 || count < FullGCHeapDumpLimit) {\n+      GCTraceTime(Info, gc) tm(before ? \"Heap Dump (before full gc)\" : \"Heap Dump (after full gc)\", timer);\n+      HeapDumper::dump_heap();\n+      count++;\n+    }\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.cpp","additions":22,"deletions":16,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,1 @@\n+#include \"gc\/shared\/softRefPolicy.hpp\"\n@@ -48,3 +49,0 @@\n-class WorkerTask;\n-class AdaptiveSizePolicy;\n-class BarrierSet;\n@@ -59,1 +57,0 @@\n-class SoftRefPolicy;\n@@ -87,2 +84,1 @@\n-\/\/   GenCollectedHeap\n-\/\/     SerialHeap\n+\/\/   SerialHeap\n@@ -97,2 +93,1 @@\n-  friend class IsGCActiveMark; \/\/ Block structured external access to _is_gc_active\n-  friend class DisableIsGCActiveMark; \/\/ Disable current IsGCActiveMark\n+  friend class IsSTWGCActiveMark; \/\/ Block structured external access to _is_stw_gc_active\n@@ -100,1 +95,0 @@\n-  friend class ParallelObjectIterator;\n@@ -109,0 +103,2 @@\n+  SoftRefPolicy _soft_ref_policy;\n+\n@@ -117,1 +113,1 @@\n-  bool _is_gc_active;\n+  bool _is_stw_gc_active;\n@@ -156,1 +152,1 @@\n-                                      size_t* actual_size);\n+                                      size_t* actual_size) = 0;\n@@ -170,1 +166,3 @@\n-  static inline size_t filler_array_min_size();\n+  static size_t filler_array_min_size();\n+\n+protected:\n@@ -333,1 +331,1 @@\n-  \/\/ that of GenCollectedHeap::ensure_parsability().\n+  \/\/ that of ParallelScavengeHeap::ensure_parsability().\n@@ -350,9 +348,1 @@\n-  virtual size_t unsafe_max_tlab_alloc(Thread *thr) const {\n-    guarantee(false, \"thread-local allocation buffers not supported\");\n-    return 0;\n-  }\n-\n-  \/\/ If a GC uses a stack watermark barrier, the stack processing is lazy, concurrent,\n-  \/\/ incremental and cooperative. In order for that to work well, mechanisms that stop\n-  \/\/ another thread might want to ensure its roots are in a sane state.\n-  virtual bool uses_stack_watermark_barrier() const { return false; }\n+  virtual size_t unsafe_max_tlab_alloc(Thread *thr) const = 0;\n@@ -387,4 +377,2 @@\n-  \/\/ Returns \"true\" iff there is a stop-world GC in progress.  (I assume\n-  \/\/ that it should answer \"false\" for the concurrent part of a concurrent\n-  \/\/ collector -- dld).\n-  bool is_gc_active() const { return _is_gc_active; }\n+  \/\/ Returns \"true\" iff there is a stop-world GC in progress.\n+  bool is_stw_gc_active() const { return _is_stw_gc_active; }\n@@ -413,1 +401,1 @@\n-  virtual SoftRefPolicy* soft_ref_policy() = 0;\n+  SoftRefPolicy* soft_ref_policy() { return &_soft_ref_policy; }\n@@ -422,1 +410,0 @@\n- protected:\n@@ -427,1 +414,0 @@\n- public:\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":16,"deletions":30,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -200,8 +200,2 @@\n-JNIEXPORT jboolean JNICALL\n-JVM_IsCDSDumpingEnabled(JNIEnv* env);\n-\n-JNIEXPORT jboolean JNICALL\n-JVM_IsSharingEnabled(JNIEnv* env);\n-\n-JNIEXPORT jboolean JNICALL\n-JVM_IsDumpingClassList(JNIEnv* env);\n+JNIEXPORT jint JNICALL\n+JVM_GetCDSConfigStatus();\n@@ -247,2 +241,1 @@\n-  JVM_STACKWALK_FILL_CLASS_REFS_ONLY       = 0x2,\n-  JVM_STACKWALK_GET_CALLER_CLASS           = 0x04,\n+  JVM_STACKWALK_CLASS_INFO_ONLY            = 0x2,\n@@ -253,0 +246,3 @@\n+JNIEXPORT void JNICALL\n+JVM_ExpandStackFrameInfo(JNIEnv *env, jobject obj);\n+\n@@ -254,1 +250,1 @@\n-JVM_CallStackWalk(JNIEnv *env, jobject stackStream, jlong mode,\n+JVM_CallStackWalk(JNIEnv *env, jobject stackStream, jint mode,\n@@ -256,1 +252,1 @@\n-                  jint frame_count, jint start_index, jobjectArray frames);\n+                  jint buffer_size, jint start_index, jobjectArray frames);\n@@ -259,2 +255,2 @@\n-JVM_MoreStackWalk(JNIEnv *env, jobject stackStream, jlong mode, jlong anchor,\n-                  jint frame_count, jint start_index,\n+JVM_MoreStackWalk(JNIEnv *env, jobject stackStream, jint mode, jlong anchor,\n+                  jint last_batch_count, jint buffer_size, jint start_index,\n@@ -782,6 +778,0 @@\n-\/*\n- * java.util.concurrent.atomic.AtomicLong\n- *\/\n-JNIEXPORT jboolean JNICALL\n-JVM_SupportsCX8(void);\n-\n@@ -1159,1 +1149,4 @@\n-JVM_VirtualThreadHideFrames(JNIEnv* env, jobject vthread, jboolean hide);\n+JVM_VirtualThreadHideFrames(JNIEnv* env, jclass clazz, jboolean hide);\n+\n+JNIEXPORT void JNICALL\n+JVM_VirtualThreadDisableSuspend(JNIEnv* env, jclass clazz, jboolean enter);\n","filename":"src\/hotspot\/share\/include\/jvm.h","additions":15,"deletions":22,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -36,2 +36,0 @@\n-#include \"jfr\/recorder\/checkpoint\/types\/jfrType.hpp\"\n-#include \"jfr\/recorder\/jfrRecorder.hpp\"\n@@ -40,0 +38,2 @@\n+#include \"jfr\/recorder\/checkpoint\/types\/jfrType.hpp\"\n+#include \"jfr\/recorder\/jfrRecorder.hpp\"\n@@ -41,1 +41,1 @@\n-#include \"jfr\/writers\/jfrJavaEventWriter.hpp\"\n+#include \"jfr\/writers\/jfrJavaEventWriter.hpp\"\n@@ -48,0 +48,1 @@\n+#include \"nmt\/nmtCommon.hpp\"\n@@ -56,1 +57,0 @@\n-#include \"services\/nmtCommon.hpp\"\n","filename":"src\/hotspot\/share\/jfr\/recorder\/checkpoint\/types\/jfrType.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -51,1 +52,2 @@\n-  const size_t sz = Message::calc_size(strlen(msg));\n+  const size_t len = strlen(msg);\n+  const size_t sz = Message::calc_size(len);\n@@ -57,1 +59,1 @@\n-    new(_buf + _pos) Message(output, decorations, msg);\n+    new(_buf + _pos) Message(output, decorations, msg, len);\n@@ -117,23 +119,1 @@\n-void AsyncLogWriter::write() {\n-  ResourceMark rm;\n-  AsyncLogMap<AnyObj::RESOURCE_AREA> snapshot;\n-\n-  \/\/ lock protection. This guarantees I\/O jobs don't block logsites.\n-  {\n-    AsyncLogLocker locker;\n-\n-    _buffer_staging->reset();\n-    swap(_buffer, _buffer_staging);\n-\n-    \/\/ move counters to snapshot and reset them.\n-    _stats.iterate([&] (LogFileStreamOutput* output, uint32_t& counter) {\n-      if (counter > 0) {\n-        bool created = snapshot.put(output, counter);\n-        assert(created == true, \"sanity check\");\n-        counter = 0;\n-      }\n-      return true;\n-    });\n-    _data_available = false;\n-  }\n-\n+void AsyncLogWriter::write(AsyncLogMap<AnyObj::RESOURCE_AREA>& snapshot) {\n@@ -160,1 +140,1 @@\n-      output->write_blocking(decorations, ss.as_string(false));\n+      output->write_blocking(decorations, ss.freeze());\n@@ -173,0 +153,2 @@\n+    ResourceMark rm;\n+    AsyncLogMap<AnyObj::RESOURCE_AREA> snapshot;\n@@ -179,0 +161,15 @@\n+      \/\/ Only doing a swap and statistics under the lock to\n+      \/\/ guarantee that I\/O jobs don't block logsites.\n+      _buffer_staging->reset();\n+      swap(_buffer, _buffer_staging);\n+\n+      \/\/ move counters to snapshot and reset them.\n+      _stats.iterate([&] (LogFileStreamOutput* output, uint32_t& counter) {\n+        if (counter > 0) {\n+          bool created = snapshot.put(output, counter);\n+          assert(created == true, \"sanity check\");\n+          counter = 0;\n+        }\n+        return true;\n+      });\n+      _data_available = false;\n@@ -180,2 +177,1 @@\n-\n-    write();\n+    write(snapshot);\n","filename":"src\/hotspot\/share\/logging\/logAsyncWriter.cpp","additions":24,"deletions":28,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -69,1 +70,1 @@\n-  \/\/ Messsage is the envelop of a log line and its associative data.\n+  \/\/ Messsage is the envelope of a log line and its associative data.\n@@ -75,1 +76,1 @@\n-  \/\/ |_output|_decorations|\"a log line\", |pad| <- pointer aligned.\n+  \/\/ |_output|_decorations|\"a log line\", |pad| <- Message aligned.\n@@ -87,1 +88,2 @@\n-    Message(LogFileStreamOutput* output, const LogDecorations& decorations, const char* msg)\n+    \/\/ msglen excludes NUL-byte\n+    Message(LogFileStreamOutput* output, const LogDecorations& decorations, const char* msg, const size_t msglen)\n@@ -90,2 +92,1 @@\n-      PRAGMA_STRINGOP_OVERFLOW_IGNORED\n-      strcpy(reinterpret_cast<char* >(this+1), msg);\n+      memcpy(reinterpret_cast<char* >(this+1), msg, msglen + 1);\n@@ -96,1 +97,1 @@\n-      return align_up(sizeof(Message) + message_len + 1, sizeof(void*));\n+      return align_up(sizeof(Message) + message_len + 1, alignof(Message));\n@@ -117,0 +118,2 @@\n+      \/\/ Ensure _pos is Message-aligned\n+      _pos = align_up(_buf, alignof(Message)) - _buf;\n@@ -127,1 +130,4 @@\n-    void reset() { _pos = 0; }\n+    void reset() {\n+      \/\/ Ensure _pos is Message-aligned\n+      _pos = align_up(_buf, alignof(Message)) - _buf;\n+    }\n@@ -171,1 +177,1 @@\n-  void write();\n+  void write(AsyncLogMap<AnyObj::RESOURCE_AREA>& snapshot);\n@@ -177,1 +183,0 @@\n-  const char* name() const override { return \"AsyncLog Thread\"; }\n@@ -204,0 +209,2 @@\n+\n+  const char* name() const override { return \"AsyncLog Thread\"; }\n","filename":"src\/hotspot\/share\/logging\/logAsyncWriter.hpp","additions":16,"deletions":9,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -508,0 +508,6 @@\n+  } else if (strcmp(outputstr, StdoutLog->name()) == 0) { \/\/ stdout\n+    idx = 0;\n+    assert(find_output(outputstr) == idx, \"sanity check\");\n+  } else if (strcmp(outputstr, StderrLog->name()) == 0) { \/\/ stderr\n+    idx = 1;\n+    assert(find_output(outputstr) == idx, \"sanity check\");\n@@ -611,1 +617,1 @@\n-  out->print_cr(\"  If the filename contains %%p and\/or %%t, they will expand to the JVM's PID and startup timestamp, respectively.\");\n+  out->print_cr(\"  If the filename contains %%p, %%t and\/or %%hn, they will expand to the JVM's PID, startup timestamp and host name, respectively.\");\n","filename":"src\/hotspot\/share\/logging\/logConfiguration.cpp","additions":8,"deletions":2,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -41,0 +41,1 @@\n+const char* const LogFileOutput::HostnameFilenamePlaceholder = \"%hn\";\n@@ -381,0 +382,1 @@\n+  char hostname_string[HostnameBufferSize];\n@@ -383,1 +385,1 @@\n-  \/\/ Lets start finding out if we have any %d and\/or %t in the name.\n+  \/\/ Lets start finding out if we have any %p, %t and\/or %hn in the name.\n@@ -387,0 +389,1 @@\n+  const char* hostname = strstr(file_name, HostnameFilenamePlaceholder);\n@@ -388,1 +391,1 @@\n-  if (pid == nullptr && timestamp == nullptr) {\n+  if (pid == nullptr && timestamp == nullptr && hostname == nullptr) {\n@@ -394,9 +397,1 @@\n-  const char* first = \"\";\n-  size_t first_pos = SIZE_MAX;\n-  size_t first_replace_len = 0;\n-\n-  const char* second = \"\";\n-  size_t second_pos = SIZE_MAX;\n-  size_t second_replace_len = 0;\n-\n-  \/\/ If we found a %p, then setup our variables accordingly\n+  size_t result_len =  strlen(file_name);\n@@ -404,9 +399,2 @@\n-    if (timestamp == nullptr || pid < timestamp) {\n-      first = pid_string;\n-      first_pos = pid - file_name;\n-      first_replace_len = strlen(PidFilenamePlaceholder);\n-    } else {\n-      second = pid_string;\n-      second_pos = pid - file_name;\n-      second_replace_len = strlen(PidFilenamePlaceholder);\n-    }\n+    result_len -= strlen(PidFilenamePlaceholder);\n+    result_len += strlen(pid_string);\n@@ -414,9 +402,7 @@\n-\n-    if (pid == nullptr || timestamp < pid) {\n-      first = timestamp_string;\n-      first_pos = timestamp - file_name;\n-      first_replace_len = strlen(TimestampFilenamePlaceholder);\n-    } else {\n-      second = timestamp_string;\n-      second_pos = timestamp - file_name;\n-      second_replace_len = strlen(TimestampFilenamePlaceholder);\n+    result_len -= strlen(TimestampFilenamePlaceholder);\n+    result_len += strlen(timestamp_string);\n+  }\n+  if (hostname != nullptr) {\n+    if (!os::get_host_name(hostname_string, sizeof(hostname_string))) {\n+      int res = jio_snprintf(hostname_string, sizeof(hostname_string), \"unknown-host\");\n+      assert(res > 0, \"Hostname buffer too small\");\n@@ -425,0 +411,2 @@\n+    result_len -= strlen(HostnameFilenamePlaceholder);\n+    result_len += strlen(hostname_string);\n@@ -426,5 +414,0 @@\n-\n-  size_t first_len = strlen(first);\n-  size_t second_len = strlen(second);\n-\n-  size_t result_len =  strlen(file_name) + first_len - first_replace_len + second_len - second_replace_len;\n@@ -438,16 +421,29 @@\n-    if (file_name_pos == first_pos) {\n-      \/\/ We are in the range of the first placeholder\n-      strcpy(result + i, first);\n-      \/\/ Bump output buffer position with length of replacing string\n-      i += first_len;\n-      \/\/ Bump source buffer position to skip placeholder\n-      file_name_pos += first_replace_len;\n-    } else if (file_name_pos == second_pos) {\n-      \/\/ We are in the range of the second placeholder\n-      strcpy(result + i, second);\n-      i += second_len;\n-      file_name_pos += second_replace_len;\n-    } else {\n-      \/\/ Else, copy char by char of the original file\n-      result[i] = file_name[file_name_pos++];\n-      i++;\n+    if (file_name[file_name_pos] == '%') {\n+      \/\/ Replace the first occurrence of any placeholder\n+      if (pid != nullptr && strncmp(&file_name[file_name_pos],\n+                                    PidFilenamePlaceholder,\n+                                    strlen(PidFilenamePlaceholder)) == 0) {\n+        strcpy(result + i, pid_string);\n+        i += strlen(pid_string);\n+        file_name_pos += strlen(PidFilenamePlaceholder);\n+        pid = nullptr;\n+        continue;\n+      }\n+      if (timestamp != nullptr && strncmp(&file_name[file_name_pos],\n+                                          TimestampFilenamePlaceholder,\n+                                          strlen(TimestampFilenamePlaceholder)) == 0) {\n+        strcpy(result + i, timestamp_string);\n+        i += strlen(timestamp_string);\n+        file_name_pos += strlen(TimestampFilenamePlaceholder);\n+        timestamp = nullptr;\n+        continue;\n+      }\n+      if (hostname != nullptr && strncmp(&file_name[file_name_pos],\n+                                         HostnameFilenamePlaceholder,\n+                                         strlen(HostnameFilenamePlaceholder)) == 0) {\n+        strcpy(result + i, hostname_string);\n+        i += strlen(hostname_string);\n+        file_name_pos += strlen(HostnameFilenamePlaceholder);\n+        hostname = nullptr;\n+        continue;\n+      }\n@@ -455,0 +451,2 @@\n+    \/\/ Else, copy char by char of the original file\n+    result[i++] = file_name[file_name_pos++];\n@@ -456,0 +454,3 @@\n+  assert(i == result_len, \"should be\");\n+  assert(file_name[file_name_pos] == '\\0', \"should be\");\n+\n","filename":"src\/hotspot\/share\/logging\/logFileOutput.cpp","additions":52,"deletions":51,"binary":false,"changes":103,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -42,0 +42,1 @@\n+  static const char* const HostnameFilenamePlaceholder;\n@@ -46,0 +47,1 @@\n+  static const size_t HostnameBufferSize = 512;\n","filename":"src\/hotspot\/share\/logging\/logFileOutput.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -101,0 +101,1 @@\n+  LOG_TAG(inlinecache)\\\n@@ -107,0 +108,1 @@\n+  LOG_TAG(jmethod) \\\n","filename":"src\/hotspot\/share\/logging\/logTag.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -45,0 +45,1 @@\n+#include \"nmt\/memTracker.hpp\"\n@@ -61,1 +62,0 @@\n-#include \"services\/memTracker.hpp\"\n","filename":"src\/hotspot\/share\/precompiled\/precompiled.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,0 +26,1 @@\n+#include \"cds\/cdsConfig.hpp\"\n@@ -99,0 +100,1 @@\n+#include \"utilities\/checkedCast.hpp\"\n@@ -105,0 +107,1 @@\n+#include \"utilities\/zipLibrary.hpp\"\n@@ -545,1 +548,1 @@\n-  java_lang_StackFrameInfo::to_stack_trace_element(stack_frame_info, stack_trace_element, THREAD);\n+  java_lang_StackFrameInfo::to_stack_trace_element(stack_frame_info, stack_trace_element, CHECK);\n@@ -550,0 +553,2 @@\n+JVM_ENTRY(void, JVM_ExpandStackFrameInfo(JNIEnv *env, jobject obj))\n+  Handle stack_frame_info(THREAD, JNIHandles::resolve_non_null(obj));\n@@ -551,0 +556,12 @@\n+  bool have_name = (java_lang_StackFrameInfo::name(stack_frame_info()) != nullptr);\n+  bool have_type = (java_lang_StackFrameInfo::type(stack_frame_info()) != nullptr);\n+  Method* method = java_lang_StackFrameInfo::get_method(stack_frame_info());\n+  if (!have_name) {\n+    oop name = StringTable::intern(method->name(), CHECK);\n+    java_lang_StackFrameInfo::set_name(stack_frame_info(), name);\n+  }\n+  if (!have_type) {\n+    Handle type = java_lang_String::create_from_symbol(method->signature(), CHECK);\n+    java_lang_StackFrameInfo::set_type(stack_frame_info(), type());\n+  }\n+JVM_END\n@@ -552,1 +569,1 @@\n-JVM_ENTRY(jobject, JVM_CallStackWalk(JNIEnv *env, jobject stackStream, jlong mode,\n+JVM_ENTRY(jobject, JVM_CallStackWalk(JNIEnv *env, jobject stackStream, jint mode,\n@@ -554,1 +571,1 @@\n-                                     jint frame_count, jint start_index, jobjectArray frames))\n+                                     jint buffer_size, jint start_index, jobjectArray frames))\n@@ -562,1 +579,1 @@\n-  \/\/ frames array is a Class<?>[] array when only getting caller reference,\n+  \/\/ frames array is a ClassFrameInfo[] array when only getting caller reference,\n@@ -568,2 +585,1 @@\n-  int limit = start_index + frame_count;\n-  if (frames_array_h->length() < limit) {\n+  if (frames_array_h->length() < buffer_size) {\n@@ -574,1 +590,1 @@\n-                               frame_count, start_index, frames_array_h, CHECK_NULL);\n+                               buffer_size, start_index, frames_array_h, CHECK_NULL);\n@@ -579,2 +595,2 @@\n-JVM_ENTRY(jint, JVM_MoreStackWalk(JNIEnv *env, jobject stackStream, jlong mode, jlong anchor,\n-                                  jint frame_count, jint start_index,\n+JVM_ENTRY(jint, JVM_MoreStackWalk(JNIEnv *env, jobject stackStream, jint mode, jlong anchor,\n+                                  jint last_batch_count, jint buffer_size, jint start_index,\n@@ -582,1 +598,1 @@\n-  \/\/ frames array is a Class<?>[] array when only getting caller reference,\n+  \/\/ frames array is a ClassFrameInfo[] array when only getting caller reference,\n@@ -588,2 +604,1 @@\n-  int limit = start_index+frame_count;\n-  if (frames_array_h->length() < limit) {\n+  if (frames_array_h->length() < buffer_size) {\n@@ -594,1 +609,1 @@\n-  return StackWalk::fetchNextBatch(stackStream_h, mode, anchor, frame_count,\n+  return StackWalk::fetchNextBatch(stackStream_h, mode, anchor, last_batch_count, buffer_size,\n@@ -2934,1 +2949,1 @@\n-  if (DumpSharedSpaces) {\n+  if (CDSConfig::is_dumping_static_archive()) {\n@@ -3403,2 +3418,1 @@\n-  ClassLoader::load_zip_library_if_needed();\n-  return ClassLoader::zip_library_handle();\n+  return ZipLibrary::handle();\n@@ -3576,6 +3590,0 @@\n-\/\/ Atomic \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-\n-JVM_LEAF(jboolean, JVM_SupportsCX8())\n-  return VM_Version::supports_cx8();\n-JVM_END\n-\n@@ -3597,1 +3605,1 @@\n-  if (!Arguments::is_dumping_archive()) {\n+  if (!CDSConfig::is_dumping_archive()) {\n@@ -3684,9 +3692,2 @@\n-JVM_LEAF(jboolean, JVM_IsCDSDumpingEnabled(JNIEnv* env))\n-  return Arguments::is_dumping_archive();\n-JVM_END\n-\n-JVM_LEAF(jboolean, JVM_IsSharingEnabled(JNIEnv* env))\n-  return UseSharedSpaces;\n-JVM_END\n-\n-  if (DumpSharedSpaces) {\n+  if (CDSConfig::is_dumping_static_archive()) {\n+    \/\/ We do this so that the default CDS archive can be deterministic.\n@@ -3714,6 +3715,2 @@\n-JVM_LEAF(jboolean, JVM_IsDumpingClassList(JNIEnv *env))\n-#if INCLUDE_CDS\n-  return ClassListWriter::is_enabled() || DynamicDumpSharedSpaces;\n-#else\n-  return false;\n-#endif \/\/ INCLUDE_CDS\n+JVM_ENTRY_NO_ENV(jint, JVM_GetCDSConfigStatus())\n+  return CDSConfig::get_status();\n@@ -3724,1 +3721,1 @@\n-  assert(ClassListWriter::is_enabled() || DynamicDumpSharedSpaces,  \"Should be set and open or do dynamic dump\");\n+  assert(CDSConfig::is_logging_lambda_form_invokers(), \"sanity\");\n@@ -3729,1 +3726,1 @@\n-    if (DynamicDumpSharedSpaces) {\n+    if (CDSConfig::is_dumping_dynamic_archive()) {\n@@ -3933,2 +3930,0 @@\n-#else\n-  fatal(\"Should only be called with JVMTI enabled\");\n@@ -3950,2 +3945,0 @@\n-#else\n-  fatal(\"Should only be called with JVMTI enabled\");\n@@ -3969,2 +3962,0 @@\n-#else\n-  fatal(\"Should only be called with JVMTI enabled\");\n@@ -3988,2 +3979,0 @@\n-#else\n-  fatal(\"Should only be called with JVMTI enabled\");\n@@ -3994,1 +3983,1 @@\n-JVM_ENTRY(void, JVM_VirtualThreadHideFrames(JNIEnv* env, jobject vthread, jboolean hide))\n+JVM_ENTRY(void, JVM_VirtualThreadHideFrames(JNIEnv* env, jclass clazz, jboolean hide))\n@@ -4003,2 +3992,14 @@\n-#else\n-  fatal(\"Should only be called with JVMTI enabled\");\n+#endif\n+JVM_END\n+\n+\/\/ Notification from VirtualThread about disabling JVMTI Suspend in a sync critical section.\n+\/\/ Needed to avoid deadlocks with JVMTI suspend mechanism.\n+JVM_ENTRY(void, JVM_VirtualThreadDisableSuspend(JNIEnv* env, jclass clazz, jboolean enter))\n+#if INCLUDE_JVMTI\n+  if (!DoJVMTIVirtualThreadTransitions) {\n+    assert(!JvmtiExport::can_support_virtual_threads(), \"sanity check\");\n+    return;\n+  }\n+  assert(thread->is_disable_suspend() != (bool)enter,\n+         \"nested or unbalanced monitor enter\/exit is not allowed\");\n+  thread->toggle_is_disable_suspend();\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":53,"deletions":52,"binary":false,"changes":105,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,0 +26,1 @@\n+#include \"cds\/cdsConfig.hpp\"\n@@ -37,0 +38,1 @@\n+uint64_t Abstract_VM_Version::_cpu_features = 0;\n@@ -38,0 +40,1 @@\n+#ifndef SUPPORTS_NATIVE_CX8\n@@ -39,0 +42,1 @@\n+#endif\n@@ -136,1 +140,1 @@\n-      return UseSharedSpaces ? \"interpreted mode, sharing\" : \"interpreted mode\";\n+      return CDSConfig::is_using_archive() ? \"interpreted mode, sharing\" : \"interpreted mode\";\n@@ -138,1 +142,1 @@\n-      if (UseSharedSpaces) {\n+      if (CDSConfig::is_using_archive()) {\n@@ -153,1 +157,1 @@\n-         return UseSharedSpaces ? \"compiled mode, emulated-client, sharing\" : \"compiled mode, emulated-client\";\n+         return CDSConfig::is_using_archive() ? \"compiled mode, emulated-client, sharing\" : \"compiled mode, emulated-client\";\n@@ -155,1 +159,1 @@\n-      return UseSharedSpaces ? \"compiled mode, sharing\" : \"compiled mode\";\n+      return CDSConfig::is_using_archive() ? \"compiled mode, sharing\" : \"compiled mode\";\n@@ -197,4 +201,0 @@\n-  #ifndef HOTSPOT_BUILD_USER\n-    #define HOTSPOT_BUILD_USER unknown\n-  #endif\n-\n@@ -243,0 +243,10 @@\n+      #elif _MSC_VER == 1934\n+        #define HOTSPOT_BUILD_COMPILER \"MS VC++ 17.4 (VS2022)\"\n+      #elif _MSC_VER == 1935\n+        #define HOTSPOT_BUILD_COMPILER \"MS VC++ 17.5 (VS2022)\"\n+      #elif _MSC_VER == 1936\n+        #define HOTSPOT_BUILD_COMPILER \"MS VC++ 17.6 (VS2022)\"\n+      #elif _MSC_VER == 1937\n+        #define HOTSPOT_BUILD_COMPILER \"MS VC++ 17.7 (VS2022)\"\n+      #elif _MSC_VER == 1938\n+        #define HOTSPOT_BUILD_COMPILER \"MS VC++ 17.8 (VS2022)\"\n@@ -274,1 +284,1 @@\n-         \" by \" XSTR(HOTSPOT_BUILD_USER) \" with \" HOTSPOT_BUILD_COMPILER\n+         \" with \" HOTSPOT_BUILD_COMPILER\n","filename":"src\/hotspot\/share\/runtime\/abstract_vm_version.cpp","additions":20,"deletions":10,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -57,1 +57,1 @@\n-  \/\/ CPU feature flags.\n+  \/\/ CPU feature flags, can be affected by VM settings.\n@@ -61,0 +61,3 @@\n+  \/\/ Original CPU feature flags, not affected by VM settings.\n+  static uint64_t _cpu_features;\n+\n@@ -62,0 +65,1 @@\n+#ifndef SUPPORTS_NATIVE_CX8\n@@ -63,0 +67,1 @@\n+#endif\n@@ -136,0 +141,2 @@\n+  \/\/ Required to be true but still dynamically checked at runtime\n+  \/\/ for platforms that don't set SUPPORTS_NATIVE_CX8\n@@ -183,0 +190,6 @@\n+  \/\/ Is recursive lightweight locking implemented for this platform?\n+  constexpr static bool supports_recursive_lightweight_locking() { return false; }\n+\n+  \/\/ Does platform support secondary supers table lookup?\n+  constexpr static bool supports_secondary_supers_table() { return false; }\n+\n@@ -189,0 +202,2 @@\n+  static bool profile_all_receivers_at_type_check() { return true; }\n+\n","filename":"src\/hotspot\/share\/runtime\/abstract_vm_version.hpp","additions":17,"deletions":2,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,0 +28,1 @@\n+#include \"cds\/cdsConfig.hpp\"\n@@ -45,0 +46,1 @@\n+#include \"nmt\/nmtCommon.hpp\"\n@@ -63,1 +65,1 @@\n-#include \"services\/nmtCommon.hpp\"\n+#include \"utilities\/checkedCast.hpp\"\n@@ -104,4 +106,0 @@\n-char*  Arguments::_default_shared_archive_path  = nullptr;\n-char*  Arguments::SharedArchivePath             = nullptr;\n-char*  Arguments::SharedDynamicArchivePath      = nullptr;\n-\n@@ -134,0 +132,3 @@\n+\/\/ True if -Xint\/-Xmixed\/-Xcomp were specified\n+static bool mode_flag_cmd_line = false;\n+\n@@ -319,1 +320,0 @@\n-  assert((strncmp(property, \"-D\", 2) != 0), \"Unexpected leading -D\");\n@@ -499,4 +499,0 @@\n-  { \"MaxGCMinorPauseMillis\",        JDK_Version::jdk(8), JDK_Version::undefined(), JDK_Version::undefined() },\n-  { \"MaxRAMFraction\",               JDK_Version::jdk(10),  JDK_Version::undefined(), JDK_Version::undefined() },\n-  { \"MinRAMFraction\",               JDK_Version::jdk(10),  JDK_Version::undefined(), JDK_Version::undefined() },\n-  { \"InitialRAMFraction\",           JDK_Version::jdk(10),  JDK_Version::undefined(), JDK_Version::undefined() },\n@@ -505,0 +501,1 @@\n+  { \"ZGenerational\",                JDK_Version::jdk(23), JDK_Version::undefined(), JDK_Version::undefined() },\n@@ -509,1 +506,11 @@\n-\n+  { \"RegisterFinalizersAtInit\",     JDK_Version::jdk(22), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n+  { \"DontYieldALot\",                JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n+  { \"OldSize\",                      JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n+  { \"PreserveAllAnnotations\",       JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n+  { \"UseNotificationThread\",        JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n+  { \"UseEmptySlotsInSupers\",        JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n+#if defined(X86)\n+  { \"UseRTMLocking\",                JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n+  { \"UseRTMDeopt\",                  JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n+  { \"RTMRetryCount\",                JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n+#endif \/\/ X86\n@@ -511,2 +518,0 @@\n-  { \"DefaultMaxRAMFraction\",        JDK_Version::jdk(8),  JDK_Version::undefined(), JDK_Version::undefined() },\n-  { \"TLABStats\",                    JDK_Version::jdk(12), JDK_Version::undefined(), JDK_Version::undefined() },\n@@ -517,10 +522,0 @@\n-  { \"G1ConcRefinementGreenZone\",    JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::undefined() },\n-  { \"G1ConcRefinementYellowZone\",   JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::undefined() },\n-  { \"G1ConcRefinementRedZone\",      JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::undefined() },\n-  { \"G1ConcRefinementThresholdStep\", JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::undefined() },\n-  { \"G1UseAdaptiveConcRefinement\",  JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::undefined() },\n-  { \"G1ConcRefinementServiceIntervalMillis\", JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::undefined() },\n-\n-  { \"G1ConcRSLogCacheSize\",         JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::undefined() },\n-  { \"G1ConcRSHotCardLimit\",         JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::undefined() },\n-  { \"RefDiscoveryPolicy\",           JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::undefined() },\n@@ -529,0 +524,26 @@\n+  { \"G1ConcRefinementGreenZone\",    JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::jdk(24) },\n+  { \"G1ConcRefinementYellowZone\",   JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::jdk(24) },\n+  { \"G1ConcRefinementRedZone\",      JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::jdk(24) },\n+  { \"G1ConcRefinementThresholdStep\", JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::jdk(24) },\n+  { \"G1UseAdaptiveConcRefinement\",  JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::jdk(24) },\n+  { \"G1ConcRefinementServiceIntervalMillis\", JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::jdk(24) },\n+\n+  { \"G1ConcRSLogCacheSize\",         JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::jdk(24) },\n+  { \"G1ConcRSHotCardLimit\",         JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::jdk(24) },\n+  { \"RefDiscoveryPolicy\",           JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::jdk(24) },\n+\n+  { \"AdaptiveSizePolicyCollectionCostMargin\",   JDK_Version::undefined(), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n+  { \"MaxGCMinorPauseMillis\",        JDK_Version::jdk(8), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n+  { \"MaxRAMFraction\",               JDK_Version::jdk(10),  JDK_Version::jdk(23), JDK_Version::jdk(24) },\n+  { \"MinRAMFraction\",               JDK_Version::jdk(10),  JDK_Version::jdk(23), JDK_Version::jdk(24) },\n+  { \"InitialRAMFraction\",           JDK_Version::jdk(10),  JDK_Version::jdk(23), JDK_Version::jdk(24) },\n+  { \"DefaultMaxRAMFraction\",        JDK_Version::jdk(8),  JDK_Version::jdk(23), JDK_Version::jdk(24) },\n+  { \"TLABStats\",                    JDK_Version::jdk(12), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n+  { \"GCLockerEdenExpansionPercent\", JDK_Version::undefined(), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n+  { \"NUMAPageScanRate\",             JDK_Version::undefined(), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n+  { \"ProcessDistributionStride\",    JDK_Version::undefined(), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n+\n+  { \"ParallelOldDeadWoodLimiterMean\",   JDK_Version::undefined(), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n+  { \"ParallelOldDeadWoodLimiterStdDev\", JDK_Version::undefined(), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n+  { \"UseNeon\",                      JDK_Version::undefined(), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n+  { \"ScavengeBeforeFullGC\",         JDK_Version::undefined(), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n@@ -554,1 +575,0 @@\n-  { \"DefaultMaxRAMFraction\",    \"MaxRAMFraction\"    },\n@@ -1129,12 +1149,1 @@\n-    if (strlen(locked_message_buf) == 0) {\n-      if (found_flag->is_bool() && !has_plus_minus) {\n-        jio_fprintf(defaultStream::error_stream(),\n-          \"Missing +\/- setting for VM option '%s'\\n\", argname);\n-      } else if (!found_flag->is_bool() && has_plus_minus) {\n-        jio_fprintf(defaultStream::error_stream(),\n-          \"Unexpected +\/- setting in VM option '%s'\\n\", argname);\n-      } else {\n-        jio_fprintf(defaultStream::error_stream(),\n-          \"Improperly specified VM option '%s'\\n\", argname);\n-      }\n-    } else {\n+    if (strlen(locked_message_buf) != 0) {\n@@ -1142,2 +1151,1 @@\n-      bool mismatched = ((msg_type == JVMFlag::NOTPRODUCT_FLAG_BUT_PRODUCT_BUILD) ||\n-                         (msg_type == JVMFlag::DEVELOPER_FLAG_BUT_PRODUCT_BUILD));\n+      bool mismatched = msg_type == JVMFlag::DEVELOPER_FLAG_BUT_PRODUCT_BUILD;\n@@ -1150,0 +1158,10 @@\n+    if (found_flag->is_bool() && !has_plus_minus) {\n+      jio_fprintf(defaultStream::error_stream(),\n+        \"Missing +\/- setting for VM option '%s'\\n\", argname);\n+    } else if (!found_flag->is_bool() && has_plus_minus) {\n+      jio_fprintf(defaultStream::error_stream(),\n+        \"Unexpected +\/- setting in VM option '%s'\\n\", argname);\n+    } else {\n+      jio_fprintf(defaultStream::error_stream(),\n+        \"Improperly specified VM option '%s'\\n\", argname);\n+    }\n@@ -1188,1 +1206,1 @@\n-  char quote_c        = 0;\n+  int  quote_c        = 0;\n@@ -1200,1 +1218,1 @@\n-          token[pos++] = c;\n+          token[pos++] = checked_cast<char>(c);\n@@ -1220,1 +1238,1 @@\n-        token[pos++] = c;\n+        token[pos++] = checked_cast<char>(c);\n@@ -1269,5 +1287,2 @@\n-#if INCLUDE_CDS\n-  if (is_internal_module_property(key) ||\n-      strcmp(key, \"jdk.module.main\") == 0) {\n-    MetaspaceShared::disable_optimized_module_handling();\n-    log_info(cds)(\"optimized module handling: disabled due to incompatible property: %s=%s\", key, value);\n+  if (internal == ExternalProperty) {\n+    CDSConfig::check_incompatible_property(key, value);\n@@ -1275,7 +1290,0 @@\n-  if (strcmp(key, \"jdk.module.showModuleResolution\") == 0 ||\n-      strcmp(key, \"jdk.module.validation\") == 0 ||\n-      strcmp(key, \"java.system.class.loader\") == 0) {\n-    MetaspaceShared::disable_full_module_graph();\n-    log_info(cds)(\"full module graph: disabled due to incompatible property: %s=%s\", key, value);\n-  }\n-#endif\n@@ -1335,54 +1343,0 @@\n-#if INCLUDE_CDS\n-const char* unsupported_properties[] = { \"jdk.module.limitmods\",\n-                                         \"jdk.module.upgrade.path\",\n-                                         \"jdk.module.patch.0\" };\n-const char* unsupported_options[] = { \"--limit-modules\",\n-                                      \"--upgrade-module-path\",\n-                                      \"--patch-module\"\n-                                    };\n-void Arguments::check_unsupported_dumping_properties() {\n-  assert(is_dumping_archive(),\n-         \"this function is only used with CDS dump time\");\n-  assert(ARRAY_SIZE(unsupported_properties) == ARRAY_SIZE(unsupported_options), \"must be\");\n-  \/\/ If a vm option is found in the unsupported_options array, vm will exit with an error message.\n-  SystemProperty* sp = system_properties();\n-  while (sp != nullptr) {\n-    for (uint i = 0; i < ARRAY_SIZE(unsupported_properties); i++) {\n-      if (strcmp(sp->key(), unsupported_properties[i]) == 0) {\n-        vm_exit_during_initialization(\n-          \"Cannot use the following option when dumping the shared archive\", unsupported_options[i]);\n-      }\n-    }\n-    sp = sp->next();\n-  }\n-\n-  \/\/ Check for an exploded module build in use with -Xshare:dump.\n-  if (!has_jimage()) {\n-    vm_exit_during_initialization(\"Dumping the shared archive is not supported with an exploded module build\");\n-  }\n-}\n-\n-bool Arguments::check_unsupported_cds_runtime_properties() {\n-  assert(UseSharedSpaces, \"this function is only used with -Xshare:{on,auto}\");\n-  assert(ARRAY_SIZE(unsupported_properties) == ARRAY_SIZE(unsupported_options), \"must be\");\n-  if (ArchiveClassesAtExit != nullptr) {\n-    \/\/ dynamic dumping, just return false for now.\n-    \/\/ check_unsupported_dumping_properties() will be called later to check the same set of\n-    \/\/ properties, and will exit the VM with the correct error message if the unsupported properties\n-    \/\/ are used.\n-    return false;\n-  }\n-  for (uint i = 0; i < ARRAY_SIZE(unsupported_properties); i++) {\n-    if (get_property(unsupported_properties[i]) != nullptr) {\n-      if (RequireSharedSpaces) {\n-        warning(\"CDS is disabled when the %s option is specified.\", unsupported_options[i]);\n-      } else {\n-        log_info(cds)(\"CDS is disabled when the %s option is specified.\", unsupported_options[i]);\n-      }\n-      return true;\n-    }\n-  }\n-  return false;\n-}\n-#endif\n-\n@@ -1438,1 +1392,1 @@\n-static void no_shared_spaces(const char* message) {\n+void Arguments::no_shared_spaces(const char* message) {\n@@ -1449,1 +1403,1 @@\n-void set_object_alignment() {\n+static void set_object_alignment() {\n@@ -1562,3 +1516,0 @@\n-                           !FLAG_IS_DEFAULT(MaxRAMFraction) ||\n-                           !FLAG_IS_DEFAULT(MinRAMFraction) ||\n-                           !FLAG_IS_DEFAULT(InitialRAMFraction) ||\n@@ -1580,14 +1531,0 @@\n-\n-  \/\/ Convert deprecated flags\n-  if (FLAG_IS_DEFAULT(MaxRAMPercentage) &&\n-      !FLAG_IS_DEFAULT(MaxRAMFraction))\n-    MaxRAMPercentage = 100.0 \/ MaxRAMFraction;\n-\n-  if (FLAG_IS_DEFAULT(MinRAMPercentage) &&\n-      !FLAG_IS_DEFAULT(MinRAMFraction))\n-    MinRAMPercentage = 100.0 \/ MinRAMFraction;\n-\n-  if (FLAG_IS_DEFAULT(InitialRAMPercentage) &&\n-      !FLAG_IS_DEFAULT(InitialRAMFraction))\n-    InitialRAMPercentage = 100.0 \/ InitialRAMFraction;\n-\n@@ -1598,2 +1535,2 @@\n-    julong reasonable_max = (julong)((phys_mem * MaxRAMPercentage) \/ 100);\n-    const julong reasonable_min = (julong)((phys_mem * MinRAMPercentage) \/ 100);\n+    julong reasonable_max = (julong)(((double)phys_mem * MaxRAMPercentage) \/ 100);\n+    const julong reasonable_min = (julong)(((double)phys_mem * MinRAMPercentage) \/ 100);\n@@ -1683,1 +1620,1 @@\n-      julong reasonable_initial = (julong)((phys_mem * InitialRAMPercentage) \/ 100);\n+      julong reasonable_initial = (julong)(((double)phys_mem * InitialRAMPercentage) \/ 100);\n@@ -1801,5 +1738,0 @@\n-  \/\/ This appears to improve mutator locality\n-  if (FLAG_SET_CMDLINE(ScavengeBeforeFullGC, false) != JVMFlag::SUCCESS) {\n-    return JNI_EINVAL;\n-  }\n-\n@@ -1921,2 +1853,1 @@\n-\n-#if !defined(X86) && !defined(AARCH64) && !defined(RISCV64) && !defined(ARM) && !defined(PPC64)\n+#if !defined(X86) && !defined(AARCH64) && !defined(RISCV64) && !defined(ARM) && !defined(PPC64) && !defined(S390)\n@@ -1929,9 +1860,0 @@\n-  if (UseHeavyMonitors) {\n-    if (FLAG_IS_CMDLINE(LockingMode) && LockingMode != LM_MONITOR) {\n-      jio_fprintf(defaultStream::error_stream(),\n-                  \"Conflicting -XX:+UseHeavyMonitors and -XX:LockingMode=%d flags\\n\", LockingMode);\n-      return false;\n-    }\n-    FLAG_SET_CMDLINE(LockingMode, LM_MONITOR);\n-  }\n-\n@@ -1984,4 +1906,4 @@\n-bool Arguments::parse_uintx(const char* value,\n-                            uintx* uintx_arg,\n-                            uintx min_size) {\n-  uintx n;\n+bool Arguments::parse_uint(const char* value,\n+                           uint* uint_arg,\n+                           uint min_size) {\n+  uint n;\n@@ -1992,1 +1914,1 @@\n-    *uintx_arg = n;\n+    *uint_arg = n;\n@@ -2001,0 +1923,1 @@\n+  CDSConfig::check_internal_module_property(prop_name, prop_value);\n@@ -2020,0 +1943,1 @@\n+  CDSConfig::check_internal_module_property(prop_base_name, prop_value);\n@@ -2121,0 +2045,1 @@\n+#if !INCLUDE_JVMTI\n@@ -2125,1 +2050,1 @@\n-bool valid_jdwp_agent(char *name, bool is_path) {\n+static bool valid_jdwp_agent(char *name, bool is_path) {\n@@ -2165,0 +2090,1 @@\n+#endif\n@@ -2373,4 +2299,0 @@\n-#if INCLUDE_CDS\n-      MetaspaceShared::disable_optimized_module_handling();\n-      log_info(cds)(\"optimized module handling: disabled because bootclasspath was appended\");\n-#endif\n@@ -2444,0 +2366,9 @@\n+    } else if (match_option(option, \"--sun-misc-unsafe-memory-access=\", &tail)) {\n+      if (strcmp(tail, \"allow\") == 0 || strcmp(tail, \"warn\") == 0 || strcmp(tail, \"debug\") == 0 || strcmp(tail, \"deny\") == 0) {\n+        PropertyList_unique_add(&_system_properties, \"sun.misc.unsafe.memory.access\", tail,\n+                                AddProperty, WriteableProperty, InternalProperty);\n+      } else {\n+        jio_fprintf(defaultStream::error_stream(),\n+                    \"Value specified to --sun-misc-unsafe-memory-access not recognized: '%s'\\n\", tail);\n+        return JNI_ERR;\n+      }\n@@ -2686,0 +2617,1 @@\n+          mode_flag_cmd_line = true;\n@@ -2689,0 +2621,1 @@\n+          mode_flag_cmd_line = true;\n@@ -2693,0 +2626,1 @@\n+          mode_flag_cmd_line = true;\n@@ -2695,1 +2629,1 @@\n-      DumpSharedSpaces = true;\n+      CDSConfig::enable_dumping_static_archive();\n@@ -2739,3 +2673,0 @@\n-    \/\/ -Xnoagent\n-    } else if (match_option(option, \"-Xnoagent\")) {\n-      warning(\"Option -Xnoagent was deprecated in JDK 22 and will likely be removed in a future release.\");\n@@ -2812,2 +2743,2 @@\n-      uintx max_tenuring_thresh = 0;\n-      if (!parse_uintx(tail, &max_tenuring_thresh, 0)) {\n+      uint max_tenuring_thresh = 0;\n+      if (!parse_uint(tail, &max_tenuring_thresh, 0)) {\n@@ -2896,4 +2827,0 @@\n-      \/\/ disable scavenge before parallel mark-compact\n-      if (FLAG_SET_CMDLINE(ScavengeBeforeFullGC, false) != JVMFlag::SUCCESS) {\n-        return JNI_EINVAL;\n-      }\n@@ -3122,21 +3049,1 @@\n-#if INCLUDE_CDS\n-  if (DumpSharedSpaces) {\n-    \/\/ Compiler threads may concurrently update the class metadata (such as method entries), so it's\n-    \/\/ unsafe with -Xshare:dump (which modifies the class metadata in place). Let's disable\n-    \/\/ compiler just to be safe.\n-    \/\/\n-    \/\/ Note: this is not a concern for dynamically dumping shared spaces, which makes a copy of the\n-    \/\/ class metadata instead of modifying them in place. The copy is inaccessible to the compiler.\n-    \/\/ TODO: revisit the following for the static archive case.\n-    set_mode_flags(_int);\n-\n-    \/\/ String deduplication may cause CDS to iterate the strings in different order from one\n-    \/\/ run to another which resulting in non-determinstic CDS archives.\n-    \/\/ Disable UseStringDeduplication while dumping CDS archive.\n-    UseStringDeduplication = false;\n-  }\n-\n-  \/\/ RecordDynamicDumpInfo is not compatible with ArchiveClassesAtExit\n-  if (ArchiveClassesAtExit != nullptr && RecordDynamicDumpInfo) {\n-    jio_fprintf(defaultStream::output_stream(),\n-                \"-XX:+RecordDynamicDumpInfo cannot be used with -XX:ArchiveClassesAtExit.\\n\");\n+  if (!CDSConfig::check_vm_args_consistency(patch_mod_javabase, mode_flag_cmd_line)) {\n@@ -3146,33 +3053,0 @@\n-  if (ArchiveClassesAtExit == nullptr && !RecordDynamicDumpInfo) {\n-    DynamicDumpSharedSpaces = false;\n-  } else {\n-    DynamicDumpSharedSpaces = true;\n-  }\n-\n-  if (AutoCreateSharedArchive) {\n-    if (SharedArchiveFile == nullptr) {\n-      log_warning(cds)(\"-XX:+AutoCreateSharedArchive requires -XX:SharedArchiveFile\");\n-      return JNI_ERR;\n-    }\n-    if (ArchiveClassesAtExit != nullptr) {\n-      log_warning(cds)(\"-XX:+AutoCreateSharedArchive does not work with ArchiveClassesAtExit\");\n-      return JNI_ERR;\n-    }\n-  }\n-\n-  if (UseSharedSpaces && patch_mod_javabase) {\n-    no_shared_spaces(\"CDS is disabled when \" JAVA_BASE_NAME \" module is patched.\");\n-  }\n-  if (UseSharedSpaces && !DumpSharedSpaces && check_unsupported_cds_runtime_properties()) {\n-    UseSharedSpaces = false;\n-  }\n-\n-  if (DumpSharedSpaces || DynamicDumpSharedSpaces) {\n-    \/\/ Always verify non-system classes during CDS dump\n-    if (!BytecodeVerificationRemote) {\n-      BytecodeVerificationRemote = true;\n-      log_info(cds)(\"All non-system classes will be verified (-Xverify:remote) during CDS dump time.\");\n-    }\n-  }\n-#endif\n-\n@@ -3450,181 +3324,0 @@\n-void Arguments::set_shared_spaces_flags_and_archive_paths() {\n-  if (DumpSharedSpaces) {\n-    if (RequireSharedSpaces) {\n-      warning(\"Cannot dump shared archive while using shared archive\");\n-    }\n-    UseSharedSpaces = false;\n-  }\n-#if INCLUDE_CDS\n-  \/\/ Initialize shared archive paths which could include both base and dynamic archive paths\n-  \/\/ This must be after set_ergonomics_flags() called so flag UseCompressedOops is set properly.\n-  \/\/\n-  \/\/ UseSharedSpaces may be disabled if -XX:SharedArchiveFile is invalid.\n-  if (DumpSharedSpaces || UseSharedSpaces) {\n-    init_shared_archive_paths();\n-  }\n-#endif  \/\/ INCLUDE_CDS\n-}\n-\n-#if INCLUDE_CDS\n-\/\/ Sharing support\n-\/\/ Construct the path to the archive\n-char* Arguments::get_default_shared_archive_path() {\n-  if (_default_shared_archive_path == nullptr) {\n-    char jvm_path[JVM_MAXPATHLEN];\n-    os::jvm_path(jvm_path, sizeof(jvm_path));\n-    char *end = strrchr(jvm_path, *os::file_separator());\n-    if (end != nullptr) *end = '\\0';\n-    size_t jvm_path_len = strlen(jvm_path);\n-    size_t file_sep_len = strlen(os::file_separator());\n-    const size_t len = jvm_path_len + file_sep_len + 20;\n-    _default_shared_archive_path = NEW_C_HEAP_ARRAY(char, len, mtArguments);\n-    jio_snprintf(_default_shared_archive_path, len,\n-                LP64_ONLY(!UseCompressedOops ? \"%s%sclasses_nocoops.jsa\":) \"%s%sclasses.jsa\",\n-                jvm_path, os::file_separator());\n-  }\n-  return _default_shared_archive_path;\n-}\n-\n-int Arguments::num_archives(const char* archive_path) {\n-  if (archive_path == nullptr) {\n-    return 0;\n-  }\n-  int npaths = 1;\n-  char* p = (char*)archive_path;\n-  while (*p != '\\0') {\n-    if (*p == os::path_separator()[0]) {\n-      npaths++;\n-    }\n-    p++;\n-  }\n-  return npaths;\n-}\n-\n-void Arguments::extract_shared_archive_paths(const char* archive_path,\n-                                         char** base_archive_path,\n-                                         char** top_archive_path) {\n-  char* begin_ptr = (char*)archive_path;\n-  char* end_ptr = strchr((char*)archive_path, os::path_separator()[0]);\n-  if (end_ptr == nullptr || end_ptr == begin_ptr) {\n-    vm_exit_during_initialization(\"Base archive was not specified\", archive_path);\n-  }\n-  size_t len = end_ptr - begin_ptr;\n-  char* cur_path = NEW_C_HEAP_ARRAY(char, len + 1, mtInternal);\n-  strncpy(cur_path, begin_ptr, len);\n-  cur_path[len] = '\\0';\n-  *base_archive_path = cur_path;\n-\n-  begin_ptr = ++end_ptr;\n-  if (*begin_ptr == '\\0') {\n-    vm_exit_during_initialization(\"Top archive was not specified\", archive_path);\n-  }\n-  end_ptr = strchr(begin_ptr, '\\0');\n-  assert(end_ptr != nullptr, \"sanity\");\n-  len = end_ptr - begin_ptr;\n-  cur_path = NEW_C_HEAP_ARRAY(char, len + 1, mtInternal);\n-  strncpy(cur_path, begin_ptr, len + 1);\n-  *top_archive_path = cur_path;\n-}\n-\n-void Arguments::init_shared_archive_paths() {\n-  if (ArchiveClassesAtExit != nullptr) {\n-    assert(!RecordDynamicDumpInfo, \"already checked\");\n-    if (DumpSharedSpaces) {\n-      vm_exit_during_initialization(\"-XX:ArchiveClassesAtExit cannot be used with -Xshare:dump\");\n-    }\n-    check_unsupported_dumping_properties();\n-\n-    if (os::same_files(get_default_shared_archive_path(), ArchiveClassesAtExit)) {\n-      vm_exit_during_initialization(\n-        \"Cannot specify the default CDS archive for -XX:ArchiveClassesAtExit\", get_default_shared_archive_path());\n-    }\n-  }\n-\n-  if (SharedArchiveFile == nullptr) {\n-    SharedArchivePath = get_default_shared_archive_path();\n-  } else {\n-    int archives = num_archives(SharedArchiveFile);\n-    assert(archives > 0, \"must be\");\n-\n-    if (is_dumping_archive() && archives > 1) {\n-      vm_exit_during_initialization(\n-        \"Cannot have more than 1 archive file specified in -XX:SharedArchiveFile during CDS dumping\");\n-    }\n-\n-    if (DumpSharedSpaces) {\n-      assert(archives == 1, \"must be\");\n-      \/\/ Static dump is simple: only one archive is allowed in SharedArchiveFile. This file\n-      \/\/ will be overwritten no matter regardless of its contents\n-      SharedArchivePath = os::strdup_check_oom(SharedArchiveFile, mtArguments);\n-    } else {\n-      \/\/ SharedArchiveFile may specify one or two files. In case (c), the path for base.jsa\n-      \/\/ is read from top.jsa\n-      \/\/    (a) 1 file:  -XX:SharedArchiveFile=base.jsa\n-      \/\/    (b) 2 files: -XX:SharedArchiveFile=base.jsa:top.jsa\n-      \/\/    (c) 2 files: -XX:SharedArchiveFile=top.jsa\n-      \/\/\n-      \/\/ However, if either RecordDynamicDumpInfo or ArchiveClassesAtExit is used, we do not\n-      \/\/ allow cases (b) and (c). Case (b) is already checked above.\n-\n-      if (archives > 2) {\n-        vm_exit_during_initialization(\n-          \"Cannot have more than 2 archive files specified in the -XX:SharedArchiveFile option\");\n-      }\n-      if (archives == 1) {\n-        char* base_archive_path = nullptr;\n-        bool success =\n-          FileMapInfo::get_base_archive_name_from_header(SharedArchiveFile, &base_archive_path);\n-        if (!success) {\n-          \/\/ If +AutoCreateSharedArchive and the specified shared archive does not exist,\n-          \/\/ regenerate the dynamic archive base on default archive.\n-          if (AutoCreateSharedArchive && !os::file_exists(SharedArchiveFile)) {\n-            DynamicDumpSharedSpaces = true;\n-            ArchiveClassesAtExit = const_cast<char *>(SharedArchiveFile);\n-            SharedArchivePath = get_default_shared_archive_path();\n-            SharedArchiveFile = nullptr;\n-          } else {\n-            if (AutoCreateSharedArchive) {\n-              warning(\"-XX:+AutoCreateSharedArchive is unsupported when base CDS archive is not loaded. Run with -Xlog:cds for more info.\");\n-              AutoCreateSharedArchive = false;\n-            }\n-            no_shared_spaces(\"invalid archive\");\n-          }\n-        } else if (base_archive_path == nullptr) {\n-          \/\/ User has specified a single archive, which is a static archive.\n-          SharedArchivePath = const_cast<char *>(SharedArchiveFile);\n-        } else {\n-          \/\/ User has specified a single archive, which is a dynamic archive.\n-          SharedDynamicArchivePath = const_cast<char *>(SharedArchiveFile);\n-          SharedArchivePath = base_archive_path; \/\/ has been c-heap allocated.\n-        }\n-      } else {\n-        extract_shared_archive_paths((const char*)SharedArchiveFile,\n-                                      &SharedArchivePath, &SharedDynamicArchivePath);\n-        if (SharedArchivePath == nullptr) {\n-          assert(SharedDynamicArchivePath == nullptr, \"must be\");\n-          no_shared_spaces(\"invalid archive\");\n-        }\n-      }\n-\n-      if (SharedDynamicArchivePath != nullptr) {\n-        \/\/ Check for case (c)\n-        if (RecordDynamicDumpInfo) {\n-          vm_exit_during_initialization(\"-XX:+RecordDynamicDumpInfo is unsupported when a dynamic CDS archive is specified in -XX:SharedArchiveFile\",\n-                                        SharedArchiveFile);\n-        }\n-        if (ArchiveClassesAtExit != nullptr) {\n-          vm_exit_during_initialization(\"-XX:ArchiveClassesAtExit is unsupported when a dynamic CDS archive is specified in -XX:SharedArchiveFile\",\n-                                        SharedArchiveFile);\n-        }\n-      }\n-\n-      if (ArchiveClassesAtExit != nullptr && os::same_files(SharedArchiveFile, ArchiveClassesAtExit)) {\n-          vm_exit_during_initialization(\n-            \"Cannot have the same archive file specified for -XX:SharedArchiveFile and -XX:ArchiveClassesAtExit\",\n-            SharedArchiveFile);\n-      }\n-    }\n-  }\n-}\n-#endif \/\/ INCLUDE_CDS\n-\n@@ -3825,2 +3518,1 @@\n-#ifndef PRODUCT\n-  \/\/ UseDebuggerErgo is notproduct\n+#ifdef ASSERT\n@@ -3830,2 +3522,0 @@\n-#endif\n-#ifndef PRODUCT\n@@ -3838,1 +3528,0 @@\n-#endif\n@@ -3847,0 +3536,1 @@\n+#endif \/\/ ASSERT\n@@ -3996,6 +3686,0 @@\n-  if (CountCompiledCalls) {\n-    if (UseCounterDecay) {\n-      warning(\"UseCounterDecay disabled because CountCalls is set\");\n-      UseCounterDecay = false;\n-    }\n-  }\n@@ -4019,1 +3703,1 @@\n-  if (DumpSharedSpaces || RequireSharedSpaces) {\n+  if (CDSConfig::is_dumping_static_archive() || RequireSharedSpaces) {\n@@ -4029,1 +3713,1 @@\n-  if ((UseSharedSpaces && xshare_auto_cmd_line) ||\n+  if ((CDSConfig::is_using_archive() && xshare_auto_cmd_line) ||\n@@ -4063,0 +3747,5 @@\n+  \/\/ The VMThread needs to stop now and then to execute these debug options.\n+  if ((HandshakeALot || SafepointALot) && FLAG_IS_DEFAULT(GuaranteedSafepointInterval)) {\n+    FLAG_SET_DEFAULT(GuaranteedSafepointInterval, 1000);\n+  }\n+\n@@ -4081,1 +3770,1 @@\n-  set_shared_spaces_flags_and_archive_paths();\n+  CDSConfig::initialize();\n@@ -4103,0 +3792,11 @@\n+  if (FLAG_IS_DEFAULT(UseSecondarySupersTable)) {\n+    FLAG_SET_DEFAULT(UseSecondarySupersTable, VM_Version::supports_secondary_supers_table());\n+  } else if (UseSecondarySupersTable && !VM_Version::supports_secondary_supers_table()) {\n+    warning(\"UseSecondarySupersTable is not supported\");\n+    FLAG_SET_DEFAULT(UseSecondarySupersTable, false);\n+  }\n+  if (!UseSecondarySupersTable) {\n+    FLAG_SET_DEFAULT(StressSecondarySupers, false);\n+    FLAG_SET_DEFAULT(VerifySecondarySupers, false);\n+  }\n+\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":115,"deletions":415,"binary":false,"changes":530,"status":"modified"},{"patch":"@@ -251,1 +251,0 @@\n-  static void set_mode_flags(Mode mode);\n@@ -267,1 +266,0 @@\n-  static void set_shared_spaces_flags_and_archive_paths();\n@@ -370,7 +368,0 @@\n-\n-  static char*  _default_shared_archive_path;\n-  static char*  SharedArchivePath;\n-  static char*  SharedDynamicArchivePath;\n-  static void extract_shared_archive_paths(const char* archive_path,\n-                                         char** base_archive_path,\n-                                         char** top_archive_path) NOT_CDS_RETURN;\n@@ -380,1 +371,0 @@\n-  static int num_archives(const char* archive_path) NOT_CDS_RETURN_(0);\n@@ -385,4 +375,4 @@\n-  \/\/ parameter passed and returns the value in uintx_arg.  Returns\n-  \/\/ false otherwise, with uintx_arg undefined.\n-  static bool parse_uintx(const char* value, uintx* uintx_arg,\n-                          uintx min_size);\n+  \/\/ parameter passed and returns the value in uint_arg.  Returns\n+  \/\/ false otherwise, with uint_arg undefined.\n+  static bool parse_uint(const char* value, uint* uintx_arg,\n+                         uint min_size);\n@@ -448,2 +438,1 @@\n-  static const char* GetSharedArchivePath() { return SharedArchivePath; }\n-  static const char* GetSharedDynamicArchivePath() { return SharedDynamicArchivePath; }\n+  static void no_shared_spaces(const char* message);\n@@ -508,3 +497,0 @@\n-  static char* get_default_shared_archive_path() NOT_CDS_RETURN_(nullptr);\n-  static void  init_shared_archive_paths() NOT_CDS_RETURN;\n-\n@@ -513,0 +499,1 @@\n+  static void set_mode_flags(Mode mode);\n@@ -524,4 +511,0 @@\n-  static void check_unsupported_dumping_properties() NOT_CDS_RETURN;\n-\n-  static bool check_unsupported_cds_runtime_properties() NOT_CDS_RETURN0;\n-\n@@ -532,6 +515,0 @@\n-  static bool is_dumping_archive() { return DumpSharedSpaces || DynamicDumpSharedSpaces; }\n-\n-  static void assert_is_dumping_archive() {\n-    assert(Arguments::is_dumping_archive(), \"dump time only\");\n-  }\n-\n","filename":"src\/hotspot\/share\/runtime\/arguments.hpp","additions":6,"deletions":29,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -34,2 +34,2 @@\n-#include \"attachListener_linux.hpp\"\n-#include \"linuxAttachOperation.hpp\"\n+#include \"attachListener_posix.hpp\"\n+#include \"posixAttachOperation.hpp\"\n@@ -169,1 +169,1 @@\n-  LinuxAttachOperation* _attach_op;\n+  PosixAttachOperation* _attach_op;\n@@ -181,1 +181,1 @@\n-    , _attach_op(jcmd_stream ? LinuxAttachListener::get_current_op() : NULL)\n+    , _attach_op(jcmd_stream ? PosixAttachListener::get_current_op() : NULL)\n","filename":"src\/hotspot\/share\/runtime\/crac_structs.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -58,1 +58,1 @@\n- * true for notproduct and develop flags in product builds.\n+ * true for develop flags in product builds.\n@@ -62,1 +62,1 @@\n-  return is_notproduct() || is_develop();\n+  return is_develop();\n@@ -124,5 +124,0 @@\n-  if (is_notproduct() && is_product_build()) {\n-    jio_snprintf(buf, buflen, \"Error: VM option '%s' is notproduct and is available only in debug version of VM.\\n\",\n-                 _name);\n-    return JVMFlag::NOTPRODUCT_FLAG_BUT_PRODUCT_BUILD;\n-  }\n@@ -136,1 +131,1 @@\n-void fill_to_pos(outputStream* st, unsigned int req_pos) {\n+static void fill_to_pos(outputStream* st, unsigned int req_pos) {\n@@ -145,1 +140,1 @@\n-  \/\/ Don't print notproduct and develop flags in a product build.\n+  \/\/ Don't print develop flags in a product build.\n@@ -278,1 +273,0 @@\n-    \/\/      uintx MinRAMFraction                                     [ 1                         ...      18446744073709551615 ]                            {product} {default}\n@@ -348,1 +342,0 @@\n-    { KIND_NOT_PRODUCT, \"notproduct\" },\n@@ -464,6 +457,6 @@\n-\/\/                                                  dev     dev-pd  pro     pro-pd  notpro  range     constraint\n-enum FlagCounter_LP64  { LP64_RUNTIME_FLAGS(        ENUM_F, ENUM_F, ENUM_F, ENUM_F, ENUM_F, IGNORE_F, IGNORE_F)  num_flags_LP64   };\n-enum FlagCounter_ARCH  { ARCH_FLAGS(                ENUM_F,         ENUM_F,         ENUM_F, IGNORE_F, IGNORE_F)  num_flags_ARCH   };\n-enum FlagCounter_JVMCI { JVMCI_ONLY(JVMCI_FLAGS(    ENUM_F, ENUM_F, ENUM_F, ENUM_F, ENUM_F, IGNORE_F, IGNORE_F)) num_flags_JVMCI  };\n-enum FlagCounter_C1    { COMPILER1_PRESENT(C1_FLAGS(ENUM_F, ENUM_F, ENUM_F, ENUM_F, ENUM_F, IGNORE_F, IGNORE_F)) num_flags_C1     };\n-enum FlagCounter_C2    { COMPILER2_PRESENT(C2_FLAGS(ENUM_F, ENUM_F, ENUM_F, ENUM_F, ENUM_F, IGNORE_F, IGNORE_F)) num_flags_C2     };\n+\/\/                                                  dev     dev-pd  pro     pro-pd  range     constraint\n+enum FlagCounter_LP64  { LP64_RUNTIME_FLAGS(        ENUM_F, ENUM_F, ENUM_F, ENUM_F, IGNORE_F, IGNORE_F)  num_flags_LP64   };\n+enum FlagCounter_ARCH  { ARCH_FLAGS(                ENUM_F,         ENUM_F,         IGNORE_F, IGNORE_F)  num_flags_ARCH   };\n+enum FlagCounter_JVMCI { JVMCI_ONLY(JVMCI_FLAGS(    ENUM_F, ENUM_F, ENUM_F, ENUM_F, IGNORE_F, IGNORE_F)) num_flags_JVMCI  };\n+enum FlagCounter_C1    { COMPILER1_PRESENT(C1_FLAGS(ENUM_F, ENUM_F, ENUM_F, ENUM_F, IGNORE_F, IGNORE_F)) num_flags_C1     };\n+enum FlagCounter_C2    { COMPILER2_PRESENT(C2_FLAGS(ENUM_F, ENUM_F, ENUM_F, ENUM_F, IGNORE_F, IGNORE_F)) num_flags_C2     };\n@@ -509,1 +502,0 @@\n-const int NOTPROD_KIND     = JVMFlag::KIND_NOT_PRODUCT;\n@@ -516,1 +508,0 @@\n-#define INITIALIZE_NOTPROD_FLAG(   type, name, value, ...) JVMFlag(FLAG_MEMBER_ENUM(name), FLAG_TYPE(type), XSTR(name), (void*)&name, NOTPROD_KIND,    __VA_ARGS__),\n@@ -529,1 +520,0 @@\n-            INITIALIZE_NOTPROD_FLAG,     \\\n@@ -566,1 +556,1 @@\n-    \/\/ Don't report notproduct and develop flags in product builds.\n+    \/\/ Don't report develop flags in product builds.\n@@ -692,2 +682,1 @@\n-      assert((flags & KIND_NOT_PRODUCT) == 0 &&\n-             (flags & KIND_DEVELOP) == 0,\n+      assert((flags & KIND_DEVELOP) == 0,\n","filename":"src\/hotspot\/share\/runtime\/flags\/jvmFlag.cpp","additions":13,"deletions":24,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -67,9 +67,8 @@\n-    KIND_NOT_PRODUCT        = 1 << 8,\n-    KIND_DEVELOP            = 1 << 9,\n-    KIND_PLATFORM_DEPENDENT = 1 << 10,\n-    KIND_C1                 = 1 << 11,\n-    KIND_C2                 = 1 << 12,\n-    KIND_ARCH               = 1 << 13,\n-    KIND_LP64_PRODUCT       = 1 << 14,\n-    KIND_JVMCI              = 1 << 15,\n-    KIND_RESTORE_SETTABLE   = 1 << 16,\n+    KIND_DEVELOP            = 1 << 8,\n+    KIND_PLATFORM_DEPENDENT = 1 << 9,\n+    KIND_C1                 = 1 << 10,\n+    KIND_C2                 = 1 << 11,\n+    KIND_ARCH               = 1 << 12,\n+    KIND_LP64_PRODUCT       = 1 << 13,\n+    KIND_JVMCI              = 1 << 14,\n+    KIND_RESTORE_SETTABLE   = 1 << 15,\n@@ -118,2 +117,1 @@\n-    DEVELOPER_FLAG_BUT_PRODUCT_BUILD,\n-    NOTPRODUCT_FLAG_BUT_PRODUCT_BUILD\n+    DEVELOPER_FLAG_BUT_PRODUCT_BUILD\n@@ -252,1 +250,0 @@\n-  bool is_notproduct() const      { return (_flags & KIND_NOT_PRODUCT) != 0;                  }\n","filename":"src\/hotspot\/share\/runtime\/flags\/jvmFlag.hpp","additions":10,"deletions":13,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -39,1 +39,0 @@\n-\/\/ notproduct flags are settable \/ visible only during development and are not declared in the PRODUCT version\n@@ -124,1 +123,0 @@\n-                           notproduct,                                      \\\n@@ -148,1 +146,0 @@\n-                           notproduct,                                      \\\n@@ -161,1 +158,0 @@\n-                      notproduct,                                           \\\n@@ -165,1 +161,1 @@\n-  notproduct(bool, CheckCompressedOops, true,                               \\\n+  develop(bool, CheckCompressedOops, true,                                  \\\n@@ -228,4 +224,0 @@\n-  product(uintx, NUMAPageScanRate, 256,                                     \\\n-          \"Maximum number of pages to include in the page scan procedure\")  \\\n-          range(0, max_uintx)                                               \\\n-                                                                            \\\n@@ -249,0 +241,2 @@\n+  product(bool, UseIntPolyIntrinsics, false, DIAGNOSTIC,                   \\\n+          \"Use intrinsics for sun.security.util.math.intpoly.MontgomeryIntegerPolynomialP256\") \\\n@@ -294,1 +288,1 @@\n-  notproduct(bool, TraceCodeBlobStacks, false,                              \\\n+  develop(bool, TraceCodeBlobStacks, false,                                 \\\n@@ -297,1 +291,1 @@\n-  notproduct(bool, PrintRewrites, false,                                    \\\n+  develop(bool, PrintRewrites, false,                                       \\\n@@ -303,0 +297,3 @@\n+  product(size_t, InlineCacheBufferSize, 10*K, EXPERIMENTAL,                \\\n+          \"InlineCacheBuffer size\")                                         \\\n+                                                                            \\\n@@ -393,1 +390,1 @@\n-  notproduct(ccstrlist, DeoptimizeOnlyAt, \"\",                               \\\n+  develop(ccstrlist, DeoptimizeOnlyAt, \"\",                                  \\\n@@ -399,1 +396,1 @@\n-  notproduct(bool, ZombieALot, false,                                       \\\n+  develop(bool, ZombieALot, false,                                          \\\n@@ -402,1 +399,1 @@\n-  notproduct(bool, WalkStackALot, false,                                    \\\n+  develop(bool, WalkStackALot, false,                                       \\\n@@ -428,1 +425,1 @@\n-  notproduct(bool, VerifyLastFrame, false,                                  \\\n+  develop(bool, VerifyLastFrame, false,                                     \\\n@@ -438,0 +435,4 @@\n+  product(uint64_t, AbortVMOnSafepointTimeoutDelay, 0, DIAGNOSTIC,          \\\n+          \"Delay in milliseconds for option AbortVMOnSafepointTimeout\")     \\\n+          range(0, max_jlong)                                               \\\n+                                                                            \\\n@@ -451,1 +452,1 @@\n-  product(uintx, LogEventsBufferEntries, 20, DIAGNOSTIC,                    \\\n+  product(int, LogEventsBufferEntries, 20, DIAGNOSTIC,                      \\\n@@ -467,1 +468,1 @@\n-  notproduct(bool, VerifyCodeCache, false,                                  \\\n+  develop(bool, VerifyCodeCache, false,                                     \\\n@@ -473,1 +474,1 @@\n-  notproduct(bool, ZapVMHandleArea, trueInDebug,                            \\\n+  develop(bool, ZapVMHandleArea, trueInDebug,                               \\\n@@ -476,1 +477,1 @@\n-  notproduct(bool, ZapStackSegments, trueInDebug,                           \\\n+  develop(bool, ZapStackSegments, trueInDebug,                              \\\n@@ -482,3 +483,0 @@\n-  develop(bool, CheckZapUnusedHeapArea, false,                              \\\n-          \"Check zapping of unused heap space\")                             \\\n-                                                                            \\\n@@ -488,0 +486,3 @@\n+  develop(bool, ZapTLAB, trueInDebug,                                       \\\n+          \"Zap allocated TLABs\")                                            \\\n+                                                                            \\\n@@ -547,1 +548,2 @@\n-          \"Dump heap to file before any major stop-the-world GC\")           \\\n+          \"Dump heap to file before any major stop-the-world GC \"           \\\n+          \"(also see FullGCHeapDumpLimit, HeapDumpPath, HeapDumpGzipLevel)\")\\\n@@ -550,1 +552,7 @@\n-          \"Dump heap to file after any major stop-the-world GC\")            \\\n+          \"Dump heap to file after any major stop-the-world GC \"            \\\n+          \"(also see FullGCHeapDumpLimit, HeapDumpPath, HeapDumpGzipLevel)\")\\\n+                                                                            \\\n+  product(uint, FullGCHeapDumpLimit, 0, MANAGEABLE,                         \\\n+          \"Limit the number of heap dumps triggered by \"                    \\\n+          \"HeapDumpBeforeFullGC or HeapDumpAfterFullGC \"                    \\\n+          \"(0 means no limit)\")                                             \\\n@@ -554,1 +562,2 @@\n-          \"from JVM\")                                                       \\\n+          \"from JVM \"                                                       \\\n+          \"(also see HeapDumpPath, HeapDumpGzipLevel)\")                     \\\n@@ -557,1 +566,2 @@\n-          \"When HeapDumpOnOutOfMemoryError is on, the path (filename or \"   \\\n+          \"When HeapDumpOnOutOfMemoryError, HeapDumpBeforeFullGC \"          \\\n+          \"or HeapDumpAfterFullGC is on, the path (filename or \"            \\\n@@ -561,2 +571,3 @@\n-  product(intx, HeapDumpGzipLevel, 0, MANAGEABLE,                           \\\n-          \"When HeapDumpOnOutOfMemoryError is on, the gzip compression \"    \\\n+  product(int, HeapDumpGzipLevel, 0, MANAGEABLE,                            \\\n+          \"When HeapDumpOnOutOfMemoryError, HeapDumpBeforeFullGC \"          \\\n+          \"or HeapDumpAfterFullGC is on, the gzip compression \"             \\\n@@ -613,1 +624,1 @@\n-  notproduct(bool, PrintNMethodStatistics, false,                           \\\n+  develop(bool, PrintNMethodStatistics, false,                              \\\n@@ -670,4 +681,0 @@\n-  product(bool, RegisterFinalizersAtInit, true,                             \\\n-          \"Register finalizable objects at end of Object.<init> or \"        \\\n-          \"after allocation\")                                               \\\n-                                                                            \\\n@@ -690,1 +697,1 @@\n-  notproduct(bool, PrintSystemDictionaryAtExit, false,                      \\\n+  develop(bool, PrintSystemDictionaryAtExit, false,                         \\\n@@ -693,1 +700,1 @@\n-  notproduct(bool, PrintClassLoaderDataGraphAtExit, false,                  \\\n+  develop(bool, PrintClassLoaderDataGraphAtExit, false,                     \\\n@@ -701,1 +708,1 @@\n-          \"Throw away obvious excess yield calls\")                          \\\n+             \"(Deprecated) Throw away obvious excess yield calls\")          \\\n@@ -734,1 +741,1 @@\n-          \"at one time (minimum is 1024).\")                      \\\n+          \"at one time (minimum is 1024).\")                                 \\\n@@ -737,1 +744,5 @@\n-  product(intx, MonitorUsedDeflationThreshold, 90, DIAGNOSTIC,              \\\n+  product(intx, MonitorUnlinkBatch, 500, DIAGNOSTIC,                        \\\n+          \"The maximum number of monitors to unlink in one batch. \")        \\\n+          range(1, max_jint)                                                \\\n+                                                                            \\\n+  product(int, MonitorUsedDeflationThreshold, 90, DIAGNOSTIC,               \\\n@@ -739,3 +750,2 @@\n-          \"off). The check is performed on GuaranteedSafepointInterval, \"   \\\n-          \"AsyncDeflationInterval or GuaranteedAsyncDeflationInterval, \"    \\\n-          \"whichever is lower.\")                                            \\\n+          \"off). The check is performed on AsyncDeflationInterval or \"      \\\n+          \"GuaranteedAsyncDeflationInterval, whichever is lower.\")          \\\n@@ -794,1 +804,1 @@\n-          \"Preserve RuntimeInvisibleAnnotations as well \"                   \\\n+          \"(Deprecated) Preserve RuntimeInvisibleAnnotations as well \"      \\\n@@ -803,1 +813,1 @@\n-  notproduct(bool, PrintFieldLayout, false,                                 \\\n+  develop(bool, PrintFieldLayout, false,                                    \\\n@@ -839,0 +849,7 @@\n+  product(intx, UserThreadWaitAttemptsAtExit, 30,                           \\\n+          \"The number of times to wait for user threads to stop executing \" \\\n+          \"native code during JVM exit. Each wait lasts 10 milliseconds. \"  \\\n+          \"The maximum number of waits is 1000, to wait at most 10 \"        \\\n+          \"seconds.\")                                                       \\\n+          range(0, 1000)                                                    \\\n+                                                                            \\\n@@ -860,8 +877,2 @@\n-  develop(bool, TraceICs, false,                                            \\\n-          \"Trace inline cache changes\")                                     \\\n-                                                                            \\\n-  notproduct(bool, TraceInvocationCounterOverflow, false,                   \\\n-          \"Trace method invocation counter overflow\")                       \\\n-                                                                            \\\n-  develop(bool, TraceInlineCacheClearing, false,                            \\\n-          \"Trace clearing of inline caches in nmethods\")                    \\\n+  develop(bool, TraceBytecodesTruncated, false,                             \\\n+          \"Truncate non control-flow bytecode when tracing bytecode\")       \\\n@@ -887,13 +898,0 @@\n-  develop(bool, TraceICBuffer, false,                                       \\\n-          \"Trace usage of IC buffer\")                                       \\\n-                                                                            \\\n-  develop(bool, TraceCompiledIC, false,                                     \\\n-          \"Trace changes of compiled IC\")                                   \\\n-                                                                            \\\n-  develop(bool, FLSVerifyDictionary, false,                                 \\\n-          \"Do lots of (expensive) FLS dictionary verification\")             \\\n-                                                                            \\\n-  product(uintx, ProcessDistributionStride, 4,                              \\\n-          \"Stride through processors when distributing processes\")          \\\n-          range(0, max_juint)                                               \\\n-                                                                            \\\n@@ -967,1 +965,1 @@\n-          \"Use Notification Thread\")                                        \\\n+          \"(Deprecated) Use Notification Thread\")                           \\\n@@ -993,3 +991,0 @@\n-  product(bool, PrintMethodFlushingStatistics, false, DIAGNOSTIC,           \\\n-          \"print statistics about method flushing\")                         \\\n-                                                                            \\\n@@ -1023,1 +1018,1 @@\n-  notproduct(bool, PrintFlagsWithComments, false,                           \\\n+  develop(bool, PrintFlagsWithComments, false,                              \\\n@@ -1063,4 +1058,0 @@\n-  develop(bool, UseHeavyMonitors, false,                                    \\\n-          \"(Deprecated) Use heavyweight instead of lightweight Java \"       \\\n-          \"monitors\")                                                       \\\n-                                                                            \\\n@@ -1069,1 +1060,1 @@\n-          \"+UseHeavyMonitors\")                                              \\\n+          \"-XX:LockingMode=0 (LM_MONITOR)\")                                 \\\n@@ -1077,1 +1068,1 @@\n-  notproduct(bool, PrintSymbolTableSizeHistogram, false,                    \\\n+  develop(bool, PrintSymbolTableSizeHistogram, false,                       \\\n@@ -1103,1 +1094,1 @@\n-  notproduct(bool, TraceLivenessQuery, false,                               \\\n+  develop(bool, TraceLivenessQuery, false,                                  \\\n@@ -1106,1 +1097,1 @@\n-  notproduct(bool, CollectIndexSetStatistics, false,                        \\\n+  develop(bool, CollectIndexSetStatistics, false,                           \\\n@@ -1109,1 +1100,1 @@\n-  develop(intx, FastAllocateSizeLimit, 128*K,                               \\\n+  develop(int, FastAllocateSizeLimit, 128*K,                                \\\n@@ -1136,1 +1127,1 @@\n-  notproduct(bool, ICMissHistogram, false,                                  \\\n+  develop(bool, ICMissHistogram, false,                                     \\\n@@ -1162,1 +1153,1 @@\n-  notproduct(bool, TraceOnStackReplacement, false,                          \\\n+  develop(bool, TraceOnStackReplacement, false,                             \\\n@@ -1220,1 +1211,1 @@\n-  notproduct(bool, CrashGCForDumpingJavaThread, false,                      \\\n+  develop(bool, CrashGCForDumpingJavaThread, false,                         \\\n@@ -1228,3 +1219,0 @@\n-  product(bool, UseCounterDecay, true,                                      \\\n-          \"Adjust recompilation counters\")                                  \\\n-                                                                            \\\n@@ -1234,4 +1222,0 @@\n-  develop(intx, CounterDecayMinIntervalLength,   500,                       \\\n-          \"The minimum interval (in milliseconds) between invocation of \"   \\\n-          \"CounterDecay\")                                                   \\\n-                                                                            \\\n@@ -1242,1 +1226,1 @@\n-  product(intx,  AllocatePrefetchStyle, 1,                                  \\\n+  product(int,  AllocatePrefetchStyle, 1,                                   \\\n@@ -1249,1 +1233,1 @@\n-  product(intx,  AllocatePrefetchDistance, -1,                              \\\n+  product(int,  AllocatePrefetchDistance, -1,                               \\\n@@ -1254,1 +1238,1 @@\n-  product(intx,  AllocatePrefetchLines, 3,                                  \\\n+  product(int,  AllocatePrefetchLines, 3,                                   \\\n@@ -1258,1 +1242,1 @@\n-  product(intx,  AllocateInstancePrefetchLines, 1,                          \\\n+  product(int,  AllocateInstancePrefetchLines, 1,                           \\\n@@ -1263,1 +1247,1 @@\n-  product(intx,  AllocatePrefetchStepSize, 16,                              \\\n+  product(int,  AllocatePrefetchStepSize, 16,                               \\\n@@ -1295,1 +1279,1 @@\n-  product(intx, GuaranteedSafepointInterval, 1000, DIAGNOSTIC,              \\\n+  product(intx, GuaranteedSafepointInterval, 0, DIAGNOSTIC,                 \\\n@@ -1300,0 +1284,5 @@\n+  product(intx, ServiceThreadCleanupInterval, 1000, DIAGNOSTIC,             \\\n+          \"Wake the ServiceThread to do periodic cleanup checks every so \"  \\\n+          \"many milliseconds (0 means none)\")                               \\\n+          range(0, max_jint)                                                \\\n+                                                                            \\\n@@ -1316,1 +1305,1 @@\n-  develop(intx, StackPrintLimit, 100,                                       \\\n+  develop(int, StackPrintLimit, 100,                                        \\\n@@ -1323,1 +1312,1 @@\n-  notproduct(intx, MaxElementPrintSize, 256,                                \\\n+  develop(int, MaxElementPrintSize, 256,                                    \\\n@@ -1326,1 +1315,1 @@\n-  notproduct(intx, MaxSubklassPrintSize, 4,                                 \\\n+  develop(intx, MaxSubklassPrintSize, 4,                                    \\\n@@ -1337,4 +1326,1 @@\n-  develop(intx, DontYieldALotInterval,    10,                               \\\n-          \"Interval between which yields will be dropped (milliseconds)\")   \\\n-                                                                            \\\n-  notproduct(intx, DeoptimizeALotInterval,     5,                           \\\n+  develop(intx, DeoptimizeALotInterval,     5,                              \\\n@@ -1343,1 +1329,1 @@\n-  notproduct(intx, ZombieALotInterval,     5,                               \\\n+  develop(intx, ZombieALotInterval,     5,                                  \\\n@@ -1421,1 +1407,1 @@\n-          range(1*M, 3*G)                                                   \\\n+          range(1*M, LP64_ONLY(4*G) NOT_LP64(max_uintx))                    \\\n@@ -1427,0 +1413,3 @@\n+  develop(bool, RandomizeClassSpaceLocation, true,                          \\\n+          \"Randomize location of class space.\")                             \\\n+                                                                            \\\n@@ -1447,5 +1436,0 @@\n-  product(bool, ShrinkHeapInSteps, true,                                    \\\n-          \"When disabled, informs the GC to shrink the java heap directly\"  \\\n-          \" to the target size at the next full GC rather than requiring\"   \\\n-          \" smaller steps during multiple full GCs.\")                       \\\n-                                                                            \\\n@@ -1465,1 +1449,1 @@\n-  product(uintx, MaxMetaspaceFreeRatio,    70,                              \\\n+  product(uint, MaxMetaspaceFreeRatio,    70,                               \\\n@@ -1471,1 +1455,1 @@\n-  product(uintx, MinMetaspaceFreeRatio,    40,                              \\\n+  product(uint, MinMetaspaceFreeRatio,    40,                               \\\n@@ -1573,1 +1557,1 @@\n-  notproduct(bool, ExitOnFullCodeCache, false,                              \\\n+  develop(bool, ExitOnFullCodeCache, false,                                 \\\n@@ -1722,1 +1706,1 @@\n-  notproduct(bool, UseDebuggerErgo, false,                                  \\\n+  develop(bool, UseDebuggerErgo, false,                                     \\\n@@ -1726,1 +1710,1 @@\n-  notproduct(bool, UseDebuggerErgo1, false,                                 \\\n+  develop(bool, UseDebuggerErgo1, false,                                    \\\n@@ -1730,1 +1714,1 @@\n-  notproduct(bool, UseDebuggerErgo2, false,                                 \\\n+  develop(bool, UseDebuggerErgo2, false,                                    \\\n@@ -1733,1 +1717,1 @@\n-  notproduct(bool, EnableJVMTIStackDepthAsserts, true,                      \\\n+  develop(bool, EnableJVMTIStackDepthAsserts, true,                         \\\n@@ -1750,1 +1734,1 @@\n-  product(intx, PerfDataSamplingInterval, 50,                               \\\n+  product(int, PerfDataSamplingInterval, 50,                                \\\n@@ -1893,4 +1877,0 @@\n-  product(size_t, ArrayAllocatorMallocLimit, SIZE_MAX, EXPERIMENTAL,        \\\n-          \"Allocation less than this value will be allocated \"              \\\n-          \"using malloc. Larger allocations will use mmap.\")                \\\n-                                                                            \\\n@@ -1977,1 +1957,2 @@\n-                \"Allow allocating fields in empty slots of super-classes\")  \\\n+          \"(Deprecated) Allow allocating fields in empty slots of \"         \\\n+          \"super-classes\")                                                  \\\n@@ -1987,3 +1968,0 @@\n-  develop(bool, TraceOptimizedUpcallStubs, false,                           \\\n-                \"Trace optimized upcall stub generation\")                   \\\n-                                                                            \\\n@@ -2047,1 +2025,1 @@\n-  product(int, LockingMode, LM_LEGACY, EXPERIMENTAL,                        \\\n+  product(int, LockingMode, LM_LIGHTWEIGHT,                                 \\\n@@ -2050,2 +2028,2 @@\n-          \"1: monitors & legacy stack-locking (LM_LEGACY, default), \"       \\\n-          \"2: monitors & new lightweight locking (LM_LIGHTWEIGHT)\")         \\\n+          \"1: monitors & legacy stack-locking (LM_LEGACY), \"                \\\n+          \"2: monitors & new lightweight locking (LM_LIGHTWEIGHT, default)\") \\\n@@ -2054,1 +2032,1 @@\n-  product(uint, TrimNativeHeapInterval, 0, EXPERIMENTAL,                    \\\n+  product(uint, TrimNativeHeapInterval, 0,                                  \\\n@@ -2060,0 +2038,24 @@\n+                                                                            \\\n+  develop(bool, SimulateFullAddressSpace, false,                            \\\n+          \"Simulates a very populated, fragmented address space; no \"       \\\n+          \"targeted reservations will succeed.\")                            \\\n+                                                                            \\\n+  product(bool, ProfileExceptionHandlers, true,                             \\\n+          \"Profile exception handlers\")                                     \\\n+                                                                            \\\n+  product(bool, AlwaysRecordEvolDependencies, true, EXPERIMENTAL,           \\\n+                \"Unconditionally record nmethod dependencies on class \"     \\\n+                \"rewriting\/transformation independently of the JVMTI \"      \\\n+                \"can_{retransform\/redefine}_classes capabilities.\")         \\\n+                                                                            \\\n+  product(bool, UseSecondarySupersCache, true, DIAGNOSTIC,                  \\\n+                \"Use secondary supers cache during subtype checks.\")        \\\n+                                                                            \\\n+  product(bool, UseSecondarySupersTable, false, DIAGNOSTIC,                 \\\n+                \"Use hash table to lookup secondary supers.\")               \\\n+                                                                            \\\n+  product(bool, VerifySecondarySupers, false, DIAGNOSTIC,                   \\\n+          \"Check that linear and hashed secondary lookups return the same result.\") \\\n+                                                                            \\\n+  product(bool, StressSecondarySupers, false, DIAGNOSTIC,                   \\\n+          \"Use a terrible hash function in order to generate many collisions.\") \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":131,"deletions":129,"binary":false,"changes":260,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -55,0 +55,1 @@\n+class InternalOOMEMark;\n@@ -123,1 +124,1 @@\n-  CompiledMethod*       _deopt_nmethod;         \/\/ CompiledMethod that is currently being deoptimized\n+  nmethod*      _deopt_nmethod;                  \/\/ nmethod that is currently being deoptimized\n@@ -161,2 +162,0 @@\n-  volatile intptr_t _Stalled;\n-\n@@ -197,4 +196,0 @@\n-  MonitorChunk* _monitor_chunks;              \/\/ Contains the off stack monitors\n-                                              \/\/ allocated during deoptimization\n-                                              \/\/ and by JNI_MonitorEnter\/Exit\n-\n@@ -228,1 +223,0 @@\n-  void install_async_exception(AsyncExceptionHandshake* aec = nullptr);\n@@ -231,0 +225,1 @@\n+  void install_async_exception(AsyncExceptionHandshake* aec = nullptr);\n@@ -261,0 +256,1 @@\n+  bool is_in_no_safepoint_scope() { return _no_safepoint_count > 0; }\n@@ -320,0 +316,2 @@\n+  bool                  _is_disable_suspend;             \/\/ JVMTI suspend is temporarily disabled; used on current thread only\n+  bool                  _VTMS_transition_mark;           \/\/ used for sync between VTMS transitions and disablers\n@@ -337,0 +335,2 @@\n+  \/\/ In scope of an InternalOOMEMark?\n+  bool _is_in_internal_oome_mark;\n@@ -352,4 +352,0 @@\n-  \/\/ True if in a runtime call from compiled code that will deoptimize\n-  \/\/ and re-execute a failed heap allocation in the interpreter.\n-  bool      _in_retryable_allocation;\n-\n@@ -382,0 +378,4 @@\n+  \/\/ This field is used to keep an nmethod visible to the GC so that it and its contained oops can\n+  \/\/ be kept alive\n+  nmethod*  _live_nmethod;\n+\n@@ -414,0 +414,9 @@\n+  void set_live_nmethod(nmethod* nm) {\n+    assert(_live_nmethod == nullptr, \"only one\");\n+    _live_nmethod = nm;\n+  }\n+\n+  void clear_live_nmethod() {\n+    _live_nmethod = nullptr;\n+  }\n+\n@@ -453,0 +462,1 @@\n+\n@@ -454,7 +464,2 @@\n-#ifdef _LP64\n-  int64_t _held_monitor_count;  \/\/ used by continuations for fast lock detection\n-  int64_t _jni_monitor_count;\n-#else\n-  int32_t _held_monitor_count;  \/\/ used by continuations for fast lock detection\n-  int32_t _jni_monitor_count;\n-#endif\n+  intx _held_monitor_count;  \/\/ used by continuations for fast lock detection\n+  intx _jni_monitor_count;\n@@ -529,0 +534,1 @@\n+  oop vthread_or_thread() const;\n@@ -602,2 +608,2 @@\n-  void inc_held_monitor_count(int i = 1, bool jni = false);\n-  void dec_held_monitor_count(int i = 1, bool jni = false);\n+  void inc_held_monitor_count(intx i = 1, bool jni = false);\n+  void dec_held_monitor_count(intx i = 1, bool jni = false);\n@@ -605,2 +611,2 @@\n-  int64_t held_monitor_count() { return (int64_t)_held_monitor_count; }\n-  int64_t jni_monitor_count()  { return (int64_t)_jni_monitor_count;  }\n+  intx held_monitor_count() { return _held_monitor_count; }\n+  intx jni_monitor_count()  { return _jni_monitor_count;  }\n@@ -654,0 +660,6 @@\n+  bool is_disable_suspend() const                { return _is_disable_suspend; }\n+  void toggle_is_disable_suspend()               { _is_disable_suspend = !_is_disable_suspend; };\n+\n+  bool VTMS_transition_mark() const              { return Atomic::load(&_VTMS_transition_mark); }\n+  void set_VTMS_transition_mark(bool val)        { Atomic::store(&_VTMS_transition_mark, val); }\n+\n@@ -666,1 +678,1 @@\n-  \/\/ Fast-locking support\n+  \/\/ Stack-locking support (not for LM_LIGHTWEIGHT)\n@@ -689,2 +701,2 @@\n-  void set_deopt_compiled_method(CompiledMethod* nm)  { _deopt_nmethod = nm; }\n-  CompiledMethod* deopt_compiled_method()        { return _deopt_nmethod; }\n+  void set_deopt_compiled_method(nmethod* nm)    { _deopt_nmethod = nm; }\n+  nmethod* deopt_compiled_method()               { return _deopt_nmethod; }\n@@ -704,0 +716,4 @@\n+  \/\/ Is thread in scope of an InternalOOMEMark?\n+  bool is_in_internal_oome_mark() const          { return _is_in_internal_oome_mark; }\n+  void set_is_in_internal_oome_mark(bool b)      { _is_in_internal_oome_mark = b;    }\n+\n@@ -713,3 +729,0 @@\n-  virtual bool in_retryable_allocation() const    { return _in_retryable_allocation; }\n-  void set_in_retryable_allocation(bool b)        { _in_retryable_allocation = b; }\n-\n@@ -814,0 +827,1 @@\n+  static ByteSize jni_monitor_count_offset()  { return byte_offset_of(JavaThread, _jni_monitor_count); }\n@@ -818,0 +832,1 @@\n+  static ByteSize is_disable_suspend_offset()        { return byte_offset_of(JavaThread, _is_disable_suspend); }\n@@ -865,6 +880,0 @@\n- private:\n-  void set_monitor_chunks(MonitorChunk* monitor_chunks) { _monitor_chunks = monitor_chunks; }\n-\n-  MonitorChunk* monitor_chunks() const           { return _monitor_chunks; }\n-  void add_monitor_chunk(MonitorChunk* chunk);\n-  void remove_monitor_chunk(MonitorChunk* chunk);\n@@ -893,2 +902,2 @@\n-  void oops_do_frames(OopClosure* f, CodeBlobClosure* cf);\n-  void oops_do_no_frames(OopClosure* f, CodeBlobClosure* cf);\n+  void oops_do_frames(OopClosure* f, NMethodClosure* cf);\n+  void oops_do_no_frames(OopClosure* f, NMethodClosure* cf);\n@@ -897,1 +906,1 @@\n-  virtual void nmethods_do(CodeBlobClosure* cf);\n+  virtual void nmethods_do(NMethodClosure* cf);\n@@ -907,0 +916,1 @@\n+  const char* name_raw() const;\n@@ -1151,0 +1161,4 @@\n+  \/\/ This is only for use by JVMTI RawMonitorWait. It emulates the actions of\n+  \/\/ the Java code in Object::wait which are not present in RawMonitorWait.\n+  bool get_and_clear_interrupted();\n+\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":53,"deletions":39,"binary":false,"changes":92,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,0 +26,1 @@\n+#include \"cds\/cdsConfig.hpp\"\n@@ -32,1 +33,0 @@\n-#include \"code\/icBuffer.hpp\"\n@@ -42,0 +42,5 @@\n+#include \"nmt\/mallocHeader.inline.hpp\"\n+#include \"nmt\/mallocTracker.hpp\"\n+#include \"nmt\/memTracker.inline.hpp\"\n+#include \"nmt\/nmtCommon.hpp\"\n+#include \"nmt\/nmtPreInit.hpp\"\n@@ -44,1 +49,1 @@\n-#include \"prims\/jvmtiAgent.hpp\"\n+#include \"prims\/jvmtiAgent.hpp\"\n@@ -66,5 +71,0 @@\n-#include \"services\/mallocTracker.hpp\"\n-#include \"services\/mallocHeader.inline.hpp\"\n-#include \"services\/memTracker.inline.hpp\"\n-#include \"services\/nmtPreInit.hpp\"\n-#include \"services\/nmtCommon.hpp\"\n@@ -73,0 +73,1 @@\n+#include \"utilities\/checkedCast.hpp\"\n@@ -76,0 +77,2 @@\n+#include \"utilities\/fastrand.hpp\"\n+#include \"utilities\/macros.hpp\"\n@@ -111,0 +114,10 @@\n+int os::vsnprintf(char* buf, size_t len, const char* fmt, va_list args) {\n+  ALLOW_C_FUNCTION(::vsnprintf, int result = ::vsnprintf(buf, len, fmt, args);)\n+  \/\/ If an encoding error occurred (result < 0) then it's not clear\n+  \/\/ whether the buffer is NUL terminated, so ensure it is.\n+  if ((result < 0) && (len > 0)) {\n+    buf[len - 1] = '\\0';\n+  }\n+  return result;\n+}\n+\n@@ -139,1 +152,1 @@\n-  const int milliseconds_per_microsecond = 1000;\n+  const int milliseconds_per_second = 1000;\n@@ -141,1 +154,1 @@\n-    milliseconds_since_19700101 \/ milliseconds_per_microsecond;\n+    milliseconds_since_19700101 \/ milliseconds_per_second;\n@@ -143,1 +156,1 @@\n-    milliseconds_since_19700101 % milliseconds_per_microsecond;\n+    checked_cast<int>(milliseconds_since_19700101 % milliseconds_per_second);\n@@ -631,1 +644,1 @@\n-    \/\/ No need to fill with 0 because DumpSharedSpaces doesn't use these\n+    \/\/ No need to fill with 0 because CDS static dumping doesn't use these\n@@ -662,1 +675,1 @@\n-  if (DumpSharedSpaces) {\n+  if (CDSConfig::is_dumping_static_archive()) {\n@@ -931,7 +944,57 @@\n-ATTRIBUTE_NO_ASAN static void print_hex_readable_pointer(outputStream* st, address p,\n-                                                         int unitsize) {\n-  switch (unitsize) {\n-    case 1: st->print(\"%02x\", *(u1*)p); break;\n-    case 2: st->print(\"%04x\", *(u2*)p); break;\n-    case 4: st->print(\"%08x\", *(u4*)p); break;\n-    case 8: st->print(\"%016\" FORMAT64_MODIFIER \"x\", *(u8*)p); break;\n+ATTRIBUTE_NO_ASAN static bool read_safely_from(intptr_t* p, intptr_t* result) {\n+  const intptr_t errval = 0x1717;\n+  intptr_t i = SafeFetchN(p, errval);\n+  if (i == errval) {\n+    i = SafeFetchN(p, ~errval);\n+    if (i == ~errval) {\n+      return false;\n+    }\n+  }\n+  (*result) = i;\n+  return true;\n+}\n+\n+static void print_hex_location(outputStream* st, address p, int unitsize) {\n+  assert(is_aligned(p, unitsize), \"Unaligned\");\n+  address pa = align_down(p, sizeof(intptr_t));\n+#ifndef _LP64\n+  \/\/ Special handling for printing qwords on 32-bit platforms\n+  if (unitsize == 8) {\n+    intptr_t i1, i2;\n+    if (read_safely_from((intptr_t*)pa, &i1) &&\n+        read_safely_from((intptr_t*)pa + 1, &i2)) {\n+      const uint64_t value =\n+        LITTLE_ENDIAN_ONLY((((uint64_t)i2) << 32) | i1)\n+        BIG_ENDIAN_ONLY((((uint64_t)i1) << 32) | i2);\n+      st->print(\"%016\" FORMAT64_MODIFIER \"x\", value);\n+    } else {\n+      st->print_raw(\"????????????????\");\n+    }\n+    return;\n+  }\n+#endif \/\/ 32-bit, qwords\n+  intptr_t i = 0;\n+  if (read_safely_from((intptr_t*)pa, &i)) {\n+    \/\/ bytes:   CA FE BA BE DE AD C0 DE\n+    \/\/ bytoff:   0  1  2  3  4  5  6  7\n+    \/\/ LE bits:  0  8 16 24 32 40 48 56\n+    \/\/ BE bits: 56 48 40 32 24 16  8  0\n+    const int offset = (int)(p - (address)pa);\n+    const int bitoffset =\n+      LITTLE_ENDIAN_ONLY(offset * BitsPerByte)\n+      BIG_ENDIAN_ONLY((int)((sizeof(intptr_t) - unitsize - offset) * BitsPerByte));\n+    const int bitfieldsize = unitsize * BitsPerByte;\n+    intptr_t value = bitfield(i, bitoffset, bitfieldsize);\n+    switch (unitsize) {\n+      case 1: st->print(\"%02x\", (u1)value); break;\n+      case 2: st->print(\"%04x\", (u2)value); break;\n+      case 4: st->print(\"%08x\", (u4)value); break;\n+      case 8: st->print(\"%016\" FORMAT64_MODIFIER \"x\", (u8)value); break;\n+    }\n+  } else {\n+    switch (unitsize) {\n+      case 1: st->print_raw(\"??\"); break;\n+      case 2: st->print_raw(\"????\"); break;\n+      case 4: st->print_raw(\"????????\"); break;\n+      case 8: st->print_raw(\"????????????????\"); break;\n+    }\n@@ -958,5 +1021,1 @@\n-    if (is_readable_pointer(p)) {\n-      print_hex_readable_pointer(st, p, unitsize);\n-    } else {\n-      st->print(\"%*.*s\", 2*unitsize, 2*unitsize, \"????????????????\");\n-    }\n+    print_hex_location(st, p, unitsize);\n@@ -1059,0 +1118,4 @@\n+static constexpr int secs_per_day  = 86400;\n+static constexpr int secs_per_hour = 3600;\n+static constexpr int secs_per_min  = 60;\n+\n@@ -1060,3 +1123,0 @@\n-  const int secs_per_day  = 86400;\n-  const int secs_per_hour = 3600;\n-  const int secs_per_min  = 60;\n@@ -1088,0 +1148,6 @@\n+  st->print(\" elapsed time: \");\n+  print_elapsed_time(st, t);\n+  st->cr();\n+}\n+\n+void os::print_elapsed_time(outputStream* st, double time) {\n@@ -1089,2 +1155,2 @@\n-  int eltime = (int)t;  \/\/ elapsed time in seconds\n-  int eltimeFraction = (int) ((t - eltime) * 1000000);\n+  int eltime = (int)time;  \/\/ elapsed time in seconds\n+  int eltimeFraction = (int) ((time - eltime) * 1000000);\n@@ -1100,1 +1166,1 @@\n-  st->print_cr(\" elapsed time: %d.%06d seconds (%dd %dh %dm %ds)\", eltime, eltimeFraction, eldays, elhours, elmins, elsecs);\n+  st->print(\"%d.%06d seconds (%dd %dh %dm %ds)\", eltime, eltimeFraction, eldays, elhours, elmins, elsecs);\n@@ -1147,0 +1213,2 @@\n+#if !INCLUDE_ASAN\n+\n@@ -1201,1 +1269,1 @@\n-    Klass* k = CompressedKlassPointers::decode_raw(narrow_klass);\n+    Klass* k = CompressedKlassPointers::decode_without_asserts(narrow_klass);\n@@ -1233,0 +1301,2 @@\n+#endif \/\/ !INCLUDE_ASAN\n+\n@@ -1234,0 +1304,1 @@\n+\n@@ -1236,1 +1307,1 @@\n-bool is_pointer_bad(intptr_t* ptr) {\n+static bool is_pointer_bad(intptr_t* ptr) {\n@@ -1394,1 +1465,1 @@\n-    buf = (void *)((char *)buf + nBytes);\n+    buf = (void *)((char *)buf + res);\n@@ -1653,0 +1724,7 @@\n+\/\/ create binary file, rewriting existing file if required\n+int os::create_binary_file(const char* path, bool rewrite_existing) {\n+  int oflags = O_WRONLY | O_CREAT WINDOWS_ONLY(| O_BINARY);\n+  oflags |= rewrite_existing ? O_TRUNC : O_EXCL;\n+  return ::open(path, oflags, S_IREAD | S_IWRITE);\n+}\n+\n@@ -1759,0 +1837,3 @@\n+    log_debug(os, map)(\"Reserved \" RANGEFMT, RANGEFMTARGS(result, bytes));\n+  } else {\n+    log_info(os, map)(\"Reserve failed (%zu bytes)\", bytes);\n@@ -1763,2 +1844,197 @@\n-char* os::attempt_reserve_memory_at(char* addr, size_t bytes, bool executable) {\n-  char* result = pd_attempt_reserve_memory_at(addr, bytes, executable);\n+char* os::attempt_reserve_memory_at(char* addr, size_t bytes, bool executable, MEMFLAGS flag) {\n+  char* result = SimulateFullAddressSpace ? nullptr : pd_attempt_reserve_memory_at(addr, bytes, executable);\n+  if (result != nullptr) {\n+    MemTracker::record_virtual_memory_reserve((address)result, bytes, CALLER_PC, flag);\n+    log_debug(os, map)(\"Reserved \" RANGEFMT, RANGEFMTARGS(result, bytes));\n+  } else {\n+    log_info(os, map)(\"Attempt to reserve \" RANGEFMT \" failed\",\n+                      RANGEFMTARGS(addr, bytes));\n+  }\n+  return result;\n+}\n+\n+#ifdef ASSERT\n+static void print_points(const char* s, unsigned* points, unsigned num) {\n+  stringStream ss;\n+  for (unsigned i = 0; i < num; i ++) {\n+    ss.print(\"%u \", points[i]);\n+  }\n+  log_trace(os, map)(\"%s, %u Points: %s\", s, num, ss.base());\n+}\n+#endif\n+\n+\/\/ Helper for os::attempt_reserve_memory_between\n+\/\/ Given an array of things, shuffle them (Fisher-Yates)\n+template <typename T>\n+static void shuffle_fisher_yates(T* arr, unsigned num, FastRandom& frand) {\n+  for (unsigned i = num - 1; i >= 1; i--) {\n+    unsigned j = frand.next() % i;\n+    swap(arr[i], arr[j]);\n+  }\n+}\n+\n+\/\/ Helper for os::attempt_reserve_memory_between\n+\/\/ Given an array of things, do a hemisphere split such that the resulting\n+\/\/ order is: [first, last, first + 1, last - 1, ...]\n+template <typename T>\n+static void hemi_split(T* arr, unsigned num) {\n+  T* tmp = (T*)::alloca(sizeof(T) * num);\n+  for (unsigned i = 0; i < num; i++) {\n+    tmp[i] = arr[i];\n+  }\n+  for (unsigned i = 0; i < num; i++) {\n+    arr[i] = is_even(i) ? tmp[i \/ 2] : tmp[num - (i \/ 2) - 1];\n+  }\n+}\n+\n+\/\/ Given an address range [min, max), attempts to reserve memory within this area, with the given alignment.\n+\/\/ If randomize is true, the location will be randomized.\n+char* os::attempt_reserve_memory_between(char* min, char* max, size_t bytes, size_t alignment, bool randomize) {\n+\n+  \/\/ Please keep the following constants in sync with the companion gtests:\n+\n+  \/\/ Number of mmap attemts we will undertake.\n+  constexpr unsigned max_attempts = 32;\n+\n+  \/\/ In randomization mode: We require a minimum number of possible attach points for\n+  \/\/ randomness. Below that we refuse to reserve anything.\n+  constexpr unsigned min_random_value_range = 16;\n+\n+  \/\/ In randomization mode: If the possible value range is below this threshold, we\n+  \/\/ use a total shuffle without regard for address space fragmentation, otherwise\n+  \/\/ we attempt to minimize fragmentation.\n+  constexpr unsigned total_shuffle_threshold = 1024;\n+\n+#define ARGSFMT \"range [\" PTR_FORMAT \"-\" PTR_FORMAT \"), size \" SIZE_FORMAT_X \", alignment \" SIZE_FORMAT_X \", randomize: %d\"\n+#define ARGSFMTARGS p2i(min), p2i(max), bytes, alignment, randomize\n+\n+  log_debug(os, map) (\"reserve_between (\" ARGSFMT \")\", ARGSFMTARGS);\n+\n+  assert(is_power_of_2(alignment), \"alignment invalid (\" ARGSFMT \")\", ARGSFMTARGS);\n+  assert(alignment < SIZE_MAX \/ 2, \"alignment too large (\" ARGSFMT \")\", ARGSFMTARGS);\n+  assert(is_aligned(bytes, os::vm_page_size()), \"size not page aligned (\" ARGSFMT \")\", ARGSFMTARGS);\n+  assert(max >= min, \"invalid range (\" ARGSFMT \")\", ARGSFMTARGS);\n+\n+  char* const absolute_max = (char*)(NOT_LP64(G * 3) LP64_ONLY(G * 128 * 1024));\n+  char* const absolute_min = (char*) os::vm_min_address();\n+\n+  \/\/ AIX is the only platform that uses System V shm for reserving virtual memory.\n+  \/\/ In this case, the required alignment of the allocated size (64K) and the alignment\n+  \/\/ of possible start points of the memory region (256M) differ.\n+  \/\/ This is not reflected by os_allocation_granularity().\n+  \/\/ The logic here is dual to the one in pd_reserve_memory in os_aix.cpp\n+  const size_t system_allocation_granularity =\n+    AIX_ONLY(os::vm_page_size() == 4*K ? 4*K : 256*M)\n+    NOT_AIX(os::vm_allocation_granularity());\n+\n+  const size_t alignment_adjusted = MAX2(alignment, system_allocation_granularity);\n+\n+  \/\/ Calculate first and last possible attach points:\n+  char* const lo_att = align_up(MAX2(absolute_min, min), alignment_adjusted);\n+  if (lo_att == nullptr) {\n+    return nullptr; \/\/ overflow\n+  }\n+\n+  char* const hi_end = MIN2(max, absolute_max);\n+  if ((uintptr_t)hi_end < bytes) {\n+    return nullptr; \/\/ no need to go on\n+  }\n+  char* const hi_att = align_down(hi_end - bytes, alignment_adjusted);\n+  if (hi_att > max) {\n+    return nullptr; \/\/ overflow\n+  }\n+\n+  \/\/ no possible attach points\n+  if (hi_att < lo_att) {\n+    return nullptr;\n+  }\n+\n+  char* result = nullptr;\n+\n+  const size_t num_attach_points = (size_t)((hi_att - lo_att) \/ alignment_adjusted) + 1;\n+  assert(num_attach_points > 0, \"Sanity\");\n+\n+  \/\/ If this fires, the input range is too large for the given alignment (we work\n+  \/\/ with int below to keep things simple). Since alignment is bound to page size,\n+  \/\/ and the lowest page size is 4K, this gives us a minimum of 4K*4G=8TB address\n+  \/\/ range.\n+  assert(num_attach_points <= UINT_MAX,\n+         \"Too many possible attach points - range too large or alignment too small (\" ARGSFMT \")\", ARGSFMTARGS);\n+\n+  const unsigned num_attempts = MIN2((unsigned)num_attach_points, max_attempts);\n+  unsigned points[max_attempts];\n+\n+  if (randomize) {\n+    FastRandom frand;\n+\n+    if (num_attach_points < min_random_value_range) {\n+      return nullptr;\n+    }\n+\n+    \/\/ We pre-calc the attach points:\n+    \/\/ 1 We divide the attach range into equidistant sections and calculate an attach\n+    \/\/   point within each section.\n+    \/\/ 2 We wiggle those attach points around within their section (depends on attach\n+    \/\/   point granularity)\n+    \/\/ 3 Should that not be enough to get effective randomization, shuffle all\n+    \/\/   attach points\n+    \/\/ 4 Otherwise, re-order them to get an optimized probing sequence.\n+    const unsigned stepsize = (unsigned)num_attach_points \/ num_attempts;\n+    const unsigned half = num_attempts \/ 2;\n+\n+    \/\/ 1+2: pre-calc points\n+    for (unsigned i = 0; i < num_attempts; i++) {\n+      const unsigned deviation = stepsize > 1 ? (frand.next() % stepsize) : 0;\n+      points[i] = (i * stepsize) + deviation;\n+    }\n+\n+    if (num_attach_points < total_shuffle_threshold) {\n+      \/\/ 3:\n+      \/\/ The numeber of possible attach points is too low for the \"wiggle\" from\n+      \/\/ point 2 to be enough to provide randomization. In that case, shuffle\n+      \/\/ all attach points at the cost of possible fragmentation (e.g. if we\n+      \/\/ end up mapping into the middle of the range).\n+      shuffle_fisher_yates(points, num_attempts, frand);\n+    } else {\n+      \/\/ 4\n+      \/\/ We have a large enough number of attach points to satisfy the randomness\n+      \/\/ goal without. In that case, we optimize probing by sorting the attach\n+      \/\/ points: We attempt outermost points first, then work ourselves up to\n+      \/\/ the middle. That reduces address space fragmentation. We also alternate\n+      \/\/ hemispheres, which increases the chance of successfull mappings if the\n+      \/\/ previous mapping had been blocked by large maps.\n+      hemi_split(points, num_attempts);\n+    }\n+  } \/\/ end: randomized\n+  else\n+  {\n+    \/\/ Non-randomized. We just attempt to reserve by probing sequentially. We\n+    \/\/ alternate between hemispheres, working ourselves up to the middle.\n+    const int stepsize = (unsigned)num_attach_points \/ num_attempts;\n+    for (unsigned i = 0; i < num_attempts; i++) {\n+      points[i] = (i * stepsize);\n+    }\n+    hemi_split(points, num_attempts);\n+  }\n+\n+#ifdef ASSERT\n+  \/\/ Print + check all pre-calculated attach points\n+  print_points(\"before reserve\", points, num_attempts);\n+  for (unsigned i = 0; i < num_attempts; i++) {\n+    assert(points[i] < num_attach_points, \"Candidate attach point %d out of range (%u, num_attach_points: %zu) \" ARGSFMT,\n+           i, points[i], num_attach_points, ARGSFMTARGS);\n+  }\n+#endif\n+\n+  \/\/ Now reserve\n+  for (unsigned i = 0; result == nullptr && i < num_attempts; i++) {\n+    const unsigned candidate_offset = points[i];\n+    char* const candidate = lo_att + candidate_offset * alignment_adjusted;\n+    assert(candidate <= hi_att, \"Invalid offset %u (\" ARGSFMT \")\", candidate_offset, ARGSFMTARGS);\n+    result = SimulateFullAddressSpace ? nullptr : os::pd_attempt_reserve_memory_at(candidate, bytes, false);\n+    if (!result) {\n+      log_trace(os, map)(\"Failed to attach at \" PTR_FORMAT, p2i(candidate));\n+    }\n+  }\n+\n+  \/\/ Sanity checks, logging, NMT stuff:\n@@ -1766,0 +2042,9 @@\n+#define ERRFMT \"result: \" PTR_FORMAT \" \" ARGSFMT\n+#define ERRFMTARGS p2i(result), ARGSFMTARGS\n+    assert(result >= min, \"OOB min (\" ERRFMT \")\", ERRFMTARGS);\n+    assert((result + bytes) <= max, \"OOB max (\" ERRFMT \")\", ERRFMTARGS);\n+    assert(result >= (char*)os::vm_min_address(), \"OOB vm.map min (\" ERRFMT \")\", ERRFMTARGS);\n+    assert((result + bytes) <= absolute_max, \"OOB vm.map max (\" ERRFMT \")\", ERRFMTARGS);\n+    assert(is_aligned(result, alignment), \"alignment invalid (\" ERRFMT \")\", ERRFMTARGS);\n+    log_trace(os, map)(ERRFMT, ERRFMTARGS);\n+    log_debug(os, map)(\"successfully attached at \" PTR_FORMAT, p2i(result));\n@@ -1768,2 +2053,1 @@\n-    log_debug(os)(\"Attempt to reserve memory at \" INTPTR_FORMAT \" for \"\n-                 SIZE_FORMAT \" bytes failed, errno %d\", p2i(addr), bytes, get_last_error());\n+    log_debug(os, map)(\"failed to attach anywhere in [\" PTR_FORMAT \"-\" PTR_FORMAT \")\", p2i(min), p2i(max));\n@@ -1772,0 +2056,4 @@\n+#undef ARGSFMT\n+#undef ERRFMT\n+#undef ARGSFMTARGS\n+#undef ERRFMTARGS\n@@ -1784,0 +2072,3 @@\n+    log_debug(os, map)(\"Committed \" RANGEFMT, RANGEFMTARGS(addr, bytes));\n+  } else {\n+    log_info(os, map)(\"Failed to commit \" RANGEFMT, RANGEFMTARGS(addr, bytes));\n@@ -1794,0 +2085,3 @@\n+    log_debug(os, map)(\"Committed \" RANGEFMT, RANGEFMTARGS(addr, size));\n+  } else {\n+    log_info(os, map)(\"Failed to commit \" RANGEFMT, RANGEFMTARGS(addr, size));\n@@ -1816,1 +2110,1 @@\n-    Tracker tkr(Tracker::uncommit);\n+    ThreadCritical tc;\n@@ -1819,1 +2113,1 @@\n-      tkr.record((address)addr, bytes);\n+      MemTracker::record_virtual_memory_uncommit((address)addr, bytes);\n@@ -1824,0 +2118,7 @@\n+\n+  if (res) {\n+    log_debug(os, map)(\"Uncommitted \" RANGEFMT, RANGEFMTARGS(addr, bytes));\n+  } else {\n+    log_info(os, map)(\"Failed to uncommit \" RANGEFMT, RANGEFMTARGS(addr, bytes));\n+  }\n+\n@@ -1831,2 +2132,1 @@\n-    \/\/ Note: Tracker contains a ThreadCritical.\n-    Tracker tkr(Tracker::release);\n+    ThreadCritical tc;\n@@ -1835,1 +2135,1 @@\n-      tkr.record((address)addr, bytes);\n+      MemTracker::record_virtual_memory_release((address)addr, bytes);\n@@ -1841,1 +2141,3 @@\n-    log_info(os)(\"os::release_memory failed (\" PTR_FORMAT \", \" SIZE_FORMAT \")\", p2i(addr), bytes);\n+    log_info(os, map)(\"Failed to release \" RANGEFMT, RANGEFMTARGS(addr, bytes));\n+  } else {\n+    log_debug(os, map)(\"Released \" RANGEFMT, RANGEFMTARGS(addr, bytes));\n@@ -1874,1 +2176,1 @@\n-    char* cur = static_cast<char*>(align_down(start, page_size));\n+    void* first = align_down(start, page_size);\n@@ -1876,6 +2178,10 @@\n-    assert(cur <= last, \"invariant\");\n-    \/\/ Iterate from first page through last (inclusive), being careful to\n-    \/\/ avoid overflow if the last page abuts the end of the address range.\n-    for ( ; true; cur += page_size) {\n-      Atomic::add(reinterpret_cast<int*>(cur), 0, memory_order_relaxed);\n-      if (cur >= last) break;\n+    assert(first <= last, \"invariant\");\n+    const size_t pd_page_size = pd_pretouch_memory(first, last, page_size);\n+    if (pd_page_size > 0) {\n+      \/\/ Iterate from first page through last (inclusive), being careful to\n+      \/\/ avoid overflow if the last page abuts the end of the address range.\n+      last = align_down(static_cast<char*>(end) - 1, pd_page_size);\n+      for (char* cur = static_cast<char*>(first); \/* break *\/; cur += pd_page_size) {\n+        Atomic::add(reinterpret_cast<int*>(cur), 0, memory_order_relaxed);\n+        if (cur >= last) break;\n+      }\n@@ -1886,1 +2192,1 @@\n-char* os::map_memory_to_file(size_t bytes, int file_desc) {\n+char* os::map_memory_to_file(size_t bytes, int file_desc, MEMFLAGS flag) {\n@@ -1892,1 +2198,1 @@\n-    MemTracker::record_virtual_memory_reserve_and_commit(result, bytes, CALLER_PC);\n+    MemTracker::record_virtual_memory_reserve_and_commit(result, bytes, CALLER_PC, flag);\n@@ -1897,1 +2203,1 @@\n-char* os::attempt_map_memory_to_file_at(char* addr, size_t bytes, int file_desc) {\n+char* os::attempt_map_memory_to_file_at(char* addr, size_t bytes, int file_desc, MEMFLAGS flag) {\n@@ -1900,1 +2206,1 @@\n-    MemTracker::record_virtual_memory_reserve_and_commit((address)result, bytes, CALLER_PC);\n+    MemTracker::record_virtual_memory_reserve_and_commit((address)result, bytes, CALLER_PC, flag);\n@@ -1915,7 +2221,0 @@\n-char* os::remap_memory(int fd, const char* file_name, size_t file_offset,\n-                             char *addr, size_t bytes, bool read_only,\n-                             bool allow_exec) {\n-  return pd_remap_memory(fd, file_name, file_offset, addr, bytes,\n-                    read_only, allow_exec);\n-}\n-\n@@ -1925,1 +2224,1 @@\n-    Tracker tkr(Tracker::release);\n+    ThreadCritical tc;\n@@ -1928,1 +2227,1 @@\n-      tkr.record((address)addr, bytes);\n+      MemTracker::record_virtual_memory_release((address)addr, bytes);\n@@ -1953,0 +2252,3 @@\n+    log_debug(os, map)(\"Reserved and committed \" RANGEFMT, RANGEFMTARGS(result, size));\n+  } else {\n+    log_info(os, map)(\"Reserve and commit failed (%zu bytes)\", size);\n@@ -1961,2 +2263,1 @@\n-    \/\/ Note: Tracker contains a ThreadCritical.\n-    Tracker tkr(Tracker::release);\n+    ThreadCritical tc;\n@@ -1965,1 +2266,1 @@\n-      tkr.record((address)addr, bytes);\n+      MemTracker::record_virtual_memory_release((address)addr, bytes);\n","filename":"src\/hotspot\/share\/runtime\/os.cpp","additions":368,"deletions":67,"binary":false,"changes":435,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -155,0 +155,13 @@\n+\/\/ Preserve errno across a range of calls\n+\n+class ErrnoPreserver {\n+  int _e;\n+\n+public:\n+  ErrnoPreserver() { _e = errno; }\n+\n+  ~ErrnoPreserver() { errno = _e; }\n+\n+  int saved_errno() { return _e; }\n+};\n+\n@@ -193,0 +206,5 @@\n+  \/\/ The default value for os::vm_min_address() unless the platform knows better. This value\n+  \/\/ is chosen to give us reasonable protection against null pointer dereferences while being\n+  \/\/ low enough to leave most of the valuable low-4gb address space open.\n+  static constexpr size_t _vm_min_address_default = 16 * M;\n+\n@@ -215,3 +233,0 @@\n-  static char*  pd_remap_memory(int fd, const char* file_name, size_t file_offset,\n-                             char *addr, size_t bytes, bool read_only,\n-                             bool allow_exec);\n@@ -222,0 +237,4 @@\n+  \/\/ Returns 0 if pretouch is done via platform dependent method, or otherwise\n+  \/\/ returns page_size that should be used for the common method.\n+  static size_t pd_pretouch_memory(void* first, void* last, size_t page_size);\n+\n@@ -322,0 +341,3 @@\n+  static jlong total_swap_space();\n+  static jlong free_swap_space();\n+\n@@ -423,0 +445,3 @@\n+  \/\/ Returns the lowest address the process is allowed to map against.\n+  static size_t vm_min_address();\n+\n@@ -433,1 +458,5 @@\n-  static char*  attempt_reserve_memory_at(char* addr, size_t bytes, bool executable = false);\n+  static char*  attempt_reserve_memory_at(char* addr, size_t bytes, bool executable = false, MEMFLAGS flag = mtNone);\n+\n+  \/\/ Given an address range [min, max), attempts to reserve memory within this area, with the given alignment.\n+  \/\/ If randomize is true, the location will be randomized.\n+  static char* attempt_reserve_memory_between(char* min, char* max, size_t bytes, size_t alignment, bool randomize);\n@@ -483,2 +512,2 @@\n-  static char* map_memory_to_file(size_t size, int fd);\n-  static char* map_memory_to_file_aligned(size_t size, size_t alignment, int fd);\n+  static char* map_memory_to_file(size_t size, int fd, MEMFLAGS flag = mtNone);\n+  static char* map_memory_to_file_aligned(size_t size, size_t alignment, int fd, MEMFLAGS flag = mtNone);\n@@ -486,1 +515,1 @@\n-  static char* attempt_map_memory_to_file_at(char* base, size_t size, int fd);\n+  static char* attempt_map_memory_to_file_at(char* base, size_t size, int fd, MEMFLAGS flag = mtNone);\n@@ -493,3 +522,0 @@\n-  static char*  remap_memory(int fd, const char* file_name, size_t file_offset,\n-                             char *addr, size_t bytes, bool read_only,\n-                             bool allow_exec);\n@@ -505,1 +531,1 @@\n-  static size_t numa_get_leaf_groups(int *ids, size_t size);\n+  static size_t numa_get_leaf_groups(uint *ids, size_t size);\n@@ -516,2 +542,0 @@\n-  static char*  scan_pages(char *start, char* end, page_info* page_expected, page_info* page_found);\n-\n@@ -526,1 +550,0 @@\n-  static bool   can_execute_large_page_memory();\n@@ -588,1 +611,1 @@\n-  ATTRIBUTE_NORETURN static void infinite_sleep();\n+  [[noreturn]] static void infinite_sleep();\n@@ -601,2 +624,1 @@\n-  static address current_stack_base();\n-  static size_t current_stack_size();\n+  static void current_stack_base_and_size(address* base, size_t* size);\n@@ -617,1 +639,1 @@\n-  ATTRIBUTE_NORETURN static void exit(int num);\n+  [[noreturn]] static void exit(int num);\n@@ -621,1 +643,1 @@\n-  ATTRIBUTE_NORETURN static void _exit(int num);\n+  [[noreturn]] static void _exit(int num);\n@@ -628,2 +650,2 @@\n-  ATTRIBUTE_NORETURN static void abort(bool dump_core, void *siginfo, const void *context);\n-  ATTRIBUTE_NORETURN static void abort(bool dump_core = true);\n+  [[noreturn]] static void abort(bool dump_core, void *siginfo, const void *context);\n+  [[noreturn]] static void abort(bool dump_core = true);\n@@ -636,1 +658,1 @@\n-  ATTRIBUTE_NORETURN static void die();\n+  [[noreturn]] static void die();\n@@ -674,1 +696,3 @@\n-  static bool is_path_absolute(const char *path);\n+  static bool           is_path_absolute(const char *path);\n+\n+  static void           prepare_native_symbols();\n@@ -761,2 +785,2 @@\n-  \/\/ Provide C99 compliant versions of these functions, since some versions\n-  \/\/ of some platforms don't.\n+  \/\/ Provide wrapper versions of these functions to guarantee NUL-termination\n+  \/\/ in all cases.\n@@ -786,1 +810,1 @@\n-  static void print_instructions(outputStream* st, address pc, int unitsize);\n+  static void print_instructions(outputStream* st, address pc, int unitsize = 1);\n@@ -793,0 +817,1 @@\n+  static void print_elapsed_time(outputStream* st, double time);\n@@ -900,4 +925,4 @@\n-  static int recv(int fd, char* buf, size_t nBytes, uint flags);\n-  static int send(int fd, char* buf, size_t nBytes, uint flags);\n-  static int raw_send(int fd, char* buf, size_t nBytes, uint flags);\n-  static int connect(int fd, struct sockaddr* him, socklen_t len);\n+  static ssize_t recv(int fd, char* buf, size_t nBytes, uint flags);\n+  static ssize_t send(int fd, char* buf, size_t nBytes, uint flags);\n+  static ssize_t raw_send(int fd, char* buf, size_t nBytes, uint flags);\n+  static ssize_t connect(int fd, struct sockaddr* him, socklen_t len);\n@@ -1066,0 +1091,1 @@\n+  static bool pd_dll_unload(void* libhandle, char* ebuf, int ebuflen);\n","filename":"src\/hotspot\/share\/runtime\/os.hpp","additions":57,"deletions":31,"binary":false,"changes":88,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,0 +28,1 @@\n+#include \"cds\/cdsConfig.hpp\"\n@@ -55,0 +56,1 @@\n+#include \"nmt\/memTracker.hpp\"\n@@ -59,1 +61,2 @@\n-#include \"prims\/jvmtiAgentList.hpp\"\n+#include \"prims\/jvmtiAgentList.hpp\"\n+#include \"prims\/jvmtiEnvBase.hpp\"\n@@ -65,1 +68,1 @@\n-#include \"runtime\/handles.inline.hpp\"\n+#include \"runtime\/handles.inline.hpp\"\n@@ -84,0 +87,1 @@\n+#include \"runtime\/stackWatermarkSet.inline.hpp\"\n@@ -87,1 +91,1 @@\n-#include \"runtime\/threads.hpp\"\n+#include \"runtime\/threads.hpp\"\n@@ -96,1 +100,0 @@\n-#include \"services\/memTracker.hpp\"\n@@ -676,1 +679,1 @@\n-  MutexLocker::post_initialize();\n+  MutexLockerImpl::post_initialize();\n@@ -703,1 +706,1 @@\n-  Chunk::start_chunk_pool_cleaner_task();\n+  Arena::start_chunk_pool_cleaner_task();\n@@ -715,0 +718,1 @@\n+  bool init_compilation = true;\n@@ -716,1 +720,1 @@\n-  bool force_JVMCI_intialization = false;\n+  bool force_JVMCI_initialization = false;\n@@ -720,6 +724,11 @@\n-    force_JVMCI_intialization = EagerJVMCI || JVMCIPrintProperties || JVMCILibDumpJNIConfig;\n-\n-    if (!force_JVMCI_intialization) {\n-      \/\/ 8145270: Force initialization of JVMCI runtime otherwise requests for blocking\n-      \/\/ compilations via JVMCI will not actually block until JVMCI is initialized.\n-      force_JVMCI_intialization = UseJVMCICompiler && (!UseInterpreter || !BackgroundCompilation);\n+    force_JVMCI_initialization = EagerJVMCI || JVMCIPrintProperties || JVMCILibDumpJNIConfig;\n+    if (!force_JVMCI_initialization && UseJVMCICompiler && !UseJVMCINativeLibrary && (!UseInterpreter || !BackgroundCompilation)) {\n+      \/\/ Force initialization of jarjvmci otherwise requests for blocking\n+      \/\/ compilations will not actually block until jarjvmci is initialized.\n+      force_JVMCI_initialization = true;\n+    }\n+    if (JVMCIPrintProperties || JVMCILibDumpJNIConfig) {\n+      \/\/ Both JVMCILibDumpJNIConfig and JVMCIPrintProperties exit the VM\n+      \/\/ so compilation should be disabled. This prevents dumping or\n+      \/\/ printing from happening more than once.\n+      init_compilation = false;\n@@ -729,5 +738,2 @@\n-  CompileBroker::compilation_init_phase1(CHECK_JNI_ERR);\n-  \/\/ Postpone completion of compiler initialization to after JVMCI\n-  \/\/ is initialized to avoid timeouts of blocking compilations.\n-  if (JVMCI_ONLY(!force_JVMCI_intialization) NOT_JVMCI(true)) {\n-    CompileBroker::compilation_init_phase2();\n+  if (init_compilation) {\n+    CompileBroker::compilation_init(CHECK_JNI_ERR);\n@@ -767,0 +773,7 @@\n+  if (Continuations::enabled()) {\n+    \/\/ Initialize Continuation class now so that failure to create enterSpecial\/doYield\n+    \/\/ special nmethods due to limited CodeCache size can be treated as a fatal error at\n+    \/\/ startup with the proper message that CodeCache size is too small.\n+    initialize_class(vmSymbols::jdk_internal_vm_Continuation(), CHECK_JNI_ERR);\n+  }\n+\n@@ -777,1 +790,1 @@\n-  if (force_JVMCI_intialization) {\n+  if (force_JVMCI_initialization) {\n@@ -779,1 +792,0 @@\n-    CompileBroker::compilation_init_phase2();\n@@ -835,1 +847,1 @@\n-  if (DumpSharedSpaces) {\n+  if (CDSConfig::is_dumping_static_archive()) {\n@@ -844,4 +856,4 @@\n-\/\/ vm_exit() when the program calls System.exit() to return a value or when\n-\/\/ there is a serious error in VM. The two shutdown paths are not exactly\n-\/\/ the same, but they share Shutdown.shutdown() at Java level and before_exit()\n-\/\/ and VM_Exit op at VM level.\n+\/\/ vm_exit(), when the program calls System.exit() to return a value, or when\n+\/\/ there is a serious error in VM.\n+\/\/ These two separate shutdown paths are not exactly the same, but they share\n+\/\/ Shutdown.shutdown() at Java level and before_exit() and VM_Exit op at VM level.\n@@ -1029,1 +1041,1 @@\n-  Events::log(p, \"Thread added: \" INTPTR_FORMAT, p2i(p));\n+  Events::log(Thread::current(), \"Thread added: \" INTPTR_FORMAT, p2i(p));\n@@ -1092,1 +1104,1 @@\n-  Events::log(p, \"Thread exited: \" INTPTR_FORMAT, p2i(p));\n+  Events::log(Thread::current(), \"Thread exited: \" INTPTR_FORMAT, p2i(p));\n@@ -1102,1 +1114,1 @@\n-void Threads::oops_do(OopClosure* f, CodeBlobClosure* cf) {\n+void Threads::oops_do(OopClosure* f, NMethodClosure* cf) {\n@@ -1130,1 +1142,1 @@\n-void assert_thread_claimed(const char* kind, Thread* t, uintx expected) {\n+static void assert_thread_claimed(const char* kind, Thread* t, uintx expected) {\n@@ -1159,1 +1171,1 @@\n-  CodeBlobClosure* _cf;\n+  NMethodClosure* _cf;\n@@ -1161,1 +1173,1 @@\n-  ParallelOopsDoThreadClosure(OopClosure* f, CodeBlobClosure* cf) : _f(f), _cf(cf) {}\n+  ParallelOopsDoThreadClosure(OopClosure* f, NMethodClosure* cf) : _f(f), _cf(cf) {}\n@@ -1167,1 +1179,1 @@\n-void Threads::possibly_parallel_oops_do(bool is_par, OopClosure* f, CodeBlobClosure* cf) {\n+void Threads::possibly_parallel_oops_do(bool is_par, OopClosure* f, NMethodClosure* cf) {\n@@ -1193,1 +1205,3 @@\n-\/\/ Get count Java threads that are waiting to enter the specified monitor.\n+#if INCLUDE_JVMTI\n+\/\/ Get Java threads that are waiting to enter or re-enter the specified monitor.\n+\/\/ Java threads that are executing mounted virtual threads are not included.\n@@ -1197,0 +1211,1 @@\n+  assert(Thread::current()->is_VM_thread(), \"Must be the VM thread\");\n@@ -1203,0 +1218,4 @@\n+    oop thread_oop = JvmtiEnvBase::get_vthread_or_thread_oop(p);\n+    if (thread_oop->is_a(vmClasses::BaseVirtualThread_klass())) {\n+      continue;\n+    }\n@@ -1206,1 +1225,6 @@\n-    if (pending == monitor) {             \/\/ found a match\n+    address waiting = (address)p->current_waiting_monitor();\n+    \/\/ do not include virtual threads to the list\n+    jint state = JvmtiEnvBase::get_thread_state(thread_oop, p);\n+    if (pending == monitor || (waiting == monitor &&\n+        (state & JVMTI_THREAD_STATE_BLOCKED_ON_MONITOR_ENTER))\n+    ) { \/\/ found a match\n@@ -1214,1 +1238,1 @@\n-\n+#endif \/\/ INCLUDE_JVMTI\n@@ -1251,0 +1275,6 @@\n+    \/\/ Need to start processing before accessing oops in the thread.\n+    StackWatermark* watermark = StackWatermarkSet::get(q, StackWatermarkKind::gc);\n+    if (watermark != nullptr) {\n+      watermark->start_processing();\n+    }\n+\n@@ -1332,4 +1362,1 @@\n-  cl.do_thread(VMThread::vm_thread());\n-  Universe::heap()->gc_threads_do(&cl);\n-  cl.do_thread(WatcherThread::watcher_thread());\n-  cl.do_thread(AsyncLogWriter::instance());\n+  non_java_threads_do(&cl);\n","filename":"src\/hotspot\/share\/runtime\/threads.cpp","additions":67,"deletions":40,"binary":false,"changes":107,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -36,0 +36,2 @@\n+class MetadataClosure;\n+class OopClosure;\n@@ -41,4 +43,0 @@\n-class CodeBlobClosure;\n-class MetadataClosure;\n-class OopClosure;\n-\n@@ -111,1 +109,1 @@\n-  static void oops_do(OopClosure* f, CodeBlobClosure* cf);\n+  static void oops_do(OopClosure* f, NMethodClosure* cf);\n@@ -113,1 +111,1 @@\n-  static void possibly_parallel_oops_do(bool is_par, OopClosure* f, CodeBlobClosure* cf);\n+  static void possibly_parallel_oops_do(bool is_par, OopClosure* f, NMethodClosure* cf);\n@@ -136,1 +134,2 @@\n-  \/\/ Get Java threads that are waiting to enter a monitor.\n+  \/\/ Get Java threads that are waiting to enter or re-enter the specified monitor.\n+  \/\/ Java threads that are executing mounted virtual threads are not included.\n","filename":"src\/hotspot\/share\/runtime\/threads.hpp","additions":7,"deletions":8,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -40,1 +40,0 @@\n-  template(Cleanup)                               \\\n@@ -51,1 +50,0 @@\n-  template(HeapDumpMerge)                         \\\n@@ -55,2 +53,2 @@\n-  template(GenCollectFull)                        \\\n-  template(GenCollectForAllocation)               \\\n+  template(SerialCollectForAllocation)            \\\n+  template(SerialGCCollect)                       \\\n@@ -84,2 +82,0 @@\n-  template(VirtualThreadGetStackTrace)            \\\n-  template(VirtualThreadGetFrameCount)            \\\n@@ -89,1 +85,0 @@\n-  template(VirtualThreadGetCurrentLocation)       \\\n@@ -111,0 +106,2 @@\n+  template(RehashStringTable)                     \\\n+  template(RehashSymbolTable)                     \\\n","filename":"src\/hotspot\/share\/runtime\/vmOperation.hpp","additions":5,"deletions":8,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -43,0 +43,1 @@\n+#include \"code\/compiledIC.hpp\"\n@@ -66,1 +67,0 @@\n-#include \"oops\/compiledICHolder.hpp\"\n@@ -88,0 +88,1 @@\n+#include \"oops\/resolvedMethodEntry.hpp\"\n@@ -183,1 +184,1 @@\n-                   static_ptr_volatile_field,                                                                                        \\\n+                   volatile_static_field,                                                                                            \\\n@@ -197,0 +198,1 @@\n+                volatile_static_field,                                                                                               \\\n@@ -212,2 +214,0 @@\n-  nonstatic_field(CompiledICHolder,            _holder_metadata,                              Metadata*)                             \\\n-  nonstatic_field(CompiledICHolder,            _holder_klass,                                 Klass*)                                \\\n@@ -226,1 +226,0 @@\n-  nonstatic_field(ConstantPoolCache,           _length,                                       int)                                   \\\n@@ -230,0 +229,2 @@\n+  nonstatic_field(ConstantPoolCache,           _resolved_method_entries,                      Array<ResolvedMethodEntry>*)           \\\n+  nonstatic_field(ResolvedMethodEntry,         _cpool_index,                                  u2)                                    \\\n@@ -248,0 +249,1 @@\n+  nonstatic_field(InstanceKlass,               _is_marked_dependent,                          bool)                                  \\\n@@ -309,1 +311,1 @@\n-  volatile_nonstatic_field(Method,             _code,                                         CompiledMethod*)                       \\\n+  volatile_nonstatic_field(Method,             _code,                                         nmethod*)                              \\\n@@ -339,9 +341,0 @@\n-  \/***********************\/                                                                                                          \\\n-  \/* Constant Pool Cache *\/                                                                                                          \\\n-  \/***********************\/                                                                                                          \\\n-                                                                                                                                     \\\n-  volatile_nonstatic_field(ConstantPoolCacheEntry,      _indices,                             intx)                                  \\\n-  volatile_nonstatic_field(ConstantPoolCacheEntry,      _f1,                                  Metadata*)                             \\\n-  volatile_nonstatic_field(ConstantPoolCacheEntry,      _f2,                                  intx)                                  \\\n-  volatile_nonstatic_field(ConstantPoolCacheEntry,      _flags,                               intx)                                  \\\n-                                                                                                                                     \\\n@@ -450,1 +443,1 @@\n-     static_field(PerfMemory,                  _initialized,                                  int)                                   \\\n+     volatile_static_field(PerfMemory,         _initialized,                                  int)                                   \\\n@@ -480,1 +473,1 @@\n-  static_ptr_volatile_field(ClassLoaderDataGraph, _head,                                      ClassLoaderData*)                      \\\n+  volatile_static_field(ClassLoaderDataGraph, _head,                                          ClassLoaderData*)                      \\\n@@ -490,0 +483,2 @@\n+  nonstatic_field(Array<ResolvedMethodEntry>,  _length,                                       int)                                   \\\n+  nonstatic_field(Array<ResolvedMethodEntry>,  _data[0],                                      ResolvedMethodEntry)                   \\\n@@ -517,1 +512,1 @@\n-  nonstatic_field(HeapBlock::Header,           _length,                                       size_t)                                \\\n+  nonstatic_field(HeapBlock::Header,           _length,                                       uint32_t)                              \\\n@@ -558,11 +553,11 @@\n-  nonstatic_field(CodeBlob,                 _name,                                   const char*)                                    \\\n-  nonstatic_field(CodeBlob,                 _size,                                   int)                                            \\\n-  nonstatic_field(CodeBlob,                 _header_size,                            int)                                            \\\n-  nonstatic_field(CodeBlob,                 _frame_complete_offset,                  int)                                            \\\n-  nonstatic_field(CodeBlob,                 _data_offset,                            int)                                            \\\n-  nonstatic_field(CodeBlob,                 _frame_size,                             int)                                            \\\n-  nonstatic_field(CodeBlob,                 _oop_maps,                               ImmutableOopMapSet*)                            \\\n-  nonstatic_field(CodeBlob,                 _code_begin,                             address)                                        \\\n-  nonstatic_field(CodeBlob,                 _code_end,                               address)                                        \\\n-  nonstatic_field(CodeBlob,                 _content_begin,                          address)                                        \\\n-  nonstatic_field(CodeBlob,                 _data_end,                               address)                                        \\\n+  nonstatic_field(CodeBlob,                    _name,                                         const char*)                           \\\n+  nonstatic_field(CodeBlob,                    _size,                                         int)                                   \\\n+  nonstatic_field(CodeBlob,                    _header_size,                                  u2)                                    \\\n+  nonstatic_field(CodeBlob,                    _relocation_size,                              int)                                   \\\n+  nonstatic_field(CodeBlob,                    _content_offset,                               int)                                   \\\n+  nonstatic_field(CodeBlob,                    _code_offset,                                  int)                                   \\\n+  nonstatic_field(CodeBlob,                    _frame_complete_offset,                        int16_t)                               \\\n+  nonstatic_field(CodeBlob,                    _data_offset,                                  int)                                   \\\n+  nonstatic_field(CodeBlob,                    _frame_size,                                   int)                                   \\\n+  nonstatic_field(CodeBlob,                    _oop_maps,                                     ImmutableOopMapSet*)                   \\\n+  nonstatic_field(CodeBlob,                    _caller_must_gc_arguments,                     bool)                                  \\\n@@ -572,12 +567,0 @@\n-  nonstatic_field(RuntimeStub,                 _caller_must_gc_arguments,                     bool)                                  \\\n-                                                                                                                                     \\\n-  \/********************************************************\/                                                                         \\\n-  \/* CompiledMethod (NOTE: incomplete, but only a little) *\/                                                                         \\\n-  \/********************************************************\/                                                                         \\\n-                                                                                                                                     \\\n-  nonstatic_field(CompiledMethod,                     _method,                                       Method*)                        \\\n-  volatile_nonstatic_field(CompiledMethod,            _exception_cache,                              ExceptionCache*)                \\\n-  nonstatic_field(CompiledMethod,                     _scopes_data_begin,                            address)                        \\\n-  nonstatic_field(CompiledMethod,                     _deopt_handler_begin,                          address)                        \\\n-  nonstatic_field(CompiledMethod,                     _deopt_mh_handler_begin,                       address)                        \\\n-                                                                                                                                     \\\n@@ -588,0 +571,1 @@\n+  nonstatic_field(nmethod,                     _method,                                       Method*)                               \\\n@@ -592,0 +576,2 @@\n+  nonstatic_field(nmethod,                     _deopt_handler_offset,                         int)                                   \\\n+  nonstatic_field(nmethod,                     _deopt_mh_handler_offset,                      int)                                   \\\n@@ -594,10 +580,7 @@\n-  nonstatic_field(nmethod,                     _consts_offset,                                int)                                   \\\n-  nonstatic_field(nmethod,                     _oops_offset,                                  int)                                   \\\n-  nonstatic_field(nmethod,                     _metadata_offset,                              int)                                   \\\n-  nonstatic_field(nmethod,                     _scopes_pcs_offset,                            int)                                   \\\n-  nonstatic_field(nmethod,                     _dependencies_offset,                          int)                                   \\\n-  nonstatic_field(nmethod,                     _handler_table_offset,                         int)                                   \\\n-  nonstatic_field(nmethod,                     _nul_chk_table_offset,                         int)                                   \\\n-  nonstatic_field(nmethod,                     _nmethod_end_offset,                           int)                                   \\\n-  nonstatic_field(nmethod,                     _entry_point,                                  address)                               \\\n-  nonstatic_field(nmethod,                     _verified_entry_point,                         address)                               \\\n+  nonstatic_field(nmethod,                     _metadata_offset,                              u2)                                    \\\n+  nonstatic_field(nmethod,                     _scopes_pcs_offset,                            int)                                    \\\n+  nonstatic_field(nmethod,                     _scopes_data_offset,                           int)                                   \\\n+  nonstatic_field(nmethod,                     _handler_table_offset,                         u2)                                    \\\n+  nonstatic_field(nmethod,                     _nul_chk_table_offset,                         u2)                                    \\\n+  nonstatic_field(nmethod,                     _entry_offset,                                 u2)                                    \\\n+  nonstatic_field(nmethod,                     _verified_entry_offset,                        u2)                                    \\\n@@ -605,0 +588,2 @@\n+  nonstatic_field(nmethod,                     _immutable_data,                               address)                               \\\n+  nonstatic_field(nmethod,                     _immutable_data_size,                          int)                                   \\\n@@ -607,0 +592,1 @@\n+  volatile_nonstatic_field(nmethod,            _exception_cache,                              ExceptionCache*)                       \\\n@@ -641,1 +627,1 @@\n-  static_ptr_volatile_field(ThreadsSMRSupport, _java_thread_list,                             ThreadsList*)                          \\\n+  volatile_static_field(ThreadsSMRSupport, _java_thread_list,                                 ThreadsList*)                          \\\n@@ -733,1 +719,0 @@\n-  nonstatic_field(ciEnv,                       _failure_reason,                               const char*)                           \\\n@@ -950,3 +935,0 @@\n-     static_field(JDK_Version,                 _current,                                      JDK_Version)                           \\\n-  nonstatic_field(JDK_Version,                 _major,                                        unsigned char)                         \\\n-                                                                                                                                     \\\n@@ -980,0 +962,1 @@\n+  unchecked_nonstatic_field(Array<ResolvedMethodEntry>,_data,                                 sizeof(ResolvedMethodEntry))           \\\n@@ -1117,0 +1100,1 @@\n+  declare_unsigned_integer_type(volatile uint)                            \\\n@@ -1150,0 +1134,1 @@\n+  declare_integer_type(int16_t)                                           \\\n@@ -1170,1 +1155,0 @@\n-  declare_toplevel_type(CompiledICHolder)                                 \\\n@@ -1323,2 +1307,1 @@\n-  declare_type(CompiledMethod,           CodeBlob)                        \\\n-  declare_type(nmethod,                  CompiledMethod)                  \\\n+  declare_type(nmethod,                  CodeBlob)                        \\\n@@ -1498,0 +1481,1 @@\n+  declare_c2_type(ConvertNode, TypeNode)                                  \\\n@@ -1753,6 +1737,1 @@\n-  declare_c2_type(ReplicateBNode, VectorNode)                             \\\n-  declare_c2_type(ReplicateSNode, VectorNode)                             \\\n-  declare_c2_type(ReplicateINode, VectorNode)                             \\\n-  declare_c2_type(ReplicateLNode, VectorNode)                             \\\n-  declare_c2_type(ReplicateFNode, VectorNode)                             \\\n-  declare_c2_type(ReplicateDNode, VectorNode)                             \\\n+  declare_c2_type(ReplicateNode, VectorNode)                              \\\n@@ -1876,1 +1855,0 @@\n-  declare_toplevel_type(JDK_Version)                                      \\\n@@ -1897,1 +1875,0 @@\n-   declare_integer_type(Generation::Name)                                 \\\n@@ -1913,0 +1890,1 @@\n+            declare_type(Array<ResolvedMethodEntry>, MetaspaceObj)        \\\n@@ -1930,1 +1908,1 @@\n-  declare_toplevel_type(ConstantPoolCacheEntry)                           \\\n+  declare_toplevel_type(ResolvedMethodEntry)                              \\\n@@ -2189,1 +2167,0 @@\n-  declare_constant(InstanceKlass::being_linked)                           \\\n@@ -2208,12 +2185,0 @@\n-  declare_constant(ConstantPool::CPCACHE_INDEX_TAG)                       \\\n-                                                                          \\\n-  \/********************************\/                                      \\\n-  \/* ConstantPoolCacheEntry enums *\/                                      \\\n-  \/********************************\/                                      \\\n-                                                                          \\\n-  declare_constant(ConstantPoolCacheEntry::is_volatile_shift)             \\\n-  declare_constant(ConstantPoolCacheEntry::is_final_shift)                \\\n-  declare_constant(ConstantPoolCacheEntry::is_forced_virtual_shift)       \\\n-  declare_constant(ConstantPoolCacheEntry::is_vfinal_shift)               \\\n-  declare_constant(ConstantPoolCacheEntry::is_field_entry_shift)          \\\n-  declare_constant(ConstantPoolCacheEntry::tos_state_shift)               \\\n@@ -2693,1 +2658,1 @@\n-             GENERATE_STATIC_PTR_VOLATILE_VM_STRUCT_ENTRY,\n+             GENERATE_VOLATILE_STATIC_VM_STRUCT_ENTRY,\n@@ -2895,1 +2860,1 @@\n-             CHECK_STATIC_PTR_VOLATILE_VM_STRUCT_ENTRY,\n+             CHECK_VOLATILE_STATIC_VM_STRUCT_ENTRY,\n@@ -3041,1 +3006,1 @@\n-    int len = end - start + 1;\n+    int len = pointer_delta_as_int(end, start) + 1;\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":50,"deletions":85,"binary":false,"changes":135,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2011, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2011, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,0 +26,1 @@\n+#include \"cds\/cdsConfig.hpp\"\n@@ -27,0 +28,1 @@\n+#include \"classfile\/classLoaderDataGraph.hpp\"\n@@ -29,1 +31,0 @@\n-#include \"classfile\/classLoaderDataGraph.hpp\"\n@@ -34,0 +35,2 @@\n+#include \"compiler\/compilationMemoryStatistic.hpp\"\n+#include \"compiler\/compiler_globals.hpp\"\n@@ -41,0 +44,3 @@\n+#include \"nmt\/memMapPrinter.hpp\"\n+#include \"nmt\/memTracker.hpp\"\n+#include \"nmt\/nmtDCmd.hpp\"\n@@ -60,1 +66,0 @@\n-#include \"services\/nmtDCmd.hpp\"\n@@ -62,2 +67,2 @@\n-#include \"attachListener_linux.hpp\"\n-#include \"linuxAttachOperation.hpp\"\n+#include \"attachListener_posix.hpp\"\n+#include \"posixAttachOperation.hpp\"\n@@ -70,0 +75,1 @@\n+#include \"utilities\/parseInteger.hpp\"\n@@ -71,1 +77,1 @@\n-#include \"trimCHeapDCmd.hpp\"\n+#include \"os_posix.hpp\"\n@@ -73,0 +79,2 @@\n+#include \"trimCHeapDCmd.hpp\"\n+#include <errno.h>\n@@ -137,0 +145,2 @@\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<SystemMapDCmd>(full_export, true,false));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<SystemDumpMapDCmd>(full_export, true,false));\n@@ -144,0 +154,1 @@\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CompilationMemoryStatisticDCmd>(full_export, true, false));\n@@ -307,1 +318,1 @@\n-      JvmtiAgentList::load_agent(\"instrument\", \"false\", _libpath.value(), output());\n+      JvmtiAgentList::load_agent(\"instrument\", false, _libpath.value(), output());\n@@ -324,1 +335,1 @@\n-      JvmtiAgentList::load_agent(\"instrument\", \"false\", opt, output());\n+      JvmtiAgentList::load_agent(\"instrument\", false, opt, output());\n@@ -329,1 +340,1 @@\n-    JvmtiAgentList::load_agent(_libpath.value(), \"true\", _option.value(), output());\n+    JvmtiAgentList::load_agent(_libpath.value(), true, _option.value(), output());\n@@ -850,0 +861,9 @@\n+#define DEFAULT_PERFMAP_FILENAME \"\/tmp\/perf-<pid>.map\"\n+\n+PerfMapDCmd::PerfMapDCmd(outputStream* output, bool heap) :\n+             DCmdWithParser(output, heap),\n+  _filename(\"filename\", \"Name of the map file\", \"STRING\", false, DEFAULT_PERFMAP_FILENAME)\n+{\n+  _dcmdparser.add_dcmd_argument(&_filename);\n+}\n+\n@@ -851,1 +871,4 @@\n-  CodeCache::write_perf_map();\n+  \/\/ The check for _filename.is_set() is because we don't want to use\n+  \/\/ DEFAULT_PERFMAP_FILENAME, since it is meant as a description\n+  \/\/ of the default, not the actual default.\n+  CodeCache::write_perf_map(_filename.is_set() ? _filename.value() : nullptr);\n@@ -887,1 +910,1 @@\n-  long max = -1;\n+  int max = -1;\n@@ -890,2 +913,2 @@\n-    max = ::strtol(max_value, &endptr, 10);\n-    if (max == 0 && max_value == endptr) {\n+    int max;\n+    if (!parse_integer(max_value, &max)) {\n@@ -983,0 +1006,2 @@\n+#define DEFAULT_CDS_ARCHIVE_FILENAME \"java_pid<pid>_<subcmd>.jsa\"\n+\n@@ -986,1 +1011,2 @@\n-  _filename(\"filename\", \"Name of shared archive to be dumped\", \"STRING\", false)\n+  _filename(\"filename\", \"Name of shared archive to be dumped\", \"STRING\", false,\n+            DEFAULT_CDS_ARCHIVE_FILENAME)\n@@ -995,1 +1021,5 @@\n-  const char* file = _filename.value();\n+\n+  \/\/ The check for _filename.is_set() is because we don't want to use\n+  \/\/ DEFAULT_CDS_ARCHIVE_FILENAME, since it is meant as a description\n+  \/\/ of the default, not the actual default.\n+  const char* file = _filename.is_set() ? _filename.value() : nullptr;\n@@ -1003,1 +1033,1 @@\n-    if (!UseSharedSpaces) {\n+    if (!CDSConfig::is_using_archive()) {\n@@ -1095,2 +1125,2 @@\n-      assert(LinuxAttachListener::get_current_op(), \"should exist\");\n-      if (LinuxAttachListener::get_current_op()->is_effectively_completed()) {\n+      assert(PosixAttachListener::get_current_op(), \"should exist\");\n+      if (PosixAttachListener::get_current_op()->is_effectively_completed()) {\n@@ -1168,0 +1198,56 @@\n+\n+CompilationMemoryStatisticDCmd::CompilationMemoryStatisticDCmd(outputStream* output, bool heap) :\n+    DCmdWithParser(output, heap),\n+  _human_readable(\"-H\", \"Human readable format\", \"BOOLEAN\", false, \"false\"),\n+  _minsize(\"-s\", \"Minimum memory size\", \"MEMORY SIZE\", false, \"0\") {\n+  _dcmdparser.add_dcmd_option(&_human_readable);\n+  _dcmdparser.add_dcmd_option(&_minsize);\n+}\n+\n+void CompilationMemoryStatisticDCmd::execute(DCmdSource source, TRAPS) {\n+  const bool human_readable = _human_readable.value();\n+  const size_t minsize = _minsize.has_value() ? _minsize.value()._size : 0;\n+  CompilationMemoryStatistic::print_all_by_size(output(), human_readable, minsize);\n+}\n+\n+#ifdef LINUX\n+\n+SystemMapDCmd::SystemMapDCmd(outputStream* output, bool heap) :\n+    DCmdWithParser(output, heap),\n+  _human_readable(\"-H\", \"Human readable format\", \"BOOLEAN\", false, \"false\") {\n+  _dcmdparser.add_dcmd_option(&_human_readable);\n+}\n+\n+void SystemMapDCmd::execute(DCmdSource source, TRAPS) {\n+  MemMapPrinter::print_all_mappings(output(), _human_readable.value());\n+}\n+\n+SystemDumpMapDCmd::SystemDumpMapDCmd(outputStream* output, bool heap) :\n+    DCmdWithParser(output, heap),\n+  _human_readable(\"-H\", \"Human readable format\", \"BOOLEAN\", false, \"false\"),\n+  _filename(\"-F\", \"file path (defaults: \\\"vm_memory_map_<pid>.txt\\\")\", \"STRING\", false) {\n+  _dcmdparser.add_dcmd_option(&_human_readable);\n+  _dcmdparser.add_dcmd_option(&_filename);\n+}\n+\n+void SystemDumpMapDCmd::execute(DCmdSource source, TRAPS) {\n+  stringStream default_name;\n+  default_name.print(\"vm_memory_map_%d.txt\", os::current_process_id());\n+  const char* name = _filename.is_set() ? _filename.value() : default_name.base();\n+  fileStream fs(name);\n+  if (fs.is_open()) {\n+    if (!MemTracker::enabled()) {\n+      output()->print_cr(\"(NMT is disabled, will not annotate mappings).\");\n+    }\n+    MemMapPrinter::print_all_mappings(&fs, _human_readable.value());\n+    \/\/ For the readers convenience, resolve path name.\n+    char tmp[JVM_MAXPATHLEN];\n+    const char* absname = os::Posix::realpath(name, tmp, sizeof(tmp));\n+    name = absname != nullptr ? absname : name;\n+    output()->print_cr(\"Memory map dumped to \\\"%s\\\".\", name);\n+  } else {\n+    output()->print_cr(\"Failed to open \\\"%s\\\" for writing (%s).\", name, os::strerror(errno));\n+  }\n+}\n+\n+#endif \/\/ LINUX\n","filename":"src\/hotspot\/share\/services\/diagnosticCommand.cpp","additions":104,"deletions":18,"binary":false,"changes":122,"status":"modified"},{"patch":"@@ -580,1 +580,3 @@\n-class PerfMapDCmd : public DCmd {\n+class PerfMapDCmd : public DCmdWithParser {\n+protected:\n+  DCmdArgument<char*> _filename;\n@@ -582,1 +584,2 @@\n-  PerfMapDCmd(outputStream* output, bool heap) : DCmd(output, heap) {}\n+  static int num_arguments() { return 1; }\n+  PerfMapDCmd(outputStream* output, bool heap);\n@@ -957,0 +960,65 @@\n+class CompilationMemoryStatisticDCmd: public DCmdWithParser {\n+protected:\n+  DCmdArgument<bool> _human_readable;\n+  DCmdArgument<MemorySizeArgument> _minsize;\n+public:\n+  static int num_arguments() { return 2; }\n+  CompilationMemoryStatisticDCmd(outputStream* output, bool heap);\n+  static const char* name() {\n+    return \"Compiler.memory\";\n+  }\n+  static const char* description() {\n+    return \"Print compilation footprint\";\n+  }\n+  static const char* impact() {\n+    return \"Medium: Pause time depends on number of compiled methods\";\n+  }\n+  static const JavaPermission permission() {\n+    JavaPermission p = {\"java.lang.management.ManagementPermission\",\n+                        \"monitor\", nullptr};\n+    return p;\n+  }\n+  virtual void execute(DCmdSource source, TRAPS);\n+};\n+\n+#ifdef LINUX\n+\n+class SystemMapDCmd : public DCmdWithParser {\n+  DCmdArgument<bool> _human_readable;\n+public:\n+  static int num_arguments() { return 1; }\n+  SystemMapDCmd(outputStream* output, bool heap);\n+  static const char* name() { return \"System.map\"; }\n+  static const char* description() {\n+    return \"Prints an annotated process memory map of the VM process (linux only).\";\n+  }\n+  static const char* impact() { return \"Low\"; }\n+  static const JavaPermission permission() {\n+    JavaPermission p = {\"java.lang.management.ManagementPermission\",\n+                        \"control\", nullptr};\n+    return p;\n+  }\n+  virtual void execute(DCmdSource source, TRAPS);\n+};\n+\n+class SystemDumpMapDCmd : public DCmdWithParser {\n+  DCmdArgument<bool> _human_readable;\n+  DCmdArgument<char*> _filename;\n+public:\n+  static int num_arguments() { return 2; }\n+  SystemDumpMapDCmd(outputStream* output, bool heap);\n+  static const char* name() { return \"System.dump_map\"; }\n+  static const char* description() {\n+    return \"Dumps an annotated process memory map to an output file (linux only).\";\n+  }\n+  static const char* impact() { return \"Low\"; }\n+  static const JavaPermission permission() {\n+    JavaPermission p = {\"java.lang.management.ManagementPermission\",\n+                        \"control\", nullptr};\n+    return p;\n+  }\n+  virtual void execute(DCmdSource source, TRAPS);\n+};\n+\n+#endif \/\/ LINUX\n+\n","filename":"src\/hotspot\/share\/services\/diagnosticCommand.hpp","additions":70,"deletions":2,"binary":false,"changes":72,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -1449,1 +1449,1 @@\n-    \/\/ Exclude notproduct and develop flags in product builds.\n+    \/\/ Exclude develop flags in product builds.\n@@ -1476,1 +1476,1 @@\n-bool add_global_entry(Handle name, jmmVMGlobal *global, JVMFlag *flag, TRAPS) {\n+static bool add_global_entry(Handle name, jmmVMGlobal *global, JVMFlag *flag, TRAPS) {\n@@ -1606,1 +1606,1 @@\n-      \/\/ Exclude notproduct and develop flags in product builds.\n+      \/\/ Exclude develop flags in product builds.\n@@ -2020,1 +2020,3 @@\n-    int pos = info_list->find((void*)cmd_name,DCmdInfo::by_name);\n+    int pos = info_list->find_if([&](DCmdInfo* info) {\n+      return info->name_equals(cmd_name);\n+    });\n","filename":"src\/hotspot\/share\/services\/management.cpp","additions":7,"deletions":5,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -642,0 +642,6 @@\n+#ifdef ADDRESS_SANITIZER\n+#define INCLUDE_ASAN 1\n+#else\n+#define INCLUDE_ASAN 0\n+#endif\n+\n","filename":"src\/hotspot\/share\/utilities\/macros.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -216,1 +216,1 @@\n-                long comp = Blocker.begin(blocking);\n+                boolean attempted = Blocker.begin(blocking);\n@@ -222,1 +222,1 @@\n-                    Blocker.end(comp);\n+                    Blocker.end(attempted);\n","filename":"src\/java.base\/linux\/classes\/sun\/nio\/ch\/EPollSelectorImpl.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -284,1 +284,1 @@\n-        long comp = Blocker.begin();\n+        boolean attempted = Blocker.begin();\n@@ -288,1 +288,1 @@\n-            Blocker.end(comp);\n+            Blocker.end(attempted);\n","filename":"src\/java.base\/share\/classes\/java\/io\/FileDescriptor.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1994, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1994, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -37,1 +37,1 @@\n-import jdk.internal.misc.Blocker;\n+import jdk.internal.event.FileReadEvent;\n@@ -70,0 +70,6 @@\n+    \/**\n+     * Flag set by jdk.internal.event.JFRTracing to indicate if\n+     * file reads should be traced by JFR.\n+     *\/\n+    private static boolean jfrTracing;\n+\n@@ -143,0 +149,1 @@\n+    @SuppressWarnings(\"this-escape\")\n@@ -187,0 +194,1 @@\n+    @SuppressWarnings(\"this-escape\")\n@@ -218,6 +226,1 @@\n-        long comp = Blocker.begin();\n-        try {\n-            open0(name);\n-        } finally {\n-            Blocker.end(comp);\n-        }\n+        open0(name);\n@@ -236,5 +239,2 @@\n-        long comp = Blocker.begin();\n-        try {\n-            return read0();\n-        } finally {\n-            Blocker.end(comp);\n+        if (jfrTracing && FileReadEvent.enabled()) {\n+            return traceRead0();\n@@ -242,0 +242,1 @@\n+        return read0();\n@@ -246,0 +247,22 @@\n+    private int traceRead0() throws IOException {\n+        int result = 0;\n+        boolean endOfFile = false;\n+        long bytesRead = 0;\n+        long start = 0;\n+        try {\n+            start = FileReadEvent.timestamp();\n+            result = read0();\n+            if (result < 0) {\n+                endOfFile = true;\n+            } else {\n+                bytesRead = 1;\n+            }\n+        } finally {\n+            long duration = FileReadEvent.timestamp() - start;\n+            if (FileReadEvent.shouldCommit(duration)) {\n+                FileReadEvent.commit(start, duration, path, bytesRead, endOfFile);\n+            }\n+        }\n+        return result;\n+    }\n+\n@@ -255,0 +278,19 @@\n+    private int traceReadBytes(byte b[], int off, int len) throws IOException {\n+        int bytesRead = 0;\n+        long start = 0;\n+        try {\n+            start = FileReadEvent.timestamp();\n+            bytesRead = readBytes(b, off, len);\n+        } finally {\n+            long duration = FileReadEvent.timestamp() - start;\n+            if (FileReadEvent.shouldCommit(duration)) {\n+                if (bytesRead < 0) {\n+                    FileReadEvent.commit(start, duration, path, 0L, true);\n+                } else {\n+                    FileReadEvent.commit(start, duration, path, bytesRead, false);\n+                }\n+            }\n+        }\n+        return bytesRead;\n+    }\n+\n@@ -268,5 +310,2 @@\n-        long comp = Blocker.begin();\n-        try {\n-            return readBytes(b, 0, b.length);\n-        } finally {\n-            Blocker.end(comp);\n+        if (jfrTracing && FileReadEvent.enabled()) {\n+            return traceReadBytes(b, 0, b.length);\n@@ -274,0 +313,1 @@\n+        return readBytes(b, 0, b.length);\n@@ -292,5 +332,2 @@\n-        long comp = Blocker.begin();\n-        try {\n-            return readBytes(b, off, len);\n-        } finally {\n-            Blocker.end(comp);\n+        if (jfrTracing && FileReadEvent.enabled()) {\n+            return traceReadBytes(b, off, len);\n@@ -298,0 +335,1 @@\n+        return readBytes(b, off, len);\n@@ -404,6 +442,1 @@\n-        long comp = Blocker.begin();\n-        try {\n-            return length0();\n-        } finally {\n-            Blocker.end(comp);\n-        }\n+        return length0();\n@@ -414,6 +447,1 @@\n-        long comp = Blocker.begin();\n-        try {\n-            return position0();\n-        } finally {\n-            Blocker.end(comp);\n-        }\n+        return position0();\n@@ -449,6 +477,1 @@\n-        long comp = Blocker.begin();\n-        try {\n-            return skip0(n);\n-        } finally {\n-            Blocker.end(comp);\n-        }\n+        return skip0(n);\n@@ -478,6 +501,1 @@\n-        long comp = Blocker.begin();\n-        try {\n-            return available0();\n-        } finally {\n-            Blocker.end(comp);\n-        }\n+        return available0();\n@@ -509,2 +527,0 @@\n-     *\n-     * @revised 1.4\n@@ -576,2 +592,2 @@\n-                    this.channel = fc = FileChannelImpl.open(fd, path, true,\n-                        false, false, this);\n+                    fc = FileChannelImpl.open(fd, path, true, false, false, false, this);\n+                    this.channel = fc;\n","filename":"src\/java.base\/share\/classes\/java\/io\/FileInputStream.java","additions":67,"deletions":51,"binary":false,"changes":118,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1994, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1994, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -40,1 +40,1 @@\n-import jdk.internal.misc.Blocker;\n+import jdk.internal.event.FileWriteEvent;\n@@ -81,0 +81,6 @@\n+    \/**\n+     * Flag set by jdk.internal.event.JFRTracing to indicate if\n+     * file writes should be traced by JFR.\n+     *\/\n+    private static boolean jfrTracing;\n+\n@@ -230,0 +236,1 @@\n+    @SuppressWarnings(\"this-escape\")\n@@ -281,0 +288,1 @@\n+    @SuppressWarnings(\"this-escape\")\n@@ -313,6 +321,1 @@\n-        long comp = Blocker.begin();\n-        try {\n-            open0(name, append, !append);\n-        } finally {\n-            Blocker.end(comp);\n-        }\n+        open0(name, append, !append);\n@@ -330,0 +333,15 @@\n+    private void traceWrite(int b, boolean append) throws IOException {\n+        long bytesWritten = 0;\n+        long start = 0;\n+        try {\n+            start = FileWriteEvent.timestamp();\n+            write(b, append);\n+            bytesWritten = 1;\n+        } finally {\n+            long duration = FileWriteEvent.timestamp() - start;\n+            if (FileWriteEvent.shouldCommit(duration)) {\n+                FileWriteEvent.commit(start, duration, path, bytesWritten);\n+            }\n+        }\n+    }\n+\n@@ -340,5 +358,3 @@\n-        long comp = Blocker.begin();\n-        try {\n-            write(b, append);\n-        } finally {\n-            Blocker.end(comp);\n+        if (jfrTracing && FileWriteEvent.enabled()) {\n+            traceWrite(b, append);\n+            return;\n@@ -346,0 +362,1 @@\n+        write(b, append);\n@@ -360,0 +377,15 @@\n+    private void traceWriteBytes(byte b[], int off, int len, boolean append) throws IOException {\n+        long bytesWritten = 0;\n+        long start = 0;\n+        try {\n+            start = FileWriteEvent.timestamp();\n+            writeBytes(b, off, len, append);\n+            bytesWritten = len;\n+        } finally {\n+            long duration = FileWriteEvent.timestamp() - start;\n+            if (FileWriteEvent.shouldCommit(duration)) {\n+                FileWriteEvent.commit(start, duration, path, bytesWritten);\n+            }\n+        }\n+    }\n+\n@@ -370,5 +402,3 @@\n-        long comp = Blocker.begin();\n-        try {\n-            writeBytes(b, 0, b.length, append);\n-        } finally {\n-            Blocker.end(comp);\n+        if (jfrTracing && FileWriteEvent.enabled()) {\n+            traceWriteBytes(b, 0, b.length, append);\n+            return;\n@@ -376,0 +406,1 @@\n+        writeBytes(b, 0, b.length, append);\n@@ -391,5 +422,3 @@\n-        long comp = Blocker.begin();\n-        try {\n-            writeBytes(b, off, len, append);\n-        } finally {\n-            Blocker.end(comp);\n+        if (jfrTracing && FileWriteEvent.enabled()) {\n+            traceWriteBytes(b, off, len, append);\n+            return;\n@@ -397,0 +426,1 @@\n+        writeBytes(b, off, len, append);\n@@ -421,2 +451,0 @@\n-     *\n-     * @revised 1.4\n@@ -489,2 +517,2 @@\n-                    this.channel = fc = FileChannelImpl.open(fd, path, false,\n-                        true, false, this);\n+                    fc = FileChannelImpl.open(fd, path, false, true, false, false, this);\n+                    this.channel = fc;\n","filename":"src\/java.base\/share\/classes\/java\/io\/FileOutputStream.java","additions":55,"deletions":27,"binary":false,"changes":82,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1994, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1994, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -36,0 +36,2 @@\n+import jdk.internal.event.FileReadEvent;\n+import jdk.internal.event.FileWriteEvent;\n@@ -73,0 +75,6 @@\n+    \/**\n+     * Flag set by jdk.internal.event.JFRTracing to indicate if\n+     * file reads and writes should be traced by JFR.\n+     *\/\n+    private static boolean jfrTracing;\n+\n@@ -76,0 +84,1 @@\n+    private final boolean sync;  \/\/ O_SYNC or O_DSYNC\n@@ -129,1 +138,1 @@\n-     * to write to, a file with the specified name. A new\n+     * to write to, a file with the specified pathname. A new\n@@ -140,1 +149,1 @@\n-     * is called with the {@code name} argument\n+     * is called with the {@code pathname} argument\n@@ -144,1 +153,1 @@\n-     * is also called with the {@code name} argument\n+     * is also called with the {@code pathname} argument\n@@ -147,2 +156,2 @@\n-     * @param      name   the system-dependent filename\n-     * @param      mode   the access <a href=\"#mode\">mode<\/a>\n+     * @param      pathname   the system-dependent pathname string\n+     * @param      mode       the access <a href=\"#mode\">mode<\/a>\n@@ -153,1 +162,1 @@\n-     *             if the mode is {@code \"r\"} but the given string does not\n+     *             if the mode is {@code \"r\"} but the given pathname string does not\n@@ -155,1 +164,1 @@\n-     *             {@code \"rw\"} but the given string does not denote an\n+     *             {@code \"rw\"} but the given pathname string does not denote an\n@@ -157,2 +166,2 @@\n-     *             that name cannot be created, or if some other error occurs\n-     *             while opening or creating the file\n+     *             that pathname cannot be created, or if some other error\n+     *             occurs while opening or creating the file\n@@ -166,2 +175,1 @@\n-     * @revised 1.4\n-    public RandomAccessFile(String name, String mode)\n+    public RandomAccessFile(String pathname, String mode)\n@@ -171,1 +179,1 @@\n-        this(name != null ? new File(name) : null, mode);\n+        this(pathname != null ? new File(pathname) : null, mode);\n@@ -229,2 +237,2 @@\n-     * also called with the path argument to see if write access to the file is\n-     * allowed.\n+     * also called with the pathname of the {@code file} argument to see if\n+     * write access to the file is allowed.\n@@ -243,2 +251,2 @@\n-     *             that name cannot be created, or if some other error occurs\n-     *             while opening or creating the file\n+     *             that pathname cannot be created, or if some other error\n+     *             occurs while opening or creating the file\n@@ -252,1 +260,1 @@\n-     * @revised 1.4\n+    @SuppressWarnings(\"this-escape\")\n@@ -267,0 +275,1 @@\n+        boolean sync = false;\n@@ -273,1 +282,1 @@\n-                if (mode.equals(\"rws\"))\n+                if (mode.equals(\"rws\")) {\n@@ -275,1 +284,2 @@\n-                else if (mode.equals(\"rwd\"))\n+                    sync = true;\n+                } else if (mode.equals(\"rwd\")) {\n@@ -277,1 +287,2 @@\n-                else\n+                    sync = true;\n+                } else\n@@ -282,0 +293,1 @@\n+        this.sync = sync;\n@@ -347,2 +359,2 @@\n-                    this.channel = fc = FileChannelImpl.open(fd, path, true,\n-                        rw, false, this);\n+                    fc = FileChannelImpl.open(fd, path, true, rw, sync, false, this);\n+                    this.channel = fc;\n@@ -389,6 +401,1 @@\n-        long comp = Blocker.begin();\n-        try {\n-            open0(name, mode);\n-        } finally {\n-            Blocker.end(comp);\n-        }\n+        open0(name, mode);\n@@ -415,5 +422,2 @@\n-        long comp = Blocker.begin();\n-        try {\n-            return read0();\n-        } finally {\n-            Blocker.end(comp);\n+        if (jfrTracing && FileReadEvent.enabled()) {\n+            return traceRead0();\n@@ -421,0 +425,1 @@\n+        return read0();\n@@ -425,0 +430,22 @@\n+    private int traceRead0() throws IOException {\n+        int result = 0;\n+        long bytesRead = 0;\n+        boolean endOfFile = false;\n+        long start = 0;\n+        try {\n+            start = FileReadEvent.timestamp();\n+            result = read0();\n+            if (result < 0) {\n+                endOfFile = true;\n+            } else {\n+                bytesRead = 1;\n+            }\n+        } finally {\n+            long duration = FileReadEvent.timestamp() - start;\n+            if (FileReadEvent.shouldCommit(duration)) {\n+                FileReadEvent.commit(start, duration, path, bytesRead, endOfFile);\n+            }\n+        }\n+        return result;\n+    }\n+\n@@ -433,5 +460,2 @@\n-        long comp = Blocker.begin();\n-        try {\n-            return readBytes0(b, off, len);\n-        } finally {\n-            Blocker.end(comp);\n+        if (jfrTracing && FileReadEvent.enabled()) {\n+            return traceReadBytes0(b, off, len);\n@@ -439,0 +463,1 @@\n+        return readBytes0(b, off, len);\n@@ -443,0 +468,19 @@\n+    private int traceReadBytes0(byte b[], int off, int len) throws IOException {\n+        int bytesRead = 0;\n+        long start = 0;\n+        try {\n+            start = FileReadEvent.timestamp();\n+            bytesRead = readBytes0(b, off, len);\n+        } finally {\n+            long duration = FileReadEvent.timestamp() - start;\n+            if (FileReadEvent.shouldCommit(duration)) {\n+                if (bytesRead < 0) {\n+                    FileReadEvent.commit(start, duration, path, 0L, true);\n+                } else {\n+                    FileReadEvent.commit(start, duration, path, bytesRead, false);\n+                }\n+            }\n+        }\n+        return bytesRead;\n+    }\n+\n@@ -586,1 +630,9 @@\n-        long comp = Blocker.begin();\n+        if (jfrTracing && FileWriteEvent.enabled()) {\n+            traceImplWrite(b);\n+            return;\n+        }\n+        implWrite(b);\n+    }\n+\n+    private void implWrite(int b) throws IOException {\n+        boolean attempted = Blocker.begin(sync);\n@@ -590,1 +642,16 @@\n-            Blocker.end(comp);\n+            Blocker.end(attempted);\n+        }\n+    }\n+\n+    private void traceImplWrite(int b) throws IOException {\n+        long bytesWritten = 0;\n+        long start = 0;\n+        try {\n+            start = FileWriteEvent.timestamp();\n+            implWrite(b);\n+            bytesWritten = 1;\n+        } finally {\n+            long duration = FileWriteEvent.timestamp() - start;\n+            if (FileWriteEvent.shouldCommit(duration)) {\n+                FileWriteEvent.commit(start, duration, path, bytesWritten);\n+            }\n@@ -605,1 +672,9 @@\n-        long comp = Blocker.begin();\n+        if (jfrTracing && FileWriteEvent.enabled()) {\n+            traceImplWriteBytes(b, off, len);\n+            return;\n+        }\n+        implWriteBytes(b, off, len);\n+    }\n+\n+    private void implWriteBytes(byte[] b, int off, int len) throws IOException {\n+        boolean attempted = Blocker.begin(sync);\n@@ -609,1 +684,16 @@\n-            Blocker.end(comp);\n+            Blocker.end(attempted);\n+        }\n+    }\n+\n+    private void traceImplWriteBytes(byte b[], int off, int len) throws IOException {\n+        long bytesWritten = 0;\n+        long start = 0;\n+        try {\n+            start = FileWriteEvent.timestamp();\n+            implWriteBytes(b, off, len);\n+            bytesWritten = len;\n+        } finally {\n+            long duration = FileWriteEvent.timestamp() - start;\n+            if (FileWriteEvent.shouldCommit(duration)) {\n+                FileWriteEvent.commit(start, duration, path, bytesWritten);\n+            }\n@@ -669,6 +759,1 @@\n-        long comp = Blocker.begin();\n-        try {\n-            seek0(pos);\n-        } finally {\n-            Blocker.end(comp);\n-        }\n+        seek0(pos);\n@@ -686,6 +771,1 @@\n-        long comp = Blocker.begin();\n-        try {\n-            return length0();\n-        } finally {\n-            Blocker.end(comp);\n-        }\n+        return length0();\n@@ -700,5 +780,3 @@\n-     * {@code length} method is greater than the {@code newLength}\n-     * argument then the file will be truncated.  In this case, if the file\n-     * offset as returned by the {@code getFilePointer} method is greater\n-     * than {@code newLength} then after this method returns the offset\n-     * will be equal to {@code newLength}.\n+     * {@linkplain #length length} method is greater than the desired length\n+     * of the file specified by the {@code newLength} argument, then the file\n+     * will be truncated.\n@@ -706,4 +784,12 @@\n-     * <p> If the present length of the file as returned by the\n-     * {@code length} method is smaller than the {@code newLength}\n-     * argument then the file will be extended.  In this case, the contents of\n-     * the extended portion of the file are not defined.\n+     * <p> If the present length of the file is smaller than the desired length,\n+     * then the file will be extended.  The contents of the extended portion of\n+     * the file are not defined.\n+     *\n+     * <p> If the present length of the file is equal to the desired length,\n+     * then the file and its length will be unchanged.\n+     *\n+     * <p> In all cases, after this method returns, the file offset as returned\n+     * by the {@linkplain #getFilePointer getFilePointer} method will equal the\n+     * minimum of the desired length and the file offset before this method was\n+     * called, even if the length is unchanged.  In other words, this method\n+     * constrains the file offset to the closed interval {@code [0,newLength]}.\n@@ -712,1 +798,2 @@\n-     * @throws     IOException  If an I\/O error occurs\n+     * @throws     IOException  If the argument is negative or\n+     *                          if some other I\/O error occurs\n@@ -716,6 +803,1 @@\n-        long comp = Blocker.begin();\n-        try {\n-            setLength0(newLength);\n-        } finally {\n-            Blocker.end(comp);\n-        }\n+        setLength0(newLength);\n@@ -741,2 +823,0 @@\n-     *\n-     * @revised 1.4\n","filename":"src\/java.base\/share\/classes\/java\/io\/RandomAccessFile.java","additions":153,"deletions":73,"binary":false,"changes":226,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1995, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1995, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -35,0 +35,1 @@\n+import jdk.internal.misc.Blocker;\n@@ -852,0 +853,69 @@\n+\n+        @Override\n+        public int read() throws IOException {\n+            boolean attempted = Blocker.begin();\n+            try {\n+                return super.read();\n+            } finally {\n+                Blocker.end(attempted);\n+            }\n+        }\n+\n+        @Override\n+        public int read(byte[] b) throws IOException {\n+            boolean attempted = Blocker.begin();\n+            try {\n+                return super.read(b);\n+            } finally {\n+                Blocker.end(attempted);\n+            }\n+        }\n+\n+        @Override\n+        public int read(byte[] b, int off, int len) throws IOException {\n+            boolean attempted = Blocker.begin();\n+            try {\n+                return super.read(b, off, len);\n+            } finally {\n+                Blocker.end(attempted);\n+            }\n+        }\n+    }\n+\n+    \/**\n+     * An output stream for a subprocess pipe.\n+     *\/\n+    static class PipeOutputStream extends FileOutputStream {\n+        PipeOutputStream(FileDescriptor fd) {\n+            super(fd);\n+        }\n+\n+        @Override\n+        public void write(int b) throws IOException {\n+            boolean attempted = Blocker.begin();\n+            try {\n+                super.write(b);\n+            } finally {\n+                Blocker.end(attempted);\n+            }\n+        }\n+\n+        @Override\n+        public void write(byte[] b) throws IOException {\n+            boolean attempted = Blocker.begin();\n+            try {\n+                super.write(b);\n+            } finally {\n+                Blocker.end(attempted);\n+            }\n+        }\n+\n+        @Override\n+        public void write(byte[] b, int off, int len) throws IOException {\n+            boolean attempted = Blocker.begin();\n+            try {\n+                super.write(b, off, len);\n+            } finally {\n+                Blocker.end(attempted);\n+            }\n+        }\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Process.java","additions":71,"deletions":1,"binary":false,"changes":72,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1994, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1994, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -38,0 +38,1 @@\n+import java.lang.foreign.MemorySegment;\n@@ -59,0 +60,1 @@\n+import java.util.Locale;\n@@ -71,0 +73,2 @@\n+import jdk.internal.logger.LoggerFinderLoader.TemporaryLoggerFinder;\n+import jdk.internal.misc.Blocker;\n@@ -80,1 +84,0 @@\n-import jdk.internal.javac.PreviewFeature;\n@@ -90,1 +93,0 @@\n-import jdk.internal.vm.annotation.ForceInline;\n@@ -192,2 +194,3 @@\n-    \/\/ Holder for the initial value of `in`, set within `initPhase1()`.\n-    private static InputStream initialIn;\n+    \/\/ Initial values of System.in and System.err, set in initPhase1().\n+    private static @Stable InputStream initialIn;\n+    private static @Stable PrintStream initialErr;\n@@ -356,3 +359,0 @@\n-    \/\/ Remember initial System.err. setSecurityManager() warning goes here\n-    private static volatile @Stable PrintStream initialErrStream;\n-\n@@ -418,1 +418,1 @@\n-                initialErrStream.printf(\"\"\"\n+                initialErr.printf(\"\"\"\n@@ -820,0 +820,4 @@\n+     * <p>\n+     * Additional locale-related system properties defined by the\n+     * {@link Locale##default_locale Default Locale} section in the {@code Locale}\n+     * class description may also be obtained with this method.\n@@ -1798,1 +1802,2 @@\n-            if (service == null) {\n+            LoggerFinder finder = service;\n+            if (finder == null) {\n@@ -1801,1 +1806,1 @@\n-                service = AccessController.doPrivileged(pa, null,\n+                finder = AccessController.doPrivileged(pa, null,\n@@ -1803,0 +1808,2 @@\n+                if (finder instanceof TemporaryLoggerFinder) return finder;\n+                service = finder;\n@@ -1804,1 +1811,1 @@\n-            return service;\n+            return finder;\n@@ -2214,3 +2221,3 @@\n-        FileInputStream fdIn = new FileInputStream(FileDescriptor.in);\n-        FileOutputStream fdOut = new FileOutputStream(FileDescriptor.out);\n-        FileOutputStream fdErr = new FileOutputStream(FileDescriptor.err);\n+        FileInputStream fdIn = new In(FileDescriptor.in);\n+        FileOutputStream fdOut = new Out(FileDescriptor.out);\n+        FileOutputStream fdErr = new Out(FileDescriptor.err);\n@@ -2223,1 +2230,2 @@\n-        setErr0(newPrintStream(fdErr, props.getProperty(\"stderr.encoding\")));\n+        initialErr = newPrintStream(fdErr, props.getProperty(\"stderr.encoding\"));\n+        setErr0(initialErr);\n@@ -2241,0 +2249,77 @@\n+    \/**\n+     * System.in.\n+     *\/\n+    private static class In extends FileInputStream {\n+        In(FileDescriptor fd) {\n+            super(fd);\n+        }\n+\n+        @Override\n+        public int read() throws IOException {\n+            boolean attempted = Blocker.begin();\n+            try {\n+                return super.read();\n+            } finally {\n+                Blocker.end(attempted);\n+            }\n+        }\n+\n+        @Override\n+        public int read(byte[] b) throws IOException {\n+            boolean attempted = Blocker.begin();\n+            try {\n+                return super.read(b);\n+            } finally {\n+                Blocker.end(attempted);\n+            }\n+        }\n+\n+        @Override\n+        public int read(byte[] b, int off, int len) throws IOException {\n+            boolean attempted = Blocker.begin();\n+            try {\n+                return super.read(b, off, len);\n+            } finally {\n+                Blocker.end(attempted);\n+            }\n+        }\n+    }\n+\n+    \/**\n+     * System.out\/System.err wrap this output stream.\n+     *\/\n+    private static class Out extends FileOutputStream {\n+        Out(FileDescriptor fd) {\n+            super(fd);\n+        }\n+\n+        public void write(int b) throws IOException {\n+            boolean attempted = Blocker.begin();\n+            try {\n+                super.write(b);\n+            } finally {\n+                Blocker.end(attempted);\n+            }\n+        }\n+\n+        @Override\n+        public void write(byte[] b) throws IOException {\n+            boolean attempted = Blocker.begin();\n+            try {\n+                super.write(b);\n+            } finally {\n+                Blocker.end(attempted);\n+            }\n+        }\n+\n+        @Override\n+        public void write(byte[] b, int off, int len) throws IOException {\n+            boolean attempted = Blocker.begin();\n+            try {\n+                super.write(b, off, len);\n+            } finally {\n+                Blocker.end(attempted);\n+            }\n+        }\n+    }\n+\n@@ -2352,2 +2437,0 @@\n-        initialErrStream = System.err;\n-\n@@ -2373,0 +2456,3 @@\n+            public Method findMethod(Class<?> klass, boolean publicOnly, String name, Class<?>... parameterTypes) {\n+                return klass.findMethod(publicOnly, name, parameterTypes);\n+            }\n@@ -2399,1 +2485,1 @@\n-                Thread.blockedOn(b);\n+                Thread.currentThread().blockedOn(b);\n@@ -2479,0 +2565,3 @@\n+            public boolean addEnableNativeAccess(ModuleLayer layer, String name) {\n+                return layer.addEnableNativeAccess(name);\n+            }\n@@ -2482,2 +2571,2 @@\n-            public void ensureNativeAccess(Module m, Class<?> owner, String methodName) {\n-                m.ensureNativeAccess(owner, methodName);\n+            public void ensureNativeAccess(Module m, Class<?> owner, String methodName, Class<?> currentClass) {\n+                m.ensureNativeAccess(owner, methodName, currentClass);\n@@ -2507,0 +2596,3 @@\n+            public void putCharUTF16(byte[] bytes, int index, int ch) {\n+                StringUTF16.putChar(bytes, index, ch);\n+            }\n@@ -2535,0 +2627,4 @@\n+            public PrintStream initialSystemErr() {\n+                return initialErr;\n+            }\n+\n@@ -2547,0 +2643,4 @@\n+            public long stringConcatHelperPrepend(long indexCoder, byte[] buf, String value) {\n+                return StringConcatHelper.prepend(indexCoder, buf, value);\n+            }\n+\n@@ -2555,3 +2655,6 @@\n-            @PreviewFeature(feature=PreviewFeature.Feature.STRING_TEMPLATES)\n-            public long stringConcatCoder(char value) {\n-                return StringConcatHelper.coder(value);\n+            public long stringConcatMix(long lengthCoder, char value) {\n+                return StringConcatHelper.mix(lengthCoder, value);\n+            }\n+\n+            public int stringSize(long i) {\n+                return Long.stringSize(i);\n@@ -2560,4 +2663,2 @@\n-            @PreviewFeature(feature=PreviewFeature.Feature.STRING_TEMPLATES)\n-            public long stringBuilderConcatMix(long lengthCoder,\n-                                               StringBuilder sb) {\n-                return sb.mix(lengthCoder);\n+            public int getCharsLatin1(long i, int index, byte[] buf) {\n+                return StringLatin1.getChars(i, index, buf);\n@@ -2566,4 +2667,2 @@\n-            @PreviewFeature(feature=PreviewFeature.Feature.STRING_TEMPLATES)\n-            public long stringBuilderConcatPrepend(long lengthCoder, byte[] buf,\n-                                                   StringBuilder sb) {\n-                return sb.prepend(lengthCoder, buf);\n+            public int getCharsUTF16(long i, int index, byte[] buf) {\n+                return StringUTF16.getChars(i, index, buf);\n@@ -2695,1 +2794,16 @@\n-                return loader.nameAndId();\n+                return loader != null ? loader.nameAndId() : \"null\";\n+            }\n+\n+            @Override\n+            public void copyToSegmentRaw(String string, MemorySegment segment, long offset) {\n+                string.copyToSegmentRaw(segment, offset);\n+            }\n+\n+            @Override\n+            public boolean bytesCompatible(String string, Charset charset) {\n+                return string.bytesCompatible(charset);\n+            }\n+\n+            @Override\n+            public boolean allowSecurityManager() {\n+                return System.allowSecurityManager();\n","filename":"src\/java.base\/share\/classes\/java\/lang\/System.java","additions":147,"deletions":33,"binary":false,"changes":180,"status":"modified"},{"patch":"@@ -42,1 +42,1 @@\n- * notified when the <a href=\"package-summary.html#reachability\">reachability<\/a>\n+ * notified when the {@linkplain java.lang.ref##reachability reachability}\n@@ -219,0 +219,8 @@\n+     * <p>The given object is kept strongly reachable (and therefore not eligible\n+     * for cleaning) during the register() method.\n+     *\n+     * <p>{@linkplain java.lang.ref##MemoryConsistency Memory consistency effects}:\n+     * Actions in a thread prior to calling {@code Cleaner.register()}\n+     * <a href=\"{@docRoot}\/java.base\/java\/util\/concurrent\/package-summary.html#MemoryVisibility\"><i>happen-before<\/i><\/a>\n+     * the cleaning action is run by the Cleaner's thread.\n+     *\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/Cleaner.java","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -405,2 +405,2 @@\n-     * Clears this reference object.  Invoking this method will not cause this\n-     * object to be enqueued.\n+     * Clears this reference object. Invoking this method does not enqueue this\n+     * object, and the garbage collector will not clear or enqueue this object.\n@@ -408,2 +408,10 @@\n-     * <p> This method is invoked only by Java code; when the garbage collector\n-     * clears references it does so directly, without invoking this method.\n+     * <p>When the garbage collector or the {@link #enqueue()} method clear\n+     * references they do so directly, without invoking this method.\n+     *\n+     * @apiNote\n+     * There is a potential race condition with the garbage collector. When this\n+     * method is called, the garbage collector may already be in the process of\n+     * (or already completed) clearing and\/or enqueueing this reference.\n+     * Avoid this race by ensuring the referent remains strongly reachable until\n+     * after the call to clear(), using {@link #reachabilityFence(Object)} if\n+     * necessary.\n@@ -487,2 +495,21 @@\n-     * Clears this reference object and adds it to the queue with which\n-     * it is registered, if any.\n+     * Clears this reference object, then attempts to add it to the queue with\n+     * which it is registered, if any.\n+     *\n+     * <p>If this reference is registered with a queue but not yet enqueued,\n+     * the reference is added to the queue; this method is\n+     * <b><i>successful<\/i><\/b> and returns true.\n+     * If this reference is not registered with a queue, or was already enqueued\n+     * (by the garbage collector, or a previous call to {@code enqueue}), this\n+     * method is <b><i>unsuccessful<\/i><\/b> and returns false.\n+     *\n+     * <p>{@linkplain java.lang.ref##MemoryConsistency Memory consistency effects}:\n+     * Actions in a thread prior to a <b><i>successful<\/i><\/b> call to {@code enqueue}\n+     * <a href=\"{@docRoot}\/java.base\/java\/util\/concurrent\/package-summary.html#MemoryVisibility\"><i>happen-before<\/i><\/a>\n+     * the reference is removed from the queue by {@link ReferenceQueue#poll}\n+     * or {@link ReferenceQueue#remove}. <b><i>Unsuccessful<\/i><\/b> calls to\n+     * {@code enqueue} have no specified memory consistency effects.\n+     *\n+     * <p> When this method clears references it does so directly, without\n+     * invoking the {@link #clear()} method. When the garbage collector clears\n+     * and enqueues references it does so directly, without invoking the\n+     * {@link #clear()} method or this method.\n@@ -490,2 +517,5 @@\n-     * <p> This method is invoked only by Java code; when the garbage collector\n-     * enqueues references it does so directly, without invoking this method.\n+     * @apiNote\n+     * Use of this method allows the registered queue's\n+     * {@link ReferenceQueue#poll} and {@link ReferenceQueue#remove} methods\n+     * to return this reference even though the referent may still be strongly\n+     * reachable.\n@@ -528,4 +558,5 @@\n-     * Ensures that the object referenced by the given reference remains\n-     * <a href=\"package-summary.html#reachability\"><em>strongly reachable<\/em><\/a>,\n-     * regardless of any prior actions of the program that might otherwise cause\n-     * the object to become unreachable; thus, the referenced object is not\n+     * Ensures that the given object remains\n+     * <a href=\"package-summary.html#reachability\"><em>strongly reachable<\/em><\/a>.\n+     * This reachability is assured regardless of any optimizing transformations\n+     * the virtual machine may perform that might otherwise allow the object to\n+     * become unreachable (see JLS {@jls 12.6.1}). Thus, the given object is not\n@@ -533,2 +564,5 @@\n-     * this method.  Invocation of this method does not itself initiate garbage\n-     * collection or finalization.\n+     * this method. References to the given object will not be cleared (or\n+     * enqueued, if applicable) by the garbage collector until after invocation\n+     * of this method.\n+     * Invocation of this method does not itself initiate reference processing,\n+     * garbage collection, or finalization.\n@@ -539,9 +573,9 @@\n-     * triggering garbage collection.  This method is designed for use in\n-     * uncommon situations of premature finalization where using\n-     * {@code synchronized} blocks or methods, or using other synchronization\n-     * facilities are not possible or do not provide the desired control.  This\n-     * method is applicable only when reclamation may have visible effects,\n-     * which is possible for objects with finalizers (See Section {@jls 12.6}\n-     * of <cite>The Java Language Specification<\/cite>) that\n-     * are implemented in ways that rely on ordering control for\n-     * correctness.\n+     * triggering garbage collection.  This method is applicable only\n+     * when reclamation may have visible effects,\n+     * such as for objects that use finalizers or {@link Cleaner}, or code that\n+     * performs {@linkplain java.lang.ref reference processing}.\n+     *\n+     * <p>{@linkplain java.lang.ref##MemoryConsistency Memory consistency effects}:\n+     * Actions in a thread prior to calling {@code reachabilityFence(x)}\n+     * <a href=\"{@docRoot}\/java.base\/java\/util\/concurrent\/package-summary.html#MemoryVisibility\"><i>happen-before<\/i><\/a>\n+     * the garbage collector clears any reference to {@code x}.\n@@ -550,6 +584,20 @@\n-     * Finalization may occur whenever the virtual machine detects that no\n-     * reference to an object will ever be stored in the heap: The garbage\n-     * collector may reclaim an object even if the fields of that object are\n-     * still in use, so long as the object has otherwise become unreachable.\n-     * This may have surprising and undesirable effects in cases such as the\n-     * following example in which the bookkeeping associated with a class is\n+     * Reference processing or finalization can occur after an object becomes\n+     * unreachable. An object can become unreachable when the virtual machine\n+     * detects that there is no further need for the object (other than for\n+     * running a finalizer). In the course of optimization, the virtual machine\n+     * can reorder operations of an object's methods such that the object\n+     * becomes unneeded earlier than might naively be expected &mdash;\n+     * including while a method of the object is still running. For instance,\n+     * the VM can move the loading of <em>values<\/em> from the object's fields\n+     * to occur earlier. The object itself is then no longer needed and becomes\n+     * unreachable, and the method can continue running using the obtained values.\n+     * This may have surprising and undesirable effects when using a Cleaner or\n+     * finalizer for cleanup: there is a race between the\n+     * program thread running the method, and the cleanup thread running the\n+     * Cleaner or finalizer. The cleanup thread could free a\n+     * resource, followed by the program thread (still running the method)\n+     * attempting to access the now-already-freed resource.\n+     * Use of {@code reachabilityFence} can prevent this race by ensuring that the\n+     * object remains strongly reachable.\n+     * <p>\n+     * The following is an example in which the bookkeeping associated with a class is\n@@ -559,1 +607,1 @@\n-     * {@code ExternalResource} has been performed; in particular here, to\n+     * {@code ExternalResource} has been performed; specifically, to\n@@ -564,1 +612,1 @@\n-     * <pre> {@code\n+     * {@snippet :\n@@ -570,1 +618,1 @@\n-     *     myIndex = ...\n+     *     this.myIndex = ...\n@@ -575,1 +623,1 @@\n-     *     externalResourceArray[myIndex] = null;\n+     *     externalResourceArray[this.myIndex] = null;\n@@ -581,1 +629,1 @@\n-     *       int i = myIndex;\n+     *       int i = this.myIndex; \/\/ last use of 'this' Resource in action()\n@@ -590,1 +638,2 @@\n-     * }}<\/pre>\n+     * }\n+     * }\n@@ -592,1 +641,1 @@\n-     * Here, the invocation of {@code reachabilityFence} is nonintuitively\n+     * The invocation of {@code reachabilityFence} is\n@@ -596,1 +645,1 @@\n-     * object.  This might be the case if, for example a usage in a user program\n+     * object.  This might be the case if, for example, a usage in a user program\n@@ -598,22 +647,5 @@\n-     * reference to this {@code Resource}.  While probably overkill here,\n-     * {@code reachabilityFence} is placed in a {@code finally} block to ensure\n-     * that it is invoked across all paths in the method.  In a method with more\n-     * complex control paths, you might need further precautions to ensure that\n-     * {@code reachabilityFence} is encountered along all of them.\n-     *\n-     * <p> It is sometimes possible to better encapsulate use of\n-     * {@code reachabilityFence}.  Continuing the above example, if it were\n-     * acceptable for the call to method {@code update} to proceed even if the\n-     * finalizer had already executed (nulling out slot), then you could\n-     * localize use of {@code reachabilityFence}:\n-     *\n-     * <pre> {@code\n-     * public void action2() {\n-     *   \/\/ ...\n-     *   Resource.update(getExternalResource());\n-     * }\n-     * private ExternalResource getExternalResource() {\n-     *   ExternalResource ext = externalResourceArray[myIndex];\n-     *   Reference.reachabilityFence(this);\n-     *   return ext;\n-     * }}<\/pre>\n+     * reference to this {@code Resource}.\n+     * The {@code reachabilityFence} call is placed in a {@code finally} block to\n+     * ensure that it is invoked across all paths in the method. A more complex\n+     * method might need further precautions to ensure that\n+     * {@code reachabilityFence} is encountered along all code paths.\n@@ -629,1 +661,1 @@\n-     * remains a better option in cases where this approach is not as efficient,\n+     * remains a better option in cases where synchronization is not as efficient,\n@@ -632,1 +664,2 @@\n-     * @param ref the reference. If {@code null}, this method has no effect.\n+     * @param ref the reference to the object to keep strongly reachable. If\n+     * {@code null}, this method has no effect.\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/Reference.java","additions":94,"deletions":61,"binary":false,"changes":155,"status":"modified"},{"patch":"@@ -37,0 +37,8 @@\n+ *\n+ * <p>{@linkplain java.lang.ref##MemoryConsistency Memory consistency effects}:\n+ * The enqueueing of a reference to a queue (by the garbage collector, or by a\n+ * successful call to {@link Reference#enqueue})\n+ * <a href=\"{@docRoot}\/java.base\/java\/util\/concurrent\/package-summary.html#MemoryVisibility\"><i>happens-before<\/i><\/a>\n+ * the reference is removed from the queue by {@link ReferenceQueue#poll} or\n+ * {@link ReferenceQueue#remove}.\n+ *\n@@ -178,0 +186,1 @@\n+     * @see java.lang.ref.Reference#enqueue()\n@@ -232,0 +241,2 @@\n+     *\n+     * @see java.lang.ref.Reference#enqueue()\n@@ -253,0 +264,1 @@\n+     * @see java.lang.ref.Reference#enqueue()\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/ReferenceQueue.java","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1996, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1996, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -200,1 +200,1 @@\n-    @Deprecated\n+    @Deprecated(forRemoval = true, since = \"1.2\")\n@@ -212,1 +212,1 @@\n-    @Deprecated\n+    @Deprecated(forRemoval = true, since = \"1.2\")\n","filename":"src\/java.base\/share\/classes\/java\/net\/DatagramSocketImpl.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1995, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1995, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -143,1 +143,1 @@\n- * <h3> Textual representation of IP addresses <\/h3>\n+ * <h3> <a id=\"format\">Textual representation of IP addresses<\/a> <\/h3>\n@@ -201,2 +201,2 @@\n- * <p> Three Java security properties control the TTL values used for\n- *  positive and negative host name resolution caching:\n+ * <p> Three Java {@linkplain java.security.Security security} properties control\n+ * the TTL values used for positive and negative host name resolution caching:\n@@ -761,2 +761,2 @@\n-     * and the result will be returned based on the system\n-     * configured resolver. If a lookup of the name service\n+     * and the result will be returned based on the system-wide\n+     * resolver. If a lookup of the name service\n@@ -815,3 +815,9 @@\n-     * Gets the fully qualified domain name for this IP address.\n-     * Best effort method, meaning we may not be able to return\n-     * the FQDN depending on the underlying system configuration.\n+     * Gets the fully qualified domain name for this\n+     * {@linkplain InetAddress#getAddress() IP address} using the system-wide\n+     * {@linkplain InetAddressResolver resolver}.\n+     *\n+     * <p>The system-wide resolver will be used to do a reverse name lookup of the IP address.\n+     * The lookup can fail for many reasons that include the host not being registered with the name\n+     * service. If the resolver is unable to determine the fully qualified\n+     * domain name, this method returns the {@linkplain #getHostAddress() textual representation}\n+     * of the IP address.\n@@ -827,3 +833,5 @@\n-     * @return  the fully qualified domain name for this IP address,\n-     *    or if the operation is not allowed by the security check,\n-     *    the textual representation of the IP address.\n+     * @return  the fully qualified domain name for this IP address.\n+     *          If either the operation is not allowed by the security check\n+     *          or the system-wide resolver wasn't able to determine the\n+     *          fully qualified domain name for the IP address, the textual\n+     *          representation of the IP address is returned instead.\n@@ -844,1 +852,1 @@\n-     * Returns the hostname for this address.\n+     * Returns the fully qualified domain name for the given address.\n@@ -850,1 +858,1 @@\n-     * the hostname for this IP address, i.e., to connect to the host.\n+     * the hostname for the given IP address, i.e., to connect to the host.\n@@ -854,4 +862,0 @@\n-     * @return  the host name for this IP address, or if the operation\n-     *    is not allowed by the security check, the textual\n-     *    representation of the IP address.\n-     *\n@@ -860,0 +864,6 @@\n+     * @return  the fully qualified domain name for the given IP address.\n+     *          If either the operation is not allowed by the security check\n+     *          or the system-wide resolver wasn't able to determine the\n+     *          fully qualified domain name for the IP address, the textual\n+     *          representation of the IP address is returned instead.\n+     *\n@@ -1236,1 +1246,1 @@\n-            long comp = Blocker.begin();\n+            boolean attempted = Blocker.begin();\n@@ -1240,1 +1250,1 @@\n-                Blocker.end(comp);\n+                Blocker.end(attempted);\n@@ -1250,1 +1260,1 @@\n-            long comp = Blocker.begin();\n+            boolean attempted = Blocker.begin();\n@@ -1254,1 +1264,1 @@\n-                Blocker.end(comp);\n+                Blocker.end(attempted);\n@@ -1437,1 +1447,1 @@\n-                addrArray = IPAddressUtil.validateNumericFormatV4(addrStr);\n+                addrArray = IPAddressUtil.validateNumericFormatV4(addrStr, false);\n@@ -1600,1 +1610,1 @@\n-     * based on the configured system {@linkplain InetAddressResolver resolver}.\n+     * based on the system-wide {@linkplain InetAddressResolver resolver}.\n@@ -1664,4 +1674,1 @@\n-            byte[] addr = null;\n-            int numericZone = -1;\n-            String ifname = null;\n-\n+            InetAddress inetAddress = null;\n@@ -1671,1 +1678,2 @@\n-                    addr = IPAddressUtil.validateNumericFormatV4(host);\n+                    \/\/ Here we check the address string for ambiguity only\n+                    inetAddress = Inet4Address.parseAddressString(host, false);\n@@ -1678,11 +1686,5 @@\n-            if (addr == null) {\n-                \/\/ Try to parse host string as an IPv6 literal\n-                \/\/ Check if a numeric or string zone id is present first\n-                int pos;\n-                if ((pos = host.indexOf('%')) != -1) {\n-                    numericZone = checkNumericZone(host);\n-                    if (numericZone == -1) { \/* remainder of string must be an ifname *\/\n-                        ifname = host.substring(pos + 1);\n-                    }\n-                }\n-                if ((addr = IPAddressUtil.textToNumericFormatV6(host)) == null &&\n+            if (inetAddress == null) {\n+                \/\/ This is supposed to be an IPv6 literal\n+                \/\/ Check for presence of a numeric or string zone id\n+                \/\/ is done in Inet6Address.parseAddressString\n+                if ((inetAddress = Inet6Address.parseAddressString(host, false)) == null &&\n@@ -1693,16 +1695,2 @@\n-            if(addr != null) {\n-                InetAddress[] ret = new InetAddress[1];\n-                if (addr.length == Inet4Address.INADDRSZ) {\n-                    if (numericZone != -1 || ifname != null) {\n-                        \/\/ IPv4-mapped address must not contain zone-id\n-                        throw new UnknownHostException(host + \": invalid IPv4-mapped address\");\n-                    }\n-                    ret[0] = new Inet4Address(null, addr);\n-                } else {\n-                    if (ifname != null) {\n-                        ret[0] = new Inet6Address(null, addr, ifname);\n-                    } else {\n-                        ret[0] = new Inet6Address(null, addr, numericZone);\n-                    }\n-                }\n-                return ret;\n+            if (inetAddress != null) {\n+                return new InetAddress[]{inetAddress};\n@@ -1738,33 +1726,0 @@\n-\n-    \/**\n-     * check if the literal address string has %nn appended\n-     * returns -1 if not, or the numeric value otherwise.\n-     *\n-     * %nn may also be a string that represents the displayName of\n-     * a currently available NetworkInterface.\n-     *\/\n-    private static int checkNumericZone (String s) throws UnknownHostException {\n-        int percent = s.indexOf ('%');\n-        int slen = s.length();\n-        int digit, zone=0;\n-        int multmax = Integer.MAX_VALUE \/ 10; \/\/ for int overflow detection\n-        if (percent == -1) {\n-            return -1;\n-        }\n-        for (int i=percent+1; i<slen; i++) {\n-            char c = s.charAt(i);\n-            if ((digit = IPAddressUtil.parseAsciiDigit(c, 10)) < 0) {\n-                return -1;\n-            }\n-            if (zone > multmax) {\n-                return -1;\n-            }\n-            zone = (zone * 10) + digit;\n-            if (zone < 0) {\n-                return -1;\n-            }\n-\n-        }\n-        return zone;\n-    }\n-\n@@ -1779,0 +1734,34 @@\n+    \/**\n+     * Creates an {@code InetAddress} based on the provided {@linkplain InetAddress##format\n+     * textual representation} of an IP address.\n+     * <p> The provided IP address literal is parsed as\n+     * {@linkplain Inet4Address#ofLiteral(String) an IPv4 address literal} first.\n+     * If it cannot be parsed as an IPv4 address literal, then the method attempts\n+     * to parse it as {@linkplain Inet6Address#ofLiteral(String) an IPv6 address literal}.\n+     * If neither attempts succeed an {@code IllegalArgumentException} is thrown.\n+     * <p> This method doesn't block, i.e. no reverse lookup is performed.\n+     *\n+     * @param ipAddressLiteral the textual representation of an IP address.\n+     * @return an {@link InetAddress} object with no hostname set, and constructed\n+     *         from the provided IP address literal.\n+     * @throws IllegalArgumentException if the {@code ipAddressLiteral} cannot be parsed\n+     *         as an IPv4 or IPv6 address literal.\n+     * @throws NullPointerException if the {@code ipAddressLiteral} is {@code null}.\n+     * @see Inet4Address#ofLiteral(String)\n+     * @see Inet6Address#ofLiteral(String)\n+     * @see Inet4Address#ofPosixLiteral(String)\n+     * @since 22\n+     *\/\n+    public static InetAddress ofLiteral(String ipAddressLiteral) {\n+        Objects.requireNonNull(ipAddressLiteral);\n+        InetAddress inetAddress;\n+        try {\n+            \/\/ First try to parse the input as an IPv4 address literal\n+            inetAddress = Inet4Address.ofLiteral(ipAddressLiteral);\n+        } catch (IllegalArgumentException iae) {\n+            \/\/ If it fails try to parse the input as an IPv6 address literal\n+            inetAddress = Inet6Address.ofLiteral(ipAddressLiteral);\n+        }\n+        return inetAddress;\n+    }\n+\n","filename":"src\/java.base\/share\/classes\/java\/net\/InetAddress.java","additions":78,"deletions":89,"binary":false,"changes":167,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1995, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1995, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,0 +29,2 @@\n+import jdk.internal.event.SocketReadEvent;\n+import jdk.internal.event.SocketWriteEvent;\n@@ -175,4 +177,5 @@\n-     * If the application has specified a client socket implementation\n-     * factory, that factory's {@code createSocketImpl} method is called to\n-     * create the actual socket implementation. Otherwise a system-default\n-     * socket implementation is created.\n+     * If the application has specified a {@linkplain SocketImplFactory client\n+     * socket implementation factory}, that factory's\n+     * {@linkplain SocketImplFactory#createSocketImpl() createSocketImpl}\n+     * method is called to create the actual socket implementation. Otherwise\n+     * a system-default socket implementation is created.\n@@ -181,1 +184,0 @@\n-     * @revised 1.4\n@@ -215,0 +217,1 @@\n+    @SuppressWarnings(\"this-escape\")\n@@ -298,4 +301,5 @@\n-     * If the application has specified a client socket implementation\n-     * factory, that factory's {@code createSocketImpl} method is called to\n-     * create the actual socket implementation. Otherwise a system-default\n-     * socket implementation is created.\n+     * If the application has specified a {@linkplain SocketImplFactory client\n+     * socket implementation factory}, that factory's\n+     * {@linkplain SocketImplFactory#createSocketImpl() createSocketImpl}\n+     * method is called to create the actual socket implementation. Otherwise\n+     * a system-default socket implementation is created.\n@@ -320,1 +324,0 @@\n-     * @see        java.net.SocketImpl\n@@ -323,0 +326,1 @@\n+    @SuppressWarnings(\"this-escape\")\n@@ -335,4 +339,5 @@\n-     * If the application has specified a client socket implementation\n-     * factory, that factory's {@code createSocketImpl} method is called to\n-     * create the actual socket implementation. Otherwise a system-default\n-     * socket implementation is created.\n+     * If the application has specified a {@linkplain SocketImplFactory client\n+     * socket implementation factory}, that factory's\n+     * {@linkplain SocketImplFactory#createSocketImpl() createSocketImpl}\n+     * method is called to create the actual socket implementation. Otherwise\n+     * a system-default socket implementation is created.\n@@ -354,1 +359,0 @@\n-     * @see        java.net.SocketImpl\n@@ -357,0 +361,1 @@\n+    @SuppressWarnings(\"this-escape\")\n@@ -398,0 +403,1 @@\n+    @SuppressWarnings(\"this-escape\")\n@@ -440,0 +446,1 @@\n+    @SuppressWarnings(\"this-escape\")\n@@ -460,4 +467,5 @@\n-     * If the application has specified a client socket implementation\n-     * factory, that factory's {@code createSocketImpl} method is called to\n-     * create the actual socket implementation. Otherwise a system-default\n-     * socket implementation is created.\n+     * If the application has specified a {@linkplain SocketImplFactory client\n+     * socket implementation factory}, that factory's\n+     * {@linkplain SocketImplFactory#createSocketImpl() createSocketImpl}\n+     * method is called to create the actual socket implementation. Otherwise\n+     * a system-default socket implementation is created.\n@@ -482,2 +490,1 @@\n-     * @see        java.net.SocketImpl\n-     * @deprecated Use DatagramSocket instead for UDP transport.\n+     * @deprecated Use {@link DatagramSocket} instead for UDP transport.\n@@ -486,1 +493,2 @@\n-    @Deprecated\n+    @Deprecated(forRemoval = true, since = \"1.1\")\n+    @SuppressWarnings(\"this-escape\")\n@@ -501,4 +509,5 @@\n-     * If the application has specified a client socket implementation\n-     * factory, that factory's {@code createSocketImpl} method is called to\n-     * create the actual socket implementation. Otherwise a system-default\n-     * socket implementation is created.\n+     * If the application has specified a {@linkplain SocketImplFactory client\n+     * socket implementation factory}, that factory's\n+     * {@linkplain SocketImplFactory#createSocketImpl() createSocketImpl}\n+     * method is called to create the actual socket implementation. Otherwise\n+     * a system-default socket implementation is created.\n@@ -524,2 +533,1 @@\n-     * @see        java.net.SocketImpl\n-     * @deprecated Use DatagramSocket instead for UDP transport.\n+     * @deprecated Use {@link DatagramSocket} instead for UDP transport.\n@@ -528,1 +536,2 @@\n-    @Deprecated\n+    @Deprecated(forRemoval = true, since = \"1.1\")\n+    @SuppressWarnings(\"this-escape\")\n@@ -1056,2 +1065,0 @@\n-     *\n-     * @revised 1.4\n@@ -1081,3 +1088,0 @@\n-     *\n-     * This class is instrumented by Java Flight Recorder (JFR) to get socket\n-     * I\/O events.\n@@ -1100,0 +1104,13 @@\n+            if (!SocketReadEvent.enabled()) {\n+                return implRead(b, off, len);\n+            }\n+            long start = SocketReadEvent.timestamp();\n+            int nbytes = implRead(b, off, len);\n+            long duration = SocketReadEvent.timestamp() - start;\n+            if (SocketReadEvent.shouldCommit(duration)) {\n+                SocketReadEvent.emit(start, duration, nbytes, parent.getRemoteSocketAddress(), getSoTimeout());\n+            }\n+            return nbytes;\n+        }\n+\n+        private int implRead(byte[] b, int off, int len) throws IOException {\n@@ -1113,0 +1130,10 @@\n+\n+        private int getSoTimeout() {\n+            try {\n+                return parent.getSoTimeout();\n+            } catch (SocketException e) {\n+                \/\/ ignored - avoiding exceptions in jfr event data gathering\n+            }\n+            return 0;\n+        }\n+\n@@ -1154,1 +1181,0 @@\n-     * @revised 1.4\n@@ -1178,3 +1204,0 @@\n-     *\n-     * This class is instrumented by Java Flight Recorder (JFR) to get socket\n-     * I\/O events.\n@@ -1196,0 +1219,13 @@\n+            if (!SocketWriteEvent.enabled()) {\n+                implWrite(b, off, len);\n+                return;\n+            }\n+            long start = SocketWriteEvent.timestamp();\n+            implWrite(b, off, len);\n+            long duration = SocketWriteEvent.timestamp() - start;\n+            if (SocketWriteEvent.shouldCommit(duration)) {\n+                SocketWriteEvent.emit(start, duration, len, parent.getRemoteSocketAddress());\n+            }\n+        }\n+\n+        private void implWrite(byte[] b, int off, int len) throws IOException {\n@@ -1214,1 +1250,1 @@\n-     * Enable\/disable {@link SocketOptions#TCP_NODELAY TCP_NODELAY}\n+     * Enable\/disable {@link StandardSocketOptions#TCP_NODELAY TCP_NODELAY}\n@@ -1217,1 +1253,1 @@\n-     * @param on {@code true} to enable TCP_NODELAY,\n+     * @param on {@code true} to enable {@code TCP_NODELAY},\n@@ -1234,1 +1270,1 @@\n-     * Tests if {@link SocketOptions#TCP_NODELAY TCP_NODELAY} is enabled.\n+     * Tests if {@link StandardSocketOptions#TCP_NODELAY TCP_NODELAY} is enabled.\n@@ -1237,1 +1273,1 @@\n-     *         {@link SocketOptions#TCP_NODELAY TCP_NODELAY} is enabled.\n+     *         {@code TCP_NODELAY} is enabled.\n@@ -1250,1 +1286,1 @@\n-     * Enable\/disable {@link SocketOptions#SO_LINGER SO_LINGER} with the\n+     * Enable\/disable {@link StandardSocketOptions#SO_LINGER SO_LINGER} with the\n@@ -1280,1 +1316,1 @@\n-     * Returns setting for {@link SocketOptions#SO_LINGER SO_LINGER}.\n+     * Returns setting for {@link StandardSocketOptions#SO_LINGER SO_LINGER}.\n@@ -1286,1 +1322,1 @@\n-     * @return the setting for {@link SocketOptions#SO_LINGER SO_LINGER}.\n+     * @return the setting for {@code SO_LINGER}.\n@@ -1334,2 +1370,1 @@\n-     * @param on {@code true} to enable\n-     *           {@link SocketOptions#SO_OOBINLINE SO_OOBINLINE},\n+     * @param on {@code true} to enable {@code SO_OOBINLINE},\n@@ -1355,1 +1390,1 @@\n-     *         {@link SocketOptions#SO_OOBINLINE SO_OOBINLINE} is enabled.\n+     *         {@code SO_OOBINLINE} is enabled.\n@@ -1397,1 +1432,1 @@\n-     * @return the setting for {@link SocketOptions#SO_TIMEOUT SO_TIMEOUT}\n+     * @return the setting for {@code SO_TIMEOUT}\n@@ -1417,1 +1452,1 @@\n-     * Sets the {@link SocketOptions#SO_SNDBUF SO_SNDBUF} option to the\n+     * Sets the {@link StandardSocketOptions#SO_SNDBUF SO_SNDBUF} option to the\n@@ -1419,3 +1454,2 @@\n-     * The {@link SocketOptions#SO_SNDBUF SO_SNDBUF} option is used by the\n-     * platform's networking code as a hint for the size to set the underlying\n-     * network I\/O buffers.\n+     * The {@code SO_SNDBUF} option is used by the platform's networking code\n+     * as a hint for the size to set the underlying network I\/O buffers.\n@@ -1423,3 +1457,2 @@\n-     * <p>Because {@link SocketOptions#SO_SNDBUF SO_SNDBUF} is a hint,\n-     * applications that want to verify what size the buffers were set to\n-     * should call {@link #getSendBufferSize()}.\n+     * <p>Because {@code SO_SNDBUF} is a hint, applications that want to verify\n+     * what size the buffers were set to should call {@link #getSendBufferSize()}.\n@@ -1448,1 +1481,1 @@\n-     * Get value of the {@link SocketOptions#SO_SNDBUF SO_SNDBUF} option\n+     * Get value of the {@link StandardSocketOptions#SO_SNDBUF SO_SNDBUF} option\n@@ -1451,2 +1484,1 @@\n-     * @return the value of the {@link SocketOptions#SO_SNDBUF SO_SNDBUF}\n-     *         option for this {@code Socket}.\n+     * @return the value of the {@code SO_SNDBUF} option for this {@code Socket}.\n@@ -1472,1 +1504,1 @@\n-     * Sets the {@link SocketOptions#SO_RCVBUF SO_RCVBUF} option to the\n+     * Sets the {@link StandardSocketOptions#SO_RCVBUF SO_RCVBUF} option to the\n@@ -1474,3 +1506,2 @@\n-     * {@link SocketOptions#SO_RCVBUF SO_RCVBUF} option is\n-     * used by the platform's networking code as a hint for the size to set\n-     * the underlying network I\/O buffers.\n+     * {@code SO_RCVBUF} option is used by the platform's networking code\n+     * as a hint for the size to set the underlying network I\/O buffers.\n@@ -1482,3 +1513,2 @@\n-     * <p>Because {@link SocketOptions#SO_RCVBUF SO_RCVBUF} is a hint,\n-     * applications that want to verify what size the buffers were set to\n-     * should call {@link #getReceiveBufferSize()}.\n+     * <p>Because {@code SO_RCVBUF} is a hint, applications that want to verify\n+     * what size the buffers were set to should call {@link #getReceiveBufferSize()}.\n@@ -1486,2 +1516,2 @@\n-     * <p>The value of {@link SocketOptions#SO_RCVBUF SO_RCVBUF} is also used\n-     * to set the TCP receive window that is advertised to the remote peer.\n+     * <p>The value of {@code SO_RCVBUF} is also used to set the TCP receive window\n+     * that is advertised to the remote peer.\n@@ -1520,1 +1550,1 @@\n-     * Gets the value of the {@link SocketOptions#SO_RCVBUF SO_RCVBUF} option\n+     * Gets the value of the {@link StandardSocketOptions#SO_RCVBUF SO_RCVBUF} option\n@@ -1524,2 +1554,1 @@\n-     * @return the value of the {@link SocketOptions#SO_RCVBUF SO_RCVBUF}\n-     *         option for this {@code Socket}.\n+     * @return the value of the {@code SO_RCVBUF} option for this {@code Socket}.\n@@ -1543,1 +1572,1 @@\n-     * Enable\/disable {@link SocketOptions#SO_KEEPALIVE SO_KEEPALIVE}.\n+     * Enable\/disable {@link StandardSocketOptions#SO_KEEPALIVE SO_KEEPALIVE}.\n@@ -1558,1 +1587,1 @@\n-     * Tests if {@link SocketOptions#SO_KEEPALIVE SO_KEEPALIVE} is enabled.\n+     * Tests if {@link StandardSocketOptions#SO_KEEPALIVE SO_KEEPALIVE} is enabled.\n@@ -1561,1 +1590,1 @@\n-     *         {@link SocketOptions#SO_KEEPALIVE SO_KEEPALIVE} is enabled.\n+     *         {@code SO_KEEPALIVE} is enabled.\n@@ -1617,1 +1646,1 @@\n-     * @see SocketOptions#IP_TOS\n+     * @see StandardSocketOptions#IP_TOS\n@@ -1641,1 +1670,1 @@\n-     * @see SocketOptions#IP_TOS\n+     * @see StandardSocketOptions#IP_TOS\n@@ -1648,1 +1677,1 @@\n-     * Enable\/disable the {@link SocketOptions#SO_REUSEADDR SO_REUSEADDR}\n+     * Enable\/disable the {@link StandardSocketOptions#SO_REUSEADDR SO_REUSEADDR}\n@@ -1660,4 +1689,3 @@\n-     * Enabling {@link SocketOptions#SO_REUSEADDR SO_REUSEADDR}\n-     * prior to binding the socket using {@link #bind(SocketAddress)} allows\n-     * the socket to be bound even though a previous connection is in a timeout\n-     * state.\n+     * Enabling {@code SO_REUSEADDR} prior to binding the socket using\n+     * {@link #bind(SocketAddress)} allows the socket to be bound even\n+     * though a previous connection is in a timeout state.\n@@ -1666,1 +1694,1 @@\n-     * of {@link SocketOptions#SO_REUSEADDR SO_REUSEADDR} is disabled.\n+     * of {@code SO_REUSEADDR} is disabled.\n@@ -1668,3 +1696,2 @@\n-     * The behaviour when {@link SocketOptions#SO_REUSEADDR SO_REUSEADDR} is\n-     * enabled or disabled after a socket is bound (See {@link #isBound()})\n-     * is not defined.\n+     * The behaviour when {@code SO_REUSEADDR} is enabled or disabled after\n+     * a socket is bound (See {@link #isBound()}) is not defined.\n@@ -1674,1 +1701,1 @@\n-     *            disabling the {@link SocketOptions#SO_REUSEADDR SO_REUSEADDR}\n+     *            disabling the {@code SO_REUSEADDR}\n@@ -1689,1 +1716,1 @@\n-     * Tests if {@link SocketOptions#SO_REUSEADDR SO_REUSEADDR} is enabled.\n+     * Tests if {@link StandardSocketOptions#SO_REUSEADDR SO_REUSEADDR} is enabled.\n@@ -1692,1 +1719,1 @@\n-     *         {@link SocketOptions#SO_REUSEADDR SO_REUSEADDR} is enabled.\n+     *         {@code SO_REUSEADDR} is enabled.\n@@ -1722,1 +1749,0 @@\n-     * @revised 1.4\n","filename":"src\/java.base\/share\/classes\/java\/net\/Socket.java","additions":116,"deletions":90,"binary":false,"changes":206,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1995, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1995, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -108,0 +108,5 @@\n+     * @apiNote\n+     * The {@link Socket} constructors to create a datagram socket\n+     * are deprecated for removal. This method will be re-specified\n+     * in a future release to not support creating datagram sockets.\n+     *\n","filename":"src\/java.base\/share\/classes\/java\/net\/SocketImpl.java","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1996, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1996, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,0 @@\n-import jdk.internal.util.random.RandomSupport.RandomGeneratorProperties;\n@@ -152,4 +151,0 @@\n-@RandomGeneratorProperties(\n-        name = \"SecureRandom\",\n-        isStochastic = true\n-)\n","filename":"src\/java.base\/share\/classes\/java\/security\/SecureRandom.java","additions":1,"deletions":6,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -66,1 +66,1 @@\n- * <p>Java 5.0 introduced the {@code java.util.concurrent} package and\n+ * @apiNote Java 5.0 introduced the {@code java.util.concurrent} package and\n@@ -77,2 +77,1 @@\n- *\n- * <p>Implementation note: This class scales to large numbers of concurrently\n+ * @implNote This class scales to large numbers of concurrently\n@@ -82,2 +81,1 @@\n- *\n- * <p>Implementation note: All constructors start a timer thread.\n+ * <p> All constructors start a timer thread.\n@@ -183,0 +181,1 @@\n+    @SuppressWarnings(\"this-escape\")\n@@ -437,2 +436,6 @@\n-     * Terminates this timer, discarding any currently scheduled tasks.\n-     * Does not interfere with a currently executing task (if it exists).\n+     * Terminates this timer, <i>discarding<\/i> any currently scheduled tasks.\n+     * It should be noted that this method does not <i>cancel<\/i> the scheduled\n+     * tasks. For a task to be considered cancelled, the task itself should\n+     * invoke {@link TimerTask#cancel()}.\n+     *\n+     * <p>This method does not interfere with a currently executing task (if it exists).\n@@ -449,0 +452,1 @@\n+     * @see TimerTask#cancel()\n@@ -458,3 +462,3 @@\n-     * Removes all cancelled tasks from this timer's task queue.  <i>Calling\n-     * this method has no effect on the behavior of the timer<\/i>, but\n-     * eliminates the references to the cancelled tasks from the queue.\n+     * Removes all <i>cancelled<\/i> tasks from this timer's task queue.\n+     * <i>Calling this method has no effect on the behavior of the timer<\/i>,\n+     * but eliminates the references to the cancelled tasks from the queue.\n@@ -467,3 +471,3 @@\n-     * runtime of the method may be proportional to n + c log n, where n\n-     * is the number of tasks in the queue and c is the number of cancelled\n-     * tasks.\n+     * runtime of the method may be proportional to {@code n + c log n}, where\n+     * {@code n} is the number of tasks in the queue and {@code c} is the number\n+     * of cancelled tasks.\n@@ -475,0 +479,2 @@\n+     * @see #cancel()\n+     * @see TimerTask#cancel()\n","filename":"src\/java.base\/share\/classes\/java\/util\/Timer.java","additions":20,"deletions":14,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1995, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1995, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -74,1 +74,1 @@\n-import sun.security.action.GetBooleanAction;\n+import sun.security.action.GetPropertyAction;\n@@ -81,1 +81,1 @@\n- * This class is used to read entries from a zip file.\n+ * This class is used to read entries from a ZIP file.\n@@ -100,1 +100,2 @@\n-    private final String name;     \/\/ zip file name\n+    private final String filePath;     \/\/ ZIP file path\n+    private final String fileName;     \/\/ name of the file\n@@ -103,1 +104,1 @@\n-    \/\/ The \"resource\" used by this zip file that needs to be\n+    \/\/ The \"resource\" used by this ZIP file that needs to be\n@@ -107,1 +108,1 @@\n-    \/\/ c) the \"native\" source of this zip file.\n+    \/\/ c) the \"native\" source of this ZIP file.\n@@ -114,1 +115,1 @@\n-     * Mode flag to open a zip file for reading.\n+     * Mode flag to open a ZIP file for reading.\n@@ -119,1 +120,1 @@\n-     * Mode flag to open a zip file and mark it for deletion.  The file will be\n+     * Mode flag to open a ZIP file and mark it for deletion.  The file will be\n@@ -128,2 +129,2 @@\n-     * Flag which specifies whether the validation of the Zip64 extra\n-     * fields should be disabled\n+     * Flag to specify whether the Extra ZIP64 validation should be\n+     * disabled.\n@@ -131,2 +132,3 @@\n-    private static final boolean disableZip64ExtraFieldValidation =\n-            GetBooleanAction.privilegedGetProperty(\"jdk.util.zip.disableZip64ExtraFieldValidation\");\n+    private static final boolean DISABLE_ZIP64_EXTRA_VALIDATION =\n+            getDisableZip64ExtraFieldValidation();\n+\n@@ -134,1 +136,1 @@\n-     * Opens a zip file for reading.\n+     * Opens a ZIP file for reading.\n@@ -143,1 +145,1 @@\n-     * @param name the name of the zip file\n+     * @param name the name of the ZIP file\n@@ -230,0 +232,1 @@\n+    @SuppressWarnings(\"this-escape\")\n@@ -249,1 +252,2 @@\n-        this.name = name;\n+        this.filePath = name;\n+        this.fileName = file.getName();\n@@ -259,1 +263,1 @@\n-     * Opens a zip file for reading.\n+     * Opens a ZIP file for reading.\n@@ -265,1 +269,1 @@\n-     * @param name the name of the zip file\n+     * @param name the name of the ZIP file\n@@ -309,1 +313,3 @@\n-     * Returns the zip file comment, or null if none.\n+     * Returns the ZIP file comment. If a comment does not exist or an error is\n+     * encountered decoding the comment using the charset specified\n+     * when opening the ZIP file, then {@code null} is returned.\n@@ -311,1 +317,1 @@\n-     * @return the comment string for the zip file, or null if none\n+     * @return the comment string for the ZIP file, or null if none\n@@ -313,1 +319,1 @@\n-     * @throws IllegalStateException if the zip file has been closed\n+     * @throws IllegalStateException if the ZIP file has been closed\n@@ -323,1 +329,7 @@\n-            return res.zsrc.zc.toString(res.zsrc.comment);\n+            \/\/ If there is a problem decoding the byte array which represents\n+            \/\/ the ZIP file comment, return null;\n+            try {\n+                return res.zsrc.zc.toString(res.zsrc.comment);\n+            } catch (IllegalArgumentException iae) {\n+                return null;\n+            }\n@@ -328,1 +340,1 @@\n-     * Returns the zip file entry for the specified name, or null\n+     * Returns the ZIP file entry for the specified name, or null\n@@ -332,2 +344,2 @@\n-     * @return the zip file entry, or null if not found\n-     * @throws IllegalStateException if the zip file has been closed\n+     * @return the ZIP file entry, or null if not found\n+     * @throws IllegalStateException if the ZIP file has been closed\n@@ -350,1 +362,1 @@\n-     * zip file entry.\n+     * ZIP file entry.\n@@ -361,1 +373,1 @@\n-     * @param entry the zip file entry\n+     * @param entry the ZIP file entry\n@@ -363,2 +375,2 @@\n-     * zip file entry or null if the zip file entry does not exist\n-     * within the zip file.\n+     * ZIP file entry or null if the ZIP file entry does not exist\n+     * within the ZIP file.\n@@ -367,1 +379,1 @@\n-     * @throws IllegalStateException if the zip file has been closed\n+     * @throws IllegalStateException if the ZIP file has been closed\n@@ -487,1 +499,10 @@\n-        return name;\n+        return filePath;\n+    }\n+\n+    \/**\n+     * {@return a string identifying this {@code ZipFile}, for debugging}\n+     *\/\n+    @Override\n+    public String toString() {\n+        return this.fileName\n+                + \"@\" + Integer.toHexString(System.identityHashCode(this));\n@@ -537,1 +558,1 @@\n-     * @throws IllegalStateException if the zip file has been closed\n+     * @throws IllegalStateException if the ZIP file has been closed\n@@ -589,1 +610,1 @@\n-     * @throws IllegalStateException if the zip file has been closed\n+     * @throws IllegalStateException if the ZIP file has been closed\n@@ -608,1 +629,1 @@\n-     * Returns an ordered {@code Stream} over the zip file entry names.\n+     * Returns an ordered {@code Stream} over the ZIP file entry names.\n@@ -613,2 +634,2 @@\n-     * @return an ordered {@code Stream} of entry names in this zip file\n-     * @throws IllegalStateException if the zip file has been closed\n+     * @return an ordered {@code Stream} of entry names in this ZIP file\n+     * @throws IllegalStateException if the ZIP file has been closed\n@@ -626,1 +647,1 @@\n-     * Returns an ordered {@code Stream} over the zip file entries.\n+     * Returns an ordered {@code Stream} over the ZIP file entries.\n@@ -631,2 +652,2 @@\n-     * @return an ordered {@code Stream} of entries in this zip file\n-     * @throws IllegalStateException if the zip file has been closed\n+     * @return an ordered {@code Stream} of entries in this ZIP file\n+     * @throws IllegalStateException if the ZIP file has been closed\n@@ -701,1 +722,1 @@\n-     * @throws IllegalStateException if the zip file has been closed\n+     * @throws IllegalStateException if the ZIP file has been closed\n@@ -801,1 +822,1 @@\n-            \/\/ Release zip src\n+            \/\/ Release ZIP src\n@@ -844,1 +865,1 @@\n-            \/\/ and release zip source\n+            \/\/ and release ZIP source\n@@ -870,1 +891,1 @@\n-     * (possibly compressed) zip file entry.\n+     * (possibly compressed) ZIP file entry.\n@@ -883,1 +904,1 @@\n-            \/\/ zip64\n+            \/\/ ZIP64\n@@ -930,1 +951,1 @@\n-         * The Zip file spec explicitly allows the LOC extra data size to\n+         * The ZIP file spec explicitly allows the LOC extra data size to\n@@ -1105,0 +1126,16 @@\n+    \/**\n+     * Returns the value of the System property which indicates whether the\n+     * Extra ZIP64 validation should be disabled.\n+     *\/\n+    static boolean getDisableZip64ExtraFieldValidation() {\n+        boolean result;\n+        String value = GetPropertyAction.privilegedGetProperty(\n+                \"jdk.util.zip.disableZip64ExtraFieldValidation\");\n+        if (value == null) {\n+            result = false;\n+        } else {\n+            result = value.isEmpty() || value.equalsIgnoreCase(\"true\");\n+        }\n+        return result;\n+    }\n+\n@@ -1169,1 +1206,1 @@\n-        private final @Stable ZipCoder zc;   \/\/ zip coder used to decode\/encode\n+        private final @Stable ZipCoder zc;   \/\/ ZIP coder used to decode\/encode\n@@ -1173,1 +1210,1 @@\n-        private RandomAccessFile zfile;      \/\/ zfile of the underlying zip file\n+        private RandomAccessFile zfile;      \/\/ zfile of the underlying ZIP file\n@@ -1176,1 +1213,1 @@\n-        private byte[] comment;              \/\/ zip file comment\n+        private byte[] comment;              \/\/ ZIP file comment\n@@ -1182,1 +1219,1 @@\n-        private final boolean startsWithLoc; \/\/ true, if zip file starts with LOCSIG (usually true)\n+        private final boolean startsWithLoc; \/\/ true, if ZIP file starts with LOCSIG (usually true)\n@@ -1223,1 +1260,8 @@\n-            if (entryPos + nlen > cen.length - ENDHDR) {\n+            int elen = CENEXT(cen, pos);\n+            int clen = CENCOM(cen, pos);\n+            long headerSize = (long)CENHDR + nlen + clen + elen;\n+            \/\/ CEN header size + name length + comment length + extra length\n+            \/\/ should not exceed 65,535 bytes per the PKWare APP.NOTE\n+            \/\/ 4.4.10, 4.4.11, & 4.4.12.  Also check that current CEN header will\n+            \/\/ not exceed the length of the CEN array\n+            if (headerSize > 0xFFFF || pos + headerSize > cen.length - ENDHDR) {\n@@ -1227,7 +1271,7 @@\n-            int elen = CENEXT(cen, pos);\n-            if (elen > 0 && !disableZip64ExtraFieldValidation) {\n-                long extraStartingOffset = pos + CENHDR + nlen;\n-                if ((int)extraStartingOffset != extraStartingOffset) {\n-                    zerror(\"invalid CEN header (bad extra offset)\");\n-                }\n-                checkExtraFields(pos, (int)extraStartingOffset, elen);\n+            if (elen > 0 && !DISABLE_ZIP64_EXTRA_VALIDATION) {\n+                checkExtraFields(pos, entryPos + nlen, elen);\n+            } else if (elen == 0 && (CENSIZ(cen, pos) == ZIP64_MAGICVAL\n+                    || CENLEN(cen, pos) == ZIP64_MAGICVAL\n+                    || CENOFF(cen, pos) == ZIP64_MAGICVAL\n+                    || CENDSK(cen, pos) == ZIP64_MAGICCOUNT)) {\n+                zerror(\"Invalid CEN header (invalid zip64 extra len size)\");\n@@ -1246,2 +1290,2 @@\n-                \/\/ Validate comment if it exists\n-                \/\/ if the bytes representing the comment cannot be converted to\n+                \/\/ Validate comment if it exists.\n+                \/\/ If the bytes representing the comment cannot be converted to\n@@ -1249,1 +1293,0 @@\n-                int clen = CENCOM(cen, pos);\n@@ -1262,0 +1305,1 @@\n+         * @param cenPos The CEN offset for the current Entry\n@@ -1276,1 +1320,1 @@\n-            if (extraEndOffset > cen.length) {\n+            if (extraEndOffset > cen.length - ENDHDR) {\n@@ -1280,1 +1324,4 @@\n-            while (currentOffset < extraEndOffset) {\n+            \/\/ Walk through each Extra Header. Each Extra Header Must consist of:\n+            \/\/       Header ID - 2 bytes\n+            \/\/       Data Size - 2 bytes:\n+            while (currentOffset + Integer.BYTES <= extraEndOffset) {\n@@ -1285,1 +1332,2 @@\n-                int tagBlockEndingOffset = currentOffset + tagBlockSize;\n+                currentOffset += Short.BYTES;\n+                long tagBlockEndingOffset = (long)currentOffset + tagBlockSize;\n@@ -1290,1 +1338,4 @@\n-                    zerror(\"Invalid CEN header (invalid zip64 extra data field size)\");\n+                    zerror(String.format(\n+                            \"Invalid CEN header (invalid extra data field size for \" +\n+                                    \"tag: 0x%04x at %d)\",\n+                            tag, cenPos));\n@@ -1292,1 +1343,0 @@\n-                currentOffset += Short.BYTES;\n@@ -1299,0 +1349,5 @@\n+                    \/\/ Get the LOC offset\n+                    long locoff = CENOFF(cen, cenPos);\n+                    \/\/ Get the Disk Number\n+                    int diskNo = CENDSK(cen, cenPos);\n+\n@@ -1300,1 +1355,1 @@\n-                            csize, size);\n+                            csize, size, locoff, diskNo);\n@@ -1308,4 +1363,5 @@\n-         * size and that the uncompressed size and compressed size field\n-         * values are not negative.\n-         * Note:  As we do not use the LOC offset or Starting disk number\n-         * field value we will not validate them\n+         * size; that the uncompressed size, compressed size field and LOC\n+         * offset fields are not negative. Also make sure the field exists if\n+         * the CEN header field is set to 0xFFFFFFFF.\n+         * Note:  As we do not use the Starting disk number field,\n+         * we will not validate its value\n@@ -1316,0 +1372,2 @@\n+         * @param locoff CEN header LOC offset\n+         * @param diskNo CEN header Disk number\n@@ -1319,1 +1377,1 @@\n-                                                long size)\n+                                                long size, long locoff, int diskNo)\n@@ -1322,0 +1380,11 @@\n+            \/\/ if ZIP64_EXTID blocksize == 0, which may occur with some older\n+            \/\/ versions of Apache Ant and Commons Compress, validate csize and size\n+            \/\/ to make sure neither field == ZIP64_MAGICVAL\n+            if (blockSize == 0) {\n+                if (csize == ZIP64_MAGICVAL || size == ZIP64_MAGICVAL ||\n+                        locoff == ZIP64_MAGICVAL || diskNo == ZIP64_MAGICCOUNT) {\n+                    zerror(\"Invalid CEN header (invalid zip64 extra data field size)\");\n+                }\n+                \/\/ Only validate the ZIP64_EXTID data if the block size > 0\n+                return;\n+            }\n@@ -1324,1 +1393,1 @@\n-            if (!isZip64ExtBlockSizeValid(blockSize)) {\n+            if (!isZip64ExtBlockSizeValid(blockSize, csize, size, locoff, diskNo)) {\n@@ -1328,6 +1397,9 @@\n-            \/\/ Note we do not need to check blockSize is >= 8 as\n-            \/\/ we know its length is at least 8 from the call to\n-            \/\/ isZip64ExtBlockSizeValid()\n-            if ((size == ZIP64_MAGICVAL)) {\n-                if(get64(cen, off) < 0) {\n-                    zerror(\"Invalid zip64 extra block size value\");\n+            if (size == ZIP64_MAGICVAL) {\n+                if ( blockSize >= Long.BYTES) {\n+                    if (get64(cen, off) < 0) {\n+                        zerror(\"Invalid zip64 extra block size value\");\n+                    }\n+                    off += Long.BYTES;\n+                    blockSize -= Long.BYTES;\n+                } else {\n+                    zerror(\"Invalid Zip64 extra block, missing size\");\n@@ -1337,3 +1409,23 @@\n-            if ((csize == ZIP64_MAGICVAL) && (blockSize >= 16)) {\n-                if (get64(cen, off + 8) < 0) {\n-                    zerror(\"Invalid zip64 extra block compressed size value\");\n+            if (csize == ZIP64_MAGICVAL) {\n+                if (blockSize >= Long.BYTES) {\n+                    if (get64(cen, off) < 0) {\n+                        zerror(\"Invalid zip64 extra block compressed size value\");\n+                    }\n+                    off += Long.BYTES;\n+                    blockSize -= Long.BYTES;\n+                } else {\n+                    zerror(\"Invalid Zip64 extra block, missing compressed size\");\n+                }\n+            }\n+            \/\/ Check the LOC offset is not negative\n+            if (locoff == ZIP64_MAGICVAL) {\n+                if (blockSize >= Long.BYTES) {\n+                    if (get64(cen, off) < 0) {\n+                        zerror(\"Invalid zip64 extra block LOC OFFSET value\");\n+                    }\n+                    \/\/ Note: We do not need to adjust the following fields as\n+                    \/\/ this is the last field we are leveraging\n+                    \/\/ off += Long.BYTES;\n+                    \/\/ blockSize -= Long.BYTES;\n+                } else {\n+                    zerror(\"Invalid Zip64 extra block, missing LOC offset value\");\n@@ -1356,0 +1448,4 @@\n+         * @param csize CEN header compressed size value\n+         * @param size CEN header uncompressed size value\n+         * @param locoff CEN header LOC offset\n+         * @param diskNo CEN header Disk number\n@@ -1358,14 +1454,10 @@\n-        private static boolean isZip64ExtBlockSizeValid(int blockSize) {\n-            \/*\n-             * As the fields must appear in order, the block size indicates which\n-             * fields to expect:\n-             *  8 - uncompressed size\n-             * 16 - uncompressed size, compressed size\n-             * 24 - uncompressed size, compressed sise, LOC Header offset\n-             * 28 - uncompressed size, compressed sise, LOC Header offset,\n-             * and Disk start number\n-             *\/\n-            return switch(blockSize) {\n-                case 8, 16, 24, 28 -> true;\n-                default -> false;\n-            };\n+        private static boolean isZip64ExtBlockSizeValid(int blockSize, long csize,\n+                                                        long size, long locoff,\n+                                                        int diskNo) {\n+            int expectedBlockSize =\n+                    (csize == ZIP64_MAGICVAL ? Long.BYTES : 0) +\n+                    (size == ZIP64_MAGICVAL ? Long.BYTES : 0) +\n+                    (locoff == ZIP64_MAGICVAL ? Long.BYTES : 0) +\n+                    (diskNo == ZIP64_MAGICCOUNT ? Integer.BYTES : 0);\n+            return expectedBlockSize == blockSize;\n+\n@@ -1381,0 +1473,7 @@\n+        \/**\n+         * A class representing a key to a ZIP file. A key is based\n+         * on the file key if available, or the path value if the\n+         * file key is not available. The key is also based on the\n+         * file's last modified time to allow for cases where a ZIP\n+         * file is re-opened after it has been modified.\n+         *\/\n@@ -1395,1 +1494,3 @@\n-                return ((int)(t ^ (t >>> 32))) + file.hashCode();\n+                Object fk = attrs.fileKey();\n+                return Long.hashCode(t) +\n+                        (fk != null ? fk.hashCode() : file.hashCode());\n@@ -1598,1 +1699,1 @@\n-                        \/\/ must check for a zip64 end record; it is always permitted to be present\n+                        \/\/ must check for a ZIP64 end record; it is always permitted to be present\n@@ -1627,1 +1728,1 @@\n-                        } catch (IOException x) {}    \/\/ no zip64 loc\/end\n+                        } catch (IOException x) {}    \/\/ no ZIP64 loc\/end\n@@ -1635,1 +1736,1 @@\n-        \/\/ Reads zip file central directory.\n+        \/\/ Reads ZIP file central directory.\n@@ -1652,1 +1753,1 @@\n-                \/\/ account that there may be a stub prefixed to the zip file.\n+                \/\/ account that there may be a stub prefixed to the ZIP file.\n@@ -1695,1 +1796,1 @@\n-                    \/\/ This will only happen if the zip file has an incorrect\n+                    \/\/ This will only happen if the ZIP file has an incorrect\n@@ -1768,1 +1869,1 @@\n-         * Returns the {@code pos} of the zip cen entry corresponding to the\n+         * Returns the {@code pos} of the ZIP cen entry corresponding to the\n@@ -1956,1 +2057,1 @@\n-         * Will not throw, even if the zip file is corrupt.\n+         * Will not throw, even if the ZIP file is corrupt.\n@@ -1958,1 +2059,1 @@\n-         * @param cen copy of the bytes in a zip file's central directory\n+         * @param cen copy of the bytes in a ZIP file's central directory\n","filename":"src\/java.base\/share\/classes\/java\/util\/zip\/ZipFile.java","additions":204,"deletions":103,"binary":false,"changes":307,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+    @SuppressWarnings(\"this-escape\")\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/crac\/JDKFdResource.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -437,3 +437,1 @@\n-            \/\/ Skip this URL if it already has a Loader. (Loader\n-            \/\/ may be null in the case where URL has not been opened\n-            \/\/ but is referenced by a JAR index.)\n+            \/\/ Skip this URL if it already has a Loader.\n@@ -493,1 +491,1 @@\n-                                    return new JarLoader(nestedUrl, jarHandler, lmap, acc);\n+                                    return new JarLoader(nestedUrl, jarHandler, acc);\n@@ -498,1 +496,1 @@\n-                                return new JarLoader(url, jarHandler, lmap, acc);\n+                                return new JarLoader(url, jarHandler, acc);\n@@ -712,2 +710,0 @@\n-        private URLStreamHandler handler;\n-        private final HashMap<String, Loader> lmap;\n@@ -725,1 +721,0 @@\n-                          HashMap<String, Loader> loaderMap,\n@@ -731,2 +726,0 @@\n-            handler = jarHandler;\n-            lmap = loaderMap;\n@@ -756,4 +749,0 @@\n-        JarFile getJarFile () {\n-            return jar;\n-        }\n-\n@@ -875,27 +864,0 @@\n-\n-        \/*\n-         * Returns true iff at least one resource in the jar file has the same\n-         * package name as that of the specified resource name.\n-         *\/\n-        boolean validIndex(final String name) {\n-            String packageName = name;\n-            int pos;\n-            if ((pos = name.lastIndexOf('\/')) != -1) {\n-                packageName = name.substring(0, pos);\n-            }\n-\n-            String entryName;\n-            ZipEntry entry;\n-            Enumeration<JarEntry> enum_ = jar.entries();\n-            while (enum_.hasMoreElements()) {\n-                entry = enum_.nextElement();\n-                entryName = entry.getName();\n-                if ((pos = entryName.lastIndexOf('\/')) != -1)\n-                    entryName = entryName.substring(0, pos);\n-                if (entryName.equals(packageName)) {\n-                    return true;\n-                }\n-            }\n-            return false;\n-        }\n-\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/loader\/URLClassPath.java","additions":3,"deletions":41,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -82,0 +82,5 @@\n+    exports java.lang.classfile;\n+    exports java.lang.classfile.attribute;\n+    exports java.lang.classfile.components;\n+    exports java.lang.classfile.constantpool;\n+    exports java.lang.classfile.instruction;\n@@ -153,0 +158,1 @@\n+        java.desktop, \/\/ for ScopedValue\n@@ -155,1 +161,5 @@\n-        jdk.jshell;\n+        jdk.jartool, \/\/ participates in preview features\n+        jdk.jdeps, \/\/ participates in preview features\n+        jdk.jfr, \/\/ participates in preview features\n+        jdk.jlink,   \/\/ participates in preview features\n+        jdk.jshell; \/\/ participates in preview features\n@@ -160,0 +170,1 @@\n+        java.management.rmi,\n@@ -191,13 +202,0 @@\n-    exports jdk.internal.classfile to\n-        jdk.jartool,\n-        jdk.jlink,\n-        jdk.jshell;\n-    exports jdk.internal.classfile.attribute to\n-        jdk.jartool,\n-        jdk.jlink;\n-    exports jdk.internal.classfile.constantpool to\n-        jdk.jartool,\n-        jdk.jlink;\n-    exports jdk.internal.classfile.instruction to\n-        jdk.jlink,\n-        jdk.jshell;\n@@ -238,0 +236,1 @@\n+        jdk.compiler,\n@@ -277,2 +276,0 @@\n-    exports jdk.internal.util.random to\n-        jdk.random;\n@@ -405,1 +402,0 @@\n-    uses java.util.random.RandomGenerator;\n@@ -431,5 +427,0 @@\n-    provides java.util.random.RandomGenerator with\n-        java.security.SecureRandom,\n-        java.util.Random,\n-        java.util.SplittableRandom;\n-\n","filename":"src\/java.base\/share\/classes\/module-info.java","additions":14,"deletions":23,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2008, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2008, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -64,1 +64,1 @@\n-    private ReadWriteLock closeLock = new ReentrantReadWriteLock();\n+    private final ReadWriteLock closeLock = new ReentrantReadWriteLock();\n","filename":"src\/java.base\/share\/classes\/sun\/nio\/ch\/AsynchronousServerSocketChannelImpl.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -578,0 +578,1 @@\n+            ensureOpen();\n@@ -810,0 +811,3 @@\n+    \/**\n+     * Receives a datagram into a direct buffer.\n+     *\/\n@@ -816,0 +820,1 @@\n+            long bufAddress = NIO_ACCESS.getBufferAddress(bb);\n@@ -817,1 +822,2 @@\n-                             ((DirectBuffer)bb).address() + pos, rem,\n+                             bufAddress + pos,\n+                             rem,\n@@ -856,0 +862,1 @@\n+            ensureOpen();\n@@ -994,0 +1001,3 @@\n+    \/**\n+     * Send a datagram contained in a direct buffer.\n+     *\/\n@@ -1006,0 +1016,1 @@\n+            long bufAddress = NIO_ACCESS.getBufferAddress(bb);\n@@ -1007,2 +1018,5 @@\n-            written = send0(fd, ((DirectBuffer)bb).address() + pos, rem,\n-                            targetSockAddr.address(), addressLen);\n+            written = send0(fd,\n+                            bufAddress + pos,\n+                            rem,\n+                            targetSockAddr.address(),\n+                            addressLen);\n@@ -1044,0 +1058,1 @@\n+            ensureOpen();\n@@ -1074,0 +1089,1 @@\n+            ensureOpen();\n@@ -1157,0 +1173,1 @@\n+            ensureOpen();\n@@ -1187,0 +1204,1 @@\n+            ensureOpen();\n@@ -1932,0 +1950,5 @@\n+        \/\/ wait for any read\/write operations to complete before trying to close\n+        readLock.lock();\n+        readLock.unlock();\n+        writeLock.lock();\n+        writeLock.unlock();\n","filename":"src\/java.base\/share\/classes\/sun\/nio\/ch\/DatagramChannelImpl.java","additions":27,"deletions":4,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -57,2 +57,1 @@\n-import jdk.internal.foreign.AbstractMemorySegmentImpl;\n-import jdk.internal.foreign.MappedMemorySegmentImpl;\n+import jdk.internal.event.FileForceEvent;\n@@ -60,0 +59,1 @@\n+import jdk.internal.foreign.SegmentFactories;\n@@ -67,1 +67,2 @@\n-\n+import jdk.internal.event.FileReadEvent;\n+import jdk.internal.event.FileWriteEvent;\n@@ -80,0 +81,4 @@\n+    \/\/ Flag set by jdk.internal.event.JFRTracing to indicate if\n+    \/\/ file reads and writes should be traced by JFR.\n+    private static boolean jfrTracing;\n+\n@@ -120,0 +125,1 @@\n+    private final boolean sync;  \/\/ O_SYNC or O_DSYNC\n@@ -164,1 +170,2 @@\n-                            boolean writable, boolean direct, Closeable parent)\n+                            boolean writable, boolean sync, boolean direct,\n+                            Closeable parent)\n@@ -170,0 +177,1 @@\n+        this.sync = sync;\n@@ -192,1 +200,1 @@\n-                                   boolean direct, Closeable parent)\n+                                   boolean sync, boolean direct, Closeable parent)\n@@ -194,1 +202,1 @@\n-        return new FileChannelImpl(fd, path, readable, writable, direct, parent);\n+        return new FileChannelImpl(fd, path, readable, writable, sync, direct, parent);\n@@ -258,0 +266,7 @@\n+        if (jfrTracing && FileReadEvent.enabled()) {\n+            return traceImplRead(dst);\n+        }\n+        return implRead(dst);\n+    }\n+\n+    private int implRead(ByteBuffer dst) throws IOException {\n@@ -272,1 +287,1 @@\n-                    long comp = Blocker.begin();\n+                    boolean attempted = Blocker.begin(direct);\n@@ -276,1 +291,1 @@\n-                        Blocker.end(comp);\n+                        Blocker.end(attempted);\n@@ -288,0 +303,19 @@\n+    private int traceImplRead(ByteBuffer dst) throws IOException {\n+        int bytesRead = 0;\n+        long start = 0;\n+        try {\n+            start = FileReadEvent.timestamp();\n+            bytesRead = implRead(dst);\n+        } finally {\n+            long duration = FileReadEvent.timestamp() - start;\n+            if (FileReadEvent.shouldCommit(duration)) {\n+                if (bytesRead < 0) {\n+                    FileReadEvent.commit(start, duration, path, 0L, true);\n+                } else {\n+                    FileReadEvent.commit(start, duration, path, bytesRead, false);\n+                }\n+            }\n+        }\n+        return bytesRead;\n+    }\n+\n@@ -289,1 +323,8 @@\n-    public long read(ByteBuffer[] dsts, int offset, int length)\n+    public long read(ByteBuffer[] dsts, int offset, int length) throws IOException {\n+        if (jfrTracing && FileReadEvent.enabled()) {\n+            return traceImplRead(dsts, offset, length);\n+        }\n+        return implRead(dsts, offset, length);\n+    }\n+\n+    private long implRead(ByteBuffer[] dsts, int offset, int length)\n@@ -307,1 +348,1 @@\n-                    long comp = Blocker.begin();\n+                    boolean attempted = Blocker.begin(direct);\n@@ -311,1 +352,1 @@\n-                        Blocker.end(comp);\n+                        Blocker.end(attempted);\n@@ -324,0 +365,19 @@\n+    private long traceImplRead(ByteBuffer[] dsts, int offset, int length) throws IOException {\n+        long bytesRead = 0;\n+        long start = 0;\n+        try {\n+            start = FileReadEvent.timestamp();\n+            bytesRead = implRead(dsts, offset, length);\n+        } finally {\n+            long duration = FileReadEvent.timestamp() - start;\n+            if (FileReadEvent.shouldCommit(duration)) {\n+                if (bytesRead < 0) {\n+                    FileReadEvent.commit(start, duration, path, 0L, true);\n+                } else {\n+                    FileReadEvent.commit(start, duration, path, bytesRead, false);\n+                }\n+            }\n+        }\n+        return bytesRead;\n+    }\n+\n@@ -326,0 +386,7 @@\n+        if (jfrTracing && FileWriteEvent.enabled()) {\n+            return traceImplWrite(src);\n+        }\n+        return implWrite(src);\n+    }\n+\n+    private int implWrite(ByteBuffer src) throws IOException {\n@@ -340,1 +407,1 @@\n-                    long comp = Blocker.begin();\n+                    boolean attempted = Blocker.begin(sync || direct);\n@@ -344,1 +411,1 @@\n-                        Blocker.end(comp);\n+                        Blocker.end(attempted);\n@@ -357,0 +424,16 @@\n+    private int traceImplWrite(ByteBuffer src) throws IOException {\n+        int bytesWritten = 0;\n+        long start = 0;\n+        try {\n+            start = FileWriteEvent.timestamp();\n+            bytesWritten = implWrite(src);\n+        } finally {\n+            long duration = FileWriteEvent.timestamp() - start;\n+            if (FileWriteEvent.shouldCommit(duration)) {\n+                long bytes = bytesWritten > 0 ? bytesWritten : 0;\n+                FileWriteEvent.commit(start, duration, path, bytes);\n+            }\n+        }\n+        return bytesWritten;\n+    }\n+\n@@ -358,3 +441,8 @@\n-    public long write(ByteBuffer[] srcs, int offset, int length)\n-        throws IOException\n-    {\n+    public long write(ByteBuffer[] srcs, int offset, int length) throws IOException {\n+        if (jfrTracing && FileWriteEvent.enabled()) {\n+            return traceImplWrite(srcs, offset, length);\n+        }\n+        return implWrite(srcs, offset, length);\n+    }\n+\n+    private long implWrite(ByteBuffer[] srcs, int offset, int length) throws IOException {\n@@ -376,1 +464,1 @@\n-                    long comp = Blocker.begin();\n+                    boolean attempted = Blocker.begin(sync || direct);\n@@ -380,1 +468,1 @@\n-                        Blocker.end(comp);\n+                        Blocker.end(attempted);\n@@ -392,0 +480,15 @@\n+    private long traceImplWrite(ByteBuffer[] srcs, int offset, int length) throws IOException {\n+        long bytesWritten = 0;\n+        long start = 0;\n+        try {\n+            start = FileWriteEvent.timestamp();\n+            bytesWritten = implWrite(srcs, offset, length);\n+        } finally {\n+            long duration = FileWriteEvent.timestamp() - start;\n+            if (FileWriteEvent.shouldCommit(duration)) {\n+                long bytes = bytesWritten > 0 ? bytesWritten : 0;\n+                FileWriteEvent.commit(start, duration, path, bytes);\n+            }\n+        }\n+        return bytesWritten;\n+    }\n@@ -407,7 +510,2 @@\n-                    long comp = Blocker.begin();\n-                    try {\n-                        \/\/ in append-mode then position is advanced to end before writing\n-                        p = (append) ? nd.size(fd) : nd.seek(fd, -1);\n-                    } finally {\n-                        Blocker.end(comp);\n-                    }\n+                    \/\/ in append-mode then position is advanced to end before writing\n+                    p = (append) ? nd.size(fd) : nd.seek(fd, -1);\n@@ -438,6 +536,1 @@\n-                    long comp = Blocker.begin();\n-                    try {\n-                        p = nd.seek(fd, newPosition);\n-                    } finally {\n-                        Blocker.end(comp);\n-                    }\n+                    p = nd.seek(fd, newPosition);\n@@ -466,6 +559,1 @@\n-                    long comp = Blocker.begin();\n-                    try {\n-                        s = nd.size(fd);\n-                    } finally {\n-                        Blocker.end(comp);\n-                    }\n+                    s = nd.size(fd);\n@@ -503,6 +591,1 @@\n-                    long comp = Blocker.begin();\n-                    try {\n-                        size = nd.size(fd);\n-                    } finally {\n-                        Blocker.end(comp);\n-                    }\n+                    size = nd.size(fd);\n@@ -515,6 +598,1 @@\n-                    long comp = Blocker.begin();\n-                    try {\n-                        p = nd.seek(fd, -1);\n-                    } finally {\n-                        Blocker.end(comp);\n-                    }\n+                    p = nd.seek(fd, -1);\n@@ -529,6 +607,1 @@\n-                        long comp = Blocker.begin();\n-                        try {\n-                            rv = nd.truncate(fd, newSize);\n-                        } finally {\n-                            Blocker.end(comp);\n-                        }\n+                        rv = nd.truncate(fd, newSize);\n@@ -544,6 +617,1 @@\n-                    long comp = Blocker.begin();\n-                    try {\n-                        rp = nd.seek(fd, p);\n-                    } finally {\n-                        Blocker.end(comp);\n-                    }\n+                    rp = nd.seek(fd, p);\n@@ -560,2 +628,1 @@\n-    @Override\n-    public void force(boolean metaData) throws IOException {\n+    private void implForce(boolean metaData) throws IOException {\n@@ -571,1 +638,1 @@\n-                long comp = Blocker.begin();\n+                boolean attempted = Blocker.begin();\n@@ -575,1 +642,1 @@\n-                    Blocker.end(comp);\n+                    Blocker.end(attempted);\n@@ -585,0 +652,11 @@\n+    @Override\n+    public void force(boolean metaData) throws IOException {\n+        if (!FileForceEvent.enabled()) {\n+            implForce(metaData);\n+            return;\n+        }\n+        long start = FileForceEvent.timestamp();\n+        implForce(metaData);\n+        FileForceEvent.offer(start, path, metaData);\n+    }\n+\n@@ -666,6 +744,1 @@\n-            long comp = Blocker.begin();\n-            try {\n-                n = nd.transferTo(fd, position, count, targetFD, append);\n-            } finally {\n-                Blocker.end(comp);\n-            }\n+            n = nd.transferTo(fd, position, count, targetFD, append);\n@@ -899,9 +972,0 @@\n-            \/\/ Now position <= sz so remaining >= 0 and\n-            \/\/ remaining == 0 if and only if sz == 0\n-            long remaining = sz - position;\n-\n-            \/\/ Adjust count only if remaining > 0, i.e.,\n-            \/\/ sz > position which means sz > 0\n-            if (remaining > 0 && remaining < count)\n-                count = remaining;\n-\n@@ -911,2 +975,9 @@\n-                \/\/ Attempt a direct transfer, if the kernel supports it, limiting\n-                \/\/ the number of bytes according to which platform\n+                \/\/ Now sz > 0 and position <= sz so remaining >= 0 and\n+                \/\/ remaining == 0 if and only if sz == position\n+                long remaining = sz - position;\n+\n+                if (remaining >= 0 && remaining < count)\n+                    count = remaining;\n+\n+                \/\/ Attempt a direct transfer, if the kernel supports it,\n+                \/\/ limiting the number of bytes according to which platform\n@@ -939,6 +1010,1 @@\n-            long comp = Blocker.begin();\n-            try {\n-                n = nd.transferFrom(srcFD, fd, position, count, append);\n-            } finally {\n-                Blocker.end(comp);\n-            }\n+            n = nd.transferFrom(srcFD, fd, position, count, append);\n@@ -1103,0 +1169,7 @@\n+        if (jfrTracing && FileReadEvent.enabled()) {\n+            return traceImplRead(dst, position);\n+        }\n+        return implRead(dst, position);\n+    }\n+\n+    private int implRead(ByteBuffer dst, long position) throws IOException {\n@@ -1121,0 +1194,19 @@\n+    private int traceImplRead(ByteBuffer dst, long position) throws IOException {\n+        int bytesRead = 0;\n+        long start = 0;\n+        try {\n+            start = FileReadEvent.timestamp();\n+            bytesRead = implRead(dst, position);\n+        } finally {\n+            long duration = FileReadEvent.timestamp() - start;\n+            if (FileReadEvent.shouldCommit(duration)) {\n+                if (bytesRead < 0) {\n+                    FileReadEvent.commit(start, duration, path, 0L, true);\n+                } else {\n+                    FileReadEvent.commit(start, duration, path, bytesRead, false);\n+                }\n+            }\n+        }\n+        return bytesRead;\n+    }\n+\n@@ -1132,1 +1224,1 @@\n-                long comp = Blocker.begin();\n+                boolean attempted = Blocker.begin(direct);\n@@ -1136,1 +1228,1 @@\n-                    Blocker.end(comp);\n+                    Blocker.end(attempted);\n@@ -1149,0 +1241,7 @@\n+        if (jfrTracing && FileReadEvent.enabled()) {\n+            return traceImplWrite(src, position);\n+        }\n+        return implWrite(src, position);\n+    }\n+\n+    private int implWrite(ByteBuffer src, long position) throws IOException {\n@@ -1167,0 +1266,16 @@\n+    private int traceImplWrite(ByteBuffer src, long position) throws IOException {\n+        int bytesWritten = 0;\n+        long start = 0;\n+        try {\n+            start = FileWriteEvent.timestamp();\n+            bytesWritten = implWrite(src, position);\n+        } finally {\n+            long duration = FileWriteEvent.timestamp() - start;\n+            if (FileWriteEvent.shouldCommit(duration)) {\n+                long bytes = bytesWritten > 0 ? bytesWritten : 0;\n+                FileWriteEvent.commit(start, duration, path, bytes);\n+            }\n+        }\n+        return bytesWritten;\n+    }\n+\n@@ -1177,1 +1292,1 @@\n-                long comp = Blocker.begin();\n+                boolean attempted = Blocker.begin(sync || direct);\n@@ -1181,1 +1296,1 @@\n-                    Blocker.end(comp);\n+                    Blocker.end(attempted);\n@@ -1195,1 +1310,1 @@\n-    private abstract static class Unmapper\n+    private abstract static sealed class Unmapper\n@@ -1198,1 +1313,1 @@\n-        private volatile long address;\n+        private final long address;\n@@ -1235,3 +1350,0 @@\n-            if (address == 0)\n-                return;\n-            address = 0;\n@@ -1255,1 +1367,1 @@\n-    private static class DefaultUnmapper extends Unmapper {\n+    private static final class DefaultUnmapper extends Unmapper {\n@@ -1288,1 +1400,1 @@\n-    private static class SyncUnmapper extends Unmapper {\n+    private static final class SyncUnmapper extends Unmapper {\n@@ -1379,16 +1491,1 @@\n-        if (unmapper != null) {\n-            AbstractMemorySegmentImpl segment =\n-                new MappedMemorySegmentImpl(unmapper.address(), unmapper, size,\n-                                            readOnly, sessionImpl);\n-            MemorySessionImpl.ResourceList.ResourceCleanup resource =\n-                new MemorySessionImpl.ResourceList.ResourceCleanup() {\n-                    @Override\n-                    public void cleanup() {\n-                        unmapper.unmap();\n-                    }\n-                };\n-            sessionImpl.addOrCleanupIfFail(resource);\n-            return segment;\n-        } else {\n-            return new MappedMemorySegmentImpl(0, null, 0, readOnly, sessionImpl);\n-        }\n+        return SegmentFactories.mapSegment(size, unmapper, readOnly, sessionImpl);\n@@ -1424,6 +1521,1 @@\n-                    long comp = Blocker.begin();\n-                    try {\n-                        filesize = nd.size(fd);\n-                    } finally {\n-                        Blocker.end(comp);\n-                    }\n+                    filesize = nd.size(fd);\n@@ -1441,6 +1533,1 @@\n-                        long comp = Blocker.begin();\n-                        try {\n-                            rv = nd.truncate(fd, position + size);\n-                        } finally {\n-                            Blocker.end(comp);\n-                        }\n+                        rv = nd.truncate(fd, position + size);\n@@ -1637,1 +1724,1 @@\n-                long comp = Blocker.begin();\n+                boolean attempted = Blocker.begin();\n@@ -1641,1 +1728,1 @@\n-                    Blocker.end(comp);\n+                    Blocker.end(attempted);\n","filename":"src\/java.base\/share\/classes\/sun\/nio\/ch\/FileChannelImpl.java","additions":217,"deletions":130,"binary":false,"changes":347,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -397,0 +397,1 @@\n+            ensureOpen();\n@@ -657,0 +658,3 @@\n+        \/\/ wait for any accept operation to complete before trying to close\n+        acceptLock.lock();\n+        acceptLock.unlock();\n","filename":"src\/java.base\/share\/classes\/sun\/nio\/ch\/ServerSocketChannelImpl.java","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -63,0 +63,2 @@\n+import jdk.internal.event.SocketReadEvent;\n+import jdk.internal.event.SocketWriteEvent;\n@@ -406,2 +408,1 @@\n-    @Override\n-    public int read(ByteBuffer buf) throws IOException {\n+    private int implRead(ByteBuffer buf) throws IOException {\n@@ -448,2 +449,1 @@\n-    @Override\n-    public long read(ByteBuffer[] dsts, int offset, int length)\n+    private long implRead(ByteBuffer[] dsts, int offset, int length)\n@@ -492,0 +492,25 @@\n+    @Override\n+    public int read(ByteBuffer buf) throws IOException {\n+        if (!SocketReadEvent.enabled()) {\n+            return implRead(buf);\n+        }\n+        long start = SocketReadEvent.timestamp();\n+        int nbytes = implRead(buf);\n+        SocketReadEvent.offer(start, nbytes, remoteAddress(), 0);\n+        return nbytes;\n+    }\n+\n+\n+    @Override\n+    public long read(ByteBuffer[] dsts, int offset, int length)\n+        throws IOException\n+    {\n+        if (!SocketReadEvent.enabled()) {\n+            return implRead(dsts, offset, length);\n+        }\n+        long start = SocketReadEvent.timestamp();\n+        long nbytes = implRead(dsts, offset, length);\n+        SocketReadEvent.offer(start, nbytes, remoteAddress(), 0);\n+        return nbytes;\n+    }\n+\n@@ -533,2 +558,1 @@\n-    @Override\n-    public int write(ByteBuffer buf) throws IOException {\n+    private int implWrite(ByteBuffer buf) throws IOException {\n@@ -562,2 +586,1 @@\n-    @Override\n-    public long write(ByteBuffer[] srcs, int offset, int length)\n+    private long implWrite(ByteBuffer[] srcs, int offset, int length)\n@@ -594,0 +617,24 @@\n+    @Override\n+    public int write(ByteBuffer buf) throws IOException {\n+        if (!SocketWriteEvent.enabled()) {\n+            return implWrite(buf);\n+        }\n+        long start = SocketWriteEvent.timestamp();\n+        int nbytes = implWrite(buf);\n+        SocketWriteEvent.offer(start, nbytes, remoteAddress());\n+        return nbytes;\n+    }\n+\n+    @Override\n+    public long write(ByteBuffer[] srcs, int offset, int length)\n+        throws IOException\n+    {\n+        if (!SocketWriteEvent.enabled()) {\n+            return implWrite(srcs, offset, length);\n+        }\n+        long start = SocketWriteEvent.timestamp();\n+        long nbytes = implWrite(srcs, offset, length);\n+        SocketWriteEvent.offer(start, nbytes, remoteAddress());\n+        return nbytes;\n+    }\n+\n@@ -913,0 +960,1 @@\n+                    ensureOpen();\n@@ -1011,0 +1059,1 @@\n+                    ensureOpen();\n@@ -1172,0 +1221,5 @@\n+        \/\/ wait for any read\/write operations to complete before trying to close\n+        readLock.lock();\n+        readLock.unlock();\n+        writeLock.lock();\n+        writeLock.unlock();\n","filename":"src\/java.base\/share\/classes\/sun\/nio\/ch\/SocketChannelImpl.java","additions":63,"deletions":9,"binary":false,"changes":72,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -33,0 +33,1 @@\n+import java.io.InvalidObjectException;\n@@ -266,1 +267,1 @@\n-     *\n+     * <p>\n@@ -365,2 +366,4 @@\n-     * readObject is called to restore the state of the random object from\n-     * a stream.  We have to create a new instance of MessageDigest, because\n+     * This method is called to restore the state of the random object from\n+     * a stream.\n+     * <p>\n+     * We have to create a new instance of {@code MessageDigest}, because\n@@ -368,3 +371,3 @@\n-     *\n-     * Note that the engineNextBytes() method invoked on the restored random\n-     * object will yield the exact same (random) bytes as the original.\n+     * <p>\n+     * Note that the {@code engineNextBytes()} method invoked on the restored\n+     * random object will yield the exact same (random) bytes as the original.\n@@ -372,1 +375,5 @@\n-     * random object, using engineSetSeed().\n+     * random object, using {@code engineSetSeed()}.\n+     *\n+     * @param  s the {@code ObjectInputStream} from which data is read\n+     * @throws IOException if an I\/O error occurs\n+     * @throws ClassNotFoundException if a serialized class cannot be loaded\n@@ -376,1 +383,1 @@\n-        throws IOException, ClassNotFoundException {\n+            throws IOException, ClassNotFoundException {\n@@ -395,0 +402,29 @@\n+\n+        \/\/ Various consistency checks\n+        if ((remainder == null) && (remCount > 0)) {\n+            throw new InvalidObjectException(\n+                    \"Remainder indicated, but no data available\");\n+        }\n+\n+        \/\/ Not yet allocated state\n+        if (state == null) {\n+            if (remainder == null) {\n+                return;\n+            } else {\n+                throw new InvalidObjectException(\n+                        \"Inconsistent buffer allocations\");\n+            }\n+        }\n+\n+        \/\/ Sanity check on sizes\/pointer\n+        if ((state.length != DIGEST_SIZE) ||\n+                ((remainder != null) && (remainder.length != DIGEST_SIZE)) ||\n+                (remCount < 0 ) || (remCount >= DIGEST_SIZE)) {\n+            throw new InvalidObjectException(\n+                    \"Inconsistent buffer sizes\/state\");\n+        }\n+\n+        state = state.clone();\n+        if (remainder != null) {\n+            remainder = remainder.clone();\n+        }\n","filename":"src\/java.base\/share\/classes\/sun\/security\/provider\/SecureRandom.java","additions":45,"deletions":9,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -1,1 +1,1 @@\n-.\\\" Copyright (c) 1994, 2023, Oracle and\/or its affiliates. All rights reserved.\n+.\\\" Copyright (c) 1994, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -39,1 +39,1 @@\n-.TH \"JAVA\" \"1\" \"2024\" \"JDK 22-ea\" \"JDK Commands\"\n+.TH \"JAVA\" \"1\" \"2024\" \"JDK 23\" \"JDK Commands\"\n@@ -66,1 +66,1 @@\n-To launch a single source-file program:\n+To launch a source-file program:\n@@ -103,1 +103,1 @@\n-Only used to launch a single source-file program.\n+Only used to launch a source-file program.\n@@ -106,2 +106,1 @@\n-See \\f[B]Using Source-File Mode to Launch Single-File Source-Code\n-Programs\\f[R]\n+See \\f[B]Using Source-File Mode to Launch Source-Code Programs\\f[R]\n@@ -131,2 +130,2 @@\n-See \\f[B]Using Source-File Mode to Launch Single-File Source-Code\n-Programs\\f[R] for a description of using the source-file mode.\n+See \\f[B]Using Source-File Mode to Launch Source-Code Programs\\f[R] for\n+a description of using the source-file mode.\n@@ -160,1 +159,1 @@\n-.SH USING SOURCE-FILE MODE TO LAUNCH SINGLE-FILE SOURCE-CODE PROGRAMS\n+.SH USING SOURCE-FILE MODE TO LAUNCH SOURCE-CODE PROGRAMS\n@@ -190,1 +189,1 @@\n-(\\f[V]22\\f[R]) and a limited number of previous releases, detailed in\n+(\\f[V]23\\f[R]) and a limited number of previous releases, detailed in\n@@ -208,1 +207,1 @@\n-contained a class named \\f[V]hello.World\\f[R], then the source-file mode\n+contained a class named \\f[V]HelloWorld\\f[R], then the source-file mode\n@@ -215,4 +214,1 @@\n-The example illustrates that the class can be in a named package, and\n-does not need to be in the unnamed package.\n-following two commands where \\f[V]hello.World\\f[R] is the name of the\n-class in the package:\n+following two commands:\n@@ -223,2 +219,2 @@\n-javac -d <memory> HelloWorld.java\n-java -cp <memory> hello.World\n+javac -d <memory> --source-path <source-root> HelloWorld.java\n+java --class-path <memory> HelloWorld\n@@ -228,0 +224,2 @@\n+where \\f[V]<source-root>\\f[R] is computed\n+.PP\n@@ -256,3 +254,18 @@\n-.IP \\[bu] 2\n-No other source files are found and compiled, as if the source path is\n-set to an empty value.\n+These include:\n+\\f[V]--class-path\\f[R]\/\\f[V]-classpath\\f[R]\/\\f[V]-cp\\f[R],\n+\\f[V]--module-path\\f[R]\/\\f[V]-p\\f[R], \\f[V]--add-exports\\f[R],\n+\\f[V]--add-modules\\f[R], \\f[V]--limit-modules\\f[R],\n+\\f[V]--patch-module\\f[R], \\f[V]--upgrade-module-path\\f[R],\n+\\f[V]--enable-preview\\f[R].\n+.IP \\[bu] 2\n+The root of the source tree, \\f[V]<source-root>\\f[R] is computed from\n+the package of the class being launched.\n+For example, if \\f[V]HelloWorld.java\\f[R] declared its classes to be in\n+the \\f[V]hello\\f[R] package, then the file \\f[V]HelloWorld.java\\f[R] is\n+expected to reside in the directory \\f[V]somedir\/hello\/\\f[R].\n+In this case, \\f[V]somedir\\f[R] is computed to be the root of the source\n+tree.\n+.IP \\[bu] 2\n+The root of the source tree serves as the source-path for compilation,\n+so that other source files found in that tree and are needed by\n+\\f[V]HelloWorld\\f[R] could be compiled.\n@@ -269,1 +282,11 @@\n-The source file is compiled in the context of an unnamed module.\n+If \\f[V]--enable-preview\\f[R] is specified, the \\f[V]--source N\\f[R]\n+arguments can be omitted.\n+If the Java runtime version is \\f[V]N\\f[R], then \\f[V]--release N\\f[R]\n+is implied when compiling source files.\n+.IP \\[bu] 2\n+If a \\f[V]module-info.java\\f[R] file exists in the\n+\\f[V]<source-root>\\f[R] directory, its module declaration is used to\n+define a named module that will contain all the classes compiled from\n+\\f[V].java\\f[R] files in the source tree.\n+If \\f[V]module-info.java\\f[R] does not exist, all the classes compiled\n+from source files will be compiled in the context of the unnamed module.\n@@ -271,2 +294,2 @@\n-The source file should contain one or more top-level classes, the first\n-of which is taken as the class to be executed.\n+The source file that is launched should contain one or more top-level\n+classes, the first of which is taken as the class to be executed.\n@@ -274,4 +297,4 @@\n-The compiler does not enforce the optional restriction defined at the\n-end of JLS 7.6, that a type in a named package should exist in a file\n-whose name is composed from the type name followed by the\n-\\f[V].java\\f[R] extension.\n+For the source file that is launched, the compiler does not enforce the\n+optional restriction defined at the end of JLS 7.6, that a type in a\n+named package should exist in a file whose name is composed from the\n+type name followed by the \\f[V].java\\f[R] extension.\n@@ -279,3 +302,3 @@\n-If the source file contains errors, appropriate error messages are\n-written to the standard error stream, and the launcher exits with a\n-non-zero exit code.\n+If a source file contains errors, appropriate error messages are written\n+to the standard error stream, and the launcher exits with a non-zero\n+exit code.\n@@ -287,2 +310,1 @@\n-It must contain a declaration of the standard\n-\\f[V]public static void main(String[])\\f[R] method.\n+It must contain a declaration of an entry \\f[V]main\\f[R] method.\n@@ -293,4 +315,9 @@\n-refer to any classes declared in the source file.\n-.IP \\[bu] 2\n-The compiled classes are executed in the context of an unnamed module,\n-as though \\f[V]--add-modules=ALL-DEFAULT\\f[R] is in effect.\n+refer to any classes declared in source files.\n+.IP \\[bu] 2\n+If a \\f[V]module-info.java\\f[R] file exists in the\n+\\f[V]<source-root>\\f[R] directory, then all the classes compiled from\n+\\f[V].java\\f[R] files in the source tree will be in that module, which\n+will serve as the root module for the execution of the program.\n+If \\f[V]module-info.java\\f[R] does not exist, the compiled classes are\n+executed in the context of an unnamed module, as though\n+\\f[V]--add-modules=ALL-DEFAULT\\f[R] is in effect.\n@@ -301,1 +328,1 @@\n-are passed to the standard main method in the obvious way.\n+are passed to the main method in the obvious way.\n@@ -306,2 +333,2 @@\n-See \\f[B]JEP 330: Launch Single-File Source-Code Programs\\f[R]\n-[https:\/\/openjdk.org\/jeps\/330] for complete details.\n+See \\f[B]JEP 458: Launch Multi-File Source-Code Programs\\f[R]\n+[https:\/\/openjdk.org\/jeps\/458] for complete details.\n@@ -524,0 +551,14 @@\n+\\f[V]--enable-native-access\\f[R] \\f[I]module\\f[R][\\f[V],\\f[R]\\f[I]module\\f[R]...]\n+Native access involves access to code or data outside the Java runtime.\n+This is generally unsafe and, if done incorrectly, might crash the JVM\n+or result in memory corruption.\n+Methods that provide native access are restricted, and by default their\n+use causes warnings.\n+This option allows code in the specified modules to use restricted\n+methods without warnings.\n+\\f[I]module\\f[R] can be \\f[V]ALL-UNNAMED\\f[R] to indicate code on the\n+class path.\n+When this option is present, any use of restricted methods by code\n+outside the specified modules causes an\n+\\f[V]IllegalCallerException\\f[R].\n+.TP\n@@ -533,4 +574,5 @@\n-Specifies where to find application modules with a list of path elements.\n-The elements of a module path can be a file path to a module or a directory\n-containing modules. Each module is either a modular JAR or an\n-exploded-module directory.\n+Specifies where to find application modules with a list of path\n+elements.\n+The elements of a module path can be a file path to a module or a\n+directory containing modules.\n+Each module is either a modular JAR or an exploded-module directory.\n@@ -539,2 +581,2 @@\n-On Windows, semicolons (\\f[V];\\f[R]) separate path elements in this list;\n-on other platforms it is a colon (\\f[V]:\\f[R]).\n+On Windows, semicolons (\\f[V];\\f[R]) separate path elements in this\n+list; on other platforms it is a colon (\\f[V]:\\f[R]).\n@@ -544,5 +586,5 @@\n-Specifies where to find module replacements of upgradeable modules in the\n-runtime image with a list of path elements.\n-The elements of a module path can be a file path to a module or a directory\n-containing modules. Each module is either a modular JAR or an\n-exploded-module directory.\n+Specifies where to find module replacements of upgradeable modules in\n+the runtime image with a list of path elements.\n+The elements of a module path can be a file path to a module or a\n+directory containing modules.\n+Each module is either a modular JAR or an exploded-module directory.\n@@ -551,2 +593,2 @@\n-On Windows, semicolons (\\f[V];\\f[R]) separate path elements in this list;\n-on other platforms it is a colon (\\f[V]:\\f[R]).\n+On Windows, semicolons (\\f[V];\\f[R]) separate path elements in this\n+list; on other platforms it is a colon (\\f[V]:\\f[R]).\n@@ -557,1 +599,1 @@\n-\\f[I]module\\f[R] also can be \\f[V]ALL-DEFAULT\\f[R],\n+\\f[I]module\\f[R] can also be \\f[V]ALL-DEFAULT\\f[R],\n@@ -1064,2 +1106,1 @@\n-Shows all categories of settings.\n-This is the default value.\n+Shows all categories of settings in \\f[B]verbose\\f[R] detail.\n@@ -1073,0 +1114,15 @@\n+\\f[V]security\\f[R]\n+Shows all settings related to security.\n+.RS\n+.PP\n+sub-category arguments for \\f[V]security\\f[R] include the following:\n+.IP \\[bu] 2\n+\\f[V]security:all\\f[R] : shows all security settings\n+.IP \\[bu] 2\n+\\f[V]security:properties\\f[R] : shows security properties\n+.IP \\[bu] 2\n+\\f[V]security:providers\\f[R] : shows static security provider settings\n+.IP \\[bu] 2\n+\\f[V]security:tls\\f[R] : shows TLS related security settings\n+.RE\n+.TP\n@@ -1119,1 +1175,2 @@\n-\\f[I]target-module\\f[R] can be all unnamed to read all unnamed modules.\n+\\f[I]target-module\\f[R] can be \\f[V]ALL-UNNAMED\\f[R] to read all unnamed\n+modules.\n@@ -1124,2 +1181,2 @@\n-The \\f[I]target-module\\f[R] can be all unnamed to export to all unnamed\n-modules.\n+\\f[I]target-module\\f[R] can be \\f[V]ALL-UNNAMED\\f[R] to export to all\n+unnamed modules.\n@@ -1140,0 +1197,24 @@\n+.TP\n+\\f[V]--sun-misc-unsafe-memory-access=\\f[R] \\f[I]value\\f[R]\n+Allow or deny usage of unsupported API \\f[V]sun.misc.Unsafe\\f[R].\n+\\f[I]value\\f[R] is one of:\n+.RS\n+.TP\n+\\f[V]allow\\f[R]\n+Allow use of the memory-access methods with no warnings at run time.\n+.TP\n+\\f[V]warn\\f[R]\n+Allow use of the memory-access methods, but issues a warning on the\n+first occasion that any memory-access method is used.\n+At most one warning is issued.\n+.TP\n+\\f[V]debug\\f[R]\n+Allow use of the memory-access methods, but issue a one-line warning and\n+a stack trace when any memory-access method is used.\n+.TP\n+\\f[V]deny\\f[R]\n+Disallow use of the memory-access methods by throwing an\n+\\f[V]UnsupportedOperationException\\f[R] on every usage.\n+.PP\n+The default value when the option is not specified is \\f[V]allow\\f[R].\n+.RE\n@@ -1328,0 +1409,1 @@\n+Multiple parameters can be specified by separating them with a comma.\n@@ -1393,3 +1475,0 @@\n-.PP\n-You can specify values for multiple parameters by separating them with a\n-comma.\n@@ -1470,0 +1549,11 @@\n+\\f[V]-XX:TrimNativeHeapInterval=\\f[R]\\f[I]millis\\f[R]\n+Interval, in ms, at which the JVM will trim the native heap.\n+Lower values will reclaim memory more eagerly at the cost of higher\n+overhead.\n+A value of 0 (default) disables native heap trimming.\n+Native heap trimming is performed in a dedicated thread.\n+.RS\n+.PP\n+This option is only supported on Linux with GNU C Library (glibc).\n+.RE\n+.TP\n@@ -1589,0 +1679,9 @@\n+\\f[V]-XX:+VerifySharedSpaces\\f[R]\n+If this option is specified, the JVM will load a CDS archive file only\n+if it passes an integrity check based on CRC32 checksums.\n+The purpose of this flag is to check for unintentional damage to CDS\n+archive files in transmission or storage.\n+To guarantee the security and proper operation of CDS, the user must\n+ensure that the CDS archive files used by Java applications cannot be\n+modified without proper authorization.\n+.TP\n@@ -1635,1 +1734,1 @@\n-\\f[V]-XX:StartFlightRecording=\\f[R]\\f[I]parameter\\f[R]\\f[V]=\\f[R]\\f[I]value\\f[R]\n+\\f[V]-XX:StartFlightRecording:\\f[R]\\f[I]parameter\\f[R]\\f[V]=\\f[R]\\f[I]value\\f[R]\n@@ -1639,0 +1738,2 @@\n+\\f[V]-XX:StartFlightRecording:help\\f[R] prints available options and\n+example command lines.\n@@ -1682,0 +1783,5 @@\n+.PP\n+If %p and\/or %t is specified in the filename, it expands to the\n+JVM\\[aq]s PID and the current timestamp, respectively.\n+The filename may also be a directory in which case, the filename is\n+generated from the PID and the current date in the specified directory.\n@@ -1762,0 +1868,3 @@\n+.PP\n+To only see warnings and errors from JFR during startup set\n+-Xlog:jfr+startup=warning.\n@@ -1836,13 +1945,0 @@\n-\\f[V]-XX:+UseHugeTLBFS\\f[R]\n-\\f[B]Linux only:\\f[R] This option is the equivalent of specifying\n-\\f[V]-XX:+UseLargePages\\f[R].\n-This option is disabled by default.\n-This option pre-allocates all large pages up-front, when memory is\n-reserved; consequently the JVM can\\[aq]t dynamically grow or shrink\n-large pages memory areas; see \\f[V]-XX:UseTransparentHugePages\\f[R] if\n-you want this behavior.\n-.RS\n-.PP\n-See \\f[B]Large Pages\\f[R].\n-.RE\n-.TP\n@@ -2196,16 +2292,0 @@\n-Specify each method with the full class name (including the packages and\n-subpackages).\n-For example, to compile only the \\f[V]length()\\f[R] method of the\n-\\f[V]String\\f[R] class and the \\f[V]size()\\f[R] method of the\n-\\f[V]List\\f[R] class, use the following:\n-.RS\n-.RS\n-.PP\n-\\f[V]-XX:CompileOnly=java\/lang\/String.length,java\/util\/List.size\\f[R]\n-.RE\n-.PP\n-Note that the full class name is specified, including all packages and\n-subpackages separated by a slash (\\f[V]\/\\f[R]).\n-For easier cut and paste operations, it\\[aq]s also possible to use the\n-method name format produced by the \\f[V]-XX:+PrintCompilation\\f[R] and\n-\\f[V]-XX:+LogCompilation\\f[R] options:\n@@ -2214,7 +2294,1 @@\n-\\f[V]-XX:CompileOnly=java.lang.String::length,java.util.List::size\\f[R]\n-.RE\n-.PP\n-Although wildcards aren\\[aq]t supported, you can specify only the class\n-or package name to compile all methods in that class or package, as well\n-as specify just the method to compile methods with this name in any\n-class:\n+\\f[V]-XX:CompileOnly=method1,method2,...,methodN\\f[R] is an alias for:\n@@ -2224,3 +2298,4 @@\n--XX:CompileOnly=java\/lang\/String\n--XX:CompileOnly=java\/lang\n--XX:CompileOnly=.length\n+-XX:CompileCommand=compileonly,method1\n+-XX:CompileCommand=compileonly,method2\n+\\&...\n+-XX:CompileCommand=compileonly,methodN\n@@ -2480,18 +2555,0 @@\n-\\f[V]-XX:RTMAbortRatio=\\f[R]\\f[I]abort_ratio\\f[R]\n-Specifies the RTM abort ratio is specified as a percentage (%) of all\n-executed RTM transactions.\n-If a number of aborted transactions becomes greater than this ratio,\n-then the compiled code is deoptimized.\n-This ratio is used when the \\f[V]-XX:+UseRTMDeopt\\f[R] option is\n-enabled.\n-The default value of this option is 50.\n-This means that the compiled code is deoptimized if 50% of all\n-transactions are aborted.\n-.TP\n-\\f[V]-XX:RTMRetryCount=\\f[R]\\f[I]number_of_retries\\f[R]\n-Specifies the number of times that the RTM locking code is retried, when\n-it is aborted or busy, before falling back to the normal locking\n-mechanism.\n-The default value for this option is 5.\n-The \\f[V]-XX:UseRTMLocking\\f[R] option must be enabled.\n-.TP\n@@ -2737,59 +2794,0 @@\n-\\f[V]-XX:+UseRTMDeopt\\f[R]\n-Autotunes RTM locking depending on the abort ratio.\n-This ratio is specified by the \\f[V]-XX:RTMAbortRatio\\f[R] option.\n-If the number of aborted transactions exceeds the abort ratio, then the\n-method containing the lock is deoptimized and recompiled with all locks\n-as normal locks.\n-This option is disabled by default.\n-The \\f[V]-XX:+UseRTMLocking\\f[R] option must be enabled.\n-.TP\n-\\f[V]-XX:+UseRTMLocking\\f[R]\n-Generates Restricted Transactional Memory (RTM) locking code for all\n-inflated locks, with the normal locking mechanism as the fallback\n-handler.\n-This option is disabled by default.\n-Options related to RTM are available only on x86 CPUs that support\n-Transactional Synchronization Extensions (TSX).\n-.RS\n-.PP\n-RTM is part of Intel\\[aq]s TSX, which is an x86 instruction set\n-extension and facilitates the creation of multithreaded applications.\n-RTM introduces the new instructions \\f[V]XBEGIN\\f[R], \\f[V]XABORT\\f[R],\n-\\f[V]XEND\\f[R], and \\f[V]XTEST\\f[R].\n-The \\f[V]XBEGIN\\f[R] and \\f[V]XEND\\f[R] instructions enclose a set of\n-instructions to run as a transaction.\n-If no conflict is found when running the transaction, then the memory\n-and register modifications are committed together at the \\f[V]XEND\\f[R]\n-instruction.\n-The \\f[V]XABORT\\f[R] instruction can be used to explicitly abort a\n-transaction and the \\f[V]XTEST\\f[R] instruction checks if a set of\n-instructions is being run in a transaction.\n-.PP\n-A lock on a transaction is inflated when another thread tries to access\n-the same transaction, thereby blocking the thread that didn\\[aq]t\n-originally request access to the transaction.\n-RTM requires that a fallback set of operations be specified in case a\n-transaction aborts or fails.\n-An RTM lock is a lock that has been delegated to the TSX\\[aq]s system.\n-.PP\n-RTM improves performance for highly contended locks with low conflict in\n-a critical region (which is code that must not be accessed by more than\n-one thread concurrently).\n-RTM also improves the performance of coarse-grain locking, which\n-typically doesn\\[aq]t perform well in multithreaded applications.\n-(Coarse-grain locking is the strategy of holding locks for long periods\n-to minimize the overhead of taking and releasing locks, while\n-fine-grained locking is the strategy of trying to achieve maximum\n-parallelism by locking only when necessary and unlocking as soon as\n-possible.)\n-Also, for lightly contended locks that are used by different threads,\n-RTM can reduce false cache line sharing, also known as cache line\n-ping-pong.\n-This occurs when multiple threads from different processors are\n-accessing different resources, but the resources share the same cache\n-line.\n-As a result, the processors repeatedly invalidate the cache lines of\n-other processors, which forces them to read from main memory instead of\n-their cache.\n-.RE\n-.TP\n@@ -3532,10 +3530,0 @@\n-\\f[V]-XX:+ScavengeBeforeFullGC\\f[R]\n-Enables GC of the young generation before each full GC.\n-This option is enabled by default.\n-It is recommended that you \\f[I]don\\[aq]t\\f[R] disable it, because\n-scavenging the young generation before a full GC can reduce the number\n-of objects reachable from the old generation space into the young\n-generation space.\n-To disable GC of the young generation before each full GC, specify the\n-option \\f[V]-XX:-ScavengeBeforeFullGC\\f[R].\n-.TP\n@@ -3694,8 +3682,0 @@\n-\\f[V]-XX:+UseSHM\\f[R]\n-\\f[B]Linux only:\\f[R] Enables the JVM to use shared memory to set up\n-large pages.\n-.RS\n-.PP\n-See \\f[B]Large Pages\\f[R] for setting up large pages.\n-.RE\n-.TP\n@@ -3804,0 +3784,99 @@\n+\\f[V]-XX:RTMAbortRatio=\\f[R]\\f[I]abort_ratio\\f[R]\n+Specifies the RTM abort ratio is specified as a percentage (%) of all\n+executed RTM transactions.\n+If a number of aborted transactions becomes greater than this ratio,\n+then the compiled code is deoptimized.\n+This ratio is used when the \\f[V]-XX:+UseRTMDeopt\\f[R] option is\n+enabled.\n+The default value of this option is 50.\n+This means that the compiled code is deoptimized if 50% of all\n+transactions are aborted.\n+.TP\n+\\f[V]-XX:RTMRetryCount=\\f[R]\\f[I]number_of_retries\\f[R]\n+Specifies the number of times that the RTM locking code is retried, when\n+it is aborted or busy, before falling back to the normal locking\n+mechanism.\n+The default value for this option is 5.\n+The \\f[V]-XX:UseRTMLocking\\f[R] option must be enabled.\n+.TP\n+\\f[V]-XX:+UseRTMDeopt\\f[R]\n+Autotunes RTM locking depending on the abort ratio.\n+This ratio is specified by the \\f[V]-XX:RTMAbortRatio\\f[R] option.\n+If the number of aborted transactions exceeds the abort ratio, then the\n+method containing the lock is deoptimized and recompiled with all locks\n+as normal locks.\n+This option is disabled by default.\n+The \\f[V]-XX:+UseRTMLocking\\f[R] option must be enabled.\n+.TP\n+\\f[V]-XX:+UseRTMLocking\\f[R]\n+Generates Restricted Transactional Memory (RTM) locking code for all\n+inflated locks, with the normal locking mechanism as the fallback\n+handler.\n+This option is disabled by default.\n+Options related to RTM are available only on x86 CPUs that support\n+Transactional Synchronization Extensions (TSX).\n+.RS\n+.PP\n+RTM is part of Intel\\[aq]s TSX, which is an x86 instruction set\n+extension and facilitates the creation of multithreaded applications.\n+RTM introduces the new instructions \\f[V]XBEGIN\\f[R], \\f[V]XABORT\\f[R],\n+\\f[V]XEND\\f[R], and \\f[V]XTEST\\f[R].\n+The \\f[V]XBEGIN\\f[R] and \\f[V]XEND\\f[R] instructions enclose a set of\n+instructions to run as a transaction.\n+If no conflict is found when running the transaction, then the memory\n+and register modifications are committed together at the \\f[V]XEND\\f[R]\n+instruction.\n+The \\f[V]XABORT\\f[R] instruction can be used to explicitly abort a\n+transaction and the \\f[V]XTEST\\f[R] instruction checks if a set of\n+instructions is being run in a transaction.\n+.PP\n+A lock on a transaction is inflated when another thread tries to access\n+the same transaction, thereby blocking the thread that didn\\[aq]t\n+originally request access to the transaction.\n+RTM requires that a fallback set of operations be specified in case a\n+transaction aborts or fails.\n+An RTM lock is a lock that has been delegated to the TSX\\[aq]s system.\n+.PP\n+RTM improves performance for highly contended locks with low conflict in\n+a critical region (which is code that must not be accessed by more than\n+one thread concurrently).\n+RTM also improves the performance of coarse-grain locking, which\n+typically doesn\\[aq]t perform well in multithreaded applications.\n+(Coarse-grain locking is the strategy of holding locks for long periods\n+to minimize the overhead of taking and releasing locks, while\n+fine-grained locking is the strategy of trying to achieve maximum\n+parallelism by locking only when necessary and unlocking as soon as\n+possible.)\n+Also, for lightly contended locks that are used by different threads,\n+RTM can reduce false cache line sharing, also known as cache line\n+ping-pong.\n+This occurs when multiple threads from different processors are\n+accessing different resources, but the resources share the same cache\n+line.\n+As a result, the processors repeatedly invalidate the cache lines of\n+other processors, which forces them to read from main memory instead of\n+their cache.\n+.RE\n+.SH OBSOLETE JAVA OPTIONS\n+.PP\n+These \\f[V]java\\f[R] options are still accepted but ignored, and a\n+warning is issued when they\\[aq]re used.\n+.TP\n+\\f[V]--illegal-access=\\f[R]\\f[I]parameter\\f[R]\n+Controlled \\f[I]relaxed strong encapsulation\\f[R], as defined in\n+\\f[B]JEP 261\\f[R]\n+[https:\/\/openjdk.org\/jeps\/261#Relaxed-strong-encapsulation].\n+This option was deprecated in JDK 16 by \\f[B]JEP 396\\f[R]\n+[https:\/\/openjdk.org\/jeps\/396] and made obsolete in JDK 17 by \\f[B]JEP\n+403\\f[R] [https:\/\/openjdk.org\/jeps\/403].\n+.TP\n+\\f[V]-XX:+ScavengeBeforeFullGC\\f[R]\n+Enables GC of the young generation before each full GC.\n+This option is enabled by default.\n+It is recommended that you \\f[I]don\\[aq]t\\f[R] disable it, because\n+scavenging the young generation before a full GC can reduce the number\n+of objects reachable from the old generation space into the young\n+generation space.\n+To disable GC of the young generation before each full GC, specify the\n+option \\f[V]-XX:-ScavengeBeforeFullGC\\f[R].\n+.TP\n@@ -3842,12 +3921,0 @@\n-.SH OBSOLETE JAVA OPTIONS\n-.PP\n-These \\f[V]java\\f[R] options are still accepted but ignored, and a\n-warning is issued when they\\[aq]re used.\n-.TP\n-\\f[V]--illegal-access=\\f[R]\\f[I]parameter\\f[R]\n-Controlled \\f[I]relaxed strong encapsulation\\f[R], as defined in\n-\\f[B]JEP 261\\f[R]\n-[https:\/\/openjdk.org\/jeps\/261#Relaxed-strong-encapsulation].\n-This option was deprecated in JDK 16 by \\f[B]JEP 396\\f[R]\n-[https:\/\/openjdk.org\/jeps\/396] and made obsolete in JDK 17 by \\f[B]JEP\n-403\\f[R] [https:\/\/openjdk.org\/jeps\/403].\n@@ -3856,1 +3923,19 @@\n-No documented java options have been removed in JDK 22.\n+These \\f[V]java\\f[R] options have been removed in JDK 23 and using them\n+results in an error of:\n+.RS\n+.PP\n+\\f[V]Unrecognized VM option\\f[R] \\f[I]option-name\\f[R]\n+.RE\n+.TP\n+\\f[V]-XX:+UseHugeTLBFS\\f[R]\n+\\f[B]Linux only:\\f[R] This option is the equivalent of specifying\n+\\f[V]-XX:+UseLargePages\\f[R].\n+This option is disabled by default.\n+This option pre-allocates all large pages up-front, when memory is\n+reserved; consequently the JVM can\\[aq]t dynamically grow or shrink\n+large pages memory areas; see \\f[V]-XX:UseTransparentHugePages\\f[R] if\n+you want this behavior.\n+.TP\n+\\f[V]-XX:+UseSHM\\f[R]\n+\\f[B]Linux only:\\f[R] Enables the JVM to use shared memory to set up\n+large pages.\n@@ -3861,0 +3946,3 @@\n+\\f[B]The \\f[VB]java\\f[B] Command, Release 22\\f[R]\n+[https:\/\/docs.oracle.com\/en\/java\/javase\/22\/docs\/specs\/man\/java.html]\n+.IP \\[bu] 2\n@@ -4304,3 +4392,3 @@\n-When using \\f[V]file=\\f[R]\\f[I]filename\\f[R], specifying \\f[V]%p\\f[R]\n-and\/or \\f[V]%t\\f[R] in the file name expands to the JVM\\[aq]s PID and\n-startup timestamp, respectively.\n+When using \\f[V]file=\\f[R]\\f[I]filename\\f[R], specifying \\f[V]%p\\f[R],\n+\\f[V]%t\\f[R] and\/or \\f[V]%hn\\f[R] in the file name expands to the\n+JVM\\[aq]s PID, startup timestamp and host name, respectively.\n@@ -4954,14 +5042,0 @@\n-.PP\n-When using the option \\f[V]-XX:+UseSHM\\f[R] to enable large pages you\n-also need to make sure the \\f[V]SHMMAX\\f[R] parameter is configured to\n-allow large enough shared memory segments to be allocated.\n-To allow a maximum shared segment of 8 GB, login as \\f[V]root\\f[R] and\n-run:\n-.RS\n-.PP\n-\\f[V]# echo 8589934592 > \/proc\/sys\/kernel\/shmmax\\f[R]\n-.RE\n-.PP\n-In some environments this is not needed since the default value is large\n-enough, but it is important to make sure the value is large enough to\n-fit the amount of memory intended to be backed by large pages.\n@@ -5134,0 +5208,12 @@\n+.PP\n+By default, when the \\f[V]-Xshare:dump\\f[R] option is used, the JVM runs\n+in interpreter-only mode (as if the \\f[V]-Xint\\f[R] option were\n+specified).\n+This is required for generating deterministic output in the shared\n+archive file.\n+I.e., the exact same archive will be generated, bit-for-bit, every time\n+you dump it.\n+However, if deterministic output is not needed, and you have a large\n+classlist, you can explicitly add \\f[V]-Xmixed\\f[R] to the command-line\n+to enable the JIT compiler.\n+This will speed up the archive creation.\n","filename":"src\/java.base\/share\/man\/java.1","additions":312,"deletions":226,"binary":false,"changes":538,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -636,1 +636,1 @@\n-            super(new FileOutputStream(fd));\n+            super(new PipeOutputStream(fd));\n","filename":"src\/java.base\/unix\/classes\/java\/lang\/ProcessImpl.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -216,2 +216,1 @@\n-    public NativePRNG() {\n-        super();\n+    public NativePRNG(SecureRandomParameters params) {\n@@ -221,0 +220,3 @@\n+        if (params != null) {\n+            throw new IllegalArgumentException(\"Unsupported params: \" + params.getClass());\n+        }\n@@ -264,2 +266,1 @@\n-        public Blocking() {\n-            super();\n+        public Blocking(SecureRandomParameters params) {\n@@ -269,0 +270,3 @@\n+            if (params != null) {\n+                throw new IllegalArgumentException(\"Unsupported params: \" + params.getClass());\n+            }\n@@ -313,2 +317,1 @@\n-        public NonBlocking() {\n-            super();\n+        public NonBlocking(SecureRandomParameters params) {\n@@ -319,0 +322,3 @@\n+            if (params != null) {\n+                throw new IllegalArgumentException(\"Unsupported params: \" + params.getClass());\n+            }\n","filename":"src\/java.base\/unix\/classes\/sun\/security\/provider\/NativePRNG.java","additions":13,"deletions":7,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -498,0 +498,2 @@\n+    JLI_TraceLauncher(\"Attempt to get JRE path from launcher executable path\\n\");\n+\n@@ -505,9 +507,7 @@\n-        \/* ensure storage for path + \/jre + NULL *\/\n-        if ((JLI_StrLen(path) + 4  + 1) > (size_t) pathsize) {\n-            JLI_TraceLauncher(\"Insufficient space to store JRE path\\n\");\n-            return JNI_FALSE;\n-        }\n-        \/* Does the app ship a private JRE in <apphome>\/jre directory? *\/\n-        JLI_Snprintf(libjava, sizeof(libjava), \"%s\/jre\/lib\/\" JAVA_DLL, path);\n-        if (access(libjava, F_OK) == 0) {\n-            JLI_StrCat(path, \"\/jre\");\n+    }\n+\n+    JLI_TraceLauncher(\"Attempt to get JRE path from shared lib of the image\\n\");\n+\n+    if (GetApplicationHomeFromDll(path, pathsize)) {\n+        JLI_Snprintf(libjava, sizeof(libjava), \"%s\/lib\/\" JAVA_DLL, path);\n+        if (stat(libjava, &s) == 0) {\n@@ -519,1 +519,3 @@\n-    if (GetApplicationHomeFromDll(path, pathsize)) {\n+#if defined(AIX)\n+    \/* at least on AIX try also the LD_LIBRARY_PATH \/ LIBPATH *\/\n+    if (GetApplicationHomeFromLibpath(path, pathsize)) {\n@@ -526,0 +528,1 @@\n+#endif\n","filename":"src\/java.base\/unix\/native\/libjli\/java_md.c","additions":14,"deletions":11,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -62,1 +62,4 @@\n-        this.addJavaOpts(javaOpts);\n+        Collections.addAll(this.javaOpts, javaOpts);\n+        \/\/ always print hserr to stderr in the docker tests to avoid\n+        \/\/ trouble accessing it after a crash in the container\n+        Collections.addAll(this.javaOpts, \"-XX:+ErrorFileToStderr\");\n","filename":"test\/lib\/jdk\/test\/lib\/containers\/docker\/DockerRunOptions.java","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -69,0 +69,5 @@\n+        \/\/ Ubuntu 22.04 ppc started to crash in libz inflateReset on Power8 based host\n+        \/\/ those recent Ubuntu versions only work on Power9+\n+        if (Platform.isPPC()) {\n+            return \"20.04\";\n+        }\n","filename":"test\/lib\/jdk\/test\/lib\/containers\/docker\/DockerfileConfig.java","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"}]}