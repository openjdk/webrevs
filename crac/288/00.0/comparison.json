{"files":[{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2022, 2024, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2022, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -43,0 +43,4 @@\n+      dry-run:\n+        required: false\n+        type: boolean\n+        default: false\n@@ -47,1 +51,1 @@\n-    runs-on: ubuntu-22.04\n+    runs-on: ubuntu-24.04\n@@ -63,1 +67,1 @@\n-            debian-version: bullseye\n+            debian-version: trixie\n@@ -69,1 +73,1 @@\n-            debian-version: bullseye\n+            debian-version: trixie\n@@ -76,1 +80,1 @@\n-#            debian-version: bullseye\n+#            debian-version: trixie\n@@ -82,1 +86,1 @@\n-#            debian-version: bullseye\n+#            debian-version: trixie\n@@ -88,2 +92,2 @@\n-#            debian-version: sid\n-#            tolerate-sysroot-errors: true\n+#            debian-version: trixie\n+#            tolerate-sysroot-errors: false\n@@ -178,0 +182,2 @@\n+          --with-external-symbols-in-bundles=none\n+          --with-native-debug-symbols-level=1\n@@ -192,1 +198,1 @@\n-        if: steps.create-sysroot.outcome == 'success' || steps.get-cached-sysroot.outputs.cache-hit == 'true'\n+        if: ((steps.create-sysroot.outcome == 'success' || steps.get-cached-sysroot.outputs.cache-hit == 'true') && inputs.dry-run == false)\n","filename":".github\/workflows\/build-cross-compile.yml","additions":15,"deletions":9,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2022, 2024, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2022, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -43,0 +43,4 @@\n+      dry-run:\n+        required: false\n+        type: boolean\n+        default: false\n@@ -158,0 +162,1 @@\n+        if: ${{ inputs.dry-run == false }}\n@@ -221,0 +226,1 @@\n+        if: ${{ inputs.dry-run == false }}\n","filename":".github\/workflows\/test.yml","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -4,1 +4,1 @@\n-version=25\n+version=27\n","filename":".jcheck\/conf","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -27,1 +27,1 @@\n-[online documentation](https:\/\/openjdk.org\/groups\/build\/doc\/building.html),\n+[online documentation](https:\/\/git.openjdk.org\/jdk\/blob\/master\/doc\/building.md),\n","filename":"README.md","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -97,0 +97,1 @@\n+# -XDaccessInternalAPI is a temporary workaround, see 8373909\n@@ -100,1 +101,2 @@\n-    --override-methods=summary\n+    --override-methods=summary \\\n+    -XDaccessInternalAPI\n@@ -106,1 +108,2 @@\n-    -html5 -javafx --expand-requires transitive\n+    -html5 -javafx --expand-requires transitive \\\n+    -XDaccessInternalAPI\n@@ -240,2 +243,2 @@\n-      <p>This document is divided into \\\n-      $$(subst 2,two,$$(subst 3,three,$$(words $$($1_GROUPS)))) sections:<\/p> \\\n+      <p>This document has \\\n+      $$(subst 2,two,$$(subst 3,three,$$(words $$($1_GROUPS)))) major sections:<\/p> \\\n@@ -250,1 +253,4 @@\n-        #\n+    <p><a href=\"..\/specs\/index.html\">Related documents<\/a> specify the Java \\\n+    programming language, the Java Virtual Machine, various protocols and file \\\n+    formats pertaining to the Java platform, and tools included in the JDK.<\/p> \\\n+    #\n@@ -292,2 +298,1 @@\n-  $1_JAVA_ARGS := -Dextlink.spec.version=$$(VERSION_SPECIFICATION) \\\n-\t-Djspec.version=$$(VERSION_SPECIFICATION)\n+  $1_JAVA_ARGS := -Dextlink.spec.version=$$(VERSION_SPECIFICATION)\n","filename":"make\/Docs.gmk","additions":12,"deletions":7,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -40,6 +40,0 @@\n-    # --disable-new-dtags forces use of RPATH instead of RUNPATH for rpaths.\n-    # This protects internal library dependencies within the JDK from being\n-    # overridden using LD_LIBRARY_PATH. See JDK-8326891 for more information.\n-    SET_EXECUTABLE_ORIGIN='-Wl,-rpath,\\$$ORIGIN[$]1 -Wl,--disable-new-dtags'\n-    SET_SHARED_LIBRARY_ORIGIN=\"-Wl,-z,origin $SET_EXECUTABLE_ORIGIN\"\n-    SET_SHARED_LIBRARY_NAME='-Wl,-soname=[$]1'\n@@ -51,3 +45,0 @@\n-      SET_EXECUTABLE_ORIGIN='-Wl,-rpath,@loader_path$(or [$]1,\/.)'\n-      SET_SHARED_LIBRARY_ORIGIN=\"$SET_EXECUTABLE_ORIGIN\"\n-      SET_SHARED_LIBRARY_NAME='-Wl,-install_name,@rpath\/[$]1'\n@@ -58,3 +49,0 @@\n-      SET_EXECUTABLE_ORIGIN=\"\"\n-      SET_SHARED_LIBRARY_ORIGIN=''\n-      SET_SHARED_LIBRARY_NAME=''\n@@ -65,13 +53,0 @@\n-      SET_EXECUTABLE_ORIGIN='-Wl,-rpath,\\$$ORIGIN[$]1'\n-      if test \"x$OPENJDK_TARGET_OS\" = xlinux; then\n-        SET_EXECUTABLE_ORIGIN=\"$SET_EXECUTABLE_ORIGIN -Wl,--disable-new-dtags\"\n-      fi\n-      SET_SHARED_LIBRARY_NAME='-Wl,-soname=[$]1'\n-\n-      # arm specific settings\n-      if test \"x$OPENJDK_TARGET_CPU\" = \"xarm\"; then\n-        # '-Wl,-z,origin' isn't used on arm.\n-        SET_SHARED_LIBRARY_ORIGIN='-Wl,-rpath,\\$$$$ORIGIN[$]1'\n-      else\n-        SET_SHARED_LIBRARY_ORIGIN=\"-Wl,-z,origin $SET_EXECUTABLE_ORIGIN\"\n-      fi\n@@ -82,3 +57,0 @@\n-    SET_EXECUTABLE_ORIGIN=''\n-    SET_SHARED_LIBRARY_ORIGIN=''\n-    SET_SHARED_LIBRARY_NAME=''\n@@ -87,3 +59,0 @@\n-  AC_SUBST(SET_EXECUTABLE_ORIGIN)\n-  AC_SUBST(SET_SHARED_LIBRARY_ORIGIN)\n-  AC_SUBST(SET_SHARED_LIBRARY_NAME)\n@@ -103,0 +72,17 @@\n+  UTIL_ARG_WITH(NAME: native-debug-symbols-level, TYPE: string,\n+    DEFAULT: \"\",\n+    RESULT: DEBUG_SYMBOLS_LEVEL,\n+    DESC: [set the native debug symbol level (GCC and Clang only)],\n+    DEFAULT_DESC: [toolchain default])\n+  AC_SUBST(DEBUG_SYMBOLS_LEVEL)\n+\n+  if test \"x${TOOLCHAIN_TYPE}\" = xgcc || \\\n+     test \"x${TOOLCHAIN_TYPE}\" = xclang; then\n+    DEBUG_SYMBOLS_LEVEL_FLAGS=\"-g\"\n+    if test \"x${DEBUG_SYMBOLS_LEVEL}\" != \"x\"; then\n+      DEBUG_SYMBOLS_LEVEL_FLAGS=\"-g${DEBUG_SYMBOLS_LEVEL}\"\n+      FLAGS_COMPILER_CHECK_ARGUMENTS(ARGUMENT: [${DEBUG_SYMBOLS_LEVEL_FLAGS}],\n+          IF_FALSE: AC_MSG_ERROR(\"Debug info level ${DEBUG_SYMBOLS_LEVEL} is not supported\"))\n+    fi\n+  fi\n+\n@@ -127,2 +113,3 @@\n-    CFLAGS_DEBUG_SYMBOLS=\"-g -gdwarf-4\"\n-    ASFLAGS_DEBUG_SYMBOLS=\"-g\"\n+    # Debug info level should follow the debug format to be effective.\n+    CFLAGS_DEBUG_SYMBOLS=\"-gdwarf-4 ${DEBUG_SYMBOLS_LEVEL_FLAGS}\"\n+    ASFLAGS_DEBUG_SYMBOLS=\"${DEBUG_SYMBOLS_LEVEL_FLAGS}\"\n@@ -147,2 +134,3 @@\n-    CFLAGS_DEBUG_SYMBOLS=\"-g ${GDWARF_FLAGS}\"\n-    ASFLAGS_DEBUG_SYMBOLS=\"-g\"\n+    # Debug info level should follow the debug format to be effective.\n+    CFLAGS_DEBUG_SYMBOLS=\"${GDWARF_FLAGS} ${DEBUG_SYMBOLS_LEVEL_FLAGS}\"\n+    ASFLAGS_DEBUG_SYMBOLS=\"${DEBUG_SYMBOLS_LEVEL_FLAGS}\"\n@@ -316,0 +304,6 @@\n+    if test \"x$TOOLCHAIN_TYPE\" = xgcc; then\n+      C_O_FLAG_LTO=\"-flto=auto -fuse-linker-plugin -fno-strict-aliasing -fno-fat-lto-objects\"\n+    else\n+      C_O_FLAG_LTO=\"-flto -fno-strict-aliasing\"\n+    fi\n+\n@@ -320,0 +314,1 @@\n+      C_O_FLAG_LTO=\"${C_O_FLAG_LTO} -ffat-lto-objects\"\n@@ -351,0 +346,1 @@\n+    C_O_FLAG_LTO=\"-GL\"\n@@ -362,0 +358,1 @@\n+  CXX_O_FLAG_LTO=\"$C_O_FLAG_LTO\"\n@@ -394,0 +391,2 @@\n+  AC_SUBST(C_O_FLAG_LTO)\n+\n@@ -400,0 +399,1 @@\n+  AC_SUBST(CXX_O_FLAG_LTO)\n@@ -600,1 +600,1 @@\n-    LANGSTD_CXXFLAGS=\"-std=c++14\"\n+    LANGSTD_CXXFLAGS=\"-std=c++17\"\n@@ -602,1 +602,1 @@\n-    LANGSTD_CXXFLAGS=\"-std:c++14\"\n+    LANGSTD_CXXFLAGS=\"-std:c++17\"\n@@ -604,1 +604,1 @@\n-    AC_MSG_ERROR([Cannot enable C++14 for this toolchain])\n+    AC_MSG_ERROR([Cannot enable C++17 for this toolchain])\n@@ -742,2 +742,9 @@\n-        # Use Power8, this is the first CPU to support PPC64 LE with ELFv2 ABI.\n-        $1_CFLAGS_CPU=\"-mcpu=power8 -mtune=power10\"\n+        # Use Power8 for target cpu, this is the first CPU to support PPC64 LE with ELFv2 ABI.\n+        # Use Power10 for tuning target, this is supported by gcc >= 10\n+        POWER_TUNE_VERSION=\"-mtune=power10\"\n+        FLAGS_COMPILER_CHECK_ARGUMENTS(ARGUMENT: [${POWER_TUNE_VERSION}],\n+          IF_FALSE: [\n+              POWER_TUNE_VERSION=\"-mtune=power8\"\n+          ]\n+        )\n+        $1_CFLAGS_CPU=\"-mcpu=power8 ${POWER_TUNE_VERSION}\"\n@@ -933,31 +940,0 @@\n-\n-  # Check whether the compiler supports the Arm C Language Extensions (ACLE)\n-  # for SVE. Set SVE_CFLAGS to -march=armv8-a+sve if it does.\n-  # ACLE and this flag are required to build the aarch64 SVE related functions in\n-  # libvectormath. Apple Silicon does not support SVE; use macOS as a proxy for\n-  # that check.\n-  if test \"x$OPENJDK_TARGET_CPU\" = \"xaarch64\" && test \"x$OPENJDK_TARGET_CPU\" = \"xlinux\"; then\n-    if test \"x$TOOLCHAIN_TYPE\" = xgcc || test \"x$TOOLCHAIN_TYPE\" = xclang; then\n-      AC_LANG_PUSH(C)\n-      OLD_CFLAGS=\"$CFLAGS\"\n-      CFLAGS=\"$CFLAGS -march=armv8-a+sve\"\n-      AC_MSG_CHECKING([if Arm SVE ACLE is supported])\n-      AC_COMPILE_IFELSE([AC_LANG_PROGRAM([#include <arm_sve.h>],\n-          [\n-            svint32_t r = svdup_n_s32(1);\n-            return 0;\n-          ])],\n-          [\n-            AC_MSG_RESULT([yes])\n-            $2SVE_CFLAGS=\"-march=armv8-a+sve\"\n-          ],\n-          [\n-            AC_MSG_RESULT([no])\n-            $2SVE_CFLAGS=\"\"\n-          ]\n-      )\n-      CFLAGS=\"$OLD_CFLAGS\"\n-      AC_LANG_POP(C)\n-    fi\n-  fi\n-  AC_SUBST($2SVE_CFLAGS)\n","filename":"make\/autoconf\/flags-cflags.m4","additions":47,"deletions":71,"binary":false,"changes":118,"status":"modified"},{"patch":"@@ -540,0 +540,4 @@\n+  if JVM_FEATURES_IS_ACTIVE(jfr) && ! JVM_FEATURES_IS_ACTIVE(services); then\n+    AC_MSG_ERROR([Specified JVM feature 'jfr' requires feature 'services' for variant '$variant'])\n+  fi\n+\n","filename":"make\/autoconf\/jvm-features.m4","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2011, 2024, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2011, 2025, Oracle and\/or its affiliates. All rights reserved.\n","filename":"make\/autoconf\/lib-bundled.m4","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -389,3 +389,16 @@\n-BUILD_JDK := @BUILD_JDK@\n-CREATE_BUILDJDK := @CREATE_BUILDJDK@\n-EXTERNAL_BUILDJDK := @EXTERNAL_BUILDJDK@\n+EXTERNAL_BUILDJDK_PATH := @EXTERNAL_BUILDJDK_PATH@\n+\n+ifneq ($(EXTERNAL_BUILDJDK_PATH), )\n+  EXTERNAL_BUILDJDK := true\n+  CREATE_BUILDJDK := false\n+  BUILD_JDK := $(EXTERNAL_BUILDJDK_PATH)\n+else\n+  EXTERNAL_BUILDJDK := false\n+  ifeq ($(COMPILE_TYPE), cross)\n+    CREATE_BUILDJDK := true\n+    BUILD_JDK := $(BUILDJDK_OUTPUTDIR)\/jdk\n+  else\n+    CREATE_BUILDJDK := false\n+    BUILD_JDK := $(JDK_OUTPUTDIR)\n+  endif\n+endif\n@@ -396,3 +409,2 @@\n-# When compiling Java source to be run by the boot jdk\n-# use these extra flags, eg -source 6 -target 6\n-BOOT_JDK_SOURCETARGET := @BOOT_JDK_SOURCETARGET@\n+# The oldest supported boot jdk version\n+OLDEST_BOOT_JDK_VERSION := @OLDEST_BOOT_JDK_VERSION@\n@@ -495,1 +507,1 @@\n-CC_OUT_OPTION := @CC_OUT_OPTION@\n+AS_NON_ASM_EXTENSION_OPTION := @AS_NON_ASM_EXTENSION_OPTION@\n@@ -504,0 +516,1 @@\n+C_O_FLAG_LTO := @C_O_FLAG_LTO@\n@@ -510,0 +523,1 @@\n+CXX_O_FLAG_LTO  := @CXX_O_FLAG_LTO@\n@@ -578,0 +592,3 @@\n+# LDFLAGS specific to link time optimization\n+LDFLAGS_LTO := @LDFLAGS_LTO@\n+\n@@ -627,4 +644,0 @@\n-# Options to linker to specify the library name.\n-# (Note absence of := assignment, because we do not want to evaluate the macro body here)\n-SET_SHARED_LIBRARY_NAME = @SET_SHARED_LIBRARY_NAME@\n-\n@@ -633,5 +646,0 @@\n-# Set origin using the linker, ie use the relative path to the dependent library to find the dependencies.\n-# (Note absence of := assignment, because we do not want to evaluate the macro body here)\n-SET_SHARED_LIBRARY_ORIGIN = @SET_SHARED_LIBRARY_ORIGIN@\n-SET_EXECUTABLE_ORIGIN = @SET_EXECUTABLE_ORIGIN@\n-\n@@ -660,2 +668,2 @@\n-JLINK_CMD := @JLINK@\n-JMOD_CMD := @JMOD@\n+JLINK_CMD := @FIXPATH@ $(BUILD_JDK)\/bin\/jlink\n+JMOD_CMD := @FIXPATH@ $(BUILD_JDK)\/bin\/jmod\n@@ -903,4 +911,4 @@\n-JDK_MACOSX_BUNDLE_TOP_DIR = jdk-$(VERSION_NUMBER).jdk\n-JRE_MACOSX_BUNDLE_TOP_DIR = jre-$(VERSION_NUMBER).jre\n-JDK_MACOSX_CONTENTS_SUBDIR = $(JDK_MACOSX_BUNDLE_TOP_DIR)\/Contents\n-JRE_MACOSX_CONTENTS_SUBDIR = $(JRE_MACOSX_BUNDLE_TOP_DIR)\/Contents\n+JDK_MACOSX_BUNDLE_TOP_SUBDIR = jdk-$(VERSION_NUMBER).jdk\n+JRE_MACOSX_BUNDLE_TOP_SUBDIR = jre-$(VERSION_NUMBER).jre\n+JDK_MACOSX_CONTENTS_SUBDIR = $(JDK_MACOSX_BUNDLE_TOP_SUBDIR)\/Contents\n+JRE_MACOSX_CONTENTS_SUBDIR = $(JRE_MACOSX_BUNDLE_TOP_SUBDIR)\/Contents\n@@ -909,0 +917,2 @@\n+JDK_MACOSX_BUNDLE_TOP_DIR = $(JDK_MACOSX_BUNDLE_DIR)\/$(JDK_MACOSX_BUNDLE_TOP_SUBDIR)\n+JRE_MACOSX_BUNDLE_TOP_DIR = $(JRE_MACOSX_BUNDLE_DIR)\/$(JRE_MACOSX_BUNDLE_TOP_SUBDIR)\n","filename":"make\/autoconf\/spec.gmk.template","additions":32,"deletions":22,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2014, 2023, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2014, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -55,1 +55,0 @@\n-    jdk.jsobject \\\n","filename":"make\/conf\/docs-modules.conf","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -29,1 +29,1 @@\n-JTREG_VERSION=7.5.1+1\n+JTREG_VERSION=8.1+1\n@@ -32,2 +32,2 @@\n-LINUX_X64_BOOT_JDK_URL=https:\/\/download.java.net\/java\/GA\/jdk24\/1f9ff9062db4449d8ca828c504ffae90\/36\/GPL\/openjdk-24_linux-x64_bin.tar.gz\n-LINUX_X64_BOOT_JDK_SHA256=88b090fa80c6c1d084ec9a755233967458788e2c0777ae2e172230c5c692d7ef\n+LINUX_X64_BOOT_JDK_URL=https:\/\/download.java.net\/java\/GA\/jdk25\/bd75d5f9689641da8e1daabeccb5528b\/36\/GPL\/openjdk-25_linux-x64_bin.tar.gz\n+LINUX_X64_BOOT_JDK_SHA256=59cdcaf255add4721de38eb411d4ecfe779356b61fb671aee63c7dec78054c2b\n@@ -36,2 +36,2 @@\n-ALPINE_LINUX_X64_BOOT_JDK_URL=https:\/\/github.com\/adoptium\/temurin24-binaries\/releases\/download\/jdk-24%2B36\/OpenJDK24U-jdk_x64_alpine-linux_hotspot_24_36.tar.gz\n-ALPINE_LINUX_X64_BOOT_JDK_SHA256=a642608f0da78344ee6812fb1490b8bc1d7ad5a18064c70994d6f330568c51cb\n+ALPINE_LINUX_X64_BOOT_JDK_URL=https:\/\/github.com\/adoptium\/temurin25-binaries\/releases\/download\/jdk-25%2B36\/OpenJDK25U-jdk_x64_alpine-linux_hotspot_25_36.tar.gz\n+ALPINE_LINUX_X64_BOOT_JDK_SHA256=637e47474d411ed86134f413af7d5fef4180ddb0bf556347b7e74a88cf8904c8\n@@ -40,2 +40,2 @@\n-MACOS_AARCH64_BOOT_JDK_URL=https:\/\/download.java.net\/java\/GA\/jdk24\/1f9ff9062db4449d8ca828c504ffae90\/36\/GPL\/openjdk-24_macos-aarch64_bin.tar.gz\n-MACOS_AARCH64_BOOT_JDK_SHA256=f7133238a12714a62c5ad2bd4da6741130be1a82512065da9ca23dee26b2d3d3\n+MACOS_AARCH64_BOOT_JDK_URL=https:\/\/download.java.net\/java\/GA\/jdk25\/bd75d5f9689641da8e1daabeccb5528b\/36\/GPL\/openjdk-25_macos-aarch64_bin.tar.gz\n+MACOS_AARCH64_BOOT_JDK_SHA256=2006337bf326fdfdf6117081751ba38c1c8706d63419ecac7ff102ff7c776876\n@@ -48,2 +48,2 @@\n-MACOS_X64_BOOT_JDK_URL=https:\/\/download.java.net\/java\/GA\/jdk24\/1f9ff9062db4449d8ca828c504ffae90\/36\/GPL\/openjdk-24_macos-x64_bin.tar.gz\n-MACOS_X64_BOOT_JDK_SHA256=6bbfb1d01741cbe55ab90299cb91464b695de9a3ace85c15131aa2f50292f321\n+MACOS_X64_BOOT_JDK_URL=https:\/\/download.java.net\/java\/GA\/jdk25\/bd75d5f9689641da8e1daabeccb5528b\/36\/GPL\/openjdk-25_macos-x64_bin.tar.gz\n+MACOS_X64_BOOT_JDK_SHA256=47482ad9888991ecac9b2bcc131e2b53ff78aff275104cef85f66252308e8a09\n@@ -52,2 +52,2 @@\n-WINDOWS_X64_BOOT_JDK_URL=https:\/\/download.java.net\/java\/GA\/jdk24\/1f9ff9062db4449d8ca828c504ffae90\/36\/GPL\/openjdk-24_windows-x64_bin.zip\n-WINDOWS_X64_BOOT_JDK_SHA256=11d1d9f6ac272d5361c8a0bef01894364081c7fb1a6914c2ad2fc312ae83d63b\n+WINDOWS_X64_BOOT_JDK_URL=https:\/\/download.java.net\/java\/GA\/jdk25\/bd75d5f9689641da8e1daabeccb5528b\/36\/GPL\/openjdk-25_windows-x64_bin.zip\n+WINDOWS_X64_BOOT_JDK_SHA256=85bcc178461e2cb3c549ab9ca9dfa73afd54c09a175d6510d0884071867137d3\n","filename":"make\/conf\/github-actions.conf","additions":11,"deletions":11,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -66,1 +66,0 @@\n-    jdk.jsobject \\\n","filename":"make\/conf\/module-loader-map.conf","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -60,1 +60,1 @@\n-    JVM_LDFLAGS_FEATURES += $(call SET_EXECUTABLE_ORIGIN,\/..)\n+    JVM_LDFLAGS_FEATURES += $(call SetExecutableOrigin,\/..)\n@@ -182,14 +182,3 @@\n-  ifeq ($(call isCompiler, gcc), true)\n-    JVM_CFLAGS_FEATURES += -flto=auto -fuse-linker-plugin -fno-strict-aliasing \\\n-        -fno-fat-lto-objects\n-    JVM_LDFLAGS_FEATURES += $(CXX_O_FLAG_HIGHEST_JVM) -flto=auto \\\n-        -fuse-linker-plugin -fno-strict-aliasing\n-  else ifeq ($(call isCompiler, clang), true)\n-    JVM_CFLAGS_FEATURES += -flto -fno-strict-aliasing\n-    ifeq ($(call isBuildOs, aix), true)\n-      JVM_CFLAGS_FEATURES += -ffat-lto-objects\n-    endif\n-    JVM_LDFLAGS_FEATURES += $(CXX_O_FLAG_HIGHEST_JVM) -flto -fno-strict-aliasing\n-  else ifeq ($(call isCompiler, microsoft), true)\n-    JVM_CFLAGS_FEATURES += -GL\n-    JVM_LDFLAGS_FEATURES += -LTCG:INCREMENTAL\n+  JVM_LTO := true\n+  ifneq ($(call isCompiler, microsoft), true)\n+    JVM_LDFLAGS_FEATURES += $(CXX_O_FLAG_HIGHEST_JVM)\n@@ -198,0 +187,1 @@\n+  JVM_LTO := false\n","filename":"make\/hotspot\/lib\/JvmFeatures.gmk","additions":5,"deletions":15,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -76,1 +76,1 @@\n-      SRC := $(TOPDIR)\/src\/$(MODULE)\/unix\/native\/launcher, \\\n+      EXTRA_FILES := $(TOPDIR)\/src\/$(MODULE)\/unix\/native\/launcher\/jexec.c, \\\n","filename":"make\/modules\/java.base\/Launcher.gmk","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -157,0 +157,2 @@\n+## The LIBDL dependency on Linux is needed to dynamically access libdl symbols,\n+## which may be needed as part of resolving some standard symbols\n@@ -199,1 +201,1 @@\n-      LIBS_linux := $(LIBDL) $(LIBM), \\\n+      LIBS_linux := $(LIBM), \\\n","filename":"make\/modules\/java.base\/Lib.gmk","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -4,0 +4,1 @@\n+ * Copyright 2025 Arm Limited and\/or its affiliates.\n@@ -35,0 +36,1 @@\n+#include \"utilities\/ostream.hpp\"\n@@ -53,10 +55,1 @@\n-static SpinWait get_spin_wait_desc() {\n-  if (strcmp(OnSpinWaitInst, \"nop\") == 0) {\n-    return SpinWait(SpinWait::NOP, OnSpinWaitInstCount);\n-  } else if (strcmp(OnSpinWaitInst, \"isb\") == 0) {\n-    return SpinWait(SpinWait::ISB, OnSpinWaitInstCount);\n-  } else if (strcmp(OnSpinWaitInst, \"yield\") == 0) {\n-    return SpinWait(SpinWait::YIELD, OnSpinWaitInstCount);\n-  } else if (strcmp(OnSpinWaitInst, \"none\") != 0) {\n-    vm_exit_during_initialization(\"The options for OnSpinWaitInst are nop, isb, yield, and none\", OnSpinWaitInst);\n-  }\n+const char* VM_Version::_features_names[MAX_CPU_FEATURES] = { nullptr };\n@@ -64,2 +57,4 @@\n-  if (!FLAG_IS_DEFAULT(OnSpinWaitInstCount) && OnSpinWaitInstCount > 0) {\n-    vm_exit_during_initialization(\"OnSpinWaitInstCount cannot be used for OnSpinWaitInst 'none'\");\n+static SpinWait get_spin_wait_desc() {\n+  SpinWait spin_wait(OnSpinWaitInst, OnSpinWaitInstCount);\n+  if (spin_wait.inst() == SpinWait::SB && !VM_Version::supports_sb()) {\n+    vm_exit_during_initialization(\"OnSpinWaitInst is SB but current CPU does not support SB instruction\");\n@@ -68,1 +63,1 @@\n-  return SpinWait{};\n+  return spin_wait;\n@@ -72,0 +67,5 @@\n+#define SET_CPU_FEATURE_NAME(id, name, bit) \\\n+  _features_names[bit] = XSTR(name);\n+  CPU_FEATURE_FLAGS(SET_CPU_FEATURE_NAME)\n+#undef SET_CPU_FEATURE_NAME\n+\n@@ -206,1 +206,1 @@\n-    _features |= CPU_A53MAC;\n+    set_feature(CPU_A53MAC);\n@@ -226,0 +226,1 @@\n+  \/\/   N3: 0xd8e\n@@ -228,0 +229,1 @@\n+  \/\/   V3: 0xd84\n@@ -229,1 +231,2 @@\n-                          model_is(0xd40) || model_is(0xd4f))) {\n+                          model_is(0xd40) || model_is(0xd4f) ||\n+                          model_is(0xd8e) || model_is(0xd84))) {\n@@ -246,1 +249,1 @@\n-  if (_features & (CPU_FP | CPU_ASIMD)) {\n+  if (supports_feature(CPU_FP) || supports_feature(CPU_ASIMD)) {\n@@ -264,1 +267,3 @@\n-  if (_cpu == CPU_ARM && (model_is(0xd40) || model_is(0xd4f))) {\n+  \/\/   V3: 0xd84\n+  if (_cpu == CPU_ARM &&\n+      (model_is(0xd40) || model_is(0xd4f) || model_is(0xd84))) {\n@@ -376,2 +381,2 @@\n-    \/\/ on Apple silicon but worse performance on Neoverse V1 and N2.\n-    if (_cpu == CPU_APPLE) {  \/\/ Apple silicon\n+    \/\/ on Apple and Qualcomm silicon but worse performance on Neoverse V1 and N2.\n+    if (_cpu == CPU_APPLE || _cpu == CPU_QUALCOMM) {  \/\/ Apple or Qualcomm silicon\n@@ -409,1 +414,1 @@\n-  if (_features & CPU_ASIMD) {\n+  if (supports_feature(CPU_ASIMD)) {\n@@ -420,1 +425,1 @@\n-  if (_features & CPU_ASIMD) {\n+  if (supports_feature(CPU_ASIMD)) {\n@@ -431,1 +436,1 @@\n-  if (_features & CPU_ASIMD) {\n+  if (supports_feature(CPU_ASIMD)) {\n@@ -632,2 +637,2 @@\n-    _features &= ~CPU_SVE2;\n-    _features &= ~CPU_SVEBITPERM;\n+    clear_feature(CPU_SVE2);\n+    clear_feature(CPU_SVEBITPERM);\n@@ -636,1 +641,1 @@\n-    _features &= ~CPU_SVE;\n+    clear_feature(CPU_SVE);\n@@ -642,2 +647,2 @@\n-  char buf[512];\n-  int buf_used_len = os::snprintf_checked(buf, sizeof(buf), \"0x%02x:0x%x:0x%03x:%d\", _cpu, _variant, _model, _revision);\n+  stringStream ss(512);\n+  ss.print(\"0x%02x:0x%x:0x%03x:%d\", _cpu, _variant, _model, _revision);\n@@ -645,1 +650,1 @@\n-    os::snprintf_checked(buf + buf_used_len, sizeof(buf) - buf_used_len, \"(0x%03x)\", _model2);\n+    ss.print(\"(0x%03x)\", _model2);\n@@ -647,7 +652,3 @@\n-  size_t features_offset = strnlen(buf, sizeof(buf));\n-#define ADD_FEATURE_IF_SUPPORTED(id, name, bit)                 \\\n-  do {                                                          \\\n-    if (VM_Version::supports_##name()) strcat(buf, \", \" #name); \\\n-  } while(0);\n-  CPU_FEATURE_FLAGS(ADD_FEATURE_IF_SUPPORTED)\n-#undef ADD_FEATURE_IF_SUPPORTED\n+  ss.print(\", \");\n+  int features_offset = (int)ss.size();\n+  insert_features_names(_features, ss);\n@@ -655,1 +656,3 @@\n-  _cpu_info_string = os::strdup(buf);\n+  _cpu_info_string = ss.as_string(true);\n+  _features_string = _cpu_info_string + features_offset;\n+}\n@@ -657,3 +660,11 @@\n-  _features_string = extract_features_string(_cpu_info_string,\n-                                             strnlen(_cpu_info_string, sizeof(buf)),\n-                                             features_offset);\n+void VM_Version::insert_features_names(uint64_t features, stringStream& ss) {\n+  int i = 0;\n+  ss.join([&]() {\n+    while (i < MAX_CPU_FEATURES) {\n+      if (supports_feature((VM_Version::Feature_Flag)i)) {\n+        return _features_names[i++];\n+      }\n+      i += 1;\n+    }\n+    return (const char*)nullptr;\n+  }, \", \");\n@@ -721,1 +732,1 @@\n-  snprintf(_cpu_name, CPU_TYPE_DESC_BUF_SIZE - 1, \"AArch64\");\n+  os::snprintf_checked(_cpu_name, CPU_TYPE_DESC_BUF_SIZE - 1, \"AArch64\");\n@@ -723,1 +734,1 @@\n-  int desc_len = snprintf(_cpu_desc, CPU_DETAILED_DESC_BUF_SIZE, \"AArch64 \");\n+  int desc_len = os::snprintf(_cpu_desc, CPU_DETAILED_DESC_BUF_SIZE, \"AArch64 \");\n@@ -726,1 +737,1 @@\n-  snprintf(_cpu_desc + desc_len, CPU_DETAILED_DESC_BUF_SIZE - desc_len, \" %s\", _cpu_info_string);\n+  os::snprintf_checked(_cpu_desc + desc_len, CPU_DETAILED_DESC_BUF_SIZE - desc_len, \" %s\", _cpu_info_string);\n","filename":"src\/hotspot\/cpu\/aarch64\/vm_version_aarch64.cpp","additions":53,"deletions":42,"binary":false,"changes":95,"status":"modified"},{"patch":"@@ -33,0 +33,4 @@\n+class stringStream;\n+\n+#define BIT_MASK(flag) (1ULL<<(flag))\n+\n@@ -72,0 +76,2 @@\n+  static void insert_features_names(uint64_t features, stringStream& ss);\n+\n@@ -106,1 +112,1 @@\n-    CPU_QUALCOM   = 'Q',\n+    CPU_QUALCOMM  = 'Q',\n@@ -137,0 +143,1 @@\n+    decl(SB,            sb,            29)    \\\n@@ -144,1 +151,1 @@\n-#define DECLARE_CPU_FEATURE_FLAG(id, name, bit) CPU_##id = (1 << bit),\n+#define DECLARE_CPU_FEATURE_FLAG(id, name, bit) CPU_##id = bit,\n@@ -147,0 +154,1 @@\n+    MAX_CPU_FEATURES\n@@ -149,0 +157,4 @@\n+  STATIC_ASSERT(sizeof(_features) * BitsPerByte >= MAX_CPU_FEATURES);\n+\n+  static const char* _features_names[MAX_CPU_FEATURES];\n+\n@@ -151,1 +163,1 @@\n-  static bool supports_##name() { return (_features & CPU_##id) != 0; };\n+  static bool supports_##name() { return supports_feature(CPU_##id); }\n@@ -155,0 +167,10 @@\n+  static void set_feature(Feature_Flag flag) {\n+    _features |= BIT_MASK(flag);\n+  }\n+  static void clear_feature(Feature_Flag flag) {\n+    _features &= (~BIT_MASK(flag));\n+  }\n+  static bool supports_feature(Feature_Flag flag) {\n+    return (_features & BIT_MASK(flag)) != 0;\n+  }\n+\n@@ -179,1 +201,1 @@\n-  constexpr static bool supports_recursive_lightweight_locking() { return true; }\n+  constexpr static bool supports_recursive_fast_locking() { return true; }\n","filename":"src\/hotspot\/cpu\/aarch64\/vm_version_aarch64.hpp","additions":26,"deletions":4,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -367,2 +367,2 @@\n-  snprintf(_cpu_name, CPU_TYPE_DESC_BUF_SIZE - 1, \"ARM%d\", _arm_arch);\n-  snprintf(_cpu_desc, CPU_DETAILED_DESC_BUF_SIZE, \"%s\", _cpu_info_string);\n+  os::snprintf_checked(_cpu_name, CPU_TYPE_DESC_BUF_SIZE - 1, \"ARM%d\", _arm_arch);\n+  os::snprintf_checked(_cpu_desc, CPU_DETAILED_DESC_BUF_SIZE, \"%s\", _cpu_info_string);\n","filename":"src\/hotspot\/cpu\/arm\/vm_version_arm_32.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -83,1 +83,3 @@\n-  config_dscr();\n+  if (VM_Version::has_mfdscr()) {\n+    config_dscr();\n+  }\n@@ -88,2 +90,4 @@\n-    FLAG_SET_ERGO(TrapBasedNullChecks,       false);\n-    FLAG_SET_ERGO(TrapBasedICMissChecks,     false);\n+    MSG(TrapBasedNMethodEntryBarriers);\n+    FLAG_SET_ERGO(TrapBasedNullChecks,           false);\n+    FLAG_SET_ERGO(TrapBasedICMissChecks,         false);\n+    FLAG_SET_ERGO(TrapBasedNMethodEntryBarriers, false);\n@@ -98,0 +102,4 @@\n+  if (FLAG_IS_DEFAULT(UsePopCountInstruction)) {\n+    FLAG_SET_ERGO(UsePopCountInstruction, true);\n+  }\n+\n@@ -106,0 +114,4 @@\n+  if (!SuperwordUseVSX && FLAG_IS_DEFAULT(EnableVectorSupport)) {\n+    \/\/ VectorSupport intrinsics currently have issues with MaxVectorSize < 16 (JDK-8370803).\n+    FLAG_SET_ERGO(EnableVectorSupport, false);\n+  }\n@@ -173,1 +185,2 @@\n-               \"ppc64 sha aes%s%s\",\n+               \"ppc64 sha aes%s%s%s\",\n+               (has_mfdscr()  ? \" mfdscr\"  : \"\"),\n@@ -493,0 +506,1 @@\n+  a->mfdscr(R0);\n@@ -529,0 +543,1 @@\n+  if (code[feature_cntr++]) features |= mfdscr_m;\n@@ -625,2 +640,2 @@\n-  snprintf(_cpu_name, CPU_TYPE_DESC_BUF_SIZE, \"PowerPC POWER%lu\", PowerArchitecturePPC64);\n-  snprintf(_cpu_desc, CPU_DETAILED_DESC_BUF_SIZE, \"PPC %s\", cpu_info_string());\n+  os::snprintf_checked(_cpu_name, CPU_TYPE_DESC_BUF_SIZE, \"PowerPC POWER%lu\", PowerArchitecturePPC64);\n+  os::snprintf_checked(_cpu_desc, CPU_DETAILED_DESC_BUF_SIZE, \"PPC %s\", cpu_info_string());\n","filename":"src\/hotspot\/cpu\/ppc\/vm_version_ppc.cpp","additions":21,"deletions":6,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+    mfdscr,\n@@ -41,0 +42,1 @@\n+    mfdscr_m              = (1 << mfdscr ),\n@@ -66,1 +68,1 @@\n-  constexpr static bool supports_recursive_lightweight_locking() { return true; }\n+  constexpr static bool supports_recursive_fast_locking() { return true; }\n@@ -73,2 +75,3 @@\n-  static bool has_darn()    { return (_features & darn_m) != 0; }\n-  static bool has_brw()     { return (_features & brw_m) != 0; }\n+  static bool has_mfdscr() { return (_features & mfdscr_m) != 0; } \/\/ Power8, but may be unavailable (QEMU)\n+  static bool has_darn()   { return (_features & darn_m) != 0; }\n+  static bool has_brw()    { return (_features & brw_m) != 0; }\n","filename":"src\/hotspot\/cpu\/ppc\/vm_version_ppc.hpp","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -38,8 +38,17 @@\n-#define DEF_RV_FEATURE(NAME, PRETTY, BIT, FSTRING, FLAGF)       \\\n-VM_Version::NAME##RVFeatureValue VM_Version::NAME(PRETTY, BIT, FSTRING);\n-RV_FEATURE_FLAGS(DEF_RV_FEATURE)\n-\n-#define ADD_RV_FEATURE_IN_LIST(NAME, PRETTY, BIT, FSTRING, FLAGF) \\\n-    &VM_Version::NAME,\n-VM_Version::RVFeatureValue* VM_Version::_feature_list[] = {\n-RV_FEATURE_FLAGS(ADD_RV_FEATURE_IN_LIST)\n+#define DEF_RV_EXT_FEATURE(PRETTY, LINUX_BIT, FSTRING, FLAGF) \\\n+VM_Version::ext_##PRETTY##RVExtFeatureValue VM_Version::ext_##PRETTY;\n+RV_EXT_FEATURE_FLAGS(DEF_RV_EXT_FEATURE)\n+#undef DEF_RV_EXT_FEATURE\n+\n+#define DEF_RV_NON_EXT_FEATURE(PRETTY, LINUX_BIT, FSTRING, FLAGF) \\\n+VM_Version::PRETTY##RVNonExtFeatureValue VM_Version::PRETTY;\n+RV_NON_EXT_FEATURE_FLAGS(DEF_RV_NON_EXT_FEATURE)\n+#undef DEF_RV_NON_EXT_FEATURE\n+\n+#define ADD_RV_EXT_FEATURE_IN_LIST(PRETTY, LINUX_BIT, FSTRING, FLAGF) \\\n+     &VM_Version::ext_##PRETTY,\n+#define ADD_RV_NON_EXT_FEATURE_IN_LIST(PRETTY, LINUX_BIT, FSTRING, FLAGF) \\\n+     &VM_Version::PRETTY,\n+ VM_Version::RVFeatureValue* VM_Version::_feature_list[] = {\n+ RV_EXT_FEATURE_FLAGS(ADD_RV_EXT_FEATURE_IN_LIST)\n+ RV_NON_EXT_FEATURE_FLAGS(ADD_RV_NON_EXT_FEATURE_IN_LIST)\n@@ -47,0 +56,4 @@\n+#undef ADD_RV_NON_EXT_FEATURE_IN_LIST\n+#undef ADD_RV_EXT_FEATURE_IN_LIST\n+\n+VM_Version::RVExtFeatures* VM_Version::_rv_ext_features = new VM_Version::RVExtFeatures();\n@@ -95,11 +108,0 @@\n-  \/\/ Enable vendor specific features\n-\n-  if (mvendorid.enabled()) {\n-    \/\/ Rivos\n-    if (mvendorid.value() == RIVOS) {\n-      if (FLAG_IS_DEFAULT(UseConservativeFence)) {\n-        FLAG_SET_DEFAULT(UseConservativeFence, false);\n-      }\n-    }\n-  }\n-\n@@ -140,1 +142,1 @@\n-  if (UseRVC && !ext_C.enabled()) {\n+  if (UseRVC && !ext_c.enabled()) {\n@@ -152,1 +154,1 @@\n-      unaligned_access.value() != MISALIGNED_FAST);\n+      unaligned_scalar.value() != MISALIGNED_SCALAR_FAST);\n@@ -167,1 +169,1 @@\n-      unaligned_access.value() == MISALIGNED_FAST);\n+      (unaligned_scalar.value() == MISALIGNED_SCALAR_FAST));\n@@ -186,1 +188,2 @@\n-  if (UseZicboz) {\n+  if (UseZicboz && zicboz_block_size.value() > 0) {\n+    assert(is_power_of_2(zicboz_block_size.value()), \"Sanity\");\n@@ -191,1 +194,1 @@\n-      FLAG_SET_DEFAULT(BlockZeroingLowLimit, 2 * CacheLineSize);\n+      FLAG_SET_DEFAULT(BlockZeroingLowLimit, 4 * zicboz_block_size.value());\n@@ -199,7 +202,2 @@\n-    if (!ext_V.enabled() && FLAG_IS_DEFAULT(UseRVV)) {\n-      warning(\"RVV is not supported on this CPU\");\n-      FLAG_SET_DEFAULT(UseRVV, false);\n-    } else {\n-      \/\/ read vector length from vector CSR vlenb\n-      _initial_vector_length = cpu_vector_length();\n-    }\n+    \/\/ read vector length from vector CSR vlenb\n+    _initial_vector_length = cpu_vector_length();\n@@ -208,1 +206,1 @@\n-  \/\/ Misc Intrinsics could depend on RVV\n+  \/\/ Misc Intrinsics that could depend on RVV.\n@@ -210,1 +208,1 @@\n-  if (UseZba || UseRVV) {\n+  if (!AvoidUnalignedAccesses && (UseZba || UseRVV)) {\n@@ -216,1 +214,1 @@\n-      warning(\"CRC32 intrinsic requires Zba or RVV instructions (not available on this CPU)\");\n+      warning(\"CRC32 intrinsic are not available on this CPU.\");\n@@ -225,30 +223,0 @@\n-\n-  \/\/ UseZvbb (depends on RVV).\n-  if (UseZvbb && !UseRVV) {\n-    warning(\"Cannot enable UseZvbb on cpu without RVV support.\");\n-    FLAG_SET_DEFAULT(UseZvbb, false);\n-  }\n-\n-  \/\/ UseZvbc (depends on RVV).\n-  if (UseZvbc && !UseRVV) {\n-    warning(\"Cannot enable UseZvbc on cpu without RVV support.\");\n-    FLAG_SET_DEFAULT(UseZvbc, false);\n-  }\n-\n-  \/\/ UseZvkn (depends on RVV).\n-  if (UseZvkn && !UseRVV) {\n-    warning(\"Cannot enable UseZvkn on cpu without RVV support.\");\n-    FLAG_SET_DEFAULT(UseZvkn, false);\n-  }\n-\n-  \/\/ UseZvfh (depends on RVV)\n-  if (UseZvfh) {\n-    if (!UseRVV) {\n-      warning(\"Cannot enable UseZvfh on cpu without RVV support.\");\n-      FLAG_SET_DEFAULT(UseZvfh, false);\n-    }\n-    if (!UseZfh) {\n-      warning(\"Cannot enable UseZvfh on cpu without Zfh support.\");\n-      FLAG_SET_DEFAULT(UseZvfh, false);\n-    }\n-  }\n@@ -274,0 +242,5 @@\n+  if (FLAG_IS_DEFAULT(AlignVector)) {\n+    FLAG_SET_DEFAULT(AlignVector,\n+      unaligned_vector.value() != MISALIGNED_VECTOR_FAST);\n+  }\n+\n@@ -330,2 +303,7 @@\n-  if (FLAG_IS_DEFAULT(UseMultiplyToLenIntrinsic)) {\n-    FLAG_SET_DEFAULT(UseMultiplyToLenIntrinsic, true);\n+  if (!AvoidUnalignedAccesses) {\n+    if (FLAG_IS_DEFAULT(UseMultiplyToLenIntrinsic)) {\n+      FLAG_SET_DEFAULT(UseMultiplyToLenIntrinsic, true);\n+    }\n+  } else if (UseMultiplyToLenIntrinsic) {\n+    warning(\"Intrinsics for BigInteger.multiplyToLen() not available on this CPU.\");\n+    FLAG_SET_DEFAULT(UseMultiplyToLenIntrinsic, false);\n@@ -334,2 +312,7 @@\n-  if (FLAG_IS_DEFAULT(UseSquareToLenIntrinsic)) {\n-    FLAG_SET_DEFAULT(UseSquareToLenIntrinsic, true);\n+  if (!AvoidUnalignedAccesses) {\n+    if (FLAG_IS_DEFAULT(UseSquareToLenIntrinsic)) {\n+      FLAG_SET_DEFAULT(UseSquareToLenIntrinsic, true);\n+    }\n+  } else if (UseSquareToLenIntrinsic) {\n+    warning(\"Intrinsics for BigInteger.squareToLen() not available on this CPU.\");\n+    FLAG_SET_DEFAULT(UseSquareToLenIntrinsic, false);\n@@ -338,2 +321,7 @@\n-  if (FLAG_IS_DEFAULT(UseMontgomeryMultiplyIntrinsic)) {\n-    FLAG_SET_DEFAULT(UseMontgomeryMultiplyIntrinsic, true);\n+  if (!AvoidUnalignedAccesses) {\n+    if (FLAG_IS_DEFAULT(UseMontgomeryMultiplyIntrinsic)) {\n+      FLAG_SET_DEFAULT(UseMontgomeryMultiplyIntrinsic, true);\n+    }\n+  } else if (UseMontgomeryMultiplyIntrinsic) {\n+    warning(\"Intrinsics for BigInteger.montgomeryMultiply() not available on this CPU.\");\n+    FLAG_SET_DEFAULT(UseMontgomeryMultiplyIntrinsic, false);\n@@ -342,2 +330,7 @@\n-  if (FLAG_IS_DEFAULT(UseMontgomerySquareIntrinsic)) {\n-    FLAG_SET_DEFAULT(UseMontgomerySquareIntrinsic, true);\n+  if (!AvoidUnalignedAccesses) {\n+    if (FLAG_IS_DEFAULT(UseMontgomerySquareIntrinsic)) {\n+      FLAG_SET_DEFAULT(UseMontgomerySquareIntrinsic, true);\n+    }\n+  } else if (UseMontgomerySquareIntrinsic) {\n+    warning(\"Intrinsics for BigInteger.montgomerySquare() not available on this CPU.\");\n+    FLAG_SET_DEFAULT(UseMontgomerySquareIntrinsic, false);\n@@ -446,0 +439,9 @@\n+\n+    if (FLAG_IS_DEFAULT(UseAESCTRIntrinsics) && UseZbb) {\n+      FLAG_SET_DEFAULT(UseAESCTRIntrinsics, true);\n+    }\n+\n+    if (UseAESCTRIntrinsics && !UseZbb) {\n+      warning(\"Cannot enable UseAESCTRIntrinsics on cpu without UseZbb support.\");\n+      FLAG_SET_DEFAULT(UseAESCTRIntrinsics, false);\n+    }\n@@ -455,0 +457,4 @@\n+    if (UseAESCTRIntrinsics) {\n+      warning(\"Cannot enable UseAESCTRIntrinsics on cpu without UseZvkn support.\");\n+      FLAG_SET_DEFAULT(UseAESCTRIntrinsics, false);\n+    }\n@@ -457,4 +463,4 @@\n-  if (UseAESCTRIntrinsics) {\n-    warning(\"AES\/CTR intrinsics are not available on this CPU\");\n-    FLAG_SET_DEFAULT(UseAESCTRIntrinsics, false);\n-  }\n+  if (UseZvkg) {\n+    if (FLAG_IS_DEFAULT(UseGHASHIntrinsics) && UseZvbb) {\n+      FLAG_SET_DEFAULT(UseGHASHIntrinsics, true);\n+    }\n@@ -462,2 +468,9 @@\n-  if (FLAG_IS_DEFAULT(AlignVector)) {\n-    FLAG_SET_DEFAULT(AlignVector, AvoidUnalignedAccesses);\n+    if (UseGHASHIntrinsics && !UseZvbb) {\n+      warning(\"Cannot enable UseGHASHIntrinsics on cpu without UseZvbb support\");\n+      FLAG_SET_DEFAULT(UseGHASHIntrinsics, false);\n+    }\n+  } else {\n+    if (UseGHASHIntrinsics) {\n+      warning(\"Cannot enable UseGHASHIntrinsics on cpu without UseZvkg support\");\n+      FLAG_SET_DEFAULT(UseGHASHIntrinsics, false);\n+    }\n@@ -478,2 +491,2 @@\n-  snprintf(_cpu_name, CPU_TYPE_DESC_BUF_SIZE - 1, \"RISCV64\");\n-  snprintf(_cpu_desc, CPU_DETAILED_DESC_BUF_SIZE, \"RISCV64 %s\", cpu_info_string());\n+  os::snprintf_checked(_cpu_name, CPU_TYPE_DESC_BUF_SIZE - 1, \"RISCV64\");\n+  os::snprintf_checked(_cpu_desc, CPU_DETAILED_DESC_BUF_SIZE, \"RISCV64 %s\", cpu_info_string());\n","filename":"src\/hotspot\/cpu\/riscv\/vm_version_riscv.cpp","additions":93,"deletions":80,"binary":false,"changes":173,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -49,0 +49,2 @@\n+  class RVExtFeatures;\n+\n@@ -52,3 +54,2 @@\n-    const uint64_t    _feature_bit;\n-    bool              _enabled;\n-    int64_t           _value;\n+    const uint64_t    _linux_feature_bit;\n+\n@@ -56,11 +57,2 @@\n-    RVFeatureValue(const char* pretty, int bit_num, bool fstring) :\n-      _pretty(pretty), _feature_string(fstring), _feature_bit(nth_bit(bit_num)),\n-      _enabled(false), _value(-1) {\n-    }\n-    void enable_feature(int64_t value = 0) {\n-      _enabled = true;\n-      _value = value;\n-    }\n-    void disable_feature() {\n-      _enabled = false;\n-      _value = -1;\n+    RVFeatureValue(const char* pretty, int linux_bit_num, bool fstring) :\n+      _pretty(pretty), _feature_string(fstring), _linux_feature_bit(nth_bit(linux_bit_num)) {\n@@ -68,0 +60,2 @@\n+    virtual void enable_feature(int64_t value = 0) = 0;\n+    virtual void disable_feature() = 0;\n@@ -69,1 +63,1 @@\n-    uint64_t feature_bit()       { return _feature_bit; }\n+    uint64_t feature_bit()       { return _linux_feature_bit; }\n@@ -71,2 +65,1 @@\n-    bool enabled()               { return _enabled; }\n-    int64_t value()              { return _value; }\n+    virtual bool enabled() = 0;\n@@ -74,0 +67,1 @@\n+    virtual void log_enabled() = 0;\n@@ -89,19 +83,31 @@\n-  #define UPDATE_DEFAULT_DEP(flag, dep)    \\\n-  void update_flag() {                     \\\n-      assert(enabled(), \"Must be.\");       \\\n-      \/* dep must be declared before *\/    \\\n-      assert((uintptr_t)(this) >           \\\n-             (uintptr_t)(&dep), \"Invalid\");\\\n-      if (FLAG_IS_DEFAULT(flag)) {         \\\n-        if (dep.enabled()) {               \\\n-          FLAG_SET_DEFAULT(flag, true);    \\\n-        } else {                           \\\n-          FLAG_SET_DEFAULT(flag, false);   \\\n-        }                                  \\\n-      } else {                             \\\n-        \/* Sync CPU features with flags *\/ \\\n-        if (!flag) {                       \\\n-          disable_feature();               \\\n-        }                                  \\\n-      }                                    \\\n-  }                                        \\\n+  #define UPDATE_DEFAULT_DEP(flag, dep0, ...)                                                               \\\n+  void update_flag() {                                                                                      \\\n+      assert(enabled(), \"Must be.\");                                                                        \\\n+      DEBUG_ONLY(verify_deps(dep0, ##__VA_ARGS__));                                                         \\\n+      if (FLAG_IS_DEFAULT(flag)) {                                                                          \\\n+        if (deps_all_enabled(dep0, ##__VA_ARGS__)) {                                                        \\\n+          FLAG_SET_DEFAULT(flag, true);                                                                     \\\n+        } else {                                                                                            \\\n+          FLAG_SET_DEFAULT(flag, false);                                                                    \\\n+          \/* Sync CPU features with flags *\/                                                                \\\n+          disable_feature();                                                                                \\\n+          stringStream ss;                                                                                  \\\n+          ss.print(\"missing dependent extension(s): \");                                                     \\\n+          deps_string(ss, dep0, ##__VA_ARGS__);                                                             \\\n+          log_disabled(ss.as_string(true));                                                                 \\\n+        }                                                                                                   \\\n+      } else {                                                                                              \\\n+        \/* Sync CPU features with flags *\/                                                                  \\\n+        if (!flag) {                                                                                        \\\n+          disable_feature();                                                                                \\\n+        } else if (!deps_all_enabled(dep0, ##__VA_ARGS__)) {                                                \\\n+          FLAG_SET_DEFAULT(flag, false);                                                                    \\\n+          \/* Sync CPU features with flags *\/                                                                \\\n+          disable_feature();                                                                                \\\n+          stringStream ss;                                                                                  \\\n+          ss.print(\"missing dependent extension(s): \");                                                     \\\n+          deps_string(ss, dep0, ##__VA_ARGS__);                                                             \\\n+          log_disabled(ss.as_string(true));                                                                 \\\n+        }                                                                                                   \\\n+      }                                                                                                     \\\n+  }                                                                                                         \\\n@@ -112,44 +118,95 @@\n-  \/\/ Frozen standard extensions\n-  \/\/ I RV64I\n-  \/\/ M Integer Multiplication and Division\n-  \/\/ A Atomic Instructions\n-  \/\/ F Single-Precision Floating-Point\n-  \/\/ D Single-Precision Floating-Point\n-  \/\/ (G = M + A + F + D)\n-  \/\/ Q Quad-Precision Floating-Point\n-  \/\/ C Compressed Instructions\n-  \/\/ H Hypervisor\n-  \/\/\n-  \/\/ Others, open and non-standard\n-  \/\/ V Vector\n-  \/\/\n-  \/\/ Cache Management Operations\n-  \/\/ Zicbom Cache Block Management Operations\n-  \/\/ Zicboz Cache Block Zero Operations\n-  \/\/ Zicbop Cache Block Prefetch Operations\n-  \/\/\n-  \/\/ Bit-manipulation\n-  \/\/ Zba Address generation instructions\n-  \/\/ Zbb Basic bit-manipulation\n-  \/\/ Zbc Carry-less multiplication\n-  \/\/ Zbs Single-bit instructions\n-  \/\/\n-  \/\/ Zfh Half-Precision Floating-Point instructions\n-  \/\/ Zfhmin Minimal Half-Precision Floating-Point instructions\n-  \/\/\n-  \/\/ Zicond Conditional operations\n-  \/\/\n-  \/\/ Zicsr Control and Status Register (CSR) Instructions\n-  \/\/ Zifencei Instruction-Fetch Fence\n-  \/\/ Zic64b Cache blocks must be 64 bytes in size, naturally aligned in the address space.\n-  \/\/ Zihintpause Pause instruction HINT\n-  \/\/\n-  \/\/ Zc  Code Size Reduction - Additional compressed instructions.\n-  \/\/ Zcb Simple code-size saving instructions\n-  \/\/\n-  \/\/ Other features and settings\n-  \/\/ mvendorid Manufactory JEDEC id encoded, ISA vol 2 3.1.2..\n-  \/\/ marchid   Id for microarch. Mvendorid plus marchid uniquely identify the microarch.\n-  \/\/ mimpid    A unique encoding of the version of the processor implementation.\n-  \/\/ unaligned_access Unaligned memory accesses (unknown, unspported, emulated, slow, firmware, fast)\n-  \/\/ satp mode SATP bits (number of virtual addr bits) mbare, sv39, sv48, sv57, sv64\n+\n+  class RVExtFeatureValue : public RVFeatureValue {\n+    const uint32_t _cpu_feature_index;\n+\n+   public:\n+    RVExtFeatureValue(const char* pretty, int linux_bit_num, uint32_t cpu_feature_index, bool fstring) :\n+      RVFeatureValue(pretty, linux_bit_num, fstring),\n+      _cpu_feature_index(cpu_feature_index) {\n+    }\n+    int cpu_feature_index() {\n+      \/\/ Can be used to check, for example, v is declared before Zvfh in RV_EXT_FEATURE_FLAGS.\n+      return _cpu_feature_index;\n+    }\n+    bool enabled() {\n+      return RVExtFeatures::current()->support_feature(_cpu_feature_index);\n+    }\n+    void enable_feature(int64_t value = 0) {\n+      RVExtFeatures::current()->set_feature(_cpu_feature_index);\n+    }\n+    void disable_feature() {\n+      RVExtFeatures::current()->clear_feature(_cpu_feature_index);\n+    }\n+    void log_enabled();\n+    void log_disabled(const char* reason);\n+\n+   protected:\n+    bool deps_all_enabled(RVExtFeatureValue* dep0, ...) {\n+      assert(dep0 != nullptr, \"must not\");\n+\n+      va_list va;\n+      va_start(va, dep0);\n+      RVExtFeatureValue* next = dep0;\n+      bool enabled = true;\n+      while (next != nullptr && enabled) {\n+        enabled = next->enabled();\n+        next = va_arg(va, RVExtFeatureValue*);\n+      }\n+      va_end(va);\n+      return enabled;\n+    }\n+\n+    void deps_string(stringStream& ss, RVExtFeatureValue* dep0, ...) {\n+      assert(dep0 != nullptr, \"must not\");\n+      ss.print(\"%s (%s)\", dep0->pretty(), dep0->enabled() ? \"enabled\" : \"disabled\");\n+\n+      va_list va;\n+      va_start(va, dep0);\n+      RVExtFeatureValue* next = nullptr;\n+      while ((next = va_arg(va, RVExtFeatureValue*)) != nullptr) {\n+        ss.print(\", %s (%s)\", next->pretty(), next->enabled() ? \"enabled\" : \"disabled\");\n+      }\n+      va_end(va);\n+    }\n+\n+#ifdef ASSERT\n+    void verify_deps(RVExtFeatureValue* dep0, ...) {\n+      assert(dep0 != nullptr, \"must not\");\n+      assert(cpu_feature_index() >= 0, \"must\");\n+\n+      va_list va;\n+      va_start(va, dep0);\n+      RVExtFeatureValue* next = dep0;\n+      while (next != nullptr) {\n+        assert(next->cpu_feature_index() >= 0, \"must\");\n+        \/\/ We only need to check depenency relationship for extension flags.\n+        \/\/ The dependant ones must be declared before this, for example, v must be declared\n+        \/\/ before Zvfh in RV_EXT_FEATURE_FLAGS. The reason is in setup_cpu_available_features\n+        \/\/ we need to make sure v is `update_flag`ed before Zvfh, so Zvfh is `update_flag`ed\n+        \/\/ based on v.\n+        assert(cpu_feature_index() > next->cpu_feature_index(), \"Invalid\");\n+        next = va_arg(va, RVExtFeatureValue*);\n+      }\n+      va_end(va);\n+    }\n+#endif \/\/ ASSERT\n+  };\n+\n+  class RVNonExtFeatureValue : public RVFeatureValue {\n+    static const int64_t DEFAULT_VALUE = -1;\n+    int64_t _value;\n+\n+   public:\n+    RVNonExtFeatureValue(const char* pretty, int linux_bit_num, bool fstring) :\n+      RVFeatureValue(pretty, linux_bit_num, fstring),\n+      _value(DEFAULT_VALUE) {\n+    }\n+    bool enabled() { return _value != DEFAULT_VALUE; }\n+    void enable_feature(int64_t value) {\n+      assert(value != DEFAULT_VALUE, \"Sanity\");\n+      _value = value;\n+    }\n+    void disable_feature() { _value = DEFAULT_VALUE; }\n+    int64_t value() { return _value; }\n+    void log_enabled();\n+  };\n@@ -162,51 +219,179 @@\n-  \/\/ declaration name  , extension name, bit pos       ,in str, mapped flag)\n-  #define RV_FEATURE_FLAGS(decl)                                                                    \\\n-  decl(ext_I           , \"i\"           ,    ('I' - 'A'), true , NO_UPDATE_DEFAULT)                  \\\n-  decl(ext_M           , \"m\"           ,    ('M' - 'A'), true , NO_UPDATE_DEFAULT)                  \\\n-  decl(ext_A           , \"a\"           ,    ('A' - 'A'), true , NO_UPDATE_DEFAULT)                  \\\n-  decl(ext_F           , \"f\"           ,    ('F' - 'A'), true , NO_UPDATE_DEFAULT)                  \\\n-  decl(ext_D           , \"d\"           ,    ('D' - 'A'), true , NO_UPDATE_DEFAULT)                  \\\n-  decl(ext_C           , \"c\"           ,    ('C' - 'A'), true , UPDATE_DEFAULT(UseRVC))             \\\n-  decl(ext_Q           , \"q\"           ,    ('Q' - 'A'), true , NO_UPDATE_DEFAULT)                  \\\n-  decl(ext_H           , \"h\"           ,    ('H' - 'A'), true , NO_UPDATE_DEFAULT)                  \\\n-  decl(ext_V           , \"v\"           ,    ('V' - 'A'), true , UPDATE_DEFAULT(UseRVV))             \\\n-  decl(ext_Zicbom      , \"Zicbom\"      , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZicbom))          \\\n-  decl(ext_Zicboz      , \"Zicboz\"      , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZicboz))          \\\n-  decl(ext_Zicbop      , \"Zicbop\"      , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZicbop))          \\\n-  decl(ext_Zba         , \"Zba\"         , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZba))             \\\n-  decl(ext_Zbb         , \"Zbb\"         , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZbb))             \\\n-  decl(ext_Zbc         , \"Zbc\"         , RV_NO_FLAG_BIT, true , NO_UPDATE_DEFAULT)                  \\\n-  decl(ext_Zbs         , \"Zbs\"         , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZbs))             \\\n-  decl(ext_Zbkb        , \"Zbkb\"        , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZbkb))            \\\n-  decl(ext_Zcb         , \"Zcb\"         , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZcb))             \\\n-  decl(ext_Zfa         , \"Zfa\"         , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZfa))             \\\n-  decl(ext_Zfh         , \"Zfh\"         , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZfh))             \\\n-  decl(ext_Zfhmin      , \"Zfhmin\"      , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZfhmin))          \\\n-  decl(ext_Zicsr       , \"Zicsr\"       , RV_NO_FLAG_BIT, true , NO_UPDATE_DEFAULT)                  \\\n-  decl(ext_Zicntr      , \"Zicntr\"      , RV_NO_FLAG_BIT, true , NO_UPDATE_DEFAULT)                  \\\n-  decl(ext_Zifencei    , \"Zifencei\"    , RV_NO_FLAG_BIT, true , NO_UPDATE_DEFAULT)                  \\\n-  decl(ext_Zic64b      , \"Zic64b\"      , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZic64b))          \\\n-  decl(ext_Ztso        , \"Ztso\"        , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZtso))            \\\n-  decl(ext_Zihintpause , \"Zihintpause\" , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZihintpause))     \\\n-  decl(ext_Zacas       , \"Zacas\"       , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZacas))           \\\n-  decl(ext_Zvbb        , \"Zvbb\"        , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT_DEP(UseZvbb, ext_V)) \\\n-  decl(ext_Zvbc        , \"Zvbc\"        , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT_DEP(UseZvbc, ext_V)) \\\n-  decl(ext_Zvfh        , \"Zvfh\"        , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT_DEP(UseZvfh, ext_V)) \\\n-  decl(ext_Zvkn        , \"Zvkn\"        , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT_DEP(UseZvkn, ext_V)) \\\n-  decl(ext_Zicond      , \"Zicond\"      , RV_NO_FLAG_BIT, true , UPDATE_DEFAULT(UseZicond))          \\\n-  decl(mvendorid       , \"VendorId\"    , RV_NO_FLAG_BIT, false, NO_UPDATE_DEFAULT)                  \\\n-  decl(marchid         , \"ArchId\"      , RV_NO_FLAG_BIT, false, NO_UPDATE_DEFAULT)                  \\\n-  decl(mimpid          , \"ImpId\"       , RV_NO_FLAG_BIT, false, NO_UPDATE_DEFAULT)                  \\\n-  decl(unaligned_access, \"Unaligned\"   , RV_NO_FLAG_BIT, false, NO_UPDATE_DEFAULT)                  \\\n-  decl(satp_mode       , \"SATP\"        , RV_NO_FLAG_BIT, false, NO_UPDATE_DEFAULT)                  \\\n-\n-  #define DECLARE_RV_FEATURE(NAME, PRETTY, BIT, FSTRING, FLAGF)        \\\n-  struct NAME##RVFeatureValue : public RVFeatureValue {                \\\n-    NAME##RVFeatureValue(const char* pretty, int bit, bool fstring) :  \\\n-      RVFeatureValue(pretty, bit, fstring) {}                          \\\n-    FLAGF;                                                             \\\n-  };                                                                   \\\n-  static NAME##RVFeatureValue NAME;                                    \\\n-\n-  RV_FEATURE_FLAGS(DECLARE_RV_FEATURE)\n-  #undef DECLARE_RV_FEATURE\n+  \/\/\n+  \/\/ Fields description in `decl`:\n+  \/\/    declaration name, extension name, bit value from linux, feature string?, mapped flag)\n+  #define RV_EXT_FEATURE_FLAGS(decl)                                                                   \\\n+  \/* A Atomic Instructions *\/                                                                          \\\n+  decl(a           ,     ('A' - 'A'),  true ,  NO_UPDATE_DEFAULT)                                      \\\n+  \/* C Compressed Instructions *\/                                                                      \\\n+  decl(c           ,     ('C' - 'A'),  true ,  UPDATE_DEFAULT(UseRVC))                                 \\\n+  \/* D Single-Precision Floating-Point *\/                                                              \\\n+  decl(d           ,     ('D' - 'A'),  true ,  NO_UPDATE_DEFAULT)                                      \\\n+  \/* F Single-Precision Floating-Point *\/                                                              \\\n+  decl(f           ,     ('F' - 'A'),  true ,  NO_UPDATE_DEFAULT)                                      \\\n+  \/* H Hypervisor *\/                                                                                   \\\n+  decl(h           ,     ('H' - 'A'),  true ,  NO_UPDATE_DEFAULT)                                      \\\n+  \/* I RV64I *\/                                                                                        \\\n+  decl(i           ,     ('I' - 'A'),  true ,  NO_UPDATE_DEFAULT)                                      \\\n+  \/* M Integer Multiplication and Division *\/                                                          \\\n+  decl(m           ,     ('M' - 'A'),  true ,  NO_UPDATE_DEFAULT)                                      \\\n+  \/* Q Quad-Precision Floating-Point *\/                                                                \\\n+  decl(q           ,     ('Q' - 'A'),  true ,  NO_UPDATE_DEFAULT)                                      \\\n+  \/* V Vector *\/                                                                                       \\\n+  decl(v           ,     ('V' - 'A'),  true ,  UPDATE_DEFAULT(UseRVV))                                 \\\n+                                                                                                       \\\n+  \/* ----------------------- Other extensions ----------------------- *\/                               \\\n+                                                                                                       \\\n+  \/* Atomic compare-and-swap (CAS) instructions *\/                                                     \\\n+  decl(Zacas       ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT(UseZacas))                               \\\n+  \/* Zba Address generation instructions *\/                                                            \\\n+  decl(Zba         ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT(UseZba))                                 \\\n+  \/* Zbb Basic bit-manipulation *\/                                                                     \\\n+  decl(Zbb         ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT(UseZbb))                                 \\\n+  \/* Zbc Carry-less multiplication *\/                                                                  \\\n+  decl(Zbc         ,  RV_NO_FLAG_BIT,  true ,  NO_UPDATE_DEFAULT)                                      \\\n+  \/* Bitmanip instructions for Cryptography *\/                                                         \\\n+  decl(Zbkb        ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT(UseZbkb))                                \\\n+  \/* Zbs Single-bit instructions *\/                                                                    \\\n+  decl(Zbs         ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT(UseZbs))                                 \\\n+  \/* Zcb Simple code-size saving instructions *\/                                                       \\\n+  decl(Zcb         ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT(UseZcb))                                 \\\n+  \/* Additional Floating-Point instructions *\/                                                         \\\n+  decl(Zfa         ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT(UseZfa))                                 \\\n+  \/* Zfh Half-Precision Floating-Point instructions *\/                                                 \\\n+  decl(Zfh         ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT(UseZfh))                                 \\\n+  \/* Zfhmin Minimal Half-Precision Floating-Point instructions *\/                                      \\\n+  decl(Zfhmin      ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT(UseZfhmin))                              \\\n+  \/* Zicbom Cache Block Management Operations *\/                                                       \\\n+  decl(Zicbom      ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT(UseZicbom))                              \\\n+  \/* Zicbop Cache Block Prefetch Operations *\/                                                         \\\n+  decl(Zicbop      ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT(UseZicbop))                              \\\n+  \/* Zicboz Cache Block Zero Operations *\/                                                             \\\n+  decl(Zicboz      ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT(UseZicboz))                              \\\n+  \/* Base Counters and Timers *\/                                                                       \\\n+  decl(Zicntr      ,  RV_NO_FLAG_BIT,  true ,  NO_UPDATE_DEFAULT)                                      \\\n+  \/* Zicond Conditional operations *\/                                                                  \\\n+  decl(Zicond      ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT(UseZicond))                              \\\n+  \/* Zicsr Control and Status Register (CSR) Instructions *\/                                           \\\n+  decl(Zicsr       ,  RV_NO_FLAG_BIT,  true ,  NO_UPDATE_DEFAULT)                                      \\\n+  \/* Zic64b Cache blocks must be 64 bytes in size, naturally aligned in the address space. *\/          \\\n+  decl(Zic64b      ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT(UseZic64b))                              \\\n+  \/* Zifencei Instruction-Fetch Fence *\/                                                               \\\n+  decl(Zifencei    ,  RV_NO_FLAG_BIT,  true ,  NO_UPDATE_DEFAULT)                                      \\\n+  \/* Zihintpause Pause instruction HINT *\/                                                             \\\n+  decl(Zihintpause ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT(UseZihintpause))                         \\\n+  \/* Total Store Ordering *\/                                                                           \\\n+  decl(Ztso        ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT(UseZtso))                                \\\n+  \/* Vector Basic Bit-manipulation *\/                                                                  \\\n+  decl(Zvbb        ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT_DEP(UseZvbb, &ext_v, nullptr))           \\\n+  \/* Vector Carryless Multiplication *\/                                                                \\\n+  decl(Zvbc        ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT_DEP(UseZvbc, &ext_v, nullptr))           \\\n+  \/* Vector Extension for Half-Precision Floating-Point *\/                                             \\\n+  decl(Zvfh        ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT_DEP(UseZvfh, &ext_v, &ext_Zfh, nullptr)) \\\n+  \/* Shorthand for Zvkned + Zvknhb + Zvkb + Zvkt *\/                                                    \\\n+  decl(Zvkn        ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT_DEP(UseZvkn, &ext_v, nullptr))           \\\n+  \/* Zvkg crypto extension for ghash and gcm *\/                                                        \\\n+  decl(Zvkg        ,  RV_NO_FLAG_BIT,  true ,  UPDATE_DEFAULT_DEP(UseZvkg, &ext_v, nullptr))           \\\n+\n+  #define DECLARE_RV_EXT_FEATURE(PRETTY, LINUX_BIT, FSTRING, FLAGF)                             \\\n+  struct ext_##PRETTY##RVExtFeatureValue : public RVExtFeatureValue {                           \\\n+    ext_##PRETTY##RVExtFeatureValue() :                                                         \\\n+      RVExtFeatureValue(#PRETTY, LINUX_BIT, RVExtFeatures::CPU_##ext_##PRETTY, FSTRING) {}      \\\n+    FLAGF;                                                                                      \\\n+  };                                                                                            \\\n+  static ext_##PRETTY##RVExtFeatureValue ext_##PRETTY;                                          \\\n+\n+  RV_EXT_FEATURE_FLAGS(DECLARE_RV_EXT_FEATURE)\n+  #undef DECLARE_RV_EXT_FEATURE\n+\n+  \/\/ Non-extension features\n+  \/\/\n+  #define RV_NON_EXT_FEATURE_FLAGS(decl)                                                       \\\n+  \/* Id for microarch. Mvendorid plus marchid uniquely identify the microarch. *\/              \\\n+  decl(marchid           ,  RV_NO_FLAG_BIT,  false,  NO_UPDATE_DEFAULT)                        \\\n+  \/* A unique encoding of the version of the processor implementation. *\/                      \\\n+  decl(mimpid            ,  RV_NO_FLAG_BIT,  false,  NO_UPDATE_DEFAULT)                        \\\n+  \/* Manufactory JEDEC id encoded, ISA vol 2 3.1.2.. *\/                                        \\\n+  decl(mvendorid         ,  RV_NO_FLAG_BIT,  false,  NO_UPDATE_DEFAULT)                        \\\n+  \/* SATP bits (number of virtual addr bits) mbare, sv39, sv48, sv57, sv64 *\/                  \\\n+  decl(satp_mode         ,  RV_NO_FLAG_BIT,  false,  NO_UPDATE_DEFAULT)                        \\\n+  \/* Performance of misaligned scalar accesses (unknown, emulated, slow, fast, unsupported) *\/ \\\n+  decl(unaligned_scalar  ,  RV_NO_FLAG_BIT,  false,  NO_UPDATE_DEFAULT)                        \\\n+  \/* Performance of misaligned vector accesses (unknown, unspported, slow, fast) *\/            \\\n+  decl(unaligned_vector  ,  RV_NO_FLAG_BIT,  false,  NO_UPDATE_DEFAULT)                        \\\n+  decl(zicboz_block_size ,  RV_NO_FLAG_BIT,  false,  NO_UPDATE_DEFAULT)                        \\\n+\n+  #define DECLARE_RV_NON_EXT_FEATURE(PRETTY, LINUX_BIT, FSTRING, FLAGF)            \\\n+  struct PRETTY##RVNonExtFeatureValue : public RVNonExtFeatureValue {              \\\n+    PRETTY##RVNonExtFeatureValue() :                                               \\\n+      RVNonExtFeatureValue(#PRETTY, LINUX_BIT, FSTRING) {}                         \\\n+    FLAGF;                                                                         \\\n+  };                                                                               \\\n+  static PRETTY##RVNonExtFeatureValue PRETTY;                                      \\\n+\n+  RV_NON_EXT_FEATURE_FLAGS(DECLARE_RV_NON_EXT_FEATURE)\n+  #undef DECLARE_RV_NON_EXT_FEATURE\n+\n+private:\n+  \/\/ Utility for AOT CPU feature store\/check.\n+  class RVExtFeatures : public CHeapObj<mtCode> {\n+   public:\n+    enum RVFeatureIndex {\n+      #define DECLARE_RV_FEATURE_ENUM(PRETTY, LINUX_BIT, FSTRING, FLAGF) CPU_##ext_##PRETTY,\n+\n+      RV_EXT_FEATURE_FLAGS(DECLARE_RV_FEATURE_ENUM)\n+      MAX_CPU_FEATURE_INDEX\n+      #undef DECLARE_RV_FEATURE_ENUM\n+    };\n+   private:\n+    uint64_t _features_bitmap[(MAX_CPU_FEATURE_INDEX \/ BitsPerLong) + 1];\n+    STATIC_ASSERT(sizeof(_features_bitmap) * BitsPerByte >= MAX_CPU_FEATURE_INDEX);\n+\n+    \/\/ Number of 8-byte elements in _features_bitmap.\n+    constexpr static int element_count() {\n+      return sizeof(_features_bitmap) \/ sizeof(uint64_t);\n+    }\n+\n+    static int element_index(RVFeatureIndex feature) {\n+      int idx = feature \/ BitsPerLong;\n+      assert(idx < element_count(), \"Features array index out of bounds\");\n+      return idx;\n+    }\n+\n+    static uint64_t feature_bit(RVFeatureIndex feature) {\n+      return (1ULL << (feature % BitsPerLong));\n+    }\n+\n+    static RVFeatureIndex convert(uint32_t index) {\n+      assert(index < MAX_CPU_FEATURE_INDEX, \"must\");\n+      return (RVFeatureIndex)index;\n+    }\n+\n+   public:\n+    static RVExtFeatures* current() {\n+      return _rv_ext_features;\n+    }\n+\n+    RVExtFeatures() {\n+      for (int i = 0; i < element_count(); i++) {\n+        _features_bitmap[i] = 0;\n+      }\n+    }\n+\n+    void set_feature(uint32_t feature) {\n+      RVFeatureIndex f = convert(feature);\n+      int idx = element_index(f);\n+      _features_bitmap[idx] |= feature_bit(f);\n+    }\n+\n+    void clear_feature(uint32_t feature) {\n+      RVFeatureIndex f = convert(feature);\n+      int idx = element_index(f);\n+      _features_bitmap[idx] &= ~feature_bit(f);\n+    }\n+\n+    bool support_feature(uint32_t feature) {\n+      RVFeatureIndex f = convert(feature);\n+      int idx = element_index(f);\n+      return (_features_bitmap[idx] & feature_bit(f)) != 0;\n+    }\n+  };\n@@ -276,6 +461,13 @@\n-  enum UNALIGNED_ACCESS : int {\n-    MISALIGNED_UNKNOWN     = 0,\n-    MISALIGNED_EMULATED    = 1,\n-    MISALIGNED_SLOW        = 2,\n-    MISALIGNED_FAST        = 3,\n-    MISALIGNED_UNSUPPORTED = 4\n+  enum UNALIGNED_SCALAR_ACCESS : int {\n+    MISALIGNED_SCALAR_UNKNOWN     = 0,\n+    MISALIGNED_SCALAR_EMULATED    = 1,\n+    MISALIGNED_SCALAR_SLOW        = 2,\n+    MISALIGNED_SCALAR_FAST        = 3,\n+    MISALIGNED_SCALAR_UNSUPPORTED = 4\n+  };\n+\n+  enum UNALIGNED_VECTOR_ACCESS : int {\n+    MISALIGNED_VECTOR_UNKNOWN     = 0,\n+    MISALIGNED_VECTOR_SLOW        = 2,\n+    MISALIGNED_VECTOR_FAST        = 3,\n+    MISALIGNED_VECTOR_UNSUPPORTED = 4\n@@ -286,0 +478,1 @@\n+  static RVExtFeatures* _rv_ext_features;\n@@ -316,1 +509,1 @@\n-  constexpr static bool supports_recursive_lightweight_locking() { return true; }\n+  constexpr static bool supports_recursive_fast_locking() { return true; }\n","filename":"src\/hotspot\/cpu\/riscv\/vm_version_riscv.hpp","additions":332,"deletions":139,"binary":false,"changes":471,"status":"modified"},{"patch":"@@ -71,0 +71,1 @@\n+\/\/   z17:  2025-04\n@@ -72,5 +73,5 @@\n-static const char* z_gen[]      = {\"  \", \"G1\",         \"G2\",         \"G3\",         \"G4\",         \"G5\",         \"G6\",         \"G7\",         \"G8\",         \"G9\",         \"G10\" };\n-static const char* z_machine[]  = {\"  \", \"2064\",       \"2084\",       \"2094\",       \"2097\",       \"2817\",       \"2827\",       \"2964\",       \"3906\",       \"8561\",       \"3931\" };\n-static const char* z_name[]     = {\"  \", \"z900\",       \"z990\",       \"z9 EC\",      \"z10 EC\",     \"z196 EC\",    \"ec12\",       \"z13\",        \"z14\",        \"z15\",        \"z16\" };\n-static const char* z_WDFM[]     = {\"  \", \"2006-06-30\", \"2008-06-30\", \"2010-06-30\", \"2012-06-30\", \"2014-06-30\", \"2016-12-31\", \"2019-06-30\", \"2021-06-30\", \"2024-12-31\", \"tbd\" };\n-static const char* z_EOS[]      = {\"  \", \"2014-12-31\", \"2014-12-31\", \"2017-10-31\", \"2019-12-31\", \"2021-12-31\", \"2023-12-31\", \"2024-12-31\", \"tbd\",        \"tbd\",        \"tbd\" };\n+static const char* z_gen[]      = {\"  \", \"G1\",         \"G2\",         \"G3\",         \"G4\",         \"G5\",         \"G6\",         \"G7\",         \"G8\",         \"G9\",         \"G10\",         \"G11\" };\n+static const char* z_machine[]  = {\"  \", \"2064\",       \"2084\",       \"2094\",       \"2097\",       \"2817\",       \"2827\",       \"2964\",       \"3906\",       \"8561\",       \"3931\",        \"9175\" };\n+static const char* z_name[]     = {\"  \", \"z900\",       \"z990\",       \"z9 EC\",      \"z10 EC\",     \"z196 EC\",    \"ec12\",       \"z13\",        \"z14\",        \"z15\",        \"z16\",         \"z17\" };\n+static const char* z_WDFM[]     = {\"  \", \"2006-06-30\", \"2008-06-30\", \"2010-06-30\", \"2012-06-30\", \"2014-06-30\", \"2016-12-31\", \"2019-06-30\", \"2021-06-30\", \"2024-12-31\", \"tbd\",         \"tbd\" };\n+static const char* z_EOS[]      = {\"  \", \"2014-12-31\", \"2014-12-31\", \"2017-10-31\", \"2019-12-31\", \"2021-12-31\", \"2023-12-31\", \"2024-12-31\", \"tbd\",        \"tbd\",        \"tbd\",         \"tbd\" };\n@@ -88,1 +89,3 @@\n-                                       \"bear_enh, sort_enh, nnpa_assist, storage_key_removal, vpack_decimal_enh\"\n+                                       \"bear_enh, sort_enh, nnpa_assist, storage_key_removal, vpack_decimal_enh\",\n+                                   \"system-z, g11-z17, ldisp_fast, extimm, pcrel_load\/store, cmpb, cond_load\/store, interlocked_update, txm, vectorinstr, instrext2, venh1, instrext3, venh2,\"\n+                                       \"bear_enh, sort_enh, nnpa_assist, storage_key_removal, vpack_decimal_enh, concurrent_function\"\n@@ -344,0 +347,5 @@\n+  if (is_z17()) {\n+    model_ix = 11;\n+    ambiguity++;\n+  }\n+\n@@ -1546,2 +1554,2 @@\n-  snprintf(_cpu_name, CPU_TYPE_DESC_BUF_SIZE, \"s390 %s\", VM_Version::get_model_string());\n-  snprintf(_cpu_desc, CPU_DETAILED_DESC_BUF_SIZE, \"s390 %s\", cpu_info_string());\n+  os::snprintf_checked(_cpu_name, CPU_TYPE_DESC_BUF_SIZE, \"s390 %s\", VM_Version::get_model_string());\n+  os::snprintf_checked(_cpu_desc, CPU_DETAILED_DESC_BUF_SIZE, \"s390 %s\", cpu_info_string());\n","filename":"src\/hotspot\/cpu\/s390\/vm_version_s390.cpp","additions":16,"deletions":8,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2016, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -103,1 +103,1 @@\n-\/\/ --- FeatureBitString Bits 128..192 (DW[2]) ---\n+\/\/ --- FeatureBitString Bits 128..191 (DW[2]) ---\n@@ -121,1 +121,1 @@\n-\/\/ --- FeatureBitString Bits 193..200 (DW[3]) ---\n+\/\/ --- FeatureBitString Bits 192..255 (DW[3]) ---\n@@ -124,0 +124,1 @@\n+#define  ConcurrentFunFacilityMask      0x0040000000000000UL  \/\/ z17, Concurrent-functions facility, Bit: 201\n@@ -192,1 +193,2 @@\n-  static bool is_z16()  { return has_BEAR_Enh_Facility(); }\n+  static bool is_z16()  { return has_BEAR_Enh_Facility()      && !has_Concurrent_Fun_Facility(); }\n+  static bool is_z17()  { return has_Concurrent_Fun_Facility();}\n@@ -429,1 +431,1 @@\n-  constexpr static bool supports_recursive_lightweight_locking() { return true; }\n+  constexpr static bool supports_recursive_fast_locking() { return true; }\n@@ -503,0 +505,1 @@\n+  static bool has_Concurrent_Fun_Facility()   { return  (_features[3] & ConcurrentFunFacilityMask)     == ConcurrentFunFacilityMask; }\n@@ -579,0 +582,1 @@\n+  static void set_has_Concurrent_Fun_Facility()   { _features[3] |= ConcurrentFunFacilityMask;}\n","filename":"src\/hotspot\/cpu\/s390\/vm_version_s390.hpp","additions":9,"deletions":5,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+#include \"utilities\/ostream.hpp\"\n@@ -60,1 +61,1 @@\n-const char* VM_Version::_features_names[] = { CPU_FEATURE_FLAGS(DECLARE_CPU_FEATURE_NAME) };\n+const char* VM_Version::_features_names[] = { CPU_FEATURE_FLAGS(DECLARE_CPU_FEATURE_NAME)};\n@@ -73,1 +74,1 @@\n-static const int stub_size = 2000;\n+static const int stub_size = 2550;\n@@ -84,0 +85,1 @@\n+  typedef void (*getCPUIDBrandString_stub_t)(void*);\n@@ -88,0 +90,1 @@\n+static getCPUIDBrandString_stub_t getCPUIDBrandString_stub = nullptr;\n@@ -108,5 +111,8 @@\n-  VM_Features flush;\n-  flush.set_feature(CPU_FLUSH);\n-  char buf[MAX_CPU_FEATURES];\n-  guarantee(flush.print_numbers(buf, sizeof(buf)) >= 0, \"buffer too short\");\n-  vm_exit_during_initialization(err_msg(\"-XX:CPUFeatures option requires FLUSH flag to be set: %s\", buf));\n+  stringStream ss;\n+  ss.print_raw(\"-XX:CPUFeatures option requires FLUSH flag to be set: \");\n+  {\n+    VM_Features flush;\n+    flush.set_feature(CPU_FLUSH);\n+    flush.print_numbers(ss);\n+  }\n+  vm_exit_during_initialization(ss.base());\n@@ -116,0 +122,9 @@\n+void VM_Version::VM_Features::print_numbers(outputStream &os, bool hexonly) const {\n+  apply_to_all_features([&](uint64_t u, int idx) {\n+    os.print(hexonly ? UINT64_FORMAT_0 : UINT64_FORMAT_X, u);\n+    if (!hexonly && idx + 1 < features_bitmap_element_count()) {\n+      os.print_raw(\",\");\n+    }\n+  });\n+}\n+\n@@ -118,1 +133,2 @@\n-  print_numbers(buf, MAX_CPU_FEATURES);\n+  stringStream ss(buf, MAX_CPU_FEATURES);\n+  print_numbers(ss);\n@@ -169,1 +185,1 @@\n-    Label detect_486, cpu486, detect_586, std_cpuid1, std_cpuid4, std_cpuid24, check_cpuidb;\n+    Label detect_486, cpu486, detect_586, std_cpuid1, std_cpuid4, std_cpuid24, std_cpuid29, check_cpuidb;\n@@ -381,0 +397,10 @@\n+    \/\/\n+    \/\/ cpuid(0x29) APX NCI NDD NF (EAX = 29H, ECX = 0).\n+    \/\/\n+    __ bind(std_cpuid29);\n+    __ movl(rax, 0x29);\n+    __ movl(rcx, 0);\n+    __ cpuid();\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::std_cpuid29_offset())));\n+    __ movl(Address(rsi, 0), rbx);\n+\n@@ -484,1 +510,0 @@\n-#ifndef PRODUCT\n@@ -501,1 +526,0 @@\n-#endif\n@@ -1284,0 +1308,1 @@\n+  GLIBC_UNSUPPORTED(HYBRID           );\n@@ -1295,5 +1320,6 @@\n-    char buf_handled[MAX_CPU_FEATURES];\n-    guarantee(handled.print_numbers(buf_handled, sizeof(buf_handled)) >= 0, \"buffer too short\");\n-    char buf_all_features[MAX_CPU_FEATURES];\n-    guarantee(all_features.print_numbers(buf_all_features, sizeof(buf_all_features)) >= 0, \"buffer too short\");\n-    vm_exit_during_initialization(err_msg(\"internal error: Unsupported disabling of some CPU_* %s != full %s\", buf_handled, buf_all_features));\n+    stringStream ss;\n+    ss.print_raw(\"internal error: Unsupported disabling of some CPU_* \");\n+    handled.print_numbers(ss);\n+    ss.print_raw(\" != full \");\n+    all_features.print_numbers(ss);\n+    vm_exit_during_initialization(ss.base());\n@@ -1315,1 +1341,1 @@\n-    tty->print_cr(\"CPU features are being kept intact as requested by -XX:CPUFeatures=ignore\");\n+    tty->print_raw_cr(\"CPU features are being kept intact as requested by -XX:CPUFeatures=ignore\");\n@@ -1317,3 +1343,3 @@\n-    char buf[MAX_CPU_FEATURES];\n-    guarantee(_features.print_numbers(buf, sizeof(buf)) >= 0, \"buffer too short\");\n-    tty->print_cr(\"CPU features being used are: -XX:CPUFeatures=%s\", buf);\n+    tty->print_raw(\"CPU features being used are: -XX:CPUFeatures=\");\n+    _features.print_numbers(*tty);\n+    tty->cr();\n@@ -1357,3 +1383,3 @@\n-    char buf[MAX_CPU_FEATURES];\n-    guarantee(_features.print_numbers(buf, sizeof(buf)) >= 0, \"buffer too short\");\n-    tty->print_cr(\"This machine's CPU features are: -XX:CPUFeatures=%s\", buf);\n+    tty->print_raw(\"This machine's CPU features are: -XX:CPUFeatures=\");\n+    _features.print_numbers(*tty);\n+    tty->cr();\n@@ -1367,5 +1393,8 @@\n-      VM_Features sse2;\n-      sse2.set_feature(CPU_SSE2);\n-      char buf[MAX_CPU_FEATURES];\n-      guarantee(sse2.print_numbers(buf, sizeof(buf)) >= 0, \"buffer too short\");\n-      vm_exit_during_initialization(err_msg(\"-XX:CPUFeatures option requires SSE2 flag to be set: %s\", buf));\n+      stringStream ss;\n+      ss.print_raw(\"-XX:CPUFeatures option requires SSE2 flag to be set: \");\n+      {\n+        VM_Features sse2;\n+        sse2.set_feature(CPU_SSE2);\n+        sse2.print_numbers(ss);\n+      }\n+      vm_exit_during_initialization(ss.base());\n@@ -1508,12 +1537,0 @@\n-  \/\/ Currently APX support is only enabled for targets supporting AVX512VL feature.\n-  bool apx_supported = os_supports_apx_egprs() && supports_apx_f() && supports_avx512vl();\n-  if (UseAPX && !apx_supported) {\n-    warning(\"UseAPX is not supported on this CPU, setting it to false\");\n-    FLAG_SET_DEFAULT(UseAPX, false);\n-  } else if (FLAG_IS_DEFAULT(UseAPX)) {\n-    FLAG_SET_DEFAULT(UseAPX, apx_supported ? true : false);\n-  }\n-\n-  if (!UseAPX) {\n-    _features.clear_feature(CPU_APX_F);\n-  }\n@@ -1543,0 +1560,1 @@\n+      _features.clear_feature(CPU_APX_F);\n@@ -1562,0 +1580,11 @@\n+    \/\/ Currently APX support is only enabled for targets supporting AVX512VL feature.\n+  bool apx_supported = os_supports_apx_egprs() && supports_apx_f() && supports_avx512vl();\n+  if (UseAPX && !apx_supported) {\n+    warning(\"UseAPX is not supported on this CPU, setting it to false\");\n+    FLAG_SET_DEFAULT(UseAPX, false);\n+  }\n+\n+  if (!UseAPX) {\n+    _features.clear_feature(CPU_APX_F);\n+  }\n+\n@@ -1564,0 +1593,1 @@\n+    FLAG_SET_ERGO(IntelJccErratumMitigation, _has_intel_jcc_erratum);\n@@ -1591,12 +1621,11 @@\n-  char buf[2048];\n-  size_t cpu_info_size = jio_snprintf(\n-              buf, sizeof(buf),\n-              \"(%u cores per cpu, %u threads per core) family %d model %d stepping %d microcode 0x%x\",\n-              cores_per_cpu(), threads_per_core(),\n-              cpu_family(), _model, _stepping, os::cpu_microcode_revision());\n-\n-  assert(cpu_info_size > 0, \"not enough temporary space allocated\");\n-\n-  insert_features_names(_features, buf + cpu_info_size, sizeof(buf) - cpu_info_size);\n-\n-  _cpu_info_string = os::strdup(buf);\n+  stringStream ss(2048);\n+  if (supports_hybrid()) {\n+    ss.print(\"(hybrid)\");\n+  } else {\n+    ss.print(\"(%u cores per cpu, %u threads per core)\", cores_per_cpu(), threads_per_core());\n+  }\n+  ss.print(\" family %d model %d stepping %d microcode 0x%x\",\n+           cpu_family(), _model, _stepping, os::cpu_microcode_revision());\n+  ss.print(\", \");\n+  int features_offset = (int)ss.size();\n+  insert_features_names(_features, ss);\n@@ -1604,3 +1633,2 @@\n-  _features_string = extract_features_string(_cpu_info_string,\n-                                             strnlen(_cpu_info_string, sizeof(buf)),\n-                                             cpu_info_size);\n+  _cpu_info_string = ss.as_string(true);\n+  _features_string = _cpu_info_string + features_offset;\n@@ -1741,1 +1769,0 @@\n-#ifdef _LP64\n@@ -1747,1 +1774,0 @@\n-#endif\n@@ -1754,2 +1780,1 @@\n-  \/\/ Currently we only have them for AVX512\n-  if (supports_evex() && supports_avx512bw()) {\n+  if (UseAVX > 1) {\n@@ -1973,10 +1998,0 @@\n-      if (supports_sse4_2()) {\n-        if (FLAG_IS_DEFAULT(UseSSE42Intrinsics)) {\n-          FLAG_SET_DEFAULT(UseSSE42Intrinsics, true);\n-        }\n-      } else {\n-        if (UseSSE42Intrinsics && !FLAG_IS_DEFAULT(UseAESIntrinsics)) {\n-          warning(\"SSE4.2 intrinsics require SSE4.2 instructions or higher. Intrinsics will be disabled.\");\n-        }\n-        FLAG_SET_DEFAULT(UseSSE42Intrinsics, false);\n-      }\n@@ -2027,10 +2042,0 @@\n-    if (supports_sse4_2()) {\n-      if (FLAG_IS_DEFAULT(UseSSE42Intrinsics)) {\n-        FLAG_SET_DEFAULT(UseSSE42Intrinsics, true);\n-      }\n-    } else {\n-      if (UseSSE42Intrinsics && !FLAG_IS_DEFAULT(UseAESIntrinsics)) {\n-        warning(\"SSE4.2 intrinsics require SSE4.2 instructions or higher. Intrinsics will be disabled.\");\n-      }\n-      FLAG_SET_DEFAULT(UseSSE42Intrinsics, false);\n-    }\n@@ -2125,10 +2130,0 @@\n-      if (supports_sse4_2()) {\n-        if (FLAG_IS_DEFAULT(UseSSE42Intrinsics)) {\n-          FLAG_SET_DEFAULT(UseSSE42Intrinsics, true);\n-        }\n-      } else {\n-        if (UseSSE42Intrinsics && !FLAG_IS_DEFAULT(UseAESIntrinsics)) {\n-          warning(\"SSE4.2 intrinsics require SSE4.2 instructions or higher. Intrinsics will be disabled.\");\n-        }\n-        FLAG_SET_DEFAULT(UseSSE42Intrinsics, false);\n-      }\n@@ -2190,1 +2185,1 @@\n-    if (MaxVectorSize < 32 || !VM_Version::supports_avx512vlbw()) {\n+    if (MaxVectorSize < 32 || (!EnableX86ECoreOpts && !VM_Version::supports_avx512vlbw())) {\n@@ -2195,1 +2190,10 @@\n-\n+  if (supports_sse4_2()) {\n+    if (FLAG_IS_DEFAULT(UseSSE42Intrinsics)) {\n+      FLAG_SET_DEFAULT(UseSSE42Intrinsics, true);\n+    }\n+  } else {\n+    if (UseSSE42Intrinsics && !FLAG_IS_DEFAULT(UseSSE42Intrinsics)) {\n+      warning(\"SSE4.2 intrinsics require SSE4.2 instructions or higher. Intrinsics will be disabled.\");\n+    }\n+    FLAG_SET_DEFAULT(UseSSE42Intrinsics, false);\n+  }\n@@ -2583,8 +2587,0 @@\n-void VM_Version::VM_Features::print_missing_features() const {\n-  char buf[MAX_CPU_FEATURES * 16];\n-  print_numbers_and_names(buf, sizeof(buf));\n-  tty->print_cr(\"; missing features of this CPU are %s\\n\"\n-                \"If you are sure it will not crash you can override this check by -XX:+UnlockExperimentalVMOptions -XX:CheckCPUFeatures=ignore .\",\n-                buf);\n-}\n-\n@@ -2612,0 +2608,4 @@\n+bool VM_Version::is_intel_darkmont() {\n+  return is_intel() && is_intel_server_family() && (_model == 0xCC || _model == 0xDD);\n+}\n+\n@@ -2618,1 +2618,1 @@\n-  return (is_intel_family_core() &&\n+  return (is_intel_server_family() &&\n@@ -2646,0 +2646,2 @@\n+  getCPUIDBrandString_stub = CAST_TO_FN_PTR(getCPUIDBrandString_stub_t,\n+                                     g.generate_getCPUIDBrandString());\n@@ -2659,7 +2661,12 @@\n-    char buf_CPUFeatures_parsed[MAX_CPU_FEATURES];\n-    guarantee(CPUFeatures_parsed.print_numbers(buf_CPUFeatures_parsed, sizeof(buf_CPUFeatures_parsed)) >= 0, \"buffer too short\");\n-    char buf_features[MAX_CPU_FEATURES];\n-    guarantee(_features.print_numbers(buf_features, sizeof(buf_features)) >= 0, \"buffer too short\");\n-    tty->print(\"Specified -XX:CPUFeatures=%s; this machine's CPU features are %s\", buf_CPUFeatures_parsed, buf_features);\n-    features_missing.print_missing_features();\n-    vm_exit_during_initialization();\n+    stringStream ss;\n+    ss.print_raw(\"Specified -XX:CPUFeatures=\");\n+    CPUFeatures_parsed.print_numbers(ss);\n+    ss.print_raw(\"; this machine's CPU features are \");\n+    _features.print_numbers(ss);\n+    ss.print_raw(\"; missing features of this CPU are \");\n+    features_missing.print_numbers(ss);\n+    ss.print_raw(\" = \");\n+    insert_features_names(features_missing, ss);\n+    ss.cr();\n+    ss.print_raw_cr(\"If you are sure it will not crash you can override this check by -XX:+UnlockExperimentalVMOptions -XX:CheckCPUFeatures=ignore .\");\n+    vm_exit_during_initialization(ss.base());\n@@ -2736,9 +2743,0 @@\n-static BufferBlob* cpuid_brand_string_stub_blob;\n-static const int   cpuid_brand_string_stub_size = 550;\n-\n-extern \"C\" {\n-  typedef void (*getCPUIDBrandString_stub_t)(void*);\n-}\n-\n-static getCPUIDBrandString_stub_t getCPUIDBrandString_stub = nullptr;\n-\n@@ -3037,13 +3035,0 @@\n-void VM_Version::initialize_tsc(void) {\n-  ResourceMark rm;\n-\n-  cpuid_brand_string_stub_blob = BufferBlob::create(\"getCPUIDBrandString_stub\", cpuid_brand_string_stub_size);\n-  if (cpuid_brand_string_stub_blob == nullptr) {\n-    vm_exit_during_initialization(\"Unable to allocate getCPUIDBrandString_stub\");\n-  }\n-  CodeBuffer c(cpuid_brand_string_stub_blob);\n-  VM_Version_StubGenerator g(&c);\n-  getCPUIDBrandString_stub = CAST_TO_FN_PTR(getCPUIDBrandString_stub_t,\n-                                   g.generate_getCPUIDBrandString());\n-}\n-\n@@ -3138,1 +3123,6 @@\n-  int threads_per_package = threads_per_core() * cores_per_cpu();\n+  int threads_per_package = _cpuid_info.tpl_cpuidB1_ebx.bits.logical_cpus;\n+  if (threads_per_package == 0) {\n+    \/\/ Fallback code to avoid div by zero in subsequent code.\n+    \/\/ CPUID 0Bh (ECX = 1) might return 0 on older AMD processor (EPYC 7763 at least)\n+    threads_per_package = threads_per_core() * cores_per_cpu();\n+  }\n@@ -3292,0 +3282,4 @@\n+  if (supports_hybrid()) {\n+      WRITE_TO_BUF(\"Hybrid Architecture\");\n+  }\n+\n@@ -3477,1 +3471,2 @@\n-      xem_xcr0_eax.bits.apx_f != 0) {\n+      xem_xcr0_eax.bits.apx_f != 0 &&\n+      std_cpuid29_ebx.bits.apx_nci_ndd_nf != 0) {\n@@ -3612,0 +3607,2 @@\n+    if (sef_cpuid7_edx.bits.hybrid != 0)\n+      vm_features.set_feature(CPU_HYBRID);\n@@ -3728,3 +3725,0 @@\n-  \/\/ Enable APX support for product builds after\n-  \/\/ completion of planned features listed in JDK-8329030.\n-#if !defined(PRODUCT)\n@@ -3736,3 +3730,0 @@\n-#else\n-  return false;\n-#endif\n@@ -3753,1 +3744,4 @@\n-    result = (_cpuid_info.ext_cpuid8_ecx.bits.cores_per_cpu + 1);\n+    result = _cpuid_info.ext_cpuid8_ecx.bits.threads_per_cpu + 1;\n+    if (cpu_family() >= 0x17) { \/\/ Zen or later\n+      result \/= _cpuid_info.ext_cpuid1E_ebx.bits.threads_per_core + 1;\n+    }\n@@ -3873,7 +3867,8 @@\n-void VM_Version::insert_features_names(VM_Version::VM_Features features, char* buf, size_t buflen) {\n-  for (int i = 0; i < MAX_CPU_FEATURES; i++) {\n-    if (features.supports_feature((VM_Version::Feature_Flag)i)) {\n-      int res = jio_snprintf(buf, buflen, \", %s\", _features_names[i]);\n-      assert(res > 0, \"not enough temporary space allocated\");\n-      buf += res;\n-      buflen -= res;\n+void VM_Version::insert_features_names(VM_Version::VM_Features features, stringStream& ss) {\n+  int i = 0;\n+  ss.join([&]() {\n+    while (i < MAX_CPU_FEATURES) {\n+      if (_features.supports_feature((VM_Version::Feature_Flag)i)) {\n+        return _features_names[i++];\n+      }\n+      i += 1;\n@@ -3881,1 +3876,2 @@\n-  }\n+    return (const char*)nullptr;\n+  }, \", \");\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":142,"deletions":146,"binary":false,"changes":288,"status":"modified"},{"patch":"@@ -34,0 +34,2 @@\n+class stringStream;\n+\n@@ -218,2 +220,2 @@\n-      uint32_t cores_per_cpu : 8,\n-                             : 24;\n+      uint32_t threads_per_cpu : 8,\n+                               : 24;\n@@ -295,1 +297,2 @@\n-                           : 5,\n+                     hybrid: 1,\n+                           : 4,\n@@ -324,0 +327,8 @@\n+  union StdCpuidEax29Ecx0 {\n+    uint32_t value;\n+    struct {\n+      uint32_t  apx_nci_ndd_nf  : 1,\n+                                : 31;\n+    } bits;\n+  };\n+\n@@ -464,11 +475,12 @@\n-    decl(FMA4,              \"fma4\",              65) \\\n-    decl(MOVBE,             \"movbe\",             66) \\\n-    decl(OSXSAVE,           \"osxsave\",           67) \\\n-    decl(IBT,               \"ibt\",               68) \\\n-    decl(SHSTK,             \"shstk\",             69) \/* Also known as cet_ss *\/ \\\n-    decl(XSAVE,             \"xsave\",             70) \\\n-    decl(CMPXCHG16,         \"cmpxchg16\",         71) \/* Also known in cpuinfo as cx16 and in glibc as cmpxchg16b *\/ \\\n-    decl(LAHFSAHF,          \"lahfsahf\",          72) \/* Also known in cpuinfo as lahf_lm and in glibc as lahf64_sahf64 *\/ \\\n-    decl(HTT,               \"htt\",               73) \/* hotspot calls it 'ht' but that is affected by threads_per_core() *\/ \\\n-    decl(XSAVEC,            \"xsavec\",            74) \\\n-    decl(AVX_Fast_Unaligned_Load, \"avx_fast_unaligned_load\", 75)\n+    decl(HYBRID,            \"hybrid\",            65) \/* Hybrid architecture *\/ \\\n+    decl(FMA4,              \"fma4\",              66) \\\n+    decl(MOVBE,             \"movbe\",             67) \\\n+    decl(OSXSAVE,           \"osxsave\",           68) \\\n+    decl(IBT,               \"ibt\",               69) \\\n+    decl(SHSTK,             \"shstk\",             70) \/* Also known as cet_ss *\/ \\\n+    decl(XSAVE,             \"xsave\",             71) \\\n+    decl(CMPXCHG16,         \"cmpxchg16\",         72) \/* Also known in cpuinfo as cx16 and in glibc as cmpxchg16b *\/ \\\n+    decl(LAHFSAHF,          \"lahfsahf\",          73) \/* Also known in cpuinfo as lahf_lm and in glibc as lahf64_sahf64 *\/ \\\n+    decl(HTT,               \"htt\",               74) \/* hotspot calls it 'ht' but that is affected by threads_per_core() *\/ \\\n+    decl(XSAVEC,            \"xsavec\",            75) \\\n+    decl(AVX_Fast_Unaligned_Load, \"avx_fast_unaligned_load\", 76)\n@@ -613,22 +625,1 @@\n-    int print_numbers(char *buf_orig, size_t buflen, bool hexonly = false) const {\n-      char *buf = buf_orig;\n-      const char *format = hexonly ? UINT64_FORMAT_0 : UINT64_FORMAT_X;\n-      apply_to_all_features([&](uint64_t u, int idx) {\n-        int res = jio_snprintf(buf, buflen, format, u);\n-        if (res < 0) {\n-          buflen = 0;\n-          return;\n-        }\n-        buf += res;\n-        buflen -= res;\n-        if (!hexonly && idx + 1 < features_bitmap_element_count() && buflen > 0) {\n-          *buf++ = ',';\n-          --buflen;\n-        }\n-      });\n-      if (buflen == 0) {\n-        return -1;\n-      }\n-      *buf = 0;\n-      return buf - buf_orig;\n-    }\n+    void print_numbers(outputStream &os, bool hexonly = false) const;\n@@ -637,19 +628,0 @@\n-\n-    void print_numbers_and_names(char *buf, size_t buflen) const {\n-      int res = print_numbers(buf, buflen);\n-      assert(res >= 0, \"buffer too short\");\n-      buf += res;\n-      buflen -= res;\n-      assert(buflen >= 3, \"not enough temporary space allocated\");\n-      *buf++ = ' ';\n-      --buflen;\n-      *buf = 0;\n-      insert_features_names(*this, buf, buflen);\n-\n-      \/\/ insert_features_names puts \", \" at the beginning, make it \" = \".\n-      if (*buf) {\n-        *buf = '=';\n-      }\n-    }\n-\n-    void print_missing_features() const;\n@@ -739,0 +711,4 @@\n+    \/\/ cpuid function 0x29 APX Advanced Performance Extensions Leaf\n+    \/\/ eax = 0x29, ecx = 0\n+    StdCpuidEax29Ecx0 std_cpuid29_ebx;\n+\n@@ -879,0 +855,1 @@\n+  static ByteSize std_cpuid29_offset() { return byte_offset_of(CpuidInfo, std_cpuid29_ebx); }\n@@ -929,1 +906,3 @@\n-  static void set_apx_cpuFeatures() { _features.set_feature(CPU_APX_F); }\n+  static void set_apx_cpuFeatures() {\n+    _features.set_feature(CPU_APX_F);\n+  }\n@@ -943,1 +922,0 @@\n-    \/\/ IgnoreCPUFeatures is ignored on checkpoint\n@@ -1056,0 +1034,1 @@\n+  static bool supports_hybrid()       { return _features.supports_feature(CPU_HYBRID); }\n@@ -1099,0 +1078,2 @@\n+  static bool is_intel_darkmont();\n+\n@@ -1103,1 +1084,1 @@\n-  static void insert_features_names(VM_Version::VM_Features features, char* buf, size_t buflen);\n+  static void insert_features_names(VM_Version::VM_Features features, stringStream& ss);\n@@ -1154,1 +1135,1 @@\n-  constexpr static bool supports_recursive_lightweight_locking() {\n+  constexpr static bool supports_recursive_fast_locking() {\n@@ -1252,1 +1233,0 @@\n-  static void initialize_tsc();\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.hpp","additions":40,"deletions":60,"binary":false,"changes":100,"status":"modified"},{"patch":"@@ -119,3 +119,2 @@\n-#if defined(IA32) || defined(AMD64) || defined(ARM) || \\\n-    defined(AARCH64) || defined(PPC) || defined(RISCV) || \\\n-    defined(S390)\n+#if defined(AMD64) || defined(ARM) || defined(AARCH64) || \\\n+    defined(PPC) || defined(RISCV) || defined(S390)\n@@ -155,2 +154,2 @@\n-  snprintf(_cpu_name, CPU_TYPE_DESC_BUF_SIZE - 1, \"Zero VM\");\n-  snprintf(_cpu_desc, CPU_DETAILED_DESC_BUF_SIZE, \"%s\", _cpu_info_string);\n+  os::snprintf_checked(_cpu_name, CPU_TYPE_DESC_BUF_SIZE - 1, \"Zero VM\");\n+  os::snprintf_checked(_cpu_desc, CPU_DETAILED_DESC_BUF_SIZE, \"%s\", _cpu_info_string);\n","filename":"src\/hotspot\/cpu\/zero\/vm_version_zero.cpp","additions":4,"deletions":5,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -46,1 +46,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -172,1 +172,1 @@\n-julong    os::Aix::_physical_memory = 0;\n+physical_memory_size_type    os::Aix::_physical_memory = 0;\n@@ -257,2 +257,2 @@\n-julong os::free_memory() {\n-  return Aix::available_memory();\n+bool os::free_memory(physical_memory_size_type& value) {\n+  return Aix::available_memory(value);\n@@ -261,2 +261,2 @@\n-julong os::available_memory() {\n-  return Aix::available_memory();\n+bool os::available_memory(physical_memory_size_type& value) {\n+  return Aix::available_memory(value);\n@@ -265,1 +265,1 @@\n-julong os::Aix::available_memory() {\n+bool os::Aix::available_memory(physical_memory_size_type& value) {\n@@ -268,1 +268,2 @@\n-    return mi.real_free;\n+    value = static_cast<physical_memory_size_type>(mi.real_free);\n+    return true;\n@@ -270,1 +271,1 @@\n-    return ULONG_MAX;\n+    return false;\n@@ -274,1 +275,1 @@\n-jlong os::total_swap_space() {\n+bool os::total_swap_space(physical_memory_size_type& value) {\n@@ -277,1 +278,1 @@\n-    return -1;\n+    return false;\n@@ -279,1 +280,2 @@\n-  return (jlong)(memory_info.pgsp_total * 4 * K);\n+  value = static_cast<physical_memory_size_type>(memory_info.pgsp_total * 4 * K);\n+  return true;\n@@ -282,1 +284,1 @@\n-jlong os::free_swap_space() {\n+bool os::free_swap_space(physical_memory_size_type& value) {\n@@ -285,1 +287,1 @@\n-    return -1;\n+    return false;\n@@ -287,1 +289,2 @@\n-  return (jlong)(memory_info.pgsp_free * 4 * K);\n+  value = static_cast<physical_memory_size_type>(memory_info.pgsp_free * 4 * K);\n+  return true;\n@@ -290,1 +293,1 @@\n-julong os::physical_memory() {\n+physical_memory_size_type os::physical_memory() {\n@@ -329,1 +332,1 @@\n-  _physical_memory = (julong) mi.real_total;\n+  _physical_memory = static_cast<physical_memory_size_type>(mi.real_total);\n@@ -882,11 +885,0 @@\n-double os::elapsedVTime() {\n-  struct rusage usage;\n-  int retval = getrusage(RUSAGE_THREAD, &usage);\n-  if (retval == 0) {\n-    return usage.ru_utime.tv_sec + usage.ru_stime.tv_sec + (usage.ru_utime.tv_usec + usage.ru_stime.tv_usec) \/ (1000.0 * 1000);\n-  } else {\n-    \/\/ better than nothing, but not much\n-    return elapsedTime();\n-  }\n-}\n-\n@@ -1052,0 +1044,2 @@\n+  Events::log_dll_message(nullptr, \"Attempting to load shared library %s\", filename);\n+\n@@ -1068,2 +1062,2 @@\n-      snprintf(ebuf, ebuflen - 1, \"%s, LIBPATH=%s, LD_LIBRARY_PATH=%s : %s\",\n-               filename, ::getenv(\"LIBPATH\"), ::getenv(\"LD_LIBRARY_PATH\"), error_report);\n+      os::snprintf_checked(ebuf, ebuflen, \"%s, LIBPATH=%s, LD_LIBRARY_PATH=%s : %s\",\n+                           filename, ::getenv(\"LIBPATH\"), ::getenv(\"LD_LIBRARY_PATH\"), error_report);\n@@ -1094,1 +1088,1 @@\n-      os::snprintf(tmp_path + prefix_size, sizeof(old_extension), \"%s\", new_extension);\n+      os::snprintf_checked(tmp_path + prefix_size, sizeof(old_extension), \"%s\", new_extension);\n@@ -1111,1 +1105,1 @@\n-  snprintf(buf, buflen, \"%s %s\", name.release, name.version);\n+  os::snprintf_checked(buf, buflen, \"%s %s\", name.release, name.version);\n@@ -1267,63 +1261,0 @@\n-static char saved_jvm_path[MAXPATHLEN] = {0};\n-\n-\/\/ Find the full path to the current module, libjvm.so.\n-void os::jvm_path(char *buf, jint buflen) {\n-  \/\/ Error checking.\n-  if (buflen < MAXPATHLEN) {\n-    assert(false, \"must use a large-enough buffer\");\n-    buf[0] = '\\0';\n-    return;\n-  }\n-  \/\/ Lazy resolve the path to current module.\n-  if (saved_jvm_path[0] != 0) {\n-    strcpy(buf, saved_jvm_path);\n-    return;\n-  }\n-\n-  Dl_info dlinfo;\n-  int ret = dladdr(CAST_FROM_FN_PTR(void *, os::jvm_path), &dlinfo);\n-  assert(ret != 0, \"cannot locate libjvm\");\n-  char* rp = os::realpath((char *)dlinfo.dli_fname, buf, buflen);\n-  assert(rp != nullptr, \"error in realpath(): maybe the 'path' argument is too long?\");\n-\n-  \/\/ If executing unit tests we require JAVA_HOME to point to the real JDK.\n-  if (Arguments::executing_unit_tests()) {\n-    \/\/ Look for JAVA_HOME in the environment.\n-    char* java_home_var = ::getenv(\"JAVA_HOME\");\n-    if (java_home_var != nullptr && java_home_var[0] != 0) {\n-\n-      \/\/ Check the current module name \"libjvm.so\".\n-      const char* p = strrchr(buf, '\/');\n-      if (p == nullptr) {\n-        return;\n-      }\n-      assert(strstr(p, \"\/libjvm\") == p, \"invalid library name\");\n-\n-      stringStream ss(buf, buflen);\n-      rp = os::realpath(java_home_var, buf, buflen);\n-      if (rp == nullptr) {\n-        return;\n-      }\n-\n-      assert((int)strlen(buf) < buflen, \"Ran out of buffer room\");\n-      ss.print(\"%s\/lib\", buf);\n-\n-      if (0 == access(buf, F_OK)) {\n-        \/\/ Use current module name \"libjvm.so\"\n-        ss.print(\"\/%s\/libjvm%s\", Abstract_VM_Version::vm_variant(), JNI_LIB_SUFFIX);\n-        assert(strcmp(buf + strlen(buf) - strlen(JNI_LIB_SUFFIX), JNI_LIB_SUFFIX) == 0,\n-               \"buf has been truncated\");\n-      } else {\n-        \/\/ Go back to path of .so\n-        rp = os::realpath((char *)dlinfo.dli_fname, buf, buflen);\n-        if (rp == nullptr) {\n-          return;\n-        }\n-      }\n-    }\n-  }\n-\n-  strncpy(saved_jvm_path, buf, sizeof(saved_jvm_path));\n-  saved_jvm_path[sizeof(saved_jvm_path) - 1] = '\\0';\n-}\n-\n@@ -1824,1 +1755,1 @@\n-void os::numa_make_global(char *addr, size_t bytes) {\n+void os::numa_set_thread_affinity(Thread *thread, int node) {\n@@ -1827,1 +1758,1 @@\n-void os::numa_make_local(char *addr, size_t bytes, int lgrp_hint) {\n+void os::numa_make_global(char *addr, size_t bytes) {\n@@ -1830,2 +1761,1 @@\n-bool os::numa_topology_changed() {\n-  return false;\n+void os::numa_make_local(char *addr, size_t bytes, int lgrp_hint) {\n@@ -2273,1 +2203,1 @@\n-  trcVerbose(\"physical memory: %lu\", Aix::_physical_memory);\n+  trcVerbose(\"physical memory: \" PHYS_MEM_TYPE_FORMAT, Aix::_physical_memory);\n@@ -2409,1 +2339,1 @@\n-        errno = EISDIR;\n+        errno = EISDIR;\n@@ -2423,2 +2353,1 @@\n-  \/\/ appropriate file descriptors (e.g. as we do in closeDescriptors in\n-  \/\/ UNIXProcess.c), and this in turn might:\n+  \/\/ appropriate file descriptors, and this in turn might:\n@@ -2510,1 +2439,1 @@\n-    tty->print_cr(\"pthread_getthrds_np failed.\");\n+    tty->print_cr(\"pthread_getthrds_np failed, errno: %d.\", errno);\n@@ -2521,1 +2450,1 @@\n-      tty->print_cr(\"pthread_getthrds_np failed.\");\n+      tty->print_cr(\"getthrds64 failed, errno: %d.\", errno);\n","filename":"src\/hotspot\/os\/aix\/os_aix.cpp","additions":34,"deletions":105,"binary":false,"changes":139,"status":"modified"},{"patch":"@@ -42,1 +42,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -117,1 +117,1 @@\n-julong os::Bsd::_physical_memory = 0;\n+physical_memory_size_type os::Bsd::_physical_memory = 0;\n@@ -136,2 +136,2 @@\n-julong os::available_memory() {\n-  return Bsd::available_memory();\n+bool os::available_memory(physical_memory_size_type& value) {\n+  return Bsd::available_memory(value);\n@@ -140,2 +140,2 @@\n-julong os::free_memory() {\n-  return Bsd::available_memory();\n+bool os::free_memory(physical_memory_size_type& value) {\n+  return Bsd::available_memory(value);\n@@ -147,2 +147,2 @@\n-julong os::Bsd::available_memory() {\n-  uint64_t available = physical_memory() >> 2;\n+bool os::Bsd::available_memory(physical_memory_size_type& value) {\n+  physical_memory_size_type available = physical_memory() >> 2;\n@@ -157,1 +157,4 @@\n-    available = vmstat.free_count * os::vm_page_size();\n+    \/\/ free_count is just a lowerbound, other page categories can be freed too and make memory available\n+    available = (vmstat.free_count + vmstat.inactive_count + vmstat.purgeable_count) * os::vm_page_size();\n+  } else {\n+    return false;\n@@ -160,1 +163,2 @@\n-  return available;\n+  value = available;\n+  return true;\n@@ -179,1 +183,1 @@\n-jlong os::total_swap_space() {\n+bool os::total_swap_space(physical_memory_size_type& value) {\n@@ -184,1 +188,1 @@\n-    return -1;\n+    return false;\n@@ -186,1 +190,2 @@\n-  return (jlong)vmusage.xsu_total;\n+  value = static_cast<physical_memory_size_type>(vmusage.xsu_total);\n+  return true;\n@@ -188,1 +193,1 @@\n-  return -1;\n+  return false;\n@@ -192,1 +197,1 @@\n-jlong os::free_swap_space() {\n+bool os::free_swap_space(physical_memory_size_type& value) {\n@@ -197,1 +202,1 @@\n-    return -1;\n+    return false;\n@@ -199,1 +204,2 @@\n-  return (jlong)vmusage.xsu_avail;\n+  value = static_cast<physical_memory_size_type>(vmusage.xsu_avail);\n+  return true;\n@@ -201,1 +207,1 @@\n-  return -1;\n+  return false;\n@@ -205,1 +211,1 @@\n-julong os::physical_memory() {\n+physical_memory_size_type os::physical_memory() {\n@@ -228,2 +234,0 @@\n-#elif defined(IA32)\n-static char cpu_arch[] = \"i386\";\n@@ -283,1 +287,1 @@\n-    _physical_memory = mem_val;\n+    _physical_memory = static_cast<physical_memory_size_type>(mem_val);\n@@ -294,1 +298,1 @@\n-    _physical_memory = MIN2(_physical_memory, (julong)limits.rlim_cur);\n+    _physical_memory = MIN2(_physical_memory, static_cast<physical_memory_size_type>(limits.rlim_cur));\n@@ -524,1 +528,1 @@\n-          user_home_dir, Arguments::get_java_home());\n+                       user_home_dir, Arguments::get_java_home());\n@@ -784,4 +788,0 @@\n-double os::elapsedVTime() {\n-  \/\/ better than nothing, but not much\n-  return elapsedTime();\n-}\n@@ -810,1 +810,1 @@\n-  const uint64_t obsv = Atomic::cmpxchg(&Bsd::_max_abstime, prev, now);\n+  const uint64_t obsv = AtomicAccess::cmpxchg(&Bsd::_max_abstime, prev, now);\n@@ -864,0 +864,84 @@\n+\/\/ Returns the uid of a process or -1 on error.\n+uid_t os::Bsd::get_process_uid(pid_t pid) {\n+  struct kinfo_proc kp;\n+  size_t size = sizeof kp;\n+  int mib_kern[4] = {CTL_KERN, KERN_PROC, KERN_PROC_PID, pid};\n+  if (sysctl(mib_kern, 4, &kp, &size, nullptr, 0) == 0) {\n+    if (size > 0 && kp.kp_proc.p_pid == pid) {\n+      return kp.kp_eproc.e_ucred.cr_uid;\n+    }\n+  }\n+  return (uid_t)-1;\n+}\n+\n+\/\/ Returns true if the process is running as root.\n+bool os::Bsd::is_process_root(pid_t pid) {\n+  uid_t uid = get_process_uid(pid);\n+  return (uid != (uid_t)-1) ? os::Posix::is_root(uid) : false;\n+}\n+\n+#ifdef __APPLE__\n+\n+\/\/ macOS has a secure per-user temporary directory.\n+\/\/ Root can attach to a non-root process, hence it needs\n+\/\/ to lookup \/var\/folders for the user specific temporary directory\n+\/\/ of the form \/var\/folders\/*\/*\/T, that contains PERFDATA_NAME_user\n+\/\/ directory.\n+static const char VAR_FOLDERS[] = \"\/var\/folders\/\";\n+int os::Bsd::get_user_tmp_dir_macos(const char* user, int vmid, char* output_path, int output_size) {\n+\n+  \/\/ read the var\/folders directory\n+  DIR* varfolders_dir = os::opendir(VAR_FOLDERS);\n+  if (varfolders_dir != nullptr) {\n+\n+    \/\/ var\/folders directory contains 2-characters subdirectories (buckets)\n+    struct dirent* bucket_de;\n+\n+    \/\/ loop until the PERFDATA_NAME_user directory has been found\n+    while ((bucket_de = os::readdir(varfolders_dir)) != nullptr) {\n+      \/\/ skip over files and special \".\" and \"..\"\n+      if (bucket_de->d_type != DT_DIR || bucket_de->d_name[0] == '.') {\n+        continue;\n+      }\n+      \/\/ absolute path to the bucket\n+      char bucket[PATH_MAX];\n+      int b = os::snprintf(bucket, PATH_MAX, \"%s%s\/\", VAR_FOLDERS, bucket_de->d_name);\n+\n+      \/\/ the total length of the absolute path must not exceed the buffer size\n+      if (b >= PATH_MAX || b < 0) {\n+        continue;\n+      }\n+      \/\/ each bucket contains next level subdirectories\n+      DIR* bucket_dir = os::opendir(bucket);\n+      if (bucket_dir == nullptr) {\n+        continue;\n+      }\n+      \/\/ read each subdirectory, skipping over regular files\n+      struct dirent* subbucket_de;\n+      while ((subbucket_de = os::readdir(bucket_dir)) != nullptr) {\n+        if (subbucket_de->d_type != DT_DIR || subbucket_de->d_name[0] == '.') {\n+          continue;\n+        }\n+        \/\/ If the PERFDATA_NAME_user directory exists in the T subdirectory,\n+        \/\/ this means the subdirectory is the temporary directory of the user.\n+        char perfdata_path[PATH_MAX];\n+        int p = os::snprintf(perfdata_path, PATH_MAX, \"%s%s\/T\/%s_%s\/\", bucket, subbucket_de->d_name, PERFDATA_NAME, user);\n+\n+        \/\/ the total length must not exceed the output buffer size\n+        if (p >= PATH_MAX || p < 0) {\n+          continue;\n+        }\n+        \/\/ check if the subdirectory exists\n+        if (os::file_exists(perfdata_path)) {\n+          \/\/ the return value of snprintf is not checked for the second time\n+          return os::snprintf(output_path, output_size, \"%s%s\/T\", bucket, subbucket_de->d_name);\n+        }\n+      }\n+      os::closedir(bucket_dir);\n+    }\n+    os::closedir(varfolders_dir);\n+  }\n+  return -1;\n+}\n+#endif\n+\n@@ -1015,1 +1099,0 @@\n-#ifndef IA32\n@@ -1038,4 +1121,0 @@\n-  \/\/ This workaround is ineffective on IA32 systems because the MXCSR\n-  \/\/ register (which controls flush-to-zero mode) is not stored in the\n-  \/\/ legacy fenv.\n-\n@@ -1045,1 +1124,2 @@\n-#endif \/\/ IA32\n+\n+  Events::log_dll_message(nullptr, \"Attempting to load shared library %s\", filename);\n@@ -1065,1 +1145,0 @@\n-#ifndef IA32\n@@ -1090,1 +1169,0 @@\n-#endif \/\/ IA32\n@@ -1119,1 +1197,4 @@\n-\n+  if (ebuf == nullptr || ebuflen < 1) {\n+    \/\/ no error reporting requested\n+    return nullptr;\n+  }\n@@ -1196,3 +1277,1 @@\n-  #if  (defined IA32)\n-  static  Elf32_Half running_arch_code=EM_386;\n-  #elif   (defined AMD64)\n+  #if    (defined AMD64)\n@@ -1220,1 +1299,1 @@\n-         IA32, AMD64, __powerpc__, ARM, S390, ALPHA, MIPS, MIPSEL, PARISC, M68K\n+         AMD64, __powerpc__, ARM, S390, ALPHA, MIPS, MIPSEL, PARISC, M68K\n@@ -1248,1 +1327,1 @@\n-    ::snprintf(diag_msg_buf, diag_msg_max_length-1,\" (Possible cause: endianness mismatch)\");\n+    os::snprintf_checked(diag_msg_buf, diag_msg_max_length-1,\" (Possible cause: endianness mismatch)\");\n@@ -1254,1 +1333,1 @@\n-    ::snprintf(diag_msg_buf, diag_msg_max_length-1,\" (Possible cause: architecture word width mismatch)\");\n+    os::snprintf_checked(diag_msg_buf, diag_msg_max_length-1,\" (Possible cause: architecture word width mismatch)\");\n@@ -1261,3 +1340,3 @@\n-      ::snprintf(diag_msg_buf, diag_msg_max_length-1,\n-                 \" (Possible cause: can't load %s-bit .so on a %s-bit platform)\",\n-                 lib_arch.name, arch_array[running_arch_index].name);\n+      os::snprintf_checked(diag_msg_buf, diag_msg_max_length-1,\n+                           \" (Possible cause: can't load %s-bit .so on a %s-bit platform)\",\n+                           lib_arch.name, arch_array[running_arch_index].name);\n@@ -1265,4 +1344,4 @@\n-      ::snprintf(diag_msg_buf, diag_msg_max_length-1,\n-                 \" (Possible cause: can't load this .so (machine code=0x%x) on a %s-bit platform)\",\n-                 lib_arch.code,\n-                 arch_array[running_arch_index].name);\n+      os::snprintf_checked(diag_msg_buf, diag_msg_max_length-1,\n+                           \" (Possible cause: can't load this .so (machine code=0x%x) on a %s-bit platform)\",\n+                           lib_arch.code,\n+                           arch_array[running_arch_index].name);\n@@ -1370,1 +1449,1 @@\n-      snprintf(buf, buflen, \"%s %s, macOS %s\", os, release, osproductversion);\n+      os::snprintf_checked(buf, buflen, \"%s %s, macOS %s\", os, release, osproductversion);\n@@ -1372,1 +1451,1 @@\n-      snprintf(buf, buflen, \"%s %s, macOS %s (%s)\", os, release, osproductversion, build);\n+      os::snprintf_checked(buf, buflen, \"%s %s, macOS %s (%s)\", os, release, osproductversion, build);\n@@ -1376,1 +1455,1 @@\n-  snprintf(buf, buflen, \"%s %s\", os, release);\n+  os::snprintf_checked(buf, buflen, \"%s %s\", os, release);\n@@ -1453,1 +1532,1 @@\n-    snprintf(buf, buflen, \"\\\"%s\\\" %s (EMULATED) %d MHz\", model, machine, mhz);\n+    os::snprintf_checked(buf, buflen, \"\\\"%s\\\" %s (EMULATED) %d MHz\", model, machine, mhz);\n@@ -1455,1 +1534,1 @@\n-    NOT_AARCH64(snprintf(buf, buflen, \"\\\"%s\\\" %s %d MHz\", model, machine, mhz));\n+    NOT_AARCH64(os::snprintf_checked(buf, buflen, \"\\\"%s\\\" %s %d MHz\", model, machine, mhz));\n@@ -1457,1 +1536,1 @@\n-    AARCH64_ONLY(snprintf(buf, buflen, \"\\\"%s\\\" %s\", model, machine));\n+    AARCH64_ONLY(os::snprintf_checked(buf, buflen, \"\\\"%s\\\" %s\", model, machine));\n@@ -1460,1 +1539,1 @@\n-  snprintf(buf, buflen, \"\\\"%s\\\" %s %d MHz\", model, machine, mhz);\n+  os::snprintf_checked(buf, buflen, \"\\\"%s\\\" %s %d MHz\", model, machine, mhz);\n@@ -1470,5 +1549,7 @@\n-\n-  st->print(\", physical \" UINT64_FORMAT \"k\",\n-            os::physical_memory() >> 10);\n-  st->print(\"(\" UINT64_FORMAT \"k free)\",\n-            os::available_memory() >> 10);\n+  physical_memory_size_type phys_mem = os::physical_memory();\n+  st->print(\", physical \" PHYS_MEM_TYPE_FORMAT \"k\",\n+            phys_mem >> 10);\n+  physical_memory_size_type avail_mem = 0;\n+  (void)os::available_memory(avail_mem);\n+  st->print(\"(\" PHYS_MEM_TYPE_FORMAT \"k free)\",\n+            avail_mem >> 10);\n@@ -1488,77 +1569,0 @@\n-static char saved_jvm_path[MAXPATHLEN] = {0};\n-\n-\/\/ Find the full path to the current module, libjvm\n-void os::jvm_path(char *buf, jint buflen) {\n-  \/\/ Error checking.\n-  if (buflen < MAXPATHLEN) {\n-    assert(false, \"must use a large-enough buffer\");\n-    buf[0] = '\\0';\n-    return;\n-  }\n-  \/\/ Lazy resolve the path to current module.\n-  if (saved_jvm_path[0] != 0) {\n-    strcpy(buf, saved_jvm_path);\n-    return;\n-  }\n-\n-  char dli_fname[MAXPATHLEN];\n-  dli_fname[0] = '\\0';\n-  bool ret = dll_address_to_library_name(\n-                                         CAST_FROM_FN_PTR(address, os::jvm_path),\n-                                         dli_fname, sizeof(dli_fname), nullptr);\n-  assert(ret, \"cannot locate libjvm\");\n-  char *rp = nullptr;\n-  if (ret && dli_fname[0] != '\\0') {\n-    rp = os::realpath(dli_fname, buf, buflen);\n-  }\n-  if (rp == nullptr) {\n-    return;\n-  }\n-\n-  \/\/ If executing unit tests we require JAVA_HOME to point to the real JDK.\n-  if (Arguments::executing_unit_tests()) {\n-    \/\/ Look for JAVA_HOME in the environment.\n-    char* java_home_var = ::getenv(\"JAVA_HOME\");\n-    if (java_home_var != nullptr && java_home_var[0] != 0) {\n-\n-      \/\/ Check the current module name \"libjvm\"\n-      const char* p = strrchr(buf, '\/');\n-      assert(strstr(p, \"\/libjvm\") == p, \"invalid library name\");\n-\n-      stringStream ss(buf, buflen);\n-      rp = os::realpath(java_home_var, buf, buflen);\n-      if (rp == nullptr) {\n-        return;\n-      }\n-\n-      assert((int)strlen(buf) < buflen, \"Ran out of buffer space\");\n-      \/\/ Add the appropriate library and JVM variant subdirs\n-      ss.print(\"%s\/lib\/%s\", buf, Abstract_VM_Version::vm_variant());\n-\n-      if (0 != access(buf, F_OK)) {\n-        ss.reset();\n-        ss.print(\"%s\/lib\", buf);\n-      }\n-\n-      \/\/ If the path exists within JAVA_HOME, add the JVM library name\n-      \/\/ to complete the path to JVM being overridden.  Otherwise fallback\n-      \/\/ to the path to the current library.\n-      if (0 == access(buf, F_OK)) {\n-        \/\/ Use current module name \"libjvm\"\n-        ss.print(\"\/libjvm%s\", JNI_LIB_SUFFIX);\n-        assert(strcmp(buf + strlen(buf) - strlen(JNI_LIB_SUFFIX), JNI_LIB_SUFFIX) == 0,\n-               \"buf has been truncated\");\n-      } else {\n-        \/\/ Fall back to path of current library\n-        rp = os::realpath(dli_fname, buf, buflen);\n-        if (rp == nullptr) {\n-          return;\n-        }\n-      }\n-    }\n-  }\n-\n-  strncpy(saved_jvm_path, buf, MAXPATHLEN);\n-  saved_jvm_path[MAXPATHLEN - 1] = '\\0';\n-}\n-\n@@ -1669,0 +1673,3 @@\n+void os::numa_set_thread_affinity(Thread *thread, int node) {\n+}\n+\n@@ -1675,2 +1682,0 @@\n-bool os::numa_topology_changed()   { return false; }\n-\n@@ -2211,1 +2216,1 @@\n-  int processor_id = Atomic::load(&processor_id_map[apic_id]);\n+  int processor_id = AtomicAccess::load(&processor_id_map[apic_id]);\n@@ -2215,1 +2220,1 @@\n-    processor_id = Atomic::cmpxchg(&processor_id_map[apic_id], processor_id_unassigned, processor_id_assigning);\n+    processor_id = AtomicAccess::cmpxchg(&processor_id_map[apic_id], processor_id_unassigned, processor_id_assigning);\n@@ -2217,2 +2222,2 @@\n-      processor_id = Atomic::fetch_then_add(&processor_id_next, 1) % os::processor_count();\n-      Atomic::store(&processor_id_map[apic_id], processor_id);\n+      processor_id = AtomicAccess::fetch_then_add(&processor_id_next, 1) % os::processor_count();\n+      AtomicAccess::store(&processor_id_map[apic_id], processor_id);\n@@ -2239,1 +2244,1 @@\n-    snprintf(buf, sizeof(buf), \"Java: %s\", name);\n+    (void) os::snprintf(buf, sizeof(buf), \"Java: %s\", name);\n@@ -2334,2 +2339,1 @@\n-  \/\/ appropriate file descriptors (e.g. as we do in closeDescriptors in\n-  \/\/ UNIXProcess.c), and this in turn might:\n+  \/\/ appropriate file descriptors, and this in turn might:\n@@ -2363,1 +2367,1 @@\n-        errno = EISDIR;\n+        errno = EISDIR;\n@@ -2574,1 +2578,1 @@\n-      snprintf(ebuf, ebuflen - 1, \"%s\", error_report);\n+      os::snprintf_checked(ebuf, ebuflen, \"%s\", error_report);\n","filename":"src\/hotspot\/os\/bsd\/os_bsd.cpp","additions":155,"deletions":151,"binary":false,"changes":306,"status":"modified"},{"patch":"@@ -25,2 +25,1 @@\n-#include <string.h>\n-\n+#include \"classfile\/classLoader.hpp\"\n@@ -28,0 +27,2 @@\n+#include \"logging\/log.hpp\"\n+#include \"logging\/logConfiguration.hpp\"\n@@ -29,1 +30,0 @@\n-#include \"runtime\/crac_structs.hpp\"\n@@ -31,0 +31,1 @@\n+#include \"runtime\/crac_structs.hpp\"\n@@ -32,4 +33,0 @@\n-#include \"utilities\/growableArray.hpp\"\n-#include \"logging\/log.hpp\"\n-#include \"logging\/logConfiguration.hpp\"\n-#include \"classfile\/classLoader.hpp\"\n@@ -37,0 +34,1 @@\n+#include \"utilities\/growableArray.hpp\"\n@@ -39,0 +37,1 @@\n+#include <string.h>\n@@ -111,1 +110,1 @@\n-  snprintf(fdpath, sizeof(fdpath), \"\/proc\/self\/fd\/%d\", fd);\n+  os::snprintf_checked(fdpath, sizeof(fdpath), \"\/proc\/self\/fd\/%d\", fd);\n@@ -280,1 +279,1 @@\n-        snprintf(detailsbuf + len, sizeof(detailsbuf) - len, \",port=%d\", (int)ntohs(sa.sin_port));\n+        os::snprintf_checked(detailsbuf + len, sizeof(detailsbuf) - len, \",port=%d\", (int)ntohs(sa.sin_port));\n@@ -345,1 +344,1 @@\n-    int len = snprintf(msg, buflen, \"FD fd=%d type=%s path=%s\", fd, type, detailsbuf);\n+    int len = os::snprintf(msg, buflen, \"FD fd=%d type=%s path=%s\", fd, type, detailsbuf);\n","filename":"src\/hotspot\/os\/linux\/crac_linux.cpp","additions":9,"deletions":10,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -38,3 +38,0 @@\n-  product(bool, UseOprofile, false,                                     \\\n-        \"(Deprecated) enable support for Oprofile profiler\")            \\\n-                                                                        \\\n@@ -98,0 +95,5 @@\n+  develop(intx, CompileTaskTimeout, 0,                                  \\\n+          \"Set the timeout for compile tasks' CPU time in milliseconds.\"\\\n+          \" 0 = no timeout (default)\")                                  \\\n+          range(0,1000000)                                              \\\n+                                                                        \\\n","filename":"src\/hotspot\/os\/linux\/globals_linux.hpp","additions":6,"deletions":4,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2026, Oracle and\/or its affiliates. All rights reserved.\n@@ -32,0 +32,1 @@\n+#include \"cppstdlib\/cstdlib.hpp\"\n@@ -41,1 +42,0 @@\n-#include \"osContainer_linux.hpp\"\n@@ -44,0 +44,1 @@\n+#include \"osContainer_linux.hpp\"\n@@ -47,1 +48,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -87,10 +88,1 @@\n-\/\/ put OS-includes here\n-# include <arpa\/inet.h>\n-# include <stdlib.h>\n-# include <sys\/types.h>\n-# include <sys\/mman.h>\n-# include <sys\/select.h>\n-# include <sys\/sendfile.h>\n-# include <sys\/sysmacros.h>\n-# include <pthread.h>\n-# include <signal.h>\n+# include <dlfcn.h>\n@@ -100,0 +92,1 @@\n+# include <fcntl.h>\n@@ -101,1 +94,8 @@\n-# include <dlfcn.h>\n+# include <inttypes.h>\n+# include <link.h>\n+# include <linux\/elf-em.h>\n+# include <poll.h>\n+# include <pthread.h>\n+# include <pwd.h>\n+# include <signal.h>\n+# include <stdint.h>\n@@ -103,1 +103,5 @@\n-# include <unistd.h>\n+# include <string.h>\n+# include <sys\/ioctl.h>\n+# include <sys\/ipc.h>\n+# include <sys\/mman.h>\n+# include <sys\/prctl.h>\n@@ -105,1 +109,3 @@\n-# include <pthread.h>\n+# include <sys\/select.h>\n+# include <sys\/sendfile.h>\n+# include <sys\/socket.h>\n@@ -107,0 +113,1 @@\n+# include <sys\/sysinfo.h>\n@@ -109,0 +116,1 @@\n+# include <sys\/types.h>\n@@ -110,13 +118,1 @@\n-# include <sys\/socket.h>\n-# include <pwd.h>\n-# include <poll.h>\n-# include <string.h>\n-# include <sys\/sysinfo.h>\n-# include <sys\/ipc.h>\n-# include <link.h>\n-# include <stdint.h>\n-# include <inttypes.h>\n-# include <sys\/ioctl.h>\n-# include <libgen.h>\n-# include <linux\/elf-em.h>\n-# include <sys\/prctl.h>\n+# include <unistd.h>\n@@ -164,1 +160,1 @@\n-julong os::Linux::_physical_memory = 0;\n+physical_memory_size_type os::Linux::_physical_memory = 0;\n@@ -169,3 +165,0 @@\n-int (*os::Linux::_pthread_getcpuclockid)(pthread_t, clockid_t *) = nullptr;\n-int (*os::Linux::_pthread_setname_np)(pthread_t, const char*) = nullptr;\n-bool os::Linux::_supports_fast_thread_cpu_time = false;\n@@ -226,11 +219,4 @@\n-julong os::Linux::available_memory_in_container() {\n-  julong avail_mem = static_cast<julong>(-1L);\n-  if (OSContainer::is_containerized()) {\n-    jlong mem_limit = OSContainer::memory_limit_in_bytes();\n-    jlong mem_usage;\n-    if (mem_limit > 0 && (mem_usage = OSContainer::memory_usage_in_bytes()) < 1) {\n-      log_debug(os, container)(\"container memory usage failed: \" JLONG_FORMAT \", using host value\", mem_usage);\n-    }\n-    if (mem_limit > 0 && mem_usage > 0) {\n-      avail_mem = mem_limit > mem_usage ? (julong)mem_limit - (julong)mem_usage : 0;\n-    }\n+bool os::available_memory(physical_memory_size_type& value) {\n+  if (OSContainer::is_containerized() && OSContainer::available_memory_in_bytes(value)) {\n+    log_trace(os)(\"available container memory: \" PHYS_MEM_TYPE_FORMAT, value);\n+    return true;\n@@ -238,4 +224,1 @@\n-  return avail_mem;\n-}\n-julong os::available_memory() {\n-  return Linux::available_memory();\n+  return Linux::available_memory(value);\n@@ -245,6 +228,2 @@\n-julong os::Linux::available_memory() {\n-  julong avail_mem = available_memory_in_container();\n-  if (avail_mem != static_cast<julong>(-1L)) {\n-    log_trace(os)(\"available container memory: \" JULONG_FORMAT, avail_mem);\n-    return avail_mem;\n-  }\n+bool os::Linux::available_memory(physical_memory_size_type& value) {\n+  physical_memory_size_type avail_mem = 0;\n@@ -252,0 +231,1 @@\n+  bool found_available_mem = false;\n@@ -256,1 +236,1 @@\n-      if (fscanf(fp, \"MemAvailable: \" JULONG_FORMAT \" kB\", &avail_mem) == 1) {\n+      if (fscanf(fp, \"MemAvailable: \" PHYS_MEM_TYPE_FORMAT \" kB\", &avail_mem) == 1) {\n@@ -258,0 +238,1 @@\n+        found_available_mem = true;\n@@ -263,2 +244,8 @@\n-  if (avail_mem == static_cast<julong>(-1L)) {\n-    avail_mem = free_memory();\n+  \/\/ Only enter the free memory block if we\n+  \/\/ haven't found the available memory\n+  if (!found_available_mem) {\n+    physical_memory_size_type free_mem = 0;\n+    if (!free_memory(free_mem)) {\n+      return false;\n+    }\n+    avail_mem = free_mem;\n@@ -266,2 +253,3 @@\n-  log_trace(os)(\"available memory: \" JULONG_FORMAT, avail_mem);\n-  return avail_mem;\n+  log_trace(os)(\"available memory: \" PHYS_MEM_TYPE_FORMAT, avail_mem);\n+  value = avail_mem;\n+  return true;\n@@ -270,2 +258,7 @@\n-julong os::free_memory() {\n-  return Linux::free_memory();\n+bool os::free_memory(physical_memory_size_type& value) {\n+  if (OSContainer::is_containerized() && OSContainer::available_memory_in_bytes(value)) {\n+    log_trace(os)(\"free container memory: \" PHYS_MEM_TYPE_FORMAT, value);\n+    return true;\n+  }\n+\n+  return Linux::free_memory(value);\n@@ -274,1 +267,1 @@\n-julong os::Linux::free_memory() {\n+bool os::Linux::free_memory(physical_memory_size_type& value) {\n@@ -277,9 +270,8 @@\n-  julong free_mem = available_memory_in_container();\n-  if (free_mem != static_cast<julong>(-1L)) {\n-    log_trace(os)(\"free container memory: \" JULONG_FORMAT, free_mem);\n-    return free_mem;\n-  }\n-  sysinfo(&si);\n-  free_mem = (julong)si.freeram * si.mem_unit;\n-  log_trace(os)(\"free memory: \" JULONG_FORMAT, free_mem);\n-  return free_mem;\n+  int ret = sysinfo(&si);\n+  if (ret != 0) {\n+    return false;\n+  }\n+  physical_memory_size_type free_mem = (physical_memory_size_type)si.freeram * si.mem_unit;\n+  log_trace(os)(\"free memory: \" PHYS_MEM_TYPE_FORMAT, free_mem);\n+  value = free_mem;\n+  return true;\n@@ -289,1 +281,1 @@\n-jlong os::total_swap_space() {\n+bool os::total_swap_space(physical_memory_size_type& value) {\n@@ -291,2 +283,9 @@\n-    if (OSContainer::memory_limit_in_bytes() > 0) {\n-      return (jlong)(OSContainer::memory_and_swap_limit_in_bytes() - OSContainer::memory_limit_in_bytes());\n+    physical_memory_size_type mem_swap_limit = value_unlimited;\n+    physical_memory_size_type memory_limit = value_unlimited;\n+    if (OSContainer::memory_and_swap_limit_in_bytes(mem_swap_limit) &&\n+        OSContainer::memory_limit_in_bytes(memory_limit)) {\n+      if (memory_limit != value_unlimited && mem_swap_limit != value_unlimited &&\n+          mem_swap_limit >= memory_limit \/* ensure swap is >= 0 *\/) {\n+        value = mem_swap_limit - memory_limit;\n+        return true;\n+      }\n@@ -294,7 +293,2 @@\n-  }\n-  struct sysinfo si;\n-  int ret = sysinfo(&si);\n-  if (ret != 0) {\n-    return -1;\n-  }\n-  return  (jlong)(si.totalswap * si.mem_unit);\n+  } \/\/ fallback to the host swap space if the container returned unlimited\n+  return Linux::host_swap(value);\n@@ -303,1 +297,1 @@\n-static jlong host_free_swap() {\n+static bool host_free_swap_f(physical_memory_size_type& value) {\n@@ -307,1 +301,2 @@\n-    return -1;\n+    assert(false, \"sysinfo failed in host_free_swap_f(): %s\", os::strerror(errno));\n+    return false;\n@@ -309,1 +304,2 @@\n-  return (jlong)(si.freeswap * si.mem_unit);\n+  value = static_cast<physical_memory_size_type>(si.freeswap) * si.mem_unit;\n+  return true;\n@@ -312,1 +308,1 @@\n-jlong os::free_swap_space() {\n+bool os::free_swap_space(physical_memory_size_type& value) {\n@@ -315,2 +311,6 @@\n-  jlong host_free_swap_val = MIN2(os::total_swap_space(), host_free_swap());\n-  assert(host_free_swap_val >= 0, \"sysinfo failed?\");\n+  physical_memory_size_type total_swap_space = 0;\n+  physical_memory_size_type host_free_swap = 0;\n+  if (!os::total_swap_space(total_swap_space) || !host_free_swap_f(host_free_swap)) {\n+    return false;\n+  }\n+  physical_memory_size_type host_free_swap_val = MIN2(total_swap_space, host_free_swap);\n@@ -318,16 +318,2 @@\n-    jlong mem_swap_limit = OSContainer::memory_and_swap_limit_in_bytes();\n-    jlong mem_limit = OSContainer::memory_limit_in_bytes();\n-    if (mem_swap_limit >= 0 && mem_limit >= 0) {\n-      jlong delta_limit = mem_swap_limit - mem_limit;\n-      if (delta_limit <= 0) {\n-        return 0;\n-      }\n-      jlong mem_swap_usage = OSContainer::memory_and_swap_usage_in_bytes();\n-      jlong mem_usage = OSContainer::memory_usage_in_bytes();\n-      if (mem_swap_usage > 0 && mem_usage > 0) {\n-        jlong delta_usage = mem_swap_usage - mem_usage;\n-        if (delta_usage >= 0) {\n-          jlong free_swap = delta_limit - delta_usage;\n-          return free_swap >= 0 ? free_swap : 0;\n-        }\n-      }\n+    if (OSContainer::available_swap_in_bytes(host_free_swap_val, value)) {\n+      return true;\n@@ -335,4 +321,3 @@\n-    \/\/ unlimited or not supported. Fall through to return host value\n-    log_trace(os,container)(\"os::free_swap_space: container_swap_limit=\" JLONG_FORMAT\n-                            \" container_mem_limit=\" JLONG_FORMAT \" returning host value: \" JLONG_FORMAT,\n-                            mem_swap_limit, mem_limit, host_free_swap_val);\n+    \/\/ Fall through to use host value\n+    log_trace(os,container)(\"os::free_swap_space: containerized value unavailable\"\n+                            \" returning host value: \" PHYS_MEM_TYPE_FORMAT, host_free_swap_val);\n@@ -340,1 +325,2 @@\n-  return host_free_swap_val;\n+  value = host_free_swap_val;\n+  return true;\n@@ -343,2 +329,1 @@\n-julong os::physical_memory() {\n-  jlong phys_mem = 0;\n+physical_memory_size_type os::physical_memory() {\n@@ -346,3 +331,3 @@\n-    jlong mem_limit;\n-    if ((mem_limit = OSContainer::memory_limit_in_bytes()) > 0) {\n-      log_trace(os)(\"total container memory: \" JLONG_FORMAT, mem_limit);\n+    physical_memory_size_type mem_limit = value_unlimited;\n+    if (OSContainer::memory_limit_in_bytes(mem_limit) && mem_limit != value_unlimited) {\n+      log_trace(os)(\"total container memory: \" PHYS_MEM_TYPE_FORMAT, mem_limit);\n@@ -353,2 +338,2 @@\n-  phys_mem = Linux::physical_memory();\n-  log_trace(os)(\"total system memory: \" JLONG_FORMAT, phys_mem);\n+  physical_memory_size_type phys_mem = Linux::physical_memory();\n+  log_trace(os)(\"total system memory: \" PHYS_MEM_TYPE_FORMAT, phys_mem);\n@@ -358,0 +343,4 @@\n+\/\/ Returns the resident set size (RSS) of the process.\n+\/\/ Falls back to using VmRSS from \/proc\/self\/status if \/proc\/self\/smaps_rollup is unavailable.\n+\/\/ Note: On kernels with memory cgroups or shared memory, VmRSS may underreport RSS.\n+\/\/ Users requiring accurate RSS values should be aware of this limitation.\n@@ -360,3 +349,8 @@\n-  os::Linux::meminfo_t info;\n-  if (os::Linux::query_process_memory_info(&info)) {\n-    size = info.vmrss * K;\n+  os::Linux::accurate_meminfo_t accurate_info;\n+  if (os::Linux::query_accurate_process_memory_info(&accurate_info) && accurate_info.rss != -1) {\n+    size = accurate_info.rss * K;\n+  } else {\n+    os::Linux::meminfo_t info;\n+    if (os::Linux::query_process_memory_info(&info)) {\n+      size = info.vmrss * K;\n+    }\n@@ -478,1 +472,1 @@\n-\/\/ i386: 224, amd64: 186, sparc: 143\n+\/\/ i386: 224, amd64: 186\n@@ -483,2 +477,0 @@\n-  #elif defined(__sparc__)\n-    #define SYS_gettid 143\n@@ -502,1 +494,1 @@\n-julong os::Linux::host_swap() {\n+bool os::Linux::host_swap(physical_memory_size_type& value) {\n@@ -504,2 +496,7 @@\n-  sysinfo(&si);\n-  return (julong)(si.totalswap * si.mem_unit);\n+  int ret = sysinfo(&si);\n+  if (ret != 0) {\n+    assert(false, \"sysinfo failed in host_swap(): %s\", os::strerror(errno));\n+    return false;\n+  }\n+  value = static_cast<physical_memory_size_type>(si.totalswap) * si.mem_unit;\n+  return true;\n@@ -534,1 +531,1 @@\n-  _physical_memory = (julong)sysconf(_SC_PHYS_PAGES) * (julong)sysconf(_SC_PAGESIZE);\n+  _physical_memory = static_cast<physical_memory_size_type>(sysconf(_SC_PHYS_PAGES)) * static_cast<physical_memory_size_type>(sysconf(_SC_PAGESIZE));\n@@ -842,6 +839,0 @@\n-  if (UseNUMA) {\n-    int lgrp_id = os::numa_get_group_id();\n-    if (lgrp_id != -1) {\n-      thread->set_lgrp_id(lgrp_id);\n-    }\n-  }\n@@ -1173,7 +1164,0 @@\n-  if (UseNUMA) {\n-    int lgrp_id = os::numa_get_group_id();\n-    if (lgrp_id != -1) {\n-      thread->set_lgrp_id(lgrp_id);\n-    }\n-  }\n-\n@@ -1498,36 +1482,0 @@\n-\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-\/\/ time support\n-double os::elapsedVTime() {\n-  struct rusage usage;\n-  int retval = getrusage(RUSAGE_THREAD, &usage);\n-  if (retval == 0) {\n-    return (double) (usage.ru_utime.tv_sec + usage.ru_stime.tv_sec) + (double) (usage.ru_utime.tv_usec + usage.ru_stime.tv_usec) \/ (1000 * 1000);\n-  } else {\n-    \/\/ better than nothing, but not much\n-    return elapsedTime();\n-  }\n-}\n-\n-void os::Linux::fast_thread_clock_init() {\n-  clockid_t clockid;\n-  struct timespec tp;\n-  int (*pthread_getcpuclockid_func)(pthread_t, clockid_t *) =\n-      (int(*)(pthread_t, clockid_t *)) dlsym(RTLD_DEFAULT, \"pthread_getcpuclockid\");\n-\n-  \/\/ Switch to using fast clocks for thread cpu time if\n-  \/\/ the clock_getres() returns 0 error code.\n-  \/\/ Note, that some kernels may support the current thread\n-  \/\/ clock (CLOCK_THREAD_CPUTIME_ID) but not the clocks\n-  \/\/ returned by the pthread_getcpuclockid().\n-  \/\/ If the fast POSIX clocks are supported then the clock_getres()\n-  \/\/ must return at least tp.tv_sec == 0 which means a resolution\n-  \/\/ better than 1 sec. This is extra check for reliability.\n-\n-  if (pthread_getcpuclockid_func &&\n-      pthread_getcpuclockid_func(_main_thread, &clockid) == 0 &&\n-      clock_getres(clockid, &tp) == 0 && tp.tv_sec == 0) {\n-    _supports_fast_thread_cpu_time = true;\n-    _pthread_getcpuclockid = pthread_getcpuclockid_func;\n-  }\n-}\n-\n@@ -1716,0 +1664,5 @@\n+  if (ebuf == nullptr || ebuflen < 1) {\n+    \/\/ no error reporting requested\n+    return nullptr;\n+  }\n+\n@@ -1874,3 +1827,3 @@\n-      ::snprintf(diag_msg_buf, diag_msg_max_length-1,\n-                 \" (Possible cause: can't load %s .so on a %s platform)\",\n-                 lib_arch.name, arch_array[running_arch_index].name);\n+      os::snprintf_checked(diag_msg_buf, diag_msg_max_length-1,\n+                           \" (Possible cause: can't load %s .so on a %s platform)\",\n+                           lib_arch.name, arch_array[running_arch_index].name);\n@@ -1878,3 +1831,3 @@\n-      ::snprintf(diag_msg_buf, diag_msg_max_length-1,\n-                 \" (Possible cause: can't load this .so (machine code=0x%x) on a %s platform)\",\n-                 lib_arch.code, arch_array[running_arch_index].name);\n+      os::snprintf_checked(diag_msg_buf, diag_msg_max_length-1,\n+                           \" (Possible cause: can't load this .so (machine code=0x%x) on a %s platform)\",\n+                           lib_arch.code, arch_array[running_arch_index].name);\n@@ -1886,1 +1839,1 @@\n-    ::snprintf(diag_msg_buf, diag_msg_max_length-1, \" (Possible cause: endianness mismatch)\");\n+    os::snprintf_checked(diag_msg_buf, diag_msg_max_length-1, \" (Possible cause: endianness mismatch)\");\n@@ -1892,1 +1845,1 @@\n-    ::snprintf(diag_msg_buf, diag_msg_max_length-1, \" (Possible cause: invalid ELF file class)\");\n+    os::snprintf_checked(diag_msg_buf, diag_msg_max_length-1, \" (Possible cause: invalid ELF file class)\");\n@@ -1897,3 +1850,3 @@\n-    ::snprintf(diag_msg_buf, diag_msg_max_length-1,\n-               \" (Possible cause: architecture word width mismatch, can't load %d-bit .so on a %d-bit platform)\",\n-               (int) lib_arch.elf_class * 32, arch_array[running_arch_index].elf_class * 32);\n+    os::snprintf_checked(diag_msg_buf, diag_msg_max_length-1,\n+                         \" (Possible cause: architecture word width mismatch, can't load %d-bit .so on a %d-bit platform)\",\n+                         (int) lib_arch.elf_class * 32, arch_array[running_arch_index].elf_class * 32);\n@@ -1939,0 +1892,2 @@\n+  Events::log_dll_message(nullptr, \"Attempting to load shared library %s\", filename);\n+\n@@ -2367,0 +2322,31 @@\n+\/\/ Accurate memory information need Linux 4.14 or newer\n+bool os::Linux::query_accurate_process_memory_info(os::Linux::accurate_meminfo_t* info) {\n+  FILE* f = os::fopen(\"\/proc\/self\/smaps_rollup\", \"r\");\n+  if (f == nullptr) {\n+    return false;\n+  }\n+\n+  const size_t num_values = sizeof(os::Linux::accurate_meminfo_t) \/ sizeof(size_t);\n+  size_t num_found = 0;\n+  char buf[256];\n+  info->rss = info->pss = info->pssdirty = info->pssanon =\n+      info->pssfile = info->pssshmem = info->swap = info->swappss = -1;\n+\n+  while (::fgets(buf, sizeof(buf), f) != nullptr && num_found < num_values) {\n+    if ( (info->rss == -1        && sscanf(buf, \"Rss: %zd kB\", &info->rss) == 1) ||\n+         (info->pss == -1        && sscanf(buf, \"Pss: %zd kB\", &info->pss) == 1) ||\n+         (info->pssdirty == -1   && sscanf(buf, \"Pss_Dirty: %zd kB\", &info->pssdirty) == 1) ||\n+         (info->pssanon == -1    && sscanf(buf, \"Pss_Anon: %zd kB\", &info->pssanon) == 1) ||\n+         (info->pssfile == -1    && sscanf(buf, \"Pss_File: %zd kB\", &info->pssfile) == 1) ||\n+         (info->pssshmem == -1   && sscanf(buf, \"Pss_Shmem: %zd kB\", &info->pssshmem) == 1) ||\n+         (info->swap == -1       && sscanf(buf, \"Swap: %zd kB\", &info->swap) == 1) ||\n+         (info->swappss == -1    && sscanf(buf, \"SwapPss: %zd kB\", &info->swappss) == 1)\n+         )\n+    {\n+      num_found ++;\n+    }\n+  }\n+  fclose(f);\n+  return true;\n+}\n+\n@@ -2451,0 +2437,1 @@\n+  assert(ret == 0, \"sysinfo failed: %s\", os::strerror(errno));\n@@ -2462,1 +2449,1 @@\n-  st->print_cr(\"container_type: %s\", p_ct != nullptr ? p_ct : \"not supported\");\n+  OSContainer::print_container_metric(st, \"container_type\", p_ct != nullptr ? p_ct : \"not supported\");\n@@ -2465,1 +2452,1 @@\n-  st->print_cr(\"cpu_cpuset_cpus: %s\", p != nullptr ? p : \"not supported\");\n+  OSContainer::print_container_metric(st, \"cpu_cpuset_cpus\", p != nullptr ? p : \"not supported\");\n@@ -2469,1 +2456,1 @@\n-  st->print_cr(\"cpu_memory_nodes: %s\", p != nullptr ? p : \"not supported\");\n+  OSContainer::print_container_metric(st, \"cpu_memory_nodes\", p != nullptr ? p : \"not supported\");\n@@ -2472,3 +2459,4 @@\n-  int i = OSContainer::active_processor_count();\n-  st->print(\"active_processor_count: \");\n-  if (i > 0) {\n+  int i = -1;\n+  bool supported = OSContainer::active_processor_count(i);\n+  if (supported) {\n+    assert(i > 0, \"must be\");\n@@ -2476,1 +2464,1 @@\n-      st->print_cr(\"%d, but overridden by -XX:ActiveProcessorCount %d\", i, ActiveProcessorCount);\n+      OSContainer::print_container_metric(st, \"active_processor_count\", ActiveProcessorCount, \"(from -XX:ActiveProcessorCount)\");\n@@ -2478,1 +2466,1 @@\n-      st->print_cr(\"%d\", i);\n+      OSContainer::print_container_metric(st, \"active_processor_count\", i);\n@@ -2481,1 +2469,1 @@\n-    st->print_cr(\"not supported\");\n+    OSContainer::print_container_metric(st, \"active_processor_count\", \"not supported\");\n@@ -2484,4 +2472,4 @@\n-  i = OSContainer::cpu_quota();\n-  st->print(\"cpu_quota: \");\n-  if (i > 0) {\n-    st->print_cr(\"%d\", i);\n+\n+  supported = OSContainer::cpu_quota(i);\n+  if (supported && i > 0) {\n+    OSContainer::print_container_metric(st, \"cpu_quota\", i);\n@@ -2489,1 +2477,1 @@\n-    st->print_cr(\"%s\", i == OSCONTAINER_ERROR ? \"not supported\" : \"no quota\");\n+    OSContainer::print_container_metric(st, \"cpu_quota\", !supported ? \"not supported\" : \"no quota\");\n@@ -2492,4 +2480,3 @@\n-  i = OSContainer::cpu_period();\n-  st->print(\"cpu_period: \");\n-  if (i > 0) {\n-    st->print_cr(\"%d\", i);\n+  supported = OSContainer::cpu_period(i);\n+  if (supported && i > 0) {\n+    OSContainer::print_container_metric(st, \"cpu_period\", i);\n@@ -2497,1 +2484,1 @@\n-    st->print_cr(\"%s\", i == OSCONTAINER_ERROR ? \"not supported\" : \"no period\");\n+    OSContainer::print_container_metric(st, \"cpu_period\", !supported ? \"not supported\" : \"no period\");\n@@ -2500,4 +2487,3 @@\n-  i = OSContainer::cpu_shares();\n-  st->print(\"cpu_shares: \");\n-  if (i > 0) {\n-    st->print_cr(\"%d\", i);\n+  supported = OSContainer::cpu_shares(i);\n+  if (supported && i > 0) {\n+    OSContainer::print_container_metric(st, \"cpu_shares\", i);\n@@ -2505,1 +2491,1 @@\n-    st->print_cr(\"%s\", i == OSCONTAINER_ERROR ? \"not supported\" : \"no shares\");\n+    OSContainer::print_container_metric(st, \"cpu_shares\", !supported ? \"not supported\" : \"no shares\");\n@@ -2508,7 +2494,56 @@\n-  OSContainer::print_container_helper(st, OSContainer::memory_limit_in_bytes(), \"memory_limit_in_bytes\");\n-  OSContainer::print_container_helper(st, OSContainer::memory_and_swap_limit_in_bytes(), \"memory_and_swap_limit_in_bytes\");\n-  OSContainer::print_container_helper(st, OSContainer::memory_soft_limit_in_bytes(), \"memory_soft_limit_in_bytes\");\n-  OSContainer::print_container_helper(st, OSContainer::memory_usage_in_bytes(), \"memory_usage_in_bytes\");\n-  OSContainer::print_container_helper(st, OSContainer::memory_max_usage_in_bytes(), \"memory_max_usage_in_bytes\");\n-  OSContainer::print_container_helper(st, OSContainer::rss_usage_in_bytes(), \"rss_usage_in_bytes\");\n-  OSContainer::print_container_helper(st, OSContainer::cache_usage_in_bytes(), \"cache_usage_in_bytes\");\n+  uint64_t j = 0;\n+  supported = OSContainer::cpu_usage_in_micros(j);\n+  if (supported && j > 0) {\n+    OSContainer::print_container_metric(st, \"cpu_usage\", j, \"us\");\n+  } else {\n+    OSContainer::print_container_metric(st, \"cpu_usage\", !supported ? \"not supported\" : \"no usage\");\n+  }\n+\n+  MetricResult memory_limit;\n+  physical_memory_size_type val = value_unlimited;\n+  if (OSContainer::memory_limit_in_bytes(val)) {\n+    memory_limit.set_value(val);\n+  }\n+  MetricResult mem_swap_limit;\n+  val = value_unlimited;\n+  if (OSContainer::memory_and_swap_limit_in_bytes(val)) {\n+    mem_swap_limit.set_value(val);\n+  }\n+  MetricResult mem_soft_limit;\n+  val = value_unlimited;\n+  if (OSContainer::memory_soft_limit_in_bytes(val)) {\n+    mem_soft_limit.set_value(val);\n+  }\n+  MetricResult mem_throttle_limit;\n+  val = value_unlimited;\n+  if (OSContainer::memory_throttle_limit_in_bytes(val)) {\n+    mem_throttle_limit.set_value(val);\n+  }\n+  MetricResult mem_usage;\n+  val = 0;\n+  if (OSContainer::memory_usage_in_bytes(val)) {\n+    mem_usage.set_value(val);\n+  }\n+  MetricResult mem_max_usage;\n+  val = 0;\n+  if (OSContainer::memory_max_usage_in_bytes(val)) {\n+    mem_max_usage.set_value(val);\n+  }\n+  MetricResult rss_usage;\n+  val = 0;\n+  if (OSContainer::rss_usage_in_bytes(val)) {\n+    rss_usage.set_value(val);\n+  }\n+  MetricResult cache_usage;\n+  val = 0;\n+  if (OSContainer::cache_usage_in_bytes(val)) {\n+    cache_usage.set_value(val);\n+  }\n+  OSContainer::print_container_helper(st, memory_limit, \"memory_limit\");\n+  OSContainer::print_container_helper(st, mem_swap_limit, \"memory_and_swap_limit\");\n+  OSContainer::print_container_helper(st, mem_soft_limit, \"memory_soft_limit\");\n+  OSContainer::print_container_helper(st, mem_throttle_limit, \"memory_throttle_limit\");\n+  OSContainer::print_container_helper(st, mem_usage, \"memory_usage\");\n+  OSContainer::print_container_helper(st, mem_max_usage, \"memory_max_usage\");\n+  OSContainer::print_container_helper(st, rss_usage, \"rss_usage\");\n+  OSContainer::print_container_helper(st, cache_usage, \"cache_usage\");\n@@ -2518,4 +2553,3 @@\n-  jlong j = OSContainer::pids_max();\n-  st->print(\"maximum number of tasks: \");\n-  if (j > 0) {\n-    st->print_cr(JLONG_FORMAT, j);\n+  supported = OSContainer::pids_max(j);\n+  if (supported && j != value_unlimited) {\n+    OSContainer::print_container_metric(st, \"maximum number of tasks\", j);\n@@ -2523,1 +2557,1 @@\n-    st->print_cr(\"%s\", j == OSCONTAINER_ERROR ? \"not supported\" : \"unlimited\");\n+    OSContainer::print_container_metric(st, \"maximum number of tasks\", !supported ? \"not supported\" : \"unlimited\");\n@@ -2526,4 +2560,3 @@\n-  j = OSContainer::pids_current();\n-  st->print(\"current number of tasks: \");\n-  if (j > 0) {\n-    st->print_cr(JLONG_FORMAT, j);\n+  supported = OSContainer::pids_current(j);\n+  if (supported && j > 0) {\n+    OSContainer::print_container_metric(st, \"current number of tasks\", j);\n@@ -2531,3 +2564,1 @@\n-    if (j == OSCONTAINER_ERROR) {\n-      st->print_cr(\"not supported\");\n-    }\n+    OSContainer::print_container_metric(st, \"current number of tasks\", !supported ? \"not supported\" : \"no tasks\");\n@@ -2564,10 +2595,15 @@\n-  sysinfo(&si);\n-\n-  st->print(\", physical \" UINT64_FORMAT \"k\",\n-            os::physical_memory() >> 10);\n-  st->print(\"(\" UINT64_FORMAT \"k free)\",\n-            os::available_memory() >> 10);\n-  st->print(\", swap \" UINT64_FORMAT \"k\",\n-            ((jlong)si.totalswap * si.mem_unit) >> 10);\n-  st->print(\"(\" UINT64_FORMAT \"k free)\",\n-            ((jlong)si.freeswap * si.mem_unit) >> 10);\n+  int ret = sysinfo(&si);\n+  assert(ret == 0, \"sysinfo failed: %s\", os::strerror(errno));\n+  physical_memory_size_type phys_mem = physical_memory();\n+  st->print(\", physical \" PHYS_MEM_TYPE_FORMAT \"k\",\n+            phys_mem >> 10);\n+  physical_memory_size_type avail_mem = 0;\n+  (void)os::available_memory(avail_mem);\n+  st->print(\"(\" PHYS_MEM_TYPE_FORMAT \"k free)\",\n+            avail_mem >> 10);\n+  if (ret == 0) {\n+    st->print(\", swap \" UINT64_FORMAT \"k\",\n+              ((jlong)si.totalswap * si.mem_unit) >> 10);\n+    st->print(\"(\" UINT64_FORMAT \"k free)\",\n+              ((jlong)si.freeswap * si.mem_unit) >> 10);\n+  }\n@@ -2585,1 +2621,1 @@\n-#if defined(IA32) || defined(AMD64)\n+#if defined(AMD64)\n@@ -2630,4 +2666,4 @@\n-      snprintf(hbuf_level, 60, \"\/sys\/devices\/system\/cpu\/cpu0\/cache\/index%u\/level\", i);\n-      snprintf(hbuf_type, 60, \"\/sys\/devices\/system\/cpu\/cpu0\/cache\/index%u\/type\", i);\n-      snprintf(hbuf_size, 60, \"\/sys\/devices\/system\/cpu\/cpu0\/cache\/index%u\/size\", i);\n-      snprintf(hbuf_coherency_line_size, 80, \"\/sys\/devices\/system\/cpu\/cpu0\/cache\/index%u\/coherency_line_size\", i);\n+      os::snprintf_checked(hbuf_level, 60, \"\/sys\/devices\/system\/cpu\/cpu0\/cache\/index%u\/level\", i);\n+      os::snprintf_checked(hbuf_type, 60, \"\/sys\/devices\/system\/cpu\/cpu0\/cache\/index%u\/type\", i);\n+      os::snprintf_checked(hbuf_size, 60, \"\/sys\/devices\/system\/cpu\/cpu0\/cache\/index%u\/size\", i);\n+      os::snprintf_checked(hbuf_coherency_line_size, 80, \"\/sys\/devices\/system\/cpu\/cpu0\/cache\/index%u\/coherency_line_size\", i);\n@@ -2644,1 +2680,1 @@\n-#if defined(IA32) || defined(AMD64)\n+#if defined(AMD64)\n@@ -2697,1 +2733,1 @@\n-#if defined(AMD64) || defined(IA32) || defined(X32)\n+#if defined(AMD64)\n@@ -2705,2 +2741,0 @@\n-#elif defined(SPARC)\n-const char* search_string = \"cpu\";\n@@ -2750,2 +2784,0 @@\n-#elif defined(IA32)\n-  strncpy(cpuinfo, \"x86_32\", length);\n@@ -2758,2 +2790,0 @@\n-#elif defined(SPARC)\n-  strncpy(cpuinfo, \"sparcv9\", length);\n@@ -2767,71 +2797,0 @@\n-static char saved_jvm_path[MAXPATHLEN] = {0};\n-\n-\/\/ Find the full path to the current module, libjvm.so\n-void os::jvm_path(char *buf, jint buflen) {\n-  \/\/ Error checking.\n-  if (buflen < MAXPATHLEN) {\n-    assert(false, \"must use a large-enough buffer\");\n-    buf[0] = '\\0';\n-    return;\n-  }\n-  \/\/ Lazy resolve the path to current module.\n-  if (saved_jvm_path[0] != 0) {\n-    strcpy(buf, saved_jvm_path);\n-    return;\n-  }\n-\n-  char dli_fname[MAXPATHLEN];\n-  dli_fname[0] = '\\0';\n-  bool ret = dll_address_to_library_name(\n-                                         CAST_FROM_FN_PTR(address, os::jvm_path),\n-                                         dli_fname, sizeof(dli_fname), nullptr);\n-  assert(ret, \"cannot locate libjvm\");\n-  char *rp = nullptr;\n-  if (ret && dli_fname[0] != '\\0') {\n-    rp = os::realpath(dli_fname, buf, buflen);\n-  }\n-  if (rp == nullptr) {\n-    return;\n-  }\n-\n-  \/\/ If executing unit tests we require JAVA_HOME to point to the real JDK.\n-  if (Arguments::executing_unit_tests()) {\n-    \/\/ Look for JAVA_HOME in the environment.\n-    char* java_home_var = ::getenv(\"JAVA_HOME\");\n-    if (java_home_var != nullptr && java_home_var[0] != 0) {\n-\n-      \/\/ Check the current module name \"libjvm.so\".\n-      const char* p = strrchr(buf, '\/');\n-      if (p == nullptr) {\n-        return;\n-      }\n-      assert(strstr(p, \"\/libjvm\") == p, \"invalid library name\");\n-\n-      stringStream ss(buf, buflen);\n-      rp = os::realpath(java_home_var, buf, buflen);\n-      if (rp == nullptr) {\n-        return;\n-      }\n-\n-      assert((int)strlen(buf) < buflen, \"Ran out of buffer room\");\n-      ss.print(\"%s\/lib\", buf);\n-\n-      if (0 == access(buf, F_OK)) {\n-        \/\/ Use current module name \"libjvm.so\"\n-        ss.print(\"\/%s\/libjvm%s\", Abstract_VM_Version::vm_variant(), JNI_LIB_SUFFIX);\n-        assert(strcmp(buf + strlen(buf) - strlen(JNI_LIB_SUFFIX), JNI_LIB_SUFFIX) == 0,\n-               \"buf has been truncated\");\n-      } else {\n-        \/\/ Go back to path of .so\n-        rp = os::realpath(dli_fname, buf, buflen);\n-        if (rp == nullptr) {\n-          return;\n-        }\n-      }\n-    }\n-  }\n-\n-  strncpy(saved_jvm_path, buf, MAXPATHLEN);\n-  saved_jvm_path[MAXPATHLEN - 1] = '\\0';\n-}\n-\n@@ -2841,38 +2800,0 @@\n-\/\/ Rationale behind this function:\n-\/\/  current (Mon Apr 25 20:12:18 MSD 2005) oprofile drops samples without executable\n-\/\/  mapping for address (see lookup_dcookie() in the kernel module), thus we cannot get\n-\/\/  samples for JITted code. Here we create private executable mapping over the code cache\n-\/\/  and then we can use standard (well, almost, as mapping can change) way to provide\n-\/\/  info for the reporting script by storing timestamp and location of symbol\n-void linux_wrap_code(char* base, size_t size) {\n-  static volatile jint cnt = 0;\n-\n-  static_assert(sizeof(off_t) == 8, \"Expected Large File Support in this file\");\n-\n-  if (!UseOprofile) {\n-    return;\n-  }\n-\n-  char buf[PATH_MAX+1];\n-  int num = Atomic::add(&cnt, 1);\n-\n-  snprintf(buf, sizeof(buf), \"%s\/hs-vm-%d-%d\",\n-           os::get_temp_directory(), os::current_process_id(), num);\n-  unlink(buf);\n-\n-  int fd = ::open(buf, O_CREAT | O_RDWR, S_IRWXU);\n-\n-  if (fd != -1) {\n-    off_t rv = ::lseek(fd, size-2, SEEK_SET);\n-    if (rv != (off_t)-1) {\n-      if (::write(fd, \"\", 1) == 1) {\n-        mmap(base, size,\n-             PROT_READ|PROT_WRITE|PROT_EXEC,\n-             MAP_PRIVATE|MAP_FIXED|MAP_NORESERVE, fd, 0);\n-      }\n-    }\n-    ::close(fd);\n-    unlink(buf);\n-  }\n-}\n-\n@@ -3071,0 +2992,4 @@\n+void os::numa_set_thread_affinity(Thread* thread, int node) {\n+  Linux::numa_set_thread_affinity(thread->osthread()->thread_id(), node);\n+}\n+\n@@ -3091,2 +3016,0 @@\n-bool os::numa_topology_changed() { return false; }\n-\n@@ -3162,8 +3085,3 @@\n-#if defined(IA32)\n-  #ifndef SYS_getcpu\n-    #define SYS_getcpu 318\n-  #endif\n-  retval = syscall(SYS_getcpu, &cpu, nullptr, nullptr);\n-#elif defined(AMD64)\n-\/\/ Unfortunately we have to bring all these macros here from vsyscall.h\n-\/\/ to be able to compile on old linuxes.\n+#if defined(AMD64)\n+  \/\/ Unfortunately we have to bring all these macros here from vsyscall.h\n+  \/\/ to be able to compile on old linuxes.\n@@ -3260,0 +3178,2 @@\n+      set_numa_bitmask_clearbit(CAST_TO_FN_PTR(numa_bitmask_clearbit_func_t,\n+                                               libnuma_dlsym(handle, \"numa_bitmask_clearbit\")));\n@@ -3274,0 +3194,4 @@\n+      set_numa_sched_setaffinity(CAST_TO_FN_PTR(numa_sched_setaffinity_func_t,\n+                                                libnuma_v2_dlsym(handle, \"numa_sched_setaffinity\")));\n+      set_numa_allocate_cpumask(CAST_TO_FN_PTR(numa_allocate_cpumask_func_t,\n+                                               libnuma_v2_dlsym(handle, \"numa_allocate_cpumask\")));\n@@ -3279,0 +3203,1 @@\n+        set_numa_all_cpus_ptr((struct bitmask **)libnuma_dlsym(handle, \"numa_all_cpus_ptr\"));\n@@ -3282,0 +3207,1 @@\n+\n@@ -3285,0 +3211,1 @@\n+\n@@ -3288,0 +3215,5 @@\n+\n+        \/\/ Create a node -> CPUs mapping\n+        _numa_affinity_masks = new (mtInternal) GrowableArray<struct bitmask*>(0, mtInternal);\n+        build_numa_affinity_masks();\n+\n@@ -3323,0 +3255,36 @@\n+void os::Linux::build_numa_affinity_masks() {\n+  \/\/ We only build the affinity masks if running libnuma v2 (_numa_node_to_cpus_v2\n+  \/\/ is available) and we have the affinity mask of the process when it started.\n+  if (_numa_node_to_cpus_v2 == nullptr || _numa_all_cpus_ptr == nullptr) {\n+    return;\n+  }\n+\n+  \/\/ It's important that we respect any user configuration by removing the\n+  \/\/ CPUs we're not allowed to run on from the affinity mask. For example,\n+  \/\/ if the user runs the JVM with \"numactl -C 0-1,4-5\" on a machine with\n+  \/\/ the following NUMA setup:\n+  \/\/ NUMA 0: CPUs 0-3, NUMA 1: CPUs 4-7\n+  \/\/ We expect to get the following affinity masks:\n+  \/\/ Affinity masks: idx 0 = (0, 1), idx 1 = (4, 5)\n+\n+  const int num_nodes = get_existing_num_nodes();\n+  const unsigned num_cpus = (unsigned)os::processor_count();\n+\n+  for (int i = 0; i < num_nodes; i++) {\n+    struct bitmask* affinity_mask = _numa_allocate_cpumask();\n+\n+    \/\/ Fill the affinity mask with all CPUs belonging to NUMA node i\n+    _numa_node_to_cpus_v2(i, affinity_mask);\n+\n+    \/\/ Clear the bits of all CPUs that the process is not allowed to\n+    \/\/ execute tasks on\n+    for (unsigned j = 0; j < num_cpus; j++) {\n+      if (!_numa_bitmask_isbitset(_numa_all_cpus_ptr, j)) {\n+        _numa_bitmask_clearbit(affinity_mask, j);\n+      }\n+    }\n+\n+    _numa_affinity_masks->push(affinity_mask);\n+  }\n+}\n+\n@@ -3438,0 +3406,19 @@\n+void os::Linux::numa_set_thread_affinity(pid_t tid, int node) {\n+  \/\/ We only set affinity if running libnuma v2 (_numa_sched_setaffinity\n+  \/\/ is available) and we have all affinity mask\n+  if (_numa_sched_setaffinity == nullptr ||\n+      _numa_all_cpus_ptr == nullptr ||\n+      _numa_affinity_masks->is_empty()) {\n+    return;\n+  }\n+\n+  if (node == -1) {\n+    \/\/ If the node is -1, the affinity is reverted to the original affinity\n+    \/\/ of the thread when the VM was started\n+    _numa_sched_setaffinity(tid, _numa_all_cpus_ptr);\n+  } else {\n+    \/\/ Normal case, set the affinity to the corresponding affinity mask\n+    _numa_sched_setaffinity(tid, _numa_affinity_masks->at(node));\n+  }\n+}\n+\n@@ -3447,0 +3434,1 @@\n+GrowableArray<struct bitmask*>* os::Linux::_numa_affinity_masks;\n@@ -3458,0 +3446,1 @@\n+os::Linux::numa_bitmask_clearbit_func_t os::Linux::_numa_bitmask_clearbit;\n@@ -3463,0 +3452,2 @@\n+os::Linux::numa_sched_setaffinity_func_t os::Linux::_numa_sched_setaffinity;\n+os::Linux::numa_allocate_cpumask_func_t os::Linux::_numa_allocate_cpumask;\n@@ -3469,0 +3460,1 @@\n+struct bitmask* os::Linux::_numa_all_cpus_ptr;\n@@ -4316,8 +4308,1 @@\n-\/\/ This is the fastest way to get thread cpu time on Linux.\n-\/\/ Returns cpu time (user+sys) for any thread, not only for current.\n-\/\/ POSIX compliant clocks are implemented in the kernels 2.6.16+.\n-\/\/ It might work on 2.6.10+ with a special kernel\/glibc patch.\n-\/\/ For reference, please, see IEEE Std 1003.1-2004:\n-\/\/   http:\/\/www.unix.org\/single_unix_specification\n-\n-jlong os::Linux::fast_thread_cpu_time(clockid_t clockid) {\n+jlong os::Linux::thread_cpu_time(clockid_t clockid) {\n@@ -4343,1 +4328,1 @@\n-  snprintf(fname, sizeof(fname), \"\/proc\/%d\/status\", vmid);\n+  os::snprintf_checked(fname, sizeof(fname), \"\/proc\/%d\/status\", vmid);\n@@ -4442,4 +4427,0 @@\n-  \/\/ retrieve entry point for pthread_setname_np\n-  Linux::_pthread_setname_np =\n-    (int(*)(pthread_t, const char*))dlsym(RTLD_DEFAULT, \"pthread_setname_np\");\n-\n@@ -4547,81 +4528,0 @@\n-#if defined(IA32) && !defined(ZERO)\n-\/*\n- * Work-around (execute code at a high address) for broken NX emulation using CS limit,\n- * Red Hat patch \"Exec-Shield\" (IA32 only).\n- *\n- * Map and execute at a high VA to prevent CS lazy updates race with SMP MM\n- * invalidation.Further code generation by the JVM will no longer cause CS limit\n- * updates.\n- *\n- * Affects IA32: RHEL 5 & 6, Ubuntu 10.04 (LTS), 10.10, 11.04, 11.10, 12.04.\n- * @see JDK-8023956\n- *\/\n-static void workaround_expand_exec_shield_cs_limit() {\n-  assert(os::Linux::initial_thread_stack_bottom() != nullptr, \"sanity\");\n-  size_t page_size = os::vm_page_size();\n-\n-  \/*\n-   * JDK-8197429\n-   *\n-   * Expand the stack mapping to the end of the initial stack before\n-   * attempting to install the codebuf.  This is needed because newer\n-   * Linux kernels impose a distance of a megabyte between stack\n-   * memory and other memory regions.  If we try to install the\n-   * codebuf before expanding the stack the installation will appear\n-   * to succeed but we'll get a segfault later if we expand the stack\n-   * in Java code.\n-   *\n-   *\/\n-  if (os::is_primordial_thread()) {\n-    address limit = os::Linux::initial_thread_stack_bottom();\n-    if (! DisablePrimordialThreadGuardPages) {\n-      limit += StackOverflow::stack_red_zone_size() +\n-               StackOverflow::stack_yellow_zone_size();\n-    }\n-    os::Linux::expand_stack_to(limit);\n-  }\n-\n-  \/*\n-   * Take the highest VA the OS will give us and exec\n-   *\n-   * Although using -(pagesz) as mmap hint works on newer kernel as you would\n-   * think, older variants affected by this work-around don't (search forward only).\n-   *\n-   * On the affected distributions, we understand the memory layout to be:\n-   *\n-   *   TASK_LIMIT= 3G, main stack base close to TASK_LIMT.\n-   *\n-   * A few pages south main stack will do it.\n-   *\n-   * If we are embedded in an app other than launcher (initial != main stack),\n-   * we don't have much control or understanding of the address space, just let it slide.\n-   *\/\n-  char* hint = (char*)(os::Linux::initial_thread_stack_bottom() -\n-                       (StackOverflow::stack_guard_zone_size() + page_size));\n-  char* codebuf = os::attempt_reserve_memory_at(hint, page_size, mtThread);\n-\n-  if (codebuf == nullptr) {\n-    \/\/ JDK-8197429: There may be a stack gap of one megabyte between\n-    \/\/ the limit of the stack and the nearest memory region: this is a\n-    \/\/ Linux kernel workaround for CVE-2017-1000364.  If we failed to\n-    \/\/ map our codebuf, try again at an address one megabyte lower.\n-    hint -= 1 * M;\n-    codebuf = os::attempt_reserve_memory_at(hint, page_size, mtThread);\n-  }\n-\n-  if ((codebuf == nullptr) || (!os::commit_memory(codebuf, page_size, true))) {\n-    return; \/\/ No matter, we tried, best effort.\n-  }\n-\n-  log_info(os)(\"[CS limit NX emulation work-around, exec code at: %p]\", codebuf);\n-\n-  \/\/ Some code to exec: the 'ret' instruction\n-  codebuf[0] = 0xC3;\n-\n-  \/\/ Call the code in the codebuf\n-  __asm__ volatile(\"call *%0\" : : \"r\"(codebuf));\n-\n-  \/\/ keep the page mapped so CS limit isn't reduced.\n-}\n-#endif \/\/ defined(IA32) && !defined(ZERO)\n-\n@@ -4637,2 +4537,0 @@\n-  Linux::fast_thread_clock_init();\n-\n@@ -4648,6 +4546,0 @@\n-#if defined(IA32) && !defined(ZERO)\n-  \/\/ Need to ensure we've determined the process's initial stack to\n-  \/\/ perform the workaround\n-  Linux::capture_initial_stack(JavaThread::stack_size_at_create());\n-  workaround_expand_exec_shield_cs_limit();\n-#else\n@@ -4658,1 +4550,0 @@\n-#endif\n@@ -4850,1 +4741,1 @@\n-\/\/ 3. extracted from cgroup cpu subsystem (shares and quotas)\n+\/\/ 3. extracted from cgroup cpu subsystem (quotas)\n@@ -4867,3 +4758,2 @@\n-  int active_cpus;\n-  if (OSContainer::is_containerized()) {\n-    active_cpus = OSContainer::active_processor_count();\n+  int active_cpus = -1;\n+  if (OSContainer::is_containerized() && OSContainer::active_processor_count(active_cpus)) {\n@@ -4887,2 +4777,2 @@\n-  if (Atomic::load(&warn_once) == 0 ||\n-      Atomic::xchg(&warn_once, 0) == 0) {\n+  if (AtomicAccess::load(&warn_once) == 0 ||\n+      AtomicAccess::xchg(&warn_once, 0) == 0) {\n@@ -4922,7 +4812,11 @@\n-  if (Linux::_pthread_setname_np) {\n-    char buf [16]; \/\/ according to glibc manpage, 16 chars incl. '\/0'\n-    snprintf(buf, sizeof(buf), \"%s\", name);\n-    buf[sizeof(buf) - 1] = '\\0';\n-    const int rc = Linux::_pthread_setname_np(pthread_self(), buf);\n-    \/\/ ERANGE should not happen; all other errors should just be ignored.\n-    assert(rc != ERANGE, \"pthread_setname_np failed\");\n+  char buf[16]; \/\/ according to glibc manpage, 16 chars incl. '\/0'\n+  \/\/ We may need to truncate the thread name. Since a common pattern\n+  \/\/ for thread names is to be both longer than 15 chars and have a\n+  \/\/ trailing number (\"DispatcherWorkerThread21\", \"C2 CompilerThread#54\" etc),\n+  \/\/ we preserve the end of the thread name by truncating the middle\n+  \/\/ (e.g. \"Dispatc..read21\").\n+  const size_t len = strlen(name);\n+  if (len < sizeof(buf)) {\n+    strcpy(buf, name);\n+  } else {\n+    (void) os::snprintf(buf, sizeof(buf), \"%.7s..%.6s\", name, name + len - 6);\n@@ -4930,0 +4824,6 @@\n+  \/\/ Note: we use the system call here instead of calling pthread_setname_np\n+  \/\/ since this is the only way to make ASAN aware of our thread names. Even\n+  \/\/ though ASAN intercepts both prctl and pthread_setname_np, it only processes\n+  \/\/ the thread name given to the former.\n+  int rc = prctl(PR_SET_NAME, buf);\n+  assert(rc == 0, \"prctl(PR_SET_NAME) failed\");\n@@ -4999,24 +4899,1 @@\n-  \/\/ might fork and exec without closing all appropriate file descriptors\n-  \/\/ (e.g. as we do in closeDescriptors in UNIXProcess.c), and this in\n-  \/\/ turn might:\n-  \/\/\n-  \/\/ - cause end-of-file to fail to be detected on some file\n-  \/\/   descriptors, resulting in mysterious hangs, or\n-  \/\/\n-  \/\/ - might cause an fopen in the subprocess to fail on a system\n-  \/\/   suffering from bug 1085341.\n-  \/\/\n-  \/\/ (Yes, the default setting of the close-on-exec flag is a Unix\n-  \/\/ design flaw)\n-  \/\/\n-  \/\/ See:\n-  \/\/ 1085341: 32-bit stdio routines should support file descriptors >255\n-  \/\/ 4843136: (process) pipe file descriptor from Runtime.exec not being closed\n-  \/\/ 6339493: (process) Runtime.exec does not close all file descriptors on Solaris 9\n-  \/\/\n-  \/\/ Modern Linux kernels (after 2.6.23 2007) support O_CLOEXEC with open().\n-  \/\/ O_CLOEXEC is preferable to using FD_CLOEXEC on an open file descriptor\n-  \/\/ because it saves a system call and removes a small window where the flag\n-  \/\/ is unset.  On ancient Linux kernels the O_CLOEXEC flag will be ignored\n-  \/\/ and we fall back to using FD_CLOEXEC (see below).\n-#ifdef O_CLOEXEC\n+  \/\/ might fork and exec without closing all appropriate file descriptors.\n@@ -5024,1 +4901,0 @@\n-#endif\n@@ -5037,1 +4913,1 @@\n-        errno = EISDIR;\n+        errno = EISDIR;\n@@ -5047,12 +4923,21 @@\n-#ifdef FD_CLOEXEC\n-  \/\/ Validate that the use of the O_CLOEXEC flag on open above worked.\n-  \/\/ With recent kernels, we will perform this check exactly once.\n-  static sig_atomic_t O_CLOEXEC_is_known_to_work = 0;\n-  if (!O_CLOEXEC_is_known_to_work) {\n-    int flags = ::fcntl(fd, F_GETFD);\n-    if (flags != -1) {\n-      if ((flags & FD_CLOEXEC) != 0)\n-        O_CLOEXEC_is_known_to_work = 1;\n-      else\n-        ::fcntl(fd, F_SETFD, flags | FD_CLOEXEC);\n-    }\n+  return fd;\n+}\n+\n+\/\/ Since kernel v2.6.12 the Linux ABI has had support for encoding the clock\n+\/\/ types in the last three bits. Bit 2 indicates whether a cpu clock refers to a\n+\/\/ thread or a process. Bits 1 and 0 give the type: PROF=0, VIRT=1, SCHED=2, or\n+\/\/ FD=3. The clock CPUCLOCK_VIRT (0b001) reports the thread's consumed user\n+\/\/ time. POSIX compliant implementations of pthread_getcpuclockid return the\n+\/\/ clock CPUCLOCK_SCHED (0b010) which reports the thread's consumed system+user\n+\/\/ time (as mandated by the POSIX standard POSIX.1-2024\/IEEE Std 1003.1-2024\n+\/\/ 3.90).\n+static bool get_thread_clockid(Thread* thread, clockid_t* clockid, bool total) {\n+  constexpr clockid_t CLOCK_TYPE_MASK = 3;\n+  constexpr clockid_t CPUCLOCK_VIRT = 1;\n+\n+  int rc = pthread_getcpuclockid(thread->osthread()->pthread_id(), clockid);\n+  if (rc != 0) {\n+    \/\/ It's possible to encounter a terminated native thread that failed\n+    \/\/ to detach itself from the VM - which should result in ESRCH.\n+    assert_status(rc == ESRCH, rc, \"pthread_getcpuclockid failed\");\n+    return false;\n@@ -5060,2 +4945,7 @@\n-#endif\n-  return fd;\n+  if (!total) {\n+    clockid_t clockid_tmp = *clockid;\n+    clockid_tmp = (clockid_tmp & ~CLOCK_TYPE_MASK) | CPUCLOCK_VIRT;\n+    *clockid = clockid_tmp;\n+  }\n+\n+  return true;\n@@ -5065,1 +4955,1 @@\n-static jlong slow_thread_cpu_time(Thread *thread, bool user_sys_cpu_time);\n+static jlong user_thread_cpu_time(Thread *thread);\n@@ -5067,12 +4957,5 @@\n-static jlong fast_cpu_time(Thread *thread) {\n-    clockid_t clockid;\n-    int rc = os::Linux::pthread_getcpuclockid(thread->osthread()->pthread_id(),\n-                                              &clockid);\n-    if (rc == 0) {\n-      return os::Linux::fast_thread_cpu_time(clockid);\n-    } else {\n-      \/\/ It's possible to encounter a terminated native thread that failed\n-      \/\/ to detach itself from the VM - which should result in ESRCH.\n-      assert_status(rc == ESRCH, rc, \"pthread_getcpuclockid failed\");\n-      return -1;\n-    }\n+static jlong total_thread_cpu_time(Thread *thread) {\n+  clockid_t clockid;\n+  bool success = get_thread_clockid(thread, &clockid, true);\n+\n+  return success ? os::Linux::thread_cpu_time(clockid) : -1;\n@@ -5089,6 +4972,1 @@\n-  if (os::Linux::supports_fast_thread_cpu_time()) {\n-    return os::Linux::fast_thread_cpu_time(CLOCK_THREAD_CPUTIME_ID);\n-  } else {\n-    \/\/ return user + sys since the cost is the same\n-    return slow_thread_cpu_time(Thread::current(), true \/* user + sys *\/);\n-  }\n+  return os::Linux::thread_cpu_time(CLOCK_THREAD_CPUTIME_ID);\n@@ -5098,6 +4976,1 @@\n-  \/\/ consistent with what current_thread_cpu_time() returns\n-  if (os::Linux::supports_fast_thread_cpu_time()) {\n-    return fast_cpu_time(thread);\n-  } else {\n-    return slow_thread_cpu_time(thread, true \/* user + sys *\/);\n-  }\n+  return total_thread_cpu_time(thread);\n@@ -5107,2 +4980,2 @@\n-  if (user_sys_cpu_time && os::Linux::supports_fast_thread_cpu_time()) {\n-    return os::Linux::fast_thread_cpu_time(CLOCK_THREAD_CPUTIME_ID);\n+  if (user_sys_cpu_time) {\n+    return os::Linux::thread_cpu_time(CLOCK_THREAD_CPUTIME_ID);\n@@ -5110,1 +4983,1 @@\n-    return slow_thread_cpu_time(Thread::current(), user_sys_cpu_time);\n+    return user_thread_cpu_time(Thread::current());\n@@ -5115,46 +4988,1 @@\n-  if (user_sys_cpu_time && os::Linux::supports_fast_thread_cpu_time()) {\n-    return fast_cpu_time(thread);\n-  } else {\n-    return slow_thread_cpu_time(thread, user_sys_cpu_time);\n-  }\n-}\n-\n-\/\/  -1 on error.\n-static jlong slow_thread_cpu_time(Thread *thread, bool user_sys_cpu_time) {\n-  pid_t  tid = thread->osthread()->thread_id();\n-  char *s;\n-  char stat[2048];\n-  size_t statlen;\n-  char proc_name[64];\n-  int count;\n-  long sys_time, user_time;\n-  char cdummy;\n-  int idummy;\n-  long ldummy;\n-  FILE *fp;\n-\n-  snprintf(proc_name, 64, \"\/proc\/self\/task\/%d\/stat\", tid);\n-  fp = os::fopen(proc_name, \"r\");\n-  if (fp == nullptr) return -1;\n-  statlen = fread(stat, 1, 2047, fp);\n-  stat[statlen] = '\\0';\n-  fclose(fp);\n-\n-  \/\/ Skip pid and the command string. Note that we could be dealing with\n-  \/\/ weird command names, e.g. user could decide to rename java launcher\n-  \/\/ to \"java 1.4.2 :)\", then the stat file would look like\n-  \/\/                1234 (java 1.4.2 :)) R ... ...\n-  \/\/ We don't really need to know the command string, just find the last\n-  \/\/ occurrence of \")\" and then start parsing from there. See bug 4726580.\n-  s = strrchr(stat, ')');\n-  if (s == nullptr) return -1;\n-\n-  \/\/ Skip blank chars\n-  do { s++; } while (s && isspace((unsigned char) *s));\n-\n-  count = sscanf(s,\"%c %d %d %d %d %d %lu %lu %lu %lu %lu %lu %lu\",\n-                 &cdummy, &idummy, &idummy, &idummy, &idummy, &idummy,\n-                 &ldummy, &ldummy, &ldummy, &ldummy, &ldummy,\n-                 &user_time, &sys_time);\n-  if (count != 13) return -1;\n-    return ((jlong)sys_time + (jlong)user_time) * (1000000000 \/ os::Posix::clock_tics_per_second());\n+    return total_thread_cpu_time(thread);\n@@ -5163,1 +4991,1 @@\n-    return (jlong)user_time * (1000000000 \/ os::Posix::clock_tics_per_second());\n+    return user_thread_cpu_time(thread);\n@@ -5167,0 +4995,7 @@\n+static jlong user_thread_cpu_time(Thread *thread) {\n+  clockid_t clockid;\n+  bool success = get_thread_clockid(thread, &clockid, false);\n+\n+  return success ? os::Linux::thread_cpu_time(clockid) : -1;\n+}\n+\n@@ -5243,1 +5078,1 @@\n-                             \"\\\"%s\\\" (or dumping to %s\/core.%d)\",\n+                             \"\\\"%s\\\" (alternatively, falling back to %s\/core.%d)\",\n@@ -5522,1 +5357,1 @@\n-      snprintf(ebuf, ebuflen - 1, \"%s\", error_report);\n+      os::snprintf_checked(ebuf, ebuflen, \"%s\", error_report);\n","filename":"src\/hotspot\/os\/linux\/os_linux.cpp","additions":438,"deletions":603,"binary":false,"changes":1041,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -36,3 +36,0 @@\n-  static int (*_pthread_getcpuclockid)(pthread_t, clockid_t *);\n-  static int (*_pthread_setname_np)(pthread_t, const char*);\n-\n@@ -45,2 +42,0 @@\n-  static bool _supports_fast_thread_cpu_time;\n-\n@@ -50,1 +45,3 @@\n-  static julong available_memory_in_container();\n+  static GrowableArray<struct bitmask*>* _numa_affinity_masks;\n+\n+  static void build_numa_affinity_masks();\n@@ -54,1 +51,1 @@\n-  static julong _physical_memory;\n+  static physical_memory_size_type _physical_memory;\n@@ -57,2 +54,2 @@\n-  static julong available_memory();\n-  static julong free_memory();\n+  static bool available_memory(physical_memory_size_type& value);\n+  static bool free_memory(physical_memory_size_type& value);\n@@ -122,2 +119,2 @@\n-  static julong physical_memory() { return _physical_memory; }\n-  static julong host_swap();\n+  static physical_memory_size_type physical_memory() { return _physical_memory; }\n+  static bool host_swap(physical_memory_size_type& value);\n@@ -150,12 +147,1 @@\n-  \/\/ fast POSIX clocks support\n-  static void fast_thread_clock_init(void);\n-\n-  static int pthread_getcpuclockid(pthread_t tid, clockid_t *clock_id) {\n-    return _pthread_getcpuclockid ? _pthread_getcpuclockid(tid, clock_id) : -1;\n-  }\n-\n-  static bool supports_fast_thread_cpu_time() {\n-    return _supports_fast_thread_cpu_time;\n-  }\n-\n-  static jlong fast_thread_cpu_time(clockid_t clockid);\n+  static jlong thread_cpu_time(clockid_t clockid);\n@@ -186,0 +172,17 @@\n+  \/\/ Output structure for query_accurate_process_memory_info() (all values in KB)\n+  struct accurate_meminfo_t {\n+    ssize_t rss;        \/\/ current resident set size\n+    ssize_t pss;        \/\/ current proportional set size\n+    ssize_t pssdirty;   \/\/ proportional set size (dirty)\n+    ssize_t pssanon;    \/\/ proportional set size (anonymous mappings)\n+    ssize_t pssfile;    \/\/ proportional set size (file mappings)\n+    ssize_t pssshmem;   \/\/ proportional set size (shared mappings)\n+    ssize_t swap;       \/\/ swapped out\n+    ssize_t swappss;    \/\/ proportional set size (swapped out)\n+  };\n+\n+  \/\/ Attempts to query accurate memory information from \/proc\/self\/smaps_rollup and return it in the output structure.\n+  \/\/ May fail (returns false) or succeed (returns true) but not all output fields are available; unavailable\n+  \/\/ fields will contain -1.\n+  static bool query_accurate_process_memory_info(accurate_meminfo_t* info);\n+\n@@ -221,0 +224,1 @@\n+  typedef int (*numa_bitmask_clearbit_func_t)(struct bitmask *bmp, unsigned int n);\n@@ -223,0 +227,2 @@\n+  typedef int (*numa_sched_setaffinity_func_t)(pid_t pid, struct bitmask* mask);\n+  typedef struct bitmask* (*numa_allocate_cpumask_func_t)(void);\n@@ -235,0 +241,1 @@\n+  static numa_bitmask_clearbit_func_t _numa_bitmask_clearbit;\n@@ -242,0 +249,2 @@\n+  static numa_sched_setaffinity_func_t _numa_sched_setaffinity;\n+  static numa_allocate_cpumask_func_t _numa_allocate_cpumask;\n@@ -245,0 +254,1 @@\n+  static struct bitmask* _numa_all_cpus_ptr;\n@@ -260,0 +270,1 @@\n+  static void set_numa_bitmask_clearbit(numa_bitmask_clearbit_func_t func) { _numa_bitmask_clearbit = func; }\n@@ -270,0 +281,1 @@\n+  static void set_numa_all_cpus_ptr(struct bitmask **ptr) { _numa_all_cpus_ptr = (ptr == nullptr ? nullptr : *ptr); }\n@@ -273,0 +285,2 @@\n+  static void set_numa_sched_setaffinity(numa_sched_setaffinity_func_t func) { _numa_sched_setaffinity = func; }\n+  static void set_numa_allocate_cpumask(numa_allocate_cpumask_func_t func) { _numa_allocate_cpumask = func; }\n@@ -283,0 +297,2 @@\n+  static void numa_set_thread_affinity(pid_t tid, int node);\n+\n","filename":"src\/hotspot\/os\/linux\/os_linux.hpp","additions":40,"deletions":24,"binary":false,"changes":64,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"attachListener_posix.hpp\"\n@@ -27,0 +28,3 @@\n+#include \"memory\/resourceArea.hpp\"\n+#include \"os_posix.hpp\"\n+#include \"posixAttachOperation.hpp\"\n@@ -29,4 +33,0 @@\n-#include \"os_posix.hpp\"\n-#include \"attachListener_posix.hpp\"\n-#include \"posixAttachOperation.hpp\"\n-#include \"memory\/resourceArea.hpp\"\n@@ -37,3 +37,3 @@\n-#include <unistd.h>\n-#include <sys\/types.h>\n-#include <sys\/un.h>\n+#include <sys\/types.h>\n+#include <sys\/un.h>\n+#include <unistd.h>\n@@ -102,2 +102,2 @@\n-  int n = snprintf(path, UNIX_PATH_MAX, \"%s\/.java_pid%d\",\n-                   os::get_temp_directory(), os::current_process_id());\n+  int n = os::snprintf(path, UNIX_PATH_MAX, \"%s\/.java_pid%d\",\n+                       os::get_temp_directory(), os::current_process_id());\n@@ -105,1 +105,1 @@\n-    n = snprintf(initial_path, UNIX_PATH_MAX, \"%s.tmp\", path);\n+    n = os::snprintf(initial_path, UNIX_PATH_MAX, \"%s.tmp\", path);\n@@ -302,3 +302,2 @@\n-  int n = snprintf(fn, UNIX_PATH_MAX, \"%s\/.java_pid%d\",\n-           os::get_temp_directory(), os::current_process_id());\n-  assert(n < (int)UNIX_PATH_MAX, \"java_pid file name buffer overflow\");\n+  os::snprintf_checked(fn, UNIX_PATH_MAX, \"%s\/.java_pid%d\",\n+                       os::get_temp_directory(), os::current_process_id());\n@@ -374,2 +373,2 @@\n-    snprintf(fn, sizeof(fn), \"%s\/.attach_pid%d\", os::get_temp_directory(),\n-             os::current_process_id());\n+    os::snprintf_checked(fn, sizeof(fn), \"%s\/.attach_pid%d\", os::get_temp_directory(),\n+                         os::current_process_id());\n","filename":"src\/hotspot\/os\/posix\/attachListener_posix.cpp","additions":14,"deletions":15,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -29,0 +29,2 @@\n+#include \"utilities\/macros.hpp\"\n+\n","filename":"src\/hotspot\/os\/posix\/attachListener_posix.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -57,1 +57,1 @@\n-#define JVM_MAXPATHLEN MAXPATHLEN + 1\n+#define JVM_MAXPATHLEN (MAXPATHLEN + 1)\n","filename":"src\/hotspot\/os\/posix\/include\/jvm_md.h","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2026, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,0 +26,1 @@\n+#include \"cppstdlib\/cstdlib.hpp\"\n@@ -34,1 +35,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -62,0 +63,1 @@\n+#include \"porting_aix.hpp\"\n@@ -75,1 +77,1 @@\n-#include <pwd.h>\n+#include <pwd.h>\n@@ -78,0 +80,1 @@\n+#include <spawn.h>\n@@ -81,1 +84,0 @@\n-#include <spawn.h>\n@@ -114,0 +116,1 @@\n+  stringStream buf(buffer, bufferSize);\n@@ -115,2 +118,2 @@\n-    jio_snprintf(buffer, bufferSize, \"CreateCoredumpOnCrash is disabled from command line\");\n-    VMError::record_coredump_status(buffer, false);\n+    buf.print(\"CreateCoredumpOnCrash is disabled from command line\");\n+    VMError::record_coredump_status(buf.freeze(), false);\n@@ -123,1 +126,5 @@\n-      jio_snprintf(buffer, bufferSize, \"core.%d (may not exist)\", current_process_id());\n+      \/\/ In the warning message, let the user know.\n+      if (check_only) {\n+        buf.print(\"the core path couldn't be determined. It commonly defaults to \");\n+      }\n+      buf.print(\"core.%d%s\", current_process_id(), check_only ? \"\" : \" (may not exist)\");\n@@ -126,1 +133,6 @@\n-      jio_snprintf(buffer, bufferSize, \"Core dumps may be processed with %s\", core_path);\n+      if (check_only) {\n+        buf.print(\"core dumps may be further processed by the following: \");\n+      } else {\n+        buf.print(\"Determined by the following: \");\n+      }\n+      buf.print(\"%s\", core_path);\n@@ -129,1 +141,4 @@\n-      jio_snprintf(buffer, bufferSize, \"%s (may not exist)\", core_path);\n+      if (check_only) {\n+        buf.print(\"the rlimit couldn't be determined. If resource limits permit, the core dump will be located at \");\n+      }\n+      buf.print(\"%s%s\", core_path, check_only ? \"\" : \" (may not exist)\");\n@@ -133,1 +148,1 @@\n-          jio_snprintf(buffer, bufferSize, \"%s\", core_path);\n+          buf.print(\"%s\", core_path);\n@@ -137,1 +152,1 @@\n-          jio_snprintf(buffer, bufferSize, \"Core dumps have been disabled. To enable core dumping, try \\\"ulimit -c unlimited\\\" before starting Java again\");\n+          buf.print(\"%s dumps have been disabled. To enable core dumping, try \\\"ulimit -c unlimited\\\" before starting Java again\", check_only ? \"core\" : \"Core\");\n@@ -141,1 +156,6 @@\n-          jio_snprintf(buffer, bufferSize, \"%s (max size \" UINT64_FORMAT \" k). To ensure a full core dump, try \\\"ulimit -c unlimited\\\" before starting Java again\", core_path, uint64_t(rlim.rlim_cur) \/ K);\n+          if (check_only) {\n+            buf.print(\"core dumps are constrained \");\n+          } else {\n+             buf.print( \"%s \", core_path);\n+          }\n+          buf.print( \"(max size \" UINT64_FORMAT \" k). To ensure a full core dump, try \\\"ulimit -c unlimited\\\" before starting Java again\", uint64_t(rlim.rlim_cur) \/ K);\n@@ -145,0 +165,1 @@\n+    const char* result = buf.freeze();\n@@ -146,1 +167,1 @@\n-      VMError::record_coredump_status(buffer, success);\n+      VMError::record_coredump_status(result, success);\n@@ -148,1 +169,1 @@\n-      warning(\"CreateCoredumpOnCrash specified, but %s\", buffer);\n+      warning(\"CreateCoredumpOnCrash specified, but %s\", result);\n@@ -328,1 +349,1 @@\n-    int n = snprintf(fullname, fullname_len + 1, \"%s%s\", dir, name_template);\n+    int n = os::snprintf(fullname, fullname_len + 1, \"%s%s\", dir, name_template);\n@@ -444,6 +465,4 @@\n-  if (base != nullptr && addr != base) {\n-    if (!os::release_memory(addr, size)) {\n-      warning(\"Could not release memory on unsuccessful file mapping\");\n-    }\n-    return nullptr;\n-  }\n+\n+  \/\/ The requested address should be the same as the returned address when using MAP_FIXED\n+  \/\/ as per POSIX.\n+  assert(base == nullptr || addr == base, \"base should equal addr when using MAP_FIXED\");\n@@ -718,1 +737,1 @@\n-\/\/ Helper, on 32bit, for os::has_allocatable_memory_limit\n+\/\/ Helper, on 32bit, for os::commit_memory_limit\n@@ -736,0 +755,4 @@\n+size_t os::commit_memory_limit() {\n+  \/\/ On POSIX systems, the amount of memory that can be commmitted is limited\n+  \/\/ by the size of the reservable memory.\n+  size_t reserve_limit = reserve_memory_limit();\n@@ -737,13 +760,1 @@\n-bool os::has_allocatable_memory_limit(size_t* limit) {\n-  struct rlimit rlim;\n-  int getrlimit_res = getrlimit(RLIMIT_AS, &rlim);\n-  \/\/ if there was an error when calling getrlimit, assume that there is no limitation\n-  \/\/ on virtual memory.\n-  bool result;\n-  if ((getrlimit_res != 0) || (rlim.rlim_cur == RLIM_INFINITY)) {\n-    result = false;\n-  } else {\n-    *limit = (size_t)rlim.rlim_cur;\n-    result = true;\n-  }\n-  return result;\n+  return reserve_limit;\n@@ -752,9 +763,5 @@\n-  \/\/ arbitrary virtual space limit for 32 bit Unices found by testing. If\n-  \/\/ getrlimit above returned a limit, bound it with this limit. Otherwise\n-  \/\/ directly use it.\n-  const size_t max_virtual_limit = 3800*M;\n-  if (result) {\n-    *limit = MIN2(*limit, max_virtual_limit);\n-  } else {\n-    *limit = max_virtual_limit;\n-  }\n+  \/\/ Arbitrary max reserve limit for 32 bit Unices found by testing.\n+  const size_t max_reserve_limit = 3800 * M;\n+\n+  \/\/ Bound the reserve limit with the arbitrary max.\n+  size_t actual_limit = MIN2(reserve_limit, max_reserve_limit);\n@@ -774,1 +781,1 @@\n-  size_t upper_limit = *limit;\n+  size_t upper_limit = actual_limit;\n@@ -778,1 +785,1 @@\n-    *limit = upper_limit;\n+    \/\/ The actual limit is allocatable, no need to do anything.\n@@ -782,1 +789,1 @@\n-    *limit = min_allocation_size;\n+    actual_limit = min_allocation_size;\n@@ -795,1 +802,1 @@\n-    *limit = lower_limit;\n+    actual_limit = lower_limit;\n@@ -797,1 +804,2 @@\n-  return true;\n+\n+  return actual_limit;\n@@ -801,0 +809,18 @@\n+size_t os::reserve_memory_limit() {\n+  struct rlimit rlim;\n+  int getrlimit_res = getrlimit(RLIMIT_AS, &rlim);\n+\n+  \/\/ If there was an error calling getrlimit, conservatively assume no limit.\n+  if (getrlimit_res != 0) {\n+    return SIZE_MAX;\n+  }\n+\n+  \/\/ If the current limit is not infinity, there is a limit.\n+  if (rlim.rlim_cur != RLIM_INFINITY) {\n+    return (size_t)rlim.rlim_cur;\n+  }\n+\n+  \/\/ No limit\n+  return SIZE_MAX;\n+}\n+\n@@ -1020,0 +1046,1 @@\n+    ErrnoPreserver ep;\n@@ -1079,0 +1106,89 @@\n+static char saved_jvm_path[MAXPATHLEN] = {0};\n+\n+\/\/ Find the full path to the current module, libjvm.so\n+void os::jvm_path(char *buf, jint buflen) {\n+  \/\/ Error checking.\n+  if (buflen < MAXPATHLEN) {\n+    assert(false, \"must use a large-enough buffer\");\n+    buf[0] = '\\0';\n+    return;\n+  }\n+  \/\/ Lazy resolve the path to current module.\n+  if (saved_jvm_path[0] != 0) {\n+    strcpy(buf, saved_jvm_path);\n+    return;\n+  }\n+\n+  const char* fname;\n+#ifdef AIX\n+  Dl_info dlinfo;\n+  int ret = dladdr(CAST_FROM_FN_PTR(void *, os::jvm_path), &dlinfo);\n+  assert(ret != 0, \"cannot locate libjvm\");\n+  if (ret == 0) {\n+    return;\n+  }\n+  fname = dlinfo.dli_fname;\n+#else\n+  char dli_fname[MAXPATHLEN];\n+  dli_fname[0] = '\\0';\n+  bool ret = dll_address_to_library_name(\n+                                         CAST_FROM_FN_PTR(address, os::jvm_path),\n+                                         dli_fname, sizeof(dli_fname), nullptr);\n+  assert(ret, \"cannot locate libjvm\");\n+  if (!ret) {\n+    return;\n+  }\n+  fname = dli_fname;\n+#endif \/\/ AIX\n+  char* rp = nullptr;\n+  if (fname[0] != '\\0') {\n+    rp = os::realpath(fname, buf, buflen);\n+  }\n+  if (rp == nullptr) {\n+    return;\n+  }\n+\n+  \/\/ If executing unit tests we require JAVA_HOME to point to the real JDK.\n+  if (Arguments::executing_unit_tests()) {\n+    \/\/ Look for JAVA_HOME in the environment.\n+    char* java_home_var = ::getenv(\"JAVA_HOME\");\n+    if (java_home_var != nullptr && java_home_var[0] != 0) {\n+\n+      \/\/ Check the current module name \"libjvm.so\".\n+      const char* p = strrchr(buf, '\/');\n+      if (p == nullptr) {\n+        return;\n+      }\n+      assert(strstr(p, \"\/libjvm\") == p, \"invalid library name\");\n+\n+      stringStream ss(buf, buflen);\n+      rp = os::realpath(java_home_var, buf, buflen);\n+      if (rp == nullptr) {\n+        return;\n+      }\n+\n+      assert((int)strlen(buf) < buflen, \"Ran out of buffer room\");\n+      ss.print(\"%s\/lib\", buf);\n+\n+      \/\/ If the path exists within JAVA_HOME, add the VM variant directory and JVM\n+      \/\/ library name to complete the path to JVM being overridden.  Otherwise fallback\n+      \/\/ to the path to the current library.\n+      if (0 == access(buf, F_OK)) {\n+        \/\/ Use current module name \"libjvm.so\"\n+        ss.print(\"\/%s\/libjvm%s\", Abstract_VM_Version::vm_variant(), JNI_LIB_SUFFIX);\n+        assert(strcmp(buf + strlen(buf) - strlen(JNI_LIB_SUFFIX), JNI_LIB_SUFFIX) == 0,\n+               \"buf has been truncated\");\n+      } else {\n+        \/\/ Go back to path of .so\n+        rp = os::realpath(fname, buf, buflen);\n+        if (rp == nullptr) {\n+          return;\n+        }\n+      }\n+    }\n+  }\n+\n+  strncpy(saved_jvm_path, buf, MAXPATHLEN);\n+  saved_jvm_path[MAXPATHLEN - 1] = '\\0';\n+}\n+\n@@ -1254,0 +1370,4 @@\n+bool os::Posix::is_current_user_root(){\n+    return is_root(geteuid());\n+}\n+\n@@ -1541,1 +1661,10 @@\n-bool os::supports_vtime() { return true; }\n+double os::elapsed_process_cpu_time() {\n+  struct rusage usage;\n+  int retval = getrusage(RUSAGE_SELF, &usage);\n+  if (retval == 0) {\n+    return usage.ru_utime.tv_sec + usage.ru_stime.tv_sec +\n+         (usage.ru_utime.tv_usec + usage.ru_stime.tv_usec) \/ (1000.0 * 1000.0);\n+  } else {\n+    return -1;\n+  }\n+}\n@@ -1617,1 +1746,1 @@\n-    if (Atomic::cmpxchg(&_event, v, v - 1) == v) break;\n+    if (AtomicAccess::cmpxchg(&_event, v, v - 1) == v) break;\n@@ -1664,1 +1793,1 @@\n-    if (Atomic::cmpxchg(&_event, v, v - 1) == v) break;\n+    if (AtomicAccess::cmpxchg(&_event, v, v - 1) == v) break;\n@@ -1720,1 +1849,1 @@\n-  if (Atomic::xchg(&_event, 1) >= 0) return;\n+  if (AtomicAccess::xchg(&_event, 1) >= 0) return;\n@@ -1773,1 +1902,1 @@\n-  \/\/ We depend on Atomic::xchg() having full barrier semantics\n+  \/\/ We depend on AtomicAccess::xchg() having full barrier semantics\n@@ -1775,1 +1904,1 @@\n-  if (Atomic::xchg(&_counter, 0) > 0) return;\n+  if (AtomicAccess::xchg(&_counter, 0) > 0) return;\n","filename":"src\/hotspot\/os\/posix\/os_posix.cpp","additions":184,"deletions":55,"binary":false,"changes":239,"status":"modified"},{"patch":"@@ -81,0 +81,3 @@\n+  \/\/ Returns true if the current user is root.\n+  static bool is_current_user_root();\n+\n","filename":"src\/hotspot\/os\/posix\/os_posix.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 2001, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2012, 2021 SAP SE. All rights reserved.\n+ * Copyright (c) 2001, 2026, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2026 SAP SE. All rights reserved.\n@@ -30,0 +30,1 @@\n+#include \"logging\/logStream.hpp\"\n@@ -44,0 +45,3 @@\n+#if defined(BSD)\n+#include \"os_bsd.hpp\"\n+#endif\n@@ -49,3 +53,2 @@\n-\/\/ put OS-includes here\n-# include <sys\/types.h>\n-# include <sys\/mman.h>\n+# include <pwd.h>\n+# include <signal.h>\n@@ -54,1 +57,1 @@\n-# include <unistd.h>\n+# include <sys\/mman.h>\n@@ -56,2 +59,2 @@\n-# include <signal.h>\n-# include <pwd.h>\n+# include <sys\/types.h>\n+# include <unistd.h>\n@@ -81,3 +84,1 @@\n-    if (PrintMiscellaneous && Verbose) {\n-      warning(\"Could not commit PerfData memory\\n\");\n-    }\n+    log_debug(perf)(\"could not commit PerfData memory\");\n@@ -153,0 +154,12 @@\n+#endif\n+#ifdef __APPLE__\n+  char buffer[PATH_MAX] = {0};\n+  \/\/ Check if the current user is root and the target VM is running as non-root.\n+  \/\/ Otherwise the output of os::get_temp_directory() is used.\n+  \/\/\n+  if (os::Posix::is_current_user_root() && !os::Bsd::is_process_root(vmid)) {\n+    int path_size = os::Bsd::get_user_tmp_dir_macos(user, vmid, buffer, sizeof buffer);\n+    if (path_size > 0 && (size_t)path_size < sizeof buffer) {\n+      tmpdir = buffer;\n+    }\n+  }\n@@ -159,1 +172,1 @@\n-  snprintf(dirname, nbytes, \"%s\/%s_%s\", tmpdir, perfdir, user);\n+  os::snprintf_checked(dirname, nbytes, \"%s\/%s_%s\", tmpdir, perfdir, user);\n@@ -307,1 +320,2 @@\n-    if (PrintMiscellaneous && Verbose) {\n+    if (log_is_enabled(Debug, perf)) {\n+      LogStreamHandle(Debug, perf) log;\n@@ -309,1 +323,1 @@\n-        warning(\"directory %s is a symlink and is not secure\\n\", dirname);\n+        log.print_cr(\"directory %s is a symlink and is not secure\", dirname);\n@@ -311,1 +325,1 @@\n-        warning(\"could not open directory %s: %s\\n\", dirname, os::strerror(errno));\n+        log.print_cr(\"could not open directory %s: %s\", dirname, os::strerror(errno));\n@@ -381,3 +395,1 @@\n-    if (PrintMiscellaneous && Verbose) {\n-      warning(\"could not change to directory %s\", dirname);\n-    }\n+    log_debug(perf)(\"could not change to directory %s\", dirname);\n@@ -421,3 +433,1 @@\n-    if (PrintMiscellaneous && Verbose) {\n-      warning(\"fstat failed on %s: %s\\n\", filename, os::strerror(errno));\n-    }\n+    log_debug(perf)(\"fstat failed on %s: %s\", filename, os::strerror(errno));\n@@ -428,3 +438,1 @@\n-    if (PrintMiscellaneous && Verbose) {\n-      warning(\"file %s has multiple links\\n\", filename);\n-    }\n+    log_debug(perf)(\"file %s has multiple links\", filename);\n@@ -457,1 +465,2 @@\n-    if (PrintMiscellaneous && Verbose) {\n+    if (log_is_enabled(Debug, perf)) {\n+      LogStreamHandle(Debug, perf) log;\n@@ -459,2 +468,1 @@\n-        warning(\"Could not retrieve passwd entry: %s\\n\",\n-                os::strerror(result));\n+        log.print_cr(\"Could not retrieve passwd entry: %s\", os::strerror(result));\n@@ -473,2 +481,1 @@\n-        warning(\"Could not retrieve passwd entry: %s\\n\",\n-                os::strerror(errno));\n+        log.print_cr(\"Could not retrieve passwd entry: %s\", os::strerror(errno));\n@@ -477,3 +484,2 @@\n-        warning(\"Could not determine user name: %s\\n\",\n-                p->pw_name == nullptr ? \"pw_name = null\" :\n-                                     \"pw_name zero length\");\n+        log.print_cr(\"Could not determine user name: %s\",\n+                     p->pw_name == nullptr ? \"pw_name = null\" : \"pw_name zero length\");\n@@ -670,1 +676,1 @@\n-  snprintf(name, nbytes, \"%s\/%d\", dirname, pid);\n+  os::snprintf_checked(name, nbytes, \"%s\/%d\", dirname, pid);\n@@ -690,1 +696,1 @@\n-  if (PrintMiscellaneous && Verbose && result == OS_ERR) {\n+  if (log_is_enabled(Debug, perf) && result == OS_ERR) {\n@@ -692,2 +698,2 @@\n-      warning(\"Could not unlink shared memory backing\"\n-              \" store file %s : %s\\n\", path, os::strerror(errno));\n+      log_debug(perf)(\"could not unlink shared memory backing store file %s : %s\",\n+                      path, os::strerror(errno));\n@@ -829,1 +835,0 @@\n-      \/\/\n@@ -832,3 +837,1 @@\n-        if (PrintMiscellaneous && Verbose) {\n-          warning(\"%s directory is insecure\\n\", dirname);\n-        }\n+        log_debug(perf)(\"%s directory is insecure\", dirname);\n@@ -841,5 +844,1 @@\n-      \/\/\n-      if (PrintMiscellaneous && Verbose) {\n-        warning(\"could not create directory %s: %s\\n\",\n-                dirname, os::strerror(errno));\n-      }\n+      log_debug(perf)(\"could not create directory %s: %s\", dirname, os::strerror(errno));\n@@ -882,1 +881,2 @@\n-    if (PrintMiscellaneous && Verbose) {\n+    if (log_is_enabled(Debug, perf)) {\n+      LogStreamHandle(Debug, perf) log;\n@@ -884,1 +884,1 @@\n-        warning(\"file %s is a symlink and is not secure\\n\", filename);\n+        log.print_cr(\"file %s is a symlink and is not secure\", filename);\n@@ -886,1 +886,1 @@\n-        warning(\"could not create file %s: %s\\n\", filename, os::strerror(errno));\n+        log.print_cr(\"could not create file %s: %s\", filename, os::strerror(errno));\n@@ -934,3 +934,1 @@\n-    if (PrintMiscellaneous && Verbose) {\n-      warning(\"could not truncate shared memory file: %s\\n\", os::strerror(errno));\n-    }\n+    log_debug(perf)(\"could not truncate shared memory file: %s\", os::strerror(errno));\n@@ -943,3 +941,1 @@\n-    if (PrintMiscellaneous && Verbose) {\n-      warning(\"could not set shared memory file size: %s\\n\", os::strerror(errno));\n-    }\n+    log_debug(perf)(\"could not set shared memory file size: %s\", os::strerror(errno));\n@@ -959,1 +955,1 @@\n-        warning(\"Insufficient space for shared memory file:\\n   %s\\nTry using the -Djava.io.tmpdir= option to select an alternate temp location.\\n\", filename);\n+        warning(\"Insufficient space for shared memory file: %s\/%s\\n\", dirname, filename);\n@@ -1067,3 +1063,1 @@\n-    if (PrintMiscellaneous && Verbose) {\n-      warning(\"mmap failed -  %s\\n\", os::strerror(errno));\n-    }\n+    log_debug(perf)(\"mmap failed - %s\", os::strerror(errno));\n@@ -1145,3 +1139,1 @@\n-    if (PrintMiscellaneous && Verbose) {\n-      warning(\"fstat failed: %s\\n\", os::strerror(errno));\n-    }\n+    log_debug(perf)(\"fstat failed: %s\", os::strerror(errno));\n@@ -1170,1 +1162,2 @@\n-  const char* luser = get_user_name(vmid, &nspid, CHECK);\n+  const char* luser = NOT_MACOS(get_user_name(vmid, &nspid, CHECK))\n+                      MACOS_ONLY(get_user_name(os::Bsd::get_process_uid(vmid)));\n@@ -1222,3 +1215,1 @@\n-    if (PrintMiscellaneous && Verbose) {\n-      warning(\"mmap failed: %s\\n\", os::strerror(errno));\n-    }\n+    log_debug(perf)(\"mmap failed: %s\", os::strerror(errno));\n@@ -1254,1 +1245,0 @@\n-\n@@ -1257,4 +1247,1 @@\n-      \/\/\n-      if (PrintMiscellaneous && Verbose) {\n-        warning(\"Reverting to non-shared PerfMemory region.\\n\");\n-      }\n+      log_debug(perf)(\"Reverting to non-shared PerfMemory region.\");\n","filename":"src\/hotspot\/os\/posix\/perfMemory_posix.cpp","additions":57,"deletions":70,"binary":false,"changes":127,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2026, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,1 +31,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -45,0 +45,1 @@\n+#include \"utilities\/deferredStatic.hpp\"\n@@ -170,1 +171,1 @@\n-  static OSXSemaphore sr_semaphore;\n+static DeferredStatic<OSXSemaphore> sr_semaphore;\n@@ -172,1 +173,1 @@\n-  static PosixSemaphore sr_semaphore;\n+static DeferredStatic<PosixSemaphore> sr_semaphore;\n@@ -180,1 +181,1 @@\n-static Semaphore* sig_semaphore = nullptr;\n+static DeferredStatic<Semaphore> sig_semaphore;\n@@ -354,1 +355,2 @@\n-  sig_semaphore = new Semaphore();\n+  int sem_count = 0;\n+  sig_semaphore.initialize(sem_count);\n@@ -358,2 +360,4 @@\n-  if (sig_semaphore != nullptr) {\n-    Atomic::inc(&pending_signals[sig]);\n+  \/\/ Signal thread is not created with ReduceSignalUsage and jdk_misc_signal_init\n+  \/\/ initialization isn't called.\n+  if (!ReduceSignalUsage) {\n+    AtomicAccess::inc(&pending_signals[sig]);\n@@ -361,4 +365,0 @@\n-  } else {\n-    \/\/ Signal thread is not created with ReduceSignalUsage and jdk_misc_signal_init\n-    \/\/ initialization isn't called.\n-    assert(ReduceSignalUsage, \"signal semaphore should be created\");\n@@ -372,1 +372,1 @@\n-      if (n > 0 && n == Atomic::cmpxchg(&pending_signals[i], n, n - 1)) {\n+      if (n > 0 && n == AtomicAccess::cmpxchg(&pending_signals[i], n, n - 1)) {\n@@ -624,3 +624,1 @@\n-        address deopt = nm->is_method_handle_return(pc) ?\n-          nm->deopt_mh_handler_begin() :\n-          nm->deopt_handler_begin();\n+        address deopt = nm->deopt_handler_entry();\n@@ -956,0 +954,26 @@\n+#if defined(LINUX)\n+\/\/ Additional kernel si_code definitions that are only exported by\n+\/\/ more recent glibc distributions, so we have to hard-code the values.\n+#ifndef BUS_MCEERR_AR \/\/ glibc 2.17\n+#define BUS_MCEERR_AR 4\n+#define BUS_MCEERR_AO 5\n+#endif\n+\n+#ifndef SEGV_PKUERR \/\/ glibc 2.27\n+#define SEGV_PKUERR 4\n+#endif\n+\n+#ifndef SYS_SECCOMP \/\/ glibc 2.28\n+#define SYS_SECCOMP 1\n+#endif\n+\n+#ifndef TRAP_BRANCH \/\/ glibc 2.30\n+#define TRAP_BRANCH 3\n+#endif\n+\n+#ifndef TRAP_HWBKPT \/\/ not glibc version specific - gdb related\n+#define TRAP_HWBKPT 4\n+#endif\n+\n+#endif \/\/ LINUX\n+\n@@ -981,0 +1005,1 @@\n+    { SIGSEGV, SEGV_PKUERR,  \"SEGV_PKUERR\",  \"Protection key checking failure.\" },\n@@ -989,0 +1014,6 @@\n+#if defined(LINUX)\n+    { SIGBUS,  BUS_MCEERR_AR,\"BUS_MCEERR_AR\",\"Hardware memory error consumed on a machine check: action required.\" },\n+    { SIGBUS,  BUS_MCEERR_AO,\"BUS_MCEERR_AO\",\"Hardware memory error detected in process but not consumed: action optional.\" },\n+\n+    { SIGSYS,  SYS_SECCOMP,  \"SYS_SECCOMP\",  \"Secure computing (seccomp) filter failure.\" },\n+#endif\n@@ -991,0 +1022,4 @@\n+#if defined(LINUX)\n+    { SIGTRAP, TRAP_BRANCH,  \"TRAP_BRANCH\",  \"Process taken branch trap.\" },\n+    { SIGTRAP, TRAP_HWBKPT,  \"TRAP_HWBKPT\",  \"Hardware breakpoint\/watchpoint.\" },\n+#endif\n@@ -998,0 +1033,1 @@\n+    { SIGPOLL, POLL_IN,      \"POLL_IN\",      \"Data input available.\" },\n@@ -1671,1 +1707,1 @@\n-  int old_errno = errno;\n+  ErrnoPreserver ep;\n@@ -1695,4 +1731,1 @@\n-  \/\/ has not already terminated - else the following assertion\n-  \/\/ will fail because the thread is no longer a JavaThread as the ~JavaThread\n-  \/\/ destructor has completed.\n-\n+  \/\/ has not already terminated, else the osthread may already have been freed.\n@@ -1703,2 +1736,0 @@\n-  assert(thread->is_VM_thread() || thread->is_Java_thread(), \"Must be VMThread or JavaThread\");\n-\n@@ -1710,0 +1741,5 @@\n+    \/\/ Only check this on an active suspend request. It is possible to get a late delivered\n+    \/\/ signal from a cancelled suspend request that hits after the JavaThread destructor\n+    \/\/ completes, but before the Thread destructor causes `is_terminated()` to be true.\n+    assert(thread->is_VM_thread() || thread->is_Java_thread(), \"Must be VMThread or JavaThread\");\n+\n@@ -1722,1 +1758,1 @@\n-      sr_semaphore.signal();\n+      sr_semaphore->signal();\n@@ -1731,1 +1767,1 @@\n-          sr_semaphore.signal();\n+          sr_semaphore->signal();\n@@ -1753,1 +1789,0 @@\n-  errno = old_errno;\n@@ -1757,0 +1792,3 @@\n+  int sem_count = 0;\n+  sr_semaphore.initialize(sem_count);\n+\n@@ -1804,1 +1842,1 @@\n-  assert(!sr_semaphore.trywait(), \"semaphore has invalid state\");\n+  assert(!sr_semaphore->trywait(), \"semaphore has invalid state\");\n@@ -1819,1 +1857,1 @@\n-    if (sr_semaphore.timedwait(2)) {\n+    if (sr_semaphore->timedwait(2)) {\n@@ -1828,1 +1866,1 @@\n-        sr_semaphore.wait();\n+        sr_semaphore->wait();\n@@ -1843,1 +1881,1 @@\n-  assert(!sr_semaphore.trywait(), \"invalid semaphore state\");\n+  assert(!sr_semaphore->trywait(), \"invalid semaphore state\");\n@@ -1853,1 +1891,1 @@\n-      if (sr_semaphore.timedwait(2)) {\n+      if (sr_semaphore->timedwait(2)) {\n","filename":"src\/hotspot\/os\/posix\/signals_posix.cpp","additions":69,"deletions":31,"binary":false,"changes":100,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"runtime\/crac.hpp\"\n@@ -26,0 +27,1 @@\n+#include \"runtime\/os.hpp\"\n","filename":"src\/hotspot\/os\/windows\/crac_windows.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2026, Oracle and\/or its affiliates. All rights reserved.\n@@ -33,0 +33,1 @@\n+#include \"cppstdlib\/cstdlib.hpp\"\n@@ -45,2 +46,1 @@\n-#include \"runtime\/atomic.hpp\"\n-#include \"runtime\/crac.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -538,7 +538,0 @@\n-  if (UseNUMA) {\n-    int lgrp_id = os::numa_get_group_id();\n-    if (lgrp_id != -1) {\n-      thread->set_lgrp_id(lgrp_id);\n-    }\n-  }\n-\n@@ -602,7 +595,0 @@\n-  if (UseNUMA) {\n-    int lgrp_id = os::numa_get_group_id();\n-    if (lgrp_id != -1) {\n-      thread->set_lgrp_id(lgrp_id);\n-    }\n-  }\n-\n@@ -857,2 +843,2 @@\n-julong os::available_memory() {\n-  return win32::available_memory();\n+bool os::available_memory(physical_memory_size_type& value) {\n+  return win32::available_memory(value);\n@@ -861,2 +847,2 @@\n-julong os::free_memory() {\n-  return win32::available_memory();\n+bool os::free_memory(physical_memory_size_type& value) {\n+  return win32::available_memory(value);\n@@ -865,1 +851,1 @@\n-julong os::win32::available_memory() {\n+bool os::win32::available_memory(physical_memory_size_type& value) {\n@@ -870,3 +856,8 @@\n-  GlobalMemoryStatusEx(&ms);\n-\n-  return (julong)ms.ullAvailPhys;\n+  BOOL res = GlobalMemoryStatusEx(&ms);\n+  if (res == TRUE) {\n+    value = static_cast<physical_memory_size_type>(ms.ullAvailPhys);\n+    return true;\n+  } else {\n+    assert(false, \"GlobalMemoryStatusEx failed in os::win32::available_memory(): %lu\", ::GetLastError());\n+    return false;\n+  }\n@@ -875,1 +866,1 @@\n-jlong os::total_swap_space() {\n+bool os::total_swap_space(physical_memory_size_type& value) {\n@@ -878,2 +869,8 @@\n-  GlobalMemoryStatusEx(&ms);\n-  return (jlong) ms.ullTotalPageFile;\n+  BOOL res = GlobalMemoryStatusEx(&ms);\n+  if (res == TRUE) {\n+    value = static_cast<physical_memory_size_type>(ms.ullTotalPageFile);\n+    return true;\n+  } else {\n+    assert(false, \"GlobalMemoryStatusEx failed in os::total_swap_space(): %lu\", ::GetLastError());\n+    return false;\n+  }\n@@ -882,1 +879,1 @@\n-jlong os::free_swap_space() {\n+bool os::free_swap_space(physical_memory_size_type& value) {\n@@ -885,2 +882,8 @@\n-  GlobalMemoryStatusEx(&ms);\n-  return (jlong) ms.ullAvailPageFile;\n+  BOOL res = GlobalMemoryStatusEx(&ms);\n+  if (res == TRUE) {\n+    value = static_cast<physical_memory_size_type>(ms.ullAvailPageFile);\n+    return true;\n+  } else {\n+    assert(false, \"GlobalMemoryStatusEx failed in os::free_swap_space(): %lu\", ::GetLastError());\n+    return false;\n+  }\n@@ -889,1 +892,1 @@\n-julong os::physical_memory() {\n+physical_memory_size_type os::physical_memory() {\n@@ -906,7 +909,0 @@\n-bool os::has_allocatable_memory_limit(size_t* limit) {\n-  MEMORYSTATUSEX ms;\n-  ms.dwLength = sizeof(ms);\n-  GlobalMemoryStatusEx(&ms);\n-  *limit = (size_t)ms.ullAvailVirtual;\n-  return true;\n-}\n@@ -1213,5 +1209,3 @@\n-bool os::supports_vtime() { return true; }\n-\n-double os::elapsedVTime() {\n-  FILETIME created;\n-  FILETIME exited;\n+double os::elapsed_process_cpu_time() {\n+  FILETIME create;\n+  FILETIME exit;\n@@ -1220,5 +1214,3 @@\n-  if (GetThreadTimes(GetCurrentThread(), &created, &exited, &kernel, &user) != 0) {\n-    \/\/ the resolution of windows_to_java_time() should be sufficient (ms)\n-    return (double) (windows_to_java_time(kernel) + windows_to_java_time(user)) \/ MILLIUNITS;\n-  } else {\n-    return elapsedTime();\n+\n+  if (GetProcessTimes(GetCurrentProcess(), &create, &exit, &kernel, &user) == 0) {\n+    return -1;\n@@ -1226,0 +1218,21 @@\n+\n+  SYSTEMTIME user_total;\n+  if (FileTimeToSystemTime(&user, &user_total) == 0) {\n+    return -1;\n+  }\n+\n+  SYSTEMTIME kernel_total;\n+  if (FileTimeToSystemTime(&kernel, &kernel_total) == 0) {\n+    return -1;\n+  }\n+\n+  double user_seconds =\n+      double(user_total.wHour) * 3600.0 + double(user_total.wMinute) * 60.0 +\n+      double(user_total.wSecond) + double(user_total.wMilliseconds) \/ 1000.0;\n+\n+  double kernel_seconds = double(kernel_total.wHour) * 3600.0 +\n+                          double(kernel_total.wMinute) * 60.0 +\n+                          double(kernel_total.wSecond) +\n+                          double(kernel_total.wMilliseconds) \/ 1000.0;\n+\n+  return user_seconds + kernel_seconds;\n@@ -1420,1 +1433,1 @@\n-    snprintf(name, MAX_PATH, \"<not available>\");\n+    os::snprintf_checked(name, MAX_PATH, \"<not available>\");\n@@ -1436,1 +1449,1 @@\n-      os::snprintf(buf, sizeof(buf), \"Attempt to unload dll failed (error code %d)\", (int) errcode);\n+      os::snprintf_checked(buf, sizeof(buf), \"Attempt to unload dll failed (error code %d)\", (int) errcode);\n@@ -1748,0 +1761,2 @@\n+  Events::log_dll_message(nullptr, \"Attempting to load shared library %s\", name);\n+\n@@ -1758,0 +1773,6 @@\n+\n+  if (ebuf == nullptr || ebuflen < 1) {\n+    \/\/ no error reporting requested\n+    return nullptr;\n+  }\n+\n@@ -1854,3 +1875,3 @@\n-    os::snprintf(ebuf, ebuflen - 1,\n-                 \"Can't load %s-bit .dll on a %s-bit platform\",\n-                 lib_arch_str, running_arch_str);\n+    os::snprintf_checked(ebuf, ebuflen,\n+                         \"Can't load %s-bit .dll on a %s-bit platform\",\n+                         lib_arch_str, running_arch_str);\n@@ -1859,3 +1880,3 @@\n-    os::snprintf(ebuf, ebuflen - 1,\n-                 \"Can't load this .dll (machine code=0x%x) on a %s-bit platform\",\n-                 lib_arch, running_arch_str);\n+    os::snprintf_checked(ebuf, ebuflen,\n+                         \"Can't load this .dll (machine code=0x%x) on a %s-bit platform\",\n+                         lib_arch, running_arch_str);\n@@ -2290,0 +2311,2 @@\n+  assert(buf != nullptr && len > 0, \"invalid buffer passed\");\n+\n@@ -2473,1 +2496,1 @@\n-    Atomic::inc(&pending_signals[sig]);\n+    AtomicAccess::inc(&pending_signals[sig]);\n@@ -2486,1 +2509,1 @@\n-      if (n > 0 && n == Atomic::cmpxchg(&pending_signals[i], n, n - 1)) {\n+      if (n > 0 && n == AtomicAccess::cmpxchg(&pending_signals[i], n, n - 1)) {\n@@ -2655,0 +2678,4 @@\n+\n+  if (handle_safefetch(exception_code, pc, (void*)exceptionInfo->ContextRecord)) {\n+    return EXCEPTION_CONTINUE_EXECUTION;\n+  }\n@@ -2657,5 +2684,0 @@\n-#else\n-  #error unknown architecture\n-#endif\n-  Thread* t = Thread::current_or_null_safe();\n-#if defined(_M_AMD64)\n@@ -2669,1 +2691,0 @@\n-#if !defined(PRODUCT)\n@@ -2676,1 +2697,2 @@\n-#endif\n+#else\n+  #error unknown architecture\n@@ -2687,0 +2709,1 @@\n+  Thread* t = Thread::current_or_null_safe();\n@@ -2717,1 +2740,0 @@\n-#if !defined(USE_VECTORED_EXCEPTION_HANDLING)\n@@ -2720,1 +2742,0 @@\n-#endif\n@@ -2772,1 +2793,0 @@\n-#if !defined(USE_VECTORED_EXCEPTION_HANDLING)\n@@ -2775,1 +2795,0 @@\n-#endif\n@@ -2798,13 +2817,0 @@\n-#ifdef _M_ARM64\n-    if (in_java &&\n-        (exception_code == EXCEPTION_ILLEGAL_INSTRUCTION ||\n-          exception_code == EXCEPTION_ILLEGAL_INSTRUCTION_2)) {\n-      if (nativeInstruction_at(pc)->is_sigill_not_entrant()) {\n-        if (TraceTraps) {\n-          tty->print_cr(\"trap: not_entrant\");\n-        }\n-        return Handle_Exception(exceptionInfo, SharedRuntime::get_handle_wrong_method_stub());\n-      }\n-    }\n-#endif\n-\n@@ -2837,3 +2843,1 @@\n-          address deopt = nm->is_method_handle_return(pc) ?\n-            nm->deopt_mh_handler_begin() :\n-            nm->deopt_handler_begin();\n+          address deopt = nm->deopt_handler_entry();\n@@ -2850,8 +2854,1 @@\n-#if !defined(USE_VECTORED_EXCEPTION_HANDLING)\n-  if (exception_code != EXCEPTION_BREAKPOINT) {\n-    report_error(t, exception_code, pc, exception_record,\n-                 exceptionInfo->ContextRecord);\n-  }\n-#endif\n-  return EXCEPTION_CONTINUE_SEARCH;\n-}\n+  bool should_report_error = (exception_code != EXCEPTION_BREAKPOINT);\n@@ -2859,8 +2856,3 @@\n-#if defined(USE_VECTORED_EXCEPTION_HANDLING)\n-LONG WINAPI topLevelVectoredExceptionFilter(struct _EXCEPTION_POINTERS* exceptionInfo) {\n-  PEXCEPTION_RECORD exceptionRecord = exceptionInfo->ExceptionRecord;\n-  address pc = (address) exceptionInfo->ContextRecord->Pc;\n-#elif defined(_M_AMD64)\n-  address pc = (address) exceptionInfo->ContextRecord->Rip;\n-#else\n-  #error unknown architecture\n+  should_report_error = should_report_error &&\n+                        FAILED(exception_code) &&\n+                        (exception_code != EXCEPTION_UNCAUGHT_CXX_EXCEPTION);\n@@ -2870,10 +2862,3 @@\n-  \/\/ Fast path for code part of the code cache\n-  if (CodeCache::low_bound() <= pc && pc < CodeCache::high_bound()) {\n-    return topLevelExceptionFilter(exceptionInfo);\n-  }\n-\n-  \/\/ If the exception occurred in the codeCache, pass control\n-  \/\/ to our normal exception handler.\n-  CodeBlob* cb = CodeCache::find_blob(pc);\n-  if (cb != nullptr) {\n-    return topLevelExceptionFilter(exceptionInfo);\n+  if (should_report_error) {\n+    report_error(t, exception_code, pc, exception_record,\n+                 exceptionInfo->ContextRecord);\n@@ -2884,1 +2869,0 @@\n-#endif\n@@ -3214,1 +3198,0 @@\n-#if !defined(IA32)\n@@ -3223,1 +3206,0 @@\n-#endif\n@@ -3241,1 +3223,1 @@\n-  int n = snprintf(fullname, fullname_len + 1, \"%s%s\", dir, name_template);\n+  int n = os::snprintf(fullname, fullname_len + 1, \"%s%s\", dir, name_template);\n@@ -3339,0 +3321,45 @@\n+size_t os::commit_memory_limit() {\n+  BOOL is_in_job_object = false;\n+  BOOL res = IsProcessInJob(GetCurrentProcess(), nullptr, &is_in_job_object);\n+  if (!res) {\n+    char buf[512];\n+    size_t buf_len = os::lasterror(buf, sizeof(buf));\n+    warning(\"Attempt to determine whether the process is running in a job failed for commit limit: %s\", buf_len != 0 ? buf : \"<unknown error>\");\n+\n+    \/\/ Conservatively assume no limit when there was an error calling IsProcessInJob.\n+    return SIZE_MAX;\n+  }\n+\n+  if (!is_in_job_object) {\n+    \/\/ Not limited by a Job Object\n+    return SIZE_MAX;\n+  }\n+\n+  JOBOBJECT_EXTENDED_LIMIT_INFORMATION jeli = {};\n+  res = QueryInformationJobObject(nullptr, JobObjectExtendedLimitInformation, &jeli, sizeof(jeli), nullptr);\n+  if (!res) {\n+    char buf[512];\n+    size_t buf_len = os::lasterror(buf, sizeof(buf));\n+    warning(\"Attempt to query job object information failed for commit limit: %s\", buf_len != 0 ? buf : \"<unknown error>\");\n+\n+    \/\/ Conservatively assume no limit when there was an error calling QueryInformationJobObject.\n+    return SIZE_MAX;\n+  }\n+\n+  if (jeli.BasicLimitInformation.LimitFlags & JOB_OBJECT_LIMIT_PROCESS_MEMORY) {\n+    return jeli.ProcessMemoryLimit;\n+  }\n+\n+  if (jeli.BasicLimitInformation.LimitFlags & JOB_OBJECT_LIMIT_JOB_MEMORY) {\n+    return jeli.JobMemoryLimit;\n+  }\n+\n+  \/\/ No limit\n+  return SIZE_MAX;\n+}\n+\n+size_t os::reserve_memory_limit() {\n+  \/\/ Virtual address space cannot be limited on Windows.\n+  return SIZE_MAX;\n+}\n+\n@@ -3773,0 +3800,1 @@\n+void os::numa_set_thread_affinity(Thread *thread, int node) { }\n@@ -3775,1 +3803,0 @@\n-bool os::numa_topology_changed()                       { return false; }\n@@ -3946,1 +3973,1 @@\n-int    os::win32::_processor_type            = 0;\n+int                       os::win32::_processor_type            = 0;\n@@ -3948,2 +3975,2 @@\n-int    os::win32::_processor_level           = 0;\n-julong os::win32::_physical_memory           = 0;\n+int                       os::win32::_processor_level           = 0;\n+physical_memory_size_type os::win32::_physical_memory           = 0;\n@@ -3951,1 +3978,1 @@\n-bool   os::win32::_is_windows_server         = false;\n+bool                      os::win32::_is_windows_server         = false;\n@@ -3956,1 +3983,1 @@\n-bool   os::win32::_has_exit_bug              = true;\n+bool                      os::win32::_has_exit_bug              = true;\n@@ -3958,4 +3985,4 @@\n-int    os::win32::_major_version             = 0;\n-int    os::win32::_minor_version             = 0;\n-int    os::win32::_build_number              = 0;\n-int    os::win32::_build_minor               = 0;\n+int                       os::win32::_major_version             = 0;\n+int                       os::win32::_minor_version             = 0;\n+int                       os::win32::_build_number              = 0;\n+int                       os::win32::_build_minor               = 0;\n@@ -3963,2 +3990,2 @@\n-bool   os::win32::_processor_group_warning_displayed = false;\n-bool   os::win32::_job_object_processor_group_warning_displayed = false;\n+bool                      os::win32::_processor_group_warning_displayed = false;\n+bool                      os::win32::_job_object_processor_group_warning_displayed = false;\n@@ -4179,6 +4206,3 @@\n-  GlobalMemoryStatusEx(&ms);\n-  _physical_memory = ms.ullTotalPhys;\n-\n-  if (FLAG_IS_DEFAULT(MaxRAM)) {\n-    \/\/ Adjust MaxRAM according to the maximum virtual address space available.\n-    FLAG_SET_DEFAULT(MaxRAM, MIN2(MaxRAM, (uint64_t) ms.ullTotalVirtual));\n+  BOOL res = GlobalMemoryStatusEx(&ms);\n+  if (res != TRUE) {\n+    assert(false, \"GlobalMemoryStatusEx failed in os::win32::initialize_system_info(): %lu\", ::GetLastError());\n@@ -4186,0 +4210,1 @@\n+  _physical_memory = static_cast<physical_memory_size_type>(ms.ullTotalPhys);\n@@ -4279,1 +4304,1 @@\n-    } else if (Atomic::load_acquire(&process_exiting) == 0) {\n+    } else if (AtomicAccess::load_acquire(&process_exiting) == 0) {\n@@ -4283,1 +4308,1 @@\n-        Atomic::cmpxchg(&process_exiting, (DWORD)0, GetCurrentThreadId());\n+        AtomicAccess::cmpxchg(&process_exiting, (DWORD)0, GetCurrentThreadId());\n@@ -4287,1 +4312,1 @@\n-      if (what == EPT_THREAD && Atomic::load_acquire(&process_exiting) == 0) {\n+      if (what == EPT_THREAD && AtomicAccess::load_acquire(&process_exiting) == 0) {\n@@ -4400,1 +4425,1 @@\n-        Atomic::load_acquire(&process_exiting) != 0 &&\n+        AtomicAccess::load_acquire(&process_exiting) != 0 &&\n@@ -4517,1 +4542,1 @@\n-  topLevelVectoredExceptionHandler = AddVectoredExceptionHandler(1, topLevelVectoredExceptionFilter);\n+  topLevelVectoredExceptionHandler = AddVectoredExceptionHandler(1, topLevelExceptionFilter);\n@@ -4681,2 +4706,2 @@\n-      errno = ::GetLastError();\n-      log_debug(os)(\"is_symbolic_link() failed to FindClose: GetLastError->%ld.\", errno);\n+      DWORD errcode = ::GetLastError();\n+      log_debug(os)(\"is_symbolic_link() failed to FindClose: GetLastError->%lu.\", errcode);\n@@ -4686,2 +4711,2 @@\n-    errno = ::GetLastError();\n-    log_debug(os)(\"is_symbolic_link() failed to FindFirstFileW: GetLastError->%ld.\", errno);\n+    DWORD errcode = ::GetLastError();\n+    log_debug(os)(\"is_symbolic_link() failed to FindFirstFileW: GetLastError->%lu.\", errcode);\n@@ -4697,2 +4722,2 @@\n-    errno = ::GetLastError();\n-    log_debug(os)(\"get_path_to_target() failed to CreateFileW: GetLastError->%ld.\", errno);\n+    DWORD errcode = ::GetLastError();\n+    log_debug(os)(\"get_path_to_target() failed to CreateFileW: GetLastError->%lu.\", errcode);\n@@ -4706,2 +4731,2 @@\n-    errno = ::GetLastError();\n-    log_debug(os)(\"get_path_to_target() failed to GetFinalPathNameByHandleW: GetLastError->%ld.\", errno);\n+    DWORD errcode = ::GetLastError();\n+    log_debug(os)(\"get_path_to_target() failed to GetFinalPathNameByHandleW: GetLastError->%lu.\", errcode);\n@@ -4717,2 +4742,2 @@\n-    errno = ::GetLastError();\n-    log_debug(os)(\"get_path_to_target() failed to GetFinalPathNameByHandleW: GetLastError->%ld.\", errno);\n+    DWORD errcode = ::GetLastError();\n+    log_debug(os)(\"get_path_to_target() failed to GetFinalPathNameByHandleW: GetLastError->%lu.\", errcode);\n@@ -4723,2 +4748,2 @@\n-    errno = ::GetLastError();\n-    log_debug(os)(\"get_path_to_target() failed to CloseHandle: GetLastError->%ld.\", errno);\n+    DWORD errcode = ::GetLastError();\n+    log_debug(os)(\"get_path_to_target() failed to CloseHandle: GetLastError->%lu.\", errcode);\n@@ -4830,3 +4855,1 @@\n-      \/\/ it is a symbolic link, but we failed to resolve it,\n-      \/\/ errno has been set in the call to get_path_to_target(),\n-      \/\/ no need to overwrite it\n+      \/\/ it is a symbolic link, but we failed to resolve it\n@@ -4834,0 +4857,1 @@\n+      errno = ENOENT;\n@@ -4843,2 +4867,2 @@\n-    errno = ::GetLastError();\n-    log_debug(os)(\"os::stat() failed to GetFileAttributesExW: GetLastError->%ld.\", errno);\n+    DWORD errcode = ::GetLastError();\n+    log_debug(os)(\"os::stat() failed to GetFileAttributesExW: GetLastError->%lu.\", errcode);\n@@ -4847,0 +4871,5 @@\n+    if (errcode == ERROR_FILE_NOT_FOUND || errcode == ERROR_PATH_NOT_FOUND) {\n+      errno = ENOENT;\n+    } else {\n+      errno = 0;\n+    }\n@@ -5044,3 +5073,1 @@\n-      \/\/ it is a symbolic link, but we failed to resolve it,\n-      \/\/ errno has been set in the call to get_path_to_target(),\n-      \/\/ no need to overwrite it\n+      \/\/ it is a symbolic link, but we failed to resolve it\n@@ -5048,0 +5075,1 @@\n+      errno = ENOENT;\n@@ -5054,1 +5082,1 @@\n-  \/\/ if opening files failed, GetLastError should be called immediately after that\n+  \/\/ if opening files failed, errno has been set to indicate the problem\n@@ -5056,2 +5084,1 @@\n-    errno = ::GetLastError();\n-    log_debug(os)(\"os::open() failed to _wopen: GetLastError->%ld.\", errno);\n+    log_debug(os)(\"os::open() failed to _wopen: errno->%s.\", strerror(errno));\n@@ -5125,1 +5152,2 @@\n-    errno = ::GetLastError();\n+    DWORD errcode = ::GetLastError();\n+    log_debug(os)(\"os::dir_is_empty() failed to FindFirstFileW: GetLastError->%lu.\", errcode);\n@@ -5321,0 +5349,1 @@\n+    ErrnoPreserver ep;\n@@ -5588,1 +5617,1 @@\n-    if (Atomic::cmpxchg(&_Event, v, v-1) == v) break;\n+    if (AtomicAccess::cmpxchg(&_Event, v, v-1) == v) break;\n@@ -5651,1 +5680,1 @@\n-    if (Atomic::cmpxchg(&_Event, v, v-1) == v) break;\n+    if (AtomicAccess::cmpxchg(&_Event, v, v-1) == v) break;\n@@ -5698,1 +5727,1 @@\n-  if (Atomic::xchg(&_Event, 1) >= 0) return;\n+  if (AtomicAccess::xchg(&_Event, 1) >= 0) return;\n@@ -6305,0 +6334,103 @@\n+\n+\/*\n+ * Windows\/x64 does not use stack frames the way expected by Java:\n+ * [1] in most cases, there is no frame pointer. All locals are addressed via RSP\n+ * [2] in rare cases, when alloca() is used, a frame pointer is used, but this may\n+ *     not be RBP.\n+ * See http:\/\/msdn.microsoft.com\/en-us\/library\/ew5tede7.aspx\n+ *\n+ * So it's not possible to print the native stack using the\n+ *     while (...) {...  fr = os::get_sender_for_C_frame(&fr); }\n+ * loop in vmError.cpp. We need to roll our own loop.\n+ * This approach works for Windows AArch64 as well.\n+ *\/\n+bool os::win32::platform_print_native_stack(outputStream* st, const void* context,\n+                                            char* buf, int buf_size, address& lastpc)\n+{\n+  CONTEXT ctx;\n+  if (context != nullptr) {\n+    memcpy(&ctx, context, sizeof(ctx));\n+  } else {\n+    RtlCaptureContext(&ctx);\n+  }\n+\n+  st->print_cr(\"Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)\");\n+\n+  DWORD machine_type;\n+  STACKFRAME stk;\n+  memset(&stk, 0, sizeof(stk));\n+  stk.AddrStack.Mode      = AddrModeFlat;\n+  stk.AddrFrame.Mode      = AddrModeFlat;\n+  stk.AddrPC.Mode         = AddrModeFlat;\n+\n+#if defined(_M_AMD64)\n+  stk.AddrStack.Offset    = ctx.Rsp;\n+  stk.AddrFrame.Offset    = ctx.Rbp;\n+  stk.AddrPC.Offset       = ctx.Rip;\n+  machine_type            = IMAGE_FILE_MACHINE_AMD64;\n+#elif defined(_M_ARM64)\n+  stk.AddrStack.Offset    = ctx.Sp;\n+  stk.AddrFrame.Offset    = ctx.Fp;\n+  stk.AddrPC.Offset       = ctx.Pc;\n+  machine_type            = IMAGE_FILE_MACHINE_ARM64;\n+#else\n+  #error unknown architecture\n+#endif\n+\n+  \/\/ Ensure we consider dynamically loaded DLLs\n+  SymbolEngine::refreshModuleList();\n+\n+  int count = 0;\n+  address lastpc_internal = 0;\n+  while (count++ < StackPrintLimit) {\n+    intptr_t* sp = (intptr_t*)stk.AddrStack.Offset;\n+    intptr_t* fp = (intptr_t*)stk.AddrFrame.Offset; \/\/ NOT necessarily the same as ctx.Rbp!\n+    address pc = (address)stk.AddrPC.Offset;\n+\n+    if (pc != nullptr) {\n+      if (count == 2 && lastpc_internal == pc) {\n+        \/\/ Skip it -- StackWalk64() may return the same PC\n+        \/\/ (but different SP) on the first try.\n+      } else {\n+        \/\/ Don't try to create a frame(sp, fp, pc) -- on WinX64, stk.AddrFrame\n+        \/\/ may not contain what Java expects, and may cause the frame() constructor\n+        \/\/ to crash. Let's just print out the symbolic address.\n+        frame::print_C_frame(st, buf, buf_size, pc);\n+        \/\/ print source file and line, if available\n+        char buf[128];\n+        int line_no;\n+        if (SymbolEngine::get_source_info(pc, buf, sizeof(buf), &line_no)) {\n+          st->print(\"  (%s:%d)\", buf, line_no);\n+        } else {\n+          st->print(\"  (no source info available)\");\n+        }\n+        st->cr();\n+      }\n+      lastpc_internal = pc;\n+    }\n+\n+    PVOID p = WindowsDbgHelp::symFunctionTableAccess64(GetCurrentProcess(), stk.AddrPC.Offset);\n+    if (p == nullptr) {\n+      \/\/ StackWalk64() can't handle this PC. Calling StackWalk64 again may cause crash.\n+      lastpc = lastpc_internal;\n+      break;\n+    }\n+\n+    BOOL result = WindowsDbgHelp::stackWalk64(\n+        machine_type,              \/\/ __in      DWORD MachineType,\n+        GetCurrentProcess(),       \/\/ __in      HANDLE hProcess,\n+        GetCurrentThread(),        \/\/ __in      HANDLE hThread,\n+        &stk,                      \/\/ __inout   LP STACKFRAME64 StackFrame,\n+        &ctx);                     \/\/ __inout   PVOID ContextRecord,\n+\n+    if (!result) {\n+      break;\n+    }\n+  }\n+  if (count > StackPrintLimit) {\n+    st->print_cr(\"...<more frames>...\");\n+  }\n+  st->cr();\n+\n+  return true;\n+}\n","filename":"src\/hotspot\/os\/windows\/os_windows.cpp","additions":298,"deletions":166,"binary":false,"changes":464,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -41,12 +41,12 @@\n-  static int    _processor_type;\n-  static int    _processor_level;\n-  static julong _physical_memory;\n-  static bool   _is_windows_server;\n-  static bool   _has_exit_bug;\n-  static bool   _processor_group_warning_displayed;\n-  static bool   _job_object_processor_group_warning_displayed;\n-\n-  static int    _major_version;\n-  static int    _minor_version;\n-  static int    _build_number;\n-  static int    _build_minor;\n+  static int                       _processor_type;\n+  static int                       _processor_level;\n+  static physical_memory_size_type _physical_memory;\n+  static bool                      _is_windows_server;\n+  static bool                      _has_exit_bug;\n+  static bool                      _processor_group_warning_displayed;\n+  static bool                      _job_object_processor_group_warning_displayed;\n+\n+  static int                       _major_version;\n+  static int                       _minor_version;\n+  static int                       _build_number;\n+  static int                       _build_minor;\n@@ -107,3 +107,3 @@\n-  static julong available_memory();\n-  static julong free_memory();\n-  static julong physical_memory() { return _physical_memory; }\n+  static bool available_memory(physical_memory_size_type& value);\n+  static bool free_memory(physical_memory_size_type& value);\n+  static physical_memory_size_type physical_memory() { return _physical_memory; }\n@@ -154,0 +154,2 @@\n+\n+  static void context_set_pc(CONTEXT* uc, address pc);\n","filename":"src\/hotspot\/os\/windows\/os_windows.hpp","additions":18,"deletions":16,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -57,1 +57,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -65,0 +65,1 @@\n+#include \"runtime\/stubInfo.hpp\"\n@@ -106,8 +107,1 @@\n-\n-CodeBlob* Runtime1::_blobs[(int)C1StubId::NUM_STUBIDS];\n-\n-#define C1_BLOB_NAME_DEFINE(name)  \"C1 Runtime \" # name \"_blob\",\n-const char *Runtime1::_blob_names[] = {\n-  C1_STUBS_DO(C1_BLOB_NAME_DEFINE)\n-};\n-#undef C1_STUB_NAME_DEFINE\n+CodeBlob* Runtime1::_blobs[StubInfo::C1_STUB_COUNT];\n@@ -191,1 +185,1 @@\n-class C1StubIdStubAssemblerCodeGenClosure: public StubAssemblerCodeGenClosure {\n+class C1StubAssemblerCodeGenClosure: public StubAssemblerCodeGenClosure {\n@@ -193,1 +187,1 @@\n-  C1StubId _id;\n+  StubId _id;\n@@ -195,1 +189,3 @@\n-  C1StubIdStubAssemblerCodeGenClosure(C1StubId id) : _id(id) {}\n+  C1StubAssemblerCodeGenClosure(StubId id) : _id(id) {\n+    assert(StubInfo::is_c1(_id), \"not a c1 stub id %s\", StubInfo::name(_id));\n+  }\n@@ -201,3 +197,3 @@\n-CodeBlob* Runtime1::generate_blob(BufferBlob* buffer_blob, C1StubId id, const char* name, bool expect_oop_map, StubAssemblerCodeGenClosure* cl) {\n-  if ((int)id >= 0) {\n-    CodeBlob* blob = AOTCodeCache::load_code_blob(AOTCodeEntry::C1Blob, (uint)id, name, 0, nullptr);\n+CodeBlob* Runtime1::generate_blob(BufferBlob* buffer_blob, StubId id, const char* name, bool expect_oop_map, StubAssemblerCodeGenClosure* cl) {\n+  if (id != StubId::NO_STUBID) {\n+    CodeBlob* blob = AOTCodeCache::load_code_blob(AOTCodeEntry::C1Blob, StubInfo::blob(id));\n@@ -243,1 +239,1 @@\n-    AOTCodeCache::store_code_blob(*blob, AOTCodeEntry::C1Blob, (uint)id, name, 0, nullptr);\n+    AOTCodeCache::store_code_blob(*blob, AOTCodeEntry::C1Blob, StubInfo::blob(id));\n@@ -248,2 +244,2 @@\n-bool Runtime1::generate_blob_for(BufferBlob* buffer_blob, C1StubId id) {\n-  assert(C1StubId::NO_STUBID < id && id < C1StubId::NUM_STUBIDS, \"illegal stub id\");\n+bool Runtime1::generate_blob_for(BufferBlob* buffer_blob, StubId id) {\n+  assert(StubInfo::is_c1(id), \"not a c1 stub %s\", StubInfo::name(id));\n@@ -255,6 +251,6 @@\n-  case C1StubId::dtrace_object_alloc_id:\n-  case C1StubId::slow_subtype_check_id:\n-  case C1StubId::fpu2long_stub_id:\n-  case C1StubId::unwind_exception_id:\n-  case C1StubId::counter_overflow_id:\n-  case C1StubId::is_instance_of_id:\n+  case StubId::c1_dtrace_object_alloc_id:\n+  case StubId::c1_slow_subtype_check_id:\n+  case StubId::c1_fpu2long_stub_id:\n+  case StubId::c1_unwind_exception_id:\n+  case StubId::c1_counter_overflow_id:\n+  case StubId::c1_is_instance_of_id:\n@@ -267,1 +263,1 @@\n-  C1StubIdStubAssemblerCodeGenClosure cl(id);\n+  C1StubAssemblerCodeGenClosure cl(id);\n@@ -270,1 +266,2 @@\n-  _blobs[(int)id] = blob;\n+  int idx = StubInfo::c1_offset(id);   \/\/ will assert on non-c1 id\n+  _blobs[idx] = blob;\n@@ -277,4 +274,5 @@\n-  \/\/ generate stubs\n-  int limit = (int)C1StubId::NUM_STUBIDS;\n-  for (int id = 0; id <= (int)C1StubId::forward_exception_id; id++) {\n-    if (!generate_blob_for(blob, (C1StubId) id)) {\n+  \/\/ iterate blobs in C1 group and generate a single stub per blob\n+  StubId id = StubInfo::stub_base(StubGroup::C1);\n+  StubId limit = StubInfo::next(StubInfo::stub_max(StubGroup::C1));\n+  for (; id != limit; id = StubInfo::next(id)) {\n+    if (!generate_blob_for(blob, id)) {\n@@ -283,5 +281,3 @@\n-  }\n-  AOTCodeCache::init_early_c1_table();\n-  for (int id = (int)C1StubId::forward_exception_id+1; id < limit; id++) {\n-    if (!generate_blob_for(blob, (C1StubId) id)) {\n-      return false;\n+    if (id == StubId::c1_forward_exception_id) {\n+      \/\/ publish early c1 stubs at this point so later stubs can refer to them\n+      AOTCodeCache::init_early_c1_table();\n@@ -294,4 +290,6 @@\n-    for (int id = 0; id < limit; id++) {\n-      _blobs[id]->print();\n-      if (_blobs[id]->oop_maps() != nullptr) {\n-        _blobs[id]->oop_maps()->print();\n+    id = StubInfo::stub_base(StubGroup::C1);\n+    for (; id != limit; id = StubInfo::next(id)) {\n+      CodeBlob* blob = blob_for(id);\n+      blob->print();\n+      if (blob->oop_maps() != nullptr) {\n+        blob->oop_maps()->print();\n@@ -306,3 +304,3 @@\n-CodeBlob* Runtime1::blob_for(C1StubId id) {\n-  assert(C1StubId::NO_STUBID < id && id < C1StubId::NUM_STUBIDS, \"illegal stub id\");\n-  return _blobs[(int)id];\n+CodeBlob* Runtime1::blob_for(StubId id) {\n+  int idx = StubInfo::c1_offset(id);   \/\/ will assert on non-c1 id\n+  return _blobs[idx];\n@@ -312,3 +310,2 @@\n-const char* Runtime1::name_for(C1StubId id) {\n-  assert(C1StubId::NO_STUBID < id && id < C1StubId::NUM_STUBIDS, \"illegal stub id\");\n-  return _blob_names[(int)id];\n+const char* Runtime1::name_for(StubId id) {\n+  return StubInfo::name(id);\n@@ -318,4 +315,5 @@\n-  int limit = (int)C1StubId::NUM_STUBIDS;\n-  for (int i = 0; i < limit; i++) {\n-    C1StubId id = (C1StubId)i;\n-    if (entry == entry_for(id)) return name_for(id);\n+  \/\/ iterate stubs starting from C1 group base\n+  StubId id = StubInfo::stub_base(StubGroup::C1);\n+  StubId limit = StubInfo::next(StubInfo::stub_max(StubGroup::C1));\n+  for (; id != limit; id = StubInfo::next(id)) {\n+    if (entry == entry_for(id)) return StubInfo::name(id);\n@@ -367,0 +365,1 @@\n+  FUNCTION_CASE(entry, StubRoutines::dsinh());\n@@ -453,1 +452,1 @@\n-JRT_ENTRY(void, Runtime1::unimplemented_entry(JavaThread* current, C1StubId id))\n+JRT_ENTRY(void, Runtime1::unimplemented_entry(JavaThread* current, StubId id))\n@@ -545,3 +544,0 @@\n-  \/\/ Reset method handle flag.\n-  current->set_is_method_handle_return(false);\n-\n@@ -553,2 +549,2 @@\n-  if (current->last_frame().cb() == Runtime1::blob_for(C1StubId::handle_exception_from_callee_id)) {\n-    \/\/ The C1StubId::handle_exception_from_callee_id handler is invoked after the\n+  if (current->last_frame().cb() == Runtime1::blob_for(StubId::c1_handle_exception_from_callee_id)) {\n+    \/\/ The StubId::c1_handle_exception_from_callee_id handler is invoked after the\n@@ -626,2 +622,0 @@\n-      \/\/ Set flag if return address is a method handle call site.\n-      current->set_is_method_handle_return(nm->is_method_handle_return(pc));\n@@ -664,2 +658,0 @@\n-  \/\/ Set flag if return address is a method handle call site.\n-  current->set_is_method_handle_return(nm->is_method_handle_return(pc));\n@@ -782,3 +774,0 @@\n-  if (LockingMode == LM_MONITOR) {\n-    lock->set_obj(obj);\n-  }\n@@ -821,1 +810,1 @@\n-    if (nm->make_not_entrant(\"C1 deoptimize\", true \/* OK to recompile *\/)) {\n+    if (nm->make_not_entrant(nmethod::InvalidationReason::C1_DEOPTIMIZE, true \/* OK to recompile *\/)) {\n@@ -950,1 +939,1 @@\n-JRT_ENTRY(void, Runtime1::patch_code(JavaThread* current, C1StubId stub_id ))\n+JRT_ENTRY(void, Runtime1::patch_code(JavaThread* current, StubId stub_id ))\n@@ -987,1 +976,1 @@\n-    (stub_id == C1StubId::load_klass_patching_id || stub_id == C1StubId::load_mirror_patching_id);\n+    (stub_id == StubId::c1_load_klass_patching_id || stub_id == StubId::c1_load_mirror_patching_id);\n@@ -989,1 +978,1 @@\n-  if (stub_id == C1StubId::access_field_patching_id) {\n+  if (stub_id == StubId::c1_access_field_patching_id) {\n@@ -1072,1 +1061,1 @@\n-  } else if (stub_id == C1StubId::load_appendix_patching_id) {\n+  } else if (stub_id == StubId::c1_load_appendix_patching_id) {\n@@ -1113,1 +1102,1 @@\n-      nm->make_not_entrant(\"C1 code patch\", true \/* OK to recompile *\/);\n+      nm->make_not_entrant(nmethod::InvalidationReason::C1_CODEPATCH, true \/* OK to recompile *\/);\n@@ -1156,1 +1145,1 @@\n-                        p2i(instr_pc), (stub_id == C1StubId::access_field_patching_id) ? \"field\" : \"klass\");\n+                        p2i(instr_pc), (stub_id == StubId::c1_access_field_patching_id) ? \"field\" : \"klass\");\n@@ -1172,1 +1161,1 @@\n-        if (stub_id == C1StubId::access_field_patching_id) {\n+        if (stub_id == StubId::c1_access_field_patching_id) {\n@@ -1198,1 +1187,1 @@\n-            if (stub_id == C1StubId::load_klass_patching_id) {\n+            if (stub_id == StubId::c1_load_klass_patching_id) {\n@@ -1210,1 +1199,1 @@\n-        } else if (stub_id == C1StubId::load_appendix_patching_id) {\n+        } else if (stub_id == StubId::c1_load_appendix_patching_id) {\n@@ -1229,1 +1218,1 @@\n-              stub_id == C1StubId::load_appendix_patching_id) &&\n+              stub_id == StubId::c1_load_appendix_patching_id) &&\n@@ -1237,2 +1226,2 @@\n-                assert(stub_id == C1StubId::load_mirror_patching_id ||\n-                       stub_id == C1StubId::load_appendix_patching_id, \"wrong stub id\");\n+                assert(stub_id == StubId::c1_load_mirror_patching_id ||\n+                       stub_id == StubId::c1_load_appendix_patching_id, \"wrong stub id\");\n@@ -1243,1 +1232,1 @@\n-                assert(stub_id == C1StubId::load_klass_patching_id, \"wrong stub id\");\n+                assert(stub_id == StubId::c1_load_klass_patching_id, \"wrong stub id\");\n@@ -1266,1 +1255,1 @@\n-              stub_id == C1StubId::load_appendix_patching_id) {\n+              stub_id == StubId::c1_load_appendix_patching_id) {\n@@ -1268,1 +1257,1 @@\n-              (stub_id == C1StubId::load_klass_patching_id) ?\n+              (stub_id == StubId::c1_load_klass_patching_id) ?\n@@ -1302,3 +1291,3 @@\n-static bool is_patching_needed(JavaThread* current, C1StubId stub_id) {\n-  if (stub_id == C1StubId::load_klass_patching_id ||\n-      stub_id == C1StubId::load_mirror_patching_id) {\n+static bool is_patching_needed(JavaThread* current, StubId stub_id) {\n+  if (stub_id == StubId::c1_load_klass_patching_id ||\n+      stub_id == StubId::c1_load_mirror_patching_id) {\n@@ -1333,1 +1322,1 @@\n-void Runtime1::patch_code(JavaThread* current, C1StubId stub_id) {\n+void Runtime1::patch_code(JavaThread* current, StubId stub_id) {\n@@ -1361,1 +1350,1 @@\n-      nm->make_not_entrant(\"C1 deoptimize for patching\", true \/* OK to recompile *\/);\n+      nm->make_not_entrant(nmethod::InvalidationReason::C1_DEOPTIMIZE_FOR_PATCHING, true \/* OK to recompile *\/);\n@@ -1388,1 +1377,1 @@\n-    patch_code(current, C1StubId::load_klass_patching_id);\n+    patch_code(current, StubId::c1_load_klass_patching_id);\n@@ -1405,1 +1394,1 @@\n-    patch_code(current, C1StubId::load_mirror_patching_id);\n+    patch_code(current, StubId::c1_load_mirror_patching_id);\n@@ -1422,1 +1411,1 @@\n-    patch_code(current, C1StubId::load_appendix_patching_id);\n+    patch_code(current, StubId::c1_load_appendix_patching_id);\n@@ -1449,1 +1438,1 @@\n-    patch_code(current, C1StubId::access_field_patching_id);\n+    patch_code(current, StubId::c1_access_field_patching_id);\n@@ -1489,1 +1478,1 @@\n-  nm->make_not_entrant(\"C1 predicate failed trap\", true \/* OK to recompile *\/);\n+  nm->make_not_entrant(nmethod::InvalidationReason::C1_PREDICATE_FAILED_TRAP, true \/* OK to recompile *\/);\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":77,"deletions":88,"binary":false,"changes":165,"status":"modified"},{"patch":"@@ -805,1 +805,1 @@\n-      nm->make_not_entrant(\"CI replay\", false \/* recompiling by ourselves *\/);\n+      nm->make_not_entrant(nmethod::InvalidationReason::CI_REPLAY, false \/* recompiling by ourselves *\/);\n@@ -1575,1 +1575,1 @@\n-      ik = ik->java_super();\n+      ik = ik->super();\n@@ -1594,1 +1594,1 @@\n-    ik = ik->java_super();\n+    ik = ik->super();\n","filename":"src\/hotspot\/share\/ci\/ciReplay.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2026, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,0 +28,1 @@\n+#include \"cds\/dynamicArchive.hpp\"\n@@ -32,1 +33,0 @@\n-#include \"classfile\/classLoaderExt.hpp\"\n@@ -45,0 +45,1 @@\n+#include \"cppstdlib\/cstdlib.hpp\"\n@@ -83,1 +84,0 @@\n-#include <stdlib.h>\n@@ -415,1 +415,1 @@\n-  JImageLocationRef location = (*JImageFindResource)(jimage_non_null(), \"\", get_jimage_version_string(), name, &size);\n+  JImageLocationRef location = 0;\n@@ -417,3 +417,2 @@\n-  if (location == 0) {\n-    TempNewSymbol class_name = SymbolTable::new_symbol(name);\n-    TempNewSymbol pkg_name = ClassLoader::package_from_class_name(class_name);\n+  TempNewSymbol class_name = SymbolTable::new_symbol(name);\n+  TempNewSymbol pkg_name = ClassLoader::package_from_class_name(class_name);\n@@ -421,15 +420,14 @@\n-    if (pkg_name != nullptr) {\n-      if (!Universe::is_module_initialized()) {\n-        location = (*JImageFindResource)(jimage_non_null(), JAVA_BASE_NAME, get_jimage_version_string(), name, &size);\n-      } else {\n-        PackageEntry* package_entry = ClassLoader::get_package_entry(pkg_name, loader_data);\n-        if (package_entry != nullptr) {\n-          ResourceMark rm(current);\n-          \/\/ Get the module name\n-          ModuleEntry* module = package_entry->module();\n-          assert(module != nullptr, \"Boot classLoader package missing module\");\n-          assert(module->is_named(), \"Boot classLoader package is in unnamed module\");\n-          const char* module_name = module->name()->as_C_string();\n-          if (module_name != nullptr) {\n-            location = (*JImageFindResource)(jimage_non_null(), module_name, get_jimage_version_string(), name, &size);\n-          }\n+  if (pkg_name != nullptr) {\n+    if (!Universe::is_module_initialized()) {\n+      location = (*JImageFindResource)(jimage_non_null(), JAVA_BASE_NAME, get_jimage_version_string(), name, &size);\n+    } else {\n+      PackageEntry* package_entry = ClassLoader::get_package_entry(pkg_name, loader_data);\n+      if (package_entry != nullptr) {\n+        ResourceMark rm(current);\n+        \/\/ Get the module name\n+        ModuleEntry* module = package_entry->module();\n+        assert(module != nullptr, \"Boot classLoader package missing module\");\n+        assert(module->is_named(), \"Boot classLoader package is in unnamed module\");\n+        const char* module_name = module->name()->as_C_string();\n+        if (module_name != nullptr) {\n+          location = (*JImageFindResource)(jimage_non_null(), module_name, get_jimage_version_string(), name, &size);\n@@ -440,0 +438,1 @@\n+\n@@ -753,1 +752,1 @@\n-      Atomic::release_store(&_first_append_entry_list, new_entry);\n+      AtomicAccess::release_store(&_first_append_entry_list, new_entry);\n@@ -1223,4 +1222,1 @@\n-    if (loader == nullptr) {\n-      \/\/ JFR classes\n-      ik->set_shared_classpath_index(0);\n-    }\n+    ik->set_shared_classpath_index(-1); \/\/ unsupported location\n@@ -1314,1 +1310,23 @@\n-  ClassLoaderExt::record_result_for_builtin_loader(checked_cast<s2>(classpath_index), ik, redefined);\n+  record_result_for_builtin_loader(checked_cast<s2>(classpath_index), ik, redefined);\n+}\n+\n+void ClassLoader::record_result_for_builtin_loader(s2 classpath_index, InstanceKlass* result, bool redefined) {\n+  assert(CDSConfig::is_dumping_archive(), \"sanity\");\n+\n+  oop loader = result->class_loader();\n+  if (SystemDictionary::is_system_class_loader(loader)) {\n+    AOTClassLocationConfig::dumptime_set_has_app_classes();\n+  } else if (SystemDictionary::is_platform_class_loader(loader)) {\n+    AOTClassLocationConfig::dumptime_set_has_platform_classes();\n+  } else {\n+    precond(loader == nullptr);\n+  }\n+\n+  if (CDSConfig::is_dumping_preimage_static_archive() || CDSConfig::is_dumping_dynamic_archive()) {\n+    if (!AOTClassLocationConfig::dumptime()->is_valid_classpath_index(classpath_index, result)) {\n+      classpath_index = -1;\n+    }\n+  }\n+\n+  AOTClassLocationConfig::dumptime_update_max_used_index(classpath_index);\n+  result->set_shared_classpath_index(classpath_index);\n@@ -1339,0 +1357,11 @@\n+\n+void ClassLoader::append_boot_classpath(ClassPathEntry* new_entry) {\n+  if (CDSConfig::is_using_archive()) {\n+    warning(\"Sharing is only supported for boot loader classes because bootstrap classpath has been appended\");\n+    FileMapInfo::current_info()->set_has_platform_or_app_classes(false);\n+    if (DynamicArchive::is_mapped()) {\n+      FileMapInfo::dynamic_info()->set_has_platform_or_app_classes(false);\n+    }\n+  }\n+  add_to_boot_append_entries(new_entry);\n+}\n","filename":"src\/hotspot\/share\/classfile\/classLoader.cpp","additions":57,"deletions":28,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -216,1 +216,1 @@\n-    return Atomic::load_acquire(&_first_append_entry_list);\n+    return AtomicAccess::load_acquire(&_first_append_entry_list);\n@@ -349,0 +349,1 @@\n+  static void record_result_for_builtin_loader(s2 classpath_index, InstanceKlass* result, bool redefined);\n@@ -350,0 +351,1 @@\n+  static void append_boot_classpath(ClassPathEntry* new_entry);\n","filename":"src\/hotspot\/share\/classfile\/classLoader.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -32,1 +32,1 @@\n-#include \"utilities\/macros.hpp\"\n+#include \"utilities\/macros.hpp\"\n@@ -223,0 +223,1 @@\n+  template(jdk_internal_vm_PreemptedException,        \"jdk\/internal\/vm\/PreemptedException\")       \\\n@@ -397,4 +398,4 @@\n-  template(notifyJvmtiStart_name,                     \"notifyJvmtiStart\")                         \\\n-  template(notifyJvmtiEnd_name,                       \"notifyJvmtiEnd\")                           \\\n-  template(notifyJvmtiMount_name,                     \"notifyJvmtiMount\")                         \\\n-  template(notifyJvmtiUnmount_name,                   \"notifyJvmtiUnmount\")                       \\\n+  template(startTransition_name,                      \"startTransition\")                          \\\n+  template(endTransition_name,                        \"endTransition\")                            \\\n+  template(startFinalTransition_name,                 \"startFinalTransition\")                     \\\n+  template(endFirstTransition_name,                   \"endFirstTransition\")                       \\\n@@ -425,1 +426,1 @@\n-  template(get_name,                                  \"get\")                                      \\\n+  template(get0_name,                                 \"get0\")                                     \\\n@@ -499,2 +500,2 @@\n-  template(jvmti_VTMS_transition_disable_count_name,  \"jvmti_VTMS_transition_disable_count\")      \\\n-  template(jvmti_is_in_VTMS_transition_name,          \"jvmti_is_in_VTMS_transition\")              \\\n+  template(vthread_transition_disable_count_name,     \"vthread_transition_disable_count\")         \\\n+  template(is_in_vthread_transition_name,             \"is_in_vthread_transition\")                 \\\n@@ -515,0 +516,2 @@\n+  template(atKlassInit_name,                          \"atKlassInit\")                              \\\n+  template(hasArgsAtTop_name,                         \"hasArgsAtTop\")                             \\\n@@ -735,0 +738,1 @@\n+  template(jdk_internal_vm_annotation_AOTSafeClassInitializer_signature, \"Ljdk\/internal\/vm\/annotation\/AOTSafeClassInitializer;\")\\\n@@ -737,0 +741,1 @@\n+  template(jdk_internal_vm_annotation_AOTRuntimeSetup_signature, \"Ljdk\/internal\/vm\/annotation\/AOTRuntimeSetup;\")  \\\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":13,"deletions":8,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -54,1 +54,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -230,5 +230,0 @@\n-    \/\/ Further down, just before FLAG_SET_ERGO(), all segment sizes are\n-    \/\/ aligned down to the next lower multiple of min_size. For large page\n-    \/\/ sizes, this may result in (non_nmethod.size == 0) which is not acceptable.\n-    \/\/ Therefore, force non_nmethod.size to at least min_size.\n-    non_nmethod.size = MAX2(non_nmethod.size, min_size);\n@@ -310,5 +305,4 @@\n-  non_profiled.size += non_nmethod.size & alignment_mask(min_size);\n-  non_profiled.size += profiled.size & alignment_mask(min_size);\n-  non_nmethod.size = align_down(non_nmethod.size, min_size);\n-  profiled.size = align_down(profiled.size, min_size);\n-  non_profiled.size = align_down(non_profiled.size, min_size);\n+  non_nmethod.size = align_up(non_nmethod.size, min_size);\n+  profiled.size = align_up(profiled.size, min_size);\n+  non_profiled.size = align_up(non_profiled.size, min_size);\n+  cache_size = non_nmethod.size + profiled.size + non_profiled.size;\n@@ -436,1 +430,1 @@\n-  size_t size_initial = MIN2((size_t)InitialCodeCacheSize, rs.size());\n+  size_t size_initial = MIN2(InitialCodeCacheSize, rs.size());\n@@ -583,1 +577,1 @@\n-      Atomic::dec(&_number_of_nmethods_with_dependencies);\n+      AtomicAccess::dec(&_number_of_nmethods_with_dependencies);\n@@ -619,1 +613,1 @@\n-      Atomic::inc(&_number_of_nmethods_with_dependencies);\n+      AtomicAccess::inc(&_number_of_nmethods_with_dependencies);\n@@ -789,1 +783,1 @@\n-    if (Atomic::cmpxchg(&_unloading_threshold_gc_requested, false, true) == false) {\n+    if (AtomicAccess::cmpxchg(&_unloading_threshold_gc_requested, false, true) == false) {\n@@ -815,1 +809,1 @@\n-    if (Atomic::cmpxchg(&_unloading_threshold_gc_requested, false, true) == false) {\n+    if (AtomicAccess::cmpxchg(&_unloading_threshold_gc_requested, false, true) == false) {\n@@ -885,0 +879,1 @@\n+  if (!VerifyInlineCaches) return;\n@@ -901,1 +896,1 @@\n-      ExceptionCache* purge_list_head = Atomic::load(&_exception_cache_purge_list);\n+      ExceptionCache* purge_list_head = AtomicAccess::load(&_exception_cache_purge_list);\n@@ -903,1 +898,1 @@\n-      if (Atomic::cmpxchg(&_exception_cache_purge_list, purge_list_head, entry) == purge_list_head) {\n+      if (AtomicAccess::cmpxchg(&_exception_cache_purge_list, purge_list_head, entry) == purge_list_head) {\n@@ -1109,1 +1104,1 @@\n-  assert(CodeCacheSegmentSize >= (uintx)CodeEntryAlignment, \"CodeCacheSegmentSize must be large enough to align entry points\");\n+  assert(CodeCacheSegmentSize >= (size_t)CodeEntryAlignment, \"CodeCacheSegmentSize must be large enough to align entry points\");\n@@ -1111,1 +1106,1 @@\n-  assert(CodeCacheSegmentSize >= (uintx)OptoLoopAlignment,  \"CodeCacheSegmentSize must be large enough to align inner loops\");\n+  assert(CodeCacheSegmentSize >= (size_t)OptoLoopAlignment,  \"CodeCacheSegmentSize must be large enough to align inner loops\");\n@@ -1154,1 +1149,1 @@\n-  return Atomic::load_acquire(&_number_of_nmethods_with_dependencies) != 0;\n+  return AtomicAccess::load_acquire(&_number_of_nmethods_with_dependencies) != 0;\n@@ -1187,1 +1182,1 @@\n-  typedef ResourceHashtable<DependencySignature, int, 11027,\n+  typedef HashTable<DependencySignature, int, 11027,\n@@ -1364,1 +1359,1 @@\n-      nm->make_not_entrant(\"marked for deoptimization\", true \/* OK to recompile *\/);\n+      nm->make_not_entrant(nmethod::InvalidationReason::MARKED_FOR_DEOPTIMIZATION, true \/* OK to recompile *\/);\n","filename":"src\/hotspot\/share\/code\/codeCache.cpp","additions":18,"deletions":23,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"cds\/cdsConfig.hpp\"\n@@ -31,1 +32,0 @@\n-#include \"code\/relocInfo.hpp\"\n@@ -37,1 +37,0 @@\n-#include \"compiler\/compileTask.hpp\"\n@@ -40,0 +39,1 @@\n+#include \"compiler\/compileTask.hpp\"\n@@ -63,0 +63,1 @@\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -64,1 +65,0 @@\n-#include \"runtime\/atomic.hpp\"\n@@ -84,1 +84,1 @@\n-#include \"utilities\/resourceHash.hpp\"\n+#include \"utilities\/hashTable.hpp\"\n@@ -381,1 +381,1 @@\n-  return Atomic::load(&_next);\n+  return AtomicAccess::load(&_next);\n@@ -385,1 +385,1 @@\n-  Atomic::store(&_next, ec);\n+  AtomicAccess::store(&_next, ec);\n@@ -470,8 +470,0 @@\n-bool nmethod::is_method_handle_return(address return_pc) {\n-  if (!has_method_handle_invokes())  return false;\n-  PcDesc* pd = pc_desc_at(return_pc);\n-  if (pd == nullptr)\n-    return false;\n-  return pd->is_method_handle_invoke();\n-}\n-\n@@ -497,1 +489,1 @@\n-    Atomic::store(&_deoptimization_status, deoptimize_done);\n+    AtomicAccess::store(&_deoptimization_status, deoptimize_done);\n@@ -502,1 +494,1 @@\n-  return Atomic::load_acquire(&_exception_cache);\n+  return AtomicAccess::load_acquire(&_exception_cache);\n@@ -522,1 +514,1 @@\n-        if (Atomic::cmpxchg(&_exception_cache, ec, next) == ec) {\n+        if (AtomicAccess::cmpxchg(&_exception_cache, ec, next) == ec) {\n@@ -532,1 +524,1 @@\n-    if (Atomic::cmpxchg(&_exception_cache, ec, new_entry) == ec) {\n+    if (AtomicAccess::cmpxchg(&_exception_cache, ec, new_entry) == ec) {\n@@ -565,1 +557,1 @@\n-        if (Atomic::cmpxchg(&_exception_cache, curr, next) != curr) {\n+        if (AtomicAccess::cmpxchg(&_exception_cache, curr, next) != curr) {\n@@ -696,7 +688,0 @@\n-  if (!is_in_use()) {\n-    low_boundary += NativeJump::instruction_size;\n-    \/\/ %%% Note:  On SPARC we patch only a 4-byte trap, not a full NativeJump.\n-    \/\/ This means that the low_boundary is going to be a little too high.\n-    \/\/ This shouldn't matter, since oops of non-entrant methods are never used.\n-    \/\/ In fact, why are we bothering to look at oops in a non-entrant method??\n-  }\n@@ -774,1 +759,1 @@\n-  assert(SafepointSynchronize::is_at_safepoint(), \"clearing of IC's only allowed at safepoint\");\n+  assert(SafepointSynchronize::is_at_safepoint() || (NMethodState_lock->owned_by_self() && is_not_installed()), \"clearing of IC's only allowed at safepoint or when not installed\");\n@@ -803,5 +788,0 @@\n-\n-static void clean_ic_if_metadata_is_dead(CompiledIC *ic) {\n-  ic->clean_metadata();\n-}\n-\n@@ -810,2 +790,1 @@\n-static void clean_if_nmethod_is_unloaded(CallsiteT* callsite, nmethod* from,\n-                                         bool clean_all) {\n+static void clean_if_nmethod_is_unloaded(CallsiteT* callsite, bool clean_all) {\n@@ -886,1 +865,1 @@\n-        clean_ic_if_metadata_is_dead(CompiledIC_at(&iter));\n+        CompiledIC_at(&iter)->clean_metadata();\n@@ -889,1 +868,1 @@\n-      clean_if_nmethod_is_unloaded(CompiledIC_at(&iter), this, clean_all);\n+      clean_if_nmethod_is_unloaded(CompiledIC_at(&iter), clean_all);\n@@ -894,1 +873,1 @@\n-      clean_if_nmethod_is_unloaded(CompiledDirectCall::at(iter.reloc()), this, clean_all);\n+      clean_if_nmethod_is_unloaded(CompiledDirectCall::at(iter.reloc()), clean_all);\n@@ -931,1 +910,1 @@\n-          Atomic::store(r->metadata_addr(), (Method*)nullptr);\n+          AtomicAccess::store(r->metadata_addr(), (Method*)nullptr);\n@@ -1177,0 +1156,1 @@\n+    immutable_data_size += ImmutableDataRefCountSize;\n@@ -1249,1 +1229,0 @@\n-  _has_method_handle_invokes  = 0;\n@@ -1327,2 +1306,1 @@\n-    _deopt_handler_offset    = 0;\n-    _deopt_mh_handler_offset = 0;\n+    _deopt_handler_entry_offset    = 0;\n@@ -1349,0 +1327,1 @@\n+    _immutable_data_ref_count_offset = 0;\n@@ -1399,0 +1378,266 @@\n+\n+nmethod::nmethod(const nmethod &nm) : CodeBlob(nm._name, nm._kind, nm._size, nm._header_size)\n+{\n+\n+  if (nm._oop_maps != nullptr) {\n+    _oop_maps                   = nm._oop_maps->clone();\n+  } else {\n+    _oop_maps                   = nullptr;\n+  }\n+\n+  _size                         = nm._size;\n+  _relocation_size              = nm._relocation_size;\n+  _content_offset               = nm._content_offset;\n+  _code_offset                  = nm._code_offset;\n+  _data_offset                  = nm._data_offset;\n+  _frame_size                   = nm._frame_size;\n+\n+  S390_ONLY( _ctable_offset     = nm._ctable_offset; )\n+\n+  _header_size                  = nm._header_size;\n+  _frame_complete_offset        = nm._frame_complete_offset;\n+\n+  _kind                         = nm._kind;\n+\n+  _caller_must_gc_arguments     = nm._caller_must_gc_arguments;\n+\n+#ifndef PRODUCT\n+  _asm_remarks.share(nm._asm_remarks);\n+  _dbg_strings.share(nm._dbg_strings);\n+#endif\n+\n+  \/\/ Allocate memory and copy mutable data to C heap\n+  _mutable_data_size            = nm._mutable_data_size;\n+  if (_mutable_data_size > 0) {\n+    _mutable_data = (address)os::malloc(_mutable_data_size, mtCode);\n+    if (_mutable_data == nullptr) {\n+      vm_exit_out_of_memory(_mutable_data_size, OOM_MALLOC_ERROR, \"nmethod: no space for mutable data\");\n+    }\n+    memcpy(mutable_data_begin(), nm.mutable_data_begin(), nm.mutable_data_size());\n+  } else {\n+    _mutable_data               = nullptr;\n+  }\n+\n+  _deoptimization_generation    = 0;\n+  _gc_epoch                     = CodeCache::gc_epoch();\n+  _method                       = nm._method;\n+  _osr_link                     = nullptr;\n+\n+  _exception_cache              = nullptr;\n+  _gc_data                      = nullptr;\n+  _oops_do_mark_nmethods        = nullptr;\n+  _oops_do_mark_link            = nullptr;\n+  _compiled_ic_data             = nullptr;\n+\n+  if (nm._osr_entry_point != nullptr) {\n+    _osr_entry_point            = (nm._osr_entry_point - (address) &nm) + (address) this;\n+  } else {\n+    _osr_entry_point            = nullptr;\n+  }\n+\n+  _entry_offset                 = nm._entry_offset;\n+  _verified_entry_offset        = nm._verified_entry_offset;\n+  _entry_bci                    = nm._entry_bci;\n+  _immutable_data_size          = nm._immutable_data_size;\n+\n+  _skipped_instructions_size    = nm._skipped_instructions_size;\n+  _stub_offset                  = nm._stub_offset;\n+  _exception_offset             = nm._exception_offset;\n+  _deopt_handler_entry_offset   = nm._deopt_handler_entry_offset;\n+  _unwind_handler_offset        = nm._unwind_handler_offset;\n+  _num_stack_arg_slots          = nm._num_stack_arg_slots;\n+  _oops_size                    = nm._oops_size;\n+#if INCLUDE_JVMCI\n+  _metadata_size                = nm._metadata_size;\n+#endif\n+  _nul_chk_table_offset         = nm._nul_chk_table_offset;\n+  _handler_table_offset         = nm._handler_table_offset;\n+  _scopes_pcs_offset            = nm._scopes_pcs_offset;\n+  _scopes_data_offset           = nm._scopes_data_offset;\n+#if INCLUDE_JVMCI\n+  _speculations_offset          = nm._speculations_offset;\n+#endif\n+  _immutable_data_ref_count_offset = nm._immutable_data_ref_count_offset;\n+\n+  \/\/ Increment number of references to immutable data to share it between nmethods\n+  if (_immutable_data_size > 0) {\n+    _immutable_data             = nm._immutable_data;\n+    inc_immutable_data_ref_count();\n+  } else {\n+    _immutable_data             = blob_end();\n+  }\n+\n+  _orig_pc_offset               = nm._orig_pc_offset;\n+  _compile_id                   = nm._compile_id;\n+  _comp_level                   = nm._comp_level;\n+  _compiler_type                = nm._compiler_type;\n+  _is_unloading_state           = nm._is_unloading_state;\n+  _state                        = not_installed;\n+\n+  _has_unsafe_access            = nm._has_unsafe_access;\n+  _has_wide_vectors             = nm._has_wide_vectors;\n+  _has_monitors                 = nm._has_monitors;\n+  _has_scoped_access            = nm._has_scoped_access;\n+  _has_flushed_dependencies     = nm._has_flushed_dependencies;\n+  _is_unlinked                  = nm._is_unlinked;\n+  _load_reported                = nm._load_reported;\n+\n+  _deoptimization_status        = nm._deoptimization_status;\n+\n+  if (nm._pc_desc_container != nullptr) {\n+    _pc_desc_container          = new PcDescContainer(scopes_pcs_begin());\n+  } else {\n+    _pc_desc_container          = nullptr;\n+  }\n+\n+  \/\/ Copy nmethod contents excluding header\n+  \/\/ - Constant part          (doubles, longs and floats used in nmethod)\n+  \/\/ - Code part:\n+  \/\/   - Code body\n+  \/\/   - Exception handler\n+  \/\/   - Stub code\n+  \/\/   - OOP table\n+  memcpy(consts_begin(), nm.consts_begin(), nm.data_end() - nm.consts_begin());\n+\n+  \/\/ Fix relocation\n+  RelocIterator iter(this);\n+  CodeBuffer src(&nm);\n+  CodeBuffer dst(this);\n+  while (iter.next()) {\n+#ifdef USE_TRAMPOLINE_STUB_FIX_OWNER\n+    \/\/ After an nmethod is moved, some direct call sites may end up out of range.\n+    \/\/ CallRelocation::fix_relocation_after_move() assumes the target is always\n+    \/\/ reachable and does not check branch range. Calling it without range checks\n+    \/\/ could cause us to write an offset too large for the instruction.\n+    \/\/\n+    \/\/ If a call site has a trampoline, we skip the normal call relocation. The\n+    \/\/ associated trampoline_stub_Relocation will handle the call and the\n+    \/\/ trampoline, including range checks and updating the branch as needed.\n+    \/\/\n+    \/\/ If no trampoline exists, we can assume the call target is always\n+    \/\/ reachable and therefore within direct branch range, so calling\n+    \/\/ CallRelocation::fix_relocation_after_move() is safe.\n+    if (iter.reloc()->is_call()) {\n+      address trampoline = trampoline_stub_Relocation::get_trampoline_for(iter.reloc()->addr(), this);\n+      if (trampoline != nullptr) {\n+        continue;\n+      }\n+    }\n+#endif\n+\n+    iter.reloc()->fix_relocation_after_move(&src, &dst);\n+  }\n+\n+  {\n+    MutexLocker ml(NMethodState_lock, Mutex::_no_safepoint_check_flag);\n+    clear_inline_caches();\n+  }\n+\n+  post_init();\n+}\n+\n+nmethod* nmethod::relocate(CodeBlobType code_blob_type) {\n+  assert(NMethodRelocation, \"must enable use of function\");\n+\n+  \/\/ Locks required to be held by caller to ensure the nmethod\n+  \/\/ is not modified or purged from code cache during relocation\n+  assert_lock_strong(CodeCache_lock);\n+  assert_lock_strong(Compile_lock);\n+  assert(CompiledICLocker::is_safe(this), \"mt unsafe call\");\n+\n+  if (!is_relocatable()) {\n+    return nullptr;\n+  }\n+\n+  run_nmethod_entry_barrier();\n+  nmethod* nm_copy = new (size(), code_blob_type) nmethod(*this);\n+\n+  if (nm_copy == nullptr) {\n+    return nullptr;\n+  }\n+\n+  \/\/ To make dependency checking during class loading fast, record\n+  \/\/ the nmethod dependencies in the classes it is dependent on.\n+  \/\/ This allows the dependency checking code to simply walk the\n+  \/\/ class hierarchy above the loaded class, checking only nmethods\n+  \/\/ which are dependent on those classes.  The slow way is to\n+  \/\/ check every nmethod for dependencies which makes it linear in\n+  \/\/ the number of methods compiled.  For applications with a lot\n+  \/\/ classes the slow way is too slow.\n+  for (Dependencies::DepStream deps(nm_copy); deps.next(); ) {\n+    if (deps.type() == Dependencies::call_site_target_value) {\n+      \/\/ CallSite dependencies are managed on per-CallSite instance basis.\n+      oop call_site = deps.argument_oop(0);\n+      MethodHandles::add_dependent_nmethod(call_site, nm_copy);\n+    } else {\n+      InstanceKlass* ik = deps.context_type();\n+      if (ik == nullptr) {\n+        continue;  \/\/ ignore things like evol_method\n+      }\n+      \/\/ record this nmethod as dependent on this klass\n+      ik->add_dependent_nmethod(nm_copy);\n+    }\n+  }\n+\n+  MutexLocker ml_NMethodState_lock(NMethodState_lock, Mutex::_no_safepoint_check_flag);\n+\n+  \/\/ Verify the nm we copied from is still valid\n+  if (!is_marked_for_deoptimization() && is_in_use()) {\n+    assert(method() != nullptr && method()->code() == this, \"should be if is in use\");\n+\n+    \/\/ Attempt to start using the copy\n+    if (nm_copy->make_in_use()) {\n+      ICache::invalidate_range(nm_copy->code_begin(), nm_copy->code_size());\n+\n+      methodHandle mh(Thread::current(), nm_copy->method());\n+      nm_copy->method()->set_code(mh, nm_copy);\n+\n+      make_not_entrant(InvalidationReason::RELOCATED, false \/* copy is now in use *\/);\n+\n+      nm_copy->post_compiled_method_load_event();\n+\n+      nm_copy->log_relocated_nmethod(this);\n+\n+      return nm_copy;\n+    }\n+  }\n+\n+  nm_copy->make_not_used();\n+\n+  return nullptr;\n+}\n+\n+bool nmethod::is_relocatable() {\n+  if (!is_java_method()) {\n+    return false;\n+  }\n+\n+  if (!is_in_use()) {\n+    return false;\n+  }\n+\n+  if (is_osr_method()) {\n+    return false;\n+  }\n+\n+  if (is_marked_for_deoptimization()) {\n+    return false;\n+  }\n+\n+#if INCLUDE_JVMCI\n+  if (jvmci_nmethod_data() != nullptr && jvmci_nmethod_data()->has_mirror()) {\n+    return false;\n+  }\n+#endif\n+\n+  if (is_unloading()) {\n+    return false;\n+  }\n+\n+  if (has_evol_metadata()) {\n+    return false;\n+  }\n+\n+  return true;\n+}\n+\n@@ -1403,0 +1648,4 @@\n+void* nmethod::operator new(size_t size, int nmethod_size, CodeBlobType code_blob_type) throw () {\n+  return CodeCache::allocate(nmethod_size, code_blob_type);\n+}\n+\n@@ -1472,1 +1721,1 @@\n-        _deopt_handler_offset    = code_offset() + offsets->value(CodeOffsets::Deopt);\n+        _deopt_handler_entry_offset    = code_offset() + offsets->value(CodeOffsets::Deopt);\n@@ -1474,6 +1723,1 @@\n-        _deopt_handler_offset    = -1;\n-      }\n-      if (offsets->value(CodeOffsets::DeoptMH) != -1) {\n-        _deopt_mh_handler_offset = code_offset() + offsets->value(CodeOffsets::DeoptMH);\n-      } else {\n-        _deopt_mh_handler_offset = -1;\n+        _deopt_handler_entry_offset    = -1;\n@@ -1485,1 +1729,0 @@\n-      assert(offsets->value(CodeOffsets::Exceptions) != -1, \"must be set\");\n@@ -1488,4 +1731,5 @@\n-      _exception_offset          = _stub_offset + offsets->value(CodeOffsets::Exceptions);\n-      _deopt_handler_offset      = _stub_offset + offsets->value(CodeOffsets::Deopt);\n-      if (offsets->value(CodeOffsets::DeoptMH) != -1) {\n-        _deopt_mh_handler_offset = _stub_offset + offsets->value(CodeOffsets::DeoptMH);\n+      bool has_exception_handler = (offsets->value(CodeOffsets::Exceptions) != -1);\n+      assert(has_exception_handler == (compiler->type() != compiler_c2),\n+             \"C2 compiler doesn't provide exception handler stub code.\");\n+      if (has_exception_handler) {\n+        _exception_offset = _stub_offset + offsets->value(CodeOffsets::Exceptions);\n@@ -1493,1 +1737,1 @@\n-        _deopt_mh_handler_offset = -1;\n+        _exception_offset = -1;\n@@ -1495,0 +1739,2 @@\n+\n+      _deopt_handler_entry_offset = _stub_offset + offsets->value(CodeOffsets::Deopt);\n@@ -1532,1 +1778,1 @@\n-    DEBUG_ONLY( int immutable_data_end_offset = _speculations_offset  + align_up(speculations_len, oopSize); )\n+    _immutable_data_ref_count_offset = _speculations_offset + align_up(speculations_len, oopSize);\n@@ -1534,1 +1780,1 @@\n-    DEBUG_ONLY( int immutable_data_end_offset = _scopes_data_offset + align_up(debug_info->data_size(), oopSize); )\n+    _immutable_data_ref_count_offset = _scopes_data_offset + align_up(debug_info->data_size(), oopSize);\n@@ -1536,0 +1782,1 @@\n+    DEBUG_ONLY( int immutable_data_end_offset = _immutable_data_ref_count_offset + ImmutableDataRefCountSize; )\n@@ -1567,0 +1814,1 @@\n+    init_immutable_data_ref_count();\n@@ -1633,0 +1881,34 @@\n+\n+void nmethod::log_relocated_nmethod(nmethod* original) const {\n+  if (LogCompilation && xtty != nullptr) {\n+    ttyLocker ttyl;\n+    xtty->begin_elem(\"relocated nmethod\");\n+    log_identity(xtty);\n+    xtty->print(\" entry='\" INTPTR_FORMAT \"' size='%d'\", p2i(code_begin()), size());\n+\n+    const char* original_code_heap_name = CodeCache::get_code_heap_name(CodeCache::get_code_blob_type(original));\n+    xtty->print(\" original_address='\" INTPTR_FORMAT \"'\", p2i(original));\n+    xtty->print(\" original_code_heap='%s'\", original_code_heap_name);\n+\n+    const char* new_code_heap_name = CodeCache::get_code_heap_name(CodeCache::get_code_blob_type(this));\n+    xtty->print(\" new_address='\" INTPTR_FORMAT \"'\", p2i(this));\n+    xtty->print(\" new_code_heap='%s'\", new_code_heap_name);\n+\n+    LOG_OFFSET(xtty, relocation);\n+    LOG_OFFSET(xtty, consts);\n+    LOG_OFFSET(xtty, insts);\n+    LOG_OFFSET(xtty, stub);\n+    LOG_OFFSET(xtty, scopes_data);\n+    LOG_OFFSET(xtty, scopes_pcs);\n+    LOG_OFFSET(xtty, dependencies);\n+    LOG_OFFSET(xtty, handler_table);\n+    LOG_OFFSET(xtty, nul_chk_table);\n+    LOG_OFFSET(xtty, oops);\n+    LOG_OFFSET(xtty, metadata);\n+\n+    xtty->method(method());\n+    xtty->stamp();\n+    xtty->end_elem();\n+  }\n+}\n+\n@@ -1657,4 +1939,0 @@\n-  \/\/ Enter a critical section to prevent a race with deopts that patch code and updates the relocation info.\n-  \/\/ Unfortunately, we have to lock the NMethodState_lock before the tty lock due to the deadlock rules and\n-  \/\/ cannot lock in a more finely grained manner.\n-  ConditionalMutexLocker ml(NMethodState_lock, !NMethodState_lock->owned_by_self(), Mutex::_no_safepoint_check_flag);\n@@ -1939,1 +2217,1 @@\n-  Atomic::store(&_gc_epoch, CodeCache::gc_epoch());\n+  AtomicAccess::store(&_gc_epoch, CodeCache::gc_epoch());\n@@ -1945,1 +2223,1 @@\n-  return Atomic::load(&_gc_epoch) >= CodeCache::previous_completed_gc_marking_cycle();\n+  return AtomicAccess::load(&_gc_epoch) >= CodeCache::previous_completed_gc_marking_cycle();\n@@ -1951,0 +2229,5 @@\n+#if INCLUDE_JVMCI\n+  if (jvmci_skip_profile_deopt()) {\n+    return;\n+  }\n+#endif\n@@ -1967,1 +2250,1 @@\n-  Atomic::store(&_state, new_state);\n+  AtomicAccess::store(&_state, new_state);\n@@ -1979,3 +2262,1 @@\n-void nmethod::log_state_change(const char* reason) const {\n-  assert(reason != nullptr, \"Must provide a reason\");\n-\n+void nmethod::log_state_change(InvalidationReason invalidation_reason) const {\n@@ -1986,1 +2267,1 @@\n-                       os::current_thread_id(), reason);\n+                       os::current_thread_id(), invalidation_reason_to_string(invalidation_reason));\n@@ -1995,1 +2276,1 @@\n-  ss.print(\"made not entrant: %s\", reason);\n+  ss.print(\"made not entrant: %s\", invalidation_reason_to_string(invalidation_reason));\n@@ -2010,3 +2291,1 @@\n-bool nmethod::make_not_entrant(const char* reason, bool can_schedule_recompilation) {\n-  assert(reason != nullptr, \"Must provide a reason\");\n-\n+bool nmethod::make_not_entrant(InvalidationReason invalidation_reason, bool can_schedule_recompilation) {\n@@ -2022,1 +2301,1 @@\n-  if (Atomic::load(&_state) == not_entrant) {\n+  if (AtomicAccess::load(&_state) == not_entrant) {\n@@ -2034,1 +2313,1 @@\n-    if (Atomic::load(&_state) == not_entrant) {\n+    if (AtomicAccess::load(&_state) == not_entrant) {\n@@ -2048,13 +2327,1 @@\n-      NativeJump::patch_verified_entry(entry_point(), verified_entry_point(),\n-                                       SharedRuntime::get_handle_wrong_method_stub());\n-\n-      \/\/ Update the relocation info for the patched entry.\n-      \/\/ First, get the old relocation info...\n-      RelocIterator iter(this, verified_entry_point(), verified_entry_point() + 8);\n-      if (iter.next() && iter.addr() == verified_entry_point()) {\n-        Relocation* old_reloc = iter.reloc();\n-        \/\/ ...then reset the iterator to update it.\n-        RelocIterator iter(this, verified_entry_point(), verified_entry_point() + 8);\n-        relocInfo::change_reloc_info_for_address(&iter, verified_entry_point(), old_reloc->type(),\n-                                                 relocInfo::relocType::runtime_call_type);\n-      }\n+      BarrierSet::barrier_set()->barrier_set_nmethod()->make_not_entrant(this);\n@@ -2081,1 +2348,1 @@\n-    log_state_change(reason);\n+    log_state_change(invalidation_reason);\n@@ -2092,1 +2359,1 @@\n-    nmethod_data->invalidate_nmethod_mirror(this);\n+    nmethod_data->invalidate_nmethod_mirror(this, invalidation_reason);\n@@ -2134,1 +2401,3 @@\n-    nmethod_data->invalidate_nmethod_mirror(this);\n+    nmethod_data->invalidate_nmethod_mirror(this, is_cold() ?\n+            nmethod::InvalidationReason::UNLOADING_COLD :\n+            nmethod::InvalidationReason::UNLOADING);\n@@ -2182,1 +2451,5 @@\n-    os::free(_immutable_data);\n+    \/\/ Free memory if this was the last nmethod referencing immutable data\n+    if (dec_immutable_data_ref_count() == 0) {\n+      os::free(_immutable_data);\n+    }\n+\n@@ -2185,0 +2458,1 @@\n+\n@@ -2190,0 +2464,1 @@\n+  JVMCI_ONLY( _metadata_size = 0; )\n@@ -2253,0 +2528,27 @@\n+#if INCLUDE_CDS\n+static GrowableArrayCHeap<nmethod*, mtClassShared>* _delayed_compiled_method_load_events = nullptr;\n+\n+void nmethod::add_delayed_compiled_method_load_event(nmethod* nm) {\n+  precond(CDSConfig::is_using_aot_linked_classes());\n+  precond(!ServiceThread::has_started());\n+\n+  \/\/ We are still in single threaded stage of VM bootstrap. No need to lock.\n+  if (_delayed_compiled_method_load_events == nullptr) {\n+    _delayed_compiled_method_load_events = new GrowableArrayCHeap<nmethod*, mtClassShared>();\n+  }\n+  _delayed_compiled_method_load_events->append(nm);\n+}\n+\n+void nmethod::post_delayed_compiled_method_load_events() {\n+  precond(ServiceThread::has_started());\n+  if (_delayed_compiled_method_load_events != nullptr) {\n+    for (int i = 0; i < _delayed_compiled_method_load_events->length(); i++) {\n+      nmethod* nm = _delayed_compiled_method_load_events->at(i);\n+      nm->post_compiled_method_load_event();\n+    }\n+    delete _delayed_compiled_method_load_events;\n+    _delayed_compiled_method_load_events = nullptr;\n+  }\n+}\n+#endif\n+\n@@ -2258,0 +2560,10 @@\n+#if INCLUDE_CDS\n+  if (!ServiceThread::has_started()) {\n+    \/\/ With AOT-linked classes, we could compile wrappers for native methods before the\n+    \/\/ ServiceThread has been started, so we must delay the events to be posted later.\n+    assert(state == nullptr, \"must be\");\n+    add_delayed_compiled_method_load_event(this);\n+    return;\n+  }\n+#endif\n+\n@@ -2349,1 +2661,1 @@\n-  if (!MethodFlushing || is_native_method() || is_not_installed()) {\n+  if (!MethodFlushing || is_not_installed()) {\n@@ -2418,1 +2730,1 @@\n-  uint8_t state = Atomic::load(&_is_unloading_state);\n+  uint8_t state = AtomicAccess::load(&_is_unloading_state);\n@@ -2441,1 +2753,1 @@\n-  uint8_t found_state = Atomic::cmpxchg(&_is_unloading_state, state, new_state, memory_order_relaxed);\n+  uint8_t found_state = AtomicAccess::cmpxchg(&_is_unloading_state, state, new_state, memory_order_relaxed);\n@@ -2454,1 +2766,1 @@\n-  Atomic::store(&_is_unloading_state, state);\n+  AtomicAccess::store(&_is_unloading_state, state);\n@@ -2474,1 +2786,1 @@\n-void nmethod::oops_do(OopClosure* f, bool allow_dead) {\n+void nmethod::oops_do(OopClosure* f) {\n@@ -2539,1 +2851,1 @@\n-      (Atomic::replace_if_null(&_oops_do_mark_link, mark_link(this, claim_weak_request_tag)))) {\n+      (AtomicAccess::replace_if_null(&_oops_do_mark_link, mark_link(this, claim_weak_request_tag)))) {\n@@ -2553,1 +2865,1 @@\n-  oops_do_mark_link* old_next = Atomic::cmpxchg(&_oops_do_mark_link, mark_link(nullptr, claim_weak_request_tag), mark_link(this, claim_strong_done_tag));\n+  oops_do_mark_link* old_next = AtomicAccess::cmpxchg(&_oops_do_mark_link, mark_link(nullptr, claim_weak_request_tag), mark_link(this, claim_strong_done_tag));\n@@ -2564,1 +2876,1 @@\n-  oops_do_mark_link* old_next = Atomic::cmpxchg(&_oops_do_mark_link, next, mark_link(this, claim_strong_request_tag));\n+  oops_do_mark_link* old_next = AtomicAccess::cmpxchg(&_oops_do_mark_link, next, mark_link(this, claim_strong_request_tag));\n@@ -2575,1 +2887,1 @@\n-  oops_do_mark_link* old_next = Atomic::cmpxchg(&_oops_do_mark_link, next, mark_link(extract_nmethod(next), claim_strong_done_tag));\n+  oops_do_mark_link* old_next = AtomicAccess::cmpxchg(&_oops_do_mark_link, next, mark_link(extract_nmethod(next), claim_strong_done_tag));\n@@ -2590,1 +2902,1 @@\n-  nmethod* old_head = Atomic::xchg(&_oops_do_mark_nmethods, this);\n+  nmethod* old_head = AtomicAccess::xchg(&_oops_do_mark_nmethods, this);\n@@ -2596,1 +2908,1 @@\n-  if (Atomic::cmpxchg(&_oops_do_mark_link, mark_link(this, claim_weak_request_tag), mark_link(old_head, claim_weak_done_tag)) == mark_link(this, claim_weak_request_tag)) {\n+  if (AtomicAccess::cmpxchg(&_oops_do_mark_link, mark_link(this, claim_weak_request_tag), mark_link(old_head, claim_weak_done_tag)) == mark_link(this, claim_weak_request_tag)) {\n@@ -2607,1 +2919,1 @@\n-  nmethod* old_head = Atomic::xchg(&_oops_do_mark_nmethods, this);\n+  nmethod* old_head = AtomicAccess::xchg(&_oops_do_mark_nmethods, this);\n@@ -2727,9 +3039,0 @@\n-  \/\/ Search for MethodHandle invokes and tag the nmethod.\n-  for (int i = 0; i < count; i++) {\n-    if (pcs[i].is_method_handle_invoke()) {\n-      set_has_method_handle_invokes(true);\n-      break;\n-    }\n-  }\n-  assert(has_method_handle_invokes() == (_deopt_mh_handler_offset != -1), \"must have deopt mh handler\");\n-\n@@ -2954,3 +3257,0 @@\n-  \/\/ Make sure all the entry points are correctly aligned for patching.\n-  NativeJump::check_verified_entry_alignment(entry_point(), verified_entry_point());\n-\n@@ -3500,0 +3800,3 @@\n+    st->bol();\n+    st->cr();\n+    st->print_cr(\"Loading hsdis library failed, undisassembled code is shown in MachCode section\");\n@@ -3534,0 +3837,3 @@\n+    st->bol();\n+    st->cr();\n+    st->print_cr(\"Loading hsdis library failed, undisassembled code is shown in MachCode section\");\n@@ -3742,1 +4048,0 @@\n-  if (has_method_handle_invokes() && (pos == deopt_mh_handler_begin())) label = \"[Deopt MH Handler Code]\";\n@@ -3747,1 +4052,1 @@\n-  if (JVMCI_ONLY(_deopt_handler_offset != -1 &&) pos == deopt_handler_begin()) label = \"[Deopt Handler Code]\";\n+  if (JVMCI_ONLY(_deopt_handler_entry_offset != -1 &&) pos == deopt_handler_entry()) label = \"[Deopt Handler Entry Point]\";\n@@ -4026,0 +4331,40 @@\n+void nmethod::print_code_snippet(outputStream* st, address addr) const {\n+  if (entry_point() <= addr && addr < code_end()) {\n+    \/\/ Pointing into the nmethod's code. Try to disassemble some instructions around addr.\n+    \/\/ Determine conservative start and end points.\n+    address start;\n+    if (frame_complete_offset() != CodeOffsets::frame_never_safe &&\n+        addr >= code_begin() + frame_complete_offset()) {\n+      start = code_begin() + frame_complete_offset();\n+    } else {\n+      start = (addr < verified_entry_point()) ? entry_point() : verified_entry_point();\n+    }\n+    address start_for_hex_dump = start; \/\/ We can choose a different starting point for hex dump, below.\n+    address end = code_end();\n+\n+    \/\/ Try using relocations to find closer instruction start and end points.\n+    \/\/ (Some platforms have variable length instructions and can only\n+    \/\/ disassemble correctly at instruction start addresses.)\n+    RelocIterator iter((nmethod*)this, start);\n+    while (iter.next() && iter.addr() < addr) { \/\/ find relocation before addr\n+      \/\/ Note: There's a relocation which doesn't point to an instruction start:\n+      \/\/ ZBarrierRelocationFormatStoreGoodAfterMov with ZGC on x86_64\n+      \/\/ We could detect and skip it, but hex dump is still usable when\n+      \/\/ disassembler produces garbage in such a very rare case.\n+      start = iter.addr();\n+      \/\/ We want at least 64 Bytes ahead in hex dump.\n+      if (iter.addr() <= (addr - 64)) start_for_hex_dump = iter.addr();\n+    }\n+    if (iter.has_current()) {\n+      if (iter.addr() == addr) iter.next(); \/\/ find relocation after addr\n+      if (iter.has_current()) end = iter.addr();\n+    }\n+\n+    \/\/ Always print hex. Disassembler may still have problems when hitting an incorrect instruction start.\n+    os::print_hex_dump(st, start_for_hex_dump, end, 1, \/* print_ascii=*\/false);\n+    if (!Disassembler::is_abstract()) {\n+      Disassembler::decode(start, end, st);\n+    }\n+  }\n+}\n+\n@@ -4087,0 +4432,4 @@\n+\n+bool nmethod::jvmci_skip_profile_deopt() const {\n+  return jvmci_nmethod_data() != nullptr && !jvmci_nmethod_data()->profile_deopt();\n+}\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":465,"deletions":116,"binary":false,"changes":581,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"runtime\/mutexLocker.hpp\"\n@@ -93,1 +94,0 @@\n-  friend class VMStructs;\n@@ -158,0 +158,1 @@\n+\/\/  - Nmethod reference counter\n@@ -171,0 +172,2 @@\n+  #define ImmutableDataRefCountSize ((int)sizeof(int))\n+\n@@ -229,4 +232,1 @@\n-  int _deopt_handler_offset;\n-  \/\/ All deoptee's at a MethodHandle call site will resume execution\n-  \/\/ at this location described by this offset.\n-  int _deopt_mh_handler_offset;\n+  int _deopt_handler_entry_offset;\n@@ -254,0 +254,1 @@\n+  int      _immutable_data_ref_count_offset;\n@@ -271,1 +272,0 @@\n-          _has_method_handle_invokes:1,\/\/ Has this method MethodHandle invokes?\n@@ -289,1 +289,1 @@\n-    return Atomic::load(&_deoptimization_status);\n+    return AtomicAccess::load(&_deoptimization_status);\n@@ -338,0 +338,2 @@\n+  nmethod(const nmethod &nm);\n+\n@@ -340,0 +342,1 @@\n+  void* operator new(size_t size, int nmethod_size, CodeBlobType code_blob_type) throw();\n@@ -474,0 +477,79 @@\n+  \/\/ If you change anything in this enum please patch\n+  \/\/ vmStructs_jvmci.cpp accordingly.\n+  enum class InvalidationReason : s1 {\n+    NOT_INVALIDATED = -1,\n+    C1_CODEPATCH,\n+    C1_DEOPTIMIZE,\n+    C1_DEOPTIMIZE_FOR_PATCHING,\n+    C1_PREDICATE_FAILED_TRAP,\n+    CI_REPLAY,\n+    UNLOADING,\n+    UNLOADING_COLD,\n+    JVMCI_INVALIDATE,\n+    JVMCI_MATERIALIZE_VIRTUAL_OBJECT,\n+    JVMCI_REPLACED_WITH_NEW_CODE,\n+    JVMCI_REPROFILE,\n+    MARKED_FOR_DEOPTIMIZATION,\n+    MISSING_EXCEPTION_HANDLER,\n+    NOT_USED,\n+    OSR_INVALIDATION_BACK_BRANCH,\n+    OSR_INVALIDATION_FOR_COMPILING_WITH_C1,\n+    OSR_INVALIDATION_OF_LOWER_LEVEL,\n+    SET_NATIVE_FUNCTION,\n+    UNCOMMON_TRAP,\n+    WHITEBOX_DEOPTIMIZATION,\n+    ZOMBIE,\n+    RELOCATED,\n+    INVALIDATION_REASONS_COUNT\n+  };\n+\n+\n+  static const char* invalidation_reason_to_string(InvalidationReason invalidation_reason) {\n+    switch (invalidation_reason) {\n+      case InvalidationReason::C1_CODEPATCH:\n+        return \"C1 code patch\";\n+      case InvalidationReason::C1_DEOPTIMIZE:\n+        return \"C1 deoptimized\";\n+      case InvalidationReason::C1_DEOPTIMIZE_FOR_PATCHING:\n+        return \"C1 deoptimize for patching\";\n+      case InvalidationReason::C1_PREDICATE_FAILED_TRAP:\n+        return \"C1 predicate failed trap\";\n+      case InvalidationReason::CI_REPLAY:\n+        return \"CI replay\";\n+      case InvalidationReason::JVMCI_INVALIDATE:\n+        return \"JVMCI invalidate\";\n+      case InvalidationReason::JVMCI_MATERIALIZE_VIRTUAL_OBJECT:\n+        return \"JVMCI materialize virtual object\";\n+      case InvalidationReason::JVMCI_REPLACED_WITH_NEW_CODE:\n+        return \"JVMCI replaced with new code\";\n+      case InvalidationReason::JVMCI_REPROFILE:\n+        return \"JVMCI reprofile\";\n+      case InvalidationReason::MARKED_FOR_DEOPTIMIZATION:\n+        return \"marked for deoptimization\";\n+      case InvalidationReason::MISSING_EXCEPTION_HANDLER:\n+        return \"missing exception handler\";\n+      case InvalidationReason::NOT_USED:\n+        return \"not used\";\n+      case InvalidationReason::OSR_INVALIDATION_BACK_BRANCH:\n+        return \"OSR invalidation back branch\";\n+      case InvalidationReason::OSR_INVALIDATION_FOR_COMPILING_WITH_C1:\n+        return \"OSR invalidation for compiling with C1\";\n+      case InvalidationReason::OSR_INVALIDATION_OF_LOWER_LEVEL:\n+        return \"OSR invalidation of lower level\";\n+      case InvalidationReason::SET_NATIVE_FUNCTION:\n+        return \"set native function\";\n+      case InvalidationReason::UNCOMMON_TRAP:\n+        return \"uncommon trap\";\n+      case InvalidationReason::WHITEBOX_DEOPTIMIZATION:\n+        return \"whitebox deoptimization\";\n+      case InvalidationReason::ZOMBIE:\n+        return \"zombie\";\n+      case InvalidationReason::RELOCATED:\n+        return \"relocated\";\n+      default: {\n+        assert(false, \"Unhandled reason\");\n+        return \"Unknown\";\n+      }\n+    }\n+  }\n+\n@@ -496,0 +578,6 @@\n+  \/\/ Relocate the nmethod to the code heap identified by code_blob_type.\n+  \/\/ Returns nullptr if the code heap does not have enough space, the\n+  \/\/ nmethod is unrelocatable, or the nmethod is invalidated during relocation,\n+  \/\/ otherwise the relocated nmethod. The original nmethod will be marked not entrant.\n+  nmethod* relocate(CodeBlobType code_blob_type);\n+\n@@ -512,0 +600,2 @@\n+  bool is_relocatable();\n+\n@@ -533,2 +623,1 @@\n-  address deopt_handler_begin   () const { return           header_begin() + _deopt_handler_offset    ; }\n-  address deopt_mh_handler_begin() const { return           header_begin() + _deopt_mh_handler_offset ; }\n+  address deopt_handler_entry   () const { return           header_begin() + _deopt_handler_entry_offset    ; }\n@@ -565,1 +654,1 @@\n-  address speculations_end      () const { return            immutable_data_end(); }\n+  address speculations_end      () const { return           _immutable_data + _immutable_data_ref_count_offset ; }\n@@ -567,1 +656,1 @@\n-  address scopes_data_end       () const { return            immutable_data_end(); }\n+  address scopes_data_end       () const { return           _immutable_data + _immutable_data_ref_count_offset ; }\n@@ -569,0 +658,1 @@\n+  address immutable_data_ref_count_begin () const { return  _immutable_data + _immutable_data_ref_count_offset ; }\n@@ -641,2 +731,2 @@\n-  bool  make_not_entrant(const char* reason, bool can_schedule_recompilation);\n-  bool  make_not_used()    { return make_not_entrant(\"not used\", false \/* likely already recompiling *\/); }\n+  bool  make_not_entrant(InvalidationReason invalidation_reason, bool can_schedule_recompilation);\n+  bool  make_not_used() { return make_not_entrant(InvalidationReason::NOT_USED, false \/* likely already recompiling *\/); }\n@@ -678,3 +768,0 @@\n-  bool  has_method_handle_invokes() const         { return _has_method_handle_invokes; }\n-  void  set_has_method_handle_invokes(bool z)     { _has_method_handle_invokes = z; }\n-\n@@ -751,2 +838,0 @@\n-  \/\/ MethodHandle\n-  bool is_method_handle_return(address return_pc);\n@@ -756,1 +841,0 @@\n-  inline bool is_deopt_mh_entry(address pc);\n@@ -845,0 +929,4 @@\n+\n+  \/\/ Returns true if the runtime should NOT collect deoptimization profile for a JVMCI\n+  \/\/ compiled method\n+  bool jvmci_skip_profile_deopt() const;\n@@ -847,2 +935,1 @@\n-  void oops_do(OopClosure* f) { oops_do(f, false); }\n-  void oops_do(OopClosure* f, bool allow_dead);\n+  void oops_do(OopClosure* f);\n@@ -887,0 +974,21 @@\n+  inline void init_immutable_data_ref_count() {\n+    assert(is_not_installed(), \"should be called in nmethod constructor\");\n+    *((int*)immutable_data_ref_count_begin()) = 1;\n+  }\n+\n+  inline int inc_immutable_data_ref_count() {\n+    assert_lock_strong(CodeCache_lock);\n+    int* ref_count = (int*)immutable_data_ref_count_begin();\n+    assert(*ref_count > 0, \"Must be positive\");\n+    return ++(*ref_count);\n+  }\n+\n+  inline int dec_immutable_data_ref_count() {\n+    assert_lock_strong(CodeCache_lock);\n+    int* ref_count = (int*)immutable_data_ref_count_begin();\n+    assert(*ref_count > 0, \"Must be positive\");\n+    return --(*ref_count);\n+  }\n+\n+  static void add_delayed_compiled_method_load_event(nmethod* nm) NOT_CDS_RETURN;\n+\n@@ -921,0 +1029,3 @@\n+  \/\/ AOT cache support\n+  static void post_delayed_compiled_method_load_events() NOT_CDS_RETURN;\n+\n@@ -925,0 +1036,1 @@\n+  void print_code_snippet(outputStream* st, address addr) const;\n@@ -955,1 +1067,2 @@\n-  void log_state_change(const char* reason) const;\n+  void log_relocated_nmethod(nmethod* original) const;\n+  void log_state_change(InvalidationReason invalidation_reason) const;\n@@ -1009,0 +1122,9 @@\n+struct NMethodMarkingScope : StackObj {\n+  NMethodMarkingScope() {\n+    nmethod::oops_do_marking_prologue();\n+  }\n+  ~NMethodMarkingScope() {\n+    nmethod::oops_do_marking_epilogue();\n+  }\n+};\n+\n","filename":"src\/hotspot\/share\/code\/nmethod.hpp","additions":144,"deletions":22,"binary":false,"changes":166,"status":"modified"},{"patch":"@@ -141,1 +141,1 @@\n-void CompilationPolicy::replay_training_at_init_impl(InstanceKlass* klass, TRAPS) {\n+void CompilationPolicy::replay_training_at_init_impl(InstanceKlass* klass, JavaThread* current) {\n@@ -153,1 +153,1 @@\n-          if (ctd->init_deps_left() == 0) {\n+          if (ctd->init_deps_left_acquire() == 0) {\n@@ -156,2 +156,2 @@\n-              const methodHandle mh(THREAD, const_cast<Method*>(mtd->holder()));\n-              CompilationPolicy::maybe_compile_early(mh, THREAD);\n+              const methodHandle mh(current, const_cast<Method*>(mtd->holder()));\n+              CompilationPolicy::maybe_compile_early(mh, current);\n@@ -166,1 +166,1 @@\n-void CompilationPolicy::replay_training_at_init(InstanceKlass* klass, TRAPS) {\n+void CompilationPolicy::replay_training_at_init(InstanceKlass* klass, JavaThread* current) {\n@@ -168,2 +168,2 @@\n-  if (TrainingData::have_data() && klass->is_shared()) {\n-    _training_replay_queue.push(klass, TrainingReplayQueue_lock, THREAD);\n+  if (TrainingData::have_data() && klass->in_aot_cache()) {\n+    _training_replay_queue.push(klass, TrainingReplayQueue_lock, current);\n@@ -184,1 +184,1 @@\n-void CompilationPolicy::replay_training_at_init_loop(TRAPS) {\n+void CompilationPolicy::replay_training_at_init_loop(JavaThread* current) {\n@@ -186,1 +186,1 @@\n-    InstanceKlass* ik = _training_replay_queue.pop(TrainingReplayQueue_lock, THREAD);\n+    InstanceKlass* ik = _training_replay_queue.pop(TrainingReplayQueue_lock, current);\n@@ -188,1 +188,1 @@\n-      replay_training_at_init_impl(ik, THREAD);\n+      replay_training_at_init_impl(ik, current);\n@@ -388,1 +388,1 @@\n-  if (comp_count > 0) {\n+  if (comp_count > 0 && feedback_k > 0) {\n@@ -407,1 +407,1 @@\n-void CompilationPolicy::print_counters(const char* prefix, Method* m) {\n+void CompilationPolicy::print_counters_on(outputStream* st, const char* prefix, Method* m) {\n@@ -419,6 +419,5 @@\n-  tty->print(\" %stotal=%d,%d %smdo=%d(%d),%d(%d)\", prefix,\n-      invocation_count, backedge_count, prefix,\n-      mdo_invocations, mdo_invocations_start,\n-      mdo_backedges, mdo_backedges_start);\n-  tty->print(\" %smax levels=%d,%d\", prefix,\n-      m->highest_comp_level(), m->highest_osr_comp_level());\n+  st->print(\" %stotal=%d,%d %smdo=%d(%d),%d(%d)\", prefix,\n+    invocation_count, backedge_count, prefix,\n+    mdo_invocations, mdo_invocations_start,\n+    mdo_backedges, mdo_backedges_start);\n+  st->print(\" %smax levels=%d,%d\", prefix, m->highest_comp_level(), m->highest_osr_comp_level());\n@@ -427,1 +426,1 @@\n-void CompilationPolicy::print_training_data(const char* prefix, Method* method) {\n+void CompilationPolicy::print_training_data_on(outputStream* st,  const char* prefix, Method* method, CompLevel cur_level) {\n@@ -429,1 +428,1 @@\n-  tty->print(\" %smtd: \", prefix);\n+  st->print(\" %smtd: \", prefix);\n@@ -432,1 +431,1 @@\n-    tty->print(\"null\");\n+    st->print(\"null\");\n@@ -434,0 +433,3 @@\n+    if (should_delay_standard_transition(m, cur_level, mtd)) {\n+      st->print(\"delayed, \");\n+    }\n@@ -435,1 +437,1 @@\n-    tty->print(\"mdo=\");\n+    st->print(\"mdo=\");\n@@ -437,1 +439,1 @@\n-      tty->print(\"null\");\n+      st->print(\"null\");\n@@ -443,1 +445,1 @@\n-      tty->print(\"%d(%d), %d(%d)\", mdo_invocations, mdo_invocations_start, mdo_backedges, mdo_backedges_start);\n+      st->print(\"%d(%d), %d(%d)\", mdo_invocations, mdo_invocations_start, mdo_backedges, mdo_backedges_start);\n@@ -446,1 +448,1 @@\n-    tty->print(\", deps=\");\n+    st->print(\", deps=\");\n@@ -448,1 +450,1 @@\n-      tty->print(\"null\");\n+      st->print(\"null\");\n@@ -450,1 +452,1 @@\n-      tty->print(\"%d\", ctd->init_deps_left());\n+      st->print(\"%d\", ctd->init_deps_left_acquire());\n@@ -456,1 +458,1 @@\n-void CompilationPolicy::print_event(EventType type, Method* m, Method* im, int bci, CompLevel level) {\n+void CompilationPolicy::print_event_on(outputStream *st, EventType type, Method* m, Method* im, int bci, CompLevel level) {\n@@ -459,2 +461,1 @@\n-  ttyLocker tty_lock;\n-  tty->print(\"%lf: [\", os::elapsedTime());\n+  st->print(\"%lf: [\", os::elapsedTime());\n@@ -464,1 +465,1 @@\n-    tty->print(\"call\");\n+    st->print(\"call\");\n@@ -467,1 +468,1 @@\n-    tty->print(\"loop\");\n+    st->print(\"loop\");\n@@ -470,1 +471,1 @@\n-    tty->print(\"compile\");\n+    st->print(\"compile\");\n@@ -473,1 +474,1 @@\n-    tty->print(\"force-compile\");\n+    st->print(\"force-compile\");\n@@ -476,1 +477,1 @@\n-    tty->print(\"remove-from-queue\");\n+    st->print(\"remove-from-queue\");\n@@ -479,1 +480,1 @@\n-    tty->print(\"update-in-queue\");\n+    st->print(\"update-in-queue\");\n@@ -482,1 +483,1 @@\n-    tty->print(\"reprofile\");\n+    st->print(\"reprofile\");\n@@ -485,1 +486,1 @@\n-    tty->print(\"make-not-entrant\");\n+    st->print(\"make-not-entrant\");\n@@ -488,1 +489,1 @@\n-    tty->print(\"unknown\");\n+    st->print(\"unknown\");\n@@ -491,1 +492,1 @@\n-  tty->print(\" level=%d \", level);\n+  st->print(\" level=%d \", level);\n@@ -495,1 +496,1 @@\n-  tty->print(\"[%s\", method_name);\n+  st->print(\"[%s\", method_name);\n@@ -498,1 +499,1 @@\n-    tty->print(\" [%s]] \", inlinee_name);\n+    st->print(\" [%s]] \", inlinee_name);\n@@ -500,3 +501,3 @@\n-  else tty->print(\"] \");\n-  tty->print(\"@%d queues=%d,%d\", bci, CompileBroker::queue_size(CompLevel_full_profile),\n-                                      CompileBroker::queue_size(CompLevel_full_optimization));\n+  else st->print(\"] \");\n+  st->print(\"@%d queues=%d,%d\", bci, CompileBroker::queue_size(CompLevel_full_profile),\n+                                     CompileBroker::queue_size(CompLevel_full_optimization));\n@@ -504,3 +505,3 @@\n-  tty->print(\" rate=\");\n-  if (m->prev_time() == 0) tty->print(\"n\/a\");\n-  else tty->print(\"%f\", m->rate());\n+  st->print(\" rate=\");\n+  if (m->prev_time() == 0) st->print(\"n\/a\");\n+  else st->print(\"%f\", m->rate());\n@@ -508,2 +509,2 @@\n-  tty->print(\" k=%.2lf,%.2lf\", threshold_scale(CompLevel_full_profile, Tier3LoadFeedback),\n-                               threshold_scale(CompLevel_full_optimization, Tier4LoadFeedback));\n+  st->print(\" k=%.2lf,%.2lf\", threshold_scale(CompLevel_full_profile, Tier3LoadFeedback),\n+                              threshold_scale(CompLevel_full_optimization, Tier4LoadFeedback));\n@@ -512,1 +513,1 @@\n-    print_counters(\"\", m);\n+    print_counters_on(st, \"\", m);\n@@ -514,1 +515,1 @@\n-      print_counters(\"inlinee \", im);\n+      print_counters_on(st, \"inlinee \", im);\n@@ -516,1 +517,1 @@\n-    tty->print(\" compilable=\");\n+    st->print(\" compilable=\");\n@@ -519,1 +520,1 @@\n-      tty->print(\"c1\");\n+      st->print(\"c1\");\n@@ -523,2 +524,2 @@\n-      if (need_comma) tty->print(\",\");\n-      tty->print(\"c1-osr\");\n+      if (need_comma) st->print(\",\");\n+      st->print(\"c1-osr\");\n@@ -528,2 +529,2 @@\n-      if (need_comma) tty->print(\",\");\n-      tty->print(\"c2\");\n+      if (need_comma) st->print(\",\");\n+      st->print(\"c2\");\n@@ -533,2 +534,2 @@\n-      if (need_comma) tty->print(\",\");\n-      tty->print(\"c2-osr\");\n+      if (need_comma) st->print(\",\");\n+      st->print(\"c2-osr\");\n@@ -536,1 +537,1 @@\n-    tty->print(\" status=\");\n+    st->print(\" status=\");\n@@ -538,3 +539,4 @@\n-      tty->print(\"in-queue\");\n-    } else tty->print(\"idle\");\n-    print_training_data(\"\", m);\n+      st->print(\"in-queue\");\n+    } else st->print(\"idle\");\n+\n+    print_training_data_on(st, \"\", m, level);\n@@ -542,1 +544,1 @@\n-      print_training_data(\"inlinee \", im);\n+      print_training_data_on(st, \"inlinee \", im, level);\n@@ -545,1 +547,9 @@\n-  tty->print_cr(\"]\");\n+  st->print_cr(\"]\");\n+\n+}\n+\n+void CompilationPolicy::print_event(EventType type, Method* m, Method* im, int bci, CompLevel level) {\n+  stringStream s;\n+  print_event_on(&s, type, m, im, bci, level);\n+  ResourceMark rm;\n+  tty->print(\"%s\", s.as_string());\n@@ -574,3 +584,10 @@\n-      size_t buffer_size = c1_only ? c1_size : (c1_size\/3 + 2*c2_size\/3);\n-      int max_count = (ReservedCodeCacheSize - (CodeCacheMinimumUseSpace DEBUG_ONLY(* 3))) \/ (int)buffer_size;\n-      if (count > max_count) {\n+      size_t buffer_size = 0;\n+      if (c1_only) {\n+        buffer_size = c1_size;\n+      } else if (c2_only) {\n+        buffer_size = c2_size;\n+      } else {\n+        buffer_size = c1_size \/ 3 + 2 * c2_size \/ 3;\n+      }\n+      size_t max_count = (NonNMethodCodeHeapSize - (CodeCacheMinimumUseSpace DEBUG_ONLY(* 3))) \/ buffer_size;\n+      if ((size_t)count > max_count) {\n@@ -578,1 +595,1 @@\n-        count = MAX2(max_count, min_count);\n+        count = MAX2((int)max_count, min_count);\n@@ -594,1 +611,1 @@\n-#endif\n+#endif \/\/ _LP64\n@@ -841,7 +858,0 @@\n-#if INCLUDE_JVMCI\n-  if (EnableJVMCI && UseJVMCICompiler &&\n-      comp_level == CompLevel_full_optimization CDS_ONLY(&& !AOTLinkedClassBulkLoader::class_preloading_finished())) {\n-    return nullptr;\n-  }\n-#endif\n-\n@@ -911,19 +921,19 @@\n-  if (!CompilationModeFlag::disable_intermediate()) {\n-    \/\/ Check if the method can be compiled. If it cannot be compiled with C1, continue profiling\n-    \/\/ in the interpreter and then compile with C2 (the transition function will request that,\n-    \/\/ see common() ). If the method cannot be compiled with C2 but still can with C1, compile it with\n-    \/\/ pure C1.\n-    if ((bci == InvocationEntryBci && !can_be_compiled(mh, level))) {\n-      if (level == CompLevel_full_optimization && can_be_compiled(mh, CompLevel_simple)) {\n-        compile(mh, bci, CompLevel_simple, THREAD);\n-      }\n-      return;\n-    }\n-    if ((bci != InvocationEntryBci && !can_be_osr_compiled(mh, level))) {\n-      if (level == CompLevel_full_optimization && can_be_osr_compiled(mh, CompLevel_simple)) {\n-        nmethod* osr_nm = mh->lookup_osr_nmethod_for(bci, CompLevel_simple, false);\n-        if (osr_nm != nullptr && osr_nm->comp_level() > CompLevel_simple) {\n-          \/\/ Invalidate the existing OSR nmethod so that a compile at CompLevel_simple is permitted.\n-          osr_nm->make_not_entrant(\"OSR invalidation for compiling with C1\", false \/* recompiling by ourselves *\/);\n-        }\n-        compile(mh, bci, CompLevel_simple, THREAD);\n+  \/\/ Check if the method can be compiled. Additional logic for TieredCompilation:\n+  \/\/ If it cannot be compiled with C1, continue profiling in the interpreter\n+  \/\/ and then compile with C2 (the transition function will request that,\n+  \/\/ see common() ). If the method cannot be compiled with C2 but still can with C1, compile it with\n+  \/\/ pure C1.\n+  if ((bci == InvocationEntryBci && !can_be_compiled(mh, level))) {\n+    if (!CompilationModeFlag::disable_intermediate() &&\n+        level == CompLevel_full_optimization && can_be_compiled(mh, CompLevel_simple)) {\n+      compile(mh, bci, CompLevel_simple, THREAD);\n+    }\n+    return;\n+  }\n+  if ((bci != InvocationEntryBci && !can_be_osr_compiled(mh, level))) {\n+    if (!CompilationModeFlag::disable_intermediate() &&\n+        level == CompLevel_full_optimization && can_be_osr_compiled(mh, CompLevel_simple)) {\n+      nmethod* osr_nm = mh->lookup_osr_nmethod_for(bci, CompLevel_simple, false);\n+      if (osr_nm != nullptr && osr_nm->comp_level() > CompLevel_simple) {\n+        \/\/ Invalidate the existing OSR nmethod so that a compile at CompLevel_simple is permitted.\n+        osr_nm->make_not_entrant(nmethod::InvalidationReason::OSR_INVALIDATION_FOR_COMPILING_WITH_C1, false \/* recompiling by ourselves *\/);\n@@ -931,1 +941,1 @@\n-      return;\n+      compile(mh, bci, CompLevel_simple, THREAD);\n@@ -933,0 +943,1 @@\n+    return;\n@@ -1148,1 +1159,1 @@\n-    \/\/ The method was a part of a level 4 compile, but don't have a stored profile,\n+    \/\/ The method was a part of a level 4 compile, but doesn't have a stored profile,\n@@ -1161,1 +1172,1 @@\n-  if (SkipTier2IfPossible && ctd->init_deps_left() == 0) {\n+  if (SkipTier2IfPossible && ctd->init_deps_left_acquire() == 0) {\n@@ -1189,1 +1200,1 @@\n-  if (ctd != nullptr && ctd->init_deps_left() == 0) {\n+  if (ctd != nullptr && ctd->init_deps_left_acquire() == 0) {\n@@ -1303,1 +1314,1 @@\n-      next_level = standard_transition<Predicate>(method, cur_level, false \/*delay_profiling*\/, disable_feedback);\n+      next_level = standard_transition<Predicate>(method, cur_level, disable_feedback);\n@@ -1306,1 +1317,1 @@\n-      if (cur_level == next_level) {\n+      if (cur_level == next_level && !should_delay_standard_transition(method, cur_level, mtd)) {\n@@ -1310,1 +1321,1 @@\n-        next_level = standard_transition<Predicate>(method, cur_level, true \/*delay_profiling*\/, disable_feedback);\n+        next_level = standard_transition<Predicate>(method, cur_level, disable_feedback);\n@@ -1314,1 +1325,1 @@\n-    next_level = standard_transition<Predicate>(method, cur_level, false \/*delay_profiling*\/, disable_feedback);\n+    next_level = standard_transition<Predicate>(method, cur_level, disable_feedback);\n@@ -1319,0 +1330,20 @@\n+bool CompilationPolicy::should_delay_standard_transition(const methodHandle& method, CompLevel cur_level, MethodTrainingData* mtd) {\n+  precond(mtd != nullptr);\n+  CompLevel highest_training_level = static_cast<CompLevel>(mtd->highest_top_level());\n+  if (highest_training_level != CompLevel_full_optimization && cur_level == CompLevel_limited_profile) {\n+    \/\/ This is a lukewarm method - it hasn't been compiled with C2 during the tranining run and is currently\n+    \/\/ running at level 2. Delay any further state changes until its counters exceed the training run counts.\n+    MethodCounters* mc = method->method_counters();\n+    if (mc == nullptr) {\n+      return false;\n+    }\n+    if (mc->invocation_counter()->carry() || mc->backedge_counter()->carry()) {\n+      return false;\n+    }\n+    if (static_cast<int>(mc->invocation_counter()->count()) <= mtd->invocation_count() &&\n+        static_cast<int>(mc->backedge_counter()->count()) <= mtd->backedge_count()) {\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n@@ -1321,1 +1352,1 @@\n-CompLevel CompilationPolicy::standard_transition(const methodHandle& method, CompLevel cur_level, bool delay_profiling, bool disable_feedback) {\n+CompLevel CompilationPolicy::standard_transition(const methodHandle& method, CompLevel cur_level, bool disable_feedback) {\n@@ -1326,1 +1357,1 @@\n-    next_level = transition_from_none<Predicate>(method, cur_level, delay_profiling, disable_feedback);\n+    next_level = transition_from_none<Predicate>(method, cur_level, disable_feedback);\n@@ -1329,1 +1360,1 @@\n-    next_level = transition_from_limited_profile<Predicate>(method, cur_level, delay_profiling, disable_feedback);\n+    next_level = transition_from_limited_profile<Predicate>(method, cur_level, disable_feedback);\n@@ -1339,1 +1370,1 @@\n-CompLevel CompilationPolicy::transition_from_none(const methodHandle& method, CompLevel cur_level, bool delay_profiling, bool disable_feedback) {\n+CompLevel CompilationPolicy::transition_from_none(const methodHandle& method, CompLevel cur_level, bool disable_feedback) {\n@@ -1344,1 +1375,0 @@\n-  double scale = delay_profiling ? Tier0ProfileDelayFactor : 1.0;\n@@ -1348,1 +1378,1 @@\n-  } else if (!CompilationModeFlag::disable_intermediate() && Predicate::apply_scaled(method, cur_level, i, b, scale)) {\n+  } else if (!CompilationModeFlag::disable_intermediate() && Predicate::apply(method, cur_level, i, b)) {\n@@ -1356,1 +1386,1 @@\n-    if (delay_profiling || (!disable_feedback && CompileBroker::queue_size(CompLevel_full_optimization) > Tier3DelayOn * compiler_count(CompLevel_full_optimization))) {\n+    if (!disable_feedback && CompileBroker::queue_size(CompLevel_full_optimization) > Tier3DelayOn * compiler_count(CompLevel_full_optimization)) {\n@@ -1385,1 +1415,1 @@\n-CompLevel CompilationPolicy::transition_from_limited_profile(const methodHandle& method, CompLevel cur_level, bool delay_profiling, bool disable_feedback) {\n+CompLevel CompilationPolicy::transition_from_limited_profile(const methodHandle& method, CompLevel cur_level, bool disable_feedback) {\n@@ -1390,1 +1420,0 @@\n-  double scale = delay_profiling ? Tier2ProfileDelayFactor : 1.0;\n@@ -1396,1 +1425,1 @@\n-                              Predicate::apply_scaled(method, cur_level, i, b, scale))) {\n+                              Predicate::apply(method, cur_level, i, b))) {\n@@ -1406,1 +1435,1 @@\n-                            Predicate::apply_scaled(method, cur_level, i, b, scale))) {\n+                            Predicate::apply(method, cur_level, i, b))) {\n@@ -1434,6 +1463,1 @@\n-#if INCLUDE_JVMCI\n-  if (EnableJVMCI && UseJVMCICompiler &&\n-      next_level == CompLevel_full_optimization CDS_ONLY(&& !AOTLinkedClassBulkLoader::class_preloading_finished())) {\n-    next_level = cur_level;\n-  }\n-#endif\n+\n@@ -1519,1 +1543,1 @@\n-            nm->make_not_entrant(\"OSR invalidation, back branch\", false \/* recompiling by ourselves *\/);\n+            nm->make_not_entrant(nmethod::InvalidationReason::OSR_INVALIDATION_BACK_BRANCH, false \/* recompiling by ourselves *\/);\n","filename":"src\/hotspot\/share\/compiler\/compilationPolicy.cpp","additions":147,"deletions":123,"binary":false,"changes":270,"status":"modified"},{"patch":"@@ -56,1 +56,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -222,0 +222,1 @@\n+  thread->timeout()->arm();\n@@ -227,0 +228,4 @@\n+\n+  \/\/ First, disarm the timeout. This still relies on the underlying task.\n+  thread->timeout()->disarm();\n+\n@@ -240,1 +245,1 @@\n-          \/\/ The waiting thread timed out and thus did not free the task.\n+          \/\/ The waiting thread timed out and thus did not delete the task.\n@@ -253,2 +258,2 @@\n-      \/\/ The task can only be freed once the task lock is released.\n-      CompileTask::free(task);\n+      \/\/ The task can only be deleted once the task lock is released.\n+      delete task;\n@@ -259,3 +264,3 @@\n-    \/\/ By convention, the compiling thread is responsible for\n-    \/\/ recycling a non-blocking CompileTask.\n-    CompileTask::free(task);\n+    \/\/ By convention, the compiling thread is responsible for deleting\n+    \/\/ a non-blocking CompileTask.\n+    delete task;\n@@ -364,3 +369,3 @@\n- * Empties compilation queue by putting all compilation tasks onto\n- * a freelist. Furthermore, the method wakes up all threads that are\n- * waiting on a compilation task to finish. This can happen if background\n+ * Empties compilation queue by deleting all compilation tasks.\n+ * Furthermore, the method wakes up all threads that are waiting\n+ * on a compilation task to finish. This can happen if background\n@@ -369,1 +374,1 @@\n-void CompileQueue::free_all() {\n+void CompileQueue::delete_all() {\n@@ -371,1 +376,1 @@\n-  CompileTask* next = _first;\n+  CompileTask* current = _first;\n@@ -374,20 +379,9 @@\n-  while (next != nullptr) {\n-    CompileTask* current = next;\n-    next = current->next();\n-    bool found_waiter = false;\n-    {\n-      MutexLocker ct_lock(CompileTaskWait_lock);\n-      assert(current->waiting_for_completion_count() <= 1, \"more than one thread are waiting for task\");\n-      if (current->waiting_for_completion_count() > 0) {\n-        \/\/ If another thread waits for this task, we must wake them up\n-        \/\/ so they will stop waiting and free the task.\n-        CompileTaskWait_lock->notify_all();\n-        found_waiter = true;\n-      }\n-    }\n-    if (!found_waiter) {\n-      \/\/ If no one was waiting for this task, we need to free it ourselves. In this case, the task\n-      \/\/ is also certainly unlocked, because, again, there is no waiter.\n-      \/\/ Otherwise, by convention, it's the waiters responsibility to free the task.\n-      \/\/ Put the task back on the freelist.\n-      CompileTask::free(current);\n+  while (current != nullptr) {\n+    CompileTask* next = current->next();\n+    if (!current->is_blocking()) {\n+      \/\/ Non-blocking task. No one is waiting for it, delete it now.\n+      delete current;\n+    } else {\n+      \/\/ Blocking task. By convention, it is the waiters responsibility\n+      \/\/ to delete the task. We cannot delete it here, because we do not\n+      \/\/ coordinate with waiters. We will notify the waiters later.\n@@ -395,0 +389,1 @@\n+    current = next;\n@@ -399,0 +394,8 @@\n+  \/\/ Wake up all blocking task waiters to deal with remaining blocking\n+  \/\/ tasks. This is not a performance sensitive path, so we do this\n+  \/\/ unconditionally to simplify coding\/testing.\n+  {\n+    MonitorLocker ml(Thread::current(), CompileTaskWait_lock);\n+    ml.notify_all();\n+  }\n+\n@@ -486,0 +489,1 @@\n+        task->set_next(nullptr);\n@@ -511,0 +515,2 @@\n+  task->set_next(nullptr);\n+  task->set_prev(nullptr);\n@@ -1062,1 +1068,3 @@\n-  julong free_memory = os::free_memory();\n+  physical_memory_size_type free_memory = 0;\n+  \/\/ Return value ignored - defaulting to 0 on failure.\n+  (void)os::free_memory(free_memory);\n@@ -1595,1 +1603,1 @@\n-    return Atomic::add(CICountNative ? &_native_compilation_id : &_compilation_id, 1);\n+    return AtomicAccess::add(CICountNative ? &_native_compilation_id : &_compilation_id, 1);\n@@ -1597,1 +1605,1 @@\n-    id = Atomic::add(&_osr_compilation_id, 1);\n+    id = AtomicAccess::add(&_osr_compilation_id, 1);\n@@ -1602,1 +1610,1 @@\n-    id = Atomic::add(&_compilation_id, 1);\n+    id = AtomicAccess::add(&_compilation_id, 1);\n@@ -1614,1 +1622,1 @@\n-  return Atomic::add(&_compilation_id, 1);\n+  return AtomicAccess::add(&_compilation_id, 1);\n@@ -1640,4 +1648,2 @@\n-  CompileTask* new_task = CompileTask::allocate();\n-  new_task->initialize(compile_id, method, osr_bci, comp_level,\n-                       hot_count, compile_reason,\n-                       blocking);\n+  CompileTask* new_task = new CompileTask(compile_id, method, osr_bci, comp_level,\n+                                          hot_count, compile_reason, blocking);\n@@ -1664,1 +1670,1 @@\n- * @return true if this thread needs to free\/recycle the task\n+ * @return true if this thread needs to delete the task\n@@ -1736,2 +1742,2 @@\n-    MonitorLocker ml(thread, CompileTaskWait_lock);\n-    task->inc_waiting_for_completion();\n+    \/\/ Wait until the task is complete or compilation is shut down.\n+    MonitorLocker ml(thread, CompileTaskWait_lock);\n@@ -1742,1 +1748,0 @@\n-    task->dec_waiting_for_completion();\n@@ -1745,5 +1750,13 @@\n-  if (free_task) {\n-    if (is_compilation_disabled_forever()) {\n-      CompileTask::free(task);\n-      return;\n-    }\n+  \/\/ It is harmless to check this status without the lock, because\n+  \/\/ completion is a stable property.\n+  if (!task->is_complete()) {\n+    \/\/ Task is not complete, likely because we are exiting for compilation\n+    \/\/ shutdown. The task can still be reached through the queue, or executed\n+    \/\/ by some compiler thread. There is no coordination with either MCQ lock\n+    \/\/ holders or compilers, therefore we cannot delete the task.\n+    \/\/\n+    \/\/ This will leave task allocated, which leaks it. At this (degraded) point,\n+    \/\/ it is less risky to abandon the task, rather than attempting a more\n+    \/\/ complicated deletion protocol.\n+    free_task = false;\n+  }\n@@ -1751,2 +1764,1 @@\n-    \/\/ It is harmless to check this status without the lock, because\n-    \/\/ completion is a stable property (until the task object is recycled).\n+  if (free_task) {\n@@ -1754,0 +1766,2 @@\n+    assert(task->next() == nullptr && task->prev() == nullptr,\n+           \"Completed task should not be in the queue\");\n@@ -1755,1 +1769,1 @@\n-    \/\/ By convention, the waiter is responsible for recycling a\n+    \/\/ By convention, the waiter is responsible for deleting a\n@@ -1758,2 +1772,2 @@\n-    \/\/ be using this CompileTask; we can free it.\n-    CompileTask::free(task);\n+    \/\/ be using this CompileTask; we can delete it.\n+    delete task;\n@@ -1763,0 +1777,4 @@\n+void CompileBroker::wait_for_no_active_tasks() {\n+  CompileTask::wait_for_no_active_tasks();\n+}\n+\n@@ -1836,1 +1854,1 @@\n-      _c1_compile_queue->free_all();\n+      _c1_compile_queue->delete_all();\n@@ -1840,1 +1858,1 @@\n-      _c2_compile_queue->free_all();\n+      _c2_compile_queue->delete_all();\n@@ -1928,0 +1946,4 @@\n+  if (!thread->init_compilation_timeout()) {\n+    return;\n+  }\n+\n@@ -2340,0 +2362,1 @@\n+        thread->timeout()->reset();\n","filename":"src\/hotspot\/share\/compiler\/compileBroker.cpp","additions":80,"deletions":57,"binary":false,"changes":137,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -33,0 +34,1 @@\n+#include \"runtime\/safepoint.hpp\"\n@@ -34,1 +36,1 @@\n-CompileLog* CompileLog::_first = nullptr;\n+CompileLog* volatile CompileLog::_list_head = nullptr;\n@@ -52,3 +54,6 @@\n-  { MutexLocker locker(CompileTaskAlloc_lock);\n-    _next = _first;\n-    _first = this;\n+  while (true) {\n+    CompileLog* head = AtomicAccess::load_acquire(&_list_head);\n+    _next = head;\n+    if (AtomicAccess::cmpxchg(&_list_head, head, this) == head) {\n+      break;\n+    }\n@@ -208,2 +213,2 @@\n-  CompileLog* log = _first;\n-  while (log != nullptr) {\n+  assert_at_safepoint();\n+  for (CompileLog* log = _list_head; log != nullptr; log = log->_next) {\n@@ -211,1 +216,0 @@\n-    log = log->_next;\n@@ -226,1 +230,1 @@\n-  CompileLog* log = _first;\n+  CompileLog* log = AtomicAccess::load_acquire(&_list_head);\n@@ -314,1 +318,1 @@\n-  _first = nullptr;\n+  AtomicAccess::store(&_list_head, (CompileLog*)nullptr);\n@@ -329,0 +333,1 @@\n+  assert_at_safepoint(); \/\/ Ensures no concurrent modifications of log list\n@@ -331,1 +336,0 @@\n-  CompileLog* log = _first;\n@@ -333,2 +337,1 @@\n-\n-  while (log != nullptr) {\n+  for (CompileLog* log = _list_head; log != nullptr; log = log->_next) {\n@@ -364,1 +367,0 @@\n-    log = log->_next;\n","filename":"src\/hotspot\/share\/compiler\/compileLog.cpp","additions":15,"deletions":13,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2002, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2002, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -56,1 +56,1 @@\n-  static CompileLog* _first;     \/\/ head of static chain\n+  static CompileLog* volatile _list_head; \/\/ head of static chain\n","filename":"src\/hotspot\/share\/compiler\/compileLog.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -87,1 +87,1 @@\n-  static CompileTask*  _task_free_list;\n+  static int           _active_tasks;\n@@ -104,1 +104,0 @@\n-  int                  _waiting_count;  \/\/ See waiting_for_completion_count()\n@@ -107,2 +106,2 @@\n-  CompileTask*         _next, *_prev;\n-  bool                 _is_free;\n+  CompileTask*         _next;\n+  CompileTask*         _prev;\n@@ -121,7 +120,4 @@\n-  CompileTask() : _failure_reason(nullptr), _failure_reason_on_C_heap(false) {}\n-  void initialize(int compile_id, const methodHandle& method, int osr_bci, int comp_level,\n-                  int hot_count,\n-                  CompileTask::CompileReason compile_reason, bool is_blocking);\n-\n-  static CompileTask* allocate();\n-  static void         free(CompileTask* task);\n+  CompileTask(int compile_id, const methodHandle& method, int osr_bci, int comp_level,\n+              int hot_count, CompileReason compile_reason, bool is_blocking);\n+  ~CompileTask();\n+  static void wait_for_no_active_tasks();\n@@ -173,17 +169,0 @@\n-  \/\/ See how many threads are waiting for this task. Must have lock to read this.\n-  int waiting_for_completion_count() {\n-    assert(CompileTaskWait_lock->owned_by_self(), \"must have lock to use waiting_for_completion_count()\");\n-    return _waiting_count;\n-  }\n-  \/\/ Indicates that a thread is waiting for this task to complete. Must have lock to use this.\n-  void inc_waiting_for_completion() {\n-    assert(CompileTaskWait_lock->owned_by_self(), \"must have lock to use inc_waiting_for_completion()\");\n-    _waiting_count++;\n-  }\n-  \/\/ Indicates that a thread stopped waiting for this task to complete. Must have lock to use this.\n-  void dec_waiting_for_completion() {\n-    assert(CompileTaskWait_lock->owned_by_self(), \"must have lock to use dec_waiting_for_completion()\");\n-    assert(_waiting_count > 0, \"waiting count is not positive\");\n-    _waiting_count--;\n-  }\n-\n@@ -209,2 +188,0 @@\n-  bool         is_free() const                   { return _is_free; }\n-  void         set_is_free(bool val)             { _is_free = val; }\n","filename":"src\/hotspot\/share\/compiler\/compileTask.hpp","additions":8,"deletions":31,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 2001, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2019, 2021, Azul Systems, Inc. All rights reserved.\n+ * Copyright (c) 2001, 2026, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2026, Azul Systems, Inc. All rights reserved.\n@@ -42,1 +42,0 @@\n-#include \"gc\/g1\/g1DirtyCardQueue.hpp\"\n@@ -64,1 +63,0 @@\n-#include \"gc\/g1\/g1RedirtyCardsQueue.hpp\"\n@@ -68,0 +66,1 @@\n+#include \"gc\/g1\/g1ReviseYoungLengthTask.hpp\"\n@@ -69,1 +68,0 @@\n-#include \"gc\/g1\/g1RootProcessor.hpp\"\n@@ -78,0 +76,1 @@\n+#include \"gc\/shared\/barrierSetNMethod.hpp\"\n@@ -108,1 +107,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -114,0 +113,1 @@\n+#include \"runtime\/threads.hpp\"\n@@ -149,1 +149,1 @@\n-uint G1CollectedHeap::get_chunks_per_region() {\n+uint G1CollectedHeap::get_chunks_per_region_for_scan() {\n@@ -159,0 +159,12 @@\n+uint G1CollectedHeap::get_chunks_per_region_for_merge() {\n+  uint log_region_size = G1HeapRegion::LogOfHRGrainBytes;\n+  \/\/ Limit the expected input values to current known possible values of the\n+  \/\/ (log) region size. Adjust as necessary after testing if changing the permissible\n+  \/\/ values for region size.\n+  assert(log_region_size >= 20 && log_region_size <= 29,\n+         \"expected value in [20,29], but got %u\", log_region_size);\n+\n+  uint half_log_region_size = (log_region_size + 1) \/ 2;\n+  return 1 << (half_log_region_size - 9);\n+}\n+\n@@ -177,4 +189,7 @@\n-    \/\/ Currently, only attempts to allocate GC alloc regions set\n-    \/\/ do_expand to true. So, we should only reach here during a\n-    \/\/ safepoint.\n-    assert(SafepointSynchronize::is_at_safepoint(), \"invariant\");\n+    \/\/ There are two situations where do_expand is set to true:\n+    \/\/  - for mutator regions during initialization\n+    \/\/  - for GC alloc regions during a safepoint\n+    \/\/ Make sure we only reach here before initialization is complete\n+    \/\/ or during a safepoint.\n+    assert(!is_init_completed() ||\n+           SafepointSynchronize::is_at_safepoint() , \"invariant\");\n@@ -342,0 +357,8 @@\n+size_t G1CollectedHeap::allocation_used_bytes(size_t allocation_word_size) {\n+  if (is_humongous(allocation_word_size)) {\n+    return humongous_obj_size_in_regions(allocation_word_size) * G1HeapRegion::GrainBytes;\n+  } else {\n+    return allocation_word_size * HeapWordSize;\n+  }\n+}\n+\n@@ -351,0 +374,4 @@\n+  if (obj_regions > num_available_regions()) {\n+    \/\/ Can't satisfy this allocation; early-return.\n+    return nullptr;\n+  }\n@@ -391,1 +418,6 @@\n-  return attempt_allocation(min_size, requested_size, actual_size);\n+  \/\/ Do not allow a GC because we are allocating a new TLAB to avoid an issue\n+  \/\/ with UseGCOverheadLimit: although this GC would return null if the overhead\n+  \/\/ limit would be exceeded, but it would likely free at least some space.\n+  \/\/ So the subsequent outside-TLAB allocation could be successful anyway and\n+  \/\/ the indication that the overhead limit had been exceeded swallowed.\n+  return attempt_allocation(min_size, requested_size, actual_size, false \/* allow_gc *\/);\n@@ -394,3 +426,1 @@\n-HeapWord*\n-G1CollectedHeap::mem_allocate(size_t word_size,\n-                              bool*  gc_overhead_limit_was_exceeded) {\n+HeapWord* G1CollectedHeap::mem_allocate(size_t word_size) {\n@@ -403,1 +433,1 @@\n-  return attempt_allocation(word_size, word_size, &dummy);\n+  return attempt_allocation(word_size, word_size, &dummy, true \/* allow_gc *\/);\n@@ -406,1 +436,1 @@\n-HeapWord* G1CollectedHeap::attempt_allocation_slow(uint node_index, size_t word_size) {\n+HeapWord* G1CollectedHeap::attempt_allocation_slow(uint node_index, size_t word_size, bool allow_gc) {\n@@ -433,0 +463,2 @@\n+      } else if (!allow_gc) {\n+        return nullptr;\n@@ -450,0 +482,7 @@\n+    \/\/ Has the gc overhead limit been reached in the meantime? If so, this mutator\n+    \/\/ should receive null even when unsuccessfully scheduling a collection as well\n+    \/\/ for global consistency.\n+    if (gc_overhead_limit_exceeded()) {\n+      return nullptr;\n+    }\n+\n@@ -451,1 +490,1 @@\n-    \/\/ another thread beat us to it). In this case immeditealy retry the allocation\n+    \/\/ another thread beat us to it). In this case immediately retry the allocation\n@@ -499,1 +538,1 @@\n-                       \" bytes, heap = %zu bytes\", word_size, reserved.word_size());\n+                       \" bytes, heap = %zu bytes\", word_size * HeapWordSize, reserved.byte_size());\n@@ -596,1 +635,2 @@\n-                                                     size_t* actual_word_size) {\n+                                                     size_t* actual_word_size,\n+                                                     bool allow_gc) {\n@@ -608,1 +648,1 @@\n-    result = attempt_allocation_slow(node_index, desired_word_size);\n+    result = attempt_allocation_slow(node_index, desired_word_size, allow_gc);\n@@ -614,1 +654,0 @@\n-    dirty_young_block(result, *actual_word_size);\n@@ -622,0 +661,6 @@\n+\/\/ Helper for [try_]collect().\n+static G1GCCounters collection_counters(G1CollectedHeap* g1h) {\n+  MutexLocker ml(Heap_lock);\n+  return G1GCCounters(g1h);\n+}\n+\n@@ -645,1 +690,2 @@\n-  if (policy()->need_to_start_conc_mark(\"concurrent humongous allocation\",\n+  \/\/ Only try that if we can actually perform a GC.\n+  if (is_init_completed() && policy()->need_to_start_conc_mark(\"concurrent humongous allocation\",\n@@ -647,1 +693,1 @@\n-    collect(GCCause::_g1_humongous_allocation);\n+    try_collect(word_size, GCCause::_g1_humongous_allocation, collection_counters(this));\n@@ -657,0 +703,2 @@\n+    \/\/ The amount of bytes the humongous object will actually take.\n+    size_t humongous_byte_size = G1HeapRegion::align_up_to_region_byte_size(word_size * HeapWordSize);\n@@ -661,1 +709,0 @@\n-      size_t size_in_regions = humongous_obj_size_in_regions(word_size);\n@@ -668,1 +715,1 @@\n-          add_allocated_humongous_bytes_since_last_gc(size_in_regions * G1HeapRegion::GrainBytes);\n+          add_allocated_humongous_bytes_since_last_gc(humongous_byte_size);\n@@ -682,2 +729,1 @@\n-        size_t size_in_regions = humongous_obj_size_in_regions(word_size);\n-          record_collection_pause_humongous_allocation(size_in_regions * G1HeapRegion::GrainBytes);\n+          record_collection_pause_humongous_allocation(humongous_byte_size);\n@@ -692,0 +738,7 @@\n+    \/\/ Has the gc overhead limit been reached in the meantime? If so, this mutator\n+    \/\/ should receive null even when unsuccessfully scheduling a collection as well\n+    \/\/ for global consistency.\n+    if (gc_overhead_limit_exceeded()) {\n+      return nullptr;\n+    }\n+\n@@ -722,1 +775,3 @@\n-    if (result != nullptr && policy()->need_to_start_conc_mark(\"STW humongous allocation\")) {\n+    if (result != nullptr &&\n+        \/\/ We just allocated the humongous object, so the given allocation size is 0.\n+        policy()->need_to_start_conc_mark(\"STW humongous allocation\", 0 \/* allocation_word_size *\/)) {\n@@ -772,1 +827,1 @@\n-  abandon_collection_set(collection_set());\n+  abandon_collection_set();\n@@ -795,1 +850,1 @@\n-  resize_heap_if_necessary(allocation_word_size);\n+  resize_heap_after_full_collection(allocation_word_size);\n@@ -797,3 +852,1 @@\n-    cleanup_unused_regions(); \/\/ Includes uncommitting\n-  } else {\n-    uncommit_regions_if_necessary();\n+    cleanup_unused_regions();\n@@ -804,0 +857,1 @@\n+  finish_codecache_marking_cycle();\n@@ -813,5 +867,21 @@\n-  \/\/ Discard all remembered set updates and reset refinement statistics.\n-  G1BarrierSet::dirty_card_queue_set().abandon_logs_and_stats();\n-  assert(G1BarrierSet::dirty_card_queue_set().num_cards() == 0,\n-         \"DCQS should be empty\");\n-  concurrent_refine()->get_and_reset_refinement_stats();\n+  G1ConcurrentRefineSweepState& sweep_state = concurrent_refine()->sweep_state();\n+  if (sweep_state.is_in_progress()) {\n+\n+    if (!sweep_state.are_java_threads_synched()) {\n+      \/\/ Synchronize Java threads with global card table that has already been swapped.\n+      class SwapThreadCardTableClosure : public ThreadClosure {\n+      public:\n+\n+        virtual void do_thread(Thread* t) {\n+          G1BarrierSet* bs = G1BarrierSet::g1_barrier_set();\n+          bs->update_card_table_base(t);\n+        }\n+      } cl;\n+      Threads::java_threads_do(&cl);\n+    }\n+\n+    \/\/ Record any available refinement statistics.\n+    policy()->record_refinement_stats(sweep_state.stats());\n+    sweep_state.complete_work(false \/* concurrent *\/, false \/* print_log *\/);\n+  }\n+  sweep_state.reset_stats();\n@@ -829,0 +899,1 @@\n+  _verifier->verify_card_tables_clean(true \/* both_card_tables *\/);\n@@ -848,3 +919,3 @@\n-void G1CollectedHeap::do_full_collection(bool clear_all_soft_refs,\n-                                         bool do_maximal_compaction,\n-                                         size_t allocation_word_size) {\n+void G1CollectedHeap::do_full_collection(size_t allocation_word_size,\n+                                         bool clear_all_soft_refs,\n+                                         bool do_maximal_compaction) {\n@@ -853,3 +924,0 @@\n-  const bool do_clear_all_soft_refs = clear_all_soft_refs ||\n-      soft_ref_policy()->should_clear_all_soft_refs();\n-\n@@ -858,1 +926,1 @@\n-  G1FullCollector collector(this, do_clear_all_soft_refs, do_maximal_compaction, gc_mark.tracer());\n+  G1FullCollector collector(this, clear_all_soft_refs, do_maximal_compaction, gc_mark.tracer());\n@@ -870,3 +938,3 @@\n-  do_full_collection(clear_all_soft_refs,\n-                     false \/* do_maximal_compaction *\/,\n-                     size_t(0) \/* allocation_word_size *\/);\n+  do_full_collection(size_t(0) \/* allocation_word_size *\/,\n+                     clear_all_soft_refs,\n+                     false \/* do_maximal_compaction *\/);\n@@ -878,18 +946,3 @@\n-  do_full_collection(true  \/* clear_all_soft_refs *\/,\n-                     false \/* do_maximal_compaction *\/,\n-                     size_t(0) \/* allocation_word_size *\/);\n-}\n-\n-void G1CollectedHeap::resize_heap_if_necessary(size_t allocation_word_size) {\n-  assert_at_safepoint_on_vm_thread();\n-\n-  bool should_expand;\n-  size_t resize_amount = _heap_sizing_policy->full_collection_resize_amount(should_expand, allocation_word_size);\n-\n-  if (resize_amount == 0) {\n-    return;\n-  } else if (should_expand) {\n-    expand(resize_amount, _workers);\n-  } else {\n-    shrink(resize_amount);\n-  }\n+  do_full_collection(size_t(0) \/* allocation_word_size *\/,\n+                     true  \/* clear_all_soft_refs *\/,\n+                     false \/* do_maximal_compaction *\/);\n@@ -914,1 +967,1 @@\n-  expand(orig_capacity - capacity());\n+  expand(orig_capacity - capacity(), _workers);\n@@ -918,0 +971,61 @@\n+void G1CollectedHeap::resize_heap(size_t resize_bytes, bool should_expand) {\n+  if (should_expand) {\n+    expand(resize_bytes, _workers);\n+  } else {\n+    shrink(resize_bytes);\n+    uncommit_regions_if_necessary();\n+  }\n+}\n+\n+void G1CollectedHeap::resize_heap_after_full_collection(size_t allocation_word_size) {\n+  assert_at_safepoint_on_vm_thread();\n+\n+  bool should_expand;\n+  size_t resize_bytes = _heap_sizing_policy->full_collection_resize_amount(should_expand, allocation_word_size);\n+\n+  if (resize_bytes != 0) {\n+    resize_heap(resize_bytes, should_expand);\n+  }\n+}\n+\n+void G1CollectedHeap::resize_heap_after_young_collection(size_t allocation_word_size) {\n+  Ticks start = Ticks::now();\n+\n+  bool should_expand;\n+\n+  size_t resize_bytes = _heap_sizing_policy->young_collection_resize_amount(should_expand, allocation_word_size);\n+\n+  if (resize_bytes != 0) {\n+    resize_heap(resize_bytes, should_expand);\n+  }\n+\n+  phase_times()->record_resize_heap_time((Ticks::now() - start).seconds() * 1000.0);\n+}\n+\n+void G1CollectedHeap::update_gc_overhead_counter() {\n+  assert(SafepointSynchronize::is_at_safepoint(), \"precondition\");\n+\n+  if (!UseGCOverheadLimit) {\n+    return;\n+  }\n+\n+  bool gc_time_over_limit = (_policy->analytics()->long_term_gc_time_ratio() * 100) >= GCTimeLimit;\n+  double free_space_percent = percent_of(num_available_regions() * G1HeapRegion::GrainBytes, max_capacity());\n+  bool free_space_below_limit = free_space_percent < GCHeapFreeLimit;\n+\n+  log_debug(gc)(\"GC Overhead Limit: GC Time %f Free Space %f Counter %zu\",\n+                (_policy->analytics()->long_term_gc_time_ratio() * 100),\n+                free_space_percent,\n+                _gc_overhead_counter);\n+\n+  if (gc_time_over_limit && free_space_below_limit) {\n+    _gc_overhead_counter++;\n+  } else {\n+    _gc_overhead_counter = 0;\n+  }\n+}\n+\n+bool G1CollectedHeap::gc_overhead_limit_exceeded() {\n+  return _gc_overhead_counter >= GCOverheadLimitThreshold;\n+}\n+\n@@ -922,7 +1036,16 @@\n-  \/\/ Let's attempt the allocation first.\n-  HeapWord* result =\n-    attempt_allocation_at_safepoint(word_size,\n-                                    expect_null_mutator_alloc_region);\n-  if (result != nullptr) {\n-    return result;\n-  }\n+  \/\/ Skip allocation if GC overhead limit has been exceeded to let the mutator run\n+  \/\/ into an OOME. It can either exit \"gracefully\" or try to free up memory asap.\n+  \/\/ For the latter situation, keep running GCs. If the mutator frees up enough\n+  \/\/ memory quickly enough, the overhead(s) will go below the threshold(s) again\n+  \/\/ and the VM may continue running.\n+  \/\/ If we did not continue garbage collections, the (gc overhead) limit may decrease\n+  \/\/ enough by itself to not count as exceeding the limit any more, in the worst\n+  \/\/ case bouncing back-and-forth all the time.\n+  if (!gc_overhead_limit_exceeded()) {\n+    \/\/ Let's attempt the allocation first.\n+    HeapWord* result =\n+      attempt_allocation_at_safepoint(word_size,\n+                                      expect_null_mutator_alloc_region);\n+    if (result != nullptr) {\n+      return result;\n+    }\n@@ -930,7 +1053,8 @@\n-  \/\/ In a G1 heap, we're supposed to keep allocation from failing by\n-  \/\/ incremental pauses.  Therefore, at least for now, we'll favor\n-  \/\/ expansion over collection.  (This might change in the future if we can\n-  \/\/ do something smarter than full collection to satisfy a failed alloc.)\n-  result = expand_and_allocate(word_size);\n-  if (result != nullptr) {\n-    return result;\n+    \/\/ In a G1 heap, we're supposed to keep allocation from failing by\n+    \/\/ incremental pauses.  Therefore, at least for now, we'll favor\n+    \/\/ expansion over collection.  (This might change in the future if we can\n+    \/\/ do something smarter than full collection to satisfy a failed alloc.)\n+    result = expand_and_allocate(word_size);\n+    if (result != nullptr) {\n+      return result;\n+    }\n@@ -949,3 +1073,3 @@\n-    do_full_collection(maximal_compaction \/* clear_all_soft_refs *\/,\n-                       maximal_compaction \/* do_maximal_compaction *\/,\n-                       word_size \/* allocation_word_size *\/);\n+    do_full_collection(word_size \/* allocation_word_size *\/,\n+                       maximal_compaction \/* clear_all_soft_refs *\/,\n+                       maximal_compaction \/* do_maximal_compaction *\/);\n@@ -960,0 +1084,4 @@\n+  \/\/ Update GC overhead limits after the initial garbage collection leading to this\n+  \/\/ allocation attempt.\n+  update_gc_overhead_counter();\n+\n@@ -964,1 +1092,1 @@\n-                                     false, \/* maximum_collection *\/\n+                                     false, \/* maximal_compaction *\/\n@@ -974,1 +1102,1 @@\n-                                            true, \/* maximum_collection *\/\n+                                            true, \/* maximal_compaction *\/\n@@ -984,1 +1112,1 @@\n-                                            false, \/* maximum_collection *\/\n+                                            false, \/* maximal_compaction *\/\n@@ -991,2 +1119,3 @@\n-  assert(!soft_ref_policy()->should_clear_all_soft_refs(),\n-         \"Flag should have been handled and cleared prior to this point\");\n+  if (gc_overhead_limit_exceeded()) {\n+    log_info(gc)(\"GC Overhead Limit exceeded too often (%zu).\", GCOverheadLimitThreshold);\n+  }\n@@ -1025,1 +1154,3 @@\n-bool G1CollectedHeap::expand(size_t expand_bytes, WorkerThreads* pretouch_workers, double* expand_time_ms) {\n+bool G1CollectedHeap::expand(size_t expand_bytes, WorkerThreads* pretouch_workers) {\n+  assert(expand_bytes > 0, \"precondition\");\n+\n@@ -1029,2 +1160,4 @@\n-  log_debug(gc, ergo, heap)(\"Expand the heap. requested expansion amount: %zuB expansion amount: %zuB\",\n-                            expand_bytes, aligned_expand_bytes);\n+  uint num_regions_to_expand = (uint)(aligned_expand_bytes \/ G1HeapRegion::GrainBytes);\n+\n+  log_debug(gc, ergo, heap)(\"Heap resize. Requested expansion amount: %zuB aligned expansion amount: %zuB (%u regions)\",\n+                            expand_bytes, aligned_expand_bytes, num_regions_to_expand);\n@@ -1033,1 +1166,1 @@\n-    log_debug(gc, ergo, heap)(\"Did not expand the heap (heap already fully expanded)\");\n+    log_debug(gc, ergo, heap)(\"Heap resize. Did not expand the heap (heap already fully expanded)\");\n@@ -1037,10 +1170,1 @@\n-  double expand_heap_start_time_sec = os::elapsedTime();\n-  uint regions_to_expand = (uint)(aligned_expand_bytes \/ G1HeapRegion::GrainBytes);\n-  assert(regions_to_expand > 0, \"Must expand by at least one region\");\n-\n-  uint expanded_by = _hrm.expand_by(regions_to_expand, pretouch_workers);\n-  if (expand_time_ms != nullptr) {\n-    *expand_time_ms = (os::elapsedTime() - expand_heap_start_time_sec) * MILLIUNITS;\n-  }\n-\n-  assert(expanded_by > 0, \"must have failed during commit.\");\n+  uint expanded_by = _hrm.expand_by(num_regions_to_expand, pretouch_workers);\n@@ -1069,2 +1193,5 @@\n-  size_t aligned_shrink_bytes = os::align_down_vm_page_size(shrink_bytes);\n-  aligned_shrink_bytes = align_down(aligned_shrink_bytes, G1HeapRegion::GrainBytes);\n+  assert(shrink_bytes > 0, \"must be\");\n+  assert(is_aligned(shrink_bytes, G1HeapRegion::GrainBytes),\n+         \"Shrink request for %zuB not aligned to heap region size %zuB\",\n+         shrink_bytes, G1HeapRegion::GrainBytes);\n+\n@@ -1076,2 +1203,2 @@\n-  log_debug(gc, ergo, heap)(\"Shrink the heap. requested shrinking amount: %zuB aligned shrinking amount: %zuB actual amount shrunk: %zuB\",\n-                            shrink_bytes, aligned_shrink_bytes, shrunk_bytes);\n+  log_debug(gc, ergo, heap)(\"Heap resize. Requested shrinking amount: %zuB actual shrinking amount: %zuB (%u regions)\",\n+                            shrink_bytes, shrunk_bytes, num_regions_removed);\n@@ -1079,1 +1206,0 @@\n-    log_debug(gc, heap)(\"Uncommittable regions after shrink: %u\", num_regions_removed);\n@@ -1082,1 +1208,1 @@\n-    log_debug(gc, ergo, heap)(\"Did not shrink the heap (heap shrinking operation failed)\");\n+    log_debug(gc, ergo, heap)(\"Heap resize. Did not shrink the heap (heap shrinking operation failed)\");\n@@ -1087,0 +1213,19 @@\n+  if (capacity() == min_capacity()) {\n+    log_debug(gc, ergo, heap)(\"Heap resize. Did not shrink the heap (heap already at minimum)\");\n+    return;\n+  }\n+\n+  size_t aligned_shrink_bytes = os::align_down_vm_page_size(shrink_bytes);\n+  aligned_shrink_bytes = align_down(aligned_shrink_bytes, G1HeapRegion::GrainBytes);\n+\n+  aligned_shrink_bytes = capacity() - MAX2(capacity() - aligned_shrink_bytes, min_capacity());\n+  assert(is_aligned(aligned_shrink_bytes, G1HeapRegion::GrainBytes), \"Bytes to shrink %zuB not aligned\", aligned_shrink_bytes);\n+\n+  log_debug(gc, ergo, heap)(\"Heap resize. Requested shrink amount: %zuB aligned shrink amount: %zuB\",\n+                            shrink_bytes, aligned_shrink_bytes);\n+\n+  if (aligned_shrink_bytes == 0) {\n+    log_debug(gc, ergo, heap)(\"Heap resize. Did not shrink the heap (shrink request too small)\");\n+    return;\n+  }\n+\n@@ -1098,1 +1243,1 @@\n-  shrink_helper(shrink_bytes);\n+  shrink_helper(aligned_shrink_bytes);\n@@ -1123,1 +1268,1 @@\n-                FreeList_lock->owned_by_self() || OldSets_lock->owned_by_self(),\n+                G1FreeList_lock->owned_by_self() || G1OldSets_lock->owned_by_self(),\n@@ -1146,1 +1291,1 @@\n-                OldSets_lock->owned_by_self(),\n+                G1OldSets_lock->owned_by_self(),\n@@ -1159,0 +1304,1 @@\n+  _gc_overhead_counter(0),\n@@ -1162,0 +1308,1 @@\n+  _revise_young_length_task(nullptr),\n@@ -1163,1 +1310,5 @@\n-  _card_table(nullptr),\n+  _refinement_epoch(0),\n+  _last_synchronized_start(0),\n+  _last_refinement_epoch_start(0),\n+  _yield_duration_in_refinement_epoch(0),\n+  _last_safepoint_refinement_epoch(0),\n@@ -1194,1 +1345,1 @@\n-  _young_regions_cset_group(card_set_config(), &_card_set_freelist_pool, 1u \/* group_id *\/),\n+  _young_regions_cset_group(card_set_config(), &_card_set_freelist_pool, G1CSetCandidateGroup::YoungRegionId),\n@@ -1283,1 +1434,1 @@\n-  _cr = G1ConcurrentRefine::create(policy(), &ecode);\n+  _cr = G1ConcurrentRefine::create(this, &ecode);\n@@ -1298,0 +1449,3 @@\n+  if (!os::is_thread_cpu_time_supported()) {\n+    vm_exit_during_initialization(\"G1 requires cpu time gathering support\");\n+  }\n@@ -1336,6 +1490,2 @@\n-  G1CardTable* ct = new G1CardTable(_reserved);\n-  G1BarrierSet* bs = new G1BarrierSet(ct);\n-  bs->initialize();\n-  assert(bs->is_a(BarrierSet::G1BarrierSet), \"sanity\");\n-  BarrierSet::set_barrier_set(bs);\n-  _card_table = ct;\n+  G1CardTable* card_table = new G1CardTable(_reserved);\n+  G1CardTable* refinement_table = new G1CardTable(_reserved);\n@@ -1343,5 +1493,2 @@\n-  {\n-    G1SATBMarkQueueSet& satbqs = bs->satb_mark_queue_set();\n-    satbqs.set_process_completed_buffers_threshold(G1SATBProcessCompletedThreshold);\n-    satbqs.set_buffer_enqueue_threshold_percentage(G1SATBBufferEnqueueingThresholdPercent);\n-  }\n+  G1BarrierSet* bs = new G1BarrierSet(card_table, refinement_table);\n+  assert(bs->is_a(BarrierSet::G1BarrierSet), \"sanity\");\n@@ -1364,1 +1511,1 @@\n-                       MinHeapSize,\n+                       min_capacity(),\n@@ -1382,0 +1529,5 @@\n+  G1RegionToSpaceMapper* refinement_cards_storage =\n+    create_aux_memory_mapper(\"Refinement Card Table\",\n+                             G1CardTable::compute_size(heap_rs.size() \/ HeapWordSize),\n+                             G1CardTable::heap_map_factor());\n+\n@@ -1386,2 +1538,11 @@\n-  _hrm.initialize(heap_storage, bitmap_storage, bot_storage, cardtable_storage);\n-  _card_table->initialize(cardtable_storage);\n+  _hrm.initialize(heap_storage, bitmap_storage, bot_storage, cardtable_storage, refinement_cards_storage);\n+  card_table->initialize(cardtable_storage);\n+  refinement_table->initialize(refinement_cards_storage);\n+\n+  BarrierSet::set_barrier_set(bs);\n+\n+  {\n+    G1SATBMarkQueueSet& satbqs = bs->satb_mark_queue_set();\n+    satbqs.set_process_completed_buffers_threshold(G1SATBProcessCompletedThreshold);\n+    satbqs.set_buffer_enqueue_threshold_percentage(G1SATBBufferEnqueueingThresholdPercent);\n+  }\n@@ -1399,1 +1560,1 @@\n-  _rem_set = new G1RemSet(this, _card_table);\n+  _rem_set = new G1RemSet(this);\n@@ -1458,0 +1619,5 @@\n+  if (policy()->use_adaptive_young_list_length()) {\n+    _revise_young_length_task = new G1ReviseYoungLengthTask(\"Revise Young Length List Task\");\n+    _service_thread->register_task(_revise_young_length_task);\n+  }\n+\n@@ -1479,0 +1645,2 @@\n+  start_new_collection_set();\n+\n@@ -1484,0 +1652,1 @@\n+  CPUTimeCounters::create_counter(CPUTimeGroups::CPUTimeType::gc_conc_refine_control);\n@@ -1508,0 +1677,2 @@\n+\n+  _last_synchronized_start = os::elapsed_counter();\n@@ -1511,0 +1682,11 @@\n+  jlong now = os::elapsed_counter();\n+  jlong synchronize_duration = now - _last_synchronized_start;\n+\n+  if (_last_safepoint_refinement_epoch == _refinement_epoch) {\n+    _yield_duration_in_refinement_epoch += synchronize_duration;\n+  } else {\n+    _last_refinement_epoch_start = now;\n+    _last_safepoint_refinement_epoch = _refinement_epoch;\n+    _yield_duration_in_refinement_epoch = 0;\n+  }\n+\n@@ -1514,0 +1696,10 @@\n+void G1CollectedHeap::set_last_refinement_epoch_start(jlong epoch_start, jlong last_yield_duration) {\n+  _last_refinement_epoch_start = epoch_start;\n+  guarantee(_yield_duration_in_refinement_epoch >= last_yield_duration, \"should be\");\n+  _yield_duration_in_refinement_epoch -= last_yield_duration;\n+}\n+\n+jlong G1CollectedHeap::yield_duration_in_refinement_epoch() {\n+  return _yield_duration_in_refinement_epoch;\n+}\n+\n@@ -1685,7 +1877,1 @@\n-\/\/ Helper for collect().\n-static G1GCCounters collection_counters(G1CollectedHeap* g1h) {\n-  MutexLocker ml(Heap_lock);\n-  return G1GCCounters(g1h);\n-}\n-\n-  try_collect(cause, collection_counters(this));\n+  try_collect(0 \/* allocation_word_size *\/, cause, collection_counters(this));\n@@ -1718,1 +1904,62 @@\n-bool G1CollectedHeap::try_collect_concurrently(GCCause::Cause cause,\n+bool G1CollectedHeap::wait_full_mark_finished(GCCause::Cause cause,\n+                                              uint old_marking_started_before,\n+                                              uint old_marking_started_after,\n+                                              uint old_marking_completed_after) {\n+  \/\/ Request is finished if a full collection (concurrent or stw)\n+  \/\/ was started after this request and has completed, e.g.\n+  \/\/ started_before < completed_after.\n+  if (gc_counter_less_than(old_marking_started_before,\n+                           old_marking_completed_after)) {\n+    LOG_COLLECT_CONCURRENTLY_COMPLETE(cause, true);\n+    return true;\n+  }\n+\n+  if (old_marking_started_after != old_marking_completed_after) {\n+    \/\/ If there is an in-progress cycle (possibly started by us), then\n+    \/\/ wait for that cycle to complete, e.g.\n+    \/\/ while completed_now < started_after.\n+    LOG_COLLECT_CONCURRENTLY(cause, \"wait\");\n+    MonitorLocker ml(G1OldGCCount_lock);\n+    while (gc_counter_less_than(_old_marking_cycles_completed,\n+                                old_marking_started_after)) {\n+      ml.wait();\n+    }\n+    \/\/ Request is finished if the collection we just waited for was\n+    \/\/ started after this request.\n+    if (old_marking_started_before != old_marking_started_after) {\n+      LOG_COLLECT_CONCURRENTLY(cause, \"complete after wait\");\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n+\/\/ After calling wait_full_mark_finished(), this method determines whether we\n+\/\/ previously failed for ordinary reasons (concurrent cycle in progress, whitebox\n+\/\/ has control). Returns if this has been such an ordinary reason.\n+static bool should_retry_vm_op(GCCause::Cause cause,\n+                               VM_G1TryInitiateConcMark* op) {\n+  if (op->cycle_already_in_progress()) {\n+    \/\/ If VMOp failed because a cycle was already in progress, it\n+    \/\/ is now complete.  But it didn't finish this user-requested\n+    \/\/ GC, so try again.\n+    LOG_COLLECT_CONCURRENTLY(cause, \"retry after in-progress\");\n+    return true;\n+  } else if (op->whitebox_attached()) {\n+    \/\/ If WhiteBox wants control, wait for notification of a state\n+    \/\/ change in the controller, then try again.  Don't wait for\n+    \/\/ release of control, since collections may complete while in\n+    \/\/ control.  Note: This won't recognize a STW full collection\n+    \/\/ while waiting; we can't wait on multiple monitors.\n+    LOG_COLLECT_CONCURRENTLY(cause, \"whitebox control stall\");\n+    MonitorLocker ml(ConcurrentGCBreakpoints::monitor());\n+    if (ConcurrentGCBreakpoints::is_controlled()) {\n+      ml.wait();\n+    }\n+    return true;\n+  }\n+  return false;\n+}\n+\n+bool G1CollectedHeap::try_collect_concurrently(size_t allocation_word_size,\n+                                               GCCause::Cause cause,\n@@ -1729,1 +1976,1 @@\n-    VM_G1TryInitiateConcMark op(gc_counter, cause);\n+    VM_G1TryInitiateConcMark op(allocation_word_size, gc_counter, cause);\n@@ -1739,2 +1986,2 @@\n-    \/\/ we're terminating, then we're done.\n-    if (op.terminating()) {\n+    \/\/ we're shutting down, then we're done.\n+    if (op.is_shutting_down()) {\n@@ -1778,0 +2025,35 @@\n+    } else if (GCCause::is_codecache_requested_gc(cause)) {\n+      assert(allocation_word_size == 0, \"must be\");\n+      \/\/ For a CodeCache requested GC, before marking, progress is ensured as the\n+      \/\/ following Remark pause unloads code (and signals the requester such).\n+      \/\/ Otherwise we must ensure that it is restarted.\n+      \/\/\n+      \/\/ For a CodeCache requested GC, a successful GC operation means that\n+      \/\/ (1) marking is in progress. I.e. the VMOp started the marking or a\n+      \/\/     Remark pause is pending from a different VM op; we will potentially\n+      \/\/     abort a mixed phase if needed.\n+      \/\/ (2) a new cycle was started (by this thread or some other), or\n+      \/\/ (3) a Full GC was performed.\n+      \/\/\n+      \/\/ Cases (2) and (3) are detected together by a change to\n+      \/\/ _old_marking_cycles_started.\n+      \/\/\n+      \/\/ Compared to other \"automatic\" GCs (see below), we do not consider being\n+      \/\/ in whitebox as sufficient too because we might be anywhere within that\n+      \/\/ cycle and we need to make progress.\n+      if (op.mark_in_progress() ||\n+          (old_marking_started_before != old_marking_started_after)) {\n+        LOG_COLLECT_CONCURRENTLY_COMPLETE(cause, true);\n+        return true;\n+      }\n+\n+      if (wait_full_mark_finished(cause,\n+                                  old_marking_started_before,\n+                                  old_marking_started_after,\n+                                  old_marking_completed_after)) {\n+        return true;\n+      }\n+\n+      if (should_retry_vm_op(cause, &op)) {\n+        continue;\n+      }\n@@ -1779,0 +2061,4 @@\n+      assert(cause == GCCause::_g1_humongous_allocation ||\n+             cause == GCCause::_g1_periodic_collection,\n+             \"Unsupported cause %s\", GCCause::to_string(cause));\n+\n@@ -1790,5 +2076,0 @@\n-      \/\/\n-      \/\/ Note that (1) does not imply (4).  If we're still in the mixed\n-      \/\/ phase of an earlier concurrent collection, the request to make the\n-      \/\/ collection a concurrent start won't be honored.  If we don't check for\n-      \/\/ both conditions we'll spin doing back-to-back collections.\n@@ -1818,6 +2099,4 @@\n-      \/\/ Request is finished if a full collection (concurrent or stw)\n-      \/\/ was started after this request and has completed, e.g.\n-      \/\/ started_before < completed_after.\n-      if (gc_counter_less_than(old_marking_started_before,\n-                               old_marking_completed_after)) {\n-        LOG_COLLECT_CONCURRENTLY_COMPLETE(cause, true);\n+      if (wait_full_mark_finished(cause,\n+                                  old_marking_started_before,\n+                                  old_marking_started_after,\n+                                  old_marking_completed_after)) {\n@@ -1827,18 +2106,0 @@\n-      if (old_marking_started_after != old_marking_completed_after) {\n-        \/\/ If there is an in-progress cycle (possibly started by us), then\n-        \/\/ wait for that cycle to complete, e.g.\n-        \/\/ while completed_now < started_after.\n-        LOG_COLLECT_CONCURRENTLY(cause, \"wait\");\n-        MonitorLocker ml(G1OldGCCount_lock);\n-        while (gc_counter_less_than(_old_marking_cycles_completed,\n-                                    old_marking_started_after)) {\n-          ml.wait();\n-        }\n-        \/\/ Request is finished if the collection we just waited for was\n-        \/\/ started after this request.\n-        if (old_marking_started_before != old_marking_started_after) {\n-          LOG_COLLECT_CONCURRENTLY(cause, \"complete after wait\");\n-          return true;\n-        }\n-      }\n-\n@@ -1851,17 +2112,1 @@\n-      if (op.cycle_already_in_progress()) {\n-        \/\/ If VMOp failed because a cycle was already in progress, it\n-        \/\/ is now complete.  But it didn't finish this user-requested\n-        \/\/ GC, so try again.\n-        LOG_COLLECT_CONCURRENTLY(cause, \"retry after in-progress\");\n-        continue;\n-      } else if (op.whitebox_attached()) {\n-        \/\/ If WhiteBox wants control, wait for notification of a state\n-        \/\/ change in the controller, then try again.  Don't wait for\n-        \/\/ release of control, since collections may complete while in\n-        \/\/ control.  Note: This won't recognize a STW full collection\n-        \/\/ while waiting; we can't wait on multiple monitors.\n-        LOG_COLLECT_CONCURRENTLY(cause, \"whitebox control stall\");\n-        MonitorLocker ml(ConcurrentGCBreakpoints::monitor());\n-        if (ConcurrentGCBreakpoints::is_controlled()) {\n-          ml.wait();\n-        }\n+      if (should_retry_vm_op(cause, &op)) {\n@@ -1879,1 +2124,2 @@\n-bool G1CollectedHeap::try_collect(GCCause::Cause cause,\n+bool G1CollectedHeap::try_collect(size_t allocation_word_size,\n+                                  GCCause::Cause cause,\n@@ -1882,1 +2128,2 @@\n-    return try_collect_concurrently(cause,\n+    return try_collect_concurrently(allocation_word_size,\n+                                    cause,\n@@ -1888,0 +2135,1 @@\n+    assert(allocation_word_size == 0, \"must be\");\n@@ -1896,0 +2144,3 @@\n+    \/\/ The only path to get here is because of a periodic collection using a Full GC\n+    \/\/ or WhiteBox full gc.\n+    assert(allocation_word_size == 0, \"must be\");\n@@ -1912,1 +2163,1 @@\n-    do_collection_pause_at_safepoint();\n+    do_collection_pause_at_safepoint(0 \/* allocation_word_size *\/);\n@@ -2049,2 +2300,2 @@\n-size_t G1CollectedHeap::tlab_capacity(Thread* ignored) const {\n-  return (_policy->young_list_target_length() - _survivor.length()) * G1HeapRegion::GrainBytes;\n+size_t G1CollectedHeap::tlab_capacity() const {\n+  return eden_target_length() * G1HeapRegion::GrainBytes;\n@@ -2053,1 +2304,1 @@\n-size_t G1CollectedHeap::tlab_used(Thread* ignored) const {\n+size_t G1CollectedHeap::tlab_used() const {\n@@ -2063,1 +2314,1 @@\n-size_t G1CollectedHeap::unsafe_max_tlab_alloc(Thread* ignored) const {\n+size_t G1CollectedHeap::unsafe_max_tlab_alloc() const {\n@@ -2071,0 +2322,4 @@\n+size_t G1CollectedHeap::min_capacity() const {\n+  return MinHeapSize;\n+}\n+\n@@ -2122,0 +2377,4 @@\n+static void print_region_type(outputStream* st, const char* type, uint count, bool last = false) {\n+  st->print(\"%u %s (%zuM)%s\", count, type, count * G1HeapRegion::GrainBytes \/ M, last ? \"\\n\" : \", \");\n+}\n+\n@@ -2123,1 +2382,2 @@\n-  size_t heap_used = Heap_lock->owned_by_self() ? used() : used_unlocked();\n+  size_t heap_used = (Thread::current_or_null_safe() != nullptr &&\n+                      Heap_lock->owned_by_self()) ? used() : used_unlocked();\n@@ -2133,8 +2393,7 @@\n-  st->print(\"region size %zuK, \", G1HeapRegion::GrainBytes \/ K);\n-  uint young_regions = young_regions_count();\n-  st->print(\"%u young (%zuK), \", young_regions,\n-            (size_t) young_regions * G1HeapRegion::GrainBytes \/ K);\n-  uint survivor_regions = survivor_regions_count();\n-  st->print(\"%u survivors (%zuK)\", survivor_regions,\n-            (size_t) survivor_regions * G1HeapRegion::GrainBytes \/ K);\n-  st->cr();\n+  st->print(\"region size %zuM, \", G1HeapRegion::GrainBytes \/ M);\n+  print_region_type(st, \"eden\", eden_regions_count());\n+  print_region_type(st, \"survivor\", survivor_regions_count());\n+  print_region_type(st, \"old\", old_regions_count());\n+  print_region_type(st, \"humongous\", humongous_regions_count());\n+  print_region_type(st, \"free\", num_free_regions(), true \/* last *\/);\n+\n@@ -2263,1 +2522,2 @@\n-  update_parallel_gc_threads_cpu_time();\n+  update_perf_counter_cpu_time();\n+  _refinement_epoch++;\n@@ -2311,1 +2571,1 @@\n-  MutexLocker x(CGC_lock, Mutex::_no_safepoint_check_flag);\n+  MutexLocker x(G1CGC_lock, Mutex::_no_safepoint_check_flag);\n@@ -2319,1 +2579,1 @@\n-  CGC_lock->notify();\n+  G1CGC_lock->notify();\n@@ -2331,1 +2591,1 @@\n-void G1CollectedHeap::verify_region_attr_remset_is_tracked() {\n+void G1CollectedHeap::verify_region_attr_is_remset_tracked() {\n@@ -2336,4 +2596,6 @@\n-      bool const remset_is_tracked = g1h->region_attr(r->bottom()).remset_is_tracked();\n-      assert(r->rem_set()->is_tracked() == remset_is_tracked,\n-             \"Region %u remset tracking status (%s) different to region attribute (%s)\",\n-             r->hrm_index(), BOOL_TO_STR(r->rem_set()->is_tracked()), BOOL_TO_STR(remset_is_tracked));\n+      G1HeapRegionAttr attr = g1h->region_attr(r->bottom());\n+      bool const is_remset_tracked = attr.is_remset_tracked();\n+      assert((r->rem_set()->is_tracked() == is_remset_tracked) ||\n+             (attr.is_new_survivor() && is_remset_tracked),\n+             \"Region %u (%s) remset tracking status (%s) different to region attribute (%s)\",\n+             r->hrm_index(), r->get_type_str(), BOOL_TO_STR(r->rem_set()->is_tracked()), BOOL_TO_STR(is_remset_tracked));\n@@ -2347,1 +2609,1 @@\n-void G1CollectedHeap::update_parallel_gc_threads_cpu_time() {\n+void G1CollectedHeap::update_perf_counter_cpu_time() {\n@@ -2350,1 +2612,1 @@\n-  if (!UsePerfData || !os::is_thread_cpu_time_supported()) {\n+  if (!UsePerfData) {\n@@ -2368,1 +2630,1 @@\n-  collection_set()->start_incremental_building();\n+  collection_set()->start();\n@@ -2390,1 +2652,0 @@\n-  _verifier->verify_dirty_young_regions();\n@@ -2412,0 +2673,1 @@\n+  _verifier->verify_free_regions_card_tables_clean();\n@@ -2416,20 +2678,0 @@\n-void G1CollectedHeap::expand_heap_after_young_collection(){\n-  size_t expand_bytes = _heap_sizing_policy->young_collection_expansion_amount();\n-  if (expand_bytes > 0) {\n-    \/\/ No need for an ergo logging here,\n-    \/\/ expansion_amount() does this when it returns a value > 0.\n-    double expand_ms = 0.0;\n-    if (!expand(expand_bytes, _workers, &expand_ms)) {\n-      \/\/ We failed to expand the heap. Cannot do anything about it.\n-    }\n-    phase_times()->record_expand_heap_time(expand_ms);\n-  }\n-}\n-\n-void G1CollectedHeap::do_collection_pause_at_safepoint() {\n-  assert_at_safepoint_on_vm_thread();\n-  guarantee(!is_stw_gc_active(), \"collection is not reentrant\");\n-\n-  do_collection_pause_at_safepoint_helper();\n-}\n-\n@@ -2497,1 +2739,4 @@\n-void G1CollectedHeap::do_collection_pause_at_safepoint_helper() {\n+void G1CollectedHeap::do_collection_pause_at_safepoint(size_t allocation_word_size) {\n+  assert_at_safepoint_on_vm_thread();\n+  assert(!is_stw_gc_active(), \"collection is not reentrant\");\n+\n@@ -2515,1 +2760,1 @@\n-  G1YoungCollector collector(gc_cause());\n+  G1YoungCollector collector(gc_cause(), allocation_word_size);\n@@ -2534,2 +2779,1 @@\n-  uint num_workers = workers()->active_workers();\n-  G1ParallelCleaningTask unlink_task(num_workers, class_unloading_occurred);\n+  G1ParallelCleaningTask unlink_task(class_unloading_occurred);\n@@ -2637,0 +2881,7 @@\n+  uint total_allocated = _survivor_evac_stats.regions_filled() + _old_evac_stats.regions_filled();\n+\n+  log_debug(gc)(\"Allocated %u survivor %u old percent total %1.2f%% (%u%%)\",\n+                _survivor_evac_stats.regions_filled(), _old_evac_stats.regions_filled(),\n+                percent_of(total_allocated, num_committed_regions() - total_allocated),\n+                G1ReservePercent);\n+\n@@ -2662,0 +2913,5 @@\n+  if (VerifyDuringGC) {\n+    \/\/ Card and refinement table must be clear for freed regions.\n+    card_table()->verify_region(MemRegion(hr->bottom(), hr->end()), G1CardTable::clean_card_val(), true);\n+    refinement_table()->verify_region(MemRegion(hr->bottom(), hr->end()), G1CardTable::clean_card_val(), true);\n+  }\n@@ -2679,1 +2935,1 @@\n-    MutexLocker x(OldSets_lock, Mutex::_no_safepoint_check_flag);\n+    MutexLocker x(G1OldSets_lock, Mutex::_no_safepoint_check_flag);\n@@ -2689,1 +2945,1 @@\n-    MutexLocker x(FreeList_lock, Mutex::_no_safepoint_check_flag);\n+    MutexLocker x(G1FreeList_lock, Mutex::_no_safepoint_check_flag);\n@@ -2722,1 +2978,1 @@\n-void G1CollectedHeap::abandon_collection_set(G1CollectionSet* collection_set) {\n+void G1CollectedHeap::abandon_collection_set() {\n@@ -2726,2 +2982,1 @@\n-  collection_set->clear();\n-  collection_set->stop_incremental_building();\n+  collection_set()->abandon();\n@@ -2730,2 +2985,7 @@\n-bool G1CollectedHeap::is_old_gc_alloc_region(G1HeapRegion* hr) {\n-  return _allocator->is_retained_old_region(hr);\n+size_t G1CollectedHeap::non_young_occupancy_after_allocation(size_t allocation_word_size) {\n+  const size_t cur_occupancy = (old_regions_count() + humongous_regions_count()) * G1HeapRegion::GrainBytes -\n+                               _allocator->free_bytes_in_retained_old_region();\n+  \/\/ Humongous allocations will always be assigned to non-young heap, so consider\n+  \/\/ that allocation in the result as well. Otherwise the allocation will always\n+  \/\/ be in young gen, so there is no need to account it here.\n+  return cur_occupancy + (is_humongous(allocation_word_size) ? allocation_used_bytes(allocation_word_size) : 0);\n@@ -2734,4 +2994,2 @@\n-void G1CollectedHeap::set_region_short_lived_locked(G1HeapRegion* hr) {\n-  _eden.add(hr);\n-  _policy->set_region_eden(hr);\n-  young_regions_cset_group()->add(hr);\n+bool G1CollectedHeap::is_old_gc_alloc_region(G1HeapRegion* hr) {\n+  return _allocator->is_retained_old_region(hr);\n@@ -2885,1 +3143,1 @@\n-                                                false \/* do_expand *\/,\n+                                                policy()->should_expand_on_mutator_allocation() \/* do_expand *\/,\n@@ -2888,1 +3146,5 @@\n-      set_region_short_lived_locked(new_alloc_region);\n+      new_alloc_region->set_eden();\n+      _eden.add(new_alloc_region);\n+      _policy->set_region_eden(new_alloc_region);\n+\n+      collection_set()->add_eden_region(new_alloc_region);\n@@ -2890,1 +3152,0 @@\n-      _policy->remset_tracker()->update_at_allocate(new_alloc_region);\n@@ -2902,1 +3163,0 @@\n-  collection_set()->add_eden_region(alloc_region);\n@@ -2924,1 +3184,1 @@\n-  assert(FreeList_lock->owned_by_self(), \"pre-condition\");\n+  assert(G1FreeList_lock->owned_by_self(), \"pre-condition\");\n@@ -2946,0 +3206,6 @@\n+      \/\/ The remembered set\/group cardset for this region will be installed at the\n+      \/\/ end of GC. Cannot do that right now because we still need the current young\n+      \/\/ gen cardset group.\n+      \/\/ However, register with the attribute table to collect remembered set entries\n+      \/\/ immediately as it is the only source for determining the need for remembered\n+      \/\/ set tracking during GC.\n@@ -2947,2 +3213,0 @@\n-      \/\/ Install the group cardset.\n-      young_regions_cset_group()->add(new_alloc_region);\n@@ -2951,0 +3215,4 @@\n+      \/\/ Update remembered set\/cardset.\n+      _policy->remset_tracker()->update_at_allocate(new_alloc_region);\n+      \/\/ Synchronize with region attribute table.\n+      update_region_attr(new_alloc_region);\n@@ -2952,2 +3220,0 @@\n-    _policy->remset_tracker()->update_at_allocate(new_alloc_region);\n-    register_region_with_region_attr(new_alloc_region);\n@@ -3014,0 +3280,2 @@\n+  BarrierSetNMethod* bs_nm = BarrierSet::barrier_set()->barrier_set_nmethod();\n+  bs_nm->disarm(nm);\n@@ -3090,6 +3358,0 @@\n-\n-void G1CollectedHeap::prepare_group_cardsets_for_scan() {\n-  young_regions_cardset()->reset_table_scanner_for_groups();\n-\n-  collection_set()->prepare_groups_for_scan();\n-}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":528,"deletions":266,"binary":false,"changes":794,"status":"modified"},{"patch":"@@ -54,1 +54,0 @@\n-#include \"gc\/shared\/softRefPolicy.hpp\"\n@@ -80,0 +79,1 @@\n+class G1ReviseYoungLengthTask;\n@@ -173,0 +173,11 @@\n+  \/\/ GC Overhead Limit functionality related members.\n+  \/\/\n+  \/\/ The goal is to return null for allocations prematurely (before really going\n+  \/\/ OOME) in case both GC CPU usage (>= GCTimeLimit) and not much available free\n+  \/\/ memory (<= GCHeapFreeLimit) so that applications can exit gracefully or try\n+  \/\/ to keep running by easing off memory.\n+  uintx _gc_overhead_counter;        \/\/ The number of consecutive garbage collections we were over the limits.\n+\n+  void update_gc_overhead_counter();\n+  bool gc_overhead_limit_exceeded();\n+\n@@ -176,0 +187,1 @@\n+  G1ReviseYoungLengthTask* _revise_young_length_task;\n@@ -178,1 +190,14 @@\n-  G1CardTable* _card_table;\n+\n+  \/\/ The current epoch for refinement, i.e. the number of times the card tables\n+  \/\/ have been swapped by a garbage collection.\n+  \/\/ Used for detecting whether concurrent refinement has been interrupted by a\n+  \/\/ garbage collection.\n+  size_t _refinement_epoch;\n+\n+  \/\/ The following members are for tracking safepoint durations between garbage\n+  \/\/ collections.\n+  jlong _last_synchronized_start;\n+\n+  jlong _last_refinement_epoch_start;\n+  jlong _yield_duration_in_refinement_epoch;       \/\/ Time spent in safepoints since beginning of last refinement epoch.\n+  size_t _last_safepoint_refinement_epoch;         \/\/ Refinement epoch before last safepoint.\n@@ -266,1 +291,1 @@\n-  void update_parallel_gc_threads_cpu_time();\n+  void update_perf_counter_cpu_time();\n@@ -278,1 +303,10 @@\n-  \/\/ Attempt to start a concurrent cycle with the indicated cause.\n+  \/\/ Wait until a full mark (either currently in progress or one that completed\n+  \/\/ after the current request) has finished. Returns whether that full mark started\n+  \/\/ after this request. If so, we typically do not need another one.\n+  bool wait_full_mark_finished(GCCause::Cause cause,\n+                               uint old_marking_started_before,\n+                               uint old_marking_started_after,\n+                               uint old_marking_completed_after);\n+\n+  \/\/ Attempt to start a concurrent cycle with the indicated cause, for potentially\n+  \/\/ allocating allocation_word_size words.\n@@ -280,1 +314,2 @@\n-  bool try_collect_concurrently(GCCause::Cause cause,\n+  bool try_collect_concurrently(size_t allocation_word_size,\n+                                GCCause::Cause cause,\n@@ -421,7 +456,3 @@\n-  \/\/   this fails, they will attempt to do an evacuation pause and\n-  \/\/   retry the allocation.\n-  \/\/\n-  \/\/ * If all allocation attempts fail, even after trying to schedule\n-  \/\/   an evacuation pause, allocate_new_tlab() will return null,\n-  \/\/   whereas mem_allocate() will attempt a heap expansion and\/or\n-  \/\/   schedule a Full GC.\n+  \/\/   this fails, (only) mem_allocate() will attempt to do an evacuation\n+  \/\/   pause and retry the allocation. Allocate_new_tlab() will return null,\n+  \/\/   deferring to the following mem_allocate().\n@@ -432,1 +463,1 @@\n-  \/\/   will satisfy them with a special path.\n+  \/\/   will satisfy them in a special path.\n@@ -438,2 +469,1 @@\n-  HeapWord* mem_allocate(size_t word_size,\n-                         bool*  gc_overhead_limit_was_exceeded) override;\n+  HeapWord* mem_allocate(size_t word_size) override;\n@@ -446,2 +476,2 @@\n-                                      size_t* actual_word_size);\n-\n+                                      size_t* actual_word_size,\n+                                      bool allow_gc);\n@@ -450,2 +480,3 @@\n-  \/\/ pause. This should only be used for non-humongous allocations.\n-  HeapWord* attempt_allocation_slow(uint node_index, size_t word_size);\n+  \/\/ pause if allow_gc is set. This should only be used for non-humongous\n+  \/\/ allocations.\n+  HeapWord* attempt_allocation_slow(uint node_index, size_t word_size, bool allow_gc);\n@@ -477,0 +508,2 @@\n+  void resize_heap(size_t resize_bytes, bool should_expand);\n+\n@@ -485,3 +518,3 @@\n-  void do_full_collection(bool clear_all_soft_refs,\n-                          bool do_maximal_compaction,\n-                          size_t allocation_word_size);\n+  void do_full_collection(size_t allocation_word_size,\n+                          bool clear_all_soft_refs,\n+                          bool do_maximal_compaction);\n@@ -537,1 +570,1 @@\n-  \/\/ within a region to claim.\n+  \/\/ within a region to claim during card table scanning.\n@@ -542,1 +575,6 @@\n-  static uint get_chunks_per_region();\n+  static uint get_chunks_per_region_for_scan();\n+  \/\/ Return \"optimal\" number of chunks per region we want to use for claiming areas\n+  \/\/ within a region to claim during card table merging.\n+  \/\/ This is much smaller than for scanning as the merge work is much smaller.\n+  \/\/ Currently 1 for 1M regions, 2 for 2\/4M regions, 4 for 8\/16M regions and so on.\n+  static uint get_chunks_per_region_for_merge();\n@@ -562,1 +600,2 @@\n-  void resize_heap_if_necessary(size_t allocation_word_size);\n+  void resize_heap_after_young_collection(size_t allocation_word_size);\n+  void resize_heap_after_full_collection(size_t allocation_word_size);\n@@ -580,1 +619,1 @@\n-  bool expand(size_t expand_bytes, WorkerThreads* pretouch_workers = nullptr, double* expand_time_ms = nullptr);\n+  bool expand(size_t expand_bytes, WorkerThreads* pretouch_workers);\n@@ -616,5 +655,4 @@\n-  \/\/ We register a region with the fast \"in collection set\" test. We\n-  \/\/ simply set to true the array slot corresponding to this region.\n-  void register_young_region_with_region_attr(G1HeapRegion* r) {\n-    _region_attr.set_in_young(r->hrm_index(), r->has_pinned_objects());\n-  }\n+  \/\/ The following methods update the region attribute table, i.e. a compact\n+  \/\/ representation of per-region information that is regularly accessed\n+  \/\/ during GC.\n+  inline void register_young_region_with_region_attr(G1HeapRegion* r);\n@@ -622,2 +660,1 @@\n-  inline void register_region_with_region_attr(G1HeapRegion* r);\n-  inline void register_old_region_with_region_attr(G1HeapRegion* r);\n+  inline void register_old_collection_set_region_with_region_attr(G1HeapRegion* r);\n@@ -626,0 +663,3 @@\n+  \/\/ Updates region state without overwriting the type in the region attribute table.\n+  inline void update_region_attr(G1HeapRegion* r);\n+\n@@ -636,1 +676,1 @@\n-  void verify_region_attr_remset_is_tracked() PRODUCT_RETURN;\n+  void verify_region_attr_is_remset_tracked() PRODUCT_RETURN;\n@@ -686,5 +726,0 @@\n-  \/\/ It dirties the cards that cover the block so that the post\n-  \/\/ write barrier never queues anything when updating objects on this\n-  \/\/ block. It is assumed (and in fact we assert) that the block\n-  \/\/ belongs to a young region.\n-  inline void dirty_young_block(HeapWord* start, size_t word_size);\n@@ -742,3 +777,3 @@\n-  HeapWord* do_collection_pause(size_t         word_size,\n-                                uint           gc_count_before,\n-                                bool*          succeeded,\n+  HeapWord* do_collection_pause(size_t word_size,\n+                                uint gc_count_before,\n+                                bool* succeeded,\n@@ -747,2 +782,3 @@\n-  \/\/ Perform an incremental collection at a safepoint, possibly\n-  \/\/ followed by a by-policy upgrade to a full collection.\n+  \/\/ Perform an incremental collection at a safepoint, possibly followed by a\n+  \/\/ by-policy upgrade to a full collection.\n+  \/\/ The collection should expect to be followed by an allocation of allocation_word_size.\n@@ -751,5 +787,1 @@\n-  void do_collection_pause_at_safepoint();\n-\n-  \/\/ Helper for do_collection_pause_at_safepoint, containing the guts\n-  \/\/ of the incremental collection pause, executed by the vm thread.\n-  void do_collection_pause_at_safepoint_helper();\n+  void do_collection_pause_at_safepoint(size_t allocation_word_size);\n@@ -772,2 +804,0 @@\n-  void expand_heap_after_young_collection();\n-  \/\/ Update object copying statistics.\n@@ -791,5 +821,0 @@\n-  G1CardSet* young_regions_cardset() { return _young_regions_cset_group.card_set(); };\n-\n-  G1MonotonicArenaMemoryStats young_regions_card_set_memory_stats() { return _young_regions_cset_group.card_set_memory_stats(); }\n-\n-  void prepare_group_cardsets_for_scan();\n@@ -803,1 +828,1 @@\n-  void abandon_collection_set(G1CollectionSet* collection_set);\n+  void abandon_collection_set();\n@@ -890,0 +915,4 @@\n+\n+  void print_tracing_info() const override;\n+  void stop() override;\n+\n@@ -899,1 +928,0 @@\n-  void stop() override;\n@@ -903,0 +931,4 @@\n+  jlong last_refinement_epoch_start() const { return _last_refinement_epoch_start; }\n+  void set_last_refinement_epoch_start(jlong epoch_start, jlong last_yield_duration);\n+  jlong yield_duration_in_refinement_epoch();\n+\n@@ -977,1 +1009,1 @@\n-    return num_inactive_regions() == 0 && num_free_regions() == 0;\n+    return num_available_regions() == 0;\n@@ -996,1 +1028,1 @@\n-  uint num_available_regions() const { return _hrm.num_available_regions(); }\n+  uint num_available_regions() const { return num_free_regions() + num_inactive_regions(); }\n@@ -1002,1 +1034,0 @@\n-\n@@ -1012,3 +1043,4 @@\n-  size_t non_young_capacity_bytes() {\n-    return (old_regions_count() + humongous_regions_count()) * G1HeapRegion::GrainBytes;\n-  }\n+  \/\/ Returns how much memory there is assigned to non-young heap that can not be\n+  \/\/ allocated into any more without garbage collection after a hypothetical\n+  \/\/ allocation of allocation_word_size.\n+  size_t non_young_occupancy_after_allocation(size_t allocation_word_size);\n@@ -1020,3 +1052,0 @@\n-  \/\/ Perform a collection of the heap; intended for use in implementing\n-  \/\/ \"System.gc\".  This probably implies as full a collection as the\n-  \/\/ \"CollectedHeap\" supports.\n@@ -1025,1 +1054,2 @@\n-  \/\/ Perform a collection of the heap with the given cause.\n+  \/\/ Try to perform a collection of the heap with the given cause to allocate allocation_word_size\n+  \/\/ words.\n@@ -1027,1 +1057,1 @@\n-  bool try_collect(GCCause::Cause cause, const G1GCCounters& counters_before);\n+  bool try_collect(size_t allocation_word_size, GCCause::Cause cause, const G1GCCounters& counters_before);\n@@ -1031,0 +1061,2 @@\n+  bool last_gc_was_periodic() { return _gc_lastcause == GCCause::_g1_periodic_collection; }\n+\n@@ -1066,1 +1098,10 @@\n-    return _card_table;\n+    return static_cast<G1CardTable*>(G1BarrierSet::g1_barrier_set()->card_table());\n+  }\n+\n+  G1CardTable* refinement_table() const {\n+    return G1BarrierSet::g1_barrier_set()->refinement_table();\n+  }\n+\n+  G1CardTable::CardValue* card_table_base() const {\n+    assert(card_table() != nullptr, \"must be\");\n+    return card_table()->byte_map_base();\n@@ -1170,2 +1211,2 @@\n-  size_t tlab_capacity(Thread* ignored) const override;\n-  size_t tlab_used(Thread* ignored) const override;\n+  size_t tlab_capacity() const override;\n+  size_t tlab_used() const override;\n@@ -1173,1 +1214,1 @@\n-  size_t unsafe_max_tlab_alloc(Thread* ignored) const override;\n+  size_t unsafe_max_tlab_alloc() const override;\n@@ -1197,0 +1238,4 @@\n+  \/\/ Returns how much space in bytes an allocation of word_size will use up in the\n+  \/\/ heap.\n+  static size_t allocation_used_bytes(size_t word_size);\n+\n@@ -1199,0 +1244,1 @@\n+  size_t min_capacity() const;\n@@ -1208,1 +1254,0 @@\n-  void set_region_short_lived_locked(G1HeapRegion* hr);\n@@ -1213,0 +1258,1 @@\n+  inline uint eden_target_length() const;\n@@ -1318,3 +1364,0 @@\n-  \/\/ Override\n-  void print_tracing_info() const override;\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.hpp","additions":120,"deletions":77,"binary":false,"changes":197,"status":"modified"},{"patch":"@@ -37,1 +37,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -55,1 +55,1 @@\n-                FreeList_lock->owned_by_self(), \"master free list MT safety protocol at a safepoint\");\n+                G1FreeList_lock->owned_by_self(), \"master free list MT safety protocol at a safepoint\");\n@@ -66,1 +66,2 @@\n-  _cardtable_mapper(nullptr),\n+  _card_table_mapper(nullptr),\n+  _refinement_table_mapper(nullptr),\n@@ -79,1 +80,2 @@\n-                                     G1RegionToSpaceMapper* cardtable) {\n+                                     G1RegionToSpaceMapper* card_table,\n+                                     G1RegionToSpaceMapper* refinement_table) {\n@@ -87,1 +89,2 @@\n-  _cardtable_mapper = cardtable;\n+  _card_table_mapper = card_table;\n+  _refinement_table_mapper = refinement_table;\n@@ -203,1 +206,2 @@\n-  _cardtable_mapper->commit_regions(index, num_regions, pretouch_workers);\n+  _card_table_mapper->commit_regions(index, num_regions, pretouch_workers);\n+  _refinement_table_mapper->commit_regions(index, num_regions, pretouch_workers);\n@@ -226,1 +230,2 @@\n-  _cardtable_mapper->uncommit_regions(start, num_regions);\n+  _card_table_mapper->uncommit_regions(start, num_regions);\n+  _refinement_table_mapper->uncommit_regions(start, num_regions);\n@@ -278,1 +283,3 @@\n-  _cardtable_mapper->signal_mapping_changed(start, num_regions);\n+  _card_table_mapper->signal_mapping_changed(start, num_regions);\n+  \/\/ Signal refinement table to clear the given regions.\n+  _refinement_table_mapper->signal_mapping_changed(start, num_regions);\n@@ -285,1 +292,2 @@\n-    _cardtable_mapper->committed_size();\n+    _card_table_mapper->committed_size() +\n+    _refinement_table_mapper->committed_size();\n@@ -290,1 +298,2 @@\n-    _cardtable_mapper->reserved_size();\n+    _card_table_mapper->reserved_size() +\n+    _refinement_table_mapper->reserved_size();\n@@ -305,1 +314,1 @@\n-    MutexLocker uc(Uncommit_lock, Mutex::_no_safepoint_check_flag);\n+    MutexLocker uc(G1Uncommit_lock, Mutex::_no_safepoint_check_flag);\n@@ -394,1 +403,1 @@\n-      MutexLocker uc(Uncommit_lock, Mutex::_no_safepoint_check_flag);\n+      MutexLocker uc(G1Uncommit_lock, Mutex::_no_safepoint_check_flag);\n@@ -521,4 +530,0 @@\n-  \/\/ Check if we can actually satisfy the allocation.\n-  if (num_regions > num_available_regions()) {\n-    return G1_NO_HRM_INDEX;\n-  }\n@@ -776,1 +781,1 @@\n-  uint old_val = Atomic::cmpxchg(&_claims[region_index], Unclaimed, Claimed);\n+  uint old_val = AtomicAccess::cmpxchg(&_claims[region_index], Unclaimed, Claimed);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeapRegionManager.cpp","additions":22,"deletions":17,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -77,1 +77,2 @@\n-  G1RegionToSpaceMapper* _cardtable_mapper;\n+  G1RegionToSpaceMapper* _card_table_mapper;\n+  G1RegionToSpaceMapper* _refinement_table_mapper;\n@@ -165,1 +166,2 @@\n-                  G1RegionToSpaceMapper* cardtable);\n+                  G1RegionToSpaceMapper* card_table,\n+                  G1RegionToSpaceMapper* refinement_table);\n@@ -243,2 +245,0 @@\n-  uint num_available_regions() const { return num_free_regions() + num_inactive_regions(); }\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeapRegionManager.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"gc\/shared\/barrierSetNMethod.hpp\"\n@@ -51,0 +52,1 @@\n+#include \"runtime\/globals_extension.hpp\"\n@@ -52,0 +54,1 @@\n+#include \"runtime\/init.hpp\"\n@@ -58,3 +61,2 @@\n-PSYoungGen*  ParallelScavengeHeap::_young_gen = nullptr;\n-PSOldGen*    ParallelScavengeHeap::_old_gen = nullptr;\n-PSGCAdaptivePolicyCounters* ParallelScavengeHeap::_gc_policy_counters = nullptr;\n+GCPolicyCounters* ParallelScavengeHeap::_gc_policy_counters = nullptr;\n+size_t ParallelScavengeHeap::_desired_page_size = 0;\n@@ -66,1 +68,7 @@\n-  ReservedHeapSpace heap_rs = Universe::reserve_heap(reserved_heap_size, HeapAlignment);\n+  assert(_desired_page_size != 0, \"Should be initialized\");\n+  ReservedHeapSpace heap_rs = Universe::reserve_heap(reserved_heap_size, HeapAlignment, _desired_page_size);\n+  \/\/ Adjust SpaceAlignment based on actually used large page size.\n+  if (UseLargePages) {\n+    SpaceAlignment = MAX2(heap_rs.page_size(), default_space_alignment());\n+  }\n+  assert(is_aligned(SpaceAlignment, heap_rs.page_size()), \"inv\");\n@@ -72,2 +80,2 @@\n-  ReservedSpace old_rs   = heap_rs.first_part(MaxOldSize, GenAlignment);\n-  ReservedSpace young_rs = heap_rs.last_part(MaxOldSize, GenAlignment);\n+  ReservedSpace old_rs   = heap_rs.first_part(MaxOldSize, SpaceAlignment);\n+  ReservedSpace young_rs = heap_rs.last_part(MaxOldSize, SpaceAlignment);\n@@ -80,1 +88,0 @@\n-  barrier_set->initialize();\n@@ -103,11 +110,2 @@\n-  const size_t eden_capacity = _young_gen->eden_space()->capacity_in_bytes();\n-  const size_t old_capacity = _old_gen->capacity_in_bytes();\n-  const size_t initial_promo_size = MIN2(eden_capacity, old_capacity);\n-  _size_policy =\n-    new PSAdaptiveSizePolicy(eden_capacity,\n-                             initial_promo_size,\n-                             young_gen()->to_space()->capacity_in_bytes(),\n-                             GenAlignment,\n-                             max_gc_pause_sec,\n-                             GCTimeRatio\n-                             );\n+  _size_policy = new PSAdaptiveSizePolicy(SpaceAlignment,\n+                                          max_gc_pause_sec);\n@@ -119,2 +117,1 @@\n-  _gc_policy_counters =\n-    new PSGCAdaptivePolicyCounters(\"ParScav:MSC\", 2, 2, _size_policy);\n+  _gc_policy_counters = new GCPolicyCounters(\"ParScav:MSC\", 2, 2);\n@@ -138,4 +135,4 @@\n-  _eden_pool = new EdenMutableSpacePool(_young_gen,\n-                                        _young_gen->eden_space(),\n-                                        \"PS Eden Space\",\n-                                        false \/* support_usage_threshold *\/);\n+  _eden_pool = new PSEdenSpacePool(_young_gen,\n+                                   _young_gen->eden_space(),\n+                                   \"PS Eden Space\",\n+                                   false \/* support_usage_threshold *\/);\n@@ -143,3 +140,3 @@\n-  _survivor_pool = new SurvivorMutableSpacePool(_young_gen,\n-                                                \"PS Survivor Space\",\n-                                                false \/* support_usage_threshold *\/);\n+  _survivor_pool = new PSSurvivorSpacePool(_young_gen,\n+                                           \"PS Survivor Space\",\n+                                           false \/* support_usage_threshold *\/);\n@@ -147,3 +144,3 @@\n-  _old_pool = new PSGenerationPool(_old_gen,\n-                                   \"PS Old Gen\",\n-                                   true \/* support_usage_threshold *\/);\n+  _old_pool = new PSOldGenerationPool(_old_gen,\n+                                      \"PS Old Gen\",\n+                                      true \/* support_usage_threshold *\/);\n@@ -163,11 +160,0 @@\n-void ParallelScavengeHeap::safepoint_synchronize_begin() {\n-  if (UseStringDeduplication) {\n-    SuspendibleThreadSet::synchronize();\n-  }\n-}\n-\n-void ParallelScavengeHeap::safepoint_synchronize_end() {\n-  if (UseStringDeduplication) {\n-    SuspendibleThreadSet::desynchronize();\n-  }\n-}\n@@ -193,0 +179,15 @@\n+void ParallelScavengeHeap::gc_epilogue(bool full) {\n+  if (_is_heap_almost_full) {\n+    \/\/ Reset emergency state if eden is empty after a young\/full gc\n+    if (_young_gen->eden_space()->is_empty()) {\n+      log_debug(gc)(\"Leaving memory constrained state; back to normal\");\n+      _is_heap_almost_full = false;\n+    }\n+  } else {\n+    if (full && !_young_gen->eden_space()->is_empty()) {\n+      log_debug(gc)(\"Non-empty young-gen after full-gc; in memory constrained state\");\n+      _is_heap_almost_full = true;\n+    }\n+  }\n+}\n+\n@@ -262,2 +263,1 @@\n-HeapWord* ParallelScavengeHeap::mem_allocate(size_t size,\n-                                             bool* gc_overhead_limit_was_exceeded) {\n+HeapWord* ParallelScavengeHeap::mem_allocate(size_t size) {\n@@ -269,1 +269,1 @@\n-  return mem_allocate_work(size, is_tlab, gc_overhead_limit_was_exceeded);\n+  return mem_allocate_work(size, is_tlab);\n@@ -272,3 +272,6 @@\n-HeapWord* ParallelScavengeHeap::mem_allocate_work(size_t size,\n-                                                  bool is_tlab,\n-                                                  bool* gc_overhead_limit_was_exceeded) {\n+HeapWord* ParallelScavengeHeap::mem_allocate_cas_noexpand(size_t size, bool is_tlab) {\n+  \/\/ Try young-gen first.\n+  HeapWord* result = young_gen()->allocate(size);\n+  if (result != nullptr) {\n+    return result;\n+  }\n@@ -276,4 +279,9 @@\n-  \/\/ In general gc_overhead_limit_was_exceeded should be false so\n-  \/\/ set it so here and reset it to true only if the gc time\n-  \/\/ limit is being exceeded as checked below.\n-  *gc_overhead_limit_was_exceeded = false;\n+  \/\/ Try allocating from the old gen for non-TLAB and large allocations.\n+  if (!is_tlab) {\n+    if (!should_alloc_in_eden(size)) {\n+      result = old_gen()->cas_allocate_noexpand(size);\n+      if (result != nullptr) {\n+        return result;\n+      }\n+    }\n+  }\n@@ -281,1 +289,16 @@\n-  HeapWord* result = young_gen()->allocate(size);\n+  \/\/ In extreme cases, try allocating in from space also.\n+  if (_is_heap_almost_full) {\n+    result = young_gen()->from_space()->cas_allocate(size);\n+    if (result != nullptr) {\n+      return result;\n+    }\n+    if (!is_tlab) {\n+      result = old_gen()->cas_allocate_noexpand(size);\n+      if (result != nullptr) {\n+        return result;\n+      }\n+    }\n+  }\n+\n+  return nullptr;\n+}\n@@ -283,15 +306,14 @@\n-  uint loop_count = 0;\n-  uint gc_count = 0;\n-\n-  while (result == nullptr) {\n-    \/\/ We don't want to have multiple collections for a single filled generation.\n-    \/\/ To prevent this, each thread tracks the total_collections() value, and if\n-    \/\/ the count has changed, does not do a new collection.\n-    \/\/\n-    \/\/ The collection count must be read only while holding the heap lock. VM\n-    \/\/ operations also hold the heap lock during collections. There is a lock\n-    \/\/ contention case where thread A blocks waiting on the Heap_lock, while\n-    \/\/ thread B is holding it doing a collection. When thread A gets the lock,\n-    \/\/ the collection count has already changed. To prevent duplicate collections,\n-    \/\/ The policy MUST attempt allocations during the same period it reads the\n-    \/\/ total_collections() value!\n+HeapWord* ParallelScavengeHeap::mem_allocate_work(size_t size, bool is_tlab) {\n+  for (uint loop_count = 0; \/* empty *\/; ++loop_count) {\n+    HeapWord* result;\n+    {\n+      ConditionalMutexLocker locker(Heap_lock, !is_init_completed());\n+      result = mem_allocate_cas_noexpand(size, is_tlab);\n+      if (result != nullptr) {\n+        return result;\n+      }\n+    }\n+\n+    \/\/ Read total_collections() under the lock so that multiple\n+    \/\/ allocation-failures result in one GC.\n+    uint gc_count;\n@@ -300,2 +322,3 @@\n-      gc_count = total_collections();\n-      result = young_gen()->allocate(size);\n+      \/\/ Re-try after acquiring the lock, because a GC might have occurred\n+      \/\/ while waiting for this lock.\n+      result = mem_allocate_cas_noexpand(size, is_tlab);\n@@ -307,5 +330,10 @@\n-      \/\/ If certain conditions hold, try allocating from the old gen.\n-      if (!is_tlab) {\n-        result = mem_allocate_old_gen(size);\n-        if (result != nullptr) {\n-          return result;\n+      if (!is_init_completed()) {\n+        \/\/ Double checked locking, this ensure that is_init_completed() does not\n+        \/\/ transition while expanding the heap.\n+        MonitorLocker ml(InitCompleted_lock, Monitor::_no_safepoint_check_flag);\n+        if (!is_init_completed()) {\n+          \/\/ Can't do GC; try heap expansion to satisfy the request.\n+          result = expand_heap_and_allocate(size, is_tlab);\n+          if (result != nullptr) {\n+            return result;\n+          }\n@@ -314,0 +342,2 @@\n+\n+      gc_count = total_collections();\n@@ -316,1 +346,0 @@\n-    assert(result == nullptr, \"inv\");\n@@ -321,3 +350,0 @@\n-      \/\/ Did the VM operation execute? If so, return the result directly.\n-      \/\/ This prevents us from looping until time out on requests that can\n-      \/\/ not be satisfied.\n@@ -326,25 +352,0 @@\n-\n-        \/\/ Exit the loop if the gc time limit has been exceeded.\n-        \/\/ The allocation must have failed above (\"result\" guarding\n-        \/\/ this path is null) and the most recent collection has exceeded the\n-        \/\/ gc overhead limit (although enough may have been collected to\n-        \/\/ satisfy the allocation).  Exit the loop so that an out-of-memory\n-        \/\/ will be thrown (return a null ignoring the contents of\n-        \/\/ op.result()),\n-        \/\/ but clear gc_overhead_limit_exceeded so that the next collection\n-        \/\/ starts with a clean slate (i.e., forgets about previous overhead\n-        \/\/ excesses).  Fill op.result() with a filler object so that the\n-        \/\/ heap remains parsable.\n-        const bool limit_exceeded = size_policy()->gc_overhead_limit_exceeded();\n-        const bool softrefs_clear = soft_ref_policy()->all_soft_refs_clear();\n-\n-        if (limit_exceeded && softrefs_clear) {\n-          *gc_overhead_limit_was_exceeded = true;\n-          size_policy()->set_gc_overhead_limit_exceeded(false);\n-          log_trace(gc)(\"ParallelScavengeHeap::mem_allocate: return null because gc_overhead_limit_exceeded is set\");\n-          if (op.result() != nullptr) {\n-            CollectedHeap::fill_with_object(op.result(), size);\n-          }\n-          return nullptr;\n-        }\n-\n@@ -355,4 +356,7 @@\n-    \/\/ The policy object will prevent us from looping forever. If the\n-    \/\/ time spent in gc crosses a threshold, we will bail out.\n-    loop_count++;\n-    if ((result == nullptr) && (QueuedAllocationWarningCount > 0) &&\n+    \/\/ Was the gc-overhead reached inside the safepoint? If so, this mutator\n+    \/\/ should return null as well for global consistency.\n+    if (_gc_overhead_counter >= GCOverheadLimitThreshold) {\n+      return nullptr;\n+    }\n+\n+    if ((QueuedAllocationWarningCount > 0) &&\n@@ -360,2 +364,1 @@\n-      log_warning(gc)(\"ParallelScavengeHeap::mem_allocate retries %d times\", loop_count);\n-      log_warning(gc)(\"\\tsize=%zu\", size);\n+      log_warning(gc)(\"ParallelScavengeHeap::mem_allocate retries %d times, size=%zu\", loop_count, size);\n@@ -364,0 +367,1 @@\n+}\n@@ -365,1 +369,4 @@\n-  return result;\n+void ParallelScavengeHeap::do_full_collection(bool clear_all_soft_refs) {\n+  \/\/ No need for max-compaction in this context.\n+  const bool should_do_max_compaction = false;\n+  PSParallelCompact::invoke(clear_all_soft_refs, should_do_max_compaction);\n@@ -368,5 +375,7 @@\n-HeapWord* ParallelScavengeHeap::allocate_old_gen_and_record(size_t size) {\n-  assert_locked_or_safepoint(Heap_lock);\n-  HeapWord* res = old_gen()->allocate(size);\n-  if (res != nullptr) {\n-    _size_policy->tenured_allocation(size * HeapWordSize);\n+bool ParallelScavengeHeap::should_attempt_young_gc() const {\n+  const bool ShouldRunYoungGC = true;\n+  const bool ShouldRunFullGC = false;\n+\n+  if (!_young_gen->to_space()->is_empty()) {\n+    log_debug(gc, ergo)(\"To-space is not empty; run full-gc instead.\");\n+    return ShouldRunFullGC;\n@@ -374,6 +383,16 @@\n-  return res;\n-}\n-HeapWord* ParallelScavengeHeap::mem_allocate_old_gen(size_t size) {\n-  if (!should_alloc_in_eden(size)) {\n-    \/\/ Size is too big for eden.\n-    return allocate_old_gen_and_record(size);\n+  \/\/ Check if the predicted promoted bytes will overflow free space in old-gen.\n+  PSAdaptiveSizePolicy* policy = _size_policy;\n+\n+  size_t avg_promoted = (size_t) policy->padded_average_promoted_in_bytes();\n+  size_t promotion_estimate = MIN2(avg_promoted, _young_gen->used_in_bytes());\n+  \/\/ Total free size after possible old gen expansion\n+  size_t free_in_old_gen_with_expansion = _old_gen->max_gen_size() - _old_gen->used_in_bytes();\n+\n+  log_trace(gc, ergo)(\"average_promoted %zu; padded_average_promoted %zu\",\n+              (size_t) policy->average_promoted_in_bytes(),\n+              (size_t) policy->padded_average_promoted_in_bytes());\n+\n+  if (promotion_estimate >= free_in_old_gen_with_expansion) {\n+    log_debug(gc, ergo)(\"Run full-gc; predicted promotion size >= max free space in old-gen: %zu >= %zu\",\n+      promotion_estimate, free_in_old_gen_with_expansion);\n+    return ShouldRunFullGC;\n@@ -383,1 +402,20 @@\n-  return nullptr;\n+  if (UseAdaptiveSizePolicy) {\n+    \/\/ Also checking OS has enough free memory to commit and expand old-gen.\n+    \/\/ Otherwise, the recorded gc-pause-time might be inflated to include time\n+    \/\/ of OS preparing free memory, resulting in inaccurate young-gen resizing.\n+    assert(_old_gen->committed().byte_size() >= _old_gen->used_in_bytes(), \"inv\");\n+    \/\/ Use uint64_t instead of size_t for 32bit compatibility.\n+    uint64_t free_mem_in_os;\n+    if (os::free_memory(free_mem_in_os)) {\n+      size_t actual_free = (size_t)MIN2(_old_gen->committed().byte_size() - _old_gen->used_in_bytes() + free_mem_in_os,\n+                                        (uint64_t)SIZE_MAX);\n+      if (promotion_estimate > actual_free) {\n+        log_debug(gc, ergo)(\"Run full-gc; predicted promotion size > free space in old-gen and OS: %zu > %zu\",\n+          promotion_estimate, actual_free);\n+        return ShouldRunFullGC;\n+      }\n+    }\n+  }\n+\n+  \/\/ No particular reasons to run full-gc, so young-gc.\n+  return ShouldRunYoungGC;\n@@ -386,2 +424,30 @@\n-void ParallelScavengeHeap::do_full_collection(bool clear_all_soft_refs) {\n-  PSParallelCompact::invoke(clear_all_soft_refs);\n+static bool check_gc_heap_free_limit(size_t free_bytes, size_t capacity_bytes) {\n+  return (free_bytes * 100 \/ capacity_bytes) < GCHeapFreeLimit;\n+}\n+\n+bool ParallelScavengeHeap::check_gc_overhead_limit() {\n+  assert(SafepointSynchronize::is_at_safepoint(), \"precondition\");\n+\n+  if (UseGCOverheadLimit) {\n+    \/\/ The goal here is to return null prematurely so that apps can exit\n+    \/\/ gracefully when GC takes the most time.\n+    bool little_mutator_time = _size_policy->mutator_time_percent() * 100 < (100 - GCTimeLimit);\n+    bool little_free_space = check_gc_heap_free_limit(_young_gen->free_in_bytes(), _young_gen->capacity_in_bytes())\n+                          && check_gc_heap_free_limit(  _old_gen->free_in_bytes(),   _old_gen->capacity_in_bytes());\n+\n+    log_debug(gc)(\"GC Overhead Limit: GC Time %f Free Space Young %f Old %f Counter %zu\",\n+                  (100 - _size_policy->mutator_time_percent()),\n+                  percent_of(_young_gen->free_in_bytes(), _young_gen->capacity_in_bytes()),\n+                  percent_of(_old_gen->free_in_bytes(), _young_gen->capacity_in_bytes()),\n+                  _gc_overhead_counter);\n+\n+    if (little_mutator_time && little_free_space) {\n+      _gc_overhead_counter++;\n+      if (_gc_overhead_counter >= GCOverheadLimitThreshold) {\n+        return true;\n+      }\n+    } else {\n+      _gc_overhead_counter = 0;\n+    }\n+  }\n+  return false;\n@@ -391,1 +457,12 @@\n-  HeapWord* result = nullptr;\n+#ifdef ASSERT\n+  assert(Heap_lock->is_locked(), \"precondition\");\n+  if (is_init_completed()) {\n+    assert(SafepointSynchronize::is_at_safepoint(), \"precondition\");\n+    assert(Thread::current()->is_VM_thread(), \"precondition\");\n+  } else {\n+    assert(Thread::current()->is_Java_thread(), \"precondition\");\n+    assert(Heap_lock->owned_by_self(), \"precondition\");\n+  }\n+#endif\n+\n+  HeapWord* result = young_gen()->expand_and_allocate(size);\n@@ -393,1 +470,0 @@\n-  result = young_gen()->allocate(size);\n@@ -397,0 +473,1 @@\n+\n@@ -405,3 +482,3 @@\n-  \/\/ If young-gen can handle this allocation, attempt young-gc firstly.\n-  bool should_run_young_gc = is_tlab || should_alloc_in_eden(size);\n-  collect_at_safepoint(!should_run_young_gc);\n+  if (!_is_heap_almost_full) {\n+    \/\/ If young-gen can handle this allocation, attempt young-gc firstly, as young-gc is usually cheaper.\n+    bool should_run_young_gc = is_tlab || should_alloc_in_eden(size);\n@@ -409,3 +486,9 @@\n-  result = expand_heap_and_allocate(size, is_tlab);\n-  if (result != nullptr) {\n-    return result;\n+    collect_at_safepoint(!should_run_young_gc);\n+\n+    \/\/ If gc-overhead is reached, we will skip allocation.\n+    if (!check_gc_overhead_limit()) {\n+      result = expand_heap_and_allocate(size, is_tlab);\n+      if (result != nullptr) {\n+        return result;\n+      }\n+    }\n@@ -414,5 +497,1 @@\n-  \/\/ If we reach this point, we're really out of memory. Try every trick\n-  \/\/ we can to reclaim memory. Force collection of soft references. Force\n-  \/\/ a complete compaction of the heap. Any additional methods for finding\n-  \/\/ free memory should be here, especially if they are expensive. If this\n-  \/\/ attempt fails, an OOM exception will be thrown.\n+  \/\/ Last resort GC; clear soft refs and do max-compaction before throwing OOM.\n@@ -420,5 +499,3 @@\n-    \/\/ Make sure the heap is fully compacted\n-    uintx old_interval = HeapMaximumCompactionInterval;\n-    HeapMaximumCompactionInterval = 0;\n-\n-    PSParallelCompact::invoke(clear_all_soft_refs);\n+    const bool should_do_max_compaction = true;\n+    PSParallelCompact::invoke(clear_all_soft_refs, should_do_max_compaction);\n+  }\n@@ -427,2 +504,3 @@\n-    \/\/ Restore\n-    HeapMaximumCompactionInterval = old_interval;\n+  if (check_gc_overhead_limit()) {\n+    log_info(gc)(\"GC Overhead Limit exceeded too often (%zu).\", GCOverheadLimitThreshold);\n+    return nullptr;\n@@ -432,8 +510,1 @@\n-  if (result != nullptr) {\n-    return result;\n-  }\n-  \/\/ What else?  We might try synchronous finalization later.  If the total\n-  \/\/ space available is large enough for the allocation, then a more\n-  \/\/ complete compaction phase than we've tried so far might be\n-  \/\/ appropriate.\n-  return nullptr;\n+  return result;\n@@ -443,1 +514,0 @@\n-\n@@ -449,2 +519,2 @@\n-size_t ParallelScavengeHeap::tlab_capacity(Thread* thr) const {\n-  return young_gen()->eden_space()->tlab_capacity(thr);\n+size_t ParallelScavengeHeap::tlab_capacity() const {\n+  return young_gen()->eden_space()->tlab_capacity();\n@@ -453,2 +523,2 @@\n-size_t ParallelScavengeHeap::tlab_used(Thread* thr) const {\n-  return young_gen()->eden_space()->tlab_used(thr);\n+size_t ParallelScavengeHeap::tlab_used() const {\n+  return young_gen()->eden_space()->tlab_used();\n@@ -457,2 +527,2 @@\n-size_t ParallelScavengeHeap::unsafe_max_tlab_alloc(Thread* thr) const {\n-  return young_gen()->eden_space()->unsafe_max_tlab_alloc(thr);\n+size_t ParallelScavengeHeap::unsafe_max_tlab_alloc() const {\n+  return young_gen()->eden_space()->unsafe_max_tlab_alloc();\n@@ -462,3 +532,1 @@\n-  bool dummy;\n-                                       true \/* is_tlab *\/,\n-                                       &dummy);\n+                                       true \/* is_tlab *\/);\n@@ -502,6 +570,1 @@\n-bool ParallelScavengeHeap::must_clear_all_soft_refs() {\n-  return _gc_cause == GCCause::_metadata_GC_clear_soft_refs ||\n-         _gc_cause == GCCause::_wb_full_gc;\n-}\n-\n-void ParallelScavengeHeap::collect_at_safepoint(bool full) {\n+void ParallelScavengeHeap::collect_at_safepoint(bool is_full) {\n@@ -509,1 +572,1 @@\n-  bool clear_soft_refs = must_clear_all_soft_refs();\n+  bool clear_soft_refs = GCCause::should_clear_all_soft_refs(_gc_cause);\n@@ -511,3 +574,3 @@\n-  if (!full) {\n-    bool success = PSScavenge::invoke(clear_soft_refs);\n-    if (success) {\n+  if (!is_full && should_attempt_young_gc()) {\n+    bool young_gc_success = PSScavenge::invoke(clear_soft_refs);\n+    if (young_gc_success) {\n@@ -516,1 +579,1 @@\n-    \/\/ Upgrade to Full-GC if young-gc fails\n+    log_debug(gc, heap)(\"Upgrade to Full-GC since Young-gc failed.\");\n@@ -518,1 +581,3 @@\n-  PSParallelCompact::invoke(clear_soft_refs);\n+\n+  const bool should_do_max_compaction = false;\n+  PSParallelCompact::invoke(clear_soft_refs, should_do_max_compaction);\n@@ -544,1 +609,1 @@\n-    block_index = Atomic::fetch_then_add(&_claimed_index, 1u);\n+    block_index = AtomicAccess::fetch_then_add(&_claimed_index, 1u);\n@@ -669,1 +734,0 @@\n-  AdaptiveSizePolicyOutput::print();\n@@ -724,4 +788,2 @@\n-  \/\/ Why do we need the total_collections()-filter below?\n-  if (total_collections() > 0) {\n-    log_debug(gc, verify)(\"Tenured\");\n-    old_gen()->verify();\n+  log_debug(gc, verify)(\"Tenured\");\n+  old_gen()->verify();\n@@ -729,2 +791,2 @@\n-    log_debug(gc, verify)(\"Eden\");\n-    young_gen()->verify();\n+  log_debug(gc, verify)(\"Eden\");\n+  young_gen()->verify();\n@@ -732,3 +794,2 @@\n-    log_debug(gc, verify)(\"CardTable\");\n-    card_table()->verify_all_young_refs_imprecise();\n-  }\n+  log_debug(gc, verify)(\"CardTable\");\n+  card_table()->verify_all_young_refs_imprecise();\n@@ -766,4 +827,94 @@\n-void ParallelScavengeHeap::resize_young_gen(size_t eden_size,\n-                                            size_t survivor_size) {\n-  \/\/ Delegate the resize to the generation.\n-  _young_gen->resize(eden_size, survivor_size);\n+static size_t calculate_free_from_free_ratio_flag(size_t live, uintx free_percent) {\n+  assert(free_percent != 100, \"precondition\");\n+  \/\/ We want to calculate how much free memory there can be based on the\n+  \/\/ live size.\n+  \/\/   percent * (free + live) = free\n+  \/\/ =>\n+  \/\/   free = (live * percent) \/ (1 - percent)\n+\n+  const double percent = free_percent \/ 100.0;\n+  return live * percent \/ (1.0 - percent);\n+}\n+\n+size_t ParallelScavengeHeap::calculate_desired_old_gen_capacity(size_t old_gen_live_size) {\n+  \/\/ If min free percent is 100%, the old-gen should always be in its max capacity\n+  if (MinHeapFreeRatio == 100) {\n+    return _old_gen->max_gen_size();\n+  }\n+\n+  \/\/ Using recorded data to calculate the new capacity of old-gen to avoid\n+  \/\/ excessive expansion but also keep footprint low\n+\n+  size_t promoted_estimate = _size_policy->padded_average_promoted_in_bytes();\n+  \/\/ Should have at least this free room for the next young-gc promotion.\n+  size_t free_size = promoted_estimate;\n+\n+  size_t largest_live_size = MAX2((size_t)_size_policy->peak_old_gen_used_estimate(), old_gen_live_size);\n+  free_size += largest_live_size - old_gen_live_size;\n+\n+  \/\/ Respect free percent\n+  if (MinHeapFreeRatio != 0) {\n+    size_t min_free = calculate_free_from_free_ratio_flag(old_gen_live_size, MinHeapFreeRatio);\n+    free_size = MAX2(free_size, min_free);\n+  }\n+\n+  if (MaxHeapFreeRatio != 100) {\n+    size_t max_free = calculate_free_from_free_ratio_flag(old_gen_live_size, MaxHeapFreeRatio);\n+    free_size = MIN2(max_free, free_size);\n+  }\n+\n+  return old_gen_live_size + free_size;\n+}\n+\n+void ParallelScavengeHeap::resize_old_gen_after_full_gc() {\n+  size_t current_capacity = _old_gen->capacity_in_bytes();\n+  size_t desired_capacity = calculate_desired_old_gen_capacity(old_gen()->used_in_bytes());\n+\n+  \/\/ If MinHeapFreeRatio is at its default value; shrink cautiously. Otherwise, users expect prompt shrinking.\n+  if (FLAG_IS_DEFAULT(MinHeapFreeRatio)) {\n+    if (desired_capacity < current_capacity) {\n+      \/\/ Shrinking\n+      if (total_full_collections() < AdaptiveSizePolicyReadyThreshold) {\n+        \/\/ No enough data for shrinking\n+        return;\n+      }\n+    }\n+  }\n+\n+  _old_gen->resize(desired_capacity);\n+}\n+\n+void ParallelScavengeHeap::resize_after_young_gc(bool is_survivor_overflowing) {\n+  _young_gen->resize_after_young_gc(is_survivor_overflowing);\n+\n+  \/\/ Consider if should shrink old-gen\n+  if (!is_survivor_overflowing) {\n+    assert(old_gen()->capacity_in_bytes() >= old_gen()->min_gen_size(), \"inv\");\n+\n+    \/\/ Old gen min_gen_size constraint.\n+    const size_t max_shrink_bytes_gen_size_constraint = old_gen()->capacity_in_bytes() - old_gen()->min_gen_size();\n+\n+    \/\/ Per-step delta to avoid too aggressive shrinking.\n+    const size_t max_shrink_bytes_per_step_constraint = SpaceAlignment;\n+\n+    \/\/ Combining the above two constraints.\n+    const size_t max_shrink_bytes = MIN2(max_shrink_bytes_gen_size_constraint,\n+                                         max_shrink_bytes_per_step_constraint);\n+\n+    size_t shrink_bytes = _size_policy->compute_old_gen_shrink_bytes(old_gen()->free_in_bytes(), max_shrink_bytes);\n+\n+    assert(old_gen()->capacity_in_bytes() >= shrink_bytes, \"inv\");\n+    assert(old_gen()->capacity_in_bytes() - shrink_bytes >= old_gen()->min_gen_size(), \"inv\");\n+\n+    if (shrink_bytes != 0) {\n+      if (MinHeapFreeRatio != 0) {\n+        size_t new_capacity = old_gen()->capacity_in_bytes() - shrink_bytes;\n+        size_t new_free_size = old_gen()->free_in_bytes() - shrink_bytes;\n+        if ((double)new_free_size \/ new_capacity * 100 < MinHeapFreeRatio) {\n+          \/\/ Would violate MinHeapFreeRatio\n+          return;\n+        }\n+      }\n+      old_gen()->shrink(shrink_bytes);\n+    }\n+  }\n@@ -772,3 +923,15 @@\n-void ParallelScavengeHeap::resize_old_gen(size_t desired_free_space) {\n-  \/\/ Delegate the resize to the generation.\n-  _old_gen->resize(desired_free_space);\n+void ParallelScavengeHeap::resize_after_full_gc() {\n+  resize_old_gen_after_full_gc();\n+  \/\/ We don't resize young-gen after full-gc because:\n+  \/\/ 1. eden-size directly affects young-gc frequency (GCTimeRatio), and we\n+  \/\/ don't have enough info to determine its desired size.\n+  \/\/ 2. eden can contain live objs after a full-gc, which is unsafe for\n+  \/\/ resizing. We will perform expansion on allocation if needed, in\n+  \/\/ satisfy_failed_allocation().\n+\n+  if (should_cleanup_unused()) {\n+    os::cleanup_memory((char*)_young_gen->eden_space()->top(), _young_gen->eden_space()->free_in_bytes());\n+    os::cleanup_memory((char*)_young_gen->from_space()->top(), _young_gen->from_space()->free_in_bytes());\n+    os::cleanup_memory((char*)_young_gen->to_space()->top(), _young_gen->to_space()->free_in_bytes());\n+    os::cleanup_memory((char*)_old_gen->object_space()->top(), _old_gen->object_space()->free_in_bytes());\n+  }\n@@ -789,0 +952,2 @@\n+  BarrierSetNMethod* bs_nm = BarrierSet::barrier_set()->barrier_set_nmethod();\n+  bs_nm->disarm(nm);\n","filename":"src\/hotspot\/share\/gc\/parallel\/parallelScavengeHeap.cpp","additions":357,"deletions":192,"binary":false,"changes":549,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"code\/nmethod.hpp\"\n@@ -60,0 +61,1 @@\n+#include \"gc\/shared\/parallelCleaning.hpp\"\n@@ -65,1 +67,0 @@\n-#include \"gc\/shared\/strongRootsScope.hpp\"\n@@ -85,1 +86,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -301,23 +302,0 @@\n-void\n-ParallelCompactData::summarize_dense_prefix(HeapWord* beg, HeapWord* end)\n-{\n-  assert(is_region_aligned(beg), \"not RegionSize aligned\");\n-  assert(is_region_aligned(end), \"not RegionSize aligned\");\n-\n-  size_t cur_region = addr_to_region_idx(beg);\n-  const size_t end_region = addr_to_region_idx(end);\n-  HeapWord* addr = beg;\n-  while (cur_region < end_region) {\n-    _region_data[cur_region].set_destination(addr);\n-    _region_data[cur_region].set_destination_count(0);\n-    _region_data[cur_region].set_source_region(cur_region);\n-\n-    \/\/ Update live_obj_size so the region appears completely full.\n-    size_t live_size = RegionSize - _region_data[cur_region].partial_obj_size();\n-    _region_data[cur_region].set_live_obj_size(live_size);\n-\n-    ++cur_region;\n-    addr += RegionSize;\n-  }\n-}\n-\n@@ -663,1 +641,0 @@\n-  \/\/ Increment the invocation count\n@@ -690,0 +667,3 @@\n+  \/\/ Need to clear claim bits for the next full-gc (marking and adjust-pointers).\n+  ClassLoaderDataGraph::clear_claimed_marks();\n+\n@@ -736,10 +716,0 @@\n-  {\n-    \/\/ Delete metaspaces for unloaded class loaders and clean up loader_data graph\n-    GCTraceTime(Debug, gc, phases) t(\"Purge Class Loader Data\", gc_timer());\n-    ClassLoaderDataGraph::purge(true \/* at_safepoint *\/);\n-    DEBUG_ONLY(MetaspaceUtils::verify();)\n-  }\n-\n-  \/\/ Need to clear claim bits for the next mark.\n-  ClassLoaderDataGraph::clear_claimed_marks();\n-\n@@ -838,1 +808,2 @@\n-bool PSParallelCompact::check_maximum_compaction(size_t total_live_words,\n+bool PSParallelCompact::check_maximum_compaction(bool should_do_max_compaction,\n+                                                 size_t total_live_words,\n@@ -848,8 +819,2 @@\n-  \/\/ Check if all live objs are larger than old-gen.\n-  const bool is_old_gen_overflowing = (total_live_words > old_space->capacity_in_words());\n-\n-  \/\/ JVM flags\n-  const uint total_invocations = heap->total_full_collections();\n-  assert(total_invocations >= _maximum_compaction_gc_num, \"sanity\");\n-  const size_t gcs_since_max = total_invocations - _maximum_compaction_gc_num;\n-  const bool is_interval_ended = gcs_since_max > HeapMaximumCompactionInterval;\n+  \/\/ Check if all live objs are too much for old-gen.\n+  const bool is_old_gen_too_full = (total_live_words >= old_space->capacity_in_words());\n@@ -861,6 +826,4 @@\n-  if (is_max_on_system_gc || is_old_gen_overflowing || is_interval_ended || is_region_full) {\n-    _maximum_compaction_gc_num = total_invocations;\n-    return true;\n-  }\n-\n-  return false;\n+  return should_do_max_compaction\n+      || is_max_on_system_gc\n+      || is_old_gen_too_full\n+      || is_region_full;\n@@ -869,1 +832,1 @@\n-void PSParallelCompact::summary_phase()\n+void PSParallelCompact::summary_phase(bool should_do_max_compaction)\n@@ -892,4 +855,13 @@\n-    bool maximum_compaction = check_maximum_compaction(total_live_words,\n-                                                       old_space,\n-                                                       full_region_prefix_end);\n-    HeapWord* dense_prefix_end = maximum_compaction\n+    should_do_max_compaction = check_maximum_compaction(should_do_max_compaction,\n+                                                        total_live_words,\n+                                                        old_space,\n+                                                        full_region_prefix_end);\n+    {\n+      GCTraceTime(Info, gc, phases) tm(\"Summary Phase: expand\", &_gc_timer);\n+      \/\/ Try to expand old-gen in order to fit all live objs and waste.\n+      size_t target_capacity_bytes = total_live_words * HeapWordSize\n+                                   + old_space->capacity_in_bytes() * (MarkSweepDeadRatio \/ 100);\n+      ParallelScavengeHeap::heap()->old_gen()->try_expand_till_size(target_capacity_bytes);\n+    }\n+\n+    HeapWord* dense_prefix_end = should_do_max_compaction\n@@ -904,1 +876,0 @@\n-      _summary_data.summarize_dense_prefix(old_space->bottom(), dense_prefix_end);\n@@ -965,13 +936,1 @@\n-\/\/ This method should contain all heap-specific policy for invoking a full\n-\/\/ collection.  invoke_no_policy() will only attempt to compact the heap; it\n-\/\/ will do nothing further.  If we need to bail out for policy reasons, scavenge\n-\/\/ before full gc, or any other specialized behavior, it needs to be added here.\n-\/\/\n-\/\/ Note that this method should only be called from the vm_thread while at a\n-\/\/ safepoint.\n-\/\/\n-\/\/ Note that the all_soft_refs_clear flag in the soft ref policy\n-\/\/ may be true because this method can be called without intervening\n-\/\/ activity.  For example when the heap space is tight and full measure\n-\/\/ are being taken to free space.\n-bool PSParallelCompact::invoke(bool clear_all_soft_refs) {\n+bool PSParallelCompact::invoke(bool clear_all_soft_refs, bool should_do_max_compaction) {\n@@ -981,0 +940,1 @@\n+  assert(ref_processor() != nullptr, \"Sanity\");\n@@ -985,20 +945,0 @@\n-  ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();\n-  clear_all_soft_refs = clear_all_soft_refs\n-                     || heap->soft_ref_policy()->should_clear_all_soft_refs();\n-\n-  return PSParallelCompact::invoke_no_policy(clear_all_soft_refs);\n-}\n-\n-static void zero_cap(MutableSpace* ms) {\n-  os::cleanup_memory((char*)ms->top(), (char*)ms->end() - (char*)ms->top());\n-}\n-static void zero_all(MutableSpace* ms) {\n-  os::cleanup_memory((char*)ms->bottom(), (char*)ms->end() - (char*)ms->bottom());\n-}\n-\n-\/\/ This method contains no policy. You should probably\n-\/\/ be calling invoke() instead.\n-bool PSParallelCompact::invoke_no_policy(bool clear_all_soft_refs) {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"must be at a safepoint\");\n-  assert(ref_processor() != nullptr, \"Sanity\");\n-\n@@ -1012,1 +952,0 @@\n-  PSYoungGen* young_gen = heap->young_gen();\n@@ -1016,5 +955,0 @@\n-  \/\/ The scope of casr should end after code that can change\n-  \/\/ SoftRefPolicy::_should_clear_all_soft_refs.\n-  ClearedAllSoftRefs casr(clear_all_soft_refs,\n-                          heap->soft_ref_policy());\n-\n@@ -1055,4 +989,0 @@\n-    ClassUnloadingContext ctx(1 \/* num_nmethod_unlink_workers *\/,\n-                              false \/* unregister_nmethods_during_purge *\/,\n-                              false \/* lock_nmethod_free_separately *\/);\n-\n@@ -1061,1 +991,1 @@\n-    summary_phase();\n+    summary_phase(should_do_max_compaction);\n@@ -1082,66 +1012,1 @@\n-    \/\/ Let the size policy know we're done\n-    size_policy->major_collection_end(old_gen->used_in_bytes(), gc_cause);\n-\n-    if (UseAdaptiveSizePolicy) {\n-      log_debug(gc, ergo)(\"AdaptiveSizeStart: collection: %d \", heap->total_collections());\n-      log_trace(gc, ergo)(\"old_gen_capacity: %zu young_gen_capacity: %zu\",\n-                          old_gen->capacity_in_bytes(), young_gen->capacity_in_bytes());\n-\n-      \/\/ Don't check if the size_policy is ready here.  Let\n-      \/\/ the size_policy check that internally.\n-      if (UseAdaptiveGenerationSizePolicyAtMajorCollection &&\n-          AdaptiveSizePolicy::should_update_promo_stats(gc_cause)) {\n-        \/\/ Swap the survivor spaces if from_space is empty. The\n-        \/\/ resize_young_gen() called below is normally used after\n-        \/\/ a successful young GC and swapping of survivor spaces;\n-        \/\/ otherwise, it will fail to resize the young gen with\n-        \/\/ the current implementation.\n-        if (young_gen->from_space()->is_empty()) {\n-          young_gen->from_space()->clear(SpaceDecorator::Mangle);\n-          young_gen->swap_spaces();\n-        }\n-\n-        \/\/ Calculate optimal free space amounts\n-        assert(young_gen->max_gen_size() >\n-          young_gen->from_space()->capacity_in_bytes() +\n-          young_gen->to_space()->capacity_in_bytes(),\n-          \"Sizes of space in young gen are out-of-bounds\");\n-\n-        size_t young_live = young_gen->used_in_bytes();\n-        size_t eden_live = young_gen->eden_space()->used_in_bytes();\n-        size_t old_live = old_gen->used_in_bytes();\n-        size_t cur_eden = young_gen->eden_space()->capacity_in_bytes();\n-        size_t max_old_gen_size = old_gen->max_gen_size();\n-        size_t max_eden_size = young_gen->max_gen_size() -\n-          young_gen->from_space()->capacity_in_bytes() -\n-          young_gen->to_space()->capacity_in_bytes();\n-\n-        \/\/ Used for diagnostics\n-        size_policy->clear_generation_free_space_flags();\n-\n-        size_policy->compute_generations_free_space(young_live,\n-                                                    eden_live,\n-                                                    old_live,\n-                                                    cur_eden,\n-                                                    max_old_gen_size,\n-                                                    max_eden_size,\n-                                                    true \/* full gc*\/);\n-\n-        size_policy->check_gc_overhead_limit(eden_live,\n-                                             max_old_gen_size,\n-                                             max_eden_size,\n-                                             true \/* full gc*\/,\n-                                             gc_cause,\n-                                             heap->soft_ref_policy());\n-\n-        size_policy->decay_supplemental_growth(true \/* full gc*\/);\n-\n-        heap->resize_old_gen(\n-          size_policy->calculated_old_free_size_in_bytes());\n-\n-        heap->resize_young_gen(size_policy->calculated_eden_size_in_bytes(),\n-                               size_policy->calculated_survivor_size_in_bytes());\n-      }\n-\n-      log_debug(gc, ergo)(\"AdaptiveSizeStop: collection: %d \", heap->total_collections());\n-    }\n+    size_policy->major_collection_end();\n@@ -1149,6 +1014,1 @@\n-    if (heap->should_cleanup_unused()) {\n-      zero_cap(young_gen->eden_space());\n-      zero_cap(young_gen->from_space());\n-      zero_all(young_gen->to_space());\n-      zero_cap(old_gen->object_space());\n-    }\n+    size_policy->sample_old_gen_used_bytes(MAX2(pre_gc_values.old_gen_used(), old_gen->used_in_bytes()));\n@@ -1156,5 +1016,2 @@\n-    if (UsePerfData) {\n-      PSGCAdaptivePolicyCounters* const counters = heap->gc_policy_counters();\n-      counters->update_counters();\n-      counters->update_old_capacity(old_gen->capacity_in_bytes());\n-      counters->update_young_capacity(young_gen->capacity_in_bytes());\n+    if (UseAdaptiveSizePolicy) {\n+      heap->resize_after_full_gc();\n@@ -1179,0 +1036,2 @@\n+\n+    size_policy->record_gc_pause_end_instant();\n@@ -1181,0 +1040,2 @@\n+  heap->gc_epilogue(true);\n+\n@@ -1188,2 +1049,0 @@\n-  AdaptiveSizePolicyOutput::print(size_policy, heap->total_collections());\n-\n@@ -1199,2 +1058,1 @@\n-private:\n-  uint _worker_id;\n+  ParCompactionManager* _cm;\n@@ -1203,1 +1061,1 @@\n-  PCAddThreadRootsMarkingTaskClosure(uint worker_id) : _worker_id(worker_id) { }\n+  PCAddThreadRootsMarkingTaskClosure(ParCompactionManager* cm) : _cm(cm) { }\n@@ -1205,2 +1063,0 @@\n-    assert(ParallelScavengeHeap::heap()->is_stw_gc_active(), \"called outside gc\");\n-\n@@ -1209,5 +1065,1 @@\n-    ParCompactionManager* cm = ParCompactionManager::gc_thread_compaction_manager(_worker_id);\n-\n-    MarkingNMethodClosure mark_and_push_in_blobs(&cm->_mark_and_push_closure,\n-                                                 !NMethodToOopClosure::FixRelocations,\n-                                                 true \/* keepalive nmethods *\/);\n+    MarkingNMethodClosure mark_and_push_in_blobs(&_cm->_mark_and_push_closure);\n@@ -1215,1 +1067,1 @@\n-    thread->oops_do(&cm->_mark_and_push_closure, &mark_and_push_in_blobs);\n+    thread->oops_do(&_cm->_mark_and_push_closure, &mark_and_push_in_blobs);\n@@ -1218,1 +1070,1 @@\n-    cm->follow_marking_stacks();\n+    _cm->follow_marking_stacks();\n@@ -1238,1 +1090,2 @@\n-  StrongRootsScope _strong_roots_scope; \/\/ needed for Threads::possibly_parallel_threads_do\n+  NMethodMarkingScope _nmethod_marking_scope;\n+  ThreadsClaimTokenScope _threads_claim_token_scope;\n@@ -1246,1 +1099,2 @@\n-      _strong_roots_scope(active_workers),\n+      _nmethod_marking_scope(),\n+      _threads_claim_token_scope(),\n@@ -1262,1 +1116,1 @@\n-      PCAddThreadRootsMarkingTaskClosure closure(worker_id);\n+      PCAddThreadRootsMarkingTaskClosure closure(cm);\n@@ -1307,0 +1161,34 @@\n+class PSParallelCleaningTask : public WorkerTask {\n+  bool                    _unloading_occurred;\n+  CodeCacheUnloadingTask  _code_cache_task;\n+  \/\/ Prune dead klasses from subklass\/sibling\/implementor lists.\n+  KlassCleaningTask       _klass_cleaning_task;\n+\n+public:\n+  PSParallelCleaningTask(bool unloading_occurred) :\n+    WorkerTask(\"PS Parallel Cleaning\"),\n+    _unloading_occurred(unloading_occurred),\n+    _code_cache_task(unloading_occurred),\n+    _klass_cleaning_task() {}\n+\n+  void work(uint worker_id) {\n+#if INCLUDE_JVMCI\n+    if (EnableJVMCI && worker_id == 0) {\n+      \/\/ Serial work; only first worker.\n+      \/\/ Clean JVMCI metadata handles.\n+      JVMCI::do_unloading(_unloading_occurred);\n+    }\n+#endif\n+\n+    \/\/ Do first pass of code cache cleaning.\n+    _code_cache_task.work(worker_id);\n+\n+    \/\/ Clean all klasses that were not unloaded.\n+    \/\/ The weak metadata in klass doesn't need to be\n+    \/\/ processed if there was no unloading.\n+    if (_unloading_occurred) {\n+      _klass_cleaning_task.work();\n+    }\n+  }\n+};\n+\n@@ -1328,2 +1216,1 @@\n-    ref_processor()->set_active_mt_degree(active_gc_threads);\n-    stats = ref_processor()->process_discovered_references(task, pt);\n+    stats = ref_processor()->process_discovered_references(task, &ParallelScavengeHeap::heap()->workers(), pt);\n@@ -1356,1 +1243,3 @@\n-    ClassUnloadingContext* ctx = ClassUnloadingContext::context();\n+    ClassUnloadingContext ctx(active_gc_threads \/* num_nmethod_unlink_workers *\/,\n+                              false \/* unregister_nmethods_during_purge *\/,\n+                              false \/* lock_nmethod_free_separately *\/);\n@@ -1358,1 +1247,0 @@\n-    bool unloading_occurred;\n@@ -1363,1 +1251,1 @@\n-      unloading_occurred = SystemDictionary::do_unloading(&_gc_timer);\n+      bool unloading_occurred = SystemDictionary::do_unloading(&_gc_timer);\n@@ -1365,2 +1253,2 @@\n-      \/\/ Unload nmethods.\n-      CodeCache::do_unloading(unloading_occurred);\n+      PSParallelCleaningTask task{unloading_occurred};\n+      ParallelScavengeHeap::heap()->workers().run_task(&task);\n@@ -1372,1 +1260,1 @@\n-      ctx->purge_nmethods();\n+      ctx.purge_nmethods();\n@@ -1380,1 +1268,7 @@\n-      ctx->free_nmethods();\n+      ctx.free_nmethods();\n+    }\n+    {\n+      \/\/ Delete metaspaces for unloaded class loaders and clean up loader_data graph\n+      GCTraceTime(Debug, gc, phases) t(\"Purge Class Loader Data\", gc_timer());\n+      ClassLoaderDataGraph::purge(true \/* at_safepoint *\/);\n+      DEBUG_ONLY(MetaspaceUtils::verify();)\n@@ -1382,6 +1276,0 @@\n-\n-    \/\/ Prune dead klasses from subklass\/sibling\/implementor lists.\n-    Klass::clean_weak_klass_links(unloading_occurred);\n-\n-    \/\/ Clean JVMCI metadata handles.\n-    JVMCI_ONLY(JVMCI::do_unloading(unloading_occurred));\n@@ -1413,1 +1301,1 @@\n-    uint counter = Atomic::fetch_then_add(claim_counter, num_regions_per_stripe);\n+    uint counter = AtomicAccess::fetch_then_add(claim_counter, num_regions_per_stripe);\n@@ -1478,1 +1366,1 @@\n-  SubTasksDone                               _sub_tasks;\n+  ThreadsClaimTokenScope                     _threads_claim_token_scope;\n@@ -1482,0 +1370,1 @@\n+  volatile bool                              _code_cache_claimed;\n@@ -1484,5 +1373,4 @@\n-  enum PSAdjustSubTask {\n-    PSAdjustSubTask_code_cache,\n-\n-    PSAdjustSubTask_num_elements\n-  };\n+  bool try_claim_code_cache_task() {\n+    return AtomicAccess::load(&_code_cache_claimed) == false\n+        && AtomicAccess::cmpxchg(&_code_cache_claimed, false, true) == false;\n+  }\n@@ -1493,1 +1381,1 @@\n-    _sub_tasks(PSAdjustSubTask_num_elements),\n+    _threads_claim_token_scope(),\n@@ -1495,1 +1383,3 @@\n-    _nworkers(nworkers) {\n+    _oop_storage_iter(),\n+    _nworkers(nworkers),\n+    _code_cache_claimed(false) {\n@@ -1498,7 +1388,0 @@\n-    if (nworkers > 1) {\n-      Threads::change_thread_claim_token();\n-    }\n-  }\n-\n-  ~PSAdjustTask() {\n-    Threads::assert_all_threads_claimed();\n@@ -1508,3 +1391,4 @@\n-    ParCompactionManager* cm = ParCompactionManager::gc_thread_compaction_manager(worker_id);\n-    cm->preserved_marks()->adjust_during_full_gc();\n-      \/\/ adjust pointers in all spaces\n+      \/\/ Pointers in heap.\n+      ParCompactionManager* cm = ParCompactionManager::gc_thread_compaction_manager(worker_id);\n+      cm->preserved_marks()->adjust_during_full_gc();\n+\n@@ -1514,0 +1398,1 @@\n+\n@@ -1515,5 +1400,1 @@\n-      ResourceMark rm;\n-      Threads::possibly_parallel_oops_do(_nworkers > 1, &pc_adjust_pointer_closure, nullptr);\n-    }\n-    _oop_storage_iter.oops_do(&pc_adjust_pointer_closure);\n-    {\n+      \/\/ All (strong and weak) CLDs.\n@@ -1523,0 +1404,12 @@\n+\n+    {\n+      \/\/ Threads stack frames. No need to visit on-stack nmethods, because all\n+      \/\/ nmethods are visited in one go via CodeCache::nmethods_do.\n+      ResourceMark rm;\n+      Threads::possibly_parallel_oops_do(_nworkers > 1, &pc_adjust_pointer_closure, nullptr);\n+      if (try_claim_code_cache_task()) {\n+        NMethodToOopClosure adjust_code(&pc_adjust_pointer_closure, NMethodToOopClosure::FixRelocations);\n+        CodeCache::nmethods_do(&adjust_code);\n+      }\n+    }\n+\n@@ -1524,0 +1417,2 @@\n+      \/\/ VM internal strong and weak roots.\n+      _oop_storage_iter.oops_do(&pc_adjust_pointer_closure);\n@@ -1527,5 +1422,0 @@\n-    if (_sub_tasks.try_claim_task(PSAdjustSubTask_code_cache)) {\n-      NMethodToOopClosure adjust_code(&pc_adjust_pointer_closure, NMethodToOopClosure::FixRelocations);\n-      CodeCache::nmethods_do(&adjust_code);\n-    }\n-    _sub_tasks.all_tasks_claimed();\n@@ -1605,0 +1495,1 @@\n+          \/\/ Empty space\n@@ -1609,1 +1500,0 @@\n-\n@@ -1653,5 +1543,4 @@\n-  HeapWord* old_dense_prefix_addr = dense_prefix(SpaceId(old_space_id));\n-  RegionData* old_region = _summary_data.region(_summary_data.addr_to_region_idx(old_dense_prefix_addr));\n-  HeapWord* bump_ptr = old_region->partial_obj_size() != 0\n-                       ? old_dense_prefix_addr + old_region->partial_obj_size()\n-                       : old_dense_prefix_addr;\n+  HeapWord* const old_dense_prefix_addr = dense_prefix(SpaceId(old_space_id));\n+  \/\/ The destination addr for the first live obj after dense-prefix.\n+  HeapWord* bump_ptr = old_dense_prefix_addr\n+                     + _summary_data.addr_to_region_ptr(old_dense_prefix_addr)->partial_obj_size();\n@@ -1662,1 +1551,2 @@\n-    HeapWord* dense_prefix_addr = dense_prefix(SpaceId(id));\n+    \/\/ Only verify objs after dense-prefix, because those before dense-prefix are not moved (forwarded).\n+    HeapWord* cur_addr = dense_prefix(SpaceId(id));\n@@ -1664,1 +1554,0 @@\n-    HeapWord* cur_addr = dense_prefix_addr;\n@@ -1746,1 +1635,1 @@\n-  for (unsigned int id = to_space_id; id + 1 > old_space_id; --id) {\n+  for (unsigned int id = last_space_id - 1; id + 1 > old_space_id; --id) {\n@@ -1804,1 +1693,0 @@\n-  uint _num_workers;\n@@ -1810,1 +1698,0 @@\n-      _num_workers(active_workers),\n@@ -1815,1 +1702,1 @@\n-    {\n+    if (worker_id == 0) {\n@@ -1817,2 +1704,2 @@\n-      PSParallelCompact::fill_dead_objs_in_dense_prefix(worker_id, _num_workers);\n-      log_trace(gc, phases)(\"Fill dense prefix by worker %u: %.3f ms\", worker_id, (Ticks::now() - start).seconds() * 1000);\n+      PSParallelCompact::fill_dead_objs_in_dense_prefix();\n+      log_trace(gc, phases)(\"Fill dense prefix by worker 0: %.3f ms\", (Ticks::now() - start).seconds() * 1000);\n@@ -1831,0 +1718,1 @@\n+      \/\/ The preceding live obj.\n@@ -1832,2 +1720,2 @@\n-      HeapWord* after_obj = obj_start + cast_to_oop(obj_start)->size();\n-      assert(after_obj == start, \"precondition\");\n+      HeapWord* obj_end = obj_start + cast_to_oop(obj_start)->size();\n+      assert(obj_end == start, \"precondition\");\n@@ -1847,1 +1735,1 @@\n-void PSParallelCompact::fill_dead_objs_in_dense_prefix(uint worker_id, uint num_workers) {\n+void PSParallelCompact::fill_dead_objs_in_dense_prefix() {\n@@ -1853,12 +1741,1 @@\n-  if (bottom == prefix_end) {\n-    return;\n-  }\n-\n-  size_t bottom_region = _summary_data.addr_to_region_idx(bottom);\n-  size_t prefix_end_region = _summary_data.addr_to_region_idx(prefix_end);\n-\n-  size_t start_region;\n-  size_t end_region;\n-  split_regions_for_worker(bottom_region, prefix_end_region,\n-                           worker_id, num_workers,\n-                           &start_region, &end_region);\n+  const size_t region_size = ParallelCompactData::RegionSize;\n@@ -1866,3 +1743,3 @@\n-  if (start_region == end_region) {\n-    return;\n-  }\n+  \/\/ Fill dead space in [start_addr, end_addr)\n+  HeapWord* const start_addr = bottom;\n+  HeapWord* const end_addr   = prefix_end;\n@@ -1870,2 +1747,11 @@\n-  HeapWord* const start_addr = _summary_data.region_to_addr(start_region);\n-  HeapWord* const end_addr = _summary_data.region_to_addr(end_region);\n+  for (HeapWord* cur_addr = start_addr; cur_addr < end_addr; \/* empty *\/) {\n+    RegionData* cur_region_ptr = _summary_data.addr_to_region_ptr(cur_addr);\n+    if (cur_region_ptr->data_size() == region_size) {\n+      \/\/ Full; no dead space. Next region.\n+      if (_summary_data.is_region_aligned(cur_addr)) {\n+        cur_addr += region_size;\n+      } else {\n+        cur_addr = _summary_data.region_align_up(cur_addr);\n+      }\n+      continue;\n+    }\n@@ -1873,10 +1759,4 @@\n-  \/\/ Skip live partial obj (if any) from previous region.\n-  HeapWord* cur_addr;\n-  RegionData* start_region_ptr = _summary_data.region(start_region);\n-  if (start_region_ptr->partial_obj_size() != 0) {\n-    HeapWord* partial_obj_start = start_region_ptr->partial_obj_addr();\n-    assert(bitmap->is_marked(partial_obj_start), \"inv\");\n-    cur_addr = partial_obj_start + cast_to_oop(partial_obj_start)->size();\n-  } else {\n-    cur_addr = start_addr;\n-  }\n+    \/\/ Fill dead space inside cur_region.\n+    if (_summary_data.is_region_aligned(cur_addr)) {\n+      cur_addr += cur_region_ptr->partial_obj_size();\n+    }\n@@ -1884,7 +1764,7 @@\n-  \/\/ end_addr is inclusive to handle regions starting with dead space.\n-  while (cur_addr <= end_addr) {\n-    \/\/ Use prefix_end to handle trailing obj in each worker region-chunk.\n-    HeapWord* live_start = bitmap->find_obj_beg(cur_addr, prefix_end);\n-    if (cur_addr != live_start) {\n-      \/\/ Only worker 0 handles proceeding dead space.\n-      if (cur_addr != start_addr || worker_id == 0) {\n+    HeapWord* region_end_addr = _summary_data.region_align_up(cur_addr + 1);\n+    assert(region_end_addr <= end_addr, \"inv\");\n+    while (cur_addr < region_end_addr) {\n+      \/\/ Use end_addr to allow filler-obj to cross region boundary.\n+      HeapWord* live_start = bitmap->find_obj_beg(cur_addr, end_addr);\n+      if (cur_addr != live_start) {\n+        \/\/ Found dead space [cur_addr, live_start).\n@@ -1893,0 +1773,6 @@\n+      if (live_start >= region_end_addr) {\n+        cur_addr = live_start;\n+        break;\n+      }\n+      assert(bitmap->is_marked(live_start), \"inv\");\n+      cur_addr = live_start + cast_to_oop(live_start)->size();\n@@ -1894,5 +1780,0 @@\n-    if (live_start >= end_addr) {\n-      break;\n-    }\n-    assert(bitmap->is_marked(live_start), \"inv\");\n-    cur_addr = live_start + cast_to_oop(live_start)->size();\n@@ -1931,7 +1812,31 @@\n-  HeapWord* cur_addr = bottom;\n-  while (cur_addr < dense_prefix_end) {\n-    oop obj = cast_to_oop(cur_addr);\n-    oopDesc::verify(obj);\n-    if (!mark_bitmap()->is_marked(cur_addr)) {\n-      Klass* k = cast_to_oop(cur_addr)->klass();\n-      assert(k == Universe::fillerArrayKlass() || k == vmClasses::FillerObject_klass(), \"inv\");\n+\n+  const size_t region_size = ParallelCompactData::RegionSize;\n+\n+  for (HeapWord* cur_addr = bottom; cur_addr < dense_prefix_end; \/* empty *\/) {\n+    RegionData* cur_region_ptr = _summary_data.addr_to_region_ptr(cur_addr);\n+    if (cur_region_ptr->data_size() == region_size) {\n+      \/\/ Full; no dead space. Next region.\n+      if (_summary_data.is_region_aligned(cur_addr)) {\n+        cur_addr += region_size;\n+      } else {\n+        cur_addr = _summary_data.region_align_up(cur_addr);\n+      }\n+      continue;\n+    }\n+\n+    \/\/ This region contains filler objs.\n+    if (_summary_data.is_region_aligned(cur_addr)) {\n+      cur_addr += cur_region_ptr->partial_obj_size();\n+    }\n+\n+    HeapWord* region_end_addr = _summary_data.region_align_up(cur_addr + 1);\n+    assert(region_end_addr <= dense_prefix_end, \"inv\");\n+\n+    while (cur_addr < region_end_addr) {\n+      oop obj = cast_to_oop(cur_addr);\n+      oopDesc::verify(obj);\n+      if (!mark_bitmap()->is_marked(cur_addr)) {\n+        Klass* k = cast_to_oop(cur_addr)->klass();\n+        assert(k == Universe::fillerArrayKlass() || k == vmClasses::FillerObject_klass(), \"inv\");\n+      }\n+      cur_addr += obj->size();\n@@ -1939,1 +1844,0 @@\n-    cur_addr += obj->size();\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":207,"deletions":303,"binary":false,"changes":510,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"classfile\/classLoaderDataGraph.hpp\"\n@@ -42,0 +43,1 @@\n+#include \"gc\/shared\/oopStorageSet.inline.hpp\"\n@@ -44,0 +46,1 @@\n+#include \"gc\/shared\/scavengableNMethods.hpp\"\n@@ -46,1 +49,0 @@\n-#include \"gc\/shared\/strongRootsScope.hpp\"\n@@ -95,1 +97,6 @@\n-    ClassLoaderData* _scanned_cld;\n+  public:\n+    \/\/ Records whether this CLD contains oops pointing into young-gen after scavenging.\n+    bool _has_oops_into_young_gen;\n+\n+    CLDOopClosure(DefNewGeneration* g) : OffHeapScanClosure(g),\n+      _has_oops_into_young_gen(false) {}\n@@ -97,2 +104,1 @@\n-    template <typename T>\n-    void do_oop_work(T* p) {\n+    void do_oop(oop* p) {\n@@ -102,3 +108,2 @@\n-        assert(_scanned_cld != nullptr, \"inv\");\n-        if (is_in_young_gen(new_obj) && !_scanned_cld->has_modified_oops()) {\n-          _scanned_cld->record_modified_oops();\n+        if (!_has_oops_into_young_gen && is_in_young_gen(new_obj)) {\n+          _has_oops_into_young_gen = true;\n@@ -109,10 +114,0 @@\n-  public:\n-    CLDOopClosure(DefNewGeneration* g) : OffHeapScanClosure(g),\n-      _scanned_cld(nullptr) {}\n-\n-    void set_scanned_cld(ClassLoaderData* cld) {\n-      assert(cld == nullptr || _scanned_cld == nullptr, \"Must be\");\n-      _scanned_cld = cld;\n-    }\n-\n-    void do_oop(oop* p)       { do_oop_work(p); }\n@@ -122,1 +117,1 @@\n-  CLDOopClosure _oop_closure;\n+  DefNewGeneration* _g;\n@@ -124,1 +119,1 @@\n-  CLDScanClosure(DefNewGeneration* g) : _oop_closure(g) {}\n+  CLDScanClosure(DefNewGeneration* g) : _g(g) {}\n@@ -129,1 +124,3 @@\n-    if (cld->has_modified_oops()) {\n+    if (!cld->has_modified_oops()) {\n+      return;\n+    }\n@@ -131,3 +128,1 @@\n-      \/\/ Tell the closure which CLD is being scanned so that it can be dirtied\n-      \/\/ if oops are left pointing into the young gen.\n-      _oop_closure.set_scanned_cld(cld);\n+    CLDOopClosure oop_closure{_g};\n@@ -135,2 +130,2 @@\n-      \/\/ Clean the cld since we're going to scavenge all the metadata.\n-      cld->oops_do(&_oop_closure, ClassLoaderData::_claim_none, \/*clear_modified_oops*\/true);\n+    \/\/ Clean the cld since we're going to scavenge all the metadata.\n+    cld->oops_do(&oop_closure, ClassLoaderData::_claim_none, \/*clear_modified_oops*\/true);\n@@ -138,1 +133,2 @@\n-      _oop_closure.set_scanned_cld(nullptr);\n+    if (oop_closure._has_oops_into_young_gen) {\n+      cld->record_modified_oops();\n@@ -233,6 +229,0 @@\n-  MemRegion cmr((HeapWord*)_virtual_space.low(),\n-                (HeapWord*)_virtual_space.high());\n-  SerialHeap* gch = SerialHeap::heap();\n-\n-  gch->rem_set()->resize_covered_region(cmr);\n-\n@@ -243,0 +233,2 @@\n+  init_spaces();\n+\n@@ -248,1 +240,4 @@\n-  _max_eden_size = size - (2*_max_survivor_size);\n+\n+  \/\/ Eden might grow to be almost as large as the entire young generation.\n+  \/\/ We approximate this as the entire virtual space.\n+  _max_eden_size = size;\n@@ -264,1 +259,0 @@\n-  compute_space_boundaries(0, SpaceDecorator::Clear, SpaceDecorator::Mangle);\n@@ -268,1 +262,0 @@\n-  _pretenure_size_threshold_words = PretenureSizeThreshold >> LogHeapWordSize;\n@@ -277,9 +270,4 @@\n-void DefNewGeneration::compute_space_boundaries(uintx minimum_eden_size,\n-                                                bool clear_space,\n-                                                bool mangle_space) {\n-  \/\/ If the spaces are being cleared (only done at heap initialization\n-  \/\/ currently), the survivor spaces need not be empty.\n-  \/\/ Otherwise, no care is taken for used areas in the survivor spaces\n-  \/\/ so check.\n-  assert(clear_space || (to()->is_empty() && from()->is_empty()),\n-    \"Initialization of the survivor spaces assumes these are empty\");\n+void DefNewGeneration::init_spaces() {\n+  \/\/ Using layout: from, to, eden, so only from can be non-empty.\n+  assert(eden()->is_empty(), \"precondition\");\n+  assert(to()->is_empty(), \"precondition\");\n@@ -287,11 +275,2 @@\n-  \/\/ Compute sizes\n-  uintx size = _virtual_space.committed_size();\n-  uintx survivor_size = compute_survivor_size(size, SpaceAlignment);\n-  uintx eden_size = size - (2*survivor_size);\n-  if (eden_size > max_eden_size()) {\n-    \/\/ Need to reduce eden_size to satisfy the max constraint. The delta needs\n-    \/\/ to be 2*SpaceAlignment aligned so that both survivors are properly\n-    \/\/ aligned.\n-    uintx eden_delta = align_up(eden_size - max_eden_size(), 2*SpaceAlignment);\n-    eden_size     -= eden_delta;\n-    survivor_size += eden_delta\/2;\n+  if (!from()->is_empty()) {\n+    assert((char*) from()->bottom() == _virtual_space.low(), \"inv\");\n@@ -299,12 +278,7 @@\n-  assert(eden_size > 0 && survivor_size <= eden_size, \"just checking\");\n-  if (eden_size < minimum_eden_size) {\n-    \/\/ May happen due to 64Kb rounding, if so adjust eden size back up\n-    minimum_eden_size = align_up(minimum_eden_size, SpaceAlignment);\n-    uintx maximum_survivor_size = (size - minimum_eden_size) \/ 2;\n-    uintx unaligned_survivor_size =\n-      align_down(maximum_survivor_size, SpaceAlignment);\n-    survivor_size = MAX2(unaligned_survivor_size, SpaceAlignment);\n-    eden_size = size - (2*survivor_size);\n-    assert(eden_size > 0 && survivor_size <= eden_size, \"just checking\");\n-    assert(eden_size >= minimum_eden_size, \"just checking\");\n-  }\n+  \/\/ Compute sizes\n+  size_t size = _virtual_space.committed_size();\n+  size_t survivor_size = compute_survivor_size(size, SpaceAlignment);\n+  assert(survivor_size >= from()->used(), \"inv\");\n+  assert(size > 2 * survivor_size, \"inv\");\n+  size_t eden_size = size - (2 * survivor_size);\n+  assert(eden_size > 0 && survivor_size <= eden_size, \"just checking\");\n@@ -313,4 +287,5 @@\n-  char *eden_start = _virtual_space.low();\n-  char *from_start = eden_start + eden_size;\n-  char *to_start   = from_start + survivor_size;\n-  char *to_end     = to_start   + survivor_size;\n+  \/\/ layout: from, to, eden\n+  char* from_start = _virtual_space.low();\n+  char* to_start = from_start + survivor_size;\n+  char* eden_start = to_start + survivor_size;\n+  char* eden_end = eden_start + eden_size;\n@@ -318,2 +293,1 @@\n-  assert(to_end == _virtual_space.high(), \"just checking\");\n-  assert(is_aligned(eden_start, SpaceAlignment), \"checking alignment\");\n+  assert(eden_end == _virtual_space.high(), \"just checking\");\n@@ -322,0 +296,2 @@\n+  assert(is_aligned(eden_start, SpaceAlignment), \"checking alignment\");\n+  assert(is_aligned(eden_end, SpaceAlignment), \"checking alignment\");\n@@ -323,7 +299,2 @@\n-  MemRegion edenMR((HeapWord*)eden_start, (HeapWord*)from_start);\n-  MemRegion toMR  ((HeapWord*)to_start, (HeapWord*)to_end);\n-\n-  \/\/ A minimum eden size implies that there is a part of eden that\n-  \/\/ is being used and that affects the initialization of any\n-  \/\/ newly formed eden.\n-  bool live_in_eden = minimum_eden_size > 0;\n+  MemRegion toMR  ((HeapWord*)to_start, (HeapWord*)eden_start);\n+  MemRegion edenMR((HeapWord*)eden_start, (HeapWord*)eden_end);\n@@ -333,12 +304,11 @@\n-  eden()->initialize(edenMR,\n-                     clear_space && !live_in_eden,\n-                     SpaceDecorator::Mangle);\n-  \/\/ If clear_space and live_in_eden, we will not have cleared any\n-  \/\/ portion of eden above its top. This can cause newly\n-  \/\/ expanded space not to be mangled if using ZapUnusedHeapArea.\n-  \/\/ We explicitly do such mangling here.\n-  if (ZapUnusedHeapArea && clear_space && live_in_eden && mangle_space) {\n-    eden()->mangle_unused_area();\n-  }\n-  from()->initialize(fromMR, clear_space, mangle_space);\n-  to()->initialize(toMR, clear_space, mangle_space);\n+  from()->initialize(fromMR, from()->is_empty());\n+  to()->initialize(toMR, true);\n+  eden()->initialize(edenMR, true);\n+\n+  post_resize();\n+}\n+\n+void DefNewGeneration::post_resize() {\n+  MemRegion cmr((HeapWord*)_virtual_space.low(),\n+                (HeapWord*)_virtual_space.high());\n+  SerialHeap::heap()->rem_set()->resize_covered_region(cmr);\n@@ -360,1 +330,3 @@\n-  HeapWord* prev_high = (HeapWord*) _virtual_space.high();\n+  assert(bytes != 0, \"precondition\");\n+  assert(is_aligned(bytes, SpaceAlignment), \"precondition\");\n+\n@@ -362,7 +334,2 @@\n-  if (success && ZapUnusedHeapArea) {\n-    \/\/ Mangle newly committed space immediately because it\n-    \/\/ can be done here more simply that after the new\n-    \/\/ spaces have been computed.\n-    HeapWord* new_high = (HeapWord*) _virtual_space.high();\n-    MemRegion mangle_region(prev_high, new_high);\n-    SpaceMangler::mangle_region(mangle_region);\n+  if (!success) {\n+    log_info(gc)(\"Failed to expand young-gen by %zu bytes\", bytes);\n@@ -374,0 +341,11 @@\n+void DefNewGeneration::expand_eden_by(size_t delta_bytes) {\n+  if (!expand(delta_bytes)) {\n+    return;\n+  }\n+\n+  MemRegion eden_mr{eden()->bottom(), (HeapWord*)_virtual_space.high()};\n+  eden()->initialize(eden_mr, eden()->is_empty());\n+\n+  post_resize();\n+}\n+\n@@ -406,18 +384,2 @@\n-void DefNewGeneration::compute_new_size() {\n-  if (Universe::heap()->should_cleanup_unused()) {\n-    os::cleanup_memory((char*)eden()->top(), (char*)eden()->end() - (char*)eden()->top());\n-    os::cleanup_memory((char*)from()->top(), (char*)from()->end() - (char*)from()->top());\n-    os::cleanup_memory((char*)to()->top(), (char*)to()->end() - (char*)to()->top());\n-  }\n-\n-  \/\/ This is called after a GC that includes the old generation, so from-space\n-  \/\/ will normally be empty.\n-  \/\/ Note that we check both spaces, since if scavenge failed they revert roles.\n-  \/\/ If not we bail out (otherwise we would have to relocate the objects).\n-  if (!from()->is_empty() || !to()->is_empty()) {\n-    return;\n-  }\n-\n-  SerialHeap* gch = SerialHeap::heap();\n-\n-  size_t old_size = gch->old_gen()->capacity();\n+size_t DefNewGeneration::calculate_desired_young_gen_bytes() const {\n+  size_t old_size = SerialHeap::heap()->old_gen()->capacity();\n@@ -444,8 +406,32 @@\n-  assert(desired_new_size <= max_new_size, \"just checking\");\n-\n-  bool changed = false;\n-  if (desired_new_size > new_size_before) {\n-    size_t change = desired_new_size - new_size_before;\n-    assert(change % alignment == 0, \"just checking\");\n-    if (expand(change)) {\n-       changed = true;\n+  if (!from()->is_empty()) {\n+    \/\/ Mininum constraint to hold all live objs inside from-space.\n+    size_t min_survivor_size = align_up(from()->used(), alignment);\n+\n+    \/\/ SurvivorRatio := eden_size \/ survivor_size\n+    \/\/ young-gen-size = eden_size                     + 2 * survivor_size\n+    \/\/                = SurvivorRatio * survivor_size + 2 * survivor_size\n+    \/\/                = (SurvivorRatio + 2) * survivor_size\n+    size_t min_young_gen_size = min_survivor_size * (SurvivorRatio + 2);\n+\n+    desired_new_size = MAX2(min_young_gen_size, desired_new_size);\n+  }\n+  assert(is_aligned(desired_new_size, alignment), \"postcondition\");\n+\n+  return desired_new_size;\n+}\n+\n+void DefNewGeneration::resize_inner() {\n+  assert(eden()->is_empty(), \"precondition\");\n+  assert(to()->is_empty(), \"precondition\");\n+\n+  size_t current_young_gen_size_bytes = _virtual_space.committed_size();\n+  size_t desired_young_gen_size_bytes = calculate_desired_young_gen_bytes();\n+  if (current_young_gen_size_bytes == desired_young_gen_size_bytes) {\n+    return;\n+  }\n+\n+  \/\/ Commit\/uncommit\n+  if (desired_young_gen_size_bytes > current_young_gen_size_bytes) {\n+    size_t delta_bytes = desired_young_gen_size_bytes - current_young_gen_size_bytes;\n+    if (!expand(delta_bytes)) {\n+      return;\n@@ -453,31 +439,49 @@\n-    \/\/ If the heap failed to expand to the desired size,\n-    \/\/ \"changed\" will be false.  If the expansion failed\n-    \/\/ (and at this point it was expected to succeed),\n-    \/\/ ignore the failure (leaving \"changed\" as false).\n-  }\n-  if (desired_new_size < new_size_before && eden()->is_empty()) {\n-    \/\/ bail out of shrinking if objects in eden\n-    size_t change = new_size_before - desired_new_size;\n-    assert(change % alignment == 0, \"just checking\");\n-    _virtual_space.shrink_by(change);\n-    changed = true;\n-  }\n-  if (changed) {\n-    \/\/ The spaces have already been mangled at this point but\n-    \/\/ may not have been cleared (set top = bottom) and should be.\n-    \/\/ Mangling was done when the heap was being expanded.\n-    compute_space_boundaries(eden()->used(),\n-                             SpaceDecorator::Clear,\n-                             SpaceDecorator::DontMangle);\n-    MemRegion cmr((HeapWord*)_virtual_space.low(),\n-                  (HeapWord*)_virtual_space.high());\n-    gch->rem_set()->resize_covered_region(cmr);\n-\n-    log_debug(gc, ergo, heap)(\n-        \"New generation size %zuK->%zuK [eden=%zuK,survivor=%zuK]\",\n-        new_size_before\/K, _virtual_space.committed_size()\/K,\n-        eden()->capacity()\/K, from()->capacity()\/K);\n-    log_trace(gc, ergo, heap)(\n-        \"  [allowed %zuK extra for %d threads]\",\n-          thread_increase_size\/K, threads_count);\n-      }\n+  } else {\n+    size_t delta_bytes = current_young_gen_size_bytes - desired_young_gen_size_bytes;\n+    _virtual_space.shrink_by(delta_bytes);\n+  }\n+\n+  assert(desired_young_gen_size_bytes == _virtual_space.committed_size(), \"inv\");\n+\n+  init_spaces();\n+\n+  log_debug(gc, ergo, heap)(\"New generation size %zuK->%zuK [eden=%zuK,survivor=%zuK]\",\n+    current_young_gen_size_bytes\/K, _virtual_space.committed_size()\/K,\n+    eden()->capacity()\/K, from()->capacity()\/K);\n+}\n+\n+void DefNewGeneration::resize_after_young_gc() {\n+  \/\/ Called only after successful young-gc.\n+  assert(eden()->is_empty(), \"precondition\");\n+  assert(to()->is_empty(), \"precondition\");\n+\n+  if ((char*)to()->bottom() == _virtual_space.low()) {\n+    \/\/ layout: to, from, eden; can't resize.\n+    return;\n+  }\n+\n+  assert((char*)from()->bottom() == _virtual_space.low(), \"inv\");\n+  resize_inner();\n+}\n+\n+void DefNewGeneration::resize_after_full_gc() {\n+  if (Universe::heap()->should_cleanup_unused()) {\n+    os::cleanup_memory((char*)eden()->top(), eden()->free());\n+    os::cleanup_memory((char*)from()->top(), from()->free());\n+    os::cleanup_memory((char*)to()->top(), to()->free());\n+  }\n+\n+  if (eden()->is_empty() && from()->is_empty() && to()->is_empty()) {\n+    resize_inner();\n+    return;\n+  }\n+\n+  \/\/ Usually the young-gen is empty after full-gc.\n+  \/\/ This is the extreme case; expand young-gen to its max size.\n+  if (_virtual_space.uncommitted_size() == 0) {\n+    \/\/ Already at its max size.\n+    return;\n+  }\n+\n+  \/\/ Keep from\/to and expand eden.\n+  expand_eden_by(_virtual_space.uncommitted_size());\n@@ -498,1 +502,0 @@\n-\n@@ -504,1 +507,0 @@\n-\n@@ -512,1 +514,2 @@\n-  return reserved_bytes - compute_survivor_size(reserved_bytes, SpaceAlignment);\n+  const size_t min_survivor_bytes = SpaceAlignment;\n+  return reserved_bytes - min_survivor_bytes;\n@@ -604,1 +607,0 @@\n-  to()->clear(SpaceDecorator::Mangle);\n@@ -614,3 +616,2 @@\n-    StrongRootsScope srs(0);\n-    RootScanClosure root_cl{this};\n-    CLDScanClosure cld_cl{this};\n+    RootScanClosure oop_closure{this};\n+    CLDScanClosure cld_closure{this};\n@@ -618,3 +619,2 @@\n-    MarkingNMethodClosure code_cl(&root_cl,\n-                                  NMethodToOopClosure::FixRelocations,\n-                                  false \/* keepalive_nmethods *\/);\n+    NMethodToOopClosure nmethod_closure(&oop_closure,\n+                                        NMethodToOopClosure::FixRelocations);\n@@ -622,6 +622,5 @@\n-    HeapWord* saved_top_in_old_gen = _old_gen->space()->top();\n-    heap->process_roots(SerialHeap::SO_ScavengeCodeCache,\n-                        &root_cl,\n-                        &cld_cl,\n-                        &cld_cl,\n-                        &code_cl);\n+    \/\/ Starting tracing from roots, there are 4 kinds of roots in young-gc.\n+    \/\/\n+    \/\/ 1. old-to-young pointers; processing them before relocating other kinds\n+    \/\/ of roots.\n+    _old_gen->scan_old_to_young_refs();\n@@ -629,1 +628,12 @@\n-    _old_gen->scan_old_to_young_refs(saved_top_in_old_gen);\n+    \/\/ 2. CLD; visit all (strong+weak) clds with the same closure, because we\n+    \/\/ don't perform class unloading during young-gc.\n+    ClassLoaderDataGraph::cld_do(&cld_closure);\n+\n+    \/\/ 3. Threads stack frames and nmethods.\n+    \/\/ Only nmethods that contain pointers into-young need to be processed\n+    \/\/ during young-gc, and they are tracked in ScavengableNMethods\n+    Threads::oops_do(&oop_closure, nullptr);\n+    ScavengableNMethods::nmethods_do(&nmethod_closure);\n+\n+    \/\/ 4. VM internal roots.\n+    OopStorageSet::strong_oops_do(&oop_closure);\n@@ -641,1 +651,1 @@\n-    const ReferenceProcessorStats& stats = rp->process_discovered_references(task, pt);\n+    const ReferenceProcessorStats& stats = rp->process_discovered_references(task, nullptr, pt);\n@@ -813,1 +823,1 @@\n-void DefNewGeneration::gc_epilogue(bool full) {\n+void DefNewGeneration::gc_epilogue() {\n@@ -824,1 +834,1 @@\n-    _gen_counters->update_all(_virtual_space.committed_size());\n+    _gen_counters->update_capacity(_virtual_space.committed_size());\n@@ -846,7 +856,11 @@\n-HeapWord* DefNewGeneration::allocate(size_t word_size) {\n-  \/\/ This is the slow-path allocation for the DefNewGeneration.\n-  \/\/ Most allocations are fast-path in compiled code.\n-  \/\/ We try to allocate from the eden.  If that works, we are happy.\n-  \/\/ Note that since DefNewGeneration supports lock-free allocation, we\n-  \/\/ have to use it here, as well.\n-  HeapWord* result = eden()->par_allocate(word_size);\n+HeapWord* DefNewGeneration::expand_and_allocate(size_t word_size) {\n+  assert(Heap_lock->is_locked(), \"precondition\");\n+\n+  size_t eden_free_bytes = eden()->free();\n+  size_t requested_bytes = word_size * HeapWordSize;\n+  if (eden_free_bytes < requested_bytes) {\n+    size_t expand_bytes = requested_bytes - eden_free_bytes;\n+    expand_eden_by(align_up(expand_bytes, SpaceAlignment));\n+  }\n+\n+  HeapWord* result = eden()->allocate(word_size);\n","filename":"src\/hotspot\/share\/gc\/serial\/defNewGeneration.cpp","additions":198,"deletions":184,"binary":false,"changes":382,"status":"modified"},{"patch":"@@ -30,1 +30,0 @@\n-#include \"gc\/shared\/collectedHeap.hpp\"\n@@ -41,0 +40,1 @@\n+#include \"gc\/shared\/stringdedup\/stringDedupProcessor.hpp\"\n@@ -65,0 +65,2 @@\n+bool CollectedHeap::_is_shutting_down = false;\n+\n@@ -70,1 +72,1 @@\n-class GCLogMessage : public FormatBuffer<512> {};\n+class GCLogMessage : public FormatBuffer<1024> {};\n@@ -279,1 +281,0 @@\n-  _soft_ref_policy(),\n@@ -285,0 +286,1 @@\n+  _vmthread_cpu_time(0),\n@@ -381,2 +383,1 @@\n-                                       full_gc_count,\n-                                       GCCause::_metadata_GC_threshold);\n+                                       full_gc_count);\n@@ -389,0 +390,1 @@\n+\n@@ -447,6 +449,0 @@\n-void CollectedHeap::fill_args_check(HeapWord* start, size_t words)\n-{\n-  assert(words >= min_fill_size(), \"too small to fill\");\n-  assert(is_object_aligned(words), \"unaligned size\");\n-}\n-\n@@ -498,1 +494,2 @@\n-  DEBUG_ONLY(fill_args_check(start, words);)\n+  assert(words >= min_fill_size(), \"too small to fill\");\n+  assert(is_object_aligned(words), \"unaligned size\");\n@@ -505,1 +502,2 @@\n-  DEBUG_ONLY(fill_args_check(start, words);)\n+  assert(words >= min_fill_size(), \"too small to fill\");\n+  assert(is_object_aligned(words), \"unaligned size\");\n@@ -607,0 +605,20 @@\n+bool CollectedHeap::is_shutting_down() {\n+  assert(Heap_lock->owned_by_self(), \"Protected by this lock\");\n+  return _is_shutting_down;\n+}\n+\n+void CollectedHeap::initiate_shutdown() {\n+  {\n+    \/\/ Acquire the Heap_lock to synchronize with VM_Heap_Sync_Operations,\n+    \/\/ which may depend on the value of _is_shutting_down flag.\n+    MutexLocker hl(Heap_lock);\n+    _is_shutting_down = true;\n+  }\n+\n+  print_tracing_info();\n+}\n+\n+size_t CollectedHeap::bootstrap_max_memory() const {\n+  return MaxNewSize;\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.cpp","additions":31,"deletions":13,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -30,1 +30,0 @@\n-#include \"gc\/shared\/softRefPolicy.hpp\"\n@@ -39,0 +38,1 @@\n+#include \"services\/cpuTimeUsage.hpp\"\n@@ -92,0 +92,1 @@\n+  friend class CPUTimeUsage::GC;\n@@ -98,0 +99,2 @@\n+  static bool _is_shutting_down;\n+\n@@ -105,2 +108,0 @@\n-  SoftRefPolicy _soft_ref_policy;\n-\n@@ -137,0 +138,2 @@\n+  jlong _vmthread_cpu_time;\n+\n@@ -163,2 +166,1 @@\n-  virtual HeapWord* mem_allocate(size_t size,\n-                                 bool* gc_overhead_limit_was_exceeded) = 0;\n+  virtual HeapWord* mem_allocate(size_t size) = 0;\n@@ -173,1 +175,0 @@\n-  DEBUG_ONLY(static void fill_args_check(HeapWord* start, size_t words);)\n@@ -211,0 +212,4 @@\n+  \/\/ Print any relevant tracing info that flags imply.\n+  \/\/ Default implementation does nothing.\n+  virtual void print_tracing_info() const = 0;\n+\n@@ -212,0 +217,2 @@\n+  \/\/ Stop any onging concurrent work and prepare for exit.\n+  virtual void stop() = 0;\n@@ -244,2 +251,3 @@\n-  \/\/ Stop any onging concurrent work and prepare for exit.\n-  virtual void stop() {}\n+  static bool is_shutting_down();\n+\n+  void initiate_shutdown();\n@@ -251,0 +259,2 @@\n+  void add_vmthread_cpu_time(jlong time);\n+\n@@ -300,3 +310,0 @@\n-  static void fill_with_object(MemRegion region, bool zap = true) {\n-    fill_with_object(region.start(), region.word_size(), zap);\n-  }\n@@ -335,1 +342,1 @@\n-  virtual size_t tlab_capacity(Thread *thr) const = 0;\n+  virtual size_t tlab_capacity() const = 0;\n@@ -337,2 +344,2 @@\n-  \/\/ The amount of used space for thread-local allocation buffers for the given thread.\n-  virtual size_t tlab_used(Thread *thr) const = 0;\n+  \/\/ The amount of space used for thread-local allocation buffers.\n+  virtual size_t tlab_used() const = 0;\n@@ -345,1 +352,1 @@\n-  virtual size_t unsafe_max_tlab_alloc(Thread *thr) const = 0;\n+  virtual size_t unsafe_max_tlab_alloc() const = 0;\n@@ -347,3 +354,1 @@\n-  \/\/ Perform a collection of the heap; intended for use in implementing\n-  \/\/ \"System.gc\".  This probably implies as full a collection as the\n-  \/\/ \"CollectedHeap\" supports.\n+  \/\/ Perform a collection of the heap of a type depending on the given cause.\n@@ -392,3 +397,0 @@\n-  \/\/ Return the SoftRefPolicy for the heap;\n-  SoftRefPolicy* soft_ref_policy() { return &_soft_ref_policy; }\n-\n@@ -459,4 +461,0 @@\n-  \/\/ Print any relevant tracing info that flags imply.\n-  \/\/ Default implementation does nothing.\n-  virtual void print_tracing_info() const = 0;\n-\n@@ -504,0 +502,1 @@\n+  virtual size_t bootstrap_max_memory() const;\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":24,"deletions":25,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -65,18 +65,0 @@\n-size_t GCArguments::compute_heap_alignment() {\n-  \/\/ The card marking array and the offset arrays for old generations are\n-  \/\/ committed in os pages as well. Make sure they are entirely full (to\n-  \/\/ avoid partial page problems), e.g. if 512 bytes heap corresponds to 1\n-  \/\/ byte entry and the os page size is 4096, the maximum heap size should\n-  \/\/ be 512*4096 = 2MB aligned.\n-\n-  size_t alignment = CardTable::ct_max_alignment_constraint();\n-\n-  if (UseLargePages) {\n-      \/\/ In presence of large pages we have to make sure that our\n-      \/\/ alignment is large page aware.\n-      alignment = lcm(os::large_page_size(), alignment);\n-  }\n-\n-  return alignment;\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/shared\/gcArguments.cpp","additions":0,"deletions":18,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -31,1 +31,0 @@\n-#include \"gc\/z\/zAllocator.inline.hpp\"\n@@ -44,0 +43,2 @@\n+#include \"gc\/z\/zObjectAllocator.hpp\"\n+#include \"gc\/z\/zPageAge.inline.hpp\"\n@@ -58,1 +59,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -113,0 +114,10 @@\n+class ZRendezvousHandshakeClosure : public HandshakeClosure {\n+public:\n+  ZRendezvousHandshakeClosure()\n+    : HandshakeClosure(\"ZRendezvous\") {}\n+\n+  void do_thread(Thread* thread) {\n+    \/\/ Does nothing\n+  }\n+};\n+\n@@ -170,5 +181,14 @@\n-  if (is_young()) {\n-    _relocate.flip_age_pages(selector->not_selected_small());\n-    _relocate.flip_age_pages(selector->not_selected_medium());\n-    _relocate.flip_age_pages(selector->not_selected_large());\n-  }\n+  _relocate.flip_age_pages(selector->not_selected_small());\n+  _relocate.flip_age_pages(selector->not_selected_medium());\n+  _relocate.flip_age_pages(selector->not_selected_large());\n+\n+  \/\/ Perform a handshake between flip promotion and running the promotion barrier. This ensures\n+  \/\/ that ZBarrierSet::on_slowpath_allocation_exit() observing a young page that was then racingly\n+  \/\/ flip promoted, will run any stores without barriers to completion before responding to the\n+  \/\/ handshake at the subsequent safepoint poll. This ensures that the flip promotion barriers always\n+  \/\/ run after compiled code missing barriers, but before relocate start.\n+  ZRendezvousHandshakeClosure cl;\n+  Handshake::execute(&cl);\n+\n+  _relocate.barrier_promoted_pages(_relocation_set.flip_promoted_pages(),\n+                                   _relocation_set.relocate_promoted_pages());\n@@ -237,1 +257,3 @@\n-  flip_age_pages(&selector);\n+  if (is_young()) {\n+    flip_age_pages(&selector);\n+  }\n@@ -289,1 +311,1 @@\n-  Atomic::add(&_freed, size, memory_order_relaxed);\n+  AtomicAccess::add(&_freed, size, memory_order_relaxed);\n@@ -297,1 +319,1 @@\n-  Atomic::add(&_promoted, size, memory_order_relaxed);\n+  AtomicAccess::add(&_promoted, size, memory_order_relaxed);\n@@ -305,1 +327,1 @@\n-  Atomic::add(&_compacted, size, memory_order_relaxed);\n+  AtomicAccess::add(&_compacted, size, memory_order_relaxed);\n@@ -444,0 +466,4 @@\n+  virtual bool is_gc_operation() const {\n+    return true;\n+  }\n+\n@@ -659,1 +685,0 @@\n-\n@@ -700,3 +725,1 @@\n-  size_t last_populated_live = 0;\n-  for (uint i = 0; i <= ZPageAgeMax; ++i) {\n-    const ZPageAge age = static_cast<ZPageAge>(i);\n+  for (ZPageAge age : ZPageAgeRangeAll) {\n@@ -706,2 +729,1 @@\n-      last_populated_age = i;\n-      last_populated_live = young_live;\n+      last_populated_age = untype(age);\n@@ -721,1 +743,0 @@\n-  const size_t young_used_at_mark_start = ZGeneration::young()->stat_heap()->used_generation_at_mark_start();\n@@ -844,4 +865,1 @@\n-  ZAllocator::eden()->retire_pages();\n-  for (ZPageAge i = ZPageAge::survivor1; i <= ZPageAge::survivor14; i = static_cast<ZPageAge>(static_cast<uint>(i) + 1)) {\n-    ZAllocator::relocation(i)->retire_pages();\n-  }\n+  ZHeap::heap()->retire_allocating_pages(ZPageAgeRangeYoung);\n@@ -1208,1 +1226,1 @@\n-  ZAllocator::old()->retire_pages();\n+  ZHeap::heap()->retire_allocating_pages(ZPageAgeRangeOld);\n@@ -1290,10 +1308,0 @@\n-class ZRendezvousHandshakeClosure : public HandshakeClosure {\n-public:\n-  ZRendezvousHandshakeClosure()\n-    : HandshakeClosure(\"ZRendezvous\") {}\n-\n-  void do_thread(Thread* thread) {\n-    \/\/ Does nothing\n-  }\n-};\n-\n@@ -1315,0 +1323,4 @@\n+  virtual bool is_gc_operation() const {\n+    return true;\n+  }\n+\n@@ -1322,1 +1334,0 @@\n-\n","filename":"src\/hotspot\/share\/gc\/z\/zGeneration.cpp","additions":45,"deletions":34,"binary":false,"changes":79,"status":"modified"},{"patch":"@@ -415,1 +415,1 @@\n-  const uint32_t             _initiating_numa_id;\n+  const uint32_t             _preferred_partition;\n@@ -423,1 +423,1 @@\n-  ZPageAllocation(ZPageType type, size_t size, ZAllocationFlags flags, ZPageAge age)\n+  ZPageAllocation(ZPageType type, size_t size, ZAllocationFlags flags, ZPageAge age, uint32_t preferred_partition)\n@@ -431,1 +431,1 @@\n-      _initiating_numa_id(ZNUMA::id()),\n+      _preferred_partition(preferred_partition),\n@@ -436,1 +436,3 @@\n-      _stall_result() {}\n+      _stall_result() {\n+    assert(_preferred_partition < ZNUMA::count(), \"Preferred partition out-of-bounds (0 <= %d < %d)\", _preferred_partition, ZNUMA::count());\n+  }\n@@ -477,2 +479,2 @@\n-  uint32_t initiating_numa_id() const {\n-    return _initiating_numa_id;\n+  uint32_t preferred_partition() const {\n+    return _preferred_partition;\n@@ -550,1 +552,4 @@\n-    EventZPageAllocation event;\n+    if (!EventZPageAllocation::is_enabled()) {\n+      \/\/ Event not enabled, exit early\n+      return;\n+    }\n@@ -555,10 +560,10 @@\n-    event.commit(_start_timestamp,\n-                 end_timestamp,\n-                 (u8)_type,\n-                 size(),\n-                 st._total_harvested,\n-                 st._total_committed_capacity,\n-                 (unsigned)st._num_harvested_vmems,\n-                 _is_multi_partition,\n-                 successful,\n-                 _flags.non_blocking());\n+    EventZPageAllocation::commit(_start_timestamp,\n+                                 end_timestamp,\n+                                 (u8)_type,\n+                                 size(),\n+                                 st._total_harvested,\n+                                 st._total_committed_capacity,\n+                                 (unsigned)st._num_harvested_vmems,\n+                                 _is_multi_partition,\n+                                 successful,\n+                                 _flags.non_blocking());\n@@ -648,1 +653,1 @@\n-    Atomic::add(&_capacity, increased);\n+    AtomicAccess::add(&_capacity, increased);\n@@ -658,1 +663,1 @@\n-  Atomic::sub(&_capacity, size);\n+  AtomicAccess::sub(&_capacity, size);\n@@ -663,1 +668,1 @@\n-    Atomic::store(&_current_max_capacity, _capacity);\n+    AtomicAccess::store(&_current_max_capacity, _capacity);\n@@ -933,1 +938,1 @@\n-      const uintptr_t claimed = Atomic::fetch_then_add(&_current, size);\n+      const uintptr_t claimed = AtomicAccess::fetch_then_add(&_current, size);\n@@ -1049,1 +1054,0 @@\n-\n@@ -1059,1 +1063,0 @@\n-  const ZVirtualMemory already_committed_vmem = vmem.first_part(already_committed);\n@@ -1090,1 +1093,2 @@\n-  assert(allocation->harvested() + allocation->committed_capacity() == freed, \"must have freed all\");\n+  assert(allocation->harvested() + allocation->committed_capacity() == freed, \"must have freed all\"\n+         \" %zu + %zu == %zu\", allocation->harvested(), allocation->committed_capacity(), freed);\n@@ -1277,1 +1281,1 @@\n-  const size_t soft_max_heapsize = Atomic::load(&SoftMaxHeapSize);\n+  const size_t soft_max_heapsize = AtomicAccess::load(&SoftMaxHeapSize);\n@@ -1286,1 +1290,1 @@\n-    current_max_capacity += Atomic::load(&partition->_current_max_capacity);\n+    current_max_capacity += AtomicAccess::load(&partition->_current_max_capacity);\n@@ -1297,1 +1301,1 @@\n-    capacity += Atomic::load(&partition->_capacity);\n+    capacity += AtomicAccess::load(&partition->_capacity);\n@@ -1304,1 +1308,1 @@\n-  return Atomic::load(&_used);\n+  return AtomicAccess::load(&_used);\n@@ -1308,1 +1312,1 @@\n-  return Atomic::load(&_used_generations[(int)id]);\n+  return AtomicAccess::load(&_used_generations[(int)id]);\n@@ -1318,2 +1322,2 @@\n-    capacity += (ssize_t)Atomic::load(&partition->_capacity);\n-    claimed += (ssize_t)Atomic::load(&partition->_claimed);\n+    capacity += (ssize_t)AtomicAccess::load(&partition->_capacity);\n+    claimed += (ssize_t)AtomicAccess::load(&partition->_claimed);\n@@ -1373,1 +1377,1 @@\n-  Atomic::add(&_used_generations[(int)id], size, memory_order_relaxed);\n+  AtomicAccess::add(&_used_generations[(int)id], size, memory_order_relaxed);\n@@ -1378,1 +1382,1 @@\n-  Atomic::sub(&_used_generations[(int)id], size, memory_order_relaxed);\n+  AtomicAccess::sub(&_used_generations[(int)id], size, memory_order_relaxed);\n@@ -1397,1 +1401,1 @@\n-ZPage* ZPageAllocator::alloc_page(ZPageType type, size_t size, ZAllocationFlags flags, ZPageAge age) {\n+ZPage* ZPageAllocator::alloc_page(ZPageType type, size_t size, ZAllocationFlags flags, ZPageAge age, uint32_t preferred_partition) {\n@@ -1400,1 +1404,1 @@\n-  ZPageAllocation allocation(type, size, flags, age);\n+  ZPageAllocation allocation(type, size, flags, age, preferred_partition);\n@@ -1420,1 +1424,0 @@\n-  const size_t committed = stats._total_committed_capacity;\n@@ -1548,1 +1551,1 @@\n-  const uint32_t start_numa_id = allocation->initiating_numa_id();\n+  const uint32_t start_numa_id = allocation->preferred_partition();\n@@ -1560,1 +1563,1 @@\n-  if (!is_multi_partition_enabled() || sum_available() < allocation->size()) {\n+  if (!is_multi_partition_allowed(allocation)) {\n@@ -1578,1 +1581,1 @@\n-  const uint32_t start_node = allocation->initiating_numa_id();\n+  const uint32_t start_node = allocation->preferred_partition();\n@@ -1907,0 +1910,1 @@\n+  assert(allocation->partial_vmems()->is_empty(), \"Invariant for single partition commit failure\");\n@@ -1908,4 +1912,7 @@\n-  const size_t committed = allocation->committed_capacity();\n-  const ZVirtualMemory non_harvested_vmem = vmem.last_part(allocation->harvested());\n-  const ZVirtualMemory committed_vmem = non_harvested_vmem.first_part(committed);\n-  const ZVirtualMemory non_committed_vmem = non_harvested_vmem.last_part(committed);\n+  \/\/ For a single partition we have unmapped the harvested memory before we\n+  \/\/ started committing, and moved its physical memory association to the start\n+  \/\/ of the vmem. As such, the partial_vmems is empty. All the harvested and\n+  \/\/ partially successfully committed memory is mapped in the first part of vmem.\n+  const size_t harvested_and_committed_capacity = allocation->harvested() + allocation->committed_capacity();\n+  const ZVirtualMemory succeeded_vmem = vmem.first_part(harvested_and_committed_capacity);\n+  const ZVirtualMemory failed_vmem = vmem.last_part(harvested_and_committed_capacity);\n@@ -1913,1 +1920,1 @@\n-  if (committed_vmem.size() > 0) {\n+  if (succeeded_vmem.size() > 0) {\n@@ -1917,1 +1924,1 @@\n-    allocation->partial_vmems()->append(committed_vmem);\n+    allocation->partial_vmems()->append(succeeded_vmem);\n@@ -1922,2 +1929,2 @@\n-  partition.free_physical(non_committed_vmem);\n-  partition.free_virtual(non_committed_vmem);\n+  partition.free_physical(failed_vmem);\n+  partition.free_virtual(failed_vmem);\n@@ -1939,1 +1946,1 @@\n-    const ZVirtualMemory non_harvested_vmem = vmem.last_part(allocation->harvested());\n+    const ZVirtualMemory non_harvested_vmem = partial_vmem.last_part(allocation->harvested());\n@@ -1957,3 +1964,0 @@\n-    \/\/ Remove the harvested part\n-    const ZVirtualMemory non_harvest_vmem = partial_vmem.last_part(allocation->harvested());\n-\n@@ -2191,0 +2195,6 @@\n+bool ZPageAllocator::is_multi_partition_allowed(const ZPageAllocation* allocation) const {\n+  return is_multi_partition_enabled() &&\n+         allocation->type() == ZPageType::large &&\n+         allocation->size() <= sum_available();\n+}\n+\n@@ -2216,1 +2226,1 @@\n-  const size_t used = Atomic::add(&_used, size);\n+  const size_t used = AtomicAccess::add(&_used, size);\n@@ -2228,1 +2238,1 @@\n-  const size_t used = Atomic::sub(&_used, size);\n+  const size_t used = AtomicAccess::sub(&_used, size);\n","filename":"src\/hotspot\/share\/gc\/z\/zPageAllocator.cpp","additions":63,"deletions":53,"binary":false,"changes":116,"status":"modified"},{"patch":"@@ -223,0 +223,1 @@\n+  bool is_multi_partition_allowed(const ZPageAllocation* allocation) const;\n@@ -266,1 +267,1 @@\n-  ZPage* alloc_page(ZPageType type, size_t size, ZAllocationFlags flags, ZPageAge age);\n+  ZPage* alloc_page(ZPageType type, size_t size, ZAllocationFlags flags, ZPageAge age, uint32_t preferred_partition);\n","filename":"src\/hotspot\/share\/gc\/z\/zPageAllocator.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -408,1 +408,1 @@\n-    Atomic::add(&_partition->_claimed, flushed);\n+    AtomicAccess::add(&_partition->_claimed, flushed);\n@@ -424,1 +424,1 @@\n-    Atomic::sub(&_partition->_claimed, flushed);\n+    AtomicAccess::sub(&_partition->_claimed, flushed);\n","filename":"src\/hotspot\/share\/gc\/z\/zUncommitter.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -56,1 +56,2 @@\n-  JMM_VERSION     = JMM_VERSION_4\n+  JMM_VERSION_5   = 0x20050000, \/\/ JDK 26\n+  JMM_VERSION     = JMM_VERSION_5\n@@ -84,2 +85,3 @@\n-  JMM_JVM_RESTORE_START_TIME_MS      = 12,   \/* Time when the JVM started restore operation *\/\n-  JMM_JVM_UPTIME_SINCE_RESTORE_MS    = 13,   \/* The JVM uptime since restore *\/\n+  JMM_TOTAL_GC_CPU_TIME              = 12,   \/* Total accumulated GC CPU time *\/\n+  JMM_JVM_RESTORE_START_TIME_MS      = 13,   \/* Time when the JVM started restore operation *\/\n+  JMM_JVM_UPTIME_SINCE_RESTORE_MS    = 14,   \/* The JVM uptime since restore *\/\n","filename":"src\/hotspot\/share\/include\/jmm.h","additions":6,"deletions":4,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -90,0 +90,3 @@\n+JNIEXPORT jboolean JNICALL\n+JVM_AOTEndRecording(JNIEnv *env);\n+\n@@ -356,0 +359,3 @@\n+JNIEXPORT jobject JNICALL\n+JVM_ReferenceGet(JNIEnv *env, jobject ref);\n+\n@@ -433,2 +439,0 @@\n- *  caller: initiating class. The initiating class may be null when a security\n- *          manager is not installed.\n@@ -437,2 +441,2 @@\n-JVM_FindClassFromCaller(JNIEnv *env, const char *name, jboolean init,\n-                        jobject loader, jclass caller);\n+JVM_FindClassFromLoader(JNIEnv *env, const char *name, jboolean init,\n+                        jobject loader);\n@@ -599,10 +603,0 @@\n-\n-\/* Differs from JVM_GetClassModifiers in treatment of inner classes.\n-   This returns the access flags for the class as specified in the\n-   class file rather than searching the InnerClasses attribute (if\n-   present) to find the source-level access flags. Only the values of\n-   the low 13 bits (i.e., a mask of 0x1FFF) are guaranteed to be\n-   valid. *\/\n-JNIEXPORT jint JNICALL\n-JVM_GetClassAccessFlags(JNIEnv *env, jclass cls);\n-\n@@ -654,1 +648,1 @@\n-(JNIEnv *env, jobject unused, jobject jcpool);\n+(JNIEnv *env, jobject jcpool);\n@@ -657,1 +651,1 @@\n-(JNIEnv *env, jobject unused, jobject jcpool, jint index);\n+(JNIEnv *env, jobject jcpool, jint index);\n@@ -660,1 +654,1 @@\n-(JNIEnv *env, jobject unused, jobject jcpool, jint index);\n+(JNIEnv *env, jobject jcpool, jint index);\n@@ -663,1 +657,1 @@\n-(JNIEnv *env, jobject obj, jobject unused, jint index);\n+(JNIEnv *env, jobject jcpool, jint index);\n@@ -666,1 +660,1 @@\n-(JNIEnv *env, jobject unused, jobject jcpool, jint index);\n+(JNIEnv *env, jobject jcpool, jint index);\n@@ -669,1 +663,1 @@\n-(JNIEnv *env, jobject unused, jobject jcpool, jint index);\n+(JNIEnv *env, jobject jcpool, jint index);\n@@ -672,1 +666,1 @@\n-(JNIEnv *env, jobject unused, jobject jcpool, jint index);\n+(JNIEnv *env, jobject jcpool, jint index);\n@@ -675,1 +669,1 @@\n-(JNIEnv *env, jobject unused, jobject jcpool, jint index);\n+(JNIEnv *env, jobject jcpool, jint index);\n@@ -678,1 +672,1 @@\n-(JNIEnv *env, jobject unused, jobject jcpool, jint index);\n+(JNIEnv *env, jobject jcpool, jint index);\n@@ -681,1 +675,1 @@\n-(JNIEnv *env, jobject obj, jobject unused, jint index);\n+(JNIEnv *env, jobject jcpool, jint index);\n@@ -684,1 +678,1 @@\n-(JNIEnv *env, jobject obj, jobject unused, jint index);\n+(JNIEnv *env, jobject jcpool, jint index);\n@@ -687,1 +681,1 @@\n-(JNIEnv *env, jobject unused, jobject jcpool, jint index);\n+(JNIEnv *env, jobject jcpool, jint index);\n@@ -690,1 +684,1 @@\n-(JNIEnv *env, jobject unused, jobject jcpool, jint index);\n+(JNIEnv *env, jobject jcpool, jint index);\n@@ -693,1 +687,1 @@\n-(JNIEnv *env, jobject unused, jobject jcpool, jint index);\n+(JNIEnv *env, jobject jcpool, jint index);\n@@ -696,1 +690,1 @@\n-(JNIEnv *env, jobject unused, jobject jcpool, jint index);\n+(JNIEnv *env, jobject jcpool, jint index);\n@@ -699,1 +693,1 @@\n-(JNIEnv *env, jobject unused, jobject jcpool, jint index);\n+(JNIEnv *env, jobject jcpool, jint index);\n@@ -702,1 +696,1 @@\n-(JNIEnv *env, jobject unused, jobject jcpool, jint index);\n+(JNIEnv *env, jobject jcpool, jint index);\n@@ -705,1 +699,1 @@\n-(JNIEnv *env, jobject unused, jobject jcpool, jint index);\n+(JNIEnv *env, jobject jcpool, jint index);\n@@ -1112,1 +1106,1 @@\n-JVM_VirtualThreadStart(JNIEnv* env, jobject vthread);\n+JVM_VirtualThreadEndFirstTransition(JNIEnv* env, jobject vthread);\n@@ -1115,1 +1109,1 @@\n-JVM_VirtualThreadEnd(JNIEnv* env, jobject vthread);\n+JVM_VirtualThreadStartFinalTransition(JNIEnv* env, jobject vthread);\n@@ -1118,1 +1112,1 @@\n-JVM_VirtualThreadMount(JNIEnv* env, jobject vthread, jboolean hide);\n+JVM_VirtualThreadStartTransition(JNIEnv* env, jobject vthread, jboolean is_mount);\n@@ -1121,1 +1115,1 @@\n-JVM_VirtualThreadUnmount(JNIEnv* env, jobject vthread, jboolean hide);\n+JVM_VirtualThreadEndTransition(JNIEnv* env, jobject vthread, jboolean is_mount);\n","filename":"src\/hotspot\/share\/include\/jvm.h","additions":30,"deletions":36,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2026, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,0 +25,1 @@\n+#include \"classfile\/classFileParser.hpp\"\n@@ -31,1 +32,1 @@\n-#include \"jfr\/recorder\/jfrRecorder.hpp\"\n+#include \"jfr\/recorder\/jfrRecorder.hpp\"\n@@ -34,2 +35,3 @@\n-#include \"jfr\/recorder\/service\/jfrOptionSet.hpp\"\n-#include \"jfr\/recorder\/service\/jfrOptionSet.hpp\"\n+#include \"jfr\/recorder\/service\/jfrOptionSet.hpp\"\n+#include \"jfr\/recorder\/service\/jfrRecorderService.hpp\"\n+#include \"jfr\/support\/jfrClassDefineEvent.hpp\"\n@@ -41,0 +43,1 @@\n+#include \"jfr\/support\/methodtracer\/jfrTraceTagging.hpp\"\n@@ -42,1 +45,0 @@\n-#include \"oops\/instanceKlass.hpp\"\n@@ -48,0 +50,2 @@\n+#include \"runtime\/os.hpp\"\n+\n@@ -86,0 +90,1 @@\n+  JfrTraceId::assign(ik);\n@@ -88,3 +93,1 @@\n-    return;\n-  }\n-  if (JfrMethodTracer::in_use()) {\n+  } else if (JfrMethodTracer::in_use()) {\n@@ -93,0 +96,3 @@\n+  if (!parser.is_internal()) {\n+    JfrClassDefineEvent::on_creation(ik, parser, THREAD);\n+  }\n@@ -95,3 +101,2 @@\n-void Jfr::on_klass_redefinition(const InstanceKlass* ik, Thread* thread) {\n-  assert(JfrMethodTracer::in_use(), \"invariant\");\n-  JfrMethodTracer::on_klass_redefinition(ik, thread);\n+void Jfr::on_klass_redefinition(const InstanceKlass* ik, const InstanceKlass* scratch_klass) {\n+  JfrTraceTagging::on_klass_redefinition(ik, scratch_klass);\n@@ -100,1 +105,0 @@\n-\n@@ -159,1 +163,1 @@\n-void Jfr::on_vm_shutdown(bool exception_handler, bool halt) {\n+void Jfr::on_vm_shutdown(bool exception_handler \/* false *\/, bool halt \/* false *\/, bool oom \/* false *\/) {\n@@ -161,1 +165,1 @@\n-    JfrEmergencyDump::on_vm_shutdown(exception_handler);\n+    JfrEmergencyDump::on_vm_shutdown(exception_handler, oom);\n@@ -192,1 +196,1 @@\n-    snprintf(buf, buf_len, \"-XX:%s=%s\", jfr_flag, flag->get_ccstr());\n+    os::snprintf_checked(buf, buf_len, \"-XX:%s=%s\", jfr_flag, flag->get_ccstr());\n@@ -204,0 +208,16 @@\n+\n+void Jfr::on_report_java_out_of_memory() {\n+  if (CrashOnOutOfMemoryError && JfrRecorder::is_recording()) {\n+    JfrRecorderService::emit_leakprofiler_events_on_oom();\n+  }\n+}\n+\n+#if INCLUDE_CDS\n+void Jfr::on_restoration(const Klass* k, JavaThread* jt) {\n+  assert(k != nullptr, \"invariant\");\n+  JfrTraceId::restore(k);\n+  if (k->is_instance_klass()) {\n+    JfrClassDefineEvent::on_restoration(InstanceKlass::cast(k), jt);\n+  }\n+}\n+#endif\n","filename":"src\/hotspot\/share\/jfr\/jfr.cpp","additions":35,"deletions":15,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2026, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,0 +28,1 @@\n+#include \"jfr\/utilities\/jfrTypes.hpp\"\n@@ -64,1 +65,1 @@\n-  static void on_klass_redefinition(const InstanceKlass* ik, Thread* thread);\n+  static void on_klass_redefinition(const InstanceKlass* ik, const InstanceKlass* scratch_klass);\n@@ -73,1 +74,1 @@\n-  static void on_vm_shutdown(bool exception_handler = false, bool halt = false);\n+  static void on_vm_shutdown(bool exception_handler = false, bool halt = false, bool oom = false);\n@@ -83,0 +84,2 @@\n+  static void on_report_java_out_of_memory();\n+  CDS_ONLY(static void on_restoration(const Klass* k, JavaThread* jt);)\n","filename":"src\/hotspot\/share\/jfr\/jfr.hpp","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2026, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,0 +25,2 @@\n+#include \"jfr\/instrumentation\/jfrEventClassTransformer.hpp\"\n+#include \"jfr\/instrumentation\/jfrJvmtiAgent.hpp\"\n@@ -27,0 +29,3 @@\n+#include \"jfr\/jni\/jfrJavaSupport.hpp\"\n+#include \"jfr\/jni\/jfrJniMethodRegistration.hpp\"\n+#include \"jfr\/leakprofiler\/leakProfiler.hpp\"\n@@ -29,2 +34,0 @@\n-#include \"jfr\/recorder\/jfrEventSetting.hpp\"\n-#include \"jfr\/recorder\/jfrRecorder.hpp\"\n@@ -33,0 +36,2 @@\n+#include \"jfr\/recorder\/jfrEventSetting.hpp\"\n+#include \"jfr\/recorder\/jfrRecorder.hpp\"\n@@ -34,1 +39,0 @@\n-#include \"jfr\/recorder\/repository\/jfrRepository.hpp\"\n@@ -38,0 +42,1 @@\n+#include \"jfr\/recorder\/repository\/jfrRepository.hpp\"\n@@ -45,5 +50,0 @@\n-#include \"jfr\/jni\/jfrJavaSupport.hpp\"\n-#include \"jfr\/jni\/jfrJniMethodRegistration.hpp\"\n-#include \"jfr\/instrumentation\/jfrEventClassTransformer.hpp\"\n-#include \"jfr\/instrumentation\/jfrJvmtiAgent.hpp\"\n-#include \"jfr\/leakprofiler\/leakProfiler.hpp\"\n@@ -55,1 +55,1 @@\n-#include \"jfr\/utilities\/jfrTimeConverter.hpp\"\n+#include \"jfr\/utilities\/jfrTimeConverter.hpp\"\n@@ -70,1 +70,1 @@\n-#include \"osContainer_linux.hpp\"\n+#include \"osContainer_linux.hpp\"\n@@ -173,1 +173,1 @@\n-JVM_ENTRY_NO_ENV(void, jfr_set_cpu_throttle(JNIEnv* env, jclass jvm, jdouble rate, jboolean auto_adapt))\n+JVM_ENTRY_NO_ENV(void, jfr_set_cpu_rate(JNIEnv* env, jclass jvm, jdouble rate))\n@@ -175,1 +175,7 @@\n-  JfrCPUTimeThreadSampling::set_rate(rate, auto_adapt == JNI_TRUE);\n+  JfrCPUTimeThreadSampling::set_rate(rate);\n+JVM_END\n+\n+JVM_ENTRY_NO_ENV(void, jfr_set_cpu_period(JNIEnv* env, jclass jvm, jlong period_nanos))\n+  assert(period_nanos >= 0, \"invariant\");\n+  JfrEventSetting::set_enabled(JfrCPUTimeSampleEvent, period_nanos > 0);\n+  JfrCPUTimeThreadSampling::set_period(period_nanos);\n@@ -361,2 +367,1 @@\n-  JfrRecorderService service;\n-  service.emit_leakprofiler_events(cutoff_ticks, emit_all == JNI_TRUE, skip_bfs == JNI_TRUE);\n+  JfrRecorderService::emit_leakprofiler_events(cutoff_ticks, emit_all == JNI_TRUE, skip_bfs == JNI_TRUE);\n@@ -409,1 +414,1 @@\n-  return os::Linux::physical_memory();\n+  return static_cast<jlong>(os::Linux::physical_memory());\n@@ -411,1 +416,1 @@\n-  return os::physical_memory();\n+  return static_cast<jlong>(os::physical_memory());\n@@ -418,1 +423,3 @@\n-  return os::Linux::host_swap();\n+  physical_memory_size_type host_swap = 0;\n+  (void)os::Linux::host_swap(host_swap); \/\/ Discard return value and treat as no swap\n+  return static_cast<jlong>(host_swap);\n@@ -420,1 +427,4 @@\n-  return os::total_swap_space();\n+  physical_memory_size_type total_swap_space = 0;\n+  \/\/ Return value ignored - defaulting to 0 on failure.\n+  (void)os::total_swap_space(total_swap_space);\n+  return static_cast<jlong>(total_swap_space);\n","filename":"src\/hotspot\/share\/jfr\/jni\/jfrJniMethod.cpp","additions":29,"deletions":19,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -132,1 +132,3 @@\n-void JNICALL jfr_set_cpu_throttle(JNIEnv* env, jclass jvm, jdouble rate, jboolean auto_adapt);\n+void JNICALL jfr_set_cpu_rate(JNIEnv* env, jclass jvm, jdouble rate);\n+\n+void JNICALL jfr_set_cpu_period(JNIEnv* env, jclass jvm, jlong period_nanos);\n","filename":"src\/hotspot\/share\/jfr\/jni\/jfrJniMethod.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+ * Copyright (c) 2025, Datadog, Inc. All rights reserved.\n@@ -30,0 +31,1 @@\n+#include \"runtime\/threadWXSetters.inline.hpp\"\n@@ -86,1 +88,2 @@\n-      (char*)\"setCPUThrottle\", (char*)\"(DZ)V\", (void*)jfr_set_cpu_throttle,\n+      (char*)\"setCPURate\", (char*)\"(D)V\", (void*)jfr_set_cpu_rate,\n+      (char*)\"setCPUPeriod\", (char*)\"(J)V\", (void*)jfr_set_cpu_period,\n@@ -116,0 +119,1 @@\n+      MACOS_AARCH64_ONLY(ThreadWXEnable __wx(WXWrite, jt));\n","filename":"src\/hotspot\/share\/jfr\/jni\/jfrJniMethodRegistration.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -270,1 +270,1 @@\n-    module = module_entry->module();\n+    module = module_entry->module_oop();\n","filename":"src\/hotspot\/share\/jfr\/jni\/jfrUpcalls.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -35,2 +35,0 @@\n-#include <stdlib.h> \/\/ for environment variables\n-\n@@ -84,4 +82,1 @@\n-  \/\/ environment information\n-  void generate_environment_variables_events();\n-\n-   \/\/ system processes information\n+  \/\/ system processes information\n","filename":"src\/hotspot\/share\/jfr\/periodic\/jfrOSInterface.cpp","additions":1,"deletions":6,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -35,1 +35,1 @@\n-#include \"jfr\/recorder\/checkpoint\/types\/jfrThreadGroup.hpp\"\n+#include \"jfr\/recorder\/checkpoint\/types\/jfrThreadGroupManager.hpp\"\n@@ -109,1 +109,1 @@\n-    _writer.write(JfrThreadGroup::thread_group_id(JavaThread::cast(t), _curthread));\n+    _writer.write(JfrThreadGroupManager::thread_group_id(JavaThread::cast(t), _curthread));\n@@ -118,1 +118,4 @@\n-    tc.do_thread(javathreads.next());\n+    JavaThread* const jt = javathreads.next();\n+    if (jt->jfr_thread_local()->should_write()) {\n+      tc.do_thread(jt);\n+    }\n@@ -127,1 +130,1 @@\n-  JfrThreadGroup::serialize(writer);\n+  JfrThreadGroupManager::serialize(writer);\n@@ -307,1 +310,1 @@\n-    JfrThreadGroup::thread_group_id(JavaThread::cast(_thread), Thread::current());\n+    JfrThreadGroupManager::thread_group_id(JavaThread::cast(_thread), Thread::current());\n@@ -310,2 +313,2 @@\n-  if (!is_vthread) {\n-    JfrThreadGroup::serialize(&writer, thread_group_id);\n+  if (thread_group_id > 1) {\n+    JfrThreadGroupManager::serialize(writer, thread_group_id, _to_blob);\n","filename":"src\/hotspot\/share\/jfr\/recorder\/checkpoint\/types\/jfrType.cpp","additions":10,"deletions":7,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -34,1 +34,2 @@\n-#include \"jfr\/recorder\/jfrRecorder.hpp\"\n+#include \"jfr\/recorder\/checkpoint\/types\/jfrThreadGroupManager.hpp\"\n+#include \"jfr\/recorder\/jfrRecorder.hpp\"\n@@ -42,1 +43,1 @@\n-#include \"jfr\/recorder\/storage\/jfrStorage.hpp\"\n+#include \"jfr\/recorder\/storage\/jfrStorage.hpp\"\n@@ -45,0 +46,1 @@\n+#include \"jfr\/support\/jfrSymbolTable.hpp\"\n@@ -51,1 +53,1 @@\n-#include \"runtime\/handles.inline.hpp\"\n+#include \"runtime\/handles.inline.hpp\"\n@@ -314,0 +316,6 @@\n+  if (!create_thread_group_manager()) {\n+    return false;\n+  }\n+  if (!create_symbol_table()) {\n+    return false;\n+  }\n@@ -408,0 +416,8 @@\n+bool JfrRecorder::create_thread_group_manager() {\n+  return JfrThreadGroupManager::create();\n+}\n+\n+bool JfrRecorder::create_symbol_table() {\n+  return JfrSymbolTable::create();\n+}\n+\n@@ -447,0 +463,2 @@\n+  JfrThreadGroupManager::destroy();\n+  JfrSymbolTable::destroy();\n","filename":"src\/hotspot\/share\/jfr\/recorder\/jfrRecorder.cpp","additions":21,"deletions":3,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -56,0 +56,1 @@\n+  static bool create_thread_group_manager();\n@@ -59,0 +60,1 @@\n+  static bool create_symbol_table();\n","filename":"src\/hotspot\/share\/jfr\/recorder\/jfrRecorder.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2011, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2011, 2026, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,1 @@\n+#include \"code\/nmethod.hpp\"\n@@ -58,1 +59,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -1010,1 +1011,1 @@\n-  LinkResolver::resolve_field(fd, link_info, Bytecodes::java_code(code), false, CHECK_NULL);\n+  LinkResolver::resolve_field(fd, link_info, Bytecodes::java_code(code), ClassInitMode::dont_init, CHECK_NULL);\n@@ -1209,1 +1210,1 @@\n-        JVMCIENV->invalidate_nmethod_mirror(nmethod_mirror, true, JVMCI_CHECK_0);\n+        JVMCIENV->invalidate_nmethod_mirror(nmethod_mirror, true, nmethod::InvalidationReason::JVMCI_REPLACED_WITH_NEW_CODE, JVMCI_CHECK_0);\n@@ -1220,0 +1221,8 @@\n+C2V_VMENTRY_NULL(jobject, getInvalidationReasonDescription, (JNIEnv *env, jobject, jint invalidation_reason))\n+  HandleMark hm(THREAD);\n+  JNIHandleMark jni_hm(thread);\n+  nmethod::InvalidationReason reason = static_cast<nmethod::InvalidationReason>(invalidation_reason);\n+  JVMCIObject desc = JVMCIENV->create_string(nmethod::invalidation_reason_to_string(reason), JVMCI_CHECK_NULL);\n+  return JVMCIENV->get_jobject(desc);\n+C2V_END\n+\n@@ -1385,1 +1394,1 @@\n-    code->make_not_entrant(\"JVMCI reprofile\", false \/* trust the compiler, ideally should be a parameter *\/);\n+    code->make_not_entrant(nmethod::InvalidationReason::JVMCI_REPROFILE, false \/* trust the compiler, ideally should be a parameter *\/);\n@@ -1398,1 +1407,6 @@\n-C2V_VMENTRY(void, invalidateHotSpotNmethod, (JNIEnv* env, jobject, jobject hs_nmethod, jboolean deoptimize))\n+C2V_VMENTRY(void, invalidateHotSpotNmethod, (JNIEnv* env, jobject, jobject hs_nmethod, jboolean deoptimize, jint invalidation_reason))\n+  int first = static_cast<int>(nmethod::InvalidationReason::C1_CODEPATCH);\n+  int last = static_cast<int>(nmethod::InvalidationReason::INVALIDATION_REASONS_COUNT);\n+  if (invalidation_reason < first || invalidation_reason >= last) {\n+    JVMCI_THROW_MSG(IllegalArgumentException, err_msg(\"Invalid invalidation_reason: %d\", invalidation_reason));\n+  }\n@@ -1400,1 +1414,1 @@\n-  JVMCIENV->invalidate_nmethod_mirror(nmethod_mirror, deoptimize, JVMCI_CHECK);\n+  JVMCIENV->invalidate_nmethod_mirror(nmethod_mirror, deoptimize, static_cast<nmethod::InvalidationReason>(invalidation_reason), JVMCI_CHECK);\n@@ -1825,1 +1839,1 @@\n-    fst.current()->cb()->as_nmethod()->make_not_entrant(\"JVMCI materialize virtual objects\",\n+    fst.current()->cb()->as_nmethod()->make_not_entrant(nmethod::InvalidationReason::JVMCI_MATERIALIZE_VIRTUAL_OBJECT,\n@@ -2002,1 +2016,1 @@\n-    Klass* k = iklass->local_interfaces()->at(index);\n+    InstanceKlass* k = iklass->local_interfaces()->at(index);\n@@ -2267,1 +2281,1 @@\n-  JVMCIObjectArray array = JVMCIENV->new_FieldInfo_array(fields->length(), JVMCIENV);\n+  JVMCIObjectArray array = JVMCIENV->new_FieldInfo_array(fields->length(), JVMCI_CHECK_NULL);\n@@ -2880,0 +2894,1 @@\n+      jboolean profileDeopt = thisEnv->get_HotSpotNmethod_profileDeopt(obj);\n@@ -2884,1 +2899,1 @@\n-      result = PEER_JVMCIENV->new_HotSpotNmethod(mh, cstring, isDefault, compileIdSnapshot, JVMCI_CHECK_0);\n+      result = PEER_JVMCIENV->new_HotSpotNmethod(mh, cstring, isDefault, profileDeopt, compileIdSnapshot, JVMCI_CHECK_0);\n@@ -2973,0 +2988,1 @@\n+\/\/ Checks that `index` denotes a non-injected field in `klass`\n@@ -2979,1 +2995,8 @@\n-  if (index < 0 || index > iklass->total_fields_count()) {\n+  if (index < 0 || index >= iklass->java_fields_count()) {\n+    if (index >= 0 && index < iklass->total_fields_count()) {\n+      fieldDescriptor fd(iklass, index);\n+      if (fd.is_injected()) {\n+        JVMCI_THROW_MSG_NULL(IllegalArgumentException,\n+            err_msg(\"Cannot get Field for injected %s.%s\", klass->external_name(), fd.name()->as_C_string()));\n+      }\n+    }\n@@ -2989,1 +3012,1 @@\n-  InstanceKlass* iklass = check_field(klass, index, JVMCIENV);\n+  InstanceKlass* iklass = check_field(klass, index, JVMCI_CHECK_NULL);\n@@ -2997,1 +3020,1 @@\n-                                              JavaThread* THREAD, JVMCIEnv* JVMCIENV) {\n+                                              JavaThread* THREAD, JVMCI_TRAPS) {\n@@ -3075,1 +3098,1 @@\n-  InstanceKlass* holder = check_field(InstanceKlass::cast(UNPACK_PAIR(Klass, klass)), index, JVMCIENV);\n+  InstanceKlass* holder = check_field(InstanceKlass::cast(UNPACK_PAIR(Klass, klass)), index, JVMCI_CHECK_NULL);\n@@ -3355,0 +3378,1 @@\n+  {CC \"getInvalidationReasonDescription\",             CC \"(I)\" STRING,                                                                      FN_PTR(getInvalidationReasonDescription)},\n@@ -3363,1 +3387,1 @@\n-  {CC \"invalidateHotSpotNmethod\",                     CC \"(\" HS_NMETHOD \"Z)V\",                                                              FN_PTR(invalidateHotSpotNmethod)},\n+  {CC \"invalidateHotSpotNmethod\",                     CC \"(\" HS_NMETHOD \"ZI)V\",                                                             FN_PTR(invalidateHotSpotNmethod)},\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.cpp","additions":40,"deletions":16,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -937,1 +937,1 @@\n-  os::vsnprintf(msg, max_msg_size, format, ap);\n+  (void) os::vsnprintf(msg, max_msg_size, format, ap);\n@@ -1213,1 +1213,1 @@\n-JVMCIObject JVMCIEnv::new_HotSpotNmethod(const methodHandle& method, const char* name, jboolean isDefault, jlong compileId, JVMCI_TRAPS) {\n+JVMCIObject JVMCIEnv::new_HotSpotNmethod(const methodHandle& method, const char* name, jboolean isDefault, jboolean profileDeopt, jlong compileId, JVMCI_TRAPS) {\n@@ -1233,0 +1233,1 @@\n+    jargs.push_int(profileDeopt);\n@@ -1237,1 +1238,1 @@\n-                            vmSymbols::method_string_bool_long_signature(),\n+                            vmSymbols::method_string_bool_bool_long_signature(),\n@@ -1466,2 +1467,1 @@\n-    Klass* byteArrayArrayKlass = TypeArrayKlass::cast(Universe::byteArrayKlass())->array_klass(CHECK_(JVMCIObject()));\n-    objArrayOop result = ObjArrayKlass::cast(byteArrayArrayKlass) ->allocate(length, CHECK_(JVMCIObject()));\n+    objArrayOop result = oopFactory::new_objArray(Universe::byteArrayKlass(), length, CHECK_(JVMCIObject()));\n@@ -1753,1 +1753,1 @@\n-void JVMCIEnv::invalidate_nmethod_mirror(JVMCIObject mirror, bool deoptimize, JVMCI_TRAPS) {\n+void JVMCIEnv::invalidate_nmethod_mirror(JVMCIObject mirror, bool deoptimize, nmethod::InvalidationReason invalidation_reason, JVMCI_TRAPS) {\n@@ -1776,1 +1776,1 @@\n-    nm->make_not_entrant(\"JVMCI invalidate nmethod mirror\", false \/* trust the compiler, ideally should be a parameter *\/);\n+    nm->make_not_entrant(invalidation_reason, false \/* trust the compiler, ideally should be a parameter *\/);\n@@ -1785,1 +1785,1 @@\n-    nm->make_not_entrant(\"JVMCI invalidate nmethod mirror\", false \/* trust the compiler, ideally should be a parameter *\/);\n+    nm->make_not_entrant(invalidation_reason, false \/* trust the compiler, ideally should be a parameter *\/);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciEnv.cpp","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -50,1 +50,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -190,1 +190,1 @@\n-  InstanceKlass* klass = InstanceKlass::cast(java_lang_Class::as_Klass(type_mirror));\n+  InstanceKlass* klass = java_lang_Class::as_InstanceKlass(type_mirror);\n@@ -231,3 +231,0 @@\n-  \/\/ Reset method handle flag.\n-  current->set_is_method_handle_return(false);\n-\n@@ -308,2 +305,0 @@\n-      \/\/ Set flag if return address is a method handle call site.\n-      current->set_is_method_handle_return(nm->is_method_handle_return(pc));\n@@ -346,3 +341,0 @@\n-  \/\/ Set flag if return address is a method handle call site.\n-  current->set_is_method_handle_return(nm->is_method_handle_return(pc));\n-\n@@ -568,2 +560,2 @@\n-  } else if (oopDesc::is_oop_or_null(obj, true) && (!as_string || !java_lang_String::is_instance(obj))) {\n-    if (oopDesc::is_oop_or_null(obj, true)) {\n+  } else if (oopDesc::is_oop_or_null(obj) && (!as_string || !java_lang_String::is_instance(obj))) {\n+    if (oopDesc::is_oop_or_null(obj)) {\n@@ -592,4 +584,0 @@\n-void JVMCIRuntime::write_barrier_post(JavaThread* thread, volatile CardValue* card_addr) {\n-  G1BarrierSetRuntime::write_ref_field_post_entry(card_addr, thread);\n-}\n-\n@@ -749,0 +737,2 @@\n+                                  bool is_default,\n+                                  bool profile_deopt,\n@@ -756,1 +746,1 @@\n-    _has_name = true;\n+    _properties.bits._has_name = 1;\n@@ -760,1 +750,1 @@\n-    _has_name = false;\n+    _properties.bits._has_name = 0;\n@@ -762,0 +752,2 @@\n+  _properties.bits._is_default = is_default;\n+  _properties.bits._profile_deopt = profile_deopt;\n@@ -765,1 +757,2 @@\n-  initialize(data->_nmethod_mirror_index, data->_nmethod_entry_patch_offset, data->name(), data->_failed_speculations);\n+  initialize(data->_nmethod_mirror_index, data->_nmethod_entry_patch_offset, data->name(), data->_properties.bits._is_default,\n+             data->_properties.bits._profile_deopt, data->_failed_speculations);\n@@ -800,1 +793,1 @@\n-void JVMCINMethodData::invalidate_nmethod_mirror(nmethod* nm) {\n+void JVMCINMethodData::invalidate_nmethod_mirror(nmethod* nm, nmethod::InvalidationReason invalidation_reason) {\n@@ -819,0 +812,4 @@\n+      if (HotSpotJVMCI::HotSpotNmethod::invalidationReason(jvmciEnv, nmethod_mirror) ==\n+        static_cast<int>(nmethod::InvalidationReason::NOT_INVALIDATED)) {\n+        HotSpotJVMCI::HotSpotNmethod::set_invalidationReason(jvmciEnv, nmethod_mirror, static_cast<int>(invalidation_reason));\n+      }\n@@ -825,0 +822,4 @@\n+      if (HotSpotJVMCI::HotSpotNmethod::invalidationReason(jvmciEnv, nmethod_mirror) ==\n+        static_cast<int>(nmethod::InvalidationReason::NOT_INVALIDATED)) {\n+        HotSpotJVMCI::HotSpotNmethod::set_invalidationReason(jvmciEnv, nmethod_mirror, static_cast<int>(invalidation_reason));\n+      }\n@@ -1612,1 +1613,1 @@\n-  if (!report_error && Atomic::cmpxchg(&report_error, 0, 1) == 0) {\n+  if (!report_error && AtomicAccess::cmpxchg(&report_error, 0, 1) == 0) {\n@@ -2079,0 +2080,1 @@\n+  bool profile_deopt = JVMCIENV->get_HotSpotNmethod_profileDeopt(nmethod_mirror) != 0;\n@@ -2125,1 +2127,1 @@\n-    if (result != JVMCI::ok) {\n+    if (install_default && result != JVMCI::ok) {\n@@ -2146,0 +2148,2 @@\n+                                                        install_default,\n+                                                        profile_deopt,\n@@ -2187,1 +2191,1 @@\n-              old->make_not_entrant(\"JVMCI register method\", false \/* already being replaced *\/);\n+              old->make_not_entrant(nmethod::InvalidationReason::JVMCI_REPLACED_WITH_NEW_CODE, false \/* already being replaced *\/);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciRuntime.cpp","additions":27,"deletions":23,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -31,1 +31,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -325,3 +325,2 @@\n-    Atomic::release_store_fence(&AsyncLogWriter::_instance, self);\n-    \/\/ All readers of _instance after the fence see non-null.\n-    \/\/ After that, we start AsyncLog Thread and it exclusively takes over all logging I\/O.\n+    \/\/ After that, we publish the initalized _instance to readers.\n+    \/\/ Then we start the AsyncLog Thread and it exclusively takes over all logging I\/O.\n@@ -332,0 +331,1 @@\n+    AtomicAccess::release_store_fence(&AsyncLogWriter::_instance, self);\n","filename":"src\/hotspot\/share\/logging\/logAsyncWriter.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -32,1 +32,1 @@\n-#include \"runtime\/os.inline.hpp\"\n+#include \"runtime\/os.inline.hpp\"\n@@ -35,1 +35,1 @@\n-#include \"utilities\/resourceHash.hpp\"\n+#include \"utilities\/hashTable.hpp\"\n@@ -69,1 +69,1 @@\n-  using AsyncLogMap = ResourceHashtable<LogFileStreamOutput*,\n+  using AsyncLogMap = HashTable<LogFileStreamOutput*,\n","filename":"src\/hotspot\/share\/logging\/logAsyncWriter.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2025, Oracle and\/or its affiliates. All rights reserved.\n","filename":"src\/hotspot\/share\/logging\/logConfiguration.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -43,1 +43,1 @@\n-  size_t              _decorator_padding[LogDecorators::Count];\n+  int                 _decorator_padding[LogDecorators::Count];\n@@ -45,5 +45,6 @@\n-  LogFileStreamOutput(FILE *stream) : _fold_multilines(false), _write_error_is_shown(false), _stream(stream) {\n-    for (size_t i = 0; i < LogDecorators::Count; i++) {\n-      _decorator_padding[i] = 0;\n-    }\n-  }\n+  LogFileStreamOutput(FILE *stream)\n+    : _fold_multilines(false),\n+      _write_error_is_shown(false),\n+      _stream(stream),\n+      _decorator_padding()\n+  {}\n","filename":"src\/hotspot\/share\/logging\/logFileStreamOutput.hpp","additions":8,"deletions":7,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+  LOG_TAG(asan) \\\n@@ -153,0 +154,1 @@\n+  LOG_TAG(package) \\\n@@ -220,0 +222,1 @@\n+  LOG_TAG(vmatree) \\\n","filename":"src\/hotspot\/share\/logging\/logTag.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -31,1 +32,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -53,1 +53,1 @@\n-#include \"logging\/log.hpp\"\n+#include \"logging\/log.hpp\"\n@@ -64,1 +64,1 @@\n-#include \"oops\/fieldStreams.inline.hpp\"\n+#include \"oops\/fieldStreams.inline.hpp\"\n@@ -81,0 +81,1 @@\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -82,1 +83,0 @@\n-#include \"runtime\/atomic.hpp\"\n@@ -162,1 +162,1 @@\n-  if (vmClasses::ClassLoader_klass_loaded()) {\n+  if (vmClasses::ClassLoader_klass_is_loaded()) {\n@@ -315,2 +315,1 @@\n-      const char* msg = ss.as_string(true \/* on C-heap *\/);\n-      SystemDictionary::add_nest_host_error(cph, _nest_host_index, msg);\n+      SystemDictionary::add_nest_host_error(cph, _nest_host_index, ss);\n@@ -320,1 +319,1 @@\n-      log_trace(class, nestmates)(\"%s\", msg);\n+      log_trace(class, nestmates)(\"%s\", ss.base());\n@@ -359,3 +358,2 @@\n-        const char* msg = ss.as_string(true \/* on C-heap *\/);\n-        SystemDictionary::add_nest_host_error(cph, _nest_host_index, msg);\n-        log_trace(class, nestmates)(\"%s\", msg);\n+        SystemDictionary::add_nest_host_error(cph, _nest_host_index, ss);\n+        log_trace(class, nestmates)(\"%s\", ss.base());\n@@ -458,5 +456,0 @@\n-void* InstanceKlass::operator new(size_t size, ClassLoaderData* loader_data, size_t word_size,\n-                                  bool use_class_space, TRAPS) throw() {\n-  return Metaspace::allocate(loader_data, word_size, ClassType, use_class_space, THREAD);\n-}\n-\n@@ -475,1 +468,0 @@\n-  const bool use_class_space = parser.klass_needs_narrow_id();\n@@ -480,1 +472,1 @@\n-    ik = new (loader_data, size, use_class_space, THREAD) InstanceRefKlass(parser);\n+    ik = new (loader_data, size, THREAD) InstanceRefKlass(parser);\n@@ -483,1 +475,1 @@\n-    ik = new (loader_data, size, use_class_space, THREAD) InstanceMirrorKlass(parser);\n+    ik = new (loader_data, size, THREAD) InstanceMirrorKlass(parser);\n@@ -486,1 +478,1 @@\n-    ik = new (loader_data, size, use_class_space, THREAD) InstanceStackChunkKlass(parser);\n+    ik = new (loader_data, size, THREAD) InstanceStackChunkKlass(parser);\n@@ -489,1 +481,1 @@\n-    ik = new (loader_data, size, use_class_space, THREAD) InstanceClassLoaderKlass(parser);\n+    ik = new (loader_data, size, THREAD) InstanceClassLoaderKlass(parser);\n@@ -492,1 +484,1 @@\n-    ik = new (loader_data, size, use_class_space, THREAD) InstanceKlass(parser);\n+    ik = new (loader_data, size, THREAD) InstanceKlass(parser);\n@@ -495,1 +487,1 @@\n-  if (ik != nullptr && UseCompressedClassPointers && use_class_space) {\n+  if (ik != nullptr && UseCompressedClassPointers) {\n@@ -561,0 +553,11 @@\n+void InstanceKlass::set_is_cloneable() {\n+  if (name() == vmSymbols::java_lang_invoke_MemberName()) {\n+    assert(is_final(), \"no subclasses allowed\");\n+    \/\/ MemberName cloning should not be intrinsified and always happen in JVM_Clone.\n+  } else if (reference_type() != REF_NONE) {\n+    \/\/ Reference cloning should not be intrinsified and always happen in JVM_Clone.\n+  } else {\n+    set_is_cloneable_fast();\n+  }\n+}\n+\n@@ -564,1 +567,1 @@\n-      !methods->is_shared()) {\n+      !methods->in_aot_cache()) {\n@@ -578,1 +581,1 @@\n-                                          const Klass* super_klass,\n+                                          const InstanceKlass* super_klass,\n@@ -587,2 +590,2 @@\n-                    InstanceKlass::cast(super_klass)->transitive_interfaces();\n-    if (ti != sti && ti != nullptr && !ti->is_shared()) {\n+                    super_klass->transitive_interfaces();\n+    if (ti != sti && ti != nullptr && !ti->in_aot_cache()) {\n@@ -595,1 +598,1 @@\n-      local_interfaces != nullptr && !local_interfaces->is_shared()) {\n+      local_interfaces != nullptr && !local_interfaces->in_aot_cache()) {\n@@ -602,1 +605,1 @@\n-  if (record_components != nullptr && !record_components->is_shared()) {\n+  if (record_components != nullptr && !record_components->in_aot_cache()) {\n@@ -646,1 +649,1 @@\n-      !method_ordering()->is_shared()) {\n+      !method_ordering()->in_aot_cache()) {\n@@ -654,1 +657,1 @@\n-      !default_methods()->is_shared()) {\n+      !default_methods()->in_aot_cache()) {\n@@ -662,1 +665,1 @@\n-      !default_vtable_indices()->is_shared()) {\n+      !default_vtable_indices()->in_aot_cache()) {\n@@ -675,1 +678,1 @@\n-      !secondary_supers()->is_shared()) {\n+      !secondary_supers()->in_aot_cache()) {\n@@ -684,1 +687,1 @@\n-  if (fieldinfo_stream() != nullptr && !fieldinfo_stream()->is_shared()) {\n+  if (fieldinfo_stream() != nullptr && !fieldinfo_stream()->in_aot_cache()) {\n@@ -689,1 +692,6 @@\n-  if (fields_status() != nullptr && !fields_status()->is_shared()) {\n+  if (fieldinfo_search_table() != nullptr && !fieldinfo_search_table()->in_aot_cache()) {\n+    MetadataFactory::free_array<u1>(loader_data, fieldinfo_search_table());\n+  }\n+  set_fieldinfo_search_table(nullptr);\n+\n+  if (fields_status() != nullptr && !fields_status()->in_aot_cache()) {\n@@ -698,1 +706,1 @@\n-    if (!constants()->is_shared()) {\n+    if (!constants()->in_aot_cache()) {\n@@ -709,1 +717,1 @@\n-      !inner_classes()->is_shared()) {\n+      !inner_classes()->in_aot_cache()) {\n@@ -716,1 +724,1 @@\n-      !nest_members()->is_shared()) {\n+      !nest_members()->in_aot_cache()) {\n@@ -723,1 +731,1 @@\n-      !permitted_subclasses()->is_shared()) {\n+      !permitted_subclasses()->in_aot_cache()) {\n@@ -729,1 +737,1 @@\n-  if (annotations() != nullptr && !annotations()->is_shared()) {\n+  if (annotations() != nullptr && !annotations()->in_aot_cache()) {\n@@ -746,1 +754,1 @@\n-         java_super() == vmClasses::Record_klass();\n+         super() == vmClasses::Record_klass();\n@@ -761,1 +769,1 @@\n-  InstanceKlass* s = java_super();\n+  InstanceKlass* s = super();\n@@ -763,1 +771,1 @@\n-          (s != nullptr && s->java_super() == vmClasses::Enum_klass()));\n+          (s != nullptr && s->super() == vmClasses::Enum_klass()));\n@@ -797,1 +805,1 @@\n-\/\/ Set the initialization lock to null so the object can be GC'ed.  Any racing\n+\/\/ Set the initialization lock to null so the object can be GC'ed. Any racing\n@@ -800,1 +808,2 @@\n-\/\/ the lock and return.\n+\/\/ the lock and return. For preempted vthreads we keep the oop protected\n+\/\/ in the ObjectMonitor (see ObjectMonitor::set_object_strong()).\n@@ -808,0 +817,25 @@\n+class PreemptableInitCall {\n+  JavaThread* _thread;\n+  bool _previous;\n+  DEBUG_ONLY(InstanceKlass* _previous_klass;)\n+ public:\n+  PreemptableInitCall(JavaThread* thread, InstanceKlass* ik) : _thread(thread) {\n+    _previous = thread->at_preemptable_init();\n+    _thread->set_at_preemptable_init(true);\n+    DEBUG_ONLY(_previous_klass = _thread->preempt_init_klass();)\n+    DEBUG_ONLY(_thread->set_preempt_init_klass(ik));\n+  }\n+  ~PreemptableInitCall() {\n+    _thread->set_at_preemptable_init(_previous);\n+    DEBUG_ONLY(_thread->set_preempt_init_klass(_previous_klass));\n+  }\n+};\n+\n+void InstanceKlass::initialize_preemptable(TRAPS) {\n+  if (this->should_be_initialized()) {\n+    PreemptableInitCall pic(THREAD, this);\n+    initialize_impl(THREAD);\n+  } else {\n+    assert(is_initialized(), \"sanity check\");\n+  }\n+}\n@@ -827,1 +861,1 @@\n-  InstanceKlass* s = java_super();\n+  InstanceKlass* s = super();\n@@ -940,1 +974,1 @@\n-  Klass* super_klass = super();\n+  InstanceKlass* super_klass = super();\n@@ -955,2 +989,1 @@\n-    InstanceKlass* ik_super = InstanceKlass::cast(super_klass);\n-    ik_super->link_class_impl(CHECK_false);\n+    super_klass->link_class_impl(CHECK_false);\n@@ -985,1 +1018,6 @@\n-    ObjectLocker ol(h_init_lock, jt);\n+    ObjectLocker ol(h_init_lock, CHECK_PREEMPTABLE_false);\n+    \/\/ Don't allow preemption if we link\/initialize classes below,\n+    \/\/ since that would release this monitor while we are in the\n+    \/\/ middle of linking this class.\n+    NoPreemptMark npm(THREAD);\n+\n@@ -993,1 +1031,1 @@\n-        if (is_shared()) {\n+        if (in_aot_cache()) {\n@@ -1012,1 +1050,1 @@\n-      } else if (is_shared()) {\n+      } else if (in_aot_cache()) {\n@@ -1030,1 +1068,1 @@\n-      if (is_shared() && verified_at_dump_time() &&\n+      if (in_aot_cache() && verified_at_dump_time() &&\n@@ -1072,1 +1110,1 @@\n-    assert(is_shared(), \"rewriting an unshared class?\");\n+    assert(in_aot_cache(), \"rewriting an unshared class?\");\n@@ -1114,1 +1152,1 @@\n-using InitializationErrorTable = ResourceHashtable<const InstanceKlass*, OopHandle, 107, AnyObj::C_HEAP, mtClass>;\n+using InitializationErrorTable = HashTable<const InstanceKlass*, OopHandle, 107, AnyObj::C_HEAP, mtClass>;\n@@ -1179,0 +1217,11 @@\n+class ThreadWaitingForClassInit : public StackObj {\n+  JavaThread* _thread;\n+ public:\n+  ThreadWaitingForClassInit(JavaThread* thread, InstanceKlass* ik) : _thread(thread) {\n+    _thread->set_class_to_be_initialized(ik);\n+  }\n+  ~ThreadWaitingForClassInit() {\n+    _thread->set_class_to_be_initialized(nullptr);\n+  }\n+};\n+\n@@ -1198,1 +1247,1 @@\n-    ObjectLocker ol(h_init_lock, jt);\n+    ObjectLocker ol(h_init_lock, CHECK_PREEMPTABLE);\n@@ -1211,3 +1260,2 @@\n-      jt->set_class_to_be_initialized(this);\n-      ol.wait_uninterruptibly(jt);\n-      jt->set_class_to_be_initialized(nullptr);\n+      ThreadWaitingForClassInit twcl(THREAD, this);\n+      ol.wait_uninterruptibly(CHECK_PREEMPTABLE);\n@@ -1271,0 +1319,4 @@\n+  \/\/ Block preemption once we are the initializer thread. Unmounting now\n+  \/\/ would complicate the reentrant case (identity is platform thread).\n+  NoPreemptMark npm(THREAD);\n+\n@@ -1412,1 +1464,1 @@\n-    InstanceKlass* ikls = Atomic::load_acquire(ik);\n+    InstanceKlass* ikls = AtomicAccess::load_acquire(ik);\n@@ -1428,1 +1480,1 @@\n-    Atomic::release_store(addr, ik);\n+    AtomicAccess::release_store(addr, ik);\n@@ -1464,1 +1516,1 @@\n-  InstanceKlass* super_ik = ik->java_super();\n+  InstanceKlass* super_ik = ik->super();\n@@ -1560,9 +1612,0 @@\n-objArrayOop InstanceKlass::allocate_objArray(int n, int length, TRAPS) {\n-  check_array_allocation_length(length, arrayOopDesc::max_array_length(T_OBJECT), CHECK_NULL);\n-  size_t size = objArrayOopDesc::object_size(length);\n-  ArrayKlass* ak = array_klass(n, CHECK_NULL);\n-  objArrayOop o = (objArrayOop)Universe::heap()->array_allocate(ak, size, length,\n-                                                                \/* do_zero *\/ true, CHECK_NULL);\n-  return o;\n-}\n-\n@@ -1684,1 +1727,1 @@\n-    assert(is_shared(), \"must be\");\n+    assert(in_aot_cache(), \"must be\");\n@@ -1758,1 +1801,1 @@\n-  OopMapCache* oop_map_cache = Atomic::load_acquire(&_oop_map_cache);\n+  OopMapCache* oop_map_cache = AtomicAccess::load_acquire(&_oop_map_cache);\n@@ -1762,1 +1805,1 @@\n-    OopMapCache* other = Atomic::cmpxchg(&_oop_map_cache, (OopMapCache*)nullptr, oop_map_cache);\n+    OopMapCache* other = AtomicAccess::cmpxchg(&_oop_map_cache, (OopMapCache*)nullptr, oop_map_cache);\n@@ -1789,7 +1832,6 @@\n-  for (JavaFieldStream fs(this); !fs.done(); fs.next()) {\n-    Symbol* f_name = fs.name();\n-    Symbol* f_sig  = fs.signature();\n-    if (f_name == name && f_sig == sig) {\n-      fd->reinitialize(const_cast<InstanceKlass*>(this), fs.to_FieldInfo());\n-      return true;\n-    }\n+  JavaFieldStream fs(this);\n+  if (fs.lookup(name, sig)) {\n+    assert(fs.name() == name, \"name must match\");\n+    assert(fs.signature() == sig, \"signature must match\");\n+    fd->reinitialize(const_cast<InstanceKlass*>(this), fs.to_FieldInfo());\n+    return true;\n@@ -1804,1 +1846,1 @@\n-    Klass* intf1 = local_interfaces()->at(i);\n+    InstanceKlass* intf1 = local_interfaces()->at(i);\n@@ -1807,1 +1849,1 @@\n-    if (InstanceKlass::cast(intf1)->find_local_field(name, sig, fd)) {\n+    if (intf1->find_local_field(name, sig, fd)) {\n@@ -1812,1 +1854,1 @@\n-    Klass* intf2 = InstanceKlass::cast(intf1)->find_interface_field(name, sig, fd);\n+    Klass* intf2 = intf1->find_interface_field(name, sig, fd);\n@@ -1831,2 +1873,2 @@\n-  { Klass* supr = super();\n-    if (supr != nullptr) return InstanceKlass::cast(supr)->find_field(name, sig, fd);\n+  { InstanceKlass* supr = super();\n+    if (supr != nullptr) return supr->find_field(name, sig, fd);\n@@ -1851,2 +1893,2 @@\n-  { Klass* supr = super();\n-    if (supr != nullptr) return InstanceKlass::cast(supr)->find_field(name, sig, is_static, fd);\n+  { InstanceKlass* supr = super();\n+    if (supr != nullptr) return supr->find_field(name, sig, is_static, fd);\n@@ -1871,1 +1913,1 @@\n-  Klass* klass = const_cast<InstanceKlass*>(this);\n+  const InstanceKlass* klass = this;\n@@ -1873,1 +1915,1 @@\n-    if (InstanceKlass::cast(klass)->find_local_field_from_offset(offset, is_static, fd)) {\n+    if (klass->find_local_field_from_offset(offset, is_static, fd)) {\n@@ -1919,1 +1961,1 @@\n-  InstanceKlass* super = superklass();\n+  InstanceKlass* super = this->super();\n@@ -1936,1 +1978,1 @@\n-  InstanceKlass* super = superklass();\n+  InstanceKlass* super = this->super();\n@@ -2231,1 +2273,1 @@\n-  const Klass* klass = this;\n+  const InstanceKlass* klass = this;\n@@ -2233,5 +2275,5 @@\n-    Method* const method = InstanceKlass::cast(klass)->find_method_impl(name,\n-                                                                        signature,\n-                                                                        overpass_local_mode,\n-                                                                        StaticLookupMode::find,\n-                                                                        private_mode);\n+    Method* const method = klass->find_method_impl(name,\n+                                                   signature,\n+                                                   overpass_local_mode,\n+                                                   StaticLookupMode::find,\n+                                                   private_mode);\n@@ -2251,1 +2293,1 @@\n-  const Klass* klass = this;\n+  const InstanceKlass* klass = this;\n@@ -2253,1 +2295,1 @@\n-    if (InstanceKlass::cast(klass)->has_been_redefined()) {\n+    if (klass->has_been_redefined()) {\n@@ -2330,1 +2372,1 @@\n-    if (ik->is_shared()) buf[i++] = 'S';\n+    if (ik->in_aot_cache()) buf[i++] = 'S';\n@@ -2390,1 +2432,1 @@\n-  Atomic::release_store(&jmeths[idnum + 1], new_id);\n+  AtomicAccess::release_store(&jmeths[idnum + 1], new_id);\n@@ -2394,0 +2436,18 @@\n+\/\/ Allocate the jmethodID cache.\n+static jmethodID* create_jmethod_id_cache(size_t size) {\n+  jmethodID* jmeths = NEW_C_HEAP_ARRAY(jmethodID, size + 1, mtClass);\n+  memset(jmeths, 0, (size + 1) * sizeof(jmethodID));\n+  \/\/ cache size is stored in element[0], other elements offset by one\n+  jmeths[0] = (jmethodID)size;\n+  return jmeths;\n+}\n+\n+\/\/ When reading outside a lock, use this.\n+jmethodID* InstanceKlass::methods_jmethod_ids_acquire() const {\n+  return AtomicAccess::load_acquire(&_methods_jmethod_ids);\n+}\n+\n+void InstanceKlass::release_set_methods_jmethod_ids(jmethodID* jmeths) {\n+  AtomicAccess::release_store(&_methods_jmethod_ids, jmeths);\n+}\n+\n@@ -2395,6 +2455,1 @@\n-\/\/ This code is called by the VMThread and JavaThreads so the\n-\/\/ locking has to be done very carefully to avoid deadlocks\n-\/\/ and\/or other cache consistency problems.\n-\/\/\n-jmethodID InstanceKlass::get_jmethod_id(const methodHandle& method_h) {\n-  Method* method = method_h();\n+jmethodID InstanceKlass::get_jmethod_id(Method* method) {\n@@ -2421,1 +2476,1 @@\n-    jmeths = methods_jmethod_ids_acquire();\n+    jmeths = _methods_jmethod_ids;\n@@ -2426,4 +2481,1 @@\n-      jmeths = NEW_C_HEAP_ARRAY(jmethodID, size + 1, mtClass);\n-      memset(jmeths, 0, (size + 1) * sizeof(jmethodID));\n-      \/\/ cache size is stored in element[0], other elements offset by one\n-      jmeths[0] = (jmethodID)size;\n+      jmeths = create_jmethod_id_cache(size);\n@@ -2438,1 +2490,1 @@\n-  jmethodID id = Atomic::load_acquire(&jmeths[idnum + 1]);\n+  jmethodID id = AtomicAccess::load_acquire(&jmeths[idnum + 1]);\n@@ -2459,4 +2511,1 @@\n-      jmethodID* new_cache = NEW_C_HEAP_ARRAY(jmethodID, size + 1, mtClass);\n-      memset(new_cache, 0, (size + 1) * sizeof(jmethodID));\n-      \/\/ The cache size is stored in element[0]; the other elements are offset by one.\n-      new_cache[0] = (jmethodID)size;\n+      jmethodID* new_cache = create_jmethod_id_cache(size);\n@@ -2473,3 +2522,2 @@\n-\/\/ Figure out how many jmethodIDs haven't been allocated, and make\n-\/\/ sure space for them is pre-allocated.  This makes getting all\n-\/\/ method ids much, much faster with classes with more than 8\n+\/\/ Make a jmethodID for all methods in this class.  This makes getting all method\n+\/\/ ids much, much faster with classes with more than 8\n@@ -2478,2 +2526,8 @@\n-void InstanceKlass::ensure_space_for_methodids(int start_offset) {\n-  int new_jmeths = 0;\n+void InstanceKlass::make_methods_jmethod_ids() {\n+  MutexLocker ml(JmethodIdCreation_lock, Mutex::_no_safepoint_check_flag);\n+  jmethodID* jmeths = _methods_jmethod_ids;\n+  if (jmeths == nullptr) {\n+    jmeths = create_jmethod_id_cache(idnum_allocated_count());\n+    release_set_methods_jmethod_ids(jmeths);\n+  }\n+\n@@ -2481,1 +2535,1 @@\n-  for (int index = start_offset; index < length; index++) {\n+  for (int index = 0; index < length; index++) {\n@@ -2483,3 +2537,7 @@\n-    jmethodID id = m->find_jmethod_id_or_null();\n-    if (id == nullptr) {\n-      new_jmeths++;\n+    int idnum = m->method_idnum();\n+    assert(!m->is_old(), \"should not have old methods or I'm confused\");\n+    jmethodID id = AtomicAccess::load_acquire(&jmeths[idnum + 1]);\n+    if (!m->is_overpass() &&  \/\/ skip overpasses\n+        id == nullptr) {\n+      id = Method::make_jmethod_id(class_loader_data(), m);\n+      AtomicAccess::release_store(&jmeths[idnum + 1], id);\n@@ -2488,3 +2546,0 @@\n-  if (new_jmeths != 0) {\n-    Method::ensure_jmethod_ids(class_loader_data(), new_jmeths);\n-  }\n@@ -2541,1 +2596,1 @@\n-      InstanceKlass* impl = Atomic::load_acquire(iklass);\n+      InstanceKlass* impl = AtomicAccess::load_acquire(iklass);\n@@ -2544,1 +2599,1 @@\n-        if (Atomic::cmpxchg(iklass, impl, (InstanceKlass*)nullptr) == impl) {\n+        if (AtomicAccess::cmpxchg(iklass, impl, (InstanceKlass*)nullptr) == impl) {\n@@ -2613,0 +2668,1 @@\n+  it->push(&_fieldinfo_search_table);\n@@ -2713,0 +2769,2 @@\n+\n+  DEBUG_ONLY(FieldInfoStream::validate_search_table(_constants, _fieldinfo_stream, _fieldinfo_search_table));\n@@ -2747,1 +2805,1 @@\n-             MetaspaceShared::is_in_shared_metaspace(_package_entry)) {\n+             AOTMetaspace::in_aot_cache(_package_entry)) {\n@@ -2819,0 +2877,2 @@\n+\n+  DEBUG_ONLY(FieldInfoStream::validate_search_table(_constants, _fieldinfo_stream, _fieldinfo_search_table));\n@@ -2821,6 +2881,1 @@\n-\/\/ Check if a class or any of its supertypes has a version older than 50.\n-\/\/ CDS will not perform verification of old classes during dump time because\n-\/\/ without changing the old verifier, the verification constraint cannot be\n-\/\/ retrieved during dump time.\n-\/\/ Verification of archived old classes will be performed during run time.\n-  if (MetaspaceShared::is_in_shared_metaspace(this)) {\n+  if (CDSConfig::is_dumping_dynamic_archive() && AOTMetaspace::in_aot_cache(this)) {\n@@ -2832,1 +2887,8 @@\n-  if (major_version() < 50 \/*JAVA_6_VERSION*\/) {\n+\n+  if (CDSConfig::is_preserving_verification_constraints()) {\n+    return true;\n+  }\n+\n+  if (CDSConfig::is_old_class_for_verifier(this)) {\n+    \/\/ The old verifier does not save verification constraints, so at run time\n+    \/\/ SystemDictionaryShared::check_verification_constraints() will not work for this class.\n@@ -2835,1 +2897,1 @@\n-  if (java_super() != nullptr && !java_super()->can_be_verified_at_dumptime()) {\n+  if (super() != nullptr && !super()->can_be_verified_at_dumptime()) {\n@@ -2917,1 +2979,1 @@\n-  jmethodID* jmeths = methods_jmethod_ids_acquire();\n+  jmethodID* jmeths = _methods_jmethod_ids;\n@@ -3063,1 +3125,1 @@\n-  if (!is_shared()) {\n+  if (!in_aot_cache()) {\n@@ -3067,1 +3129,1 @@\n-  if (is_shared() && _package_entry != nullptr) {\n+  if (in_aot_cache() && _package_entry != nullptr) {\n@@ -3070,1 +3132,1 @@\n-      assert(MetaspaceShared::is_in_shared_metaspace(_package_entry), \"must be\");\n+      assert(AOTMetaspace::in_aot_cache(_package_entry), \"must be\");\n@@ -3495,1 +3557,1 @@\n-      inv->make_not_entrant(\"OSR invalidation of lower levels\", false \/* already being replaced *\/);\n+      inv->make_not_entrant(nmethod::InvalidationReason::OSR_INVALIDATION_OF_LOWER_LEVEL, false \/* already being replaced *\/);\n@@ -3763,0 +3825,5 @@\n+\n+  if (fieldinfo_search_table() != nullptr) {\n+    st->print_cr(BULLET\"---- field info search table:\");\n+    FieldInfoStream::print_search_table(st, _constants, _fieldinfo_stream, _fieldinfo_search_table);\n+  }\n@@ -3947,2 +4014,2 @@\n-    assert(this->is_shared(), \"must be\");\n-    if (MetaspaceShared::is_shared_dynamic((void*)this)) {\n+    assert(this->in_aot_cache(), \"must be\");\n+    if (AOTMetaspace::in_aot_cache_dynamic_region((void*)this)) {\n@@ -3962,1 +4029,1 @@\n-                       p2i(this),  p2i(superklass()));\n+                       p2i(this),  p2i(super()));\n@@ -3970,1 +4037,1 @@\n-                           p2i(InstanceKlass::cast(local_interfaces()->at(i))));\n+                           p2i(local_interfaces()->at(i)));\n@@ -4183,1 +4250,0 @@\n-\n@@ -4188,1 +4254,1 @@\n-JNIid::JNIid(Klass* holder, int offset, JNIid* next) {\n+JNIid::JNIid(InstanceKlass* holder, int offset, JNIid* next) {\n@@ -4195,1 +4261,0 @@\n-\n@@ -4213,2 +4278,1 @@\n-\n-void JNIid::verify(Klass* holder) {\n+void JNIid::verify(InstanceKlass* holder) {\n@@ -4217,1 +4281,1 @@\n-  end_field_offset = first_field_offset + (InstanceKlass::cast(holder)->static_field_size() * wordSize);\n+  end_field_offset = first_field_offset + (holder->static_field_size() * wordSize);\n@@ -4234,1 +4298,1 @@\n-  bool good_state = is_shared() ? (_init_state <= state)\n+  bool good_state = in_aot_cache() ? (_init_state <= state)\n@@ -4239,1 +4303,1 @@\n-  Atomic::release_store(&_init_state, state);\n+  AtomicAccess::release_store(&_init_state, state);\n@@ -4264,8 +4328,4 @@\n-\/\/ This nulls out jmethodIDs for all methods in 'klass'\n-\/\/ It needs to be called explicitly for all previous versions of a class because these may not be cleaned up\n-\/\/ during class unloading.\n-\/\/ We can not use the jmethodID cache associated with klass directly because the 'previous' versions\n-\/\/ do not have the jmethodID cache filled in. Instead, we need to lookup jmethodID for each method and this\n-\/\/ is expensive - O(n) for one jmethodID lookup. For all contained methods it is O(n^2).\n-\/\/ The reason for expensive jmethodID lookup for each method is that there is no direct link between method and jmethodID.\n-void InstanceKlass::clear_jmethod_ids(InstanceKlass* klass) {\n+\/\/ This nulls out the jmethodID for all obsolete methods in the previous version of the 'klass'.\n+\/\/ These obsolete methods only exist in the previous version and we're about to delete the memory for them.\n+\/\/ The jmethodID for these are deallocated when we unload the class, so this doesn't remove them from the table.\n+void InstanceKlass::clear_obsolete_jmethod_ids(InstanceKlass* klass) {\n@@ -4275,0 +4335,1 @@\n+    \/\/ Only need to clear obsolete methods.\n@@ -4324,1 +4385,1 @@\n-      clear_jmethod_ids(pv_node); \/\/ jmethodID maintenance for the unloaded class\n+      clear_obsolete_jmethod_ids(pv_node); \/\/ jmethodID maintenance for the unloaded class\n@@ -4338,1 +4399,1 @@\n-      if (pvcp->is_shared()) {\n+      if (pvcp->in_aot_cache()) {\n@@ -4450,1 +4511,1 @@\n-  if (cp_ref->is_shared()) {\n+  if (cp_ref->in_aot_cache()) {\n@@ -4533,1 +4594,1 @@\n-    _current = _current->superklass(); \/\/ backtrack; no more sibling subclasses left\n+    _current = _current->java_super(); \/\/ backtrack; no more sibling subclasses left\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":231,"deletions":170,"binary":false,"changes":401,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -27,1 +28,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -39,0 +39,1 @@\n+#include \"interpreter\/bytecodes.hpp\"\n@@ -41,1 +42,0 @@\n-#include \"interpreter\/bytecodes.hpp\"\n@@ -54,1 +54,2 @@\n-#include \"oops\/constMethod.hpp\"\n+#include \"oops\/constMethod.hpp\"\n+#include \"oops\/jmethodIDTable.hpp\"\n@@ -66,1 +67,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -154,0 +155,3 @@\n+  if (is_abstract()) {\n+    return SharedRuntime::throw_AbstractMethodError_entry();\n+  }\n@@ -159,0 +163,3 @@\n+  if (is_abstract()) {\n+    return SharedRuntime::get_handle_wrong_method_abstract_stub();\n+  }\n@@ -164,0 +171,3 @@\n+  if (is_abstract()) {\n+    return SharedRuntime::get_handle_wrong_method_abstract_stub();\n+  }\n@@ -169,0 +179,3 @@\n+  if (is_abstract()) {\n+    return nullptr;\n+  }\n@@ -442,1 +455,1 @@\n-  if (is_shared() && !MetaspaceShared::remapped_readwrite() && method_holder()->verified_at_dump_time()) {\n+  if (in_aot_cache() && !AOTMetaspace::remapped_readwrite() && method_holder()->verified_at_dump_time()) {\n@@ -453,1 +466,1 @@\n-  if (is_shared() && !MetaspaceShared::remapped_readwrite() && method_holder()->verified_at_dump_time()) {\n+  if (in_aot_cache() && !AOTMetaspace::remapped_readwrite() && method_holder()->verified_at_dump_time()) {\n@@ -629,1 +642,1 @@\n-    Atomic::replace_if_null(&method->_method_data, mtd->final_profile());\n+    AtomicAccess::replace_if_null(&method->_method_data, mtd->final_profile());\n@@ -656,1 +669,1 @@\n-  if (!Atomic::replace_if_null(&method->_method_data, method_data)) {\n+  if (!AtomicAccess::replace_if_null(&method->_method_data, method_data)) {\n@@ -707,1 +720,1 @@\n-  return Atomic::replace_if_null(&_method_counters, counters);\n+  return AtomicAccess::replace_if_null(&_method_counters, counters);\n@@ -1031,1 +1044,1 @@\n-    nm->make_not_entrant(\"set native function\", false \/* replaced by native function *\/);\n+    nm->make_not_entrant(nmethod::InvalidationReason::SET_NATIVE_FUNCTION, false \/* replaced by native function *\/);\n@@ -1167,1 +1180,1 @@\n-    _from_compiled_entry    = nullptr;\n+    _from_compiled_entry = nullptr;\n@@ -1169,1 +1182,1 @@\n-    _from_compiled_entry    = adapter()->get_c2i_entry();\n+    _from_compiled_entry = adapter()->get_c2i_entry();\n@@ -1198,1 +1211,1 @@\n-  if (!CDSConfig::is_dumping_adapters() || AdapterHandlerLibrary::is_abstract_method_adapter(_adapter)) {\n+  if (!CDSConfig::is_dumping_adapters()) {\n@@ -1247,1 +1260,1 @@\n-    if (adapter()->is_shared()) {\n+    if (adapter()->in_aot_cache()) {\n@@ -1279,1 +1292,3 @@\n-  if (_adapter == nullptr) {\n+  if (is_abstract()) {\n+    h_method->_from_compiled_entry = SharedRuntime::get_handle_wrong_method_abstract_stub();\n+  } else if (_adapter == nullptr) {\n@@ -1281,0 +1296,1 @@\n+#ifndef ZERO\n@@ -1282,0 +1298,2 @@\n+#endif\n+    h_method->_from_compiled_entry = adapter()->get_c2i_entry();\n@@ -1302,0 +1320,1 @@\n+  assert(!mh->is_abstract(), \"abstract methods do not have adapters\");\n@@ -1320,1 +1339,0 @@\n-  mh->_from_compiled_entry = adapter->get_c2i_entry();\n@@ -1342,1 +1360,1 @@\n-  nmethod *code = Atomic::load_acquire(&_code);\n+  nmethod *code = AtomicAccess::load_acquire(&_code);\n@@ -1382,1 +1400,1 @@\n-    Atomic::release_store(&mh->_from_interpreted_entry , mh->get_i2c_entry());\n+    AtomicAccess::release_store(&mh->_from_interpreted_entry , mh->get_i2c_entry());\n@@ -2062,146 +2080,3 @@\n-\n-\/\/ This is a block allocating object, sort of like JNIHandleBlock, only a\n-\/\/ lot simpler.\n-\/\/ It's allocated on the CHeap because once we allocate a jmethodID, we can\n-\/\/ never get rid of it.\n-\n-static const int min_block_size = 8;\n-\n-class JNIMethodBlockNode : public CHeapObj<mtClass> {\n-  friend class JNIMethodBlock;\n-  Method**        _methods;\n-  int             _number_of_methods;\n-  int             _top;\n-  JNIMethodBlockNode* _next;\n-\n- public:\n-\n-  JNIMethodBlockNode(int num_methods = min_block_size);\n-\n-  ~JNIMethodBlockNode() { FREE_C_HEAP_ARRAY(Method*, _methods); }\n-\n-  void ensure_methods(int num_addl_methods) {\n-    if (_top < _number_of_methods) {\n-      num_addl_methods -= _number_of_methods - _top;\n-      if (num_addl_methods <= 0) {\n-        return;\n-      }\n-    }\n-    if (_next == nullptr) {\n-      _next = new JNIMethodBlockNode(MAX2(num_addl_methods, min_block_size));\n-    } else {\n-      _next->ensure_methods(num_addl_methods);\n-    }\n-  }\n-};\n-\n-class JNIMethodBlock : public CHeapObj<mtClass> {\n-  JNIMethodBlockNode _head;\n-  JNIMethodBlockNode *_last_free;\n- public:\n-  static Method* const _free_method;\n-\n-  JNIMethodBlock(int initial_capacity = min_block_size)\n-      : _head(initial_capacity), _last_free(&_head) {}\n-\n-  void ensure_methods(int num_addl_methods) {\n-    _last_free->ensure_methods(num_addl_methods);\n-  }\n-\n-  Method** add_method(Method* m) {\n-    for (JNIMethodBlockNode* b = _last_free; b != nullptr; b = b->_next) {\n-      if (b->_top < b->_number_of_methods) {\n-        \/\/ top points to the next free entry.\n-        int i = b->_top;\n-        b->_methods[i] = m;\n-        b->_top++;\n-        _last_free = b;\n-        return &(b->_methods[i]);\n-      } else if (b->_top == b->_number_of_methods) {\n-        \/\/ if the next free entry ran off the block see if there's a free entry\n-        for (int i = 0; i < b->_number_of_methods; i++) {\n-          if (b->_methods[i] == _free_method) {\n-            b->_methods[i] = m;\n-            _last_free = b;\n-            return &(b->_methods[i]);\n-          }\n-        }\n-        \/\/ Only check each block once for frees.  They're very unlikely.\n-        \/\/ Increment top past the end of the block.\n-        b->_top++;\n-      }\n-      \/\/ need to allocate a next block.\n-      if (b->_next == nullptr) {\n-        b->_next = _last_free = new JNIMethodBlockNode();\n-      }\n-    }\n-    guarantee(false, \"Should always allocate a free block\");\n-    return nullptr;\n-  }\n-\n-  bool contains(Method** m) {\n-    if (m == nullptr) return false;\n-    for (JNIMethodBlockNode* b = &_head; b != nullptr; b = b->_next) {\n-      if (b->_methods <= m && m < b->_methods + b->_number_of_methods) {\n-        \/\/ This is a bit of extra checking, for two reasons.  One is\n-        \/\/ that contains() deals with pointers that are passed in by\n-        \/\/ JNI code, so making sure that the pointer is aligned\n-        \/\/ correctly is valuable.  The other is that <= and > are\n-        \/\/ technically not defined on pointers, so the if guard can\n-        \/\/ pass spuriously; no modern compiler is likely to make that\n-        \/\/ a problem, though (and if one did, the guard could also\n-        \/\/ fail spuriously, which would be bad).\n-        ptrdiff_t idx = m - b->_methods;\n-        if (b->_methods + idx == m) {\n-          return true;\n-        }\n-      }\n-    }\n-    return false;  \/\/ not found\n-  }\n-\n-  \/\/ During class unloading the methods are cleared, which is different\n-  \/\/ than freed.\n-  void clear_all_methods() {\n-    for (JNIMethodBlockNode* b = &_head; b != nullptr; b = b->_next) {\n-      for (int i = 0; i< b->_number_of_methods; i++) {\n-        b->_methods[i] = nullptr;\n-      }\n-    }\n-  }\n-#ifndef PRODUCT\n-  int count_methods() {\n-    \/\/ count all allocated methods\n-    int count = 0;\n-    for (JNIMethodBlockNode* b = &_head; b != nullptr; b = b->_next) {\n-      for (int i = 0; i< b->_number_of_methods; i++) {\n-        if (b->_methods[i] != _free_method) count++;\n-      }\n-    }\n-    return count;\n-  }\n-#endif \/\/ PRODUCT\n-};\n-\n-\/\/ Something that can't be mistaken for an address or a markWord\n-Method* const JNIMethodBlock::_free_method = (Method*)55;\n-\n-JNIMethodBlockNode::JNIMethodBlockNode(int num_methods) : _top(0), _next(nullptr) {\n-  _number_of_methods = MAX2(num_methods, min_block_size);\n-  _methods = NEW_C_HEAP_ARRAY(Method*, _number_of_methods, mtInternal);\n-  for (int i = 0; i < _number_of_methods; i++) {\n-    _methods[i] = JNIMethodBlock::_free_method;\n-  }\n-}\n-\n-void Method::ensure_jmethod_ids(ClassLoaderData* cld, int capacity) {\n-  \/\/ Have to add jmethod_ids() to class loader data thread-safely.\n-  \/\/ Also have to add the method to the list safely, which the lock\n-  \/\/ protects as well.\n-  MutexLocker ml(JmethodIdCreation_lock,  Mutex::_no_safepoint_check_flag);\n-  if (cld->jmethod_ids() == nullptr) {\n-    cld->set_jmethod_ids(new JNIMethodBlock(capacity));\n-  } else {\n-    cld->jmethod_ids()->ensure_methods(capacity);\n-  }\n-}\n+\/\/ jmethodIDs are 64-bit integers that will never run out and are mapped in a table\n+\/\/ to their Method and vice versa.  If JNI code has access to stale jmethodID, this\n+\/\/ wastes no memory but the Method* returned is null.\n@@ -2212,1 +2087,1 @@\n-  \/\/ Also have to add the method to the list safely, which the lock\n+  \/\/ Also have to add the method to the InstanceKlass list safely, which the lock\n@@ -2215,0 +2090,2 @@\n+  jmethodID jmid = JmethodIDTable::make_jmethod_id(m);\n+  assert(jmid != nullptr, \"must be created\");\n@@ -2216,7 +2093,3 @@\n-  ResourceMark rm;\n-  log_debug(jmethod)(\"Creating jmethodID for Method %s\", m->external_name());\n-  if (cld->jmethod_ids() == nullptr) {\n-    cld->set_jmethod_ids(new JNIMethodBlock());\n-  }\n-  \/\/ jmethodID is a pointer to Method*\n-  return (jmethodID)cld->jmethod_ids()->add_method(m);\n+  \/\/ Add to growable array in CLD.\n+  cld->add_jmethod_id(jmid);\n+  return jmid;\n@@ -2225,0 +2098,1 @@\n+\/\/ This looks in the InstanceKlass cache, then calls back to make_jmethod_id if not found.\n@@ -2226,2 +2100,7 @@\n-  methodHandle mh(Thread::current(), this);\n-  return method_holder()->get_jmethod_id(mh);\n+  return method_holder()->get_jmethod_id(this);\n+}\n+\n+\/\/ Get the Method out of the table given the method id.\n+Method* Method::resolve_jmethod_id(jmethodID mid) {\n+  assert(mid != nullptr, \"JNI method id should not be null\");\n+  return JmethodIDTable::resolve_jmethod_id(mid);\n@@ -2235,1 +2114,1 @@\n-           new_method->method_holder()->class_loader() == nullptr, \/\/ allow Unsafe substitution\n+         new_method->method_holder()->class_loader() == nullptr, \/\/ allow substitution to Unsafe method\n@@ -2237,2 +2116,11 @@\n-  \/\/ Just change the method in place, jmethodID pointer doesn't change.\n-  *((Method**)jmid) = new_method;\n+  JmethodIDTable::change_method_associated_with_jmethod_id(jmid, new_method);\n+}\n+\n+\/\/ If there's a jmethodID for this method, clear the Method\n+\/\/ but leave jmethodID for this method in the table.\n+\/\/ It's deallocated with class unloading.\n+void Method::clear_jmethod_id() {\n+  jmethodID mid = method_holder()->jmethod_id_or_null(this);\n+  if (mid != nullptr) {\n+    JmethodIDTable::clear_jmethod_id(mid, this);\n+  }\n@@ -2241,1 +2129,1 @@\n-bool Method::is_method_id(jmethodID mid) {\n+bool Method::validate_jmethod_id(jmethodID mid) {\n@@ -2247,1 +2135,1 @@\n-  return (cld->jmethod_ids()->contains((Method**)mid));\n+  return (cld->jmethod_ids()->contains(mid));\n@@ -2253,1 +2141,1 @@\n-  if (o == nullptr || o == JNIMethodBlock::_free_method) {\n+  if (o == nullptr) {\n@@ -2262,1 +2150,1 @@\n-};\n+}\n@@ -2283,19 +2171,0 @@\n-\/\/ Called when the class loader is unloaded to make all methods weak.\n-void Method::clear_jmethod_ids(ClassLoaderData* loader_data) {\n-  loader_data->jmethod_ids()->clear_all_methods();\n-}\n-\n-void Method::clear_jmethod_id() {\n-  \/\/ Being at a safepoint prevents racing against other class redefinitions\n-  assert(SafepointSynchronize::is_at_safepoint(), \"should be at safepoint\");\n-  \/\/ The jmethodID is not stored in the Method instance, we need to look it up first\n-  jmethodID methodid = find_jmethod_id_or_null();\n-  \/\/ We need to make sure that jmethodID actually resolves to this method\n-  \/\/ - multiple redefined versions may share jmethodID slots and if a method\n-  \/\/   has already been rewired to a newer version we could be removing reference\n-  \/\/   to a still existing method instance\n-  if (methodid != nullptr && *((Method**)methodid) == this) {\n-    *((Method**)methodid) = nullptr;\n-  }\n-}\n-\n@@ -2317,1 +2186,1 @@\n-  } else if (m->is_shared()) {\n+  } else if (m->in_aot_cache()) {\n@@ -2326,7 +2195,0 @@\n-#ifndef PRODUCT\n-void Method::print_jmethod_ids_count(const ClassLoaderData* loader_data, outputStream* out) {\n-  out->print(\"%d\", loader_data->jmethod_ids()->count_methods());\n-}\n-#endif \/\/ PRODUCT\n-\n-\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":70,"deletions":208,"binary":false,"changes":278,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -35,1 +36,0 @@\n-#include \"classfile\/classLoaderData.hpp\"\n@@ -64,1 +64,0 @@\n-#include \"oops\/recordComponent.hpp\"\n@@ -68,0 +67,1 @@\n+#include \"oops\/recordComponent.hpp\"\n@@ -74,1 +74,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -78,0 +78,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -80,0 +81,1 @@\n+#include \"runtime\/handshake.hpp\"\n@@ -82,2 +84,0 @@\n-#include \"runtime\/deoptimization.hpp\"\n-#include \"runtime\/handshake.hpp\"\n@@ -89,0 +89,1 @@\n+#include \"runtime\/mountUnmountDisabler.hpp\"\n@@ -97,1 +98,1 @@\n-#include \"runtime\/vmOperations.hpp\"\n+#include \"runtime\/vmOperations.hpp\"\n@@ -233,0 +234,13 @@\n+JVM_ENTRY(jboolean, JVM_AOTEndRecording(JNIEnv *env))\n+#if INCLUDE_CDS\n+  if (CDSConfig::is_dumping_preimage_static_archive()) {\n+    if (!AOTMetaspace::preimage_static_archive_dumped()) {\n+      AOTMetaspace::dump_static_archive(THREAD);\n+      return JNI_TRUE;\n+    }\n+  }\n+  return JNI_FALSE;\n+#else\n+  return JNI_FALSE;\n+#endif \/\/ INCLUDE_CDS\n+JVM_END\n@@ -804,4 +818,3 @@\n-\/\/ Find a class with this name in this loader, using the caller's protection domain.\n-JVM_ENTRY(jclass, JVM_FindClassFromCaller(JNIEnv* env, const char* name,\n-                                          jboolean init, jobject loader,\n-                                          jclass caller))\n+\/\/ Find a class with this name in this loader.\n+JVM_ENTRY(jclass, JVM_FindClassFromLoader(JNIEnv* env, const char* name,\n+                                          jboolean init, jobject loader))\n@@ -813,1 +826,0 @@\n-  oop from_class = JNIHandles::resolve(caller);\n@@ -832,7 +844,5 @@\n-  Klass* from_class = (from_class_oop == nullptr)\n-                           ? (Klass*)nullptr\n-                           : java_lang_Class::as_Klass(from_class_oop);\n-  oop class_loader = nullptr;\n-  if (from_class != nullptr) {\n-    class_loader = from_class->class_loader();\n-  }\n+  assert(from_class_oop != nullptr, \"must be\");\n+  Klass* from_class = java_lang_Class::as_Klass(from_class_oop);\n+  assert(from_class != nullptr, \"must be\");\n+  oop class_loader = from_class->class_loader();\n+\n@@ -845,3 +855,4 @@\n-    oop from_mirror = JNIHandles::resolve_non_null(from);\n-    Klass* from_class = java_lang_Class::as_Klass(from_mirror);\n-    const char * from_name = from_class->external_name();\n+    const char* from_name = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(from))->external_name();\n+    const char* to_name = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(result))->external_name();\n+    log_debug(class, resolve)(\"%s %s (verification)\", from_name, to_name);\n+  }\n@@ -849,4 +860,4 @@\n-    oop mirror = JNIHandles::resolve_non_null(result);\n-    Klass* to_class = java_lang_Class::as_Klass(mirror);\n-    const char * to = to_class->external_name();\n-    log_debug(class, resolve)(\"%s %s (verification)\", from_name, to);\n+#if INCLUDE_CDS\n+  if (CDSConfig::is_preserving_verification_constraints() && from_class->is_instance_klass()) {\n+    InstanceKlass* ik = InstanceKlass::cast(from_class);\n+    SystemDictionaryShared::add_old_verification_constraint(THREAD, ik, h_name);\n@@ -854,0 +865,1 @@\n+#endif\n@@ -916,2 +928,2 @@\n-  Klass* lookup_k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(lookup));\n-  \/\/ Lookup class must be a non-null instance\n+  InstanceKlass* lookup_k = java_lang_Class::as_InstanceKlass(JNIHandles::resolve_non_null(lookup));\n+  \/\/ Lookup class must not be a primitive class (whose mirror has a null Klass*)\n@@ -919,0 +931,1 @@\n+    \/\/ The error message is wrong. We come here only if lookup is a primitive class\n@@ -921,1 +934,0 @@\n-  assert(lookup_k->is_instance_klass(), \"Lookup class must be an instance klass\");\n@@ -932,1 +944,1 @@\n-    host_class = InstanceKlass::cast(lookup_k)->nest_host(CHECK_NULL);\n+    host_class = lookup_k->nest_host(CHECK_NULL);\n@@ -1182,1 +1194,1 @@\n-      Klass* k = InstanceKlass::cast(klass)->local_interfaces()->at(index);\n+      InstanceKlass* k = InstanceKlass::cast(klass)->local_interfaces()->at(index);\n@@ -1204,9 +1216,0 @@\n-class ScopedValueBindingsResolver {\n-public:\n-  InstanceKlass* Carrier_klass;\n-  ScopedValueBindingsResolver(JavaThread* THREAD) {\n-    Klass *k = SystemDictionary::resolve_or_fail(vmSymbols::java_lang_ScopedValue_Carrier(), true, THREAD);\n-    Carrier_klass = InstanceKlass::cast(k);\n-  }\n-};\n-\n@@ -1218,2 +1221,0 @@\n-  static ScopedValueBindingsResolver resolver(THREAD);\n-\n@@ -1232,1 +1233,1 @@\n-          || holder == resolver.Carrier_klass) {\n+          || holder == vmClasses::ScopedValue_Carrier_klass()) {\n@@ -1263,1 +1264,1 @@\n-  InstanceKlass* k = InstanceKlass::cast(java_lang_Class::as_Klass(ofMirror));\n+  InstanceKlass* k = java_lang_Class::as_InstanceKlass(ofMirror);\n@@ -1402,1 +1403,0 @@\n-  Klass* k    = java_lang_Class::as_Klass(mirror);\n@@ -1406,1 +1406,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(k);\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(mirror);\n@@ -1442,1 +1442,1 @@\n-  Klass* k = java_lang_Class::as_Klass(mirror);\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(mirror);\n@@ -1444,1 +1444,1 @@\n-  Method* m = InstanceKlass::cast(k)->method_with_idnum(slot);\n+  Method* m = ik->method_with_idnum(slot);\n@@ -1568,1 +1568,1 @@\n-  InstanceKlass* k = InstanceKlass::cast(java_lang_Class::as_Klass(ofMirror));\n+  InstanceKlass* k = java_lang_Class::as_InstanceKlass(ofMirror);\n@@ -1625,3 +1625,1 @@\n-  Klass* c = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(ofClass));\n-  assert(c->is_instance_klass(), \"must be\");\n-  InstanceKlass* ik = InstanceKlass::cast(c);\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve_non_null(ofClass));\n@@ -1669,1 +1667,1 @@\n-  InstanceKlass* k = InstanceKlass::cast(java_lang_Class::as_Klass(ofMirror));\n+  InstanceKlass* k = java_lang_Class::as_InstanceKlass(ofMirror);\n@@ -1746,13 +1744,0 @@\n-JVM_ENTRY(jint, JVM_GetClassAccessFlags(JNIEnv *env, jclass cls))\n-{\n-  oop mirror = JNIHandles::resolve_non_null(cls);\n-  if (java_lang_Class::is_primitive(mirror)) {\n-    \/\/ Primitive type\n-    return JVM_ACC_ABSTRACT | JVM_ACC_FINAL | JVM_ACC_PUBLIC;\n-  }\n-\n-  Klass* k = java_lang_Class::as_Klass(mirror);\n-  return k->access_flags().as_class_flags();\n-}\n-JVM_END\n-\n@@ -1761,7 +1746,3 @@\n-  Klass* c = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(current));\n-  assert(c->is_instance_klass(), \"must be\");\n-  InstanceKlass* ck = InstanceKlass::cast(c);\n-  Klass* m = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(member));\n-  assert(m->is_instance_klass(), \"must be\");\n-  InstanceKlass* mk = InstanceKlass::cast(m);\n-  return ck->has_nestmate_access_to(mk, THREAD);\n+  InstanceKlass* c = java_lang_Class::as_InstanceKlass(JNIHandles::resolve_non_null(current));\n+  InstanceKlass* m = java_lang_Class::as_InstanceKlass(JNIHandles::resolve_non_null(member));\n+  return c->has_nestmate_access_to(m, THREAD);\n@@ -1774,4 +1755,2 @@\n-  Klass* c = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(current));\n-  assert(c->is_instance_klass(), \"must be\");\n-  InstanceKlass* ck = InstanceKlass::cast(c);\n-  InstanceKlass* host = ck->nest_host(THREAD);\n+  InstanceKlass* c = java_lang_Class::as_InstanceKlass(JNIHandles::resolve_non_null(current));\n+  InstanceKlass* host = c->nest_host(THREAD);\n@@ -1787,4 +1766,2 @@\n-  Klass* c = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(current));\n-  assert(c->is_instance_klass(), \"must be\");\n-  InstanceKlass* ck = InstanceKlass::cast(c);\n-  InstanceKlass* host = ck->nest_host(THREAD);\n+  InstanceKlass* c = java_lang_Class::as_InstanceKlass(JNIHandles::resolve_non_null(current));\n+  InstanceKlass* host = c->nest_host(THREAD);\n@@ -1793,1 +1770,1 @@\n-                              ck->external_name(), host->external_name());\n+                              c->external_name(), host->external_name());\n@@ -1856,1 +1833,1 @@\n-      assert(host == ck || ck->is_hidden(), \"must be singleton nest or dynamic nestmate\");\n+      assert(host == c || c->is_hidden(), \"must be singleton nest or dynamic nestmate\");\n@@ -1867,3 +1844,2 @@\n-  Klass* c = java_lang_Class::as_Klass(mirror);\n-  assert(c->is_instance_klass(), \"must be\");\n-  InstanceKlass* ik = InstanceKlass::cast(c);\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(mirror);\n+\n@@ -1945,1 +1921,1 @@\n-JVM_ENTRY(jint, JVM_ConstantPoolGetSize(JNIEnv *env, jobject obj, jobject unused))\n+JVM_ENTRY(jint, JVM_ConstantPoolGetSize(JNIEnv *env, jobject obj))\n@@ -1953,1 +1929,1 @@\n-JVM_ENTRY(jclass, JVM_ConstantPoolGetClassAt(JNIEnv *env, jobject obj, jobject unused, jint index))\n+JVM_ENTRY(jclass, JVM_ConstantPoolGetClassAt(JNIEnv *env, jobject obj, jint index))\n@@ -1966,1 +1942,1 @@\n-JVM_ENTRY(jclass, JVM_ConstantPoolGetClassAtIfLoaded(JNIEnv *env, jobject obj, jobject unused, jint index))\n+JVM_ENTRY(jclass, JVM_ConstantPoolGetClassAtIfLoaded(JNIEnv *env, jobject obj, jint index))\n@@ -2010,1 +1986,1 @@\n-JVM_ENTRY(jobject, JVM_ConstantPoolGetMethodAt(JNIEnv *env, jobject obj, jobject unused, jint index))\n+JVM_ENTRY(jobject, JVM_ConstantPoolGetMethodAt(JNIEnv *env, jobject obj, jint index))\n@@ -2020,1 +1996,1 @@\n-JVM_ENTRY(jobject, JVM_ConstantPoolGetMethodAtIfLoaded(JNIEnv *env, jobject obj, jobject unused, jint index))\n+JVM_ENTRY(jobject, JVM_ConstantPoolGetMethodAtIfLoaded(JNIEnv *env, jobject obj, jint index))\n@@ -2055,1 +2031,1 @@\n-JVM_ENTRY(jobject, JVM_ConstantPoolGetFieldAt(JNIEnv *env, jobject obj, jobject unusedl, jint index))\n+JVM_ENTRY(jobject, JVM_ConstantPoolGetFieldAt(JNIEnv *env, jobject obj, jint index))\n@@ -2065,1 +2041,1 @@\n-JVM_ENTRY(jobject, JVM_ConstantPoolGetFieldAtIfLoaded(JNIEnv *env, jobject obj, jobject unused, jint index))\n+JVM_ENTRY(jobject, JVM_ConstantPoolGetFieldAtIfLoaded(JNIEnv *env, jobject obj, jint index))\n@@ -2075,1 +2051,1 @@\n-JVM_ENTRY(jobjectArray, JVM_ConstantPoolGetMemberRefInfoAt(JNIEnv *env, jobject obj, jobject unused, jint index))\n+JVM_ENTRY(jobjectArray, JVM_ConstantPoolGetMemberRefInfoAt(JNIEnv *env, jobject obj, jint index))\n@@ -2100,1 +2076,1 @@\n-JVM_ENTRY(jint, JVM_ConstantPoolGetClassRefIndexAt(JNIEnv *env, jobject obj, jobject unused, jint index))\n+JVM_ENTRY(jint, JVM_ConstantPoolGetClassRefIndexAt(JNIEnv *env, jobject obj, jint index))\n@@ -2113,1 +2089,1 @@\n-JVM_ENTRY(jint, JVM_ConstantPoolGetNameAndTypeRefIndexAt(JNIEnv *env, jobject obj, jobject unused, jint index))\n+JVM_ENTRY(jint, JVM_ConstantPoolGetNameAndTypeRefIndexAt(JNIEnv *env, jobject obj, jint index))\n@@ -2126,1 +2102,1 @@\n-JVM_ENTRY(jobjectArray, JVM_ConstantPoolGetNameAndTypeRefInfoAt(JNIEnv *env, jobject obj, jobject unused, jint index))\n+JVM_ENTRY(jobjectArray, JVM_ConstantPoolGetNameAndTypeRefInfoAt(JNIEnv *env, jobject obj, jint index))\n@@ -2147,1 +2123,1 @@\n-JVM_ENTRY(jint, JVM_ConstantPoolGetIntAt(JNIEnv *env, jobject obj, jobject unused, jint index))\n+JVM_ENTRY(jint, JVM_ConstantPoolGetIntAt(JNIEnv *env, jobject obj, jint index))\n@@ -2159,1 +2135,1 @@\n-JVM_ENTRY(jlong, JVM_ConstantPoolGetLongAt(JNIEnv *env, jobject obj, jobject unused, jint index))\n+JVM_ENTRY(jlong, JVM_ConstantPoolGetLongAt(JNIEnv *env, jobject obj, jint index))\n@@ -2171,1 +2147,1 @@\n-JVM_ENTRY(jfloat, JVM_ConstantPoolGetFloatAt(JNIEnv *env, jobject obj, jobject unused, jint index))\n+JVM_ENTRY(jfloat, JVM_ConstantPoolGetFloatAt(JNIEnv *env, jobject obj, jint index))\n@@ -2183,1 +2159,1 @@\n-JVM_ENTRY(jdouble, JVM_ConstantPoolGetDoubleAt(JNIEnv *env, jobject obj, jobject unused, jint index))\n+JVM_ENTRY(jdouble, JVM_ConstantPoolGetDoubleAt(JNIEnv *env, jobject obj, jint index))\n@@ -2195,1 +2171,1 @@\n-JVM_ENTRY(jstring, JVM_ConstantPoolGetStringAt(JNIEnv *env, jobject obj, jobject unused, jint index))\n+JVM_ENTRY(jstring, JVM_ConstantPoolGetStringAt(JNIEnv *env, jobject obj, jint index))\n@@ -2208,1 +2184,1 @@\n-JVM_ENTRY(jstring, JVM_ConstantPoolGetUTF8At(JNIEnv *env, jobject obj, jobject unused, jint index))\n+JVM_ENTRY(jstring, JVM_ConstantPoolGetUTF8At(JNIEnv *env, jobject obj, jint index))\n@@ -2223,1 +2199,1 @@\n-JVM_ENTRY(jbyte, JVM_ConstantPoolGetTagAt(JNIEnv *env, jobject obj, jobject unused, jint index))\n+JVM_ENTRY(jbyte, JVM_ConstantPoolGetTagAt(JNIEnv *env, jobject obj, jint index))\n@@ -2281,6 +2257,20 @@\n-\/\/ All functions from this section should call the jvmtiThreadSate function:\n-\/\/   Klass* class_to_verify_considering_redefinition(Klass* klass).\n-\/\/ The function returns a Klass* of the _scratch_class if the verifier\n-\/\/ was invoked in the middle of the class redefinition.\n-\/\/ Otherwise it returns its argument value which is the _the_class Klass*.\n-\/\/ Please, refer to the description in the jvmtiThreadState.hpp.\n+\/\/ All functions from this section, unless noted otherwise, should call the functions\n+\/\/   get_klass_considering_redefinition(), or\n+\/\/   get_instance_klass_considering_redefinition()\n+\/\/ These functions return JvmtiThreadState::_scratch_class if the verifier\n+\/\/ was invoked in the middle of the redefinition of cls.\n+\/\/ See jvmtiThreadState.hpp for details.\n+\n+inline Klass* get_klass_considering_redefinition(jclass cls, JavaThread* thread) {\n+  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n+  if (k->is_instance_klass()) {\n+    return JvmtiThreadState::class_to_verify_considering_redefinition(InstanceKlass::cast(k), thread);\n+  } else {\n+    return k;\n+  }\n+}\n+\n+inline InstanceKlass* get_instance_klass_considering_redefinition(jclass cls, JavaThread* thread) {\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve_non_null(cls));\n+  return JvmtiThreadState::class_to_verify_considering_redefinition(ik, thread);\n+}\n@@ -2294,1 +2284,1 @@\n-  \/\/ This isn't necessary since answer is the same since redefinition\n+  \/\/ This isn't necessary since answer is the same because redefinition\n@@ -2296,1 +2286,1 @@\n-  \/\/ k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n+  \/\/ k = get_klass_considering_redefinition(cls, thread)\n@@ -2303,1 +2293,1 @@\n-\n+  \/\/ No need to call get_klass_considering_redefinition() as redefinition cannot change a class's name.\n@@ -2306,1 +2296,0 @@\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n@@ -2312,2 +2301,1 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n+  Klass* k = get_klass_considering_redefinition(cls, thread);\n@@ -2327,2 +2315,1 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n+  Klass* k = get_klass_considering_redefinition(cls, thread);\n@@ -2334,2 +2321,1 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n+  Klass* k = get_klass_considering_redefinition(cls, thread);\n@@ -2341,2 +2327,1 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n+  Klass* k = get_klass_considering_redefinition(cls, thread);\n@@ -2353,3 +2338,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2367,3 +2351,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2375,3 +2358,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2383,3 +2365,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2391,3 +2372,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2403,3 +2383,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2411,3 +2390,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2419,3 +2397,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  return InstanceKlass::cast(k)->field_access_flags(field_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  return ik->field_access_flags(field_index);\n@@ -2426,3 +2403,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2434,3 +2410,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2442,3 +2417,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2451,3 +2425,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2460,3 +2433,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2467,3 +2439,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2475,3 +2446,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2490,3 +2460,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  ConstantPool* cp = InstanceKlass::cast(k)->constants();\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  ConstantPool* cp = ik->constants();\n@@ -2505,3 +2474,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  ConstantPool* cp = InstanceKlass::cast(k)->constants();\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  ConstantPool* cp = ik->constants();\n@@ -2521,3 +2489,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  ConstantPool* cp = InstanceKlass::cast(k)->constants();\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  ConstantPool* cp = ik->constants();\n@@ -2537,3 +2504,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  ConstantPool* cp = InstanceKlass::cast(k)->constants();\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  ConstantPool* cp = ik->constants();\n@@ -2552,3 +2518,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  ConstantPool* cp = InstanceKlass::cast(k)->constants();\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  ConstantPool* cp = ik->constants();\n@@ -2561,3 +2526,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  ConstantPool* cp = InstanceKlass::cast(k)->constants();\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  ConstantPool* cp = ik->constants();\n@@ -2579,3 +2543,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  ConstantPool* cp = InstanceKlass::cast(k)->constants();\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  ConstantPool* cp = ik->constants();\n@@ -2598,6 +2561,4 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  Klass* k_called = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(called_cls));\n-  k        = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  k_called = JvmtiThreadState::class_to_verify_considering_redefinition(k_called, thread);\n-  ConstantPool* cp = InstanceKlass::cast(k)->constants();\n-  ConstantPool* cp_called = InstanceKlass::cast(k_called)->constants();\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  InstanceKlass* ik_called = get_instance_klass_considering_redefinition(called_cls, thread);\n+  ConstantPool* cp = ik->constants();\n+  ConstantPool* cp_called = ik_called->constants();\n@@ -2608,2 +2569,1 @@\n-      InstanceKlass* ik = InstanceKlass::cast(k_called);\n-      for (JavaFieldStream fs(ik); !fs.done(); fs.next()) {\n+      for (JavaFieldStream fs(ik_called); !fs.done(); fs.next()) {\n@@ -2625,5 +2585,3 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  Klass* k_called = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(called_cls));\n-  k        = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  k_called = JvmtiThreadState::class_to_verify_considering_redefinition(k_called, thread);\n-  ConstantPool* cp = InstanceKlass::cast(k)->constants();\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  InstanceKlass* ik_called = get_instance_klass_considering_redefinition(called_cls, thread);\n+  ConstantPool* cp = ik->constants();\n@@ -2635,1 +2593,1 @@\n-      Array<Method*>* methods = InstanceKlass::cast(k_called)->methods();\n+      Array<Method*>* methods = ik_called->methods();\n@@ -2898,1 +2856,1 @@\n-    if (!thread->sleep_nanos(nanos)) { \/\/ interrupted\n+    if (!thread->sleep_nanos(nanos)) { \/\/ interrupted or async exception was installed\n@@ -2903,4 +2861,5 @@\n-\n-        \/\/ TODO-FIXME: THROW_MSG returns which means we will not call set_state()\n-        \/\/ to properly restore the thread state.  That's likely wrong.\n-        THROW_MSG(vmSymbols::java_lang_InterruptedException(), \"sleep interrupted\");\n+        if (!thread->has_async_exception_condition()) {\n+          \/\/ TODO-FIXME: THROW_MSG returns which means we will not call set_state()\n+          \/\/ to properly restore the thread state.  That's likely wrong.\n+          THROW_MSG(vmSymbols::java_lang_InterruptedException(), \"sleep interrupted\");\n+        }\n@@ -2962,1 +2921,1 @@\n-  oop trace = java_lang_Thread::async_get_stack_trace(JNIHandles::resolve(jthread), THREAD);\n+  oop trace = java_lang_Thread::async_get_stack_trace(jthread, THREAD);\n@@ -2971,1 +2930,1 @@\n-  return nullptr;\n+  THROW_NULL(vmSymbols::java_lang_UnsupportedOperationException());\n@@ -3045,0 +3004,8 @@\n+JVM_ENTRY(jobject, JVM_ReferenceGet(JNIEnv* env, jobject ref))\n+  oop ref_oop = JNIHandles::resolve_non_null(ref);\n+  \/\/ PhantomReference has its own implementation of get().\n+  assert(!java_lang_ref_Reference::is_phantom(ref_oop), \"precondition\");\n+  oop referent = java_lang_ref_Reference::weak_referent(ref_oop);\n+  return JNIHandles::make_local(THREAD, referent);\n+JVM_END\n+\n@@ -3047,1 +3014,1 @@\n-  \/\/ PhantomReference has it's own implementation of refersTo().\n+  \/\/ PhantomReference has its own implementation of refersTo().\n@@ -3381,2 +3348,1 @@\n-  Klass* caller_k = java_lang_Class::as_Klass(JNIHandles::resolve(caller));\n-  InstanceKlass* caller_ik = InstanceKlass::cast(caller_k);\n+  InstanceKlass* caller_ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(caller));\n@@ -3389,2 +3355,1 @@\n-  Klass* lambda_k = java_lang_Class::as_Klass(JNIHandles::resolve(lambdaProxyClass));\n-  InstanceKlass* lambda_ik = InstanceKlass::cast(lambda_k);\n+  InstanceKlass* lambda_ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(lambdaProxyClass));\n@@ -3430,3 +3395,2 @@\n-  Klass* caller_k = java_lang_Class::as_Klass(JNIHandles::resolve(caller));\n-  InstanceKlass* caller_ik = InstanceKlass::cast(caller_k);\n-  if (!caller_ik->is_shared()) {\n+  InstanceKlass* caller_ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(caller));\n+  if (!caller_ik->in_aot_cache()) {\n@@ -3513,1 +3477,1 @@\n-  MetaspaceShared::dump_loaded_classes(file_name, THREAD);\n+  AOTMetaspace::dump_loaded_classes(file_name, THREAD);\n@@ -3726,13 +3690,3 @@\n-JVM_ENTRY(void, JVM_VirtualThreadStart(JNIEnv* env, jobject vthread))\n-#if INCLUDE_JVMTI\n-  if (!DoJVMTIVirtualThreadTransitions) {\n-    assert(!JvmtiExport::can_support_virtual_threads(), \"sanity check\");\n-    return;\n-  }\n-  if (JvmtiVTMSTransitionDisabler::VTMS_notify_jvmti_events()) {\n-    JvmtiVTMSTransitionDisabler::VTMS_vthread_start(vthread);\n-  } else {\n-    \/\/ set VTMS transition bit value in JavaThread and java.lang.VirtualThread object\n-    JvmtiVTMSTransitionDisabler::set_is_in_VTMS_transition(thread, vthread, false);\n-  }\n-#endif\n+JVM_ENTRY(void, JVM_VirtualThreadEndFirstTransition(JNIEnv* env, jobject vthread))\n+  oop vt = JNIHandles::resolve_external_guard(vthread);\n+  MountUnmountDisabler::end_transition(thread, vt, true \/*is_mount*\/, true \/*is_thread_start*\/);\n@@ -3741,13 +3695,3 @@\n-JVM_ENTRY(void, JVM_VirtualThreadEnd(JNIEnv* env, jobject vthread))\n-#if INCLUDE_JVMTI\n-  if (!DoJVMTIVirtualThreadTransitions) {\n-    assert(!JvmtiExport::can_support_virtual_threads(), \"sanity check\");\n-    return;\n-  }\n-  if (JvmtiVTMSTransitionDisabler::VTMS_notify_jvmti_events()) {\n-    JvmtiVTMSTransitionDisabler::VTMS_vthread_end(vthread);\n-  } else {\n-    \/\/ set VTMS transition bit value in JavaThread and java.lang.VirtualThread object\n-    JvmtiVTMSTransitionDisabler::set_is_in_VTMS_transition(thread, vthread, true);\n-  }\n-#endif\n+JVM_ENTRY(void, JVM_VirtualThreadStartFinalTransition(JNIEnv* env, jobject vthread))\n+  oop vt = JNIHandles::resolve_external_guard(vthread);\n+  MountUnmountDisabler::start_transition(thread, vt, false \/*is_mount *\/, true \/*is_thread_end*\/);\n@@ -3756,15 +3700,3 @@\n-\/\/ If notifications are disabled then just update the VTMS transition bit and return.\n-\/\/ Otherwise, the bit is updated in the given jvmtiVTMSTransitionDisabler function call.\n-JVM_ENTRY(void, JVM_VirtualThreadMount(JNIEnv* env, jobject vthread, jboolean hide))\n-#if INCLUDE_JVMTI\n-  if (!DoJVMTIVirtualThreadTransitions) {\n-    assert(!JvmtiExport::can_support_virtual_threads(), \"sanity check\");\n-    return;\n-  }\n-  if (JvmtiVTMSTransitionDisabler::VTMS_notify_jvmti_events()) {\n-    JvmtiVTMSTransitionDisabler::VTMS_vthread_mount(vthread, hide);\n-  } else {\n-    \/\/ set VTMS transition bit value in JavaThread and java.lang.VirtualThread object\n-    JvmtiVTMSTransitionDisabler::set_is_in_VTMS_transition(thread, vthread, hide);\n-  }\n-#endif\n+JVM_ENTRY(void, JVM_VirtualThreadStartTransition(JNIEnv* env, jobject vthread, jboolean is_mount))\n+  oop vt = JNIHandles::resolve_external_guard(vthread);\n+  MountUnmountDisabler::start_transition(thread, vt, is_mount, false \/*is_thread_end*\/);\n@@ -3773,15 +3705,3 @@\n-\/\/ If notifications are disabled then just update the VTMS transition bit and return.\n-\/\/ Otherwise, the bit is updated in the given jvmtiVTMSTransitionDisabler function call below.\n-JVM_ENTRY(void, JVM_VirtualThreadUnmount(JNIEnv* env, jobject vthread, jboolean hide))\n-#if INCLUDE_JVMTI\n-  if (!DoJVMTIVirtualThreadTransitions) {\n-    assert(!JvmtiExport::can_support_virtual_threads(), \"sanity check\");\n-    return;\n-  }\n-  if (JvmtiVTMSTransitionDisabler::VTMS_notify_jvmti_events()) {\n-    JvmtiVTMSTransitionDisabler::VTMS_vthread_unmount(vthread, hide);\n-  } else {\n-    \/\/ set VTMS transition bit value in JavaThread and java.lang.VirtualThread object\n-    JvmtiVTMSTransitionDisabler::set_is_in_VTMS_transition(thread, vthread, hide);\n-  }\n-#endif\n+JVM_ENTRY(void, JVM_VirtualThreadEndTransition(JNIEnv* env, jobject vthread, jboolean is_mount))\n+  oop vt = JNIHandles::resolve_external_guard(vthread);\n+  MountUnmountDisabler::end_transition(thread, vt, is_mount, false \/*is_thread_start*\/);\n@@ -3837,0 +3757,1 @@\n+\n@@ -3848,5 +3769,1 @@\n-  assert(!java_lang_Class::as_Klass(mirror)->is_array_klass(), \"unexpected array class\");\n-\n-  Klass* c = java_lang_Class::as_Klass(mirror);\n-  assert(c->is_instance_klass(), \"must be\");\n-  InstanceKlass* ik = InstanceKlass::cast(c);\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(mirror);\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":195,"deletions":278,"binary":false,"changes":473,"status":"modified"},{"patch":"@@ -30,1 +30,0 @@\n-#include \"prims\/jvmtiEventController.hpp\"\n@@ -44,1 +43,1 @@\n-#include \"runtime\/vmThread.hpp\"\n+#include \"runtime\/vmThread.hpp\"\n@@ -499,0 +498,4 @@\n+  if (JvmtiEventController::is_execution_finished()) {\n+    now_enabled &= VM_DEATH_BIT;\n+  }\n+\n@@ -541,0 +544,4 @@\n+  if (JvmtiEventController::is_execution_finished()) {\n+    now_enabled &= VM_DEATH_BIT;\n+  }\n+\n@@ -788,3 +795,0 @@\n-  \/\/ May be changing the event handler for ObjectFree.\n-  flush_object_free_events(env);\n-\n@@ -1059,1 +1063,1 @@\n-  \/\/ events are disabled (phase has changed)\n+  \/\/ events are disabled, see JvmtiEventController::_execution_finished\n@@ -1071,0 +1075,3 @@\n+volatile bool JvmtiEventController::_execution_finished = false;\n+volatile int  JvmtiEventController::_in_callback_count = 0;\n+\n@@ -1081,4 +1088,0 @@\n-  if (event_type == JVMTI_EVENT_OBJECT_FREE) {\n-    JvmtiEventControllerPrivate::flush_object_free_events(env);\n-  }\n-\n@@ -1093,0 +1096,5 @@\n+\n+    if (event_type == JVMTI_EVENT_OBJECT_FREE) {\n+      JvmtiEventControllerPrivate::flush_object_free_events(env);\n+    }\n+\n@@ -1108,0 +1116,2 @@\n+    JvmtiEventControllerPrivate::flush_object_free_events(env);\n+\n@@ -1195,0 +1205,2 @@\n+    JvmtiEventControllerPrivate::flush_object_free_events(env);\n+\n@@ -1219,0 +1231,2 @@\n+  \/\/ No new event callbacks except vm_death can be called after this point.\n+  AtomicAccess::store(&_execution_finished, true);\n@@ -1223,0 +1237,13 @@\n+\n+  \/\/ Some events might be still in callback for daemons and VM internal threads.\n+  const double start = os::elapsedTime();\n+  const double max_wait_time = 60;\n+  \/\/ The first time we see the callback count reach zero we know all actual\n+  \/\/ callbacks are complete. The count could rise again, but those \"callbacks\"\n+  \/\/ will immediately see `execution_finished()` and return (dropping the count).\n+  while (in_callback_count() > 0) {\n+    os::naked_short_sleep(100);\n+    if (os::elapsedTime() - start > max_wait_time) {\n+      break;\n+    }\n+  }\n","filename":"src\/hotspot\/share\/prims\/jvmtiEventController.cpp","additions":37,"deletions":10,"binary":false,"changes":47,"status":"modified"},{"patch":"@@ -204,0 +204,5 @@\n+  \/\/ These fields are used to synchronize stop posting events and\n+  \/\/ wait until already executing callbacks are finished.\n+  volatile static bool  _execution_finished;\n+  volatile static int   _in_callback_count;\n+\n@@ -252,0 +257,4 @@\n+  static bool is_execution_finished();\n+  static void inc_in_callback_count();\n+  static void dec_in_callback_count();\n+  static int in_callback_count();\n","filename":"src\/hotspot\/share\/prims\/jvmtiEventController.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"cds\/aotThread.hpp\"\n@@ -47,1 +48,0 @@\n-#include \"prims\/jvmtiEventController.hpp\"\n@@ -64,1 +64,1 @@\n-#include \"runtime\/objectMonitor.hpp\"\n+#include \"runtime\/mountUnmountDisabler.hpp\"\n@@ -102,1 +102,6 @@\n-    _hm(thread)  {};\n+    _hm(thread) {\n+    JvmtiEventController::inc_in_callback_count();\n+  };\n+  ~JvmtiJavaThreadEventTransition() {\n+    JvmtiEventController::dec_in_callback_count();\n+  }\n@@ -116,0 +121,1 @@\n+    JvmtiEventController::inc_in_callback_count();\n@@ -130,1 +136,1 @@\n-    if (_jthread != nullptr)\n+    if (_jthread != nullptr) {\n@@ -132,0 +138,2 @@\n+    }\n+    JvmtiEventController::dec_in_callback_count();\n@@ -135,0 +143,13 @@\n+\/\/ The JVMTI_...__BLOCK are used to ensure that vm_death is the last posted event.\n+\/\/ The callbacks are not executed after _execution_finished is set to true\n+\/\/ and the _in_callback_count contains the number of callbacks still in progress.\n+#define JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread) \\\n+  JvmtiJavaThreadEventTransition jet(thread); \\\n+  if (JvmtiEventController::is_execution_finished()) {\\\n+    return; \\\n+  }\n+#define JVMTI_THREAD_EVENT_CALLBACK_BLOCK(thread) \\\n+  JvmtiThreadEventTransition jet(thread); \\\n+  if (JvmtiEventController::is_execution_finished()) { \\\n+    return; \\\n+  }\n@@ -395,1 +416,1 @@\n-      if (!JvmtiVTMSTransitionDisabler::VTMS_notify_jvmti_events()) {\n+      if (!MountUnmountDisabler::notify_jvmti_events()) {\n@@ -409,1 +430,1 @@\n-      JvmtiVTMSTransitionDisabler::set_VTMS_notify_jvmti_events(true);\n+      MountUnmountDisabler::set_notify_jvmti_events(true, true \/*is_onload*\/);\n@@ -423,0 +444,1 @@\n+  assert(thread->thread_state() == _thread_in_vm, \"thread should be in vm\");\n@@ -666,1 +688,1 @@\n-      JvmtiJavaThreadEventTransition jet(thread);\n+      JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -678,0 +700,7 @@\n+  \/\/ The JvmtiThreadState is incomplete if initialized in post_early_vm_start\n+  \/\/ before classes are initialized. It should be updated now.\n+  JavaThread *thread  = JavaThread::current();\n+  if (thread->jvmti_thread_state() != nullptr) {\n+    thread->jvmti_thread_state()->update_thread_oop_during_vm_start();\n+  }\n+\n@@ -687,2 +716,1 @@\n-      JavaThread *thread  = JavaThread::current();\n-      JvmtiJavaThreadEventTransition jet(thread);\n+      JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -739,1 +767,1 @@\n-      JvmtiJavaThreadEventTransition jet(thread);\n+      JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -767,0 +795,5 @@\n+  \/\/ It is needed to disable event generation before setting DEAD phase and wait\n+  \/\/ until already executing events are finished.\n+  \/\/ The VM_DEATH should be the last posted event.\n+  JvmtiEventController::vm_death();\n+\n@@ -774,0 +807,1 @@\n+      \/\/ JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK must not be used here\n@@ -783,1 +817,0 @@\n-  JvmtiEventController::vm_death();\n@@ -862,41 +895,0 @@\n-\/\/ Convert an oop to a JavaThread found on the specified ThreadsList.\n-\/\/ The ThreadsListHandle in the caller \"protects\" the returned\n-\/\/ JavaThread *.\n-\/\/\n-\/\/ On success, *jt_pp is set to the converted JavaThread * and\n-\/\/ JVMTI_ERROR_NONE is returned. On error, returns various\n-\/\/ JVMTI_ERROR_* values.\n-\/\/\n-jvmtiError\n-JvmtiExport::cv_oop_to_JavaThread(ThreadsList * t_list, oop thread_oop,\n-                                  JavaThread ** jt_pp) {\n-  assert(t_list != nullptr, \"must have a ThreadsList\");\n-  assert(thread_oop != nullptr, \"must have an oop\");\n-  assert(jt_pp != nullptr, \"must have a return JavaThread pointer\");\n-\n-  if (!thread_oop->is_a(vmClasses::Thread_klass())) {\n-    \/\/ The oop is not a java.lang.Thread.\n-    return JVMTI_ERROR_INVALID_THREAD;\n-  }\n-  \/\/ Looks like a java.lang.Thread oop at this point.\n-\n-  JavaThread * java_thread = java_lang_Thread::thread(thread_oop);\n-  if (java_thread == nullptr) {\n-    \/\/ The java.lang.Thread does not contain a JavaThread * so it has\n-    \/\/ not yet run or it has died.\n-    return JVMTI_ERROR_THREAD_NOT_ALIVE;\n-  }\n-  \/\/ Looks like a live JavaThread at this point.\n-\n-  if (!t_list->includes(java_thread)) {\n-    \/\/ Not on the JavaThreads list so it is not alive.\n-    return JVMTI_ERROR_THREAD_NOT_ALIVE;\n-  }\n-\n-  \/\/ Return a live JavaThread that is \"protected\" by the\n-  \/\/ ThreadsListHandle in the caller.\n-  *jt_pp = java_thread;\n-\n-  return JVMTI_ERROR_NONE;\n-}\n-\n@@ -918,1 +910,0 @@\n-  bool                 _has_been_modified;\n@@ -935,1 +926,0 @@\n-    _has_been_modified = false;\n@@ -946,1 +936,1 @@\n-            module_entry->module() != nullptr &&\n+            module_entry->module_oop() != nullptr &&\n@@ -951,1 +941,1 @@\n-            Handle class_module(_thread, module_entry->module()); \/\/ Obtain j.l.r.Module\n+            Handle class_module(_thread, module_entry->module_oop()); \/\/ Obtain j.l.r.Module\n@@ -974,2 +964,0 @@\n-  bool has_been_modified() { return _has_been_modified; }\n-\n@@ -1010,1 +998,1 @@\n-    JvmtiJavaThreadEventTransition jet(_thread);\n+    JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(_thread)\n@@ -1022,1 +1010,0 @@\n-      _has_been_modified = true;\n@@ -1097,1 +1084,1 @@\n-bool JvmtiExport::post_class_file_load_hook(Symbol* h_name,\n+void JvmtiExport::post_class_file_load_hook(Symbol* h_name,\n@@ -1104,1 +1091,1 @@\n-    return false;\n+    return;\n@@ -1108,1 +1095,1 @@\n-    return false;\n+    return;\n@@ -1116,1 +1103,0 @@\n-  return poster.has_been_modified();\n@@ -1222,1 +1208,1 @@\n-      JvmtiJavaThreadEventTransition jet(thread);\n+      JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -1264,1 +1250,1 @@\n-      JvmtiJavaThreadEventTransition jet(thread);\n+      JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -1356,5 +1342,3 @@\n-void JvmtiExport::expose_single_stepping(JavaThread *thread) {\n-  JvmtiThreadState *state = get_jvmti_thread_state(thread);\n-  if (state != nullptr) {\n-    state->clear_hide_single_stepping();\n-  }\n+void JvmtiExport::expose_single_stepping(JvmtiThreadState* state) {\n+  assert(state != nullptr, \"must be non-null\");\n+  state->clear_hide_single_stepping();\n@@ -1364,1 +1348,1 @@\n-bool JvmtiExport::hide_single_stepping(JavaThread *thread) {\n+JvmtiThreadState* JvmtiExport::hide_single_stepping(JavaThread *thread) {\n@@ -1368,1 +1352,1 @@\n-    return true;\n+    return state;\n@@ -1370,1 +1354,1 @@\n-    return false;\n+    return nullptr;\n@@ -1405,1 +1389,1 @@\n-      JvmtiJavaThreadEventTransition jet(thread);\n+      JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -1446,1 +1430,1 @@\n-      JvmtiJavaThreadEventTransition jet(thread);\n+      JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -1489,1 +1473,1 @@\n-        JvmtiJavaThreadEventTransition jet(thread);\n+        JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -1506,0 +1490,7 @@\n+  if (thread->is_aot_thread()) {\n+    \/\/ The AOT thread is hidden from view but has no thread oop when it starts due\n+    \/\/ to bootstrapping complexity, so we check for it before checking for bound\n+    \/\/ virtual threads. When exiting it is filtered out due to being hidden.\n+    return;\n+  }\n+\n@@ -1535,1 +1526,1 @@\n-        JvmtiJavaThreadEventTransition jet(thread);\n+        JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -1583,1 +1574,1 @@\n-        JvmtiJavaThreadEventTransition jet(thread);\n+        JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -1613,1 +1604,1 @@\n-        JvmtiJavaThreadEventTransition jet(thread);\n+        JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -1649,1 +1640,1 @@\n-        JvmtiJavaThreadEventTransition jet(thread);\n+        JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -1652,1 +1643,1 @@\n-          (*callback)(env->jvmti_external(), jem.jni_env(), vthread);\n+          (*callback)(env->jvmti_external(), jem.jni_env(), jem.jni_thread());\n@@ -1684,1 +1675,1 @@\n-        JvmtiJavaThreadEventTransition jet(thread);\n+        JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -1719,1 +1710,1 @@\n-        JvmtiJavaThreadEventTransition jet(thread);\n+        JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -1729,0 +1720,17 @@\n+bool JvmtiExport::has_frame_pops(JavaThread* thread) {\n+  if (!can_post_frame_pop()) {\n+    return false;\n+  }\n+  JvmtiThreadState *state = thread->jvmti_thread_state();\n+  if (state == nullptr) {\n+    return false;\n+  }\n+  JvmtiEnvThreadStateIterator it(state);\n+  for (JvmtiEnvThreadState* ets = it.first(); ets != nullptr; ets = it.next(ets)) {\n+    if (ets->has_frame_pops()) {\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n@@ -1735,1 +1743,1 @@\n-  JvmtiThreadState *state = get_jvmti_thread_state(thread);\n+  JvmtiThreadState *state = thread->jvmti_thread_state();\n@@ -1778,1 +1786,1 @@\n-  JvmtiJavaThreadEventTransition jet(javaThread);\n+  JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(javaThread)\n@@ -1815,1 +1823,1 @@\n-      JvmtiJavaThreadEventTransition jet(thread);\n+      JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -1855,1 +1863,1 @@\n-        JvmtiJavaThreadEventTransition jet(thread);\n+        JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -1866,0 +1874,6 @@\n+  \/\/ At this point we only have the address of a \"raw result\" and\n+  \/\/ we just call into the interpreter to convert this into a jvalue.\n+  \/\/ This method always makes transition to vm and back where GC can happen.\n+  \/\/ So it is needed to preserve result and then restore it\n+  \/\/ even if events are not actually posted.\n+  \/\/ Saving oop_result into value.j is deferred until jvmti state is ready.\n@@ -1868,11 +1882,1 @@\n-\n-  JvmtiThreadState *state = get_jvmti_thread_state(thread);\n-\n-  if (state == nullptr || !state->is_interp_only_mode()) {\n-    \/\/ for any thread that actually wants method exit, interp_only_mode is set\n-    return;\n-  }\n-\n-  \/\/ return a flag when a method terminates by throwing an exception\n-  \/\/ i.e. if an exception is thrown and it's not caught by the current method\n-  bool exception_exit = state->is_exception_detected() && !state->is_exception_caught();\n+  oop oop_result;\n@@ -1882,14 +1886,5 @@\n-\n-  if (state->is_enabled(JVMTI_EVENT_METHOD_EXIT)) {\n-    \/\/ if the method hasn't been popped because of an exception then we populate\n-    \/\/ the return_value parameter for the callback. At this point we only have\n-    \/\/ the address of a \"raw result\" and we just call into the interpreter to\n-    \/\/ convert this into a jvalue.\n-    if (!exception_exit) {\n-      oop oop_result;\n-      BasicType type = current_frame.interpreter_frame_result(&oop_result, &value);\n-      if (is_reference_type(type)) {\n-        result = Handle(thread, oop_result);\n-        value.l = JNIHandles::make_local(thread, result());\n-      }\n-    }\n+  BasicType type = current_frame.interpreter_frame_result(&oop_result, &value);\n+  assert(mh->is_native() || type == T_VOID || current_frame.interpreter_frame_expression_stack_size() > 0,\n+         \"Stack shouldn't be empty\");\n+  if (is_reference_type(type)) {\n+    result = Handle(thread, oop_result);\n@@ -1897,8 +1892,1 @@\n-\n-  \/\/ Do not allow NotifyFramePop to add new FramePop event request at\n-  \/\/ depth 0 as it is already late in the method exiting dance.\n-  state->set_top_frame_is_exiting();\n-\n-  \/\/ Deferred transition to VM, so we can stash away the return oop before GC\n-  \/\/ Note that this transition is not needed when throwing an exception, because\n-  \/\/ there is no oop to retain.\n+  JvmtiThreadState* state; \/\/ should be initialized in vm state only\n@@ -1906,0 +1894,1 @@\n+  bool interp_only; \/\/ might be changed in JRT_BLOCK_END\n@@ -1907,2 +1896,9 @@\n-    post_method_exit_inner(thread, mh, state, exception_exit, current_frame, value);\n-  JRT_BLOCK_END\n+    state = get_jvmti_thread_state(thread);\n+    interp_only = state != nullptr && state->is_interp_only_mode();\n+    if (interp_only) {\n+      if (state->is_enabled(JVMTI_EVENT_METHOD_EXIT)) {\n+        \/\/ Deferred saving Object result into value.\n+        if (is_reference_type(type)) {\n+          value.l = JNIHandles::make_local(thread, result());\n+        }\n+      }\n@@ -1910,3 +1906,3 @@\n-  \/\/ The JRT_BLOCK_END can safepoint in ThreadInVMfromJava desctructor. Now it is safe to allow\n-  \/\/ adding FramePop event requests as no safepoint can happen before removing activation.\n-  state->clr_top_frame_is_exiting();\n+      \/\/ Do not allow NotifyFramePop to add new FramePop event request at\n+      \/\/ depth 0 as it is already late in the method exiting dance.\n+      state->set_top_frame_is_exiting();\n@@ -1914,0 +1910,8 @@\n+      post_method_exit_inner(thread, mh, state, false \/* not exception exit *\/, current_frame, value);\n+    }\n+  JRT_BLOCK_END\n+  if (interp_only) {\n+    \/\/ The JRT_BLOCK_END can safepoint in ThreadInVMfromJava destructor. Now it is safe to allow\n+    \/\/ adding FramePop event requests as no safepoint can happen before removing activation.\n+    state->clr_top_frame_is_exiting();\n+  }\n@@ -1946,1 +1950,1 @@\n-        JvmtiJavaThreadEventTransition jet(thread);\n+        JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -1973,1 +1977,1 @@\n-          JvmtiJavaThreadEventTransition jet(thread);\n+          JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -2021,1 +2025,1 @@\n-      JvmtiJavaThreadEventTransition jet(thread);\n+      JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -2109,1 +2113,1 @@\n-        JvmtiJavaThreadEventTransition jet(thread);\n+        JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -2184,1 +2188,1 @@\n-          JvmtiJavaThreadEventTransition jet(thread);\n+          JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -2213,0 +2217,5 @@\n+  \/\/ The last java frame might be compiled in 2 cases:\n+  \/\/ 1) Field events and interp_only mode are not enabled for this thread.\n+  \/\/ This method is called from any thread. The thread filtering is done later.\n+  \/\/ 2) The same JNI call is stll executing after event was enabled.\n+  \/\/ In this case the last frame is only marked for deoptimization but still remains compiled.\n@@ -2235,4 +2244,10 @@\n-  post_field_access(thread,\n-                    thread->last_frame().interpreter_frame_method(),\n-                    thread->last_frame().interpreter_frame_bcp(),\n-                    klass, h_obj, fieldID);\n+\n+  RegisterMap reg_map(thread,\n+                      RegisterMap::UpdateMap::skip,\n+                      RegisterMap::ProcessFrames::skip,\n+                      RegisterMap::WalkContinuation::skip);\n+  javaVFrame *jvf = thread->last_java_vframe(&reg_map);\n+  Method* method = jvf->method();\n+  address address = jvf->method()->code_base();\n+\n+  post_field_access(thread, method, address, klass, h_obj, fieldID);\n@@ -2270,1 +2285,1 @@\n-      JvmtiJavaThreadEventTransition jet(thread);\n+      JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -2299,0 +2314,5 @@\n+  \/\/ The last java frame might be compiled in 2 cases:\n+  \/\/ 1) Field events and interp_only mode are not enabled for this thread.\n+  \/\/ This method is called from any thread. The thread filtering is done later.\n+  \/\/ 2) The same JNI call is stll executing after event was enabled.\n+  \/\/ In this case the last frame is only marked for deoptimization but still remains compiled.\n@@ -2322,3 +2342,10 @@\n-  post_field_modification(thread,\n-                          thread->last_frame().interpreter_frame_method(),\n-                          thread->last_frame().interpreter_frame_bcp(),\n+\n+  RegisterMap reg_map(thread,\n+                      RegisterMap::UpdateMap::skip,\n+                      RegisterMap::ProcessFrames::skip,\n+                      RegisterMap::WalkContinuation::skip);\n+  javaVFrame *jvf = thread->last_java_vframe(&reg_map);\n+  Method* method = jvf->method();\n+  address address = jvf->method()->code_base();\n+\n+  post_field_modification(thread, method, address,\n@@ -2428,1 +2455,1 @@\n-      JvmtiJavaThreadEventTransition jet(thread);\n+      JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -2460,1 +2487,1 @@\n-        JvmtiJavaThreadEventTransition jet(thread);\n+        JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -2557,1 +2584,1 @@\n-  JvmtiJavaThreadEventTransition jet(thread);\n+  JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -2584,1 +2611,1 @@\n-      JvmtiJavaThreadEventTransition jet(thread);\n+      JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -2626,1 +2653,1 @@\n-    JvmtiJavaThreadEventTransition jet(thread);\n+    JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -2710,1 +2737,1 @@\n-      JvmtiThreadEventTransition jet(thread);\n+      JVMTI_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -2731,1 +2758,1 @@\n-      JvmtiThreadEventTransition jet(thread);\n+      JVMTI_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -2752,1 +2779,1 @@\n-     JvmtiThreadEventTransition jet(thread);\n+     JVMTI_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -2786,1 +2813,1 @@\n-      JvmtiThreadEventTransition jet(thread);\n+      JVMTI_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -2820,1 +2847,1 @@\n-      JvmtiThreadEventTransition jet(thread);\n+      JVMTI_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -2853,1 +2880,1 @@\n-      JvmtiThreadEventTransition jet(thread);\n+      JVMTI_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -2887,1 +2914,1 @@\n-      JvmtiThreadEventTransition jet(thread);\n+      JVMTI_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -2901,1 +2928,1 @@\n-  JvmtiVTMSTransitionDisabler::VTMS_vthread_mount((jthread)vthread.raw_value(), false);\n+  MountUnmountDisabler::end_transition(current, vthread(), true \/*is_mount*\/, false \/*is_thread_start*\/);\n@@ -2907,1 +2934,1 @@\n-  JvmtiVTMSTransitionDisabler::VTMS_vthread_unmount((jthread)vthread.raw_value(), true);\n+  MountUnmountDisabler::start_transition(current, vthread(), false \/*is_mount*\/, false \/*is_thread_start*\/);\n@@ -2930,1 +2957,1 @@\n-      JvmtiJavaThreadEventTransition jet(thread);\n+      JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -2968,1 +2995,1 @@\n-      JvmtiJavaThreadEventTransition jet(thread);\n+      JVMTI_JAVA_THREAD_EVENT_CALLBACK_BLOCK(thread)\n@@ -3136,6 +3163,1 @@\n-\/\/ Disable collection of VMObjectAlloc events\n-NoJvmtiVMObjectAllocMark::NoJvmtiVMObjectAllocMark() : _collector(nullptr) {\n-  \/\/ a no-op if VMObjectAlloc event is not enabled\n-  if (!JvmtiExport::should_post_vm_object_alloc()) {\n-    return;\n-  }\n+NoJvmtiEventsMark::NoJvmtiEventsMark() {\n@@ -3145,9 +3167,1 @@\n-    JvmtiThreadState *state = current_thread->jvmti_thread_state();\n-    if (state != nullptr) {\n-      JvmtiVMObjectAllocEventCollector *collector;\n-      collector = state->get_vm_object_alloc_event_collector();\n-      if (collector != nullptr && collector->is_enabled()) {\n-        _collector = collector;\n-        _collector->set_enabled(false);\n-      }\n-    }\n+    current_thread->disable_jvmti_events();\n@@ -3157,4 +3171,5 @@\n-\/\/ Re-Enable collection of VMObjectAlloc events (if previously enabled)\n-NoJvmtiVMObjectAllocMark::~NoJvmtiVMObjectAllocMark() {\n-  if (was_enabled()) {\n-    _collector->set_enabled(true);\n+NoJvmtiEventsMark::~NoJvmtiEventsMark() {\n+  Thread* thread = Thread::current_or_null();\n+  if (thread != nullptr && thread->is_Java_thread())  {\n+    JavaThread* current_thread = JavaThread::cast(thread);\n+    current_thread->enable_jvmti_events();\n","filename":"src\/hotspot\/share\/prims\/jvmtiExport.cpp","additions":189,"deletions":174,"binary":false,"changes":363,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -320,2 +320,2 @@\n-  static void expose_single_stepping(JavaThread *thread) NOT_JVMTI_RETURN;\n-  static bool hide_single_stepping(JavaThread *thread) NOT_JVMTI_RETURN_(false);\n+  static void expose_single_stepping(JvmtiThreadState* state) NOT_JVMTI_RETURN;\n+  static JvmtiThreadState* hide_single_stepping(JavaThread *thread) NOT_JVMTI_RETURN_(nullptr);\n@@ -379,0 +379,1 @@\n+  static bool has_frame_pops(JavaThread* thread) NOT_JVMTI_RETURN_(false);\n@@ -382,2 +383,1 @@\n-  \/\/ Return true if the class was modified by the hook.\n-  static bool post_class_file_load_hook(Symbol* h_name, Handle class_loader,\n+  static void post_class_file_load_hook(Symbol* h_name, Handle class_loader,\n@@ -386,1 +386,1 @@\n-                                        JvmtiCachedClassFileData **cache_ptr) NOT_JVMTI_RETURN_(false);\n+                                        JvmtiCachedClassFileData **cache_ptr) NOT_JVMTI_RETURN;\n@@ -460,2 +460,0 @@\n-  static jvmtiError cv_oop_to_JavaThread(ThreadsList * t_list, oop thread_oop,\n-                                         JavaThread ** jt_pp);\n@@ -593,19 +591,2 @@\n-\/\/ Marker class to disable the posting of VMObjectAlloc events\n-\/\/ within its scope.\n-\/\/\n-\/\/ Usage :-\n-\/\/\n-\/\/ {\n-\/\/   NoJvmtiVMObjectAllocMark njm;\n-\/\/   :\n-\/\/   \/\/ VMObjAlloc event will not be posted\n-\/\/   JvmtiExport::vm_object_alloc_event_collector(obj);\n-\/\/   :\n-\/\/ }\n-\n-class NoJvmtiVMObjectAllocMark : public StackObj {\n- private:\n-  \/\/ enclosing collector if enabled, null otherwise\n-  JvmtiVMObjectAllocEventCollector *_collector;\n-\n-  bool was_enabled()    { return _collector != nullptr; }\n+\/\/ Marker class to temporary disable posting of jvmti events.\n+class NoJvmtiEventsMark : public StackObj {\n@@ -614,2 +595,2 @@\n-  NoJvmtiVMObjectAllocMark() NOT_JVMTI_RETURN;\n-  ~NoJvmtiVMObjectAllocMark() NOT_JVMTI_RETURN;\n+  NoJvmtiEventsMark() NOT_JVMTI_RETURN;\n+  ~NoJvmtiEventsMark() NOT_JVMTI_RETURN;\n@@ -630,2 +611,1 @@\n-  bool         _single_step_hidden;\n-  JavaThread * _thread;\n+  JvmtiThreadState* _state;\n@@ -634,1 +614,1 @@\n-  JvmtiHideSingleStepping(JavaThread * thread) {\n+  JvmtiHideSingleStepping(JavaThread * thread) : _state(nullptr) {\n@@ -637,3 +617,1 @@\n-    _single_step_hidden = false;\n-    _thread = thread;\n-      _single_step_hidden = JvmtiExport::hide_single_stepping(_thread);\n+      _state = JvmtiExport::hide_single_stepping(thread);\n@@ -645,2 +623,2 @@\n-    if (_single_step_hidden) {\n-      JvmtiExport::expose_single_stepping(_thread);\n+    if (_state != nullptr) {\n+      JvmtiExport::expose_single_stepping(_state);\n","filename":"src\/hotspot\/share\/prims\/jvmtiExport.hpp","additions":15,"deletions":37,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"runtime\/mountUnmountDisabler.hpp\"\n@@ -80,1 +81,1 @@\n-  JvmtiVTMSTransitionDisabler disabler;\n+  MountUnmountDisabler disabler;\n@@ -138,1 +139,1 @@\n-  JvmtiVTMSTransitionDisabler disabler;\n+  MountUnmountDisabler disabler;\n","filename":"src\/hotspot\/share\/prims\/jvmtiExtensions.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -26,1 +26,2 @@\n-#include \"cds\/archiveHeapLoader.hpp\"\n+#include \"cds\/aotMappedHeapLoader.hpp\"\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -29,2 +30,1 @@\n-#include \"cds\/heapShared.hpp\"\n-#include \"cds\/metaspaceShared.hpp\"\n+#include \"cds\/heapShared.inline.hpp\"\n@@ -42,0 +42,1 @@\n+#include \"code\/compiledIC.hpp\"\n@@ -49,0 +50,1 @@\n+#include \"jfr\/periodic\/sampling\/jfrCPUTimeThreadSampler.hpp\"\n@@ -76,1 +78,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -104,0 +106,1 @@\n+#include \"utilities\/vmError.hpp\"\n@@ -120,0 +123,1 @@\n+#include \"gc\/z\/zHeap.inline.hpp\"\n@@ -127,1 +131,1 @@\n-#include \"osContainer_linux.hpp\"\n+#include \"osContainer_linux.hpp\"\n@@ -198,0 +202,4 @@\n+WB_ENTRY(jlong, WB_GetMinimumJavaStackSize(JNIEnv* env, jobject o))\n+  return os::get_minimum_java_stack_size();\n+WB_END\n+\n@@ -507,0 +515,16 @@\n+WB_ENTRY(jboolean, WB_ShipDebugInfoFull(JNIEnv* env, jobject o))\n+#if defined(SHIP_DEBUGINFO_FULL)\n+  return true;\n+#else\n+  return false;\n+#endif\n+WB_END\n+\n+WB_ENTRY(jboolean, WB_ShipDebugInfoPublic(JNIEnv* env, jobject o))\n+#if defined(SHIP_DEBUGINFO_PUBLIC)\n+  return true;\n+#else\n+  return false;\n+#endif\n+WB_END\n+\n@@ -586,22 +610,0 @@\n-#endif \/\/ INCLUDE_G1GC\n-\n-#if INCLUDE_PARALLELGC\n-\n-WB_ENTRY(jlong, WB_PSVirtualSpaceAlignment(JNIEnv* env, jobject o))\n-  if (UseParallelGC) {\n-    return GenAlignment;\n-  }\n-  THROW_MSG_0(vmSymbols::java_lang_UnsupportedOperationException(), \"WB_PSVirtualSpaceAlignment: Parallel GC is not enabled\");\n-WB_END\n-\n-WB_ENTRY(jlong, WB_PSHeapGenerationAlignment(JNIEnv* env, jobject o))\n-  if (UseParallelGC) {\n-    return GenAlignment;\n-  }\n-  THROW_MSG_0(vmSymbols::java_lang_UnsupportedOperationException(), \"WB_PSHeapGenerationAlignment: Parallel GC is not enabled\");\n-WB_END\n-\n-#endif \/\/ INCLUDE_PARALLELGC\n-\n-#if INCLUDE_G1GC\n-\n@@ -797,1 +799,1 @@\n-                nm->make_not_entrant(\"Whitebox deoptimization\", false \/* don't interfere with testing *\/);\n+                nm->make_not_entrant(nmethod::InvalidationReason::WHITEBOX_DEOPTIMIZATION, false \/* don't interfere with testing *\/);\n@@ -1100,0 +1102,16 @@\n+bool WhiteBox::is_asan_enabled() {\n+#ifdef ADDRESS_SANITIZER\n+  return true;\n+#else\n+  return false;\n+#endif\n+}\n+\n+bool WhiteBox::is_ubsan_enabled() {\n+#ifdef UNDEFINED_BEHAVIOR_SANITIZER\n+  return true;\n+#else\n+  return false;\n+#endif\n+}\n+\n@@ -1162,1 +1180,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(klass)));\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(klass));\n@@ -1507,7 +1525,0 @@\n-  Universe::heap()->soft_ref_policy()->set_should_clear_all_soft_refs(true);\n-#if INCLUDE_G1GC || INCLUDE_SERIALGC\n-  if (UseG1GC || UseSerialGC) {\n-    \/\/ Needs to be cleared explicitly for G1 and Serial GC.\n-    Universe::heap()->soft_ref_policy()->set_should_clear_all_soft_refs(false);\n-  }\n-#endif \/\/ INCLUDE_G1GC || INCLUDE_SERIALGC\n@@ -1560,1 +1571,3 @@\n-      address((jlong) blob) { }\n+      address((jlong) blob),\n+      code_begin((jlong) blob->code_begin()),\n+      is_nmethod((jboolean) blob->is_nmethod()) { }\n@@ -1566,0 +1579,2 @@\n+  const jlong       code_begin;\n+  const jboolean    is_nmethod;\n@@ -1572,1 +1587,1 @@\n-  jobjectArray result = env->NewObjectArray(4, clazz, nullptr);\n+  jobjectArray result = env->NewObjectArray(6, clazz, nullptr);\n@@ -1590,0 +1605,8 @@\n+  obj = longBox(thread, env, cb->code_begin);\n+  CHECK_JNI_EXCEPTION_(env, nullptr);\n+  env->SetObjectArrayElement(result, 4, obj);\n+\n+  obj = booleanBox(thread, env, cb->is_nmethod);\n+  CHECK_JNI_EXCEPTION_(env, nullptr);\n+  env->SetObjectArrayElement(result, 5, obj);\n+\n@@ -1639,0 +1662,38 @@\n+WB_ENTRY(void, WB_RelocateNMethodFromMethod(JNIEnv* env, jobject o, jobject method, jint blob_type))\n+  ResourceMark rm(THREAD);\n+  jmethodID jmid = reflected_method_to_jmid(thread, env, method);\n+  CHECK_JNI_EXCEPTION(env);\n+  methodHandle mh(THREAD, Method::checked_resolve_jmethod_id(jmid));\n+  nmethod* code = mh->code();\n+  if (code != nullptr) {\n+    MutexLocker ml_Compile_lock(Compile_lock);\n+    CompiledICLocker ic_locker(code);\n+    MutexLocker ml_CodeCache_lock(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+    code->relocate(static_cast<CodeBlobType>(blob_type));\n+  }\n+WB_END\n+\n+WB_ENTRY(void, WB_RelocateNMethodFromAddr(JNIEnv* env, jobject o, jlong addr, jint blob_type))\n+  ResourceMark rm(THREAD);\n+  CHECK_JNI_EXCEPTION(env);\n+  void* address = (void*) addr;\n+\n+  if (address == nullptr) {\n+    return;\n+  }\n+\n+  MutexLocker ml_Compile_lock(Compile_lock);\n+  MutexLocker ml_CompiledIC_lock(CompiledIC_lock, Mutex::_no_safepoint_check_flag);\n+  MutexLocker ml_CodeCache_lock(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+\n+  \/\/ Verify that nmethod address is still valid\n+  CodeBlob* blob = CodeCache::find_blob(address);\n+  if (blob != nullptr && blob->is_nmethod()) {\n+    nmethod* code = blob->as_nmethod();\n+    if (code->is_in_use() && !code->is_unloading()) {\n+      CompiledICLocker ic_locker(code);\n+      code->relocate(static_cast<CodeBlobType>(blob_type));\n+    }\n+  }\n+WB_END\n+\n@@ -1897,1 +1958,1 @@\n-WB_ENTRY(jlong, WB_MetaspaceSharedRegionAlignment(JNIEnv* env, jobject wb))\n+WB_ENTRY(jlong, WB_AOTMetaspaceRegionAlignment(JNIEnv* env, jobject wb))\n@@ -1899,1 +1960,1 @@\n-  return (jlong)MetaspaceShared::core_region_alignment();\n+  return (jlong)AOTMetaspace::core_region_alignment();\n@@ -1911,0 +1972,8 @@\n+WB_ENTRY(jboolean, WB_IsAsanEnabled(JNIEnv* env))\n+  return (jboolean) WhiteBox::is_asan_enabled();\n+WB_END\n+\n+WB_ENTRY(jboolean, WB_IsUbsanEnabled(JNIEnv* env))\n+  return (jboolean) WhiteBox::is_ubsan_enabled();\n+WB_END\n+\n@@ -1919,2 +1988,2 @@\n-WB_ENTRY(jboolean, WB_supportsRecursiveLightweightLocking(JNIEnv* env))\n-  return (jboolean) VM_Version::supports_recursive_lightweight_locking();\n+WB_ENTRY(jboolean, WB_supportsRecursiveFastLocking(JNIEnv* env))\n+  return (jboolean) VM_Version::supports_recursive_fast_locking();\n@@ -1940,1 +2009,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(klass)));\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(klass));\n@@ -1945,1 +2014,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(klass)));\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(klass));\n@@ -1951,1 +2020,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(klass)));\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(klass));\n@@ -1960,1 +2029,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(klass)));\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(klass));\n@@ -1969,1 +2038,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(klass)));\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(klass));\n@@ -1978,1 +2047,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(klass)));\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(klass));\n@@ -1987,1 +2056,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(klass)));\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(klass));\n@@ -1996,1 +2065,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(klass)));\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(klass));\n@@ -2151,0 +2220,3 @@\n+  if (!HeapShared::is_loading_mapping_mode()) {\n+    return false;\n+  }\n@@ -2159,1 +2231,1 @@\n-  return (jboolean)MetaspaceShared::is_in_shared_metaspace(java_lang_Class::as_Klass(JNIHandles::resolve_non_null(clazz)));\n+  return (jboolean)AOTMetaspace::in_aot_cache(java_lang_Class::as_Klass(JNIHandles::resolve_non_null(clazz)));\n@@ -2163,1 +2235,1 @@\n-  return ArchiveHeapLoader::is_mapped();\n+  return AOTMappedHeapLoader::is_mapped();\n@@ -2176,1 +2248,1 @@\n-  return ArchiveHeapLoader::is_mapped();\n+  return AOTMappedHeapLoader::is_mapped();\n@@ -2206,1 +2278,1 @@\n-WB_ENTRY(jboolean, WB_CanWriteJavaHeapArchive(JNIEnv* env))\n+static bool canWriteJavaHeapArchive() {\n@@ -2208,0 +2280,8 @@\n+}\n+\n+WB_ENTRY(jboolean, WB_CanWriteJavaHeapArchive(JNIEnv* env))\n+  return canWriteJavaHeapArchive();\n+WB_END\n+\n+WB_ENTRY(jboolean, WB_CanWriteMappedJavaHeapArchive(JNIEnv* env))\n+  return canWriteJavaHeapArchive() && !AOTStreamableObjects;\n@@ -2210,0 +2290,3 @@\n+WB_ENTRY(jboolean, WB_CanWriteStreamedJavaHeapArchive(JNIEnv* env))\n+  return canWriteJavaHeapArchive() && AOTStreamableObjects;\n+WB_END\n@@ -2246,1 +2329,1 @@\n-  class ReadMonitorsClosure : public HandshakeClosure {\n+  class ReadMonitorsHandshakeClosure : public HandshakeClosure {\n@@ -2281,1 +2364,1 @@\n-    ReadMonitorsClosure() : HandshakeClosure(\"WB_HandshakeReadMonitors\"), _executed(false) {}\n+    ReadMonitorsHandshakeClosure() : HandshakeClosure(\"WB_HandshakeReadMonitors\"), _executed(false) {}\n@@ -2285,1 +2368,1 @@\n-  ReadMonitorsClosure rmc;\n+  ReadMonitorsHandshakeClosure rmhc;\n@@ -2291,1 +2374,1 @@\n-      Handshake::execute(&rmc, &tlh, target);\n+      Handshake::execute(&rmhc, &tlh, target);\n@@ -2294,1 +2377,1 @@\n-  return rmc.executed();\n+  return rmhc.executed();\n@@ -2298,1 +2381,1 @@\n-  class TraceSelfClosure : public HandshakeClosure {\n+  class TraceSelfHandshakeClosure : public HandshakeClosure {\n@@ -2308,1 +2391,1 @@\n-      Atomic::inc(&_num_threads_completed);\n+      AtomicAccess::inc(&_num_threads_completed);\n@@ -2312,1 +2395,1 @@\n-    TraceSelfClosure(Thread* thread) : HandshakeClosure(\"WB_TraceSelf\"), _num_threads_completed(0) {}\n+    TraceSelfHandshakeClosure(Thread* thread) : HandshakeClosure(\"WB_TraceSelf\"), _num_threads_completed(0) {}\n@@ -2316,1 +2399,1 @@\n-  TraceSelfClosure tsc(Thread::current());\n+  TraceSelfHandshakeClosure tshc(Thread::current());\n@@ -2319,1 +2402,1 @@\n-    Handshake::execute(&tsc);\n+    Handshake::execute(&tshc);\n@@ -2325,1 +2408,1 @@\n-      Handshake::execute(&tsc, &tlh, target);\n+      Handshake::execute(&tshc, &tlh, target);\n@@ -2328,1 +2411,1 @@\n-  return tsc.num_threads_completed();\n+  return tshc.num_threads_completed();\n@@ -2332,1 +2415,1 @@\n-  class TraceSelfClosure : public AsyncHandshakeClosure {\n+  class TraceSelfHandshakeClosure : public AsyncHandshakeClosure {\n@@ -2347,1 +2430,1 @@\n-    TraceSelfClosure(JavaThread* self_target) : AsyncHandshakeClosure(\"WB_TraceSelf\"), _self(self_target) {}\n+    TraceSelfHandshakeClosure(JavaThread* self_target) : AsyncHandshakeClosure(\"WB_TraceSelf\"), _self(self_target) {}\n@@ -2354,2 +2437,2 @@\n-      TraceSelfClosure* tsc = new TraceSelfClosure(target);\n-      Handshake::execute(tsc, target);\n+      TraceSelfHandshakeClosure* tshc = new TraceSelfHandshakeClosure(target);\n+      Handshake::execute(tshc, target);\n@@ -2375,1 +2458,1 @@\n-    while (Atomic::cmpxchg(&_emulated_lock, 0, 1) != 0) {}\n+    while (AtomicAccess::cmpxchg(&_emulated_lock, 0, 1) != 0) {}\n@@ -2382,1 +2465,1 @@\n-  Atomic::store(&_emulated_lock, 0);\n+  AtomicAccess::store(&_emulated_lock, 0);\n@@ -2390,4 +2473,2 @@\n-  \/\/Get the class of our object\n-  Klass* arg_klass = object->klass();\n-  \/\/Turn it into an instance-klass\n-  InstanceKlass* ik = InstanceKlass::cast(arg_klass);\n+  \/\/Only non-array oops have fields. Don't call this function on arrays!\n+  InstanceKlass* ik = InstanceKlass::cast(object->klass());\n@@ -2510,2 +2591,2 @@\n-  LINUX_ONLY(return os::Linux::physical_memory();)\n-  return os::physical_memory();\n+  LINUX_ONLY(return static_cast<jlong>(os::Linux::physical_memory());)\n+  return static_cast<jlong>(os::physical_memory());\n@@ -2516,1 +2597,4 @@\n-  return os::available_memory();\n+  physical_memory_size_type avail_mem = 0;\n+  \/\/ Return value ignored - defaulting to 0 on failure.\n+  (void)os::available_memory(avail_mem);\n+  return static_cast<jlong>(avail_mem);\n@@ -2521,1 +2605,7 @@\n-  LINUX_ONLY(return (jlong)os::Linux::host_swap();)\n+#ifdef LINUX\n+  physical_memory_size_type swap_val = 0;\n+  if (!os::Linux::host_swap(swap_val)) {\n+    return -1; \/\/ treat as unlimited\n+  }\n+  return static_cast<jlong>(swap_val);\n+#endif\n@@ -2662,0 +2752,17 @@\n+WB_ENTRY(void, WB_BusyWaitCPUTime(JNIEnv* env, jobject wb, jint time))\n+  ThreadToNativeFromVM  ttn(thread);\n+  u8 start = os::current_thread_cpu_time();\n+  u8 target_duration = time * (u8)1000000;\n+  while (os::current_thread_cpu_time() - start < target_duration) {\n+    for (volatile int i = 0; i < 1000000; i++);\n+  }\n+WB_END\n+\n+WB_ENTRY(jboolean, WB_CPUSamplerSetOutOfStackWalking(JNIEnv* env, jobject wb, jboolean enable))\n+  #if defined(ASSERT) && INCLUDE_JFR && defined(LINUX)\n+    return JfrCPUTimeThreadSampling::set_out_of_stack_walking_enabled(enable == JNI_TRUE) ? JNI_TRUE : JNI_FALSE;\n+  #else\n+    return JNI_FALSE;\n+  #endif\n+WB_END\n+\n@@ -2728,0 +2835,8 @@\n+WB_ENTRY(void, WB_ControlledCrash(JNIEnv* env, jobject o, jint how))\n+#ifdef ASSERT\n+  VMError::controlled_crash(how);\n+#else\n+  THROW_MSG(vmSymbols::java_lang_UnsupportedOperationException(), \"Only available in debug builds\");\n+#endif\n+WB_END\n+\n@@ -2740,0 +2855,2 @@\n+  {CC\"shipsFullDebugInfo\",               CC\"()Z\",                   (void*)&WB_ShipDebugInfoFull},\n+  {CC\"shipsPublicDebugInfo\",             CC\"()Z\",                   (void*)&WB_ShipDebugInfoPublic},\n@@ -2776,4 +2893,0 @@\n-#if INCLUDE_PARALLELGC\n-  {CC\"psVirtualSpaceAlignment\",CC\"()J\",               (void*)&WB_PSVirtualSpaceAlignment},\n-  {CC\"psHeapGenerationAlignment\",CC\"()J\",             (void*)&WB_PSHeapGenerationAlignment},\n-#endif\n@@ -2885,1 +2998,1 @@\n-  {CC\"metaspaceSharedRegionAlignment\", CC\"()J\",       (void*)&WB_MetaspaceSharedRegionAlignment },\n+  {CC\"metaspaceSharedRegionAlignment\", CC\"()J\",       (void*)&WB_AOTMetaspaceRegionAlignment },\n@@ -2889,0 +3002,3 @@\n+  {CC\"relocateNMethodFromMethod0\", CC\"(Ljava\/lang\/reflect\/Executable;I)V\",\n+                                                      (void*)&WB_RelocateNMethodFromMethod },\n+  {CC\"relocateNMethodFromAddr\", CC\"(JI)V\",            (void*)&WB_RelocateNMethodFromAddr },\n@@ -2911,0 +3027,2 @@\n+  {CC\"isAsanEnabled\", CC\"()Z\",                        (void*)&WB_IsAsanEnabled },\n+  {CC\"isUbsanEnabled\", CC\"()Z\",                       (void*)&WB_IsUbsanEnabled },\n@@ -2913,1 +3031,1 @@\n-  {CC\"supportsRecursiveLightweightLocking\", CC\"()Z\",  (void*)&WB_supportsRecursiveLightweightLocking },\n+  {CC\"supportsRecursiveFastLocking\", CC\"()Z\",         (void*)&WB_supportsRecursiveFastLocking },\n@@ -2958,0 +3076,2 @@\n+  {CC\"canWriteMappedJavaHeapArchive\",     CC\"()Z\",    (void*)&WB_CanWriteMappedJavaHeapArchive },\n+  {CC\"canWriteStreamedJavaHeapArchive\",   CC\"()Z\",    (void*)&WB_CanWriteStreamedJavaHeapArchive },\n@@ -3009,0 +3129,2 @@\n+  {CC\"busyWaitCPUTime\", CC\"(I)V\",                     (void*)&WB_BusyWaitCPUTime},\n+  {CC\"cpuSamplerSetOutOfStackWalking\", CC\"(Z)Z\",      (void*)&WB_CPUSamplerSetOutOfStackWalking},\n@@ -3018,1 +3140,2 @@\n-  {CC\"lockAndStuckInSafepoint\", CC\"()V\", (void*)&WB_TakeLockAndHangInSafepoint},\n+  {CC\"lockAndStuckInSafepoint\", CC\"()V\",              (void*)&WB_TakeLockAndHangInSafepoint},\n+  {CC\"getMinimumJavaStackSize\", CC\"()J\",              (void*)&WB_GetMinimumJavaStackSize},\n@@ -3021,1 +3144,2 @@\n-  {CC\"isStatic\", CC\"()Z\",                             (void*)&WB_IsStaticallyLinked}\n+  {CC\"isStatic\", CC\"()Z\",                             (void*)&WB_IsStaticallyLinked},\n+  {CC\"controlledCrash\",CC\"(I)V\",                      (void*)&WB_ControlledCrash},\n@@ -3024,1 +3148,0 @@\n-\n@@ -3031,1 +3154,1 @@\n-      InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(wbclass)));\n+      InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(wbclass));\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":213,"deletions":90,"binary":false,"changes":303,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"runtime\/os.hpp\"\n@@ -208,1 +209,0 @@\n-                 IA32_ONLY(\"x86\")                \\\n@@ -275,0 +275,14 @@\n+      #elif _MSC_VER == 1939\n+        #define HOTSPOT_BUILD_COMPILER \"MS VC++ 17.9 (VS2022)\"\n+      #elif _MSC_VER == 1940\n+        #define HOTSPOT_BUILD_COMPILER \"MS VC++ 17.10 (VS2022)\"\n+      #elif _MSC_VER == 1941\n+        #define HOTSPOT_BUILD_COMPILER \"MS VC++ 17.11 (VS2022)\"\n+      #elif _MSC_VER == 1942\n+        #define HOTSPOT_BUILD_COMPILER \"MS VC++ 17.12 (VS2022)\"\n+      #elif _MSC_VER == 1943\n+        #define HOTSPOT_BUILD_COMPILER \"MS VC++ 17.13 (VS2022)\"\n+      #elif _MSC_VER == 1944\n+        #define HOTSPOT_BUILD_COMPILER \"MS VC++ 17.14 (VS2022)\"\n+      #elif _MSC_VER == 1950\n+        #define HOTSPOT_BUILD_COMPILER \"MS VC++ 18.0 (VS2026)\"\n@@ -329,13 +343,0 @@\n-const char* Abstract_VM_Version::extract_features_string(const char* cpu_info_string,\n-                                                         size_t cpu_info_string_len,\n-                                                         size_t features_offset) {\n-  assert(features_offset <= cpu_info_string_len, \"\");\n-  if (features_offset < cpu_info_string_len) {\n-    assert(cpu_info_string[features_offset + 0] == ',', \"\");\n-    assert(cpu_info_string[features_offset + 1] == ' ', \"\");\n-    return cpu_info_string + features_offset + 2; \/\/ skip initial \", \"\n-  } else {\n-    return \"\"; \/\/ empty\n-  }\n-}\n-\n","filename":"src\/hotspot\/share\/runtime\/abstract_vm_version.cpp","additions":15,"deletions":14,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -55,1 +55,1 @@\n-    int print_numbers(char *buf_orig, size_t buflen, bool hexonly = false) const { return 0; }\n+    void print_numbers(outputStream &os, bool hexonly = false) const {}\n@@ -140,3 +140,0 @@\n-  static const char* extract_features_string(const char* cpu_info_string,\n-                                             size_t cpu_info_string_len,\n-                                             size_t features_offset);\n@@ -202,2 +199,2 @@\n-  \/\/ Is recursive lightweight locking implemented for this platform?\n-  constexpr static bool supports_recursive_lightweight_locking() { return false; }\n+  \/\/ Is recursive fast locking implemented for this platform?\n+  constexpr static bool supports_recursive_fast_locking() { return false; }\n","filename":"src\/hotspot\/share\/runtime\/abstract_vm_version.hpp","additions":3,"deletions":6,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2026, Oracle and\/or its affiliates. All rights reserved.\n@@ -35,0 +35,2 @@\n+#include \"cppstdlib\/limits.hpp\"\n+#include \"gc\/shared\/gc_globals.hpp\"\n@@ -67,1 +69,0 @@\n-#include \"utilities\/checkedCast.hpp\"\n@@ -79,3 +80,0 @@\n-#include <limits>\n-#include <type_traits>\n-\n@@ -326,0 +324,4 @@\n+#define ENABLE_FINAL_FIELD_MUTATION \"enable.final.field.mutation\"\n+#define ENABLE_FINAL_FIELD_MUTATION_LEN 27\n+#define ILLEGAL_FINAL_FIELD_MUTATION \"illegal.final.field.mutation\"\n+#define ILLEGAL_FINAL_FIELD_MUTATION_LEN 28\n@@ -352,1 +354,3 @@\n-        matches_property_suffix(property_suffix, ILLEGAL_NATIVE_ACCESS, ILLEGAL_NATIVE_ACCESS_LEN)) {\n+        matches_property_suffix(property_suffix, ILLEGAL_NATIVE_ACCESS, ILLEGAL_NATIVE_ACCESS_LEN) ||\n+        matches_property_suffix(property_suffix, ENABLE_FINAL_FIELD_MUTATION, ENABLE_FINAL_FIELD_MUTATION_LEN) ||\n+        matches_property_suffix(property_suffix, ILLEGAL_FINAL_FIELD_MUTATION, ILLEGAL_FINAL_FIELD_MUTATION_LEN)) {\n@@ -537,6 +541,1 @@\n-#ifdef LINUX\n-  { \"UseLinuxPosixThreadCPUClocks\", JDK_Version::jdk(24), JDK_Version::jdk(25), JDK_Version::jdk(26) },\n-  { \"UseOprofile\",                  JDK_Version::jdk(25), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n-#endif\n-  { \"LockingMode\",                  JDK_Version::jdk(24), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n-  { \"UseCompressedClassPointers\",   JDK_Version::jdk(25),  JDK_Version::jdk(26), JDK_Version::undefined() },\n+  { \"UseCompressedClassPointers\",   JDK_Version::jdk(25),  JDK_Version::jdk(27), JDK_Version::undefined() },\n@@ -545,0 +544,6 @@\n+  { \"ParallelRefProcEnabled\",       JDK_Version::jdk(26),  JDK_Version::jdk(27), JDK_Version::jdk(28) },\n+  { \"ParallelRefProcBalancingEnabled\", JDK_Version::jdk(26),  JDK_Version::jdk(27), JDK_Version::jdk(28) },\n+  { \"MaxRAM\",                       JDK_Version::jdk(26),  JDK_Version::jdk(27), JDK_Version::jdk(28) },\n+  { \"AggressiveHeap\",               JDK_Version::jdk(26),  JDK_Version::jdk(27), JDK_Version::jdk(28) },\n+  { \"NeverActAsServerClassMachine\", JDK_Version::jdk(26),  JDK_Version::jdk(27), JDK_Version::jdk(28) },\n+  { \"AlwaysActAsServerClassMachine\", JDK_Version::jdk(26),  JDK_Version::jdk(27), JDK_Version::jdk(28) },\n@@ -550,3 +555,0 @@\n-  { \"PerfDataSamplingInterval\",     JDK_Version::undefined(), JDK_Version::jdk(25), JDK_Version::jdk(26) },\n-  { \"ZGenerational\",                JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::undefined() },\n-  { \"ZMarkStackSpaceLimit\",         JDK_Version::undefined(), JDK_Version::jdk(25), JDK_Version::undefined() },\n@@ -558,0 +560,2 @@\n+  { \"PSChunkLargeArrays\",           JDK_Version::jdk(26),  JDK_Version::jdk(27), JDK_Version::jdk(28) },\n+\n@@ -573,11 +577,0 @@\n-  { \"CREngine\",                     JDK_Version::jdk(24), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n-  { \"CRAllowedOpenFilePrefixes\",    JDK_Version::jdk(24), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n-  { \"CRAllowToSkipCheckpoint\",      JDK_Version::jdk(24), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n-  { \"CRHeapDumpOnCheckpointException\", JDK_Version::jdk(24), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n-  { \"CRPrintResourcesOnCheckpoint\", JDK_Version::jdk(24), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n-  { \"CRTraceStartupTime\",           JDK_Version::jdk(24), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n-  { \"CRDoThrowCheckpointException\", JDK_Version::jdk(24), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n-  { \"CRPauseOnCheckpointError\",     JDK_Version::jdk(24), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n-  { \"CRTrace\",                      JDK_Version::undefined(), JDK_Version::jdk(24), JDK_Version::jdk(26) },\n-  { \"CRaCAllowToSkipCheckpoint\",    JDK_Version::jdk(25), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n-  { \"CRaCDoThrowCheckpointException\", JDK_Version::undefined(), JDK_Version::jdk(25), JDK_Version::jdk(26) },\n@@ -597,9 +590,0 @@\n-  { \"CREngine\",                        \"CRaCEngine\" },\n-  { \"CRAllowedOpenFilePrefixes\",       \"CRaCAllowedOpenFilePrefixes\" },\n-  { \"CRAllowToSkipCheckpoint\",         \"CRaCSkipCheckpoint\"},\n-  { \"CRHeapDumpOnCheckpointException\", \"CRaCHeapDumpOnCheckpointException\" },\n-  { \"CRPrintResourcesOnCheckpoint\",    \"CRaCPrintResourcesOnCheckpoint\" },\n-  { \"CRTraceStartupTime\",              \"CRaCTraceStartupTime\" },\n-  { \"CRDoThrowCheckpointException\",    \"CRaCDoThrowCheckpointException\" },\n-  { \"CRPauseOnCheckpointError\",        \"CRaCPauseOnCheckpointError\" },\n-  { \"CRaCAllowToSkipCheckpoint\",       \"CRaCSkipCheckpoint\" },\n@@ -1121,0 +1105,7 @@\n+void Arguments::set_jvm_flags_file(const char *value) {\n+  if (_jvm_flags_file != nullptr) {\n+    os::free(_jvm_flags_file);\n+  }\n+  _jvm_flags_file = os::strdup_check_oom(value);\n+}\n+\n@@ -1235,1 +1226,1 @@\n-  int  pos = 0;\n+  size_t pos = 0;\n@@ -1240,1 +1231,1 @@\n-  int  quote_c        = 0;\n+  char quote_c        = 0;\n@@ -1243,2 +1234,8 @@\n-  int c = getc(stream);\n-  while(c != EOF && pos < (int)(sizeof(token)-1)) {\n+  int c_or_eof = getc(stream);\n+  while (c_or_eof != EOF && pos < (sizeof(token) - 1)) {\n+    \/\/ We have checked the c_or_eof for EOF. getc should only ever return the\n+    \/\/ EOF or an unsigned char converted to an int. We cast down to a char to\n+    \/\/ avoid the char to int promotions we would otherwise do in the comparisons\n+    \/\/ below (which would be incorrect if we ever compared to a non-ascii char),\n+    \/\/ and the int to char conversions we would otherwise do in the assignments.\n+    const char c = static_cast<char>(c_or_eof);\n@@ -1252,1 +1249,1 @@\n-          token[pos++] = checked_cast<char>(c);\n+          token[pos++] = c;\n@@ -1272,1 +1269,1 @@\n-        token[pos++] = checked_cast<char>(c);\n+        token[pos++] = c;\n@@ -1275,1 +1272,1 @@\n-    c = getc(stream);\n+    c_or_eof = getc(stream);\n@@ -1502,1 +1499,1 @@\n-  _conservative_max_heap_alignment = MAX4(heap_alignment,\n+  _conservative_max_heap_alignment = MAX3(heap_alignment,\n@@ -1504,2 +1501,2 @@\n-                                          os::max_page_size(),\n-                                          GCArguments::compute_heap_alignment());\n+                                          os::max_page_size());\n+  assert(is_power_of_2(_conservative_max_heap_alignment), \"Expected to be a power-of-2\");\n@@ -1524,13 +1521,10 @@\n-  size_t max_allocatable;\n-  size_t result = limit;\n-  if (os::has_allocatable_memory_limit(&max_allocatable)) {\n-    \/\/ The AggressiveHeap check is a temporary workaround to avoid calling\n-    \/\/ GCarguments::heap_virtual_to_physical_ratio() before a GC has been\n-    \/\/ selected. This works because AggressiveHeap implies UseParallelGC\n-    \/\/ where we know the ratio will be 1. Once the AggressiveHeap option is\n-    \/\/ removed, this can be cleaned up.\n-    size_t heap_virtual_to_physical_ratio = (AggressiveHeap ? 1 : GCConfig::arguments()->heap_virtual_to_physical_ratio());\n-    size_t fraction = MaxVirtMemFraction * heap_virtual_to_physical_ratio;\n-    result = MIN2(result, max_allocatable \/ fraction);\n-  }\n-  return result;\n+  \/\/ The AggressiveHeap check is a temporary workaround to avoid calling\n+  \/\/ GCarguments::heap_virtual_to_physical_ratio() before a GC has been\n+  \/\/ selected. This works because AggressiveHeap implies UseParallelGC\n+  \/\/ where we know the ratio will be 1. Once the AggressiveHeap option is\n+  \/\/ removed, this can be cleaned up.\n+  size_t heap_virtual_to_physical_ratio = (AggressiveHeap ? 1 : GCConfig::arguments()->heap_virtual_to_physical_ratio());\n+  size_t fraction = MaxVirtMemFraction * heap_virtual_to_physical_ratio;\n+  size_t max_allocatable = os::commit_memory_limit();\n+\n+  return MIN2(limit, max_allocatable \/ fraction);\n@@ -1542,0 +1536,4 @@\n+static size_t clamp_by_size_t_max(uint64_t value) {\n+  return (size_t)MIN2(value, (uint64_t)std::numeric_limits<size_t>::max());\n+}\n+\n@@ -1543,16 +1541,10 @@\n-  julong phys_mem;\n-\n-  \/\/ If the user specified one of these options, they\n-  \/\/ want specific memory sizing so do not limit memory\n-  \/\/ based on compressed oops addressability.\n-  \/\/ Also, memory limits will be calculated based on\n-  \/\/ available os physical memory, not our MaxRAM limit,\n-  \/\/ unless MaxRAM is also specified.\n-  bool override_coop_limit = (!FLAG_IS_DEFAULT(MaxRAMPercentage) ||\n-                           !FLAG_IS_DEFAULT(MinRAMPercentage) ||\n-                           !FLAG_IS_DEFAULT(InitialRAMPercentage) ||\n-                           !FLAG_IS_DEFAULT(MaxRAM));\n-  if (override_coop_limit) {\n-    if (FLAG_IS_DEFAULT(MaxRAM)) {\n-      phys_mem = os::physical_memory();\n-      FLAG_SET_ERGO(MaxRAM, (uint64_t)phys_mem);\n+  \/\/ Check if the user has configured any limit on the amount of RAM we may use.\n+  bool has_ram_limit = !FLAG_IS_DEFAULT(MaxRAMPercentage) ||\n+                       !FLAG_IS_DEFAULT(MinRAMPercentage) ||\n+                       !FLAG_IS_DEFAULT(InitialRAMPercentage) ||\n+                       !FLAG_IS_DEFAULT(MaxRAM);\n+\n+  if (FLAG_IS_DEFAULT(MaxRAM)) {\n+    if (CompilerConfig::should_set_client_emulation_mode_flags()) {\n+      \/\/ Limit the available memory if client emulation mode is enabled.\n+      FLAG_SET_ERGO(MaxRAM, 1ULL*G);\n@@ -1560,1 +1552,2 @@\n-      phys_mem = (julong)MaxRAM;\n+      \/\/ Use the available physical memory on the system.\n+      FLAG_SET_ERGO(MaxRAM, os::physical_memory());\n@@ -1562,3 +1555,0 @@\n-  } else {\n-    phys_mem = FLAG_IS_DEFAULT(MaxRAM) ? MIN2(os::physical_memory(), (julong)MaxRAM)\n-                                       : (julong)MaxRAM;\n@@ -1567,3 +1557,3 @@\n-  \/\/ If the maximum heap size has not been set with -Xmx,\n-  \/\/ then set it as fraction of the size of physical memory,\n-  \/\/ respecting the maximum and minimum sizes of the heap.\n+  \/\/ If the maximum heap size has not been set with -Xmx, then set it as\n+  \/\/ fraction of the size of physical memory, respecting the maximum and\n+  \/\/ minimum sizes of the heap.\n@@ -1571,2 +1561,6 @@\n-    julong reasonable_max = (julong)(((double)phys_mem * MaxRAMPercentage) \/ 100);\n-    const julong reasonable_min = (julong)(((double)phys_mem * MinRAMPercentage) \/ 100);\n+    uint64_t min_memory = (uint64_t)(((double)MaxRAM * MinRAMPercentage) \/ 100);\n+    uint64_t max_memory = (uint64_t)(((double)MaxRAM * MaxRAMPercentage) \/ 100);\n+\n+    const size_t reasonable_min = clamp_by_size_t_max(min_memory);\n+    size_t reasonable_max = clamp_by_size_t_max(max_memory);\n+\n@@ -1579,1 +1573,1 @@\n-      reasonable_max = MAX2(reasonable_max, (julong)MaxHeapSize);\n+      reasonable_max = MAX2(reasonable_max, MaxHeapSize);\n@@ -1584,1 +1578,1 @@\n-      reasonable_max = MIN2(reasonable_max, (julong)ErgoHeapSizeLimit);\n+      reasonable_max = MIN2(reasonable_max, ErgoHeapSizeLimit);\n@@ -1594,1 +1588,1 @@\n-      reasonable_max = MAX2(reasonable_max, (julong)InitialHeapSize);\n+      reasonable_max = MAX2(reasonable_max, InitialHeapSize);\n@@ -1596,1 +1590,1 @@\n-      reasonable_max = MAX2(reasonable_max, (julong)MinHeapSize);\n+      reasonable_max = MAX2(reasonable_max, MinHeapSize);\n@@ -1605,2 +1599,2 @@\n-          log_debug(gc, heap, coops)(\"HeapBaseMinAddress must be at least %zu\"\n-                                     \" (%zuG) which is greater than value given %zu\",\n+          log_debug(gc, heap, coops)(\"HeapBaseMinAddress must be at least %zu \"\n+                                     \"(%zuG) which is greater than value given %zu\",\n@@ -1614,0 +1608,1 @@\n+\n@@ -1615,2 +1610,2 @@\n-      \/\/ Limit the heap size to the maximum possible when using compressed oops\n-      julong max_coop_heap = (julong)max_heap_for_compressed_oops();\n+      uintptr_t heap_end = HeapBaseMinAddress + MaxHeapSize;\n+      uintptr_t max_coop_heap = max_heap_for_compressed_oops();\n@@ -1618,3 +1613,4 @@\n-      if (HeapBaseMinAddress + MaxHeapSize < max_coop_heap) {\n-        \/\/ Heap should be above HeapBaseMinAddress to get zero based compressed oops\n-        \/\/ but it should be not less than default MaxHeapSize.\n+      \/\/ Limit the heap size to the maximum possible when using compressed oops\n+      if (heap_end < max_coop_heap) {\n+        \/\/ Heap should be above HeapBaseMinAddress to get zero based compressed\n+        \/\/ oops but it should be not less than default MaxHeapSize.\n@@ -1624,4 +1620,3 @@\n-      \/\/ If user specified flags prioritizing os physical\n-      \/\/ memory limits, then disable compressed oops if\n-      \/\/ limits exceed max_coop_heap and UseCompressedOops\n-      \/\/ was not specified.\n+      \/\/ If the user has configured any limit on the amount of RAM we may use,\n+      \/\/ then disable compressed oops if the calculated max exceeds max_coop_heap\n+      \/\/ and UseCompressedOops was not specified.\n@@ -1629,5 +1624,5 @@\n-        if (FLAG_IS_ERGO(UseCompressedOops) && override_coop_limit) {\n-          aot_log_info(aot)(\"UseCompressedOops and UseCompressedClassPointers have been disabled due to\"\n-            \" max heap %zu > compressed oop heap %zu. \"\n-            \"Please check the setting of MaxRAMPercentage %5.2f.\"\n-            ,(size_t)reasonable_max, (size_t)max_coop_heap, MaxRAMPercentage);\n+        if (FLAG_IS_ERGO(UseCompressedOops) && has_ram_limit) {\n+          log_debug(gc, heap, coops)(\"UseCompressedOops disabled due to \"\n+                                     \"max heap %zu > compressed oop heap %zu. \"\n+                                     \"Please check the setting of MaxRAMPercentage %5.2f.\",\n+                                     reasonable_max, (size_t)max_coop_heap, MaxRAMPercentage);\n@@ -1636,1 +1631,1 @@\n-          reasonable_max = MIN2(reasonable_max, max_coop_heap);\n+          reasonable_max = max_coop_heap;\n@@ -1642,2 +1637,2 @@\n-    log_trace(gc, heap)(\"  Maximum heap size %zu\", (size_t) reasonable_max);\n-    FLAG_SET_ERGO(MaxHeapSize, (size_t)reasonable_max);\n+    log_trace(gc, heap)(\"  Maximum heap size %zu\", reasonable_max);\n+    FLAG_SET_ERGO(MaxHeapSize, reasonable_max);\n@@ -1649,4 +1644,2 @@\n-    julong reasonable_minimum = (julong)(OldSize + NewSize);\n-\n-    reasonable_minimum = MIN2(reasonable_minimum, (julong)MaxHeapSize);\n-\n+    size_t reasonable_minimum = clamp_by_size_t_max((uint64_t)OldSize + (uint64_t)NewSize);\n+    reasonable_minimum = MIN2(reasonable_minimum, MaxHeapSize);\n@@ -1656,1 +1649,2 @@\n-      julong reasonable_initial = (julong)(((double)phys_mem * InitialRAMPercentage) \/ 100);\n+      uint64_t initial_memory = (uint64_t)(((double)MaxRAM * InitialRAMPercentage) \/ 100);\n+      size_t reasonable_initial = clamp_by_size_t_max(initial_memory);\n@@ -1659,2 +1653,2 @@\n-      reasonable_initial = MAX3(reasonable_initial, reasonable_minimum, (julong)MinHeapSize);\n-      reasonable_initial = MIN2(reasonable_initial, (julong)MaxHeapSize);\n+      reasonable_initial = MAX3(reasonable_initial, reasonable_minimum, MinHeapSize);\n+      reasonable_initial = MIN2(reasonable_initial, MaxHeapSize);\n@@ -1665,0 +1659,1 @@\n+\n@@ -1668,1 +1663,1 @@\n-      FLAG_SET_ERGO(MinHeapSize, MIN2((size_t)reasonable_minimum, InitialHeapSize));\n+      FLAG_SET_ERGO(MinHeapSize, MIN2(reasonable_minimum, InitialHeapSize));\n@@ -1685,1 +1680,2 @@\n-  julong total_memory = os::physical_memory();\n+  physical_memory_size_type phys_mem = os::physical_memory();\n+  julong total_memory = static_cast<julong>(phys_mem);\n@@ -1840,0 +1836,1 @@\n+static unsigned int enable_final_field_mutation = 0;\n@@ -1891,37 +1888,0 @@\n-#ifndef _LP64\n-  if (LockingMode == LM_LEGACY) {\n-    FLAG_SET_CMDLINE(LockingMode, LM_LIGHTWEIGHT);\n-    \/\/ Self-forwarding in bit 3 of the mark-word conflicts\n-    \/\/ with 4-byte-aligned stack-locks.\n-    warning(\"Legacy locking not supported on this platform\");\n-  }\n-#endif\n-\n-  if (UseObjectMonitorTable && LockingMode != LM_LIGHTWEIGHT) {\n-    \/\/ ObjectMonitorTable requires lightweight locking.\n-    FLAG_SET_CMDLINE(UseObjectMonitorTable, false);\n-    warning(\"UseObjectMonitorTable requires LM_LIGHTWEIGHT\");\n-  }\n-\n-#if !defined(X86) && !defined(AARCH64) && !defined(PPC64) && !defined(RISCV64) && !defined(S390)\n-  if (LockingMode == LM_MONITOR) {\n-    jio_fprintf(defaultStream::error_stream(),\n-                \"LockingMode == 0 (LM_MONITOR) is not fully implemented on this architecture\\n\");\n-    return false;\n-  }\n-#endif\n-  if (VerifyHeavyMonitors && LockingMode != LM_MONITOR) {\n-    jio_fprintf(defaultStream::error_stream(),\n-                \"-XX:+VerifyHeavyMonitors requires LockingMode == 0 (LM_MONITOR)\\n\");\n-    return false;\n-  }\n-\n-  if (IgnoreCPUFeatures) {\n-    if (FLAG_IS_DEFAULT(CheckCPUFeatures)) {\n-      FLAG_SET_CMDLINE(CheckCPUFeatures, \"skip\");\n-    } else {\n-      jio_fprintf(defaultStream::error_stream(),\n-                \"Cannot set both -XX:+IgnoreCPUFeatures and -XX:CheckCPUFeatures=%s\\n\", CheckCPUFeatures);\n-      return false;\n-    }\n-  }\n@@ -2348,0 +2308,13 @@\n+    } else if (match_option(option, \"--enable-final-field-mutation=\", &tail)) {\n+      if (!create_numbered_module_property(\"jdk.module.enable.final.field.mutation\", tail, enable_final_field_mutation++)) {\n+        return JNI_ENOMEM;\n+      }\n+    } else if (match_option(option, \"--illegal-final-field-mutation=\", &tail)) {\n+      if (strcmp(tail, \"allow\") == 0 || strcmp(tail, \"warn\") == 0 || strcmp(tail, \"debug\") == 0 || strcmp(tail, \"deny\") == 0) {\n+        PropertyList_unique_add(&_system_properties, \"jdk.module.illegal.final.field.mutation\", tail,\n+                                AddProperty, WriteableProperty, InternalProperty);\n+      } else {\n+        jio_fprintf(defaultStream::error_stream(),\n+                    \"Value specified to --illegal-final-field-mutation not recognized: '%s'\\n\", tail);\n+        return JNI_ERR;\n+      }\n@@ -2477,1 +2450,1 @@\n-      int maxf = (int)(strtod(tail, &err) * 100);\n+      double dmaxf = strtod(tail, &err);\n@@ -2480,1 +2453,1 @@\n-                    \"Bad max heap free percentage size: %s\\n\",\n+                    \"Bad max heap free ratio: %s\\n\",\n@@ -2483,4 +2456,16 @@\n-      } else {\n-        if (FLAG_SET_CMDLINE(MaxHeapFreeRatio, maxf) != JVMFlag::SUCCESS) {\n-            return JNI_EINVAL;\n-        }\n+      }\n+      if (dmaxf < 0.0 || dmaxf > 1.0) {\n+        jio_fprintf(defaultStream::error_stream(),\n+                    \"-Xmaxf value (%s) is outside the allowed range [ 0.0 ... 1.0 ]\\n\",\n+                    option->optionString);\n+        return JNI_EINVAL;\n+      }\n+      const uintx umaxf = (uintx)(dmaxf * 100);\n+      if (MinHeapFreeRatio > umaxf) {\n+        jio_fprintf(defaultStream::error_stream(),\n+                    \"-Xmaxf value (%s) must be greater than or equal to the implicit -Xminf value (%.2f)\\n\",\n+                    tail, MinHeapFreeRatio \/ 100.0f);\n+        return JNI_EINVAL;\n+      }\n+      if (FLAG_SET_CMDLINE(MaxHeapFreeRatio, umaxf) != JVMFlag::SUCCESS) {\n+        return JNI_EINVAL;\n@@ -2491,1 +2476,1 @@\n-      int minf = (int)(strtod(tail, &err) * 100);\n+      double dminf = strtod(tail, &err);\n@@ -2494,1 +2479,1 @@\n-                    \"Bad min heap free percentage size: %s\\n\",\n+                    \"Bad min heap free ratio: %s\\n\",\n@@ -2497,4 +2482,16 @@\n-      } else {\n-        if (FLAG_SET_CMDLINE(MinHeapFreeRatio, minf) != JVMFlag::SUCCESS) {\n-          return JNI_EINVAL;\n-        }\n+      }\n+      if (dminf < 0.0 || dminf > 1.0) {\n+        jio_fprintf(defaultStream::error_stream(),\n+                    \"-Xminf value (%s) is outside the allowed range [ 0.0 ... 1.0 ]\\n\",\n+                    tail);\n+        return JNI_EINVAL;\n+      }\n+      const uintx uminf = (uintx)(dminf * 100);\n+      if (MaxHeapFreeRatio < uminf) {\n+        jio_fprintf(defaultStream::error_stream(),\n+                    \"-Xminf value (%s) must be less than or equal to the implicit -Xmaxf value (%.2f)\\n\",\n+                    tail, MaxHeapFreeRatio \/ 100.0f);\n+        return JNI_EINVAL;\n+      }\n+      if (FLAG_SET_CMDLINE(MinHeapFreeRatio, uminf) != JVMFlag::SUCCESS) {\n+        return JNI_EINVAL;\n@@ -2514,0 +2511,3 @@\n+      if (match_option(option, \"-Xmaxjitcodesize\", &tail)) {\n+        warning(\"Option -Xmaxjitcodesize was deprecated in JDK 26 and will likely be removed in a future release.\");\n+      }\n@@ -2522,1 +2522,1 @@\n-      if (FLAG_SET_CMDLINE(ReservedCodeCacheSize, (uintx)long_ReservedCodeCacheSize) != JVMFlag::SUCCESS) {\n+      if (FLAG_SET_CMDLINE(ReservedCodeCacheSize, (size_t)long_ReservedCodeCacheSize) != JVMFlag::SUCCESS) {\n@@ -2897,0 +2897,4 @@\n+void Arguments::set_ext_dirs(char *value) {\n+  _ext_dirs = os::strdup_check_oom(value);\n+}\n+\n@@ -3960,3 +3964,0 @@\n-  if (UseCompactObjectHeaders && LockingMode != LM_LIGHTWEIGHT) {\n-    FLAG_SET_DEFAULT(LockingMode, LM_LIGHTWEIGHT);\n-  }\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":169,"deletions":168,"binary":false,"changes":337,"status":"modified"},{"patch":"@@ -28,3 +28,1 @@\n-#include \"logging\/logLevel.hpp\"\n-#include \"logging\/logTag.hpp\"\n-#include \"memory\/allStatic.hpp\"\n+#include \"jni.h\"\n@@ -32,1 +30,2 @@\n-#include \"runtime\/globals.hpp\"\n+#include \"memory\/allStatic.hpp\"\n+#include \"runtime\/flags\/jvmFlag.hpp\"\n@@ -34,3 +33,1 @@\n-#include \"runtime\/os.hpp\"\n-#include \"utilities\/debug.hpp\"\n-#include \"utilities\/vmEnums.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -40,0 +37,2 @@\n+template <typename E>\n+class GrowableArray;\n@@ -428,6 +427,2 @@\n-  static void set_jvm_flags_file(const char *value) {\n-    if (_jvm_flags_file != nullptr) {\n-      os::free(_jvm_flags_file);\n-    }\n-    _jvm_flags_file = os::strdup_check_oom(value);\n-  }\n+  static void set_jvm_flags_file(const char *value);\n+\n@@ -497,1 +492,1 @@\n-  static void set_ext_dirs(char *value)     { _ext_dirs = os::strdup_check_oom(value); }\n+  static void set_ext_dirs(char *value);\n","filename":"src\/hotspot\/share\/runtime\/arguments.hpp","additions":9,"deletions":14,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+#include \"runtime\/crac.hpp\"\n@@ -39,1 +40,0 @@\n-#include \"runtime\/crac.hpp\"\n@@ -45,0 +45,1 @@\n+#include \"runtime\/os.inline.hpp\"\n@@ -52,1 +53,0 @@\n-#include \"os.inline.hpp\"\n@@ -121,1 +121,1 @@\n-    return snprintf(buf, buflen, zero_pad ? \"%0*\" PRId64 : \"%*\" PRId64, width, (int64_t) (timeMillis \/ 1000));\n+    return os::snprintf(buf, buflen, zero_pad ? \"%0*\" PRId64 : \"%*\" PRId64, width, static_cast<int64_t>(timeMillis \/ 1000));\n@@ -127,1 +127,1 @@\n-    return snprintf(buf, buflen, \"%0*zu\", width, size);\n+    return os::snprintf(buf, buflen, \"%0*zu\", width, size);\n@@ -129,1 +129,1 @@\n-    return snprintf(buf, buflen, \"%*zu\", width, size);\n+    return os::snprintf(buf, buflen, \"%*zu\", width, size);\n@@ -137,1 +137,1 @@\n-    return snprintf(buf, buflen, \"%zu%s\", size, suffix);\n+    return os::snprintf(buf, buflen, \"%zu%s\", size, suffix);\n@@ -169,0 +169,1 @@\n+\/\/ TODO: use stringStream or similar instead of a raw buffer\n@@ -215,1 +216,1 @@\n-      check_retval(snprintf(buf, buflen, \"%s\", ARCHPROPNAME));\n+      check_retval(os::snprintf(buf, buflen, \"%s\", ARCHPROPNAME));\n@@ -221,1 +222,5 @@\n-          check_retval(data.print_numbers(buf, buflen, true));\n+          \/\/ The copying is inefficient but the proper fix is to use stringStream on the caller-site\n+          stringStream ss;\n+          data.print_numbers(ss, true);\n+          check_retval(static_cast<int>(ss.size()));\n+          memcpy(buf - ss.size(), ss.base(), ss.size());\n@@ -235,1 +240,1 @@\n-        check_retval(snprintf(buf, buflen, \"%08x-%04x-4%03x-%04x-%04x%08x\",\n+        check_retval(os::snprintf(buf, buflen, \"%08x-%04x-4%03x-%04x-%04x%08x\",\n@@ -254,1 +259,1 @@\n-      check_retval(snprintf(buf, buflen, zero_pad ? \"%0*d\" : \"%*d\", width, os::current_process_id()));\n+      check_retval(os::snprintf(buf, buflen, zero_pad ? \"%0*d\" : \"%*d\", width, os::current_process_id()));\n@@ -257,1 +262,1 @@\n-      check_retval(snprintf(buf, buflen, zero_pad ? \"%0*d\" : \"%*d\", width, os::active_processor_count()));\n+      check_retval(os::snprintf(buf, buflen, zero_pad ? \"%0*d\" : \"%*d\", width, os::active_processor_count()));\n@@ -264,1 +269,1 @@\n-      check_retval(snprintf(buf, buflen, zero_pad ? \"%0*d\" : \"%*d\", width, _generation));\n+      check_retval(os::snprintf(buf, buflen, zero_pad ? \"%0*d\" : \"%*d\", width, _generation));\n@@ -812,4 +817,0 @@\n-  \/\/ Previously IgnoreCPUFeatures didn't disable the check completely; the difference\n-  \/\/ was printed out but continued even despite features not being satisfied.\n-  \/\/ Since the check itself is delegated to the C\/R Engine we will simply\n-  \/\/ skip the check here.\n","filename":"src\/hotspot\/share\/runtime\/crac.cpp","additions":17,"deletions":16,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -24,1 +24,0 @@\n-#include \"runtime\/cracRecompiler.hpp\"\n@@ -27,1 +26,0 @@\n-#include \"compiler\/compileTask.hpp\"\n@@ -29,0 +27,1 @@\n+#include \"compiler\/compileTask.hpp\"\n@@ -36,0 +35,1 @@\n+#include \"runtime\/cracRecompiler.hpp\"\n@@ -139,1 +139,1 @@\n-static volatile bool is_recording;\n+static Atomic<bool> is_recording;\n@@ -149,2 +149,2 @@\n-  assert(!is_recording && decompilations == nullptr, \"unexpected state: is_recording = %s, decompilations = %p\",\n-         BOOL_TO_STR(is_recording), decompilations);\n+  assert(!is_recording.load_relaxed() && decompilations == nullptr, \"unexpected state: is_recording = %s, decompilations = %p\",\n+         BOOL_TO_STR(is_recording.load_relaxed()), decompilations);\n@@ -152,1 +152,1 @@\n-  Atomic::release_store_fence(&is_recording, true);\n+  is_recording.release_store_fence(true);\n@@ -162,3 +162,3 @@\n-    assert(is_recording && decompilations != nullptr, \"unexpected state: is_recording = %s, decompilations = %p\",\n-           BOOL_TO_STR(is_recording), decompilations);\n-    Atomic::release_store_fence(&is_recording, false);\n+    assert(is_recording.load_relaxed() && decompilations != nullptr, \"unexpected state: is_recording = %s, decompilations = %p\",\n+           BOOL_TO_STR(is_recording.load_relaxed()), decompilations);\n+    is_recording.release_store_fence(false);\n@@ -188,1 +188,1 @@\n-  if (!Atomic::load_acquire(&is_recording)) {\n+  if (!is_recording.load_acquire()) {\n@@ -193,1 +193,1 @@\n-  if (is_recording) { \/\/ Re-check under the lock to be safe from concurrent changes\n+  if (is_recording.load_relaxed()) { \/\/ Re-check under the lock to be safe from concurrent changes\n@@ -195,1 +195,1 @@\n-           BOOL_TO_STR(is_recording), decompilations);\n+           BOOL_TO_STR(is_recording.load_relaxed()), decompilations);\n","filename":"src\/hotspot\/share\/runtime\/cracRecompiler.cpp","additions":12,"deletions":12,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"utilities\/hashTable.hpp\"\n@@ -37,1 +38,0 @@\n-#include \"utilities\/resourceHash.hpp\"\n@@ -159,2 +159,2 @@\n-using CStringSet = ResourceHashtable<const char *, bool, 256, AnyObj::C_HEAP, MemTag::mtInternal,\n-                                     CStringUtils::hash, CStringUtils::equals>;\n+using CStringSet = HashTable<const char *, bool, 256, AnyObj::C_HEAP, MemTag::mtInternal,\n+                             CStringUtils::hash, CStringUtils::equals>;\n","filename":"src\/hotspot\/share\/runtime\/crac_engine.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -29,0 +29,2 @@\n+#include \"runtime\/os.hpp\"\n+#include \"runtime\/vmOperation.hpp\"\n@@ -31,1 +33,0 @@\n-#include \"runtime\/vmOperation.hpp\"\n@@ -139,1 +140,1 @@\n-      int len = snprintf(prop, sizeof(prop), \"%s=%s\", p->key(), p->value());\n+      int len = os::snprintf(prop, sizeof(prop), \"%s=%s\", p->key(), p->value());\n@@ -212,1 +213,1 @@\n-    int shmpathlen = snprintf(_path, sizeof(_path), \"%s\/crac_%d\", os::get_temp_directory(), id);\n+    int shmpathlen = os::snprintf(_path, sizeof(_path), \"%s\/crac_%d\", os::get_temp_directory(), id);\n","filename":"src\/hotspot\/share\/runtime\/crac_structs.hpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -38,1 +38,0 @@\n-#include \"interpreter\/bytecode.hpp\"\n@@ -65,1 +64,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -71,1 +70,0 @@\n-#include \"runtime\/fieldDescriptor.hpp\"\n@@ -79,1 +77,0 @@\n-#include \"runtime\/lightweightSynchronizer.hpp\"\n@@ -90,1 +87,1 @@\n-#include \"runtime\/synchronizer.inline.hpp\"\n+#include \"runtime\/synchronizer.hpp\"\n@@ -94,1 +91,1 @@\n-#include \"runtime\/vframeArray.hpp\"\n+#include \"runtime\/vframeArray.hpp\"\n@@ -140,1 +137,1 @@\n-  Atomic::store(&nm->_deoptimization_status, status);\n+  AtomicAccess::store(&nm->_deoptimization_status, status);\n@@ -504,0 +501,3 @@\n+  if (exec_mode == Unpack_deopt) {\n+    assert(deoptee.is_deoptimized_frame(), \"frame is not marked for deoptimization\");\n+  }\n@@ -564,1 +564,2 @@\n-    guarantee(expressions != nullptr && expressions->length() > 0, \"must have exception to throw\");\n+    guarantee(expressions != nullptr && expressions->length() == 1, \"should have only exception on stack\");\n+    guarantee(exec_mode != Unpack_exception, \"rethrow_exception set with Unpack_exception\");\n@@ -593,6 +594,1 @@\n-\n-  \/\/ If the deopt call site is a MethodHandle invoke call site we have\n-  \/\/ to adjust the unpack_sp.\n-  nmethod* deoptee_nm = deoptee.cb()->as_nmethod_or_null();\n-  if (deoptee_nm != nullptr && deoptee_nm->is_method_handle_return(deoptee.pc()))\n-    unpack_sp = deoptee.unextended_sp();\n+  assert(unpack_sp == deoptee.unextended_sp(), \"must be\");\n@@ -740,0 +736,1 @@\n+    assert(array->element(0)->rethrow_exception(), \"must be\");\n@@ -847,0 +844,1 @@\n+#ifdef ASSERT\n@@ -871,0 +869,1 @@\n+#endif\n@@ -935,4 +934,3 @@\n-    bool is_top_frame = true;\n-    int callee_max_locals = 0;\n-    for (int i = 0; i < cur_array->frames(); i++) {\n-      vframeArrayElement* el = cur_array->element(i);\n+    for (int frame_idx = 0; frame_idx < cur_array->frames(); frame_idx++) {\n+      bool is_top_frame = (frame_idx == 0);\n+      vframeArrayElement* el = cur_array->element(frame_idx);\n@@ -942,0 +940,2 @@\n+      methodHandle mh(thread, iframe->interpreter_frame_method());\n+      bool reexecute = el->should_reexecute();\n@@ -943,8 +943,29 @@\n-      \/\/ Get the oop map for this bci\n-      InterpreterOopMap mask;\n-      bool try_next_mask = false;\n-      int next_mask_expression_stack_size = -1;\n-      methodHandle mh(thread, iframe->interpreter_frame_method());\n-      OopMapCache::compute_one_oop_map(mh, iframe->interpreter_frame_bci(), &mask);\n-      BytecodeStream str(mh, iframe->interpreter_frame_bci());\n-      \/\/ Get to the next bytecode if possible\n+      BytecodeStream str(mh, iframe->interpreter_frame_bci());\n+      assert(str.bci() < max_bci, \"bci in interpreter frame out of bounds\");\n+      Bytecodes::Code cur_code = str.next();\n+\n+      if (!reexecute && !Bytecodes::is_invoke(cur_code)) {\n+        \/\/ We can only compute OopMaps for the before state, so we need to roll forward\n+        \/\/ to the next bytecode.\n+        assert(is_top_frame, \"must be\");\n+        assert(falls_through(cur_code), \"must be\");\n+        assert(cur_code != Bytecodes::_illegal, \"illegal bytecode\");\n+        assert(str.bci() < max_bci, \"bci in interpreter frame out of bounds\");\n+\n+        \/\/ Need to subtract off the size of the result type of\n+        \/\/ the bytecode because this is not described in the\n+        \/\/ debug info but returned to the interpreter in the TOS\n+        \/\/ caching register\n+        BasicType bytecode_result_type = Bytecodes::result_type(cur_code);\n+        if (bytecode_result_type != T_ILLEGAL) {\n+          top_frame_expression_stack_adjustment = type2size[bytecode_result_type];\n+        }\n+        assert(top_frame_expression_stack_adjustment >= 0, \"stack adjustment must be positive\");\n+\n+        cur_code = str.next();\n+        \/\/ Reflect the fact that we have rolled forward and now need\n+        \/\/ top_frame_expression_stack_adjustment\n+        reexecute = true;\n+      }\n+\n+      assert(cur_code != Bytecodes::_illegal, \"illegal bytecode\");\n@@ -955,0 +976,4 @@\n+\n+      \/\/ Get the oop map for this bci\n+      InterpreterOopMap mask;\n+      OopMapCache::compute_one_oop_map(mh, str.bci(), &mask);\n@@ -958,3 +983,1 @@\n-      Bytecodes::Code cur_code = str.next();\n-      Bytecodes::Code next_code = Bytecodes::_shouldnotreachhere;\n-        Bytecode_invoke invoke(mh, iframe->interpreter_frame_bci());\n+        Bytecode_invoke invoke(mh, str.bci());\n@@ -963,1 +986,1 @@\n-        if (i != 0 && invoke.has_member_arg()) {\n+        if (!is_top_frame && invoke.has_member_arg()) {\n@@ -967,30 +990,0 @@\n-      if (str.bci() < max_bci) {\n-        next_code = str.next();\n-        if (next_code >= 0) {\n-          \/\/ The interpreter oop map generator reports results before\n-          \/\/ the current bytecode has executed except in the case of\n-          \/\/ calls. It seems to be hard to tell whether the compiler\n-          \/\/ has emitted debug information matching the \"state before\"\n-          \/\/ a given bytecode or the state after, so we try both\n-          if (!Bytecodes::is_invoke(cur_code) && falls_through(cur_code)) {\n-            \/\/ Get expression stack size for the next bytecode\n-            InterpreterOopMap next_mask;\n-            OopMapCache::compute_one_oop_map(mh, str.bci(), &next_mask);\n-            next_mask_expression_stack_size = next_mask.expression_stack_size();\n-            if (Bytecodes::is_invoke(next_code)) {\n-              Bytecode_invoke invoke(mh, str.bci());\n-              next_mask_expression_stack_size += invoke.size_of_parameters();\n-            }\n-            \/\/ Need to subtract off the size of the result type of\n-            \/\/ the bytecode because this is not described in the\n-            \/\/ debug info but returned to the interpreter in the TOS\n-            \/\/ caching register\n-            BasicType bytecode_result_type = Bytecodes::result_type(cur_code);\n-            if (bytecode_result_type != T_ILLEGAL) {\n-              top_frame_expression_stack_adjustment = type2size[bytecode_result_type];\n-            }\n-            assert(top_frame_expression_stack_adjustment >= 0, \"stack adjustment must be positive\");\n-            try_next_mask = true;\n-          }\n-        }\n-      }\n@@ -999,38 +992,5 @@\n-      \/\/ This assertion may be dependent on the platform we're running on and may need modification (tested on x86 and sparc)\n-      if (!(\n-            \/* SPARC *\/\n-            (iframe->interpreter_frame_expression_stack_size() == mask.expression_stack_size() + callee_size_of_parameters) ||\n-            \/* x86 *\/\n-            (iframe->interpreter_frame_expression_stack_size() == mask.expression_stack_size() + callee_max_locals) ||\n-            (try_next_mask &&\n-             (iframe->interpreter_frame_expression_stack_size() == (next_mask_expression_stack_size -\n-                                                                    top_frame_expression_stack_adjustment))) ||\n-            (is_top_frame && (exec_mode == Unpack_exception) && iframe->interpreter_frame_expression_stack_size() == 0) ||\n-            (is_top_frame && (exec_mode == Unpack_uncommon_trap || exec_mode == Unpack_reexecute || el->should_reexecute()) &&\n-             (iframe->interpreter_frame_expression_stack_size() == mask.expression_stack_size() + cur_invoke_parameter_size))\n-            )) {\n-        {\n-          \/\/ Print out some information that will help us debug the problem\n-          tty->print_cr(\"Wrong number of expression stack elements during deoptimization\");\n-          tty->print_cr(\"  Error occurred while verifying frame %d (0..%d, 0 is topmost)\", i, cur_array->frames() - 1);\n-          tty->print_cr(\"  Current code %s\", Bytecodes::name(cur_code));\n-          if (try_next_mask) {\n-            tty->print_cr(\"  Next code %s\", Bytecodes::name(next_code));\n-          }\n-          tty->print_cr(\"  Fabricated interpreter frame had %d expression stack elements\",\n-                        iframe->interpreter_frame_expression_stack_size());\n-          tty->print_cr(\"  Interpreter oop map had %d expression stack elements\", mask.expression_stack_size());\n-          tty->print_cr(\"  try_next_mask = %d\", try_next_mask);\n-          tty->print_cr(\"  next_mask_expression_stack_size = %d\", next_mask_expression_stack_size);\n-          tty->print_cr(\"  callee_size_of_parameters = %d\", callee_size_of_parameters);\n-          tty->print_cr(\"  callee_max_locals = %d\", callee_max_locals);\n-          tty->print_cr(\"  top_frame_expression_stack_adjustment = %d\", top_frame_expression_stack_adjustment);\n-          tty->print_cr(\"  exec_mode = %d\", exec_mode);\n-          tty->print_cr(\"  cur_invoke_parameter_size = %d\", cur_invoke_parameter_size);\n-          tty->print_cr(\"  Thread = \" INTPTR_FORMAT \", thread ID = %d\", p2i(thread), thread->osthread()->thread_id());\n-          tty->print_cr(\"  Interpreted frames:\");\n-          for (int k = 0; k < cur_array->frames(); k++) {\n-            vframeArrayElement* el = cur_array->element(k);\n-            tty->print_cr(\"    %s (bci %d)\", el->method()->name_and_sig_as_C_string(), el->bci());\n-          }\n-          cur_array->print_on_2(tty);\n+      auto match = [&]() {\n+        int iframe_expr_ssize = iframe->interpreter_frame_expression_stack_size();\n+#if INCLUDE_JVMCI\n+        if (is_top_frame && el->rethrow_exception()) {\n+          return iframe_expr_ssize == 1;\n@@ -1038,0 +998,39 @@\n+#endif\n+        \/\/ This should only be needed for C1\n+        if (is_top_frame && exec_mode == Unpack_exception && iframe_expr_ssize == 0) {\n+          return true;\n+        }\n+        if (reexecute) {\n+          int expr_ssize_before = iframe_expr_ssize + top_frame_expression_stack_adjustment;\n+          int oopmap_expr_invoke_ssize = mask.expression_stack_size() + cur_invoke_parameter_size;\n+          return expr_ssize_before == oopmap_expr_invoke_ssize;\n+        } else {\n+          int oopmap_expr_callee_ssize = mask.expression_stack_size() + callee_size_of_parameters;\n+          return iframe_expr_ssize == oopmap_expr_callee_ssize;\n+        }\n+      };\n+      if (!match()) {\n+        \/\/ Print out some information that will help us debug the problem\n+        tty->print_cr(\"Wrong number of expression stack elements during deoptimization\");\n+        tty->print_cr(\"  Error occurred while verifying frame %d (0..%d, 0 is topmost)\", frame_idx, cur_array->frames() - 1);\n+        tty->print_cr(\"  Current code %s\", Bytecodes::name(cur_code));\n+        tty->print_cr(\"  Fabricated interpreter frame had %d expression stack elements\",\n+                      iframe->interpreter_frame_expression_stack_size());\n+        tty->print_cr(\"  Interpreter oop map had %d expression stack elements\", mask.expression_stack_size());\n+        tty->print_cr(\"  callee_size_of_parameters = %d\", callee_size_of_parameters);\n+        tty->print_cr(\"  top_frame_expression_stack_adjustment = %d\", top_frame_expression_stack_adjustment);\n+        tty->print_cr(\"  exec_mode = %d\", exec_mode);\n+        tty->print_cr(\"  original should_reexecute = %s\", el->should_reexecute() ? \"true\" : \"false\");\n+        tty->print_cr(\"  reexecute = %s%s\", reexecute ? \"true\" : \"false\",\n+                      (reexecute != el->should_reexecute()) ? \" (changed)\" : \"\");\n+#if INCLUDE_JVMCI\n+        tty->print_cr(\"  rethrow_exception = %s\", el->rethrow_exception() ? \"true\" : \"false\");\n+#endif\n+        tty->print_cr(\"  cur_invoke_parameter_size = %d\", cur_invoke_parameter_size);\n+        tty->print_cr(\"  Thread = \" INTPTR_FORMAT \", thread ID = %d\", p2i(thread), thread->osthread()->thread_id());\n+        tty->print_cr(\"  Interpreted frames:\");\n+        for (int k = 0; k < cur_array->frames(); k++) {\n+          vframeArrayElement* el = cur_array->element(k);\n+          tty->print_cr(\"    %s (bci %d)\", el->method()->name_and_sig_as_C_string(), el->bci());\n+        }\n+        cur_array->print_on_2(tty);\n@@ -1043,2 +1042,0 @@\n-      callee_max_locals = mh->max_locals();\n-      is_top_frame = false;\n@@ -1052,1 +1049,1 @@\n-class DeoptimizeMarkedClosure : public HandshakeClosure {\n+class DeoptimizeMarkedHandshakeClosure : public HandshakeClosure {\n@@ -1054,1 +1051,1 @@\n-  DeoptimizeMarkedClosure() : HandshakeClosure(\"Deoptimize\") {}\n+  DeoptimizeMarkedHandshakeClosure() : HandshakeClosure(\"Deoptimize\") {}\n@@ -1067,1 +1064,1 @@\n-  DeoptimizeMarkedClosure deopt;\n+  DeoptimizeMarkedHandshakeClosure deopt;\n@@ -1122,1 +1119,1 @@\n-      if (!Atomic::replace_if_null(&_singleton, s)) {\n+      if (!AtomicAccess::replace_if_null(&_singleton, s)) {\n@@ -1185,1 +1182,1 @@\n-      if (!Atomic::replace_if_null(&_singleton, s)) {\n+      if (!AtomicAccess::replace_if_null(&_singleton, s)) {\n@@ -1277,1 +1274,1 @@\n-      obj = ak->allocate(len, THREAD);\n+      obj = ak->allocate_instance(len, THREAD);\n@@ -1281,1 +1278,1 @@\n-      obj = ak->allocate(sv->field_size(), THREAD);\n+      obj = ak->allocate_instance(sv->field_size(), THREAD);\n@@ -1385,0 +1382,3 @@\n+#if INCLUDE_JVMCI\n+      \/\/ big_value allows encoding double\/long value as e.g. [int = 0, long], and storing\n+      \/\/ the value in two array elements.\n@@ -1412,0 +1412,3 @@\n+#else \/\/ not INCLUDE_JVMCI\n+      obj->int_at_put(index, value->get_jint());\n+#endif \/\/ INCLUDE_JVMCI\n@@ -1477,1 +1480,1 @@\n-  InstanceKlass* super = klass->superklass();\n+  InstanceKlass* super = klass->super();\n@@ -1648,7 +1651,0 @@\n-          if (LockingMode == LM_LEGACY && mark.has_locker() && fr.sp() > (intptr_t*)mark.locker()) {\n-            \/\/ With exec_mode == Unpack_none obj may be thread local and locked in\n-            \/\/ a callee frame. Make the lock in the callee a recursive lock and restore the displaced header.\n-            markWord dmw = mark.displaced_mark_helper();\n-            mark.locker()->set_displaced_header(markWord::encode((BasicLock*) nullptr));\n-            obj->set_mark(dmw);\n-          }\n@@ -1660,3 +1656,1 @@\n-              if (LockingMode == LM_LEGACY) {\n-                mon_info->lock()->set_displaced_header(markWord::unused_mark());\n-              } else if (UseObjectMonitorTable) {\n+              if (UseObjectMonitorTable) {\n@@ -1667,2 +1661,2 @@\n-                assert(LockingMode == LM_MONITOR || !UseObjectMonitorTable, \"must be\");\n-                mon_info->lock()->set_bad_metadata_deopt();\n+                assert(!UseObjectMonitorTable, \"must be\");\n+                mon_info->lock()->set_bad_monitor_deopt();\n@@ -1677,22 +1671,8 @@\n-        if (LockingMode == LM_LIGHTWEIGHT) {\n-          \/\/ We have lost information about the correct state of the lock stack.\n-          \/\/ Entering may create an invalid lock stack. Inflate the lock if it\n-          \/\/ was fast_locked to restore the valid lock stack.\n-          if (UseObjectMonitorTable) {\n-            \/\/ UseObjectMonitorTable expects the BasicLock cache to be either a\n-            \/\/ valid ObjectMonitor* or nullptr. Right now it is garbage, set it\n-            \/\/ to nullptr.\n-            lock->clear_object_monitor_cache();\n-          }\n-          ObjectSynchronizer::enter_for(obj, lock, deoptee_thread);\n-          if (deoptee_thread->lock_stack().contains(obj())) {\n-            LightweightSynchronizer::inflate_fast_locked_object(obj(), ObjectSynchronizer::InflateCause::inflate_cause_vm_internal,\n-                                                                deoptee_thread, thread);\n-          }\n-          assert(mon_info->owner()->is_locked(), \"object must be locked now\");\n-          assert(obj->mark().has_monitor(), \"must be\");\n-          assert(!deoptee_thread->lock_stack().contains(obj()), \"must be\");\n-          assert(ObjectSynchronizer::read_monitor(thread, obj(), obj->mark())->has_owner(deoptee_thread), \"must be\");\n-        } else {\n-          ObjectSynchronizer::enter_for(obj, lock, deoptee_thread);\n-          assert(mon_info->owner()->is_locked(), \"object must be locked now\");\n+        \/\/ We have lost information about the correct state of the lock stack.\n+        \/\/ Entering may create an invalid lock stack. Inflate the lock if it\n+        \/\/ was fast_locked to restore the valid lock stack.\n+        if (UseObjectMonitorTable) {\n+          \/\/ UseObjectMonitorTable expects the BasicLock cache to be either a\n+          \/\/ valid ObjectMonitor* or nullptr. Right now it is garbage, set it\n+          \/\/ to nullptr.\n+          lock->clear_object_monitor_cache();\n@@ -1700,0 +1680,9 @@\n+        ObjectSynchronizer::enter_for(obj, lock, deoptee_thread);\n+        if (deoptee_thread->lock_stack().contains(obj())) {\n+            ObjectSynchronizer::inflate_fast_locked_object(obj(), ObjectSynchronizer::InflateCause::inflate_cause_vm_internal,\n+                                                           deoptee_thread, thread);\n+        }\n+        assert(mon_info->owner()->is_locked(), \"object must be locked now\");\n+        assert(obj->mark().has_monitor(), \"must be\");\n+        assert(!deoptee_thread->lock_stack().contains(obj()), \"must be\");\n+        assert(ObjectSynchronizer::read_monitor(thread, obj(), obj->mark())->has_owner(deoptee_thread), \"must be\");\n@@ -1826,2 +1815,1 @@\n-#if INCLUDE_JVMCI\n-address Deoptimization::deoptimize_for_missing_exception_handler(nmethod* nm) {\n+address Deoptimization::deoptimize_for_missing_exception_handler(nmethod* nm, bool make_not_entrant) {\n@@ -1829,1 +1817,3 @@\n-  nm->make_not_entrant(\"missing exception handler\", true \/* OK to recompile *\/);\n+  if (make_not_entrant) {\n+    nm->make_not_entrant(nmethod::InvalidationReason::MISSING_EXCEPTION_HANDLER, true \/* OK to recompile *\/);\n+  }\n@@ -1843,0 +1833,9 @@\n+\n+  Deoptimization::deoptimize(thread, caller_frame, Deoptimization::Reason_not_compiled_exception_handler);\n+\n+  if (!nm->is_compiled_by_jvmci()) {\n+    return SharedRuntime::deopt_blob()->unpack_with_exception_in_tls();\n+  }\n+\n+#if INCLUDE_JVMCI\n+  \/\/ JVMCI support\n@@ -1858,1 +1857,0 @@\n-  Deoptimization::deoptimize(thread, caller_frame, Deoptimization::Reason_not_compiled_exception_handler);\n@@ -1864,0 +1862,1 @@\n+#endif\n@@ -1867,1 +1866,0 @@\n-#endif\n@@ -1988,1 +1986,1 @@\n-  if (1 == critical_section || Atomic::cmpxchg(&critical_section, 0, 1) == 1) {\n+  if (1 == critical_section || AtomicAccess::cmpxchg(&critical_section, 0, 1) == 1) {\n@@ -2366,0 +2364,8 @@\n+#if INCLUDE_JVMCI\n+    \/\/ Deoptimization count is used by the CompileBroker to reason about compilations\n+    \/\/ it requests so do not pollute the count for deoptimizations in non-default (i.e.\n+    \/\/ non-CompilerBroker) compilations.\n+    if (nm->jvmci_skip_profile_deopt()) {\n+      update_trap_state = false;\n+    }\n+#endif\n@@ -2458,1 +2464,1 @@\n-      if (!nm->make_not_entrant(\"uncommon trap\", true \/* OK to recompile *\/)) {\n+      if (!nm->make_not_entrant(nmethod::InvalidationReason::UNCOMMON_TRAP, true \/* OK to recompile *\/)) {\n@@ -2476,1 +2482,0 @@\n-\n@@ -2763,0 +2768,2 @@\n+  \"not_compiled_exception_handler\",\n+  \"short_running_loop\" JVMCI_ONLY(\"_or_aliasing\"),\n@@ -2764,2 +2771,0 @@\n-  \"aliasing\",\n-  \"not_compiled_exception_handler\",\n@@ -2920,2 +2925,0 @@\n-            if (bc_case == BC_CASE_LIMIT && (int)bc == 0)\n-              bc = Bytecodes::_illegal;\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":157,"deletions":154,"binary":false,"changes":311,"status":"modified"},{"patch":"@@ -165,1 +165,1 @@\n-    \/\/     double InitialRAMPercentage                     = 1.562500                                  {product} {default}\n+    \/\/     double InitialRAMPercentage                     = 0.000000                                  {product} {default}\n@@ -718,1 +718,1 @@\n-      if (!visited && flagTable[i].is_unlocked() && !skip) {\n+      if (!visited && !skip) {\n","filename":"src\/hotspot\/share\/runtime\/flags\/jvmFlag.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,1 @@\n-#include \"utilities\/globalDefinitions.hpp\"\n+#include \"cppstdlib\/type_traits.hpp\"\n@@ -30,0 +30,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -32,1 +33,0 @@\n-#include <type_traits>\n","filename":"src\/hotspot\/share\/runtime\/flags\/jvmFlag.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2026, Oracle and\/or its affiliates. All rights reserved.\n@@ -130,4 +130,0 @@\n-  product(bool, UseCompressedClassPointers, true,                           \\\n-          \"(Deprecated) Use 32-bit class pointers in 64-bit VM. \"           \\\n-          \"lp64_product means flag is always constant in 32 bit VM\")        \\\n-                                                                            \\\n@@ -152,1 +148,0 @@\n-const bool UseCompressedClassPointers = false;\n@@ -250,1 +245,2 @@\n-          \"page size for the environment as the maximum)\")                  \\\n+          \"page size for the environment as the maximum) \"                  \\\n+          \"(must be a power of 2)\")                                         \\\n@@ -252,0 +248,1 @@\n+          constraint(LargePageSizeInBytesConstraintFunc, AtParse)           \\\n@@ -301,0 +298,3 @@\n+  develop(bool, VerifyInlineCaches, true,                                   \\\n+          \"Verify Inline Caches\")                                           \\\n+                                                                            \\\n@@ -493,0 +493,3 @@\n+  develop(bool, ZapCHeap, trueInDebug,                                      \\\n+          \"Zap allocated\/freed C heap space\")                               \\\n+                                                                            \\\n@@ -507,1 +510,1 @@\n-          range(0, 17)                                                      \\\n+          range(0, 18)                                                      \\\n@@ -623,3 +626,0 @@\n-  product(bool, VerifyAdapterCalls, trueInDebug, DIAGNOSTIC,                \\\n-          \"Verify that i2c\/c2i adapters are called properly\")               \\\n-                                                                            \\\n@@ -817,0 +817,1 @@\n+          range(0, 1024)                                                    \\\n@@ -956,4 +957,0 @@\n-  develop(bool, GenerateSynchronizationCode, true,                          \\\n-          \"generate locking\/unlocking code for synchronized methods and \"   \\\n-          \"monitors\")                                                       \\\n-                                                                            \\\n@@ -1060,4 +1057,0 @@\n-  develop(bool, VerifyHeavyMonitors, false,                                 \\\n-          \"Checks that no stack locking happens when using \"                \\\n-          \"-XX:LockingMode=0 (LM_MONITOR)\")                                 \\\n-                                                                            \\\n@@ -1102,0 +1095,3 @@\n+  \/* This value is later shifted left by up to LogBytesPerLong bits       *\/\\\n+  \/* (to convert from element count to size in bytes), so we must ensure  *\/\\\n+  \/* it does not overflow during the shift.                               *\/\\\n@@ -1105,0 +1101,1 @@\n+          range(0, (1 << (BitsPerInt - LogBytesPerLong - 1)) - 1)           \\\n@@ -1381,0 +1378,1 @@\n+          range(0, 100)                                                     \\\n@@ -1406,0 +1404,3 @@\n+  product(bool, UseCompressedClassPointers, true,                           \\\n+          \"(Deprecated) Use 32-bit class pointers.\")                        \\\n+                                                                            \\\n@@ -1509,1 +1510,1 @@\n-  product_pd(uintx, CodeCacheSegmentSize, EXPERIMENTAL,                     \\\n+  product_pd(size_t, CodeCacheSegmentSize, EXPERIMENTAL,                    \\\n@@ -1524,1 +1525,1 @@\n-  product_pd(uintx, InitialCodeCacheSize,                                   \\\n+  product_pd(size_t, InitialCodeCacheSize,                                  \\\n@@ -1528,1 +1529,1 @@\n-  develop_pd(uintx, CodeCacheMinimumUseSpace,                               \\\n+  develop_pd(size_t, CodeCacheMinimumUseSpace,                              \\\n@@ -1530,1 +1531,1 @@\n-          range(0, max_uintx)                                               \\\n+          range(0, SIZE_MAX)                                                \\\n@@ -1535,1 +1536,1 @@\n-  product_pd(uintx, ReservedCodeCacheSize,                                  \\\n+  product_pd(size_t, ReservedCodeCacheSize,                                 \\\n@@ -1539,1 +1540,1 @@\n-  product_pd(uintx, NonProfiledCodeHeapSize,                                \\\n+  product_pd(size_t, NonProfiledCodeHeapSize,                               \\\n@@ -1541,1 +1542,1 @@\n-          range(0, max_uintx)                                               \\\n+          range(0, SIZE_MAX)                                                \\\n@@ -1543,1 +1544,1 @@\n-  product_pd(uintx, ProfiledCodeHeapSize,                                   \\\n+  product_pd(size_t, ProfiledCodeHeapSize,                                  \\\n@@ -1545,1 +1546,1 @@\n-          range(0, max_uintx)                                               \\\n+          range(0, SIZE_MAX)                                                \\\n@@ -1547,1 +1548,1 @@\n-  product_pd(uintx, NonNMethodCodeHeapSize,                                 \\\n+  product_pd(size_t, NonNMethodCodeHeapSize,                                \\\n@@ -1551,1 +1552,1 @@\n-  product_pd(uintx, CodeCacheExpansionSize,                                 \\\n+  product_pd(size_t, CodeCacheExpansionSize,                                \\\n@@ -1553,1 +1554,1 @@\n-          range(32*K, max_uintx)                                            \\\n+          range(32*K, SIZE_MAX)                                             \\\n@@ -1555,1 +1556,1 @@\n-  product_pd(uintx, CodeCacheMinBlockLength, DIAGNOSTIC,                    \\\n+  product_pd(size_t, CodeCacheMinBlockLength, DIAGNOSTIC,                   \\\n@@ -1571,3 +1572,1 @@\n-          \"Start aggressive sweeping if X[%] of the code cache is free.\"    \\\n-          \"Segmented code cache: X[%] of the non-profiled heap.\"            \\\n-          \"Non-segmented code cache: X[%] of the total code cache\")         \\\n+          \"Start aggressive sweeping if less than X[%] of the total code cache is free.\")\\\n@@ -1576,0 +1575,3 @@\n+  product(bool, NMethodRelocation, false, EXPERIMENTAL,                     \\\n+          \"Enables use of experimental function nmethod::relocate()\")       \\\n+                                                                            \\\n@@ -1679,1 +1681,1 @@\n-  develop(intx, MinOopMapAllocation,     8,                                 \\\n+  develop(int, MinOopMapAllocation, 8,                                      \\\n@@ -1681,0 +1683,1 @@\n+          range(0, max_jint)                                                \\\n@@ -2044,5 +2047,1 @@\n-  product(bool, IgnoreCPUFeatures, false, RESTORE_SETTABLE | EXPERIMENTAL,  \\\n-          \"Do not refuse to run after -XX:CRaCRestoreFrom finds out some \"  \\\n-          \"CPU features are missing\")                                       \\\n-                                                                            \\\n-  product(ccstr, CheckCPUFeatures, nullptr, RESTORE_SETTABLE,                \\\n+  product(ccstr, CheckCPUFeatures, nullptr, RESTORE_SETTABLE,               \\\n@@ -2055,15 +2054,8 @@\n-  product(int, LockingMode, LM_LIGHTWEIGHT,                                 \\\n-          \"(Deprecated) Select locking mode: \"                              \\\n-          \"0: (Deprecated) monitors only (LM_MONITOR), \"                    \\\n-          \"1: (Deprecated) monitors & legacy stack-locking (LM_LEGACY), \"   \\\n-          \"2: monitors & new lightweight locking (LM_LIGHTWEIGHT, default)\") \\\n-          range(0, 2)                                                       \\\n-                                                                            \\\n-          \"With Lightweight Locking mode, use a table to record inflated \"  \\\n-          \"monitors rather than the first word of the object.\")             \\\n-                                                                            \\\n-  product(int, LightweightFastLockingSpins, 13, DIAGNOSTIC,                 \\\n-          \"Specifies the number of times lightweight fast locking will \"    \\\n-          \"attempt to CAS the markWord before inflating. Between each \"     \\\n-          \"CAS it will spin for exponentially more time, resulting in \"     \\\n-          \"a total number of spins on the order of O(2^value)\")             \\\n+          \"Use a table to record inflated monitors rather than the first \"  \\\n+          \"word of the object.\")                                            \\\n+                                                                            \\\n+  product(int, FastLockingSpins, 13, DIAGNOSTIC,                            \\\n+          \"Specifies the number of times fast locking will attempt to \"     \\\n+          \"CAS the markWord before inflating. Between each CAS it will \"    \\\n+          \"spin for exponentially more time, resulting in a total number \"  \\\n+          \"of spins on the order of O(2^value)\")                            \\\n@@ -2107,0 +2099,5 @@\n+                                                                            \\\n+  develop(uint, BinarySearchThreshold, 16,                                  \\\n+          \"Minimal number of elements in a sorted collection to prefer\"     \\\n+          \"binary search over simple linear search.\" )                      \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":53,"deletions":56,"binary":false,"changes":109,"status":"modified"},{"patch":"@@ -35,1 +35,1 @@\n-#include \"compiler\/compileTask.hpp\"\n+#include \"compiler\/compileTask.hpp\"\n@@ -59,1 +59,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -91,2 +91,1 @@\n-#include \"runtime\/vframeArray.hpp\"\n-#include \"runtime\/vmThread.hpp\"\n+#include \"runtime\/vframeArray.hpp\"\n@@ -95,0 +94,1 @@\n+#include \"runtime\/vmThread.hpp\"\n@@ -124,1 +124,1 @@\n-    {                                                                      \\\n+    if (!javathread->is_aot_thread()) {                                    \\\n@@ -447,0 +447,1 @@\n+  _throwing_unsafe_access_error(false),\n@@ -450,1 +451,0 @@\n-  _is_in_VTMS_transition(false),\n@@ -453,1 +453,1 @@\n-  _VTMS_transition_mark(false),\n+  _jvmti_events_disabled(0),\n@@ -456,3 +456,0 @@\n-#ifdef ASSERT\n-  _is_VTMS_transition_disabler(false),\n-#endif\n@@ -479,1 +476,0 @@\n-  _is_method_handle_return(0),\n@@ -492,2 +488,0 @@\n-  _held_monitor_count(0),\n-  _jni_monitor_count(0),\n@@ -499,0 +493,4 @@\n+  _at_preemptable_init(false),\n+  DEBUG_ONLY(_preempt_init_klass(nullptr) COMMA)\n+  DEBUG_ONLY(_interp_at_preemptable_vmcall_cnt(0) COMMA)\n+  DEBUG_ONLY(_interp_redoing_vm_call(false) COMMA)\n@@ -501,0 +499,5 @@\n+  _suspend_resume_manager(this, &_handshake._lock),\n+\n+  _is_in_vthread_transition(false),\n+  DEBUG_ONLY(_is_vthread_transition_disabler(false) COMMA)\n+  DEBUG_ONLY(_is_disabler_at_start(false) COMMA)\n@@ -540,1 +543,0 @@\n-  assert(deferred_card_mark().is_empty(), \"Default MemRegion ctor\");\n@@ -740,0 +742,2 @@\n+  JFR_ONLY(Jfr::on_thread_start(this);)\n+\n@@ -762,1 +766,1 @@\n-  assert(_threadObj.peek() != nullptr, \"just checking\");\n+  assert(_threadObj.peek() != nullptr || is_aot_thread(), \"just checking\");\n@@ -928,21 +932,0 @@\n-    \/\/ Check for monitor counts being out of sync.\n-    assert(held_monitor_count() == jni_monitor_count(),\n-           \"held monitor count should be equal to jni: %zd != %zd\",\n-           held_monitor_count(), jni_monitor_count());\n-    \/\/ All in-use monitors, including JNI-locked ones, should have been released above.\n-    assert(held_monitor_count() == 0, \"Failed to unlock %zd object monitors\",\n-           held_monitor_count());\n-  } else {\n-    \/\/ Check for monitor counts being out of sync.\n-    assert(held_monitor_count() == jni_monitor_count(),\n-           \"held monitor count should be equal to jni: %zd != %zd\",\n-           held_monitor_count(), jni_monitor_count());\n-    \/\/ It is possible that a terminating thread failed to unlock monitors it locked\n-    \/\/ via JNI so we don't assert the count is zero.\n-  }\n-\n-  if (CheckJNICalls && jni_monitor_count() > 0) {\n-    \/\/ We would like a fatal here, but due to we never checked this before there\n-    \/\/ is a lot of tests which breaks, even with an error log.\n-    log_debug(jni)(\"JavaThread %s (tid: %zu) with Objects still locked by JNI MonitorEnter.\",\n-                   exit_type == JavaThread::normal_exit ? \"exiting\" : \"detaching\", os::current_thread_id());\n@@ -1063,6 +1046,1 @@\n-bool JavaThread::is_lock_owned(address adr) const {\n-  assert(LockingMode != LM_LIGHTWEIGHT, \"should not be called with new lightweight locking\");\n-  return is_in_full_stack(adr);\n-}\n-\n-  return Atomic::load(&_exception_oop);\n+  return AtomicAccess::load(&_exception_oop);\n@@ -1073,1 +1051,1 @@\n-  Atomic::store(&_exception_oop, o);\n+  AtomicAccess::store(&_exception_oop, o);\n@@ -1077,1 +1055,5 @@\n-  if (is_obj_deopt_suspend()) {\n+  \/\/ We mustn't block for object deopt if the thread is\n+  \/\/ currently executing in a JNI critical region, as that\n+  \/\/ can cause deadlock because allocation may be locked out\n+  \/\/ and the object deopt suspender may try to allocate.\n+  if (is_obj_deopt_suspend() && !in_critical()) {\n@@ -1126,1 +1108,1 @@\n-void JavaThread::install_async_exception(AsyncExceptionHandshake* aeh) {\n+void JavaThread::install_async_exception(AsyncExceptionHandshakeClosure* aehc) {\n@@ -1130,1 +1112,1 @@\n-    delete aeh;\n+    delete aehc;\n@@ -1134,2 +1116,2 @@\n-  oop exception = aeh->exception();\n-  Handshake::execute(aeh, this);  \/\/ Install asynchronous handshake\n+  oop exception = aehc->exception();\n+  Handshake::execute(aehc, this);  \/\/ Install asynchronous handshake\n@@ -1140,1 +1122,1 @@\n-                         InstanceKlass::cast(exception->klass())->external_name());\n+                         exception->klass()->external_name());\n@@ -1148,1 +1130,0 @@\n-    java_lang_Thread::set_interrupted(threadObj(), true);\n@@ -1153,2 +1134,2 @@\n-class InstallAsyncExceptionHandshake : public HandshakeClosure {\n-  AsyncExceptionHandshake* _aeh;\n+class InstallAsyncExceptionHandshakeClosure : public HandshakeClosure {\n+  AsyncExceptionHandshakeClosure* _aehc;\n@@ -1156,5 +1137,5 @@\n-  InstallAsyncExceptionHandshake(AsyncExceptionHandshake* aeh) :\n-    HandshakeClosure(\"InstallAsyncException\"), _aeh(aeh) {}\n-  ~InstallAsyncExceptionHandshake() {\n-    \/\/ If InstallAsyncExceptionHandshake was never executed we need to clean up _aeh.\n-    delete _aeh;\n+  InstallAsyncExceptionHandshakeClosure(AsyncExceptionHandshakeClosure* aehc) :\n+    HandshakeClosure(\"InstallAsyncException\"), _aehc(aehc) {}\n+  ~InstallAsyncExceptionHandshakeClosure() {\n+    \/\/ If InstallAsyncExceptionHandshakeClosure was never executed we need to clean up _aehc.\n+    delete _aehc;\n@@ -1164,2 +1145,2 @@\n-    target->install_async_exception(_aeh);\n-    _aeh = nullptr;\n+    target->install_async_exception(_aehc);\n+    _aehc = nullptr;\n@@ -1171,1 +1152,1 @@\n-  InstallAsyncExceptionHandshake iaeh(new AsyncExceptionHandshake(e));\n+  InstallAsyncExceptionHandshakeClosure iaeh(new AsyncExceptionHandshakeClosure(e));\n@@ -1175,4 +1156,10 @@\n-#if INCLUDE_JVMTI\n-void JavaThread::set_is_in_VTMS_transition(bool val) {\n-  assert(is_in_VTMS_transition() != val, \"already %s transition\", val ? \"inside\" : \"outside\");\n-  _is_in_VTMS_transition = val;\n+bool JavaThread::is_in_vthread_transition() const {\n+  DEBUG_ONLY(Thread* current = Thread::current();)\n+  assert(is_handshake_safe_for(current) || SafepointSynchronize::is_at_safepoint()\n+         || JavaThread::cast(current)->is_disabler_at_start(), \"not safe\");\n+  return AtomicAccess::load(&_is_in_vthread_transition);\n+}\n+\n+void JavaThread::set_is_in_vthread_transition(bool val) {\n+  assert(is_in_vthread_transition() != val, \"already %s transition\", val ? \"inside\" : \"outside\");\n+  AtomicAccess::store(&_is_in_vthread_transition, val);\n@@ -1182,2 +1169,6 @@\n-void JavaThread::set_is_VTMS_transition_disabler(bool val) {\n-  _is_VTMS_transition_disabler = val;\n+void JavaThread::set_is_vthread_transition_disabler(bool val) {\n+  _is_vthread_transition_disabler = val;\n+}\n+\n+void JavaThread::set_is_disabler_at_start(bool val) {\n+  _is_disabler_at_start = val;\n@@ -1185,1 +1176,0 @@\n-#endif\n@@ -1195,5 +1185,2 @@\n-#if INCLUDE_JVMTI\n-  \/\/ Suspending a JavaThread in VTMS transition or disabling VTMS transitions can cause deadlocks.\n-  assert(!is_in_VTMS_transition(), \"no suspend allowed in VTMS transition\");\n-  assert(!is_VTMS_transition_disabler(), \"no suspend allowed for VTMS transition disablers\");\n-#endif\n+  \/\/ Suspending a vthread transition disabler can cause deadlocks.\n+  assert(!is_vthread_transition_disabler(), \"no suspend allowed for vthread transition disablers\");\n@@ -1203,1 +1190,1 @@\n-  return this->handshake_state()->suspend(register_vthread_SR);\n+  return this->suspend_resume_manager()->suspend(register_vthread_SR);\n@@ -1209,1 +1196,1 @@\n-  return this->handshake_state()->resume(register_vthread_SR);\n+  return this->suspend_resume_manager()->resume(register_vthread_SR);\n@@ -1340,1 +1327,1 @@\n-      nm->make_not_entrant(\"zombie\", false \/* don't interfere with testing\/debugging *\/);\n+      nm->make_not_entrant(nmethod::InvalidationReason::ZOMBIE, false \/* don't interfere with testing\/debugging *\/);\n@@ -1389,3 +1376,0 @@\n-  \/\/ Verify that the deferred card marks have been flushed.\n-  assert(deferred_card_mark().is_empty(), \"Should be empty during GC\");\n-\n@@ -1438,3 +1422,2 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    lock_stack().oops_do(f);\n-  }\n+  \/\/ Due to fast locking\n+  lock_stack().oops_do(f);\n@@ -1996,50 +1979,0 @@\n-\/\/ Slow-path increment of the held monitor counts. JNI locking is always\n-\/\/ this slow-path.\n-void JavaThread::inc_held_monitor_count(intx i, bool jni) {\n-#ifdef SUPPORT_MONITOR_COUNT\n-\n-  if (LockingMode != LM_LEGACY) {\n-    \/\/ Nothing to do. Just do some sanity check.\n-    assert(_held_monitor_count == 0, \"counter should not be used\");\n-    assert(_jni_monitor_count == 0, \"counter should not be used\");\n-    return;\n-  }\n-\n-  assert(_held_monitor_count >= 0, \"Must always be non-negative: %zd\", _held_monitor_count);\n-  _held_monitor_count += i;\n-  if (jni) {\n-    assert(_jni_monitor_count >= 0, \"Must always be non-negative: %zd\", _jni_monitor_count);\n-    _jni_monitor_count += i;\n-  }\n-  assert(_held_monitor_count >= _jni_monitor_count, \"Monitor count discrepancy detected - held count \"\n-         \"%zd is less than JNI count %zd\", _held_monitor_count, _jni_monitor_count);\n-#endif \/\/ SUPPORT_MONITOR_COUNT\n-}\n-\n-\/\/ Slow-path decrement of the held monitor counts. JNI unlocking is always\n-\/\/ this slow-path.\n-void JavaThread::dec_held_monitor_count(intx i, bool jni) {\n-#ifdef SUPPORT_MONITOR_COUNT\n-\n-  if (LockingMode != LM_LEGACY) {\n-    \/\/ Nothing to do. Just do some sanity check.\n-    assert(_held_monitor_count == 0, \"counter should not be used\");\n-    assert(_jni_monitor_count == 0, \"counter should not be used\");\n-    return;\n-  }\n-\n-  _held_monitor_count -= i;\n-  assert(_held_monitor_count >= 0, \"Must always be non-negative: %zd\", _held_monitor_count);\n-  if (jni) {\n-    _jni_monitor_count -= i;\n-    assert(_jni_monitor_count >= 0, \"Must always be non-negative: %zd\", _jni_monitor_count);\n-  }\n-  \/\/ When a thread is detaching with still owned JNI monitors, the logic that releases\n-  \/\/ the monitors doesn't know to set the \"jni\" flag and so the counts can get out of sync.\n-  \/\/ So we skip this assert if the thread is exiting. Once all monitors are unlocked the\n-  \/\/ JNI count is directly set to zero.\n-  assert(_held_monitor_count >= _jni_monitor_count || is_exiting(), \"Monitor count discrepancy detected - held count \"\n-         \"%zd is less than JNI count %zd\", _held_monitor_count, _jni_monitor_count);\n-#endif \/\/ SUPPORT_MONITOR_COUNT\n-}\n-\n@@ -2100,1 +2033,1 @@\n-\/\/ if the thread was interrupted.\n+\/\/ if the thread was interrupted or async exception was installed.\n@@ -2120,0 +2053,3 @@\n+    if (has_async_exception_condition()) {\n+      return false;\n+    }\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":68,"deletions":132,"binary":false,"changes":200,"status":"modified"},{"patch":"@@ -41,1 +41,2 @@\n-#include \"runtime\/stackWatermarkSet.hpp\"\n+#include \"runtime\/stackWatermarkSet.hpp\"\n+#include \"runtime\/suspendResumeManager.hpp\"\n@@ -55,1 +56,1 @@\n-class AsyncExceptionHandshake;\n+class AsyncExceptionHandshakeClosure;\n@@ -151,5 +152,0 @@\n-  \/\/ See ReduceInitialCardMarks: this holds the precise space interval of\n-  \/\/ the most recent slow path allocation for which compiled code has\n-  \/\/ elided card-marks for performance along the fast-path.\n-  MemRegion     _deferred_card_mark;\n-\n@@ -184,1 +180,1 @@\n-    \/\/ Use Atomic::load() to prevent data race between concurrent modification and\n+    \/\/ Use AtomicAccess::load() to prevent data race between concurrent modification and\n@@ -187,1 +183,1 @@\n-    return Atomic::load(&_current_pending_monitor);\n+    return AtomicAccess::load(&_current_pending_monitor);\n@@ -190,1 +186,1 @@\n-    Atomic::store(&_current_pending_monitor, monitor);\n+    AtomicAccess::store(&_current_pending_monitor, monitor);\n@@ -200,1 +196,1 @@\n-    return Atomic::load(&_current_waiting_monitor);\n+    return AtomicAccess::load(&_current_waiting_monitor);\n@@ -203,1 +199,1 @@\n-    Atomic::store(&_current_waiting_monitor, monitor);\n+    AtomicAccess::store(&_current_waiting_monitor, monitor);\n@@ -235,2 +231,2 @@\n-  friend class InstallAsyncExceptionHandshake;\n-  friend class AsyncExceptionHandshake;\n+  friend class InstallAsyncExceptionHandshakeClosure;\n+  friend class AsyncExceptionHandshakeClosure;\n@@ -241,1 +237,1 @@\n-  void install_async_exception(AsyncExceptionHandshake* aec = nullptr);\n+  void install_async_exception(AsyncExceptionHandshakeClosure* aec = nullptr);\n@@ -324,0 +320,1 @@\n+  volatile bool         _throwing_unsafe_access_error;   \/\/ Thread has faulted and is throwing an exception\n@@ -328,1 +325,0 @@\n-  bool                  _is_in_VTMS_transition;          \/\/ thread is in virtual thread mount state transition\n@@ -331,1 +327,1 @@\n-  bool                  _VTMS_transition_mark;           \/\/ used for sync between VTMS transitions and disablers\n+  int                   _jvmti_events_disabled;          \/\/ JVMTI events disabled manually\n@@ -334,3 +330,0 @@\n-#ifdef ASSERT\n-  bool                  _is_VTMS_transition_disabler;    \/\/ thread currently disabled VTMS transitions\n-#endif\n@@ -452,1 +445,0 @@\n-  volatile int     _is_method_handle_return;     \/\/ true (== 1) if the current exception PC is a MethodHandle call site.\n@@ -479,3 +471,0 @@\n-  \/\/ It's signed for error detection.\n-  intx _held_monitor_count;  \/\/ used by continuations for fast lock detection\n-  intx _jni_monitor_count;\n@@ -495,0 +484,3 @@\n+  \/\/ We allow preemption on some klass initialization calls.\n+  \/\/ We use this boolean to mark such calls.\n+  bool _at_preemptable_init;\n@@ -503,1 +495,1 @@\n-  bool preempting()           { return _preempt_alternate_return != nullptr; }\n+  bool preempting()                              { return _preempt_alternate_return != nullptr; }\n@@ -506,1 +498,12 @@\n-private:\n+  bool at_preemptable_init()           { return _at_preemptable_init; }\n+  void set_at_preemptable_init(bool b) { _at_preemptable_init = b; }\n+\n+#ifdef ASSERT\n+  \/\/ Used for extra logging with -Xlog:continuation+preempt\n+  InstanceKlass* _preempt_init_klass;\n+\n+  InstanceKlass* preempt_init_klass() { return _preempt_init_klass; }\n+  void set_preempt_init_klass(InstanceKlass* ik) { _preempt_init_klass = ik; }\n+\n+  int _interp_at_preemptable_vmcall_cnt;\n+  int interp_at_preemptable_vmcall_cnt() { return _interp_at_preemptable_vmcall_cnt; }\n@@ -508,0 +511,24 @@\n+  bool _interp_redoing_vm_call;\n+  bool interp_redoing_vm_call() const { return _interp_redoing_vm_call; };\n+\n+  class AtRedoVMCall : public StackObj {\n+    JavaThread* _thread;\n+   public:\n+    AtRedoVMCall(JavaThread* t) : _thread(t) {\n+      assert(!_thread->_interp_redoing_vm_call, \"\");\n+      _thread->_interp_redoing_vm_call = true;\n+      _thread->_interp_at_preemptable_vmcall_cnt++;\n+      assert(_thread->_interp_at_preemptable_vmcall_cnt > 0, \"Unexpected count: %d\",\n+             _thread->_interp_at_preemptable_vmcall_cnt);\n+    }\n+    ~AtRedoVMCall() {\n+      assert(_thread->_interp_redoing_vm_call, \"\");\n+      _thread->_interp_redoing_vm_call = false;\n+      _thread->_interp_at_preemptable_vmcall_cnt--;\n+      assert(_thread->_interp_at_preemptable_vmcall_cnt >= 0, \"Unexpected count: %d\",\n+             _thread->_interp_at_preemptable_vmcall_cnt);\n+    }\n+  };\n+#endif \/\/ ASSERT\n+\n+private:\n@@ -633,0 +660,3 @@\n+  bool is_throwing_unsafe_access_error()          { return _throwing_unsafe_access_error; }\n+  void set_throwing_unsafe_access_error(bool val) { _throwing_unsafe_access_error = val; }\n+\n@@ -665,7 +695,0 @@\n-  void inc_held_monitor_count(intx i = 1, bool jni = false);\n-  void dec_held_monitor_count(intx i = 1, bool jni = false);\n-\n-  intx held_monitor_count() { return _held_monitor_count; }\n-  intx jni_monitor_count()  { return _jni_monitor_count;  }\n-  void clear_jni_monitor_count() { _jni_monitor_count = 0; }\n-\n@@ -697,0 +720,3 @@\n+private:\n+  SuspendResumeManager _suspend_resume_manager;\n+public:\n@@ -699,1 +725,2 @@\n-  bool is_suspended()     { return _handshake.is_suspended(); }\n+  bool is_suspended()     { return _suspend_resume_manager.is_suspended(); }\n+  SuspendResumeManager* suspend_resume_manager() { return &_suspend_resume_manager; }\n@@ -708,0 +735,14 @@\n+private:\n+  bool _is_in_vthread_transition;                    \/\/ thread is in virtual thread mount state transition\n+  DEBUG_ONLY(bool _is_vthread_transition_disabler;)  \/\/ thread currently disabled vthread transitions\n+  DEBUG_ONLY(bool _is_disabler_at_start;)            \/\/ thread at process of disabling vthread transitions\n+public:\n+  bool is_in_vthread_transition() const;\n+  void set_is_in_vthread_transition(bool val);\n+#ifdef ASSERT\n+  bool is_vthread_transition_disabler() const       { return _is_vthread_transition_disabler; }\n+  void set_is_vthread_transition_disabler(bool val);\n+  bool is_disabler_at_start() const                 { return _is_disabler_at_start; }\n+  void set_is_disabler_at_start(bool val);\n+#endif\n+\n@@ -713,1 +754,1 @@\n-    return Atomic::load(&_carrier_thread_suspended);\n+    return AtomicAccess::load(&_carrier_thread_suspended);\n@@ -716,4 +757,1 @@\n-  bool is_in_VTMS_transition() const             { return _is_in_VTMS_transition; }\n-  void set_is_in_VTMS_transition(bool val);\n-\n-  void toggle_is_disable_suspend()               { _is_disable_suspend = !_is_disable_suspend; };\n+  void toggle_is_disable_suspend()               { _is_disable_suspend = !_is_disable_suspend; }\n@@ -723,1 +761,1 @@\n-  void toggle_is_in_java_upcall()                { _is_in_java_upcall = !_is_in_java_upcall; };\n+  void toggle_is_in_java_upcall()                { _is_in_java_upcall = !_is_in_java_upcall; }\n@@ -725,2 +763,2 @@\n-  bool VTMS_transition_mark() const              { return Atomic::load(&_VTMS_transition_mark); }\n-  void set_VTMS_transition_mark(bool val)        { Atomic::store(&_VTMS_transition_mark, val); }\n+  void disable_jvmti_events()                    { _jvmti_events_disabled++; }\n+  void enable_jvmti_events()                     { _jvmti_events_disabled--; }\n@@ -729,1 +767,1 @@\n-  \/\/ - is in a VTMS transition (_is_in_VTMS_transition)\n+  \/\/ - is in a vthread transition (_is_in_vthread_transition)\n@@ -732,1 +770,3 @@\n-  bool should_hide_jvmti_events() const          { return _is_in_VTMS_transition || _is_disable_suspend || _is_in_java_upcall; }\n+  bool should_hide_jvmti_events() const {\n+    return _is_in_vthread_transition || _is_disable_suspend || _is_in_java_upcall || _jvmti_events_disabled != 0;\n+  }\n@@ -739,4 +779,0 @@\n-#ifdef ASSERT\n-  bool is_VTMS_transition_disabler() const       { return _is_VTMS_transition_disabler; }\n-  void set_is_VTMS_transition_disabler(bool val);\n-#endif\n@@ -753,3 +789,0 @@\n-  \/\/ Stack-locking support (not for LM_LIGHTWEIGHT)\n-  bool is_lock_owned(address adr) const;\n-\n@@ -788,3 +821,0 @@\n-  MemRegion deferred_card_mark() const           { return _deferred_card_mark; }\n-  void set_deferred_card_mark(MemRegion mr)      { _deferred_card_mark = mr;   }\n-\n@@ -818,1 +848,0 @@\n-  void set_is_method_handle_return(bool value)   { _is_method_handle_return = value ? 1 : 0; }\n@@ -867,1 +896,0 @@\n-  static ByteSize is_method_handle_return_offset() { return byte_offset_of(JavaThread, _is_method_handle_return); }\n@@ -901,2 +929,0 @@\n-  static ByteSize held_monitor_count_offset() { return byte_offset_of(JavaThread, _held_monitor_count); }\n-  static ByteSize jni_monitor_count_offset()  { return byte_offset_of(JavaThread, _jni_monitor_count); }\n@@ -905,0 +931,1 @@\n+  DEBUG_ONLY(static ByteSize interp_at_preemptable_vmcall_cnt_offset() { return byte_offset_of(JavaThread, _interp_at_preemptable_vmcall_cnt); })\n@@ -906,0 +933,1 @@\n+  static ByteSize is_in_vthread_transition_offset()     { return byte_offset_of(JavaThread, _is_in_vthread_transition); }\n@@ -908,1 +936,0 @@\n-  static ByteSize is_in_VTMS_transition_offset()     { return byte_offset_of(JavaThread, _is_in_VTMS_transition); }\n@@ -944,1 +971,1 @@\n-  bool in_critical_atomic() { return Atomic::load(&_jni_active_critical) > 0; }\n+  bool in_critical_atomic() { return AtomicAccess::load(&_jni_active_critical) > 0; }\n@@ -1162,1 +1189,1 @@\n-  \/\/ (see EnterInterpOnlyModeClosure).\n+  \/\/ (see EnterInterpOnlyModeHandshakeClosure).\n@@ -1351,2 +1378,2 @@\n-  NoPreemptMark(JavaThread* thread) : _ce(thread->last_continuation()), _unpin(false) {\n-    if (_ce != nullptr) _unpin = _ce->pin();\n+  NoPreemptMark(JavaThread* thread, bool ignore_mark = false) : _ce(thread->last_continuation()), _unpin(false) {\n+    if (_ce != nullptr && !ignore_mark) _unpin = _ce->pin();\n@@ -1379,0 +1406,14 @@\n+class ThrowingUnsafeAccessError : public StackObj {\n+  JavaThread* _thread;\n+  bool _prev;\n+public:\n+  ThrowingUnsafeAccessError(JavaThread* thread) :\n+      _thread(thread),\n+      _prev(thread->is_throwing_unsafe_access_error()) {\n+    _thread->set_throwing_unsafe_access_error(true);\n+  }\n+  ~ThrowingUnsafeAccessError() {\n+    _thread->set_throwing_unsafe_access_error(_prev);\n+  }\n+};\n+\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":104,"deletions":63,"binary":false,"changes":167,"status":"modified"},{"patch":"@@ -53,1 +53,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -68,1 +68,1 @@\n-#include \"runtime\/vmOperations.hpp\"\n+#include \"runtime\/vmOperations.hpp\"\n@@ -92,1 +92,1 @@\n-# include <signal.h>\n+# include <signal.h>\n@@ -111,1 +111,1 @@\n-int os::snprintf_checked(char* buf, size_t len, const char* fmt, ...) {\n+void os::snprintf_checked(char* buf, size_t len, const char* fmt, ...) {\n@@ -116,2 +116,0 @@\n-  assert(result >= 0, \"os::snprintf error\");\n-  return result;\n@@ -122,0 +120,2 @@\n+  assert(buf != nullptr || len == 0, \"Valid buffer and length must be given\");\n+  assert(fmt != nullptr, \"Missing format string\");\n@@ -123,1 +123,1 @@\n-  \/\/ If an encoding error occurred (result < 0) then it's not clear\n+  \/\/ If an error occurred (result < 0) then it's not clear\n@@ -125,1 +125,1 @@\n-  if ((result < 0) && (len > 0)) {\n+  if ((result < 0) && (len > 0) && (buf != nullptr)) {\n@@ -128,0 +128,1 @@\n+  assert(result >= 0, \"os::vsnprintf error: %s\", strerror(errno));\n@@ -461,1 +462,1 @@\n-            InstanceKlass::cast(PENDING_EXCEPTION->klass())->\n+            PENDING_EXCEPTION->klass()->\n@@ -669,2 +670,2 @@\n-  } else {\n-    DEBUG_ONLY(::memset(inner_ptr, uninitBlockPad, size);)\n+  } else if (ZapCHeap) {\n+    ::memset(inner_ptr, uninitBlockPad, size);\n@@ -743,1 +744,1 @@\n-    if (old_size < size) {\n+    if (ZapCHeap && old_size < size) {\n@@ -829,1 +830,1 @@\n-    if (Atomic::cmpxchg(&_rand_seed, seed, rand, memory_order_relaxed) == seed) {\n+    if (AtomicAccess::cmpxchg(&_rand_seed, seed, rand, memory_order_relaxed) == seed) {\n@@ -1045,1 +1046,1 @@\n-    logical_p += unitsize;\n+    logical_p = (const_address) ((uintptr_t)logical_p + unitsize);\n@@ -1128,1 +1129,1 @@\n-  const JvmtiAgentList::Iterator it = JvmtiAgentList::all();\n+  JvmtiAgentList::Iterator it = JvmtiAgentList::all();\n@@ -1186,1 +1187,2 @@\n-  size_t mem = physical_memory()\/G;\n+  physical_memory_size_type phys_mem = physical_memory();\n+  physical_memory_size_type mem = phys_mem\/G;\n@@ -1188,2 +1190,2 @@\n-    mem = physical_memory()\/M;\n-    st->print(\"%d cores, %zuM, \", processor_count(), mem);\n+    mem = phys_mem\/M;\n+    st->print(\"%d cores, \" PHYS_MEM_TYPE_FORMAT \"M, \", processor_count(), mem);\n@@ -1191,1 +1193,1 @@\n-    st->print(\"%d cores, %zuG, \", processor_count(), mem);\n+    st->print(\"%d cores, \" PHYS_MEM_TYPE_FORMAT \"G, \", processor_count(), mem);\n@@ -1577,1 +1579,1 @@\n-  Atomic::release_store(&_image_release_file_content, tmp);\n+  AtomicAccess::release_store(&_image_release_file_content, tmp);\n@@ -1582,1 +1584,1 @@\n-  char* ifrc = Atomic::load_acquire(&_image_release_file_content);\n+  char* ifrc = AtomicAccess::load_acquire(&_image_release_file_content);\n@@ -1936,3 +1938,3 @@\n-  bool         result            = false;\n-  const unsigned int    server_processors = 2;\n-  const julong server_memory     = 2UL * G;\n+  bool  result                                    = false;\n+  const unsigned int server_processors            = 2;\n+  const physical_memory_size_type server_memory   = 2UL * G;\n@@ -1942,2 +1944,2 @@\n-  const julong missing_memory   = 256UL * M;\n-\n+  const physical_memory_size_type missing_memory  = 256UL * M;\n+  physical_memory_size_type phys_mem              = os::physical_memory();\n@@ -1946,1 +1948,1 @@\n-      (os::physical_memory() >= (server_memory - missing_memory))) {\n+      (phys_mem >= server_memory - missing_memory)) {\n@@ -2205,1 +2207,1 @@\n-julong os::used_memory() {\n+bool os::used_memory(physical_memory_size_type& value) {\n@@ -2208,4 +2210,1 @@\n-    jlong mem_usage = OSContainer::memory_usage_in_bytes();\n-    if (mem_usage > 0) {\n-      return mem_usage;\n-    }\n+    return OSContainer::memory_usage_in_bytes(value);\n@@ -2214,1 +2213,6 @@\n-  return os::physical_memory() - os::available_memory();\n+  physical_memory_size_type avail_mem = 0;\n+  \/\/ Return value ignored - defaulting to 0 on failure.\n+  (void)os::available_memory(avail_mem);\n+  physical_memory_size_type phys_mem = os::physical_memory();\n+  value = phys_mem - avail_mem;\n+  return true;\n@@ -2348,1 +2352,1 @@\n-        Atomic::add(reinterpret_cast<int*>(cur), 0, memory_order_relaxed);\n+        AtomicAccess::add(reinterpret_cast<int*>(cur), 0, memory_order_relaxed);\n@@ -2585,0 +2589,4 @@\n+jlong os::get_minimum_java_stack_size() {\n+  return static_cast<jlong>(_java_thread_min_stack_allowed);\n+}\n+\n","filename":"src\/hotspot\/share\/runtime\/os.cpp","additions":42,"deletions":34,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -171,1 +171,0 @@\n-  friend class VMStructs;\n@@ -298,6 +297,1 @@\n-  \/\/ The \"virtual time\" of a thread is the amount of time a thread has\n-  \/\/ actually run.  The first function indicates whether the OS supports\n-  \/\/ this functionality for the current thread, and if so the second\n-  \/\/ returns the elapsed virtual time for the current thread.\n-  static bool supports_vtime();\n-  static double elapsedVTime();\n+  static double elapsed_process_cpu_time();\n@@ -342,3 +336,3 @@\n-  static julong available_memory();\n-  static julong used_memory();\n-  static julong free_memory();\n+  [[nodiscard]] static bool available_memory(physical_memory_size_type& value);\n+  [[nodiscard]] static bool used_memory(physical_memory_size_type& value);\n+  [[nodiscard]] static bool free_memory(physical_memory_size_type& value);\n@@ -346,2 +340,2 @@\n-  static jlong total_swap_space();\n-  static jlong free_swap_space();\n+  [[nodiscard]] static bool total_swap_space(physical_memory_size_type& value);\n+  [[nodiscard]] static bool free_swap_space(physical_memory_size_type& value);\n@@ -349,2 +343,1 @@\n-  static julong physical_memory();\n-  static bool has_allocatable_memory_limit(size_t* limit);\n+  static physical_memory_size_type physical_memory();\n@@ -402,0 +395,2 @@\n+  \/\/ get allowed minimum java stack size\n+  static jlong get_minimum_java_stack_size();\n@@ -459,0 +454,10 @@\n+  \/\/ Returns an upper limit beyond which reserve_memory() calls are guaranteed\n+  \/\/ to fail. It is not guaranteed that reserving less memory than this will\n+  \/\/ succeed, however.\n+  static size_t reserve_memory_limit();\n+\n+  \/\/ Returns an upper limit beyond which commit_memory() calls are guaranteed\n+  \/\/ to fail. It is not guaranteed that committing less memory than this will\n+  \/\/ succeed, however.\n+  static size_t commit_memory_limit();\n+\n@@ -538,1 +543,1 @@\n-  static bool   numa_has_group_homing();\n+  static void   numa_set_thread_affinity(Thread* thread, int node);\n@@ -543,1 +548,0 @@\n-  static bool   numa_topology_changed();\n@@ -815,5 +819,13 @@\n-  static int vsnprintf(char* buf, size_t len, const char* fmt, va_list args) ATTRIBUTE_PRINTF(3, 0);\n-  static int snprintf(char* buf, size_t len, const char* fmt, ...) ATTRIBUTE_PRINTF(3, 4);\n-  \/\/ Performs snprintf and asserts the result is non-negative (so there was not\n-  \/\/ an encoding error) and that the output was not truncated.\n-  static int snprintf_checked(char* buf, size_t len, const char* fmt, ...) ATTRIBUTE_PRINTF(3, 4);\n+  \/\/ Performs vsnprintf and asserts the result is non-negative (so there was not\n+  \/\/ an encoding error or any other kind of usage error).\n+  [[nodiscard]]\n+  ATTRIBUTE_PRINTF(3, 0)\n+  static int vsnprintf(char* buf, size_t len, const char* fmt, va_list args);\n+  \/\/ Delegates to vsnprintf.\n+  [[nodiscard]]\n+  ATTRIBUTE_PRINTF(3, 4)\n+  static int snprintf(char* buf, size_t len, const char* fmt, ...);\n+\n+  \/\/ Delegates to snprintf and asserts that the output was not truncated.\n+  ATTRIBUTE_PRINTF(3, 4)\n+  static void snprintf_checked(char* buf, size_t len, const char* fmt, ...);\n@@ -985,4 +997,1 @@\n-  \/\/ Thread CPU Time - return the fast estimate on a platform\n-  \/\/ On Linux   - fast clock_gettime where available - user+sys\n-  \/\/            - otherwise: very slow \/proc fs - user+sys\n-  \/\/ On Windows - GetThreadTimes - user+sys\n+  \/\/ Thread CPU Time - return the fast estimate on a platform - user+sys\n@@ -1109,1 +1118,1 @@\n-\/\/ so arguably we should provide Atomic::SpinPause() instead\n+\/\/ so arguably we should provide AtomicAccess::SpinPause() instead\n","filename":"src\/hotspot\/share\/runtime\/os.hpp","additions":36,"deletions":27,"binary":false,"changes":63,"status":"modified"},{"patch":"@@ -1,1 +1,0 @@\n-\n@@ -28,0 +27,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -30,2 +30,1 @@\n-#include \"cds\/heapShared.hpp\"\n-#include \"cds\/metaspaceShared.hpp\"\n+#include \"cds\/heapShared.inline.hpp\"\n@@ -40,1 +39,1 @@\n-#include \"compiler\/compileTask.hpp\"\n+#include \"compiler\/compileTask.hpp\"\n@@ -95,1 +94,1 @@\n-#include \"runtime\/threadSMR.inline.hpp\"\n+#include \"runtime\/threadSMR.inline.hpp\"\n@@ -100,1 +99,2 @@\n-#include \"runtime\/vmOperations.hpp\"\n+#include \"runtime\/vmOperations.hpp\"\n+#include \"sanitizers\/address.hpp\"\n@@ -106,0 +106,1 @@\n+#include \"utilities\/debug.hpp\"\n@@ -348,0 +349,5 @@\n+  \/\/ This is before the execution of the very first Java bytecode.\n+  if (CDSConfig::is_using_aot_linked_classes()) {\n+    AOTLinkedClassBulkLoader::link_classes(THREAD);\n+  }\n+\n@@ -382,0 +388,2 @@\n+  HeapShared::materialize_thread_object();\n+\n@@ -409,0 +417,1 @@\n+  initialize_class(vmSymbols::jdk_internal_vm_PreemptedException(), CHECK);\n@@ -459,0 +468,3 @@\n+  \/\/ Deferred \"static\" initialization\n+  NonJavaThread::init();\n+\n@@ -568,1 +580,2 @@\n-  \/\/ Attach the main thread to this os thread\n+  \/\/ Attach the main thread to this os thread. It is added to the threads list inside\n+  \/\/ universe_init(), within init_globals().\n@@ -582,1 +595,3 @@\n-  main_thread->set_monitor_owner_id(ThreadIdentifier::next());\n+  const int64_t main_thread_tid = ThreadIdentifier::next();\n+  guarantee(main_thread_tid == 3, \"Must equal the PRIMORDIAL_TID used in Threads.java\");\n+  main_thread->set_monitor_owner_id(main_thread_tid);\n@@ -630,8 +645,0 @@\n-  \/\/ Add main_thread to threads list to finish barrier setup with\n-  \/\/ on_thread_attach.  Should be before starting to build Java objects in\n-  \/\/ init_globals2, which invokes barriers.\n-  {\n-    MutexLocker mu(Threads_lock);\n-    Threads::add(main_thread);\n-  }\n-\n@@ -721,0 +728,7 @@\n+  \/\/ Prepare AOT heap loader for GC.\n+  HeapShared::enable_gc();\n+\n+#ifdef ADDRESS_SANITIZER\n+  Asan::initialize();\n+#endif\n+\n@@ -766,0 +780,4 @@\n+  if (CDSConfig::is_using_aot_linked_classes()) {\n+    nmethod::post_delayed_compiled_method_load_events();\n+  }\n+\n@@ -797,1 +815,1 @@\n-    AOTLinkedClassBulkLoader::finish_loading_javabase_classes(CHECK_JNI_ERR);\n+    AOTLinkedClassBulkLoader::init_javabase_classes(THREAD);\n@@ -817,1 +835,1 @@\n-    AOTLinkedClassBulkLoader::load_non_javabase_classes(THREAD);\n+    AOTLinkedClassBulkLoader::init_non_javabase_classes(THREAD);\n@@ -908,0 +926,3 @@\n+  \/\/ Finish materializing AOT objects\n+  HeapShared::finish_materialize_objects();\n+\n@@ -915,1 +936,1 @@\n-    MetaspaceShared::preload_and_dump(CHECK_JNI_ERR);\n+    AOTMetaspace::dump_static_archive(CHECK_JNI_ERR);\n@@ -918,1 +939,1 @@\n-    MetaspaceShared::preload_and_dump(CHECK_JNI_ERR);\n+    AOTMetaspace::dump_static_archive(CHECK_JNI_ERR);\n@@ -1320,14 +1341,0 @@\n-JavaThread *Threads::owning_thread_from_stacklock(ThreadsList * t_list, address basicLock) {\n-  assert(LockingMode == LM_LEGACY, \"Not with new lightweight locking\");\n-\n-  JavaThread* the_owner = nullptr;\n-  for (JavaThread* q : *t_list) {\n-    if (q->is_lock_owned(basicLock)) {\n-      the_owner = q;\n-      break;\n-    }\n-  }\n-  return the_owner;\n-}\n-\n-  assert(LockingMode == LM_LIGHTWEIGHT, \"Only with new lightweight locking\");\n@@ -1351,6 +1358,1 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n-      return owning_thread_from_object(t_list, monitor->object());\n-    } else {\n-      assert(LockingMode == LM_LEGACY, \"invariant\");\n-      return owning_thread_from_stacklock(t_list, (address)monitor->stack_locker());\n-    }\n+    return owning_thread_from_object(t_list, monitor->object());\n@@ -1392,1 +1394,1 @@\n-  st->print_cr(\"Full thread dump %s (%s %s):\",\n+  st->print_cr(\"Full thread dump %s (%s %s)\",\n@@ -1396,0 +1398,14 @@\n+  JDK_Version::current().to_string(buf, sizeof(buf));\n+  const char* runtime_name = JDK_Version::runtime_name() != nullptr ?\n+                             JDK_Version::runtime_name() : \"\";\n+  const char* runtime_version = JDK_Version::runtime_version() != nullptr ?\n+                                JDK_Version::runtime_version() : \"\";\n+  const char* vendor_version = JDK_Version::runtime_vendor_version() != nullptr ?\n+                               JDK_Version::runtime_vendor_version() : \"\";\n+  const char* jdk_debug_level = VM_Version::printable_jdk_debug_level() != nullptr ?\n+                                VM_Version::printable_jdk_debug_level() : \"\";\n+\n+  st->print_cr(\"                 JDK version: %s%s%s (%s) (%sbuild %s)\", runtime_name,\n+                (*vendor_version != '\\0') ? \" \" : \"\", vendor_version,\n+                buf, jdk_debug_level, runtime_version);\n+\n","filename":"src\/hotspot\/share\/runtime\/threads.cpp","additions":57,"deletions":41,"binary":false,"changes":98,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -51,1 +51,0 @@\n-  template(CollectForCodeCacheAllocation)         \\\n@@ -62,0 +61,1 @@\n+  template(G1RendezvousGCThreads)                 \\\n@@ -71,4 +71,0 @@\n-  template(XMarkStart)                            \\\n-  template(XMarkEnd)                              \\\n-  template(XRelocateStart)                        \\\n-  template(XVerify)                               \\\n@@ -116,1 +112,0 @@\n-  template(JvmtiPostObjectFree)                   \\\n@@ -164,0 +159,4 @@\n+  \/\/ VMOp_Type may belong to a category of the operation.\n+  \/\/ Override is_XX_operation() appropriately in subclasses.\n+  virtual bool is_gc_operation() const { return false; }\n+\n","filename":"src\/hotspot\/share\/runtime\/vmOperation.hpp","additions":6,"deletions":7,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -1,1 +1,0 @@\n-\n@@ -47,0 +46,1 @@\n+#include \"jfr\/recorder\/service\/jfrRecorderThread.hpp\"\n@@ -48,1 +48,0 @@\n-#include \"memory\/allocation.hpp\"\n@@ -58,1 +57,1 @@\n-#include \"oops\/constMethod.hpp\"\n+#include \"oops\/bsmAttribute.hpp\"\n@@ -60,0 +59,1 @@\n+#include \"oops\/constMethod.hpp\"\n@@ -62,3 +62,0 @@\n-#include \"oops\/instanceClassLoaderKlass.hpp\"\n-#include \"oops\/instanceMirrorKlass.hpp\"\n-#include \"oops\/instanceStackChunkKlass.hpp\"\n@@ -88,1 +85,0 @@\n-#include \"runtime\/java.hpp\"\n@@ -101,1 +97,1 @@\n-#include \"runtime\/vmStructs.hpp\"\n+#include \"runtime\/vmStructs.hpp\"\n@@ -174,0 +170,3 @@\n+  nonstatic_field(BSMAttributeEntries,         _offsets,                                      Array<u4>*)                            \\\n+  nonstatic_field(BSMAttributeEntries,         _bootstrap_methods,                            Array<u2>*)                            \\\n+  nonstatic_field(ConstantPool,                _bsm_entries,                                  BSMAttributeEntries)                   \\\n@@ -177,1 +176,0 @@\n-  nonstatic_field(ConstantPool,                _operands,                                     Array<u2>*)                            \\\n@@ -221,0 +219,1 @@\n+  nonstatic_field(InstanceKlass,               _access_flags,                                 AccessFlags)                           \\\n@@ -230,1 +229,0 @@\n-  nonstatic_field(Klass,                       _access_flags,                                 AccessFlags)                           \\\n@@ -323,1 +321,1 @@\n-  nonstatic_field(JNIid,                       _holder,                                       Klass*)                                \\\n+  nonstatic_field(JNIid,                       _holder,                                       InstanceKlass*)                        \\\n@@ -350,2 +348,2 @@\n-     static_field(MetaspaceObj,                _shared_metaspace_base,                        void*)                                 \\\n-     static_field(MetaspaceObj,                _shared_metaspace_top,                         void*)                                 \\\n+     static_field(MetaspaceObj,                _aot_metaspace_base,                           void*)                                 \\\n+     static_field(MetaspaceObj,                _aot_metaspace_top,                            void*)                                 \\\n@@ -543,2 +541,1 @@\n-  nonstatic_field(nmethod,                     _deopt_handler_offset,                         int)                                   \\\n-  nonstatic_field(nmethod,                     _deopt_mh_handler_offset,                      int)                                   \\\n+  nonstatic_field(nmethod,                     _deopt_handler_entry_offset,                   int)                                   \\\n@@ -547,0 +544,1 @@\n+  nonstatic_field(nmethod,                     _immutable_data_ref_count_offset,              int)                                   \\\n@@ -616,1 +614,0 @@\n-  volatile_nonstatic_field(JavaThread,         _is_method_handle_return,                      int)                                   \\\n@@ -626,0 +623,1 @@\n+  nonstatic_field(JavaThread,                  _cont_entry,                                   ContinuationEntry*)                    \\\n@@ -669,0 +667,8 @@\n+  \/******************************************************************************************\/                                       \\\n+  \/* CI (NOTE: these CI fields are retained in VMStructs for the benefit of external tools, *\/                                       \\\n+  \/* to ease their migration to a future alternative.)                                      *\/                                       \\\n+  \/******************************************************************************************\/                                       \\\n+                                                                                                                                     \\\n+  nonstatic_field(CompilerThread,              _env,                                          ciEnv*)                                \\\n+  nonstatic_field(ciEnv,                       _task,                                         CompileTask*)                          \\\n+                                                                                                                                     \\\n@@ -676,2 +682,0 @@\n-  volatile_nonstatic_field(ObjectMonitor,      _stack_locker,                                 BasicLock*)                            \\\n-  volatile_nonstatic_field(BasicLock,          _metadata,                                     uintptr_t)                             \\\n@@ -736,0 +740,1 @@\n+  unchecked_nonstatic_field(Array<u4>,                 _data,                                 sizeof(u4))                            \\\n@@ -800,1 +805,2 @@\n-  volatile_nonstatic_field(Mutex,              _owner,                                        Thread*)\n+  volatile_nonstatic_field(Mutex,              _owner,                                        Thread*)                               \\\n+  static_field(ContinuationEntry,              _return_pc,                                    address)\n@@ -966,0 +972,1 @@\n+  declare_toplevel_type(BSMAttributeEntries)                              \\\n@@ -1030,0 +1037,1 @@\n+        declare_type(JfrRecorderThread, JavaThread)                       \\\n@@ -1151,0 +1159,6 @@\n+  \/*********************\/                                                 \\\n+  \/* CI *\/                                                                \\\n+  \/*********************\/                                                 \\\n+                                                                          \\\n+  declare_toplevel_type(ciEnv)                                            \\\n+                                                                          \\\n@@ -1267,0 +1281,1 @@\n+  declare_toplevel_type(ContinuationEntry)                                \\\n@@ -1486,3 +1501,3 @@\n-  \/***********************************************\/                       \\\n-  \/* ConstantPool* layout enum for InvokeDynamic *\/                       \\\n-  \/***********************************************\/                       \\\n+  \/******************************************************\/                \\\n+  \/* BSMAttributeEntry* - layout enum for InvokeDynamic *\/                \\\n+  \/******************************************************\/                \\\n@@ -1490,3 +1505,3 @@\n-  declare_constant(ConstantPool::_indy_bsm_offset)                        \\\n-  declare_constant(ConstantPool::_indy_argc_offset)                       \\\n-  declare_constant(ConstantPool::_indy_argv_offset)                       \\\n+  declare_constant(BSMAttributeEntry::_bsmi_offset)                       \\\n+  declare_constant(BSMAttributeEntry::_argc_offset)                       \\\n+  declare_constant(BSMAttributeEntry::_argv_offset)                       \\\n@@ -1567,0 +1582,1 @@\n+  declare_constant(Deoptimization::Reason_short_running_long_loop)        \\\n@@ -1574,1 +1590,1 @@\n-  NOT_ZERO(JVMCI_ONLY(declare_constant(Deoptimization::Reason_aliasing)))                       \\\n+  declare_constant(Deoptimization::Reason_not_compiled_exception_handler) \\\n@@ -1576,1 +1592,0 @@\n-  NOT_ZERO(JVMCI_ONLY(declare_constant(Deoptimization::Reason_not_compiled_exception_handler))) \\\n@@ -1642,8 +1657,0 @@\n-  \/**********************************************\/                        \\\n-  \/* LockingMode enum (globalDefinitions.hpp) *\/                          \\\n-  \/**********************************************\/                        \\\n-                                                                          \\\n-  declare_constant(LM_MONITOR)                                            \\\n-  declare_constant(LM_LEGACY)                                             \\\n-  declare_constant(LM_LIGHTWEIGHT)                                        \\\n-                                                                          \\\n@@ -1714,1 +1721,0 @@\n-  declare_constant(PcDesc::PCDESC_is_method_handle_invoke)                \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":42,"deletions":36,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -29,1 +29,1 @@\n-#include \"cds\/cdsConfig.hpp\"\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -31,0 +31,1 @@\n+#include \"cds\/cdsConfig.hpp\"\n@@ -39,1 +40,1 @@\n-#include \"compiler\/compiler_globals.hpp\"\n+#include \"compiler\/compiler_globals.hpp\"\n@@ -44,1 +45,1 @@\n-#include \"memory\/metaspaceUtils.hpp\"\n+#include \"memory\/metaspaceUtils.hpp\"\n@@ -63,1 +64,1 @@\n-#include \"runtime\/vmOperations.hpp\"\n+#include \"runtime\/vmOperations.hpp\"\n@@ -82,1 +83,1 @@\n-#include \"os_posix.hpp\"\n+#include \"os_posix.hpp\"\n@@ -85,0 +86,1 @@\n+\n@@ -102,5 +104,2 @@\n-void DCmd::register_dcmds(){\n-  \/\/ Registration of the diagnostic commands\n-  \/\/ First argument specifies which interfaces will export the command\n-  \/\/ Second argument specifies if the command is enabled\n-  \/\/ Third  argument specifies if the command is hidden\n+void DCmd::register_dcmds() {\n+  \/\/ Argument specifies on which interfaces a command is made available:\n@@ -109,13 +108,13 @@\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<HelpDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<VersionDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CommandLineDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<PrintSystemPropertiesDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<PrintVMFlagsDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<SetVMFlagDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<VMDynamicLibrariesDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<VMUptimeDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<VMInfoDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<SystemGCDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<RunFinalizationDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<HeapInfoDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<FinalizerInfoDCmd>(full_export, true, false));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<HelpDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<VersionDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CommandLineDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<PrintSystemPropertiesDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<PrintVMFlagsDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<SetVMFlagDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<VMDynamicLibrariesDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<VMUptimeDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<VMInfoDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<SystemGCDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<RunFinalizationDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<HeapInfoDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<FinalizerInfoDCmd>(full_export));\n@@ -123,9 +122,9 @@\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<HeapDumpDCmd>(DCmd_Source_Internal | DCmd_Source_AttachAPI, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<ClassHistogramDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<SystemDictionaryDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<ClassHierarchyDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<ClassesDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<SymboltableDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<StringtableDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<metaspace::MetaspaceDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<EventLogDCmd>(full_export, true, false));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<HeapDumpDCmd>(DCmd_Source_Internal | DCmd_Source_AttachAPI));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<ClassHistogramDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<SystemDictionaryDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<ClassHierarchyDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<ClassesDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<SymboltableDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<StringtableDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<metaspace::MetaspaceDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<EventLogDCmd>(full_export));\n@@ -133,1 +132,1 @@\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<JVMTIAgentLoadDCmd>(full_export, true, false));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<JVMTIAgentLoadDCmd>(full_export));\n@@ -137,1 +136,1 @@\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<JVMTIDataDumpDCmd>(full_export, true, false));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<JVMTIDataDumpDCmd>(full_export));\n@@ -139,1 +138,1 @@\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<ThreadDumpDCmd>(full_export, true, false));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<ThreadDumpDCmd>(full_export));\n@@ -141,1 +140,1 @@\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<ThreadDumpToFileDCmd>(full_export, true, false));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<ThreadDumpToFileDCmd>(full_export));\n@@ -143,7 +142,7 @@\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<VThreadSchedulerDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<VThreadPollersDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<ClassLoaderStatsDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<ClassLoaderHierarchyDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CompileQueueDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CodeListDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CodeCacheDCmd>(full_export, true, false));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<VThreadSchedulerDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<VThreadPollersDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<ClassLoaderStatsDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<ClassLoaderHierarchyDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CompileQueueDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CodeListDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CodeCacheDCmd>(full_export));\n@@ -151,3 +150,3 @@\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<PerfMapDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<TrimCLibcHeapDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<MallocInfoDcmd>(full_export, true, false));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<PerfMapDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<TrimCLibcHeapDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<MallocInfoDcmd>(full_export));\n@@ -156,2 +155,2 @@\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<SystemMapDCmd>(full_export, true,false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<SystemDumpMapDCmd>(full_export, true,false));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<SystemMapDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<SystemDumpMapDCmd>(full_export));\n@@ -159,1 +158,1 @@\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CodeHeapAnalyticsDCmd>(full_export, true, false));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CodeHeapAnalyticsDCmd>(full_export));\n@@ -161,5 +160,5 @@\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CompilerDirectivesPrintDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CompilerDirectivesAddDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CompilerDirectivesRemoveDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CompilerDirectivesClearDCmd>(full_export, true, false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CompilationMemoryStatisticDCmd>(full_export, true, false));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CompilerDirectivesPrintDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CompilerDirectivesAddDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CompilerDirectivesRemoveDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CompilerDirectivesClearDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CompilationMemoryStatisticDCmd>(full_export));\n@@ -167,1 +166,1 @@\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CheckpointDCmd>(full_export, true,false));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<CheckpointDCmd>(full_export));\n@@ -172,4 +171,4 @@\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<JMXStartRemoteDCmd>(jmx_agent_export_flags, true,false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<JMXStartLocalDCmd>(jmx_agent_export_flags, true,false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<JMXStopRemoteDCmd>(jmx_agent_export_flags, true,false));\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<JMXStatusDCmd>(jmx_agent_export_flags, true,false));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<JMXStartRemoteDCmd>(jmx_agent_export_flags));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<JMXStartLocalDCmd>(jmx_agent_export_flags));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<JMXStopRemoteDCmd>(jmx_agent_export_flags));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<JMXStatusDCmd>(jmx_agent_export_flags));\n@@ -178,1 +177,2 @@\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<DumpSharedArchiveDCmd>(full_export, true, false));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<DumpSharedArchiveDCmd>(full_export));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<AOTEndRecordingDCmd>(full_export));\n@@ -181,1 +181,1 @@\n-  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<NMTDCmd>(full_export, true, false));\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<NMTDCmd>(full_export));\n@@ -204,2 +204,1 @@\n-      output()->print_cr(\"%s%s\", factory->name(),\n-                         factory->is_enabled() ? \"\" : \" [disabled]\");\n+      output()->print_cr(\"%s\", factory->name());\n@@ -215,2 +214,1 @@\n-      output()->print_cr(\"%s%s\", factory->name(),\n-                         factory->is_enabled() ? \"\" : \" [disabled]\");\n+      output()->print_cr(\"%s\", factory->name());\n@@ -235,2 +233,1 @@\n-      output()->print_cr(\"%s%s\", factory->name(),\n-                         factory->is_enabled() ? \"\" : \" [disabled]\");\n+      output()->print_cr(\"%s\", factory->name());\n@@ -1000,0 +997,22 @@\n+#if INCLUDE_CDS\n+void AOTEndRecordingDCmd::execute(DCmdSource source, TRAPS) {\n+  if (!CDSConfig::is_dumping_preimage_static_archive()) {\n+    output()->print_cr(\"AOT.end_recording is unsupported when VM flags -XX:AOTMode=record or -XX:AOTCacheOutput=<file> are missing.\");\n+    return;\n+  }\n+\n+  if (AOTMetaspace::preimage_static_archive_dumped()) {\n+    output()->print_cr(\"Recording has already ended.\");\n+    return;\n+  }\n+\n+  AOTMetaspace::dump_static_archive(THREAD);\n+  if (!AOTMetaspace::preimage_static_archive_dumped()) {\n+    output()->print_cr(\"Error: Failed to end recording.\");\n+    return;\n+  }\n+\n+  output()->print_cr(\"Recording ended successfully.\");\n+}\n+#endif \/\/ INCLUDE_CDS\n+\n","filename":"src\/hotspot\/share\/services\/diagnosticCommand.cpp","additions":86,"deletions":67,"binary":false,"changes":153,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"oops\/method.hpp\"\n@@ -40,1 +41,0 @@\n-#include \"oops\/method.hpp\"\n@@ -328,0 +328,15 @@\n+#if INCLUDE_CDS\n+class AOTEndRecordingDCmd : public DCmd {\n+public:\n+  AOTEndRecordingDCmd(outputStream* output, bool heap) : DCmd(output, heap) { }\n+    static const char* name() { return \"AOT.end_recording\"; }\n+    static const char* description() {\n+      return \"End AOT recording.\";\n+    }\n+    static const char* impact() {\n+      return \"Medium: Pause time depends on number of loaded classes\";\n+    }\n+    virtual void execute(DCmdSource source, TRAPS);\n+};\n+#endif \/\/ INCLUDE_CDS\n+\n@@ -359,1 +374,3 @@\n-    return \"Print all threads with stacktraces.\";\n+    return \"Print all platform threads, and mounted virtual threads, \"\n+           \"with stack traces. The Thread.dump_to_file command will \"\n+           \"print all threads to a file.\";\n@@ -771,1 +788,2 @@\n-    return \"Dump threads, with stack traces, to a file in plain text or JSON format.\";\n+    return \"Dump all threads, with stack traces, \"\n+           \"to a file in plain text or JSON format.\";\n","filename":"src\/hotspot\/share\/services\/diagnosticCommand.hpp","additions":21,"deletions":3,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -58,0 +58,1 @@\n+#include \"services\/cpuTimeUsage.hpp\"\n@@ -61,1 +62,1 @@\n-#include \"services\/writeableFlags.hpp\"\n+#include \"services\/gcNotifier.hpp\"\n@@ -64,1 +65,0 @@\n-#include \"services\/gcNotifier.hpp\"\n@@ -71,0 +71,1 @@\n+#include \"services\/writeableFlags.hpp\"\n@@ -893,0 +894,15 @@\n+static jlong get_gc_cpu_time() {\n+  if (!os::is_thread_cpu_time_supported()) {\n+    return -1;\n+  }\n+\n+  {\n+    MutexLocker hl(Heap_lock);\n+    if (Universe::heap()->is_shutting_down()) {\n+      return -1;\n+    }\n+\n+    return CPUTimeUsage::GC::total();\n+  }\n+}\n+\n@@ -919,0 +935,3 @@\n+  case JMM_TOTAL_GC_CPU_TIME:\n+    return get_gc_cpu_time();\n+\n@@ -979,1 +998,1 @@\n-    return os::physical_memory();\n+    return static_cast<jlong>(os::physical_memory());\n@@ -2029,1 +2048,5 @@\n-    infoArray[i].enabled = info->is_enabled();\n+\n+    \/\/ All registered DCmds are always enabled. We set the dcmdInfo::enabled\n+    \/\/ field to true to be compatible with the Java API\n+    \/\/ com.sun.management.internal.DiagnosticCommandInfo.\n+    infoArray[i].enabled = true;\n","filename":"src\/hotspot\/share\/services\/management.cpp","additions":27,"deletions":4,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -28,1 +28,0 @@\n-#include \"utilities\/xmlstream.hpp\"\n@@ -30,0 +29,1 @@\n+#include \"utilities\/xmlstream.hpp\"\n","filename":"src\/hotspot\/share\/utilities\/defaultStream.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -459,1 +459,1 @@\n-#if defined(IA32) || defined(AMD64)\n+#if defined(AMD64)\n@@ -469,8 +469,0 @@\n-#ifdef IA32\n-#define IA32_ONLY(code) code\n-#define NOT_IA32(code)\n-#else\n-#define IA32_ONLY(code)\n-#define NOT_IA32(code) code\n-#endif\n-\n@@ -630,1 +622,1 @@\n-#if INCLUDE_CDS && INCLUDE_G1GC && defined(_LP64)\n+#if INCLUDE_CDS && defined(_LP64)\n","filename":"src\/hotspot\/share\/utilities\/macros.hpp","additions":3,"deletions":11,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -999,2 +999,3 @@\n-  delete defaultStream::instance;\n-  xtty = nullptr;\n+  \/\/ Keep xtty usable as long as possible by ensuring we null it out before\n+  \/\/ deleting anything.\n+  defaultStream* ds = defaultStream::instance;\n@@ -1002,0 +1003,3 @@\n+  xtty = nullptr;\n+  OrderAccess::fence(); \/\/ force visibility to concurrently executing threads\n+  delete ds;\n@@ -1084,4 +1088,4 @@\n-#include <sys\/types.h>\n-#include <sys\/socket.h>\n-#include <netinet\/in.h>\n-#include <netdb.h>\n+#include <netdb.h>\n+#include <netinet\/in.h>\n+#include <sys\/socket.h>\n+#include <sys\/types.h>\n","filename":"src\/hotspot\/share\/utilities\/ostream.cpp","additions":10,"deletions":6,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -168,0 +168,14 @@\n+\n+   \/\/ Append strings returned by gen, separating each with separator.\n+   \/\/ Stops when gen returns null.\n+   template <typename Generator>\n+   void join(Generator gen, const char* separator) {\n+     bool first = true;\n+     const char* str = gen();\n+     while (str != nullptr) {\n+       const char* sep = first ? \"\" : separator;\n+       print(\"%s%s\", sep, str);\n+       first = false;\n+       str = gen();\n+     }\n+   }\n@@ -185,1 +199,1 @@\n-  StreamIndentor(outputStream* os, int indentation) :\n+  StreamIndentor(outputStream* os, int indentation = 2) :\n","filename":"src\/hotspot\/share\/utilities\/ostream.hpp","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"runtime\/os.hpp\"\n","filename":"src\/hotspot\/share\/utilities\/stringUtils.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2025, Oracle and\/or its affiliates. All rights reserved.\n","filename":"src\/hotspot\/share\/utilities\/stringUtils.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -58,1 +58,1 @@\n-  return Atomic::load_acquire(&_loaded);\n+  return AtomicAccess::load_acquire(&_loaded);\n@@ -117,1 +117,1 @@\n-  Atomic::release_store(&_loaded, true);\n+  AtomicAccess::release_store(&_loaded, true);\n","filename":"src\/hotspot\/share\/utilities\/zipLibrary.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1068,0 +1068,15 @@\n+        if (jfrTracing && FileReadEvent.enabled()) {\n+            long bytesRead = 0;\n+            long start = FileReadEvent.timestamp();\n+            try {\n+                String result = implReadLine();\n+                bytesRead = result == null ? 0 : result.length();\n+                return result;\n+            } finally {\n+                FileReadEvent.offer(start, path, bytesRead);\n+            }\n+        }\n+        return implReadLine();\n+    }\n+\n+    private final String implReadLine() throws IOException {\n@@ -1073,1 +1088,1 @@\n-            switch (c = read()) {\n+            switch (c = read0()) {\n@@ -1078,1 +1093,1 @@\n-                    if ((read()) != '\\n') {\n+                    if ((read0()) != '\\n') {\n","filename":"src\/java.base\/share\/classes\/java\/io\/RandomAccessFile.java","additions":17,"deletions":2,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1995, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1995, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -51,1 +51,1 @@\n- * ProcessBuilder.start and Runtime.exec.\n+ * {@code ProcessBuilder.start} and {@code Runtime.exec}.\n@@ -88,4 +88,0 @@\n- * <p>The process is not killed when there are no more references to\n- * the {@code Process} object, but rather the process\n- * continues executing asynchronously.\n- *\n@@ -99,1 +95,23 @@\n- * <p>Subclasses of Process should override the {@link #onExit()} and\n+ * <p>Subclasses of Process should ensure that each overridden method\n+ * invokes the superclass method.\n+ * For example, if {@linkplain #close() close} is overridden, the subclass should\n+ * ensure that {@code Process.close()} is called.\n+ * {@snippet lang = \"java\" :\n+ * public class LoggingProcess extends java.lang.Process {\n+ *     ...\n+ *     @Override\n+ *     public void close() throws IOException  {\n+ *         try {\n+ *             super.close();\n+ *         } catch (IOException ex) {\n+ *             LOGGER.log(ex);\n+*          } finally {\n+ *             LOGGER.log(\"process closed\");\n+ *         }\n+ *     }\n+ *     ...\n+ * }\n+ * }\n+ *\n+ * <p>Subclasses of Process that wrap another Process instance\n+ * should override and delegate the {@link #onExit()} and\n@@ -108,0 +126,45 @@\n+ * <h2>Resource Usage<\/h2>\n+ * {@linkplain ProcessBuilder#start() Starting a process} uses resources in both the invoking process and the invoked\n+ * process and for the communication streams between them.\n+ * The resources to control the process and for communication between the processes are retained\n+ * until there are no longer any references to the Process or the input, error, and output streams\n+ * or readers, or they have been closed. The Process {@linkplain Process#close close} method closes\n+ * all the streams and terminates the process to release the resources. Using try-with-resources\n+ * will ensure the process is terminated when the try-with-resources block exits.\n+ *\n+ * <p>The process is not killed when there are no more references to the {@code Process} object,\n+ * but rather the process continues executing asynchronously.\n+ * The process implementation closes file descriptors and handles for streams\n+ * that are no longer referenced to prevent leaking operating system resources.\n+ * Processes that have terminated or been terminated are monitored and their resources released.\n+ *\n+ * <p>Streams should be closed when they are no longer needed, to avoid delaying\n+ * releasing the operating system resources.\n+ * {@code Try-with-resources} can be used to open and close the streams.\n+ * <p>For example, to capture the output of a program known to produce some output and then exit:\n+ * {@snippet lang = \"java\" :\n+ * List<String> capture(List<String> args) throws Exception {\n+ *     ProcessBuilder pb = new ProcessBuilder(args);\n+ *     try (Process process = pb.start();\n+ *          BufferedReader in = process.inputReader()) {\n+ *         List<String> captured = in.readAllLines();\n+ *         int status = process.waitFor();\n+ *         if (status != 0) {\n+ *             throw new RuntimeException(\"Process %d: %s failed with %d\"\n+ *                         .formatted(process.pid(), args, status));\n+ *         }\n+ *         return captured;\n+ *     }\n+ * }\n+ * }\n+ * <p>Stream resources (file descriptor or handle) are always paired; one in the invoking process\n+ * and the other end of that connection in the invoked process.\n+ * Closing a stream at either end terminates communication but does not have any direct effect\n+ * on the other Process. The closing of the stream typically results in the other process exiting.\n+ *\n+ * <p> {@linkplain #destroy Destroying a process} signals the operating system to terminate the process.\n+ * It is up to the operating system to clean up and release the resources of that process.\n+ * Typically, file descriptors and handles are closed. When they are closed, any connections to\n+ * other processes are terminated and file descriptors and handles in the invoking process signal\n+ * end-of-file or closed. Usually, that is seen as an end-of-file or an exception.\n+ *\n@@ -110,1 +173,1 @@\n-public abstract class Process {\n+public abstract class Process implements Closeable {\n@@ -120,0 +183,1 @@\n+    private boolean closed;     \/\/ true if close() has been called\n@@ -126,0 +190,103 @@\n+    \/**\n+     * Closes all reader and writer streams and waits for the process to terminate.\n+     * This method is idempotent, if this {@code Process} has already been closed\n+     * invoking this method has no effect.\n+     * <p>\n+     * If the data from the process input or error streams is needed, it must be read before\n+     * calling this method. The contents of streams that have not been read to end of stream\n+     * are lost, they are discarded or ignored.\n+     * <p>\n+     * If the process exit value is of interest, then the caller must\n+     * {@linkplain #waitFor() wait for} the process to terminate before calling this method.\n+     * <p>\n+     * Streams should be closed when no longer needed.\n+     * Closing an already closed stream usually has no effect but is specific to the stream.\n+     * If an {@code IOException} occurs when closing a stream it is thrown\n+     * after the process has terminated.\n+     * Exceptions thrown by closing the streams, if any, are added to the first\n+     * {@code IOException} as {@linkplain IOException#addSuppressed suppressed exceptions}.\n+     * <p>\n+     * After the streams are closed this method {@linkplain #waitFor() waits for} the\n+     * process to terminate. If {@linkplain Thread#interrupt interrupted} while waiting\n+     * the process is {@linkplain #destroyForcibly() forcibly destroyed} and\n+     * this method continues to wait for the process to terminate.\n+     * The interrupted status is re-asserted before this method returns or\n+     * any {@code IOExceptions} are thrown.\n+     * @apiNote\n+     * Try-with-resources example to write text to a process, read back the\n+     * response, and close the streams and process:\n+     * {@snippet file=\"ProcessExamples.java\" region=example}\n+     *\n+     * @implNote\n+     * Concrete implementations that override this class are strongly encouraged to\n+     * override this method and invoke the superclass {@code close} method.\n+     *\n+     * @implSpec\n+     * This method closes the process I\/O streams and then\n+     * {@linkplain #waitFor() waits for} the process to terminate.\n+     * If {@link #waitFor() waitFor()} is {@linkplain Thread#interrupt() interrupted}\n+     * the process is {@linkplain #destroyForcibly() forcibly destroyed}\n+     * and then {@code close()} waits for the process to terminate.\n+     * @throws IOException if closing any of the streams throws an exception\n+     * @since 26\n+     *\/\n+    @Override\n+    public void close() throws IOException {\n+        synchronized(this) {\n+            if (closed) {\n+                return;\n+            }\n+            closed = true;\n+            \/\/ Close each stream\n+            IOException ioe = quietClose(outputWriter != null ? outputWriter : getOutputStream(), null);\n+            ioe = quietClose(inputReader != null ? inputReader : getInputStream(), ioe);\n+            ioe = quietClose(errorReader != null ? errorReader : getErrorStream(), ioe);\n+\n+            \/\/ Wait for the process to terminate\n+            \/\/ If waitFor is interrupted, destroy the process\n+            \/\/ Continue waiting indefinitely for the process to terminate\n+            if (!tryWait()) {\n+                destroyForcibly();\n+                while (!tryWait()) {\n+                    continue;\n+                }\n+                \/\/ Re-assert the interrupted status\n+                Thread.currentThread().interrupt();\n+            }\n+            if (ioe != null) {\n+                throw ioe;\n+            }\n+        }\n+    }\n+\n+    \/\/ Try to wait for the process to terminate.\n+    \/\/ Return true if the process has terminated, false if wait is interrupted.\n+    private boolean tryWait() {\n+        try {\n+            waitFor();\n+            return true;\n+        } catch (InterruptedException ie) {\n+            return false;\n+        }\n+    }\n+\n+    \/\/ Quietly close.\n+    \/\/ If an IOException occurs, and it is the first, return it.\n+    \/\/ If there is no first IOException, a first IOException is created with the Throwable.\n+    \/\/ Otherwise, add the Throwable as a suppressed exception to the first.\n+    private static IOException quietClose(Closeable c, IOException firstIOE) {\n+        try {\n+            c.close();\n+            return firstIOE;\n+        } catch (Throwable th) {\n+            if (firstIOE == null && th instanceof IOException ioe) {\n+                return ioe;\n+            } else if (firstIOE == null) {\n+                firstIOE = new IOException(th);\n+            } else {\n+                firstIOE.addSuppressed(th);\n+            }\n+            return firstIOE;\n+        }\n+    }\n+\n@@ -137,0 +304,3 @@\n+     * <p>The output stream should be {@linkplain OutputStream#close closed}\n+     * when it is no longer needed.\n+     *\n@@ -169,0 +339,3 @@\n+     * <p>The input stream should be {@linkplain InputStream#close closed}\n+     * when it is no longer needed.\n+     *\n@@ -170,2 +343,5 @@\n-     * Use {@link #getInputStream()} and {@link #inputReader()} with extreme care.\n-     * The {@code BufferedReader} may have buffered input from the input stream.\n+     * Use either this method or an {@linkplain #inputReader() input reader}\n+     * but not both on the same {@code Process}.\n+     * The input reader consumes and buffers bytes from the input stream.\n+     * Bytes read from the input stream would not be seen by the reader and\n+     * buffer contents are unpredictable.\n@@ -195,0 +371,3 @@\n+     * <p>The error stream should be {@linkplain InputStream#close closed}\n+     * when it is no longer needed.\n+     *\n@@ -196,2 +375,5 @@\n-     * Use {@link #getErrorStream()} and {@link #errorReader()} with extreme care.\n-     * The {@code BufferedReader} may have buffered input from the error stream.\n+     * Use either this method or an {@linkplain #errorReader() error reader}\n+     * but not both on the same {@code Process}.\n+     * The error reader consumes and buffers bytes from the error stream.\n+     * Bytes read from the error stream would not be seen by the reader and the\n+     * buffer contents are unpredictable.\n@@ -218,0 +400,10 @@\n+     * <p>The reader should be {@linkplain BufferedReader#close closed}\n+     * when it is no longer needed.\n+     *\n+     * @apiNote\n+     * Use either this method or the {@linkplain #getInputStream input stream}\n+     * but not both on the same {@code Process}.\n+     * The input reader consumes and buffers bytes from the input stream.\n+     * Bytes read from the input stream would not be seen by the reader and the\n+     * buffer contents are unpredictable.\n+     *\n@@ -248,0 +440,3 @@\n+     * <p>The reader should be {@linkplain BufferedReader#close closed}\n+     * when it is no longer needed.\n+     *\n@@ -255,3 +450,5 @@\n-     * Using both {@link #getInputStream} and {@link #inputReader(Charset)} has\n-     * unpredictable behavior since the buffered reader reads ahead from the\n-     * input stream.\n+     * Use either this method or the {@linkplain #getInputStream input stream}\n+     * but not both on the same {@code Process}.\n+     * The input reader consumes and buffers bytes from the input stream.\n+     * Bytes read from the input stream would not be seen by the reader and the\n+     * buffer contents are unpredictable.\n@@ -293,0 +490,10 @@\n+     * <p>The error reader should be {@linkplain BufferedReader#close closed}\n+     * when it is no longer needed.\n+     *\n+     * @apiNote\n+     * Use either this method or the {@linkplain #getErrorStream error stream}\n+     * but not both on the same {@code Process}.\n+     * The error reader consumes and buffers bytes from the error stream.\n+     * Bytes read from the error stream would not be seen by the reader and the\n+     * buffer contents are unpredictable.\n+     *\n@@ -324,0 +531,3 @@\n+     * <p>The error reader should be {@linkplain BufferedReader#close closed}\n+     * when it is no longer needed.\n+     *\n@@ -325,3 +535,5 @@\n-     * Using both {@link #getErrorStream} and {@link #errorReader(Charset)} has\n-     * unpredictable behavior since the buffered reader reads ahead from the\n-     * error stream.\n+     * Use either this method or the {@linkplain #getErrorStream error stream}\n+     * but not both on the same {@code Process}.\n+     * The error reader consumes and buffers bytes from the error stream.\n+     * Bytes read from the error stream would not be seen by the reader and the\n+     * buffer contents are unpredictable.\n@@ -356,1 +568,1 @@\n-     * Writes text to a character-output stream, buffering characters so as to provide\n+     * Writes text to a character-output stream, buffering characters to provide\n@@ -364,0 +576,3 @@\n+     * <p>The output writer should be {@linkplain BufferedWriter#close closed}\n+     * when it is no longer needed.\n+     *\n@@ -375,1 +590,1 @@\n-     * Writes text to a character-output stream, buffering characters so as to provide\n+     * Writes text to a character-output stream, buffering characters to provide\n@@ -393,0 +608,3 @@\n+     * <p>The output writer should be {@linkplain BufferedWriter#close closed}\n+     * when it is no longer needed.\n+     *\n@@ -684,5 +902,6 @@\n-     * <pre> {@code   Process p = new ProcessBuilder(\"cmp\", \"f1\", \"f2\").start();\n-     *    Future<Boolean> identical = p.onExit().thenApply(p1 -> p1.exitValue() == 0);\n-     *    ...\n-     *    if (identical.get()) { ... }\n-     * }<\/pre>\n+     * {@snippet lang = \"java\" :\n+     *     Process p = new ProcessBuilder(\"cmp\", \"f1\", \"f2\").start();\n+     *     Future<Boolean> identical = p.onExit().thenApply(p1 -> p1.exitValue() == 0);\n+     *     ...\n+     *     if (identical.get()) { ... }\n+     * }\n@@ -693,1 +912,1 @@\n-     * {@code waitFor} is interrupted, the thread's interrupt status is preserved.\n+     * {@code waitFor} is interrupted, the thread's interrupted status is preserved.\n@@ -705,1 +924,1 @@\n-     * <pre>{@code\n+     * {@snippet lang = \"java\" :\n@@ -709,1 +928,1 @@\n-     * }<\/pre>\n+     * }\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Process.java","additions":247,"deletions":28,"binary":false,"changes":275,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -161,1 +161,2 @@\n- * <pre> {@code\n+ * {@snippet lang = \"java\" :\n+\n@@ -163,1 +164,2 @@\n- * }<\/pre>\n+ * }\n+\n@@ -169,16 +171,17 @@\n- * <pre> {@code\n- * ProcessBuilder pb =\n- *   new ProcessBuilder(\"myCommand\", \"myArg1\", \"myArg2\");\n- * Map<String, String> env = pb.environment();\n- * env.put(\"VAR1\", \"myValue\");\n- * env.remove(\"OTHERVAR\");\n- * env.put(\"VAR2\", env.get(\"VAR1\") + \"suffix\");\n- * pb.directory(new File(\"myDir\"));\n- * File log = new File(\"log\");\n- * pb.redirectErrorStream(true);\n- * pb.redirectOutput(Redirect.appendTo(log));\n- * Process p = pb.start();\n- * assert pb.redirectInput() == Redirect.PIPE;\n- * assert pb.redirectOutput().file() == log;\n- * assert p.getInputStream().read() == -1;\n- * }<\/pre>\n+ * {@snippet lang = \"java\":\n+ *     ProcessBuilder pb = new ProcessBuilder(\"myCommand\", \"myArg1\", \"myArg2\");\n+ *     Map<String, String> env = pb.environment();\n+ *     env.put(\"VAR1\", \"myValue\");\n+ *     env.remove(\"OTHERVAR\");\n+ *     env.put(\"VAR2\", env.get(\"VAR1\") + \"suffix\");\n+ *\n+ *     pb.directory(new File(\"myDir\"));\n+ *     File log = new File(\"log\");\n+ *     pb.redirectErrorStream(true);\n+ *     pb.redirectOutput(Redirect.appendTo(log));\n+ *\n+ *     Process p = pb.start();\n+ *     assert pb.redirectInput() == Redirect.PIPE;\n+ *     assert pb.redirectOutput().file() == log;\n+ *     assert p.getInputStream().read() == -1;\n+ * }\n@@ -517,4 +520,4 @@\n-         *  <pre> {@code\n-         * Redirect.PIPE.file() == null &&\n-         * Redirect.PIPE.type() == Redirect.Type.PIPE\n-         * }<\/pre>\n+         * {@snippet lang = \"java\" :\n+         *     Redirect.PIPE.file() == null &&\n+         *     Redirect.PIPE.type() == Redirect.Type.PIPE\n+         * }\n@@ -532,4 +535,4 @@\n-         *  <pre> {@code\n-         * Redirect.INHERIT.file() == null &&\n-         * Redirect.INHERIT.type() == Redirect.Type.INHERIT\n-         * }<\/pre>\n+         * {@snippet lang = \"java\" :\n+         *     Redirect.INHERIT.file() == null &&\n+         *     Redirect.INHERIT.type() == Redirect.Type.INHERIT\n+         * }\n@@ -548,5 +551,4 @@\n-         * <pre> {@code\n-         * Redirect.DISCARD.file() is the filename appropriate for the operating system\n-         * and may be null &&\n-         * Redirect.DISCARD.type() == Redirect.Type.WRITE\n-         * }<\/pre>\n+         * {@snippet lang = \"java\" :\n+         *     Redirect.DISCARD.file() != null && \/\/ is the filename appropriate for the operating system\n+         *     Redirect.DISCARD.type() == Redirect.Type.WRITE;\n+         * }\n@@ -583,4 +585,4 @@\n-         *  <pre> {@code\n-         * Redirect.from(file).file() == file &&\n-         * Redirect.from(file).type() == Redirect.Type.READ\n-         * }<\/pre>\n+         * {@snippet lang = \"java\" :\n+         *     Redirect.from(file).file() == file &&\n+         *     Redirect.from(file).type() == Redirect.Type.READ\n+         * }\n@@ -609,4 +611,4 @@\n-         *  <pre> {@code\n-         * Redirect.to(file).file() == file &&\n-         * Redirect.to(file).type() == Redirect.Type.WRITE\n-         * }<\/pre>\n+         * {@snippet lang = \"java\" :\n+         *     Redirect.to(file).file() == file &&\n+         *     Redirect.to(file).type() == Redirect.Type.WRITE\n+         * }\n@@ -639,4 +641,4 @@\n-         *  <pre> {@code\n-         * Redirect.appendTo(file).file() == file &&\n-         * Redirect.appendTo(file).type() == Redirect.Type.APPEND\n-         * }<\/pre>\n+         * {@snippet lang = \"java\" :\n+         *     Redirect.appendTo(file).file() == file &&\n+         *     Redirect.appendTo(file).type() == Redirect.Type.APPEND\n+         * }\n@@ -927,3 +929,3 @@\n-     *  <pre> {@code\n-     * pb.inheritIO()\n-     * }<\/pre>\n+     * {@snippet lang = \"java\" :\n+     *      pb.inheritIO()\n+     * }\n@@ -931,5 +933,5 @@\n-     *  <pre> {@code\n-     * pb.redirectInput(Redirect.INHERIT)\n-     *   .redirectOutput(Redirect.INHERIT)\n-     *   .redirectError(Redirect.INHERIT)\n-     * }<\/pre>\n+     * {@snippet lang = \"java\" :\n+     *      pb.redirectInput(Redirect.INHERIT)\n+     *          .redirectOutput(Redirect.INHERIT)\n+     *          .redirectError(Redirect.INHERIT)\n+     * }\n@@ -1189,3 +1191,3 @@\n-     * <pre>{@code\n-     * String directory = \"\/home\/duke\/src\";\n-     * ProcessBuilder[] builders = {\n+     * {@snippet lang = \"java\" :\n+     *     String directory = \"\/home\/duke\/src\";\n+     *     ProcessBuilder[] builders = {\n@@ -1196,4 +1198,3 @@\n-     * List<Process> processes = ProcessBuilder.startPipeline(\n-     *         Arrays.asList(builders));\n-     * Process last = processes.get(processes.size()-1);\n-     * try (InputStream is = last.getInputStream();\n+     *     List<Process> processes = ProcessBuilder.startPipeline( Arrays.asList(builders));\n+     *     Process last = processes.get(processes.size() - 1);\n+     *     try (InputStream is = last.getInputStream();\n@@ -1202,1 +1203,2 @@\n-     *     long count = r.lines().count();\n+     *         long count = r.lines().count();\n+     *     }\n@@ -1204,1 +1206,0 @@\n-     * }<\/pre>\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ProcessBuilder.java","additions":62,"deletions":61,"binary":false,"changes":123,"status":"modified"},{"patch":"@@ -241,1 +241,1 @@\n-     * Returns the unique {@link java.io.Console Console} object associated\n+     * Returns the unique {@link Console Console} object associated\n@@ -245,0 +245,1 @@\n+     * @see Console\n@@ -2057,0 +2058,3 @@\n+            public int getClassFileAccessFlags(Class<?> klass) {\n+                return klass.getClassFileAccessFlags();\n+            }\n@@ -2128,2 +2132,2 @@\n-            public Module addEnableNativeAccess(Module m) {\n-                return m.implAddEnableNativeAccess();\n+            public void addEnableNativeAccess(Module m) {\n+                m.implAddEnableNativeAccess();\n@@ -2135,1 +2139,1 @@\n-                Module.implAddEnableNativeAccessToAllUnnamed();\n+                Module.addEnableNativeAccessToAllUnnamed();\n@@ -2140,0 +2144,15 @@\n+            public boolean isStaticallyExported(Module m, String pn, Module other) {\n+                return m.isStaticallyExported(pn, other);\n+            }\n+            public boolean isStaticallyOpened(Module m, String pn, Module other) {\n+                return m.isStaticallyOpened(pn, other);\n+            }\n+            public boolean isFinalMutationEnabled(Module m) {\n+                return m.isFinalMutationEnabled();\n+            }\n+            public boolean tryEnableFinalMutation(Module m) {\n+                return m.tryEnableFinalMutation();\n+            }\n+            public void addEnableFinalMutationToAllUnnamed() {\n+                Module.addEnableFinalMutationToAllUnnamed();\n+            }\n@@ -2153,1 +2172,1 @@\n-            public int uncheckedCountPositives(byte[] bytes, int offset, int length) {\n+            public int countPositives(byte[] bytes, int offset, int length) {\n@@ -2156,0 +2175,1 @@\n+\n@@ -2159,2 +2179,7 @@\n-            public String uncheckedNewStringNoRepl(byte[] bytes, Charset cs) throws CharacterCodingException  {\n-                return String.newStringNoRepl(bytes, cs);\n+\n+            public String uncheckedNewStringWithLatin1Bytes(byte[] bytes) {\n+                return String.newStringWithLatin1Bytes(bytes);\n+            }\n+\n+            public String uncheckedNewStringOrThrow(byte[] bytes, Charset cs) throws CharacterCodingException  {\n+                return String.newStringOrThrow(bytes, cs);\n@@ -2162,0 +2187,1 @@\n+\n@@ -2165,0 +2191,1 @@\n+\n@@ -2168,5 +2195,2 @@\n-            public byte[] uncheckedGetBytesNoRepl(String s, Charset cs) throws CharacterCodingException {\n-                return String.getBytesNoRepl(s, cs);\n-            }\n-            public String newStringUTF8NoRepl(byte[] bytes, int off, int len) {\n-                return String.newStringUTF8NoRepl(bytes, off, len, true);\n+            public byte[] uncheckedGetBytesOrThrow(String s, Charset cs) throws CharacterCodingException {\n+                return String.getBytesOrThrow(s, cs);\n@@ -2176,2 +2200,2 @@\n-            public byte[] getBytesUTF8NoRepl(String s) {\n-                return String.getBytesUTF8NoRepl(s);\n+            public byte[] getBytesUTF8OrThrow(String s) throws CharacterCodingException {\n+                return String.getBytesUTF8OrThrow(s);\n@@ -2180,1 +2204,1 @@\n-            public void uncheckedInflateBytesToChars(byte[] src, int srcOff, char[] dst, int dstOff, int len) {\n+            public void inflateBytesToChars(byte[] src, int srcOff, char[] dst, int dstOff, int len) {\n@@ -2184,1 +2208,1 @@\n-            public int uncheckedDecodeASCII(byte[] src, int srcOff, char[] dst, int dstOff, int len) {\n+            public int decodeASCII(byte[] src, int srcOff, char[] dst, int dstOff, int len) {\n@@ -2212,12 +2236,0 @@\n-            public long stringConcatInitialCoder() {\n-                return StringConcatHelper.initialCoder();\n-            }\n-\n-            public long stringConcatMix(long lengthCoder, String constant) {\n-                return StringConcatHelper.mix(lengthCoder, constant);\n-            }\n-\n-            public long stringConcatMix(long lengthCoder, char value) {\n-                return StringConcatHelper.mix(lengthCoder, value);\n-            }\n-\n@@ -2354,2 +2366,2 @@\n-            public void copyToSegmentRaw(String string, MemorySegment segment, long offset) {\n-                string.copyToSegmentRaw(segment, offset);\n+            public void copyToSegmentRaw(String string, MemorySegment segment, long offset, int srcIndex, int srcLength) {\n+                string.copyToSegmentRaw(segment, offset, srcIndex, srcLength);\n@@ -2359,2 +2371,2 @@\n-            public boolean bytesCompatible(String string, Charset charset) {\n-                return string.bytesCompatible(charset);\n+            public boolean bytesCompatible(String string, Charset charset, int srcIndex, int numChars) {\n+                return string.bytesCompatible(charset, srcIndex, numChars);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/System.java","additions":44,"deletions":32,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2025, Oracle and\/or its affiliates. All rights reserved.\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/Cleaner.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -32,1 +32,1 @@\n-import jdk.internal.misc.Unsafe;\n+import jdk.internal.vm.annotation.AOTSafeClassInitializer;\n@@ -37,1 +37,0 @@\n-import jdk.internal.ref.Cleaner;\n@@ -50,1 +49,1 @@\n-\n+@AOTSafeClassInitializer\n@@ -206,5 +205,0 @@\n-            \/\/ pre-load and initialize Cleaner class so that we don't\n-            \/\/ get into trouble later in the run loop if there's\n-            \/\/ memory shortage while loading\/initializing it lazily.\n-            Unsafe.getUnsafe().ensureClassInitialized(Cleaner.class);\n-\n@@ -260,12 +254,1 @@\n-\n-            if (ref instanceof Cleaner) {\n-                ((Cleaner)ref).clean();\n-                \/\/ Notify any waiters that progress has been made.\n-                \/\/ This improves latency for nio.Bits waiters, which\n-                \/\/ are the only important ones.\n-                synchronized (processPendingLock) {\n-                    processPendingLock.notifyAll();\n-                }\n-            } else {\n-                ref.enqueueFromPending();\n-            }\n+            ref.enqueueFromPending();\n@@ -314,5 +297,0 @@\n-        runtimeSetup();\n-    }\n-\n-    \/\/ Also called from JVM when loading an AOT cache\n-    private static void runtimeSetup() {\n@@ -374,2 +352,1 @@\n-    @IntrinsicCandidate\n-        return this.referent;\n+        return get0();\n@@ -379,0 +356,8 @@\n+    \/* Implementation of get().  This method exists to avoid making get() all\n+     * of virtual, native, and intrinsic candidate. That could have the\n+     * undesirable effect of having the native method used instead of the\n+     * intrinsic when devirtualization fails.\n+     *\/\n+    @IntrinsicCandidate\n+    private native T get0();\n+\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/Reference.java","additions":12,"deletions":27,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1996, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1996, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -196,24 +196,0 @@\n-    \/**\n-     * Set the TTL (time-to-live) option.\n-     * @param ttl a byte specifying the TTL value\n-     *\n-     * @deprecated use setTimeToLive instead.\n-     * @throws    IOException if an I\/O exception occurs while setting\n-     * the time-to-live option.\n-     * @see #getTTL()\n-     *\/\n-    @Deprecated(forRemoval = true, since = \"1.2\")\n-    protected abstract void setTTL(byte ttl) throws IOException;\n-\n-    \/**\n-     * Retrieve the TTL (time-to-live) option.\n-     *\n-     * @throws    IOException if an I\/O exception occurs\n-     * while retrieving the time-to-live option\n-     * @deprecated use getTimeToLive instead.\n-     * @return a byte representing the TTL value\n-     * @see #setTTL(byte)\n-     *\/\n-    @Deprecated(forRemoval = true, since = \"1.2\")\n-    protected abstract byte getTTL() throws IOException;\n-\n","filename":"src\/java.base\/share\/classes\/java\/net\/DatagramSocketImpl.java","additions":1,"deletions":25,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -577,1 +577,2 @@\n-     *        {@link ClosedByInterruptException} with the interrupt status set.\n+     *        {@link ClosedByInterruptException} with the thread's interrupted\n+     *        status set.\n@@ -582,1 +583,1 @@\n-     *        {@code SocketException} with the interrupt status set.\n+     *        {@code SocketException} with the thread's interrupted status set.\n@@ -617,1 +618,2 @@\n-     *        {@link ClosedByInterruptException} with the interrupt status set.\n+     *        {@link ClosedByInterruptException} with the thread's interrupted\n+     *        status set.\n@@ -622,1 +624,1 @@\n-     *        {@code SocketException} with the interrupt status set.\n+     *        {@code SocketException} with the thread's interrupted status set.\n@@ -625,0 +627,7 @@\n+     * @apiNote Establishing a TCP\/IP connection is subject to connect timeout settings\n+     * in the operating system. The typical operating system timeout is in the range of tens of\n+     * seconds to minutes. If the operating system timeout expires before the\n+     * {@code timeout} specified to this method then an {@code IOException} is thrown.\n+     * The {@code timeout} specified to this method is typically a timeout value that is\n+     * shorter than the operating system timeout.\n+     *\n@@ -883,2 +892,2 @@\n-     *        throw {@link ClosedByInterruptException} with the interrupt\n-     *        status set.\n+     *        throw {@link ClosedByInterruptException} with the thread's\n+     *        interrupted status set.\n@@ -889,1 +898,2 @@\n-     *        throw {@code SocketException} with the interrupt status set.\n+     *        throw {@code SocketException} with the thread's interrupted\n+     *        status set.\n@@ -1023,2 +1033,2 @@\n-     *        throw {@link ClosedByInterruptException} with the interrupt status\n-     *        set.\n+     *        throw {@link ClosedByInterruptException} with the thread's\n+     *        interrupted status set.\n@@ -1029,1 +1039,2 @@\n-     *        throw {@code SocketException} with the interrupt status set.\n+     *        throw {@code SocketException} with the thread's interrupted\n+     *        status set.\n@@ -1846,0 +1857,3 @@\n+     *\n+     * @deprecated This method was intended to allow for protocols that are now\n+     *             obsolete.\n@@ -1847,0 +1861,1 @@\n+    @Deprecated(since = \"26\", forRemoval = true)\n","filename":"src\/java.base\/share\/classes\/java\/net\/Socket.java","additions":25,"deletions":10,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -406,0 +406,3 @@\n+     *\n+     * @deprecated This method was intended to allow for protocols that are now\n+     *             obsolete.\n@@ -407,0 +410,1 @@\n+    @Deprecated(since = \"26\", forRemoval = true)\n","filename":"src\/java.base\/share\/classes\/java\/net\/SocketImpl.java","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+import jdk.internal.util.ByteArray;\n@@ -860,0 +861,10 @@\n+    \/**\n+     * {@inheritDoc}\n+     *\/\n+    @Override\n+    public long nextLong() {\n+        byte[] b = new byte[8];\n+        nextBytes(b); \/\/ Calls engineNextBytes internally\n+        return ByteArray.getLong(b, 0);\n+    }\n+\n","filename":"src\/java.base\/share\/classes\/java\/security\/SecureRandom.java","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -43,4 +43,6 @@\n- * and return a task object that can be used to cancel or check\n- * execution. The {@code scheduleAtFixedRate} and\n- * {@code scheduleWithFixedDelay} methods create and execute tasks\n- * that run periodically until cancelled.\n+ * and return {@link ScheduledFuture} objects that can be used to cancel or check\n+ * execution. When delays elapse, tasks are enabled for execution and\n+ * behave in accord with other {@link ExecutorService} tasks, except\n+ * that {@code scheduleAtFixedRate} and {@code scheduleWithFixedDelay}\n+ * methods create and execute tasks that run periodically until\n+ * cancelled.\n@@ -94,1 +96,1 @@\n-     * Submits a one-shot task that becomes enabled after the given delay.\n+     * Submits a one-shot task that becomes enabled for execution after the given delay.\n@@ -110,1 +112,1 @@\n-     * Submits a value-returning one-shot task that becomes enabled\n+     * Submits a value-returning one-shot task that becomes enabled for execution\n@@ -126,1 +128,1 @@\n-     * Submits a periodic action that becomes enabled first after the\n+     * Submits a periodic action that becomes enabled for execution first after the\n@@ -175,1 +177,1 @@\n-     * Submits a periodic action that becomes enabled first after the\n+     * Submits a periodic action that becomes enabled for execution first after the\n","filename":"src\/java.base\/share\/classes\/java\/util\/concurrent\/ScheduledExecutorService.java","additions":10,"deletions":8,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -346,1 +346,1 @@\n-            in = new ZipFileInputStream(zsrc.cen, pos);\n+            in = new ZipFileInputStream(zsrc.cen, pos, entry.locOffset);\n@@ -658,0 +658,1 @@\n+        e.locOffset = CENOFF(cen, pos);\n@@ -860,1 +861,8 @@\n-        ZipFileInputStream(byte[] cen, int cenpos) {\n+        \/**\n+         * @param cen       the ZIP's CEN\n+         * @param cenpos    the entry's offset within the CEN\n+         * @param locOffset the entry's LOC offset in the ZIP stream. If -1 is passed\n+         *                  then the LOC offset for the entry will be read from the\n+         *                  entry's central header\n+         *\/\n+        ZipFileInputStream(byte[] cen, int cenpos, long locOffset) {\n@@ -863,1 +871,5 @@\n-            pos = CENOFF(cen, cenpos);\n+            if (locOffset == -1) {\n+                pos = CENOFF(cen, cenpos);\n+            } else {\n+                pos = locOffset;\n+            }\n","filename":"src\/java.base\/share\/classes\/java\/util\/zip\/ZipFile.java","additions":15,"deletions":3,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -28,0 +28,3 @@\n+import jdk.internal.vm.annotation.AOTSafeClassInitializer;\n+import jdk.internal.vm.annotation.Stable;\n+\n@@ -59,0 +62,12 @@\n+ *\n+ * <p> Notes on the @AOTSafeClassInitializer annotation:\n+ *\n+ * <p>All static fields in SharedSecrets that are initialized in the AOT\n+ * assembly phase must be stateless (as checked by the HotSpot C++ class\n+ * CDSHeapVerifier::SharedSecretsAccessorFinder) so they can be safely\n+ * stored in the AOT cache.\n+ *\n+ * <p>Static fields such as javaObjectInputFilterAccess point to a Lambda\n+ * which is not stateless. The AOT assembly phase must not execute any Java\n+ * code that would lead to the initialization of such fields, or else the AOT\n+ * cache creation will fail.\n@@ -60,1 +75,1 @@\n-\n+@AOTSafeClassInitializer\n@@ -62,1 +77,1 @@\n-    private static JavaAWTAccess javaAWTAccess;\n+    \/\/ This field is not necessarily stable\n@@ -64,31 +79,31 @@\n-    private static JavaBeansAccess javaBeansAccess;\n-    private static JavaLangAccess javaLangAccess;\n-    private static JavaLangInvokeAccess javaLangInvokeAccess;\n-    private static JavaLangModuleAccess javaLangModuleAccess;\n-    private static JavaLangRefAccess javaLangRefAccess;\n-    private static JavaLangReflectAccess javaLangReflectAccess;\n-    private static JavaIOAccess javaIOAccess;\n-    private static JavaIOFileDescriptorAccess javaIOFileDescriptorAccess;\n-    private static JavaIORandomAccessFileAccess javaIORandomAccessFileAccess;\n-    private static JavaObjectInputStreamReadString javaObjectInputStreamReadString;\n-    private static JavaObjectInputStreamAccess javaObjectInputStreamAccess;\n-    private static JavaObjectInputFilterAccess javaObjectInputFilterAccess;\n-    private static JavaObjectStreamReflectionAccess javaObjectStreamReflectionAccess;\n-    private static JavaNetInetAddressAccess javaNetInetAddressAccess;\n-    private static JavaNetHttpCookieAccess javaNetHttpCookieAccess;\n-    private static JavaNetUriAccess javaNetUriAccess;\n-    private static JavaNetURLAccess javaNetURLAccess;\n-    private static JavaNioAccess javaNioAccess;\n-    private static JavaNioChannelsSpiAccess javaNioChannelsSpiAccess;\n-    private static JavaUtilCollectionAccess javaUtilCollectionAccess;\n-    private static JavaUtilConcurrentTLRAccess javaUtilConcurrentTLRAccess;\n-    private static JavaUtilConcurrentFJPAccess javaUtilConcurrentFJPAccess;\n-    private static JavaUtilJarAccess javaUtilJarAccess;\n-    private static JavaUtilZipFileAccess javaUtilZipFileAccess;\n-    private static JavaUtilResourceBundleAccess javaUtilResourceBundleAccess;\n-    private static JavaSecurityPropertiesAccess javaSecurityPropertiesAccess;\n-    private static JavaSecuritySignatureAccess javaSecuritySignatureAccess;\n-    private static JavaSecuritySpecAccess javaSecuritySpecAccess;\n-    private static JavaxCryptoSealedObjectAccess javaxCryptoSealedObjectAccess;\n-    private static JavaxCryptoSpecAccess javaxCryptoSpecAccess;\n-    private static JavaxSecurityAccess javaxSecurityAccess;\n+    @Stable private static JavaBeansAccess javaBeansAccess;\n+    @Stable private static JavaLangAccess javaLangAccess;\n+    @Stable private static JavaLangInvokeAccess javaLangInvokeAccess;\n+    @Stable private static JavaLangModuleAccess javaLangModuleAccess;\n+    @Stable private static JavaLangRefAccess javaLangRefAccess;\n+    @Stable private static JavaLangReflectAccess javaLangReflectAccess;\n+    @Stable private static JavaIOAccess javaIOAccess;\n+    @Stable private static JavaIOFileDescriptorAccess javaIOFileDescriptorAccess;\n+    @Stable private static JavaIORandomAccessFileAccess javaIORandomAccessFileAccess;\n+    @Stable private static JavaObjectInputStreamReadString javaObjectInputStreamReadString;\n+    @Stable private static JavaObjectInputStreamAccess javaObjectInputStreamAccess;\n+    @Stable private static JavaObjectInputFilterAccess javaObjectInputFilterAccess;\n+    @Stable private static JavaObjectStreamReflectionAccess javaObjectStreamReflectionAccess;\n+    @Stable private static JavaNetInetAddressAccess javaNetInetAddressAccess;\n+    @Stable private static JavaNetHttpCookieAccess javaNetHttpCookieAccess;\n+    @Stable private static JavaNetUriAccess javaNetUriAccess;\n+    @Stable private static JavaNetURLAccess javaNetURLAccess;\n+    @Stable private static JavaNioAccess javaNioAccess;\n+    @Stable private static JavaNioChannelsSpiAccess javaNioChannelsSpiAccess;\n+    @Stable private static JavaUtilCollectionAccess javaUtilCollectionAccess;\n+    @Stable private static JavaUtilConcurrentTLRAccess javaUtilConcurrentTLRAccess;\n+    @Stable private static JavaUtilConcurrentFJPAccess javaUtilConcurrentFJPAccess;\n+    @Stable private static JavaUtilJarAccess javaUtilJarAccess;\n+    @Stable private static JavaUtilZipFileAccess javaUtilZipFileAccess;\n+    @Stable private static JavaUtilResourceBundleAccess javaUtilResourceBundleAccess;\n+    @Stable private static JavaSecurityPropertiesAccess javaSecurityPropertiesAccess;\n+    @Stable private static JavaSecuritySignatureAccess javaSecuritySignatureAccess;\n+    @Stable private static JavaSecuritySpecAccess javaSecuritySpecAccess;\n+    @Stable private static JavaxCryptoSealedObjectAccess javaxCryptoSealedObjectAccess;\n+    @Stable private static JavaxCryptoSpecAccess javaxCryptoSpecAccess;\n+    @Stable private static JavaxSecurityAccess javaxSecurityAccess;\n@@ -338,10 +353,0 @@\n-    public static void setJavaAWTAccess(JavaAWTAccess jaa) {\n-        javaAWTAccess = jaa;\n-    }\n-\n-    public static JavaAWTAccess getJavaAWTAccess() {\n-        \/\/ this may return null in which case calling code needs to\n-        \/\/ provision for.\n-        return javaAWTAccess;\n-    }\n-\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/access\/SharedSecrets.java","additions":48,"deletions":43,"binary":false,"changes":91,"status":"modified"},{"patch":"@@ -7,0 +7,1 @@\n+import jdk.internal.vm.annotation.Stable;\n@@ -17,1 +18,9 @@\n-    private static final Path[] CLASSPATH_ENTRIES;\n+    \/\/ Non-final to reduce the amount of static initialization. Currently\n+    \/\/ initialization of this class always becomes a part of VM initialization.\n+    \/\/\n+    \/\/ Besides the performance benefit when no C\/R will be performed, we want to\n+    \/\/ keep the static initialization order of the CRaC project closer to the\n+    \/\/ mainline JDK to reduce incompatibilities (the order defines the final\n+    \/\/ result).\n+    @Stable\n+    private static volatile Path[] CLASSPATH_ENTRIES;\n@@ -19,4 +28,14 @@\n-    static {\n-        String[] items = System.getProperty(\"java.class.path\")\n-                .split(File.pathSeparator);\n-        CLASSPATH_ENTRIES = new Path[items.length];\n+    private static Path[] getClasspathEntries() {\n+        if (CLASSPATH_ENTRIES == null) {\n+            synchronized (JDKFileResource.class) {\n+                if (CLASSPATH_ENTRIES == null) {\n+                    CLASSPATH_ENTRIES = createClasspathEntries();\n+                }\n+            }\n+        }\n+        return CLASSPATH_ENTRIES;\n+    }\n+\n+    private static Path[] createClasspathEntries() {\n+        final var items = System.getProperty(\"java.class.path\").split(File.pathSeparator);\n+        final var entries = new Path[items.length];\n@@ -27,1 +46,1 @@\n-                CLASSPATH_ENTRIES[i] = new File(items[i]).toPath();\n+                entries[i] = new File(items[i]).toPath();\n@@ -33,0 +52,1 @@\n+        return entries;\n@@ -58,1 +78,1 @@\n-        for (Path entry : CLASSPATH_ENTRIES) {\n+        for (Path entry : getClasspathEntries()) {\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/crac\/JDKFileResource.java","additions":27,"deletions":7,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2026, Oracle and\/or its affiliates. All rights reserved.\n@@ -340,8 +340,0 @@\n-    public static void releaseByteBuffer(ByteBuffer buffer) {\n-        Objects.requireNonNull(buffer);\n-\n-        if (!MAP_ALL) {\n-            ImageBufferCache.releaseBuffer(buffer);\n-        }\n-    }\n-\n@@ -437,7 +429,6 @@\n-        int[] attributeOffsets = new int[offsets.capacity()];\n-        offsets.get(attributeOffsets);\n-        return IntStream.of(attributeOffsets)\n-                        .filter(o -> o != 0)\n-                        .mapToObj(o -> ImageLocation.readFrom(this, o).getFullName())\n-                        .sorted()\n-                        .toArray(String[]::new);\n+        return IntStream.range(0, offsets.capacity())\n+                .map(offsets::get)\n+                .filter(o -> o != 0)\n+                .mapToObj(o -> ImageLocation.readFrom(this, o).getFullName())\n+                .sorted()\n+                .toArray(String[]::new);\n@@ -483,0 +474,1 @@\n+        int checkedOffset = (int) offset;\n@@ -485,1 +477,1 @@\n-            throw new IndexOutOfBoundsException(\"Bad size: \" + size);\n+            throw new IllegalArgumentException(\"Bad size: \" + size);\n@@ -487,0 +479,1 @@\n+        int checkedSize = (int) size;\n@@ -489,1 +482,1 @@\n-            ByteBuffer buffer = slice(memoryMap, (int)offset, (int)size);\n+            ByteBuffer buffer = slice(memoryMap, checkedOffset, checkedSize);\n@@ -497,2 +490,1 @@\n-\n-            ByteBuffer buffer = ImageBufferCache.getBuffer(size);\n+            ByteBuffer buffer = ByteBuffer.allocate(checkedSize);\n@@ -501,1 +493,1 @@\n-                read = channel.read(buffer, offset);\n+                read = channel.read(buffer, checkedOffset);\n@@ -504,1 +496,0 @@\n-                ImageBufferCache.releaseBuffer(buffer);\n@@ -508,2 +499,1 @@\n-            if (read != size) {\n-                ImageBufferCache.releaseBuffer(buffer);\n+            if (read != checkedSize) {\n@@ -511,1 +501,1 @@\n-                                           \" instead of \" + size + \" bytes\");\n+                        \" instead of \" + checkedSize + \" bytes\");\n@@ -527,9 +517,1 @@\n-\n-        if (buffer != null) {\n-            byte[] bytes = getBufferBytes(buffer);\n-            ImageBufferCache.releaseBuffer(buffer);\n-\n-            return bytes;\n-        }\n-\n-        return null;\n+        return buffer != null ? getBufferBytes(buffer) : null;\n@@ -538,0 +520,3 @@\n+    \/**\n+     * Returns the content of jimage location in a newly allocated byte buffer.\n+     *\/\n@@ -558,1 +543,0 @@\n-\n@@ -561,1 +545,0 @@\n-                ImageBufferCache.releaseBuffer(buffer);\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/jimage\/BasicImageReader.java","additions":19,"deletions":36,"binary":false,"changes":55,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -230,0 +230,1 @@\n+        private volatile boolean closed;\n@@ -296,0 +297,9 @@\n+        \/**\n+         * Throws an IOException if the ModuleReader is closed.\n+         *\/\n+        private void ensureOpen() throws IOException {\n+            if (closed) {\n+                throw new IOException(\"ModuleReader is closed\");\n+            }\n+        }\n+\n@@ -315,1 +325,1 @@\n-\n+            assert !closed : \"module reader is closed\";\n@@ -359,0 +369,1 @@\n+            ensureOpen();\n@@ -370,0 +381,1 @@\n+            ensureOpen();\n@@ -380,0 +392,1 @@\n+            ensureOpen();\n@@ -403,0 +416,1 @@\n+            ensureOpen();\n@@ -412,0 +426,4 @@\n+            if (closed) {\n+                return;\n+            }\n+            closed = true;\n@@ -472,2 +490,4 @@\n-                    byte[] bytes = getInputStream().readAllBytes();\n-                    return ByteBuffer.wrap(bytes);\n+                    try (InputStream in = getInputStream()) {\n+                        byte[] bytes = in.readAllBytes();\n+                        return ByteBuffer.wrap(bytes);\n+                    }\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/module\/ModulePatcher.java","additions":24,"deletions":4,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -156,8 +156,1 @@\n-        java.desktop, \/\/ for ScopedValue\n-        jdk.compiler,\n-        jdk.incubator.vector, \/\/ participates in preview features\n-        jdk.jartool, \/\/ participates in preview features\n-        jdk.jdeps, \/\/ participates in preview features\n-        jdk.jfr, \/\/ participates in preview features\n-        jdk.jlink,   \/\/ participates in preview features\n-        jdk.jshell; \/\/ participates in preview features\n+        jdk.compiler;\n@@ -204,0 +197,2 @@\n+    exports jdk.internal.net.quic to\n+        java.net.http;\n@@ -325,0 +320,1 @@\n+        java.security.sasl,\n@@ -409,2 +405,1 @@\n-    uses sun.util.resources.LocaleData.CommonResourceBundleProvider;\n-    uses sun.util.resources.LocaleData.SupplementaryResourceBundleProvider;\n+    uses sun.util.resources.LocaleData.LocaleDataResourceBundleProvider;\n","filename":"src\/java.base\/share\/classes\/module-info.java","additions":5,"deletions":10,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2008, 2018, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2008, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -40,0 +40,2 @@\n+import jdk.internal.access.JavaNioAccess;\n+import jdk.internal.access.SharedSecrets;\n@@ -48,0 +50,2 @@\n+    private static final JavaNioAccess NIO_ACCESS = SharedSecrets.getJavaNioAccess();\n+\n@@ -252,0 +256,4 @@\n+        if (dst.isReadOnly())\n+            throw new IllegalArgumentException(\"Read-only buffer\");\n+        if (NIO_ACCESS.isThreadConfined(dst))\n+            throw new IllegalArgumentException(\"Buffer is thread confined\");\n@@ -263,0 +271,4 @@\n+        if (dst.isReadOnly())\n+            throw new IllegalArgumentException(\"Read-only buffer\");\n+        if (NIO_ACCESS.isThreadConfined(dst))\n+            throw new IllegalArgumentException(\"Buffer is thread confined\");\n@@ -274,0 +286,2 @@\n+        if (NIO_ACCESS.isThreadConfined(src))\n+            throw new IllegalArgumentException(\"Buffer is thread confined\");\n@@ -285,0 +299,2 @@\n+        if (NIO_ACCESS.isThreadConfined(src))\n+            throw new IllegalArgumentException(\"Buffer is thread confined\");\n","filename":"src\/java.base\/share\/classes\/sun\/nio\/ch\/AsynchronousFileChannelImpl.java","additions":17,"deletions":1,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -41,1 +41,0 @@\n-\n@@ -43,1 +42,0 @@\n-import sun.net.NetHooks;\n@@ -222,1 +220,0 @@\n-                NetHooks.beforeTcpBind(fd, isa.getAddress(), isa.getPort());\n","filename":"src\/java.base\/share\/classes\/sun\/nio\/ch\/AsynchronousServerSocketChannelImpl.java","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2008, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2008, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -42,1 +42,2 @@\n-\n+import jdk.internal.access.JavaNioAccess;\n+import jdk.internal.access.SharedSecrets;\n@@ -47,1 +48,0 @@\n-import sun.net.NetHooks;\n@@ -58,0 +58,1 @@\n+    private static final JavaNioAccess NIO_ACCESS = SharedSecrets.getJavaNioAccess();\n@@ -293,0 +294,2 @@\n+        if (NIO_ACCESS.isThreadConfined(dst))\n+            throw new IllegalArgumentException(\"Buffer is thread confined\");\n@@ -307,0 +310,2 @@\n+        if (NIO_ACCESS.isThreadConfined(dst))\n+            throw new IllegalArgumentException(\"Buffer is thread confined\");\n@@ -322,3 +327,3 @@\n-        ByteBuffer[] bufs = Util.subsequence(dsts, offset, length);\n-        for (int i=0; i<bufs.length; i++) {\n-            if (bufs[i].isReadOnly())\n+        dsts = Util.subsequence(dsts, offset, length);\n+        for (ByteBuffer dst : dsts) {\n+            if (dst.isReadOnly())\n@@ -326,0 +331,2 @@\n+            if (NIO_ACCESS.isThreadConfined(dst))\n+                throw new IllegalArgumentException(\"Buffer is thread confined\");\n@@ -327,1 +334,1 @@\n-        read(true, null, bufs, timeout, unit, attachment, handler);\n+        read(true, null, dsts, timeout, unit, attachment, handler);\n@@ -396,0 +403,2 @@\n+        if (NIO_ACCESS.isThreadConfined(src))\n+            throw new IllegalArgumentException(\"Buffer is thread confined\");\n@@ -408,0 +417,2 @@\n+        if (NIO_ACCESS.isThreadConfined(src))\n+            throw new IllegalArgumentException(\"Buffer is thread confined\");\n@@ -424,0 +435,5 @@\n+        for (ByteBuffer src : srcs) {\n+            if (NIO_ACCESS.isThreadConfined(src)) {\n+                throw new IllegalArgumentException(\"Buffer is thread confined\");\n+            }\n+        }\n@@ -440,1 +456,0 @@\n-                NetHooks.beforeTcpBind(fd, isa.getAddress(), isa.getPort());\n","filename":"src\/java.base\/share\/classes\/sun\/nio\/ch\/AsynchronousSocketChannelImpl.java","additions":23,"deletions":8,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -65,1 +65,0 @@\n-import jdk.internal.ref.Cleaner;\n@@ -70,0 +69,1 @@\n+import sun.nio.Cleaner;\n@@ -219,1 +219,5 @@\n-        if (!uninterruptible) end(completed);\n+        if (!uninterruptible) {\n+            end(completed);\n+        } else if (!completed && !isOpen()) {\n+            throw new AsynchronousCloseException();\n+        }\n","filename":"src\/java.base\/share\/classes\/sun\/nio\/ch\/FileChannelImpl.java","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -59,1 +59,0 @@\n-import sun.net.NetHooks;\n@@ -83,4 +82,0 @@\n-    \/\/ The maximum number of bytes to read\/write per syscall to avoid needing\n-    \/\/ a huge buffer from the temporary buffer cache\n-    private static final int MAX_BUFFER_SIZE = 128 * 1024;\n-\n@@ -302,0 +297,1 @@\n+        SocketException ex = null;\n@@ -320,1 +316,0 @@\n-            return n;\n@@ -327,2 +322,2 @@\n-            \/\/ throw SocketException to maintain compatibility\n-            throw asSocketException(ioe);\n+            \/\/ translate to SocketException to maintain compatibility\n+            ex = asSocketException(ioe);\n@@ -332,0 +327,7 @@\n+        if (n <= 0 && isInputClosed) {\n+            return -1;\n+        }\n+        if (ex != null) {\n+            throw ex;\n+        }\n+        return n;\n@@ -361,2 +363,2 @@\n-                \/\/ read up to MAX_BUFFER_SIZE bytes\n-                int size = Math.min(len, MAX_BUFFER_SIZE);\n+                \/\/ read up to Streams.MAX_BUFFER_SIZE bytes\n+                int size = Math.min(len, Streams.MAX_BUFFER_SIZE);\n@@ -424,0 +426,1 @@\n+        SocketException ex = null;\n@@ -432,1 +435,0 @@\n-            return n;\n@@ -436,2 +438,2 @@\n-            \/\/ throw SocketException to maintain compatibility\n-            throw asSocketException(ioe);\n+            \/\/ translate to SocketException to maintain compatibility\n+            ex = asSocketException(ioe);\n@@ -441,0 +443,4 @@\n+        if (ex != null) {\n+            throw ex;\n+        }\n+        return n;\n@@ -455,2 +461,2 @@\n-                    \/\/ write up to MAX_BUFFER_SIZE bytes\n-                    int size = Math.min((end - pos), MAX_BUFFER_SIZE);\n+                    \/\/ write up to Streams.MAX_BUFFER_SIZE bytes\n+                    int size = Math.min((end - pos), Streams.MAX_BUFFER_SIZE);\n@@ -540,5 +546,0 @@\n-            \/\/ invoke beforeTcpConnect hook if not already bound\n-            if (localport == 0) {\n-                NetHooks.beforeTcpConnect(fd, address, port);\n-            }\n-\n@@ -676,1 +677,0 @@\n-            NetHooks.beforeTcpBind(fd, host, port);\n","filename":"src\/java.base\/share\/classes\/sun\/nio\/ch\/NioSocketImpl.java","additions":21,"deletions":21,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -68,1 +68,0 @@\n-import sun.net.NetHooks;\n@@ -349,1 +348,0 @@\n-        NetHooks.beforeTcpBind(fd, isa.getAddress(), isa.getPort());\n","filename":"src\/java.base\/share\/classes\/sun\/nio\/ch\/ServerSocketChannelImpl.java","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -66,1 +66,0 @@\n-import sun.net.NetHooks;\n@@ -833,1 +832,0 @@\n-        NetHooks.beforeTcpBind(fd, isa.getAddress(), isa.getPort());\n@@ -851,1 +849,1 @@\n-     * @param isa the remote address\n+     * @param sa the remote socket address\n@@ -876,1 +874,0 @@\n-                NetHooks.beforeTcpConnect(fd, isa.getAddress(), isa.getPort());\n@@ -1075,2 +1072,2 @@\n-     * Closes the socket if there are no I\/O operations in progress and the\n-     * channel is not registered with a Selector.\n+     * Closes the socket if there are no I\/O operations in progress (or no I\/O\n+     * operations tracked), and the channel is not registered with a Selector.\n@@ -1101,1 +1098,3 @@\n-     * Closes this channel when configured in blocking mode.\n+     * Closes this channel when configured in blocking mode. If there are no I\/O\n+     * operations in progress (or tracked), then the channel's socket is closed. If\n+     * there are I\/O operations in progress then the behavior is platform specific.\n@@ -1103,3 +1102,11 @@\n-     * If there is an I\/O operation in progress then the socket is pre-closed\n-     * and the I\/O threads signalled, in which case the final close is deferred\n-     * until all I\/O operations complete.\n+     * On Unix systems, the channel's socket is pre-closed. This unparks any virtual\n+     * threads that are blocked in I\/O operations on this channel. If there are\n+     * platform threads blocked on the channel's socket then the socket is dup'ed\n+     * and the platform threads signalled. The final close is deferred until all I\/O\n+     * operations complete.\n+     *\n+     * On Windows, the channel's socket is pre-closed. This unparks any virtual\n+     * threads that are blocked in I\/O operations on this channel. If there are no\n+     * virtual threads blocked in I\/O operations on this channel then the channel's\n+     * socket is closed. If there are virtual threads in I\/O then the final close is\n+     * deferred until all I\/O operations on virtual threads complete.\n@@ -1117,1 +1124,1 @@\n-            if (!tryClose()) {\n+            if (connected && Net.shouldShutdownWriteBeforeClose()) {\n@@ -1119,8 +1126,7 @@\n-                if (connected) {\n-                    try {\n-                        var SO_LINGER = StandardSocketOptions.SO_LINGER;\n-                        if ((int) Net.getSocketOption(fd, SO_LINGER) != 0) {\n-                            Net.shutdown(fd, Net.SHUT_WR);\n-                        }\n-                    } catch (IOException ignore) { }\n-                }\n+                try {\n+                    var SO_LINGER = StandardSocketOptions.SO_LINGER;\n+                    if ((int) Net.getSocketOption(fd, SO_LINGER) != 0) {\n+                        Net.shutdown(fd, Net.SHUT_WR);\n+                    }\n+                } catch (IOException ignore) { }\n+            }\n@@ -1128,0 +1134,1 @@\n+            if (!tryClose()) {\n@@ -1371,0 +1378,1 @@\n+        len = Math.min(len, Streams.MAX_BUFFER_SIZE);\n@@ -1467,1 +1475,1 @@\n-                    int size = end - pos;\n+                    int size = Math.min(end - pos, Streams.MAX_BUFFER_SIZE);\n","filename":"src\/java.base\/share\/classes\/sun\/nio\/ch\/SocketChannelImpl.java","additions":28,"deletions":20,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 1994, 2025, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 1994, 2026, Oracle and\/or its affiliates. All rights reserved.\n@@ -64,1 +64,1 @@\n-`-jar` *jarfile*\n+[`-jar`]{#-jar} *jarfile*\n@@ -73,1 +73,1 @@\n-`-m` or `--module` *module*\\[`\/`*mainclass*\\]\n+[`-m`]{#-m} or `--module` *module*\\[`\/`*mainclass*\\]\n@@ -373,1 +373,1 @@\n-`-agentlib:`*libname*\\[`=`*options*\\]\n+[`-agentlib:`]{#-agentlib}*libname*\\[`=`*options*\\]\n@@ -396,1 +396,1 @@\n-`-agentpath:`*pathname*\\[`=`*options*\\]\n+[`-agentpath:`]{#-agentpath}*pathname*\\[`=`*options*\\]\n@@ -401,1 +401,1 @@\n-`--class-path` *classpath*, `-classpath` *classpath*, or `-cp` *classpath*\n+[`--class-path`]{#--class-path} *classpath*, `-classpath` *classpath*, or `-cp` *classpath*\n@@ -427,1 +427,1 @@\n-`--disable-@files`\n+[`--disable-@files`]{#--disable-@files}\n@@ -432,1 +432,1 @@\n-`--enable-preview`\n+[`--enable-preview`]{#--enable-preview}\n@@ -435,1 +435,1 @@\n-`--enable-native-access` *module*\\[`,`*module*...\\]\n+[`--enable-native-access`]{#--enable-native-access} *module*\\[`,`*module*...\\]\n@@ -453,1 +453,1 @@\n-        without any warings.\n+        without any warnings.\n@@ -468,1 +468,34 @@\n-`--finalization=`*value*\n+[`--enable-final-field-mutation`]{#--enable-final-field-mutation} *module*\\[,*module*...\\]\n+:   Mutation of final fields is possible with the reflection API of the Java Platform.\n+    However, it compromises safety and performance in all programs.\n+    This option allows code in the specified modules to mutate final fields by reflection.\n+    Attempts by code in any other module to mutate final fields by reflection are deemed _illegal_.\n+\n+    *module* can be the name of a module on the module path, or `ALL-UNNAMED` to indicate\n+    code on the class path.\n+\n+-`--illegal-final-field-mutation=`*parameter*\n+:   This option specifies a mode for how _illegal_ final field mutation is handled:\n+\n+    > **Note:** This option will be removed in a future release.\n+\n+    -   `allow`: This mode allows illegal final field mutation in all modules,\n+        without any warnings.\n+\n+    -   `warn`: This mode is identical to `allow` except that a warning message is\n+        issued for the first illegal final field mutation performaed in a module.\n+        This mode is the default for the current JDK but will change in a future\n+        release.\n+\n+    -   `debug`: This mode is identical to `allow` except that a warning message\n+        and stack trace are printed for every illegal final field mutation.\n+\n+    -   `deny`: This mode disables final field mutation. That is, any illegal final\n+        field mutation access causes an `IllegalAccessException`. This mode will\n+        become the default in a future release.\n+\n+    To verify that your application is ready for a future version of the JDK,\n+    run it with `--illegal-final-field-mutation=deny` along with any necessary\n+    `--enable-final-field-mutation` options.\n+\n+[`--finalization=`]{#--finalization}*value*\n@@ -474,1 +507,1 @@\n-`--module-path` *modulepath*... or `-p` *modulepath*\n+[`--module-path`]{#--module-path} *modulepath*... or `-p` *modulepath*\n@@ -483,1 +516,1 @@\n-`--upgrade-module-path` *modulepath*...\n+[`--upgrade-module-path`]{#--upgrade-module-path} *modulepath*...\n@@ -493,1 +526,1 @@\n-`--add-modules` *module*\\[`,`*module*...\\]\n+[`--add-modules`]{#--add-modules} *module*\\[`,`*module*...\\]\n@@ -497,1 +530,1 @@\n-`--list-modules`\n+[`--list-modules`]{#--list-modules}\n@@ -500,1 +533,1 @@\n-`-d` *module\\_name* or `--describe-module` *module\\_name*\n+[`-d`]{#-d} *module\\_name* or `--describe-module` *module\\_name*\n@@ -503,1 +536,1 @@\n-`--dry-run`\n+[`--dry-run`]{#--dry-run}\n@@ -508,1 +541,1 @@\n-`--validate-modules`\n+[`--validate-modules`]{#--validate-modules}\n@@ -512,1 +545,1 @@\n-`-D`*property*`=`*value*\n+[`-D`]{#-D}*property*`=`*value*\n@@ -519,1 +552,1 @@\n-`-disableassertions`\\[`:`\\[*packagename*\\]...\\|`:`*classname*\\] or `-da`\\[`:`\\[*packagename*\\]...\\|`:`*classname*\\]\n+[`-disableassertions`]{#-disableassertions}\\[`:`\\[*packagename*\\]...\\|`:`*classname*\\] or `-da`\\[`:`\\[*packagename*\\]...\\|`:`*classname*\\]\n@@ -544,1 +577,1 @@\n-`-disablesystemassertions` or `-dsa`\n+[`-disablesystemassertions`]{#-disablesystemassertions} or `-dsa`\n@@ -547,1 +580,1 @@\n-`-enableassertions`\\[`:`\\[*packagename*\\]...\\|`:`*classname*\\] or `-ea`\\[`:`\\[*packagename*\\]...\\|`:`*classname*\\]\n+[`-enableassertions`]{#-enableassertions}\\[`:`\\[*packagename*\\]...\\|`:`*classname*\\] or `-ea`\\[`:`\\[*packagename*\\]...\\|`:`*classname*\\]\n@@ -574,1 +607,1 @@\n-`-enablesystemassertions` or `-esa`\n+[`-enablesystemassertions`]{#-enablesystemassertions} or `-esa`\n@@ -577,1 +610,1 @@\n-`-help`, `-h`, or `-?`\n+[`-help`]{#-help}, `-h`, or `-?`\n@@ -580,1 +613,1 @@\n-`--help`\n+[`--help`]{#--help}\n@@ -583,1 +616,1 @@\n-`-javaagent:`*jarpath*\\[`=`*options*\\]\n+[`-javaagent:`]{#-javaagent_}*jarpath*\\[`=`*options*\\]\n@@ -586,1 +619,1 @@\n-`--show-version`\n+[`--show-version`]{#--show-version}\n@@ -589,1 +622,1 @@\n-`-showversion`\n+[`-showversion`]{#-showversion}\n@@ -592,1 +625,1 @@\n-`--show-module-resolution`\n+[`--show-module-resolution`]{#--show-module-resolution}\n@@ -595,1 +628,1 @@\n-`-splash:`*imagepath*\n+[`-splash:`]{#-splash_}*imagepath*\n@@ -609,1 +642,1 @@\n-`-verbose:class`\n+[`-verbose:class`]{#-verbose_class}\n@@ -612,1 +645,1 @@\n-`-verbose:gc`\n+[`-verbose:gc`]{#-verbose_gc}\n@@ -615,1 +648,1 @@\n-`-verbose:jni`\n+[`-verbose:jni`]{#-verbose_jni}\n@@ -619,1 +652,1 @@\n-`-verbose:module`\n+[`-verbose:module`]{#-verbose_module}\n@@ -622,1 +655,1 @@\n-`--version`\n+[`--version`]{#--version}\n@@ -625,1 +658,1 @@\n-`-version`\n+[`-version`]{#-version}\n@@ -628,1 +661,1 @@\n-`-X`\n+[`-X`]{#-X}\n@@ -631,1 +664,1 @@\n-`--help-extra`\n+[`--help-extra`]{#--help-extra}\n@@ -658,1 +691,1 @@\n-`-Xbatch`\n+[`-Xbatch`]{#-Xbatch}\n@@ -666,1 +699,1 @@\n-`-Xbootclasspath\/a:`*directories*\\|*zip*\\|*JAR-files*\n+[`-Xbootclasspath\/a:`]{#-Xbootclasspath}*directories*\\|*zip*\\|*JAR-files*\n@@ -673,1 +706,1 @@\n-`-Xcheck:jni`\n+[`-Xcheck:jni`]{#-Xcheck_jni}\n@@ -704,1 +737,2 @@\n-      or `Get\/ReleaseStringCritical`\n+      or `Get\/ReleaseStringCritical`.\n+    - A JNI call was made to mutate a final field.\n@@ -708,1 +742,1 @@\n-`-Xcomp`\n+[`-Xcomp`]{#-Xcomp}\n@@ -711,1 +745,1 @@\n-`-Xdebug`\n+[`-Xdebug`]{#-Xdebug}\n@@ -714,1 +748,1 @@\n-`-Xdiag`\n+[`-Xdiag`]{#-Xdiag}\n@@ -717,1 +751,1 @@\n-`-Xint`\n+[`-Xint`]{#-Xint}\n@@ -723,1 +757,1 @@\n-`-Xinternalversion`\n+[`-Xinternalversion`]{#-Xinternalversion}\n@@ -732,1 +766,1 @@\n-`-Xmixed`\n+[`-Xmixed`]{#-Xmixed}\n@@ -736,1 +770,1 @@\n-`-Xmn` *size*\n+[`-Xmn`]{#-Xmn} *size*\n@@ -762,1 +796,1 @@\n-`-Xms` *size*\n+[`-Xms`]{#-Xms} *size*\n@@ -784,1 +818,1 @@\n-`-Xmx` *size*\n+[`-Xmx`]{#-Xmx} *size*\n@@ -801,1 +835,1 @@\n-`-Xnoclassgc`\n+[`-Xnoclassgc`]{#-Xnoclassgc}\n@@ -809,1 +843,1 @@\n-`-Xrs`\n+[`-Xrs`]{#-Xrs}\n@@ -859,1 +893,1 @@\n-`-Xshare:`*mode*\n+[`-Xshare:`]{#-Xshare_}*mode*\n@@ -879,1 +913,1 @@\n-`-XshowSettings`\n+[`-XshowSettings`]{#-XshowSettings}\n@@ -882,1 +916,1 @@\n-`-XshowSettings:`*category*\n+[`-XshowSettings:`]{#-XshowSettings_}*category*\n@@ -911,1 +945,1 @@\n-`-Xss` *size*\n+[`-Xss`]{#-Xss} *size*\n@@ -939,1 +973,1 @@\n-`--add-reads` *module*`=`*target-module*(`,`*target-module*)\\*\n+[`--add-reads`]{#--add-reads} *module*`=`*target-module*(`,`*target-module*)\\*\n@@ -944,1 +978,1 @@\n-`--add-exports` *module*`\/`*package*`=`*target-module*(`,`*target-module*)\\*\n+[`--add-exports`]{#--add-exports} *module*`\/`*package*`=`*target-module*(`,`*target-module*)\\*\n@@ -949,1 +983,1 @@\n-`--add-opens` *module*`\/`*package*`=`*target-module*(`,`*target-module*)\\*\n+[`--add-opens`]{#--add-opens} *module*`\/`*package*`=`*target-module*(`,`*target-module*)\\*\n@@ -953,1 +987,1 @@\n-`--limit-modules` *module*\\[`,`*module*...\\]\n+[`--limit-modules`]{#--limit-modules} *module*\\[`,`*module*...\\]\n@@ -956,1 +990,1 @@\n-`--patch-module` *module*`=`*file*(`;`*file*)\\*\n+[`--patch-module`]{#--patch-module} *module*`=`*file*(`;`*file*)\\*\n@@ -960,1 +994,1 @@\n-`--source` *version*\n+[`--source`]{#--source} *version*\n@@ -964,1 +998,1 @@\n-`--sun-misc-unsafe-memory-access=` *value*\n+[`--sun-misc-unsafe-memory-access=`]{#--sun-misc-unsafe-memory-access} *value*\n@@ -990,1 +1024,1 @@\n-`-XstartOnFirstThread`\n+[`-XstartOnFirstThread`]{#-XstartOnFirstThread}\n@@ -993,1 +1027,1 @@\n-`-Xdock:name=`*application\\_name*\n+[`-Xdock:name=`]{#-Xdock_name}*application\\_name*\n@@ -996,1 +1030,1 @@\n-`-Xdock:icon=`*path\\_to\\_icon\\_file*\n+[`-Xdock:icon=`]{#-Xdock_icon}*path\\_to\\_icon\\_file*\n@@ -1003,1 +1037,1 @@\n-`-XX:+UnlockDiagnosticVMOptions`\n+[`-XX:+UnlockDiagnosticVMOptions`]{#-XX__UnlockDiagnosticVMOptions}\n@@ -1015,1 +1049,1 @@\n-`-XX:+UnlockExperimentalVMOptions`\n+[`-XX:+UnlockExperimentalVMOptions`]{#-XX__UnlockExperimentalVMOptions}\n@@ -1023,1 +1057,1 @@\n-`-XX:ActiveProcessorCount=`*x*\n+[`-XX:ActiveProcessorCount=`]{#-XX_ActiveProcessorCount}*x*\n@@ -1035,1 +1069,1 @@\n-`-XX:AllocateHeapAt=`*path*\n+[`-XX:AllocateHeapAt=`]{#-XX_AllocateHeapAt}*path*\n@@ -1053,1 +1087,1 @@\n-`-XX:-CompactStrings`\n+[`-XX:-CompactStrings`]{#-XX__CompactStrings}\n@@ -1076,1 +1110,1 @@\n-`-XX:CRaCCheckpointTo=`*directory*\n+[`-XX:CRaCCheckpointTo=`]{#-XX_CRaCCheckpointTo}*directory*\n@@ -1107,1 +1141,1 @@\n-`-XX:CRaCRestoreFrom=`*directory*\n+[`-XX:CRaCRestoreFrom=`]{#-XX_CRaCRestoreFrom}*directory*\n@@ -1115,1 +1149,1 @@\n-`-XX:+CRaCIgnoreRestoreIfUnavailable`\n+[`-XX:+CRaCIgnoreRestoreIfUnavailable`]{#-XX__CRaCIgnoreRestoreIfUnavailable}\n@@ -1126,1 +1160,1 @@\n-`-XX:CRaCMinPid=`*value*\n+[`-XX:CRaCMinPid=`]{#-XX_CRaCMinPid}*value*\n@@ -1130,1 +1164,1 @@\n-`-XX:ErrorFile=`*filename*\n+[`-XX:ErrorFile=`]{#-XX_ErrorFile}*filename*\n@@ -1162,1 +1196,1 @@\n-`-XX:+ExtensiveErrorReports`\n+[`-XX:+ExtensiveErrorReports`]{#-XX__ExtensiveErrorReports}\n@@ -1170,1 +1204,1 @@\n-`-XX:FlightRecorderOptions=`*parameter*`=`*value* (or) `-XX:FlightRecorderOptions:`*parameter*`=`*value*\n+[`-XX:FlightRecorderOptions=`]{#-XX_FlightRecorderOptions}*parameter*`=`*value* (or) `-XX:FlightRecorderOptions:`*parameter*`=`*value*\n@@ -1230,1 +1264,1 @@\n-`-XX:LargePageSizeInBytes=`*size*\n+[`-XX:LargePageSizeInBytes=`]{#-XX_LargePageSizeInBytes}*size*\n@@ -1244,1 +1278,1 @@\n-`-XX:MaxDirectMemorySize=`*size*\n+[`-XX:MaxDirectMemorySize=`]{#-XX_MaxDirectMemorySize}*size*\n@@ -1260,1 +1294,1 @@\n-`-XX:-MaxFDLimit`\n+[`-XX:-MaxFDLimit`]{#-XX__MaxFDLimit}\n@@ -1267,1 +1301,1 @@\n-`-XX:NativeMemoryTracking=`*mode*\n+[`-XX:NativeMemoryTracking=`]{#-XX_NativeMemoryTracking}*mode*\n@@ -1284,1 +1318,1 @@\n-`-XX:TrimNativeHeapInterval=`*millis*\n+[`-XX:TrimNativeHeapInterval=`]{#-XX_TrimNativeHeapInterval}*millis*\n@@ -1292,21 +1326,1 @@\n-`-XX:+NeverActAsServerClassMachine`\n-:   Enable the \"Client VM emulation\" mode which only uses the C1 JIT compiler,\n-    a 32Mb CodeCache and the Serial GC. The maximum amount of memory that the\n-    JVM may use (controlled by the `-XX:MaxRAM=n` flag) is set to 1GB by default.\n-    The string \"emulated-client\" is added to the JVM version string.\n-\n-    By default the flag is set to `true` only on Windows in 32-bit mode and\n-    `false` in all other cases.\n-\n-    The \"Client VM emulation\" mode will not be enabled if any of the following\n-    flags are used on the command line:\n-\n-    ```\n-    -XX:{+|-}TieredCompilation\n-    -XX:CompilationMode=mode\n-    -XX:TieredStopAtLevel=n\n-    -XX:{+|-}EnableJVMCI\n-    -XX:{+|-}UseJVMCICompiler\n-    ```\n-\n-`-XX:ObjectAlignmentInBytes=`*alignment*\n+[`-XX:ObjectAlignmentInBytes=`]{#-XX_ObjectAlignmentInBytes}*alignment*\n@@ -1326,1 +1340,1 @@\n-`-XX:OnError=`*string*\n+[`-XX:OnError=`]{#-XX_OnError}*string*\n@@ -1347,1 +1361,1 @@\n-`-XX:OnOutOfMemoryError=`*string*\n+[`-XX:OnOutOfMemoryError=`]{#-XX_OnOutOfMemoryError}*string*\n@@ -1359,1 +1373,1 @@\n-`-XX:+PrintCommandLineFlags`\n+[`-XX:+PrintCommandLineFlags`]{#-XX__PrintCommandLineFlags}\n@@ -1365,1 +1379,1 @@\n-`-XX:+PreserveFramePointer`\n+[`-XX:+PreserveFramePointer`]{#-XX__PreserveFramePointer}\n@@ -1372,1 +1386,1 @@\n-`-XX:+PrintNMTStatistics`\n+[`-XX:+PrintNMTStatistics`]{#-XX__PrintNMTStatistics}\n@@ -1378,1 +1392,1 @@\n-`-XX:SharedArchiveFile=`*path*\n+[`-XX:SharedArchiveFile=`]{#-XX_SharedArchiveFile}*path*\n@@ -1383,1 +1397,1 @@\n-`-XX:+VerifySharedSpaces`\n+[`-XX:+VerifySharedSpaces`]{#-XX__VerifySharedSpaces}\n@@ -1391,1 +1405,1 @@\n-`-XX:SharedArchiveConfigFile=`*shared\\_config\\_file*\n+[`-XX:SharedArchiveConfigFile=`]{#-XX_SharedArchiveConfigFile}*shared\\_config\\_file*\n@@ -1394,1 +1408,1 @@\n-`-XX:SharedClassListFile=`*file\\_name*\n+[`-XX:SharedClassListFile=`]{#-XX_SharedClassListFile}*file\\_name*\n@@ -1412,1 +1426,1 @@\n-`-XX:+ShowCodeDetailsInExceptionMessages`\n+[`-XX:+ShowCodeDetailsInExceptionMessages`]{#-XX__ShowCodeDetailsInExceptionMessages}\n@@ -1421,1 +1435,1 @@\n-`-XX:+ShowMessageBoxOnError`\n+[`-XX:+ShowMessageBoxOnError`]{#-XX__ShowMessageBoxOnError}\n@@ -1427,1 +1441,1 @@\n-`-XX:StartFlightRecording:`*parameter*`=`*value*\n+[`-XX:StartFlightRecording:`]{#-XX_StartFlightRecording_}*parameter*`=`*value*\n@@ -1506,3 +1520,4 @@\n-        (JVM) shuts down. This option is not available if the disk option is set\n-        to false. For a list of available views, see `jfr help view`. By default,\n-        no report is generated.\n+        (JVM) shuts down. To specify more than one view, use the report-on-exit\n+        parameter repeatedly. This option is not available if the disk option\n+        is set to false. For a list of available views, see `jfr help view`.\n+        By default, no report is generated.\n@@ -1545,1 +1560,1 @@\n-`-XX:ThreadStackSize=`*size*\n+[`-XX:ThreadStackSize=`]{#-XX_ThreadStackSize}*size*\n@@ -1571,1 +1586,10 @@\n-`-XX:-UseCompressedOops`\n+[`-XX:+UseCompactObjectHeaders`]{#-XX__UseCompactObjectHeaders}\n+:   Enables compact object headers. By default, this option is disabled.\n+    Enabling this option reduces memory footprint in the Java heap by\n+    4 bytes per object (on average) and often improves performance.\n+\n+    The feature remains disabled by default while it continues to be evaluated.\n+    In a future release it is expected to be enabled by default, and\n+    eventually will be the only mode of operation.\n+\n+[`-XX:-UseCompressedOops`]{#-XX__UseCompressedOops}\n@@ -1586,1 +1610,1 @@\n-`-XX:-UseContainerSupport`\n+[`-XX:-UseContainerSupport`]{#-XX__UseContainerSupport}\n@@ -1601,1 +1625,1 @@\n-`-XX:+UseLargePages`\n+[`-XX:+UseLargePages`]{#-XX__UseLargePages}\n@@ -1607,1 +1631,1 @@\n-`-XX:+UseTransparentHugePages`\n+[`-XX:+UseTransparentHugePages`]{#-XX__UseTransparentHugePages}\n@@ -1613,1 +1637,1 @@\n-`-XX:+AllowUserSignalHandlers`\n+[`-XX:+AllowUserSignalHandlers`]{#-XX__AllowUserSignalHandlers}\n@@ -1618,1 +1642,1 @@\n-`-XX:VMOptionsFile=`*filename*\n+[`-XX:VMOptionsFile=`]{#-XX_VMOptionsFile}*filename*\n@@ -1622,1 +1646,1 @@\n-`-XX:UseBranchProtection=`*mode*\n+[`-XX:UseBranchProtection=`]{#-XX_UseBranchProtection}*mode*\n@@ -1646,1 +1670,1 @@\n-`-XX:AllocateInstancePrefetchLines=`*lines*\n+[`-XX:AllocateInstancePrefetchLines=`]{#-XX_AllocateInstancePrefetchLines}*lines*\n@@ -1653,1 +1677,1 @@\n-`-XX:AllocatePrefetchDistance=`*size*\n+[`-XX:AllocatePrefetchDistance=`]{#-XX_AllocatePrefetchDistance}*size*\n@@ -1669,1 +1693,1 @@\n-`-XX:AllocatePrefetchInstr=`*instruction*\n+[`-XX:AllocatePrefetchInstr=`]{#-XX_AllocatePrefetchInstr}*instruction*\n@@ -1677,1 +1701,1 @@\n-`-XX:AllocatePrefetchLines=`*lines*\n+[`-XX:AllocatePrefetchLines=`]{#-XX_AllocatePrefetchLines}*lines*\n@@ -1689,1 +1713,1 @@\n-`-XX:AllocatePrefetchStepSize=`*size*\n+[`-XX:AllocatePrefetchStepSize=`]{#-XX_AllocatePrefetchStepSize}*size*\n@@ -1698,1 +1722,1 @@\n-`-XX:AllocatePrefetchStyle=`*style*\n+[`-XX:AllocatePrefetchStyle=`]{#-XX_AllocatePrefetchStyle}*style*\n@@ -1717,1 +1741,1 @@\n-`-XX:+BackgroundCompilation`\n+[`-XX:+BackgroundCompilation`]{#-XX__BackgroundCompilation}\n@@ -1722,1 +1746,1 @@\n-`-XX:CICompilerCount=`*threads*\n+[`-XX:CICompilerCount=`]{#-XX_CICompilerCount}*threads*\n@@ -1730,1 +1754,1 @@\n-`-XX:+UseDynamicNumberOfCompilerThreads`\n+[`-XX:+UseDynamicNumberOfCompilerThreads`]{#-XX__UseDynamicNumberOfCompilerThreads}\n@@ -1734,1 +1758,1 @@\n-`-XX:CompileCommand=`*command*`,`*method*\\[`,`*option*\\]\n+[`-XX:CompileCommand=`]{#-XX_CompileCommand}*command*`,`*method*\\[`,`*option*\\]\n@@ -1833,1 +1857,1 @@\n-`-XX:CompileCommandFile=`*filename*\n+[`-XX:CompileCommandFile=`]{#-XX_CompileCommandFile}*filename*\n@@ -1847,1 +1871,1 @@\n-`-XX:CompilerDirectivesFile=`*file*\n+[`-XX:CompilerDirectivesFile=`]{#-XX_CompilerDirectivesFile}*file*\n@@ -1855,1 +1879,1 @@\n-`-XX:+CompilerDirectivesPrint`\n+[`-XX:+CompilerDirectivesPrint`]{#-XX__CompilerDirectivesPrint}\n@@ -1862,1 +1886,1 @@\n-`-XX:CompileOnly=`*methods*\n+[`-XX:CompileOnly=`]{#-XX_CompileOnly}*methods*\n@@ -1874,1 +1898,1 @@\n-`-XX:CompileThresholdScaling=`*scale*\n+[`-XX:CompileThresholdScaling=`]{#-XX_CompileThresholdScaling}*scale*\n@@ -1884,1 +1908,1 @@\n-`-XX:CPUFeatures=`*features*\n+[`-XX:CPUFeatures=`]{#-XX_CPUFeatures}*features*\n@@ -1903,1 +1927,1 @@\n-`-XX:+DoEscapeAnalysis`\n+[`-XX:+DoEscapeAnalysis`]{#-XX__DoEscapeAnalysis}\n@@ -1907,1 +1931,1 @@\n-`-XX:CheckCPUFeatures=`*check*\n+[`-XX:CheckCPUFeatures=`]{#-XX_CheckCPUFeatures}*check*\n@@ -1920,1 +1944,1 @@\n-`-XX:InitialCodeCacheSize=`*size*\n+[`-XX:InitialCodeCacheSize=`]{#-XX_InitialCodeCacheSize}*size*\n@@ -1930,1 +1954,1 @@\n-`-XX:+Inline`\n+[`-XX:+Inline`]{#-XX__Inline}\n@@ -1934,1 +1958,1 @@\n-`-XX:InlineSmallCode=`*size*\n+[`-XX:InlineSmallCode=`]{#-XX_InlineSmallCode}*size*\n@@ -1944,1 +1968,1 @@\n-`-XX:+LogCompilation`\n+[`-XX:+LogCompilation`]{#-XX__LogCompilation}\n@@ -1958,1 +1982,1 @@\n-`-XX:FreqInlineSize=`*size*\n+[`-XX:FreqInlineSize=`]{#-XX_FreqInlineSize}*size*\n@@ -1968,1 +1992,1 @@\n-`-XX:MaxInlineSize=`*size*\n+[`-XX:MaxInlineSize=`]{#-XX_MaxInlineSize}*size*\n@@ -1977,1 +2001,1 @@\n-`-XX:C1MaxInlineSize=`*size*\n+[`-XX:C1MaxInlineSize=`]{#-XX_C1MaxInlineSize}*size*\n@@ -1986,1 +2010,1 @@\n-`-XX:MaxTrivialSize=`*size*\n+[`-XX:MaxTrivialSize=`]{#-XX_MaxTrivialSize}*size*\n@@ -1995,1 +2019,1 @@\n-`-XX:C1MaxTrivialSize=`*size*\n+[`-XX:C1MaxTrivialSize=`]{#-XX_C1MaxTrivialSize}*size*\n@@ -2004,1 +2028,1 @@\n-`-XX:MaxNodeLimit=`*nodes*\n+[`-XX:MaxNodeLimit=`]{#-XX_MaxNodeLimit}*nodes*\n@@ -2011,1 +2035,1 @@\n-`-XX:NonNMethodCodeHeapSize=`*size*\n+[`-XX:NonNMethodCodeHeapSize=`]{#-XX_NonNMethodCodeHeapSize}*size*\n@@ -2019,1 +2043,1 @@\n-`-XX:NonProfiledCodeHeapSize=`*size*\n+[`-XX:NonProfiledCodeHeapSize=`]{#-XX_NonProfiledCodeHeapSize}*size*\n@@ -2023,1 +2047,1 @@\n-`-XX:+OptimizeStringConcat`\n+[`-XX:+OptimizeStringConcat`]{#-XX__OptimizeStringConcat}\n@@ -2028,1 +2052,1 @@\n-`-XX:+PrintAssembly`\n+[`-XX:+PrintAssembly`]{#-XX__PrintAssembly}\n@@ -2038,1 +2062,1 @@\n-`-XX:ProfiledCodeHeapSize=`*size*\n+[`-XX:ProfiledCodeHeapSize=`]{#-XX_ProfiledCodeHeapSize}*size*\n@@ -2042,1 +2066,1 @@\n-`-XX:+PrintCompilation`\n+[`-XX:+PrintCompilation`]{#-XX__PrintCompilation}\n@@ -2051,1 +2075,1 @@\n-`-XX:+PrintInlining`\n+[`-XX:+PrintInlining`]{#-XX__PrintInlining}\n@@ -2060,1 +2084,1 @@\n-`-XX:ReservedCodeCacheSize=`*size*\n+[`-XX:ReservedCodeCacheSize=`]{#-XX_ReservedCodeCacheSize}*size*\n@@ -2070,1 +2094,1 @@\n-`-XX:+SegmentedCodeCache`\n+[`-XX:+SegmentedCodeCache`]{#-XX__SegmentedCodeCache}\n@@ -2083,1 +2107,1 @@\n-`-XX:+ShowCPUFeatures`\n+[`-XX:+ShowCPUFeatures`]{#-XX__ShowCPUFeatures}\n@@ -2087,1 +2111,1 @@\n-`-XX:StartAggressiveSweepingAt=`*percent*\n+[`-XX:StartAggressiveSweepingAt=`]{#-XX_StartAggressiveSweepingAt}*percent*\n@@ -2092,1 +2116,1 @@\n-`-XX:-TieredCompilation`\n+[`-XX:-TieredCompilation`]{#-XX__TieredCompilation}\n@@ -2095,1 +2119,1 @@\n-`-XX:UseSSE=`*version*\n+[`-XX:UseSSE=`]{#-XX_UseSSE}*version*\n@@ -2099,1 +2123,1 @@\n-`-XX:UseAVX=`*version*\n+[`-XX:UseAVX=`]{#-XX_UseAVX}*version*\n@@ -2103,1 +2127,1 @@\n-`-XX:+UseAES`\n+[`-XX:+UseAES`]{#-XX__UseAES}\n@@ -2109,1 +2133,1 @@\n-`-XX:+UseAESIntrinsics`\n+[`-XX:+UseAESIntrinsics`]{#-XX__UseAESIntrinsics}\n@@ -2120,1 +2144,1 @@\n-`-XX:+UseAESCTRIntrinsics`\n+[`-XX:+UseAESCTRIntrinsics`]{#-XX__UseAESCTRIntrinsics}\n@@ -2123,1 +2147,1 @@\n-`-XX:+UseGHASHIntrinsics`\n+[`-XX:+UseGHASHIntrinsics`]{#-XX__UseGHASHIntrinsics}\n@@ -2128,1 +2152,1 @@\n-`-XX:+UseChaCha20Intrinsics`\n+[`-XX:+UseChaCha20Intrinsics`]{#-XX__UseChaCha20Intrinsics}\n@@ -2134,1 +2158,1 @@\n-`-XX:+UsePoly1305Intrinsics`\n+[`-XX:+UsePoly1305Intrinsics`]{#-XX__UsePoly1305Intrinsics}\n@@ -2140,1 +2164,1 @@\n-`-XX:+UseBASE64Intrinsics`\n+[`-XX:+UseBASE64Intrinsics`]{#-XX__UseBASE64Intrinsics}\n@@ -2145,1 +2169,1 @@\n-`-XX:+UseAdler32Intrinsics`\n+[`-XX:+UseAdler32Intrinsics`]{#-XX__UseAdler32Intrinsics}\n@@ -2150,1 +2174,1 @@\n-`-XX:+UseCRC32Intrinsics`\n+[`-XX:+UseCRC32Intrinsics`]{#-XX__UseCRC32Intrinsics}\n@@ -2155,1 +2179,1 @@\n-`-XX:+UseCRC32CIntrinsics`\n+[`-XX:+UseCRC32CIntrinsics`]{#-XX__UseCRC32CIntrinsics}\n@@ -2160,1 +2184,1 @@\n-`-XX:+UseSHA`\n+[`-XX:+UseSHA`]{#-XX__UseSHA}\n@@ -2177,1 +2201,1 @@\n-`-XX:+UseSHA1Intrinsics`\n+[`-XX:+UseSHA1Intrinsics`]{#-XX__UseSHA1Intrinsics}\n@@ -2181,1 +2205,1 @@\n-`-XX:+UseSHA256Intrinsics`\n+[`-XX:+UseSHA256Intrinsics`]{#-XX__UseSHA256Intrinsics}\n@@ -2186,1 +2210,1 @@\n-`-XX:+UseSHA512Intrinsics`\n+[`-XX:+UseSHA512Intrinsics`]{#-XX__UseSHA512Intrinsics}\n@@ -2191,1 +2215,1 @@\n-`-XX:+UseMathExactIntrinsics`\n+[`-XX:+UseMathExactIntrinsics`]{#-XX__UseMathExactIntrinsics}\n@@ -2196,1 +2220,1 @@\n-`-XX:+UseMultiplyToLenIntrinsic`\n+[`-XX:+UseMultiplyToLenIntrinsic`]{#-XX__UseMultiplyToLenIntrinsic}\n@@ -2221,1 +2245,1 @@\n-`-XX:+UseCMoveUnconditionally`\n+[`-XX:+UseCMoveUnconditionally`]{#-XX__UseCMoveUnconditionally}\n@@ -2225,1 +2249,1 @@\n-`-XX:+UseCodeCacheFlushing`\n+[`-XX:+UseCodeCacheFlushing`]{#-XX__UseCodeCacheFlushing}\n@@ -2230,1 +2254,1 @@\n-`-XX:+UseCondCardMark`\n+[`-XX:+UseCondCardMark`]{#-XX__UseCondCardMark}\n@@ -2236,1 +2260,1 @@\n-`-XX:+UseCountedLoopSafepoints`\n+[`-XX:+UseCountedLoopSafepoints`]{#-XX__UseCountedLoopSafepoints}\n@@ -2240,1 +2264,1 @@\n-`-XX:LoopStripMiningIter=`*number_of_iterations*\n+[`-XX:LoopStripMiningIter=`]{#-XX_LoopStripMiningIter}*number_of_iterations*\n@@ -2247,1 +2271,1 @@\n-`-XX:LoopStripMiningIterShortLoop=`*number_of_iterations*\n+[`-XX:LoopStripMiningIterShortLoop=`]{#-XX_LoopStripMiningIterShortLoop}*number_of_iterations*\n@@ -2252,1 +2276,1 @@\n-`-XX:+UseFMA`\n+[`-XX:+UseFMA`]{#-XX__UseFMA}\n@@ -2258,1 +2282,1 @@\n-`-XX:+UseSuperWord`\n+[`-XX:+UseSuperWord`]{#-XX__UseSuperWord}\n@@ -2269,1 +2293,1 @@\n-`-XX:+DisableAttachMechanism`\n+[`-XX:+DisableAttachMechanism`]{#-XX__DisableAttachMechanism}\n@@ -2280,1 +2304,1 @@\n-`-XX:+DTraceAllocProbes`\n+[`-XX:+DTraceAllocProbes`]{#-XX__DTraceAllocProbes}\n@@ -2283,1 +2307,1 @@\n-`-XX:+DTraceMethodProbes`\n+[`-XX:+DTraceMethodProbes`]{#-XX__DTraceMethodProbes}\n@@ -2287,1 +2311,1 @@\n-`-XX:+DTraceMonitorProbes`\n+[`-XX:+DTraceMonitorProbes`]{#-XX__DTraceMonitorProbes}\n@@ -2290,1 +2314,1 @@\n-`-XX:+HeapDumpOnOutOfMemoryError`\n+[`-XX:+HeapDumpOnOutOfMemoryError`]{#-XX__HeapDumpOnOutOfMemoryError}\n@@ -2302,1 +2326,1 @@\n-`-XX:HeapDumpPath=`*path*\n+[`-XX:HeapDumpPath=`]{#-XX_HeapDumpPath}*path*\n@@ -2322,1 +2346,1 @@\n-`-XX:LogFile=`*path*\n+[`-XX:LogFile=`]{#-XX_LogFile}*path*\n@@ -2337,1 +2361,1 @@\n-`-XX:+PrintClassHistogram`\n+[`-XX:+PrintClassHistogram`]{#-XX__PrintClassHistogram}\n@@ -2351,1 +2375,1 @@\n-`-XX:+PrintConcurrentLocks`\n+[`-XX:+PrintConcurrentLocks`]{#-XX__PrintConcurrentLocks}\n@@ -2365,1 +2389,1 @@\n-`-XX:+PrintFlagsRanges`\n+[`-XX:+PrintFlagsRanges`]{#-XX__PrintFlagsRanges}\n@@ -2370,1 +2394,1 @@\n-`-XX:+PerfDataSaveToFile`\n+[`-XX:+PerfDataSaveToFile`]{#-XX__PerfDataSaveToFile}\n@@ -2381,1 +2405,1 @@\n-`-XX:+UsePerfData`\n+[`-XX:+UsePerfData`]{#-XX__UsePerfData}\n@@ -2392,7 +2416,1 @@\n-`-XX:+AggressiveHeap`\n-:   Enables Java heap optimization. This sets various parameters to be\n-    optimal for long-running jobs with intensive memory allocation, based on\n-    the configuration of the computer (RAM and CPU). By default, the option\n-    is disabled and the heap sizes are configured less aggressively.\n-\n-`-XX:+AlwaysPreTouch`\n+[`-XX:+AlwaysPreTouch`]{#-XX__AlwaysPreTouch}\n@@ -2404,1 +2422,1 @@\n-`-XX:ConcGCThreads=`*threads*\n+[`-XX:ConcGCThreads=`]{#-XX_ConcGCThreads}*threads*\n@@ -2414,1 +2432,1 @@\n-`-XX:+DisableExplicitGC`\n+[`-XX:+DisableExplicitGC`]{#-XX__DisableExplicitGC}\n@@ -2420,1 +2438,1 @@\n-`-XX:+ExplicitGCInvokesConcurrent`\n+[`-XX:+ExplicitGCInvokesConcurrent`]{#-XX__ExplicitGCInvokesConcurrent}\n@@ -2424,1 +2442,1 @@\n-`-XX:G1AdaptiveIHOPNumInitialSamples=`*number*\n+[`-XX:G1AdaptiveIHOPNumInitialSamples=`]{#-XX_G1AdaptiveIHOPNumInitialSamples}*number*\n@@ -2431,1 +2449,1 @@\n-`-XX:G1HeapRegionSize=`*size*\n+[`-XX:G1HeapRegionSize=`]{#-XX_G1HeapRegionSize}*size*\n@@ -2442,1 +2460,1 @@\n-`-XX:G1HeapWastePercent=`*percent*\n+[`-XX:G1HeapWastePercent=`]{#-XX_G1HeapWastePercent}*percent*\n@@ -2448,1 +2466,1 @@\n-`-XX:G1MaxNewSizePercent=`*percent*\n+[`-XX:G1MaxNewSizePercent=`]{#-XX_G1MaxNewSizePercent}*percent*\n@@ -2455,1 +2473,1 @@\n-`-XX:G1MixedGCCountTarget=`*number*\n+[`-XX:G1MixedGCCountTarget=`]{#-XX_G1MixedGCCountTarget}*number*\n@@ -2461,1 +2479,1 @@\n-`-XX:G1MixedGCLiveThresholdPercent=`*percent*\n+[`-XX:G1MixedGCLiveThresholdPercent=`]{#-XX_G1MixedGCLiveThresholdPercent}*percent*\n@@ -2468,1 +2486,1 @@\n-`-XX:G1NewSizePercent=`*percent*\n+[`-XX:G1NewSizePercent=`]{#-XX_G1NewSizePercent}*percent*\n@@ -2475,1 +2493,1 @@\n-`-XX:G1OldCSetRegionThresholdPercent=`*percent*\n+[`-XX:G1OldCSetRegionThresholdPercent=`]{#-XX_G1OldCSetRegionThresholdPercent}*percent*\n@@ -2479,1 +2497,1 @@\n-`-XX:G1ReservePercent=`*percent*\n+[`-XX:G1ReservePercent=`]{#-XX_G1ReservePercent}*percent*\n@@ -2490,1 +2508,1 @@\n-`-XX:+G1UseAdaptiveIHOP`\n+[`-XX:+G1UseAdaptiveIHOP`]{#-XX__G1UseAdaptiveIHOP}\n@@ -2503,1 +2521,1 @@\n-`-XX:InitialHeapSize=`*size*\n+[`-XX:InitialHeapSize=`]{#-XX_InitialHeapSize}*size*\n@@ -2527,1 +2545,1 @@\n-`-XX:InitialRAMPercentage=`*percent*\n+[`-XX:InitialRAMPercentage=`]{#-XX_InitialRAMPercentage}*percent*\n@@ -2530,2 +2548,1 @@\n-    determined as described in the `-XX:MaxRAM` option. The default value is\n-    1.5625 percent.\n+    determined as described in the `-XX:MaxRAM` option.\n@@ -2538,1 +2555,1 @@\n-`-XX:InitialSurvivorRatio=`*ratio*\n+[`-XX:InitialSurvivorRatio=`]{#-XX_InitialSurvivorRatio}*ratio*\n@@ -2567,1 +2584,1 @@\n-`-XX:InitiatingHeapOccupancyPercent=`*percent*\n+[`-XX:InitiatingHeapOccupancyPercent=`]{#-XX_InitiatingHeapOccupancyPercent}*percent*\n@@ -2582,1 +2599,1 @@\n-`-XX:MaxGCPauseMillis=`*time*\n+[`-XX:MaxGCPauseMillis=`]{#-XX_MaxGCPauseMillis}*time*\n@@ -2584,4 +2601,3 @@\n-    soft goal, and the JVM will make its best effort to achieve it. The\n-    specified value doesn't adapt to your heap size. By default, for G1 the\n-    maximum pause time target is 200 milliseconds. The other generational\n-    collectors do not use a pause time goal by default.\n+    soft goal, and the JVM will make its best effort to achieve it. Only G1\n+    and Parallel support a maximum GC pause time target. For G1, the default\n+    maximum pause time target is 200 milliseconds.\n@@ -2594,1 +2610,1 @@\n-`-XX:MaxHeapSize=`*size*\n+[`-XX:MaxHeapSize=`]{#-XX_MaxHeapSize}*size*\n@@ -2614,1 +2630,1 @@\n-`-XX:MaxHeapFreeRatio=`*percent*\n+[`-XX:MaxHeapFreeRatio=`]{#-XX_MaxHeapFreeRatio}*percent*\n@@ -2635,1 +2651,1 @@\n-`-XX:MaxMetaspaceSize=`*size*\n+[`-XX:MaxMetaspaceSize=`]{#-XX_MaxMetaspaceSize}*size*\n@@ -2646,1 +2662,1 @@\n-`-XX:MaxNewSize=`*size*\n+[`-XX:MaxNewSize=`]{#-XX_MaxNewSize}*size*\n@@ -2650,20 +2666,1 @@\n-`-XX:MaxRAM=`*size*\n-:   Sets the maximum amount of memory that the JVM may use for the Java heap\n-    before applying ergonomics heuristics. The default value is the maximum\n-    amount of available memory to the JVM process or 128 GB, whichever is lower.\n-\n-    The maximum amount of available memory to the JVM process is the minimum\n-    of the machine's physical memory and any constraints set by the environment\n-    (e.g. container).\n-\n-    Specifying this option disables automatic use of compressed oops if\n-    the combined result of this and other options influencing the maximum amount\n-    of memory is larger than the range of memory addressable by compressed oops.\n-    See `-XX:UseCompressedOops` for further information about compressed oops.\n-\n-    The following example shows how to set the maximum amount of available\n-    memory for sizing the Java heap to 2 GB:\n-\n-    >   `-XX:MaxRAM=2G`\n-\n-`-XX:MaxRAMPercentage=`*percent*\n+[`-XX:MaxRAMPercentage=`]{#-XX_MaxRAMPercentage}*percent*\n@@ -2685,1 +2682,1 @@\n-`-XX:MinRAMPercentage=`*percent*\n+[`-XX:MinRAMPercentage=`]{#-XX_MinRAMPercentage}*percent*\n@@ -2696,1 +2693,1 @@\n-`-XX:MaxTenuringThreshold=`*threshold*\n+[`-XX:MaxTenuringThreshold=`]{#-XX_MaxTenuringThreshold}*threshold*\n@@ -2706,1 +2703,1 @@\n-`-XX:MetaspaceSize=`*size*\n+[`-XX:MetaspaceSize=`]{#-XX_MetaspaceSize}*size*\n@@ -2712,1 +2709,1 @@\n-`-XX:MinHeapFreeRatio=`*percent*\n+[`-XX:MinHeapFreeRatio=`]{#-XX_MinHeapFreeRatio}*percent*\n@@ -2733,1 +2730,1 @@\n-`-XX:MinHeapSize=`*size*\n+[`-XX:MinHeapSize=`]{#-XX_MinHeapSize}*size*\n@@ -2752,1 +2749,1 @@\n-`-XX:NewRatio=`*ratio*\n+[`-XX:NewRatio=`]{#-XX_NewRatio}*ratio*\n@@ -2759,1 +2756,1 @@\n-`-XX:NewSize=`*size*\n+[`-XX:NewSize=`]{#-XX_NewSize}*size*\n@@ -2783,1 +2780,1 @@\n-`-XX:ParallelGCThreads=`*threads*\n+[`-XX:ParallelGCThreads=`]{#-XX_ParallelGCThreads}*threads*\n@@ -2793,9 +2790,1 @@\n-`-XX:+ParallelRefProcEnabled`\n-:   Enables parallel reference processing. By default, collectors employing multiple\n-    threads perform parallel reference processing if the number of parallel threads\n-    to use is larger than one.\n-    The option is available only when the throughput or G1 garbage collector is used\n-    (`-XX:+UseParallelGC` or `-XX:+UseG1GC`). Other collectors employing multiple\n-    threads always perform reference processing in parallel.\n-\n-`-XX:+PrintAdaptiveSizePolicy`\n+[`-XX:+PrintAdaptiveSizePolicy`]{#-XX__PrintAdaptiveSizePolicy}\n@@ -2805,1 +2794,1 @@\n-`-XX:SoftRefLRUPolicyMSPerMB=`*time*\n+[`-XX:SoftRefLRUPolicyMSPerMB=`]{#-XX_SoftRefLRUPolicyMSPerMB}*time*\n@@ -2822,1 +2811,1 @@\n-`-XX:-ShrinkHeapInSteps`\n+[`-XX:-ShrinkHeapInSteps`]{#-XX__ShrinkHeapInSteps}\n@@ -2834,1 +2823,1 @@\n-`-XX:StringDeduplicationAgeThreshold=`*threshold*\n+[`-XX:StringDeduplicationAgeThreshold=`]{#-XX_StringDeduplicationAgeThreshold}*threshold*\n@@ -2845,1 +2834,1 @@\n-`-XX:SurvivorRatio=`*ratio*\n+[`-XX:SurvivorRatio=`]{#-XX_SurvivorRatio}*ratio*\n@@ -2852,1 +2841,1 @@\n-`-XX:TargetSurvivorRatio=`*percent*\n+[`-XX:TargetSurvivorRatio=`]{#-XX_TargetSurvivorRatio}*percent*\n@@ -2861,1 +2850,1 @@\n-`-XX:TLABSize=`*size*\n+[`-XX:TLABSize=`]{#-XX_TLABSize}*size*\n@@ -2871,1 +2860,1 @@\n-`-XX:+UseAdaptiveSizePolicy`\n+[`-XX:+UseAdaptiveSizePolicy`]{#-XX__UseAdaptiveSizePolicy}\n@@ -2877,1 +2866,1 @@\n-`-XX:+UseG1GC`\n+[`-XX:+UseG1GC`]{#-XX__UseG1GC}\n@@ -2887,1 +2876,1 @@\n-`-XX:+UseGCOverheadLimit`\n+[`-XX:+UseGCOverheadLimit`]{#-XX__UseGCOverheadLimit}\n@@ -2897,1 +2886,1 @@\n-`-XX:+UseNUMA`\n+[`-XX:+UseNUMA`]{#-XX__UseNUMA}\n@@ -2900,3 +2889,2 @@\n-    of lower latency memory. By default, this option is disabled and no\n-    optimization for NUMA is made. The option is available only when the\n-    parallel garbage collector is used (`-XX:+UseParallelGC`).\n+    of lower latency memory. The default value for this option depends on the\n+    garbage collector.\n@@ -2904,1 +2892,1 @@\n-`-XX:+UseParallelGC`\n+[`-XX:+UseParallelGC`]{#-XX__UseParallelGC}\n@@ -2911,1 +2899,1 @@\n-`-XX:+UseSerialGC`\n+[`-XX:+UseSerialGC`]{#-XX__UseSerialGC}\n@@ -2917,1 +2905,1 @@\n-`-XX:+UseStringDeduplication`\n+[`-XX:+UseStringDeduplication`]{#-XX__UseStringDeduplication}\n@@ -2927,1 +2915,1 @@\n-`-XX:+UseTLAB`\n+[`-XX:+UseTLAB`]{#-XX__UseTLAB}\n@@ -2932,1 +2920,1 @@\n-`-XX:+UseZGC`\n+[`-XX:+UseZGC`]{#-XX__UseZGC}\n@@ -2938,1 +2926,1 @@\n-`-XX:ZAllocationSpikeTolerance=`*factor*\n+[`-XX:ZAllocationSpikeTolerance=`]{#-XX_ZAllocationSpikeTolerance}*factor*\n@@ -2944,1 +2932,1 @@\n-`-XX:ZCollectionInterval=`*seconds*\n+[`-XX:ZCollectionInterval=`]{#-XX_ZCollectionInterval}*seconds*\n@@ -2948,1 +2936,1 @@\n-`-XX:ZFragmentationLimit=`*percent*\n+[`-XX:ZFragmentationLimit=`]{#-XX_ZFragmentationLimit}*percent*\n@@ -2954,1 +2942,1 @@\n-`-XX:+ZProactive`\n+[`-XX:+ZProactive`]{#-XX__ZProactive}\n@@ -2962,1 +2950,1 @@\n-`-XX:+ZUncommit`\n+[`-XX:+ZUncommit`]{#-XX__ZUncommit}\n@@ -2968,1 +2956,1 @@\n-`-XX:ZUncommitDelay=`*seconds*\n+[`-XX:ZUncommitDelay=`]{#-XX_ZUncommitDelay}*seconds*\n@@ -2975,0 +2963,40 @@\n+[`-XX:+UseShenandoahGC`]{#-XX__UseShenandoahGC}\n+:   Enables the use of the Shenandoah garbage collector. This is a low pause\n+    time, concurrent garbage collector. Its pause times are not proportional to\n+    the size of the heap. Shenandoah garbage collector can work with compressed\n+    pointers. See `-XX:UseCompressedOops` for further information about\n+    compressed pointers.\n+\n+[`-XX:ShenandoahGCMode=`]{#-XX_ShenandoahGCMode}*mode*\n+:   Sets the GC mode for Shenandoah GC to use. By default, this option is set\n+    to `satb`. Among other things, this defines which barriers are in use.\n+    Possible mode values include the following:\n+\n+    `satb`\n+    :   Snapshot-at-the-beginning concurrent GC (three pass mark-evac-update).\n+        It is a single generation GC.\n+\n+    `generational`\n+    :   It is also a snapshot-at-the-beginning and concurrent GC, but it is\n+        generational. Please see [JEP 404](https:\/\/openjdk.org\/jeps\/404) and\n+        [JEP 521](https:\/\/openjdk.org\/jeps\/521) for its advantages and risks.\n+\n+[`-XX:ShenandoahGCHeuristics=`]{#-XX_ShenandoahGCHeuristics}*heuristics*\n+:   Sets the heuristics for Shenandoah GC to use. By default, this option is\n+    set to `adaptive`. This fine-tunes the GC mode selected, by choosing when\n+    to start the GC, how much to process on each cycle, and what other features\n+    to automatically enable. When `-XX:ShenandoahGCMode` is `generational`, the\n+    only supported option is the default, `adaptive`.\n+\n+    Possible heuristics are the following:\n+\n+    `adaptive`\n+    :   To maintain the given amount of free heap at all times, even during\n+        the GC cycle.\n+\n+    `static`\n+    :   Trigger GC when free heap falls below a specified threshold.\n+\n+    `compact`\n+    :   Run GC more frequently and with deeper targets to free up more memory.\n+\n@@ -2981,1 +3009,1 @@\n-`-Xloggc:`*filename*\n+[`-Xloggc:`]{#-Xloggc_}*filename*\n@@ -2992,1 +3020,1 @@\n-`-XX:+FlightRecorder`\n+[`-XX:+FlightRecorder`]{#-XX__FlightRecorder}\n@@ -2996,0 +3024,53 @@\n+[`-XX:+ParallelRefProcEnabled`]{#-XX__ParallelRefProcEnabled}\n+:   Enables parallel reference processing. By default, collectors employing multiple\n+    threads perform parallel reference processing if the number of parallel threads\n+    to use is larger than one.\n+    The option is available only when the throughput or G1 garbage collector is used\n+    (`-XX:+UseParallelGC` or `-XX:+UseG1GC`). Other collectors employing multiple\n+    threads always perform reference processing in parallel.\n+\n+[`-XX:MaxRAM=`]{#-XX_MaxRAM}*size*\n+:   Sets the maximum amount of memory that the JVM may use for the Java heap\n+    before applying ergonomics heuristics. The default value is the amount of\n+    available memory to the JVM process.\n+\n+    The maximum amount of available memory to the JVM process is the minimum\n+    of the machine's physical memory and any constraints set by the environment\n+    (e.g. container).\n+\n+    Specifying this option disables automatic use of compressed oops if\n+    the combined result of this and other options influencing the maximum amount\n+    of memory is larger than the range of memory addressable by compressed oops.\n+    See `-XX:UseCompressedOops` for further information about compressed oops.\n+\n+    The following example shows how to set the maximum amount of available\n+    memory for sizing the Java heap to 2 GB:\n+\n+    >   `-XX:MaxRAM=2G`\n+\n+[`-XX:+AggressiveHeap`]{#-XX__AggressiveHeap}\n+:   Enables Java heap optimization. This sets various parameters to be\n+    optimal for long-running jobs with intensive memory allocation, based on\n+    the configuration of the computer (RAM and CPU). By default, the option\n+    is disabled and the heap sizes are configured less aggressively.\n+\n+[`-XX:+NeverActAsServerClassMachine`]{#-XX__NeverActAsServerClassMachine}\n+:   Enable the \"Client VM emulation\" mode which only uses the C1 JIT compiler,\n+    a 32Mb CodeCache and the Serial GC. The maximum amount of memory that the\n+    JVM may use (controlled by the `-XX:MaxRAM=n` flag) is set to 1GB by default.\n+    The string \"emulated-client\" is added to the JVM version string.\n+\n+    By default the flag is set to `true` only on Windows in 32-bit mode and\n+    `false` in all other cases.\n+\n+    The \"Client VM emulation\" mode will not be enabled if any of the following\n+    flags are used on the command line:\n+\n+    ```\n+    -XX:{+|-}TieredCompilation\n+    -XX:CompilationMode=mode\n+    -XX:TieredStopAtLevel=n\n+    -XX:{+|-}EnableJVMCI\n+    -XX:{+|-}UseJVMCICompiler\n+    ```\n+\n@@ -3001,1 +3082,1 @@\n-`--illegal-access=`*parameter*\n+[`--illegal-access=`]{#--illegal-access}*parameter*\n@@ -3010,62 +3091,1 @@\n-These `java` options have been removed in JDK @@VERSION_SPECIFICATION@@ and using them results in an error of:\n-\n->   `Unrecognized VM option` *option-name*\n-\n-`-XX:RTMAbortRatio=`*abort\\_ratio*\n-:   Specifies the RTM abort ratio is specified as a percentage (%) of all\n-    executed RTM transactions. If a number of aborted transactions becomes\n-    greater than this ratio, then the compiled code is deoptimized. This ratio\n-    is used when the `-XX:+UseRTMDeopt` option is enabled. The default value of\n-    this option is 50. This means that the compiled code is deoptimized if 50%\n-    of all transactions are aborted.\n-\n-`-XX:RTMRetryCount=`*number\\_of\\_retries*\n-:   Specifies the number of times that the RTM locking code is retried, when it\n-    is aborted or busy, before falling back to the normal locking mechanism.\n-    The default value for this option is 5. The `-XX:UseRTMLocking` option must\n-    be enabled.\n-\n-`-XX:+UseRTMDeopt`\n-:   Autotunes RTM locking depending on the abort ratio. This ratio is specified\n-    by the `-XX:RTMAbortRatio` option. If the number of aborted transactions\n-    exceeds the abort ratio, then the method containing the lock is deoptimized\n-    and recompiled with all locks as normal locks. This option is disabled by\n-    default. The `-XX:+UseRTMLocking` option must be enabled.\n-\n-`-XX:+UseRTMLocking`\n-:   Generates Restricted Transactional Memory (RTM) locking code for all\n-    inflated locks, with the normal locking mechanism as the fallback handler.\n-    This option is disabled by default. Options related to RTM are available\n-    only on x86 CPUs that support Transactional Synchronization Extensions (TSX).\n-\n-    RTM is part of Intel's TSX, which is an x86 instruction set extension and\n-    facilitates the creation of multithreaded applications. RTM introduces the\n-    new instructions `XBEGIN`, `XABORT`, `XEND`, and `XTEST`. The `XBEGIN` and\n-    `XEND` instructions enclose a set of instructions to run as a transaction.\n-    If no conflict is found when running the transaction, then the memory and\n-    register modifications are committed together at the `XEND` instruction.\n-    The `XABORT` instruction can be used to explicitly abort a transaction and\n-    the `XTEST` instruction checks if a set of instructions is being run in a\n-    transaction.\n-\n-    A lock on a transaction is inflated when another thread tries to access the\n-    same transaction, thereby blocking the thread that didn't originally\n-    request access to the transaction. RTM requires that a fallback set of\n-    operations be specified in case a transaction aborts or fails. An RTM lock\n-    is a lock that has been delegated to the TSX's system.\n-\n-    RTM improves performance for highly contended locks with low conflict in a\n-    critical region (which is code that must not be accessed by more than one\n-    thread concurrently). RTM also improves the performance of coarse-grain\n-    locking, which typically doesn't perform well in multithreaded\n-    applications. (Coarse-grain locking is the strategy of holding locks for\n-    long periods to minimize the overhead of taking and releasing locks, while\n-    fine-grained locking is the strategy of trying to achieve maximum\n-    parallelism by locking only when necessary and unlocking as soon as\n-    possible.) Also, for lightly contended locks that are used by different\n-    threads, RTM can reduce false cache line sharing, also known as cache line\n-    ping-pong. This occurs when multiple threads from different processors are\n-    accessing different resources, but the resources share the same cache line.\n-    As a result, the processors repeatedly invalidate the cache lines of other\n-    processors, which forces them to read from main memory instead of their\n-    cache.\n+No documented java options have been removed in JDK @@VERSION_SPECIFICATION@@.\n@@ -3075,0 +3095,4 @@\n+-   [The `java` Command, Release 26](https:\/\/docs.oracle.com\/en\/java\/javase\/26\/docs\/specs\/man\/java.html)\n+\n+-   [The `java` Command, Release 25](https:\/\/docs.oracle.com\/en\/java\/javase\/25\/docs\/specs\/man\/java.html)\n+\n@@ -3352,1 +3376,1 @@\n-`-Xlog`\n+[`-Xlog`]{#-Xlog}\n@@ -3639,1 +3663,1 @@\n-`-Xlog`\n+[`-Xlog`]{#-Xlog}\n@@ -3899,3 +3923,4 @@\n-(The names \"static\" and \"dynamic\" are used for historical reasons.\n-The only significance is that the \"static\" archive is loaded first and\n-the \"dynamic\" archive is loaded second).\n+The names \"static\" and \"dynamic\" are used for historical reasons. The dynamic\n+archive, while still useful, supports fewer optimizations than\n+available for the static CDS archive. If the full set of CDS\/AOT\n+optimizations are desired, consider using the AOT cache described below.\n@@ -4143,1 +4168,1 @@\n-`-XX:AOTCache=`*cachefile*\n+[`-XX:AOTCache=`]{#-XX_AOTCache}*cachefile*\n@@ -4152,1 +4177,1 @@\n-`-XX:AOTCacheOutput=`*cachefile*\n+[`-XX:AOTCacheOutput=`]{#-XX_AOTCacheOutput}*cachefile*\n@@ -4158,1 +4183,1 @@\n-`-XX:AOTConfiguration=`*configfile*\n+[`-XX:AOTConfiguration=`]{#-XX_AOTConfiguration}*configfile*\n@@ -4166,1 +4191,1 @@\n-`-XX:AOTMode=`*mode*\n+[`-XX:AOTMode=`]{#-XX_AOTMode}*mode*\n@@ -4238,1 +4263,1 @@\n-`-XX:+AOTClassLinking`\n+[`-XX:+AOTClassLinking`]{#-XX__AOTClassLinking}\n","filename":"src\/java.base\/share\/man\/java.md","additions":402,"deletions":377,"binary":false,"changes":779,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1995, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1995, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -33,1 +33,1 @@\n-#include \"defines.h\"\n+#include \"java.h\"\n@@ -37,1 +37,0 @@\n-#ifndef WIN32\n@@ -39,0 +38,14 @@\n+\n+\/\/ Unused, but retained for JLI_Launch compatibility\n+#define DOT_VERSION \"0.0\"\n+\n+\/\/ This is reported when requesting a full version\n+static char* launcher = LAUNCHER_NAME;\n+\n+\/\/ This is used as the name of the executable in the help message\n+static char* progname = PROGNAME;\n+\n+#ifdef JAVA_ARGS\n+static const char* jargs[] = JAVA_ARGS;\n+#else\n+static const char** jargs = NULL;\n@@ -40,2 +53,34 @@\n-#ifdef LINUX\n-#include <syscall.h>\n+static int jargc;\n+\n+static jboolean cpwildcard = CLASSPATH_WILDCARDS;\n+static jboolean disable_argfile = DISABLE_ARGFILE;\n+\n+#ifdef STATIC_BUILD\n+static void check_relauncher_argument(char* arg) {\n+    if (strcmp(arg, \"-J-DjavaLauncherWildcards=false\") == 0) {\n+        cpwildcard = JNI_FALSE;\n+    }\n+    const char *progname_prefix = \"-J-DjavaLauncherProgname=\";\n+    size_t progname_prefix_len = strlen(progname_prefix);\n+    if (strncmp(arg, progname_prefix, progname_prefix_len) == 0) {\n+        progname = arg + progname_prefix_len;\n+    }\n+    const char *args_prefix = \"-J-DjavaLauncherArgs=\";\n+    size_t args_prefix_len = strlen(args_prefix);\n+    if (strncmp(arg, args_prefix, args_prefix_len) == 0) {\n+        char* java_args_ptr = arg + args_prefix_len;\n+        size_t java_args_len = strlen(arg) - args_prefix_len;\n+\n+        JLI_List java_args = JLI_List_new(java_args_len);\n+        char* next_space;\n+        while ((next_space = strchr(java_args_ptr, ' ')) != NULL) {\n+            size_t next_arg_len = next_space - java_args_ptr;\n+            JLI_List_addSubstring(java_args, java_args_ptr, next_arg_len);\n+            java_args_ptr = next_space + 1;\n+        }\n+        JLI_List_add(java_args, java_args_ptr);\n+\n+        jargc = (int) java_args->size;\n+        jargs = (const char**) java_args->elements;\n+    }\n+}\n@@ -54,1 +99,1 @@\n-    const jboolean const_javaw = JNI_TRUE;\n+    const jboolean javaw = JNI_TRUE;\n@@ -211,1 +256,1 @@\n-    const jboolean const_javaw = JNI_FALSE;\n+    const jboolean javaw = JNI_FALSE;\n@@ -216,4 +261,2 @@\n-    int jargc;\n-    const char** jargv = const_jargs;\n-    jargc = (sizeof(const_jargs) \/ sizeof(char *)) > 1\n-        ? sizeof(const_jargs) \/ sizeof(char *)\n+    jargc = (sizeof(jargs) \/ sizeof(char *)) > 1\n+        ? sizeof(jargs) \/ sizeof(char *)\n@@ -223,1 +266,9 @@\n-    JLI_InitArgProcessing(jargc > 0, const_disable_argfile);\n+#ifdef STATIC_BUILD\n+        \/\/ Relaunchers always give -J-DjavaLauncherArgFiles as the first argument, if present\n+        \/\/ We must check disable_argfile before calling JLI_InitArgProcessing.\n+        if (argc > 1 && strcmp(argv[1], \"-J-DjavaLauncherArgFiles=false\") == 0) {\n+            disable_argfile = JNI_TRUE;\n+        }\n+#endif\n+\n+    JLI_InitArgProcessing(jargc > 0, disable_argfile);\n@@ -262,0 +313,3 @@\n+#ifdef STATIC_BUILD\n+            check_relauncher_argument(margv[i]);\n+#endif\n@@ -286,0 +340,3 @@\n+#ifdef STATIC_BUILD\n+            check_relauncher_argument(argv[i]);\n+#endif\n@@ -378,1 +435,1 @@\n-                   jargc, jargv,\n+                   jargc, jargs,\n@@ -382,2 +439,2 @@\n-                   (const_progname != NULL) ? const_progname : *margv,\n-                   (const_launcher != NULL) ? const_launcher : *margv,\n+                   progname,\n+                   launcher,\n@@ -385,1 +442,1 @@\n-                   const_cpwildcard, const_javaw, 0);\n+                   cpwildcard, javaw, 0);\n","filename":"src\/java.base\/share\/native\/launcher\/main.c","additions":73,"deletions":16,"binary":false,"changes":89,"status":"modified"},{"patch":"@@ -582,0 +582,1 @@\n+#ifdef USE_MMAP\n@@ -583,0 +584,1 @@\n+#endif\n@@ -607,0 +609,1 @@\n+#ifdef USE_MMAP\n@@ -608,0 +611,1 @@\n+#endif\n","filename":"src\/java.base\/share\/native\/libzip\/zip_util.c","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2025, Oracle and\/or its affiliates. All rights reserved.\n","filename":"src\/java.base\/unix\/classes\/java\/lang\/ProcessImpl.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+    private static final boolean SUPPORTS_PENDING_SIGNALS = NativeThread.supportPendingSignals();\n@@ -119,3 +120,1 @@\n-    @Override\n-    void implPreClose(FileDescriptor fd, long reader, long writer) throws IOException {\n-        preClose0(fd);\n+    private void signalThreads(long reader, long writer) {\n@@ -128,0 +127,11 @@\n+    @Override\n+    void implPreClose(FileDescriptor fd, long reader, long writer) throws IOException {\n+        if (SUPPORTS_PENDING_SIGNALS) {\n+            signalThreads(reader, writer);\n+        }\n+        preClose0(fd);\n+        if (!SUPPORTS_PENDING_SIGNALS) {\n+            signalThreads(reader, writer);\n+        }\n+    }\n+\n","filename":"src\/java.base\/unix\/classes\/sun\/nio\/ch\/UnixDispatcher.java","additions":13,"deletions":3,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -279,0 +279,3 @@\n+    \/* Compute\/set the name of the executable *\/\n+    SetExecname(*pargv);\n+\n@@ -300,3 +303,0 @@\n-    \/* Compute\/set the name of the executable *\/\n-    SetExecname(*pargv);\n-\n","filename":"src\/java.base\/unix\/native\/libjli\/java_md.c","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -114,1 +114,2 @@\n-    error = getaddrinfo(hostname, NULL, &hints, &res);\n+    NET_RESTARTABLE(error, getaddrinfo(hostname, NULL, &hints, &res),\n+                    error == EAI_SYSTEM && errno == EINTR);\n@@ -235,4 +236,7 @@\n-    if (getnameinfo((struct sockaddr *)&sa, sizeof(struct sockaddr_in),\n-                    host, sizeof(host), NULL, 0, NI_NAMEREQD)) {\n-        JNU_ThrowByName(env, \"java\/net\/UnknownHostException\", NULL);\n-    } else {\n+    int r;\n+\n+    NET_RESTARTABLE(r, getnameinfo((struct sockaddr *)&sa, sizeof(struct sockaddr_in),\n+                                   host, sizeof(host), NULL, 0, NI_NAMEREQD),\n+                    r == EAI_SYSTEM && errno == EINTR);\n+\n+    if (r == 0) {\n@@ -240,2 +244,2 @@\n-        if (ret == NULL) {\n-            JNU_ThrowByName(env, \"java\/net\/UnknownHostException\", NULL);\n+        if (ret != NULL) {\n+            return ret;\n@@ -245,1 +249,2 @@\n-    return ret;\n+    JNU_ThrowByName(env, \"java\/net\/UnknownHostException\", NULL);\n+    return NULL;\n@@ -289,1 +294,2 @@\n-    connect_rv = connect(fd, &sa->sa, sizeof(struct sockaddr_in));\n+    NET_RESTARTABLE(connect_rv, connect(fd, &sa->sa, sizeof(struct sockaddr_in)),\n+                    connect_rv == -1 && errno == EINTR);\n@@ -407,0 +413,1 @@\n+\n@@ -408,1 +415,3 @@\n-        n = sendto(fd, sendbuf, plen, 0, &sa->sa, sizeof(struct sockaddr_in));\n+        NET_RESTARTABLE(n, sendto(fd, sendbuf, plen, 0, &sa->sa, sizeof(struct sockaddr_in)),\n+                        n == -1 && errno == EINTR)\n+\n@@ -432,2 +441,3 @@\n-                n = recvfrom(fd, recvbuf, sizeof(recvbuf), 0,\n-                             (struct sockaddr *)&sa_recv, &len);\n+                NET_RESTARTABLE(n, recvfrom(fd, recvbuf, sizeof(recvbuf), 0,\n+                                      (struct sockaddr *)&sa_recv, &len),\n+                                      n == -1 && errno == EINTR);\n","filename":"src\/java.base\/unix\/native\/libnet\/Inet4AddressImpl.c","additions":23,"deletions":13,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -233,1 +233,2 @@\n-    error = getaddrinfo(hostname, NULL, &hints, &res);\n+    NET_RESTARTABLE(error, getaddrinfo(hostname, NULL, &hints, &res),\n+                                      error == EAI_SYSTEM && errno == EINTR);\n@@ -436,3 +437,6 @@\n-    if (getnameinfo(&sa.sa, len, host, sizeof(host), NULL, 0, NI_NAMEREQD)) {\n-        JNU_ThrowByName(env, \"java\/net\/UnknownHostException\", NULL);\n-    } else {\n+    int r;\n+\n+    NET_RESTARTABLE(r, getnameinfo(&sa.sa, len, host, sizeof(host), NULL, 0, NI_NAMEREQD),\n+                    r == EAI_SYSTEM && errno == EINTR);\n+\n+    if (r == 0) {\n@@ -440,2 +444,2 @@\n-        if (ret == NULL) {\n-            JNU_ThrowByName(env, \"java\/net\/UnknownHostException\", NULL);\n+        if (ret != NULL) {\n+            return ret;\n@@ -445,1 +449,2 @@\n-    return ret;\n+    JNU_ThrowByName(env, \"java\/net\/UnknownHostException\", NULL);\n+    return NULL;\n@@ -489,1 +494,2 @@\n-    connect_rv = connect(fd, &sa->sa, sizeof(struct sockaddr_in6));\n+    NET_RESTARTABLE(connect_rv, connect(fd, &sa->sa, sizeof(struct sockaddr_in6)),\n+                    connect_rv == -1 && errno == EINTR);\n@@ -614,1 +620,4 @@\n-        n = sendto(fd, sendbuf, plen, 0, &sa->sa, sizeof(struct sockaddr_in6));\n+\n+        NET_RESTARTABLE(n, sendto(fd, sendbuf, plen, 0, &sa->sa, sizeof(struct sockaddr_in6)),\n+                        n == -1 && errno == EINTR);\n+\n@@ -638,2 +647,3 @@\n-                n = recvfrom(fd, recvbuf, sizeof(recvbuf), 0,\n-                             (struct sockaddr *)&sa_recv, &len);\n+                NET_RESTARTABLE(n, recvfrom(fd, recvbuf, sizeof(recvbuf), 0,\n+                                   (struct sockaddr *)&sa_recv, &len),\n+                                   n == -1 && errno == EINTR);\n","filename":"src\/java.base\/unix\/native\/libnet\/Inet6AddressImpl.c","additions":21,"deletions":11,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2013, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -51,0 +51,3 @@\n+    \/\/ AOT Subsystem\n+    public boolean endAOTRecording();\n+\n@@ -58,0 +61,1 @@\n+    public long    getTotalGcCpuTime();\n","filename":"src\/java.management\/share\/classes\/sun\/management\/VMManagement.java","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -120,0 +120,3 @@\n+    \/\/ AOT Subsystem\n+    public native boolean endAOTRecording();\n+\n@@ -131,0 +134,1 @@\n+    public native long getTotalGcCpuTime();\n","filename":"src\/java.management\/share\/classes\/sun\/management\/VMManagementImpl.java","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -104,0 +104,7 @@\n+JNIEXPORT jboolean JNICALL\n+Java_sun_management_VMManagementImpl_endAOTRecording\n+  (JNIEnv *env, jobject dummy)\n+{\n+    return JVM_AOTEndRecording(env);\n+}\n+\n@@ -124,0 +131,7 @@\n+JNIEXPORT jlong JNICALL\n+Java_sun_management_VMManagementImpl_getTotalGcCpuTime\n+  (JNIEnv *env, jobject dummy)\n+{\n+    return jmm_interface->GetLongAttribute(env, NULL, JMM_TOTAL_GC_CPU_TIME);\n+}\n+\n","filename":"src\/java.management\/share\/native\/libmanagement\/VMManagementImpl.c","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -291,0 +291,1 @@\n+        HYBRID,\n","filename":"src\/jdk.internal.vm.ci\/share\/classes\/jdk\/vm\/ci\/amd64\/AMD64.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -187,1 +187,1 @@\n-    jvmtiCompileTimeMajorVersion  = ( JVMTI_VERSION & JVMTI_VERSION_MASK_MAJOR )\n+    jvmtiCompileTimeMajorVersion  = ((unsigned)JVMTI_VERSION & JVMTI_VERSION_MASK_MAJOR)\n@@ -189,1 +189,1 @@\n-    jvmtiCompileTimeMinorVersion  = ( JVMTI_VERSION & JVMTI_VERSION_MASK_MINOR )\n+    jvmtiCompileTimeMinorVersion  = ((unsigned)JVMTI_VERSION & JVMTI_VERSION_MASK_MINOR)\n@@ -191,1 +191,1 @@\n-    jvmtiCompileTimeMicroVersion  = ( JVMTI_VERSION & JVMTI_VERSION_MASK_MICRO )\n+    jvmtiCompileTimeMicroVersion  = ((unsigned)JVMTI_VERSION & JVMTI_VERSION_MASK_MICRO)\n@@ -898,2 +898,0 @@\n- \"debugflags=flags             debug flags (bitmask)           none\\n\"\n- \"                               USE_ITERATE_THROUGH_HEAP 0x01\\n\"\n@@ -1200,7 +1198,0 @@\n-        } else if (strcmp(buf, \"debugflags\") == 0) {\n-            \/*LINTED*\/\n-            if (!get_tok(&str, current, (int)(end - current), ',')) {\n-                goto syntax_error;\n-            }\n-            \/*LINTED*\/\n-            gdata->debugflags = (unsigned)strtol(current, NULL, 0);\n","filename":"src\/jdk.jdwp.agent\/share\/native\/libjdwp\/debugInit.c","additions":4,"deletions":13,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -62,0 +62,8 @@\n+\/* To handle \"format string is not a string literal\" warning. *\/\n+#if !defined(_MSC_VER)\n+  #define ATTRIBUTE_PRINTF(fmt_pos_num, vargs_pos_num) \\\n+          __attribute__((format(printf, fmt_pos_num, vargs_pos_num)))\n+#else\n+  #define ATTRIBUTE_PRINTF(fmt_pos_num, vargs_pos_num)\n+#endif\n+\n@@ -95,6 +103,0 @@\n-    \/* Debug flags (bit mask) *\/\n-    int      debugflags;\n-\n-    \/* Possible debug flags *\/\n-    #define USE_ITERATE_THROUGH_HEAP 0X001\n-\n","filename":"src\/jdk.jdwp.agent\/share\/native\/libjdwp\/util.h","additions":9,"deletions":7,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -36,0 +36,1 @@\n+#include <fcntl.h>\n@@ -54,0 +55,15 @@\n+static int\n+markCloseOnExec(int fd)\n+{\n+    const int flags = fcntl(fd, F_GETFD);\n+    if (flags < 0) {\n+        return -1;\n+    }\n+    if ((flags & FD_CLOEXEC) == 0) {\n+        if (fcntl(fd, F_SETFD, flags | FD_CLOEXEC) < 0) {\n+            return -1;\n+        }\n+    }\n+    return 0;\n+}\n+\n@@ -63,5 +79,4 @@\n-\/\/ Closes every file descriptor that is listed as a directory\n-\/\/ entry in \"\/proc\/self\/fd\" (or its equivalent). Standard\n-\/\/ input\/output\/error file descriptors will not be closed\n-\/\/ by this function. This function returns 0 on failure\n-\/\/ and 1 on success.\n+\/\/ Marks all file descriptors found in \/proc\/self\/fd with the\n+\/\/ FD_CLOEXEC flag to ensure they are automatically closed\n+\/\/ upon execution of a new program via exec(). This function\n+\/\/ returns -1 on failure and 0 on success.\n@@ -69,1 +84,1 @@\n-closeDescriptors(void)\n+markDescriptorsCloseOnExec(void)\n@@ -73,15 +88,1 @@\n-    \/* leave out standard input\/output\/error descriptors *\/\n-    int from_fd = STDERR_FILENO + 1;\n-\n-    \/* We're trying to close all file descriptors, but opendir() might\n-     * itself be implemented using a file descriptor, and we certainly\n-     * don't want to close that while it's in use.  We assume that if\n-     * opendir() is implemented using a file descriptor, then it uses\n-     * the lowest numbered file descriptor, just like open().  So\n-     * before calling opendir(), we close a couple explicitly, so that\n-     * opendir() can then use these lowest numbered closed file\n-     * descriptors afresh.   *\/\n-\n-    close(from_fd);          \/* for possible use by opendir() *\/\n-    close(from_fd + 1);      \/* another one for good luck *\/\n-    from_fd += 2; \/* leave out the 2 we just closed, which the opendir() may use *\/\n+    const int from_fd = STDERR_FILENO;\n@@ -90,2 +91,1 @@\n-    \/* set FD_DIR for AIX which does not understand '\/proc\/self' - it\n-     * requires the real process ID *\/\n+    \/* AIX does not understand '\/proc\/self' - it requires the real process ID *\/\n@@ -103,1 +103,1 @@\n-                       \" file descriptors to close for process %d\",\n+                       \" file descriptors to mark or close for process %d\",\n@@ -105,1 +105,1 @@\n-        return 0; \/\/ failure\n+        return -1; \/\/ failure\n@@ -108,0 +108,2 @@\n+    int dir_fd = dirfd(dp);\n+\n@@ -112,3 +114,5 @@\n-        const long fd = strtol(dirp->d_name, NULL, 10);\n-        if (fd <= INT_MAX && fd >= from_fd) {\n-            (void)close((int)fd);\n+        int fd = strtol(dirp->d_name, NULL, 10);\n+        if (fd <= INT_MAX && fd > from_fd && fd != dir_fd) {\n+            if (markCloseOnExec(fd) == -1) {\n+                (void)close((int)fd);\n+            }\n@@ -120,1 +124,1 @@\n-    return 1; \/\/ success\n+    return 0; \/\/ success\n@@ -123,3 +127,4 @@\n-\/\/ Does necessary housekeeping of a forked child process\n-\/\/ (like closing copied file descriptors) before\n-\/\/ execing the child process. This function never returns.\n+\/\/ Performs necessary housekeeping in the forked child process,\n+\/\/ such as marking copied file descriptors (except standard input\/output\/error)\n+\/\/ with FD_CLOEXEC to ensure they are closed during exec().\n+\/\/ This function never returns.\n@@ -129,3 +134,4 @@\n-    \/* Close all file descriptors that have been copied over\n-     * from the parent process due to fork(). *\/\n-    if (closeDescriptors() == 0) { \/* failed,  close the old way *\/\n+    \/* Mark all file descriptors (except standard input\/output\/error)\n+     * copied from the parent process with FD_CLOEXEC, so they are\n+     * closed automatically upon exec(). *\/\n+    if (markDescriptorsCloseOnExec() < 0) { \/* failed,  close the old way *\/\n@@ -143,1 +149,1 @@\n-                       \" %d file descriptors sequentially\", (max_fd - i + 1)));\n+                       \" %d file descriptors sequentially\", (max_fd - i)));\n","filename":"src\/jdk.jdwp.agent\/unix\/native\/libjdwp\/exec_md.c","additions":43,"deletions":37,"binary":false,"changes":80,"status":"modified"},{"patch":"@@ -276,0 +276,2 @@\n+     * Use {@link #setCPUPeriod(long)} if you want a fixed sampling period instead.\n+     *\n@@ -279,2 +281,12 @@\n-     * @param autoAdapt true if the rate should be adapted automatically\n-    public static native void setCPUThrottle(double rate, boolean autoAdapt);\n+    public static native void setCPURate(double rate);\n+\n+    \/**\n+     * Set the fixed CPU time sampler period.\n+     *\n+     * Use {@link #setCPURate(double)} if you want a fixed rate with an auto-adjusted period instead.\n+     *\n+     * Setting period to 0 turns off the CPU time sampler.\n+     *\n+     * @param periodNanos the new fixed period in nanoseconds\n+     *\/\n+    public static native void setCPUPeriod(long periodNanos);\n","filename":"src\/jdk.jfr\/share\/classes\/jdk\/jfr\/internal\/JVM.java","additions":14,"deletions":2,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -364,1 +364,1 @@\n-        PeriodicEvents.doChunkBegin();\n+        PeriodicEvents.doChunkBegin(true);\n@@ -436,1 +436,1 @@\n-            PeriodicEvents.doChunkBegin();\n+            PeriodicEvents.doChunkBegin(false);\n@@ -491,1 +491,1 @@\n-        PeriodicEvents.doChunkBegin();\n+        PeriodicEvents.doChunkBegin(false);\n","filename":"src\/jdk.jfr\/share\/classes\/jdk\/jfr\/internal\/PlatformRecorder.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+import java.nio.channels.FileLock;\n@@ -747,1 +748,8 @@\n-        try (ChunksChannel cc = new ChunksChannel(chunks); FileChannel fc = FileChannel.open(path.getReal(), StandardOpenOption.WRITE, StandardOpenOption.APPEND)) {\n+        \/\/ Before writing, wipe the file if it already exists.\n+        try (ChunksChannel cc = new ChunksChannel(chunks); FileChannel fc = FileChannel.open(path.getReal(), StandardOpenOption.WRITE, StandardOpenOption.TRUNCATE_EXISTING,  StandardOpenOption.CREATE)) {\n+            \/\/ Mitigate races against other processes\n+            FileLock l = fc.tryLock();\n+            if (l == null) {\n+                Logger.log(LogTag.JFR, LogLevel.INFO, \"Dump operation skipped for recording \\\"\" + name + \"\\\" (\" + id + \"). File \" + path.getRealPathText() + \" is locked by other dump operation or activity.\");\n+                return;\n+            }\n","filename":"src\/jdk.jfr\/share\/classes\/jdk\/jfr\/internal\/PlatformRecording.java","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2011, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2011, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -198,1 +198,1 @@\n-    if (read_ticks(\"\/proc\/self\/stat\", &userTicks, &systemTicks) < 0) {\n+    if (read_ticks(\"\/proc\/self\/stat\", &userTicks, &systemTicks) != 2) {\n","filename":"src\/jdk.management\/linux\/native\/libmanagement_ext\/UnixOperatingSystem.c","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -43,0 +43,1 @@\n+import jdk.management.HotSpotAOTCacheMXBean;\n@@ -170,0 +171,35 @@\n+        \/**\n+        * HotSpotAOTCacheMXBean.\n+        *\/\n+        initMBeanList.add(new PlatformComponent<HotSpotAOTCacheMXBean>() {\n+            private final Set<Class<? extends HotSpotAOTCacheMXBean>> mbeanInterfaces =\n+                    Set.of(HotSpotAOTCacheMXBean.class);\n+            private final Set<String> mbeanInterfaceNames =\n+                    Set.of(HotSpotAOTCacheMXBean.class.getName());\n+            private HotSpotAOTCacheMXBean impl;\n+\n+            @Override\n+            public Set<Class<? extends HotSpotAOTCacheMXBean>> mbeanInterfaces() {\n+                return mbeanInterfaces;\n+            }\n+\n+            @Override\n+            public Set<String> mbeanInterfaceNames() {\n+                return mbeanInterfaceNames;\n+            }\n+\n+            @Override\n+            public String getObjectNamePattern() {\n+                return \"jdk.management:type=HotSpotAOTCache\";\n+            }\n+\n+            @Override\n+            public Map<String, HotSpotAOTCacheMXBean> nameToMBeanMap() {\n+                HotSpotAOTCacheMXBean impl = this.impl;\n+                if (impl == null) {\n+                    this.impl = impl = new HotSpotAOTCacheImpl(ManagementFactoryHelper.getVMManagement());\n+                }\n+                return Map.of(\"jdk.management:type=HotSpotAOTCache\", impl);\n+            }\n+        });\n+\n","filename":"src\/jdk.management\/share\/classes\/com\/sun\/management\/internal\/PlatformMBeanProviderImpl.java","additions":37,"deletions":1,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -52,1 +52,1 @@\n-compiler\/loopopts\/TestUnreachableInnerLoop.java 8288981 linux-s390x\n+compiler\/runtime\/Test7196199.java 8365196 windows-x64\n@@ -69,0 +69,1 @@\n+compiler\/jvmci\/jdk.vm.ci.code.test\/src\/jdk\/vm\/ci\/code\/test\/CodeInvalidationReasonTest.java 8360168 linux-riscv64\n@@ -77,6 +78,1 @@\n-compiler\/ciReplay\/TestInliningProtectionDomain.java 8349191 generic-all\n-compiler\/ciReplay\/TestIncrementalInlining.java 8349191 generic-all\n-\n-compiler\/c2\/TestVerifyConstraintCasts.java 8355574 generic-all\n-\n-compiler\/startup\/StartupOutput.java 8358129 windows-all\n+compiler\/c2\/aarch64\/TestStaticCallStub.java 8359963 linux-aarch64,macosx-aarch64\n@@ -89,1 +85,0 @@\n-gc\/g1\/humongousObjects\/objectGraphTest\/TestObjectGraphAfterGC.java 8156755 generic-all\n@@ -98,0 +93,3 @@\n+gc\/shenandoah\/TestRetainObjects.java#no-tlab 8361099 generic-all\n+gc\/shenandoah\/TestSieveObjects.java#no-tlab 8361099 generic-all\n+gc\/shenandoah\/TestSieveObjects.java#no-tlab-genshen 8361099 generic-all\n@@ -128,1 +126,2 @@\n-serviceability\/sa\/sadebugd\/DebugdConnectTest.java 8239062,8270326 macosx-x64,macosx-aarch64\n+# 8239062 and 8270326 only affects macosx-x64,macosx-aarch64\n+serviceability\/sa\/sadebugd\/DebugdConnectTest.java 8239062,8270326 generic-all\n@@ -131,1 +130,0 @@\n-serviceability\/jvmti\/ModuleAwareAgents\/ThreadStart\/MAAThreadStart.java 8225354 windows-all\n@@ -145,0 +143,2 @@\n+serviceability\/sa\/ClhsdbThreadContext.java        8356704 windows-x64\n+\n@@ -168,1 +168,1 @@\n-vmTestbase\/nsk\/jvmti\/AttachOnDemand\/attach045\/TestDescription.java 8358094 generic-all\n+vmTestbase\/nsk\/jvmti\/scenarios\/events\/EM02\/em02t006\/TestDescription.java 8372206 generic-all\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":11,"deletions":11,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -3,1 +3,1 @@\n-# Copyright (c) 2009, 2025, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2009, 2026, Oracle and\/or its affiliates. All rights reserved.\n@@ -153,0 +153,1 @@\n+java\/awt\/List\/NoEvents\/ProgrammaticChange.java 8201307 linux-all\n@@ -154,2 +155,1 @@\n-java\/awt\/Mixing\/AWT_Mixing\/HierarchyBoundsListenerMixingTest.java 8049405 macosx-all\n-java\/awt\/Mixing\/AWT_Mixing\/OpaqueOverlapping.java 8294264 windows-x64\n+java\/awt\/Mixing\/AWT_Mixing\/OpaqueOverlapping.java 8370584 windows-x64\n@@ -163,27 +163,1 @@\n-java\/awt\/Mixing\/AWT_Mixing\/JButtonInGlassPaneOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JButtonOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JColorChooserOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JEditorPaneInGlassPaneOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JEditorPaneOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JLabelInGlassPaneOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JLabelOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JListInGlassPaneOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JListOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JPanelInGlassPaneOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JPanelOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JProgressBarInGlassPaneOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JProgressBarOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JScrollBarInGlassPaneOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JScrollBarOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JSliderInGlassPaneOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JSliderOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JSpinnerInGlassPaneOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JSpinnerOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JTableInGlassPaneOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JTableOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JTextAreaInGlassPaneOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JTextAreaOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JTextFieldInGlassPaneOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JTextFieldOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JToggleButtonInGlassPaneOverlapping.java 8158801 windows-all\n-java\/awt\/Mixing\/AWT_Mixing\/JToggleButtonOverlapping.java 8158801 windows-all\n+java\/awt\/Mixing\/AWT_Mixing\/JTableInGlassPaneOverlapping.java 8357360 windows-all,linux-all\n@@ -191,1 +165,0 @@\n-java\/awt\/Mouse\/EnterExitEvents\/DragWindowTest.java 8298823 macosx-all\n@@ -252,0 +225,1 @@\n+sun\/java2d\/OpenGL\/OpaqueDest.java#id1 8367574 macosx-all\n@@ -258,1 +232,0 @@\n-sun\/java2d\/X11SurfaceData\/SharedMemoryPixmapsTest\/SharedMemoryPixmapsTest.sh 7184899,8221451 linux-all,macosx-aarch64\n@@ -263,1 +236,0 @@\n-java\/awt\/Choice\/ChoiceMouseWheelTest\/ChoiceMouseWheelTest.java 6849371 macosx-all,linux-all\n@@ -274,0 +246,1 @@\n+java\/awt\/Dialog\/ModalExcludedTest.java 7125054 macosx-all\n@@ -413,1 +386,0 @@\n-java\/awt\/Modal\/ToFront\/DialogToFrontModeless1Test.java 8213530 linux-all\n@@ -457,2 +429,0 @@\n-java\/awt\/SplashScreen\/MultiResolutionSplash\/unix\/UnixMultiResolutionSplashTest.java 8203004 linux-all\n-java\/awt\/ScrollPane\/ScrollPositionTest.java 8040070 linux-all\n@@ -477,1 +447,1 @@\n-java\/awt\/PopupMenu\/PopupMenuLocation.java 8259913,8315878 windows-all,macosx-aarch64\n+java\/awt\/PopupMenu\/PopupMenuLocation.java 8259913 windows-all\n@@ -494,2 +464,0 @@\n-java\/awt\/KeyboardFocusmanager\/ConsumeNextMnemonicKeyTypedTest\/ConsumeNextMnemonicKeyTypedTest.java 8321303 linux-all\n-java\/awt\/Window\/GetScreenLocation\/GetScreenLocationTest.java 8225787 linux-x64\n@@ -509,0 +477,1 @@\n+sun\/awt\/image\/bug8038000.java 8373065 generic-all\n@@ -556,1 +525,1 @@\n-java\/io\/IO\/IO.java                                              8337935 linux-ppc64le\n+java\/lang\/IO\/IO.java                                            8337935 linux-ppc64le\n@@ -562,2 +531,0 @@\n-com\/sun\/management\/OperatingSystemMXBean\/GetProcessCpuLoad.java 8030957 aix-all\n-com\/sun\/management\/OperatingSystemMXBean\/GetSystemCpuLoad.java  8030957 aix-all\n@@ -566,1 +533,0 @@\n-java\/lang\/management\/MemoryMXBean\/PendingAllGC.sh               8158837 generic-all\n@@ -578,1 +544,0 @@\n-javax\/management\/MBeanServer\/OldMBeanServerTest.java            8030957 aix-all\n@@ -601,2 +566,0 @@\n-java\/net\/Socket\/asyncClose\/Race.java                            8317801 aix-ppc64\n-\n@@ -607,2 +570,0 @@\n-java\/nio\/channels\/Channels\/SocketChannelStreams.java            8317838 aix-ppc64\n-\n@@ -625,2 +586,0 @@\n-java\/rmi\/transport\/checkLeaseInfoLeak\/CheckLeaseLeak.java       7191877 generic-all\n-\n@@ -629,1 +588,0 @@\n-\n@@ -663,3 +621,0 @@\n-javax\/sound\/sampled\/DirectAudio\/bug6372428.java                      8055097 generic-all\n-javax\/sound\/sampled\/Clip\/bug5070081.java                             8055097 generic-all\n-javax\/sound\/sampled\/DataLine\/LongFramePosition.java                  8055097 generic-all\n@@ -669,7 +624,0 @@\n-javax\/sound\/sampled\/Mixers\/DisabledAssertionCrash.java 7067310 generic-all\n-\n-javax\/sound\/midi\/Sequencer\/Recording.java 8167580,8265485 linux-all,macosx-aarch64\n-javax\/sound\/midi\/Sequencer\/Looping.java 8136897 generic-all\n-javax\/sound\/sampled\/Clip\/ClipIsRunningAfterStop.java 8307574 linux-x64\n-javax\/sound\/sampled\/Clip\/ClipFlushCrash.java 8308395 linux-x64\n-\n@@ -700,1 +648,0 @@\n-javax\/swing\/JTabbedPane\/4624207\/bug4624207.java 8064922 macosx-all\n@@ -739,2 +686,0 @@\n-com\/sun\/jdi\/RepStep.java                                        8043571 generic-all\n-\n@@ -762,5 +707,0 @@\n-sun\/tools\/jstat\/jstatLineCounts1.sh                             8248691,8268211 linux-ppc64le,aix-ppc64,linux-aarch64\n-sun\/tools\/jstat\/jstatLineCounts2.sh                             8248691,8268211 linux-ppc64le,aix-ppc64,linux-aarch64\n-sun\/tools\/jstat\/jstatLineCounts3.sh                             8248691,8268211 linux-ppc64le,aix-ppc64,linux-aarch64\n-sun\/tools\/jstat\/jstatLineCounts4.sh                             8248691,8268211 linux-ppc64le,aix-ppc64,linux-aarch64\n-\n@@ -781,1 +721,1 @@\n-jdk\/jfr\/jvm\/TestWaste.java                                      8282427 generic-all\n+jdk\/jfr\/jvm\/TestWaste.java                                      8371630 generic-all\n@@ -803,1 +743,0 @@\n-javax\/swing\/JTabbedPane\/bug4666224.java 8144124  macosx-all\n@@ -812,2 +751,0 @@\n-java\/awt\/Modal\/PrintDialogsTest\/PrintDialogsTest.java 8068378 generic-all\n-java\/awt\/event\/MouseEvent\/AltGraphModifierTest\/AltGraphModifierTest.java 8162380 generic-all\n@@ -823,0 +760,1 @@\n+java\/awt\/FileDialog\/DoubleActionESC.java 8356981 linux-all\n@@ -828,1 +766,0 @@\n-java\/awt\/Focus\/AppletInitialFocusTest\/AppletInitialFocusTest1.java 8256289 windows-x64\n@@ -834,1 +771,0 @@\n-java\/awt\/Focus\/InactiveFocusRace.java 8023263 linux-all\n@@ -843,0 +779,7 @@\n+java\/awt\/Cursor\/CursorDragTest\/ListDragCursor.java 7177297 macosx-all\n+\n+############################################################################\n+\n+# jdk_since_checks\n+\n+tools\/sincechecker\/modules\/jdk.management.jfr\/JdkManagementJfrCheckSince.java 8354921 generic-all\n","filename":"test\/jdk\/ProblemList.txt","additions":18,"deletions":75,"binary":false,"changes":93,"status":"modified"},{"patch":"@@ -27,1 +27,1 @@\n-import jdk.test.lib.crac.CracBuilder;\n+import jdk.test.lib.crac.CracContainerBuilder;\n@@ -38,0 +38,2 @@\n+ * @comment Static JDK eagerly loads X11 which is missing from the Docker image\n+ * @requires !jdk.static\n@@ -39,0 +41,1 @@\n+ * @modules java.base\/jdk.internal.platform\n@@ -47,3 +50,1 @@\n-        if (!DockerTestUtils.canTestDocker()) {\n-            return;\n-        }\n+        DockerTestUtils.checkCanUseResourceLimits();\n@@ -51,1 +52,1 @@\n-        CracBuilder builder = new CracBuilder()\n+        CracContainerBuilder builder = new CracContainerBuilder()\n","filename":"test\/jdk\/jdk\/crac\/ContainerOOMETest.java","additions":6,"deletions":5,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -26,2 +26,1 @@\n-import jdk.test.lib.containers.docker.DockerTestUtils;\n-import jdk.test.lib.crac.CracBuilder;\n+import jdk.test.lib.crac.CracContainerBuilder;\n@@ -36,2 +35,0 @@\n-import java.util.Arrays;\n-\n@@ -43,0 +40,2 @@\n+ * @comment Static JDK eagerly loads X11 which is missing from the Docker image\n+ * @requires !jdk.static\n@@ -44,0 +43,1 @@\n+ * @modules java.base\/jdk.internal.platform\n@@ -60,1 +60,0 @@\n-\n@@ -86,3 +85,0 @@\n-        if (!DockerTestUtils.canTestDocker()) {\n-            return;\n-        }\n@@ -90,1 +86,1 @@\n-        CracBuilder builder = new CracBuilder()\n+        CracContainerBuilder builder = new CracContainerBuilder()\n@@ -108,2 +104,2 @@\n-                    builder.containerSetup(Arrays.asList(\"sh\", \"-x\", \"-c\",\n-                            \"adduser -D the_user && cat \/proc\/sys\/kernel\/pid_max && \" + setupLastPidCmd));\n+                    builder.containerSetup(\"sh\", \"-x\", \"-c\",\n+                            \"adduser -D the_user && cat \/proc\/sys\/kernel\/pid_max && \" + setupLastPidCmd);\n@@ -111,2 +107,2 @@\n-                    builder.containerSetup(Arrays.asList(\"bash\", \"-x\", \"-c\",\n-                            \"useradd the_user && cat \/proc\/sys\/kernel\/pid_max && \" + setupLastPidCmd));\n+                    builder.containerSetup(\"bash\", \"-x\", \"-c\",\n+                            \"useradd the_user && cat \/proc\/sys\/kernel\/pid_max && \" + setupLastPidCmd);\n@@ -114,1 +110,1 @@\n-                builder.dockerCheckpointOptions(Arrays.asList(\"-u\", \"the_user\"));\n+                builder.dockerCheckpointOptions(\"-u\", \"the_user\");\n","filename":"test\/jdk\/jdk\/crac\/ContainerPidAdjustmentTest.java","additions":10,"deletions":14,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -45,1 +45,0 @@\n- * @requires !jdk.static\n","filename":"test\/jdk\/jdk\/crac\/JcmdArgsTest.java","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -36,1 +36,0 @@\n-import java.nio.file.Path;\n@@ -130,7 +129,0 @@\n-        \/\/ Only restore-settable options one of which is aliased => should succeed\n-        \/\/ TODO: once we have aliased restore-settable boolean options include them here\n-        builder.clearVmOptions();\n-        setVmOptions(builder, OPTIONS_RESTORE);\n-        builder.vmOption(\"-XX:CREngine=criuengine\"); \/\/ Deprecated alias\n-        checkRestoreOutput(builder.doRestore());\n-\n","filename":"test\/jdk\/jdk\/crac\/VMOptionsTest.java","additions":0,"deletions":8,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -29,2 +29,1 @@\n-import jdk.test.lib.containers.docker.DockerTestUtils;\n-import jdk.test.lib.crac.CracBuilder;\n+import jdk.test.lib.crac.CracContainerBuilder;\n@@ -39,1 +38,0 @@\n-import java.util.Arrays;\n@@ -48,0 +46,2 @@\n+ * @comment Static JDK eagerly loads X11 which is missing from the Docker image\n+ * @requires !jdk.static\n@@ -49,0 +49,1 @@\n+ * @modules java.base\/jdk.internal.platform\n@@ -65,4 +66,1 @@\n-        if (!DockerTestUtils.canTestDocker()) {\n-            return;\n-        }\n-        CracBuilder builder = new CracBuilder();\n+        CracContainerBuilder builder = new CracContainerBuilder();\n@@ -85,1 +83,1 @@\n-                    CracBuilder.CONTAINER_NAME,\n+                    CracContainerBuilder.CONTAINER_NAME,\n@@ -91,1 +89,1 @@\n-                    CracBuilder.DOCKER_JAVA);\n+                    CracContainerBuilder.DOCKER_JAVA);\n@@ -97,1 +95,1 @@\n-            builder.doRestore(Container.ENGINE_COMMAND, \"exec\", CracBuilder.CONTAINER_NAME,\n+            builder.doRestore(Container.ENGINE_COMMAND, \"exec\", CracContainerBuilder.CONTAINER_NAME,\n@@ -99,1 +97,1 @@\n-                    CracBuilder.DOCKER_JAVA);\n+                    CracContainerBuilder.DOCKER_JAVA);\n","filename":"test\/jdk\/jdk\/crac\/java\/lang\/System\/NanoTimeTest.java","additions":9,"deletions":11,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -27,2 +27,1 @@\n-import jdk.test.lib.containers.docker.DockerTestUtils;\n-import jdk.test.lib.crac.CracBuilder;\n+import jdk.test.lib.crac.CracContainerBuilder;\n@@ -32,1 +31,0 @@\n-import java.io.IOException;\n@@ -51,0 +49,2 @@\n+ * @comment Static JDK eagerly loads X11 which is missing from the Docker image\n+ * @requires !jdk.static\n@@ -52,0 +52,1 @@\n+ * @modules java.base\/jdk.internal.platform\n@@ -61,4 +62,0 @@\n-        if (!DockerTestUtils.canTestDocker()) {\n-            return;\n-        }\n-\n@@ -67,1 +64,1 @@\n-        CracBuilder builder = new CracBuilder();\n+        CracContainerBuilder builder = new CracContainerBuilder();\n@@ -81,1 +78,1 @@\n-                    CracBuilder.CONTAINER_NAME,\n+                    CracContainerBuilder.CONTAINER_NAME,\n@@ -83,1 +80,1 @@\n-                    CracBuilder.DOCKER_JAVA);\n+                    CracContainerBuilder.DOCKER_JAVA);\n","filename":"test\/jdk\/jdk\/crac\/java\/lang\/System\/TimedWaitingTest.java","additions":7,"deletions":10,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -26,2 +26,1 @@\n-import jdk.test.lib.containers.docker.DockerTestUtils;\n-import jdk.test.lib.crac.CracBuilder;\n+import jdk.test.lib.crac.CracContainerBuilder;\n@@ -43,0 +42,2 @@\n+ * @comment Static JDK eagerly loads X11 which is missing from the Docker image\n+ * @requires !jdk.static\n@@ -44,0 +45,1 @@\n+ * @modules java.base\/jdk.internal.platform\n@@ -58,4 +60,0 @@\n-        if (!DockerTestUtils.canTestDocker()) {\n-            return;\n-        }\n-\n@@ -64,1 +62,1 @@\n-        CracBuilder builder = new CracBuilder()\n+        CracContainerBuilder builder = new CracContainerBuilder()\n","filename":"test\/jdk\/jdk\/crac\/java\/net\/InetAddress\/ResolveTest.java","additions":5,"deletions":7,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -148,1 +148,0 @@\n-        new ToolHelpSpec(\"jrunscript\",  1,   1,   1,   0,         1,    1,     7),     \/\/ -?, -h, --help -help, Documents -help\n","filename":"test\/jdk\/tools\/launcher\/HelpFlagsTest.java","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2007, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2007, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -102,1 +102,0 @@\n-        \"jrunscript\",\n","filename":"test\/jdk\/tools\/launcher\/VersionCheck.java","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -69,4 +69,5 @@\n-                    \"apx_f\",        \"avx10_1\",          \"avx10_2\",           \"fma4\",\n-                    \"movbe\",        \"osxsave\",          \"ibt\",               \"shstk\",\n-                    \"xsave\",        \"cmpxchg16\",        \"lahfsahf\",          \"htt\",\n-                    \"xsavec\",       \"avx_fast_unaligned_load\"\n+                    \"apx_f\",        \"avx10_1\",          \"avx10_2\",           \"avx512_fp16\",\n+                    \"sha512\",       \"hybrid\",           \"fma4\",              \"movbe\",\n+                    \"osxsave\",      \"ibt\",              \"shstk\",             \"xsave\",\n+                    \"cmpxchg16\",    \"lahfsahf\",         \"htt\",               \"xsavec\",\n+                    \"avx_fast_unaligned_load\"\n","filename":"test\/lib-test\/jdk\/test\/whitebox\/CPUInfoTest.java","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -34,0 +34,1 @@\n+    public ArrayList<String> engineOpts = new ArrayList<>();\n@@ -74,0 +75,5 @@\n+    public final DockerRunOptions addEngineOpts(String... opts) {\n+        Collections.addAll(engineOpts, opts);\n+        return this;\n+    }\n+\n","filename":"test\/lib\/jdk\/test\/lib\/containers\/docker\/DockerRunOptions.java","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1,68 +1,22 @@\n-package jdk.test.lib.crac;\n-\n-import jdk.test.lib.Container;\n-import jdk.test.lib.Utils;\n-import jdk.test.lib.containers.docker.DockerTestUtils;\n-import jdk.test.lib.containers.docker.DockerfileConfig;\n-import jdk.test.lib.process.OutputAnalyzer;\n-import jdk.test.lib.util.FileUtils;\n-\n-import java.io.File;\n-import java.io.IOException;\n-import java.nio.file.NoSuchFileException;\n-import java.nio.file.Path;\n-import java.util.*;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-import static jdk.test.lib.Asserts.*;\n-\n-public class CracBuilder {\n-    private static final String DEFAULT_IMAGE_DIR = \"cr\";\n-    \/\/ Make it unique so that tests running in parallel do not conflict with:\n-    \/\/ docker: Error response from daemon: Conflict. The container name \"\/crac-test\" is already in use by container \"<hash>\". You have to remove (or rename) that container to be able to reuse that name.\n-    public static final String CONTAINER_NAME = \"crac-test\" + ProcessHandle.current().pid();\n-    public static final String JAVA = Utils.TEST_JDK + \"\/bin\/java\";\n-    public static final String DOCKER_JAVA = \"\/jdk\/bin\/java\";\n-    private static final List<String> CRIU_CANDIDATES = Arrays.asList(Utils.TEST_JDK + \"\/lib\/criu\", \"\/usr\/sbin\/criu\", \"\/sbin\/criu\");\n-    private static final String CRIU_PATH;\n-\n-    \/\/ Set this property to true to re-use an existing image.\n-    \/\/ By default an image will be built from scratch.\n-    \/\/ Reusing an image may be useful for running test cases with the same image,\n-    \/\/ without rebuilding it.\n-    public static final boolean REUSE_IMAGE_IF_EXIST =\n-        Boolean.getBoolean(\"jdk.test.crac.reuse.image\");\n-\n-    \/\/ This dummy field is here as workaround for (possibly) a JTReg bug;\n-    \/\/ some tests don't build CracTestArg into their Test.d\/ directory\n-    \/\/ (not all classes from \/test\/lib are built!) and the tests would fail.\n-    \/\/ This does not always happen when the test is run individually but breaks\n-    \/\/ when the whole suite is executed.\n-    private static final Class<CracTestArg> dummyWorkaround = CracTestArg.class;\n-\n-    boolean verbose = true;\n-    boolean debug = false;\n-    final List<String> classpathEntries = new ArrayList<>();\n-    final Map<String, String> env = new HashMap<>();\n-    final List<String> vmOptions = new ArrayList<>();\n-    final Map<String, String> javaOptions = new HashMap<>();\n-    String imageDir = DEFAULT_IMAGE_DIR;\n-    CracEngine engine;\n-    String[] engineOptions;\n-    boolean printResources;\n-    boolean forwardClasspathOnRestore;\n-    Class<?> main;\n-    String[] args;\n-    boolean captureOutput;\n-    String dockerImageBaseName;\n-    String dockerImageBaseVersion;\n-    String dockerImageName;\n-    private String[] dockerOptions;\n-    private List<String> dockerCheckpointOptions;\n-    boolean containerUsePrivileged = true;\n-    private List<String> containerSetupCommand;\n-    boolean runContainerDirectly = false;\n-    \/\/ make sure to update copy() when adding another field here\n-\n-    boolean containerStarted;\n+\/*\n+ * Copyright (c) 2026, Azul Systems, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n@@ -70,12 +24,1 @@\n-    static {\n-        String path = System.getenv(\"CRAC_CRIU_PATH\");\n-        if (path == null) {\n-            for (String candidate : CRIU_CANDIDATES) {\n-                if (new File(candidate).exists()) {\n-                    path = candidate;\n-                    break;\n-                }\n-            }\n-        }\n-        CRIU_PATH = path;\n-    }\n+package jdk.test.lib.crac;\n@@ -83,0 +26,1 @@\n+public class CracBuilder extends CracBuilderBase<CracBuilder> {\n@@ -86,99 +30,2 @@\n-    public CracBuilder copy() {\n-        CracBuilder other = new CracBuilder();\n-        other.verbose = verbose;\n-        other.debug = debug;\n-        other.classpathEntries.addAll(classpathEntries);\n-        other.env.putAll(env);\n-        other.vmOptions.addAll(vmOptions);\n-        other.javaOptions.putAll(javaOptions);\n-        other.imageDir = imageDir;\n-        other.engine = engine;\n-        other.engineOptions = engineOptions == null ? null : Arrays.copyOf(engineOptions, engineOptions.length);\n-        other.printResources = printResources;\n-        other.forwardClasspathOnRestore = forwardClasspathOnRestore;\n-        other.main = main;\n-        other.args = args == null ? null : Arrays.copyOf(args, args.length);\n-        other.captureOutput = captureOutput;\n-        other.dockerImageName = dockerImageName;\n-        other.dockerOptions = dockerOptions == null ? null : Arrays.copyOf(dockerOptions, dockerOptions.length);\n-        other.dockerCheckpointOptions = dockerCheckpointOptions;\n-        other.containerUsePrivileged = containerUsePrivileged;\n-        other.containerSetupCommand = containerSetupCommand;\n-        other.runContainerDirectly = runContainerDirectly;\n-        return other;\n-    }\n-\n-    public CracBuilder verbose(boolean verbose) {\n-        this.verbose = verbose;\n-        return this;\n-    }\n-\n-    public CracBuilder debug(boolean debug) {\n-        this.debug = debug;\n-        return this;\n-    }\n-\n-    public CracBuilder dockerCheckpointOptions(List<String> options) {\n-        this.dockerCheckpointOptions = options;\n-        return this;\n-    }\n-\n-    public CracBuilder containerSetup(List<String> cmd) {\n-        this.containerSetupCommand = cmd;\n-        return this;\n-    }\n-\n-    public CracBuilder containerUsePrivileged(boolean usePrivileged) {\n-        this.containerUsePrivileged = usePrivileged;\n-        return this;\n-    }\n-\n-    public CracBuilder runContainerDirectly(boolean runDirectly) {\n-        this.runContainerDirectly = runDirectly;\n-        return this;\n-    }\n-\n-    public CracBuilder classpathEntry(String cp) {\n-        classpathEntries.add(cp);\n-        return this;\n-    }\n-\n-    public CracBuilder engine(CracEngine engine) {\n-        assertTrue(this.engine == null || this.engine.equals(engine));\n-        this.engine = engine;\n-        return this;\n-    }\n-\n-    public CracBuilder engineOptions(String... options) {\n-        this.engineOptions = options;\n-        return this;\n-    }\n-\n-    public Path imageDir() {\n-        return Path.of(imageDir);\n-    }\n-\n-    public CracBuilder imageDir(String imageDir) {\n-        assertEquals(DEFAULT_IMAGE_DIR, this.imageDir); \/\/ set once\n-        this.imageDir = imageDir;\n-        return this;\n-    }\n-\n-    public CracBuilder vmOption(String option) {\n-        vmOptions.add(option);\n-        return this;\n-    }\n-\n-    public CracBuilder clearVmOptions() {\n-        vmOptions.clear();\n-        return this;\n-    }\n-\n-    public CracBuilder printResources(boolean print) {\n-        this.printResources = print;\n-        return this;\n-    }\n-\n-    public CracBuilder forwardClasspathOnRestore(boolean forward) {\n-        this.forwardClasspathOnRestore = forward;\n-        return this;\n+    protected CracBuilder(CracBuilder other) {\n+        super(other);\n@@ -187,2 +34,2 @@\n-    public CracBuilder env(String name, String value) {\n-        env.put(name, value);\n+    @Override\n+    protected CracBuilder self() {\n@@ -192,367 +39,3 @@\n-    public CracBuilder javaOption(String name, String value) {\n-        javaOptions.put(name, value);\n-        return this;\n-    }\n-\n-    public CracBuilder main(Class<?> mainClass) {\n-        assertNull(this.main); \/\/ set once\n-        this.main = mainClass;\n-        return this;\n-    }\n-\n-    public Class<?> main() {\n-        return main != null ? main : CracTest.class;\n-    }\n-\n-    public CracBuilder args(String... args) {\n-        assertNull(this.args); \/\/ set once\n-        this.args = args;\n-        return this;\n-    }\n-\n-    public String[] args() {\n-        return args != null ? args : CracTest.args();\n-    }\n-\n-    public CracBuilder captureOutput(boolean captureOutput) {\n-        this.captureOutput = captureOutput;\n-        return this;\n-    }\n-\n-    public CracBuilder withBaseImage(String name, String tag) {\n-        assertNull(dockerImageBaseName);\n-        assertNull(dockerImageBaseVersion);\n-        this.dockerImageBaseName = name;\n-        this.dockerImageBaseVersion = tag;\n-        return this;\n-    }\n-\n-    public CracBuilder inDockerImage(String imageName) {\n-        assertNull(dockerImageName);\n-        this.dockerImageName = imageName;\n-        return this;\n-    }\n-\n-    public CracBuilder dockerOptions(String... options) {\n-        assertNull(dockerOptions);\n-        this.dockerOptions = options;\n-        return this;\n-    }\n-\n-    public CracBuilder clearDockerOptions() {\n-        assertNotNull(dockerOptions);;\n-        this.dockerOptions = null;\n-        return this;\n-    }\n-\n-    public void doCheckpoint(String... javaPrefix) throws Exception {\n-        startCheckpoint(javaPrefix).waitForCheckpointed();\n-    }\n-\n-    public CracProcess startCheckpoint(String... javaPrefix) throws Exception {\n-        List<String> list = javaPrefix.length == 0 ? null : Arrays.asList(javaPrefix);\n-        return startCheckpoint(list);\n-    }\n-\n-    public CracProcess startCheckpoint(List<String> javaPrefix) throws Exception {\n-        if (runContainerDirectly) {\n-            prepareContainer();\n-        } else {\n-            ensureContainerStarted();\n-        }\n-        List<String> cmd = prepareCommand(javaPrefix, false);\n-        if (imageDir != null) {\n-            cmd.add(\"-XX:CRaCCheckpointTo=\" + imageDir);\n-        }\n-        cmd.add(main().getName());\n-        cmd.addAll(Arrays.asList(args()));\n-        log(\"Starting process to be checkpointed:\");\n-        log(String.join(\" \", cmd));\n-        return new CracProcess(this, cmd);\n-    }\n-\n-    void log(String fmt, Object... args) {\n-        if (verbose) {\n-            if (args.length == 0) {\n-                System.err.println(fmt);\n-            } else {\n-                System.err.printf(fmt, args);\n-            }\n-        }\n-    }\n-\n-    public void ensureContainerStarted() throws Exception {\n-        if (dockerImageName == null) {\n-            return;\n-        }\n-        if (CRIU_PATH == null) {\n-            fail(\"CRAC_CRIU_PATH is not set and cannot find criu executable in any of: \" + CRIU_CANDIDATES);\n-        }\n-        if (!containerStarted) {\n-            prepareContainer();\n-            List<String> cmd = prepareContainerCommand(dockerImageName, dockerOptions);\n-            log(\"Starting docker container:\\n\" + String.join(\" \", cmd));\n-            assertEquals(0, new ProcessBuilder().inheritIO().command(cmd).start().waitFor());\n-            containerSetup();\n-            containerStarted = true;\n-        }\n-    }\n-\n-    private void prepareContainer() throws Exception {\n-        if (runContainerDirectly && null != containerSetupCommand) {\n-            fail(\"runContainerDirectly and containerSetupCommand cannot be used together.\");\n-        }\n-        ensureContainerKilled();\n-\n-        \/\/ FIXME cooperate better with DockerTestUtils\n-        try {\n-            FileUtils.deleteFileTreeWithRetry(Path.of(\".\", dockerImageName.replace(\":\", \"-\")));\n-        } catch (NoSuchFileException ignore) {\n-        }\n-\n-        buildDockerImage();\n-    }\n-\n-    private void containerSetup() throws Exception {\n-        if (null != containerSetupCommand && 0 < containerSetupCommand.size()) {\n-            List<String> cmd = new ArrayList<>();\n-            cmd.addAll(Arrays.asList(Container.ENGINE_COMMAND, \"exec\", CONTAINER_NAME));\n-            cmd.addAll(containerSetupCommand);\n-            log(\"Container set up:\\n\" + String.join(\" \", cmd));\n-            DockerTestUtils.execute(cmd).shouldHaveExitValue(0);\n-        }\n-    }\n-\n-    private void buildDockerImage() throws Exception {\n-        String previousBaseImageName = null;\n-        String previousBaseImageVersion = null;\n-        try {\n-            previousBaseImageName = System.getProperty(DockerfileConfig.BASE_IMAGE_NAME);\n-            previousBaseImageVersion = System.getProperty(DockerfileConfig.BASE_IMAGE_VERSION);\n-            if (dockerImageBaseName != null) {\n-                System.setProperty(DockerfileConfig.BASE_IMAGE_NAME, dockerImageBaseName);\n-            }\n-            if (dockerImageBaseVersion != null) {\n-                System.setProperty(DockerfileConfig.BASE_IMAGE_VERSION, dockerImageBaseVersion);\n-            }\n-            if (REUSE_IMAGE_IF_EXIST) {\n-                if (0 == DockerTestUtils.execute(Container.ENGINE_COMMAND, \"inspect\", \"--type=image\", dockerImageName).getExitValue()) {\n-                    return;\n-                }\n-            }\n-            DockerTestUtils.buildJdkContainerImage(dockerImageName);\n-        } finally {\n-            if (previousBaseImageName != null) {\n-                System.setProperty(DockerfileConfig.BASE_IMAGE_NAME, previousBaseImageName);\n-            } else {\n-                System.clearProperty(DockerfileConfig.BASE_IMAGE_NAME);\n-            }\n-            if (previousBaseImageVersion != null) {\n-                System.setProperty(DockerfileConfig.BASE_IMAGE_VERSION, previousBaseImageVersion);\n-            } else {\n-                System.clearProperty(DockerfileConfig.BASE_IMAGE_VERSION);\n-            }\n-        }\n-    }\n-\n-    private List<String> prepareContainerCommandBase(String imageName, String[] options) {\n-        List<String> cmd = new ArrayList<>();\n-        cmd.add(Container.ENGINE_COMMAND);\n-        cmd.addAll(Arrays.asList(\"run\", \"--rm\"));\n-        if (!runContainerDirectly) {\n-            cmd.add(\"-d\");\n-            cmd.add(\"--init\"); \/\/ otherwise the checkpointed process would not be reaped (by sleep with PID 1)\n-        }\n-        if (containerUsePrivileged) {\n-            cmd.add(\"--privileged\"); \/\/ required to give CRIU sufficient permissions\n-        }\n-        int entryCounter = 0;\n-        for (var entry : Utils.TEST_CLASS_PATH.split(File.pathSeparator)) {\n-            cmd.addAll(Arrays.asList(\"--volume\", entry + \":\/cp\/\" + (entryCounter++)));\n-        }\n-        new File(System.getProperty(\"user.dir\") + \"\/cr\").mkdirs(); \/\/ create \"cr\" dir under the current user, to be able to delete it later.\n-        cmd.addAll(Arrays.asList(\"--volume\", System.getProperty(\"user.dir\") + \"\/cr:\/cr\"));\n-        cmd.addAll(Arrays.asList(\"--volume\", CRIU_PATH + \":\/criu\"));\n-        cmd.addAll(Arrays.asList(\"--env\", \"CRAC_CRIU_PATH=\/criu\"));\n-        cmd.addAll(Arrays.asList(\"--name\", CONTAINER_NAME));\n-        if (debug) {\n-            cmd.addAll(Arrays.asList(\"--publish\", \"5005:5005\"));\n-        }\n-        if (options != null) {\n-            cmd.addAll(Arrays.asList(options));\n-        }\n-        cmd.add(imageName);\n-        return cmd;\n-    }\n-\n-    private List<String> prepareContainerCommand(String imageName, String[] options) {\n-        List<String> cmd = prepareContainerCommandBase(imageName, options);\n-        cmd.addAll(Arrays.asList(\"sleep\", \"3600\"));\n-        return cmd;\n-    }\n-\n-    public void ensureContainerKilled() throws Exception {\n-        DockerTestUtils.execute(Container.ENGINE_COMMAND, \"kill\", CONTAINER_NAME).getExitValue();\n-        if (!DockerTestUtils.RETAIN_IMAGE_AFTER_TEST) {\n-            DockerTestUtils.removeDockerImage(dockerImageName);\n-        }\n-    }\n-\n-    public void recreateContainer(String imageName, String... options) throws Exception {\n-        assertTrue(containerStarted);\n-        DockerTestUtils.execute(Container.ENGINE_COMMAND, \"kill\", CONTAINER_NAME).getExitValue();\n-\n-        \/\/ Docker needs some time to remove a container after kill\n-        OutputAnalyzer oa = null;\n-        do {\n-            oa = DockerTestUtils.execute(Container.ENGINE_COMMAND, \"ps\");\n-            oa.getExitValue();\n-        } while (oa.getStdout().contains(CONTAINER_NAME));\n-\n-        List<String> cmd = prepareContainerCommand(imageName, options);\n-        log(\"Recreating docker container:\\n\" + String.join(\" \", cmd));\n-        assertEquals(0, new ProcessBuilder().inheritIO().command(cmd).start().waitFor());\n-    }\n-\n-    public CracProcess doRestore(String... javaPrefix) throws Exception {\n-        return startRestore(javaPrefix).waitForSuccess();\n-    }\n-\n-    public CracProcess startRestore(String... javaPrefix) throws Exception {\n-         List<String> list = javaPrefix.length == 0 ? null : Arrays.asList(javaPrefix);\n-         return startRestore(list);\n-    }\n-\n-    public CracProcess startRestore(List<String> javaPrefix) throws Exception {\n-        return startRestoreWithArgs(javaPrefix, null);\n-    }\n-\n-    public CracProcess startRestoreWithArgs(List<String> javaPrefix, List<String> args) throws Exception {\n-        if (!runContainerDirectly) {\n-            ensureContainerStarted();\n-        }\n-        List<String> cmd = prepareCommand(javaPrefix, true);\n-        if (imageDir != null) {\n-            cmd.add(\"-XX:CRaCRestoreFrom=\" + imageDir);\n-        }\n-        if (null != args) {\n-            cmd.addAll(args);\n-        }\n-        log(\"Starting restored process:\");\n-        log(String.join(\" \", cmd));\n-        return new CracProcess(this, cmd);\n-    }\n-\n-    public CracProcess startPlain() throws IOException {\n-        List<String> cmd = new ArrayList<>();\n-        if (dockerImageName != null) {\n-            cmd.addAll(Arrays.asList(Container.ENGINE_COMMAND, \"exec\", CONTAINER_NAME));\n-        }\n-        cmd.add(JAVA);\n-        cmd.add(\"-ea\");\n-        cmd.add(\"-cp\");\n-        cmd.add(getClassPath());\n-        if (debug) {\n-            cmd.add(\"-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=0.0.0.0:5005\");\n-        }\n-        cmd.addAll(vmOptions);\n-        for (var entry : javaOptions.entrySet()) {\n-            cmd.add(\"-D\" + entry.getKey() + \"=\" + entry.getValue());\n-        }\n-        cmd.add(main().getName());\n-        cmd.addAll(Arrays.asList(args()));\n-        log(\"Starting process without CRaC:\");\n-        log(String.join(\" \", cmd));\n-        return new CracProcess(this, cmd);\n-    }\n-\n-    private String getClassPath() {\n-        String classPath = classpathEntries.isEmpty() ? \"\" : String.join(File.pathSeparator, classpathEntries) + File.pathSeparator;\n-        if (dockerImageName == null) {\n-            classPath += Utils.TEST_CLASS_PATH;\n-        } else {\n-            int numEntries = Utils.TEST_CLASS_PATH.split(File.pathSeparator).length;\n-            for (int i = 0; i < numEntries; ++i) {\n-                classPath += \"\/cp\/\" + i + File.pathSeparator;\n-            }\n-        }\n-        return classPath;\n-    }\n-\n-    public CracProcess doPlain() throws IOException, InterruptedException {\n-        return startPlain().waitForSuccess();\n-    }\n-\n-    private List<String> prepareCommand(List<String> javaPrefix, boolean isRestore) {\n-        List<String> cmd = new ArrayList<>();\n-        if (javaPrefix != null) {\n-            cmd.addAll(javaPrefix);\n-        } else if (dockerImageName != null) {\n-            if (runContainerDirectly) {\n-                cmd = prepareContainerCommandBase(dockerImageName, dockerOptions);\n-            } else {\n-                cmd.add(Container.ENGINE_COMMAND);\n-                cmd.add(\"exec\");\n-                if (null != dockerCheckpointOptions) {\n-                    cmd.addAll(dockerCheckpointOptions);\n-                }\n-                cmd.add(CONTAINER_NAME);\n-            }\n-            cmd.add(DOCKER_JAVA);\n-        } else {\n-            cmd.add(JAVA);\n-        }\n-        cmd.add(\"-ea\");\n-        if (engine != null) {\n-            cmd.add(\"-XX:CRaCEngine=\" + engine.engine);\n-        }\n-        if (engineOptions != null) {\n-            cmd.add(\"-XX:CRaCEngineOptions=\" + String.join(\",\", engineOptions));\n-        }\n-        if (!isRestore || forwardClasspathOnRestore) {\n-            cmd.add(\"-cp\");\n-            cmd.add(getClassPath());\n-        }\n-        if (!isRestore && printResources) {\n-            cmd.add(\"-XX:+UnlockDiagnosticVMOptions\");\n-            cmd.add(\"-XX:+CRaCPrintResourcesOnCheckpoint\");\n-        }\n-        if (debug) {\n-            cmd.add(\"-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=0.0.0.0:5005\");\n-        }\n-        cmd.addAll(vmOptions);\n-        for (var entry : javaOptions.entrySet()) {\n-            cmd.add(\"-D\" + entry.getKey() + \"=\" + entry.getValue());\n-        }\n-        return cmd;\n-    }\n-\n-    public void doCheckpointAndRestore() throws Exception {\n-        doCheckpoint();\n-        doRestore();\n-    }\n-\n-    public void checkpointViaJcmd(long pid, String... args) throws Exception {\n-        runJcmd(Long.toString(pid), Stream.concat(Stream.of(\"JDK.checkpoint\"), Stream.of(args)).toArray(String[]::new))\n-                .shouldHaveExitValue(0).outputTo(System.out).errorTo(System.err);\n-    }\n-\n-    public void checkpointViaJcmd() throws Exception {\n-        if (null == dockerImageName) {\n-            fail(\"Docker container is not set. Use checkpointViaJcmd(long pid) to run jcmd for non-container tests.\");\n-        }\n-        runJcmd(main().getName(), \"JDK.checkpoint\").shouldHaveExitValue(0)\n-                .outputTo(System.out).errorTo(System.err);\n-    }\n-\n-    public OutputAnalyzer runJcmd(String id, String... command) throws Exception {\n-        List<String> cmd = new ArrayList<>();\n-        if (dockerImageName != null) {\n-            cmd.addAll(Arrays.asList(Container.ENGINE_COMMAND, \"exec\", CONTAINER_NAME, \"\/jdk\/bin\/jcmd\"));\n-        } else {\n-            cmd.add(Utils.TEST_JDK + \"\/bin\/jcmd\");\n-        }\n-        cmd.add(id);\n-        cmd.addAll(Arrays.asList(command));\n-        \/\/ This works for non-docker commands, too\n-        return DockerTestUtils.execute(cmd);\n+    @Override\n+    public CracBuilder copy() {\n+        return new CracBuilder(this);\n","filename":"test\/lib\/jdk\/test\/lib\/crac\/CracBuilder.java","additions":31,"deletions":548,"binary":false,"changes":579,"status":"modified"},{"patch":"@@ -0,0 +1,326 @@\n+\/*\n+ * Copyright (c) 2026, Azul Systems, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package jdk.test.lib.crac;\n+\n+import jdk.test.lib.Utils;\n+import jdk.test.lib.process.OutputAnalyzer;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.util.*;\n+import java.util.stream.Stream;\n+\n+import static jdk.test.lib.Asserts.*;\n+\n+public abstract class CracBuilderBase<T extends CracBuilderBase<T>> {\n+    private static final String DEFAULT_IMAGE_DIR = \"cr\";\n+    public static final String JAVA = Utils.TEST_JDK + \"\/bin\/java\";\n+\n+    \/\/ This dummy field is here as workaround for (possibly) a JTReg bug;\n+    \/\/ some tests don't build CracTestArg into their Test.d\/ directory\n+    \/\/ (not all classes from \/test\/lib are built!) and the tests would fail.\n+    \/\/ This does not always happen when the test is run individually but breaks\n+    \/\/ when the whole suite is executed.\n+    private static final Class<CracTestArg> dummyWorkaround = CracTestArg.class;\n+\n+    boolean verbose = true;\n+    boolean debug = false;\n+    final List<String> classpathEntries;\n+    final Map<String, String> env;\n+    final List<String> vmOptions;\n+    final Map<String, String> javaOptions;\n+    String imageDir = DEFAULT_IMAGE_DIR;\n+    CracEngine engine;\n+    String[] engineOptions;\n+    boolean printResources;\n+    boolean forwardClasspathOnRestore;\n+    Class<?> main;\n+    String[] args;\n+    boolean captureOutput;\n+    \/\/ make sure to update copy constructor when adding new fields\n+\n+    protected abstract T self();\n+\n+    public abstract T copy();\n+\n+    public CracBuilderBase() {\n+        classpathEntries = new ArrayList<>();\n+        env = new HashMap<>();\n+        vmOptions = new ArrayList<>();\n+        javaOptions = new HashMap<>();\n+    }\n+\n+    protected CracBuilderBase(T other) {\n+        verbose = other.verbose;\n+        debug = other.debug;\n+        classpathEntries = new ArrayList<>(other.classpathEntries);\n+        env = new HashMap<>(other.env);\n+        vmOptions = new ArrayList<>(other.vmOptions);\n+        javaOptions = new HashMap<>(other.javaOptions);\n+        imageDir = other.imageDir;\n+        engine = other.engine;\n+        engineOptions = other.engineOptions == null ? null : Arrays.copyOf(other.engineOptions, other.engineOptions.length);\n+        printResources = other.printResources;\n+        forwardClasspathOnRestore = other.forwardClasspathOnRestore;\n+        main = other.main;\n+        args = other.args == null ? null : Arrays.copyOf(other.args, other.args.length);\n+        captureOutput = other.captureOutput;\n+    }\n+\n+    public T verbose(boolean verbose) {\n+        this.verbose = verbose;\n+        return self();\n+    }\n+\n+    public T debug(boolean debug) {\n+        this.debug = debug;\n+        return self();\n+    }\n+\n+    public T classpathEntry(String cp) {\n+        classpathEntries.add(cp);\n+        return self();\n+    }\n+\n+    public T engine(CracEngine engine) {\n+        assertTrue(this.engine == null || this.engine.equals(engine));\n+        this.engine = engine;\n+        return self();\n+    }\n+\n+    public T engineOptions(String... options) {\n+        this.engineOptions = options;\n+        return self();\n+    }\n+\n+    public Path imageDir() {\n+        return Path.of(imageDir);\n+    }\n+\n+    public T imageDir(String imageDir) {\n+        assertEquals(DEFAULT_IMAGE_DIR, this.imageDir); \/\/ set once\n+        this.imageDir = imageDir;\n+        return self();\n+    }\n+\n+    public T vmOption(String option) {\n+        vmOptions.add(option);\n+        return self();\n+    }\n+\n+    public T clearVmOptions() {\n+        vmOptions.clear();\n+        return self();\n+    }\n+\n+    public T printResources(boolean print) {\n+        this.printResources = print;\n+        return self();\n+    }\n+\n+    public T forwardClasspathOnRestore(boolean forward) {\n+        this.forwardClasspathOnRestore = forward;\n+        return self();\n+    }\n+\n+    public T env(String name, String value) {\n+        env.put(name, value);\n+        return self();\n+    }\n+\n+    public T javaOption(String name, String value) {\n+        javaOptions.put(name, value);\n+        return self();\n+    }\n+\n+    public T main(Class<?> mainClass) {\n+        assertNull(this.main); \/\/ set once\n+        this.main = mainClass;\n+        return self();\n+    }\n+\n+    public Class<?> main() {\n+        return main != null ? main : CracTest.class;\n+    }\n+\n+    public T args(String... args) {\n+        assertNull(this.args); \/\/ set once\n+        this.args = args;\n+        return self();\n+    }\n+\n+    public String[] args() {\n+        return args != null ? args : CracTest.args();\n+    }\n+\n+    public T captureOutput(boolean captureOutput) {\n+        this.captureOutput = captureOutput;\n+        return self();\n+    }\n+\n+    public void doCheckpoint(String... javaPrefix) throws Exception {\n+        startCheckpoint(javaPrefix).waitForCheckpointed();\n+    }\n+\n+    public CracProcess startCheckpoint(String... javaPrefix) throws Exception {\n+        List<String> list = javaPrefix.length == 0 ? null : Arrays.asList(javaPrefix);\n+        return startCheckpoint(list);\n+    }\n+\n+    public CracProcess startCheckpoint(List<String> javaPrefix) throws Exception {\n+        List<String> cmd = prepareCommand(javaPrefix, false);\n+        if (imageDir != null) {\n+            cmd.add(\"-XX:CRaCCheckpointTo=\" + imageDir);\n+        }\n+        cmd.add(main().getName());\n+        cmd.addAll(Arrays.asList(args()));\n+        log(\"Starting process to be checkpointed:\");\n+        log(String.join(\" \", cmd));\n+        return new CracProcess(this, cmd);\n+    }\n+\n+    void log(String fmt, Object... args) {\n+        if (verbose) {\n+            if (args.length == 0) {\n+                System.err.println(fmt);\n+            } else {\n+                System.err.printf(fmt, args);\n+            }\n+        }\n+    }\n+\n+    public CracProcess doRestore(String... javaPrefix) throws Exception {\n+        return startRestore(javaPrefix).waitForSuccess();\n+    }\n+\n+    public CracProcess startRestore(String... javaPrefix) throws Exception {\n+        List<String> list = javaPrefix.length == 0 ? null : Arrays.asList(javaPrefix);\n+        return startRestore(list);\n+    }\n+\n+    public CracProcess startRestore(List<String> javaPrefix) throws Exception {\n+        return startRestoreWithArgs(javaPrefix, null);\n+    }\n+\n+    public CracProcess startRestoreWithArgs(List<String> javaPrefix, List<String> args) throws Exception {\n+        List<String> cmd = prepareCommand(javaPrefix, true);\n+        if (imageDir != null) {\n+            cmd.add(\"-XX:CRaCRestoreFrom=\" + imageDir);\n+        }\n+        if (null != args) {\n+            cmd.addAll(args);\n+        }\n+        log(\"Starting restored process:\");\n+        log(String.join(\" \", cmd));\n+        return new CracProcess(this, cmd);\n+    }\n+\n+    public CracProcess startPlain() throws IOException {\n+        List<String> cmd = new ArrayList<>(getPlainCommandPrefix());\n+        cmd.add(JAVA);\n+        cmd.add(\"-ea\");\n+        cmd.add(\"-cp\");\n+        cmd.add(getClassPath());\n+        if (debug) {\n+            cmd.add(\"-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=0.0.0.0:5005\");\n+        }\n+        cmd.addAll(vmOptions);\n+        for (var entry : javaOptions.entrySet()) {\n+            cmd.add(\"-D\" + entry.getKey() + \"=\" + entry.getValue());\n+        }\n+        cmd.add(main().getName());\n+        cmd.addAll(Arrays.asList(args()));\n+        log(\"Starting process without CRaC:\");\n+        log(String.join(\" \", cmd));\n+        return new CracProcess(this, cmd);\n+    }\n+\n+    protected List<String> getPlainCommandPrefix() {\n+        return List.of();\n+    }\n+\n+    private String getClassPath() {\n+        String classPath = classpathEntries.isEmpty() ? \"\" : String.join(File.pathSeparator, classpathEntries) + File.pathSeparator;\n+        return classPath + getTestClassPath();\n+    }\n+\n+    protected String getTestClassPath() {\n+        return Utils.TEST_CLASS_PATH;\n+    }\n+\n+    public CracProcess doPlain() throws IOException, InterruptedException {\n+        return startPlain().waitForSuccess();\n+    }\n+\n+    private List<String> prepareCommand(List<String> javaPrefix, boolean isRestore) {\n+        List<String> cmd = new ArrayList<>(javaPrefix != null ? javaPrefix : getDefaultJavaPrefix());\n+        cmd.add(\"-ea\");\n+        if (engine != null) {\n+            cmd.add(\"-XX:CRaCEngine=\" + engine.engine);\n+        }\n+        if (engineOptions != null) {\n+            cmd.add(\"-XX:CRaCEngineOptions=\" + String.join(\",\", engineOptions));\n+        }\n+        if (!isRestore || forwardClasspathOnRestore) {\n+            cmd.add(\"-cp\");\n+            cmd.add(getClassPath());\n+        }\n+        if (!isRestore && printResources) {\n+            cmd.add(\"-XX:+UnlockDiagnosticVMOptions\");\n+            cmd.add(\"-XX:+CRaCPrintResourcesOnCheckpoint\");\n+        }\n+        if (debug) {\n+            cmd.add(\"-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=0.0.0.0:5005\");\n+        }\n+        cmd.addAll(vmOptions);\n+        for (var entry : javaOptions.entrySet()) {\n+            cmd.add(\"-D\" + entry.getKey() + \"=\" + entry.getValue());\n+        }\n+        return cmd;\n+    }\n+\n+    protected List<String> getDefaultJavaPrefix() {\n+        return List.of(JAVA);\n+    }\n+\n+    public void doCheckpointAndRestore() throws Exception {\n+        doCheckpoint();\n+        doRestore();\n+    }\n+\n+    public void checkpointViaJcmd(long pid, String... args) throws Exception {\n+        runJcmd(Long.toString(pid), Stream.concat(Stream.of(\"JDK.checkpoint\"), Stream.of(args)).toArray(String[]::new))\n+                .shouldHaveExitValue(0).outputTo(System.out).errorTo(System.err);\n+    }\n+\n+    public OutputAnalyzer runJcmd(String id, String... command) throws Exception {\n+        final List<String> cmd = new ArrayList<>();\n+        cmd.add(Utils.TEST_JDK + \"\/bin\/jcmd\");\n+        cmd.add(id);\n+        cmd.addAll(Arrays.asList(command));\n+        log(\"Executing JCMD command for PID \" + id + \": \" + String.join(\" \", List.of(command)));\n+        return new OutputAnalyzer(new ProcessBuilder(cmd).start());\n+    }\n+}\n","filename":"test\/lib\/jdk\/test\/lib\/crac\/CracBuilderBase.java","additions":326,"deletions":0,"binary":false,"changes":326,"status":"added"},{"patch":"@@ -0,0 +1,362 @@\n+\/*\n+ * Copyright (c) 2026, Azul Systems, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package jdk.test.lib.crac;\n+\n+import jdk.test.lib.Container;\n+import jdk.test.lib.Utils;\n+import jdk.test.lib.containers.docker.DockerTestUtils;\n+import jdk.test.lib.containers.docker.DockerfileConfig;\n+import jdk.test.lib.process.OutputAnalyzer;\n+import jdk.test.lib.util.FileUtils;\n+\n+import java.io.File;\n+import java.nio.file.NoSuchFileException;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static jdk.test.lib.Asserts.*;\n+\n+\/**\n+ * Tests using this must be tagged with:\n+ * <ul>\n+ * <li> {@code @modules java.base\/jdk.internal.platform}, see\n+ * <a href=\"https:\/\/github.com\/openjdk\/jdk\/pull\/28557#issuecomment-3597274354\">this discussion<\/a>; <\/li>\n+ * <li> {@code @requires !jdk.static} unless the test uses an image that has X11 installed,\n+ * the default image currently does not have it making static JDK that loads X11 eagerly\n+ * fail to start. <\/li>\n+ * <\/ul>\n+ *\/\n+public class CracContainerBuilder extends CracBuilderBase<CracContainerBuilder> {\n+    \/\/ Make it unique so that tests running in parallel do not conflict with:\n+    \/\/ docker: Error response from daemon: Conflict. The container name \"\/crac-test\" is already in use by container \"<hash>\". You have to remove (or rename) that container to be able to reuse that name.\n+    public static final String CONTAINER_NAME = \"crac-test\" + ProcessHandle.current().pid();\n+    public static final String DOCKER_JAVA = \"\/jdk\/bin\/java\";\n+    \/\/ Set this property to true to re-use an existing image.\n+    \/\/ By default an image will be built from scratch.\n+    \/\/ Reusing an image may be useful for running test cases with the same image,\n+    \/\/ without rebuilding it.\n+    public static final boolean REUSE_IMAGE_IF_EXIST = Boolean.getBoolean(\"jdk.test.crac.reuse.image\");\n+\n+    private static final List<String> CRIU_CANDIDATES = List.of(Utils.TEST_JDK + \"\/lib\/criu\", \"\/usr\/sbin\/criu\", \"\/sbin\/criu\");\n+    private static final String CRIU_PATH;\n+    static {\n+        String path = System.getenv(\"CRAC_CRIU_PATH\");\n+        if (path == null) {\n+            for (String candidate : CRIU_CANDIDATES) {\n+                if (new File(candidate).exists()) {\n+                    path = candidate;\n+                    break;\n+                }\n+            }\n+        }\n+        CRIU_PATH = path;\n+    }\n+\n+    String dockerImageBaseName;\n+    String dockerImageBaseVersion;\n+    String dockerImageName;\n+    private List<String> dockerOptions; \/\/ Immutable\n+    private List<String> dockerCheckpointOptions; \/\/ Immutable\n+    private List<String> containerSetupCommand; \/\/ Immutable\n+    boolean containerUsePrivileged = true;\n+    boolean runContainerDirectly = false;\n+    \/\/ make sure to update copy constructor when adding new fields\n+\n+    boolean containerStarted;\n+\n+    public CracContainerBuilder() {\n+        super();\n+        dockerOptions = List.of();\n+        dockerCheckpointOptions = List.of();\n+        containerSetupCommand = List.of();\n+    }\n+\n+    protected CracContainerBuilder(CracContainerBuilder other) {\n+        super(other);\n+        dockerImageBaseName = other.dockerImageBaseName;\n+        dockerImageBaseVersion = other.dockerImageBaseVersion;\n+        dockerImageName = other.dockerImageName;\n+        dockerOptions = other.dockerOptions; \/\/ No deep copy because immutable\n+        dockerCheckpointOptions = other.dockerCheckpointOptions; \/\/ No deep copy because immutable\n+        containerSetupCommand = other.containerSetupCommand; \/\/ No deep copy because immutable\n+        containerUsePrivileged = other.containerUsePrivileged;\n+        runContainerDirectly = other.runContainerDirectly;\n+        \/\/ containerStarted is left out intentionally\n+    }\n+\n+    @Override\n+    protected CracContainerBuilder self() {\n+        return this;\n+    }\n+\n+    @Override\n+    public CracContainerBuilder copy() {\n+        return new CracContainerBuilder(this);\n+    }\n+\n+    public CracContainerBuilder withBaseImage(String name, String tag) {\n+        assertNull(dockerImageBaseName);\n+        assertNull(dockerImageBaseVersion);\n+        dockerImageBaseName = name;\n+        dockerImageBaseVersion = tag;\n+        return this;\n+    }\n+\n+    public CracContainerBuilder inDockerImage(String imageName) {\n+        assertNull(dockerImageName);\n+        dockerImageName = imageName;\n+        return this;\n+    }\n+\n+    public CracContainerBuilder dockerOptions(String... options) {\n+        dockerOptions = List.of(options);\n+        return this;\n+    }\n+\n+    public CracContainerBuilder clearDockerOptions() {\n+        dockerOptions = List.of();\n+        return this;\n+    }\n+\n+    public CracContainerBuilder dockerCheckpointOptions(String... options) {\n+        dockerCheckpointOptions = List.of(options);\n+        return this;\n+    }\n+\n+    public CracContainerBuilder containerSetup(String... cmd) {\n+        containerSetupCommand = List.of(cmd);\n+        return this;\n+    }\n+\n+    public CracContainerBuilder containerUsePrivileged(boolean usePrivileged) {\n+        containerUsePrivileged = usePrivileged;\n+        return this;\n+    }\n+\n+    public CracContainerBuilder runContainerDirectly(boolean runDirectly) {\n+        runContainerDirectly = runDirectly;\n+        return this;\n+    }\n+\n+    public void ensureContainerStarted() throws Exception {\n+        assertNotNull(dockerImageName, \"Docker image name must be specified\");\n+        if (engine == CracEngine.CRIU && CRIU_PATH == null) {\n+            fail(\"CRAC_CRIU_PATH is not set and cannot find criu executable in any of: \" + CRIU_CANDIDATES);\n+        }\n+        if (!containerStarted) {\n+            prepareContainer();\n+            List<String> cmd = prepareContainerCommand(dockerImageName, dockerOptions);\n+            log(\"Starting docker container:\\n\" + String.join(\" \", cmd));\n+            try (final var p = new ProcessBuilder().inheritIO().command(cmd).start()) {\n+                assertEquals(0, p.waitFor());\n+            }\n+            setupContainer();\n+            containerStarted = true;\n+        }\n+    }\n+    private void prepareContainer() throws Exception {\n+        DockerTestUtils.checkCanTestDocker();\n+\n+        if (runContainerDirectly && !containerSetupCommand.isEmpty()) {\n+            fail(\"runContainerDirectly and containerSetupCommand cannot be used together.\");\n+        }\n+        ensureContainerKilled();\n+\n+        \/\/ FIXME cooperate better with DockerTestUtils\n+        try {\n+            FileUtils.deleteFileTreeWithRetry(Path.of(\".\", dockerImageName.replace(\":\", \"-\")));\n+        } catch (NoSuchFileException ignore) {\n+        }\n+\n+        buildDockerImage();\n+    }\n+\n+    private void buildDockerImage() throws Exception {\n+        String previousBaseImageName = null;\n+        String previousBaseImageVersion = null;\n+        try {\n+            previousBaseImageName = System.getProperty(DockerfileConfig.BASE_IMAGE_NAME);\n+            previousBaseImageVersion = System.getProperty(DockerfileConfig.BASE_IMAGE_VERSION);\n+            if (dockerImageBaseName != null) {\n+                System.setProperty(DockerfileConfig.BASE_IMAGE_NAME, dockerImageBaseName);\n+            }\n+            if (dockerImageBaseVersion != null) {\n+                System.setProperty(DockerfileConfig.BASE_IMAGE_VERSION, dockerImageBaseVersion);\n+            }\n+            if (REUSE_IMAGE_IF_EXIST) {\n+                if (0 == DockerTestUtils.execute(Container.ENGINE_COMMAND, \"inspect\", \"--type=image\", dockerImageName).getExitValue()) {\n+                    return;\n+                }\n+            }\n+            DockerTestUtils.buildJdkContainerImage(dockerImageName);\n+        } finally {\n+            if (previousBaseImageName != null) {\n+                System.setProperty(DockerfileConfig.BASE_IMAGE_NAME, previousBaseImageName);\n+            } else {\n+                System.clearProperty(DockerfileConfig.BASE_IMAGE_NAME);\n+            }\n+            if (previousBaseImageVersion != null) {\n+                System.setProperty(DockerfileConfig.BASE_IMAGE_VERSION, previousBaseImageVersion);\n+            } else {\n+                System.clearProperty(DockerfileConfig.BASE_IMAGE_VERSION);\n+            }\n+        }\n+    }\n+\n+    private List<String> prepareContainerCommand(String imageName, List<String> options) {\n+        List<String> cmd = prepareContainerCommandBase(imageName, options);\n+        cmd.addAll(Arrays.asList(\"sleep\", \"3600\"));\n+        return cmd;\n+    }\n+\n+    private List<String> prepareContainerCommandBase(String imageName, List<String> options) {\n+        List<String> cmd = new ArrayList<>();\n+        cmd.add(Container.ENGINE_COMMAND);\n+        cmd.addAll(Arrays.asList(\"run\", \"--rm\"));\n+        if (!runContainerDirectly) {\n+            cmd.add(\"-d\");\n+            cmd.add(\"--init\"); \/\/ otherwise the checkpointed process would not be reaped (by sleep with PID 1)\n+        }\n+        if (containerUsePrivileged) {\n+            cmd.add(\"--privileged\"); \/\/ required to give CRIU sufficient permissions\n+        }\n+        int entryCounter = 0;\n+        for (var entry : Utils.TEST_CLASS_PATH.split(File.pathSeparator)) {\n+            cmd.addAll(Arrays.asList(\"--volume\", entry + \":\/cp\/\" + (entryCounter++)));\n+        }\n+        new File(System.getProperty(\"user.dir\") + \"\/cr\").mkdirs(); \/\/ create \"cr\" dir under the current user, to be able to delete it later.\n+        cmd.addAll(Arrays.asList(\"--volume\", System.getProperty(\"user.dir\") + \"\/cr:\/cr\"));\n+        if (engine == CracEngine.CRIU) {\n+            cmd.addAll(Arrays.asList(\"--volume\", CRIU_PATH + \":\/criu\"));\n+            cmd.addAll(Arrays.asList(\"--env\", \"CRAC_CRIU_PATH=\/criu\"));\n+        }\n+        cmd.addAll(Arrays.asList(\"--name\", CONTAINER_NAME));\n+        if (debug) {\n+            cmd.addAll(Arrays.asList(\"--publish\", \"5005:5005\"));\n+        }\n+        cmd.addAll(options);\n+        cmd.add(imageName);\n+        return cmd;\n+    }\n+\n+    private void setupContainer() throws Exception {\n+        if (!containerSetupCommand.isEmpty()) {\n+            List<String> cmd = new ArrayList<>();\n+            cmd.addAll(Arrays.asList(Container.ENGINE_COMMAND, \"exec\", CONTAINER_NAME));\n+            cmd.addAll(containerSetupCommand);\n+            log(\"Container set up:\\n\" + String.join(\" \", cmd));\n+            DockerTestUtils.execute(cmd).shouldHaveExitValue(0);\n+        }\n+    }\n+\n+    public void ensureContainerKilled() throws Exception {\n+        DockerTestUtils.execute(Container.ENGINE_COMMAND, \"kill\", CONTAINER_NAME).getExitValue();\n+        if (!DockerTestUtils.RETAIN_IMAGE_AFTER_TEST) {\n+            DockerTestUtils.removeDockerImage(dockerImageName);\n+        }\n+    }\n+\n+    public void recreateContainer(String imageName, String... options) throws Exception {\n+        assertTrue(containerStarted);\n+        DockerTestUtils.execute(Container.ENGINE_COMMAND, \"kill\", CONTAINER_NAME).getExitValue();\n+\n+        \/\/ Docker needs some time to remove a container after kill\n+        OutputAnalyzer oa;\n+        do {\n+            oa = DockerTestUtils.execute(Container.ENGINE_COMMAND, \"ps\");\n+            oa.getExitValue();\n+        } while (oa.getStdout().contains(CONTAINER_NAME));\n+\n+        List<String> cmd = prepareContainerCommand(imageName, List.of(options));\n+        log(\"Recreating docker container:\\n\" + String.join(\" \", cmd));\n+        try (final var p = new ProcessBuilder().inheritIO().command(cmd).start()) {\n+            assertEquals(0, p.waitFor());\n+        }\n+    }\n+\n+    @Override\n+    public CracProcess startCheckpoint(List<String> javaPrefix) throws Exception {\n+        if (runContainerDirectly) {\n+            prepareContainer();\n+        } else {\n+            ensureContainerStarted();\n+        }\n+        return super.startCheckpoint(javaPrefix);\n+    }\n+\n+    @Override\n+    public CracProcess startRestoreWithArgs(List<String> javaPrefix, List<String> args) throws Exception {\n+        if (!runContainerDirectly) {\n+            ensureContainerStarted();\n+        }\n+        return super.startRestoreWithArgs(javaPrefix, args);\n+    }\n+\n+    @Override\n+    protected List<String> getPlainCommandPrefix() {\n+        return Arrays.asList(Container.ENGINE_COMMAND, \"exec\", CONTAINER_NAME);\n+    }\n+\n+    @Override\n+    protected String getTestClassPath() {\n+        StringBuilder builder = new StringBuilder();\n+        final int numEntries = Utils.TEST_CLASS_PATH.split(File.pathSeparator).length;\n+        for (int i = 0; i < numEntries; ++i) {\n+            builder.append(\"\/cp\/\").append(i).append(File.pathSeparator);\n+        }\n+        return builder.toString();\n+    }\n+\n+    @Override\n+    protected List<String> getDefaultJavaPrefix() {\n+        List<String> cmd;\n+        if (runContainerDirectly) {\n+            cmd = prepareContainerCommandBase(dockerImageName, dockerOptions);\n+        } else {\n+            cmd = new ArrayList<>();\n+            cmd.add(Container.ENGINE_COMMAND);\n+            cmd.add(\"exec\");\n+            cmd.addAll(dockerCheckpointOptions);\n+            cmd.add(CONTAINER_NAME);\n+        }\n+        cmd.add(DOCKER_JAVA);\n+        return cmd;\n+    }\n+\n+    public void checkpointViaJcmd() throws Exception {\n+        runJcmd(main().getName(), \"JDK.checkpoint\").shouldHaveExitValue(0)\n+                .outputTo(System.out).errorTo(System.err);\n+    }\n+\n+    @Override\n+    public OutputAnalyzer runJcmd(String id, String... command) throws Exception {\n+        final List<String> cmd = new ArrayList<>();\n+        cmd.addAll(List.of(Container.ENGINE_COMMAND, \"exec\", CONTAINER_NAME, \"\/jdk\/bin\/jcmd\"));\n+        cmd.add(id);\n+        cmd.addAll(Arrays.asList(command));\n+        return DockerTestUtils.execute(cmd);\n+    }\n+}\n","filename":"test\/lib\/jdk\/test\/lib\/crac\/CracContainerBuilder.java","additions":362,"deletions":0,"binary":false,"changes":362,"status":"added"},{"patch":"@@ -23,1 +23,1 @@\n-    private final CracBuilder builder;\n+    private final CracBuilderBase<?> builder;\n@@ -26,1 +26,1 @@\n-    public CracProcess(CracBuilder builder, List<String> cmd) throws IOException {\n+    public CracProcess(CracBuilderBase<?> builder, List<String> cmd) throws IOException {\n","filename":"test\/lib\/jdk\/test\/lib\/crac\/CracProcess.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"}]}