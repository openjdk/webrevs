{"files":[{"patch":"@@ -50,0 +50,1 @@\n+    - [Code Models](articles\/code-models) (June 2024)\n","filename":"site\/_index.md","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -0,0 +1,1340 @@\n+# Code Models\n+\n+#### Paul Sandoz {.author}\n+\n+#### June 2024 {.date}\n+\n+Code reflection, an enhancement to Java reflection, enables access to symbolic\n+representations of Java code in method bodies and lambda bodies. \"Symbolic\n+representations of Java code\" may seem like a fancy term, but its easily\n+demystified. It's a model of Java code where the code of a method or lambda body\n+is represented as instances of specific Java classes arranged in an appropriate\n+structure. Thereby it is possible to write Java programs that manipulate Java\n+programs. Before we get into the details of how code reflection models Java code\n+we should talk about two existing approaches to modeling Java code.\n+\n+Java developers use a Java program every day that manipulates Java programs.\n+It's called the Java compiler. It has its own internal model of Java code,\n+instances of which are called Abstract Syntax Trees (ASTs). The AST model\n+closely aligns with the Java grammar as specified by the Java Language\n+Specification. The Java compiler parses source program text into instances of\n+specific Java classes that form the AST, traverses and manipulates the AST to\n+verify the source program is a correct, and if so generates class files\n+containing bytecode instructions.\n+\n+Bytecode is another model of Java code, one that is standardized by the Java\n+Virtual Machine Specification and consumed by Java run times. The Java compiler\n+transforms Java code represented as instances of specific Java classes in the\n+AST model into Java code represented as specific classes in the bytecode model.\n+After which it can generate code attributes in class files. The OpenJDK HotSpot\n+runtime, a C++ program, manipulates the bytecode to interpret it or compile\n+parts of it to executable machine code.\n+\n+The AST model and bytecode model naturally serve different purposes, and as a\n+result they have very different properties. However, the source program, the\n+AST, the bytecode, and even generated machine code, represent the same Java\n+program. The Java compiler and HotSpot runtime preserve Java program meaning\n+when they manipulate representations of Java code.\n+\n+Neither the AST model nor the bytecode model is a suitable model for the\n+purposes of code reflection. We want to ensure code reflection's model of Java\n+code is broadly applicable across many use cases that may ingest Java code and\n+generate derived Java code or foreign code (such as differentiated Java code,\n+GPU code, or SQL statements). The AST model is too close to the source\n+containing too much information (syntactic details), and the bytecode model too\n+close to an executable form with useful information removed (types erased,\n+structures flattened). Both are hard to analyze and transform. So much so modern\n+compilers, in general, will commonly translate an AST-based model or\n+instruction-based (stack machine) model to a more appropriate model that is\n+easier to analyze and transform. Herein lies important clues as to the design of\n+code reflection's model.\n+\n+## Code model design\n+\n+Code reflection devises a third model of Java code, instances of which are\n+called _code models_. Code models for identified method and lambda bodies are\n+produced by the Java compiler, stored in class files, and made accessible at run\n+time via reflective APIs. The Java compiler will transform an AST to a Java code\n+model, in addition to generating bytecode instructions. Such code models\n+preserve Java program meaning. The code model will not contain all the syntactic\n+details as present in the AST but will retain type information and structural\n+information that is not present in bytecode. It is useful to think of code\n+models situated somewhere between ASTs and bytecode, initially closer to ASTs\n+than to the bytecode (further on we shall present how a code model may be\n+transformed and become closer to bytecode).\n+\n+The code model design is heavily influenced by the design of data structures\n+used by many modern compilers to represent code. These data structures are\n+commonly referred to as Intermediate Representations (IRs). The design is\n+further influenced by Multi-Level Intermediate Representation (MLIR), a\n+sub-project of the LLVM Compiler Infrastructure project. Our intention is not to\n+compete with such compilers. We will focus on high-fidelity modeling of Java\n+code, manipulation of that code at a mid- to high-level, and interchange to\n+other models and compiler toolchains (native or otherwise). A particularly\n+challenging aspect of code reflection is ensuring the code model design and\n+respective Java API be broadly accessible to competent Java developers who don't\n+have PhDs in programming language theory and compilers (although we hope those\n+that do will enjoy using code reflection).\n+\n+A code model contains code elements, operations, bodies, and blocks, that form a\n+tree. An operation contains zero or more bodies. A body contains one or more\n+blocks. A block contains a sequence of one or more operations. A block can\n+declare zero or more block parameters, values. An operation declares an\n+operation result, a value. An operation may use values as operands, but only\n+after they have been declared. A value has a type.\n+\n+Code models are in Static Single Assignment (SSA) form, values can only be\n+assigned exactly once. The blocks within a body are interconnected with each\n+other and form a control flow graph. Values are also interconnected with each\n+other and form either expression graphs or use graphs. The relationship between\n+an operation result and its operands form part of an expression graph. The\n+relationship between a value and its uses form part of a use graph.\n+\n+The Java API for code models has Java classes corresponding to operation, body,\n+block, block parameter, operation result, value, and value type. A code model\n+comprises instances of those Java classes arranged in the tree structure with\n+support for tree traversal. Additionally, a model supports graph traversal by\n+connecting blocks to blocks, operation results to operands, and values to\n+dependent values (uses).\n+\n+Using this simple tree structure we can define specific operations, extending\n+from the Java class associated with an operation, that model many Java language\n+constructs, and therefore we can build code models that model many Java\n+programs. This may appear surprising at first. Readers may be more familiar with\n+term \"operation\" in a more conventional sense, such as arithmetic operations.\n+However, given the structure described above, there is no need to limit\n+ourselves to this conventional sense. We are free to define an operation whose\n+operational semantics model a method declaration, model a lambda expression, or\n+even model a `try` statement.\n+\n+Code models are immutable. Code models can be produced by building, or by\n+transforming an existing code model. Transforming takes an input code model and\n+builds an output code model. For each input operation encountered in the input\n+code model we have the choice to add that operation to the builder of the output\n+code model (copying), to not add it (removal), or add new output operations\n+(replacement or addition).\n+\n+This may all seem a little abstract so lets look at some examples.\n+\n+> All the code presented in this article is available\n+> in [test source][test-source] located in the Babylon repository\n+\n+[test-source]: https:\/\/github.com\/openjdk\/babylon\/blob\/code-reflection\/test\/jdk\/java\/lang\/reflect\/code\/TestExpressionGraphs.java\n+\n+## Code model access\n+\n+Consider the following method, `sub`, that subtracts two values.\n+\n+[\/\/]: # (@formatter:off)\n+```java\n+@CodeReflection\n+static double sub(double a, double b) {\n+   return a - b;\n+}\n+```\n+[\/\/]: # (@formatter:on)\n+\n+We annotate it with `@CodeReflection` to identify that the method's code model\n+should be built by the compiler and made accessible at runtime using the\n+reflection API.\n+\n+We find the `java.lang.reflect.Method` instance of `sub`, and then ask it for\n+its code model by invoking the method `getCodeModel`. Only methods annotated\n+with `@CodeReflection` will have code models, hence this method is partial.\n+\n+[\/\/]: # (@formatter:off)\n+```java\n+\/\/ Get the reflective object for method sub\n+Method m = ExpressionGraphs.class.getDeclaredMethod(\n+        \"sub\", double.class, double.class);\n+\/\/ Get the code model for method sub\n+Optional<CoreOp.FuncOp> oModel = m.getCodeModel();\n+CoreOp.FuncOp model = oModel.orElseThrow();\n+```\n+[\/\/]: # (@formatter:on)\n+\n+## Traversal of code model elements\n+\n+`sub`'s code model is represented as an instance of `CoreOp.FuncOp`,\n+corresponding to a *function declaration* operation that models a Java method\n+declaration. What does the code model of `sub` look like? We can get a sense of\n+this by traversing the model, a tree, and printing out all the code elements.\n+\n+[\/\/]: # (@formatter:off)\n+```jshelllanguage\n+\/\/ Depth-first search, reporting elements in pre-order\n+model.traverse(null, (acc, codeElement) -> {\n+    \/\/ Count the depth of the code element by\n+    \/\/ traversing up the tree from child to parent\n+    int depth = 0;\n+    CodeElement<?, ?> parent = codeElement;\n+    while ((parent = parent.parent()) != null) depth++;\n+    \/\/ Print out code element class\n+    System.out.println(\"  \".repeat(depth) + codeElement.getClass());\n+    return acc;\n+});\n+```\n+[\/\/]: # (@formatter:on)\n+\n+> The first argument passed to the `traverse` method is the initial value of an\n+> object that can be used to accumulate a result. The final accumulated\n+> result is returned. In this case we don't need to accumulate, so we pass\n+> a `null` value.\n+\n+The method `traverse` calls the lambda expression for each encountered _code\n+element_ in the model and prints out the class name prefixed with space\n+proportional to the tree depth of the element. The output is shown below.\n+\n+```text\n+class java.lang.reflect.code.op.CoreOp$FuncOp\n+  class java.lang.reflect.code.Body\n+    class java.lang.reflect.code.Block\n+      class java.lang.reflect.code.op.CoreOp$VarOp\n+      class java.lang.reflect.code.op.CoreOp$VarOp\n+      class java.lang.reflect.code.op.CoreOp$VarAccessOp$VarLoadOp\n+      class java.lang.reflect.code.op.CoreOp$VarAccessOp$VarLoadOp\n+      class java.lang.reflect.code.op.CoreOp$SubOp\n+      class java.lang.reflect.code.op.CoreOp$ReturnOp\n+```\n+\n+We can observe that the top of the tree is the `CoreOp.FuncOp` which contains\n+one child, a `Body`, which in turn contains one child, a `Block`, which in turn\n+contains a sequence of operations.\n+\n+The implementation of `traverse` applies the code element to the function\n+parameter and then the code element's children are recursively traversed.\n+\n+```java\n+default <T> T traverse(T t, BiFunction<T, CodeElement<?, ?>, T> v) {\n+    t = v.apply(t, this);\n+    for (C r : children()) {\n+        t = r.traverse(t, v);\n+    }\n+\n+    return t;\n+}\n+```\n+\n+So far we have seen that the code model API supports two kinds of tree traversal\n+of code elements:\n+\n+1. up the tree, from child to parent when we calculated the depth of a code\n+   element; and\n+2. down the tree, from parent to children in the implementation of\n+   the `traverse` method.\n+\n+Later we shall explore traversal of values in code models.\n+\n+## Explanation of code models by printing them\n+\n+Our traversal that prints out the code element classes is not particularly\n+informative. A superior way to see what a code model looks like is to traverse\n+the model and print out more descriptive information about each code element.\n+Thankfully we don't need to write this ourselves. We can call the method\n+`toText` on the model that returns a string representation that we can then\n+print.\n+\n+```jshelllanguage\n+System.out.println(model.toText());\n+```\n+\n+Which outputs the following text.\n+\n+```text\n+func @\"sub\" @loc=\"19:5:file:\/...\/ExpressionGraphs.java\" (%0 : double, %1 : double)double -> {\n+    %2 : Var<double> = var %0 @\"a\" @loc=\"19:5\";\n+    %3 : Var<double> = var %1 @\"b\" @loc=\"19:5\";\n+    %4 : double = var.load %2 @loc=\"21:16\";\n+    %5 : double = var.load %3 @loc=\"21:20\";\n+    %6 : double = sub %4 %5 @loc=\"21:16\";\n+    return %6 @loc=\"21:9\";\n+};\n+```\n+\n+> A code model's text is designed to be human-readable and is very useful for\n+> debugging models and for testing. It is also an invaluable for explaining\n+> code models, and we shall use it extensively in this article.\n+\n+> To aid debugging each operation has line number information, and the root\n+> operation also has source information from where the code model originated.\n+\n+The code model text shows the code model's root is a function declaration\n+(`func`) operation. The lambda-like expression represents the fusion of the\n+function declaration operation's single body and the body's first and only\n+block, called the entry block. Then there is a sequence of operations in the\n+entry block. For each operation there is an instance of a corresponding Java\n+class, all of which extend from the abstract class `java.lang.reflect.code.Op`\n+and which have already seen when we printed out the classes. Unsurprisingly the\n+printed operations and printed operation classes occur in the same order since\n+the `toText` method traverses the model in the same order as we traversed.\n+\n+> The function declaration operation has an operation result, like all other\n+> operations, but since it's the root of the tree and not used we don't\n+> present it.\n+\n+The entry block has two block parameters, `%0` and `%1` each described by a type\n+of `double`, which model method `sub`'s initial values for parameters `a`\n+and `b`. The method parameters themselves (variables) are modeled as `var`\n+operations that are initialized with the corresponding block parameters. The\n+result of a `var` operation is value, a _variable value_, whose type is a\n+_variable type_, `Var<T>`. A variable value holds another value of type `T`, the\n+value of the variable, which can be loaded or stored using variable access\n+operations, respectively modeling an expression that denotes a variable and\n+assignment to a variable.\n+\n+> Although `Var<T>` looks like a generic Java type it is not. Just as\n+> we can define a set of operations for use in code models we can also\n+> define a set of types. We have a set of operations for modeling Java code,\n+> and we also have a set of code model types for modeling Java types. In\n+> addition, we require some other non-Java types such as for the\n+> modeling of local variables or say the grouping of multiple values (tuples)\n+> where the rules for Java types do not apply.\n+\n+The expressions denoting parameters `a` and `b` are modeled as `var.load`\n+operations. The results of these operations are _used_ as operands of other\n+operations. Likewise, subsequent operations also produce results, e.g., `%6` the\n+result of a subtraction operation, that is used as an operand of the\n+`return` operation.\n+\n+> The `return` operation has a result, again like all other operations, but\n+> since that result cannot be meaningfully used we don't present it by default.\n+\n+Now let us consider a slightly more complex method, `distance1`, that computes a\n+simple mathematical expression, the distance between two scalar values.\n+\n+[\/\/]: # (@formatter:off)\n+```java\n+@CodeReflection\n+static double distance1(double a, double b) {\n+   return Math.abs(a - b);\n+}\n+```\n+[\/\/]: # (@formatter:on)\n+\n+This is similar to the `sub` method except we now have an invocation\n+to `Math.abs` that operates on the result of the subtraction. How is that\n+invocation (a class invocation expression) represented in the code model? Or\n+alternatively how is the invocation expression modelled? To help answer this\n+question we can print out the code model, like we did previously.\n+\n+```text\n+func @\"distance1\" @loc=\"24:5:file:\/...\/ExpressionGraphs.java\" (%0 : double, %1 : double)double -> {\n+    %2 : Var<double> = var %0 @\"a\" @loc=\"24:5\";\n+    %3 : Var<double> = var %1 @\"b\" @loc=\"24:5\";\n+    %4 : double = var.load %2 @loc=\"26:25\";\n+    %5 : double = var.load %3 @loc=\"26:29\";\n+    %6 : double = sub %4 %5 @loc=\"26:25\";\n+    %7 : double = invoke %6 @\"java.lang.Math::abs(double)double\" @loc=\"26:16\";\n+    return %7 @loc=\"26:9\";\n+};\n+```\n+\n+The invocation is modeled as an `invoke` operation, and its result is used as\n+the operand of the `return` operation. It accepts as an operand the result of\n+the `sub` operation. The `invoke` operation declares a method reference, a\n+symbolic description of the method `Math.abs`.\n+\n+> In this case we know the `invoke` operation models a class invocation\n+> expression (a call to a static method) because the number of\n+> operands is the same as the number of described method parameters. An\n+> instance invocation expression would have a number of operands that is one\n+> more than the number described method parameters, where the first operand\n+> is the receiver.\n+\n+## Code models and Static Single Assignment (SSA)\n+\n+We can clearly see code models are in Static Single Assignment (SSA) form, and\n+there is no explicit distinction, as there is in the source code, between\n+statements and expressions. Block parameters and operation results are declared\n+before they are used and cannot be reassigned (and we therefore require special\n+operations and types to model variables). It's as if we were to rewrite\n+method `distance1` as say `distance1a`, where for each simple expression we\n+assign the result to a new final local variable and then subsequently use that\n+variable.\n+\n+[\/\/]: # (@formatter:off)\n+```java\n+@CodeReflection\n+static double distance1a(final double a, final double b) {\n+    final double diff = a - b;\n+    final double result = Math.abs(diff);\n+    return result;\n+}\n+```\n+[\/\/]: # (@formatter:on)\n+\n+> We are not encouraging developers to generally write code like this!\n+> Source code should be readable and maintainable. Code models have\n+> different requirements, and so the text of models is naturally not\n+> designed to be as readable and maintainable as the source code it\n+> originated from.\n+\n+We can print out the code model for method `distance1a`.\n+\n+```text\n+func @\"distance1a\" @loc=\"29:5:file:\/...\/ExpressionGraphs.java\" (%0 : double, %1 : double)double -> {\n+    %2 : Var<double> = var %0 @\"a\" @loc=\"29:5\";\n+    %3 : Var<double> = var %1 @\"b\" @loc=\"29:5\";\n+    %4 : double = var.load %2 @loc=\"31:29\";\n+    %5 : double = var.load %3 @loc=\"31:33\";\n+    %6 : double = sub %4 %5 @loc=\"31:29\";\n+    %7 : Var<double> = var %6 @\"diff\" @loc=\"31:9\";\n+    %8 : double = var.load %7 @loc=\"32:40\";\n+    %9 : double = invoke %8 @\"java.lang.Math::abs(double)double\" @loc=\"32:31\";\n+    %10 : Var<double> = var %9 @\"result\" @loc=\"32:9\";\n+    %11 : double = var.load %10 @loc=\"33:16\";\n+    return %11 @loc=\"33:9\";\n+};\n+```\n+\n+The model looks very similar to `distance1`'s model, except that we now have\n+additional `var` operations modeling _local_ variables `diff` and `result`. Even\n+though there are differences both methods and their models are equivalent in\n+terms of program behaviour (ignoring the effects of debugging). We can show this\n+by performing a pure SSA transformation on both models and comparing them.\n+\n+```java\n+CoreOp.FuncOp ssaModel = SSA.transform(model);\n+```\n+\n+Such a transformation removes the variable operations, replacing the use of\n+their results with their operands.\n+\n+Here are the two models after transforming.\n+\n+```text\n+func @\"distance1\" @loc=\"24:5:file:\/...\/ExpressionGraphs.java\" (%0 : double, %1 : double)double -> {\n+    %2 : double = sub %0 %1 @loc=\"26:25\";\n+    %3 : double = invoke %2 @\"java.lang.Math::abs(double)double\" @loc=\"26:16\";\n+    return %3 @loc=\"26:9\";\n+};\n+\n+func @\"distance1a\" @loc=\"29:5:file:\/...\/ExpressionGraphs.java\" (%0 : double, %1 : double)double -> {\n+    %2 : double = sub %0 %1 @loc=\"31:29\";\n+    %3 : double = invoke %2 @\"java.lang.Math::abs(double)double\" @loc=\"32:31\";\n+    return %3 @loc=\"33:9\";\n+};\n+```\n+\n+Apart from the difference in location details the two models are identical, and\n+have become easier to analyse for certain use cases.\n+\n+> Notice the SSA transformation has preserved location information on\n+> operations that were copied\n+\n+## Code models with simple control flow\n+\n+Let's further modify `distance1b` by replacing the method invocation to\n+`Math.abs` with an (almost) equivalent inlined expression using the conditional\n+operator `? :`.\n+\n+[\/\/]: # (@formatter:off)\n+```java\n+@CodeReflection\n+static double distance1b(final double a, final double b) {\n+    final double diff = a - b;\n+    \/\/ Note, incorrect for negative zero values\n+    final double result = diff < 0d ? -diff : diff;\n+    return result;\n+}\n+```\n+[\/\/]: # (@formatter:on)\n+\n+We now have some control flow in the expression whose result is assigned to\n+local variable `result`. How do we model conditional operator `? :`? To find out\n+let's print out `distance1b`'s model.\n+\n+```text\n+func @\"distance1b\" @loc=\"36:5:file:\/...\/ExpressionGraphs.java\" (%0 : double, %1 : double)double -> {\n+    %2 : Var<double> = var %0 @\"a\" @loc=\"36:5\";\n+    %3 : Var<double> = var %1 @\"b\" @loc=\"36:5\";\n+    %4 : double = var.load %2 @loc=\"38:29\";\n+    %5 : double = var.load %3 @loc=\"38:33\";\n+    %6 : double = sub %4 %5 @loc=\"38:29\";\n+    %7 : Var<double> = var %6 @\"diff\" @loc=\"38:9\";\n+    %8 : double = java.cexpression @loc=\"40:31\"\n+        ()boolean -> {\n+            %9 : double = var.load %7 @loc=\"40:31\";\n+            %10 : double = constant @\"0.0\" @loc=\"40:38\";\n+            %11 : boolean = lt %9 %10 @loc=\"40:31\";\n+            yield %11 @loc=\"40:31\";\n+        }\n+        ()double -> {\n+            %12 : double = var.load %7 @loc=\"40:44\";\n+            %13 : double = neg %12 @loc=\"40:43\";\n+            yield %13 @loc=\"40:31\";\n+        }\n+        ()double -> {\n+            %14 : double = var.load %7 @loc=\"40:51\";\n+            yield %14 @loc=\"40:31\";\n+        };\n+    %15 : Var<double> = var %8 @\"result\" @loc=\"40:9\";\n+    %16 : double = var.load %15 @loc=\"41:16\";\n+    return %16 @loc=\"41:9\";\n+};\n+```\n+\n+The `java.cexpression` operation models the conditional operator `? :`. It\n+contains three bodies, each with one block. Each expression of the conditional\n+operator `? :` is modeled as a body, and therefore we capture code structure\n+associated with control flow. The operation specifies how control flows between\n+its bodies according to Java program behaviour as specified by the Java Language\n+Specification. Many operations modeling more complex Java language expressions\n+and statements will follow a similar pattern.\n+\n+Sometimes it's useful to process a model with a `java.cexpression` operation but\n+in other cases it may be problematic as we need to understand the operation's\n+behaviour. It is possible to replace a `java.cexpression` operation with other\n+code elements that explicitly model the operation's control flow in a more basic\n+and general form. We can perform such replacement with a _transformation_\n+that _lowers_ such operations.\n+\n+[\/\/]: # (@formatter:off)\n+```jshelllanguage\n+CoreOp.FuncOp loweredModel = model.transform(OpTransformer.LOWERING_TRANSFORMER);\n+```\n+[\/\/]: # (@formatter:on)\n+\n+The `transform` method traverses a model and builds a new model. It accepts a\n+transformer function as an argument that implements the transformation. In this\n+case the transformer `LOWERING_TRANSFORMER` lowers operations that are capable\n+of being lowered, such as the `java.cexpression` operation (there are many other\n+lowerable operations, such as the operation modelling a `for` loop that we shall\n+see later.)\n+\n+Printing out the lowered model reveals the replacing code elements.\n+\n+```text\n+func @\"distance1b\" @loc=\"36:5:file:\/...\/ExpressionGraphs.java\" (%0 : double, %1 : double)double -> {\n+    %2 : Var<double> = var %0 @\"a\" @loc=\"36:5\";\n+    %3 : Var<double> = var %1 @\"b\" @loc=\"36:5\";\n+    %4 : double = var.load %2 @loc=\"38:29\";\n+    %5 : double = var.load %3 @loc=\"38:33\";\n+    %6 : double = sub %4 %5 @loc=\"38:29\";\n+    %7 : Var<double> = var %6 @\"diff\" @loc=\"38:9\";\n+    %8 : double = var.load %7 @loc=\"40:31\";\n+    %9 : double = constant @\"0.0\" @loc=\"40:38\";\n+    %10 : boolean = lt %8 %9 @loc=\"40:31\";\n+    cbranch %10 ^block_1 ^block_2;\n+  \n+  ^block_1:\n+    %11 : double = var.load %7 @loc=\"40:44\";\n+    %12 : double = neg %11 @loc=\"40:43\";\n+    branch ^block_3(%12);\n+  \n+  ^block_2:\n+    %13 : double = var.load %7 @loc=\"40:51\";\n+    branch ^block_3(%13);\n+  \n+  ^block_3(%14 : double):\n+    %15 : Var<double> = var %14 @\"result\" @loc=\"40:9\";\n+    %16 : double = var.load %15 @loc=\"41:16\";\n+    return %16 @loc=\"41:9\";\n+};\n+```\n+\n+We can clearly see three new blocks have been added to the `func`\n+operation's body, `^block_1`, `^block_2`, `^block_3`, and they are\n+interconnected. They form a _control-flow graph_.\n+\n+The `func` operation's body's entry block contains the same operations in the\n+prior model up to the `java.cexpression` operation. Then all operations, except\n+the last, in the first body of the `java.cexpression` operation have been\n+appended to the entry block. All operations, except the last, in the second body\n+of the `java.cexpression` operation have been appended to `^block_1`. All\n+operations, except the last, in the third body of the `java.cexpression`\n+operation have been appended to `^block_2`. Finally `^block_3` contains the same\n+operations in the prior model that occur after the `java.cexpression` operation.\n+\n+The last operations in each body of the `java.cexpression` operation,\n+`yield` operations, are replaced with a branch operations. The entry block\n+branches conditionally to a _successor_ block, either `^block_1` or `^block_2`\n+based on its boolean operand. Both of those blocks branch unconditionally to\n+successor `^block_3`, and they each pass their yielded result as a block\n+argument. `^block_3` has a block parameter, `%14`, that replaces the result of\n+the `java.cexpression` operation.\n+\n+> Block parameter, `%14`, represents a value that comes from\n+> two control flow paths. Such values are equivalent to PHI (Φ) nodes or\n+> PHI instructions in other intermediate representations. Block arguments and\n+> block parameters look and feel like function arguments and function\n+> parameters.\n+> Blocks look like functions. And, branches to blocks look like function\n+> calls or tail calls. This is much easier for developers to understand than PHI\n+> nodes.\n+\n+We can observe that the child blocks of a body occur in a specific order,\n+reverse postorder where generally a block occurs before its successor(s). This\n+order is useful for control-flow analysis.\n+\n+> Reverse postorder is a topological sort of the blocks in the control-flow\n+> graph\n+\n+Transforming the lowered model with the SSA transformation (presented earlier)\n+results in a simpler model.\n+\n+```text\n+func @\"distance1b\" @loc=\"36:5:file:\/...\/ExpressionGraphs.java\" (%0 : double, %1 : double)double -> {\n+    %2 : double = sub %0 %1 @loc=\"38:29\";\n+    %3 : double = constant @\"0.0\" @loc=\"40:38\";\n+    %4 : boolean = lt %2 %3 @loc=\"40:31\";\n+    cbranch %4 ^block_1 ^block_2;\n+  \n+  ^block_1:\n+    %5 : double = neg %2 @loc=\"40:43\";\n+    branch ^block_3(%5);\n+  \n+  ^block_2:\n+    branch ^block_3(%2);\n+  \n+  ^block_3(%6 : double):\n+    return %6 @loc=\"41:9\";\n+};\n+```\n+\n+> The SSA transformation is implemented as a code model transformer, like\n+> the lowering transformer, it's just implemented in the `SSA.transform` method\n+\n+All three models have the same program behaviour as the original Java program.\n+\n+## Code models with more complex control flow\n+\n+Let's enhance the distance function to compute the distance between two\n+N-dimensional points.\n+\n+[\/\/]: # (@formatter:off)\n+```java\n+@CodeReflection\n+static double distanceN(double[] a, double[] b) {\n+    double sum = 0d;\n+    for (int i = 0; i < a.length; i++) {\n+        sum += Math.pow(a[i] - b[i], 2d);\n+    }\n+    return Math.sqrt(sum);\n+}\n+```\n+[\/\/]: # (@formatter:on)\n+\n+We loop over the number of dimensions, sum the square of the distance between\n+each dimension, and then return the square root of the final sum.\n+\n+How do we model the `for` statement? To find out let's print out `distanceN`'s\n+model.\n+\n+```text\n+func @\"distanceN\" @loc=\"44:5:file:\/...\/ExpressionGraphs.java\" (%0 : double[], %1 : double[])double -> {\n+    %2 : Var<double[]> = var %0 @\"a\" @loc=\"44:5\";\n+    %3 : Var<double[]> = var %1 @\"b\" @loc=\"44:5\";\n+    %4 : double = constant @\"0.0\" @loc=\"46:22\";\n+    %5 : Var<double> = var %4 @\"sum\" @loc=\"46:9\";\n+    java.for @loc=\"47:9\"\n+        ()Var<int> -> {\n+            %6 : int = constant @\"0\" @loc=\"47:22\";\n+            %7 : Var<int> = var %6 @\"i\" @loc=\"47:14\";\n+            yield %7 @loc=\"47:9\";\n+        }\n+        (%8 : Var<int>)boolean -> {\n+            %9 : int = var.load %8 @loc=\"47:25\";\n+            %10 : double[] = var.load %2 @loc=\"47:29\";\n+            %11 : int = array.length %10 @loc=\"47:29\";\n+            %12 : boolean = lt %9 %11 @loc=\"47:25\";\n+            yield %12 @loc=\"47:9\";\n+        }\n+        (%13 : Var<int>)void -> {\n+            %14 : int = var.load %13 @loc=\"47:39\";\n+            %15 : int = constant @\"1\" @loc=\"47:39\";\n+            %16 : int = add %14 %15 @loc=\"47:39\";\n+            var.store %13 %16 @loc=\"47:39\";\n+            yield @loc=\"47:9\";\n+        }\n+        (%17 : Var<int>)void -> {\n+            %18 : double = var.load %5 @loc=\"48:13\";\n+            %19 : double[] = var.load %2 @loc=\"48:29\";\n+            %20 : int = var.load %17 @loc=\"48:31\";\n+            %21 : double = array.load %19 %20 @loc=\"48:29\";\n+            %22 : double[] = var.load %3 @loc=\"48:36\";\n+            %23 : int = var.load %17 @loc=\"48:38\";\n+            %24 : double = array.load %22 %23 @loc=\"48:36\";\n+            %25 : double = sub %21 %24 @loc=\"48:29\";\n+            %26 : double = constant @\"2.0\" @loc=\"48:42\";\n+            %27 : double = invoke %25 %26 @\"java.lang.Math::pow(double, double)double\" @loc=\"48:20\";\n+            %28 : double = add %18 %27 @loc=\"48:13\";\n+            var.store %5 %28 @loc=\"48:13\";\n+            java.continue @loc=\"47:9\";\n+        };\n+    %29 : double = var.load %5 @loc=\"50:26\";\n+    %30 : double = invoke %29 @\"java.lang.Math::sqrt(double)double\" @loc=\"50:16\";\n+    return %30 @loc=\"50:9\";\n+};\n+```\n+\n+The `java.for` operation models the `for` statement. There are four bodies\n+corresponding, in order, to four nonterminal symbols in the grammar specified in\n+the Java Language Specification:\n+\n+```text\n+BasicForStatement:\n+  for ( [ForInit] ; [Expression] ; [ForUpdate] ) Statement \n+```\n+\n+which also states (in section [14.14.1][jls-14.14.1]):\n+\n+> The basic for statement executes some initialization code, then executes an\n+> _Expression_, a _Statement_, and some update code repeatedly until the\n+> value of the _Expression_ is false.\n+\n+[jls-14.14.1]: https:\/\/docs.oracle.com\/javase\/specs\/jls\/se22\/html\/jls-14.html#jls-14.14.1\n+\n+We can see that the first body corresponds to the initialization code. It yields\n+a variable value modeling local variable `i`. This variable value then _flows_\n+as a parameter to all the other bodies and therefore they can access `i`.\n+\n+> In general a for loop can declare zero or more local variables and\n+> therefore the first body may yield zero or more variable values. Two or more\n+> variable values are wrapped in a yielded tuple value, since code\n+> models do not explicitly support the grouping of multiple return values or an\n+> operation producing multiple results.\n+\n+The second body corresponds to the _Expression_ that models the code checking\n+whether local variable `i` is less than the array length. The third body\n+corresponds to the update code that increments `i`. And, the fourth body\n+corresponds to the _Statement_ that performs the intermediate computation for\n+each dimension.\n+\n+Like with the code model for `distance1b` we can replace the `java.for`\n+operation with other code elements by performing the same lowering\n+transformation. Printing out the lowered model reveals the replacing code\n+elements.\n+\n+```text\n+func @\"distanceN\" @loc=\"44:5:file:\/...\/ExpressionGraphs.java\" (%0 : double[], %1 : double[])double -> {\n+    %2 : Var<double[]> = var %0 @\"a\" @loc=\"44:5\";\n+    %3 : Var<double[]> = var %1 @\"b\" @loc=\"44:5\";\n+    %4 : double = constant @\"0.0\" @loc=\"46:22\";\n+    %5 : Var<double> = var %4 @\"sum\" @loc=\"46:9\";\n+    %6 : int = constant @\"0\" @loc=\"47:22\";\n+    %7 : Var<int> = var %6 @\"i\" @loc=\"47:14\";\n+    branch ^block_1;\n+  \n+  ^block_1:\n+    %8 : int = var.load %7 @loc=\"47:25\";\n+    %9 : double[] = var.load %2 @loc=\"47:29\";\n+    %10 : int = array.length %9 @loc=\"47:29\";\n+    %11 : boolean = lt %8 %10 @loc=\"47:25\";\n+    cbranch %11 ^block_2 ^block_4;\n+  \n+  ^block_2:\n+    %12 : double = var.load %5 @loc=\"48:13\";\n+    %13 : double[] = var.load %2 @loc=\"48:29\";\n+    %14 : int = var.load %7 @loc=\"48:31\";\n+    %15 : double = array.load %13 %14;\n+    %16 : double[] = var.load %3 @loc=\"48:36\";\n+    %17 : int = var.load %7 @loc=\"48:38\";\n+    %18 : double = array.load %16 %17;\n+    %19 : double = sub %15 %18 @loc=\"48:29\";\n+    %20 : double = constant @\"2.0\" @loc=\"48:42\";\n+    %21 : double = invoke %19 %20 @\"java.lang.Math::pow(double, double)double\" @loc=\"48:20\";\n+    %22 : double = add %12 %21 @loc=\"48:13\";\n+    var.store %5 %22 @loc=\"48:13\";\n+    branch ^block_3;\n+  \n+  ^block_3:\n+    %23 : int = var.load %7 @loc=\"47:39\";\n+    %24 : int = constant @\"1\" @loc=\"47:39\";\n+    %25 : int = add %23 %24 @loc=\"47:39\";\n+    var.store %7 %25 @loc=\"47:39\";\n+    branch ^block_1;\n+  \n+  ^block_4:\n+    %26 : double = var.load %5 @loc=\"50:26\";\n+    %27 : double = invoke %26 @\"java.lang.Math::sqrt(double)double\" @loc=\"50:16\";\n+    return %27 @loc=\"50:9\";\n+};\n+```\n+\n+> Both the `java.for` operation and the `java.cexpression` operation\n+> implement their own replacement. The corresponding operation classes\n+> extend from `Op.Lowerable` interface, which declares an abstract method,\n+> `lower`, that each operation implements.\n+\n+The `func` operation's body contains a control flow graph. Notice that\n+`^block_3` branches to `^block_1`, which is commonly referred to as a _back\n+branch_. This models continuation of the loop.\n+\n+Transforming the lowered model with the SSA transformation again results in a\n+simpler model.\n+\n+```text\n+func @\"distanceN\" @loc=\"44:5:file:\/...\/ExpressionGraphs.java\" (%0 : double[], %1 : double[])double -> {\n+    %2 : double = constant @\"0.0\" @loc=\"46:22\";\n+    %3 : int = constant @\"0\" @loc=\"47:22\";\n+    branch ^block_1(%2, %3);\n+  \n+  ^block_1(%4 : double, %5 : int):\n+    %6 : int = array.length %0 @loc=\"47:29\";\n+    %7 : boolean = lt %5 %6 @loc=\"47:25\";\n+    cbranch %7 ^block_2 ^block_4;\n+  \n+  ^block_2:\n+    %8 : double = array.load %0 %5;\n+    %9 : double = array.load %1 %5;\n+    %10 : double = sub %8 %9 @loc=\"48:29\";\n+    %11 : double = constant @\"2.0\" @loc=\"48:42\";\n+    %12 : double = invoke %10 %11 @\"java.lang.Math::pow(double, double)double\" @loc=\"48:20\";\n+    %13 : double = add %4 %12 @loc=\"48:13\";\n+    branch ^block_3;\n+  \n+  ^block_3:\n+    %14 : int = constant @\"1\" @loc=\"47:39\";\n+    %15 : int = add %5 %14 @loc=\"47:39\";\n+    branch ^block_1(%13, %15);\n+  \n+  ^block_4:\n+    %16 : double = invoke %4 @\"java.lang.Math::sqrt(double)double\" @loc=\"50:16\";\n+    return %16 @loc=\"50:9\";\n+};\n+```\n+\n+`^block_1` now has two block parameters, `%4` and `%5`, corresponding to the\n+values of local variables `sum` and `i` respectively for the current loop\n+iteration. The (back) branch in `^block_3` passes the values to be used for the\n+next loop iteration as block arguments.\n+\n+> A value can be used by an operation if it is defined earlier in the same\n+> block or defined in a dominating block. This is why the `invoke` operation\n+> in `^block_2` can use `%4`, since `^block_1` dominates `^block_2`.\n+\n+> Structured control flow operations and pure SSA form are not mutually\n+> exclusive. Although we will not model Java expressions and statement\n+> with control flow in such a manner the code model design itself does not have\n+> such limitations (see the [Triton example][Triton-example] for using code\n+> models to model non-Java programs).\n+\n+[Triton-example]: https:\/\/openjdk.org\/projects\/babylon\/articles\/triton\n+\n+## Expression graphs and use graphs\n+\n+So far we have shown tree traversal of a code model's elements (operations,\n+bodies, and blocks). There are other ways to traverse _items_ of a code model,\n+specifically the traversal of values. Given an operation result we can traverse\n+to the values that are the operation's operands, and so on, to produce an\n+expression graph. We can also think about the reverse. Given a value we can\n+traverse to the operation results of operations that _uses_ it as an operand,\n+and so on, to produce a use graph.\n+\n+> It is an expression _graph_ because two or more operations may use the\n+> same value as an operand. An expression graph cannot have cycles, so it is\n+> also acyclic. Conceptually an expression graph traverses up the code model.\n+>\n+> It is a use _graph_ because a value can be used by more two or more operations\n+> whose results are all subsequently used by another operation. A use graph\n+> is also acyclic. Conceptually a use graph traverses down the code model.\n+\n+In this section we shall show how to traverse expression graphs and use graphs\n+and build up simple graph structures. We declare a record class that represents\n+a node in a graph. A node has two components, a value associated with the node\n+and a list of outgoing edges to other nodes.\n+\n+```java\n+record Node<T>(T value, List<Node<T>> edges) {\n+}\n+```\n+\n+Then, we implement a method, `expressionGraph`, that computes the expression\n+graph for a given value.\n+\n+```java\n+static Node<Value> expressionGraph(Value value) {\n+    return expressionGraph(new HashMap<>(), value);\n+}\n+\n+static Node<Value> expressionGraph(Map<Value, Node<Value>> visited, Value value) {\n+    \/\/ If value has already been visited return its node\n+    if (visited.containsKey(value)) {\n+        return visited.get(value);\n+    }\n+\n+    \/\/ Find the expression graphs for each operand\n+    List<Node<Value>> edges = new ArrayList<>();\n+    for (Value operand : value.dependsOn()) {\n+        edges.add(expressionGraph(operand));\n+    }\n+    Node<Value> node = new Node<>(value, edges);\n+    visited.put(value, node);\n+    return node;\n+}\n+```\n+\n+Given a value the corresponding node's edges are the nodes produced by\n+recursively computing the expression graphs for the set of values the value\n+_depends on_. If the value is an operation result then that set will be the set\n+of the operation's operands. It is a set because an operation may use a value\n+two or more times as two or more operands. If the value is a block parameter it\n+depends on no other values so the set is empty. Since we are creating a graph we\n+also need to check if we have already visited a value, if so we reuse its\n+corresponding node.\n+\n+It is instructive to show an alternative implementation of`expressionGraph`\n+that performs explicit instance of checks on the value. However, in general it\n+is recommended the method `Value.dependsOn` be used instead.\n+\n+```java\n+static Node<Value> expressionGraph(Map<Value, Node<Value>> visited, Value value) {\n+    \/\/ If value has already been visited return its node\n+    if (visited.containsKey(value)) {\n+        return visited.get(value);\n+    }\n+\n+    List<Node<Value>> edges;\n+    if (value instanceof Op.Result result) {\n+        edges = new ArrayList<>();\n+        \/\/ Find the expression graphs for each operand\n+        Set<Value> valueVisited = new HashSet<>();\n+        for (Value operand : result.op().operands()) {\n+            \/\/ Ensure an operand is visited only once\n+            if (valueVisited.add(operand)) {\n+                edges.add(expressionGraph(operand));\n+            }\n+        }\n+        \/\/ TODO if terminating operation find expression graphs\n+        \/\/      for each successor argument\n+    } else {\n+        assert value instanceof Block.Parameter;\n+        \/\/ A block parameter has no outgoing edges\n+        edges = List.of();\n+    }\n+    Node<Value> node = new Node<>(value, edges);\n+    visited.put(value, node);\n+    return node;\n+}\n+```\n+\n+Given a value we test if the value is an instance of an operation result. If so,\n+the corresponding node's edges are the nodes produced by recursively computing\n+the expression graphs for the operation's operands. Otherwise, a value is an\n+instance of a block parameter, and we create a node with no edges.\n+\n+> The TODO comment indicates that an operation result depends on the\n+> operation's operands and also its successor arguments, if the operation is\n+> the terminating (or last) operation in a block. Method `Op.Result.dependsOn`\n+> will return the set of operands and successor arguments.\n+> We have already seen such operations, branch operations, when looking at the\n+> lowered code models of methods `distance1b` and `distanceN`.\n+\n+Finally, we implement a method, `useGraph`, that computes the use graph for a\n+given value.\n+\n+```java\n+static Node<Value> useGraph(Value value) {\n+    return useGraph(new HashMap<>(), value);\n+}\n+\n+static Node<Value> useGraph(Map<Value, Node<Value>> visited, Value value) {\n+    \/\/ If value has already been visited return its node\n+    if (visited.containsKey(value)) {\n+        return visited.get(value);\n+    }\n+\n+    \/\/ Find the use graphs for each use\n+    List<Node<Value>> edges = new ArrayList<>();\n+    for (Op.Result use : value.uses()) {\n+        edges.add(useGraph(visited, use));\n+    }\n+    Node<Value> node = new Node<>(value, edges);\n+    visited.put(value, node);\n+    return node;\n+}\n+```\n+\n+The method `useGraph` is similarly structured to method `expressionGraph`,\n+except that the corresponding node's edges are the nodes produced by recursively\n+computing the use graphs for the values uses.\n+\n+Now we can start producing graphs for some of the models we have previously\n+presented. Let's take another look at the `distance1`. What does the expression\n+graph look like for the `return` operation? Let's compute the graph and print it\n+out along with the code model for comparison.\n+\n+[\/\/]: # (@formatter:off)\n+```java\n+CoreOp.FuncOp model = ...;\n+\/\/ Create the expression graph for the terminating operation result\n+Op.Result returnResult = model.body().entryBlock().terminatingOp().result();\n+Node<Value> returnGraph = expressionGraph(returnResult);\n+\/\/ Transform from Node<Value> to Node<String> and print the graph\n+System.out.println(returnGraph.transformValues(v -> printValue(names, v)));\n+```\n+[\/\/]: # (@formatter:on)\n+\n+```text\n+@CodeReflection\n+static double distance1(double a, double b) {\n+   return Math.abs(a - b);\n+}\n+\n+func @\"distance1\" @loc=\"24:5:file:\/...\/ExpressionGraphs.java\" (%0 : double, %1 : double)double -> {\n+    %2 : Var<double> = var %0 @\"a\" @loc=\"24:5\";\n+    %3 : Var<double> = var %1 @\"b\" @loc=\"24:5\";\n+    %4 : double = var.load %2 @loc=\"26:25\";\n+    %5 : double = var.load %3 @loc=\"26:29\";\n+    %6 : double = sub %4 %5 @loc=\"26:25\";\n+    %7 : double = invoke %6 @\"java.lang.Math::abs(double)double\" @loc=\"26:16\";\n+    %8 : void = return %7 @loc=\"26:9\";\n+};\n+\n+%8 : void = return %7 @loc=\"26:9\";\n+└── %7 : double = invoke %6 @\"java.lang.Math::abs(double)double\" @loc=\"26:16\";\n+    └── %6 : double = sub %4 %5 @loc=\"26:25\";\n+        ├── %4 : double = var.load %2 @loc=\"26:25\";\n+        │   └── %2 : Var<double> = var %0 @\"a\" @loc=\"24:5\";\n+        │       └── %0 <block parameter>\n+        └── %5 : double = var.load %3 @loc=\"26:29\";\n+            └── %3 : Var<double> = var %1 @\"b\" @loc=\"24:5\";\n+                └── %1 <block parameter>\n+```\n+\n+> Note that we are printing out the graph as a tree, so if a node has two or\n+> more outgoing edges it would be printed out two or more times, which is  \n+> fine because there are no cycles. In this case the expression graph is a\n+> tree, each non-root node has one incoming edge.\n+\n+We can see that the expression graph bears a striking resemblance to an\n+_abstract syntax tree_. As we can see such trees are present in code models even\n+if initially it may not be so obvious that they are. Reversing the lines of the\n+printed expression tree, and removing the lines associated with the block\n+parameters, reveals a similar order to the operations in the function\n+declaration operation.\n+\n+What do the use graphs look like for each of the function's parameters?\n+Similarly, lets compute the two use graphs and print them out.\n+\n+[\/\/]: # (@formatter:off)\n+```java\n+for (Block.Parameter parameter : model.parameters()) {\n+   Node<Value> useNode = useGraph(parameter);\n+   System.out.println(useNode.transformValues(v -> printValue(names, v)));\n+}\n+```\n+[\/\/]: # (@formatter:on)\n+\n+```text\n+@CodeReflection\n+static double distance1(double a, double b) {\n+   return Math.abs(a - b);\n+}\n+\n+%0 <block parameter>\n+└── %2 : Var<double> = var %0 @\"a\" @loc=\"24:5\";\n+    └── %4 : double = var.load %2 @loc=\"26:25\";\n+        └── %6 : double = sub %4 %5 @loc=\"26:25\";\n+            └── %7 : double = invoke %6 @\"java.lang.Math::abs(double)double\" @loc=\"26:16\";\n+                └── %8 : void = return %7 @loc=\"26:9\";\n+\n+%1 <block parameter>\n+└── %3 : Var<double> = var %1 @\"b\" @loc=\"24:5\";\n+    └── %5 : double = var.load %3 @loc=\"26:29\";\n+        └── %6 : double = sub %4 %5 @loc=\"26:25\";\n+            └── %7 : double = invoke %6 @\"java.lang.Math::abs(double)double\" @loc=\"26:16\";\n+                └── %8 : void = return %7 @loc=\"26:9\";\n+```\n+\n+The use graph follows the same order as the operations in the function\n+declaration operation. We can also observe that the use graphs are sub-graphs of\n+the expression graph (in this case they are reverse paths).\n+\n+What if we want to compute the expression graphs for all values in a code model?\n+One approach would be to apply the `expressionGraph` method to each and every\n+value. Alternatively, we can compute all the expression graphs by traversing the\n+code mode elements, in a similar manner to how we printed code element classes.\n+\n+```java\n+static Map<Value, Node<Value>> expressionGraphs(CoreOp.FuncOp f) {\n+    return expressionGraphs(f.body());\n+}\n+\n+static Map<Value, Node<Value>> expressionGraphs(Body b) {\n+    \/\/ Traverse the model building structurally shared expression graphs\n+    return b.traverse(new LinkedHashMap<>(), (graphs, codeElement) -> {\n+        switch (codeElement) {\n+            case Body _ -> {\n+                \/\/ Do nothing\n+            }\n+            case Block block -> {\n+                \/\/ Create the expression graphs for each block parameter\n+                \/\/ A block parameter has no outgoing edges\n+                for (Block.Parameter parameter : block.parameters()) {\n+                    graphs.put(parameter, new Node<>(parameter, List.of()));\n+                }\n+            }\n+            case Op op -> {\n+                \/\/ Find the expression graphs for each operand\n+                List<Node<Value>> edges = new ArrayList<>();\n+                for (Value operand : op.result().dependsOn()) {\n+                    \/\/ Get expression graph for the operand\n+                    \/\/ It must be previously computed since we encounter the\n+                    \/\/ declaration of values before their use\n+                    edges.add(graphs.get(operand));\n+                }\n+                \/\/ Create the expression graph for this operation result\n+                graphs.put(op.result(), new Node<>(op.result(), edges));\n+            }\n+        }\n+        return graphs;\n+    });\n+}\n+```\n+\n+> The switch statement is exhaustive and does not require a default clause.\n+> `Body`, `Block`, and `Op` extend from the sealed abstract class\n+> `CodeElement` which permits only those prior classes.\n+\n+This approach works because code elements are traversed in a specific order,\n+where values are declared before they are used. Therefore, we don't need to\n+track visited values as before. The node for an operand is guaranteed to be\n+present in `graphs`, the map of value to node. This approach also happens to be\n+more efficient than directly producing the expression graphs for each value,\n+since we can share node instances.\n+\n+> Since code models are immutable the computed expressions graphs are stable\n+> and can never become out-of-sync with the model they are associated with.\n+\n+We can easily verify both methods produce the same graphs by comparing the\n+`return` operation's expression graph computed by each method.\n+\n+[\/\/]: # (@formatter:off)\n+```java\n+\/\/ Create the expression graphs for all values\n+Map<Value, Node<Value>> graphs = expressionGraphs(model);\n+\/\/ The graphs for the terminating operation result are the same\n+assert returnGraph.equals(graphs.get(returnGraph.value()));\n+```\n+[\/\/]: # (@formatter:on)\n+\n+> We rely on record's capability to automatically implement the `equals`\n+> method.\n+\n+## Root expression graphs and trees\n+\n+Now that we know how to produce expression graphs we can start categorizing and\n+manipulating graphs based on certain rules that, for example, identify parts of\n+a code model that model statements or expressions. Why would we want to do this?\n+Apart from presenting further details on how to analyse code models for\n+analysis’ sake this does have practical use. Specifically, for the translation\n+for code models to C source code. Two use cases come to mind.\n+\n+The [Babylon GPU work][babylon-hat] requires the transformation of code models\n+to GPU kernels (methods that execute on GPU hardware). One approach is to\n+transform code models to OpenCL C source or CUDA C source and compile using the\n+GPU-specific toolchains. We would like the transformed source to be idiomatic\n+(approximately as if a written by hand), allowing for easier debugging and\n+enabling the compilers to better optimize (since they likely better optimize\n+idiomatic code). Identifying expression graphs that model statements is useful\n+for the generation of idiomatic C code.\n+\n+[babylon-hat]: https:\/\/github.com\/openjdk\/babylon\/tree\/code-reflection\/hat\n+\n+> Note the Babylon GPU work is also exploring the transformation of code\n+> models to kernels consisting of SPIRV or PTX instructions. Thereby\n+> we will thoroughly explore many options and help ensure code reflection is\n+> fit for purpose.\n+\n+The Foreign Function and Memory API (Project Panama) supports the binding of a\n+Java method to a native function pointer so that the Java method can be invoked\n+natively via that function pointer. Such invocation is commonly referred to as\n+an upcall. Panama's upcalls are very efficient, but there is still a cost\n+transitioning from native to Java and back again. This transition can be removed\n+if we can access the code model of the Java method, translate it to C code,\n+compile it to native code, and bind the function pointer to that native code. It\n+would likely be applicable only to Java methods with simple expressions and\n+statements, e.g, methods whose behaviour is a function of their input. Again,\n+identifying expressions graphs that model statements is useful to determine\n+whether the Java method is applicable for transformation and for the generation\n+of idiomatic C code.\n+\n+With those two use cases in mind lets focus on further analyzing expression\n+Given all the expressions graphs we can filter them, selecting graphs that are\n+considered _roots_. Let's initially define a _root expression graph_ as a graph\n+whose root node value has no uses. Then we can filter the graphs as follows.\n+\n+[\/\/]: # (@formatter:off)\n+```java\n+\/\/ Filter for root graphs, operation results with no uses\n+List<Node<Value>> rootGraphs = graphs.values().stream()\n+        .filter(n -> n.value() instanceof Op.Result opr &&\n+                switch (opr.op()) {\n+                    \/\/ An operation result with no uses\n+                    default -> opr.uses().isEmpty();\n+                })\n+        .toList();\n+```\n+[\/\/]: # (@formatter:on)\n+\n+> We will add another case to the switch statement later on\n+\n+For the purposes of this section we shall focus on another method,\n+`squareDiff`, that computes the difference between two squares.\n+\n+[\/\/]: # (@formatter:off)\n+```java\n+@CodeReflection\n+static double squareDiff(double a, double b) {\n+    \/\/ a^2 - b^2 = (a + b) * (a - b)\n+    final double plus = a + b;\n+    final double minus = a - b;\n+    return plus * minus;\n+}\n+```\n+[\/\/]: # (@formatter:on)\n+\n+We similarly structure the method like `distance1a`, with multiple variable\n+declaration statements. In addition, parameters `a` and `b` are used more than\n+once. These features will exercise the analysis. The `squareDiff` method\n+contains one such root expression graph associated with the `return` operation.\n+Here it is.\n+\n+```text\n+%15 : void = return %14 @loc=\"58:9\";\n+└── %14 : double = mul %12 %13 @loc=\"58:16\";\n+    ├── %12 : double = var.load %7 @loc=\"58:16\";\n+    │   └── %7 : Var<double> = var %6 @\"plus\" @loc=\"56:9\";\n+    │       └── %6 : double = add %4 %5 @loc=\"56:29\";\n+    │           ├── %4 : double = var.load %2 @loc=\"56:29\";\n+    │           │   └── %2 : Var<double> = var %0 @\"a\" @loc=\"53:5\";\n+    │           │       └── %0 <block parameter>\n+    │           └── %5 : double = var.load %3 @loc=\"56:33\";\n+    │               └── %3 : Var<double> = var %1 @\"b\" @loc=\"53:5\";\n+    │                   └── %1 <block parameter>\n+    └── %13 : double = var.load %11 @loc=\"58:23\";\n+        └── %11 : Var<double> = var %10 @\"minus\" @loc=\"57:9\";\n+            └── %10 : double = sub %8 %9 @loc=\"57:30\";\n+                ├── %8 : double = var.load %2 @loc=\"57:30\";\n+                │   └── %2 : Var<double> = var %0 @\"a\" @loc=\"53:5\";\n+                │       └── %0 <block parameter>\n+                └── %9 : double = var.load %3 @loc=\"57:34\";\n+                    └── %3 : Var<double> = var %1 @\"b\" @loc=\"53:5\";\n+                        └── %1 <block parameter>\n+```\n+\n+Notice that the method has three statements, the two variable declaration\n+statements and the return statement, and yet there is only one root expression\n+graph.\n+\n+Also notice that the graph contains the results of variable declaration\n+operations, modeling the local variable declaration statements (values `%7`\n+and `%11` for local variables `plus` and `minus` respectively), and also those\n+modeling the method parameter declarations (values `%2` and `%3` for\n+parameters `a` and `b` respectively). The results are used by variable load\n+operations modeling the expressions that denote the local variables and\n+parameters. The variable declarations are not part of the return statement, and\n+yet their modeled operations are present in the root expression graph.\n+\n+> The operations modeling method parameter declarations occur twice, since\n+> the graph is rendered as tree.\n+\n+To produce distinct root expressions graphs for each statement we need to do two\n+things, expand the set of root expression graphs, and prune the graphs by\n+removing the nodes corresponding to variable declaration operations that are not\n+directly associated with statements.\n+\n+We expand the set of root expression graphs to include those whose operation is\n+a variable declaration operation, and more specifically only when the value used\n+to initialize the variable value is an operation result (thereby we avoid\n+including the variable values modeling the method parameters, where the value\n+used to initialize is a block parameter).\n+\n+```java\n+List<Node<Value>> rootGraphs = graphs.values().stream()\n+        .filter(n -> n.value() instanceof Op.Result opr &&\n+                switch (opr.op()) {\n+                    \/\/ Variable declarations modeling local variables\n+                    case CoreOp.VarOp vop ->\n+                            vop.operands().get(0) instanceof Op.Result;\n+                    \/\/ An operation result with no uses\n+                    default -> opr.uses().isEmpty();\n+                })\n+        .toList();\n+```\n+\n+We prune the graphs by enhancing method `expressionGraphs`, copying and\n+modifying, to create a new method `prunedExpressionGraphs`.\n+\n+[\/\/]: # (@formatter:off)\n+```java\n+static Map<Value, Node<Value>> prunedExpressionGraphs(CoreOp.FuncOp f) {\n+    return prunedExpressionGraphs(f.body());\n+}\n+\n+static Map<Value, Node<Value>> prunedExpressionGraphs(Body b) {\n+    \/\/ Traverse the model building structurally shared expression graphs\n+    return b.traverse(new LinkedHashMap<>(), (graphs, codeElement) -> {\n+        switch (codeElement) {\n+            case Body _ -> { ... }\n+            case Block block -> { ... }\n+            \/\/ Prune graph for variable load operation\n+            case CoreOp.VarAccessOp.VarLoadOp op -> {\n+                \/\/ Ignore edge for the variable value operand\n+                graphs.put(op.result(), new Node<>(op.result(), List.of()));\n+            }\n+            \/\/ Prune graph for variable store operation\n+            case CoreOp.VarAccessOp.VarStoreOp op -> {\n+                \/\/ Ignore edge for the variable value operand\n+                \/\/ Add edge for value to store\n+                List<Node<Value>> edges = List.of(graphs.get(op.operands().get(1)));\n+                graphs.put(op.result(), new Node<>(op.result(), edges));\n+            }\n+            case Op op -> { ... }\n+        }\n+        return graphs;\n+    });\n+}\n+```\n+[\/\/]: # (@formatter:on)\n+\n+Two new cases are added checking if a code element is an instance of a variable\n+load or variable store operation respectively. For a variable load operation a\n+new node is created with no edges, since the single operand corresponds to the\n+variable value. For a variable store operation a new node is created with one\n+edge corresponding to the first operand, the value to store.\n+\n+> Note that the switch is still exhaustive. The two new cases dominate the\n+> the more general operation case. Alternatively, we could have\n+> implemented the same behaviour within the more general operation case,\n+> checking if a dependent value is an instance of an operation result and the\n+> operation is an instance of a variable declaration. However, we think\n+> the above implementation is more instructive.\n+\n+With these enhancements we can now compute three root expression graphs.\n+\n+```text\n+@CodeReflection\n+static double squareDiff(double a, double b) {\n+    \/\/ a^2 - b^2 = (a + b) * (a - b)\n+    final double plus = a + b;\n+    final double minus = a - b;\n+    return plus * minus;\n+}\n+\n+%7 : Var<double> = var %6 @\"plus\" @loc=\"56:9\";\n+└── %6 : double = add %4 %5 @loc=\"56:29\";\n+    ├── %4 : double = var.load %2 @loc=\"56:29\";\n+    └── %5 : double = var.load %3 @loc=\"56:33\";\n+\n+%11 : Var<double> = var %10 @\"minus\" @loc=\"57:9\";\n+└── %10 : double = sub %8 %9 @loc=\"57:30\";\n+    ├── %8 : double = var.load %2 @loc=\"57:30\";\n+    └── %9 : double = var.load %3 @loc=\"57:34\";\n+\n+%15 : void = return %14 @loc=\"58:9\";\n+└── %14 : double = mul %12 %13 @loc=\"58:16\";\n+    ├── %12 : double = var.load %7 @loc=\"58:16\";\n+    └── %13 : double = var.load %11 @loc=\"58:23\";\n+```\n+\n+Notice how the three root expression graphs correspond, in order, to the three\n+statements in method `squareDiff`. These graphs are also _root expression\n+trees_, and it should also be possible to generate idiomatic C code from such\n+trees.\n+\n+> The rules will need to be expanded if we want to support assignment\n+> expressions and distinguish them from assignment expression statements. We\n+> shall leave that investigation for another day.\n","filename":"site\/articles\/code-models.md","additions":1340,"deletions":0,"binary":false,"changes":1340,"status":"added"}]}