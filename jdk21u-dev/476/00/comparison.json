{"files":[{"patch":"@@ -31,0 +31,1 @@\n+#include \"memory\/allocation.hpp\"\n@@ -32,0 +33,3 @@\n+#include \"runtime\/atomic.hpp\"\n+#include \"utilities\/concurrentHashTable.inline.hpp\"\n+#include \"utilities\/concurrentHashTableTasks.inline.hpp\"\n@@ -33,5 +37,8 @@\n-void G1CodeRootSet::add(nmethod* nm) {\n-  assert(_is_iterating == false, \"should not mutate while iterating the table\");\n-  bool added = false;\n-  if (_table == nullptr) {\n-    _table = new (mtGC) Table(SmallSize, LargeSize);\n+class G1CodeRootSetHashTableConfig : public StackObj {\n+public:\n+  using Value = nmethod*;\n+\n+  static uintx get_hash(Value const& value, bool* is_dead);\n+\n+  static void* allocate_node(void* context, size_t size, Value const& value) {\n+    return AllocateHeap(size, mtGC);\n@@ -39,3 +46,3 @@\n-  added = _table->put(nm, nm);\n-  if (added && _table->table_size() == SmallSize && length() == Threshold) {\n-    _table->resize(LargeSize);\n+\n+  static void free_node(void* context, void* memory, Value const& value) {\n+    FreeHeap(memory);\n@@ -43,0 +50,184 @@\n+};\n+\n+\/\/ Storage container for the code root set.\n+class G1CodeRootSetHashTable : public CHeapObj<mtGC> {\n+  using HashTable = ConcurrentHashTable<G1CodeRootSetHashTableConfig, mtGC>;\n+  using HashTableScanTask = HashTable::ScanTask;\n+\n+  \/\/ Default (log2) number of buckets; small since typically we do not expect many\n+  \/\/ entries.\n+  static const size_t Log2DefaultNumBuckets = 2;\n+  static const uint BucketClaimSize = 16;\n+\n+  HashTable _table;\n+  HashTableScanTask _table_scanner;\n+\n+  size_t volatile _num_entries;\n+\n+  bool is_empty() const { return number_of_entries() == 0; }\n+\n+  class HashTableLookUp : public StackObj {\n+    nmethod* _nmethod;\n+\n+  public:\n+    explicit HashTableLookUp(nmethod* nmethod) : _nmethod(nmethod) { }\n+    uintx get_hash() const;\n+    bool equals(nmethod** value);\n+    bool is_dead(nmethod** value) const { return false; }\n+  };\n+\n+  class HashTableIgnore : public StackObj {\n+  public:\n+    HashTableIgnore() { }\n+    void operator()(nmethod** value) { \/* do nothing *\/ }\n+  };\n+\n+public:\n+  G1CodeRootSetHashTable() :\n+    _table(Log2DefaultNumBuckets,\n+           HashTable::DEFAULT_MAX_SIZE_LOG2),\n+    _table_scanner(&_table, BucketClaimSize), _num_entries(0) {\n+    clear();\n+  }\n+\n+  \/\/ Robert Jenkins 1996 & Thomas Wang 1997\n+  \/\/ http:\/\/web.archive.org\/web\/20071223173210\/http:\/\/www.concentric.net\/~Ttwang\/tech\/inthash.htm\n+  static uint32_t hash(uint32_t key) {\n+    key = ~key + (key << 15);\n+    key = key ^ (key >> 12);\n+    key = key + (key << 2);\n+    key = key ^ (key >> 4);\n+    key = key * 2057;\n+    key = key ^ (key >> 16);\n+    return key;\n+  }\n+\n+  static uintx get_hash(nmethod* nmethod) {\n+    uintptr_t value = (uintptr_t)nmethod;\n+    \/\/ The CHT only uses the bits smaller than HashTable::DEFAULT_MAX_SIZE_LOG2, so\n+    \/\/ try to increase the randomness by incorporating the upper bits of the\n+    \/\/ address too.\n+    STATIC_ASSERT(HashTable::DEFAULT_MAX_SIZE_LOG2 <= sizeof(uint32_t) * BitsPerByte);\n+#ifdef _LP64\n+    return hash((uint32_t)value ^ (uint32_t(value >> 32)));\n+#else\n+    return hash((uint32_t)value);\n+#endif\n+  }\n+\n+  void insert(nmethod* method) {\n+    HashTableLookUp lookup(method);\n+    bool grow_hint = false;\n+    bool inserted = _table.insert(Thread::current(), lookup, method, &grow_hint);\n+    if (inserted) {\n+      Atomic::inc(&_num_entries);\n+    }\n+    if (grow_hint) {\n+      _table.grow(Thread::current());\n+    }\n+  }\n+\n+  bool remove(nmethod* method) {\n+    HashTableLookUp lookup(method);\n+    bool removed = _table.remove(Thread::current(), lookup);\n+    if (removed) {\n+      Atomic::dec(&_num_entries);\n+    }\n+    return removed;\n+  }\n+\n+  bool contains(nmethod* method) {\n+    HashTableLookUp lookup(method);\n+    HashTableIgnore ignore;\n+    return _table.get(Thread::current(), lookup, ignore);\n+  }\n+\n+  void clear() {\n+    \/\/ Remove all entries.\n+    auto always_true = [] (nmethod** value) {\n+                         return true;\n+                       };\n+    clean(always_true);\n+  }\n+\n+  void iterate_at_safepoint(CodeBlobClosure* blk) {\n+    assert_at_safepoint();\n+    \/\/ A lot of code root sets are typically empty.\n+    if (is_empty()) {\n+      return;\n+    }\n+\n+    auto do_value =\n+      [&] (nmethod** value) {\n+        blk->do_code_blob(*value);\n+        return true;\n+      };\n+    _table_scanner.do_safepoint_scan(do_value);\n+  }\n+\n+  \/\/ Removes entries as indicated by the given EVAL closure.\n+  template <class EVAL>\n+  void clean(EVAL& eval) {\n+    \/\/ A lot of code root sets are typically empty.\n+    if (is_empty()) {\n+      return;\n+    }\n+\n+    size_t num_deleted = 0;\n+    auto do_delete =\n+      [&] (nmethod** value) {\n+        num_deleted++;\n+      };\n+    bool succeeded = _table.try_bulk_delete(Thread::current(), eval, do_delete);\n+    guarantee(succeeded, \"unable to clean table\");\n+\n+    if (num_deleted != 0) {\n+      size_t current_size = Atomic::sub(&_num_entries, num_deleted);\n+      shrink_to_match(current_size);\n+    }\n+  }\n+\n+  \/\/ Calculate the log2 of the table size we want to shrink to.\n+  size_t log2_target_shrink_size(size_t current_size) const {\n+    \/\/ A table with the new size should be at most filled by this factor. Otherwise\n+    \/\/ we would grow again quickly.\n+    const float WantedLoadFactor = 0.5;\n+    size_t min_expected_size = checked_cast<size_t>(ceil(current_size \/ WantedLoadFactor));\n+\n+    size_t result = Log2DefaultNumBuckets;\n+    if (min_expected_size != 0) {\n+      size_t log2_bound = checked_cast<size_t>(log2i_exact(round_up_power_of_2(min_expected_size)));\n+      result = clamp(log2_bound, Log2DefaultNumBuckets, HashTable::DEFAULT_MAX_SIZE_LOG2);\n+    }\n+    return result;\n+  }\n+\n+  \/\/ Shrink to keep table size appropriate to the given number of entries.\n+  void shrink_to_match(size_t current_size) {\n+    size_t prev_log2size = _table.get_size_log2(Thread::current());\n+    size_t new_log2_table_size = log2_target_shrink_size(current_size);\n+    if (new_log2_table_size < prev_log2size) {\n+      _table.shrink(Thread::current(), new_log2_table_size);\n+    }\n+  }\n+\n+  void reset_table_scanner() {\n+    _table_scanner.set(&_table, BucketClaimSize);\n+  }\n+\n+  size_t mem_size() { return sizeof(*this) + _table.get_mem_size(Thread::current()); }\n+\n+  size_t number_of_entries() const { return Atomic::load(&_num_entries); }\n+};\n+\n+uintx G1CodeRootSetHashTable::HashTableLookUp::get_hash() const {\n+  return G1CodeRootSetHashTable::get_hash(_nmethod);\n+}\n+\n+bool G1CodeRootSetHashTable::HashTableLookUp::equals(nmethod** value) {\n+  return *value == _nmethod;\n+}\n+\n+uintx G1CodeRootSetHashTableConfig::get_hash(Value const& value, bool* is_dead) {\n+  *is_dead = false;\n+  return G1CodeRootSetHashTable::get_hash(value);\n@@ -45,0 +236,13 @@\n+size_t G1CodeRootSet::length() const { return _table->number_of_entries(); }\n+\n+void G1CodeRootSet::add(nmethod* method) {\n+  if (!contains(method)) {\n+    assert(!_is_iterating, \"must be\");\n+    _table->insert(method);\n+  }\n+}\n+\n+G1CodeRootSet::G1CodeRootSet() :\n+  _table(new G1CodeRootSetHashTable())\n+  DEBUG_ONLY(COMMA _is_iterating(false)) { }\n+\n@@ -50,11 +254,2 @@\n-  assert(_is_iterating == false, \"should not mutate while iterating the table\");\n-  bool removed = false;\n-  if (_table != nullptr) {\n-    removed = _table->remove(method);\n-  }\n-  if (removed) {\n-    if (length() == 0) {\n-      clear();\n-    }\n-  }\n-  return removed;\n+  assert(!_is_iterating, \"should not mutate while iterating the table\");\n+  return _table->remove(method);\n@@ -64,4 +259,1 @@\n-  if (_table != nullptr) {\n-    return _table->contains(method);\n-  }\n-  return false;\n+  return _table->contains(method);\n@@ -71,3 +263,2 @@\n-  assert(_is_iterating == false, \"should not mutate while iterating the table\");\n-  delete _table;\n-  _table = nullptr;\n+  assert(!_is_iterating, \"should not mutate while iterating the table\");\n+  _table->clear();\n@@ -77,3 +268,5 @@\n-  return (_table == nullptr)\n-    ? sizeof(*this)\n-    : sizeof(*this) + _table->mem_size();\n+  return sizeof(*this) + _table->mem_size();\n+}\n+\n+void G1CodeRootSet::reset_table_scanner() {\n+  _table->reset_table_scanner();\n@@ -84,5 +277,1 @@\n-  if (_table != nullptr) {\n-    _table->iterate_all([&](nmethod* nm, nmethod* _) {\n-      blk->do_code_blob(nm);\n-    });\n-  }\n+  _table->iterate_at_safepoint(blk);\n@@ -94,0 +283,1 @@\n+\n@@ -96,11 +286,0 @@\n-   public:\n-    bool _points_into;\n-    PointsIntoHRDetectionClosure(HeapRegion* hr) : _hr(hr), _points_into(false) {}\n-\n-    void do_oop(narrowOop* o) {\n-      do_oop_work(o);\n-    }\n-\n-    void do_oop(oop* o) {\n-      do_oop_work(o);\n-    }\n@@ -114,0 +293,8 @@\n+\n+   public:\n+    bool _points_into;\n+    PointsIntoHRDetectionClosure(HeapRegion* hr) : _hr(hr), _points_into(false) {}\n+\n+    void do_oop(narrowOop* o) { do_oop_work(o); }\n+\n+    void do_oop(oop* o) { do_oop_work(o); }\n@@ -122,1 +309,1 @@\n-  bool do_entry(nmethod* nm, nmethod* _) {\n+  bool operator()(nmethod** value) {\n@@ -124,1 +311,1 @@\n-    _blobs.do_code_blob(nm);\n+    _blobs.do_code_blob(*value);\n@@ -130,8 +317,4 @@\n-  assert(_is_iterating == false, \"should not mutate while iterating the table\");\n-  CleanCallback should_clean(owner);\n-  if (_table != nullptr) {\n-    _table->unlink(&should_clean);\n-  }\n-  if (length() == 0) {\n-    clear();\n-  }\n+  assert(!_is_iterating, \"should not mutate while iterating the table\");\n+\n+  CleanCallback eval(owner);\n+  _table->clean(eval);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CodeRootSet.cpp","additions":238,"deletions":55,"binary":false,"changes":293,"status":"modified"},{"patch":"@@ -30,1 +30,0 @@\n-#include \"utilities\/resizeableResourceHash.hpp\"\n@@ -32,0 +31,1 @@\n+class G1CodeRootSetHashTable;\n@@ -36,1 +36,1 @@\n-\/\/ This class is not thread safe, locks are needed.\n+\/\/ This class is thread safe.\n@@ -38,10 +38,1 @@\n-  friend class G1CodeRootSetTest;\n-  friend class G1CodeRootSetTest_g1_code_cache_rem_set_vm_Test;\n-\n- private:\n-  const static size_t SmallSize = 32;\n-  const static size_t Threshold = 24;\n-  const static size_t LargeSize = 512;\n-\n-  using Table = ResizeableResourceHashtable<nmethod*, nmethod*, AnyObj::C_HEAP, mtGC>;\n-  Table* _table;\n+  G1CodeRootSetHashTable* _table;\n@@ -51,1 +42,1 @@\n-  G1CodeRootSet() : _table(nullptr) DEBUG_ONLY(COMMA _is_iterating(false)) {}\n+  G1CodeRootSet();\n@@ -58,0 +49,3 @@\n+\n+  \/\/ Prepare for MT iteration. Must be called before nmethods_do.\n+  void reset_table_scanner();\n@@ -60,1 +54,1 @@\n-  \/\/ Remove all nmethods which no longer contain pointers into our \"owner\" region\n+  \/\/ Remove all nmethods which no longer contain pointers into our \"owner\" region.\n@@ -66,1 +60,1 @@\n-  size_t length() const { return _table == nullptr ? 0 : _table->number_of_entries(); }\n+  size_t length() const;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CodeRootSet.hpp","additions":9,"deletions":15,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -3011,2 +3011,1 @@\n-      \/\/ HeapRegion::add_code_root_locked() avoids adding duplicate entries.\n-      hr->add_code_root_locked(_nm);\n+      hr->add_code_root(_nm);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1279,1 +1279,1 @@\n-    r->rem_set()->clear_locked(true \/* only_cardset *\/);\n+    r->rem_set()->clear(true \/* only_cardset *\/);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Policy.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -260,1 +260,0 @@\n-    _collection_set_iter_state(nullptr),\n@@ -273,1 +272,0 @@\n-    FREE_C_HEAP_ARRAY(G1RemsetIterState, _collection_set_iter_state);\n@@ -280,1 +278,1 @@\n-    assert(_collection_set_iter_state == nullptr, \"Must not be initialized twice\");\n+    assert(_card_table_scan_state == nullptr, \"Must not be initialized twice\");\n@@ -282,1 +280,0 @@\n-    _collection_set_iter_state = NEW_C_HEAP_ARRAY(G1RemsetIterState, max_reserved_regions, mtGC);\n@@ -297,1 +294,0 @@\n-      reset_region_claim((uint)i);\n@@ -402,14 +398,0 @@\n-  void reset_region_claim(uint region_idx) {\n-    _collection_set_iter_state[region_idx] = false;\n-  }\n-\n-  \/\/ Attempt to claim the given region in the collection set for iteration. Returns true\n-  \/\/ if this call caused the transition from Unclaimed to Claimed.\n-  inline bool claim_collection_set_region(uint region) {\n-    assert(region < _max_reserved_regions, \"Tried to access invalid region %u\", region);\n-    if (_collection_set_iter_state[region]) {\n-      return false;\n-    }\n-    return !Atomic::cmpxchg(&_collection_set_iter_state[region], false, true);\n-  }\n-\n@@ -832,2 +814,0 @@\n-    uint const region_idx = r->hrm_index();\n-\n@@ -844,1 +824,2 @@\n-    if (_scan_state->claim_collection_set_region(region_idx)) {\n+    \/\/ Scan code root remembered sets.\n+    {\n@@ -1213,1 +1194,1 @@\n-      r->rem_set()->clear_locked(true \/* only_cardset *\/);\n+      r->rem_set()->clear(true \/* only_cardset *\/);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1RemSet.cpp","additions":4,"deletions":23,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -145,1 +145,1 @@\n-                                           r->rem_set()->clear_locked(true \/* only_cardset *\/);\n+                                           r->rem_set()->clear(true \/* only_cardset *\/);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1RemSetTrackingPolicy.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -110,1 +110,1 @@\n-  _rem_set->clear_locked(true \/* only_cardset *\/);\n+  _rem_set->clear(true \/* only_cardset *\/);\n@@ -127,1 +127,1 @@\n-  rem_set()->clear_locked();\n+  rem_set()->clear();\n@@ -210,1 +210,1 @@\n-  return _rem_set->reset_table_scanner();\n+  _rem_set->reset_table_scanner();\n@@ -291,8 +291,1 @@\n-  HeapRegionRemSet* hrrs = rem_set();\n-  hrrs->add_code_root(nm);\n-}\n-\n-void HeapRegion::add_code_root_locked(nmethod* nm) {\n-  assert_locked_or_safepoint(CodeCache_lock);\n-  HeapRegionRemSet* hrrs = rem_set();\n-  hrrs->add_code_root_locked(nm);\n+  rem_set()->add_code_root(nm);\n@@ -302,2 +295,1 @@\n-  HeapRegionRemSet* hrrs = rem_set();\n-  hrrs->remove_code_root(nm);\n+  rem_set()->remove_code_root(nm);\n@@ -307,2 +299,1 @@\n-  HeapRegionRemSet* hrrs = rem_set();\n-  hrrs->code_roots_do(blk);\n+  rem_set()->code_roots_do(blk);\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.cpp","additions":6,"deletions":15,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -552,1 +552,0 @@\n-  void add_code_root_locked(nmethod* nm);\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -60,1 +60,0 @@\n-  _m(Mutex::service - 1, FormatBuffer<128>(\"HeapRegionRemSet#%u_lock\", hr->hrm_index())),\n@@ -72,5 +71,0 @@\n-  MutexLocker x(&_m, Mutex::_no_safepoint_check_flag);\n-  clear_locked(only_cardset);\n-}\n-\n-void HeapRegionRemSet::clear_locked(bool only_cardset) {\n@@ -87,0 +81,1 @@\n+  _code_roots.reset_table_scanner();\n@@ -106,21 +101,1 @@\n-  assert(nm != nullptr, \"sanity\");\n-  assert((!CodeCache_lock->owned_by_self() || SafepointSynchronize::is_at_safepoint()),\n-          \"should call add_code_root_locked instead. CodeCache_lock->owned_by_self(): %s, is_at_safepoint(): %s\",\n-          BOOL_TO_STR(CodeCache_lock->owned_by_self()), BOOL_TO_STR(SafepointSynchronize::is_at_safepoint()));\n-\n-  MutexLocker ml(&_m, Mutex::_no_safepoint_check_flag);\n-  add_code_root_locked(nm);\n-}\n-\n-void HeapRegionRemSet::add_code_root_locked(nmethod* nm) {\n-  assert(nm != nullptr, \"sanity\");\n-  assert((CodeCache_lock->owned_by_self() ||\n-         (SafepointSynchronize::is_at_safepoint() &&\n-          (_m.owned_by_self() || Thread::current()->is_VM_thread()))),\n-          \"not safely locked. CodeCache_lock->owned_by_self(): %s, is_at_safepoint(): %s, _m.owned_by_self(): %s, Thread::current()->is_VM_thread(): %s\",\n-          BOOL_TO_STR(CodeCache_lock->owned_by_self()), BOOL_TO_STR(SafepointSynchronize::is_at_safepoint()),\n-          BOOL_TO_STR(_m.owned_by_self()), BOOL_TO_STR(Thread::current()->is_VM_thread()));\n-\n-  if (!_code_roots.contains(nm)) { \/\/ with this test, we can assert that we do not modify the hash table while iterating over it\n-    _code_roots.add(nm);\n-  }\n+  _code_roots.add(nm);\n@@ -131,1 +106,0 @@\n-  assert_locked_or_safepoint(CodeCache_lock);\n@@ -133,1 +107,0 @@\n-  MutexLocker ml(CodeCache_lock->owned_by_self() ? nullptr : &_m, Mutex::_no_safepoint_check_flag);\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegionRemSet.cpp","additions":2,"deletions":29,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -43,1 +43,0 @@\n-  Mutex _m;\n@@ -121,1 +120,0 @@\n-  void clear_locked(bool only_cardset = false);\n@@ -170,1 +168,0 @@\n-    MutexLocker ml(&_m, Mutex::_no_safepoint_check_flag);\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegionRemSet.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -307,1 +307,1 @@\n-  MUTEX_DEFN(ThreadsSMRDelete_lock           , PaddedMonitor, nosafepoint-3); \/\/ Holds ConcurrentHashTableResize_lock\n+  MUTEX_DEFN(ThreadsSMRDelete_lock           , PaddedMonitor, service-2); \/\/ Holds ConcurrentHashTableResize_lock\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1027,1 +1027,1 @@\n-    new Mutex(Mutex::nosafepoint-2, \"ConcurrentHashTableResize_lock\");\n+    new Mutex(Mutex::service-1, \"ConcurrentHashTableResize_lock\");\n","filename":"src\/hotspot\/share\/utilities\/concurrentHashTable.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -28,9 +28,1 @@\n-class G1CodeRootSetTest : public ::testing::Test {\n- public:\n-\n-  size_t threshold() {\n-    return G1CodeRootSet::Threshold;\n-  }\n-};\n-\n-TEST_VM_F(G1CodeRootSetTest, g1_code_cache_rem_set) {\n+TEST_VM(G1CodeRootSet, g1_code_cache_rem_set) {\n@@ -46,1 +38,1 @@\n-  const size_t num_to_add = (size_t) threshold() + 1;\n+  const size_t num_to_add = 1000;\n@@ -63,3 +55,0 @@\n-  ASSERT_EQ(root_set._table->table_size(), 512u)\n-          << \"should have grown to large hashtable\";\n-\n@@ -79,1 +68,1 @@\n-          << \"should have grown to large hashtable\";\n+          << \"should be empty\";\n","filename":"test\/hotspot\/gtest\/gc\/g1\/test_g1CodeRootSet.cpp","additions":3,"deletions":14,"binary":false,"changes":17,"status":"modified"}]}