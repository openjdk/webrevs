{"files":[{"patch":"@@ -9967,0 +9967,8 @@\n+void Assembler::vgf2p8affineqb(XMMRegister dst, XMMRegister src2, XMMRegister src3, int imm8, int vector_len) {\n+  assert(VM_Version::supports_gfni(), \"requires GFNI support\");\n+  assert(VM_Version::supports_sse(), \"\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src3->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes);\n+  emit_int24((unsigned char)0xCE, (unsigned char)(0xC0 | encode), imm8);\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2742,0 +2742,3 @@\n+  \/\/ Galois field affine transformation instructions.\n+  void vgf2p8affineqb(XMMRegister dst, XMMRegister src2, XMMRegister src3, int imm8, int vector_len);\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -4532,0 +4532,154 @@\n+\n+\/\/ Bit reversal algorithm first reverses the bits of each byte followed by\n+\/\/ a byte level reversal for multi-byte primitive types (short\/int\/long).\n+\/\/ Algorithm performs a lookup table access to get reverse bit sequence\n+\/\/ corresponding to a 4 bit value. Thus a reverse bit sequence for a byte\n+\/\/ is obtained by swapping the reverse bit sequences of upper and lower\n+\/\/ nibble of a byte.\n+void C2_MacroAssembler::vector_reverse_bit(BasicType bt, XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                           XMMRegister xtmp2, Register rtmp, int vec_enc) {\n+  if (VM_Version::supports_avx512vlbw()) {\n+\n+    \/\/ Get the reverse bit sequence of lower nibble of each byte.\n+    vmovdqu(xtmp1, ExternalAddress(StubRoutines::x86::vector_reverse_bit_lut()), rtmp, vec_enc);\n+    movl(rtmp, 0x0F0F0F0F);\n+    evpbroadcastd(xtmp2, rtmp, vec_enc);\n+    vpandq(dst, xtmp2, src, vec_enc);\n+    vpshufb(dst, xtmp1, dst, vec_enc);\n+    vpsllq(dst, dst, 4, vec_enc);\n+\n+    \/\/ Get the reverse bit sequence of upper nibble of each byte.\n+    vpandn(xtmp2, xtmp2, src, vec_enc);\n+    vpsrlq(xtmp2, xtmp2, 4, vec_enc);\n+    vpshufb(xtmp2, xtmp1, xtmp2, vec_enc);\n+\n+    \/\/ Perform logical OR operation b\/w left shifted reverse bit sequence of lower nibble and\n+    \/\/ right shifted reverse bit sequence of upper nibble to obtain the reverse bit sequence of each byte.\n+    vporq(xtmp2, dst, xtmp2, vec_enc);\n+    vector_reverse_byte(bt, dst, xtmp2, rtmp, vec_enc);\n+\n+  } else if(!VM_Version::supports_avx512vlbw() && vec_enc == Assembler::AVX_512bit) {\n+\n+    \/\/ Shift based bit reversal.\n+    assert(bt == T_LONG || bt == T_INT, \"\");\n+    movl(rtmp, 0x0f0f0f0f);\n+    evpbroadcastd(xtmp1, rtmp, vec_enc);\n+\n+    \/\/ Swap lower and upper nibble of each byte.\n+    vpandq(dst, xtmp1, src, vec_enc);\n+    vpsllq(dst, dst, 4, vec_enc);\n+    vpandn(xtmp2, xtmp1, src, vec_enc);\n+    vpsrlq(xtmp2, xtmp2, 4, vec_enc);\n+    vporq(xtmp1, dst, xtmp2, vec_enc);\n+\n+    \/\/ Swap two least and most significant bits of each nibble.\n+    movl(rtmp, 0x33333333);\n+    evpbroadcastd(xtmp2, rtmp, vec_enc);\n+    vpandq(dst, xtmp2, xtmp1, vec_enc);\n+    vpsllq(dst, dst, 2, vec_enc);\n+    vpandn(xtmp2, xtmp2, xtmp1, vec_enc);\n+    vpsrlq(xtmp2, xtmp2, 2, vec_enc);\n+    vporq(xtmp1, dst, xtmp2, vec_enc);\n+\n+    \/\/ Swap adjacent pair of bits.\n+    movl(rtmp, 0x55555555);\n+    evpbroadcastd(xtmp2, rtmp, vec_enc);\n+    vpandq(dst, xtmp2, xtmp1, vec_enc);\n+    vpsllq(dst, dst, 1, vec_enc);\n+    vpandn(xtmp2, xtmp2, xtmp1, vec_enc);\n+    vpsrlq(xtmp2, xtmp2, 1, vec_enc);\n+    vporq(xtmp1, dst, xtmp2, vec_enc);\n+\n+    vector_reverse_byte64(bt, dst, xtmp1, xtmp1, xtmp2, rtmp, vec_enc);\n+\n+  } else {\n+    vmovdqu(xtmp1, ExternalAddress(StubRoutines::x86::vector_reverse_bit_lut()), rtmp, vec_enc);\n+    movl(rtmp, 0x0F0F0F0F);\n+    movdl(xtmp2, rtmp);\n+    vpbroadcastd(xtmp2, xtmp2, vec_enc);\n+\n+    \/\/ Get the reverse bit sequence of lower nibble of each byte.\n+    vpand(dst, xtmp2, src, vec_enc);\n+    vpshufb(dst, xtmp1, dst, vec_enc);\n+    vpsllq(dst, dst, 4, vec_enc);\n+\n+    \/\/ Get the reverse bit sequence of upper nibble of each byte.\n+    vpandn(xtmp2, xtmp2, src, vec_enc);\n+    vpsrlq(xtmp2, xtmp2, 4, vec_enc);\n+    vpshufb(xtmp2, xtmp1, xtmp2, vec_enc);\n+\n+    \/\/ Perform logical OR operation b\/w left shifted reverse bit sequence of lower nibble and\n+    \/\/ right shifted reverse bit sequence of upper nibble to obtain the reverse bit sequence of each byte.\n+    vpor(xtmp2, dst, xtmp2, vec_enc);\n+    vector_reverse_byte(bt, dst, xtmp2, rtmp, vec_enc);\n+  }\n+}\n+\n+void C2_MacroAssembler::vector_reverse_bit_gfni(BasicType bt, XMMRegister dst, XMMRegister src,\n+                                                XMMRegister xtmp, AddressLiteral mask, Register rtmp, int vec_enc) {\n+  \/\/ Galois field instruction based bit reversal based on following algorithm.\n+  \/\/ http:\/\/0x80.pl\/articles\/avx512-galois-field-for-bit-shuffling.html\n+  assert(VM_Version::supports_gfni(), \"\");\n+  vpbroadcastq(xtmp, mask, vec_enc, rtmp);\n+  vgf2p8affineqb(xtmp, src, xtmp, 0, vec_enc);\n+  vector_reverse_byte(bt, dst, xtmp, rtmp, vec_enc);\n+}\n+\n+void C2_MacroAssembler::vector_reverse_byte64(BasicType bt, XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                              XMMRegister xtmp2, Register rtmp, int vec_enc) {\n+  \/\/ Shift based bit reversal.\n+  assert(VM_Version::supports_evex(), \"\");\n+  evmovdqul(xtmp1, k0, src, true, vec_enc);\n+  switch(bt) {\n+    case T_LONG:\n+      \/\/ Swap upper and lower double word of each quad word.\n+      evprorq(xtmp1, k0, xtmp1, 32, true, vec_enc);\n+    case T_INT:\n+      \/\/ Swap upper and lower word of each double word.\n+      evprord(xtmp1, k0, xtmp1, 16, true, vec_enc);\n+    case T_SHORT:\n+      \/\/ Swap upper and lower byte of each word.\n+      movl(rtmp, 0x00FF00FF);\n+      evpbroadcastd(dst, rtmp, vec_enc);\n+      vpandq(xtmp2, dst, xtmp1, vec_enc);\n+      vpsllq(xtmp2, xtmp2, 8, vec_enc);\n+      vpandn(xtmp1, dst, xtmp1, vec_enc);\n+      vpsrlq(dst, xtmp1, 8, vec_enc);\n+      vporq(dst, dst, xtmp2, vec_enc);\n+      break;\n+    case T_BYTE:\n+      evmovdquq(dst, k0, src, true, vec_enc);\n+      break;\n+    default:\n+      fatal(\"Unsupported type\");\n+      break;\n+  }\n+}\n+\n+void C2_MacroAssembler::vector_reverse_byte(BasicType bt, XMMRegister dst, XMMRegister src, Register rtmp, int vec_enc) {\n+  if (bt == T_BYTE) {\n+    if (VM_Version::supports_avx512vl() || vec_enc == Assembler::AVX_512bit) {\n+      evmovdquq(dst, k0, src, true, vec_enc);\n+    } else {\n+      vmovdqu(dst, src);\n+    }\n+    return;\n+  }\n+  \/\/ Perform byte reversal by shuffling the bytes of a multi-byte primitive type using\n+  \/\/ pre-computed shuffle indices.\n+  switch(bt) {\n+    case T_LONG:\n+      vmovdqu(dst, ExternalAddress(StubRoutines::x86::vector_reverse_byte_perm_mask_long()), rtmp, vec_enc);\n+      break;\n+    case T_INT:\n+      vmovdqu(dst, ExternalAddress(StubRoutines::x86::vector_reverse_byte_perm_mask_int()), rtmp, vec_enc);\n+      break;\n+    case T_SHORT:\n+      vmovdqu(dst, ExternalAddress(StubRoutines::x86::vector_reverse_byte_perm_mask_short()), rtmp, vec_enc);\n+      break;\n+    default:\n+      fatal(\"Unsupported type\");\n+      break;\n+  }\n+  vpshufb(dst, src, dst, vec_enc);\n+}\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":154,"deletions":0,"binary":false,"changes":154,"status":"modified"},{"patch":"@@ -324,0 +324,8 @@\n+  void vector_reverse_bit(BasicType bt, XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                          XMMRegister xtmp2, Register rtmp, int vec_enc);\n+\n+  void vector_reverse_bit_gfni(BasicType bt, XMMRegister dst, XMMRegister src, XMMRegister xtmp,\n+                               AddressLiteral mask, Register rtmp, int vec_enc);\n+\n+  void vector_reverse_byte(BasicType bt, XMMRegister dst, XMMRegister src, Register rtmp, int vec_enc);\n+\n@@ -331,0 +339,4 @@\n+  void vector_reverse_byte64(BasicType bt, XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                             XMMRegister xtmp2, Register rtmp, int vec_enc);\n+\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2535,2 +2535,4 @@\n-  assert(vector_len <= AVX_256bit, \"AVX2 vector length\");\n-  if (vector_len == AVX_256bit) {\n+  assert(vector_len <= AVX_512bit, \"unexpected vector length\");\n+  if (vector_len == AVX_512bit) {\n+    evmovdquq(dst, src, AVX_512bit, scratch_reg);\n+  } else if (vector_len == AVX_256bit) {\n@@ -3148,0 +3150,9 @@\n+void MacroAssembler::vpbroadcastq(XMMRegister dst, AddressLiteral src, int vector_len, Register rscratch) {\n+  if (reachable(src)) {\n+    Assembler::vpbroadcastq(dst, as_Address(src), vector_len);\n+  } else {\n+    lea(rscratch, src);\n+    Assembler::vpbroadcastq(dst, Address(rscratch, 0), vector_len);\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":13,"deletions":2,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -1288,0 +1288,5 @@\n+  void vpbroadcastq(XMMRegister dst, AddressLiteral src, int vector_len, Register rscratch = rscratch1);\n+  void vpbroadcastq(XMMRegister dst, XMMRegister src, int vector_len) { Assembler::vpbroadcastq(dst, src, vector_len); }\n+  void vpbroadcastq(XMMRegister dst, Address src, int vector_len) { Assembler::vpbroadcastq(dst, src, vector_len); }\n+\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -192,0 +192,1 @@\n+      case Op_ReverseV:  return VM_Version::supports_gfni() ? 0 : 30;\n","filename":"src\/hotspot\/cpu\/x86\/matcher_x86.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -638,0 +638,92 @@\n+  address generate_vector_reverse_bit_lut(const char *stub_name) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+    address start = __ pc();\n+    __ emit_data(0x0C040800, relocInfo::none, 0);\n+    __ emit_data(0x0E060A02, relocInfo::none, 0);\n+    __ emit_data(0x0D050901, relocInfo::none, 0);\n+    __ emit_data(0x0F070B03, relocInfo::none, 0);\n+    __ emit_data(0x0C040800, relocInfo::none, 0);\n+    __ emit_data(0x0E060A02, relocInfo::none, 0);\n+    __ emit_data(0x0D050901, relocInfo::none, 0);\n+    __ emit_data(0x0F070B03, relocInfo::none, 0);\n+    __ emit_data(0x0C040800, relocInfo::none, 0);\n+    __ emit_data(0x0E060A02, relocInfo::none, 0);\n+    __ emit_data(0x0D050901, relocInfo::none, 0);\n+    __ emit_data(0x0F070B03, relocInfo::none, 0);\n+    __ emit_data(0x0C040800, relocInfo::none, 0);\n+    __ emit_data(0x0E060A02, relocInfo::none, 0);\n+    __ emit_data(0x0D050901, relocInfo::none, 0);\n+    __ emit_data(0x0F070B03, relocInfo::none, 0);\n+    return start;\n+  }\n+\n+  address generate_vector_reverse_byte_perm_mask_long(const char *stub_name) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+    address start = __ pc();\n+    __ emit_data(0x04050607, relocInfo::none, 0);\n+    __ emit_data(0x00010203, relocInfo::none, 0);\n+    __ emit_data(0x0C0D0E0F, relocInfo::none, 0);\n+    __ emit_data(0x08090A0B, relocInfo::none, 0);\n+    __ emit_data(0x04050607, relocInfo::none, 0);\n+    __ emit_data(0x00010203, relocInfo::none, 0);\n+    __ emit_data(0x0C0D0E0F, relocInfo::none, 0);\n+    __ emit_data(0x08090A0B, relocInfo::none, 0);\n+    __ emit_data(0x04050607, relocInfo::none, 0);\n+    __ emit_data(0x00010203, relocInfo::none, 0);\n+    __ emit_data(0x0C0D0E0F, relocInfo::none, 0);\n+    __ emit_data(0x08090A0B, relocInfo::none, 0);\n+    __ emit_data(0x04050607, relocInfo::none, 0);\n+    __ emit_data(0x00010203, relocInfo::none, 0);\n+    __ emit_data(0x0C0D0E0F, relocInfo::none, 0);\n+    __ emit_data(0x08090A0B, relocInfo::none, 0);\n+    return start;\n+  }\n+\n+  address generate_vector_reverse_byte_perm_mask_int(const char *stub_name) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+    address start = __ pc();\n+    __ emit_data(0x00010203, relocInfo::none, 0);\n+    __ emit_data(0x04050607, relocInfo::none, 0);\n+    __ emit_data(0x08090A0B, relocInfo::none, 0);\n+    __ emit_data(0x0C0D0E0F, relocInfo::none, 0);\n+    __ emit_data(0x00010203, relocInfo::none, 0);\n+    __ emit_data(0x04050607, relocInfo::none, 0);\n+    __ emit_data(0x08090A0B, relocInfo::none, 0);\n+    __ emit_data(0x0C0D0E0F, relocInfo::none, 0);\n+    __ emit_data(0x00010203, relocInfo::none, 0);\n+    __ emit_data(0x04050607, relocInfo::none, 0);\n+    __ emit_data(0x08090A0B, relocInfo::none, 0);\n+    __ emit_data(0x0C0D0E0F, relocInfo::none, 0);\n+    __ emit_data(0x00010203, relocInfo::none, 0);\n+    __ emit_data(0x04050607, relocInfo::none, 0);\n+    __ emit_data(0x08090A0B, relocInfo::none, 0);\n+    __ emit_data(0x0C0D0E0F, relocInfo::none, 0);\n+    return start;\n+  }\n+\n+  address generate_vector_reverse_byte_perm_mask_short(const char *stub_name) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+    address start = __ pc();\n+    __ emit_data(0x02030001, relocInfo::none, 0);\n+    __ emit_data(0x06070405, relocInfo::none, 0);\n+    __ emit_data(0x0A0B0809, relocInfo::none, 0);\n+    __ emit_data(0x0E0F0C0D, relocInfo::none, 0);\n+    __ emit_data(0x02030001, relocInfo::none, 0);\n+    __ emit_data(0x06070405, relocInfo::none, 0);\n+    __ emit_data(0x0A0B0809, relocInfo::none, 0);\n+    __ emit_data(0x0E0F0C0D, relocInfo::none, 0);\n+    __ emit_data(0x02030001, relocInfo::none, 0);\n+    __ emit_data(0x06070405, relocInfo::none, 0);\n+    __ emit_data(0x0A0B0809, relocInfo::none, 0);\n+    __ emit_data(0x0E0F0C0D, relocInfo::none, 0);\n+    __ emit_data(0x02030001, relocInfo::none, 0);\n+    __ emit_data(0x06070405, relocInfo::none, 0);\n+    __ emit_data(0x0A0B0809, relocInfo::none, 0);\n+    __ emit_data(0x0E0F0C0D, relocInfo::none, 0);\n+    return start;\n+  }\n+\n@@ -4030,0 +4122,4 @@\n+    StubRoutines::x86::_vector_reverse_bit_lut = generate_vector_reverse_bit_lut(\"reverse_bit_lut\");\n+    StubRoutines::x86::_vector_reverse_byte_perm_mask_long = generate_vector_reverse_byte_perm_mask_long(\"perm_mask_long\");\n+    StubRoutines::x86::_vector_reverse_byte_perm_mask_int = generate_vector_reverse_byte_perm_mask_int(\"perm_mask_int\");\n+    StubRoutines::x86::_vector_reverse_byte_perm_mask_short = generate_vector_reverse_byte_perm_mask_short(\"perm_mask_short\");\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_32.cpp","additions":96,"deletions":0,"binary":false,"changes":96,"status":"modified"},{"patch":"@@ -828,0 +828,60 @@\n+  address generate_vector_reverse_bit_lut(const char *stub_name) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+    address start = __ pc();\n+    __ emit_data64(0x0E060A020C040800, relocInfo::none);\n+    __ emit_data64(0x0F070B030D050901, relocInfo::none);\n+    __ emit_data64(0x0E060A020C040800, relocInfo::none);\n+    __ emit_data64(0x0F070B030D050901, relocInfo::none);\n+    __ emit_data64(0x0E060A020C040800, relocInfo::none);\n+    __ emit_data64(0x0F070B030D050901, relocInfo::none);\n+    __ emit_data64(0x0E060A020C040800, relocInfo::none);\n+    __ emit_data64(0x0F070B030D050901, relocInfo::none);\n+    return start;\n+  }\n+\n+  address generate_vector_reverse_byte_perm_mask_long(const char *stub_name) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+    address start = __ pc();\n+    __ emit_data64(0x0001020304050607, relocInfo::none);\n+    __ emit_data64(0x08090A0B0C0D0E0F, relocInfo::none);\n+    __ emit_data64(0x0001020304050607, relocInfo::none);\n+    __ emit_data64(0x08090A0B0C0D0E0F, relocInfo::none);\n+    __ emit_data64(0x0001020304050607, relocInfo::none);\n+    __ emit_data64(0x08090A0B0C0D0E0F, relocInfo::none);\n+    __ emit_data64(0x0001020304050607, relocInfo::none);\n+    __ emit_data64(0x08090A0B0C0D0E0F, relocInfo::none);\n+    return start;\n+  }\n+\n+  address generate_vector_reverse_byte_perm_mask_int(const char *stub_name) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+    address start = __ pc();\n+    __ emit_data64(0x0405060700010203, relocInfo::none);\n+    __ emit_data64(0x0C0D0E0F08090A0B, relocInfo::none);\n+    __ emit_data64(0x0405060700010203, relocInfo::none);\n+    __ emit_data64(0x0C0D0E0F08090A0B, relocInfo::none);\n+    __ emit_data64(0x0405060700010203, relocInfo::none);\n+    __ emit_data64(0x0C0D0E0F08090A0B, relocInfo::none);\n+    __ emit_data64(0x0405060700010203, relocInfo::none);\n+    __ emit_data64(0x0C0D0E0F08090A0B, relocInfo::none);\n+    return start;\n+  }\n+\n+  address generate_vector_reverse_byte_perm_mask_short(const char *stub_name) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+    address start = __ pc();\n+    __ emit_data64(0x0607040502030001, relocInfo::none);\n+    __ emit_data64(0x0E0F0C0D0A0B0809, relocInfo::none);\n+    __ emit_data64(0x0607040502030001, relocInfo::none);\n+    __ emit_data64(0x0E0F0C0D0A0B0809, relocInfo::none);\n+    __ emit_data64(0x0607040502030001, relocInfo::none);\n+    __ emit_data64(0x0E0F0C0D0A0B0809, relocInfo::none);\n+    __ emit_data64(0x0607040502030001, relocInfo::none);\n+    __ emit_data64(0x0E0F0C0D0A0B0809, relocInfo::none);\n+    return start;\n+  }\n+\n@@ -7730,0 +7790,4 @@\n+    StubRoutines::x86::_vector_reverse_bit_lut = generate_vector_reverse_bit_lut(\"reverse_bit_lut\");\n+    StubRoutines::x86::_vector_reverse_byte_perm_mask_long = generate_vector_reverse_byte_perm_mask_long(\"perm_mask_long\");\n+    StubRoutines::x86::_vector_reverse_byte_perm_mask_int = generate_vector_reverse_byte_perm_mask_int(\"perm_mask_int\");\n+    StubRoutines::x86::_vector_reverse_byte_perm_mask_short = generate_vector_reverse_byte_perm_mask_short(\"perm_mask_short\");\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":64,"deletions":0,"binary":false,"changes":64,"status":"modified"},{"patch":"@@ -62,0 +62,4 @@\n+address StubRoutines::x86::_vector_reverse_bit_lut = NULL;\n+address StubRoutines::x86::_vector_reverse_byte_perm_mask_long = NULL;\n+address StubRoutines::x86::_vector_reverse_byte_perm_mask_int = NULL;\n+address StubRoutines::x86::_vector_reverse_byte_perm_mask_short = NULL;\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -181,0 +181,4 @@\n+  static address _vector_reverse_bit_lut;\n+  static address _vector_reverse_byte_perm_mask_long;\n+  static address _vector_reverse_byte_perm_mask_int;\n+  static address _vector_reverse_byte_perm_mask_short;\n@@ -344,0 +348,16 @@\n+  static address vector_reverse_bit_lut() {\n+    return _vector_reverse_bit_lut;\n+  }\n+\n+  static address vector_reverse_byte_perm_mask_long() {\n+    return _vector_reverse_byte_perm_mask_long;\n+  }\n+\n+  static address vector_reverse_byte_perm_mask_int() {\n+    return _vector_reverse_byte_perm_mask_int;\n+  }\n+\n+  static address vector_reverse_byte_perm_mask_short() {\n+    return _vector_reverse_byte_perm_mask_short;\n+  }\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.hpp","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -954,0 +954,1 @@\n+      _features &= ~CPU_GFNI;\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -364,1 +364,2 @@\n-    decl(SERIALIZE,         \"serialize\",         47) \/* CPU SERIALIZE *\/\n+    decl(SERIALIZE,         \"serialize\",         47) \/* CPU SERIALIZE *\/ \\\n+    decl(GFNI,              \"gfni\",              48) \/* Vector GFNI instructions *\/\n@@ -594,0 +595,2 @@\n+        if (_cpuid_info.sef_cpuid7_ecx.bits.gfni != 0)\n+          result |= CPU_GFNI;\n@@ -900,0 +903,1 @@\n+  static bool supports_gfni()         { return (_features & CPU_GFNI) != 0; }\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.hpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1908,0 +1908,5 @@\n+    case Op_ReverseV:\n+    case Op_ReverseBytesV:\n+      if (UseAVX < 2) {\n+        return false;\n+      }\n@@ -8976,0 +8981,58 @@\n+\/\/ -------------------------------- Bit and Byte Reversal Vector Operations ------------------------\n+\n+instruct vreverse_reg(vec dst, vec src, vec xtmp1, vec xtmp2, rRegI rtmp) %{\n+  predicate(!VM_Version::supports_gfni());\n+  match(Set dst (ReverseV src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP rtmp);\n+  format %{ \"vector_reverse_bit_evex $dst, $src!\\t using $xtmp1, $xtmp2 and $rtmp as TEMP\" %}\n+  ins_encode %{\n+    int vec_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ vector_reverse_bit(bt, $dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                          $xtmp2$$XMMRegister, $rtmp$$Register, vec_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vreverse_reg_gfni(vec dst, vec src, vec xtmp, rRegI rtmp) %{\n+  predicate(VM_Version::supports_gfni());\n+  match(Set dst (ReverseV src));\n+  effect(TEMP dst, TEMP xtmp, TEMP rtmp);\n+  format %{ \"vector_reverse_bit_gfni $dst, $src!\\t using $rtmp and $xtmp as TEMP\" %}\n+  ins_encode %{\n+    int vec_enc = vector_length_encoding(this);\n+    BasicType bt  = Matcher::vector_element_basic_type(this);\n+    InternalAddress addr = $constantaddress(T_LONG, vreplicate_imm(T_LONG, 0x8040201008040201L, 1));\n+    __ vector_reverse_bit_gfni(bt, $dst$$XMMRegister, $src$$XMMRegister, $xtmp$$XMMRegister,\n+                               addr, $rtmp$$Register, vec_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vreverse_byte_reg(vec dst, vec src, rRegI rtmp) %{\n+  predicate(VM_Version::supports_avx512bw() || Matcher::vector_length_in_bytes(n) < 64);\n+  match(Set dst (ReverseBytesV src));\n+  effect(TEMP dst, TEMP rtmp);\n+  format %{ \"vector_reverse_byte $dst, $src!\\t using $rtmp as TEMP\" %}\n+  ins_encode %{\n+    int vec_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ vector_reverse_byte(bt, $dst$$XMMRegister, $src$$XMMRegister, $rtmp$$Register, vec_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vreverse_byte64_reg(vec dst, vec src, vec xtmp1, vec xtmp2, rRegI rtmp) %{\n+  predicate(!VM_Version::supports_avx512bw() && Matcher::vector_length_in_bytes(n) == 64);\n+  match(Set dst (ReverseBytesV src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP rtmp);\n+  format %{ \"vector_reverse_byte $dst, $src!\\t using $xtmp1, $xtmp2 and $rtmp as TEMP\" %}\n+  ins_encode %{\n+    int vec_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ vector_reverse_byte64(bt, $dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                             $xtmp2$$XMMRegister, $rtmp$$Register, vec_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":63,"deletions":0,"binary":false,"changes":63,"status":"modified"},{"patch":"@@ -4231,1 +4231,1 @@\n-    \"ReplicateB\",\"ReplicateS\",\"ReplicateI\",\"ReplicateL\",\"ReplicateF\",\"ReplicateD\",\n+    \"ReplicateB\",\"ReplicateS\",\"ReplicateI\",\"ReplicateL\",\"ReplicateF\",\"ReplicateD\", \"ReverseV\", \"ReverseBytesV\",\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -54,0 +54,1 @@\n+macro(ReverseBytesV)\n@@ -287,0 +288,1 @@\n+macro(ReverseV)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3406,0 +3406,21 @@\n+  case Op_ReverseV: {\n+    if (n->in(1)->Opcode() == Op_ReverseV) {\n+      if (n->is_predicated_vector() && n->in(1)->is_predicated_vector() &&\n+          n->in(2) == n->in(1)->in(2)) {\n+        n->subsume_by(n->in(1)->in(1), this);\n+      } else {\n+        bool is_user_blend = false;\n+        for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax; i++) {\n+          if (n->fast_out(i)->Opcode() == Op_VectorBlend) {\n+            is_user_blend = true;\n+            break;\n+          }\n+        }\n+        if (!is_user_blend) {\n+          n->subsume_by(n->in(1)->in(1), this);\n+        }\n+      }\n+    }\n+    break;\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":21,"deletions":0,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -977,0 +977,4 @@\n+      } break;\n+      case Op_ReverseV: {\n+        const TypeVect* vt = n->bottom_type()->is_vect();\n+        body_size += Matcher::vector_op_pre_select_sz_estimate(n->Opcode(), vt->element_basic_type(), vt->length());\n","filename":"src\/hotspot\/share\/opto\/loopTransform.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -160,2 +160,0 @@\n-    \/\/ Not implemented. Returning 0 temporarily\n-    return 0;\n@@ -163,2 +161,5 @@\n-    \/\/ Not implemented. Returning 0 temporarily\n-    return 0;\n+    return (is_integral_type(bt) ? Op_ReverseV : 0);\n+  case Op_ReverseBytesS:\n+  case Op_ReverseBytesI:\n+  case Op_ReverseBytesL:\n+    return (is_integral_type(bt) ? Op_ReverseBytesV : 0);\n@@ -554,0 +555,3 @@\n+  case Op_ReverseV: return new ReverseVNode(n1, vt);\n+  case Op_ReverseBytesV: return new ReverseBytesVNode(n1, vt);\n+\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":8,"deletions":4,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -1689,0 +1689,15 @@\n+class ReverseVNode : public VectorNode {\n+public:\n+  ReverseVNode(Node* in, const TypeVect* vt)\n+  : VectorNode(in, vt) {}\n+\n+  virtual int Opcode() const;\n+};\n+\n+class ReverseBytesVNode : public VectorNode {\n+public:\n+  ReverseBytesVNode(Node* in, const TypeVect* vt)\n+  : VectorNode(in, vt) {}\n+\n+  virtual int Opcode() const;\n+};\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -224,0 +224,1 @@\n+        GFNI,\n","filename":"src\/jdk.internal.vm.ci\/share\/classes\/jdk.vm.ci.amd64\/src\/jdk\/vm\/ci\/amd64\/AMD64.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"}]}