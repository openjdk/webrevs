{"files":[{"patch":"@@ -2303,0 +2303,2 @@\n+    case Op_ConvHF2I:\n+    case Op_ConvHF2L:\n@@ -14602,1 +14604,4 @@\n-            \"fcvt $dst, $tmp\\t# convert half to single precision\"\n+            \"fcvt $dst, $tmp\\t# convert half to single precision\" %}\n+  effect(TEMP tmp);\n+  ins_encode %{\n+      __ flt16_to_flt($dst$$FloatRegister, $src$$Register, $tmp$$FloatRegister, T_FLOAT);\n@@ -14604,0 +14609,7 @@\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct convHF2D_reg_reg(vRegD dst, iRegINoSp src, vRegF tmp) %{\n+  match(Set dst (ConvHF2D src));\n+  format %{\"mov $tmp, $src\\t# move source from $src to $tmp\\n\\t\"\n+           \"fcvt $dst, $src\\t# convert half to double precision\" %}\n@@ -14606,1 +14618,1 @@\n-      __ flt16_to_flt($dst$$FloatRegister, $src$$Register, $tmp$$FloatRegister);\n+    __ flt16_to_flt($dst$$FloatRegister, $src$$Register, $tmp$$FloatRegister, T_DOUBLE);\n@@ -14611,0 +14623,24 @@\n+instruct convHF2I_reg_reg(iRegINoSp dst, iRegINoSp src, vRegF tmp) %{\n+  match(Set dst (ConvHF2I src));\n+  format %{\"mov $tmp, $src\\t# move source from $src to $tmp\\n\\t\"\n+           \"fcvtzs $dst, $src \\t# convert half float to int\" %}\n+  effect(TEMP tmp);\n+  ins_encode %{\n+    __ flt16_to_int($dst$$Register, $src$$Register, $tmp$$FloatRegister, T_INT);\n+  %}\n+\n+  ins_pipe(fp_f2i);\n+%}\n+\n+instruct convHF2L_reg_reg(iRegLNoSp dst, iRegINoSp src, vRegF tmp) %{\n+  match(Set dst (ConvHF2L src));\n+  format %{\"mov $tmp, $src\\t# move source from $src to $tmp\\n\\t\"\n+           \"fcvtzs $dst, $src \\t# convert half float to long\" %}\n+  effect(TEMP tmp);\n+  ins_encode %{\n+    __ flt16_to_int($dst$$Register, $src$$Register, $tmp$$FloatRegister, T_LONG);\n+  %}\n+\n+  ins_pipe(fp_f2l);\n+%}\n+\n@@ -17222,2 +17258,1 @@\n-instruct convF2HFAndS2HF(vRegF dst, vRegF src)\n-%{\n+instruct convF2HFAndS2HF(vRegF dst, vRegF src) %{\n@@ -17232,2 +17267,3 @@\n-instruct reinterpretHF2SAndHF2F(vRegF dst, vRegF src)\n-%{\n+\/\/ Optimize a sequence of ReinterpretHF2S followed by ConvHF2X\n+\/\/ to do away with redundant mov operations.\n+instruct reinterpretHF2SAndHF2F(vRegF dst, vRegF src) %{\n@@ -17241,0 +17277,30 @@\n+\n+instruct reinterpretHF2SAndHF2I(iRegINoSp dst, vRegF src) %{\n+  match(Set dst (ConvHF2I (ReinterpretHF2S src)));\n+  format %{\"reinterpretHF2SAndHF2I $dst, $src\" %}\n+  ins_encode %{\n+    __ fcvtzshw($dst$$Register, $src$$FloatRegister);\n+  %}\n+\n+  ins_pipe(fp_f2i);\n+%}\n+\n+instruct reinterpretHF2SAndHF2D(vRegD dst, vRegF src) %{\n+  match(Set dst (ConvHF2D (ReinterpretHF2S src)));\n+  format %{\"reinterpretHF2SAndHF2D $dst, $src\" %}\n+  ins_encode %{\n+    __ fcvthd($dst$$FloatRegister, $src$$FloatRegister);\n+  %}\n+\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reinterpretHF2SAndHF2L(iRegLNoSp dst, vRegF src) %{\n+  match(Set dst (ConvHF2L (ReinterpretHF2S src)));\n+  format %{\"reinterpretHF2SAndHF2L $dst, $src\" %}\n+  ins_encode %{\n+    __ fcvtzshx($dst$$Register, $src$$FloatRegister);\n+  %}\n+\n+  ins_pipe(fp_f2l);\n+%}\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":72,"deletions":6,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -251,0 +251,12 @@\n+      case Op_VectorCastHF2X:\n+        \/\/ Vectorization is not possible for types - T_LONG and T_DOUBLE when vector length <= 16B.\n+        if ((bt == T_LONG || bt == T_DOUBLE) && UseSVE > 0 && length_in_bytes > 16) {\n+          break;\n+        \/\/ T_FLOAT type is vectorizable on both Neon and SVE machines and it does not need a FEAT_FP16 check either.\n+        } else if (bt == T_FLOAT) {\n+          break;\n+        \/\/ If the type is T_INT, it is vectorizable on both Neon and SVE machines but it needs a FEAT_FP16 check on Neon.\n+        } else if (bt == T_INT && (UseSVE > 0 || (VM_Version::supports_fphp() && VM_Version::supports_asimdhp()))) {\n+          break;\n+        }\n+        return false;\n@@ -4480,5 +4492,6 @@\n-\/\/ VectorCastHF2F\n-\n-instruct vcvtHFtoF(vReg dst, vReg src) %{\n-  match(Set dst (VectorCastHF2F src));\n-  format %{ \"vcvtHFtoF $dst, $src\" %}\n+\/\/ VectorCastHF2X\n+\/\/ Conversions from half-precision float to float\/int\/long\/double.\n+\/\/ Conversion to double\/long is not vectorizable on Neon but is vectorizable on SVE.\n+instruct vcvtHFtoX(vReg dst, vReg src) %{\n+  match(Set dst (VectorCastHF2X src));\n+  format %{ \"vcvtHFtoX $dst, $src\\t# half float to float\/int\/long\/double\" %}\n@@ -4486,0 +4499,1 @@\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n@@ -4487,4 +4501,25 @@\n-    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n-      \/\/ 4HF to 4F\n-      __ fcvtl($dst$$FloatRegister, __ T4S, $src$$FloatRegister, __ T4H);\n-    } else {\n+    if (bt == T_INT) {\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        \/\/ 4HF to 4I\n+        __ fcvtl($dst$$FloatRegister, __ T4S, $src$$FloatRegister, __ T4H);\n+        __ fcvtzs($dst$$FloatRegister, __ T4S, $dst$$FloatRegister);\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_vector_extend($dst$$FloatRegister, __ S, $src$$FloatRegister, __ H);\n+        __ sve_fcvtzs($dst$$FloatRegister, __ S, ptrue, $dst$$FloatRegister, __ H);\n+      }\n+    } else if (bt == T_FLOAT) {\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        \/\/ 4HF to 4F\n+        __ fcvtl($dst$$FloatRegister, __ T4S, $src$$FloatRegister, __ T4H);\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_vector_extend($dst$$FloatRegister, __ S, $src$$FloatRegister, __ H);\n+        __ sve_fcvt($dst$$FloatRegister, __ S, ptrue, $dst$$FloatRegister, __ H);\n+      }\n+    } else if (bt == T_LONG) {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_vector_extend($dst$$FloatRegister, __ D, $src$$FloatRegister, __ H);\n+      __ sve_fcvtzs($dst$$FloatRegister, __ D, ptrue, $dst$$FloatRegister, __ H);\n+    } else { \/\/ Has to be a double type\n+      assert(bt == T_DOUBLE, \"unsupported type\");\n@@ -4492,2 +4527,2 @@\n-      __ sve_vector_extend($dst$$FloatRegister, __ S, $src$$FloatRegister, __ H);\n-      __ sve_fcvt($dst$$FloatRegister, __ S, ptrue, $dst$$FloatRegister, __ H);\n+      __ sve_vector_extend($dst$$FloatRegister, __ D, $src$$FloatRegister, __ H);\n+      __ sve_fcvt($dst$$FloatRegister, __ D, ptrue, $dst$$FloatRegister, __ H);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector.ad","additions":46,"deletions":11,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -241,0 +241,12 @@\n+      case Op_VectorCastHF2X:\n+        \/\/ Vectorization is not possible for types - T_LONG and T_DOUBLE when vector length <= 16B.\n+        if ((bt == T_LONG || bt == T_DOUBLE) && UseSVE > 0 && length_in_bytes > 16) {\n+          break;\n+        \/\/ T_FLOAT type is vectorizable on both Neon and SVE machines and it does not need a FEAT_FP16 check either.\n+        } else if (bt == T_FLOAT) {\n+          break;\n+        \/\/ If the type is T_INT, it is vectorizable on both Neon and SVE machines but it needs a FEAT_FP16 check on Neon.\n+        } else if (bt == T_INT && (UseSVE > 0 || (VM_Version::supports_fphp() && VM_Version::supports_asimdhp()))) {\n+          break;\n+        }\n+        return false;\n@@ -2786,5 +2798,6 @@\n-\/\/ VectorCastHF2F\n-\n-instruct vcvtHFtoF(vReg dst, vReg src) %{\n-  match(Set dst (VectorCastHF2F src));\n-  format %{ \"vcvtHFtoF $dst, $src\" %}\n+\/\/ VectorCastHF2X\n+\/\/ Conversions from half-precision float to float\/int\/long\/double.\n+\/\/ Conversion to double\/long is not vectorizable on Neon but is vectorizable on SVE.\n+instruct vcvtHFtoX(vReg dst, vReg src) %{\n+  match(Set dst (VectorCastHF2X src));\n+  format %{ \"vcvtHFtoX $dst, $src\\t# half float to float\/int\/long\/double\" %}\n@@ -2792,0 +2805,1 @@\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n@@ -2793,4 +2807,25 @@\n-    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n-      \/\/ 4HF to 4F\n-      __ fcvtl($dst$$FloatRegister, __ T4S, $src$$FloatRegister, __ T4H);\n-    } else {\n+    if (bt == T_INT) {\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        \/\/ 4HF to 4I\n+        __ fcvtl($dst$$FloatRegister, __ T4S, $src$$FloatRegister, __ T4H);\n+        __ fcvtzs($dst$$FloatRegister, __ T4S, $dst$$FloatRegister);\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_vector_extend($dst$$FloatRegister, __ S, $src$$FloatRegister, __ H);\n+        __ sve_fcvtzs($dst$$FloatRegister, __ S, ptrue, $dst$$FloatRegister, __ H);\n+      }\n+    } else if (bt == T_FLOAT) {\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        \/\/ 4HF to 4F\n+        __ fcvtl($dst$$FloatRegister, __ T4S, $src$$FloatRegister, __ T4H);\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_vector_extend($dst$$FloatRegister, __ S, $src$$FloatRegister, __ H);\n+        __ sve_fcvt($dst$$FloatRegister, __ S, ptrue, $dst$$FloatRegister, __ H);\n+      }\n+    } else if (bt == T_LONG) {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_vector_extend($dst$$FloatRegister, __ D, $src$$FloatRegister, __ H);\n+      __ sve_fcvtzs($dst$$FloatRegister, __ D, ptrue, $dst$$FloatRegister, __ H);\n+    } else { \/\/ Has to be a double type\n+      assert(bt == T_DOUBLE, \"unsupported type\");\n@@ -2798,2 +2833,2 @@\n-      __ sve_vector_extend($dst$$FloatRegister, __ S, $src$$FloatRegister, __ H);\n-      __ sve_fcvt($dst$$FloatRegister, __ S, ptrue, $dst$$FloatRegister, __ H);\n+      __ sve_vector_extend($dst$$FloatRegister, __ D, $src$$FloatRegister, __ H);\n+      __ sve_fcvt($dst$$FloatRegister, __ D, ptrue, $dst$$FloatRegister, __ H);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector_ad.m4","additions":46,"deletions":11,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -2022,0 +2022,1 @@\n+  INSN(fcvthd, 0b11, 0b000101);   \/\/ Half-precision to double-precision\n@@ -2171,4 +2172,6 @@\n-  INSN(fcvtzsw, 0b0, 0b00, 0b11, 0b000);\n-  INSN(fcvtzs,  0b1, 0b00, 0b11, 0b000);\n-  INSN(fcvtzdw, 0b0, 0b01, 0b11, 0b000);\n-  INSN(fcvtzd,  0b1, 0b01, 0b11, 0b000);\n+  INSN(fcvtzsw,  0b0, 0b00, 0b11, 0b000);\n+  INSN(fcvtzs,   0b1, 0b00, 0b11, 0b000);\n+  INSN(fcvtzdw,  0b0, 0b01, 0b11, 0b000);\n+  INSN(fcvtzd,   0b1, 0b01, 0b11, 0b000);\n+  INSN(fcvtzshw, 0b0, 0b11, 0b11, 0b000);  \/\/ half-precision -> 32-bit\n+  INSN(fcvtzshx, 0x1, 0b11, 0b11, 0b000);  \/\/ half-precision -> 64-bit\n@@ -3173,9 +3176,13 @@\n-#define INSN(NAME, U, size, tmask, opcode)                                         \\\n-  void NAME(FloatRegister Vd, SIMD_Arrangement T, FloatRegister Vn) {              \\\n-       starti;                                                                     \\\n-       assert((ASSERTION), MSG);                                                   \\\n-       int op23 = (T == T4H || T == T8H) ? 0b11 : ((int)(T >> 1) & tmask);         \\\n-       int op20 = (T == T4H || T == T8H) ? 0b11 : 0b00;                            \\\n-       f(0, 31), f((int)T & 1, 30), f(U, 29), f(0b01110, 28, 24);                  \\\n-       f(size | op23, 23, 22), f(1, 21), f(op20, 20, 19), f(0b00, 18, 17);         \\\n-       f(opcode, 16, 12), f(0b10, 11, 10), rf(Vn, 5), rf(Vd, 0);                   \\\n+#define INSN(NAME, U, size, tmask, opcode)                                      \\\n+  void NAME(FloatRegister Vd, SIMD_Arrangement T, FloatRegister Vn) {           \\\n+    starti;                                                                     \\\n+    assert((ASSERTION), MSG);                                                   \\\n+    int op22 = (int)(T >> 1) & tmask;                                           \\\n+    int op19 = 0b00;                                                            \\\n+    if (tmask == 0b01 && (T == T4H || T == T8H)) {                              \\\n+      op22 = 0b1;                                                               \\\n+      op19 = 0b11;                                                              \\\n+    }                                                                           \\\n+    f(0, 31), f((int)T & 1, 30), f(U, 29), f(0b01110, 28, 24);                  \\\n+    f(size | op22, 23, 22), f(1, 21), f(op19, 20, 19), f(0b00, 18, 17);         \\\n+    f(opcode, 16, 12), f(0b10, 11, 10), rf(Vn, 5), rf(Vd, 0);                   \\\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":20,"deletions":13,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -1937,1 +1937,1 @@\n-  case lir_hf2f: __ flt16_to_flt(dest->as_float_reg(), value->as_register(), tmp->as_float_reg()); break;\n+  case lir_hf2f: __ flt16_to_flt(dest->as_float_reg(), value->as_register(), tmp->as_float_reg(), T_FLOAT); break;\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -532,0 +532,1 @@\n+  \/\/ Convert float to half-precision float\n@@ -537,1 +538,2 @@\n-  void flt16_to_flt(FloatRegister dst, Register src, FloatRegister tmp) {\n+  \/\/ Convert half-precision float to float\/double\n+  void flt16_to_flt(FloatRegister dst, Register src, FloatRegister tmp, BasicType bt) {\n@@ -539,1 +541,15 @@\n-    fcvths(dst, tmp);\n+    switch (bt) {\n+    case T_FLOAT:  fcvths(dst, tmp); break;\n+    case T_DOUBLE: fcvthd(dst, tmp); break;\n+    default: ShouldNotReachHere();\n+    }\n+  }\n+\n+  \/\/ Convert half-precision float to int\/long\n+  void flt16_to_int(Register dst, Register src, FloatRegister tmp, BasicType bt) {\n+    mov(tmp, H, 0, src);\n+    switch (bt) {\n+    case T_INT:  fcvtzshw(dst, tmp); break;\n+    case T_LONG: fcvtzshx(dst, tmp); break;\n+    default: ShouldNotReachHere();\n+    }\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":18,"deletions":2,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -5496,1 +5496,1 @@\n-  \/\/ v0 = result (float)\n+  \/\/ v0 = result (float or double)\n@@ -5498,1 +5498,1 @@\n-  address generate_float16ToFloat() {\n+  address generate_float16ToFP(BasicType bt) {\n@@ -5500,1 +5500,1 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"float16ToFloat\");\n+    StubCodeMark mark(this, \"StubRoutines\", \"float16 to float\/double\");\n@@ -5503,1 +5503,22 @@\n-    __ flt16_to_flt(v0, r0, v1);\n+    switch (bt) {\n+      case T_FLOAT:  __ flt16_to_flt(v0, r0, v1, T_FLOAT);  break;\n+      case T_DOUBLE: __ flt16_to_flt(v0, r0, v1, T_DOUBLE); break;\n+      default: ShouldNotReachHere();\n+    }\n+    __ ret(lr);\n+    return entry;\n+  }\n+\n+  \/\/ r1 = input (float16)\n+  \/\/ r0 = result (int or long)\n+  \/\/ v1 = temporary float register\n+  address generate_float16ToIntegral(BasicType bt) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", \"float16 to int\/long\");\n+    address entry = __ pc();\n+    BLOCK_COMMENT(\"Entry:\");\n+    switch (bt) {\n+      case T_INT:  __ flt16_to_int(r1, r0, v0, T_INT);  break;\n+      case T_LONG: __ flt16_to_int(r1, r0, v0, T_LONG); break;\n+      default: ShouldNotReachHere();\n+    }\n@@ -8551,1 +8572,1 @@\n-      StubRoutines::_hf2f = generate_float16ToFloat();\n+      StubRoutines::_hf2f = generate_float16ToFP(T_FLOAT);\n@@ -8555,0 +8576,12 @@\n+    if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_float16ToInt)) {\n+      StubRoutines::_hf2i = generate_float16ToIntegral(T_INT);\n+    }\n+\n+    if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_float16ToDouble)) {\n+      StubRoutines::_hf2d = generate_float16ToFP(T_DOUBLE);\n+    }\n+\n+    if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_float16ToLong)) {\n+      StubRoutines::_hf2l = generate_float16ToIntegral(T_LONG);\n+    }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":38,"deletions":5,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -317,1 +317,1 @@\n-  __ flt16_to_flt(v0, c_rarg0, v1);\n+  __ flt16_to_flt(v0, c_rarg0, v1, T_FLOAT);\n","filename":"src\/hotspot\/cpu\/aarch64\/templateInterpreterGenerator_aarch64.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -3,1 +3,1 @@\n-\/\/ Copyright (c) 2020, 2023, Arm Limited. All rights reserved.\n+\/\/ Copyright (c) 2020, 2024, Arm Limited. All rights reserved.\n@@ -90,1 +90,2 @@\n-      case Op_VectorCastHF2F:\n+      case Op_VectorCastHF2X:\n+        return bt == T_FLOAT && UseZvfh;\n@@ -4450,1 +4451,1 @@\n-instruct vconvHF2F(vReg dst, vReg src, vRegMask_V0 v0) %{\n+instruct vconvHF2X(vReg dst, vReg src, vRegMask_V0 v0) %{\n@@ -4452,1 +4453,1 @@\n-  match(Set dst (VectorCastHF2F src));\n+  match(Set dst (VectorCastHF2X src));\n","filename":"src\/hotspot\/cpu\/riscv\/riscv_v.ad","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1699,1 +1699,1 @@\n-    case Op_VectorCastHF2F:\n+    case Op_VectorCastHF2X:\n@@ -1918,1 +1918,0 @@\n-    case Op_VectorCastHF2F:\n@@ -1925,0 +1924,7 @@\n+    case Op_VectorCastHF2X:\n+      if (bt != T_FLOAT && (!VM_Version::supports_f16c() &&\n+         ((!VM_Version::supports_evex() ||\n+         ((size_in_bits != 512) && !VM_Version::supports_avx512vl()))))) {\n+        return false;\n+      }\n+      break;\n@@ -3752,1 +3758,1 @@\n-  match(Set dst (VectorCastHF2F (LoadVector mem)));\n+  match(Set dst (VectorCastHF2X (LoadVector mem)));\n@@ -3755,0 +3761,1 @@\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n@@ -3756,1 +3763,3 @@\n-    __ vcvtph2ps($dst$$XMMRegister, $mem$$Address, vlen_enc);\n+    if (bt == T_FLOAT) {\n+      __ vcvtph2ps($dst$$XMMRegister, $mem$$Address, vlen_enc);\n+    }\n@@ -3762,1 +3771,1 @@\n-  match(Set dst (VectorCastHF2F src));\n+  match(Set dst (VectorCastHF2X src));\n@@ -3764,1 +3773,1 @@\n-  format %{ \"vector_conv_HF2F $dst,$src\" %}\n+  format %{ \"vector_conv_HF2X $dst,$src\" %}\n@@ -3766,0 +3775,1 @@\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n@@ -3767,1 +3777,3 @@\n-    __ vcvtph2ps($dst$$XMMRegister, $src$$XMMRegister, vlen_enc);\n+    if (bt == T_FLOAT) {\n+      __ vcvtph2ps($dst$$XMMRegister, $src$$XMMRegister, vlen_enc);\n+    }\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":19,"deletions":7,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -4362,1 +4362,1 @@\n-    \"VectorCastL2X\", \"VectorCastF2X\", \"VectorCastD2X\", \"VectorCastF2HF\", \"VectorCastHF2F\",\n+    \"VectorCastL2X\", \"VectorCastF2X\", \"VectorCastD2X\", \"VectorCastF2HF\", \"VectorCastHF2X\",\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -223,0 +223,4 @@\n+  \/* Float16 conversion intrinsics *\/                                                                                   \\\n+  do_intrinsic(_float16ToDouble,          java_lang_Float16,      doubleValue_name, void_double_signature,       F_R)   \\\n+  do_intrinsic(_float16ToInt,             java_lang_Float16,      intValue_name,    void_int_signature,          F_R)   \\\n+  do_intrinsic(_float16ToLong,            java_lang_Float16,      longValue_name,   void_long_signature,         F_R)   \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -638,0 +638,9 @@\n+  case vmIntrinsics::_float16ToDouble:\n+    if (!Matcher::match_rule_supported(Op_ConvHF2D)) return false;\n+    break;\n+  case vmIntrinsics::_float16ToInt:\n+    if (!Matcher::match_rule_supported(Op_ConvHF2I)) return false;\n+    break;\n+  case vmIntrinsics::_float16ToLong:\n+    if (!Matcher::match_rule_supported(Op_ConvHF2L)) return false;\n+    break;\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1900,1 +1900,1 @@\n-static BasicType get_convert_type(Node* convert, const Type* type) {\n+static BasicType get_convert_type(Node* convert, const Type* type, const bool is_source=false) {\n@@ -1902,2 +1902,6 @@\n-  if (type->isa_int() && (convert_op == Op_ConvHF2F || convert_op == Op_ConvF2HF)) {\n-    return T_SHORT;\n+  if (type->isa_int()) {\n+    if (is_source && convert_op == Op_ConvHF2I) {\n+      return T_SHORT;\n+    } else if (convert_op == Op_ConvHF2F || convert_op == Op_ConvF2HF || convert_op == Op_ConvHF2D || convert_op == Op_ConvHF2L) {\n+      return T_SHORT;\n+    }\n@@ -2669,1 +2673,1 @@\n-        return ConvertNode::create_convert(get_convert_type(convert, source_type), get_convert_type(convert, dest_type), newphi);\n+        return ConvertNode::create_convert(get_convert_type(convert, source_type, true), get_convert_type(convert, dest_type), newphi);\n","filename":"src\/hotspot\/share\/opto\/cfgnode.cpp","additions":8,"deletions":4,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -156,0 +156,3 @@\n+macro(ConvHF2D)\n+macro(ConvHF2I)\n+macro(ConvHF2L)\n@@ -533,1 +536,1 @@\n-macro(VectorCastHF2F)\n+macro(VectorCastHF2X)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -141,0 +141,6 @@\n+    } else if (target == T_DOUBLE) {\n+      return new ConvHF2DNode(input);\n+    } else if (target == T_INT) {\n+      return new ConvHF2INode(input);\n+    } else if (target == T_LONG) {\n+      return new ConvHF2LNode(input);\n@@ -354,0 +360,48 @@\n+\/\/=============================================================================\n+\/\/------------------------------Value------------------------------------------\n+const Type* ConvHF2DNode::Value(PhaseGVN* phase) const {\n+  const Type *t = phase->type(in(1));\n+  if (t == Type::TOP) return Type::TOP;\n+  if (t == TypeInt::SHORT || StubRoutines::hf2d_adr() == nullptr) {\n+    return Type::DOUBLE;\n+  }\n+\n+  const TypeInt *ti = t->is_int();\n+  if (ti->is_con()) {\n+    return TypeD::make(StubRoutines::hf2d(ti->get_con()));\n+  }\n+  return Type::DOUBLE;\n+}\n+\n+\/\/=============================================================================\n+\/\/------------------------------Value------------------------------------------\n+const Type* ConvHF2INode::Value(PhaseGVN* phase) const {\n+  const Type *t = phase->type(in(1));\n+  if (t == Type::TOP) return Type::TOP;\n+  if (t == TypeInt::SHORT || StubRoutines::hf2i_adr() == nullptr) {\n+    return TypeInt::INT;\n+  }\n+\n+  const TypeInt *ti = t->is_int();\n+  if (ti->is_con()) {\n+    return TypeInt::make(StubRoutines::hf2i(ti->get_con()));\n+  }\n+  return TypeInt::INT;\n+}\n+\n+\/\/=============================================================================\n+\/\/------------------------------Value------------------------------------------\n+const Type* ConvHF2LNode::Value(PhaseGVN* phase) const {\n+  const Type *t = phase->type(in(1));\n+  if (t == Type::TOP) return Type::TOP;\n+  if (t == TypeInt::SHORT || StubRoutines::hf2l_adr() == nullptr) {\n+    return TypeLong::LONG;\n+  }\n+\n+  const TypeInt *ti = t->is_int();\n+  if (ti->is_con()) {\n+    return TypeLong::make(StubRoutines::hf2l(ti->get_con()));\n+  }\n+  return TypeLong::LONG;\n+ }\n+\n","filename":"src\/hotspot\/share\/opto\/convertnode.cpp","additions":54,"deletions":0,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -143,1 +143,1 @@\n-\/\/ Convert Halffloat to float\n+\/\/ Convert half-precision float to float\n@@ -150,0 +150,34 @@\n+  virtual const Type* bottom_type() const { return Type::FLOAT; }\n+};\n+\n+\/\/------------------------------ConvHF2DNode------------------------------------\n+\/\/ Convert half-precision float to double\n+class ConvHF2DNode : public ConvertNode {\n+public:\n+  ConvHF2DNode(Node* in1) : ConvertNode(Type::DOUBLE, in1) {}\n+  virtual int Opcode() const;\n+  virtual const Type* in_type() const { return TypeInt::SHORT; }\n+  virtual const Type* Value(PhaseGVN* phase) const;\n+  virtual const Type* bottom_type() const { return Type::DOUBLE; }\n+};\n+\n+\/\/------------------------------ConvHF2INode-----------------------------------\n+\/\/ Convert half-precision float to integer\n+class ConvHF2INode : public ConvertNode {\n+public:\n+  ConvHF2INode(Node* in1) : ConvertNode(TypeInt::INT, in1) {}\n+  virtual int Opcode() const;\n+  virtual const Type* in_type() const { return TypeInt::SHORT; }\n+  virtual const Type* Value(PhaseGVN* phase) const;\n+  virtual const Type* bottom_type() const { return TypeInt::INT; }\n+};\n+\n+\/\/------------------------------ConvHF2LNode-----------------------------------\n+\/\/ Convert half-precision float to long\n+class ConvHF2LNode : public ConvertNode {\n+public:\n+  ConvHF2LNode(Node* in1) : ConvertNode(TypeLong::LONG, in1) {}\n+  virtual int Opcode() const;\n+  virtual const Type* in_type() const { return TypeInt::SHORT; }\n+  virtual const Type* Value(PhaseGVN* phase) const;\n+  virtual const Type* bottom_type() const { return TypeLong::LONG; }\n","filename":"src\/hotspot\/share\/opto\/convertnode.hpp","additions":35,"deletions":1,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -559,0 +559,3 @@\n+  case vmIntrinsics::_float16ToDouble:\n+  case vmIntrinsics::_float16ToInt:\n+  case vmIntrinsics::_float16ToLong:            return inline_fp16_conversions(intrinsic_id());\n@@ -5141,0 +5144,20 @@\n+bool LibraryCallKit::inline_fp16_conversions(vmIntrinsics::ID id) {\n+  Node* arg = argument(0);\n+  if (!arg->is_InlineType()) {\n+    return false;\n+  }\n+\n+  Node* result = nullptr;\n+\n+  switch (id) {\n+  case vmIntrinsics::_float16ToDouble:  result = _gvn.transform(new ConvHF2DNode(arg->as_InlineType()->field_value(0))); break;\n+  case vmIntrinsics::_float16ToInt:     result = _gvn.transform(new ConvHF2INode(arg->as_InlineType()->field_value(0))); break;\n+  case vmIntrinsics::_float16ToLong:    result = _gvn.transform(new ConvHF2LNode(arg->as_InlineType()->field_value(0))); break;\n+  default:\n+    fatal_unexpected_iid(id);\n+    break;\n+  }\n+  set_result(_gvn.transform(result));\n+  return true;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":23,"deletions":0,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -315,0 +315,1 @@\n+  bool inline_fp16_conversions(vmIntrinsics::ID id);\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -577,0 +577,3 @@\n+    case Op_ConvHF2I:\n+    case Op_ConvHF2D:\n+    case Op_ConvHF2L:\n@@ -1436,1 +1439,1 @@\n-    case Op_VectorCastHF2F: return new VectorCastHF2FNode(n1, vt);\n+    case Op_VectorCastHF2X: return new VectorCastHF2XNode(n1, vt);\n@@ -1450,0 +1453,3 @@\n+    case Op_ConvHF2I:\n+    case Op_ConvHF2D:\n+    case Op_ConvHF2L:\n@@ -1451,1 +1457,1 @@\n-      return Op_VectorCastHF2F;\n+      return Op_VectorCastHF2X;\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":8,"deletions":2,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -1738,1 +1738,1 @@\n-class VectorCastHF2FNode : public VectorCastNode {\n+class VectorCastHF2XNode : public VectorCastNode {\n@@ -1740,1 +1740,1 @@\n-  VectorCastHF2FNode(Node* in, const TypeVect* vt) : VectorCastNode(in, vt) {\n+  VectorCastHF2XNode(Node* in, const TypeVect* vt) : VectorCastNode(in, vt) {\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -183,0 +183,3 @@\n+address StubRoutines::_hf2d = nullptr;\n+address StubRoutines::_hf2i = nullptr;\n+address StubRoutines::_hf2l = nullptr;\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -263,0 +263,3 @@\n+  static address _hf2d;\n+  static address _hf2i;\n+  static address _hf2l;\n@@ -471,0 +474,3 @@\n+  static address hf2d_adr()            { return _hf2d; }\n+  static address hf2i_adr()            { return _hf2i; }\n+  static address hf2l_adr()            { return _hf2l; }\n@@ -485,0 +491,21 @@\n+  static jdouble hf2d(jshort x) {\n+    assert(_hf2d != nullptr, \"stub is not implemented on this platform\");\n+    MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXExec, Thread::current());) \/\/ About to call into code cache\n+    typedef jdouble (*hf2d_stub_t)(jshort x);\n+    return ((hf2d_stub_t)_hf2d)(x);\n+  }\n+\n+  static jint hf2i(jshort x) {\n+    assert(_hf2i != nullptr, \"stub is not implemented on this platform\");\n+    MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXExec, Thread::current());) \/\/ About to call into code cache\n+    typedef jint (*hf2i_stub_t)(jshort x);\n+    return ((hf2i_stub_t)_hf2i)(x);\n+  }\n+\n+  static jlong hf2l(jshort x) {\n+    assert(_hf2l != nullptr, \"stub is not implemented on this platform\");\n+    MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXExec, Thread::current());) \/\/ About to call into code cache\n+    typedef jlong (*hf2l_stub_t)(jshort x);\n+    return ((hf2l_stub_t)_hf2l)(x);\n+  }\n+\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.hpp","additions":27,"deletions":0,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -641,0 +641,1 @@\n+    @IntrinsicCandidate\n@@ -652,0 +653,1 @@\n+    @IntrinsicCandidate\n@@ -682,0 +684,1 @@\n+    @IntrinsicCandidate\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Float16.java","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1048,1 +1048,1 @@\n-        if (self._name in [\"fcvtsh\", \"fcvths\"]):\n+        if (self._name in [\"fcvtsh\", \"fcvths\", \"fcvthd\"]):\n@@ -1609,1 +1609,1 @@\n-          [\"fcvts\", \"ds\"], [\"fcvtsh\", \"hs\"], [\"fcvths\", \"sh\"],\n+          [\"fcvts\", \"ds\"], [\"fcvtsh\", \"hs\"], [\"fcvths\", \"sh\"], [\"fcvthd\", \"dh\"],\n@@ -1616,0 +1616,1 @@\n+                          [\"fcvtzshw\", \"fcvtzs\", \"wh\"], [\"fcvtzshx\", \"fcvtzs\", \"xh\"],\n","filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -528,8 +528,9 @@\n-    __ fmovd(v12, v5);                                 \/\/       fmov    d12, d5\n-    __ fabsd(v12, v24);                                \/\/       fabs    d12, d24\n-    __ fnegd(v24, v29);                                \/\/       fneg    d24, d29\n-    __ fsqrtd(v27, v21);                               \/\/       fsqrt   d27, d21\n-    __ fcvtd(v16, v22);                                \/\/       fcvt    s16, d22\n-    __ fabsh(v5, v28);                                 \/\/       fabs    h5, h28\n-    __ fnegh(v22, v17);                                \/\/       fneg    h22, h17\n-    __ fsqrth(v13, v19);                               \/\/       fsqrt   h13, h19\n+    __ fcvthd(v12, v5);                                \/\/       fcvt    d12, h5\n+    __ fmovd(v12, v24);                                \/\/       fmov    d12, d24\n+    __ fabsd(v24, v29);                                \/\/       fabs    d24, d29\n+    __ fnegd(v27, v21);                                \/\/       fneg    d27, d21\n+    __ fsqrtd(v16, v22);                               \/\/       fsqrt   d16, d22\n+    __ fcvtd(v5, v28);                                 \/\/       fcvt    s5, d28\n+    __ fabsh(v22, v17);                                \/\/       fabs    h22, h17\n+    __ fnegh(v13, v19);                                \/\/       fneg    h13, h19\n+    __ fsqrth(v19, v27);                               \/\/       fsqrt   h19, h27\n@@ -538,6 +539,8 @@\n-    __ fcvtzsw(r19, v27);                              \/\/       fcvtzs  w19, s27\n-    __ fcvtzs(r17, v6);                                \/\/       fcvtzs  x17, s6\n-    __ fcvtzdw(r13, v7);                               \/\/       fcvtzs  w13, d7\n-    __ fcvtzd(r28, v26);                               \/\/       fcvtzs  x28, d26\n-    __ scvtfws(v17, r6);                               \/\/       scvtf   s17, w6\n-    __ scvtfs(v1, r4);                                 \/\/       scvtf   s1, x4\n+    __ fcvtzsw(r17, v6);                               \/\/       fcvtzs  w17, s6\n+    __ fcvtzs(r13, v7);                                \/\/       fcvtzs  x13, s7\n+    __ fcvtzdw(r28, v26);                              \/\/       fcvtzs  w28, d26\n+    __ fcvtzd(r17, v6);                                \/\/       fcvtzs  x17, d6\n+    __ fcvtzshw(r1, v4);                               \/\/       fcvtzs  w1, h4\n+    __ fcvtzshx(r13, v20);                             \/\/       fcvtzs  x13, h20\n+    __ scvtfws(v6, r21);                               \/\/       scvtf   s6, w21\n+    __ scvtfs(v26, r23);                               \/\/       scvtf   s26, x23\n@@ -545,9 +548,9 @@\n-    __ scvtfd(v6, r21);                                \/\/       scvtf   d6, x21\n-    __ fcvtassw(r26, v23);                             \/\/       fcvtas  w26, s23\n-    __ fcvtasd(r13, v20);                              \/\/       fcvtas  x13, d20\n-    __ fcvtmssw(r30, v27);                             \/\/       fcvtms  w30, s27\n-    __ fcvtmsd(r10, v21);                              \/\/       fcvtms  x10, d21\n-    __ fmovs(r5, v17);                                 \/\/       fmov    w5, s17\n-    __ fmovd(r11, v13);                                \/\/       fmov    x11, d13\n-    __ fmovs(v13, r20);                                \/\/       fmov    s13, w20\n-    __ fmovd(v26, r14);                                \/\/       fmov    d26, x14\n+    __ scvtfd(v30, r27);                               \/\/       scvtf   d30, x27\n+    __ fcvtassw(r10, v21);                             \/\/       fcvtas  w10, s21\n+    __ fcvtasd(r5, v17);                               \/\/       fcvtas  x5, d17\n+    __ fcvtmssw(r11, v13);                             \/\/       fcvtms  w11, s13\n+    __ fcvtmsd(r13, v20);                              \/\/       fcvtms  x13, d20\n+    __ fmovs(r26, v14);                                \/\/       fmov    w26, s14\n+    __ fmovd(r4, v23);                                 \/\/       fmov    x4, d23\n+    __ fmovs(v23, r29);                                \/\/       fmov    s23, w29\n+    __ fmovd(v12, r14);                                \/\/       fmov    d12, x14\n@@ -556,4 +559,4 @@\n-    __ fcmps(v4, v23);                                 \/\/       fcmp    s4, s23\n-    __ fcmpd(v23, v29);                                \/\/       fcmp    d23, d29\n-    __ fcmps(v12, 0.0);                                \/\/       fcmp    s12, #0.0\n-    __ fcmpd(v14, 0.0);                                \/\/       fcmp    d14, #0.0\n+    __ fcmps(v16, v27);                                \/\/       fcmp    s16, s27\n+    __ fcmpd(v21, v0);                                 \/\/       fcmp    d21, d0\n+    __ fcmps(v6, 0.0);                                 \/\/       fcmp    s6, #0.0\n+    __ fcmpd(v26, 0.0);                                \/\/       fcmp    d26, #0.0\n@@ -562,5 +565,5 @@\n-    __ stpw(r27, r21, Address(r0, -48));               \/\/       stp     w27, w21, [x0, #-48]\n-    __ ldpw(r12, r6, Address(r27, -176));              \/\/       ldp     w12, w6, [x27, #-176]\n-    __ ldpsw(r14, r11, Address(r19, -256));            \/\/       ldpsw   x14, x11, [x19, #-256]\n-    __ stp(r2, r30, Address(r15, -48));                \/\/       stp     x2, x30, [x15, #-48]\n-    __ ldp(r23, r24, Address(r9, -256));               \/\/       ldp     x23, x24, [x9, #-256]\n+    __ stpw(r27, r12, Address(r6, -32));               \/\/       stp     w27, w12, [x6, #-32]\n+    __ ldpw(r14, r11, Address(r19, -256));             \/\/       ldp     w14, w11, [x19, #-256]\n+    __ ldpsw(r0, r12, Address(r15, -48));              \/\/       ldpsw   x0, x12, [x15, #-48]\n+    __ stp(r9, r23, Address(r23, 32));                 \/\/       stp     x9, x23, [x23, #32]\n+    __ ldp(r15, r4, Address(r26, -176));               \/\/       ldp     x15, x4, [x26, #-176]\n@@ -569,5 +572,5 @@\n-    __ stpw(r30, r0, Address(__ pre(r15, -176)));      \/\/       stp     w30, w0, [x15, #-176]!\n-    __ ldpw(r26, r6, Address(__ pre(r11, -208)));      \/\/       ldp     w26, w6, [x11, #-208]!\n-    __ ldpsw(r2, r4, Address(__ pre(r19, -64)));       \/\/       ldpsw   x2, x4, [x19, #-64]!\n-    __ stp(r1, r30, Address(__ pre(r9, -32)));         \/\/       stp     x1, x30, [x9, #-32]!\n-    __ ldp(r29, r23, Address(__ pre(r27, 32)));        \/\/       ldp     x29, x23, [x27, #32]!\n+    __ stpw(r17, r8, Address(__ pre(r6, -160)));       \/\/       stp     w17, w8, [x6, #-160]!\n+    __ ldpw(r7, r2, Address(__ pre(r4, -112)));        \/\/       ldp     w7, w2, [x4, #-112]!\n+    __ ldpsw(r14, r9, Address(__ pre(r22, -16)));      \/\/       ldpsw   x14, x9, [x22, #-16]!\n+    __ stp(r13, r20, Address(__ pre(r24, -256)));      \/\/       stp     x13, x20, [x24, #-256]!\n+    __ ldp(r8, r11, Address(__ pre(r10, 96)));         \/\/       ldp     x8, x11, [x10, #96]!\n@@ -576,5 +579,5 @@\n-    __ stpw(r13, r0, Address(__ post(r11, -224)));     \/\/       stp     w13, w0, [x11], #-224\n-    __ ldpw(r25, r16, Address(__ post(r10, -128)));    \/\/       ldp     w25, w16, [x10], #-128\n-    __ ldpsw(r26, r9, Address(__ post(r10, -48)));     \/\/       ldpsw   x26, x9, [x10], #-48\n-    __ stp(r19, r12, Address(__ post(r1, 128)));       \/\/       stp     x19, x12, [x1], #128\n-    __ ldp(r14, r15, Address(__ post(r24, -32)));      \/\/       ldp     x14, x15, [x24], #-32\n+    __ stpw(r24, r5, Address(__ post(r16, -112)));     \/\/       stp     w24, w5, [x16], #-112\n+    __ ldpw(r0, r26, Address(__ post(r9, -128)));      \/\/       ldp     w0, w26, [x9], #-128\n+    __ ldpsw(r24, r2, Address(__ post(r17, -128)));    \/\/       ldpsw   x24, x2, [x17], #-128\n+    __ stp(r26, r17, Address(__ post(r14, -48)));      \/\/       stp     x26, x17, [x14], #-48\n+    __ ldp(r30, r21, Address(__ post(r29, 48)));       \/\/       ldp     x30, x21, [x29], #48\n@@ -583,4 +586,4 @@\n-    __ stnpw(r17, r21, Address(r30, -128));            \/\/       stnp    w17, w21, [x30, #-128]\n-    __ ldnpw(r23, r10, Address(r17, 16));              \/\/       ldnp    w23, w10, [x17, #16]\n-    __ stnp(r30, r10, Address(r30, -160));             \/\/       stnp    x30, x10, [x30, #-160]\n-    __ ldnp(r8, r20, Address(r30, 80));                \/\/       ldnp    x8, x20, [x30, #80]\n+    __ stnpw(r17, r23, Address(r10, -112));            \/\/       stnp    w17, w23, [x10, #-112]\n+    __ ldnpw(r26, r6, Address(r30, -160));             \/\/       ldnp    w26, w6, [x30, #-160]\n+    __ stnp(r30, r8, Address(r20, 64));                \/\/       stnp    x30, x8, [x20, #64]\n+    __ ldnp(r22, r29, Address(r9, 48));                \/\/       ldnp    x22, x29, [x9, #48]\n@@ -589,22 +592,22 @@\n-    __ ld1(v3, __ T8B, Address(r23));                  \/\/       ld1     {v3.8B}, [x23]\n-    __ ld1(v30, v31, __ T16B, Address(__ post(r22, 32))); \/\/    ld1     {v30.16B, v31.16B}, [x22], 32\n-    __ ld1(v26, v27, v28, __ T1D, Address(__ post(r30, r5))); \/\/        ld1     {v26.1D, v27.1D, v28.1D}, [x30], x5\n-    __ ld1(v17, v18, v19, v20, __ T8H, Address(__ post(r20, 64))); \/\/   ld1     {v17.8H, v18.8H, v19.8H, v20.8H}, [x20], 64\n-    __ ld1r(v11, __ T8B, Address(r24));                \/\/       ld1r    {v11.8B}, [x24]\n-    __ ld1r(v0, __ T4S, Address(__ post(r16, 4)));     \/\/       ld1r    {v0.4S}, [x16], 4\n-    __ ld1r(v21, __ T1D, Address(__ post(r23, r16)));  \/\/       ld1r    {v21.1D}, [x23], x16\n-    __ ld2(v7, v8, __ T2D, Address(r26));              \/\/       ld2     {v7.2D, v8.2D}, [x26]\n-    __ ld2(v7, v8, __ T4H, Address(__ post(r25, 16))); \/\/       ld2     {v7.4H, v8.4H}, [x25], 16\n-    __ ld2r(v5, v6, __ T16B, Address(r30));            \/\/       ld2r    {v5.16B, v6.16B}, [x30]\n-    __ ld2r(v29, v30, __ T2S, Address(__ post(r15, 8))); \/\/     ld2r    {v29.2S, v30.2S}, [x15], 8\n-    __ ld2r(v4, v5, __ T2D, Address(__ post(r30, r23))); \/\/     ld2r    {v4.2D, v5.2D}, [x30], x23\n-    __ ld3(v23, v24, v25, __ T4S, Address(__ post(r7, r6))); \/\/ ld3     {v23.4S, v24.4S, v25.4S}, [x7], x6\n-    __ ld3(v21, v22, v23, __ T2S, Address(r4));        \/\/       ld3     {v21.2S, v22.2S, v23.2S}, [x4]\n-    __ ld3r(v9, v10, v11, __ T8H, Address(r4));        \/\/       ld3r    {v9.8H, v10.8H, v11.8H}, [x4]\n-    __ ld3r(v23, v24, v25, __ T4S, Address(__ post(r25, 12))); \/\/       ld3r    {v23.4S, v24.4S, v25.4S}, [x25], 12\n-    __ ld3r(v15, v16, v17, __ T1D, Address(__ post(r26, r5))); \/\/       ld3r    {v15.1D, v16.1D, v17.1D}, [x26], x5\n-    __ ld4(v14, v15, v16, v17, __ T8H, Address(__ post(r25, 64))); \/\/   ld4     {v14.8H, v15.8H, v16.8H, v17.8H}, [x25], 64\n-    __ ld4(v5, v6, v7, v8, __ T8B, Address(__ post(r2, r6))); \/\/        ld4     {v5.8B, v6.8B, v7.8B, v8.8B}, [x2], x6\n-    __ ld4r(v9, v10, v11, v12, __ T8B, Address(r29));  \/\/       ld4r    {v9.8B, v10.8B, v11.8B, v12.8B}, [x29]\n-    __ ld4r(v0, v1, v2, v3, __ T4H, Address(__ post(r25, 8))); \/\/       ld4r    {v0.4H, v1.4H, v2.4H, v3.4H}, [x25], 8\n-    __ ld4r(v15, v16, v17, v18, __ T2S, Address(__ post(r16, r10))); \/\/ ld4r    {v15.2S, v16.2S, v17.2S, v18.2S}, [x16], x10\n+    __ ld1(v12, __ T8B, Address(r1));                  \/\/       ld1     {v12.8B}, [x1]\n+    __ ld1(v0, v1, __ T16B, Address(__ post(r16, 32))); \/\/      ld1     {v0.16B, v1.16B}, [x16], 32\n+    __ ld1(v21, v22, v23, __ T1D, Address(__ post(r25, r19))); \/\/       ld1     {v21.1D, v22.1D, v23.1D}, [x25], x19\n+    __ ld1(v25, v26, v27, v28, __ T8H, Address(__ post(r26, 64))); \/\/   ld1     {v25.8H, v26.8H, v27.8H, v28.8H}, [x26], 64\n+    __ ld1r(v9, __ T8B, Address(r15));                 \/\/       ld1r    {v9.8B}, [x15]\n+    __ ld1r(v12, __ T4S, Address(__ post(r25, 4)));    \/\/       ld1r    {v12.4S}, [x25], 4\n+    __ ld1r(v4, __ T1D, Address(__ post(r14, r29)));   \/\/       ld1r    {v4.1D}, [x14], x29\n+    __ ld2(v17, v18, __ T2D, Address(r17));            \/\/       ld2     {v17.2D, v18.2D}, [x17]\n+    __ ld2(v22, v23, __ T4H, Address(__ post(r27, 16))); \/\/     ld2     {v22.4H, v23.4H}, [x27], 16\n+    __ ld2r(v2, v3, __ T16B, Address(r24));            \/\/       ld2r    {v2.16B, v3.16B}, [x24]\n+    __ ld2r(v10, v11, __ T2S, Address(__ post(r0, 8))); \/\/      ld2r    {v10.2S, v11.2S}, [x0], 8\n+    __ ld2r(v2, v3, __ T2D, Address(__ post(r12, r22))); \/\/     ld2r    {v2.2D, v3.2D}, [x12], x22\n+    __ ld3(v20, v21, v22, __ T4S, Address(__ post(r13, r13))); \/\/       ld3     {v20.4S, v21.4S, v22.4S}, [x13], x13\n+    __ ld3(v12, v13, v14, __ T2S, Address(r11));       \/\/       ld3     {v12.2S, v13.2S, v14.2S}, [x11]\n+    __ ld3r(v17, v18, v19, __ T8H, Address(r14));      \/\/       ld3r    {v17.8H, v18.8H, v19.8H}, [x14]\n+    __ ld3r(v25, v26, v27, __ T4S, Address(__ post(r21, 12))); \/\/       ld3r    {v25.4S, v26.4S, v27.4S}, [x21], 12\n+    __ ld3r(v20, v21, v22, __ T1D, Address(__ post(r16, r27))); \/\/      ld3r    {v20.1D, v21.1D, v22.1D}, [x16], x27\n+    __ ld4(v0, v1, v2, v3, __ T8H, Address(__ post(r1, 64))); \/\/        ld4     {v0.8H, v1.8H, v2.8H, v3.8H}, [x1], 64\n+    __ ld4(v0, v1, v2, v3, __ T8B, Address(__ post(r27, r29))); \/\/      ld4     {v0.8B, v1.8B, v2.8B, v3.8B}, [x27], x29\n+    __ ld4r(v17, v18, v19, v20, __ T8B, Address(r17)); \/\/       ld4r    {v17.8B, v18.8B, v19.8B, v20.8B}, [x17]\n+    __ ld4r(v5, v6, v7, v8, __ T4H, Address(__ post(r24, 8))); \/\/       ld4r    {v5.4H, v6.4H, v7.4H, v8.4H}, [x24], 8\n+    __ ld4r(v27, v28, v29, v30, __ T2S, Address(__ post(r5, r20))); \/\/  ld4r    {v27.2S, v28.2S, v29.2S, v30.2S}, [x5], x20\n@@ -613,26 +616,26 @@\n-    __ addv(v17, __ T8B, v18);                         \/\/       addv    b17, v18.8B\n-    __ addv(v29, __ T16B, v30);                        \/\/       addv    b29, v30.16B\n-    __ addv(v26, __ T4H, v27);                         \/\/       addv    h26, v27.4H\n-    __ addv(v28, __ T8H, v29);                         \/\/       addv    h28, v29.8H\n-    __ addv(v1, __ T4S, v2);                           \/\/       addv    s1, v2.4S\n-    __ smaxv(v27, __ T8B, v28);                        \/\/       smaxv   b27, v28.8B\n-    __ smaxv(v0, __ T16B, v1);                         \/\/       smaxv   b0, v1.16B\n-    __ smaxv(v20, __ T4H, v21);                        \/\/       smaxv   h20, v21.4H\n-    __ smaxv(v28, __ T8H, v29);                        \/\/       smaxv   h28, v29.8H\n-    __ smaxv(v15, __ T4S, v16);                        \/\/       smaxv   s15, v16.4S\n-    __ fmaxv(v12, __ T4S, v13);                        \/\/       fmaxv   s12, v13.4S\n-    __ sminv(v10, __ T8B, v11);                        \/\/       sminv   b10, v11.8B\n-    __ uminv(v28, __ T8B, v29);                        \/\/       uminv   b28, v29.8B\n-    __ sminv(v28, __ T16B, v29);                       \/\/       sminv   b28, v29.16B\n-    __ uminv(v19, __ T16B, v20);                       \/\/       uminv   b19, v20.16B\n-    __ sminv(v22, __ T4H, v23);                        \/\/       sminv   h22, v23.4H\n-    __ uminv(v10, __ T4H, v11);                        \/\/       uminv   h10, v11.4H\n-    __ sminv(v4, __ T8H, v5);                          \/\/       sminv   h4, v5.8H\n-    __ uminv(v30, __ T8H, v31);                        \/\/       uminv   h30, v31.8H\n-    __ sminv(v20, __ T4S, v21);                        \/\/       sminv   s20, v21.4S\n-    __ uminv(v8, __ T4S, v9);                          \/\/       uminv   s8, v9.4S\n-    __ fminv(v30, __ T4S, v31);                        \/\/       fminv   s30, v31.4S\n-    __ fmaxp(v17, v18, __ S);                          \/\/       fmaxp   s17, v18.2S\n-    __ fmaxp(v10, v11, __ D);                          \/\/       fmaxp   d10, v11.2D\n-    __ fminp(v27, v28, __ S);                          \/\/       fminp   s27, v28.2S\n-    __ fminp(v2, v3, __ D);                            \/\/       fminp   d2, v3.2D\n+    __ addv(v0, __ T8B, v1);                           \/\/       addv    b0, v1.8B\n+    __ addv(v20, __ T16B, v21);                        \/\/       addv    b20, v21.16B\n+    __ addv(v28, __ T4H, v29);                         \/\/       addv    h28, v29.4H\n+    __ addv(v15, __ T8H, v16);                         \/\/       addv    h15, v16.8H\n+    __ addv(v12, __ T4S, v13);                         \/\/       addv    s12, v13.4S\n+    __ smaxv(v10, __ T8B, v11);                        \/\/       smaxv   b10, v11.8B\n+    __ smaxv(v28, __ T16B, v29);                       \/\/       smaxv   b28, v29.16B\n+    __ smaxv(v28, __ T4H, v29);                        \/\/       smaxv   h28, v29.4H\n+    __ smaxv(v19, __ T8H, v20);                        \/\/       smaxv   h19, v20.8H\n+    __ smaxv(v22, __ T4S, v23);                        \/\/       smaxv   s22, v23.4S\n+    __ fmaxv(v10, __ T4S, v11);                        \/\/       fmaxv   s10, v11.4S\n+    __ sminv(v4, __ T8B, v5);                          \/\/       sminv   b4, v5.8B\n+    __ uminv(v30, __ T8B, v31);                        \/\/       uminv   b30, v31.8B\n+    __ sminv(v20, __ T16B, v21);                       \/\/       sminv   b20, v21.16B\n+    __ uminv(v8, __ T16B, v9);                         \/\/       uminv   b8, v9.16B\n+    __ sminv(v30, __ T4H, v31);                        \/\/       sminv   h30, v31.4H\n+    __ uminv(v17, __ T4H, v18);                        \/\/       uminv   h17, v18.4H\n+    __ sminv(v10, __ T8H, v11);                        \/\/       sminv   h10, v11.8H\n+    __ uminv(v27, __ T8H, v28);                        \/\/       uminv   h27, v28.8H\n+    __ sminv(v2, __ T4S, v3);                          \/\/       sminv   s2, v3.4S\n+    __ uminv(v24, __ T4S, v25);                        \/\/       uminv   s24, v25.4S\n+    __ fminv(v4, __ T4S, v5);                          \/\/       fminv   s4, v5.4S\n+    __ fmaxp(v3, v4, __ S);                            \/\/       fmaxp   s3, v4.2S\n+    __ fmaxp(v8, v9, __ D);                            \/\/       fmaxp   d8, v9.2D\n+    __ fminp(v22, v23, __ S);                          \/\/       fminp   s22, v23.2S\n+    __ fminp(v17, v18, __ D);                          \/\/       fminp   d17, v18.2D\n@@ -641,1 +644,1 @@\n-    __ fcm(Assembler::GT, v24, __ T2S, v25);           \/\/       fcmgt   v24.2S, v25.2S, #0.0\n+    __ fcm(Assembler::GT, v13, __ T2S, v14);           \/\/       fcmgt   v13.2S, v14.2S, #0.0\n@@ -643,11 +646,11 @@\n-    __ fcm(Assembler::GT, v3, __ T2D, v4);             \/\/       fcmgt   v3.2D, v4.2D, #0.0\n-    __ fcm(Assembler::GE, v8, __ T2S, v9);             \/\/       fcmge   v8.2S, v9.2S, #0.0\n-    __ fcm(Assembler::GE, v22, __ T4S, v23);           \/\/       fcmge   v22.4S, v23.4S, #0.0\n-    __ fcm(Assembler::GE, v17, __ T2D, v18);           \/\/       fcmge   v17.2D, v18.2D, #0.0\n-    __ fcm(Assembler::EQ, v13, __ T2S, v14);           \/\/       fcmeq   v13.2S, v14.2S, #0.0\n-    __ fcm(Assembler::EQ, v4, __ T4S, v5);             \/\/       fcmeq   v4.4S, v5.4S, #0.0\n-    __ fcm(Assembler::EQ, v28, __ T2D, v29);           \/\/       fcmeq   v28.2D, v29.2D, #0.0\n-    __ fcm(Assembler::LT, v23, __ T2S, v24);           \/\/       fcmlt   v23.2S, v24.2S, #0.0\n-    __ fcm(Assembler::LT, v21, __ T4S, v22);           \/\/       fcmlt   v21.4S, v22.4S, #0.0\n-    __ fcm(Assembler::LT, v25, __ T2D, v26);           \/\/       fcmlt   v25.2D, v26.2D, #0.0\n-    __ fcm(Assembler::LE, v24, __ T2S, v25);           \/\/       fcmle   v24.2S, v25.2S, #0.0\n+    __ fcm(Assembler::GT, v28, __ T2D, v29);           \/\/       fcmgt   v28.2D, v29.2D, #0.0\n+    __ fcm(Assembler::GE, v23, __ T2S, v24);           \/\/       fcmge   v23.2S, v24.2S, #0.0\n+    __ fcm(Assembler::GE, v21, __ T4S, v22);           \/\/       fcmge   v21.4S, v22.4S, #0.0\n+    __ fcm(Assembler::GE, v25, __ T2D, v26);           \/\/       fcmge   v25.2D, v26.2D, #0.0\n+    __ fcm(Assembler::EQ, v24, __ T2S, v25);           \/\/       fcmeq   v24.2S, v25.2S, #0.0\n+    __ fcm(Assembler::EQ, v3, __ T4S, v4);             \/\/       fcmeq   v3.4S, v4.4S, #0.0\n+    __ fcm(Assembler::EQ, v23, __ T2D, v24);           \/\/       fcmeq   v23.2D, v24.2D, #0.0\n+    __ fcm(Assembler::LT, v26, __ T2S, v27);           \/\/       fcmlt   v26.2S, v27.2S, #0.0\n+    __ fcm(Assembler::LT, v23, __ T4S, v24);           \/\/       fcmlt   v23.4S, v24.4S, #0.0\n+    __ fcm(Assembler::LT, v14, __ T2D, v15);           \/\/       fcmlt   v14.2D, v15.2D, #0.0\n+    __ fcm(Assembler::LE, v21, __ T2S, v22);           \/\/       fcmle   v21.2S, v22.2S, #0.0\n@@ -658,18 +661,18 @@\n-    __ absr(v26, __ T8B, v27);                         \/\/       abs     v26.8B, v27.8B\n-    __ absr(v23, __ T16B, v24);                        \/\/       abs     v23.16B, v24.16B\n-    __ absr(v14, __ T4H, v15);                         \/\/       abs     v14.4H, v15.4H\n-    __ absr(v21, __ T8H, v22);                         \/\/       abs     v21.8H, v22.8H\n-    __ absr(v3, __ T2S, v4);                           \/\/       abs     v3.2S, v4.2S\n-    __ absr(v23, __ T4S, v24);                         \/\/       abs     v23.4S, v24.4S\n-    __ absr(v8, __ T2D, v9);                           \/\/       abs     v8.2D, v9.2D\n-    __ fabs(v24, __ T2S, v25);                         \/\/       fabs    v24.2S, v25.2S\n-    __ fabs(v19, __ T4S, v20);                         \/\/       fabs    v19.4S, v20.4S\n-    __ fabs(v15, __ T2D, v16);                         \/\/       fabs    v15.2D, v16.2D\n-    __ fneg(v16, __ T2S, v17);                         \/\/       fneg    v16.2S, v17.2S\n-    __ fneg(v2, __ T4S, v3);                           \/\/       fneg    v2.4S, v3.4S\n-    __ fneg(v1, __ T2D, v2);                           \/\/       fneg    v1.2D, v2.2D\n-    __ fsqrt(v0, __ T2S, v1);                          \/\/       fsqrt   v0.2S, v1.2S\n-    __ fsqrt(v24, __ T4S, v25);                        \/\/       fsqrt   v24.4S, v25.4S\n-    __ fsqrt(v4, __ T2D, v5);                          \/\/       fsqrt   v4.2D, v5.2D\n-    __ notr(v3, __ T8B, v4);                           \/\/       not     v3.8B, v4.8B\n-    __ notr(v11, __ T16B, v12);                        \/\/       not     v11.16B, v12.16B\n+    __ absr(v8, __ T8B, v9);                           \/\/       abs     v8.8B, v9.8B\n+    __ absr(v24, __ T16B, v25);                        \/\/       abs     v24.16B, v25.16B\n+    __ absr(v19, __ T4H, v20);                         \/\/       abs     v19.4H, v20.4H\n+    __ absr(v15, __ T8H, v16);                         \/\/       abs     v15.8H, v16.8H\n+    __ absr(v16, __ T2S, v17);                         \/\/       abs     v16.2S, v17.2S\n+    __ absr(v2, __ T4S, v3);                           \/\/       abs     v2.4S, v3.4S\n+    __ absr(v1, __ T2D, v2);                           \/\/       abs     v1.2D, v2.2D\n+    __ fabs(v0, __ T2S, v1);                           \/\/       fabs    v0.2S, v1.2S\n+    __ fabs(v24, __ T4S, v25);                         \/\/       fabs    v24.4S, v25.4S\n+    __ fabs(v4, __ T2D, v5);                           \/\/       fabs    v4.2D, v5.2D\n+    __ fneg(v3, __ T2S, v4);                           \/\/       fneg    v3.2S, v4.2S\n+    __ fneg(v11, __ T4S, v12);                         \/\/       fneg    v11.4S, v12.4S\n+    __ fneg(v30, __ T2D, v31);                         \/\/       fneg    v30.2D, v31.2D\n+    __ fsqrt(v27, __ T2S, v28);                        \/\/       fsqrt   v27.2S, v28.2S\n+    __ fsqrt(v9, __ T4S, v10);                         \/\/       fsqrt   v9.4S, v10.4S\n+    __ fsqrt(v25, __ T2D, v26);                        \/\/       fsqrt   v25.2D, v26.2D\n+    __ notr(v2, __ T8B, v3);                           \/\/       not     v2.8B, v3.8B\n+    __ notr(v12, __ T16B, v13);                        \/\/       not     v12.16B, v13.16B\n@@ -678,6 +681,6 @@\n-    __ andr(v30, __ T8B, v31, v0);                     \/\/       and     v30.8B, v31.8B, v0.8B\n-    __ andr(v27, __ T16B, v28, v29);                   \/\/       and     v27.16B, v28.16B, v29.16B\n-    __ orr(v9, __ T8B, v10, v11);                      \/\/       orr     v9.8B, v10.8B, v11.8B\n-    __ orr(v25, __ T16B, v26, v27);                    \/\/       orr     v25.16B, v26.16B, v27.16B\n-    __ eor(v2, __ T8B, v3, v4);                        \/\/       eor     v2.8B, v3.8B, v4.8B\n-    __ eor(v12, __ T16B, v13, v14);                    \/\/       eor     v12.16B, v13.16B, v14.16B\n+    __ andr(v17, __ T8B, v18, v19);                    \/\/       and     v17.8B, v18.8B, v19.8B\n+    __ andr(v30, __ T16B, v31, v0);                    \/\/       and     v30.16B, v31.16B, v0.16B\n+    __ orr(v1, __ T8B, v2, v3);                        \/\/       orr     v1.8B, v2.8B, v3.8B\n+    __ orr(v12, __ T16B, v13, v14);                    \/\/       orr     v12.16B, v13.16B, v14.16B\n+    __ eor(v28, __ T8B, v29, v30);                     \/\/       eor     v28.8B, v29.8B, v30.8B\n+    __ eor(v0, __ T16B, v1, v2);                       \/\/       eor     v0.16B, v1.16B, v2.16B\n@@ -685,11 +688,11 @@\n-    __ addv(v30, __ T16B, v31, v0);                    \/\/       add     v30.16B, v31.16B, v0.16B\n-    __ addv(v1, __ T4H, v2, v3);                       \/\/       add     v1.4H, v2.4H, v3.4H\n-    __ addv(v12, __ T8H, v13, v14);                    \/\/       add     v12.8H, v13.8H, v14.8H\n-    __ addv(v28, __ T2S, v29, v30);                    \/\/       add     v28.2S, v29.2S, v30.2S\n-    __ addv(v0, __ T4S, v1, v2);                       \/\/       add     v0.4S, v1.4S, v2.4S\n-    __ addv(v17, __ T2D, v18, v19);                    \/\/       add     v17.2D, v18.2D, v19.2D\n-    __ fadd(v12, __ T2S, v13, v14);                    \/\/       fadd    v12.2S, v13.2S, v14.2S\n-    __ fadd(v17, __ T4S, v18, v19);                    \/\/       fadd    v17.4S, v18.4S, v19.4S\n-    __ fadd(v21, __ T2D, v22, v23);                    \/\/       fadd    v21.2D, v22.2D, v23.2D\n-    __ subv(v12, __ T8B, v13, v14);                    \/\/       sub     v12.8B, v13.8B, v14.8B\n-    __ subv(v27, __ T16B, v28, v29);                   \/\/       sub     v27.16B, v28.16B, v29.16B\n+    __ addv(v12, __ T16B, v13, v14);                   \/\/       add     v12.16B, v13.16B, v14.16B\n+    __ addv(v17, __ T4H, v18, v19);                    \/\/       add     v17.4H, v18.4H, v19.4H\n+    __ addv(v21, __ T8H, v22, v23);                    \/\/       add     v21.8H, v22.8H, v23.8H\n+    __ addv(v12, __ T2S, v13, v14);                    \/\/       add     v12.2S, v13.2S, v14.2S\n+    __ addv(v27, __ T4S, v28, v29);                    \/\/       add     v27.4S, v28.4S, v29.4S\n+    __ addv(v29, __ T2D, v30, v31);                    \/\/       add     v29.2D, v30.2D, v31.2D\n+    __ fadd(v30, __ T2S, v31, v0);                     \/\/       fadd    v30.2S, v31.2S, v0.2S\n+    __ fadd(v1, __ T4S, v2, v3);                       \/\/       fadd    v1.4S, v2.4S, v3.4S\n+    __ fadd(v25, __ T2D, v26, v27);                    \/\/       fadd    v25.2D, v26.2D, v27.2D\n+    __ subv(v27, __ T8B, v28, v29);                    \/\/       sub     v27.8B, v28.8B, v29.8B\n+    __ subv(v4, __ T16B, v5, v6);                      \/\/       sub     v4.16B, v5.16B, v6.16B\n@@ -697,28 +700,28 @@\n-    __ subv(v30, __ T8H, v31, v0);                     \/\/       sub     v30.8H, v31.8H, v0.8H\n-    __ subv(v1, __ T2S, v2, v3);                       \/\/       sub     v1.2S, v2.2S, v3.2S\n-    __ subv(v25, __ T4S, v26, v27);                    \/\/       sub     v25.4S, v26.4S, v27.4S\n-    __ subv(v27, __ T2D, v28, v29);                    \/\/       sub     v27.2D, v28.2D, v29.2D\n-    __ fsub(v4, __ T2S, v5, v6);                       \/\/       fsub    v4.2S, v5.2S, v6.2S\n-    __ fsub(v29, __ T4S, v30, v31);                    \/\/       fsub    v29.4S, v30.4S, v31.4S\n-    __ fsub(v3, __ T2D, v4, v5);                       \/\/       fsub    v3.2D, v4.2D, v5.2D\n-    __ mulv(v6, __ T8B, v7, v8);                       \/\/       mul     v6.8B, v7.8B, v8.8B\n-    __ mulv(v29, __ T16B, v30, v31);                   \/\/       mul     v29.16B, v30.16B, v31.16B\n-    __ mulv(v25, __ T4H, v26, v27);                    \/\/       mul     v25.4H, v26.4H, v27.4H\n-    __ mulv(v17, __ T8H, v18, v19);                    \/\/       mul     v17.8H, v18.8H, v19.8H\n-    __ mulv(v8, __ T2S, v9, v10);                      \/\/       mul     v8.2S, v9.2S, v10.2S\n-    __ mulv(v7, __ T4S, v8, v9);                       \/\/       mul     v7.4S, v8.4S, v9.4S\n-    __ fabd(v12, __ T2S, v13, v14);                    \/\/       fabd    v12.2S, v13.2S, v14.2S\n-    __ fabd(v0, __ T4S, v1, v2);                       \/\/       fabd    v0.4S, v1.4S, v2.4S\n-    __ fabd(v19, __ T2D, v20, v21);                    \/\/       fabd    v19.2D, v20.2D, v21.2D\n-    __ faddp(v1, __ T2S, v2, v3);                      \/\/       faddp   v1.2S, v2.2S, v3.2S\n-    __ faddp(v23, __ T4S, v24, v25);                   \/\/       faddp   v23.4S, v24.4S, v25.4S\n-    __ faddp(v2, __ T2D, v3, v4);                      \/\/       faddp   v2.2D, v3.2D, v4.2D\n-    __ fmul(v0, __ T2S, v1, v2);                       \/\/       fmul    v0.2S, v1.2S, v2.2S\n-    __ fmul(v8, __ T4S, v9, v10);                      \/\/       fmul    v8.4S, v9.4S, v10.4S\n-    __ fmul(v23, __ T2D, v24, v25);                    \/\/       fmul    v23.2D, v24.2D, v25.2D\n-    __ mlav(v25, __ T4H, v26, v27);                    \/\/       mla     v25.4H, v26.4H, v27.4H\n-    __ mlav(v15, __ T8H, v16, v17);                    \/\/       mla     v15.8H, v16.8H, v17.8H\n-    __ mlav(v29, __ T2S, v30, v31);                    \/\/       mla     v29.2S, v30.2S, v31.2S\n-    __ mlav(v3, __ T4S, v4, v5);                       \/\/       mla     v3.4S, v4.4S, v5.4S\n-    __ fmla(v10, __ T2S, v11, v12);                    \/\/       fmla    v10.2S, v11.2S, v12.2S\n-    __ fmla(v22, __ T4S, v23, v24);                    \/\/       fmla    v22.4S, v23.4S, v24.4S\n+    __ subv(v3, __ T8H, v4, v5);                       \/\/       sub     v3.8H, v4.8H, v5.8H\n+    __ subv(v6, __ T2S, v7, v8);                       \/\/       sub     v6.2S, v7.2S, v8.2S\n+    __ subv(v29, __ T4S, v30, v31);                    \/\/       sub     v29.4S, v30.4S, v31.4S\n+    __ subv(v25, __ T2D, v26, v27);                    \/\/       sub     v25.2D, v26.2D, v27.2D\n+    __ fsub(v17, __ T2S, v18, v19);                    \/\/       fsub    v17.2S, v18.2S, v19.2S\n+    __ fsub(v8, __ T4S, v9, v10);                      \/\/       fsub    v8.4S, v9.4S, v10.4S\n+    __ fsub(v7, __ T2D, v8, v9);                       \/\/       fsub    v7.2D, v8.2D, v9.2D\n+    __ mulv(v12, __ T8B, v13, v14);                    \/\/       mul     v12.8B, v13.8B, v14.8B\n+    __ mulv(v0, __ T16B, v1, v2);                      \/\/       mul     v0.16B, v1.16B, v2.16B\n+    __ mulv(v19, __ T4H, v20, v21);                    \/\/       mul     v19.4H, v20.4H, v21.4H\n+    __ mulv(v1, __ T8H, v2, v3);                       \/\/       mul     v1.8H, v2.8H, v3.8H\n+    __ mulv(v23, __ T2S, v24, v25);                    \/\/       mul     v23.2S, v24.2S, v25.2S\n+    __ mulv(v2, __ T4S, v3, v4);                       \/\/       mul     v2.4S, v3.4S, v4.4S\n+    __ fabd(v0, __ T2S, v1, v2);                       \/\/       fabd    v0.2S, v1.2S, v2.2S\n+    __ fabd(v8, __ T4S, v9, v10);                      \/\/       fabd    v8.4S, v9.4S, v10.4S\n+    __ fabd(v23, __ T2D, v24, v25);                    \/\/       fabd    v23.2D, v24.2D, v25.2D\n+    __ faddp(v25, __ T2S, v26, v27);                   \/\/       faddp   v25.2S, v26.2S, v27.2S\n+    __ faddp(v15, __ T4S, v16, v17);                   \/\/       faddp   v15.4S, v16.4S, v17.4S\n+    __ faddp(v29, __ T2D, v30, v31);                   \/\/       faddp   v29.2D, v30.2D, v31.2D\n+    __ fmul(v3, __ T2S, v4, v5);                       \/\/       fmul    v3.2S, v4.2S, v5.2S\n+    __ fmul(v10, __ T4S, v11, v12);                    \/\/       fmul    v10.4S, v11.4S, v12.4S\n+    __ fmul(v22, __ T2D, v23, v24);                    \/\/       fmul    v22.2D, v23.2D, v24.2D\n+    __ mlav(v10, __ T4H, v11, v12);                    \/\/       mla     v10.4H, v11.4H, v12.4H\n+    __ mlav(v4, __ T8H, v5, v6);                       \/\/       mla     v4.8H, v5.8H, v6.8H\n+    __ mlav(v17, __ T2S, v18, v19);                    \/\/       mla     v17.2S, v18.2S, v19.2S\n+    __ mlav(v1, __ T4S, v2, v3);                       \/\/       mla     v1.4S, v2.4S, v3.4S\n+    __ fmla(v11, __ T2S, v12, v13);                    \/\/       fmla    v11.2S, v12.2S, v13.2S\n+    __ fmla(v7, __ T4S, v8, v9);                       \/\/       fmla    v7.4S, v8.4S, v9.4S\n@@ -726,8 +729,8 @@\n-    __ mlsv(v4, __ T4H, v5, v6);                       \/\/       mls     v4.4H, v5.4H, v6.4H\n-    __ mlsv(v17, __ T8H, v18, v19);                    \/\/       mls     v17.8H, v18.8H, v19.8H\n-    __ mlsv(v1, __ T2S, v2, v3);                       \/\/       mls     v1.2S, v2.2S, v3.2S\n-    __ mlsv(v11, __ T4S, v12, v13);                    \/\/       mls     v11.4S, v12.4S, v13.4S\n-    __ fmls(v7, __ T2S, v8, v9);                       \/\/       fmls    v7.2S, v8.2S, v9.2S\n-    __ fmls(v10, __ T4S, v11, v12);                    \/\/       fmls    v10.4S, v11.4S, v12.4S\n-    __ fmls(v15, __ T2D, v16, v17);                    \/\/       fmls    v15.2D, v16.2D, v17.2D\n-    __ fdiv(v16, __ T2S, v17, v18);                    \/\/       fdiv    v16.2S, v17.2S, v18.2S\n+    __ mlsv(v15, __ T4H, v16, v17);                    \/\/       mls     v15.4H, v16.4H, v17.4H\n+    __ mlsv(v16, __ T8H, v17, v18);                    \/\/       mls     v16.8H, v17.8H, v18.8H\n+    __ mlsv(v2, __ T2S, v3, v4);                       \/\/       mls     v2.2S, v3.2S, v4.2S\n+    __ mlsv(v9, __ T4S, v10, v11);                     \/\/       mls     v9.4S, v10.4S, v11.4S\n+    __ fmls(v11, __ T2S, v12, v13);                    \/\/       fmls    v11.2S, v12.2S, v13.2S\n+    __ fmls(v12, __ T4S, v13, v14);                    \/\/       fmls    v12.4S, v13.4S, v14.4S\n+    __ fmls(v14, __ T2D, v15, v16);                    \/\/       fmls    v14.2D, v15.2D, v16.2D\n+    __ fdiv(v13, __ T2S, v14, v15);                    \/\/       fdiv    v13.2S, v14.2S, v15.2S\n@@ -735,5 +738,5 @@\n-    __ fdiv(v9, __ T2D, v10, v11);                     \/\/       fdiv    v9.2D, v10.2D, v11.2D\n-    __ maxv(v11, __ T8B, v12, v13);                    \/\/       smax    v11.8B, v12.8B, v13.8B\n-    __ maxv(v12, __ T16B, v13, v14);                   \/\/       smax    v12.16B, v13.16B, v14.16B\n-    __ maxv(v14, __ T4H, v15, v16);                    \/\/       smax    v14.4H, v15.4H, v16.4H\n-    __ maxv(v13, __ T8H, v14, v15);                    \/\/       smax    v13.8H, v14.8H, v15.8H\n+    __ fdiv(v6, __ T2D, v7, v8);                       \/\/       fdiv    v6.2D, v7.2D, v8.2D\n+    __ maxv(v19, __ T8B, v20, v21);                    \/\/       smax    v19.8B, v20.8B, v21.8B\n+    __ maxv(v25, __ T16B, v26, v27);                   \/\/       smax    v25.16B, v26.16B, v27.16B\n+    __ maxv(v15, __ T4H, v16, v17);                    \/\/       smax    v15.4H, v16.4H, v17.4H\n+    __ maxv(v4, __ T8H, v5, v6);                       \/\/       smax    v4.8H, v5.8H, v6.8H\n@@ -741,28 +744,28 @@\n-    __ maxv(v6, __ T4S, v7, v8);                       \/\/       smax    v6.4S, v7.4S, v8.4S\n-    __ smaxp(v19, __ T8B, v20, v21);                   \/\/       smaxp   v19.8B, v20.8B, v21.8B\n-    __ smaxp(v25, __ T16B, v26, v27);                  \/\/       smaxp   v25.16B, v26.16B, v27.16B\n-    __ smaxp(v15, __ T4H, v16, v17);                   \/\/       smaxp   v15.4H, v16.4H, v17.4H\n-    __ smaxp(v4, __ T8H, v5, v6);                      \/\/       smaxp   v4.8H, v5.8H, v6.8H\n-    __ smaxp(v2, __ T2S, v3, v4);                      \/\/       smaxp   v2.2S, v3.2S, v4.2S\n-    __ smaxp(v4, __ T4S, v5, v6);                      \/\/       smaxp   v4.4S, v5.4S, v6.4S\n-    __ fmax(v11, __ T2S, v12, v13);                    \/\/       fmax    v11.2S, v12.2S, v13.2S\n-    __ fmax(v17, __ T4S, v18, v19);                    \/\/       fmax    v17.4S, v18.4S, v19.4S\n-    __ fmax(v20, __ T2D, v21, v22);                    \/\/       fmax    v20.2D, v21.2D, v22.2D\n-    __ minv(v16, __ T8B, v17, v18);                    \/\/       smin    v16.8B, v17.8B, v18.8B\n-    __ minv(v17, __ T16B, v18, v19);                   \/\/       smin    v17.16B, v18.16B, v19.16B\n-    __ minv(v10, __ T4H, v11, v12);                    \/\/       smin    v10.4H, v11.4H, v12.4H\n-    __ minv(v20, __ T8H, v21, v22);                    \/\/       smin    v20.8H, v21.8H, v22.8H\n-    __ minv(v22, __ T2S, v23, v24);                    \/\/       smin    v22.2S, v23.2S, v24.2S\n-    __ minv(v12, __ T4S, v13, v14);                    \/\/       smin    v12.4S, v13.4S, v14.4S\n-    __ sminp(v25, __ T8B, v26, v27);                   \/\/       sminp   v25.8B, v26.8B, v27.8B\n-    __ sminp(v23, __ T16B, v24, v25);                  \/\/       sminp   v23.16B, v24.16B, v25.16B\n-    __ sminp(v28, __ T4H, v29, v30);                   \/\/       sminp   v28.4H, v29.4H, v30.4H\n-    __ sminp(v14, __ T8H, v15, v16);                   \/\/       sminp   v14.8H, v15.8H, v16.8H\n-    __ sminp(v10, __ T2S, v11, v12);                   \/\/       sminp   v10.2S, v11.2S, v12.2S\n-    __ sminp(v24, __ T4S, v25, v26);                   \/\/       sminp   v24.4S, v25.4S, v26.4S\n-    __ fmin(v1, __ T2S, v2, v3);                       \/\/       fmin    v1.2S, v2.2S, v3.2S\n-    __ fmin(v11, __ T4S, v12, v13);                    \/\/       fmin    v11.4S, v12.4S, v13.4S\n-    __ fmin(v30, __ T2D, v31, v0);                     \/\/       fmin    v30.2D, v31.2D, v0.2D\n-    __ facgt(v10, __ T2S, v11, v12);                   \/\/       facgt   v10.2S, v11.2S, v12.2S\n-    __ facgt(v15, __ T4S, v16, v17);                   \/\/       facgt   v15.4S, v16.4S, v17.4S\n-    __ facgt(v7, __ T2D, v8, v9);                      \/\/       facgt   v7.2D, v8.2D, v9.2D\n+    __ maxv(v4, __ T4S, v5, v6);                       \/\/       smax    v4.4S, v5.4S, v6.4S\n+    __ smaxp(v11, __ T8B, v12, v13);                   \/\/       smaxp   v11.8B, v12.8B, v13.8B\n+    __ smaxp(v17, __ T16B, v18, v19);                  \/\/       smaxp   v17.16B, v18.16B, v19.16B\n+    __ smaxp(v20, __ T4H, v21, v22);                   \/\/       smaxp   v20.4H, v21.4H, v22.4H\n+    __ smaxp(v16, __ T8H, v17, v18);                   \/\/       smaxp   v16.8H, v17.8H, v18.8H\n+    __ smaxp(v17, __ T2S, v18, v19);                   \/\/       smaxp   v17.2S, v18.2S, v19.2S\n+    __ smaxp(v10, __ T4S, v11, v12);                   \/\/       smaxp   v10.4S, v11.4S, v12.4S\n+    __ fmax(v20, __ T2S, v21, v22);                    \/\/       fmax    v20.2S, v21.2S, v22.2S\n+    __ fmax(v22, __ T4S, v23, v24);                    \/\/       fmax    v22.4S, v23.4S, v24.4S\n+    __ fmax(v12, __ T2D, v13, v14);                    \/\/       fmax    v12.2D, v13.2D, v14.2D\n+    __ minv(v25, __ T8B, v26, v27);                    \/\/       smin    v25.8B, v26.8B, v27.8B\n+    __ minv(v23, __ T16B, v24, v25);                   \/\/       smin    v23.16B, v24.16B, v25.16B\n+    __ minv(v28, __ T4H, v29, v30);                    \/\/       smin    v28.4H, v29.4H, v30.4H\n+    __ minv(v14, __ T8H, v15, v16);                    \/\/       smin    v14.8H, v15.8H, v16.8H\n+    __ minv(v10, __ T2S, v11, v12);                    \/\/       smin    v10.2S, v11.2S, v12.2S\n+    __ minv(v24, __ T4S, v25, v26);                    \/\/       smin    v24.4S, v25.4S, v26.4S\n+    __ sminp(v1, __ T8B, v2, v3);                      \/\/       sminp   v1.8B, v2.8B, v3.8B\n+    __ sminp(v11, __ T16B, v12, v13);                  \/\/       sminp   v11.16B, v12.16B, v13.16B\n+    __ sminp(v30, __ T4H, v31, v0);                    \/\/       sminp   v30.4H, v31.4H, v0.4H\n+    __ sminp(v10, __ T8H, v11, v12);                   \/\/       sminp   v10.8H, v11.8H, v12.8H\n+    __ sminp(v15, __ T2S, v16, v17);                   \/\/       sminp   v15.2S, v16.2S, v17.2S\n+    __ sminp(v7, __ T4S, v8, v9);                      \/\/       sminp   v7.4S, v8.4S, v9.4S\n+    __ fmin(v2, __ T2S, v3, v4);                       \/\/       fmin    v2.2S, v3.2S, v4.2S\n+    __ fmin(v3, __ T4S, v4, v5);                       \/\/       fmin    v3.4S, v4.4S, v5.4S\n+    __ fmin(v13, __ T2D, v14, v15);                    \/\/       fmin    v13.2D, v14.2D, v15.2D\n+    __ facgt(v19, __ T2S, v20, v21);                   \/\/       facgt   v19.2S, v20.2S, v21.2S\n+    __ facgt(v16, __ T4S, v17, v18);                   \/\/       facgt   v16.4S, v17.4S, v18.4S\n+    __ facgt(v16, __ T2D, v17, v18);                   \/\/       facgt   v16.2D, v17.2D, v18.2D\n@@ -771,36 +774,36 @@\n-    __ cm(Assembler::GT, v2, __ T8B, v3, v4);          \/\/       cmgt    v2.8B, v3.8B, v4.8B\n-    __ cm(Assembler::GT, v3, __ T16B, v4, v5);         \/\/       cmgt    v3.16B, v4.16B, v5.16B\n-    __ cm(Assembler::GT, v13, __ T4H, v14, v15);       \/\/       cmgt    v13.4H, v14.4H, v15.4H\n-    __ cm(Assembler::GT, v19, __ T8H, v20, v21);       \/\/       cmgt    v19.8H, v20.8H, v21.8H\n-    __ cm(Assembler::GT, v16, __ T2S, v17, v18);       \/\/       cmgt    v16.2S, v17.2S, v18.2S\n-    __ cm(Assembler::GT, v16, __ T4S, v17, v18);       \/\/       cmgt    v16.4S, v17.4S, v18.4S\n-    __ cm(Assembler::GT, v3, __ T2D, v4, v5);          \/\/       cmgt    v3.2D, v4.2D, v5.2D\n-    __ cm(Assembler::GE, v1, __ T8B, v2, v3);          \/\/       cmge    v1.8B, v2.8B, v3.8B\n-    __ cm(Assembler::GE, v11, __ T16B, v12, v13);      \/\/       cmge    v11.16B, v12.16B, v13.16B\n-    __ cm(Assembler::GE, v29, __ T4H, v30, v31);       \/\/       cmge    v29.4H, v30.4H, v31.4H\n-    __ cm(Assembler::GE, v5, __ T8H, v6, v7);          \/\/       cmge    v5.8H, v6.8H, v7.8H\n-    __ cm(Assembler::GE, v8, __ T2S, v9, v10);         \/\/       cmge    v8.2S, v9.2S, v10.2S\n-    __ cm(Assembler::GE, v14, __ T4S, v15, v16);       \/\/       cmge    v14.4S, v15.4S, v16.4S\n-    __ cm(Assembler::GE, v28, __ T2D, v29, v30);       \/\/       cmge    v28.2D, v29.2D, v30.2D\n-    __ cm(Assembler::EQ, v29, __ T8B, v30, v31);       \/\/       cmeq    v29.8B, v30.8B, v31.8B\n-    __ cm(Assembler::EQ, v0, __ T16B, v1, v2);         \/\/       cmeq    v0.16B, v1.16B, v2.16B\n-    __ cm(Assembler::EQ, v20, __ T4H, v21, v22);       \/\/       cmeq    v20.4H, v21.4H, v22.4H\n-    __ cm(Assembler::EQ, v7, __ T8H, v8, v9);          \/\/       cmeq    v7.8H, v8.8H, v9.8H\n-    __ cm(Assembler::EQ, v20, __ T2S, v21, v22);       \/\/       cmeq    v20.2S, v21.2S, v22.2S\n-    __ cm(Assembler::EQ, v23, __ T4S, v24, v25);       \/\/       cmeq    v23.4S, v24.4S, v25.4S\n-    __ cm(Assembler::EQ, v27, __ T2D, v28, v29);       \/\/       cmeq    v27.2D, v28.2D, v29.2D\n-    __ cm(Assembler::HI, v21, __ T8B, v22, v23);       \/\/       cmhi    v21.8B, v22.8B, v23.8B\n-    __ cm(Assembler::HI, v26, __ T16B, v27, v28);      \/\/       cmhi    v26.16B, v27.16B, v28.16B\n-    __ cm(Assembler::HI, v24, __ T4H, v25, v26);       \/\/       cmhi    v24.4H, v25.4H, v26.4H\n-    __ cm(Assembler::HI, v4, __ T8H, v5, v6);          \/\/       cmhi    v4.8H, v5.8H, v6.8H\n-    __ cm(Assembler::HI, v1, __ T2S, v2, v3);          \/\/       cmhi    v1.2S, v2.2S, v3.2S\n-    __ cm(Assembler::HI, v22, __ T4S, v23, v24);       \/\/       cmhi    v22.4S, v23.4S, v24.4S\n-    __ cm(Assembler::HI, v16, __ T2D, v17, v18);       \/\/       cmhi    v16.2D, v17.2D, v18.2D\n-    __ cm(Assembler::HS, v30, __ T8B, v31, v0);        \/\/       cmhs    v30.8B, v31.8B, v0.8B\n-    __ cm(Assembler::HS, v5, __ T16B, v6, v7);         \/\/       cmhs    v5.16B, v6.16B, v7.16B\n-    __ cm(Assembler::HS, v11, __ T4H, v12, v13);       \/\/       cmhs    v11.4H, v12.4H, v13.4H\n-    __ cm(Assembler::HS, v8, __ T8H, v9, v10);         \/\/       cmhs    v8.8H, v9.8H, v10.8H\n-    __ cm(Assembler::HS, v27, __ T2S, v28, v29);       \/\/       cmhs    v27.2S, v28.2S, v29.2S\n-    __ cm(Assembler::HS, v14, __ T4S, v15, v16);       \/\/       cmhs    v14.4S, v15.4S, v16.4S\n-    __ cm(Assembler::HS, v28, __ T2D, v29, v30);       \/\/       cmhs    v28.2D, v29.2D, v30.2D\n-    __ fcm(Assembler::EQ, v21, __ T2S, v22, v23);      \/\/       fcmeq   v21.2S, v22.2S, v23.2S\n+    __ cm(Assembler::GT, v3, __ T8B, v4, v5);          \/\/       cmgt    v3.8B, v4.8B, v5.8B\n+    __ cm(Assembler::GT, v1, __ T16B, v2, v3);         \/\/       cmgt    v1.16B, v2.16B, v3.16B\n+    __ cm(Assembler::GT, v11, __ T4H, v12, v13);       \/\/       cmgt    v11.4H, v12.4H, v13.4H\n+    __ cm(Assembler::GT, v29, __ T8H, v30, v31);       \/\/       cmgt    v29.8H, v30.8H, v31.8H\n+    __ cm(Assembler::GT, v5, __ T2S, v6, v7);          \/\/       cmgt    v5.2S, v6.2S, v7.2S\n+    __ cm(Assembler::GT, v8, __ T4S, v9, v10);         \/\/       cmgt    v8.4S, v9.4S, v10.4S\n+    __ cm(Assembler::GT, v14, __ T2D, v15, v16);       \/\/       cmgt    v14.2D, v15.2D, v16.2D\n+    __ cm(Assembler::GE, v28, __ T8B, v29, v30);       \/\/       cmge    v28.8B, v29.8B, v30.8B\n+    __ cm(Assembler::GE, v29, __ T16B, v30, v31);      \/\/       cmge    v29.16B, v30.16B, v31.16B\n+    __ cm(Assembler::GE, v0, __ T4H, v1, v2);          \/\/       cmge    v0.4H, v1.4H, v2.4H\n+    __ cm(Assembler::GE, v20, __ T8H, v21, v22);       \/\/       cmge    v20.8H, v21.8H, v22.8H\n+    __ cm(Assembler::GE, v7, __ T2S, v8, v9);          \/\/       cmge    v7.2S, v8.2S, v9.2S\n+    __ cm(Assembler::GE, v20, __ T4S, v21, v22);       \/\/       cmge    v20.4S, v21.4S, v22.4S\n+    __ cm(Assembler::GE, v23, __ T2D, v24, v25);       \/\/       cmge    v23.2D, v24.2D, v25.2D\n+    __ cm(Assembler::EQ, v27, __ T8B, v28, v29);       \/\/       cmeq    v27.8B, v28.8B, v29.8B\n+    __ cm(Assembler::EQ, v21, __ T16B, v22, v23);      \/\/       cmeq    v21.16B, v22.16B, v23.16B\n+    __ cm(Assembler::EQ, v26, __ T4H, v27, v28);       \/\/       cmeq    v26.4H, v27.4H, v28.4H\n+    __ cm(Assembler::EQ, v24, __ T8H, v25, v26);       \/\/       cmeq    v24.8H, v25.8H, v26.8H\n+    __ cm(Assembler::EQ, v4, __ T2S, v5, v6);          \/\/       cmeq    v4.2S, v5.2S, v6.2S\n+    __ cm(Assembler::EQ, v1, __ T4S, v2, v3);          \/\/       cmeq    v1.4S, v2.4S, v3.4S\n+    __ cm(Assembler::EQ, v22, __ T2D, v23, v24);       \/\/       cmeq    v22.2D, v23.2D, v24.2D\n+    __ cm(Assembler::HI, v16, __ T8B, v17, v18);       \/\/       cmhi    v16.8B, v17.8B, v18.8B\n+    __ cm(Assembler::HI, v30, __ T16B, v31, v0);       \/\/       cmhi    v30.16B, v31.16B, v0.16B\n+    __ cm(Assembler::HI, v5, __ T4H, v6, v7);          \/\/       cmhi    v5.4H, v6.4H, v7.4H\n+    __ cm(Assembler::HI, v11, __ T8H, v12, v13);       \/\/       cmhi    v11.8H, v12.8H, v13.8H\n+    __ cm(Assembler::HI, v8, __ T2S, v9, v10);         \/\/       cmhi    v8.2S, v9.2S, v10.2S\n+    __ cm(Assembler::HI, v27, __ T4S, v28, v29);       \/\/       cmhi    v27.4S, v28.4S, v29.4S\n+    __ cm(Assembler::HI, v14, __ T2D, v15, v16);       \/\/       cmhi    v14.2D, v15.2D, v16.2D\n+    __ cm(Assembler::HS, v28, __ T8B, v29, v30);       \/\/       cmhs    v28.8B, v29.8B, v30.8B\n+    __ cm(Assembler::HS, v21, __ T16B, v22, v23);      \/\/       cmhs    v21.16B, v22.16B, v23.16B\n+    __ cm(Assembler::HS, v30, __ T4H, v31, v0);        \/\/       cmhs    v30.4H, v31.4H, v0.4H\n+    __ cm(Assembler::HS, v17, __ T8H, v18, v19);       \/\/       cmhs    v17.8H, v18.8H, v19.8H\n+    __ cm(Assembler::HS, v30, __ T2S, v31, v0);        \/\/       cmhs    v30.2S, v31.2S, v0.2S\n+    __ cm(Assembler::HS, v5, __ T4S, v6, v7);          \/\/       cmhs    v5.4S, v6.4S, v7.4S\n+    __ cm(Assembler::HS, v13, __ T2D, v14, v15);       \/\/       cmhs    v13.2D, v14.2D, v15.2D\n+    __ fcm(Assembler::EQ, v17, __ T2S, v18, v19);      \/\/       fcmeq   v17.2S, v18.2S, v19.2S\n@@ -809,6 +812,6 @@\n-    __ fcm(Assembler::GT, v30, __ T2S, v31, v0);       \/\/       fcmgt   v30.2S, v31.2S, v0.2S\n-    __ fcm(Assembler::GT, v5, __ T4S, v6, v7);         \/\/       fcmgt   v5.4S, v6.4S, v7.4S\n-    __ fcm(Assembler::GT, v13, __ T2D, v14, v15);      \/\/       fcmgt   v13.2D, v14.2D, v15.2D\n-    __ fcm(Assembler::GE, v17, __ T2S, v18, v19);      \/\/       fcmge   v17.2S, v18.2S, v19.2S\n-    __ fcm(Assembler::GE, v30, __ T4S, v31, v0);       \/\/       fcmge   v30.4S, v31.4S, v0.4S\n-    __ fcm(Assembler::GE, v17, __ T2D, v18, v19);      \/\/       fcmge   v17.2D, v18.2D, v19.2D\n+    __ fcm(Assembler::GT, v26, __ T2S, v27, v28);      \/\/       fcmgt   v26.2S, v27.2S, v28.2S\n+    __ fcm(Assembler::GT, v19, __ T4S, v20, v21);      \/\/       fcmgt   v19.4S, v20.4S, v21.4S\n+    __ fcm(Assembler::GT, v15, __ T2D, v16, v17);      \/\/       fcmgt   v15.2D, v16.2D, v17.2D\n+    __ fcm(Assembler::GE, v12, __ T2S, v13, v14);      \/\/       fcmge   v12.2S, v13.2S, v14.2S\n+    __ fcm(Assembler::GE, v11, __ T4S, v12, v13);      \/\/       fcmge   v11.4S, v12.4S, v13.4S\n+    __ fcm(Assembler::GE, v9, __ T2D, v10, v11);       \/\/       fcmge   v9.2D, v10.2D, v11.2D\n@@ -817,6 +820,6 @@\n-    __ sve_fcm(Assembler::EQ, p13, __ D, p3, z19, 0.0); \/\/      fcmeq   p13.d, p3\/z, z19.d, #0.0\n-    __ sve_fcm(Assembler::GT, p5, __ S, p7, z9, 0.0);  \/\/       fcmgt   p5.s, p7\/z, z9.s, #0.0\n-    __ sve_fcm(Assembler::GE, p8, __ D, p7, z26, 0.0); \/\/       fcmge   p8.d, p7\/z, z26.d, #0.0\n-    __ sve_fcm(Assembler::LT, p3, __ D, p2, z10, 0.0); \/\/       fcmlt   p3.d, p2\/z, z10.d, #0.0\n-    __ sve_fcm(Assembler::LE, p2, __ D, p4, z23, 0.0); \/\/       fcmle   p2.d, p4\/z, z23.d, #0.0\n-    __ sve_fcm(Assembler::NE, p11, __ D, p3, z3, 0.0); \/\/       fcmne   p11.d, p3\/z, z3.d, #0.0\n+    __ sve_fcm(Assembler::EQ, p3, __ D, p6, z29, 0.0); \/\/       fcmeq   p3.d, p6\/z, z29.d, #0.0\n+    __ sve_fcm(Assembler::GT, p14, __ S, p2, z29, 0.0); \/\/      fcmgt   p14.s, p2\/z, z29.s, #0.0\n+    __ sve_fcm(Assembler::GE, p10, __ S, p6, z9, 0.0); \/\/       fcmge   p10.s, p6\/z, z9.s, #0.0\n+    __ sve_fcm(Assembler::LT, p8, __ D, p0, z16, 0.0); \/\/       fcmlt   p8.d, p0\/z, z16.d, #0.0\n+    __ sve_fcm(Assembler::LE, p14, __ D, p4, z14, 0.0); \/\/      fcmle   p14.d, p4\/z, z14.d, #0.0\n+    __ sve_fcm(Assembler::NE, p9, __ S, p3, z22, 0.0); \/\/       fcmne   p9.s, p3\/z, z22.s, #0.0\n@@ -825,10 +828,10 @@\n-    __ sve_cmp(Assembler::EQ, p11, __ S, p5, z17, -14); \/\/      cmpeq   p11.s, p5\/z, z17.s, #-14\n-    __ sve_cmp(Assembler::GT, p7, __ H, p4, z6, -5);   \/\/       cmpgt   p7.h, p4\/z, z6.h, #-5\n-    __ sve_cmp(Assembler::GE, p6, __ B, p7, z22, 3);   \/\/       cmpge   p6.b, p7\/z, z22.b, #3\n-    __ sve_cmp(Assembler::LT, p2, __ B, p4, z17, 6);   \/\/       cmplt   p2.b, p4\/z, z17.b, #6\n-    __ sve_cmp(Assembler::LE, p6, __ S, p7, z9, 11);   \/\/       cmple   p6.s, p7\/z, z9.s, #11\n-    __ sve_cmp(Assembler::NE, p6, __ B, p0, z26, 15);  \/\/       cmpne   p6.b, p0\/z, z26.b, #15\n-    __ sve_cmp(Assembler::HS, p12, __ S, p2, z19, 115); \/\/      cmphs   p12.s, p2\/z, z19.s, #115\n-    __ sve_cmp(Assembler::HI, p13, __ B, p5, z14, 92); \/\/       cmphi   p13.b, p5\/z, z14.b, #92\n-    __ sve_cmp(Assembler::LS, p15, __ B, p7, z24, 109); \/\/      cmpls   p15.b, p7\/z, z24.b, #109\n-    __ sve_cmp(Assembler::LO, p9, __ S, p4, z10, 12);  \/\/       cmplo   p9.s, p4\/z, z10.s, #12\n+    __ sve_cmp(Assembler::EQ, p3, __ S, p2, z12, -3);  \/\/       cmpeq   p3.s, p2\/z, z12.s, #-3\n+    __ sve_cmp(Assembler::GT, p11, __ D, p4, z1, -11); \/\/       cmpgt   p11.d, p4\/z, z1.d, #-11\n+    __ sve_cmp(Assembler::GE, p8, __ S, p5, z2, -3);   \/\/       cmpge   p8.s, p5\/z, z2.s, #-3\n+    __ sve_cmp(Assembler::LT, p5, __ D, p6, z20, -4);  \/\/       cmplt   p5.d, p6\/z, z20.d, #-4\n+    __ sve_cmp(Assembler::LE, p13, __ B, p7, z3, 8);   \/\/       cmple   p13.b, p7\/z, z3.b, #8\n+    __ sve_cmp(Assembler::NE, p9, __ H, p7, z17, 11);  \/\/       cmpne   p9.h, p7\/z, z17.h, #11\n+    __ sve_cmp(Assembler::HS, p7, __ S, p5, z6, 127);  \/\/       cmphs   p7.s, p5\/z, z6.s, #127\n+    __ sve_cmp(Assembler::HI, p12, __ D, p6, z2, 74);  \/\/       cmphi   p12.d, p6\/z, z2.d, #74\n+    __ sve_cmp(Assembler::LS, p5, __ S, p0, z22, 72);  \/\/       cmpls   p5.s, p0\/z, z22.s, #72\n+    __ sve_cmp(Assembler::LO, p0, __ D, p5, z24, 11);  \/\/       cmplo   p0.d, p5\/z, z24.d, #11\n@@ -1089,9 +1092,9 @@\n-    __ swp(Assembler::xword, r16, r0, r25);            \/\/       swp     x16, x0, [x25]\n-    __ ldadd(Assembler::xword, r26, r23, r2);          \/\/       ldadd   x26, x23, [x2]\n-    __ ldbic(Assembler::xword, r16, r12, r4);          \/\/       ldclr   x16, x12, [x4]\n-    __ ldeor(Assembler::xword, r28, r30, r29);         \/\/       ldeor   x28, x30, [x29]\n-    __ ldorr(Assembler::xword, r16, r27, r6);          \/\/       ldset   x16, x27, [x6]\n-    __ ldsmin(Assembler::xword, r9, r29, r15);         \/\/       ldsmin  x9, x29, [x15]\n-    __ ldsmax(Assembler::xword, r7, r4, r7);           \/\/       ldsmax  x7, x4, [x7]\n-    __ ldumin(Assembler::xword, r15, r9, r23);         \/\/       ldumin  x15, x9, [x23]\n-    __ ldumax(Assembler::xword, r8, r2, r28);          \/\/       ldumax  x8, x2, [x28]\n+    __ swp(Assembler::xword, r16, r12, r4);            \/\/       swp     x16, x12, [x4]\n+    __ ldadd(Assembler::xword, r28, r30, r29);         \/\/       ldadd   x28, x30, [x29]\n+    __ ldbic(Assembler::xword, r16, r27, r6);          \/\/       ldclr   x16, x27, [x6]\n+    __ ldeor(Assembler::xword, r9, r29, r15);          \/\/       ldeor   x9, x29, [x15]\n+    __ ldorr(Assembler::xword, r7, r4, r7);            \/\/       ldset   x7, x4, [x7]\n+    __ ldsmin(Assembler::xword, r15, r9, r23);         \/\/       ldsmin  x15, x9, [x23]\n+    __ ldsmax(Assembler::xword, r8, r2, r28);          \/\/       ldsmax  x8, x2, [x28]\n+    __ ldumin(Assembler::xword, r21, zr, r5);          \/\/       ldumin  x21, xzr, [x5]\n+    __ ldumax(Assembler::xword, r27, r0, r17);         \/\/       ldumax  x27, x0, [x17]\n@@ -1100,9 +1103,9 @@\n-    __ swpa(Assembler::xword, r21, zr, r5);            \/\/       swpa    x21, xzr, [x5]\n-    __ ldadda(Assembler::xword, r27, r0, r17);         \/\/       ldadda  x27, x0, [x17]\n-    __ ldbica(Assembler::xword, r15, r4, r26);         \/\/       ldclra  x15, x4, [x26]\n-    __ ldeora(Assembler::xword, r8, r28, r22);         \/\/       ldeora  x8, x28, [x22]\n-    __ ldorra(Assembler::xword, r27, r27, r25);        \/\/       ldseta  x27, x27, [x25]\n-    __ ldsmina(Assembler::xword, r23, r0, r4);         \/\/       ldsmina x23, x0, [x4]\n-    __ ldsmaxa(Assembler::xword, r6, r16, r0);         \/\/       ldsmaxa x6, x16, [x0]\n-    __ ldumina(Assembler::xword, r4, r15, r1);         \/\/       ldumina x4, x15, [x1]\n-    __ ldumaxa(Assembler::xword, r10, r7, r5);         \/\/       ldumaxa x10, x7, [x5]\n+    __ swpa(Assembler::xword, r15, r4, r26);           \/\/       swpa    x15, x4, [x26]\n+    __ ldadda(Assembler::xword, r8, r28, r22);         \/\/       ldadda  x8, x28, [x22]\n+    __ ldbica(Assembler::xword, r27, r27, r25);        \/\/       ldclra  x27, x27, [x25]\n+    __ ldeora(Assembler::xword, r23, r0, r4);          \/\/       ldeora  x23, x0, [x4]\n+    __ ldorra(Assembler::xword, r6, r16, r0);          \/\/       ldseta  x6, x16, [x0]\n+    __ ldsmina(Assembler::xword, r4, r15, r1);         \/\/       ldsmina x4, x15, [x1]\n+    __ ldsmaxa(Assembler::xword, r10, r7, r5);         \/\/       ldsmaxa x10, x7, [x5]\n+    __ ldumina(Assembler::xword, r10, r28, r7);        \/\/       ldumina x10, x28, [x7]\n+    __ ldumaxa(Assembler::xword, r20, r23, r21);       \/\/       ldumaxa x20, x23, [x21]\n@@ -1111,9 +1114,9 @@\n-    __ swpal(Assembler::xword, r10, r28, r7);          \/\/       swpal   x10, x28, [x7]\n-    __ ldaddal(Assembler::xword, r20, r23, r21);       \/\/       ldaddal x20, x23, [x21]\n-    __ ldbical(Assembler::xword, r6, r11, r8);         \/\/       ldclral x6, x11, [x8]\n-    __ ldeoral(Assembler::xword, r17, zr, r6);         \/\/       ldeoral x17, xzr, [x6]\n-    __ ldorral(Assembler::xword, r17, r2, r12);        \/\/       ldsetal x17, x2, [x12]\n-    __ ldsminal(Assembler::xword, r30, r29, r3);       \/\/       ldsminal        x30, x29, [x3]\n-    __ ldsmaxal(Assembler::xword, r27, r22, r29);      \/\/       ldsmaxal        x27, x22, [x29]\n-    __ lduminal(Assembler::xword, r14, r13, r28);      \/\/       lduminal        x14, x13, [x28]\n-    __ ldumaxal(Assembler::xword, r17, r24, r5);       \/\/       ldumaxal        x17, x24, [x5]\n+    __ swpal(Assembler::xword, r6, r11, r8);           \/\/       swpal   x6, x11, [x8]\n+    __ ldaddal(Assembler::xword, r17, zr, r6);         \/\/       ldaddal x17, xzr, [x6]\n+    __ ldbical(Assembler::xword, r17, r2, r12);        \/\/       ldclral x17, x2, [x12]\n+    __ ldeoral(Assembler::xword, r30, r29, r3);        \/\/       ldeoral x30, x29, [x3]\n+    __ ldorral(Assembler::xword, r27, r22, r29);       \/\/       ldsetal x27, x22, [x29]\n+    __ ldsminal(Assembler::xword, r14, r13, r28);      \/\/       ldsminal        x14, x13, [x28]\n+    __ ldsmaxal(Assembler::xword, r17, r24, r5);       \/\/       ldsmaxal        x17, x24, [x5]\n+    __ lduminal(Assembler::xword, r2, r14, r10);       \/\/       lduminal        x2, x14, [x10]\n+    __ ldumaxal(Assembler::xword, r16, r11, r27);      \/\/       ldumaxal        x16, x11, [x27]\n@@ -1122,9 +1125,9 @@\n-    __ swpl(Assembler::xword, r2, r14, r10);           \/\/       swpl    x2, x14, [x10]\n-    __ ldaddl(Assembler::xword, r16, r11, r27);        \/\/       ldaddl  x16, x11, [x27]\n-    __ ldbicl(Assembler::xword, r23, r12, r4);         \/\/       ldclrl  x23, x12, [x4]\n-    __ ldeorl(Assembler::xword, r22, r17, r4);         \/\/       ldeorl  x22, x17, [x4]\n-    __ ldorrl(Assembler::xword, r1, r19, r16);         \/\/       ldsetl  x1, x19, [x16]\n-    __ ldsminl(Assembler::xword, r16, r13, r14);       \/\/       ldsminl x16, x13, [x14]\n-    __ ldsmaxl(Assembler::xword, r12, r2, r17);        \/\/       ldsmaxl x12, x2, [x17]\n-    __ lduminl(Assembler::xword, r3, r21, r23);        \/\/       lduminl x3, x21, [x23]\n-    __ ldumaxl(Assembler::xword, r5, r6, r7);          \/\/       ldumaxl x5, x6, [x7]\n+    __ swpl(Assembler::xword, r23, r12, r4);           \/\/       swpl    x23, x12, [x4]\n+    __ ldaddl(Assembler::xword, r22, r17, r4);         \/\/       ldaddl  x22, x17, [x4]\n+    __ ldbicl(Assembler::xword, r1, r19, r16);         \/\/       ldclrl  x1, x19, [x16]\n+    __ ldeorl(Assembler::xword, r16, r13, r14);        \/\/       ldeorl  x16, x13, [x14]\n+    __ ldorrl(Assembler::xword, r12, r2, r17);         \/\/       ldsetl  x12, x2, [x17]\n+    __ ldsminl(Assembler::xword, r3, r21, r23);        \/\/       ldsminl x3, x21, [x23]\n+    __ ldsmaxl(Assembler::xword, r5, r6, r7);          \/\/       ldsmaxl x5, x6, [x7]\n+    __ lduminl(Assembler::xword, r19, r13, r28);       \/\/       lduminl x19, x13, [x28]\n+    __ ldumaxl(Assembler::xword, r17, r16, r6);        \/\/       ldumaxl x17, x16, [x6]\n@@ -1133,9 +1136,9 @@\n-    __ swp(Assembler::word, r19, r13, r28);            \/\/       swp     w19, w13, [x28]\n-    __ ldadd(Assembler::word, r17, r16, r6);           \/\/       ldadd   w17, w16, [x6]\n-    __ ldbic(Assembler::word, r2, r29, r3);            \/\/       ldclr   w2, w29, [x3]\n-    __ ldeor(Assembler::word, r4, r6, r15);            \/\/       ldeor   w4, w6, [x15]\n-    __ ldorr(Assembler::word, r20, r13, r12);          \/\/       ldset   w20, w13, [x12]\n-    __ ldsmin(Assembler::word, r20, r8, r25);          \/\/       ldsmin  w20, w8, [x25]\n-    __ ldsmax(Assembler::word, r20, r19, r0);          \/\/       ldsmax  w20, w19, [x0]\n-    __ ldumin(Assembler::word, r11, r24, r6);          \/\/       ldumin  w11, w24, [x6]\n-    __ ldumax(Assembler::word, r20, zr, r14);          \/\/       ldumax  w20, wzr, [x14]\n+    __ swp(Assembler::word, r2, r29, r3);              \/\/       swp     w2, w29, [x3]\n+    __ ldadd(Assembler::word, r4, r6, r15);            \/\/       ldadd   w4, w6, [x15]\n+    __ ldbic(Assembler::word, r20, r13, r12);          \/\/       ldclr   w20, w13, [x12]\n+    __ ldeor(Assembler::word, r20, r8, r25);           \/\/       ldeor   w20, w8, [x25]\n+    __ ldorr(Assembler::word, r20, r19, r0);           \/\/       ldset   w20, w19, [x0]\n+    __ ldsmin(Assembler::word, r11, r24, r6);          \/\/       ldsmin  w11, w24, [x6]\n+    __ ldsmax(Assembler::word, r20, zr, r14);          \/\/       ldsmax  w20, wzr, [x14]\n+    __ ldumin(Assembler::word, r16, r6, r0);           \/\/       ldumin  w16, w6, [x0]\n+    __ ldumax(Assembler::word, r7, r15, r19);          \/\/       ldumax  w7, w15, [x19]\n@@ -1144,9 +1147,9 @@\n-    __ swpa(Assembler::word, r16, r6, r0);             \/\/       swpa    w16, w6, [x0]\n-    __ ldadda(Assembler::word, r7, r15, r19);          \/\/       ldadda  w7, w15, [x19]\n-    __ ldbica(Assembler::word, r26, r9, r10);          \/\/       ldclra  w26, w9, [x10]\n-    __ ldeora(Assembler::word, r23, r21, r22);         \/\/       ldeora  w23, w21, [x22]\n-    __ ldorra(Assembler::word, r28, r2, r3);           \/\/       ldseta  w28, w2, [x3]\n-    __ ldsmina(Assembler::word, r15, r19, r20);        \/\/       ldsmina w15, w19, [x20]\n-    __ ldsmaxa(Assembler::word, r7, r4, r29);          \/\/       ldsmaxa w7, w4, [x29]\n-    __ ldumina(Assembler::word, r7, r0, r9);           \/\/       ldumina w7, w0, [x9]\n-    __ ldumaxa(Assembler::word, r16, r20, r23);        \/\/       ldumaxa w16, w20, [x23]\n+    __ swpa(Assembler::word, r26, r9, r10);            \/\/       swpa    w26, w9, [x10]\n+    __ ldadda(Assembler::word, r23, r21, r22);         \/\/       ldadda  w23, w21, [x22]\n+    __ ldbica(Assembler::word, r28, r2, r3);           \/\/       ldclra  w28, w2, [x3]\n+    __ ldeora(Assembler::word, r15, r19, r20);         \/\/       ldeora  w15, w19, [x20]\n+    __ ldorra(Assembler::word, r7, r4, r29);           \/\/       ldseta  w7, w4, [x29]\n+    __ ldsmina(Assembler::word, r7, r0, r9);           \/\/       ldsmina w7, w0, [x9]\n+    __ ldsmaxa(Assembler::word, r16, r20, r23);        \/\/       ldsmaxa w16, w20, [x23]\n+    __ ldumina(Assembler::word, r4, r16, r10);         \/\/       ldumina w4, w16, [x10]\n+    __ ldumaxa(Assembler::word, r23, r11, r25);        \/\/       ldumaxa w23, w11, [x25]\n@@ -1155,9 +1158,9 @@\n-    __ swpal(Assembler::word, r4, r16, r10);           \/\/       swpal   w4, w16, [x10]\n-    __ ldaddal(Assembler::word, r23, r11, r25);        \/\/       ldaddal w23, w11, [x25]\n-    __ ldbical(Assembler::word, r6, zr, r16);          \/\/       ldclral w6, wzr, [x16]\n-    __ ldeoral(Assembler::word, r13, r23, r12);        \/\/       ldeoral w13, w23, [x12]\n-    __ ldorral(Assembler::word, r1, r14, r9);          \/\/       ldsetal w1, w14, [x9]\n-    __ ldsminal(Assembler::word, r21, r16, r26);       \/\/       ldsminal        w21, w16, [x26]\n-    __ ldsmaxal(Assembler::word, r15, r4, r4);         \/\/       ldsmaxal        w15, w4, [x4]\n-    __ lduminal(Assembler::word, r16, r8, r6);         \/\/       lduminal        w16, w8, [x6]\n-    __ ldumaxal(Assembler::word, r30, r4, r29);        \/\/       ldumaxal        w30, w4, [x29]\n+    __ swpal(Assembler::word, r6, zr, r16);            \/\/       swpal   w6, wzr, [x16]\n+    __ ldaddal(Assembler::word, r13, r23, r12);        \/\/       ldaddal w13, w23, [x12]\n+    __ ldbical(Assembler::word, r1, r14, r9);          \/\/       ldclral w1, w14, [x9]\n+    __ ldeoral(Assembler::word, r21, r16, r26);        \/\/       ldeoral w21, w16, [x26]\n+    __ ldorral(Assembler::word, r15, r4, r4);          \/\/       ldsetal w15, w4, [x4]\n+    __ ldsminal(Assembler::word, r16, r8, r6);         \/\/       ldsminal        w16, w8, [x6]\n+    __ ldsmaxal(Assembler::word, r30, r4, r29);        \/\/       ldsmaxal        w30, w4, [x29]\n+    __ lduminal(Assembler::word, r17, r29, r26);       \/\/       lduminal        w17, w29, [x26]\n+    __ ldumaxal(Assembler::word, r9, r15, r2);         \/\/       ldumaxal        w9, w15, [x2]\n@@ -1166,9 +1169,9 @@\n-    __ swpl(Assembler::word, r17, r29, r26);           \/\/       swpl    w17, w29, [x26]\n-    __ ldaddl(Assembler::word, r9, r15, r2);           \/\/       ldaddl  w9, w15, [x2]\n-    __ ldbicl(Assembler::word, r11, r29, r3);          \/\/       ldclrl  w11, w29, [x3]\n-    __ ldeorl(Assembler::word, r7, r1, r27);           \/\/       ldeorl  w7, w1, [x27]\n-    __ ldorrl(Assembler::word, r21, r16, r14);         \/\/       ldsetl  w21, w16, [x14]\n-    __ ldsminl(Assembler::word, r8, r16, r22);         \/\/       ldsminl w8, w16, [x22]\n-    __ ldsmaxl(Assembler::word, r25, r5, r20);         \/\/       ldsmaxl w25, w5, [x20]\n-    __ lduminl(Assembler::word, r21, r16, r23);        \/\/       lduminl w21, w16, [x23]\n-    __ ldumaxl(Assembler::word, r16, r30, r20);        \/\/       ldumaxl w16, w30, [x20]\n+    __ swpl(Assembler::word, r11, r29, r3);            \/\/       swpl    w11, w29, [x3]\n+    __ ldaddl(Assembler::word, r7, r1, r27);           \/\/       ldaddl  w7, w1, [x27]\n+    __ ldbicl(Assembler::word, r21, r16, r14);         \/\/       ldclrl  w21, w16, [x14]\n+    __ ldeorl(Assembler::word, r8, r16, r22);          \/\/       ldeorl  w8, w16, [x22]\n+    __ ldorrl(Assembler::word, r25, r5, r20);          \/\/       ldsetl  w25, w5, [x20]\n+    __ ldsminl(Assembler::word, r21, r16, r23);        \/\/       ldsminl w21, w16, [x23]\n+    __ ldsmaxl(Assembler::word, r16, r30, r20);        \/\/       ldsmaxl w16, w30, [x20]\n+    __ lduminl(Assembler::word, r20, r0, r4);          \/\/       lduminl w20, w0, [x4]\n+    __ ldumaxl(Assembler::word, r19, r24, r4);         \/\/       ldumaxl w19, w24, [x4]\n@@ -1177,4 +1180,4 @@\n-    __ bcax(v19, __ T16B, v0, v4, v17);                \/\/       bcax            v19.16B, v0.16B, v4.16B, v17.16B\n-    __ eor3(v23, __ T16B, v4, v19, v4);                \/\/       eor3            v23.16B, v4.16B, v19.16B, v4.16B\n-    __ rax1(v23, __ T2D, v25, v19);                    \/\/       rax1            v23.2D, v25.2D, v19.2D\n-    __ xar(v2, __ T2D, v8, v8, 29);                    \/\/       xar             v2.2D, v8.2D, v8.2D, #29\n+    __ bcax(v19, __ T16B, v4, v23, v25);               \/\/       bcax            v19.16B, v4.16B, v23.16B, v25.16B\n+    __ eor3(v19, __ T16B, v2, v8, v8);                 \/\/       eor3            v19.16B, v2.16B, v8.16B, v8.16B\n+    __ rax1(v14, __ T2D, v24, v17);                    \/\/       rax1            v14.2D, v24.2D, v17.2D\n+    __ xar(v30, __ T2D, v21, v4, 62);                  \/\/       xar             v30.2D, v21.2D, v4.2D, #62\n@@ -1183,4 +1186,4 @@\n-    __ sha512h(v24, __ T2D, v17, v30);                 \/\/       sha512h         q24, q17, v30.2D\n-    __ sha512h2(v21, __ T2D, v4, v30);                 \/\/       sha512h2                q21, q4, v30.2D\n-    __ sha512su0(v1, __ T2D, v10);                     \/\/       sha512su0               v1.2D, v10.2D\n-    __ sha512su1(v19, __ T2D, v12, v0);                \/\/       sha512su1               v19.2D, v12.2D, v0.2D\n+    __ sha512h(v1, __ T2D, v10, v19);                  \/\/       sha512h         q1, q10, v19.2D\n+    __ sha512h2(v12, __ T2D, v0, v9);                  \/\/       sha512h2                q12, q0, v9.2D\n+    __ sha512su0(v7, __ T2D, v24);                     \/\/       sha512su0               v7.2D, v24.2D\n+    __ sha512su1(v17, __ T2D, v4, v27);                \/\/       sha512su1               v17.2D, v4.2D, v27.2D\n@@ -1189,5 +1192,5 @@\n-    __ sve_add(z9, __ B, 198u);                        \/\/       add     z9.b, z9.b, #0xc6\n-    __ sve_sub(z17, __ B, 223u);                       \/\/       sub     z17.b, z17.b, #0xdf\n-    __ sve_and(z6, __ H, 57407u);                      \/\/       and     z6.h, z6.h, #0xe03f\n-    __ sve_eor(z13, __ S, 4229955583u);                \/\/       eor     z13.s, z13.s, #0xfc1fffff\n-    __ sve_orr(z22, __ S, 4294950919u);                \/\/       orr     z22.s, z22.s, #0xffffc007\n+    __ sve_add(z6, __ H, 223u);                        \/\/       add     z6.h, z6.h, #0xdf\n+    __ sve_sub(z23, __ H, 132u);                       \/\/       sub     z23.h, z23.h, #0x84\n+    __ sve_and(z30, __ S, 4160749823u);                \/\/       and     z30.s, z30.s, #0xf80000ff\n+    __ sve_eor(z30, __ D, 2017612633061982208u);       \/\/       eor     z30.d, z30.d, #0x1c00000000000000\n+    __ sve_orr(z19, __ B, 243u);                       \/\/       orr     z19.b, z19.b, #0xf3\n@@ -1196,5 +1199,5 @@\n-    __ sve_add(z9, __ H, 162u);                        \/\/       add     z9.h, z9.h, #0xa2\n-    __ sve_sub(z7, __ S, 231u);                        \/\/       sub     z7.s, z7.s, #0xe7\n-    __ sve_and(z9, __ H, 16368u);                      \/\/       and     z9.h, z9.h, #0x3ff0\n-    __ sve_eor(z19, __ B, 96u);                        \/\/       eor     z19.b, z19.b, #0x60\n-    __ sve_orr(z19, __ H, 33279u);                     \/\/       orr     z19.h, z19.h, #0x81ff\n+    __ sve_add(z9, __ H, 115u);                        \/\/       add     z9.h, z9.h, #0x73\n+    __ sve_sub(z11, __ S, 13u);                        \/\/       sub     z11.s, z11.s, #0xd\n+    __ sve_and(z24, __ H, 32256u);                     \/\/       and     z24.h, z24.h, #0x7e00\n+    __ sve_eor(z17, __ S, 917504u);                    \/\/       eor     z17.s, z17.s, #0xe0000\n+    __ sve_orr(z0, __ B, 96u);                         \/\/       orr     z0.b, z0.b, #0x60\n@@ -1203,5 +1206,5 @@\n-    __ sve_add(z16, __ B, 1u);                         \/\/       add     z16.b, z16.b, #0x1\n-    __ sve_sub(z3, __ H, 65u);                         \/\/       sub     z3.h, z3.h, #0x41\n-    __ sve_and(z15, __ H, 255u);                       \/\/       and     z15.h, z15.h, #0xff\n-    __ sve_eor(z15, __ D, 1u);                         \/\/       eor     z15.d, z15.d, #0x1\n-    __ sve_orr(z10, __ S, 122880u);                    \/\/       orr     z10.s, z10.s, #0x1e000\n+    __ sve_add(z15, __ H, 131u);                       \/\/       add     z15.h, z15.h, #0x83\n+    __ sve_sub(z4, __ H, 243u);                        \/\/       sub     z4.h, z4.h, #0xf3\n+    __ sve_and(z5, __ B, 191u);                        \/\/       and     z5.b, z5.b, #0xbf\n+    __ sve_eor(z26, __ B, 96u);                        \/\/       eor     z26.b, z26.b, #0x60\n+    __ sve_orr(z19, __ D, 18446532967477018623u);      \/\/       orr     z19.d, z19.d, #0xffff3fffffffffff\n@@ -1210,5 +1213,5 @@\n-    __ sve_add(z0, __ H, 159u);                        \/\/       add     z0.h, z0.h, #0x9f\n-    __ sve_sub(z28, __ H, 199u);                       \/\/       sub     z28.h, z28.h, #0xc7\n-    __ sve_and(z3, __ S, 4286578691u);                 \/\/       and     z3.s, z3.s, #0xff800003\n-    __ sve_eor(z28, __ H, 8064u);                      \/\/       eor     z28.h, z28.h, #0x1f80\n-    __ sve_orr(z26, __ H, 65534u);                     \/\/       orr     z26.h, z26.h, #0xfffe\n+    __ sve_add(z3, __ S, 63u);                         \/\/       add     z3.s, z3.s, #0x3f\n+    __ sve_sub(z23, __ D, 113u);                       \/\/       sub     z23.d, z23.d, #0x71\n+    __ sve_and(z21, __ H, 16368u);                     \/\/       and     z21.h, z21.h, #0x3ff0\n+    __ sve_eor(z17, __ D, 2017612633061982208u);       \/\/       eor     z17.d, z17.d, #0x1c00000000000000\n+    __ sve_orr(z2, __ D, 18437736874454811647u);       \/\/       orr     z2.d, z2.d, #0xffe00000000003ff\n@@ -1217,5 +1220,5 @@\n-    __ sve_add(z17, __ H, 24u);                        \/\/       add     z17.h, z17.h, #0x18\n-    __ sve_sub(z29, __ S, 179u);                       \/\/       sub     z29.s, z29.s, #0xb3\n-    __ sve_and(z20, __ B, 12u);                        \/\/       and     z20.b, z20.b, #0xc\n-    __ sve_eor(z1, __ D, 4503599627354112u);           \/\/       eor     z1.d, z1.d, #0xfffffffffc000\n-    __ sve_orr(z16, __ S, 1u);                         \/\/       orr     z16.s, z16.s, #0x1\n+    __ sve_add(z20, __ B, 163u);                       \/\/       add     z20.b, z20.b, #0xa3\n+    __ sve_sub(z2, __ B, 215u);                        \/\/       sub     z2.b, z2.b, #0xd7\n+    __ sve_and(z17, __ H, 33279u);                     \/\/       and     z17.h, z17.h, #0x81ff\n+    __ sve_eor(z21, __ B, 12u);                        \/\/       eor     z21.b, z21.b, #0xc\n+    __ sve_orr(z23, __ H, 8064u);                      \/\/       orr     z23.h, z23.h, #0x1f80\n@@ -1224,5 +1227,5 @@\n-    __ sve_add(z4, __ B, 192u);                        \/\/       add     z4.b, z4.b, #0xc0\n-    __ sve_sub(z14, __ B, 95u);                        \/\/       sub     z14.b, z14.b, #0x5f\n-    __ sve_and(z20, __ H, 65283u);                     \/\/       and     z20.h, z20.h, #0xff03\n-    __ sve_eor(z12, __ B, 191u);                       \/\/       eor     z12.b, z12.b, #0xbf\n-    __ sve_orr(z9, __ B, 243u);                        \/\/       orr     z9.b, z9.b, #0xf3\n+    __ sve_add(z20, __ H, 139u);                       \/\/       add     z20.h, z20.h, #0x8b\n+    __ sve_sub(z29, __ H, 26u);                        \/\/       sub     z29.h, z29.h, #0x1a\n+    __ sve_and(z3, __ S, 122880u);                     \/\/       and     z3.s, z3.s, #0x1e000\n+    __ sve_eor(z24, __ D, 18158513714670600195u);      \/\/       eor     z24.d, z24.d, #0xfc000003fc000003\n+    __ sve_orr(z22, __ B, 191u);                       \/\/       orr     z22.b, z22.b, #0xbf\n@@ -1231,56 +1234,56 @@\n-    __ sve_add(z3, __ B, z19, z22);                    \/\/       add     z3.b, z19.b, z22.b\n-    __ sve_sub(z25, __ B, z21, z13);                   \/\/       sub     z25.b, z21.b, z13.b\n-    __ sve_fadd(z7, __ D, z25, z5);                    \/\/       fadd    z7.d, z25.d, z5.d\n-    __ sve_fmul(z17, __ S, z17, z0);                   \/\/       fmul    z17.s, z17.s, z0.s\n-    __ sve_fsub(z9, __ S, z19, z11);                   \/\/       fsub    z9.s, z19.s, z11.s\n-    __ sve_abs(z11, __ S, p3, z17);                    \/\/       abs     z11.s, p3\/m, z17.s\n-    __ sve_add(z11, __ S, p3, z24);                    \/\/       add     z11.s, p3\/m, z11.s, z24.s\n-    __ sve_and(z30, __ S, p4, z8);                     \/\/       and     z30.s, p4\/m, z30.s, z8.s\n-    __ sve_asr(z14, __ D, p6, z22);                    \/\/       asr     z14.d, p6\/m, z14.d, z22.d\n-    __ sve_bic(z22, __ B, p2, z8);                     \/\/       bic     z22.b, p2\/m, z22.b, z8.b\n-    __ sve_clz(z27, __ B, p7, z10);                    \/\/       clz     z27.b, p7\/m, z10.b\n-    __ sve_cnt(z14, __ S, p6, z21);                    \/\/       cnt     z14.s, p6\/m, z21.s\n-    __ sve_eor(z0, __ D, p0, z22);                     \/\/       eor     z0.d, p0\/m, z0.d, z22.d\n-    __ sve_lsl(z5, __ S, p6, z29);                     \/\/       lsl     z5.s, p6\/m, z5.s, z29.s\n-    __ sve_lsr(z17, __ H, p0, z12);                    \/\/       lsr     z17.h, p0\/m, z17.h, z12.h\n-    __ sve_mul(z29, __ S, p3, z0);                     \/\/       mul     z29.s, p3\/m, z29.s, z0.s\n-    __ sve_neg(z2, __ S, p7, z20);                     \/\/       neg     z2.s, p7\/m, z20.s\n-    __ sve_not(z21, __ H, p7, z12);                    \/\/       not     z21.h, p7\/m, z12.h\n-    __ sve_orr(z2, __ S, p0, z14);                     \/\/       orr     z2.s, p0\/m, z2.s, z14.s\n-    __ sve_rbit(z22, __ D, p0, z19);                   \/\/       rbit    z22.d, p0\/m, z19.d\n-    __ sve_revb(z26, __ D, p6, z12);                   \/\/       revb    z26.d, p6\/m, z12.d\n-    __ sve_smax(z21, __ H, p0, z1);                    \/\/       smax    z21.h, p0\/m, z21.h, z1.h\n-    __ sve_smin(z19, __ D, p3, z19);                   \/\/       smin    z19.d, p3\/m, z19.d, z19.d\n-    __ sve_sub(z23, __ S, p2, z30);                    \/\/       sub     z23.s, p2\/m, z23.s, z30.s\n-    __ sve_fabs(z19, __ S, p5, z20);                   \/\/       fabs    z19.s, p5\/m, z20.s\n-    __ sve_fadd(z20, __ D, p3, z30);                   \/\/       fadd    z20.d, p3\/m, z20.d, z30.d\n-    __ sve_fdiv(z30, __ D, p7, z25);                   \/\/       fdiv    z30.d, p7\/m, z30.d, z25.d\n-    __ sve_fmax(z17, __ S, p3, z11);                   \/\/       fmax    z17.s, p3\/m, z17.s, z11.s\n-    __ sve_fmin(z28, __ S, p5, z5);                    \/\/       fmin    z28.s, p5\/m, z28.s, z5.s\n-    __ sve_fmul(z13, __ S, p3, z2);                    \/\/       fmul    z13.s, p3\/m, z13.s, z2.s\n-    __ sve_fneg(z10, __ S, p3, z19);                   \/\/       fneg    z10.s, p3\/m, z19.s\n-    __ sve_frintm(z25, __ S, p3, z2);                  \/\/       frintm  z25.s, p3\/m, z2.s\n-    __ sve_frintn(z29, __ S, p0, z20);                 \/\/       frintn  z29.s, p0\/m, z20.s\n-    __ sve_frintp(z20, __ S, p7, z28);                 \/\/       frintp  z20.s, p7\/m, z28.s\n-    __ sve_fsqrt(z13, __ D, p2, z13);                  \/\/       fsqrt   z13.d, p2\/m, z13.d\n-    __ sve_fsub(z1, __ S, p3, z27);                    \/\/       fsub    z1.s, p3\/m, z1.s, z27.s\n-    __ sve_fmad(z3, __ S, p6, z8, z24);                \/\/       fmad    z3.s, p6\/m, z8.s, z24.s\n-    __ sve_fmla(z1, __ S, p6, z10, z14);               \/\/       fmla    z1.s, p6\/m, z10.s, z14.s\n-    __ sve_fmls(z20, __ D, p6, z6, z28);               \/\/       fmls    z20.d, p6\/m, z6.d, z28.d\n-    __ sve_fmsb(z16, __ S, p1, z27, z13);              \/\/       fmsb    z16.s, p1\/m, z27.s, z13.s\n-    __ sve_fnmad(z28, __ S, p2, z9, z1);               \/\/       fnmad   z28.s, p2\/m, z9.s, z1.s\n-    __ sve_fnmsb(z1, __ S, p6, z26, z14);              \/\/       fnmsb   z1.s, p6\/m, z26.s, z14.s\n-    __ sve_fnmla(z4, __ S, p7, z17, z24);              \/\/       fnmla   z4.s, p7\/m, z17.s, z24.s\n-    __ sve_fnmls(z2, __ D, p6, z3, z25);               \/\/       fnmls   z2.d, p6\/m, z3.d, z25.d\n-    __ sve_mla(z13, __ S, p0, z22, z13);               \/\/       mla     z13.s, p0\/m, z22.s, z13.s\n-    __ sve_mls(z27, __ D, p4, z4, z11);                \/\/       mls     z27.d, p4\/m, z4.d, z11.d\n-    __ sve_and(z15, z2, z15);                          \/\/       and     z15.d, z2.d, z15.d\n-    __ sve_eor(z27, z7, z22);                          \/\/       eor     z27.d, z7.d, z22.d\n-    __ sve_orr(z27, z16, z10);                         \/\/       orr     z27.d, z16.d, z10.d\n-    __ sve_bic(z16, z28, z7);                          \/\/       bic     z16.d, z28.d, z7.d\n-    __ sve_uzp1(z4, __ H, z12, z24);                   \/\/       uzp1    z4.h, z12.h, z24.h\n-    __ sve_uzp2(z8, __ B, z10, z11);                   \/\/       uzp2    z8.b, z10.b, z11.b\n-    __ sve_fabd(z4, __ D, p5, z21);                    \/\/       fabd    z4.d, p5\/m, z4.d, z21.d\n-    __ sve_bext(z4, __ H, z3, z15);                    \/\/       bext    z4.h, z3.h, z15.h\n-    __ sve_bdep(z3, __ D, z29, z25);                   \/\/       bdep    z3.d, z29.d, z25.d\n-    __ sve_eor3(z5, z20, z25);                         \/\/       eor3    z5.d, z5.d, z20.d, z25.d\n+    __ sve_add(z13, __ D, z5, z7);                     \/\/       add     z13.d, z5.d, z7.d\n+    __ sve_sub(z5, __ S, z21, z17);                    \/\/       sub     z5.s, z21.s, z17.s\n+    __ sve_fadd(z0, __ D, z3, z9);                     \/\/       fadd    z0.d, z3.d, z9.d\n+    __ sve_fmul(z11, __ S, z7, z11);                   \/\/       fmul    z11.s, z7.s, z11.s\n+    __ sve_fsub(z17, __ S, z17, z11);                  \/\/       fsub    z17.s, z17.s, z11.s\n+    __ sve_abs(z24, __ S, p4, z30);                    \/\/       abs     z24.s, p4\/m, z30.s\n+    __ sve_add(z8, __ D, p4, z14);                     \/\/       add     z8.d, p4\/m, z8.d, z14.d\n+    __ sve_and(z22, __ H, p7, z22);                    \/\/       and     z22.h, p7\/m, z22.h, z22.h\n+    __ sve_asr(z8, __ D, p1, z27);                     \/\/       asr     z8.d, p1\/m, z8.d, z27.d\n+    __ sve_bic(z10, __ D, p0, z14);                    \/\/       bic     z10.d, p0\/m, z10.d, z14.d\n+    __ sve_clz(z21, __ B, p5, z0);                     \/\/       clz     z21.b, p5\/m, z0.b\n+    __ sve_cnt(z22, __ D, p6, z5);                     \/\/       cnt     z22.d, p6\/m, z5.d\n+    __ sve_eor(z29, __ B, p4, z17);                    \/\/       eor     z29.b, p4\/m, z29.b, z17.b\n+    __ sve_lsl(z12, __ H, p3, z29);                    \/\/       lsl     z12.h, p3\/m, z12.h, z29.h\n+    __ sve_lsr(z0, __ D, p4, z2);                      \/\/       lsr     z0.d, p4\/m, z0.d, z2.d\n+    __ sve_mul(z20, __ D, p5, z21);                    \/\/       mul     z20.d, p5\/m, z20.d, z21.d\n+    __ sve_neg(z12, __ B, p2, z2);                     \/\/       neg     z12.b, p2\/m, z2.b\n+    __ sve_not(z14, __ B, p5, z22);                    \/\/       not     z14.b, p5\/m, z22.b\n+    __ sve_orr(z19, __ D, p6, z26);                    \/\/       orr     z19.d, p6\/m, z19.d, z26.d\n+    __ sve_rbit(z12, __ B, p5, z21);                   \/\/       rbit    z12.b, p5\/m, z21.b\n+    __ sve_revb(z1, __ S, p2, z19);                    \/\/       revb    z1.s, p2\/m, z19.s\n+    __ sve_smax(z19, __ H, p6, z23);                   \/\/       smax    z19.h, p6\/m, z19.h, z23.h\n+    __ sve_smin(z30, __ S, p4, z19);                   \/\/       smin    z30.s, p4\/m, z30.s, z19.s\n+    __ sve_sub(z20, __ H, p1, z20);                    \/\/       sub     z20.h, p1\/m, z20.h, z20.h\n+    __ sve_fabs(z30, __ D, p5, z30);                   \/\/       fabs    z30.d, p5\/m, z30.d\n+    __ sve_fadd(z25, __ S, p4, z17);                   \/\/       fadd    z25.s, p4\/m, z25.s, z17.s\n+    __ sve_fdiv(z11, __ D, p3, z28);                   \/\/       fdiv    z11.d, p3\/m, z11.d, z28.d\n+    __ sve_fmax(z5, __ S, p0, z13);                    \/\/       fmax    z5.s, p0\/m, z5.s, z13.s\n+    __ sve_fmin(z2, __ S, p1, z10);                    \/\/       fmin    z2.s, p1\/m, z2.s, z10.s\n+    __ sve_fmul(z19, __ S, p1, z25);                   \/\/       fmul    z19.s, p1\/m, z19.s, z25.s\n+    __ sve_fneg(z2, __ S, p0, z29);                    \/\/       fneg    z2.s, p0\/m, z29.s\n+    __ sve_frintm(z20, __ D, p1, z20);                 \/\/       frintm  z20.d, p1\/m, z20.d\n+    __ sve_frintn(z28, __ S, p3, z13);                 \/\/       frintn  z28.s, p3\/m, z13.s\n+    __ sve_frintp(z13, __ S, p7, z1);                  \/\/       frintp  z13.s, p7\/m, z1.s\n+    __ sve_fsqrt(z27, __ D, p0, z3);                   \/\/       fsqrt   z27.d, p0\/m, z3.d\n+    __ sve_fsub(z8, __ S, p6, z9);                     \/\/       fsub    z8.s, p6\/m, z8.s, z9.s\n+    __ sve_fmad(z25, __ D, p2, z14, z1);               \/\/       fmad    z25.d, p2\/m, z14.d, z1.d\n+    __ sve_fmla(z25, __ D, p1, z28, z19);              \/\/       fmla    z25.d, p1\/m, z28.d, z19.d\n+    __ sve_fmls(z6, __ D, p7, z13, z1);                \/\/       fmls    z6.d, p7\/m, z13.d, z1.d\n+    __ sve_fmsb(z11, __ S, p2, z1, z1);                \/\/       fmsb    z11.s, p2\/m, z1.s, z1.s\n+    __ sve_fnmad(z27, __ S, p6, z14, z2);              \/\/       fnmad   z27.s, p6\/m, z14.s, z2.s\n+    __ sve_fnmsb(z29, __ S, p4, z24, z2);              \/\/       fnmsb   z29.s, p4\/m, z24.s, z2.s\n+    __ sve_fnmla(z24, __ S, p0, z25, z28);             \/\/       fnmla   z24.s, p0\/m, z25.s, z28.s\n+    __ sve_fnmls(z3, __ D, p5, z13, z15);              \/\/       fnmls   z3.d, p5\/m, z13.d, z15.d\n+    __ sve_mla(z16, __ S, p1, z11, z26);               \/\/       mla     z16.s, p1\/m, z11.s, z26.s\n+    __ sve_mls(z2, __ B, p4, z1, z27);                 \/\/       mls     z2.b, p4\/m, z1.b, z27.b\n+    __ sve_and(z22, z30, z27);                         \/\/       and     z22.d, z30.d, z27.d\n+    __ sve_eor(z10, z21, z16);                         \/\/       eor     z10.d, z21.d, z16.d\n+    __ sve_orr(z7, z21, z4);                           \/\/       orr     z7.d, z21.d, z4.d\n+    __ sve_bic(z24, z11, z8);                          \/\/       bic     z24.d, z11.d, z8.d\n+    __ sve_uzp1(z11, __ S, z0, z4);                    \/\/       uzp1    z11.s, z0.s, z4.s\n+    __ sve_uzp2(z21, __ B, z20, z4);                   \/\/       uzp2    z21.b, z20.b, z4.b\n+    __ sve_fabd(z15, __ D, p3, z3);                    \/\/       fabd    z15.d, p3\/m, z15.d, z3.d\n+    __ sve_bext(z25, __ S, z27, z5);                   \/\/       bext    z25.s, z27.s, z5.s\n+    __ sve_bdep(z25, __ B, z10, z30);                  \/\/       bdep    z25.b, z10.b, z30.b\n+    __ sve_eor3(z24, z4, z7);                          \/\/       eor3    z24.d, z24.d, z4.d, z7.d\n@@ -1289,9 +1292,9 @@\n-    __ sve_andv(v30, __ B, p0, z24);                   \/\/       andv b30, p0, z24.b\n-    __ sve_orv(v7, __ S, p1, z3);                      \/\/       orv s7, p1, z3.s\n-    __ sve_eorv(v7, __ D, p6, z23);                    \/\/       eorv d7, p6, z23.d\n-    __ sve_smaxv(v24, __ B, p7, z17);                  \/\/       smaxv b24, p7, z17.b\n-    __ sve_sminv(v10, __ H, p3, z29);                  \/\/       sminv h10, p3, z29.h\n-    __ sve_fminv(v8, __ S, p6, z28);                   \/\/       fminv s8, p6, z28.s\n-    __ sve_fmaxv(v30, __ D, p5, z30);                  \/\/       fmaxv d30, p5, z30.d\n-    __ sve_fadda(v0, __ D, p5, z7);                    \/\/       fadda d0, p5, d0, z7.d\n-    __ sve_uaddv(v28, __ H, p6, z21);                  \/\/       uaddv d28, p6, z21.h\n+    __ sve_andv(v3, __ D, p5, z7);                     \/\/       andv d3, p5, z7.d\n+    __ sve_orv(v23, __ D, p7, z24);                    \/\/       orv d23, p7, z24.d\n+    __ sve_eorv(v17, __ H, p0, z10);                   \/\/       eorv h17, p0, z10.h\n+    __ sve_smaxv(v29, __ D, p3, z8);                   \/\/       smaxv d29, p3, z8.d\n+    __ sve_sminv(v28, __ S, p0, z30);                  \/\/       sminv s28, p0, z30.s\n+    __ sve_fminv(v30, __ D, p5, z0);                   \/\/       fminv d30, p5, z0.d\n+    __ sve_fmaxv(v7, __ D, p7, z28);                   \/\/       fmaxv d7, p7, z28.d\n+    __ sve_fadda(v21, __ D, p2, z28);                  \/\/       fadda d21, p2, d21, z28.d\n+    __ sve_uaddv(v19, __ S, p1, z6);                   \/\/       uaddv d19, p1, z6.s\n@@ -1316,7 +1319,7 @@\n-    0x14000000,     0x17ffffd7,     0x14000437,     0x94000000,\n-    0x97ffffd4,     0x94000434,     0x3400000a,     0x34fffa2a,\n-    0x3400862a,     0x35000008,     0x35fff9c8,     0x350085c8,\n-    0xb400000b,     0xb4fff96b,     0xb400856b,     0xb500001d,\n-    0xb5fff91d,     0xb500851d,     0x10000013,     0x10fff8b3,\n-    0x100084b3,     0x90000013,     0x36300016,     0x3637f836,\n-    0x36308436,     0x3758000c,     0x375ff7cc,     0x375883cc,\n+    0x14000000,     0x17ffffd7,     0x1400043a,     0x94000000,\n+    0x97ffffd4,     0x94000437,     0x3400000a,     0x34fffa2a,\n+    0x3400868a,     0x35000008,     0x35fff9c8,     0x35008628,\n+    0xb400000b,     0xb4fff96b,     0xb40085cb,     0xb500001d,\n+    0xb5fff91d,     0xb500857d,     0x10000013,     0x10fff8b3,\n+    0x10008513,     0x90000013,     0x36300016,     0x3637f836,\n+    0x36308496,     0x3758000c,     0x375ff7cc,     0x3758842c,\n@@ -1327,13 +1330,13 @@\n-    0x540081a0,     0x54000001,     0x54fff541,     0x54008141,\n-    0x54000002,     0x54fff4e2,     0x540080e2,     0x54000002,\n-    0x54fff482,     0x54008082,     0x54000003,     0x54fff423,\n-    0x54008023,     0x54000003,     0x54fff3c3,     0x54007fc3,\n-    0x54000004,     0x54fff364,     0x54007f64,     0x54000005,\n-    0x54fff305,     0x54007f05,     0x54000006,     0x54fff2a6,\n-    0x54007ea6,     0x54000007,     0x54fff247,     0x54007e47,\n-    0x54000008,     0x54fff1e8,     0x54007de8,     0x54000009,\n-    0x54fff189,     0x54007d89,     0x5400000a,     0x54fff12a,\n-    0x54007d2a,     0x5400000b,     0x54fff0cb,     0x54007ccb,\n-    0x5400000c,     0x54fff06c,     0x54007c6c,     0x5400000d,\n-    0x54fff00d,     0x54007c0d,     0x5400000e,     0x54ffefae,\n-    0x54007bae,     0x5400000f,     0x54ffef4f,     0x54007b4f,\n+    0x54008200,     0x54000001,     0x54fff541,     0x540081a1,\n+    0x54000002,     0x54fff4e2,     0x54008142,     0x54000002,\n+    0x54fff482,     0x540080e2,     0x54000003,     0x54fff423,\n+    0x54008083,     0x54000003,     0x54fff3c3,     0x54008023,\n+    0x54000004,     0x54fff364,     0x54007fc4,     0x54000005,\n+    0x54fff305,     0x54007f65,     0x54000006,     0x54fff2a6,\n+    0x54007f06,     0x54000007,     0x54fff247,     0x54007ea7,\n+    0x54000008,     0x54fff1e8,     0x54007e48,     0x54000009,\n+    0x54fff189,     0x54007de9,     0x5400000a,     0x54fff12a,\n+    0x54007d8a,     0x5400000b,     0x54fff0cb,     0x54007d2b,\n+    0x5400000c,     0x54fff06c,     0x54007ccc,     0x5400000d,\n+    0x54fff00d,     0x54007c6d,     0x5400000e,     0x54ffefae,\n+    0x54007c0e,     0x5400000f,     0x54ffef4f,     0x54007baf,\n@@ -1410,177 +1413,178 @@\n-    0x1e22c341,     0x1e23c2f8,     0x1ee242ae,     0x1e6040ac,\n-    0x1e60c30c,     0x1e6143b8,     0x1e61c2bb,     0x1e6242d0,\n-    0x1ee0c385,     0x1ee14236,     0x1ee1c26d,     0x1e380373,\n-    0x9e3800d1,     0x1e7800ed,     0x9e78035c,     0x1e2200d1,\n-    0x9e220081,     0x1e62028d,     0x9e6202a6,     0x1e2402fa,\n-    0x9e64028d,     0x1e30037e,     0x9e7002aa,     0x1e260225,\n-    0x9e6601ab,     0x1e27028d,     0x9e6701da,     0x1e372080,\n-    0x1e7d22e0,     0x1e202188,     0x1e6021c8,     0x293a541b,\n-    0x296a1b6c,     0x69602e6e,     0xa93d79e2,     0xa9706137,\n-    0x29aa01fe,     0x29e6197a,     0x69f81262,     0xa9be7921,\n-    0xa9c25f7d,     0x28a4016d,     0x28f04159,     0x68fa255a,\n-    0xa8883033,     0xa8fe3f0e,     0x283057d1,     0x28422a37,\n-    0xa8362bde,     0xa84553c8,     0x0c4072e3,     0x4cdfa2de,\n-    0x0cc56fda,     0x4cdf2691,     0x0d40c30b,     0x4ddfca00,\n-    0x0dd0cef5,     0x4c408f47,     0x0cdf8727,     0x4d60c3c5,\n-    0x0dffc9fd,     0x4df7cfc4,     0x4cc648f7,     0x0c404895,\n-    0x4d40e489,     0x4ddfeb37,     0x0dc5ef4f,     0x4cdf072e,\n-    0x0cc60045,     0x0d60e3a9,     0x0dffe720,     0x0deaea0f,\n-    0x0e31ba51,     0x4e31bbdd,     0x0e71bb7a,     0x4e71bbbc,\n-    0x4eb1b841,     0x0e30ab9b,     0x4e30a820,     0x0e70aab4,\n-    0x4e70abbc,     0x4eb0aa0f,     0x6e30f9ac,     0x0e31a96a,\n-    0x2e31abbc,     0x4e31abbc,     0x6e31aa93,     0x0e71aaf6,\n-    0x2e71a96a,     0x4e71a8a4,     0x6e71abfe,     0x4eb1aab4,\n-    0x6eb1a928,     0x6eb0fbfe,     0x7e30fa51,     0x7e70f96a,\n-    0x7eb0fb9b,     0x7ef0f862,     0x0ea0cb38,     0x4ea0c8a4,\n-    0x4ee0c883,     0x2ea0c928,     0x6ea0caf6,     0x6ee0ca51,\n-    0x0ea0d9cd,     0x4ea0d8a4,     0x4ee0dbbc,     0x0ea0eb17,\n-    0x4ea0ead5,     0x4ee0eb59,     0x2ea0db38,     0x6ea0d883,\n-    0x6ee0db17,     0x0e20bb7a,     0x4e20bb17,     0x0e60b9ee,\n-    0x4e60bad5,     0x0ea0b883,     0x4ea0bb17,     0x4ee0b928,\n-    0x0ea0fb38,     0x4ea0fa93,     0x4ee0fa0f,     0x2ea0fa30,\n-    0x6ea0f862,     0x6ee0f841,     0x2ea1f820,     0x6ea1fb38,\n-    0x6ee1f8a4,     0x2e205883,     0x6e20598b,     0x0e201ffe,\n-    0x4e3d1f9b,     0x0eab1d49,     0x4ebb1f59,     0x2e241c62,\n-    0x6e2e1dac,     0x0e338651,     0x4e2087fe,     0x0e638441,\n-    0x4e6e85ac,     0x0ebe87bc,     0x4ea28420,     0x4ef38651,\n-    0x0e2ed5ac,     0x4e33d651,     0x4e77d6d5,     0x2e2e85ac,\n-    0x6e3d879b,     0x2e7f87dd,     0x6e6087fe,     0x2ea38441,\n-    0x6ebb8759,     0x6efd879b,     0x0ea6d4a4,     0x4ebfd7dd,\n-    0x4ee5d483,     0x0e289ce6,     0x4e3f9fdd,     0x0e7b9f59,\n-    0x4e739e51,     0x0eaa9d28,     0x4ea99d07,     0x2eaed5ac,\n-    0x6ea2d420,     0x6ef5d693,     0x2e23d441,     0x6e39d717,\n-    0x6e64d462,     0x2e22dc20,     0x6e2add28,     0x6e79df17,\n-    0x0e7b9759,     0x4e71960f,     0x0ebf97dd,     0x4ea59483,\n-    0x0e2ccd6a,     0x4e38cef6,     0x4e6ccd6a,     0x2e6694a4,\n-    0x6e739651,     0x2ea39441,     0x6ead958b,     0x0ea9cd07,\n-    0x4eaccd6a,     0x4ef1ce0f,     0x2e32fe30,     0x6e24fc62,\n-    0x6e6bfd49,     0x0e2d658b,     0x4e2e65ac,     0x0e7065ee,\n-    0x4e6f65cd,     0x0ea46462,     0x4ea864e6,     0x0e35a693,\n-    0x4e3ba759,     0x0e71a60f,     0x4e66a4a4,     0x0ea4a462,\n-    0x4ea6a4a4,     0x0e2df58b,     0x4e33f651,     0x4e76f6b4,\n-    0x0e326e30,     0x4e336e51,     0x0e6c6d6a,     0x4e766eb4,\n-    0x0eb86ef6,     0x4eae6dac,     0x0e3baf59,     0x4e39af17,\n-    0x0e7eafbc,     0x4e70adee,     0x0eacad6a,     0x4ebaaf38,\n-    0x0ea3f441,     0x4eadf58b,     0x4ee0f7fe,     0x2eaced6a,\n-    0x6eb1ee0f,     0x6ee9ed07,     0x0e243462,     0x4e253483,\n-    0x0e6f35cd,     0x4e753693,     0x0eb23630,     0x4eb23630,\n-    0x4ee53483,     0x0e233c41,     0x4e2d3d8b,     0x0e7f3fdd,\n-    0x4e673cc5,     0x0eaa3d28,     0x4eb03dee,     0x4efe3fbc,\n-    0x2e3f8fdd,     0x6e228c20,     0x2e768eb4,     0x6e698d07,\n-    0x2eb68eb4,     0x6eb98f17,     0x6efd8f9b,     0x2e3736d5,\n-    0x6e3c377a,     0x2e7a3738,     0x6e6634a4,     0x2ea33441,\n-    0x6eb836f6,     0x6ef23630,     0x2e203ffe,     0x6e273cc5,\n-    0x2e6d3d8b,     0x6e6a3d28,     0x2ebd3f9b,     0x6eb03dee,\n-    0x6efe3fbc,     0x0e37e6d5,     0x4e20e7fe,     0x4e73e651,\n-    0x2ea0e7fe,     0x6ea7e4c5,     0x6eefe5cd,     0x2e33e651,\n-    0x6e20e7fe,     0x6e73e651,     0x65d22e6d,     0x65903d35,\n-    0x65d03f48,     0x65d12943,     0x65d132f2,     0x65d32c6b,\n-    0x2592962b,     0x255b10d7,     0x25031ec6,     0x25063222,\n-    0x258b3d36,     0x250f8356,     0x24bcca6c,     0x243715dd,\n-    0x243b7f1f,     0x24a33149,     0xba5fd3e3,     0x3a5f03e5,\n-    0xfa411be4,     0x7a42cbe2,     0x93df03ff,     0xc820ffff,\n-    0x8822fc7f,     0xc8247cbf,     0x88267fff,     0x4e010fe0,\n-    0x5e040420,     0x4e081fe1,     0x4e0c1fe1,     0x4e0a1fe1,\n-    0x4e071fe1,     0x4e042c20,     0x4e062c20,     0x4e052c20,\n-    0x4e083c20,     0x0e0c3c20,     0x0e0a3c20,     0x0e073c20,\n-    0x9eae0020,     0x0f03f409,     0x6f03f40e,     0x4cc0ac3f,\n-    0x0ea1b820,     0x4e21c862,     0x4e61b8a4,     0x05a08020,\n-    0x05104fe0,     0x05505001,     0x05906fe2,     0x05d03005,\n-    0x05101fea,     0x05901feb,     0x04b0e3e0,     0x0470e7e1,\n-    0x042f9c20,     0x043f9c35,     0x047f9c20,     0x04ff9c20,\n-    0x04299420,     0x04319160,     0x0461943e,     0x04a19020,\n-    0x04038100,     0x040381a0,     0x040387e1,     0x04438be2,\n-    0x04c38fe3,     0x040181e0,     0x04018100,     0x04018621,\n-    0x04418b22,     0x04418822,     0x04818c23,     0x040081e0,\n-    0x04008120,     0x04008761,     0x04008621,     0x04408822,\n-    0x04808c23,     0x042053ff,     0x047f5401,     0x25208028,\n-    0x2538cfe0,     0x2578d001,     0x25b8efe2,     0x25f8f007,\n-    0x2538dfea,     0x25b8dfeb,     0xa400a3e0,     0xa420a7e0,\n-    0xa4484be0,     0xa467afe0,     0xa4a8a7ea,     0xa547a814,\n-    0xa4084ffe,     0xa55c53e0,     0xa5e1540b,     0xe400fbf6,\n-    0xe408ffff,     0xe420e7e0,     0xe4484be0,     0xe460efe0,\n-    0xe547e400,     0xe4014be0,     0xe4a84fe0,     0xe5f15000,\n-    0x858043e0,     0x85a043ff,     0xe59f5d08,     0x0420e3e9,\n-    0x0460e3ea,     0x04a0e3eb,     0x04e0e3ec,     0x25104042,\n-    0x25104871,     0x25904861,     0x25904c92,     0x05344020,\n-    0x05744041,     0x05b44062,     0x05f44083,     0x252c8840,\n-    0x253c1420,     0x25681572,     0x25a21ce3,     0x25ea1e34,\n-    0x253c0421,     0x25680572,     0x25a20ce3,     0x25ea0e34,\n-    0x0522c020,     0x05e6c0a4,     0x2401a001,     0x2443a051,\n-    0x24858881,     0x24c78cd1,     0x24850891,     0x24c70cc1,\n-    0x250f9001,     0x25508051,     0x25802491,     0x25df28c1,\n-    0x25850c81,     0x251e10d1,     0x65816001,     0x65c36051,\n-    0x65854891,     0x65c74cc1,     0x05733820,     0x05b238a4,\n-    0x05f138e6,     0x0570396a,     0x65d0a001,     0x65d6a443,\n-    0x65d4a826,     0x6594ac26,     0x6554ac26,     0x6556ac26,\n-    0x6552ac26,     0x65cbac85,     0x65caac01,     0x6589ac85,\n-    0x6588ac01,     0x65c9ac85,     0x65c8ac01,     0x65dea833,\n-    0x659ca509,     0x65d8a801,     0x65dcac01,     0x655cb241,\n-    0x0520a1e0,     0x0521a601,     0x052281e0,     0x05238601,\n-    0x04a14026,     0x042244a6,     0x046344a6,     0x04a444a6,\n-    0x04e544a7,     0x0568aca7,     0x05b23230,     0x853040af,\n-    0xc5b040af,     0xe57080af,     0xe5b080af,     0x25034440,\n-    0x254054c4,     0x25034640,     0x25415a05,     0x25834440,\n-    0x25c54489,     0x250b5d3a,     0x2550dc20,     0x2518e3e1,\n-    0x2518e021,     0x2518e0a1,     0x2518e121,     0x2518e1a1,\n-    0x2558e3e2,     0x2558e042,     0x2558e0c2,     0x2558e142,\n-    0x2598e3e3,     0x2598e063,     0x2598e0e3,     0x2598e163,\n-    0x25d8e3e4,     0x25d8e084,     0x25d8e104,     0x25d8e184,\n-    0x2518e407,     0x05214800,     0x05614800,     0x05a14800,\n-    0x05e14800,     0x05214c00,     0x05614c00,     0x05a14c00,\n-    0x05e14c00,     0x05304001,     0x05314001,     0x05a18610,\n-    0x05e18610,     0x05271e11,     0x6545e891,     0x6585e891,\n-    0x65c5e891,     0x6545c891,     0x6585c891,     0x65c5c891,\n-    0x45b0c210,     0x45f1c231,     0x1e601000,     0x1e603000,\n-    0x1e621000,     0x1e623000,     0x1e641000,     0x1e643000,\n-    0x1e661000,     0x1e663000,     0x1e681000,     0x1e683000,\n-    0x1e6a1000,     0x1e6a3000,     0x1e6c1000,     0x1e6c3000,\n-    0x1e6e1000,     0x1e6e3000,     0x1e701000,     0x1e703000,\n-    0x1e721000,     0x1e723000,     0x1e741000,     0x1e743000,\n-    0x1e761000,     0x1e763000,     0x1e781000,     0x1e783000,\n-    0x1e7a1000,     0x1e7a3000,     0x1e7c1000,     0x1e7c3000,\n-    0x1e7e1000,     0x1e7e3000,     0xf8308320,     0xf83a0057,\n-    0xf830108c,     0xf83c23be,     0xf83030db,     0xf82951fd,\n-    0xf82740e4,     0xf82f72e9,     0xf8286382,     0xf8b580bf,\n-    0xf8bb0220,     0xf8af1344,     0xf8a822dc,     0xf8bb333b,\n-    0xf8b75080,     0xf8a64010,     0xf8a4702f,     0xf8aa60a7,\n-    0xf8ea80fc,     0xf8f402b7,     0xf8e6110b,     0xf8f120df,\n-    0xf8f13182,     0xf8fe507d,     0xf8fb43b6,     0xf8ee738d,\n-    0xf8f160b8,     0xf862814e,     0xf870036b,     0xf877108c,\n-    0xf8762091,     0xf8613213,     0xf87051cd,     0xf86c4222,\n-    0xf86372f5,     0xf86560e6,     0xb833838d,     0xb83100d0,\n-    0xb822107d,     0xb82421e6,     0xb834318d,     0xb8345328,\n-    0xb8344013,     0xb82b70d8,     0xb83461df,     0xb8b08006,\n-    0xb8a7026f,     0xb8ba1149,     0xb8b722d5,     0xb8bc3062,\n-    0xb8af5293,     0xb8a743a4,     0xb8a77120,     0xb8b062f4,\n-    0xb8e48150,     0xb8f7032b,     0xb8e6121f,     0xb8ed2197,\n-    0xb8e1312e,     0xb8f55350,     0xb8ef4084,     0xb8f070c8,\n-    0xb8fe63a4,     0xb871835d,     0xb869004f,     0xb86b107d,\n-    0xb8672361,     0xb87531d0,     0xb86852d0,     0xb8794285,\n-    0xb87572f0,     0xb870629e,     0xce244413,     0xce131097,\n-    0xce738f37,     0xce887502,     0xce7e8238,     0xce7e8495,\n-    0xcec08141,     0xce608993,     0x2520d8c9,     0x2521dbf1,\n-    0x05801d06,     0x0540334d,     0x05009296,     0x2560d449,\n-    0x25a1dce7,     0x05806529,     0x05401e33,     0x05000d33,\n-    0x2520c030,     0x2561c823,     0x058004ef,     0x0542000f,\n-    0x0500986a,     0x2560d3e0,     0x2561d8fc,     0x05804943,\n-    0x05404cbc,     0x05007dda,     0x2560c311,     0x25a1d67d,\n-    0x05803634,     0x054394a1,     0x05000010,     0x2520d804,\n-    0x2521cbee,     0x05804534,     0x05400ecc,     0x050026a9,\n-    0x04360263,     0x042d06b9,     0x65c50327,     0x65800a31,\n-    0x658b0669,     0x0496ae2b,     0x04800f0b,     0x049a111e,\n-    0x04d09ace,     0x041b0916,     0x0419bd5b,     0x049abaae,\n-    0x04d902c0,     0x04939ba5,     0x04518191,     0x04900c1d,\n-    0x0497be82,     0x045ebd95,     0x049801c2,     0x05e78276,\n-    0x05e4999a,     0x04480035,     0x04ca0e73,     0x04810bd7,\n-    0x049cb693,     0x65c08fd4,     0x65cd9f3e,     0x65868d71,\n-    0x658794bc,     0x65828c4d,     0x049dae6a,     0x6582ac59,\n-    0x6580a29d,     0x6581bf94,     0x65cda9ad,     0x65818f61,\n-    0x65b89903,     0x65ae1941,     0x65fc38d4,     0x65ada770,\n-    0x65a1c93c,     0x65aefb41,     0x65b85e24,     0x65f97862,\n-    0x048d42cd,     0x04cb709b,     0x042f304f,     0x04b630fb,\n-    0x046a321b,     0x04e73390,     0x05786984,     0x052b6d48,\n-    0x65c896a4,     0x454fb064,     0x45d9b7a3,     0x04343b25,\n-    0x041a231e,     0x04982467,     0x04d93ae7,     0x04083e38,\n-    0x044a2faa,     0x65873b88,     0x65c637de,     0x65d834e0,\n-    0x04413abc,\n+    0x1e22c341,     0x1e23c2f8,     0x1ee242ae,     0x1ee2c0ac,\n+    0x1e60430c,     0x1e60c3b8,     0x1e6142bb,     0x1e61c2d0,\n+    0x1e624385,     0x1ee0c236,     0x1ee1426d,     0x1ee1c373,\n+    0x1e3800d1,     0x9e3800ed,     0x1e78035c,     0x9e7800d1,\n+    0x1ef80081,     0x9ef8028d,     0x1e2202a6,     0x9e2202fa,\n+    0x1e62028d,     0x9e62037e,     0x1e2402aa,     0x9e640225,\n+    0x1e3001ab,     0x9e70028d,     0x1e2601da,     0x9e6602e4,\n+    0x1e2703b7,     0x9e6701cc,     0x1e3b2200,     0x1e6022a0,\n+    0x1e2020c8,     0x1e602348,     0x293c30db,     0x29602e6e,\n+    0x697a31e0,     0xa9025ee9,     0xa975134f,     0x29ac20d1,\n+    0x29f20887,     0x69fe26ce,     0xa9b0530d,     0xa9c62d48,\n+    0x28b21618,     0x28f06920,     0x68f00a38,     0xa8bd45da,\n+    0xa8c357be,     0x28325d51,     0x286c1bda,     0xa804229e,\n+    0xa8437536,     0x0c40702c,     0x4cdfa200,     0x0cd36f35,\n+    0x4cdf2759,     0x0d40c1e9,     0x4ddfcb2c,     0x0dddcdc4,\n+    0x4c408e31,     0x0cdf8776,     0x4d60c302,     0x0dffc80a,\n+    0x4df6cd82,     0x4ccd49b4,     0x0c40496c,     0x4d40e5d1,\n+    0x4ddfeab9,     0x0ddbee14,     0x4cdf0420,     0x0cdd0360,\n+    0x0d60e231,     0x0dffe705,     0x0df4e8bb,     0x0e31b820,\n+    0x4e31bab4,     0x0e71bbbc,     0x4e71ba0f,     0x4eb1b9ac,\n+    0x0e30a96a,     0x4e30abbc,     0x0e70abbc,     0x4e70aa93,\n+    0x4eb0aaf6,     0x6e30f96a,     0x0e31a8a4,     0x2e31abfe,\n+    0x4e31aab4,     0x6e31a928,     0x0e71abfe,     0x2e71aa51,\n+    0x4e71a96a,     0x6e71ab9b,     0x4eb1a862,     0x6eb1ab38,\n+    0x6eb0f8a4,     0x7e30f883,     0x7e70f928,     0x7eb0faf6,\n+    0x7ef0fa51,     0x0ea0c9cd,     0x4ea0c8a4,     0x4ee0cbbc,\n+    0x2ea0cb17,     0x6ea0cad5,     0x6ee0cb59,     0x0ea0db38,\n+    0x4ea0d883,     0x4ee0db17,     0x0ea0eb7a,     0x4ea0eb17,\n+    0x4ee0e9ee,     0x2ea0dad5,     0x6ea0d883,     0x6ee0db17,\n+    0x0e20b928,     0x4e20bb38,     0x0e60ba93,     0x4e60ba0f,\n+    0x0ea0ba30,     0x4ea0b862,     0x4ee0b841,     0x0ea0f820,\n+    0x4ea0fb38,     0x4ee0f8a4,     0x2ea0f883,     0x6ea0f98b,\n+    0x6ee0fbfe,     0x2ea1fb9b,     0x6ea1f949,     0x6ee1fb59,\n+    0x2e205862,     0x6e2059ac,     0x0e331e51,     0x4e201ffe,\n+    0x0ea31c41,     0x4eae1dac,     0x2e3e1fbc,     0x6e221c20,\n+    0x0e338651,     0x4e2e85ac,     0x0e738651,     0x4e7786d5,\n+    0x0eae85ac,     0x4ebd879b,     0x4eff87dd,     0x0e20d7fe,\n+    0x4e23d441,     0x4e7bd759,     0x2e3d879b,     0x6e2684a4,\n+    0x2e7f87dd,     0x6e658483,     0x2ea884e6,     0x6ebf87dd,\n+    0x6efb8759,     0x0eb3d651,     0x4eaad528,     0x4ee9d507,\n+    0x0e2e9dac,     0x4e229c20,     0x0e759e93,     0x4e639c41,\n+    0x0eb99f17,     0x4ea49c62,     0x2ea2d420,     0x6eaad528,\n+    0x6ef9d717,     0x2e3bd759,     0x6e31d60f,     0x6e7fd7dd,\n+    0x2e25dc83,     0x6e2cdd6a,     0x6e78def6,     0x0e6c956a,\n+    0x4e6694a4,     0x0eb39651,     0x4ea39441,     0x0e2dcd8b,\n+    0x4e29cd07,     0x4e6ccd6a,     0x2e71960f,     0x6e729630,\n+    0x2ea49462,     0x6eab9549,     0x0eadcd8b,     0x4eaecdac,\n+    0x4ef0cdee,     0x2e2ffdcd,     0x6e24fc62,     0x6e68fce6,\n+    0x0e356693,     0x4e3b6759,     0x0e71660f,     0x4e6664a4,\n+    0x0ea46462,     0x4ea664a4,     0x0e2da58b,     0x4e33a651,\n+    0x0e76a6b4,     0x4e72a630,     0x0eb3a651,     0x4eaca56a,\n+    0x0e36f6b4,     0x4e38f6f6,     0x4e6ef5ac,     0x0e3b6f59,\n+    0x4e396f17,     0x0e7e6fbc,     0x4e706dee,     0x0eac6d6a,\n+    0x4eba6f38,     0x0e23ac41,     0x4e2dad8b,     0x0e60affe,\n+    0x4e6cad6a,     0x0eb1ae0f,     0x4ea9ad07,     0x0ea4f462,\n+    0x4ea5f483,     0x4eeff5cd,     0x2eb5ee93,     0x6eb2ee30,\n+    0x6ef2ee30,     0x0e253483,     0x4e233441,     0x0e6d358b,\n+    0x4e7f37dd,     0x0ea734c5,     0x4eaa3528,     0x4ef035ee,\n+    0x0e3e3fbc,     0x4e3f3fdd,     0x0e623c20,     0x4e763eb4,\n+    0x0ea93d07,     0x4eb63eb4,     0x4ef93f17,     0x2e3d8f9b,\n+    0x6e378ed5,     0x2e7c8f7a,     0x6e7a8f38,     0x2ea68ca4,\n+    0x6ea38c41,     0x6ef88ef6,     0x2e323630,     0x6e2037fe,\n+    0x2e6734c5,     0x6e6d358b,     0x2eaa3528,     0x6ebd379b,\n+    0x6ef035ee,     0x2e3e3fbc,     0x6e373ed5,     0x2e603ffe,\n+    0x6e733e51,     0x2ea03ffe,     0x6ea73cc5,     0x6eef3dcd,\n+    0x0e33e651,     0x4e20e7fe,     0x4e73e651,     0x2ebce77a,\n+    0x6eb5e693,     0x6ef1e60f,     0x2e2ee5ac,     0x6e2de58b,\n+    0x6e6be549,     0x65d23ba3,     0x65902bbe,     0x6590392a,\n+    0x65d12208,     0x65d131de,     0x65932ec9,     0x259d8983,\n+    0x25d5103b,     0x259d1448,     0x25dc3a85,     0x25083c7d,\n+    0x254b9e39,     0x24bfd4c7,     0x24f2985c,     0x24b222d5,\n+    0x24e2f700,     0xba5fd3e3,     0x3a5f03e5,     0xfa411be4,\n+    0x7a42cbe2,     0x93df03ff,     0xc820ffff,     0x8822fc7f,\n+    0xc8247cbf,     0x88267fff,     0x4e010fe0,     0x5e040420,\n+    0x4e081fe1,     0x4e0c1fe1,     0x4e0a1fe1,     0x4e071fe1,\n+    0x4e042c20,     0x4e062c20,     0x4e052c20,     0x4e083c20,\n+    0x0e0c3c20,     0x0e0a3c20,     0x0e073c20,     0x9eae0020,\n+    0x0f03f409,     0x6f03f40e,     0x4cc0ac3f,     0x0ea1b820,\n+    0x4e21c862,     0x4e61b8a4,     0x05a08020,     0x05104fe0,\n+    0x05505001,     0x05906fe2,     0x05d03005,     0x05101fea,\n+    0x05901feb,     0x04b0e3e0,     0x0470e7e1,     0x042f9c20,\n+    0x043f9c35,     0x047f9c20,     0x04ff9c20,     0x04299420,\n+    0x04319160,     0x0461943e,     0x04a19020,     0x04038100,\n+    0x040381a0,     0x040387e1,     0x04438be2,     0x04c38fe3,\n+    0x040181e0,     0x04018100,     0x04018621,     0x04418b22,\n+    0x04418822,     0x04818c23,     0x040081e0,     0x04008120,\n+    0x04008761,     0x04008621,     0x04408822,     0x04808c23,\n+    0x042053ff,     0x047f5401,     0x25208028,     0x2538cfe0,\n+    0x2578d001,     0x25b8efe2,     0x25f8f007,     0x2538dfea,\n+    0x25b8dfeb,     0xa400a3e0,     0xa420a7e0,     0xa4484be0,\n+    0xa467afe0,     0xa4a8a7ea,     0xa547a814,     0xa4084ffe,\n+    0xa55c53e0,     0xa5e1540b,     0xe400fbf6,     0xe408ffff,\n+    0xe420e7e0,     0xe4484be0,     0xe460efe0,     0xe547e400,\n+    0xe4014be0,     0xe4a84fe0,     0xe5f15000,     0x858043e0,\n+    0x85a043ff,     0xe59f5d08,     0x0420e3e9,     0x0460e3ea,\n+    0x04a0e3eb,     0x04e0e3ec,     0x25104042,     0x25104871,\n+    0x25904861,     0x25904c92,     0x05344020,     0x05744041,\n+    0x05b44062,     0x05f44083,     0x252c8840,     0x253c1420,\n+    0x25681572,     0x25a21ce3,     0x25ea1e34,     0x253c0421,\n+    0x25680572,     0x25a20ce3,     0x25ea0e34,     0x0522c020,\n+    0x05e6c0a4,     0x2401a001,     0x2443a051,     0x24858881,\n+    0x24c78cd1,     0x24850891,     0x24c70cc1,     0x250f9001,\n+    0x25508051,     0x25802491,     0x25df28c1,     0x25850c81,\n+    0x251e10d1,     0x65816001,     0x65c36051,     0x65854891,\n+    0x65c74cc1,     0x05733820,     0x05b238a4,     0x05f138e6,\n+    0x0570396a,     0x65d0a001,     0x65d6a443,     0x65d4a826,\n+    0x6594ac26,     0x6554ac26,     0x6556ac26,     0x6552ac26,\n+    0x65cbac85,     0x65caac01,     0x6589ac85,     0x6588ac01,\n+    0x65c9ac85,     0x65c8ac01,     0x65dea833,     0x659ca509,\n+    0x65d8a801,     0x65dcac01,     0x655cb241,     0x0520a1e0,\n+    0x0521a601,     0x052281e0,     0x05238601,     0x04a14026,\n+    0x042244a6,     0x046344a6,     0x04a444a6,     0x04e544a7,\n+    0x0568aca7,     0x05b23230,     0x853040af,     0xc5b040af,\n+    0xe57080af,     0xe5b080af,     0x25034440,     0x254054c4,\n+    0x25034640,     0x25415a05,     0x25834440,     0x25c54489,\n+    0x250b5d3a,     0x2550dc20,     0x2518e3e1,     0x2518e021,\n+    0x2518e0a1,     0x2518e121,     0x2518e1a1,     0x2558e3e2,\n+    0x2558e042,     0x2558e0c2,     0x2558e142,     0x2598e3e3,\n+    0x2598e063,     0x2598e0e3,     0x2598e163,     0x25d8e3e4,\n+    0x25d8e084,     0x25d8e104,     0x25d8e184,     0x2518e407,\n+    0x05214800,     0x05614800,     0x05a14800,     0x05e14800,\n+    0x05214c00,     0x05614c00,     0x05a14c00,     0x05e14c00,\n+    0x05304001,     0x05314001,     0x05a18610,     0x05e18610,\n+    0x05271e11,     0x6545e891,     0x6585e891,     0x65c5e891,\n+    0x6545c891,     0x6585c891,     0x65c5c891,     0x45b0c210,\n+    0x45f1c231,     0x1e601000,     0x1e603000,     0x1e621000,\n+    0x1e623000,     0x1e641000,     0x1e643000,     0x1e661000,\n+    0x1e663000,     0x1e681000,     0x1e683000,     0x1e6a1000,\n+    0x1e6a3000,     0x1e6c1000,     0x1e6c3000,     0x1e6e1000,\n+    0x1e6e3000,     0x1e701000,     0x1e703000,     0x1e721000,\n+    0x1e723000,     0x1e741000,     0x1e743000,     0x1e761000,\n+    0x1e763000,     0x1e781000,     0x1e783000,     0x1e7a1000,\n+    0x1e7a3000,     0x1e7c1000,     0x1e7c3000,     0x1e7e1000,\n+    0x1e7e3000,     0xf830808c,     0xf83c03be,     0xf83010db,\n+    0xf82921fd,     0xf82730e4,     0xf82f52e9,     0xf8284382,\n+    0xf83570bf,     0xf83b6220,     0xf8af8344,     0xf8a802dc,\n+    0xf8bb133b,     0xf8b72080,     0xf8a63010,     0xf8a4502f,\n+    0xf8aa40a7,     0xf8aa70fc,     0xf8b462b7,     0xf8e6810b,\n+    0xf8f100df,     0xf8f11182,     0xf8fe207d,     0xf8fb33b6,\n+    0xf8ee538d,     0xf8f140b8,     0xf8e2714e,     0xf8f0636b,\n+    0xf877808c,     0xf8760091,     0xf8611213,     0xf87021cd,\n+    0xf86c3222,     0xf86352f5,     0xf86540e6,     0xf873738d,\n+    0xf87160d0,     0xb822807d,     0xb82401e6,     0xb834118d,\n+    0xb8342328,     0xb8343013,     0xb82b50d8,     0xb83441df,\n+    0xb8307006,     0xb827626f,     0xb8ba8149,     0xb8b702d5,\n+    0xb8bc1062,     0xb8af2293,     0xb8a733a4,     0xb8a75120,\n+    0xb8b042f4,     0xb8a47150,     0xb8b7632b,     0xb8e6821f,\n+    0xb8ed0197,     0xb8e1112e,     0xb8f52350,     0xb8ef3084,\n+    0xb8f050c8,     0xb8fe43a4,     0xb8f1735d,     0xb8e9604f,\n+    0xb86b807d,     0xb8670361,     0xb87511d0,     0xb86822d0,\n+    0xb8793285,     0xb87552f0,     0xb870429e,     0xb8747080,\n+    0xb8736098,     0xce376493,     0xce082053,     0xce718f0e,\n+    0xce84fabe,     0xce738141,     0xce69840c,     0xcec08307,\n+    0xce7b8891,     0x2560dbe6,     0x2561d097,     0x0580299e,\n+    0x0542305e,     0x050026b3,     0x2560ce69,     0x25a1c1ab,\n+    0x05803cb8,     0x05407851,     0x05001e20,     0x2560d06f,\n+    0x2561de64,     0x05800ec5,     0x05401e3a,     0x050287b3,\n+    0x25a0c7e3,     0x25e1ce37,     0x05806535,     0x05423051,\n+    0x05025a82,     0x2520d474,     0x2521dae2,     0x05800d31,\n+    0x05403635,     0x05004cb7,     0x2560d174,     0x2561c35d,\n+    0x05809863,     0x054030f8,     0x05000ed6,     0x04e700ad,\n+    0x04b106a5,     0x65c90060,     0x658b08eb,     0x658b0631,\n+    0x0496b3d8,     0x04c011c8,     0x045a1ed6,     0x04d08768,\n+    0x04db01ca,     0x0419b415,     0x04dab8b6,     0x0419123d,\n+    0x04538fac,     0x04d19040,     0x04d016b4,     0x0417a84c,\n+    0x041eb6ce,     0x04d81b53,     0x052796ac,     0x05a48a61,\n+    0x04481af3,     0x048a127e,     0x04410694,     0x04dcb7de,\n+    0x65809239,     0x65cd8f8b,     0x658681a5,     0x65878542,\n+    0x65828733,     0x049da3a2,     0x65c2a694,     0x6580adbc,\n+    0x6581bc2d,     0x65cda07b,     0x65819928,     0x65e189d9,\n+    0x65f30799,     0x65e13da6,     0x65a1a82b,     0x65a2d9db,\n+    0x65a2f31d,     0x65bc4338,     0x65ef75a3,     0x049a4570,\n+    0x041b7022,     0x043b33d6,     0x04b032aa,     0x046432a7,\n+    0x04e83178,     0x05a4680b,     0x05246e95,     0x65c88c6f,\n+    0x4585b379,     0x451eb559,     0x042438f8,     0x04da34e3,\n+    0x04d83f17,     0x04592151,     0x04c82d1d,     0x048a23dc,\n+    0x65c7341e,     0x65c63f87,     0x65d82b95,     0x048124d3,\n+\n","filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h","additions":644,"deletions":640,"binary":false,"changes":1284,"status":"modified"},{"patch":"@@ -197,0 +197,33 @@\n+\n+    @Test\n+    @IR(counts = {IRNode.CONV_HF2I, \"> 0\"},\n+        applyIfCPUFeatureAnd = {\"fphp\", \"true\", \"asimdhp\", \"true\"})\n+    public void testConvHF2I() {\n+        int result = 0;\n+        for (int i = 0; i < count; i++) {\n+            result = shortBitsToFloat16(src[i]).intValue();\n+            dst[i] = (short)result;\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.CONV_HF2D, \"> 0\"},\n+        applyIfCPUFeatureAnd = {\"fphp\", \"true\", \"asimdhp\", \"true\"})\n+    public void testConvHF2D() {\n+        double result = 0;\n+        for (int i = 0; i < count; i++) {\n+            result = shortBitsToFloat16(src[i]).doubleValue();\n+            dst[i] = Float.floatToFloat16((float)result);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.CONV_HF2L, \"> 0\"},\n+        applyIfCPUFeatureAnd = {\"fphp\", \"true\", \"asimdhp\", \"true\"})\n+    public void testConvHF2L() {\n+        long result = 0;\n+        for (int i = 0; i < count; i++) {\n+            result = shortBitsToFloat16(src[i]).longValue();\n+            dst[i] = (short)result;\n+        }\n+    }\n","filename":"test\/hotspot\/jtreg\/compiler\/intrinsics\/float16\/TestFP16ScalarOps.java","additions":33,"deletions":0,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -495,0 +495,15 @@\n+    public static final String CONV_HF2I = PREFIX + \"CONV_HF2I\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(CONV_HF2I, \"ConvHF2I\");\n+    }\n+\n+    public static final String CONV_HF2D = PREFIX + \"CONV_HF2D\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(CONV_HF2D, \"ConvHF2D\");\n+    }\n+\n+    public static final String CONV_HF2L = PREFIX + \"CONV_HF2L\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(CONV_HF2L, \"ConvHF2L\");\n+    }\n+\n@@ -1987,0 +2002,15 @@\n+    public static final String VECTOR_CAST_HF2I = VECTOR_PREFIX + \"VECTOR_CAST_HF2I\" + POSTFIX;\n+    static {\n+        vectorNode(VECTOR_CAST_HF2I, \"VectorCastHF2X\", TYPE_INT);\n+    }\n+\n+    public static final String VECTOR_CAST_HF2L = VECTOR_PREFIX + \"VECTOR_CAST_HF2L\" + POSTFIX;\n+    static {\n+        vectorNode(VECTOR_CAST_HF2L, \"VectorCastHF2X\", TYPE_LONG);\n+    }\n+\n+    public static final String VECTOR_CAST_HF2D = VECTOR_PREFIX + \"VECTOR_CAST_HF2D\" + POSTFIX;\n+    static {\n+        vectorNode(VECTOR_CAST_HF2D, \"VectorCastHF2X\", TYPE_DOUBLE);\n+    }\n+\n@@ -1989,1 +2019,1 @@\n-        vectorNode(VECTOR_CAST_HF2F, \"VectorCastHF2F\", TYPE_FLOAT);\n+        vectorNode(VECTOR_CAST_HF2F, \"VectorCastHF2X\", TYPE_FLOAT);\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/IRNode.java","additions":31,"deletions":1,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+\n@@ -45,0 +46,5 @@\n+    private int[] iout;\n+    private long[] lout;\n+    private double[] dout;\n+    private float[] fout;\n+\n@@ -56,0 +62,1 @@\n+\n@@ -57,0 +64,5 @@\n+        iout = new int[LEN];\n+        lout = new long[LEN];\n+        dout = new double[LEN];\n+        fout = new float[LEN];\n+\n@@ -82,1 +94,1 @@\n-                throw new RuntimeException(\"Invalid result: output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n+                throw new RuntimeException(\"Invalid result for add operation : output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n@@ -104,1 +116,1 @@\n-                throw new RuntimeException(\"Invalid result: output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n+                throw new RuntimeException(\"Invalid result for Float16 sub operation : output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n@@ -126,1 +138,1 @@\n-                throw new RuntimeException(\"Invalid result: output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n+                throw new RuntimeException(\"Invalid result for Float16 mul operation : output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n@@ -148,1 +160,1 @@\n-                throw new RuntimeException(\"Invalid result: output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n+                throw new RuntimeException(\"Invalid result for Float16 divide operation : output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n@@ -170,1 +182,1 @@\n-                throw new RuntimeException(\"Invalid result: output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n+                throw new RuntimeException(\"Invalid result for Float16 min operation : output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n@@ -192,1 +204,1 @@\n-                throw new RuntimeException(\"Invalid result: output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n+                throw new RuntimeException(\"Invalid result for Float16 max operation : output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n@@ -214,1 +226,1 @@\n-                throw new RuntimeException(\"Invalid result: output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n+                throw new RuntimeException(\"Invalid result for Float16 Abs operation : output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n@@ -236,1 +248,1 @@\n-                throw new RuntimeException(\"Invalid result: output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n+                throw new RuntimeException(\"Invalid result for Float16 Negate operation : output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n@@ -258,1 +270,1 @@\n-                throw new RuntimeException(\"Invalid result: output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n+                throw new RuntimeException(\"Invalid result for Float16 sqrt operation : output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n@@ -280,1 +292,68 @@\n-                throw new RuntimeException(\"Invalid result: output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n+                throw new RuntimeException(\"Invalid result for Float16 FMA operation : output[\" + i + \"] = \" + float16ToRawShortBits(output[i]) + \" != \" + float16ToRawShortBits(expected));\n+            }\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(10000)\n+    @IR(counts = {IRNode.VECTOR_CAST_HF2I, \">= 1\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"})\n+    @IR(counts = {IRNode.VECTOR_CAST_HF2I, \">= 1\"},\n+        applyIfCPUFeatureAnd = {\"fphp\", \"true\", \"asimdhp\", \"true\"})\n+    public void vectorFloat16ToInt() {\n+        for (int i = 0; i < LEN; ++i) {\n+            iout[i] = input1[i].intValue();\n+        }\n+    }\n+\n+    @Check(test=\"vectorFloat16ToInt\")\n+    public void checkResultFloat16ToInt() {\n+        int expected;\n+        for (int i = 0; i < LEN; ++i) {\n+            expected = input1[i].intValue();\n+            if (expected != iout[i]) {\n+                throw new RuntimeException(\"Invalid result for Float16 to int conversion : iout[\" + i + \"] = \" + iout[i] + \" != \" + expected);\n+            }\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(10000)\n+    @IR(counts = {IRNode.VECTOR_CAST_HF2L, \">= 1\"},\n+        applyIf = {\"MaxVectorSize\", \"> 16\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"})\n+    public void vectorFloat16ToLong() {\n+        for (int i = 0; i < LEN; ++i) {\n+            lout[i] = input1[i].longValue();\n+        }\n+    }\n+\n+    @Check(test=\"vectorFloat16ToLong\")\n+    public void checkResultFloat16ToLong() {\n+        long expected;\n+        for (int i = 0; i < LEN; ++i) {\n+            expected = input1[i].longValue();\n+            if (expected != lout[i]) {\n+                throw new RuntimeException(\"Invalid result for Float16 to long conversion : lout[\" + i + \"] = \" + lout[i] + \" != \" + expected);\n+            }\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(10000)\n+    @IR(counts = {IRNode.VECTOR_CAST_HF2D, \">= 1\"},\n+        applyIf = {\"MaxVectorSize\", \"> 16\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"})\n+    public void vectorFloat16ToDouble() {\n+        for (int i = 0; i < LEN; ++i) {\n+            dout[i] = input1[i].doubleValue();\n+        }\n+    }\n+\n+    @Check(test=\"vectorFloat16ToDouble\")\n+    public void checkResultFloat16ToDouble() {\n+        double expected;\n+        for (int i = 0; i < LEN; ++i) {\n+            expected = input1[i].doubleValue();\n+            if (expected != dout[i]) {\n+                throw new RuntimeException(\"Invalid result for Float16 to double conversion : dout[\" + i + \"] = \" + dout[i] + \" != \" + expected);\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/TestFloat16VectorOps.java","additions":89,"deletions":10,"binary":false,"changes":99,"status":"modified"},{"patch":"@@ -58,1 +58,1 @@\n-    \/\/ fails due to an assertion error when testing for the source type in vectorCastNode::opcode() for\n+    \/\/ fails due to an assertion error when testing for the source type in VectorCastNode::opcode() for\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/TestFloat16VectorReinterpretConv.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -149,0 +149,38 @@\n+    public static void test_fp16ToInt(Float16 fp16) {\n+        int expected, actual;\n+        actual = fp16.intValue();\n+        expected = Float.valueOf(fp16.floatValue()).intValue();\n+\n+        if (expected != actual) {\n+            System.out.println(\"Incorrest result for FP16 to int conversion. Expected value:\" + expected + \" Actual value: \" + actual);\n+        }\n+    }\n+\n+    public static void test_fp16ToLong(Float16 fp16) {\n+        long expected, actual;\n+        actual = fp16.longValue();\n+        expected = Float.valueOf(fp16.floatValue()).longValue();\n+\n+        if (expected != actual) {\n+            System.out.println(\"Incorrest result for FP16 to long conversion. Expected value:\" + expected + \" Actual value: \" + actual);\n+        }\n+    }\n+\n+    public static void test_fp16ToDouble(Float16 fp16) {\n+        double expected, actual;\n+        actual = fp16.doubleValue();\n+        expected = Float.valueOf(fp16.floatValue()).doubleValue();\n+\n+        if (expected != actual) {\n+            System.out.println(\"Incorrest result for FP16 to double conversion. Expected value:\" + expected + \" Actual value: \" + actual);\n+        }\n+    }\n+\n+    public static void test_conversions(Float16 inp []) {\n+        for (int i = 0; i < inp.length; i++) {\n+            test_fp16ToInt(inp[i]);\n+            test_fp16ToLong(inp[i]);\n+            test_fp16ToDouble(inp[i]);\n+        }\n+    }\n+\n@@ -179,0 +217,4 @@\n+\n+            \/\/ Test conversions from FP16 to int\/long\/double\n+            test_conversions(input1);\n+            test_conversions(special_values);\n","filename":"test\/jdk\/java\/lang\/Float16\/FP16ScalarOperations.java","additions":42,"deletions":0,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -42,0 +42,4 @@\n+    double  [] dres;\n+    int     [] ires;\n+    long    [] lres;\n+\n@@ -50,0 +54,4 @@\n+        dres      = new double[vectorDim];\n+        ires      = new int[vectorDim];\n+        lres      = new long[vectorDim];\n+\n@@ -235,0 +243,21 @@\n+\n+    @Benchmark\n+    public void fp16ToDouble() {\n+        for (int i = 0; i < vectorDim; i++) {\n+            dres[i] = vector1[i].doubleValue();\n+        }\n+    }\n+\n+    @Benchmark\n+    public void fp16ToInt() {\n+        for (int i = 0; i < vectorDim; i++) {\n+            ires[i] = vector1[i].intValue();\n+        }\n+    }\n+\n+    @Benchmark\n+    public void fp16ToLong() {\n+        for (int i = 0; i < vectorDim; i++) {\n+            lres[i] = vector1[i].longValue();\n+        }\n+    }\n","filename":"test\/micro\/org\/openjdk\/bench\/java\/lang\/Float16OpsBenchmark.java","additions":29,"deletions":0,"binary":false,"changes":29,"status":"modified"}]}