{"files":[{"patch":"@@ -600,3 +600,1 @@\n-  CREATE_BUILDJDK=false\n-  EXTERNAL_BUILDJDK=false\n-  BUILD_JDK_FOUND=\"no\"\n+  EXTERNAL_BUILDJDK_PATH=\"\"\n@@ -604,0 +602,1 @@\n+    BUILD_JDK_FOUND=no\n@@ -611,11 +610,1 @@\n-    EXTERNAL_BUILDJDK=true\n-  else\n-    if test \"x$COMPILE_TYPE\" = \"xcross\"; then\n-      BUILD_JDK=\"\\$(BUILDJDK_OUTPUTDIR)\/jdk\"\n-      BUILD_JDK_FOUND=yes\n-      CREATE_BUILDJDK=true\n-      AC_MSG_CHECKING([for Build JDK])\n-      AC_MSG_RESULT([yes, will build it for the host platform])\n-    else\n-      BUILD_JDK=\"\\$(JDK_OUTPUTDIR)\"\n-      BUILD_JDK_FOUND=yes\n+    if test \"x$BUILD_JDK_FOUND\" != \"xyes\"; then\n@@ -623,1 +612,2 @@\n-      AC_MSG_RESULT([yes, will use output dir])\n+      AC_MSG_RESULT([no])\n+      AC_MSG_ERROR([Could not find a suitable Build JDK])\n@@ -625,0 +615,1 @@\n+    EXTERNAL_BUILDJDK_PATH=\"$BUILD_JDK\"\n@@ -627,18 +618,1 @@\n-  # Since these tools do not yet exist, we cannot use UTIL_FIXUP_EXECUTABLE to\n-  # detect the need of fixpath\n-  JMOD=\"$BUILD_JDK\/bin\/jmod\"\n-  UTIL_ADD_FIXPATH(JMOD)\n-  JLINK=\"$BUILD_JDK\/bin\/jlink\"\n-  UTIL_ADD_FIXPATH(JLINK)\n-  AC_SUBST(JMOD)\n-  AC_SUBST(JLINK)\n-\n-  if test \"x$BUILD_JDK_FOUND\" != \"xyes\"; then\n-    AC_MSG_CHECKING([for Build JDK])\n-    AC_MSG_RESULT([no])\n-    AC_MSG_ERROR([Could not find a suitable Build JDK])\n-  fi\n-\n-  AC_SUBST(CREATE_BUILDJDK)\n-  AC_SUBST(BUILD_JDK)\n-  AC_SUBST(EXTERNAL_BUILDJDK)\n+  AC_SUBST(EXTERNAL_BUILDJDK_PATH)\n","filename":"make\/autoconf\/boot-jdk.m4","additions":7,"deletions":33,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -1177,3 +1177,3 @@\n-            version: \"7.5.1\",\n-            build_number: \"1\",\n-            file: \"bundles\/jtreg-7.5.1+1.zip\",\n+            version: \"8\",\n+            build_number: \"2\",\n+            file: \"bundles\/jtreg-8+2.zip\",\n","filename":"make\/conf\/jib-profiles.js","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -59,1 +59,1 @@\n-    JVM_LDFLAGS_FEATURES += $(call SET_EXECUTABLE_ORIGIN,\/..)\n+    JVM_LDFLAGS_FEATURES += $(call SetExecutableOrigin,\/..)\n","filename":"make\/hotspot\/lib\/JvmFeatures.gmk","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -36,1 +36,0 @@\n-include gensrc\/GensrcExceptions.gmk\n","filename":"make\/modules\/java.base\/Gensrc.gmk","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2795,0 +2795,87 @@\n+\n+\/\/ Vector expand implementation. Elements from the src vector are expanded into\n+\/\/ the dst vector under the control of the vector mask.\n+\/\/ Since there are no native instructions directly corresponding to expand before\n+\/\/ SVE2p2, the following implementations mainly leverages the TBL instruction to\n+\/\/ implement expand. To compute the index input for TBL, the prefix sum algorithm\n+\/\/ (https:\/\/en.wikipedia.org\/wiki\/Prefix_sum) is used. The same algorithm is used\n+\/\/ for NEON and SVE, but with different instructions where appropriate.\n+\n+\/\/ Vector expand implementation for NEON.\n+\/\/\n+\/\/ An example of 128-bit Byte vector:\n+\/\/   Data direction: high <== low\n+\/\/   Input:\n+\/\/         src   = g  f  e  d  c  b  a  9  8  7  6  5  4  3  2  1\n+\/\/         mask  = 0  0 -1 -1  0  0 -1 -1  0  0 -1 -1  0  0 -1 -1\n+\/\/   Expected result:\n+\/\/         dst   = 0  0  8  7  0  0  6  5  0  0  4  3  0  0  2  1\n+void C2_MacroAssembler::vector_expand_neon(FloatRegister dst, FloatRegister src, FloatRegister mask,\n+                                           FloatRegister tmp1, FloatRegister tmp2, BasicType bt,\n+                                           int vector_length_in_bytes) {\n+  assert(vector_length_in_bytes <= 16, \"the vector length in bytes for NEON must be <= 16\");\n+  assert_different_registers(dst, src, mask, tmp1, tmp2);\n+  \/\/ Since the TBL instruction only supports byte table, we need to\n+  \/\/ compute indices in byte type for all types.\n+  SIMD_Arrangement size = vector_length_in_bytes == 16 ? T16B : T8B;\n+  \/\/ tmp1 =  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n+  dup(tmp1, size, zr);\n+  \/\/ dst  =  0  0  1  1  0  0  1  1  0  0  1  1  0  0  1  1\n+  negr(dst, size, mask);\n+  \/\/ Calculate vector index for TBL with prefix sum algorithm.\n+  \/\/ dst  =  8  8  8  7  6  6  6  5  4  4  4  3  2  2  2  1\n+  for (int i = 1; i < vector_length_in_bytes; i <<= 1) {\n+    ext(tmp2, size, tmp1, dst, vector_length_in_bytes - i);\n+    addv(dst, size, tmp2, dst);\n+  }\n+  \/\/ tmp2 =  0  0 -1 -1  0  0 -1 -1  0  0 -1 -1  0  0 -1 -1\n+  orr(tmp2, size, mask, mask);\n+  \/\/ tmp2 =  0  0  8  7  0  0  6  5  0  0  4  3  0  0  2  1\n+  bsl(tmp2, size, dst, tmp1);\n+  \/\/ tmp1 =  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n+  movi(tmp1, size, 1);\n+  \/\/ dst  = -1 -1  7  6 -1 -1  5  4 -1 -1  3  2 -1 -1  1  0\n+  subv(dst, size, tmp2, tmp1);\n+  \/\/ dst  =  0  0  8  7  0  0  6  5  0  0  4  3  0  0  2  1\n+  tbl(dst, size, src, 1, dst);\n+}\n+\n+\/\/ Vector expand implementation for SVE.\n+\/\/\n+\/\/ An example of 128-bit Short vector:\n+\/\/   Data direction: high <== low\n+\/\/   Input:\n+\/\/         src   = gf ed cb a9 87 65 43 21\n+\/\/         pg    = 00 01 00 01 00 01 00 01\n+\/\/   Expected result:\n+\/\/         dst   = 00 87 00 65 00 43 00 21\n+void C2_MacroAssembler::vector_expand_sve(FloatRegister dst, FloatRegister src, PRegister pg,\n+                                          FloatRegister tmp1, FloatRegister tmp2, BasicType bt,\n+                                          int vector_length_in_bytes) {\n+  assert(UseSVE > 0, \"expand implementation only for SVE\");\n+  assert_different_registers(dst, src, tmp1, tmp2);\n+  SIMD_RegVariant size = elemType_to_regVariant(bt);\n+\n+  \/\/ tmp1 = 00 00 00 00 00 00 00 00\n+  sve_dup(tmp1, size, 0);\n+  sve_movprfx(tmp2, tmp1);\n+  \/\/ tmp2 = 00 01 00 01 00 01 00 01\n+  sve_cpy(tmp2, size, pg, 1, true);\n+  \/\/ Calculate vector index for TBL with prefix sum algorithm.\n+  \/\/ tmp2 = 04 04 03 03 02 02 01 01\n+  for (int i = type2aelembytes(bt); i < vector_length_in_bytes; i <<= 1) {\n+    sve_movprfx(dst, tmp1);\n+    \/\/ The EXT instruction operates on the full-width sve register. The correct\n+    \/\/ index calculation method is:\n+    \/\/ vector_length_in_bytes - i + MaxVectorSize - vector_length_in_bytes =>\n+    \/\/ MaxVectorSize - i.\n+    sve_ext(dst, tmp2, MaxVectorSize - i);\n+    sve_add(tmp2, size, dst, tmp2);\n+  }\n+  \/\/ dst  = 00 04 00 03 00 02 00 01\n+  sve_sel(dst, size, pg, tmp2, tmp1);\n+  \/\/ dst  = -1 03 -1 02 -1 01 -1 00\n+  sve_sub(dst, size, 1);\n+  \/\/ dst  = 00 87 00 65 00 43 00 21\n+  sve_tbl(dst, size, src, dst);\n+}\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":87,"deletions":0,"binary":false,"changes":87,"status":"modified"},{"patch":"@@ -209,0 +209,6 @@\n+  void vector_expand_neon(FloatRegister dst, FloatRegister src, FloatRegister mask,\n+                          FloatRegister tmp1, FloatRegister tmp2, BasicType bt,\n+                          int vector_length_in_bytes);\n+  void vector_expand_sve(FloatRegister dst, FloatRegister src, PRegister pg,\n+                         FloatRegister tmp1, FloatRegister tmp2, BasicType bt,\n+                         int vector_length_in_bytes);\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -89,9 +89,42 @@\n-void G1BarrierSetAssembler::gen_write_ref_array_post_barrier(MacroAssembler* masm, DecoratorSet decorators,\n-                                                             Register start, Register count, Register scratch, RegSet saved_regs) {\n-  __ push(saved_regs, sp);\n-  assert_different_registers(start, count, scratch);\n-  assert_different_registers(c_rarg0, count);\n-  __ mov(c_rarg0, start);\n-  __ mov(c_rarg1, count);\n-  __ call_VM_leaf(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_array_post_entry), 2);\n-  __ pop(saved_regs, sp);\n+void G1BarrierSetAssembler::gen_write_ref_array_post_barrier(MacroAssembler* masm,\n+                                                             DecoratorSet decorators,\n+                                                             Register start,\n+                                                             Register count,\n+                                                             Register scratch,\n+                                                             RegSet saved_regs) {\n+\n+  Label done;\n+  Label loop;\n+  Label next;\n+\n+  __ cbz(count, done);\n+\n+  \/\/ Calculate the number of card marks to set. Since the object might start and\n+  \/\/ end within a card, we need to calculate this via the card table indexes of\n+  \/\/ the actual start and last addresses covered by the object.\n+  \/\/ Temporarily use the count register for the last element address.\n+  __ lea(count, Address(start, count, Address::lsl(LogBytesPerHeapOop))); \/\/ end = start + count << LogBytesPerHeapOop\n+  __ sub(count, count, BytesPerHeapOop);                                  \/\/ Use last element address for end.\n+\n+  __ lsr(start, start, CardTable::card_shift());\n+  __ lsr(count, count, CardTable::card_shift());\n+  __ sub(count, count, start);                                            \/\/ Number of bytes to mark - 1.\n+\n+  \/\/ Add card table base offset to start.\n+  __ ldr(scratch, Address(rthread, in_bytes(G1ThreadLocalData::card_table_base_offset())));\n+  __ add(start, start, scratch);\n+\n+  __ bind(loop);\n+  if (UseCondCardMark) {\n+    __ ldrb(scratch, Address(start, count));\n+    \/\/ Instead of loading clean_card_val and comparing, we exploit the fact that\n+    \/\/ the LSB of non-clean cards is always 0, and the LSB of clean cards 1.\n+    __ tbz(scratch, 0, next);\n+  }\n+  static_assert(G1CardTable::dirty_card_val() == 0, \"must be to use zr\");\n+  __ strb(zr, Address(start, count));\n+  __ bind(next);\n+  __ subs(count, count, 1);\n+  __ br(Assembler::GE, loop);\n+\n+  __ bind(done);\n@@ -215,7 +248,11 @@\n-static void generate_post_barrier_fast_path(MacroAssembler* masm,\n-                                            const Register store_addr,\n-                                            const Register new_val,\n-                                            const Register tmp1,\n-                                            const Register tmp2,\n-                                            Label& done,\n-                                            bool new_val_may_be_null) {\n+static void generate_post_barrier(MacroAssembler* masm,\n+                                  const Register store_addr,\n+                                  const Register new_val,\n+                                  const Register thread,\n+                                  const Register tmp1,\n+                                  const Register tmp2,\n+                                  Label& done,\n+                                  bool new_val_may_be_null) {\n+  assert(thread == rthread, \"must be\");\n+  assert_different_registers(store_addr, new_val, thread, tmp1, tmp2, noreg, rscratch1);\n+\n@@ -230,1 +267,1 @@\n-  \/\/ Storing region crossing non-null, is card young?\n+  \/\/ Storing region crossing non-null.\n@@ -232,24 +269,10 @@\n-  __ load_byte_map_base(tmp2);                           \/\/ tmp2 := card table base address\n-  __ add(tmp1, tmp1, tmp2);                              \/\/ tmp1 := card address\n-  __ ldrb(tmp2, Address(tmp1));                          \/\/ tmp2 := card\n-  __ cmpw(tmp2, (int)G1CardTable::g1_young_card_val());  \/\/ tmp2 := card == young_card_val?\n-}\n-static void generate_post_barrier_slow_path(MacroAssembler* masm,\n-                                            const Register thread,\n-                                            const Register tmp1,\n-                                            const Register tmp2,\n-                                            Label& done,\n-                                            Label& runtime) {\n-  __ membar(Assembler::StoreLoad);  \/\/ StoreLoad membar\n-  __ ldrb(tmp2, Address(tmp1));     \/\/ tmp2 := card\n-  __ cbzw(tmp2, done);\n-  \/\/ Storing a region crossing, non-null oop, card is clean.\n-  \/\/ Dirty card and log.\n-  STATIC_ASSERT(CardTable::dirty_card_val() == 0);\n-  __ strb(zr, Address(tmp1));       \/\/ *(card address) := dirty_card_val\n-  generate_queue_test_and_insertion(masm,\n-                                    G1ThreadLocalData::dirty_card_queue_index_offset(),\n-                                    G1ThreadLocalData::dirty_card_queue_buffer_offset(),\n-                                    runtime,\n-                                    thread, tmp1, tmp2, rscratch1);\n-  __ b(done);\n+  Address card_table_addr(thread, in_bytes(G1ThreadLocalData::card_table_base_offset()));\n+  __ ldr(tmp2, card_table_addr);                         \/\/ tmp2 := card table base address\n+  if (UseCondCardMark) {\n+    __ ldrb(rscratch1, Address(tmp1, tmp2));             \/\/ rscratch1 := card\n+    \/\/ Instead of loading clean_card_val and comparing, we exploit the fact that\n+    \/\/ the LSB of non-clean cards is always 0, and the LSB of clean cards 1.\n+    __ tbz(rscratch1, 0, done);\n+  }\n+  static_assert(G1CardTable::dirty_card_val() == 0, \"must be to use zr\");\n+  __ strb(zr, Address(tmp1, tmp2));                      \/\/ *(card address) := dirty_card_val\n@@ -265,33 +288,1 @@\n-  assert(thread == rthread, \"must be\");\n-  assert_different_registers(store_addr, new_val, thread, tmp1, tmp2,\n-                             rscratch1);\n-  assert(store_addr != noreg && new_val != noreg && tmp1 != noreg\n-         && tmp2 != noreg, \"expecting a register\");\n-\n-  Label runtime;\n-\n-  generate_post_barrier_fast_path(masm, store_addr, new_val, tmp1, tmp2, done, true \/* new_val_may_be_null *\/);\n-  \/\/ If card is young, jump to done\n-  __ br(Assembler::EQ, done);\n-  generate_post_barrier_slow_path(masm, thread, tmp1, tmp2, done, runtime);\n-\n-  __ bind(runtime);\n-\n-  \/\/ save the live input values\n-  RegSet saved = RegSet::of(store_addr);\n-  FloatRegSet fsaved;\n-\n-  \/\/ Barriers might be emitted when converting between (scalarized) calling\n-  \/\/ conventions for inline types. Save all argument registers before calling\n-  \/\/ into the runtime.\n-  \/\/ TODO 8366717 Without this, r11 is corrupted below and it holds the array of pre-allocated value objects in the C2I adapter...\n-  \/\/ Check if__ push_call_clobbered_registers() is sufficient\n-  assert_different_registers(rscratch1, tmp1); \/\/ push_CPU_state trashes rscratch1\n-  __ enter();\n-  __ push_CPU_state(true);\n-\n-  __ call_VM_leaf(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_field_post_entry), tmp1, thread);\n-\n-  __ pop_CPU_state(true);\n-  __ leave();\n-\n+  generate_post_barrier(masm, store_addr, new_val, thread, tmp1, tmp2, done, false \/* new_val_may_be_null *\/);\n@@ -358,32 +349,4 @@\n-                                                     G1PostBarrierStubC2* stub) {\n-  assert(thread == rthread, \"must be\");\n-  assert_different_registers(store_addr, new_val, thread, tmp1, tmp2,\n-                             rscratch1);\n-  assert(store_addr != noreg && new_val != noreg && tmp1 != noreg\n-         && tmp2 != noreg, \"expecting a register\");\n-\n-  stub->initialize_registers(thread, tmp1, tmp2);\n-\n-  bool new_val_may_be_null = (stub->barrier_data() & G1C2BarrierPostNotNull) == 0;\n-  generate_post_barrier_fast_path(masm, store_addr, new_val, tmp1, tmp2, *stub->continuation(), new_val_may_be_null);\n-  \/\/ If card is not young, jump to stub (slow path)\n-  __ br(Assembler::NE, *stub->entry());\n-\n-  __ bind(*stub->continuation());\n-}\n-\n-void G1BarrierSetAssembler::generate_c2_post_barrier_stub(MacroAssembler* masm,\n-                                                          G1PostBarrierStubC2* stub) const {\n-  Assembler::InlineSkippedInstructionsCounter skip_counter(masm);\n-  Label runtime;\n-  Register thread = stub->thread();\n-  Register tmp1 = stub->tmp1(); \/\/ tmp1 holds the card address.\n-  Register tmp2 = stub->tmp2();\n-  assert(stub->tmp3() == noreg, \"not needed in this platform\");\n-\n-  __ bind(*stub->entry());\n-  generate_post_barrier_slow_path(masm, thread, tmp1, tmp2, *stub->continuation(), runtime);\n-\n-  __ bind(runtime);\n-  generate_c2_barrier_runtime_call(masm, stub, tmp1, CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_field_post_entry));\n-  __ b(*stub->continuation());\n+                                                     bool new_val_may_be_null) {\n+  Label done;\n+  generate_post_barrier(masm, store_addr, new_val, thread, tmp1, tmp2, done, new_val_may_be_null);\n+  __ bind(done);\n@@ -502,12 +465,0 @@\n-void G1BarrierSetAssembler::gen_post_barrier_stub(LIR_Assembler* ce, G1PostBarrierStub* stub) {\n-  G1BarrierSetC1* bs = (G1BarrierSetC1*)BarrierSet::barrier_set()->barrier_set_c1();\n-  __ bind(*stub->entry());\n-  assert(stub->addr()->is_register(), \"Precondition.\");\n-  assert(stub->new_val()->is_register(), \"Precondition.\");\n-  Register new_val_reg = stub->new_val()->as_register();\n-  __ cbz(new_val_reg, *stub->continuation());\n-  ce->store_parameter(stub->addr()->as_pointer_register(), 0);\n-  __ far_call(RuntimeAddress(bs->post_barrier_c1_runtime_code_blob()->code_begin()));\n-  __ b(*stub->continuation());\n-}\n-\n@@ -516,0 +467,11 @@\n+void G1BarrierSetAssembler::g1_write_barrier_post_c1(MacroAssembler* masm,\n+                                                     Register store_addr,\n+                                                     Register new_val,\n+                                                     Register thread,\n+                                                     Register tmp1,\n+                                                     Register tmp2) {\n+  Label done;\n+  generate_post_barrier(masm, store_addr, new_val, thread, tmp1, tmp2, done, true \/* new_val_may_be_null *\/);\n+  masm->bind(done);\n+}\n+\n@@ -567,68 +529,0 @@\n-void G1BarrierSetAssembler::generate_c1_post_barrier_runtime_stub(StubAssembler* sasm) {\n-  __ prologue(\"g1_post_barrier\", false);\n-\n-  \/\/ arg0: store_address\n-  Address store_addr(rfp, 2*BytesPerWord);\n-\n-  BarrierSet* bs = BarrierSet::barrier_set();\n-  CardTableBarrierSet* ctbs = barrier_set_cast<CardTableBarrierSet>(bs);\n-  CardTable* ct = ctbs->card_table();\n-\n-  Label done;\n-  Label runtime;\n-\n-  \/\/ At this point we know new_value is non-null and the new_value crosses regions.\n-  \/\/ Must check to see if card is already dirty\n-\n-  const Register thread = rthread;\n-\n-  Address queue_index(thread, in_bytes(G1ThreadLocalData::dirty_card_queue_index_offset()));\n-  Address buffer(thread, in_bytes(G1ThreadLocalData::dirty_card_queue_buffer_offset()));\n-\n-  const Register card_offset = rscratch2;\n-  \/\/ LR is free here, so we can use it to hold the byte_map_base.\n-  const Register byte_map_base = lr;\n-\n-  assert_different_registers(card_offset, byte_map_base, rscratch1);\n-\n-  __ load_parameter(0, card_offset);\n-  __ lsr(card_offset, card_offset, CardTable::card_shift());\n-  __ load_byte_map_base(byte_map_base);\n-  __ ldrb(rscratch1, Address(byte_map_base, card_offset));\n-  __ cmpw(rscratch1, (int)G1CardTable::g1_young_card_val());\n-  __ br(Assembler::EQ, done);\n-\n-  assert((int)CardTable::dirty_card_val() == 0, \"must be 0\");\n-\n-  __ membar(Assembler::StoreLoad);\n-  __ ldrb(rscratch1, Address(byte_map_base, card_offset));\n-  __ cbzw(rscratch1, done);\n-\n-  \/\/ storing region crossing non-null, card is clean.\n-  \/\/ dirty card and log.\n-  __ strb(zr, Address(byte_map_base, card_offset));\n-\n-  \/\/ Convert card offset into an address in card_addr\n-  Register card_addr = card_offset;\n-  __ add(card_addr, byte_map_base, card_addr);\n-\n-  __ ldr(rscratch1, queue_index);\n-  __ cbz(rscratch1, runtime);\n-  __ sub(rscratch1, rscratch1, wordSize);\n-  __ str(rscratch1, queue_index);\n-\n-  \/\/ Reuse LR to hold buffer_addr\n-  const Register buffer_addr = lr;\n-\n-  __ ldr(buffer_addr, buffer);\n-  __ str(card_addr, Address(buffer_addr, rscratch1));\n-  __ b(done);\n-\n-  __ bind(runtime);\n-  __ push_call_clobbered_registers();\n-  __ call_VM_leaf(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_field_post_entry), card_addr, thread);\n-  __ pop_call_clobbered_registers();\n-  __ bind(done);\n-  __ epilogue();\n-}\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/g1\/g1BarrierSetAssembler_aarch64.cpp","additions":80,"deletions":186,"binary":false,"changes":266,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2024, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -64,3 +64,2 @@\n-                               Register tmp2,\n-                               RegSet preserve = RegSet()) {\n-  if (!G1PostBarrierStubC2::needs_barrier(node)) {\n+                               Register tmp2) {\n+  if (!G1BarrierStubC2::needs_post_barrier(node)) {\n@@ -71,5 +70,2 @@\n-  G1PostBarrierStubC2* const stub = G1PostBarrierStubC2::create(node);\n-  for (RegSetIterator<Register> reg = preserve.begin(); *reg != noreg; ++reg) {\n-    stub->preserve(*reg);\n-  }\n-  g1_asm->g1_write_barrier_post_c2(masm, store_addr, new_val, rthread, tmp1, tmp2, stub);\n+  bool new_val_may_be_null = G1BarrierStubC2::post_new_val_may_be_null(node);\n+  g1_asm->g1_write_barrier_post_c2(masm, store_addr, new_val, rthread, tmp1, tmp2, new_val_may_be_null);\n@@ -101,2 +97,1 @@\n-                      $tmp3$$Register \/* tmp2 *\/,\n-                      RegSet::of($mem$$Register, $src$$Register, $tmp4$$Register) \/* preserve *\/);\n+                      $tmp3$$Register \/* tmp2 *\/);\n@@ -155,2 +150,1 @@\n-                       $tmp3$$Register \/* tmp2 *\/,\n-                       RegSet::of($src$$Register, $tmp4$$Register) \/* preserve *\/);\n+                       $tmp3$$Register \/* tmp2 *\/);\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/g1\/g1_aarch64.ad","additions":7,"deletions":13,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -963,1 +963,1 @@\n-                                            AdapterHandlerEntry* handler,\n+                                            address entry_address[AdapterBlob::ENTRY_COUNT],\n@@ -966,1 +966,2 @@\n-  address i2c_entry = __ pc();\n+\n+  entry_address[AdapterBlob::I2C] = __ pc();\n@@ -978,2 +979,2 @@\n-  address c2i_unverified_entry        = __ pc();\n-  address c2i_unverified_inline_entry = __ pc();\n+  entry_address[AdapterBlob::C2I_Unverified] = __ pc();\n+  entry_address[AdapterBlob::C2I_Unverified_Inline] = __ pc();\n@@ -989,2 +990,2 @@\n-  address c2i_no_clinit_check_entry = nullptr;\n-  address c2i_inline_ro_entry = __ pc();\n+  entry_address[AdapterBlob::C2I_No_Clinit_Check] = nullptr;\n+  entry_address[AdapterBlob::C2I_Inline_RO] = __ pc();\n@@ -993,2 +994,2 @@\n-    gen_c2i_adapter(masm, sig_cc_ro, regs_cc_ro, \/* requires_clinit_barrier = *\/ false, c2i_no_clinit_check_entry,\n-                    skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, \/* alloc_inline_receiver = *\/ false);\n+    gen_c2i_adapter(masm, sig_cc_ro, regs_cc_ro, \/* requires_clinit_barrier = *\/ false, entry_address[AdapterBlob::C2I_No_Clinit_Check],\n+                    skip_fixup, entry_address[AdapterBlob::I2C], oop_maps, frame_complete, frame_size_in_words, \/* alloc_inline_receiver = *\/ false);\n@@ -999,4 +1000,4 @@\n-  address c2i_entry        = __ pc();\n-  address c2i_inline_entry = __ pc();\n-  gen_c2i_adapter(masm, sig_cc, regs_cc, \/* requires_clinit_barrier = *\/ true, c2i_no_clinit_check_entry,\n-                  skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, \/* alloc_inline_receiver = *\/ true);\n+  entry_address[AdapterBlob::C2I]        = __ pc();\n+  entry_address[AdapterBlob::C2I_Inline] = __ pc();\n+  gen_c2i_adapter(masm, sig_cc, regs_cc, \/* requires_clinit_barrier = *\/ true, entry_address[AdapterBlob::C2I_No_Clinit_Check],\n+                  skip_fixup, entry_address[AdapterBlob::I2C], oop_maps, frame_complete, frame_size_in_words, \/* alloc_inline_receiver = *\/ true);\n@@ -1006,1 +1007,1 @@\n-    c2i_unverified_inline_entry = __ pc();\n+    entry_address[AdapterBlob::C2I_Unverified_Inline] = __ pc();\n@@ -1010,3 +1011,3 @@\n-    c2i_inline_entry = __ pc();\n-    gen_c2i_adapter(masm, sig, regs, \/* requires_clinit_barrier = *\/ true, c2i_no_clinit_check_entry,\n-                    inline_entry_skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, \/* alloc_inline_receiver = *\/ false);\n+    entry_address[AdapterBlob::C2I_Inline] = __ pc();\n+    gen_c2i_adapter(masm, sig, regs, \/* requires_clinit_barrier = *\/ true, entry_address[AdapterBlob::C2I_No_Clinit_Check],\n+                    inline_entry_skip_fixup, entry_address[AdapterBlob::I2C], oop_maps, frame_complete, frame_size_in_words, \/* alloc_inline_receiver = *\/ false);\n@@ -1021,7 +1022,1 @@\n-    entry_offset[0] = 0; \/\/ i2c_entry offset\n-    entry_offset[1] = c2i_entry - i2c_entry;\n-    entry_offset[2] = c2i_inline_entry - i2c_entry;\n-    entry_offset[3] = c2i_inline_ro_entry - i2c_entry;\n-    entry_offset[4] = c2i_unverified_entry - i2c_entry;\n-    entry_offset[5] = c2i_unverified_inline_entry - i2c_entry;\n-    entry_offset[6] = c2i_no_clinit_check_entry - i2c_entry;\n+    AdapterHandlerLibrary::address_to_offset(entry_address, entry_offset);\n@@ -1030,3 +1025,0 @@\n-\n-  handler->set_entry_points(i2c_entry, c2i_entry, c2i_inline_entry, c2i_inline_ro_entry, c2i_unverified_entry,\n-                            c2i_unverified_inline_entry, c2i_no_clinit_check_entry);\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":18,"deletions":26,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -92,5 +92,30 @@\n-  __ push_call_clobbered_registers(false \/* save_fpu *\/);\n-  if (c_rarg0 == count) { \/\/ On win64 c_rarg0 == rcx\n-    assert_different_registers(c_rarg1, addr);\n-    __ mov(c_rarg1, count);\n-    __ mov(c_rarg0, addr);\n+  Label done;\n+\n+  __ testptr(count, count);\n+  __ jcc(Assembler::zero, done);\n+\n+  \/\/ Calculate end address in \"count\".\n+  Address::ScaleFactor scale = UseCompressedOops ? Address::times_4 : Address::times_8;\n+  __ leaq(count, Address(addr, count, scale));\n+\n+  \/\/ Calculate start card address in \"addr\".\n+  __ shrptr(addr, CardTable::card_shift());\n+\n+  Register thread = r15_thread;\n+\n+  __ movptr(tmp, Address(thread, in_bytes(G1ThreadLocalData::card_table_base_offset())));\n+  __ addptr(addr, tmp);\n+\n+  \/\/ Calculate address of card of last word in the array.\n+  __ subptr(count, 1);\n+  __ shrptr(count, CardTable::card_shift());\n+  __ addptr(count, tmp);\n+\n+  Label loop;\n+  \/\/ Iterate from start card to end card (inclusive).\n+  __ bind(loop);\n+\n+  Label is_clean_card;\n+  if (UseCondCardMark) {\n+    __ cmpb(Address(addr, 0), G1CardTable::clean_card_val());\n+    __ jcc(Assembler::equal, is_clean_card);\n@@ -98,3 +123,1 @@\n-    assert_different_registers(c_rarg0, count);\n-    __ mov(c_rarg0, addr);\n-    __ mov(c_rarg1, count);\n+   __ movb(Address(addr, 0), G1CardTable::dirty_card_val());\n@@ -102,2 +125,13 @@\n-  __ call_VM_leaf(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_array_post_entry), 2);\n-  __ pop_call_clobbered_registers(false \/* save_fpu *\/);\n+  Label next_card;\n+  __ bind(next_card);\n+  __ addptr(addr, sizeof(CardTable::CardValue));\n+  __ cmpptr(addr, count);\n+  __ jcc(Assembler::belowEqual, loop);\n+  __ jmp(done);\n+\n+  __ bind(is_clean_card);\n+  \/\/ Card was clean. Dirty card and go to next..\n+  __ movb(Address(addr, 0), G1CardTable::dirty_card_val());\n+  __ jmp(next_card);\n+\n+  __ bind(done);\n@@ -185,1 +219,0 @@\n-\n@@ -268,8 +301,11 @@\n-static void generate_post_barrier_fast_path(MacroAssembler* masm,\n-                                            const Register store_addr,\n-                                            const Register new_val,\n-                                            const Register tmp,\n-                                            const Register tmp2,\n-                                            Label& done,\n-                                            bool new_val_may_be_null) {\n-  CardTableBarrierSet* ct = barrier_set_cast<CardTableBarrierSet>(BarrierSet::barrier_set());\n+static void generate_post_barrier(MacroAssembler* masm,\n+                                  const Register store_addr,\n+                                  const Register new_val,\n+                                  const Register tmp1,\n+                                  Label& done,\n+                                  bool new_val_may_be_null) {\n+\n+  assert_different_registers(store_addr, new_val, tmp1, noreg);\n+\n+  Register thread = r15_thread;\n+\n@@ -277,3 +313,3 @@\n-  __ movptr(tmp, store_addr);                                    \/\/ tmp := store address\n-  __ xorptr(tmp, new_val);                                       \/\/ tmp := store address ^ new value\n-  __ shrptr(tmp, G1HeapRegion::LogOfHRGrainBytes);               \/\/ ((store address ^ new value) >> LogOfHRGrainBytes) == 0?\n+  __ movptr(tmp1, store_addr);                                    \/\/ tmp1 := store address\n+  __ xorptr(tmp1, new_val);                                       \/\/ tmp1 := store address ^ new value\n+  __ shrptr(tmp1, G1HeapRegion::LogOfHRGrainBytes);               \/\/ ((store address ^ new value) >> LogOfHRGrainBytes) == 0?\n@@ -281,0 +317,1 @@\n+\n@@ -283,1 +320,1 @@\n-    __ cmpptr(new_val, NULL_WORD);                               \/\/ new value == null?\n+    __ cmpptr(new_val, NULL_WORD);                                \/\/ new value == null?\n@@ -286,18 +323,9 @@\n-  \/\/ Storing region crossing non-null, is card young?\n-  __ movptr(tmp, store_addr);                                    \/\/ tmp := store address\n-  __ shrptr(tmp, CardTable::card_shift());                       \/\/ tmp := card address relative to card table base\n-  \/\/ Do not use ExternalAddress to load 'byte_map_base', since 'byte_map_base' is NOT\n-  \/\/ a valid address and therefore is not properly handled by the relocation code.\n-  __ movptr(tmp2, (intptr_t)ct->card_table()->byte_map_base());  \/\/ tmp2 := card table base address\n-  __ addptr(tmp, tmp2);                                          \/\/ tmp := card address\n-  __ cmpb(Address(tmp, 0), G1CardTable::g1_young_card_val());    \/\/ *(card address) == young_card_val?\n-}\n-static void generate_post_barrier_slow_path(MacroAssembler* masm,\n-                                            const Register thread,\n-                                            const Register tmp,\n-                                            const Register tmp2,\n-                                            Label& done,\n-                                            Label& runtime) {\n-  __ membar(Assembler::Membar_mask_bits(Assembler::StoreLoad));  \/\/ StoreLoad membar\n-  __ cmpb(Address(tmp, 0), G1CardTable::dirty_card_val());       \/\/ *(card address) == dirty_card_val?\n-  __ jcc(Assembler::equal, done);\n+  __ movptr(tmp1, store_addr);                                    \/\/ tmp1 := store address\n+  __ shrptr(tmp1, CardTable::card_shift());                       \/\/ tmp1 := card address relative to card table base\n+\n+  Address card_table_addr(thread, in_bytes(G1ThreadLocalData::card_table_base_offset()));\n+  __ addptr(tmp1, card_table_addr);                               \/\/ tmp1 := card address\n+  if (UseCondCardMark) {\n+    __ cmpb(Address(tmp1, 0), G1CardTable::clean_card_val());     \/\/ *(card address) == clean_card_val?\n+    __ jcc(Assembler::notEqual, done);\n+  }\n@@ -306,8 +334,2 @@\n-  \/\/ Dirty card and log.\n-  __ movb(Address(tmp, 0), G1CardTable::dirty_card_val());       \/\/ *(card address) := dirty_card_val\n-  generate_queue_insertion(masm,\n-                           G1ThreadLocalData::dirty_card_queue_index_offset(),\n-                           G1ThreadLocalData::dirty_card_queue_buffer_offset(),\n-                           runtime,\n-                           thread, tmp, tmp2);\n-  __ jmp(done);\n+  \/\/ Dirty card.\n+  __ movb(Address(tmp1, 0), G1CardTable::dirty_card_val());       \/\/ *(card address) := dirty_card_val\n@@ -319,4 +341,1 @@\n-                                                  Register tmp,\n-                                                  Register tmp2) {\n-  const Register thread = r15_thread;\n-\n+                                                  Register tmp) {\n@@ -324,36 +343,1 @@\n-  Label runtime;\n-\n-  generate_post_barrier_fast_path(masm, store_addr, new_val, tmp, tmp2, done, true \/* new_val_may_be_null *\/);\n-  \/\/ If card is young, jump to done\n-  __ jcc(Assembler::equal, done);\n-  generate_post_barrier_slow_path(masm, thread, tmp, tmp2, done, runtime);\n-\n-  __ bind(runtime);\n-  \/\/ Barriers might be emitted when converting between (scalarized) calling conventions for inline\n-  \/\/ types. Save all argument registers before calling into the runtime.\n-  \/\/ TODO 8366717: use push_set() (see JDK-8283327 push\/pop_call_clobbered_registers & aarch64)\n-  __ pusha();\n-  __ subptr(rsp, 64);\n-  __ movdbl(Address(rsp, 0),  j_farg0);\n-  __ movdbl(Address(rsp, 8),  j_farg1);\n-  __ movdbl(Address(rsp, 16), j_farg2);\n-  __ movdbl(Address(rsp, 24), j_farg3);\n-  __ movdbl(Address(rsp, 32), j_farg4);\n-  __ movdbl(Address(rsp, 40), j_farg5);\n-  __ movdbl(Address(rsp, 48), j_farg6);\n-  __ movdbl(Address(rsp, 56), j_farg7);\n-\n-  __ call_VM_leaf(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_field_post_entry), tmp, thread);\n-\n-  \/\/ Restore registers\n-  __ movdbl(j_farg0, Address(rsp, 0));\n-  __ movdbl(j_farg1, Address(rsp, 8));\n-  __ movdbl(j_farg2, Address(rsp, 16));\n-  __ movdbl(j_farg3, Address(rsp, 24));\n-  __ movdbl(j_farg4, Address(rsp, 32));\n-  __ movdbl(j_farg5, Address(rsp, 40));\n-  __ movdbl(j_farg6, Address(rsp, 48));\n-  __ movdbl(j_farg7, Address(rsp, 56));\n-  __ addptr(rsp, 64);\n-  __ popa();\n-\n+  generate_post_barrier(masm, store_addr, new_val, tmp, done, true \/* new_val_may_be_null *\/);\n@@ -422,28 +406,4 @@\n-                                                     Register tmp2,\n-                                                     G1PostBarrierStubC2* stub) {\n-  const Register thread = r15_thread;\n-  stub->initialize_registers(thread, tmp, tmp2);\n-\n-  bool new_val_may_be_null = (stub->barrier_data() & G1C2BarrierPostNotNull) == 0;\n-  generate_post_barrier_fast_path(masm, store_addr, new_val, tmp, tmp2, *stub->continuation(), new_val_may_be_null);\n-  \/\/ If card is not young, jump to stub (slow path)\n-  __ jcc(Assembler::notEqual, *stub->entry());\n-\n-  __ bind(*stub->continuation());\n-}\n-\n-void G1BarrierSetAssembler::generate_c2_post_barrier_stub(MacroAssembler* masm,\n-                                                          G1PostBarrierStubC2* stub) const {\n-  Assembler::InlineSkippedInstructionsCounter skip_counter(masm);\n-  Label runtime;\n-  Register thread = stub->thread();\n-  Register tmp = stub->tmp1(); \/\/ tmp holds the card address.\n-  Register tmp2 = stub->tmp2();\n-  assert(stub->tmp3() == noreg, \"not needed in this platform\");\n-\n-  __ bind(*stub->entry());\n-  generate_post_barrier_slow_path(masm, thread, tmp, tmp2, *stub->continuation(), runtime);\n-\n-  __ bind(runtime);\n-  generate_c2_barrier_runtime_call(masm, stub, tmp, CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_field_post_entry));\n-  __ jmp(*stub->continuation());\n+                                                     bool new_val_may_be_null) {\n+  Label done;\n+  generate_post_barrier(masm, store_addr, new_val, tmp, done, new_val_may_be_null);\n+  __ bind(done);\n@@ -497,2 +457,1 @@\n-                            tmp3 \/* tmp *\/,\n-                            tmp2 \/* tmp2 *\/);\n+                            tmp3 \/* tmp *\/);\n@@ -532,13 +491,0 @@\n-void G1BarrierSetAssembler::gen_post_barrier_stub(LIR_Assembler* ce, G1PostBarrierStub* stub) {\n-  G1BarrierSetC1* bs = (G1BarrierSetC1*)BarrierSet::barrier_set()->barrier_set_c1();\n-  __ bind(*stub->entry());\n-  assert(stub->addr()->is_register(), \"Precondition.\");\n-  assert(stub->new_val()->is_register(), \"Precondition.\");\n-  Register new_val_reg = stub->new_val()->as_register();\n-  __ cmpptr(new_val_reg, NULL_WORD);\n-  __ jcc(Assembler::equal, *stub->continuation());\n-  ce->store_parameter(stub->addr()->as_pointer_register(), 0);\n-  __ call(RuntimeAddress(bs->post_barrier_c1_runtime_code_blob()->code_begin()));\n-  __ jmp(*stub->continuation());\n-}\n-\n@@ -547,0 +493,11 @@\n+void G1BarrierSetAssembler::g1_write_barrier_post_c1(MacroAssembler* masm,\n+                                                     Register store_addr,\n+                                                     Register new_val,\n+                                                     Register thread,\n+                                                     Register tmp1,\n+                                                     Register tmp2 \/* unused on x86 *\/) {\n+  Label done;\n+  generate_post_barrier(masm, store_addr, new_val, tmp1, done, true \/* new_val_may_be_null *\/);\n+  masm->bind(done);\n+}\n+\n@@ -611,72 +568,0 @@\n-void G1BarrierSetAssembler::generate_c1_post_barrier_runtime_stub(StubAssembler* sasm) {\n-  __ prologue(\"g1_post_barrier\", false);\n-\n-  CardTableBarrierSet* ct =\n-    barrier_set_cast<CardTableBarrierSet>(BarrierSet::barrier_set());\n-\n-  Label done;\n-  Label enqueued;\n-  Label runtime;\n-\n-  \/\/ At this point we know new_value is non-null and the new_value crosses regions.\n-  \/\/ Must check to see if card is already dirty\n-\n-  const Register thread = r15_thread;\n-\n-  Address queue_index(thread, in_bytes(G1ThreadLocalData::dirty_card_queue_index_offset()));\n-  Address buffer(thread, in_bytes(G1ThreadLocalData::dirty_card_queue_buffer_offset()));\n-\n-  __ push_ppx(rax);\n-  __ push_ppx(rcx);\n-\n-  const Register cardtable = rax;\n-  const Register card_addr = rcx;\n-\n-  __ load_parameter(0, card_addr);\n-  __ shrptr(card_addr, CardTable::card_shift());\n-  \/\/ Do not use ExternalAddress to load 'byte_map_base', since 'byte_map_base' is NOT\n-  \/\/ a valid address and therefore is not properly handled by the relocation code.\n-  __ movptr(cardtable, (intptr_t)ct->card_table()->byte_map_base());\n-  __ addptr(card_addr, cardtable);\n-\n-  __ cmpb(Address(card_addr, 0), G1CardTable::g1_young_card_val());\n-  __ jcc(Assembler::equal, done);\n-\n-  __ membar(Assembler::Membar_mask_bits(Assembler::StoreLoad));\n-  __ cmpb(Address(card_addr, 0), CardTable::dirty_card_val());\n-  __ jcc(Assembler::equal, done);\n-\n-  \/\/ storing region crossing non-null, card is clean.\n-  \/\/ dirty card and log.\n-\n-  __ movb(Address(card_addr, 0), CardTable::dirty_card_val());\n-\n-  const Register tmp = rdx;\n-  __ push_ppx(rdx);\n-\n-  __ movptr(tmp, queue_index);\n-  __ testptr(tmp, tmp);\n-  __ jcc(Assembler::zero, runtime);\n-  __ subptr(tmp, wordSize);\n-  __ movptr(queue_index, tmp);\n-  __ addptr(tmp, buffer);\n-  __ movptr(Address(tmp, 0), card_addr);\n-  __ jmp(enqueued);\n-\n-  __ bind(runtime);\n-  __ push_call_clobbered_registers();\n-\n-  __ call_VM_leaf(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_field_post_entry), card_addr, thread);\n-\n-  __ pop_call_clobbered_registers();\n-\n-  __ bind(enqueued);\n-  __ pop_ppx(rdx);\n-\n-  __ bind(done);\n-  __ pop_ppx(rcx);\n-  __ pop_ppx(rax);\n-\n-  __ epilogue();\n-}\n-\n","filename":"src\/hotspot\/cpu\/x86\/gc\/g1\/g1BarrierSetAssembler_x86.cpp","additions":89,"deletions":204,"binary":false,"changes":293,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2024, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -62,4 +62,2 @@\n-                               Register tmp1,\n-                               Register tmp2,\n-                               RegSet preserve = RegSet()) {\n-  if (!G1PostBarrierStubC2::needs_barrier(node)) {\n+                               Register tmp1) {\n+  if (!G1BarrierStubC2::needs_post_barrier(node)) {\n@@ -70,5 +68,2 @@\n-  G1PostBarrierStubC2* const stub = G1PostBarrierStubC2::create(node);\n-  for (RegSetIterator<Register> reg = preserve.begin(); *reg != noreg; ++reg) {\n-    stub->preserve(*reg);\n-  }\n-  g1_asm->g1_write_barrier_post_c2(masm, store_addr, new_val, tmp1, tmp2, stub);\n+  bool new_val_may_be_null = G1BarrierStubC2::post_new_val_may_be_null(node);\n+  g1_asm->g1_write_barrier_post_c2(masm, store_addr, new_val, tmp1, new_val_may_be_null);\n@@ -102,2 +97,1 @@\n-                       $tmp3$$Register \/* tmp1 *\/,\n-                       $tmp2$$Register \/* tmp2 *\/);\n+                       $tmp3$$Register \/* tmp1 *\/);\n@@ -139,2 +133,1 @@\n-                       $tmp3$$Register \/* tmp1 *\/,\n-                       $tmp2$$Register \/* tmp2 *\/);\n+                       $tmp3$$Register \/* tmp1 *\/);\n@@ -180,3 +173,1 @@\n-                       $tmp3$$Register \/* tmp1 *\/,\n-                       $tmp2$$Register \/* tmp2 *\/,\n-                       RegSet::of($tmp1$$Register, $src$$Register) \/* preserve *\/);\n+                       $tmp3$$Register \/* tmp1 *\/);\n@@ -187,2 +178,1 @@\n-                       $tmp3$$Register \/* tmp1 *\/,\n-                       $tmp2$$Register \/* tmp2 *\/);\n+                       $tmp3$$Register \/* tmp1 *\/);\n@@ -219,2 +209,1 @@\n-                       $tmp3$$Register \/* tmp1 *\/,\n-                       $tmp2$$Register \/* tmp2 *\/);\n+                       $tmp3$$Register \/* tmp1 *\/);\n@@ -250,2 +239,1 @@\n-                       $tmp3$$Register \/* tmp1 *\/,\n-                       $tmp2$$Register \/* tmp2 *\/);\n+                       $tmp3$$Register \/* tmp1 *\/);\n@@ -279,2 +267,1 @@\n-                       $tmp2$$Register \/* tmp1 *\/,\n-                       $tmp3$$Register \/* tmp2 *\/);\n+                       $tmp2$$Register \/* tmp1 *\/);\n@@ -306,2 +293,1 @@\n-                       $tmp2$$Register \/* tmp1 *\/,\n-                       $tmp3$$Register \/* tmp2 *\/);\n+                       $tmp2$$Register \/* tmp1 *\/);\n@@ -338,2 +324,1 @@\n-                       $tmp2$$Register \/* tmp1 *\/,\n-                       $tmp3$$Register \/* tmp2 *\/);\n+                       $tmp2$$Register \/* tmp1 *\/);\n@@ -371,2 +356,1 @@\n-                       $tmp2$$Register \/* tmp1 *\/,\n-                       $tmp3$$Register \/* tmp2 *\/);\n+                       $tmp2$$Register \/* tmp1 *\/);\n@@ -395,2 +379,1 @@\n-                       $tmp2$$Register \/* tmp1 *\/,\n-                       $tmp3$$Register \/* tmp2 *\/);\n+                       $tmp2$$Register \/* tmp1 *\/);\n@@ -420,2 +403,1 @@\n-                       $tmp2$$Register \/* tmp1 *\/,\n-                       $tmp3$$Register \/* tmp2 *\/);\n+                       $tmp2$$Register \/* tmp1 *\/);\n","filename":"src\/hotspot\/cpu\/x86\/gc\/g1\/g1_x86_64.ad","additions":17,"deletions":35,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -3018,1 +3018,2 @@\n-  bool blend_emulation = EnableX86ECoreOpts && UseAVX > 1;\n+  bool blend_emulation = EnableX86ECoreOpts && UseAVX > 1 &&\n+                         !(VM_Version::is_intel_darkmont() && (dst == src1)); \/\/ partially fixed on Darkmont\n@@ -3042,1 +3043,2 @@\n-  bool blend_emulation = EnableX86ECoreOpts && UseAVX > 1;\n+  bool blend_emulation = EnableX86ECoreOpts && UseAVX > 1 &&\n+                         !(VM_Version::is_intel_darkmont() && (dst == src1)); \/\/ partially fixed on Darkmont\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1284,1 +1284,1 @@\n-                                            AdapterHandlerEntry* handler,\n+                                            address entry_address[AdapterBlob::ENTRY_COUNT],\n@@ -1287,1 +1287,1 @@\n-  address i2c_entry = __ pc();\n+  entry_address[AdapterBlob::I2C] = __ pc();\n@@ -1299,2 +1299,2 @@\n-  address c2i_unverified_entry        = __ pc();\n-  address c2i_unverified_inline_entry = __ pc();\n+  entry_address[AdapterBlob::C2I_Unverified] = __ pc();\n+  entry_address[AdapterBlob::C2I_Unverified_Inline] = __ pc();\n@@ -1310,2 +1310,2 @@\n-  address c2i_no_clinit_check_entry = nullptr;\n-  address c2i_inline_ro_entry = __ pc();\n+  entry_address[AdapterBlob::C2I_No_Clinit_Check] = nullptr;\n+  entry_address[AdapterBlob::C2I_Inline_RO] = __ pc();\n@@ -1314,2 +1314,2 @@\n-    gen_c2i_adapter(masm, sig_cc_ro, regs_cc_ro, \/* requires_clinit_barrier = *\/ false, c2i_no_clinit_check_entry,\n-                    skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, \/* alloc_inline_receiver = *\/ false);\n+    gen_c2i_adapter(masm, sig_cc_ro, regs_cc_ro, \/* requires_clinit_barrier = *\/ false, entry_address[AdapterBlob::C2I_No_Clinit_Check],\n+                    skip_fixup, entry_address[AdapterBlob::I2C], oop_maps, frame_complete, frame_size_in_words, \/* alloc_inline_receiver = *\/ false);\n@@ -1320,4 +1320,4 @@\n-  address c2i_entry        = __ pc();\n-  address c2i_inline_entry = __ pc();\n-  gen_c2i_adapter(masm, sig_cc, regs_cc, \/* requires_clinit_barrier = *\/ true, c2i_no_clinit_check_entry,\n-                  skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, \/* alloc_inline_receiver = *\/ true);\n+  entry_address[AdapterBlob::C2I]        = __ pc();\n+  entry_address[AdapterBlob::C2I_Inline] = __ pc();\n+  gen_c2i_adapter(masm, sig_cc, regs_cc, \/* requires_clinit_barrier = *\/ true, entry_address[AdapterBlob::C2I_No_Clinit_Check],\n+                  skip_fixup, entry_address[AdapterBlob::I2C], oop_maps, frame_complete, frame_size_in_words, \/* alloc_inline_receiver = *\/ true);\n@@ -1327,1 +1327,1 @@\n-    c2i_unverified_inline_entry = __ pc();\n+    entry_address[AdapterBlob::C2I_Unverified_Inline] = __ pc();\n@@ -1331,3 +1331,3 @@\n-    c2i_inline_entry = __ pc();\n-    gen_c2i_adapter(masm, sig, regs, \/* requires_clinit_barrier = *\/ true, c2i_no_clinit_check_entry,\n-                    inline_entry_skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, \/* alloc_inline_receiver = *\/ false);\n+    entry_address[AdapterBlob::C2I_Inline] = __ pc();\n+    gen_c2i_adapter(masm, sig, regs, \/* requires_clinit_barrier = *\/ true, entry_address[AdapterBlob::C2I_No_Clinit_Check],\n+                    inline_entry_skip_fixup, entry_address[AdapterBlob::I2C], oop_maps, frame_complete, frame_size_in_words, \/* alloc_inline_receiver = *\/ false);\n@@ -1342,8 +1342,1 @@\n-    entry_offset[0] = 0; \/\/ i2c_entry offset\n-    entry_offset[1] = c2i_entry - i2c_entry;\n-    entry_offset[2] = c2i_inline_entry - i2c_entry;\n-    entry_offset[3] = c2i_inline_ro_entry - i2c_entry;\n-    entry_offset[4] = c2i_unverified_entry - i2c_entry;\n-    entry_offset[5] = c2i_unverified_inline_entry - i2c_entry;\n-    entry_offset[6] = c2i_no_clinit_check_entry - i2c_entry;\n-\n+    AdapterHandlerLibrary::address_to_offset(entry_address, entry_offset);\n@@ -1352,3 +1345,0 @@\n-\n-  handler->set_entry_points(i2c_entry, c2i_entry, c2i_inline_entry, c2i_inline_ro_entry, c2i_unverified_entry,\n-                            c2i_unverified_inline_entry, c2i_no_clinit_check_entry);\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":17,"deletions":27,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -142,1 +142,1 @@\n-    Label detect_486, cpu486, detect_586, std_cpuid1, std_cpuid4, std_cpuid24;\n+    Label detect_486, cpu486, detect_586, std_cpuid1, std_cpuid4, std_cpuid24, std_cpuid29;\n@@ -341,0 +341,10 @@\n+    \/\/\n+    \/\/ cpuid(0x29) APX NCI NDD NF (EAX = 29H, ECX = 0).\n+    \/\/\n+    __ bind(std_cpuid29);\n+    __ movl(rax, 0x29);\n+    __ movl(rcx, 0);\n+    __ cpuid();\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::std_cpuid29_offset())));\n+    __ movl(Address(rsi, 0), rbx);\n+\n@@ -2086,0 +2096,4 @@\n+bool VM_Version::is_intel_darkmont() {\n+  return is_intel() && is_intel_server_family() && (_model == 0xCC || _model == 0xDD);\n+}\n+\n@@ -2917,1 +2931,2 @@\n-      xem_xcr0_eax.bits.apx_f != 0) {\n+      xem_xcr0_eax.bits.apx_f != 0 &&\n+      std_cpuid29_ebx.bits.apx_nci_ndd_nf != 0) {\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":17,"deletions":2,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -41,6 +41,0 @@\n-\n-static address zero_null_code_stub() {\n-  address start = ShouldNotCallThisStub();\n-  return start;\n-}\n-\n@@ -72,1 +66,1 @@\n-                                            AdapterHandlerEntry* handler,\n+                                            address entry_address[AdapterBlob::ENTRY_COUNT],\n@@ -75,21 +69,2 @@\n-  if (allocate_code_blob) {\n-    int entry_offset[AdapterHandlerEntry::ENTRIES_COUNT];\n-    assert(AdapterHandlerEntry::ENTRIES_COUNT == 7, \"sanity\");\n-    entry_offset[0] = 0; \/\/ i2c_entry offset\n-    entry_offset[1] = -1;\n-    entry_offset[2] = -1;\n-    entry_offset[3] = -1;\n-    entry_offset[4] = -1;\n-    entry_offset[5] = -1;\n-    entry_offset[6] = -1;\n-\n-    new_adapter = AdapterBlob::create(masm->code(), entry_offset, 0, 0, nullptr);\n-  }\n-  \/\/ foil any attempt to call the i2c, c2i or unverified c2i entries\n-  handler->set_entry_points(CAST_FROM_FN_PTR(address,zero_null_code_stub),\n-                            CAST_FROM_FN_PTR(address,zero_null_code_stub),\n-                            CAST_FROM_FN_PTR(address,zero_null_code_stub),\n-                            CAST_FROM_FN_PTR(address,zero_null_code_stub),\n-                            CAST_FROM_FN_PTR(address,zero_null_code_stub),\n-                            CAST_FROM_FN_PTR(address,zero_null_code_stub),\n-                            nullptr);\n+  ShouldNotCallThis();\n+  return;\n","filename":"src\/hotspot\/cpu\/zero\/sharedRuntime_zero.cpp","additions":3,"deletions":28,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -129,1 +129,1 @@\n-\/\/ [0] All classes are loaded in AOTMetaspace::loadable_descriptors(). All metadata are\n+\/\/ [0] All classes are loaded in AOTMetaspace::load_classes(). All metadata are\n@@ -725,0 +725,1 @@\n+  HeapShared::delete_tables_with_raw_oops();\n@@ -808,0 +809,17 @@\n+  if (CDSConfig::is_dumping_final_static_archive()) {\n+    \/\/ - Load and link all classes used in the training run.\n+    \/\/ - Initialize @AOTSafeClassInitializer classes that were\n+    \/\/   initialized in the training run.\n+    \/\/ - Perform per-class optimization such as AOT-resolution of\n+    \/\/   constant pool entries that were resolved during the training run.\n+    FinalImageRecipes::apply_recipes(CHECK);\n+\n+    \/\/ Because the AOT assembly phase does not run the same exact code as in the\n+    \/\/ training run (e.g., we use different lambda form invoker classes;\n+    \/\/ generated lambda form classes are not recorded in FinalImageRecipes),\n+    \/\/ the recipes do not cover all classes that have been loaded so far. As\n+    \/\/ a result, we might have some unlinked classes at this point. Since we\n+    \/\/ require cached classes to be linked, all such classes will be linked\n+    \/\/ by the following step.\n+  }\n+\n@@ -821,4 +839,0 @@\n-\n-  if (CDSConfig::is_dumping_final_static_archive()) {\n-    FinalImageRecipes::apply_recipes(CHECK);\n-  }\n@@ -827,3 +841,1 @@\n-\/\/ Preload classes from a list, populate the shared spaces and dump to a\n-\/\/ file.\n-void AOTMetaspace::preload_and_dump(TRAPS) {\n+void AOTMetaspace::dump_static_archive(TRAPS) {\n@@ -832,1 +844,1 @@\n- HandleMark hm(THREAD);\n+  HandleMark hm(THREAD);\n@@ -840,1 +852,1 @@\n-  preload_and_dump_impl(builder, THREAD);\n+  dump_static_archive_impl(builder, THREAD);\n@@ -906,1 +918,1 @@\n-void AOTMetaspace::loadable_descriptors(TRAPS) {\n+void AOTMetaspace::load_classes(TRAPS) {\n@@ -933,2 +945,2 @@\n-  \/\/ Some classes are used at CDS runtime but are not loaded, and therefore archived, at\n-  \/\/ dumptime. We can perform dummmy calls to these classes at dumptime to ensure they\n+  \/\/ Some classes are used at CDS runtime but are not yet loaded at this point.\n+  \/\/ We can perform dummmy calls to these classes at dumptime to ensure they\n@@ -950,1 +962,1 @@\n-void AOTMetaspace::preload_and_dump_impl(StaticArchiveBuilder& builder, TRAPS) {\n+void AOTMetaspace::dump_static_archive_impl(StaticArchiveBuilder& builder, TRAPS) {\n@@ -953,1 +965,1 @@\n-    loadable_descriptors(CHECK);\n+    load_classes(CHECK);\n@@ -1081,5 +1093,0 @@\n-\n-  if (AllowArchivingWithJavaAgent) {\n-    aot_log_warning(aot)(\"This %s was created with AllowArchivingWithJavaAgent. It should be used \"\n-            \"for testing purposes only and should not be used in a production environment\", CDSConfig::type_of_archive_being_loaded());\n-  }\n","filename":"src\/hotspot\/share\/cds\/aotMetaspace.cpp","additions":27,"deletions":20,"binary":false,"changes":47,"status":"modified"},{"patch":"@@ -98,0 +98,5 @@\n+void ArchiveHeapWriter::delete_tables_with_raw_oops() {\n+  delete _source_objs;\n+  _source_objs = nullptr;\n+}\n+\n@@ -148,1 +153,1 @@\n-  HeapShared::CachedOopInfo* p = HeapShared::archived_object_cache()->get(src_obj);\n+  HeapShared::CachedOopInfo* p = HeapShared::get_cached_oop_info(src_obj);\n@@ -157,3 +162,3 @@\n-  oop* p = _buffer_offset_to_source_obj_table->get(buffered_address_to_offset(buffered_addr));\n-  if (p != nullptr) {\n-    return *p;\n+  OopHandle* oh = _buffer_offset_to_source_obj_table->get(buffered_address_to_offset(buffered_addr));\n+  if (oh != nullptr) {\n+    return oh->resolve();\n@@ -360,1 +365,1 @@\n-    HeapShared::CachedOopInfo* info = HeapShared::archived_object_cache()->get(src_obj);\n+    HeapShared::CachedOopInfo* info = HeapShared::get_cached_oop_info(src_obj);\n@@ -365,1 +370,2 @@\n-    _buffer_offset_to_source_obj_table->put_when_absent(buffer_offset, src_obj);\n+    OopHandle handle(Universe::vm_global(), src_obj);\n+    _buffer_offset_to_source_obj_table->put_when_absent(buffer_offset, handle);\n@@ -702,1 +708,1 @@\n-    HeapShared::CachedOopInfo* info = HeapShared::archived_object_cache()->get(src_obj);\n+    HeapShared::CachedOopInfo* info = HeapShared::get_cached_oop_info(src_obj);\n@@ -764,1 +770,1 @@\n-    HeapShared::CachedOopInfo* p = HeapShared::archived_object_cache()->get(src_obj);\n+    HeapShared::CachedOopInfo* p = HeapShared::get_cached_oop_info(src_obj);\n","filename":"src\/hotspot\/share\/cds\/archiveHeapWriter.cpp","additions":14,"deletions":8,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -74,1 +74,2 @@\n-  return (is_dumping_archive()              ? IS_DUMPING_ARCHIVE : 0) |\n+  return (is_dumping_aot_linked_classes()   ? IS_DUMPING_AOT_LINKED_CLASSES : 0) |\n+         (is_dumping_archive()              ? IS_DUMPING_ARCHIVE : 0) |\n@@ -494,4 +495,0 @@\n-\n-  \/\/ This is an old flag used by CDS regression testing only. It doesn't apply\n-  \/\/ to the AOT workflow.\n-  FLAG_SET_ERGO(AllowArchivingWithJavaAgent, false);\n@@ -740,7 +737,0 @@\n-  if (is_dumping_classic_static_archive() && AOTClassLinking) {\n-    if (JvmtiAgentList::disable_agent_list()) {\n-      FLAG_SET_ERGO(AllowArchivingWithJavaAgent, false);\n-      log_warning(cds)(\"Disabled all JVMTI agents with -Xshare:dump -XX:+AOTClassLinking\");\n-    }\n-  }\n-\n","filename":"src\/hotspot\/share\/cds\/cdsConfig.cpp","additions":2,"deletions":12,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -87,5 +87,6 @@\n-  static const int IS_DUMPING_ARCHIVE              = 1 << 0;\n-  static const int IS_DUMPING_METHOD_HANDLES       = 1 << 1;\n-  static const int IS_DUMPING_STATIC_ARCHIVE       = 1 << 2;\n-  static const int IS_LOGGING_LAMBDA_FORM_INVOKERS = 1 << 3;\n-  static const int IS_USING_ARCHIVE                = 1 << 4;\n+  static const int IS_DUMPING_AOT_LINKED_CLASSES   = 1 << 0;\n+  static const int IS_DUMPING_ARCHIVE              = 1 << 1;\n+  static const int IS_DUMPING_METHOD_HANDLES       = 1 << 2;\n+  static const int IS_DUMPING_STATIC_ARCHIVE       = 1 << 3;\n+  static const int IS_LOGGING_LAMBDA_FORM_INVOKERS = 1 << 4;\n+  static const int IS_USING_ARCHIVE                = 1 << 5;\n","filename":"src\/hotspot\/share\/cds\/cdsConfig.hpp","additions":6,"deletions":5,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -43,1 +43,3 @@\n-\/\/ -- Handling of Enum objects\n+\/\/ !!! This is legacy support for enum classes before JEP 483. This file is not used when\n+\/\/ !!! CDSConfig::is_initing_classes_at_dump_time()==true.\n+\/\/\n@@ -65,0 +67,1 @@\n+  assert(!CDSConfig::is_initing_classes_at_dump_time(), \"only for legacy support of enums\");\n","filename":"src\/hotspot\/share\/cds\/cdsEnumKlass.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -401,5 +401,0 @@\n-    if (AllowArchivingWithJavaAgent) {\n-      aot_log_warning(aot)(\"This %s was created with AllowArchivingWithJavaAgent. It should be used \"\n-                       \"for testing purposes only and should not be used in a production environment\",\n-                       CDSConfig::type_of_archive_being_loaded());\n-    }\n@@ -449,2 +444,0 @@\n-      assert(!oak->is_typeArray_klass(), \"all type array classes must be in static archive\");\n-\n","filename":"src\/hotspot\/share\/cds\/dynamicArchive.cpp","additions":0,"deletions":7,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -328,1 +328,0 @@\n-  _allow_archiving_with_java_agent = AllowArchivingWithJavaAgent;\n@@ -386,1 +385,0 @@\n-  st->print_cr(\"- allow_archiving_with_java_agent:%d\", _allow_archiving_with_java_agent);\n@@ -2127,15 +2125,0 @@\n-  \/\/ Java agents are allowed during run time. Therefore, the following condition is not\n-  \/\/ checked: (!_allow_archiving_with_java_agent && AllowArchivingWithJavaAgent)\n-  \/\/ Note: _allow_archiving_with_java_agent is set in the shared archive during dump time\n-  \/\/ while AllowArchivingWithJavaAgent is set during the current run.\n-  if (_allow_archiving_with_java_agent && !AllowArchivingWithJavaAgent) {\n-    AOTMetaspace::report_loading_error(\"The setting of the AllowArchivingWithJavaAgent is different \"\n-                                          \"from the setting in the %s.\", file_type);\n-    return false;\n-  }\n-\n-  if (_allow_archiving_with_java_agent) {\n-    aot_log_warning(aot)(\"This %s was created with AllowArchivingWithJavaAgent. It should be used \"\n-            \"for testing purposes only and should not be used in a production environment\", file_type);\n-  }\n-\n","filename":"src\/hotspot\/share\/cds\/filemap.cpp","additions":0,"deletions":17,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -170,1 +170,0 @@\n-  bool   _allow_archiving_with_java_agent; \/\/ setting of the AllowArchivingWithJavaAgent option\n","filename":"src\/hotspot\/share\/cds\/filemap.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"cds\/aotOopChecker.hpp\"\n@@ -61,0 +62,1 @@\n+#include \"oops\/oopHandle.inline.hpp\"\n@@ -162,0 +164,4 @@\n+oop HeapShared::CachedOopInfo::orig_referrer() const {\n+  return _orig_referrer.resolve();\n+}\n+\n@@ -163,0 +169,2 @@\n+  assert(SafepointSynchronize::is_at_safepoint() ||\n+         JavaThread::current()->is_in_no_safepoint_scope(), \"sanity\");\n@@ -168,0 +176,17 @@\n+unsigned int HeapShared::oop_handle_hash_raw(const OopHandle& oh) {\n+  return oop_hash(oh.resolve());\n+}\n+\n+unsigned int HeapShared::oop_handle_hash(const OopHandle& oh) {\n+  oop o = oh.resolve();\n+  if (o == nullptr) {\n+    return 0;\n+  } else {\n+    return o->identity_hash();\n+  }\n+}\n+\n+bool HeapShared::oop_handle_equals(const OopHandle& a, const OopHandle& b) {\n+  return a.resolve() == b.resolve();\n+}\n+\n@@ -219,1 +244,2 @@\n-  return archived_object_cache()->get(obj) != nullptr;\n+  OopHandle oh(&obj);\n+  return archived_object_cache()->get(oh) != nullptr;\n@@ -303,0 +329,2 @@\n+    AOTOopChecker::check(obj); \/\/ Make sure contents of this oop are safe.\n+\n@@ -306,1 +334,3 @@\n-    archived_object_cache()->put_when_absent(obj, info);\n+\n+    OopHandle oh(Universe::vm_global(), obj);\n+    archived_object_cache()->put_when_absent(oh, info);\n@@ -588,1 +618,1 @@\n-static void copy_java_mirror_hashcode(oop orig_mirror, oop scratch_m) {\n+void HeapShared::copy_java_mirror(oop orig_mirror, oop scratch_m) {\n@@ -605,0 +635,5 @@\n+\n+  if (CDSConfig::is_dumping_aot_linked_classes()) {\n+    java_lang_Class::set_module(scratch_m, java_lang_Class::module(orig_mirror));\n+    java_lang_Class::set_protection_domain(scratch_m, java_lang_Class::protection_domain(orig_mirror));\n+  }\n@@ -640,1 +675,2 @@\n-  CachedOopInfo* info = archived_object_cache()->get(src_obj);\n+  OopHandle oh(&src_obj);\n+  CachedOopInfo* info = archived_object_cache()->get(oh);\n@@ -647,1 +683,2 @@\n-  CachedOopInfo* info = archived_object_cache()->get(src_obj);\n+  OopHandle oh(&src_obj);\n+  CachedOopInfo* info = archived_object_cache()->get(oh);\n@@ -702,1 +739,1 @@\n-    copy_java_mirror_hashcode(orig_mirror, m);\n+    copy_java_mirror(orig_mirror, m);\n@@ -1461,1 +1498,1 @@\n-  return CachedOopInfo(referrer, points_to_oops_checker.result());\n+  return CachedOopInfo(OopHandle(Universe::vm_global(), referrer), points_to_oops_checker.result());\n@@ -1617,2 +1654,2 @@\n-    \/\/ The enum klasses are archived with aot-initialized mirror.\n-    \/\/ See AOTClassInitializer::can_archive_initialized_mirror().\n+    \/\/ The classes of all archived enum instances have been marked as aot-init,\n+    \/\/ so there's nothing else to be done in the production run.\n@@ -1620,0 +1657,2 @@\n+    \/\/ This is legacy support for enum classes before JEP 483 -- we cannot rerun\n+    \/\/ the enum's <clinit> in the production run, so special handling is needed.\n@@ -2111,0 +2150,12 @@\n+\/\/ These tables should be used only within the CDS safepoint, so\n+\/\/ delete them before we exit the safepoint. Otherwise the table will\n+\/\/ contain bad oops after a GC.\n+void HeapShared::delete_tables_with_raw_oops() {\n+  assert(_seen_objects_table == nullptr, \"should have been deleted\");\n+\n+  delete _dumped_interned_strings;\n+  _dumped_interned_strings = nullptr;\n+\n+  ArchiveHeapWriter::delete_tables_with_raw_oops();\n+}\n+\n","filename":"src\/hotspot\/share\/cds\/heapShared.cpp","additions":60,"deletions":9,"binary":false,"changes":69,"status":"modified"},{"patch":"@@ -120,1 +120,1 @@\n-    assert(is_in_encoding_range || k->is_interface() || k->is_abstract(), \"sanity\");\n+    assert(is_in_encoding_range, \"sanity\");\n","filename":"src\/hotspot\/share\/ci\/ciKlass.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -5424,40 +5424,0 @@\n-  \/\/ AOT-related checks.\n-  \/\/ Note we cannot check this in general due to instrumentation or module patching\n-  if (CDSConfig::is_initing_classes_at_dump_time()) {\n-    \/\/ Check the aot initialization safe status.\n-    \/\/ @AOTSafeClassInitializer is used only to support ahead-of-time initialization of classes\n-    \/\/ in the AOT assembly phase.\n-    if (ik->has_aot_safe_initializer()) {\n-      \/\/ If a type is included in the tables inside can_archive_initialized_mirror(), we require that\n-      \/\/   - all super classes must be included\n-      \/\/   - all super interfaces that have <clinit> must be included.\n-      \/\/ This ensures that in the production run, we don't run the <clinit> of a supertype but skips\n-      \/\/ ik's <clinit>.\n-      if (_super_klass != nullptr) {\n-        guarantee_property(_super_klass->has_aot_safe_initializer(),\n-                           \"Missing @AOTSafeClassInitializer in superclass %s for class %s\",\n-                           _super_klass->external_name(),\n-                           CHECK);\n-      }\n-\n-      int len = _local_interfaces->length();\n-      for (int i = 0; i < len; i++) {\n-        InstanceKlass* intf = _local_interfaces->at(i);\n-        guarantee_property(intf->class_initializer() == nullptr || intf->has_aot_safe_initializer(),\n-                           \"Missing @AOTSafeClassInitializer in superinterface %s for class %s\",\n-                           intf->external_name(),\n-                           CHECK);\n-      }\n-\n-      if (log_is_enabled(Info, aot, init)) {\n-        ResourceMark rm;\n-        log_info(aot, init)(\"Found @AOTSafeClassInitializer class %s\", ik->external_name());\n-      }\n-    } else {\n-      \/\/ @AOTRuntimeSetup only meaningful in @AOTClassInitializer\n-      guarantee_property(!ik->is_runtime_setup_required(),\n-                         \"@AOTRuntimeSetup meaningless in non-@AOTSafeClassInitializer class %s\",\n-                         CHECK);\n-    }\n-  }\n-\n@@ -6425,9 +6385,0 @@\n-\/\/ Returns true if the future Klass will need to be addressable with a narrow Klass ID.\n-bool ClassFileParser::klass_needs_narrow_id() const {\n-  \/\/ Classes that are never instantiated need no narrow Klass Id, since the\n-  \/\/ only point of having a narrow id is to put it into an object header. Keeping\n-  \/\/ never instantiated classes out of class space lessens the class space pressure.\n-  \/\/ For more details, see JDK-8338526.\n-  return !is_interface() && !is_abstract();\n-}\n-\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":0,"deletions":49,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -563,4 +563,0 @@\n-  \/\/ Returns true if the Klass to be generated will need to be addressable\n-  \/\/ with a narrow Klass ID.\n-  bool klass_needs_narrow_id() const;\n-\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1217,4 +1217,1 @@\n-    if (loader == nullptr) {\n-      \/\/ JFR classes\n-      ik->set_shared_classpath_index(0);\n-    }\n+    ik->set_shared_classpath_index(-1); \/\/ unsupported location\n@@ -1331,18 +1328,0 @@\n-\n-#if INCLUDE_CDS_JAVA_HEAP\n-  if (CDSConfig::is_dumping_heap() && AllowArchivingWithJavaAgent && result->defined_by_boot_loader() &&\n-      classpath_index < 0 && redefined) {\n-    \/\/ When dumping the heap (which happens only during static dump), classes for the built-in\n-    \/\/ loaders are always loaded from known locations (jimage, classpath or modulepath),\n-    \/\/ so classpath_index should always be >= 0.\n-    \/\/ The only exception is when a java agent is used during dump time (for testing\n-    \/\/ purposes only). If a class is transformed by the agent, the AOTClassLocation of\n-    \/\/ this class may point to an unknown location. This may break heap object archiving,\n-    \/\/ which requires all the boot classes to be from known locations. This is an\n-    \/\/ uncommon scenario (even in test cases). Let's simply disable heap object archiving.\n-    ResourceMark rm;\n-    log_warning(aot)(\"heap objects cannot be written because class %s maybe modified by ClassFileLoadHook.\",\n-                     result->external_name());\n-    CDSConfig::disable_heap_dumping();\n-  }\n-#endif \/\/ INCLUDE_CDS_JAVA_HEAP\n","filename":"src\/hotspot\/share\/classfile\/classLoader.cpp","additions":1,"deletions":22,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -1018,0 +1018,9 @@\n+  if (CDSConfig::is_using_aot_linked_classes()) {\n+    oop archived_module = java_lang_Class::module(mirror());\n+    if (archived_module != nullptr) {\n+      precond(module() == nullptr || module() == archived_module);\n+      precond(AOTMetaspace::in_aot_cache_static_region((void*)k));\n+      return;\n+    }\n+  }\n+\n@@ -1024,0 +1033,4 @@\n+    \/\/ With AOT-linked classes, java.base should have been defined before the\n+    \/\/ VM loads any classes.\n+    precond(!CDSConfig::is_using_aot_linked_classes());\n+\n@@ -1057,7 +1070,13 @@\n-  GrowableArray<Klass*>* mirror_list =\n-    new (mtClass) GrowableArray<Klass*>(40, mtClass);\n-  set_fixup_mirror_list(mirror_list);\n-\n-  GrowableArray<Klass*>* module_list =\n-    new (mtModule) GrowableArray<Klass*>(500, mtModule);\n-  set_fixup_module_field_list(module_list);\n+  if (!CDSConfig::is_using_aot_linked_classes()) {\n+    \/\/ fixup_mirror_list() is not used when we have preloaded classes. See\n+    \/\/ Universe::fixup_mirrors().\n+    GrowableArray<Klass*>* mirror_list =\n+      new (mtClass) GrowableArray<Klass*>(40, mtClass);\n+    set_fixup_mirror_list(mirror_list);\n+\n+    \/\/ With AOT-linked classes, java.base module is defined before any class\n+    \/\/ is loaded, so there's no need for fixup_module_field_list().\n+    GrowableArray<Klass*>* module_list =\n+      new (mtModule) GrowableArray<Klass*>(500, mtModule);\n+    set_fixup_module_field_list(module_list);\n+  }\n@@ -1182,0 +1201,1 @@\n+    assert(!CDSConfig::is_using_aot_linked_classes(), \"should not come here\");\n@@ -1227,1 +1247,1 @@\n-  if (!vmClasses::Class_klass_loaded()) {\n+  if (!vmClasses::Class_klass_loaded() && !CDSConfig::is_using_aot_linked_classes()) {\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":28,"deletions":8,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -237,0 +237,1 @@\n+  friend class HeapShared;\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -214,0 +214,1 @@\n+      bool Bug8370217_FIXED = false;\n@@ -215,1 +216,1 @@\n-      if (EnableValhalla) {\n+      if (EnableValhalla && Bug8370217_FIXED) {\n@@ -224,3 +225,5 @@\n-  assert(_java_system_loader.is_empty(), \"already set!\");\n-  _java_system_loader = cld->class_loader_handle();\n-\n+  if (_java_system_loader.is_empty()) {\n+    _java_system_loader = cld->class_loader_handle();\n+  } else {\n+    assert(_java_system_loader.resolve() == cld->class_loader(), \"sanity\");\n+  }\n@@ -230,2 +233,5 @@\n-  assert(_java_platform_loader.is_empty(), \"already set!\");\n-  _java_platform_loader = cld->class_loader_handle();\n+  if (_java_platform_loader.is_empty()) {\n+    _java_platform_loader = cld->class_loader_handle();\n+  } else {\n+    assert(_java_platform_loader.resolve() == cld->class_loader(), \"sanity\");\n+  }\n@@ -1270,0 +1276,52 @@\n+\/\/ This is much more lightweight than SystemDictionary::resolve_or_null\n+\/\/ - There's only a single Java thread at this point. No need for placeholder.\n+\/\/ - All supertypes of ik have been loaded\n+\/\/ - There's no circularity (checked in AOT assembly phase)\n+\/\/ - There's no need to call java.lang.ClassLoader::load_class() because the boot\/platform\/app\n+\/\/   loaders are well-behaved\n+void SystemDictionary::preload_class(Handle class_loader, InstanceKlass* ik, TRAPS) {\n+  precond(Universe::is_bootstrapping());\n+  precond(java_platform_loader() != nullptr && java_system_loader() != nullptr);\n+  precond(class_loader() == nullptr || class_loader() == java_platform_loader() ||class_loader() == java_system_loader());\n+  precond(CDSConfig::is_using_aot_linked_classes());\n+  precond(AOTMetaspace::in_aot_cache_static_region((void*)ik));\n+  precond(!ik->is_loaded());\n+\n+#ifdef ASSERT\n+  \/\/ preload_class() must be called in the correct order -- all super types must have\n+  \/\/ already been loaded.\n+  if (ik->java_super() != nullptr) {\n+    assert(ik->java_super()->is_loaded(), \"must be\");\n+  }\n+\n+  Array<InstanceKlass*>* interfaces = ik->local_interfaces();\n+  int num_interfaces = interfaces->length();\n+  for (int index = 0; index < num_interfaces; index++) {\n+    assert(interfaces->at(index)->is_loaded(), \"must be\");\n+  }\n+#endif\n+\n+  ClassLoaderData* loader_data = ClassLoaderData::class_loader_data(class_loader());\n+  oop java_mirror = ik->archived_java_mirror();\n+  precond(java_mirror != nullptr);\n+\n+  Handle pd(THREAD, java_lang_Class::protection_domain(java_mirror));\n+  PackageEntry* pkg_entry = ik->package();\n+  assert(pkg_entry != nullptr || ClassLoader::package_from_class_name(ik->name()) == nullptr,\n+         \"non-empty packages must have been archived\");\n+\n+  \/\/ TODO: the following assert requires JDK-8365580\n+  \/\/ assert(is_shared_class_visible(ik->name(), ik, pkg_entry, class_loader), \"must be\");\n+\n+  ik->restore_unshareable_info(loader_data, pd, pkg_entry, CHECK);\n+  load_shared_class_misc(ik, loader_data);\n+  ik->add_to_hierarchy(THREAD);\n+\n+  if (!ik->is_hidden()) {\n+    update_dictionary(THREAD, ik, loader_data);\n+  }\n+\n+  assert(java_lang_Class::module(java_mirror) != nullptr, \"must have been archived\");\n+  assert(ik->is_loaded(), \"Must be in at least loaded state\");\n+}\n+\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":64,"deletions":6,"binary":false,"changes":70,"status":"modified"},{"patch":"@@ -330,1 +330,1 @@\n-  \/\/ Used by SystemDictionaryShared and LambdaProxyClassDictionary\n+  \/\/ Used by AOTLinkedClassBulkLoader, LambdaProxyClassDictionary, and SystemDictionaryShared\n@@ -343,0 +343,1 @@\n+  static void preload_class(Handle class_loader, InstanceKlass* ik, TRAPS);\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1379,1 +1379,0 @@\n-  SET_ADDRESS(_extrs, G1BarrierSetRuntime::write_ref_field_post_entry);\n","filename":"src\/hotspot\/share\/code\/aotCodeCache.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -457,1 +457,2 @@\n-  assert(entry_offset[0] == 0, \"sanity check\");\n+#ifdef ASSERT\n+  assert(entry_offset[I2C] == 0, \"sanity check\");\n@@ -460,3 +461,4 @@\n-    assert((entry_offset[i] > 0 && entry_offset[i] < cb->insts()->size()) ||\n-           (entry_offset[i] == -1),\n-           \"invalid entry offset[%d] = 0x%x\", i, entry_offset[i]);\n+    int offset = entry_offset[i];\n+    assert((offset > 0 && offset < cb->insts()->size()) ||\n+           (i >= C2I_No_Clinit_Check && offset == -1),\n+           \"invalid entry offset[%d] = 0x%x\", i, offset);\n@@ -464,6 +466,7 @@\n-  _c2i_offset = entry_offset[1];\n-  _c2i_inline_offset = entry_offset[2];\n-  _c2i_inline_ro_offset = entry_offset[3];\n-  _c2i_unverified_offset = entry_offset[4];\n-  _c2i_unverified_inline_offset = entry_offset[5];\n-  _c2i_no_clinit_check_offset = entry_offset[6];\n+#endif \/\/ ASSERT\n+  _c2i_offset = entry_offset[C2I];\n+  _c2i_inline_offset = entry_offset[C2I_Inline];\n+  _c2i_inline_ro_offset = entry_offset[C2I_Inline_RO];\n+  _c2i_unverified_offset = entry_offset[C2I_Unverified];\n+  _c2i_unverified_inline_offset = entry_offset[C2I_Unverified_Inline];\n+  _c2i_no_clinit_check_offset = entry_offset[C2I_No_Clinit_Check];\n@@ -490,10 +493,0 @@\n-void AdapterBlob::get_offsets(int entry_offset[ENTRY_COUNT]) {\n-  entry_offset[0] = 0;\n-  entry_offset[1] = _c2i_offset;\n-  entry_offset[2] = _c2i_inline_offset;\n-  entry_offset[3] = _c2i_inline_ro_offset;\n-  entry_offset[4] = _c2i_unverified_offset;\n-  entry_offset[5] = _c2i_unverified_inline_offset;\n-  entry_offset[6] = _c2i_no_clinit_check_offset;\n-}\n-\n","filename":"src\/hotspot\/share\/code\/codeBlob.cpp","additions":13,"deletions":20,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -413,1 +413,10 @@\n-  static const int ENTRY_COUNT = 7;\n+  enum Entry {\n+    I2C,\n+    C2I,\n+    C2I_Inline,\n+    C2I_Inline_RO,\n+    C2I_Unverified,\n+    C2I_Unverified_Inline,\n+    C2I_No_Clinit_Check,\n+    ENTRY_COUNT\n+  };\n@@ -435,1 +444,7 @@\n-  void get_offsets(int entry_offset[ENTRY_COUNT]);\n+  address i2c_entry() { return code_begin(); }\n+  address c2i_entry() { return i2c_entry() + _c2i_offset; }\n+  address c2i_inline_entry() { return i2c_entry() + _c2i_inline_offset; }\n+  address c2i_inline_ro_entry() { return i2c_entry() + _c2i_inline_ro_offset; }\n+  address c2i_unverified_entry() { return i2c_entry() + _c2i_unverified_offset; }\n+  address c2i_unverified_inline_entry() { return i2c_entry() + _c2i_unverified_inline_offset; }\n+  address c2i_no_clinit_check_entry() { return _c2i_no_clinit_check_offset == -1 ? nullptr : i2c_entry() + _c2i_no_clinit_check_offset; }\n","filename":"src\/hotspot\/share\/code\/codeBlob.hpp","additions":17,"deletions":2,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -2352,0 +2352,1 @@\n+        thread->timeout()->reset();\n","filename":"src\/hotspot\/share\/compiler\/compileBroker.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -300,1 +300,7 @@\n-    nodes += 60;\n+    \/\/ Approximate the number of nodes needed; an if costs 4 nodes (Cmp, Bool,\n+    \/\/ If, If projection), any other (Assembly) instruction is approximated with\n+    \/\/ a cost of 1.\n+    nodes +=   4  \/\/ base cost for the card write containing getting base offset, address calculation and the card write;\n+             + 6  \/\/ same region check: Uncompress (new_val) oop, xor, shr, (cmp), jmp\n+             + 4  \/\/ new_val is null check\n+             + (UseCondCardMark ? 4 : 0); \/\/ card not clean check.\n@@ -388,2 +394,3 @@\n-    return G1PreBarrierStubC2::needs_barrier(mach) ||\n-           G1PostBarrierStubC2::needs_barrier(mach);\n+    \/\/ Liveness data is only required to compute registers that must be preserved\n+    \/\/ across the runtime call in the pre-barrier stub.\n+    return G1BarrierStubC2::needs_pre_barrier(mach);\n@@ -403,0 +410,12 @@\n+bool G1BarrierStubC2::needs_pre_barrier(const MachNode* node) {\n+  return (node->barrier_data() & G1C2BarrierPre) != 0;\n+}\n+\n+bool G1BarrierStubC2::needs_post_barrier(const MachNode* node) {\n+  return (node->barrier_data() & G1C2BarrierPost) != 0;\n+}\n+\n+bool G1BarrierStubC2::post_new_val_may_be_null(const MachNode* node) {\n+  return (node->barrier_data() & G1C2BarrierPostNotNull) == 0;\n+}\n+\n@@ -406,1 +425,1 @@\n-  return (node->barrier_data() & G1C2BarrierPre) != 0;\n+  return needs_pre_barrier(node);\n@@ -450,42 +469,0 @@\n-G1PostBarrierStubC2::G1PostBarrierStubC2(const MachNode* node) : G1BarrierStubC2(node) {}\n-\n-bool G1PostBarrierStubC2::needs_barrier(const MachNode* node) {\n-  return (node->barrier_data() & G1C2BarrierPost) != 0;\n-}\n-\n-G1PostBarrierStubC2* G1PostBarrierStubC2::create(const MachNode* node) {\n-  G1PostBarrierStubC2* const stub = new (Compile::current()->comp_arena()) G1PostBarrierStubC2(node);\n-  if (!Compile::current()->output()->in_scratch_emit_size()) {\n-    barrier_set_state()->stubs()->append(stub);\n-  }\n-  return stub;\n-}\n-\n-void G1PostBarrierStubC2::initialize_registers(Register thread, Register tmp1, Register tmp2, Register tmp3) {\n-  _thread = thread;\n-  _tmp1 = tmp1;\n-  _tmp2 = tmp2;\n-  _tmp3 = tmp3;\n-}\n-\n-Register G1PostBarrierStubC2::thread() const {\n-  return _thread;\n-}\n-\n-Register G1PostBarrierStubC2::tmp1() const {\n-  return _tmp1;\n-}\n-\n-Register G1PostBarrierStubC2::tmp2() const {\n-  return _tmp2;\n-}\n-\n-Register G1PostBarrierStubC2::tmp3() const {\n-  return _tmp3;\n-}\n-\n-void G1PostBarrierStubC2::emit_code(MacroAssembler& masm) {\n-  G1BarrierSetAssembler* bs = static_cast<G1BarrierSetAssembler*>(BarrierSet::barrier_set()->barrier_set_assembler());\n-  bs->generate_c2_post_barrier_stub(&masm, this);\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/c2\/g1BarrierSetC2.cpp","additions":23,"deletions":46,"binary":false,"changes":69,"status":"modified"},{"patch":"@@ -40,0 +40,4 @@\n+  static bool needs_pre_barrier(const MachNode* node);\n+  static bool needs_post_barrier(const MachNode* node);\n+  static bool post_new_val_may_be_null(const MachNode* node);\n+\n@@ -67,21 +71,0 @@\n-class G1PostBarrierStubC2 : public G1BarrierStubC2 {\n-private:\n-  Register _thread;\n-  Register _tmp1;\n-  Register _tmp2;\n-  Register _tmp3;\n-\n-protected:\n-  G1PostBarrierStubC2(const MachNode* node);\n-\n-public:\n-  static bool needs_barrier(const MachNode* node);\n-  static G1PostBarrierStubC2* create(const MachNode* node);\n-  void initialize_registers(Register thread, Register tmp1 = noreg, Register tmp2 = noreg, Register tmp3 = noreg);\n-  Register thread() const;\n-  Register tmp1() const;\n-  Register tmp2() const;\n-  Register tmp3() const;\n-  virtual void emit_code(MacroAssembler& masm);\n-};\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/c2\/g1BarrierSetC2.hpp","additions":4,"deletions":21,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -60,1 +60,0 @@\n-                                           G1RedirtyCardsQueueSet* rdcqs,\n@@ -67,2 +66,1 @@\n-    _rdc_local_qset(rdcqs),\n-    _ct(g1h->card_table()),\n+    _ct(g1h->refinement_table()),\n@@ -75,1 +73,2 @@\n-    _last_enqueued_card(SIZE_MAX),\n+    _num_cards_marked_dirty(0),\n+    _num_cards_marked_to_cset(0),\n@@ -91,1 +90,1 @@\n-    _evac_failure_enqueued_cards(0)\n+    _num_cards_from_evac_failure(0)\n@@ -115,2 +114,1 @@\n-size_t G1ParScanThreadState::flush_stats(size_t* surviving_young_words, uint num_workers, BufferNodeList* rdc_buffers) {\n-  *rdc_buffers = _rdc_local_qset.flush();\n+size_t G1ParScanThreadState::flush_stats(size_t* surviving_young_words, uint num_workers) {\n@@ -150,2 +148,10 @@\n-size_t G1ParScanThreadState::evac_failure_enqueued_cards() const {\n-  return _evac_failure_enqueued_cards;\n+size_t G1ParScanThreadState::num_cards_pending() const {\n+  return _num_cards_marked_dirty + _num_cards_from_evac_failure;\n+}\n+\n+size_t G1ParScanThreadState::num_cards_marked() const {\n+  return num_cards_pending() + _num_cards_marked_to_cset;\n+}\n+\n+size_t G1ParScanThreadState::num_cards_from_evac_failure() const {\n+  return _num_cards_from_evac_failure;\n@@ -233,1 +239,1 @@\n-  G1SkipCardEnqueueSetter x(&_scanner, dest_attr.is_new_survivor());\n+  G1SkipCardMarkSetter x(&_scanner, dest_attr.is_new_survivor());\n@@ -254,1 +260,1 @@\n-  assert(_scanner.skip_card_enqueue_set(), \"must be\");\n+  assert(_scanner.skip_card_mark_set(), \"must be\");\n@@ -456,1 +462,1 @@\n-    assert(_scanner.skip_card_enqueue_set(), \"must be\");\n+    assert(_scanner.skip_card_mark_set(), \"must be\");\n@@ -551,1 +557,1 @@\n-      G1SkipCardEnqueueSetter x(&_scanner, dest_attr.is_young());\n+      G1SkipCardMarkSetter x(&_scanner, dest_attr.is_young());\n@@ -574,1 +580,1 @@\n-      new G1ParScanThreadState(_g1h, rdcqs(),\n+      new G1ParScanThreadState(_g1h,\n@@ -600,2 +606,5 @@\n-    size_t copied_bytes = pss->flush_stats(_surviving_young_words_total, _num_workers, &_rdc_buffers[worker_id]) * HeapWordSize;\n-    size_t evac_fail_enqueued_cards = pss->evac_failure_enqueued_cards();\n+    size_t copied_bytes = pss->flush_stats(_surviving_young_words_total, _num_workers) * HeapWordSize;\n+    size_t pending_cards = pss->num_cards_pending();\n+    size_t to_young_gen_cards = pss->num_cards_marked() - pss->num_cards_pending();\n+    size_t evac_failure_cards = pss->num_cards_from_evac_failure();\n+    size_t marked_cards = pss->num_cards_marked();\n@@ -606,1 +615,4 @@\n-    p->record_or_add_thread_work_item(G1GCPhaseTimes::MergePSS, worker_id, evac_fail_enqueued_cards, G1GCPhaseTimes::MergePSSEvacFailExtra);\n+    p->record_or_add_thread_work_item(G1GCPhaseTimes::MergePSS, worker_id, pending_cards, G1GCPhaseTimes::MergePSSPendingCards);\n+    p->record_or_add_thread_work_item(G1GCPhaseTimes::MergePSS, worker_id, to_young_gen_cards, G1GCPhaseTimes::MergePSSToYoungGenCards);\n+    p->record_or_add_thread_work_item(G1GCPhaseTimes::MergePSS, worker_id, evac_failure_cards, G1GCPhaseTimes::MergePSSEvacFail);\n+    p->record_or_add_thread_work_item(G1GCPhaseTimes::MergePSS, worker_id, marked_cards, G1GCPhaseTimes::MergePSSMarked);\n@@ -612,4 +624,0 @@\n-  G1DirtyCardQueueSet& dcq = G1BarrierSet::dirty_card_queue_set();\n-  dcq.merge_bufferlists(rdcqs());\n-  rdcqs()->verify_empty();\n-\n@@ -657,1 +665,1 @@\n-      G1SkipCardEnqueueSetter x(&_scanner, false \/* skip_card_enqueue *\/);\n+      G1SkipCardMarkSetter x(&_scanner, false \/* skip_card_mark *\/);\n@@ -714,2 +722,0 @@\n-    _rdcqs(G1BarrierSet::dirty_card_queue_set().allocator()),\n-    _rdc_buffers(NEW_C_HEAP_ARRAY(BufferNodeList, num_workers, mtGC)),\n@@ -724,1 +730,0 @@\n-    _rdc_buffers[i] = BufferNodeList();\n@@ -733,1 +738,0 @@\n-  FREE_C_HEAP_ARRAY(BufferNodeList, _rdc_buffers);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":30,"deletions":26,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -301,23 +301,0 @@\n-void\n-ParallelCompactData::summarize_dense_prefix(HeapWord* beg, HeapWord* end)\n-{\n-  assert(is_region_aligned(beg), \"not RegionSize aligned\");\n-  assert(is_region_aligned(end), \"not RegionSize aligned\");\n-\n-  size_t cur_region = addr_to_region_idx(beg);\n-  const size_t end_region = addr_to_region_idx(end);\n-  HeapWord* addr = beg;\n-  while (cur_region < end_region) {\n-    _region_data[cur_region].set_destination(addr);\n-    _region_data[cur_region].set_destination_count(0);\n-    _region_data[cur_region].set_source_region(cur_region);\n-\n-    \/\/ Update live_obj_size so the region appears completely full.\n-    size_t live_size = RegionSize - _region_data[cur_region].partial_obj_size();\n-    _region_data[cur_region].set_live_obj_size(live_size);\n-\n-    ++cur_region;\n-    addr += RegionSize;\n-  }\n-}\n-\n@@ -898,1 +875,0 @@\n-      _summary_data.summarize_dense_prefix(old_space->bottom(), dense_prefix_end);\n@@ -1093,3 +1069,1 @@\n-    MarkingNMethodClosure mark_and_push_in_blobs(&cm->_mark_and_push_closure,\n-                                                 !NMethodToOopClosure::FixRelocations,\n-                                                 true \/* keepalive nmethods *\/);\n+    MarkingNMethodClosure mark_and_push_in_blobs(&cm->_mark_and_push_closure);\n@@ -1387,3 +1361,1 @@\n-    if (nworkers > 1) {\n-      Threads::change_thread_claim_token();\n-    }\n+    Threads::change_thread_claim_token();\n@@ -1543,4 +1515,3 @@\n-  RegionData* old_region = _summary_data.region(_summary_data.addr_to_region_idx(old_dense_prefix_addr));\n-  HeapWord* bump_ptr = old_region->partial_obj_size() != 0\n-                       ? old_dense_prefix_addr + old_region->partial_obj_size()\n-                       : old_dense_prefix_addr;\n+  \/\/ The destination addr for the first live obj after dense-prefix.\n+  HeapWord* bump_ptr = old_dense_prefix_addr\n+                     + _summary_data.addr_to_region_ptr(old_dense_prefix_addr)->partial_obj_size();\n@@ -1551,1 +1522,2 @@\n-    HeapWord* dense_prefix_addr = dense_prefix(SpaceId(id));\n+    \/\/ Only verify objs after dense-prefix, because those before dense-prefix are not moved (forwarded).\n+    HeapWord* cur_addr = dense_prefix(SpaceId(id));\n@@ -1553,1 +1525,0 @@\n-    HeapWord* cur_addr = dense_prefix_addr;\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":7,"deletions":36,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -489,3 +489,1 @@\n-    MarkingNMethodClosure mark_code_closure(&follow_root_closure,\n-                                            !NMethodToOopClosure::FixRelocations,\n-                                            true);\n+    MarkingNMethodClosure mark_code_closure(&follow_root_closure);\n","filename":"src\/hotspot\/share\/gc\/serial\/serialFullGC.cpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1227,1 +1227,1 @@\n-    if (new_live.is_NotEmpty()) {\n+    if (!new_live.is_Empty()) {\n","filename":"src\/hotspot\/share\/gc\/shared\/c2\/barrierSetC2.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -249,0 +249,7 @@\n+  bool is_shutting_down() const;\n+\n+  \/\/ If the VM is shutting down, we may have skipped VM_CollectForAllocation.\n+  \/\/ In this case, stall the allocation request briefly in the hope that\n+  \/\/ the VM shutdown completes before the allocation request returns.\n+  void stall_for_vm_shutdown();\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -75,2 +75,0 @@\n-void z_assert_is_barrier_safe();\n-\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrier.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -36,0 +36,17 @@\n+  static void load_barrier_all(oop src, size_t size);\n+  static void color_store_good_all(oop dst, size_t size);\n+\n+  static zaddress load_barrier_on_oop_field_preloaded(volatile zpointer* p, zpointer o);\n+  static zaddress no_keep_alive_load_barrier_on_weak_oop_field_preloaded(volatile zpointer* p, zpointer o);\n+  static zaddress no_keep_alive_load_barrier_on_phantom_oop_field_preloaded(volatile zpointer* p, zpointer o);\n+  static zaddress load_barrier_on_weak_oop_field_preloaded(volatile zpointer* p, zpointer o);\n+  static zaddress load_barrier_on_phantom_oop_field_preloaded(volatile zpointer* p, zpointer o);\n+\n+  static void store_barrier_on_heap_oop_field(volatile zpointer* p, bool heal);\n+  static void no_keep_alive_store_barrier_on_heap_oop_field(volatile zpointer* p);\n+  static void store_barrier_on_native_oop_field(volatile zpointer* p, bool heal);\n+\n+  static zaddress load_barrier_on_oop_field(volatile zpointer* p);\n+\n+  static void clone_obj_array(objArrayOop src, objArrayOop dst);\n+\n@@ -42,2 +59,0 @@\n-  static void clone_obj_array(objArrayOop src, objArrayOop dst);\n-\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrierSet.hpp","additions":17,"deletions":2,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -32,2 +32,1 @@\n-#include \"gc\/z\/zBarrier.inline.hpp\"\n-#include \"gc\/z\/zIterator.inline.hpp\"\n+#include \"gc\/z\/zHeap.hpp\"\n@@ -35,1 +34,0 @@\n-#include \"memory\/iterator.inline.hpp\"\n@@ -37,0 +35,1 @@\n+#include \"oops\/objArrayOop.hpp\"\n@@ -74,1 +73,1 @@\n-      return ZBarrier::load_barrier_on_oop_field_preloaded(p, o);\n+      return ZBarrierSet::load_barrier_on_oop_field_preloaded(p, o);\n@@ -76,1 +75,1 @@\n-      return ZBarrier::no_keep_alive_load_barrier_on_weak_oop_field_preloaded(p, o);\n+      return ZBarrierSet::no_keep_alive_load_barrier_on_weak_oop_field_preloaded(p, o);\n@@ -79,1 +78,1 @@\n-      return ZBarrier::no_keep_alive_load_barrier_on_phantom_oop_field_preloaded(p, o);\n+      return ZBarrierSet::no_keep_alive_load_barrier_on_phantom_oop_field_preloaded(p, o);\n@@ -83,1 +82,1 @@\n-      return ZBarrier::load_barrier_on_oop_field_preloaded(p, o);\n+      return ZBarrierSet::load_barrier_on_oop_field_preloaded(p, o);\n@@ -85,1 +84,1 @@\n-      return ZBarrier::load_barrier_on_weak_oop_field_preloaded(p, o);\n+      return ZBarrierSet::load_barrier_on_weak_oop_field_preloaded(p, o);\n@@ -88,1 +87,1 @@\n-      return ZBarrier::load_barrier_on_phantom_oop_field_preloaded(p, o);\n+      return ZBarrierSet::load_barrier_on_phantom_oop_field_preloaded(p, o);\n@@ -103,1 +102,1 @@\n-      return ZBarrier::load_barrier_on_oop_field_preloaded(p, o);\n+      return ZBarrierSet::load_barrier_on_oop_field_preloaded(p, o);\n@@ -105,1 +104,1 @@\n-      return ZBarrier::no_keep_alive_load_barrier_on_weak_oop_field_preloaded(p, o);\n+      return ZBarrierSet::no_keep_alive_load_barrier_on_weak_oop_field_preloaded(p, o);\n@@ -108,1 +107,1 @@\n-      return ZBarrier::no_keep_alive_load_barrier_on_phantom_oop_field_preloaded(p, o);\n+      return ZBarrierSet::no_keep_alive_load_barrier_on_phantom_oop_field_preloaded(p, o);\n@@ -112,1 +111,1 @@\n-      return ZBarrier::load_barrier_on_oop_field_preloaded(p, o);\n+      return ZBarrierSet::load_barrier_on_oop_field_preloaded(p, o);\n@@ -114,1 +113,1 @@\n-      return ZBarrier::load_barrier_on_weak_oop_field_preloaded(p, o);\n+      return ZBarrierSet::load_barrier_on_weak_oop_field_preloaded(p, o);\n@@ -117,1 +116,1 @@\n-      return ZBarrier::load_barrier_on_phantom_oop_field_preloaded(p, o);\n+      return ZBarrierSet::load_barrier_on_phantom_oop_field_preloaded(p, o);\n@@ -132,1 +131,1 @@\n-    ZBarrier::store_barrier_on_heap_oop_field(p, true \/* heal *\/);\n+    ZBarrierSet::store_barrier_on_heap_oop_field(p, true \/* heal *\/);\n@@ -141,1 +140,1 @@\n-    ZBarrier::store_barrier_on_heap_oop_field(p, false \/* heal *\/);\n+    ZBarrierSet::store_barrier_on_heap_oop_field(p, false \/* heal *\/);\n@@ -148,1 +147,1 @@\n-    ZBarrier::no_keep_alive_store_barrier_on_heap_oop_field(p);\n+    ZBarrierSet::no_keep_alive_store_barrier_on_heap_oop_field(p);\n@@ -155,1 +154,1 @@\n-    ZBarrier::store_barrier_on_native_oop_field(p, true \/* heal *\/);\n+    ZBarrierSet::store_barrier_on_native_oop_field(p, true \/* heal *\/);\n@@ -164,1 +163,1 @@\n-    ZBarrier::store_barrier_on_native_oop_field(p, false \/* heal *\/);\n+    ZBarrierSet::store_barrier_on_native_oop_field(p, false \/* heal *\/);\n@@ -331,1 +330,1 @@\n-  return ZBarrier::load_barrier_on_oop_field(src);\n+  return ZBarrierSet::load_barrier_on_oop_field(src);\n@@ -364,1 +363,0 @@\n-\n@@ -430,25 +428,0 @@\n-class ZColorStoreGoodOopClosure : public BasicOopIterateClosure {\n-public:\n-  virtual void do_oop(oop* p_) {\n-    volatile zpointer* const p = (volatile zpointer*)p_;\n-    const zpointer ptr = ZBarrier::load_atomic(p);\n-    const zaddress addr = ZPointer::uncolor(ptr);\n-    AtomicAccess::store(p, ZAddress::store_good(addr));\n-  }\n-\n-  virtual void do_oop(narrowOop* p) {\n-    ShouldNotReachHere();\n-  }\n-};\n-\n-class ZLoadBarrierOopClosure : public BasicOopIterateClosure {\n-public:\n-  virtual void do_oop(oop* p) {\n-    ZBarrier::load_barrier_on_oop_field((zpointer*)p);\n-  }\n-\n-  virtual void do_oop(narrowOop* p) {\n-    ShouldNotReachHere();\n-  }\n-};\n-\n@@ -471,2 +444,1 @@\n-  ZLoadBarrierOopClosure cl;\n-  ZIterator::oop_iterate(src, &cl);\n+  ZBarrierSet::load_barrier_all(src, size);\n@@ -477,4 +449,1 @@\n-  assert(dst->is_typeArray() || ZHeap::heap()->is_young(to_zaddress(dst)), \"ZColorStoreGoodOopClosure is only valid for young objects\");\n-\n-  ZColorStoreGoodOopClosure cl_sg;\n-  ZIterator::oop_iterate(dst, &cl_sg);\n+  ZBarrierSet::color_store_good_all(dst, size);\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrierSet.inline.hpp","additions":22,"deletions":53,"binary":false,"changes":75,"status":"modified"},{"patch":"@@ -367,1 +367,1 @@\n-    \/\/ before the concurrent processign of the code cache, make sure that\n+    \/\/ before the concurrent processing of the code cache, make sure that\n","filename":"src\/hotspot\/share\/gc\/z\/zHeapIterator.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -391,1 +391,0 @@\n-\n@@ -793,1 +792,0 @@\n-  ZMark* const                  _mark;\n@@ -804,1 +802,1 @@\n-  ZMarkOldRootsTask(ZMark* mark)\n+  ZMarkOldRootsTask()\n@@ -806,1 +804,0 @@\n-      _mark(mark),\n@@ -851,1 +848,0 @@\n-  ZMark* const               _mark;\n@@ -862,1 +858,1 @@\n-  ZMarkYoungRootsTask(ZMark* mark)\n+  ZMarkYoungRootsTask()\n@@ -864,1 +860,0 @@\n-      _mark(mark),\n@@ -932,1 +927,1 @@\n-  ZMarkYoungRootsTask task(this);\n+  ZMarkYoungRootsTask task;\n@@ -938,1 +933,1 @@\n-  ZMarkOldRootsTask task(this);\n+  ZMarkOldRootsTask task;\n","filename":"src\/hotspot\/share\/gc\/z\/zMark.cpp","additions":4,"deletions":9,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -24,0 +24,1 @@\n+#include \"gc\/z\/zGeneration.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/z\/zObjArrayAllocator.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -563,0 +563,1 @@\n+  declare_constant_with_value(\"CardTable::clean_card\", CardTable::clean_card_val()) \\\n@@ -934,1 +935,0 @@\n-  G1GC_ONLY(declare_function(JVMCIRuntime::write_barrier_post))           \\\n@@ -953,1 +953,0 @@\n-  declare_constant_with_value(\"G1CardTable::g1_young_gen\", G1CardTable::g1_young_card_val()) \\\n@@ -957,2 +956,1 @@\n-  declare_constant_with_value(\"G1ThreadLocalData::dirty_card_queue_index_offset\", in_bytes(G1ThreadLocalData::dirty_card_queue_index_offset())) \\\n-  declare_constant_with_value(\"G1ThreadLocalData::dirty_card_queue_buffer_offset\", in_bytes(G1ThreadLocalData::dirty_card_queue_buffer_offset()))\n+  declare_constant_with_value(\"G1ThreadLocalData::card_table_base_offset\", in_bytes(G1ThreadLocalData::card_table_base_offset())) \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":2,"deletions":4,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -265,2 +265,2 @@\n-class MarkingNMethodClosure : public NMethodToOopClosure {\n-  bool _keepalive_nmethods;\n+class MarkingNMethodClosure : public NMethodClosure {\n+  OopClosure* _cl;\n@@ -269,3 +269,1 @@\n-  MarkingNMethodClosure(OopClosure* cl, bool fix_relocations, bool keepalive_nmethods) :\n-      NMethodToOopClosure(cl, fix_relocations),\n-      _keepalive_nmethods(keepalive_nmethods) {}\n+  MarkingNMethodClosure(OopClosure* cl) : _cl(cl) {}\n","filename":"src\/hotspot\/share\/memory\/iterator.hpp","additions":3,"deletions":5,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,1 +30,0 @@\n-#include \"cds\/aotLinkedClassBulkLoader.hpp\"\n@@ -56,6 +55,1 @@\n-  ClassLoaderData* cld = k->class_loader_data();\n-  if (cld != nullptr) {\n-    ClaimMetadataVisitingOopIterateClosure::do_cld(cld);\n-  } else {\n-    assert(AOTLinkedClassBulkLoader::is_pending_aot_linked_class(k), \"sanity\");\n-  }\n+  ClaimMetadataVisitingOopIterateClosure::do_cld(k->class_loader_data());\n","filename":"src\/hotspot\/share\/memory\/iterator.inline.hpp","additions":2,"deletions":8,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -189,0 +189,1 @@\n+volatile bool   Universe::_is_shutting_down = false;\n@@ -587,0 +588,5 @@\n+  if (CDSConfig::is_using_aot_linked_classes()) {\n+    \/\/ All mirrors of preloaded classes are already restored. No need to fix up.\n+    return;\n+  }\n+\n@@ -1363,1 +1369,8 @@\n-  log_cpu_time();\n+  {\n+    \/\/ Acquire the Heap_lock to synchronize with VM_Heap_Sync_Operations,\n+    \/\/ which may depend on the value of _is_shutting_down flag.\n+    MutexLocker hl(Heap_lock);\n+    log_cpu_time();\n+    AtomicAccess::release_store(&_is_shutting_down, true);\n+  }\n+\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":14,"deletions":1,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -132,0 +132,3 @@\n+  \/\/ Shutdown\n+  static volatile bool _is_shutting_down;\n+\n@@ -331,0 +334,2 @@\n+  static bool is_shutting_down()                  { return  AtomicAccess::load_acquire(&_is_shutting_down); }\n+\n","filename":"src\/hotspot\/share\/memory\/universe.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -47,4 +47,0 @@\n-void* ArrayKlass::operator new(size_t size, ClassLoaderData* loader_data, size_t word_size, TRAPS) throw() {\n-  return Metaspace::allocate(loader_data, word_size, MetaspaceObj::ClassType, true, THREAD);\n-}\n-\n","filename":"src\/hotspot\/share\/oops\/arrayKlass.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -71,2 +71,0 @@\n-  void* operator new(size_t size, ClassLoaderData* loader_data, size_t word_size, TRAPS) throw();\n-\n","filename":"src\/hotspot\/share\/oops\/arrayKlass.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -479,5 +479,0 @@\n-void* InstanceKlass::operator new(size_t size, ClassLoaderData* loader_data, size_t word_size,\n-                                  bool use_class_space, TRAPS) throw() {\n-  return Metaspace::allocate(loader_data, word_size, ClassType, use_class_space, THREAD);\n-}\n-\n@@ -497,1 +492,0 @@\n-  const bool use_class_space = UseClassMetaspaceForAllClasses || parser.klass_needs_narrow_id();\n@@ -502,1 +496,1 @@\n-    ik = new (loader_data, size, use_class_space, THREAD) InstanceRefKlass(parser);\n+    ik = new (loader_data, size, THREAD) InstanceRefKlass(parser);\n@@ -505,1 +499,1 @@\n-    ik = new (loader_data, size, use_class_space, THREAD) InstanceMirrorKlass(parser);\n+    ik = new (loader_data, size, THREAD) InstanceMirrorKlass(parser);\n@@ -508,1 +502,1 @@\n-    ik = new (loader_data, size, use_class_space, THREAD) InstanceStackChunkKlass(parser);\n+    ik = new (loader_data, size, THREAD) InstanceStackChunkKlass(parser);\n@@ -511,1 +505,1 @@\n-    ik = new (loader_data, size, use_class_space, THREAD) InstanceClassLoaderKlass(parser);\n+    ik = new (loader_data, size, THREAD) InstanceClassLoaderKlass(parser);\n@@ -514,1 +508,1 @@\n-    ik = new (loader_data, size, use_class_space, THREAD) InlineKlass(parser);\n+    ik = new (loader_data, size, THREAD) InlineKlass(parser);\n@@ -517,1 +511,1 @@\n-    ik = new (loader_data, size, use_class_space, THREAD) InstanceKlass(parser);\n+    ik = new (loader_data, size, THREAD) InstanceKlass(parser);\n@@ -520,1 +514,1 @@\n-  if (ik != nullptr && UseCompressedClassPointers && use_class_space) {\n+  if (ik != nullptr && UseCompressedClassPointers) {\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":7,"deletions":13,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -208,2 +208,0 @@\n-  void* operator new(size_t size, ClassLoaderData* loader_data, size_t word_size, bool use_class_space, TRAPS) throw();\n-\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -277,0 +277,4 @@\n+void* Klass::operator new(size_t size, ClassLoaderData* loader_data, size_t word_size, TRAPS) throw() {\n+  return Metaspace::allocate(loader_data, word_size, MetaspaceObj::ClassType, THREAD);\n+}\n+\n@@ -1044,1 +1048,1 @@\n-  if (UseCompressedClassPointers && needs_narrow_id()) {\n+  if (UseCompressedClassPointers) {\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -214,0 +214,2 @@\n+  void* operator new(size_t size, ClassLoaderData* loader_data, size_t word_size, TRAPS) throw();\n+\n@@ -829,4 +831,0 @@\n-\n-  \/\/ Returns true if this Klass needs to be addressable via narrow Klass ID.\n-  inline bool needs_narrow_id() const;\n-\n","filename":"src\/hotspot\/share\/oops\/klass.hpp","additions":2,"deletions":4,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -66,5 +66,2 @@\n-    \/\/ Note that only those Klass that can be instantiated have a narrow Klass ID.\n-    \/\/ For those who don't, we leave the klass bits empty and assert if someone\n-    \/\/ tries to use those.\n-    const narrowKlass nk = CompressedKlassPointers::is_encodable(kls) ?\n-        CompressedKlassPointers::encode(const_cast<Klass*>(kls)) : 0;\n+    precond(CompressedKlassPointers::is_encodable(kls));\n+    const narrowKlass nk = CompressedKlassPointers::encode(const_cast<Klass*>(kls));\n@@ -191,9 +188,0 @@\n-\/\/ Returns true if this Klass needs to be addressable via narrow Klass ID.\n-inline bool Klass::needs_narrow_id() const {\n-  \/\/ Classes that are never instantiated need no narrow Klass Id, since the\n-  \/\/ only point of having a narrow id is to put it into an object header. Keeping\n-  \/\/ never instantiated classes out of class space lessens the class space pressure.\n-  \/\/ For more details, see JDK-8338526.\n-  \/\/ Note: don't call this function before access flags are initialized.\n-  return UseClassMetaspaceForAllClasses || (!is_abstract() && !is_interface());\n-}\n","filename":"src\/hotspot\/share\/oops\/klass.inline.hpp","additions":2,"deletions":14,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -1340,0 +1340,1 @@\n+#ifndef ZERO\n@@ -1341,0 +1342,1 @@\n+#endif\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -71,2 +71,0 @@\n-  \/\/ Compiler\/Interpreter offset\n-  static ByteSize element_klass_offset() { return in_ByteSize(offset_of(ObjArrayKlass, _element_klass)); }\n@@ -81,0 +79,3 @@\n+  \/\/ Compiler\/Interpreter offset\n+  static ByteSize element_klass_offset() { return byte_offset_of(ObjArrayKlass, _element_klass); }\n+\n","filename":"src\/hotspot\/share\/oops\/objArrayKlass.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -90,1 +90,10 @@\n-    klass()->oop_print_value_on(obj, st);\n+    Klass* k = klass_without_asserts();\n+    if (k == nullptr) {\n+      st->print(\"null klass\");\n+    } else if (!Metaspace::contains(k)) {\n+      st->print(\"klass not in Metaspace\");\n+    } else if (!k->is_klass()) {\n+      st->print(\"klass not a Klass\");\n+    } else {\n+      k->oop_print_value_on(obj, st);\n+    }\n","filename":"src\/hotspot\/share\/oops\/oop.cpp","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -563,0 +563,3 @@\n+  if (C->failing()) {\n+    return;\n+  }\n@@ -640,0 +643,3 @@\n+    if (C->failing()) {\n+      return;\n+    }\n@@ -770,1 +776,1 @@\n-      _lrg_map.map(n->_idx, rm.is_NotEmpty() ? lr_counter++ : 0);\n+      _lrg_map.map(n->_idx, !rm.is_Empty() ? lr_counter++ : 0);\n@@ -791,1 +797,1 @@\n-      _lrg_map.map(n->_idx, rm.is_NotEmpty() ? n->_idx : 0);\n+      _lrg_map.map(n->_idx, !rm.is_Empty() ? n->_idx : 0);\n@@ -1401,3 +1407,2 @@\n-static bool is_legal_reg(LRG &lrg, OptoReg::Name reg, int chunk) {\n-  if (reg >= chunk && reg < (chunk + RegMask::CHUNK_SIZE) &&\n-      lrg.mask().Member(OptoReg::add(reg,-chunk))) {\n+static bool is_legal_reg(LRG& lrg, OptoReg::Name reg) {\n+  if (lrg.mask().can_represent(reg) && lrg.mask().Member(reg)) {\n@@ -1426,1 +1431,1 @@\n-static OptoReg::Name find_first_set(LRG &lrg, RegMask mask, int chunk) {\n+static OptoReg::Name find_first_set(LRG& lrg, RegMask& mask) {\n@@ -1432,1 +1437,3 @@\n-    if (chunk == 0 && OptoReg::is_reg(assigned)) {\n+    if (OptoReg::is_reg(assigned)) {\n+      assert(!lrg.mask().is_offset(),\n+             \"offset register masks can only contain stack slots\");\n@@ -1448,1 +1455,2 @@\n-      while (OptoReg::is_valid(assigned) && RegMask::can_represent(assigned)) {\n+      while (OptoReg::is_valid(assigned)) {\n+        assert(mask.can_represent(assigned), \"sanity\");\n@@ -1472,1 +1480,1 @@\n-OptoReg::Name PhaseChaitin::bias_color( LRG &lrg, int chunk ) {\n+OptoReg::Name PhaseChaitin::bias_color(LRG& lrg) {\n@@ -1486,1 +1494,1 @@\n-      if (is_legal_reg(lrg, reg, chunk))\n+      if (is_legal_reg(lrg, reg)) {\n@@ -1488,0 +1496,1 @@\n+      }\n@@ -1497,1 +1506,1 @@\n-      if (is_legal_reg(lrg, reg, chunk))\n+      if (is_legal_reg(lrg, reg)) {\n@@ -1499,1 +1508,2 @@\n-    } else if( chunk == 0 ) {\n+      }\n+    } else if (!lrg.mask().is_offset()) {\n@@ -1501,1 +1511,2 @@\n-      RegMask tempmask = lrg.mask();\n+      ResourceMark rm(C->regmask_arena());\n+      RegMask tempmask(lrg.mask(), C->regmask_arena());\n@@ -1504,1 +1515,1 @@\n-      OptoReg::Name reg = find_first_set(lrg, tempmask, chunk);\n+      OptoReg::Name reg = find_first_set(lrg, tempmask);\n@@ -1513,1 +1524,3 @@\n-    return OptoReg::add(find_first_set(lrg, lrg.mask(), chunk), chunk);\n+    ResourceMark rm(C->regmask_arena());\n+    RegMask tempmask(lrg.mask(), C->regmask_arena());\n+    return find_first_set(lrg, tempmask);\n@@ -1526,1 +1539,1 @@\n-    if( OptoReg::is_reg(reg2))\n+    if (OptoReg::is_reg(reg2)) {\n@@ -1528,0 +1541,1 @@\n+    }\n@@ -1529,1 +1543,1 @@\n-  return OptoReg::add( reg, chunk );\n+  return reg;\n@@ -1533,3 +1547,3 @@\n-OptoReg::Name PhaseChaitin::choose_color( LRG &lrg, int chunk ) {\n-  assert( C->in_preserve_stack_slots() == 0 || chunk != 0 || lrg._is_bound || lrg.mask().is_bound1() || !lrg.mask().Member(OptoReg::Name(_matcher._old_SP-1)), \"must not allocate stack0 (inside preserve area)\");\n-  assert(C->out_preserve_stack_slots() == 0 || chunk != 0 || lrg._is_bound || lrg.mask().is_bound1() || !lrg.mask().Member(OptoReg::Name(_matcher._old_SP+0)), \"must not allocate stack0 (inside preserve area)\");\n+OptoReg::Name PhaseChaitin::choose_color(LRG& lrg) {\n+  assert(C->in_preserve_stack_slots() == 0 || lrg.mask().is_offset() || lrg._is_bound || lrg.mask().is_bound1() || !lrg.mask().Member(OptoReg::Name(_matcher._old_SP - 1)), \"must not allocate stack0 (inside preserve area)\");\n+  assert(C->out_preserve_stack_slots() == 0 || lrg.mask().is_offset() || lrg._is_bound || lrg.mask().is_bound1() || !lrg.mask().Member(OptoReg::Name(_matcher._old_SP + 0)), \"must not allocate stack0 (inside preserve area)\");\n@@ -1540,1 +1554,1 @@\n-    return bias_color(lrg, chunk);\n+    return bias_color(lrg);\n@@ -1548,1 +1562,1 @@\n-  assert( !chunk, \"always color in 1st chunk\" );\n+  assert(!lrg.mask().is_offset(), \"always color in 1st chunk\");\n@@ -1588,1 +1602,0 @@\n-    int chunk = 0;              \/\/ Current chunk is first chunk\n@@ -1593,1 +1606,4 @@\n-    DEBUG_ONLY(RegMask orig_mask = lrg->mask();)\n+#ifndef PRODUCT\n+    ResourceMark rm(C->regmask_arena());\n+    RegMask orig_mask(lrg->mask(), C->regmask_arena());\n+#endif\n@@ -1599,6 +1615,0 @@\n-        \/\/ Note that neighbor might be a spill_reg.  In this case, exclusion\n-        \/\/ of its color will be a no-op, since the spill_reg chunk is in outer\n-        \/\/ space.  Also, if neighbor is in a different chunk, this exclusion\n-        \/\/ will be a no-op.  (Later on, if lrg runs out of possible colors in\n-        \/\/ its chunk, a new chunk of color may be tried, in which case\n-        \/\/ examination of neighbors is started again, at retry_next_chunk.)\n@@ -1607,2 +1617,7 @@\n-        \/\/ Only subtract masks in the same chunk\n-        if (nreg >= chunk && nreg < chunk + RegMask::CHUNK_SIZE) {\n+        \/\/ The neighbor might be a spill_reg. In this case, exclusion of its\n+        \/\/ color will be a no-op, since the spill_reg is in outer space. In\n+        \/\/ this case, do not exclude the corresponding mask. Later on, if lrg\n+        \/\/ runs out of possible colors in its chunk, a new chunk of color may\n+        \/\/ be tried, in which case examination of neighbors is started again,\n+        \/\/ at retry_next_chunk.\n+        if (nreg < LRG::SPILL_REG) {\n@@ -1611,1 +1626,2 @@\n-          RegMask rm = lrg->mask();\n+          ResourceMark rm(C->regmask_arena());\n+          RegMask trace_mask(lrg->mask(), C->regmask_arena());\n@@ -1613,1 +1629,1 @@\n-          lrg->SUBTRACT(nlrg.mask());\n+          lrg->SUBTRACT_inner(nlrg.mask());\n@@ -1618,1 +1634,1 @@\n-            rm.dump();\n+            trace_mask.dump();\n@@ -1622,2 +1638,2 @@\n-            rm.SUBTRACT(lrg->mask());\n-            rm.dump();\n+            trace_mask.SUBTRACT(lrg->mask());\n+            trace_mask.dump();\n@@ -1640,1 +1656,1 @@\n-    OptoReg::Name reg = choose_color( *lrg, chunk );\n+    OptoReg::Name reg = choose_color(*lrg);\n@@ -1643,3 +1659,5 @@\n-    \/\/ If we fail to color and the infinite flag is set, trigger\n-    \/\/ a chunk-rollover event\n-    if (!OptoReg::is_valid(OptoReg::add(reg, -chunk)) && is_infinite_stack) {\n+    \/\/ If we fail to color and the infinite flag is set, we must trigger\n+    \/\/ a chunk-rollover event and continue searching for a color in the next set\n+    \/\/ of slots (which are all necessarily stack slots, as registers are only in\n+    \/\/ the initial chunk)\n+    if (!OptoReg::is_valid(reg) && is_infinite_stack) {\n@@ -1647,2 +1665,10 @@\n-      chunk += RegMask::CHUNK_SIZE;\n-      lrg->Set_All();\n+      bool success = lrg->rollover();\n+      if (!success) {\n+        \/\/ We should never get here in practice. Bail out in product,\n+        \/\/ assert in debug.\n+        assert(false, \"the next available stack slots should be within the \"\n+                      \"OptoRegPair range\");\n+        C->record_method_not_compilable(\n+            \"chunk-rollover outside of OptoRegPair range\");\n+        return -1;\n+      }\n@@ -1656,1 +1682,2 @@\n-      RegMask avail_rm = lrg->mask();\n+      ResourceMark rm(C->regmask_arena());\n+      RegMask avail_rm(lrg->mask(), C->regmask_arena());\n@@ -1662,4 +1689,3 @@\n-      if( reg >= _max_reg )     \/\/ Compute max register limit\n-        _max_reg = OptoReg::add(reg,1);\n-      \/\/ Fold reg back into normal space\n-      reg = OptoReg::add(reg,-chunk);\n+      if (reg >= _max_reg) { \/\/ Compute max register limit\n+        _max_reg = OptoReg::add(reg, 1);\n+      }\n","filename":"src\/hotspot\/share\/opto\/chaitin.cpp","additions":74,"deletions":48,"binary":false,"changes":122,"status":"modified"},{"patch":"@@ -712,0 +712,1 @@\n+      _FIRST_STACK_mask(comp_arena()),\n@@ -713,0 +714,1 @@\n+      _regmask_arena(mtCompiler, Arena::Tag::tag_regmask),\n@@ -982,0 +984,1 @@\n+      _FIRST_STACK_mask(comp_arena()),\n@@ -983,0 +986,1 @@\n+      _regmask_arena(mtCompiler, Arena::Tag::tag_regmask),\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -536,0 +536,6 @@\n+  \/\/ Holds dynamically allocated extensions of short-lived register masks. Such\n+  \/\/ extensions are potentially quite large and need tight resource marks which\n+  \/\/ may conflict with other allocations in the default resource area.\n+  \/\/ Therefore, we use a dedicated resource area for register masks.\n+  ResourceArea          _regmask_arena;\n+\n@@ -1142,0 +1148,1 @@\n+  ResourceArea*     regmask_arena()             { return &_regmask_arena; }\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1452,1 +1452,1 @@\n-  if (mach && mach->out_RegMask().is_bound1() && mach->out_RegMask().is_NotEmpty())\n+  if (mach != nullptr && mach->out_RegMask().is_bound1() && !mach->out_RegMask().is_Empty())\n@@ -1485,1 +1485,1 @@\n-    if (mach && LCA == root_block)\n+    if (mach != nullptr && LCA == root_block)\n","filename":"src\/hotspot\/share\/opto\/gcm.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -899,1 +899,2 @@\n-  RegMask regs;\n+  ResourceMark rm(C->regmask_arena());\n+  RegMask regs(C->regmask_arena());\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"opto\/regmask.hpp\"\n@@ -41,2 +42,8 @@\n-BoxLockNode::BoxLockNode( int slot ) : Node( Compile::current()->root() ),\n-                                       _slot(slot), _kind(BoxLockNode::Regular) {\n+BoxLockNode::BoxLockNode(int slot)\n+    : Node(Compile::current()->root()),\n+      _slot(slot),\n+      \/\/ In debug mode, signal that the register mask is constant.\n+      _inmask(OptoReg::stack2reg(_slot),\n+              Compile::current()->comp_arena()\n+              DEBUG_ONLY(COMMA \/*read_only*\/ true)),\n+      _kind(BoxLockNode::Regular) {\n@@ -45,3 +52,3 @@\n-  OptoReg::Name reg = OptoReg::stack2reg(_slot);\n-  if (!RegMask::can_represent(reg, Compile::current()->sync_stack_slots())) {\n-    Compile::current()->record_method_not_compilable(\"must be able to represent all monitor slots in reg mask\");\n+  if (_slot > BoxLockNode_SLOT_LIMIT) {\n+    Compile::current()->record_method_not_compilable(\n+        \"reached BoxLockNode slot limit\");\n@@ -50,1 +57,0 @@\n-  _inmask.Insert(reg);\n","filename":"src\/hotspot\/share\/opto\/locknode.cpp","additions":12,"deletions":6,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -35,2 +35,2 @@\n-  const int     _slot; \/\/ stack slot\n-  RegMask     _inmask; \/\/ OptoReg corresponding to stack slot\n+  const int _slot;       \/\/ stack slot\n+  const RegMask _inmask; \/\/ OptoReg corresponding to stack slot\n","filename":"src\/hotspot\/share\/opto\/locknode.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -549,1 +549,1 @@\n-    if (rm.is_NotEmpty() && rm.is_bound(ideal_reg())) {\n+    if (!rm.is_Empty() && rm.is_bound(ideal_reg())) {\n","filename":"src\/hotspot\/share\/opto\/machnode.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -793,1 +793,4 @@\n-  MachProjNode( Node *multi, uint con, const RegMask &out, uint ideal_reg ) : ProjNode(multi,con), _rout(out), _ideal_reg(ideal_reg) {\n+  MachProjNode(Node* multi, uint con, const RegMask& out, uint ideal_reg)\n+      : ProjNode(multi, con),\n+        _rout(out, Compile::current()->comp_arena()),\n+        _ideal_reg(ideal_reg) {\n","filename":"src\/hotspot\/share\/opto\/machnode.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -83,1 +83,2 @@\n-  _register_save_type(register_save_type) {\n+  _register_save_type(register_save_type),\n+  _return_addr_mask(C->comp_arena()) {\n@@ -143,6 +144,0 @@\n-    if (!RegMask::can_represent_arg(warped)) {\n-      \/\/ the compiler cannot represent this method's calling sequence\n-      \/\/ Bailout. We do not have space to represent all arguments.\n-      C->record_method_not_compilable(\"unsupported incoming calling sequence\");\n-      return OptoReg::Bad;\n-    }\n@@ -202,0 +197,1 @@\n+    new (mask + i) RegMask();\n@@ -245,1 +241,3 @@\n-  _return_addr_mask = return_addr();\n+  assert(_return_addr_mask.is_Empty(),\n+         \"return address mask must be empty initially\");\n+  _return_addr_mask.Insert(return_addr());\n@@ -270,0 +268,1 @@\n+    new (_calling_convention_mask + i) RegMask(C->comp_arena());\n@@ -326,3 +325,0 @@\n-    if (C->failing()) {\n-      return;\n-    }\n@@ -333,3 +329,0 @@\n-    if (C->failing()) {\n-      return;\n-    }\n@@ -356,8 +349,0 @@\n-  if (!RegMask::can_represent_arg(OptoReg::add(_out_arg_limit,-1))) {\n-    \/\/ the compiler cannot represent this method's calling sequence\n-    \/\/ Bailout. We do not have space to represent all arguments.\n-    C->record_method_not_compilable(\"must be able to represent all call arguments in reg mask\");\n-  }\n-\n-  if (C->failing())  return;  \/\/ bailed out on incoming arg failure\n-\n@@ -486,0 +471,3 @@\n+  for (unsigned int i = 0; i < size; ++i) {\n+    new (rms + i) RegMask(Compile::current()->comp_arena());\n+  }\n@@ -525,1 +513,1 @@\n-    new (rms + i) RegMask();\n+    new (rms + i) RegMask(C->comp_arena());\n@@ -574,2 +562,0 @@\n-  OptoReg::Name i;\n-\n@@ -581,1 +567,1 @@\n-  for (i = init_in; i < _in_arg_limit; i = OptoReg::add(i,1)) {\n+  for (OptoReg::Name i = init_in; i < _in_arg_limit; i = OptoReg::add(i, 1)) {\n@@ -586,8 +572,1 @@\n-  guarantee(RegMask::can_represent_arg(OptoReg::add(_out_arg_limit,-1)),\n-            \"must be able to represent all call arguments in reg mask\");\n-  OptoReg::Name init = _out_arg_limit;\n-  for (i = init; RegMask::can_represent(i); i = OptoReg::add(i,1)) {\n-    C->FIRST_STACK_mask().Insert(i);\n-  }\n-  \/\/ Finally, set the \"infinite stack\" bit.\n-  C->FIRST_STACK_mask().set_infinite_stack();\n+  C->FIRST_STACK_mask().Set_All_From(_out_arg_limit);\n@@ -596,1 +575,1 @@\n-  RegMask aligned_stack_mask = C->FIRST_STACK_mask();\n+  RegMask aligned_stack_mask(C->FIRST_STACK_mask(), C->comp_arena());\n@@ -600,1 +579,1 @@\n-  RegMask scalable_stack_mask = aligned_stack_mask;\n+  RegMask scalable_stack_mask(aligned_stack_mask, C->comp_arena());\n@@ -1019,1 +998,1 @@\n-  c_frame_ptr_mask = c_frame_pointer();\n+  c_frame_ptr_mask = RegMask(c_frame_pointer());\n@@ -1027,6 +1006,1 @@\n-  OptoReg::Name init = OptoReg::stack2reg(0);\n-  OptoReg::Name i;\n-  for (i = init; RegMask::can_represent(i); i = OptoReg::add(i,1))\n-    STACK_ONLY_mask.Insert(i);\n-  \/\/ Also set the \"infinite stack\" bit.\n-  STACK_ONLY_mask.set_infinite_stack();\n+  STACK_ONLY_mask.Set_All_From(OptoReg::stack2reg(0));\n@@ -1035,1 +1009,2 @@\n-  for (i = OptoReg::Name(0); i < OptoReg::Name(_last_Mach_Reg); i = OptoReg::add(i, 1)) {\n+  for (OptoReg::Name i = OptoReg::Name(0); i < OptoReg::Name(_last_Mach_Reg);\n+       i = OptoReg::add(i, 1)) {\n@@ -1316,6 +1291,2 @@\n-    if( warped >= out_arg_limit_per_call )\n-      out_arg_limit_per_call = OptoReg::add(warped,1);\n-    if (!RegMask::can_represent_arg(warped)) {\n-      \/\/ Bailout. For example not enough space on stack for all arguments. Happens for methods with too many arguments.\n-      C->record_method_not_compilable(\"unsupported calling sequence\");\n-      return OptoReg::Bad;\n+    if (warped >= out_arg_limit_per_call) {\n+      out_arg_limit_per_call = OptoReg::add(warped, 1);\n@@ -1405,1 +1376,3 @@\n-  for (uint i = 0; i < cnt; i++) ::new (&(msfpt->_in_rms[i])) RegMask();\n+  for (uint i = 0; i < cnt; i++) {\n+    ::new (msfpt->_in_rms + i) RegMask(C->comp_arena());\n+  }\n@@ -1491,3 +1464,0 @@\n-      if (C->failing()) {\n-        return nullptr;\n-      }\n@@ -1499,3 +1469,0 @@\n-      if (C->failing()) {\n-        return nullptr;\n-      }\n@@ -1522,6 +1489,2 @@\n-    if (!RegMask::can_represent_arg(OptoReg::Name(out_arg_limit_per_call-1))) {\n-      \/\/ Bailout. We do not have space to represent all arguments.\n-      C->record_method_not_compilable(\"unsupported outgoing calling sequence\");\n-    } else {\n-      for (int i = begin_out_arg_area; i < out_arg_limit_per_call; i++)\n-        proj->_rout.Insert(OptoReg::Name(i));\n+    for (int i = begin_out_arg_area; i < out_arg_limit_per_call; i++) {\n+      proj->_rout.Insert(OptoReg::Name(i));\n@@ -1529,1 +1492,1 @@\n-    if (proj->_rout.is_NotEmpty()) {\n+    if (!proj->_rout.is_Empty()) {\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":27,"deletions":64,"binary":false,"changes":91,"status":"modified"},{"patch":"@@ -553,0 +553,8 @@\n+  if (this->is_MachProj()) {\n+    \/\/ MachProjNodes contain register masks that may contain pointers to\n+    \/\/ externally allocated memory. Make sure to use a proper constructor\n+    \/\/ instead of just shallowly copying.\n+    MachProjNode* mach = n->as_MachProj();\n+    MachProjNode* mthis = this->as_MachProj();\n+    new (&mach->_rout) RegMask(mthis->_rout);\n+  }\n","filename":"src\/hotspot\/share\/opto\/node.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2432,6 +2432,20 @@\n-\/\/ All functions from this section should call the jvmtiThreadSate function:\n-\/\/   Klass* class_to_verify_considering_redefinition(Klass* klass).\n-\/\/ The function returns a Klass* of the _scratch_class if the verifier\n-\/\/ was invoked in the middle of the class redefinition.\n-\/\/ Otherwise it returns its argument value which is the _the_class Klass*.\n-\/\/ Please, refer to the description in the jvmtiThreadState.hpp.\n+\/\/ All functions from this section, unless noted otherwise, should call the functions\n+\/\/   get_klass_considering_redefinition(), or\n+\/\/   get_instance_klass_considering_redefinition()\n+\/\/ These functions return JvmtiThreadState::_scratch_class if the verifier\n+\/\/ was invoked in the middle of the redefinition of cls.\n+\/\/ See jvmtiThreadState.hpp for details.\n+\n+inline Klass* get_klass_considering_redefinition(jclass cls, JavaThread* thread) {\n+  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n+  if (k->is_instance_klass()) {\n+    return JvmtiThreadState::class_to_verify_considering_redefinition(InstanceKlass::cast(k), thread);\n+  } else {\n+    return k;\n+  }\n+}\n+\n+inline InstanceKlass* get_instance_klass_considering_redefinition(jclass cls, JavaThread* thread) {\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve_non_null(cls));\n+  return JvmtiThreadState::class_to_verify_considering_redefinition(ik, thread);\n+}\n@@ -2445,1 +2459,1 @@\n-  \/\/ This isn't necessary since answer is the same since redefinition\n+  \/\/ This isn't necessary since answer is the same because redefinition\n@@ -2447,1 +2461,1 @@\n-  \/\/ k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n+  \/\/ k = get_klass_considering_redefinition(cls, thread)\n@@ -2454,1 +2468,1 @@\n-\n+  \/\/ No need to call get_klass_considering_redefinition() as redefinition cannot change a class's name.\n@@ -2457,1 +2471,0 @@\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n@@ -2463,2 +2476,1 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n+  Klass* k = get_klass_considering_redefinition(cls, thread);\n@@ -2478,2 +2490,1 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n+  Klass* k = get_klass_considering_redefinition(cls, thread);\n@@ -2485,2 +2496,1 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n+  Klass* k = get_klass_considering_redefinition(cls, thread);\n@@ -2492,2 +2502,1 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n+  Klass* k = get_klass_considering_redefinition(cls, thread);\n@@ -2504,3 +2513,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2518,3 +2526,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2526,3 +2533,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2534,3 +2540,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2542,3 +2547,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2554,3 +2558,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2562,3 +2565,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2570,3 +2572,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  return InstanceKlass::cast(k)->field_access_flags(field_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  return ik->field_access_flags(field_index);\n@@ -2577,3 +2578,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2585,3 +2585,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2593,3 +2592,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2602,3 +2600,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2611,3 +2608,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2618,3 +2614,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2626,3 +2621,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  Method* method = InstanceKlass::cast(k)->methods()->at(method_index);\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  Method* method = ik->methods()->at(method_index);\n@@ -2641,3 +2635,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  ConstantPool* cp = InstanceKlass::cast(k)->constants();\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  ConstantPool* cp = ik->constants();\n@@ -2656,3 +2649,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  ConstantPool* cp = InstanceKlass::cast(k)->constants();\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  ConstantPool* cp = ik->constants();\n@@ -2672,3 +2664,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  ConstantPool* cp = InstanceKlass::cast(k)->constants();\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  ConstantPool* cp = ik->constants();\n@@ -2688,3 +2679,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  ConstantPool* cp = InstanceKlass::cast(k)->constants();\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  ConstantPool* cp = ik->constants();\n@@ -2703,3 +2693,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  ConstantPool* cp = InstanceKlass::cast(k)->constants();\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  ConstantPool* cp = ik->constants();\n@@ -2712,3 +2701,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  ConstantPool* cp = InstanceKlass::cast(k)->constants();\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  ConstantPool* cp = ik->constants();\n@@ -2730,3 +2718,2 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  ConstantPool* cp = InstanceKlass::cast(k)->constants();\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  ConstantPool* cp = ik->constants();\n@@ -2749,6 +2736,4 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  Klass* k_called = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(called_cls));\n-  k        = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  k_called = JvmtiThreadState::class_to_verify_considering_redefinition(k_called, thread);\n-  ConstantPool* cp = InstanceKlass::cast(k)->constants();\n-  ConstantPool* cp_called = InstanceKlass::cast(k_called)->constants();\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  InstanceKlass* ik_called = get_instance_klass_considering_redefinition(called_cls, thread);\n+  ConstantPool* cp = ik->constants();\n+  ConstantPool* cp_called = ik_called->constants();\n@@ -2759,2 +2744,1 @@\n-      InstanceKlass* ik = InstanceKlass::cast(k_called);\n-      for (JavaFieldStream fs(ik); !fs.done(); fs.next()) {\n+      for (JavaFieldStream fs(ik_called); !fs.done(); fs.next()) {\n@@ -2776,5 +2760,3 @@\n-  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));\n-  Klass* k_called = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(called_cls));\n-  k        = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);\n-  k_called = JvmtiThreadState::class_to_verify_considering_redefinition(k_called, thread);\n-  ConstantPool* cp = InstanceKlass::cast(k)->constants();\n+  InstanceKlass* ik = get_instance_klass_considering_redefinition(cls, thread);\n+  InstanceKlass* ik_called = get_instance_klass_considering_redefinition(called_cls, thread);\n+  ConstantPool* cp = ik->constants();\n@@ -2786,1 +2768,1 @@\n-      Array<Method*>* methods = InstanceKlass::cast(k_called)->methods();\n+      Array<Method*>* methods = ik_called->methods();\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":80,"deletions":98,"binary":false,"changes":178,"status":"modified"},{"patch":"@@ -102,1 +102,1 @@\n-  return InstanceKlass::cast(java_lang_Class::as_Klass(mirror));\n+  return java_lang_Class::as_InstanceKlass(mirror);\n@@ -1312,1 +1312,1 @@\n-  Klass*            _scratch_class;\n+  InstanceKlass*    _scratch_class;\n@@ -1317,1 +1317,1 @@\n-  RedefineVerifyMark(Klass* the_class, Klass* scratch_class,\n+  RedefineVerifyMark(InstanceKlass* the_class, InstanceKlass* scratch_class,\n","filename":"src\/hotspot\/share\/prims\/jvmtiRedefineClasses.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -127,0 +127,1 @@\n+#include \"gc\/z\/zHeap.inline.hpp\"\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -562,0 +562,1 @@\n+  { \"G1UpdateBufferSize\",           JDK_Version::undefined(), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2053,3 +2053,0 @@\n-  product(bool, UseClassMetaspaceForAllClasses, false, DIAGNOSTIC,          \\\n-          \"Use the class metaspace for all classes including \"              \\\n-          \"abstract and interface classes.\")                                \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2613,2 +2613,1 @@\n-static void post_adapter_creation(const AdapterBlob* new_adapter,\n-                                  const AdapterHandlerEntry* entry) {\n+static void post_adapter_creation(const AdapterHandlerEntry* entry) {\n@@ -2616,0 +2615,1 @@\n+    AdapterBlob* adapter_blob = entry->adapter_blob();\n@@ -2620,1 +2620,1 @@\n-                 new_adapter->name(),\n+                 adapter_blob->name(),\n@@ -2623,1 +2623,1 @@\n-      Forte::register_stub(blob_id, new_adapter->content_begin(), new_adapter->content_end());\n+      Forte::register_stub(blob_id, adapter_blob->content_begin(), adapter_blob->content_end());\n@@ -2627,1 +2627,1 @@\n-      JvmtiExport::post_dynamic_code_generated(blob_id, new_adapter->content_begin(), new_adapter->content_end());\n+      JvmtiExport::post_dynamic_code_generated(blob_id, adapter_blob->content_begin(), adapter_blob->content_end());\n@@ -2649,5 +2649,0 @@\n-  AdapterBlob* no_arg_blob = nullptr;\n-  AdapterBlob* int_arg_blob = nullptr;\n-  AdapterBlob* obj_arg_blob = nullptr;\n-  AdapterBlob* obj_int_arg_blob = nullptr;\n-  AdapterBlob* obj_obj_arg_blob = nullptr;\n@@ -2659,1 +2654,1 @@\n-    _no_arg_handler = create_adapter(no_arg_blob, no_args, true);\n+    _no_arg_handler = create_adapter(no_args, true);\n@@ -2664,1 +2659,1 @@\n-    _obj_arg_handler = create_adapter(obj_arg_blob, obj_args, true);\n+    _obj_arg_handler = create_adapter(obj_args, true);\n@@ -2669,1 +2664,1 @@\n-    _int_arg_handler = create_adapter(int_arg_blob, int_args, true);\n+    _int_arg_handler = create_adapter(int_args, true);\n@@ -2675,1 +2670,1 @@\n-    _obj_int_arg_handler = create_adapter(obj_int_arg_blob, obj_int_args, true);\n+    _obj_int_arg_handler = create_adapter(obj_int_args, true);\n@@ -2681,1 +2676,1 @@\n-    _obj_obj_arg_handler = create_adapter(obj_obj_arg_blob, obj_obj_args, true);\n+    _obj_obj_arg_handler = create_adapter(obj_obj_args, true);\n@@ -2695,5 +2690,5 @@\n-  post_adapter_creation(no_arg_blob, _no_arg_handler);\n-  post_adapter_creation(obj_arg_blob, _obj_arg_handler);\n-  post_adapter_creation(int_arg_blob, _int_arg_handler);\n-  post_adapter_creation(obj_int_arg_blob, _obj_int_arg_handler);\n-  post_adapter_creation(obj_obj_arg_blob, _obj_obj_arg_handler);\n+  post_adapter_creation(_no_arg_handler);\n+  post_adapter_creation(_obj_arg_handler);\n+  post_adapter_creation(_int_arg_handler);\n+  post_adapter_creation(_obj_int_arg_handler);\n+  post_adapter_creation(_obj_obj_arg_handler);\n@@ -3117,3 +3112,2 @@\n-  AdapterBlob* comparison_blob = nullptr;\n-  AdapterHandlerEntry* comparison_entry = create_adapter(comparison_blob, ces, false, true);\n-  assert(comparison_blob == nullptr, \"no blob should be created when creating an adapter for comparison\");\n+  AdapterHandlerEntry* comparison_entry = create_adapter(ces, false, true);\n+  assert(comparison_entry->adapter_blob() == nullptr, \"no blob should be created when creating an adapter for comparison\");\n@@ -3141,1 +3135,1 @@\n-  AdapterBlob* adapter_blob = nullptr;\n+  bool new_entry = false;\n@@ -3160,13 +3154,0 @@\n-    if (ces.has_scalarized_args() && method->is_abstract()) {\n-      \/\/ Save a C heap allocated version of the signature for abstract methods with scalarized inline type arguments\n-      address wrong_method_abstract = SharedRuntime::get_handle_wrong_method_abstract_stub();\n-      entry = AdapterHandlerLibrary::new_entry(AdapterFingerPrint::allocate(nullptr));\n-      entry->set_entry_points(SharedRuntime::throw_AbstractMethodError_entry(),\n-                              wrong_method_abstract, wrong_method_abstract, wrong_method_abstract,\n-                              wrong_method_abstract, wrong_method_abstract);\n-      GrowableArray<SigEntry>* heap_sig = new (mtInternal) GrowableArray<SigEntry>(ces.sig_cc_ro()->length(), mtInternal);\n-      heap_sig->appendAll(ces.sig_cc_ro());\n-      entry->set_sig_cc(heap_sig);\n-      return entry;\n-    }\n-\n@@ -3177,0 +3158,1 @@\n+#ifndef ZERO\n@@ -3178,0 +3160,1 @@\n+#endif\n@@ -3184,1 +3167,4 @@\n-      entry = create_adapter(adapter_blob, ces, \/* allocate_code_blob *\/ true);\n+      entry = create_adapter(ces, \/* allocate_code_blob *\/ true);\n+      if (entry != nullptr) {\n+        new_entry = true;\n+      }\n@@ -3189,2 +3175,2 @@\n-  if (adapter_blob != nullptr) {\n-    post_adapter_creation(adapter_blob, entry);\n+  if (new_entry) {\n+    post_adapter_creation(entry);\n@@ -3195,1 +3181,1 @@\n-AdapterBlob* AdapterHandlerLibrary::lookup_aot_cache(AdapterHandlerEntry* handler) {\n+void AdapterHandlerLibrary::lookup_aot_cache(AdapterHandlerEntry* handler) {\n@@ -3199,2 +3185,0 @@\n-  int offsets[AdapterBlob::ENTRY_COUNT];\n-  AdapterBlob* adapter_blob = nullptr;\n@@ -3204,15 +3188,2 @@\n-    adapter_blob = blob->as_adapter_blob();\n-    adapter_blob->get_offsets(offsets);\n-    address i2c_entry = adapter_blob->content_begin();\n-    assert(offsets[0] == 0, \"sanity check\");\n-    handler->set_entry_points(\n-      i2c_entry,\n-      (offsets[1] != -1) ? (i2c_entry + offsets[1]) : nullptr,\n-      (offsets[2] != -1) ? (i2c_entry + offsets[2]) : nullptr,\n-      (offsets[3] != -1) ? (i2c_entry + offsets[3]) : nullptr,\n-      (offsets[4] != -1) ? (i2c_entry + offsets[4]) : nullptr,\n-      (offsets[5] != -1) ? (i2c_entry + offsets[5]) : nullptr,\n-      (offsets[6] != -1) ? (i2c_entry + offsets[6]) : nullptr\n-    );\n-  }\n-  return adapter_blob;\n+    handler->set_adapter_blob(blob->as_adapter_blob());\n+  }\n@@ -3222,1 +3193,1 @@\n-void AdapterHandlerLibrary::print_adapter_handler_info(outputStream* st, AdapterHandlerEntry* handler, AdapterBlob* adapter_blob) {\n+void AdapterHandlerLibrary::print_adapter_handler_info(outputStream* st, AdapterHandlerEntry* handler) {\n@@ -3228,0 +3199,1 @@\n+  AdapterBlob* adapter_blob = handler->adapter_blob();\n@@ -3237,1 +3209,1 @@\n-    address first_pc = handler->base_address();\n+    address first_pc = adapter_blob->content_begin();\n@@ -3246,2 +3218,16 @@\n-bool AdapterHandlerLibrary::generate_adapter_code(AdapterBlob*& adapter_blob,\n-                                                  AdapterHandlerEntry* handler,\n+void AdapterHandlerLibrary::address_to_offset(address entry_address[AdapterBlob::ENTRY_COUNT],\n+                                              int entry_offset[AdapterBlob::ENTRY_COUNT]) {\n+  entry_offset[AdapterBlob::I2C] = 0;\n+  entry_offset[AdapterBlob::C2I] = entry_address[AdapterBlob::C2I] - entry_address[AdapterBlob::I2C];\n+  entry_offset[AdapterBlob::C2I_Inline] = entry_address[AdapterBlob::C2I_Inline] - entry_address[AdapterBlob::I2C];\n+  entry_offset[AdapterBlob::C2I_Inline_RO] = entry_address[AdapterBlob::C2I_Inline_RO] - entry_address[AdapterBlob::I2C];\n+  entry_offset[AdapterBlob::C2I_Unverified] = entry_address[AdapterBlob::C2I_Unverified] - entry_address[AdapterBlob::I2C];\n+  entry_offset[AdapterBlob::C2I_Unverified_Inline] = entry_address[AdapterBlob::C2I_Unverified_Inline] - entry_address[AdapterBlob::I2C];\n+  if (entry_address[AdapterBlob::C2I_No_Clinit_Check] == nullptr) {\n+    entry_offset[AdapterBlob::C2I_No_Clinit_Check] = -1;\n+  } else {\n+    entry_offset[AdapterBlob::C2I_No_Clinit_Check] = entry_address[AdapterBlob::C2I_No_Clinit_Check] - entry_address[AdapterBlob::I2C];\n+  }\n+}\n+\n+bool AdapterHandlerLibrary::generate_adapter_code(AdapterHandlerEntry* handler,\n@@ -3255,0 +3241,2 @@\n+#ifndef ZERO\n+  AdapterBlob* adapter_blob = nullptr;\n@@ -3261,0 +3249,1 @@\n+  address entry_address[AdapterBlob::ENTRY_COUNT];\n@@ -3270,1 +3259,1 @@\n-                                         handler,\n+                                         entry_address,\n@@ -3280,1 +3269,0 @@\n-#ifdef ZERO\n@@ -3284,2 +3272,2 @@\n-  adapter_blob = nullptr;\n-#else\n+  int entry_offset[AdapterBlob::ENTRY_COUNT];\n+  address_to_offset(entry_address, entry_offset);\n@@ -3294,1 +3282,0 @@\n-\n@@ -3301,0 +3288,1 @@\n+  handler->set_adapter_blob(adapter_blob);\n@@ -3308,1 +3296,0 @@\n-  handler->relocate(adapter_blob->content_begin());\n@@ -3314,1 +3301,1 @@\n-    print_adapter_handler_info(tty, handler, adapter_blob);\n+    print_adapter_handler_info(tty, handler);\n@@ -3321,2 +3308,1 @@\n-AdapterHandlerEntry* AdapterHandlerLibrary::create_adapter(AdapterBlob*& adapter_blob,\n-                                                           CompiledEntrySignature& ces,\n+AdapterHandlerEntry* AdapterHandlerLibrary::create_adapter(CompiledEntrySignature& ces,\n@@ -3332,1 +3318,1 @@\n-  if (!generate_adapter_code(adapter_blob, handler, ces, allocate_code_blob, is_transient)) {\n+  if (!generate_adapter_code(handler, ces, allocate_code_blob, is_transient)) {\n@@ -3349,1 +3335,2 @@\n-  set_entry_points(nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, false);\n+   _adapter_blob = nullptr;\n+   _linked = false;\n@@ -3399,1 +3386,1 @@\n-AdapterBlob* AdapterHandlerLibrary::link_aot_adapter_handler(AdapterHandlerEntry* handler) {\n+void AdapterHandlerLibrary::link_aot_adapter_handler(AdapterHandlerEntry* handler) {\n@@ -3402,1 +3389,1 @@\n-    return nullptr;\n+    return;\n@@ -3405,1 +3392,1 @@\n-  AdapterBlob* blob = lookup_aot_cache(handler);\n+  lookup_aot_cache(handler);\n@@ -3408,2 +3395,2 @@\n-  if ((blob != nullptr) && (PrintAdapterHandlers || PrintStubCode)) {\n-    print_adapter_handler_info(tty, handler, blob);\n+  if (PrintAdapterHandlers || PrintStubCode) {\n+    print_adapter_handler_info(tty, handler);\n@@ -3412,1 +3399,0 @@\n-  return blob;\n@@ -3418,1 +3404,0 @@\n-  AdapterBlob* adapter_blob = nullptr;\n@@ -3426,2 +3411,3 @@\n-    adapter_blob = AdapterHandlerLibrary::link_aot_adapter_handler(this);\n-    if (adapter_blob == nullptr) {\n+    AdapterHandlerLibrary::link_aot_adapter_handler(this);\n+    \/\/ If link_aot_adapter_handler() succeeds, _adapter_blob will be non-null\n+    if (_adapter_blob == nullptr) {\n@@ -3437,1 +3423,1 @@\n-    if (!AdapterHandlerLibrary::generate_adapter_code(adapter_blob, this, ces, true, false)) {\n+    if (!AdapterHandlerLibrary::generate_adapter_code(this, ces, true, false)) {\n@@ -3444,3 +3430,2 @@\n-  \/\/ Outside of the lock\n-  if (adapter_blob != nullptr) {\n-    post_adapter_creation(adapter_blob, this);\n+  if (_adapter_blob != nullptr) {\n+    post_adapter_creation(this);\n@@ -3505,33 +3490,0 @@\n-address AdapterHandlerEntry::base_address() {\n-  address base = _i2c_entry;\n-  if (base == nullptr)  base = _c2i_entry;\n-  assert(base <= _c2i_entry || _c2i_entry == nullptr, \"\");\n-  assert(base <= _c2i_inline_entry || _c2i_inline_entry == nullptr, \"\");\n-  assert(base <= _c2i_inline_ro_entry || _c2i_inline_ro_entry == nullptr, \"\");\n-  assert(base <= _c2i_unverified_entry || _c2i_unverified_entry == nullptr, \"\");\n-  assert(base <= _c2i_unverified_inline_entry || _c2i_unverified_inline_entry == nullptr, \"\");\n-  assert(base <= _c2i_no_clinit_check_entry || _c2i_no_clinit_check_entry == nullptr, \"\");\n-  return base;\n-}\n-\n-void AdapterHandlerEntry::relocate(address new_base) {\n-  address old_base = base_address();\n-  assert(old_base != nullptr, \"\");\n-  ptrdiff_t delta = new_base - old_base;\n-  if (_i2c_entry != nullptr)\n-    _i2c_entry += delta;\n-  if (_c2i_entry != nullptr)\n-    _c2i_entry += delta;\n-  if (_c2i_inline_entry != nullptr)\n-    _c2i_inline_entry += delta;\n-  if (_c2i_inline_ro_entry != nullptr)\n-    _c2i_inline_ro_entry += delta;\n-  if (_c2i_unverified_entry != nullptr)\n-    _c2i_unverified_entry += delta;\n-  if (_c2i_unverified_inline_entry != nullptr)\n-    _c2i_unverified_inline_entry += delta;\n-  if (_c2i_no_clinit_check_entry != nullptr)\n-    _c2i_no_clinit_check_entry += delta;\n-  assert(base_address() == new_base, \"\");\n-}\n-\n@@ -3925,1 +3877,1 @@\n-  if (get_i2c_entry() != nullptr) {\n+  if (adapter_blob() != nullptr) {\n@@ -3927,4 +3879,0 @@\n-  }\n-  if (get_c2i_entry() != nullptr) {\n-  }\n-  if (get_c2i_entry() != nullptr) {\n@@ -3932,2 +3880,0 @@\n-  }\n-  if (get_c2i_entry() != nullptr) {\n@@ -3935,2 +3881,0 @@\n-  }\n-  if (get_c2i_unverified_entry() != nullptr) {\n@@ -3938,2 +3882,0 @@\n-  }\n-  if (get_c2i_unverified_entry() != nullptr) {\n@@ -3941,3 +3883,3 @@\n-  }\n-  if (get_c2i_no_clinit_check_entry() != nullptr) {\n-    st->print(\" c2iNCI: \" INTPTR_FORMAT, p2i(get_c2i_no_clinit_check_entry()));\n+    if (get_c2i_no_clinit_check_entry() != nullptr) {\n+      st->print(\" c2iNCI: \" INTPTR_FORMAT, p2i(get_c2i_no_clinit_check_entry()));\n+    }\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":75,"deletions":133,"binary":false,"changes":208,"status":"modified"},{"patch":"@@ -499,1 +499,1 @@\n-                                      AdapterHandlerEntry* handler,\n+                                      address entry_address[AdapterBlob::ENTRY_COUNT],\n@@ -712,8 +712,2 @@\n-  address _i2c_entry;\n-  address _c2i_entry;\n-  address _c2i_inline_entry;\n-  address _c2i_inline_ro_entry;\n-  address _c2i_unverified_entry;\n-  address _c2i_unverified_inline_entry;\n-  address _c2i_no_clinit_check_entry;\n-  bool    _linked;\n+  AdapterBlob* _adapter_blob;\n+  bool _linked;\n@@ -735,7 +729,1 @@\n-    _i2c_entry(nullptr),\n-    _c2i_entry(nullptr),\n-    _c2i_inline_entry(nullptr),\n-    _c2i_inline_ro_entry(nullptr),\n-    _c2i_unverified_entry(nullptr),\n-    _c2i_unverified_inline_entry(nullptr),\n-    _c2i_no_clinit_check_entry(nullptr),\n+    _adapter_blob(nullptr),\n@@ -771,12 +759,3 @@\n-  void set_entry_points(address i2c_entry, address c2i_entry, address c2i_inline_entry, address c2i_inline_ro_entry,\n-                        address c2i_unverified_entry, address c2i_unverified_inline_entry,\n-                        address c2i_no_clinit_check_entry = nullptr,\n-                        bool linked = true) {\n-    _i2c_entry = i2c_entry;\n-    _c2i_entry = c2i_entry;\n-    _c2i_inline_entry = c2i_inline_entry;\n-    _c2i_inline_ro_entry = c2i_inline_ro_entry;\n-    _c2i_unverified_entry = c2i_unverified_entry;\n-    _c2i_unverified_inline_entry = c2i_unverified_inline_entry;\n-    _c2i_no_clinit_check_entry = c2i_no_clinit_check_entry;\n-    _linked = linked;\n+  void set_adapter_blob(AdapterBlob* blob) {\n+    _adapter_blob = blob;\n+    _linked = true;\n@@ -785,11 +764,7 @@\n-  address get_i2c_entry()                   const { return _i2c_entry; }\n-  address get_c2i_entry()                   const { return _c2i_entry; }\n-  address get_c2i_inline_entry()            const { return _c2i_inline_entry; }\n-  address get_c2i_inline_ro_entry()         const { return _c2i_inline_ro_entry; }\n-  address get_c2i_unverified_entry()        const { return _c2i_unverified_entry; }\n-  address get_c2i_unverified_inline_entry() const { return _c2i_unverified_inline_entry; }\n-  address get_c2i_no_clinit_check_entry()   const { return _c2i_no_clinit_check_entry; }\n-\n-  static const char* entry_name(int i) {\n-    assert(i >=0 && i < ENTRIES_COUNT, \"entry id out of range\");\n-    return _entry_names[i];\n+  address get_i2c_entry() const {\n+#ifndef ZERO\n+    assert(_adapter_blob != nullptr, \"must be\");\n+    return _adapter_blob->i2c_entry();\n+#else\n+    return nullptr;\n+#endif \/\/ ZERO\n@@ -798,0 +773,55 @@\n+  address get_c2i_entry() const {\n+#ifndef ZERO\n+    assert(_adapter_blob != nullptr, \"must be\");\n+    return _adapter_blob->c2i_entry();\n+#else\n+    return nullptr;\n+#endif \/\/ ZERO\n+  }\n+\n+  address get_c2i_inline_entry() const {\n+#ifndef ZERO\n+    assert(_adapter_blob != nullptr, \"must be\");\n+    return _adapter_blob->c2i_inline_entry();\n+#else\n+    return nullptr;\n+#endif \/\/ ZERO\n+  }\n+\n+  address get_c2i_inline_ro_entry() const {\n+#ifndef ZERO\n+    assert(_adapter_blob != nullptr, \"must be\");\n+    return _adapter_blob->c2i_inline_ro_entry();\n+#else\n+    return nullptr;\n+#endif \/\/ ZERO\n+  }\n+\n+  address get_c2i_unverified_entry() const {\n+#ifndef ZERO\n+    assert(_adapter_blob != nullptr, \"must be\");\n+    return _adapter_blob->c2i_unverified_entry();\n+#else\n+    return nullptr;\n+#endif \/\/ ZERO\n+  }\n+\n+  address get_c2i_unverified_inline_entry() const {\n+#ifndef ZERO\n+    assert(_adapter_blob != nullptr, \"must be\");\n+    return _adapter_blob->c2i_unverified_inline_entry();\n+#else\n+    return nullptr;\n+#endif \/\/ ZERO\n+  }\n+\n+  address get_c2i_no_clinit_check_entry()  const {\n+#ifndef ZERO\n+    assert(_adapter_blob != nullptr, \"must be\");\n+    return _adapter_blob->c2i_no_clinit_check_entry();\n+#else\n+    return nullptr;\n+#endif \/\/ ZERO\n+  }\n+\n+  AdapterBlob* adapter_blob() const { return _adapter_blob; }\n@@ -799,2 +829,0 @@\n-  address base_address();\n-  void relocate(address new_base);\n@@ -847,3 +875,2 @@\n-  static AdapterBlob* lookup_aot_cache(AdapterHandlerEntry* handler);\n-  static AdapterHandlerEntry* create_adapter(AdapterBlob*& new_adapter,\n-                                             CompiledEntrySignature& ces,\n+  static void lookup_aot_cache(AdapterHandlerEntry* handler);\n+  static AdapterHandlerEntry* create_adapter(CompiledEntrySignature& ces,\n@@ -854,1 +881,1 @@\n-  static void print_adapter_handler_info(outputStream* st, AdapterHandlerEntry* handler, AdapterBlob* adapter_blob);\n+  static void print_adapter_handler_info(outputStream* st, AdapterHandlerEntry* handler);\n@@ -862,2 +889,1 @@\n-  static bool generate_adapter_code(AdapterBlob*& adapter_blob,\n-                                    AdapterHandlerEntry* handler,\n+  static bool generate_adapter_code(AdapterHandlerEntry* handler,\n@@ -881,1 +907,1 @@\n-  static AdapterBlob* link_aot_adapter_handler(AdapterHandlerEntry* handler) NOT_CDS_RETURN_(nullptr);\n+  static void link_aot_adapter_handler(AdapterHandlerEntry* handler) NOT_CDS_RETURN;\n@@ -885,0 +911,1 @@\n+  static void address_to_offset(address entry_address[AdapterBlob::ENTRY_COUNT], int entry_offset[AdapterBlob::ENTRY_COUNT]);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":75,"deletions":48,"binary":false,"changes":123,"status":"modified"},{"patch":"@@ -33,3 +33,0 @@\n-#if INCLUDE_ZGC\n-#include \"gc\/z\/zBarrier.inline.hpp\"\n-#endif\n","filename":"src\/hotspot\/share\/runtime\/stackValue.cpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -776,1 +776,1 @@\n-    AOTLinkedClassBulkLoader::finish_loading_javabase_classes(CHECK_JNI_ERR);\n+    AOTLinkedClassBulkLoader::link_or_init_javabase_classes(THREAD);\n@@ -795,1 +795,1 @@\n-    AOTLinkedClassBulkLoader::load_non_javabase_classes(THREAD);\n+    AOTLinkedClassBulkLoader::link_or_init_non_javabase_classes(THREAD);\n@@ -893,1 +893,1 @@\n-    AOTMetaspace::preload_and_dump(CHECK_JNI_ERR);\n+    AOTMetaspace::dump_static_archive(CHECK_JNI_ERR);\n@@ -896,1 +896,1 @@\n-    AOTMetaspace::preload_and_dump(CHECK_JNI_ERR);\n+    AOTMetaspace::dump_static_archive(CHECK_JNI_ERR);\n","filename":"src\/hotspot\/share\/runtime\/threads.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -62,0 +62,1 @@\n+  template(G1RendezvousGCThreads)                 \\\n","filename":"src\/hotspot\/share\/runtime\/vmOperation.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -539,0 +539,1 @@\n+const int max_method_parameter_length = 255; \/\/ JVM spec, 22nd ed. section 4.3.3 (p.83)\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -29,0 +29,2 @@\n+import java.lang.runtime.ExactConversionsSupport;\n+\n@@ -1943,2 +1945,2 @@\n-            int utflen = utfLen(str, countNonZeroAscii);\n-            if (utflen <= 0xFFFF) {\n+            long utflen = utfLen(str, countNonZeroAscii);\n+            if (ExactConversionsSupport.isLongToCharExact(utflen)) {\n@@ -1948,1 +1950,1 @@\n-                writeShort(utflen);\n+                writeShort((short)utflen);\n","filename":"src\/java.base\/share\/classes\/java\/io\/ObjectOutputStream.java","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1439,1 +1439,1 @@\n-\n+     *\n@@ -1446,0 +1446,16 @@\n+     * @apiNote\n+     * The inclusion of a total order idiom in the Java SE API\n+     * predates the inclusion of that functionality in the IEEE 754\n+     * standard. The ordering of the totalOrder predicate chosen by\n+     * IEEE 754 differs from the total order chosen by this method.\n+     * While this method treats all NaN representations as being in\n+     * the same equivalence class, the IEEE 754 total order defines an\n+     * ordering based on the bit patterns of the NaN among the\n+     * different NaN representations. The IEEE 754 order regards\n+     * \"negative\" NaN representations, that is NaN representations\n+     * whose sign bit is set, to be less than any finite or infinite\n+     * value and less than any \"positive\" NaN. In addition, the IEEE\n+     * order regards all positive NaN values as greater than positive\n+     * infinity. See the IEEE 754 standard for full details of its\n+     * total ordering.\n+     *\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Double.java","additions":17,"deletions":1,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -1267,0 +1267,4 @@\n+     * @apiNote\n+     * For a discussion of differences between the total order of this\n+     * method compared to the total order defined by the IEEE 754\n+     * standard, see the note in {@link Double#compareTo(Double)}.\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Float.java","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2204,12 +2204,0 @@\n-            public long stringConcatInitialCoder() {\n-                return StringConcatHelper.initialCoder();\n-            }\n-\n-            public long stringConcatMix(long lengthCoder, String constant) {\n-                return StringConcatHelper.mix(lengthCoder, constant);\n-            }\n-\n-            public long stringConcatMix(long lengthCoder, char value) {\n-                return StringConcatHelper.mix(lengthCoder, value);\n-            }\n-\n","filename":"src\/java.base\/share\/classes\/java\/lang\/System.java","additions":0,"deletions":12,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -456,15 +456,0 @@\n-    \/**\n-     * Get the string concat initial coder\n-     *\/\n-    long stringConcatInitialCoder();\n-\n-    \/**\n-     * Update lengthCoder for constant\n-     *\/\n-    long stringConcatMix(long lengthCoder, String constant);\n-\n-    \/**\n-     * Mix value length and coder into current length and coder.\n-     *\/\n-    long stringConcatMix(long lengthCoder, char value);\n-\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/access\/JavaLangAccess.java","additions":0,"deletions":15,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+import java.lang.runtime.ExactConversionsSupport;\n@@ -321,2 +322,5 @@\n-        int utflen = utfLen(str, countNonZeroAscii);\n-        Util.checkU2(utflen, \"utf8 length\");\n+        long utflenLong = utfLen(str, countNonZeroAscii);\n+        if (!ExactConversionsSupport.isLongToCharExact(utflenLong)) {\n+            throw new IllegalArgumentException(\"utf8 length out of range of u2: \" + utflenLong);\n+        }\n+        int utflen = (int)utflenLong;\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/classfile\/impl\/BufWriterImpl.java","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2023, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -314,1 +314,1 @@\n-                        map(cts.classDesc()),\n+                        Util.toInternalName(map(cts.classDesc())),\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/classfile\/impl\/ClassRemapperImpl.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -193,0 +193,2 @@\n+    exports jdk.internal.net.quic to\n+        java.net.http;\n@@ -265,0 +267,1 @@\n+        java.net.http,\n","filename":"src\/java.base\/share\/classes\/module-info.java","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -70,2 +70,0 @@\n-    final boolean useClassMetaspaceForAllClasses = getFlag(\"UseClassMetaspaceForAllClasses\", Boolean.class);\n-\n","filename":"src\/jdk.internal.vm.ci\/share\/classes\/jdk\/vm\/ci\/hotspot\/HotSpotVMConfig.java","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -43,1 +43,0 @@\n-serviceability\/sa\/ClhsdbFindPC.java#apa                       8307393   generic-all\n@@ -57,2 +56,0 @@\n-serviceability\/sa\/ClhsdbLauncher.java                         8307393   generic-all\n-serviceability\/sa\/ClhsdbPmap.java                             8307393   generic-all\n@@ -67,1 +64,2 @@\n-serviceability\/sa\/ClhsdbScanOops.java                         8307393   generic-all\n+serviceability\/sa\/ClhsdbScanOops.java#parallel                8307393   generic-all\n+serviceability\/sa\/ClhsdbScanOops.java#serial                  8307393   generic-all\n@@ -76,8 +74,0 @@\n-serviceability\/sa\/LingeredAppSysProps.java                    8307393   generic-all\n-serviceability\/sa\/LingeredAppWithDefaultMethods.java          8307393   generic-all\n-serviceability\/sa\/LingeredAppWithEnum.java                    8307393   generic-all\n-serviceability\/sa\/LingeredAppWithInterface.java               8307393   generic-all\n-serviceability\/sa\/LingeredAppWithInvokeDynamic.java           8307393   generic-all\n-serviceability\/sa\/LingeredAppWithLock.java                    8307393   generic-all\n-serviceability\/sa\/LingeredAppWithNativeMethod.java            8307393   generic-all\n-serviceability\/sa\/LingeredAppWithRecComputation.java          8307393   generic-all\n@@ -107,1 +97,0 @@\n-serviceability\/sa\/jmap-hprof\/JMapHProfLargeHeapProc.java      8307393   generic-all\n@@ -113,1 +102,0 @@\n-serviceability\/sa\/sadebugd\/DebugdUtils.java                   8307393   generic-all\n","filename":"test\/hotspot\/jtreg\/ProblemList-zgc.txt","additions":2,"deletions":14,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -145,1 +145,2 @@\n-serviceability\/sa\/sadebugd\/DebugdConnectTest.java 8239062,8270326 macosx-x64,macosx-aarch64\n+# 8239062 and 8270326 only affects macosx-x64,macosx-aarch64\n+serviceability\/sa\/sadebugd\/DebugdConnectTest.java 8239062,8270326,8344261 generic-all\n@@ -167,1 +168,0 @@\n-serviceability\/sa\/sadebugd\/DebugdConnectTest.java       8344261 generic-all\n@@ -215,0 +215,2 @@\n+serviceability\/sa\/ClhsdbScanOops.java#serial 8365722 generic-all\n+serviceability\/sa\/ClhsdbScanOops.java#parallel 8365722 generic-all\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -435,0 +435,1 @@\n+ -runtime\/cds\/appcds\/aotAnnotations \\\n@@ -450,3 +451,0 @@\n- -runtime\/cds\/appcds\/javaldr\/ExceptionDuringDumpAtObjectsInitPhase.java \\\n- -runtime\/cds\/appcds\/javaldr\/GCSharedStringsDuringDump.java \\\n- -runtime\/cds\/appcds\/javaldr\/LockDuringDump.java \\\n@@ -474,1 +472,0 @@\n- -runtime\/cds\/appcds\/LambdaWithJavaAgent.java \\\n@@ -518,1 +515,0 @@\n-  runtime\/cds\/appcds\/jvmti\/dumpingWithAgent\/DumpingWithJavaAgent.java \\\n@@ -540,0 +536,1 @@\n+ -runtime\/cds\/appcds\/aotAnnotations \\\n@@ -559,3 +556,0 @@\n- -runtime\/cds\/appcds\/javaldr\/ExceptionDuringDumpAtObjectsInitPhase.java \\\n- -runtime\/cds\/appcds\/javaldr\/GCDuringDump.java \\\n- -runtime\/cds\/appcds\/javaldr\/LockDuringDump.java \\\n@@ -577,1 +571,0 @@\n- -runtime\/cds\/appcds\/LambdaWithJavaAgent.java \\\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":2,"deletions":9,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -509,1 +509,1 @@\n-        counts = {IRNode.G1_STORE_P_WITH_BARRIER_FLAG, POST_ONLY, \"1\"},\n+        counts = {IRNode.G1_STORE_P_WITH_BARRIER_FLAG, POST_ONLY, \">1\"},\n@@ -512,1 +512,1 @@\n-        counts = {IRNode.G1_ENCODE_P_AND_STORE_N_WITH_BARRIER_FLAG, POST_ONLY, \"1\"},\n+        counts = {IRNode.G1_ENCODE_P_AND_STORE_N_WITH_BARRIER_FLAG, POST_ONLY, \">1\"},\n","filename":"test\/hotspot\/jtreg\/compiler\/gcbarriers\/TestG1BarrierGeneration.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2815,0 +2815,30 @@\n+    public static final String EXPAND_VB = VECTOR_PREFIX + \"EXPAND_VB\" + POSTFIX;\n+    static {\n+        vectorNode(EXPAND_VB, \"ExpandV\", TYPE_BYTE);\n+    }\n+\n+    public static final String EXPAND_VS = VECTOR_PREFIX + \"EXPAND_VS\" + POSTFIX;\n+    static {\n+        vectorNode(EXPAND_VS, \"ExpandV\", TYPE_SHORT);\n+    }\n+\n+    public static final String EXPAND_VI = VECTOR_PREFIX + \"EXPAND_VI\" + POSTFIX;\n+    static {\n+        vectorNode(EXPAND_VI, \"ExpandV\", TYPE_INT);\n+    }\n+\n+    public static final String EXPAND_VL = VECTOR_PREFIX + \"EXPAND_VL\" + POSTFIX;\n+    static {\n+        vectorNode(EXPAND_VL, \"ExpandV\", TYPE_LONG);\n+    }\n+\n+    public static final String EXPAND_VF = VECTOR_PREFIX + \"EXPAND_VF\" + POSTFIX;\n+    static {\n+        vectorNode(EXPAND_VF, \"ExpandV\", TYPE_FLOAT);\n+    }\n+\n+    public static final String EXPAND_VD = VECTOR_PREFIX + \"EXPAND_VD\" + POSTFIX;\n+    static {\n+        vectorNode(EXPAND_VD, \"ExpandV\", TYPE_DOUBLE);\n+    }\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/IRNode.java","additions":30,"deletions":0,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -2405,1 +2405,1 @@\n-    @IR(applyIf = {\"UseArrayFlattening\", \"true\"},\n+    @IR(applyIfAnd = {\"UseArrayFlattening\", \"true\", \"OnError\", \"JDK-8370070-IsFixed\"},\n@@ -2426,1 +2426,1 @@\n-    @IR(applyIf = {\"UseArrayFlattening\", \"true\"},\n+    @IR(applyIfAnd = {\"UseArrayFlattening\", \"true\", \"OnError\", \"JDK-8370070-IsFixed\"},\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestLWorld.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1498,1 +1498,1 @@\n-    @IR(counts = {IRNode.COUNTED_LOOP, \"1\"}) \/\/ not fail\n+    @IR(counts = {IRNode.COUNTED_LOOP, \">1\"}) \/\/ not fail\n","filename":"test\/hotspot\/jtreg\/testlibrary_tests\/ir_framework\/tests\/TestIRMatching.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -58,1 +58,0 @@\n-java\/lang\/Thread\/virtual\/GetStackTraceWhenRunnable.java 0000000 generic-all\n@@ -66,3 +65,0 @@\n-java\/lang\/SecurityManager\/modules\/CustomSecurityManagerTest.java 0000000 generic-all\n-java\/util\/PluggableLocale\/PermissionTest.java 0000000 generic-all\n-java\/util\/Properties\/StoreReproducibilityTest.java 0000000 generic-all\n","filename":"test\/jdk\/ProblemList-Virtual.txt","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -258,1 +258,0 @@\n-sun\/java2d\/X11SurfaceData\/SharedMemoryPixmapsTest\/SharedMemoryPixmapsTest.sh 7184899,8221451 linux-all,macosx-aarch64\n@@ -273,0 +272,1 @@\n+java\/awt\/Dialog\/ModalExcludedTest.java 7125054 macosx-all\n@@ -412,1 +412,0 @@\n-java\/awt\/Modal\/ToFront\/DialogToFrontModeless1Test.java 8213530 linux-all\n@@ -551,1 +550,1 @@\n-java\/io\/IO\/IO.java                                              8337935 linux-ppc64le\n+java\/lang\/IO\/IO.java                                            8337935 linux-ppc64le\n@@ -562,1 +561,0 @@\n-java\/lang\/management\/MemoryMXBean\/PendingAllGC.sh               8158837 generic-all\n@@ -733,2 +731,0 @@\n-com\/sun\/jdi\/RepStep.java                                        8043571 generic-all\n-\n","filename":"test\/jdk\/ProblemList.txt","additions":2,"deletions":6,"binary":false,"changes":8,"status":"modified"}]}