{"files":[{"patch":"@@ -2043,2 +2043,3 @@\n-InlineTypeNode* PhiNode::push_inline_types_through(PhaseGVN* phase, bool can_reshape, ciInlineKlass* vk) {\n-  InlineTypeNode* vt = InlineTypeNode::make_null(*phase, vk)->clone_with_phis(phase, in(0), !_type->maybe_null());\n+InlineTypeNode* PhiNode::push_inline_types_down(PhaseGVN* phase, bool can_reshape, ciInlineKlass* inline_klass) {\n+  assert(inline_klass != nullptr, \"must be\");\n+  InlineTypeNode* vt = InlineTypeNode::make_null(*phase, inline_klass)->clone_with_phis(phase, in(0), !_type->maybe_null());\n@@ -2067,1 +2068,1 @@\n-      n = InlineTypeNode::make_null(*phase, vk);\n+      n = InlineTypeNode::make_null(*phase, inline_klass);\n@@ -2070,1 +2071,1 @@\n-      n = phase->transform(n->as_Phi()->push_inline_types_through(phase, can_reshape, vk));\n+      n = phase->transform(n->as_Phi()->push_inline_types_down(phase, can_reshape, inline_klass));\n@@ -2636,64 +2637,3 @@\n-  \/\/ Check recursively if inputs are either an inline type, constant null\n-  \/\/ or another Phi (including self references through data loops). If so,\n-  \/\/ push the inline types down through the phis to enable folding of loads.\n-  if (EnableValhalla && _type->isa_ptr() && req() > 2) {\n-    ResourceMark rm;\n-    Unique_Node_List worklist;\n-    worklist.push(this);\n-    bool can_optimize = true;\n-    ciInlineKlass* vk = nullptr;\n-    Node_List casts;\n-\n-    \/\/ TODO 8302217 We need to prevent endless pushing through\n-    bool only_phi = (outcnt() != 0);\n-    for (DUIterator_Fast imax, i = fast_outs(imax); i < imax; i++) {\n-      Node* n = fast_out(i);\n-      if (n->is_InlineType() && n->in(1) == this) {\n-        can_optimize = false;\n-        break;\n-      }\n-      if (!n->is_Phi()) {\n-        only_phi = false;\n-      }\n-    }\n-    if (only_phi) {\n-      can_optimize = false;\n-    }\n-    for (uint next = 0; next < worklist.size() && can_optimize; next++) {\n-      Node* phi = worklist.at(next);\n-      for (uint i = 1; i < phi->req() && can_optimize; i++) {\n-        Node* n = phi->in(i);\n-        if (n == nullptr) {\n-          can_optimize = false;\n-          break;\n-        }\n-        while (n->is_ConstraintCast()) {\n-          if (n->in(0) != nullptr && n->in(0)->is_top()) {\n-            \/\/ Will die, don't optimize\n-            can_optimize = false;\n-            break;\n-          }\n-          casts.push(n);\n-          n = n->in(1);\n-        }\n-        const Type* t = phase->type(n);\n-        if (n->is_InlineType() && (vk == nullptr || vk == t->inline_klass())) {\n-          vk = (vk == nullptr) ? t->inline_klass() : vk;\n-        } else if (n->is_Phi() && can_reshape && n->bottom_type()->isa_ptr()) {\n-          worklist.push(n);\n-        } else if (!t->is_zero_type()) {\n-          can_optimize = false;\n-        }\n-      }\n-    }\n-    \/\/ Check if cast nodes can be pushed through\n-    const Type* t = Type::get_const_type(vk);\n-    while (casts.size() != 0 && can_optimize && t != nullptr) {\n-      Node* cast = casts.pop();\n-      if (t->filter(cast->bottom_type()) == Type::TOP) {\n-        can_optimize = false;\n-      }\n-    }\n-    if (can_optimize && vk != nullptr) {\n-      return push_inline_types_through(phase, can_reshape, vk);\n-    }\n+  Node* inline_type = try_push_inline_types_down(phase, can_reshape);\n+  if (inline_type != this) {\n+    return inline_type;\n@@ -2745,0 +2685,84 @@\n+\/\/ Check recursively if inputs are either an inline type, constant null\n+\/\/ or another Phi (including self references through data loops). If so,\n+\/\/ push the inline types down through the phis to enable folding of loads.\n+Node* PhiNode::try_push_inline_types_down(PhaseGVN* phase, const bool can_reshape) {\n+  if (!can_be_inline_type()) {\n+    return this;\n+  }\n+\n+  ciInlineKlass* inline_klass;\n+  if (can_push_inline_types_down(phase, can_reshape, inline_klass)) {\n+    assert(inline_klass != nullptr, \"must be\");\n+    return push_inline_types_down(phase, can_reshape, inline_klass);\n+  }\n+  return this;\n+}\n+\n+bool PhiNode::can_push_inline_types_down(PhaseGVN* phase, const bool can_reshape, ciInlineKlass*& inline_klass) {\n+  if (req() <= 2) {\n+    \/\/ Dead phi.\n+    return false;\n+  }\n+  inline_klass = nullptr;\n+\n+  \/\/ TODO 8302217 We need to prevent endless pushing through\n+  bool only_phi = (outcnt() != 0);\n+  for (DUIterator_Fast imax, i = fast_outs(imax); i < imax; i++) {\n+    Node* n = fast_out(i);\n+    if (n->is_InlineType() && n->in(1) == this) {\n+      return false;\n+    }\n+    if (!n->is_Phi()) {\n+      only_phi = false;\n+    }\n+  }\n+  if (only_phi) {\n+    return false;\n+  }\n+\n+  ResourceMark rm;\n+  Unique_Node_List worklist;\n+  worklist.push(this);\n+  Node_List casts;\n+\n+  for (uint next = 0; next < worklist.size(); next++) {\n+    Node* phi = worklist.at(next);\n+    for (uint i = 1; i < phi->req(); i++) {\n+      Node* n = phi->in(i);\n+      if (n == nullptr) {\n+        return false;\n+      }\n+      while (n->is_ConstraintCast()) {\n+        if (n->in(0) != nullptr && n->in(0)->is_top()) {\n+          \/\/ Will die, don't optimize\n+          return false;\n+        }\n+        casts.push(n);\n+        n = n->in(1);\n+      }\n+      const Type* type = phase->type(n);\n+      if (n->is_InlineType() && (inline_klass == nullptr || inline_klass == type->inline_klass())) {\n+        inline_klass = type->inline_klass();\n+      } else if (n->is_Phi() && can_reshape && n->bottom_type()->isa_ptr()) {\n+        worklist.push(n);\n+      } else if (!type->is_zero_type()) {\n+        return false;\n+      }\n+    }\n+  }\n+  if (inline_klass == nullptr) {\n+    return false;\n+  }\n+\n+  \/\/ Check if cast nodes can be pushed through\n+  const Type* t = Type::get_const_type(inline_klass);\n+  while (casts.size() != 0 && t != nullptr) {\n+    Node* cast = casts.pop();\n+    if (t->filter(cast->bottom_type()) == Type::TOP) {\n+      return false;\n+    }\n+  }\n+\n+  return true;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/cfgnode.cpp","additions":92,"deletions":68,"binary":false,"changes":160,"status":"modified"},{"patch":"@@ -184,0 +184,3 @@\n+  bool can_push_inline_types_down(PhaseGVN* phase, bool can_reshape, ciInlineKlass*& inline_klass);\n+  InlineTypeNode* push_inline_types_down(PhaseGVN* phase, bool can_reshape, ciInlineKlass* inline_klass);\n+\n@@ -257,1 +260,5 @@\n-  InlineTypeNode* push_inline_types_through(PhaseGVN* phase, bool can_reshape, ciInlineKlass* vk);\n+  bool can_be_inline_type() const {\n+    return EnableValhalla && _type->isa_instptr() && _type->is_instptr()->can_be_inline_type();\n+  }\n+\n+  Node* try_push_inline_types_down(PhaseGVN* phase, bool can_reshape);\n","filename":"src\/hotspot\/share\/opto\/cfgnode.hpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -690,0 +690,4 @@\n+          if (res->is_Phi() && res->as_Phi()->can_be_inline_type()) {\n+            \/\/ Can only eliminate allocation if the phi had been replaced by an InlineTypeNode before which did not happen.\n+            can_eliminate = false;\n+          }\n@@ -899,3 +903,3 @@\n-      ciInlineKlass* vk = res_type->is_aryptr()->elem()->inline_klass();\n-      assert(vk->flat_in_array(), \"must be flat in array\");\n-      field_val = inline_type_from_mem(sfpt->memory(), sfpt->control(), vk, field_addr_type->isa_aryptr(), 0, alloc);\n+      ciInlineKlass* inline_klass = res_type->is_aryptr()->elem()->inline_klass();\n+      assert(inline_klass->flat_in_array(), \"must be flat in array\");\n+      field_val = inline_type_from_mem(sfpt->memory(), sfpt->control(), inline_klass, field_addr_type->isa_aryptr(), 0, alloc);\n@@ -945,0 +949,2 @@\n+\n+    \/\/ Keep track of inline types to scalarize them later\n@@ -946,1 +952,0 @@\n-      \/\/ Keep track of inline types to scalarize them later\n@@ -948,0 +953,8 @@\n+    } else if (field_val->is_Phi()) {\n+      PhiNode* phi = field_val->as_Phi();\n+      \/\/ Eagerly replace inline type phis now since we could be removing an inline type allocation where we must\n+      \/\/ scalarize all its fields in safepoints.\n+      field_val = phi->try_push_inline_types_down(&_igvn, true);\n+      if (field_val->is_InlineType()) {\n+        value_worklist->push(field_val);\n+      }\n@@ -1206,1 +1219,1 @@\n-  if (!alloc->_is_scalar_replaceable && (!boxing_alloc || (res != nullptr))) {\n+  if (!alloc->_is_scalar_replaceable && !boxing_alloc && !inline_alloc) {\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":18,"deletions":5,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -3183,3 +3183,2 @@\n-\/\/ TODO 8293541\n-\/\/    @IR(failOn = {ALLOC_G, MEMBAR},\n-\/\/        counts = {PREDICATE_TRAP, \"= 1\"})\n+    @IR(failOn = {ALLOC_G, MEMBAR},\n+        counts = {PREDICATE_TRAP, \"= 1\"})\n@@ -3222,3 +3221,2 @@\n-\/\/ TODO 8293541\n-\/\/    @IR(failOn = {ALLOC_G, MEMBAR},\n-\/\/        counts = {PREDICATE_TRAP, \"= 1\"})\n+    @IR(failOn = {ALLOC_G, MEMBAR},\n+        counts = {PREDICATE_TRAP, \"= 1\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestLWorld.java","additions":4,"deletions":6,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -123,0 +123,1 @@\n+    \/\/ TODO: Should be fixed with JDK-8327465.\n@@ -124,1 +125,1 @@\n-    @Test(compLevel = CompLevel.WAIT_FOR_COMPILATION)\n+    \/\/@Test(compLevel = CompLevel.WAIT_FOR_COMPILATION)\n@@ -139,2 +140,2 @@\n-    @Run(test = \"test3\")\n-    @Warmup(0)\n+    \/\/@Run(test = \"test3\")\n+    \/\/@Warmup(0)\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestOnStackReplacement.java","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"}]}