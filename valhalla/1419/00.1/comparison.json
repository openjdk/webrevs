{"files":[{"patch":"@@ -1492,0 +1492,1 @@\n+        args = concat(args, \"--with-version-pre=\" + version_numbers.get(\"DEFAULT_PROMOTED_VERSION_PRE\"));\n","filename":"make\/conf\/jib-profiles.js","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+include gensrc\/GensrcValueClasses.gmk\n","filename":"make\/modules\/java.base\/Gensrc.gmk","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -761,0 +761,1 @@\n+BUILD_HOTSPOT_JTREG_LIBRARIES_CFLAGS_libobjmonusage007 := $(NSK_JVMTI_AGENT_INCLUDES)\n@@ -1476,0 +1477,1 @@\n+  BUILD_HOTSPOT_JTREG_LIBRARIES_LIBS_libobjmonusage007 += $(LIBPTHREAD)\n","filename":"make\/test\/JtregNativeHotspot.gmk","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1657,0 +1657,3 @@\n+  } else if (_entry_point == nullptr) {\n+    \/\/ See CallLeafNoFPIndirect\n+    return 1 * NativeInstruction::instruction_size;\n@@ -1765,3 +1768,0 @@\n-  \/\/ n.b. frame size includes space for return pc and rfp\n-  const int framesize = C->output()->frame_size_in_bytes();\n-\n@@ -1772,4 +1772,1 @@\n-  if (C->clinit_barrier_on_entry()) {\n-    assert(!C->method()->holder()->is_not_initialized(), \"initialization should have been started\");\n-\n-    Label L_skip_barrier;\n+  __ verified_entry(C, 0);\n@@ -1777,8 +1774,2 @@\n-    __ mov_metadata(rscratch2, C->method()->holder()->constant_encoding());\n-    __ clinit_barrier(rscratch2, rscratch1, &L_skip_barrier);\n-    __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));\n-    __ bind(L_skip_barrier);\n-  }\n-\n-  if (C->max_vector_size() > 0) {\n-    __ reinitialize_ptrue();\n+  if (C->stub_function() == nullptr) {\n+    __ entry_barrier();\n@@ -1787,25 +1778,2 @@\n-  int bangsize = C->output()->bang_size_in_bytes();\n-  if (C->output()->need_stack_bang(bangsize))\n-    __ generate_stack_overflow_check(bangsize);\n-\n-  __ build_frame(framesize);\n-\n-  if (C->stub_function() == nullptr) {\n-    BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-    \/\/ Dummy labels for just measuring the code size\n-    Label dummy_slow_path;\n-    Label dummy_continuation;\n-    Label dummy_guard;\n-    Label* slow_path = &dummy_slow_path;\n-    Label* continuation = &dummy_continuation;\n-    Label* guard = &dummy_guard;\n-    if (!Compile::current()->output()->in_scratch_emit_size()) {\n-      \/\/ Use real labels from actual stub when not emitting code for the purpose of measuring its size\n-      C2EntryBarrierStub* stub = new (Compile::current()->comp_arena()) C2EntryBarrierStub();\n-      Compile::current()->output()->add_stub(stub);\n-      slow_path = &stub->entry();\n-      continuation = &stub->continuation();\n-      guard = &stub->guard();\n-    }\n-    \/\/ In the C2 code, we move the non-hot part of nmethod entry barriers out-of-line to a stub.\n-    bs->nmethod_entry_barrier(masm, slow_path, continuation, guard);\n+  if (!Compile::current()->output()->in_scratch_emit_size()) {\n+    __ bind(*_verified_entry);\n@@ -1828,6 +1796,0 @@\n-uint MachPrologNode::size(PhaseRegAlloc* ra_) const\n-{\n-  return MachNode::size(ra_); \/\/ too many variables; just compute it\n-                              \/\/ the hard way\n-}\n-\n@@ -1876,1 +1838,1 @@\n-  __ remove_frame(framesize);\n+  __ remove_frame(framesize, C->needs_stack_repair());\n@@ -1895,5 +1857,0 @@\n-uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {\n-  \/\/ Variable size. Determine dynamically.\n-  return MachNode::size(ra_);\n-}\n-\n@@ -2195,1 +2152,12 @@\n-\/\/=============================================================================\n+\/\/\/=============================================================================\n+#ifndef PRODUCT\n+void MachVEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const\n+{\n+  st->print_cr(\"# MachVEPNode\");\n+  if (!_verified) {\n+    st->print_cr(\"\\t load_class\");\n+  } else {\n+    st->print_cr(\"\\t unpack_inline_arg\");\n+  }\n+}\n+#endif\n@@ -2197,0 +2165,31 @@\n+void MachVEPNode::emit(C2_MacroAssembler *masm, PhaseRegAlloc* ra_) const\n+{\n+  if (!_verified) {\n+    __ ic_check(1);\n+  } else {\n+    \/\/ insert a nop at the start of the prolog so we can patch in a\n+    \/\/ branch if we need to invalidate the method later\n+    __ nop();\n+\n+    \/\/ TODO 8284443 Avoid creation of temporary frame\n+    if (ra_->C->stub_function() == nullptr) {\n+      __ verified_entry(ra_->C, 0);\n+      __ entry_barrier();\n+      int framesize = ra_->C->output()->frame_slots() << LogBytesPerInt;\n+      __ remove_frame(framesize, false);\n+    }\n+    \/\/ Unpack inline type args passed as oop and then jump to\n+    \/\/ the verified entry point (skipping the unverified entry).\n+    int sp_inc = __ unpack_inline_args(ra_->C, _receiver_only);\n+    \/\/ Emit code for verified entry and save increment for stack repair on return\n+    __ verified_entry(ra_->C, sp_inc);\n+    if (Compile::current()->output()->in_scratch_emit_size()) {\n+      Label dummy_verified_entry;\n+      __ b(dummy_verified_entry);\n+    } else {\n+      __ b(*_verified_entry);\n+    }\n+  }\n+}\n+\n+\/\/=============================================================================\n@@ -2219,5 +2218,0 @@\n-uint MachUEPNode::size(PhaseRegAlloc* ra_) const\n-{\n-  return MachNode::size(ra_);\n-}\n-\n@@ -3696,0 +3690,31 @@\n+    if (tf()->returns_inline_type_as_fields() && !_method->is_method_handle_intrinsic()) {\n+      \/\/ The last return value is not set by the callee but used to pass IsInit information to compiled code.\n+      \/\/ Search for the corresponding projection, get the register and emit code that initialized it.\n+      uint con = (tf()->range_cc()->cnt() - 1);\n+      for (DUIterator_Fast imax, i = fast_outs(imax); i < imax; i++) {\n+        ProjNode* proj = fast_out(i)->as_Proj();\n+        if (proj->_con == con) {\n+          \/\/ Set IsInit if r0 is non-null (a non-null value is returned buffered or scalarized)\n+          OptoReg::Name optoReg = ra_->get_reg_first(proj);\n+          VMReg reg = OptoReg::as_VMReg(optoReg, ra_->_framesize, OptoReg::reg2stack(ra_->_matcher._new_SP));\n+          Register toReg = reg->is_reg() ? reg->as_Register() : rscratch1;\n+          __ cmp(r0, zr);\n+          __ cset(toReg, Assembler::NE);\n+          if (reg->is_stack()) {\n+            int st_off = reg->reg2stack() * VMRegImpl::stack_slot_size;\n+            __ str(toReg, Address(sp, st_off));\n+          }\n+          break;\n+        }\n+      }\n+      if (return_value_is_used()) {\n+        \/\/ An inline type is returned as fields in multiple registers.\n+        \/\/ R0 either contains an oop if the inline type is buffered or a pointer\n+        \/\/ to the corresponding InlineKlass with the lowest bit set to 1. Zero r0\n+        \/\/ if the lowest bit is set to allow C2 to use the oop after null checking.\n+        \/\/ r0 &= (r0 & 1) - 1\n+        __ andr(rscratch1, r0, 0x1);\n+        __ sub(rscratch1, rscratch1, 0x1);\n+        __ andr(r0, r0, rscratch1);\n+      }\n+    }\n@@ -6792,1 +6817,1 @@\n-    \"mov  $dst, $con\\t# ptr\\n\\t\"\n+    \"mov  $dst, $con\\t# ptr\"\n@@ -7988,0 +8013,30 @@\n+instruct castI2N(iRegNNoSp dst, iRegI src) %{\n+  match(Set dst (CastI2N src));\n+\n+  ins_cost(INSN_COST);\n+  format %{ \"mov $dst, $src\\t# int -> narrow ptr\" %}\n+\n+  ins_encode %{\n+    if ($dst$$reg != $src$$reg) {\n+      __ mov(as_Register($dst$$reg), as_Register($src$$reg));\n+    }\n+  %}\n+\n+  ins_pipe(ialu_reg);\n+%}\n+\n+instruct castN2X(iRegLNoSp dst, iRegN src) %{\n+  match(Set dst (CastP2X src));\n+\n+  ins_cost(INSN_COST);\n+  format %{ \"mov $dst, $src\\t# ptr -> long\" %}\n+\n+  ins_encode %{\n+    if ($dst$$reg != $src$$reg) {\n+      __ mov(as_Register($dst$$reg), as_Register($src$$reg));\n+    }\n+  %}\n+\n+  ins_pipe(ialu_reg);\n+%}\n+\n@@ -14813,1 +14868,1 @@\n-instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)\n+instruct clearArray_reg_reg_immL0(iRegL_R11 cnt, iRegP_R10 base, immL0 zero, Universe dummy, rFlagsReg cr)\n@@ -14815,1 +14870,1 @@\n-  match(Set dummy (ClearArray cnt base));\n+  match(Set dummy (ClearArray (Binary cnt base) zero));\n@@ -14832,0 +14887,16 @@\n+instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, iRegL val, Universe dummy, rFlagsReg cr)\n+%{\n+  predicate(((ClearArrayNode*)n)->word_copy_only());\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n+  effect(USE_KILL cnt, USE_KILL base, KILL cr);\n+\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ClearArray $cnt, $base, $val\" %}\n+\n+  ins_encode %{\n+    __ fill_words($base$$Register, $cnt$$Register, $val$$Register);\n+  %}\n+\n+  ins_pipe(pipe_class_memory);\n+%}\n+\n@@ -14835,1 +14906,2 @@\n-            < (uint64_t)(BlockZeroingLowLimit >> LogBytesPerWord));\n+            < (uint64_t)(BlockZeroingLowLimit >> LogBytesPerWord)\n+            && !((ClearArrayNode*)n)->word_copy_only());\n@@ -16186,0 +16258,18 @@\n+\/\/ entry point is null, target holds the address to call\n+instruct CallLeafNoFPIndirect(iRegP target)\n+%{\n+  predicate(n->as_Call()->entry_point() == nullptr);\n+\n+  match(CallLeafNoFP target);\n+\n+  ins_cost(CALL_COST);\n+\n+  format %{ \"CALL, runtime leaf nofp indirect $target\" %}\n+\n+  ins_encode %{\n+    __ blr($target$$Register);\n+  %}\n+\n+  ins_pipe(pipe_class_call);\n+%}\n+\n@@ -16188,0 +16278,2 @@\n+  predicate(n->as_Call()->entry_point() != nullptr);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":154,"deletions":62,"binary":false,"changes":216,"status":"modified"},{"patch":"@@ -49,0 +49,21 @@\n+void C2_MacroAssembler::entry_barrier() {\n+  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+  \/\/ Dummy labels for just measuring the code size\n+  Label dummy_slow_path;\n+  Label dummy_continuation;\n+  Label dummy_guard;\n+  Label* slow_path = &dummy_slow_path;\n+  Label* continuation = &dummy_continuation;\n+  Label* guard = &dummy_guard;\n+  if (!Compile::current()->output()->in_scratch_emit_size()) {\n+    \/\/ Use real labels from actual stub when not emitting code for the purpose of measuring its size\n+    C2EntryBarrierStub* stub = new (Compile::current()->comp_arena()) C2EntryBarrierStub();\n+    Compile::current()->output()->add_stub(stub);\n+    slow_path = &stub->entry();\n+    continuation = &stub->continuation();\n+    guard = &stub->guard();\n+  }\n+  \/\/ In the C2 code, we move the non-hot part of nmethod entry barriers out-of-line to a stub.\n+  bs->nmethod_entry_barrier(this, slow_path, continuation, guard);\n+}\n+\n@@ -178,0 +199,5 @@\n+    if (EnableValhalla) {\n+      \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n+      andr(tmp, tmp, ~((int) markWord::inline_type_bit_in_place));\n+    }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":26,"deletions":0,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/shared\/barrierSetRuntime.hpp\"\n@@ -52,0 +53,1 @@\n+\n@@ -89,0 +91,2 @@\n+  bool is_not_null = (decorators & IS_NOT_NULL) != 0;\n+\n@@ -92,5 +96,6 @@\n-    val = val == noreg ? zr : val;\n-      if (UseCompressedOops) {\n-        assert(!dst.uses(val), \"not enough registers\");\n-        if (val != zr) {\n-          __ encode_heap_oop(val);\n+      if (val == noreg) {\n+        assert(!is_not_null, \"inconsistent access\");\n+        if (UseCompressedOops) {\n+          __ strw(zr, dst);\n+        } else {\n+          __ str(zr, dst);\n@@ -99,2 +104,11 @@\n-        __ strw(val, dst);\n-        __ str(val, dst);\n+        if (UseCompressedOops) {\n+          assert(!dst.uses(val), \"not enough registers\");\n+          if (is_not_null) {\n+            __ encode_heap_oop_not_null(val);\n+          } else {\n+            __ encode_heap_oop(val);\n+          }\n+          __ strw(val, dst);\n+        } else {\n+          __ str(val, dst);\n+        }\n@@ -105,0 +119,1 @@\n+      assert(val != noreg, \"not supported\");\n@@ -125,0 +140,13 @@\n+void BarrierSetAssembler::flat_field_copy(MacroAssembler* masm, DecoratorSet decorators,\n+                                     Register src, Register dst, Register inline_layout_info) {\n+  \/\/ flat_field_copy implementation is fairly complex, and there are not any\n+  \/\/ \"short-cuts\" to be made from asm. What there is, appears to have the same\n+  \/\/ cost in C++, so just \"call_VM_leaf\" for now rather than maintain hundreds\n+  \/\/ of hand-rolled instructions...\n+  if (decorators & IS_DEST_UNINITIALIZED) {\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, BarrierSetRuntime::value_copy_is_dest_uninitialized), src, dst, inline_layout_info);\n+  } else {\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, BarrierSetRuntime::value_copy), src, dst, inline_layout_info);\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.cpp","additions":35,"deletions":7,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -331,4 +331,11 @@\n-    __ ldr(j_rarg2, result);\n-    Label is_long, is_float, is_double, exit;\n-    __ ldr(j_rarg1, result_type);\n-    __ cmp(j_rarg1, (u1)T_OBJECT);\n+    \/\/ All of j_rargN may be used to return inline type fields so be careful\n+    \/\/ not to clobber those.\n+    \/\/ SharedRuntime::generate_buffered_inline_type_adapter() knows the register\n+    \/\/ assignment of Rresult below.\n+    Register Rresult = r14, Rresult_type = r15;\n+    __ ldr(Rresult, result);\n+    Label is_long, is_float, is_double, check_prim, exit;\n+    __ ldr(Rresult_type, result_type);\n+    __ cmp(Rresult_type, (u1)T_OBJECT);\n+    __ br(Assembler::EQ, check_prim);\n+    __ cmp(Rresult_type, (u1)T_LONG);\n@@ -336,3 +343,1 @@\n-    __ cmp(j_rarg1, (u1)T_LONG);\n-    __ br(Assembler::EQ, is_long);\n-    __ cmp(j_rarg1, (u1)T_FLOAT);\n+    __ cmp(Rresult_type, (u1)T_FLOAT);\n@@ -340,1 +345,1 @@\n-    __ cmp(j_rarg1, (u1)T_DOUBLE);\n+    __ cmp(Rresult_type, (u1)T_DOUBLE);\n@@ -344,1 +349,1 @@\n-    __ strw(r0, Address(j_rarg2));\n+    __ strw(r0, Address(Rresult));\n@@ -396,0 +401,11 @@\n+    __ BIND(check_prim);\n+    if (InlineTypeReturnedAsFields) {\n+      \/\/ Check for scalarized return value\n+      __ tbz(r0, 0, is_long);\n+      \/\/ Load pack handler address\n+      __ andr(rscratch1, r0, -2);\n+      __ ldr(rscratch1, Address(rscratch1, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+      __ ldr(rscratch1, Address(rscratch1, InlineKlass::pack_handler_jobject_offset()));\n+      __ blr(rscratch1);\n+      __ b(exit);\n+    }\n@@ -398,1 +414,1 @@\n-    __ str(r0, Address(j_rarg2, 0));\n+    __ str(r0, Address(Rresult, 0));\n@@ -402,1 +418,1 @@\n-    __ strs(j_farg0, Address(j_rarg2, 0));\n+    __ strs(j_farg0, Address(Rresult, 0));\n@@ -406,1 +422,1 @@\n-    __ strd(j_farg0, Address(j_rarg2, 0));\n+    __ strd(j_farg0, Address(Rresult, 0));\n@@ -2227,0 +2243,6 @@\n+    \/\/ Check for flat inline type array -> return -1\n+    __ test_flat_array_oop(src, rscratch2, L_failed);\n+\n+    \/\/ Check for null-free (non-flat) inline type array -> handle as object array\n+    __ test_null_free_array_oop(src, rscratch2, L_objArray);\n+\n@@ -9838,0 +9860,128 @@\n+  \/\/ Call here from the interpreter or compiled code to either load\n+  \/\/ multiple returned values from the inline type instance being\n+  \/\/ returned to registers or to store returned values to a newly\n+  \/\/ allocated inline type instance.\n+  address generate_return_value_stub(address destination, const char* name, bool has_res) {\n+    \/\/ We need to save all registers the calling convention may use so\n+    \/\/ the runtime calls read or update those registers. This needs to\n+    \/\/ be in sync with SharedRuntime::java_return_convention().\n+    \/\/ n.b. aarch64 asserts that frame::arg_reg_save_area_bytes == 0\n+    enum layout {\n+      j_rarg7_off = 0, j_rarg7_2,    \/\/ j_rarg7 is r0\n+      j_rarg6_off, j_rarg6_2,\n+      j_rarg5_off, j_rarg5_2,\n+      j_rarg4_off, j_rarg4_2,\n+      j_rarg3_off, j_rarg3_2,\n+      j_rarg2_off, j_rarg2_2,\n+      j_rarg1_off, j_rarg1_2,\n+      j_rarg0_off, j_rarg0_2,\n+\n+      j_farg7_off, j_farg7_2,\n+      j_farg6_off, j_farg6_2,\n+      j_farg5_off, j_farg5_2,\n+      j_farg4_off, j_farg4_2,\n+      j_farg3_off, j_farg3_2,\n+      j_farg2_off, j_farg2_2,\n+      j_farg1_off, j_farg1_2,\n+      j_farg0_off, j_farg0_2,\n+\n+      rfp_off, rfp_off2,\n+      return_off, return_off2,\n+\n+      framesize \/\/ inclusive of return address\n+    };\n+\n+    CodeBuffer code(name, 512, 64);\n+    MacroAssembler* masm = new MacroAssembler(&code);\n+\n+    int frame_size_in_bytes = align_up(framesize*BytesPerInt, 16);\n+    assert(frame_size_in_bytes == framesize*BytesPerInt, \"misaligned\");\n+    int frame_size_in_slots = frame_size_in_bytes \/ BytesPerInt;\n+    int frame_size_in_words = frame_size_in_bytes \/ wordSize;\n+\n+    OopMapSet* oop_maps = new OopMapSet();\n+    OopMap* map = new OopMap(frame_size_in_slots, 0);\n+\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg7_off), j_rarg7->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg6_off), j_rarg6->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg5_off), j_rarg5->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg4_off), j_rarg4->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg3_off), j_rarg3->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg2_off), j_rarg2->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg1_off), j_rarg1->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg0_off), j_rarg0->as_VMReg());\n+\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg0_off), j_farg0->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg1_off), j_farg1->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg2_off), j_farg2->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg3_off), j_farg3->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg4_off), j_farg4->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg5_off), j_farg5->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg6_off), j_farg6->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg7_off), j_farg7->as_VMReg());\n+\n+    address start = __ pc();\n+\n+    __ enter(); \/\/ Save FP and LR before call\n+\n+    __ stpd(j_farg1, j_farg0, Address(__ pre(sp, -2 * wordSize)));\n+    __ stpd(j_farg3, j_farg2, Address(__ pre(sp, -2 * wordSize)));\n+    __ stpd(j_farg5, j_farg4, Address(__ pre(sp, -2 * wordSize)));\n+    __ stpd(j_farg7, j_farg6, Address(__ pre(sp, -2 * wordSize)));\n+\n+    __ stp(j_rarg1, j_rarg0, Address(__ pre(sp, -2 * wordSize)));\n+    __ stp(j_rarg3, j_rarg2, Address(__ pre(sp, -2 * wordSize)));\n+    __ stp(j_rarg5, j_rarg4, Address(__ pre(sp, -2 * wordSize)));\n+    __ stp(j_rarg7, j_rarg6, Address(__ pre(sp, -2 * wordSize)));\n+\n+    int frame_complete = __ offset();\n+\n+    \/\/ Set up last_Java_sp and last_Java_fp\n+    address the_pc = __ pc();\n+    __ set_last_Java_frame(sp, noreg, the_pc, rscratch1);\n+\n+    \/\/ Call runtime\n+    __ mov(c_rarg1, r0);\n+    __ mov(c_rarg0, rthread);\n+\n+    __ mov(rscratch1, destination);\n+    __ blr(rscratch1);\n+\n+    oop_maps->add_gc_map(the_pc - start, map);\n+\n+    __ reset_last_Java_frame(false);\n+\n+    __ ldp(j_rarg7, j_rarg6, Address(__ post(sp, 2 * wordSize)));\n+    __ ldp(j_rarg5, j_rarg4, Address(__ post(sp, 2 * wordSize)));\n+    __ ldp(j_rarg3, j_rarg2, Address(__ post(sp, 2 * wordSize)));\n+    __ ldp(j_rarg1, j_rarg0, Address(__ post(sp, 2 * wordSize)));\n+\n+    __ ldpd(j_farg7, j_farg6, Address(__ post(sp, 2 * wordSize)));\n+    __ ldpd(j_farg5, j_farg4, Address(__ post(sp, 2 * wordSize)));\n+    __ ldpd(j_farg3, j_farg2, Address(__ post(sp, 2 * wordSize)));\n+    __ ldpd(j_farg1, j_farg0, Address(__ post(sp, 2 * wordSize)));\n+\n+    __ leave();\n+\n+    \/\/ check for pending exceptions\n+    Label pending;\n+    __ ldr(rscratch1, Address(rthread, in_bytes(Thread::pending_exception_offset())));\n+    __ cbnz(rscratch1, pending);\n+\n+    if (has_res) {\n+      __ get_vm_result(r0, rthread);\n+    }\n+\n+    __ ret(lr);\n+\n+    __ bind(pending);\n+    __ far_jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+\n+    \/\/ -------------\n+    \/\/ make sure all code is generated\n+    masm->flush();\n+\n+    RuntimeStub* stub = RuntimeStub::new_runtime_stub(name, &code, frame_complete, frame_size_in_words, oop_maps, false);\n+    return stub->entry_point();\n+  }\n+\n@@ -9884,0 +10034,8 @@\n+\n+    if (InlineTypeReturnedAsFields) {\n+      StubRoutines::_load_inline_type_fields_in_regs =\n+         generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::load_inline_type_fields_in_regs), \"load_inline_type_fields_in_regs\", false);\n+      StubRoutines::_store_inline_type_fields_to_buf =\n+         generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::store_inline_type_fields_to_buf), \"store_inline_type_fields_to_buf\", true);\n+    }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":170,"deletions":12,"binary":false,"changes":182,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -470,0 +471,5 @@\n+\n+  if (state == atos && InlineTypeReturnedAsFields) {\n+    __ store_inline_type_fields_to_buf(nullptr, true);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/templateInterpreterGenerator_aarch64.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -52,1 +52,20 @@\n-void C2_MacroAssembler::verified_entry(int framesize, int stack_bang_size, bool fp_mode_24b, bool is_stub) {\n+void C2_MacroAssembler::verified_entry(Compile* C, int sp_inc) {\n+  if (C->clinit_barrier_on_entry()) {\n+    assert(VM_Version::supports_fast_class_init_checks(), \"sanity\");\n+    assert(!C->method()->holder()->is_not_initialized(), \"initialization should have been started\");\n+\n+    Label L_skip_barrier;\n+    Register klass = rscratch1;\n+\n+    mov_metadata(klass, C->method()->holder()->constant_encoding());\n+    clinit_barrier(klass, r15_thread, &L_skip_barrier \/*L_fast_path*\/);\n+\n+    jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub())); \/\/ slow path\n+\n+    bind(L_skip_barrier);\n+  }\n+\n+  int framesize = C->output()->frame_size_in_bytes();\n+  int bangsize = C->output()->bang_size_in_bytes();\n+  bool fp_mode_24b = false;\n+  int stack_bang_size = C->output()->need_stack_bang(bangsize) ? bangsize : 0;\n@@ -105,0 +124,6 @@\n+  if (C->needs_stack_repair()) {\n+    \/\/ Save stack increment just below the saved rbp (also account for fixed framesize and rbp)\n+    assert((sp_inc & (StackAlignmentInBytes-1)) == 0, \"stack increment not aligned\");\n+    movptr(Address(rsp, framesize - wordSize), sp_inc + framesize + wordSize);\n+  }\n+\n@@ -133,0 +158,1 @@\n+}\n@@ -134,16 +160,16 @@\n-  if (!is_stub) {\n-    BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n- #ifdef _LP64\n-    \/\/ We put the non-hot code of the nmethod entry barrier out-of-line in a stub.\n-    Label dummy_slow_path;\n-    Label dummy_continuation;\n-    Label* slow_path = &dummy_slow_path;\n-    Label* continuation = &dummy_continuation;\n-    if (!Compile::current()->output()->in_scratch_emit_size()) {\n-      \/\/ Use real labels from actual stub when not emitting code for the purpose of measuring its size\n-      C2EntryBarrierStub* stub = new (Compile::current()->comp_arena()) C2EntryBarrierStub();\n-      Compile::current()->output()->add_stub(stub);\n-      slow_path = &stub->entry();\n-      continuation = &stub->continuation();\n-    }\n-    bs->nmethod_entry_barrier(this, slow_path, continuation);\n+void C2_MacroAssembler::entry_barrier() {\n+  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+#ifdef _LP64\n+  \/\/ We put the non-hot code of the nmethod entry barrier out-of-line in a stub.\n+  Label dummy_slow_path;\n+  Label dummy_continuation;\n+  Label* slow_path = &dummy_slow_path;\n+  Label* continuation = &dummy_continuation;\n+  if (!Compile::current()->output()->in_scratch_emit_size()) {\n+    \/\/ Use real labels from actual stub when not emitting code for the purpose of measuring its size\n+    C2EntryBarrierStub* stub = new (Compile::current()->comp_arena()) C2EntryBarrierStub();\n+    Compile::current()->output()->add_stub(stub);\n+    slow_path = &stub->entry();\n+    continuation = &stub->continuation();\n+  }\n+  bs->nmethod_entry_barrier(this, slow_path, continuation);\n@@ -151,2 +177,2 @@\n-    \/\/ Don't bother with out-of-line nmethod entry barrier stub for x86_32.\n-    bs->nmethod_entry_barrier(this, nullptr \/* slow_path *\/, nullptr \/* continuation *\/);\n+  \/\/ Don't bother with out-of-line nmethod entry barrier stub for x86_32.\n+  bs->nmethod_entry_barrier(this, nullptr \/* slow_path *\/, nullptr \/* continuation *\/);\n@@ -154,1 +180,0 @@\n-  }\n@@ -292,0 +317,4 @@\n+    if (EnableValhalla) {\n+      \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n+      andptr(tmpReg, ~((int) markWord::inline_type_bit_in_place));\n+    }\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":49,"deletions":20,"binary":false,"changes":69,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"asm\/macroAssembler.inline.hpp\"\n@@ -29,0 +30,1 @@\n+#include \"gc\/shared\/barrierSetRuntime.hpp\"\n@@ -200,0 +202,13 @@\n+void BarrierSetAssembler::flat_field_copy(MacroAssembler* masm, DecoratorSet decorators,\n+                                     Register src, Register dst, Register inline_layout_info) {\n+  \/\/ flat_field_copy implementation is fairly complex, and there are not any\n+  \/\/ \"short-cuts\" to be made from asm. What there is, appears to have the same\n+  \/\/ cost in C++, so just \"call_VM_leaf\" for now rather than maintain hundreds\n+  \/\/ of hand-rolled instructions...\n+  if (decorators & IS_DEST_UNINITIALIZED) {\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, BarrierSetRuntime::value_copy_is_dest_uninitialized), src, dst, inline_layout_info);\n+  } else {\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, BarrierSetRuntime::value_copy), src, dst, inline_layout_info);\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetAssembler_x86.cpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -144,1 +144,8 @@\n-      store_check(masm, dst.base(), dst);\n+      if (tmp3 != noreg) {\n+        \/\/ Called by MacroAssembler::pack_inline_helper. We cannot corrupt the dst.base() register\n+        __ movptr(tmp3, dst.base());\n+        store_check(masm, tmp3, dst);\n+      } else {\n+        \/\/ It's OK to corrupt the dst.base() register.\n+        store_check(masm, dst.base(), dst);\n+      }\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/cardTableBarrierSetAssembler_x86.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"asm\/assembler.hpp\"\n@@ -41,0 +42,2 @@\n+#include \"utilities\/macros.hpp\"\n+#include \"vmreg_x86.inline.hpp\"\n@@ -304,4 +307,6 @@\n-  __ movptr(c_rarg0, result);\n-  Label is_long, is_float, is_double, exit;\n-  __ movl(c_rarg1, result_type);\n-  __ cmpl(c_rarg1, T_OBJECT);\n+  __ movptr(r13, result);\n+  Label is_long, is_float, is_double, check_prim, exit;\n+  __ movl(rbx, result_type);\n+  __ cmpl(rbx, T_OBJECT);\n+  __ jcc(Assembler::equal, check_prim);\n+  __ cmpl(rbx, T_LONG);\n@@ -309,3 +314,1 @@\n-  __ cmpl(c_rarg1, T_LONG);\n-  __ jcc(Assembler::equal, is_long);\n-  __ cmpl(c_rarg1, T_FLOAT);\n+  __ cmpl(rbx, T_FLOAT);\n@@ -313,1 +316,1 @@\n-  __ cmpl(c_rarg1, T_DOUBLE);\n+  __ cmpl(rbx, T_DOUBLE);\n@@ -319,1 +322,1 @@\n-    __ cmpl(c_rarg1, T_INT);\n+    __ cmpl(rbx, T_INT);\n@@ -327,1 +330,1 @@\n-  __ movl(Address(c_rarg0, 0), rax);\n+  __ movl(Address(r13, 0), rax);\n@@ -385,0 +388,13 @@\n+  __ BIND(check_prim);\n+  if (InlineTypeReturnedAsFields) {\n+    \/\/ Check for scalarized return value\n+    __ testptr(rax, 1);\n+    __ jcc(Assembler::zero, is_long);\n+    \/\/ Load pack handler address\n+    __ andptr(rax, -2);\n+    __ movptr(rax, Address(rax, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+    __ movptr(rbx, Address(rax, InlineKlass::pack_handler_jobject_offset()));\n+    \/\/ Call pack handler to initialize the buffer\n+    __ call(rbx);\n+    __ jmp(exit);\n+  }\n@@ -386,1 +402,1 @@\n-  __ movq(Address(c_rarg0, 0), rax);\n+  __ movq(Address(r13, 0), rax);\n@@ -390,1 +406,1 @@\n-  __ movflt(Address(c_rarg0, 0), xmm0);\n+  __ movflt(Address(r13, 0), xmm0);\n@@ -394,1 +410,1 @@\n-  __ movdbl(Address(c_rarg0, 0), xmm0);\n+  __ movdbl(Address(r13, 0), xmm0);\n@@ -4068,0 +4084,10 @@\n+  \/\/ Generate these first because they are called from other stubs\n+  if (InlineTypeReturnedAsFields) {\n+    StubRoutines::_load_inline_type_fields_in_regs =\n+      generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::load_inline_type_fields_in_regs),\n+                                 \"load_inline_type_fields_in_regs\", false);\n+    StubRoutines::_store_inline_type_fields_to_buf =\n+      generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::store_inline_type_fields_to_buf),\n+                                 \"store_inline_type_fields_to_buf\", true);\n+  }\n+\n@@ -4120,0 +4146,144 @@\n+\/\/ Call here from the interpreter or compiled code to either load\n+\/\/ multiple returned values from the inline type instance being\n+\/\/ returned to registers or to store returned values to a newly\n+\/\/ allocated inline type instance.\n+\/\/ Register is a class, but it would be assigned numerical value.\n+\/\/ \"0\" is assigned for xmm0. Thus we need to ignore -Wnonnull.\n+PRAGMA_DIAG_PUSH\n+PRAGMA_NONNULL_IGNORED\n+address StubGenerator::generate_return_value_stub(address destination, const char* name, bool has_res) {\n+  \/\/ We need to save all registers the calling convention may use so\n+  \/\/ the runtime calls read or update those registers. This needs to\n+  \/\/ be in sync with SharedRuntime::java_return_convention().\n+  enum layout {\n+    pad_off = frame::arg_reg_save_area_bytes\/BytesPerInt, pad_off_2,\n+    rax_off, rax_off_2,\n+    j_rarg5_off, j_rarg5_2,\n+    j_rarg4_off, j_rarg4_2,\n+    j_rarg3_off, j_rarg3_2,\n+    j_rarg2_off, j_rarg2_2,\n+    j_rarg1_off, j_rarg1_2,\n+    j_rarg0_off, j_rarg0_2,\n+    j_farg0_off, j_farg0_2,\n+    j_farg1_off, j_farg1_2,\n+    j_farg2_off, j_farg2_2,\n+    j_farg3_off, j_farg3_2,\n+    j_farg4_off, j_farg4_2,\n+    j_farg5_off, j_farg5_2,\n+    j_farg6_off, j_farg6_2,\n+    j_farg7_off, j_farg7_2,\n+    rbp_off, rbp_off_2,\n+    return_off, return_off_2,\n+\n+    framesize\n+  };\n+\n+  CodeBuffer buffer(name, 1000, 512);\n+  MacroAssembler* _masm = new MacroAssembler(&buffer);\n+\n+  int frame_size_in_bytes = align_up(framesize*BytesPerInt, 16);\n+  assert(frame_size_in_bytes == framesize*BytesPerInt, \"misaligned\");\n+  int frame_size_in_slots = frame_size_in_bytes \/ BytesPerInt;\n+  int frame_size_in_words = frame_size_in_bytes \/ wordSize;\n+\n+  OopMapSet *oop_maps = new OopMapSet();\n+  OopMap* map = new OopMap(frame_size_in_slots, 0);\n+\n+  map->set_callee_saved(VMRegImpl::stack2reg(rax_off), rax->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_rarg5_off), j_rarg5->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_rarg4_off), j_rarg4->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_rarg3_off), j_rarg3->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_rarg2_off), j_rarg2->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_rarg1_off), j_rarg1->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_rarg0_off), j_rarg0->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg0_off), j_farg0->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg1_off), j_farg1->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg2_off), j_farg2->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg3_off), j_farg3->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg4_off), j_farg4->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg5_off), j_farg5->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg6_off), j_farg6->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg7_off), j_farg7->as_VMReg());\n+\n+  int start = __ offset();\n+\n+  __ subptr(rsp, frame_size_in_bytes - 8 \/* return address*\/);\n+\n+  __ movptr(Address(rsp, rbp_off * BytesPerInt), rbp);\n+  __ movdbl(Address(rsp, j_farg7_off * BytesPerInt), j_farg7);\n+  __ movdbl(Address(rsp, j_farg6_off * BytesPerInt), j_farg6);\n+  __ movdbl(Address(rsp, j_farg5_off * BytesPerInt), j_farg5);\n+  __ movdbl(Address(rsp, j_farg4_off * BytesPerInt), j_farg4);\n+  __ movdbl(Address(rsp, j_farg3_off * BytesPerInt), j_farg3);\n+  __ movdbl(Address(rsp, j_farg2_off * BytesPerInt), j_farg2);\n+  __ movdbl(Address(rsp, j_farg1_off * BytesPerInt), j_farg1);\n+  __ movdbl(Address(rsp, j_farg0_off * BytesPerInt), j_farg0);\n+\n+  __ movptr(Address(rsp, j_rarg0_off * BytesPerInt), j_rarg0);\n+  __ movptr(Address(rsp, j_rarg1_off * BytesPerInt), j_rarg1);\n+  __ movptr(Address(rsp, j_rarg2_off * BytesPerInt), j_rarg2);\n+  __ movptr(Address(rsp, j_rarg3_off * BytesPerInt), j_rarg3);\n+  __ movptr(Address(rsp, j_rarg4_off * BytesPerInt), j_rarg4);\n+  __ movptr(Address(rsp, j_rarg5_off * BytesPerInt), j_rarg5);\n+  __ movptr(Address(rsp, rax_off * BytesPerInt), rax);\n+\n+  int frame_complete = __ offset();\n+\n+  __ set_last_Java_frame(noreg, noreg, nullptr, rscratch1);\n+\n+  __ mov(c_rarg0, r15_thread);\n+  __ mov(c_rarg1, rax);\n+\n+  __ call(RuntimeAddress(destination));\n+\n+  \/\/ Set an oopmap for the call site.\n+\n+  oop_maps->add_gc_map( __ offset() - start, map);\n+\n+  \/\/ clear last_Java_sp\n+  __ reset_last_Java_frame(false);\n+\n+  __ movptr(rbp, Address(rsp, rbp_off * BytesPerInt));\n+  __ movdbl(j_farg7, Address(rsp, j_farg7_off * BytesPerInt));\n+  __ movdbl(j_farg6, Address(rsp, j_farg6_off * BytesPerInt));\n+  __ movdbl(j_farg5, Address(rsp, j_farg5_off * BytesPerInt));\n+  __ movdbl(j_farg4, Address(rsp, j_farg4_off * BytesPerInt));\n+  __ movdbl(j_farg3, Address(rsp, j_farg3_off * BytesPerInt));\n+  __ movdbl(j_farg2, Address(rsp, j_farg2_off * BytesPerInt));\n+  __ movdbl(j_farg1, Address(rsp, j_farg1_off * BytesPerInt));\n+  __ movdbl(j_farg0, Address(rsp, j_farg0_off * BytesPerInt));\n+\n+  __ movptr(j_rarg0, Address(rsp, j_rarg0_off * BytesPerInt));\n+  __ movptr(j_rarg1, Address(rsp, j_rarg1_off * BytesPerInt));\n+  __ movptr(j_rarg2, Address(rsp, j_rarg2_off * BytesPerInt));\n+  __ movptr(j_rarg3, Address(rsp, j_rarg3_off * BytesPerInt));\n+  __ movptr(j_rarg4, Address(rsp, j_rarg4_off * BytesPerInt));\n+  __ movptr(j_rarg5, Address(rsp, j_rarg5_off * BytesPerInt));\n+  __ movptr(rax, Address(rsp, rax_off * BytesPerInt));\n+\n+  __ addptr(rsp, frame_size_in_bytes-8);\n+\n+  \/\/ check for pending exceptions\n+  Label pending;\n+  __ cmpptr(Address(r15_thread, Thread::pending_exception_offset()), (int32_t)NULL_WORD);\n+  __ jcc(Assembler::notEqual, pending);\n+\n+  if (has_res) {\n+    __ get_vm_result(rax, r15_thread);\n+  }\n+\n+  __ ret(0);\n+\n+  __ bind(pending);\n+\n+  __ movptr(rax, Address(r15_thread, Thread::pending_exception_offset()));\n+  __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+\n+  \/\/ -------------\n+  \/\/ make sure all code is generated\n+  _masm->flush();\n+\n+  RuntimeStub* stub = RuntimeStub::new_runtime_stub(name, &buffer, frame_complete, frame_size_in_words, oop_maps, false);\n+  return stub->entry_point();\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":183,"deletions":13,"binary":false,"changes":196,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -67,1 +68,1 @@\n-int TemplateInterpreter::InterpreterCodeSize = JVMCI_ONLY(268) NOT_JVMCI(256) * 1024;\n+int TemplateInterpreter::InterpreterCodeSize = JVMCI_ONLY(280) NOT_JVMCI(268) * 1024;\n@@ -212,2 +213,2 @@\n-  __ movptr(rcx, Address(rbp, frame::interpreter_frame_last_sp_offset * wordSize));\n-  __ lea(rsp, Address(rbp, rcx, Address::times_ptr));\n+  __ movptr(rscratch1, Address(rbp, frame::interpreter_frame_last_sp_offset * wordSize));\n+  __ lea(rsp, Address(rbp, rscratch1, Address::times_ptr));\n@@ -217,0 +218,4 @@\n+  if (state == atos && InlineTypeReturnedAsFields) {\n+    __ store_inline_type_fields_to_buf(nullptr);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/x86\/templateInterpreterGenerator_x86.cpp","additions":8,"deletions":3,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -606,0 +606,4 @@\n+  if (_entry_point == nullptr) {\n+    \/\/ CallLeafNoFPInDirect\n+    return 3; \/\/ callq (register)\n+  }\n@@ -612,0 +616,1 @@\n+\n@@ -837,14 +842,1 @@\n-  int framesize = C->output()->frame_size_in_bytes();\n-  int bangsize = C->output()->bang_size_in_bytes();\n-\n-  if (C->clinit_barrier_on_entry()) {\n-    assert(VM_Version::supports_fast_class_init_checks(), \"sanity\");\n-    assert(!C->method()->holder()->is_not_initialized(), \"initialization should have been started\");\n-\n-    Label L_skip_barrier;\n-    Register klass = rscratch1;\n-\n-    __ mov_metadata(klass, C->method()->holder()->constant_encoding());\n-    __ clinit_barrier(klass, r15_thread, &L_skip_barrier \/*L_fast_path*\/);\n-\n-    __ jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub())); \/\/ slow path\n+  __ verified_entry(C);\n@@ -852,1 +844,2 @@\n-    __ bind(L_skip_barrier);\n+  if (ra_->C->stub_function() == nullptr) {\n+    __ entry_barrier();\n@@ -855,1 +848,3 @@\n-  __ verified_entry(framesize, C->output()->need_stack_bang(bangsize)?bangsize:0, false, C->stub_function() != nullptr);\n+  if (!Compile::current()->output()->in_scratch_emit_size()) {\n+    __ bind(*_verified_entry);\n+  }\n@@ -867,6 +862,0 @@\n-uint MachPrologNode::size(PhaseRegAlloc* ra_) const\n-{\n-  return MachNode::size(ra_); \/\/ too many variables; just compute it\n-                              \/\/ the hard way\n-}\n-\n@@ -919,13 +908,3 @@\n-  int framesize = C->output()->frame_size_in_bytes();\n-  assert((framesize & (StackAlignmentInBytes-1)) == 0, \"frame size not aligned\");\n-  \/\/ Remove word for return adr already pushed\n-  \/\/ and RBP\n-  framesize -= 2*wordSize;\n-\n-  \/\/ Note that VerifyStackAtCalls' Majik cookie does not change the frame size popped here\n-\n-  if (framesize) {\n-    __ addq(rsp, framesize);\n-  }\n-\n-  __ popq(rbp);\n+  \/\/ Subtract two words to account for return address and rbp\n+  int initial_framesize = C->output()->frame_size_in_bytes() - 2*wordSize;\n+  __ remove_frame(initial_framesize, C->needs_stack_repair());\n@@ -950,6 +929,0 @@\n-uint MachEpilogNode::size(PhaseRegAlloc* ra_) const\n-{\n-  return MachNode::size(ra_); \/\/ too many variables; just compute it\n-                              \/\/ the hard way\n-}\n-\n@@ -1553,0 +1526,43 @@\n+\/\/=============================================================================\n+#ifndef PRODUCT\n+void MachVEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const\n+{\n+  st->print_cr(\"MachVEPNode\");\n+}\n+#endif\n+\n+void MachVEPNode::emit(C2_MacroAssembler* masm, PhaseRegAlloc* ra_) const\n+{\n+  CodeBuffer* cbuf = masm->code();\n+  uint insts_size = cbuf->insts_size();\n+  if (!_verified) {\n+    __ ic_check(1);\n+  } else {\n+    \/\/ TODO 8284443 Avoid creation of temporary frame\n+    if (ra_->C->stub_function() == nullptr) {\n+      __ verified_entry(ra_->C, 0);\n+      __ entry_barrier();\n+      int initial_framesize = ra_->C->output()->frame_size_in_bytes() - 2*wordSize;\n+      __ remove_frame(initial_framesize, false);\n+    }\n+    \/\/ Unpack inline type args passed as oop and then jump to\n+    \/\/ the verified entry point (skipping the unverified entry).\n+    int sp_inc = __ unpack_inline_args(ra_->C, _receiver_only);\n+    \/\/ Emit code for verified entry and save increment for stack repair on return\n+    __ verified_entry(ra_->C, sp_inc);\n+    if (Compile::current()->output()->in_scratch_emit_size()) {\n+      Label dummy_verified_entry;\n+      __ jmp(dummy_verified_entry);\n+    } else {\n+      __ jmp(*_verified_entry);\n+    }\n+  }\n+  \/* WARNING these NOPs are critical so that verified entry point is properly\n+     4 bytes aligned for patching by NativeJump::patch_verified_entry() *\/\n+  int nops_cnt = 4 - ((cbuf->insts_size() - insts_size) & 0x3);\n+  nops_cnt &= 0x3; \/\/ Do not add nops if code is aligned.\n+  if (nops_cnt > 0) {\n+    __ nop(nops_cnt);\n+  }\n+}\n+\n@@ -1573,7 +1589,0 @@\n-uint MachUEPNode::size(PhaseRegAlloc* ra_) const\n-{\n-  return MachNode::size(ra_); \/\/ too many variables; just compute it\n-                              \/\/ the hard way\n-}\n-\n-\n@@ -3054,0 +3063,16 @@\n+\/\/ Indirect Narrow Oop Operand\n+operand indCompressedOop(rRegN reg) %{\n+  predicate(UseCompressedOops && (CompressedOops::shift() == Address::times_8));\n+  constraint(ALLOC_IN_RC(ptr_reg));\n+  match(DecodeN reg);\n+\n+  op_cost(10);\n+  format %{\"[R12 + $reg << 3] (compressed oop addressing)\" %}\n+  interface(MEMORY_INTER) %{\n+    base(0xc); \/\/ R12\n+    index($reg);\n+    scale(0x3);\n+    disp(0x0);\n+  %}\n+%}\n+\n@@ -3400,1 +3425,1 @@\n-               indCompressedOopOffset,\n+               indCompressedOop, indCompressedOopOffset,\n@@ -5936,0 +5961,26 @@\n+instruct castI2N(rRegN dst, rRegI src)\n+%{\n+  match(Set dst (CastI2N src));\n+\n+  format %{ \"movq    $dst, $src\\t# int -> narrow ptr\" %}\n+  ins_encode %{\n+    if ($dst$$reg != $src$$reg) {\n+      __ movl($dst$$Register, $src$$Register);\n+    }\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ XXX\n+%}\n+\n+instruct castN2X(rRegL dst, rRegN src)\n+%{\n+  match(Set dst (CastP2X src));\n+\n+  format %{ \"movq    $dst, $src\\t# ptr -> long\" %}\n+  ins_encode %{\n+    if ($dst$$reg != $src$$reg) {\n+      __ movptr($dst$$Register, $src$$Register);\n+    }\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ XXX\n+%}\n+\n@@ -10495,0 +10546,1 @@\n+\n@@ -10497,1 +10549,1 @@\n-instruct rep_stos(rcx_RegL cnt, rdi_RegP base, regD tmp, rax_RegI zero,\n+instruct rep_stos(rcx_RegL cnt, rdi_RegP base, regD tmp, rax_RegL val,\n@@ -10500,3 +10552,120 @@\n-  predicate(!((ClearArrayNode*)n)->is_large() && (UseAVX <= 2));\n-  match(Set dummy (ClearArray cnt base));\n-  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, KILL zero, KILL cr);\n+  predicate(!((ClearArrayNode*)n)->is_large() && !((ClearArrayNode*)n)->word_copy_only() && (UseAVX <= 2));\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, USE_KILL val, KILL cr);\n+\n+  format %{ $$template\n+    $$emit$$\"cmp     InitArrayShortSize,rcx\\n\\t\"\n+    $$emit$$\"jg      LARGE\\n\\t\"\n+    $$emit$$\"dec     rcx\\n\\t\"\n+    $$emit$$\"js      DONE\\t# Zero length\\n\\t\"\n+    $$emit$$\"mov     rax,(rdi,rcx,8)\\t# LOOP\\n\\t\"\n+    $$emit$$\"dec     rcx\\n\\t\"\n+    $$emit$$\"jge     LOOP\\n\\t\"\n+    $$emit$$\"jmp     DONE\\n\\t\"\n+    $$emit$$\"# LARGE:\\n\\t\"\n+    if (UseFastStosb) {\n+       $$emit$$\"shlq    rcx,3\\t# Convert doublewords to bytes\\n\\t\"\n+       $$emit$$\"rep     stosb\\t# Store rax to *rdi++ while rcx--\\n\\t\"\n+    } else if (UseXMMForObjInit) {\n+       $$emit$$\"movdq   $tmp, $val\\n\\t\"\n+       $$emit$$\"punpcklqdq $tmp, $tmp\\n\\t\"\n+       $$emit$$\"vinserti128_high $tmp, $tmp\\n\\t\"\n+       $$emit$$\"jmpq    L_zero_64_bytes\\n\\t\"\n+       $$emit$$\"# L_loop:\\t# 64-byte LOOP\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,(rax)\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,0x20(rax)\\n\\t\"\n+       $$emit$$\"add     0x40,rax\\n\\t\"\n+       $$emit$$\"# L_zero_64_bytes:\\n\\t\"\n+       $$emit$$\"sub     0x8,rcx\\n\\t\"\n+       $$emit$$\"jge     L_loop\\n\\t\"\n+       $$emit$$\"add     0x4,rcx\\n\\t\"\n+       $$emit$$\"jl      L_tail\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,(rax)\\n\\t\"\n+       $$emit$$\"add     0x20,rax\\n\\t\"\n+       $$emit$$\"sub     0x4,rcx\\n\\t\"\n+       $$emit$$\"# L_tail:\\t# Clearing tail bytes\\n\\t\"\n+       $$emit$$\"add     0x4,rcx\\n\\t\"\n+       $$emit$$\"jle     L_end\\n\\t\"\n+       $$emit$$\"dec     rcx\\n\\t\"\n+       $$emit$$\"# L_sloop:\\t# 8-byte short loop\\n\\t\"\n+       $$emit$$\"vmovq   xmm0,(rax)\\n\\t\"\n+       $$emit$$\"add     0x8,rax\\n\\t\"\n+       $$emit$$\"dec     rcx\\n\\t\"\n+       $$emit$$\"jge     L_sloop\\n\\t\"\n+       $$emit$$\"# L_end:\\n\\t\"\n+    } else {\n+       $$emit$$\"rep     stosq\\t# Store rax to *rdi++ while rcx--\\n\\t\"\n+    }\n+    $$emit$$\"# DONE\"\n+  %}\n+  ins_encode %{\n+    __ clear_mem($base$$Register, $cnt$$Register, $val$$Register,\n+                 $tmp$$XMMRegister, false, false);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct rep_stos_word_copy(rcx_RegL cnt, rdi_RegP base, regD tmp, rax_RegL val,\n+                            Universe dummy, rFlagsReg cr)\n+%{\n+  predicate(!((ClearArrayNode*)n)->is_large() && ((ClearArrayNode*)n)->word_copy_only() && (UseAVX <= 2));\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, USE_KILL val, KILL cr);\n+\n+  format %{ $$template\n+    $$emit$$\"cmp     InitArrayShortSize,rcx\\n\\t\"\n+    $$emit$$\"jg      LARGE\\n\\t\"\n+    $$emit$$\"dec     rcx\\n\\t\"\n+    $$emit$$\"js      DONE\\t# Zero length\\n\\t\"\n+    $$emit$$\"mov     rax,(rdi,rcx,8)\\t# LOOP\\n\\t\"\n+    $$emit$$\"dec     rcx\\n\\t\"\n+    $$emit$$\"jge     LOOP\\n\\t\"\n+    $$emit$$\"jmp     DONE\\n\\t\"\n+    $$emit$$\"# LARGE:\\n\\t\"\n+    if (UseXMMForObjInit) {\n+       $$emit$$\"movdq   $tmp, $val\\n\\t\"\n+       $$emit$$\"punpcklqdq $tmp, $tmp\\n\\t\"\n+       $$emit$$\"vinserti128_high $tmp, $tmp\\n\\t\"\n+       $$emit$$\"jmpq    L_zero_64_bytes\\n\\t\"\n+       $$emit$$\"# L_loop:\\t# 64-byte LOOP\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,(rax)\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,0x20(rax)\\n\\t\"\n+       $$emit$$\"add     0x40,rax\\n\\t\"\n+       $$emit$$\"# L_zero_64_bytes:\\n\\t\"\n+       $$emit$$\"sub     0x8,rcx\\n\\t\"\n+       $$emit$$\"jge     L_loop\\n\\t\"\n+       $$emit$$\"add     0x4,rcx\\n\\t\"\n+       $$emit$$\"jl      L_tail\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,(rax)\\n\\t\"\n+       $$emit$$\"add     0x20,rax\\n\\t\"\n+       $$emit$$\"sub     0x4,rcx\\n\\t\"\n+       $$emit$$\"# L_tail:\\t# Clearing tail bytes\\n\\t\"\n+       $$emit$$\"add     0x4,rcx\\n\\t\"\n+       $$emit$$\"jle     L_end\\n\\t\"\n+       $$emit$$\"dec     rcx\\n\\t\"\n+       $$emit$$\"# L_sloop:\\t# 8-byte short loop\\n\\t\"\n+       $$emit$$\"vmovq   xmm0,(rax)\\n\\t\"\n+       $$emit$$\"add     0x8,rax\\n\\t\"\n+       $$emit$$\"dec     rcx\\n\\t\"\n+       $$emit$$\"jge     L_sloop\\n\\t\"\n+       $$emit$$\"# L_end:\\n\\t\"\n+    } else {\n+       $$emit$$\"rep     stosq\\t# Store rax to *rdi++ while rcx--\\n\\t\"\n+    }\n+    $$emit$$\"# DONE\"\n+  %}\n+  ins_encode %{\n+    __ clear_mem($base$$Register, $cnt$$Register, $val$$Register,\n+                 $tmp$$XMMRegister, false, true);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Small non-constant length ClearArray for AVX512 targets.\n+instruct rep_stos_evex(rcx_RegL cnt, rdi_RegP base, legRegD tmp, kReg ktmp, rax_RegL val,\n+                       Universe dummy, rFlagsReg cr)\n+%{\n+  predicate(!((ClearArrayNode*)n)->is_large() && !((ClearArrayNode*)n)->word_copy_only() && (UseAVX > 2));\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n+  ins_cost(125);\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, USE_KILL val, KILL cr);\n@@ -10550,2 +10719,2 @@\n-    __ clear_mem($base$$Register, $cnt$$Register, $zero$$Register,\n-                 $tmp$$XMMRegister, false, knoreg);\n+    __ clear_mem($base$$Register, $cnt$$Register, $val$$Register,\n+                 $tmp$$XMMRegister, false, false, $ktmp$$KRegister);\n@@ -10556,3 +10725,2 @@\n-\/\/ Small non-constant length ClearArray for AVX512 targets.\n-instruct rep_stos_evex(rcx_RegL cnt, rdi_RegP base, legRegD tmp, kReg ktmp, rax_RegI zero,\n-                       Universe dummy, rFlagsReg cr)\n+instruct rep_stos_evex_word_copy(rcx_RegL cnt, rdi_RegP base, legRegD tmp, kReg ktmp, rax_RegL val,\n+                                 Universe dummy, rFlagsReg cr)\n@@ -10560,2 +10728,2 @@\n-  predicate(!((ClearArrayNode*)n)->is_large() && (UseAVX > 2));\n-  match(Set dummy (ClearArray cnt base));\n+  predicate(!((ClearArrayNode*)n)->is_large() && ((ClearArrayNode*)n)->word_copy_only() && (UseAVX > 2));\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n@@ -10563,1 +10731,1 @@\n-  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, KILL zero, KILL cr);\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, USE_KILL val, KILL cr);\n@@ -10611,2 +10779,2 @@\n-    __ clear_mem($base$$Register, $cnt$$Register, $zero$$Register,\n-                 $tmp$$XMMRegister, false, $ktmp$$KRegister);\n+    __ clear_mem($base$$Register, $cnt$$Register, $val$$Register,\n+                 $tmp$$XMMRegister, false, true, $ktmp$$KRegister);\n@@ -10618,1 +10786,1 @@\n-instruct rep_stos_large(rcx_RegL cnt, rdi_RegP base, regD tmp, rax_RegI zero,\n+instruct rep_stos_large(rcx_RegL cnt, rdi_RegP base, regD tmp, rax_RegL val,\n@@ -10621,3 +10789,99 @@\n-  predicate((UseAVX <=2) && ((ClearArrayNode*)n)->is_large());\n-  match(Set dummy (ClearArray cnt base));\n-  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, KILL zero, KILL cr);\n+  predicate(((ClearArrayNode*)n)->is_large() && !((ClearArrayNode*)n)->word_copy_only() && (UseAVX <= 2));\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, USE_KILL val, KILL cr);\n+\n+  format %{ $$template\n+    if (UseFastStosb) {\n+       $$emit$$\"shlq    rcx,3\\t# Convert doublewords to bytes\\n\\t\"\n+       $$emit$$\"rep     stosb\\t# Store rax to *rdi++ while rcx--\"\n+    } else if (UseXMMForObjInit) {\n+       $$emit$$\"movdq   $tmp, $val\\n\\t\"\n+       $$emit$$\"punpcklqdq $tmp, $tmp\\n\\t\"\n+       $$emit$$\"vinserti128_high $tmp, $tmp\\n\\t\"\n+       $$emit$$\"jmpq    L_zero_64_bytes\\n\\t\"\n+       $$emit$$\"# L_loop:\\t# 64-byte LOOP\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,(rax)\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,0x20(rax)\\n\\t\"\n+       $$emit$$\"add     0x40,rax\\n\\t\"\n+       $$emit$$\"# L_zero_64_bytes:\\n\\t\"\n+       $$emit$$\"sub     0x8,rcx\\n\\t\"\n+       $$emit$$\"jge     L_loop\\n\\t\"\n+       $$emit$$\"add     0x4,rcx\\n\\t\"\n+       $$emit$$\"jl      L_tail\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,(rax)\\n\\t\"\n+       $$emit$$\"add     0x20,rax\\n\\t\"\n+       $$emit$$\"sub     0x4,rcx\\n\\t\"\n+       $$emit$$\"# L_tail:\\t# Clearing tail bytes\\n\\t\"\n+       $$emit$$\"add     0x4,rcx\\n\\t\"\n+       $$emit$$\"jle     L_end\\n\\t\"\n+       $$emit$$\"dec     rcx\\n\\t\"\n+       $$emit$$\"# L_sloop:\\t# 8-byte short loop\\n\\t\"\n+       $$emit$$\"vmovq   xmm0,(rax)\\n\\t\"\n+       $$emit$$\"add     0x8,rax\\n\\t\"\n+       $$emit$$\"dec     rcx\\n\\t\"\n+       $$emit$$\"jge     L_sloop\\n\\t\"\n+       $$emit$$\"# L_end:\\n\\t\"\n+    } else {\n+       $$emit$$\"rep     stosq\\t# Store rax to *rdi++ while rcx--\"\n+    }\n+  %}\n+  ins_encode %{\n+    __ clear_mem($base$$Register, $cnt$$Register, $val$$Register,\n+                 $tmp$$XMMRegister, true, false);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct rep_stos_large_word_copy(rcx_RegL cnt, rdi_RegP base, regD tmp, rax_RegL val,\n+                                  Universe dummy, rFlagsReg cr)\n+%{\n+  predicate(((ClearArrayNode*)n)->is_large() && ((ClearArrayNode*)n)->word_copy_only() && (UseAVX <= 2));\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, USE_KILL val, KILL cr);\n+\n+  format %{ $$template\n+    if (UseXMMForObjInit) {\n+       $$emit$$\"movdq   $tmp, $val\\n\\t\"\n+       $$emit$$\"punpcklqdq $tmp, $tmp\\n\\t\"\n+       $$emit$$\"vinserti128_high $tmp, $tmp\\n\\t\"\n+       $$emit$$\"jmpq    L_zero_64_bytes\\n\\t\"\n+       $$emit$$\"# L_loop:\\t# 64-byte LOOP\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,(rax)\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,0x20(rax)\\n\\t\"\n+       $$emit$$\"add     0x40,rax\\n\\t\"\n+       $$emit$$\"# L_zero_64_bytes:\\n\\t\"\n+       $$emit$$\"sub     0x8,rcx\\n\\t\"\n+       $$emit$$\"jge     L_loop\\n\\t\"\n+       $$emit$$\"add     0x4,rcx\\n\\t\"\n+       $$emit$$\"jl      L_tail\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,(rax)\\n\\t\"\n+       $$emit$$\"add     0x20,rax\\n\\t\"\n+       $$emit$$\"sub     0x4,rcx\\n\\t\"\n+       $$emit$$\"# L_tail:\\t# Clearing tail bytes\\n\\t\"\n+       $$emit$$\"add     0x4,rcx\\n\\t\"\n+       $$emit$$\"jle     L_end\\n\\t\"\n+       $$emit$$\"dec     rcx\\n\\t\"\n+       $$emit$$\"# L_sloop:\\t# 8-byte short loop\\n\\t\"\n+       $$emit$$\"vmovq   xmm0,(rax)\\n\\t\"\n+       $$emit$$\"add     0x8,rax\\n\\t\"\n+       $$emit$$\"dec     rcx\\n\\t\"\n+       $$emit$$\"jge     L_sloop\\n\\t\"\n+       $$emit$$\"# L_end:\\n\\t\"\n+    } else {\n+       $$emit$$\"rep     stosq\\t# Store rax to *rdi++ while rcx--\"\n+    }\n+  %}\n+  ins_encode %{\n+    __ clear_mem($base$$Register, $cnt$$Register, $val$$Register,\n+                 $tmp$$XMMRegister, true, true);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Large non-constant length ClearArray for AVX512 targets.\n+instruct rep_stos_large_evex(rcx_RegL cnt, rdi_RegP base, legRegD tmp, kReg ktmp, rax_RegL val,\n+                             Universe dummy, rFlagsReg cr)\n+%{\n+  predicate(((ClearArrayNode*)n)->is_large() && !((ClearArrayNode*)n)->word_copy_only() && (UseAVX > 2));\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, USE_KILL val, KILL cr);\n@@ -10662,2 +10926,2 @@\n-    __ clear_mem($base$$Register, $cnt$$Register, $zero$$Register,\n-                 $tmp$$XMMRegister, true, knoreg);\n+    __ clear_mem($base$$Register, $cnt$$Register, $val$$Register,\n+                 $tmp$$XMMRegister, true, false, $ktmp$$KRegister);\n@@ -10668,3 +10932,2 @@\n-\/\/ Large non-constant length ClearArray for AVX512 targets.\n-instruct rep_stos_large_evex(rcx_RegL cnt, rdi_RegP base, legRegD tmp, kReg ktmp, rax_RegI zero,\n-                             Universe dummy, rFlagsReg cr)\n+instruct rep_stos_large_evex_word_copy(rcx_RegL cnt, rdi_RegP base, legRegD tmp, kReg ktmp, rax_RegL val,\n+                                       Universe dummy, rFlagsReg cr)\n@@ -10672,3 +10935,3 @@\n-  predicate((UseAVX > 2) && ((ClearArrayNode*)n)->is_large());\n-  match(Set dummy (ClearArray cnt base));\n-  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, KILL zero, KILL cr);\n+  predicate(((ClearArrayNode*)n)->is_large() && ((ClearArrayNode*)n)->word_copy_only() && (UseAVX > 2));\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, USE_KILL val, KILL cr);\n@@ -10713,2 +10976,2 @@\n-    __ clear_mem($base$$Register, $cnt$$Register, $zero$$Register,\n-                 $tmp$$XMMRegister, true, $ktmp$$KRegister);\n+    __ clear_mem($base$$Register, $cnt$$Register, $val$$Register,\n+                 $tmp$$XMMRegister, true, true, $ktmp$$KRegister);\n@@ -10720,1 +10983,1 @@\n-instruct rep_stos_im(immL cnt, rRegP base, regD tmp, rRegI zero, kReg ktmp, Universe dummy, rFlagsReg cr)\n+instruct rep_stos_im(immL cnt, rRegP base, regD tmp, rax_RegL val, kReg ktmp, Universe dummy, rFlagsReg cr)\n@@ -10722,2 +10985,3 @@\n-  predicate(!((ClearArrayNode*)n)->is_large() && (MaxVectorSize >= 32) && VM_Version::supports_avx512vl());\n-  match(Set dummy (ClearArray cnt base));\n+  predicate(!((ClearArrayNode*)n)->is_large() && !((ClearArrayNode*)n)->word_copy_only() &&\n+            ((MaxVectorSize >= 32) && VM_Version::supports_avx512vl()));\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n@@ -10725,1 +10989,1 @@\n-  effect(TEMP tmp, TEMP zero, TEMP ktmp, KILL cr);\n+  effect(TEMP tmp, USE_KILL val, TEMP ktmp, KILL cr);\n@@ -10728,1 +10992,1 @@\n-   __ clear_mem($base$$Register, $cnt$$constant, $zero$$Register, $tmp$$XMMRegister, $ktmp$$KRegister);\n+    __ clear_mem($base$$Register, $cnt$$constant, $val$$Register, $tmp$$XMMRegister, $ktmp$$KRegister);\n@@ -12547,0 +12811,15 @@\n+\/\/ entry point is null, target holds the address to call\n+instruct CallLeafNoFPInDirect(rRegP target)\n+%{\n+  predicate(n->as_Call()->entry_point() == nullptr);\n+  match(CallLeafNoFP target);\n+\n+  ins_cost(300);\n+  format %{ \"call_leaf_nofp,runtime indirect \" %}\n+  ins_encode %{\n+     __ call($target$$Register);\n+  %}\n+\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -12549,0 +12828,1 @@\n+  predicate(n->as_Call()->entry_point() != nullptr);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":362,"deletions":82,"binary":false,"changes":444,"status":"modified"},{"patch":"@@ -52,0 +52,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/flatArrayOop.inline.hpp\"\n@@ -122,0 +124,1 @@\n+uint Runtime1::_new_null_free_array_slowcase_cnt = 0;\n@@ -124,0 +127,5 @@\n+uint Runtime1::_load_flat_array_slowcase_cnt = 0;\n+uint Runtime1::_store_flat_array_slowcase_cnt = 0;\n+uint Runtime1::_substitutability_check_slowcase_cnt = 0;\n+uint Runtime1::_buffer_inline_args_slowcase_cnt = 0;\n+uint Runtime1::_buffer_inline_args_no_receiver_slowcase_cnt = 0;\n@@ -133,0 +141,2 @@\n+uint Runtime1::_throw_illegal_monitor_state_exception_count = 0;\n+uint Runtime1::_throw_identity_exception_count = 0;\n@@ -353,2 +363,1 @@\n-\n-JRT_ENTRY(void, Runtime1::new_instance(JavaThread* current, Klass* klass))\n+static void allocate_instance(JavaThread* current, Klass* klass, TRAPS) {\n@@ -357,1 +366,1 @@\n-    _new_instance_slowcase_cnt++;\n+    Runtime1::_new_instance_slowcase_cnt++;\n@@ -366,2 +375,8 @@\n-  \/\/ allocate instance and return via TLS\n-  oop obj = h->allocate_instance(CHECK);\n+  oop obj = nullptr;\n+  if (h->is_inline_klass() && InlineKlass::cast(h)->is_empty_inline_type()) {\n+    obj = InlineKlass::cast(h)->default_value();\n+    assert(obj != nullptr, \"default value must exist\");\n+  } else {\n+    \/\/ allocate instance and return via TLS\n+    obj = h->allocate_instance(CHECK);\n+  }\n@@ -371,0 +386,3 @@\n+JRT_ENTRY(void, Runtime1::new_instance(JavaThread* current, Klass* klass))\n+  allocate_instance(current, klass, CHECK);\n+JRT_END\n@@ -405,1 +423,1 @@\n-  Klass* elem_klass = ObjArrayKlass::cast(array_klass)->element_klass();\n+  Klass* elem_klass = ArrayKlass::cast(array_klass)->element_klass();\n@@ -416,0 +434,29 @@\n+JRT_ENTRY(void, Runtime1::new_null_free_array(JavaThread* current, Klass* array_klass, jint length))\n+  NOT_PRODUCT(_new_null_free_array_slowcase_cnt++;)\n+  \/\/ TODO 8350865 This is dead code since 8325660 because null-free arrays can only be created via the factory methods that are not yet implemented in C1. Should probably be fixed by 8265122.\n+\n+  \/\/ Note: no handle for klass needed since they are not used\n+  \/\/       anymore after new_objArray() and no GC can happen before.\n+  \/\/       (This may have to change if this code changes!)\n+  assert(array_klass->is_klass(), \"not a class\");\n+  Handle holder(THREAD, array_klass->klass_holder()); \/\/ keep the klass alive\n+  Klass* elem_klass = ArrayKlass::cast(array_klass)->element_klass();\n+  assert(elem_klass->is_inline_klass(), \"must be\");\n+  InlineKlass* vk = InlineKlass::cast(elem_klass);\n+  \/\/ Logically creates elements, ensure klass init\n+  elem_klass->initialize(CHECK);\n+  arrayOop obj= nullptr;\n+  if (UseArrayFlattening && vk->has_non_atomic_layout()) {\n+    obj = oopFactory::new_flatArray(elem_klass, length, LayoutKind::NON_ATOMIC_FLAT, CHECK);\n+  } else {\n+    obj = oopFactory::new_null_free_objArray(elem_klass, length, CHECK);\n+  }\n+  current->set_vm_result(obj);\n+  \/\/ This is pretty rare but this runtime patch is stressful to deoptimization\n+  \/\/ if we deoptimize here so force a deopt to stress the path.\n+  if (DeoptimizeALot) {\n+    deopt_caller(current);\n+  }\n+JRT_END\n+\n+\n@@ -430,0 +477,96 @@\n+static void profile_flat_array(JavaThread* current, bool load, bool null_free) {\n+  ResourceMark rm(current);\n+  vframeStream vfst(current, true);\n+  assert(!vfst.at_end(), \"Java frame must exist\");\n+  \/\/ Check if array access profiling is enabled\n+  if (vfst.nm()->comp_level() != CompLevel_full_profile || !C1UpdateMethodData) {\n+    return;\n+  }\n+  int bci = vfst.bci();\n+  Method* method = vfst.method();\n+  MethodData* md = method->method_data();\n+  if (md != nullptr) {\n+    \/\/ Lock to access ProfileData, and ensure lock is not broken by a safepoint\n+    MutexLocker ml(md->extra_data_lock(), Mutex::_no_safepoint_check_flag);\n+\n+    ProfileData* data = md->bci_to_data(bci);\n+    assert(data != nullptr, \"incorrect profiling entry\");\n+    if (data->is_ArrayLoadData()) {\n+      assert(load, \"should be an array load\");\n+      ArrayLoadData* load_data = (ArrayLoadData*) data;\n+      load_data->set_flat_array();\n+      if (null_free) {\n+        load_data->set_null_free_array();\n+      }\n+    } else {\n+      assert(data->is_ArrayStoreData(), \"\");\n+      assert(!load, \"should be an array store\");\n+      ArrayStoreData* store_data = (ArrayStoreData*) data;\n+      store_data->set_flat_array();\n+      if (null_free) {\n+        store_data->set_null_free_array();\n+      }\n+    }\n+  }\n+}\n+\n+JRT_ENTRY(void, Runtime1::load_flat_array(JavaThread* current, flatArrayOopDesc* array, int index))\n+  assert(array->klass()->is_flatArray_klass(), \"should not be called\");\n+  profile_flat_array(current, true, array->is_null_free_array());\n+\n+  NOT_PRODUCT(_load_flat_array_slowcase_cnt++;)\n+  assert(array->length() > 0 && index < array->length(), \"already checked\");\n+  flatArrayHandle vah(current, array);\n+  oop obj = array->read_value_from_flat_array(index, CHECK);\n+  current->set_vm_result(obj);\n+JRT_END\n+\n+JRT_ENTRY(void, Runtime1::store_flat_array(JavaThread* current, flatArrayOopDesc* array, int index, oopDesc* value))\n+  \/\/ TOOD 8350865 We can call here with a non-flat array because of LIR_Assembler::emit_opFlattenedArrayCheck\n+  if (array->klass()->is_flatArray_klass()) {\n+    profile_flat_array(current, false, array->is_null_free_array());\n+  }\n+\n+  NOT_PRODUCT(_store_flat_array_slowcase_cnt++;)\n+  if (value == nullptr && array->is_null_free_array()) {\n+    SharedRuntime::throw_and_post_jvmti_exception(current, vmSymbols::java_lang_NullPointerException());\n+  } else {\n+    assert(array->klass()->is_flatArray_klass(), \"should not be called\");\n+    array->write_value_to_flat_array(value, index, CHECK);\n+  }\n+JRT_END\n+\n+JRT_ENTRY(int, Runtime1::substitutability_check(JavaThread* current, oopDesc* left, oopDesc* right))\n+  NOT_PRODUCT(_substitutability_check_slowcase_cnt++;)\n+  JavaCallArguments args;\n+  args.push_oop(Handle(THREAD, left));\n+  args.push_oop(Handle(THREAD, right));\n+  JavaValue result(T_BOOLEAN);\n+  JavaCalls::call_static(&result,\n+                         vmClasses::ValueObjectMethods_klass(),\n+                         vmSymbols::isSubstitutable_name(),\n+                         vmSymbols::object_object_boolean_signature(),\n+                         &args, CHECK_0);\n+  return result.get_jboolean() ? 1 : 0;\n+JRT_END\n+\n+\n+extern \"C\" void ps();\n+\n+void Runtime1::buffer_inline_args_impl(JavaThread* current, Method* m, bool allocate_receiver) {\n+  JavaThread* THREAD = current;\n+  methodHandle method(current, m); \/\/ We are inside the verified_entry or verified_inline_ro_entry of this method.\n+  oop obj = SharedRuntime::allocate_inline_types_impl(current, method, allocate_receiver, CHECK);\n+  current->set_vm_result(obj);\n+}\n+\n+JRT_ENTRY(void, Runtime1::buffer_inline_args(JavaThread* current, Method* method))\n+  NOT_PRODUCT(_buffer_inline_args_slowcase_cnt++;)\n+  buffer_inline_args_impl(current, method, true);\n+JRT_END\n+\n+JRT_ENTRY(void, Runtime1::buffer_inline_args_no_receiver(JavaThread* current, Method* method))\n+  NOT_PRODUCT(_buffer_inline_args_no_receiver_slowcase_cnt++;)\n+  buffer_inline_args_impl(current, method, false);\n+JRT_END\n+\n@@ -753,0 +896,13 @@\n+JRT_ENTRY(void, Runtime1::throw_illegal_monitor_state_exception(JavaThread* current))\n+  NOT_PRODUCT(_throw_illegal_monitor_state_exception_count++;)\n+  ResourceMark rm(current);\n+  SharedRuntime::throw_and_post_jvmti_exception(current, vmSymbols::java_lang_IllegalMonitorStateException());\n+JRT_END\n+\n+JRT_ENTRY(void, Runtime1::throw_identity_exception(JavaThread* current, oopDesc* object))\n+  NOT_PRODUCT(_throw_identity_exception_count++;)\n+  ResourceMark rm(current);\n+  char* message = SharedRuntime::generate_identity_exception_message(current, object->klass());\n+  SharedRuntime::throw_and_post_jvmti_exception(current, vmSymbols::java_lang_IdentityException(), message);\n+JRT_END\n+\n@@ -958,0 +1114,2 @@\n+  bool deoptimize_for_null_free = false;\n+  bool deoptimize_for_flat = false;\n@@ -1001,0 +1159,10 @@\n+    \/\/ The field we are patching is null-free. Deoptimize and regenerate\n+    \/\/ the compiled code if we patch a putfield\/putstatic because it\n+    \/\/ does not contain the required null check.\n+    deoptimize_for_null_free = result.is_null_free_inline_type() && (field_access.is_putfield() || field_access.is_putstatic());\n+\n+    \/\/ The field we are patching is flat. Deoptimize and regenerate\n+    \/\/ the compiled code which can't handle the layout of the flat\n+    \/\/ field because it was unknown at compile time.\n+    deoptimize_for_flat = result.is_flat();\n+\n@@ -1073,1 +1241,1 @@\n-  if (deoptimize_for_volatile || deoptimize_for_atomic) {\n+  if (deoptimize_for_volatile || deoptimize_for_atomic || deoptimize_for_null_free || deoptimize_for_flat) {\n@@ -1084,0 +1252,6 @@\n+      if (deoptimize_for_null_free) {\n+        tty->print_cr(\"Deoptimizing for patching null-free field reference\");\n+      }\n+      if (deoptimize_for_flat) {\n+        tty->print_cr(\"Deoptimizing for patching flat field reference\");\n+      }\n@@ -1534,0 +1708,1 @@\n+  tty->print_cr(\" _new_null_free_array_slowcase_cnt: %u\", _new_null_free_array_slowcase_cnt);\n@@ -1536,0 +1711,6 @@\n+  tty->print_cr(\" _load_flat_array_slowcase_cnt:   %u\", _load_flat_array_slowcase_cnt);\n+  tty->print_cr(\" _store_flat_array_slowcase_cnt:  %u\", _store_flat_array_slowcase_cnt);\n+  tty->print_cr(\" _substitutability_check_slowcase_cnt: %u\", _substitutability_check_slowcase_cnt);\n+  tty->print_cr(\" _buffer_inline_args_slowcase_cnt:%u\", _buffer_inline_args_slowcase_cnt);\n+  tty->print_cr(\" _buffer_inline_args_no_receiver_slowcase_cnt:%u\", _buffer_inline_args_no_receiver_slowcase_cnt);\n+\n@@ -1546,0 +1727,2 @@\n+  tty->print_cr(\" _throw_illegal_monitor_state_exception_count:  %u:\", _throw_illegal_monitor_state_exception_count);\n+  tty->print_cr(\" _throw_identity_exception_count:               %u:\", _throw_identity_exception_count);\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":190,"deletions":7,"binary":false,"changes":197,"status":"modified"},{"patch":"@@ -2016,0 +2016,7 @@\n+\n+    if (CDSConfig::is_valhalla_preview() && strcmp(klass_name, \"jdk\/internal\/module\/ArchivedModuleGraph\") == 0) {\n+      \/\/ FIXME -- ArchivedModuleGraph doesn't work when java.base is patched with valhalla classes.\n+      i++;\n+      continue;\n+    }\n+\n","filename":"src\/hotspot\/share\/cds\/heapShared.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -514,1 +515,1 @@\n-      \/\/ array\n+      \/\/ TODO 8350865 I think we need to handle null-free\/flat arrays here\n@@ -964,0 +965,1 @@\n+\n@@ -1010,27 +1012,79 @@\n-  \/\/ staticfield <klass> <name> <signature> <value>\n-  \/\/\n-  \/\/ Initialize a class and fill in the value for a static field.\n-  \/\/ This is useful when the compile was dependent on the value of\n-  \/\/ static fields but it's impossible to properly rerun the static\n-  \/\/ initializer.\n-  void process_staticfield(TRAPS) {\n-    InstanceKlass* k = (InstanceKlass *)parse_klass(CHECK);\n-\n-    if (k == nullptr || ReplaySuppressInitializers == 0 ||\n-        (ReplaySuppressInitializers == 2 && k->class_loader() == nullptr)) {\n-      skip_remaining();\n-      return;\n-    }\n-\n-    assert(k->is_initialized(), \"must be\");\n-\n-    const char* field_name = parse_escaped_string();\n-    const char* field_signature = parse_string();\n-    fieldDescriptor fd;\n-    Symbol* name = SymbolTable::new_symbol(field_name);\n-    Symbol* sig = SymbolTable::new_symbol(field_signature);\n-    if (!k->find_local_field(name, sig, &fd) ||\n-        !fd.is_static() ||\n-        fd.has_initial_value()) {\n-      report_error(field_name);\n-      return;\n+  class InlineTypeFieldInitializer : public FieldClosure {\n+    oop _vt;\n+    CompileReplay* _replay;\n+  public:\n+    InlineTypeFieldInitializer(oop vt, CompileReplay* replay)\n+  : _vt(vt), _replay(replay) {}\n+\n+    void do_field(fieldDescriptor* fd) {\n+      BasicType bt = fd->field_type();\n+      const char* string_value = fd->is_null_free_inline_type() ? nullptr : _replay->parse_escaped_string();\n+      switch (bt) {\n+      case T_BYTE: {\n+        int value = atoi(string_value);\n+        _vt->byte_field_put(fd->offset(), value);\n+        break;\n+      }\n+      case T_BOOLEAN: {\n+        int value = atoi(string_value);\n+        _vt->bool_field_put(fd->offset(), value);\n+        break;\n+      }\n+      case T_SHORT: {\n+        int value = atoi(string_value);\n+        _vt->short_field_put(fd->offset(), value);\n+        break;\n+      }\n+      case T_CHAR: {\n+        int value = atoi(string_value);\n+        _vt->char_field_put(fd->offset(), value);\n+        break;\n+      }\n+      case T_INT: {\n+        int value = atoi(string_value);\n+        _vt->int_field_put(fd->offset(), value);\n+        break;\n+      }\n+      case T_LONG: {\n+        jlong value;\n+        if (sscanf(string_value, JLONG_FORMAT, &value) != 1) {\n+          fprintf(stderr, \"Error parsing long: %s\\n\", string_value);\n+          break;\n+        }\n+        _vt->long_field_put(fd->offset(), value);\n+        break;\n+      }\n+      case T_FLOAT: {\n+        float value = atof(string_value);\n+        _vt->float_field_put(fd->offset(), value);\n+        break;\n+      }\n+      case T_DOUBLE: {\n+        double value = atof(string_value);\n+        _vt->double_field_put(fd->offset(), value);\n+        break;\n+      }\n+      case T_ARRAY:\n+      case T_OBJECT:\n+        if (!fd->is_null_free_inline_type()) {\n+          JavaThread* THREAD = JavaThread::current();\n+          bool res = _replay->process_staticfield_reference(string_value, _vt, fd, THREAD);\n+          assert(res, \"should succeed for arrays & objects\");\n+          break;\n+        } else {\n+          InlineKlass* vk = InlineKlass::cast(fd->field_holder()->get_inline_type_field_klass(fd->index()));\n+          if (fd->is_flat()) {\n+            int field_offset = fd->offset() - vk->payload_offset();\n+            oop obj = cast_to_oop(cast_from_oop<address>(_vt) + field_offset);\n+            InlineTypeFieldInitializer init_fields(obj, _replay);\n+            vk->do_nonstatic_fields(&init_fields);\n+          } else {\n+            oop value = vk->allocate_instance(JavaThread::current());\n+            _vt->obj_field_put(fd->offset(), value);\n+          }\n+          break;\n+        }\n+      default: {\n+        fatal(\"Unhandled type: %s\", type2name(bt));\n+      }\n+      }\n@@ -1038,0 +1092,1 @@\n+  };\n@@ -1039,1 +1094,1 @@\n-    oop java_mirror = k->java_mirror();\n+  bool process_staticfield_reference(const char* field_signature, oop java_mirror, fieldDescriptor* fd, TRAPS) {\n@@ -1047,4 +1102,2 @@\n-          ArrayKlass* kelem = (ArrayKlass *)parse_klass(CHECK);\n-          if (kelem == nullptr) {\n-            return;\n-          }\n+          Klass* k = resolve_klass(field_signature, CHECK_(true));\n+          ArrayKlass* kelem = (ArrayKlass *)k;\n@@ -1060,1 +1113,1 @@\n-          value = kelem->multi_allocate(rank, dims, CHECK);\n+          value = kelem->multi_allocate(rank, dims, CHECK_(true));\n@@ -1063,1 +1116,1 @@\n-            value = oopFactory::new_byteArray(length, CHECK);\n+            value = oopFactory::new_byteArray(length, CHECK_(true));\n@@ -1065,1 +1118,1 @@\n-            value = oopFactory::new_boolArray(length, CHECK);\n+            value = oopFactory::new_boolArray(length, CHECK_(true));\n@@ -1067,1 +1120,1 @@\n-            value = oopFactory::new_charArray(length, CHECK);\n+            value = oopFactory::new_charArray(length, CHECK_(true));\n@@ -1069,1 +1122,1 @@\n-            value = oopFactory::new_shortArray(length, CHECK);\n+            value = oopFactory::new_shortArray(length, CHECK_(true));\n@@ -1071,1 +1124,1 @@\n-            value = oopFactory::new_floatArray(length, CHECK);\n+            value = oopFactory::new_floatArray(length, CHECK_(true));\n@@ -1073,1 +1126,1 @@\n-            value = oopFactory::new_doubleArray(length, CHECK);\n+            value = oopFactory::new_doubleArray(length, CHECK_(true));\n@@ -1075,1 +1128,1 @@\n-            value = oopFactory::new_intArray(length, CHECK);\n+            value = oopFactory::new_intArray(length, CHECK_(true));\n@@ -1077,1 +1130,1 @@\n-            value = oopFactory::new_longArray(length, CHECK);\n+            value = oopFactory::new_longArray(length, CHECK_(true));\n@@ -1080,1 +1133,2 @@\n-            Klass* actual_array_klass = parse_klass(CHECK);\n+            Klass* actual_array_klass = parse_klass(CHECK_(true));\n+            \/\/ TODO 8350865 I think we need to handle null-free\/flat arrays here\n@@ -1082,1 +1136,1 @@\n-            value = oopFactory::new_objArray(kelem, length, CHECK);\n+            value = oopFactory::new_objArray(kelem, length, CHECK_(true));\n@@ -1087,0 +1141,14 @@\n+        java_mirror->obj_field_put(fd->offset(), value);\n+        return true;\n+      }\n+    } else if (strcmp(field_signature, \"Ljava\/lang\/String;\") == 0) {\n+      const char* string_value = parse_escaped_string();\n+      Handle value = java_lang_String::create_from_str(string_value, CHECK_(true));\n+      java_mirror->obj_field_put(fd->offset(), value());\n+      return true;\n+    } else if (field_signature[0] == JVM_SIGNATURE_CLASS) {\n+      const char* instance = parse_escaped_string();\n+      oop value = nullptr;\n+      if (instance != nullptr) {\n+        Klass* k = resolve_klass(instance, CHECK_(true));\n+        value = InstanceKlass::cast(k)->allocate_instance(CHECK_(true));\n@@ -1088,0 +1156,76 @@\n+      java_mirror->obj_field_put(fd->offset(), value);\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  \/\/ Initialize a class and fill in the value for a static field.\n+  \/\/ This is useful when the compile was dependent on the value of\n+  \/\/ static fields but it's impossible to properly rerun the static\n+  \/\/ initializer.\n+  void process_staticfield(TRAPS) {\n+    InstanceKlass* k = (InstanceKlass *)parse_klass(CHECK);\n+\n+    if (k == nullptr || ReplaySuppressInitializers == 0 ||\n+        (ReplaySuppressInitializers == 2 && k->class_loader() == nullptr)) {\n+        skip_remaining();\n+      return;\n+    }\n+\n+    assert(k->is_initialized(), \"must be\");\n+\n+    const char* field_name = parse_escaped_string();\n+    const char* field_signature = parse_string();\n+    fieldDescriptor fd;\n+    Symbol* name = SymbolTable::new_symbol(field_name);\n+    Symbol* sig = SymbolTable::new_symbol(field_signature);\n+    if (!k->find_local_field(name, sig, &fd) ||\n+        !fd.is_static() ||\n+        fd.has_initial_value()) {\n+      report_error(field_name);\n+      return;\n+    }\n+\n+    oop java_mirror = k->java_mirror();\n+    if (strcmp(field_signature, \"I\") == 0) {\n+      const char* string_value = parse_escaped_string();\n+      int value = atoi(string_value);\n+      java_mirror->int_field_put(fd.offset(), value);\n+    } else if (strcmp(field_signature, \"B\") == 0) {\n+      const char* string_value = parse_escaped_string();\n+      int value = atoi(string_value);\n+      java_mirror->byte_field_put(fd.offset(), value);\n+    } else if (strcmp(field_signature, \"C\") == 0) {\n+      const char* string_value = parse_escaped_string();\n+      int value = atoi(string_value);\n+      java_mirror->char_field_put(fd.offset(), value);\n+    } else if (strcmp(field_signature, \"S\") == 0) {\n+      const char* string_value = parse_escaped_string();\n+      int value = atoi(string_value);\n+      java_mirror->short_field_put(fd.offset(), value);\n+    } else if (strcmp(field_signature, \"Z\") == 0) {\n+      const char* string_value = parse_escaped_string();\n+      int value = atoi(string_value);\n+      java_mirror->bool_field_put(fd.offset(), value);\n+    } else if (strcmp(field_signature, \"J\") == 0) {\n+      const char* string_value = parse_escaped_string();\n+      jlong value;\n+      if (sscanf(string_value, JLONG_FORMAT, &value) != 1) {\n+        fprintf(stderr, \"Error parsing long: %s\\n\", string_value);\n+        return;\n+      }\n+      java_mirror->long_field_put(fd.offset(), value);\n+    } else if (strcmp(field_signature, \"F\") == 0) {\n+      const char* string_value = parse_escaped_string();\n+      float value = atof(string_value);\n+      java_mirror->float_field_put(fd.offset(), value);\n+    } else if (strcmp(field_signature, \"D\") == 0) {\n+      const char* string_value = parse_escaped_string();\n+      double value = atof(string_value);\n+      java_mirror->double_field_put(fd.offset(), value);\n+    } else if (fd.is_null_free_inline_type()) {\n+      Klass* kelem = resolve_klass(field_signature, CHECK);\n+      InlineKlass* vk = InlineKlass::cast(kelem);\n+      oop value = vk->allocate_instance(CHECK);\n+      InlineTypeFieldInitializer init_fields(value, this);\n+      vk->do_nonstatic_fields(&init_fields);\n@@ -1090,40 +1234,2 @@\n-      const char* string_value = parse_escaped_string();\n-      if (strcmp(field_signature, \"I\") == 0) {\n-        int value = atoi(string_value);\n-        java_mirror->int_field_put(fd.offset(), value);\n-      } else if (strcmp(field_signature, \"B\") == 0) {\n-        int value = atoi(string_value);\n-        java_mirror->byte_field_put(fd.offset(), value);\n-      } else if (strcmp(field_signature, \"C\") == 0) {\n-        int value = atoi(string_value);\n-        java_mirror->char_field_put(fd.offset(), value);\n-      } else if (strcmp(field_signature, \"S\") == 0) {\n-        int value = atoi(string_value);\n-        java_mirror->short_field_put(fd.offset(), value);\n-      } else if (strcmp(field_signature, \"Z\") == 0) {\n-        int value = atoi(string_value);\n-        java_mirror->bool_field_put(fd.offset(), value);\n-      } else if (strcmp(field_signature, \"J\") == 0) {\n-        jlong value;\n-        if (sscanf(string_value, JLONG_FORMAT, &value) != 1) {\n-          fprintf(stderr, \"Error parsing long: %s\\n\", string_value);\n-          return;\n-        }\n-        java_mirror->long_field_put(fd.offset(), value);\n-      } else if (strcmp(field_signature, \"F\") == 0) {\n-        float value = atof(string_value);\n-        java_mirror->float_field_put(fd.offset(), value);\n-      } else if (strcmp(field_signature, \"D\") == 0) {\n-        double value = atof(string_value);\n-        java_mirror->double_field_put(fd.offset(), value);\n-      } else if (strcmp(field_signature, \"Ljava\/lang\/String;\") == 0) {\n-        Handle value = java_lang_String::create_from_str(string_value, CHECK);\n-        java_mirror->obj_field_put(fd.offset(), value());\n-      } else if (field_signature[0] == JVM_SIGNATURE_CLASS) {\n-        oop value = nullptr;\n-        if (string_value != nullptr) {\n-          Klass* k = resolve_klass(string_value, CHECK);\n-          value = InstanceKlass::cast(k)->allocate_instance(CHECK);\n-        }\n-        java_mirror->obj_field_put(fd.offset(), value);\n-      } else {\n+      bool res = process_staticfield_reference(field_signature, java_mirror, &fd, CHECK);\n+      if (!res)  {\n","filename":"src\/hotspot\/share\/ci\/ciReplay.cpp","additions":190,"deletions":84,"binary":false,"changes":274,"status":"modified"},{"patch":"@@ -66,0 +66,1 @@\n+static_assert(!std::is_polymorphic<BufferedInlineTypeBlob>::value,   \"no virtual methods are allowed in code blobs\");\n@@ -91,0 +92,1 @@\n+      &BufferedInlineTypeBlob::_vpntr,\n@@ -310,2 +312,2 @@\n-BufferBlob::BufferBlob(const char* name, CodeBlobKind kind, CodeBuffer* cb, int size)\n-  : RuntimeBlob(name, kind, cb, size, sizeof(BufferBlob), CodeOffsets::frame_never_safe, 0, nullptr)\n+BufferBlob::BufferBlob(const char* name, CodeBlobKind kind, CodeBuffer* cb, int size, int header_size)\n+  : RuntimeBlob(name, kind, cb, size, header_size, CodeOffsets::frame_never_safe, 0, nullptr)\n@@ -323,1 +325,1 @@\n-    blob = new (size) BufferBlob(name, CodeBlobKind::Buffer, cb, size);\n+    blob = new (size) BufferBlob(name, CodeBlobKind::Buffer, cb, size, sizeof(BufferBlob));\n@@ -339,0 +341,4 @@\n+BufferBlob::BufferBlob(const char* name, CodeBlobKind kind, CodeBuffer* cb, int size, int frame_complete, int frame_size, OopMapSet* oop_maps, bool caller_must_gc_arguments)\n+  : RuntimeBlob(name, kind, cb, size, sizeof(BufferBlob), frame_complete, frame_size, oop_maps, caller_must_gc_arguments)\n+{}\n+\n@@ -343,2 +349,2 @@\n-AdapterBlob::AdapterBlob(int size, CodeBuffer* cb) :\n-  BufferBlob(\"I2C\/C2I adapters\", CodeBlobKind::Adapter, cb, size) {\n+AdapterBlob::AdapterBlob(int size, CodeBuffer* cb, int frame_complete, int frame_size, OopMapSet* oop_maps, bool caller_must_gc_arguments) :\n+  BufferBlob(\"I2C\/C2I adapters\", CodeBlobKind::Adapter, cb, size, frame_complete, frame_size, oop_maps, caller_must_gc_arguments) {\n@@ -348,1 +354,1 @@\n-AdapterBlob* AdapterBlob::create(CodeBuffer* cb) {\n+AdapterBlob* AdapterBlob::create(CodeBuffer* cb, int frame_complete, int frame_size, OopMapSet* oop_maps, bool caller_must_gc_arguments) {\n@@ -357,1 +363,1 @@\n-    blob = new (size) AdapterBlob(size, cb);\n+    blob = new (size) AdapterBlob(size, cb, frame_complete, frame_size, oop_maps, caller_must_gc_arguments);\n@@ -435,0 +441,25 @@\n+  return blob;\n+}\n+\n+\/\/----------------------------------------------------------------------------------------------------\n+\/\/ Implementation of BufferedInlineTypeBlob\n+BufferedInlineTypeBlob::BufferedInlineTypeBlob(int size, CodeBuffer* cb, int pack_fields_off, int pack_fields_jobject_off, int unpack_fields_off) :\n+  BufferBlob(\"buffered inline type\", CodeBlobKind::BufferedInlineType, cb, size, sizeof(BufferedInlineTypeBlob)),\n+  _pack_fields_off(pack_fields_off),\n+  _pack_fields_jobject_off(pack_fields_jobject_off),\n+  _unpack_fields_off(unpack_fields_off) {\n+  CodeCache::commit(this);\n+}\n+\n+BufferedInlineTypeBlob* BufferedInlineTypeBlob::create(CodeBuffer* cb, int pack_fields_off, int pack_fields_jobject_off, int unpack_fields_off) {\n+  ThreadInVMfromUnknown __tiv;  \/\/ get to VM state in case we block on CodeCache_lock\n+\n+  BufferedInlineTypeBlob* blob = nullptr;\n+  unsigned int size = CodeBlob::allocation_size(cb, sizeof(BufferedInlineTypeBlob));\n+  {\n+    MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+    blob = new (size) BufferedInlineTypeBlob(size, cb, pack_fields_off, pack_fields_jobject_off, unpack_fields_off);\n+  }\n+  \/\/ Track memory usage statistic after releasing CodeCache_lock\n+  MemoryService::track_code_cache_memory_usage();\n+\n","filename":"src\/hotspot\/share\/code\/codeBlob.cpp","additions":38,"deletions":7,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -61,0 +61,1 @@\n+\/\/    BufferedInlineTypeBlob   : used for pack\/unpack handlers\n@@ -86,0 +87,1 @@\n+  BufferedInlineType,\n@@ -185,0 +187,1 @@\n+  bool is_buffered_inline_type_blob() const   { return _kind == CodeBlobKind::BufferedInlineType; }\n@@ -329,0 +332,1 @@\n+  friend class BufferedInlineTypeBlob;\n@@ -335,1 +339,2 @@\n-  BufferBlob(const char* name, CodeBlobKind kind, CodeBuffer* cb, int size);\n+  BufferBlob(const char* name, CodeBlobKind kind, CodeBuffer* cb, int size, int header_size);\n+  BufferBlob(const char* name, CodeBlobKind kind, CodeBuffer* cb, int size, int frame_complete, int frame_size, OopMapSet* oop_maps, bool caller_must_gc_arguments = false);\n@@ -367,1 +372,1 @@\n-  AdapterBlob(int size, CodeBuffer* cb);\n+  AdapterBlob(int size, CodeBuffer* cb, int frame_complete, int frame_size, OopMapSet* oop_maps, bool caller_must_gc_arguments = false);\n@@ -371,1 +376,7 @@\n-  static AdapterBlob* create(CodeBuffer* cb);\n+  static AdapterBlob* create(CodeBuffer* cb,\n+                             int frame_complete,\n+                             int frame_size,\n+                             OopMapSet* oop_maps,\n+                             bool caller_must_gc_arguments = false);\n+\n+  bool caller_must_gc_arguments(JavaThread* thread) const { return true; }\n@@ -398,0 +409,19 @@\n+\/\/----------------------------------------------------------------------------------------------------\n+\/\/ BufferedInlineTypeBlob : used for pack\/unpack handlers\n+\n+class BufferedInlineTypeBlob: public BufferBlob {\n+private:\n+  const int _pack_fields_off;\n+  const int _pack_fields_jobject_off;\n+  const int _unpack_fields_off;\n+\n+  BufferedInlineTypeBlob(int size, CodeBuffer* cb, int pack_fields_off, int pack_fields_jobject_off, int unpack_fields_off);\n+\n+public:\n+  \/\/ Creation\n+  static BufferedInlineTypeBlob* create(CodeBuffer* cb, int pack_fields_off, int pack_fields_jobject_off, int unpack_fields_off);\n+\n+  address pack_fields() const { return code_begin() + _pack_fields_off; }\n+  address pack_fields_jobject() const { return code_begin() + _pack_fields_jobject_off; }\n+  address unpack_fields() const { return code_begin() + _unpack_fields_off; }\n+};\n","filename":"src\/hotspot\/share\/code\/codeBlob.hpp","additions":33,"deletions":3,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -728,0 +728,11 @@\n+\n+      \/\/ If inline types are passed as fields, use the extended signature\n+      \/\/ which contains the types of all (oop) fields of the inline type.\n+      if (is_compiled_by_c2() && callee->has_scalarized_args()) {\n+        const GrowableArray<SigEntry>* sig = callee->adapter()->get_sig_cc();\n+        assert(sig != nullptr, \"sig should never be null\");\n+        TempNewSymbol tmp_sig = SigEntry::create_symbol(sig);\n+        has_receiver = false; \/\/ The extended signature contains the receiver type\n+        fr.oops_compiled_arguments_do(tmp_sig, has_receiver, has_appendix, reg_map, f);\n+        return;\n+      }\n@@ -1262,0 +1273,4 @@\n+  _inline_entry_point             = entry_point();\n+  _verified_inline_entry_point    = verified_entry_point();\n+  _verified_inline_ro_entry_point = verified_entry_point();\n+\n@@ -1301,1 +1316,1 @@\n-\n+    assert(!method->has_scalarized_args(), \"scalarized native wrappers not supported yet\");\n@@ -1502,0 +1517,3 @@\n+    _inline_entry_point             = code_begin() + offsets->value(CodeOffsets::Inline_Entry);\n+    _verified_inline_entry_point    = code_begin() + offsets->value(CodeOffsets::Verified_Inline_Entry);\n+    _verified_inline_ro_entry_point = code_begin() + offsets->value(CodeOffsets::Verified_Inline_Entry_RO);\n@@ -3705,0 +3723,1 @@\n+  if (pos == inline_entry_point())                                      label = \"[Inline Entry Point]\";\n@@ -3706,0 +3725,2 @@\n+  if (pos == verified_inline_entry_point())                             label = \"[Verified Inline Entry Point]\";\n+  if (pos == verified_inline_ro_entry_point())                          label = \"[Verified Inline Entry Point (RO)]\";\n@@ -3715,0 +3736,10 @@\n+static int maybe_print_entry_label(outputStream* stream, address pos, address entry, const char* label) {\n+  if (pos == entry) {\n+    stream->bol();\n+    stream->print_cr(\"%s\", label);\n+    return 1;\n+  } else {\n+    return 0;\n+  }\n+}\n+\n@@ -3717,33 +3748,12 @@\n-    const char* label = nmethod_section_label(block_begin);\n-    if (label != nullptr) {\n-      stream->bol();\n-      stream->print_cr(\"%s\", label);\n-    }\n-  }\n-\n-  if (block_begin == entry_point()) {\n-    Method* m = method();\n-    if (m != nullptr) {\n-      stream->print(\"  # \");\n-      m->print_value_on(stream);\n-      stream->cr();\n-    }\n-    if (m != nullptr && !is_osr_method()) {\n-      ResourceMark rm;\n-      int sizeargs = m->size_of_parameters();\n-      BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, sizeargs);\n-      VMRegPair* regs   = NEW_RESOURCE_ARRAY(VMRegPair, sizeargs);\n-      {\n-        int sig_index = 0;\n-        if (!m->is_static())\n-          sig_bt[sig_index++] = T_OBJECT; \/\/ 'this'\n-        for (SignatureStream ss(m->signature()); !ss.at_return_type(); ss.next()) {\n-          BasicType t = ss.type();\n-          sig_bt[sig_index++] = t;\n-          if (type2size[t] == 2) {\n-            sig_bt[sig_index++] = T_VOID;\n-          } else {\n-            assert(type2size[t] == 1, \"size is 1 or 2\");\n-          }\n-        }\n-        assert(sig_index == sizeargs, \"\");\n+    int n = 0;\n+    \/\/ Multiple entry points may be at the same position. Print them all.\n+    n += maybe_print_entry_label(stream, block_begin, entry_point(),                    \"[Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, inline_entry_point(),             \"[Inline Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, verified_entry_point(),           \"[Verified Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, verified_inline_entry_point(),    \"[Verified Inline Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, verified_inline_ro_entry_point(), \"[Verified Inline Entry Point (RO)]\");\n+    if (n == 0) {\n+      const char* label = nmethod_section_label(block_begin);\n+      if (label != nullptr) {\n+        stream->bol();\n+        stream->print_cr(\"%s\", label);\n@@ -3751,54 +3761,63 @@\n-      const char* spname = \"sp\"; \/\/ make arch-specific?\n-      SharedRuntime::java_calling_convention(sig_bt, regs, sizeargs);\n-      int stack_slot_offset = this->frame_size() * wordSize;\n-      int tab1 = 14, tab2 = 24;\n-      int sig_index = 0;\n-      int arg_index = (m->is_static() ? 0 : -1);\n-      bool did_old_sp = false;\n-      for (SignatureStream ss(m->signature()); !ss.at_return_type(); ) {\n-        bool at_this = (arg_index == -1);\n-        bool at_old_sp = false;\n-        BasicType t = (at_this ? T_OBJECT : ss.type());\n-        assert(t == sig_bt[sig_index], \"sigs in sync\");\n-        if (at_this)\n-          stream->print(\"  # this: \");\n-        else\n-          stream->print(\"  # parm%d: \", arg_index);\n-        stream->move_to(tab1);\n-        VMReg fst = regs[sig_index].first();\n-        VMReg snd = regs[sig_index].second();\n-        if (fst->is_reg()) {\n-          stream->print(\"%s\", fst->name());\n-          if (snd->is_valid())  {\n-            stream->print(\":%s\", snd->name());\n-          }\n-        } else if (fst->is_stack()) {\n-          int offset = fst->reg2stack() * VMRegImpl::stack_slot_size + stack_slot_offset;\n-          if (offset == stack_slot_offset)  at_old_sp = true;\n-          stream->print(\"[%s+0x%x]\", spname, offset);\n-        } else {\n-          stream->print(\"reg%d:%d??\", (int)(intptr_t)fst, (int)(intptr_t)snd);\n-        }\n-        stream->print(\" \");\n-        stream->move_to(tab2);\n-        stream->print(\"= \");\n-        if (at_this) {\n-          m->method_holder()->print_value_on(stream);\n-        } else {\n-          bool did_name = false;\n-          if (!at_this && ss.is_reference()) {\n-            Symbol* name = ss.as_symbol();\n-            name->print_value_on(stream);\n-            did_name = true;\n-          }\n-          if (!did_name)\n-            stream->print(\"%s\", type2name(t));\n-        }\n-        if (at_old_sp) {\n-          stream->print(\"  (%s of caller)\", spname);\n-          did_old_sp = true;\n-        }\n-        stream->cr();\n-        sig_index += type2size[t];\n-        arg_index += 1;\n-        if (!at_this)  ss.next();\n+    }\n+  }\n+\n+  Method* m = method();\n+  if (m == nullptr || is_osr_method()) {\n+    return;\n+  }\n+\n+  \/\/ Print the name of the method (only once)\n+  address low = MIN4(entry_point(), verified_entry_point(), verified_inline_entry_point(), verified_inline_ro_entry_point());\n+  low = MIN2(low, inline_entry_point());\n+  assert(low != 0, \"sanity\");\n+  if (block_begin == low) {\n+    stream->print(\"  # \");\n+    m->print_value_on(stream);\n+    stream->cr();\n+  }\n+\n+  \/\/ Print the arguments for the 3 types of verified entry points\n+  CompiledEntrySignature ces(m);\n+  ces.compute_calling_conventions(false);\n+  const GrowableArray<SigEntry>* sig_cc;\n+  const VMRegPair* regs;\n+  if (block_begin == verified_entry_point()) {\n+    sig_cc = ces.sig_cc();\n+    regs = ces.regs_cc();\n+  } else if (block_begin == verified_inline_entry_point()) {\n+    sig_cc = ces.sig();\n+    regs = ces.regs();\n+  } else if (block_begin == verified_inline_ro_entry_point()) {\n+    sig_cc = ces.sig_cc_ro();\n+    regs = ces.regs_cc_ro();\n+  } else {\n+    return;\n+  }\n+\n+  bool has_this = !m->is_static();\n+  if (ces.has_inline_recv() && block_begin == verified_entry_point()) {\n+    \/\/ <this> argument is scalarized for verified_entry_point()\n+    has_this = false;\n+  }\n+  const char* spname = \"sp\"; \/\/ make arch-specific?\n+  int stack_slot_offset = this->frame_size() * wordSize;\n+  int tab1 = 14, tab2 = 24;\n+  int sig_index = 0;\n+  int arg_index = has_this ? -1 : 0;\n+  bool did_old_sp = false;\n+  for (ExtendedSignature sig = ExtendedSignature(sig_cc, SigEntryFilter()); !sig.at_end(); ++sig) {\n+    bool at_this = (arg_index == -1);\n+    bool at_old_sp = false;\n+    BasicType t = (*sig)._bt;\n+    if (at_this) {\n+      stream->print(\"  # this: \");\n+    } else {\n+      stream->print(\"  # parm%d: \", arg_index);\n+    }\n+    stream->move_to(tab1);\n+    VMReg fst = regs[sig_index].first();\n+    VMReg snd = regs[sig_index].second();\n+    if (fst->is_reg()) {\n+      stream->print(\"%s\", fst->name());\n+      if (snd->is_valid())  {\n+        stream->print(\":%s\", snd->name());\n@@ -3806,6 +3825,24 @@\n-      if (!did_old_sp) {\n-        stream->print(\"  # \");\n-        stream->move_to(tab1);\n-        stream->print(\"[%s+0x%x]\", spname, stack_slot_offset);\n-        stream->print(\"  (%s of caller)\", spname);\n-        stream->cr();\n+    } else if (fst->is_stack()) {\n+      int offset = fst->reg2stack() * VMRegImpl::stack_slot_size + stack_slot_offset;\n+      if (offset == stack_slot_offset)  at_old_sp = true;\n+      stream->print(\"[%s+0x%x]\", spname, offset);\n+    } else {\n+      stream->print(\"reg%d:%d??\", (int)(intptr_t)fst, (int)(intptr_t)snd);\n+    }\n+    stream->print(\" \");\n+    stream->move_to(tab2);\n+    stream->print(\"= \");\n+    if (at_this) {\n+      m->method_holder()->print_value_on(stream);\n+    } else {\n+      bool did_name = false;\n+      if (is_reference_type(t)) {\n+        Symbol* name = (*sig)._symbol;\n+        name->print_value_on(stream);\n+        did_name = true;\n+      }\n+      if (!did_name)\n+        stream->print(\"%s\", type2name(t));\n+      \/\/ If the entry has a non-default sort_offset, it must be a null marker\n+      if ((*sig)._sort_offset != (*sig)._offset) {\n+        stream->print(\" (null marker)\");\n@@ -3814,0 +3851,14 @@\n+    if (at_old_sp) {\n+      stream->print(\"  (%s of caller)\", spname);\n+      did_old_sp = true;\n+    }\n+    stream->cr();\n+    sig_index += type2size[t];\n+    arg_index += 1;\n+  }\n+  if (!did_old_sp) {\n+    stream->print(\"  # \");\n+    stream->move_to(tab1);\n+    stream->print(\"[%s+0x%x]\", spname, stack_slot_offset);\n+    stream->print(\"  (%s of caller)\", spname);\n+    stream->cr();\n@@ -3937,1 +3988,1 @@\n-      st->print(\" {reexecute=%d rethrow=%d return_oop=%d}\", sd->should_reexecute(), sd->rethrow_exception(), sd->return_oop());\n+      st->print(\" {reexecute=%d rethrow=%d return_oop=%d return_scalarized=%d}\", sd->should_reexecute(), sd->rethrow_exception(), sd->return_oop(), sd->return_scalarized());\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":146,"deletions":95,"binary":false,"changes":241,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"compiler\/compilerDefinitions.hpp\"\n@@ -216,0 +217,4 @@\n+  \/\/ TODO: can these be uint16_t, seem rely on -1 CodeOffset, can change later...\n+  address _inline_entry_point;              \/\/ inline type entry point (unpack all inline type args) with class check\n+  address _verified_inline_entry_point;     \/\/ inline type entry point (unpack all inline type args) without class check\n+  address _verified_inline_ro_entry_point;  \/\/ inline type entry point (unpack receiver only) without class check\n@@ -608,0 +613,3 @@\n+  address inline_entry_point() const              { return _inline_entry_point; }             \/\/ inline type entry point (unpack all inline type args)\n+  address verified_inline_entry_point() const     { return _verified_inline_entry_point; }    \/\/ inline type entry point (unpack all inline type args) without class check\n+  address verified_inline_ro_entry_point() const  { return _verified_inline_ro_entry_point; } \/\/ inline type entry point (only unpack receiver) without class check\n@@ -677,0 +685,10 @@\n+  bool  needs_stack_repair() const {\n+    if (is_compiled_by_c1()) {\n+      return method()->c1_needs_stack_repair();\n+    } else if (is_compiled_by_c2()) {\n+      return method()->c2_needs_stack_repair();\n+    } else {\n+      return false;\n+    }\n+  }\n+\n","filename":"src\/hotspot\/share\/code\/nmethod.hpp","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"classfile\/vmSymbols.hpp\"\n@@ -29,0 +30,2 @@\n+#include \"memory\/resourceArea.hpp\"\n+#include \"oops\/objArrayKlass.inline.hpp\"\n@@ -54,0 +57,27 @@\n+void BarrierSet::throw_array_null_pointer_store_exception(arrayOop src, arrayOop dst, TRAPS) {\n+  ResourceMark rm(THREAD);\n+  Klass* bound = ObjArrayKlass::cast(dst->klass())->element_klass();\n+  stringStream ss;\n+  ss.print(\"arraycopy: can not copy null values into %s[]\",\n+           bound->external_name());\n+  THROW_MSG(vmSymbols::java_lang_NullPointerException(), ss.as_string());\n+}\n+\n+void BarrierSet::throw_array_store_exception(arrayOop src, arrayOop dst, TRAPS) {\n+  ResourceMark rm(THREAD);\n+  Klass* bound = ObjArrayKlass::cast(dst->klass())->element_klass();\n+  Klass* stype = ObjArrayKlass::cast(src->klass())->element_klass();\n+  stringStream ss;\n+  if (!bound->is_subtype_of(stype)) {\n+    ss.print(\"arraycopy: type mismatch: can not copy %s[] into %s[]\",\n+             stype->external_name(), bound->external_name());\n+  } else {\n+    \/\/ oop_arraycopy should return the index in the source array that\n+    \/\/ contains the problematic oop.\n+    ss.print(\"arraycopy: element type mismatch: can not cast one of the elements\"\n+             \" of %s[] to the type of the destination array, %s\",\n+             stype->external_name(), bound->external_name());\n+  }\n+  THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), ss.as_string());\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/barrierSet.cpp","additions":30,"deletions":0,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -899,1 +899,1 @@\n-    Node* offset = phase->igvn().MakeConX(in_bytes(ShenandoahThreadLocalData::gc_state_offset()));\n+    Node* offset = phase->MakeConX(in_bytes(ShenandoahThreadLocalData::gc_state_offset()));\n@@ -947,1 +947,1 @@\n-    phase->igvn().replace_node(ac, call);\n+    phase->replace_node(ac, call);\n@@ -967,1 +967,1 @@\n-void ShenandoahBarrierSetC2::eliminate_gc_barrier(PhaseMacroExpand* macro, Node* node) const {\n+void ShenandoahBarrierSetC2::eliminate_gc_barrier(PhaseIterGVN* igvn, Node* node) const {\n@@ -969,1 +969,1 @@\n-    shenandoah_eliminate_wb_pre(node, &macro->igvn());\n+    shenandoah_eliminate_wb_pre(node, igvn);\n@@ -980,1 +980,1 @@\n-        macro->replace_node(mem, macro->intcon(0));\n+        igvn->replace_node(mem, igvn->intcon(0));\n@@ -984,1 +984,1 @@\n-      macro->replace_node(mem, mem->in(MemNode::Memory));\n+      igvn->replace_node(mem, mem->in(MemNode::Memory));\n@@ -1116,1 +1116,1 @@\n-    uint cnt = ShenandoahBarrierSetC2::write_ref_field_pre_Type()->domain()->cnt();\n+    uint cnt = ShenandoahBarrierSetC2::write_ref_field_pre_Type()->domain_sig()->cnt();\n@@ -1202,1 +1202,1 @@\n-        uint cnt = ShenandoahBarrierSetC2::write_ref_field_pre_Type()->domain()->cnt();\n+        uint cnt = ShenandoahBarrierSetC2::write_ref_field_pre_Type()->domain_sig()->cnt();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/c2\/shenandoahBarrierSetC2.cpp","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -129,1 +129,1 @@\n-  virtual void eliminate_gc_barrier(PhaseMacroExpand* macro, Node* node) const;\n+  virtual void eliminate_gc_barrier(PhaseIterGVN* igvn, Node* node) const;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/c2\/shenandoahBarrierSetC2.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -371,1 +371,1 @@\n-bool ShenandoahBarrierSet::AccessBarrier<decorators, BarrierSetT>::oop_arraycopy_in_heap(arrayOop src_obj, size_t src_offset_in_bytes, T* src_raw,\n+void ShenandoahBarrierSet::AccessBarrier<decorators, BarrierSetT>::oop_arraycopy_in_heap(arrayOop src_obj, size_t src_offset_in_bytes, T* src_raw,\n@@ -378,2 +378,4 @@\n-  bs->arraycopy_barrier(src, dst, length);\n-  bool result = Raw::oop_arraycopy_in_heap(src_obj, src_offset_in_bytes, src_raw, dst_obj, dst_offset_in_bytes, dst_raw, length);\n+  bs->arraycopy_barrier(arrayOopDesc::obj_offset_to_raw(src_obj, src_offset_in_bytes, src_raw),\n+                        arrayOopDesc::obj_offset_to_raw(dst_obj, dst_offset_in_bytes, dst_raw),\n+                        length);\n+  Raw::oop_arraycopy_in_heap(src_obj, src_offset_in_bytes, src_raw, dst_obj, dst_offset_in_bytes, dst_raw, length);\n@@ -383,1 +385,0 @@\n-  return result;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahBarrierSet.inline.hpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"classfile\/systemDictionary.hpp\"\n@@ -47,0 +48,3 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/flatArrayOop.inline.hpp\"\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -79,0 +83,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -226,0 +231,113 @@\n+JRT_ENTRY(void, InterpreterRuntime::uninitialized_static_inline_type_field(JavaThread* current, oopDesc* mirror, ResolvedFieldEntry* entry))\n+  \/\/ The interpreter tries to access an inline static field that has not been initialized.\n+  \/\/ This situation can happen in different scenarios:\n+  \/\/   1 - if the load or initialization of the field failed during step 8 of\n+  \/\/       the initialization of the holder of the field, in this case the access to the field\n+  \/\/       must fail\n+  \/\/   2 - it can also happen when the initialization of the holder class triggered the initialization of\n+  \/\/       another class which accesses this field in its static initializer, in this case the\n+  \/\/       access must succeed to allow circularity\n+  \/\/ The code below tries to load and initialize the field's class again before returning the default value.\n+  \/\/ If the field was not initialized because of an error, an exception should be thrown.\n+  \/\/ If the class is being initialized, the default value is returned.\n+  assert(entry->is_valid(), \"Invalid ResolvedFieldEntry\");\n+  instanceHandle mirror_h(THREAD, (instanceOop)mirror);\n+  InstanceKlass* klass = entry->field_holder();\n+  u2 index = entry->field_index();\n+  assert(klass == java_lang_Class::as_Klass(mirror), \"Not the field holder klass\");\n+  assert(klass->field_is_null_free_inline_type(index), \"Sanity check\");\n+  if (klass->is_being_initialized() && klass->is_reentrant_initialization(THREAD)) {\n+    int offset = klass->field_offset(index);\n+    Klass* field_k = klass->get_inline_type_field_klass_or_null(index);\n+    if (field_k == nullptr) {\n+      field_k = SystemDictionary::resolve_or_fail(klass->field_signature(index)->fundamental_name(THREAD),\n+          Handle(THREAD, klass->class_loader()),\n+          true, CHECK);\n+      assert(field_k != nullptr, \"Should have been loaded or an exception thrown above\");\n+      if (!field_k->is_inline_klass()) {\n+        THROW_MSG(vmSymbols::java_lang_IncompatibleClassChangeError(),\n+                  err_msg(\"class %s expects class %s to be a concrete value class but it is not\",\n+                  klass->name()->as_C_string(), field_k->external_name()));\n+      }\n+      InlineLayoutInfo* li = klass->inline_layout_info_adr(index);\n+      li->set_klass(InlineKlass::cast(field_k));\n+      li->set_kind(LayoutKind::REFERENCE);\n+    }\n+    field_k->initialize(CHECK);\n+    oop defaultvalue = InlineKlass::cast(field_k)->default_value();\n+    \/\/ It is safe to initialize the static field because 1) the current thread is the initializing thread\n+    \/\/ and is the only one that can access it, and 2) the field is actually not initialized (i.e. null)\n+    \/\/ otherwise the JVM should not be executing this code.\n+    mirror_h()->obj_field_put(offset, defaultvalue);\n+    current->set_vm_result(defaultvalue);\n+  } else {\n+    assert(klass->is_in_error_state(), \"If not initializing, initialization must have failed to get there\");\n+    ResourceMark rm(THREAD);\n+    const char* desc = \"Could not initialize class \";\n+    const char* className = klass->external_name();\n+    size_t msglen = strlen(desc) + strlen(className) + 1;\n+    char* message = NEW_RESOURCE_ARRAY(char, msglen);\n+    if (nullptr == message) {\n+      \/\/ Out of memory: can't create detailed error message\n+      THROW_MSG(vmSymbols::java_lang_NoClassDefFoundError(), className);\n+    } else {\n+      jio_snprintf(message, msglen, \"%s%s\", desc, className);\n+      THROW_MSG(vmSymbols::java_lang_NoClassDefFoundError(), message);\n+    }\n+  }\n+JRT_END\n+\n+JRT_ENTRY(void, InterpreterRuntime::read_flat_field(JavaThread* current, oopDesc* obj, ResolvedFieldEntry* entry))\n+  assert(oopDesc::is_oop(obj), \"Sanity check\");\n+  Handle obj_h(THREAD, obj);\n+\n+  InstanceKlass* holder = InstanceKlass::cast(entry->field_holder());\n+  assert(entry->field_holder()->field_is_flat(entry->field_index()), \"Sanity check\");\n+\n+  InlineLayoutInfo* layout_info = holder->inline_layout_info_adr(entry->field_index());\n+  InlineKlass* field_vklass = layout_info->klass();\n+\n+#ifdef ASSERT\n+  fieldDescriptor fd;\n+  bool found = holder->find_field_from_offset(entry->field_offset(), false, &fd);\n+  assert(found, \"Field not found\");\n+  assert(fd.is_flat(), \"Field must be flat\");\n+#endif \/\/ ASSERT\n+\n+  oop res = field_vklass->read_payload_from_addr(obj_h(), entry->field_offset(), layout_info->kind(), CHECK);\n+  current->set_vm_result(res);\n+JRT_END\n+\n+JRT_ENTRY(void, InterpreterRuntime::read_nullable_flat_field(JavaThread* current, oopDesc* obj, ResolvedFieldEntry* entry))\n+  assert(oopDesc::is_oop(obj), \"Sanity check\");\n+  assert(entry->has_null_marker(), \"Otherwise should not get there\");\n+  Handle obj_h(THREAD, obj);\n+\n+  InstanceKlass* holder = entry->field_holder();\n+  int field_index = entry->field_index();\n+  InlineLayoutInfo* li= holder->inline_layout_info_adr(field_index);\n+\n+#ifdef ASSERT\n+  fieldDescriptor fd;\n+  bool found = holder->find_field_from_offset(entry->field_offset(), false, &fd);\n+  assert(found, \"Field not found\");\n+  assert(fd.is_flat(), \"Field must be flat\");\n+#endif \/\/ ASSERT\n+\n+  InlineKlass* field_vklass = InlineKlass::cast(li->klass());\n+  oop res = field_vklass->read_payload_from_addr(obj_h(), entry->field_offset(), li->kind(), CHECK);\n+  current->set_vm_result(res);\n+\n+JRT_END\n+\n+JRT_ENTRY(void, InterpreterRuntime::write_nullable_flat_field(JavaThread* current, oopDesc* obj, oopDesc* value, ResolvedFieldEntry* entry))\n+  assert(oopDesc::is_oop(obj), \"Sanity check\");\n+  Handle obj_h(THREAD, obj);\n+  assert(value == nullptr || oopDesc::is_oop(value), \"Sanity check\");\n+  Handle val_h(THREAD, value);\n+\n+  InstanceKlass* holder = entry->field_holder();\n+  InlineLayoutInfo* li = holder->inline_layout_info_adr(entry->field_index());\n+  InlineKlass* vk = li->klass();\n+  vk->write_value_to_addr(val_h(), ((char*)(oopDesc*)obj_h()) + entry->field_offset(), li->kind(), true, CHECK);\n+JRT_END\n@@ -235,1 +353,1 @@\n-  objArrayOop obj = oopFactory::new_objArray(klass, size, CHECK);\n+  arrayOop obj = oopFactory::new_objArray(klass, size, CHECK);\n@@ -239,0 +357,12 @@\n+JRT_ENTRY(void, InterpreterRuntime::flat_array_load(JavaThread* current, arrayOopDesc* array, int index))\n+  assert(array->is_flatArray(), \"Must be\");\n+  flatArrayOop farray = (flatArrayOop)array;\n+  oop res = farray->read_value_from_flat_array(index, CHECK);\n+  current->set_vm_result(res);\n+JRT_END\n+\n+JRT_ENTRY(void, InterpreterRuntime::flat_array_store(JavaThread* current, oopDesc* val, arrayOopDesc* array, int index))\n+  assert(array->is_flatArray(), \"Must be\");\n+  flatArrayOop farray = (flatArrayOop)array;\n+  farray->write_value_to_flat_array(val, index, CHECK);\n+JRT_END\n@@ -244,2 +374,2 @@\n-  int          i = last_frame.get_index_u2(Bytecodes::_multianewarray);\n-  Klass* klass   = constants->klass_at(i, CHECK);\n+  int i = last_frame.get_index_u2(Bytecodes::_multianewarray);\n+  Klass* klass = constants->klass_at(i, CHECK);\n@@ -274,0 +404,24 @@\n+JRT_ENTRY(jboolean, InterpreterRuntime::is_substitutable(JavaThread* current, oopDesc* aobj, oopDesc* bobj))\n+  assert(oopDesc::is_oop(aobj) && oopDesc::is_oop(bobj), \"must be valid oops\");\n+\n+  Handle ha(THREAD, aobj);\n+  Handle hb(THREAD, bobj);\n+  JavaValue result(T_BOOLEAN);\n+  JavaCallArguments args;\n+  args.push_oop(ha);\n+  args.push_oop(hb);\n+  methodHandle method(current, Universe::is_substitutable_method());\n+  method->method_holder()->initialize(CHECK_false); \/\/ Ensure class ValueObjectMethods is initialized\n+  JavaCalls::call(&result, method, &args, THREAD);\n+  if (HAS_PENDING_EXCEPTION) {\n+    \/\/ Something really bad happened because isSubstitutable() should not throw exceptions\n+    \/\/ If it is an error, just let it propagate\n+    \/\/ If it is an exception, wrap it into an InternalError\n+    if (!PENDING_EXCEPTION->is_a(vmClasses::Error_klass())) {\n+      Handle e(THREAD, PENDING_EXCEPTION);\n+      CLEAR_PENDING_EXCEPTION;\n+      THROW_MSG_CAUSE_(vmSymbols::java_lang_InternalError(), \"Internal error in substitutability test\", e, false);\n+    }\n+  }\n+  return result.get_jboolean();\n+JRT_END\n@@ -617,0 +771,4 @@\n+JRT_ENTRY(void, InterpreterRuntime::throw_InstantiationError(JavaThread* current))\n+  THROW(vmSymbols::java_lang_InstantiationError());\n+JRT_END\n+\n@@ -701,1 +859,5 @@\n-    get_code = ((is_static) ? Bytecodes::_getstatic : Bytecodes::_getfield);\n+    if (is_static) {\n+      get_code = Bytecodes::_getstatic;\n+    } else {\n+      get_code = Bytecodes::_getfield;\n+    }\n@@ -703,1 +865,1 @@\n-      put_code = ((is_static) ? Bytecodes::_putstatic : Bytecodes::_putfield);\n+        put_code = ((is_static) ? Bytecodes::_putstatic : Bytecodes::_putfield);\n@@ -708,1 +870,4 @@\n-  entry->set_flags(info.access_flags().is_final(), info.access_flags().is_volatile());\n+  entry->set_flags(info.access_flags().is_final(), info.access_flags().is_volatile(),\n+                   info.is_flat(), info.is_null_free_inline_type(),\n+                   info.has_null_marker());\n+\n@@ -755,1 +920,0 @@\n-\n@@ -760,1 +924,0 @@\n-\n@@ -775,0 +938,15 @@\n+JRT_ENTRY(void, InterpreterRuntime::throw_identity_exception(JavaThread* current, oopDesc* obj))\n+  Klass* klass = cast_to_oop(obj)->klass();\n+  ResourceMark rm(THREAD);\n+  const char* desc = \"Cannot synchronize on an instance of value class \";\n+  const char* className = klass->external_name();\n+  size_t msglen = strlen(desc) + strlen(className) + 1;\n+  char* message = NEW_RESOURCE_ARRAY(char, msglen);\n+  if (nullptr == message) {\n+    \/\/ Out of memory: can't create detailed error message\n+    THROW_MSG(vmSymbols::java_lang_IdentityException(), className);\n+  } else {\n+    jio_snprintf(message, msglen, \"%s%s\", desc, className);\n+    THROW_MSG(vmSymbols::java_lang_IdentityException(), message);\n+  }\n+JRT_END\n@@ -1184,0 +1362,1 @@\n+  assert(entry->is_valid(), \"Invalid ResolvedFieldEntry\");\n@@ -1191,0 +1370,1 @@\n+  bool is_flat = entry->is_flat();\n@@ -1199,1 +1379,1 @@\n-  jfieldID fid = jfieldIDWorkaround::to_jfieldID(field_holder, entry->field_offset(), is_static);\n+  jfieldID fid = jfieldIDWorkaround::to_jfieldID(field_holder, entry->field_offset(), is_static, is_flat);\n@@ -1207,0 +1387,1 @@\n+  assert(entry->is_valid(), \"Invalid ResolvedFieldEntry\");\n@@ -1228,0 +1409,1 @@\n+\n@@ -1229,0 +1411,1 @@\n+  bool is_flat = entry->is_flat();\n@@ -1231,1 +1414,1 @@\n-  jfieldID fid = jfieldIDWorkaround::to_jfieldID(ik, entry->field_offset(), is_static);\n+  jfieldID fid = jfieldIDWorkaround::to_jfieldID(ik, entry->field_offset(), is_static, is_flat);\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":193,"deletions":10,"binary":false,"changes":203,"status":"modified"},{"patch":"@@ -1603,1 +1603,1 @@\n-              Deoptimization::reassign_fields(vf->frame_pointer(), &reg_map, objects, realloc_failures, false);\n+              Deoptimization::reassign_fields(vf->frame_pointer(), &reg_map, objects, realloc_failures, false, CHECK_NULL);\n@@ -1854,1 +1854,1 @@\n-  Deoptimization::reassign_fields(fstAfterDeopt.current(), fstAfterDeopt.register_map(), objects, realloc_failures, false);\n+  Deoptimization::reassign_fields(fstAfterDeopt.current(), fstAfterDeopt.register_map(), objects, realloc_failures, false, THREAD);\n@@ -2182,1 +2182,1 @@\n-    if (m->is_object_initializer()) {\n+    if (m->is_object_constructor()) {\n@@ -2209,1 +2209,1 @@\n-    if (!m->is_object_initializer() && !m->is_static_initializer() && !m->is_overpass()) {\n+    if (!(m->is_object_constructor() || m->is_class_initializer()) && !m->is_overpass()) {\n@@ -2921,1 +2921,5 @@\n-  if (m->is_object_initializer()) {\n+  if (m->is_class_initializer()) {\n+      JVMCI_THROW_MSG_NULL(IllegalArgumentException,\n+          \"Cannot create java.lang.reflect.Method for class initializer\");\n+  }\n+  else if (m->is_object_constructor()) {\n@@ -2923,3 +2927,0 @@\n-  } else if (m->is_static_initializer()) {\n-    JVMCI_THROW_MSG_NULL(IllegalArgumentException,\n-        \"Cannot create java.lang.reflect.Method for class initializer\");\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.cpp","additions":9,"deletions":8,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -213,1 +213,1 @@\n-  nonstatic_field(InstanceKlass,               _misc_flags._flags,                            u2)                                    \\\n+  nonstatic_field(InstanceKlass,               _misc_flags._flags,                            u4)                                    \\\n@@ -692,0 +692,3 @@\n+  declare_constant(DataLayout::array_store_data_tag)                      \\\n+  declare_constant(DataLayout::array_load_data_tag)                       \\\n+  declare_constant(DataLayout::acmp_data_tag)                             \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -72,0 +72,1 @@\n+#include \"oops\/markWord.hpp\"\n@@ -76,0 +77,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -153,0 +155,5 @@\n+void InlineLayoutInfo::metaspace_pointers_do(MetaspaceClosure* it) {\n+  log_trace(cds)(\"Iter(InlineFieldInfo): %p\", this);\n+  it->push(&_klass);\n+}\n+\n@@ -174,0 +181,13 @@\n+bool InstanceKlass::field_is_null_free_inline_type(int index) const {\n+  return field(index).field_flags().is_null_free_inline_type();\n+}\n+\n+bool InstanceKlass::is_class_in_loadable_descriptors_attribute(Symbol* name) const {\n+  if (_loadable_descriptors == nullptr) return false;\n+  for (int i = 0; i < _loadable_descriptors->length(); i++) {\n+        Symbol* class_name = _constants->symbol_at(_loadable_descriptors->at(i));\n+        if (class_name == name) return true;\n+  }\n+  return false;\n+}\n+\n@@ -468,1 +488,2 @@\n-                                       parser.is_interface());\n+                                       parser.is_interface(),\n+                                       parser.is_inline_type());\n@@ -491,0 +512,3 @@\n+  } else if (parser.is_inline_type()) {\n+    \/\/ inline type\n+    ik = new (loader_data, size, use_class_space, THREAD) InlineKlass(parser);\n@@ -507,0 +531,6 @@\n+#ifdef ASSERT\n+  ik->bounds_check((address) ik->start_of_vtable(), false, size);\n+  ik->bounds_check((address) ik->start_of_itable(), false, size);\n+  ik->bounds_check((address) ik->end_of_itable(), true, size);\n+  ik->bounds_check((address) ik->end_of_nonstatic_oop_maps(), true, size);\n+#endif \/\/ASSERT\n@@ -510,0 +540,23 @@\n+#ifndef PRODUCT\n+bool InstanceKlass::bounds_check(address addr, bool edge_ok, intptr_t size_in_bytes) const {\n+  const char* bad = nullptr;\n+  address end = nullptr;\n+  if (addr < (address)this) {\n+    bad = \"before\";\n+  } else if (addr == (address)this) {\n+    if (edge_ok)  return true;\n+    bad = \"just before\";\n+  } else if (addr == (end = (address)this + sizeof(intptr_t) * (size_in_bytes < 0 ? size() : size_in_bytes))) {\n+    if (edge_ok)  return true;\n+    bad = \"just after\";\n+  } else if (addr > end) {\n+    bad = \"after\";\n+  } else {\n+    return true;\n+  }\n+  tty->print_cr(\"%s object bounds: \" INTPTR_FORMAT \" [\" INTPTR_FORMAT \"..\" INTPTR_FORMAT \"]\",\n+      bad, (intptr_t)addr, (intptr_t)this, (intptr_t)end);\n+  Verbose = WizardMode = true; this->print(); \/\/@@\n+  return false;\n+}\n+#endif \/\/PRODUCT\n@@ -537,2 +590,2 @@\n-InstanceKlass::InstanceKlass(const ClassFileParser& parser, KlassKind kind, ReferenceType reference_type) :\n-  Klass(kind),\n+InstanceKlass::InstanceKlass(const ClassFileParser& parser, KlassKind kind, markWord prototype_header, ReferenceType reference_type) :\n+  Klass(kind, prototype_header),\n@@ -549,1 +602,4 @@\n-  _init_thread(nullptr)\n+  _init_thread(nullptr),\n+  _inline_layout_info_array(nullptr),\n+  _loadable_descriptors(nullptr),\n+  _adr_inlineklass_fixed_block(nullptr)\n@@ -556,0 +612,3 @@\n+  if (parser.has_inline_fields()) {\n+    set_has_inline_type_fields();\n+  }\n@@ -695,0 +754,5 @@\n+  if (inline_layout_info_array() != nullptr) {\n+    MetadataFactory::free_array<InlineLayoutInfo>(loader_data, inline_layout_info_array());\n+  }\n+  set_inline_layout_info_array(nullptr);\n+\n@@ -729,0 +793,7 @@\n+  if (loadable_descriptors() != nullptr &&\n+      loadable_descriptors() != Universe::the_empty_short_array() &&\n+      !loadable_descriptors()->is_shared()) {\n+    MetadataFactory::free_array<jushort>(loader_data, loadable_descriptors());\n+  }\n+  set_loadable_descriptors(nullptr);\n+\n@@ -963,0 +1034,105 @@\n+\n+  \/\/ If a class declares a method that uses an inline class as an argument\n+  \/\/ type or return inline type, this inline class must be loaded during the\n+  \/\/ linking of this class because size and properties of the inline class\n+  \/\/ must be known in order to be able to perform inline type optimizations.\n+  \/\/ The implementation below is an approximation of this rule, the code\n+  \/\/ iterates over all methods of the current class (including overridden\n+  \/\/ methods), not only the methods declared by this class. This\n+  \/\/ approximation makes the code simpler, and doesn't change the semantic\n+  \/\/ because classes declaring methods overridden by the current class are\n+  \/\/ linked (and have performed their own pre-loading) before the linking\n+  \/\/ of the current class.\n+\n+\n+  \/\/ Note:\n+  \/\/ Inline class types are loaded during\n+  \/\/ the loading phase (see ClassFileParser::post_process_parsed_stream()).\n+  \/\/ Inline class types used as element types for array creation\n+  \/\/ are not pre-loaded. Their loading is triggered by either anewarray\n+  \/\/ or multianewarray bytecodes.\n+\n+  \/\/ Could it be possible to do the following processing only if the\n+  \/\/ class uses inline types?\n+  if (EnableValhalla) {\n+    ResourceMark rm(THREAD);\n+    for (AllFieldStream fs(this); !fs.done(); fs.next()) {\n+      if (fs.is_null_free_inline_type() && fs.access_flags().is_static()) {\n+        Symbol* sig = fs.signature();\n+        TempNewSymbol s = Signature::strip_envelope(sig);\n+        if (s != name()) {\n+          log_info(class, preload)(\"Preloading class %s during linking of class %s. Cause: a null-free static field is declared with this type\", s->as_C_string(), name()->as_C_string());\n+          Klass* klass = SystemDictionary::resolve_or_fail(s,\n+                                                          Handle(THREAD, class_loader()), true,\n+                                                          CHECK_false);\n+          if (HAS_PENDING_EXCEPTION) {\n+            log_warning(class, preload)(\"Preloading of class %s during linking of class %s (cause: null-free static field) failed: %s\",\n+                                      s->as_C_string(), name()->as_C_string(), PENDING_EXCEPTION->klass()->name()->as_C_string());\n+            return false; \/\/ Exception is still pending\n+          }\n+          log_info(class, preload)(\"Preloading of class %s during linking of class %s (cause: null-free static field) succeeded\",\n+                                   s->as_C_string(), name()->as_C_string());\n+          assert(klass != nullptr, \"Sanity check\");\n+          if (klass->is_abstract()) {\n+            THROW_MSG_(vmSymbols::java_lang_IncompatibleClassChangeError(),\n+                      err_msg(\"Class %s expects class %s to be concrete value class, but it is an abstract class\",\n+                      name()->as_C_string(),\n+                      InstanceKlass::cast(klass)->external_name()), false);\n+          }\n+          if (!klass->is_inline_klass()) {\n+            THROW_MSG_(vmSymbols::java_lang_IncompatibleClassChangeError(),\n+                       err_msg(\"class %s expects class %s to be a value class but it is an identity class\",\n+                       name()->as_C_string(), klass->external_name()), false);\n+          }\n+          InlineKlass* vk = InlineKlass::cast(klass);\n+          if (!vk->is_implicitly_constructible()) {\n+             THROW_MSG_(vmSymbols::java_lang_IncompatibleClassChangeError(),\n+                        err_msg(\"class %s is not implicitly constructible and it is used in a null restricted static field (not supported)\",\n+                        klass->external_name()), false);\n+          }\n+          \/\/ the inline_type_field_klasses_array might have been loaded with CDS, so update only if not already set and check consistency\n+          InlineLayoutInfo* li = inline_layout_info_adr(fs.index());\n+          if (li->klass() == nullptr) {\n+            li->set_klass(InlineKlass::cast(vk));\n+            li->set_kind(LayoutKind::REFERENCE);\n+          }\n+          assert(get_inline_type_field_klass(fs.index()) == vk, \"Must match\");\n+        } else {\n+          InlineLayoutInfo* li = inline_layout_info_adr(fs.index());\n+          if (li->klass() == nullptr) {\n+            li->set_klass(InlineKlass::cast(this));\n+            li->set_kind(LayoutKind::REFERENCE);\n+          }\n+          assert(get_inline_type_field_klass(fs.index()) == this, \"Must match\");\n+        }\n+      }\n+    }\n+\n+    \/\/ Aggressively preloading all classes from the LoadableDescriptors attribute\n+    if (loadable_descriptors() != nullptr) {\n+      HandleMark hm(THREAD);\n+      for (int i = 0; i < loadable_descriptors()->length(); i++) {\n+        Symbol* sig = constants()->symbol_at(loadable_descriptors()->at(i));\n+        if (!Signature::has_envelope(sig)) continue;\n+        TempNewSymbol class_name = Signature::strip_envelope(sig);\n+        if (class_name == name()) continue;\n+        log_info(class, preload)(\"Preloading class %s during linking of class %s because of the class is listed in the LoadableDescriptors attribute\", sig->as_C_string(), name()->as_C_string());\n+        oop loader = class_loader();\n+        Klass* klass = SystemDictionary::resolve_or_null(class_name,\n+                                                         Handle(THREAD, loader), THREAD);\n+        if (HAS_PENDING_EXCEPTION) {\n+          CLEAR_PENDING_EXCEPTION;\n+        }\n+        if (klass != nullptr) {\n+          log_info(class, preload)(\"Preloading of class %s during linking of class %s (cause: LoadableDescriptors attribute) succeeded\", class_name->as_C_string(), name()->as_C_string());\n+          if (!klass->is_inline_klass()) {\n+            \/\/ Non value class are allowed by the current spec, but it could be an indication of an issue so let's log a warning\n+              log_warning(class, preload)(\"Preloading class %s during linking of class %s (cause: LoadableDescriptors attribute) but loaded class is not a value class\", class_name->as_C_string(), name()->as_C_string());\n+          }\n+        } else {\n+          log_warning(class, preload)(\"Preloading of class %s during linking of class %s (cause: LoadableDescriptors attribute) failed\", class_name->as_C_string(), name()->as_C_string());\n+        }\n+      }\n+    }\n+  }\n+\n@@ -1267,0 +1443,35 @@\n+  \/\/ Pre-allocating an instance of the default value\n+  if (is_inline_klass()) {\n+      InlineKlass* vk = InlineKlass::cast(this);\n+      oop val = vk->allocate_instance(THREAD);\n+      if (HAS_PENDING_EXCEPTION) {\n+          Handle e(THREAD, PENDING_EXCEPTION);\n+          CLEAR_PENDING_EXCEPTION;\n+          {\n+              EXCEPTION_MARK;\n+              add_initialization_error(THREAD, e);\n+              \/\/ Locks object, set state, and notify all waiting threads\n+              set_initialization_state_and_notify(initialization_error, THREAD);\n+              CLEAR_PENDING_EXCEPTION;\n+          }\n+          THROW_OOP(e());\n+      }\n+      vk->set_default_value(val);\n+      if (vk->has_nullable_atomic_layout()) {\n+        val = vk->allocate_instance(THREAD);\n+        if (HAS_PENDING_EXCEPTION) {\n+            Handle e(THREAD, PENDING_EXCEPTION);\n+            CLEAR_PENDING_EXCEPTION;\n+            {\n+                EXCEPTION_MARK;\n+                add_initialization_error(THREAD, e);\n+                \/\/ Locks object, set state, and notify all waiting threads\n+                set_initialization_state_and_notify(initialization_error, THREAD);\n+                CLEAR_PENDING_EXCEPTION;\n+            }\n+            THROW_OOP(e());\n+        }\n+        vk->set_null_reset_value(val);\n+      }\n+  }\n+\n@@ -1299,1 +1510,33 @@\n-\n+  \/\/ Initialize classes of inline fields\n+  if (EnableValhalla) {\n+    for (AllFieldStream fs(this); !fs.done(); fs.next()) {\n+      if (fs.is_null_free_inline_type()) {\n+\n+        \/\/ inline type field klass array entries must have alreadyt been filed at load time or link time\n+        Klass* klass = get_inline_type_field_klass(fs.index());\n+\n+        InstanceKlass::cast(klass)->initialize(THREAD);\n+        if (fs.access_flags().is_static()) {\n+          if (java_mirror()->obj_field(fs.offset()) == nullptr) {\n+            java_mirror()->obj_field_put(fs.offset(), InlineKlass::cast(klass)->default_value());\n+          }\n+        }\n+\n+        if (HAS_PENDING_EXCEPTION) {\n+          Handle e(THREAD, PENDING_EXCEPTION);\n+          CLEAR_PENDING_EXCEPTION;\n+          {\n+            EXCEPTION_MARK;\n+            add_initialization_error(THREAD, e);\n+            \/\/ Locks object, set state, and notify all waiting threads\n+            set_initialization_state_and_notify(initialization_error, THREAD);\n+            CLEAR_PENDING_EXCEPTION;\n+          }\n+          THROW_OOP(e());\n+        }\n+      }\n+    }\n+  }\n+\n+\n+  \/\/ Step 9\n@@ -1322,1 +1565,1 @@\n-  \/\/ Step 9\n+  \/\/ Step 10\n@@ -1328,1 +1571,1 @@\n-    \/\/ Step 10 and 11\n+    \/\/ Step 11 and 12\n@@ -1624,1 +1867,1 @@\n-      ObjArrayKlass* k = ObjArrayKlass::allocate_objArray_klass(class_loader_data(), 1, this, CHECK_NULL);\n+      ObjArrayKlass* k = ObjArrayKlass::allocate_objArray_klass(class_loader_data(), 1, this, false, CHECK_NULL);\n@@ -1631,1 +1874,1 @@\n-  ObjArrayKlass* ak = array_klasses();\n+  ArrayKlass* ak = array_klasses();\n@@ -1638,2 +1881,2 @@\n-  ObjArrayKlass* oak = array_klasses_acquire();\n-  if (oak == nullptr) {\n+  ArrayKlass* ak = array_klasses_acquire();\n+  if (ak == nullptr) {\n@@ -1642,1 +1885,1 @@\n-    return oak->array_klass_or_null(n);\n+    return ak->array_klass_or_null(n);\n@@ -1659,1 +1902,1 @@\n-  if (clinit != nullptr && clinit->has_valid_initializer_flags()) {\n+  if (clinit != nullptr && clinit->is_class_initializer()) {\n@@ -1768,4 +2011,0 @@\n-bool InstanceKlass::contains_field_offset(int offset) {\n-  fieldDescriptor fd;\n-  return find_field_from_offset(offset, false, &fd);\n-}\n@@ -1853,0 +2092,9 @@\n+bool InstanceKlass::contains_field_offset(int offset) {\n+  if (this->is_inline_klass()) {\n+    InlineKlass* vk = InlineKlass::cast(this);\n+    return offset >= vk->payload_offset() && offset < (vk->payload_offset() + vk->payload_size_in_bytes());\n+  } else {\n+    fieldDescriptor fd;\n+    return find_field_from_offset(offset, false, &fd);\n+  }\n+}\n@@ -2244,0 +2492,3 @@\n+    if (name == vmSymbols::object_initializer_name()) {\n+      break;  \/\/ <init> is never inherited\n+    }\n@@ -2641,0 +2892,1 @@\n+  it->push(&_loadable_descriptors);\n@@ -2642,0 +2894,1 @@\n+  it->push(&_inline_layout_info_array, MetaspaceClosure::_writable);\n@@ -2687,1 +2940,1 @@\n-  \/\/ These are not allocated from metaspace. They are safe to set to null.\n+  \/\/ These are not allocated from metaspace. They are safe to set to nullptr.\n@@ -2776,0 +3029,4 @@\n+  if (is_inline_klass()) {\n+    InlineKlass::cast(this)->initialize_calling_convention(CHECK);\n+  }\n+\n@@ -2809,1 +3066,1 @@\n-    assert(this == array_klasses()->bottom_klass(), \"sanity\");\n+    assert(this == ObjArrayKlass::cast(array_klasses())->bottom_klass(), \"sanity\");\n@@ -3006,0 +3263,2 @@\n+  return signature_name_of_carrier(JVM_SIGNATURE_CLASS);\n+}\n@@ -3007,0 +3266,1 @@\n+const char* InstanceKlass::signature_name_of_carrier(char c) const {\n@@ -3013,1 +3273,1 @@\n-  \/\/ Add L as type indicator\n+  \/\/ Add L or Q as type indicator\n@@ -3015,1 +3275,1 @@\n-  dest[dest_index++] = JVM_SIGNATURE_CLASS;\n+  dest[dest_index++] = c;\n@@ -3362,2 +3622,1 @@\n-  \/\/ Remember to strip ACC_SUPER bit\n-  return (access & (~JVM_ACC_SUPER));\n+  return access;\n@@ -3617,1 +3876,4 @@\n-static void print_vtable(intptr_t* start, int len, outputStream* st) {\n+static void print_vtable(address self, intptr_t* start, int len, outputStream* st) {\n+  ResourceMark rm;\n+  int* forward_refs = NEW_RESOURCE_ARRAY(int, len);\n+  for (int i = 0; i < len; i++)  forward_refs[i] = 0;\n@@ -3621,0 +3883,5 @@\n+    if (forward_refs[i] != 0) {\n+      int from = forward_refs[i];\n+      int off = (int) start[from];\n+      st->print(\" (offset %d <= [%d])\", off, from);\n+    }\n@@ -3624,0 +3891,6 @@\n+    } else if (self != nullptr && e > 0 && e < 0x10000) {\n+      address location = self + e;\n+      int index = (int)((intptr_t*)location - start);\n+      st->print(\" (offset %d => [%d])\", (int)e, index);\n+      if (index >= 0 && index < len)\n+        forward_refs[index] = i;\n@@ -3630,1 +3903,22 @@\n-  return print_vtable(reinterpret_cast<intptr_t*>(start), len, st);\n+  return print_vtable(nullptr, reinterpret_cast<intptr_t*>(start), len, st);\n+}\n+\n+template<typename T>\n+ static void print_array_on(outputStream* st, Array<T>* array) {\n+   if (array == nullptr) { st->print_cr(\"nullptr\"); return; }\n+   array->print_value_on(st); st->cr();\n+   if (Verbose || WizardMode) {\n+     for (int i = 0; i < array->length(); i++) {\n+       st->print(\"%d : \", i); array->at(i)->print_value_on(st); st->cr();\n+     }\n+   }\n+ }\n+\n+static void print_array_on(outputStream* st, Array<int>* array) {\n+  if (array == nullptr) { st->print_cr(\"nullptr\"); return; }\n+  array->print_value_on(st); st->cr();\n+  if (Verbose || WizardMode) {\n+    for (int i = 0; i < array->length(); i++) {\n+      st->print(\"%d : %d\", i, array->at(i)); st->cr();\n+    }\n+  }\n@@ -3671,8 +3965,2 @@\n-  st->print(BULLET\"methods:           \"); methods()->print_value_on(st);               st->cr();\n-  if (Verbose || WizardMode) {\n-    Array<Method*>* method_array = methods();\n-    for (int i = 0; i < method_array->length(); i++) {\n-      st->print(\"%d : \", i); method_array->at(i)->print_value(); st->cr();\n-    }\n-  }\n-  st->print(BULLET\"method ordering:   \"); method_ordering()->print_value_on(st);      st->cr();\n+  st->print(BULLET\"methods:           \"); print_array_on(st, methods());\n+  st->print(BULLET\"method ordering:   \"); print_array_on(st, method_ordering());\n@@ -3680,7 +3968,1 @@\n-    st->print(BULLET\"default_methods:   \"); default_methods()->print_value_on(st);    st->cr();\n-    if (Verbose) {\n-      Array<Method*>* method_array = default_methods();\n-      for (int i = 0; i < method_array->length(); i++) {\n-        st->print(\"%d : \", i); method_array->at(i)->print_value(); st->cr();\n-      }\n-    }\n+    st->print(BULLET\"default_methods:   \"); print_array_on(st, default_methods());\n@@ -3746,0 +4028,1 @@\n+  st->print(BULLET\"loadable descriptors:     \"); loadable_descriptors()->print_value_on(st); st->cr();\n@@ -3756,1 +4039,1 @@\n-  if (itable_length() > 0 && (Verbose || WizardMode))  print_vtable(start_of_itable(), itable_length(), st);\n+  if (itable_length() > 0 && (Verbose || WizardMode))  print_vtable(nullptr, start_of_itable(), itable_length(), st);\n@@ -3783,0 +4066,1 @@\n+  for (int i = 0; i < _indent; i++) _st->print(\"  \");\n@@ -3785,1 +4069,1 @@\n-     fd->print_on(_st);\n+     fd->print_on(_st, _base_offset);\n@@ -3788,2 +4072,2 @@\n-     fd->print_on_for(_st, _obj);\n-     _st->cr();\n+     fd->print_on_for(_st, _obj, _indent, _base_offset);\n+     if (!fd->field_flags().is_flat()) _st->cr();\n@@ -3794,1 +4078,1 @@\n-void InstanceKlass::oop_print_on(oop obj, outputStream* st) {\n+void InstanceKlass::oop_print_on(oop obj, outputStream* st, int indent, int base_offset) {\n@@ -3810,1 +4094,1 @@\n-  FieldPrinter print_field(st, obj);\n+  FieldPrinter print_field(st, obj, indent, base_offset);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":330,"deletions":46,"binary":false,"changes":376,"status":"modified"},{"patch":"@@ -62,0 +62,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -122,1 +123,0 @@\n-\n@@ -160,0 +160,5 @@\n+address Method::get_c2i_inline_entry() {\n+  assert(adapter() != nullptr, \"must have\");\n+  return adapter()->get_c2i_inline_entry();\n+}\n+\n@@ -165,0 +170,5 @@\n+address Method::get_c2i_unverified_inline_entry() {\n+  assert(adapter() != nullptr, \"must have\");\n+  return adapter()->get_c2i_unverified_inline_entry();\n+}\n+\n@@ -390,1 +400,1 @@\n-  if (!method_holder()->is_rewritten()) {\n+  if (!method_holder()->is_rewritten() || CDSConfig::is_valhalla_preview()) {\n@@ -667,0 +677,16 @@\n+\/\/ InlineKlass the method is declared to return. This must not\n+\/\/ safepoint as it is called with references live on the stack at\n+\/\/ locations the GC is unaware of.\n+InlineKlass* Method::returns_inline_type(Thread* thread) const {\n+  assert(InlineTypeReturnedAsFields, \"Inline types should never be returned as fields\");\n+  if (is_native()) {\n+    return nullptr;\n+  }\n+  NoSafepointVerifier nsv;\n+  SignatureStream ss(signature());\n+  while (!ss.at_return_type()) {\n+    ss.next();\n+  }\n+  return ss.as_inline_klass(method_holder());\n+}\n+\n@@ -815,0 +841,5 @@\n+  if (has_scalarized_return()) {\n+    \/\/ Don't treat this as (trivial) getter method because the\n+    \/\/ inline type should be returned in a scalarized form.\n+    return false;\n+  }\n@@ -836,0 +867,5 @@\n+  if (has_scalarized_args()) {\n+    \/\/ Don't treat this as (trivial) setter method because the\n+    \/\/ inline type argument should be passed in a scalarized form.\n+    return false;\n+  }\n@@ -846,1 +882,2 @@\n-          Bytecodes::is_return(java_code_at(last_index)));\n+          Bytecodes::is_return(java_code_at(last_index)) &&\n+          !has_scalarized_args());\n@@ -849,6 +886,1 @@\n-bool Method::has_valid_initializer_flags() const {\n-  return (is_static() ||\n-          method_holder()->major_version() < 51);\n-}\n-\n-bool Method::is_static_initializer() const {\n+bool Method::is_class_initializer() const {\n@@ -858,2 +890,3 @@\n-  return name() == vmSymbols::class_initializer_name() &&\n-         has_valid_initializer_flags();\n+  return (name() == vmSymbols::class_initializer_name() &&\n+          (is_static() ||\n+           method_holder()->major_version() < 51));\n@@ -862,2 +895,3 @@\n-bool Method::is_object_initializer() const {\n-   return name() == vmSymbols::object_initializer_name();\n+\/\/ A method named <init>, is a classic object constructor.\n+bool Method::is_object_constructor() const {\n+  return name() == vmSymbols::object_initializer_name();\n@@ -926,1 +960,1 @@\n-  if( constants()->tag_at(klass_index).is_unresolved_klass() ) {\n+  if( constants()->tag_at(klass_index).is_unresolved_klass()) {\n@@ -941,1 +975,3 @@\n-    if (constants()->tag_at(klass_index).is_unresolved_klass()) return false;\n+    if (constants()->tag_at(klass_index).is_unresolved_klass()) {\n+      return false;\n+    }\n@@ -1110,0 +1146,2 @@\n+    _from_compiled_inline_entry = nullptr;\n+    _from_compiled_inline_ro_entry = nullptr;\n@@ -1112,0 +1150,2 @@\n+    _from_compiled_inline_entry = adapter()->get_c2i_inline_entry();\n+    _from_compiled_inline_ro_entry = adapter()->get_c2i_inline_ro_entry();\n@@ -1143,0 +1183,2 @@\n+  _from_compiled_inline_entry = nullptr;\n+  _from_compiled_inline_ro_entry = nullptr;\n@@ -1168,0 +1210,2 @@\n+  set_has_scalarized_args(false);\n+  set_has_scalarized_return(false);\n@@ -1200,0 +1244,3 @@\n+  if (InlineTypeReturnedAsFields && returns_inline_type(THREAD) && !has_scalarized_return()) {\n+    set_has_scalarized_return();\n+  }\n@@ -1248,0 +1295,2 @@\n+  mh->_from_compiled_inline_entry = adapter->get_c2i_inline_entry();\n+  mh->_from_compiled_inline_ro_entry = adapter->get_c2i_inline_ro_entry();\n@@ -1264,0 +1313,12 @@\n+address Method::verified_inline_code_entry() {\n+  debug_only(NoSafepointVerifier nsv;)\n+  assert(_from_compiled_inline_entry != nullptr, \"must be set\");\n+  return _from_compiled_inline_entry;\n+}\n+\n+address Method::verified_inline_ro_code_entry() {\n+  debug_only(NoSafepointVerifier nsv;)\n+  assert(_from_compiled_inline_ro_entry != nullptr, \"must be set\");\n+  return _from_compiled_inline_ro_entry;\n+}\n+\n@@ -1295,0 +1356,2 @@\n+  mh->_from_compiled_inline_entry = code->verified_inline_entry_point();\n+  mh->_from_compiled_inline_ro_entry = code->verified_inline_ro_entry_point();\n@@ -2250,0 +2313,25 @@\n+bool Method::is_scalarized_arg(int idx) const {\n+  if (!has_scalarized_args()) {\n+    return false;\n+  }\n+  \/\/ Search through signature and check if argument is wrapped in T_METADATA\/T_VOID\n+  int depth = 0;\n+  const GrowableArray<SigEntry>* sig = adapter()->get_sig_cc();\n+  for (int i = 0; i < sig->length(); i++) {\n+    BasicType bt = sig->at(i)._bt;\n+    if (bt == T_METADATA) {\n+      depth++;\n+    }\n+    if (idx == 0) {\n+      break; \/\/ Argument found\n+    }\n+    if (bt == T_VOID && (sig->at(i-1)._bt != T_LONG && sig->at(i-1)._bt != T_DOUBLE)) {\n+      depth--;\n+    }\n+    if (depth == 0 && bt != T_LONG && bt != T_DOUBLE) {\n+      idx--; \/\/ Advance to next argument\n+    }\n+  }\n+  return depth != 0;\n+}\n+\n@@ -2282,0 +2370,4 @@\n+#ifdef ASSERT\n+  if (valid_itable_index())\n+    st->print_cr(\" - itable index:      %d\",   itable_index());\n+#endif\n@@ -2289,1 +2381,3 @@\n-  st->print_cr(\" - compiled entry     \" PTR_FORMAT, p2i(from_compiled_entry()));\n+  st->print_cr(\" - compiled entry           \" PTR_FORMAT, p2i(from_compiled_entry()));\n+  st->print_cr(\" - compiled inline entry    \" PTR_FORMAT, p2i(from_compiled_inline_entry()));\n+  st->print_cr(\" - compiled inline ro entry \" PTR_FORMAT, p2i(from_compiled_inline_ro_entry()));\n@@ -2359,0 +2453,1 @@\n+  if (WizardMode) access_flags().print_on(st);\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":111,"deletions":16,"binary":false,"changes":127,"status":"modified"},{"patch":"@@ -79,1 +79,1 @@\n-  virtual Node *match( const ProjNode *proj, const Matcher *m );\n+  virtual Node *match(const ProjNode *proj, const Matcher *m, const RegMask* mask);\n@@ -93,1 +93,0 @@\n-  static  const TypeTuple *osr_domain();\n@@ -654,1 +653,1 @@\n-class CallProjections : public StackObj {\n+class CallProjections {\n@@ -663,1 +662,19 @@\n-  Node* resproj;\n+  uint nb_resproj;\n+  Node* resproj[1]; \/\/ at least one projection\n+\n+  CallProjections(uint nbres) {\n+    fallthrough_proj      = nullptr;\n+    fallthrough_catchproj = nullptr;\n+    fallthrough_memproj   = nullptr;\n+    fallthrough_ioproj    = nullptr;\n+    catchall_catchproj    = nullptr;\n+    catchall_memproj      = nullptr;\n+    catchall_ioproj       = nullptr;\n+    exobj                 = nullptr;\n+    nb_resproj            = nbres;\n+    resproj[0]            = nullptr;\n+    for (uint i = 1; i < nb_resproj; i++) {\n+      resproj[i]          = nullptr;\n+    }\n+  }\n+\n@@ -685,1 +702,1 @@\n-    : SafePointNode(tf->domain()->cnt(), jvms, adr_type),\n+    : SafePointNode(tf->domain_cc()->cnt(), jvms, adr_type),\n@@ -712,1 +729,1 @@\n-  virtual Node*       match(const ProjNode* proj, const Matcher* m);\n+  virtual Node*       match(const ProjNode* proj, const Matcher* m, const RegMask* mask);\n@@ -726,0 +743,1 @@\n+  bool                has_debug_use(Node* n);\n@@ -732,2 +750,3 @@\n-    const TypeTuple* r = tf()->range();\n-    return (r->cnt() > TypeFunc::Parms &&\n+    const TypeTuple* r = tf()->range_sig();\n+    return (!tf()->returns_inline_type_as_fields() &&\n+            r->cnt() > TypeFunc::Parms &&\n@@ -740,1 +759,1 @@\n-  void extract_projections(CallProjections* projs, bool separate_io_proj, bool do_asserts = true);\n+  CallProjections* extract_projections(bool separate_io_proj, bool do_asserts = true);\n@@ -809,0 +828,3 @@\n+\n+  bool remove_unknown_flat_array_load(PhaseIterGVN* igvn, Node* ctl, Node* mem, Node* unc_arg);\n+\n@@ -817,0 +839,11 @@\n+    const TypeTuple *r = tf->range_sig();\n+    if (InlineTypeReturnedAsFields &&\n+        method != nullptr &&\n+        method->is_method_handle_intrinsic() &&\n+        r->cnt() > TypeFunc::Parms &&\n+        r->field_at(TypeFunc::Parms)->isa_oopptr() &&\n+        r->field_at(TypeFunc::Parms)->is_oopptr()->can_be_inline_type()) {\n+      \/\/ Make sure this call is processed by PhaseMacroExpand::expand_mh_intrinsic_return\n+      init_flags(Flag_is_macro);\n+      C->add_macro_node(this);\n+    }\n@@ -927,0 +960,1 @@\n+  virtual uint match_edge(uint idx) const;\n@@ -969,0 +1003,3 @@\n+    InlineType,                       \/\/ InlineTypeNode if this is an inline type allocation\n+    DefaultValue,                     \/\/ default value in case of non-flat inline type array\n+    RawDefaultValue,                  \/\/ same as above but as raw machine word\n@@ -979,0 +1016,3 @@\n+    fields[InlineType] = Type::BOTTOM;\n+    fields[DefaultValue] = TypeInstPtr::NOTNULL;\n+    fields[RawDefaultValue] = TypeX_X;\n@@ -996,0 +1036,1 @@\n+  bool _larval;\n@@ -999,1 +1040,2 @@\n-               Node *size, Node *klass_node, Node *initial_test);\n+               Node *size, Node *klass_node, Node *initial_test,\n+               InlineTypeNode* inline_type_node = nullptr);\n@@ -1064,1 +1106,1 @@\n-  Node* make_ideal_mark(PhaseGVN *phase, Node* obj, Node* control, Node* mem);\n+  Node* make_ideal_mark(PhaseGVN* phase, Node* control, Node* mem);\n@@ -1074,1 +1116,2 @@\n-                    Node* initial_test, Node* count_val, Node* valid_length_test)\n+                    Node* initial_test, Node* count_val, Node* valid_length_test,\n+                    Node* default_value, Node* raw_default_value)\n@@ -1081,0 +1124,2 @@\n+    init_req(AllocateNode::DefaultValue,  default_value);\n+    init_req(AllocateNode::RawDefaultValue, raw_default_value);\n@@ -1082,0 +1127,1 @@\n+  virtual uint size_of() const { return sizeof(*this); }\n","filename":"src\/hotspot\/share\/opto\/callnode.hpp","additions":58,"deletions":12,"binary":false,"changes":70,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -523,0 +524,1 @@\n+\n@@ -969,1 +971,2 @@\n-             cmp1->is_SubTypeCheck() || cmp2->is_SubTypeCheck()) {\n+             cmp1->is_SubTypeCheck() || cmp2->is_SubTypeCheck() ||\n+             cmp1->is_FlatArrayCheck() || cmp2->is_FlatArrayCheck()) {\n@@ -1048,1 +1051,1 @@\n-\/\/ note that these functions assume that the _adr_type field is flattened\n+\/\/ note that these functions assume that the _adr_type field is flat\n@@ -1066,1 +1069,1 @@\n-  assert(t != Type::MEMORY || at == flatten_phi_adr_type(at), \"flatten at\");\n+  assert(t != Type::MEMORY || at == flatten_phi_adr_type(at) || (flatten_phi_adr_type(at) == TypeAryPtr::INLINES && Compile::current()->flat_accesses_share_alias()), \"flatten at\");\n@@ -1195,0 +1198,8 @@\n+  \/\/ Flat array element shouldn't get their own memory slice until flat_accesses_share_alias is cleared.\n+  \/\/ It could be the graph has no loads\/stores and flat_accesses_share_alias is never cleared. EA could still\n+  \/\/ creates per element Phis but that wouldn't be a problem as there are no memory accesses for that array.\n+  assert(_adr_type == nullptr || _adr_type->isa_aryptr() == nullptr ||\n+         _adr_type->is_aryptr()->is_known_instance() ||\n+         !_adr_type->is_aryptr()->is_flat() ||\n+         !Compile::current()->flat_accesses_share_alias() ||\n+         _adr_type == TypeAryPtr::INLINES, \"flat array element shouldn't get its own slice yet\");\n@@ -1413,0 +1424,1 @@\n+\n@@ -2033,0 +2045,46 @@\n+\/\/ Push inline type input nodes (and null) down through the phi recursively (can handle data loops).\n+InlineTypeNode* PhiNode::push_inline_types_down(PhaseGVN* phase, bool can_reshape, ciInlineKlass* inline_klass) {\n+  assert(inline_klass != nullptr, \"must be\");\n+  InlineTypeNode* vt = InlineTypeNode::make_null(*phase, inline_klass, \/* transform = *\/ false)->clone_with_phis(phase, in(0), nullptr, !_type->maybe_null());\n+  if (can_reshape) {\n+    \/\/ Replace phi right away to be able to use the inline\n+    \/\/ type node when reaching the phi again through data loops.\n+    PhaseIterGVN* igvn = phase->is_IterGVN();\n+    for (DUIterator_Fast imax, i = fast_outs(imax); i < imax; i++) {\n+      Node* u = fast_out(i);\n+      igvn->rehash_node_delayed(u);\n+      imax -= u->replace_edge(this, vt);\n+      --i;\n+    }\n+    igvn->rehash_node_delayed(this);\n+    assert(outcnt() == 0, \"should be dead now\");\n+  }\n+  ResourceMark rm;\n+  Node_List casts;\n+  for (uint i = 1; i < req(); ++i) {\n+    Node* n = in(i);\n+    while (n->is_ConstraintCast()) {\n+      casts.push(n);\n+      n = n->in(1);\n+    }\n+    if (phase->type(n)->is_zero_type()) {\n+      n = InlineTypeNode::make_null(*phase, inline_klass);\n+    } else if (n->is_Phi()) {\n+      assert(can_reshape, \"can only handle phis during IGVN\");\n+      n = phase->transform(n->as_Phi()->push_inline_types_down(phase, can_reshape, inline_klass));\n+    }\n+    while (casts.size() != 0) {\n+      \/\/ Push the cast(s) through the InlineTypeNode\n+      \/\/ TODO 8302217 Can we avoid cloning? See InlineTypeNode::clone_if_required\n+      Node* cast = casts.pop()->clone();\n+      cast->set_req_X(1, n->as_InlineType()->get_oop(), phase);\n+      n = n->clone();\n+      n->as_InlineType()->set_oop(*phase, phase->transform(cast));\n+      n = phase->transform(n);\n+    }\n+    bool transform = !can_reshape && (i == (req()-1)); \/\/ Transform phis on last merge\n+    vt->merge_with(phase, n->as_InlineType(), i, transform);\n+  }\n+  return vt;\n+}\n+\n@@ -2433,0 +2491,2 @@\n+    \/\/ TODO revisit this with JDK-8247216\n+    bool mergemem_only = true;\n@@ -2448,0 +2508,2 @@\n+      } else {\n+        mergemem_only = false;\n@@ -2471,1 +2533,1 @@\n-    if (!split_always_terminates && adr_type() == TypePtr::BOTTOM &&\n+    if (!mergemem_only && !split_always_terminates && adr_type() == TypePtr::BOTTOM &&\n@@ -2544,0 +2606,5 @@\n+            if (igvn) {\n+              \/\/ TODO revisit this with JDK-8247216\n+              \/\/ Put 'n' on the worklist because it might be modified by MergeMemStream::iteration_setup\n+              igvn->_worklist.push(n);\n+            }\n@@ -2662,0 +2729,5 @@\n+  Node* inline_type = try_push_inline_types_down(phase, can_reshape);\n+  if (inline_type != this) {\n+    return inline_type;\n+  }\n+\n@@ -2705,0 +2777,95 @@\n+\/\/ Check recursively if inputs are either an inline type, constant null\n+\/\/ or another Phi (including self references through data loops). If so,\n+\/\/ push the inline types down through the phis to enable folding of loads.\n+Node* PhiNode::try_push_inline_types_down(PhaseGVN* phase, const bool can_reshape) {\n+  if (!can_be_inline_type()) {\n+    return this;\n+  }\n+\n+  ciInlineKlass* inline_klass;\n+  if (can_push_inline_types_down(phase, can_reshape, inline_klass)) {\n+    assert(inline_klass != nullptr, \"must be\");\n+    return push_inline_types_down(phase, can_reshape, inline_klass);\n+  }\n+  return this;\n+}\n+\n+bool PhiNode::can_push_inline_types_down(PhaseGVN* phase, const bool can_reshape, ciInlineKlass*& inline_klass) {\n+  if (req() <= 2) {\n+    \/\/ Dead phi.\n+    return false;\n+  }\n+  inline_klass = nullptr;\n+\n+  \/\/ TODO 8302217 We need to prevent endless pushing through\n+  bool only_phi = (outcnt() != 0);\n+  for (DUIterator_Fast imax, i = fast_outs(imax); i < imax; i++) {\n+    Node* n = fast_out(i);\n+    if (n->is_InlineType() && n->in(1) == this) {\n+      return false;\n+    }\n+    if (!n->is_Phi()) {\n+      only_phi = false;\n+    }\n+  }\n+  if (only_phi) {\n+    return false;\n+  }\n+\n+  ResourceMark rm;\n+  Unique_Node_List worklist;\n+  worklist.push(this);\n+  Node_List casts;\n+\n+  for (uint next = 0; next < worklist.size(); next++) {\n+    Node* phi = worklist.at(next);\n+    for (uint i = 1; i < phi->req(); i++) {\n+      Node* n = phi->in(i);\n+      if (n == nullptr) {\n+        return false;\n+      }\n+      while (n->is_ConstraintCast()) {\n+        if (n->in(0) != nullptr && n->in(0)->is_top()) {\n+          \/\/ Will die, don't optimize\n+          return false;\n+        }\n+        casts.push(n);\n+        n = n->in(1);\n+      }\n+      const Type* type = phase->type(n);\n+      if (n->is_InlineType() && (inline_klass == nullptr || inline_klass == type->inline_klass())) {\n+        inline_klass = type->inline_klass();\n+      } else if (n->is_Phi() && can_reshape && n->bottom_type()->isa_ptr()) {\n+        worklist.push(n);\n+      } else if (!type->is_zero_type()) {\n+        return false;\n+      }\n+    }\n+  }\n+  if (inline_klass == nullptr) {\n+    return false;\n+  }\n+\n+  \/\/ Check if cast nodes can be pushed through\n+  const Type* t = Type::get_const_type(inline_klass);\n+  while (casts.size() != 0 && t != nullptr) {\n+    Node* cast = casts.pop();\n+    if (t->filter(cast->bottom_type()) == Type::TOP) {\n+      return false;\n+    }\n+  }\n+\n+  return true;\n+}\n+\n+#ifdef ASSERT\n+bool PhiNode::can_push_inline_types_down(PhaseGVN* phase) {\n+  if (!can_be_inline_type()) {\n+    return false;\n+  }\n+\n+  ciInlineKlass* inline_klass;\n+  return can_push_inline_types_down(phase, true, inline_klass);\n+}\n+#endif \/\/ ASSERT\n+\n@@ -3087,0 +3254,6 @@\n+\n+  \/\/ CheckCastPPNode::Ideal() for inline types reuses the exception\n+  \/\/ paths of a call to perform an allocation: we can see a Phi here.\n+  if (in(1)->is_Phi()) {\n+    return this;\n+  }\n","filename":"src\/hotspot\/share\/opto\/cfgnode.cpp","additions":177,"deletions":4,"binary":false,"changes":181,"status":"modified"},{"patch":"@@ -185,0 +185,3 @@\n+  bool can_push_inline_types_down(PhaseGVN* phase, bool can_reshape, ciInlineKlass*& inline_klass);\n+  InlineTypeNode* push_inline_types_down(PhaseGVN* phase, bool can_reshape, ciInlineKlass* inline_klass);\n+\n@@ -260,0 +263,7 @@\n+  bool can_be_inline_type() const {\n+    return EnableValhalla && _type->isa_instptr() && _type->is_instptr()->can_be_inline_type();\n+  }\n+\n+  Node* try_push_inline_types_down(PhaseGVN* phase, bool can_reshape);\n+  DEBUG_ONLY(bool can_push_inline_types_down(PhaseGVN* phase);)\n+\n@@ -453,0 +463,2 @@\n+  bool is_flat_array_check(PhaseTransform* phase, Node** array = nullptr);\n+\n@@ -726,0 +738,1 @@\n+    init_class_id(Class_Blackhole);\n","filename":"src\/hotspot\/share\/opto\/cfgnode.hpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -60,0 +60,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -67,0 +68,1 @@\n+#include \"opto\/movenode.hpp\"\n@@ -405,0 +407,3 @@\n+  if (dead->is_InlineType()) {\n+    remove_inline_type(dead);\n+  }\n@@ -452,0 +457,3 @@\n+    if (n->outcnt() == 0) {\n+      worklist.push(n);\n+    }\n@@ -459,0 +467,6 @@\n+  remove_useless_nodes(_inline_type_nodes,  useful); \/\/ remove useless inline type nodes\n+#ifdef ASSERT\n+  if (_modified_nodes != nullptr) {\n+    _modified_nodes->remove_useless_nodes(useful.member_set());\n+  }\n+#endif\n@@ -640,0 +654,1 @@\n+      _has_circular_inline_type(false),\n@@ -659,0 +674,1 @@\n+      _inline_type_nodes (comp_arena(), 8, 0, nullptr),\n@@ -763,4 +779,2 @@\n-      const TypeTuple *domain = StartOSRNode::osr_domain();\n-      const TypeTuple *range = TypeTuple::make_range(method()->signature());\n-      init_tf(TypeFunc::make(domain, range));\n-      StartNode* s = new StartOSRNode(root(), domain);\n+      init_tf(TypeFunc::make(method(), \/* is_osr_compilation = *\/ true));\n+      StartNode* s = new StartOSRNode(root(), tf()->domain_sig());\n@@ -773,1 +787,1 @@\n-      StartNode* s = new StartNode(root(), tf()->domain());\n+      StartNode* s = new StartNode(root(), tf()->domain_cc());\n@@ -884,0 +898,10 @@\n+  if (needs_stack_repair()) {\n+    \/\/ One extra slot for the special stack increment value\n+    next_slot += 2;\n+  }\n+  \/\/ TODO 8284443 Only reserve extra slot if needed\n+  if (InlineTypeReturnedAsFields) {\n+    \/\/ One extra slot to hold the IsInit information for a nullable\n+    \/\/ inline type return if we run out of registers.\n+    next_slot += 2;\n+  }\n@@ -899,1 +923,1 @@\n-                 const char* stub_name,\n+                 const char *stub_name,\n@@ -919,0 +943,1 @@\n+      _has_circular_inline_type(false),\n@@ -1062,0 +1087,4 @@\n+  _has_flat_accesses = false;\n+  _flat_accesses_share_alias = true;\n+  _scalarize_in_safepoints = false;\n+\n@@ -1333,1 +1362,2 @@\n-    assert(InlineUnsafeOps || StressReflectiveCode, \"indeterminate pointers come only from unsafe ops\");\n+    bool default_value_load = EnableValhalla && tj->is_instptr()->instance_klass() == ciEnv::current()->Class_klass();\n+    assert(InlineUnsafeOps || StressReflectiveCode || default_value_load, \"indeterminate pointers come only from unsafe ops\");\n@@ -1346,0 +1376,9 @@\n+  if (ta && ta->is_not_flat()) {\n+    \/\/ Erase not flat property for alias analysis.\n+    tj = ta = ta->cast_to_not_flat(false);\n+  }\n+  if (ta && ta->is_not_null_free()) {\n+    \/\/ Erase not null free property for alias analysis.\n+    tj = ta = ta->cast_to_not_null_free(false);\n+  }\n+\n@@ -1359,0 +1398,2 @@\n+    \/\/ For flat inline type array, each field has its own slice so\n+    \/\/ we must include the field offset.\n@@ -1399,1 +1440,1 @@\n-      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,nullptr,false,offset);\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,nullptr,false,Type::Offset(offset), ta->field_offset());\n@@ -1403,1 +1444,6 @@\n-      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,nullptr,false,offset);\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,nullptr,false,Type::Offset(offset), ta->field_offset());\n+    }\n+    \/\/ Initially all flattened array accesses share a single slice\n+    if (ta->is_flat() && ta->elem() != TypeInstPtr::BOTTOM && _flat_accesses_share_alias) {\n+      const TypeAry* tary = TypeAry::make(TypeInstPtr::BOTTOM, ta->size(), \/* stable= *\/ false, \/* flat= *\/ true);\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,nullptr,false,Type::Offset(offset), Type::Offset(Type::OffsetBot));\n@@ -1410,1 +1456,1 @@\n-      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,aklass,false,offset);\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,aklass,false,Type::Offset(offset), ta->field_offset());\n@@ -1460,1 +1506,1 @@\n-        tj = to = TypeInstPtr::make(TypePtr::BotPTR, env()->Object_klass(), false, nullptr, offset);\n+        tj = to = TypeInstPtr::make(TypePtr::BotPTR, env()->Object_klass(), false, nullptr, Type::Offset(offset));\n@@ -1481,1 +1527,1 @@\n-        assert(tj == TypeInstPtr::make(to->ptr(), canonical_holder, is_known_inst, nullptr, offset, instance_id), \"exact type should be canonical type\");\n+        assert(tj == TypeInstPtr::make(to->ptr(), canonical_holder, is_known_inst, nullptr, Type::Offset(offset), instance_id), \"exact type should be canonical type\");\n@@ -1484,1 +1530,1 @@\n-        tj = to = TypeInstPtr::make(to->ptr(), canonical_holder, is_known_inst, nullptr, offset, instance_id);\n+        tj = to = TypeInstPtr::make(to->ptr(), canonical_holder, is_known_inst, nullptr, Type::Offset(offset), instance_id);\n@@ -1499,1 +1545,1 @@\n-                                       offset);\n+                                       Type::Offset(offset));\n@@ -1505,1 +1551,1 @@\n-        tj = tk = TypeInstKlassPtr::make(TypePtr::NotNull, env()->Object_klass(), offset);\n+        tj = tk = TypeInstKlassPtr::make(TypePtr::NotNull, env()->Object_klass(), Type::Offset(offset));\n@@ -1507,1 +1553,1 @@\n-        tj = tk = TypeAryKlassPtr::make(TypePtr::NotNull, tk->is_aryklassptr()->elem(), k, offset);\n+        tj = tk = TypeAryKlassPtr::make(TypePtr::NotNull, tk->is_aryklassptr()->elem(), k, Type::Offset(offset), tk->is_not_flat(), tk->is_not_null_free(), tk->is_flat(), tk->is_null_free());\n@@ -1510,1 +1556,0 @@\n-\n@@ -1640,1 +1685,1 @@\n-Compile::AliasType* Compile::find_alias_type(const TypePtr* adr_type, bool no_create, ciField* original_field) {\n+Compile::AliasType* Compile::find_alias_type(const TypePtr* adr_type, bool no_create, ciField* original_field, bool uncached) {\n@@ -1645,3 +1690,6 @@\n-  AliasCacheEntry* ace = probe_alias_cache(adr_type);\n-  if (ace->_adr_type == adr_type) {\n-    return alias_type(ace->_index);\n+  AliasCacheEntry* ace = nullptr;\n+  if (!uncached) {\n+    ace = probe_alias_cache(adr_type);\n+    if (ace->_adr_type == adr_type) {\n+      return alias_type(ace->_index);\n+    }\n@@ -1697,0 +1745,1 @@\n+    ciField* field = nullptr;\n@@ -1703,0 +1752,1 @@\n+      const Type* elemtype = flat->is_aryptr()->elem();\n@@ -1704,1 +1754,8 @@\n-        alias_type(idx)->set_element(flat->is_aryptr()->elem());\n+        alias_type(idx)->set_element(elemtype);\n+      }\n+      int field_offset = flat->is_aryptr()->field_offset().get();\n+      if (flat->is_flat() &&\n+          field_offset != Type::OffsetBot) {\n+        ciInlineKlass* vk = elemtype->inline_klass();\n+        field_offset += vk->payload_offset();\n+        field = vk->get_field_by_offset(field_offset, false);\n@@ -1720,0 +1777,2 @@\n+      if (flat->offset() == in_bytes(Klass::layout_helper_offset()))\n+        alias_type(idx)->set_rewritable(false);\n@@ -1730,1 +1789,0 @@\n-      ciField* field;\n@@ -1737,0 +1795,4 @@\n+      } else if (tinst->is_inlinetypeptr()) {\n+        \/\/ Inline type field\n+        ciInlineKlass* vk = tinst->inline_klass();\n+        field = vk->get_field_by_offset(tinst->offset(), false);\n@@ -1741,7 +1803,14 @@\n-      assert(field == nullptr ||\n-             original_field == nullptr ||\n-             (field->holder() == original_field->holder() &&\n-              field->offset_in_bytes() == original_field->offset_in_bytes() &&\n-              field->is_static() == original_field->is_static()), \"wrong field?\");\n-      \/\/ Set field() and is_rewritable() attributes.\n-      if (field != nullptr)  alias_type(idx)->set_field(field);\n+    }\n+    assert(field == nullptr ||\n+           original_field == nullptr ||\n+           (field->holder() == original_field->holder() &&\n+            field->offset_in_bytes() == original_field->offset_in_bytes() &&\n+            field->is_static() == original_field->is_static()), \"wrong field?\");\n+    \/\/ Set field() and is_rewritable() attributes.\n+    if (field != nullptr) {\n+      alias_type(idx)->set_field(field);\n+      if (flat->isa_aryptr()) {\n+        \/\/ Fields of flat arrays are rewritable although they are declared final\n+        assert(flat->is_flat(), \"must be a flat array\");\n+        alias_type(idx)->set_rewritable(true);\n+      }\n@@ -1752,3 +1821,4 @@\n-  ace->_adr_type = adr_type;\n-  ace->_index    = idx;\n-  assert(alias_type(adr_type) == alias_type(idx),  \"type must be installed\");\n+  if (!uncached) {\n+    ace->_adr_type = adr_type;\n+    ace->_index    = idx;\n+    assert(alias_type(adr_type) == alias_type(idx),  \"type must be installed\");\n@@ -1756,6 +1826,7 @@\n-  \/\/ Might as well try to fill the cache for the flattened version, too.\n-  AliasCacheEntry* face = probe_alias_cache(flat);\n-  if (face->_adr_type == nullptr) {\n-    face->_adr_type = flat;\n-    face->_index    = idx;\n-    assert(alias_type(flat) == alias_type(idx), \"flat type must work too\");\n+    \/\/ Might as well try to fill the cache for the flattened version, too.\n+    AliasCacheEntry* face = probe_alias_cache(flat);\n+    if (face->_adr_type == nullptr) {\n+      face->_adr_type = flat;\n+      face->_index    = idx;\n+      assert(alias_type(flat) == alias_type(idx), \"flat type must work too\");\n+    }\n@@ -1881,0 +1952,398 @@\n+void Compile::add_inline_type(Node* n) {\n+  assert(n->is_InlineType(), \"unexpected node\");\n+  _inline_type_nodes.push(n);\n+}\n+\n+void Compile::remove_inline_type(Node* n) {\n+  assert(n->is_InlineType(), \"unexpected node\");\n+  if (_inline_type_nodes.contains(n)) {\n+    _inline_type_nodes.remove(n);\n+  }\n+}\n+\n+\/\/ Does the return value keep otherwise useless inline type allocations alive?\n+static bool return_val_keeps_allocations_alive(Node* ret_val) {\n+  ResourceMark rm;\n+  Unique_Node_List wq;\n+  wq.push(ret_val);\n+  bool some_allocations = false;\n+  for (uint i = 0; i < wq.size(); i++) {\n+    Node* n = wq.at(i);\n+    if (n->outcnt() > 1) {\n+      \/\/ Some other use for the allocation\n+      return false;\n+    } else if (n->is_InlineType()) {\n+      wq.push(n->in(1));\n+    } else if (n->is_Phi()) {\n+      for (uint j = 1; j < n->req(); j++) {\n+        wq.push(n->in(j));\n+      }\n+    } else if (n->is_CheckCastPP() &&\n+               n->in(1)->is_Proj() &&\n+               n->in(1)->in(0)->is_Allocate()) {\n+      some_allocations = true;\n+    } else if (n->is_CheckCastPP()) {\n+      wq.push(n->in(1));\n+    }\n+  }\n+  return some_allocations;\n+}\n+\n+void Compile::process_inline_types(PhaseIterGVN &igvn, bool remove) {\n+  \/\/ Make sure that the return value does not keep an otherwise unused allocation alive\n+  if (tf()->returns_inline_type_as_fields()) {\n+    Node* ret = nullptr;\n+    for (uint i = 1; i < root()->req(); i++) {\n+      Node* in = root()->in(i);\n+      if (in->Opcode() == Op_Return) {\n+        assert(ret == nullptr, \"only one return\");\n+        ret = in;\n+      }\n+    }\n+    if (ret != nullptr) {\n+      Node* ret_val = ret->in(TypeFunc::Parms);\n+      if (igvn.type(ret_val)->isa_oopptr() &&\n+          return_val_keeps_allocations_alive(ret_val)) {\n+        igvn.replace_input_of(ret, TypeFunc::Parms, InlineTypeNode::tagged_klass(igvn.type(ret_val)->inline_klass(), igvn));\n+        assert(ret_val->outcnt() == 0, \"should be dead now\");\n+        igvn.remove_dead_node(ret_val);\n+      }\n+    }\n+  }\n+  if (_inline_type_nodes.length() == 0) {\n+    return;\n+  }\n+  \/\/ Scalarize inline types in safepoint debug info.\n+  \/\/ Delay this until all inlining is over to avoid getting inconsistent debug info.\n+  set_scalarize_in_safepoints(true);\n+  for (int i = _inline_type_nodes.length()-1; i >= 0; i--) {\n+    InlineTypeNode* vt = _inline_type_nodes.at(i)->as_InlineType();\n+    vt->make_scalar_in_safepoints(&igvn);\n+    igvn.record_for_igvn(vt);\n+  }\n+  if (remove) {\n+    \/\/ Remove inline type nodes by replacing them with their oop input\n+    while (_inline_type_nodes.length() > 0) {\n+      InlineTypeNode* vt = _inline_type_nodes.pop()->as_InlineType();\n+      if (vt->outcnt() == 0) {\n+        igvn.remove_dead_node(vt);\n+        continue;\n+      }\n+      for (DUIterator i = vt->outs(); vt->has_out(i); i++) {\n+        DEBUG_ONLY(bool must_be_buffered = false);\n+        Node* u = vt->out(i);\n+        \/\/ Check if any users are blackholes. If so, rewrite them to use either the\n+        \/\/ allocated buffer, or individual components, instead of the inline type node\n+        \/\/ that goes away.\n+        if (u->is_Blackhole()) {\n+          BlackholeNode* bh = u->as_Blackhole();\n+\n+          \/\/ Unlink the old input\n+          int idx = bh->find_edge(vt);\n+          assert(idx != -1, \"The edge should be there\");\n+          bh->del_req(idx);\n+          --i;\n+\n+          if (vt->is_allocated(&igvn)) {\n+            \/\/ Already has the allocated instance, blackhole that\n+            bh->add_req(vt->get_oop());\n+          } else {\n+            \/\/ Not allocated yet, blackhole the components\n+            for (uint c = 0; c < vt->field_count(); c++) {\n+              bh->add_req(vt->field_value(c));\n+            }\n+          }\n+\n+          \/\/ Node modified, record for IGVN\n+          igvn.record_for_igvn(bh);\n+        }\n+#ifdef ASSERT\n+        \/\/ Verify that inline type is buffered when replacing by oop\n+        else if (u->is_InlineType()) {\n+          \/\/ InlineType uses don't need buffering because they are about to be replaced as well\n+        } else if (u->is_Phi()) {\n+          \/\/ TODO 8302217 Remove this once InlineTypeNodes are reliably pushed through\n+        } else {\n+          must_be_buffered = true;\n+        }\n+        if (must_be_buffered && !vt->is_allocated(&igvn)) {\n+          vt->dump(0);\n+          u->dump(0);\n+          assert(false, \"Should have been buffered\");\n+        }\n+#endif\n+      }\n+      igvn.replace_node(vt, vt->get_oop());\n+    }\n+  }\n+  igvn.optimize();\n+}\n+\n+void Compile::adjust_flat_array_access_aliases(PhaseIterGVN& igvn) {\n+  if (!_has_flat_accesses) {\n+    return;\n+  }\n+  \/\/ Initially, all flat array accesses share the same slice to\n+  \/\/ keep dependencies with Object[] array accesses (that could be\n+  \/\/ to a flat array) correct. We're done with parsing so we\n+  \/\/ now know all flat array accesses in this compile\n+  \/\/ unit. Let's move flat array accesses to their own slice,\n+  \/\/ one per element field. This should help memory access\n+  \/\/ optimizations.\n+  ResourceMark rm;\n+  Unique_Node_List wq;\n+  wq.push(root());\n+\n+  Node_List mergememnodes;\n+  Node_List memnodes;\n+\n+  \/\/ Alias index currently shared by all flat memory accesses\n+  int index = get_alias_index(TypeAryPtr::INLINES);\n+\n+  \/\/ Find MergeMem nodes and flat array accesses\n+  for (uint i = 0; i < wq.size(); i++) {\n+    Node* n = wq.at(i);\n+    if (n->is_Mem()) {\n+      const TypePtr* adr_type = nullptr;\n+      adr_type = get_adr_type(get_alias_index(n->adr_type()));\n+      if (adr_type == TypeAryPtr::INLINES) {\n+        memnodes.push(n);\n+      }\n+    } else if (n->is_MergeMem()) {\n+      MergeMemNode* mm = n->as_MergeMem();\n+      if (mm->memory_at(index) != mm->base_memory()) {\n+        mergememnodes.push(n);\n+      }\n+    }\n+    for (uint j = 0; j < n->req(); j++) {\n+      Node* m = n->in(j);\n+      if (m != nullptr) {\n+        wq.push(m);\n+      }\n+    }\n+  }\n+\n+  if (memnodes.size() > 0) {\n+    _flat_accesses_share_alias = false;\n+\n+    \/\/ We are going to change the slice for the flat array\n+    \/\/ accesses so we need to clear the cache entries that refer to\n+    \/\/ them.\n+    for (uint i = 0; i < AliasCacheSize; i++) {\n+      AliasCacheEntry* ace = &_alias_cache[i];\n+      if (ace->_adr_type != nullptr &&\n+          ace->_adr_type->is_flat()) {\n+        ace->_adr_type = nullptr;\n+        ace->_index = (i != 0) ? 0 : AliasIdxTop; \/\/ Make sure the nullptr adr_type resolves to AliasIdxTop\n+      }\n+    }\n+\n+    \/\/ Find what aliases we are going to add\n+    int start_alias = num_alias_types()-1;\n+    int stop_alias = 0;\n+\n+    for (uint i = 0; i < memnodes.size(); i++) {\n+      Node* m = memnodes.at(i);\n+      const TypePtr* adr_type = nullptr;\n+      adr_type = m->adr_type();\n+#ifdef ASSERT\n+      m->as_Mem()->set_adr_type(adr_type);\n+#endif\n+      int idx = get_alias_index(adr_type);\n+      start_alias = MIN2(start_alias, idx);\n+      stop_alias = MAX2(stop_alias, idx);\n+    }\n+\n+    assert(stop_alias >= start_alias, \"should have expanded aliases\");\n+\n+    Node_Stack stack(0);\n+#ifdef ASSERT\n+    VectorSet seen(Thread::current()->resource_area());\n+#endif\n+    \/\/ Now let's fix the memory graph so each flat array access\n+    \/\/ is moved to the right slice. Start from the MergeMem nodes.\n+    uint last = unique();\n+    for (uint i = 0; i < mergememnodes.size(); i++) {\n+      MergeMemNode* current = mergememnodes.at(i)->as_MergeMem();\n+      Node* n = current->memory_at(index);\n+      MergeMemNode* mm = nullptr;\n+      do {\n+        \/\/ Follow memory edges through memory accesses, phis and\n+        \/\/ narrow membars and push nodes on the stack. Once we hit\n+        \/\/ bottom memory, we pop element off the stack one at a\n+        \/\/ time, in reverse order, and move them to the right slice\n+        \/\/ by changing their memory edges.\n+        if ((n->is_Phi() && n->adr_type() != TypePtr::BOTTOM) || n->is_Mem() || n->adr_type() == TypeAryPtr::INLINES) {\n+          assert(!seen.test_set(n->_idx), \"\");\n+          \/\/ Uses (a load for instance) will need to be moved to the\n+          \/\/ right slice as well and will get a new memory state\n+          \/\/ that we don't know yet. The use could also be the\n+          \/\/ backedge of a loop. We put a place holder node between\n+          \/\/ the memory node and its uses. We replace that place\n+          \/\/ holder with the correct memory state once we know it,\n+          \/\/ i.e. when nodes are popped off the stack. Using the\n+          \/\/ place holder make the logic work in the presence of\n+          \/\/ loops.\n+          if (n->outcnt() > 1) {\n+            Node* place_holder = nullptr;\n+            assert(!n->has_out_with(Op_Node), \"\");\n+            for (DUIterator k = n->outs(); n->has_out(k); k++) {\n+              Node* u = n->out(k);\n+              if (u != current && u->_idx < last) {\n+                bool success = false;\n+                for (uint l = 0; l < u->req(); l++) {\n+                  if (!stack.is_empty() && u == stack.node() && l == stack.index()) {\n+                    continue;\n+                  }\n+                  Node* in = u->in(l);\n+                  if (in == n) {\n+                    if (place_holder == nullptr) {\n+                      place_holder = new Node(1);\n+                      place_holder->init_req(0, n);\n+                    }\n+                    igvn.replace_input_of(u, l, place_holder);\n+                    success = true;\n+                  }\n+                }\n+                if (success) {\n+                  --k;\n+                }\n+              }\n+            }\n+          }\n+          if (n->is_Phi()) {\n+            stack.push(n, 1);\n+            n = n->in(1);\n+          } else if (n->is_Mem()) {\n+            stack.push(n, n->req());\n+            n = n->in(MemNode::Memory);\n+          } else {\n+            assert(n->is_Proj() && n->in(0)->Opcode() == Op_MemBarCPUOrder, \"\");\n+            stack.push(n, n->req());\n+            n = n->in(0)->in(TypeFunc::Memory);\n+          }\n+        } else {\n+          assert(n->adr_type() == TypePtr::BOTTOM || (n->Opcode() == Op_Node && n->_idx >= last) || (n->is_Proj() && n->in(0)->is_Initialize()), \"\");\n+          \/\/ Build a new MergeMem node to carry the new memory state\n+          \/\/ as we build it. IGVN should fold extraneous MergeMem\n+          \/\/ nodes.\n+          mm = MergeMemNode::make(n);\n+          igvn.register_new_node_with_optimizer(mm);\n+          while (stack.size() > 0) {\n+            Node* m = stack.node();\n+            uint idx = stack.index();\n+            if (m->is_Mem()) {\n+              \/\/ Move memory node to its new slice\n+              const TypePtr* adr_type = m->adr_type();\n+              int alias = get_alias_index(adr_type);\n+              Node* prev = mm->memory_at(alias);\n+              igvn.replace_input_of(m, MemNode::Memory, prev);\n+              mm->set_memory_at(alias, m);\n+            } else if (m->is_Phi()) {\n+              \/\/ We need as many new phis as there are new aliases\n+              igvn.replace_input_of(m, idx, mm);\n+              if (idx == m->req()-1) {\n+                Node* r = m->in(0);\n+                for (uint j = (uint)start_alias; j <= (uint)stop_alias; j++) {\n+                  const TypePtr* adr_type = get_adr_type(j);\n+                  if (!adr_type->isa_aryptr() || !adr_type->is_flat() || j == (uint)index) {\n+                    continue;\n+                  }\n+                  Node* phi = new PhiNode(r, Type::MEMORY, get_adr_type(j));\n+                  igvn.register_new_node_with_optimizer(phi);\n+                  for (uint k = 1; k < m->req(); k++) {\n+                    phi->init_req(k, m->in(k)->as_MergeMem()->memory_at(j));\n+                  }\n+                  mm->set_memory_at(j, phi);\n+                }\n+                Node* base_phi = new PhiNode(r, Type::MEMORY, TypePtr::BOTTOM);\n+                igvn.register_new_node_with_optimizer(base_phi);\n+                for (uint k = 1; k < m->req(); k++) {\n+                  base_phi->init_req(k, m->in(k)->as_MergeMem()->base_memory());\n+                }\n+                mm->set_base_memory(base_phi);\n+              }\n+            } else {\n+              \/\/ This is a MemBarCPUOrder node from\n+              \/\/ Parse::array_load()\/Parse::array_store(), in the\n+              \/\/ branch that handles flat arrays hidden under\n+              \/\/ an Object[] array. We also need one new membar per\n+              \/\/ new alias to keep the unknown access that the\n+              \/\/ membars protect properly ordered with accesses to\n+              \/\/ known flat array.\n+              assert(m->is_Proj(), \"projection expected\");\n+              Node* ctrl = m->in(0)->in(TypeFunc::Control);\n+              igvn.replace_input_of(m->in(0), TypeFunc::Control, top());\n+              for (uint j = (uint)start_alias; j <= (uint)stop_alias; j++) {\n+                const TypePtr* adr_type = get_adr_type(j);\n+                if (!adr_type->isa_aryptr() || !adr_type->is_flat() || j == (uint)index) {\n+                  continue;\n+                }\n+                MemBarNode* mb = new MemBarCPUOrderNode(this, j, nullptr);\n+                igvn.register_new_node_with_optimizer(mb);\n+                Node* mem = mm->memory_at(j);\n+                mb->init_req(TypeFunc::Control, ctrl);\n+                mb->init_req(TypeFunc::Memory, mem);\n+                ctrl = new ProjNode(mb, TypeFunc::Control);\n+                igvn.register_new_node_with_optimizer(ctrl);\n+                mem = new ProjNode(mb, TypeFunc::Memory);\n+                igvn.register_new_node_with_optimizer(mem);\n+                mm->set_memory_at(j, mem);\n+              }\n+              igvn.replace_node(m->in(0)->as_Multi()->proj_out(TypeFunc::Control), ctrl);\n+            }\n+            if (idx < m->req()-1) {\n+              idx += 1;\n+              stack.set_index(idx);\n+              n = m->in(idx);\n+              break;\n+            }\n+            \/\/ Take care of place holder nodes\n+            if (m->has_out_with(Op_Node)) {\n+              Node* place_holder = m->find_out_with(Op_Node);\n+              if (place_holder != nullptr) {\n+                Node* mm_clone = mm->clone();\n+                igvn.register_new_node_with_optimizer(mm_clone);\n+                Node* hook = new Node(1);\n+                hook->init_req(0, mm);\n+                igvn.replace_node(place_holder, mm_clone);\n+                hook->destruct(&igvn);\n+              }\n+              assert(!m->has_out_with(Op_Node), \"place holder should be gone now\");\n+            }\n+            stack.pop();\n+          }\n+        }\n+      } while(stack.size() > 0);\n+      \/\/ Fix the memory state at the MergeMem we started from\n+      igvn.rehash_node_delayed(current);\n+      for (uint j = (uint)start_alias; j <= (uint)stop_alias; j++) {\n+        const TypePtr* adr_type = get_adr_type(j);\n+        if (!adr_type->isa_aryptr() || !adr_type->is_flat()) {\n+          continue;\n+        }\n+        current->set_memory_at(j, mm);\n+      }\n+      current->set_memory_at(index, current->base_memory());\n+    }\n+    igvn.optimize();\n+  }\n+  print_method(PHASE_SPLIT_INLINES_ARRAY, 2);\n+#ifdef ASSERT\n+  if (!_flat_accesses_share_alias) {\n+    wq.clear();\n+    wq.push(root());\n+    for (uint i = 0; i < wq.size(); i++) {\n+      Node* n = wq.at(i);\n+      assert(n->adr_type() != TypeAryPtr::INLINES, \"should have been removed from the graph\");\n+      for (uint j = 0; j < n->req(); j++) {\n+        Node* m = n->in(j);\n+        if (m != nullptr) {\n+          wq.push(m);\n+        }\n+      }\n+    }\n+  }\n+#endif\n+}\n+\n@@ -1999,1 +2468,1 @@\n-        if (!live_locals.at(i) && !local->is_top() && local != lhs && local!= rhs) {\n+        if (!live_locals.at(i) && !local->is_top() && local != lhs && local != rhs) {\n@@ -2014,1 +2483,1 @@\n-    \/\/ keep the mondified trap for late query\n+    \/\/ keep the modified trap for late query\n@@ -2209,1 +2678,4 @@\n-  assert(_modified_nodes == nullptr, \"not allowed\");\n+#ifdef ASSERT\n+  Unique_Node_List* modified_nodes = _modified_nodes;\n+  _modified_nodes = nullptr;\n+#endif\n@@ -2222,0 +2694,1 @@\n+  DEBUG_ONLY( _modified_nodes = modified_nodes; )\n@@ -2366,0 +2839,5 @@\n+  \/\/ Process inline type nodes now that all inlining is over\n+  process_inline_types(igvn);\n+\n+  adjust_flat_array_access_aliases(igvn);\n+\n@@ -2491,0 +2969,8 @@\n+  assert(_late_inlines.length() == 0 || IncrementalInlineMH || IncrementalInlineVirtual, \"not empty\");\n+\n+  if (_late_inlines.length() > 0) {\n+    \/\/ More opportunities to optimize virtual and MH calls.\n+    \/\/ Though it's maybe too late to perform inlining, strength-reducing them to direct calls is still an option.\n+    process_late_inline_calls_no_inline(igvn);\n+  }\n+\n@@ -2502,0 +2988,4 @@\n+  \/\/ Process inline type nodes again and remove them. From here\n+  \/\/ on we don't need to keep track of field values anymore.\n+  process_inline_types(igvn, \/* remove= *\/ true);\n+\n@@ -2518,0 +3008,1 @@\n+  DEBUG_ONLY( _late_inlines.clear(); )\n@@ -2520,9 +3011,0 @@\n-\n-  assert(_late_inlines.length() == 0 || IncrementalInlineMH || IncrementalInlineVirtual, \"not empty\");\n-\n-  if (_late_inlines.length() > 0) {\n-    \/\/ More opportunities to optimize virtual and MH calls.\n-    \/\/ Though it's maybe too late to perform inlining, strength-reducing them to direct calls is still an option.\n-    process_late_inline_calls_no_inline(igvn);\n-    if (failing())  return;\n-  }\n@@ -3301,0 +3783,1 @@\n+  case Op_StoreLSpecial:\n@@ -3844,0 +4327,5 @@\n+  case Op_InlineType: {\n+    n->dump(-1);\n+    assert(false, \"inline type node was not removed\");\n+    break;\n+  }\n@@ -4230,2 +4718,2 @@\n-      if (accessing_method->is_static_initializer() ||\n-          accessing_method->is_object_initializer() ||\n+      if (accessing_method->is_class_initializer() ||\n+          accessing_method->is_object_constructor() ||\n@@ -4239,1 +4727,1 @@\n-      if (accessing_method->is_static_initializer()) {\n+      if (accessing_method->is_class_initializer()) {\n@@ -4295,0 +4783,1 @@\n+               (n->is_Allocate() && i >= AllocateNode::InlineType) ||\n@@ -4297,1 +4786,1 @@\n-              \"only region, phi, arraycopy, unlock or membar nodes have null data edges\");\n+              \"only region, phi, arraycopy, allocate, unlock or membar nodes have null data edges\");\n@@ -4448,0 +4937,7 @@\n+\n+    \/\/ Do not fold the subtype check to an array klass pointer comparison for null-able inline type arrays\n+    \/\/ because null-free [LMyValue <: null-able [LMyValue but the klasses are different. Perform a full test.\n+    if (!superk->is_aryklassptr()->is_null_free() && superk->is_aryklassptr()->elem()->isa_instklassptr() &&\n+        superk->is_aryklassptr()->elem()->is_instklassptr()->instance_klass()->is_inlinetype()) {\n+      return SSC_full_test;\n+    }\n@@ -4929,0 +5425,21 @@\n+Node* Compile::optimize_acmp(PhaseGVN* phase, Node* a, Node* b) {\n+  const TypeInstPtr* ta = phase->type(a)->isa_instptr();\n+  const TypeInstPtr* tb = phase->type(b)->isa_instptr();\n+  if (!EnableValhalla || ta == nullptr || tb == nullptr ||\n+      ta->is_zero_type() || tb->is_zero_type() ||\n+      !ta->can_be_inline_type() || !tb->can_be_inline_type()) {\n+    \/\/ Use old acmp if one operand is null or not an inline type\n+    return new CmpPNode(a, b);\n+  } else if (ta->is_inlinetypeptr() || tb->is_inlinetypeptr()) {\n+    \/\/ We know that one operand is an inline type. Therefore,\n+    \/\/ new acmp will only return true if both operands are nullptr.\n+    \/\/ Check if both operands are null by or'ing the oops.\n+    a = phase->transform(new CastP2XNode(nullptr, a));\n+    b = phase->transform(new CastP2XNode(nullptr, b));\n+    a = phase->transform(new OrXNode(a, b));\n+    return new CmpXNode(a, phase->MakeConX(0));\n+  }\n+  \/\/ Use new acmp\n+  return nullptr;\n+}\n+\n@@ -5274,0 +5791,2 @@\n+  } else if (bt == T_FLOAT) {\n+    result = new MoveI2FNode(value);\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":574,"deletions":55,"binary":false,"changes":629,"status":"modified"},{"patch":"@@ -56,0 +56,1 @@\n+class CallNode;\n@@ -98,0 +99,1 @@\n+class InlineTypeNode;\n@@ -334,0 +336,1 @@\n+  bool                  _has_circular_inline_type; \/\/ True if method loads an inline type with a circular, non-flat field\n@@ -361,0 +364,3 @@\n+  bool                  _has_flat_accesses;     \/\/ Any known flat array accesses?\n+  bool                  _flat_accesses_share_alias; \/\/ Initially all flat array share a single slice\n+  bool                  _scalarize_in_safepoints; \/\/ Scalarize inline types in safepoint debug info\n@@ -378,0 +384,1 @@\n+  GrowableArray<Node*>  _inline_type_nodes;     \/\/ List of InlineType nodes\n@@ -604,0 +611,2 @@\n+  bool              has_circular_inline_type() const { return _has_circular_inline_type; }\n+  void          set_has_circular_inline_type(bool z) { _has_circular_inline_type = z; }\n@@ -636,0 +645,10 @@\n+  void          set_flat_accesses()              { _has_flat_accesses = true; }\n+  bool          flat_accesses_share_alias() const { return _flat_accesses_share_alias; }\n+  void          set_flat_accesses_share_alias(bool z) { _flat_accesses_share_alias = z; }\n+  bool          scalarize_in_safepoints() const { return _scalarize_in_safepoints; }\n+  void          set_scalarize_in_safepoints(bool z) { _scalarize_in_safepoints = z; }\n+\n+  \/\/ Support for scalarized inline type calling convention\n+  bool              has_scalarized_args() const  { return _method != nullptr && _method->has_scalarized_args(); }\n+  bool              needs_stack_repair()  const  { return _method != nullptr && _method->get_Method()->c2_needs_stack_repair(); }\n+\n@@ -766,0 +785,7 @@\n+  \/\/ Keep track of inline type nodes for later processing\n+  void add_inline_type(Node* n);\n+  void remove_inline_type(Node* n);\n+  void process_inline_types(PhaseIterGVN &igvn, bool remove = false);\n+\n+  void adjust_flat_array_access_aliases(PhaseIterGVN& igvn);\n+\n@@ -948,1 +974,1 @@\n-  AliasType*        alias_type(const TypePtr* adr_type, ciField* field = nullptr) { return find_alias_type(adr_type, false, field); }\n+  AliasType*        alias_type(const TypePtr* adr_type, ciField* field = nullptr, bool uncached = false) { return find_alias_type(adr_type, false, field, uncached); }\n@@ -952,1 +978,1 @@\n-  int               get_alias_index(const TypePtr* at)  { return alias_type(at)->index(); }\n+  int               get_alias_index(const TypePtr* at, bool uncached = false) { return alias_type(at, nullptr, uncached)->index(); }\n@@ -1193,1 +1219,1 @@\n-  AliasType* find_alias_type(const TypePtr* adr_type, bool no_create, ciField* field);\n+  AliasType* find_alias_type(const TypePtr* adr_type, bool no_create, ciField* field, bool uncached = false);\n@@ -1269,1 +1295,3 @@\n-  \/\/ Auxiliary methods for randomized fuzzing\/stressing\n+  Node* optimize_acmp(PhaseGVN* phase, Node* a, Node* b);\n+\n+  \/\/ Auxiliary method for randomized fuzzing\/stressing\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":32,"deletions":4,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"memory\/metaspace.hpp\"\n@@ -38,0 +39,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -166,0 +168,10 @@\n+    if ((n->Opcode() == Op_LoadX || n->Opcode() == Op_StoreX) &&\n+        !n->in(MemNode::Address)->is_AddP() &&\n+        _igvn->type(n->in(MemNode::Address))->isa_oopptr()) {\n+      \/\/ Load\/Store at mark work address is at offset 0 so has no AddP which confuses EA\n+      Node* addp = new AddPNode(n->in(MemNode::Address), n->in(MemNode::Address), _igvn->MakeConX(0));\n+      _igvn->register_new_node_with_optimizer(addp);\n+      _igvn->replace_input_of(n, MemNode::Address, addp);\n+      ideal_nodes.push(addp);\n+      _nodes.at_put_grow(addp->_idx, nullptr, nullptr);\n+    }\n@@ -1255,1 +1267,9 @@\n-      SafePointScalarObjectNode* sobj = mexp.create_scalarized_object_description(alloc, sfpt);\n+      Unique_Node_List value_worklist;\n+#ifdef ASSERT\n+      const Type* res_type = alloc->result_cast()->bottom_type();\n+      if (res_type->is_inlinetypeptr() && !Compile::current()->has_circular_inline_type()) {\n+        PhiNode* phi = ophi->as_Phi();\n+        assert(!ophi->as_Phi()->can_push_inline_types_down(_igvn), \"missed earlier scalarization opportunity\");\n+      }\n+#endif\n+      SafePointScalarObjectNode* sobj = mexp.create_scalarized_object_description(alloc, sfpt, &value_worklist);\n@@ -1257,0 +1277,1 @@\n+        _compile->record_failure(C2Compiler::retry_no_reduce_allocation_merges());\n@@ -1267,0 +1288,9 @@\n+\n+      \/\/ Scalarize inline types that were added to the safepoint.\n+      \/\/ Don't allow linking a constant oop (if available) for flat array elements\n+      \/\/ because Deoptimization::reassign_flat_array_elements needs field values.\n+      const bool allow_oop = !merge_t->is_flat();\n+      for (uint j = 0; j < value_worklist.size(); ++j) {\n+        InlineTypeNode* vt = value_worklist.at(j)->as_InlineType();\n+        vt->make_scalar_in_safepoints(_igvn, allow_oop);\n+      }\n@@ -1465,1 +1495,1 @@\n-      const TypeTuple* d = call->tf()->domain();\n+      const TypeTuple* d = call->tf()->domain_sig();\n@@ -1539,0 +1569,11 @@\n+      } else if (n->as_Call()->tf()->returns_inline_type_as_fields()) {\n+        bool returns_oop = false;\n+        for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax && !returns_oop; i++) {\n+          ProjNode* pn = n->fast_out(i)->as_Proj();\n+          if (pn->_con >= TypeFunc::Parms && pn->bottom_type()->isa_ptr()) {\n+            returns_oop = true;\n+          }\n+        }\n+        if (returns_oop) {\n+          add_call_node(n->as_Call());\n+        }\n@@ -1566,1 +1607,2 @@\n-    case Op_CastX2P: {\n+    case Op_CastX2P:\n+    case Op_CastI2N: {\n@@ -1570,0 +1612,1 @@\n+    case Op_InlineType:\n@@ -1641,2 +1684,4 @@\n-      if (n->as_Proj()->_con == TypeFunc::Parms && n->in(0)->is_Call() &&\n-          n->in(0)->as_Call()->returns_pointer()) {\n+      if (n->as_Proj()->_con >= TypeFunc::Parms && n->in(0)->is_Call() &&\n+          (n->in(0)->as_Call()->returns_pointer() || n->bottom_type()->isa_ptr())) {\n+        assert((n->as_Proj()->_con == TypeFunc::Parms && n->in(0)->as_Call()->returns_pointer()) ||\n+               n->in(0)->as_Call()->tf()->returns_inline_type_as_fields(), \"what kind of oop return is it?\");\n@@ -1744,0 +1789,1 @@\n+    case Op_InlineType:\n@@ -1798,2 +1844,2 @@\n-      assert(n->as_Proj()->_con == TypeFunc::Parms && n->in(0)->is_Call() &&\n-             n->in(0)->as_Call()->returns_pointer(), \"Unexpected node type\");\n+      assert((n->as_Proj()->_con == TypeFunc::Parms && n->in(0)->as_Call()->returns_pointer()) ||\n+             n->in(0)->as_Call()->tf()->returns_inline_type_as_fields(), \"what kind of oop return is it?\");\n@@ -1975,1 +2021,1 @@\n-  assert(call->returns_pointer(), \"only for call which returns pointer\");\n+  assert(call->returns_pointer() || call->tf()->returns_inline_type_as_fields(), \"only for call which returns pointer\");\n@@ -2051,1 +2097,2 @@\n-      assert(strncmp(name, \"C2 Runtime multianewarray\", 25) == 0, \"TODO: add failed case check\");\n+      assert(strncmp(name, \"C2 Runtime multianewarray\", 25) == 0 ||\n+             strncmp(name, \"C2 Runtime load_unknown_inline\", 30) == 0, \"TODO: add failed case check\");\n@@ -2082,1 +2129,1 @@\n-        const TypeTuple* d = call->tf()->domain();\n+        const TypeTuple* d = call->tf()->domain_cc();\n@@ -2130,1 +2177,1 @@\n-      const TypeTuple * d = call->tf()->domain();\n+      const TypeTuple * d = call->tf()->domain_sig();\n@@ -2161,1 +2208,4 @@\n-                               (aat->isa_aryptr() && (aat->isa_aryptr()->elem() == Type::BOTTOM || aat->isa_aryptr()->elem()->make_oopptr() != nullptr)));\n+                               (aat->isa_aryptr() && (aat->isa_aryptr()->elem() == Type::BOTTOM || aat->isa_aryptr()->elem()->make_oopptr() != nullptr)) ||\n+                               (aat->isa_aryptr() && aat->isa_aryptr()->elem() != nullptr &&\n+                                                               aat->isa_aryptr()->is_flat() &&\n+                                                               aat->isa_aryptr()->elem()->inline_klass()->contains_oops()));\n@@ -2218,0 +2268,3 @@\n+                  strcmp(call->as_CallLeaf()->_name, \"vectorizedMismatch\") == 0 ||\n+                  strcmp(call->as_CallLeaf()->_name, \"load_unknown_inline\") == 0 ||\n+                  strcmp(call->as_CallLeaf()->_name, \"store_unknown_inline\") == 0 ||\n@@ -2284,1 +2337,1 @@\n-        const TypeTuple* d = call->tf()->domain();\n+        const TypeTuple* d = call->tf()->domain_cc();\n@@ -2328,1 +2381,1 @@\n-      const TypeTuple* d = call->tf()->domain();\n+      const TypeTuple* d = call->tf()->domain_cc();\n@@ -2741,0 +2794,1 @@\n+  PointsToNode* init_val = phantom_obj;\n@@ -2746,1 +2800,8 @@\n-    return 0;\n+    if (alloc->as_Allocate()->in(AllocateNode::DefaultValue) != nullptr) {\n+      \/\/ Non-flat inline type arrays are initialized with\n+      \/\/ the default value instead of null. Handle them here.\n+      init_val = ptnode_adr(alloc->as_Allocate()->in(AllocateNode::DefaultValue)->_idx);\n+      assert(init_val != nullptr, \"default value should be registered\");\n+    } else {\n+      return 0;\n+    }\n@@ -2748,1 +2809,2 @@\n-  assert(pta->arraycopy_dst() || alloc->as_CallStaticJava(), \"sanity\");\n+  \/\/ Non-escaped allocation returned from Java or runtime call has unknown values in fields.\n+  assert(pta->arraycopy_dst() || alloc->is_CallStaticJava() || init_val != phantom_obj, \"sanity\");\n@@ -2750,1 +2812,1 @@\n-  if (!pta->arraycopy_dst() && alloc->as_CallStaticJava()->method() == nullptr) {\n+  if (alloc->is_CallStaticJava() && alloc->as_CallStaticJava()->method() == nullptr) {\n@@ -2752,1 +2814,2 @@\n-    assert(strncmp(name, \"C2 Runtime multianewarray\", 25) == 0, \"sanity\");\n+    assert(strncmp(name, \"C2 Runtime multianewarray\", 25) == 0 ||\n+           strncmp(name, \"C2 Runtime load_unknown_inline\", 30) == 0, \"sanity\");\n@@ -2760,1 +2823,1 @@\n-      if (add_edge(field, phantom_obj)) {\n+      if (add_edge(field, init_val)) {\n@@ -2775,1 +2838,1 @@\n-  if (!alloc->is_Allocate()) {\n+  if (!alloc->is_Allocate() || alloc->as_Allocate()->in(AllocateNode::DefaultValue) != nullptr) {\n@@ -2861,1 +2924,1 @@\n-                tty->print_cr(\"----------missed referernce to object-----------\");\n+                tty->print_cr(\"----------missed reference to object------------\");\n@@ -2863,1 +2926,1 @@\n-                tty->print_cr(\"----------object referernced by init store -----\");\n+                tty->print_cr(\"----------object referenced by init store-------\");\n@@ -3219,1 +3282,2 @@\n-          if (can_eliminate_lock(alock)) {\n+          const Type* obj_type = igvn->type(alock->obj_node());\n+          if (can_eliminate_lock(alock) && !obj_type->is_inlinetypeptr()) {\n@@ -3261,5 +3325,10 @@\n-      MemBarNode* mb = MemBarNode::make(C, Op_MemBarCPUOrder, Compile::AliasIdxBot);\n-      mb->init_req(TypeFunc::Memory,  storestore->in(TypeFunc::Memory));\n-      mb->init_req(TypeFunc::Control, storestore->in(TypeFunc::Control));\n-      igvn->register_new_node_with_optimizer(mb);\n-      igvn->replace_node(storestore, mb);\n+      if (alloc->in(AllocateNode::InlineType) != nullptr) {\n+        \/\/ Non-escaping inline type buffer allocations don't require a membar\n+        storestore->as_MemBar()->remove(_igvn);\n+      } else {\n+        MemBarNode* mb = MemBarNode::make(C, Op_MemBarCPUOrder, Compile::AliasIdxBot);\n+        mb->init_req(TypeFunc::Memory,  storestore->in(TypeFunc::Memory));\n+        mb->init_req(TypeFunc::Control, storestore->in(TypeFunc::Control));\n+        igvn->register_new_node_with_optimizer(mb);\n+        igvn->replace_node(storestore, mb);\n+      }\n@@ -3427,0 +3496,1 @@\n+  int field_offset = adr_type->isa_aryptr() ? adr_type->isa_aryptr()->field_offset().get() : Type::OffsetBot;\n@@ -3428,1 +3498,1 @@\n-  if (offset == Type::OffsetBot) {\n+  if (offset == Type::OffsetBot && field_offset == Type::OffsetBot) {\n@@ -3440,1 +3510,1 @@\n-      ciField* field = _compile->alias_type(adr_type->isa_instptr())->field();\n+      ciField* field = _compile->alias_type(adr_type->is_ptr())->field();\n@@ -3459,2 +3529,8 @@\n-        const Type* elemtype = adr_type->isa_aryptr()->elem();\n-        bt = elemtype->array_element_basic_type();\n+        const Type* elemtype = adr_type->is_aryptr()->elem();\n+        if (adr_type->is_aryptr()->is_flat() && field_offset != Type::OffsetBot) {\n+          ciInlineKlass* vk = elemtype->inline_klass();\n+          field_offset += vk->payload_offset();\n+          bt = vk->get_field_by_offset(field_offset, false)->layout_type();\n+        } else {\n+          bt = elemtype->array_element_basic_type();\n+        }\n@@ -3657,3 +3733,1 @@\n-  const TypePtr *t_ptr = adr_type->isa_ptr();\n-  assert(t_ptr != nullptr, \"must be a pointer type\");\n-  return t_ptr->offset();\n+  return adr_type->is_ptr()->flat_offset();\n@@ -3813,1 +3887,8 @@\n-    t = base_t->add_offset(offs)->is_oopptr();\n+    if (base_t->isa_aryptr() != nullptr) {\n+      \/\/ In the case of a flat inline type array, each field has its\n+      \/\/ own slice so we need to extract the field being accessed from\n+      \/\/ the address computation\n+      t = base_t->isa_aryptr()->add_field_offset_and_offset(offs)->is_oopptr();\n+    } else {\n+      t = base_t->add_offset(offs)->is_oopptr();\n+    }\n@@ -3815,1 +3896,1 @@\n-  int inst_id =  base_t->instance_id();\n+  int inst_id = base_t->instance_id();\n@@ -3829,1 +3910,1 @@\n-  \/\/ It could happened when CHA type is different from MDO type on a dead path\n+  \/\/ It could happen when CHA type is different from MDO type on a dead path\n@@ -3839,1 +3920,12 @@\n-  const TypeOopPtr *tinst = base_t->add_offset(t->offset())->is_oopptr();\n+  const TypePtr* tinst = base_t->add_offset(t->offset());\n+  if (tinst->isa_aryptr() && t->isa_aryptr()) {\n+    \/\/ In the case of a flat inline type array, each field has its\n+    \/\/ own slice so we need to keep track of the field being accessed.\n+    tinst = tinst->is_aryptr()->with_field_offset(t->is_aryptr()->field_offset().get());\n+    \/\/ Keep array properties (not flat\/null-free)\n+    tinst = tinst->is_aryptr()->update_properties(t->is_aryptr());\n+    if (tinst == nullptr) {\n+      return false; \/\/ Skip dead path with inconsistent properties\n+    }\n+  }\n+\n@@ -4545,0 +4637,7 @@\n+          if (tn_t->isa_aryptr()) {\n+            \/\/ Keep array properties (not flat\/null-free)\n+            tinst = tinst->is_aryptr()->update_properties(tn_t->is_aryptr());\n+            if (tinst == nullptr) {\n+              continue; \/\/ Skip dead path with inconsistent properties\n+            }\n+          }\n@@ -4570,1 +4669,1 @@\n-      if(use->is_Mem() && use->in(MemNode::Address) == n) {\n+      if (use->is_Mem() && use->in(MemNode::Address) == n) {\n@@ -4606,0 +4705,3 @@\n+      } else if (use->Opcode() == Op_Return) {\n+        \/\/ Allocation is referenced by field of returned inline type\n+        assert(_compile->tf()->returns_inline_type_as_fields(), \"EA: unexpected reference by ReturnNode\");\n@@ -4619,1 +4721,1 @@\n-              op == Op_SubTypeCheck ||\n+              op == Op_SubTypeCheck || op == Op_InlineType || op == Op_FlatArrayCheck ||\n@@ -4723,0 +4825,3 @@\n+    } else if (n->is_CallLeaf() && n->as_CallLeaf()->_name != nullptr &&\n+               strcmp(n->as_CallLeaf()->_name, \"store_unknown_inline\") == 0) {\n+      n = n->as_CallLeaf()->proj_out(TypeFunc::Memory);\n@@ -4767,1 +4872,1 @@\n-      } else if(use->is_Mem()) {\n+      } else if (use->is_Mem()) {\n@@ -4776,0 +4881,4 @@\n+      } else if (use->is_CallLeaf() && use->as_CallLeaf()->_name != nullptr &&\n+                 strcmp(use->as_CallLeaf()->_name, \"store_unknown_inline\") == 0) {\n+        \/\/ store_unknown_inline overwrites destination array\n+        memnode_worklist.append_if_missing(use);\n@@ -4785,1 +4894,1 @@\n-              op == Op_StrEquals || op == Op_StrIndexOf || op == Op_StrIndexOfChar)) {\n+              op == Op_StrEquals || op == Op_StrIndexOf || op == Op_StrIndexOfChar || op == Op_FlatArrayCheck)) {\n@@ -4886,1 +4995,1 @@\n-  \/\/ chains as is done in split_memory_phi() since they  will\n+  \/\/ chains as is done in split_memory_phi() since they will\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":153,"deletions":44,"binary":false,"changes":197,"status":"modified"},{"patch":"@@ -2495,1 +2495,2 @@\n-      assert(outer->outcnt() >= phis + 2 - be_loads && outer->outcnt() <= phis + 2 + stores + 1, \"only phis\");\n+      \/\/ TODO: 8353717\n+      \/\/assert(outer->outcnt() >= phis + 2 - be_loads && outer->outcnt() <= phis + 2 + stores + 1, \"only phis\");\n","filename":"src\/hotspot\/share\/opto\/loopnode.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -46,0 +46,1 @@\n+class UnswitchCandidate;\n@@ -88,1 +89,1 @@\n-       };\n+         FlatArrays            = 1<<18};\n@@ -111,0 +112,1 @@\n+  bool is_flat_arrays() const { return _loop_flags & FlatArrays; }\n@@ -124,0 +126,1 @@\n+  void mark_flat_arrays() { _loop_flags |= FlatArrays; }\n@@ -727,0 +730,1 @@\n+  bool no_unswitch_candidate() const;\n@@ -1480,1 +1484,2 @@\n-  IfNode* find_unswitch_candidate(const IdealLoopTree* loop) const;\n+  IfNode* find_unswitch_candidates(const IdealLoopTree* loop, Node_List& flat_array_checks) const;\n+  IfNode* find_unswitch_candidate_from_idoms(const IdealLoopTree* loop) const;\n@@ -1487,1 +1492,1 @@\n-                                   const UnswitchedLoopSelector& unswitched_loop_selector);\n+                                   const UnswitchCandidate& unswitch_candidate, const IfNode* loop_selector);\n@@ -1495,0 +1500,1 @@\n+                                            const UnswitchCandidate& unswitch_candidate,\n@@ -1636,0 +1642,1 @@\n+  void move_flat_array_check_out_of_loop(Node* n);\n@@ -1637,0 +1644,1 @@\n+  bool flat_array_element_type_check(Node *n);\n@@ -1826,0 +1834,2 @@\n+  void collect_flat_array_checks(const IdealLoopTree* loop, Node_List& flat_array_checks) const;\n+\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":13,"deletions":3,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -66,0 +67,6 @@\n+  \/\/ Inline types should not be split through Phis because they cannot be merged\n+  \/\/ through Phi nodes but each value input needs to be merged individually.\n+  if (n->is_InlineType()) {\n+    return nullptr;\n+  }\n+\n@@ -763,0 +770,4 @@\n+      if (inp->isa_InlineType()) {\n+        \/\/ TODO 8302217 This prevents PhiNode::push_inline_types_through\n+        return nullptr;\n+      }\n@@ -1099,0 +1110,48 @@\n+\/\/ We can't use immutable memory for the flat array check because we are loading the mark word which is\n+\/\/ mutable. Although the bits we are interested in are immutable (we check for markWord::unlocked_value),\n+\/\/ we need to use raw memory to not break anti dependency analysis. Below code will attempt to still move\n+\/\/ flat array checks out of loops, mainly to enable loop unswitching.\n+void PhaseIdealLoop::move_flat_array_check_out_of_loop(Node* n) {\n+  \/\/ Skip checks for more than one array\n+  if (n->req() > 3) {\n+    return;\n+  }\n+  Node* mem = n->in(FlatArrayCheckNode::Memory);\n+  Node* array = n->in(FlatArrayCheckNode::ArrayOrKlass)->uncast();\n+  IdealLoopTree* check_loop = get_loop(get_ctrl(n));\n+  IdealLoopTree* ary_loop = get_loop(get_ctrl(array));\n+\n+  \/\/ Check if array is loop invariant\n+  if (!check_loop->is_member(ary_loop)) {\n+    \/\/ Walk up memory graph from the check until we leave the loop\n+    VectorSet wq;\n+    wq.set(mem->_idx);\n+    while (check_loop->is_member(get_loop(ctrl_or_self(mem)))) {\n+      if (mem->is_Phi()) {\n+        mem = mem->in(1);\n+      } else if (mem->is_MergeMem()) {\n+        mem = mem->as_MergeMem()->memory_at(Compile::AliasIdxRaw);\n+      } else if (mem->is_Proj()) {\n+        mem = mem->in(0);\n+      } else if (mem->is_MemBar() || mem->is_SafePoint()) {\n+        mem = mem->in(TypeFunc::Memory);\n+      } else if (mem->is_Store() || mem->is_LoadStore() || mem->is_ClearArray()) {\n+        mem = mem->in(MemNode::Memory);\n+      } else {\n+#ifdef ASSERT\n+        mem->dump();\n+#endif\n+        ShouldNotReachHere();\n+      }\n+      if (wq.test_set(mem->_idx)) {\n+        return;\n+      }\n+    }\n+    \/\/ Replace memory input and re-compute ctrl to move the check out of the loop\n+    _igvn.replace_input_of(n, 1, mem);\n+    set_ctrl_and_loop(n, get_early_ctrl(n));\n+    Node* bol = n->unique_out();\n+    set_ctrl_and_loop(bol, get_early_ctrl(bol));\n+  }\n+}\n+\n@@ -1130,0 +1189,6 @@\n+\n+  if (n->isa_FlatArrayCheck()) {\n+    move_flat_array_check_out_of_loop(n);\n+    return n;\n+  }\n+\n@@ -1409,0 +1474,98 @@\n+bool PhaseIdealLoop::flat_array_element_type_check(Node *n) {\n+  \/\/ If the CmpP is a subtype check for a value that has just been\n+  \/\/ loaded from an array, the subtype check guarantees the value\n+  \/\/ can't be stored in a flat array and the load of the value\n+  \/\/ happens with a flat array check then: push the type check\n+  \/\/ through the phi of the flat array check. This needs special\n+  \/\/ logic because the subtype check's input is not a phi but a\n+  \/\/ LoadKlass that must first be cloned through the phi.\n+  if (n->Opcode() != Op_CmpP) {\n+    return false;\n+  }\n+\n+  Node* klassptr = n->in(1);\n+  Node* klasscon = n->in(2);\n+\n+  if (klassptr->is_DecodeNarrowPtr()) {\n+    klassptr = klassptr->in(1);\n+  }\n+\n+  if (klassptr->Opcode() != Op_LoadKlass && klassptr->Opcode() != Op_LoadNKlass) {\n+    return false;\n+  }\n+\n+  if (!klasscon->is_Con()) {\n+    return false;\n+  }\n+\n+  Node* addr = klassptr->in(MemNode::Address);\n+\n+  if (!addr->is_AddP()) {\n+    return false;\n+  }\n+\n+  intptr_t offset;\n+  Node* obj = AddPNode::Ideal_base_and_offset(addr, &_igvn, offset);\n+\n+  if (obj == nullptr) {\n+    return false;\n+  }\n+\n+  assert(obj != nullptr && addr->in(AddPNode::Base) == addr->in(AddPNode::Address), \"malformed AddP?\");\n+  if (obj->Opcode() == Op_CastPP) {\n+    obj = obj->in(1);\n+  }\n+\n+  if (!obj->is_Phi()) {\n+    return false;\n+  }\n+\n+  Node* region = obj->in(0);\n+\n+  Node* phi = PhiNode::make_blank(region, n->in(1));\n+  for (uint i = 1; i < region->req(); i++) {\n+    Node* in = obj->in(i);\n+    Node* ctrl = region->in(i);\n+    if (addr->in(AddPNode::Base) != obj) {\n+      Node* cast = addr->in(AddPNode::Base);\n+      assert(cast->Opcode() == Op_CastPP && cast->in(0) != nullptr, \"inconsistent subgraph\");\n+      Node* cast_clone = cast->clone();\n+      cast_clone->set_req(0, ctrl);\n+      cast_clone->set_req(1, in);\n+      register_new_node(cast_clone, ctrl);\n+      const Type* tcast = cast_clone->Value(&_igvn);\n+      _igvn.set_type(cast_clone, tcast);\n+      cast_clone->as_Type()->set_type(tcast);\n+      in = cast_clone;\n+    }\n+    Node* addr_clone = addr->clone();\n+    addr_clone->set_req(AddPNode::Base, in);\n+    addr_clone->set_req(AddPNode::Address, in);\n+    register_new_node(addr_clone, ctrl);\n+    _igvn.set_type(addr_clone, addr_clone->Value(&_igvn));\n+    Node* klassptr_clone = klassptr->clone();\n+    klassptr_clone->set_req(2, addr_clone);\n+    register_new_node(klassptr_clone, ctrl);\n+    _igvn.set_type(klassptr_clone, klassptr_clone->Value(&_igvn));\n+    if (klassptr != n->in(1)) {\n+      Node* decode = n->in(1);\n+      assert(decode->is_DecodeNarrowPtr(), \"inconsistent subgraph\");\n+      Node* decode_clone = decode->clone();\n+      decode_clone->set_req(1, klassptr_clone);\n+      register_new_node(decode_clone, ctrl);\n+      _igvn.set_type(decode_clone, decode_clone->Value(&_igvn));\n+      klassptr_clone = decode_clone;\n+    }\n+    phi->set_req(i, klassptr_clone);\n+  }\n+  register_new_node(phi, region);\n+  Node* orig = n->in(1);\n+  _igvn.replace_input_of(n, 1, phi);\n+  split_if_with_blocks_post(n);\n+  if (n->outcnt() != 0) {\n+    _igvn.replace_input_of(n, 1, orig);\n+    _igvn.remove_dead_node(phi);\n+  }\n+  return true;\n+}\n+\n@@ -1415,0 +1578,4 @@\n+  if (flat_array_element_type_check(n)) {\n+    return;\n+  }\n+\n@@ -1565,0 +1732,5 @@\n+\n+  \/\/ Remove multiple allocations of the same inline type\n+  if (n->is_InlineType()) {\n+    n->as_InlineType()->remove_redundant_allocations(this);\n+  }\n@@ -2056,1 +2228,9 @@\n-  Node *sample_cmp = sample_bool->in(1);\n+  Node* sample_cmp = sample_bool->in(1);\n+  const Type* t = Type::TOP;\n+  const TypePtr* at = nullptr;\n+  if (sample_cmp->is_FlatArrayCheck()) {\n+    \/\/ Left input of a FlatArrayCheckNode is memory, set the (adr) type of the phi accordingly\n+    assert(sample_cmp->in(1)->bottom_type() == Type::MEMORY, \"unexpected input type\");\n+    t = Type::MEMORY;\n+    at = TypeRawPtr::BOTTOM;\n+  }\n@@ -2059,1 +2239,1 @@\n-  PhiNode *phi1 = new PhiNode(phi->in(0), Type::TOP);\n+  PhiNode *phi1 = new PhiNode(phi->in(0), t, at);\n","filename":"src\/hotspot\/share\/opto\/loopopts.cpp","additions":182,"deletions":2,"binary":false,"changes":184,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n@@ -27,0 +28,1 @@\n+#include \"classfile\/systemDictionary.hpp\"\n@@ -41,0 +43,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -236,0 +239,2 @@\n+                     ->cast_to_not_flat(t_oop->is_aryptr()->is_not_flat())\n+                     ->cast_to_not_null_free(t_oop->is_aryptr()->is_not_null_free())\n@@ -262,1 +267,1 @@\n-               tp->isa_aryptr() &&        tp->offset() == Type::OffsetBot &&\n+        tp->isa_aryptr() &&        tp->offset() == Type::OffsetBot &&\n@@ -1015,1 +1020,1 @@\n-    return (eliminate_boxing && non_volatile) || is_stable_ary;\n+    return (eliminate_boxing && non_volatile) || is_stable_ary || tp->is_inlinetypeptr();\n@@ -1072,1 +1077,1 @@\n-      uint shift  = exact_log2(type2aelembytes(ary_elem));\n+      uint shift  = ary_t->is_flat() ? ary_t->flat_log_elem_size() : exact_log2(type2aelembytes(ary_elem));\n@@ -1096,0 +1101,11 @@\n+static Node* see_through_inline_type(PhaseValues* phase, const MemNode* load, Node* base, int offset) {\n+  if (!load->is_mismatched_access() && base != nullptr && base->is_InlineType() && offset > oopDesc::klass_offset_in_bytes()) {\n+    InlineTypeNode* vt = base->as_InlineType();\n+    assert(!vt->is_larval(), \"must not load from a larval object\");\n+    Node* value = vt->field_value_by_offset(offset, true);\n+    assert(value != nullptr, \"must see some value\");\n+    return value;\n+  }\n+\n+  return nullptr;\n+}\n@@ -1108,0 +1124,10 @@\n+\n+  \/\/ Try to see through an InlineTypeNode\n+  \/\/ LoadN is special because the input is not compressed\n+  if (Opcode() != Op_LoadN) {\n+    Node* value = see_through_inline_type(phase, this, ld_base, ld_off);\n+    if (value != nullptr) {\n+      return value;\n+    }\n+  }\n+\n@@ -1191,1 +1217,1 @@\n-        const TypeVect* out_vt = as_LoadVector()->vect_type();\n+        const TypeVect* out_vt = is_Load() ? as_LoadVector()->vect_type() : as_StoreVector()->vect_type();\n@@ -1209,0 +1235,5 @@\n+      Node* default_value = ld_alloc->in(AllocateNode::DefaultValue);\n+      if (default_value != nullptr) {\n+        return default_value;\n+      }\n+      assert(ld_alloc->in(AllocateNode::RawDefaultValue) == nullptr, \"default value may not be null\");\n@@ -1869,0 +1900,1 @@\n+        && !(phase->type(address)->is_inlinetypeptr() && is_mismatched_access())\n@@ -2067,0 +2099,1 @@\n+        && !ary->is_flat()\n@@ -2102,0 +2135,2 @@\n+            \/\/ Default value load\n+            tp->is_instptr()->instance_klass() == ciEnv::current()->Class_klass() ||\n@@ -2107,1 +2142,3 @@\n-    \/\/ Optimize loads from constant fields.\n+    BasicType bt = memory_type();\n+\n+    \/\/ Optimize loads from constant fields.\n@@ -2111,1 +2148,1 @@\n-      const Type* con_type = Type::make_constant_from_field(const_oop->as_instance(), off, is_unsigned(), memory_type());\n+      const Type* con_type = Type::make_constant_from_field(const_oop->as_instance(), off, is_unsigned(), bt);\n@@ -2158,1 +2195,1 @@\n-      if (UseCompactObjectHeaders) {\n+      if (UseCompactObjectHeaders) { \/\/ TODO: Should EnableValhalla also take this path ?\n@@ -2239,1 +2276,0 @@\n-\n@@ -2243,1 +2279,10 @@\n-      return TypeX::make(markWord::prototype().value());\n+      if (EnableValhalla) {\n+        \/\/ The mark word may contain property bits (inline, flat, null-free)\n+        Node* klass_node = alloc->in(AllocateNode::KlassNode);\n+        const TypeKlassPtr* tkls = phase->type(klass_node)->isa_klassptr();\n+        if (tkls != nullptr && tkls->is_loaded() && tkls->klass_is_exact()) {\n+          return TypeX::make(tkls->exact_klass()->prototype_header());\n+        }\n+      } else {\n+        return TypeX::make(markWord::prototype().value());\n+      }\n@@ -2392,0 +2437,13 @@\n+Node* LoadNNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  \/\/ Loading from an InlineType, find the input and make an EncodeP\n+  Node* addr = in(Address);\n+  intptr_t offset;\n+  Node* base = AddPNode::Ideal_base_and_offset(addr, phase, offset);\n+  Node* value = see_through_inline_type(phase, this, base, offset);\n+  if (value != nullptr) {\n+    return new EncodePNode(value, type());\n+  }\n+\n+  return LoadNode::Ideal(phase, can_reshape);\n+}\n+\n@@ -2436,1 +2494,2 @@\n-      ciType* t = tinst->java_mirror_type();\n+      bool is_null_free_array = false;\n+      ciType* t = tinst->java_mirror_type(&is_null_free_array);\n@@ -2446,1 +2505,5 @@\n-          return TypeKlassPtr::make(ciArrayKlass::make(t), Type::trust_interfaces);\n+          const TypeKlassPtr* tklass = TypeKlassPtr::make(ciArrayKlass::make(t), Type::trust_interfaces);\n+          if (is_null_free_array) {\n+            tklass = tklass->is_aryklassptr()->cast_to_null_free();\n+          }\n+          return tklass;\n@@ -2453,1 +2516,5 @@\n-        return TypeKlassPtr::make(t->as_klass(), Type::trust_interfaces);\n+        const TypeKlassPtr* tklass = TypeKlassPtr::make(t->as_klass(), Type::trust_interfaces);\n+        if (is_null_free_array) {\n+          tklass = tklass->is_aryklassptr()->cast_to_null_free();\n+        }\n+        return tklass;\n@@ -2465,1 +2532,1 @@\n-  const TypeAryPtr *tary = tp->isa_aryptr();\n+  const TypeAryPtr* tary = tp->isa_aryptr();\n@@ -3381,2 +3448,2 @@\n-  \/\/ unsafe if I have intervening uses.\n-  {\n+  \/\/ unsafe if I have intervening uses...\n+  if (phase->C->get_adr_type(phase->C->get_alias_index(adr_type())) != TypeAryPtr::INLINES) {\n@@ -3402,0 +3469,2 @@\n+             (Opcode() == Op_StoreL && st->Opcode() == Op_StoreN) ||\n+             (st->adr_type()->isa_aryptr() && st->adr_type()->is_aryptr()->is_flat()) || \/\/ TODO 8343835\n@@ -3539,2 +3608,1 @@\n-  if (result == this &&\n-      ReduceFieldZeroing && phase->type(val)->is_zero_type()) {\n+  if (result == this && ReduceFieldZeroing) {\n@@ -3542,1 +3610,2 @@\n-    if (mem->is_Proj() && mem->in(0)->is_Allocate()) {\n+    if (mem->is_Proj() && mem->in(0)->is_Allocate() &&\n+        (phase->type(val)->is_zero_type() || mem->in(0)->in(AllocateNode::DefaultValue) == val)) {\n@@ -3546,1 +3615,1 @@\n-    if (result == this) {\n+    if (result == this && phase->type(val)->is_zero_type()) {\n@@ -3862,1 +3931,1 @@\n-    return new ClearArrayNode(in(0), in(1), in(2), in(3), true);\n+    return new ClearArrayNode(in(0), in(1), in(2), in(3), in(4), true);\n@@ -3880,1 +3949,1 @@\n-  Node *zero = phase->makecon(TypeLong::ZERO);\n+  Node *val = in(4);\n@@ -3882,1 +3951,1 @@\n-  mem = new StoreLNode(in(0),mem,adr,atp,zero,MemNode::unordered,false);\n+  mem = new StoreLNode(in(0), mem, adr, atp, val, MemNode::unordered, false);\n@@ -3887,1 +3956,1 @@\n-    mem = new StoreLNode(in(0),mem,adr,atp,zero,MemNode::unordered,false);\n+    mem = new StoreLNode(in(0), mem, adr, atp, val, MemNode::unordered, false);\n@@ -3921,0 +3990,2 @@\n+                                   Node* val,\n+                                   Node* raw_val,\n@@ -3931,1 +4002,7 @@\n-    mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase->zerocon(T_INT), T_INT, MemNode::unordered);\n+    if (val != nullptr) {\n+      assert(phase->type(val)->isa_narrowoop(), \"should be narrow oop\");\n+      mem = new StoreNNode(ctl, mem, adr, atp, val, MemNode::unordered);\n+    } else {\n+      assert(raw_val == nullptr, \"val may not be null\");\n+      mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase->zerocon(T_INT), T_INT, MemNode::unordered);\n+    }\n@@ -3938,1 +4015,1 @@\n-  return clear_memory(ctl, mem, dest, phase->MakeConX(offset), end_offset, phase);\n+  return clear_memory(ctl, mem, dest, raw_val, phase->MakeConX(offset), end_offset, phase);\n@@ -3942,0 +4019,1 @@\n+                                   Node* raw_val,\n@@ -3964,1 +4042,4 @@\n-  mem = new ClearArrayNode(ctl, mem, zsize, adr, false);\n+  if (raw_val == nullptr) {\n+    raw_val = phase->MakeConX(0);\n+  }\n+  mem = new ClearArrayNode(ctl, mem, zsize, adr, raw_val, false);\n@@ -3969,0 +4050,2 @@\n+                                   Node* val,\n+                                   Node* raw_val,\n@@ -3983,1 +4066,1 @@\n-    mem = clear_memory(ctl, mem, dest,\n+    mem = clear_memory(ctl, mem, dest, val, raw_val,\n@@ -3990,1 +4073,7 @@\n-    mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase->zerocon(T_INT), T_INT, MemNode::unordered);\n+    if (val != nullptr) {\n+      assert(phase->type(val)->isa_narrowoop(), \"should be narrow oop\");\n+      mem = new StoreNNode(ctl, mem, adr, atp, val, MemNode::unordered);\n+    } else {\n+      assert(raw_val == nullptr, \"val may not be null\");\n+      mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase->zerocon(T_INT), T_INT, MemNode::unordered);\n+    }\n@@ -4136,1 +4225,1 @@\n-Node *MemBarNode::match( const ProjNode *proj, const Matcher *m ) {\n+Node *MemBarNode::match(const ProjNode *proj, const Matcher *m, const RegMask* mask) {\n@@ -4423,1 +4512,3 @@\n-  if (init == nullptr || init->is_complete())  return false;\n+  if (init == nullptr || init->is_complete()) {\n+    return false;\n+  }\n@@ -4607,0 +4698,6 @@\n+                if (base->is_Phi()) {\n+                  \/\/ In rare case, base may be a PhiNode and it may read\n+                  \/\/ the same memory slice between InitializeNode and store.\n+                  failed = true;\n+                  break;\n+                }\n@@ -5193,0 +5290,2 @@\n+                                              allocation()->in(AllocateNode::DefaultValue),\n+                                              allocation()->in(AllocateNode::RawDefaultValue),\n@@ -5252,0 +5351,2 @@\n+                                            allocation()->in(AllocateNode::DefaultValue),\n+                                            allocation()->in(AllocateNode::RawDefaultValue),\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":131,"deletions":30,"binary":false,"changes":161,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -563,0 +564,3 @@\n+  if (n->is_InlineType()) {\n+    C->add_inline_type(n);\n+  }\n@@ -623,0 +627,3 @@\n+  if (is_InlineType()) {\n+    compile->remove_inline_type(this);\n+  }\n","filename":"src\/hotspot\/share\/opto\/node.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -89,0 +89,1 @@\n+class FlatArrayCheckNode;\n@@ -121,0 +122,1 @@\n+class MachPrologNode;\n@@ -127,0 +129,1 @@\n+class MachVEPNode;\n@@ -183,0 +186,1 @@\n+class InlineTypeNode;\n@@ -694,0 +698,1 @@\n+        DEFINE_CLASS_ID(Blackhole,        MemBar, 2)\n@@ -715,0 +720,2 @@\n+      DEFINE_CLASS_ID(MachProlog,       Mach, 8)\n+      DEFINE_CLASS_ID(MachVEP,          Mach, 9)\n@@ -747,1 +754,2 @@\n-      DEFINE_CLASS_ID(Con, Type, 8)\n+      DEFINE_CLASS_ID(InlineType, Type, 8)\n+      DEFINE_CLASS_ID(Con, Type, 9)\n@@ -749,2 +757,2 @@\n-      DEFINE_CLASS_ID(SafePointScalarMerge, Type, 9)\n-      DEFINE_CLASS_ID(Convert, Type, 10)\n+      DEFINE_CLASS_ID(SafePointScalarMerge, Type, 10)\n+      DEFINE_CLASS_ID(Convert, Type, 11)\n@@ -788,3 +796,4 @@\n-        DEFINE_CLASS_ID(FastLock,   Cmp, 0)\n-        DEFINE_CLASS_ID(FastUnlock, Cmp, 1)\n-        DEFINE_CLASS_ID(SubTypeCheck,Cmp, 2)\n+        DEFINE_CLASS_ID(FastLock,       Cmp, 0)\n+        DEFINE_CLASS_ID(FastUnlock,     Cmp, 1)\n+        DEFINE_CLASS_ID(SubTypeCheck,   Cmp, 2)\n+        DEFINE_CLASS_ID(FlatArrayCheck, Cmp, 3)\n@@ -899,0 +908,1 @@\n+  DEFINE_CLASS_QUERY(Blackhole)\n@@ -931,0 +941,1 @@\n+  DEFINE_CLASS_QUERY(FlatArrayCheck)\n@@ -963,0 +974,1 @@\n+  DEFINE_CLASS_QUERY(MachProlog)\n@@ -969,0 +981,1 @@\n+  DEFINE_CLASS_QUERY(MachVEP)\n@@ -1006,0 +1019,1 @@\n+  DEFINE_CLASS_QUERY(InlineType)\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":20,"deletions":6,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -117,0 +117,2 @@\n+  flags(SPLIT_INLINES_ARRAY,            \"Split inlines array\") \\\n+  flags(SPLIT_INLINES_ARRAY_IGVN,       \"IGVN after split inlines array\") \\\n","filename":"src\/hotspot\/share\/opto\/phasetype.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -59,0 +59,1 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n@@ -414,0 +415,92 @@\n+static void validate_array_arguments(Klass* elmClass, jint len, TRAPS) {\n+  if (len < 0) {\n+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), \"Array length is negative\");\n+  }\n+  elmClass->initialize(CHECK);\n+  if (elmClass->is_identity_class()) {\n+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), \"Element class is not a value class\");\n+  }\n+  if (elmClass->is_abstract()) {\n+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), \"Element class is abstract\");\n+  }\n+}\n+\n+JVM_ENTRY(jarray, JVM_NewNullRestrictedArray(JNIEnv *env, jclass elmClass, jint len))\n+  oop mirror = JNIHandles::resolve_non_null(elmClass);\n+  Klass* klass = java_lang_Class::as_Klass(mirror);\n+  klass->initialize(CHECK_NULL);\n+  validate_array_arguments(klass, len, CHECK_NULL);\n+  InlineKlass* vk = InlineKlass::cast(klass);\n+  if (!vk->is_implicitly_constructible()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Element class is not implicitly constructible\");\n+  }\n+  oop array = nullptr;\n+  if (vk->flat_array() && vk->has_non_atomic_layout()) {\n+    array = oopFactory::new_flatArray(vk, len, LayoutKind::NON_ATOMIC_FLAT, CHECK_NULL);\n+  } else {\n+    array = oopFactory::new_null_free_objArray(vk, len, CHECK_NULL);\n+  }\n+  return (jarray) JNIHandles::make_local(THREAD, array);\n+JVM_END\n+\n+JVM_ENTRY(jarray, JVM_NewNullRestrictedAtomicArray(JNIEnv *env, jclass elmClass, jint len))\n+  oop mirror = JNIHandles::resolve_non_null(elmClass);\n+  Klass* klass = java_lang_Class::as_Klass(mirror);\n+  klass->initialize(CHECK_NULL);\n+  validate_array_arguments(klass, len, CHECK_NULL);\n+  InlineKlass* vk = InlineKlass::cast(klass);\n+  if (!vk->is_implicitly_constructible()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Element class is not implicitly constructible\");\n+  }\n+  oop array = nullptr;\n+  if (UseArrayFlattening && vk->is_naturally_atomic() && vk->has_non_atomic_layout()) {\n+    array = oopFactory::new_flatArray(vk, len, LayoutKind::NON_ATOMIC_FLAT, CHECK_NULL);\n+  } else if (UseArrayFlattening && vk->has_atomic_layout()) {\n+    array = oopFactory::new_flatArray(vk, len, LayoutKind::ATOMIC_FLAT, CHECK_NULL);\n+  } else {\n+    array = oopFactory::new_null_free_objArray(vk, len, CHECK_NULL);\n+  }\n+  return (jarray) JNIHandles::make_local(THREAD, array);\n+JVM_END\n+\n+JVM_ENTRY(jarray, JVM_NewNullableAtomicArray(JNIEnv *env, jclass elmClass, jint len))\n+  oop mirror = JNIHandles::resolve_non_null(elmClass);\n+  Klass* klass = java_lang_Class::as_Klass(mirror);\n+  klass->initialize(CHECK_NULL);\n+  validate_array_arguments(klass, len, CHECK_NULL);\n+  InlineKlass* vk = InlineKlass::cast(klass);\n+  oop array = nullptr;\n+  if (UseArrayFlattening && vk->has_nullable_atomic_layout()) {\n+    array = oopFactory::new_flatArray(vk, len, LayoutKind::NULLABLE_ATOMIC_FLAT, CHECK_NULL);\n+  } else {\n+    array = oopFactory::new_objArray(vk, len, CHECK_NULL);\n+  }\n+  return (jarray) JNIHandles::make_local(THREAD, array);\n+JVM_END\n+\n+JVM_ENTRY(jboolean, JVM_IsFlatArray(JNIEnv *env, jobject obj))\n+  arrayOop oop = arrayOop(JNIHandles::resolve_non_null(obj));\n+  return oop->is_flatArray();\n+JVM_END\n+\n+JVM_ENTRY(jboolean, JVM_IsNullRestrictedArray(JNIEnv *env, jobject obj))\n+  arrayOop oop = arrayOop(JNIHandles::resolve_non_null(obj));\n+  return oop->is_null_free_array();\n+JVM_END\n+\n+JVM_ENTRY(jboolean, JVM_IsAtomicArray(JNIEnv *env, jobject obj))\n+  \/\/ There are multiple cases where an array can\/must support atomic access:\n+  \/\/   - the array is a reference array\n+  \/\/   - the array uses an atomic flat layout: NULLABLE_ATOMIC_FLAT or ATOMIC_FLAT\n+  \/\/   - the array is flat and its component type is naturally atomic\n+  arrayOop oop = arrayOop(JNIHandles::resolve_non_null(obj));\n+  if (oop->is_objArray()) return true;\n+  if (oop->is_flatArray()) {\n+    FlatArrayKlass* fak = FlatArrayKlass::cast(oop->klass());\n+    if (fak->layout_kind() == LayoutKind::ATOMIC_FLAT || fak->layout_kind() == LayoutKind::NULLABLE_ATOMIC_FLAT) {\n+      return true;\n+    }\n+    if (fak->element_klass()->is_naturally_atomic()) return true;\n+  }\n+  return false;\n+JVM_END\n@@ -622,2 +715,22 @@\n-  return handle == nullptr ? 0 :\n-         checked_cast<jint>(ObjectSynchronizer::FastHashCode (THREAD, JNIHandles::resolve_non_null(handle)));\n+  if (handle == nullptr) {\n+    return 0;\n+  }\n+  oop obj = JNIHandles::resolve_non_null(handle);\n+  if (EnableValhalla && obj->klass()->is_inline_klass()) {\n+      JavaValue result(T_INT);\n+      JavaCallArguments args;\n+      Handle ho(THREAD, obj);\n+      args.push_oop(ho);\n+      methodHandle method(THREAD, Universe::value_object_hash_code_method());\n+      JavaCalls::call(&result, method, &args, THREAD);\n+      if (HAS_PENDING_EXCEPTION) {\n+        if (!PENDING_EXCEPTION->is_a(vmClasses::Error_klass())) {\n+          Handle e(THREAD, PENDING_EXCEPTION);\n+          CLEAR_PENDING_EXCEPTION;\n+          THROW_MSG_CAUSE_(vmSymbols::java_lang_InternalError(), \"Internal error in hashCode\", e, false);\n+        }\n+      }\n+      return result.get_jint();\n+  } else {\n+    return checked_cast<jint>(ObjectSynchronizer::FastHashCode(THREAD, obj));\n+  }\n@@ -671,0 +784,6 @@\n+  if (klass->is_inline_klass()) {\n+    \/\/ Value instances have no identity, so return the current instance instead of allocating a new one\n+    \/\/ Value classes cannot have finalizers, so the method can return immediately\n+    return JNIHandles::make_local(THREAD, obj());\n+  }\n+\n@@ -1165,1 +1284,2 @@\n-    size = InstanceKlass::cast(klass)->local_interfaces()->length();\n+    InstanceKlass* ik = InstanceKlass::cast(klass);\n+    size = ik->local_interfaces()->length();\n@@ -1167,1 +1287,1 @@\n-    assert(klass->is_objArray_klass() || klass->is_typeArray_klass(), \"Illegal mirror klass\");\n+    assert(klass->is_objArray_klass() || klass->is_typeArray_klass() || klass->is_flatArray_klass(), \"Illegal mirror klass\");\n@@ -1178,1 +1298,2 @@\n-      Klass* k = InstanceKlass::cast(klass)->local_interfaces()->at(index);\n+      InstanceKlass* ik = InstanceKlass::cast(klass);\n+      Klass* k = ik->local_interfaces()->at(index);\n@@ -1199,0 +1320,19 @@\n+JVM_ENTRY(jboolean, JVM_IsIdentityClass(JNIEnv *env, jclass cls))\n+  oop mirror = JNIHandles::resolve_non_null(cls);\n+  if (java_lang_Class::is_primitive(mirror)) {\n+    return JNI_FALSE;\n+  }\n+  Klass* k = java_lang_Class::as_Klass(mirror);\n+  if (EnableValhalla) {\n+    return k->is_array_klass() || k->is_identity_class();\n+  } else {\n+    return k->is_interface() ? JNI_FALSE : JNI_TRUE;\n+  }\n+JVM_END\n+\n+JVM_ENTRY(jboolean, JVM_IsImplicitlyConstructibleClass(JNIEnv *env, jclass cls))\n+  oop mirror = JNIHandles::resolve_non_null(cls);\n+  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(mirror));\n+  return ik->is_implicitly_constructible();\n+JVM_END\n+\n@@ -1683,1 +1823,1 @@\n-    if (want_constructor && !method->is_object_initializer()) {\n+    if (want_constructor && !method->is_object_constructor()) {\n@@ -1687,1 +1827,1 @@\n-        (method->is_object_initializer() || method->is_static_initializer() ||\n+        (method->is_object_constructor() || method->is_class_initializer() ||\n@@ -1715,0 +1855,1 @@\n+        assert(method->is_object_constructor(), \"must be\");\n@@ -1997,1 +2138,1 @@\n-  if (m->is_object_initializer()) {\n+  if (m->is_object_constructor()) {\n@@ -2000,1 +2141,0 @@\n-    \/\/ new_method accepts <clinit> as Method here\n@@ -2272,0 +2412,37 @@\n+\/\/ Arrays support \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+JVM_ENTRY(jboolean, JVM_ArrayIsAccessAtomic(JNIEnv *env, jclass unused, jobject array))\n+  oop o = JNIHandles::resolve(array);\n+  Klass* k = o->klass();\n+  if ((o == nullptr) || (!k->is_array_klass())) {\n+    THROW_0(vmSymbols::java_lang_IllegalArgumentException());\n+  }\n+  return ArrayKlass::cast(k)->element_access_must_be_atomic();\n+JVM_END\n+\n+JVM_ENTRY(jobject, JVM_ArrayEnsureAccessAtomic(JNIEnv *env, jclass unused, jobject array))\n+  oop o = JNIHandles::resolve(array);\n+  Klass* k = o->klass();\n+  if ((o == nullptr) || (!k->is_array_klass())) {\n+    THROW_0(vmSymbols::java_lang_IllegalArgumentException());\n+  }\n+  if (k->is_flatArray_klass()) {\n+    FlatArrayKlass* vk = FlatArrayKlass::cast(k);\n+    if (!vk->element_access_must_be_atomic()) {\n+      \/**\n+       * Need to decide how to implement:\n+       *\n+       * 1) Change to objArrayOop layout, therefore oop->klass() differs so\n+       * then \"<atomic>[Qfoo;\" klass needs to subclass \"[Qfoo;\" to pass through\n+       * \"checkcast\" & \"instanceof\"\n+       *\n+       * 2) Use extra header in the flatArrayOop to flag atomicity required and\n+       * possibly per instance lock structure. Said info, could be placed in\n+       * \"trailer\" rather than disturb the current arrayOop\n+       *\/\n+      Unimplemented();\n+    }\n+  }\n+  return array;\n+JVM_END\n+\n@@ -2450,1 +2627,1 @@\n-  return method->name() == vmSymbols::object_initializer_name();\n+  return method->is_object_constructor();\n@@ -3241,0 +3418,4 @@\n+JVM_LEAF(jboolean, JVM_IsValhallaEnabled(void))\n+  return EnableValhalla ? JNI_TRUE : JNI_FALSE;\n+JVM_END\n+\n@@ -3320,1 +3501,1 @@\n-    objArrayHandle args(THREAD, objArrayOop(JNIHandles::resolve(args0)));\n+    objArrayHandle args = oopFactory::ensure_objArray(JNIHandles::resolve(args0), CHECK_NULL);\n@@ -3340,0 +3521,1 @@\n+  objArrayHandle args = oopFactory::ensure_objArray(JNIHandles::resolve(args0), CHECK_NULL);\n@@ -3341,1 +3523,0 @@\n-  objArrayHandle args(THREAD, objArrayOop(JNIHandles::resolve(args0)));\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":193,"deletions":12,"binary":false,"changes":205,"status":"modified"},{"patch":"@@ -55,0 +55,1 @@\n+#include \"memory\/iterator.inline.hpp\"\n@@ -61,0 +62,1 @@\n+#include \"oops\/access.hpp\"\n@@ -63,0 +65,1 @@\n+#include \"oops\/compressedOops.inline.hpp\"\n@@ -70,0 +73,1 @@\n+#include \"oops\/objArrayOop.inline.hpp\"\n@@ -88,0 +92,1 @@\n+#include \"runtime\/keepStackGCProcessed.hpp\"\n@@ -1938,0 +1943,103 @@\n+WB_ENTRY(jobjectArray, WB_getObjectsViaKlassOopMaps(JNIEnv* env, jobject wb, jobject thing))\n+  oop aoop = JNIHandles::resolve(thing);\n+  if (!aoop->is_instance()) {\n+    return nullptr;\n+  }\n+  instanceHandle ih(THREAD, (instanceOop) aoop);\n+  InstanceKlass* klass = InstanceKlass::cast(ih->klass());\n+  if (klass->nonstatic_oop_map_count() == 0) {\n+    return nullptr;\n+  }\n+  const OopMapBlock* map = klass->start_of_nonstatic_oop_maps();\n+  const OopMapBlock* const end = map + klass->nonstatic_oop_map_count();\n+  int oop_count = 0;\n+  while (map < end) {\n+    oop_count += map->count();\n+    map++;\n+  }\n+\n+  objArrayHandle result_array =\n+      oopFactory::new_objArray_handle(vmClasses::Object_klass(), oop_count, CHECK_NULL);\n+  map = klass->start_of_nonstatic_oop_maps();\n+  int index = 0;\n+  while (map < end) {\n+    int offset = map->offset();\n+    for (unsigned int j = 0; j < map->count(); j++) {\n+      result_array->obj_at_put(index++, ih->obj_field(offset));\n+      offset += heapOopSize;\n+    }\n+    map++;\n+  }\n+  return (jobjectArray)JNIHandles::make_local(THREAD, result_array());\n+WB_END\n+\n+\/\/ Collect Object oops but not value objects...loaded from heap\n+class CollectObjectOops : public BasicOopIterateClosure {\n+  public:\n+  GrowableArray<Handle>* _array;\n+\n+  CollectObjectOops() {\n+      _array = new GrowableArray<Handle>(128);\n+  }\n+\n+  void add_oop(oop o) {\n+    Handle oh = Handle(Thread::current(), o);\n+    if (oh != nullptr && oh->is_inline_type()) {\n+      oh->oop_iterate(this);\n+    } else {\n+      _array->append(oh);\n+    }\n+  }\n+\n+  template <class T> inline void add_oop(T* p) { add_oop(HeapAccess<>::oop_load(p)); }\n+  void do_oop(oop* o) { add_oop(o); }\n+  void do_oop(narrowOop* v) { add_oop(v); }\n+\n+  jobjectArray create_jni_result(JNIEnv* env, TRAPS) {\n+    objArrayHandle result_array =\n+        oopFactory::new_objArray_handle(vmClasses::Object_klass(), _array->length(), CHECK_NULL);\n+    for (int i = 0 ; i < _array->length(); i++) {\n+      result_array->obj_at_put(i, _array->at(i)());\n+    }\n+    return (jobjectArray)JNIHandles::make_local(THREAD, result_array());\n+  }\n+};\n+\n+\/\/ Collect Object oops but not value objects...loaded from frames\n+class CollectFrameObjectOops : public BasicOopIterateClosure {\n+ public:\n+  CollectObjectOops _collect;\n+\n+  template <class T> inline void add_oop(T* p) { _collect.add_oop(RawAccess<>::oop_load(p)); }\n+  void do_oop(oop* o) { add_oop(o); }\n+  void do_oop(narrowOop* v) { add_oop(v); }\n+\n+  jobjectArray create_jni_result(JNIEnv* env, TRAPS) {\n+    return _collect.create_jni_result(env, THREAD);\n+  }\n+};\n+\n+\/\/ Collect Object oops for the given oop, iterate through value objects\n+WB_ENTRY(jobjectArray, WB_getObjectsViaOopIterator(JNIEnv* env, jobject wb, jobject thing))\n+  ResourceMark rm(thread);\n+  Handle objh(thread, JNIHandles::resolve(thing));\n+  CollectObjectOops collectOops;\n+  objh->oop_iterate(&collectOops);\n+  return collectOops.create_jni_result(env, THREAD);\n+WB_END\n+\n+\/\/ Collect Object oops for the given frame deep, iterate through value objects\n+WB_ENTRY(jobjectArray, WB_getObjectsViaFrameOopIterator(JNIEnv* env, jobject wb, jint depth))\n+  KeepStackGCProcessedMark ksgcpm(THREAD);\n+  ResourceMark rm(THREAD);\n+  CollectFrameObjectOops collectOops;\n+  StackFrameStream sfs(thread, true \/* update *\/, true \/* process_frames *\/);\n+  while (depth > 0) { \/\/ Skip the native WB API frame\n+    sfs.next();\n+    frame* f = sfs.current();\n+    f->oops_do(&collectOops, nullptr, sfs.register_map());\n+    depth--;\n+  }\n+  return collectOops.create_jni_result(env, THREAD);\n+WB_END\n+\n@@ -2899,0 +3007,6 @@\n+  {CC\"getObjectsViaKlassOopMaps0\",\n+      CC\"(Ljava\/lang\/Object;)[Ljava\/lang\/Object;\",    (void*)&WB_getObjectsViaKlassOopMaps},\n+  {CC\"getObjectsViaOopIterator0\",\n+          CC\"(Ljava\/lang\/Object;)[Ljava\/lang\/Object;\",(void*)&WB_getObjectsViaOopIterator},\n+  {CC\"getObjectsViaFrameOopIterator\",\n+      CC\"(I)[Ljava\/lang\/Object;\",                     (void*)&WB_getObjectsViaFrameOopIterator},\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":114,"deletions":0,"binary":false,"changes":114,"status":"modified"},{"patch":"@@ -53,0 +53,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/flatArrayOop.hpp\"\n@@ -58,0 +60,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -353,2 +356,13 @@\n-  bool save_oop_result = chunk->at(0)->scope()->return_oop() && !thread->popframe_forcing_deopt_reexecution() && (exec_mode == Deoptimization::Unpack_deopt);\n-  Handle return_value;\n+  ScopeDesc* scope = chunk->at(0)->scope();\n+  bool save_oop_result = scope->return_oop() && !thread->popframe_forcing_deopt_reexecution() && (exec_mode == Deoptimization::Unpack_deopt);\n+  \/\/ In case of the return of multiple values, we must take care\n+  \/\/ of all oop return values.\n+  GrowableArray<Handle> return_oops;\n+  InlineKlass* vk = nullptr;\n+  if (save_oop_result && scope->return_scalarized()) {\n+    vk = InlineKlass::returned_inline_klass(map);\n+    if (vk != nullptr) {\n+      vk->save_oop_fields(map, return_oops);\n+      save_oop_result = false;\n+    }\n+  }\n@@ -360,1 +374,1 @@\n-    return_value = Handle(thread, result);\n+    return_oops.push(Handle(thread, result));\n@@ -367,1 +381,1 @@\n-  if (objects != nullptr) {\n+  if (objects != nullptr || vk != nullptr) {\n@@ -372,1 +386,8 @@\n-      realloc_failures = Deoptimization::realloc_objects(thread, &deoptee, &map, objects, CHECK_AND_CLEAR_(true));\n+      if (vk != nullptr) {\n+        realloc_failures = Deoptimization::realloc_inline_type_result(vk, map, return_oops, CHECK_AND_CLEAR_(true));\n+      }\n+      if (objects != nullptr) {\n+        realloc_failures = realloc_failures || Deoptimization::realloc_objects(thread, &deoptee, &map, objects, CHECK_AND_CLEAR_(true));\n+        bool skip_internal = (compiled_method != nullptr) && !compiled_method->is_compiled_by_jvmci();\n+        Deoptimization::reassign_fields(&deoptee, &map, objects, realloc_failures, skip_internal, CHECK_AND_CLEAR_(true));\n+      }\n@@ -377,1 +398,8 @@\n-      realloc_failures = Deoptimization::realloc_objects(thread, &deoptee, &map, objects, THREAD);\n+      if (vk != nullptr) {\n+        realloc_failures = Deoptimization::realloc_inline_type_result(vk, map, return_oops, THREAD);\n+      }\n+      if (objects != nullptr) {\n+        realloc_failures = realloc_failures || Deoptimization::realloc_objects(thread, &deoptee, &map, objects, THREAD);\n+        bool skip_internal = (compiled_method != nullptr) && !compiled_method->is_compiled_by_jvmci();\n+        Deoptimization::reassign_fields(&deoptee, &map, objects, realloc_failures, skip_internal, THREAD);\n+      }\n@@ -380,3 +408,1 @@\n-    bool skip_internal = (compiled_method != nullptr) && !compiled_method->is_compiled_by_jvmci();\n-    Deoptimization::reassign_fields(&deoptee, &map, objects, realloc_failures, skip_internal);\n-    if (TraceDeoptimization) {\n+    if (TraceDeoptimization && objects != nullptr) {\n@@ -386,1 +412,1 @@\n-  if (save_oop_result) {\n+  if (save_oop_result || vk != nullptr) {\n@@ -388,1 +414,2 @@\n-    deoptee.set_saved_oop_result(&map, return_value());\n+    assert(return_oops.length() == 1, \"no inline type\");\n+    deoptee.set_saved_oop_result(&map, return_oops.pop()());\n@@ -722,1 +749,1 @@\n-  \/\/ If the sender is deoptimized the we must retrieve the address of the handler\n+  \/\/ If the sender is deoptimized we must retrieve the address of the handler\n@@ -1227,2 +1254,11 @@\n-\n-    oop obj = nullptr;\n+    \/\/ Check if the object may be null and has an additional is_init input that needs\n+    \/\/ to be checked before using the field values. Skip re-allocation if it is null.\n+    if (sv->maybe_null()) {\n+      assert(k->is_inline_klass(), \"must be an inline klass\");\n+      jint is_init = StackValue::create_stack_value(fr, reg_map, sv->is_init())->get_jint();\n+      if (is_init == 0) {\n+        continue;\n+      }\n+    }\n+\n+    oop obj = nullptr;\n@@ -1258,0 +1294,4 @@\n+    } else if (k->is_flatArray_klass()) {\n+      FlatArrayKlass* ak = FlatArrayKlass::cast(k);\n+      \/\/ Inline type array must be zeroed because not all memory is reassigned\n+      obj = ak->allocate(sv->field_size(), ak->layout_kind(), THREAD);\n@@ -1289,0 +1329,15 @@\n+\/\/ We're deoptimizing at the return of a call, inline type fields are\n+\/\/ in registers. When we go back to the interpreter, it will expect a\n+\/\/ reference to an inline type instance. Allocate and initialize it from\n+\/\/ the register values here.\n+bool Deoptimization::realloc_inline_type_result(InlineKlass* vk, const RegisterMap& map, GrowableArray<Handle>& return_oops, TRAPS) {\n+  oop new_vt = vk->realloc_result(map, return_oops, THREAD);\n+  if (new_vt == nullptr) {\n+    CLEAR_PENDING_EXCEPTION;\n+    THROW_OOP_(Universe::out_of_memory_error_realloc_objects(), true);\n+  }\n+  return_oops.clear();\n+  return_oops.push(Handle(THREAD, new_vt));\n+  return false;\n+}\n+\n@@ -1454,0 +1509,3 @@\n+  InstanceKlass* _klass;\n+  bool _is_flat;\n+  bool _is_null_free;\n@@ -1455,4 +1513,1 @@\n-  ReassignedField() {\n-    _offset = 0;\n-    _type = T_ILLEGAL;\n-  }\n+  ReassignedField() : _offset(0), _type(T_ILLEGAL), _klass(nullptr), _is_flat(false), _is_null_free(false) { }\n@@ -1467,1 +1522,1 @@\n-static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal) {\n+static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal, int base_offset, GrowableArray<int>* null_marker_offsets, TRAPS) {\n@@ -1476,0 +1531,6 @@\n+        if (fs.is_flat()) {\n+          field._is_flat = true;\n+          field._is_null_free = fs.is_null_free_inline_type();\n+          \/\/ Resolve klass of flat inline type field\n+          field._klass = InlineKlass::cast(klass->get_inline_type_field_klass(fs.index()));\n+        }\n@@ -1482,0 +1543,6 @@\n+  \/\/ Keep track of null marker offset for flat fields\n+  bool set_null_markers = false;\n+  if (null_marker_offsets == nullptr) {\n+    set_null_markers = true;\n+    null_marker_offsets = new GrowableArray<int>();\n+  }\n@@ -1483,0 +1550,15 @@\n+    BasicType type = fields->at(i)._type;\n+    int offset = base_offset + fields->at(i)._offset;\n+    \/\/ Check for flat inline type field before accessing the ScopeValue because it might not have any fields\n+    if (fields->at(i)._is_flat) {\n+      \/\/ Recursively re-assign flat inline type fields\n+      InstanceKlass* vk = fields->at(i)._klass;\n+      assert(vk != nullptr, \"must be resolved\");\n+      offset -= InlineKlass::cast(vk)->payload_offset(); \/\/ Adjust offset to omit oop header\n+      svIndex = reassign_fields_by_klass(vk, fr, reg_map, sv, svIndex, obj, skip_internal, offset, null_marker_offsets, CHECK_0);\n+      if (!fields->at(i)._is_null_free) {\n+        int nm_offset = offset + InlineKlass::cast(vk)->null_marker_offset();\n+        null_marker_offsets->append(nm_offset);\n+      }\n+      continue; \/\/ Continue because we don't need to increment svIndex\n+    }\n@@ -1485,3 +1567,2 @@\n-    int offset = fields->at(i)._offset;\n-    BasicType type = fields->at(i)._type;\n-      case T_OBJECT: case T_ARRAY:\n+      case T_OBJECT:\n+      case T_ARRAY:\n@@ -1559,0 +1640,8 @@\n+  if (set_null_markers) {\n+    \/\/ The null marker values come after all the field values in the debug info\n+    for (int i = 0; i < null_marker_offsets->length(); ++i) {\n+      int offset = null_marker_offsets->at(i);\n+      jbyte is_init = (jbyte)StackValue::create_stack_value(fr, reg_map, sv->field_at(svIndex++))->get_jint();\n+      obj->byte_field_put(offset, is_init);\n+    }\n+  }\n@@ -1562,0 +1651,14 @@\n+\/\/ restore fields of an eliminated inline type array\n+void Deoptimization::reassign_flat_array_elements(frame* fr, RegisterMap* reg_map, ObjectValue* sv, flatArrayOop obj, FlatArrayKlass* vak, bool skip_internal, TRAPS) {\n+  InlineKlass* vk = vak->element_klass();\n+  assert(vk->flat_array(), \"should only be used for flat inline type arrays\");\n+  \/\/ Adjust offset to omit oop header\n+  int base_offset = arrayOopDesc::base_offset_in_bytes(T_FLAT_ELEMENT) - InlineKlass::cast(vk)->payload_offset();\n+  \/\/ Initialize all elements of the flat inline type array\n+  for (int i = 0; i < sv->field_size(); i++) {\n+    ScopeValue* val = sv->field_at(i);\n+    int offset = base_offset + (i << Klass::layout_helper_log2_element_size(vak->layout_helper()));\n+    reassign_fields_by_klass(vk, fr, reg_map, val->as_ObjectValue(), 0, (oop)obj, skip_internal, offset, nullptr, CHECK);\n+  }\n+}\n+\n@@ -1563,1 +1666,1 @@\n-void Deoptimization::reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray<ScopeValue*>* objects, bool realloc_failures, bool skip_internal) {\n+void Deoptimization::reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray<ScopeValue*>* objects, bool realloc_failures, bool skip_internal, TRAPS) {\n@@ -1569,1 +1672,1 @@\n-    assert(obj.not_null() || realloc_failures, \"reallocation was missed\");\n+    assert(obj.not_null() || realloc_failures || sv->maybe_null(), \"reallocation was missed\");\n@@ -1607,1 +1710,4 @@\n-      reassign_fields_by_klass(ik, fr, reg_map, sv, 0, obj(), skip_internal);\n+      reassign_fields_by_klass(ik, fr, reg_map, sv, 0, obj(), skip_internal, 0, nullptr, CHECK);\n+    } else if (k->is_flatArray_klass()) {\n+      FlatArrayKlass* vak = FlatArrayKlass::cast(k);\n+      reassign_flat_array_elements(fr, reg_map, sv, (flatArrayOop) obj(), vak, skip_internal, CHECK);\n@@ -1797,1 +1903,1 @@\n-  \/\/ Deoptimize only if the frame comes from compile code.\n+  \/\/ Deoptimize only if the frame comes from compiled code.\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":132,"deletions":26,"binary":false,"changes":158,"status":"modified"},{"patch":"@@ -806,1 +806,1 @@\n-  develop(bool, PrintFieldLayout, false,                                    \\\n+  product(bool, PrintFieldLayout, false, DIAGNOSTIC,                        \\\n@@ -809,0 +809,24 @@\n+  product(bool, PrintInlineLayout, false, DIAGNOSTIC,                       \\\n+          \"Print field layout for each inline type or class with inline fields\") \\\n+                                                                            \\\n+  product(bool, PrintFlatArrayLayout, false, DIAGNOSTIC,                    \\\n+          \"Print array layout for each inline type array\")                  \\\n+                                                                            \\\n+  product(bool, UseArrayFlattening, true,                                   \\\n+          \"Allow the VM to flatten arrays\")                                 \\\n+                                                                            \\\n+  product(bool, UseFieldFlattening, true,                                   \\\n+          \"Allow the VM to flatten value fields\")                           \\\n+                                                                            \\\n+  product(bool, UseNonAtomicValueFlattening, true,                          \\\n+          \"Allow the JVM to flatten some non-atomic null-free values\")      \\\n+                                                                            \\\n+  product(bool, UseNullableValueFlattening, false,                          \\\n+          \"Allow the JVM to flatten some nullable values\")                  \\\n+                                                                            \\\n+  product(bool, UseAtomicValueFlattening, false,                            \\\n+          \"Allow the JVM to flatten some atomic values\")                    \\\n+                                                                            \\\n+  product(intx, FlatArrayElementMaxOops, 4,                                 \\\n+          \"Max nof embedded object references in an inline type to flatten, <0 no limit\")  \\\n+                                                                            \\\n@@ -1775,0 +1799,3 @@\n+  product(bool, IgnoreAssertUnsetFields, false, DIAGNOSTIC,                           \\\n+          \"Ignore assert_unset_fields\")                                     \\\n+                                                                            \\\n@@ -1946,0 +1973,17 @@\n+  product(bool, EnableValhalla, true,                                       \\\n+          \"Enable experimental Valhalla features\")                          \\\n+                                                                            \\\n+  product_pd(bool, InlineTypePassFieldsAsArgs,                              \\\n+          \"Pass each inline type field as an argument at calls\")            \\\n+                                                                            \\\n+  product_pd(bool, InlineTypeReturnedAsFields,                              \\\n+          \"Return fields instead of an inline type reference\")              \\\n+                                                                            \\\n+  develop(bool, StressCallingConvention, false,                             \\\n+          \"Stress the scalarized calling convention.\")                      \\\n+                                                                            \\\n+  product(ccstrlist, ForceNonTearable, \"\", DIAGNOSTIC,                      \\\n+          \"List of inline classes which are forced to be atomic \"           \\\n+          \"(whitespace and commas separate names, \"                         \\\n+          \"and leading and trailing stars '*' are wildcards)\")              \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":45,"deletions":1,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -50,0 +50,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -319,0 +319,16 @@\n+\/\/ These checks are required for wait, notify and exit to avoid inflating the monitor to\n+\/\/ find out this inline type object cannot be locked.\n+#define CHECK_THROW_NOSYNC_IMSE(obj)  \\\n+  if (EnableValhalla && (obj)->mark().is_inline_type()) {  \\\n+    JavaThread* THREAD = current;           \\\n+    ResourceMark rm(THREAD);                \\\n+    THROW_MSG(vmSymbols::java_lang_IllegalMonitorStateException(), obj->klass()->external_name()); \\\n+  }\n+\n+#define CHECK_THROW_NOSYNC_IMSE_0(obj)  \\\n+  if (EnableValhalla && (obj)->mark().is_inline_type()) {  \\\n+    JavaThread* THREAD = current;             \\\n+    ResourceMark rm(THREAD);                  \\\n+    THROW_MSG_0(vmSymbols::java_lang_IllegalMonitorStateException(), obj->klass()->external_name()); \\\n+  }\n+\n@@ -345,0 +361,1 @@\n+  assert(!EnableValhalla || !obj->klass()->is_inline_klass(), \"monitor op on inline type\");\n@@ -409,0 +426,1 @@\n+  assert(!EnableValhalla || !obj->klass()->is_inline_klass(), \"monitor op on inline type\");\n@@ -524,0 +542,1 @@\n+  assert(!EnableValhalla || !obj->klass()->is_inline_klass(), \"JITed code should never have locked an instance of a value class\");\n@@ -546,0 +565,1 @@\n+  assert(!EnableValhalla || !obj->klass()->is_inline_klass(), \"This method should never be called on an instance of an inline class\");\n@@ -565,0 +585,1 @@\n+  guarantee(!EnableValhalla || !obj->klass()->is_inline_klass(), \"Attempt to inflate inline type\");\n@@ -612,0 +633,3 @@\n+    if (EnableValhalla && mark.is_inline_type()) {\n+      return;\n+    }\n@@ -668,0 +692,1 @@\n+  JavaThread* THREAD = current;\n@@ -676,0 +701,10 @@\n+  if (EnableValhalla && obj->klass()->is_inline_klass()) {\n+    ResourceMark rm(THREAD);\n+    const char* desc = \"Cannot synchronize on an instance of value class \";\n+    const char* className = obj->klass()->external_name();\n+    size_t msglen = strlen(desc) + strlen(className) + 1;\n+    char* message = NEW_RESOURCE_ARRAY(char, msglen);\n+    assert(message != nullptr, \"NEW_RESOURCE_ARRAY should have called vm_exit_out_of_memory and not return nullptr\");\n+    THROW_MSG(vmSymbols::java_lang_IdentityException(), className);\n+  }\n+\n@@ -702,0 +737,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -746,0 +782,1 @@\n+  CHECK_THROW_NOSYNC_IMSE_0(obj);\n@@ -788,0 +825,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -816,0 +854,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -997,0 +1036,4 @@\n+  if (EnableValhalla && obj->klass()->is_inline_klass()) {\n+    \/\/ VM should be calling bootstrap method\n+    ShouldNotReachHere();\n+  }\n@@ -1123,0 +1166,3 @@\n+  if (EnableValhalla && h_obj->mark().is_inline_type()) {\n+    return false;\n+  }\n@@ -1466,0 +1512,3 @@\n+  if (EnableValhalla) {\n+    guarantee(!object->klass()->is_inline_klass(), \"Attempt to inflate inline type\");\n+  }\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":49,"deletions":0,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -61,0 +61,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/inlineKlass.hpp\"\n@@ -192,1 +194,1 @@\n-  volatile_nonstatic_field(InstanceKlass,      _array_klasses,                                ObjArrayKlass*)                        \\\n+  volatile_nonstatic_field(InstanceKlass,      _array_klasses,                                ArrayKlass*)                        \\\n@@ -940,0 +942,1 @@\n+           declare_type(FlatArrayKlass, ArrayKlass)                       \\\n@@ -943,0 +946,1 @@\n+        declare_type(InlineKlass, InstanceKlass)                          \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -270,0 +270,4 @@\n+        GET_FLAT_VALUE(\"getFlatValue\"),\n+        PUT_FLAT_VALUE(\"putFlatValue\"),\n+        GET_FLAT_VALUE_VOLATILE(\"getFlatValueVolatile\"),\n+        PUT_FLAT_VALUE_VOLATILE(\"putFlatValueVolatile\"),\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/LambdaForm.java","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1549,0 +1549,6 @@\n+            public boolean isNullRestrictedField(MethodHandle mh) {\n+                var memberName = mh.internalMemberName();\n+                assert memberName.isField();\n+                return memberName.isNullRestricted();\n+            }\n+\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/MethodHandleImpl.java","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2664,0 +2664,2 @@\n+         *\n+         *\n@@ -2677,0 +2679,3 @@\n+            if (type.returnType() != void.class) {\n+                throw new NoSuchMethodException(\"Constructors must have void return type: \" + refc.getName());\n+            }\n@@ -3843,1 +3848,0 @@\n-\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/MethodHandles.java","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -107,0 +107,3 @@\n+            new UnknownProfileData(this, config.dataLayoutArrayStoreDataTag),\n+            new UnknownProfileData(this, config.dataLayoutArrayLoadDataTag),\n+            new UnknownProfileData(this, config.dataLayoutACmpDataTag),\n","filename":"src\/jdk.internal.vm.ci\/share\/classes\/jdk\/vm\/ci\/hotspot\/HotSpotMethodData.java","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -79,0 +79,3 @@\n+compiler\/c2\/irTests\/scalarReplacement\/ScalarReplacementWithGCBarrierTests.java 8342488 generic-all\n+compiler\/c2\/TestMergeStores.java#id1 8348959 generic-all\n+\n@@ -106,0 +109,1 @@\n+runtime\/cds\/appcds\/redefineClass\/RedefineRunningMethods_Shared.java  8304168 generic-all\n@@ -127,0 +131,40 @@\n+\n+# Valhalla\n+runtime\/AccModule\/ConstModule.java 8294051 generic-all\n+runtime\/valhalla\/inlinetypes\/CircularityTest.java 8349037 generic-all\n+runtime\/valhalla\/inlinetypes\/PreloadCircularityTest.java 8349631 linux-aarch64-debug\n+runtime\/valhalla\/inlinetypes\/ValuePreloadTest.java 8349630 linux-aarch64-debug\n+compiler\/gcbarriers\/TestG1BarrierGeneration.java 8343420 generic-all\n+\n+# Valhalla + COH\n+compiler\/c2\/autovectorization\/TestIndexOverflowIR.java                          8348568 generic-all\n+compiler\/c2\/irTests\/TestVectorConditionalMove.java                              8348568 generic-all\n+compiler\/c2\/irTests\/TestVectorizationMismatchedAccess.java                      8348568 generic-all\n+compiler\/c2\/irTests\/TestVectorizationNotRun.java                                8348568 generic-all\n+compiler\/c2\/TestCastX2NotProcessedIGVN.java                                     8348568 generic-all\n+compiler\/loopopts\/superword\/TestAlignVector.java                                8348568 generic-all\n+compiler\/loopopts\/superword\/TestAlignVector.java#NoAlignVector-COH              8348568 generic-all\n+compiler\/loopopts\/superword\/TestAlignVector.java#VerifyAlignVector-COH          8348568 generic-all\n+compiler\/loopopts\/superword\/TestIndependentPacksWithCyclicDependency.java       8348568 generic-all\n+compiler\/loopopts\/superword\/TestMulAddS2I.java                                  8348568 generic-all\n+compiler\/loopopts\/superword\/TestScheduleReordersScalarMemops.java               8348568 generic-all\n+compiler\/loopopts\/superword\/TestSplitPacks.java                                 8348568 generic-all\n+compiler\/loopopts\/superword\/TestUnorderedReductionPartialVectorization.java     8348568 generic-all\n+compiler\/vectorization\/TestFloatConversionsVector.java                          8348568 generic-all\n+compiler\/vectorization\/runner\/ArrayTypeConvertTest.java                         8348568 generic-all\n+compiler\/vectorization\/runner\/LoopCombinedOpTest.java                           8348568 generic-all\n+compiler\/vectorization\/runner\/VectorizationTestRunner.java                      8348568 generic-all\n+\n+gc\/stress\/gcbasher\/TestGCBasherWithParallel.java                                8348568 generic-all\n+\n+gtest\/CompressedKlassGtest.java#use-zero-based-encoding-coh                     8348568 generic-all\n+gtest\/CompressedKlassGtest.java#use-zero-based-encoding-coh-large-class-space   8348568 generic-all\n+gtest\/MetaspaceGtests.java#UseCompactObjectHeaders                              8348568 generic-all\n+\n+runtime\/CompressedOops\/CompressedClassPointersEncodingScheme.java               8348568 generic-all\n+runtime\/FieldLayout\/BaseOffsets.java#no-coops-with-coh                          8348568 generic-all\n+runtime\/FieldLayout\/BaseOffsets.java#with-coop--with-coh                        8348568 generic-all\n+runtime\/cds\/TestDefaultArchiveLoading.java#coops_coh                            8348568 generic-all\n+runtime\/cds\/TestDefaultArchiveLoading.java#nocoops_coh                          8348568 generic-all\n+runtime\/cds\/appcds\/TestZGCWithCDS.java                                          8348568 generic-all\n+\n@@ -150,0 +194,31 @@\n+# Valhalla TODO:\n+serviceability\/jvmti\/valhalla\/HeapDump\/HeapDump.java 8317416 generic-all\n+\n+serviceability\/sa\/ClhsdbCDSCore.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbCDSJstackPrintAll.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbFindPC.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbInspect.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbLongConstant.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbJdis.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbJstack.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintAll.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintAs.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintStatics.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbSource.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbSymbol.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbWhere.java 8190936 generic-all\n+serviceability\/sa\/JhsdbThreadInfoTest.java 8190936 generic-all\n+serviceability\/sa\/TestClassDump.java 8190936 generic-all\n+serviceability\/sa\/TestClhsdbJstackLock.java 8190936 generic-all\n+serviceability\/sa\/TestCpoolForInvokeDynamic.java 8190936 generic-all\n+serviceability\/sa\/TestHeapDumpForInvokeDynamic.java 8190936 generic-all\n+serviceability\/sa\/TestHeapDumpForLargeArray.java 8190936 generic-all\n+serviceability\/sa\/TestIntConstant.java 8190936 generic-all\n+serviceability\/sa\/TestJhsdbJstackLock.java 8190936 generic-all\n+serviceability\/sa\/TestJmapCore.java 8190936 generic-all\n+serviceability\/sa\/TestJmapCoreMetaspace.java 8190936 generic-all\n+serviceability\/sa\/TestPrintMdo.java 8190936 generic-all\n+serviceability\/sa\/jmap-hprof\/JMapHProfLargeHeapTest.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbDumpclass.java 8190936 generic-all\n+\n+\n@@ -186,0 +261,2 @@\n+vmTestbase\/vm\/mlvm\/hiddenloader\/stress\/byteMutation\/Test.java 8317172 generic-all\n+\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":77,"deletions":0,"binary":false,"changes":77,"status":"modified"},{"patch":"@@ -49,1 +49,1 @@\n-  runtime\n+  runtime \\\n@@ -65,0 +65,8 @@\n+hotspot_valhalla = \\\n+  runtime\/valhalla \\\n+  compiler\/valhalla \\\n+  serviceability\/jvmti\/valhalla\n+\n+hotspot_valhalla_runtime = \\\n+  runtime\/valhalla\n+\n@@ -207,0 +215,1 @@\n+  compiler\/valhalla\/ \\\n@@ -248,0 +257,7 @@\n+\n+tier1_compiler_no_valhalla = \\\n+  :tier1_compiler_1 \\\n+  :tier1_compiler_2 \\\n+  :tier1_compiler_3 \\\n+  -compiler\/valhalla\n+\n@@ -400,0 +416,4 @@\n+tier1_runtime_no_valhalla = \\\n+  :tier1_runtime \\\n+  -runtime\/valhalla\n+\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":21,"deletions":1,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+import compiler.valhalla.inlinetypes.InlineTypeIRNode;\n@@ -155,0 +156,6 @@\n+    \/\/ Valhalla: Make sure that all Valhalla specific IR nodes are also properly initialized. Doing it here also\n+    \/\/           ensures that the Flag VM is able to pick up the correct compile phases.\n+    static {\n+        InlineTypeIRNode.forceStaticInitialization();\n+    }\n+\n@@ -345,1 +352,1 @@\n-        String optoRegex = \"(.*precise .*\\\\R((.*(?i:mov|mv|xorl|nop|spill).*|\\\\s*)\\\\R)*.*(?i:call,static).*wrapper for: C2 Runtime new_instance\" + END;\n+        String optoRegex = \"(.*precise .*\\\\R((.*(?i:mov|mv|xorl|nop|spill|pushq|popq).*|\\\\s*)\\\\R)*.*(?i:call,static).*wrapper for: C2 Runtime new_instance\" + END;\n@@ -351,1 +358,1 @@\n-        String regex = \"(.*precise .*\" + IS_REPLACED + \":.*\\\\R((.*(?i:mov|mv|xorl|nop|spill).*|\\\\s*)\\\\R)*.*(?i:call,static).*wrapper for: C2 Runtime new_instance\" + END;\n+        String regex = \"(.*precise .*\" + IS_REPLACED + \":.*\\\\R((.*(?i:mov|mv|xorl|nop|spill|pushq|popq).*|\\\\s*)\\\\R)*.*(?i:call,static).*wrapper for: C2 Runtime new_instance\" + END;\n@@ -357,1 +364,1 @@\n-        String optoRegex = \"(.*precise \\\\[.*\\\\R((.*(?i:mov|mv|xor|nop|spill).*|\\\\s*|.*(LGHI|LI).*)\\\\R)*.*(?i:call,static).*wrapper for: C2 Runtime new_array\" + END;\n+        String optoRegex = \"(.*precise \\\\[.*\\\\R((.*(?i:mov|mv|xor|nop|spill|pushq|popq).*|\\\\s*|.*(LGHI|LI).*)\\\\R)*.*(?i:call,static).*wrapper for: C2 Runtime new_array\" + END;\n@@ -363,1 +370,1 @@\n-        String regex = \"(.*precise \\\\[.*\" + IS_REPLACED + \":.*\\\\R((.*(?i:mov|mv|xorl|nop|spill).*|\\\\s*|.*(LGHI|LI).*)\\\\R)*.*(?i:call,static).*wrapper for: C2 Runtime new_array\" + END;\n+        String regex = \"(.*precise \\\\[.*\" + IS_REPLACED + \":.*\\\\R((.*(?i:mov|mv|xorl|nop|spill|pushq|popq).*|\\\\s*|.*(LGHI|LI).*)\\\\R)*.*(?i:call,static).*wrapper for: C2 Runtime new_array\" + END;\n@@ -776,0 +783,5 @@\n+    public static final String INLINE_TYPE = PREFIX + \"INLINE_TYPE\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(INLINE_TYPE, \"InlineType\");\n+    }\n+\n@@ -1877,1 +1889,1 @@\n-        beforeMatchingNameRegex(SUBTYPE_CHECK, \"SubTypeCheck\");\n+        macroNodes(SUBTYPE_CHECK, \"SubTypeCheck\");\n@@ -2577,1 +2589,1 @@\n-    private static void beforeMatching(String irNodePlaceholder, String regex) {\n+    public static void beforeMatching(String irNodePlaceholder, String regex) {\n@@ -2633,1 +2645,1 @@\n-    private static void optoOnly(String irNodePlaceholder, String regex) {\n+    public static void optoOnly(String irNodePlaceholder, String regex) {\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/IRNode.java","additions":19,"deletions":7,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -564,0 +564,12 @@\n+    \/**\n+     * Checks if deopt of {@code m} is stable at the specified {@code compLevel}.\n+     *\n+     * @param m the method to be checked.\n+     * @param compLevel the compilation level.\n+     * @return {@code true} if deopt of {@code m} is stable at {@code compLevel};\n+     *         {@code false} otherwise.\n+     *\/\n+    public static boolean isStableDeopt(Method m, CompLevel compLevel) {\n+        return TestVM.isStableDeopt(m, compLevel);\n+    }\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/TestFramework.java","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -0,0 +1,4667 @@\n+\/*\n+ * Copyright (c) 2019, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import compiler.lib.ir_framework.*;\n+import jdk.test.lib.Asserts;\n+import test.java.lang.invoke.lib.InstructionHelper;\n+\n+import java.lang.invoke.MethodHandle;\n+import java.lang.invoke.MethodHandles;\n+import java.lang.invoke.MethodType;\n+import java.lang.reflect.Method;\n+import java.util.Arrays;\n+import java.util.Objects;\n+\n+import jdk.internal.value.ValueClass;\n+import jdk.internal.vm.annotation.ImplicitlyConstructible;\n+import jdk.internal.vm.annotation.LooselyConsistentValue;\n+import jdk.internal.vm.annotation.NullRestricted;\n+\n+import static compiler.valhalla.inlinetypes.InlineTypeIRNode.*;\n+import static compiler.valhalla.inlinetypes.InlineTypes.*;\n+\n+\/*\n+ * @test\n+ * @key randomness\n+ * @summary Test inline types in LWorld.\n+ * @library \/test\/lib \/test\/jdk\/java\/lang\/invoke\/common \/\n+ * @requires (os.simpleArch == \"x64\" | os.simpleArch == \"aarch64\")\n+ * @enablePreview\n+ * @modules java.base\/jdk.internal.value\n+ *          java.base\/jdk.internal.vm.annotation\n+ * @build test.java.lang.invoke.lib.InstructionHelper\n+ * @run main\/othervm\/timeout=450 compiler.valhalla.inlinetypes.TestLWorld\n+ *\/\n+\n+@ForceCompileClassInitializer\n+public class TestLWorld {\n+\n+    public static void main(String[] args) {\n+        \/\/ Make sure Test140Value is loaded but not linked\n+        Class<?> class1 = Test140Value.class;\n+        \/\/ Make sure Test141Value is linked but not initialized\n+        Class<?> class2 = Test141Value.class;\n+        class2.getDeclaredFields();\n+\n+        Scenario[] scenarios = InlineTypes.DEFAULT_SCENARIOS;\n+        scenarios[3].addFlags(\"-XX:-MonomorphicArrayCheck\", \"-XX:+UseArrayFlattening\");\n+        scenarios[4].addFlags(\"-XX:-MonomorphicArrayCheck\");\n+\n+        InlineTypes.getFramework()\n+                   .addScenarios(scenarios)\n+                   .addHelperClasses(MyValue1.class,\n+                                     MyValue2.class,\n+                                     MyValue2Inline.class,\n+                                     MyValue3.class,\n+                                     MyValue3Inline.class)\n+                   .start();\n+    }\n+\n+    static {\n+        \/\/ Make sure RuntimeException is loaded to prevent uncommon traps in IR verified tests\n+        RuntimeException tmp = new RuntimeException(\"42\");\n+    }\n+\n+    \/\/ Helper methods\n+\n+    @NullRestricted\n+    private static final MyValue1 testValue1 = MyValue1.createWithFieldsInline(rI, rL);\n+    @NullRestricted\n+    private static final MyValue2 testValue2 = MyValue2.createWithFieldsInline(rI, rD);\n+\n+    protected long hash() {\n+        return testValue1.hash();\n+    }\n+\n+    \/\/ Test passing an inline type as an Object\n+    @DontInline\n+    public Object test1_dontinline1(Object o) {\n+        return o;\n+    }\n+\n+    @DontInline\n+    public MyValue1 test1_dontinline2(Object o) {\n+        return (MyValue1)o;\n+    }\n+\n+    @ForceInline\n+    public Object test1_inline1(Object o) {\n+        return o;\n+    }\n+\n+    @ForceInline\n+    public MyValue1 test1_inline2(Object o) {\n+        return (MyValue1)o;\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public MyValue1 test1() {\n+        MyValue1 vt = testValue1;\n+        vt = (MyValue1)test1_dontinline1(vt);\n+        vt =           test1_dontinline2(vt);\n+        vt = (MyValue1)test1_inline1(vt);\n+        vt =           test1_inline2(vt);\n+        return vt;\n+    }\n+\n+    @Run(test = \"test1\")\n+    public void test1_verifier() {\n+        Asserts.assertEQ(test1().hash(), hash());\n+    }\n+\n+    \/\/ Test storing\/loading inline types to\/from Object and inline type fields\n+    Object objectField1 = null;\n+    Object objectField2 = null;\n+    Object objectField3 = null;\n+    Object objectField4 = null;\n+    Object objectField5 = null;\n+    Object objectField6 = null;\n+\n+    @NullRestricted\n+    MyValue1 valueField1 = testValue1;\n+    @NullRestricted\n+    MyValue1 valueField2 = testValue1;\n+    MyValue1 valueField3 = testValue1;\n+    @NullRestricted\n+    MyValue1 valueField4;\n+    MyValue1 valueField5;\n+\n+    static MyValue1 staticValueField1 = testValue1;\n+    @NullRestricted\n+    static MyValue1 staticValueField2 = testValue1;\n+    @NullRestricted\n+    static MyValue1 staticValueField3;\n+    static MyValue1 staticValueField4;\n+\n+    @DontInline\n+    public Object readValueField5() {\n+        return (Object)valueField5;\n+    }\n+\n+    @DontInline\n+    public Object readStaticValueField4() {\n+        return (Object)staticValueField4;\n+    }\n+\n+    @Test\n+    public long test2(MyValue1 vt1, Object vt2) {\n+        objectField1 = vt1;\n+        objectField2 = (MyValue1)vt2;\n+        objectField3 = testValue1;\n+        objectField4 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        objectField5 = valueField1;\n+        objectField6 = valueField3;\n+        valueField1 = (MyValue1)objectField1;\n+        valueField2 = (MyValue1)vt2;\n+        valueField3 = (MyValue1)vt2;\n+        staticValueField1 = (MyValue1)objectField1;\n+        staticValueField2 = (MyValue1)vt1;\n+        \/\/ Don't inline these methods because reading NULL will trigger a deoptimization\n+        if (readValueField5() != null || readStaticValueField4() != null) {\n+            throw new RuntimeException(\"Should be null\");\n+        }\n+        return ((MyValue1)objectField1).hash() + ((MyValue1)objectField2).hash() +\n+               ((MyValue1)objectField3).hash() + ((MyValue1)objectField4).hash() +\n+               ((MyValue1)objectField5).hash() + ((MyValue1)objectField6).hash() +\n+                valueField1.hash() + valueField2.hash() + valueField3.hash() + valueField4.hashPrimitive() +\n+                staticValueField1.hash() + staticValueField2.hash() + staticValueField3.hashPrimitive();\n+    }\n+\n+    @Run(test = \"test2\")\n+    public void test2_verifier() {\n+        MyValue1 vt = testValue1;\n+        MyValue1 def = MyValue1.createDefaultDontInline();\n+        long result = test2(vt, vt);\n+        Asserts.assertEQ(result, 11*vt.hash() + 2*def.hashPrimitive());\n+    }\n+\n+    \/\/ Test merging inline types and objects\n+    @Test\n+    public Object test3(int state) {\n+        Object res = null;\n+        if (state == 0) {\n+            res = new NonValueClass(rI);\n+        } else if (state == 1) {\n+            res = MyValue1.createWithFieldsInline(rI, rL);\n+        } else if (state == 2) {\n+            res = MyValue1.createWithFieldsDontInline(rI, rL);\n+        } else if (state == 3) {\n+            res = (MyValue1)objectField1;\n+        } else if (state == 4) {\n+            res = valueField1;\n+        } else if (state == 5) {\n+            res = null;\n+        } else if (state == 6) {\n+            res = MyValue2.createWithFieldsInline(rI, rD);\n+        } else if (state == 7) {\n+            res = testValue2;\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test3\")\n+    public void test3_verifier() {\n+        objectField1 = valueField1;\n+        Object result = null;\n+        result = test3(0);\n+        Asserts.assertEQ(((NonValueClass)result).x, rI);\n+        result = test3(1);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test3(2);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test3(3);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test3(4);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test3(5);\n+        Asserts.assertEQ(result, null);\n+        result = test3(6);\n+        Asserts.assertEQ(((MyValue2)result).hash(), testValue2.hash());\n+        result = test3(7);\n+        Asserts.assertEQ(((MyValue2)result).hash(), testValue2.hash());\n+    }\n+\n+    \/\/ Test merging inline types and objects in loops\n+    @Test\n+    public Object test4(int iters) {\n+        Object res = new NonValueClass(rI);\n+        for (int i = 0; i < iters; ++i) {\n+            if (res instanceof NonValueClass) {\n+                res = MyValue1.createWithFieldsInline(rI, rL);\n+            } else {\n+                res = MyValue1.createWithFieldsInline(((MyValue1)res).x + 1, rL);\n+            }\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test4\")\n+    public void test4_verifier() {\n+        NonValueClass result1 = (NonValueClass)test4(0);\n+        Asserts.assertEQ(result1.x, rI);\n+        int iters = (Math.abs(rI) % 10) + 1;\n+        MyValue1 result2 = (MyValue1)test4(iters);\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI + iters - 1, rL);\n+        Asserts.assertEQ(result2.hash(), vt.hash());\n+    }\n+\n+    \/\/ Test inline types in object variables that are live at safepoint\n+    @Test\n+    @IR(failOn = {ALLOC, STORE, LOOP})\n+    public long test5(MyValue1 arg, boolean deopt, Method m) {\n+        Object vt1 = MyValue1.createWithFieldsInline(rI, rL);\n+        Object vt2 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        Object vt3 = arg;\n+        Object vt4 = valueField1;\n+        if (deopt) {\n+            \/\/ uncommon trap\n+            TestFramework.deoptimize(m);\n+        }\n+        return ((MyValue1)vt1).hash() + ((MyValue1)vt2).hash() +\n+               ((MyValue1)vt3).hash() + ((MyValue1)vt4).hash();\n+    }\n+\n+    @Run(test = \"test5\")\n+    public void test5_verifier(RunInfo info) {\n+        long result = test5(valueField1, !info.isWarmUp(), info.getTest());\n+        Asserts.assertEQ(result, 4*hash());\n+    }\n+\n+    \/\/ Test comparing inline types with objects\n+    @Test\n+    public boolean test6(Object arg) {\n+        Object vt = MyValue1.createWithFieldsInline(rI, rL);\n+        if (vt == arg || vt == (Object)valueField1 || vt == objectField1 || vt == null ||\n+            arg == vt || (Object)valueField1 == vt || objectField1 == vt || null == vt) {\n+            return true;\n+        }\n+        return false;\n+    }\n+\n+    @Run(test = \"test6\")\n+    public void test6_verifier() {\n+        boolean result = test6(null);\n+        Asserts.assertFalse(result);\n+    }\n+\n+    \/\/ merge of inline type and non-inline type\n+    @Test\n+    public Object test7(boolean flag) {\n+        Object res = null;\n+        if (flag) {\n+            res = valueField1;\n+        } else {\n+            res = objectField1;\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test7\")\n+    public void test7_verifier() {\n+        test7(true);\n+        test7(false);\n+    }\n+\n+    @Test\n+    public Object test8(boolean flag) {\n+        Object res = null;\n+        if (flag) {\n+            res = objectField1;\n+        } else {\n+            res = valueField1;\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test8\")\n+    public void test8_verifier() {\n+        test8(true);\n+        test8(false);\n+    }\n+\n+    \/\/ merge of inline types in a loop, stored in an object local\n+    @Test\n+    public Object test9() {\n+        Object o = valueField1;\n+        for (int i = 1; i < 100; i *= 2) {\n+            MyValue1 v = (MyValue1)o;\n+            o = MyValue1.setX(v, v.x + 1);\n+        }\n+        return o;\n+    }\n+\n+    @Run(test = \"test9\")\n+    public void test9_verifier() {\n+        test9();\n+    }\n+\n+    \/\/ merge of inline types in an object local\n+    @ForceInline\n+    public Object test10_helper() {\n+        return valueField1;\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public void test10(boolean flag) {\n+        Object o = null;\n+        if (flag) {\n+            o = valueField1;\n+        } else {\n+            o = test10_helper();\n+        }\n+        valueField1 = (MyValue1)o;\n+    }\n+\n+    @Run(test = \"test10\")\n+    public void test10_verifier() {\n+        test10(true);\n+        test10(false);\n+    }\n+\n+    \/\/ Interface tests\n+\n+    @DontInline\n+    public MyInterface test11_dontinline1(MyInterface o) {\n+        return o;\n+    }\n+\n+    @DontInline\n+    public MyValue1 test11_dontinline2(MyInterface o) {\n+        return (MyValue1)o;\n+    }\n+\n+    @ForceInline\n+    public MyInterface test11_inline1(MyInterface o) {\n+        return o;\n+    }\n+\n+    @ForceInline\n+    public MyValue1 test11_inline2(MyInterface o) {\n+        return (MyValue1)o;\n+    }\n+\n+    @Test\n+    public MyValue1 test11() {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        vt = (MyValue1)test11_dontinline1(vt);\n+        vt =           test11_dontinline2(vt);\n+        vt = (MyValue1)test11_inline1(vt);\n+        vt =           test11_inline2(vt);\n+        return vt;\n+    }\n+\n+    @Run(test = \"test11\")\n+    public void test11_verifier() {\n+        Asserts.assertEQ(test11().hash(), hash());\n+    }\n+\n+    \/\/ Test storing\/loading inline types to\/from interface and inline type fields\n+    MyInterface interfaceField1 = null;\n+    MyInterface interfaceField2 = null;\n+    MyInterface interfaceField3 = null;\n+    MyInterface interfaceField4 = null;\n+    MyInterface interfaceField5 = null;\n+    MyInterface interfaceField6 = null;\n+\n+    @DontInline\n+    public MyInterface readValueField5AsInterface() {\n+        return (MyInterface)valueField5;\n+    }\n+\n+    @DontInline\n+    public MyInterface readStaticValueField4AsInterface() {\n+        return (MyInterface)staticValueField4;\n+    }\n+\n+    @Test\n+    public long test12(MyValue1 vt1, MyInterface vt2) {\n+        interfaceField1 = vt1;\n+        interfaceField2 = (MyValue1)vt2;\n+        interfaceField3 = MyValue1.createWithFieldsInline(rI, rL);\n+        interfaceField4 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        interfaceField5 = valueField1;\n+        interfaceField6 = valueField3;\n+        valueField1 = (MyValue1)interfaceField1;\n+        valueField2 = (MyValue1)vt2;\n+        valueField3 = (MyValue1)vt2;\n+        staticValueField1 = (MyValue1)interfaceField1;\n+        staticValueField2 = (MyValue1)vt1;\n+        \/\/ Don't inline these methods because reading NULL will trigger a deoptimization\n+        if (readValueField5AsInterface() != null || readStaticValueField4AsInterface() != null) {\n+            throw new RuntimeException(\"Should be null\");\n+        }\n+        return ((MyValue1)interfaceField1).hash() + ((MyValue1)interfaceField2).hash() +\n+               ((MyValue1)interfaceField3).hash() + ((MyValue1)interfaceField4).hash() +\n+               ((MyValue1)interfaceField5).hash() + ((MyValue1)interfaceField6).hash() +\n+                valueField1.hash() + valueField2.hash() + valueField3.hash() + valueField4.hashPrimitive() +\n+                staticValueField1.hash() + staticValueField2.hash() + staticValueField3.hashPrimitive();\n+    }\n+\n+    @Run(test = \"test12\")\n+    public void test12_verifier() {\n+        MyValue1 vt = testValue1;\n+        MyValue1 def = MyValue1.createDefaultDontInline();\n+        long result = test12(vt, vt);\n+        Asserts.assertEQ(result, 11*vt.hash() + 2*def.hashPrimitive());\n+    }\n+\n+    class MyObject1 implements MyInterface {\n+        public int x;\n+\n+        public MyObject1(int x) {\n+            this.x = x;\n+        }\n+\n+        @ForceInline\n+        public long hash() {\n+            return x;\n+        }\n+    }\n+\n+    \/\/ Test merging inline types and interfaces\n+    @Test\n+    public MyInterface test13(int state) {\n+        MyInterface res = null;\n+        if (state == 0) {\n+            res = new MyObject1(rI);\n+        } else if (state == 1) {\n+            res = MyValue1.createWithFieldsInline(rI, rL);\n+        } else if (state == 2) {\n+            res = MyValue1.createWithFieldsDontInline(rI, rL);\n+        } else if (state == 3) {\n+            res = (MyValue1)objectField1;\n+        } else if (state == 4) {\n+            res = valueField1;\n+        } else if (state == 5) {\n+            res = null;\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test13\")\n+    public void test13_verifier() {\n+        objectField1 = valueField1;\n+        MyInterface result = null;\n+        result = test13(0);\n+        Asserts.assertEQ(((MyObject1)result).x, rI);\n+        result = test13(1);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test13(2);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test13(3);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test13(4);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test13(5);\n+        Asserts.assertEQ(result, null);\n+    }\n+\n+    \/\/ Test merging inline types and interfaces in loops\n+    @Test\n+    public MyInterface test14(int iters) {\n+        MyInterface res = new MyObject1(rI);\n+        for (int i = 0; i < iters; ++i) {\n+            if (res instanceof MyObject1) {\n+                res = MyValue1.createWithFieldsInline(rI, rL);\n+            } else {\n+                res = MyValue1.createWithFieldsInline(((MyValue1)res).x + 1, rL);\n+            }\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test14\")\n+    public void test14_verifier() {\n+        MyObject1 result1 = (MyObject1)test14(0);\n+        Asserts.assertEQ(result1.x, rI);\n+        int iters = (Math.abs(rI) % 10) + 1;\n+        MyValue1 result2 = (MyValue1)test14(iters);\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI + iters - 1, rL);\n+        Asserts.assertEQ(result2.hash(), vt.hash());\n+    }\n+\n+    \/\/ Test inline types in interface variables that are live at safepoint\n+    @Test\n+    @IR(failOn = {ALLOC, STORE, LOOP})\n+    public long test15(MyValue1 arg, boolean deopt, Method m) {\n+        MyInterface vt1 = MyValue1.createWithFieldsInline(rI, rL);\n+        MyInterface vt2 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        MyInterface vt3 = arg;\n+        MyInterface vt4 = valueField1;\n+        return ((MyValue1)vt1).hash() + ((MyValue1)vt2).hash() +\n+               ((MyValue1)vt3).hash() + ((MyValue1)vt4).hash();\n+    }\n+\n+    @Run(test = \"test15\")\n+    public void test15_verifier(RunInfo info) {\n+        long result = test15(valueField1, !info.isWarmUp(), info.getTest());\n+        Asserts.assertEQ(result, 4*hash());\n+    }\n+\n+    \/\/ Test comparing inline types with interfaces\n+    @Test\n+    public boolean test16(Object arg) {\n+        MyInterface vt = MyValue1.createWithFieldsInline(rI, rL);\n+        if (vt == arg || vt == (MyInterface)valueField1 || vt == interfaceField1 || vt == null ||\n+            arg == vt || (MyInterface)valueField1 == vt || interfaceField1 == vt || null == vt) {\n+            return true;\n+        }\n+        return false;\n+    }\n+\n+    @Run(test = \"test16\")\n+    public void test16_verifier() {\n+        boolean result = test16(null);\n+        Asserts.assertFalse(result);\n+    }\n+\n+    \/\/ Test subtype check when casting to inline type\n+    @Test\n+    @IR(failOn = {ALLOC})\n+    public MyValue1 test17(MyValue1 vt, Object obj) {\n+        try {\n+            vt = (MyValue1)obj;\n+            throw new RuntimeException(\"ClassCastException expected\");\n+        } catch (ClassCastException e) {\n+            \/\/ Expected\n+        }\n+        return vt;\n+    }\n+\n+    @Run(test = \"test17\")\n+    public void test17_verifier() {\n+        MyValue1 vt = testValue1;\n+        MyValue1 result = test17(vt, new NonValueClass(rI));\n+        Asserts.assertEquals(result.hash(), vt.hash());\n+    }\n+\n+    @Test\n+    public MyValue1 test18(MyValue1 vt) {\n+        Object obj = vt;\n+        vt = (MyValue1)obj;\n+        return vt;\n+    }\n+\n+    @Run(test = \"test18\")\n+    public void test18_verifier() {\n+        MyValue1 vt = testValue1;\n+        MyValue1 result = test18(vt);\n+        Asserts.assertEquals(result.hash(), vt.hash());\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public void test19(MyValue1 vt) {\n+        if (vt == null) {\n+            return;\n+        }\n+        Object obj = vt;\n+        try {\n+            MyValue2 vt2 = (MyValue2)obj;\n+            throw new RuntimeException(\"ClassCastException expected\");\n+        } catch (ClassCastException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @Run(test = \"test19\")\n+    public void test19_verifier() {\n+        test19(valueField1);\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public void test20(MyValue1 vt) {\n+        if (vt == null) {\n+            return;\n+        }\n+        Object obj = vt;\n+        try {\n+            NonValueClass i = (NonValueClass)obj;\n+            throw new RuntimeException(\"ClassCastException expected\");\n+        } catch (ClassCastException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @Run(test = \"test20\")\n+    public void test20_verifier() {\n+        test20(valueField1);\n+    }\n+\n+    \/\/ Array tests\n+\n+    private static final MyValue1[] testValue1Array = (MyValue1[])ValueClass.newNullRestrictedArray(MyValue1.class, 3);\n+    static {\n+        for (int i = 0; i < 3; ++i) {\n+            testValue1Array[i] = testValue1;\n+        }\n+    }\n+\n+    private static final MyValue1[][] testValue1Array2 = new MyValue1[][] {testValue1Array,\n+                                                                           testValue1Array,\n+                                                                           testValue1Array};\n+\n+    private static final MyValue2[] testValue2Array = (MyValue2[])ValueClass.newNullRestrictedArray(MyValue2.class, 3);\n+    static {\n+        for (int i = 0; i < 3; ++i) {\n+            testValue2Array[i] = testValue2;\n+        }\n+    }\n+\n+    private static final NonValueClass[] testNonValueArray = new NonValueClass[42];\n+\n+    \/\/ Test load from (flattened) inline type array disguised as object array\n+    @Test\n+    public Object test21(Object[] oa, int index) {\n+        return oa[index];\n+    }\n+\n+    @Run(test = \"test21\")\n+    public void test21_verifier() {\n+        MyValue1 result = (MyValue1)test21(testValue1Array, Math.abs(rI) % 3);\n+        Asserts.assertEQ(result.hash(), hash());\n+    }\n+\n+    \/\/ Test load from (flattened) inline type array disguised as interface array\n+    @Test\n+    public Object test22Interface(MyInterface[] ia, int index) {\n+        return ia[index];\n+    }\n+\n+    @Run(test = \"test22Interface\")\n+    public void test22Interface_verifier() {\n+        MyValue1 result = (MyValue1)test22Interface(testValue1Array, Math.abs(rI) % 3);\n+        Asserts.assertEQ(result.hash(), hash());\n+    }\n+\n+    \/\/ Test load from (flattened) inline type array disguised as abstract array\n+    @Test\n+    public Object test22Abstract(MyAbstract[] ia, int index) {\n+        return ia[index];\n+    }\n+\n+    @Run(test = \"test22Abstract\")\n+    public void test22Abstract_verifier() {\n+        MyValue1 result = (MyValue1)test22Abstract(testValue1Array, Math.abs(rI) % 3);\n+        Asserts.assertEQ(result.hash(), hash());\n+    }\n+\n+    \/\/ Test inline store to (flattened) inline type array disguised as object array\n+    @ForceInline\n+    public void test23_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test\n+    public void test23(Object[] oa, MyValue1 vt, int index) {\n+        test23_inline(oa, vt, index);\n+    }\n+\n+    @Run(test = \"test23\")\n+    public void test23_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI + 1, rL + 1);\n+        test23(testValue1Array, vt, index);\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt.hash());\n+        testValue1Array[index] = testValue1;\n+        try {\n+            test23(testValue2Array, vt, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue2Array[index].hash(), testValue2.hash());\n+    }\n+\n+    @ForceInline\n+    public void test24_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test\n+    public void test24(Object[] oa, MyValue1 vt, int index) {\n+        test24_inline(oa, vt, index);\n+    }\n+\n+    @Run(test = \"test24\")\n+    public void test24_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test24(testNonValueArray, testValue1, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @ForceInline\n+    public void test25_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test\n+    public void test25(Object[] oa, MyValue1 vt, int index) {\n+        test25_inline(oa, vt, index);\n+    }\n+\n+    @Run(test = \"test25\")\n+    public void test25_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test25(null, testValue1, index);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test inline store to (flattened) inline type array disguised as interface array\n+    @ForceInline\n+    public void test26Interface_inline(MyInterface[] ia, MyInterface i, int index) {\n+        ia[index] = i;\n+    }\n+\n+    @Test\n+    public void test26Interface(MyInterface[] ia, MyValue1 vt, int index) {\n+      test26Interface_inline(ia, vt, index);\n+    }\n+\n+    @Run(test = \"test26Interface\")\n+    public void test26Interface_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI + 1, rL + 1);\n+        test26Interface(testValue1Array, vt, index);\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt.hash());\n+        testValue1Array[index] = testValue1;\n+        try {\n+            test26Interface(testValue2Array, vt, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue2Array[index].hash(), testValue2.hash());\n+    }\n+\n+    @ForceInline\n+    public void test27Interface_inline(MyInterface[] ia, MyInterface i, int index) {\n+        ia[index] = i;\n+    }\n+\n+    @Test\n+    public void test27Interface(MyInterface[] ia, MyValue1 vt, int index) {\n+        test27Interface_inline(ia, vt, index);\n+    }\n+\n+    @Run(test = \"test27Interface\")\n+    public void test27Interface_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test27Interface(null, testValue1, index);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test inline store to (flattened) inline type array disguised as abstract array\n+    @ForceInline\n+    public void test26Abstract_inline(MyAbstract[] ia, MyAbstract i, int index) {\n+        ia[index] = i;\n+    }\n+\n+    @Test\n+    public void test26Abstract(MyAbstract[] ia, MyValue1 vt, int index) {\n+      test26Abstract_inline(ia, vt, index);\n+    }\n+\n+    @Run(test = \"test26Abstract\")\n+    public void test26Abstract_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI + 1, rL + 1);\n+        test26Abstract(testValue1Array, vt, index);\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt.hash());\n+        testValue1Array[index] = testValue1;\n+        try {\n+            test26Abstract(testValue2Array, vt, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue2Array[index].hash(), testValue2.hash());\n+    }\n+\n+    @ForceInline\n+    public void test27Abstract_inline(MyAbstract[] ia, MyAbstract i, int index) {\n+        ia[index] = i;\n+    }\n+\n+    @Test\n+    public void test27Abstract(MyAbstract[] ia, MyValue1 vt, int index) {\n+        test27Abstract_inline(ia, vt, index);\n+    }\n+\n+    @Run(test = \"test27Abstract\")\n+    public void test27Abstract_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test27Abstract(null, testValue1, index);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test object store to (flattened) inline type array disguised as object array\n+    @ForceInline\n+    public void test28_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test\n+    public void test28(Object[] oa, Object o, int index) {\n+        test28_inline(oa, o, index);\n+    }\n+\n+    @Run(test = \"test28\")\n+    public void test28_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        MyValue1 vt1 = MyValue1.createWithFieldsInline(rI + 1, rL + 1);\n+        test28(testValue1Array, vt1, index);\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt1.hash());\n+        try {\n+            test28(testValue1Array, testValue2, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt1.hash());\n+        testValue1Array[index] = testValue1;\n+    }\n+\n+    @ForceInline\n+    public void test29_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test\n+    public void test29(Object[] oa, Object o, int index) {\n+        test29_inline(oa, o, index);\n+    }\n+\n+    @Run(test = \"test29\")\n+    public void test29_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test29(testValue2Array, testValue1, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue2Array[index].hash(), testValue2.hash());\n+    }\n+\n+    @ForceInline\n+    public void test30_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test\n+    public void test30(Object[] oa, Object o, int index) {\n+        test30_inline(oa, o, index);\n+    }\n+\n+    @Run(test = \"test30\")\n+    public void test30_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test30(testNonValueArray, testValue1, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test inline store to (flattened) inline type array disguised as interface array\n+    @ForceInline\n+    public void test31Interface_inline(MyInterface[] ia, MyInterface i, int index) {\n+        ia[index] = i;\n+    }\n+\n+    @Test\n+    public void test31Interface(MyInterface[] ia, MyInterface i, int index) {\n+        test31Interface_inline(ia, i, index);\n+    }\n+\n+    @Run(test = \"test31Interface\")\n+    public void test31Interface_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        MyValue1 vt1 = MyValue1.createWithFieldsInline(rI + 1, rL + 1);\n+        test31Interface(testValue1Array, vt1, index);\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt1.hash());\n+        try {\n+            test31Interface(testValue1Array, testValue2, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt1.hash());\n+        testValue1Array[index] = testValue1;\n+    }\n+\n+    @ForceInline\n+    public void test32Interface_inline(MyInterface[] ia, MyInterface i, int index) {\n+        ia[index] = i;\n+    }\n+\n+    @Test\n+    public void test32Interface(MyInterface[] ia, MyInterface i, int index) {\n+        test32Interface_inline(ia, i, index);\n+    }\n+\n+    @Run(test = \"test32Interface\")\n+    public void test32Interface_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test32Interface(testValue2Array, testValue1, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test inline store to (flattened) inline type array disguised as abstract array\n+    @ForceInline\n+    public void test31Abstract_inline(MyAbstract[] ia, MyAbstract i, int index) {\n+        ia[index] = i;\n+    }\n+\n+    @Test\n+    public void test31Abstract(MyAbstract[] ia, MyAbstract i, int index) {\n+        test31Abstract_inline(ia, i, index);\n+    }\n+\n+    @Run(test = \"test31Abstract\")\n+    public void test31Abstract_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        MyValue1 vt1 = MyValue1.createWithFieldsInline(rI + 1, rL + 1);\n+        test31Abstract(testValue1Array, vt1, index);\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt1.hash());\n+        try {\n+            test31Abstract(testValue1Array, testValue2, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt1.hash());\n+        testValue1Array[index] = testValue1;\n+    }\n+\n+    @ForceInline\n+    public void test32Abstract_inline(MyAbstract[] ia, MyAbstract i, int index) {\n+        ia[index] = i;\n+    }\n+\n+    @Test\n+    public void test32Abstract(MyAbstract[] ia, MyAbstract i, int index) {\n+        test32Abstract_inline(ia, i, index);\n+    }\n+\n+    @Run(test = \"test32Abstract\")\n+    public void test32Abstract_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test32Abstract(testValue2Array, testValue1, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test writing null to a (flattened) inline type array disguised as object array\n+    @ForceInline\n+    public void test33_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test\n+    public void test33(Object[] oa, Object o, int index) {\n+        test33_inline(oa, o, index);\n+    }\n+\n+    @Run(test = \"test33\")\n+    public void test33_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test33(testValue1Array, null, index);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), hash());\n+    }\n+\n+    \/\/ Test writing constant null to a (flattened) inline type array disguised as object array\n+\n+    @ForceInline\n+    public void test34_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test\n+    public void test34(Object[] oa, int index) {\n+        test34_inline(oa, null, index);\n+    }\n+\n+    @Run(test = \"test34\")\n+    public void test34_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test34(testValue1Array, index);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), hash());\n+    }\n+\n+    \/\/ Test writing constant null to a (flattened) inline type array\n+\n+    private static final MethodHandle setArrayElementNull = InstructionHelper.buildMethodHandle(MethodHandles.lookup(),\n+        \"setArrayElementNull\",\n+        MethodType.methodType(void.class, TestLWorld.class, MyValue1[].class, int.class),\n+        CODE -> {\n+            CODE.\n+            aload(1).\n+            iload(2).\n+            aconst_null().\n+            aastore().\n+            return_();\n+        });\n+\n+    @Test\n+    public void test35(MyValue1[] va, int index) throws Throwable {\n+        setArrayElementNull.invoke(this, va, index);\n+    }\n+\n+    @Run(test = \"test35\")\n+    @Warmup(10000)\n+    public void test35_verifier() throws Throwable {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test35(testValue1Array, index);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), hash());\n+    }\n+\n+    \/\/ Test writing an inline type to a null inline type array\n+    @Test\n+    public void test36(MyValue1[] va, MyValue1 vt, int index) {\n+        va[index] = vt;\n+    }\n+\n+    @Run(test = \"test36\")\n+    public void test36_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test36(null, testValue1Array[index], index);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test incremental inlining\n+    @ForceInline\n+    public void test37_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public void test37(MyValue1[] va, Object o, int index) {\n+        test37_inline(va, o, index);\n+    }\n+\n+    @Run(test = \"test37\")\n+    public void test37_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        MyValue1 vt1 = MyValue1.createWithFieldsInline(rI + 1, rL + 1);\n+        test37(testValue1Array, vt1, index);\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt1.hash());\n+        try {\n+            test37(testValue1Array, testValue2, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt1.hash());\n+        testValue1Array[index] = testValue1;\n+    }\n+\n+    \/\/ Test merging of inline type arrays\n+\n+    @ForceInline\n+    public Object[] test38_inline() {\n+        return (MyValue1[])ValueClass.newNullRestrictedArray(MyValue1.class, 42);\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC})\n+    public Object[] test38(Object[] oa, Object o, int i1, int i2, int num) {\n+        Object[] result = null;\n+        switch (num) {\n+        case 0:\n+            result = test38_inline();\n+            break;\n+        case 1:\n+            result = oa;\n+            break;\n+        case 2:\n+            result = testValue1Array;\n+            break;\n+        case 3:\n+            result = testValue2Array;\n+            break;\n+        case 4:\n+            result = testNonValueArray;\n+            break;\n+        case 5:\n+            result = null;\n+            break;\n+        case 6:\n+            result = testValue1Array2;\n+            break;\n+        }\n+        result[i1] = result[i2];\n+        result[i2] = o;\n+        return result;\n+    }\n+\n+    @Run(test = \"test38\")\n+    public void test38_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        MyValue1[] va = (MyValue1[])ValueClass.newNullRestrictedArray(MyValue1.class, 42);\n+        Object[] result = test38(null, testValue1, index, index, 0);\n+        Asserts.assertEQ(((MyValue1)result[index]).hash(), testValue1.hash());\n+        result = test38(testValue1Array, testValue1, index, index, 1);\n+        Asserts.assertEQ(((MyValue1)result[index]).hash(), testValue1.hash());\n+        result = test38(null, testValue1, index, index, 2);\n+        Asserts.assertEQ(((MyValue1)result[index]).hash(), testValue1.hash());\n+        result = test38(null, testValue2, index, index, 3);\n+        Asserts.assertEQ(((MyValue2)result[index]).hash(), testValue2.hash());\n+        try {\n+            result = test38(null, null, index, index, 3);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        result = test38(null, null, index, index, 4);\n+        try {\n+            result = test38(null, testValue1, index, index, 4);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        try {\n+            result = test38(null, testValue1, index, index, 5);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        result = test38(null, testValue1Array, index, index, 6);\n+        Asserts.assertEQ(((MyValue1[][])result)[index][index].hash(), testValue1.hash());\n+    }\n+\n+    @ForceInline\n+    public Object test39_inline() {\n+        return (MyValue1[])ValueClass.newNullRestrictedArray(MyValue1.class, 42);\n+    }\n+\n+    \/\/ Same as above but merging into Object instead of Object[]\n+    @Test\n+    public Object test39(Object oa, Object o, int i1, int i2, int num) {\n+        Object result = null;\n+        switch (num) {\n+        case 0:\n+            result = test39_inline();\n+            break;\n+        case 1:\n+            result = oa;\n+            break;\n+        case 2:\n+            result = testValue1Array;\n+            break;\n+        case 3:\n+            result = testValue2Array;\n+            break;\n+        case 4:\n+            result = testNonValueArray;\n+            break;\n+        case 5:\n+            result = null;\n+            break;\n+        case 6:\n+            result = testValue1;\n+            break;\n+        case 7:\n+            result = testValue2;\n+            break;\n+        case 8:\n+            result = MyValue1.createWithFieldsInline(rI, rL);\n+            break;\n+        case 9:\n+            result = new NonValueClass(42);\n+            break;\n+        case 10:\n+            result = testValue1Array2;\n+            break;\n+        }\n+        if (result instanceof Object[]) {\n+            ((Object[])result)[i1] = ((Object[])result)[i2];\n+            ((Object[])result)[i2] = o;\n+        }\n+        return result;\n+    }\n+\n+    @Run(test = \"test39\")\n+    public void test39_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        MyValue1[] va = (MyValue1[])ValueClass.newNullRestrictedArray(MyValue1.class, 42);\n+        Object result = test39(null, testValue1, index, index, 0);\n+        Asserts.assertEQ(((MyValue1[])result)[index].hash(), testValue1.hash());\n+        result = test39(testValue1Array, testValue1, index, index, 1);\n+        Asserts.assertEQ(((MyValue1[])result)[index].hash(), testValue1.hash());\n+        result = test39(null, testValue1, index, index, 2);\n+        Asserts.assertEQ(((MyValue1[])result)[index].hash(), testValue1.hash());\n+        result = test39(null, testValue2, index, index, 3);\n+        Asserts.assertEQ(((MyValue2[])result)[index].hash(), testValue2.hash());\n+        try {\n+            result = test39(null, null, index, index, 3);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        result = test39(null, null, index, index, 4);\n+        try {\n+            result = test39(null, testValue1, index, index, 4);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        result = test39(null, testValue1, index, index, 5);\n+        Asserts.assertEQ(result, null);\n+        result = test39(null, testValue1, index, index, 6);\n+        Asserts.assertEQ(((MyValue1)result).hash(), testValue1.hash());\n+        result = test39(null, testValue1, index, index, 7);\n+        Asserts.assertEQ(((MyValue2)result).hash(), testValue2.hash());\n+        result = test39(null, testValue1, index, index, 8);\n+        Asserts.assertEQ(((MyValue1)result).hash(), testValue1.hash());\n+        result = test39(null, testValue1, index, index, 9);\n+        Asserts.assertEQ(((NonValueClass)result).x, 42);\n+        result = test39(null, testValue1Array, index, index, 10);\n+        Asserts.assertEQ(((MyValue1[][])result)[index][index].hash(), testValue1.hash());\n+    }\n+\n+    \/\/ Test instanceof with inline types and arrays\n+    @Test\n+    @IR(applyIf = {\"InlineTypePassFieldsAsArgs\", \"true\"},\n+        failOn = {ALLOC_G})\n+    public long test40(Object o, int index) {\n+        if (o instanceof MyValue1) {\n+          return ((MyValue1)o).hashInterpreted();\n+        } else if (o instanceof MyValue1[]) {\n+          return ((MyValue1[])o)[index].hashInterpreted();\n+        } else if (o instanceof MyValue2) {\n+          return ((MyValue2)o).hash();\n+        } else if (o instanceof MyValue2[]) {\n+          return ((MyValue2[])o)[index].hash();\n+        } else if (o instanceof MyValue1[][]) {\n+          return ((MyValue1[][])o)[index][index].hash();\n+        } else if (o instanceof Long) {\n+          return (long)o;\n+        }\n+        return 0;\n+    }\n+\n+    @Run(test = \"test40\")\n+    public void test40_verifier() {\n+        int index = Math.abs(rI) % 3;\n+        long result = test40(testValue1, 0);\n+        Asserts.assertEQ(result, testValue1.hashInterpreted());\n+        result = test40(testValue1Array, index);\n+        Asserts.assertEQ(result, testValue1.hashInterpreted());\n+        result = test40(testValue2, index);\n+        Asserts.assertEQ(result, testValue2.hash());\n+        result = test40(testValue2Array, index);\n+        Asserts.assertEQ(result, testValue2.hash());\n+        result = test40(testValue1Array2, index);\n+        Asserts.assertEQ(result, testValue1.hash());\n+        result = test40(Long.valueOf(42), index);\n+        Asserts.assertEQ(result, 42L);\n+    }\n+\n+    \/\/ Test for bug in Escape Analysis\n+    @DontInline\n+    public void test41_dontinline(Object o) {\n+        Asserts.assertEQ(o, rI);\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC})\n+    public void test41() {\n+        MyValue1[] vals = (MyValue1[])ValueClass.newNullRestrictedArray(MyValue1.class, 1);\n+        vals[0] = testValue1;\n+        test41_dontinline(vals[0].oa[0]);\n+        test41_dontinline(vals[0].oa[0]);\n+    }\n+\n+    @Run(test = \"test41\")\n+    public void test41_verifier() {\n+        test41();\n+    }\n+\n+    \/\/ Test for bug in Escape Analysis\n+    private static final MyValue1 test42VT1 = MyValue1.createWithFieldsInline(rI, rL);\n+    private static final MyValue1 test42VT2 = MyValue1.createWithFieldsInline(rI + 1, rL + 1);\n+\n+    @Test\n+    @IR(failOn = {ALLOC})\n+    public void test42() {\n+        MyValue1[] vals = (MyValue1[])ValueClass.newNullRestrictedArray(MyValue1.class, 2);\n+        vals[0] = test42VT1;\n+        vals[1] = test42VT2;\n+        Asserts.assertEQ(vals[0].hash(), test42VT1.hash());\n+        Asserts.assertEQ(vals[1].hash(), test42VT2.hash());\n+    }\n+\n+    @Run(test = \"test42\")\n+    public void test42_verifier(RunInfo info) {\n+        if (!info.isWarmUp()) test42(); \/\/ We need -Xcomp behavior\n+    }\n+\n+    \/\/ Test for bug in Escape Analysis\n+    @Test\n+    @IR(failOn = {ALLOC})\n+    public long test43(boolean deopt, Method m) {\n+        MyValue1[] vals = (MyValue1[])ValueClass.newNullRestrictedArray(MyValue1.class, 2);\n+        vals[0] = test42VT1;\n+        vals[1] = test42VT2;\n+\n+        if (deopt) {\n+            \/\/ uncommon trap\n+            TestFramework.deoptimize(m);\n+            Asserts.assertEQ(vals[0].hash(), test42VT1.hash());\n+            Asserts.assertEQ(vals[1].hash(), test42VT2.hash());\n+        }\n+\n+        return vals[0].hash();\n+    }\n+\n+    @Run(test = \"test43\")\n+    public void test43_verifier(RunInfo info) {\n+        test43(!info.isWarmUp(), info.getTest());\n+    }\n+\n+    \/\/ Tests writing an array element with a (statically known) incompatible type\n+    private static final MethodHandle setArrayElementIncompatible = InstructionHelper.buildMethodHandle(MethodHandles.lookup(),\n+        \"setArrayElementIncompatible\",\n+        MethodType.methodType(void.class, TestLWorld.class, MyValue1[].class, int.class, MyValue2.class),\n+        CODE -> {\n+            CODE.\n+            aload(1).\n+            iload(2).\n+            aload(3).\n+            aastore().\n+            return_();\n+        });\n+\n+    @Test\n+    public void test44(MyValue1[] va, int index, MyValue2 v) throws Throwable {\n+        setArrayElementIncompatible.invoke(this, va, index, v);\n+    }\n+\n+    @Run(test = \"test44\")\n+    @Warmup(10000)\n+    public void test44_verifier() throws Throwable {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test44(testValue1Array, index, testValue2);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), hash());\n+    }\n+\n+    \/\/ Tests writing an array element with a (statically known) incompatible type\n+    @ForceInline\n+    public void test45_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test\n+    public void test45(MyValue1[] va, int index, MyValue2 v) throws Throwable {\n+        test45_inline(va, v, index);\n+    }\n+\n+    @Run(test = \"test45\")\n+    public void test45_verifier() throws Throwable {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test45(testValue1Array, index, testValue2);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), hash());\n+    }\n+\n+    \/\/ instanceof tests with inline types\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public boolean test46(MyValue1 vt) {\n+        Object obj = vt;\n+        return obj instanceof MyValue1;\n+    }\n+\n+    @Run(test = \"test46\")\n+    public void test46_verifier() {\n+        MyValue1 vt = testValue1;\n+        boolean result = test46(vt);\n+        Asserts.assertTrue(result);\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public boolean test47(MyValue1 vt) {\n+        Object obj = vt;\n+        return obj instanceof MyValue2;\n+    }\n+\n+    @Run(test = \"test47\")\n+    public void test47_verifier() {\n+        MyValue1 vt = testValue1;\n+        boolean result = test47(vt);\n+        Asserts.assertFalse(result);\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public boolean test48(Object obj) {\n+        return obj instanceof MyValue1;\n+    }\n+\n+    @Run(test = \"test48\")\n+    public void test48_verifier() {\n+        MyValue1 vt = testValue1;\n+        boolean result = test48(vt);\n+        Asserts.assertTrue(result);\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public boolean test49(Object obj) {\n+        return obj instanceof MyValue2;\n+    }\n+\n+    @Run(test = \"test49\")\n+    public void test49_verifier() {\n+        MyValue1 vt = testValue1;\n+        boolean result = test49(vt);\n+        Asserts.assertFalse(result);\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public boolean test50(Object obj) {\n+        return obj instanceof MyValue1;\n+    }\n+\n+    @Run(test = \"test50\")\n+    public void test50_verifier() {\n+        Asserts.assertFalse(test49(new NonValueClass(42)));\n+    }\n+\n+    \/\/ Inline type with some non-flattened fields\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    value class Test51Value {\n+        Object objectField1;\n+        Object objectField2;\n+        Object objectField3;\n+        Object objectField4;\n+        Object objectField5;\n+        Object objectField6;\n+\n+        @NullRestricted\n+        MyValue1 valueField1;\n+        @NullRestricted\n+        MyValue1 valueField2;\n+        MyValue1 valueField3;\n+        @NullRestricted\n+        MyValue1 valueField4;\n+        MyValue1 valueField5;\n+\n+        public Test51Value() {\n+            objectField1 = null;\n+            objectField2 = null;\n+            objectField3 = null;\n+            objectField4 = null;\n+            objectField5 = null;\n+            objectField6 = null;\n+            valueField1 = testValue1;\n+            valueField2 = testValue1;\n+            valueField3 = testValue1;\n+            valueField4 = MyValue1.createDefaultDontInline();\n+            valueField5 = MyValue1.createDefaultDontInline();\n+        }\n+\n+        public Test51Value(Object o1, Object o2, Object o3, Object o4, Object o5, Object o6,\n+                           MyValue1 vt1, MyValue1 vt2, MyValue1 vt3, MyValue1 vt4, MyValue1 vt5) {\n+            objectField1 = o1;\n+            objectField2 = o2;\n+            objectField3 = o3;\n+            objectField4 = o4;\n+            objectField5 = o5;\n+            objectField6 = o6;\n+            valueField1 = vt1;\n+            valueField2 = vt2;\n+            valueField3 = vt3;\n+            valueField4 = vt4;\n+            valueField5 = vt5;\n+        }\n+\n+        @ForceInline\n+        public long test(Test51Value holder, MyValue1 vt1, Object vt2) {\n+            holder = new Test51Value(vt1, holder.objectField2, holder.objectField3, holder.objectField4, holder.objectField5, holder.objectField6,\n+                                     holder.valueField1, holder.valueField2, holder.valueField3, holder.valueField4, holder.valueField5);\n+            holder = new Test51Value(holder.objectField1, (MyValue1)vt2, holder.objectField3, holder.objectField4, holder.objectField5, holder.objectField6,\n+                                     holder.valueField1, holder.valueField2, holder.valueField3, holder.valueField4, holder.valueField5);\n+            holder = new Test51Value(holder.objectField1, holder.objectField2, testValue1, holder.objectField4, holder.objectField5, holder.objectField6,\n+                                     holder.valueField1, holder.valueField2, holder.valueField3, holder.valueField4, holder.valueField5);\n+            holder = new Test51Value(holder.objectField1, holder.objectField2, holder.objectField3, MyValue1.createWithFieldsDontInline(rI, rL), holder.objectField5, holder.objectField6,\n+                                     holder.valueField1, holder.valueField2, holder.valueField3, holder.valueField4, holder.valueField5);\n+            holder = new Test51Value(holder.objectField1, holder.objectField2, holder.objectField3, holder.objectField4, holder.valueField1, holder.objectField6,\n+                                     holder.valueField1, holder.valueField2, holder.valueField3, holder.valueField4, holder.valueField5);\n+            holder = new Test51Value(holder.objectField1, holder.objectField2, holder.objectField3, holder.objectField4, holder.objectField5, holder.valueField3,\n+                                     holder.valueField1, holder.valueField2, holder.valueField3, holder.valueField4, holder.valueField5);\n+            holder = new Test51Value(holder.objectField1, holder.objectField2, holder.objectField3, holder.objectField4, holder.objectField5, holder.objectField6,\n+                                     (MyValue1)holder.objectField1, holder.valueField2, holder.valueField3, holder.valueField4, holder.valueField5);\n+            holder = new Test51Value(holder.objectField1, holder.objectField2, holder.objectField3, holder.objectField4, holder.objectField5, holder.objectField6,\n+                                     holder.valueField1, (MyValue1)vt2, holder.valueField3, holder.valueField4, holder.valueField5);\n+            holder = new Test51Value(holder.objectField1, holder.objectField2, holder.objectField3, holder.objectField4, holder.objectField5, holder.objectField6,\n+                                     holder.valueField1, holder.valueField2, (MyValue1)vt2, holder.valueField4, holder.valueField5);\n+\n+            return ((MyValue1)holder.objectField1).hash() +\n+                   ((MyValue1)holder.objectField2).hash() +\n+                   ((MyValue1)holder.objectField3).hash() +\n+                   ((MyValue1)holder.objectField4).hash() +\n+                   ((MyValue1)holder.objectField5).hash() +\n+                   ((MyValue1)holder.objectField6).hash() +\n+                   holder.valueField1.hash() +\n+                   holder.valueField2.hash() +\n+                   holder.valueField3.hash() +\n+                   holder.valueField4.hashPrimitive();\n+        }\n+    }\n+\n+    \/\/ Pass arguments via fields to avoid exzessive spilling leading to compilation bailouts\n+    @NullRestricted\n+    static Test51Value test51_arg1;\n+    @NullRestricted\n+    static MyValue1 test51_arg2;\n+    static Object test51_arg3;\n+\n+    \/\/ Same as test2 but with field holder being an inline type\n+    @Test\n+    public long test51() {\n+        return test51_arg1.test(test51_arg1, test51_arg2, test51_arg3);\n+    }\n+\n+    @Run(test = \"test51\")\n+    public void test51_verifier() {\n+        MyValue1 vt = testValue1;\n+        MyValue1 def = MyValue1.createDefaultDontInline();\n+        Test51Value holder = new Test51Value();\n+        Asserts.assertEQ(testValue1.hash(), vt.hash());\n+        Asserts.assertEQ(holder.valueField1.hash(), vt.hash());\n+        test51_arg1 = holder;\n+        test51_arg2 = vt;\n+        test51_arg3 = vt;\n+        long result = test51();\n+        Asserts.assertEQ(result, 9*vt.hash() + def.hashPrimitive());\n+    }\n+\n+    \/\/ Access non-flattened, uninitialized inline type field with inline type holder\n+    @Test\n+    @IR(failOn = {ALLOC})\n+    public void test52(Test51Value holder) {\n+        if ((Object)holder.valueField5 != null) {\n+            throw new RuntimeException(\"Should be null\");\n+        }\n+    }\n+\n+    @Run(test = \"test52\")\n+    public void test52_verifier() {\n+        Test51Value vt = new Test51Value(null, null, null, null, null, null,\n+                                         MyValue1.createDefaultInline(), MyValue1.createDefaultInline(), null, MyValue1.createDefaultInline(), null);\n+        test52(vt);\n+    }\n+\n+    \/\/ Merging inline types of different types\n+    @Test\n+    public Object test53(Object o, boolean b) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        return b ? vt : o;\n+    }\n+\n+    @Run(test = \"test53\")\n+    public void test53_verifier() {\n+        test53(new Object(), false);\n+        MyValue1 result = (MyValue1)test53(new Object(), true);\n+        Asserts.assertEQ(result.hash(), hash());\n+    }\n+\n+    @Test\n+    public Object test54(boolean b) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        return b ? vt : testValue2;\n+    }\n+\n+    @Run(test = \"test54\")\n+    public void test54_verifier() {\n+        MyValue1 result1 = (MyValue1)test54(true);\n+        Asserts.assertEQ(result1.hash(), hash());\n+        MyValue2 result2 = (MyValue2)test54(false);\n+        Asserts.assertEQ(result2.hash(), testValue2.hash());\n+    }\n+\n+    @Test\n+    public Object test55(boolean b) {\n+        MyValue1 vt1 = MyValue1.createWithFieldsInline(rI, rL);\n+        MyValue2 vt2 = MyValue2.createWithFieldsInline(rI, rD);\n+        return b ? vt1 : vt2;\n+    }\n+\n+    @Run(test = \"test55\")\n+    public void test55_verifier() {\n+        MyValue1 result1 = (MyValue1)test55(true);\n+        Asserts.assertEQ(result1.hash(), hash());\n+        MyValue2 result2 = (MyValue2)test55(false);\n+        Asserts.assertEQ(result2.hash(), testValue2.hash());\n+    }\n+\n+    \/\/ Test synchronization on inline types\n+    @Test\n+    public void test56(Object vt) {\n+        synchronized (vt) {\n+            throw new RuntimeException(\"test56 failed: synchronization on inline type should not succeed\");\n+        }\n+    }\n+\n+    @Run(test = \"test56\")\n+    public void test56_verifier() {\n+        try {\n+            test56(testValue1);\n+            throw new RuntimeException(\"test56 failed: no exception thrown\");\n+        } catch (IdentityException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @ForceInline\n+    public void test57_inline(Object vt) {\n+        synchronized (vt) {\n+            throw new RuntimeException(\"test57 failed: synchronization on inline type should not succeed\");\n+        }\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public void test57(MyValue1 vt) {\n+        test57_inline(vt);\n+    }\n+\n+    @Run(test = \"test57\")\n+    public void test57_verifier() {\n+        try {\n+            test57(testValue1);\n+            throw new RuntimeException(\"test57 failed: no exception thrown\");\n+        } catch (IdentityException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @ForceInline\n+    public void test58_inline(Object vt) {\n+        synchronized (vt) {\n+            throw new RuntimeException(\"test58 failed: synchronization on inline type should not succeed\");\n+        }\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC})\n+    public void test58() {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        test58_inline(vt);\n+    }\n+\n+    @Run(test = \"test58\")\n+    public void test58_verifier() {\n+        try {\n+            test58();\n+            throw new RuntimeException(\"test58 failed: no exception thrown\");\n+        } catch (IdentityException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @Test\n+    public void test59(Object o, boolean b) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        Object sync = b ? vt : o;\n+        synchronized (sync) {\n+            if (b) {\n+                throw new RuntimeException(\"test59 failed: synchronization on inline type should not succeed\");\n+            }\n+        }\n+    }\n+\n+    @Run(test = \"test59\")\n+    public void test59_verifier() {\n+        test59(new Object(), false);\n+        try {\n+            test59(new Object(), true);\n+            throw new RuntimeException(\"test59 failed: no exception thrown\");\n+        } catch (IdentityException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @Test\n+    public void test60(boolean b) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        Object sync = b ? vt : testValue2;\n+        synchronized (sync) {\n+            throw new RuntimeException(\"test60 failed: synchronization on inline type should not succeed\");\n+        }\n+    }\n+\n+    @Run(test = \"test60\")\n+    public void test60_verifier() {\n+        try {\n+            test60(false);\n+            throw new RuntimeException(\"test60 failed: no exception thrown\");\n+        } catch (IdentityException ex) {\n+            \/\/ Expected\n+        }\n+        try {\n+            test60(true);\n+            throw new RuntimeException(\"test60 failed: no exception thrown\");\n+        } catch (IdentityException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test catching the IdentityException in compiled code\n+    @Test\n+    public void test61(Object vt) {\n+        boolean thrown = false;\n+        try {\n+            synchronized (vt) {\n+                throw new RuntimeException(\"test61 failed: no exception thrown\");\n+            }\n+        } catch (IdentityException ex) {\n+            thrown = true;\n+        }\n+        if (!thrown) {\n+            throw new RuntimeException(\"test61 failed: no exception thrown\");\n+        }\n+    }\n+\n+    @Run(test = \"test61\")\n+    public void test61_verifier() {\n+        test61(testValue1);\n+    }\n+\n+    @Test\n+    public void test62(Object o) {\n+        try {\n+            synchronized (o) { }\n+        } catch (IdentityException ex) {\n+            \/\/ Expected\n+            return;\n+        }\n+        throw new RuntimeException(\"test62 failed: no exception thrown\");\n+    }\n+\n+    @Run(test = \"test62\")\n+    public void test62_verifier() {\n+        test62(testValue1);\n+    }\n+\n+    \/\/ Test synchronization without any instructions in the synchronized block\n+    @Test\n+    public void test63(Object o) {\n+        synchronized (o) { }\n+    }\n+\n+    @Run(test = \"test63\")\n+    public void test63_verifier() {\n+        try {\n+            test63(testValue1);\n+        } catch (IdentityException ex) {\n+            \/\/ Expected\n+            return;\n+        }\n+        throw new RuntimeException(\"test63 failed: no exception thrown\");\n+    }\n+\n+    \/\/ type system test with interface and inline type\n+    @ForceInline\n+    public MyInterface test64Interface_helper(MyValue1 vt) {\n+        return vt;\n+    }\n+\n+    @Test\n+    public MyInterface test64Interface(MyValue1 vt) {\n+        return test64Interface_helper(vt);\n+    }\n+\n+    @Run(test = \"test64Interface\")\n+    public void test64Interface_verifier() {\n+        test64Interface(testValue1);\n+    }\n+\n+    \/\/ type system test with abstract and inline type\n+    @ForceInline\n+    public MyAbstract test64Abstract_helper(MyValue1 vt) {\n+        return vt;\n+    }\n+\n+    @Test\n+    public MyAbstract test64Abstract(MyValue1 vt) {\n+        return test64Abstract_helper(vt);\n+    }\n+\n+    @Run(test = \"test64Abstract\")\n+    public void test64Abstract_verifier() {\n+        test64Abstract(testValue1);\n+    }\n+\n+    \/\/ Array store tests\n+    @Test\n+    public void test65(Object[] array, MyValue1 vt) {\n+        array[0] = vt;\n+    }\n+\n+    @Run(test = \"test65\")\n+    public void test65_verifier() {\n+        Object[] array = new Object[1];\n+        test65(array, testValue1);\n+        Asserts.assertEQ(((MyValue1)array[0]).hash(), testValue1.hash());\n+    }\n+\n+    @Test\n+    public void test66(Object[] array, MyValue1 vt) {\n+        array[0] = vt;\n+    }\n+\n+    @Run(test = \"test66\")\n+    public void test66_verifier() {\n+        MyValue1[] array = (MyValue1[])ValueClass.newNullRestrictedArray(MyValue1.class, 1);\n+        test66(array, testValue1);\n+        Asserts.assertEQ(array[0].hash(), testValue1.hash());\n+    }\n+\n+    @Test\n+    public void test67(Object[] array, Object vt) {\n+        array[0] = vt;\n+    }\n+\n+    @Run(test = \"test67\")\n+    public void test67_verifier() {\n+        MyValue1[] array = (MyValue1[])ValueClass.newNullRestrictedArray(MyValue1.class, 1);\n+        test67(array, testValue1);\n+        Asserts.assertEQ(array[0].hash(), testValue1.hash());\n+    }\n+\n+    @Test\n+    public void test68(Object[] array, NonValueClass o) {\n+        array[0] = o;\n+    }\n+\n+    @Run(test = \"test68\")\n+    public void test68_verifier() {\n+        NonValueClass[] array = new NonValueClass[1];\n+        NonValueClass obj = new NonValueClass(1);\n+        test68(array, obj);\n+        Asserts.assertEQ(array[0], obj);\n+    }\n+\n+    \/\/ Test convertion between an inline type and java.lang.Object without an allocation\n+    @ForceInline\n+    public Object test69_sum(Object a, Object b) {\n+        int sum = ((MyValue1)a).x + ((MyValue1)b).x;\n+        return MyValue1.setX(((MyValue1)a), sum);\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G, STORE})\n+    public int test69(MyValue1[] array) {\n+        MyValue1 result = MyValue1.createDefaultInline();\n+        for (int i = 0; i < array.length; ++i) {\n+            result = (MyValue1)test69_sum(result, array[i]);\n+        }\n+        return result.x;\n+    }\n+\n+    @Run(test = \"test69\")\n+    public void test69_verifier() {\n+        int result = test69(testValue1Array);\n+        Asserts.assertEQ(result, rI * testValue1Array.length);\n+    }\n+\n+    \/\/ Same as test69 but with an Interface\n+    @ForceInline\n+    public MyInterface test70Interface_sum(MyInterface a, MyInterface b) {\n+        int sum = ((MyValue1)a).x + ((MyValue1)b).x;\n+        return MyValue1.setX(((MyValue1)a), sum);\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G, STORE})\n+    public int test70Interface(MyValue1[] array) {\n+        MyValue1 result = MyValue1.createDefaultInline();\n+        for (int i = 0; i < array.length; ++i) {\n+            result = (MyValue1)test70Interface_sum(result, array[i]);\n+        }\n+        return result.x;\n+    }\n+\n+    @Run(test = \"test70Interface\")\n+    public void test70Interface_verifier() {\n+        int result = test70Interface(testValue1Array);\n+        Asserts.assertEQ(result, rI * testValue1Array.length);\n+    }\n+\n+    \/\/ Same as test69 but with an Abstract\n+    @ForceInline\n+    public MyAbstract test70Abstract_sum(MyAbstract a, MyAbstract b) {\n+        int sum = ((MyValue1)a).x + ((MyValue1)b).x;\n+        return MyValue1.setX(((MyValue1)a), sum);\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G, STORE})\n+    public int test70Abstract(MyValue1[] array) {\n+        MyValue1 result = MyValue1.createDefaultInline();\n+        for (int i = 0; i < array.length; ++i) {\n+            result = (MyValue1)test70Abstract_sum(result, array[i]);\n+        }\n+        return result.x;\n+    }\n+\n+    @Run(test = \"test70Abstract\")\n+    public void test70Abstract_verifier() {\n+        int result = test70Abstract(testValue1Array);\n+        Asserts.assertEQ(result, rI * testValue1Array.length);\n+    }\n+\n+    \/\/ Test that allocated inline type is not used in non-dominated path\n+    public MyValue1 test71_inline(Object obj) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        try {\n+            vt = (MyValue1)Objects.requireNonNull(obj);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        return vt;\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC})\n+    public MyValue1 test71() {\n+        return test71_inline(null);\n+    }\n+\n+    @Run(test = \"test71\")\n+    public void test71_verifier() {\n+        MyValue1 vt = test71();\n+        Asserts.assertEquals(vt.hash(), hash());\n+    }\n+\n+    \/\/ Test calling a method on an uninitialized inline type\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    value class Test72Value {\n+        int x = 0;\n+\n+        public int get() {\n+            return x;\n+        }\n+    }\n+\n+    \/\/ Make sure Test72Value is loaded but not initialized\n+    public void unused(Test72Value vt) { }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public int test72() {\n+        Test72Value vt = new Test72Value();\n+        return vt.get();\n+    }\n+\n+    @Run(test = \"test72\")\n+    @Warmup(0)\n+    public void test72_verifier() {\n+        int result = test72();\n+        Asserts.assertEquals(result, 0);\n+    }\n+\n+    \/\/ Tests for loading\/storing unkown values\n+    @Test\n+    public Object test73(Object[] va) {\n+        return va[0];\n+    }\n+\n+    @Run(test = \"test73\")\n+    public void test73_verifier() {\n+        MyValue1 vt = (MyValue1)test73(testValue1Array);\n+        Asserts.assertEquals(testValue1Array[0].hash(), vt.hash());\n+    }\n+\n+    @Test\n+    public void test74(Object[] va, Object vt) {\n+        va[0] = vt;\n+    }\n+\n+    @Run(test = \"test74\")\n+    public void test74_verifier() {\n+        MyValue1[] va = (MyValue1[])ValueClass.newNullRestrictedArray(MyValue1.class, 1);\n+        test74(va, testValue1);\n+        Asserts.assertEquals(va[0].hash(), testValue1.hash());\n+    }\n+\n+    \/\/ Verify that mixing instances and arrays with the clone api\n+    \/\/ doesn't break anything\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public Object test75(Object o) {\n+        MyValue1[] va = (MyValue1[])ValueClass.newNullRestrictedArray(MyValue1.class, 1);\n+        Object[] next = va;\n+        Object[] arr = va;\n+        for (int i = 0; i < 10; i++) {\n+            arr = next;\n+            next = new NonValueClass[1];\n+        }\n+        return arr[0];\n+    }\n+\n+    @Run(test = \"test75\")\n+    public void test75_verifier() {\n+        test75(42);\n+    }\n+\n+    \/\/ Casting an NonValueClass to a inline type should throw a ClassCastException\n+    @ForceInline\n+    public MyValue1 test77_helper(Object o) {\n+        return (MyValue1)o;\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public MyValue1 test77(NonValueClass obj) throws Throwable {\n+        return test77_helper(obj);\n+    }\n+\n+    @Run(test = \"test77\")\n+    public void test77_verifier() throws Throwable {\n+        try {\n+            test77(new NonValueClass(42));\n+            throw new RuntimeException(\"ClassCastException expected\");\n+        } catch (ClassCastException e) {\n+            \/\/ Expected\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"test77 failed: unexpected exception\", e);\n+        }\n+    }\n+\n+    \/\/ Casting a null NonValueClass to a nullable inline type should not throw\n+    @ForceInline\n+    public MyValue1 test78_helper(Object o) {\n+        return (MyValue1)o;\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public MyValue1 test78(NonValueClass obj) throws Throwable {\n+        return test78_helper(obj);\n+    }\n+\n+    @Run(test = \"test78\")\n+    public void test78_verifier() throws Throwable {\n+        try {\n+            test78(null); \/\/ Should not throw\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"test78 failed: unexpected exception\", e);\n+        }\n+    }\n+\n+    \/\/ Casting an NonValueClass to a nullable inline type should throw a ClassCastException\n+    @ForceInline\n+    public MyValue1 test79_helper(Object o) {\n+        return (MyValue1)o;\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public MyValue1 test79(NonValueClass obj) throws Throwable {\n+        return test79_helper(obj);\n+    }\n+\n+    @Run(test = \"test79\")\n+    public void test79_verifier() throws Throwable {\n+        try {\n+            test79(new NonValueClass(42));\n+            throw new RuntimeException(\"ClassCastException expected\");\n+        } catch (ClassCastException e) {\n+            \/\/ Expected\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"test79 failed: unexpected exception\", e);\n+        }\n+    }\n+\n+    \/\/ Test flattened field with non-flattenend (but flattenable) inline type field\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class Small {\n+        int i;\n+        @NullRestricted\n+        Big big; \/\/ Too big to be flattened\n+\n+        private Small() {\n+            i = rI;\n+            big = new Big();\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class Big {\n+        long l0,l1,l2,l3,l4,l5,l6,l7,l8,l9;\n+        long l10,l11,l12,l13,l14,l15,l16,l17,l18,l19;\n+        long l20,l21,l22,l23,l24,l25,l26,l27,l28,l29;\n+\n+        private Big() {\n+            l0 = l1 = l2 = l3 = l4 = l5 = l6 = l7 = l8 = l9 = rL;\n+            l10 = l11 = l12 = l13 = l14 = l15 = l16 = l17 = l18 = l19 = rL+1;\n+            l20 = l21 = l22 = l23 = l24 = l25 = l26 = l27 = l28 = l29 = rL+2;\n+        }\n+    }\n+\n+    @NullRestricted\n+    Small small = new Small();\n+    @NullRestricted\n+    Small smallDefault;\n+    @NullRestricted\n+    Big big = new Big();\n+    @NullRestricted\n+    Big bigDefault;\n+\n+    @Test\n+    public long test80() {\n+        return small.i + small.big.l0 + smallDefault.i + smallDefault.big.l29 + big.l0 + bigDefault.l29;\n+    }\n+\n+    @Run(test = \"test80\")\n+    public void test80_verifier() throws Throwable {\n+        long result = test80();\n+        Asserts.assertEQ(result, rI + 2*rL);\n+    }\n+\n+    \/\/ Test scalarization with exceptional control flow\n+    public int test81Callee(MyValue1 vt)  {\n+        return vt.x;\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G, LOAD, STORE})\n+    public int test81()  {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        int result = 0;\n+        for (int i = 0; i < 10; i++) {\n+            try {\n+                result += test81Callee(vt);\n+            } catch (NullPointerException npe) {\n+                result += rI;\n+            }\n+        }\n+        return result;\n+    }\n+\n+    @Run(test = \"test81\")\n+    public void test81_verifier() {\n+        int result = test81();\n+        Asserts.assertEQ(result, 10*rI);\n+    }\n+\n+    \/\/ Test check for null free array when storing to inline tpye array\n+    @Test\n+    public void test82(Object[] dst, Object v) {\n+        dst[0] = v;\n+    }\n+\n+    @Run(test = \"test82\")\n+    public void test82_verifier(RunInfo info) {\n+        MyValue2[] dst = (MyValue2[])ValueClass.newNullRestrictedArray(MyValue2.class, 1);\n+        test82(dst, testValue2);\n+        if (!info.isWarmUp()) {\n+            try {\n+                test82(dst, null);\n+                throw new RuntimeException(\"No ArrayStoreException thrown\");\n+            } catch (NullPointerException e) {\n+                \/\/ Expected\n+            }\n+        }\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public void test83(Object[] dst, Object v, boolean flag) {\n+        if (dst == null) { \/\/ null check\n+        }\n+        if (flag) {\n+            if (dst.getClass() == MyValue1[].class) { \/\/ trigger split if\n+            }\n+        } else {\n+            dst = (MyValue2[])ValueClass.newNullRestrictedArray(MyValue2.class, 1); \/\/ constant null free property\n+        }\n+        dst[0] = v;\n+    }\n+\n+    @Run(test = \"test83\")\n+    @Warmup(10000)\n+    public void test83_verifier(RunInfo info) {\n+        MyValue2[] dst = (MyValue2[])ValueClass.newNullRestrictedArray(MyValue2.class, 1);\n+        test83(dst, testValue2, false);\n+        test83(dst, testValue2, true);\n+        if (!info.isWarmUp()) {\n+            try {\n+                test83(dst, null, true);\n+                throw new RuntimeException(\"No ArrayStoreException thrown\");\n+            } catch (NullPointerException e) {\n+                \/\/ Expected\n+            }\n+        }\n+    }\n+\n+    private void rerun_and_recompile_for(Method m, int num, Runnable test) {\n+        for (int i = 1; i < num; i++) {\n+            test.run();\n+\n+            if (!TestFramework.isCompiled(m)) {\n+                TestFramework.compile(m, CompLevel.C2);\n+            }\n+        }\n+    }\n+\n+    \/\/ Tests for the Loop Unswitching optimization\n+    \/\/ Should make 2 copies of the loop, one for non flattened arrays, one for other cases.\n+    @Test\n+    @IR(applyIf = {\"UseArrayFlattening\", \"true\"},\n+        counts = {COUNTEDLOOP_MAIN, \"= 2\"})\n+    @IR(applyIf = {\"UseArrayFlattening\", \"false\"},\n+        counts = {COUNTEDLOOP_MAIN, \"= 1\"})\n+    public void test84(Object[] src, Object[] dst) {\n+        for (int i = 0; i < src.length; i++) {\n+            dst[i] = src[i];\n+        }\n+    }\n+\n+    @Run(test = \"test84\")\n+    @Warmup(0)\n+    public void test84_verifier(RunInfo info) {\n+        MyValue2[] src = (MyValue2[])ValueClass.newNullRestrictedArray(MyValue2.class, 100);\n+        Arrays.fill(src, testValue2);\n+        MyValue2[] dst = (MyValue2[])ValueClass.newNullRestrictedArray(MyValue2.class, 100);\n+        rerun_and_recompile_for(info.getTest(), 10,\n+                                () ->  { test84(src, dst);\n+                                         Asserts.assertTrue(Arrays.equals(src, dst)); });\n+    }\n+\n+    @Test\n+    @IR(applyIfAnd = {\"UseG1GC\", \"true\", \"UseArrayFlattening\", \"true\"},\n+        counts = {COUNTEDLOOP, \"= 2\", LOAD_UNKNOWN_INLINE, \"= 1\"})\n+    @IR(applyIfAnd = {\"UseG1GC\", \"false\", \"UseArrayFlattening\", \"true\"},\n+        counts = {COUNTEDLOOP_MAIN, \"= 2\", LOAD_UNKNOWN_INLINE, \"= 4\"})\n+    public void test85(Object[] src, Object[] dst) {\n+        for (int i = 0; i < src.length; i++) {\n+            dst[i] = src[i];\n+        }\n+    }\n+\n+    @Run(test = \"test85\")\n+    @Warmup(0)\n+    public void test85_verifier(RunInfo info) {\n+        Object[] src = new Object[100];\n+        Arrays.fill(src, new Object());\n+        src[0] = null;\n+        Object[] dst = new Object[100];\n+        rerun_and_recompile_for(info.getTest(), 10,\n+                                () -> { test85(src, dst);\n+                                        Asserts.assertTrue(Arrays.equals(src, dst)); });\n+    }\n+\n+    @Test\n+    @IR(applyIfAnd = {\"UseG1GC\", \"true\", \"UseArrayFlattening\", \"true\"},\n+        counts = {COUNTEDLOOP, \"= 2\"})\n+    @IR(applyIfAnd = {\"UseG1GC\", \"false\", \"UseArrayFlattening\", \"true\"},\n+        counts = {COUNTEDLOOP_MAIN, \"= 2\"})\n+    public void test86(Object[] src, Object[] dst) {\n+        for (int i = 0; i < src.length; i++) {\n+            dst[i] = src[i];\n+        }\n+    }\n+\n+    @Run(test = \"test86\")\n+    @Warmup(0)\n+    public void test86_verifier(RunInfo info) {\n+        MyValue2[] src = (MyValue2[])ValueClass.newNullRestrictedArray(MyValue2.class, 100);\n+        Arrays.fill(src, testValue2);\n+        Object[] dst = new Object[100];\n+        rerun_and_recompile_for(info.getTest(), 10,\n+                                () -> { test86(src, dst);\n+                                        Asserts.assertTrue(Arrays.equals(src, dst)); });\n+    }\n+\n+    @Test\n+    @IR(applyIf = {\"UseArrayFlattening\", \"true\"},\n+        counts = {COUNTEDLOOP_MAIN, \"= 2\"})\n+    @IR(applyIf = {\"UseArrayFlattening\", \"false\"},\n+        counts = {COUNTEDLOOP_MAIN, \"= 1\"})\n+    public void test87(Object[] src, Object[] dst) {\n+        for (int i = 0; i < src.length; i++) {\n+            dst[i] = src[i];\n+        }\n+    }\n+\n+    @Run(test = \"test87\")\n+    @Warmup(0)\n+    public void test87_verifier(RunInfo info) {\n+        Object[] src = new Object[100];\n+        Arrays.fill(src, testValue2);\n+        MyValue2[] dst = (MyValue2[])ValueClass.newNullRestrictedArray(MyValue2.class, 100);\n+\n+        rerun_and_recompile_for(info.getTest(), 10,\n+                                () -> { test87(src, dst);\n+                                        Asserts.assertTrue(Arrays.equals(src, dst)); });\n+    }\n+\n+    @Test\n+    \/* FIX: JDK-8344532\n+    @IR(applyIf = {\"UseArrayFlattening\", \"true\"},\n+        counts = {COUNTEDLOOP_MAIN, \"= 2\"})\n+    @IR(applyIf = {\"UseArrayFlattening\", \"false\"},\n+        counts = {COUNTEDLOOP_MAIN, \"= 0\"})\n+    *\/\n+    public void test88(Object[] src1, Object[] dst1, Object[] src2, Object[] dst2) {\n+        for (int i = 0; i < src1.length; i++) {\n+            dst1[i] = src1[i];\n+            dst2[i] = src2[i];\n+        }\n+    }\n+\n+    @Run(test = \"test88\")\n+    @Warmup(0)\n+    public void test88_verifier(RunInfo info) {\n+        MyValue2[] src1 = (MyValue2[])ValueClass.newNullRestrictedArray(MyValue2.class, 100);\n+        Arrays.fill(src1, testValue2);\n+        MyValue2[] dst1 = (MyValue2[])ValueClass.newNullRestrictedArray(MyValue2.class, 100);\n+        Object[] src2 = new Object[100];\n+        Arrays.fill(src2, new Object());\n+        Object[] dst2 = new Object[100];\n+\n+        rerun_and_recompile_for(info.getTest(), 10,\n+                                () -> { test88(src1, dst1, src2, dst2);\n+                                        Asserts.assertTrue(Arrays.equals(src1, dst1));\n+                                        Asserts.assertTrue(Arrays.equals(src2, dst2)); });\n+    }\n+\n+    @Test\n+    public boolean test89(Object obj) {\n+        return obj.getClass() == NonValueClass.class;\n+    }\n+\n+    @Run(test = \"test89\")\n+    public void test89_verifier() {\n+        Asserts.assertTrue(test89(new NonValueClass(42)));\n+        Asserts.assertFalse(test89(new Object()));\n+    }\n+\n+    @Test\n+    public NonValueClass test90(Object obj) {\n+        return (NonValueClass)obj;\n+    }\n+\n+    @Run(test = \"test90\")\n+    public void test90_verifier() {\n+        test90(new NonValueClass(42));\n+        try {\n+            test90(new Object());\n+            throw new RuntimeException(\"ClassCastException expected\");\n+        } catch (ClassCastException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @Test\n+    public boolean test91(Object obj) {\n+        return obj.getClass() == MyValue2[].class;\n+    }\n+\n+    @Run(test = \"test91\")\n+    public void test91_verifier() {\n+        Asserts.assertFalse(test91((MyValue2[])ValueClass.newNullRestrictedArray(MyValue2.class, 1)));\n+        Asserts.assertTrue(test91(new MyValue2[1]));\n+        Asserts.assertFalse(test91(new Object()));\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class Test92Value {\n+        int field;\n+\n+        public Test92Value() {\n+            field = 0x42;\n+        }\n+    }\n+\n+    @Test\n+    @IR(applyIf = {\"UseArrayFlattening\", \"true\"},\n+        counts = {CLASS_CHECK_TRAP, \"= 2\"},\n+        failOn = {LOAD_UNKNOWN_INLINE, ALLOC_G, MEMBAR})\n+    public Object test92(Object[] array) {\n+        \/\/ Dummy loops to ensure we run enough passes of split if\n+        for (int i = 0; i < 2; i++) {\n+            for (int j = 0; j < 2; j++) {\n+              for (int k = 0; k < 2; k++) {\n+              }\n+            }\n+        }\n+\n+        return (NonValueClass)array[0];\n+    }\n+\n+    @Run(test = \"test92\")\n+    @Warmup(10000)\n+    public void test92_verifier() {\n+        Object[] array = new Object[1];\n+        Object obj = new NonValueClass(rI);\n+        array[0] = obj;\n+        Object result = test92(array);\n+        Asserts.assertEquals(result, obj);\n+    }\n+\n+    \/\/ If the class check succeeds, the flattened array check that\n+    \/\/ precedes will never succeed and the flat array branch should\n+    \/\/ trigger an uncommon trap.\n+    @Test\n+    public Object test93(Object[] array) {\n+        for (int i = 0; i < 2; i++) {\n+            for (int j = 0; j < 2; j++) {\n+            }\n+        }\n+\n+        Object v = (NonValueClass)array[0];\n+        return v;\n+    }\n+\n+    @Run(test = \"test93\")\n+    @Warmup(10000)\n+    public void test93_verifier(RunInfo info) {\n+        if (info.isWarmUp()) {\n+            Object[] array = new Object[1];\n+            array[0] = new NonValueClass(42);\n+            Object result = test93(array);\n+            Asserts.assertEquals(((NonValueClass)result).x, 42);\n+        } else {\n+            Object[] array = (Test92Value[])ValueClass.newNullRestrictedArray(Test92Value.class, 1);\n+            Method m = info.getTest();\n+            int extra = 3;\n+            for (int j = 0; j < extra; j++) {\n+                for (int i = 0; i < 10; i++) {\n+                    try {\n+                        test93(array);\n+                    } catch (ClassCastException cce) {\n+                    }\n+                }\n+                boolean compiled = TestFramework.isCompiled(m);\n+                boolean compilationSkipped = info.isCompilationSkipped();\n+                Asserts.assertTrue(compilationSkipped || compiled || (j != extra-1));\n+                if (!compilationSkipped && !compiled) {\n+                    TestFramework.compile(m, CompLevel.ANY);\n+                }\n+            }\n+        }\n+    }\n+\n+    @Test\n+    @IR(applyIf = {\"UseArrayFlattening\", \"true\"},\n+        counts = {CLASS_CHECK_TRAP, \"= 2\", LOOP, \"= 1\"},\n+        failOn = {LOAD_UNKNOWN_INLINE, ALLOC_G, MEMBAR})\n+    public int test94(Object[] array) {\n+        int res = 0;\n+        for (int i = 1; i < 4; i *= 2) {\n+            Object v = array[i];\n+            res += ((NonValueClass)v).x;\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test94\")\n+    @Warmup(10000)\n+    public void test94_verifier() {\n+        Object[] array = new Object[4];\n+        Object obj = new NonValueClass(rI);\n+        array[0] = obj;\n+        array[1] = obj;\n+        array[2] = obj;\n+        array[3] = obj;\n+        int result = test94(array);\n+        Asserts.assertEquals(result, rI * 2);\n+    }\n+\n+    @Test\n+    public boolean test95(Object o1, Object o2) {\n+        return o1 == o2;\n+    }\n+\n+    @Run(test = \"test95\")\n+    @Warmup(10000)\n+    public void test95_verifier() {\n+        Object o1 = new Object();\n+        Object o2 = new Object();\n+        Asserts.assertTrue(test95(o1, o1));\n+        Asserts.assertTrue(test95(null, null));\n+        Asserts.assertFalse(test95(o1, null));\n+        Asserts.assertFalse(test95(o1, o2));\n+    }\n+\n+    @Test\n+    public boolean test96(Object o1, Object o2) {\n+        return o1 == o2;\n+    }\n+\n+    @Run(test = \"test96\")\n+    @Warmup(10000)\n+    public void test96_verifier(RunInfo info) {\n+        Object o1 = new Object();\n+        Object o2 = new Object();\n+        Asserts.assertTrue(test96(o1, o1));\n+        Asserts.assertFalse(test96(o1, o2));\n+        if (!info.isWarmUp()) {\n+            Asserts.assertTrue(test96(null, null));\n+            Asserts.assertFalse(test96(o1, null));\n+        }\n+    }\n+\n+    \/\/ Abstract class tests\n+\n+    @DontInline\n+    public MyAbstract test97_dontinline1(MyAbstract o) {\n+        return o;\n+    }\n+\n+    @DontInline\n+    public MyValue1 test97_dontinline2(MyAbstract o) {\n+        return (MyValue1)o;\n+    }\n+\n+    @ForceInline\n+    public MyAbstract test97_inline1(MyAbstract o) {\n+        return o;\n+    }\n+\n+    @ForceInline\n+    public MyValue1 test97_inline2(MyAbstract o) {\n+        return (MyValue1)o;\n+    }\n+\n+    @Test\n+    public MyValue1 test97() {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        vt = (MyValue1)test97_dontinline1(vt);\n+        vt =           test97_dontinline2(vt);\n+        vt = (MyValue1)test97_inline1(vt);\n+        vt =           test97_inline2(vt);\n+        return vt;\n+    }\n+\n+    @Run(test = \"test97\")\n+    public void test97_verifier() {\n+        Asserts.assertEQ(test97().hash(), hash());\n+    }\n+\n+    \/\/ Test storing\/loading inline types to\/from abstract and inline type fields\n+    MyAbstract abstractField1 = null;\n+    MyAbstract abstractField2 = null;\n+    MyAbstract abstractField3 = null;\n+    MyAbstract abstractField4 = null;\n+    MyAbstract abstractField5 = null;\n+    MyAbstract abstractField6 = null;\n+\n+    @DontInline\n+    public MyAbstract readValueField5AsAbstract() {\n+        return (MyAbstract)valueField5;\n+    }\n+\n+    @DontInline\n+    public MyAbstract readStaticValueField4AsAbstract() {\n+        return (MyAbstract)staticValueField4;\n+    }\n+\n+    @Test\n+    public long test98(MyValue1 vt1, MyAbstract vt2) {\n+        abstractField1 = vt1;\n+        abstractField2 = (MyValue1)vt2;\n+        abstractField3 = MyValue1.createWithFieldsInline(rI, rL);\n+        abstractField4 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        abstractField5 = valueField1;\n+        abstractField6 = valueField3;\n+        valueField1 = (MyValue1)abstractField1;\n+        valueField2 = (MyValue1)vt2;\n+        valueField3 = (MyValue1)vt2;\n+        staticValueField1 = (MyValue1)abstractField1;\n+        staticValueField2 = (MyValue1)vt1;\n+        \/\/ Don't inline these methods because reading NULL will trigger a deoptimization\n+        if (readValueField5AsAbstract() != null || readStaticValueField4AsAbstract() != null) {\n+            throw new RuntimeException(\"Should be null\");\n+        }\n+        return ((MyValue1)abstractField1).hash() + ((MyValue1)abstractField2).hash() +\n+               ((MyValue1)abstractField3).hash() + ((MyValue1)abstractField4).hash() +\n+               ((MyValue1)abstractField5).hash() + ((MyValue1)abstractField6).hash() +\n+                valueField1.hash() + valueField2.hash() + valueField3.hash() + valueField4.hashPrimitive() +\n+                staticValueField1.hash() + staticValueField2.hash() + staticValueField3.hashPrimitive();\n+    }\n+\n+    @Run(test = \"test98\")\n+    public void test98_verifier() {\n+        MyValue1 vt = testValue1;\n+        MyValue1 def = MyValue1.createDefaultDontInline();\n+        long result = test98(vt, vt);\n+        Asserts.assertEQ(result, 11*vt.hash() + 2*def.hashPrimitive());\n+    }\n+\n+    value class MyObject2 extends MyAbstract {\n+        public int x;\n+\n+        public MyObject2(int x) {\n+            this.x = x;\n+        }\n+\n+        @ForceInline\n+        public long hash() {\n+            return x;\n+        }\n+    }\n+\n+    \/\/ Test merging inline types and abstract classes\n+    @Test\n+    public MyAbstract test99(int state) {\n+        MyAbstract res = null;\n+        if (state == 0) {\n+            res = new MyObject2(rI);\n+        } else if (state == 1) {\n+            res = MyValue1.createWithFieldsInline(rI, rL);\n+        } else if (state == 2) {\n+            res = MyValue1.createWithFieldsDontInline(rI, rL);\n+        } else if (state == 3) {\n+            res = (MyValue1)objectField1;\n+        } else if (state == 4) {\n+            res = valueField1;\n+        } else if (state == 5) {\n+            res = null;\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test99\")\n+    public void test99_verifier() {\n+        objectField1 = valueField1;\n+        MyAbstract result = null;\n+        result = test99(0);\n+        Asserts.assertEQ(((MyObject2)result).x, rI);\n+        result = test99(1);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test99(2);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test99(3);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test99(4);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test99(5);\n+        Asserts.assertEQ(result, null);\n+    }\n+\n+    \/\/ Test merging inline types and abstract classes in loops\n+    @Test\n+    public MyAbstract test100(int iters) {\n+        MyAbstract res = new MyObject2(rI);\n+        for (int i = 0; i < iters; ++i) {\n+            if (res instanceof MyObject2) {\n+                res = MyValue1.createWithFieldsInline(rI, rL);\n+            } else {\n+                res = MyValue1.createWithFieldsInline(((MyValue1)res).x + 1, rL);\n+            }\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test100\")\n+    public void test100_verifier() {\n+        MyObject2 result1 = (MyObject2)test100(0);\n+        Asserts.assertEQ(result1.x, rI);\n+        int iters = (Math.abs(rI) % 10) + 1;\n+        MyValue1 result2 = (MyValue1)test100(iters);\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI + iters - 1, rL);\n+        Asserts.assertEQ(result2.hash(), vt.hash());\n+    }\n+\n+    \/\/ Test inline types in abstract class variables that are live at safepoint\n+    @Test\n+    @IR(failOn = {ALLOC, STORE, LOOP})\n+    public long test101(MyValue1 arg, boolean deopt, Method m) {\n+        MyAbstract vt1 = MyValue1.createWithFieldsInline(rI, rL);\n+        MyAbstract vt2 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        MyAbstract vt3 = arg;\n+        MyAbstract vt4 = valueField1;\n+        if (deopt) {\n+            \/\/ uncommon trap\n+            TestFramework.deoptimize(m);\n+        }\n+        return ((MyValue1)vt1).hash() + ((MyValue1)vt2).hash() +\n+               ((MyValue1)vt3).hash() + ((MyValue1)vt4).hash();\n+    }\n+\n+    @Run(test = \"test101\")\n+    public void test101_verifier(RunInfo info) {\n+        long result = test101(valueField1, !info.isWarmUp(), info.getTest());\n+        Asserts.assertEQ(result, 4*hash());\n+    }\n+\n+    \/\/ Test comparing inline types with abstract classes\n+    @Test\n+    public boolean test102(Object arg) {\n+        MyAbstract vt = MyValue1.createWithFieldsInline(rI, rL);\n+        if (vt == arg || vt == (MyAbstract)valueField1 || vt == abstractField1 || vt == null ||\n+            arg == vt || (MyAbstract)valueField1 == vt || abstractField1 == vt || null == vt) {\n+            return true;\n+        }\n+        return false;\n+    }\n+\n+    @Run(test = \"test102\")\n+    public void test102_verifier() {\n+        boolean result = test102(null);\n+        Asserts.assertFalse(result);\n+    }\n+\n+    \/\/ An abstract class with a non-static field can never be implemented by an inline type\n+    abstract class NoValueImplementors1 {\n+        int field = 42;\n+    }\n+\n+    class MyObject3 extends NoValueImplementors1 {\n+\n+    }\n+\n+    class MyObject4 extends NoValueImplementors1 {\n+\n+    }\n+\n+    \/\/ Loading from an abstract class array does not require a flatness check if the abstract class has a non-static field\n+    @Test\n+    @IR(failOn = {ALLOC_G, MEMBAR, LOAD_UNKNOWN_INLINE, STORE_UNKNOWN_INLINE, INLINE_ARRAY_NULL_GUARD})\n+    public NoValueImplementors1 test103(NoValueImplementors1[] array, int i) {\n+        return array[i];\n+    }\n+\n+    @Run(test = \"test103\")\n+    public void test103_verifier() {\n+        NoValueImplementors1[] array1 = new NoValueImplementors1[3];\n+        MyObject3[] array2 = new MyObject3[3];\n+        MyObject4[] array3 = new MyObject4[3];\n+        NoValueImplementors1 result = test103(array1, 0);\n+        Asserts.assertEquals(result, array1[0]);\n+\n+        result = test103(array2, 1);\n+        Asserts.assertEquals(result, array1[1]);\n+\n+        result = test103(array3, 2);\n+        Asserts.assertEquals(result, array1[2]);\n+    }\n+\n+    \/\/ Storing to an abstract class array does not require a flatness\/null check if the abstract class has a non-static field\n+    @Test\n+    @IR(failOn = {ALLOC_G, LOAD_UNKNOWN_INLINE, STORE_UNKNOWN_INLINE, INLINE_ARRAY_NULL_GUARD})\n+    public NoValueImplementors1 test104(NoValueImplementors1[] array, NoValueImplementors1 v, MyObject3 o, int i) {\n+        array[0] = v;\n+        array[1] = array[0];\n+        array[2] = o;\n+        return array[i];\n+    }\n+\n+    @Run(test = \"test104\")\n+    public void test104_verifier() {\n+        MyObject4 v = new MyObject4();\n+        MyObject3 o = new MyObject3();\n+        NoValueImplementors1[] array1 = new NoValueImplementors1[3];\n+        MyObject3[] array2 = new MyObject3[3];\n+        MyObject4[] array3 = new MyObject4[3];\n+        NoValueImplementors1 result = test104(array1, v, o, 0);\n+        Asserts.assertEquals(array1[0], v);\n+        Asserts.assertEquals(array1[1], v);\n+        Asserts.assertEquals(array1[2], o);\n+        Asserts.assertEquals(result, v);\n+\n+        result = test104(array2, o, o, 1);\n+        Asserts.assertEquals(array2[0], o);\n+        Asserts.assertEquals(array2[1], o);\n+        Asserts.assertEquals(array2[2], o);\n+        Asserts.assertEquals(result, o);\n+\n+        result = test104(array3, v, null, 1);\n+        Asserts.assertEquals(array3[0], v);\n+        Asserts.assertEquals(array3[1], v);\n+        Asserts.assertEquals(array3[2], null);\n+        Asserts.assertEquals(result, v);\n+    }\n+\n+    \/\/ An abstract class with a single, non-inline implementor\n+    abstract class NoValueImplementors2 {\n+\n+    }\n+\n+    class MyObject5 extends NoValueImplementors2 {\n+\n+    }\n+\n+    \/\/ Loading from an abstract class array does not require a flatness check if the abstract class has no inline implementor\n+    @Test\n+    @IR(failOn = {ALLOC_G, MEMBAR, LOAD_UNKNOWN_INLINE, STORE_UNKNOWN_INLINE, INLINE_ARRAY_NULL_GUARD})\n+    public NoValueImplementors2 test105(NoValueImplementors2[] array, int i) {\n+        return array[i];\n+    }\n+\n+    @Run(test = \"test105\")\n+    public void test105_verifier() {\n+        NoValueImplementors2[] array1 = new NoValueImplementors2[3];\n+        MyObject5[] array2 = new MyObject5[3];\n+        NoValueImplementors2 result = test105(array1, 0);\n+        Asserts.assertEquals(result, array1[0]);\n+\n+        result = test105(array2, 1);\n+        Asserts.assertEquals(result, array1[1]);\n+    }\n+\n+    \/\/ Storing to an abstract class array does not require a flatness\/null check if the abstract class has no inline implementor\n+    @Test\n+    @IR(failOn = {ALLOC_G, LOAD_UNKNOWN_INLINE, STORE_UNKNOWN_INLINE, INLINE_ARRAY_NULL_GUARD})\n+    public NoValueImplementors2 test106(NoValueImplementors2[] array, NoValueImplementors2 v, MyObject5 o, int i) {\n+        array[0] = v;\n+        array[1] = array[0];\n+        array[2] = o;\n+        return array[i];\n+    }\n+\n+    @Run(test = \"test106\")\n+    public void test106_verifier() {\n+        MyObject5 v = new MyObject5();\n+        NoValueImplementors2[] array1 = new NoValueImplementors2[3];\n+        MyObject5[] array2 = new MyObject5[3];\n+        NoValueImplementors2 result = test106(array1, v, null, 0);\n+        Asserts.assertEquals(array1[0], v);\n+        Asserts.assertEquals(array1[1], v);\n+        Asserts.assertEquals(array1[2], null);\n+        Asserts.assertEquals(result, v);\n+\n+        result = test106(array2, v, v, 1);\n+        Asserts.assertEquals(array2[0], v);\n+        Asserts.assertEquals(array2[1], v);\n+        Asserts.assertEquals(array2[2], v);\n+        Asserts.assertEquals(result, v);\n+    }\n+\n+    \/\/ More tests for the Loop Unswitching optimization (similar to test84 and following)\n+    Object oFld1, oFld2;\n+\n+    @Test\n+    \/* TODO: 8353717\n+    @IR(applyIfAnd = {\"UseG1GC\", \"true\", \"UseArrayFlattening\", \"true\"},\n+        failOn = {STORE_UNKNOWN_INLINE, INLINE_ARRAY_NULL_GUARD},\n+        counts = {COUNTEDLOOP, \"= 2\", LOAD_UNKNOWN_INLINE, \"= 2\"})\n+    @IR(applyIfAnd = {\"UseG1GC\", \"false\", \"UseArrayFlattening\", \"true\"},\n+        failOn = {STORE_UNKNOWN_INLINE, INLINE_ARRAY_NULL_GUARD},\n+        counts = {COUNTEDLOOP, \"= 3\", LOAD_UNKNOWN_INLINE, \"= 2\"})\n+    *\/\n+    public void test107(Object[] src1, Object[] src2) {\n+        for (int i = 0; i < src1.length; i++) {\n+            oFld1 = src1[i];\n+            oFld2 = src2[i];\n+        }\n+    }\n+\n+    @Run(test = \"test107\")\n+    @Warmup(0)\n+    public void test107_verifier(RunInfo info) {\n+        MyValue2[] src1 = (MyValue2[])ValueClass.newNullRestrictedArray(MyValue2.class, 100);\n+        Arrays.fill(src1, testValue2);\n+        Object[] src2 = new Object[100];\n+        Object obj = new Object();\n+        Arrays.fill(src2, obj);\n+        rerun_and_recompile_for(info.getTest(), 10,\n+                                () -> { test107(src1, src2);\n+                                        Asserts.assertEquals(oFld1, testValue2);\n+                                        Asserts.assertEquals(oFld2, obj);\n+                                        test107(src2, src1);\n+                                        Asserts.assertEquals(oFld1, obj);\n+                                        Asserts.assertEquals(oFld2, testValue2);  });\n+    }\n+\n+    @Test\n+    @IR(applyIfAnd = {\"UseG1GC\", \"true\", \"UseArrayFlattening\", \"true\"},\n+        failOn = {LOAD_UNKNOWN_INLINE, INLINE_ARRAY_NULL_GUARD},\n+        counts = {COUNTEDLOOP, \"= 4\", STORE_UNKNOWN_INLINE, \"= 9\"})\n+    @IR(applyIfAnd = {\"UseG1GC\", \"false\", \"UseArrayFlattening\", \"true\"},\n+        failOn = {LOAD_UNKNOWN_INLINE, INLINE_ARRAY_NULL_GUARD},\n+        counts = {COUNTEDLOOP, \"= 4\", STORE_UNKNOWN_INLINE, \"= 12\"})\n+    public void test108(Object[] dst1, Object[] dst2, Object o1, Object o2) {\n+        for (int i = 0; i < dst1.length; i++) {\n+            dst1[i] = o1;\n+            dst2[i] = o2;\n+        }\n+    }\n+\n+    @Run(test = \"test108\")\n+    @Warmup(0)\n+    public void test108_verifier(RunInfo info) {\n+        MyValue2[] dst1 = (MyValue2[])ValueClass.newNullRestrictedArray(MyValue2.class, 100);\n+        Object[] dst2 = new Object[100];\n+        Object o1 = new Object();\n+        rerun_and_recompile_for(info.getTest(), 10,\n+                                () -> { test108(dst1, dst2, testValue2, o1);\n+                                        for (int i = 0; i < dst1.length; i++) {\n+                                            Asserts.assertEquals(dst1[i], testValue2);\n+                                            Asserts.assertEquals(dst2[i], o1);\n+                                        }\n+                                        test108(dst2, dst1, o1, testValue2);\n+                                        for (int i = 0; i < dst1.length; i++) {\n+                                            Asserts.assertEquals(dst1[i], testValue2);\n+                                            Asserts.assertEquals(dst2[i], o1);\n+                                        } });\n+    }\n+\n+    \/\/ Escape analysis tests\n+\n+    static interface WrapperInterface {\n+        long value();\n+\n+        final static WrapperInterface ZERO = new LongWrapper(0);\n+\n+        @ForceInline\n+        static WrapperInterface wrap(long val) {\n+            return (val == 0L) ? ZERO : new LongWrapper(val);\n+        }\n+    }\n+\n+    @ForceCompileClassInitializer\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class LongWrapper implements WrapperInterface {\n+        @NullRestricted\n+        final static LongWrapper ZERO = new LongWrapper(0);\n+        private long val;\n+\n+        @ForceInline\n+        LongWrapper(long val) {\n+            this.val = val;\n+        }\n+\n+        @ForceInline\n+        static LongWrapper wrap(long val) {\n+            return (val == 0L) ? ZERO : new LongWrapper(val);\n+        }\n+\n+        @ForceInline\n+        public long value() {\n+            return val;\n+        }\n+    }\n+\n+    static class InterfaceBox {\n+        WrapperInterface content;\n+\n+        @ForceInline\n+        InterfaceBox(WrapperInterface content) {\n+            this.content = content;\n+        }\n+\n+        @ForceInline\n+        static InterfaceBox box_sharp(long val) {\n+            return new InterfaceBox(LongWrapper.wrap(val));\n+        }\n+\n+        @ForceInline\n+        static InterfaceBox box(long val) {\n+            return new InterfaceBox(WrapperInterface.wrap(val));\n+        }\n+    }\n+\n+    static class ObjectBox {\n+        Object content;\n+\n+        @ForceInline\n+        ObjectBox(Object content) {\n+            this.content = content;\n+        }\n+\n+        @ForceInline\n+        static ObjectBox box_sharp(long val) {\n+            return new ObjectBox(LongWrapper.wrap(val));\n+        }\n+\n+        @ForceInline\n+        static ObjectBox box(long val) {\n+            return new ObjectBox(WrapperInterface.wrap(val));\n+        }\n+    }\n+\n+    static class RefBox {\n+        LongWrapper content;\n+\n+        @ForceInline\n+        RefBox(LongWrapper content) {\n+            this.content = content;\n+        }\n+\n+        @ForceInline\n+        static RefBox box_sharp(long val) {\n+            return new RefBox(LongWrapper.wrap(val));\n+        }\n+\n+        @ForceInline\n+        static RefBox box(long val) {\n+            return new RefBox((LongWrapper)WrapperInterface.wrap(val));\n+        }\n+    }\n+\n+    static class InlineBox {\n+        @NullRestricted\n+        LongWrapper content;\n+\n+        @ForceInline\n+        InlineBox(long val) {\n+            this.content = LongWrapper.wrap(val);\n+        }\n+\n+        @ForceInline\n+        static InlineBox box(long val) {\n+            return new InlineBox(val);\n+        }\n+    }\n+\n+    static class GenericBox<T> {\n+        T content;\n+\n+        @ForceInline\n+        static GenericBox<LongWrapper> box_sharp(long val) {\n+            GenericBox<LongWrapper> res = new GenericBox<>();\n+            res.content = LongWrapper.wrap(val);\n+            return res;\n+        }\n+\n+        @ForceInline\n+        static GenericBox<WrapperInterface> box(long val) {\n+            GenericBox<WrapperInterface> res = new GenericBox<>();\n+            res.content = WrapperInterface.wrap(val);\n+            return res;\n+        }\n+    }\n+\n+    long[] lArr = {0L, rL, 0L, rL, 0L, rL, 0L, rL, 0L, rL};\n+\n+    \/\/ Test removal of allocations when inline type instance is wrapped into box object\n+    @Test\n+    @IR(failOn = {ALLOC_G, MEMBAR},\n+        counts = {PREDICATE_TRAP, \"= 1\"})\n+    public long test109() {\n+        long res = 0;\n+        for (int i = 0; i < lArr.length; i++) {\n+            res += InterfaceBox.box(lArr[i]).content.value();\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test109\")\n+    @Warmup(10000) \/\/ Make sure interface calls are inlined\n+    public void test109_verifier() {\n+        long res = test109();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    @Test\n+    \/* TODO: 8353717\n+    @IR(failOn = {ALLOC_G, MEMBAR},\n+        counts = {PREDICATE_TRAP, \"= 1\"})\n+    @IR(failOn = {ALLOC_G, MEMBAR})\n+    *\/\n+    public long test109_sharp() {\n+        long res = 0;\n+        for (int i = 0; i < lArr.length; i++) {\n+            res += InterfaceBox.box_sharp(lArr[i]).content.value();\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test109_sharp\")\n+    @Warmup(10000) \/\/ Make sure interface calls are inlined\n+    public void test109_sharp_verifier() {\n+        long res = test109_sharp();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    \/\/ Same as test109 but with ObjectBox\n+    @Test\n+    @IR(failOn = {ALLOC_G, MEMBAR},\n+        counts = {PREDICATE_TRAP, \"= 1\"})\n+    public long test110() {\n+        long res = 0;\n+        for (int i = 0; i < lArr.length; i++) {\n+            res += ((WrapperInterface)ObjectBox.box(lArr[i]).content).value();\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test110\")\n+    @Warmup(10000) \/\/ Make sure interface calls are inlined\n+    public void test110_verifier() {\n+        long res = test110();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    @Test\n+    \/* TODO: 8353717\n+    @IR(failOn = {ALLOC_G, MEMBAR},\n+        counts = {PREDICATE_TRAP, \"= 1\"})\n+    @IR(failOn = {ALLOC_G, MEMBAR})\n+    *\/\n+    public long test110_sharp() {\n+        long res = 0;\n+        for (int i = 0; i < lArr.length; i++) {\n+            res += ((WrapperInterface)ObjectBox.box_sharp(lArr[i]).content).value();\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test110_sharp\")\n+    @Warmup(10000) \/\/ Make sure interface calls are inlined\n+    public void test110_sharp_verifier() {\n+        long res = test110_sharp();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    \/\/ Same as test109 but with RefBox\n+    @Test\n+    @IR(failOn = {ALLOC_G, MEMBAR},\n+        counts = {PREDICATE_TRAP, \"= 1\"})\n+    public long test111() {\n+        long res = 0;\n+        for (int i = 0; i < lArr.length; i++) {\n+            res += RefBox.box(lArr[i]).content.value();\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test111\")\n+    public void test111_verifier() {\n+        long res = test111();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    @Test\n+    \/* TODO: 8353717\n+    @IR(failOn = {ALLOC_G, MEMBAR},\n+        counts = {PREDICATE_TRAP, \"= 1\"})\n+    *\/\n+    public long test111_sharp() {\n+        long res = 0;\n+        for (int i = 0; i < lArr.length; i++) {\n+            res += RefBox.box_sharp(lArr[i]).content.value();\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test111_sharp\")\n+    public void test111_sharp_verifier() {\n+        long res = test111_sharp();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    \/\/ Same as test109 but with InlineBox\n+    @Test\n+    @IR(failOn = {ALLOC_G, MEMBAR},\n+        counts = {PREDICATE_TRAP, \"= 1\"})\n+    public long test112() {\n+        long res = 0;\n+        for (int i = 0; i < lArr.length; i++) {\n+            res += InlineBox.box(lArr[i]).content.value();\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test112\")\n+    public void test112_verifier() {\n+        long res = test112();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    \/\/ Same as test109 but with GenericBox\n+    @Test\n+    @IR(failOn = {ALLOC_G, MEMBAR},\n+        counts = {PREDICATE_TRAP, \"= 1\"})\n+    public long test113() {\n+        long res = 0;\n+        for (int i = 0; i < lArr.length; i++) {\n+            res += GenericBox.box(lArr[i]).content.value();\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test113\")\n+    @Warmup(10000) \/\/ Make sure interface calls are inlined\n+    public void test113_verifier() {\n+        long res = test113();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    @Test\n+    \/* TODO: 8353717\n+    @IR(failOn = {ALLOC_G, MEMBAR},\n+        counts = {PREDICATE_TRAP, \"= 1\"})\n+    *\/\n+    public long test113_sharp() {\n+        long res = 0;\n+        for (int i = 0; i < lArr.length; i++) {\n+            res += GenericBox.box_sharp(lArr[i]).content.value();\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test113_sharp\")\n+    @Warmup(10000) \/\/ Make sure interface calls are inlined\n+    public void test113_sharp_verifier() {\n+        long res = test113_sharp();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    static interface WrapperInterface2 {\n+        public long value();\n+\n+        static final InlineWrapper ZERO = new InlineWrapper(0);\n+\n+        @ForceInline\n+        public static WrapperInterface2 wrap(long val) {\n+            return (val == 0) ? ZERO.content : new LongWrapper2(val);\n+        }\n+\n+        @ForceInline\n+        public static WrapperInterface2 wrap_default(long val) {\n+            return (val == 0) ? new LongWrapper2(0) : new LongWrapper2(val);\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class LongWrapper2 implements WrapperInterface2 {\n+        private long val;\n+\n+        @ForceInline\n+        public LongWrapper2(long val) {\n+            this.val = val;\n+        }\n+\n+        @ForceInline\n+        public long value() {\n+            return val;\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class InlineWrapper {\n+        WrapperInterface2 content;\n+\n+        @ForceInline\n+        public InlineWrapper(long val) {\n+            content = new LongWrapper2(val);\n+        }\n+    }\n+\n+    static class InterfaceBox2 {\n+        WrapperInterface2 content;\n+\n+        @ForceInline\n+        public InterfaceBox2(long val, boolean def) {\n+            this.content = def ? WrapperInterface2.wrap_default(val) : WrapperInterface2.wrap(val);\n+        }\n+\n+        @ForceInline\n+        static InterfaceBox2 box(long val) {\n+            return new InterfaceBox2(val, false);\n+        }\n+\n+        @ForceInline\n+        static InterfaceBox2 box_default(long val) {\n+            return new InterfaceBox2(val, true);\n+        }\n+    }\n+\n+    \/\/ Same as tests above but with ZERO hidden in field of another inline type\n+    @Test\n+    @IR(failOn = {ALLOC_G, MEMBAR},\n+        counts = {PREDICATE_TRAP, \"= 1\"})\n+    public long test114() {\n+        long res = 0;\n+        for (int i = 0; i < lArr.length; i++) {\n+            res += InterfaceBox2.box(lArr[i]).content.value();\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test114\")\n+    @Warmup(10000)\n+    public void test114_verifier() {\n+        long res = test114();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    \/\/ Same as test114 but with default instead of ZERO field\n+    @Test\n+    \/* TODO: 8353717\n+      @IR(failOn = {ALLOC_G, MEMBAR},\n+      counts = {PREDICATE_TRAP, \"= 1\"}) *\/\n+    public long test115() {\n+        long res = 0;\n+        for (int i = 0; i < lArr.length; i++) {\n+            res += InterfaceBox2.box_default(lArr[i]).content.value();\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test115\")\n+    @Warmup(10000)\n+    public void test115_verifier() {\n+        long res = test115();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    @NullRestricted\n+    static MyValueEmpty fEmpty1;\n+    static MyValueEmpty fEmpty2 = new MyValueEmpty();\n+    @NullRestricted\n+           MyValueEmpty fEmpty3;\n+           MyValueEmpty fEmpty4 = new MyValueEmpty();\n+\n+    \/\/ Test fields loads\/stores with empty inline types\n+    @Test\n+    @IR(failOn = {ALLOC_G, TRAP})\n+    public void test116() {\n+        fEmpty1 = fEmpty4;\n+        fEmpty2 = fEmpty1;\n+        fEmpty3 = fEmpty2;\n+        fEmpty4 = fEmpty3;\n+    }\n+\n+    @Run(test = \"test116\")\n+    public void test116_verifier() {\n+        test116();\n+        Asserts.assertEquals(fEmpty1, fEmpty2);\n+        Asserts.assertEquals(fEmpty2, fEmpty3);\n+        Asserts.assertEquals(fEmpty3, fEmpty4);\n+    }\n+\n+    \/\/ Test array loads\/stores with empty inline types\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public MyValueEmpty test117(MyValueEmpty[] arr1, MyValueEmpty[] arr2) {\n+        arr1[0] = arr2[0];\n+        arr2[0] = new MyValueEmpty();\n+        return arr1[0];\n+    }\n+\n+    @Run(test = \"test117\")\n+    public void test117_verifier() {\n+        MyValueEmpty[] arr1 = new MyValueEmpty[] { new MyValueEmpty() };\n+        MyValueEmpty res = test117(arr1, arr1);\n+        Asserts.assertEquals(res, new MyValueEmpty());\n+        Asserts.assertEquals(arr1[0], new MyValueEmpty());\n+    }\n+\n+    \/\/ Test acmp with empty inline types\n+    @Test\n+    public boolean test118(MyValueEmpty v1, MyValueEmpty v2, Object o1) {\n+        return (v1 == v2) && (v2 == o1);\n+    }\n+\n+    @Run(test = \"test118\")\n+    public void test118_verifier() {\n+        boolean res = test118(new MyValueEmpty(), new MyValueEmpty(), new MyValueEmpty());\n+        Asserts.assertTrue(res);\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class EmptyContainer {\n+        @NullRestricted\n+        private MyValueEmpty empty = new MyValueEmpty();\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MixedContainer {\n+        public int val = 0;\n+        @NullRestricted\n+        private EmptyContainer empty = new EmptyContainer();\n+    }\n+\n+    @NullRestricted\n+    static final MyValueEmpty empty = new MyValueEmpty();\n+\n+    @NullRestricted\n+    static final EmptyContainer emptyC = new EmptyContainer();\n+\n+    @NullRestricted\n+    static final MixedContainer mixedContainer = new MixedContainer();\n+\n+    \/\/ Test re-allocation of empty inline type array during deoptimization\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public void test119(boolean deopt, Method m) {\n+        MyValueEmpty[]   array1 = new MyValueEmpty[] { empty };\n+        EmptyContainer[] array2 = (EmptyContainer[])ValueClass.newNullRestrictedArray(EmptyContainer.class, 1);\n+        array2[0] = emptyC;\n+        MixedContainer[] array3 = (MixedContainer[])ValueClass.newNullRestrictedArray(MixedContainer.class, 1);\n+        array3[0] = mixedContainer;\n+        if (deopt) {\n+            \/\/ uncommon trap\n+            TestFramework.deoptimize(m);\n+        }\n+        Asserts.assertEquals(array1[0], empty);\n+        Asserts.assertEquals(array2[0], emptyC);\n+        Asserts.assertEquals(array3[0], mixedContainer);\n+    }\n+\n+    @Run(test = \"test119\")\n+    public void test119_verifier(RunInfo info) {\n+        test119(!info.isWarmUp(), info.getTest());\n+    }\n+\n+    \/\/ Test removal of empty inline type field stores\n+    @Test\n+    @IR(failOn = {ALLOC_G, LOAD, STORE, FIELD_ACCESS, NULL_CHECK_TRAP, TRAP})\n+    public void test120() {\n+        fEmpty1 = empty;\n+        fEmpty3 = empty;\n+        \/\/ fEmpty2 and fEmpty4 could be null, store can't be removed\n+    }\n+\n+    @Run(test = \"test120\")\n+    public void test120_verifier() {\n+        test120();\n+        Asserts.assertEquals(fEmpty1, empty);\n+        Asserts.assertEquals(fEmpty2, empty);\n+    }\n+\n+    \/\/ Test removal of empty inline type field loads\n+    @Test\n+    @IR(failOn = {ALLOC_G, LOAD, STORE, FIELD_ACCESS, NULL_CHECK_TRAP, TRAP})\n+    public boolean test121() {\n+        return fEmpty1.equals(fEmpty3);\n+        \/\/ fEmpty2 and fEmpty4 could be null, load can't be removed\n+    }\n+\n+    @Run(test = \"test121\")\n+    public void test121_verifier() {\n+        boolean res = test121();\n+        Asserts.assertTrue(res);\n+    }\n+\n+    \/\/ Verify that empty inline type field loads check for null holder\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public MyValueEmpty test122(TestLWorld t) {\n+        return t.fEmpty3;\n+    }\n+\n+    @Run(test = \"test122\")\n+    public void test122_verifier() {\n+        MyValueEmpty res = test122(this);\n+        Asserts.assertEquals(res, new MyValueEmpty());\n+        try {\n+            test122(null);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Verify that empty inline type field stores check for null holder\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public void test123(TestLWorld t) {\n+        t.fEmpty3 = new MyValueEmpty();\n+    }\n+\n+    @Run(test = \"test123\")\n+    public void test123_verifier() {\n+        test123(this);\n+        Asserts.assertEquals(fEmpty3, new MyValueEmpty());\n+        try {\n+            test123(null);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ acmp doesn't need substitutability test when one input is known\n+    \/\/ not to be a value type\n+    @Test\n+    @IR(failOn = SUBSTITUTABILITY_TEST)\n+    public boolean test124(NonValueClass o1, Object o2) {\n+        return o1 == o2;\n+    }\n+\n+    @Run(test = \"test124\")\n+    public void test124_verifier() {\n+        NonValueClass obj = new NonValueClass(rI);\n+        test124(obj, obj);\n+        test124(obj, testValue1);\n+    }\n+\n+    \/\/ acmp doesn't need substitutability test when one input is null\n+    @Test\n+    @IR(failOn = {SUBSTITUTABILITY_TEST})\n+    public boolean test125(Object o1) {\n+        Object o2 = null;\n+        return o1 == o2;\n+    }\n+\n+    @Run(test = \"test125\")\n+    public void test125_verifier() {\n+        test125(testValue1);\n+        test125(null);\n+    }\n+\n+    \/\/ Test inline type that can only be scalarized after loop opts\n+    @Test\n+    @IR(failOn = {ALLOC_G, LOAD, STORE})\n+    public long test126(boolean trap) {\n+        MyValue2 nonNull = MyValue2.createWithFieldsInline(rI, rD);\n+        MyValue2 val = null;\n+\n+        for (int i = 0; i < 4; i++) {\n+            if ((i % 2) == 0) {\n+                val = nonNull;\n+            }\n+        }\n+        \/\/ 'val' is always non-null here but that's only known after loop opts\n+        if (trap) {\n+            \/\/ Uncommon trap with an inline input that can only be scalarized after loop opts\n+            return val.hash();\n+        }\n+        return 0;\n+    }\n+\n+    @Run(test = \"test126\")\n+    @Warmup(10000)\n+    public void test126_verifier(RunInfo info) {\n+        long res = test126(false);\n+        Asserts.assertEquals(res, 0L);\n+        if (!info.isWarmUp()) {\n+            res = test126(true);\n+            Asserts.assertEquals(res, testValue2.hash());\n+        }\n+    }\n+\n+    \/\/ Same as test126 but with interface type\n+    @Test\n+    @IR(failOn = {ALLOC_G, LOAD, STORE})\n+    public long test127(boolean trap) {\n+        MyValue2 nonNull = MyValue2.createWithFieldsInline(rI, rD);\n+        MyInterface val = null;\n+\n+        for (int i = 0; i < 4; i++) {\n+            if ((i % 2) == 0) {\n+                val = nonNull;\n+            }\n+        }\n+        \/\/ 'val' is always non-null here but that's only known after loop opts\n+        if (trap) {\n+            \/\/ Uncommon trap with an inline input that can only be scalarized after loop opts\n+            return val.hash();\n+        }\n+        return 0;\n+    }\n+\n+    @Run(test = \"test127\")\n+    @Warmup(10000)\n+    public void test127_verifier(RunInfo info) {\n+        long res = test127(false);\n+        Asserts.assertEquals(res, 0L);\n+        if (!info.isWarmUp()) {\n+            res = test127(true);\n+            Asserts.assertEquals(res, testValue2.hash());\n+        }\n+    }\n+\n+    \/\/ Test inline type that can only be scalarized after CCP\n+    @Test\n+    @IR(failOn = {ALLOC_G, LOAD, STORE})\n+    public long test128(boolean trap) {\n+        MyValue2 nonNull = MyValue2.createWithFieldsInline(rI, rD);\n+        MyValue2 val = null;\n+\n+        int limit = 2;\n+        for (; limit < 4; limit *= 2);\n+        for (int i = 2; i < limit; i++) {\n+            val = nonNull;\n+        }\n+        \/\/ 'val' is always non-null here but that's only known after CCP\n+        if (trap) {\n+            \/\/ Uncommon trap with an inline input that can only be scalarized after CCP\n+            return val.hash();\n+        }\n+        return 0;\n+    }\n+\n+    @Run(test = \"test128\")\n+    @Warmup(10000)\n+    public void test128_verifier(RunInfo info) {\n+        long res = test128(false);\n+        Asserts.assertEquals(res, 0L);\n+        if (!info.isWarmUp()) {\n+            res = test128(true);\n+            Asserts.assertEquals(res, testValue2.hash());\n+        }\n+    }\n+\n+    \/\/ Same as test128 but with interface type\n+    @Test\n+    @IR(failOn = {ALLOC_G, LOAD, STORE})\n+    public long test129(boolean trap) {\n+        MyValue2 nonNull = MyValue2.createWithFieldsInline(rI, rD);\n+        MyInterface val = null;\n+\n+        int limit = 2;\n+        for (; limit < 4; limit *= 2);\n+        for (int i = 0; i < limit; i++) {\n+            val = nonNull;\n+        }\n+        \/\/ 'val' is always non-null here but that's only known after CCP\n+        if (trap) {\n+            \/\/ Uncommon trap with an inline input that can only be scalarized after CCP\n+            return val.hash();\n+        }\n+        return 0;\n+    }\n+\n+    @Run(test = \"test129\")\n+    @Warmup(10000)\n+    public void test129_verifier(RunInfo info) {\n+        long res = test129(false);\n+        Asserts.assertEquals(res, 0L);\n+        if (!info.isWarmUp()) {\n+            res = test129(true);\n+            Asserts.assertEquals(res, testValue2.hash());\n+        }\n+    }\n+\n+    \/\/ Lock on inline type (known after inlining)\n+    @ForceInline\n+    public Object test130_inlinee() {\n+        return MyValue1.createWithFieldsInline(rI, rL);\n+    }\n+\n+    @Test\n+    @IR(failOn = {LOAD},\n+        \/\/ LockNode keeps MyValue1 allocation alive up until macro expansion which in turn keeps MyValue2\n+        \/\/ alloc alive. Although the MyValue1 allocation is removed (unused), MyValue2 is expanded first\n+        \/\/ and therefore stays.\n+        counts = {ALLOC, \"<= 1\", STORE, \"<= 1\"})\n+    public void test130() {\n+        Object obj = test130_inlinee();\n+        synchronized (obj) {\n+            throw new RuntimeException(\"test130 failed: synchronization on inline type should not succeed\");\n+        }\n+    }\n+\n+    @Run(test = \"test130\")\n+    public void test130_verifier() {\n+        try {\n+            test130();\n+            throw new RuntimeException(\"test130 failed: no exception thrown\");\n+        } catch (IdentityException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Same as test130 but with field load instead of allocation\n+    @ForceInline\n+    public Object test131_inlinee() {\n+        return testValue1;\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public void test131() {\n+        Object obj = test131_inlinee();\n+        synchronized (obj) {\n+            throw new RuntimeException(\"test131 failed: synchronization on inline type should not succeed\");\n+        }\n+    }\n+\n+    @Run(test = \"test131\")\n+    public void test131_verifier() {\n+        try {\n+            test131();\n+            throw new RuntimeException(\"test131 failed: no exception thrown\");\n+        } catch (IdentityException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test locking on object that is known to be an inline type only after CCP\n+    @Test\n+    @IR(failOn = {ALLOC, LOAD, STORE})\n+    public void test132() {\n+        MyValue2 vt = MyValue2.createWithFieldsInline(rI, rD);\n+        Object obj = new NonValueClass(42);\n+\n+        int limit = 2;\n+        for (; limit < 4; limit *= 2);\n+        for (int i = 2; i < limit; i++) {\n+            obj = vt;\n+        }\n+        synchronized (obj) {\n+            throw new RuntimeException(\"test132 failed: synchronization on inline type should not succeed\");\n+        }\n+    }\n+\n+    @Run(test = \"test132\")\n+    @Warmup(10000)\n+    public void test132_verifier() {\n+        try {\n+            test132();\n+            throw new RuntimeException(\"test132 failed: no exception thrown\");\n+        } catch (IdentityException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test conditional locking on inline type and non-escaping object\n+    @Test\n+    public void test133(boolean b) {\n+        Object obj = b ? new NonValueClass(rI) : MyValue2.createWithFieldsInline(rI, rD);\n+        synchronized (obj) {\n+            if (!b) {\n+                throw new RuntimeException(\"test133 failed: synchronization on inline type should not succeed\");\n+            }\n+        }\n+    }\n+\n+    @Run(test = \"test133\")\n+    public void test133_verifier() {\n+        test133(true);\n+        try {\n+            test133(false);\n+            throw new RuntimeException(\"test133 failed: no exception thrown\");\n+        } catch (IdentityException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Variant with non-scalarized inline type\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public void test134(boolean b) {\n+        Object obj = null;\n+        if (b) {\n+            obj = MyValue2.createWithFieldsInline(rI, rD);\n+        }\n+        synchronized (obj) {\n+\n+        }\n+    }\n+\n+    @Run(test = \"test134\")\n+    public void test134_verifier() {\n+        try {\n+            test134(true);\n+            throw new RuntimeException(\"test134 failed: no exception thrown\");\n+        } catch (IdentityException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test that acmp of the same inline object is removed\n+    @Test\n+    @IR(failOn = {ALLOC_G, LOAD, STORE, NULL_CHECK_TRAP, TRAP})\n+    public boolean test135() {\n+        MyValue1 val = MyValue1.createWithFieldsInline(rI, rL);\n+        return val == val;\n+    }\n+\n+    @Run(test = \"test135\")\n+    public void test135_verifier() {\n+        Asserts.assertTrue(test135());\n+    }\n+\n+    \/\/ Same as test135 but with null\n+    @Test\n+    @IR(failOn = {ALLOC_G, LOAD, STORE, NULL_CHECK_TRAP, TRAP})\n+    public boolean test136(boolean b) {\n+        MyValue1 val = MyValue1.createWithFieldsInline(rI, rL);\n+        if (b) {\n+            val = null;\n+        }\n+        return val == val;\n+    }\n+\n+    @Run(test = \"test136\")\n+    public void test136_verifier() {\n+        Asserts.assertTrue(test136(false));\n+        Asserts.assertTrue(test136(true));\n+    }\n+\n+    \/\/ Test that acmp of different inline objects with same content is removed\n+    @Test\n+    \/\/ TODO 8228361\n+    \/\/ @IR(failOn = {ALLOC_G, LOAD, STORE, NULL_CHECK_TRAP, TRAP})\n+    public boolean test137(int i) {\n+        MyValue2 val1 = MyValue2.createWithFieldsInline(i, rD);\n+        MyValue2 val2 = MyValue2.createWithFieldsInline(i, rD);\n+        return val1 == val2;\n+    }\n+\n+    @Run(test = \"test137\")\n+    public void test137_verifier() {\n+        Asserts.assertTrue(test137(rI));\n+    }\n+\n+    \/\/ Same as test137 but with null\n+    @Test\n+    \/\/ TODO 8228361\n+    \/\/ @IR(failOn = {ALLOC_G, LOAD, STORE, NULL_CHECK_TRAP, TRAP})\n+    public boolean test138(int i, boolean b) {\n+        MyValue2 val1 = MyValue2.createWithFieldsInline(i, rD);\n+        MyValue2 val2 = MyValue2.createWithFieldsInline(i, rD);\n+        if (b) {\n+            val1 = null;\n+            val2 = null;\n+        }\n+        return val1 == val2;\n+    }\n+\n+    @Run(test = \"test138\")\n+    public void test138_verifier() {\n+        Asserts.assertTrue(test138(rI, false));\n+        Asserts.assertTrue(test138(rI, true));\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class Test139Value {\n+        Object obj = null;\n+        @NullRestricted\n+        MyValueEmpty empty = new MyValueEmpty();\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class Test139Wrapper {\n+        @NullRestricted\n+        Test139Value value = new Test139Value();\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G, LOAD, STORE, TRAP})\n+    public MyValueEmpty test139() {\n+        Test139Wrapper w = new Test139Wrapper();\n+        return w.value.empty;\n+    }\n+\n+    @Run(test = \"test139\")\n+    public void test139_verifier() {\n+        MyValueEmpty empty = test139();\n+        Asserts.assertEquals(empty, new MyValueEmpty());\n+    }\n+\n+    \/\/ Test calling a method on a loaded but not linked inline type\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    value class Test140Value {\n+        int x = 0;\n+\n+        public int get() {\n+            return x;\n+        }\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public int test140() {\n+        Test140Value vt = new Test140Value();\n+        return vt.get();\n+    }\n+\n+    @Run(test = \"test140\")\n+    @Warmup(0)\n+    public void test140_verifier() {\n+        int result = test140();\n+        Asserts.assertEquals(result, 0);\n+    }\n+\n+    \/\/ Test calling a method on a linked but not initialized inline type\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    value class Test141Value {\n+        int x = 0;\n+\n+        public int get() {\n+            return x;\n+        }\n+    }\n+\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public int test141() {\n+        Test141Value vt = new Test141Value();\n+        return vt.get();\n+    }\n+\n+    @Run(test = \"test141\")\n+    @Warmup(0)\n+    public void test141_verifier() {\n+        int result = test141();\n+        Asserts.assertEquals(result, 0);\n+    }\n+\n+    \/\/ Test that virtual calls on inline type receivers are properly inlined\n+    @Test\n+    @IR(failOn = {ALLOC_G, LOAD, STORE})\n+    public long test142() {\n+        MyValue2 nonNull = MyValue2.createWithFieldsInline(rI, rD);\n+        MyInterface val = null;\n+\n+        for (int i = 0; i < 4; i++) {\n+            if ((i % 2) == 0) {\n+                val = nonNull;\n+            }\n+        }\n+        return val.hash();\n+    }\n+\n+    @Run(test = \"test142\")\n+    public void test142_verifier() {\n+        long res = test142();\n+        Asserts.assertEquals(res, testValue2.hash());\n+    }\n+\n+    \/\/ Test merging of buffered default and non-default inline types\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public Object test144(int i) {\n+        if (i == 0) {\n+            return MyValue1.createDefaultInline();\n+        } else if (i == 1) {\n+            return testValue1;\n+        } else {\n+            return MyValue1.createDefaultInline();\n+        }\n+    }\n+\n+    @Run(test = \"test144\")\n+    public void test144_verifier() {\n+        Asserts.assertEquals(test144(0), MyValue1.createDefaultInline());\n+        Asserts.assertEquals(test144(1), testValue1);\n+        Asserts.assertEquals(test144(2), MyValue1.createDefaultInline());\n+    }\n+\n+    \/\/ Tests writing an array element with a (statically known) incompatible type\n+    private static final MethodHandle setArrayElementIncompatibleRef = InstructionHelper.buildMethodHandle(MethodHandles.lookup(),\n+        \"setArrayElementIncompatibleRef\",\n+        MethodType.methodType(void.class, TestLWorld.class, MyValue1[].class, int.class, MyValue2.class),\n+        CODE -> {\n+            CODE.\n+            aload(1).\n+            iload(2).\n+            aload(3).\n+            aastore().\n+            return_();\n+        });\n+\n+    \/\/ Test inline type connected to result node\n+    @Test\n+    @IR(failOn = {ALLOC_G})\n+    public MyValue1 test146(Object obj) {\n+        return (MyValue1)obj;\n+    }\n+\n+    @Run(test = \"test146\")\n+    @Warmup(10000)\n+    public void test146_verifier() {\n+        Asserts.assertEQ(test146(testValue1), testValue1);\n+    }\n+\n+    @ForceInline\n+    public Object test148_helper(Object obj) {\n+        return (MyValue1)obj;\n+    }\n+\n+    \/\/ Same as test146 but with helper method\n+    @Test\n+    public Object test148(Object obj) {\n+        return test148_helper(obj);\n+    }\n+\n+    @Run(test = \"test148\")\n+    @Warmup(10000)\n+    public void test148_verifier() {\n+        Asserts.assertEQ(test148(testValue1), testValue1);\n+    }\n+\n+    @ForceInline\n+    public Object test149_helper(Object obj) {\n+        return (MyValue1)obj;\n+    }\n+\n+    \/\/ Same as test147 but with helper method\n+    @Test\n+    public Object test149(Object obj) {\n+        return test149_helper(obj);\n+    }\n+\n+    @Run(test = \"test149\")\n+    @Warmup(10000)\n+    public void test149_verifier() {\n+        Asserts.assertEQ(test149(testValue1), testValue1);\n+        Asserts.assertEQ(test149(null), null);\n+    }\n+\n+    \/\/ Test post-parse call devirtualization with inline type receiver\n+    @Test\n+    @IR(applyIf = {\"InlineTypePassFieldsAsArgs\", \"true\"},\n+        failOn = {ALLOC})\n+    @IR(failOn = {compiler.lib.ir_framework.IRNode.DYNAMIC_CALL_OF_METHOD, \"MyValue2::hash\"},\n+        counts = {compiler.lib.ir_framework.IRNode.STATIC_CALL_OF_METHOD, \"MyValue2::hash\", \"= 1\"})\n+    public long test150() {\n+        MyValue2 val = MyValue2.createWithFieldsInline(rI, rD);\n+        MyInterface receiver = MyValue1.createWithFieldsInline(rI, rL);\n+\n+        for (int i = 0; i < 4; i++) {\n+            if ((i % 2) == 0) {\n+                receiver = val;\n+            }\n+        }\n+        \/\/ Trigger post parse call devirtualization (strength-reducing\n+        \/\/ virtual calls to direct calls).\n+        return receiver.hash();\n+    }\n+\n+    @Run(test = \"test150\")\n+    public void test150_verifier() {\n+        Asserts.assertEquals(test150(), testValue2.hash());\n+    }\n+\n+\/\/ TODO 8336003 This triggers #  assert(false) failed: Should have been buffered\n+\/*\n+    \/\/ Same as test150 but with val not being allocated in the scope of the method\n+    @Test\n+    @IR(failOn = {compiler.lib.ir_framework.IRNode.DYNAMIC_CALL_OF_METHOD, \"MyValue2::hash\"},\n+        counts = {compiler.lib.ir_framework.IRNode.STATIC_CALL_OF_METHOD, \"MyValue2::hash\", \"= 1\"})\n+    public long test151(MyValue2 val) {\n+        MyAbstract receiver = MyValue1.createWithFieldsInline(rI, rL);\n+\n+        for (int i = 0; i < 100; i++) {\n+            if ((i % 2) == 0) {\n+                receiver = val;\n+            }\n+        }\n+        \/\/ Trigger post parse call devirtualization (strength-reducing\n+        \/\/ virtual calls to direct calls).\n+        return receiver.hash();\n+    }\n+\n+    @Run(test = \"test151\")\n+    @Warmup(0) \/\/ Make sure there is no receiver type profile\n+    public void test151_verifier() {\n+        Asserts.assertEquals(test151(testValue2), testValue2.hash());\n+    }\n+*\/\n+\n+    static interface MyInterface2 {\n+        public int val();\n+    }\n+\n+    @ImplicitlyConstructible\n+    static abstract value class MyAbstract2 implements MyInterface2 {\n+\n+    }\n+\n+    static class MyClass152 extends MyAbstract2 {\n+        private int val;\n+\n+        @ForceInline\n+        public MyClass152(int val) {\n+            this.val = val;\n+        }\n+\n+        @Override\n+        public int val() {\n+            return val;\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue152 extends MyAbstract2 {\n+        private int unused = 0; \/\/ Make sure sub-offset of val is field non-zero\n+        private int val;\n+\n+        @ForceInline\n+        public MyValue152(int val) {\n+            this.val = val;\n+        }\n+\n+        @Override\n+        public int val() {\n+            return val;\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyWrapper152 {\n+        private int unused = 0; \/\/ Make sure sub-offset of val field is non-zero\n+        @NullRestricted\n+        MyValue152 val;\n+\n+        @ForceInline\n+        public MyWrapper152(MyInterface2 val) {\n+            this.val = (MyValue152)val;\n+        }\n+    }\n+\n+    \/\/ Test that checkcast with speculative type does not break scalarization in return\n+    @Test\n+    public MyWrapper152 test152(MyInterface2 val) {\n+        return new MyWrapper152(val);\n+    }\n+\n+    @Run(test = \"test152\")\n+    @Warmup(10000) \/\/ Make sure profile information is available at cast\n+    public void test152_verifier() {\n+        MyClass152 unused = new MyClass152(rI);\n+        MyValue152 val = new MyValue152(rI);\n+        Asserts.assertEquals(test152(val).val, val);\n+    }\n+\n+    @DontInline\n+    static void test153_helper(MyWrapper152 arg) {\n+\n+    }\n+\n+    \/\/ Test that checkcast with speculative type does not prevent scalarization in args\n+    @Test\n+    public void test153(MyInterface2 val) {\n+        test153_helper(new MyWrapper152(val));\n+    }\n+\n+    @Run(test = \"test153\")\n+    @Warmup(10000) \/\/ Make sure profile information is available at cast\n+    public void test153_verifier() {\n+        MyClass152 unused = new MyClass152(rI);\n+        MyValue152 val = new MyValue152(rI);\n+        test153(val);\n+    }\n+\n+    \/\/ Test that checkcast with speculative type enables scalarization\n+    @Test\n+    @IR(failOn = {ALLOC_G, STORE})\n+    public int test154(Method m, MyInterface2 val, boolean b1, boolean b2) {\n+        MyInterface2 obj = new MyValue152(rI);\n+        if (b1) {\n+            \/\/ Speculative cast to MyValue152 enables scalarization\n+            obj = (MyAbstract2)val;\n+        }\n+        if (b2) {\n+            \/\/ Uncommon trap\n+            TestFramework.deoptimize(m);\n+            return obj.val();\n+        }\n+        return -1;\n+    }\n+\n+    @Run(test = \"test154\")\n+    @Warmup(10000) \/\/ Make sure profile information is available at cast\n+    public void test154_verifier(RunInfo info) {\n+        MyClass152 unused = new MyClass152(rI);\n+        MyValue152 val = new MyValue152(rI);\n+        Asserts.assertEquals(test154(info.getTest(), val, false, false), -1);\n+        Asserts.assertEquals(test154(info.getTest(), val, true, false), -1);\n+        if (!info.isWarmUp()) {\n+            Asserts.assertEquals(test154(info.getTest(), val, false, true), rI);\n+        }\n+    }\n+\n+    \/\/ Same as test154 but with null val\n+    @Test\n+    @IR(failOn = {ALLOC_G, STORE})\n+    public int test155(Method m, MyInterface2 val, boolean b1, boolean b2) {\n+        MyInterface2 obj = new MyValue152(rI);\n+        if (b1) {\n+            \/\/ Speculative cast to MyValue152 enables scalarization\n+            obj = (MyAbstract2)val;\n+        }\n+        if (b2) {\n+            \/\/ Uncommon trap\n+            TestFramework.deoptimize(m);\n+            return obj.val();\n+        }\n+        return -1;\n+    }\n+\n+    @Run(test = \"test155\")\n+    @Warmup(10000) \/\/ Make sure profile information is available at cast\n+    public void test155_verifier(RunInfo info) {\n+        MyClass152 unused = new MyClass152(rI);\n+        MyValue152 val = new MyValue152(rI);\n+        Asserts.assertEquals(test155(info.getTest(), val, false, false), -1);\n+        Asserts.assertEquals(test155(info.getTest(), val, true, false), -1);\n+        Asserts.assertEquals(test155(info.getTest(), null, true, false), -1);\n+        if (!info.isWarmUp()) {\n+            Asserts.assertEquals(test155(info.getTest(), val, false, true), rI);\n+        }\n+    }\n+\n+    @NullRestricted\n+    final static MyValue1 test157Cache = MyValue1.createWithFieldsInline(rI, 0);\n+\n+    \/\/ Test merging buffered inline type from field load with non-buffered inline type\n+    @Test\n+    public MyValue1 test157(long val) {\n+        return (val == 0L) ? test157Cache : MyValue1.createWithFieldsInline(rI, val);\n+    }\n+\n+    @Run(test = \"test157\")\n+    public void test157_verifier() {\n+        Asserts.assertEquals(test157(0), test157Cache);\n+        Asserts.assertEquals(test157(rL).hash(), testValue1.hash());\n+    }\n+\n+    @NullRestricted\n+    static MyValue1 test158Cache = MyValue1.createWithFieldsInline(rI, 0);\n+\n+    \/\/ Same as test157 but with non-final field load\n+    @Test\n+    public MyValue1 test158(long val) {\n+        return (val == 0L) ? test158Cache : MyValue1.createWithFieldsInline(rI, val);\n+    }\n+\n+    @Run(test = \"test158\")\n+    public void test158_verifier() {\n+        Asserts.assertEquals(test158(0), test158Cache);\n+        Asserts.assertEquals(test158(rL).hash(), testValue1.hash());\n+    }\n+\n+    \/\/ Verify that cast that with incompatible types is properly handled\n+    @Test\n+    public void test160(NonValueClass arg) {\n+        Object tmp = arg;\n+        MyValue1 res = (MyValue1)tmp;\n+    }\n+\n+    @Run(test = \"test160\")\n+    @Warmup(10000)\n+    public void test160_verifier(RunInfo info) {\n+        try {\n+            test160(new NonValueClass(42));\n+            throw new RuntimeException(\"No CCE thrown\");\n+        } catch (ClassCastException e) {\n+            \/\/ Expected\n+        }\n+        test160(null);\n+    }\n+\n+    abstract value static class AbstractValueClassSingleSubclass {\n+    }\n+\n+    value static class UniqueValueSubClass extends AbstractValueClassSingleSubclass {\n+        int x = 34;\n+    }\n+\n+    static AbstractValueClassSingleSubclass abstractValueClassSingleSubclass = new UniqueValueSubClass();\n+\n+    @Test\n+    public void testUniqueConcreteValueSubKlass(boolean flag) {\n+        \/\/ C2 should recognize that even though we do not know the exact layout of the underlying inline type of the\n+        \/\/ abstract field abstractValueClassSingleSubclass (i.e. cannot scalarize), we only have a unique concrete sub\n+        \/\/ class from which we know at compile time whether it can be scalarized or not. This unique sub class\n+        \/\/ optimization was missing, resulting in a missing InlineTypeNode assertion failure.\n+        doNothing(abstractValueClassSingleSubclass, flag ? 23 : 34);\n+    }\n+\n+    void doNothing(Object a, int i) {}\n+\n+    @Run(test = \"testUniqueConcreteValueSubKlass\")\n+    public void testUniqueConcreteValueSubKlass_verifier() {\n+        testUniqueConcreteValueSubKlass(true);\n+    }\n+\n+    static value class MyValueContainer {\n+        private final Object value;\n+\n+        private MyValueContainer(Object value) {\n+            this.value = value;\n+        }\n+    }\n+\n+    static value class MyValue161 {\n+        int x = 0;\n+    }\n+\n+    \/\/ Test merging value classes with Object fields\n+    @Test\n+    public MyValueContainer test161(boolean b) {\n+        MyValueContainer res = b ? new MyValueContainer(new MyValue161()) : null;\n+        \/\/ Cast to verify that merged values are of correct type\n+        Object obj = b ? (MyValue161)res.value : null;\n+        return res;\n+    }\n+\n+    @Run(test = \"test161\")\n+    public void test161_verifier() {\n+        Asserts.assertEquals(test161(true), new MyValueContainer(new MyValue161()));\n+        Asserts.assertEquals(test161(false), null);\n+    }\n+\n+    @Test\n+    public MyValueContainer test162(boolean b) {\n+        MyValueContainer res = b ? null : new MyValueContainer(new MyValue161());\n+        \/\/ Cast to verify that merged values are of correct type\n+        Object obj = b ? null : (MyValue161)res.value;\n+        return res;\n+    }\n+\n+    @Run(test = \"test162\")\n+    public void test162_verifier() {\n+        Asserts.assertEquals(test162(true), null);\n+        Asserts.assertEquals(test162(false), new MyValueContainer(new MyValue161()));\n+    }\n+\n+    @Test\n+    public MyValueContainer test163(boolean b) {\n+        MyValueContainer res = b ? new MyValueContainer(new MyValue161()) : new MyValueContainer(null);\n+        \/\/ Cast to verify that merged values are of correct type\n+        Object obj = b ? (MyValue161)res.value : (MyValue161)res.value;\n+        return res;\n+    }\n+\n+    @Run(test = \"test163\")\n+    public void test163_verifier() {\n+        Asserts.assertEquals(test163(true), new MyValueContainer(new MyValue161()));\n+        Asserts.assertEquals(test163(false), new MyValueContainer(null));\n+    }\n+\n+    @Test\n+    public MyValueContainer test164(boolean b) {\n+        MyValueContainer res = b ? new MyValueContainer(null) : new MyValueContainer(new MyValue161());\n+        \/\/ Cast to verify that merged values are of correct type\n+        Object obj = b ? (MyValue161)res.value : (MyValue161)res.value;\n+        return res;\n+    }\n+\n+    @Run(test = \"test164\")\n+    public void test164_verifier() {\n+        Asserts.assertEquals(test164(true), new MyValueContainer(null));\n+        Asserts.assertEquals(test164(false), new MyValueContainer(new MyValue161()));\n+    }\n+\n+    @Test\n+    public MyValueContainer test165(boolean b) {\n+        MyValueContainer res = b ? new MyValueContainer(new MyValue161()) : new MyValueContainer(42);\n+        \/\/ Cast to verify that merged values are of correct type\n+        Object obj = b ? (MyValue161)res.value : (Integer)res.value;\n+        return res;\n+    }\n+\n+    @Run(test = \"test165\")\n+    public void test165_verifier() {\n+        Asserts.assertEquals(test165(true), new MyValueContainer(new MyValue161()));\n+        Asserts.assertEquals(test165(false), new MyValueContainer(42));\n+    }\n+\n+    @Test\n+    public MyValueContainer test166(boolean b) {\n+        MyValueContainer res = b ? new MyValueContainer(42) : new MyValueContainer(new MyValue161());\n+        \/\/ Cast to verify that merged values are of correct type\n+        Object obj = b ? (Integer)res.value : (MyValue161)res.value;\n+        return res;\n+    }\n+\n+    @Run(test = \"test166\")\n+    public void test166_verifier() {\n+        Asserts.assertEquals(test166(true), new MyValueContainer(42));\n+        Asserts.assertEquals(test166(false), new MyValueContainer(new MyValue161()));\n+    }\n+\n+    \/\/ Verify that monitor information in JVMState is correct at method exit\n+    @Test\n+    public synchronized Object test167() {\n+        return MyValue1.createWithFieldsInline(rI, rL); \/\/ Might trigger buffering which requires JVMState\n+    }\n+\n+    @Run(test = \"test167\")\n+    public void test167_verifier() {\n+        Asserts.assertEquals(((MyValue1)test167()).hash(), hash());\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class ValueClassWithInt {\n+        int i;\n+\n+        ValueClassWithInt(int i) {\n+            this.i = i;\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class ValueClassWithDouble {\n+        double d;\n+\n+        ValueClassWithDouble(double d) {\n+            this.d = d;\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static abstract value class AbstractValueClassWithByte {\n+        byte b;\n+\n+        AbstractValueClassWithByte(byte b) {\n+            this.b = b;\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class SubValueClassWithInt extends AbstractValueClassWithByte {\n+        int i;\n+\n+        SubValueClassWithInt(int i) {\n+            this.i = i;\n+            super((byte)(i + 1));\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class SubValueClassWithDouble extends AbstractValueClassWithByte {\n+        double d;\n+\n+        SubValueClassWithDouble(double d) {\n+            this.d = d;\n+            super((byte)(d + 1));\n+        }\n+    }\n+\n+    \/\/ TODO 8350865 We need more copies of these tests for all ValueClass array factories\n+    static final ValueClassWithInt[] VALUE_CLASS_WITH_INT_ARRAY = (ValueClassWithInt[]) ValueClass.newNullRestrictedArray(ValueClassWithInt.class, 2);\n+    static final ValueClassWithDouble[] VALUE_CLASS_WITH_DOUBLE_ARRAY = (ValueClassWithDouble[]) ValueClass.newNullRestrictedArray(ValueClassWithDouble.class, 2);\n+    static final SubValueClassWithInt[] SUB_VALUE_CLASS_WITH_INT_ARRAY = (SubValueClassWithInt[]) ValueClass.newNullRestrictedArray(SubValueClassWithInt.class, 2);\n+    static final SubValueClassWithDouble[] SUB_VALUE_CLASS_WITH_DOUBLE_ARRAY = (SubValueClassWithDouble[]) ValueClass.newNullRestrictedArray(SubValueClassWithDouble.class, 2);\n+\n+\/\/ TODO: Can only be enabled once JDK-8343835 is fixed. Otherwise, we hit the mismatched stores assert.\n+\/\/    static {\n+\/\/        VALUE_CLASS_WITH_INT_ARRAY[0] = new ValueClassWithInt(5);\n+\/\/        VALUE_CLASS_WITH_DOUBLE_ARRAY[0] = new ValueClassWithDouble(6);\n+\/\/        SUB_VALUE_CLASS_WITH_INT_ARRAY[0] = new SubValueClassWithInt(7);\n+\/\/        SUB_VALUE_CLASS_WITH_DOUBLE_ARRAY[0] = new SubValueClassWithDouble(8);\n+\/\/    }\n+\n+    @Test\n+    static void testFlatArrayInexactObjectStore(Object o, boolean flag) {\n+        Object[] oArr;\n+        if (flag) {\n+            oArr = VALUE_CLASS_WITH_INT_ARRAY; \/\/ VALUE_CLASS_WITH_INT_ARRAY is statically known to be flat.\n+        } else {\n+            oArr = VALUE_CLASS_WITH_DOUBLE_ARRAY; \/\/ VALUE_CLASS_WITH_DOUBLE_ARRAY is statically known to be flat.\n+        }\n+        \/\/ The type of 'oArr' is inexact here because we merge two arrays. Since both arrays are flat, 'oArr' is also flat:\n+        \/\/     Type: flat:narrowoop: java\/lang\/Object:NotNull * (flat in array)[int:2]\n+        \/\/ Since the type is inexact, we do not know the exact flat array layout statically and thus need to fall back\n+        \/\/ to call \"store_unknown_inline_Type()\" at runtime where we know the flat array layout\n+        oArr[0] = o;\n+    }\n+\n+    @Test\n+    static Object testFlatArrayInexactObjectLoad(boolean flag) {\n+        Object[] oArr;\n+        if (flag) {\n+            oArr = VALUE_CLASS_WITH_INT_ARRAY; \/\/ VALUE_CLASS_WITH_INT_ARRAY is statically known to be flat.\n+        } else {\n+            oArr = VALUE_CLASS_WITH_DOUBLE_ARRAY; \/\/ VALUE_CLASS_WITH_DOUBLE_ARRAY is statically known to be flat.\n+        }\n+        \/\/ The type of 'oArr' is inexact here because we merge two arrays. Since both arrays are flat, 'oArr' is also flat:\n+        \/\/     Type: flat:narrowoop: java\/lang\/Object:NotNull * (flat in array)[int:2]\n+        \/\/ Since the type is inexact, we do not know the exact flat array layout statically and thus need to fall back\n+        \/\/ to call \"load_unknown_inline_Type()\" at runtime where we know the flat array layout\n+        return oArr[0];\n+    }\n+\n+    @Test\n+    static void testFlatArrayInexactAbstractValueClassStore(AbstractValueClassWithByte abstractValueClassWithByte,\n+                                                            boolean flag) {\n+        AbstractValueClassWithByte[] avArr;\n+        if (flag) {\n+            avArr = SUB_VALUE_CLASS_WITH_INT_ARRAY;\n+        } else {\n+            avArr = SUB_VALUE_CLASS_WITH_DOUBLE_ARRAY;\n+        }\n+        \/\/ Same as testFlatArrayInexactObjectStore() but the inexact type is with an abstract value class:\n+        \/\/    flat:narrowoop: compiler\/valhalla\/inlinetypes\/TestLWorld$AbstractValueClassWithByte:NotNull * (flat in array)[int:2]\n+        avArr[0] = abstractValueClassWithByte;\n+    }\n+\n+    @Test\n+    static AbstractValueClassWithByte testFlatArrayInexactAbstractValueClassLoad(boolean flag) {\n+        AbstractValueClassWithByte[] avArr;\n+        if (flag) {\n+            avArr = SUB_VALUE_CLASS_WITH_INT_ARRAY;\n+        } else {\n+            avArr = SUB_VALUE_CLASS_WITH_DOUBLE_ARRAY;\n+        }\n+        \/\/ Same as testFlatArrayInexactObjectLoad() but the inexact type is with an abstract value class:\n+        \/\/    flat:narrowoop: compiler\/valhalla\/inlinetypes\/TestLWorld$AbstractValueClassWithByte:NotNull * (flat in array)[int:2]\n+        return avArr[0];\n+    }\n+\n+    @Run(test = {\"testFlatArrayInexactObjectStore\",\n+                 \"testFlatArrayInexactObjectLoad\",\n+                 \"testFlatArrayInexactAbstractValueClassStore\",\n+                 \"testFlatArrayInexactAbstractValueClassLoad\"})\n+    static void runFlatArrayInexactLoadAndStore() {\n+        \/\/ TODO: Remove these again once JDK-8343835 is fixed and uncomment static initializer above\n+        VALUE_CLASS_WITH_INT_ARRAY[0] = new ValueClassWithInt(5);\n+        VALUE_CLASS_WITH_DOUBLE_ARRAY[0] = new ValueClassWithDouble(6);\n+        SUB_VALUE_CLASS_WITH_INT_ARRAY[0] = new SubValueClassWithInt(7);\n+        SUB_VALUE_CLASS_WITH_DOUBLE_ARRAY[0] = new SubValueClassWithDouble(8);\n+\n+        boolean flag = true;\n+        ValueClassWithInt valueClassWithInt = new ValueClassWithInt(15);\n+        ValueClassWithDouble valueClassWithDouble = new ValueClassWithDouble(16);\n+\n+        testFlatArrayInexactObjectStore(valueClassWithInt, true);\n+        Asserts.assertEQ(valueClassWithInt, VALUE_CLASS_WITH_INT_ARRAY[0]);\n+        testFlatArrayInexactObjectStore(valueClassWithDouble, false);\n+        Asserts.assertEQ(valueClassWithDouble, VALUE_CLASS_WITH_DOUBLE_ARRAY[0]);\n+\n+        Asserts.assertEQ(valueClassWithInt, testFlatArrayInexactObjectLoad(true));\n+        Asserts.assertEQ(valueClassWithDouble, testFlatArrayInexactObjectLoad(false));\n+\n+        SubValueClassWithInt subValueClassWithInt = new SubValueClassWithInt(17);\n+        SubValueClassWithDouble subValueClassWithDouble = new SubValueClassWithDouble(18);\n+\n+        testFlatArrayInexactAbstractValueClassStore(subValueClassWithInt, true);\n+        Asserts.assertEQ(subValueClassWithInt, SUB_VALUE_CLASS_WITH_INT_ARRAY[0]);\n+        testFlatArrayInexactAbstractValueClassStore(subValueClassWithDouble, false);\n+        Asserts.assertEQ(subValueClassWithDouble, SUB_VALUE_CLASS_WITH_DOUBLE_ARRAY[0]);\n+\n+        Asserts.assertEQ(subValueClassWithInt, testFlatArrayInexactAbstractValueClassLoad(true));\n+        Asserts.assertEQ(subValueClassWithDouble, testFlatArrayInexactAbstractValueClassLoad(false));\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestLWorld.java","additions":4667,"deletions":0,"binary":false,"changes":4667,"status":"added"},{"patch":"@@ -0,0 +1,960 @@\n+\/*\n+ * Copyright (c) 2022, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import compiler.lib.ir_framework.*;\n+import jdk.test.lib.Asserts;\n+\n+import java.lang.reflect.Method;\n+\n+import static compiler.valhalla.inlinetypes.InlineTypeIRNode.*;\n+import static compiler.valhalla.inlinetypes.InlineTypes.*;\n+\n+import jdk.internal.vm.annotation.ImplicitlyConstructible;\n+import jdk.internal.vm.annotation.LooselyConsistentValue;\n+import jdk.internal.vm.annotation.NullRestricted;\n+\n+\/*\n+ * @test\n+ * @key randomness\n+ * @summary Test correct handling of value classes.\n+ * @library \/test\/lib \/test\/jdk\/java\/lang\/invoke\/common \/\n+ * @requires (os.simpleArch == \"x64\" | os.simpleArch == \"aarch64\")\n+ * @enablePreview\n+ * @modules java.base\/jdk.internal.value\n+ *          java.base\/jdk.internal.vm.annotation\n+ * @run main\/othervm\/timeout=300 compiler.valhalla.inlinetypes.TestValueClasses\n+ *\/\n+\n+@ForceCompileClassInitializer\n+public class TestValueClasses {\n+\n+    public static void main(String[] args) {\n+        Scenario[] scenarios = InlineTypes.DEFAULT_SCENARIOS;\n+        \/\/ Don't generate bytecodes but call through runtime for reflective calls\n+        scenarios[0].addFlags(\"-Dsun.reflect.inflationThreshold=10000\");\n+        scenarios[1].addFlags(\"-Dsun.reflect.inflationThreshold=10000\");\n+        scenarios[3].addFlags(\"-XX:-MonomorphicArrayCheck\", \"-XX:+UseArrayFlattening\");\n+        scenarios[4].addFlags(\"-XX:-UseTLAB\", \"-XX:-MonomorphicArrayCheck\");\n+\n+        InlineTypes.getFramework()\n+                   .addScenarios(scenarios)\n+                   .addHelperClasses(MyValueClass1.class,\n+                                     MyValueClass2.class,\n+                                     MyValueClass2Inline.class)\n+                   .start();\n+    }\n+\n+    static {\n+        \/\/ Make sure RuntimeException is loaded to prevent uncommon traps in IR verified tests\n+        RuntimeException tmp = new RuntimeException(\"42\");\n+    }\n+\n+    private static final MyValueClass1 testValue1 = MyValueClass1.createWithFieldsInline(rI, rL);\n+\n+    MyValueClass1 nullValField = null;\n+    MyValueClass1 testField1;\n+    MyValueClass1 testField2;\n+    MyValueClass1 testField3;\n+    MyValueClass1 testField4;\n+    static MyValueClass1 testField5;\n+    static MyValueClass1 testField6;\n+    static MyValueClass1 testField7;\n+    static MyValueClass1 testField8;\n+\n+    \/\/ Test field loads\n+    @Test\n+    public long test1(boolean b) {\n+        MyValueClass1 val1 = b ? testField3 : MyValueClass1.createWithFieldsInline(rI, rL);\n+        MyValueClass1 val2 = b ? testField7 : MyValueClass1.createWithFieldsInline(rI, rL);\n+        long res = 0;\n+        res += testField1.hash();\n+        res += ((Object)testField2 == null) ? 42 : testField2.hash();\n+        res += val1.hash();\n+        res += testField4.hash();\n+\n+        res += testField5.hash();\n+        res += ((Object)testField6 == null) ? 42 : testField6.hash();\n+        res += val2.hash();\n+        res += testField8.hash();\n+        return res;\n+    }\n+\n+    @Run(test = \"test1\")\n+    public void test1_verifier() {\n+        testField1 = testValue1;\n+        testField2 = nullValField;\n+        testField3 = testValue1;\n+        testField4 = testValue1;\n+\n+        testField5 = testValue1;\n+        testField6 = nullValField;\n+        testField7 = testValue1;\n+        testField8 = testValue1;\n+        long res = test1(true);\n+        Asserts.assertEquals(res, 2*42 + 6*testValue1.hash());\n+\n+        testField2 = testValue1;\n+        testField6 = testValue1;\n+        res = test1(false);\n+        Asserts.assertEquals(res, 8*testValue1.hash());\n+    }\n+\n+    \/\/ Test field stores\n+    @Test\n+    public MyValueClass1 test2(MyValueClass1 val1) {\n+        MyValueClass1 ret = MyValueClass1.createWithFieldsInline(rI, rL);\n+        MyValueClass1 val2 = MyValueClass1.setV4(testValue1, null);\n+        testField1 = testField4;\n+        testField2 = val1;\n+        testField3 = val2;\n+\n+        testField5 = ret;\n+        testField6 = val1;\n+        testField7 = val2;\n+        testField8 = testField4;\n+        return ret;\n+    }\n+\n+    @Run(test = \"test2\")\n+    public void test2_verifier() {\n+        testField4 = testValue1;\n+        MyValueClass1 ret = test2(null);\n+        MyValueClass1 val2 = MyValueClass1.setV4(testValue1, null);\n+        Asserts.assertEquals(testField1, testValue1);\n+        Asserts.assertEquals(testField2, null);\n+        Asserts.assertEquals(testField3, val2);\n+\n+        Asserts.assertEquals(testField5, ret);\n+        Asserts.assertEquals(testField6, null);\n+        Asserts.assertEquals(testField7, val2);\n+        Asserts.assertEquals(testField8, testField4);\n+\n+        testField4 = null;\n+        test2(null);\n+        Asserts.assertEquals(testField1, testField4);\n+        Asserts.assertEquals(testField8, testField4);\n+    }\n+\n+    \/\/ Non-value class Wrapper\n+    static class Test3Wrapper {\n+        MyValueClass1 val;\n+\n+        public Test3Wrapper(MyValueClass1 val) {\n+            this.val = val;\n+        }\n+    }\n+\n+    \/\/ Test scalarization in safepoint debug info and re-allocation on deopt\n+    @Test\n+    \/\/@IR(failOn = {ALLOC, STORE}) TODO: 8353717\n+    public long test3(boolean deopt, boolean b1, boolean b2, Method m) {\n+        MyValueClass1 ret = MyValueClass1.createWithFieldsInline(rI, rL);\n+        if (b1) {\n+            ret = null;\n+        }\n+        if (b2) {\n+            ret = MyValueClass1.setV4(ret, null);\n+        }\n+        Test3Wrapper wrapper = new Test3Wrapper(ret);\n+        if (deopt) {\n+            \/\/ Uncommon trap\n+            TestFramework.deoptimize(m);\n+        }\n+        long res = ((Object)ret != null && (Object)ret.v4 != null) ? ret.hash() : 42;\n+        res += ((Object)wrapper.val != null && (Object)wrapper.val.v4 != null) ? wrapper.val.hash() : 0;\n+        return res;\n+    }\n+\n+    @Run(test = \"test3\")\n+    public void test3_verifier(RunInfo info) {\n+        Asserts.assertEquals(test3(false, false, false, info.getTest()), 2*testValue1.hash());\n+        Asserts.assertEquals(test3(false, true, false, info.getTest()), 42L);\n+        if (!info.isWarmUp()) {\n+            switch (rI % 4) {\n+            case 0:\n+                Asserts.assertEquals(test3(true, false, false, info.getTest()), 2*testValue1.hash());\n+                break;\n+            case 1:\n+                Asserts.assertEquals(test3(true, true, false, info.getTest()), 42L);\n+                break;\n+            case 2:\n+                Asserts.assertEquals(test3(true, false, true, info.getTest()), 42L);\n+                break;\n+            case 3:\n+                try {\n+                    Asserts.assertEquals(test3(true, true, true, info.getTest()), 42L);\n+                    throw new RuntimeException(\"NullPointerException expected\");\n+                } catch (NullPointerException e) {\n+                    \/\/ Expected\n+                }\n+                break;\n+            }\n+        }\n+    }\n+\n+    \/\/ Test scalarization in safepoint debug info and re-allocation on deopt\n+    @Test\n+    @IR(failOn = {ALLOC, STORE})\n+    public boolean test4(boolean deopt, boolean b, Method m) {\n+        MyValueClass1 val = b ? null : MyValueClass1.createWithFieldsInline(rI, rL);\n+        Test3Wrapper wrapper = new Test3Wrapper(val);\n+        if (deopt) {\n+            \/\/ Uncommon trap\n+            TestFramework.deoptimize(m);\n+        }\n+        return (Object)wrapper.val == null;\n+    }\n+\n+    @Run(test = \"test4\")\n+    public void test4_verifier(RunInfo info) {\n+        Asserts.assertTrue(test4(false, true, info.getTest()));\n+        Asserts.assertFalse(test4(false, false, info.getTest()));\n+        if (!info.isWarmUp()) {\n+            switch (rI % 2) {\n+                case 0:\n+                    Asserts.assertTrue(test4(true, true, info.getTest()));\n+                    break;\n+                case 1:\n+                    Asserts.assertFalse(test4(false, false, info.getTest()));\n+                    break;\n+            }\n+        }\n+    }\n+\n+    static value class SmallNullable2 {\n+        float f1;\n+        double f2;\n+\n+        @ForceInline\n+        public SmallNullable2() {\n+            f1 = (float)rL;\n+            f2 = (double)rL;\n+        }\n+    }\n+\n+    static value class SmallNullable1 {\n+        char c;\n+        byte b;\n+        short s;\n+        int i;\n+        SmallNullable2 vt;\n+\n+        @ForceInline\n+        public SmallNullable1(boolean useNull) {\n+            c = (char)rL;\n+            b = (byte)rL;\n+            s = (short)rL;\n+            i = (int)rL;\n+            vt = useNull ? null : new SmallNullable2();\n+        }\n+    }\n+\n+    @DontCompile\n+    public SmallNullable1 test5_interpreted(boolean b1, boolean b2) {\n+        return b1 ? null : new SmallNullable1(b2);\n+    }\n+\n+    @DontInline\n+    public SmallNullable1 test5_compiled(boolean b1, boolean b2) {\n+        return b1 ? null : new SmallNullable1(b2);\n+    }\n+\n+    SmallNullable1 test5_field1;\n+    SmallNullable1 test5_field2;\n+\n+    \/\/ Test scalarization in returns\n+    @Test\n+    public SmallNullable1 test5(boolean b1, boolean b2) {\n+        SmallNullable1 ret = test5_interpreted(b1, b2);\n+        if (b1 != ((Object)ret == null)) {\n+            throw new RuntimeException(\"test5 failed\");\n+        }\n+        test5_field1 = ret;\n+        ret = test5_compiled(b1, b2);\n+        if (b1 != ((Object)ret == null)) {\n+            throw new RuntimeException(\"test5 failed\");\n+        }\n+        test5_field2 = ret;\n+        return ret;\n+    }\n+\n+    @Run(test = \"test5\")\n+    public void test5_verifier() {\n+        SmallNullable1 vt = new SmallNullable1(false);\n+        Asserts.assertEquals(test5(true, false), null);\n+        Asserts.assertEquals(test5_field1, null);\n+        Asserts.assertEquals(test5_field2, null);\n+        Asserts.assertEquals(test5(false, false), vt);\n+        Asserts.assertEquals(test5_field1, vt);\n+        Asserts.assertEquals(test5_field2, vt);\n+        vt = new SmallNullable1(true);\n+        Asserts.assertEquals(test5(true, true), null);\n+        Asserts.assertEquals(test5_field1, null);\n+        Asserts.assertEquals(test5_field2, null);\n+        Asserts.assertEquals(test5(false, true), vt);\n+        Asserts.assertEquals(test5_field1, vt);\n+        Asserts.assertEquals(test5_field2, vt);\n+    }\n+\n+    static value class Empty2 {\n+\n+    }\n+\n+    static value class Empty1 {\n+        Empty2 empty2 = new Empty2();\n+    }\n+\n+    static value class Container {\n+        int x = 0;\n+        Empty1 empty1;\n+        Empty2 empty2 = new Empty2();\n+\n+        @ForceInline\n+        public Container(Empty1 val) {\n+            empty1 = val;\n+        }\n+    }\n+\n+    @DontInline\n+    public static Empty1 test6_helper1(Empty1 vt) {\n+        return vt;\n+    }\n+\n+    @DontInline\n+    public static Empty2 test6_helper2(Empty2 vt) {\n+        return vt;\n+    }\n+\n+    @DontInline\n+    public static Container test6_helper3(Container vt) {\n+        return vt;\n+    }\n+\n+    \/\/ Test scalarization in calls and returns with empty value classes\n+    @Test\n+    public Empty1 test6(Empty1 vt) {\n+        Empty1 empty1 = test6_helper1(vt);\n+        test6_helper2((empty1 != null) ? empty1.empty2 : null);\n+        Container c = test6_helper3(new Container(empty1));\n+        return c.empty1;\n+    }\n+\n+    @Run(test = \"test6\")\n+    @Warmup(10000) \/\/ Warmup to make sure helper methods are compiled as well\n+    public void test6_verifier() {\n+        Asserts.assertEQ(test6(new Empty1()), new Empty1());\n+        Asserts.assertEQ(test6(null), null);\n+    }\n+\n+    @DontCompile\n+    public void test7_helper2(boolean doit) {\n+        if (doit) {\n+            \/\/ uncommon trap\n+            try {\n+                TestFramework.deoptimize(getClass().getDeclaredMethod(\"test7\", boolean.class, boolean.class, boolean.class));\n+            } catch (NoSuchMethodException e) {\n+                throw new RuntimeException(e);\n+            }\n+        }\n+    }\n+\n+    \/\/ Test deoptimization at call return with value object returned in registers\n+    @DontInline\n+    public SmallNullable1 test7_helper1(boolean deopt, boolean b1, boolean b2) {\n+        test7_helper2(deopt);\n+        return b1 ? null : new SmallNullable1(b2);\n+    }\n+\n+    @Test\n+    public SmallNullable1 test7(boolean flag, boolean b1, boolean b2) {\n+        return test7_helper1(flag, b1, b2);\n+    }\n+\n+    @Run(test = \"test7\")\n+    @Warmup(10000)\n+    public void test7_verifier(RunInfo info) {\n+        boolean b1 = ((rI % 3) == 0);\n+        boolean b2 = ((rI % 3) == 1);\n+        SmallNullable1 result = test7(!info.isWarmUp(), b1, b2);\n+        SmallNullable1 vt = new SmallNullable1(b2);\n+        Asserts.assertEQ(result, b1 ? null : vt);\n+    }\n+\n+    \/\/ Test calling a method returning a value class as fields via reflection\n+    @Test\n+    public SmallNullable1 test8(boolean b1, boolean b2) {\n+        return b1 ? null : new SmallNullable1(b2);\n+    }\n+\n+    @Run(test = \"test8\")\n+    public void test8_verifier() throws Exception {\n+        Method m = getClass().getDeclaredMethod(\"test8\", boolean.class, boolean.class);\n+        Asserts.assertEQ(m.invoke(this, false, true), new SmallNullable1(true));\n+        Asserts.assertEQ(m.invoke(this, false, false), new SmallNullable1(false));\n+        Asserts.assertEQ(m.invoke(this, true, false), null);\n+    }\n+\n+    \/\/ Test value classes as arg\/return\n+    @Test\n+    public SmallNullable1 test9(MyValueClass1 vt1, MyValueClass1 vt2, boolean b1, boolean b2) {\n+        Asserts.assertEQ(vt1, testValue1);\n+        if (b1) {\n+            Asserts.assertEQ(vt2, null);\n+        } else {\n+            Asserts.assertEQ(vt2, testValue1);\n+        }\n+        return b1 ? null : new SmallNullable1(b2);\n+    }\n+\n+    @Run(test = \"test9\")\n+    public void test9_verifier() {\n+        Asserts.assertEQ(test9(testValue1, testValue1, false, true), new SmallNullable1(true));\n+        Asserts.assertEQ(test9(testValue1, testValue1, false, false), new SmallNullable1(false));\n+        Asserts.assertEQ(test9(testValue1, null, true, false), null);\n+    }\n+\n+    \/\/ Class.cast\n+    @Test\n+    public Object test10(Class c, MyValueClass1 vt) {\n+        return c.cast(vt);\n+    }\n+\n+    @Run(test = \"test10\")\n+    public void test10_verifier() {\n+        Asserts.assertEQ(test10(MyValueClass1.class, testValue1), testValue1);\n+        Asserts.assertEQ(test10(MyValueClass1.class, null), null);\n+        Asserts.assertEQ(test10(Integer.class, null), null);\n+        try {\n+            test10(MyValueClass2.class, testValue1);\n+            throw new RuntimeException(\"ClassCastException expected\");\n+        } catch (ClassCastException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test acmp\n+    @Test\n+    public boolean test12(MyValueClass1 vt1, MyValueClass1 vt2) {\n+        return vt1 == vt2;\n+    }\n+\n+    @Run(test = \"test12\")\n+    public void test12_verifier() {\n+        Asserts.assertTrue(test12(testValue1, testValue1));\n+        Asserts.assertTrue(test12(null, null));\n+        Asserts.assertFalse(test12(testValue1, null));\n+        Asserts.assertFalse(test12(null, testValue1));\n+        Asserts.assertFalse(test12(testValue1, MyValueClass1.createDefaultInline()));\n+    }\n+\n+    \/\/ Same as test13 but with Object argument\n+    @Test\n+    public boolean test13(Object obj, MyValueClass1 vt2) {\n+        return obj == vt2;\n+    }\n+\n+    @Run(test = \"test13\")\n+    public void test13_verifier() {\n+        Asserts.assertTrue(test13(testValue1, testValue1));\n+        Asserts.assertTrue(test13(null, null));\n+        Asserts.assertFalse(test13(testValue1, null));\n+        Asserts.assertFalse(test13(null, testValue1));\n+        Asserts.assertFalse(test13(testValue1, MyValueClass1.createDefaultInline()));\n+    }\n+\n+    static MyValueClass1 test14_field1;\n+    static MyValueClass1 test14_field2;\n+\n+    \/\/ Test buffer checks emitted by acmp followed by buffering\n+    @Test\n+    public boolean test14(MyValueClass1 vt1, MyValueClass1 vt2) {\n+        \/\/ Trigger buffer checks\n+        if (vt1 != vt2) {\n+            throw new RuntimeException(\"Should be equal\");\n+        }\n+        if (vt2 != vt1) {\n+            throw new RuntimeException(\"Should be equal\");\n+        }\n+        \/\/ Trigger buffering\n+        test14_field1 = vt1;\n+        test14_field2 = vt2;\n+        return vt1 == null;\n+    }\n+\n+    @Run(test = \"test14\")\n+    public void test14_verifier() {\n+        Asserts.assertFalse(test14(testValue1, testValue1));\n+        Asserts.assertTrue(test14(null, null));\n+    }\n+\n+    @DontInline\n+    public MyValueClass1 test15_helper1(MyValueClass1 vt) {\n+        return vt;\n+    }\n+\n+    @ForceInline\n+    public MyValueClass1 test15_helper2(MyValueClass1 vt) {\n+        return test15_helper1(vt);\n+    }\n+\n+    @ForceInline\n+    public MyValueClass1 test15_helper3(Object vt) {\n+        return test15_helper2((MyValueClass1)vt);\n+    }\n+\n+    \/\/ Test that calling convention optimization prevents buffering of arguments\n+    @Test\n+    @IR(applyIf = {\"InlineTypePassFieldsAsArgs\", \"true\"},\n+        counts = {ALLOC_G, \" <= 7\"}) \/\/ 6 MyValueClass2\/MyValueClass2Inline allocations + 1 Integer allocation (if not the default value)\n+    @IR(applyIf = {\"InlineTypePassFieldsAsArgs\", \"false\"},\n+        counts = {ALLOC_G, \" <= 8\"}) \/\/ 1 MyValueClass1 allocation + 6 MyValueClass2\/MyValueClass2Inline allocations + 1 Integer allocation (if not the default value)\n+    public MyValueClass1 test15(MyValueClass1 vt) {\n+        MyValueClass1 res = test15_helper1(vt);\n+        vt = MyValueClass1.createWithFieldsInline(rI, rL);\n+        test15_helper1(vt);\n+        test15_helper2(vt);\n+        test15_helper3(vt);\n+        vt.dontInline(vt);\n+        return res;\n+    }\n+\n+    @Run(test = \"test15\")\n+    public void test15_verifier() {\n+        Asserts.assertEQ(test15(testValue1), testValue1);\n+        Asserts.assertEQ(test15(null), null);\n+    }\n+\n+    @DontInline\n+    public MyValueClass2 test16_helper1(boolean b) {\n+        return b ? null : MyValueClass2.createWithFieldsInline(rI, rD);\n+    }\n+\n+    @ForceInline\n+    public MyValueClass2 test16_helper2() {\n+        return null;\n+    }\n+\n+    @ForceInline\n+    public MyValueClass2 test16_helper3(boolean b) {\n+        return b ? null : MyValueClass2.createWithFieldsInline(rI, rD);\n+    }\n+\n+    \/\/ Test that calling convention optimization prevents buffering of return values\n+    @Test\n+    @IR(applyIf = {\"InlineTypeReturnedAsFields\", \"true\"},\n+        counts = {ALLOC_G, \" <= 1\"}) \/\/ 1 MyValueClass2Inline allocation (if not the default value)\n+    @IR(applyIf = {\"InlineTypeReturnedAsFields\", \"false\"},\n+        counts = {ALLOC_G, \" <= 2\"}) \/\/ 1 MyValueClass2 + 1 MyValueClass2Inline allocation  (if not the default value)\n+    public MyValueClass2 test16(int c, boolean b) {\n+        MyValueClass2 res = null;\n+        if (c == 1) {\n+            res = test16_helper1(b);\n+        } else if (c == 2) {\n+            res = test16_helper2();\n+        } else if (c == 3) {\n+            res = test16_helper3(b);\n+        }\n+        return res;\n+    }\n+\n+    @Run(test = \"test16\")\n+    public void test16_verifier() {\n+        Asserts.assertEQ(test16(0, false), null);\n+        Asserts.assertEQ(test16(1, false).hash(), MyValueClass2.createWithFieldsInline(rI, rD).hash());\n+        Asserts.assertEQ(test16(1, true), null);\n+        Asserts.assertEQ(test16(2, false), null);\n+        Asserts.assertEQ(test16(3, false).hash(), MyValueClass2.createWithFieldsInline(rI, rD).hash());\n+        Asserts.assertEQ(test16(3, true), null);\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyPrimitive17 {\n+        MyValueClass1 nonFlattened;\n+\n+        public MyPrimitive17(MyValueClass1 val) {\n+            this.nonFlattened = val;\n+        }\n+    }\n+\n+    static value class MyValue17 {\n+        @NullRestricted\n+        MyPrimitive17 flattened;\n+\n+        public MyValue17(boolean b) {\n+            this.flattened = new MyPrimitive17(b ? null : testValue1);\n+        }\n+    }\n+\n+    @DontCompile\n+    public MyValue17 test17_interpreted(boolean b1, boolean b2) {\n+        return b1 ? null : new MyValue17(b2);\n+    }\n+\n+    @DontInline\n+    public MyValue17 test17_compiled(boolean b1, boolean b2) {\n+        return b1 ? null : new MyValue17(b2);\n+    }\n+\n+    MyValue17 test17_field1;\n+    MyValue17 test17_field2;\n+\n+    \/\/ Test handling of null when mixing nullable and null-restricted fields\n+    @Test\n+    public MyValue17 test17(boolean b1, boolean b2) {\n+        MyValue17 ret = test17_interpreted(b1, b2);\n+        if (b1 != ((Object)ret == null)) {\n+            throw new RuntimeException(\"test17 failed\");\n+        }\n+        test17_field1 = ret;\n+        ret = test17_compiled(b1, b2);\n+        if (b1 != ((Object)ret == null)) {\n+            throw new RuntimeException(\"test17 failed\");\n+        }\n+        test17_field2 = ret;\n+        return ret;\n+    }\n+\n+    @Run(test = \"test17\")\n+    public void test17_verifier() {\n+        MyValue17 vt = new MyValue17(false);\n+        Asserts.assertEquals(test17(true, false), null);\n+        Asserts.assertEquals(test17_field1, null);\n+        Asserts.assertEquals(test17_field2, null);\n+        Asserts.assertEquals(test17(false, false), vt);\n+        Asserts.assertEquals(test17_field1, vt);\n+        Asserts.assertEquals(test17_field2, vt);\n+        vt = new MyValue17(true);\n+        Asserts.assertEquals(test17(true, true), null);\n+        Asserts.assertEquals(test17_field1, null);\n+        Asserts.assertEquals(test17_field2, null);\n+        Asserts.assertEquals(test17(false, true), vt);\n+        Asserts.assertEquals(test17_field1, vt);\n+        Asserts.assertEquals(test17_field2, vt);\n+    }\n+\n+    \/\/ Uses all registers available for returning values on x86_64\n+    static value class UseAllRegs {\n+        long l1;\n+        long l2;\n+        long l3;\n+        long l4;\n+        long l5;\n+        long l6;\n+        double d1;\n+        double d2;\n+        double d3;\n+        double d4;\n+        double d5;\n+        double d6;\n+        double d7;\n+        double d8;\n+\n+        @ForceInline\n+        public UseAllRegs(long l1, long l2, long l3, long l4, long l5, long l6,\n+                          double d1, double d2, double d3, double d4, double d5, double d6, double d7, double d8) {\n+            this.l1 = l1;\n+            this.l2 = l2;\n+            this.l3 = l3;\n+            this.l4 = l4;\n+            this.l5 = l5;\n+            this.l6 = l6;\n+            this.d1 = d1;\n+            this.d2 = d2;\n+            this.d3 = d3;\n+            this.d4 = d4;\n+            this.d5 = d5;\n+            this.d6 = d6;\n+            this.d7 = d7;\n+            this.d8 = d8;\n+        }\n+    }\n+\n+    @DontInline\n+    public UseAllRegs test18_helper1(UseAllRegs val, long a, long b, long c, long d, long e, long f, long g, long h, long i, long j) {\n+        Asserts.assertEquals(a & b & c & d & e & f & g & h & i & j, 0L);\n+        return val;\n+    }\n+\n+    @DontCompile\n+    public UseAllRegs test18_helper2(UseAllRegs val, long a, long b, long c, long d, long e, long f, long g, long h, long i, long j) {\n+        Asserts.assertEquals(a & b & c & d & e & f & g & h & i & j, 0L);\n+        return val;\n+    }\n+\n+    static boolean test18_b;\n+\n+    \/\/ Methods with no arguments (no stack slots reserved for incoming args)\n+    @DontInline\n+    public static UseAllRegs test18_helper3() {\n+        return test18_b ? null : new UseAllRegs(rL + 1, rL + 2, rL + 3, rL + 4, rL + 5, rL + 6, rL + 7, rL + 8, rL + 9, rL + 10, rL + 11, rL + 12, rL + 13, rL + 14);\n+    }\n+\n+    @DontCompile\n+    public static UseAllRegs test18_helper4() {\n+        return test18_b ? null : test18_helper3();\n+    }\n+\n+    \/\/ Test proper register allocation of isInit projection of a call in C2\n+    @Test\n+    public UseAllRegs test18(boolean b, long val1, long l1, long val2, long l2, long val3, long l3, long val4, long l4, long val5, long l5, long val6, long l6,\n+                             long val7, double d1, long val8, double d2, long val9, double d3, long val10, double d4, long val11, double d5, long val12, double d6, long val13, double d7, long val14, double d8, long val15) {\n+        Asserts.assertEquals(val1, rL);\n+        Asserts.assertEquals(val2, rL);\n+        Asserts.assertEquals(val3, rL);\n+        Asserts.assertEquals(val4, rL);\n+        Asserts.assertEquals(val5, rL);\n+        Asserts.assertEquals(val6, rL);\n+        Asserts.assertEquals(val7, rL);\n+        Asserts.assertEquals(val8, rL);\n+        Asserts.assertEquals(val9, rL);\n+        Asserts.assertEquals(val10, rL);\n+        Asserts.assertEquals(val11, rL);\n+        Asserts.assertEquals(val12, rL);\n+        Asserts.assertEquals(val13, rL);\n+        Asserts.assertEquals(val14, rL);\n+        Asserts.assertEquals(val15, rL);\n+        UseAllRegs val = b ? null : new UseAllRegs(l1, l2, l3, l4, l5, l6, d1, d2, d3, d4, d5, d6, d7, d8);\n+        val = test18_helper1(val, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n+        val = test18_helper2(val, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n+        Asserts.assertEquals(val1, rL);\n+        Asserts.assertEquals(val2, rL);\n+        Asserts.assertEquals(val3, rL);\n+        Asserts.assertEquals(val4, rL);\n+        Asserts.assertEquals(val5, rL);\n+        Asserts.assertEquals(val6, rL);\n+        Asserts.assertEquals(val7, rL);\n+        Asserts.assertEquals(val8, rL);\n+        Asserts.assertEquals(val9, rL);\n+        Asserts.assertEquals(val10, rL);\n+        Asserts.assertEquals(val11, rL);\n+        Asserts.assertEquals(val12, rL);\n+        Asserts.assertEquals(val13, rL);\n+        Asserts.assertEquals(val14, rL);\n+        Asserts.assertEquals(val15, rL);\n+        Asserts.assertEquals(test18_helper3(), val);\n+        Asserts.assertEquals(test18_helper4(), val);\n+        return val;\n+    }\n+\n+    @Run(test = \"test18\")\n+    public void test18_verifier() {\n+        UseAllRegs val = new UseAllRegs(rL + 1, rL + 2, rL + 3, rL + 4, rL + 5, rL + 6, rL + 7, rL + 8, rL + 9, rL + 10, rL + 11, rL + 12, rL + 13, rL + 14);\n+        test18_b = false;\n+        Asserts.assertEquals(test18(false, rL, rL + 1, rL, rL + 2, rL, rL + 3, rL, rL + 4, rL, rL + 5, rL, rL + 6,\n+                                    rL, rL + 7, rL, rL + 8, rL, rL + 9, rL, rL + 10, rL, rL + 11, rL, rL + 12, rL, rL + 13, rL, rL + 14, rL), val);\n+        test18_b = true;\n+        Asserts.assertEquals(test18(true, rL, rL + 1, rL, rL + 2, rL, rL + 3, rL, rL + 4, rL, rL + 5, rL, rL + 6,\n+                                    rL, rL + 7, rL, rL + 8, rL, rL + 9, rL, rL + 10, rL, rL + 11, rL, rL + 12, rL, rL + 13, rL, rL + 14, rL), null);\n+    }\n+\n+    @DontInline\n+    static public UseAllRegs test19_helper() {\n+        return new UseAllRegs(rL + 1, rL + 2, rL + 3, rL + 4, rL + 5, rL + 6, rL + 7, rL + 8, rL + 9, rL + 10, rL + 11, rL + 12, rL + 13, rL + 14);\n+    }\n+\n+    \/\/ Test proper register allocation of isInit projection of a call in C2\n+    @Test\n+    static public void test19(long a, long b, long c, long d, long e, long f) {\n+        if (test19_helper() == null) {\n+            throw new RuntimeException(\"test19 failed: Unexpected null\");\n+        }\n+        if ((a & b & c & d & e & f) != 0) {\n+            throw new RuntimeException(\"test19 failed: Unexpected argument values\");\n+        }\n+    }\n+\n+    @Run(test = \"test19\")\n+    public void test19_verifier() {\n+        test19(0, 0, 0, 0, 0, 0);\n+    }\n+\n+    \/\/ Uses almost all registers available for returning values on x86_64\n+    static value class UseAlmostAllRegs {\n+        long l1;\n+        long l2;\n+        long l3;\n+        long l4;\n+        long l5;\n+        double d1;\n+        double d2;\n+        double d3;\n+        double d4;\n+        double d5;\n+        double d6;\n+        double d7;\n+\n+        @ForceInline\n+        public UseAlmostAllRegs(long l1, long l2, long l3, long l4, long l5,\n+                                double d1, double d2, double d3, double d4, double d5, double d6, double d7) {\n+            this.l1 = l1;\n+            this.l2 = l2;\n+            this.l3 = l3;\n+            this.l4 = l4;\n+            this.l5 = l5;\n+            this.d1 = d1;\n+            this.d2 = d2;\n+            this.d3 = d3;\n+            this.d4 = d4;\n+            this.d5 = d5;\n+            this.d6 = d6;\n+            this.d7 = d7;\n+        }\n+    }\n+\n+    @DontInline\n+    public UseAlmostAllRegs test20_helper1(UseAlmostAllRegs val, long a, long b, long c, long d, long e, long f, long g, long h, long i, long j) {\n+        Asserts.assertEquals(a & b & c & d & e & f & g & h & i & j, 0L);\n+        return val;\n+    }\n+\n+    @DontCompile\n+    public UseAlmostAllRegs test20_helper2(UseAlmostAllRegs val, long a, long b, long c, long d, long e, long f, long g, long h, long i, long j) {\n+        Asserts.assertEquals(a & b & c & d & e & f & g & h & i & j, 0L);\n+        return val;\n+    }\n+\n+    static boolean test20_b;\n+\n+    \/\/ Methods with no arguments (no stack slots reserved for incoming args)\n+    @DontInline\n+    public static UseAlmostAllRegs test20_helper3() {\n+        return test20_b ? null : new UseAlmostAllRegs(rL + 1, rL + 2, rL + 3, rL + 4, rL + 5, rL + 6, rL + 7, rL + 8, rL + 9, rL + 10, rL + 11, rL + 12);\n+    }\n+\n+    @DontCompile\n+    public static UseAlmostAllRegs test20_helper4() {\n+        return test20_b ? null : test20_helper3();\n+    }\n+\n+    \/\/ Test proper register allocation of isInit projection of a call in C2\n+    @Test\n+    public UseAlmostAllRegs test20(boolean b, long val1, long l1, long val2, long l2, long val3, long l3, long val4, long l4, long val5, long l5, long val6,\n+                                   long val7, double d1, long val8, double d2, long val9, double d3, long val10, double d4, long val11, double d5, long val12, double d6, long val13, double d7, long val14, long val15) {\n+        Asserts.assertEquals(val1, rL);\n+        Asserts.assertEquals(val2, rL);\n+        Asserts.assertEquals(val3, rL);\n+        Asserts.assertEquals(val4, rL);\n+        Asserts.assertEquals(val5, rL);\n+        Asserts.assertEquals(val6, rL);\n+        Asserts.assertEquals(val7, rL);\n+        Asserts.assertEquals(val8, rL);\n+        Asserts.assertEquals(val9, rL);\n+        Asserts.assertEquals(val10, rL);\n+        Asserts.assertEquals(val11, rL);\n+        Asserts.assertEquals(val12, rL);\n+        Asserts.assertEquals(val13, rL);\n+        Asserts.assertEquals(val14, rL);\n+        Asserts.assertEquals(val15, rL);\n+        UseAlmostAllRegs val = b ? null : new UseAlmostAllRegs(l1, l2, l3, l4, l5, d1, d2, d3, d4, d5, d6, d7);\n+        val = test20_helper1(val, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n+        val = test20_helper2(val, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n+        Asserts.assertEquals(val1, rL);\n+        Asserts.assertEquals(val2, rL);\n+        Asserts.assertEquals(val3, rL);\n+        Asserts.assertEquals(val4, rL);\n+        Asserts.assertEquals(val5, rL);\n+        Asserts.assertEquals(val6, rL);\n+        Asserts.assertEquals(val7, rL);\n+        Asserts.assertEquals(val8, rL);\n+        Asserts.assertEquals(val9, rL);\n+        Asserts.assertEquals(val10, rL);\n+        Asserts.assertEquals(val11, rL);\n+        Asserts.assertEquals(val12, rL);\n+        Asserts.assertEquals(val13, rL);\n+        Asserts.assertEquals(val14, rL);\n+        Asserts.assertEquals(val15, rL);\n+        Asserts.assertEquals(test20_helper3(), val);\n+        Asserts.assertEquals(test20_helper4(), val);\n+        return val;\n+    }\n+\n+    @Run(test = \"test20\")\n+    public void test20_verifier() {\n+        UseAlmostAllRegs val = new UseAlmostAllRegs(rL + 1, rL + 2, rL + 3, rL + 4, rL + 5, rL + 6, rL + 7, rL + 8, rL + 9, rL + 10, rL + 11, rL + 12);\n+        test20_b = false;\n+        Asserts.assertEquals(test20(false, rL, rL + 1, rL, rL + 2, rL, rL + 3, rL, rL + 4, rL, rL + 5, rL,\n+                                    rL, rL + 6, rL, rL + 7, rL, rL + 8, rL, rL + 9, rL, rL + 10, rL, rL + 11, rL, rL + 12, rL, rL), val);\n+        test20_b = true;\n+        Asserts.assertEquals(test20(true, rL, rL + 1, rL, rL + 2, rL, rL + 3, rL, rL + 4, rL, rL + 5, rL,\n+                                    rL, rL + 6, rL, rL + 7, rL, rL + 8, rL, rL + 9, rL, rL + 10, rL, rL + 11, rL, rL + 12, rL, rL), null);\n+    }\n+\n+    @DontInline\n+    static public UseAlmostAllRegs test21_helper() {\n+        return new UseAlmostAllRegs(rL + 1, rL + 2, rL + 3, rL + 4, rL + 5, rL + 6, rL + 7, rL + 8, rL + 9, rL + 10, rL + 11, rL + 12);\n+    }\n+\n+    \/\/ Test proper register allocation of isInit projection of a call in C2\n+    @Test\n+    static public void test21(long a, long b, long c, long d, long e, long f) {\n+        if (test21_helper() == null) {\n+            throw new RuntimeException(\"test21 failed: Unexpected null\");\n+        }\n+        if ((a & b & c & d & e & f) != 0) {\n+            throw new RuntimeException(\"test21 failed: Unexpected argument values\");\n+        }\n+    }\n+\n+    @Run(test = \"test21\")\n+    public void test21_verifier() {\n+        test21(0, 0, 0, 0, 0, 0);\n+    }\n+\n+    static value class ManyOopsValue {\n+        Integer i1 = 1;\n+        Integer i2 = 2;\n+        Integer i3 = 3;\n+        Integer i4 = 4;\n+        Integer i5 = 5;\n+        Integer i6 = 6;\n+        Integer i7 = 7;\n+        Integer i8 = 8;\n+        Integer i9 = 9;\n+        Integer i10 = 10;\n+        Integer i11 = 11;\n+        Integer i12 = 12;\n+        Integer i13 = 13;\n+        Integer i14 = 14;\n+        Integer i15 = 15;\n+\n+        @DontInline\n+        public int sum() {\n+            return i1 + i2 + i3 + i4 + i5 + i6 + i7 + i8 + i9 + i10 + i11 + i12 + i13 + i14 + i15;\n+        }\n+    }\n+\n+    \/\/ Verify that C2 scratch buffer size is large enough to hold many GC barriers used by the entry points\n+    @Test\n+    static public int test22(ManyOopsValue val) {\n+        return val.sum();\n+    }\n+\n+    @Run(test = \"test22\")\n+    @Warmup(10_000)\n+    public void test22_verifier() {\n+        Asserts.assertEquals(test22(new ManyOopsValue()), 120);\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestValueClasses.java","additions":960,"deletions":0,"binary":false,"changes":960,"status":"added"},{"patch":"@@ -521,0 +521,5 @@\n+java\/lang\/ModuleLayer\/LayerControllerTest.java                  8337048 generic-all\n+java\/lang\/ModuleLayer\/BasicLayerTest.java                       8337048 generic-all\n+\n+java\/lang\/Thread\/virtual\/stress\/Skynet.java#default             8342977 generic-all\n+\n@@ -721,0 +726,4 @@\n+com\/sun\/jdi\/cds\/CDSBreakpointTest.java                          8304168 generic-all\n+com\/sun\/jdi\/cds\/CDSDeleteAllBkptsTest.java                      8304168 generic-all\n+com\/sun\/jdi\/cds\/CDSFieldWatchpoints.java                        8304168 generic-all\n+\n@@ -766,0 +775,6 @@\n+jdk\/classfile\/SwapTest.java                                     8308778 generic-all\n+jdk\/classfile\/LowAdaptTest.java                                 8308778 generic-all\n+jdk\/classfile\/BuilderBlockTest.java                             8308778 generic-all\n+jdk\/classfile\/BuilderTryCatchTest.java                          8308778 generic-all\n+jdk\/classfile\/PrimitiveClassConstantTest.java                   8310649 generic-all\n+\n@@ -812,0 +827,4 @@\n+\n+# valhalla\n+jdk\/jfr\/event\/runtime\/TestSyncOnValueBasedClassEvent.java 8328777 generic-all\n+\n","filename":"test\/jdk\/ProblemList.txt","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"}]}