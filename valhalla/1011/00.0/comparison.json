{"files":[{"patch":"@@ -96,1 +96,1 @@\n-    entry_frame_after_call_words                     = 27,\n+    entry_frame_after_call_words                     = 29,\n","filename":"src\/hotspot\/cpu\/aarch64\/frame_aarch64.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -389,1 +389,1 @@\n-    __ movptr(rscratch1, (uintptr_t) StubRoutines::aarch64::method_entry_barrier());\n+    __ lea(rscratch1, RuntimeAddress(StubRoutines::method_entry_barrier()));\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -579,0 +579,13 @@\n+  \/\/ FPCR : op1 == 011\n+  \/\/        CRn == 0100\n+  \/\/        CRm == 0100\n+  \/\/        op2 == 000\n+\n+  inline void get_fpcr(Register reg) {\n+    mrs(0b11, 0b0100, 0b0100, 0b000, reg);\n+  }\n+\n+  inline void set_fpcr(Register reg) {\n+    msr(0b011, 0b0100, 0b0100, 0b000, reg);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -1091,2 +1091,0 @@\n-                                         VMRegPair *regs2,\n-  assert(regs2 == nullptr, \"not needed on AArch64\");\n@@ -1188,1 +1186,0 @@\n-                                         VMRegPair *regs2,\n@@ -1191,1 +1188,1 @@\n-  int result = c_calling_convention_priv(sig_bt, regs, regs2, total_args_passed);\n+  int result = c_calling_convention_priv(sig_bt, regs, total_args_passed);\n@@ -1748,1 +1745,1 @@\n-  out_arg_slots = c_calling_convention_priv(out_sig_bt, out_regs, nullptr, total_c_args);\n+  out_arg_slots = c_calling_convention_priv(out_sig_bt, out_regs, total_c_args);\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":2,"deletions":5,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -144,1 +144,2 @@\n-  \/\/ -27 [ argument word 1      ]\n+  \/\/ -29 [ argument word 1      ]\n+  \/\/ -28 [ saved Floating-point Control Register ]\n@@ -176,1 +177,1 @@\n-    sp_after_call_off = -26,\n+    sp_after_call_off  = -28,\n@@ -178,0 +179,1 @@\n+    fpcr_off           = sp_after_call_off,\n@@ -207,1 +209,1 @@\n-    const Address sp_after_call(rfp, sp_after_call_off * wordSize);\n+    const Address sp_after_call (rfp, sp_after_call_off * wordSize);\n@@ -209,0 +211,1 @@\n+    const Address fpcr_save     (rfp, fpcr_off           * wordSize);\n@@ -257,0 +260,8 @@\n+    __ get_fpcr(rscratch1);\n+    __ str(rscratch1, fpcr_save);\n+    \/\/ Set FPCR to the state we need. We do want Round to Nearest. We\n+    \/\/ don't want non-IEEE rounding modes or floating-point traps.\n+    __ bfi(rscratch1, zr, 22, 4); \/\/ Clear DN, FZ, and Rmode\n+    __ bfi(rscratch1, zr, 8, 5);  \/\/ Clear exception-control bits (8-12)\n+    __ set_fpcr(rscratch1);\n+\n@@ -377,0 +388,4 @@\n+    \/\/ restore fpcr\n+    __ ldr(rscratch1,  fpcr_save);\n+    __ set_fpcr(rscratch1);\n+\n@@ -8542,1 +8557,1 @@\n-      StubRoutines::aarch64::_method_entry_barrier = generate_method_entry_barrier();\n+      StubRoutines::_method_entry_barrier = generate_method_entry_barrier();\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":19,"deletions":4,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -420,1 +420,1 @@\n-    __ call(RuntimeAddress(StubRoutines::x86::method_entry_barrier()));\n+    __ call(RuntimeAddress(StubRoutines::method_entry_barrier()));\n@@ -441,1 +441,1 @@\n-  __ call(RuntimeAddress(StubRoutines::x86::method_entry_barrier()));\n+  __ call(RuntimeAddress(StubRoutines::method_entry_barrier()));\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetAssembler_x86.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1885,0 +1885,86 @@\n+void MacroAssembler::cvtss2sd(XMMRegister dst, XMMRegister src) {\n+  if ((UseAVX > 0) && (dst != src)) {\n+    xorpd(dst, dst);\n+  }\n+  Assembler::cvtss2sd(dst, src);\n+}\n+\n+void MacroAssembler::cvtss2sd(XMMRegister dst, Address src) {\n+  if (UseAVX > 0) {\n+    xorpd(dst, dst);\n+  }\n+  Assembler::cvtss2sd(dst, src);\n+}\n+\n+void MacroAssembler::cvtsd2ss(XMMRegister dst, XMMRegister src) {\n+  if ((UseAVX > 0) && (dst != src)) {\n+    xorps(dst, dst);\n+  }\n+  Assembler::cvtsd2ss(dst, src);\n+}\n+\n+void MacroAssembler::cvtsd2ss(XMMRegister dst, Address src) {\n+  if (UseAVX > 0) {\n+    xorps(dst, dst);\n+  }\n+  Assembler::cvtsd2ss(dst, src);\n+}\n+\n+void MacroAssembler::cvtsi2sdl(XMMRegister dst, Register src) {\n+  if (UseAVX > 0) {\n+    xorpd(dst, dst);\n+  }\n+  Assembler::cvtsi2sdl(dst, src);\n+}\n+\n+void MacroAssembler::cvtsi2sdl(XMMRegister dst, Address src) {\n+  if (UseAVX > 0) {\n+    xorpd(dst, dst);\n+  }\n+  Assembler::cvtsi2sdl(dst, src);\n+}\n+\n+void MacroAssembler::cvtsi2ssl(XMMRegister dst, Register src) {\n+  if (UseAVX > 0) {\n+    xorps(dst, dst);\n+  }\n+  Assembler::cvtsi2ssl(dst, src);\n+}\n+\n+void MacroAssembler::cvtsi2ssl(XMMRegister dst, Address src) {\n+  if (UseAVX > 0) {\n+    xorps(dst, dst);\n+  }\n+  Assembler::cvtsi2ssl(dst, src);\n+}\n+\n+#ifdef _LP64\n+void MacroAssembler::cvtsi2sdq(XMMRegister dst, Register src) {\n+  if (UseAVX > 0) {\n+    xorpd(dst, dst);\n+  }\n+  Assembler::cvtsi2sdq(dst, src);\n+}\n+\n+void MacroAssembler::cvtsi2sdq(XMMRegister dst, Address src) {\n+  if (UseAVX > 0) {\n+    xorpd(dst, dst);\n+  }\n+  Assembler::cvtsi2sdq(dst, src);\n+}\n+\n+void MacroAssembler::cvtsi2ssq(XMMRegister dst, Register src) {\n+  if (UseAVX > 0) {\n+    xorps(dst, dst);\n+  }\n+  Assembler::cvtsi2ssq(dst, src);\n+}\n+\n+void MacroAssembler::cvtsi2ssq(XMMRegister dst, Address src) {\n+  if (UseAVX > 0) {\n+    xorps(dst, dst);\n+  }\n+  Assembler::cvtsi2ssq(dst, src);\n+}\n+#endif  \/\/ _LP64\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":86,"deletions":0,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -863,0 +863,17 @@\n+\n+  \/\/ cvt instructions\n+  void cvtss2sd(XMMRegister dst, XMMRegister src);\n+  void cvtss2sd(XMMRegister dst, Address src);\n+  void cvtsd2ss(XMMRegister dst, XMMRegister src);\n+  void cvtsd2ss(XMMRegister dst, Address src);\n+  void cvtsi2sdl(XMMRegister dst, Register src);\n+  void cvtsi2sdl(XMMRegister dst, Address src);\n+  void cvtsi2ssl(XMMRegister dst, Register src);\n+  void cvtsi2ssl(XMMRegister dst, Address src);\n+#ifdef _LP64\n+  void cvtsi2sdq(XMMRegister dst, Register src);\n+  void cvtsi2sdq(XMMRegister dst, Address src);\n+  void cvtsi2ssq(XMMRegister dst, Register src);\n+  void cvtsi2ssq(XMMRegister dst, Address src);\n+#endif\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -997,2 +997,1 @@\n-                                         VMRegPair *regs2,\n-  assert(regs2 == nullptr, \"not needed on x86\");\n+\n@@ -1386,1 +1385,1 @@\n-  out_arg_slots = c_calling_convention(out_sig_bt, out_regs, nullptr, total_c_args);\n+  out_arg_slots = c_calling_convention(out_sig_bt, out_regs, total_c_args);\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1333,2 +1333,1 @@\n-                                         VMRegPair *regs2,\n-  assert(regs2 == nullptr, \"not needed on x86\");\n+\n@@ -2084,1 +2083,1 @@\n-  out_arg_slots = c_calling_convention(out_sig_bt, out_regs, nullptr, total_c_args);\n+  out_arg_slots = c_calling_convention(out_sig_bt, out_regs, total_c_args);\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -4227,1 +4227,1 @@\n-    StubRoutines::x86::_method_entry_barrier = generate_method_entry_barrier();\n+    StubRoutines::_method_entry_barrier = generate_method_entry_barrier();\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -9029,1 +9029,1 @@\n-instruct vmask_gen(kReg dst, rRegL len, rRegL temp) %{\n+instruct vmask_gen(kReg dst, rRegL len, rRegL temp, rFlagsReg cr) %{\n@@ -9031,1 +9031,1 @@\n-  effect(TEMP temp);\n+  effect(TEMP temp, KILL cr);\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -526,181 +526,0 @@\n-\/\/ EMIT_RM()\n-void emit_rm(CodeBuffer &cbuf, int f1, int f2, int f3) {\n-  unsigned char c = (unsigned char) ((f1 << 6) | (f2 << 3) | f3);\n-  cbuf.insts()->emit_int8(c);\n-}\n-\n-\/\/ EMIT_CC()\n-void emit_cc(CodeBuffer &cbuf, int f1, int f2) {\n-  unsigned char c = (unsigned char) (f1 | f2);\n-  cbuf.insts()->emit_int8(c);\n-}\n-\n-\/\/ EMIT_OPCODE()\n-void emit_opcode(CodeBuffer &cbuf, int code) {\n-  cbuf.insts()->emit_int8((unsigned char) code);\n-}\n-\n-\/\/ EMIT_OPCODE() w\/ relocation information\n-void emit_opcode(CodeBuffer &cbuf,\n-                 int code, relocInfo::relocType reloc, int offset, int format)\n-{\n-  cbuf.relocate(cbuf.insts_mark() + offset, reloc, format);\n-  emit_opcode(cbuf, code);\n-}\n-\n-\/\/ EMIT_D8()\n-void emit_d8(CodeBuffer &cbuf, int d8) {\n-  cbuf.insts()->emit_int8((unsigned char) d8);\n-}\n-\n-\/\/ EMIT_D16()\n-void emit_d16(CodeBuffer &cbuf, int d16) {\n-  cbuf.insts()->emit_int16(d16);\n-}\n-\n-\/\/ EMIT_D32()\n-void emit_d32(CodeBuffer &cbuf, int d32) {\n-  cbuf.insts()->emit_int32(d32);\n-}\n-\n-\/\/ EMIT_D64()\n-void emit_d64(CodeBuffer &cbuf, int64_t d64) {\n-  cbuf.insts()->emit_int64(d64);\n-}\n-\n-\/\/ emit 32 bit value and construct relocation entry from relocInfo::relocType\n-void emit_d32_reloc(CodeBuffer& cbuf,\n-                    int d32,\n-                    relocInfo::relocType reloc,\n-                    int format)\n-{\n-  assert(reloc != relocInfo::external_word_type, \"use 2-arg emit_d32_reloc\");\n-  cbuf.relocate(cbuf.insts_mark(), reloc, format);\n-  cbuf.insts()->emit_int32(d32);\n-}\n-\n-\/\/ emit 32 bit value and construct relocation entry from RelocationHolder\n-void emit_d32_reloc(CodeBuffer& cbuf, int d32, RelocationHolder const& rspec, int format) {\n-#ifdef ASSERT\n-  if (rspec.reloc()->type() == relocInfo::oop_type &&\n-      d32 != 0 && d32 != (intptr_t) Universe::non_oop_word()) {\n-    assert(Universe::heap()->is_in((address)(intptr_t)d32), \"should be real oop\");\n-    assert(oopDesc::is_oop(cast_to_oop((intptr_t)d32)), \"cannot embed broken oops in code\");\n-  }\n-#endif\n-  cbuf.relocate(cbuf.insts_mark(), rspec, format);\n-  cbuf.insts()->emit_int32(d32);\n-}\n-\n-void emit_d32_reloc(CodeBuffer& cbuf, address addr) {\n-  address next_ip = cbuf.insts_end() + 4;\n-  emit_d32_reloc(cbuf, (int) (addr - next_ip),\n-                 external_word_Relocation::spec(addr),\n-                 RELOC_DISP32);\n-}\n-\n-\n-\/\/ emit 64 bit value and construct relocation entry from relocInfo::relocType\n-void emit_d64_reloc(CodeBuffer& cbuf, int64_t d64, relocInfo::relocType reloc, int format) {\n-  cbuf.relocate(cbuf.insts_mark(), reloc, format);\n-  cbuf.insts()->emit_int64(d64);\n-}\n-\n-\/\/ emit 64 bit value and construct relocation entry from RelocationHolder\n-void emit_d64_reloc(CodeBuffer& cbuf, int64_t d64, RelocationHolder const& rspec, int format) {\n-#ifdef ASSERT\n-  if (rspec.reloc()->type() == relocInfo::oop_type &&\n-      d64 != 0 && d64 != (int64_t) Universe::non_oop_word()) {\n-    assert(Universe::heap()->is_in((address)d64), \"should be real oop\");\n-    assert(oopDesc::is_oop(cast_to_oop(d64)), \"cannot embed broken oops in code\");\n-  }\n-#endif\n-  cbuf.relocate(cbuf.insts_mark(), rspec, format);\n-  cbuf.insts()->emit_int64(d64);\n-}\n-\n-\/\/ Access stack slot for load or store\n-void store_to_stackslot(CodeBuffer &cbuf, int opcode, int rm_field, int disp)\n-{\n-  emit_opcode(cbuf, opcode);                  \/\/ (e.g., FILD   [RSP+src])\n-  if (-0x80 <= disp && disp < 0x80) {\n-    emit_rm(cbuf, 0x01, rm_field, RSP_enc);   \/\/ R\/M byte\n-    emit_rm(cbuf, 0x00, RSP_enc, RSP_enc);    \/\/ SIB byte\n-    emit_d8(cbuf, disp);     \/\/ Displacement  \/\/ R\/M byte\n-  } else {\n-    emit_rm(cbuf, 0x02, rm_field, RSP_enc);   \/\/ R\/M byte\n-    emit_rm(cbuf, 0x00, RSP_enc, RSP_enc);    \/\/ SIB byte\n-    emit_d32(cbuf, disp);     \/\/ Displacement \/\/ R\/M byte\n-  }\n-}\n-\n-   \/\/ rRegI ereg, memory mem) %{    \/\/ emit_reg_mem\n-void encode_RegMem(CodeBuffer &cbuf,\n-                   int reg,\n-                   int base, int index, int scale, int disp, relocInfo::relocType disp_reloc)\n-{\n-  assert(disp_reloc == relocInfo::none, \"cannot have disp\");\n-  int regenc = reg & 7;\n-  int baseenc = base & 7;\n-  int indexenc = index & 7;\n-\n-  \/\/ There is no index & no scale, use form without SIB byte\n-  if (index == 0x4 && scale == 0 && base != RSP_enc && base != R12_enc) {\n-    \/\/ If no displacement, mode is 0x0; unless base is [RBP] or [R13]\n-    if (disp == 0 && base != RBP_enc && base != R13_enc) {\n-      emit_rm(cbuf, 0x0, regenc, baseenc); \/\/ *\n-    } else if (-0x80 <= disp && disp < 0x80 && disp_reloc == relocInfo::none) {\n-      \/\/ If 8-bit displacement, mode 0x1\n-      emit_rm(cbuf, 0x1, regenc, baseenc); \/\/ *\n-      emit_d8(cbuf, disp);\n-    } else {\n-      \/\/ If 32-bit displacement\n-      if (base == -1) { \/\/ Special flag for absolute address\n-        emit_rm(cbuf, 0x0, regenc, 0x5); \/\/ *\n-        if (disp_reloc != relocInfo::none) {\n-          emit_d32_reloc(cbuf, disp, relocInfo::oop_type, RELOC_DISP32);\n-        } else {\n-          emit_d32(cbuf, disp);\n-        }\n-      } else {\n-        \/\/ Normal base + offset\n-        emit_rm(cbuf, 0x2, regenc, baseenc); \/\/ *\n-        if (disp_reloc != relocInfo::none) {\n-          emit_d32_reloc(cbuf, disp, relocInfo::oop_type, RELOC_DISP32);\n-        } else {\n-          emit_d32(cbuf, disp);\n-        }\n-      }\n-    }\n-  } else {\n-    \/\/ Else, encode with the SIB byte\n-    \/\/ If no displacement, mode is 0x0; unless base is [RBP] or [R13]\n-    if (disp == 0 && base != RBP_enc && base != R13_enc) {\n-      \/\/ If no displacement\n-      emit_rm(cbuf, 0x0, regenc, 0x4); \/\/ *\n-      emit_rm(cbuf, scale, indexenc, baseenc);\n-    } else {\n-      if (-0x80 <= disp && disp < 0x80 && disp_reloc == relocInfo::none) {\n-        \/\/ If 8-bit displacement, mode 0x1\n-        emit_rm(cbuf, 0x1, regenc, 0x4); \/\/ *\n-        emit_rm(cbuf, scale, indexenc, baseenc);\n-        emit_d8(cbuf, disp);\n-      } else {\n-        \/\/ If 32-bit displacement\n-        if (base == 0x04 ) {\n-          emit_rm(cbuf, 0x2, regenc, 0x4);\n-          emit_rm(cbuf, scale, indexenc, 0x04); \/\/ XXX is this valid???\n-        } else {\n-          emit_rm(cbuf, 0x2, regenc, 0x4);\n-          emit_rm(cbuf, scale, indexenc, baseenc); \/\/ *\n-        }\n-        if (disp_reloc != relocInfo::none) {\n-          emit_d32_reloc(cbuf, disp, relocInfo::oop_type, RELOC_DISP32);\n-        } else {\n-          emit_d32(cbuf, disp);\n-        }\n-      }\n-    }\n-  }\n-}\n-\n@@ -1612,13 +1431,3 @@\n-  if (offset >= 0x80) {\n-    emit_opcode(cbuf, reg < 8 ? Assembler::REX_W : Assembler::REX_WR);\n-    emit_opcode(cbuf, 0x8D); \/\/ LEA  reg,[SP+offset]\n-    emit_rm(cbuf, 0x2, reg & 7, 0x04);\n-    emit_rm(cbuf, 0x0, 0x04, RSP_enc);\n-    emit_d32(cbuf, offset);\n-  } else {\n-    emit_opcode(cbuf, reg < 8 ? Assembler::REX_W : Assembler::REX_WR);\n-    emit_opcode(cbuf, 0x8D); \/\/ LEA  reg,[SP+offset]\n-    emit_rm(cbuf, 0x1, reg & 7, 0x04);\n-    emit_rm(cbuf, 0x0, 0x04, RSP_enc);\n-    emit_d8(cbuf, offset);\n-  }\n+\n+  MacroAssembler masm(&cbuf);\n+  masm.lea(as_Register(reg), Address(rsp, offset));\n@@ -1865,54 +1674,0 @@\n-  \/\/ Build emit functions for each basic byte or larger field in the\n-  \/\/ intel encoding scheme (opcode, rm, sib, immediate), and call them\n-  \/\/ from C++ code in the enc_class source block.  Emit functions will\n-  \/\/ live in the main source block for now.  In future, we can\n-  \/\/ generalize this by adding a syntax that specifies the sizes of\n-  \/\/ fields in an order, so that the adlc can build the emit functions\n-  \/\/ automagically\n-\n-  \/\/ Emit primary opcode\n-  enc_class OpcP\n-  %{\n-    emit_opcode(cbuf, $primary);\n-  %}\n-\n-  \/\/ Emit secondary opcode\n-  enc_class OpcS\n-  %{\n-    emit_opcode(cbuf, $secondary);\n-  %}\n-\n-  \/\/ Emit tertiary opcode\n-  enc_class OpcT\n-  %{\n-    emit_opcode(cbuf, $tertiary);\n-  %}\n-\n-  \/\/ Emit opcode directly\n-  enc_class Opcode(immI d8)\n-  %{\n-    emit_opcode(cbuf, $d8$$constant);\n-  %}\n-\n-  \/\/ Emit size prefix\n-  enc_class SizePrefix\n-  %{\n-    emit_opcode(cbuf, 0x66);\n-  %}\n-\n-  enc_class reg(rRegI reg)\n-  %{\n-    emit_rm(cbuf, 0x3, 0, $reg$$reg & 7);\n-  %}\n-\n-  enc_class reg_reg(rRegI dst, rRegI src)\n-  %{\n-    emit_rm(cbuf, 0x3, $dst$$reg & 7, $src$$reg & 7);\n-  %}\n-\n-  enc_class opc_reg_reg(immI opcode, rRegI dst, rRegI src)\n-  %{\n-    emit_opcode(cbuf, $opcode$$constant);\n-    emit_rm(cbuf, 0x3, $dst$$reg & 7, $src$$reg & 7);\n-  %}\n-\n@@ -2036,91 +1791,0 @@\n-  \/\/ Opcde enc_class for 8\/32 bit immediate instructions with sign-extension\n-  enc_class OpcSE(immI imm)\n-  %{\n-    \/\/ Emit primary opcode and set sign-extend bit\n-    \/\/ Check for 8-bit immediate, and set sign extend bit in opcode\n-    if (-0x80 <= $imm$$constant && $imm$$constant < 0x80) {\n-      emit_opcode(cbuf, $primary | 0x02);\n-    } else {\n-      \/\/ 32-bit immediate\n-      emit_opcode(cbuf, $primary);\n-    }\n-  %}\n-\n-  enc_class OpcSErm(rRegI dst, immI imm)\n-  %{\n-    \/\/ OpcSEr\/m\n-    int dstenc = $dst$$reg;\n-    if (dstenc >= 8) {\n-      emit_opcode(cbuf, Assembler::REX_B);\n-      dstenc -= 8;\n-    }\n-    \/\/ Emit primary opcode and set sign-extend bit\n-    \/\/ Check for 8-bit immediate, and set sign extend bit in opcode\n-    if (-0x80 <= $imm$$constant && $imm$$constant < 0x80) {\n-      emit_opcode(cbuf, $primary | 0x02);\n-    } else {\n-      \/\/ 32-bit immediate\n-      emit_opcode(cbuf, $primary);\n-    }\n-    \/\/ Emit r\/m byte with secondary opcode, after primary opcode.\n-    emit_rm(cbuf, 0x3, $secondary, dstenc);\n-  %}\n-\n-  enc_class OpcSErm_wide(rRegL dst, immI imm)\n-  %{\n-    \/\/ OpcSEr\/m\n-    int dstenc = $dst$$reg;\n-    if (dstenc < 8) {\n-      emit_opcode(cbuf, Assembler::REX_W);\n-    } else {\n-      emit_opcode(cbuf, Assembler::REX_WB);\n-      dstenc -= 8;\n-    }\n-    \/\/ Emit primary opcode and set sign-extend bit\n-    \/\/ Check for 8-bit immediate, and set sign extend bit in opcode\n-    if (-0x80 <= $imm$$constant && $imm$$constant < 0x80) {\n-      emit_opcode(cbuf, $primary | 0x02);\n-    } else {\n-      \/\/ 32-bit immediate\n-      emit_opcode(cbuf, $primary);\n-    }\n-    \/\/ Emit r\/m byte with secondary opcode, after primary opcode.\n-    emit_rm(cbuf, 0x3, $secondary, dstenc);\n-  %}\n-\n-  enc_class Con8or32(immI imm)\n-  %{\n-    \/\/ Check for 8-bit immediate, and set sign extend bit in opcode\n-    if (-0x80 <= $imm$$constant && $imm$$constant < 0x80) {\n-      $$$emit8$imm$$constant;\n-    } else {\n-      \/\/ 32-bit immediate\n-      $$$emit32$imm$$constant;\n-    }\n-  %}\n-\n-  enc_class opc2_reg(rRegI dst)\n-  %{\n-    \/\/ BSWAP\n-    emit_cc(cbuf, $secondary, $dst$$reg);\n-  %}\n-\n-  enc_class opc3_reg(rRegI dst)\n-  %{\n-    \/\/ BSWAP\n-    emit_cc(cbuf, $tertiary, $dst$$reg);\n-  %}\n-\n-  enc_class reg_opc(rRegI div)\n-  %{\n-    \/\/ INC, DEC, IDIV, IMOD, JMP indirect, ...\n-    emit_rm(cbuf, 0x3, $secondary, $div$$reg & 7);\n-  %}\n-\n-  enc_class enc_cmov(cmpOp cop)\n-  %{\n-    \/\/ CMOV\n-    $$$emit8$primary;\n-    emit_cc(cbuf, $secondary, $cop$$cmpcode);\n-  %}\n-\n@@ -2173,1 +1837,0 @@\n-    cbuf.set_insts_mark();\n@@ -2176,4 +1839,1 @@\n-      $$$emit8$primary;\n-      emit_d32_reloc(cbuf, (int) ($meth$$method - ((intptr_t) cbuf.insts_end()) - 4),\n-                     runtime_call_Relocation::spec(),\n-                     RELOC_DISP32);\n+      __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, $meth$$method)));\n@@ -2186,1 +1846,0 @@\n-      $$$emit8$primary;\n@@ -2190,3 +1849,3 @@\n-      emit_d32_reloc(cbuf, (int) ($meth$$method - ((intptr_t) cbuf.insts_end()) - 4),\n-                     rspec, RELOC_DISP32);\n-      address mark = cbuf.insts_mark();\n+      address mark = __ pc();\n+      int call_offset = __ offset();\n+      __ call(AddressLiteral(CAST_FROM_FN_PTR(address, $meth$$method), rspec));\n@@ -2196,1 +1855,1 @@\n-        cbuf.shared_stub_to_interp_for(_method, cbuf.insts()->mark_off());\n+        cbuf.shared_stub_to_interp_for(_method, call_offset);\n@@ -2206,1 +1865,0 @@\n-    _masm.clear_inst_mark();\n@@ -2216,523 +1874,0 @@\n-  enc_class reg_opc_imm(rRegI dst, immI8 shift)\n-  %{\n-    \/\/ SAL, SAR, SHR\n-    int dstenc = $dst$$reg;\n-    if (dstenc >= 8) {\n-      emit_opcode(cbuf, Assembler::REX_B);\n-      dstenc -= 8;\n-    }\n-    $$$emit8$primary;\n-    emit_rm(cbuf, 0x3, $secondary, dstenc);\n-    $$$emit8$shift$$constant;\n-  %}\n-\n-  enc_class reg_opc_imm_wide(rRegL dst, immI8 shift)\n-  %{\n-    \/\/ SAL, SAR, SHR\n-    int dstenc = $dst$$reg;\n-    if (dstenc < 8) {\n-      emit_opcode(cbuf, Assembler::REX_W);\n-    } else {\n-      emit_opcode(cbuf, Assembler::REX_WB);\n-      dstenc -= 8;\n-    }\n-    $$$emit8$primary;\n-    emit_rm(cbuf, 0x3, $secondary, dstenc);\n-    $$$emit8$shift$$constant;\n-  %}\n-\n-  enc_class load_immI(rRegI dst, immI src)\n-  %{\n-    int dstenc = $dst$$reg;\n-    if (dstenc >= 8) {\n-      emit_opcode(cbuf, Assembler::REX_B);\n-      dstenc -= 8;\n-    }\n-    emit_opcode(cbuf, 0xB8 | dstenc);\n-    $$$emit32$src$$constant;\n-  %}\n-\n-  enc_class load_immL(rRegL dst, immL src)\n-  %{\n-    int dstenc = $dst$$reg;\n-    if (dstenc < 8) {\n-      emit_opcode(cbuf, Assembler::REX_W);\n-    } else {\n-      emit_opcode(cbuf, Assembler::REX_WB);\n-      dstenc -= 8;\n-    }\n-    emit_opcode(cbuf, 0xB8 | dstenc);\n-    emit_d64(cbuf, $src$$constant);\n-  %}\n-\n-  enc_class load_immUL32(rRegL dst, immUL32 src)\n-  %{\n-    \/\/ same as load_immI, but this time we care about zeroes in the high word\n-    int dstenc = $dst$$reg;\n-    if (dstenc >= 8) {\n-      emit_opcode(cbuf, Assembler::REX_B);\n-      dstenc -= 8;\n-    }\n-    emit_opcode(cbuf, 0xB8 | dstenc);\n-    $$$emit32$src$$constant;\n-  %}\n-\n-  enc_class load_immL32(rRegL dst, immL32 src)\n-  %{\n-    int dstenc = $dst$$reg;\n-    if (dstenc < 8) {\n-      emit_opcode(cbuf, Assembler::REX_W);\n-    } else {\n-      emit_opcode(cbuf, Assembler::REX_WB);\n-      dstenc -= 8;\n-    }\n-    emit_opcode(cbuf, 0xC7);\n-    emit_rm(cbuf, 0x03, 0x00, dstenc);\n-    $$$emit32$src$$constant;\n-  %}\n-\n-  enc_class load_immP31(rRegP dst, immP32 src)\n-  %{\n-    \/\/ same as load_immI, but this time we care about zeroes in the high word\n-    int dstenc = $dst$$reg;\n-    if (dstenc >= 8) {\n-      emit_opcode(cbuf, Assembler::REX_B);\n-      dstenc -= 8;\n-    }\n-    emit_opcode(cbuf, 0xB8 | dstenc);\n-    $$$emit32$src$$constant;\n-  %}\n-\n-  enc_class load_immP(rRegP dst, immP src)\n-  %{\n-    int dstenc = $dst$$reg;\n-    if (dstenc < 8) {\n-      emit_opcode(cbuf, Assembler::REX_W);\n-    } else {\n-      emit_opcode(cbuf, Assembler::REX_WB);\n-      dstenc -= 8;\n-    }\n-    emit_opcode(cbuf, 0xB8 | dstenc);\n-    \/\/ This next line should be generated from ADLC\n-    if ($src->constant_reloc() != relocInfo::none) {\n-      emit_d64_reloc(cbuf, $src$$constant, $src->constant_reloc(), RELOC_IMM64);\n-    } else {\n-      emit_d64(cbuf, $src$$constant);\n-    }\n-  %}\n-\n-  enc_class Con32(immI src)\n-  %{\n-    \/\/ Output immediate\n-    $$$emit32$src$$constant;\n-  %}\n-\n-  enc_class Con32F_as_bits(immF src)\n-  %{\n-    \/\/ Output Float immediate bits\n-    jfloat jf = $src$$constant;\n-    jint jf_as_bits = jint_cast(jf);\n-    emit_d32(cbuf, jf_as_bits);\n-  %}\n-\n-  enc_class Con16(immI src)\n-  %{\n-    \/\/ Output immediate\n-    $$$emit16$src$$constant;\n-  %}\n-\n-  \/\/ How is this different from Con32??? XXX\n-  enc_class Con_d32(immI src)\n-  %{\n-    emit_d32(cbuf,$src$$constant);\n-  %}\n-\n-  enc_class conmemref (rRegP t1) %{    \/\/ Con32(storeImmI)\n-    \/\/ Output immediate memory reference\n-    emit_rm(cbuf, 0x00, $t1$$reg, 0x05 );\n-    emit_d32(cbuf, 0x00);\n-  %}\n-\n-  enc_class lock_prefix()\n-  %{\n-    emit_opcode(cbuf, 0xF0); \/\/ lock\n-  %}\n-\n-  enc_class REX_mem(memory mem)\n-  %{\n-    if ($mem$$base >= 8) {\n-      if ($mem$$index < 8) {\n-        emit_opcode(cbuf, Assembler::REX_B);\n-      } else {\n-        emit_opcode(cbuf, Assembler::REX_XB);\n-      }\n-    } else {\n-      if ($mem$$index >= 8) {\n-        emit_opcode(cbuf, Assembler::REX_X);\n-      }\n-    }\n-  %}\n-\n-  enc_class REX_mem_wide(memory mem)\n-  %{\n-    if ($mem$$base >= 8) {\n-      if ($mem$$index < 8) {\n-        emit_opcode(cbuf, Assembler::REX_WB);\n-      } else {\n-        emit_opcode(cbuf, Assembler::REX_WXB);\n-      }\n-    } else {\n-      if ($mem$$index < 8) {\n-        emit_opcode(cbuf, Assembler::REX_W);\n-      } else {\n-        emit_opcode(cbuf, Assembler::REX_WX);\n-      }\n-    }\n-  %}\n-\n-  \/\/ for byte regs\n-  enc_class REX_breg(rRegI reg)\n-  %{\n-    if ($reg$$reg >= 4) {\n-      emit_opcode(cbuf, $reg$$reg < 8 ? Assembler::REX : Assembler::REX_B);\n-    }\n-  %}\n-\n-  \/\/ for byte regs\n-  enc_class REX_reg_breg(rRegI dst, rRegI src)\n-  %{\n-    if ($dst$$reg < 8) {\n-      if ($src$$reg >= 4) {\n-        emit_opcode(cbuf, $src$$reg < 8 ? Assembler::REX : Assembler::REX_B);\n-      }\n-    } else {\n-      if ($src$$reg < 8) {\n-        emit_opcode(cbuf, Assembler::REX_R);\n-      } else {\n-        emit_opcode(cbuf, Assembler::REX_RB);\n-      }\n-    }\n-  %}\n-\n-  \/\/ for byte regs\n-  enc_class REX_breg_mem(rRegI reg, memory mem)\n-  %{\n-    if ($reg$$reg < 8) {\n-      if ($mem$$base < 8) {\n-        if ($mem$$index >= 8) {\n-          emit_opcode(cbuf, Assembler::REX_X);\n-        } else if ($reg$$reg >= 4) {\n-          emit_opcode(cbuf, Assembler::REX);\n-        }\n-      } else {\n-        if ($mem$$index < 8) {\n-          emit_opcode(cbuf, Assembler::REX_B);\n-        } else {\n-          emit_opcode(cbuf, Assembler::REX_XB);\n-        }\n-      }\n-    } else {\n-      if ($mem$$base < 8) {\n-        if ($mem$$index < 8) {\n-          emit_opcode(cbuf, Assembler::REX_R);\n-        } else {\n-          emit_opcode(cbuf, Assembler::REX_RX);\n-        }\n-      } else {\n-        if ($mem$$index < 8) {\n-          emit_opcode(cbuf, Assembler::REX_RB);\n-        } else {\n-          emit_opcode(cbuf, Assembler::REX_RXB);\n-        }\n-      }\n-    }\n-  %}\n-\n-  enc_class REX_reg(rRegI reg)\n-  %{\n-    if ($reg$$reg >= 8) {\n-      emit_opcode(cbuf, Assembler::REX_B);\n-    }\n-  %}\n-\n-  enc_class REX_reg_wide(rRegI reg)\n-  %{\n-    if ($reg$$reg < 8) {\n-      emit_opcode(cbuf, Assembler::REX_W);\n-    } else {\n-      emit_opcode(cbuf, Assembler::REX_WB);\n-    }\n-  %}\n-\n-  enc_class REX_reg_reg(rRegI dst, rRegI src)\n-  %{\n-    if ($dst$$reg < 8) {\n-      if ($src$$reg >= 8) {\n-        emit_opcode(cbuf, Assembler::REX_B);\n-      }\n-    } else {\n-      if ($src$$reg < 8) {\n-        emit_opcode(cbuf, Assembler::REX_R);\n-      } else {\n-        emit_opcode(cbuf, Assembler::REX_RB);\n-      }\n-    }\n-  %}\n-\n-  enc_class REX_reg_reg_wide(rRegI dst, rRegI src)\n-  %{\n-    if ($dst$$reg < 8) {\n-      if ($src$$reg < 8) {\n-        emit_opcode(cbuf, Assembler::REX_W);\n-      } else {\n-        emit_opcode(cbuf, Assembler::REX_WB);\n-      }\n-    } else {\n-      if ($src$$reg < 8) {\n-        emit_opcode(cbuf, Assembler::REX_WR);\n-      } else {\n-        emit_opcode(cbuf, Assembler::REX_WRB);\n-      }\n-    }\n-  %}\n-\n-  enc_class REX_reg_mem(rRegI reg, memory mem)\n-  %{\n-    if ($reg$$reg < 8) {\n-      if ($mem$$base < 8) {\n-        if ($mem$$index >= 8) {\n-          emit_opcode(cbuf, Assembler::REX_X);\n-        }\n-      } else {\n-        if ($mem$$index < 8) {\n-          emit_opcode(cbuf, Assembler::REX_B);\n-        } else {\n-          emit_opcode(cbuf, Assembler::REX_XB);\n-        }\n-      }\n-    } else {\n-      if ($mem$$base < 8) {\n-        if ($mem$$index < 8) {\n-          emit_opcode(cbuf, Assembler::REX_R);\n-        } else {\n-          emit_opcode(cbuf, Assembler::REX_RX);\n-        }\n-      } else {\n-        if ($mem$$index < 8) {\n-          emit_opcode(cbuf, Assembler::REX_RB);\n-        } else {\n-          emit_opcode(cbuf, Assembler::REX_RXB);\n-        }\n-      }\n-    }\n-  %}\n-\n-  enc_class REX_reg_mem_wide(rRegL reg, memory mem)\n-  %{\n-    if ($reg$$reg < 8) {\n-      if ($mem$$base < 8) {\n-        if ($mem$$index < 8) {\n-          emit_opcode(cbuf, Assembler::REX_W);\n-        } else {\n-          emit_opcode(cbuf, Assembler::REX_WX);\n-        }\n-      } else {\n-        if ($mem$$index < 8) {\n-          emit_opcode(cbuf, Assembler::REX_WB);\n-        } else {\n-          emit_opcode(cbuf, Assembler::REX_WXB);\n-        }\n-      }\n-    } else {\n-      if ($mem$$base < 8) {\n-        if ($mem$$index < 8) {\n-          emit_opcode(cbuf, Assembler::REX_WR);\n-        } else {\n-          emit_opcode(cbuf, Assembler::REX_WRX);\n-        }\n-      } else {\n-        if ($mem$$index < 8) {\n-          emit_opcode(cbuf, Assembler::REX_WRB);\n-        } else {\n-          emit_opcode(cbuf, Assembler::REX_WRXB);\n-        }\n-      }\n-    }\n-  %}\n-\n-  enc_class reg_mem(rRegI ereg, memory mem)\n-  %{\n-    \/\/ High registers handle in encode_RegMem\n-    int reg = $ereg$$reg;\n-    int base = $mem$$base;\n-    int index = $mem$$index;\n-    int scale = $mem$$scale;\n-    int disp = $mem$$disp;\n-    relocInfo::relocType disp_reloc = $mem->disp_reloc();\n-\n-    encode_RegMem(cbuf, reg, base, index, scale, disp, disp_reloc);\n-  %}\n-\n-  enc_class RM_opc_mem(immI rm_opcode, memory mem)\n-  %{\n-    int rm_byte_opcode = $rm_opcode$$constant;\n-\n-    \/\/ High registers handle in encode_RegMem\n-    int base = $mem$$base;\n-    int index = $mem$$index;\n-    int scale = $mem$$scale;\n-    int displace = $mem$$disp;\n-\n-    relocInfo::relocType disp_reloc = $mem->disp_reloc();       \/\/ disp-as-oop when\n-                                            \/\/ working with static\n-                                            \/\/ globals\n-    encode_RegMem(cbuf, rm_byte_opcode, base, index, scale, displace,\n-                  disp_reloc);\n-  %}\n-\n-  enc_class reg_lea(rRegI dst, rRegI src0, immI src1)\n-  %{\n-    int reg_encoding = $dst$$reg;\n-    int base         = $src0$$reg;      \/\/ 0xFFFFFFFF indicates no base\n-    int index        = 0x04;            \/\/ 0x04 indicates no index\n-    int scale        = 0x00;            \/\/ 0x00 indicates no scale\n-    int displace     = $src1$$constant; \/\/ 0x00 indicates no displacement\n-    relocInfo::relocType disp_reloc = relocInfo::none;\n-    encode_RegMem(cbuf, reg_encoding, base, index, scale, displace,\n-                  disp_reloc);\n-  %}\n-\n-  enc_class neg_reg(rRegI dst)\n-  %{\n-    int dstenc = $dst$$reg;\n-    if (dstenc >= 8) {\n-      emit_opcode(cbuf, Assembler::REX_B);\n-      dstenc -= 8;\n-    }\n-    \/\/ NEG $dst\n-    emit_opcode(cbuf, 0xF7);\n-    emit_rm(cbuf, 0x3, 0x03, dstenc);\n-  %}\n-\n-  enc_class neg_reg_wide(rRegI dst)\n-  %{\n-    int dstenc = $dst$$reg;\n-    if (dstenc < 8) {\n-      emit_opcode(cbuf, Assembler::REX_W);\n-    } else {\n-      emit_opcode(cbuf, Assembler::REX_WB);\n-      dstenc -= 8;\n-    }\n-    \/\/ NEG $dst\n-    emit_opcode(cbuf, 0xF7);\n-    emit_rm(cbuf, 0x3, 0x03, dstenc);\n-  %}\n-\n-  enc_class setLT_reg(rRegI dst)\n-  %{\n-    int dstenc = $dst$$reg;\n-    if (dstenc >= 8) {\n-      emit_opcode(cbuf, Assembler::REX_B);\n-      dstenc -= 8;\n-    } else if (dstenc >= 4) {\n-      emit_opcode(cbuf, Assembler::REX);\n-    }\n-    \/\/ SETLT $dst\n-    emit_opcode(cbuf, 0x0F);\n-    emit_opcode(cbuf, 0x9C);\n-    emit_rm(cbuf, 0x3, 0x0, dstenc);\n-  %}\n-\n-  enc_class setNZ_reg(rRegI dst)\n-  %{\n-    int dstenc = $dst$$reg;\n-    if (dstenc >= 8) {\n-      emit_opcode(cbuf, Assembler::REX_B);\n-      dstenc -= 8;\n-    } else if (dstenc >= 4) {\n-      emit_opcode(cbuf, Assembler::REX);\n-    }\n-    \/\/ SETNZ $dst\n-    emit_opcode(cbuf, 0x0F);\n-    emit_opcode(cbuf, 0x95);\n-    emit_rm(cbuf, 0x3, 0x0, dstenc);\n-  %}\n-\n-\n-  \/\/ Compare the lonogs and set -1, 0, or 1 into dst\n-  enc_class cmpl3_flag(rRegL src1, rRegL src2, rRegI dst)\n-  %{\n-    int src1enc = $src1$$reg;\n-    int src2enc = $src2$$reg;\n-    int dstenc = $dst$$reg;\n-\n-    \/\/ cmpq $src1, $src2\n-    if (src1enc < 8) {\n-      if (src2enc < 8) {\n-        emit_opcode(cbuf, Assembler::REX_W);\n-      } else {\n-        emit_opcode(cbuf, Assembler::REX_WB);\n-      }\n-    } else {\n-      if (src2enc < 8) {\n-        emit_opcode(cbuf, Assembler::REX_WR);\n-      } else {\n-        emit_opcode(cbuf, Assembler::REX_WRB);\n-      }\n-    }\n-    emit_opcode(cbuf, 0x3B);\n-    emit_rm(cbuf, 0x3, src1enc & 7, src2enc & 7);\n-\n-    \/\/ movl $dst, -1\n-    if (dstenc >= 8) {\n-      emit_opcode(cbuf, Assembler::REX_B);\n-    }\n-    emit_opcode(cbuf, 0xB8 | (dstenc & 7));\n-    emit_d32(cbuf, -1);\n-\n-    \/\/ jl,s done\n-    emit_opcode(cbuf, 0x7C);\n-    emit_d8(cbuf, dstenc < 4 ? 0x06 : 0x08);\n-\n-    \/\/ setne $dst\n-    if (dstenc >= 4) {\n-      emit_opcode(cbuf, dstenc < 8 ? Assembler::REX : Assembler::REX_B);\n-    }\n-    emit_opcode(cbuf, 0x0F);\n-    emit_opcode(cbuf, 0x95);\n-    emit_opcode(cbuf, 0xC0 | (dstenc & 7));\n-\n-    \/\/ movzbl $dst, $dst\n-    if (dstenc >= 4) {\n-      emit_opcode(cbuf, dstenc < 8 ? Assembler::REX : Assembler::REX_RB);\n-    }\n-    emit_opcode(cbuf, 0x0F);\n-    emit_opcode(cbuf, 0xB6);\n-    emit_rm(cbuf, 0x3, dstenc & 7, dstenc & 7);\n-  %}\n-\n-  enc_class Push_ResultXD(regD dst) %{\n-    MacroAssembler _masm(&cbuf);\n-    __ fstp_d(Address(rsp, 0));\n-    __ movdbl($dst$$XMMRegister, Address(rsp, 0));\n-    __ addptr(rsp, 8);\n-  %}\n-\n-  enc_class Push_SrcXD(regD src) %{\n-    MacroAssembler _masm(&cbuf);\n-    __ subptr(rsp, 8);\n-    __ movdbl(Address(rsp, 0), $src$$XMMRegister);\n-    __ fld_d(Address(rsp, 0));\n-  %}\n-\n-\n-  enc_class enc_rethrow()\n-  %{\n-    cbuf.set_insts_mark();\n-    emit_opcode(cbuf, 0xE9); \/\/ jmp entry\n-    emit_d32_reloc(cbuf,\n-                   (int) (OptoRuntime::rethrow_stub() - cbuf.insts_end() - 4),\n-                   runtime_call_Relocation::spec(),\n-                   RELOC_DISP32);\n-  %}\n-\n@@ -4612,11 +3747,0 @@\n-\/\/ XXX\n-\/\/ \/\/ Conditional move double reg-reg\n-\/\/ pipe_class pipe_cmovD_reg( rFlagsReg cr, regDPR1 dst, regD src)\n-\/\/ %{\n-\/\/     single_instruction;\n-\/\/     dst    : S4(write);\n-\/\/     src    : S3(read);\n-\/\/     cr     : S3(read);\n-\/\/     DECODE : S0;     \/\/ any decoder\n-\/\/ %}\n-\n@@ -5933,1 +5057,1 @@\n-    __ xorpd ($dst$$XMMRegister, $dst$$XMMRegister);\n+    __ xorpd($dst$$XMMRegister, $dst$$XMMRegister);\n@@ -5944,2 +5068,3 @@\n-  opcode(0x8B);\n-  ins_encode(REX_reg_mem(dst, src), OpcP, reg_mem(dst, src));\n+  ins_encode %{\n+    __ movl($dst$$Register, $src$$Address);\n+  %}\n@@ -5955,2 +5080,3 @@\n-  opcode(0x8B);\n-  ins_encode(REX_reg_mem_wide(dst, src), OpcP, reg_mem(dst, src));\n+  ins_encode %{\n+    __ movq($dst$$Register, $src$$Address);\n+  %}\n@@ -5966,2 +5092,3 @@\n-  opcode(0x8B);\n-  ins_encode(REX_reg_mem_wide(dst, src), OpcP, reg_mem(dst, src));\n+  ins_encode %{\n+    __ movq($dst$$Register, $src$$Address);\n+  %}\n@@ -6425,2 +5552,3 @@\n-  opcode(0x89);\n-  ins_encode(REX_reg_mem(src, dst), OpcP, reg_mem(src, dst));\n+  ins_encode %{\n+    __ movl($dst$$Address, $src$$Register);\n+  %}\n@@ -6436,2 +5564,3 @@\n-  opcode(0x89);\n-  ins_encode(REX_reg_mem_wide(src, dst), OpcP, reg_mem(src, dst));\n+  ins_encode %{\n+    __ movq($dst$$Address, $src$$Register);\n+  %}\n@@ -6447,2 +5576,3 @@\n-  opcode(0x89);\n-  ins_encode(REX_reg_mem_wide(src, dst), OpcP, reg_mem(src, dst));\n+  ins_encode %{\n+    __ movq($dst$$Address, $src$$Register);\n+  %}\n@@ -7416,27 +6546,0 @@\n-\/\/ DISABLED: Requires the ADLC to emit a bottom_type call that\n-\/\/ correctly meets the two pointer arguments; one is an incoming\n-\/\/ register but the other is a memory operand.  ALSO appears to\n-\/\/ be buggy with implicit null checks.\n-\/\/\n-\/\/\/\/ Conditional move\n-\/\/instruct cmovP_mem(cmpOp cop, rFlagsReg cr, rRegP dst, memory src)\n-\/\/%{\n-\/\/  match(Set dst (CMoveP (Binary cop cr) (Binary dst (LoadP src))));\n-\/\/  ins_cost(250);\n-\/\/  format %{ \"CMOV$cop $dst,$src\\t# ptr\" %}\n-\/\/  opcode(0x0F,0x40);\n-\/\/  ins_encode( enc_cmov(cop), reg_mem( dst, src ) );\n-\/\/  ins_pipe( pipe_cmov_mem );\n-\/\/%}\n-\/\/\n-\/\/\/\/ Conditional move\n-\/\/instruct cmovP_memU(cmpOpU cop, rFlagsRegU cr, rRegP dst, memory src)\n-\/\/%{\n-\/\/  match(Set dst (CMoveP (Binary cop cr) (Binary dst (LoadP src))));\n-\/\/  ins_cost(250);\n-\/\/  format %{ \"CMOV$cop $dst,$src\\t# ptr\" %}\n-\/\/  opcode(0x0F,0x40);\n-\/\/  ins_encode( enc_cmov(cop), reg_mem( dst, src ) );\n-\/\/  ins_pipe( pipe_cmov_mem );\n-\/\/%}\n-\n@@ -7597,12 +6700,0 @@\n-\/\/ instruct cmovF_mem(cmpOp cop, rFlagsReg cr, regF dst, memory src)\n-\/\/ %{\n-\/\/   match(Set dst (CMoveF (Binary cop cr) (Binary dst (LoadL src))));\n-\n-\/\/   ins_cost(200); \/\/ XXX\n-\/\/   format %{ \"jn$cop    skip\\t# signed cmove float\\n\\t\"\n-\/\/             \"movss     $dst, $src\\n\"\n-\/\/     \"skip:\" %}\n-\/\/   ins_encode(enc_cmovf_mem_branch(cop, dst, src));\n-\/\/   ins_pipe(pipe_slow);\n-\/\/ %}\n-\n@@ -8689,2 +7780,3 @@\n-  opcode(0x2B);\n-  ins_encode(REX_reg_reg_wide(dst, src), OpcP, reg_reg(dst, src));\n+  ins_encode %{\n+    __ subq($dst$$Register, $src$$Register);\n+  %}\n@@ -11104,1 +10196,1 @@\n-\n+  effect(TEMP dst);\n@@ -11126,1 +10218,1 @@\n-\n+  effect(TEMP dst);\n@@ -11342,17 +10434,0 @@\n-\/\/ instruct convI2L_reg_reg_foo(rRegL dst, rRegI src)\n-\/\/ %{\n-\/\/   match(Set dst (ConvI2L src));\n-\/\/ \/\/   predicate(_kids[0]->_leaf->as_Type()->type()->is_int()->_lo >= 0 &&\n-\/\/ \/\/             _kids[0]->_leaf->as_Type()->type()->is_int()->_hi >= 0);\n-\/\/   predicate(((const TypeNode*) n)->type()->is_long()->_hi ==\n-\/\/             (unsigned int) ((const TypeNode*) n)->type()->is_long()->_hi &&\n-\/\/             ((const TypeNode*) n)->type()->is_long()->_lo ==\n-\/\/             (unsigned int) ((const TypeNode*) n)->type()->is_long()->_lo);\n-\n-\/\/   format %{ \"movl    $dst, $src\\t# unsigned i2l\" %}\n-\/\/   ins_encode(enc_copy(dst, src));\n-\/\/ \/\/   opcode(0x63); \/\/ needs REX.W\n-\/\/ \/\/   ins_encode(REX_reg_reg_wide(dst, src), OpcP, reg_reg(dst,src));\n-\/\/   ins_pipe(ialu_reg_reg);\n-\/\/ %}\n-\n@@ -12849,11 +11924,0 @@\n-\/\/ \/\/ \/\/ Cisc-spilled version of cmpU_rReg\n-\/\/ \/\/instruct compU_mem_rReg(rFlagsRegU cr, memory op1, rRegI op2)\n-\/\/ \/\/%{\n-\/\/ \/\/  match(Set cr (CmpU (LoadI op1) op2));\n-\/\/ \/\/\n-\/\/ \/\/  format %{ \"CMPu   $op1,$op2\" %}\n-\/\/ \/\/  ins_cost(500);\n-\/\/ \/\/  opcode(0x39);  \/* Opcode 39 \/r *\/\n-\/\/ \/\/  ins_encode( OpcP, reg_mem( op1, op2) );\n-\/\/ \/\/%}\n-\n@@ -12895,11 +11959,0 @@\n-\/\/ \/\/ \/\/ Cisc-spilled version of cmpP_rReg\n-\/\/ \/\/instruct compP_mem_rReg(rFlagsRegU cr, memory op1, rRegP op2)\n-\/\/ \/\/%{\n-\/\/ \/\/  match(Set cr (CmpP (LoadP op1) op2));\n-\/\/ \/\/\n-\/\/ \/\/  format %{ \"CMPu   $op1,$op2\" %}\n-\/\/ \/\/  ins_cost(500);\n-\/\/ \/\/  opcode(0x39);  \/* Opcode 39 \/r *\/\n-\/\/ \/\/  ins_encode( OpcP, reg_mem( op1, op2) );\n-\/\/ \/\/%}\n-\n@@ -13898,1 +12951,3 @@\n-  ins_encode(enc_rethrow);\n+  ins_encode %{\n+    __ jump(RuntimeAddress(OptoRuntime::rethrow_stub()), noreg);\n+  %}\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":35,"deletions":980,"binary":false,"changes":1015,"status":"modified"},{"patch":"@@ -144,1 +144,0 @@\n-                                         VMRegPair *regs2,\n","filename":"src\/hotspot\/cpu\/zero\/sharedRuntime_zero.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -218,2 +218,2 @@\n-  static int desired_max_code_buffer_size() {\n-    return (int)NMethodSizeLimit;  \/\/ default 64K\n+  static uint desired_max_code_buffer_size() {\n+    return (uint)NMethodSizeLimit;  \/\/ default 64K\n@@ -221,1 +221,1 @@\n-  static int desired_max_constant_size() {\n+  static uint desired_max_constant_size() {\n","filename":"src\/hotspot\/share\/c1\/c1_Compilation.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -121,1 +121,1 @@\n-  intptr_t out_preserve = SharedRuntime::c_calling_convention(sig_bt, regs, nullptr, sizeargs);\n+  intptr_t out_preserve = SharedRuntime::c_calling_convention(sig_bt, regs, sizeargs);\n","filename":"src\/hotspot\/share\/c1\/c1_FrameMap.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -225,1 +225,1 @@\n-  assert(DumpSharedSpaces, \"must\");\n+  assert(CDSConfig::is_dumping_static_archive(), \"cpp tables are only dumped into static archive\");\n@@ -293,1 +293,1 @@\n-  assert(DumpSharedSpaces, \"dump-time only\");\n+  assert(CDSConfig::is_dumping_static_archive(), \"cpp tables are only dumped into static archive\");\n","filename":"src\/hotspot\/share\/cds\/cppVtables.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -249,1 +249,1 @@\n-  assert(DumpSharedSpaces, \"should be called for dump time only\");\n+  assert(CDSConfig::is_dumping_static_archive(), \"sanity\");\n","filename":"src\/hotspot\/share\/cds\/metaspaceShared.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -6004,1 +6004,1 @@\n-  if (DumpSharedSpaces) {\n+  if (CDSConfig::is_dumping_static_archive()) {\n@@ -6368,1 +6368,1 @@\n-  if (DumpSharedSpaces) {\n+  if (CDSConfig::is_dumping_static_archive()) {\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1132,1 +1132,1 @@\n-    if (!DumpSharedSpaces) {\n+    if (!CDSConfig::is_dumping_static_archive()) {\n@@ -1493,2 +1493,1 @@\n-    assert(!DumpSharedSpaces, \"DumpSharedSpaces not supported with exploded module builds\");\n-    assert(!CDSConfig::is_dumping_dynamic_archive(), \"not supported with exploded module builds\");\n+    assert(!CDSConfig::is_dumping_archive(), \"not supported with exploded module builds\");\n","filename":"src\/hotspot\/share\/classfile\/classLoader.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -809,3 +809,1 @@\n-  \/\/ Can't use vmSymbols::string_signature() as fd->signature() may have been relocated\n-  \/\/ during DumpSharedSpaces\n-  assert(fd->signature()->equals(\"Ljava\/lang\/String;\"), \"just checking\");\n+  assert(fd->signature() == vmSymbols::string_signature(), \"just checking\");\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -427,1 +427,1 @@\n-  if (DumpSharedSpaces) {\n+  if (CDSConfig::is_dumping_static_archive()) {\n@@ -938,1 +938,1 @@\n-  if (!DumpSharedSpaces) {\n+  if (!CDSConfig::is_dumping_static_archive()) {\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"cds\/cdsConfig.hpp\"\n@@ -202,1 +203,1 @@\n-    \/\/ If DumpSharedSpaces is set then don't fall back to the old verifier on\n+    \/\/ If dumping static archive then don't fall back to the old verifier on\n@@ -207,1 +208,1 @@\n-    bool can_failover = !DumpSharedSpaces &&\n+    bool can_failover = !CDSConfig::is_dumping_static_archive() &&\n","filename":"src\/hotspot\/share\/classfile\/verifier.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -252,1 +252,1 @@\n-BufferBlob* BufferBlob::create(const char* name, int buffer_size) {\n+BufferBlob* BufferBlob::create(const char* name, uint buffer_size) {\n","filename":"src\/hotspot\/share\/code\/codeBlob.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -416,1 +416,1 @@\n-  static BufferBlob* create(const char* name, int buffer_size);\n+  static BufferBlob* create(const char* name, uint buffer_size);\n","filename":"src\/hotspot\/share\/code\/codeBlob.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -274,0 +274,8 @@\n+Handle ObjectMergeValue::value() const {\n+  if (_selected != nullptr) {\n+    return _selected->value();\n+  } else {\n+    return Handle();\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/code\/debugInfo.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -240,1 +240,1 @@\n-  Handle                      value() const                   { assert(_selected != nullptr, \"Should call select() first.\"); return _selected->value(); }\n+  Handle                      value() const;\n","filename":"src\/hotspot\/share\/code\/debugInfo.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -247,1 +247,1 @@\n-  assert(DumpSharedSpaces, \"dump-time only\");\n+  assert(CDSConfig::is_dumping_heap(), \"sanity\");\n@@ -494,1 +494,1 @@\n-    if (DumpSharedSpaces) {\n+    if (CDSConfig::is_dumping_heap()) {\n@@ -813,2 +813,0 @@\n-  \/\/ Create memory for metadata.  Must be after initializing heap for\n-  \/\/ DumpSharedSpaces.\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":2,"deletions":4,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"cds\/cdsConfig.hpp\"\n@@ -46,0 +47,4 @@\n+ArrayKlass::ArrayKlass() {\n+  assert(CDSConfig::is_dumping_static_archive() || UseSharedSpaces, \"only for CDS\");\n+}\n+\n","filename":"src\/hotspot\/share\/oops\/arrayKlass.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -57,1 +57,1 @@\n-  ArrayKlass() { assert(DumpSharedSpaces || UseSharedSpaces, \"only for cds\"); }\n+  ArrayKlass();\n","filename":"src\/hotspot\/share\/oops\/arrayKlass.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -108,0 +108,4 @@\n+ConstantPool::ConstantPool() {\n+  assert(CDSConfig::is_dumping_static_archive() || UseSharedSpaces, \"only for CDS\");\n+}\n+\n","filename":"src\/hotspot\/share\/oops\/constantPool.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -165,1 +165,1 @@\n-  ConstantPool() { assert(DumpSharedSpaces || UseSharedSpaces, \"only for CDS\"); }\n+  ConstantPool();\n","filename":"src\/hotspot\/share\/oops\/constantPool.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -451,1 +451,1 @@\n-  assert(DumpSharedSpaces, \"called only during runtime\");\n+  assert(CDSConfig::is_dumping_heap(), \"sanity\");\n","filename":"src\/hotspot\/share\/oops\/cpCache.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"cds\/cdsConfig.hpp\"\n@@ -46,1 +47,1 @@\n-  InlineKlass() { assert(DumpSharedSpaces || UseSharedSpaces, \"only for CDS\"); }\n+  InlineKlass() { assert(CDSConfig::is_dumping_archive() || UseSharedSpaces, \"only for CDS\"); }\n","filename":"src\/hotspot\/share\/oops\/inlineKlass.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -0,0 +1,32 @@\n+\/*\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"cds\/cdsConfig.hpp\"\n+#include \"oops\/instanceClassLoaderKlass.hpp\"\n+#include \"oops\/instanceKlass.inline.hpp\"\n+\n+InstanceClassLoaderKlass::InstanceClassLoaderKlass() {\n+  assert(CDSConfig::is_dumping_static_archive() || UseSharedSpaces, \"only for CDS\");\n+}\n","filename":"src\/hotspot\/share\/oops\/instanceClassLoaderKlass.cpp","additions":32,"deletions":0,"binary":false,"changes":32,"status":"added"},{"patch":"@@ -543,0 +543,4 @@\n+InstanceKlass::InstanceKlass() {\n+  assert(CDSConfig::is_dumping_static_archive() || UseSharedSpaces, \"only for CDS\");\n+}\n+\n@@ -880,2 +884,2 @@\n-  if (DumpSharedSpaces && SystemDictionaryShared::has_class_failed_verification(this)) {\n-    \/\/ This is for CDS dumping phase only -- we use the in_error_state to indicate that\n+  if (CDSConfig::is_dumping_static_archive() && SystemDictionaryShared::has_class_failed_verification(this)) {\n+    \/\/ This is for CDS static dump only -- we use the in_error_state to indicate that\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -170,1 +170,1 @@\n-  InstanceKlass() { assert(DumpSharedSpaces || UseSharedSpaces, \"only for CDS\"); }\n+  InstanceKlass();\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -198,0 +198,4 @@\n+Klass::Klass() : _kind(UnknownKlassKind) {\n+  assert(CDSConfig::is_dumping_static_archive() || UseSharedSpaces, \"only for cds\");\n+}\n+\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -199,2 +199,1 @@\n-  \/\/ Constructor\n-  Klass() : _kind(UnknownKlassKind) { assert(DumpSharedSpaces || UseSharedSpaces, \"only for cds\"); }\n+  Klass();\n","filename":"src\/hotspot\/share\/oops\/klass.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -55,0 +55,3 @@\n+                                                                            \\\n+  product(bool, StressIncrementalInlining, false, DIAGNOSTIC,               \\\n+          \"Randomize the incremental inlining decision\")                    \\\n","filename":"src\/hotspot\/share\/opto\/c2_globals.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -463,1 +463,1 @@\n-    assert(!cg->is_late_inline() || cg->is_mh_late_inline() || AlwaysIncrementalInline, \"we're doing late inlining\");\n+    assert(!cg->is_late_inline() || cg->is_mh_late_inline() || AlwaysIncrementalInline || StressIncrementalInlining, \"we're doing late inlining\");\n@@ -585,1 +585,1 @@\n-    assert(!cg->is_late_inline() || cg->is_mh_late_inline() || AlwaysIncrementalInline, \"we're doing late inlining\");\n+    assert(!cg->is_late_inline() || cg->is_mh_late_inline() || AlwaysIncrementalInline || StressIncrementalInlining, \"we're doing late inlining\");\n@@ -1142,0 +1142,1 @@\n+  bool should_delay = C->should_delay_inlining();\n@@ -1143,1 +1144,1 @@\n-    if (AlwaysIncrementalInline) {\n+    if (should_delay) {\n@@ -1154,1 +1155,1 @@\n-                            (call_site_count > 0 && (input_not_const || !C->inlining_incrementally() || C->over_inlining_cutoff())))) {\n+                            (call_site_count > 0 && (should_delay || input_not_const || !C->inlining_incrementally() || C->over_inlining_cutoff())))) {\n","filename":"src\/hotspot\/share\/opto\/callGenerator.cpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1424,1 +1424,1 @@\n-  SharedRuntime::c_calling_convention(sig_bt, parm_regs, \/*regs2=*\/nullptr, argcnt);\n+  SharedRuntime::c_calling_convention(sig_bt, parm_regs, argcnt);\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -436,0 +436,1 @@\n+  bool is_zero_trip_guard() const;\n","filename":"src\/hotspot\/share\/opto\/cfgnode.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -290,0 +290,1 @@\n+    PhaseIterGVN::add_users_of_use_to_worklist(nn, use, *_igvn_worklist);\n@@ -854,1 +855,1 @@\n-  if (StressLCM || StressGCM || StressIGVN || StressCCP) {\n+  if (StressLCM || StressGCM || StressIGVN || StressCCP || StressIncrementalInlining) {\n@@ -2750,1 +2751,1 @@\n-    if (AlwaysIncrementalInline) {\n+    if (AlwaysIncrementalInline || StressIncrementalInlining) {\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1098,0 +1098,1 @@\n+  bool should_delay_inlining() { return AlwaysIncrementalInline || (StressIncrementalInlining && (random() % 2) == 0); }\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -189,1 +189,1 @@\n-      bool should_delay = AlwaysIncrementalInline;\n+      bool should_delay = C->should_delay_inlining();\n@@ -208,1 +208,3 @@\n-          if (should_delay_string_inlining(callee, jvms)) {\n+          if (should_delay) {\n+            return CallGenerator::for_late_inline(callee, cg);\n+          } else if (should_delay_string_inlining(callee, jvms)) {\n@@ -214,2 +216,0 @@\n-          } else if (should_delay) {\n-            return CallGenerator::for_late_inline(callee, cg);\n","filename":"src\/hotspot\/share\/opto\/doCall.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1794,0 +1794,7 @@\n+bool IfNode::is_zero_trip_guard() const {\n+  if (in(1)->is_Bool() && in(1)->in(1)->is_Cmp()) {\n+    return in(1)->in(1)->in(1)->Opcode() == Op_OpaqueZeroTripGuard;\n+  }\n+  return false;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/ifnode.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1127,0 +1127,1 @@\n+  clear_upper_avx();\n@@ -1381,0 +1382,1 @@\n+  clear_upper_avx();\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1465,1 +1465,1 @@\n-void PhaseIterGVN::add_users_to_worklist0( Node *n ) {\n+void PhaseIterGVN::add_users_to_worklist0(Node* n, Unique_Node_List& worklist) {\n@@ -1467,1 +1467,1 @@\n-    _worklist.push(n->fast_out(i));  \/\/ Push on worklist\n+    worklist.push(n->fast_out(i));  \/\/ Push on worklist\n@@ -1492,2 +1492,2 @@\n-void PhaseIterGVN::add_users_to_worklist( Node *n ) {\n-  add_users_to_worklist0(n);\n+void PhaseIterGVN::add_users_to_worklist(Node *n) {\n+  add_users_to_worklist0(n, _worklist);\n@@ -1495,0 +1495,1 @@\n+  Unique_Node_List& worklist = _worklist;\n@@ -1498,0 +1499,3 @@\n+    add_users_of_use_to_worklist(n, use, worklist);\n+  }\n+}\n@@ -1499,33 +1503,33 @@\n-    if( use->is_Multi() ||      \/\/ Multi-definer?  Push projs on worklist\n-        use->is_Store() )       \/\/ Enable store\/load same address\n-      add_users_to_worklist0(use);\n-\n-    \/\/ If we changed the receiver type to a call, we need to revisit\n-    \/\/ the Catch following the call.  It's looking for a non-null\n-    \/\/ receiver to know when to enable the regular fall-through path\n-    \/\/ in addition to the NullPtrException path.\n-    if (use->is_CallDynamicJava() && n == use->in(TypeFunc::Parms)) {\n-      Node* p = use->as_CallDynamicJava()->proj_out_or_null(TypeFunc::Control);\n-      if (p != nullptr) {\n-        add_users_to_worklist0(p);\n-      }\n-    }\n-\n-    uint use_op = use->Opcode();\n-    if(use->is_Cmp()) {       \/\/ Enable CMP\/BOOL optimization\n-      add_users_to_worklist(use); \/\/ Put Bool on worklist\n-      if (use->outcnt() > 0) {\n-        Node* bol = use->raw_out(0);\n-        if (bol->outcnt() > 0) {\n-          Node* iff = bol->raw_out(0);\n-          if (iff->outcnt() == 2) {\n-            \/\/ Look for the 'is_x2logic' pattern: \"x ? : 0 : 1\" and put the\n-            \/\/ phi merging either 0 or 1 onto the worklist\n-            Node* ifproj0 = iff->raw_out(0);\n-            Node* ifproj1 = iff->raw_out(1);\n-            if (ifproj0->outcnt() > 0 && ifproj1->outcnt() > 0) {\n-              Node* region0 = ifproj0->raw_out(0);\n-              Node* region1 = ifproj1->raw_out(0);\n-              if( region0 == region1 )\n-                add_users_to_worklist0(region0);\n-            }\n+void PhaseIterGVN::add_users_of_use_to_worklist(Node* n, Node* use, Unique_Node_List& worklist) {\n+  if(use->is_Multi() ||      \/\/ Multi-definer?  Push projs on worklist\n+      use->is_Store() )       \/\/ Enable store\/load same address\n+    add_users_to_worklist0(use, worklist);\n+\n+  \/\/ If we changed the receiver type to a call, we need to revisit\n+  \/\/ the Catch following the call.  It's looking for a non-null\n+  \/\/ receiver to know when to enable the regular fall-through path\n+  \/\/ in addition to the NullPtrException path.\n+  if (use->is_CallDynamicJava() && n == use->in(TypeFunc::Parms)) {\n+    Node* p = use->as_CallDynamicJava()->proj_out_or_null(TypeFunc::Control);\n+    if (p != nullptr) {\n+      add_users_to_worklist0(p, worklist);\n+    }\n+  }\n+\n+  uint use_op = use->Opcode();\n+  if(use->is_Cmp()) {       \/\/ Enable CMP\/BOOL optimization\n+    add_users_to_worklist0(use, worklist); \/\/ Put Bool on worklist\n+    if (use->outcnt() > 0) {\n+      Node* bol = use->raw_out(0);\n+      if (bol->outcnt() > 0) {\n+        Node* iff = bol->raw_out(0);\n+        if (iff->outcnt() == 2) {\n+          \/\/ Look for the 'is_x2logic' pattern: \"x ? : 0 : 1\" and put the\n+          \/\/ phi merging either 0 or 1 onto the worklist\n+          Node* ifproj0 = iff->raw_out(0);\n+          Node* ifproj1 = iff->raw_out(1);\n+          if (ifproj0->outcnt() > 0 && ifproj1->outcnt() > 0) {\n+            Node* region0 = ifproj0->raw_out(0);\n+            Node* region1 = ifproj1->raw_out(0);\n+            if( region0 == region1 )\n+              add_users_to_worklist0(region0, worklist);\n@@ -1535,8 +1539,8 @@\n-      if (use_op == Op_CmpI || use_op == Op_CmpL) {\n-        Node* phi = countedloop_phi_from_cmp(use->as_Cmp(), n);\n-        if (phi != nullptr) {\n-          \/\/ Input to the cmp of a loop exit check has changed, thus\n-          \/\/ the loop limit may have changed, which can then change the\n-          \/\/ range values of the trip-count Phi.\n-          _worklist.push(phi);\n-        }\n+    }\n+    if (use_op == Op_CmpI || use_op == Op_CmpL) {\n+      Node* phi = countedloop_phi_from_cmp(use->as_Cmp(), n);\n+      if (phi != nullptr) {\n+        \/\/ Input to the cmp of a loop exit check has changed, thus\n+        \/\/ the loop limit may have changed, which can then change the\n+        \/\/ range values of the trip-count Phi.\n+        worklist.push(phi);\n@@ -1544,39 +1548,39 @@\n-      if (use_op == Op_CmpI) {\n-        Node* cmp = use;\n-        Node* in1 = cmp->in(1);\n-        Node* in2 = cmp->in(2);\n-        \/\/ Notify CmpI \/ If pattern from CastIINode::Value (left pattern).\n-        \/\/ Must also notify if in1 is modified and possibly turns into X (right pattern).\n-        \/\/\n-        \/\/ in1  in2                   in1  in2\n-        \/\/  |    |                     |    |\n-        \/\/  +--- | --+                 |    |\n-        \/\/  |    |   |                 |    |\n-        \/\/ CmpINode  |                CmpINode\n-        \/\/    |      |                   |\n-        \/\/ BoolNode  |                BoolNode\n-        \/\/    |      |        OR         |\n-        \/\/  IfNode   |                 IfNode\n-        \/\/    |      |                   |\n-        \/\/  IfProj   |                 IfProj   X\n-        \/\/    |      |                   |      |\n-        \/\/   CastIINode                 CastIINode\n-        \/\/\n-        if (in1 != in2) { \/\/ if they are equal, the CmpI can fold them away\n-          if (in1 == n) {\n-            \/\/ in1 modified -> could turn into X -> do traversal based on right pattern.\n-            for (DUIterator_Fast i2max, i2 = cmp->fast_outs(i2max); i2 < i2max; i2++) {\n-              Node* bol = cmp->fast_out(i2); \/\/ For each Bool\n-              if (bol->is_Bool()) {\n-                for (DUIterator_Fast i3max, i3 = bol->fast_outs(i3max); i3 < i3max; i3++) {\n-                  Node* iff = bol->fast_out(i3); \/\/ For each If\n-                  if (iff->is_If()) {\n-                    for (DUIterator_Fast i4max, i4 = iff->fast_outs(i4max); i4 < i4max; i4++) {\n-                      Node* if_proj = iff->fast_out(i4); \/\/ For each IfProj\n-                      assert(if_proj->is_IfProj(), \"If only has IfTrue and IfFalse as outputs\");\n-                      for (DUIterator_Fast i5max, i5 = if_proj->fast_outs(i5max); i5 < i5max; i5++) {\n-                        Node* castii = if_proj->fast_out(i5); \/\/ For each CastII\n-                        if (castii->is_CastII() &&\n-                            castii->as_CastII()->carry_dependency()) {\n-                          _worklist.push(castii);\n-                        }\n+    }\n+    if (use_op == Op_CmpI) {\n+      Node* cmp = use;\n+      Node* in1 = cmp->in(1);\n+      Node* in2 = cmp->in(2);\n+      \/\/ Notify CmpI \/ If pattern from CastIINode::Value (left pattern).\n+      \/\/ Must also notify if in1 is modified and possibly turns into X (right pattern).\n+      \/\/\n+      \/\/ in1  in2                   in1  in2\n+      \/\/  |    |                     |    |\n+      \/\/  +--- | --+                 |    |\n+      \/\/  |    |   |                 |    |\n+      \/\/ CmpINode  |                CmpINode\n+      \/\/    |      |                   |\n+      \/\/ BoolNode  |                BoolNode\n+      \/\/    |      |        OR         |\n+      \/\/  IfNode   |                 IfNode\n+      \/\/    |      |                   |\n+      \/\/  IfProj   |                 IfProj   X\n+      \/\/    |      |                   |      |\n+      \/\/   CastIINode                 CastIINode\n+      \/\/\n+      if (in1 != in2) { \/\/ if they are equal, the CmpI can fold them away\n+        if (in1 == n) {\n+          \/\/ in1 modified -> could turn into X -> do traversal based on right pattern.\n+          for (DUIterator_Fast i2max, i2 = cmp->fast_outs(i2max); i2 < i2max; i2++) {\n+            Node* bol = cmp->fast_out(i2); \/\/ For each Bool\n+            if (bol->is_Bool()) {\n+              for (DUIterator_Fast i3max, i3 = bol->fast_outs(i3max); i3 < i3max; i3++) {\n+                Node* iff = bol->fast_out(i3); \/\/ For each If\n+                if (iff->is_If()) {\n+                  for (DUIterator_Fast i4max, i4 = iff->fast_outs(i4max); i4 < i4max; i4++) {\n+                    Node* if_proj = iff->fast_out(i4); \/\/ For each IfProj\n+                    assert(if_proj->is_IfProj(), \"If only has IfTrue and IfFalse as outputs\");\n+                    for (DUIterator_Fast i5max, i5 = if_proj->fast_outs(i5max); i5 < i5max; i5++) {\n+                      Node* castii = if_proj->fast_out(i5); \/\/ For each CastII\n+                      if (castii->is_CastII() &&\n+                          castii->as_CastII()->carry_dependency()) {\n+                        worklist.push(castii);\n@@ -1589,14 +1593,14 @@\n-          } else {\n-            \/\/ Only in2 modified -> can assume X == in2 (left pattern).\n-            assert(n == in2, \"only in2 modified\");\n-            \/\/ Find all CastII with input in1.\n-            for (DUIterator_Fast jmax, j = in1->fast_outs(jmax); j < jmax; j++) {\n-              Node* castii = in1->fast_out(j);\n-              if (castii->is_CastII() && castii->as_CastII()->carry_dependency()) {\n-                \/\/ Find If.\n-                if (castii->in(0) != nullptr && castii->in(0)->in(0) != nullptr && castii->in(0)->in(0)->is_If()) {\n-                  Node* ifnode = castii->in(0)->in(0);\n-                  \/\/ Check that if connects to the cmp\n-                  if (ifnode->in(1) != nullptr && ifnode->in(1)->is_Bool() && ifnode->in(1)->in(1) == cmp) {\n-                    _worklist.push(castii);\n-                  }\n+          }\n+        } else {\n+          \/\/ Only in2 modified -> can assume X == in2 (left pattern).\n+          assert(n == in2, \"only in2 modified\");\n+          \/\/ Find all CastII with input in1.\n+          for (DUIterator_Fast jmax, j = in1->fast_outs(jmax); j < jmax; j++) {\n+            Node* castii = in1->fast_out(j);\n+            if (castii->is_CastII() && castii->as_CastII()->carry_dependency()) {\n+              \/\/ Find If.\n+              if (castii->in(0) != nullptr && castii->in(0)->in(0) != nullptr && castii->in(0)->in(0)->is_If()) {\n+                Node* ifnode = castii->in(0)->in(0);\n+                \/\/ Check that if connects to the cmp\n+                if (ifnode->in(1) != nullptr && ifnode->in(1)->is_Bool() && ifnode->in(1)->in(1) == cmp) {\n+                  worklist.push(castii);\n@@ -1610,0 +1614,1 @@\n+  }\n@@ -1611,23 +1616,7 @@\n-    \/\/ Inline type nodes can have other inline types as users. If an input gets\n-    \/\/ updated, make sure that inline type users get a chance for optimization.\n-    if (use->is_InlineType()) {\n-      for (DUIterator_Fast i2max, i2 = use->fast_outs(i2max); i2 < i2max; i2++) {\n-        Node* u = use->fast_out(i2);\n-        if (u->is_InlineType())\n-          _worklist.push(u);\n-      }\n-    }\n-    \/\/ If changed Cast input, notify down for Phi, Sub, and Xor - all do \"uncast\"\n-    \/\/ Patterns:\n-    \/\/ ConstraintCast+ -> Sub\n-    \/\/ ConstraintCast+ -> Phi\n-    \/\/ ConstraintCast+ -> Xor\n-    if (use->is_ConstraintCast()) {\n-      auto push_the_uses_to_worklist = [&](Node* n){\n-        if (n->is_Phi() || n->is_Sub() || n->Opcode() == Op_XorI || n->Opcode() == Op_XorL) {\n-          _worklist.push(n);\n-        }\n-      };\n-      auto is_boundary = [](Node* n){ return !n->is_ConstraintCast(); };\n-      use->visit_uses(push_the_uses_to_worklist, is_boundary);\n-\n+  \/\/ Inline type nodes can have other inline types as users. If an input gets\n+  \/\/ updated, make sure that inline type users get a chance for optimization.\n+  if (use->is_InlineType()) {\n+    for (DUIterator_Fast i2max, i2 = use->fast_outs(i2max); i2 < i2max; i2++) {\n+      Node* u = use->fast_out(i2);\n+      if (u->is_InlineType())\n+        worklist.push(u);\n@@ -1635,6 +1624,10 @@\n-    \/\/ If changed LShift inputs, check RShift users for useless sign-ext\n-    if( use_op == Op_LShiftI ) {\n-      for (DUIterator_Fast i2max, i2 = use->fast_outs(i2max); i2 < i2max; i2++) {\n-        Node* u = use->fast_out(i2);\n-        if (u->Opcode() == Op_RShiftI)\n-          _worklist.push(u);\n+  }\n+  \/\/ If changed Cast input, notify down for Phi, Sub, and Xor - all do \"uncast\"\n+  \/\/ Patterns:\n+  \/\/ ConstraintCast+ -> Sub\n+  \/\/ ConstraintCast+ -> Phi\n+  \/\/ ConstraintCast+ -> Xor\n+  if (use->is_ConstraintCast()) {\n+    auto push_the_uses_to_worklist = [&](Node* n){\n+      if (n->is_Phi() || n->is_Sub() || n->Opcode() == Op_XorI || n->Opcode() == Op_XorL) {\n+        worklist.push(n);\n@@ -1642,8 +1635,18 @@\n-    }\n-    \/\/ If changed LShift inputs, check And users for shift and mask (And) operation\n-    if (use_op == Op_LShiftI || use_op == Op_LShiftL) {\n-      for (DUIterator_Fast i2max, i2 = use->fast_outs(i2max); i2 < i2max; i2++) {\n-        Node* u = use->fast_out(i2);\n-        if (u->Opcode() == Op_AndI || u->Opcode() == Op_AndL) {\n-          _worklist.push(u);\n-        }\n+    };\n+    auto is_boundary = [](Node* n){ return !n->is_ConstraintCast(); };\n+    use->visit_uses(push_the_uses_to_worklist, is_boundary);\n+  }\n+  \/\/ If changed LShift inputs, check RShift users for useless sign-ext\n+  if( use_op == Op_LShiftI ) {\n+    for (DUIterator_Fast i2max, i2 = use->fast_outs(i2max); i2 < i2max; i2++) {\n+      Node* u = use->fast_out(i2);\n+      if (u->Opcode() == Op_RShiftI)\n+        worklist.push(u);\n+    }\n+  }\n+  \/\/ If changed LShift inputs, check And users for shift and mask (And) operation\n+  if (use_op == Op_LShiftI || use_op == Op_LShiftL) {\n+    for (DUIterator_Fast i2max, i2 = use->fast_outs(i2max); i2 < i2max; i2++) {\n+      Node* u = use->fast_out(i2);\n+      if (u->Opcode() == Op_AndI || u->Opcode() == Op_AndL) {\n+        worklist.push(u);\n@@ -1652,7 +1655,7 @@\n-    \/\/ If changed AddI\/SubI inputs, check CmpU for range check optimization.\n-    if (use_op == Op_AddI || use_op == Op_SubI) {\n-      for (DUIterator_Fast i2max, i2 = use->fast_outs(i2max); i2 < i2max; i2++) {\n-        Node* u = use->fast_out(i2);\n-        if (u->is_Cmp() && (u->Opcode() == Op_CmpU)) {\n-          _worklist.push(u);\n-        }\n+  }\n+  \/\/ If changed AddI\/SubI inputs, check CmpU for range check optimization.\n+  if (use_op == Op_AddI || use_op == Op_SubI) {\n+    for (DUIterator_Fast i2max, i2 = use->fast_outs(i2max); i2 < i2max; i2++) {\n+      Node* u = use->fast_out(i2);\n+      if (u->is_Cmp() && (u->Opcode() == Op_CmpU)) {\n+        worklist.push(u);\n@@ -1661,7 +1664,7 @@\n-    \/\/ If changed AddP inputs, check Stores for loop invariant\n-    if( use_op == Op_AddP ) {\n-      for (DUIterator_Fast i2max, i2 = use->fast_outs(i2max); i2 < i2max; i2++) {\n-        Node* u = use->fast_out(i2);\n-        if (u->is_Mem())\n-          _worklist.push(u);\n-      }\n+  }\n+  \/\/ If changed AddP inputs, check Stores for loop invariant\n+  if( use_op == Op_AddP ) {\n+    for (DUIterator_Fast i2max, i2 = use->fast_outs(i2max); i2 < i2max; i2++) {\n+      Node* u = use->fast_out(i2);\n+      if (u->is_Mem())\n+        worklist.push(u);\n@@ -1669,7 +1672,7 @@\n-    \/\/ If changed initialization activity, check dependent Stores\n-    if (use_op == Op_Allocate || use_op == Op_AllocateArray) {\n-      InitializeNode* init = use->as_Allocate()->initialization();\n-      if (init != nullptr) {\n-        Node* imem = init->proj_out_or_null(TypeFunc::Memory);\n-        if (imem != nullptr)  add_users_to_worklist0(imem);\n-      }\n+  }\n+  \/\/ If changed initialization activity, check dependent Stores\n+  if (use_op == Op_Allocate || use_op == Op_AllocateArray) {\n+    InitializeNode* init = use->as_Allocate()->initialization();\n+    if (init != nullptr) {\n+      Node* imem = init->proj_out_or_null(TypeFunc::Memory);\n+      if (imem != nullptr) add_users_to_worklist0(imem, worklist);\n@@ -1677,8 +1680,8 @@\n-    \/\/ If the ValidLengthTest input changes then the fallthrough path out of the AllocateArray may have become dead.\n-    \/\/ CatchNode::Value() is responsible for killing that path. The CatchNode has to be explicitly enqueued for igvn\n-    \/\/ to guarantee the change is not missed.\n-    if (use_op == Op_AllocateArray && n == use->in(AllocateNode::ValidLengthTest)) {\n-      Node* p = use->as_AllocateArray()->proj_out_or_null(TypeFunc::Control);\n-      if (p != nullptr) {\n-        add_users_to_worklist0(p);\n-      }\n+  }\n+  \/\/ If the ValidLengthTest input changes then the fallthrough path out of the AllocateArray may have become dead.\n+  \/\/ CatchNode::Value() is responsible for killing that path. The CatchNode has to be explicitly enqueued for igvn\n+  \/\/ to guarantee the change is not missed.\n+  if (use_op == Op_AllocateArray && n == use->in(AllocateNode::ValidLengthTest)) {\n+    Node* p = use->as_AllocateArray()->proj_out_or_null(TypeFunc::Control);\n+    if (p != nullptr) {\n+      add_users_to_worklist0(p, worklist);\n@@ -1686,0 +1689,1 @@\n+  }\n@@ -1687,10 +1691,15 @@\n-    if (use_op == Op_Initialize) {\n-      Node* imem = use->as_Initialize()->proj_out_or_null(TypeFunc::Memory);\n-      if (imem != nullptr)  add_users_to_worklist0(imem);\n-    }\n-    if (use_op == Op_CastP2X) {\n-      for (DUIterator_Fast i2max, i2 = use->fast_outs(i2max); i2 < i2max; i2++) {\n-        Node* u = use->fast_out(i2);\n-        if (u->Opcode() == Op_AndX) {\n-          _worklist.push(u);\n-        }\n+  if (use_op == Op_Initialize) {\n+    Node* imem = use->as_Initialize()->proj_out_or_null(TypeFunc::Memory);\n+    if (imem != nullptr) add_users_to_worklist0(imem, worklist);\n+  }\n+  \/\/ Loading the java mirror from a Klass requires two loads and the type\n+  \/\/ of the mirror load depends on the type of 'n'. See LoadNode::Value().\n+  \/\/   LoadBarrier?(LoadP(LoadP(AddP(foo:Klass, #java_mirror))))\n+  BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();\n+  bool has_load_barrier_nodes = bs->has_load_barrier_nodes();\n+\n+  if (use_op == Op_CastP2X) {\n+    for (DUIterator_Fast i2max, i2 = use->fast_outs(i2max); i2 < i2max; i2++) {\n+      Node* u = use->fast_out(i2);\n+      if (u->Opcode() == Op_AndX) {\n+        worklist.push(u);\n@@ -1699,18 +1708,12 @@\n-    \/\/ Loading the java mirror from a Klass requires two loads and the type\n-    \/\/ of the mirror load depends on the type of 'n'. See LoadNode::Value().\n-    \/\/   LoadBarrier?(LoadP(LoadP(AddP(foo:Klass, #java_mirror))))\n-    BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();\n-    bool has_load_barrier_nodes = bs->has_load_barrier_nodes();\n-\n-    if (use_op == Op_LoadP && use->bottom_type()->isa_rawptr()) {\n-      for (DUIterator_Fast i2max, i2 = use->fast_outs(i2max); i2 < i2max; i2++) {\n-        Node* u = use->fast_out(i2);\n-        const Type* ut = u->bottom_type();\n-        if (u->Opcode() == Op_LoadP && ut->isa_instptr()) {\n-          if (has_load_barrier_nodes) {\n-            \/\/ Search for load barriers behind the load\n-            for (DUIterator_Fast i3max, i3 = u->fast_outs(i3max); i3 < i3max; i3++) {\n-              Node* b = u->fast_out(i3);\n-              if (bs->is_gc_barrier_node(b)) {\n-                _worklist.push(b);\n-              }\n+  }\n+  if (use_op == Op_LoadP && use->bottom_type()->isa_rawptr()) {\n+    for (DUIterator_Fast i2max, i2 = use->fast_outs(i2max); i2 < i2max; i2++) {\n+      Node* u = use->fast_out(i2);\n+      const Type* ut = u->bottom_type();\n+      if (u->Opcode() == Op_LoadP && ut->isa_instptr()) {\n+        if (has_load_barrier_nodes) {\n+          \/\/ Search for load barriers behind the load\n+          for (DUIterator_Fast i3max, i3 = u->fast_outs(i3max); i3 < i3max; i3++) {\n+            Node* b = u->fast_out(i3);\n+            if (bs->is_gc_barrier_node(b)) {\n+              worklist.push(b);\n@@ -1719,1 +1722,1 @@\n-          _worklist.push(u);\n+        worklist.push(u);\n@@ -1723,10 +1726,9 @@\n-\n-    \/\/ Give CallStaticJavaNode::remove_useless_allocation a chance to run\n-    if (use->is_Region()) {\n-      Node* c = use;\n-      do {\n-        c = c->unique_ctrl_out_or_null();\n-      } while (c != nullptr && c->is_Region());\n-      if (c != nullptr && c->is_CallStaticJava() && c->as_CallStaticJava()->uncommon_trap_request() != 0) {\n-        _worklist.push(c);\n-      }\n+  }\n+  \/\/ Give CallStaticJavaNode::remove_useless_allocation a chance to run\n+  if (use->is_Region()) {\n+    Node* c = use;\n+    do {\n+      c = c->unique_ctrl_out_or_null();\n+    } while (c != nullptr && c->is_Region());\n+    if (c != nullptr && c->is_CallStaticJava() && c->as_CallStaticJava()->uncommon_trap_request() != 0) {\n+      worklist.push(c);\n@@ -1734,6 +1736,6 @@\n-    if (use->Opcode() == Op_OpaqueZeroTripGuard) {\n-      assert(use->outcnt() <= 1, \"OpaqueZeroTripGuard can't be shared\");\n-      if (use->outcnt() == 1) {\n-        Node* cmp = use->unique_out();\n-        _worklist.push(cmp);\n-      }\n+  }\n+  if (use->Opcode() == Op_OpaqueZeroTripGuard) {\n+    assert(use->outcnt() <= 1, \"OpaqueZeroTripGuard can't be shared\");\n+    if (use->outcnt() == 1) {\n+      Node* cmp = use->unique_out();\n+      worklist.push(cmp);\n","filename":"src\/hotspot\/share\/opto\/phaseX.cpp","additions":211,"deletions":209,"binary":false,"changes":420,"status":"modified"},{"patch":"@@ -531,2 +531,3 @@\n-  void add_users_to_worklist0( Node *n );\n-  void add_users_to_worklist ( Node *n );\n+  static void add_users_to_worklist0(Node* n, Unique_Node_List& worklist);\n+  static void add_users_of_use_to_worklist(Node* n, Node* use, Unique_Node_List& worklist);\n+  void add_users_to_worklist(Node* n);\n","filename":"src\/hotspot\/share\/opto\/phaseX.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -154,6 +154,6 @@\n-          Node* prev = stack.node_at(stack.size() - 2);\n-          for (uint j = 1; j < region->req(); ++j) {\n-            if (n->in(j) == prev) {\n-              Node* in = region->in(j);\n-              if (in != nullptr && !in->is_top()) {\n-                if (is_dominator(ctl, in)) {\n+          if (n->req() == region->req()) { \/\/ ignore dead phis\n+            Node* prev = stack.node_at(stack.size() - 2);\n+            for (uint j = 1; j < region->req(); ++j) {\n+              if (n->in(j) == prev) {\n+                Node* in = region->in(j);\n+                if (in != nullptr && !in->is_top() && is_dominator(ctl, in)) {\n@@ -224,0 +224,1 @@\n+    uint index_before_clone = C->unique();\n@@ -253,0 +254,3 @@\n+          if (n->_idx < index_before_clone) {\n+            PhaseIterGVN::add_users_of_use_to_worklist(clone, n, *C->igvn_worklist());\n+          }\n","filename":"src\/hotspot\/share\/opto\/replacednodes.cpp","additions":10,"deletions":6,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -3051,1 +3051,1 @@\n-  if (DumpSharedSpaces) {\n+  if (CDSConfig::is_dumping_static_archive()) {\n@@ -3813,1 +3813,2 @@\n-  if (DumpSharedSpaces) {\n+  if (CDSConfig::is_dumping_static_archive()) {\n+    \/\/ We do this so that the default CDS archive can be deterministic.\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1714,41 +1714,3 @@\n-  JavaThread* current_thread = JavaThread::current();\n-  HandleMark hm(current_thread);\n-\n-  JvmtiVTMSTransitionDisabler disabler(thread);\n-  ThreadsListHandle tlh(current_thread);\n-\n-  JavaThread* java_thread = nullptr;\n-  oop thread_obj = nullptr;\n-  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n-  if (err != JVMTI_ERROR_NONE) {\n-    return err;\n-  }\n-\n-  if (java_lang_VirtualThread::is_instance(thread_obj)) {\n-    if (java_thread == nullptr) {  \/\/ Target virtual thread is unmounted.\n-      ResourceMark rm(current_thread);\n-\n-      VM_VirtualThreadGetStackTrace op(this, Handle(current_thread, thread_obj),\n-                                       start_depth, max_frame_count,\n-                                       frame_buffer, count_ptr);\n-      VMThread::execute(&op);\n-      return op.result();\n-    }\n-    VirtualThreadGetStackTraceClosure op(this, Handle(current_thread, thread_obj),\n-                                         start_depth, max_frame_count, frame_buffer, count_ptr);\n-    Handshake::execute(&op, java_thread);\n-    return op.result();\n-  }\n-\n-  \/\/ It is only safe to perform the direct operation on the current\n-  \/\/ thread. All other usage needs to use a direct handshake for safety.\n-  if (java_thread == JavaThread::current()) {\n-    err = get_stack_trace(java_thread, start_depth, max_frame_count, frame_buffer, count_ptr);\n-  } else {\n-    \/\/ Get stack trace with handshake.\n-    GetStackTraceClosure op(this, start_depth, max_frame_count, frame_buffer, count_ptr);\n-    Handshake::execute(&op, java_thread);\n-    err = op.result();\n-  }\n-\n-  return err;\n+  GetStackTraceClosure op(this, start_depth, max_frame_count, frame_buffer, count_ptr);\n+  JvmtiHandshake::execute(&op, thread);\n+  return op.result();\n@@ -1832,35 +1794,3 @@\n-  JavaThread* current_thread = JavaThread::current();\n-  HandleMark hm(current_thread);\n-\n-  JvmtiVTMSTransitionDisabler disabler(thread);\n-  ThreadsListHandle tlh(current_thread);\n-\n-  JavaThread* java_thread = nullptr;\n-  oop thread_obj = nullptr;\n-  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n-  if (err != JVMTI_ERROR_NONE) {\n-    return err;\n-  }\n-\n-  if (java_lang_VirtualThread::is_instance(thread_obj)) {\n-    if (java_thread == nullptr) {  \/\/ Target virtual thread is unmounted.\n-      VM_VirtualThreadGetFrameCount op(this, Handle(current_thread, thread_obj),  count_ptr);\n-      VMThread::execute(&op);\n-      return op.result();\n-    }\n-    VirtualThreadGetFrameCountClosure op(this, Handle(current_thread, thread_obj), count_ptr);\n-    Handshake::execute(&op, java_thread);\n-    return op.result();\n-  }\n-\n-  \/\/ It is only safe to perform the direct operation on the current\n-  \/\/ thread. All other usage needs to use a direct handshake for safety.\n-  if (java_thread == JavaThread::current()) {\n-    err = get_frame_count(java_thread, count_ptr);\n-  } else {\n-    \/\/ get java stack frame count with handshake.\n-    GetFrameCountClosure op(this, count_ptr);\n-    Handshake::execute(&op, java_thread);\n-    err = op.result();\n-  }\n-  return err;\n+  GetFrameCountClosure op(this, count_ptr);\n+  JvmtiHandshake::execute(&op, thread);\n+  return op.result();\n@@ -1926,35 +1856,3 @@\n-  JavaThread* current_thread = JavaThread::current();\n-  HandleMark hm(current_thread);\n-\n-  JvmtiVTMSTransitionDisabler disabler(thread);\n-  ThreadsListHandle tlh(current_thread);\n-\n-  JavaThread* java_thread = nullptr;\n-  oop thread_obj = nullptr;\n-  jvmtiError err = get_threadOop_and_JavaThread(tlh.list(), thread, &java_thread, &thread_obj);\n-  if (err != JVMTI_ERROR_NONE) {\n-    return err;\n-  }\n-\n-  if (java_lang_VirtualThread::is_instance(thread_obj)) {\n-    if (java_thread == nullptr) {  \/\/ Target virtual thread is unmounted.\n-      err = get_frame_location(thread_obj, depth, method_ptr, location_ptr);\n-      return err;\n-    }\n-    VirtualThreadGetFrameLocationClosure op(this, Handle(current_thread, thread_obj),\n-                                            depth, method_ptr, location_ptr);\n-    Handshake::execute(&op, java_thread);\n-    return op.result();\n-  }\n-\n-  \/\/ It is only safe to perform the direct operation on the current\n-  \/\/ thread. All other usage needs to use a direct handshake for safety.\n-  if (java_thread == JavaThread::current()) {\n-    err = get_frame_location(java_thread, depth, method_ptr, location_ptr);\n-  } else {\n-    \/\/ JVMTI get java stack frame location via direct handshake.\n-    GetFrameLocationClosure op(this, depth, method_ptr, location_ptr);\n-    Handshake::execute(&op, java_thread);\n-    err = op.result();\n-  }\n-  return err;\n+  GetFrameLocationClosure op(this, depth, method_ptr, location_ptr);\n+  JvmtiHandshake::execute(&op, thread);\n+  return op.result();\n@@ -1987,12 +1885,0 @@\n-  if (java_lang_VirtualThread::is_instance(thread_handle())) {\n-    VirtualThreadSetFramePopClosure op(this, thread_handle, state, depth);\n-    MutexLocker mu(current, JvmtiThreadState_lock);\n-    if (java_thread == nullptr || java_thread == current) {\n-      \/\/ Target virtual thread is unmounted or current.\n-      op.doit(java_thread, true \/* self *\/);\n-    } else {\n-      Handshake::execute(&op, java_thread);\n-    }\n-    return op.result();\n-  }\n-\n@@ -2001,5 +1887,1 @@\n-  if (java_thread == current) {\n-    op.doit(java_thread, true \/* self *\/);\n-  } else {\n-    Handshake::execute(&op, java_thread);\n-  }\n+  JvmtiHandshake::execute(&op, &tlh, java_thread, thread_handle);\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnv.cpp","additions":10,"deletions":128,"binary":false,"changes":138,"status":"modified"},{"patch":"@@ -1855,1 +1855,1 @@\n-  return ObjectSynchronizer::request_deflate_idle_monitors();\n+  return ObjectSynchronizer::request_deflate_idle_monitors_from_wb();\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -533,0 +533,1 @@\n+  { \"UseCounterDecay\",              JDK_Version::undefined(), JDK_Version::jdk(22), JDK_Version::jdk(23) },\n@@ -2691,1 +2692,1 @@\n-      DumpSharedSpaces = true;\n+      CDSConfig::enable_dumping_static_archive();\n@@ -3134,1 +3135,1 @@\n-  if (DumpSharedSpaces) {\n+  if (CDSConfig::is_dumping_static_archive()) {\n@@ -3181,1 +3182,1 @@\n-  if (UseSharedSpaces && !DumpSharedSpaces && check_unsupported_cds_runtime_properties()) {\n+  if (UseSharedSpaces && check_unsupported_cds_runtime_properties()) {\n@@ -3462,1 +3463,1 @@\n-  if (DumpSharedSpaces) {\n+  if (CDSConfig::is_dumping_static_archive()) {\n@@ -3473,1 +3474,1 @@\n-  if (DumpSharedSpaces || UseSharedSpaces) {\n+  if (CDSConfig::is_dumping_static_archive() || UseSharedSpaces) {\n@@ -3543,1 +3544,1 @@\n-    if (DumpSharedSpaces) {\n+    if (CDSConfig::is_dumping_static_archive()) {\n@@ -3565,1 +3566,1 @@\n-    if (DumpSharedSpaces) {\n+    if (CDSConfig::is_dumping_static_archive()) {\n@@ -4007,6 +4008,0 @@\n-  if (CountCompiledCalls) {\n-    if (UseCounterDecay) {\n-      warning(\"UseCounterDecay disabled because CountCalls is set\");\n-      UseCounterDecay = false;\n-    }\n-  }\n@@ -4030,1 +4025,1 @@\n-  if (DumpSharedSpaces || RequireSharedSpaces) {\n+  if (CDSConfig::is_dumping_static_archive() || RequireSharedSpaces) {\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":9,"deletions":14,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -1241,3 +1241,0 @@\n-  product(bool, UseCounterDecay, true,                                      \\\n-          \"Adjust recompilation counters\")                                  \\\n-                                                                            \\\n@@ -1246,4 +1243,0 @@\n-                                                                            \\\n-  develop(intx, CounterDecayMinIntervalLength,   500,                       \\\n-          \"The minimum interval (in milliseconds) between invocation of \"   \\\n-          \"CounterDecay\")                                                   \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":0,"deletions":7,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"cds\/cdsConfig.hpp\"\n@@ -475,1 +476,1 @@\n-    \/\/ Ignore modules for DumpSharedSpaces because we do not have any package\n+    \/\/ Ignore modules for -Xshare:dump because we do not have any package\n@@ -477,1 +478,1 @@\n-    if (DumpSharedSpaces) {\n+    if (CDSConfig::is_dumping_static_archive()) {\n","filename":"src\/hotspot\/share\/runtime\/reflection.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -412,2 +412,1 @@\n-  static int c_calling_convention(const BasicType *sig_bt, VMRegPair *regs, VMRegPair *regs2,\n-                                  int total_args_passed);\n+  static int c_calling_convention(const BasicType *sig_bt, VMRegPair *regs, int total_args_passed);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -182,0 +182,1 @@\n+address StubRoutines::_method_entry_barrier = nullptr;\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -259,0 +259,2 @@\n+  static address _method_entry_barrier;\n+\n@@ -466,0 +468,2 @@\n+  static address method_entry_barrier() { return _method_entry_barrier; }\n+\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -66,39 +66,0 @@\n-class ObjectMonitorsHashtable::PtrList :\n-  public LinkedListImpl<ObjectMonitor*,\n-                        AnyObj::C_HEAP, mtThread,\n-                        AllocFailStrategy::RETURN_NULL> {};\n-\n-class CleanupObjectMonitorsHashtable: StackObj {\n- public:\n-  bool do_entry(void*& key, ObjectMonitorsHashtable::PtrList*& list) {\n-    list->clear();  \/\/ clear the LinkListNodes\n-    delete list;    \/\/ then delete the LinkedList\n-    return true;\n-  }\n-};\n-\n-ObjectMonitorsHashtable::~ObjectMonitorsHashtable() {\n-  CleanupObjectMonitorsHashtable cleanup;\n-  _ptrs->unlink(&cleanup);  \/\/ cleanup the LinkedLists\n-  delete _ptrs;             \/\/ then delete the hash table\n-}\n-\n-void ObjectMonitorsHashtable::add_entry(void* key, ObjectMonitor* om) {\n-  ObjectMonitorsHashtable::PtrList* list = get_entry(key);\n-  if (list == nullptr) {\n-    \/\/ Create new list and add it to the hash table:\n-    list = new (mtThread) ObjectMonitorsHashtable::PtrList;\n-    add_entry(key, list);\n-  }\n-  list->add(om);  \/\/ Add the ObjectMonitor to the list.\n-  _om_count++;\n-}\n-\n-bool ObjectMonitorsHashtable::has_entry(void* key, ObjectMonitor* om) {\n-  ObjectMonitorsHashtable::PtrList* list = get_entry(key);\n-  if (list == nullptr || list->find(om) == nullptr) {\n-    return false;\n-  }\n-  return true;\n-}\n-\n@@ -1134,6 +1095,3 @@\n-\/\/ Iterate ObjectMonitors where the owner == thread; this does NOT include\n-\/\/ ObjectMonitors where owner is set to a stack-lock address in thread.\n-\/\/\n-\/\/ This version of monitors_iterate() works with the in-use monitor list.\n-\/\/\n-void ObjectSynchronizer::monitors_iterate(MonitorClosure* closure, JavaThread* thread) {\n+\/\/ Iterate over all ObjectMonitors.\n+template <typename Function>\n+void ObjectSynchronizer::monitors_iterate(Function function) {\n@@ -1142,17 +1100,2 @@\n-    ObjectMonitor* mid = iter.next();\n-    if (mid->owner() != thread) {\n-      \/\/ Not owned by the target thread and intentionally skips when owner\n-      \/\/ is set to a stack-lock address in the target thread.\n-      continue;\n-    }\n-    if (!mid->is_being_async_deflated() && mid->object_peek() != nullptr) {\n-      \/\/ Only process with closure if the object is set.\n-\n-      \/\/ monitors_iterate() is only called at a safepoint or when the\n-      \/\/ target thread is suspended or when the target thread is\n-      \/\/ operating on itself. The current closures in use today are\n-      \/\/ only interested in an owned ObjectMonitor and ownership\n-      \/\/ cannot be dropped under the calling contexts so the\n-      \/\/ ObjectMonitor cannot be async deflated.\n-      closure->do_monitor(mid);\n-    }\n+    ObjectMonitor* monitor = iter.next();\n+    function(monitor);\n@@ -1162,21 +1105,16 @@\n-\/\/ This version of monitors_iterate() works with the specified linked list.\n-\/\/\n-void ObjectSynchronizer::monitors_iterate(MonitorClosure* closure,\n-                                          ObjectMonitorsHashtable::PtrList* list,\n-                                          JavaThread* thread) {\n-  typedef LinkedListIterator<ObjectMonitor*> ObjectMonitorIterator;\n-  ObjectMonitorIterator iter(list->head());\n-  while (!iter.is_empty()) {\n-    ObjectMonitor* mid = *iter.next();\n-    \/\/ Owner set to a stack-lock address in thread should never be seen here:\n-    assert(mid->owner() == thread, \"must be\");\n-    if (!mid->is_being_async_deflated() && mid->object_peek() != nullptr) {\n-      \/\/ Only process with closure if the object is set.\n-\n-      \/\/ monitors_iterate() is only called at a safepoint or when the\n-      \/\/ target thread is suspended or when the target thread is\n-      \/\/ operating on itself. The current closures in use today are\n-      \/\/ only interested in an owned ObjectMonitor and ownership\n-      \/\/ cannot be dropped under the calling contexts so the\n-      \/\/ ObjectMonitor cannot be async deflated.\n-      closure->do_monitor(mid);\n+\/\/ Iterate ObjectMonitors owned by any thread and where the owner `filter`\n+\/\/ returns true.\n+template <typename OwnerFilter>\n+void ObjectSynchronizer::owned_monitors_iterate_filtered(MonitorClosure* closure, OwnerFilter filter) {\n+  monitors_iterate([&](ObjectMonitor* monitor) {\n+    \/\/ This function is only called at a safepoint or when the\n+    \/\/ target thread is suspended or when the target thread is\n+    \/\/ operating on itself. The current closures in use today are\n+    \/\/ only interested in an owned ObjectMonitor and ownership\n+    \/\/ cannot be dropped under the calling contexts so the\n+    \/\/ ObjectMonitor cannot be async deflated.\n+    if (monitor->has_owner() && filter(monitor->owner_raw())) {\n+      assert(!monitor->is_being_async_deflated(), \"Owned monitors should not be deflating\");\n+      assert(monitor->object_peek() != nullptr, \"Owned monitors should not have a dead object\");\n+\n+      closure->do_monitor(monitor);\n@@ -1184,1 +1122,14 @@\n-  }\n+  });\n+}\n+\n+\/\/ Iterate ObjectMonitors where the owner == thread; this does NOT include\n+\/\/ ObjectMonitors where owner is set to a stack-lock address in thread.\n+void ObjectSynchronizer::owned_monitors_iterate(MonitorClosure* closure, JavaThread* thread) {\n+  auto thread_filter = [&](void* owner) { return owner == thread; };\n+  return owned_monitors_iterate_filtered(closure, thread_filter);\n+}\n+\n+\/\/ Iterate ObjectMonitors owned by any thread.\n+void ObjectSynchronizer::owned_monitors_iterate(MonitorClosure* closure) {\n+  auto all_filter = [&](void* owner) { return true; };\n+  return owned_monitors_iterate_filtered(closure, all_filter);\n@@ -1291,1 +1242,7 @@\n-bool ObjectSynchronizer::request_deflate_idle_monitors() {\n+void ObjectSynchronizer::request_deflate_idle_monitors() {\n+  MonitorLocker ml(MonitorDeflation_lock, Mutex::_no_safepoint_check_flag);\n+  set_is_async_deflation_requested(true);\n+  ml.notify_all();\n+}\n+\n+bool ObjectSynchronizer::request_deflate_idle_monitors_from_wb() {\n@@ -1296,5 +1253,3 @@\n-  set_is_async_deflation_requested(true);\n-  {\n-    MonitorLocker ml(MonitorDeflation_lock, Mutex::_no_safepoint_check_flag);\n-    ml.notify_all();\n-  }\n+\n+  request_deflate_idle_monitors();\n+\n@@ -1621,9 +1576,1 @@\n-\/\/ If table != nullptr, we gather owned ObjectMonitors indexed by the\n-\/\/ owner in the table. Please note that ObjectMonitors where the owner\n-\/\/ is set to a stack-lock address are NOT associated with the JavaThread\n-\/\/ that holds that stack-lock. All of the current consumers of\n-\/\/ ObjectMonitorsHashtable info only care about JNI locked monitors and\n-\/\/ those do not have the owner set to a stack-lock address.\n-\/\/\n-                                                elapsedTimer* timer_p,\n-                                                ObjectMonitorsHashtable* table) {\n+                                                elapsedTimer* timer_p) {\n@@ -1641,12 +1588,0 @@\n-    } else if (table != nullptr) {\n-      \/\/ The caller is interested in the owned ObjectMonitors. This does\n-      \/\/ not include when owner is set to a stack-lock address in thread.\n-      \/\/ This also does not capture unowned ObjectMonitors that cannot be\n-      \/\/ deflated because of a waiter.\n-      void* key = mid->owner();\n-      \/\/ Since deflate_idle_monitors() and deflate_monitor_list() can be\n-      \/\/ called more than once, we have to make sure the entry has not\n-      \/\/ already been added.\n-      if (key != nullptr && !table->has_entry(key, mid)) {\n-        table->add_entry(key, mid);\n-      }\n@@ -1696,3 +1631,2 @@\n-\/\/ ObjectMonitors. It is also called via do_final_audit_and_print_stats()\n-\/\/ and VM_ThreadDump::doit() by the VMThread.\n-size_t ObjectSynchronizer::deflate_idle_monitors(ObjectMonitorsHashtable* table) {\n+\/\/ ObjectMonitors.\n+size_t ObjectSynchronizer::deflate_idle_monitors() {\n@@ -1723,1 +1657,1 @@\n-  size_t deflated_count = deflate_monitor_list(current, ls, &timer, table);\n+  size_t deflated_count = deflate_monitor_list(current, ls, &timer);\n@@ -1726,5 +1660,2 @@\n-  if (deflated_count > 0 || is_final_audit()) {\n-    \/\/ There are ObjectMonitors that have been deflated or this is the\n-    \/\/ final audit and all the remaining ObjectMonitors have been\n-    \/\/ deflated, BUT the MonitorDeflationThread blocked for the final\n-    \/\/ safepoint during unlinking.\n+  if (deflated_count > 0) {\n+    \/\/ There are ObjectMonitors that have been deflated.\n@@ -1805,4 +1736,0 @@\n-    if (table != nullptr) {\n-      ls->print_cr(\"ObjectMonitorsHashtable: key_count=\" SIZE_FORMAT \", om_count=\" SIZE_FORMAT,\n-                   table->key_count(), table->om_count());\n-    }\n@@ -1861,1 +1788,1 @@\n-  ObjectSynchronizer::monitors_iterate(&rjmc, current);\n+  ObjectSynchronizer::owned_monitors_iterate(&rjmc, current);\n@@ -1915,6 +1842,0 @@\n-    \/\/ Do deflations in order to reduce the in-use monitor population\n-    \/\/ that is reported by ObjectSynchronizer::log_in_use_monitor_details()\n-    \/\/ which is called by ObjectSynchronizer::audit_and_print_stats().\n-    while (deflate_idle_monitors(\/* ObjectMonitorsHashtable is not needed here *\/ nullptr) > 0) {\n-      ; \/\/ empty\n-    }\n@@ -1969,1 +1890,1 @@\n-    log_in_use_monitor_details(ls);\n+    log_in_use_monitor_details(ls, !on_exit \/* log_all *\/);\n@@ -2049,2 +1970,1 @@\n-void ObjectSynchronizer::log_in_use_monitor_details(outputStream* out) {\n-  stringStream ss;\n+void ObjectSynchronizer::log_in_use_monitor_details(outputStream* out, bool log_all) {\n@@ -2052,0 +1972,1 @@\n+    stringStream ss;\n@@ -2057,12 +1978,18 @@\n-    MonitorList::Iterator iter = _in_use_list.iterator();\n-    while (iter.has_next()) {\n-      ObjectMonitor* mid = iter.next();\n-      const oop obj = mid->object_peek();\n-      const markWord mark = mid->header();\n-      ResourceMark rm;\n-      out->print(INTPTR_FORMAT \"  %d%d%d  \" INTPTR_FORMAT \"  %s\", p2i(mid),\n-                 mid->is_busy(), mark.hash() != 0, mid->owner() != nullptr,\n-                 p2i(obj), obj == nullptr ? \"\" : obj->klass()->external_name());\n-      if (mid->is_busy()) {\n-        out->print(\" (%s)\", mid->is_busy_to_string(&ss));\n-        ss.reset();\n+\n+    auto is_interesting = [&](ObjectMonitor* monitor) {\n+      return log_all || monitor->has_owner() || monitor->is_busy();\n+    };\n+\n+    monitors_iterate([&](ObjectMonitor* monitor) {\n+      if (is_interesting(monitor)) {\n+        const oop obj = monitor->object_peek();\n+        const markWord mark = monitor->header();\n+        ResourceMark rm;\n+        out->print(INTPTR_FORMAT \"  %d%d%d  \" INTPTR_FORMAT \"  %s\", p2i(monitor),\n+                   monitor->is_busy(), mark.hash() != 0, monitor->owner() != nullptr,\n+                   p2i(obj), obj == nullptr ? \"\" : obj->klass()->external_name());\n+        if (monitor->is_busy()) {\n+          out->print(\" (%s)\", monitor->is_busy_to_string(&ss));\n+          ss.reset();\n+        }\n+        out->cr();\n@@ -2070,2 +1997,1 @@\n-      out->cr();\n-    }\n+    });\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":74,"deletions":148,"binary":false,"changes":222,"status":"modified"},{"patch":"@@ -84,2 +84,0 @@\n-  template(VirtualThreadGetStackTrace)            \\\n-  template(VirtualThreadGetFrameCount)            \\\n","filename":"src\/hotspot\/share\/runtime\/vmOperation.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -46,0 +46,1 @@\n+#include \"runtime\/objectMonitor.inline.hpp\"\n@@ -52,0 +53,1 @@\n+#include \"utilities\/ticks.hpp\"\n@@ -231,1 +233,0 @@\n-  _result = result;\n@@ -246,1 +247,0 @@\n-  _result = result;\n@@ -268,0 +268,99 @@\n+\/\/ Hash table of void* to a list of ObjectMonitor* owned by the JavaThread.\n+\/\/ The JavaThread's owner key is either a JavaThread* or a stack lock\n+\/\/ address in the JavaThread so we use \"void*\".\n+\/\/\n+class ObjectMonitorsDump : public MonitorClosure, public ObjectMonitorsView {\n+ private:\n+  static unsigned int ptr_hash(void* const& s1) {\n+    \/\/ 2654435761 = 2^32 * Phi (golden ratio)\n+    return (unsigned int)(((uint32_t)(uintptr_t)s1) * 2654435761u);\n+  }\n+\n+ private:\n+  class ObjectMonitorLinkedList :\n+    public LinkedListImpl<ObjectMonitor*,\n+                          AnyObj::C_HEAP, mtThread,\n+                          AllocFailStrategy::RETURN_NULL> {};\n+\n+  \/\/ ResourceHashtable SIZE is specified at compile time so we\n+  \/\/ use 1031 which is the first prime after 1024.\n+  typedef ResourceHashtable<void*, ObjectMonitorLinkedList*, 1031, AnyObj::C_HEAP, mtThread,\n+                            &ObjectMonitorsDump::ptr_hash> PtrTable;\n+  PtrTable* _ptrs;\n+  size_t _key_count;\n+  size_t _om_count;\n+\n+  void add_list(void* key, ObjectMonitorLinkedList* list) {\n+    _ptrs->put(key, list);\n+    _key_count++;\n+  }\n+\n+  ObjectMonitorLinkedList* get_list(void* key) {\n+    ObjectMonitorLinkedList** listpp = _ptrs->get(key);\n+    return (listpp == nullptr) ? nullptr : *listpp;\n+  }\n+\n+  void add(ObjectMonitor* monitor) {\n+    void* key = monitor->owner();\n+\n+    ObjectMonitorLinkedList* list = get_list(key);\n+    if (list == nullptr) {\n+      \/\/ Create new list and add it to the hash table:\n+      list = new (mtThread) ObjectMonitorLinkedList;\n+      _ptrs->put(key, list);\n+      _key_count++;\n+    }\n+\n+    assert(list->find(monitor) == nullptr, \"Should not contain duplicates\");\n+    list->add(monitor);  \/\/ Add the ObjectMonitor to the list.\n+    _om_count++;\n+  }\n+\n+ public:\n+  \/\/ ResourceHashtable is passed to various functions and populated in\n+  \/\/ different places so we allocate it using C_HEAP to make it immune\n+  \/\/ from any ResourceMarks that happen to be in the code paths.\n+  ObjectMonitorsDump() : _ptrs(new (mtThread) PtrTable), _key_count(0), _om_count(0) {}\n+\n+  ~ObjectMonitorsDump() {\n+    class CleanupObjectMonitorsDump: StackObj {\n+     public:\n+      bool do_entry(void*& key, ObjectMonitorLinkedList*& list) {\n+        list->clear();  \/\/ clear the LinkListNodes\n+        delete list;    \/\/ then delete the LinkedList\n+        return true;\n+      }\n+    } cleanup;\n+\n+    _ptrs->unlink(&cleanup);  \/\/ cleanup the LinkedLists\n+    delete _ptrs;             \/\/ then delete the hash table\n+  }\n+\n+  \/\/ Implements MonitorClosure used to collect all owned monitors in the system\n+  void do_monitor(ObjectMonitor* monitor) override {\n+    assert(monitor->has_owner(), \"Expects only owned monitors\");\n+\n+    if (monitor->is_owner_anonymous()) {\n+      \/\/ There's no need to collect anonymous owned monitors\n+      \/\/ because the caller of this code is only interested\n+      \/\/ in JNI owned monitors.\n+      return;\n+    }\n+\n+    add(monitor);\n+  }\n+\n+  \/\/ Implements the ObjectMonitorsView interface\n+  void visit(MonitorClosure* closure, JavaThread* thread) override {\n+    ObjectMonitorLinkedList* list = get_list(thread);\n+    LinkedListIterator<ObjectMonitor*> iter(list != nullptr ? list->head() : nullptr);\n+    while (!iter.is_empty()) {\n+      ObjectMonitor* monitor = *iter.next();\n+      closure->do_monitor(monitor);\n+    }\n+  }\n+\n+  size_t key_count() { return _key_count; }\n+  size_t om_count() { return _om_count; }\n+};\n+\n@@ -282,2 +381,1 @@\n-  ObjectMonitorsHashtable table;\n-  ObjectMonitorsHashtable* tablep = nullptr;\n+  ObjectMonitorsDump object_monitors;\n@@ -285,7 +383,12 @@\n-    \/\/ The caller wants locked monitor information and that's expensive to gather\n-    \/\/ when there are a lot of inflated monitors. So we deflate idle monitors and\n-    \/\/ gather information about owned monitors at the same time.\n-    tablep = &table;\n-    while (ObjectSynchronizer::deflate_idle_monitors(tablep) > 0) {\n-      ; \/* empty *\/\n-    }\n+    \/\/ Gather information about owned monitors.\n+    ObjectSynchronizer::owned_monitors_iterate(&object_monitors);\n+\n+    \/\/ If there are many object monitors in the system then the above iteration\n+    \/\/ can start to take time. Be friendly to following thread dumps by telling\n+    \/\/ the MonitorDeflationThread to deflate monitors.\n+    \/\/\n+    \/\/ This is trying to be somewhat backwards compatible with the previous\n+    \/\/ implementation, which performed monitor deflation right here. We might\n+    \/\/ want to reconsider the need to trigger monitor deflation from the thread\n+    \/\/ dumping and instead maybe tweak the deflation heuristics.\n+    ObjectSynchronizer::request_deflate_idle_monitors();\n@@ -308,1 +411,1 @@\n-      snapshot_thread(jt, tcl, tablep);\n+      snapshot_thread(jt, tcl, &object_monitors);\n@@ -343,1 +446,1 @@\n-      snapshot_thread(jt, tcl, tablep);\n+      snapshot_thread(jt, tcl, &object_monitors);\n@@ -349,1 +452,1 @@\n-                                    ObjectMonitorsHashtable* table) {\n+                                    ObjectMonitorsView* monitors) {\n@@ -351,1 +454,1 @@\n-  snapshot->dump_stack_at_safepoint(_max_depth, _with_locked_monitors, table, false);\n+  snapshot->dump_stack_at_safepoint(_max_depth, _with_locked_monitors, monitors, false);\n","filename":"src\/hotspot\/share\/runtime\/vmOperations.cpp","additions":118,"deletions":15,"binary":false,"changes":133,"status":"modified"},{"patch":"@@ -33,1 +33,1 @@\n-class ObjectMonitorsHashtable;\n+class ObjectMonitorsView;\n@@ -207,1 +207,1 @@\n-                       ObjectMonitorsHashtable* table);\n+                       ObjectMonitorsView* monitors);\n","filename":"src\/hotspot\/share\/runtime\/vmOperations.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -43,1 +43,0 @@\n-bool DumpSharedSpaces;\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -556,1 +556,0 @@\n-extern bool DumpSharedSpaces;\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -50,1 +50,0 @@\n-import jdk.internal.javac.PreviewFeature;\n@@ -424,1 +423,0 @@\n-   @PreviewFeature(feature=PreviewFeature.Feature.STRING_TEMPLATES)\n@@ -430,1 +428,0 @@\n-   @PreviewFeature(feature=PreviewFeature.Feature.STRING_TEMPLATES)\n@@ -435,2 +432,1 @@\n-     *\/\n-    @PreviewFeature(feature=PreviewFeature.Feature.STRING_TEMPLATES)\n+    *\/\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/access\/JavaLangAccess.java","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -73,1 +73,1 @@\n-        @JEP(number=430, title=\"String Templates\")\n+        @JEP(number=459, title=\"String Templates\", status=\"Second Preview\")\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/javac\/PreviewFeature.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -150,0 +150,1 @@\n+        java.desktop, \/\/ for ScopedValue\n","filename":"src\/java.base\/share\/classes\/module-info.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -180,0 +180,1 @@\n+         * @since 21\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/source\/tree\/Tree.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -275,0 +275,1 @@\n+     * @since 21\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/source\/tree\/TreeVisitor.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -661,0 +661,1 @@\n+     * @since 21\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/source\/util\/SimpleTreeVisitor.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -812,0 +812,1 @@\n+     * @since 21\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/source\/util\/TreeScanner.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -133,0 +133,1 @@\n+            values.add(LintCategory.INCUBATING);\n@@ -218,0 +219,5 @@\n+        \/**\n+         * Warn about use of incubating modules.\n+         *\/\n+        INCUBATING(\"incubating\"),\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Lint.java","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1733,1 +1733,1 @@\n-                    !areDisjoint((ClassSymbol)t.tsym, (ClassSymbol)s.tsym);\n+                    !(new DisjointChecker().areDisjoint((ClassSymbol)t.tsym, (ClassSymbol)s.tsym));\n@@ -1738,11 +1738,6 @@\n-        private boolean areDisjoint(ClassSymbol ts, ClassSymbol ss) {\n-            if (isSubtype(erasure(ts.type.referenceProjectionOrSelf()), erasure(ss.type))) {\n-                return false;\n-            }\n-            \/\/ if both are classes or both are interfaces, shortcut\n-            if (ts.isInterface() == ss.isInterface() && isSubtype(erasure(ss.type), erasure(ts.type))) {\n-                return false;\n-            }\n-            if (ts.isInterface() && !ss.isInterface()) {\n-                \/* so ts is interface but ss is a class\n-                 * an interface is disjoint from a class if the class is disjoint form the interface\n+        class DisjointChecker {\n+            Set<Pair<ClassSymbol, ClassSymbol>> pairsSeen = new HashSet<>();\n+            private boolean areDisjoint(ClassSymbol ts, ClassSymbol ss) {\n+                Pair<ClassSymbol, ClassSymbol> newPair = new Pair<>(ts, ss);\n+                \/* if we are seeing the same pair again then there is an issue with the sealed hierarchy\n+                 * bail out, a detailed error will be reported downstream\n@@ -1750,12 +1745,30 @@\n-                return areDisjoint(ss, ts);\n-            }\n-            \/\/ a final class that is not subtype of ss is disjoint\n-            if (!ts.isInterface() && ts.isFinal()) {\n-                return true;\n-            }\n-            \/\/ if at least one is sealed\n-            if (ts.isSealed() || ss.isSealed()) {\n-                \/\/ permitted subtypes have to be disjoint with the other symbol\n-                ClassSymbol sealedOne = ts.isSealed() ? ts : ss;\n-                ClassSymbol other = sealedOne == ts ? ss : ts;\n-                return sealedOne.permitted.stream().allMatch(sym -> areDisjoint((ClassSymbol)sym, other));\n+                if (!pairsSeen.add(newPair))\n+                    return false;\n+                if (isSubtype(erasure(ts.type.referenceProjectionOrSelf()), erasure(ss.type))) {\n+                    return false;\n+                }\n+                if (isSubtype(erasure(ts.type), erasure(ss.type))) {\n+                    return false;\n+                }\n+                \/\/ if both are classes or both are interfaces, shortcut\n+                if (ts.isInterface() == ss.isInterface() && isSubtype(erasure(ss.type), erasure(ts.type))) {\n+                    return false;\n+                }\n+                if (ts.isInterface() && !ss.isInterface()) {\n+                    \/* so ts is interface but ss is a class\n+                     * an interface is disjoint from a class if the class is disjoint form the interface\n+                     *\/\n+                    return areDisjoint(ss, ts);\n+                }\n+                \/\/ a final class that is not subtype of ss is disjoint\n+                if (!ts.isInterface() && ts.isFinal()) {\n+                    return true;\n+                }\n+                \/\/ if at least one is sealed\n+                if (ts.isSealed() || ss.isSealed()) {\n+                    \/\/ permitted subtypes have to be disjoint with the other symbol\n+                    ClassSymbol sealedOne = ts.isSealed() ? ts : ss;\n+                    ClassSymbol other = sealedOne == ts ? ss : ts;\n+                    return sealedOne.permitted.stream().allMatch(sym -> areDisjoint((ClassSymbol)sym, other));\n+                }\n+                return false;\n@@ -1763,1 +1776,0 @@\n-            return false;\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Types.java","additions":37,"deletions":25,"binary":false,"changes":62,"status":"modified"},{"patch":"@@ -5125,6 +5125,5 @@\n-        Type resultType = syms.stringTemplateType;\n-\n-        if (processor != null) {\n-            resultType = attribTree(processor, env, new ResultInfo(KindSelector.VAL, Type.noType));\n-            resultType = chk.checkProcessorType(processor, resultType, env);\n-        }\n+        Type processorType = attribTree(processor, env, new ResultInfo(KindSelector.VAL, Type.noType));\n+        chk.checkProcessorType(processor, processorType, env);\n+        Type processMethodType = getProcessMethodType(tree, processorType);\n+        tree.processMethodType = processMethodType;\n+        Type resultType = processMethodType.getReturnType();\n@@ -5140,1 +5139,0 @@\n-\n@@ -5144,0 +5142,7 @@\n+    private Type getProcessMethodType(JCStringTemplate tree, Type processorType) {\n+        MethodSymbol processSymbol = rs.resolveInternalMethod(tree.pos(),\n+                env, types.skipTypeVars(processorType, false),\n+                names.process, List.of(syms.stringTemplateType), List.nil());\n+        return types.memberType(processorType, processSymbol);\n+    }\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Attr.java","additions":12,"deletions":7,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -4627,2 +4627,1 @@\n-                log.error(DiagnosticFlag.RESOLVE_ERROR, processor.pos,\n-                        Errors.ProcessorTypeCannotBeARawType(processorType.tsym));\n+                resultType = syms.objectType;\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Check.java","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1683,17 +1683,2 @@\n-            JCExpression processor = tree.processor;\n-\n-            if (processor != null) {\n-                scan(processor);\n-                Type interfaceType = types.asSuper(processor.type, syms.processorType.tsym);\n-\n-                if (interfaceType != null) {\n-                    List<Type> typeArguments = interfaceType.getTypeArguments();\n-\n-                    if (typeArguments.size() == 2) {\n-                        Type throwType = typeArguments.tail.head;\n-\n-                        if (throwType != null) {\n-                            markThrown(tree, throwType);\n-                        }\n-                    }\n-                }\n+            for (Type thrown : tree.processMethodType.getThrownTypes()) {\n+                markThrown(tree, thrown);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Flow.java","additions":2,"deletions":17,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -1201,0 +1201,12 @@\n+    private boolean noClassDefIn(JCTree tree) {\n+        var scanner = new TreeScanner() {\n+            boolean noClassDef = true;\n+            @Override\n+            public void visitClassDef(JCClassDecl tree) {\n+                noClassDef = false;\n+            }\n+        };\n+        scanner.scan(tree);\n+        return scanner.noClassDef;\n+    }\n+\n@@ -3047,1 +3059,1 @@\n-        if (isTrue(cond)) {\n+        if (isTrue(cond) && noClassDefIn(tree.falsepart)) {\n@@ -3050,1 +3062,1 @@\n-        } else if (isFalse(cond)) {\n+        } else if (isFalse(cond) && noClassDefIn(tree.truepart)) {\n@@ -3074,1 +3086,1 @@\n-        if (isTrue(cond)) {\n+        if (isTrue(cond) && noClassDefIn(tree.elsepart)) {\n@@ -3077,1 +3089,1 @@\n-        } else if (isFalse(cond)) {\n+        } else if (isFalse(cond) && noClassDefIn(tree.thenpart)) {\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Lower.java","additions":16,"deletions":4,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -120,0 +120,1 @@\n+import com.sun.tools.javac.code.Lint;\n@@ -137,0 +138,1 @@\n+    private final Lint lint;\n@@ -188,0 +190,1 @@\n+        lint = Lint.instance(context);\n@@ -1355,4 +1358,5 @@\n-        String incubatingModules = filterAlreadyWarnedIncubatorModules(result.stream()\n-                .filter(msym -> msym.resolutionFlags.contains(ModuleResolutionFlags.WARN_INCUBATING))\n-                .map(msym -> msym.name.toString()))\n-                .collect(Collectors.joining(\",\"));\n+        if (lint.isEnabled(LintCategory.INCUBATING)) {\n+            String incubatingModules = filterAlreadyWarnedIncubatorModules(result.stream()\n+                    .filter(msym -> msym.resolutionFlags.contains(ModuleResolutionFlags.WARN_INCUBATING))\n+                    .map(msym -> msym.name.toString()))\n+                    .collect(Collectors.joining(\",\"));\n@@ -1360,2 +1364,3 @@\n-        if (!incubatingModules.isEmpty()) {\n-            log.warning(Warnings.IncubatingModules(incubatingModules));\n+            if (!incubatingModules.isEmpty()) {\n+                log.warning(Warnings.IncubatingModules(incubatingModules));\n+            }\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Modules.java","additions":11,"deletions":6,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -1363,4 +1363,0 @@\n-# 0: symbol\n-compiler.err.processor.type.cannot.be.a.raw.type=\\\n-    processor type cannot be a raw type: {0}\n-\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/resources\/compiler.properties","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -216,0 +216,3 @@\n+javac.opt.Xlint.desc.incubating=\\\n+    Warn about use of incubating modules.\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/resources\/javac.properties","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2562,0 +2562,1 @@\n+        public Type processMethodType;\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/tree\/JCTree.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1504,3 +1504,1 @@\n-            if (processor != null) {\n-                printExpr(processor);\n-            }\n+            printExpr(processor);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/tree\/Pretty.java","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -566,5 +566,1 @@\n-                if (node.processor == null) {\n-                    return node.pos;\n-                } else {\n-                    return getStartPos(node.processor);\n-                }\n+                return node.processor == null ? node.pos : getStartPos(node.processor);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/tree\/TreeInfo.java","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -54,2 +54,0 @@\n-compiler\/rangechecks\/TestRangeCheckHoistingScaledIV.java 8315969 generic-all\n-\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -407,0 +407,1 @@\n+ -runtime\/Monitor\/ConcurrentDeflation.java \\\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -36,1 +36,1 @@\n- *      -XX:+WhiteBoxAPI -XX:+TieredCompilation -XX:-UseCounterDecay\n+ *      -XX:+WhiteBoxAPI -XX:+TieredCompilation\n","filename":"test\/hotspot\/jtreg\/compiler\/tiered\/ConstantGettersTransitionsTest.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -597,1 +597,0 @@\n-    java\/util\/zip\/ZipFile\/TestTooManyEntries.java \\\n","filename":"test\/jdk\/TEST.groups","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"}]}