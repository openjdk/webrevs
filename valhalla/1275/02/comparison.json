{"files":[{"patch":"@@ -154,0 +154,13 @@\n+void BarrierSetAssembler::flat_field_copy(MacroAssembler* masm, DecoratorSet decorators,\n+                                     Register src, Register dst, Register inline_layout_info) {\n+  \/\/ flat_field_copy implementation is fairly complex, and there are not any\n+  \/\/ \"short-cuts\" to be made from asm. What there is, appears to have the same\n+  \/\/ cost in C++, so just \"call_VM_leaf\" for now rather than maintain hundreds\n+  \/\/ of hand-rolled instructions...\n+  if (decorators & IS_DEST_UNINITIALIZED) {\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, BarrierSetRuntime::value_copy_is_dest_uninitialized2), src, dst, inline_layout_info);\n+  } else {\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, BarrierSetRuntime::value_copy2), src, dst, inline_layout_info);\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.cpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -105,0 +105,2 @@\n+  virtual void flat_field_copy(MacroAssembler* masm, DecoratorSet decorators,\n+                          Register src, Register dst, Register inline_layout_info);\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -227,1 +227,1 @@\n-void InterpreterMacroAssembler::read_flat_field(Register holder_klass,\n+void InterpreterMacroAssembler::read_flat_field(Register entry,\n@@ -232,3 +232,4 @@\n-  const Register alloc_temp = rscratch1;\n-  const Register dst_temp   = temp;\n-  assert_different_registers(obj, holder_klass, field_index, field_offset, dst_temp);\n+  const Register alloc_temp = r10;\n+  const Register dst_temp   = field_index;\n+  const Register layout_info = temp;\n+  assert_different_registers(obj, entry, field_index, field_offset, temp, alloc_temp);\n@@ -237,3 +238,2 @@\n-  push(holder_klass);\n-  const Register field_klass = holder_klass;\n-  get_inline_type_field_klass(holder_klass, field_index, field_klass);\n+  ldr(rscratch1, Address(entry, in_bytes(ResolvedFieldEntry::field_holder_offset())));\n+  inline_layout_info(rscratch1, field_index, layout_info);\n@@ -241,2 +241,5 @@\n-  \/\/check for empty value klass\n-  test_klass_is_empty_inline_type(field_klass, dst_temp, empty_value);\n+  const Register field_klass = dst_temp;\n+  ldr(field_klass, Address(layout_info, in_bytes(InlineLayoutInfo::klass_offset())));\n+\n+  \/\/ check for empty value klass\n+  test_klass_is_empty_inline_type(field_klass, rscratch1, empty_value);\n@@ -246,1 +249,1 @@\n-  allocate_instance(field_klass, obj, alloc_temp, dst_temp, false, alloc_failed);\n+  allocate_instance(field_klass, obj, alloc_temp, rscratch2, false, alloc_failed);\n@@ -249,1 +252,1 @@\n-  data_for_oop(obj, dst_temp, field_klass);\n+  data_for_oop(obj, dst_temp, field_klass);  \/\/ danger, uses rscratch1\n@@ -254,1 +257,1 @@\n-  access_value_copy(IS_DEST_UNINITIALIZED, src, dst_temp, field_klass);\n+  flat_field_copy(IS_DEST_UNINITIALIZED, src, dst_temp, layout_info);\n@@ -256,1 +259,0 @@\n-  pop(holder_klass);\n@@ -260,2 +262,1 @@\n-  get_empty_inline_type_oop(field_klass, dst_temp, obj);\n-  pop(holder_klass);\n+  get_empty_inline_type_oop(field_klass, alloc_temp, obj);\n@@ -266,1 +267,0 @@\n-  pop(holder_klass);\n@@ -268,1 +268,1 @@\n-          obj, field_index, holder_klass);\n+          obj, entry);\n@@ -271,3 +271,0 @@\n-\n-  \/\/ Ensure the stores to copy the inline field contents are visible\n-  \/\/ before any subsequent store that publishes this reference.\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":17,"deletions":20,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -152,1 +152,1 @@\n-  void read_flat_field(Register holder_klass,\n+  void read_flat_field(Register entry,\n@@ -154,1 +154,1 @@\n-                       Register temp,  Register obj = r0);\n+                       Register temp, Register obj = r0);\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1179,0 +1179,1 @@\n+  assert_different_registers(inline_klass, temp_reg, obj, rscratch2);\n@@ -1190,1 +1191,1 @@\n-  ldr(offset, Address(offset, in_bytes(InlineKlass::default_value_offset_offset())));\n+  load_sized_value(offset, Address(offset, in_bytes(InlineKlass::default_value_offset_offset())), sizeof(int), true \/*is_signed*\/);\n@@ -1194,1 +1195,1 @@\n-  resolve_oop_handle(obj, inline_klass, temp_reg);\n+  resolve_oop_handle(obj, inline_klass, rscratch2);\n@@ -5415,0 +5416,6 @@\n+void MacroAssembler::flat_field_copy(DecoratorSet decorators, Register src, Register dst,\n+                                     Register inline_layout_info) {\n+  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+  bs->flat_field_copy(this, decorators, src, dst, inline_layout_info);\n+}\n+\n@@ -5660,8 +5667,14 @@\n-void MacroAssembler::get_inline_type_field_klass(Register klass, Register index, Register inline_klass) {\n-  ldr(inline_klass, Address(klass, InstanceKlass::inline_type_field_klasses_offset()));\n-#ifdef ASSERT\n-  {\n-    Label done;\n-    cbnz(inline_klass, done);\n-    stop(\"get_inline_type_field_klass contains no inline klass\");\n-    bind(done);\n+void MacroAssembler::get_inline_type_field_klass(Register holder_klass, Register index, Register inline_klass) {\n+  inline_layout_info(holder_klass, index, inline_klass);\n+  ldr(inline_klass, Address(inline_klass, InlineLayoutInfo::klass_offset()));\n+}\n+\n+void MacroAssembler::inline_layout_info(Register holder_klass, Register index, Register layout_info) {\n+  assert_different_registers(holder_klass, index, layout_info);\n+  InlineLayoutInfo array[2];\n+  int size = (char*)&array[1] - (char*)&array[0]; \/\/ computing size of array elements\n+  if (is_power_of_2(size)) {\n+    lsl(index, index, log2i_exact(size)); \/\/ Scale index by power of 2\n+  } else {\n+    mov(layout_info, size);\n+    mul(index, index, layout_info); \/\/ Scale the index to be the entry index * array_element_size\n@@ -5669,3 +5682,3 @@\n-#endif\n-  lea(inline_klass, Address(inline_klass, Array<InlineKlass*>::base_offset_in_bytes()));\n-  ldr(inline_klass, Address(inline_klass, index, Address::lsl(3)));\n+  ldr(layout_info, Address(holder_klass, InstanceKlass::inline_layout_info_array_offset()));\n+  add(layout_info, layout_info, Array<InlineLayoutInfo>::base_offset_in_bytes());\n+  lea(layout_info, Address(layout_info, index));\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":26,"deletions":13,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -930,0 +930,1 @@\n+  void flat_field_copy(DecoratorSet decorators, Register src, Register dst, Register inline_layout_info);\n@@ -1021,0 +1022,2 @@\n+  void inline_layout_info(Register holder_klass, Register index, Register layout_info);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2846,1 +2846,1 @@\n-          __ read_flat_field(klass, field_index, off, inline_klass \/* temp *\/, r0);\n+          __ read_flat_field(cache, field_index, off, inline_klass \/* temp *\/, r0);\n@@ -3122,1 +3122,4 @@\n-        \/\/ field is flat\n+        __ load_field_entry(cache, index); \/\/ reload field entry (cache) because it was erased by tos_state\n+        __ load_unsigned_short(index, Address(cache, in_bytes(ResolvedFieldEntry::field_index_offset())));\n+        __ ldr(r2, Address(cache, in_bytes(ResolvedFieldEntry::field_holder_offset())));\n+        __ inline_layout_info(r2, index, r6);\n@@ -3124,1 +3127,0 @@\n-        assert_different_registers(r0, inline_klass, obj, off);\n@@ -3128,1 +3130,2 @@\n-        __ access_value_copy(IN_HEAP, r0, obj, inline_klass);\n+        \/\/ because we use InlineLayoutInfo, we need special value access code specialized for fields (arrays will need a different API)\n+        __ flat_field_copy(IN_HEAP, r0, obj, r6);\n@@ -3364,0 +3367,4 @@\n+      __ load_field_entry(r4, r3);\n+      __ load_unsigned_short(r3, Address(r4, in_bytes(ResolvedFieldEntry::field_index_offset())));\n+      __ ldr(r4, Address(r4, in_bytes(ResolvedFieldEntry::field_holder_offset())));\n+      __ inline_layout_info(r4, r3, r5);\n@@ -3367,1 +3374,1 @@\n-      __ access_value_copy(IN_HEAP, r0, rscratch1, r4);\n+      __ flat_field_copy(IN_HEAP, r0, rscratch1, r5);\n@@ -3487,2 +3494,1 @@\n-        __ ldr(klass, Address(r2, in_bytes(ResolvedFieldEntry::field_holder_offset())));\n-        __ read_flat_field(klass, index, r1, tmp \/* temp *\/, r0);\n+        __ read_flat_field(r2, index, r1, tmp \/* temp *\/, r0);\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":13,"deletions":7,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -216,0 +216,13 @@\n+void BarrierSetAssembler::flat_field_copy(MacroAssembler* masm, DecoratorSet decorators,\n+                                     Register src, Register dst, Register inline_layout_info) {\n+  \/\/ flat_field_copy implementation is fairly complex, and there are not any\n+  \/\/ \"short-cuts\" to be made from asm. What there is, appears to have the same\n+  \/\/ cost in C++, so just \"call_VM_leaf\" for now rather than maintain hundreds\n+  \/\/ of hand-rolled instructions...\n+  if (decorators & IS_DEST_UNINITIALIZED) {\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, BarrierSetRuntime::value_copy_is_dest_uninitialized2), src, dst, inline_layout_info);\n+  } else {\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, BarrierSetRuntime::value_copy2), src, dst, inline_layout_info);\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetAssembler_x86.cpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -53,0 +53,2 @@\n+  virtual void flat_field_copy(MacroAssembler* masm, DecoratorSet decorators,\n+                          Register src, Register dst, Register inline_layout_info);\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetAssembler_x86.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1200,4 +1200,1 @@\n-\n-void InterpreterMacroAssembler::read_flat_field(Register holder_klass,\n-                                                Register field_index, Register field_offset,\n-                                                Register obj) {\n+void InterpreterMacroAssembler::read_flat_field(Register entry, Register tmp1, Register tmp2, Register obj) {\n@@ -1205,1 +1202,0 @@\n-  const Register src = field_offset;\n@@ -1208,1 +1204,4 @@\n-  assert_different_registers(obj, holder_klass, field_index, field_offset, dst_temp);\n+  assert_different_registers(obj, entry, tmp1, tmp2, dst_temp, r8, r9);\n+\n+  \/\/ FIXME: code below could be re-written to better use InlineLayoutInfo data structure\n+  \/\/ see aarch64 version\n@@ -1211,3 +1210,4 @@\n-  push(holder_klass);\n-  const Register field_klass = holder_klass;\n-  get_inline_type_field_klass(holder_klass, field_index, field_klass);\n+  const Register field_klass = tmp1;\n+  load_unsigned_short(tmp2, Address(entry, in_bytes(ResolvedFieldEntry::field_index_offset())));\n+  movptr(tmp1, Address(entry, ResolvedFieldEntry::field_holder_offset()));\n+  get_inline_type_field_klass(tmp1, tmp2, field_klass);\n@@ -1215,1 +1215,1 @@\n-  \/\/check for empty value klass\n+    \/\/check for empty value klass\n@@ -1219,1 +1219,1 @@\n-  push(obj); \/\/ save holder\n+  push(obj);  \/\/ push object being read from     \/\/ FIXME spilling on stack could probably be avoided by using tmp2\n@@ -1223,0 +1223,4 @@\n+  load_unsigned_short(r9, Address(entry, in_bytes(ResolvedFieldEntry::field_index_offset())));\n+  movptr(r8, Address(entry, in_bytes(ResolvedFieldEntry::field_holder_offset())));\n+  inline_layout_info(r8, r9, r8); \/\/ holder, index, info => InlineLayoutInfo into r8\n+\n@@ -1224,2 +1228,3 @@\n-  pop(alloc_temp);             \/\/ restore holder\n-  lea(src, Address(alloc_temp, field_offset));\n+  pop(alloc_temp);             \/\/ restore object being read from\n+  load_sized_value(tmp2, Address(entry, in_bytes(ResolvedFieldEntry::field_offset_offset())), sizeof(int), true \/*is_signed*\/);\n+  lea(tmp2, Address(alloc_temp, tmp2));\n@@ -1228,1 +1233,2 @@\n-  access_value_copy(IS_DEST_UNINITIALIZED, src, dst_temp, field_klass);\n+  \/\/ access_value_copy(IS_DEST_UNINITIALIZED, tmp2, dst_temp, field_klass);\n+  flat_field_copy(IS_DEST_UNINITIALIZED, tmp2, dst_temp, r8);\n@@ -1230,1 +1236,0 @@\n-  pop(holder_klass);\n@@ -1235,1 +1240,0 @@\n-  pop(holder_klass);\n@@ -1240,4 +1244,3 @@\n-  pop(holder_klass);\n-  call_VM(obj, CAST_FROM_FN_PTR(address, InterpreterRuntime::read_flat_field),\n-          obj, field_index, holder_klass);\n-\n+  call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::read_flat_field),\n+          obj, entry);\n+  get_vm_result(obj, r15_thread);\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":23,"deletions":20,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -215,1 +215,1 @@\n-  \/\/ Kills t1 and t2, perserves klass, return allocation in new_obj\n+  \/\/ Kills t1 and t2, preserves klass, return allocation in new_obj\n@@ -219,0 +219,1 @@\n+\n@@ -224,3 +225,2 @@\n-  \/\/   - 32 bits: kills rdi and rsi\n-  void read_flat_field(Register holder_klass,\n-                       Register field_index, Register field_offset,\n+  void read_flat_field(Register entry,\n+                       Register tmp1, Register tmp2,\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -4577,2 +4577,7 @@\n-void MacroAssembler::get_inline_type_field_klass(Register klass, Register index, Register inline_klass) {\n-  movptr(inline_klass, Address(klass, InstanceKlass::inline_type_field_klasses_offset()));\n+void MacroAssembler::get_inline_type_field_klass(Register holder_klass, Register index, Register inline_klass) {\n+  inline_layout_info(holder_klass, index, inline_klass);\n+  movptr(inline_klass, Address(inline_klass, InlineLayoutInfo::klass_offset()));\n+}\n+\n+void MacroAssembler::inline_layout_info(Register holder_klass, Register index, Register layout_info) {\n+  movptr(layout_info, Address(holder_klass, InstanceKlass::inline_layout_info_array_offset()));\n@@ -4582,1 +4587,1 @@\n-    cmpptr(inline_klass, 0);\n+    cmpptr(layout_info, 0);\n@@ -4584,1 +4589,1 @@\n-    stop(\"get_inline_type_field_klass contains no inline klass\");\n+    stop(\"inline_layout_info_array is null\");\n@@ -4588,1 +4593,9 @@\n-  movptr(inline_klass, Address(inline_klass, index, Address::times_ptr, Array<InlineKlass*>::base_offset_in_bytes()));\n+\n+  InlineLayoutInfo array[2];\n+  int size = (char*)&array[1] - (char*)&array[0]; \/\/ computing size of array elements\n+  if (is_power_of_2(size)) {\n+    shll(index, log2i_exact(size)); \/\/ Scale index by power of 2\n+  } else {\n+    imull(index, index, size); \/\/ Scale the index to be the entry index * array_element_size\n+  }\n+  lea(layout_info, Address(layout_info, index, Address::times_1, Array<InlineLayoutInfo>::base_offset_in_bytes()));\n@@ -6051,0 +6064,6 @@\n+void MacroAssembler::flat_field_copy(DecoratorSet decorators, Register src, Register dst,\n+                                     Register inline_layout_info) {\n+  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+  bs->flat_field_copy(this, decorators, src, dst, inline_layout_info);\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":24,"deletions":5,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -409,0 +409,3 @@\n+  void flat_field_copy(DecoratorSet decorators, Register src, Register dst, Register inline_layout_info);\n+  \/\/ We probably need the following for arrays:    TODO FIXME\n+  \/\/ void flat_element_copy(DecoratorSet decorators, Register src, Register dst, Register array);\n@@ -654,0 +657,2 @@\n+  void inline_layout_info(Register klass, Register index, Register layout_info);\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -3224,2 +3224,0 @@\n-          __ load_unsigned_short(rdx, Address(cache, in_bytes(ResolvedFieldEntry::field_index_offset())));\n-          __ movptr(rcx, Address(cache, ResolvedFieldEntry::field_holder_offset()));\n@@ -3549,4 +3547,5 @@\n-            pop_and_check_object(obj);\n-            assert_different_registers(rax, rdx, obj, off);\n-            __ load_klass(rdx, rax, rscratch1);\n-            __ data_for_oop(rax, rax, rdx);\n+            __ load_unsigned_short(rdx, Address(rcx, in_bytes(ResolvedFieldEntry::field_index_offset())));\n+            __ movptr(r9, Address(rcx, in_bytes(ResolvedFieldEntry::field_holder_offset())));\n+            pop_and_check_object(obj);  \/\/ obj = rcx\n+            __ load_klass(r8, rax, rscratch1);\n+            __ data_for_oop(rax, rax, r8);\n@@ -3554,1 +3553,3 @@\n-            __ access_value_copy(IN_HEAP, rax, obj, rdx);\n+            __ inline_layout_info(r9, rdx, rbx);\n+            \/\/ because we use InlineLayoutInfo, we need special value access code specialized for fields (arrays will need a different API)\n+            __ flat_field_copy(IN_HEAP, rax, obj, rbx);\n@@ -3800,1 +3801,4 @@\n-        \/\/ field is flat\n+        __ load_field_entry(r8, r9);\n+        __ load_unsigned_short(r9, Address(r8, in_bytes(ResolvedFieldEntry::field_index_offset())));\n+        __ movptr(r8, Address(r8, in_bytes(ResolvedFieldEntry::field_holder_offset())));\n+        __ inline_layout_info(r8, r9, r8);\n@@ -3804,1 +3808,1 @@\n-        __ access_value_copy(IN_HEAP, rax, rcx, rdx);\n+        __ flat_field_copy(IN_HEAP, rax, rcx, r8);\n@@ -3906,4 +3910,0 @@\n-        __ push(rdx); \/\/ save offset\n-        __ load_unsigned_short(rdx, Address(rcx, in_bytes(ResolvedFieldEntry::field_index_offset())));\n-        __ movptr(rcx, Address(rcx, ResolvedFieldEntry::field_holder_offset()));\n-        __ pop(rbx); \/\/ restore offset\n","filename":"src\/hotspot\/cpu\/x86\/templateTable_x86.cpp","additions":13,"deletions":13,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -374,1 +374,1 @@\n-  if (h->is_empty_inline_type()) {\n+  if (h->is_inline_klass() &&  InlineKlass::cast(h)->is_empty_inline_type()) {\n@@ -521,1 +521,1 @@\n-    array->value_copy_to_index(value, index);\n+    array->value_copy_to_index(value, index, LayoutKind::PAYLOAD); \/\/ Non atomic is currently the only layout supported by flat arrays\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -184,1 +184,3 @@\n-  f(InlineTypeReturnedAsFields)\n+  f(InlineTypeReturnedAsFields) \\\n+  f(AtomicFieldFlattening) \\\n+  f(NullableFieldFlattening)\n","filename":"src\/hotspot\/share\/cds\/filemap.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1509,1 +1509,0 @@\n-  int index = length;\n@@ -1537,3 +1536,2 @@\n-      fi.set_index(index);\n-      _temp_field_info->append(fi);\n-      index++;\n+      int idx = _temp_field_info->append(fi);\n+      _temp_field_info->adr_at(idx)->set_index(idx);\n@@ -1553,2 +1551,2 @@\n-    fi.set_index(index);\n-    _temp_field_info->append(fi);\n+    int idx = _temp_field_info->append(fi);\n+    _temp_field_info->adr_at(idx)->set_index(idx);\n@@ -1556,13 +1554,7 @@\n-    index++;\n-  }\n-\n-  if (is_inline_type && instance_fields_count == 0) {\n-    \/\/ Inject \".empty\" dummy field\n-    _is_empty_inline_type = true;\n-\n-    FieldInfo::FieldFlags fflags(0);\n-    fflags.update_injected(true);\n-    AccessFlags aflags;\n-    FieldInfo fi(aflags,\n-                 (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(empty_marker_name)),\n-                 (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(byte_signature)),\n+    \/\/ Inject static \".null_reset\" field. This is the same as the .default field but will never have its null-channel set to non-zero.\n+    FieldInfo::FieldFlags fflags2(0);\n+    fflags2.update_injected(true);\n+    AccessFlags aflags2(JVM_ACC_STATIC);\n+    FieldInfo fi2(aflags2,\n+                 (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(null_reset_value_name)),\n+                 (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(object_signature)),\n@@ -1570,9 +1562,4 @@\n-                 fflags);\n-    fi.set_index(index);\n-    _temp_field_info->append(fi);\n-\n-    index++;\n-  }\n-\n-  if (instance_fields_count > 0) {\n-    _has_nonstatic_fields = true;\n+                 fflags2);\n+    int idx2 = _temp_field_info->append(fi2);\n+    _temp_field_info->adr_at(idx2)->set_index(idx2);\n+    _static_oop_count++;\n@@ -1581,2 +1568,0 @@\n-  assert(_temp_field_info->length() == index, \"Must be\");\n-\n@@ -3917,2 +3902,1 @@\n-  this_klass->set_inline_type_field_klasses_array(_inline_type_field_klasses);\n-  this_klass->set_null_marker_offsets_array(_null_marker_offsets);\n+  this_klass->set_inline_layout_info_array(_inline_layout_info_array);\n@@ -5150,2 +5134,2 @@\n-  assert(_field_info != nullptr, \"invariant\");\n-  return _field_info->_static_field_size;\n+  assert(_layout_info != nullptr, \"invariant\");\n+  return _layout_info->_static_field_size;\n@@ -5155,2 +5139,2 @@\n-  assert(_field_info != nullptr, \"invariant\");\n-  return _field_info->oop_map_blocks->_nonstatic_oop_map_count;\n+  assert(_layout_info != nullptr, \"invariant\");\n+  return _layout_info->oop_map_blocks->_nonstatic_oop_map_count;\n@@ -5160,2 +5144,2 @@\n-  assert(_field_info != nullptr, \"invariant\");\n-  return _field_info->_instance_size;\n+  assert(_layout_info != nullptr, \"invariant\");\n+  return _layout_info->_instance_size;\n@@ -5297,3 +5281,3 @@\n-  assert(_field_info != nullptr, \"invariant\");\n-  assert(ik->static_field_size() == _field_info->_static_field_size, \"sanity\");\n-  assert(ik->nonstatic_oop_map_count() == _field_info->oop_map_blocks->_nonstatic_oop_map_count,\n+  assert(_layout_info != nullptr, \"invariant\");\n+  assert(ik->static_field_size() == _layout_info->_static_field_size, \"sanity\");\n+  assert(ik->nonstatic_oop_map_count() == _layout_info->oop_map_blocks->_nonstatic_oop_map_count,\n@@ -5303,1 +5287,1 @@\n-  assert(ik->size_helper() == _field_info->_instance_size, \"sanity\");\n+  assert(ik->size_helper() == _layout_info->_instance_size, \"sanity\");\n@@ -5309,3 +5293,4 @@\n-  ik->set_nonstatic_field_size(_field_info->_nonstatic_field_size);\n-  ik->set_has_nonstatic_fields(_field_info->_has_nonstatic_fields);\n-  if (_field_info->_is_naturally_atomic && ik->is_inline_klass()) {\n+  ik->set_nonstatic_field_size(_layout_info->_nonstatic_field_size);\n+  ik->set_has_nonstatic_fields(_layout_info->_has_nonstatic_fields);\n+\n+  if (_layout_info->_is_naturally_atomic) {\n@@ -5315,0 +5300,7 @@\n+  if (_layout_info->_must_be_atomic) {\n+    ik->set_must_be_atomic();\n+  }\n+  if (_is_implicitly_constructible) {\n+    ik->set_is_implicitly_constructible();\n+  }\n+\n@@ -5340,1 +5332,1 @@\n-  assert(nullptr == _inline_type_field_klasses, \"invariant\");\n+  assert(nullptr == _inline_layout_info_array, \"invariant\");\n@@ -5376,6 +5368,0 @@\n-  if (_must_be_atomic) {\n-    ik->set_must_be_atomic();\n-  }\n-  if (_is_implicitly_constructible) {\n-    ik->set_is_implicitly_constructible();\n-  }\n@@ -5424,1 +5410,1 @@\n-  OopMapBlocksBuilder* oop_map_blocks = _field_info->oop_map_blocks;\n+  OopMapBlocksBuilder* oop_map_blocks = _layout_info->oop_map_blocks;\n@@ -5486,19 +5472,0 @@\n-  bool all_fields_empty = true;\n-  for (AllFieldStream fs(ik); !fs.done(); fs.next()) {\n-    if (!fs.access_flags().is_static()) {\n-      if (fs.field_descriptor().is_null_free_inline_type()) {\n-        Klass* k = ik->inline_type_field_klasses_array()->at(fs.index());\n-        assert(k->is_inline_klass(), \"must be\");\n-        if (!InlineKlass::cast(k)->is_empty_inline_type()) { all_fields_empty = false; }\n-      } else {\n-        all_fields_empty = false;\n-      }\n-    } else if (is_inline_type() && (fs.name() == vmSymbols::default_value_name())) {\n-      InlineKlass::cast(ik)->set_default_value_offset(ik->field_offset(fs.index()));\n-    }\n-  }\n-\n-  if (_is_empty_inline_type || (is_inline_type() && all_fields_empty)) {\n-    ik->set_is_empty_inline_type();\n-  }\n-\n@@ -5507,5 +5474,12 @@\n-    vk->set_alignment(_alignment);\n-    vk->set_first_field_offset(_first_field_offset);\n-    vk->set_payload_size_in_bytes(_payload_size_in_bytes);\n-    vk->set_internal_null_marker_offset(_internal_null_marker_offset);\n-    InlineKlass::cast(ik)->initialize_calling_convention(CHECK);\n+    vk->set_payload_alignment(_layout_info->_payload_alignment);\n+    vk->set_first_field_offset(_layout_info->_first_field_offset);\n+    vk->set_payload_size_in_bytes(_layout_info->_payload_size_in_bytes);\n+    vk->set_non_atomic_size_in_bytes(_layout_info->_non_atomic_size_in_bytes);\n+    vk->set_non_atomic_alignment(_layout_info->_non_atomic_alignment);\n+    vk->set_atomic_size_in_bytes(_layout_info->_atomic_layout_size_in_bytes);\n+    vk->set_nullable_size_in_bytes(_layout_info->_nullable_layout_size_in_bytes);\n+    vk->set_null_marker_offset(_layout_info->_null_marker_offset);\n+    vk->set_default_value_offset(_layout_info->_default_value_offset);\n+    vk->set_null_reset_value_offset(_layout_info->_null_reset_value_offset);\n+    if (_layout_info->_is_empty_inline_klass) vk->set_is_empty_inline_type();\n+    vk->initialize_calling_convention(CHECK);\n@@ -5619,3 +5593,2 @@\n-  _field_info(nullptr),\n-  _inline_type_field_klasses(nullptr),\n-  _null_marker_offsets(nullptr),\n+  _layout_info(nullptr),\n+  _inline_layout_info_array(nullptr),\n@@ -5651,2 +5624,0 @@\n-  _has_nonstatic_fields(false),\n-  _is_empty_inline_type(false),\n@@ -5712,2 +5683,1 @@\n-  _inline_type_field_klasses = nullptr;\n-  _null_marker_offsets = nullptr;\n+  _inline_layout_info_array = nullptr;\n@@ -5732,6 +5702,2 @@\n-  if (_inline_type_field_klasses != nullptr) {\n-     MetadataFactory::free_array<InlineKlass*>(_loader_data, _inline_type_field_klasses);\n-  }\n-\n-  if (_null_marker_offsets != nullptr) {\n-     MetadataFactory::free_array<int>(_loader_data, _null_marker_offsets);\n+  if (_inline_layout_info_array != nullptr) {\n+    MetadataFactory::free_array<InlineLayoutInfo>(_loader_data, _inline_layout_info_array);\n@@ -6131,1 +6097,0 @@\n-  \/\/ Test might need extensions when field inheritance is added for value classes\n@@ -6135,0 +6100,5 @@\n+      \/\/ Conditions above are not sufficient to determine atomicity requirements,\n+      \/\/ the presence of fields with atomic requirements could force the current class to have atomicy requirements too\n+      \/\/ Marking as not needing atomicity for now, can be updated when computing the fields layout\n+      \/\/ The InstanceKlass must be filled with the value from the FieldLayoutInfo returned by\n+      \/\/ the FieldLayoutBuilder, not with this _must_be_atomic field.\n@@ -6231,1 +6201,1 @@\n-    _inline_type_field_klasses = MetadataFactory::new_array<InlineKlass*>(_loader_data,\n+    _inline_layout_info_array = MetadataFactory::new_array<InlineLayoutInfo>(_loader_data,\n@@ -6233,1 +6203,0 @@\n-                                                   nullptr,\n@@ -6275,1 +6244,1 @@\n-        _inline_type_field_klasses->at_put(fieldinfo.index(), vk);\n+        _inline_layout_info_array->adr_at(fieldinfo.index())->set_klass(vk);\n@@ -6287,1 +6256,1 @@\n-              _inline_type_field_klasses->at_put(fieldinfo.index(), InlineKlass::cast(klass));\n+              _inline_layout_info_array->adr_at(fieldinfo.index())->set_klass(InlineKlass::cast(klass));\n@@ -6306,1 +6275,1 @@\n-  _field_info = new FieldLayoutInfo();\n+  _layout_info = new FieldLayoutInfo();\n@@ -6310,1 +6279,1 @@\n-      _field_info, _inline_type_field_klasses);\n+      _must_be_atomic, _layout_info, _inline_layout_info_array);\n@@ -6312,7 +6281,1 @@\n-  if (is_inline_type()) {\n-    _alignment = lb.get_alignment();\n-    _first_field_offset = lb.get_first_field_offset();\n-    _payload_size_in_bytes = lb.get_payload_size_in_byte();\n-    _internal_null_marker_offset = lb.get_internal_null_marker_offset();\n-  }\n-  _has_inline_type_fields = _field_info->_has_inline_fields;\n+  _has_inline_type_fields = _layout_info->_has_inline_fields;\n@@ -6328,11 +6291,0 @@\n-  if (_field_info->_has_null_marker_offsets) {\n-    int idx = 0;\n-    _null_marker_offsets = MetadataFactory::new_array<int>(_loader_data, _temp_field_info->length(), 0, CHECK);\n-    for (GrowableArrayIterator<FieldInfo> it = _temp_field_info->begin(); it != _temp_field_info->end(); ++it, ++idx) {\n-      FieldInfo fieldinfo = *it;\n-      if (fieldinfo.field_flags().has_null_marker()) {\n-        assert(fieldinfo.null_marker_offset() != 0, \"Invalid value\");\n-        _null_marker_offsets->at_put(idx, fieldinfo.null_marker_offset());\n-      }\n-    }\n-  }\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":67,"deletions":115,"binary":false,"changes":182,"status":"modified"},{"patch":"@@ -77,0 +77,10 @@\n+  int _payload_alignment;\n+  int _first_field_offset;\n+  int _payload_size_in_bytes;\n+  int _non_atomic_size_in_bytes;\n+  int _non_atomic_alignment;\n+  int _atomic_layout_size_in_bytes;\n+  int _nullable_layout_size_in_bytes;\n+  int _null_marker_offset;\n+  int _default_value_offset;\n+  int _null_reset_value_offset;\n@@ -79,0 +89,1 @@\n+  bool _must_be_atomic;\n@@ -80,1 +91,1 @@\n-  bool _has_null_marker_offsets;\n+  bool _is_empty_inline_klass;\n@@ -149,3 +160,2 @@\n-  FieldLayoutInfo* _field_info;\n-  Array<InlineKlass*>* _inline_type_field_klasses;\n-  Array<int>* _null_marker_offsets;\n+  FieldLayoutInfo* _layout_info;\n+  Array<InlineLayoutInfo>* _inline_layout_info_array;\n@@ -165,4 +175,0 @@\n-  int _alignment;\n-  int _first_field_offset;\n-  int _payload_size_in_bytes;\n-  int _internal_null_marker_offset;\n@@ -210,2 +216,0 @@\n-  bool _has_nonstatic_fields;\n-  bool _is_empty_inline_type;\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.hpp","additions":14,"deletions":10,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -39,0 +39,51 @@\n+#include \"utilities\/powerOfTwo.hpp\"\n+\n+static LayoutKind field_layout_selection(FieldInfo field_info, Array<InlineLayoutInfo>* inline_layout_info_array) {\n+\n+  if (field_info.field_flags().is_injected()) {\n+    \/\/ don't flatten injected fields\n+    return LayoutKind::REFERENCE;\n+  }\n+\n+  if (inline_layout_info_array == nullptr || inline_layout_info_array->adr_at(field_info.index())->klass() == nullptr) {\n+    \/\/ field's type is not a known value class, using a reference\n+    return LayoutKind::REFERENCE;\n+  }\n+\n+  InlineLayoutInfo* inline_field_info = inline_layout_info_array->adr_at(field_info.index());\n+  InlineKlass* vk = inline_field_info->klass();\n+\n+  if (field_info.field_flags().is_null_free_inline_type()) {\n+    assert(vk->is_implicitly_constructible(), \"null-free fields must be implicitly constructible\");\n+    if (vk->must_be_atomic() || field_info.access_flags().is_volatile() ||  AlwaysAtomicAccesses) {\n+      return vk->has_atomic_layout() ? LayoutKind::ATOMIC_FLAT : LayoutKind::REFERENCE;\n+    } else {\n+      return vk->has_non_atomic_layout() ? LayoutKind::NON_ATOMIC_FLAT : LayoutKind::REFERENCE;\n+    }\n+  } else {\n+    if (NullableFieldFlattening && vk->has_nullable_layout()) {\n+      return LayoutKind::NULLABLE_ATOMIC_FLAT;\n+    } else {\n+      return LayoutKind::REFERENCE;\n+    }\n+  }\n+}\n+\n+static void get_size_and_alignment(InlineKlass* vk, LayoutKind kind, int* size, int* alignment) {\n+  switch(kind) {\n+    case LayoutKind::NON_ATOMIC_FLAT:\n+      *size = vk->non_atomic_size_in_bytes();\n+      *alignment = vk->non_atomic_alignment();\n+      break;\n+    case LayoutKind::ATOMIC_FLAT:\n+      *size = vk->atomic_size_in_bytes();\n+      *alignment = *size;\n+      break;\n+    case LayoutKind::NULLABLE_ATOMIC_FLAT:\n+      *size = vk->nullable_size_in_bytes();\n+      *alignment = *size;\n+    break;\n+    default:\n+      ShouldNotReachHere();\n+  }\n+}\n@@ -44,1 +95,1 @@\n-  _kind(kind),\n+  _block_kind(kind),\n@@ -48,4 +99,1 @@\n-  _field_index(-1),\n-  _null_marker_offset(-1),\n-  _is_reference(false),\n-  _needs_null_marker(false) {\n+  _field_index(-1) {\n@@ -58,1 +106,1 @@\n-LayoutRawBlock::LayoutRawBlock(int index, Kind kind, int size, int alignment, bool is_reference) :\n+LayoutRawBlock::LayoutRawBlock(int index, Kind kind, int size, int alignment) :\n@@ -62,1 +110,1 @@\n- _kind(kind),\n+ _block_kind(kind),\n@@ -66,5 +114,2 @@\n- _field_index(index),\n- _null_marker_offset(-1),\n- _is_reference(is_reference),\n- _needs_null_marker(false) {\n-  assert(kind == REGULAR || kind == FLAT || kind == INHERITED || kind == INHERITED_NULL_MARKER,\n+ _field_index(index) {\n+  assert(kind == REGULAR || kind == FLAT || kind == INHERITED,\n@@ -94,1 +139,1 @@\n-  LayoutRawBlock* block = new LayoutRawBlock(idx, LayoutRawBlock::REGULAR, size, size \/* alignment == size for primitive types *\/, false);\n+  LayoutRawBlock* block = new LayoutRawBlock(idx, LayoutRawBlock::REGULAR, size, size \/* alignment == size for primitive types *\/);\n@@ -104,1 +149,1 @@\n-  LayoutRawBlock* block = new LayoutRawBlock(idx, LayoutRawBlock::REGULAR, size, size \/* alignment == size for oops *\/, true);\n+  LayoutRawBlock* block = new LayoutRawBlock(idx, LayoutRawBlock::REGULAR, size, size \/* alignment == size for oops *\/);\n@@ -112,2 +157,2 @@\n-void FieldGroup::add_flat_field(int idx, InlineKlass* vk, bool needs_null_marker) {\n-  LayoutRawBlock* block = new LayoutRawBlock(idx, LayoutRawBlock::FLAT, vk->get_payload_size_in_bytes(), vk->get_alignment(), false);\n+void FieldGroup::add_flat_field(int idx, InlineKlass* vk, LayoutKind lk, int size, int alignment) {\n+  LayoutRawBlock* block = new LayoutRawBlock(idx, LayoutRawBlock::FLAT, size, alignment);\n@@ -115,1 +160,1 @@\n-  if (needs_null_marker) block->set_needs_null_marker();\n+  block->set_layout_kind(lk);\n@@ -146,1 +191,1 @@\n-FieldLayout::FieldLayout(GrowableArray<FieldInfo>* field_info, ConstantPool* cp) :\n+FieldLayout::FieldLayout(GrowableArray<FieldInfo>* field_info, Array<InlineLayoutInfo>* inline_layout_info_array, ConstantPool* cp) :\n@@ -148,0 +193,1 @@\n+  _inline_layout_info_array(inline_layout_info_array),\n@@ -155,0 +201,2 @@\n+  _default_value_offset(-1),\n+  _null_reset_value_offset(-1),\n@@ -156,1 +204,1 @@\n-  _has_missing_null_markers(false) {}\n+  _has_inherited_fields(false) {}\n@@ -194,3 +242,4 @@\n-         && block->kind() != LayoutRawBlock::INHERITED\n-         && block->kind() != LayoutRawBlock::REGULAR\n-         && block->kind() != LayoutRawBlock::FLAT) {\n+         && block->block_kind() != LayoutRawBlock::INHERITED\n+         && block->block_kind() != LayoutRawBlock::REGULAR\n+         && block->block_kind() != LayoutRawBlock::FLAT\n+         && block->block_kind() != LayoutRawBlock::NULL_MARKER) {\n@@ -236,1 +285,1 @@\n-        if (cursor->kind() == LayoutRawBlock::EMPTY && cursor->fit(b->size(), b->alignment())) {\n+        if (cursor->block_kind() == LayoutRawBlock::EMPTY && cursor->fit(b->size(), b->alignment())) {\n@@ -248,1 +297,1 @@\n-      assert(candidate->kind() == LayoutRawBlock::EMPTY, \"Candidate must be an empty block\");\n+      assert(candidate->block_kind() == LayoutRawBlock::EMPTY, \"Candidate must be an empty block\");\n@@ -266,1 +315,1 @@\n-      assert(slot->kind() == LayoutRawBlock::EMPTY, \"Matching slot must be an empty slot\");\n+      assert(slot->block_kind() == LayoutRawBlock::EMPTY, \"Matching slot must be an empty slot\");\n@@ -277,1 +326,1 @@\n-      if (block->kind() == LayoutRawBlock::REGULAR || block->kind() == LayoutRawBlock::FLAT) {\n+      if (block->block_kind() == LayoutRawBlock::REGULAR || block->block_kind() == LayoutRawBlock::FLAT) {\n@@ -308,1 +357,1 @@\n-    while (candidate->kind() != LayoutRawBlock::EMPTY || !candidate->fit(size, first->alignment())) {\n+    while (candidate->block_kind() != LayoutRawBlock::EMPTY || !candidate->fit(size, first->alignment())) {\n@@ -316,1 +365,1 @@\n-    assert(candidate->kind() == LayoutRawBlock::EMPTY, \"Candidate must be an empty block\");\n+    assert(candidate->block_kind() == LayoutRawBlock::EMPTY, \"Candidate must be an empty block\");\n@@ -328,1 +377,1 @@\n-  assert(slot->kind() == LayoutRawBlock::EMPTY, \"Blocks can only be inserted in empty blocks\");\n+  assert(slot->block_kind() == LayoutRawBlock::EMPTY, \"Blocks can only be inserted in empty blocks\");\n@@ -336,3 +385,0 @@\n-  if (block->needs_null_marker()) {\n-    _has_missing_null_markers = true;\n-  }\n@@ -342,3 +388,2 @@\n-  \/\/ NULL_MARKER blocks have a field index pointing to the field that needs a null marker,\n-  \/\/ so the field_info at this index must not be updated with the null marker's offset\n-  if (block->kind() != LayoutRawBlock::NULL_MARKER) {\n+  \/\/ NULL_MARKER blocks are not real fields, so they don't have an entry in the FieldInfo array\n+  if (block->block_kind() != LayoutRawBlock::NULL_MARKER) {\n@@ -346,0 +391,6 @@\n+    if (_field_info->adr_at(block->field_index())->name(_cp) == vmSymbols::default_value_name()) {\n+      _default_value_offset = block->offset();\n+    }\n+    if (_field_info->adr_at(block->field_index())->name(_cp) == vmSymbols::null_reset_value_name()) {\n+      _null_reset_value_offset = block->offset();\n+    }\n@@ -347,0 +398,6 @@\n+  if (block->block_kind() == LayoutRawBlock::FLAT && block->layout_kind() == LayoutKind::NULLABLE_ATOMIC_FLAT) {\n+    int nm_offset = block->inline_klass()->null_marker_offset() - block->inline_klass()->first_field_offset() + block->offset();\n+    _field_info->adr_at(block->field_index())->set_null_marker_offset(nm_offset);\n+    _inline_layout_info_array->adr_at(block->field_index())->set_null_marker_offset(nm_offset);\n+  }\n+\n@@ -362,0 +419,1 @@\n+      _has_inherited_fields = true;\n@@ -365,12 +423,7 @@\n-        InlineKlass* vk = InlineKlass::cast(ik->get_inline_type_field_klass(fs.index()));\n-        block = new LayoutRawBlock(fs.index(), LayoutRawBlock::INHERITED, vk->get_payload_size_in_bytes(),\n-                                   vk->get_alignment(), false);\n-        assert(_super_alignment == -1 || _super_alignment >=  vk->get_alignment(), \"Invalid value alignment\");\n-        _super_min_align_required = _super_min_align_required > vk->get_alignment() ? _super_min_align_required : vk->get_alignment();\n-        if (!fs.field_flags().is_null_free_inline_type()) {\n-          assert(fs.field_flags().has_null_marker(), \"Nullable flat fields must have a null marker\");\n-          LayoutRawBlock* marker = new LayoutRawBlock(fs.index(), LayoutRawBlock::INHERITED_NULL_MARKER, 1 \/* current NULL_MARKER block are one byte *\/,\n-                                    1, false);\n-          marker->set_offset(fs.null_marker_offset());\n-          all_fields->append(marker);\n-        }\n+        InlineLayoutInfo layout_info = ik->inline_layout_info(fs.index());\n+        InlineKlass* vk = layout_info.klass();\n+        block = new LayoutRawBlock(fs.index(), LayoutRawBlock::INHERITED,\n+                                   vk->layout_size_in_bytes(layout_info.kind()),\n+                                   vk->layout_alignment(layout_info.kind()));\n+        assert(_super_alignment == -1 || _super_alignment >=  vk->payload_alignment(), \"Invalid value alignment\");\n+        _super_min_align_required = _super_min_align_required > vk->payload_alignment() ? _super_min_align_required : vk->payload_alignment();\n@@ -380,1 +433,1 @@\n-        block = new LayoutRawBlock(fs.index(), LayoutRawBlock::INHERITED, size, size, false);\n+        block = new LayoutRawBlock(fs.index(), LayoutRawBlock::INHERITED, size, size);\n@@ -418,0 +471,1 @@\n+      \/\/ FIXME it would be better if initial empty block where tagged as PADDING for value classes\n@@ -428,1 +482,1 @@\n-  assert(b->kind() != LayoutRawBlock::EMPTY, \"Sanity check\");\n+  assert(b->block_kind() != LayoutRawBlock::EMPTY, \"Sanity check\");\n@@ -449,1 +503,1 @@\n-  assert(slot->kind() == LayoutRawBlock::EMPTY, \"Blocks can only be inserted in empty blocks\");\n+  assert(slot->block_kind() == LayoutRawBlock::EMPTY, \"Blocks can only be inserted in empty blocks\");\n@@ -489,1 +543,71 @@\n-void FieldLayout::print(outputStream* output, bool is_static, const InstanceKlass* super, Array<InlineKlass*>* inline_fields) {\n+void FieldLayout::shift_fields(int shift) {\n+  LayoutRawBlock* b = first_field_block();\n+  LayoutRawBlock* previous = b->prev_block();\n+  if (previous->block_kind() == LayoutRawBlock::EMPTY) {\n+    previous->set_size(previous->size() + shift);\n+  } else {\n+    LayoutRawBlock* nb = new LayoutRawBlock(LayoutRawBlock::PADDING, shift);\n+    nb->set_offset(b->offset());\n+    previous->set_next_block(nb);\n+    nb->set_prev_block(previous);\n+    b->set_prev_block(nb);\n+    nb->set_next_block(b);\n+  }\n+  while (b != nullptr) {\n+    b->set_offset(b->offset() + shift);\n+    if (b->block_kind() == LayoutRawBlock::REGULAR || b->block_kind() == LayoutRawBlock::FLAT) {\n+      _field_info->adr_at(b->field_index())->set_offset(b->offset());\n+    }\n+    assert(b->block_kind() == LayoutRawBlock::EMPTY || b->offset() % b->alignment() == 0, \"Must still be correctly aligned\");\n+    b = b->next_block();\n+  }\n+}\n+\n+LayoutRawBlock* FieldLayout::find_null_marker() {\n+  LayoutRawBlock* b = _blocks;\n+  while (b != nullptr) {\n+    if (b->block_kind() == LayoutRawBlock::NULL_MARKER) {\n+      return b;\n+    }\n+    b = b->next_block();\n+  }\n+  ShouldNotReachHere();\n+}\n+\n+void FieldLayout::remove_null_marker() {\n+  LayoutRawBlock* b = first_field_block();\n+  while (b != nullptr) {\n+    if (b->block_kind() == LayoutRawBlock::NULL_MARKER) {\n+      if (b->next_block()->block_kind() == LayoutRawBlock::EMPTY) {\n+        LayoutRawBlock* n = b->next_block();\n+        remove(b);\n+        n->set_offset(b->offset());\n+        n->set_size(n->size() + b->size());\n+      } else {\n+        b->set_block_kind(LayoutRawBlock::EMPTY);\n+      }\n+      return;\n+    }\n+    b = b->next_block();\n+  }\n+  ShouldNotReachHere(); \/\/ if we reach this point, the null marker was not found!\n+}\n+\n+static const char* layout_kind_to_string(LayoutKind lk) {\n+  switch(lk) {\n+    case LayoutKind::REFERENCE:\n+      return \"REFERENCE\";\n+    case LayoutKind::NON_ATOMIC_FLAT:\n+      return \"NON_ATOMIC_FLAT\";\n+    case LayoutKind::ATOMIC_FLAT:\n+      return \"ATOMIC_FLAT\";\n+    case LayoutKind::NULLABLE_ATOMIC_FLAT:\n+      return \"NULLABLE_ATOMIC_FLAT\";\n+    case LayoutKind::UNKNOWN:\n+      return \"UNKNOWN\";\n+    default:\n+      ShouldNotReachHere();\n+  }\n+}\n+\n+void FieldLayout::print(outputStream* output, bool is_static, const InstanceKlass* super, Array<InlineLayoutInfo>* inline_fields) {\n@@ -493,1 +617,1 @@\n-    switch(b->kind()) {\n+    switch(b->block_kind()) {\n@@ -507,1 +631,1 @@\n-        InlineKlass* ik = inline_fields->at(fi->index());\n+        InlineKlass* ik = inline_fields->adr_at(fi->index())->klass();\n@@ -509,1 +633,1 @@\n-        output->print(\" @%d %s %d\/%d \\\"%s\\\" %s %s@%p\",\n+        output->print_cr(\" @%d %s %d\/%d \\\"%s\\\" %s %s@%p %s\",\n@@ -517,7 +641,1 @@\n-                         ik->class_loader_data());\n-        if (fi->field_flags().has_null_marker()) {\n-          output->print_cr(\" null marker offset %d %s\", fi->null_marker_offset(),\n-                           fi->field_flags().is_null_marker_internal() ? \"(internal)\" : \"\");\n-        } else {\n-          output->print_cr(\"\");\n-        }\n+                         ik->class_loader_data(), layout_kind_to_string(b->layout_kind()));\n@@ -556,6 +674,0 @@\n-    case LayoutRawBlock::INHERITED_NULL_MARKER :\n-      output->print_cr(\" @%d %s %d\/1\",\n-                       b->offset(),\n-                      \"INHERITED_NULL_MARKER\",\n-                       b->size());\n-      break;\n@@ -576,2 +688,1 @@\n-      FieldInfo* fi = _field_info->adr_at(b->field_index());\n-      output->print_cr(\" @%d %s %d\/1 null marker for field at offset %d\",\n+      output->print_cr(\" @%d %s %d\/1 \",\n@@ -580,2 +691,1 @@\n-                      b->size(),\n-                      fi->offset());\n+                      b->size());\n@@ -593,1 +703,1 @@\n-                                       FieldLayoutInfo* info, Array<InlineKlass*>* inline_type_field_klasses) :\n+                                       bool must_be_atomic, FieldLayoutInfo* info, Array<InlineLayoutInfo>* inline_layout_info_array) :\n@@ -600,1 +710,1 @@\n-  _inline_type_field_klasses(inline_type_field_klasses),\n+  _inline_layout_info_array(inline_layout_info_array),\n@@ -607,1 +717,1 @@\n-  _alignment(-1),\n+  _payload_alignment(-1),\n@@ -609,1 +719,1 @@\n-  _internal_null_marker_offset(-1),\n+  _null_marker_offset(-1),\n@@ -611,1 +721,4 @@\n-  _atomic_field_count(0),\n+  _non_atomic_layout_size_in_bytes(-1),\n+  _non_atomic_layout_alignment(-1),\n+  _atomic_layout_size_in_bytes(-1),\n+  _nullable_layout_size_in_bytes(-1),\n@@ -613,0 +726,4 @@\n+  _declared_non_static_fields_count(0),\n+  _has_non_naturally_atomic_fields(false),\n+  _is_naturally_atomic(false),\n+  _must_be_atomic(must_be_atomic),\n@@ -619,3 +736,1 @@\n-  _has_nonatomic_values(false),\n-  _nullable_atomic_flat_candidate(false),\n-  _has_null_markers(false) {}\n+  _is_empty_inline_class(false) {}\n@@ -636,1 +751,1 @@\n-  _layout = new FieldLayout(_field_info, _constant_pool);\n+  _layout = new FieldLayout(_field_info, _inline_layout_info_array, _constant_pool);\n@@ -639,0 +754,1 @@\n+  _nonstatic_oopmap_count = super_klass == nullptr ? 0 : super_klass->nonstatic_oop_map_count();\n@@ -642,1 +758,1 @@\n-  _static_layout = new FieldLayout(_field_info, _constant_pool);\n+  _static_layout = new FieldLayout(_field_info, _inline_layout_info_array, _constant_pool);\n@@ -663,1 +779,0 @@\n-      _atomic_field_count++;  \/\/ we might decrement this\n@@ -692,5 +807,9 @@\n-      bool field_is_known_value_class =  !fieldinfo.field_flags().is_injected() && _inline_type_field_klasses != nullptr && _inline_type_field_klasses->at(fieldinfo.index()) != nullptr;\n-      bool value_has_oops = field_is_known_value_class ? _inline_type_field_klasses->at(fieldinfo.index())->nonstatic_oop_count() > 0 : true;\n-      bool is_candidate_for_flattening = fieldinfo.field_flags().is_null_free_inline_type() || (EnableNullableFieldFlattening && field_is_known_value_class && !value_has_oops);\n-      \/\/ if (!fieldinfo.field_flags().is_null_free_inline_type()) {\n-      if (!is_candidate_for_flattening) {\n+      LayoutKind lk = field_layout_selection(fieldinfo, _inline_layout_info_array);\n+      if (fieldinfo.field_flags().is_null_free_inline_type() || lk != LayoutKind::REFERENCE\n+          || (!fieldinfo.field_flags().is_injected()\n+              && _inline_layout_info_array != nullptr && _inline_layout_info_array->adr_at(fieldinfo.index())->klass() != nullptr\n+              && !_inline_layout_info_array->adr_at(fieldinfo.index())->klass()->is_identity_class())) {\n+        _has_inline_type_fields = true;\n+        _has_flattening_information = true;\n+      }\n+      if (lk == LayoutKind::REFERENCE) {\n@@ -700,40 +819,10 @@\n-        assert(type != T_ARRAY, \"null free ptr to array not supported\");\n-        _has_inline_type_fields = true;\n-        if (group == _static_fields) {\n-          \/\/ static fields are never flat\n-          group->add_oop_field(idx);\n-        } else {\n-          \/\/ Check below is performed for non-static fields, it should be performed for static fields too but at this stage,\n-          \/\/ it is not guaranteed that the klass of the static field has been loaded, so the test for static fields is delayed\n-          \/\/ until the linking phase\n-          Klass* klass =  _inline_type_field_klasses->at(idx);\n-          assert(klass != nullptr, \"Sanity check\");\n-          InlineKlass* vk = InlineKlass::cast(klass);\n-          assert(!fieldinfo.field_flags().is_null_free_inline_type() || vk->is_implicitly_constructible(), \"must be, should have been checked in post_process_parsed_stream()\");\n-          _has_flattening_information = true;\n-          \/\/ Flattening decision to be taken here\n-          \/\/ This code assumes all verification already have been performed\n-          \/\/ (field's type has been loaded and it is an inline klass)\n-          bool too_big_to_flatten = (InlineFieldMaxFlatSize >= 0 &&\n-                                    (vk->size_helper() * HeapWordSize) > InlineFieldMaxFlatSize);\n-          bool too_atomic_to_flatten = vk->must_be_atomic() || AlwaysAtomicAccesses;\n-          bool too_volatile_to_flatten = fieldinfo.access_flags().is_volatile();\n-          if (vk->is_naturally_atomic()) {\n-            too_atomic_to_flatten = false;\n-            \/\/too_volatile_to_flatten = false; \/\/FIXME\n-            \/\/ Currently, volatile fields are never flat, this could change in the future\n-          }\n-          if (!(too_big_to_flatten | too_atomic_to_flatten | too_volatile_to_flatten)) {\n-            group->add_flat_field(idx, vk, !fieldinfo.field_flags().is_null_free_inline_type());\n-            _nonstatic_oopmap_count += vk->nonstatic_oop_map_count();\n-            _field_info->adr_at(idx)->field_flags_addr()->update_flat(true);\n-            if (!vk->is_atomic()) {  \/\/ flat and non-atomic: take note\n-              _has_nonatomic_values = true;\n-              _atomic_field_count--;  \/\/ every other field is atomic but this one\n-            }\n-            if (!fieldinfo.field_flags().is_null_free_inline_type()) _has_null_markers = true;\n-          } else {\n-            _nonstatic_oopmap_count++;\n-            group->add_oop_field(idx);\n-          }\n-        }\n+        _has_flattening_information = true;\n+        InlineKlass* vk = _inline_layout_info_array->adr_at(fieldinfo.index())->klass();\n+        int size, alignment;\n+        get_size_and_alignment(vk, lk, &size, &alignment);\n+        group->add_flat_field(idx, vk, lk, size, alignment);\n+        _inline_layout_info_array->adr_at(fieldinfo.index())->set_kind(lk);\n+        _nonstatic_oopmap_count += vk->nonstatic_oop_map_count();\n+        _field_info->adr_at(idx)->field_flags_addr()->update_flat(true);\n+        _field_info->adr_at(idx)->set_layout_kind(lk);\n+        \/\/ no need to update _must_be_atomic if vk->must_be_atomic() is true because current class is not an inline class\n@@ -770,1 +859,2 @@\n-  for (GrowableArrayIterator<FieldInfo> it = _field_info->begin(); it != _field_info->end(); ++it) {\n+  int idx = 0;\n+  for (GrowableArrayIterator<FieldInfo> it = _field_info->begin(); it != _field_info->end(); ++it, ++idx) {\n@@ -778,1 +868,1 @@\n-      _atomic_field_count++;  \/\/ we might decrement this\n+      _declared_non_static_fields_count++;\n@@ -800,5 +890,9 @@\n-      bool field_is_known_value_class =  !fieldinfo.field_flags().is_injected() && _inline_type_field_klasses != nullptr && _inline_type_field_klasses->at(fieldinfo.index()) != nullptr;\n-      bool value_has_oops = field_is_known_value_class ? _inline_type_field_klasses->at(fieldinfo.index())->nonstatic_oop_count() > 0 : true;\n-      bool is_candidate_for_flattening = fieldinfo.field_flags().is_null_free_inline_type() || (EnableNullableFieldFlattening && field_is_known_value_class && !value_has_oops);\n-      \/\/ if (!fieldinfo.field_flags().is_null_free_inline_type()) {\n-      if (!is_candidate_for_flattening) {\n+      LayoutKind lk = field_layout_selection(fieldinfo, _inline_layout_info_array);\n+      if (fieldinfo.field_flags().is_null_free_inline_type() || lk != LayoutKind::REFERENCE\n+          || (!fieldinfo.field_flags().is_injected()\n+              && _inline_layout_info_array != nullptr && _inline_layout_info_array->adr_at(fieldinfo.index())->klass() != nullptr\n+              && !_inline_layout_info_array->adr_at(fieldinfo.index())->klass()->is_identity_class())) {\n+        _has_inline_type_fields = true;\n+        _has_flattening_information = true;\n+      }\n+      if (lk == LayoutKind::REFERENCE) {\n@@ -809,1 +903,1 @@\n-        group->add_oop_field(fieldinfo.index());\n+        group->add_oop_field(idx);\n@@ -811,40 +905,15 @@\n-        assert(type != T_ARRAY, \"null free ptr to array not supported\");\n-        _has_inline_type_fields = true;\n-        if (group == _static_fields) {\n-          \/\/ static fields are never flat\n-          group->add_oop_field(fieldinfo.index());\n-        } else {\n-          \/\/ Check below is performed for non-static fields, it should be performed for static fields too but at this stage,\n-          \/\/ it is not guaranteed that the klass of the static field has been loaded, so the test for static fields is delayed\n-          \/\/ until the linking phase\n-          Klass* klass =  _inline_type_field_klasses->at(fieldinfo.index());\n-          assert(klass != nullptr, \"Sanity check\");\n-          InlineKlass* vk = InlineKlass::cast(klass);\n-          assert(vk->is_implicitly_constructible(), \"must be, should have been checked in post_process_parsed_stream()\");\n-          \/\/ Flattening decision to be taken here\n-          \/\/ This code assumes all verifications have already been performed\n-          \/\/ (field's type has been loaded and it is an inline klass)\n-          bool too_big_to_flatten = (InlineFieldMaxFlatSize >= 0 &&\n-                                    (vk->size_helper() * HeapWordSize) > InlineFieldMaxFlatSize);\n-          bool too_atomic_to_flatten = vk->must_be_atomic() || AlwaysAtomicAccesses;\n-          bool too_volatile_to_flatten = fieldinfo.access_flags().is_volatile();\n-          if (vk->is_naturally_atomic()) {\n-            too_atomic_to_flatten = false;\n-            \/\/too_volatile_to_flatten = false; \/\/FIXME\n-            \/\/ Currently, volatile fields are never flat, this could change in the future\n-          }\n-          if (!(too_big_to_flatten | too_atomic_to_flatten | too_volatile_to_flatten)) {\n-            group->add_flat_field(fieldinfo.index(), vk, !fieldinfo.field_flags().is_null_free_inline_type());\n-            _nonstatic_oopmap_count += vk->nonstatic_oop_map_count();\n-            field_alignment = vk->get_alignment();\n-            _field_info->adr_at(fieldinfo.index())->field_flags_addr()->update_flat(true);\n-            if (!vk->is_atomic()) {  \/\/ flat and non-atomic: take note\n-              _has_nonatomic_values = true;\n-              _atomic_field_count--;  \/\/ every other field is atomic but this one\n-            }\n-            if (!fieldinfo.field_flags().is_null_free_inline_type()) _has_null_markers = true;\n-          } else {\n-            _nonstatic_oopmap_count++;\n-            field_alignment = type2aelembytes(T_OBJECT);\n-            group->add_oop_field(fieldinfo.index());\n-          }\n+        _has_flattening_information = true;\n+        InlineKlass* vk = _inline_layout_info_array->adr_at(fieldinfo.index())->klass();\n+        if (!vk->is_naturally_atomic()) _has_non_naturally_atomic_fields = true;\n+        int size, alignment;\n+        get_size_and_alignment(vk, lk, &size, &alignment);\n+        group->add_flat_field(idx, vk, lk, size, alignment);\n+        _inline_layout_info_array->adr_at(fieldinfo.index())->set_kind(lk);\n+        _nonstatic_oopmap_count += vk->nonstatic_oop_map_count();\n+        field_alignment = alignment;\n+        _field_info->adr_at(idx)->field_flags_addr()->update_flat(true);\n+        _field_info->adr_at(idx)->set_layout_kind(lk);\n+        \/\/ default is atomic, but class file parsing could have set _must_be_atomic to false (@LooselyConsistentValue + checks)\n+        \/\/ Presence of a must_be_atomic field must revert the _must_be_atomic flag of the holder to true\n+        if (vk->must_be_atomic()) {\n+          _must_be_atomic = true;\n@@ -860,1 +929,1 @@\n-  _alignment = alignment;\n+  _payload_alignment = alignment;\n@@ -909,4 +978,0 @@\n-  if (EnableNullableFieldFlattening && _layout->has_missing_null_markers()) {\n-    insert_null_markers();\n-  }\n-\n@@ -921,33 +986,0 @@\n-void FieldLayoutBuilder::insert_null_markers() {\n-  if (!EnableNullableFieldFlattening || !_layout->has_missing_null_markers()) return;\n-  GrowableArray<LayoutRawBlock*>* list = new GrowableArray<LayoutRawBlock*>(10);\n-  for (LayoutRawBlock* block = _layout->first_field_block(); block != _layout->last_block(); block = block->next_block()) {\n-    if (block->needs_null_marker()) {\n-      assert(block->kind() == LayoutRawBlock::FLAT, \"Only flat fields might need null markers\");\n-      if (block->inline_klass()->has_internal_null_marker_offset()) {\n-        \/\/ The inline klass has an internal null marker slot, let's use it\n-        \/\/ The inline klass has the internal null marker offset from the begining of the object,\n-        \/\/ compute the offset relative to begining of payload\n-        int internal_null_marker_offset = block->inline_klass()->get_internal_null_marker_offset() - block->inline_klass()->first_field_offset();\n-        block->set_null_marker_offset(block->offset() + internal_null_marker_offset);\n-        _field_info->adr_at(block->field_index())->set_null_marker_offset(block->null_marker_offset());\n-        _field_info->adr_at(block->field_index())->field_flags_addr()->update_null_marker(true);\n-        _field_info->adr_at(block->field_index())->field_flags_addr()->update_internal_null_marker(true);\n-      } else {\n-        \/\/ No internal null marker, need a external slot in the container\n-        LayoutRawBlock* marker = new LayoutRawBlock(LayoutRawBlock::NULL_MARKER, 1);\n-        marker->set_field_index(block->field_index());\n-        list->append(marker);\n-      }\n-    }\n-  }\n-  _layout->add(list);\n-  for (GrowableArrayIterator<LayoutRawBlock*> it = list->begin(); it != list->end(); ++it) {\n-    LayoutRawBlock* block = *it;\n-    assert(block->offset() != -1, \"Must be set\");\n-    assert(!block->needs_null_marker(), \"Must have been set\");\n-    _field_info->adr_at(block->field_index())->set_null_marker_offset(block->offset());\n-    _field_info->adr_at(block->field_index())->field_flags_addr()->update_null_marker(true);\n-  }\n-}\n-\n@@ -967,0 +999,40 @@\n+\n+  \/\/ Test if the concrete inline class is an empty class (no instance fields)\n+  \/\/ and insert a dummy field if needed\n+  if (!_is_abstract_value) {\n+    bool declares_non_static_fields = false;\n+    for (GrowableArrayIterator<FieldInfo> it = _field_info->begin(); it != _field_info->end(); ++it) {\n+      FieldInfo fieldinfo = *it;\n+      if (!fieldinfo.access_flags().is_static()) {\n+        declares_non_static_fields = true;\n+        break;\n+      }\n+    }\n+    if (!declares_non_static_fields) {\n+      bool has_inherited_fields = false;\n+      const InstanceKlass* super = _super_klass;\n+      while(super != nullptr) {\n+        if (super->has_nonstatic_fields()) {\n+          has_inherited_fields = true;\n+          break;\n+        }\n+        super = super->super() == nullptr ? nullptr : InstanceKlass::cast(super->super());\n+      }\n+\n+      if (!has_inherited_fields) {\n+        \/\/ Inject \".empty\" dummy field\n+        _is_empty_inline_class = true;\n+        FieldInfo::FieldFlags fflags(0);\n+        fflags.update_injected(true);\n+        AccessFlags aflags;\n+        FieldInfo fi(aflags,\n+                    (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(empty_marker_name)),\n+                    (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(byte_signature)),\n+                    0,\n+                    fflags);\n+        int idx = _field_info->append(fi);\n+        _field_info->adr_at(idx)->set_index(idx);\n+      }\n+    }\n+  }\n+\n@@ -970,1 +1042,1 @@\n-  assert(_layout->start()->kind() == LayoutRawBlock::RESERVED, \"Unexpected\");\n+  assert(_layout->start()->block_kind() == LayoutRawBlock::RESERVED, \"Unexpected\");\n@@ -979,2 +1051,2 @@\n-      assert(_layout->super_alignment() >= _alignment, \"Incompatible alignment\");\n-      assert(_layout->super_alignment() % _alignment == 0, \"Incompatible alignment\");\n+      assert(_layout->super_alignment() >= _payload_alignment, \"Incompatible alignment\");\n+      assert(_layout->super_alignment() % _payload_alignment == 0, \"Incompatible alignment\");\n@@ -982,3 +1054,3 @@\n-      if (_alignment < _layout->super_alignment()) {\n-        int new_alignment = _alignment > _layout->super_min_align_required() ? _alignment : _layout->super_min_align_required();\n-        assert(new_alignment % _alignment == 0, \"Must be\");\n+      if (_payload_alignment < _layout->super_alignment()) {\n+        int new_alignment = _payload_alignment > _layout->super_min_align_required() ? _payload_alignment : _layout->super_min_align_required();\n+        assert(new_alignment % _payload_alignment == 0, \"Must be\");\n@@ -986,1 +1058,1 @@\n-        _alignment = new_alignment;\n+        _payload_alignment = new_alignment;\n@@ -990,2 +1062,2 @@\n-        if (first_empty->offset() % _alignment != 0) {\n-          int size =  _alignment - (first_empty->offset() % _alignment);\n+        if (first_empty->offset() % _payload_alignment != 0) {\n+          int size =  _payload_alignment - (first_empty->offset() % _payload_alignment);\n@@ -1004,1 +1076,1 @@\n-      _alignment = type2aelembytes(BasicType::T_LONG);\n+      _payload_alignment = type2aelembytes(BasicType::T_LONG);\n@@ -1006,1 +1078,1 @@\n-    assert(_layout->start()->next_block()->kind() == LayoutRawBlock::EMPTY || !UseCompressedClassPointers, \"Unexpected\");\n+    assert(_layout->start()->next_block()->block_kind() == LayoutRawBlock::EMPTY || !UseCompressedClassPointers, \"Unexpected\");\n@@ -1008,2 +1080,2 @@\n-    if (first_empty->offset() % _alignment != 0) {\n-      LayoutRawBlock* padding = new LayoutRawBlock(LayoutRawBlock::PADDING, _alignment - (first_empty->offset() % _alignment));\n+    if (first_empty->offset() % _payload_alignment != 0) {\n+      LayoutRawBlock* padding = new LayoutRawBlock(LayoutRawBlock::PADDING, _payload_alignment - (first_empty->offset() % _payload_alignment));\n@@ -1022,4 +1094,0 @@\n-  if (EnableNullableFieldFlattening && _layout->has_missing_null_markers()) {\n-    insert_null_markers();\n-  }\n-\n@@ -1031,1 +1099,1 @@\n-    \/\/ special case for empty value types\n+    assert(_is_abstract_value, \"Concrete inline types must have at least one field\");\n@@ -1035,5 +1103,5 @@\n-  if (_layout->first_field_block() == nullptr) {\n-    assert(_is_abstract_value, \"Concrete inline types must have at least one field\");\n-    _payload_size_in_bytes = 0;\n-  } else {\n-    _payload_size_in_bytes = _layout->last_block()->offset() - _layout->first_field_block()->offset();\n+\n+  \/\/ Determining if the value class is naturally atomic:\n+  if ((!_layout->super_has_fields() && _declared_non_static_fields_count <= 1 && !_has_non_naturally_atomic_fields)\n+      || (_layout->super_has_fields() && _super_klass->is_naturally_atomic() && _declared_non_static_fields_count == 0)) {\n+        _is_naturally_atomic = true;\n@@ -1042,6 +1110,18 @@\n-  \/\/ Looking if there's an empty slot inside the layout that could be used to store a null marker\n-  LayoutRawBlock* b = _layout->first_field_block();\n-  if (b != nullptr) {\n-    while (b != _layout->last_block()) {\n-      if (b->kind() == LayoutRawBlock::EMPTY) {\n-        break;\n+  \/\/ At this point, the characteristics of the raw layout (used in standalone instances) are known.\n+  \/\/ From this, additional layouts will be computed: atomic and nullable layouts\n+  \/\/ Once those additional layouts are computed, the raw layout might need some adjustments\n+\n+  if (!_is_abstract_value) { \/\/ Flat layouts are only for concrete value classes\n+    \/\/ Validation of the non atomic layout\n+    if ((InlineFieldMaxFlatSize < 0 || _payload_size_in_bytes * BitsPerByte <= InlineFieldMaxFlatSize)\n+         && (!_must_be_atomic || _is_naturally_atomic)) {\n+      _non_atomic_layout_size_in_bytes = _payload_size_in_bytes;\n+      _non_atomic_layout_alignment = _payload_alignment;\n+    }\n+\n+    \/\/ Next step is to compute the characteristics for a layout enabling atomic updates\n+    if (AtomicFieldFlattening) {\n+      int atomic_size = _payload_size_in_bytes == 0 ? 0 : round_up_power_of_2(_payload_size_in_bytes);\n+      if (  atomic_size <= (int)MAX_ATOMIC_OP_SIZE\n+          && (InlineFieldMaxFlatSize < 0 || atomic_size * BitsPerByte <= InlineFieldMaxFlatSize)) {\n+        _atomic_layout_size_in_bytes = atomic_size;\n@@ -1049,1 +1129,0 @@\n-      b = b->next_block();\n@@ -1051,3 +1130,83 @@\n-    if (b != _layout->last_block()) {\n-      \/\/ found an empty slot, register its offset from the beginning of the payload\n-      _internal_null_marker_offset = b->offset();\n+\n+    \/\/ Next step is the nullable layout: the layout must include a null marker and must also be atomic\n+    if (NullableFieldFlattening) {\n+      \/\/ Looking if there's an empty slot inside the layout that could be used to store a null marker\n+      \/\/ FIXME: could it be possible to re-use the .empty field as a null marker for empty values?\n+      LayoutRawBlock* b = _layout->first_field_block();\n+      assert(b != nullptr, \"A concrete value class must have at least one (possible dummy) field\");\n+      int null_marker_offset = -1;\n+      if (_is_empty_inline_class) {\n+        \/\/ Reusing the dummy field as a field marker\n+        assert(_field_info->adr_at(b->field_index())->name(_constant_pool) == vmSymbols::empty_marker_name(), \"b must be the dummy field\");\n+        null_marker_offset = b->offset();\n+      } else {\n+        while (b != _layout->last_block()) {\n+          if (b->block_kind() == LayoutRawBlock::EMPTY) {\n+            break;\n+          }\n+          b = b->next_block();\n+        }\n+        if (b != _layout->last_block()) {\n+          \/\/ found an empty slot, register its offset from the beginning of the payload\n+          null_marker_offset = b->offset();\n+          LayoutRawBlock* marker = new LayoutRawBlock(LayoutRawBlock::NULL_MARKER, 1);\n+          _layout->add_field_at_offset(marker, b->offset());\n+        }\n+        if (null_marker_offset == -1) { \/\/ no empty slot available to store the null marker, need to inject one\n+          int last_offset = _layout->last_block()->offset();\n+          LayoutRawBlock* marker = new LayoutRawBlock(LayoutRawBlock::NULL_MARKER, 1);\n+          _layout->insert_field_block(_layout->last_block(), marker);\n+          assert(marker->offset() == last_offset, \"Null marker should have been inserted at the end\");\n+          null_marker_offset = marker->offset();\n+        }\n+      }\n+\n+      \/\/ Now that the null marker is there, the size of the nullable layout must computed (remember, must be atomic too)\n+      int new_raw_size = _layout->last_block()->offset() - _layout->first_field_block()->offset();\n+      int nullable_size = round_up_power_of_2(new_raw_size);\n+      if (nullable_size <= (int)MAX_ATOMIC_OP_SIZE\n+        && (InlineFieldMaxFlatSize < 0 || nullable_size * BitsPerByte <= InlineFieldMaxFlatSize)) {\n+        _nullable_layout_size_in_bytes = nullable_size;\n+        _null_marker_offset = null_marker_offset;\n+      } else {\n+        \/\/ If the nullable layout is rejected, the NULL_MARKER block should be removed\n+        \/\/ from the layout, otherwise it will appear anyway if the layout is printer\n+        _layout->remove_null_marker();\n+        _null_marker_offset = -1;\n+      }\n+    }\n+    \/\/ If the inline class has an atomic or nullable (which is also atomic) layout,\n+    \/\/ we want the raw layout to have the same alignment as those atomic layouts so access codes\n+    \/\/ could remain  simple (single instruction without intermediate copy). This might required\n+    \/\/ to shift all fields in the raw layout, but this operation is possible only if the class\n+    \/\/ doesn't have inherited fields (offsets of inherited fields cannot be changed). If a\n+    \/\/ field shift is needed but not possible, all atomic layouts are disabled and only reference\n+    \/\/ and loosely consistent are supported.\n+    int required_alignment = _payload_alignment;\n+    if (has_atomic_layout() && _payload_alignment < atomic_layout_size_in_bytes()) {\n+      required_alignment = atomic_layout_size_in_bytes();\n+    }\n+    if (has_nullable_layout() && _payload_alignment < nullable_layout_size_in_bytes()) {\n+      required_alignment = nullable_layout_size_in_bytes();\n+    }\n+    int shift = first_field->offset() % required_alignment;\n+    if (shift != 0) {\n+      if (required_alignment > _payload_alignment && !_layout->has_inherited_fields()) {\n+        assert(_layout->first_field_block() != nullptr, \"A concrete value class must have at least one (possible dummy) field\");\n+        _layout->shift_fields(shift);\n+        _first_field_offset = _layout->first_field_block()->offset();\n+        if (has_nullable_layout()) {\n+          assert(!_is_empty_inline_class, \"Should not get here with empty values\");\n+          _null_marker_offset = _layout->find_null_marker()->offset();\n+        }\n+        _payload_alignment = required_alignment;\n+      } else {\n+        _atomic_layout_size_in_bytes = -1;\n+        if (has_nullable_layout() && !_is_empty_inline_class) {  \/\/ empty values don't have a dedicated NULL_MARKER block\n+          _layout->remove_null_marker();\n+        }\n+        _nullable_layout_size_in_bytes = -1;\n+        _null_marker_offset = -1;\n+      }\n+    } else {\n+      _payload_alignment = required_alignment;\n@@ -1055,3 +1214,0 @@\n-  } else {\n-    assert(_is_abstract_value, \"Only abstract value can have no fields\");\n-  }\n@@ -1059,0 +1215,7 @@\n+    \/\/ If the inline class has a nullable layout, the layout used in heap allocated standalone\n+    \/\/ instances must also be the nullable layout, in order to be able to set the null marker to\n+    \/\/ non-null before copying the payload to other containers.\n+    if (has_nullable_layout() && payload_layout_size_in_bytes() < nullable_layout_size_in_bytes()) {\n+      _payload_size_in_bytes = nullable_layout_size_in_bytes();\n+    }\n+  }\n@@ -1079,9 +1242,8 @@\n-  if (list != nullptr) {\n-    for (int i = 0; i < list->length(); i++) {\n-      LayoutRawBlock* f = list->at(i);\n-      if (f->kind() == LayoutRawBlock::FLAT) {\n-        InlineKlass* vk = f->inline_klass();\n-        assert(vk != nullptr, \"Should have been initialized\");\n-        if (vk->contains_oops()) {\n-          add_flat_field_oopmap(nonstatic_oop_maps, vk, f->offset());\n-        }\n+  if (list == nullptr) return;\n+  for (int i = 0; i < list->length(); i++) {\n+    LayoutRawBlock* f = list->at(i);\n+    if (f->block_kind() == LayoutRawBlock::FLAT) {\n+      InlineKlass* vk = f->inline_klass();\n+      assert(vk != nullptr, \"Should have been initialized\");\n+      if (vk->contains_oops()) {\n+        add_flat_field_oopmap(nonstatic_oop_maps, vk, f->offset());\n@@ -1106,2 +1268,0 @@\n-  int super_oop_map_count = (_super_klass == nullptr) ? 0 :_super_klass->nonstatic_oop_map_count();\n-  int max_oop_map_count = super_oop_map_count + _nonstatic_oopmap_count;\n@@ -1109,1 +1269,2 @@\n-      new OopMapBlocksBuilder(max_oop_map_count);\n+      new OopMapBlocksBuilder(_nonstatic_oopmap_count);\n+  int super_oop_map_count = (_super_klass == nullptr) ? 0 :_super_klass->nonstatic_oop_map_count();\n@@ -1140,8 +1301,16 @@\n-  _info->_has_null_marker_offsets = _has_null_markers;\n-\n-  \/\/ An inline type is naturally atomic if it has just one field, and\n-  \/\/ that field is simple enough.\n-  _info->_is_naturally_atomic = (_is_inline_type &&\n-                                 (_atomic_field_count <= 1) &&\n-                                 !_has_nonatomic_values &&\n-                                 _contended_groups.is_empty());\n+  _info->_is_naturally_atomic = _is_naturally_atomic;\n+  if (_is_inline_type) {\n+    _info->_must_be_atomic = _must_be_atomic;\n+    _info->_payload_alignment = _payload_alignment;\n+    _info->_first_field_offset = _first_field_offset;\n+    _info->_payload_size_in_bytes = _payload_size_in_bytes;\n+    _info->_non_atomic_size_in_bytes = _non_atomic_layout_size_in_bytes;\n+    _info->_non_atomic_alignment = _non_atomic_layout_alignment;\n+    _info->_atomic_layout_size_in_bytes = _atomic_layout_size_in_bytes;\n+    _info->_nullable_layout_size_in_bytes = _nullable_layout_size_in_bytes;\n+    _info->_null_marker_offset = _null_marker_offset;\n+    _info->_default_value_offset = _static_layout->default_value_offset();\n+    _info->_null_reset_value_offset = _static_layout->null_reset_value_offset();\n+    _info->_is_empty_inline_klass = _is_empty_inline_class;\n+  }\n+\n@@ -1161,1 +1330,4 @@\n-    if (b->kind() == LayoutRawBlock::REGULAR || b->kind() == LayoutRawBlock::FLAT) {\n+    if (b->block_kind() == LayoutRawBlock::REGULAR || b->block_kind() == LayoutRawBlock::FLAT) {\n+      if (_field_info->adr_at(b->field_index())->offset() != (u4)b->offset()) {\n+        tty->print_cr(\"Offset from field info = %d, offset from block = %d\", (int)_field_info->adr_at(b->field_index())->offset(), b->offset());\n+      }\n@@ -1168,1 +1340,1 @@\n-    if (b->kind() == LayoutRawBlock::REGULAR || b->kind() == LayoutRawBlock::FLAT) {\n+    if (b->block_kind() == LayoutRawBlock::REGULAR || b->block_kind() == LayoutRawBlock::FLAT) {\n@@ -1193,1 +1365,1 @@\n-    _layout->print(&st, false, _super_klass, _inline_type_field_klasses);\n+    _layout->print(&st, false, _super_klass, _inline_layout_info_array);\n@@ -1195,1 +1367,1 @@\n-    _static_layout->print(&st, true, nullptr, _inline_type_field_klasses);\n+    _static_layout->print(&st, true, nullptr, _inline_layout_info_array);\n@@ -1199,4 +1371,18 @@\n-      st.print_cr(\"Alignment = %d bytes\", _alignment);\n-      st.print_cr(\"Exact size = %d bytes\", _payload_size_in_bytes);\n-      if (_internal_null_marker_offset != -1) {\n-        st.print_cr(\"Null marker offset = %d\", _internal_null_marker_offset);\n+      st.print_cr(\"Payload layout: %d\/%d\", _payload_size_in_bytes, _payload_alignment);\n+      if (has_non_atomic_flat_layout()) {\n+        st.print_cr(\"Non atomic flat layout: %d\/%d\", _non_atomic_layout_size_in_bytes, _non_atomic_layout_alignment);\n+      } else {\n+        st.print_cr(\"Non atomic flat layout: -\/-\");\n+      }\n+      if (has_atomic_layout()) {\n+        st.print_cr(\"Atomic flat layout: %d\/%d\", _atomic_layout_size_in_bytes, _atomic_layout_size_in_bytes);\n+      } else {\n+        st.print_cr(\"Atomic flat layout: -\/-\");\n+      }\n+      if (has_nullable_layout()) {\n+        st.print_cr(\"Nullable flat layout: %d\/%d\", _nullable_layout_size_in_bytes, _nullable_layout_size_in_bytes);\n+      } else {\n+        st.print_cr(\"Nullable flat layout: -\/-\");\n+      }\n+      if (_null_marker_offset != -1) {\n+        st.print_cr(\"Null marker offset = %d\", _null_marker_offset);\n","filename":"src\/hotspot\/share\/classfile\/fieldLayoutBuilder.cpp","additions":463,"deletions":277,"binary":false,"changes":740,"status":"modified"},{"patch":"@@ -32,0 +32,2 @@\n+#include \"oops\/inlineKlass.hpp\"\n+#include \"oops\/instanceKlass.hpp\"\n@@ -52,0 +54,3 @@\n+\n+#define MAX_ATOMIC_OP_SIZE sizeof(uint64_t)\n+\n@@ -62,2 +67,1 @@\n-    NULL_MARKER,           \/\/ stores the null marker for a flat field\n-    INHERITED_NULL_MARKER  \/\/ a super-class used this slot to store a null marker\n+    NULL_MARKER            \/\/ stores the null marker for a flat field\n@@ -70,1 +74,2 @@\n-  Kind _kind;\n+  Kind _block_kind;\n+  LayoutKind _layout_kind;\n@@ -76,2 +81,0 @@\n-  bool _is_reference;\n-  bool _needs_null_marker;\n@@ -82,1 +85,1 @@\n-  LayoutRawBlock(int index, Kind kind, int size, int alignment, bool is_reference = false);\n+  LayoutRawBlock(int index, Kind kind, int size, int alignment);\n@@ -87,1 +90,2 @@\n-  Kind kind() const { return _kind; }\n+  Kind block_kind() const { return _block_kind; }\n+  void set_block_kind(LayoutRawBlock::Kind kind) { _block_kind = kind; } \/\/ Dangerous operation, is only used by remove_null_marker();\n@@ -104,1 +108,0 @@\n-  bool is_reference() const { return _is_reference; }\n@@ -110,7 +113,1 @@\n-  void set_needs_null_marker() { _needs_null_marker = true; }\n-  bool needs_null_marker() const { return _needs_null_marker; }\n-  void set_null_marker_offset(int offset) {\n-    assert(_needs_null_marker, \"\");\n-    _null_marker_offset = offset;\n-    _needs_null_marker = false;\n-  }\n+  void set_null_marker_offset(int offset) { _null_marker_offset = offset; }\n@@ -119,0 +116,3 @@\n+  LayoutKind layout_kind() const { return _layout_kind; }\n+  void set_layout_kind(LayoutKind kind) { _layout_kind = kind; }\n+\n@@ -170,1 +170,1 @@\n-  void add_flat_field(int idx, InlineKlass* vk, bool needs_null_marker);\n+  void add_flat_field(int idx, InlineKlass* vk, LayoutKind lk, int size, int alignment);\n@@ -197,0 +197,1 @@\n+  Array<InlineLayoutInfo>* _inline_layout_info_array;\n@@ -204,0 +205,2 @@\n+  int _default_value_offset;  \/\/ offset of the default value in class mirror, only for static layout of inline classes\n+  int _null_reset_value_offset;    \/\/ offset of the reset value in class mirror, only for static layout of inline classes\n@@ -205,1 +208,1 @@\n-  bool _has_missing_null_markers;\n+  bool _has_inherited_fields;\n@@ -208,1 +211,1 @@\n-  FieldLayout(GrowableArray<FieldInfo>* field_info, ConstantPool* cp);\n+  FieldLayout(GrowableArray<FieldInfo>* field_info, Array<InlineLayoutInfo>* inline_layout_info_array, ConstantPool* cp);\n@@ -214,1 +217,1 @@\n-    while (block->kind() != LayoutRawBlock::EMPTY) {\n+    while (block->block_kind() != LayoutRawBlock::EMPTY) {\n@@ -228,0 +231,8 @@\n+  int default_value_offset() const {\n+    assert(_default_value_offset != -1, \"Must have been set\");\n+    return _default_value_offset;\n+  }\n+  int null_reset_value_offset() const {\n+    assert(_null_reset_value_offset != -1, \"Must have been set\");\n+    return _null_reset_value_offset;\n+  }\n@@ -229,1 +240,1 @@\n-  bool has_missing_null_markers() const { return _has_missing_null_markers; }\n+  bool has_inherited_fields() const { return _has_inherited_fields; }\n@@ -240,1 +251,4 @@\n-  void print(outputStream* output, bool is_static, const InstanceKlass* super, Array<InlineKlass*>* inline_fields);\n+  void shift_fields(int shift);\n+  LayoutRawBlock* find_null_marker();\n+  void remove_null_marker();\n+  void print(outputStream* output, bool is_static, const InstanceKlass* super, Array<InlineLayoutInfo>* inline_fields);\n@@ -268,0 +282,1 @@\n+\n@@ -275,1 +290,1 @@\n-  Array<InlineKlass*>* _inline_type_field_klasses;\n+  Array<InlineLayoutInfo>* _inline_layout_info_array;\n@@ -282,1 +297,1 @@\n-  int _alignment;\n+  int _payload_alignment;\n@@ -284,1 +299,1 @@\n-  int _internal_null_marker_offset; \/\/ if any, -1 means no internal null marker\n+  int _null_marker_offset; \/\/ if any, -1 means no internal null marker\n@@ -286,1 +301,4 @@\n-  int _atomic_field_count;\n+  int _non_atomic_layout_size_in_bytes;\n+  int _non_atomic_layout_alignment;\n+  int _atomic_layout_size_in_bytes;\n+  int _nullable_layout_size_in_bytes;\n@@ -288,0 +306,4 @@\n+  int _declared_non_static_fields_count;\n+  bool _has_non_naturally_atomic_fields;\n+  bool _is_naturally_atomic;\n+  bool _must_be_atomic;\n@@ -294,3 +316,1 @@\n-  bool _has_nonatomic_values;\n-  bool _nullable_atomic_flat_candidate;\n-  bool _has_null_markers;\n+  bool _is_empty_inline_class;\n@@ -303,20 +323,14 @@\n-                     FieldLayoutInfo* info, Array<InlineKlass*>* inline_type_field_klasses);\n-\n-  int get_alignment() {\n-    assert(_alignment != -1, \"Uninitialized\");\n-    return _alignment;\n-  }\n-\n-  int get_first_field_offset() {\n-    assert(_first_field_offset != -1, \"Uninitialized\");\n-    return _first_field_offset;\n-  }\n-\n-  int get_payload_size_in_byte() {\n-    assert(_payload_size_in_bytes != -1, \"Uninitialized\");\n-    return _payload_size_in_bytes;\n-  }\n-\n-  int get_internal_null_marker_offset() {\n-    return _internal_null_marker_offset;\n-  }\n+                     bool must_be_atomic, FieldLayoutInfo* info, Array<InlineLayoutInfo>* inline_layout_info_array);\n+\n+  int first_field_offset() const               { assert(_first_field_offset != -1, \"Uninitialized\"); return _first_field_offset; }\n+  int  payload_layout_size_in_bytes() const    { return _payload_size_in_bytes; }\n+  int  payload_layout_alignment() const        { assert(_payload_alignment != -1, \"Uninitialized\"); return _payload_alignment; }\n+  bool has_non_atomic_flat_layout() const      { return _non_atomic_layout_size_in_bytes != -1; }\n+  int  non_atomic_layout_size_in_bytes() const { return _non_atomic_layout_size_in_bytes; }\n+  int  non_atomic_layout_alignment() const     { return _non_atomic_layout_alignment; }\n+  bool has_atomic_layout() const               { return _atomic_layout_size_in_bytes != -1; }\n+  int  atomic_layout_size_in_bytes() const     { return _atomic_layout_size_in_bytes; }\n+  bool has_nullable_layout() const             { return _nullable_layout_size_in_bytes != -1; }\n+  int  nullable_layout_size_in_bytes() const   { return _nullable_layout_size_in_bytes; }\n+  int  null_marker_offset() const              { return _null_marker_offset; }\n+  bool is_empty_inline_class() const           { return _is_empty_inline_class; }\n@@ -328,1 +342,0 @@\n-  void insert_null_markers();\n","filename":"src\/hotspot\/share\/classfile\/fieldLayoutBuilder.hpp","additions":62,"deletions":49,"binary":false,"changes":111,"status":"modified"},{"patch":"@@ -3847,1 +3847,1 @@\n-  macro(_value_offset,      integerKlass, \"value\", int_signature, false); \\\n+  macro(_value_offset,      byteKlass, \"value\", byte_signature, false); \\\n@@ -3851,1 +3851,1 @@\n-  InstanceKlass* integerKlass = vmClasses::Integer_klass();\n+  InstanceKlass* byteKlass = vmClasses::Byte_klass();\n@@ -5506,1 +5506,5 @@\n-  CHECK_OFFSET(\"java\/lang\/Float\",     java_lang_boxing_object, value, \"F\");\n+  if (Arguments::enable_preview() && NullableFieldFlattening && (InlineFieldMaxFlatSize >= 64 || InlineFieldMaxFlatSize < 0)) {\n+    CHECK_LONG_OFFSET(\"java\/lang\/Float\",     java_lang_boxing_object, value, \"F\");\n+  } else {\n+    CHECK_OFFSET(\"java\/lang\/Float\",     java_lang_boxing_object, value, \"F\");\n+  }\n@@ -5510,1 +5514,5 @@\n-  CHECK_OFFSET(\"java\/lang\/Integer\",   java_lang_boxing_object, value, \"I\");\n+  if (Arguments::enable_preview() && NullableFieldFlattening && (InlineFieldMaxFlatSize >= 64 || InlineFieldMaxFlatSize < 0)) {\n+    CHECK_LONG_OFFSET(\"java\/lang\/Integer\",   java_lang_boxing_object, value, \"I\");\n+  } else {\n+    CHECK_OFFSET(\"java\/lang\/Integer\",   java_lang_boxing_object, value, \"I\");\n+  }\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":12,"deletions":4,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -516,0 +516,1 @@\n+  template(null_reset_value_name,                     \".null_reset\")                              \\\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -320,2 +320,2 @@\n-    static void value_copy_in_heap(void* src, void* dst, InlineKlass* md) {\n-      Raw::value_copy(src, dst, md);\n+    static void value_copy_in_heap(void* src, void* dst, InlineKlass* md, LayoutKind lk) {\n+      Raw::value_copy(src, dst, md, lk);\n","filename":"src\/hotspot\/share\/gc\/shared\/barrierSet.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+\n@@ -33,1 +34,5 @@\n-  HeapAccess<>::value_copy(src, dst, md);\n+  HeapAccess<>::value_copy(src, dst, md, LayoutKind::PAYLOAD);  \/\/ FIXME Hard coded value for the transition\n+JRT_END\n+\n+JRT_LEAF(void, BarrierSetRuntime::value_copy2(void* src, void* dst, InlineLayoutInfo* li))\n+  HeapAccess<>::value_copy(src, dst, li->klass(), li->kind());\n@@ -38,1 +43,5 @@\n-  HeapAccess<IS_DEST_UNINITIALIZED>::value_copy(src, dst, md);\n+  HeapAccess<IS_DEST_UNINITIALIZED>::value_copy(src, dst, md, LayoutKind::PAYLOAD); \/\/ FIXME Hard coded value for the transition\n+JRT_END\n+\n+JRT_LEAF(void, BarrierSetRuntime::value_copy_is_dest_uninitialized2(void* src, void* dst, InlineLayoutInfo* li))\n+  HeapAccess<IS_DEST_UNINITIALIZED>::value_copy(src, dst, li->klass(), li->kind());\n","filename":"src\/hotspot\/share\/gc\/shared\/barrierSetRuntime.cpp","additions":11,"deletions":2,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+  static void value_copy2(void* src, void* dst, InlineLayoutInfo* layout_info);\n@@ -42,0 +43,1 @@\n+  static void value_copy_is_dest_uninitialized2(void* src, void* dst, InlineLayoutInfo* layout_info);\n","filename":"src\/hotspot\/share\/gc\/shared\/barrierSetRuntime.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -107,1 +107,1 @@\n-    static void value_copy_in_heap(void* src, void* dst, InlineKlass* md);\n+    static void value_copy_in_heap(void* src, void* dst, InlineKlass* md, LayoutKind lk);\n","filename":"src\/hotspot\/share\/gc\/shared\/modRefBarrierSet.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -161,1 +161,1 @@\n-value_copy_in_heap(void* src, void* dst, InlineKlass* md) {\n+value_copy_in_heap(void* src, void* dst, InlineKlass* md, LayoutKind lk) {\n@@ -163,1 +163,1 @@\n-    Raw::value_copy(src, dst, md);\n+    Raw::value_copy(src, dst, md, lk);\n@@ -179,1 +179,1 @@\n-    Raw::value_copy(src, dst, md);\n+    Raw::value_copy(src, dst, md, lk);\n","filename":"src\/hotspot\/share\/gc\/shared\/modRefBarrierSet.inline.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -87,1 +87,1 @@\n-    static void value_copy_in_heap(void* src, void* dst, InlineKlass* md);\n+    static void value_copy_in_heap(void* src, void* dst, InlineKlass* md, LayoutKind lk);\n","filename":"src\/hotspot\/share\/gc\/x\/xBarrierSet.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -220,1 +220,1 @@\n-inline void XBarrierSet::AccessBarrier<decorators, BarrierSetT>::value_copy_in_heap(void* src, void* dst, InlineKlass* md) {\n+inline void XBarrierSet::AccessBarrier<decorators, BarrierSetT>::value_copy_in_heap(void* src, void* dst, InlineKlass* md, LayoutKind lk) {\n@@ -233,1 +233,1 @@\n-  Raw::value_copy_in_heap(src, dst, md);\n+  Raw::value_copy_in_heap(src, dst, md, lk);\n","filename":"src\/hotspot\/share\/gc\/x\/xBarrierSet.inline.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -144,1 +144,1 @@\n-    static void value_copy_in_heap(void* src, void* dst, InlineKlass* md);\n+    static void value_copy_in_heap(void* src, void* dst, InlineKlass* md, LayoutKind lk);\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrierSet.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -483,1 +483,1 @@\n-inline void ZBarrierSet::AccessBarrier<decorators, BarrierSetT>::value_copy_in_heap(void* src, void* dst, InlineKlass* md) {\n+inline void ZBarrierSet::AccessBarrier<decorators, BarrierSetT>::value_copy_in_heap(void* src, void* dst, InlineKlass* md, LayoutKind lk) {\n@@ -499,1 +499,1 @@\n-  Raw::value_copy_in_heap(src, dst, md);\n+  Raw::value_copy_in_heap(src, dst, md, lk);\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrierSet.inline.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -262,1 +262,8 @@\n-      klass->set_inline_type_field_klass(index, InlineKlass::cast(field_k));\n+      if (!field_k->is_inline_klass()) {\n+        THROW_MSG(vmSymbols::java_lang_IncompatibleClassChangeError(),\n+                  err_msg(\"class %s expects class %s to be a concrete value class but it is not\",\n+                  klass->name()->as_C_string(), field_k->external_name()));\n+      }\n+      InlineLayoutInfo* li = klass->inline_layout_info_adr(index);\n+      li->set_klass(InlineKlass::cast(field_k));\n+      li->set_kind(LayoutKind::REFERENCE);\n@@ -288,3 +295,1 @@\n-JRT_ENTRY(void, InterpreterRuntime::read_flat_field(JavaThread* current, oopDesc* obj, int index, Klass* field_holder))\n-  Handle obj_h(THREAD, obj);\n-\n+JRT_ENTRY(void, InterpreterRuntime::read_flat_field(JavaThread* current, oopDesc* obj, ResolvedFieldEntry* entry))\n@@ -292,0 +297,1 @@\n+  Handle obj_h(THREAD, obj);\n@@ -293,4 +299,2 @@\n-  assert(field_holder->is_instance_klass(), \"Sanity check\");\n-  InstanceKlass* klass = InstanceKlass::cast(field_holder);\n-\n-  assert(klass->field_is_flat(index), \"Sanity check\");\n+  InstanceKlass* holder = InstanceKlass::cast(entry->field_holder());\n+  assert(entry->field_holder()->field_is_flat(entry->field_index()), \"Sanity check\");\n@@ -298,1 +302,2 @@\n-  InlineKlass* field_vklass = InlineKlass::cast(klass->get_inline_type_field_klass(index));\n+  InlineLayoutInfo* layout_info = holder->inline_layout_info_adr(entry->field_index());\n+  InlineKlass* field_vklass = layout_info->klass();\n@@ -300,1 +305,1 @@\n-  oop res = field_vklass->read_flat_field(obj_h(), klass->field_offset(index), CHECK);\n+  oop res = field_vklass->read_flat_field(obj_h(), entry->field_offset(), layout_info->kind(), CHECK);\n@@ -304,5 +309,0 @@\n-\/\/ The protocol to read a nullable flat field is:\n-\/\/ Step 1: read the null marker with an load_acquire barrier to ensure that\n-\/\/         reordered loads won't try to load the value before the null marker is read\n-\/\/ Step 2: if the null marker value is zero, the field's value is null\n-\/\/         otherwise the flat field value can be read like a regular flat field\n@@ -314,1 +314,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(obj_h()->klass());\n+  InstanceKlass* holder = entry->field_holder();\n@@ -316,1 +316,3 @@\n-  int nm_offset = ik->null_marker_offsets_array()->at(field_index);\n+  InlineLayoutInfo* li= holder->inline_layout_info_adr(field_index);\n+\n+  int nm_offset = li->null_marker_offset();\n@@ -320,2 +322,2 @@\n-    InlineKlass* field_vklass = InlineKlass::cast(ik->get_inline_type_field_klass(field_index));\n-    oop res = field_vklass->read_flat_field(obj_h(), ik->field_offset(field_index), CHECK);\n+    InlineKlass* field_vklass = InlineKlass::cast(li->klass());\n+    oop res = field_vklass->read_flat_field(obj_h(), entry->field_offset(), LayoutKind::NULLABLE_ATOMIC_FLAT, CHECK);\n@@ -326,6 +328,0 @@\n-\/\/ The protocol to write a nullable flat field is:\n-\/\/ If the new field value is null, just write zero to the null marker\n-\/\/ Otherwise:\n-\/\/ Step 1: write the field value like a regular flat field\n-\/\/ Step 2: have a memory barrier to ensure that the whole value content is visible\n-\/\/ Step 3: update the null marker to a non zero value\n@@ -338,2 +334,6 @@\n-  InstanceKlass* ik = InstanceKlass::cast(obj_h()->klass());\n-  int nm_offset = ik->null_marker_offsets_array()->at(entry->field_index());\n+  InstanceKlass* holder = entry->field_holder();\n+  InlineLayoutInfo* li = holder->inline_layout_info_adr(entry->field_index());\n+  InlineKlass* vk = li->klass();\n+  assert(li->kind() == LayoutKind::NULLABLE_ATOMIC_FLAT, \"Must be\");\n+  int nm_offset = li->null_marker_offset();\n+\n@@ -341,1 +341,8 @@\n-    obj_h()->byte_field_put(nm_offset, (jbyte)0);\n+    if(li->klass()->nonstatic_oop_count() == 0) {\n+      \/\/ No embedded oops, just reset the null marker\n+      obj_h()->byte_field_put(nm_offset, (jbyte)0);\n+    } else {\n+      \/\/ Has embedded oops, using the reset value to rewrite all fields to null\/zeros\n+      assert(li->klass()->null_reset_value()->byte_field(vk->null_marker_offset()) == 0, \"reset value must always have a null marker set to 0\");\n+      vk->inline_copy_oop_to_payload(vk->null_reset_value(), ((char*)(oopDesc*)obj_h()) + entry->field_offset(), li->kind());\n+    }\n@@ -344,13 +351,7 @@\n-  InlineKlass* vk = InlineKlass::cast(val_h()->klass());\n-  if (entry->has_internal_null_marker()) {\n-    \/\/ The interpreter copies values with a bulk operation\n-    \/\/ To avoid accidently setting the null marker to \"null\" during\n-    \/\/ the copying, the null marker is set to non zero in the source object\n-    if (val_h()->byte_field(vk->get_internal_null_marker_offset()) == 0) {\n-      val_h()->byte_field_put(vk->get_internal_null_marker_offset(), (jbyte)1);\n-    }\n-    vk->write_non_null_flat_field(obj_h(), entry->field_offset(), val_h());\n-  } else {\n-    vk->write_non_null_flat_field(obj_h(), entry->field_offset(), val_h());\n-    OrderAccess::release();\n-    obj_h()->byte_field_put(nm_offset, (jbyte)1);\n+\n+  assert(val_h()->klass() == vk, \"Must match because flat fields are monomorphic\");\n+  \/\/ The interpreter copies values with a bulk operation\n+  \/\/ To avoid accidentally setting the null marker to \"null\" during\n+  \/\/ the copying, the null marker is set to non zero in the source object\n+  if (val_h()->byte_field(vk->null_marker_offset()) == 0) {\n+    val_h()->byte_field_put(vk->null_marker_offset(), (jbyte)1);\n@@ -358,0 +359,1 @@\n+  vk->inline_copy_oop_to_payload(val_h(), ((char*)(oopDesc*)obj_h()) + entry->field_offset(), li->kind());\n@@ -380,1 +382,1 @@\n-  ((flatArrayOop)array)->value_copy_to_index(cast_to_oop(val), index);\n+  ((flatArrayOop)array)->value_copy_to_index(cast_to_oop(val), index, LayoutKind::PAYLOAD); \/\/ Non atomic is the only layout currently supported by flat arrays\n@@ -885,1 +887,1 @@\n-                   info.has_null_marker(), info.has_internal_null_marker());\n+                   info.has_null_marker());\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":45,"deletions":43,"binary":false,"changes":88,"status":"modified"},{"patch":"@@ -66,1 +66,1 @@\n-  static void    read_flat_field(JavaThread* current, oopDesc* value, int index, Klass* field_holder);\n+  static void    read_flat_field(JavaThread* current, oopDesc* object, ResolvedFieldEntry* entry);\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -318,1 +318,2 @@\n-  f(RecordComponent)\n+  f(RecordComponent) \\\n+  f(InlineLayoutInfo)\n","filename":"src\/hotspot\/share\/memory\/allocation.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -93,2 +94,0 @@\n-class InlineKlass;\n-\n@@ -226,1 +225,1 @@\n-  static inline void value_copy(void* src, void* dst, InlineKlass* md) {\n+  static inline void value_copy(void* src, void* dst, InlineKlass* md, LayoutKind lk) {\n@@ -228,1 +227,1 @@\n-    AccessInternal::value_copy<decorators>(src, dst, md);\n+    AccessInternal::value_copy<decorators>(src, dst, md, lk);\n","filename":"src\/hotspot\/share\/oops\/access.hpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -204,2 +204,2 @@\n-    static void access_barrier(void* src, void* dst, InlineKlass* md) {\n-      GCBarrierType::value_copy_in_heap(src, dst, md);\n+    static void access_barrier(void* src, void* dst, InlineKlass* md, LayoutKind lk) {\n+      GCBarrierType::value_copy_in_heap(src, dst, md, lk);\n@@ -358,1 +358,1 @@\n-  void RuntimeDispatch<decorators, T, BARRIER_VALUE_COPY>::value_copy_init(void* src, void* dst, InlineKlass* md) {\n+  void RuntimeDispatch<decorators, T, BARRIER_VALUE_COPY>::value_copy_init(void* src, void* dst, InlineKlass* md, LayoutKind lk) {\n@@ -361,1 +361,1 @@\n-    function(src, dst, md);\n+    function(src, dst, md,lk);\n","filename":"src\/hotspot\/share\/oops\/access.inline.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -109,1 +110,1 @@\n-    typedef void (*value_copy_func_t)(void* src, void* dst, InlineKlass* md);\n+    typedef void (*value_copy_func_t)(void* src, void* dst, InlineKlass* md, LayoutKind lk);\n@@ -351,1 +352,1 @@\n-  static void value_copy(void* src, void* dst, InlineKlass* md);\n+  static void value_copy(void* src, void* dst, InlineKlass* md, LayoutKind lk);\n@@ -554,1 +555,1 @@\n-    static void value_copy_init(void* src, void* dst, InlineKlass* md);\n+    static void value_copy_init(void* src, void* dst, InlineKlass* md, LayoutKind lk);\n@@ -556,2 +557,2 @@\n-    static inline void value_copy(void* src, void* dst, InlineKlass* md) {\n-      _value_copy_func(src, dst, md);\n+    static inline void value_copy(void* src, void* dst, InlineKlass* md, LayoutKind lk) {\n+      _value_copy_func(src, dst, md, lk);\n@@ -924,1 +925,1 @@\n-    value_copy(void* src, void* dst, InlineKlass* md) {\n+    value_copy(void* src, void* dst, InlineKlass* md, LayoutKind lk) {\n@@ -926,1 +927,1 @@\n-      Raw::value_copy(src, dst, md);\n+      Raw::value_copy(src, dst, md, lk);\n@@ -932,1 +933,1 @@\n-      value_copy(void* src, void* dst, InlineKlass* md) {\n+      value_copy(void* src, void* dst, InlineKlass* md, LayoutKind lk) {\n@@ -934,1 +935,1 @@\n-      RuntimeDispatch<expanded_decorators, void*, BARRIER_VALUE_COPY>::value_copy(src, dst, md);\n+      RuntimeDispatch<expanded_decorators, void*, BARRIER_VALUE_COPY>::value_copy(src, dst, md, lk);\n@@ -1229,1 +1230,1 @@\n-  inline void value_copy(void* src, void* dst, InlineKlass* md) {\n+  inline void value_copy(void* src, void* dst, InlineKlass* md, LayoutKind lk) {\n@@ -1231,1 +1232,1 @@\n-    PreRuntimeDispatch::value_copy<expanded_decorators>(src, dst, md);\n+    PreRuntimeDispatch::value_copy<expanded_decorators>(src, dst, md, lk);\n","filename":"src\/hotspot\/share\/oops\/accessBackend.hpp","additions":12,"deletions":11,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -335,3 +335,3 @@\n-inline void RawAccessBarrier<decorators>::value_copy(void* src, void* dst, InlineKlass* md) {\n-  assert(is_aligned(src, md->get_alignment()) && is_aligned(dst, md->get_alignment()), \"Unalign value_copy\");\n-  AccessInternal::arraycopy_conjoint_atomic(src, dst, static_cast<size_t>(md->get_payload_size_in_bytes()));\n+inline void RawAccessBarrier<decorators>::value_copy(void* src, void* dst, InlineKlass* md, LayoutKind lk) {\n+  assert(is_aligned(src, md->layout_alignment(lk)) && is_aligned(dst, md->layout_alignment(lk)), \"Unalign value_copy\");\n+  AccessInternal::arraycopy_conjoint_atomic(src, dst, static_cast<size_t>(md->layout_size_in_bytes(lk)));\n","filename":"src\/hotspot\/share\/oops\/accessBackend.inline.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -74,1 +74,1 @@\n-  virtual bool element_access_is_atomic() { return true; }\n+  virtual bool element_access_must_be_atomic() { return true; }\n","filename":"src\/hotspot\/share\/oops\/arrayKlass.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -111,0 +111,3 @@\n+    if (fi_ref->field_flags().is_flat()) {\n+      assert(fi_ref->layout_kind() == fi.layout_kind(), \"Must be\");\n+    }\n","filename":"src\/hotspot\/share\/oops\/fieldInfo.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -37,0 +37,8 @@\n+enum LayoutKind {\n+  REFERENCE            = 0,    \/\/ indirection to a heap allocated instance\n+  PAYLOAD              = 1,    \/\/ layout used in heap allocated standalone instances, probably temporary for the transition\n+  NON_ATOMIC_FLAT      = 2,    \/\/ flat, no guarantee of atomic updates, no null marker\n+  ATOMIC_FLAT          = 3,    \/\/ flat, size compatible with atomic updates, alignment requirement is equal to the size\n+  NULLABLE_ATOMIC_FLAT = 4,    \/\/ flat, include a null marker, plus same properties as ATOMIC layout\n+  UNKNOWN              = 5     \/\/ used for uninitialized fields of type LayoutKind\n+};\n@@ -76,1 +84,2 @@\n-      _ff_flat,         \/\/ field is a flat field\n+      _ff_flat,         \/\/ field is a flat field, optional section includes a layout kind\n+      _ff_null_marker,  \/\/ field has a null marker, optional section includes the null marker offset\n@@ -81,3 +90,1 @@\n-      _ff_contended,    \/\/ is contended, may have contention-group\n-      _ff_null_marker,  \/\/ field has a null marker, optional section include the null marker offset\n-      _ff_internal_null_marker \/\/ null marker is internal (inside the layout of a flat field)\n+      _ff_contended    \/\/ is contended, may have contention-group\n@@ -92,0 +99,1 @@\n+      flag_mask((int)_ff_flat)        |\n@@ -122,1 +130,0 @@\n-    bool is_null_marker_internal() const {return test_flag(_ff_internal_null_marker); }\n@@ -132,1 +139,0 @@\n-    void update_internal_null_marker(bool z) { update_flag(_ff_internal_null_marker, z); }\n@@ -148,0 +154,1 @@\n+  LayoutKind _layout_kind;      \/\/ LayoutKind if the field is flat\n@@ -160,0 +167,1 @@\n+                _layout_kind(LayoutKind::UNKNOWN),\n@@ -171,0 +179,1 @@\n+            _layout_kind(LayoutKind::UNKNOWN),\n@@ -191,0 +200,5 @@\n+  LayoutKind layout_kind() const             { return _layout_kind; }\n+  void set_layout_kind(LayoutKind lk) {\n+    assert(_field_flags.is_flat(), \"Must be\");\n+    _layout_kind = lk;\n+  }\n@@ -192,1 +206,4 @@\n-  void set_null_marker_offset(u4 offset)     { _null_marker_offset = offset; }\n+  void set_null_marker_offset(u4 offset) {\n+    _field_flags.update_null_marker(true);\n+    _null_marker_offset = offset;\n+  }\n","filename":"src\/hotspot\/share\/oops\/fieldInfo.hpp","additions":24,"deletions":7,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"oops\/instanceKlass.hpp\"\n@@ -88,0 +89,4 @@\n+    if (fi.field_flags().is_flat()) {\n+      assert(fi.layout_kind() != LayoutKind::UNKNOWN, \"Must be set\");\n+      _consumer->accept_uint(fi.layout_kind());\n+    }\n@@ -126,0 +131,3 @@\n+  if (fi._field_flags.is_flat()) {\n+    fi._layout_kind = static_cast<LayoutKind>(next_uint());\n+  }\n@@ -142,0 +150,1 @@\n+                                ff.is_flat() +\n","filename":"src\/hotspot\/share\/oops\/fieldInfo.inline.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -97,1 +97,1 @@\n-  assert(element_klass->is_naturally_atomic() || (!InlineArrayAtomicAccess), \"Atomic by-default\");\n+  assert(element_klass->must_be_atomic() || (!InlineArrayAtomicAccess), \"Atomic by-default\");\n@@ -161,1 +161,1 @@\n-  int esize = log2i_exact(round_up_power_of_2(vk->get_payload_size_in_bytes()));\n+  int esize = log2i_exact(round_up_power_of_2(vk->payload_size_in_bytes()));\n@@ -272,1 +272,1 @@\n-             HeapAccess<>::value_copy(src, dst, s_elem_vklass);\n+             HeapAccess<>::value_copy(src, dst, s_elem_vklass, LayoutKind::PAYLOAD); \/\/ Temporary hack for the transition\n@@ -277,1 +277,1 @@\n-             HeapAccess<>::value_copy(src, dst, s_elem_vklass);\n+             HeapAccess<>::value_copy(src, dst, s_elem_vklass, LayoutKind::PAYLOAD); \/\/ Temporary hack for the transition\n@@ -320,1 +320,1 @@\n-       d_elem_vklass->inline_copy_oop_to_payload(se, dst);\n+       d_elem_vklass->inline_copy_oop_to_payload(se, dst, LayoutKind::PAYLOAD); \/\/ Temporary hack for the transition\n","filename":"src\/hotspot\/share\/oops\/flatArrayKlass.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -80,2 +80,2 @@\n-  bool element_access_is_atomic() {\n-    return element_klass()->is_atomic();\n+  bool element_access_must_be_atomic() {\n+    return element_klass()->must_be_atomic();\n","filename":"src\/hotspot\/share\/oops\/flatArrayKlass.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -43,2 +44,2 @@\n-  void value_copy_from_index(int index, oop dst) const;\n-  void value_copy_to_index(oop src, int index) const;\n+  void value_copy_from_index(int index, oop dst, LayoutKind lk) const;\n+  void value_copy_to_index(oop src, int index, LayoutKind lk) const;\n","filename":"src\/hotspot\/share\/oops\/flatArrayOop.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -56,1 +56,2 @@\n-    vklass->inline_copy_payload_to_new_oop(vah->value_at_addr(index, vaklass->layout_helper()), buf);\n+    vklass->inline_copy_payload_to_new_oop(vah->value_at_addr(index, vaklass->layout_helper()),\n+                                           buf, LayoutKind::PAYLOAD); \/\/ temporary hack for the transition\n@@ -61,1 +62,1 @@\n-inline void flatArrayOopDesc::value_copy_from_index(int index, oop dst) const {\n+inline void flatArrayOopDesc::value_copy_from_index(int index, oop dst, LayoutKind lk) const {\n@@ -65,1 +66,1 @@\n-  return vklass->inline_copy_payload_to_new_oop(src, dst);\n+  return vklass->inline_copy_payload_to_new_oop(src, dst, lk);\n@@ -68,1 +69,1 @@\n-inline void flatArrayOopDesc::value_copy_to_index(oop src, int index) const {\n+inline void flatArrayOopDesc::value_copy_to_index(oop src, int index, LayoutKind lk) const {\n@@ -75,1 +76,1 @@\n-  vklass->inline_copy_oop_to_payload(src, dst);\n+  vklass->inline_copy_oop_to_payload(src, dst, lk);\n","filename":"src\/hotspot\/share\/oops\/flatArrayOop.inline.hpp","additions":6,"deletions":5,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -75,1 +75,0 @@\n-  *((int*)adr_default_value_offset()) = 0;\n@@ -77,0 +76,10 @@\n+  set_default_value_offset(0);\n+  set_null_reset_value_offset(0);\n+  set_first_field_offset(-1);\n+  set_payload_size_in_bytes(-1);\n+  set_payload_alignment(-1);\n+  set_non_atomic_size_in_bytes(-1);\n+  set_non_atomic_alignment(-1);\n+  set_atomic_size_in_bytes(-1);\n+  set_nullable_size_in_bytes(-1);\n+  set_null_marker_offset(-1);\n@@ -79,3 +88,1 @@\n-oop InlineKlass::default_value() {\n-  assert(is_initialized() || is_being_initialized() || is_in_error_state(), \"default value is set at the beginning of initialization\");\n-  oop val = java_mirror()->obj_field_acquire(default_value_offset());\n+void InlineKlass::set_default_value(oop val) {\n@@ -86,1 +93,1 @@\n-  return val;\n+  java_mirror()->obj_field_put(default_value_offset(), val);\n@@ -89,12 +96,6 @@\n-int InlineKlass::first_field_offset_old() {\n-#ifdef ASSERT\n-  int first_offset = INT_MAX;\n-  for (AllFieldStream fs(this); !fs.done(); fs.next()) {\n-    if (fs.offset() < first_offset) first_offset= fs.offset();\n-  }\n-#endif\n-  int base_offset = instanceOopDesc::base_offset_in_bytes();\n-  \/\/ The first field of line types is aligned on a long boundary\n-  base_offset = align_up(base_offset, BytesPerLong);\n-  assert(base_offset == first_offset, \"inconsistent offsets\");\n-  return base_offset;\n+void InlineKlass::set_null_reset_value(oop val) {\n+  assert(val != nullptr, \"Sanity check\");\n+  assert(oopDesc::is_oop(val), \"Sanity check\");\n+  assert(val->is_inline_type(), \"Sanity check\");\n+  assert(val->klass() == this, \"sanity check\");\n+  java_mirror()->obj_field_put(null_reset_value_offset(), val);\n@@ -131,1 +132,54 @@\n-oop InlineKlass::read_flat_field(oop obj, int offset, TRAPS) {\n+int InlineKlass::layout_size_in_bytes(LayoutKind kind) const {\n+  switch(kind) {\n+    case LayoutKind::NON_ATOMIC_FLAT:\n+      assert(has_non_atomic_layout(), \"Layout not available\");\n+      return non_atomic_size_in_bytes();\n+      break;\n+    case LayoutKind::ATOMIC_FLAT:\n+      assert(has_atomic_layout(), \"Layout not available\");\n+      return atomic_size_in_bytes();\n+      break;\n+    case LayoutKind::NULLABLE_ATOMIC_FLAT:\n+      assert(has_nullable_layout(), \"Layout not available\");\n+      return nullable_size_in_bytes();\n+      break;\n+    case PAYLOAD:\n+      return payload_size_in_bytes();\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+  }\n+}\n+\n+int InlineKlass::layout_alignment(LayoutKind kind) const {\n+  switch(kind) {\n+    case LayoutKind::NON_ATOMIC_FLAT:\n+      assert(has_non_atomic_layout(), \"Layout not available\");\n+      return non_atomic_alignment();\n+      break;\n+    case LayoutKind::ATOMIC_FLAT:\n+      assert(has_atomic_layout(), \"Layout not available\");\n+      return atomic_size_in_bytes();\n+      break;\n+    case LayoutKind::NULLABLE_ATOMIC_FLAT:\n+      assert(has_nullable_layout(), \"Layout not available\");\n+      return nullable_size_in_bytes();\n+      break;\n+    case LayoutKind::PAYLOAD:\n+      return payload_alignment();\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+  }\n+}\n+\n+oop InlineKlass::read_flat_field(oop obj, int offset, LayoutKind lk, TRAPS) {\n+\n+  if (lk == LayoutKind::NULLABLE_ATOMIC_FLAT) {\n+    InstanceKlass* recv = InstanceKlass::cast(obj->klass());\n+    int nm_offset = offset + (null_marker_offset() - first_field_offset());\n+    jbyte nm = obj->byte_field(nm_offset);\n+    if (nm_offset == 0) {\n+      return nullptr;\n+    }\n+  }\n@@ -140,1 +194,1 @@\n-    inline_copy_payload_to_new_oop(((char*)(oopDesc*)obj_h()) + offset, res);\n+    inline_copy_payload_to_new_oop(((char*)(oopDesc*)obj_h()) + offset, res, lk);\n@@ -146,2 +200,2 @@\n-void InlineKlass::write_flat_field(oop obj, int offset, oop value, TRAPS) {\n-  if (value == nullptr) {\n+void InlineKlass::write_flat_field(oop obj, int offset, oop value, bool is_null_free, LayoutKind lk, TRAPS) {\n+  if (is_null_free && value == nullptr) {\n@@ -150,8 +204,2 @@\n-  write_non_null_flat_field(obj, offset, value);\n-}\n-\n-void InlineKlass::write_non_null_flat_field(oop obj, int offset, oop value) {\n-  assert(value != nullptr, \"\");\n-  if (!is_empty_inline_type()) {\n-    inline_copy_oop_to_payload(value, ((char*)(oopDesc*)obj) + offset);\n-  }\n+  assert(!is_null_free || (lk == LayoutKind::ATOMIC_FLAT || lk == LayoutKind::NON_ATOMIC_FLAT || lk == LayoutKind::REFERENCE || lk == LayoutKind::PAYLOAD), \"Consistency check\");\n+  inline_copy_oop_to_payload(value, ((char*)(oopDesc*)obj) + offset, lk);\n@@ -167,1 +215,1 @@\n-  int elem_bytes = get_payload_size_in_bytes();\n+  int elem_bytes = payload_size_in_bytes();\n","filename":"src\/hotspot\/share\/oops\/inlineKlass.cpp","additions":78,"deletions":30,"binary":false,"changes":108,"status":"modified"},{"patch":"@@ -83,0 +83,5 @@\n+  address adr_null_reset_value_offset() const {\n+    assert(_adr_inlineklass_fixed_block != nullptr, \"Should have been initialized\");\n+    return ((address)_adr_inlineklass_fixed_block) + in_bytes(null_reset_value_offset_offset());\n+  }\n+\n@@ -92,5 +97,0 @@\n-  address adr_alignment() const {\n-    assert(_adr_inlineklass_fixed_block != nullptr, \"Should have been initialized\");\n-    return ((address)_adr_inlineklass_fixed_block) + in_bytes(byte_offset_of(InlineKlassFixedBlock, _alignment));\n-  }\n-\n@@ -107,1 +107,1 @@\n-  address adr_internal_null_marker_offset() const {\n+  address adr_payload_alignment() const {\n@@ -109,1 +109,1 @@\n-    return ((address)_adr_inlineklass_fixed_block) + in_bytes(byte_offset_of(InlineKlassFixedBlock, _internal_null_marker_offset));\n+    return ((address)_adr_inlineklass_fixed_block) + in_bytes(byte_offset_of(InlineKlassFixedBlock, _payload_alignment));\n@@ -112,3 +112,8 @@\n- public:\n-  int get_alignment() const {\n-    return *(int*)adr_alignment();\n+  address adr_non_atomic_size_in_bytes() const {\n+    assert(_adr_inlineklass_fixed_block != nullptr, \"Should have been initialized\");\n+    return ((address)_adr_inlineklass_fixed_block) + in_bytes(byte_offset_of(InlineKlassFixedBlock, _non_atomic_size_in_bytes));\n+  }\n+\n+  address adr_non_atomic_alignment() const {\n+    assert(_adr_inlineklass_fixed_block != nullptr, \"Should have been initialized\");\n+    return ((address)_adr_inlineklass_fixed_block) + in_bytes(byte_offset_of(InlineKlassFixedBlock, _non_atomic_alignment));\n@@ -117,2 +122,8 @@\n-  void set_alignment(int alignment) {\n-    *(int*)adr_alignment() = alignment;\n+  address adr_atomic_size_in_bytes() const {\n+    assert(_adr_inlineklass_fixed_block != nullptr, \"Should have been initialized\");\n+    return ((address)_adr_inlineklass_fixed_block) + in_bytes(byte_offset_of(InlineKlassFixedBlock, _atomic_size_in_bytes));\n+  }\n+\n+  address adr_nullable_size_in_bytes() const {\n+    assert(_adr_inlineklass_fixed_block != nullptr, \"Should have been initialized\");\n+    return ((address)_adr_inlineklass_fixed_block) + in_bytes(byte_offset_of(InlineKlassFixedBlock, _nullable_size_in_bytes));\n@@ -121,0 +132,10 @@\n+  address adr_null_marker_offset() const {\n+    assert(_adr_inlineklass_fixed_block != nullptr, \"Should have been initialized\");\n+    return ((address)_adr_inlineklass_fixed_block) + in_bytes(byte_offset_of(InlineKlassFixedBlock, _null_marker_offset));\n+  }\n+\n+ public:\n+\n+  bool is_empty_inline_type() const   { return _misc_flags.is_empty_inline_type(); }\n+  void set_is_empty_inline_type()     { _misc_flags.set_is_empty_inline_type(true); }\n+\n@@ -127,3 +148,1 @@\n-  void set_first_field_offset(int offset) {\n-    *(int*)adr_first_field_offset() = offset;\n-  }\n+  void set_first_field_offset(int offset) { *(int*)adr_first_field_offset() = offset; }\n@@ -131,3 +150,2 @@\n-  int get_payload_size_in_bytes() const {\n-    return *(int*)adr_payload_size_in_bytes();\n-  }\n+  int payload_size_in_bytes() const { return *(int*)adr_payload_size_in_bytes(); }\n+  void set_payload_size_in_bytes(int payload_size) { *(int*)adr_payload_size_in_bytes() = payload_size; }\n@@ -135,3 +153,2 @@\n-  void set_payload_size_in_bytes(int payload_size) {\n-    *(int*)adr_payload_size_in_bytes() = payload_size;\n-  }\n+  int payload_alignment() const { return *(int*)adr_payload_alignment(); }\n+  void set_payload_alignment(int alignment) { *(int*)adr_payload_alignment() = alignment; }\n@@ -139,3 +156,5 @@\n-  void set_internal_null_marker_offset(int offset) {\n-    *(int*)adr_internal_null_marker_offset() = offset;\n-  }\n+  bool has_non_atomic_layout() const { return non_atomic_size_in_bytes() != -1; }\n+  int non_atomic_size_in_bytes() const { return *(int*)adr_non_atomic_size_in_bytes(); }\n+  void set_non_atomic_size_in_bytes(int size) { *(int*)adr_non_atomic_size_in_bytes() = size; }\n+  int non_atomic_alignment() const { return *(int*)adr_non_atomic_alignment(); }\n+  void set_non_atomic_alignment(int alignment) { *(int*)adr_non_atomic_alignment() = alignment; }\n@@ -143,3 +162,3 @@\n-  bool has_internal_null_marker_offset() const {\n-    return *(int*)adr_internal_null_marker_offset() != -1;\n-  }\n+  bool has_atomic_layout() const { return atomic_size_in_bytes() != -1; }\n+  int atomic_size_in_bytes() const { return *(int*)adr_atomic_size_in_bytes(); }\n+  void set_atomic_size_in_bytes(int size) { *(int*)adr_atomic_size_in_bytes() = size; }\n@@ -147,4 +166,5 @@\n-  int get_internal_null_marker_offset() const {\n-    assert(has_internal_null_marker_offset(), \"Must not be call if value class has no internal null marker\");\n-    return *(int*)adr_internal_null_marker_offset();\n-  }\n+  bool has_nullable_layout() const { return nullable_size_in_bytes() != -1; }\n+  int nullable_size_in_bytes() const { return *(int*)adr_nullable_size_in_bytes(); }\n+  void set_nullable_size_in_bytes(int size) { *(int*)adr_nullable_size_in_bytes() = size; }\n+  int null_marker_offset() const { return *(int*)adr_null_marker_offset(); }\n+  void set_null_marker_offset(int offset) { *(int*)adr_null_marker_offset() = offset; }\n@@ -152,1 +172,2 @@\n-  int first_field_offset_old();\n+  int layout_alignment(LayoutKind kind) const;\n+  int layout_size_in_bytes(LayoutKind kind) const;\n@@ -169,1 +190,10 @@\n-  static InlineKlass* cast(Klass* k);\n+\n+  static InlineKlass* cast(Klass* k) {\n+    return const_cast<InlineKlass*>(cast(const_cast<const Klass*>(k)));\n+  }\n+\n+  static const InlineKlass* cast(const Klass* k) {\n+    assert(k != nullptr, \"k should not be null\");\n+    assert(k->is_inline_klass(), \"cast to InlineKlass\");\n+    return static_cast<const InlineKlass*>(k);\n+  }\n@@ -187,3 +217,0 @@\n-  \/\/ Query if this class promises atomicity one way or another\n-  bool is_atomic() { return is_naturally_atomic() || must_be_atomic(); }\n-\n@@ -215,4 +242,4 @@\n-  void inline_copy_payload_to_new_oop(void* src, oop dst);\n-  void inline_copy_oop_to_new_oop(oop src, oop dst);\n-  void inline_copy_oop_to_new_payload(oop src, void* dst);\n-  void inline_copy_oop_to_payload(oop src, void* dst);\n+  void inline_copy_payload_to_new_oop(void* src, oop dst, LayoutKind lk);\n+  void inline_copy_oop_to_new_oop(oop src, oop dst, LayoutKind lk);\n+  void inline_copy_oop_to_new_payload(oop src, void* dst, LayoutKind lk);\n+  void inline_copy_oop_to_payload(oop src, void* dst, LayoutKind lk);\n@@ -220,3 +247,2 @@\n-  oop read_flat_field(oop obj, int offset, TRAPS);\n-  void write_flat_field(oop obj, int offset, oop value, TRAPS);\n-  void write_non_null_flat_field(oop obj, int offset, oop value);\n+  oop read_flat_field(oop obj, int offset, LayoutKind lk, TRAPS);\n+  void write_flat_field(oop obj, int offset, oop value, bool is_null_free, LayoutKind lk, TRAPS);\n@@ -270,0 +296,4 @@\n+  static ByteSize null_reset_value_offset_offset() {\n+    return byte_offset_of(InlineKlassFixedBlock, _null_reset_value_offset);\n+  }\n+\n@@ -274,2 +304,2 @@\n-  static ByteSize internal_null_marker_offset_offset() {\n-    return byte_offset_of(InlineKlassFixedBlock, _internal_null_marker_offset);\n+  static ByteSize null_marker_offset_offset() {\n+    return byte_offset_of(InlineKlassFixedBlock, _null_marker_offset);\n@@ -288,2 +318,26 @@\n-  void set_default_value(oop val) {\n-    java_mirror()->obj_field_put(default_value_offset(), val);\n+  void set_default_value(oop val);\n+\n+  oop default_value() {\n+    assert(is_initialized() || is_being_initialized() || is_in_error_state(), \"default value is set at the beginning of initialization\");\n+    oop val = java_mirror()->obj_field_acquire(default_value_offset());\n+    assert(val != nullptr, \"Sanity check\");\n+    return val;\n+  }\n+\n+  void set_null_reset_value_offset(int offset) {\n+    *((int*)adr_null_reset_value_offset()) = offset;\n+  }\n+\n+  int null_reset_value_offset() {\n+    int offset = *((int*)adr_null_reset_value_offset());\n+    assert(offset != 0, \"must not be called if not initialized\");\n+    return offset;\n+  }\n+\n+  void set_null_reset_value(oop val);\n+\n+  oop null_reset_value() {\n+    assert(is_initialized() || is_being_initialized() || is_in_error_state(), \"null reset value is set at the beginning of initialization\");\n+    oop val = java_mirror()->obj_field_acquire(null_reset_value_offset());\n+    assert(val != nullptr, \"Sanity check\");\n+    return val;\n@@ -292,1 +346,0 @@\n-  oop default_value();\n","filename":"src\/hotspot\/share\/oops\/inlineKlass.hpp","additions":101,"deletions":48,"binary":false,"changes":149,"status":"modified"},{"patch":"@@ -54,6 +54,0 @@\n-\n-inline InlineKlass* InlineKlass::cast(Klass* k) {\n-  assert(k->is_inline_klass(), \"cast to InlineKlass\");\n-  return (InlineKlass*) k;\n-}\n-\n@@ -64,2 +58,2 @@\n-inline void InlineKlass::inline_copy_payload_to_new_oop(void* src, oop dst) {\n-  HeapAccess<IS_DEST_UNINITIALIZED>::value_copy(src, data_for_oop(dst), this);\n+inline void InlineKlass::inline_copy_payload_to_new_oop(void* src, oop dst, LayoutKind lk) {\n+  HeapAccess<IS_DEST_UNINITIALIZED>::value_copy(src, data_for_oop(dst), this, lk);\n@@ -68,2 +62,2 @@\n-inline void InlineKlass::inline_copy_oop_to_new_oop(oop src, oop dst) {\n-  HeapAccess<IS_DEST_UNINITIALIZED>::value_copy(data_for_oop(src), data_for_oop(dst), this);\n+inline void InlineKlass::inline_copy_oop_to_new_oop(oop src, oop dst, LayoutKind lk) {\n+  HeapAccess<IS_DEST_UNINITIALIZED>::value_copy(data_for_oop(src), data_for_oop(dst), this, lk);\n@@ -72,2 +66,2 @@\n-inline void InlineKlass::inline_copy_oop_to_new_payload(oop src, void* dst) {\n-  HeapAccess<IS_DEST_UNINITIALIZED>::value_copy(data_for_oop(src), dst, this);\n+inline void InlineKlass::inline_copy_oop_to_new_payload(oop src, void* dst, LayoutKind lk) {\n+  HeapAccess<IS_DEST_UNINITIALIZED>::value_copy(data_for_oop(src), dst, this, lk);\n@@ -76,2 +70,2 @@\n-inline void InlineKlass::inline_copy_oop_to_payload(oop src, void* dst) {\n-  HeapAccess<>::value_copy(data_for_oop(src), dst, this);\n+inline void InlineKlass::inline_copy_oop_to_payload(oop src, void* dst, LayoutKind lk) {\n+  HeapAccess<>::value_copy(data_for_oop(src), dst, this, lk);\n","filename":"src\/hotspot\/share\/oops\/inlineKlass.inline.hpp","additions":8,"deletions":14,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -152,0 +152,5 @@\n+void InlineLayoutInfo::metaspace_pointers_do(MetaspaceClosure* it) {\n+  log_trace(cds)(\"Iter(InlineFieldInfo): %p\", this);\n+  it->push(&_klass);\n+}\n+\n@@ -180,1 +185,1 @@\n-        Symbol* class_name = _constants->klass_at_noresolve(_loadable_descriptors->at(i));\n+        Symbol* class_name = _constants->symbol_at(_loadable_descriptors->at(i));\n@@ -573,2 +578,1 @@\n-  _inline_type_field_klasses(nullptr),\n-  _null_marker_offsets(nullptr),\n+  _inline_layout_info_array(nullptr),\n@@ -725,8 +729,2 @@\n-  if (inline_type_field_klasses_array() != nullptr) {\n-    MetadataFactory::free_array<InlineKlass*>(loader_data, inline_type_field_klasses_array());\n-    set_inline_type_field_klasses_array(nullptr);\n-  }\n-\n-  if (null_marker_offsets_array() != nullptr) {\n-    MetadataFactory::free_array<int>(loader_data, null_marker_offsets_array());\n-    set_null_marker_offsets_array(nullptr);\n+  if (inline_layout_info_array() != nullptr) {\n+    MetadataFactory::free_array<InlineLayoutInfo>(loader_data, inline_layout_info_array());\n@@ -734,0 +732,1 @@\n+  set_inline_layout_info_array(nullptr);\n@@ -976,5 +975,0 @@\n-          if (!klass->is_inline_klass()) {\n-            THROW_MSG_(vmSymbols::java_lang_IncompatibleClassChangeError(),\n-                       err_msg(\"class %s expects class %s to be a value class but it is an identity class\",\n-                       name()->as_C_string(), klass->external_name()), false);\n-          }\n@@ -987,2 +981,7 @@\n-          InstanceKlass* ik = InstanceKlass::cast(klass);\n-          if (!ik->is_implicitly_constructible()) {\n+          if (!klass->is_inline_klass()) {\n+            THROW_MSG_(vmSymbols::java_lang_IncompatibleClassChangeError(),\n+                       err_msg(\"class %s expects class %s to be a value class but it is an identity class\",\n+                       name()->as_C_string(), klass->external_name()), false);\n+          }\n+          InlineKlass* vk = InlineKlass::cast(klass);\n+          if (!vk->is_implicitly_constructible()) {\n@@ -994,2 +993,4 @@\n-          if (inline_type_field_klasses_array()->at(fs.index()) == nullptr) {\n-            set_inline_type_field_klass(fs.index(), InlineKlass::cast(ik));\n+          InlineLayoutInfo* li = inline_layout_info_adr(fs.index());\n+          if (li->klass() == nullptr) {\n+            li->set_klass(InlineKlass::cast(vk));\n+            li->set_kind(LayoutKind::REFERENCE);\n@@ -997,1 +998,1 @@\n-          assert(get_inline_type_field_klass(fs.index()) == ik, \"Must match\");\n+          assert(get_inline_type_field_klass(fs.index()) == vk, \"Must match\");\n@@ -999,2 +1000,4 @@\n-          if (inline_type_field_klasses_array()->at(fs.index()) == nullptr) {\n-            set_inline_type_field_klass(fs.index(), InlineKlass::cast(this));\n+          InlineLayoutInfo* li = inline_layout_info_adr(fs.index());\n+          if (li->klass() == nullptr) {\n+            li->set_klass(InlineKlass::cast(this));\n+            li->set_kind(LayoutKind::REFERENCE);\n@@ -1357,0 +1360,16 @@\n+      if (vk->has_nullable_layout()) {\n+        val = vk->allocate_instance(THREAD);\n+        if (HAS_PENDING_EXCEPTION) {\n+            Handle e(THREAD, PENDING_EXCEPTION);\n+            CLEAR_PENDING_EXCEPTION;\n+            {\n+                EXCEPTION_MARK;\n+                add_initialization_error(THREAD, e);\n+                \/\/ Locks object, set state, and notify all waiting threads\n+                set_initialization_state_and_notify(initialization_error, THREAD);\n+                CLEAR_PENDING_EXCEPTION;\n+            }\n+            THROW_OOP(e());\n+        }\n+        vk->set_null_reset_value(val);\n+      }\n@@ -1940,1 +1959,1 @@\n-    return offset >= vk->first_field_offset() && offset < (vk->first_field_offset() + vk->get_payload_size_in_bytes());\n+    return offset >= vk->first_field_offset() && offset < (vk->first_field_offset() + vk->payload_size_in_bytes());\n@@ -2738,3 +2757,1 @@\n-\n-  it->push(&_inline_type_field_klasses, MetaspaceClosure::_writable);\n-  it->push(&_null_marker_offsets);\n+  it->push(&_inline_layout_info_array, MetaspaceClosure::_writable);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":44,"deletions":27,"binary":false,"changes":71,"status":"modified"},{"patch":"@@ -148,0 +148,1 @@\n+  int* _null_reset_value_offset;\n@@ -149,1 +150,0 @@\n-  int _alignment;\n@@ -151,2 +151,7 @@\n-  int _payload_size_in_bytes;\n-  int _internal_null_marker_offset; \/\/ -1 if none\n+  int _payload_size_in_bytes;   \/\/ size of payload layout\n+  int _payload_alignment;       \/\/ alignment required for payload\n+  int _non_atomic_size_in_bytes; \/\/ size of null-free non-atomic flat layout\n+  int _non_atomic_alignment;    \/\/ alignment requirement for null-free non-atomic layout\n+  int _atomic_size_in_bytes;    \/\/ size and alignment requirement for a null-free atomic layout, -1 if no atomic flat layout is possible\n+  int _nullable_size_in_bytes;  \/\/ size and alignment requirement for a nullable layout (always atomic), -1 if no nullable flat layout is possible\n+  int _null_marker_offset;\n@@ -157,0 +162,32 @@\n+class InlineLayoutInfo : public MetaspaceObj {\n+  InlineKlass* _klass;\n+  LayoutKind _kind;\n+  int _null_marker_offset; \/\/ null marker offset for this field, relative to the beginning of the current container\n+\n+ public:\n+  InlineLayoutInfo(): _klass(nullptr), _kind(LayoutKind::UNKNOWN), _null_marker_offset(-1)  {}\n+  InlineLayoutInfo(InlineKlass* ik, LayoutKind kind, int size, int nm_offset):\n+    _klass(ik), _kind(kind), _null_marker_offset(nm_offset) {}\n+\n+  InlineKlass* klass() const { return _klass; }\n+  void set_klass(InlineKlass* k) { _klass = k; }\n+\n+  LayoutKind kind() const {\n+    assert(_kind != LayoutKind::UNKNOWN, \"Not set\");\n+    return _kind;\n+  }\n+  void set_kind(LayoutKind lk) { _kind = lk; }\n+\n+  int null_marker_offset() const {\n+    assert(_null_marker_offset != -1, \"Not set\");\n+    return _null_marker_offset;\n+  }\n+  void set_null_marker_offset(int o) { _null_marker_offset = o; }\n+\n+  void metaspace_pointers_do(MetaspaceClosure* it);\n+  MetaspaceObj::Type type() const { return InlineLayoutInfoType; }\n+\n+  static ByteSize klass_offset() { return in_ByteSize(offset_of(InlineLayoutInfo, _klass)); }\n+  static ByteSize null_marker_offset_offset() { return in_ByteSize(offset_of(InlineLayoutInfo, _null_marker_offset)); }\n+};\n+\n@@ -305,2 +342,1 @@\n-  Array<InlineKlass*>* _inline_type_field_klasses; \/\/ For \"inline class\" fields, null if none present\n-  Array<int>* _null_marker_offsets; \/\/ for flat fields with a null marker\n+  Array<InlineLayoutInfo>* _inline_layout_info_array;\n@@ -366,8 +402,0 @@\n-  bool is_empty_inline_type() const   { return _misc_flags.is_empty_inline_type(); }\n-  void set_is_empty_inline_type()     { _misc_flags.set_is_empty_inline_type(true); }\n-\n-  \/\/ Note:  The naturally_atomic property only applies to\n-  \/\/ inline classes; it is never true on identity classes.\n-  \/\/ The bit is placed on instanceKlass for convenience.\n-\n-  \/\/ Query if h\/w provides atomic load\/store for instances.\n@@ -377,1 +405,1 @@\n-  \/\/ Query if this class is mentioned in the JVM option ForceNonTearable.\n+  \/\/ Query if this class has atomicity requirements (default is yes)\n@@ -381,0 +409,2 @@\n+  \/\/ Its value depends on the ForceNonTearable VM option, the LooselyConsistentValue annotation\n+  \/\/ and the presence of flat fields with atomicity requirements\n@@ -384,0 +414,3 @@\n+  \/\/ Query if this class can be implicitly constructed, meaning the VM is allowed\n+  \/\/ to create instances without calling a constructor\n+  \/\/ Applies to inline classes and their super types\n@@ -919,2 +952,1 @@\n-  static ByteSize inline_type_field_klasses_offset() { return in_ByteSize(offset_of(InstanceKlass, _inline_type_field_klasses)); }\n-  static ByteSize null_marker_array_offset() { return in_ByteSize(offset_of(InstanceKlass, _null_marker_offsets)); }\n+  static ByteSize inline_layout_info_array_offset() { return in_ByteSize(offset_of(InstanceKlass, _inline_layout_info_array)); }\n@@ -1008,5 +1040,14 @@\n-  Array<InlineKlass*>* inline_type_field_klasses_array() const { return _inline_type_field_klasses; }\n-  void set_inline_type_field_klasses_array(Array<InlineKlass*>* array) { _inline_type_field_klasses = array; }\n-\n-  Array<int>* null_marker_offsets_array() const { return _null_marker_offsets; }\n-  void set_null_marker_offsets_array(Array<int>* array) { _null_marker_offsets = array; }\n+  void set_inline_layout_info_array(Array<InlineLayoutInfo>* array) { _inline_layout_info_array = array; }\n+  Array<InlineLayoutInfo>* inline_layout_info_array() const { return _inline_layout_info_array; }\n+  void set_inline_layout_info(int index, InlineLayoutInfo *info) {\n+    assert(_inline_layout_info_array != nullptr ,\"Array not created\");\n+    _inline_layout_info_array->at_put(index, *info);\n+  }\n+  InlineLayoutInfo inline_layout_info(int index) const {\n+    assert(_inline_layout_info_array != nullptr ,\"Array not created\");\n+    return _inline_layout_info_array->at(index);\n+  }\n+  InlineLayoutInfo* inline_layout_info_adr(int index) {\n+    assert(_inline_layout_info_array != nullptr ,\"Array not created\");\n+    return _inline_layout_info_array->adr_at(index);\n+  }\n@@ -1014,1 +1055,1 @@\n-  inline InlineKlass* get_inline_type_field_klass(int idx) const;\n+  inline InlineKlass* get_inline_type_field_klass(int idx) const ;\n@@ -1016,2 +1057,0 @@\n-  inline void set_inline_type_field_klass(int idx, InlineKlass* k);\n-  inline void reset_inline_type_field_klass(int idx);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":63,"deletions":24,"binary":false,"changes":87,"status":"modified"},{"patch":"@@ -69,1 +69,1 @@\n-  InlineKlass* k = inline_type_field_klasses_array()->at(idx);\n+  InlineKlass* k = inline_layout_info(idx).klass();\n@@ -77,1 +77,1 @@\n-  InlineKlass* k = inline_type_field_klasses_array()->at(idx);\n+  InlineKlass* k = inline_layout_info(idx).klass();\n@@ -81,16 +81,0 @@\n-inline void InstanceKlass::set_inline_type_field_klass(int idx, InlineKlass* k) {\n-  assert(has_inline_type_fields(), \"Sanity checking\");\n-  assert(idx < java_fields_count(), \"IOOB\");\n-  assert(k != nullptr, \"Should not be set to nullptr\");\n-  assert(inline_type_field_klasses_array() != nullptr, \"array must have been created\");\n-  assert(inline_type_field_klasses_array()->at(idx) == nullptr, \"Should not be set twice\");\n-  inline_type_field_klasses_array()->at_put(idx, k);\n-}\n-\n-inline void InstanceKlass::reset_inline_type_field_klass(int idx) {\n-  assert(has_inline_type_fields(), \"Sanity checking\");\n-  assert(idx < java_fields_count(), \"IOOB\");\n-  inline_type_field_klasses_array()->at_put(idx, nullptr);\n-}\n-\n-\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.inline.hpp","additions":2,"deletions":18,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -59,1 +59,1 @@\n-    flag(is_naturally_atomic                , 1 << 16) \/* loaded\/stored in one instruction *\/ \\\n+    flag(is_naturally_atomic                , 1 << 16) \/* loaded\/stored in one instruction*\/ \\\n@@ -62,1 +62,1 @@\n-    flag(is_implicitly_constructible        , 1 << 19) \/* the class has the ImplicitlyConstrutible annotation *\/\n+    flag(is_implicitly_constructible        , 1 << 19) \/* the class has the ImplicitlyConstrutible annotation *\/ \\\n","filename":"src\/hotspot\/share\/oops\/instanceKlassFlags.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -55,1 +55,1 @@\n-  u1 _flags;                    \/\/ Flags: [00|has_internal_null_marker|has_null_marker|is_null_free_inline_type|is_flat|is_final|is_volatile]\n+  u1 _flags;                    \/\/ Flags: [000|has_null_marker|is_null_free_inline_type|is_flat|is_final|is_volatile]\n@@ -100,2 +100,1 @@\n-      has_internal_null_marker_shift = 5,\n-      max_flag_shift = has_internal_null_marker_shift\n+      max_flag_shift = has_null_marker_shift\n@@ -117,1 +116,0 @@\n-  bool has_internal_null_marker() const { return (_flags & (1 << has_internal_null_marker_shift)) != 0; }\n@@ -136,1 +134,1 @@\n-                 bool has_null_marker_flag, bool has_internal_null_marker_flag) {\n+                 bool has_null_marker_flag) {\n@@ -140,2 +138,1 @@\n-      ((has_null_marker_flag ? 1 : 0) << has_null_marker_shift) |\n-      ((has_internal_null_marker_flag ? 1 : 0) << has_internal_null_marker_shift);\n+      ((has_null_marker_flag ? 1 : 0) << has_null_marker_shift);\n@@ -148,1 +145,0 @@\n-    assert(has_internal_null_marker() == has_internal_null_marker_flag, \"Must be\");\n","filename":"src\/hotspot\/share\/oops\/resolvedFieldEntry.hpp","additions":4,"deletions":8,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2027,1 +2027,1 @@\n-  array->value_copy_to_index(buffer, index);\n+  array->value_copy_to_index(buffer, index, LayoutKind::PAYLOAD); \/\/ Temporary hack for the transition\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1838,2 +1838,3 @@\n-    InlineKlass* field_vklass = InlineKlass::cast(holder->get_inline_type_field_klass(fd.index()));\n-    res = field_vklass->read_flat_field(o, ik->field_offset(fd.index()), CHECK_NULL);\n+    InlineLayoutInfo* li = holder->inline_layout_info_adr(fd.index());\n+    InlineKlass* field_vklass = li->klass();\n+    res = field_vklass->read_flat_field(o, ik->field_offset(fd.index()), li->kind(), CHECK_NULL);\n@@ -1941,1 +1942,2 @@\n-    InlineKlass* vklass = InlineKlass::cast(holder->get_inline_type_field_klass(fd.index()));\n+    InlineLayoutInfo* li = holder->inline_layout_info_adr(fd.index());\n+    InlineKlass* vklass = li->klass();\n@@ -1943,1 +1945,1 @@\n-    vklass->write_flat_field(o, offset, v, CHECK);\n+    vklass->write_flat_field(o, offset, v, fd.is_null_free_inline_type(), li->kind(), CHECK);\n@@ -2410,1 +2412,1 @@\n-         a->value_copy_to_index(v, index);\n+         a->value_copy_to_index(v, index, LayoutKind::PAYLOAD);  \/\/ Temporary hack for the transition\n","filename":"src\/hotspot\/share\/prims\/jni.cpp","additions":7,"deletions":5,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -441,2 +441,5 @@\n-  InstanceKlass* ik = InstanceKlass::cast(klass);\n-  if (!ik->is_implicitly_constructible()) {\n+  if (klass->is_abstract()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Element class is abstract\");\n+  }\n+  InlineKlass* vk = InlineKlass::cast(klass);\n+  if (!vk->is_implicitly_constructible()) {\n@@ -445,1 +448,1 @@\n-  oop array = oopFactory::new_valueArray(ik, len, CHECK_NULL);\n+  oop array = oopFactory::new_valueArray(vk, len, CHECK_NULL);\n@@ -2535,1 +2538,1 @@\n-  return ArrayKlass::cast(k)->element_access_is_atomic();\n+  return ArrayKlass::cast(k)->element_access_must_be_atomic();\n@@ -2546,1 +2549,1 @@\n-    if (!vk->element_access_is_atomic()) {\n+    if (!vk->element_access_must_be_atomic()) {\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":8,"deletions":5,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -376,1 +376,1 @@\n-  return InstanceKlass::cast(k)->null_marker_offsets_array()->at(slot);\n+  fatal(\"Not supported yet\");\n@@ -397,1 +397,1 @@\n-  oop v = vk->read_flat_field(base_h(), offset, CHECK_NULL);\n+  oop v = vk->read_flat_field(base_h(), offset, LayoutKind::PAYLOAD, CHECK_NULL);  \/\/ TODO FIXME Hard coded layout kind to make the code compile, Unsafe must be upgraded to handle correct layout kind\n@@ -408,1 +408,1 @@\n-  vk->write_flat_field(base, offset, v, CHECK);\n+  vk->write_flat_field(base, offset, v, true \/*null free*\/, LayoutKind::PAYLOAD, CHECK);  \/\/ TODO FIXME Hard coded layout kind to make the code compile, Unsafe must be upgraded to handle correct layout kind\n@@ -417,1 +417,1 @@\n-  vk->inline_copy_oop_to_new_oop(vh(),  new_value);\n+  vk->inline_copy_oop_to_new_oop(vh(), new_value, LayoutKind::PAYLOAD);  \/\/ FIXME temporary hack for the transition\n","filename":"src\/hotspot\/share\/prims\/unsafe.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -92,1 +92,0 @@\n-  inline bool has_internal_null_marker() const;\n","filename":"src\/hotspot\/share\/runtime\/fieldDescriptor.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -72,1 +72,0 @@\n-inline bool fieldDescriptor::has_internal_null_marker() const { return field().field_flags().is_null_marker_internal(); }\n","filename":"src\/hotspot\/share\/runtime\/fieldDescriptor.inline.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -819,1 +819,1 @@\n-  develop(bool, EnableNullableFieldFlattening, false,                       \\\n+  product(bool, NullableFieldFlattening, false,                             \\\n@@ -822,0 +822,3 @@\n+  product(bool, AtomicFieldFlattening, false,                               \\\n+          \"Allow the JVM to flatten some atomic fields\")                    \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -67,1 +67,2 @@\n-                        \"-XX:TypeProfileLevel=0\"),\n+                        \"-XX:TypeProfileLevel=0\",\n+                        \"-XX:InlineFieldMaxFlatSize=256\"),\n@@ -88,1 +89,2 @@\n-                        \"-XX:-TieredCompilation\"),\n+                        \"-XX:-TieredCompilation\",\n+                        \"-XX:InlineFieldMaxFlatSize=256\"),\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestLWorldProfiling.java","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -25,0 +25,2 @@\n+import java.lang.management.ManagementFactory;\n+import java.lang.management.RuntimeMXBean;\n@@ -27,0 +29,1 @@\n+import java.util.List;\n@@ -34,0 +37,2 @@\n+\n+\n@@ -49,0 +54,1 @@\n+    static boolean nullableLayoutEnabled;\n@@ -51,0 +57,3 @@\n+        RuntimeMXBean runtimeMxBean = ManagementFactory.getRuntimeMXBean();\n+        List<String> arguments = runtimeMxBean.getInputArguments();\n+        nullableLayoutEnabled = arguments.contains(\"-XX:+NullableFieldFlattening\");\n@@ -165,0 +174,1 @@\n+    @LooselyConsistentValue\n@@ -181,1 +191,5 @@\n-            Asserts.assertFalse(UNSAFE.isFlatField(f0), \"Unexpected flat field\");\n+            if (nullableLayoutEnabled) {\n+                Asserts.assertTrue(UNSAFE.isFlatField(f0), \"Flat field expected, but field is not flat\");\n+            } else {\n+                Asserts.assertFalse(UNSAFE.isFlatField(f0), \"Unexpected flat field\");\n+            }\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/AnnotationsTests.java","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -104,1 +104,1 @@\n- *                   -XX:+UnlockDiagnosticVMOptions -XX:+ZVerifyViews -XX:InlineFieldMaxFlatSize=128\n+ *                   -XX:+UnlockDiagnosticVMOptions -XX:+ZVerifyViews -XX:InlineFieldMaxFlatSize=160\n@@ -121,1 +121,1 @@\n- *                   -XX:+UnlockDiagnosticVMOptions -XX:+ZVerifyViews -XX:InlineFieldMaxFlatSize=128\n+ *                   -XX:+UnlockDiagnosticVMOptions -XX:+ZVerifyViews -XX:InlineFieldMaxFlatSize=160\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/InlineOops.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -48,1 +48,1 @@\n- *                    -XX:+WhiteBoxAPI InlineTypeDensity\n+ *                   -XX:+WhiteBoxAPI InlineTypeDensity\n@@ -51,1 +51,1 @@\n- *                    -XX:+WhiteBoxAPI InlineTypeDensity\n+ *                   -XX:+WhiteBoxAPI InlineTypeDensity\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/InlineTypeDensity.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+ * @ignore\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/NullableFlatFieldTest.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -37,1 +37,1 @@\n- * @run main\/othervm -XX:FlatArrayElementMaxSize=-1 -XX:InlineFieldMaxFlatSize=-1 -XX:+EnableNullableFieldFlattening runtime.valhalla.inlinetypes.UnsafeTest\n+ * @run main\/othervm -XX:FlatArrayElementMaxSize=-1 -XX:InlineFieldMaxFlatSize=-1 runtime.valhalla.inlinetypes.UnsafeTest\n@@ -204,1 +204,1 @@\n-        test1();\n+        \/\/ test1();  \/\/ test1 is about nullable flat fields which are not fully supported yet\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/UnsafeTest.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -42,0 +42,2 @@\n+import java.lang.management.ManagementFactory;\n+import java.lang.management.RuntimeMXBean;\n@@ -43,0 +45,1 @@\n+import java.util.List;\n@@ -47,0 +50,2 @@\n+    static boolean atomicLayoutEnabled;\n+\n@@ -62,1 +67,4 @@\n-    static public void main (String[] args) {\n+    static public void main(String[] args) {\n+        RuntimeMXBean runtimeMxBean = ManagementFactory.getRuntimeMXBean();\n+        List<String> arguments = runtimeMxBean.getInputArguments();\n+        atomicLayoutEnabled = arguments.contains(\"-XX:+AtomicFieldFlattening\");\n@@ -74,1 +82,5 @@\n-        Asserts.assertFalse(U.isFlatField(f1), \"mv1 should not be flattened\");\n+        if (atomicLayoutEnabled) {\n+            Asserts.assertTrue(U.isFlatField(f1), \"mv1 should be flattened\");\n+        } else {\n+            Asserts.assertFalse(U.isFlatField(f1), \"mv1 should not be flattened\");\n+        }\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/VolatileTest.java","additions":14,"deletions":2,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -26,1 +26,1 @@\n- * @requires vm.bits == 32 & vm.flagless\n+ * @requires vm.bits == 32\n@@ -36,1 +36,1 @@\n- * @requires vm.bits == 64 & vm.flagless\n+ * @requires vm.bits == 64\n@@ -46,1 +46,1 @@\n- * @requires vm.bits == 64 & vm.flagless\n+ * @requires vm.bits == 64\n@@ -59,0 +59,2 @@\n+ import jdk.internal.vm.annotation.LooselyConsistentValue;\n+ import jdk.internal.vm.annotation.NullRestricted;\n@@ -96,7 +98,7 @@\n-  @ImplicitlyConstructible static value class ValueOneByte { byte val = 0; }\n-  @ImplicitlyConstructible static value class ValueOneChar { char val = 0; }\n-  @ImplicitlyConstructible static value class ValueOneShort { short val = 0; }\n-  @ImplicitlyConstructible static value class ValueOneInt { int val = 0; }\n-  @ImplicitlyConstructible static value class ValueOneLong { long val = 0; }\n-  @ImplicitlyConstructible static value class ValueOneFloat { float val = 0f; }\n-  @ImplicitlyConstructible static value class ValueOneDouble { double val = 0d; }\n+  @ImplicitlyConstructible @LooselyConsistentValue static value class ValueOneByte { byte val = 0; }\n+  @ImplicitlyConstructible @LooselyConsistentValue static value class ValueOneChar { char val = 0; }\n+  @ImplicitlyConstructible @LooselyConsistentValue static value class ValueOneShort { short val = 0; }\n+  @ImplicitlyConstructible @LooselyConsistentValue static value class ValueOneInt { int val = 0; }\n+  @ImplicitlyConstructible @LooselyConsistentValue static value class ValueOneLong { long val = 0; }\n+  @ImplicitlyConstructible @LooselyConsistentValue static value class ValueOneFloat { float val = 0f; }\n+  @ImplicitlyConstructible @LooselyConsistentValue static value class ValueOneDouble { double val = 0d; }\n@@ -104,2 +106,2 @@\n-  @ImplicitlyConstructible static value class ValueByteLong { byte b = 0; long l = 0; }\n-  @ImplicitlyConstructible static value class ValueByteInt { byte b = 0; int i = 0; }\n+  @ImplicitlyConstructible @LooselyConsistentValue static value class ValueByteLong { byte b = 0; long l = 0; }\n+  @ImplicitlyConstructible @LooselyConsistentValue static value class ValueByteInt { byte b = 0; int i = 0; }\n@@ -155,1 +157,1 @@\n-    Collections.addAll(argsList, \"-cp\", System.getProperty(\"java.class.path\") + \":.\");\n+    Collections.addAll(argsList, \"-cp\", System.getProperty(\"java.class.path\") + System.getProperty(\"path.separator\") +\".\");\n@@ -182,0 +184,5 @@\n+    if (out.getExitValue() != 0) {\n+      out.outputTo(System.out);\n+    }\n+    Asserts.assertEquals(out.getExitValue(), 0, \"Something went wrong while running the tests\");\n+\n@@ -183,1 +190,0 @@\n-    System.out.print(out.getOutput());\n@@ -187,1 +193,6 @@\n-    fla.check();\n+    try {\n+      fla.check();\n+    } catch (Throwable t) {\n+      out.outputTo(System.out);\n+      throw t;\n+    }\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/field_layout\/FieldAlignmentTest.java","additions":26,"deletions":15,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -30,0 +30,2 @@\n+import javax.management.RuntimeErrorException;\n+\n@@ -60,2 +62,1 @@\n-    NULL_MARKER,\n-    INHERITED_NULL_MARKER;\n+    NULL_MARKER;\n@@ -72,1 +73,0 @@\n-        case \"INHERITED_NULL_MARKER\" : return INHERITED_NULL_MARKER;\n@@ -79,0 +79,18 @@\n+  static enum LayoutKind {\n+    NON_FLAT,\n+    NON_ATOMIC_FLAT,\n+    ATOMIC_FLAT,\n+    NULLABLE_FLAT;\n+\n+    static LayoutKind parseLayoutKind(String s) {\n+      switch(s) {\n+        case \"\"                : return NON_FLAT;\n+        case \"NON_ATOMIC_FLAT\" : return NON_ATOMIC_FLAT;\n+        case \"ATOMIC_FLAT\"     : return ATOMIC_FLAT;\n+        case \"NULLABLE_FLAT\"   : return NULLABLE_FLAT;\n+        default:\n+          throw new RuntimeException(\"Unknown layout kind: \" + s);\n+      }\n+    }\n+  }\n+\n@@ -86,4 +104,1 @@\n-                            int nullMarkerOffset,\n-                            boolean hasInternalNullMarker,\n-                            int referenceFieldOffset) { \/\/ for null marker blocks, gives the offset of the field they refer to\n-\n+                            LayoutKind layoutKind) {\n@@ -91,2 +106,2 @@\n-    static FieldBlock createSpecialBlock(int offset, BlockType type, int size, int alignment, int referenceFieldOffset) {\n-      return new FieldBlock(offset, type, size, alignment, null, null, null, -1, false, referenceFieldOffset);\n+    static FieldBlock createSpecialBlock(int offset, BlockType type, int size, int alignment) {\n+      return new FieldBlock(offset, type, size, alignment, null, null, null, LayoutKind.NON_FLAT);\n@@ -95,2 +110,2 @@\n-    static FieldBlock createJavaFieldBlock(int offset, BlockType type, int size, int alignment, String name, String signature, String fieldClass, int nullMarkerOffset, boolean hasInternalNullMarker) {\n-      return new FieldBlock(offset, type, size, alignment, name, signature, fieldClass, nullMarkerOffset, hasInternalNullMarker, -1);\n+    static FieldBlock createJavaFieldBlock(int offset, BlockType type, int size, int alignment, String name, String signature, String fieldClass, LayoutKind layoutKind) {\n+      return new FieldBlock(offset, type, size, alignment, name, signature, fieldClass, layoutKind);\n@@ -110,1 +125,0 @@\n-    boolean hasNullMarker() {return nullMarkerOffset != -1; }\n@@ -132,3 +146,2 @@\n-        case BlockType.PADDING:\n-        case BlockType.INHERITED_NULL_MARKER: {\n-            block = FieldBlock.createSpecialBlock(offset, type, size, alignment, 0);\n+        case BlockType.PADDING: {\n+            block = FieldBlock.createSpecialBlock(offset, type, size, alignment);\n@@ -143,0 +156,1 @@\n+            String layoutKind = \"\";\n@@ -144,1 +158,0 @@\n-            boolean hasInternalNullMarker = false;\n@@ -147,7 +160,1 @@\n-              if (fieldLine.length >= 11) {\n-                nullMarkerOffset = Integer.parseInt(fieldLine[10]);\n-              }\n-              if (fieldLine.length >= 12 ) {\n-                Asserts.assertEquals(fieldLine[11], \"(internal)\");\n-                hasInternalNullMarker = true;\n-              }\n+              layoutKind = fieldLine[7];\n@@ -155,1 +162,1 @@\n-            block = FieldBlock.createJavaFieldBlock(offset, type, size, alignment, name, signature, fieldClass, nullMarkerOffset, hasInternalNullMarker);\n+            block = FieldBlock.createJavaFieldBlock(offset, type, size, alignment, name, signature, fieldClass, LayoutKind.parseLayoutKind(layoutKind));\n@@ -159,2 +166,1 @@\n-          int referenceFieldOffset = Integer.parseInt(fieldLine[10]);\n-          block = FieldBlock.createSpecialBlock(offset, type, size, alignment, referenceFieldOffset);\n+          block = FieldBlock.createSpecialBlock(offset, type, size, alignment);\n@@ -167,0 +173,1 @@\n+\n@@ -173,1 +180,3 @@\n-    int size;\n+    int instanceSize;\n+    int payloadSize;\n+    int payloadAlignment;\n@@ -175,2 +184,7 @@\n-    int alignment;\n-    int exactSize;\n+    int nonAtomicLayoutSize;         \/\/ -1 if no non-nullable layout\n+    int nonAtomicLayoutAlignment;    \/\/ -1 if no non-nullable layout\n+    int atomicLayoutSize;            \/\/ -1 if no atomic layout\n+    int atomicLayoutAlignment;       \/\/ -1 if no atomic layout\n+    int nullableLayoutSize;          \/\/ -1 if no nullable layout\n+    int nullableLayoutAlignment;     \/\/ -1 if no nullable layout\n+    int nullMarkerOffset;            \/\/ -1 if no nullable layout\n@@ -180,1 +194,0 @@\n-    int internalNullMarkerOffset; \/\/ -1 if no internal null marker\n@@ -187,0 +200,41 @@\n+    boolean hasNonAtomicLayout() { return nonAtomicLayoutSize != -1; }\n+    boolean hasAtomicLayout() { return atomicLayoutSize != -1; }\n+    boolean hasNullableLayout() { return nullableLayoutSize != -1; }\n+    boolean hasNullMarker() {return nullMarkerOffset != -1; }\n+\n+    int getSize(LayoutKind layoutKind) {\n+      switch(layoutKind) {\n+        case NON_FLAT:\n+          throw new RuntimeException(\"Should not be called on non-flat fields\");\n+        case NON_ATOMIC_FLAT:\n+          Asserts.assertTrue(nonAtomicLayoutSize != -1);\n+          return nonAtomicLayoutSize;\n+        case ATOMIC_FLAT:\n+          Asserts.assertTrue(atomicLayoutSize != -1);\n+          return atomicLayoutSize;\n+        case NULLABLE_FLAT:\n+          Asserts.assertTrue(nullableLayoutSize != -1);\n+          return nullableLayoutSize;\n+        default:\n+          throw new RuntimeException(\"Unknown LayoutKind \" + layoutKind);\n+      }\n+    }\n+\n+    int getAlignment(LayoutKind layoutKind) {\n+      switch(layoutKind) {\n+        case NON_FLAT:\n+          throw new RuntimeException(\"Should not be called on non-flat fields\");\n+        case NON_ATOMIC_FLAT:\n+          Asserts.assertTrue(nonAtomicLayoutSize != -1);\n+          return nonAtomicLayoutAlignment;\n+        case ATOMIC_FLAT:\n+          Asserts.assertTrue(atomicLayoutSize != -1);\n+          return atomicLayoutAlignment;\n+        case NULLABLE_FLAT:\n+          Asserts.assertTrue(nullableLayoutSize != -1);\n+          return nullableLayoutAlignment;\n+        default:\n+          throw new RuntimeException(\"Unknown LayoutKind \" + layoutKind);\n+      }\n+    }\n+\n@@ -227,1 +281,1 @@\n-      cl.size = Integer.parseInt(sizeLine[3]);\n+      cl.instanceSize = Integer.parseInt(sizeLine[3]);\n@@ -232,0 +286,1 @@\n+        \/\/ First field offset = xx\n@@ -235,2 +290,6 @@\n-        String[] alignmentLine = lo.getCurrentLine().split(\"\\\\s+\");\n-        cl.alignment = Integer.parseInt(alignmentLine[2]);\n+        \/\/ Payload layout: x\/y\n+        Asserts.assertTrue(lo.getCurrentLine().startsWith(\"Payload layout\"));\n+        String[] payloadLayoutLine = lo.getCurrentLine().split(\"\\\\s+\");\n+        String[] size_align = payloadLayoutLine[2].split(\"\/\");\n+        cl.payloadSize = Integer.parseInt(size_align[0]);\n+        cl.payloadAlignment = Integer.parseInt(size_align[1]);\n@@ -238,2 +297,25 @@\n-        String[] exactSizeLine = lo.getCurrentLine().split(\"\\\\s+\");\n-        cl.exactSize = Integer.parseInt(exactSizeLine[3]);\n+        \/\/ Non atomic flat layout: x\/y\n+        Asserts.assertTrue(lo.getCurrentLine().startsWith(\"Non atomic flat layout\"));\n+        String[] nonAtomicLayoutLine = lo.getCurrentLine().split(\"\\\\s+\");\n+        size_align = nonAtomicLayoutLine[4].split(\"\/\");\n+        if (size_align[0].contentEquals(\"-\")) {\n+          Asserts.assertTrue(size_align[1].contentEquals(\"-\"), \"Size\/Alignment mismatch\");\n+          cl.nonAtomicLayoutSize = -1;\n+          cl.nonAtomicLayoutAlignment = -1;\n+        } else {\n+          cl.nonAtomicLayoutSize = Integer.parseInt(size_align[0]);\n+          cl.nonAtomicLayoutAlignment = Integer.parseInt(size_align[1]);\n+        }\n+        lo.moveToNextLine();\n+        \/\/ Atomic flat layout: x\/y\n+        Asserts.assertTrue(lo.getCurrentLine().startsWith(\"Atomic flat layout\"));\n+        String[] atomicLayoutLine = lo.getCurrentLine().split(\"\\\\s+\");\n+        size_align = atomicLayoutLine[3].split(\"\/\");\n+        if (size_align[0].contentEquals(\"-\")) {\n+          Asserts.assertTrue(size_align[1].contentEquals(\"-\"), \"Size\/Alignment mismatch\");\n+          cl.atomicLayoutSize = -1;\n+          cl.atomicLayoutAlignment = -1;\n+        } else {\n+          cl.atomicLayoutSize = Integer.parseInt(size_align[0]);\n+          cl.atomicLayoutAlignment = Integer.parseInt(size_align[1]);\n+        }\n@@ -241,1 +323,16 @@\n-        if (lo.getCurrentLine().startsWith(\"Null marker offset\")) {\n+        \/\/ Nullable flat layout: x\/y\n+        Asserts.assertTrue(lo.getCurrentLine().startsWith(\"Nullable flat layout\"));\n+        String[] nullableLayoutLine = lo.getCurrentLine().split(\"\\\\s+\");\n+        size_align = nullableLayoutLine[3].split(\"\/\");\n+        if (size_align[0].contentEquals(\"-\")) {\n+          Asserts.assertTrue(size_align[1].contentEquals(\"-\"), \"Size\/Alignment mismatch\");\n+          cl.nullableLayoutSize = -1;\n+          cl.nullableLayoutAlignment = -1;\n+        } else {\n+          cl.nullableLayoutSize = Integer.parseInt(size_align[0]);\n+          cl.nullableLayoutAlignment = Integer.parseInt(size_align[1]);\n+        }\n+        lo.moveToNextLine();\n+        \/\/ Null marker offset = 15 (if class has a nullable flat layout)\n+        if (cl.nullableLayoutSize != -1) {\n+          Asserts.assertTrue(lo.getCurrentLine().startsWith(\"Null marker offset\"));\n@@ -243,1 +340,1 @@\n-          cl.internalNullMarkerOffset = Integer.parseInt(nullMarkerLine[4]);\n+          cl.nullMarkerOffset = Integer.parseInt(nullMarkerLine[4]);\n@@ -246,1 +343,1 @@\n-          cl.internalNullMarkerOffset = -1;\n+          cl.nullMarkerOffset = -1;\n@@ -266,0 +363,8 @@\n+      FieldBlock block = getFieldFromName(fieldName, isStatic);\n+      if (block == null) {\n+        throw new RuntimeException(\"No \" + (isStatic ? \"static\" : \"nonstatic\") + \" field found with name \"+ fieldName);\n+      }\n+      return block;\n+    }\n+\n+    FieldBlock getFieldFromNameOrNull(String fieldName, boolean isStatic) {\n@@ -273,1 +378,1 @@\n-      throw new RuntimeException(\"No \" + (isStatic ? \"static\" : \"nonstatic\") + \" field found with name \"+ fieldName);\n+      return null;\n@@ -363,1 +468,1 @@\n-        || block.type == BlockType.NULL_MARKER || block.type == BlockType.INHERITED_NULL_MARKER) {\n+        || block.type == BlockType.NULL_MARKER) {\n@@ -389,1 +494,1 @@\n-          if (block.type == BlockType.INHERITED || block.type == BlockType.INHERITED_NULL_MARKER) {\n+          if (block.type == BlockType.INHERITED) {\n@@ -397,2 +502,2 @@\n-            Asserts.assertEquals(block.size(), fcl.exactSize);\n-            Asserts.assertEquals(block.alignment(), fcl.alignment);\n+            Asserts.assertEquals(block.size(), fcl.getSize(block.layoutKind));\n+            Asserts.assertEquals(block.alignment(), fcl.getAlignment(block.layoutKind));\n@@ -510,0 +615,1 @@\n+        if (block.type() == BlockType.NULL_MARKER) continue;\n@@ -525,2 +631,1 @@\n-    Asserts.assertTrue((block.type != BlockType.NULL_MARKER && block.type != BlockType.INHERITED_NULL_MARKER && b.type == BlockType.INHERITED)\n-                       || ((block.type == BlockType.NULL_MARKER || block.type == BlockType.INHERITED_NULL_MARKER) && b.type == BlockType.INHERITED_NULL_MARKER));\n+    Asserts.assertTrue(b.type == BlockType.INHERITED);\n@@ -543,9 +648,0 @@\n-          if (block.type() == BlockType.FLAT && block.nullMarkerOffset() != -1) {\n-            if (block.hasInternalNullMarker()) {\n-              Asserts.assertTrue(block.nullMarkerOffset() > block.offset());\n-              Asserts.assertTrue(block.nullMarkerOffset() < block.offset() + block.size());\n-            } else {\n-              FieldBlock marker = layout.getFieldAtOffset(block.nullMarkerOffset(), false);\n-              Asserts.assertEquals(block.nullMarkerOffset(), marker.offset());\n-            }\n-          }\n@@ -553,3 +649,3 @@\n-            FieldBlock flatField = layout.getFieldAtOffset(block.referenceFieldOffset(), false);\n-            Asserts.assertEquals(flatField.type(), BlockType.FLAT);\n-            Asserts.assertEquals(flatField.nullMarkerOffset(), block.offset());\n+            Asserts.assertTrue(layout.hasNullMarker());\n+            Asserts.assertTrue(layout.hasNullableLayout());\n+            Asserts.assertEQ(block.offset(), layout.nullMarkerOffset);\n@@ -565,3 +661,1 @@\n-          if (block.type() == BlockType.FLAT) {\n-            Asserts.assertEquals(block.nullMarkerOffset(), -1); \/\/ -1 means no null marker\n-          }\n+          Asserts.assertNotEquals(block.type(), BlockType.FLAT);\n@@ -586,11 +680,13 @@\n-    while (lo.hasMoreLines()) {\n-      if (lo.getCurrentLine().startsWith(\"Heap oop size = \")) {\n-        String[] oopSizeLine = lo.getCurrentLine().split(\"\\\\s+\");\n-        oopSize = Integer.parseInt(oopSizeLine[4]);\n-        Asserts.assertTrue(oopSize == 4 || oopSize == 8);\n-      }\n-      if (lo.getCurrentLine().startsWith(\"Layout of class\")) {\n-        ClassLayout cl = ClassLayout.parseClassLayout(lo);\n-        layouts.add(cl);\n-      } else {\n-        lo.moveToNextLine(); \/\/ skipping line\n+    try {\n+      while (lo.hasMoreLines()) {\n+        if (lo.getCurrentLine().startsWith(\"Heap oop size = \")) {\n+          String[] oopSizeLine = lo.getCurrentLine().split(\"\\\\s+\");\n+          oopSize = Integer.parseInt(oopSizeLine[4]);\n+          Asserts.assertTrue(oopSize == 4 || oopSize == 8);\n+        }\n+        if (lo.getCurrentLine().startsWith(\"Layout of class\")) {\n+          ClassLayout cl = ClassLayout.parseClassLayout(lo);\n+          layouts.add(cl);\n+        } else {\n+          lo.moveToNextLine(); \/\/ skipping line\n+        }\n@@ -598,0 +694,4 @@\n+      Asserts.assertTrue(oopSize != 0);\n+    } catch (Throwable t) {\n+      System.out.println(\"Error while processing line: \" + lo.getCurrentLine());\n+      throw t;\n@@ -599,1 +699,0 @@\n-    Asserts.assertTrue(oopSize != 0);\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/field_layout\/FieldLayoutAnalyzer.java","additions":171,"deletions":72,"binary":false,"changes":243,"status":"modified"},{"patch":"@@ -26,1 +26,2 @@\n- * @requires vm.bits == 32 & vm.flagless\n+ * @ignore\n+ * @requires vm.bits == 32\n@@ -36,1 +37,2 @@\n- * @requires vm.bits == 64 & vm.flagless\n+ * @ignore\n+ * @requires vm.bits == 64\n@@ -46,1 +48,2 @@\n- * @requires vm.bits == 64 & vm.flagless\n+ * @ignore\n+ * @requires vm.bits == 64\n@@ -56,1 +59,2 @@\n- * @requires vm.bits == 64 & vm.flagless\n+ * @ignore\n+ * @requires vm.bits == 64\n@@ -303,1 +307,1 @@\n-    Collections.addAll(argsList, \"-cp\", System.getProperty(\"java.class.path\") + \":.\");\n+    Collections.addAll(argsList, \"-cp\", System.getProperty(\"java.class.path\") + System.getProperty(\"path.separator\") + \".\");\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/field_layout\/NullMarkersTest.java","additions":9,"deletions":5,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -26,1 +26,1 @@\n- * @requires vm.bits == 32 & vm.flagless\n+ * @requires vm.bits == 32\n@@ -36,1 +36,1 @@\n- * @requires vm.bits == 64 & vm.flagless\n+ * @requires vm.bits == 64\n@@ -46,1 +46,1 @@\n- * @requires vm.bits == 64 & vm.flagless\n+ * @requires vm.bits == 64\n@@ -56,1 +56,1 @@\n- * @requires vm.bits == 64 & vm.flagless\n+ * @requires vm.bits == 64\n@@ -187,1 +187,1 @@\n-    Collections.addAll(argsList, \"-cp\", System.getProperty(\"java.class.path\") + \":.\");\n+    Collections.addAll(argsList, \"-cp\", System.getProperty(\"java.class.path\") + System.getProperty(\"path.separator\") + \".\");\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/field_layout\/ValueFieldInheritanceTest.java","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"}]}