{"files":[{"patch":"@@ -209,1 +209,1 @@\n-  const ptrdiff_t estimate = 124;\n+  const ptrdiff_t estimate = 144;\n","filename":"src\/hotspot\/cpu\/aarch64\/vtableStubs_aarch64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2865,0 +2865,1 @@\n+  assert(__ last_calls_return_pc() == __ pc(), \"pcn not at return pc\");\n","filename":"src\/hotspot\/cpu\/ppc\/c1_LIRAssembler_ppc.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1121,1 +1121,2 @@\n-  assert_different_registers(a, b, tmp, atmp, btmp);\n+  assert_different_registers(a, tmp, atmp, btmp);\n+  assert_different_registers(b, tmp, atmp, btmp);\n@@ -1208,1 +1209,2 @@\n-  assert_different_registers(dst, a, b, atmp, btmp);\n+  assert_different_registers(dst, a, atmp, btmp);\n+  assert_different_registers(dst, b, atmp, btmp);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2275,2 +2275,2 @@\n-    keys = high - low + 1;\n-    if (keys < 0) {\n+    int64_t keys64 = ((int64_t)high - low) + 1;\n+    if (keys64 > 65535) {  \/\/ Max code length\n@@ -2280,0 +2280,1 @@\n+    keys = (int)keys64;\n","filename":"src\/hotspot\/share\/classfile\/verifier.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -190,1 +190,1 @@\n-    ICStub* stub = ICStub_from_destination_address(stub_address());\n+    ICStub* stub = ICStub::from_destination_address(stub_address());\n","filename":"src\/hotspot\/share\/code\/compiledIC.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -285,0 +285,3 @@\n+  \/\/ Estimated size of the node barrier in number of C2 Ideal nodes.\n+  \/\/ This is used to guide heuristics in C2, e.g. whether to unroll a loop.\n+  virtual uint estimated_barrier_size(const Node* node) const { return 0; }\n","filename":"src\/hotspot\/share\/gc\/shared\/c2\/barrierSetC2.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -87,2 +87,1 @@\n-\/\/   GenCollectedHeap\n-\/\/     SerialHeap\n+\/\/   SerialHeap\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1107,1 +1107,1 @@\n-    return n->as_If()->dominated_by(prev_dom, phase->is_IterGVN());\n+    return n->as_If()->dominated_by(prev_dom, phase->is_IterGVN(), false);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/c2\/shenandoahBarrierSetC2.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -323,0 +323,14 @@\n+uint ZBarrierSetC2::estimated_barrier_size(const Node* node) const {\n+  uint8_t barrier_data = MemNode::barrier_data(node);\n+  assert(barrier_data != 0, \"should be a barrier node\");\n+  uint uncolor_or_color_size = node->is_Load() ? 1 : 2;\n+  if ((barrier_data & ZBarrierElided) != 0) {\n+    return uncolor_or_color_size;\n+  }\n+  \/\/ A compare and branch corresponds to approximately four fast-path Ideal\n+  \/\/ nodes (Cmp, Bool, If, If projection). The slow path (If projection and\n+  \/\/ runtime call) is excluded since the corresponding code is laid out\n+  \/\/ separately and does not directly affect performance.\n+  return uncolor_or_color_size + 4;\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/z\/c2\/zBarrierSetC2.cpp","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -131,0 +131,1 @@\n+  virtual uint estimated_barrier_size(const Node* node) const;\n","filename":"src\/hotspot\/share\/gc\/z\/c2\/zBarrierSetC2.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -390,1 +390,1 @@\n-      \/\/ Promote calculation to 64 bits to do range checks, used by the verifier.\n+      \/\/ Promote calculation to signed 64 bits to do range checks, used by the verifier.\n@@ -394,3 +394,8 @@\n-      \/\/ only return len if it can be represented as a positive int;\n-      \/\/ return -1 otherwise\n-      return (len > 0 && len == (int)len) ? (int)len : -1;\n+      \/\/ Only return len if it can be represented as a positive int and lo <= hi.\n+      \/\/ The caller checks for bytecode stream overflow.\n+      if (lo <= hi && len == (int)len) {\n+        assert(len > 0, \"must be\");\n+        return (int)len;\n+      } else {\n+        return -1;\n+      }\n@@ -409,3 +414,7 @@\n-      \/\/ only return len if it can be represented as a positive int;\n-      \/\/ return -1 otherwise\n-      return (len > 0 && len == (int)len) ? (int)len : -1;\n+      \/\/ Only return len if it can be represented as a positive int and npairs >= 0.\n+      if (npairs >= 0 && len == (int)len) {\n+        assert(len > 0, \"must be\");\n+        return (int)len;\n+      } else {\n+        return -1;\n+      }\n","filename":"src\/hotspot\/share\/interpreter\/bytecodes.cpp","additions":16,"deletions":7,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -3040,0 +3040,7 @@\n+  if (!JVMCIENV->is_hotspot()) {\n+    \/\/ It's generally not safe to call Java code before the module system is initialized\n+    if (!Universe::is_module_initialized()) {\n+      JVMCI_event_1(\"callSystemExit(%d) before Universe::is_module_initialized() -> direct VM exit\", status);\n+      vm_exit_during_initialization();\n+    }\n+  }\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -821,0 +821,7 @@\n+\n+  \/\/ Convert \"~a | ~b\" into \"~(a & b)\"\n+  if (AddNode::is_not(phase, in(1), T_INT) && AddNode::is_not(phase, in(2), T_INT)) {\n+    Node* and_a_b = new AndINode(in(1)->in(1), in(2)->in(1));\n+    Node* tn = phase->transform(and_a_b);\n+    return AddNode::make_not(phase, tn, T_INT);\n+  }\n@@ -887,0 +894,8 @@\n+\n+  \/\/ Convert \"~a | ~b\" into \"~(a & b)\"\n+  if (AddNode::is_not(phase, in(1), T_LONG) && AddNode::is_not(phase, in(2), T_LONG)) {\n+    Node* and_a_b = new AndLNode(in(1)->in(1), in(2)->in(1));\n+    Node* tn = phase->transform(and_a_b);\n+    return AddNode::make_not(phase, tn, T_LONG);\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/addnode.cpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -305,0 +305,9 @@\n+CastIINode* CastIINode::pin_array_access_node() const {\n+  assert(_dependency == RegularDependency, \"already pinned\");\n+  if (has_range_check()) {\n+    return new CastIINode(in(0), in(1), bottom_type(), StrongDependency, has_range_check());\n+  }\n+  return nullptr;\n+}\n+\n+\n@@ -519,0 +528,1 @@\n+  return nullptr;\n","filename":"src\/hotspot\/share\/opto\/castnode.cpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -117,1 +117,1 @@\n-  bool has_range_check() {\n+  bool has_range_check() const {\n@@ -126,0 +126,2 @@\n+  CastIINode* pin_array_access_node() const;\n+\n","filename":"src\/hotspot\/share\/opto\/castnode.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -442,1 +442,1 @@\n-  Node* dominated_by(Node* prev_dom, PhaseIterGVN* igvn);\n+  Node* dominated_by(Node* prev_dom, PhaseIterGVN* igvn, bool pin_array_access_nodes);\n@@ -519,0 +519,2 @@\n+  void pin_array_access_nodes(PhaseIterGVN* igvn);\n+\n","filename":"src\/hotspot\/share\/opto\/cfgnode.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -4093,0 +4093,7 @@\n+    } else if (n->is_CallLeaf()) {\n+      \/\/ Runtime calls with narrow memory input (no MergeMem node)\n+      \/\/ get the memory projection\n+      n = n->as_Call()->proj_out_or_null(TypeFunc::Memory);\n+      if (n == nullptr) {\n+        continue;\n+      }\n@@ -4138,1 +4145,1 @@\n-      } else if (use->is_MemBar()) {\n+      } else if (use->is_MemBar() || use->is_CallLeaf()) {\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -542,1 +542,1 @@\n-static void adjust_check(Node* proj, Node* range, Node* index,\n+static void adjust_check(IfProjNode* proj, Node* range, Node* index,\n@@ -550,2 +550,2 @@\n-  DEBUG_ONLY( if( !bol->is_Bool() ) { proj->dump(3); fatal(\"Expect projection-->IfNode-->BoolNode\"); } )\n-  if( !bol->is_Bool() ) return;\n+  DEBUG_ONLY( if (!bol->is_Bool()) { proj->dump(3); fatal(\"Expect projection-->IfNode-->BoolNode\"); } )\n+  if (!bol->is_Bool()) return;\n@@ -556,2 +556,2 @@\n-  if( index ) {\n-    new_add = off_lo ? gvn->transform(new AddINode( index, new_add )) : index;\n+  if (index) {\n+    new_add = off_lo ? gvn->transform(new AddINode(index, new_add)) : index;\n@@ -560,2 +560,2 @@\n-    ? new CmpUNode( new_add, range )\n-    : new CmpUNode( range, new_add );\n+    ? new CmpUNode(new_add, range)\n+    : new CmpUNode(range, new_add);\n@@ -564,1 +564,1 @@\n-  if( new_cmp == cmp ) return;\n+  if (new_cmp == cmp) return;\n@@ -566,3 +566,9 @@\n-  Node *new_bol = gvn->transform( new BoolNode( new_cmp, bol->as_Bool()->_test._test ) );\n-  igvn->rehash_node_delayed( iff );\n-  iff->set_req_X( 1, new_bol, igvn );\n+  Node* new_bol = gvn->transform(new BoolNode(new_cmp, bol->as_Bool()->_test._test));\n+  igvn->rehash_node_delayed(iff);\n+  iff->set_req_X(1, new_bol, igvn);\n+  \/\/ As part of range check smearing, this range check is widened. Loads and range check Cast nodes that are control\n+  \/\/ dependent on this range check now depend on multiple dominating range checks. These control dependent nodes end up\n+  \/\/ at the lowest\/nearest dominating check in the graph. To ensure that these Loads\/Casts do not float above any of the\n+  \/\/ dominating checks (even when the lowest dominating check is later replaced by yet another dominating check), we\n+  \/\/ need to pin them at the lowest dominating check.\n+  proj->pin_array_access_nodes(igvn);\n@@ -1438,1 +1444,1 @@\n-  Node* ctl;\n+  IfProjNode* ctl;\n@@ -1506,1 +1512,1 @@\n-    return dominated_by(prev_dom, igvn);\n+    return dominated_by(prev_dom, igvn, false);\n@@ -1513,1 +1519,1 @@\n-Node* IfNode::dominated_by(Node* prev_dom, PhaseIterGVN *igvn) {\n+Node* IfNode::dominated_by(Node* prev_dom, PhaseIterGVN* igvn, bool pin_array_access_nodes) {\n@@ -1526,9 +1532,0 @@\n-  \/\/ Loop predicates may have depending checks which should not\n-  \/\/ be skipped. For example, range check predicate has two checks\n-  \/\/ for lower and upper bounds.\n-  ProjNode* unc_proj = proj_out(1 - prev_dom->as_Proj()->_con)->as_Proj();\n-  if (unc_proj->is_uncommon_trap_proj(Deoptimization::Reason_predicate) != nullptr ||\n-      unc_proj->is_uncommon_trap_proj(Deoptimization::Reason_profile_predicate) != nullptr) {\n-    prev_dom = idom;\n-  }\n-\n@@ -1557,0 +1554,13 @@\n+        if (pin_array_access_nodes && data_target != top) {\n+          \/\/ As a result of range check smearing, Loads and range check Cast nodes that are control dependent on this\n+          \/\/ range check (that is about to be removed) now depend on multiple dominating range checks. After the removal\n+          \/\/ of this range check, these control dependent nodes end up at the lowest\/nearest dominating check in the\n+          \/\/ graph. To ensure that these Loads\/Casts do not float above any of the dominating checks (even when the\n+          \/\/ lowest dominating check is later replaced by yet another dominating check), we need to pin them at the\n+          \/\/ lowest dominating check.\n+          Node* clone = s->pin_array_access_node();\n+          if (clone != nullptr) {\n+            clone = igvn->transform(clone);\n+            igvn->replace_node(s, clone);\n+          }\n+        }\n@@ -1801,0 +1811,16 @@\n+void IfProjNode::pin_array_access_nodes(PhaseIterGVN* igvn) {\n+  for (DUIterator i = outs(); has_out(i); i++) {\n+    Node* u = out(i);\n+    if (!u->depends_only_on_test()) {\n+      continue;\n+    }\n+    Node* clone = u->pin_array_access_node();\n+    if (clone != nullptr) {\n+      clone = igvn->transform(clone);\n+      assert(clone != u, \"shouldn't common\");\n+      igvn->replace_node(u, clone);\n+      --i;\n+    }\n+  }\n+}\n+\n@@ -1892,0 +1918,40 @@\n+    \/\/\n+    \/\/ Example:\n+    \/\/ a[i+x] \/\/ (1) 1 < x < 6\n+    \/\/ a[i+3] \/\/ (2)\n+    \/\/ a[i+4] \/\/ (3)\n+    \/\/ a[i+6] \/\/ max = max of all constants\n+    \/\/ a[i+2]\n+    \/\/ a[i+1] \/\/ min = min of all constants\n+    \/\/\n+    \/\/ If x < 3:\n+    \/\/   (1) a[i+x]: Leave unchanged\n+    \/\/   (2) a[i+3]: Replace with a[i+max] = a[i+6]: i+x < i+3 <= i+6  -> (2) is covered\n+    \/\/   (3) a[i+4]: Replace with a[i+min] = a[i+1]: i+1 < i+4 <= i+6  -> (3) and all following checks are covered\n+    \/\/   Remove all other a[i+c] checks\n+    \/\/\n+    \/\/ If x >= 3:\n+    \/\/   (1) a[i+x]: Leave unchanged\n+    \/\/   (2) a[i+3]: Replace with a[i+min] = a[i+1]: i+1 < i+3 <= i+x  -> (2) is covered\n+    \/\/   (3) a[i+4]: Replace with a[i+max] = a[i+6]: i+1 < i+4 <= i+6  -> (3) and all following checks are covered\n+    \/\/   Remove all other a[i+c] checks\n+    \/\/\n+    \/\/ We only need the top 2 range checks if x is the min or max of all constants.\n+    \/\/\n+    \/\/ This, however, only works if the interval [i+min,i+max] is not larger than max_int (i.e. abs(max - min) < max_int):\n+    \/\/ The theoretical max size of an array is max_int with:\n+    \/\/ - Valid index space: [0,max_int-1]\n+    \/\/ - Invalid index space: [max_int,-1] \/\/ max_int, min_int, min_int - 1 ..., -1\n+    \/\/\n+    \/\/ The size of the consecutive valid index space is smaller than the size of the consecutive invalid index space.\n+    \/\/ If we choose min and max in such a way that:\n+    \/\/ - abs(max - min) < max_int\n+    \/\/ - i+max and i+min are inside the valid index space\n+    \/\/ then all indices [i+min,i+max] must be in the valid index space. Otherwise, the invalid index space must be\n+    \/\/ smaller than the valid index space which is never the case for any array size.\n+    \/\/\n+    \/\/ Choosing a smaller array size only makes the valid index space smaller and the invalid index space larger and\n+    \/\/ the argument above still holds.\n+    \/\/\n+    \/\/ Note that the same optimization with the same maximal accepted interval size can also be found in C1.\n+    const jlong maximum_number_of_min_max_interval_indices = (jlong)max_jint;\n@@ -1926,7 +1992,12 @@\n-          \/\/ Gather expanded bounds\n-          off_lo = MIN2(off_lo,offset2);\n-          off_hi = MAX2(off_hi,offset2);\n-          \/\/ Record top NRC range checks\n-          prev_checks[nb_checks%NRC].ctl = prev_dom;\n-          prev_checks[nb_checks%NRC].off = offset2;\n-          nb_checks++;\n+\n+          \/\/ \"x - y\" -> must add one to the difference for number of elements in [x,y]\n+          const jlong diff = (jlong)MIN2(offset2, off_lo) - (jlong)MAX2(offset2, off_hi);\n+          if (ABS(diff) < maximum_number_of_min_max_interval_indices) {\n+            \/\/ Gather expanded bounds\n+            off_lo = MIN2(off_lo, offset2);\n+            off_hi = MAX2(off_hi, offset2);\n+            \/\/ Record top NRC range checks\n+            prev_checks[nb_checks % NRC].ctl = prev_dom->as_IfProj();\n+            prev_checks[nb_checks % NRC].off = offset2;\n+            nb_checks++;\n+          }\n@@ -1947,0 +2018,9 @@\n+      if (can_reshape && !phase->C->post_loop_opts_phase()) {\n+        \/\/ We are about to perform range check smearing (i.e. remove this RangeCheck if it is dominated by\n+        \/\/ a series of RangeChecks which have a range that covers this RangeCheck). This can cause array access nodes to\n+        \/\/ be pinned. We want to avoid that and first allow range check elimination a chance to remove the RangeChecks\n+        \/\/ from loops. Hence, we delay range check smearing until after loop opts.\n+        phase->C->record_for_post_loop_opts_igvn(this);\n+        return nullptr;\n+      }\n+\n@@ -2020,0 +2100,20 @@\n+      \/\/ The last RangeCheck is found to be redundant with a sequence of n (n >= 2) preceding RangeChecks.\n+      \/\/ If an array load is control dependent on the eliminated range check, the array load nodes (CastII and Load)\n+      \/\/ become control dependent on the last range check of the sequence, but they are really dependent on the entire\n+      \/\/ sequence of RangeChecks. If RangeCheck#n is later replaced by a dominating identical check, the array load\n+      \/\/ nodes must not float above the n-1 other RangeCheck in the sequence. We pin the array load nodes here to\n+      \/\/ guarantee it doesn't happen.\n+      \/\/\n+      \/\/ RangeCheck#1                 RangeCheck#1\n+      \/\/    |      \\                     |      \\\n+      \/\/    |      uncommon trap         |      uncommon trap\n+      \/\/    ..                           ..\n+      \/\/ RangeCheck#n              -> RangeCheck#n\n+      \/\/    |      \\                     |      \\\n+      \/\/    |      uncommon trap        CastII  uncommon trap\n+      \/\/ RangeCheck                     Load\n+      \/\/    |      \\\n+      \/\/   CastII  uncommon trap\n+      \/\/   Load\n+\n+      return dominated_by(prev_dom, igvn, true);\n@@ -2030,1 +2130,1 @@\n-  return dominated_by(prev_dom, igvn);\n+  return dominated_by(prev_dom, igvn, false);\n","filename":"src\/hotspot\/share\/opto\/ifnode.cpp","additions":131,"deletions":31,"binary":false,"changes":162,"status":"modified"},{"patch":"@@ -4871,1 +4871,1 @@\n-  \/\/ Test the header to see if it is unlocked.\n+  \/\/ Test the header to see if it is safe to read w.r.t. locking.\n@@ -4875,3 +4875,4 @@\n-  Node *unlocked_val   = _gvn.MakeConX(markWord::unlocked_value);\n-  Node *chk_unlocked   = _gvn.transform(new CmpXNode( lmasked_header, unlocked_val));\n-  Node *test_unlocked  = _gvn.transform(new BoolNode( chk_unlocked, BoolTest::ne));\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    Node *monitor_val   = _gvn.MakeConX(markWord::monitor_value);\n+    Node *chk_monitor   = _gvn.transform(new CmpXNode(lmasked_header, monitor_val));\n+    Node *test_monitor  = _gvn.transform(new BoolNode(chk_monitor, BoolTest::eq));\n@@ -4879,1 +4880,8 @@\n-  generate_slow_guard(test_unlocked, slow_region);\n+    generate_slow_guard(test_monitor, slow_region);\n+  } else {\n+    Node *unlocked_val      = _gvn.MakeConX(markWord::unlocked_value);\n+    Node *chk_unlocked      = _gvn.transform(new CmpXNode(lmasked_header, unlocked_val));\n+    Node *test_not_unlocked = _gvn.transform(new BoolNode(chk_unlocked, BoolTest::ne));\n+\n+    generate_slow_guard(test_not_unlocked, slow_region);\n+  }\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":13,"deletions":5,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -1352,0 +1352,2 @@\n+  bool has_dominating_loop_limit_check(Node* init_trip, Node* limit, jlong stride_con, BasicType iv_bt,\n+                                       Node* loop_entry);\n@@ -1513,1 +1515,1 @@\n-  void dominated_by(IfProjNode* prevdom, IfNode* iff, bool flip = false, bool exclude_loop_predicate = false);\n+  void dominated_by(IfProjNode* prevdom, IfNode* iff, bool flip = false, bool pin_array_access_nodes = false);\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -297,1 +297,5 @@\n-  assert(n->in(0) == nullptr, \"divisions with zero check should already have bailed out earlier in split-if\");\n+  if (n->in(0) != nullptr) {\n+    \/\/ Cannot split through phi if Div or Mod node has a control dependency to a zero check.\n+    return true;\n+  }\n+\n@@ -315,1 +319,1 @@\n-void PhaseIdealLoop::dominated_by(IfProjNode* prevdom, IfNode* iff, bool flip, bool exclude_loop_predicate) {\n+void PhaseIdealLoop::dominated_by(IfProjNode* prevdom, IfNode* iff, bool flip, bool pin_array_access_nodes) {\n@@ -340,1 +344,1 @@\n-  \/\/ If I dont have a reachable TRUE and FALSE path following the IfNode then\n+  \/\/ If I don't have a reachable TRUE and FALSE path following the IfNode then\n@@ -351,3 +355,0 @@\n-  \/\/ Loop predicates may have depending checks which should not\n-  \/\/ be skipped. For example, range check predicate has two checks\n-  \/\/ for lower and upper bounds.\n@@ -357,12 +358,0 @@\n-  ProjNode* dp_proj  = dp->as_Proj();\n-  ProjNode* unc_proj = iff->proj_out(1 - dp_proj->_con)->as_Proj();\n-  if (exclude_loop_predicate &&\n-      (unc_proj->is_uncommon_trap_proj(Deoptimization::Reason_predicate) != nullptr ||\n-       unc_proj->is_uncommon_trap_proj(Deoptimization::Reason_profile_predicate) != nullptr ||\n-       unc_proj->is_uncommon_trap_proj(Deoptimization::Reason_range_check) != nullptr)) {\n-    \/\/ If this is a range check (IfNode::is_range_check), do not\n-    \/\/ reorder because Compile::allow_range_check_smearing might have\n-    \/\/ changed the check.\n-    return; \/\/ Let IGVN transformation change control dependence.\n-  }\n-\n@@ -377,0 +366,14 @@\n+      if (pin_array_access_nodes) {\n+        \/\/ Because of Loop Predication, Loads and range check Cast nodes that are control dependent on this range\n+        \/\/ check (that is about to be removed) now depend on multiple dominating Hoisted Check Predicates. After the\n+        \/\/ removal of this range check, these control dependent nodes end up at the lowest\/nearest dominating predicate\n+        \/\/ in the graph. To ensure that these Loads\/Casts do not float above any of the dominating checks (even when the\n+        \/\/ lowest dominating check is later replaced by yet another dominating check), we need to pin them at the lowest\n+        \/\/ dominating check.\n+        Node* clone = cd->pin_array_access_node();\n+        if (clone != nullptr) {\n+          clone = _igvn.register_new_node_with_optimizer(clone, cd);\n+          _igvn.replace_node(cd, clone);\n+          cd = clone;\n+        }\n+      }\n@@ -1657,1 +1660,1 @@\n-          dominated_by(prevdom->as_IfProj(), n->as_If(), false, true);\n+          dominated_by(prevdom->as_IfProj(), n->as_If());\n@@ -1755,1 +1758,1 @@\n-        dominated_by(dom_proj_true->as_IfProj(), new_false_region->in(i)->in(0)->as_If(), false, false);\n+        dominated_by(dom_proj_true->as_IfProj(), new_false_region->in(i)->in(0)->as_If());\n@@ -1758,1 +1761,1 @@\n-        dominated_by(dom_proj_false->as_IfProj(), new_false_region->in(i)->in(0)->as_If(), false, false);\n+        dominated_by(dom_proj_false->as_IfProj(), new_false_region->in(i)->in(0)->as_If());\n","filename":"src\/hotspot\/share\/opto\/loopopts.cpp","additions":24,"deletions":21,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -848,0 +848,9 @@\n+uint8_t MemNode::barrier_data(const Node* n) {\n+  if (n->is_LoadStore()) {\n+    return n->as_LoadStore()->barrier_data();\n+  } else if (n->is_Mem()) {\n+    return n->as_Mem()->barrier_data();\n+  }\n+  return 0;\n+}\n+\n@@ -854,2 +863,6 @@\n-bool LoadNode::cmp( const Node &n ) const\n-{ return !Type::cmp( _type, ((LoadNode&)n)._type ); }\n+bool LoadNode::cmp(const Node &n) const {\n+  LoadNode& load = (LoadNode &)n;\n+  return !Type::cmp(_type, load._type) &&\n+         _control_dependency == load._control_dependency &&\n+         _mo == load._mo;\n+}\n@@ -992,0 +1005,8 @@\n+LoadNode* LoadNode::pin_array_access_node() const {\n+  const TypePtr* adr_type = this->adr_type();\n+  if (adr_type != nullptr && adr_type->isa_aryptr()) {\n+    return clone_pinned();\n+  }\n+  return nullptr;\n+}\n+\n@@ -1011,1 +1032,2 @@\n-    LoadNode* ld = clone()->as_Load();\n+    \/\/ load depends on the tests that validate the arraycopy\n+    LoadNode* ld = clone_pinned();\n@@ -1053,2 +1075,0 @@\n-    \/\/ load depends on the tests that validate the arraycopy\n-    ld->_control_dependency = UnknownControl;\n@@ -2561,0 +2581,6 @@\n+LoadNode* LoadNode::clone_pinned() const {\n+  LoadNode* ld = clone()->as_Load();\n+  ld->_control_dependency = UnknownControl;\n+  return ld;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":31,"deletions":5,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -133,0 +133,3 @@\n+  \/\/ Return the barrier data of n, if available, or 0 otherwise.\n+  static uint8_t barrier_data(const Node* n);\n+\n@@ -299,0 +302,2 @@\n+  LoadNode* pin_array_access_node() const;\n+\n@@ -324,0 +329,2 @@\n+\n+  LoadNode* clone_pinned() const;\n","filename":"src\/hotspot\/share\/opto\/memnode.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -296,1 +296,2 @@\n-\/\/ Classes to perform mul_ring() for MulI\/MulLNode.\n+\/\/ This template class performs type multiplication for MulI\/MulLNode. NativeType is either jint or jlong.\n+\/\/ In this class, the inputs of the MulNodes are named left and right with types [left_lo,left_hi] and [right_lo,right_hi].\n@@ -298,4 +299,4 @@\n-\/\/ This class checks if all cross products of the left and right input of a multiplication have the same \"overflow value\".\n-\/\/ Without overflow\/underflow:\n-\/\/ Product is positive? High signed multiplication result: 0\n-\/\/ Product is negative? High signed multiplication result: -1\n+\/\/ In general, the multiplication of two x-bit values could produce a result that consumes up to 2x bits if there is\n+\/\/ enough space to hold them all. We can therefore distinguish the following two cases for the product:\n+\/\/ - no overflow (i.e. product fits into x bits)\n+\/\/ - overflow (i.e. product does not fit into x bits)\n@@ -303,8 +304,55 @@\n-\/\/ We normalize these values (see normalize_overflow_value()) such that we get the same \"overflow value\" by adding 1 if\n-\/\/ the product is negative. This allows us to compare all the cross product \"overflow values\". If one is different,\n-\/\/ compared to the others, then we know that this multiplication has a different number of over- or underflows compared\n-\/\/ to the others. In this case, we need to use bottom type and cannot guarantee a better type. Otherwise, we can take\n-\/\/ the min und max of all computed cross products as type of this Mul node.\n-template<typename IntegerType>\n-class IntegerMulRing {\n-  using NativeType = std::conditional_t<std::is_same<TypeInt, IntegerType>::value, jint, jlong>;\n+\/\/ When multiplying the two x-bit inputs 'left' and 'right' with their x-bit types [left_lo,left_hi] and [right_lo,right_hi]\n+\/\/ we need to find the minimum and maximum of all possible products to define a new type. To do that, we compute the\n+\/\/ cross product of [left_lo,left_hi] and [right_lo,right_hi] in 2x-bit space where no over- or underflow can happen.\n+\/\/ The cross product consists of the following four multiplications with 2x-bit results:\n+\/\/ (1) left_lo * right_lo\n+\/\/ (2) left_lo * right_hi\n+\/\/ (3) left_hi * right_lo\n+\/\/ (4) left_hi * right_hi\n+\/\/\n+\/\/ Let's define the following two functions:\n+\/\/ - Lx(i): Returns the lower x bits of the 2x-bit number i.\n+\/\/ - Ux(i): Returns the upper x bits of the 2x-bit number i.\n+\/\/\n+\/\/ Let's first assume all products are positive where only overflows are possible but no underflows. If there is no\n+\/\/ overflow for a product p, then the upper x bits of the 2x-bit result p are all zero:\n+\/\/     Ux(p) = 0\n+\/\/     Lx(p) = p\n+\/\/\n+\/\/ If none of the multiplications (1)-(4) overflow, we can truncate the upper x bits and use the following result type\n+\/\/ with x bits:\n+\/\/      [result_lo,result_hi] = [MIN(Lx(1),Lx(2),Lx(3),Lx(4)),MAX(Lx(1),Lx(2),Lx(3),Lx(4))]\n+\/\/\n+\/\/ If any of these multiplications overflows, we could pessimistically take the bottom type for the x bit result\n+\/\/ (i.e. all values in the x-bit space could be possible):\n+\/\/      [result_lo,result_hi] = [NativeType_min,NativeType_max]\n+\/\/\n+\/\/ However, in case of any overflow, we can do better by analyzing the upper x bits of all multiplications (1)-(4) with\n+\/\/ 2x-bit results. The upper x bits tell us something about how many times a multiplication has overflown the lower\n+\/\/ x bits. If the upper x bits of (1)-(4) are all equal, then we know that all of these multiplications overflowed\n+\/\/ the lower x bits the same number of times:\n+\/\/     Ux((1)) = Ux((2)) = Ux((3)) = Ux((4))\n+\/\/\n+\/\/ If all upper x bits are equal, we can conclude:\n+\/\/     Lx(MIN((1),(2),(3),(4))) = MIN(Lx(1),Lx(2),Lx(3),Lx(4)))\n+\/\/     Lx(MAX((1),(2),(3),(4))) = MAX(Lx(1),Lx(2),Lx(3),Lx(4)))\n+\/\/\n+\/\/ Therefore, we can use the same precise x-bit result type as for the no-overflow case:\n+\/\/     [result_lo,result_hi] = [(MIN(Lx(1),Lx(2),Lx(3),Lx(4))),MAX(Lx(1),Lx(2),Lx(3),Lx(4)))]\n+\/\/\n+\/\/\n+\/\/ Now let's assume that (1)-(4) are signed multiplications where over- and underflow could occur:\n+\/\/ Negative numbers are all sign extend with ones. Therefore, if a negative product does not underflow, then the\n+\/\/ upper x bits of the 2x-bit result are all set to ones which is minus one in two's complement. If there is an underflow,\n+\/\/ the upper x bits are decremented by the number of times an underflow occurred. The smallest possible negative product\n+\/\/ is NativeType_min*NativeType_max, where the upper x bits are set to NativeType_min \/ 2 (b11...0). It is therefore\n+\/\/ impossible to underflow the upper x bits. Thus, when having all ones (i.e. minus one) in the upper x bits, we know\n+\/\/ that there is no underflow.\n+\/\/\n+\/\/ To be able to compare the number of over-\/underflows of positive and negative products, respectively, we normalize\n+\/\/ the upper x bits of negative 2x-bit products by adding one. This way a product has no over- or underflow if the\n+\/\/ normalized upper x bits are zero. Now we can use the same improved type as for strictly positive products because we\n+\/\/ can compare the upper x bits in a unified way with N() being the normalization function:\n+\/\/     N(Ux((1))) = N(Ux((2))) = N(Ux((3)) = N(Ux((4)))\n+template<typename NativeType>\n+class IntegerTypeMultiplication {\n@@ -316,4 +364,0 @@\n-  NativeType _lo_lo_product;\n-  NativeType _lo_hi_product;\n-  NativeType _hi_lo_product;\n-  NativeType _hi_hi_product;\n@@ -324,8 +368,5 @@\n-  static NativeType multiply_high_signed_overflow_value(NativeType x, NativeType y);\n-\n-  \/\/ Pre-compute cross products which are used at several places\n-  void compute_cross_products() {\n-    _lo_lo_product = java_multiply(_lo_left, _lo_right);\n-    _lo_hi_product = java_multiply(_lo_left, _hi_right);\n-    _hi_lo_product = java_multiply(_hi_left, _lo_right);\n-    _hi_hi_product = java_multiply(_hi_left, _hi_right);\n+  static NativeType multiply_high(NativeType x, NativeType y);\n+  const Type* create_type(NativeType lo, NativeType hi) const;\n+\n+  static NativeType multiply_high_signed_overflow_value(NativeType x, NativeType y) {\n+    return normalize_overflow_value(x, y, multiply_high(x, y));\n@@ -334,1 +375,1 @@\n-  bool cross_products_not_same_overflow() const {\n+  bool cross_product_not_same_overflow_value() const {\n@@ -344,0 +385,4 @@\n+  bool does_product_overflow(NativeType x, NativeType y) const {\n+    return multiply_high_signed_overflow_value(x, y) != 0;\n+  }\n+\n@@ -349,4 +394,5 @@\n-  IntegerMulRing(const IntegerType* left, const IntegerType* right) : _lo_left(left->_lo), _lo_right(right->_lo),\n-    _hi_left(left->_hi), _hi_right(right->_hi), _widen_left(left->_widen), _widen_right(right->_widen)  {\n-    compute_cross_products();\n-  }\n+  template<class IntegerType>\n+  IntegerTypeMultiplication(const IntegerType* left, const IntegerType* right)\n+      : _lo_left(left->_lo), _lo_right(right->_lo),\n+        _hi_left(left->_hi), _hi_right(right->_hi),\n+        _widen_left(left->_widen), _widen_right(right->_widen)  {}\n@@ -359,1 +405,1 @@\n-    if (cross_products_not_same_overflow()) {\n+    if (cross_product_not_same_overflow_value()) {\n@@ -362,3 +408,8 @@\n-    const NativeType min = MIN4(_lo_lo_product, _lo_hi_product, _hi_lo_product, _hi_hi_product);\n-    const NativeType max = MAX4(_lo_lo_product, _lo_hi_product, _hi_lo_product, _hi_hi_product);\n-    return IntegerType::make(min, max, MAX2(_widen_left, _widen_right));\n+\n+    NativeType lo_lo_product = java_multiply(_lo_left, _lo_right);\n+    NativeType lo_hi_product = java_multiply(_lo_left, _hi_right);\n+    NativeType hi_lo_product = java_multiply(_hi_left, _lo_right);\n+    NativeType hi_hi_product = java_multiply(_hi_left, _hi_right);\n+    const NativeType min = MIN4(lo_lo_product, lo_hi_product, hi_lo_product, hi_hi_product);\n+    const NativeType max = MAX4(lo_lo_product, lo_hi_product, hi_lo_product, hi_hi_product);\n+    return create_type(min, max);\n@@ -366,1 +417,7 @@\n-};\n+  bool does_overflow() const {\n+    return does_product_overflow(_lo_left, _lo_right) ||\n+           does_product_overflow(_lo_left, _hi_right) ||\n+           does_product_overflow(_hi_left, _lo_right) ||\n+           does_product_overflow(_hi_left, _hi_right);\n+  }\n+};\n@@ -370,1 +427,1 @@\n-const Type* IntegerMulRing<TypeInt>::overflow_type() {\n+const Type* IntegerTypeMultiplication<jint>::overflow_type() {\n@@ -375,1 +432,1 @@\n-jint IntegerMulRing<TypeInt>::multiply_high_signed_overflow_value(const jint x, const jint y) {\n+jint IntegerTypeMultiplication<jint>::multiply_high(const jint x, const jint y) {\n@@ -379,2 +436,1 @@\n-  const jint result = (jint)((uint64_t)product >> 32u);\n-  return normalize_overflow_value(x, y, result);\n+  return (jint)((uint64_t)product >> 32u);\n@@ -384,1 +440,6 @@\n-const Type* IntegerMulRing<TypeLong>::overflow_type() {\n+const Type* IntegerTypeMultiplication<jint>::create_type(jint lo, jint hi) const {\n+  return TypeInt::make(lo, hi, MAX2(_widen_left, _widen_right));\n+}\n+\n+template <>\n+const Type* IntegerTypeMultiplication<jlong>::overflow_type() {\n@@ -389,3 +450,7 @@\n-jlong IntegerMulRing<TypeLong>::multiply_high_signed_overflow_value(const jlong x, const jlong y) {\n-  const jlong result = multiply_high_signed(x, y);\n-  return normalize_overflow_value(x, y, result);\n+jlong IntegerTypeMultiplication<jlong>::multiply_high(const jlong x, const jlong y) {\n+  return multiply_high_signed(x, y);\n+}\n+\n+template <>\n+const Type* IntegerTypeMultiplication<jlong>::create_type(jlong lo, jlong hi) const {\n+  return TypeLong::make(lo, hi, MAX2(_widen_left, _widen_right));\n@@ -396,2 +461,7 @@\n-  const IntegerMulRing<TypeInt> integer_mul_ring(type_left->is_int(), type_right->is_int());\n-  return integer_mul_ring.compute();\n+  const IntegerTypeMultiplication<jint> integer_multiplication(type_left->is_int(), type_right->is_int());\n+  return integer_multiplication.compute();\n+}\n+\n+bool MulINode::does_overflow(const TypeInt* type_left, const TypeInt* type_right) {\n+  const IntegerTypeMultiplication<jint> integer_multiplication(type_left, type_right);\n+  return integer_multiplication.does_overflow();\n@@ -402,2 +472,2 @@\n-  const IntegerMulRing<TypeLong> integer_mul_ring(type_left->is_long(), type_right->is_long());\n-  return integer_mul_ring.compute();\n+  const IntegerTypeMultiplication<jlong> integer_multiplication(type_left->is_long(), type_right->is_long());\n+  return integer_multiplication.compute();\n","filename":"src\/hotspot\/share\/opto\/mulnode.cpp","additions":117,"deletions":47,"binary":false,"changes":164,"status":"modified"},{"patch":"@@ -1153,1 +1153,8 @@\n-\/\/----------------- Code Generation\n+  \/\/ Returns a clone of the current node that's pinned (if the current node is not) for nodes found in array accesses\n+  \/\/ (Load and range check CastII nodes).\n+  \/\/ This is used when an array access is made dependent on 2 or more range checks (range check smearing or Loop Predication).\n+  virtual Node* pin_array_access_node() const {\n+    return nullptr;\n+  }\n+\n+  \/\/----------------- Code Generation\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -840,1 +840,1 @@\n-    if (mv == NULL) {\n+    if (mv == nullptr) {\n@@ -848,1 +848,1 @@\n-      (void)FillLocArray(1, NULL, sfpt->in(selector_idx), &deps, NULL);\n+      (void)FillLocArray(1, nullptr, sfpt->in(selector_idx), &deps, nullptr);\n@@ -1154,0 +1154,24 @@\n+      } else if (obj_node->is_SafePointScalarMerge()) {\n+        SafePointScalarMergeNode* smerge = obj_node->as_SafePointScalarMerge();\n+        ObjectMergeValue* mv = (ObjectMergeValue*) sv_for_node_id(objs, smerge->_idx);\n+\n+        if (mv == nullptr) {\n+          GrowableArray<ScopeValue*> deps;\n+\n+          int merge_pointer_idx = smerge->merge_pointer_idx(youngest_jvms);\n+          FillLocArray(0, sfn, sfn->in(merge_pointer_idx), &deps, objs);\n+          assert(deps.length() == 1, \"missing value\");\n+\n+          int selector_idx = smerge->selector_idx(youngest_jvms);\n+          FillLocArray(1, nullptr, sfn->in(selector_idx), &deps, nullptr);\n+          assert(deps.length() == 2, \"missing value\");\n+\n+          mv = new ObjectMergeValue(smerge->_idx, deps.at(0), deps.at(1));\n+          set_sv_for_object_node(objs, mv);\n+\n+          for (uint i = 1; i < smerge->req(); i++) {\n+            Node* obj_node = smerge->in(i);\n+            FillLocArray(mv->possible_objects()->length(), sfn, obj_node, mv->possible_objects(), objs);\n+          }\n+        }\n+        scval = mv;\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":27,"deletions":3,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -25,2 +25,0 @@\n-#include \"opto\/addnode.hpp\"\n-#include \"opto\/node.hpp\"\n@@ -29,0 +27,1 @@\n+#include \"opto\/addnode.hpp\"\n@@ -33,0 +32,1 @@\n+#include \"opto\/node.hpp\"\n@@ -35,1 +35,0 @@\n-\n","filename":"src\/hotspot\/share\/opto\/split_if.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -46,12 +46,0 @@\n-      if (subk->is_same_java_type_as(superk) && !sub_t->maybe_null()) {\n-        \/\/ The super_t has no subclasses, and sub_t has the same type and is not null,\n-        \/\/ hence the check should always evaluate to EQ. However, this is an impossible\n-        \/\/ situation since super_t is also abstract, and hence sub_t cannot have the\n-        \/\/ same type and be non-null.\n-        \/\/ Still, if the non-static method of an abstract class without subclasses is\n-        \/\/ force-compiled, the Param0 has the self\/this pointer with NotNull. This\n-        \/\/ method would now never be called, because of the leaf-type dependency. Hence,\n-        \/\/ just for consistency with verification, we return EQ.\n-        return TypeInt::CC_EQ;\n-      }\n-      \/\/ subk is either a supertype of superk, or null. In either case, superk is a subtype.\n","filename":"src\/hotspot\/share\/opto\/subtypenode.cpp","additions":0,"deletions":12,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -937,0 +937,5 @@\n+  if (selected_method->is_abstract()) {\n+    ResourceMark rm(THREAD);\n+    THROW_MSG(vmSymbols::java_lang_AbstractMethodError(), selected_method->name()->as_C_string());\n+  }\n+\n","filename":"src\/hotspot\/share\/prims\/jni.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -2899,1 +2899,0 @@\n-\n@@ -2902,4 +2901,12 @@\n-  int result_count = 0;\n-  \/\/ First, count the fields.\n-  FilteredFieldStream flds(ik, true, true);\n-  result_count = flds.field_count();\n+  FilteredJavaFieldStream flds(ik);\n+\n+  int result_count = flds.field_count();\n+\n+  \/\/ Allocate the result and fill it in.\n+  jfieldID* result_list = (jfieldID*)jvmtiMalloc(result_count * sizeof(jfieldID));\n+  for (int i = 0; i < result_count; i++, flds.next()) {\n+    result_list[i] = jfieldIDWorkaround::to_jfieldID(ik, flds.offset(),\n+                                                     flds.access_flags().is_static(),\n+                                                     flds.field_descriptor().is_flat());\n+  }\n+  assert(flds.done(), \"just checking\");\n@@ -2907,13 +2914,0 @@\n-  \/\/ Allocate the result and fill it in\n-  jfieldID* result_list = (jfieldID*) jvmtiMalloc(result_count * sizeof(jfieldID));\n-  \/\/ The JVMTI spec requires fields in the order they occur in the class file,\n-  \/\/ this is the reverse order of what FieldStream hands out.\n-  int id_index = (result_count - 1);\n-\n-  for (FilteredFieldStream src_st(ik, true, true); !src_st.eos(); src_st.next()) {\n-    result_list[id_index--] = jfieldIDWorkaround::to_jfieldID(\n-                                            ik, src_st.offset(),\n-                                            src_st.access_flags().is_static(),\n-                                            src_st.field_descriptor().is_flat());\n-  }\n-  assert(id_index == -1, \"just checking\");\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnv.cpp","additions":13,"deletions":19,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -539,2 +539,2 @@\n-        if (mark.is_neutral()) {\n-          assert(!lock_stack.contains(obj()), \"thread must not already hold the lock\");\n+        while (mark.is_neutral()) {\n+          \/\/ Retry until a lock state change has been observed.  cas_set_mark() may collide with non lock bits modifications.\n@@ -542,2 +542,3 @@\n-          markWord locked_mark = mark.set_fast_locked();\n-          markWord old_mark = obj()->cas_set_mark(locked_mark, mark);\n+          assert(!lock_stack.contains(obj()), \"thread must not already hold the lock\");\n+          const markWord locked_mark = mark.set_fast_locked();\n+          const markWord old_mark = obj()->cas_set_mark(locked_mark, mark);\n@@ -549,0 +550,1 @@\n+          mark = old_mark;\n@@ -601,13 +603,7 @@\n-      if (mark.is_fast_locked()) {\n-        markWord unlocked_mark = mark.set_unlocked();\n-        markWord old_mark = object->cas_set_mark(unlocked_mark, mark);\n-        if (old_mark != mark) {\n-          \/\/ Another thread won the CAS, it must have inflated the monitor.\n-          \/\/ It can only have installed an anonymously locked monitor at this point.\n-          \/\/ Fetch that monitor, set owner correctly to this thread, and\n-          \/\/ exit it (allowing waiting threads to enter).\n-          assert(old_mark.has_monitor(), \"must have monitor\");\n-          ObjectMonitor* monitor = old_mark.monitor();\n-          assert(monitor->is_owner_anonymous(), \"must be anonymous owner\");\n-          monitor->set_owner_from_anonymous(current);\n-          monitor->exit(current);\n+      while (mark.is_fast_locked()) {\n+        \/\/ Retry until a lock state change has been observed.  cas_set_mark() may collide with non lock bits modifications.\n+        const markWord unlocked_mark = mark.set_unlocked();\n+        const markWord old_mark = object->cas_set_mark(unlocked_mark, mark);\n+        if (old_mark == mark) {\n+          current->lock_stack().remove(object);\n+          return;\n@@ -615,3 +611,1 @@\n-        LockStack& lock_stack = current->lock_stack();\n-        lock_stack.remove(object);\n-        return;\n+        mark = old_mark;\n@@ -936,7 +930,0 @@\n-\/\/ Can be called from non JavaThreads (e.g., VMThread) for FastHashCode\n-\/\/ calculations as part of JVM\/TI tagging.\n-static bool is_lock_owned(Thread* thread, oop obj) {\n-  assert(LockingMode == LM_LIGHTWEIGHT, \"only call this with new lightweight locking enabled\");\n-  return thread->is_Java_thread() ? JavaThread::cast(thread)->lock_stack().contains(obj) : false;\n-}\n-\n@@ -958,1 +945,1 @@\n-    if (mark.is_neutral()) {               \/\/ if this is a normal header\n+    if (mark.is_neutral() || (LockingMode == LM_LIGHTWEIGHT && mark.is_fast_locked())) {\n@@ -970,0 +957,4 @@\n+      if (LockingMode == LM_LIGHTWEIGHT) {\n+        \/\/ CAS failed, retry\n+        continue;\n+      }\n@@ -1001,7 +992,0 @@\n-    } else if (LockingMode == LM_LIGHTWEIGHT && mark.is_fast_locked() && is_lock_owned(current, obj)) {\n-      \/\/ This is a fast-lock owned by the calling thread so use the\n-      \/\/ markWord from the object.\n-      hash = mark.hash();\n-      if (hash != 0) {                  \/\/ if it has a hash, just return it\n-        return hash;\n-      }\n@@ -1340,0 +1324,7 @@\n+\/\/ Can be called from non JavaThreads (e.g., VMThread) for FastHashCode\n+\/\/ calculations as part of JVM\/TI tagging.\n+static bool is_lock_owned(Thread* thread, oop obj) {\n+  assert(LockingMode == LM_LIGHTWEIGHT, \"only call this with new lightweight locking enabled\");\n+  return thread->is_Java_thread() ? JavaThread::cast(thread)->lock_stack().contains(obj) : false;\n+}\n+\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":26,"deletions":35,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -42,2 +42,9 @@\n- * @see Class#accessFlags()\n- * @see Member#accessFlags()\n+ * @apiNote\n+ * Not all modifiers that are syntactic Java language modifiers are\n+ * represented in this class, only those modifiers that <em>also<\/em>\n+ * have a corresponding JVM {@linkplain AccessFlag access flag} are\n+ * included. In particular the {@code default} method modifier (JLS\n+ * {@jls 9.4.3}) and the {@code sealed} and {@code non-sealed} class\n+ * (JLS {@jls 8.1.1.2}) and interface (JLS {@jls 9.1.1.4}) modifiers\n+ * are <em>not<\/em> represented in this class.\n+ *\n@@ -234,0 +241,1 @@\n+     *\n@@ -247,0 +255,16 @@\n+     * @apiNote\n+     * To make a high-fidelity representation of the Java source\n+     * modifiers of a class or member, source-level modifiers that do\n+     * <em>not<\/em> have a constant in this class should be included\n+     * and appear in an order consistent with the full recommended\n+     * ordering for that kind of declaration as given in <cite>The\n+     * Java Language Specification<\/cite>. For example, for a\n+     * {@linkplain Method#toGenericString() method} the \"{@link\n+     * Method#isDefault() default}\" modifier is ordered immediately\n+     * before \"{@code static}\" (JLS {@jls 9.4}). For a {@linkplain\n+     * Class#toGenericString() class object}, the \"{@link\n+     * Class#isSealed() sealed}\" or {@code \"non-sealed\"} modifier is\n+     * ordered immediately after \"{@code final}\" for a class (JLS\n+     * {@jls 8.1.1}) and immediately after \"{@code static}\" for an\n+     * interface (JLS {@jls 9.1.1}).\n+     *\n","filename":"src\/java.base\/share\/classes\/java\/lang\/reflect\/Modifier.java","additions":26,"deletions":2,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -67,0 +67,1 @@\n+compiler\/c2\/irTests\/TestDuplicateBackedge.java 8318904 generic-all\n@@ -92,1 +93,0 @@\n-gc\/stress\/TestStressG1Humongous.java 8286554 windows-x64\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -258,0 +258,1 @@\n+  applications\/ctw\/modules \\\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -627,1 +627,0 @@\n-sun\/security\/pkcs11\/Provider\/MultipleLogins.sh                  8319128 linux-aarch64\n","filename":"test\/jdk\/ProblemList.txt","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"}]}