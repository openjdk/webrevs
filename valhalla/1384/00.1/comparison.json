{"files":[{"patch":"@@ -100,1 +100,1 @@\n-JAVADOC_OPTIONS := -use -keywords -notimestamp \\\n+JAVADOC_OPTIONS := -XDignore.symbol.file=true -use -keywords -notimestamp \\\n@@ -103,0 +103,2 @@\n+    -XDenableValueTypes \\\n+    --enable-preview -source $(JDK_SOURCE_TARGET_VERSION) \\\n","filename":"make\/Docs.gmk","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -78,0 +78,4 @@\n+GENERATED_VALUE_CLASS_SUBDIRS += \\\n+    $(SUPPORT_OUTPUTDIR)\/gensrc-valueclasses \\\n+    #\n+\n@@ -147,0 +151,6 @@\n+# Find value class source dirs for a particular module  (only generated)\n+# $1 - Module to find source dirs for\n+FindModuleValueClassSrcDirs = \\\n+    $(strip $(wildcard \\\n+        $(addsuffix \/$(strip $1), $(GENERATED_VALUE_CLASS_SUBDIRS))))\n+\n@@ -169,0 +179,6 @@\n+# Construct the complete module source path for value classes\n+GetModuleValueClassSrcPath = \\\n+    $(call PathList, \\\n+        $(addsuffix \/*, $(GENERATED_VALUE_CLASS_SUBDIRS) $(GENERATED_SRC_DIRS) $(IMPORT_MODULES_SRC)) \\\n+        $(foreach sub, $(SRC_SUBDIRS), $(addsuffix \/*\/$(sub), $(TOP_SRC_DIRS))))\n+\n","filename":"make\/common\/Modules.gmk","additions":16,"deletions":0,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -87,1 +87,1 @@\n-        serial preview dangling-doc-comments, \\\n+        serial preview unchecked deprecation dangling-doc-comments, \\\n","filename":"make\/test\/BuildMicrobenchmark.gmk","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -156,2 +156,2 @@\n-      sender_unextended_sp = sender_sp;\n-      saved_fp = (intptr_t*) *(sender_sp - frame::sender_sp_offset);\n+      intptr_t **saved_fp_addr = (intptr_t**) (sender_sp - frame::sender_sp_offset);\n+      saved_fp = *saved_fp_addr;\n@@ -162,1 +162,4 @@\n-    }\n+      \/\/ Repair the sender sp if this is a method with scalarized inline type args\n+      sender_sp = repair_sender_sp(sender_sp, saved_fp_addr);\n+      sender_unextended_sp = sender_sp;\n+    }\n@@ -825,0 +828,16 @@\n+\/\/ Check for a method with scalarized inline type arguments that needs\n+\/\/ a stack repair and return the repaired sender stack pointer.\n+intptr_t* frame::repair_sender_sp(intptr_t* sender_sp, intptr_t** saved_fp_addr) const {\n+  nmethod* nm = _cb->as_nmethod_or_null();\n+  if (nm != nullptr && nm->needs_stack_repair()) {\n+    \/\/ The stack increment resides just below the saved FP on the stack and\n+    \/\/ records the total frame size excluding the two words for saving FP and LR.\n+    intptr_t* sp_inc_addr = (intptr_t*) (saved_fp_addr - 1);\n+    assert(*sp_inc_addr % StackAlignmentInBytes == 0, \"sp_inc not aligned\");\n+    int real_frame_size = (*sp_inc_addr \/ wordSize) + 2;\n+    assert(real_frame_size >= _cb->frame_size() && real_frame_size <= 1000000, \"invalid frame size\");\n+    sender_sp = unextended_sp() + real_frame_size;\n+  }\n+  return sender_sp;\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/frame_aarch64.cpp","additions":22,"deletions":3,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -3200,0 +3200,3 @@\n+void LIR_Assembler::emit_profile_inline_type(LIR_OpProfileInlineType* op) {\n+  Unimplemented();\n+}\n","filename":"src\/hotspot\/cpu\/ppc\/c1_LIRAssembler_ppc.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1859,1 +1859,1 @@\n-  if (!UseFastStosb && UseSSE >= 2 && UseUnalignedLoadStores) {\n+  if (UseSSE >= 2 && UseUnalignedLoadStores) {\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -283,1 +283,1 @@\n-  if (!x->mismatched() && array != nullptr && index != nullptr) {\n+  if (!x->should_profile() && !x->mismatched() && array != nullptr && index != nullptr) {\n@@ -651,1 +651,2 @@\n-      if (!is_interface && klass->is_subtype_of(x->klass())) {\n+      if (!is_interface && klass->is_subtype_of(x->klass()) && (!x->is_null_free() || obj->is_null_free())) {\n+        assert(!x->klass()->is_inlinetype() || x->klass() == klass, \"Inline klasses can't have subtypes\");\n@@ -656,2 +657,2 @@\n-    \/\/ checkcast of null returns null\n-    if (obj->as_Constant() && obj->type()->as_ObjectType()->constant_value()->is_null_object()) {\n+    \/\/ checkcast of null returns null for non null-free klasses\n+    if (!x->is_null_free() && obj->is_null_obj()) {\n@@ -671,1 +672,1 @@\n-    if (obj->as_Constant() && obj->type()->as_ObjectType()->constant_value()->is_null_object()) {\n+    if (obj->as_Constant() && obj->is_null_obj()) {\n@@ -849,2 +850,3 @@\n-void Canonicalizer::do_ProfileInvoke  (ProfileInvoke*   x) {}\n-void Canonicalizer::do_RuntimeCall    (RuntimeCall*     x) {}\n+void Canonicalizer::do_ProfileInvoke    (ProfileInvoke* x) {}\n+void Canonicalizer::do_ProfileACmpTypes (ProfileACmpTypes* x) {}\n+void Canonicalizer::do_RuntimeCall      (RuntimeCall* x) {}\n","filename":"src\/hotspot\/share\/c1\/c1_Canonicalizer.cpp","additions":9,"deletions":7,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -33,0 +33,2 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -218,0 +220,2 @@\n+  assert(!_gen->in_conditional_code(), \"LIRItem cannot be loaded in conditional code\");\n+\n@@ -625,1 +629,2 @@\n-void LIRGenerator::monitor_enter(LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr scratch, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info) {\n+void LIRGenerator::monitor_enter(LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr scratch, int monitor_no,\n+                                 CodeEmitInfo* info_for_exception, CodeEmitInfo* info, CodeStub* throw_ie_stub) {\n@@ -628,1 +633,1 @@\n-  CodeStub* slow_path = new MonitorEnterStub(object, lock, info);\n+  CodeStub* slow_path = new MonitorEnterStub(object, lock, info, throw_ie_stub, scratch);\n@@ -631,1 +636,1 @@\n-  __ lock_object(hdr, object, lock, scratch, slow_path, info_for_exception);\n+  __ lock_object(hdr, object, lock, scratch, slow_path, info_for_exception, throw_ie_stub);\n@@ -655,4 +660,9 @@\n-void LIRGenerator::new_instance(LIR_Opr dst, ciInstanceKlass* klass, bool is_unresolved, LIR_Opr scratch1, LIR_Opr scratch2, LIR_Opr scratch3, LIR_Opr scratch4, LIR_Opr klass_reg, CodeEmitInfo* info) {\n-  klass2reg_with_patching(klass_reg, klass, info, is_unresolved);\n-  \/\/ If klass is not loaded we do not know if the klass has finalizers:\n-  if (UseFastNewInstance && klass->is_loaded()\n+void LIRGenerator::new_instance(LIR_Opr dst, ciInstanceKlass* klass, bool is_unresolved, bool allow_inline, LIR_Opr scratch1, LIR_Opr scratch2, LIR_Opr scratch3, LIR_Opr scratch4, LIR_Opr klass_reg, CodeEmitInfo* info) {\n+  if (allow_inline) {\n+    assert(!is_unresolved && klass->is_loaded(), \"inline type klass should be resolved\");\n+    __ metadata2reg(klass->constant_encoding(), klass_reg);\n+  } else {\n+    klass2reg_with_patching(klass_reg, klass, info, is_unresolved);\n+  }\n+  \/\/ If klass is not loaded we do not know if the klass has finalizers or is an unexpected inline klass\n+  if (UseFastNewInstance && klass->is_loaded() && (allow_inline || !klass->is_inlinetype())\n@@ -673,1 +683,1 @@\n-    __ branch(lir_cond_always, slow_path);\n+    __ jump(slow_path);\n@@ -773,0 +783,10 @@\n+  if (!src->is_loaded_flat_array() && !dst->is_loaded_flat_array()) {\n+    flags &= ~LIR_OpArrayCopy::always_slow_path;\n+  }\n+  if (!src->maybe_flat_array()) {\n+    flags &= ~LIR_OpArrayCopy::src_inlinetype_check;\n+  }\n+  if (!dst->maybe_flat_array() && !dst->maybe_null_free_array()) {\n+    flags &= ~LIR_OpArrayCopy::dst_inlinetype_check;\n+  }\n+\n@@ -1511,2 +1531,4 @@\n-  _constants.append(c);\n-  _reg_for_constants.append(result);\n+  if (!in_conditional_code()) {\n+    _constants.append(c);\n+    _reg_for_constants.append(result);\n+  }\n@@ -1516,0 +1538,6 @@\n+void LIRGenerator::set_in_conditional_code(bool v) {\n+  assert(v != _in_conditional_code, \"must change state\");\n+  _in_conditional_code = v;\n+}\n+\n+\n@@ -1533,0 +1561,8 @@\n+\/\/ Returns a int\/long value with the null marker bit set\n+static LIR_Opr null_marker_mask(BasicType bt, ciField* field) {\n+  assert(field->null_marker_offset() != -1, \"field does not have null marker\");\n+  int nm_offset = field->null_marker_offset() - field->offset_in_bytes();\n+  jlong null_marker = 1ULL << (nm_offset << LogBitsPerByte);\n+  return (bt == T_LONG) ? LIR_OprFact::longConst(null_marker) : LIR_OprFact::intConst(null_marker);\n+}\n+\n@@ -1562,0 +1598,1 @@\n+  ciField* field = x->field();\n@@ -1563,1 +1600,1 @@\n-  bool is_volatile = x->field()->is_volatile();\n+  bool is_volatile = field->is_volatile();\n@@ -1584,10 +1621,2 @@\n-  if (is_volatile || needs_patching) {\n-    \/\/ load item if field is volatile (fewer special cases for volatiles)\n-    \/\/ load item if field not initialized\n-    \/\/ load item if field not constant\n-    \/\/ because of code patching we cannot inline constants\n-    if (field_type == T_BYTE || field_type == T_BOOLEAN) {\n-      value.load_byte_item();\n-    } else  {\n-      value.load_item();\n-    }\n+  if (field->is_flat()) {\n+    value.load_item();\n@@ -1595,1 +1624,13 @@\n-    value.load_for_store(field_type);\n+    if (is_volatile || needs_patching) {\n+      \/\/ load item if field is volatile (fewer special cases for volatiles)\n+      \/\/ load item if field not initialized\n+      \/\/ load item if field not constant\n+      \/\/ because of code patching we cannot inline constants\n+      if (field_type == T_BYTE || field_type == T_BOOLEAN) {\n+        value.load_byte_item();\n+      } else  {\n+        value.load_item();\n+      }\n+    } else {\n+      value.load_for_store(field_type);\n+    }\n@@ -1624,0 +1665,43 @@\n+  if (field->is_flat()) {\n+    ciInlineKlass* vk = field->type()->as_inline_klass();\n+\n+#ifdef ASSERT\n+    bool is_naturally_atomic = vk->nof_declared_nonstatic_fields() <= 1;\n+    bool needs_atomic_access = !field->is_null_free() || (field->is_volatile() && !is_naturally_atomic);\n+    assert(needs_atomic_access, \"No atomic access required\");\n+    \/\/ ZGC does not support compressed oops, so only one oop can be in the payload which is written by a \"normal\" oop store.\n+    assert(!vk->contains_oops() || !UseZGC, \"ZGC does not support embedded oops in flat fields\");\n+#endif\n+\n+    \/\/ Zero the payload\n+    BasicType bt = vk->payload_size_to_basic_type();\n+    LIR_Opr payload = new_register((bt == T_LONG) ? bt : T_INT);\n+    LIR_Opr zero = (bt == T_LONG) ? LIR_OprFact::longConst(0) : LIR_OprFact::intConst(0);\n+    __ move(zero, payload);\n+\n+    bool is_constant_null = value.is_constant() && value.value()->is_null_obj();\n+    if (!is_constant_null) {\n+      LabelObj* L_isNull = new LabelObj();\n+      bool needs_null_check = !value.is_constant() || value.value()->is_null_obj();\n+      if (needs_null_check) {\n+        __ cmp(lir_cond_equal, value.result(), LIR_OprFact::oopConst(nullptr));\n+        __ branch(lir_cond_equal, L_isNull->label());\n+      }\n+      \/\/ Load payload (if not empty) and set null marker (if not null-free)\n+      if (!vk->is_empty()) {\n+        access_load_at(decorators, bt, value, LIR_OprFact::intConst(vk->payload_offset()), payload);\n+      }\n+      if (!field->is_null_free()) {\n+        __ logical_or(payload, null_marker_mask(bt, field), payload);\n+      }\n+      if (needs_null_check) {\n+        __ branch_destination(L_isNull->label());\n+      }\n+    }\n+    access_store_at(decorators, bt, object, LIR_OprFact::intConst(x->offset()), payload,\n+                    \/\/ Make sure to emit an implicit null check and pass the information\n+                    \/\/ that this is a flat store that might require gc barriers for oop fields.\n+                    info != nullptr ? new CodeEmitInfo(info) : nullptr, info, vk);\n+    return;\n+  }\n+\n@@ -1628,0 +1712,173 @@\n+\/\/ FIXME -- I can't find any other way to pass an address to access_load_at().\n+class TempResolvedAddress: public Instruction {\n+ public:\n+  TempResolvedAddress(ValueType* type, LIR_Opr addr) : Instruction(type) {\n+    set_operand(addr);\n+  }\n+  virtual void input_values_do(ValueVisitor*) {}\n+  virtual void visit(InstructionVisitor* v)   {}\n+  virtual const char* name() const  { return \"TempResolvedAddress\"; }\n+};\n+\n+LIR_Opr LIRGenerator::get_and_load_element_address(LIRItem& array, LIRItem& index) {\n+  ciType* array_type = array.value()->declared_type();\n+  ciFlatArrayKlass* flat_array_klass = array_type->as_flat_array_klass();\n+  assert(flat_array_klass->is_loaded(), \"must be\");\n+\n+  int array_header_size = flat_array_klass->array_header_in_bytes();\n+  int shift = flat_array_klass->log2_element_size();\n+\n+#ifndef _LP64\n+  LIR_Opr index_op = new_register(T_INT);\n+  \/\/ FIXME -- on 32-bit, the shift below can overflow, so we need to check that\n+  \/\/ the top (shift+1) bits of index_op must be zero, or\n+  \/\/ else throw ArrayIndexOutOfBoundsException\n+  if (index.result()->is_constant()) {\n+    jint const_index = index.result()->as_jint();\n+    __ move(LIR_OprFact::intConst(const_index << shift), index_op);\n+  } else {\n+    __ shift_left(index_op, shift, index.result());\n+  }\n+#else\n+  LIR_Opr index_op = new_register(T_LONG);\n+  if (index.result()->is_constant()) {\n+    jint const_index = index.result()->as_jint();\n+    __ move(LIR_OprFact::longConst(const_index << shift), index_op);\n+  } else {\n+    __ convert(Bytecodes::_i2l, index.result(), index_op);\n+    \/\/ Need to shift manually, as LIR_Address can scale only up to 3.\n+    __ shift_left(index_op, shift, index_op);\n+  }\n+#endif\n+\n+  LIR_Opr elm_op = new_pointer_register();\n+  LIR_Address* elm_address = generate_address(array.result(), index_op, 0, array_header_size, T_ADDRESS);\n+  __ leal(LIR_OprFact::address(elm_address), elm_op);\n+  return elm_op;\n+}\n+\n+void LIRGenerator::access_sub_element(LIRItem& array, LIRItem& index, LIR_Opr& result, ciField* field, int sub_offset) {\n+  assert(field != nullptr, \"Need a subelement type specified\");\n+\n+  \/\/ Find the starting address of the source (inside the array)\n+  LIR_Opr elm_op = get_and_load_element_address(array, index);\n+\n+  BasicType subelt_type = field->type()->basic_type();\n+  TempResolvedAddress* elm_resolved_addr = new TempResolvedAddress(as_ValueType(subelt_type), elm_op);\n+  LIRItem elm_item(elm_resolved_addr, this);\n+\n+  DecoratorSet decorators = IN_HEAP;\n+  access_load_at(decorators, subelt_type,\n+                     elm_item, LIR_OprFact::intConst(sub_offset), result,\n+                     nullptr, nullptr);\n+\n+  if (field->is_null_free()) {\n+    assert(field->type()->is_loaded(), \"Must be\");\n+    assert(field->type()->is_inlinetype(), \"Must be if loaded\");\n+    assert(field->type()->as_inline_klass()->is_initialized(), \"Must be\");\n+    LabelObj* L_end = new LabelObj();\n+    __ cmp(lir_cond_notEqual, result, LIR_OprFact::oopConst(nullptr));\n+    __ branch(lir_cond_notEqual, L_end->label());\n+    set_in_conditional_code(true);\n+    Constant* default_value = new Constant(new InstanceConstant(field->type()->as_inline_klass()->default_instance()));\n+    if (default_value->is_pinned()) {\n+      __ move(LIR_OprFact::value_type(default_value->type()), result);\n+    } else {\n+      __ move(load_constant(default_value), result);\n+    }\n+    __ branch_destination(L_end->label());\n+    set_in_conditional_code(false);\n+  }\n+}\n+\n+void LIRGenerator::access_flat_array(bool is_load, LIRItem& array, LIRItem& index, LIRItem& obj_item,\n+                                          ciField* field, int sub_offset) {\n+  assert(sub_offset == 0 || field != nullptr, \"Sanity check\");\n+\n+  \/\/ Find the starting address of the source (inside the array)\n+  LIR_Opr elm_op = get_and_load_element_address(array, index);\n+\n+  ciInlineKlass* elem_klass = nullptr;\n+  if (field != nullptr) {\n+    elem_klass = field->type()->as_inline_klass();\n+  } else {\n+    elem_klass = array.value()->declared_type()->as_flat_array_klass()->element_klass()->as_inline_klass();\n+  }\n+  for (int i = 0; i < elem_klass->nof_nonstatic_fields(); i++) {\n+    ciField* inner_field = elem_klass->nonstatic_field_at(i);\n+    assert(!inner_field->is_flat(), \"flat fields must have been expanded\");\n+    int obj_offset = inner_field->offset_in_bytes();\n+    int elm_offset = obj_offset - elem_klass->payload_offset() + sub_offset; \/\/ object header is not stored in array.\n+    BasicType field_type = inner_field->type()->basic_type();\n+\n+    \/\/ Types which are smaller than int are still passed in an int register.\n+    BasicType reg_type = field_type;\n+    switch (reg_type) {\n+    case T_BYTE:\n+    case T_BOOLEAN:\n+    case T_SHORT:\n+    case T_CHAR:\n+      reg_type = T_INT;\n+      break;\n+    default:\n+      break;\n+    }\n+\n+    LIR_Opr temp = new_register(reg_type);\n+    TempResolvedAddress* elm_resolved_addr = new TempResolvedAddress(as_ValueType(field_type), elm_op);\n+    LIRItem elm_item(elm_resolved_addr, this);\n+\n+    DecoratorSet decorators = IN_HEAP;\n+    if (is_load) {\n+      access_load_at(decorators, field_type,\n+                     elm_item, LIR_OprFact::intConst(elm_offset), temp,\n+                     nullptr, nullptr);\n+      access_store_at(decorators, field_type,\n+                      obj_item, LIR_OprFact::intConst(obj_offset), temp,\n+                      nullptr, nullptr);\n+    } else {\n+      access_load_at(decorators, field_type,\n+                     obj_item, LIR_OprFact::intConst(obj_offset), temp,\n+                     nullptr, nullptr);\n+      access_store_at(decorators, field_type,\n+                      elm_item, LIR_OprFact::intConst(elm_offset), temp,\n+                      nullptr, nullptr);\n+    }\n+  }\n+}\n+\n+void LIRGenerator::check_flat_array(LIR_Opr array, LIR_Opr value, CodeStub* slow_path) {\n+  LIR_Opr tmp = new_register(T_METADATA);\n+  __ check_flat_array(array, value, tmp, slow_path);\n+}\n+\n+void LIRGenerator::check_null_free_array(LIRItem& array, LIRItem& value, CodeEmitInfo* info) {\n+  LabelObj* L_end = new LabelObj();\n+  LIR_Opr tmp = new_register(T_METADATA);\n+  __ check_null_free_array(array.result(), tmp);\n+  __ branch(lir_cond_equal, L_end->label());\n+  __ null_check(value.result(), info);\n+  __ branch_destination(L_end->label());\n+}\n+\n+bool LIRGenerator::needs_flat_array_store_check(StoreIndexed* x) {\n+  if (x->elt_type() == T_OBJECT && x->array()->maybe_flat_array()) {\n+    ciType* type = x->value()->declared_type();\n+    if (type != nullptr && type->is_klass()) {\n+      ciKlass* klass = type->as_klass();\n+      if (!klass->can_be_inline_klass() || (klass->is_inlinetype() && !klass->as_inline_klass()->flat_in_array())) {\n+        \/\/ This is known to be a non-flat object. If the array is a flat array,\n+        \/\/ it will be caught by the code generated by array_store_check().\n+        return false;\n+      }\n+    }\n+    \/\/ We're not 100% sure, so let's do the flat_array_store_check.\n+    return true;\n+  }\n+  return false;\n+}\n+\n+bool LIRGenerator::needs_null_free_array_store_check(StoreIndexed* x) {\n+  return x->elt_type() == T_OBJECT && x->array()->maybe_null_free_array();\n+}\n+\n@@ -1630,0 +1887,2 @@\n+  assert(x->elt_type() != T_ARRAY, \"never used\");\n+  bool is_loaded_flat_array = x->array()->is_loaded_flat_array();\n@@ -1633,3 +1892,3 @@\n-  bool needs_store_check = obj_store && (x->value()->as_Constant() == nullptr ||\n-                                         !get_jobject_constant(x->value())->is_null_object() ||\n-                                         x->should_profile());\n+  bool needs_store_check = obj_store && !(is_loaded_flat_array && x->is_exact_flat_array_store()) &&\n+                                        (x->value()->as_Constant() == nullptr ||\n+                                         !get_jobject_constant(x->value())->is_null_object());\n@@ -1648,2 +1907,3 @@\n-\n-  if (needs_store_check || x->check_boolean()) {\n+\n+  if (needs_store_check || x->check_boolean()\n+      || is_loaded_flat_array || needs_flat_array_store_check(x) || needs_null_free_array_store_check(x)) {\n@@ -1678,0 +1938,20 @@\n+  if (x->should_profile()) {\n+    if (x->array()->is_loaded_flat_array()) {\n+      \/\/ No need to profile a store to a flat array of known type. This can happen if\n+      \/\/ the type only became known after optimizations (for example, after the PhiSimplifier).\n+      x->set_should_profile(false);\n+    } else {\n+      int bci = x->profiled_bci();\n+      ciMethodData* md = x->profiled_method()->method_data();\n+      assert(md != nullptr, \"Sanity\");\n+      ciProfileData* data = md->bci_to_data(bci);\n+      assert(data != nullptr && data->is_ArrayStoreData(), \"incorrect profiling entry\");\n+      ciArrayStoreData* store_data = (ciArrayStoreData*)data;\n+      profile_array_type(x, md, store_data);\n+      assert(store_data->is_ArrayStoreData(), \"incorrect profiling entry\");\n+      if (x->array()->maybe_null_free_array()) {\n+        profile_null_free_array(array, md, store_data);\n+      }\n+    }\n+  }\n+\n@@ -1683,4 +1963,26 @@\n-  DecoratorSet decorators = IN_HEAP | IS_ARRAY;\n-  if (x->check_boolean()) {\n-    decorators |= C1_MASK_BOOLEAN;\n-  }\n+  if (is_loaded_flat_array) {\n+    if (!x->value()->is_null_free()) {\n+      __ null_check(value.result(), new CodeEmitInfo(range_check_info));\n+    }\n+    \/\/ If array element is an empty inline type, no need to copy anything\n+    if (!x->array()->declared_type()->as_flat_array_klass()->element_klass()->as_inline_klass()->is_empty()) {\n+      access_flat_array(false, array, index, value);\n+    }\n+  } else {\n+    StoreFlattenedArrayStub* slow_path = nullptr;\n+\n+    if (needs_flat_array_store_check(x)) {\n+      \/\/ Check if we indeed have a flat array\n+      index.load_item();\n+      slow_path = new StoreFlattenedArrayStub(array.result(), index.result(), value.result(), state_for(x, x->state_before()));\n+      check_flat_array(array.result(), value.result(), slow_path);\n+      set_in_conditional_code(true);\n+    } else if (needs_null_free_array_store_check(x)) {\n+      CodeEmitInfo* info = new CodeEmitInfo(range_check_info);\n+      check_null_free_array(array, value, info);\n+    }\n+\n+    DecoratorSet decorators = IN_HEAP | IS_ARRAY;\n+    if (x->check_boolean()) {\n+      decorators |= C1_MASK_BOOLEAN;\n+    }\n@@ -1688,2 +1990,7 @@\n-  access_store_at(decorators, x->elt_type(), array, index.result(), value.result(),\n-                  nullptr, null_check_info);\n+    access_store_at(decorators, x->elt_type(), array, index.result(), value.result(),\n+                    nullptr, null_check_info);\n+    if (slow_path != nullptr) {\n+      __ branch_destination(slow_path->continuation());\n+      set_in_conditional_code(false);\n+    }\n+  }\n@@ -1718,1 +2025,2 @@\n-                                   CodeEmitInfo* patch_info, CodeEmitInfo* store_emit_info) {\n+                                   CodeEmitInfo* patch_info, CodeEmitInfo* store_emit_info,\n+                                   ciInlineKlass* vk) {\n@@ -1720,1 +2028,1 @@\n-  LIRAccess access(this, decorators, base, offset, type, patch_info, store_emit_info);\n+  LIRAccess access(this, decorators, base, offset, type, patch_info, store_emit_info, vk);\n@@ -1771,0 +2079,1 @@\n+  ciField* field = x->field();\n@@ -1772,1 +2081,1 @@\n-  bool is_volatile = x->field()->is_volatile();\n+  bool is_volatile = field->is_volatile();\n@@ -1823,0 +2132,37 @@\n+  if (field->is_flat()) {\n+    ciInlineKlass* vk = field->type()->as_inline_klass();\n+#ifdef ASSERT\n+    bool is_naturally_atomic = vk->nof_declared_nonstatic_fields() <= 1;\n+    bool needs_atomic_access = !field->is_null_free() || (field->is_volatile() && !is_naturally_atomic);\n+    assert(needs_atomic_access, \"No atomic access required\");\n+    assert(x->state_before() != nullptr, \"Needs state before\");\n+#endif\n+\n+    \/\/ Allocate buffer (we can't easily do this conditionally on the null check below\n+    \/\/ because branches added in the LIR are opaque to the register allocator).\n+    NewInstance* buffer = new NewInstance(vk, x->state_before(), false, true);\n+    do_NewInstance(buffer);\n+    LIRItem dest(buffer, this);\n+\n+    \/\/ Copy the payload to the buffer\n+    BasicType bt = vk->payload_size_to_basic_type();\n+    LIR_Opr payload = new_register((bt == T_LONG) ? bt : T_INT);\n+    access_load_at(decorators, bt, object, LIR_OprFact::intConst(field->offset_in_bytes()), payload,\n+                   \/\/ Make sure to emit an implicit null check\n+                   info ? new CodeEmitInfo(info) : nullptr, info);\n+    access_store_at(decorators, bt, dest, LIR_OprFact::intConst(vk->payload_offset()), payload);\n+\n+    if (field->is_null_free()) {\n+      set_result(x, buffer->operand());\n+    } else {\n+      \/\/ Check the null marker and set result to null if it's not set\n+      __ logical_and(payload, null_marker_mask(bt, field), payload);\n+      __ cmp(lir_cond_equal, payload, (bt == T_LONG) ? LIR_OprFact::longConst(0) : LIR_OprFact::intConst(0));\n+      __ cmove(lir_cond_equal, LIR_OprFact::oopConst(nullptr), buffer->operand(), rlock_result(x), T_OBJECT);\n+    }\n+\n+    \/\/ Ensure the copy is visible before any subsequent store that publishes the buffer.\n+    __ membar_storestore();\n+    return;\n+  }\n+\n@@ -1827,0 +2173,33 @@\n+\n+  if (field->is_null_free()) {\n+    \/\/ Load from non-flat inline type field requires\n+    \/\/ a null check to replace null with the default value.\n+    ciInstanceKlass* holder = field->holder();\n+    if (field->is_static() && holder->is_loaded()) {\n+      ciObject* val = holder->java_mirror()->field_value(field).as_object();\n+      if (!val->is_null_object()) {\n+        \/\/ Static field is initialized, we don't need to perform a null check.\n+        return;\n+      }\n+    }\n+    ciInlineKlass* inline_klass = field->type()->as_inline_klass();\n+    if (inline_klass->is_initialized()) {\n+      LabelObj* L_end = new LabelObj();\n+      __ cmp(lir_cond_notEqual, result, LIR_OprFact::oopConst(nullptr));\n+      __ branch(lir_cond_notEqual, L_end->label());\n+      set_in_conditional_code(true);\n+      Constant* default_value = new Constant(new InstanceConstant(inline_klass->default_instance()));\n+      if (default_value->is_pinned()) {\n+        __ move(LIR_OprFact::value_type(default_value->type()), result);\n+      } else {\n+        __ move(load_constant(default_value), result);\n+      }\n+      __ branch_destination(L_end->label());\n+      set_in_conditional_code(false);\n+    } else {\n+      info = state_for(x, x->state_before());\n+      __ cmp(lir_cond_equal, result, LIR_OprFact::oopConst(nullptr));\n+      __ branch(lir_cond_equal, new DeoptimizeStub(info, Deoptimization::Reason_uninitialized,\n+                                                         Deoptimization::Action_make_not_entrant));\n+    }\n+  }\n@@ -1971,1 +2350,66 @@\n-  DecoratorSet decorators = IN_HEAP | IS_ARRAY;\n+  ciMethodData* md = nullptr;\n+  ciArrayLoadData* load_data = nullptr;\n+  if (x->should_profile()) {\n+    if (x->array()->is_loaded_flat_array()) {\n+      \/\/ No need to profile a load from a flat array of known type. This can happen if\n+      \/\/ the type only became known after optimizations (for example, after the PhiSimplifier).\n+      x->set_should_profile(false);\n+    } else {\n+      int bci = x->profiled_bci();\n+      md = x->profiled_method()->method_data();\n+      assert(md != nullptr, \"Sanity\");\n+      ciProfileData* data = md->bci_to_data(bci);\n+      assert(data != nullptr && data->is_ArrayLoadData(), \"incorrect profiling entry\");\n+      load_data = (ciArrayLoadData*)data;\n+      profile_array_type(x, md, load_data);\n+    }\n+  }\n+\n+  Value element;\n+  if (x->vt() != nullptr) {\n+    assert(x->array()->is_loaded_flat_array(), \"must be\");\n+    \/\/ Find the destination address (of the NewInlineTypeInstance).\n+    LIRItem obj_item(x->vt(), this);\n+\n+    access_flat_array(true, array, index, obj_item,\n+                      x->delayed() == nullptr ? 0 : x->delayed()->field(),\n+                      x->delayed() == nullptr ? 0 : x->delayed()->offset());\n+    set_no_result(x);\n+  } else if (x->delayed() != nullptr) {\n+    assert(x->array()->is_loaded_flat_array(), \"must be\");\n+    LIR_Opr result = rlock_result(x, x->delayed()->field()->type()->basic_type());\n+    access_sub_element(array, index, result, x->delayed()->field(), x->delayed()->offset());\n+  } else if (x->array() != nullptr && x->array()->is_loaded_flat_array() &&\n+             x->array()->declared_type()->as_flat_array_klass()->element_klass()->as_inline_klass()->is_initialized() &&\n+             x->array()->declared_type()->as_flat_array_klass()->element_klass()->as_inline_klass()->is_empty()) {\n+    \/\/ Load the default instance instead of reading the element\n+    ciInlineKlass* elem_klass = x->array()->declared_type()->as_flat_array_klass()->element_klass()->as_inline_klass();\n+    LIR_Opr result = rlock_result(x, x->elt_type());\n+    assert(elem_klass->is_initialized(), \"Must be\");\n+    Constant* default_value = new Constant(new InstanceConstant(elem_klass->default_instance()));\n+    if (default_value->is_pinned()) {\n+      __ move(LIR_OprFact::value_type(default_value->type()), result);\n+    } else {\n+      __ move(load_constant(default_value), result);\n+    }\n+  } else {\n+    LIR_Opr result = rlock_result(x, x->elt_type());\n+    LoadFlattenedArrayStub* slow_path = nullptr;\n+\n+    if (x->should_profile() && x->array()->maybe_null_free_array()) {\n+      profile_null_free_array(array, md, load_data);\n+    }\n+\n+    if (x->elt_type() == T_OBJECT && x->array()->maybe_flat_array()) {\n+      assert(x->delayed() == nullptr, \"Delayed LoadIndexed only apply to loaded_flat_arrays\");\n+      index.load_item();\n+      \/\/ if we are loading from a flat array, load it using a runtime call\n+      slow_path = new LoadFlattenedArrayStub(array.result(), index.result(), result, state_for(x, x->state_before()));\n+      check_flat_array(array.result(), LIR_OprFact::illegalOpr, slow_path);\n+      set_in_conditional_code(true);\n+    }\n+\n+    DecoratorSet decorators = IN_HEAP | IS_ARRAY;\n+    access_load_at(decorators, x->elt_type(),\n+                   array, index.result(), result,\n+                   nullptr, null_check_info);\n@@ -1973,4 +2417,11 @@\n-  LIR_Opr result = rlock_result(x, x->elt_type());\n-  access_load_at(decorators, x->elt_type(),\n-                 array, index.result(), result,\n-                 nullptr, null_check_info);\n+    if (slow_path != nullptr) {\n+      __ branch_destination(slow_path->continuation());\n+      set_in_conditional_code(false);\n+    }\n+\n+    element = x;\n+  }\n+\n+  if (x->should_profile()) {\n+    profile_element_type(element, md, load_data);\n+  }\n@@ -2478,1 +2929,1 @@\n-  if (do_update) {\n+  if (do_update && signature_at_call_k != nullptr) {\n@@ -2563,0 +3014,40 @@\n+void LIRGenerator::profile_flags(ciMethodData* md, ciProfileData* data, int flag, LIR_Condition condition) {\n+  assert(md != nullptr && data != nullptr, \"should have been initialized\");\n+  LIR_Opr mdp = new_register(T_METADATA);\n+  __ metadata2reg(md->constant_encoding(), mdp);\n+  LIR_Address* addr = new LIR_Address(mdp, md->byte_offset_of_slot(data, DataLayout::flags_offset()), T_BYTE);\n+  LIR_Opr flags = new_register(T_INT);\n+  __ move(addr, flags);\n+  if (condition != lir_cond_always) {\n+    LIR_Opr update = new_register(T_INT);\n+    __ cmove(condition, LIR_OprFact::intConst(0), LIR_OprFact::intConst(flag), update, T_INT);\n+  } else {\n+    __ logical_or(flags, LIR_OprFact::intConst(flag), flags);\n+  }\n+  __ store(flags, addr);\n+}\n+\n+template <class ArrayData> void LIRGenerator::profile_null_free_array(LIRItem array, ciMethodData* md, ArrayData* load_store) {\n+  assert(compilation()->profile_array_accesses(), \"array access profiling is disabled\");\n+  LabelObj* L_end = new LabelObj();\n+  LIR_Opr tmp = new_register(T_METADATA);\n+  __ check_null_free_array(array.result(), tmp);\n+\n+  profile_flags(md, load_store, ArrayStoreData::null_free_array_byte_constant(), lir_cond_equal);\n+}\n+\n+template <class ArrayData> void LIRGenerator::profile_array_type(AccessIndexed* x, ciMethodData*& md, ArrayData*& load_store) {\n+  assert(compilation()->profile_array_accesses(), \"array access profiling is disabled\");\n+  LIR_Opr mdp = LIR_OprFact::illegalOpr;\n+  profile_type(md, md->byte_offset_of_slot(load_store, ArrayData::array_offset()), 0,\n+               load_store->array()->type(), x->array(), mdp, true, nullptr, nullptr);\n+}\n+\n+void LIRGenerator::profile_element_type(Value element, ciMethodData* md, ciArrayLoadData* load_data) {\n+  assert(compilation()->profile_array_accesses(), \"array access profiling is disabled\");\n+  assert(md != nullptr && load_data != nullptr, \"should have been initialized\");\n+  LIR_Opr mdp = LIR_OprFact::illegalOpr;\n+  profile_type(md, md->byte_offset_of_slot(load_data, ArrayLoadData::element_offset()), 0,\n+               load_data->element()->type(), element, mdp, false, nullptr, nullptr);\n+}\n+\n@@ -2645,0 +3136,8 @@\n+  if (method()->has_scalarized_args()) {\n+    \/\/ Check if deoptimization was triggered (i.e. orig_pc was set) while buffering scalarized inline type arguments\n+    \/\/ in the entry point (see comments in frame::deoptimize). If so, deoptimize only now that we have the right state.\n+    CodeEmitInfo* info = new CodeEmitInfo(scope()->start()->state()->copy(ValueStack::StateBefore, 0), nullptr, false);\n+    CodeStub* deopt_stub = new DeoptimizeStub(info, Deoptimization::Reason_none, Deoptimization::Action_none);\n+    __ append(new LIR_Op0(lir_check_orig_pc));\n+    __ branch(lir_cond_notEqual, deopt_stub);\n+  }\n@@ -2660,0 +3159,13 @@\n+void LIRGenerator::invoke_load_one_argument(LIRItem* param, LIR_Opr loc) {\n+  if (loc->is_register()) {\n+    param->load_item_force(loc);\n+  } else {\n+    LIR_Address* addr = loc->as_address_ptr();\n+    param->load_for_store(addr->type());\n+    if (addr->type() == T_OBJECT) {\n+      __ move_wide(param->result(), addr);\n+    } else {\n+      __ move(param->result(), addr);\n+    }\n+  }\n+}\n@@ -2667,10 +3179,1 @@\n-    if (loc->is_register()) {\n-      param->load_item_force(loc);\n-    } else {\n-      LIR_Address* addr = loc->as_address_ptr();\n-      param->load_for_store(addr->type());\n-      if (addr->type() == T_OBJECT) {\n-        __ move_wide(param->result(), addr);\n-      } else\n-        __ move(param->result(), addr);\n-    }\n+    invoke_load_one_argument(param, loc);\n@@ -2842,1 +3345,1 @@\n-  if (can_inline_as_constant(right.value())) {\n+  if (can_inline_as_constant(right.value()) && !x->substitutability_check()) {\n@@ -2845,0 +3348,1 @@\n+    \/\/ substitutability_check() needs to use right as a base register.\n@@ -2852,3 +3356,60 @@\n-  LIR_Opr reg = rlock_result(x);\n-  __ cmp(lir_cond(x->cond()), left.result(), right.result());\n-  __ cmove(lir_cond(x->cond()), t_val.result(), f_val.result(), reg, as_BasicType(x->x()->type()));\n+  if (x->substitutability_check()) {\n+    substitutability_check(x, left, right, t_val, f_val);\n+  } else {\n+    LIR_Opr reg = rlock_result(x);\n+    __ cmp(lir_cond(x->cond()), left.result(), right.result());\n+    __ cmove(lir_cond(x->cond()), t_val.result(), f_val.result(), reg, as_BasicType(x->x()->type()));\n+  }\n+}\n+\n+void LIRGenerator::substitutability_check(IfOp* x, LIRItem& left, LIRItem& right, LIRItem& t_val, LIRItem& f_val) {\n+  assert(x->cond() == If::eql || x->cond() == If::neq, \"must be\");\n+  bool is_acmpeq = (x->cond() == If::eql);\n+  LIR_Opr equal_result     = is_acmpeq ? t_val.result() : f_val.result();\n+  LIR_Opr not_equal_result = is_acmpeq ? f_val.result() : t_val.result();\n+  LIR_Opr result = rlock_result(x);\n+  CodeEmitInfo* info = state_for(x, x->state_before());\n+\n+  substitutability_check_common(x->x(), x->y(), left, right, equal_result, not_equal_result, result, info);\n+}\n+\n+void LIRGenerator::substitutability_check(If* x, LIRItem& left, LIRItem& right) {\n+  LIR_Opr equal_result     = LIR_OprFact::intConst(1);\n+  LIR_Opr not_equal_result = LIR_OprFact::intConst(0);\n+  LIR_Opr result = new_register(T_INT);\n+  CodeEmitInfo* info = state_for(x, x->state_before());\n+\n+  substitutability_check_common(x->x(), x->y(), left, right, equal_result, not_equal_result, result, info);\n+\n+  assert(x->cond() == If::eql || x->cond() == If::neq, \"must be\");\n+  __ cmp(lir_cond(x->cond()), result, equal_result);\n+}\n+\n+void LIRGenerator::substitutability_check_common(Value left_val, Value right_val, LIRItem& left, LIRItem& right,\n+                                                 LIR_Opr equal_result, LIR_Opr not_equal_result, LIR_Opr result,\n+                                                 CodeEmitInfo* info) {\n+  LIR_Opr tmp1 = LIR_OprFact::illegalOpr;\n+  LIR_Opr tmp2 = LIR_OprFact::illegalOpr;\n+  LIR_Opr left_klass_op = LIR_OprFact::illegalOpr;\n+  LIR_Opr right_klass_op = LIR_OprFact::illegalOpr;\n+\n+  ciKlass* left_klass  = left_val ->as_loaded_klass_or_null();\n+  ciKlass* right_klass = right_val->as_loaded_klass_or_null();\n+\n+  if ((left_klass == nullptr || right_klass == nullptr) ||\/\/ The klass is still unloaded, or came from a Phi node.\n+      !left_klass->is_inlinetype() || !right_klass->is_inlinetype()) {\n+    init_temps_for_substitutability_check(tmp1, tmp2);\n+  }\n+\n+  if (left_klass != nullptr && left_klass->is_inlinetype() && left_klass == right_klass) {\n+    \/\/ No need to load klass -- the operands are statically known to be the same inline klass.\n+  } else {\n+    BasicType t_klass = UseCompressedOops ? T_INT : T_METADATA;\n+    left_klass_op = new_register(t_klass);\n+    right_klass_op = new_register(t_klass);\n+  }\n+\n+  CodeStub* slow_path = new SubstitutabilityCheckStub(left.result(), right.result(), info);\n+  __ substitutability_check(result, left.result(), right.result(), equal_result, not_equal_result,\n+                            tmp1, tmp2,\n+                            left_klass, right_klass, left_klass_op, right_klass_op, info, slow_path);\n@@ -3128,1 +3689,1 @@\n-    ciReturnTypeEntry* ret = data->is_CallTypeData() ? ((ciCallTypeData*)data)->ret() : ((ciVirtualCallTypeData*)data)->ret();\n+    ciSingleTypeEntry* ret = data->is_CallTypeData() ? ((ciCallTypeData*)data)->ret() : ((ciVirtualCallTypeData*)data)->ret();\n@@ -3149,0 +3710,47 @@\n+bool LIRGenerator::profile_inline_klass(ciMethodData* md, ciProfileData* data, Value value, int flag) {\n+  ciKlass* klass = value->as_loaded_klass_or_null();\n+  if (klass != nullptr) {\n+    if (klass->is_inlinetype()) {\n+      profile_flags(md, data, flag, lir_cond_always);\n+    } else if (klass->can_be_inline_klass()) {\n+      return false;\n+    }\n+  } else {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+\n+void LIRGenerator::do_ProfileACmpTypes(ProfileACmpTypes* x) {\n+  ciMethod* method = x->method();\n+  assert(method != nullptr, \"method should be set if branch is profiled\");\n+  ciMethodData* md = method->method_data_or_null();\n+  assert(md != nullptr, \"Sanity\");\n+  ciProfileData* data = md->bci_to_data(x->bci());\n+  assert(data != nullptr, \"must have profiling data\");\n+  assert(data->is_ACmpData(), \"need BranchData for two-way branches\");\n+  ciACmpData* acmp = (ciACmpData*)data;\n+  LIR_Opr mdp = LIR_OprFact::illegalOpr;\n+  profile_type(md, md->byte_offset_of_slot(acmp, ACmpData::left_offset()), 0,\n+               acmp->left()->type(), x->left(), mdp, !x->left_maybe_null(), nullptr, nullptr);\n+  int flags_offset = md->byte_offset_of_slot(data, DataLayout::flags_offset());\n+  if (!profile_inline_klass(md, acmp, x->left(), ACmpData::left_inline_type_byte_constant())) {\n+    LIR_Opr mdp = new_register(T_METADATA);\n+    __ metadata2reg(md->constant_encoding(), mdp);\n+    LIRItem value(x->left(), this);\n+    value.load_item();\n+    __ profile_inline_type(new LIR_Address(mdp, flags_offset, T_INT), value.result(), ACmpData::left_inline_type_byte_constant(), new_register(T_INT), !x->left_maybe_null());\n+  }\n+  profile_type(md, md->byte_offset_of_slot(acmp, ACmpData::left_offset()),\n+               in_bytes(ACmpData::right_offset()) - in_bytes(ACmpData::left_offset()),\n+               acmp->right()->type(), x->right(), mdp, !x->right_maybe_null(), nullptr, nullptr);\n+  if (!profile_inline_klass(md, acmp, x->right(), ACmpData::right_inline_type_byte_constant())) {\n+    LIR_Opr mdp = new_register(T_METADATA);\n+    __ metadata2reg(md->constant_encoding(), mdp);\n+    LIRItem value(x->right(), this);\n+    value.load_item();\n+    __ profile_inline_type(new LIR_Address(mdp, flags_offset, T_INT), value.result(), ACmpData::right_inline_type_byte_constant(), new_register(T_INT), !x->left_maybe_null());\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":665,"deletions":57,"binary":false,"changes":722,"status":"modified"},{"patch":"@@ -172,0 +172,1 @@\n+  bool          _in_conditional_code;\n@@ -198,0 +199,1 @@\n+  void set_in_conditional_code(bool v);\n@@ -217,0 +219,1 @@\n+  bool in_conditional_code() { return _in_conditional_code; }\n@@ -276,0 +279,13 @@\n+  void access_flat_array(bool is_load, LIRItem& array, LIRItem& index, LIRItem& obj_item, ciField* field = nullptr, int offset = 0);\n+  void access_sub_element(LIRItem& array, LIRItem& index, LIR_Opr& result, ciField* field, int sub_offset);\n+  LIR_Opr get_and_load_element_address(LIRItem& array, LIRItem& index);\n+  bool needs_flat_array_store_check(StoreIndexed* x);\n+  void check_flat_array(LIR_Opr array, LIR_Opr value, CodeStub* slow_path);\n+  bool needs_null_free_array_store_check(StoreIndexed* x);\n+  void check_null_free_array(LIRItem& array, LIRItem& value,  CodeEmitInfo* info);\n+  void substitutability_check(IfOp* x, LIRItem& left, LIRItem& right, LIRItem& t_val, LIRItem& f_val);\n+  void substitutability_check(If* x, LIRItem& left, LIRItem& right);\n+  void substitutability_check_common(Value left_val, Value right_val, LIRItem& left, LIRItem& right,\n+                                     LIR_Opr equal_result, LIR_Opr not_equal_result, LIR_Opr result, CodeEmitInfo* info);\n+  void init_temps_for_substitutability_check(LIR_Opr& tmp1, LIR_Opr& tmp2);\n+\n@@ -292,1 +308,1 @@\n-                       CodeEmitInfo* patch_info = nullptr, CodeEmitInfo* store_emit_info = nullptr);\n+                       CodeEmitInfo* patch_info = nullptr, CodeEmitInfo* store_emit_info = nullptr, ciInlineKlass* vk = nullptr);\n@@ -329,1 +345,1 @@\n-\n+  void invoke_load_one_argument(LIRItem* param, LIR_Opr loc);\n@@ -365,1 +381,1 @@\n-  void monitor_enter (LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr scratch, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info);\n+  void monitor_enter (LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr scratch, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info, CodeStub* throw_ie_stub);\n@@ -368,1 +384,1 @@\n-  void new_instance    (LIR_Opr  dst, ciInstanceKlass* klass, bool is_unresolved, LIR_Opr  scratch1, LIR_Opr  scratch2, LIR_Opr  scratch3,  LIR_Opr scratch4, LIR_Opr  klass_reg, CodeEmitInfo* info);\n+  void new_instance(LIR_Opr dst, ciInstanceKlass* klass, bool is_unresolved, bool allow_inline, LIR_Opr scratch1, LIR_Opr scratch2, LIR_Opr scratch3, LIR_Opr scratch4, LIR_Opr klass_reg, CodeEmitInfo* info);\n@@ -480,0 +496,5 @@\n+  void profile_flags(ciMethodData* md, ciProfileData* load_store, int flag, LIR_Condition condition = lir_cond_always);\n+  template <class ArrayData> void profile_null_free_array(LIRItem array, ciMethodData* md, ArrayData* load_store);\n+  template <class ArrayData> void profile_array_type(AccessIndexed* x, ciMethodData*& md, ArrayData*& load_store);\n+  void profile_element_type(Value element, ciMethodData* md, ciArrayLoadData* load_store);\n+  bool profile_inline_klass(ciMethodData* md, ciProfileData* data, Value value, int flag);\n@@ -507,0 +528,1 @@\n+    , _in_conditional_code(false)\n@@ -589,0 +611,1 @@\n+  virtual void do_ProfileACmpTypes(ProfileACmpTypes* x);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.hpp","additions":27,"deletions":4,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"runtime\/globals.hpp\"\n@@ -55,0 +56,8 @@\n+bool CDSConfig::_module_patching_disables_cds = false;\n+bool CDSConfig::_java_base_module_patching_disables_cds = false;\n+\n+bool CDSConfig::is_valhalla_preview() {\n+  return Arguments::enable_preview() && EnableValhalla;\n+}\n+\n+\n@@ -108,0 +117,3 @@\n+    if (is_valhalla_preview()) {\n+      tmp.print_raw(\"_valhalla\");\n+    }\n@@ -291,2 +303,1 @@\n-    \"jdk.module.upgrade.path\",\n-    \"jdk.module.patch.0\"\n+    \"jdk.module.upgrade.path\"\n@@ -296,2 +307,1 @@\n-    \"--upgrade-module-path\",\n-    \"--patch-module\"\n+    \"--upgrade-module-path\"\n@@ -320,0 +330,6 @@\n+\n+  if (module_patching_disables_cds()) {\n+    vm_exit_during_initialization(\n+            \"Cannot use the following option when dumping the shared archive\", \"--patch-module\");\n+  }\n+\n@@ -348,0 +364,10 @@\n+\n+  if (module_patching_disables_cds()) {\n+    if (RequireSharedSpaces) {\n+      warning(\"CDS is disabled when the %s option is specified.\", \"--patch-module\");\n+    } else {\n+      log_info(cds)(\"CDS is disabled when the %s option is specified.\", \"--patch-module\");\n+    }\n+    return true;\n+  }\n+\n@@ -461,1 +487,1 @@\n-bool CDSConfig::check_vm_args_consistency(bool patch_mod_javabase, bool mode_flag_cmd_line) {\n+bool CDSConfig::check_vm_args_consistency(bool mode_flag_cmd_line) {\n@@ -526,1 +552,1 @@\n-  if (is_using_archive() && patch_mod_javabase) {\n+  if (is_using_archive() && java_base_module_patching_disables_cds() && module_patching_disables_cds()) {\n@@ -653,0 +679,4 @@\n+  if (is_valhalla_preview()) {\n+    \/\/ Not working yet -- e.g., HeapShared::oop_hash() needs to be implemented for value oops\n+    return false;\n+  }\n","filename":"src\/hotspot\/share\/cds\/cdsConfig.cpp","additions":36,"deletions":6,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -46,0 +46,3 @@\n+  static bool _module_patching_disables_cds;\n+  static bool _java_base_module_patching_disables_cds;\n+\n@@ -86,1 +89,6 @@\n-  static bool check_vm_args_consistency(bool patch_mod_javabase, bool mode_flag_cmd_line) NOT_CDS_RETURN_(true);\n+  static bool check_vm_args_consistency(bool mode_flag_cmd_line) NOT_CDS_RETURN_(true);\n+\n+  static bool module_patching_disables_cds() { return _module_patching_disables_cds; }\n+  static void set_module_patching_disables_cds() { _module_patching_disables_cds = true; }\n+  static bool java_base_module_patching_disables_cds() { return _java_base_module_patching_disables_cds; }\n+  static void set_java_base_module_patching_disables_cds() { _java_base_module_patching_disables_cds = true; }\n@@ -172,0 +180,2 @@\n+  static bool is_valhalla_preview();\n+\n","filename":"src\/hotspot\/share\/cds\/cdsConfig.hpp","additions":11,"deletions":1,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -547,1 +547,5 @@\n-  if (k->local_interfaces()->length() != _interfaces->length()) {\n+  const int actual_num_interfaces = k->local_interfaces()->length();\n+  const int specified_num_interfaces = _interfaces->length(); \/\/ specified in classlist\n+  int expected_num_interfaces = actual_num_interfaces;\n+\n+  if (specified_num_interfaces != expected_num_interfaces) {\n@@ -551,1 +555,1 @@\n-          _interfaces->length(), k->local_interfaces()->length());\n+          specified_num_interfaces, expected_num_interfaces);\n","filename":"src\/hotspot\/share\/cds\/classListParser.cpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -31,0 +31,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/inlineKlass.hpp\"\n@@ -32,0 +34,1 @@\n+#include \"oops\/instanceKlass.inline.hpp\"\n@@ -55,0 +58,1 @@\n+\/\/ NOTE: this table must be in-sync with sun.jvm.hotspot.memory.FileMapInfo::populateMetadataTypeArray().\n@@ -64,1 +68,3 @@\n-  f(TypeArrayKlass)\n+  f(TypeArrayKlass) \\\n+  f(FlatArrayKlass) \\\n+  f(InlineKlass)\n","filename":"src\/hotspot\/share\/cds\/cppVtables.cpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -88,0 +88,65 @@\n+inline void CDSMustMatchFlags::do_print(outputStream* st, bool v) {\n+  st->print(\"%s\", v ? \"true\" : \"false\");\n+}\n+\n+inline void CDSMustMatchFlags::do_print(outputStream* st, intx v) {\n+  st->print(\"%zd\", v);\n+}\n+\n+inline void CDSMustMatchFlags::do_print(outputStream* st, uintx v) {\n+  st->print(\"%zu\", v);\n+}\n+\n+inline void CDSMustMatchFlags::do_print(outputStream* st, double v) {\n+  st->print(\"%f\", v);\n+}\n+\n+void CDSMustMatchFlags::init() {\n+  assert(CDSConfig::is_dumping_archive(), \"sanity\");\n+  _max_name_width = 0;\n+\n+#define INIT_CDS_MUST_MATCH_FLAG(n) \\\n+  _v_##n = n; \\\n+  _max_name_width = MAX2(_max_name_width,strlen(#n));\n+  CDS_MUST_MATCH_FLAGS_DO(INIT_CDS_MUST_MATCH_FLAG);\n+#undef INIT_CDS_MUST_MATCH_FLAG\n+}\n+\n+bool CDSMustMatchFlags::runtime_check() const {\n+#define CHECK_CDS_MUST_MATCH_FLAG(n) \\\n+  if (_v_##n != n) { \\\n+    ResourceMark rm; \\\n+    stringStream ss; \\\n+    ss.print(\"VM option %s is different between dumptime (\", #n);  \\\n+    do_print(&ss, _v_ ## n); \\\n+    ss.print(\") and runtime (\"); \\\n+    do_print(&ss, n); \\\n+    ss.print(\")\"); \\\n+    log_info(cds)(\"%s\", ss.as_string()); \\\n+    return false; \\\n+  }\n+  CDS_MUST_MATCH_FLAGS_DO(CHECK_CDS_MUST_MATCH_FLAG);\n+#undef CHECK_CDS_MUST_MATCH_FLAG\n+\n+  return true;\n+}\n+\n+void CDSMustMatchFlags::print_info() const {\n+  LogTarget(Info, cds) lt;\n+  if (lt.is_enabled()) {\n+    LogStream ls(lt);\n+    ls.print_cr(\"Recorded VM flags during dumptime:\");\n+    print(&ls);\n+  }\n+}\n+\n+void CDSMustMatchFlags::print(outputStream* st) const {\n+#define PRINT_CDS_MUST_MATCH_FLAG(n) \\\n+  st->print(\"- %-s \", #n);                   \\\n+  st->sp(int(_max_name_width - strlen(#n))); \\\n+  do_print(st, _v_##n);                      \\\n+  st->cr();\n+  CDS_MUST_MATCH_FLAGS_DO(PRINT_CDS_MUST_MATCH_FLAG);\n+#undef PRINT_CDS_MUST_MATCH_FLAG\n+}\n+\n@@ -237,0 +302,1 @@\n+  _has_valhalla_patched_classes = CDSConfig::is_valhalla_preview();\n@@ -252,0 +318,1 @@\n+  _must_match.init();\n@@ -311,0 +378,2 @@\n+  st->print_cr(\"- has_valhalla_patched_classes    %d\", _has_valhalla_patched_classes);\n+  _must_match.print(st);\n@@ -695,0 +764,4 @@\n+  if (!header()->check_must_match_flags()) {\n+    return false;\n+  }\n+\n@@ -1935,0 +2008,18 @@\n+  if (is_static()) {\n+    const char* err = nullptr;\n+    if (CDSConfig::is_valhalla_preview()) {\n+      if (!_has_valhalla_patched_classes) {\n+        err = \"not created\";\n+      }\n+    } else {\n+      if (_has_valhalla_patched_classes) {\n+        err = \"created\";\n+      }\n+    }\n+    if (err != nullptr) {\n+      log_warning(cds)(\"This archive was %s with --enable-preview -XX:+EnableValhalla. It is \"\n+                         \"incompatible with the current JVM setting\", err);\n+      return false;\n+    }\n+  }\n+\n","filename":"src\/hotspot\/share\/cds\/filemap.cpp","additions":91,"deletions":0,"binary":false,"changes":91,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"runtime\/globals.hpp\"\n@@ -101,0 +102,29 @@\n+#define CDS_MUST_MATCH_FLAGS_DO(f) \\\n+  f(EnableValhalla) \\\n+  f(UseArrayFlattening) \\\n+  f(UseFieldFlattening) \\\n+  f(InlineTypePassFieldsAsArgs) \\\n+  f(InlineTypeReturnedAsFields) \\\n+  f(UseAtomicValueFlattening) \\\n+  f(UseNullableValueFlattening)\n+\n+class CDSMustMatchFlags {\n+private:\n+  size_t _max_name_width;\n+#define DECLARE_CDS_MUST_MATCH_FLAG(n) \\\n+  decltype(n) _v_##n;\n+  CDS_MUST_MATCH_FLAGS_DO(DECLARE_CDS_MUST_MATCH_FLAG);\n+#undef DECLARE_CDS_MUST_MATCH_FLAG\n+\n+  inline static void do_print(outputStream* st, bool v);\n+  inline static void do_print(outputStream* st, intx v);\n+  inline static void do_print(outputStream* st, uintx v);\n+  inline static void do_print(outputStream* st, double v);\n+  void print_info() const;\n+\n+public:\n+  void init();\n+  bool runtime_check() const;\n+  void print(outputStream* st) const;\n+};\n+\n@@ -143,0 +173,2 @@\n+  bool   _has_valhalla_patched_classes; \/\/ Is this archived dumped with --enable-preview -XX:+EnableValhalla?\n+  CDSMustMatchFlags _must_match;        \/\/ These flags must be the same between dumptime and runtime\n@@ -240,0 +272,4 @@\n+  bool check_must_match_flags() const {\n+    return _must_match.runtime_check();\n+  }\n+\n","filename":"src\/hotspot\/share\/cds\/filemap.hpp","additions":36,"deletions":0,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -1991,0 +1991,7 @@\n+\n+    if (CDSConfig::is_valhalla_preview() && strcmp(klass_name, \"jdk\/internal\/module\/ArchivedModuleGraph\") == 0) {\n+      \/\/ FIXME -- ArchivedModuleGraph doesn't work when java.base is patched with valhalla classes.\n+      i++;\n+      continue;\n+    }\n+\n","filename":"src\/hotspot\/share\/cds\/heapShared.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -74,0 +74,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/inlineKlass.hpp\"\n@@ -118,1 +120,1 @@\n-\/\/ [0] All classes are loaded in MetaspaceShared::preload_classes(). All metadata are\n+\/\/ [0] All classes are loaded in MetaspaceShared::loadable_descriptors(). All metadata are\n@@ -890,1 +892,1 @@\n-void MetaspaceShared::preload_classes(TRAPS) {\n+void MetaspaceShared::loadable_descriptors(TRAPS) {\n@@ -937,1 +939,1 @@\n-    preload_classes(CHECK);\n+    loadable_descriptors(CHECK);\n@@ -1089,0 +1091,5 @@\n+  if (CDSConfig::is_valhalla_preview()) {\n+    log_info(cds)(\"Archived java heap is not yet supported with Valhalla preview\");\n+    return;\n+  }\n+\n","filename":"src\/hotspot\/share\/cds\/metaspaceShared.cpp","additions":10,"deletions":3,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -1034,0 +1034,1 @@\n+  bool is_patched = false;\n@@ -1053,2 +1054,16 @@\n-    assert(!CDSConfig::is_dumping_archive(), \"CDS doesn't support --patch-module during dumping\");\n-    stream = search_module_entries(THREAD, _patch_mod_entries, pkg_entry, file_name);\n+    \/\/ At CDS dump time, the --patch-module entries are ignored. That means a\n+    \/\/ class is still loaded from the runtime image even if it might\n+    \/\/ appear in the _patch_mod_entries. The runtime shared class visibility\n+    \/\/ check will determine if a shared class is visible based on the runtime\n+    \/\/ environment, including the runtime --patch-module setting.\n+    if (!CDSConfig::is_valhalla_preview()) {\n+      \/\/ Dynamic dumping requires UseSharedSpaces to be enabled. Since --patch-module\n+      \/\/ is not supported with UseSharedSpaces, we can never come here during dynamic dumping.\n+      assert(!CDSConfig::is_dumping_archive(), \"CDS doesn't support --patch-module during dumping\");\n+    }\n+    if (CDSConfig::is_valhalla_preview() || !CDSConfig::is_dumping_static_archive()) {\n+      stream = search_module_entries(THREAD, _patch_mod_entries, pkg_entry, file_name);\n+      if (stream != nullptr) {\n+        is_patched = true;\n+      }\n+    }\n@@ -1103,0 +1118,4 @@\n+  if (is_patched) {\n+    result->set_shared_classpath_index(0);\n+    result->set_shared_class_loader_type(ClassLoader::BOOT_LOADER);\n+  }\n@@ -1179,0 +1198,4 @@\n+  if (ik->shared_classpath_index() == 0 && ik->is_shared_boot_class()) {\n+    return;\n+  }\n+\n","filename":"src\/hotspot\/share\/classfile\/classLoader.cpp","additions":25,"deletions":2,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -55,0 +55,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -56,1 +58,1 @@\n-#include \"oops\/instanceMirrorKlass.hpp\"\n+#include \"oops\/instanceMirrorKlass.inline.hpp\"\n@@ -1076,1 +1078,9 @@\n-    if (k->is_typeArray_klass()) {\n+    if (k->is_flatArray_klass()) {\n+      Klass* element_klass = (Klass*) FlatArrayKlass::cast(k)->element_klass();\n+      assert(element_klass->is_inline_klass(), \"Must be inline type component\");\n+      if (is_scratch) {\n+        comp_mirror = Handle(THREAD, HeapShared::scratch_java_mirror(element_klass));\n+      } else {\n+        comp_mirror = Handle(THREAD, element_klass->java_mirror());\n+      }\n+    } else if (k->is_typeArray_klass()) {\n@@ -1087,0 +1097,1 @@\n+      oop comp_oop = element_klass->java_mirror();\n@@ -1090,1 +1101,1 @@\n-        comp_mirror = Handle(THREAD, element_klass->java_mirror());\n+        comp_mirror = Handle(THREAD, comp_oop);\n@@ -1146,0 +1157,1 @@\n+\n@@ -1168,3 +1180,3 @@\n-  if (k->class_loader() != nullptr &&\n-      k->class_loader() != SystemDictionary::java_platform_loader() &&\n-      k->class_loader() != SystemDictionary::java_system_loader()) {\n+  if ((k->class_loader() != nullptr &&\n+       k->class_loader() != SystemDictionary::java_platform_loader() &&\n+       k->class_loader() != SystemDictionary::java_system_loader())) {\n@@ -1398,1 +1410,3 @@\n-  if (is_instance)  st->print(\"L\");\n+  if (is_instance)  {\n+    st->print(\"L\");\n+  }\n@@ -1457,0 +1471,4 @@\n+  if (klass->is_flatArray_klass() || (klass->is_objArray_klass() && ObjArrayKlass::cast(klass)->is_null_free_array_klass())) {\n+    \/\/ TODO 8336006 Ignore flat \/ null-free arrays\n+    return;\n+  }\n@@ -2842,1 +2860,1 @@\n-      if (method->name() == vmSymbols::object_initializer_name() &&\n+      if (method->is_object_constructor() &&\n@@ -3201,2 +3219,2 @@\n-  if (m->is_object_initializer()) {\n-    flags |= java_lang_invoke_MemberName::MN_IS_CONSTRUCTOR;\n+  if (m->is_object_constructor()) {\n+    flags |= java_lang_invoke_MemberName::MN_IS_OBJECT_CONSTRUCTOR;\n@@ -3593,1 +3611,1 @@\n-int java_lang_reflect_Field::_trusted_final_offset;\n+int java_lang_reflect_Field::_flags_offset;\n@@ -3603,1 +3621,1 @@\n-  macro(_trusted_final_offset,    k, vmSymbols::trusted_final_name(),    bool_signature,       false); \\\n+  macro(_flags_offset,     k, vmSymbols::flags_name(),     int_signature,    false); \\\n@@ -3668,2 +3686,2 @@\n-void java_lang_reflect_Field::set_trusted_final(oop field) {\n-  field->bool_field_put(_trusted_final_offset, true);\n+void java_lang_reflect_Field::set_flags(oop field, int value) {\n+  field->int_field_put(_flags_offset, value);\n@@ -3976,1 +3994,1 @@\n-  macro(_value_offset,      integerKlass, \"value\", int_signature, false); \\\n+  macro(_value_offset,      byteKlass, \"value\", byte_signature, false); \\\n@@ -3980,1 +3998,1 @@\n-  InstanceKlass* integerKlass = vmClasses::Integer_klass();\n+  InstanceKlass* byteKlass = vmClasses::Byte_klass();\n@@ -4501,1 +4519,0 @@\n-\n@@ -4511,1 +4528,1 @@\n-  return (flags(mname) & (MN_IS_METHOD | MN_IS_CONSTRUCTOR)) > 0;\n+  return (flags(mname) & (MN_IS_METHOD | MN_IS_OBJECT_CONSTRUCTOR)) > 0;\n@@ -5516,1 +5533,5 @@\n-  CHECK_OFFSET(\"java\/lang\/Float\",     java_lang_boxing_object, value, \"F\");\n+  if (Arguments::enable_preview() && UseNullableValueFlattening && UseFieldFlattening) {\n+    CHECK_LONG_OFFSET(\"java\/lang\/Float\",     java_lang_boxing_object, value, \"F\");\n+  } else {\n+    CHECK_OFFSET(\"java\/lang\/Float\",     java_lang_boxing_object, value, \"F\");\n+  }\n@@ -5520,1 +5541,5 @@\n-  CHECK_OFFSET(\"java\/lang\/Integer\",   java_lang_boxing_object, value, \"I\");\n+  if (Arguments::enable_preview() && UseNullableValueFlattening && UseFieldFlattening) {\n+    CHECK_LONG_OFFSET(\"java\/lang\/Integer\",   java_lang_boxing_object, value, \"I\");\n+  } else {\n+    CHECK_OFFSET(\"java\/lang\/Integer\",   java_lang_boxing_object, value, \"I\");\n+  }\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":45,"deletions":20,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -254,0 +254,1 @@\n+\n@@ -271,0 +272,1 @@\n+\n@@ -315,0 +317,1 @@\n+\n@@ -826,1 +829,1 @@\n-  static int _trusted_final_offset;\n+  static int _flags_offset;\n@@ -854,1 +857,1 @@\n-  static void set_trusted_final(oop field);\n+  static void set_flags(oop field, int value);\n@@ -1353,1 +1356,1 @@\n-    MN_IS_CONSTRUCTOR        = 0x00020000, \/\/ constructor\n+    MN_IS_OBJECT_CONSTRUCTOR = 0x00020000, \/\/ constructor\n@@ -1359,0 +1362,1 @@\n+    MN_NULL_RESTRICTED_FIELD = 0x00800000, \/\/ null-restricted field\n@@ -1360,1 +1364,3 @@\n-    MN_REFERENCE_KIND_MASK   = 0x0F000000 >> MN_REFERENCE_KIND_SHIFT,\n+    MN_REFERENCE_KIND_MASK   = 0x0F000000 >> MN_REFERENCE_KIND_SHIFT, \/\/ 4 bits\n+    MN_LAYOUT_SHIFT          = 28, \/\/ field layout\n+    MN_LAYOUT_MASK           = 0x70000000 >> MN_LAYOUT_SHIFT, \/\/ 3 bits\n@@ -1864,1 +1870,0 @@\n-\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.hpp","additions":10,"deletions":5,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -206,1 +206,2 @@\n-    return VerificationType::reference_type(_cp->klass_name_at(class_index));\n+    Symbol* klass_name = _cp->klass_name_at(class_index);\n+    return VerificationType::reference_type(klass_name);\n","filename":"src\/hotspot\/share\/classfile\/stackMapTable.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -58,0 +58,1 @@\n+#include \"oops\/fieldStreams.inline.hpp\"\n@@ -69,0 +70,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -77,0 +79,1 @@\n+#include \"runtime\/os.hpp\"\n@@ -352,1 +355,1 @@\n-      \/\/ Ignore wrapping L and ;.\n+      \/\/ Ignore wrapping L and ; (and Q and ; for value types).\n@@ -921,2 +924,1 @@\n-  assert(!ModuleEntryTable::javabase_moduleEntry()->is_patched(),\n-         \"Cannot use sharing if java.base is patched\");\n+  assert(!CDSConfig::module_patching_disables_cds(), \"Cannot use CDS\");\n@@ -998,1 +1000,1 @@\n-        assert(!mod_entry->is_patched(), \"cannot load archived classes for patched module\");\n+        assert(!CDSConfig::module_patching_disables_cds(), \"Cannot use CDS\");\n@@ -1130,0 +1132,32 @@\n+  if (ik->has_inline_type_fields()) {\n+    for (AllFieldStream fs(ik); !fs.done(); fs.next()) {\n+      if (fs.access_flags().is_static()) continue;\n+      Symbol* sig = fs.signature();\n+      if (fs.is_null_free_inline_type()) {\n+        \/\/ Pre-load inline class\n+        TempNewSymbol name = Signature::strip_envelope(sig);\n+        Klass* real_k = SystemDictionary::resolve_with_circularity_detection_or_fail(ik->name(), name,\n+          class_loader, false, CHECK_NULL);\n+        Klass* k = ik->get_inline_type_field_klass_or_null(fs.index());\n+        if (real_k != k) {\n+          \/\/ oops, the app has substituted a different version of k!\n+          return nullptr;\n+        }\n+      } else if (Signature::has_envelope(sig)) {\n+        TempNewSymbol name = Signature::strip_envelope(sig);\n+        if (name != ik->name() && ik->is_class_in_loadable_descriptors_attribute(name)) {\n+          Klass* real_k = SystemDictionary::resolve_with_circularity_detection_or_fail(ik->name(), name,\n+            class_loader, false, THREAD);\n+          if (HAS_PENDING_EXCEPTION) {\n+            CLEAR_PENDING_EXCEPTION;\n+          }\n+          Klass* k = ik->get_inline_type_field_klass_or_null(fs.index());\n+          if (real_k != k) {\n+            \/\/ oops, the app has substituted a different version of k!\n+            return nullptr;\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n@@ -1165,0 +1199,1 @@\n+\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":39,"deletions":4,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -69,0 +69,1 @@\n+#define INLINE_TYPE_MAJOR_VERSION                       56\n@@ -500,0 +501,7 @@\n+    case WRONG_INLINE_TYPE:\n+      ss->print(\"Type \");\n+      _type.details(ss);\n+      ss->print(\" and type \");\n+      _expected.details(ss);\n+      ss->print(\" must be identical inline types.\");\n+      break;\n@@ -620,0 +628,5 @@\n+static bool supports_strict_fields(InstanceKlass* klass) {\n+  int ver = klass->major_version();\n+  return ver > Verifier::VALUE_TYPES_MAJOR_VERSION ||\n+         (ver == Verifier::VALUE_TYPES_MAJOR_VERSION && klass->minor_version() == Verifier::JAVA_PREVIEW_MINOR_VERSION);\n+}\n@@ -1686,1 +1699,1 @@\n-          if (_method->name() == vmSymbols::object_initializer_name() &&\n+          if (_method->is_object_constructor() &&\n@@ -1709,4 +1722,0 @@\n-          verify_invoke_instructions(\n-            &bcs, code_length, &current_frame, (bci >= ex_min && bci < ex_max),\n-            &this_uninit, return_type, cp, &stackmap_table, CHECK_VERIFY(this));\n-          no_control_flow = false; break;\n@@ -1717,1 +1726,1 @@\n-            &this_uninit, return_type, cp, &stackmap_table, CHECK_VERIFY(this));\n+            &this_uninit, cp, &stackmap_table, CHECK_VERIFY(this));\n@@ -1775,2 +1784,2 @@\n-        case Bytecodes::_monitorexit :\n-          current_frame.pop_stack(\n+        case Bytecodes::_monitorexit : {\n+          VerificationType ref = current_frame.pop_stack(\n@@ -1779,0 +1788,1 @@\n+        }\n@@ -2156,1 +2166,1 @@\n-            | (1 << JVM_CONSTANT_String)  | (1 << JVM_CONSTANT_Class)\n+            | (1 << JVM_CONSTANT_String) | (1 << JVM_CONSTANT_Class)\n@@ -2332,1 +2342,1 @@\n-    (!allow_arrays || !ref_class_type.is_array())) {\n+      (!allow_arrays || !ref_class_type.is_array())) {\n@@ -2339,0 +2349,1 @@\n+\n@@ -2380,1 +2391,1 @@\n-      \/\/ The JVMS 2nd edition allows field initialization before the superclass\n+      \/\/ Field initialization is allowed before the superclass\n@@ -2383,4 +2394,14 @@\n-      if (stack_object_type == VerificationType::uninitialized_this_type() &&\n-          target_class_type.equals(current_type()) &&\n-          _klass->find_local_field(field_name, field_sig, &fd)) {\n-        stack_object_type = current_type();\n+      bool is_local_field = _klass->find_local_field(field_name, field_sig, &fd) &&\n+                            target_class_type.equals(current_type());\n+      if (stack_object_type == VerificationType::uninitialized_this_type()) {\n+        if (is_local_field) {\n+          \/\/ Set the type to the current type so the is_assignable check passes.\n+          stack_object_type = current_type();\n+        }\n+      } else if (supports_strict_fields(_klass)) {\n+        \/\/ `strict` fields are not writable, but only local fields produce verification errors\n+        if (is_local_field && fd.access_flags().is_strict()) {\n+          verify_error(ErrorContext::bad_code(bci),\n+                       \"Illegal use of putfield on a strict field\");\n+          return;\n+        }\n@@ -2791,1 +2812,1 @@\n-    bool in_try_block, bool *this_uninit, VerificationType return_type,\n+    bool in_try_block, bool *this_uninit,\n@@ -2823,1 +2844,1 @@\n-  \/\/ Get referenced class type\n+  \/\/ Get referenced class\n@@ -2889,1 +2910,2 @@\n-    \/\/ Make sure <init> can only be invoked by invokespecial\n+    \/\/ Make sure:\n+    \/\/   <init> can only be invoked by invokespecial.\n@@ -2891,1 +2913,1 @@\n-        method_name != vmSymbols::object_initializer_name()) {\n+          method_name != vmSymbols::object_initializer_name()) {\n@@ -2899,1 +2921,1 @@\n-                  current_class()->super()->name()))) {\n+                  current_class()->super()->name()))) { \/\/ super() can never be an inline_type.\n@@ -2984,3 +3006,1 @@\n-      \/\/ <init> method must have a void return type\n-      \/* Unreachable?  Class file parser verifies that methods with '<' have\n-       * void return *\/\n+      \/\/ an <init> method must have a void return type\n","filename":"src\/hotspot\/share\/classfile\/verifier.cpp","additions":43,"deletions":23,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -264,0 +264,1 @@\n+  case vmIntrinsics::_newNullRestrictedArray:\n@@ -328,0 +329,2 @@\n+  case vmIntrinsics::_makePrivateBuffer:\n+  case vmIntrinsics::_finishPrivateBuffer:\n@@ -337,0 +340,1 @@\n+  case vmIntrinsics::_getValue:\n@@ -346,0 +350,1 @@\n+  case vmIntrinsics::_putValue:\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -325,0 +325,3 @@\n+  do_intrinsic(_newNullRestrictedArray,   jdk_internal_value_ValueClass, newNullRestrictedArray_name, newNullRestrictedArray_signature, F_SN) \\\n+   do_signature(newNullRestrictedArray_signature,                 \"(Ljava\/lang\/Class;I)[Ljava\/lang\/Object;\")            \\\n+   do_name(     newNullRestrictedArray_name,                      \"newNullRestrictedArray\")                             \\\n@@ -630,0 +633,2 @@\n+  do_intrinsic(_isFlatArray,              jdk_internal_misc_Unsafe,     isFlatArray_name, class_boolean_signature, F_RN)         \\\n+   do_name(     isFlatArray_name,                                       \"isFlatArray\")                                           \\\n@@ -681,0 +686,2 @@\n+  do_signature(getValue_signature,        \"(Ljava\/lang\/Object;JLjava\/lang\/Class;)Ljava\/lang\/Object;\")                   \\\n+  do_signature(putValue_signature,        \"(Ljava\/lang\/Object;JLjava\/lang\/Class;Ljava\/lang\/Object;)V\")                  \\\n@@ -691,0 +698,3 @@\n+  do_name(getValue_name,\"getValue\")             do_name(putValue_name,\"putValue\")                                       \\\n+  do_name(makePrivateBuffer_name,\"makePrivateBuffer\")                                                                   \\\n+  do_name(finishPrivateBuffer_name,\"finishPrivateBuffer\")                                                               \\\n@@ -701,0 +711,1 @@\n+  do_intrinsic(_getValue,           jdk_internal_misc_Unsafe,     getValue_name, getValue_signature,             F_RN)  \\\n@@ -710,0 +721,4 @@\n+  do_intrinsic(_putValue,           jdk_internal_misc_Unsafe,     putValue_name, putValue_signature,             F_RN)  \\\n+                                                                                                                        \\\n+  do_intrinsic(_makePrivateBuffer,  jdk_internal_misc_Unsafe,     makePrivateBuffer_name, object_object_signature, F_RN)   \\\n+  do_intrinsic(_finishPrivateBuffer,  jdk_internal_misc_Unsafe,   finishPrivateBuffer_name, object_object_signature, F_RN) \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -78,0 +78,1 @@\n+#include \"oops\/flatArrayKlass.inline.hpp\"\n@@ -2453,0 +2454,3 @@\n+    \/\/ Read the klass before the copying, since it might destroy the klass (i.e. overlapping copy)\n+    \/\/ and if partial copy, the destination klass may not be copied yet\n+    Klass* klass = cast_to_oop(source())->klass();\n@@ -2454,1 +2458,1 @@\n-    cast_to_oop(copy_destination())->init_mark();\n+    cast_to_oop(copy_destination())->set_mark(Klass::default_prototype_header(klass));\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -177,0 +177,3 @@\n+JNIEXPORT jboolean JNICALL\n+JVM_IsValhallaEnabled(void);\n+\n@@ -552,0 +555,6 @@\n+JNIEXPORT jboolean JNICALL\n+JVM_IsIdentityClass(JNIEnv *env, jclass cls);\n+\n+JNIEXPORT jboolean JNICALL\n+JVM_IsImplicitlyConstructibleClass(JNIEnv *env, jclass cls);\n+\n@@ -1088,0 +1097,15 @@\n+JNIEXPORT jarray JNICALL\n+JVM_NewNullRestrictedArray(JNIEnv *env, jclass elmClass, jint len);\n+\n+JNIEXPORT jarray JNICALL\n+JVM_NewNullRestrictedAtomicArray(JNIEnv *env, jclass elmClass, jint len);\n+\n+JNIEXPORT jarray JNICALL\n+JVM_NewNullableAtomicArray(JNIEnv *env, jclass elmClass, jint len);\n+\n+JNIEXPORT jboolean JNICALL\n+JVM_IsFlatArray(JNIEnv *env, jobject obj);\n+\n+JNIEXPORT jboolean JNICALL\n+JVM_IsNullRestrictedArray(JNIEnv *env, jobject obj);\n+\n","filename":"src\/hotspot\/share\/include\/jvm.h","additions":24,"deletions":0,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -162,0 +162,1 @@\n+  LOG_TAG(preload)   \/* Trace successfull class preloading *\/ \\\n@@ -215,0 +216,1 @@\n+  LOG_TAG(valuetypes) \\\n","filename":"src\/hotspot\/share\/logging\/logTag.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -317,0 +317,1 @@\n+  f(InlineLayoutInfo) \\\n","filename":"src\/hotspot\/share\/memory\/allocation.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -56,0 +56,1 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n@@ -265,1 +266,1 @@\n-      \/\/ All of these should have been reverted back to ClassIndex before calling\n+      \/\/ All of these should have been reverted back to Unresolved before calling\n@@ -642,0 +643,6 @@\n+void check_is_inline_type(Klass* k, TRAPS) {\n+  if (!k->is_inline_klass()) {\n+    THROW(vmSymbols::java_lang_IncompatibleClassChangeError());\n+  }\n+}\n+\n@@ -680,0 +687,1 @@\n+  bool inline_type_signature = false;\n@@ -688,0 +696,3 @@\n+  if (inline_type_signature) {\n+    name->decrement_refcount();\n+  }\n@@ -696,0 +707,16 @@\n+  if (!HAS_PENDING_EXCEPTION && inline_type_signature) {\n+    check_is_inline_type(k, THREAD);\n+  }\n+\n+  if (!HAS_PENDING_EXCEPTION) {\n+    Klass* bottom_klass = nullptr;\n+    if (k->is_objArray_klass()) {\n+      bottom_klass = ObjArrayKlass::cast(k)->bottom_klass();\n+      assert(bottom_klass != nullptr, \"Should be set\");\n+      assert(bottom_klass->is_instance_klass() || bottom_klass->is_typeArray_klass(), \"Sanity check\");\n+    } else if (k->is_flatArray_klass()) {\n+      bottom_klass = FlatArrayKlass::cast(k)->element_klass();\n+      assert(bottom_klass != nullptr, \"Should be set\");\n+    }\n+  }\n+\n","filename":"src\/hotspot\/share\/oops\/constantPool.cpp","additions":28,"deletions":1,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -72,0 +72,1 @@\n+#include \"oops\/markWord.hpp\"\n@@ -76,0 +77,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -153,0 +155,5 @@\n+void InlineLayoutInfo::metaspace_pointers_do(MetaspaceClosure* it) {\n+  log_trace(cds)(\"Iter(InlineFieldInfo): %p\", this);\n+  it->push(&_klass);\n+}\n+\n@@ -174,0 +181,13 @@\n+bool InstanceKlass::field_is_null_free_inline_type(int index) const {\n+  return field(index).field_flags().is_null_free_inline_type();\n+}\n+\n+bool InstanceKlass::is_class_in_loadable_descriptors_attribute(Symbol* name) const {\n+  if (_loadable_descriptors == nullptr) return false;\n+  for (int i = 0; i < _loadable_descriptors->length(); i++) {\n+        Symbol* class_name = _constants->symbol_at(_loadable_descriptors->at(i));\n+        if (class_name == name) return true;\n+  }\n+  return false;\n+}\n+\n@@ -468,1 +488,2 @@\n-                                       parser.is_interface());\n+                                       parser.is_interface(),\n+                                       parser.is_inline_type());\n@@ -491,0 +512,3 @@\n+  } else if (parser.is_inline_type()) {\n+    \/\/ inline type\n+    ik = new (loader_data, size, use_class_space, THREAD) InlineKlass(parser);\n@@ -507,0 +531,6 @@\n+#ifdef ASSERT\n+  ik->bounds_check((address) ik->start_of_vtable(), false, size);\n+  ik->bounds_check((address) ik->start_of_itable(), false, size);\n+  ik->bounds_check((address) ik->end_of_itable(), true, size);\n+  ik->bounds_check((address) ik->end_of_nonstatic_oop_maps(), true, size);\n+#endif \/\/ASSERT\n@@ -510,0 +540,23 @@\n+#ifndef PRODUCT\n+bool InstanceKlass::bounds_check(address addr, bool edge_ok, intptr_t size_in_bytes) const {\n+  const char* bad = nullptr;\n+  address end = nullptr;\n+  if (addr < (address)this) {\n+    bad = \"before\";\n+  } else if (addr == (address)this) {\n+    if (edge_ok)  return true;\n+    bad = \"just before\";\n+  } else if (addr == (end = (address)this + sizeof(intptr_t) * (size_in_bytes < 0 ? size() : size_in_bytes))) {\n+    if (edge_ok)  return true;\n+    bad = \"just after\";\n+  } else if (addr > end) {\n+    bad = \"after\";\n+  } else {\n+    return true;\n+  }\n+  tty->print_cr(\"%s object bounds: \" INTPTR_FORMAT \" [\" INTPTR_FORMAT \"..\" INTPTR_FORMAT \"]\",\n+      bad, (intptr_t)addr, (intptr_t)this, (intptr_t)end);\n+  Verbose = WizardMode = true; this->print(); \/\/@@\n+  return false;\n+}\n+#endif \/\/PRODUCT\n@@ -537,2 +590,2 @@\n-InstanceKlass::InstanceKlass(const ClassFileParser& parser, KlassKind kind, ReferenceType reference_type) :\n-  Klass(kind),\n+InstanceKlass::InstanceKlass(const ClassFileParser& parser, KlassKind kind, markWord prototype_header, ReferenceType reference_type) :\n+  Klass(kind, prototype_header),\n@@ -549,1 +602,4 @@\n-  _init_thread(nullptr)\n+  _init_thread(nullptr),\n+  _inline_layout_info_array(nullptr),\n+  _loadable_descriptors(nullptr),\n+  _adr_inlineklass_fixed_block(nullptr)\n@@ -556,0 +612,3 @@\n+  if (parser.has_inline_fields()) {\n+    set_has_inline_type_fields();\n+  }\n@@ -695,0 +754,5 @@\n+  if (inline_layout_info_array() != nullptr) {\n+    MetadataFactory::free_array<InlineLayoutInfo>(loader_data, inline_layout_info_array());\n+  }\n+  set_inline_layout_info_array(nullptr);\n+\n@@ -729,0 +793,7 @@\n+  if (loadable_descriptors() != nullptr &&\n+      loadable_descriptors() != Universe::the_empty_short_array() &&\n+      !loadable_descriptors()->is_shared()) {\n+    MetadataFactory::free_array<jushort>(loader_data, loadable_descriptors());\n+  }\n+  set_loadable_descriptors(nullptr);\n+\n@@ -963,0 +1034,105 @@\n+\n+  \/\/ If a class declares a method that uses an inline class as an argument\n+  \/\/ type or return inline type, this inline class must be loaded during the\n+  \/\/ linking of this class because size and properties of the inline class\n+  \/\/ must be known in order to be able to perform inline type optimizations.\n+  \/\/ The implementation below is an approximation of this rule, the code\n+  \/\/ iterates over all methods of the current class (including overridden\n+  \/\/ methods), not only the methods declared by this class. This\n+  \/\/ approximation makes the code simpler, and doesn't change the semantic\n+  \/\/ because classes declaring methods overridden by the current class are\n+  \/\/ linked (and have performed their own pre-loading) before the linking\n+  \/\/ of the current class.\n+\n+\n+  \/\/ Note:\n+  \/\/ Inline class types are loaded during\n+  \/\/ the loading phase (see ClassFileParser::post_process_parsed_stream()).\n+  \/\/ Inline class types used as element types for array creation\n+  \/\/ are not pre-loaded. Their loading is triggered by either anewarray\n+  \/\/ or multianewarray bytecodes.\n+\n+  \/\/ Could it be possible to do the following processing only if the\n+  \/\/ class uses inline types?\n+  if (EnableValhalla) {\n+    ResourceMark rm(THREAD);\n+    for (AllFieldStream fs(this); !fs.done(); fs.next()) {\n+      if (fs.is_null_free_inline_type() && fs.access_flags().is_static()) {\n+        Symbol* sig = fs.signature();\n+        TempNewSymbol s = Signature::strip_envelope(sig);\n+        if (s != name()) {\n+          log_info(class, preload)(\"Preloading class %s during linking of class %s. Cause: a null-free static field is declared with this type\", s->as_C_string(), name()->as_C_string());\n+          Klass* klass = SystemDictionary::resolve_or_fail(s,\n+                                                          Handle(THREAD, class_loader()), true,\n+                                                          CHECK_false);\n+          if (HAS_PENDING_EXCEPTION) {\n+            log_warning(class, preload)(\"Preloading of class %s during linking of class %s (cause: null-free static field) failed: %s\",\n+                                      s->as_C_string(), name()->as_C_string(), PENDING_EXCEPTION->klass()->name()->as_C_string());\n+            return false; \/\/ Exception is still pending\n+          }\n+          log_info(class, preload)(\"Preloading of class %s during linking of class %s (cause: null-free static field) succeeded\",\n+                                   s->as_C_string(), name()->as_C_string());\n+          assert(klass != nullptr, \"Sanity check\");\n+          if (klass->is_abstract()) {\n+            THROW_MSG_(vmSymbols::java_lang_IncompatibleClassChangeError(),\n+                      err_msg(\"Class %s expects class %s to be concrete value class, but it is an abstract class\",\n+                      name()->as_C_string(),\n+                      InstanceKlass::cast(klass)->external_name()), false);\n+          }\n+          if (!klass->is_inline_klass()) {\n+            THROW_MSG_(vmSymbols::java_lang_IncompatibleClassChangeError(),\n+                       err_msg(\"class %s expects class %s to be a value class but it is an identity class\",\n+                       name()->as_C_string(), klass->external_name()), false);\n+          }\n+          InlineKlass* vk = InlineKlass::cast(klass);\n+          if (!vk->is_implicitly_constructible()) {\n+             THROW_MSG_(vmSymbols::java_lang_IncompatibleClassChangeError(),\n+                        err_msg(\"class %s is not implicitly constructible and it is used in a null restricted static field (not supported)\",\n+                        klass->external_name()), false);\n+          }\n+          \/\/ the inline_type_field_klasses_array might have been loaded with CDS, so update only if not already set and check consistency\n+          InlineLayoutInfo* li = inline_layout_info_adr(fs.index());\n+          if (li->klass() == nullptr) {\n+            li->set_klass(InlineKlass::cast(vk));\n+            li->set_kind(LayoutKind::REFERENCE);\n+          }\n+          assert(get_inline_type_field_klass(fs.index()) == vk, \"Must match\");\n+        } else {\n+          InlineLayoutInfo* li = inline_layout_info_adr(fs.index());\n+          if (li->klass() == nullptr) {\n+            li->set_klass(InlineKlass::cast(this));\n+            li->set_kind(LayoutKind::REFERENCE);\n+          }\n+          assert(get_inline_type_field_klass(fs.index()) == this, \"Must match\");\n+        }\n+      }\n+    }\n+\n+    \/\/ Aggressively preloading all classes from the LoadableDescriptors attribute\n+    if (loadable_descriptors() != nullptr) {\n+      HandleMark hm(THREAD);\n+      for (int i = 0; i < loadable_descriptors()->length(); i++) {\n+        Symbol* sig = constants()->symbol_at(loadable_descriptors()->at(i));\n+        if (!Signature::has_envelope(sig)) continue;\n+        TempNewSymbol class_name = Signature::strip_envelope(sig);\n+        if (class_name == name()) continue;\n+        log_info(class, preload)(\"Preloading class %s during linking of class %s because of the class is listed in the LoadableDescriptors attribute\", sig->as_C_string(), name()->as_C_string());\n+        oop loader = class_loader();\n+        Klass* klass = SystemDictionary::resolve_or_null(class_name,\n+                                                         Handle(THREAD, loader), THREAD);\n+        if (HAS_PENDING_EXCEPTION) {\n+          CLEAR_PENDING_EXCEPTION;\n+        }\n+        if (klass != nullptr) {\n+          log_info(class, preload)(\"Preloading of class %s during linking of class %s (cause: LoadableDescriptors attribute) succeeded\", class_name->as_C_string(), name()->as_C_string());\n+          if (!klass->is_inline_klass()) {\n+            \/\/ Non value class are allowed by the current spec, but it could be an indication of an issue so let's log a warning\n+              log_warning(class, preload)(\"Preloading class %s during linking of class %s (cause: LoadableDescriptors attribute) but loaded class is not a value class\", class_name->as_C_string(), name()->as_C_string());\n+          }\n+        } else {\n+          log_warning(class, preload)(\"Preloading of class %s during linking of class %s (cause: LoadableDescriptors attribute) failed\", class_name->as_C_string(), name()->as_C_string());\n+        }\n+      }\n+    }\n+  }\n+\n@@ -1267,0 +1443,35 @@\n+  \/\/ Pre-allocating an instance of the default value\n+  if (is_inline_klass()) {\n+      InlineKlass* vk = InlineKlass::cast(this);\n+      oop val = vk->allocate_instance(THREAD);\n+      if (HAS_PENDING_EXCEPTION) {\n+          Handle e(THREAD, PENDING_EXCEPTION);\n+          CLEAR_PENDING_EXCEPTION;\n+          {\n+              EXCEPTION_MARK;\n+              add_initialization_error(THREAD, e);\n+              \/\/ Locks object, set state, and notify all waiting threads\n+              set_initialization_state_and_notify(initialization_error, THREAD);\n+              CLEAR_PENDING_EXCEPTION;\n+          }\n+          THROW_OOP(e());\n+      }\n+      vk->set_default_value(val);\n+      if (vk->has_nullable_atomic_layout()) {\n+        val = vk->allocate_instance(THREAD);\n+        if (HAS_PENDING_EXCEPTION) {\n+            Handle e(THREAD, PENDING_EXCEPTION);\n+            CLEAR_PENDING_EXCEPTION;\n+            {\n+                EXCEPTION_MARK;\n+                add_initialization_error(THREAD, e);\n+                \/\/ Locks object, set state, and notify all waiting threads\n+                set_initialization_state_and_notify(initialization_error, THREAD);\n+                CLEAR_PENDING_EXCEPTION;\n+            }\n+            THROW_OOP(e());\n+        }\n+        vk->set_null_reset_value(val);\n+      }\n+  }\n+\n@@ -1299,1 +1510,33 @@\n-\n+  \/\/ Initialize classes of inline fields\n+  if (EnableValhalla) {\n+    for (AllFieldStream fs(this); !fs.done(); fs.next()) {\n+      if (fs.is_null_free_inline_type()) {\n+\n+        \/\/ inline type field klass array entries must have alreadyt been filed at load time or link time\n+        Klass* klass = get_inline_type_field_klass(fs.index());\n+\n+        InstanceKlass::cast(klass)->initialize(THREAD);\n+        if (fs.access_flags().is_static()) {\n+          if (java_mirror()->obj_field(fs.offset()) == nullptr) {\n+            java_mirror()->obj_field_put(fs.offset(), InlineKlass::cast(klass)->default_value());\n+          }\n+        }\n+\n+        if (HAS_PENDING_EXCEPTION) {\n+          Handle e(THREAD, PENDING_EXCEPTION);\n+          CLEAR_PENDING_EXCEPTION;\n+          {\n+            EXCEPTION_MARK;\n+            add_initialization_error(THREAD, e);\n+            \/\/ Locks object, set state, and notify all waiting threads\n+            set_initialization_state_and_notify(initialization_error, THREAD);\n+            CLEAR_PENDING_EXCEPTION;\n+          }\n+          THROW_OOP(e());\n+        }\n+      }\n+    }\n+  }\n+\n+\n+  \/\/ Step 9\n@@ -1322,1 +1565,1 @@\n-  \/\/ Step 9\n+  \/\/ Step 10\n@@ -1328,1 +1571,1 @@\n-    \/\/ Step 10 and 11\n+    \/\/ Step 11 and 12\n@@ -1624,1 +1867,1 @@\n-      ObjArrayKlass* k = ObjArrayKlass::allocate_objArray_klass(class_loader_data(), 1, this, CHECK_NULL);\n+      ObjArrayKlass* k = ObjArrayKlass::allocate_objArray_klass(class_loader_data(), 1, this, false, CHECK_NULL);\n@@ -1631,1 +1874,1 @@\n-  ObjArrayKlass* ak = array_klasses();\n+  ArrayKlass* ak = array_klasses();\n@@ -1638,2 +1881,2 @@\n-  ObjArrayKlass* oak = array_klasses_acquire();\n-  if (oak == nullptr) {\n+  ArrayKlass* ak = array_klasses_acquire();\n+  if (ak == nullptr) {\n@@ -1642,1 +1885,1 @@\n-    return oak->array_klass_or_null(n);\n+    return ak->array_klass_or_null(n);\n@@ -1659,1 +1902,1 @@\n-  if (clinit != nullptr && clinit->has_valid_initializer_flags()) {\n+  if (clinit != nullptr && clinit->is_class_initializer()) {\n@@ -1768,4 +2011,0 @@\n-bool InstanceKlass::contains_field_offset(int offset) {\n-  fieldDescriptor fd;\n-  return find_field_from_offset(offset, false, &fd);\n-}\n@@ -1853,0 +2092,9 @@\n+bool InstanceKlass::contains_field_offset(int offset) {\n+  if (this->is_inline_klass()) {\n+    InlineKlass* vk = InlineKlass::cast(this);\n+    return offset >= vk->payload_offset() && offset < (vk->payload_offset() + vk->payload_size_in_bytes());\n+  } else {\n+    fieldDescriptor fd;\n+    return find_field_from_offset(offset, false, &fd);\n+  }\n+}\n@@ -2244,0 +2492,3 @@\n+    if (name == vmSymbols::object_initializer_name()) {\n+      break;  \/\/ <init> is never inherited\n+    }\n@@ -2641,0 +2892,1 @@\n+  it->push(&_loadable_descriptors);\n@@ -2642,0 +2894,1 @@\n+  it->push(&_inline_layout_info_array, MetaspaceClosure::_writable);\n@@ -2687,1 +2940,1 @@\n-  \/\/ These are not allocated from metaspace. They are safe to set to null.\n+  \/\/ These are not allocated from metaspace. They are safe to set to nullptr.\n@@ -2776,0 +3029,4 @@\n+  if (is_inline_klass()) {\n+    InlineKlass::cast(this)->initialize_calling_convention(CHECK);\n+  }\n+\n@@ -2809,1 +3066,1 @@\n-    assert(this == array_klasses()->bottom_klass(), \"sanity\");\n+    assert(this == ObjArrayKlass::cast(array_klasses())->bottom_klass(), \"sanity\");\n@@ -3006,0 +3263,2 @@\n+  return signature_name_of_carrier(JVM_SIGNATURE_CLASS);\n+}\n@@ -3007,0 +3266,1 @@\n+const char* InstanceKlass::signature_name_of_carrier(char c) const {\n@@ -3013,1 +3273,1 @@\n-  \/\/ Add L as type indicator\n+  \/\/ Add L or Q as type indicator\n@@ -3015,1 +3275,1 @@\n-  dest[dest_index++] = JVM_SIGNATURE_CLASS;\n+  dest[dest_index++] = c;\n@@ -3362,2 +3622,1 @@\n-  \/\/ Remember to strip ACC_SUPER bit\n-  return (access & (~JVM_ACC_SUPER));\n+  return access;\n@@ -3617,1 +3876,4 @@\n-static void print_vtable(intptr_t* start, int len, outputStream* st) {\n+static void print_vtable(address self, intptr_t* start, int len, outputStream* st) {\n+  ResourceMark rm;\n+  int* forward_refs = NEW_RESOURCE_ARRAY(int, len);\n+  for (int i = 0; i < len; i++)  forward_refs[i] = 0;\n@@ -3621,0 +3883,5 @@\n+    if (forward_refs[i] != 0) {\n+      int from = forward_refs[i];\n+      int off = (int) start[from];\n+      st->print(\" (offset %d <= [%d])\", off, from);\n+    }\n@@ -3624,0 +3891,6 @@\n+    } else if (self != nullptr && e > 0 && e < 0x10000) {\n+      address location = self + e;\n+      int index = (int)((intptr_t*)location - start);\n+      st->print(\" (offset %d => [%d])\", (int)e, index);\n+      if (index >= 0 && index < len)\n+        forward_refs[index] = i;\n@@ -3630,1 +3903,22 @@\n-  return print_vtable(reinterpret_cast<intptr_t*>(start), len, st);\n+  return print_vtable(nullptr, reinterpret_cast<intptr_t*>(start), len, st);\n+}\n+\n+template<typename T>\n+ static void print_array_on(outputStream* st, Array<T>* array) {\n+   if (array == nullptr) { st->print_cr(\"nullptr\"); return; }\n+   array->print_value_on(st); st->cr();\n+   if (Verbose || WizardMode) {\n+     for (int i = 0; i < array->length(); i++) {\n+       st->print(\"%d : \", i); array->at(i)->print_value_on(st); st->cr();\n+     }\n+   }\n+ }\n+\n+static void print_array_on(outputStream* st, Array<int>* array) {\n+  if (array == nullptr) { st->print_cr(\"nullptr\"); return; }\n+  array->print_value_on(st); st->cr();\n+  if (Verbose || WizardMode) {\n+    for (int i = 0; i < array->length(); i++) {\n+      st->print(\"%d : %d\", i, array->at(i)); st->cr();\n+    }\n+  }\n@@ -3671,8 +3965,2 @@\n-  st->print(BULLET\"methods:           \"); methods()->print_value_on(st);               st->cr();\n-  if (Verbose || WizardMode) {\n-    Array<Method*>* method_array = methods();\n-    for (int i = 0; i < method_array->length(); i++) {\n-      st->print(\"%d : \", i); method_array->at(i)->print_value(); st->cr();\n-    }\n-  }\n-  st->print(BULLET\"method ordering:   \"); method_ordering()->print_value_on(st);      st->cr();\n+  st->print(BULLET\"methods:           \"); print_array_on(st, methods());\n+  st->print(BULLET\"method ordering:   \"); print_array_on(st, method_ordering());\n@@ -3680,7 +3968,1 @@\n-    st->print(BULLET\"default_methods:   \"); default_methods()->print_value_on(st);    st->cr();\n-    if (Verbose) {\n-      Array<Method*>* method_array = default_methods();\n-      for (int i = 0; i < method_array->length(); i++) {\n-        st->print(\"%d : \", i); method_array->at(i)->print_value(); st->cr();\n-      }\n-    }\n+    st->print(BULLET\"default_methods:   \"); print_array_on(st, default_methods());\n@@ -3746,0 +4028,1 @@\n+  st->print(BULLET\"loadable descriptors:     \"); loadable_descriptors()->print_value_on(st); st->cr();\n@@ -3756,1 +4039,1 @@\n-  if (itable_length() > 0 && (Verbose || WizardMode))  print_vtable(start_of_itable(), itable_length(), st);\n+  if (itable_length() > 0 && (Verbose || WizardMode))  print_vtable(nullptr, start_of_itable(), itable_length(), st);\n@@ -3783,0 +4066,1 @@\n+  for (int i = 0; i < _indent; i++) _st->print(\"  \");\n@@ -3785,1 +4069,1 @@\n-     fd->print_on(_st);\n+     fd->print_on(_st, _base_offset);\n@@ -3788,2 +4072,2 @@\n-     fd->print_on_for(_st, _obj);\n-     _st->cr();\n+     fd->print_on_for(_st, _obj, _indent, _base_offset);\n+     if (!fd->field_flags().is_flat()) _st->cr();\n@@ -3794,1 +4078,1 @@\n-void InstanceKlass::oop_print_on(oop obj, outputStream* st) {\n+void InstanceKlass::oop_print_on(oop obj, outputStream* st, int indent, int base_offset) {\n@@ -3810,1 +4094,1 @@\n-  FieldPrinter print_field(st, obj);\n+  FieldPrinter print_field(st, obj, indent, base_offset);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":330,"deletions":46,"binary":false,"changes":376,"status":"modified"},{"patch":"@@ -71,0 +71,1 @@\n+    InlineKlassKind,\n@@ -76,0 +77,1 @@\n+    FlatArrayKlassKind,\n@@ -102,1 +104,1 @@\n-  \/\/    tag is 0x80 if the elements are oops, 0xC0 if non-oops\n+  \/\/    tag is 0x80 if the elements are oops, 0xC0 if non-oops, 0xA0 if value types\n@@ -208,1 +210,1 @@\n-  Klass(KlassKind kind);\n+  Klass(KlassKind kind, markWord prototype_header = markWord::prototype());\n@@ -464,1 +466,1 @@\n-  static const int _lh_array_tag_bits          = 2;\n+  static const int _lh_array_tag_bits          = 3;\n@@ -466,2 +468,9 @@\n-  static const int _lh_array_tag_obj_value     = ~0x01;   \/\/ 0x80000000 >> 30\n-  static const unsigned int _lh_array_tag_type_value = 0Xffffffff; \/\/ ~0x00,  \/\/ 0xC0000000 >> 30\n+  static const unsigned int _lh_array_tag_type_value = 0Xfffffffc;\n+  static const unsigned int _lh_array_tag_vt_value   = 0Xfffffffd;\n+  static const unsigned int _lh_array_tag_obj_value  = 0Xfffffffe;\n+\n+  \/\/ null-free array flag bit under the array tag bits, shift one more to get array tag value\n+  static const int _lh_null_free_shift = _lh_array_tag_shift - 1;\n+  static const int _lh_null_free_mask  = 1;\n+\n+  static const jint _lh_array_tag_flat_value_bit_inplace = (jint) (1 << _lh_array_tag_shift);\n@@ -485,2 +494,1 @@\n-    \/\/ _lh_array_tag_type_value == (lh >> _lh_array_tag_shift);\n-    return (juint)lh >= (juint)(_lh_array_tag_type_value << _lh_array_tag_shift);\n+    return (juint) _lh_array_tag_type_value == (juint)(lh >> _lh_array_tag_shift);\n@@ -489,2 +497,13 @@\n-    \/\/ _lh_array_tag_obj_value == (lh >> _lh_array_tag_shift);\n-    return (jint)lh < (jint)(_lh_array_tag_type_value << _lh_array_tag_shift);\n+    return (juint)_lh_array_tag_obj_value == (juint)(lh >> _lh_array_tag_shift);\n+  }\n+  static bool layout_helper_is_flatArray(jint lh) {\n+    return (juint)_lh_array_tag_vt_value == (juint)(lh >> _lh_array_tag_shift);\n+  }\n+  static bool layout_helper_is_null_free(jint lh) {\n+    assert(layout_helper_is_flatArray(lh) || layout_helper_is_objArray(lh), \"must be array of inline types\");\n+    return ((lh >> _lh_null_free_shift) & _lh_null_free_mask);\n+  }\n+  static jint layout_helper_set_null_free(jint lh) {\n+    lh |= (_lh_null_free_mask << _lh_null_free_shift);\n+    assert(layout_helper_is_null_free(lh), \"Bad encoding\");\n+    return lh;\n@@ -501,1 +520,1 @@\n-    assert(btvalue >= T_BOOLEAN && btvalue <= T_OBJECT, \"sanity\");\n+    assert((btvalue >= T_BOOLEAN && btvalue <= T_OBJECT) || btvalue == T_FLAT_ELEMENT, \"sanity\");\n@@ -522,1 +541,1 @@\n-    assert(l2esz <= LogBytesPerLong,\n+    assert(layout_helper_element_type(lh) == T_FLAT_ELEMENT || l2esz <= LogBytesPerLong,\n@@ -526,1 +545,1 @@\n-  static jint array_layout_helper(jint tag, int hsize, BasicType etype, int log2_esize) {\n+  static jint array_layout_helper(jint tag, bool null_free, int hsize, BasicType etype, int log2_esize) {\n@@ -528,0 +547,1 @@\n+      |    ((null_free ? 1 : 0) <<  _lh_null_free_shift)\n@@ -671,0 +691,1 @@\n+  virtual bool is_flatArray_klass_slow()    const { return false; }\n@@ -672,0 +693,2 @@\n+  \/\/ current implementation uses this method even in non debug builds\n+  virtual bool is_inline_klass_slow()       const { return false; }\n@@ -687,2 +710,1 @@\n-  \/\/ Other is anything that is not one of the more specialized kinds of InstanceKlass.\n-  bool is_other_instance_klass()        const { return _kind == InstanceKlassKind; }\n+  bool is_inline_klass()                const { return assert_same_query(_kind == InlineKlassKind, is_inline_klass_slow()); }\n@@ -694,0 +716,1 @@\n+  bool is_flatArray_klass()             const { return assert_same_query( _kind == FlatArrayKlassKind, is_flatArray_klass_slow()); }\n@@ -698,0 +721,2 @@\n+  inline bool is_null_free_array_klass()      const { return layout_helper_is_null_free(layout_helper()); }\n+\n@@ -706,1 +731,1 @@\n-  bool is_super() const                 { return _access_flags.is_super(); }\n+  bool is_identity_class() const        { return _access_flags.is_identity_class(); }\n@@ -723,0 +748,1 @@\n+  static inline markWord make_prototype_header(const Klass* kls, markWord prototype = markWord::prototype());\n@@ -726,0 +752,1 @@\n+  static inline markWord default_prototype_header(Klass* k);\n","filename":"src\/hotspot\/share\/oops\/klass.hpp","additions":42,"deletions":15,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -126,1 +126,2 @@\n-  bool eliminate_boxing = EliminateAutoBox;\n+  \/\/ TODO 8328675 Re-enable\n+  bool eliminate_boxing = false; \/\/ EliminateAutoBox;\n@@ -651,0 +652,2 @@\n+  case vmIntrinsics::_makePrivateBuffer:\n+  case vmIntrinsics::_finishPrivateBuffer:\n@@ -660,0 +663,1 @@\n+  case vmIntrinsics::_getValue:\n@@ -669,0 +673,1 @@\n+  case vmIntrinsics::_putValue:\n@@ -751,0 +756,1 @@\n+  case vmIntrinsics::_isFlatArray:\n@@ -752,0 +758,1 @@\n+  case vmIntrinsics::_newNullRestrictedArray:\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n@@ -318,0 +319,2 @@\n+  case vmIntrinsics::_makePrivateBuffer:        return inline_unsafe_make_private_buffer();\n+  case vmIntrinsics::_finishPrivateBuffer:      return inline_unsafe_finish_private_buffer();\n@@ -327,0 +330,1 @@\n+  case vmIntrinsics::_getValue:                 return inline_unsafe_access(!is_store, T_OBJECT,   Relaxed, false, true);\n@@ -337,0 +341,1 @@\n+  case vmIntrinsics::_putValue:                 return inline_unsafe_access( is_store, T_OBJECT,   Relaxed, false, true);\n@@ -503,0 +508,1 @@\n+  case vmIntrinsics::_isFlatArray:              return inline_unsafe_isFlatArray();\n@@ -515,0 +521,1 @@\n+  case vmIntrinsics::_newNullRestrictedArray:   return inline_newNullRestrictedArray();\n@@ -2236,0 +2243,1 @@\n+  bool null_free = false;\n@@ -2241,0 +2249,1 @@\n+      null_free = alias_type->field()->is_null_free();\n@@ -2249,0 +2258,1 @@\n+      null_free = adr_type->is_aryptr()->is_null_free();\n@@ -2261,0 +2271,3 @@\n+    if (null_free) {\n+      result = result->join_speculative(TypePtr::NOTNULL)->is_oopptr();\n+    }\n@@ -2291,1 +2304,1 @@\n-bool LibraryCallKit::inline_unsafe_access(bool is_store, const BasicType type, const AccessKind kind, const bool unaligned) {\n+bool LibraryCallKit::inline_unsafe_access(bool is_store, const BasicType type, const AccessKind kind, const bool unaligned, const bool is_flat) {\n@@ -2316,1 +2329,1 @@\n-      assert(sig->count() == 2, \"oop getter has 2 arguments\");\n+      assert(sig->count() == 2 || (is_flat && sig->count() == 3), \"oop getter has 2 or 3 arguments\");\n@@ -2322,1 +2335,1 @@\n-      assert(sig->count() == 3, \"oop putter has 3 arguments\");\n+      assert(sig->count() == 3 || (is_flat && sig->count() == 4), \"oop putter has 3 arguments\");\n@@ -2348,0 +2361,55 @@\n+\n+  ciInlineKlass* inline_klass = nullptr;\n+  if (is_flat) {\n+    const TypeInstPtr* cls = _gvn.type(argument(4))->isa_instptr();\n+    if (cls == nullptr || cls->const_oop() == nullptr) {\n+      return false;\n+    }\n+    ciType* mirror_type = cls->const_oop()->as_instance()->java_mirror_type();\n+    if (!mirror_type->is_inlinetype()) {\n+      return false;\n+    }\n+    inline_klass = mirror_type->as_inline_klass();\n+  }\n+\n+  if (base->is_InlineType()) {\n+    InlineTypeNode* vt = base->as_InlineType();\n+    if (is_store) {\n+      if (!vt->is_allocated(&_gvn)) {\n+        return false;\n+      }\n+      base = vt->get_oop();\n+    } else {\n+      if (offset->is_Con()) {\n+        long off = find_long_con(offset, 0);\n+        ciInlineKlass* vk = vt->type()->inline_klass();\n+        if ((long)(int)off != off || !vk->contains_field_offset(off)) {\n+          return false;\n+        }\n+\n+        ciField* field = vk->get_non_flat_field_by_offset(off);\n+        if (field != nullptr) {\n+          BasicType bt = type2field[field->type()->basic_type()];\n+          if (bt == T_ARRAY || bt == T_NARROWOOP) {\n+            bt = T_OBJECT;\n+          }\n+          if (bt == type && (!field->is_flat() || field->type() == inline_klass)) {\n+            Node* value = vt->field_value_by_offset(off, false);\n+            if (value->is_InlineType()) {\n+              value = value->as_InlineType()->adjust_scalarization_depth(this);\n+            }\n+            set_result(value);\n+            return true;\n+          }\n+        }\n+      }\n+      {\n+        \/\/ Re-execute the unsafe access if allocation triggers deoptimization.\n+        PreserveReexecuteState preexecs(this);\n+        jvms()->set_should_reexecute(true);\n+        vt = vt->buffer(this);\n+      }\n+      base = vt->get_oop();\n+    }\n+  }\n+\n@@ -2359,1 +2427,1 @@\n-    if (type != T_OBJECT) {\n+    if (type != T_OBJECT && (inline_klass == nullptr || !inline_klass->has_object_fields())) {\n@@ -2377,1 +2445,1 @@\n-  Node* val = is_store ? argument(4) : nullptr;\n+  Node* val = is_store ? argument(4 + (is_flat ? 1 : 0)) : nullptr;\n@@ -2398,1 +2466,22 @@\n-  BasicType bt = alias_type->basic_type();\n+  BasicType bt = T_ILLEGAL;\n+  ciField* field = nullptr;\n+  if (adr_type->isa_instptr()) {\n+    const TypeInstPtr* instptr = adr_type->is_instptr();\n+    ciInstanceKlass* k = instptr->instance_klass();\n+    int off = instptr->offset();\n+    if (instptr->const_oop() != nullptr &&\n+        k == ciEnv::current()->Class_klass() &&\n+        instptr->offset() >= (k->size_helper() * wordSize)) {\n+      k = instptr->const_oop()->as_instance()->java_lang_Class_klass()->as_instance_klass();\n+      field = k->get_field_by_offset(off, true);\n+    } else {\n+      field = k->get_non_flat_field_by_offset(off);\n+    }\n+    if (field != nullptr) {\n+      bt = type2field[field->type()->basic_type()];\n+    }\n+    assert(bt == alias_type->basic_type() || is_flat, \"should match\");\n+  } else {\n+    bt = alias_type->basic_type();\n+  }\n+\n@@ -2421,0 +2510,23 @@\n+  if (is_flat) {\n+    if (adr_type->isa_instptr()) {\n+      if (field == nullptr || field->type() != inline_klass) {\n+        mismatched = true;\n+      }\n+    } else if (adr_type->isa_aryptr()) {\n+      const Type* elem = adr_type->is_aryptr()->elem();\n+      if (!adr_type->is_flat() || elem->inline_klass() != inline_klass) {\n+        mismatched = true;\n+      }\n+    } else {\n+      mismatched = true;\n+    }\n+    if (is_store) {\n+      const Type* val_t = _gvn.type(val);\n+      if (!val_t->is_inlinetypeptr() || val_t->inline_klass() != inline_klass) {\n+        set_map(old_map);\n+        set_sp(old_sp);\n+        return false;\n+      }\n+    }\n+  }\n+\n@@ -2422,1 +2534,1 @@\n-  assert(!mismatched || alias_type->adr_type()->is_oopptr(), \"off-heap access can't be mismatched\");\n+  assert(!mismatched || is_flat || alias_type->adr_type()->is_oopptr(), \"off-heap access can't be mismatched\");\n@@ -2434,4 +2546,6 @@\n-  if (!is_store && type == T_OBJECT) {\n-    const TypeOopPtr* tjp = sharpen_unsafe_type(alias_type, adr_type);\n-    if (tjp != nullptr) {\n-      value_type = tjp;\n+  if (!is_store) {\n+    if (type == T_OBJECT && !is_flat) {\n+      const TypeOopPtr* tjp = sharpen_unsafe_type(alias_type, adr_type);\n+      if (tjp != nullptr) {\n+        value_type = tjp;\n+      }\n@@ -2453,2 +2567,2 @@\n-    ciField* field = alias_type->field();\n-    if (heap_base_oop != top() && field != nullptr && field->is_constant() && !mismatched) {\n+\n+    if (heap_base_oop != top() && field != nullptr && field->is_constant() && !field->is_flat() && !mismatched) {\n@@ -2460,1 +2574,16 @@\n-      p = access_load_at(heap_base_oop, adr, adr_type, value_type, type, decorators);\n+      if (is_flat) {\n+        if (adr_type->isa_instptr() && !mismatched) {\n+          ciInstanceKlass* holder = adr_type->is_instptr()->instance_klass();\n+          int offset = adr_type->is_instptr()->offset();\n+          p = InlineTypeNode::make_from_flat(this, inline_klass, base, base, holder, offset, false, -1, decorators);\n+        } else {\n+          p = InlineTypeNode::make_from_flat(this, inline_klass, base, adr, nullptr, 0, false, -1, decorators);\n+        }\n+      } else {\n+        p = access_load_at(heap_base_oop, adr, adr_type, value_type, type, decorators);\n+        const TypeOopPtr* ptr = value_type->make_oopptr();\n+        if (ptr != nullptr && ptr->is_inlinetypeptr()) {\n+          \/\/ Load a non-flattened inline type from memory\n+          p = InlineTypeNode::make_from_oop(this, p, ptr->inline_klass(), !ptr->maybe_null());\n+        }\n+      }\n@@ -2498,1 +2627,17 @@\n-    access_store_at(heap_base_oop, adr, adr_type, val, value_type, type, decorators);\n+    if (is_flat) {\n+      if (adr_type->isa_instptr() && !mismatched) {\n+        ciInstanceKlass* holder = adr_type->is_instptr()->instance_klass();\n+        int offset = adr_type->is_instptr()->offset();\n+        val->as_InlineType()->store_flat(this, base, base, holder, offset, false, -1, decorators);\n+      } else {\n+        val->as_InlineType()->store_flat(this, base, adr, nullptr, 0, false, -1, decorators);\n+      }\n+    } else {\n+      access_store_at(heap_base_oop, adr, adr_type, val, value_type, type, decorators);\n+    }\n+  }\n+\n+  if (argument(1)->is_InlineType() && is_store) {\n+    InlineTypeNode* value = InlineTypeNode::make_from_oop(this, base, _gvn.type(argument(1))->inline_klass());\n+    value = value->make_larval(this, false);\n+    replace_in_map(argument(1), value);\n@@ -2504,0 +2649,40 @@\n+bool LibraryCallKit::inline_unsafe_make_private_buffer() {\n+  Node* receiver = argument(0);\n+  Node* value = argument(1);\n+  if (!value->is_InlineType()) {\n+    return false;\n+  }\n+\n+  receiver = null_check(receiver);\n+  if (stopped()) {\n+    return true;\n+  }\n+\n+  set_result(value->as_InlineType()->make_larval(this, true));\n+  return true;\n+}\n+\n+bool LibraryCallKit::inline_unsafe_finish_private_buffer() {\n+  Node* receiver = argument(0);\n+  Node* buffer = argument(1);\n+  if (!buffer->is_InlineType()) {\n+    return false;\n+  }\n+  InlineTypeNode* vt = buffer->as_InlineType();\n+  if (!vt->is_allocated(&_gvn)) {\n+    return false;\n+  }\n+  \/\/ TODO 8239003 Why is this needed?\n+  if (AllocateNode::Ideal_allocation(vt->get_oop()) == nullptr) {\n+    return false;\n+  }\n+\n+  receiver = null_check(receiver);\n+  if (stopped()) {\n+    return true;\n+  }\n+\n+  set_result(vt->finish_larval(this));\n+  return true;\n+}\n+\n@@ -2709,0 +2894,13 @@\n+    if (oldval != nullptr && oldval->is_InlineType()) {\n+      \/\/ Re-execute the unsafe access if allocation triggers deoptimization.\n+      PreserveReexecuteState preexecs(this);\n+      jvms()->set_should_reexecute(true);\n+      oldval = oldval->as_InlineType()->buffer(this)->get_oop();\n+    }\n+    if (newval != nullptr && newval->is_InlineType()) {\n+      \/\/ Re-execute the unsafe access if allocation triggers deoptimization.\n+      PreserveReexecuteState preexecs(this);\n+      jvms()->set_should_reexecute(true);\n+      newval = newval->as_InlineType()->buffer(this)->get_oop();\n+    }\n+\n@@ -2895,2 +3093,7 @@\n-\n-  Node* obj = new_instance(kls, test);\n+  Node* obj = nullptr;\n+  const TypeInstKlassPtr* tkls = _gvn.type(kls)->isa_instklassptr();\n+  if (tkls != nullptr && tkls->instance_klass()->is_inlinetype()) {\n+    obj = InlineTypeNode::make_default(_gvn, tkls->instance_klass()->as_inline_klass())->buffer(this);\n+  } else {\n+    obj = new_instance(kls, test);\n+  }\n@@ -3678,1 +3881,1 @@\n-  const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS);\n+  const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS, \/* stable= *\/ false, \/* flat= *\/ false, \/* not_flat= *\/ true, \/* not_null_free= *\/ true);\n@@ -3683,1 +3886,1 @@\n-  const Type* objects_type = TypeAryPtr::make(TypePtr::BotPTR, arr0, objects_klass, xk, 0);\n+  const Type* objects_type = TypeAryPtr::make(TypePtr::BotPTR, arr0, objects_klass, xk, TypeAryPtr::Offset(0));\n@@ -3807,9 +4010,0 @@\n-\/\/---------------------------load_mirror_from_klass----------------------------\n-\/\/ Given a klass oop, load its java mirror (a java.lang.Class oop).\n-Node* LibraryCallKit::load_mirror_from_klass(Node* klass) {\n-  Node* p = basic_plus_adr(klass, in_bytes(Klass::java_mirror_offset()));\n-  Node* load = make_load(nullptr, p, TypeRawPtr::NOTNULL, T_ADDRESS, MemNode::unordered);\n-  \/\/ mirror = ((OopHandle)mirror)->resolve();\n-  return access_load(load, TypeInstPtr::MIRROR, T_OBJECT, IN_NATIVE);\n-}\n-\n@@ -3859,0 +4053,1 @@\n+\n@@ -4017,0 +4212,1 @@\n+\n@@ -4032,1 +4228,2 @@\n-  ciType* tm = mirror_con->java_mirror_type();\n+  bool is_null_free_array = false;\n+  ciType* tm = mirror_con->java_mirror_type(&is_null_free_array);\n@@ -4039,1 +4236,5 @@\n-      int static_res = C->static_subtype_check(TypeKlassPtr::make(tm->as_klass(), Type::trust_interfaces), tp->as_klass_type());\n+      const TypeKlassPtr* tklass = TypeKlassPtr::make(tm->as_klass(), Type::trust_interfaces);\n+      if (is_null_free_array) {\n+        tklass = tklass->is_aryklassptr()->cast_to_null_free();\n+      }\n+      int static_res = C->static_subtype_check(tklass, tp->as_klass_type());\n@@ -4068,2 +4269,2 @@\n-  \/\/ Not-subtype or the mirror's klass ptr is null (in case it is a primitive).\n-  enum { _bad_type_path = 1, _prim_path = 2, PATH_LIMIT };\n+  \/\/ Not-subtype or the mirror's klass ptr is nullptr (in case it is a primitive).\n+  enum { _bad_type_path = 1, _prim_path = 2, _npe_path = 3, PATH_LIMIT };\n@@ -4079,0 +4280,2 @@\n+  Node* io = i_o();\n+  Node* mem = merged_memory();\n@@ -4080,0 +4283,1 @@\n+\n@@ -4086,1 +4290,2 @@\n-      region->in(_bad_type_path) != top()) {\n+      region->in(_bad_type_path) != top() ||\n+      region->in(_npe_path) != top()) {\n@@ -4090,0 +4295,3 @@\n+    \/\/ Set IO and memory because gen_checkcast may override them when buffering inline types\n+    set_i_o(io);\n+    set_all_memory(mem);\n@@ -4123,0 +4331,1 @@\n+  RegionNode* prim_region = new RegionNode(2);\n@@ -4125,0 +4334,1 @@\n+  record_for_igvn(prim_region);\n@@ -4149,2 +4359,5 @@\n-    int prim_path = (which_arg == 0 ? _prim_0_path : _prim_1_path);\n-    region->init_req(prim_path, null_ctl);\n+    if (which_arg == 0) {\n+      prim_region->init_req(1, null_ctl);\n+    } else {\n+      region->init_req(_prim_1_path, null_ctl);\n+    }\n@@ -4160,1 +4373,0 @@\n-    \/\/ now we have a successful reference subtype check\n@@ -4167,1 +4379,2 @@\n-  set_control(region->in(_prim_0_path)); \/\/ go back to first null check\n+  \/\/ This path is also used if superc is a value mirror.\n+  set_control(_gvn.transform(prim_region));\n@@ -4172,1 +4385,1 @@\n-    generate_guard(bol_eq, region, PROB_FAIR);\n+    generate_fair_guard(bol_eq, region);\n@@ -4203,2 +4416,1 @@\n-Node* LibraryCallKit::generate_array_guard_common(Node* kls, RegionNode* region,\n-                                                  bool obj_array, bool not_array, Node** obj) {\n+Node* LibraryCallKit::generate_array_guard_common(Node* kls, RegionNode* region, ArrayKind kind, Node** obj) {\n@@ -4210,9 +4422,0 @@\n-  \/\/ If obj_array\/non_array==false\/false:\n-  \/\/ Branch around if the given klass is in fact an array (either obj or prim).\n-  \/\/ If obj_array\/non_array==false\/true:\n-  \/\/ Branch around if the given klass is not an array klass of any kind.\n-  \/\/ If obj_array\/non_array==true\/true:\n-  \/\/ Branch around if the kls is not an oop array (kls is int[], String, etc.)\n-  \/\/ If obj_array\/non_array==true\/false:\n-  \/\/ Branch around if the kls is an oop array (Object[] or subtype)\n-  \/\/\n@@ -4223,4 +4426,11 @@\n-    bool query = (obj_array\n-                  ? Klass::layout_helper_is_objArray(layout_con)\n-                  : Klass::layout_helper_is_array(layout_con));\n-    if (query == not_array) {\n+    bool query = 0;\n+    switch(kind) {\n+      case ObjectArray:    query = Klass::layout_helper_is_objArray(layout_con); break;\n+      case NonObjectArray: query = !Klass::layout_helper_is_objArray(layout_con); break;\n+      case TypeArray:      query = Klass::layout_helper_is_typeArray(layout_con); break;\n+      case AnyArray:       query = Klass::layout_helper_is_array(layout_con); break;\n+      case NonArray:       query = !Klass::layout_helper_is_array(layout_con); break;\n+      default:\n+        ShouldNotReachHere();\n+    }\n+    if (!query) {\n@@ -4236,0 +4446,21 @@\n+  unsigned int value = 0;\n+  BoolTest::mask btest = BoolTest::illegal;\n+  switch(kind) {\n+    case ObjectArray:\n+    case NonObjectArray: {\n+      value = Klass::_lh_array_tag_obj_value;\n+      layout_val = _gvn.transform(new RShiftINode(layout_val, intcon(Klass::_lh_array_tag_shift)));\n+      btest = (kind == ObjectArray) ? BoolTest::eq : BoolTest::ne;\n+      break;\n+    }\n+    case TypeArray: {\n+      value = Klass::_lh_array_tag_type_value;\n+      layout_val = _gvn.transform(new RShiftINode(layout_val, intcon(Klass::_lh_array_tag_shift)));\n+      btest = BoolTest::eq;\n+      break;\n+    }\n+    case AnyArray:    value = Klass::_lh_neutral_value; btest = BoolTest::lt; break;\n+    case NonArray:    value = Klass::_lh_neutral_value; btest = BoolTest::gt; break;\n+    default:\n+      ShouldNotReachHere();\n+  }\n@@ -4237,4 +4468,1 @@\n-  jint  nval = (obj_array\n-                ? (jint)(Klass::_lh_array_tag_type_value\n-                   <<    Klass::_lh_array_tag_shift)\n-                : Klass::_lh_neutral_value);\n+  jint nval = (jint)value;\n@@ -4242,3 +4470,0 @@\n-  BoolTest::mask btest = BoolTest::lt;  \/\/ correct for testing is_[obj]array\n-  \/\/ invert the test if we are looking for a non-array\n-  if (not_array)  btest = BoolTest(btest).negate();\n@@ -4247,1 +4472,1 @@\n-  Node* is_array_ctrl = not_array ? control() : ctrl;\n+  Node* is_array_ctrl = kind == NonArray ? control() : ctrl;\n@@ -4261,0 +4486,26 @@\n+\/\/-----------------------inline_newNullRestrictedArray--------------------------\n+\/\/ public static native Object[] newNullRestrictedArray(Class<?> componentType, int length);\n+bool LibraryCallKit::inline_newNullRestrictedArray() {\n+  Node* componentType = argument(0);\n+  Node* length = argument(1);\n+\n+  const TypeInstPtr* tp = _gvn.type(componentType)->isa_instptr();\n+  if (tp != nullptr) {\n+    ciInstanceKlass* ik = tp->instance_klass();\n+    if (ik == C->env()->Class_klass()) {\n+      ciType* t = tp->java_mirror_type();\n+      if (t != nullptr && t->is_inlinetype()) {\n+        ciArrayKlass* array_klass = ciArrayKlass::make(t, true);\n+        if (array_klass->is_loaded() && array_klass->element_klass()->as_inline_klass()->is_initialized()) {\n+          const TypeAryKlassPtr* array_klass_type = TypeKlassPtr::make(array_klass, Type::trust_interfaces)->is_aryklassptr();\n+          array_klass_type = array_klass_type->cast_to_null_free();\n+          Node* obj = new_array(makecon(array_klass_type), length, 0, nullptr, false);  \/\/ no arguments to push\n+          set_result(obj);\n+          assert(gvn().type(obj)->is_aryptr()->is_null_free(), \"must be null-free\");\n+          return true;\n+        }\n+      }\n+    }\n+  }\n+  return false;\n+}\n@@ -4263,1 +4514,1 @@\n-\/\/ private static native Object java.lang.reflect.newArray(Class<?> componentType, int length);\n+\/\/ private static native Object java.lang.reflect.Array.newArray(Class<?> componentType, int length);\n@@ -4409,1 +4660,13 @@\n-    Node* not_objArray = generate_non_objArray_guard(klass_node, bailout);\n+    \/\/ Inline type array may have object field that would require a\n+    \/\/ write barrier. Conservatively, go to slow path.\n+    \/\/ TODO 8251971: Optimize for the case when flat src\/dst are later found\n+    \/\/ to not contain oops (i.e., move this check to the macro expansion phase).\n+    BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();\n+    const TypeAryPtr* orig_t = _gvn.type(original)->isa_aryptr();\n+    const TypeKlassPtr* tklass = _gvn.type(klass_node)->is_klassptr();\n+    bool exclude_flat = UseArrayFlattening && bs->array_copy_requires_gc_barriers(true, T_OBJECT, false, false, BarrierSetC2::Parsing) &&\n+                        \/\/ Can src array be flat and contain oops?\n+                        (orig_t == nullptr || (!orig_t->is_not_flat() && (!orig_t->is_flat() || orig_t->elem()->inline_klass()->contains_oops()))) &&\n+                        \/\/ Can dest array be flat and contain oops?\n+                        tklass->can_be_inline_array() && (!tklass->is_flat() || tklass->is_aryklassptr()->elem()->is_instklassptr()->instance_klass()->as_inline_klass()->contains_oops());\n+    Node* not_objArray = exclude_flat ? generate_non_objArray_guard(klass_node, bailout) : generate_typeArray_guard(klass_node, bailout);\n@@ -4413,1 +4676,1 @@\n-      const Type* akls = TypeKlassPtr::make(TypePtr::NotNull, ak, 0\/*offset*\/);\n+      const Type* akls = TypeKlassPtr::make(TypePtr::NotNull, ak, Type::Offset(0));\n@@ -4433,0 +4696,38 @@\n+    \/\/ Handle inline type arrays\n+    bool can_validate = !too_many_traps(Deoptimization::Reason_class_check);\n+    if (!stopped()) {\n+      \/\/ TODO JDK-8329224\n+      if (!orig_t->is_null_free()) {\n+        \/\/ Not statically known to be null free, add a check\n+        generate_fair_guard(null_free_array_test(original), bailout);\n+      }\n+      orig_t = _gvn.type(original)->isa_aryptr();\n+      if (orig_t != nullptr && orig_t->is_flat()) {\n+        \/\/ Src is flat, check that dest is flat as well\n+        if (exclude_flat) {\n+          \/\/ Dest can't be flat, bail out\n+          bailout->add_req(control());\n+          set_control(top());\n+        } else {\n+          generate_fair_guard(flat_array_test(klass_node, \/* flat = *\/ false), bailout);\n+        }\n+      } else if (UseArrayFlattening && (orig_t == nullptr || !orig_t->is_not_flat()) &&\n+                 \/\/ If dest is flat, src must be flat as well (guaranteed by src <: dest check if validated).\n+                 ((!tklass->is_flat() && tklass->can_be_inline_array()) || !can_validate)) {\n+        \/\/ Src might be flat and dest might not be flat. Go to the slow path if src is flat.\n+        \/\/ TODO 8251971: Optimize for the case when src\/dest are later found to be both flat.\n+        generate_fair_guard(flat_array_test(load_object_klass(original)), bailout);\n+        if (orig_t != nullptr) {\n+          orig_t = orig_t->cast_to_not_flat();\n+          original = _gvn.transform(new CheckCastPPNode(control(), original, orig_t));\n+        }\n+      }\n+      if (!can_validate) {\n+        \/\/ No validation. The subtype check emitted at macro expansion time will not go to the slow\n+        \/\/ path but call checkcast_arraycopy which can not handle flat\/null-free inline type arrays.\n+        \/\/ TODO 8251971: Optimize for the case when src\/dest are later found to be both flat\/null-free.\n+        generate_fair_guard(flat_array_test(klass_node), bailout);\n+        generate_fair_guard(null_free_array_test(original), bailout);\n+      }\n+    }\n+\n@@ -4478,1 +4779,1 @@\n-      if (!too_many_traps(Deoptimization::Reason_class_check)) {\n+      if (can_validate) {\n@@ -4564,1 +4865,1 @@\n-    const TypeTuple* range = tf->range();\n+    const TypeTuple* range = tf->range_cc();\n@@ -4568,1 +4869,1 @@\n-    tf = TypeFunc::make(tf->domain(), new_range);\n+    tf = TypeFunc::make(tf->domain_cc(), new_range);\n@@ -4625,1 +4926,8 @@\n-  Node* obj = nullptr;\n+  Node* obj = argument(0);\n+\n+  \/\/ Don't intrinsify hashcode on inline types for now.\n+  \/\/ The \"is locked\" runtime check below also serves as inline type check and goes to the slow path.\n+  if (gvn().type(obj)->is_inlinetypeptr()) {\n+    return false;\n+  }\n+\n@@ -4635,1 +4943,0 @@\n-    obj = argument(0);\n@@ -4676,1 +4983,2 @@\n-    Node *lock_mask      = _gvn.MakeConX(markWord::lock_mask_in_place);\n+  \/\/ This also serves as guard against inline types\n+    Node *lock_mask      = _gvn.MakeConX(markWord::inline_type_mask_in_place);\n@@ -4751,1 +5059,10 @@\n-  Node* obj = null_check_receiver();\n+  Node* obj = argument(0);\n+  if (obj->is_InlineType()) {\n+    const Type* t = _gvn.type(obj);\n+    if (t->maybe_null()) {\n+      null_check(obj);\n+    }\n+    set_result(makecon(TypeInstPtr::make(t->inline_klass()->java_mirror())));\n+    return true;\n+  }\n+  obj = null_check_receiver();\n@@ -5103,0 +5420,14 @@\n+\/\/----------------------inline_unsafe_isFlatArray------------------------\n+\/\/ public native boolean Unsafe.isFlatArray(Class<?> arrayClass);\n+\/\/ This intrinsic exploits assumptions made by the native implementation\n+\/\/ (arrayClass is neither null nor primitive) to avoid unnecessary null checks.\n+bool LibraryCallKit::inline_unsafe_isFlatArray() {\n+  Node* cls = argument(1);\n+  Node* p = basic_plus_adr(cls, java_lang_Class::klass_offset());\n+  Node* kls = _gvn.transform(LoadKlassNode::make(_gvn, immutable_memory(), p,\n+                                                 TypeRawPtr::BOTTOM, TypeInstKlassPtr::OBJECT));\n+  Node* result = flat_array_test(kls);\n+  set_result(result);\n+  return true;\n+}\n+\n@@ -5173,1 +5504,2 @@\n-    Node* obj = null_check_receiver();\n+    Node* obj = argument(0);\n+    obj = null_check_receiver();\n@@ -5177,0 +5509,6 @@\n+    if (obj_type->is_inlinetypeptr()) {\n+      \/\/ If the object to clone is an inline type, we can simply return it (i.e. a nop) since inline types have\n+      \/\/ no identity.\n+      set_result(obj);\n+      return true;\n+    }\n@@ -5183,1 +5521,2 @@\n-        obj_type->speculative_type()->is_instance_klass()) {\n+        obj_type->speculative_type()->is_instance_klass() &&\n+        !obj_type->speculative_type()->is_inlinetype()) {\n@@ -5213,0 +5552,5 @@\n+    \/\/ We only go to the fast case code if we pass a number of guards.\n+    \/\/ The paths which do not pass are accumulated in the slow_region.\n+    RegionNode* slow_region = new RegionNode(1);\n+    record_for_igvn(slow_region);\n+\n@@ -5219,3 +5563,0 @@\n-      Node* obj_length = load_array_length(array_obj);\n-      Node* array_size = nullptr; \/\/ Size of the array without object alignment padding.\n-      Node* alloc_obj = new_array(obj_klass, obj_length, 0, &array_size, \/*deoptimize_on_exception=*\/true);\n@@ -5224,20 +5565,7 @@\n-      if (bs->array_copy_requires_gc_barriers(true, T_OBJECT, true, false, BarrierSetC2::Parsing)) {\n-        \/\/ If it is an oop array, it requires very special treatment,\n-        \/\/ because gc barriers are required when accessing the array.\n-        Node* is_obja = generate_objArray_guard(obj_klass, (RegionNode*)nullptr);\n-        if (is_obja != nullptr) {\n-          PreserveJVMState pjvms2(this);\n-          set_control(is_obja);\n-          \/\/ Generate a direct call to the right arraycopy function(s).\n-          \/\/ Clones are always tightly coupled.\n-          ArrayCopyNode* ac = ArrayCopyNode::make(this, true, array_obj, intcon(0), alloc_obj, intcon(0), obj_length, true, false);\n-          ac->set_clone_oop_array();\n-          Node* n = _gvn.transform(ac);\n-          assert(n == ac, \"cannot disappear\");\n-          ac->connect_outputs(this, \/*deoptimize_on_exception=*\/true);\n-\n-          result_reg->init_req(_objArray_path, control());\n-          result_val->init_req(_objArray_path, alloc_obj);\n-          result_i_o ->set_req(_objArray_path, i_o());\n-          result_mem ->set_req(_objArray_path, reset_memory());\n-        }\n+      const TypeAryPtr* ary_ptr = obj_type->isa_aryptr();\n+      if (UseArrayFlattening && bs->array_copy_requires_gc_barriers(true, T_OBJECT, true, false, BarrierSetC2::Expansion) &&\n+          obj_type->can_be_inline_array() &&\n+          (ary_ptr == nullptr || (!ary_ptr->is_not_flat() && (!ary_ptr->is_flat() || ary_ptr->elem()->inline_klass()->contains_oops())))) {\n+        \/\/ Flat inline type array may have object field that would require a\n+        \/\/ write barrier. Conservatively, go to slow path.\n+        generate_fair_guard(flat_array_test(obj_klass), slow_region);\n@@ -5245,7 +5573,0 @@\n-      \/\/ Otherwise, there are no barriers to worry about.\n-      \/\/ (We can dispense with card marks if we know the allocation\n-      \/\/  comes out of eden (TLAB)...  In fact, ReduceInitialCardMarks\n-      \/\/  causes the non-eden paths to take compensating steps to\n-      \/\/  simulate a fresh allocation, so that no further\n-      \/\/  card marks are required in compiled code to initialize\n-      \/\/  the object.)\n@@ -5254,7 +5575,43 @@\n-        copy_to_clone(array_obj, alloc_obj, array_size, true);\n-\n-        \/\/ Present the results of the copy.\n-        result_reg->init_req(_array_path, control());\n-        result_val->init_req(_array_path, alloc_obj);\n-        result_i_o ->set_req(_array_path, i_o());\n-        result_mem ->set_req(_array_path, reset_memory());\n+        Node* obj_length = load_array_length(array_obj);\n+        Node* array_size = nullptr; \/\/ Size of the array without object alignment padding.\n+        Node* alloc_obj = new_array(obj_klass, obj_length, 0, &array_size, \/*deoptimize_on_exception=*\/true);\n+\n+        BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();\n+        if (bs->array_copy_requires_gc_barriers(true, T_OBJECT, true, false, BarrierSetC2::Parsing)) {\n+          \/\/ If it is an oop array, it requires very special treatment,\n+          \/\/ because gc barriers are required when accessing the array.\n+          Node* is_obja = generate_objArray_guard(obj_klass, (RegionNode*)nullptr);\n+          if (is_obja != nullptr) {\n+            PreserveJVMState pjvms2(this);\n+            set_control(is_obja);\n+            \/\/ Generate a direct call to the right arraycopy function(s).\n+            \/\/ Clones are always tightly coupled.\n+            ArrayCopyNode* ac = ArrayCopyNode::make(this, true, array_obj, intcon(0), alloc_obj, intcon(0), obj_length, true, false);\n+            ac->set_clone_oop_array();\n+            Node* n = _gvn.transform(ac);\n+            assert(n == ac, \"cannot disappear\");\n+            ac->connect_outputs(this, \/*deoptimize_on_exception=*\/true);\n+\n+            result_reg->init_req(_objArray_path, control());\n+            result_val->init_req(_objArray_path, alloc_obj);\n+            result_i_o ->set_req(_objArray_path, i_o());\n+            result_mem ->set_req(_objArray_path, reset_memory());\n+          }\n+        }\n+        \/\/ Otherwise, there are no barriers to worry about.\n+        \/\/ (We can dispense with card marks if we know the allocation\n+        \/\/  comes out of eden (TLAB)...  In fact, ReduceInitialCardMarks\n+        \/\/  causes the non-eden paths to take compensating steps to\n+        \/\/  simulate a fresh allocation, so that no further\n+        \/\/  card marks are required in compiled code to initialize\n+        \/\/  the object.)\n+\n+        if (!stopped()) {\n+          copy_to_clone(obj, alloc_obj, array_size, true);\n+\n+          \/\/ Present the results of the copy.\n+          result_reg->init_req(_array_path, control());\n+          result_val->init_req(_array_path, alloc_obj);\n+          result_i_o ->set_req(_array_path, i_o());\n+          result_mem ->set_req(_array_path, reset_memory());\n+        }\n@@ -5264,4 +5621,0 @@\n-    \/\/ We only go to the instance fast case code if we pass a number of guards.\n-    \/\/ The paths which do not pass are accumulated in the slow_region.\n-    RegionNode* slow_region = new RegionNode(1);\n-    record_for_igvn(slow_region);\n@@ -5399,0 +5752,12 @@\n+  int adjustment = 1;\n+  const TypeAryKlassPtr* ary_klass_ptr = alloc->in(AllocateNode::KlassNode)->bottom_type()->is_aryklassptr();\n+  if (ary_klass_ptr->is_null_free()) {\n+    \/\/ A null-free, tightly coupled array allocation can only come from LibraryCallKit::inline_newNullRestrictedArray\n+    \/\/ which requires both the component type and the array length on stack for re-execution. Re-create and push\n+    \/\/ the component type.\n+    ciArrayKlass* klass = ary_klass_ptr->exact_klass()->as_array_klass();\n+    ciInstance* instance = klass->component_mirror_instance();\n+    const TypeInstPtr* t_instance = TypeInstPtr::make(instance);\n+    sfpt->ins_req(old_jvms->stkoff() + old_jvms->sp(), makecon(t_instance));\n+    adjustment++;\n+  }\n@@ -5400,5 +5765,5 @@\n-  sfpt->ins_req(old_jvms->stkoff() + old_jvms->sp(), alloc->in(AllocateNode::ALength));\n-  old_jvms->set_sp(old_jvms->sp()+1);\n-  old_jvms->set_monoff(old_jvms->monoff()+1);\n-  old_jvms->set_scloff(old_jvms->scloff()+1);\n-  old_jvms->set_endoff(old_jvms->endoff()+1);\n+  sfpt->ins_req(old_jvms->stkoff() + old_jvms->sp() + adjustment - 1, alloc->in(AllocateNode::ALength));\n+  old_jvms->set_sp(old_jvms->sp() + adjustment);\n+  old_jvms->set_monoff(old_jvms->monoff() + adjustment);\n+  old_jvms->set_scloff(old_jvms->scloff() + adjustment);\n+  old_jvms->set_endoff(old_jvms->endoff() + adjustment);\n@@ -5437,2 +5802,1 @@\n-    CallProjections callprojs;\n-    alloc->extract_projections(&callprojs, true);\n+    CallProjections* callprojs = alloc->extract_projections(true);\n@@ -5441,1 +5805,1 @@\n-    C->gvn_replace_by(callprojs.fallthrough_ioproj, alloc->in(TypeFunc::I_O));\n+    C->gvn_replace_by(callprojs->fallthrough_ioproj, alloc->in(TypeFunc::I_O));\n@@ -5483,1 +5847,1 @@\n-    set_i_o(callprojs.fallthrough_ioproj);\n+    set_i_o(callprojs->fallthrough_ioproj);\n@@ -5821,1 +6185,1 @@\n-    if (src_elem == dest_elem && src_elem == T_OBJECT) {\n+    if (src_elem == dest_elem && top_src->is_flat() == top_dest->is_flat() && src_elem == T_OBJECT) {\n@@ -5848,0 +6212,2 @@\n+          src_type = _gvn.type(src);\n+          top_src = src_type->isa_aryptr();\n@@ -5851,0 +6217,2 @@\n+          dest_type = _gvn.type(dest);\n+          top_dest = dest_type->isa_aryptr();\n@@ -5866,2 +6234,1 @@\n-      can_emit_guards &&\n-      !src->is_top() && !dest->is_top()) {\n+      can_emit_guards && !src->is_top() && !dest->is_top()) {\n@@ -5910,0 +6277,2 @@\n+      slow_region->add_req(not_subtype_ctrl);\n+    }\n@@ -5911,6 +6280,28 @@\n-      if (not_subtype_ctrl != top()) {\n-        PreserveJVMState pjvms(this);\n-        set_control(not_subtype_ctrl);\n-        uncommon_trap(Deoptimization::Reason_intrinsic,\n-                      Deoptimization::Action_make_not_entrant);\n-        assert(stopped(), \"Should be stopped\");\n+    const TypeKlassPtr* dest_klass_t = _gvn.type(dest_klass)->is_klassptr();\n+    const Type* toop = dest_klass_t->cast_to_exactness(false)->as_instance_type();\n+    src = _gvn.transform(new CheckCastPPNode(control(), src, toop));\n+    src_type = _gvn.type(src);\n+    top_src  = src_type->isa_aryptr();\n+\n+    \/\/ Handle flat inline type arrays (null-free arrays are handled by the subtype check above)\n+    if (!stopped() && UseArrayFlattening) {\n+      \/\/ If dest is flat, src must be flat as well (guaranteed by src <: dest check). Handle flat src here.\n+      assert(top_dest == nullptr || !top_dest->is_flat() || top_src->is_flat(), \"src array must be flat\");\n+      if (top_src != nullptr && top_src->is_flat()) {\n+        \/\/ Src is flat, check that dest is flat as well\n+        if (top_dest != nullptr && !top_dest->is_flat()) {\n+          generate_fair_guard(flat_array_test(dest_klass, \/* flat = *\/ false), slow_region);\n+          \/\/ Since dest is flat and src <: dest, dest must have the same type as src.\n+          top_dest = top_src->cast_to_exactness(false);\n+          assert(top_dest->is_flat(), \"dest must be flat\");\n+          dest = _gvn.transform(new CheckCastPPNode(control(), dest, top_dest));\n+        }\n+      } else if (top_src == nullptr || !top_src->is_not_flat()) {\n+        \/\/ Src might be flat and dest might not be flat. Go to the slow path if src is flat.\n+        \/\/ TODO 8251971: Optimize for the case when src\/dest are later found to be both flat.\n+        assert(top_dest == nullptr || !top_dest->is_flat(), \"dest array must not be flat\");\n+        generate_fair_guard(flat_array_test(src), slow_region);\n+        if (top_src != nullptr) {\n+          top_src = top_src->cast_to_not_flat();\n+          src = _gvn.transform(new CheckCastPPNode(control(), src, top_src));\n+        }\n@@ -5919,0 +6310,1 @@\n+\n@@ -5926,4 +6318,0 @@\n-\n-    const TypeKlassPtr* dest_klass_t = _gvn.type(dest_klass)->is_klassptr();\n-    const Type *toop = dest_klass_t->cast_to_exactness(false)->as_instance_type();\n-    src = _gvn.transform(new CheckCastPPNode(control(), src, toop));\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":524,"deletions":136,"binary":false,"changes":660,"status":"modified"},{"patch":"@@ -46,0 +46,1 @@\n+class UnswitchCandidate;\n@@ -82,1 +83,2 @@\n-         LoopNestLongOuterLoop = 1<<16 };\n+         LoopNestLongOuterLoop = 1<<16,\n+         FlatArrays            = 1<<17};\n@@ -105,0 +107,1 @@\n+  bool is_flat_arrays() const { return _loop_flags & FlatArrays; }\n@@ -118,0 +121,1 @@\n+  void mark_flat_arrays() { _loop_flags |= FlatArrays; }\n@@ -693,0 +697,1 @@\n+  bool no_unswitch_candidate() const;\n@@ -1444,1 +1449,2 @@\n-  IfNode* find_unswitch_candidate(const IdealLoopTree* loop) const;\n+  IfNode* find_unswitch_candidates(const IdealLoopTree* loop, Node_List& flat_array_checks) const;\n+  IfNode* find_unswitch_candidate_from_idoms(const IdealLoopTree* loop) const;\n@@ -1451,1 +1457,1 @@\n-                                   const UnswitchedLoopSelector& unswitched_loop_selector);\n+                                   const UnswitchCandidate& unswitch_candidate, const IfNode* loop_selector);\n@@ -1459,0 +1465,1 @@\n+                                            const UnswitchCandidate& unswitch_candidate,\n@@ -1593,0 +1600,1 @@\n+  void move_flat_array_check_out_of_loop(Node* n);\n@@ -1594,0 +1602,1 @@\n+  bool flat_array_element_type_check(Node *n);\n@@ -1783,0 +1792,2 @@\n+  void collect_flat_array_checks(const IdealLoopTree* loop, Node_List& flat_array_checks) const;\n+\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":14,"deletions":3,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -56,0 +56,2 @@\n+#include \"oops\/flatArrayOop.inline.hpp\"\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -423,0 +425,1 @@\n+  bool is_flat = InstanceKlass::cast(k1)->field_is_flat(slot);\n@@ -424,1 +427,1 @@\n-  ret = jfieldIDWorkaround::to_instance_jfieldID(k1, offset);\n+  ret = jfieldIDWorkaround::to_instance_jfieldID(k1, offset, is_flat);\n@@ -441,1 +444,1 @@\n-  if (m->is_object_initializer()) {\n+  if (m->is_object_constructor()) {\n@@ -800,1 +803,1 @@\n-    case T_OBJECT:      push_object(va_arg(_ap, jobject)); break;\n+    case T_OBJECT: push_object(va_arg(_ap, jobject)); break;\n@@ -840,1 +843,2 @@\n-    case T_OBJECT:      push_object((_ap++)->l); break;\n+    case T_OBJECT:\n+    case T_FLAT_ELEMENT: push_object((_ap++)->l); break;\n@@ -967,1 +971,7 @@\n-  instanceOop i = InstanceKlass::allocate_instance(JNIHandles::resolve_non_null(clazz), CHECK_NULL);\n+  oop clazzoop = JNIHandles::resolve_non_null(clazz);\n+  Klass* k = java_lang_Class::as_Klass(clazzoop);\n+  if (k == nullptr || k->is_inline_klass()) {\n+    ResourceMark rm(THREAD);\n+    THROW_(vmSymbols::java_lang_InstantiationException(), nullptr);\n+  }\n+  instanceOop i = InstanceKlass::allocate_instance(clazzoop, CHECK_NULL);\n@@ -981,1 +991,8 @@\n-  instanceOop i = InstanceKlass::allocate_instance(JNIHandles::resolve_non_null(clazz), CHECK_NULL);\n+  oop clazzoop = JNIHandles::resolve_non_null(clazz);\n+  Klass* k = java_lang_Class::as_Klass(clazzoop);\n+  if (k == nullptr) {\n+    ResourceMark rm(THREAD);\n+    THROW_(vmSymbols::java_lang_InstantiationException(), nullptr);\n+  }\n+\n+  instanceOop i = InstanceKlass::allocate_instance(clazzoop, CHECK_NULL);\n@@ -986,0 +1003,1 @@\n+\n@@ -987,1 +1005,1 @@\n-JNI_END\n+  JNI_END\n@@ -999,1 +1017,8 @@\n-  instanceOop i = InstanceKlass::allocate_instance(JNIHandles::resolve_non_null(clazz), CHECK_NULL);\n+  oop clazzoop = JNIHandles::resolve_non_null(clazz);\n+  Klass* k = java_lang_Class::as_Klass(clazzoop);\n+  if (k == nullptr) {\n+    ResourceMark rm(THREAD);\n+    THROW_(vmSymbols::java_lang_InstantiationException(), nullptr);\n+  }\n+\n+  instanceOop i = InstanceKlass::allocate_instance(clazzoop, CHECK_NULL);\n@@ -1004,0 +1029,1 @@\n+\n@@ -1017,1 +1043,8 @@\n-  instanceOop i = InstanceKlass::allocate_instance(JNIHandles::resolve_non_null(clazz), CHECK_NULL);\n+  oop clazzoop = JNIHandles::resolve_non_null(clazz);\n+  Klass* k = java_lang_Class::as_Klass(clazzoop);\n+  if (k == nullptr) {\n+    ResourceMark rm(THREAD);\n+    THROW_(vmSymbols::java_lang_InstantiationException(), nullptr);\n+  }\n+\n+  instanceOop i = InstanceKlass::allocate_instance(clazzoop, CHECK_NULL);\n@@ -1025,0 +1058,1 @@\n+\n@@ -1775,1 +1809,1 @@\n-  ret = jfieldIDWorkaround::to_instance_jfieldID(k, fd.offset());\n+  ret = jfieldIDWorkaround::to_instance_jfieldID(k, fd.offset(), fd.is_flat());\n@@ -1785,0 +1819,1 @@\n+  oop res = nullptr;\n@@ -1790,2 +1825,15 @@\n-  oop loaded_obj = HeapAccess<ON_UNKNOWN_OOP_REF>::oop_load_at(o, offset);\n-  jobject ret = JNIHandles::make_local(THREAD, loaded_obj);\n+  if (!jfieldIDWorkaround::is_flat_jfieldID(fieldID)) {\n+    res = HeapAccess<ON_UNKNOWN_OOP_REF>::oop_load_at(o, offset);\n+  } else {\n+    assert(k->is_instance_klass(), \"Only instance can have flat fields\");\n+    InstanceKlass* ik = InstanceKlass::cast(k);\n+    fieldDescriptor fd;\n+    bool found = ik->find_field_from_offset(offset, false, &fd);  \/\/ performance bottleneck\n+    assert(found, \"Field not found\");\n+    InstanceKlass* holder = fd.field_holder();\n+    assert(holder->field_is_flat(fd.index()), \"Must be\");\n+    InlineLayoutInfo* li = holder->inline_layout_info_adr(fd.index());\n+    InlineKlass* field_vklass = li->klass();\n+    res = field_vklass->read_payload_from_addr(o, ik->field_offset(fd.index()), li->kind(), CHECK_NULL);\n+  }\n+  jobject ret = JNIHandles::make_local(THREAD, res);\n@@ -1796,2 +1844,0 @@\n-\n-\n@@ -1883,1 +1929,13 @@\n-  HeapAccess<ON_UNKNOWN_OOP_REF>::oop_store_at(o, offset, JNIHandles::resolve(value));\n+  if (!jfieldIDWorkaround::is_flat_jfieldID(fieldID)) {\n+    HeapAccess<ON_UNKNOWN_OOP_REF>::oop_store_at(o, offset, JNIHandles::resolve(value));\n+  } else {\n+    assert(k->is_instance_klass(), \"Only instances can have flat fields\");\n+    InstanceKlass* ik = InstanceKlass::cast(k);\n+    fieldDescriptor fd;\n+    ik->find_field_from_offset(offset, false, &fd);\n+    InstanceKlass* holder = fd.field_holder();\n+    InlineLayoutInfo* li = holder->inline_layout_info_adr(fd.index());\n+    InlineKlass* vklass = li->klass();\n+    oop v = JNIHandles::resolve_non_null(value);\n+    vklass->write_value_to_addr(v, ((char*)(oopDesc*)obj) + offset, li->kind(), true, CHECK);\n+  }\n@@ -2308,4 +2366,12 @@\n-  objArrayOop a = objArrayOop(JNIHandles::resolve_non_null(array));\n-  if (a->is_within_bounds(index)) {\n-    ret = JNIHandles::make_local(THREAD, a->obj_at(index));\n-    return ret;\n+  oop res = nullptr;\n+  arrayOop arr((arrayOop)JNIHandles::resolve_non_null(array));\n+  if (arr->is_within_bounds(index)) {\n+    if (arr->is_flatArray()) {\n+      flatArrayOop a = flatArrayOop(JNIHandles::resolve_non_null(array));\n+      res = a->read_value_from_flat_array(index, CHECK_NULL);\n+      assert(res != nullptr, \"Must be set in one of two paths above\");\n+    } else {\n+      assert(arr->is_objArray(), \"If not a valueArray. must be an objArray\");\n+      objArrayOop a = objArrayOop(JNIHandles::resolve_non_null(array));\n+      res = a->obj_at(index);\n+    }\n@@ -2315,1 +2381,1 @@\n-    ss.print(\"Index %d out of bounds for length %d\", index, a->length());\n+    ss.print(\"Index %d out of bounds for length %d\", index,arr->length());\n@@ -2318,0 +2384,2 @@\n+  ret = JNIHandles::make_local(THREAD, res);\n+  return ret;\n@@ -2327,24 +2395,51 @@\n-  objArrayOop a = objArrayOop(JNIHandles::resolve_non_null(array));\n-  oop v = JNIHandles::resolve(value);\n-  if (a->is_within_bounds(index)) {\n-    if (v == nullptr || v->is_a(ObjArrayKlass::cast(a->klass())->element_klass())) {\n-      a->obj_at_put(index, v);\n-    } else {\n-      ResourceMark rm(THREAD);\n-      stringStream ss;\n-      Klass *bottom_kl = ObjArrayKlass::cast(a->klass())->bottom_klass();\n-      ss.print(\"type mismatch: can not store %s to %s[%d]\",\n-               v->klass()->external_name(),\n-               bottom_kl->is_typeArray_klass() ? type2name_tab[ArrayKlass::cast(bottom_kl)->element_type()] : bottom_kl->external_name(),\n-               index);\n-      for (int dims = ArrayKlass::cast(a->klass())->dimension(); dims > 1; --dims) {\n-        ss.print(\"[]\");\n-      }\n-      THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), ss.as_string());\n-    }\n-  } else {\n-    ResourceMark rm(THREAD);\n-    stringStream ss;\n-    ss.print(\"Index %d out of bounds for length %d\", index, a->length());\n-    THROW_MSG(vmSymbols::java_lang_ArrayIndexOutOfBoundsException(), ss.as_string());\n-  }\n+   bool oob = false;\n+   int length = -1;\n+   oop res = nullptr;\n+   arrayOop arr((arrayOop)JNIHandles::resolve_non_null(array));\n+   if (arr->is_within_bounds(index)) {\n+     if (arr->is_flatArray()) {\n+       flatArrayOop a = flatArrayOop(JNIHandles::resolve_non_null(array));\n+       oop v = JNIHandles::resolve(value);\n+       FlatArrayKlass* vaklass = FlatArrayKlass::cast(a->klass());\n+       InlineKlass* element_vklass = vaklass->element_klass();\n+       if (v != nullptr && v->is_a(element_vklass)) {\n+         a->write_value_to_flat_array(v, index, CHECK);\n+       } else {\n+         ResourceMark rm(THREAD);\n+         stringStream ss;\n+         Klass *kl = FlatArrayKlass::cast(a->klass());\n+         ss.print(\"type mismatch: can not store %s to %s[%d]\",\n+             v->klass()->external_name(),\n+             kl->external_name(),\n+             index);\n+         for (int dims = ArrayKlass::cast(a->klass())->dimension(); dims > 1; --dims) {\n+           ss.print(\"[]\");\n+         }\n+         THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), ss.as_string());\n+       }\n+     } else {\n+       assert(arr->is_objArray(), \"If not a valueArray. must be an objArray\");\n+       objArrayOop a = objArrayOop(JNIHandles::resolve_non_null(array));\n+       oop v = JNIHandles::resolve(value);\n+       if (v == nullptr || v->is_a(ObjArrayKlass::cast(a->klass())->element_klass())) {\n+         a->obj_at_put(index, v);\n+       } else {\n+         ResourceMark rm(THREAD);\n+         stringStream ss;\n+         Klass *bottom_kl = ObjArrayKlass::cast(a->klass())->bottom_klass();\n+         ss.print(\"type mismatch: can not store %s to %s[%d]\",\n+             v->klass()->external_name(),\n+             bottom_kl->is_typeArray_klass() ? type2name_tab[ArrayKlass::cast(bottom_kl)->element_type()] : bottom_kl->external_name(),\n+                 index);\n+         for (int dims = ArrayKlass::cast(a->klass())->dimension(); dims > 1; --dims) {\n+           ss.print(\"[]\");\n+         }\n+         THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), ss.as_string());\n+       }\n+     }\n+   } else {\n+     ResourceMark rm(THREAD);\n+     stringStream ss;\n+     ss.print(\"Index %d out of bounds for length %d\", index, arr->length());\n+     THROW_MSG(vmSymbols::java_lang_ArrayIndexOutOfBoundsException(), ss.as_string());\n+   }\n","filename":"src\/hotspot\/share\/prims\/jni.cpp","additions":139,"deletions":44,"binary":false,"changes":183,"status":"modified"},{"patch":"@@ -59,0 +59,1 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n@@ -414,0 +415,75 @@\n+static void validate_array_arguments(Klass* elmClass, jint len, TRAPS) {\n+  if (len < 0) {\n+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), \"Array length is negative\");\n+  }\n+  elmClass->initialize(CHECK);\n+  if (elmClass->is_identity_class()) {\n+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), \"Element class is not a value class\");\n+  }\n+  if (elmClass->is_abstract()) {\n+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), \"Element class is abstract\");\n+  }\n+}\n+\n+JVM_ENTRY(jarray, JVM_NewNullRestrictedArray(JNIEnv *env, jclass elmClass, jint len))\n+  oop mirror = JNIHandles::resolve_non_null(elmClass);\n+  Klass* klass = java_lang_Class::as_Klass(mirror);\n+  klass->initialize(CHECK_NULL);\n+  validate_array_arguments(klass, len, CHECK_NULL);\n+  InlineKlass* vk = InlineKlass::cast(klass);\n+  if (!vk->is_implicitly_constructible()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Element class is not implicitly constructible\");\n+  }\n+  oop array = nullptr;\n+  if (vk->flat_array() && vk->has_non_atomic_layout()) {\n+    array = oopFactory::new_flatArray(vk, len, LayoutKind::NON_ATOMIC_FLAT, CHECK_NULL);\n+  } else {\n+    array = oopFactory::new_null_free_objArray(vk, len, CHECK_NULL);\n+  }\n+  return (jarray) JNIHandles::make_local(THREAD, array);\n+JVM_END\n+\n+JVM_ENTRY(jarray, JVM_NewNullRestrictedAtomicArray(JNIEnv *env, jclass elmClass, jint len))\n+  oop mirror = JNIHandles::resolve_non_null(elmClass);\n+  Klass* klass = java_lang_Class::as_Klass(mirror);\n+  klass->initialize(CHECK_NULL);\n+  validate_array_arguments(klass, len, CHECK_NULL);\n+  InlineKlass* vk = InlineKlass::cast(klass);\n+  if (!vk->is_implicitly_constructible()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Element class is not implicitly constructible\");\n+  }\n+  oop array = nullptr;\n+  if (UseArrayFlattening && vk->is_naturally_atomic() && vk->has_non_atomic_layout()) {\n+    array = oopFactory::new_flatArray(vk, len, LayoutKind::NON_ATOMIC_FLAT, CHECK_NULL);\n+  } else if (UseArrayFlattening && vk->has_atomic_layout()) {\n+    array = oopFactory::new_flatArray(vk, len, LayoutKind::ATOMIC_FLAT, CHECK_NULL);\n+  } else {\n+    array = oopFactory::new_null_free_objArray(vk, len, CHECK_NULL);\n+  }\n+  return (jarray) JNIHandles::make_local(THREAD, array);\n+JVM_END\n+\n+JVM_ENTRY(jarray, JVM_NewNullableAtomicArray(JNIEnv *env, jclass elmClass, jint len))\n+  oop mirror = JNIHandles::resolve_non_null(elmClass);\n+  Klass* klass = java_lang_Class::as_Klass(mirror);\n+  klass->initialize(CHECK_NULL);\n+  validate_array_arguments(klass, len, CHECK_NULL);\n+  InlineKlass* vk = InlineKlass::cast(klass);\n+  oop array = nullptr;\n+  if (UseArrayFlattening && vk->has_nullable_atomic_layout()) {\n+    array = oopFactory::new_flatArray(vk, len, LayoutKind::NULLABLE_ATOMIC_FLAT, CHECK_NULL);\n+  } else {\n+    array = oopFactory::new_objArray(vk, len, CHECK_NULL);\n+  }\n+  return (jarray) JNIHandles::make_local(THREAD, array);\n+JVM_END\n+\n+JVM_ENTRY(jboolean, JVM_IsFlatArray(JNIEnv *env, jobject obj))\n+  arrayOop oop = arrayOop(JNIHandles::resolve_non_null(obj));\n+  return oop->is_flatArray();\n+JVM_END\n+\n+JVM_ENTRY(jboolean, JVM_IsNullRestrictedArray(JNIEnv *env, jobject obj))\n+  arrayOop oop = arrayOop(JNIHandles::resolve_non_null(obj));\n+  return oop->is_null_free_array();\n+JVM_END\n@@ -622,2 +698,22 @@\n-  return handle == nullptr ? 0 :\n-         checked_cast<jint>(ObjectSynchronizer::FastHashCode (THREAD, JNIHandles::resolve_non_null(handle)));\n+  if (handle == nullptr) {\n+    return 0;\n+  }\n+  oop obj = JNIHandles::resolve_non_null(handle);\n+  if (EnableValhalla && obj->klass()->is_inline_klass()) {\n+      JavaValue result(T_INT);\n+      JavaCallArguments args;\n+      Handle ho(THREAD, obj);\n+      args.push_oop(ho);\n+      methodHandle method(THREAD, Universe::value_object_hash_code_method());\n+      JavaCalls::call(&result, method, &args, THREAD);\n+      if (HAS_PENDING_EXCEPTION) {\n+        if (!PENDING_EXCEPTION->is_a(vmClasses::Error_klass())) {\n+          Handle e(THREAD, PENDING_EXCEPTION);\n+          CLEAR_PENDING_EXCEPTION;\n+          THROW_MSG_CAUSE_(vmSymbols::java_lang_InternalError(), \"Internal error in hashCode\", e, false);\n+        }\n+      }\n+      return result.get_jint();\n+  } else {\n+    return checked_cast<jint>(ObjectSynchronizer::FastHashCode(THREAD, obj));\n+  }\n@@ -671,0 +767,6 @@\n+  if (klass->is_inline_klass()) {\n+    \/\/ Value instances have no identity, so return the current instance instead of allocating a new one\n+    \/\/ Value classes cannot have finalizers, so the method can return immediately\n+    return JNIHandles::make_local(THREAD, obj());\n+  }\n+\n@@ -1165,1 +1267,2 @@\n-    size = InstanceKlass::cast(klass)->local_interfaces()->length();\n+    InstanceKlass* ik = InstanceKlass::cast(klass);\n+    size = ik->local_interfaces()->length();\n@@ -1167,1 +1270,1 @@\n-    assert(klass->is_objArray_klass() || klass->is_typeArray_klass(), \"Illegal mirror klass\");\n+    assert(klass->is_objArray_klass() || klass->is_typeArray_klass() || klass->is_flatArray_klass(), \"Illegal mirror klass\");\n@@ -1178,1 +1281,2 @@\n-      Klass* k = InstanceKlass::cast(klass)->local_interfaces()->at(index);\n+      InstanceKlass* ik = InstanceKlass::cast(klass);\n+      Klass* k = ik->local_interfaces()->at(index);\n@@ -1199,0 +1303,19 @@\n+JVM_ENTRY(jboolean, JVM_IsIdentityClass(JNIEnv *env, jclass cls))\n+  oop mirror = JNIHandles::resolve_non_null(cls);\n+  if (java_lang_Class::is_primitive(mirror)) {\n+    return JNI_FALSE;\n+  }\n+  Klass* k = java_lang_Class::as_Klass(mirror);\n+  if (EnableValhalla) {\n+    return k->is_array_klass() || k->is_identity_class();\n+  } else {\n+    return k->is_interface() ? JNI_FALSE : JNI_TRUE;\n+  }\n+JVM_END\n+\n+JVM_ENTRY(jboolean, JVM_IsImplicitlyConstructibleClass(JNIEnv *env, jclass cls))\n+  oop mirror = JNIHandles::resolve_non_null(cls);\n+  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(mirror));\n+  return ik->is_implicitly_constructible();\n+JVM_END\n+\n@@ -1683,1 +1806,1 @@\n-    if (want_constructor && !method->is_object_initializer()) {\n+    if (want_constructor && !method->is_object_constructor()) {\n@@ -1687,1 +1810,1 @@\n-        (method->is_object_initializer() || method->is_static_initializer() ||\n+        (method->is_object_constructor() || method->is_class_initializer() ||\n@@ -1715,0 +1838,1 @@\n+        assert(method->is_object_constructor(), \"must be\");\n@@ -1997,1 +2121,1 @@\n-  if (m->is_object_initializer()) {\n+  if (m->is_object_constructor()) {\n@@ -2000,1 +2124,0 @@\n-    \/\/ new_method accepts <clinit> as Method here\n@@ -2272,0 +2395,37 @@\n+\/\/ Arrays support \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+JVM_ENTRY(jboolean, JVM_ArrayIsAccessAtomic(JNIEnv *env, jclass unused, jobject array))\n+  oop o = JNIHandles::resolve(array);\n+  Klass* k = o->klass();\n+  if ((o == nullptr) || (!k->is_array_klass())) {\n+    THROW_0(vmSymbols::java_lang_IllegalArgumentException());\n+  }\n+  return ArrayKlass::cast(k)->element_access_must_be_atomic();\n+JVM_END\n+\n+JVM_ENTRY(jobject, JVM_ArrayEnsureAccessAtomic(JNIEnv *env, jclass unused, jobject array))\n+  oop o = JNIHandles::resolve(array);\n+  Klass* k = o->klass();\n+  if ((o == nullptr) || (!k->is_array_klass())) {\n+    THROW_0(vmSymbols::java_lang_IllegalArgumentException());\n+  }\n+  if (k->is_flatArray_klass()) {\n+    FlatArrayKlass* vk = FlatArrayKlass::cast(k);\n+    if (!vk->element_access_must_be_atomic()) {\n+      \/**\n+       * Need to decide how to implement:\n+       *\n+       * 1) Change to objArrayOop layout, therefore oop->klass() differs so\n+       * then \"<atomic>[Qfoo;\" klass needs to subclass \"[Qfoo;\" to pass through\n+       * \"checkcast\" & \"instanceof\"\n+       *\n+       * 2) Use extra header in the flatArrayOop to flag atomicity required and\n+       * possibly per instance lock structure. Said info, could be placed in\n+       * \"trailer\" rather than disturb the current arrayOop\n+       *\/\n+      Unimplemented();\n+    }\n+  }\n+  return array;\n+JVM_END\n+\n@@ -2450,1 +2610,1 @@\n-  return method->name() == vmSymbols::object_initializer_name();\n+  return method->is_object_constructor();\n@@ -3241,0 +3401,4 @@\n+JVM_LEAF(jboolean, JVM_IsValhallaEnabled(void))\n+  return EnableValhalla ? JNI_TRUE : JNI_FALSE;\n+JVM_END\n+\n@@ -3320,1 +3484,1 @@\n-    objArrayHandle args(THREAD, objArrayOop(JNIHandles::resolve(args0)));\n+    objArrayHandle args = oopFactory::ensure_objArray(JNIHandles::resolve(args0), CHECK_NULL);\n@@ -3340,0 +3504,1 @@\n+  objArrayHandle args = oopFactory::ensure_objArray(JNIHandles::resolve(args0), CHECK_NULL);\n@@ -3341,1 +3506,0 @@\n-  objArrayHandle args(THREAD, objArrayOop(JNIHandles::resolve(args0)));\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":176,"deletions":12,"binary":false,"changes":188,"status":"modified"},{"patch":"@@ -2721,4 +2721,0 @@\n-  if (!java_lang_Class::is_primitive(k_mirror)) {\n-    \/\/ Reset the deleted  ACC_SUPER bit (deleted in compute_modifier_flags()).\n-    result |= JVM_ACC_SUPER;\n-  }\n@@ -2852,1 +2848,2 @@\n-                                                     flds.access_flags().is_static());\n+                                                     flds.access_flags().is_static(),\n+                                                     flds.field_descriptor().is_flat());\n@@ -2890,2 +2887,3 @@\n-    Array<InstanceKlass*>* interface_list = InstanceKlass::cast(k)->local_interfaces();\n-    const int result_length = (interface_list == nullptr ? 0 : interface_list->length());\n+    InstanceKlass* ik = InstanceKlass::cast(k);\n+    Array<InstanceKlass*>* interface_list = ik->local_interfaces();\n+    int result_length = (interface_list == nullptr ? 0 : interface_list->length());\n@@ -3087,3 +3085,6 @@\n-  {\n-    jint result = (jint) mirror->identity_hash();\n-    *hash_code_ptr = result;\n+  if (mirror->is_inline_type()) {\n+    \/\/ For inline types, use the klass as a hash code.\n+    \/\/ TBD to improve this (see also JvmtiTagMapKey::get_hash for similar case).\n+    *hash_code_ptr = (jint)((int64_t)mirror->klass() >> 3);\n+  } else {\n+    *hash_code_ptr = (jint)mirror->identity_hash();\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnv.cpp","additions":11,"deletions":10,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -55,0 +55,1 @@\n+#include \"memory\/iterator.inline.hpp\"\n@@ -61,0 +62,1 @@\n+#include \"oops\/access.hpp\"\n@@ -63,0 +65,1 @@\n+#include \"oops\/compressedOops.inline.hpp\"\n@@ -70,0 +73,1 @@\n+#include \"oops\/objArrayOop.inline.hpp\"\n@@ -88,0 +92,1 @@\n+#include \"runtime\/keepStackGCProcessed.hpp\"\n@@ -1938,0 +1943,103 @@\n+WB_ENTRY(jobjectArray, WB_getObjectsViaKlassOopMaps(JNIEnv* env, jobject wb, jobject thing))\n+  oop aoop = JNIHandles::resolve(thing);\n+  if (!aoop->is_instance()) {\n+    return nullptr;\n+  }\n+  instanceHandle ih(THREAD, (instanceOop) aoop);\n+  InstanceKlass* klass = InstanceKlass::cast(ih->klass());\n+  if (klass->nonstatic_oop_map_count() == 0) {\n+    return nullptr;\n+  }\n+  const OopMapBlock* map = klass->start_of_nonstatic_oop_maps();\n+  const OopMapBlock* const end = map + klass->nonstatic_oop_map_count();\n+  int oop_count = 0;\n+  while (map < end) {\n+    oop_count += map->count();\n+    map++;\n+  }\n+\n+  objArrayHandle result_array =\n+      oopFactory::new_objArray_handle(vmClasses::Object_klass(), oop_count, CHECK_NULL);\n+  map = klass->start_of_nonstatic_oop_maps();\n+  int index = 0;\n+  while (map < end) {\n+    int offset = map->offset();\n+    for (unsigned int j = 0; j < map->count(); j++) {\n+      result_array->obj_at_put(index++, ih->obj_field(offset));\n+      offset += heapOopSize;\n+    }\n+    map++;\n+  }\n+  return (jobjectArray)JNIHandles::make_local(THREAD, result_array());\n+WB_END\n+\n+\/\/ Collect Object oops but not value objects...loaded from heap\n+class CollectObjectOops : public BasicOopIterateClosure {\n+  public:\n+  GrowableArray<Handle>* _array;\n+\n+  CollectObjectOops() {\n+      _array = new GrowableArray<Handle>(128);\n+  }\n+\n+  void add_oop(oop o) {\n+    Handle oh = Handle(Thread::current(), o);\n+    if (oh != nullptr && oh->is_inline_type()) {\n+      oh->oop_iterate(this);\n+    } else {\n+      _array->append(oh);\n+    }\n+  }\n+\n+  template <class T> inline void add_oop(T* p) { add_oop(HeapAccess<>::oop_load(p)); }\n+  void do_oop(oop* o) { add_oop(o); }\n+  void do_oop(narrowOop* v) { add_oop(v); }\n+\n+  jobjectArray create_jni_result(JNIEnv* env, TRAPS) {\n+    objArrayHandle result_array =\n+        oopFactory::new_objArray_handle(vmClasses::Object_klass(), _array->length(), CHECK_NULL);\n+    for (int i = 0 ; i < _array->length(); i++) {\n+      result_array->obj_at_put(i, _array->at(i)());\n+    }\n+    return (jobjectArray)JNIHandles::make_local(THREAD, result_array());\n+  }\n+};\n+\n+\/\/ Collect Object oops but not value objects...loaded from frames\n+class CollectFrameObjectOops : public BasicOopIterateClosure {\n+ public:\n+  CollectObjectOops _collect;\n+\n+  template <class T> inline void add_oop(T* p) { _collect.add_oop(RawAccess<>::oop_load(p)); }\n+  void do_oop(oop* o) { add_oop(o); }\n+  void do_oop(narrowOop* v) { add_oop(v); }\n+\n+  jobjectArray create_jni_result(JNIEnv* env, TRAPS) {\n+    return _collect.create_jni_result(env, THREAD);\n+  }\n+};\n+\n+\/\/ Collect Object oops for the given oop, iterate through value objects\n+WB_ENTRY(jobjectArray, WB_getObjectsViaOopIterator(JNIEnv* env, jobject wb, jobject thing))\n+  ResourceMark rm(thread);\n+  Handle objh(thread, JNIHandles::resolve(thing));\n+  CollectObjectOops collectOops;\n+  objh->oop_iterate(&collectOops);\n+  return collectOops.create_jni_result(env, THREAD);\n+WB_END\n+\n+\/\/ Collect Object oops for the given frame deep, iterate through value objects\n+WB_ENTRY(jobjectArray, WB_getObjectsViaFrameOopIterator(JNIEnv* env, jobject wb, jint depth))\n+  KeepStackGCProcessedMark ksgcpm(THREAD);\n+  ResourceMark rm(THREAD);\n+  CollectFrameObjectOops collectOops;\n+  StackFrameStream sfs(thread, true \/* update *\/, true \/* process_frames *\/);\n+  while (depth > 0) { \/\/ Skip the native WB API frame\n+    sfs.next();\n+    frame* f = sfs.current();\n+    f->oops_do(&collectOops, nullptr, sfs.register_map());\n+    depth--;\n+  }\n+  return collectOops.create_jni_result(env, THREAD);\n+WB_END\n+\n@@ -2899,0 +3007,6 @@\n+  {CC\"getObjectsViaKlassOopMaps0\",\n+      CC\"(Ljava\/lang\/Object;)[Ljava\/lang\/Object;\",    (void*)&WB_getObjectsViaKlassOopMaps},\n+  {CC\"getObjectsViaOopIterator0\",\n+          CC\"(Ljava\/lang\/Object;)[Ljava\/lang\/Object;\",(void*)&WB_getObjectsViaOopIterator},\n+  {CC\"getObjectsViaFrameOopIterator\",\n+      CC\"(I)[Ljava\/lang\/Object;\",                     (void*)&WB_getObjectsViaFrameOopIterator},\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":114,"deletions":0,"binary":false,"changes":114,"status":"modified"},{"patch":"@@ -77,0 +77,1 @@\n+#include <string.h>\n@@ -1776,1 +1777,0 @@\n-static unsigned int patch_mod_count = 0;\n@@ -1783,1 +1783,1 @@\n-  if (!CDSConfig::check_vm_args_consistency(patch_mod_javabase, mode_flag_cmd_line)) {\n+  if (!CDSConfig::check_vm_args_consistency(mode_flag_cmd_line)) {\n@@ -2082,1 +2082,1 @@\n-      add_patch_mod_prefix(module_name, module_equal + 1);\n+      add_patch_mod_prefix(module_name, module_equal + 1, false \/* no append *\/, false \/* no cds *\/);\n@@ -2084,3 +2084,0 @@\n-      if (!create_numbered_module_property(\"jdk.module.patch\", patch_mod_tail, patch_mod_count++)) {\n-        return JNI_ENOMEM;\n-      }\n@@ -2094,0 +2091,64 @@\n+\/\/ VALUECLASS_STR must match string used in the build\n+#define VALUECLASS_STR \"valueclasses\"\n+#define VALUECLASS_JAR \"-\" VALUECLASS_STR \".jar\"\n+\n+\/\/ Finalize --patch-module args and --enable-preview related to value class module patches.\n+\/\/ Create all numbered properties passing module patches.\n+int Arguments::finalize_patch_module() {\n+  \/\/ If --enable-preview and EnableValhalla is true, each module may have value classes that\n+  \/\/ are to be patched into the module.\n+  \/\/ For each <module>-valueclasses.jar in <JAVA_HOME>\/lib\/valueclasses\/\n+  \/\/ appends the equivalent of --patch-module <module>=<JAVA_HOME>\/lib\/valueclasses\/<module>-valueclasses.jar\n+  if (enable_preview() && EnableValhalla) {\n+    char * valueclasses_dir = AllocateHeap(JVM_MAXPATHLEN, mtArguments);\n+    const char * fileSep = os::file_separator();\n+\n+    jio_snprintf(valueclasses_dir, JVM_MAXPATHLEN, \"%s%slib%s\" VALUECLASS_STR \"%s\",\n+                 Arguments::get_java_home(), fileSep, fileSep, fileSep);\n+    DIR* dir = os::opendir(valueclasses_dir);\n+    if (dir != nullptr) {\n+      char * module_name = AllocateHeap(JVM_MAXPATHLEN, mtArguments);\n+      char * path = AllocateHeap(JVM_MAXPATHLEN, mtArguments);\n+\n+      for (dirent * entry = os::readdir(dir); entry != nullptr; entry = os::readdir(dir)) {\n+        \/\/ Test if file ends-with \"-valueclasses.jar\"\n+        int len = (int)strlen(entry->d_name) - (sizeof(VALUECLASS_JAR) - 1);\n+        if (len <= 0 || strcmp(&entry->d_name[len], VALUECLASS_JAR) != 0) {\n+          continue;         \/\/ too short or not the expected suffix\n+        }\n+\n+        strcpy(module_name, entry->d_name);\n+        module_name[len] = '\\0';     \/\/ truncate to just module-name\n+\n+        jio_snprintf(path, JVM_MAXPATHLEN, \"%s%s\", valueclasses_dir, &entry->d_name);\n+        add_patch_mod_prefix(module_name, path, true \/* append *\/, true \/* cds OK*\/);\n+        log_info(class)(\"--enable-preview appending value classes for module %s: %s\", module_name, entry->d_name);\n+      }\n+      FreeHeap(module_name);\n+      FreeHeap(path);\n+      os::closedir(dir);\n+    }\n+    FreeHeap(valueclasses_dir);\n+  }\n+\n+  \/\/ Create numbered properties for each module that has been patched either\n+  \/\/ by --patch-module or --enable-preview\n+  \/\/ Format is \"jdk.module.patch.<n>=<module_name>=<path>\"\n+  if (_patch_mod_prefix != nullptr) {\n+    char * prop_value = AllocateHeap(JVM_MAXPATHLEN + JVM_MAXPATHLEN + 1, mtArguments);\n+    unsigned int patch_mod_count = 0;\n+\n+    for (GrowableArrayIterator<ModulePatchPath *> it = _patch_mod_prefix->begin();\n+            it != _patch_mod_prefix->end(); ++it) {\n+      jio_snprintf(prop_value, JVM_MAXPATHLEN + JVM_MAXPATHLEN + 1, \"%s=%s\",\n+                   (*it)->module_name(), (*it)->path_string());\n+      if (!create_numbered_module_property(\"jdk.module.patch\", prop_value, patch_mod_count++)) {\n+        FreeHeap(prop_value);\n+        return JNI_ENOMEM;\n+      }\n+    }\n+    FreeHeap(prop_value);\n+  }\n+  return JNI_OK;\n+}\n+\n@@ -2349,0 +2410,4 @@\n+      \/\/ --enable-preview enables Valhalla, EnableValhalla VM option will eventually be removed before integration\n+      if (FLAG_SET_CMDLINE(EnableValhalla, true) != JVMFlag::SUCCESS) {\n+        return JNI_EINVAL;\n+      }\n@@ -2828,10 +2893,5 @@\n-void Arguments::add_patch_mod_prefix(const char* module_name, const char* path) {\n-  \/\/ For java.base check for duplicate --patch-module options being specified on the command line.\n-  \/\/ This check is only required for java.base, all other duplicate module specifications\n-  \/\/ will be checked during module system initialization.  The module system initialization\n-  \/\/ will throw an ExceptionInInitializerError if this situation occurs.\n-  if (strcmp(module_name, JAVA_BASE_NAME) == 0) {\n-    if (patch_mod_javabase) {\n-      vm_exit_during_initialization(\"Cannot specify \" JAVA_BASE_NAME \" more than once to --patch-module\");\n-    } else {\n-      patch_mod_javabase = true;\n+void Arguments::add_patch_mod_prefix(const char* module_name, const char* path, bool allow_append, bool allow_cds) {\n+  if (!allow_cds) {\n+    CDSConfig::set_module_patching_disables_cds();\n+    if (strcmp(module_name, JAVA_BASE_NAME) == 0) {\n+      CDSConfig::set_java_base_module_patching_disables_cds();\n@@ -2846,1 +2906,18 @@\n-  _patch_mod_prefix->push(new ModulePatchPath(module_name, path));\n+  \/\/ Scan patches for matching module\n+  int i = _patch_mod_prefix->find_if([&](ModulePatchPath* patch) {\n+    return (strcmp(module_name, patch->module_name()) == 0);\n+  });\n+  if (i == -1) {\n+    _patch_mod_prefix->push(new ModulePatchPath(module_name, path));\n+  } else {\n+    if (allow_append) {\n+      \/\/ append path to existing module entry\n+      _patch_mod_prefix->at(i)->append_path(path);\n+    } else {\n+      if (strcmp(module_name, JAVA_BASE_NAME) == 0) {\n+        vm_exit_during_initialization(\"Cannot specify \" JAVA_BASE_NAME \" more than once to --patch-module\");\n+      } else {\n+        vm_exit_during_initialization(\"Cannot specify a module more than once to --patch-module\", module_name);\n+      }\n+    }\n+  }\n@@ -2959,1 +3036,2 @@\n-  if (!check_vm_args_consistency()) {\n+  \/\/ finalize --module-patch and related --enable-preview\n+  if (finalize_patch_module() != JNI_OK) {\n@@ -2963,0 +3041,3 @@\n+  if (!check_vm_args_consistency()) {\n+    return JNI_ERR;\n+  }\n@@ -3764,0 +3845,7 @@\n+  if (!EnableValhalla || (is_interpreter_only() && !CDSConfig::is_dumping_archive() && !UseSharedSpaces)) {\n+    \/\/ Disable calling convention optimizations if inline types are not supported.\n+    \/\/ Also these aren't useful in -Xint. However, don't disable them when dumping or using\n+    \/\/ the CDS archive, as the values must match between dumptime and runtime.\n+    InlineTypePassFieldsAsArgs = false;\n+    InlineTypeReturnedAsFields = false;\n+  }\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":106,"deletions":18,"binary":false,"changes":124,"status":"modified"},{"patch":"@@ -803,1 +803,1 @@\n-  develop(bool, PrintFieldLayout, false,                                    \\\n+  product(bool, PrintFieldLayout, false, DIAGNOSTIC,                        \\\n@@ -806,0 +806,24 @@\n+  product(bool, PrintInlineLayout, false, DIAGNOSTIC,                       \\\n+          \"Print field layout for each inline type or class with inline fields\") \\\n+                                                                            \\\n+  product(bool, PrintFlatArrayLayout, false, DIAGNOSTIC,                    \\\n+          \"Print array layout for each inline type array\")                  \\\n+                                                                            \\\n+  product(bool, UseArrayFlattening, true,                                   \\\n+          \"Allow the VM to flatten arrays\")                                 \\\n+                                                                            \\\n+  product(bool, UseFieldFlattening, true,                                   \\\n+          \"Allow the VM to flatten value fields\")                           \\\n+                                                                            \\\n+  product(bool, UseNonAtomicValueFlattening, true,                          \\\n+          \"Allow the JVM to flatten some non-atomic null-free values\")      \\\n+                                                                            \\\n+  product(bool, UseNullableValueFlattening, false,                          \\\n+          \"Allow the JVM to flatten some nullable values\")                  \\\n+                                                                            \\\n+  product(bool, UseAtomicValueFlattening, false,                            \\\n+          \"Allow the JVM to flatten some atomic values\")                    \\\n+                                                                            \\\n+  product(intx, FlatArrayElementMaxOops, 4,                                 \\\n+          \"Max nof embedded object references in an inline type to flatten, <0 no limit\")  \\\n+                                                                            \\\n@@ -1940,0 +1964,17 @@\n+  product(bool, EnableValhalla, true,                                       \\\n+          \"Enable experimental Valhalla features\")                          \\\n+                                                                            \\\n+  product_pd(bool, InlineTypePassFieldsAsArgs,                              \\\n+          \"Pass each inline type field as an argument at calls\")            \\\n+                                                                            \\\n+  product_pd(bool, InlineTypeReturnedAsFields,                              \\\n+          \"Return fields instead of an inline type reference\")              \\\n+                                                                            \\\n+  develop(bool, StressCallingConvention, false,                             \\\n+          \"Stress the scalarized calling convention.\")                      \\\n+                                                                            \\\n+  product(ccstrlist, ForceNonTearable, \"\", DIAGNOSTIC,                      \\\n+          \"List of inline classes which are forced to be atomic \"           \\\n+          \"(whitespace and commas separate names, \"                         \\\n+          \"and leading and trailing stars '*' are wildcards)\")              \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":42,"deletions":1,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -150,0 +150,1 @@\n+  oop           _return_buffered_value; \/\/ buffered value being returned\n@@ -783,0 +784,3 @@\n+  oop return_buffered_value() const              { return _return_buffered_value; }\n+  void set_return_buffered_value(oop val)        { _return_buffered_value = val; }\n+\n@@ -849,0 +853,1 @@\n+  static ByteSize return_buffered_value_offset() { return byte_offset_of(JavaThread, _return_buffered_value); }\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -787,0 +788,1 @@\n+    ResourceMark rm;\n@@ -788,1 +790,2 @@\n-    bool return_oop = nm->method()->is_returning_oop();\n+    Method* method = nm->method();\n+    bool return_oop = method->is_returning_oop();\n@@ -790,1 +793,16 @@\n-    Handle return_value;\n+    GrowableArray<Handle> return_values;\n+    InlineKlass* vk = nullptr;\n+    if (return_oop && InlineTypeReturnedAsFields &&\n+        (method->result_type() == T_OBJECT)) {\n+      \/\/ Check if an inline type is returned as fields\n+      vk = InlineKlass::returned_inline_klass(map);\n+      if (vk != nullptr) {\n+        \/\/ We're at a safepoint at the return of a method that returns\n+        \/\/ multiple values. We must make sure we preserve the oop values\n+        \/\/ across the safepoint.\n+        assert(vk == method->returns_inline_type(thread()), \"bad inline klass\");\n+        vk->save_oop_fields(map, return_values);\n+        return_oop = false;\n+      }\n+    }\n+\n@@ -797,1 +815,1 @@\n-      return_value = Handle(self, result);\n+      return_values.push(Handle(self, result));\n@@ -811,1 +829,4 @@\n-      caller_fr.set_saved_oop_result(&map, return_value());\n+      assert(return_values.length() == 1, \"only one return value\");\n+      caller_fr.set_saved_oop_result(&map, return_values.pop()());\n+    } else if (vk != nullptr) {\n+      vk->restore_oop_results(map, return_values);\n","filename":"src\/hotspot\/share\/runtime\/safepoint.cpp","additions":25,"deletions":4,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -45,0 +45,1 @@\n+#include \"memory\/oopFactory.hpp\"\n@@ -47,0 +48,2 @@\n+#include \"oops\/access.hpp\"\n+#include \"oops\/fieldStreams.inline.hpp\"\n@@ -51,0 +54,1 @@\n+#include \"oops\/objArrayOop.inline.hpp\"\n@@ -52,0 +56,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -1188,0 +1193,15 @@\n+  \/\/ Substitutability test implementation piggy backs on static call resolution\n+  Bytecodes::Code code = caller->java_code_at(bci);\n+  if (code == Bytecodes::_if_acmpeq || code == Bytecodes::_if_acmpne) {\n+    bc = Bytecodes::_invokestatic;\n+    methodHandle attached_method(THREAD, extract_attached_method(vfst));\n+    assert(attached_method.not_null(), \"must have attached method\");\n+    vmClasses::ValueObjectMethods_klass()->initialize(CHECK_NH);\n+    LinkResolver::resolve_invoke(callinfo, receiver, attached_method, bc, false, CHECK_NH);\n+#ifdef ASSERT\n+    Method* is_subst = vmClasses::ValueObjectMethods_klass()->find_method(vmSymbols::isSubstitutable_name(), vmSymbols::object_object_boolean_signature());\n+    assert(callinfo.selected_method() == is_subst, \"must be isSubstitutable method\");\n+#endif\n+    return receiver;\n+  }\n+\n@@ -1223,0 +1243,6 @@\n+    } else {\n+      assert(attached_method->has_scalarized_args(), \"invalid use of attached method\");\n+      if (!attached_method->method_holder()->is_inline_klass()) {\n+        \/\/ Ignore the attached method in this case to not confuse below code\n+        attached_method = methodHandle(current, nullptr);\n+      }\n@@ -1231,0 +1257,1 @@\n+  bool check_null_and_abstract = true;\n@@ -1244,2 +1271,3 @@\n-    if (attached_method.is_null()) {\n-      Method* callee = bytecode.static_target(CHECK_NH);\n+    Method* callee = attached_method();\n+    if (callee == nullptr) {\n+      callee = bytecode.static_target(CHECK_NH);\n@@ -1250,7 +1278,17 @@\n-\n-    \/\/ Retrieve from a compiled argument list\n-    receiver = Handle(current, callerFrame.retrieve_receiver(&reg_map2));\n-    assert(oopDesc::is_oop_or_null(receiver()), \"\");\n-\n-    if (receiver.is_null()) {\n-      THROW_(vmSymbols::java_lang_NullPointerException(), nullHandle);\n+    bool caller_is_c1 = callerFrame.is_compiled_frame() && callerFrame.cb()->as_nmethod()->is_compiled_by_c1();\n+    if (!caller_is_c1 && callee->is_scalarized_arg(0)) {\n+      \/\/ If the receiver is an inline type that is passed as fields, no oop is available\n+      \/\/ Resolve the call without receiver null checking.\n+      assert(!callee->mismatch(), \"calls with inline type receivers should never mismatch\");\n+      assert(attached_method.not_null() && !attached_method->is_abstract(), \"must have non-abstract attached method\");\n+      if (bc == Bytecodes::_invokeinterface) {\n+        bc = Bytecodes::_invokevirtual; \/\/ C2 optimistically replaces interface calls by virtual calls\n+      }\n+      check_null_and_abstract = false;\n+    } else {\n+      \/\/ Retrieve from a compiled argument list\n+      receiver = Handle(current, callerFrame.retrieve_receiver(&reg_map2));\n+      assert(oopDesc::is_oop_or_null(receiver()), \"\");\n+      if (receiver.is_null()) {\n+        THROW_(vmSymbols::java_lang_NullPointerException(), nullHandle);\n+      }\n@@ -1263,1 +1301,1 @@\n-    LinkResolver::resolve_invoke(callinfo, receiver, attached_method, bc, CHECK_NH);\n+    LinkResolver::resolve_invoke(callinfo, receiver, attached_method, bc, check_null_and_abstract, CHECK_NH);\n@@ -1272,1 +1310,1 @@\n-  if (has_receiver) {\n+  if (has_receiver && check_null_and_abstract) {\n@@ -1300,1 +1338,1 @@\n-methodHandle SharedRuntime::find_callee_method(TRAPS) {\n+methodHandle SharedRuntime::find_callee_method(bool is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1326,0 +1364,4 @@\n+    \/\/ Calls via mismatching methods are always non-scalarized\n+    if (callinfo.resolved_method()->mismatch() && !is_optimized) {\n+      caller_is_c1 = true;\n+    }\n@@ -1333,1 +1375,1 @@\n-methodHandle SharedRuntime::resolve_helper(bool is_virtual, bool is_optimized, TRAPS) {\n+methodHandle SharedRuntime::resolve_helper(bool is_virtual, bool is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1356,0 +1398,4 @@\n+  \/\/ Calls via mismatching methods are always non-scalarized\n+  if (caller_nm->is_compiled_by_c1() || (call_info.resolved_method()->mismatch() && !is_optimized)) {\n+    caller_is_c1 = true;\n+  }\n@@ -1374,1 +1420,1 @@\n-    tty->print(\"resolving %s%s (%s) call to\",\n+    tty->print(\"resolving %s%s (%s) call%s to\",\n@@ -1376,1 +1422,1 @@\n-               Bytecodes::name(invoke_code));\n+               Bytecodes::name(invoke_code), (caller_is_c1) ? \" from C1\" : \"\");\n@@ -1415,1 +1461,1 @@\n-    inline_cache->update(&call_info, receiver->klass());\n+    inline_cache->update(&call_info, receiver->klass(), caller_is_c1);\n@@ -1419,1 +1465,1 @@\n-    callsite->set(callee_method);\n+    callsite->set(callee_method, caller_is_c1);\n@@ -1439,0 +1485,2 @@\n+  bool is_optimized = false;\n+  bool caller_is_c1 = false;\n@@ -1440,1 +1488,1 @@\n-    callee_method = SharedRuntime::handle_ic_miss_helper(CHECK_NULL);\n+    callee_method = SharedRuntime::handle_ic_miss_helper(is_optimized, caller_is_c1, CHECK_NULL);\n@@ -1445,1 +1493,1 @@\n-  return get_resolved_entry(current, callee_method);\n+  return get_resolved_entry(current, callee_method, false, is_optimized, caller_is_c1);\n@@ -1486,1 +1534,5 @@\n-      return callee->get_c2i_entry();\n+      if (caller_frame.is_interpreted_frame()) {\n+        return callee->get_c2i_inline_entry();\n+      } else {\n+        return callee->get_c2i_entry();\n+      }\n@@ -1492,0 +1544,3 @@\n+  bool is_static_call = false;\n+  bool is_optimized = false;\n+  bool caller_is_c1 = false;\n@@ -1494,1 +1549,1 @@\n-    callee_method = SharedRuntime::reresolve_call_site(CHECK_NULL);\n+    callee_method = SharedRuntime::reresolve_call_site(is_static_call, is_optimized, caller_is_c1, CHECK_NULL);\n@@ -1498,1 +1553,1 @@\n-  return get_resolved_entry(current, callee_method);\n+  return get_resolved_entry(current, callee_method, is_static_call, is_optimized, caller_is_c1);\n@@ -1537,1 +1592,2 @@\n-address SharedRuntime::get_resolved_entry(JavaThread* current, methodHandle callee_method) {\n+address SharedRuntime::get_resolved_entry(JavaThread* current, methodHandle callee_method,\n+                                          bool is_static_call, bool is_optimized, bool caller_is_c1) {\n@@ -1543,2 +1599,11 @@\n-  assert(callee_method->verified_code_entry() != nullptr, \" Jump to zero!\");\n-  return callee_method->verified_code_entry();\n+\n+  if (caller_is_c1) {\n+    assert(callee_method->verified_inline_code_entry() != nullptr, \"Jump to zero!\");\n+    return callee_method->verified_inline_code_entry();\n+  } else if (is_static_call || is_optimized) {\n+    assert(callee_method->verified_code_entry() != nullptr, \"Jump to zero!\");\n+    return callee_method->verified_code_entry();\n+  } else {\n+    assert(callee_method->verified_inline_ro_code_entry() != nullptr, \"Jump to zero!\");\n+    return callee_method->verified_inline_ro_code_entry();\n+  }\n@@ -1550,0 +1615,1 @@\n+  bool caller_is_c1 = false;\n@@ -1552,1 +1618,1 @@\n-    callee_method = SharedRuntime::resolve_helper(false, false, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(false, false, caller_is_c1, CHECK_NULL);\n@@ -1556,1 +1622,1 @@\n-  return get_resolved_entry(current, callee_method);\n+  return get_resolved_entry(current, callee_method, true, false, caller_is_c1);\n@@ -1562,0 +1628,1 @@\n+  bool caller_is_c1 = false;\n@@ -1563,1 +1630,1 @@\n-    callee_method = SharedRuntime::resolve_helper(true, false, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(true, false, caller_is_c1, CHECK_NULL);\n@@ -1567,1 +1634,1 @@\n-  return get_resolved_entry(current, callee_method);\n+  return get_resolved_entry(current, callee_method, false, false, caller_is_c1);\n@@ -1575,0 +1642,1 @@\n+  bool caller_is_c1 = false;\n@@ -1576,1 +1644,1 @@\n-    callee_method = SharedRuntime::resolve_helper(true, true, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(true, true, caller_is_c1, CHECK_NULL);\n@@ -1580,1 +1648,1 @@\n-  return get_resolved_entry(current, callee_method);\n+  return get_resolved_entry(current, callee_method, false, true, caller_is_c1);\n@@ -1583,1 +1651,3 @@\n-methodHandle SharedRuntime::handle_ic_miss_helper(TRAPS) {\n+\n+\n+methodHandle SharedRuntime::handle_ic_miss_helper(bool& is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1601,1 +1671,1 @@\n-    tty->print(\"IC miss (%s) call to\", Bytecodes::name(bc));\n+    tty->print(\"IC miss (%s) call%s to\", Bytecodes::name(bc), (caller_is_c1) ? \" from C1\" : \"\");\n@@ -1633,0 +1703,4 @@\n+  \/\/ Calls via mismatching methods are always non-scalarized\n+  if (caller_nm->is_compiled_by_c1() || call_info.resolved_method()->mismatch()) {\n+    caller_is_c1 = true;\n+  }\n@@ -1636,1 +1710,1 @@\n-  inline_cache->update(&call_info, receiver()->klass());\n+  inline_cache->update(&call_info, receiver()->klass(), caller_is_c1);\n@@ -1647,1 +1721,1 @@\n-methodHandle SharedRuntime::reresolve_call_site(TRAPS) {\n+methodHandle SharedRuntime::reresolve_call_site(bool& is_static_call, bool& is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1657,0 +1731,3 @@\n+  if (caller.is_compiled_frame()) {\n+    caller_is_c1 = caller.cb()->as_nmethod()->is_compiled_by_c1();\n+  }\n@@ -1697,0 +1774,2 @@\n+        is_static_call = false;\n+        is_optimized = false;\n@@ -1699,0 +1778,1 @@\n+            is_static_call = true;\n@@ -1700,0 +1780,1 @@\n+            is_optimized = (iter.type() == relocInfo::opt_virtual_call_type);\n@@ -1704,1 +1785,0 @@\n-\n@@ -1718,2 +1798,1 @@\n-  methodHandle callee_method = find_callee_method(CHECK_(methodHandle()));\n-\n+  methodHandle callee_method = find_callee_method(is_optimized, caller_is_c1, CHECK_(methodHandle()));\n@@ -1726,1 +1805,1 @@\n-    tty->print(\"handle_wrong_method reresolving call to\");\n+    tty->print(\"handle_wrong_method reresolving call%s to\", (caller_is_c1) ? \" from C1\" : \"\");\n@@ -1932,0 +2011,15 @@\n+char* SharedRuntime::generate_identity_exception_message(JavaThread* current, Klass* klass) {\n+  assert(klass->is_inline_klass(), \"Must be a concrete value class\");\n+  const char* desc = \"Cannot synchronize on an instance of value class \";\n+  const char* className = klass->external_name();\n+  size_t msglen = strlen(desc) + strlen(className) + 1;\n+  char* message = NEW_RESOURCE_ARRAY(char, msglen);\n+  if (nullptr == message) {\n+    \/\/ Out of memory: can't create detailed error message\n+    message = const_cast<char*>(klass->external_name());\n+  } else {\n+    jio_snprintf(message, msglen, \"%s%s\", desc, className);\n+  }\n+  return message;\n+}\n+\n@@ -2182,1 +2276,1 @@\n-    _basic_type_bits = 4,\n+    _basic_type_bits = 5,\n@@ -2200,1 +2294,1 @@\n-  static int adapter_encoding(BasicType in) {\n+  static BasicType adapter_encoding(BasicType in) {\n@@ -2206,1 +2300,1 @@\n-        \/\/ There are all promoted to T_INT in the calling convention\n+        \/\/ They are all promoted to T_INT in the calling convention\n@@ -2233,1 +2327,1 @@\n-  AdapterFingerPrint(int total_args_passed, BasicType* sig_bt) {\n+  AdapterFingerPrint(const GrowableArray<SigEntry>* sig, bool has_ro_adapter = false) {\n@@ -2236,0 +2330,1 @@\n+    int total_args_passed = (sig != nullptr) ? sig->length() : 0;\n@@ -2253,0 +2348,2 @@\n+    BasicType prev_bt = T_ILLEGAL;\n+    int vt_count = 0;\n@@ -2255,4 +2352,27 @@\n-      for (int byte = 0; sig_index < total_args_passed && byte < _basic_types_per_int; byte++) {\n-        int bt = adapter_encoding(sig_bt[sig_index++]);\n-        assert((bt & _basic_type_mask) == bt, \"must fit in 4 bits\");\n-        value = (value << _basic_type_bits) | bt;\n+      for (int byte = 0; byte < _basic_types_per_int; byte++) {\n+        BasicType bt = T_ILLEGAL;\n+        if (sig_index < total_args_passed) {\n+          bt = sig->at(sig_index++)._bt;\n+          if (bt == T_METADATA) {\n+            \/\/ Found start of inline type in signature\n+            assert(InlineTypePassFieldsAsArgs, \"unexpected start of inline type\");\n+            if (sig_index == 1 && has_ro_adapter) {\n+              \/\/ With a ro_adapter, replace receiver inline type delimiter by T_VOID to prevent matching\n+              \/\/ with other adapters that have the same inline type as first argument and no receiver.\n+              bt = T_VOID;\n+            }\n+            vt_count++;\n+          } else if (bt == T_VOID && prev_bt != T_LONG && prev_bt != T_DOUBLE) {\n+            \/\/ Found end of inline type in signature\n+            assert(InlineTypePassFieldsAsArgs, \"unexpected end of inline type\");\n+            vt_count--;\n+            assert(vt_count >= 0, \"invalid vt_count\");\n+          } else if (vt_count == 0) {\n+            \/\/ Widen fields that are not part of a scalarized inline type argument\n+            bt = adapter_encoding(bt);\n+          }\n+          prev_bt = bt;\n+        }\n+        int bt_val = (bt == T_ILLEGAL) ? 0 : bt;\n+        assert((bt_val & _basic_type_mask) == bt_val, \"must fit in 4 bits\");\n+        value = (value << _basic_type_bits) | bt_val;\n@@ -2262,0 +2382,1 @@\n+    assert(vt_count == 0, \"invalid vt_count\");\n@@ -2326,8 +2447,4 @@\n-        }\n-        switch (v) {\n-          case T_INT:    st.print(\"I\");    break;\n-          case T_LONG:   long_prev = true; break;\n-          case T_FLOAT:  st.print(\"F\");    break;\n-          case T_DOUBLE: st.print(\"D\");    break;\n-          case T_VOID:   break;\n-          default: ShouldNotReachHere();\n+        } else if (v == T_LONG) {\n+          long_prev = true;\n+        } else if (v != T_VOID){\n+          st.print(\"%c\", type2char((BasicType)v));\n@@ -2381,1 +2498,1 @@\n-static AdapterHandlerEntry* lookup(int total_args_passed, BasicType* sig_bt) {\n+static AdapterHandlerEntry* lookup(const GrowableArray<SigEntry>* sig, bool has_ro_adapter = false) {\n@@ -2384,1 +2501,1 @@\n-  AdapterFingerPrint fp(total_args_passed, sig_bt);\n+  AdapterFingerPrint fp(sig, has_ro_adapter);\n@@ -2418,1 +2535,1 @@\n-const int AdapterHandlerLibrary_size = 16*K;\n+const int AdapterHandlerLibrary_size = 48*K;\n@@ -2461,1 +2578,1 @@\n-    _abstract_method_handler = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(0, nullptr),\n+    _abstract_method_handler = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(nullptr),\n@@ -2463,0 +2580,1 @@\n+                                                                wrong_method_abstract, wrong_method_abstract, wrong_method_abstract,\n@@ -2464,4 +2582,8 @@\n-\n-    _no_arg_handler = create_adapter(no_arg_blob, 0, nullptr, true);\n-    BasicType obj_args[] = { T_OBJECT };\n-    _obj_arg_handler = create_adapter(obj_arg_blob, 1, obj_args, true);\n+    CompiledEntrySignature no_args;\n+    no_args.compute_calling_conventions();\n+    _no_arg_handler = create_adapter(no_arg_blob, no_args, true);\n+\n+    CompiledEntrySignature obj_args;\n+    SigEntry::add_entry(obj_args.sig(), T_OBJECT);\n+    obj_args.compute_calling_conventions();\n+    _obj_arg_handler = create_adapter(obj_arg_blob, obj_args, true);\n@@ -2471,2 +2593,4 @@\n-    BasicType int_args[] = { T_INT };\n-    _int_arg_handler = create_adapter(int_arg_blob, 1, int_args, true);\n+    CompiledEntrySignature int_args;\n+    SigEntry::add_entry(int_args.sig(), T_INT);\n+    int_args.compute_calling_conventions();\n+    _int_arg_handler = create_adapter(int_arg_blob, int_args, true);\n@@ -2474,2 +2598,5 @@\n-    BasicType obj_int_args[] = { T_OBJECT, T_INT };\n-    _obj_int_arg_handler = create_adapter(obj_int_arg_blob, 2, obj_int_args, true);\n+    CompiledEntrySignature obj_int_args;\n+    SigEntry::add_entry(obj_int_args.sig(), T_OBJECT);\n+    SigEntry::add_entry(obj_int_args.sig(), T_INT);\n+    obj_int_args.compute_calling_conventions();\n+    _obj_int_arg_handler = create_adapter(obj_int_arg_blob, obj_int_args, true);\n@@ -2477,2 +2604,5 @@\n-    BasicType obj_obj_args[] = { T_OBJECT, T_OBJECT };\n-    _obj_obj_arg_handler = create_adapter(obj_obj_arg_blob, 2, obj_obj_args, true);\n+    CompiledEntrySignature obj_obj_args;\n+    SigEntry::add_entry(obj_obj_args.sig(), T_OBJECT);\n+    SigEntry::add_entry(obj_obj_args.sig(), T_OBJECT);\n+    obj_obj_args.compute_calling_conventions();\n+    _obj_obj_arg_handler = create_adapter(obj_obj_arg_blob, obj_obj_args, true);\n@@ -2486,0 +2616,1 @@\n+  return;\n@@ -2498,0 +2629,2 @@\n+                                                      address c2i_inline_entry,\n+                                                      address c2i_inline_ro_entry,\n@@ -2499,0 +2632,1 @@\n+                                                      address c2i_unverified_inline_entry,\n@@ -2500,3 +2634,2 @@\n-  \/\/ Insert an entry into the table\n-  return new AdapterHandlerEntry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry,\n-                                 c2i_no_clinit_check_entry);\n+  return new AdapterHandlerEntry(fingerprint, i2c_entry, c2i_entry, c2i_inline_entry, c2i_inline_ro_entry, c2i_unverified_entry,\n+                              c2i_unverified_inline_entry, c2i_no_clinit_check_entry);\n@@ -2507,1 +2640,1 @@\n-    return _abstract_method_handler;\n+    return nullptr;\n@@ -2514,0 +2647,3 @@\n+      if (InlineTypePassFieldsAsArgs && method->method_holder()->is_inline_klass()) {\n+        return nullptr;\n+      }\n@@ -2517,1 +2653,10 @@\n-      case JVM_SIGNATURE_CLASS:\n+      case JVM_SIGNATURE_CLASS: {\n+        if (InlineTypePassFieldsAsArgs) {\n+          SignatureStream ss(method->signature());\n+          InlineKlass* vk = ss.as_inline_klass(method->method_holder());\n+          if (vk != nullptr) {\n+            return nullptr;\n+          }\n+        }\n+        return _obj_arg_handler;\n+      }\n@@ -2528,1 +2673,1 @@\n-             !method->is_static()) {\n+             !method->is_static() && (!InlineTypePassFieldsAsArgs || !method->method_holder()->is_inline_klass())) {\n@@ -2530,1 +2675,10 @@\n-      case JVM_SIGNATURE_CLASS:\n+      case JVM_SIGNATURE_CLASS: {\n+        if (InlineTypePassFieldsAsArgs) {\n+          SignatureStream ss(method->signature());\n+          InlineKlass* vk = ss.as_inline_klass(method->method_holder());\n+          if (vk != nullptr) {\n+            return nullptr;\n+          }\n+        }\n+        return _obj_obj_arg_handler;\n+      }\n@@ -2544,5 +2698,9 @@\n-class AdapterSignatureIterator : public SignatureIterator {\n- private:\n-  BasicType stack_sig_bt[16];\n-  BasicType* sig_bt;\n-  int index;\n+CompiledEntrySignature::CompiledEntrySignature(Method* method) :\n+  _method(method), _num_inline_args(0), _has_inline_recv(false),\n+  _regs(nullptr), _regs_cc(nullptr), _regs_cc_ro(nullptr),\n+  _args_on_stack(0), _args_on_stack_cc(0), _args_on_stack_cc_ro(0),\n+  _c1_needs_stack_repair(false), _c2_needs_stack_repair(false), _supers(nullptr) {\n+  _sig = new GrowableArray<SigEntry>((method != nullptr) ? method->size_of_parameters() : 1);\n+  _sig_cc = new GrowableArray<SigEntry>((method != nullptr) ? method->size_of_parameters() : 1);\n+  _sig_cc_ro = new GrowableArray<SigEntry>((method != nullptr) ? method->size_of_parameters() : 1);\n+}\n@@ -2550,11 +2708,24 @@\n- public:\n-  AdapterSignatureIterator(Symbol* signature,\n-                           fingerprint_t fingerprint,\n-                           bool is_static,\n-                           int total_args_passed) :\n-    SignatureIterator(signature, fingerprint),\n-    index(0)\n-  {\n-    sig_bt = (total_args_passed <= 16) ? stack_sig_bt : NEW_RESOURCE_ARRAY(BasicType, total_args_passed);\n-    if (!is_static) { \/\/ Pass in receiver first\n-      sig_bt[index++] = T_OBJECT;\n+\/\/ See if we can save space by sharing the same entry for VIEP and VIEP(RO),\n+\/\/ or the same entry for VEP and VIEP(RO).\n+CodeOffsets::Entries CompiledEntrySignature::c1_inline_ro_entry_type() const {\n+  if (!has_scalarized_args()) {\n+    \/\/ VEP\/VIEP\/VIEP(RO) all share the same entry. There's no packing.\n+    return CodeOffsets::Verified_Entry;\n+  }\n+  if (_method->is_static()) {\n+    \/\/ Static methods don't need VIEP(RO)\n+    return CodeOffsets::Verified_Entry;\n+  }\n+\n+  if (has_inline_recv()) {\n+    if (num_inline_args() == 1) {\n+      \/\/ Share same entry for VIEP and VIEP(RO).\n+      \/\/ This is quite common: we have an instance method in an InlineKlass that has\n+      \/\/ no inline type args other than <this>.\n+      return CodeOffsets::Verified_Inline_Entry;\n+    } else {\n+      assert(num_inline_args() > 1, \"must be\");\n+      \/\/ No sharing:\n+      \/\/   VIEP(RO) -- <this> is passed as object\n+      \/\/   VEP      -- <this> is passed as fields\n+      return CodeOffsets::Verified_Inline_Entry_RO;\n@@ -2562,1 +2733,0 @@\n-    do_parameters_on(this);\n@@ -2565,2 +2735,9 @@\n-  BasicType* basic_types() {\n-    return sig_bt;\n+  \/\/ Either a static method, or <this> is not an inline type\n+  if (args_on_stack_cc() != args_on_stack_cc_ro()) {\n+    \/\/ No sharing:\n+    \/\/ Some arguments are passed on the stack, and we have inserted reserved entries\n+    \/\/ into the VEP, but we never insert reserved entries into the VIEP(RO).\n+    return CodeOffsets::Verified_Inline_Entry_RO;\n+  } else {\n+    \/\/ Share same entry for VEP and VIEP(RO).\n+    return CodeOffsets::Verified_Entry;\n@@ -2568,0 +2745,1 @@\n+}\n@@ -2569,3 +2747,39 @@\n-#ifdef ASSERT\n-  int slots() {\n-    return index;\n+\/\/ Returns all super methods (transitive) in classes and interfaces that are overridden by the current method.\n+GrowableArray<Method*>* CompiledEntrySignature::get_supers() {\n+  if (_supers != nullptr) {\n+    return _supers;\n+  }\n+  _supers = new GrowableArray<Method*>();\n+  \/\/ Skip private, static, and <init> methods\n+  if (_method->is_private() || _method->is_static() || _method->is_object_constructor()) {\n+    return _supers;\n+  }\n+  Symbol* name = _method->name();\n+  Symbol* signature = _method->signature();\n+  const Klass* holder = _method->method_holder()->super();\n+  Symbol* holder_name = holder->name();\n+  ThreadInVMfromUnknown tiv;\n+  JavaThread* current = JavaThread::current();\n+  HandleMark hm(current);\n+  Handle loader(current, _method->method_holder()->class_loader());\n+\n+  \/\/ Walk up the class hierarchy and search for super methods\n+  while (holder != nullptr) {\n+    Method* super_method = holder->lookup_method(name, signature);\n+    if (super_method == nullptr) {\n+      break;\n+    }\n+    if (!super_method->is_static() && !super_method->is_private() &&\n+        (!super_method->is_package_private() ||\n+         super_method->method_holder()->is_same_class_package(loader(), holder_name))) {\n+      _supers->push(super_method);\n+    }\n+    holder = super_method->method_holder()->super();\n+  }\n+  \/\/ Search interfaces for super methods\n+  Array<InstanceKlass*>* interfaces = _method->method_holder()->transitive_interfaces();\n+  for (int i = 0; i < interfaces->length(); ++i) {\n+    Method* m = interfaces->at(i)->lookup_method(name, signature);\n+    if (m != nullptr && !m->is_static() && m->is_public()) {\n+      _supers->push(m);\n+    }\n@@ -2573,0 +2787,50 @@\n+  return _supers;\n+}\n+\n+\/\/ Iterate over arguments and compute scalarized and non-scalarized signatures\n+void CompiledEntrySignature::compute_calling_conventions(bool init) {\n+  bool has_scalarized = false;\n+  if (_method != nullptr) {\n+    InstanceKlass* holder = _method->method_holder();\n+    int arg_num = 0;\n+    if (!_method->is_static()) {\n+      \/\/ We shouldn't scalarize 'this' in a value class constructor\n+      if (holder->is_inline_klass() && InlineKlass::cast(holder)->can_be_passed_as_fields() && !_method->is_object_constructor() &&\n+          (init || _method->is_scalarized_arg(arg_num))) {\n+        _sig_cc->appendAll(InlineKlass::cast(holder)->extended_sig());\n+        has_scalarized = true;\n+        _has_inline_recv = true;\n+        _num_inline_args++;\n+      } else {\n+        SigEntry::add_entry(_sig_cc, T_OBJECT, holder->name());\n+      }\n+      SigEntry::add_entry(_sig, T_OBJECT, holder->name());\n+      SigEntry::add_entry(_sig_cc_ro, T_OBJECT, holder->name());\n+      arg_num++;\n+    }\n+    for (SignatureStream ss(_method->signature()); !ss.at_return_type(); ss.next()) {\n+      BasicType bt = ss.type();\n+      if (bt == T_OBJECT) {\n+        InlineKlass* vk = ss.as_inline_klass(holder);\n+        if (vk != nullptr && vk->can_be_passed_as_fields() && (init || _method->is_scalarized_arg(arg_num))) {\n+          \/\/ Check for a calling convention mismatch with super method(s)\n+          bool scalar_super = false;\n+          bool non_scalar_super = false;\n+          GrowableArray<Method*>* supers = get_supers();\n+          for (int i = 0; i < supers->length(); ++i) {\n+            Method* super_method = supers->at(i);\n+            if (super_method->is_scalarized_arg(arg_num)) {\n+              scalar_super = true;\n+            } else {\n+              non_scalar_super = true;\n+            }\n+          }\n+#ifdef ASSERT\n+          \/\/ Randomly enable below code paths for stress testing\n+          bool stress = init && StressCallingConvention;\n+          if (stress && (os::random() & 1) == 1) {\n+            non_scalar_super = true;\n+            if ((os::random() & 1) == 1) {\n+              scalar_super = true;\n+            }\n+          }\n@@ -2574,0 +2838,51 @@\n+          if (non_scalar_super) {\n+            \/\/ Found a super method with a non-scalarized argument. Fall back to the non-scalarized calling convention.\n+            if (scalar_super) {\n+              \/\/ Found non-scalar *and* scalar super methods. We can't handle both.\n+              \/\/ Mark the scalar method as mismatch and re-compile call sites to use non-scalarized calling convention.\n+              for (int i = 0; i < supers->length(); ++i) {\n+                Method* super_method = supers->at(i);\n+                if (super_method->is_scalarized_arg(arg_num) debug_only(|| (stress && (os::random() & 1) == 1))) {\n+                  super_method->set_mismatch();\n+                  MutexLocker ml(Compile_lock, Mutex::_safepoint_check_flag);\n+                  JavaThread* thread = JavaThread::current();\n+                  HandleMark hm(thread);\n+                  methodHandle mh(thread, super_method);\n+                  DeoptimizationScope deopt_scope;\n+                  CodeCache::mark_for_deoptimization(&deopt_scope, mh());\n+                  deopt_scope.deoptimize_marked();\n+                }\n+              }\n+            }\n+            \/\/ Fall back to non-scalarized calling convention\n+            SigEntry::add_entry(_sig_cc, T_OBJECT, ss.as_symbol());\n+            SigEntry::add_entry(_sig_cc_ro, T_OBJECT, ss.as_symbol());\n+          } else {\n+            _num_inline_args++;\n+            has_scalarized = true;\n+            int last = _sig_cc->length();\n+            int last_ro = _sig_cc_ro->length();\n+            _sig_cc->appendAll(vk->extended_sig());\n+            _sig_cc_ro->appendAll(vk->extended_sig());\n+            if (bt == T_OBJECT) {\n+              \/\/ Nullable inline type argument, insert InlineTypeNode::IsInit field right after T_METADATA delimiter\n+              \/\/ Set the sort_offset so that the field is detected as null marker by nmethod::print_nmethod_labels.\n+              _sig_cc->insert_before(last+1, SigEntry(T_BOOLEAN, -1, 0));\n+              _sig_cc_ro->insert_before(last_ro+1, SigEntry(T_BOOLEAN, -1, 0));\n+            }\n+          }\n+        } else {\n+          SigEntry::add_entry(_sig_cc, T_OBJECT, ss.as_symbol());\n+          SigEntry::add_entry(_sig_cc_ro, T_OBJECT, ss.as_symbol());\n+        }\n+        bt = T_OBJECT;\n+      } else {\n+        SigEntry::add_entry(_sig_cc, ss.type(), ss.as_symbol());\n+        SigEntry::add_entry(_sig_cc_ro, ss.type(), ss.as_symbol());\n+      }\n+      SigEntry::add_entry(_sig, bt, ss.as_symbol());\n+      if (bt != T_VOID) {\n+        arg_num++;\n+      }\n+    }\n+  }\n@@ -2575,1 +2890,11 @@\n- private:\n+  \/\/ Compute the non-scalarized calling convention\n+  _regs = NEW_RESOURCE_ARRAY(VMRegPair, _sig->length());\n+  _args_on_stack = SharedRuntime::java_calling_convention(_sig, _regs);\n+\n+  \/\/ Compute the scalarized calling conventions if there are scalarized inline types in the signature\n+  if (has_scalarized && !_method->is_native()) {\n+    _regs_cc = NEW_RESOURCE_ARRAY(VMRegPair, _sig_cc->length());\n+    _args_on_stack_cc = SharedRuntime::java_calling_convention(_sig_cc, _regs_cc);\n+\n+    _regs_cc_ro = NEW_RESOURCE_ARRAY(VMRegPair, _sig_cc_ro->length());\n+    _args_on_stack_cc_ro = SharedRuntime::java_calling_convention(_sig_cc_ro, _regs_cc_ro);\n@@ -2577,5 +2902,8 @@\n-  friend class SignatureIterator;  \/\/ so do_parameters_on can call do_type\n-  void do_type(BasicType type) {\n-    sig_bt[index++] = type;\n-    if (type == T_LONG || type == T_DOUBLE) {\n-      sig_bt[index++] = T_VOID; \/\/ Longs & doubles take 2 Java slots\n+    _c1_needs_stack_repair = (_args_on_stack_cc < _args_on_stack) || (_args_on_stack_cc_ro < _args_on_stack);\n+    _c2_needs_stack_repair = (_args_on_stack_cc > _args_on_stack) || (_args_on_stack_cc > _args_on_stack_cc_ro);\n+\n+    \/\/ Upper bound on stack arguments to avoid hitting the argument limit and\n+    \/\/ bailing out of compilation (\"unsupported incoming calling sequence\").\n+    \/\/ TODO we need a reasonable limit (flag?) here\n+    if (MAX2(_args_on_stack_cc, _args_on_stack_cc_ro) <= 60) {\n+      return; \/\/ Success\n@@ -2584,1 +2912,10 @@\n-};\n+\n+  \/\/ No scalarized args\n+  _sig_cc = _sig;\n+  _regs_cc = _regs;\n+  _args_on_stack_cc = _args_on_stack;\n+\n+  _sig_cc_ro = _sig;\n+  _regs_cc_ro = _regs;\n+  _args_on_stack_cc_ro = _args_on_stack;\n+}\n@@ -2601,2 +2938,15 @@\n-  \/\/ Fill in the signature array, for the calling-convention call.\n-  int total_args_passed = method->size_of_parameters(); \/\/ All args on stack\n+  CompiledEntrySignature ces(method());\n+  ces.compute_calling_conventions();\n+  if (ces.has_scalarized_args()) {\n+    if (!method->has_scalarized_args()) {\n+      method->set_has_scalarized_args();\n+    }\n+    if (ces.c1_needs_stack_repair()) {\n+      method->set_c1_needs_stack_repair();\n+    }\n+    if (ces.c2_needs_stack_repair() && !method->c2_needs_stack_repair()) {\n+      method->set_c2_needs_stack_repair();\n+    }\n+  } else if (method->is_abstract()) {\n+    return _abstract_method_handler;\n+  }\n@@ -2604,4 +2954,0 @@\n-  AdapterSignatureIterator si(method->signature(), method->constMethod()->fingerprint(),\n-                              method->is_static(), total_args_passed);\n-  assert(si.slots() == total_args_passed, \"\");\n-  BasicType* sig_bt = si.basic_types();\n@@ -2611,0 +2957,13 @@\n+    if (ces.has_scalarized_args() && method->is_abstract()) {\n+      \/\/ Save a C heap allocated version of the signature for abstract methods with scalarized inline type arguments\n+      address wrong_method_abstract = SharedRuntime::get_handle_wrong_method_abstract_stub();\n+      entry = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(nullptr),\n+                                               SharedRuntime::throw_AbstractMethodError_entry(),\n+                                               wrong_method_abstract, wrong_method_abstract, wrong_method_abstract,\n+                                               wrong_method_abstract, wrong_method_abstract);\n+      GrowableArray<SigEntry>* heap_sig = new (mtInternal) GrowableArray<SigEntry>(ces.sig_cc_ro()->length(), mtInternal);\n+      heap_sig->appendAll(ces.sig_cc_ro());\n+      entry->set_sig_cc(heap_sig);\n+      return entry;\n+    }\n+\n@@ -2612,1 +2971,1 @@\n-    entry = lookup(total_args_passed, sig_bt);\n+    entry = lookup(ces.sig_cc(), ces.has_inline_recv());\n@@ -2618,1 +2977,1 @@\n-        AdapterHandlerEntry* comparison_entry = create_adapter(comparison_blob, total_args_passed, sig_bt, false);\n+        AdapterHandlerEntry* comparison_entry = create_adapter(comparison_blob, ces, false);\n@@ -2628,1 +2987,1 @@\n-    entry = create_adapter(new_adapter, total_args_passed, sig_bt, \/* allocate_code_blob *\/ true);\n+    entry = create_adapter(new_adapter, ces, \/* allocate_code_blob *\/ true);\n@@ -2639,2 +2998,1 @@\n-                                                           int total_args_passed,\n-                                                           BasicType* sig_bt,\n+                                                           CompiledEntrySignature& ces,\n@@ -2652,5 +3010,0 @@\n-  VMRegPair stack_regs[16];\n-  VMRegPair* regs = (total_args_passed <= 16) ? stack_regs : NEW_RESOURCE_ARRAY(VMRegPair, total_args_passed);\n-\n-  \/\/ Get a description of the compiled java calling convention and the largest used (VMReg) stack slot usage\n-  int comp_args_on_stack = SharedRuntime::java_calling_convention(sig_bt, regs, total_args_passed);\n@@ -2664,1 +3017,1 @@\n-  AdapterFingerPrint* fingerprint = new AdapterFingerPrint(total_args_passed, sig_bt);\n+  AdapterFingerPrint* fingerprint = new AdapterFingerPrint(ces.sig_cc(), ces.has_inline_recv());\n@@ -2667,5 +3020,17 @@\n-                                                total_args_passed,\n-                                                comp_args_on_stack,\n-                                                sig_bt,\n-                                                regs,\n-                                                fingerprint);\n+                                                ces.args_on_stack(),\n+                                                ces.sig(),\n+                                                ces.regs(),\n+                                                ces.sig_cc(),\n+                                                ces.regs_cc(),\n+                                                ces.sig_cc_ro(),\n+                                                ces.regs_cc_ro(),\n+                                                fingerprint,\n+                                                new_adapter,\n+                                                allocate_code_blob);\n+\n+  if (ces.has_scalarized_args()) {\n+    \/\/ Save a C heap allocated version of the scalarized signature and store it in the adapter\n+    GrowableArray<SigEntry>* heap_sig = new (mtInternal) GrowableArray<SigEntry>(ces.sig_cc()->length(), mtInternal);\n+    heap_sig->appendAll(ces.sig_cc());\n+    entry->set_sig_cc(heap_sig);\n+  }\n@@ -2682,1 +3047,0 @@\n-  new_adapter = AdapterBlob::create(&buffer);\n@@ -2724,0 +3088,2 @@\n+  assert(base <= _c2i_inline_entry || _c2i_inline_entry == nullptr, \"\");\n+  assert(base <= _c2i_inline_ro_entry || _c2i_inline_ro_entry == nullptr, \"\");\n@@ -2725,0 +3091,1 @@\n+  assert(base <= _c2i_unverified_inline_entry || _c2i_unverified_inline_entry == nullptr, \"\");\n@@ -2737,0 +3104,4 @@\n+  if (_c2i_inline_entry != nullptr)\n+    _c2i_inline_entry += delta;\n+  if (_c2i_inline_ro_entry != nullptr)\n+    _c2i_inline_ro_entry += delta;\n@@ -2739,0 +3110,2 @@\n+  if (_c2i_unverified_inline_entry != nullptr)\n+    _c2i_unverified_inline_entry += delta;\n@@ -2747,0 +3120,3 @@\n+  if (_sig_cc != nullptr) {\n+    delete _sig_cc;\n+  }\n@@ -2833,0 +3209,1 @@\n+      BasicType stack_sig_bt[16];\n@@ -2834,0 +3211,1 @@\n+      BasicType* sig_bt = (total_args_passed <= 16) ? stack_sig_bt : NEW_RESOURCE_ARRAY(BasicType, total_args_passed);\n@@ -2836,5 +3214,13 @@\n-      AdapterSignatureIterator si(method->signature(), method->constMethod()->fingerprint(),\n-                              method->is_static(), total_args_passed);\n-      BasicType* sig_bt = si.basic_types();\n-      assert(si.slots() == total_args_passed, \"\");\n-      BasicType ret_type = si.return_type();\n+      int i = 0;\n+      if (!method->is_static()) {  \/\/ Pass in receiver first\n+        sig_bt[i++] = T_OBJECT;\n+      }\n+      SignatureStream ss(method->signature());\n+      for (; !ss.at_return_type(); ss.next()) {\n+        sig_bt[i++] = ss.type();  \/\/ Collect remaining bits of signature\n+        if (ss.type() == T_LONG || ss.type() == T_DOUBLE) {\n+          sig_bt[i++] = T_VOID;   \/\/ Longs & doubles take 2 Java slots\n+        }\n+      }\n+      assert(i == total_args_passed, \"\");\n+      BasicType ret_type = ss.type();\n@@ -3087,0 +3473,6 @@\n+  if (get_c2i_entry() != nullptr) {\n+    st->print(\" c2iVE: \" INTPTR_FORMAT, p2i(get_c2i_inline_entry()));\n+  }\n+  if (get_c2i_entry() != nullptr) {\n+    st->print(\" c2iVROE: \" INTPTR_FORMAT, p2i(get_c2i_inline_ro_entry()));\n+  }\n@@ -3088,1 +3480,4 @@\n-    st->print(\" c2iUV: \" INTPTR_FORMAT, p2i(get_c2i_unverified_entry()));\n+    st->print(\" c2iUE: \" INTPTR_FORMAT, p2i(get_c2i_unverified_entry()));\n+  }\n+  if (get_c2i_unverified_entry() != nullptr) {\n+    st->print(\" c2iUVE: \" INTPTR_FORMAT, p2i(get_c2i_unverified_inline_entry()));\n@@ -3177,0 +3572,195 @@\n+\n+\/\/ We are at a compiled code to interpreter call. We need backing\n+\/\/ buffers for all inline type arguments. Allocate an object array to\n+\/\/ hold them (convenient because once we're done with it we don't have\n+\/\/ to worry about freeing it).\n+oop SharedRuntime::allocate_inline_types_impl(JavaThread* current, methodHandle callee, bool allocate_receiver, TRAPS) {\n+  assert(InlineTypePassFieldsAsArgs, \"no reason to call this\");\n+  ResourceMark rm;\n+\n+  int nb_slots = 0;\n+  InstanceKlass* holder = callee->method_holder();\n+  allocate_receiver &= !callee->is_static() && holder->is_inline_klass() && callee->is_scalarized_arg(0);\n+  if (allocate_receiver) {\n+    nb_slots++;\n+  }\n+  int arg_num = callee->is_static() ? 0 : 1;\n+  for (SignatureStream ss(callee->signature()); !ss.at_return_type(); ss.next()) {\n+    BasicType bt = ss.type();\n+    if (bt == T_OBJECT && callee->is_scalarized_arg(arg_num)) {\n+      nb_slots++;\n+    }\n+    if (bt != T_VOID) {\n+      arg_num++;\n+    }\n+  }\n+  objArrayOop array_oop = oopFactory::new_objectArray(nb_slots, CHECK_NULL);\n+  objArrayHandle array(THREAD, array_oop);\n+  arg_num = callee->is_static() ? 0 : 1;\n+  int i = 0;\n+  if (allocate_receiver) {\n+    InlineKlass* vk = InlineKlass::cast(holder);\n+    oop res = vk->allocate_instance(CHECK_NULL);\n+    array->obj_at_put(i++, res);\n+  }\n+  for (SignatureStream ss(callee->signature()); !ss.at_return_type(); ss.next()) {\n+    BasicType bt = ss.type();\n+    if (bt == T_OBJECT && callee->is_scalarized_arg(arg_num)) {\n+      InlineKlass* vk = ss.as_inline_klass(holder);\n+      assert(vk != nullptr, \"Unexpected klass\");\n+      oop res = vk->allocate_instance(CHECK_NULL);\n+      array->obj_at_put(i++, res);\n+    }\n+    if (bt != T_VOID) {\n+      arg_num++;\n+    }\n+  }\n+  return array();\n+}\n+\n+JRT_ENTRY(void, SharedRuntime::allocate_inline_types(JavaThread* current, Method* callee_method, bool allocate_receiver))\n+  methodHandle callee(current, callee_method);\n+  oop array = SharedRuntime::allocate_inline_types_impl(current, callee, allocate_receiver, CHECK);\n+  current->set_vm_result(array);\n+  current->set_vm_result_2(callee()); \/\/ TODO: required to keep callee live?\n+JRT_END\n+\n+\/\/ We're returning from an interpreted method: load each field into a\n+\/\/ register following the calling convention\n+JRT_LEAF(void, SharedRuntime::load_inline_type_fields_in_regs(JavaThread* current, oopDesc* res))\n+{\n+  assert(res->klass()->is_inline_klass(), \"only inline types here\");\n+  ResourceMark rm;\n+  RegisterMap reg_map(current,\n+                      RegisterMap::UpdateMap::include,\n+                      RegisterMap::ProcessFrames::include,\n+                      RegisterMap::WalkContinuation::skip);\n+  frame stubFrame = current->last_frame();\n+  frame callerFrame = stubFrame.sender(&reg_map);\n+  assert(callerFrame.is_interpreted_frame(), \"should be coming from interpreter\");\n+\n+  InlineKlass* vk = InlineKlass::cast(res->klass());\n+\n+  const Array<SigEntry>* sig_vk = vk->extended_sig();\n+  const Array<VMRegPair>* regs = vk->return_regs();\n+\n+  if (regs == nullptr) {\n+    \/\/ The fields of the inline klass don't fit in registers, bail out\n+    return;\n+  }\n+\n+  int j = 1;\n+  for (int i = 0; i < sig_vk->length(); i++) {\n+    BasicType bt = sig_vk->at(i)._bt;\n+    if (bt == T_METADATA) {\n+      continue;\n+    }\n+    if (bt == T_VOID) {\n+      if (sig_vk->at(i-1)._bt == T_LONG ||\n+          sig_vk->at(i-1)._bt == T_DOUBLE) {\n+        j++;\n+      }\n+      continue;\n+    }\n+    int off = sig_vk->at(i)._offset;\n+    assert(off > 0, \"offset in object should be positive\");\n+    VMRegPair pair = regs->at(j);\n+    address loc = reg_map.location(pair.first(), nullptr);\n+    switch(bt) {\n+    case T_BOOLEAN:\n+      *(jboolean*)loc = res->bool_field(off);\n+      break;\n+    case T_CHAR:\n+      *(jchar*)loc = res->char_field(off);\n+      break;\n+    case T_BYTE:\n+      *(jbyte*)loc = res->byte_field(off);\n+      break;\n+    case T_SHORT:\n+      *(jshort*)loc = res->short_field(off);\n+      break;\n+    case T_INT: {\n+      *(jint*)loc = res->int_field(off);\n+      break;\n+    }\n+    case T_LONG:\n+#ifdef _LP64\n+      *(intptr_t*)loc = res->long_field(off);\n+#else\n+      Unimplemented();\n+#endif\n+      break;\n+    case T_OBJECT:\n+    case T_ARRAY: {\n+      *(oop*)loc = res->obj_field(off);\n+      break;\n+    }\n+    case T_FLOAT:\n+      *(jfloat*)loc = res->float_field(off);\n+      break;\n+    case T_DOUBLE:\n+      *(jdouble*)loc = res->double_field(off);\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n+    j++;\n+  }\n+  assert(j == regs->length(), \"missed a field?\");\n+\n+#ifdef ASSERT\n+  VMRegPair pair = regs->at(0);\n+  address loc = reg_map.location(pair.first(), nullptr);\n+  assert(*(oopDesc**)loc == res, \"overwritten object\");\n+#endif\n+\n+  current->set_vm_result(res);\n+}\n+JRT_END\n+\n+\/\/ We've returned to an interpreted method, the interpreter needs a\n+\/\/ reference to an inline type instance. Allocate it and initialize it\n+\/\/ from field's values in registers.\n+JRT_BLOCK_ENTRY(void, SharedRuntime::store_inline_type_fields_to_buf(JavaThread* current, intptr_t res))\n+{\n+  ResourceMark rm;\n+  RegisterMap reg_map(current,\n+                      RegisterMap::UpdateMap::include,\n+                      RegisterMap::ProcessFrames::include,\n+                      RegisterMap::WalkContinuation::skip);\n+  frame stubFrame = current->last_frame();\n+  frame callerFrame = stubFrame.sender(&reg_map);\n+\n+#ifdef ASSERT\n+  InlineKlass* verif_vk = InlineKlass::returned_inline_klass(reg_map);\n+#endif\n+\n+  if (!is_set_nth_bit(res, 0)) {\n+    \/\/ We're not returning with inline type fields in registers (the\n+    \/\/ calling convention didn't allow it for this inline klass)\n+    assert(!Metaspace::contains((void*)res), \"should be oop or pointer in buffer area\");\n+    current->set_vm_result((oopDesc*)res);\n+    assert(verif_vk == nullptr, \"broken calling convention\");\n+    return;\n+  }\n+\n+  clear_nth_bit(res, 0);\n+  InlineKlass* vk = (InlineKlass*)res;\n+  assert(verif_vk == vk, \"broken calling convention\");\n+  assert(Metaspace::contains((void*)res), \"should be klass\");\n+\n+  \/\/ Allocate handles for every oop field so they are safe in case of\n+  \/\/ a safepoint when allocating\n+  GrowableArray<Handle> handles;\n+  vk->save_oop_fields(reg_map, handles);\n+\n+  \/\/ It's unsafe to safepoint until we are here\n+  JRT_BLOCK;\n+  {\n+    JavaThread* THREAD = current;\n+    oop vt = vk->realloc_result(reg_map, handles, CHECK);\n+    current->set_vm_result(vt);\n+  }\n+  JRT_BLOCK_END;\n+}\n+JRT_END\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":724,"deletions":134,"binary":false,"changes":858,"status":"modified"},{"patch":"@@ -95,0 +95,1 @@\n+  do_blob(new_null_free_array)                                         \\\n@@ -96,0 +97,5 @@\n+  do_blob(load_flat_array)                                             \\\n+  do_blob(store_flat_array)                                            \\\n+  do_blob(substitutability_check)                                      \\\n+  do_blob(buffer_inline_args)                                          \\\n+  do_blob(buffer_inline_args_no_receiver)                              \\\n@@ -102,0 +108,2 @@\n+  do_blob(throw_illegal_monitor_state_exception)                       \\\n+  do_blob(throw_identity_exception)                                    \\\n@@ -170,0 +178,2 @@\n+  do_stub(load_unknown_inline, 0, true, false)                         \\\n+  do_stub(store_unknown_inline, 0, true, false)                        \\\n","filename":"src\/hotspot\/share\/runtime\/stubDeclarations.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -411,0 +411,1 @@\n+  initialize_class(vmSymbols::java_lang_IdentityException(), CHECK);\n","filename":"src\/hotspot\/share\/runtime\/threads.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+import java.lang.reflect.ClassFileFormatVersion;\n@@ -73,0 +74,1 @@\n+import jdk.internal.javac.PreviewFeature;\n@@ -75,0 +77,1 @@\n+import jdk.internal.misc.PreviewFeatures;\n@@ -220,3 +223,3 @@\n-    private static final int ANNOTATION= 0x00002000;\n-    private static final int ENUM      = 0x00004000;\n-    private static final int SYNTHETIC = 0x00001000;\n+    private static final int ANNOTATION = 0x00002000;\n+    private static final int ENUM       = 0x00004000;\n+    private static final int SYNTHETIC  = 0x00001000;\n@@ -318,0 +321,2 @@\n+                \/\/ Modifier.toString() below mis-interprets SYNCHRONIZED, STRICT, and VOLATILE bits\n+                modifiers &= ~(Modifier.SYNCHRONIZED | Modifier.STRICT | Modifier.VOLATILE);\n@@ -331,0 +336,3 @@\n+                if (isValue()) {\n+                    sb.append(\"value \");\n+                }\n@@ -605,0 +613,33 @@\n+    \/**\n+     * {@return {@code true} if this {@code Class} object represents an identity\n+     * class or interface; otherwise {@code false}}\n+     *\n+     * If this {@code Class} object represents an array type, then this method\n+     * returns {@code true}.\n+     * If this {@code Class} object represents a primitive type, or {@code void},\n+     * then this method returns {@code false}.\n+     *\n+     * @since Valhalla\n+     *\/\n+    @PreviewFeature(feature = PreviewFeature.Feature.VALUE_OBJECTS, reflective=true)\n+    public native boolean isIdentity();\n+\n+    \/**\n+     * {@return {@code true} if this {@code Class} object represents a value\n+     * class; otherwise {@code false}}\n+     *\n+     * If this {@code Class} object represents an array type, an interface,\n+     * a primitive type, or {@code void}, then this method returns {@code false}.\n+     *\n+     * @since Valhalla\n+     *\/\n+    @PreviewFeature(feature = PreviewFeature.Feature.VALUE_OBJECTS, reflective=true)\n+    public boolean isValue() {\n+        if (!PreviewFeatures.isEnabled()) {\n+            return false;\n+        }\n+         if (isPrimitive() || isArray() || isInterface())\n+             return false;\n+        return ((getModifiers() & Modifier.IDENTITY) == 0);\n+    }\n+\n@@ -1331,0 +1372,1 @@\n+     * <li> its {@code identity} modifier is always true\n@@ -1355,1 +1397,1 @@\n-    \/**\n+   \/**\n@@ -1358,0 +1400,1 @@\n+     * The {@code AccessFlags} may depend on the class file format version of the class.\n@@ -1366,0 +1409,1 @@\n+    * <li> its {@code identity} modifier is always true\n@@ -1387,4 +1431,11 @@\n-        return AccessFlag.maskToAccessFlags((location == AccessFlag.Location.CLASS) ?\n-                                            getClassAccessFlagsRaw() :\n-                                            getModifiers(),\n-                                            location);\n+        int accessFlags = (location == AccessFlag.Location.CLASS) ?\n+                getClassAccessFlagsRaw() : getModifiers();\n+        if (isArray() && PreviewFeatures.isEnabled()) {\n+            accessFlags |= Modifier.IDENTITY;\n+        }\n+        var cffv = ClassFileFormatVersion.fromMajor(getClassFileVersion() & 0xffff);\n+        if (cffv.compareTo(ClassFileFormatVersion.latest()) >= 0) {\n+            \/\/ Ignore unspecified (0x0800) access flag for current version\n+            accessFlags &= ~0x0800;\n+        }\n+        return AccessFlag.maskToAccessFlags(accessFlags, location, cffv);\n@@ -1393,1 +1444,1 @@\n-    \/**\n+   \/**\n@@ -1401,0 +1452,1 @@\n+\n@@ -3788,1 +3840,1 @@\n-         return TypeAnnotationParser.buildAnnotatedInterfaces(getRawTypeAnnotations(), getConstantPool(), this);\n+        return TypeAnnotationParser.buildAnnotatedInterfaces(getRawTypeAnnotations(), getConstantPool(), this);\n@@ -4128,1 +4180,2 @@\n-    private int getClassFileVersion() {\n+    \/* package-private *\/\n+    int getClassFileVersion() {\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Class.java","additions":64,"deletions":11,"binary":false,"changes":75,"status":"modified"},{"patch":"@@ -482,0 +482,1 @@\n+ *     | LoadableDescriptorsAttribute?(List<Utf8Entry> loadableDescriptors)\n","filename":"src\/java.base\/share\/classes\/java\/lang\/classfile\/package-info.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -59,0 +59,1 @@\n+    {\"isIdentity\",       \"()Z\",             (void *)&JVM_IsIdentityClass},\n","filename":"src\/java.base\/share\/native\/libjava\/Class.c","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -182,0 +182,2 @@\n+        allowValueClasses = (!preview.isPreview(Feature.VALUE_CLASSES) || preview.isEnabled()) &&\n+                Feature.VALUE_CLASSES.allowedInSource(source);\n@@ -221,0 +223,4 @@\n+    \/** Are value classes allowed\n+     *\/\n+    private final boolean allowValueClasses;\n+\n@@ -728,0 +734,25 @@\n+    void checkConstraintsOfValueClass(JCClassDecl tree, ClassSymbol c) {\n+        DiagnosticPosition pos = tree.pos();\n+        for (Type st : types.closure(c.type)) {\n+            if (st == null || st.tsym == null || st.tsym.kind == ERR)\n+                continue;\n+            if  (st.tsym == syms.objectType.tsym || st.tsym == syms.recordType.tsym || st.isInterface())\n+                continue;\n+            if (!st.tsym.isAbstract()) {\n+                if (c != st.tsym) {\n+                    log.error(pos, Errors.ConcreteSupertypeForValueClass(c, st));\n+                }\n+                continue;\n+            }\n+            \/\/ dealing with an abstract value or value super class below.\n+            for (Symbol s : st.tsym.members().getSymbols(NON_RECURSIVE)) {\n+                if (s.kind == MTH) {\n+                    if ((s.flags() & (SYNCHRONIZED | STATIC)) == SYNCHRONIZED) {\n+                        log.error(pos, Errors.SuperClassMethodCannotBeSynchronized(s, c, st));\n+                    }\n+                    break;\n+                }\n+            }\n+        }\n+    }\n+\n@@ -785,0 +816,26 @@\n+    \/** Check that type is an identity type, i.e. not a value type.\n+     *  When not discernible statically, give it the benefit of doubt\n+     *  and defer to runtime.\n+     *\n+     *  @param pos           Position to be used for error reporting.\n+     *  @param t             The type to be checked.\n+     *\/\n+    boolean checkIdentityType(DiagnosticPosition pos, Type t) {\n+        if (t.hasTag(TYPEVAR)) {\n+            t = types.skipTypeVars(t, false);\n+        }\n+        if (t.isIntersection()) {\n+            IntersectionClassType ict = (IntersectionClassType)t;\n+            boolean result = true;\n+            for (Type component : ict.getExplicitComponents()) {\n+                result &= checkIdentityType(pos, component);\n+            }\n+            return result;\n+        }\n+        if (t.isPrimitive() || (t.isValueClass() && !t.tsym.isAbstract())) {\n+            typeTagError(pos, diags.fragment(Fragments.TypeReqIdentity), t);\n+            return false;\n+        }\n+        return true;\n+    }\n+\n@@ -1176,2 +1233,7 @@\n-            else\n-                mask = VarFlags;\n+            else {\n+                boolean isInstanceFieldOfValueClass = sym.owner.type.isValueClass() && (flags & STATIC) == 0;\n+                mask = !isInstanceFieldOfValueClass ? VarFlags : ValueFieldFlags;\n+                if (isInstanceFieldOfValueClass) {\n+                    implicit |= FINAL | STRICT;\n+                }\n+            }\n@@ -1203,1 +1265,2 @@\n-                mask = RecordMethodFlags;\n+                mask = ((sym.owner.flags_field & VALUE_CLASS) != 0 && (flags & Flags.STATIC) == 0) ?\n+                        RecordMethodFlags & ~SYNCHRONIZED : RecordMethodFlags;\n@@ -1205,1 +1268,3 @@\n-                mask = MethodFlags;\n+                \/\/ value objects do not have an associated monitor\/lock\n+                mask = ((sym.owner.flags_field & VALUE_CLASS) != 0 && (flags & Flags.STATIC) == 0) ?\n+                        MethodFlags & ~SYNCHRONIZED : MethodFlags;\n@@ -1222,1 +1287,1 @@\n-                mask = staticOrImplicitlyStatic && allowRecords && (flags & ANNOTATION) == 0 ? StaticLocalFlags : LocalClassFlags;\n+                mask = staticOrImplicitlyStatic && allowRecords && (flags & ANNOTATION) == 0 ? ExtendedStaticLocalClassFlags : ExtendedLocalClassFlags;\n@@ -1238,0 +1303,4 @@\n+            if ((flags & (VALUE_CLASS | SEALED | ABSTRACT)) == (VALUE_CLASS | SEALED) ||\n+                (flags & (VALUE_CLASS | NON_SEALED | ABSTRACT)) == (VALUE_CLASS | NON_SEALED)) {\n+                log.error(pos, Errors.NonAbstractValueClassCantBeSealedOrNonSealed);\n+            }\n@@ -1241,0 +1310,4 @@\n+            if ((flags & (INTERFACE | VALUE_CLASS)) == 0) {\n+                implicit |= IDENTITY_TYPE;\n+            }\n+\n@@ -1242,2 +1315,2 @@\n-                \/\/ enums can't be declared abstract, final, sealed or non-sealed\n-                mask &= ~(ABSTRACT | FINAL | SEALED | NON_SEALED);\n+                \/\/ enums can't be declared abstract, final, sealed or non-sealed or value\n+                mask &= ~(ABSTRACT | FINAL | SEALED | NON_SEALED | VALUE_CLASS);\n@@ -1256,0 +1329,5 @@\n+\n+            \/\/ concrete value classes are implicitly final\n+            if ((flags & (ABSTRACT | INTERFACE | VALUE_CLASS)) == VALUE_CLASS) {\n+                implicit |= FINAL;\n+            }\n@@ -1270,2 +1348,1 @@\n-        }\n-        else if ((sym.kind == TYP ||\n+        } else if ((sym.kind == TYP ||\n@@ -1294,1 +1371,2 @@\n-                 checkDisjoint(pos, flags,\n+                 \/\/ we are using `implicit` here as instance fields of value classes are implicitly final\n+                 checkDisjoint(pos, flags | implicit,\n@@ -1310,1 +1388,7 @@\n-                                ANNOTATION)) {\n+                                ANNOTATION)\n+                && checkDisjoint(pos, flags,\n+                                VALUE_CLASS,\n+                                ANNOTATION)\n+                && checkDisjoint(pos, flags,\n+                                VALUE_CLASS,\n+                                INTERFACE) ) {\n@@ -2122,0 +2206,5 @@\n+        if (allowValueClasses && origin.isValueClass() && names.finalize.equals(m.name)) {\n+            if (m.overrides(syms.objectFinalize, origin, types, false)) {\n+                log.warning(tree.pos(), Warnings.ValueFinalize);\n+            }\n+        }\n@@ -2557,0 +2646,12 @@\n+\n+        Type identitySuper = null;\n+        for (Type t : types.closure(c)) {\n+            if (t != c) {\n+                if (t.isIdentityClass() && (t.tsym.flags() & VALUE_BASED) == 0)\n+                    identitySuper = t;\n+                if (c.isValueClass() && identitySuper != null && identitySuper.tsym != syms.objectType.tsym) { \/\/ Object is special\n+                    log.error(pos, Errors.ValueTypeHasIdentitySuperType(c, identitySuper));\n+                    break;\n+                }\n+            }\n+        }\n@@ -4909,2 +5010,2 @@\n-    public void checkSerialStructure(JCClassDecl tree, ClassSymbol c) {\n-        (new SerialTypeVisitor()).visit(c, tree);\n+    public void checkSerialStructure(Env<AttrContext> env, JCClassDecl tree, ClassSymbol c) {\n+        (new SerialTypeVisitor(env)).visit(c, tree);\n@@ -4941,1 +5042,2 @@\n-        SerialTypeVisitor() {\n+        Env<AttrContext> env;\n+        SerialTypeVisitor(Env<AttrContext> env) {\n@@ -4943,0 +5045,1 @@\n+            this.env = env;\n@@ -5002,0 +5105,1 @@\n+            final boolean[] hasWriteReplace = {false};\n@@ -5076,1 +5180,1 @@\n-                            case \"writeReplace\"     -> checkWriteReplace(tree,e, method);\n+                            case \"writeReplace\"     -> {hasWriteReplace[0] = true; hasAppropriateWriteReplace(tree, method, true);}\n@@ -5087,1 +5191,20 @@\n-\n+            if (!hasWriteReplace[0] &&\n+                    (c.isValueClass() || hasAbstractValueSuperClass(c, Set.of(syms.numberType.tsym))) &&\n+                    !c.isAbstract() && !c.isRecord() &&\n+                    types.unboxedType(c.type) == Type.noType) {\n+                \/\/ we need to check if the class is inheriting an appropriate writeReplace method\n+                MethodSymbol ms = null;\n+                Log.DiagnosticHandler discardHandler = new Log.DiscardDiagnosticHandler(log);\n+                try {\n+                    ms = rs.resolveInternalMethod(env.tree, env, c.type, names.writeReplace, List.nil(), List.nil());\n+                } catch (FatalError fe) {\n+                    \/\/ ignore no method was found\n+                } finally {\n+                    log.popDiagnosticHandler(discardHandler);\n+                }\n+                if (ms == null || !hasAppropriateWriteReplace(p, ms, false)) {\n+                    log.warning(p.pos(),\n+                            c.isValueClass() ? LintWarnings.SerializableValueClassWithoutWriteReplace1 :\n+                                    LintWarnings.SerializableValueClassWithoutWriteReplace2);\n+                }\n+            }\n@@ -5095,0 +5218,16 @@\n+        private boolean hasAbstractValueSuperClass(Symbol c, Set<Symbol> excluding) {\n+            while (c.getKind() == ElementKind.CLASS) {\n+                Type sup = ((ClassSymbol)c).getSuperclass();\n+                if (!sup.hasTag(CLASS) || sup.isErroneous() ||\n+                        sup.tsym == syms.objectType.tsym) {\n+                    return false;\n+                }\n+                \/\/ if it is a value super class it has to be abstract\n+                if (sup.isValueClass() && !excluding.contains(sup.tsym)) {\n+                    return true;\n+                }\n+                c = sup.tsym;\n+            }\n+            return false;\n+        }\n+\n@@ -5218,1 +5357,1 @@\n-            checkReturnType(tree, e, method, syms.voidType);\n+            isExpectedReturnType(tree, method, syms.voidType, true);\n@@ -5220,1 +5359,1 @@\n-            checkExceptions(tree, e, method, syms.ioExceptionType);\n+            hasExpectedExceptions(tree, method, true, syms.ioExceptionType);\n@@ -5224,1 +5363,1 @@\n-        private void checkWriteReplace(JCClassDecl tree, Element e, MethodSymbol method) {\n+        private boolean hasAppropriateWriteReplace(JCClassDecl tree, MethodSymbol method, boolean warn) {\n@@ -5230,4 +5369,4 @@\n-            checkConcreteInstanceMethod(tree, e, method);\n-            checkReturnType(tree, e, method, syms.objectType);\n-            checkNoArgs(tree, e, method);\n-            checkExceptions(tree, e, method, syms.objectStreamExceptionType);\n+            return isConcreteInstanceMethod(tree, method, warn) &&\n+                    isExpectedReturnType(tree, method, syms.objectType, warn) &&\n+                    hasNoArgs(tree, method, warn) &&\n+                    hasExpectedExceptions(tree, method, warn, syms.objectStreamExceptionType);\n@@ -5244,1 +5383,1 @@\n-            checkReturnType(tree, e, method, syms.voidType);\n+            isExpectedReturnType(tree, method, syms.voidType, true);\n@@ -5246,1 +5385,1 @@\n-            checkExceptions(tree, e, method, syms.ioExceptionType, syms.classNotFoundExceptionType);\n+            hasExpectedExceptions(tree, method, true, syms.ioExceptionType, syms.classNotFoundExceptionType);\n@@ -5253,3 +5392,3 @@\n-            checkReturnType(tree, e, method, syms.voidType);\n-            checkNoArgs(tree, e, method);\n-            checkExceptions(tree, e, method, syms.objectStreamExceptionType);\n+            isExpectedReturnType(tree, method, syms.voidType, true);\n+            hasNoArgs(tree, method, true);\n+            hasExpectedExceptions(tree, method, true, syms.objectStreamExceptionType);\n@@ -5265,4 +5404,4 @@\n-            checkConcreteInstanceMethod(tree, e, method);\n-            checkReturnType(tree,e, method, syms.objectType);\n-            checkNoArgs(tree, e, method);\n-            checkExceptions(tree, e, method, syms.objectStreamExceptionType);\n+            isConcreteInstanceMethod(tree, method, true);\n+            isExpectedReturnType(tree, method, syms.objectType, true);\n+            hasNoArgs(tree, method, true);\n+            hasExpectedExceptions(tree, method, true, syms.objectStreamExceptionType);\n@@ -5518,1 +5657,1 @@\n-                        case \"writeReplace\" -> checkWriteReplace(tree, e, method);\n+                        case \"writeReplace\" -> hasAppropriateWriteReplace(tree, method, true);\n@@ -5536,3 +5675,3 @@\n-        void checkConcreteInstanceMethod(JCClassDecl tree,\n-                                         Element enclosing,\n-                                         MethodSymbol method) {\n+        boolean isConcreteInstanceMethod(JCClassDecl tree,\n+                                         MethodSymbol method,\n+                                         boolean warn) {\n@@ -5540,0 +5679,1 @@\n+                if (warn) {\n@@ -5543,0 +5683,2 @@\n+                }\n+                return false;\n@@ -5544,0 +5686,1 @@\n+            return true;\n@@ -5546,4 +5689,4 @@\n-        private void checkReturnType(JCClassDecl tree,\n-                                     Element enclosing,\n-                                     MethodSymbol method,\n-                                     Type expectedReturnType) {\n+        private boolean isExpectedReturnType(JCClassDecl tree,\n+                                          MethodSymbol method,\n+                                          Type expectedReturnType,\n+                                          boolean warn) {\n@@ -5557,2 +5700,3 @@\n-                log.warning(\n-                        TreeInfo.diagnosticPositionFor(method, tree),\n+                if (warn) {\n+                    log.warning(\n+                            TreeInfo.diagnosticPositionFor(method, tree),\n@@ -5561,0 +5705,2 @@\n+                }\n+                return false;\n@@ -5562,0 +5708,1 @@\n+            return true;\n@@ -5599,1 +5746,1 @@\n-        private void checkNoArgs(JCClassDecl tree, Element enclosing, MethodSymbol method) {\n+        boolean hasNoArgs(JCClassDecl tree, MethodSymbol method, boolean warn) {\n@@ -5602,2 +5749,3 @@\n-                log.warning(\n-                        TreeInfo.diagnosticPositionFor(parameters.get(0), tree),\n+                if (warn) {\n+                    log.warning(\n+                            TreeInfo.diagnosticPositionFor(parameters.get(0), tree),\n@@ -5605,0 +5753,2 @@\n+                }\n+                return false;\n@@ -5606,0 +5756,1 @@\n+            return true;\n@@ -5618,4 +5769,4 @@\n-        private void checkExceptions(JCClassDecl tree,\n-                                     Element enclosing,\n-                                     MethodSymbol method,\n-                                     Type... declaredExceptions) {\n+        private boolean hasExpectedExceptions(JCClassDecl tree,\n+                                              MethodSymbol method,\n+                                              boolean warn,\n+                                              Type... declaredExceptions) {\n@@ -5640,2 +5791,3 @@\n-                        log.warning(\n-                                TreeInfo.diagnosticPositionFor(method, tree),\n+                        if (warn) {\n+                            log.warning(\n+                                    TreeInfo.diagnosticPositionFor(method, tree),\n@@ -5644,0 +5796,2 @@\n+                        }\n+                        return false;\n@@ -5647,1 +5801,1 @@\n-            return;\n+            return true;\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Check.java","additions":206,"deletions":52,"binary":false,"changes":258,"status":"modified"},{"patch":"@@ -80,0 +80,3 @@\n+compiler\/c2\/irTests\/scalarReplacement\/ScalarReplacementWithGCBarrierTests.java 8342488 generic-all\n+compiler\/c2\/TestMergeStores.java#id1 8348959 generic-all\n+\n@@ -106,0 +109,1 @@\n+runtime\/cds\/appcds\/redefineClass\/RedefineRunningMethods_Shared.java  8304168 generic-all\n@@ -127,0 +131,40 @@\n+\n+# Valhalla\n+runtime\/AccModule\/ConstModule.java 8294051 generic-all\n+runtime\/valhalla\/inlinetypes\/CircularityTest.java 8349037 generic-all\n+runtime\/valhalla\/inlinetypes\/PreloadCircularityTest.java 8349631 linux-aarch64-debug\n+runtime\/valhalla\/inlinetypes\/ValuePreloadTest.java 8349630 linux-aarch64-debug\n+compiler\/gcbarriers\/TestG1BarrierGeneration.java 8343420 generic-all\n+\n+# Valhalla + COH\n+compiler\/c2\/autovectorization\/TestIndexOverflowIR.java                          8348568 generic-all\n+compiler\/c2\/irTests\/TestVectorConditionalMove.java                              8348568 generic-all\n+compiler\/c2\/irTests\/TestVectorizationMismatchedAccess.java                      8348568 generic-all\n+compiler\/c2\/irTests\/TestVectorizationNotRun.java                                8348568 generic-all\n+compiler\/c2\/TestCastX2NotProcessedIGVN.java                                     8348568 generic-all\n+compiler\/loopopts\/superword\/TestAlignVector.java                                8348568 generic-all\n+compiler\/loopopts\/superword\/TestAlignVector.java#NoAlignVector-COH              8348568 generic-all\n+compiler\/loopopts\/superword\/TestAlignVector.java#VerifyAlignVector-COH          8348568 generic-all\n+compiler\/loopopts\/superword\/TestIndependentPacksWithCyclicDependency.java       8348568 generic-all\n+compiler\/loopopts\/superword\/TestMulAddS2I.java                                  8348568 generic-all\n+compiler\/loopopts\/superword\/TestScheduleReordersScalarMemops.java               8348568 generic-all\n+compiler\/loopopts\/superword\/TestSplitPacks.java                                 8348568 generic-all\n+compiler\/loopopts\/superword\/TestUnorderedReductionPartialVectorization.java     8348568 generic-all\n+compiler\/vectorization\/TestFloatConversionsVector.java                          8348568 generic-all\n+compiler\/vectorization\/runner\/ArrayTypeConvertTest.java                         8348568 generic-all\n+compiler\/vectorization\/runner\/LoopCombinedOpTest.java                           8348568 generic-all\n+compiler\/vectorization\/runner\/VectorizationTestRunner.java                      8348568 generic-all\n+\n+gc\/stress\/gcbasher\/TestGCBasherWithParallel.java                                8348568 generic-all\n+\n+gtest\/CompressedKlassGtest.java#use-zero-based-encoding-coh                     8348568 generic-all\n+gtest\/CompressedKlassGtest.java#use-zero-based-encoding-coh-large-class-space   8348568 generic-all\n+gtest\/MetaspaceGtests.java#UseCompactObjectHeaders                              8348568 generic-all\n+\n+runtime\/CompressedOops\/CompressedClassPointersEncodingScheme.java               8348568 generic-all\n+runtime\/FieldLayout\/BaseOffsets.java#no-coops-with-coh                          8348568 generic-all\n+runtime\/FieldLayout\/BaseOffsets.java#with-coop--with-coh                        8348568 generic-all\n+runtime\/cds\/TestDefaultArchiveLoading.java#coops_coh                            8348568 generic-all\n+runtime\/cds\/TestDefaultArchiveLoading.java#nocoops_coh                          8348568 generic-all\n+runtime\/cds\/appcds\/TestZGCWithCDS.java                                          8348568 generic-all\n+\n@@ -150,0 +194,31 @@\n+# Valhalla TODO:\n+serviceability\/jvmti\/valhalla\/HeapDump\/HeapDump.java 8317416 generic-all\n+\n+serviceability\/sa\/ClhsdbCDSCore.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbCDSJstackPrintAll.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbFindPC.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbInspect.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbLongConstant.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbJdis.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbJstack.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintAll.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintAs.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintStatics.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbSource.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbSymbol.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbWhere.java 8190936 generic-all\n+serviceability\/sa\/JhsdbThreadInfoTest.java 8190936 generic-all\n+serviceability\/sa\/TestClassDump.java 8190936 generic-all\n+serviceability\/sa\/TestClhsdbJstackLock.java 8190936 generic-all\n+serviceability\/sa\/TestCpoolForInvokeDynamic.java 8190936 generic-all\n+serviceability\/sa\/TestHeapDumpForInvokeDynamic.java 8190936 generic-all\n+serviceability\/sa\/TestHeapDumpForLargeArray.java 8190936 generic-all\n+serviceability\/sa\/TestIntConstant.java 8190936 generic-all\n+serviceability\/sa\/TestJhsdbJstackLock.java 8190936 generic-all\n+serviceability\/sa\/TestJmapCore.java 8190936 generic-all\n+serviceability\/sa\/TestJmapCoreMetaspace.java 8190936 generic-all\n+serviceability\/sa\/TestPrintMdo.java 8190936 generic-all\n+serviceability\/sa\/jmap-hprof\/JMapHProfLargeHeapTest.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbDumpclass.java 8190936 generic-all\n+\n+\n@@ -186,0 +261,2 @@\n+vmTestbase\/vm\/mlvm\/hiddenloader\/stress\/byteMutation\/Test.java 8317172 generic-all\n+\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":77,"deletions":0,"binary":false,"changes":77,"status":"modified"},{"patch":"@@ -49,1 +49,1 @@\n-  runtime\n+  runtime \\\n@@ -65,0 +65,8 @@\n+hotspot_valhalla = \\\n+  runtime\/valhalla \\\n+  compiler\/valhalla \\\n+  serviceability\/jvmti\/valhalla\n+\n+hotspot_valhalla_runtime = \\\n+  runtime\/valhalla\n+\n@@ -207,0 +215,1 @@\n+  compiler\/valhalla\/ \\\n@@ -248,0 +257,7 @@\n+\n+tier1_compiler_no_valhalla = \\\n+  :tier1_compiler_1 \\\n+  :tier1_compiler_2 \\\n+  :tier1_compiler_3 \\\n+  -compiler\/valhalla\n+\n@@ -399,0 +415,4 @@\n+tier1_runtime_no_valhalla = \\\n+  :tier1_runtime \\\n+  -runtime\/valhalla\n+\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":21,"deletions":1,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -222,1 +222,2 @@\n-    @Test\n+    \/\/ TODO 8291719\n+    \/\/ @Test\n@@ -300,1 +301,3 @@\n-            assertEquals(expected.length, actual.length);\n+            \/\/ With injection of the IdentityObject interface by the JVM, the number of\n+            \/\/ interfaces visible through reflection and through JVMCI could differ by one\n+            assertTrue(expected.length == actual.length || (actual.length - expected.length) == 1);\n","filename":"test\/hotspot\/jtreg\/compiler\/jvmci\/jdk.vm.ci.runtime.test\/src\/jdk\/vm\/ci\/runtime\/test\/TestResolvedJavaType.java","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -523,0 +523,5 @@\n+java\/lang\/ModuleLayer\/LayerControllerTest.java                  8337048 generic-all\n+java\/lang\/ModuleLayer\/BasicLayerTest.java                       8337048 generic-all\n+\n+java\/lang\/Thread\/virtual\/stress\/Skynet.java#default             8342977 generic-all\n+\n@@ -722,0 +727,4 @@\n+com\/sun\/jdi\/cds\/CDSBreakpointTest.java                          8304168 generic-all\n+com\/sun\/jdi\/cds\/CDSDeleteAllBkptsTest.java                      8304168 generic-all\n+com\/sun\/jdi\/cds\/CDSFieldWatchpoints.java                        8304168 generic-all\n+\n@@ -766,0 +775,6 @@\n+jdk\/classfile\/SwapTest.java                                     8308778 generic-all\n+jdk\/classfile\/LowAdaptTest.java                                 8308778 generic-all\n+jdk\/classfile\/BuilderBlockTest.java                             8308778 generic-all\n+jdk\/classfile\/BuilderTryCatchTest.java                          8308778 generic-all\n+jdk\/classfile\/PrimitiveClassConstantTest.java                   8310649 generic-all\n+\n@@ -812,0 +827,3 @@\n+\n+# valhalla\n+jdk\/jfr\/event\/runtime\/TestSyncOnValueBasedClassEvent.java 8328777 generic-all\n","filename":"test\/jdk\/ProblemList.txt","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -131,1 +131,9 @@\n-    jni\/nullCaller\n+    jni\/nullCaller \\\n+    valhalla\n+\n+# valhalla lworld tests\n+jdk_valhalla = \\\n+    java\/lang\/invoke \\\n+    valhalla \\\n+    java\/lang\/instrument\/valhalla\n+\n","filename":"test\/jdk\/TEST.groups","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -381,0 +381,1 @@\n+        vmOptFinalFlag(map, \"TieredCompilation\");\n","filename":"test\/jtreg-ext\/requires\/VMProps.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -150,0 +150,14 @@\n+  private native Object[] getObjectsViaKlassOopMaps0(Object thing);\n+  public Object[] getObjectsViaKlassOopMaps(Object thing) {\n+    Objects.requireNonNull(thing);\n+    return getObjectsViaKlassOopMaps0(thing);\n+  }\n+\n+  private native Object[] getObjectsViaOopIterator0(Object thing);\n+  public Object[] getObjectsViaOopIterator(Object thing) {\n+    Objects.requireNonNull(thing);\n+    return getObjectsViaOopIterator0(thing);\n+  }\n+\n+  public native Object[] getObjectsViaFrameOopIterator(int depth);\n+\n","filename":"test\/lib\/jdk\/test\/whitebox\/WhiteBox.java","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"}]}