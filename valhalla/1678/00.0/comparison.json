{"files":[{"patch":"@@ -512,1 +512,1 @@\n-\t$$(call ExecuteWithLog, $$($1_TEST_SUPPORT_DIR)\/gtest, ( \\\n+\t$$(call ExecuteWithLog, $$($1_TEST_SUPPORT_DIR)\/gtest, \\\n@@ -523,1 +523,1 @@\n-\t))\n+\t)\n@@ -647,1 +647,1 @@\n-\t$$(call ExecuteWithLog, $$($1_TEST_SUPPORT_DIR)\/micro, ( \\\n+\t$$(call ExecuteWithLog, $$($1_TEST_SUPPORT_DIR)\/micro, \\\n@@ -658,1 +658,1 @@\n-\t))\n+\t)\n@@ -761,1 +761,1 @@\n-\t  $$(call ExecuteWithLog, $$($1_AOT_JDK_OUTPUT_DIR), ( \\\n+\t  $$(call ExecuteWithLog, $$($1_AOT_JDK_OUTPUT_DIR), \\\n@@ -765,1 +765,1 @@\n-\t          -Xlog:class+load,aot,aot+class=debug:file=$$($1_AOT_JDK_CACHE).log  -Xlog:cds*=error -Xlog:aot*=error  \\\n+\t          -Xlog:class+load$$(COMMA)aot$$(COMMA)aot+class=debug:file=$$($1_AOT_JDK_CACHE).log  -Xlog:cds*=error -Xlog:aot*=error  \\\n@@ -768,1 +768,1 @@\n-\t  ))\n+\t  )\n@@ -773,1 +773,1 @@\n-\t  $$(call ExecuteWithLog, $$($1_AOT_JDK_OUTPUT_DIR), ( \\\n+\t  $$(call ExecuteWithLog, $$($1_AOT_JDK_OUTPUT_DIR), \\\n@@ -777,1 +777,1 @@\n-\t          -Xlog:class+load,aot,aot+class=debug:file=$$($1_AOT_JDK_CONF).log  -Xlog:cds*=error -Xlog:aot*=error \\\n+\t          -Xlog:class+load$$(COMMA)aot$$(COMMA)aot+class=debug:file=$$($1_AOT_JDK_CONF).log  -Xlog:cds*=error -Xlog:aot*=error \\\n@@ -780,1 +780,1 @@\n-\t  ))\n+\t  )\n@@ -783,1 +783,1 @@\n-\t  $$(call ExecuteWithLog, $$($1_AOT_JDK_OUTPUT_DIR), ( \\\n+\t  $$(call ExecuteWithLog, $$($1_AOT_JDK_OUTPUT_DIR), \\\n@@ -785,1 +785,1 @@\n-\t          $$($1_VM_OPTIONS) -Xlog:aot,aot+class=debug:file=$$($1_AOT_JDK_CACHE).log -Xlog:cds*=error -Xlog:aot*=error \\\n+\t          $$($1_VM_OPTIONS) -Xlog:aot$$(COMMA)aot+class=debug:file=$$($1_AOT_JDK_CACHE).log -Xlog:cds*=error -Xlog:aot*=error \\\n@@ -788,1 +788,1 @@\n-\t  ))\n+\t  )\n@@ -1088,1 +1088,1 @@\n-\t$$(call ExecuteWithLog, $$($1_TEST_SUPPORT_DIR)\/jtreg, ( \\\n+\t$$(call ExecuteWithLog, $$($1_TEST_SUPPORT_DIR)\/jtreg, \\\n@@ -1090,1 +1090,1 @@\n-\t))\n+\t)\n@@ -1207,1 +1207,1 @@\n-\t$$(call ExecuteWithLog, $$($1_TEST_SUPPORT_DIR)\/test-execution, ( \\\n+\t$$(call ExecuteWithLog, $$($1_TEST_SUPPORT_DIR)\/test-execution, \\\n@@ -1212,1 +1212,1 @@\n-\t))\n+\t)\n","filename":"make\/RunTests.gmk","additions":17,"deletions":17,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -29,0 +29,2 @@\n+include GensrcProperties.gmk\n+include GensrcStreamPreProcessing.gmk\n@@ -75,2 +77,0 @@\n-include GensrcProperties.gmk\n-\n","filename":"make\/modules\/java.base\/Gensrc.gmk","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -31,0 +31,5 @@\n+VARHANDLES_INPUT_DIR := $(MODULE_SRC)\/share\/classes\/java\/lang\/invoke\n+VARHANDLES_OUTPUT_DIR := $(SUPPORT_OUTPUTDIR)\/gensrc\/java.base\/java\/lang\/invoke\n+\n+################################################################################\n+\n@@ -43,0 +48,2 @@\n+  $1_type := $$(call lowercase, $2)\n+  $1_Type := $2\n@@ -74,0 +81,1 @@\n+    $1_type := Object\n@@ -79,0 +87,1 @@\n+      $1_type := Object\n@@ -85,0 +94,2 @@\n+    $1_type := Object\n+    $1_Type := FlatValue\n@@ -89,0 +100,2 @@\n+    $1_type := Object\n+    $1_Type := FlatValue\n@@ -105,1 +118,1 @@\n-\t  $$(eval $1_type := $$$$(shell $(TR) '[:upper:]' '[:lower:]' <<< $$$$($1_InputType)))\n+\t  $$(eval $1_type := $$$$($1_type))\n@@ -347,0 +360,12 @@\n+GENSRC_VARHANDLEGUARDS := $(VARHANDLES_OUTPUT_DIR)\/VarHandleGuards.java\n+\n+$(GENSRC_VARHANDLEGUARDS): $(BUILD_TOOLS_JDK)\n+\t$(call LogInfo, Generating $@)\n+\t$(call MakeTargetDir)\n+\t$(TOOL_VARHANDLEGUARDMETHODGENERATOR) \\\n+\t    $(GENSRC_VARHANDLEGUARDS)\n+\n+TARGETS += $(GENSRC_VARHANDLEGUARDS)\n+\n+################################################################################\n+\n","filename":"make\/modules\/java.base\/gensrc\/GensrcVarHandles.gmk","additions":26,"deletions":1,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -5990,3 +5990,0 @@\n-\n-  \/\/ List of nop instructions\n-  nops( MachNop );\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2786,5 +2786,0 @@\n-void LIR_Assembler::emit_delay(LIR_OpDelay*) {\n-  Unimplemented();\n-}\n-\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -362,7 +362,1 @@\n-    assert(patching_type == NMethodPatchingType::conc_data_patch, \"must be\");\n-    \/\/ Subsequent loads of oops must occur after load of guard value.\n-    \/\/ BarrierSetNMethod::disarm sets guard with release semantics.\n-    __ membar(__ LoadLoad);\n-    Address thread_disarmed_addr(rthread, in_bytes(bs_nm->thread_disarmed_guard_value_offset()));\n-    __ ldrw(rscratch2, thread_disarmed_addr);\n-    __ cmpw(rscratch1, rscratch2);\n+    ShouldNotReachHere();\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.cpp","additions":1,"deletions":7,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -42,2 +42,1 @@\n-  conc_instruction_and_data_patch,\n-  conc_data_patch\n+  conc_instruction_and_data_patch\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -61,2 +61,0 @@\n-  case NMethodPatchingType::conc_data_patch:\n-    return -4 * (5 + slow_path_size(nm));\n@@ -122,2 +120,16 @@\n-  void set_value(int value) {\n-    Atomic::release_store(guard_addr(), value);\n+  void set_value(int value, int bit_mask) {\n+    if (bit_mask == ~0) {\n+      Atomic::release_store(guard_addr(), value);\n+      return;\n+    }\n+    assert((value & ~bit_mask) == 0, \"trying to set bits outside the mask\");\n+    value &= bit_mask;\n+    int old_value = Atomic::load(guard_addr());\n+    while (true) {\n+      \/\/ Only bits in the mask are changed\n+      int new_value = value | (old_value & ~bit_mask);\n+      if (new_value == old_value) break;\n+      int v = Atomic::cmpxchg(guard_addr(), old_value, new_value, memory_order_release);\n+      if (v == old_value) break;\n+      old_value = v;\n+    }\n@@ -186,1 +198,1 @@\n-static void set_value(nmethod* nm, jint val) {\n+static void set_value(nmethod* nm, jint val, int bit_mask) {\n@@ -188,1 +200,1 @@\n-  cmp1.set_value(val);\n+  cmp1.set_value(val, bit_mask);\n@@ -200,1 +212,1 @@\n-    cmp2.set_value(val);\n+    cmp2.set_value(val, bit_mask);\n@@ -206,1 +218,1 @@\n-      cmp3.set_value(val);\n+      cmp3.set_value(val, bit_mask);\n@@ -211,1 +223,1 @@\n-void BarrierSetNMethod::set_guard_value(nmethod* nm, int value) {\n+void BarrierSetNMethod::set_guard_value(nmethod* nm, int value, int bit_mask) {\n@@ -227,1 +239,1 @@\n-  set_value(nm, value);\n+  set_value(nm, value, bit_mask);\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetNMethod_aarch64.cpp","additions":22,"deletions":10,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -2559,5 +2559,0 @@\n-void LIR_Assembler::emit_delay(LIR_OpDelay*) {\n-  Unimplemented();\n-}\n-\n-\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRAssembler_arm.cpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2750,5 +2750,0 @@\n-void LIR_Assembler::emit_delay(LIR_OpDelay* op) {\n-  Unimplemented();\n-}\n-\n-\n","filename":"src\/hotspot\/cpu\/ppc\/c1_LIRAssembler_ppc.cpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2819,4 +2819,0 @@\n-void LIR_Assembler::emit_delay(LIR_OpDelay* op) {\n-  ShouldNotCallThis(); \/\/ There are no delay slots on ZARCH_64.\n-}\n-\n","filename":"src\/hotspot\/cpu\/s390\/c1_LIRAssembler_s390.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -3225,4 +3225,0 @@\n-void LIR_Assembler::emit_delay(LIR_OpDelay*) {\n-  Unimplemented();\n-}\n-\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -53,0 +53,2 @@\n+  NativeNMethodCmpBarrier* nativeNMethodCmpBarrier_at(address a) { return (NativeNMethodCmpBarrier*)a; }\n+\n@@ -54,1 +56,22 @@\n-  void set_immediate(jint imm) { set_int_at(imm_offset, imm); }\n+  void set_immediate(jint imm, int bit_mask) {\n+    if (bit_mask == ~0) {\n+      set_int_at(imm_offset, imm);\n+      return;\n+    }\n+\n+    assert((imm & ~bit_mask) == 0, \"trying to set bits outside the mask\");\n+    imm &= bit_mask;\n+\n+    assert(align_up(immediate_address(), sizeof(jint)) ==\n+           align_down(immediate_address(), sizeof(jint)), \"immediate not aligned\");\n+    jint* data_addr = (jint*)immediate_address();\n+    jint old_value = Atomic::load(data_addr);\n+    while (true) {\n+      \/\/ Only bits in the mask are changed\n+      jint new_value = imm | (old_value & ~bit_mask);\n+      if (new_value == old_value) break;\n+      jint v = Atomic::cmpxchg(data_addr, old_value, new_value, memory_order_release);\n+      if (v == old_value) break;\n+      old_value = v;\n+    }\n+  }\n@@ -162,1 +185,1 @@\n-static void set_immediate(nmethod* nm, jint val) {\n+static void set_immediate(nmethod* nm, jint val, int bit_mask) {\n@@ -164,1 +187,1 @@\n-  cmp1->set_immediate(val);\n+  cmp1->set_immediate(val, bit_mask);\n@@ -176,1 +199,1 @@\n-    cmp2->set_immediate(val);\n+    cmp2->set_immediate(val, bit_mask);\n@@ -182,1 +205,1 @@\n-      cmp3->set_immediate(val);\n+      cmp3->set_immediate(val, bit_mask);\n@@ -187,1 +210,1 @@\n-void BarrierSetNMethod::set_guard_value(nmethod* nm, int value) {\n+void BarrierSetNMethod::set_guard_value(nmethod* nm, int value, int bit_mask) {\n@@ -192,1 +215,1 @@\n-  set_immediate(nm, value);\n+  set_immediate(nm, value, bit_mask);\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetNMethod_x86.cpp","additions":30,"deletions":7,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -1668,1 +1668,1 @@\n-    if (MaxVectorSize < 32 || !VM_Version::supports_avx512vlbw()) {\n+    if (MaxVectorSize < 32 || (!EnableX86ECoreOpts && !VM_Version::supports_avx512vlbw())) {\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3457,3 +3457,0 @@\n-\n-  \/\/ List of nop instructions\n-  nops( MachNop );\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -839,9 +839,0 @@\n-\/\/ LIR_OpDelay\n-    case lir_delay_slot: {\n-      assert(op->as_OpDelay() != nullptr, \"must be\");\n-      LIR_OpDelay* opDelay = (LIR_OpDelay*)op;\n-\n-      visit(opDelay->delay_op());\n-      break;\n-    }\n-\n@@ -1219,4 +1210,0 @@\n-void LIR_OpDelay::emit_code(LIR_Assembler* masm) {\n-  masm->emit_delay(this);\n-}\n-\n@@ -1940,2 +1927,0 @@\n-     \/\/ LIR_OpDelay\n-     case lir_delay_slot:            s = \"delay\";         break;\n@@ -2269,5 +2254,0 @@\n-void LIR_OpDelay::print_instr(outputStream* out) const {\n-  _op->print_on(out);\n-}\n-\n-\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.cpp","additions":0,"deletions":20,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -882,1 +882,0 @@\n-class    LIR_OpDelay;\n@@ -993,3 +992,0 @@\n-  , begin_delay_slot\n-    , lir_delay_slot\n-  , end_delay_slot\n@@ -1142,1 +1138,0 @@\n-  virtual LIR_OpDelay* as_OpDelay() { return nullptr; }\n@@ -1996,19 +1991,0 @@\n-class LIR_OpDelay: public LIR_Op {\n- friend class LIR_OpVisitState;\n-\n- private:\n-  LIR_Op* _op;\n-\n- public:\n-  LIR_OpDelay(LIR_Op* op, CodeEmitInfo* info):\n-    LIR_Op(lir_delay_slot, LIR_OprFact::illegalOpr, info),\n-    _op(op) {\n-    assert(op->code() == lir_nop, \"should be filling with nops\");\n-  }\n-  virtual void emit_code(LIR_Assembler* masm);\n-  virtual LIR_OpDelay* as_OpDelay() { return this; }\n-  void print_instr(outputStream* out) const PRODUCT_RETURN;\n-  LIR_Op* delay_op() const { return _op; }\n-  CodeEmitInfo* call_info() const { return info(); }\n-};\n-\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.hpp","additions":0,"deletions":24,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -200,2 +200,1 @@\n-             handler->entry_code()->instructions_list()->last()->code() == lir_branch ||\n-             handler->entry_code()->instructions_list()->last()->code() == lir_delay_slot, \"last operation must be branch\");\n+             handler->entry_code()->instructions_list()->last()->code() == lir_branch, \"last operation must be branch\");\n","filename":"src\/hotspot\/share\/c1\/c1_LIRAssembler.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -163,2 +163,1 @@\n-  \/\/ any last minute peephole optimizations are performed here.  In\n-  \/\/ particular sparc uses this for delay slot filling.\n+  \/\/ any last minute peephole optimizations are performed here.\n@@ -217,1 +216,0 @@\n-  void emit_delay(LIR_OpDelay* op);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRAssembler.hpp","additions":2,"deletions":4,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -644,1 +644,1 @@\n-  CodeStub* slow_path = new MonitorExitStub(lock, LockingMode != LM_MONITOR, monitor_no);\n+  CodeStub* slow_path = new MonitorExitStub(lock, true, monitor_no);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -926,3 +926,0 @@\n-  if (LockingMode == LM_MONITOR) {\n-    lock->set_obj(obj);\n-  }\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -224,1 +224,1 @@\n-          MetaspaceShared::unrecoverable_loading_error();\n+          AOTMetaspace::unrecoverable_loading_error();\n","filename":"src\/hotspot\/share\/cds\/aotLinkedClassBulkLoader.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -50,1 +51,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -109,9 +109,9 @@\n-ReservedSpace MetaspaceShared::_symbol_rs;\n-VirtualSpace MetaspaceShared::_symbol_vs;\n-bool MetaspaceShared::_archive_loading_failed = false;\n-bool MetaspaceShared::_remapped_readwrite = false;\n-void* MetaspaceShared::_aot_metaspace_static_top = nullptr;\n-intx MetaspaceShared::_relocation_delta;\n-char* MetaspaceShared::_requested_base_address;\n-Array<Method*>* MetaspaceShared::_archived_method_handle_intrinsics = nullptr;\n-bool MetaspaceShared::_use_optimized_module_handling = true;\n+ReservedSpace AOTMetaspace::_symbol_rs;\n+VirtualSpace AOTMetaspace::_symbol_vs;\n+bool AOTMetaspace::_archive_loading_failed = false;\n+bool AOTMetaspace::_remapped_readwrite = false;\n+void* AOTMetaspace::_aot_metaspace_static_top = nullptr;\n+intx AOTMetaspace::_relocation_delta;\n+char* AOTMetaspace::_requested_base_address;\n+Array<Method*>* AOTMetaspace::_archived_method_handle_intrinsics = nullptr;\n+bool AOTMetaspace::_use_optimized_module_handling = true;\n@@ -126,1 +126,1 @@\n-\/\/ These regions are aligned with MetaspaceShared::core_region_alignment().\n+\/\/ These regions are aligned with AOTMetaspace::core_region_alignment().\n@@ -129,1 +129,1 @@\n-\/\/ [0] All classes are loaded in MetaspaceShared::loadable_descriptors(). All metadata are\n+\/\/ [0] All classes are loaded in AOTMetaspace::loadable_descriptors(). All metadata are\n@@ -144,1 +144,1 @@\n-char* MetaspaceShared::symbol_space_alloc(size_t num_bytes) {\n+char* AOTMetaspace::symbol_space_alloc(size_t num_bytes) {\n@@ -157,1 +157,1 @@\n-size_t MetaspaceShared::core_region_alignment() {\n+size_t AOTMetaspace::core_region_alignment() {\n@@ -161,1 +161,1 @@\n-size_t MetaspaceShared::protection_zone_size() {\n+size_t AOTMetaspace::protection_zone_size() {\n@@ -222,1 +222,1 @@\n-void MetaspaceShared::dump_loaded_classes(const char* file_name, TRAPS) {\n+void AOTMetaspace::dump_loaded_classes(const char* file_name, TRAPS) {\n@@ -250,1 +250,1 @@\n-  size_t alignment = MetaspaceShared::core_region_alignment();\n+  size_t alignment = AOTMetaspace::core_region_alignment();\n@@ -296,1 +296,1 @@\n-void MetaspaceShared::initialize_for_static_dump() {\n+void AOTMetaspace::initialize_for_static_dump() {\n@@ -323,1 +323,1 @@\n-    MetaspaceShared::unrecoverable_writing_error();\n+    AOTMetaspace::unrecoverable_writing_error();\n@@ -329,1 +329,1 @@\n-void MetaspaceShared::post_initialize(TRAPS) {\n+void AOTMetaspace::post_initialize(TRAPS) {\n@@ -342,1 +342,1 @@\n-    static_mapinfo->unmap_region(MetaspaceShared::bm);\n+    static_mapinfo->unmap_region(AOTMetaspace::bm);\n@@ -346,1 +346,1 @@\n-      dynamic_mapinfo->unmap_region(MetaspaceShared::bm);\n+      dynamic_mapinfo->unmap_region(AOTMetaspace::bm);\n@@ -363,1 +363,1 @@\n-void MetaspaceShared::read_extra_data(JavaThread* current, const char* filename) {\n+void AOTMetaspace::read_extra_data(JavaThread* current, const char* filename) {\n@@ -377,1 +377,1 @@\n-      MetaspaceShared::unrecoverable_loading_error();\n+      AOTMetaspace::unrecoverable_loading_error();\n@@ -412,1 +412,1 @@\n-void MetaspaceShared::make_method_handle_intrinsics_shareable() {\n+void AOTMetaspace::make_method_handle_intrinsics_shareable() {\n@@ -421,1 +421,1 @@\n-void MetaspaceShared::write_method_handle_intrinsics() {\n+void AOTMetaspace::write_method_handle_intrinsics() {\n@@ -457,1 +457,1 @@\n-\/\/ of these xxx::serialize() functions inside MetaspaceShared::serialize(), which\n+\/\/ of these xxx::serialize() functions inside AOTMetaspace::serialize(), which\n@@ -463,1 +463,1 @@\n-\/\/ MetaspaceShared::early_serialize(). Such functions must not produce side effects that\n+\/\/ AOTMetaspace::early_serialize(). Such functions must not produce side effects that\n@@ -466,1 +466,1 @@\n-void MetaspaceShared::early_serialize(SerializeClosure* soc) {\n+void AOTMetaspace::early_serialize(SerializeClosure* soc) {\n@@ -473,1 +473,1 @@\n-void MetaspaceShared::serialize(SerializeClosure* soc) {\n+void AOTMetaspace::serialize(SerializeClosure* soc) {\n@@ -546,1 +546,1 @@\n-void MetaspaceShared::rewrite_nofast_bytecodes_and_calculate_fingerprints(Thread* thread, InstanceKlass* ik) {\n+void AOTMetaspace::rewrite_nofast_bytecodes_and_calculate_fingerprints(Thread* thread, InstanceKlass* ik) {\n@@ -622,1 +622,1 @@\n-  MetaspaceShared::early_serialize(&wc);\n+  AOTMetaspace::early_serialize(&wc);\n@@ -638,1 +638,1 @@\n-  MetaspaceShared::write_method_handle_intrinsics();\n+  AOTMetaspace::write_method_handle_intrinsics();\n@@ -651,1 +651,1 @@\n-  MetaspaceShared::serialize(&wc);\n+  AOTMetaspace::serialize(&wc);\n@@ -657,0 +657,2 @@\n+  CDSConfig::set_is_at_aot_safepoint(true);\n+\n@@ -689,1 +691,1 @@\n-  MetaspaceShared::make_method_handle_intrinsics_shareable();\n+  AOTMetaspace::make_method_handle_intrinsics_shareable();\n@@ -717,1 +719,1 @@\n-  _map_info->populate_header(MetaspaceShared::core_region_alignment());\n+  _map_info->populate_header(AOTMetaspace::core_region_alignment());\n@@ -722,0 +724,2 @@\n+\n+  CDSConfig::set_is_at_aot_safepoint(false);\n@@ -759,1 +763,1 @@\n-bool MetaspaceShared::may_be_eagerly_linked(InstanceKlass* ik) {\n+bool AOTMetaspace::may_be_eagerly_linked(InstanceKlass* ik) {\n@@ -778,4 +782,1 @@\n-void MetaspaceShared::link_shared_classes(TRAPS) {\n-  AOTClassLinker::initialize();\n-  AOTClassInitializer::init_test_class(CHECK);\n-\n+void AOTMetaspace::link_all_loaded_classes(JavaThread* current) {\n@@ -783,1 +784,1 @@\n-    ResourceMark rm(THREAD);\n+    ResourceMark rm(current);\n@@ -791,1 +792,1 @@\n-        has_linked |= try_link_class(THREAD, ik);\n+        has_linked |= try_link_class(current, ik);\n@@ -801,0 +802,7 @@\n+}\n+\n+void AOTMetaspace::link_shared_classes(TRAPS) {\n+  AOTClassLinker::initialize();\n+  AOTClassInitializer::init_test_class(CHECK);\n+\n+  link_all_loaded_classes(THREAD);\n@@ -821,1 +829,1 @@\n-void MetaspaceShared::preload_and_dump(TRAPS) {\n+void AOTMetaspace::preload_and_dump(TRAPS) {\n@@ -837,1 +845,1 @@\n-      MetaspaceShared::writing_error();\n+      AOTMetaspace::writing_error();\n@@ -842,1 +850,1 @@\n-      MetaspaceShared::writing_error(err_msg(\"Unexpected exception, use -Xlog:aot%s,exceptions=trace for detail\",\n+      AOTMetaspace::writing_error(err_msg(\"Unexpected exception, use -Xlog:aot%s,exceptions=trace for detail\",\n@@ -869,1 +877,1 @@\n-void MetaspaceShared::adjust_heap_sizes_for_dumping() {\n+void AOTMetaspace::adjust_heap_sizes_for_dumping() {\n@@ -892,1 +900,1 @@\n-void MetaspaceShared::get_default_classlist(char* default_classlist, const size_t buf_size) {\n+void AOTMetaspace::get_default_classlist(char* default_classlist, const size_t buf_size) {\n@@ -898,1 +906,1 @@\n-void MetaspaceShared::loadable_descriptors(TRAPS) {\n+void AOTMetaspace::loadable_descriptors(TRAPS) {\n@@ -933,1 +941,1 @@\n-void MetaspaceShared::exercise_runtime_cds_code(TRAPS) {\n+void AOTMetaspace::exercise_runtime_cds_code(TRAPS) {\n@@ -942,1 +950,1 @@\n-void MetaspaceShared::preload_and_dump_impl(StaticArchiveBuilder& builder, TRAPS) {\n+void AOTMetaspace::preload_and_dump_impl(StaticArchiveBuilder& builder, TRAPS) {\n@@ -1063,2 +1071,2 @@\n-bool MetaspaceShared::write_static_archive(ArchiveBuilder* builder, FileMapInfo* map_info, ArchiveHeapInfo* heap_info) {\n-  \/\/ relocate the data so that it can be mapped to MetaspaceShared::requested_base_address()\n+bool AOTMetaspace::write_static_archive(ArchiveBuilder* builder, FileMapInfo* map_info, ArchiveHeapInfo* heap_info) {\n+  \/\/ relocate the data so that it can be mapped to AOTMetaspace::requested_base_address()\n@@ -1182,1 +1190,1 @@\n-void MetaspaceShared::fork_and_dump_final_static_archive(TRAPS) {\n+void AOTMetaspace::fork_and_dump_final_static_archive(TRAPS) {\n@@ -1208,1 +1216,1 @@\n-bool MetaspaceShared::try_link_class(JavaThread* current, InstanceKlass* ik) {\n+bool AOTMetaspace::try_link_class(JavaThread* current, InstanceKlass* ik) {\n@@ -1262,1 +1270,1 @@\n-void MetaspaceShared::set_aot_metaspace_range(void* base, void *static_top, void* top) {\n+void AOTMetaspace::set_aot_metaspace_range(void* base, void *static_top, void* top) {\n@@ -1268,1 +1276,1 @@\n-bool MetaspaceShared::in_aot_cache_dynamic_region(void* p) {\n+bool AOTMetaspace::in_aot_cache_dynamic_region(void* p) {\n@@ -1277,1 +1285,1 @@\n-bool MetaspaceShared::in_aot_cache_static_region(void* p) {\n+bool AOTMetaspace::in_aot_cache_static_region(void* p) {\n@@ -1290,1 +1298,1 @@\n-void MetaspaceShared::unrecoverable_loading_error(const char* message) {\n+void AOTMetaspace::unrecoverable_loading_error(const char* message) {\n@@ -1302,1 +1310,1 @@\n-void MetaspaceShared::report_loading_error(const char* format, ...) {\n+void AOTMetaspace::report_loading_error(const char* format, ...) {\n@@ -1335,1 +1343,1 @@\n-void MetaspaceShared::unrecoverable_writing_error(const char* message) {\n+void AOTMetaspace::unrecoverable_writing_error(const char* message) {\n@@ -1342,1 +1350,1 @@\n-void MetaspaceShared::writing_error(const char* message) {\n+void AOTMetaspace::writing_error(const char* message) {\n@@ -1349,1 +1357,1 @@\n-void MetaspaceShared::initialize_runtime_shared_and_meta_spaces() {\n+void AOTMetaspace::initialize_runtime_shared_and_meta_spaces() {\n@@ -1395,1 +1403,1 @@\n-      MetaspaceShared::unrecoverable_loading_error(\"Unable to use shared archive.\");\n+      AOTMetaspace::unrecoverable_loading_error(\"Unable to use shared archive.\");\n@@ -1398,1 +1406,1 @@\n-        MetaspaceShared::unrecoverable_loading_error(\"Unable to map shared spaces\");\n+        AOTMetaspace::unrecoverable_loading_error(\"Unable to map shared spaces\");\n@@ -1416,1 +1424,1 @@\n-      MetaspaceShared::unrecoverable_loading_error(\"Unable to map shared spaces\");\n+      AOTMetaspace::unrecoverable_loading_error(\"Unable to map shared spaces\");\n@@ -1420,1 +1428,1 @@\n-FileMapInfo* MetaspaceShared::open_static_archive() {\n+FileMapInfo* AOTMetaspace::open_static_archive() {\n@@ -1431,1 +1439,1 @@\n-FileMapInfo* MetaspaceShared::open_dynamic_archive() {\n+FileMapInfo* AOTMetaspace::open_dynamic_archive() {\n@@ -1444,1 +1452,1 @@\n-      MetaspaceShared::unrecoverable_loading_error(\"Failed to initialize dynamic archive\");\n+      AOTMetaspace::unrecoverable_loading_error(\"Failed to initialize dynamic archive\");\n@@ -1454,2 +1462,2 @@\n-MapArchiveResult MetaspaceShared::map_archives(FileMapInfo* static_mapinfo, FileMapInfo* dynamic_mapinfo,\n-                                               bool use_requested_addr) {\n+MapArchiveResult AOTMetaspace::map_archives(FileMapInfo* static_mapinfo, FileMapInfo* dynamic_mapinfo,\n+                                            bool use_requested_addr) {\n@@ -1527,1 +1535,1 @@\n-    if (MetaspaceShared::use_windows_memory_mapping()) {\n+    if (AOTMetaspace::use_windows_memory_mapping()) {\n@@ -1731,6 +1739,6 @@\n-char* MetaspaceShared::reserve_address_space_for_archives(FileMapInfo* static_mapinfo,\n-                                                          FileMapInfo* dynamic_mapinfo,\n-                                                          bool use_archive_base_addr,\n-                                                          ReservedSpace& total_space_rs,\n-                                                          ReservedSpace& archive_space_rs,\n-                                                          ReservedSpace& class_space_rs) {\n+char* AOTMetaspace::reserve_address_space_for_archives(FileMapInfo* static_mapinfo,\n+                                                       FileMapInfo* dynamic_mapinfo,\n+                                                       bool use_archive_base_addr,\n+                                                       ReservedSpace& total_space_rs,\n+                                                       ReservedSpace& archive_space_rs,\n+                                                       ReservedSpace& class_space_rs) {\n@@ -1889,3 +1897,3 @@\n-void MetaspaceShared::release_reserved_spaces(ReservedSpace& total_space_rs,\n-                                              ReservedSpace& archive_space_rs,\n-                                              ReservedSpace& class_space_rs) {\n+void AOTMetaspace::release_reserved_spaces(ReservedSpace& total_space_rs,\n+                                           ReservedSpace& archive_space_rs,\n+                                           ReservedSpace& class_space_rs) {\n@@ -1910,1 +1918,1 @@\n-static int archive_regions[]     = { MetaspaceShared::rw, MetaspaceShared::ro };\n+static int archive_regions[]     = { AOTMetaspace::rw, AOTMetaspace::ro };\n@@ -1913,1 +1921,1 @@\n-MapArchiveResult MetaspaceShared::map_archive(FileMapInfo* mapinfo, char* mapped_base_address, ReservedSpace rs) {\n+MapArchiveResult AOTMetaspace::map_archive(FileMapInfo* mapinfo, char* mapped_base_address, ReservedSpace rs) {\n@@ -1956,1 +1964,1 @@\n-void MetaspaceShared::unmap_archive(FileMapInfo* mapinfo) {\n+void AOTMetaspace::unmap_archive(FileMapInfo* mapinfo) {\n@@ -1960,1 +1968,1 @@\n-    mapinfo->unmap_region(MetaspaceShared::bm);\n+    mapinfo->unmap_region(AOTMetaspace::bm);\n@@ -1981,1 +1989,1 @@\n-void MetaspaceShared::initialize_shared_spaces() {\n+void AOTMetaspace::initialize_shared_spaces() {\n@@ -2062,1 +2070,1 @@\n-bool MetaspaceShared::remap_shared_readonly_as_readwrite() {\n+bool AOTMetaspace::remap_shared_readonly_as_readwrite() {\n@@ -2082,1 +2090,1 @@\n-void MetaspaceShared::print_on(outputStream* st) {\n+void AOTMetaspace::print_on(outputStream* st) {\n","filename":"src\/hotspot\/share\/cds\/aotMetaspace.cpp","additions":96,"deletions":88,"binary":false,"changes":184,"previous_filename":"src\/hotspot\/share\/cds\/metaspaceShared.cpp","status":"renamed"},{"patch":"@@ -25,2 +25,2 @@\n-#ifndef SHARE_CDS_METASPACESHARED_HPP\n-#define SHARE_CDS_METASPACESHARED_HPP\n+#ifndef SHARE_CDS_AOTMETASPACE_HPP\n+#define SHARE_CDS_AOTMETASPACE_HPP\n@@ -52,1 +52,1 @@\n-class MetaspaceShared : AllStatic {\n+class AOTMetaspace : AllStatic {\n@@ -66,2 +66,2 @@\n-    rw = 0,  \/\/ read-write shared space\n-    ro = 1,  \/\/ read-only shared space\n+    rw = 0,  \/\/ read-write\n+    ro = 1,  \/\/ read-only\n@@ -138,0 +138,1 @@\n+  static void link_all_loaded_classes(JavaThread* current);\n@@ -205,1 +206,1 @@\n-#endif \/\/ SHARE_CDS_METASPACESHARED_HPP\n+#endif \/\/ SHARE_CDS_AOTMETASPACE_HPP\n","filename":"src\/hotspot\/share\/cds\/aotMetaspace.hpp","additions":7,"deletions":6,"binary":false,"changes":13,"previous_filename":"src\/hotspot\/share\/cds\/metaspaceShared.hpp","status":"renamed"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -38,1 +39,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -333,1 +333,1 @@\n-                                             MetaspaceShared::core_region_alignment(),\n+                                             AOTMetaspace::core_region_alignment(),\n@@ -338,1 +338,1 @@\n-    MetaspaceShared::unrecoverable_writing_error();\n+    AOTMetaspace::unrecoverable_writing_error();\n@@ -360,1 +360,1 @@\n-  _requested_static_archive_bottom = (address)MetaspaceShared::requested_base_address();\n+  _requested_static_archive_bottom = (address)AOTMetaspace::requested_base_address();\n@@ -375,1 +375,1 @@\n-    my_archive_requested_bottom = align_up(_requested_static_archive_top, MetaspaceShared::core_region_alignment());\n+    my_archive_requested_bottom = align_up(_requested_static_archive_top, AOTMetaspace::core_region_alignment());\n@@ -390,1 +390,1 @@\n-    MetaspaceShared::unrecoverable_writing_error();\n+    AOTMetaspace::unrecoverable_writing_error();\n@@ -396,1 +396,1 @@\n-    _pz_region.allocate(MetaspaceShared::protection_zone_size());\n+    _pz_region.allocate(AOTMetaspace::protection_zone_size());\n@@ -543,1 +543,1 @@\n-    if (CDSConfig::is_dumping_dynamic_archive() && MetaspaceShared::in_aot_cache_static_region(bottom)) {\n+    if (CDSConfig::is_dumping_dynamic_archive() && AOTMetaspace::in_aot_cache_static_region(bottom)) {\n@@ -556,1 +556,1 @@\n-  if (CDSConfig::is_dumping_dynamic_archive() && MetaspaceShared::in_aot_cache(obj)) {\n+  if (CDSConfig::is_dumping_dynamic_archive() && AOTMetaspace::in_aot_cache(obj)) {\n@@ -946,1 +946,1 @@\n-      if (!ik->can_be_verified_at_dumptime()) {\n+      if (CDSConfig::is_old_class_for_verifier(ik)) {\n@@ -951,1 +951,1 @@\n-      if (ik->is_generated_shared_class()) {\n+      if (ik->is_aot_generated_class()) {\n@@ -965,1 +965,1 @@\n-      MetaspaceShared::rewrite_nofast_bytecodes_and_calculate_fingerprints(Thread::current(), ik);\n+      AOTMetaspace::rewrite_nofast_bytecodes_and_calculate_fingerprints(Thread::current(), ik);\n@@ -1197,2 +1197,2 @@\n-  \/\/ MetaspaceShared::n_regions (internal to hotspot).\n-  assert(NUM_CDS_REGIONS == MetaspaceShared::n_regions, \"sanity\");\n+  \/\/ AOTMetaspace::n_regions (internal to hotspot).\n+  assert(NUM_CDS_REGIONS == AOTMetaspace::n_regions, \"sanity\");\n@@ -1200,3 +1200,3 @@\n-  write_region(mapinfo, MetaspaceShared::rw, &_rw_region, \/*read_only=*\/false,\/*allow_exec=*\/false);\n-  write_region(mapinfo, MetaspaceShared::ro, &_ro_region, \/*read_only=*\/true, \/*allow_exec=*\/false);\n-  write_region(mapinfo, MetaspaceShared::ac, &_ac_region, \/*read_only=*\/false,\/*allow_exec=*\/false);\n+  write_region(mapinfo, AOTMetaspace::rw, &_rw_region, \/*read_only=*\/false,\/*allow_exec=*\/false);\n+  write_region(mapinfo, AOTMetaspace::ro, &_ro_region, \/*read_only=*\/true, \/*allow_exec=*\/false);\n+  write_region(mapinfo, AOTMetaspace::ac, &_ac_region, \/*read_only=*\/false,\/*allow_exec=*\/false);\n@@ -1217,1 +1217,1 @@\n-  mapinfo->set_requested_base((char*)MetaspaceShared::requested_base_address());\n+  mapinfo->set_requested_base((char*)AOTMetaspace::requested_base_address());\n@@ -1248,2 +1248,2 @@\n-  const size_t bitmap_used = mapinfo->region_at(MetaspaceShared::bm)->used();\n-  const size_t bitmap_reserved = mapinfo->region_at(MetaspaceShared::bm)->used_aligned();\n+  const size_t bitmap_used = mapinfo->region_at(AOTMetaspace::bm)->used();\n+  const size_t bitmap_reserved = mapinfo->region_at(AOTMetaspace::bm)->used_aligned();\n@@ -1293,1 +1293,1 @@\n-  MetaspaceShared::unrecoverable_writing_error();\n+  AOTMetaspace::unrecoverable_writing_error();\n","filename":"src\/hotspot\/share\/cds\/archiveBuilder.cpp","additions":21,"deletions":21,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -36,1 +37,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -120,1 +120,1 @@\n-    \/\/ MetaspaceShared::default_base_address()==0, we can't distinguish between a pointer\n+    \/\/ AOTMetaspace::default_base_address()==0, we can't distinguish between a pointer\n@@ -212,1 +212,1 @@\n-      MetaspaceShared::unrecoverable_writing_error();\n+      AOTMetaspace::unrecoverable_writing_error();\n@@ -239,1 +239,1 @@\n-    MetaspaceShared::unrecoverable_writing_error();\n+    AOTMetaspace::unrecoverable_writing_error();\n@@ -243,1 +243,1 @@\n-  if (_rs->base() == (char*)MetaspaceShared::symbol_rs_base()) {\n+  if (_rs->base() == (char*)AOTMetaspace::symbol_rs_base()) {\n@@ -301,1 +301,1 @@\n-    _end = (char*)align_up(_top, MetaspaceShared::core_region_alignment());\n+    _end = (char*)align_up(_top, AOTMetaspace::core_region_alignment());\n@@ -304,1 +304,1 @@\n-  _end = (char*)align_up(_top, MetaspaceShared::core_region_alignment());\n+  _end = (char*)align_up(_top, AOTMetaspace::core_region_alignment());\n","filename":"src\/hotspot\/share\/cds\/archiveUtils.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -60,0 +60,1 @@\n+bool CDSConfig::_is_at_aot_safepoint = false;\n@@ -791,1 +792,1 @@\n-      MetaspaceShared::unrecoverable_loading_error();\n+      AOTMetaspace::unrecoverable_loading_error();\n@@ -946,0 +947,29 @@\n+bool CDSConfig::is_preserving_verification_constraints() {\n+  \/\/ Verification dependencies are classes used in assignability checks by the\n+  \/\/ bytecode verifier. In the following example, the verification dependencies\n+  \/\/ for X are A and B.\n+  \/\/\n+  \/\/     class X {\n+  \/\/        A getA() { return new B(); }\n+  \/\/     }\n+  \/\/\n+  \/\/ With the AOT cache, we can ensure that all the verification dependencies\n+  \/\/ (A and B in the above example) are unconditionally loaded during the bootstrap\n+  \/\/ of the production run. This means that if a class was successfully verified\n+  \/\/ in the assembly phase, all of the verifier's assignability checks will remain\n+  \/\/ valid in the production run, so we don't need to verify aot-linked classes again.\n+\n+  if (is_dumping_preimage_static_archive()) { \/\/ writing AOT config\n+    return AOTClassLinking;\n+  } else if (is_dumping_final_static_archive()) { \/\/ writing AOT cache\n+    return is_dumping_aot_linked_classes();\n+  } else {\n+    \/\/ For simplicity, we don't support this optimization with the old CDS workflow.\n+    return false;\n+  }\n+}\n+\n+bool CDSConfig::is_old_class_for_verifier(const InstanceKlass* ik) {\n+  return ik->major_version() < 50 \/*JAVA_6_VERSION*\/;\n+}\n+\n","filename":"src\/hotspot\/share\/cds\/cdsConfig.cpp","additions":31,"deletions":1,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+class InstanceKlass;\n@@ -47,0 +48,1 @@\n+  static bool _is_at_aot_safepoint;\n@@ -111,0 +113,3 @@\n+  static bool is_at_aot_safepoint()                          { return CDS_ONLY(_is_at_aot_safepoint) NOT_CDS(false); }\n+  static void set_is_at_aot_safepoint(bool value)            { CDS_ONLY(_is_at_aot_safepoint = value); }\n+\n@@ -173,0 +178,4 @@\n+  \/\/ Bytecode verification\n+  static bool is_preserving_verification_constraints();\n+  static bool is_old_class_for_verifier(const InstanceKlass* ik);\n+\n","filename":"src\/hotspot\/share\/cds\/cdsConfig.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -122,1 +122,1 @@\n-    assert(MetaspaceShared::in_aot_cache(pkg_entry), \"must be\");\n+    assert(AOTMetaspace::in_aot_cache(pkg_entry), \"must be\");\n","filename":"src\/hotspot\/share\/cds\/cdsProtectionDomain.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -31,1 +32,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -188,1 +188,1 @@\n-    MetaspaceShared::try_link_class(THREAD, ik);\n+    AOTMetaspace::try_link_class(THREAD, ik);\n@@ -681,1 +681,1 @@\n-    MetaspaceShared::try_link_class(THREAD, ik);\n+    AOTMetaspace::try_link_class(THREAD, ik);\n","filename":"src\/hotspot\/share\/cds\/classListParser.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -29,1 +30,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -332,1 +332,1 @@\n-  assert(MetaspaceShared::in_aot_cache(m), \"must be\");\n+  assert(AOTMetaspace::in_aot_cache(m), \"must be\");\n","filename":"src\/hotspot\/share\/cds\/cppVtables.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -37,1 +38,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -113,0 +113,6 @@\n+    CDSConfig::set_is_at_aot_safepoint(true);\n+    doit_inner();\n+    CDSConfig::set_is_at_aot_safepoint(false);\n+  }\n+\n+  void doit_inner() {\n@@ -190,1 +196,1 @@\n-      assert(MetaspaceShared::in_aot_cache_static_region((void*)k),\n+      assert(AOTMetaspace::in_aot_cache_static_region((void*)k),\n@@ -219,1 +225,1 @@\n-  for (int i = 0; i < MetaspaceShared::n_regions; i++) {\n+  for (int i = 0; i < AOTMetaspace::n_regions; i++) {\n@@ -256,1 +262,1 @@\n-  if (MetaspaceShared::in_aot_cache(ik)) {\n+  if (AOTMetaspace::in_aot_cache(ik)) {\n@@ -290,1 +296,1 @@\n-      assert(MetaspaceShared::in_aot_cache(name) || is_in_buffer_space(name), \"must be\");\n+      assert(AOTMetaspace::in_aot_cache(name) || is_in_buffer_space(name), \"must be\");\n@@ -296,1 +302,1 @@\n-      assert(MetaspaceShared::in_aot_cache(name) || is_in_buffer_space(name), \"must be\");\n+      assert(AOTMetaspace::in_aot_cache(name) || is_in_buffer_space(name), \"must be\");\n@@ -373,1 +379,1 @@\n-      if (MetaspaceShared::in_aot_cache_static_region(elem)) {\n+      if (AOTMetaspace::in_aot_cache_static_region(elem)) {\n@@ -380,1 +386,1 @@\n-        assert(!MetaspaceShared::in_aot_cache_static_region(oak),\n+        assert(!AOTMetaspace::in_aot_cache_static_region(oak),\n@@ -441,1 +447,1 @@\n-      assert(MetaspaceShared::in_aot_cache_static_region((void*)elm), \"must be\");\n+      assert(AOTMetaspace::in_aot_cache_static_region((void*)elm), \"must be\");\n@@ -484,1 +490,1 @@\n-  MetaspaceShared::link_shared_classes(CHECK);\n+  AOTMetaspace::link_shared_classes(CHECK);\n@@ -540,1 +546,1 @@\n-  for (int i = 0; i < MetaspaceShared::n_regions; i++) {\n+  for (int i = 0; i < AOTMetaspace::n_regions; i++) {\n","filename":"src\/hotspot\/share\/cds\/dynamicArchive.cpp","additions":17,"deletions":11,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -36,1 +37,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -401,1 +401,1 @@\n-      MetaspaceShared::set_archive_loading_failed();\n+      AOTMetaspace::set_archive_loading_failed();\n@@ -410,1 +410,1 @@\n-    MetaspaceShared::report_loading_error(\"optimized module handling: disabled because extra module path(s) are specified\");\n+    AOTMetaspace::report_loading_error(\"optimized module handling: disabled because extra module path(s) are specified\");\n@@ -481,1 +481,1 @@\n-      MetaspaceShared::report_loading_error(\"Specified %s not found (%s)\", CDSConfig::type_of_archive_being_loaded(), _archive_name);\n+      AOTMetaspace::report_loading_error(\"Specified %s not found (%s)\", CDSConfig::type_of_archive_being_loaded(), _archive_name);\n@@ -766,1 +766,1 @@\n-  for (int i = 0; i < MetaspaceShared::n_regions; i++) {\n+  for (int i = 0; i < AOTMetaspace::n_regions; i++) {\n@@ -784,1 +784,1 @@\n-    MetaspaceShared::unrecoverable_loading_error();\n+    AOTMetaspace::unrecoverable_loading_error();\n@@ -839,1 +839,1 @@\n-    MetaspaceShared::writing_error();\n+    AOTMetaspace::writing_error();\n@@ -849,1 +849,1 @@\n-  header_bytes = align_up(header_bytes, MetaspaceShared::core_region_alignment());\n+  header_bytes = align_up(header_bytes, AOTMetaspace::core_region_alignment());\n@@ -864,1 +864,1 @@\n-  return align_up(used(), MetaspaceShared::core_region_alignment());\n+  return align_up(used(), AOTMetaspace::core_region_alignment());\n@@ -870,1 +870,1 @@\n-  _is_bitmap_region = (region_index == MetaspaceShared::bm);\n+  _is_bitmap_region = (region_index == AOTMetaspace::bm);\n@@ -966,1 +966,1 @@\n-  if (region == MetaspaceShared::bm) {\n+  if (region == AOTMetaspace::bm) {\n@@ -984,1 +984,1 @@\n-    char* requested_SharedBaseAddress = (char*)MetaspaceShared::requested_base_address();\n+    char* requested_SharedBaseAddress = (char*)AOTMetaspace::requested_base_address();\n@@ -1060,1 +1060,1 @@\n-  region_at(MetaspaceShared::rw)->init_ptrmap(0, rw_ptrmap->size());\n+  region_at(AOTMetaspace::rw)->init_ptrmap(0, rw_ptrmap->size());\n@@ -1063,1 +1063,1 @@\n-  region_at(MetaspaceShared::ro)->init_ptrmap(written, ro_ptrmap->size());\n+  region_at(AOTMetaspace::ro)->init_ptrmap(written, ro_ptrmap->size());\n@@ -1067,1 +1067,1 @@\n-    FileMapRegion* r = region_at(MetaspaceShared::hp);\n+    FileMapRegion* r = region_at(AOTMetaspace::hp);\n@@ -1076,1 +1076,1 @@\n-  write_region(MetaspaceShared::bm, (char*)buffer, size_in_bytes, \/*read_only=*\/true, \/*allow_exec=*\/false);\n+  write_region(AOTMetaspace::bm, (char*)buffer, size_in_bytes, \/*read_only=*\/true, \/*allow_exec=*\/false);\n@@ -1083,1 +1083,1 @@\n-  write_region(MetaspaceShared::hp, buffer_start, buffer_size, false, false);\n+  write_region(AOTMetaspace::hp, buffer_start, buffer_size, false, false);\n@@ -1098,1 +1098,1 @@\n-      MetaspaceShared::writing_error(\"Unable to write to AOT configuration file.\");\n+      AOTMetaspace::writing_error(\"Unable to write to AOT configuration file.\");\n@@ -1100,1 +1100,1 @@\n-      MetaspaceShared::writing_error(\"Unable to write to AOT cache.\");\n+      AOTMetaspace::writing_error(\"Unable to write to AOT cache.\");\n@@ -1102,1 +1102,1 @@\n-      MetaspaceShared::writing_error(\"Unable to write to shared archive.\");\n+      AOTMetaspace::writing_error(\"Unable to write to shared archive.\");\n@@ -1110,1 +1110,1 @@\n-                                  MetaspaceShared::core_region_alignment());\n+                                  AOTMetaspace::core_region_alignment());\n@@ -1118,1 +1118,1 @@\n-                                    MetaspaceShared::core_region_alignment());\n+                                    AOTMetaspace::core_region_alignment());\n@@ -1144,1 +1144,1 @@\n-      MetaspaceShared::unrecoverable_loading_error(\"Unable to close the shared archive file.\");\n+      AOTMetaspace::unrecoverable_loading_error(\"Unable to close the shared archive file.\");\n@@ -1169,1 +1169,1 @@\n-  int idx = MetaspaceShared::ro;\n+  int idx = AOTMetaspace::ro;\n@@ -1276,1 +1276,1 @@\n-  if (MetaspaceShared::use_windows_memory_mapping()) {\n+  if (AOTMetaspace::use_windows_memory_mapping()) {\n@@ -1288,1 +1288,1 @@\n-  if (MetaspaceShared::use_windows_memory_mapping() && rs.is_reserved()) {\n+  if (AOTMetaspace::use_windows_memory_mapping() && rs.is_reserved()) {\n@@ -1294,1 +1294,1 @@\n-      MetaspaceShared::report_loading_error(\"Failed to read %s shared space into reserved space at \" INTPTR_FORMAT,\n+      AOTMetaspace::report_loading_error(\"Failed to read %s shared space into reserved space at \" INTPTR_FORMAT,\n@@ -1303,1 +1303,1 @@\n-    \/\/ space (Posix). See also comment in MetaspaceShared::map_archives().\n+    \/\/ space (Posix). See also comment in AOTMetaspace::map_archives().\n@@ -1308,1 +1308,1 @@\n-      MetaspaceShared::report_loading_error(\"Unable to map %s shared space at \" INTPTR_FORMAT,\n+      AOTMetaspace::report_loading_error(\"Unable to map %s shared space at \" INTPTR_FORMAT,\n@@ -1334,1 +1334,1 @@\n-  FileMapRegion* r = region_at(MetaspaceShared::bm);\n+  FileMapRegion* r = region_at(AOTMetaspace::bm);\n@@ -1343,1 +1343,1 @@\n-    MetaspaceShared::report_loading_error(\"failed to map relocation bitmap\");\n+    AOTMetaspace::report_loading_error(\"failed to map relocation bitmap\");\n@@ -1359,2 +1359,2 @@\n-                MetaspaceShared::bm, p2i(r->mapped_base()), p2i(r->mapped_end()),\n-                shared_region_name[MetaspaceShared::bm]);\n+                AOTMetaspace::bm, p2i(r->mapped_base()), p2i(r->mapped_end()),\n+                shared_region_name[AOTMetaspace::bm]);\n@@ -1365,1 +1365,1 @@\n-  FileMapRegion* r = region_at(MetaspaceShared::ac);\n+  FileMapRegion* r = region_at(AOTMetaspace::ac);\n@@ -1372,3 +1372,3 @@\n-  if (MetaspaceShared::use_windows_memory_mapping()) {\n-    if (!read_region(MetaspaceShared::ac, requested_base, r->used_aligned(), \/* do_commit = *\/ true)) {\n-      MetaspaceShared::report_loading_error(\"Failed to read aot code shared space into reserved space at \" INTPTR_FORMAT,\n+  if (AOTMetaspace::use_windows_memory_mapping()) {\n+    if (!read_region(AOTMetaspace::ac, requested_base, r->used_aligned(), \/* do_commit = *\/ true)) {\n+      AOTMetaspace::report_loading_error(\"Failed to read aot code shared space into reserved space at \" INTPTR_FORMAT,\n@@ -1387,1 +1387,1 @@\n-    MetaspaceShared::report_loading_error(\"failed to map aot code region\");\n+    AOTMetaspace::report_loading_error(\"failed to map aot code region\");\n@@ -1394,2 +1394,2 @@\n-                  MetaspaceShared::ac, p2i(r->mapped_base()), p2i(r->mapped_end()),\n-                  shared_region_name[MetaspaceShared::ac]);\n+                  AOTMetaspace::ac, p2i(r->mapped_base()), p2i(r->mapped_end()),\n+                  shared_region_name[AOTMetaspace::ac]);\n@@ -1435,2 +1435,2 @@\n-    BitMapView rw_ptrmap = ptrmap_view(MetaspaceShared::rw);\n-    BitMapView ro_ptrmap = ptrmap_view(MetaspaceShared::ro);\n+    BitMapView rw_ptrmap = ptrmap_view(AOTMetaspace::rw);\n+    BitMapView ro_ptrmap = ptrmap_view(AOTMetaspace::ro);\n@@ -1474,1 +1474,1 @@\n-    \/\/ The MetaspaceShared::bm region will be unmapped in MetaspaceShared::initialize_shared_spaces().\n+    \/\/ The AOTMetaspace::bm region will be unmapped in AOTMetaspace::initialize_shared_spaces().\n@@ -1497,1 +1497,1 @@\n-    FileMapRegion* r = FileMapInfo::current_info()->region_at(MetaspaceShared::ro);\n+    FileMapRegion* r = FileMapInfo::current_info()->region_at(AOTMetaspace::ro);\n@@ -1501,1 +1501,1 @@\n-    FileMapRegion* r = FileMapInfo::dynamic_info()->region_at(MetaspaceShared::ro);\n+    FileMapRegion* r = FileMapInfo::dynamic_info()->region_at(AOTMetaspace::ro);\n@@ -1511,1 +1511,1 @@\n-  return (region_at(MetaspaceShared::hp)->used() > 0);\n+  return (region_at(AOTMetaspace::hp)->used() > 0);\n@@ -1519,1 +1519,1 @@\n-  FileMapRegion* r = region_at(MetaspaceShared::hp);\n+  FileMapRegion* r = region_at(AOTMetaspace::hp);\n@@ -1541,1 +1541,1 @@\n-        MetaspaceShared::report_loading_error(\"Cannot use CDS heap data. Selected GC not compatible -XX:-UseCompressedOops\");\n+        AOTMetaspace::report_loading_error(\"Cannot use CDS heap data. Selected GC not compatible -XX:-UseCompressedOops\");\n@@ -1543,1 +1543,1 @@\n-        MetaspaceShared::report_loading_error(\"Cannot use CDS heap data. UseEpsilonGC, UseG1GC, UseSerialGC, UseParallelGC, or UseShenandoahGC are required.\");\n+        AOTMetaspace::report_loading_error(\"Cannot use CDS heap data. UseEpsilonGC, UseG1GC, UseSerialGC, UseParallelGC, or UseShenandoahGC are required.\");\n@@ -1558,1 +1558,1 @@\n-      MetaspaceShared::unrecoverable_loading_error();\n+      AOTMetaspace::unrecoverable_loading_error();\n@@ -1651,1 +1651,1 @@\n-  FileMapRegion* r = region_at(MetaspaceShared::hp);\n+  FileMapRegion* r = region_at(AOTMetaspace::hp);\n@@ -1665,1 +1665,1 @@\n-  FileMapRegion* r = region_at(MetaspaceShared::hp);\n+  FileMapRegion* r = region_at(AOTMetaspace::hp);\n@@ -1719,1 +1719,1 @@\n-  FileMapRegion* r = region_at(MetaspaceShared::hp);\n+  FileMapRegion* r = region_at(AOTMetaspace::hp);\n@@ -1733,1 +1733,1 @@\n-    MetaspaceShared::report_loading_error(\"UseSharedSpaces: Unable to allocate java heap region for archive heap.\");\n+    AOTMetaspace::report_loading_error(\"UseSharedSpaces: Unable to allocate java heap region for archive heap.\");\n@@ -1744,1 +1744,1 @@\n-  if (MetaspaceShared::use_windows_memory_mapping() || UseLargePages) {\n+  if (AOTMetaspace::use_windows_memory_mapping() || UseLargePages) {\n@@ -1748,1 +1748,1 @@\n-    if (!read_region(MetaspaceShared::hp, addr,\n+    if (!read_region(AOTMetaspace::hp, addr,\n@@ -1763,1 +1763,1 @@\n-      MetaspaceShared::report_loading_error(\"UseSharedSpaces: Unable to map at required address in java heap. \"\n+      AOTMetaspace::report_loading_error(\"UseSharedSpaces: Unable to map at required address in java heap. \"\n@@ -1771,1 +1771,1 @@\n-      MetaspaceShared::report_loading_error(\"UseSharedSpaces: mapped heap region is corrupt\");\n+      AOTMetaspace::report_loading_error(\"UseSharedSpaces: mapped heap region is corrupt\");\n@@ -1795,1 +1795,1 @@\n-      MetaspaceShared::report_loading_error(\"CDS heap cannot be used because bitmap region cannot be mapped\");\n+      AOTMetaspace::report_loading_error(\"CDS heap cannot be used because bitmap region cannot be mapped\");\n@@ -1810,1 +1810,1 @@\n-  FileMapRegion* r = region_at(MetaspaceShared::hp);\n+  FileMapRegion* r = region_at(AOTMetaspace::hp);\n@@ -1822,1 +1822,1 @@\n-  FileMapRegion* r = region_at(MetaspaceShared::hp);\n+  FileMapRegion* r = region_at(AOTMetaspace::hp);\n@@ -1825,1 +1825,1 @@\n-      (address)(region_at(MetaspaceShared::bm)->mapped_base()) + r->oopmap_offset(),\n+      (address)(region_at(AOTMetaspace::bm)->mapped_base()) + r->oopmap_offset(),\n@@ -1881,1 +1881,1 @@\n-    MetaspaceShared::unrecoverable_loading_error(\"Mark mismatch while restoring from shared file.\");\n+    AOTMetaspace::unrecoverable_loading_error(\"Mark mismatch while restoring from shared file.\");\n@@ -1908,1 +1908,1 @@\n-    MetaspaceShared::report_loading_error(\"CDS is disabled because early JVMTI ClassFileLoadHook is in use.\");\n+    AOTMetaspace::report_loading_error(\"CDS is disabled because early JVMTI ClassFileLoadHook is in use.\");\n@@ -1914,1 +1914,1 @@\n-      MetaspaceShared::report_loading_error(\"Loading static archive failed.\");\n+      AOTMetaspace::report_loading_error(\"Loading static archive failed.\");\n@@ -1917,1 +1917,1 @@\n-      MetaspaceShared::report_loading_error(\"Loading dynamic archive failed.\");\n+      AOTMetaspace::report_loading_error(\"Loading dynamic archive failed.\");\n@@ -1970,1 +1970,1 @@\n-  return region_at(MetaspaceShared::rw);\n+  return region_at(AOTMetaspace::rw);\n@@ -1974,1 +1974,1 @@\n-  return region_at(MetaspaceShared::ro);\n+  return region_at(AOTMetaspace::ro);\n@@ -2001,1 +2001,1 @@\n-    MetaspaceShared::report_loading_error(\"The %s's ObjectAlignmentInBytes of %d\"\n+    AOTMetaspace::report_loading_error(\"The %s's ObjectAlignmentInBytes of %d\"\n@@ -2007,1 +2007,1 @@\n-    MetaspaceShared::report_loading_error(\"The %s's CompactStrings setting (%s)\"\n+    AOTMetaspace::report_loading_error(\"The %s's CompactStrings setting (%s)\"\n@@ -2025,1 +2025,1 @@\n-    MetaspaceShared::report_loading_error(\"The %s's JIT compiler setting (%s)\"\n+    AOTMetaspace::report_loading_error(\"The %s's JIT compiler setting (%s)\"\n@@ -2032,1 +2032,1 @@\n-      MetaspaceShared::report_loading_error(\"The %s's TypeProfileLevel setting (%d)\"\n+      AOTMetaspace::report_loading_error(\"The %s's TypeProfileLevel setting (%d)\"\n@@ -2038,1 +2038,1 @@\n-      MetaspaceShared::report_loading_error(\"The %s's TypeProfileArgsLimit setting (%d)\"\n+      AOTMetaspace::report_loading_error(\"The %s's TypeProfileArgsLimit setting (%d)\"\n@@ -2044,1 +2044,1 @@\n-      MetaspaceShared::report_loading_error(\"The %s's TypeProfileParamsLimit setting (%d)\"\n+      AOTMetaspace::report_loading_error(\"The %s's TypeProfileParamsLimit setting (%d)\"\n@@ -2051,1 +2051,1 @@\n-      MetaspaceShared::report_loading_error(\"The %s's TypeProfileWidth setting (%d)\"\n+      AOTMetaspace::report_loading_error(\"The %s's TypeProfileWidth setting (%d)\"\n@@ -2058,1 +2058,1 @@\n-      MetaspaceShared::report_loading_error(\"The %s's BciProfileWidth setting (%d)\"\n+      AOTMetaspace::report_loading_error(\"The %s's BciProfileWidth setting (%d)\"\n@@ -2064,1 +2064,1 @@\n-      MetaspaceShared::report_loading_error(\"The %s's TypeProfileCasts setting (%s)\"\n+      AOTMetaspace::report_loading_error(\"The %s's TypeProfileCasts setting (%s)\"\n@@ -2073,1 +2073,1 @@\n-      MetaspaceShared::report_loading_error(\"The %s's ProfileTraps setting (%s)\"\n+      AOTMetaspace::report_loading_error(\"The %s's ProfileTraps setting (%s)\"\n@@ -2081,1 +2081,1 @@\n-      MetaspaceShared::report_loading_error(\"The %s's SpecTrapLimitExtraEntries setting (%d)\"\n+      AOTMetaspace::report_loading_error(\"The %s's SpecTrapLimitExtraEntries setting (%d)\"\n@@ -2094,1 +2094,1 @@\n-      MetaspaceShared::report_loading_error(\"%s has aot-linked classes. It cannot be used when the \"\n+      AOTMetaspace::report_loading_error(\"%s has aot-linked classes. It cannot be used when the \"\n@@ -2108,1 +2108,1 @@\n-    MetaspaceShared::report_loading_error(\"The %s's BytecodeVerificationLocal setting (%s)\"\n+    AOTMetaspace::report_loading_error(\"The %s's BytecodeVerificationLocal setting (%s)\"\n@@ -2132,1 +2132,1 @@\n-    MetaspaceShared::report_loading_error(\"The setting of the AllowArchivingWithJavaAgent is different \"\n+    AOTMetaspace::report_loading_error(\"The setting of the AllowArchivingWithJavaAgent is different \"\n","filename":"src\/hotspot\/share\/cds\/filemap.cpp","additions":82,"deletions":82,"binary":false,"changes":164,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -29,1 +30,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -75,1 +75,1 @@\n-  size_t used_aligned()             const; \/\/ aligned up to MetaspaceShared::core_region_alignment()\n+  size_t used_aligned()             const; \/\/ aligned up to AOTMetaspace::core_region_alignment()\n","filename":"src\/hotspot\/share\/cds\/filemap.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -38,1 +39,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -877,1 +877,1 @@\n-  MetaspaceShared::unrecoverable_writing_error();\n+  AOTMetaspace::unrecoverable_writing_error();\n@@ -1517,1 +1517,1 @@\n-    MetaspaceShared::unrecoverable_writing_error();\n+    AOTMetaspace::unrecoverable_writing_error();\n@@ -1570,1 +1570,1 @@\n-      MetaspaceShared::unrecoverable_writing_error();\n+      AOTMetaspace::unrecoverable_writing_error();\n@@ -1600,1 +1600,1 @@\n-        MetaspaceShared::unrecoverable_writing_error();\n+        AOTMetaspace::unrecoverable_writing_error();\n","filename":"src\/hotspot\/share\/cds\/heapShared.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -3968,4 +3968,4 @@\n-const InstanceKlass* ClassFileParser::parse_super_class(ConstantPool* const cp,\n-                                                        const int super_class_index,\n-                                                        const bool need_verify,\n-                                                        TRAPS) {\n+void ClassFileParser::check_super_class(ConstantPool* const cp,\n+                                        const int super_class_index,\n+                                        const bool need_verify,\n+                                        TRAPS) {\n@@ -3973,1 +3973,0 @@\n-  const InstanceKlass* super_klass = nullptr;\n@@ -3977,2 +3976,2 @@\n-                   \"Invalid superclass index 0 in class file %s\",\n-                   CHECK_NULL);\n+                       \"Invalid superclass index 0 in class file %s\",\n+                       CHECK);\n@@ -3983,1 +3982,2 @@\n-                       CHECK_NULL);\n+                       CHECK);\n+\n@@ -3986,6 +3986,2 @@\n-    if (cp->tag_at(super_class_index).is_klass()) {\n-      super_klass = InstanceKlass::cast(cp->resolved_klass_at(super_class_index));\n-    }\n-      bool is_array = (cp->klass_name_at(super_class_index)->char_at(0) == JVM_SIGNATURE_ARRAY);\n-      guarantee_property(!is_array,\n-                        \"Bad superclass name in class file %s\", CHECK_NULL);\n+      guarantee_property(cp->klass_name_at(super_class_index)->char_at(0) != JVM_SIGNATURE_ARRAY,\n+                        \"Bad superclass name in class file %s\", CHECK);\n@@ -3995,1 +3991,0 @@\n-  return super_klass;\n@@ -5966,4 +5961,4 @@\n-  _super_klass = parse_super_class(cp,\n-                                   _super_class_index,\n-                                   _need_verify,\n-                                   CHECK);\n+  check_super_class(cp,\n+                    _super_class_index,\n+                    _need_verify,\n+                    CHECK);\n@@ -6072,0 +6067,2 @@\n+    precond(_super_class_index == 0);\n+    precond(_super_klass == nullptr);\n@@ -6073,5 +6070,5 @@\n-        \"java.lang.Object cannot implement an interface in class file %s\",\n-        CHECK);\n-  }\n-  \/\/ We check super class after class file is parsed and format is checked\n-  if (_super_class_index > 0 && nullptr == _super_klass) {\n+                       \"java.lang.Object cannot implement an interface in class file %s\",\n+                       CHECK);\n+  } else {\n+    \/\/ Set _super_klass after class file is parsed and format is checked\n+    assert(_super_class_index > 0, \"any class other than Object must have a super class\");\n@@ -6088,0 +6085,1 @@\n+      \/\/ fast path to avoid lookup\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":22,"deletions":24,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -268,4 +268,4 @@\n-  const InstanceKlass* parse_super_class(ConstantPool* const cp,\n-                                         const int super_class_index,\n-                                         const bool need_verify,\n-                                         TRAPS);\n+  void check_super_class(ConstantPool* const cp,\n+                         const int super_class_index,\n+                         const bool need_verify,\n+                         TRAPS);\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -30,1 +31,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -2614,1 +2614,2 @@\n-\/\/ Print stack trace element to resource allocated buffer\n+\/\/ Print stack trace element to the specified output stream.\n+\/\/ The output is formatted into a stringStream and written to the outputStream in one step.\n@@ -2618,0 +2619,1 @@\n+  stringStream ss;\n@@ -2619,1 +2621,0 @@\n-  \/\/ Get strings and string lengths\n@@ -2622,3 +2623,1 @@\n-  int buf_len = (int)strlen(klass_name);\n-\n-  buf_len += (int)strlen(method_name);\n+  ss.print(\"\\tat %s.%s(\", klass_name, method_name);\n@@ -2627,8 +2626,1 @@\n-  char* source_file_name = nullptr;\n-  Symbol* source = Backtrace::get_source_file_name(holder, version);\n-  if (source != nullptr) {\n-    source_file_name = source->as_C_string();\n-    buf_len += (int)strlen(source_file_name);\n-  }\n-\n-  char *module_name = nullptr, *module_version = nullptr;\n+  \/\/ Print module information\n@@ -2637,2 +2629,1 @@\n-    module_name = module->name()->as_C_string();\n-    buf_len += (int)strlen(module_name);\n+    char* module_name = module->name()->as_C_string();\n@@ -2640,2 +2631,4 @@\n-      module_version = module->version()->as_C_string();\n-      buf_len += (int)strlen(module_version);\n+      char* module_version = module->version()->as_C_string();\n+      ss.print(\"%s@%s\/\", module_name, module_version);\n+    } else {\n+      ss.print(\"%s\/\", module_name);\n@@ -2645,16 +2638,4 @@\n-  \/\/ Allocate temporary buffer with extra space for formatting and line number\n-  const size_t buf_size = buf_len + 64;\n-  char* buf = NEW_RESOURCE_ARRAY(char, buf_size);\n-\n-  \/\/ Print stack trace line in buffer\n-  int buf_off = os::snprintf(buf, buf_size, \"\\tat %s.%s(\", klass_name, method_name);\n-  assert(static_cast<size_t>(buf_off) < buf_size, \"buffer is wrong size\");\n-  \/\/ Print module information\n-  if (module_name != nullptr) {\n-    if (module_version != nullptr) {\n-      buf_off += os::snprintf(buf + buf_off, buf_size - buf_off, \"%s@%s\/\", module_name, module_version);\n-      assert(static_cast<size_t>(buf_off) < buf_size, \"buffer is wrong size\");\n-    } else {\n-      buf_off += os::snprintf(buf + buf_off, buf_size - buf_off, \"%s\/\", module_name);\n-      assert(static_cast<size_t>(buf_off) < buf_size, \"buffer is wrong size\");\n-    }\n+  char* source_file_name = nullptr;\n+  Symbol* source = Backtrace::get_source_file_name(holder, version);\n+  if (source != nullptr) {\n+    source_file_name = source->as_C_string();\n@@ -2666,1 +2647,1 @@\n-    strcat(buf, \"Redefined)\");\n+    ss.print(\"Redefined)\");\n@@ -2670,1 +2651,1 @@\n-      strcat(buf, \"Native Method)\");\n+      ss.print(\"Native Method)\");\n@@ -2674,2 +2655,1 @@\n-        buf_off += os::snprintf(buf + buf_off, buf_size - buf_off, \"%s:%d)\", source_file_name, line_number);\n-        assert(static_cast<size_t>(buf_off) < buf_size, \"buffer is wrong size\");\n+        ss.print(\"%s:%d)\", source_file_name, line_number);\n@@ -2678,2 +2658,1 @@\n-        buf_off += os::snprintf(buf + buf_off, buf_size - buf_off, \"%s)\", source_file_name);\n-        assert(static_cast<size_t>(buf_off) < buf_size, \"buffer is wrong size\");\n+        ss.print(\"%s)\", source_file_name);\n@@ -2682,2 +2661,1 @@\n-        buf_off += os::snprintf(buf + buf_off, buf_size - buf_off, \"Unknown Source)\");\n-        assert(static_cast<size_t>(buf_off) < buf_size, \"buffer is wrong size\");\n+        ss.print(\"Unknown Source)\");\n@@ -2687,1 +2665,1 @@\n-        os::snprintf_checked(buf + buf_off, buf_size - buf_off, \"(nmethod \" INTPTR_FORMAT \")\", (intptr_t)nm);\n+        ss.print(\"(nmethod \" INTPTR_FORMAT \")\", p2i(nm));\n@@ -2692,1 +2670,2 @@\n-  st->print_cr(\"%s\", buf);\n+  ss.cr();\n+  st->print_raw(ss.freeze(), ss.size());\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":23,"deletions":44,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -996,1 +996,1 @@\n-      MetaspaceShared::unrecoverable_writing_error();\n+      AOTMetaspace::unrecoverable_writing_error();\n","filename":"src\/hotspot\/share\/classfile\/stringTable.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2122,1 +2122,1 @@\n-  Array<Method*>* list = MetaspaceShared::archived_method_handle_intrinsics();\n+  Array<Method*>* list = AOTMetaspace::archived_method_handle_intrinsics();\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -31,1 +32,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -99,1 +99,1 @@\n-\/\/ MetaspaceShared::open_static_archive() which is calles\n+\/\/ AOTMetaspace::open_static_archive() which is calles\n@@ -168,1 +168,1 @@\n-\/\/ It is called from MetaspaceShared::initialize_shared_spaces()\n+\/\/ It is called from AOTMetaspace::initialize_shared_spaces()\n","filename":"src\/hotspot\/share\/code\/aotCodeCache.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -830,1 +830,2 @@\n-bool PSParallelCompact::check_maximum_compaction(size_t total_live_words,\n+bool PSParallelCompact::check_maximum_compaction(bool should_do_max_compaction,\n+                                                 size_t total_live_words,\n@@ -843,6 +844,0 @@\n-  \/\/ JVM flags\n-  const uint total_invocations = heap->total_full_collections();\n-  assert(total_invocations >= _maximum_compaction_gc_num, \"sanity\");\n-  const size_t gcs_since_max = total_invocations - _maximum_compaction_gc_num;\n-  const bool is_interval_ended = gcs_since_max > HeapMaximumCompactionInterval;\n-\n@@ -853,6 +848,4 @@\n-  if (is_max_on_system_gc || is_old_gen_too_full || is_interval_ended || is_region_full) {\n-    _maximum_compaction_gc_num = total_invocations;\n-    return true;\n-  }\n-\n-  return false;\n+  return should_do_max_compaction\n+      || is_max_on_system_gc\n+      || is_old_gen_too_full\n+      || is_region_full;\n@@ -861,1 +854,1 @@\n-void PSParallelCompact::summary_phase()\n+void PSParallelCompact::summary_phase(bool should_do_max_compaction)\n@@ -884,3 +877,4 @@\n-    bool maximum_compaction = check_maximum_compaction(total_live_words,\n-                                                       old_space,\n-                                                       full_region_prefix_end);\n+    should_do_max_compaction = check_maximum_compaction(should_do_max_compaction,\n+                                                        total_live_words,\n+                                                        old_space,\n+                                                        full_region_prefix_end);\n@@ -895,1 +889,1 @@\n-    HeapWord* dense_prefix_end = maximum_compaction\n+    HeapWord* dense_prefix_end = should_do_max_compaction\n@@ -965,5 +959,1 @@\n-\/\/ This method invokes a full collection. The argument controls whether\n-\/\/ soft-refs should be cleared or not.\n-\/\/ Note that this method should only be called from the vm_thread while at a\n-\/\/ safepoint.\n-bool PSParallelCompact::invoke(bool clear_all_soft_refs) {\n+bool PSParallelCompact::invoke(bool clear_all_soft_refs, bool should_do_max_compaction) {\n@@ -1024,1 +1014,1 @@\n-    summary_phase();\n+    summary_phase(should_do_max_compaction);\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":14,"deletions":24,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -165,2 +165,1 @@\n-  virtual HeapWord* mem_allocate(size_t size,\n-                                 bool* gc_overhead_limit_was_exceeded) = 0;\n+  virtual HeapWord* mem_allocate(size_t size) = 0;\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -51,1 +51,0 @@\n-  bool                _overhead_limit_exceeded;\n@@ -74,1 +73,0 @@\n-      _overhead_limit_exceeded(false),\n@@ -122,1 +120,1 @@\n-  const char* message = _overhead_limit_exceeded ? \"GC overhead limit exceeded\" : \"Java heap space\";\n+  const char* message = \"Java heap space\";\n@@ -136,4 +134,1 @@\n-    oop exception = _overhead_limit_exceeded ?\n-        Universe::out_of_memory_error_gc_overhead_limit() :\n-        Universe::out_of_memory_error_java_heap();\n-    THROW_OOP_(exception, true);\n+    THROW_OOP_(Universe::out_of_memory_error_java_heap(), true);\n@@ -241,1 +236,1 @@\n-  HeapWord* mem = Universe::heap()->mem_allocate(_word_size, &allocation._overhead_limit_exceeded);\n+  HeapWord* mem = Universe::heap()->mem_allocate(_word_size);\n","filename":"src\/hotspot\/share\/gc\/shared\/memAllocator.cpp","additions":3,"deletions":8,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -26,1 +26,1 @@\n-#include \"cds\/metaspaceShared.hpp\"\n+#include \"cds\/aotMetaspace.hpp\"\n","filename":"src\/hotspot\/share\/interpreter\/abstractInterpreter.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -26,1 +27,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n","filename":"src\/hotspot\/share\/interpreter\/rewriter.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -373,0 +373,1 @@\n+    queue.resize_if_needed();\n","filename":"src\/hotspot\/share\/jfr\/periodic\/sampling\/jfrThreadSampling.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -344,1 +344,0 @@\n-  volatile_nonstatic_field(ObjectMonitor,      _stack_locker,                                 BasicLock*)                            \\\n@@ -786,4 +785,0 @@\n-  declare_constant(LockingMode::LM_MONITOR)                               \\\n-  declare_constant(LockingMode::LM_LEGACY)                                \\\n-  declare_constant(LockingMode::LM_LIGHTWEIGHT)                           \\\n-                                                                          \\\n@@ -839,1 +834,0 @@\n-  AARCH64_ONLY(declare_constant(NMethodPatchingType::conc_data_patch))                 \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -29,1 +30,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -885,1 +885,1 @@\n-  MetaspaceShared::adjust_heap_sizes_for_dumping();\n+  AOTMetaspace::adjust_heap_sizes_for_dumping();\n@@ -910,1 +910,1 @@\n-    MetaspaceShared::initialize_shared_spaces();\n+    AOTMetaspace::initialize_shared_spaces();\n@@ -1180,1 +1180,1 @@\n-  MetaspaceShared::post_initialize(CHECK_false);\n+  AOTMetaspace::post_initialize(CHECK_false);\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -57,1 +57,1 @@\n-  friend class MetaspaceShared;\n+  friend class AOTMetaspace;\n","filename":"src\/hotspot\/share\/memory\/universe.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -26,1 +27,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -287,1 +287,1 @@\n-    if (MetaspaceShared::in_aot_cache_dynamic_region((void*)k)) {\n+    if (AOTMetaspace::in_aot_cache_dynamic_region((void*)k)) {\n@@ -289,1 +289,1 @@\n-    } else if (MetaspaceShared::in_aot_cache_static_region((void*)k)) {\n+    } else if (AOTMetaspace::in_aot_cache_static_region((void*)k)) {\n","filename":"src\/hotspot\/share\/oops\/arrayKlass.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -624,1 +624,1 @@\n-  assert(oopDesc::is_oop_or_null(o, true), \"Bad oop return: \" PTR_FORMAT, ptr);\n+  assert(oopDesc::is_oop_or_null(o), \"Bad oop return: \" PTR_FORMAT, ptr);\n","filename":"src\/hotspot\/share\/oops\/inlineKlass.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -31,1 +32,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -3002,1 +3002,1 @@\n-             MetaspaceShared::in_aot_cache(_package_entry)) {\n+             AOTMetaspace::in_aot_cache(_package_entry)) {\n@@ -3088,6 +3088,1 @@\n-\/\/ Check if a class or any of its supertypes has a version older than 50.\n-\/\/ CDS will not perform verification of old classes during dump time because\n-\/\/ without changing the old verifier, the verification constraint cannot be\n-\/\/ retrieved during dump time.\n-\/\/ Verification of archived old classes will be performed during run time.\n-  if (MetaspaceShared::in_aot_cache(this)) {\n+  if (AOTMetaspace::in_aot_cache(this)) {\n@@ -3099,1 +3094,8 @@\n-  if (major_version() < 50 \/*JAVA_6_VERSION*\/) {\n+\n+  if (CDSConfig::is_preserving_verification_constraints()) {\n+    return true;\n+  }\n+\n+  if (CDSConfig::is_old_class_for_verifier(this)) {\n+    \/\/ The old verifier does not save verification constraints, so at run time\n+    \/\/ SystemDictionaryShared::check_verification_constraints() will not work for this class.\n@@ -3344,1 +3346,1 @@\n-      assert(MetaspaceShared::in_aot_cache(_package_entry), \"must be\");\n+      assert(AOTMetaspace::in_aot_cache(_package_entry), \"must be\");\n@@ -4270,1 +4272,1 @@\n-    if (MetaspaceShared::in_aot_cache_dynamic_region((void*)this)) {\n+    if (AOTMetaspace::in_aot_cache_dynamic_region((void*)this)) {\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":13,"deletions":11,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -865,8 +865,0 @@\n-  \/\/ Indicates presence of @AOTSafeClassInitializer. Also see AOTClassInitializer for more details.\n-  bool has_aot_safe_initializer() const { return _misc_flags.has_aot_safe_initializer(); }\n-  void set_has_aot_safe_initializer()   { _misc_flags.set_has_aot_safe_initializer(true); }\n-\n-  \/\/ Indicates @AOTRuntimeSetup private static void runtimeSetup() presence.\n-  bool is_runtime_setup_required() const { return _misc_flags.is_runtime_setup_required(); }\n-  void set_is_runtime_setup_required()   { _misc_flags.set_is_runtime_setup_required(true); }\n-\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":0,"deletions":8,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -57,8 +57,6 @@\n-    flag(has_aot_safe_initializer           , 1 << 14) \/* has @AOTSafeClassInitializer annotation *\/ \\\n-    flag(is_runtime_setup_required          , 1 << 15) \/* has a runtimeSetup method to be called *\/ \\\n-    flag(has_inline_type_fields             , 1 << 16) \/* has inline fields and related embedded section is not empty *\/ \\\n-    flag(is_empty_inline_type               , 1 << 17) \/* empty inline type (*) *\/ \\\n-    flag(is_naturally_atomic                , 1 << 18) \/* loaded\/stored in one instruction*\/ \\\n-    flag(must_be_atomic                     , 1 << 19) \/* doesn't allow tearing *\/ \\\n-    flag(has_loosely_consistent_annotation  , 1 << 20) \/* the class has the LooselyConsistentValue annotation WARNING: it doesn't automatically mean that the class allows tearing *\/ \\\n-    flag(has_strict_static_fields           , 1 << 21) \/* True if strict static fields declared *\/ \\\n+    flag(has_inline_type_fields             , 1 << 14) \/* has inline fields and related embedded section is not empty *\/ \\\n+    flag(is_empty_inline_type               , 1 << 15) \/* empty inline type (*) *\/ \\\n+    flag(is_naturally_atomic                , 1 << 16) \/* loaded\/stored in one instruction*\/ \\\n+    flag(must_be_atomic                     , 1 << 17) \/* doesn't allow tearing *\/ \\\n+    flag(has_loosely_consistent_annotation  , 1 << 18) \/* the class has the LooselyConsistentValue annotation WARNING: it doesn't automatically mean that the class allows tearing *\/ \\\n+    flag(has_strict_static_fields           , 1 << 19) \/* True if strict static fields declared *\/ \\\n","filename":"src\/hotspot\/share\/oops\/instanceKlassFlags.hpp","additions":6,"deletions":8,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -288,1 +288,1 @@\n-  CDS_ONLY(_shared_class_flags = 0;)\n+  CDS_ONLY(_aot_class_flags = 0;)\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -181,2 +181,2 @@\n-  u2 _shared_class_flags;\n-  enum CDSSharedClassFlags {\n+  u2 _aot_class_flags;\n+  enum  {\n@@ -188,5 +188,7 @@\n-    \/\/ This class was not loaded from a classfile in the module image\n-    \/\/ or classpath.\n-    _is_generated_shared_class             = 1 << 5,\n-    \/\/ archived mirror already initialized by AOT-cache assembly: no further need to call <clinit>\n-    _has_aot_initialized_mirror            = 1 << 6,\n+    _is_aot_generated_class                = 1 << 5, \/\/ this class was not loaded from a classfile in the module image\n+                                                     \/\/ or classpath, but was generated during AOT cache assembly.\n+    _has_aot_initialized_mirror            = 1 << 6, \/\/ archived mirror already initialized by AOT cache assembly.\n+                                                     \/\/ no further need to call <clinit>\n+    _has_aot_safe_initializer              = 1 << 7, \/\/ has @AOTSafeClassInitializer annotation\n+    _is_runtime_setup_required             = 1 << 8, \/\/ has a runtimeSetup method to be called when\n+                                                     \/\/ this class is loaded from AOT cache\n@@ -332,1 +334,1 @@\n-    CDS_ONLY(_shared_class_flags |= _archived_lambda_proxy_is_available;)\n+    CDS_ONLY(_aot_class_flags |= _archived_lambda_proxy_is_available;)\n@@ -335,1 +337,1 @@\n-    CDS_ONLY(_shared_class_flags &= (u2)(~_archived_lambda_proxy_is_available);)\n+    CDS_ONLY(_aot_class_flags &= (u2)(~_archived_lambda_proxy_is_available);)\n@@ -338,1 +340,1 @@\n-    CDS_ONLY(return (_shared_class_flags & _archived_lambda_proxy_is_available) != 0;)\n+    CDS_ONLY(return (_aot_class_flags & _archived_lambda_proxy_is_available) != 0;)\n@@ -343,1 +345,1 @@\n-    CDS_ONLY(_shared_class_flags |= _has_value_based_class_annotation;)\n+    CDS_ONLY(_aot_class_flags |= _has_value_based_class_annotation;)\n@@ -346,1 +348,1 @@\n-    CDS_ONLY(_shared_class_flags &= (u2)(~_has_value_based_class_annotation);)\n+    CDS_ONLY(_aot_class_flags &= (u2)(~_has_value_based_class_annotation);)\n@@ -349,1 +351,1 @@\n-    CDS_ONLY(return (_shared_class_flags & _has_value_based_class_annotation) != 0;)\n+    CDS_ONLY(return (_aot_class_flags & _has_value_based_class_annotation) != 0;)\n@@ -354,1 +356,1 @@\n-    CDS_ONLY(_shared_class_flags |= _verified_at_dump_time;)\n+    CDS_ONLY(_aot_class_flags |= _verified_at_dump_time;)\n@@ -357,1 +359,1 @@\n-    CDS_ONLY(return (_shared_class_flags & _verified_at_dump_time) != 0;)\n+    CDS_ONLY(return (_aot_class_flags & _verified_at_dump_time) != 0;)\n@@ -362,1 +364,1 @@\n-    CDS_ONLY(_shared_class_flags |= _has_archived_enum_objs;)\n+    CDS_ONLY(_aot_class_flags |= _has_archived_enum_objs;)\n@@ -365,1 +367,1 @@\n-    CDS_ONLY(return (_shared_class_flags & _has_archived_enum_objs) != 0;)\n+    CDS_ONLY(return (_aot_class_flags & _has_archived_enum_objs) != 0;)\n@@ -369,2 +371,2 @@\n-  void set_is_generated_shared_class() {\n-    CDS_ONLY(_shared_class_flags |= _is_generated_shared_class;)\n+  void set_is_aot_generated_class() {\n+    CDS_ONLY(_aot_class_flags |= _is_aot_generated_class;)\n@@ -372,2 +374,2 @@\n-  bool is_generated_shared_class() const {\n-    CDS_ONLY(return (_shared_class_flags & _is_generated_shared_class) != 0;)\n+  bool is_aot_generated_class() const {\n+    CDS_ONLY(return (_aot_class_flags & _is_aot_generated_class) != 0;)\n@@ -378,1 +380,1 @@\n-    CDS_ONLY(_shared_class_flags |= _has_aot_initialized_mirror;)\n+    CDS_ONLY(_aot_class_flags |= _has_aot_initialized_mirror;)\n@@ -381,1 +383,19 @@\n-    CDS_ONLY(return (_shared_class_flags & _has_aot_initialized_mirror) != 0;)\n+    CDS_ONLY(return (_aot_class_flags & _has_aot_initialized_mirror) != 0;)\n+    NOT_CDS(return false;)\n+  }\n+\n+  \/\/ Indicates presence of @AOTSafeClassInitializer. Also see AOTClassInitializer for more details.\n+  void set_has_aot_safe_initializer() {\n+    CDS_ONLY(_aot_class_flags |= _has_aot_safe_initializer;)\n+  }\n+  bool has_aot_safe_initializer() const {\n+    CDS_ONLY(return (_aot_class_flags & _has_aot_safe_initializer) != 0;)\n+    NOT_CDS(return false;)\n+  }\n+\n+  \/\/ Indicates @AOTRuntimeSetup private static void runtimeSetup() presence.\n+  void set_is_runtime_setup_required() {\n+    CDS_ONLY(_aot_class_flags |= _is_runtime_setup_required;)\n+  }\n+  bool is_runtime_setup_required() const {\n+    CDS_ONLY(return (_aot_class_flags & _is_runtime_setup_required) != 0;)\n@@ -386,1 +406,1 @@\n-    CDS_ONLY(return (_shared_class_flags & _in_aot_cache) != 0;)\n+    CDS_ONLY(return (_aot_class_flags & _in_aot_cache) != 0;)\n@@ -391,1 +411,1 @@\n-    CDS_ONLY(_shared_class_flags |= _in_aot_cache;)\n+    CDS_ONLY(_aot_class_flags |= _in_aot_cache;)\n","filename":"src\/hotspot\/share\/oops\/klass.hpp","additions":45,"deletions":25,"binary":false,"changes":70,"status":"modified"},{"patch":"@@ -25,1 +25,1 @@\n-#include \"cds\/metaspaceShared.hpp\"\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -53,1 +53,1 @@\n-  return _klass->in_aot_cache() && !MetaspaceShared::remapped_readwrite() && _klass->verified_at_dump_time();\n+  return _klass->in_aot_cache() && !AOTMetaspace::remapped_readwrite() && _klass->verified_at_dump_time();\n@@ -1092,2 +1092,2 @@\n-  if (MetaspaceShared::in_aot_cache((void*)&_method) &&\n-     !MetaspaceShared::remapped_readwrite() &&\n+  if (AOTMetaspace::in_aot_cache((void*)&_method) &&\n+     !AOTMetaspace::remapped_readwrite() &&\n","filename":"src\/hotspot\/share\/oops\/klassVtable.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -39,12 +39,4 @@\n-  if (has_monitor()) {\n-    \/\/ Has an inflated monitor. Must be checked before has_locker().\n-    ObjectMonitor* monitor = this->monitor();\n-    return monitor->header();\n-  }\n-  if (has_locker()) {  \/\/ has a stack lock\n-    BasicLock* locker = this->locker();\n-    return locker->displaced_header();\n-  }\n-  \/\/ This should never happen:\n-  fatal(\"bad header=\" INTPTR_FORMAT, value());\n-  return markWord(value());\n+  \/\/ Make sure we have an inflated monitor.\n+  guarantee(has_monitor(), \"bad header=\" INTPTR_FORMAT, value());\n+  ObjectMonitor* monitor = this->monitor();\n+  return monitor->header();\n@@ -55,13 +47,4 @@\n-  if (has_monitor()) {\n-    \/\/ Has an inflated monitor. Must be checked before has_locker().\n-    ObjectMonitor* monitor = this->monitor();\n-    monitor->set_header(m);\n-    return;\n-  }\n-  if (has_locker()) {  \/\/ has a stack lock\n-    BasicLock* locker = this->locker();\n-    locker->set_displaced_header(m);\n-    return;\n-  }\n-  \/\/ This should never happen:\n-  fatal(\"bad header=\" INTPTR_FORMAT, value());\n+  \/\/ Make sure we have an inflated monitor.\n+  guarantee(has_monitor(), \"bad header=\" INTPTR_FORMAT, value());\n+  ObjectMonitor* monitor = this->monitor();\n+  monitor->set_header(m);\n","filename":"src\/hotspot\/share\/oops\/markWord.cpp","additions":8,"deletions":25,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -319,8 +319,0 @@\n-  bool has_locker() const {\n-    assert(LockingMode == LM_LEGACY, \"should only be called with legacy stack locking\");\n-    return (value() & lock_mask_in_place) == locked_value;\n-  }\n-  BasicLock* locker() const {\n-    assert(has_locker(), \"check\");\n-    return (BasicLock*) value();\n-  }\n@@ -329,1 +321,0 @@\n-    assert(LockingMode == LM_LIGHTWEIGHT, \"should only be called with new lightweight locking\");\n@@ -348,5 +339,1 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n-      return !UseObjectMonitorTable && lockbits == monitor_value;\n-    }\n-    \/\/ monitor (0b10) | stack-locked (0b00)?\n-    return (lockbits & unlocked_value) == 0;\n+    return !UseObjectMonitorTable && lockbits == monitor_value;\n@@ -468,1 +455,0 @@\n-    NOT_LP64(assert(LockingMode != LM_LEGACY, \"incorrect with LM_LEGACY on 32 bit\");)\n@@ -473,1 +459,0 @@\n-    NOT_LP64(assert(LockingMode != LM_LEGACY, \"incorrect with LM_LEGACY on 32 bit\");)\n@@ -478,1 +463,0 @@\n-    NOT_LP64(assert(LockingMode != LM_LEGACY, \"incorrect with LM_LEGACY on 32 bit\");)\n","filename":"src\/hotspot\/share\/oops\/markWord.hpp","additions":1,"deletions":17,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -27,1 +28,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -461,1 +461,1 @@\n-  if (in_aot_cache() && !MetaspaceShared::remapped_readwrite() && method_holder()->verified_at_dump_time()) {\n+  if (in_aot_cache() && !AOTMetaspace::remapped_readwrite() && method_holder()->verified_at_dump_time()) {\n@@ -472,1 +472,1 @@\n-  if (in_aot_cache() && !MetaspaceShared::remapped_readwrite() && method_holder()->verified_at_dump_time()) {\n+  if (in_aot_cache() && !AOTMetaspace::remapped_readwrite() && method_holder()->verified_at_dump_time()) {\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -326,3 +326,2 @@\n-  if (SafepointSynchronize::is_at_safepoint() &&\n-      CDSConfig::is_dumping_archive() &&\n-      CDSConfig::current_thread_is_vm_or_dumper()) {\n+  if (CDSConfig::is_at_aot_safepoint()) {\n+    \/\/ Check for CDS exclusion only at CDS safe point.\n","filename":"src\/hotspot\/share\/oops\/methodData.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -113,16 +113,2 @@\n-bool oopDesc::is_oop(oop obj, bool ignore_mark_word) {\n-  if (!Universe::heap()->is_oop(obj)) {\n-    return false;\n-  }\n-\n-  \/\/ Header verification: the mark is typically non-zero. If we're\n-  \/\/ at a safepoint, it must not be zero, except when using the new lightweight locking.\n-  \/\/ Outside of a safepoint, the header could be changing (for example,\n-  \/\/ another thread could be inflating a lock on this object).\n-  if (ignore_mark_word) {\n-    return true;\n-  }\n-  if (obj->mark().value() != 0) {\n-    return true;\n-  }\n-  return LockingMode == LM_LIGHTWEIGHT || !SafepointSynchronize::is_at_safepoint();\n+bool oopDesc::is_oop(oop obj) {\n+  return Universe::heap()->is_oop(obj);\n@@ -132,2 +118,2 @@\n-bool oopDesc::is_oop_or_null(oop obj, bool ignore_mark_word) {\n-  return obj == nullptr ? true : is_oop(obj, ignore_mark_word);\n+bool oopDesc::is_oop_or_null(oop obj) {\n+  return obj == nullptr ? true : is_oop(obj);\n","filename":"src\/hotspot\/share\/oops\/oop.cpp","additions":4,"deletions":18,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -283,2 +283,2 @@\n-  static bool is_oop(oop obj, bool ignore_mark_word = false);\n-  static bool is_oop_or_null(oop obj, bool ignore_mark_word = false);\n+  static bool is_oop(oop obj);\n+  static bool is_oop_or_null(oop obj);\n","filename":"src\/hotspot\/share\/oops\/oop.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -26,1 +26,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n","filename":"src\/hotspot\/share\/oops\/symbol.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -63,0 +63,1 @@\n+    _caller_jvms->set_receiver_info(caller_jvms->receiver_info());\n@@ -440,6 +441,5 @@\n-    \/\/ count the current method and the callee\n-    int inline_level = 0;\n-    if (!is_compiled_lambda_form) {\n-      if (method() == callee_method) {\n-        inline_level++;\n-      }\n+    const bool is_method_handle_invoker = is_compiled_lambda_form && !jvms->method()->is_compiled_lambda_form();\n+\n+    ciInstance* lform_callee_recv = nullptr;\n+    if (is_compiled_lambda_form && !is_method_handle_invoker) { \/\/ MH invokers don't have a receiver\n+      lform_callee_recv = jvms->compute_receiver_info(callee_method);\n@@ -448,3 +448,3 @@\n-    \/\/ count callers of current method and callee\n-    Node* callee_argument0 = is_compiled_lambda_form ? jvms->map()->argument(jvms, 0)->uncast() : nullptr;\n-    for (JVMState* j = jvms->caller(); j != nullptr && j->has_method(); j = j->caller()) {\n+\n+    int inline_level = 0;\n+    for (JVMState* j = jvms; j != nullptr && j->has_method(); j = j->caller()) {\n@@ -452,6 +452,9 @@\n-        if (is_compiled_lambda_form) {\n-          \/\/ Since compiled lambda forms are heavily reused we allow recursive inlining.  If it is truly\n-          \/\/ a recursion (using the same \"receiver\") we limit inlining otherwise we can easily blow the\n-          \/\/ compiler stack.\n-          Node* caller_argument0 = j->map()->argument(j, 0)->uncast();\n-          if (caller_argument0 == callee_argument0) {\n+        \/\/ Since compiled lambda forms are heavily reused we allow recursive inlining.  If it is truly\n+        \/\/ a recursion (using the same \"receiver\") we limit inlining otherwise we can easily blow the\n+        \/\/ compiler stack.\n+        if (lform_callee_recv != nullptr) {\n+          ciInstance* lform_caller_recv = j->receiver_info();\n+          assert(lform_caller_recv != nullptr || j->depth() == 1 ||\n+                 !j->caller()->method()->is_compiled_lambda_form(), \/\/ MH invoker\n+                 \"missing receiver info\");\n+          if (lform_caller_recv == lform_callee_recv || lform_caller_recv == nullptr) {\n","filename":"src\/hotspot\/share\/opto\/bytecodeInfo.cpp","additions":18,"deletions":15,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -257,1 +257,2 @@\n-  _method(method) {\n+  _method(method),\n+  _receiver_info(nullptr) {\n@@ -273,1 +274,2 @@\n-  _method(nullptr) {\n+  _method(nullptr),\n+  _receiver_info(nullptr) {\n@@ -620,0 +622,1 @@\n+  n->set_receiver_info(_receiver_info);\n@@ -694,0 +697,14 @@\n+\/\/ Compute receiver info for a compiled lambda form at call site.\n+ciInstance* JVMState::compute_receiver_info(ciMethod* callee) const {\n+  assert(callee != nullptr && callee->is_compiled_lambda_form(), \"\");\n+  if (has_method() && method()->is_compiled_lambda_form()) { \/\/ callee is not a MH invoker\n+    Node* recv = map()->argument(this, 0);\n+    assert(recv != nullptr, \"\");\n+    const TypeOopPtr* recv_toop = recv->bottom_type()->isa_oopptr();\n+    if (recv_toop != nullptr && recv_toop->const_oop() != nullptr) {\n+      return recv_toop->const_oop()->as_instance();\n+    }\n+  }\n+  return nullptr;\n+}\n+\n@@ -1555,1 +1572,1 @@\n-void SafePointNode::set_local(JVMState* jvms, uint idx, Node *c) {\n+void SafePointNode::set_local(const JVMState* jvms, uint idx, Node *c) {\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":20,"deletions":3,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -219,0 +219,1 @@\n+  ciInstance*       _receiver_info; \/\/ Constant receiver instance for compiled lambda forms\n@@ -261,0 +262,1 @@\n+  ciInstance*    receiver_info() const { assert(has_method(), \"\"); return _receiver_info; }\n@@ -306,0 +308,1 @@\n+  void              set_receiver_info(ciInstance* recv) { assert(has_method() || recv == nullptr, \"\"); _receiver_info = recv; }\n@@ -313,0 +316,1 @@\n+  ciInstance* compute_receiver_info(ciMethod* callee) const;\n@@ -376,1 +380,1 @@\n-  void verify_input(JVMState* jvms, uint idx) const {\n+  void verify_input(const JVMState* jvms, uint idx) const {\n@@ -385,3 +389,5 @@\n-  Node *local(JVMState* jvms, uint idx) const {\n-    verify_input(jvms, jvms->locoff() + idx);\n-    return in(jvms->locoff() + idx);\n+  Node* local(const JVMState* jvms, uint idx) const {\n+    uint loc_idx = jvms->locoff() + idx;\n+    assert(jvms->is_loc(loc_idx), \"not a local slot\");\n+    verify_input(jvms, loc_idx);\n+    return in(loc_idx);\n@@ -389,3 +395,5 @@\n-  Node *stack(JVMState* jvms, uint idx) const {\n-    verify_input(jvms, jvms->stkoff() + idx);\n-    return in(jvms->stkoff() + idx);\n+  Node* stack(const JVMState* jvms, uint idx) const {\n+    uint stk_idx = jvms->stkoff() + idx;\n+    assert(jvms->is_stk(stk_idx), \"not a stack slot\");\n+    verify_input(jvms, stk_idx);\n+    return in(stk_idx);\n@@ -393,2 +401,4 @@\n-  Node *argument(JVMState* jvms, uint idx) const {\n-    verify_input(jvms, jvms->argoff() + idx);\n+  Node* argument(const JVMState* jvms, uint idx) const {\n+    uint arg_idx = jvms->argoff() + idx;\n+    assert(jvms->is_stk(arg_idx), \"not an argument slot\");\n+    verify_input(jvms, arg_idx);\n@@ -397,1 +407,1 @@\n-  Node *monitor_box(JVMState* jvms, uint idx) const {\n+  Node* monitor_box(const JVMState* jvms, uint idx) const {\n@@ -399,1 +409,3 @@\n-    return in(jvms->monitor_box_offset(idx));\n+    uint mon_box_idx = jvms->monitor_box_offset(idx);\n+    assert(jvms->is_monitor_box(mon_box_idx), \"not a monitor box offset\");\n+    return in(mon_box_idx);\n@@ -401,1 +413,1 @@\n-  Node *monitor_obj(JVMState* jvms, uint idx) const {\n+  Node* monitor_obj(const JVMState* jvms, uint idx) const {\n@@ -403,1 +415,3 @@\n-    return in(jvms->monitor_obj_offset(idx));\n+    uint mon_obj_idx = jvms->monitor_obj_offset(idx);\n+    assert(jvms->is_mon(mon_obj_idx) && !jvms->is_monitor_box(mon_obj_idx), \"not a monitor obj offset\");\n+    return in(mon_obj_idx);\n@@ -406,1 +420,1 @@\n-  void  set_local(JVMState* jvms, uint idx, Node *c);\n+  void  set_local(const JVMState* jvms, uint idx, Node *c);\n@@ -408,1 +422,1 @@\n-  void  set_stack(JVMState* jvms, uint idx, Node *c) {\n+  void  set_stack(const JVMState* jvms, uint idx, Node *c) {\n@@ -412,1 +426,1 @@\n-  void  set_argument(JVMState* jvms, uint idx, Node *c) {\n+  void  set_argument(const JVMState* jvms, uint idx, Node *c) {\n","filename":"src\/hotspot\/share\/opto\/callnode.hpp","additions":30,"deletions":16,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -5383,4 +5383,3 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n-      Node *monitor_val   = _gvn.MakeConX(markWord::monitor_value);\n-      Node *chk_monitor   = _gvn.transform(new CmpXNode(lmasked_header, monitor_val));\n-      Node *test_monitor  = _gvn.transform(new BoolNode(chk_monitor, BoolTest::eq));\n+    Node *monitor_val   = _gvn.MakeConX(markWord::monitor_value);\n+    Node *chk_monitor   = _gvn.transform(new CmpXNode(lmasked_header, monitor_val));\n+    Node *test_monitor  = _gvn.transform(new BoolNode(chk_monitor, BoolTest::eq));\n@@ -5388,8 +5387,1 @@\n-      generate_slow_guard(test_monitor, slow_region);\n-    } else {\n-      Node *unlocked_val      = _gvn.MakeConX(markWord::unlocked_value);\n-      Node *chk_unlocked      = _gvn.transform(new CmpXNode(lmasked_header, unlocked_val));\n-      Node *test_not_unlocked = _gvn.transform(new BoolNode(chk_unlocked, BoolTest::ne));\n-\n-      generate_slow_guard(test_not_unlocked, slow_region);\n-    }\n+    generate_slow_guard(test_monitor, slow_region);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":4,"deletions":12,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -240,2 +240,2 @@\n-    tty->print(\"Split %d %s through %d Phi in %d %s\",\n-               n->_idx, n->Name(), phi->_idx, region->_idx, region->Name());\n+    tty->print_cr(\"Split %d %s through %d Phi in %d %s\",\n+                  n->_idx, n->Name(), phi->_idx, region->_idx, region->Name());\n","filename":"src\/hotspot\/share\/opto\/loopopts.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -110,6 +110,0 @@\n-  \/\/ Use this for an unconditional branch delay slot\n-  Node *_unconditional_delay_slot;\n-\n-  \/\/ Pointer to a Nop\n-  MachNopNode *_nop;\n-\n@@ -132,3 +126,0 @@\n-  \/\/ Destructor\n-  NOT_PRODUCT( ~Scheduling(); )\n-\n@@ -198,3 +189,0 @@\n-  uint _branches, _unconditional_delays;\n-\n-  static uint _total_branches, _total_unconditional_delays;\n@@ -1495,4 +1483,0 @@\n-  \/\/ fill in the nop array for bundling computations\n-  MachNode *_nop_list[Bundle::_nop_count];\n-  Bundle::initialize_nops(_nop_list);\n-\n@@ -1572,1 +1556,0 @@\n-  Node* delay_slot = nullptr;\n@@ -1611,9 +1594,0 @@\n-      \/\/ See if delay slots are supported\n-      if (valid_bundle_info(n) && node_bundling(n)->used_in_unconditional_delay()) {\n-        assert(delay_slot == nullptr, \"no use of delay slot node\");\n-        assert(n->size(C->regalloc()) == Pipeline::instr_unit_size(), \"delay slot instruction wrong size\");\n-\n-        delay_slot = n;\n-        continue;\n-      }\n-\n@@ -1638,3 +1612,0 @@\n-        \/\/ A padding may be needed again since a previous instruction\n-        \/\/ could be moved to delay slot.\n-\n@@ -1715,1 +1686,1 @@\n-          \/\/ Try to replace long branch if delay slot is not used,\n+          \/\/ Try to replace long branch,\n@@ -1718,4 +1689,1 @@\n-          bool delay_slot_is_used = valid_bundle_info(n) &&\n-                                    C->output()->node_bundling(n)->use_unconditional_delay();\n-          if (!delay_slot_is_used && mach->may_be_short_branch()) {\n-            assert(delay_slot == nullptr, \"not expecting delay slot node\");\n+          if (mach->may_be_short_branch()) {\n@@ -1854,38 +1822,0 @@\n-      \/\/ See if this instruction has a delay slot\n-      if (valid_bundle_info(n) && node_bundling(n)->use_unconditional_delay()) {\n-        guarantee(delay_slot != nullptr, \"expecting delay slot node\");\n-\n-        \/\/ Back up 1 instruction\n-        masm->code()->set_insts_end(masm->code()->insts_end() - Pipeline::instr_unit_size());\n-\n-        \/\/ Save the offset for the listing\n-#if defined(SUPPORT_OPTO_ASSEMBLY)\n-        if ((node_offsets != nullptr) && (delay_slot->_idx < node_offset_limit)) {\n-          node_offsets[delay_slot->_idx] = masm->offset();\n-        }\n-#endif\n-\n-        \/\/ Support a SafePoint in the delay slot\n-        if (delay_slot->is_MachSafePoint()) {\n-          MachNode *mach = delay_slot->as_Mach();\n-          \/\/ !!!!! Stubs only need an oopmap right now, so bail out\n-          if (!mach->is_MachCall() && mach->as_MachSafePoint()->jvms()->method() == nullptr) {\n-            \/\/ Write the oopmap directly to the code blob??!!\n-            delay_slot = nullptr;\n-            continue;\n-          }\n-\n-          int adjusted_offset = current_offset - Pipeline::instr_unit_size();\n-          non_safepoints.observe_safepoint(mach->as_MachSafePoint()->jvms(),\n-                                           adjusted_offset);\n-          \/\/ Generate an OopMap entry\n-          Process_OopMap_Node(mach, adjusted_offset);\n-        }\n-\n-        \/\/ Insert the delay slot instruction\n-        delay_slot->emit(masm, C->regalloc());\n-\n-        \/\/ Don't reuse it\n-        delay_slot = nullptr;\n-      }\n-\n@@ -2132,2 +2062,0 @@\n-uint Scheduling::_total_branches = 0;\n-uint Scheduling::_total_unconditional_delays = 0;\n@@ -2151,9 +2079,1 @@\n-#ifndef PRODUCT\n-        , _branches(0)\n-        , _unconditional_delays(0)\n-#endif\n-  \/\/ Create a MachNopNode\n-  _nop = new MachNopNode();\n-\n-  \/\/ Now that the nops are in the array, save the count\n-  \/\/ (but allow entries for the nops)\n+  \/\/ Save the count\n@@ -2189,8 +2109,0 @@\n-#ifndef PRODUCT\n-\/\/ Scheduling destructor\n-Scheduling::~Scheduling() {\n-  _total_branches             += _branches;\n-  _total_unconditional_delays += _unconditional_delays;\n-}\n-#endif\n-\n@@ -2301,9 +2213,0 @@\n-  \/\/ If this is the unconditional delay instruction, then it fits\n-  if (n == _unconditional_delay_slot) {\n-#ifndef PRODUCT\n-    if (_cfg->C->trace_opto_output())\n-      tty->print(\"#     NodeFitsInBundle [%4d]: TRUE; is in unconditional delay slot\\n\", n->_idx);\n-#endif\n-    return (true);\n-  }\n-\n@@ -2325,2 +2228,0 @@\n-  else if (node_pipeline->hasBranchDelay() && !_unconditional_delay_slot)\n-    instruction_count++;\n@@ -2538,93 +2439,0 @@\n-  \/\/ Check for instructions to be placed in the delay slot. We\n-  \/\/ do this before we actually schedule the current instruction,\n-  \/\/ because the delay slot follows the current instruction.\n-  if (Pipeline::_branch_has_delay_slot &&\n-      node_pipeline->hasBranchDelay() &&\n-      !_unconditional_delay_slot) {\n-\n-    uint siz = _available.size();\n-\n-    \/\/ Conditional branches can support an instruction that\n-    \/\/ is unconditionally executed and not dependent by the\n-    \/\/ branch, OR a conditionally executed instruction if\n-    \/\/ the branch is taken.  In practice, this means that\n-    \/\/ the first instruction at the branch target is\n-    \/\/ copied to the delay slot, and the branch goes to\n-    \/\/ the instruction after that at the branch target\n-    if ( n->is_MachBranch() ) {\n-\n-      assert( !n->is_MachNullCheck(), \"should not look for delay slot for Null Check\" );\n-      assert( !n->is_Catch(),         \"should not look for delay slot for Catch\" );\n-\n-#ifndef PRODUCT\n-      _branches++;\n-#endif\n-\n-      \/\/ At least 1 instruction is on the available list\n-      \/\/ that is not dependent on the branch\n-      for (uint i = 0; i < siz; i++) {\n-        Node *d = _available[i];\n-        const Pipeline *avail_pipeline = d->pipeline();\n-\n-        \/\/ Don't allow safepoints in the branch shadow, that will\n-        \/\/ cause a number of difficulties\n-        if ( avail_pipeline->instructionCount() == 1 &&\n-             !avail_pipeline->hasMultipleBundles() &&\n-             !avail_pipeline->hasBranchDelay() &&\n-             Pipeline::instr_has_unit_size() &&\n-             d->size(_regalloc) == Pipeline::instr_unit_size() &&\n-             NodeFitsInBundle(d) &&\n-             !node_bundling(d)->used_in_delay()) {\n-\n-          if (d->is_Mach() && !d->is_MachSafePoint()) {\n-            \/\/ A node that fits in the delay slot was found, so we need to\n-            \/\/ set the appropriate bits in the bundle pipeline information so\n-            \/\/ that it correctly indicates resource usage.  Later, when we\n-            \/\/ attempt to add this instruction to the bundle, we will skip\n-            \/\/ setting the resource usage.\n-            _unconditional_delay_slot = d;\n-            node_bundling(n)->set_use_unconditional_delay();\n-            node_bundling(d)->set_used_in_unconditional_delay();\n-            _bundle_use.add_usage(avail_pipeline->resourceUse());\n-            _current_latency[d->_idx] = _bundle_cycle_number;\n-            _next_node = d;\n-            ++_bundle_instr_count;\n-#ifndef PRODUCT\n-            _unconditional_delays++;\n-#endif\n-            break;\n-          }\n-        }\n-      }\n-    }\n-\n-    \/\/ No delay slot, add a nop to the usage\n-    if (!_unconditional_delay_slot) {\n-      \/\/ See if adding an instruction in the delay slot will overflow\n-      \/\/ the bundle.\n-      if (!NodeFitsInBundle(_nop)) {\n-#ifndef PRODUCT\n-        if (_cfg->C->trace_opto_output())\n-          tty->print(\"#  *** STEP(1 instruction for delay slot) ***\\n\");\n-#endif\n-        step(1);\n-      }\n-\n-      _bundle_use.add_usage(_nop->pipeline()->resourceUse());\n-      _next_node = _nop;\n-      ++_bundle_instr_count;\n-    }\n-\n-    \/\/ See if the instruction in the delay slot requires a\n-    \/\/ step of the bundles\n-    if (!NodeFitsInBundle(n)) {\n-#ifndef PRODUCT\n-      if (_cfg->C->trace_opto_output())\n-        tty->print(\"#  *** STEP(branch won't fit) ***\\n\");\n-#endif\n-      \/\/ Update the state information\n-      _bundle_instr_count = 0;\n-      _bundle_cycle_number += 1;\n-      _bundle_use.step(1);\n-    }\n-  }\n@@ -2658,5 +2466,2 @@\n-  \/\/ If this was placed in the delay slot, ignore it\n-  if (n != _unconditional_delay_slot) {\n-\n-    if (delay == 0) {\n-      if (node_pipeline->hasMultipleBundles()) {\n+  if (delay == 0) {\n+    if (node_pipeline->hasMultipleBundles()) {\n@@ -2664,2 +2469,2 @@\n-        if (_cfg->C->trace_opto_output())\n-          tty->print(\"#  *** STEP(multiple instructions) ***\\n\");\n+      if (_cfg->C->trace_opto_output())\n+        tty->print(\"#  *** STEP(multiple instructions) ***\\n\");\n@@ -2667,2 +2472,2 @@\n-        step(1);\n-      }\n+      step(1);\n+    }\n@@ -2670,1 +2475,1 @@\n-      else if (instruction_count + _bundle_instr_count > Pipeline::_max_instrs_per_cycle) {\n+    else if (instruction_count + _bundle_instr_count > Pipeline::_max_instrs_per_cycle) {\n@@ -2672,4 +2477,4 @@\n-        if (_cfg->C->trace_opto_output())\n-          tty->print(\"#  *** STEP(%d >= %d instructions) ***\\n\",\n-                     instruction_count + _bundle_instr_count,\n-                     Pipeline::_max_instrs_per_cycle);\n+      if (_cfg->C->trace_opto_output())\n+        tty->print(\"#  *** STEP(%d >= %d instructions) ***\\n\",\n+                   instruction_count + _bundle_instr_count,\n+                   Pipeline::_max_instrs_per_cycle);\n@@ -2677,2 +2482,1 @@\n-        step(1);\n-      }\n+      step(1);\n@@ -2680,0 +2484,1 @@\n+  }\n@@ -2681,5 +2486,2 @@\n-    if (node_pipeline->hasBranchDelay() && !_unconditional_delay_slot)\n-      _bundle_instr_count++;\n-\n-    \/\/ Set the node's latency\n-    _current_latency[n->_idx] = _bundle_cycle_number;\n+  \/\/ Set the node's latency\n+  _current_latency[n->_idx] = _bundle_cycle_number;\n@@ -2687,3 +2489,3 @@\n-    \/\/ Now merge the functional unit information\n-    if (instruction_count > 0 || !node_pipeline->mayHaveNoCode())\n-      _bundle_use.add_usage(node_usage);\n+  \/\/ Now merge the functional unit information\n+  if (instruction_count > 0 || !node_pipeline->mayHaveNoCode())\n+    _bundle_use.add_usage(node_usage);\n@@ -2691,2 +2493,2 @@\n-    \/\/ Increment the number of instructions in this bundle\n-    _bundle_instr_count += instruction_count;\n+  \/\/ Increment the number of instructions in this bundle\n+  _bundle_instr_count += instruction_count;\n@@ -2694,4 +2496,3 @@\n-    \/\/ Remember this node for later\n-    if (n->is_Mach())\n-      _next_node = n;\n-  }\n+  \/\/ Remember this node for later\n+  if (n->is_Mach())\n+    _next_node = n;\n@@ -2749,3 +2550,0 @@\n-  \/\/ No delay slot specified\n-  _unconditional_delay_slot = nullptr;\n-\n@@ -2869,5 +2667,1 @@\n-    \/\/ might schedule.  _bb_end points just after last schedulable inst.  We\n-    \/\/ normally schedule conditional branches (despite them being forced last\n-    \/\/ in the block), because they have delay slots we can fill.  Calls all\n-    \/\/ have their delay slots filled in the template expansions, so we don't\n-    \/\/ bother scheduling them.\n+    \/\/ might schedule.  _bb_end points just after last schedulable inst.\n@@ -2939,1 +2733,1 @@\n-          if (bundle->instr_count() > 0 || bundle->flags() > 0) {\n+          if (bundle->instr_count() > 0) {\n@@ -3388,10 +3182,0 @@\n-  \/\/ Print the number of branch shadows filled\n-  if (Pipeline::_branch_has_delay_slot) {\n-    tty->print(\"Of %d branches, %d had unconditional delay slots filled\",\n-               _total_branches, _total_unconditional_delays);\n-    if (_total_branches > 0)\n-      tty->print(\", for %.2f%%\",\n-                 ((double)_total_unconditional_delays) \/ ((double)_total_branches) * 100.0);\n-    tty->print(\"\\n\");\n-  }\n-\n@@ -3711,1 +3495,0 @@\n-    Node *delay = nullptr;\n@@ -3720,4 +3503,0 @@\n-        if (bundle->used_in_unconditional_delay()) {\n-          delay = n;\n-          continue;\n-        }\n@@ -3756,23 +3535,0 @@\n-      \/\/ If we have an instruction with a delay slot, and have seen a delay,\n-      \/\/ then back up and print it\n-      if (valid_bundle_info(n) && node_bundling(n)->use_unconditional_delay()) {\n-        \/\/ Coverity finding - Explicit null dereferenced.\n-        guarantee(delay != nullptr, \"no unconditional delay instruction\");\n-        if (WizardMode) delay->dump();\n-\n-        if (node_bundling(delay)->starts_bundle())\n-          starts_bundle = '+';\n-        if ((pcs != nullptr) && (n->_idx < pc_limit)) {\n-          pc = pcs[n->_idx];\n-          st->print(\"%*.*x\", pc_digits, pc_digits, pc);\n-        } else {\n-          st->fill_to(pc_digits);\n-        }\n-        st->print(\" %c \", starts_bundle);\n-        starts_bundle = ' ';\n-        st->fill_to(prefix_len);\n-        delay->format(C->regalloc(), st);\n-        st->cr();\n-        delay = nullptr;\n-      }\n-\n@@ -3787,1 +3543,0 @@\n-    assert(cut_short || delay == nullptr, \"no unconditional delay branch\");\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":28,"deletions":273,"binary":false,"changes":301,"status":"modified"},{"patch":"@@ -1231,0 +1231,7 @@\n+\n+  \/\/ Capture receiver info for compiled lambda forms.\n+  if (method()->is_compiled_lambda_form()) {\n+    ciInstance* recv_info = _caller->compute_receiver_info(method());\n+    jvms->set_receiver_info(recv_info);\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/parse1.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -783,1 +783,1 @@\n-    if (!no_dead_loop) n->dump_bfs(100,nullptr,\"#\");\n+    if (!no_dead_loop) { n->dump_bfs(100, nullptr, \"\"); }\n@@ -1673,0 +1673,1 @@\n+    \/\/   Note: The -XX:LockingMode option is not available anymore.\n","filename":"src\/hotspot\/share\/opto\/phaseX.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -1028,0 +1029,7 @@\n+#if INCLUDE_CDS\n+  if (CDSConfig::is_preserving_verification_constraints() && from_class->is_instance_klass()) {\n+    InstanceKlass* ik = InstanceKlass::cast(from_class);\n+    SystemDictionaryShared::add_old_verification_constraint(THREAD, ik, h_name);\n+  }\n+#endif\n+\n@@ -3689,1 +3697,1 @@\n-  MetaspaceShared::dump_loaded_classes(file_name, THREAD);\n+  AOTMetaspace::dump_loaded_classes(file_name, THREAD);\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -1031,0 +1031,5 @@\n+  \/\/ We must copy bytecodes only from linked classes.\n+  \/\/ Being linked guarantees we are not getting bytecodes at\n+  \/\/ the same time the linking process is rewriting them.\n+  guarantee(mh->method_holder()->is_linked(), \"Bytecodes must be copied from a linked class\");\n+\n","filename":"src\/hotspot\/share\/prims\/jvmtiClassFileReconstituter.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -453,0 +453,12 @@\n+      \/\/ Link the class to avoid races with the rewriter. This will call the verifier also\n+      \/\/ on the class. Linking is also done in VM_RedefineClasses below, but we need\n+      \/\/ to keep that for other VM_RedefineClasses callers.\n+      JavaThread* THREAD = current_thread;\n+      ik->link_class(THREAD);\n+      if (HAS_PENDING_EXCEPTION) {\n+        \/\/ Retransform\/JVMTI swallows error messages. Using this class will rerun the verifier in a context\n+        \/\/ that propagates the VerifyError, if thrown.\n+        CLEAR_PENDING_EXCEPTION;\n+        return JVMTI_ERROR_INVALID_CLASS;\n+      }\n+\n@@ -1370,5 +1382,0 @@\n-  if (LockingMode == LM_LEGACY && java_thread == nullptr) {\n-    *owned_monitor_count_ptr = 0;\n-    return JVMTI_ERROR_NONE;\n-  }\n-\n@@ -1430,5 +1437,0 @@\n-  if (LockingMode == LM_LEGACY && java_thread == nullptr) {\n-    *monitor_info_count_ptr = 0;\n-    return JVMTI_ERROR_NONE;\n-  }\n-\n@@ -3421,1 +3423,2 @@\n-  methodHandle mh(Thread::current(), method);\n+  JavaThread* current_thread = JavaThread::current();\n+  methodHandle mh(current_thread, method);\n@@ -3430,0 +3433,7 @@\n+  \/\/ Make sure the class is verified and rewritten first.\n+  JavaThread* THREAD = current_thread;\n+  mh->method_holder()->link_class(THREAD);\n+  if (HAS_PENDING_EXCEPTION) {\n+    CLEAR_PENDING_EXCEPTION;\n+    return JVMTI_ERROR_INVALID_CLASS;\n+  }\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnv.cpp","additions":21,"deletions":11,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -26,1 +27,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -257,1 +257,1 @@\n-    if (!MetaspaceShared::remap_shared_readonly_as_readwrite()) {\n+    if (!AOTMetaspace::remap_shared_readonly_as_readwrite()) {\n","filename":"src\/hotspot\/share\/prims\/jvmtiRedefineClasses.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -30,1 +31,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -49,0 +49,1 @@\n+#include \"jfr\/periodic\/sampling\/jfrCPUTimeThreadSampler.hpp\"\n@@ -1891,1 +1892,1 @@\n-WB_ENTRY(jlong, WB_MetaspaceSharedRegionAlignment(JNIEnv* env, jobject wb))\n+WB_ENTRY(jlong, WB_AOTMetaspaceRegionAlignment(JNIEnv* env, jobject wb))\n@@ -1893,1 +1894,1 @@\n-  return (jlong)MetaspaceShared::core_region_alignment();\n+  return (jlong)AOTMetaspace::core_region_alignment();\n@@ -2264,1 +2265,1 @@\n-  return (jboolean)MetaspaceShared::in_aot_cache(java_lang_Class::as_Klass(JNIHandles::resolve_non_null(clazz)));\n+  return (jboolean)AOTMetaspace::in_aot_cache(java_lang_Class::as_Klass(JNIHandles::resolve_non_null(clazz)));\n@@ -2770,0 +2771,26 @@\n+WB_ENTRY(void, WB_BusyWait(JNIEnv* env, jobject wb, jint time))\n+  ThreadToNativeFromVM  ttn(thread);\n+  u8 start = os::current_thread_cpu_time();\n+  u8 target_duration = time * (u8)1000000;\n+  while (os::current_thread_cpu_time() - start < target_duration) {\n+    for (volatile int i = 0; i < 1000000; i++);\n+  }\n+WB_END\n+\n+WB_ENTRY(jboolean, WB_CPUSamplerSetOutOfStackWalking(JNIEnv* env, jobject wb, jboolean enable))\n+  #if defined(ASSERT) && INCLUDE_JFR && defined(LINUX)\n+    JfrCPUTimeThreadSampling::set_out_of_stack_walking_enabled(enable == JNI_TRUE);\n+    return JNI_TRUE;\n+  #else\n+    return JNI_FALSE;\n+  #endif\n+WB_END\n+\n+WB_ENTRY(jlong, WB_CPUSamplerOutOfStackWalkingIterations(JNIEnv* env, jobject wb))\n+  #if defined(ASSERT) && INCLUDE_JFR && defined(LINUX)\n+    return (jlong)JfrCPUTimeThreadSampling::out_of_stack_walking_iterations();\n+  #else\n+    return 0;\n+  #endif\n+WB_END\n+\n@@ -2997,1 +3024,1 @@\n-  {CC\"metaspaceSharedRegionAlignment\", CC\"()J\",       (void*)&WB_MetaspaceSharedRegionAlignment },\n+  {CC\"metaspaceSharedRegionAlignment\", CC\"()J\",       (void*)&WB_AOTMetaspaceRegionAlignment },\n@@ -3129,0 +3156,3 @@\n+  {CC\"busyWait\", CC\"(I)V\",                            (void*)&WB_BusyWait},\n+  {CC\"cpuSamplerSetOutOfStackWalking\", CC\"(Z)Z\",      (void*)&WB_CPUSamplerSetOutOfStackWalking},\n+  {CC\"cpuSamplerOutOfStackWalkingIterations\", CC\"()J\",(void*)&WB_CPUSamplerOutOfStackWalkingIterations},\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":35,"deletions":5,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -584,0 +584,1 @@\n+  { \"HeapMaximumCompactionInterval\",JDK_Version::undefined(), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n@@ -1869,18 +1870,0 @@\n-  if (UseObjectMonitorTable && LockingMode != LM_LIGHTWEIGHT) {\n-    \/\/ ObjectMonitorTable requires lightweight locking.\n-    FLAG_SET_CMDLINE(UseObjectMonitorTable, false);\n-    warning(\"UseObjectMonitorTable requires LM_LIGHTWEIGHT\");\n-  }\n-\n-#if !defined(X86) && !defined(AARCH64) && !defined(PPC64) && !defined(RISCV64) && !defined(S390)\n-  if (LockingMode == LM_MONITOR) {\n-    jio_fprintf(defaultStream::error_stream(),\n-                \"LockingMode == 0 (LM_MONITOR) is not fully implemented on this architecture\\n\");\n-    return false;\n-  }\n-#endif\n-  if (VerifyHeavyMonitors && LockingMode != LM_MONITOR) {\n-    jio_fprintf(defaultStream::error_stream(),\n-                \"-XX:+VerifyHeavyMonitors requires LockingMode == 0 (LM_MONITOR)\\n\");\n-    return false;\n-  }\n@@ -2494,1 +2477,1 @@\n-      int maxf = (int)(strtod(tail, &err) * 100);\n+      double dmaxf = strtod(tail, &err);\n@@ -2497,1 +2480,7 @@\n-                    \"Bad max heap free percentage size: %s\\n\",\n+                    \"Bad max heap free ratio: %s\\n\",\n+                    option->optionString);\n+        return JNI_EINVAL;\n+      }\n+      if (dmaxf < 0.0 || dmaxf > 1.0) {\n+        jio_fprintf(defaultStream::error_stream(),\n+                    \"-Xmaxf value (%s) is outside the allowed range [ 0.0 ... 1.0 ]\\n\",\n@@ -2500,4 +2489,10 @@\n-      } else {\n-        if (FLAG_SET_CMDLINE(MaxHeapFreeRatio, maxf) != JVMFlag::SUCCESS) {\n-            return JNI_EINVAL;\n-        }\n+      }\n+      const uintx umaxf = (uintx)(dmaxf * 100);\n+      if (MinHeapFreeRatio > umaxf) {\n+        jio_fprintf(defaultStream::error_stream(),\n+                    \"-Xmaxf value (%s) must be greater than or equal to the implicit -Xminf value (%.2f)\\n\",\n+                    tail, MinHeapFreeRatio \/ 100.0f);\n+        return JNI_EINVAL;\n+      }\n+      if (FLAG_SET_CMDLINE(MaxHeapFreeRatio, umaxf) != JVMFlag::SUCCESS) {\n+        return JNI_EINVAL;\n@@ -2508,1 +2503,1 @@\n-      int minf = (int)(strtod(tail, &err) * 100);\n+      double dminf = strtod(tail, &err);\n@@ -2511,1 +2506,1 @@\n-                    \"Bad min heap free percentage size: %s\\n\",\n+                    \"Bad min heap free ratio: %s\\n\",\n@@ -2514,4 +2509,16 @@\n-      } else {\n-        if (FLAG_SET_CMDLINE(MinHeapFreeRatio, minf) != JVMFlag::SUCCESS) {\n-          return JNI_EINVAL;\n-        }\n+      }\n+      if (dminf < 0.0 || dminf > 1.0) {\n+        jio_fprintf(defaultStream::error_stream(),\n+                    \"-Xminf value (%s) is outside the allowed range [ 0.0 ... 1.0 ]\\n\",\n+                    tail);\n+        return JNI_EINVAL;\n+      }\n+      const uintx uminf = (uintx)(dminf * 100);\n+      if (MaxHeapFreeRatio < uminf) {\n+        jio_fprintf(defaultStream::error_stream(),\n+                    \"-Xminf value (%s) must be less than or equal to the implicit -Xmaxf value (%.2f)\\n\",\n+                    tail, MaxHeapFreeRatio \/ 100.0f);\n+        return JNI_EINVAL;\n+      }\n+      if (FLAG_SET_CMDLINE(MinHeapFreeRatio, uminf) != JVMFlag::SUCCESS) {\n+        return JNI_EINVAL;\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":37,"deletions":30,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -149,4 +149,0 @@\n-  if (LockingMode == LM_LEGACY) {\n-    return freeze_unsupported;\n-  }\n-\n","filename":"src\/hotspot\/share\/runtime\/continuation.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -536,5 +536,1 @@\n-  if (LockingMode != LM_LIGHTWEIGHT) {\n-    _monitors_in_lockstack = 0;\n-  } else {\n-    _monitors_in_lockstack = _thread->lock_stack().monitor_count();\n-  }\n+  _monitors_in_lockstack = _thread->lock_stack().monitor_count();\n@@ -590,20 +586,0 @@\n-#ifdef ASSERT\n-static bool monitors_on_stack(JavaThread* thread) {\n-  assert_frames_in_continuation_are_safe(thread);\n-  ContinuationEntry* ce = thread->last_continuation();\n-  RegisterMap map(thread,\n-                  RegisterMap::UpdateMap::include,\n-                  RegisterMap::ProcessFrames::skip,\n-                  RegisterMap::WalkContinuation::skip);\n-  map.set_include_argument_oops(false);\n-  for (frame f = thread->last_frame(); Continuation::is_frame_in_continuation(ce, f); f = f.sender(&map)) {\n-    if ((f.is_interpreted_frame() && ContinuationHelper::InterpretedFrame::is_owning_locks(f)) ||\n-        (f.is_compiled_frame() && ContinuationHelper::CompiledFrame::is_owning_locks(map.thread(), &map, f)) ||\n-        (f.is_native_frame() && ContinuationHelper::NativeFrame::is_owning_locks(map.thread(), f))) {\n-      return true;\n-    }\n-  }\n-  return false;\n-}\n-#endif \/\/ ASSERT\n-\n@@ -616,1 +592,0 @@\n-  assert(LockingMode != LM_LEGACY || !monitors_on_stack(_thread), \"unexpected monitors on stack\");\n@@ -1788,2 +1763,2 @@\n-  assert(LockingMode == LM_LEGACY || (current->held_monitor_count() == 0 && current->jni_monitor_count() == 0),\n-         \"Held monitor count should only be used for LM_LEGACY: \" INT64_FORMAT \" JNI: \" INT64_FORMAT, (int64_t)current->held_monitor_count(), (int64_t)current->jni_monitor_count());\n+  assert((current->held_monitor_count() == 0 && current->jni_monitor_count() == 0),\n+         \"Held monitor count should not be used for lightweight locking: \" INT64_FORMAT \" JNI: \" INT64_FORMAT, (int64_t)current->held_monitor_count(), (int64_t)current->jni_monitor_count());\n","filename":"src\/hotspot\/share\/runtime\/continuationFreezeThaw.cpp","additions":3,"deletions":28,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -1768,7 +1768,0 @@\n-          if (LockingMode == LM_LEGACY && mark.has_locker() && fr.sp() > (intptr_t*)mark.locker()) {\n-            \/\/ With exec_mode == Unpack_none obj may be thread local and locked in\n-            \/\/ a callee frame. Make the lock in the callee a recursive lock and restore the displaced header.\n-            markWord dmw = mark.displaced_mark_helper();\n-            mark.locker()->set_displaced_header(markWord::encode((BasicLock*) nullptr));\n-            obj->set_mark(dmw);\n-          }\n@@ -1780,3 +1773,1 @@\n-              if (LockingMode == LM_LEGACY) {\n-                mon_info->lock()->set_displaced_header(markWord::unused_mark());\n-              } else if (UseObjectMonitorTable) {\n+              if (UseObjectMonitorTable) {\n@@ -1787,1 +1778,1 @@\n-                assert(LockingMode == LM_MONITOR || !UseObjectMonitorTable, \"must be\");\n+                assert(!UseObjectMonitorTable, \"must be\");\n@@ -1797,12 +1788,11 @@\n-        if (LockingMode == LM_LIGHTWEIGHT) {\n-          \/\/ We have lost information about the correct state of the lock stack.\n-          \/\/ Entering may create an invalid lock stack. Inflate the lock if it\n-          \/\/ was fast_locked to restore the valid lock stack.\n-          if (UseObjectMonitorTable) {\n-            \/\/ UseObjectMonitorTable expects the BasicLock cache to be either a\n-            \/\/ valid ObjectMonitor* or nullptr. Right now it is garbage, set it\n-            \/\/ to nullptr.\n-            lock->clear_object_monitor_cache();\n-          }\n-          ObjectSynchronizer::enter_for(obj, lock, deoptee_thread);\n-          if (deoptee_thread->lock_stack().contains(obj())) {\n+        \/\/ We have lost information about the correct state of the lock stack.\n+        \/\/ Entering may create an invalid lock stack. Inflate the lock if it\n+        \/\/ was fast_locked to restore the valid lock stack.\n+        if (UseObjectMonitorTable) {\n+          \/\/ UseObjectMonitorTable expects the BasicLock cache to be either a\n+          \/\/ valid ObjectMonitor* or nullptr. Right now it is garbage, set it\n+          \/\/ to nullptr.\n+          lock->clear_object_monitor_cache();\n+        }\n+        ObjectSynchronizer::enter_for(obj, lock, deoptee_thread);\n+        if (deoptee_thread->lock_stack().contains(obj())) {\n@@ -1810,9 +1800,1 @@\n-                                                                deoptee_thread, thread);\n-          }\n-          assert(mon_info->owner()->is_locked(), \"object must be locked now\");\n-          assert(obj->mark().has_monitor(), \"must be\");\n-          assert(!deoptee_thread->lock_stack().contains(obj()), \"must be\");\n-          assert(ObjectSynchronizer::read_monitor(thread, obj(), obj->mark())->has_owner(deoptee_thread), \"must be\");\n-        } else {\n-          ObjectSynchronizer::enter_for(obj, lock, deoptee_thread);\n-          assert(mon_info->owner()->is_locked(), \"object must be locked now\");\n+                                                              deoptee_thread, thread);\n@@ -1820,0 +1802,4 @@\n+        assert(mon_info->owner()->is_locked(), \"object must be locked now\");\n+        assert(obj->mark().has_monitor(), \"must be\");\n+        assert(!deoptee_thread->lock_stack().contains(obj()), \"must be\");\n+        assert(ObjectSynchronizer::read_monitor(thread, obj(), obj->mark())->has_owner(deoptee_thread), \"must be\");\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":18,"deletions":32,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -1078,4 +1078,0 @@\n-  develop(bool, VerifyHeavyMonitors, false,                                 \\\n-          \"Checks that no stack locking happens when using \"                \\\n-          \"-XX:LockingMode=0 (LM_MONITOR)\")                                 \\\n-                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -571,1 +571,1 @@\n-      guarantee(oopDesc::is_oop_or_null(vv, true),\n+      guarantee(oopDesc::is_oop_or_null(vv),\n","filename":"src\/hotspot\/share\/runtime\/javaCalls.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1067,5 +1067,0 @@\n-bool JavaThread::is_lock_owned(address adr) const {\n-  assert(LockingMode != LM_LIGHTWEIGHT, \"should not be called with new lightweight locking\");\n-  return is_in_full_stack(adr);\n-}\n-\n@@ -1441,3 +1436,2 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    lock_stack().oops_do(f);\n-  }\n+  \/\/ Due to lightweight locking\n+  lock_stack().oops_do(f);\n@@ -2003,16 +1997,3 @@\n-\n-  if (LockingMode != LM_LEGACY) {\n-    \/\/ Nothing to do. Just do some sanity check.\n-    assert(_held_monitor_count == 0, \"counter should not be used\");\n-    assert(_jni_monitor_count == 0, \"counter should not be used\");\n-    return;\n-  }\n-\n-  assert(_held_monitor_count >= 0, \"Must always be non-negative: %zd\", _held_monitor_count);\n-  _held_monitor_count += i;\n-  if (jni) {\n-    assert(_jni_monitor_count >= 0, \"Must always be non-negative: %zd\", _jni_monitor_count);\n-    _jni_monitor_count += i;\n-  }\n-  assert(_held_monitor_count >= _jni_monitor_count, \"Monitor count discrepancy detected - held count \"\n-         \"%zd is less than JNI count %zd\", _held_monitor_count, _jni_monitor_count);\n+  \/\/ Nothing to do. Just do some sanity check.\n+  assert(_held_monitor_count == 0, \"counter should not be used\");\n+  assert(_jni_monitor_count == 0, \"counter should not be used\");\n@@ -2026,20 +2007,3 @@\n-\n-  if (LockingMode != LM_LEGACY) {\n-    \/\/ Nothing to do. Just do some sanity check.\n-    assert(_held_monitor_count == 0, \"counter should not be used\");\n-    assert(_jni_monitor_count == 0, \"counter should not be used\");\n-    return;\n-  }\n-\n-  _held_monitor_count -= i;\n-  assert(_held_monitor_count >= 0, \"Must always be non-negative: %zd\", _held_monitor_count);\n-  if (jni) {\n-    _jni_monitor_count -= i;\n-    assert(_jni_monitor_count >= 0, \"Must always be non-negative: %zd\", _jni_monitor_count);\n-  }\n-  \/\/ When a thread is detaching with still owned JNI monitors, the logic that releases\n-  \/\/ the monitors doesn't know to set the \"jni\" flag and so the counts can get out of sync.\n-  \/\/ So we skip this assert if the thread is exiting. Once all monitors are unlocked the\n-  \/\/ JNI count is directly set to zero.\n-  assert(_held_monitor_count >= _jni_monitor_count || is_exiting(), \"Monitor count discrepancy detected - held count \"\n-         \"%zd is less than JNI count %zd\", _held_monitor_count, _jni_monitor_count);\n+  \/\/ Nothing to do. Just do some sanity check.\n+  assert(_held_monitor_count == 0, \"counter should not be used\");\n+  assert(_jni_monitor_count == 0, \"counter should not be used\");\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":8,"deletions":44,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -759,3 +759,0 @@\n-  \/\/ Stack-locking support (not for LM_LIGHTWEIGHT)\n-  bool is_lock_owned(address adr) const;\n-\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -3820,12 +3820,1 @@\n-      if (LockingMode == LM_LEGACY) {\n-        \/\/ Inflate so the object's header no longer refers to the BasicLock.\n-        if (lock->displaced_header().is_unlocked()) {\n-          \/\/ The object is locked and the resulting ObjectMonitor* will also be\n-          \/\/ locked so it can't be async deflated until ownership is dropped.\n-          \/\/ See the big comment in basicLock.cpp: BasicLock::move_to().\n-          ObjectSynchronizer::inflate_helper(kptr2->obj());\n-        }\n-        \/\/ Now the displaced header is free to move because the\n-        \/\/ object's header no longer refers to it.\n-        buf[i] = (intptr_t)lock->displaced_header().value();\n-      } else if (UseObjectMonitorTable) {\n+      if (UseObjectMonitorTable) {\n@@ -3994,2 +3983,0 @@\n-        \/\/ scope_desc_near() must be used, instead of scope_desc_at() because on\n-        \/\/ SPARC, the pcDesc can be on the delay slot after the call instruction.\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":1,"deletions":14,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -284,3 +284,1 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    LightweightSynchronizer::initialize();\n-  }\n+  LightweightSynchronizer::initialize();\n@@ -362,12 +360,4 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    if (mark.is_fast_locked() && current->lock_stack().contains(cast_to_oop(obj))) {\n-      \/\/ Degenerate notify\n-      \/\/ fast-locked by caller so by definition the implied waitset is empty.\n-      return true;\n-    }\n-  } else if (LockingMode == LM_LEGACY) {\n-    if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n-      \/\/ Degenerate notify\n-      \/\/ stack-locked by caller so by definition the implied waitset is empty.\n-      return true;\n-    }\n+  if (mark.is_fast_locked() && current->lock_stack().contains(cast_to_oop(obj))) {\n+    \/\/ Degenerate notify\n+    \/\/ fast-locked by caller so by definition the implied waitset is empty.\n+    return true;\n@@ -378,1 +368,1 @@\n-    if (LockingMode == LM_LIGHTWEIGHT && mon == nullptr) {\n+    if (mon == nullptr) {\n@@ -401,74 +391,0 @@\n-static bool useHeavyMonitors() {\n-#if defined(X86) || defined(AARCH64) || defined(PPC64) || defined(RISCV64) || defined(S390)\n-  return LockingMode == LM_MONITOR;\n-#else\n-  return false;\n-#endif\n-}\n-\n-\/\/ The LockNode emitted directly at the synchronization site would have\n-\/\/ been too big if it were to have included support for the cases of inflated\n-\/\/ recursive enter and exit, so they go here instead.\n-\/\/ Note that we can't safely call AsyncPrintJavaStack() from within\n-\/\/ quick_enter() as our thread state remains _in_Java.\n-\n-bool ObjectSynchronizer::quick_enter_legacy(oop obj, BasicLock* lock, JavaThread* current) {\n-  assert(current->thread_state() == _thread_in_Java, \"invariant\");\n-  assert(!EnableValhalla || !obj->klass()->is_inline_klass(), \"monitor op on inline type\");\n-\n-  if (useHeavyMonitors()) {\n-    return false;  \/\/ Slow path\n-  }\n-\n-  assert(LockingMode == LM_LEGACY, \"legacy mode below\");\n-\n-  const markWord mark = obj->mark();\n-\n-  if (mark.has_monitor()) {\n-\n-    ObjectMonitor* const m = read_monitor(mark);\n-    \/\/ An async deflation or GC can race us before we manage to make\n-    \/\/ the ObjectMonitor busy by setting the owner below. If we detect\n-    \/\/ that race we just bail out to the slow-path here.\n-    if (m->object_peek() == nullptr) {\n-      return false;\n-    }\n-\n-    \/\/ Lock contention and Transactional Lock Elision (TLE) diagnostics\n-    \/\/ and observability\n-    \/\/ Case: light contention possibly amenable to TLE\n-    \/\/ Case: TLE inimical operations such as nested\/recursive synchronization\n-\n-    if (m->has_owner(current)) {\n-      m->increment_recursions(current);\n-      current->inc_held_monitor_count();\n-      return true;\n-    }\n-\n-    \/\/ This Java Monitor is inflated so obj's header will never be\n-    \/\/ displaced to this thread's BasicLock. Make the displaced header\n-    \/\/ non-null so this BasicLock is not seen as recursive nor as\n-    \/\/ being locked. We do this unconditionally so that this thread's\n-    \/\/ BasicLock cannot be mis-interpreted by any stack walkers. For\n-    \/\/ performance reasons, stack walkers generally first check for\n-    \/\/ stack-locking in the object's header, the second check is for\n-    \/\/ recursive stack-locking in the displaced header in the BasicLock,\n-    \/\/ and last are the inflated Java Monitor (ObjectMonitor) checks.\n-    lock->set_displaced_header(markWord::unused_mark());\n-\n-    if (!m->has_owner() && m->try_set_owner(current)) {\n-      assert(m->recursions() == 0, \"invariant\");\n-      current->inc_held_monitor_count();\n-      return true;\n-    }\n-  }\n-\n-  \/\/ Note that we could inflate in quick_enter.\n-  \/\/ This is likely a useful optimization\n-  \/\/ Critically, in quick_enter() we must not:\n-  \/\/ -- block indefinitely, or\n-  \/\/ -- reach a safepoint\n-\n-  return false;        \/\/ revert to slow-path\n-}\n-\n@@ -534,143 +450,1 @@\n-\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    return LightweightSynchronizer::enter_for(obj, lock, locking_thread);\n-  }\n-\n-  if (!enter_fast_impl(obj, lock, locking_thread)) {\n-    \/\/ Inflated ObjectMonitor::enter_for is required\n-\n-    \/\/ An async deflation can race after the inflate_for() call and before\n-    \/\/ enter_for() can make the ObjectMonitor busy. enter_for() returns false\n-    \/\/ if we have lost the race to async deflation and we simply try again.\n-    while (true) {\n-      ObjectMonitor* monitor = inflate_for(locking_thread, obj(), inflate_cause_monitor_enter);\n-      if (monitor->enter_for(locking_thread)) {\n-        return;\n-      }\n-      assert(monitor->is_being_async_deflated(), \"must be\");\n-    }\n-  }\n-}\n-\n-void ObjectSynchronizer::enter_legacy(Handle obj, BasicLock* lock, JavaThread* current) {\n-  assert(!EnableValhalla || !obj->klass()->is_inline_klass(), \"This method should never be called on an instance of an inline class\");\n-  if (!enter_fast_impl(obj, lock, current)) {\n-    \/\/ Inflated ObjectMonitor::enter is required\n-\n-    \/\/ An async deflation can race after the inflate() call and before\n-    \/\/ enter() can make the ObjectMonitor busy. enter() returns false if\n-    \/\/ we have lost the race to async deflation and we simply try again.\n-    while (true) {\n-      ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_monitor_enter);\n-      if (monitor->enter(current)) {\n-        return;\n-      }\n-    }\n-  }\n-}\n-\n-\/\/ The interpreter and compiler assembly code tries to lock using the fast path\n-\/\/ of this algorithm. Make sure to update that code if the following function is\n-\/\/ changed. The implementation is extremely sensitive to race condition. Be careful.\n-bool ObjectSynchronizer::enter_fast_impl(Handle obj, BasicLock* lock, JavaThread* locking_thread) {\n-  guarantee(!EnableValhalla || !obj->klass()->is_inline_klass(), \"Attempt to inflate inline type\");\n-  assert(LockingMode != LM_LIGHTWEIGHT, \"Use LightweightSynchronizer\");\n-\n-  if (obj->klass()->is_value_based()) {\n-    handle_sync_on_value_based_class(obj, locking_thread);\n-  }\n-\n-  locking_thread->inc_held_monitor_count();\n-\n-  if (!useHeavyMonitors()) {\n-    if (LockingMode == LM_LEGACY) {\n-      markWord mark = obj->mark();\n-      if (mark.is_unlocked()) {\n-        \/\/ Anticipate successful CAS -- the ST of the displaced mark must\n-        \/\/ be visible <= the ST performed by the CAS.\n-        lock->set_displaced_header(mark);\n-        if (mark == obj()->cas_set_mark(markWord::from_pointer(lock), mark)) {\n-          return true;\n-        }\n-      } else if (mark.has_locker() &&\n-                 locking_thread->is_lock_owned((address) mark.locker())) {\n-        assert(lock != mark.locker(), \"must not re-lock the same lock\");\n-        assert(lock != (BasicLock*) obj->mark().value(), \"don't relock with same BasicLock\");\n-        lock->set_displaced_header(markWord::from_pointer(nullptr));\n-        return true;\n-      }\n-\n-      \/\/ The object header will never be displaced to this lock,\n-      \/\/ so it does not matter what the value is, except that it\n-      \/\/ must be non-zero to avoid looking like a re-entrant lock,\n-      \/\/ and must not look locked either.\n-      lock->set_displaced_header(markWord::unused_mark());\n-\n-      \/\/ Failed to fast lock.\n-      return false;\n-    }\n-  } else if (VerifyHeavyMonitors) {\n-    guarantee((obj->mark().value() & markWord::lock_mask_in_place) != markWord::locked_value, \"must not be lightweight\/stack-locked\");\n-  }\n-\n-  return false;\n-}\n-\n-void ObjectSynchronizer::exit_legacy(oop object, BasicLock* lock, JavaThread* current) {\n-  assert(LockingMode != LM_LIGHTWEIGHT, \"Use LightweightSynchronizer\");\n-\n-  if (!useHeavyMonitors()) {\n-    markWord mark = object->mark();\n-    if (EnableValhalla && mark.is_inline_type()) {\n-      return;\n-    }\n-    if (LockingMode == LM_LEGACY) {\n-      markWord dhw = lock->displaced_header();\n-      if (dhw.value() == 0) {\n-        \/\/ If the displaced header is null, then this exit matches up with\n-        \/\/ a recursive enter. No real work to do here except for diagnostics.\n-#ifndef PRODUCT\n-        if (mark != markWord::INFLATING()) {\n-          \/\/ Only do diagnostics if we are not racing an inflation. Simply\n-          \/\/ exiting a recursive enter of a Java Monitor that is being\n-          \/\/ inflated is safe; see the has_monitor() comment below.\n-          assert(!mark.is_unlocked(), \"invariant\");\n-          assert(!mark.has_locker() ||\n-                 current->is_lock_owned((address)mark.locker()), \"invariant\");\n-          if (mark.has_monitor()) {\n-            \/\/ The BasicLock's displaced_header is marked as a recursive\n-            \/\/ enter and we have an inflated Java Monitor (ObjectMonitor).\n-            \/\/ This is a special case where the Java Monitor was inflated\n-            \/\/ after this thread entered the stack-lock recursively. When a\n-            \/\/ Java Monitor is inflated, we cannot safely walk the Java\n-            \/\/ Monitor owner's stack and update the BasicLocks because a\n-            \/\/ Java Monitor can be asynchronously inflated by a thread that\n-            \/\/ does not own the Java Monitor.\n-            ObjectMonitor* m = read_monitor(mark);\n-            assert(m->object()->mark() == mark, \"invariant\");\n-            assert(m->is_entered(current), \"invariant\");\n-          }\n-        }\n-#endif\n-        return;\n-      }\n-\n-      if (mark == markWord::from_pointer(lock)) {\n-        \/\/ If the object is stack-locked by the current thread, try to\n-        \/\/ swing the displaced header from the BasicLock back to the mark.\n-        assert(dhw.is_neutral(), \"invariant\");\n-        if (object->cas_set_mark(dhw, mark) == mark) {\n-          return;\n-        }\n-      }\n-    }\n-  } else if (VerifyHeavyMonitors) {\n-    guarantee((object->mark().value() & markWord::lock_mask_in_place) != markWord::locked_value, \"must not be lightweight\/stack-locked\");\n-  }\n-\n-  \/\/ We have to take the slow-path of possible inflation and then exit.\n-  \/\/ The ObjectMonitor* can't be async deflated until ownership is\n-  \/\/ dropped inside exit() and the ObjectMonitor* must be !is_busy().\n-  ObjectMonitor* monitor = inflate(current, object, inflate_cause_vm_internal);\n-  assert(!monitor->has_anonymous_owner(), \"must not be\");\n-  monitor->exit(current);\n+  return LightweightSynchronizer::enter_for(obj, lock, locking_thread);\n@@ -708,11 +482,2 @@\n-    ObjectMonitor* monitor;\n-    bool entered;\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n-      BasicLock lock;\n-      entered = LightweightSynchronizer::inflate_and_enter(obj(), &lock, inflate_cause_jni_enter, current, current) != nullptr;\n-    } else {\n-      monitor = inflate(current, obj(), inflate_cause_jni_enter);\n-      entered = monitor->enter(current);\n-    }\n-\n-    if (entered) {\n+    BasicLock lock;\n+    if (LightweightSynchronizer::inflate_and_enter(obj(), &lock, inflate_cause_jni_enter, current, current) != nullptr) {\n@@ -732,7 +497,1 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    monitor = LightweightSynchronizer::inflate_locked_or_imse(obj, inflate_cause_jni_exit, CHECK);\n-  } else {\n-    \/\/ The ObjectMonitor* can't be async deflated until ownership is\n-    \/\/ dropped inside exit() and the ObjectMonitor* must be !is_busy().\n-    monitor = inflate(current, obj, inflate_cause_jni_exit);\n-  }\n+  monitor = LightweightSynchronizer::inflate_locked_or_imse(obj, inflate_cause_jni_exit, CHECK);\n@@ -780,8 +539,1 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    monitor = LightweightSynchronizer::inflate_locked_or_imse(obj(), inflate_cause_wait, CHECK_0);\n-  } else {\n-    \/\/ The ObjectMonitor* can't be async deflated because the _waiters\n-    \/\/ field is incremented before ownership is dropped and decremented\n-    \/\/ after ownership is regained.\n-    monitor = inflate(current, obj(), inflate_cause_wait);\n-  }\n+  monitor = LightweightSynchronizer::inflate_locked_or_imse(obj(), inflate_cause_wait, CHECK_0);\n@@ -806,5 +558,1 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    monitor = LightweightSynchronizer::inflate_locked_or_imse(obj(), inflate_cause_wait, CHECK);\n-  } else {\n-    monitor = inflate(THREAD, obj(), inflate_cause_wait);\n-  }\n+  monitor = LightweightSynchronizer::inflate_locked_or_imse(obj(), inflate_cause_wait, CHECK);\n@@ -820,19 +568,3 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    if ((mark.is_fast_locked() && current->lock_stack().contains(obj()))) {\n-      \/\/ Not inflated so there can't be any waiters to notify.\n-      return;\n-    }\n-  } else if (LockingMode == LM_LEGACY) {\n-    if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n-      \/\/ Not inflated so there can't be any waiters to notify.\n-      return;\n-    }\n-  }\n-\n-  ObjectMonitor* monitor;\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    monitor = LightweightSynchronizer::inflate_locked_or_imse(obj(), inflate_cause_notify, CHECK);\n-  } else {\n-    \/\/ The ObjectMonitor* can't be async deflated until ownership is\n-    \/\/ dropped by the calling thread.\n-    monitor = inflate(current, obj(), inflate_cause_notify);\n+  if ((mark.is_fast_locked() && current->lock_stack().contains(obj()))) {\n+    \/\/ Not inflated so there can't be any waiters to notify.\n+    return;\n@@ -840,0 +572,1 @@\n+  ObjectMonitor* monitor = LightweightSynchronizer::inflate_locked_or_imse(obj(), inflate_cause_notify, CHECK);\n@@ -849,10 +582,3 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    if ((mark.is_fast_locked() && current->lock_stack().contains(obj()))) {\n-      \/\/ Not inflated so there can't be any waiters to notify.\n-      return;\n-    }\n-  } else if (LockingMode == LM_LEGACY) {\n-    if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n-      \/\/ Not inflated so there can't be any waiters to notify.\n-      return;\n-    }\n+  if ((mark.is_fast_locked() && current->lock_stack().contains(obj()))) {\n+    \/\/ Not inflated so there can't be any waiters to notify.\n+    return;\n@@ -861,8 +587,1 @@\n-  ObjectMonitor* monitor;\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    monitor = LightweightSynchronizer::inflate_locked_or_imse(obj(), inflate_cause_notify, CHECK);\n-  } else {\n-    \/\/ The ObjectMonitor* can't be async deflated until ownership is\n-    \/\/ dropped by the calling thread.\n-    monitor = inflate(current, obj(), inflate_cause_notify);\n-  }\n+  ObjectMonitor* monitor = LightweightSynchronizer::inflate_locked_or_imse(obj(), inflate_cause_notify, CHECK);\n@@ -888,61 +607,0 @@\n-static markWord read_stable_mark(oop obj) {\n-  markWord mark = obj->mark_acquire();\n-  if (!mark.is_being_inflated() || LockingMode == LM_LIGHTWEIGHT) {\n-    \/\/ New lightweight locking does not use the markWord::INFLATING() protocol.\n-    return mark;       \/\/ normal fast-path return\n-  }\n-\n-  int its = 0;\n-  for (;;) {\n-    markWord mark = obj->mark_acquire();\n-    if (!mark.is_being_inflated()) {\n-      return mark;    \/\/ normal fast-path return\n-    }\n-\n-    \/\/ The object is being inflated by some other thread.\n-    \/\/ The caller of read_stable_mark() must wait for inflation to complete.\n-    \/\/ Avoid live-lock.\n-\n-    ++its;\n-    if (its > 10000 || !os::is_MP()) {\n-      if (its & 1) {\n-        os::naked_yield();\n-      } else {\n-        \/\/ Note that the following code attenuates the livelock problem but is not\n-        \/\/ a complete remedy.  A more complete solution would require that the inflating\n-        \/\/ thread hold the associated inflation lock.  The following code simply restricts\n-        \/\/ the number of spinners to at most one.  We'll have N-2 threads blocked\n-        \/\/ on the inflationlock, 1 thread holding the inflation lock and using\n-        \/\/ a yield\/park strategy, and 1 thread in the midst of inflation.\n-        \/\/ A more refined approach would be to change the encoding of INFLATING\n-        \/\/ to allow encapsulation of a native thread pointer.  Threads waiting for\n-        \/\/ inflation to complete would use CAS to push themselves onto a singly linked\n-        \/\/ list rooted at the markword.  Once enqueued, they'd loop, checking a per-thread flag\n-        \/\/ and calling park().  When inflation was complete the thread that accomplished inflation\n-        \/\/ would detach the list and set the markword to inflated with a single CAS and\n-        \/\/ then for each thread on the list, set the flag and unpark() the thread.\n-\n-        \/\/ Index into the lock array based on the current object address.\n-        static_assert(is_power_of_2(inflation_lock_count()), \"must be\");\n-        size_t ix = (cast_from_oop<intptr_t>(obj) >> 5) & (inflation_lock_count() - 1);\n-        int YieldThenBlock = 0;\n-        assert(ix < inflation_lock_count(), \"invariant\");\n-        inflation_lock(ix)->lock();\n-        while (obj->mark_acquire() == markWord::INFLATING()) {\n-          \/\/ Beware: naked_yield() is advisory and has almost no effect on some platforms\n-          \/\/ so we periodically call current->_ParkEvent->park(1).\n-          \/\/ We use a mixed spin\/yield\/block mechanism.\n-          if ((YieldThenBlock++) >= 16) {\n-            Thread::current()->_ParkEvent->park(1);\n-          } else {\n-            os::naked_yield();\n-          }\n-        }\n-        inflation_lock(ix)->unlock();\n-      }\n-    } else {\n-      SpinPause();       \/\/ SMP-polite spinning\n-    }\n-  }\n-}\n-\n@@ -1007,1 +665,1 @@\n-  assert(UseObjectMonitorTable && LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+  assert(UseObjectMonitorTable, \"must be\");\n@@ -1042,6 +700,2 @@\n-    markWord mark = read_stable_mark(obj);\n-    if (VerifyHeavyMonitors) {\n-      assert(LockingMode == LM_MONITOR, \"+VerifyHeavyMonitors requires LockingMode == 0 (LM_MONITOR)\");\n-      guarantee((obj->mark().value() & markWord::lock_mask_in_place) != markWord::locked_value, \"must not be lightweight\/stack-locked\");\n-    }\n-    if (mark.is_unlocked() || (LockingMode == LM_LIGHTWEIGHT && mark.is_fast_locked())) {\n+    markWord mark = obj->mark_acquire();\n+    if (mark.is_unlocked() || mark.is_fast_locked()) {\n@@ -1059,4 +713,3 @@\n-      if (LockingMode == LM_LIGHTWEIGHT) {\n-        \/\/ CAS failed, retry\n-        continue;\n-      }\n+      \/\/ CAS failed, retry\n+      continue;\n+\n@@ -1094,19 +747,0 @@\n-    } else if (LockingMode == LM_LEGACY && mark.has_locker()\n-               && current->is_Java_thread()\n-               && JavaThread::cast(current)->is_lock_owned((address)mark.locker())) {\n-      \/\/ This is a stack-lock owned by the calling thread so fetch the\n-      \/\/ displaced markWord from the BasicLock on the stack.\n-      temp = mark.displaced_mark_helper();\n-      assert(temp.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, temp.value());\n-      hash = temp.hash();\n-      if (hash != 0) {                  \/\/ if it has a hash, just return it\n-        return hash;\n-      }\n-      \/\/ WARNING:\n-      \/\/ The displaced header in the BasicLock on a thread's stack\n-      \/\/ is strictly immutable. It CANNOT be changed in ANY cases.\n-      \/\/ So we have to inflate the stack-lock into an ObjectMonitor\n-      \/\/ even if the current thread owns the lock. The BasicLock on\n-      \/\/ a thread's stack can be asynchronously read by other threads\n-      \/\/ during an inflate() call so any change to that stack memory\n-      \/\/ may not propagate to other threads correctly.\n@@ -1115,3 +749,0 @@\n-    \/\/ Inflate the monitor to set the hash.\n-\n-    \/\/ There's no need to inflate if the mark has already got a monitor.\n@@ -1121,1 +752,3 @@\n-    monitor = mark.has_monitor() ? mark.monitor() : inflate(current, obj, inflate_cause_hash_code);\n+    assert(mark.has_monitor(), \"must be\");\n+    monitor = mark.monitor();\n+\n@@ -1164,6 +797,1 @@\n-  markWord mark = read_stable_mark(obj);\n-\n-  if (LockingMode == LM_LEGACY && mark.has_locker()) {\n-    \/\/ stack-locked case, header points into owner's stack\n-    return current->is_lock_owned((address)mark.locker());\n-  }\n+  markWord mark = obj->mark_acquire();\n@@ -1171,1 +799,1 @@\n-  if (LockingMode == LM_LIGHTWEIGHT && mark.is_fast_locked()) {\n+  if (mark.is_fast_locked()) {\n@@ -1176,1 +804,1 @@\n-  while (LockingMode == LM_LIGHTWEIGHT && mark.has_monitor()) {\n+  while (mark.has_monitor()) {\n@@ -1190,7 +818,0 @@\n-  if (LockingMode != LM_LIGHTWEIGHT && mark.has_monitor()) {\n-    \/\/ Inflated monitor so header points to ObjectMonitor (tagged pointer).\n-    \/\/ The first stage of async deflation does not affect any field\n-    \/\/ used by this comparison so the ObjectMonitor* is usable here.\n-    ObjectMonitor* monitor = read_monitor(mark);\n-    return monitor->is_entered(current) != 0;\n-  }\n@@ -1204,7 +825,1 @@\n-  markWord mark = read_stable_mark(obj);\n-\n-  if (LockingMode == LM_LEGACY && mark.has_locker()) {\n-    \/\/ stack-locked so header points into owner's stack.\n-    \/\/ owning_thread_from_monitor_owner() may also return null here:\n-    return Threads::owning_thread_from_stacklock(t_list, (address) mark.locker());\n-  }\n+  markWord mark = obj->mark_acquire();\n@@ -1212,1 +827,1 @@\n-  if (LockingMode == LM_LIGHTWEIGHT && mark.is_fast_locked()) {\n+  if (mark.is_fast_locked()) {\n@@ -1218,1 +833,1 @@\n-  while (LockingMode == LM_LIGHTWEIGHT && mark.has_monitor()) {\n+  while (mark.has_monitor()) {\n@@ -1232,10 +847,0 @@\n-  if (LockingMode != LM_LIGHTWEIGHT && mark.has_monitor()) {\n-    \/\/ Inflated monitor so header points to ObjectMonitor (tagged pointer).\n-    \/\/ The first stage of async deflation does not affect any field\n-    \/\/ used by this comparison so the ObjectMonitor* is usable here.\n-    ObjectMonitor* monitor = read_monitor(mark);\n-    assert(monitor != nullptr, \"monitor should be non-null\");\n-    \/\/ owning_thread_from_monitor() may also return null here:\n-    return Threads::owning_thread_from_monitor(t_list, monitor);\n-  }\n-\n@@ -1464,227 +1069,0 @@\n-static void post_monitor_inflate_event(EventJavaMonitorInflate* event,\n-                                       const oop obj,\n-                                       ObjectSynchronizer::InflateCause cause) {\n-  assert(event != nullptr, \"invariant\");\n-  const Klass* monitor_klass = obj->klass();\n-  if (ObjectMonitor::is_jfr_excluded(monitor_klass)) {\n-    return;\n-  }\n-  event->set_monitorClass(monitor_klass);\n-  event->set_address((uintptr_t)(void*)obj);\n-  event->set_cause((u1)cause);\n-  event->commit();\n-}\n-\n-\/\/ Fast path code shared by multiple functions\n-void ObjectSynchronizer::inflate_helper(oop obj) {\n-  assert(LockingMode != LM_LIGHTWEIGHT, \"only inflate through enter\");\n-  markWord mark = obj->mark_acquire();\n-  if (mark.has_monitor()) {\n-    ObjectMonitor* monitor = read_monitor(mark);\n-    markWord dmw = monitor->header();\n-    assert(dmw.is_neutral(), \"sanity check: header=\" INTPTR_FORMAT, dmw.value());\n-    return;\n-  }\n-  (void)inflate(Thread::current(), obj, inflate_cause_vm_internal);\n-}\n-\n-ObjectMonitor* ObjectSynchronizer::inflate(Thread* current, oop obj, const InflateCause cause) {\n-  assert(current == Thread::current(), \"must be\");\n-  assert(LockingMode != LM_LIGHTWEIGHT, \"only inflate through enter\");\n-  return inflate_impl(current->is_Java_thread() ? JavaThread::cast(current) : nullptr, obj, cause);\n-}\n-\n-ObjectMonitor* ObjectSynchronizer::inflate_for(JavaThread* thread, oop obj, const InflateCause cause) {\n-  assert(thread == Thread::current() || thread->is_obj_deopt_suspend(), \"must be\");\n-  assert(LockingMode != LM_LIGHTWEIGHT, \"LM_LIGHTWEIGHT cannot use inflate_for\");\n-  return inflate_impl(thread, obj, cause);\n-}\n-\n-ObjectMonitor* ObjectSynchronizer::inflate_impl(JavaThread* locking_thread, oop object, const InflateCause cause) {\n-  if (EnableValhalla) {\n-    guarantee(!object->klass()->is_inline_klass(), \"Attempt to inflate inline type\");\n-  }\n-  \/\/ The JavaThread* locking_thread requires that the locking_thread == Thread::current() or\n-  \/\/ is suspended throughout the call by some other mechanism.\n-  \/\/ The thread might be nullptr when called from a non JavaThread. (As may still be\n-  \/\/ the case from FastHashCode). However it is only important for correctness that the\n-  \/\/ thread is set when called from ObjectSynchronizer::enter from the owning thread,\n-  \/\/ ObjectSynchronizer::enter_for from any thread, or ObjectSynchronizer::exit.\n-  assert(LockingMode != LM_LIGHTWEIGHT, \"LM_LIGHTWEIGHT cannot use inflate_impl\");\n-  EventJavaMonitorInflate event;\n-\n-  for (;;) {\n-    const markWord mark = object->mark_acquire();\n-\n-    \/\/ The mark can be in one of the following states:\n-    \/\/ *  inflated     - If the ObjectMonitor owner is anonymous and the\n-    \/\/                   locking_thread owns the object lock, then we\n-    \/\/                   make the locking_thread the ObjectMonitor owner.\n-    \/\/ *  stack-locked - Coerce it to inflated from stack-locked.\n-    \/\/ *  INFLATING    - Busy wait for conversion from stack-locked to\n-    \/\/                   inflated.\n-    \/\/ *  unlocked     - Aggressively inflate the object.\n-\n-    \/\/ CASE: inflated\n-    if (mark.has_monitor()) {\n-      ObjectMonitor* inf = mark.monitor();\n-      markWord dmw = inf->header();\n-      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n-      if (inf->has_anonymous_owner() && locking_thread != nullptr) {\n-        assert(LockingMode == LM_LEGACY, \"invariant\");\n-        if (locking_thread->is_lock_owned((address)inf->stack_locker())) {\n-          inf->set_stack_locker(nullptr);\n-          inf->set_owner_from_anonymous(locking_thread);\n-        }\n-      }\n-      return inf;\n-    }\n-\n-    \/\/ CASE: inflation in progress - inflating over a stack-lock.\n-    \/\/ Some other thread is converting from stack-locked to inflated.\n-    \/\/ Only that thread can complete inflation -- other threads must wait.\n-    \/\/ The INFLATING value is transient.\n-    \/\/ Currently, we spin\/yield\/park and poll the markword, waiting for inflation to finish.\n-    \/\/ We could always eliminate polling by parking the thread on some auxiliary list.\n-    if (mark == markWord::INFLATING()) {\n-      read_stable_mark(object);\n-      continue;\n-    }\n-\n-    \/\/ CASE: stack-locked\n-    \/\/ Could be stack-locked either by current or by some other thread.\n-    \/\/\n-    \/\/ Note that we allocate the ObjectMonitor speculatively, _before_ attempting\n-    \/\/ to install INFLATING into the mark word.  We originally installed INFLATING,\n-    \/\/ allocated the ObjectMonitor, and then finally STed the address of the\n-    \/\/ ObjectMonitor into the mark.  This was correct, but artificially lengthened\n-    \/\/ the interval in which INFLATING appeared in the mark, thus increasing\n-    \/\/ the odds of inflation contention. If we lose the race to set INFLATING,\n-    \/\/ then we just delete the ObjectMonitor and loop around again.\n-    \/\/\n-    LogStreamHandle(Trace, monitorinflation) lsh;\n-    if (LockingMode == LM_LEGACY && mark.has_locker()) {\n-      ObjectMonitor* m = new ObjectMonitor(object);\n-      \/\/ Optimistically prepare the ObjectMonitor - anticipate successful CAS\n-      \/\/ We do this before the CAS in order to minimize the length of time\n-      \/\/ in which INFLATING appears in the mark.\n-\n-      markWord cmp = object->cas_set_mark(markWord::INFLATING(), mark);\n-      if (cmp != mark) {\n-        delete m;\n-        continue;       \/\/ Interference -- just retry\n-      }\n-\n-      \/\/ We've successfully installed INFLATING (0) into the mark-word.\n-      \/\/ This is the only case where 0 will appear in a mark-word.\n-      \/\/ Only the singular thread that successfully swings the mark-word\n-      \/\/ to 0 can perform (or more precisely, complete) inflation.\n-      \/\/\n-      \/\/ Why do we CAS a 0 into the mark-word instead of just CASing the\n-      \/\/ mark-word from the stack-locked value directly to the new inflated state?\n-      \/\/ Consider what happens when a thread unlocks a stack-locked object.\n-      \/\/ It attempts to use CAS to swing the displaced header value from the\n-      \/\/ on-stack BasicLock back into the object header.  Recall also that the\n-      \/\/ header value (hash code, etc) can reside in (a) the object header, or\n-      \/\/ (b) a displaced header associated with the stack-lock, or (c) a displaced\n-      \/\/ header in an ObjectMonitor.  The inflate() routine must copy the header\n-      \/\/ value from the BasicLock on the owner's stack to the ObjectMonitor, all\n-      \/\/ the while preserving the hashCode stability invariants.  If the owner\n-      \/\/ decides to release the lock while the value is 0, the unlock will fail\n-      \/\/ and control will eventually pass from slow_exit() to inflate.  The owner\n-      \/\/ will then spin, waiting for the 0 value to disappear.   Put another way,\n-      \/\/ the 0 causes the owner to stall if the owner happens to try to\n-      \/\/ drop the lock (restoring the header from the BasicLock to the object)\n-      \/\/ while inflation is in-progress.  This protocol avoids races that might\n-      \/\/ would otherwise permit hashCode values to change or \"flicker\" for an object.\n-      \/\/ Critically, while object->mark is 0 mark.displaced_mark_helper() is stable.\n-      \/\/ 0 serves as a \"BUSY\" inflate-in-progress indicator.\n-\n-\n-      \/\/ fetch the displaced mark from the owner's stack.\n-      \/\/ The owner can't die or unwind past the lock while our INFLATING\n-      \/\/ object is in the mark.  Furthermore the owner can't complete\n-      \/\/ an unlock on the object, either.\n-      markWord dmw = mark.displaced_mark_helper();\n-      \/\/ Catch if the object's header is not neutral (not locked and\n-      \/\/ not marked is what we care about here).\n-      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n-\n-      \/\/ Setup monitor fields to proper values -- prepare the monitor\n-      m->set_header(dmw);\n-\n-      \/\/ Note that a thread can inflate an object\n-      \/\/ that it has stack-locked -- as might happen in wait() -- directly\n-      \/\/ with CAS.  That is, we can avoid the xchg-nullptr .... ST idiom.\n-      if (locking_thread != nullptr && locking_thread->is_lock_owned((address)mark.locker())) {\n-        m->set_owner(locking_thread);\n-      } else {\n-        \/\/ Use ANONYMOUS_OWNER to indicate that the owner is the BasicLock on the stack,\n-        \/\/ and set the stack locker field in the monitor.\n-        m->set_stack_locker(mark.locker());\n-        m->set_anonymous_owner();\n-      }\n-      \/\/ TODO-FIXME: assert BasicLock->dhw != 0.\n-\n-      \/\/ Must preserve store ordering. The monitor state must\n-      \/\/ be stable at the time of publishing the monitor address.\n-      guarantee(object->mark() == markWord::INFLATING(), \"invariant\");\n-      \/\/ Release semantics so that above set_object() is seen first.\n-      object->release_set_mark(markWord::encode(m));\n-\n-      \/\/ Once ObjectMonitor is configured and the object is associated\n-      \/\/ with the ObjectMonitor, it is safe to allow async deflation:\n-      _in_use_list.add(m);\n-\n-      if (log_is_enabled(Trace, monitorinflation)) {\n-        ResourceMark rm;\n-        lsh.print_cr(\"inflate(has_locker): object=\" INTPTR_FORMAT \", mark=\"\n-                     INTPTR_FORMAT \", type='%s'\", p2i(object),\n-                     object->mark().value(), object->klass()->external_name());\n-      }\n-      if (event.should_commit()) {\n-        post_monitor_inflate_event(&event, object, cause);\n-      }\n-      return m;\n-    }\n-\n-    \/\/ CASE: unlocked\n-    \/\/ TODO-FIXME: for entry we currently inflate and then try to CAS _owner.\n-    \/\/ If we know we're inflating for entry it's better to inflate by swinging a\n-    \/\/ pre-locked ObjectMonitor pointer into the object header.   A successful\n-    \/\/ CAS inflates the object *and* confers ownership to the inflating thread.\n-    \/\/ In the current implementation we use a 2-step mechanism where we CAS()\n-    \/\/ to inflate and then CAS() again to try to swing _owner from null to current.\n-    \/\/ An inflateTry() method that we could call from enter() would be useful.\n-\n-    assert(mark.is_unlocked(), \"invariant: header=\" INTPTR_FORMAT, mark.value());\n-    ObjectMonitor* m = new ObjectMonitor(object);\n-    \/\/ prepare m for installation - set monitor to initial state\n-    m->set_header(mark);\n-\n-    if (object->cas_set_mark(markWord::encode(m), mark) != mark) {\n-      delete m;\n-      m = nullptr;\n-      continue;\n-      \/\/ interference - the markword changed - just retry.\n-      \/\/ The state-transitions are one-way, so there's no chance of\n-      \/\/ live-lock -- \"Inflated\" is an absorbing state.\n-    }\n-\n-    \/\/ Once the ObjectMonitor is configured and object is associated\n-    \/\/ with the ObjectMonitor, it is safe to allow async deflation:\n-    _in_use_list.add(m);\n-\n-    if (log_is_enabled(Trace, monitorinflation)) {\n-      ResourceMark rm;\n-      lsh.print_cr(\"inflate(unlocked): object=\" INTPTR_FORMAT \", mark=\"\n-                   INTPTR_FORMAT \", type='%s'\", p2i(object),\n-                   object->mark().value(), object->klass()->external_name());\n-    }\n-    if (event.should_commit()) {\n-      post_monitor_inflate_event(&event, object, cause);\n-    }\n-    return m;\n-  }\n-}\n-\n@@ -1966,1 +1344,0 @@\n-    case inflate_cause_hash_code:      return \"Monitor Hash Code\";\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":35,"deletions":658,"binary":false,"changes":693,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"cds\/aotMetaspace.hpp\"\n@@ -31,1 +32,0 @@\n-#include \"cds\/metaspaceShared.hpp\"\n@@ -893,1 +893,1 @@\n-    MetaspaceShared::preload_and_dump(CHECK_JNI_ERR);\n+    AOTMetaspace::preload_and_dump(CHECK_JNI_ERR);\n@@ -896,1 +896,1 @@\n-    MetaspaceShared::preload_and_dump(CHECK_JNI_ERR);\n+    AOTMetaspace::preload_and_dump(CHECK_JNI_ERR);\n@@ -1298,14 +1298,0 @@\n-JavaThread *Threads::owning_thread_from_stacklock(ThreadsList * t_list, address basicLock) {\n-  assert(LockingMode == LM_LEGACY, \"Not with new lightweight locking\");\n-\n-  JavaThread* the_owner = nullptr;\n-  for (JavaThread* q : *t_list) {\n-    if (q->is_lock_owned(basicLock)) {\n-      the_owner = q;\n-      break;\n-    }\n-  }\n-  return the_owner;\n-}\n-\n-  assert(LockingMode == LM_LIGHTWEIGHT, \"Only with new lightweight locking\");\n@@ -1329,6 +1315,1 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n-      return owning_thread_from_object(t_list, monitor->object());\n-    } else {\n-      assert(LockingMode == LM_LEGACY, \"invariant\");\n-      return owning_thread_from_stacklock(t_list, (address)monitor->stack_locker());\n-    }\n+    return owning_thread_from_object(t_list, monitor->object());\n","filename":"src\/hotspot\/share\/runtime\/threads.cpp","additions":4,"deletions":23,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -678,1 +678,0 @@\n-  volatile_nonstatic_field(ObjectMonitor,      _stack_locker,                                 BasicLock*)                            \\\n@@ -1648,8 +1647,0 @@\n-  \/**********************************************\/                        \\\n-  \/* LockingMode enum (globalDefinitions.hpp) *\/                          \\\n-  \/**********************************************\/                        \\\n-                                                                          \\\n-  declare_constant(LM_MONITOR)                                            \\\n-  declare_constant(LM_LEGACY)                                             \\\n-  declare_constant(LM_LIGHTWEIGHT)                                        \\\n-                                                                          \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":0,"deletions":9,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -59,2 +59,0 @@\n-const int LockingMode = LM_LIGHTWEIGHT;\n-\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1020,11 +1020,0 @@\n-enum LockingMode {\n-  \/\/ Use only heavy monitors for locking\n-  LM_MONITOR     = 0,\n-  \/\/ Legacy stack-locking, with monitors as 2nd tier\n-  LM_LEGACY      = 1,\n-  \/\/ New lightweight locking, with monitors as 2nd tier\n-  LM_LIGHTWEIGHT = 2\n-};\n-\n-extern const int LockingMode;\n-\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":0,"deletions":11,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -2143,0 +2143,1 @@\n+\n@@ -2151,2 +2152,2 @@\n-            public String uncheckedNewStringNoRepl(byte[] bytes, Charset cs) throws CharacterCodingException  {\n-                return String.newStringNoRepl(bytes, cs);\n+            public String uncheckedNewStringOrThrow(byte[] bytes, Charset cs) throws CharacterCodingException  {\n+                return String.newStringOrThrow(bytes, cs);\n@@ -2154,0 +2155,1 @@\n+\n@@ -2157,0 +2159,1 @@\n+\n@@ -2160,2 +2163,3 @@\n-            public byte[] uncheckedGetBytesNoRepl(String s, Charset cs) throws CharacterCodingException {\n-                return String.getBytesNoRepl(s, cs);\n+\n+            public byte[] uncheckedGetBytesOrThrow(String s, Charset cs) throws CharacterCodingException {\n+                return String.getBytesOrThrow(s, cs);\n@@ -2164,2 +2168,2 @@\n-            public byte[] getBytesUTF8NoRepl(String s) {\n-                return String.getBytesUTF8NoRepl(s);\n+            public byte[] getBytesUTF8OrThrow(String s) throws CharacterCodingException {\n+                return String.getBytesUTF8OrThrow(s);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/System.java","additions":10,"deletions":6,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+import jdk.internal.classfile.impl.StackMapGenerator;\n@@ -133,1 +134,1 @@\n-        int ITEM_TOP = 0;\n+        int ITEM_TOP = StackMapGenerator.ITEM_TOP;\n@@ -136,1 +137,1 @@\n-        int ITEM_INTEGER = 1;\n+        int ITEM_INTEGER = StackMapGenerator.ITEM_INTEGER;\n@@ -139,1 +140,1 @@\n-        int ITEM_FLOAT = 2;\n+        int ITEM_FLOAT = StackMapGenerator.ITEM_FLOAT;\n@@ -142,1 +143,1 @@\n-        int ITEM_DOUBLE = 3;\n+        int ITEM_DOUBLE = StackMapGenerator.ITEM_DOUBLE;\n@@ -145,1 +146,1 @@\n-        int ITEM_LONG = 4;\n+        int ITEM_LONG = StackMapGenerator.ITEM_LONG;\n@@ -148,1 +149,1 @@\n-        int ITEM_NULL = 5;\n+        int ITEM_NULL = StackMapGenerator.ITEM_NULL;\n@@ -151,1 +152,1 @@\n-        int ITEM_UNINITIALIZED_THIS = 6;\n+        int ITEM_UNINITIALIZED_THIS = StackMapGenerator.ITEM_UNINITIALIZED_THIS;\n@@ -154,1 +155,1 @@\n-        int ITEM_OBJECT = 7;\n+        int ITEM_OBJECT = StackMapGenerator.ITEM_OBJECT;\n@@ -157,1 +158,1 @@\n-        int ITEM_UNINITIALIZED = 8;\n+        int ITEM_UNINITIALIZED = StackMapGenerator.ITEM_UNINITIALIZED;\n","filename":"src\/java.base\/share\/classes\/java\/lang\/classfile\/attribute\/StackMapFrameInfo.java","additions":10,"deletions":9,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -1077,1 +1077,7 @@\n-    \/* Placeholder class for DirectMethodHandles generated ahead of time *\/\n+    \/\/\/ Holds pre-generated bytecode for lambda forms used by DirectMethodHandle.\n+    \/\/\/\n+    \/\/\/ This class may be substituted in the JDK's modules image, or in an AOT\n+    \/\/\/ cache, by a version generated by [GenerateJLIClassesHelper].\n+    \/\/\/\n+    \/\/\/ The method names of this class are internal tokens recognized by\n+    \/\/\/ [InvokerBytecodeGenerator#lookupPregenerated] and are subject to change.\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/DirectMethodHandle.java","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -51,5 +51,66 @@\n-\/**\n- * Helper class to assist the GenerateJLIClassesPlugin to get access to\n- * generate classes ahead of time.\n- *\/\n-class GenerateJLIClassesHelper {\n+\/\/\/ Generates bound method handle species classes, and classes with methods that\n+\/\/\/ hold compiled lambda form bytecode ahead of time, so certain lambda forms\n+\/\/\/ no longer need to spin classes because they can find existing bytecode.\n+\/\/\/ Bytecode pre-generation reduces static initialization costs, footprint costs,\n+\/\/\/ and circular dependencies that may arise if a class is generated per\n+\/\/\/ LambdaForm by [InvokerBytecodeGenerator].\n+\/\/\/\n+\/\/\/ Since lambda forms and bound method handle species are closely tied to\n+\/\/\/ method types, which have many varieties, this generator needs *traces* to\n+\/\/\/ detect which method types are used, so generation matches the actual usage.\n+\/\/\/ See the main entrypoint [#generateHolderClasses(Stream)] for more details\n+\/\/\/ about *traces*.\n+\/\/\/\n+\/\/\/ Note this pregeneration does not cover all lambda forms that can be created.\n+\/\/\/ For example, forms created by [LambdaFormEditor] are not captured.\n+\/\/\/\n+\/\/\/ Pregenerated species classes are resolved in [ClassSpecializer.Factory#loadSpecies]\n+\/\/\/ and behave identically to on-demand generated ones.  Pregenerated lambda\n+\/\/\/ forms are resolved in [InvokerBytecodeGenerator#lookupPregenerated], which\n+\/\/\/ looks up methods for code from the following 4 possibly-generated classes:\n+\/\/\/  -  [Invokers.Holder]\n+\/\/\/  -  [DirectMethodHandle.Holder]\n+\/\/\/  -  [DelegatingMethodHandle.Holder]\n+\/\/\/  -  [LambdaForm.Holder]\n+\/\/\/\n+\/\/\/ [VarHandle] linker forms, analogous to invoker forms in [Invokers.Holder],\n+\/\/\/ have a similar pre-generation system except it is done at source generation;\n+\/\/\/ they reside in [VarHandleGuards].\n+\/\/\/\n+\/\/\/ ## Usages of this generator\n+\/\/\/ Currently, `GenerateJLIClassesHelper` is invoked when creating a modular JDK\n+\/\/\/ image or generating an AOT cache.\n+\/\/\/\n+\/\/\/ #### Modular Image\n+\/\/\/ When creating a modular JDK image,\n+\/\/\/ `jdk.tools.jlink.internal.plugins.GenerateJLIClassesPlugin` passes the\n+\/\/\/ *traces* in the file `jdk\/tools\/jlink\/internal\/plugins\/default_jli_trace.txt`\n+\/\/\/ in `$JAVA_HOME\/lib\/modules` to this generator.  The *traces* are generated\n+\/\/\/ from the execution of `build.tools.classlist.HelloClasslist` in the build\n+\/\/\/ process of the JDK.\n+\/\/\/\n+\/\/\/ > To list all the Species classes in a JDK image:\n+\/\/\/ > ```\n+\/\/\/ > jimage list $JAVA_HOME\/lib\/modules | grep BoundMethodHandle.Species_\n+\/\/\/ > ```\n+\/\/\/\n+\/\/\/ > All these pregenerated classes can be examined by javap in the same image:\n+\/\/\/ > (Note to escape `$` in bash)\n+\/\/\/ > ```\n+\/\/\/ > javap -c -p -v java.lang.invoke.LambdaForm\\$Holder\n+\/\/\/ > ```\n+\/\/\/\n+\/\/\/ #### AOT Cache\n+\/\/\/ When creating an AOT cache, *traces* generated from the training run are\n+\/\/\/ captured and stored inside the AOT configuration file, and are accessed with\n+\/\/\/ the C++ `FinalImageRecipes` class.  Classes regenerated from these *traces*\n+\/\/\/ are linked in assembly phase; see `regeneratedClasses.hpp`.\n+\/\/\/\n+\/\/\/ @see #generateHolderClasses(Stream)\n+\/\/\/ @see BoundMethodHandle.Specializer\n+\/\/\/ @see DelegatingMethodHandle.Holder\n+\/\/\/ @see DirectMethodHandle.Holder\n+\/\/\/ @see Invokers.Holder\n+\/\/\/ @see LambdaForm.Holder\n+\/\/\/ @see VarHandleGuards\n+final class GenerateJLIClassesHelper {\n@@ -325,7 +386,17 @@\n-    \/*\n-     * Returns a map of class name in internal form to the corresponding class bytes\n-     * per the given stream of SPECIES_RESOLVE and LF_RESOLVE trace logs.\n-     *\n-     * Used by GenerateJLIClassesPlugin to pre-generate holder classes during\n-     * jlink phase.\n-     *\/\n+    \/\/\/ Returns a map from class names in internal form to the corresponding\n+    \/\/\/ class bytes.\n+    \/\/\/\n+    \/\/\/ A few known lambda forms, such as field accessors, can be comprehensively\n+    \/\/\/ generated.  Most others lambda forms are associated with unique method\n+    \/\/\/ types; thus they are generated per the given stream of SPECIES_RESOLVE\n+    \/\/\/ and LF_RESOLVE *trace* logs, which are created according to {@link\n+    \/\/\/ MethodHandleStatics#TRACE_RESOLVE} configuration.\n+    \/\/\/\n+    \/\/\/ The names of methods in the generated classes are internal tokens\n+    \/\/\/ recognized by [InvokerBytecodeGenerator#lookupPregenerated] and are\n+    \/\/\/ subject to change.\n+    \/\/\/\n+    \/\/\/ @param traces the *traces* to determine the lambda forms and species\n+    \/\/\/        to generate\n+    \/\/\/ @see MethodHandleStatics#traceLambdaForm\n+    \/\/\/ @see MethodHandleStatics#traceSpeciesType\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/GenerateJLIClassesHelper.java","additions":83,"deletions":12,"binary":false,"changes":95,"status":"modified"},{"patch":"@@ -142,0 +142,3 @@\n+    \/\/\/ Represents the \"basic\" types that exist in the JVM linkage and stack\/locals.\n+    \/\/\/ All objects are erased to a reference.\n+    \/\/\/ All subwords (boolean, byte, char, short) are promoted to int.\n@@ -143,1 +146,1 @@\n-        L_TYPE('L', Object.class, Wrapper.OBJECT, TypeKind.REFERENCE), \/\/ all reference types\n+        L_TYPE('L', Object.class, Wrapper.OBJECT, TypeKind.REFERENCE),\n@@ -147,2 +150,2 @@\n-        D_TYPE('D', double.class, Wrapper.DOUBLE, TypeKind.DOUBLE),  \/\/ all primitive types\n-        V_TYPE('V', void.class,   Wrapper.VOID,   TypeKind.VOID);    \/\/ not valid in all contexts\n+        D_TYPE('D', double.class, Wrapper.DOUBLE, TypeKind.DOUBLE),  \/\/ end arg types\n+        V_TYPE('V', void.class,   Wrapper.VOID,   TypeKind.VOID);    \/\/ only valid in method return\n@@ -1757,1 +1760,7 @@\n-    \/* Placeholder class for identity and constant forms generated ahead of time *\/\n+    \/\/\/ Holds pre-generated bytecode for common lambda forms.\n+    \/\/\/\n+    \/\/\/ This class may be substituted in the JDK's modules image, or in an AOT\n+    \/\/\/ cache, by a version generated by [GenerateJLIClassesHelper].\n+    \/\/\/\n+    \/\/\/ The method names of this class are internal tokens recognized by\n+    \/\/\/ [InvokerBytecodeGenerator#lookupPregenerated] and are subject to change.\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/LambdaForm.java","additions":13,"deletions":4,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -738,238 +738,0 @@\n-\n-\/\/    \/**\n-\/\/     * A helper program to generate the VarHandleGuards class with a set of\n-\/\/     * static guard methods each of which corresponds to a particular shape and\n-\/\/     * performs a type check of the symbolic type descriptor with the VarHandle\n-\/\/     * type descriptor before linking\/invoking to the underlying operation as\n-\/\/     * characterized by the operation member name on the VarForm of the\n-\/\/     * VarHandle.\n-\/\/     * <p>\n-\/\/     * The generated class essentially encapsulates pre-compiled LambdaForms,\n-\/\/     * one for each method, for the most set of common method signatures.\n-\/\/     * This reduces static initialization costs, footprint costs, and circular\n-\/\/     * dependencies that may arise if a class is generated per LambdaForm.\n-\/\/     * <p>\n-\/\/     * A maximum of L*T*S methods will be generated where L is the number of\n-\/\/     * access modes kinds (or unique operation signatures) and T is the number\n-\/\/     * of variable types and S is the number of shapes (such as instance field,\n-\/\/     * static field, or array access).\n-\/\/     * If there are 4 unique operation signatures, 5 basic types (Object, int,\n-\/\/     * long, float, double), and 3 shapes then a maximum of 60 methods will be\n-\/\/     * generated.  However, the number is likely to be less since there\n-\/\/     * be duplicate signatures.\n-\/\/     * <p>\n-\/\/     * Each method is annotated with @LambdaForm.Compiled to inform the runtime\n-\/\/     * that such methods should be treated as if a method of a class that is the\n-\/\/     * result of compiling a LambdaForm.  Annotation of such methods is\n-\/\/     * important for correct evaluation of certain assertions and method return\n-\/\/     * type profiling in HotSpot.\n-\/\/     *\/\n-\/\/    public static class GuardMethodGenerator {\n-\/\/\n-\/\/        static final String GUARD_METHOD_SIG_TEMPLATE = \"<RETURN> <NAME>_<SIGNATURE>(<PARAMS>)\";\n-\/\/\n-\/\/        static final String GUARD_METHOD_TEMPLATE =\n-\/\/                \"\"\"\n-\/\/                @ForceInline\n-\/\/                @LambdaForm.Compiled\n-\/\/                @Hidden\n-\/\/                static final <METHOD> throws Throwable {\n-\/\/                    boolean direct = handle.checkAccessModeThenIsDirect(ad);\n-\/\/                    if (direct && handle.vform.methodType_table[ad.type] == ad.symbolicMethodTypeErased) {\n-\/\/                        <RESULT_ERASED>MethodHandle.linkToStatic(<LINK_TO_STATIC_ARGS>);<RETURN_ERASED>\n-\/\/                    } else {\n-\/\/                        MethodHandle mh = handle.getMethodHandle(ad.mode);\n-\/\/                        <RETURN>mh.asType(ad.symbolicMethodTypeInvoker).invokeBasic(<LINK_TO_INVOKER_ARGS>);\n-\/\/                    }\n-\/\/                }\"\"\";\n-\/\/\n-\/\/        static final String GUARD_METHOD_TEMPLATE_V =\n-\/\/                \"\"\"\n-\/\/                @ForceInline\n-\/\/                @LambdaForm.Compiled\n-\/\/                @Hidden\n-\/\/                static final <METHOD> throws Throwable {\n-\/\/                    boolean direct = handle.checkAccessModeThenIsDirect(ad);\n-\/\/                    if (direct && handle.vform.methodType_table[ad.type] == ad.symbolicMethodTypeErased) {\n-\/\/                        MethodHandle.linkToStatic(<LINK_TO_STATIC_ARGS>);\n-\/\/                    } else if (direct && handle.vform.getMethodType_V(ad.type) == ad.symbolicMethodTypeErased) {\n-\/\/                        MethodHandle.linkToStatic(<LINK_TO_STATIC_ARGS>);\n-\/\/                    } else {\n-\/\/                        MethodHandle mh = handle.getMethodHandle(ad.mode);\n-\/\/                        mh.asType(ad.symbolicMethodTypeInvoker).invokeBasic(<LINK_TO_INVOKER_ARGS>);\n-\/\/                    }\n-\/\/                }\"\"\";\n-\/\/\n-\/\/        \/\/ A template for deriving the operations\n-\/\/        \/\/ could be supported by annotating VarHandle directly with the\n-\/\/        \/\/ operation kind and shape\n-\/\/        interface VarHandleTemplate {\n-\/\/            Object get();\n-\/\/\n-\/\/            void set(Object value);\n-\/\/\n-\/\/            boolean compareAndSet(Object actualValue, Object expectedValue);\n-\/\/\n-\/\/            Object compareAndExchange(Object actualValue, Object expectedValue);\n-\/\/\n-\/\/            Object getAndUpdate(Object value);\n-\/\/        }\n-\/\/\n-\/\/        record HandleType(Class<?> receiver, Class<?>... intermediates) {\n-\/\/        }\n-\/\/\n-\/\/        \/**\n-\/\/         * @param args parameters\n-\/\/         *\/\n-\/\/        public static void main(String[] args) {\n-\/\/            System.out.println(\"package java.lang.invoke;\");\n-\/\/            System.out.println();\n-\/\/            System.out.println(\"import jdk.internal.vm.annotation.AOTSafeClassInitializer;\");\n-\/\/            System.out.println(\"import jdk.internal.vm.annotation.ForceInline;\");\n-\/\/            System.out.println(\"import jdk.internal.vm.annotation.Hidden;\");\n-\/\/            System.out.println();\n-\/\/            System.out.println(\"\/\/ This class is auto-generated by \" +\n-\/\/                               GuardMethodGenerator.class.getName() +\n-\/\/                               \". Do not edit.\");\n-\/\/            System.out.println(\"@AOTSafeClassInitializer\");\n-\/\/            System.out.println(\"final class VarHandleGuards {\");\n-\/\/\n-\/\/            System.out.println();\n-\/\/\n-\/\/            \/\/ Declare the stream of shapes\n-\/\/            List<HandleType> hts = List.of(\n-\/\/                    \/\/ Object->T\n-\/\/                    new HandleType(Object.class),\n-\/\/\n-\/\/                    \/\/ <static>->T\n-\/\/                    new HandleType(null),\n-\/\/\n-\/\/                    \/\/ Array[index]->T\n-\/\/                    new HandleType(Object.class, int.class),\n-\/\/\n-\/\/                    \/\/ MS[base]->T\n-\/\/                    new HandleType(Object.class, long.class),\n-\/\/\n-\/\/                    \/\/ MS[base][offset]->T\n-\/\/                    new HandleType(Object.class, long.class, long.class)\n-\/\/            );\n-\/\/\n-\/\/            Stream.of(VarHandleTemplate.class.getMethods()).<MethodType>\n-\/\/                    mapMulti((m, sink) -> {\n-\/\/                        for (var ht : hts) {\n-\/\/                            for (var bt : LambdaForm.BasicType.ARG_TYPES) {\n-\/\/                                sink.accept(generateMethodType(m, ht.receiver, bt.btClass, ht.intermediates));\n-\/\/                            }\n-\/\/                        }\n-\/\/                    }).\n-\/\/                    distinct().\n-\/\/                    map(GuardMethodGenerator::generateMethod).\n-\/\/                    forEach(System.out::println);\n-\/\/\n-\/\/            System.out.println(\"}\");\n-\/\/        }\n-\/\/\n-\/\/        static MethodType generateMethodType(Method m, Class<?> receiver, Class<?> value, Class<?>... intermediates) {\n-\/\/            Class<?> returnType = m.getReturnType() == Object.class\n-\/\/                                  ? value : m.getReturnType();\n-\/\/\n-\/\/            List<Class<?>> params = new ArrayList<>();\n-\/\/            if (receiver != null)\n-\/\/                params.add(receiver);\n-\/\/            java.util.Collections.addAll(params, intermediates);\n-\/\/            for (var p : m.getParameters()) {\n-\/\/                params.add(value);\n-\/\/            }\n-\/\/            return MethodType.methodType(returnType, params);\n-\/\/        }\n-\/\/\n-\/\/        static String generateMethod(MethodType mt) {\n-\/\/            Class<?> returnType = mt.returnType();\n-\/\/\n-\/\/            var params = new java.util.LinkedHashMap<String, Class<?>>();\n-\/\/            params.put(\"handle\", VarHandle.class);\n-\/\/            for (int i = 0; i < mt.parameterCount(); i++) {\n-\/\/                params.put(\"arg\" + i, mt.parameterType(i));\n-\/\/            }\n-\/\/            params.put(\"ad\", VarHandle.AccessDescriptor.class);\n-\/\/\n-\/\/            \/\/ Generate method signature line\n-\/\/            String RETURN = className(returnType);\n-\/\/            String NAME = \"guard\";\n-\/\/            String SIGNATURE = getSignature(mt);\n-\/\/            String PARAMS = params.entrySet().stream().\n-\/\/                    map(e -> className(e.getValue()) + \" \" + e.getKey()).\n-\/\/                    collect(java.util.stream.Collectors.joining(\", \"));\n-\/\/            String METHOD = GUARD_METHOD_SIG_TEMPLATE.\n-\/\/                    replace(\"<RETURN>\", RETURN).\n-\/\/                    replace(\"<NAME>\", NAME).\n-\/\/                    replace(\"<SIGNATURE>\", SIGNATURE).\n-\/\/                    replace(\"<PARAMS>\", PARAMS);\n-\/\/\n-\/\/            \/\/ Generate method\n-\/\/            params.remove(\"ad\");\n-\/\/\n-\/\/            List<String> LINK_TO_STATIC_ARGS = new ArrayList<>(params.keySet());\n-\/\/            LINK_TO_STATIC_ARGS.add(\"handle.vform.getMemberName(ad.mode)\");\n-\/\/\n-\/\/            List<String> LINK_TO_INVOKER_ARGS = new ArrayList<>(params.keySet());\n-\/\/            LINK_TO_INVOKER_ARGS.set(0, LINK_TO_INVOKER_ARGS.get(0) + \".asDirect()\");\n-\/\/\n-\/\/            RETURN = returnType == void.class\n-\/\/                     ? \"\"\n-\/\/                     : returnType == Object.class\n-\/\/                       ? \"return \"\n-\/\/                       : \"return (\" + returnType.getName() + \") \";\n-\/\/\n-\/\/            String RESULT_ERASED = returnType == void.class\n-\/\/                                   ? \"\"\n-\/\/                                   : returnType != Object.class\n-\/\/                                     ? \"return (\" + returnType.getName() + \") \"\n-\/\/                                     : \"Object r = \";\n-\/\/\n-\/\/            String RETURN_ERASED = returnType != Object.class\n-\/\/                                   ? \"\"\n-\/\/                                   : \"\\n        return ad.returnType.cast(r);\";\n-\/\/\n-\/\/            String template = returnType == void.class\n-\/\/                              ? GUARD_METHOD_TEMPLATE_V\n-\/\/                              : GUARD_METHOD_TEMPLATE;\n-\/\/            return template.\n-\/\/                    replace(\"<METHOD>\", METHOD).\n-\/\/                    replace(\"<NAME>\", NAME).\n-\/\/                    replaceAll(\"<RETURN>\", RETURN).\n-\/\/                    replace(\"<RESULT_ERASED>\", RESULT_ERASED).\n-\/\/                    replace(\"<RETURN_ERASED>\", RETURN_ERASED).\n-\/\/                    replaceAll(\"<LINK_TO_STATIC_ARGS>\", String.join(\", \", LINK_TO_STATIC_ARGS)).\n-\/\/                    replace(\"<LINK_TO_INVOKER_ARGS>\", String.join(\", \", LINK_TO_INVOKER_ARGS))\n-\/\/                    .indent(4);\n-\/\/        }\n-\/\/\n-\/\/        static String className(Class<?> c) {\n-\/\/            String n = c.getName();\n-\/\/            if (n.startsWith(\"java.lang.\")) {\n-\/\/                n = n.replace(\"java.lang.\", \"\");\n-\/\/                if (n.startsWith(\"invoke.\")) {\n-\/\/                    n = n.replace(\"invoke.\", \"\");\n-\/\/                }\n-\/\/            }\n-\/\/            return n.replace('$', '.');\n-\/\/        }\n-\/\/\n-\/\/        static String getSignature(MethodType m) {\n-\/\/            StringBuilder sb = new StringBuilder(m.parameterCount() + 1);\n-\/\/\n-\/\/            for (int i = 0; i < m.parameterCount(); i++) {\n-\/\/                Class<?> pt = m.parameterType(i);\n-\/\/                sb.append(getCharType(pt));\n-\/\/            }\n-\/\/\n-\/\/            sb.append('_').append(getCharType(m.returnType()));\n-\/\/\n-\/\/            return sb.toString();\n-\/\/        }\n-\/\/\n-\/\/        static char getCharType(Class<?> pt) {\n-\/\/            return Wrapper.forBasicType(pt).basicTypeChar();\n-\/\/        }\n-\/\/    }\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/VarHandles.java","additions":0,"deletions":238,"binary":false,"changes":238,"status":"modified"},{"patch":"@@ -49,1 +49,0 @@\n-import java.util.function.BiFunction;\n@@ -336,1 +335,1 @@\n-     * using the specified {@linkplain java.nio.charset.Charset charset}.\n+     * using the specified {@code Charset}.\n@@ -346,0 +345,1 @@\n+     * @throws NullPointerException If {@code bytes} or {@code cs} is null\n@@ -347,1 +347,1 @@\n-    String uncheckedNewStringNoRepl(byte[] bytes, Charset cs) throws CharacterCodingException;\n+    String uncheckedNewStringOrThrow(byte[] bytes, Charset cs) throws CharacterCodingException;\n@@ -350,2 +350,2 @@\n-     * Encode the given string into a sequence of bytes using the specified\n-     * {@linkplain java.nio.charset.Charset charset}.\n+     * {@return the sequence of bytes obtained by encoding the given string in\n+     * the specified {@code Charset}}\n@@ -356,3 +356,0 @@\n-     * <p>\n-     * This method throws {@code CharacterCodingException} instead of replacing\n-     * when malformed input or unmappable characters are encountered.\n@@ -362,1 +359,1 @@\n-     * @return the encoded bytes\n+     * @throws NullPointerException If {@code s} or {@code cs} is null\n@@ -365,1 +362,1 @@\n-    byte[] uncheckedGetBytesNoRepl(String s, Charset cs) throws CharacterCodingException;\n+    byte[] uncheckedGetBytesOrThrow(String s, Charset cs) throws CharacterCodingException;\n@@ -391,1 +388,1 @@\n-     * Encode the given string into a sequence of bytes using utf8.\n+     * {@return the sequence of bytes obtained by encoding the given string in UTF-8}\n@@ -394,2 +391,2 @@\n-     * @return the encoded bytes in utf8\n-     * @throws IllegalArgumentException for malformed surrogates\n+     * @throws NullPointerException If {@code s} is null\n+     * @throws CharacterCodingException For malformed input or unmappable characters\n@@ -397,1 +394,1 @@\n-    byte[] getBytesUTF8NoRepl(String s);\n+    byte[] getBytesUTF8OrThrow(String s) throws CharacterCodingException;\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/access\/JavaLangAccess.java","additions":11,"deletions":14,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+import static jdk.internal.classfile.impl.StackMapGenerator.*;\n@@ -296,1 +297,1 @@\n-            if (frameType < 64) {\n+            if (frameType <= SAME_FRAME_END) {\n@@ -300,1 +301,1 @@\n-            else if (frameType < 128) {\n+            else if (frameType <= SAME_LOCALS_1_STACK_ITEM_FRAME_END) {\n@@ -306,1 +307,1 @@\n-                    case StackMapDecoder.EARLY_LARVAL -> {\n+                    case EARLY_LARVAL -> {\n@@ -313,1 +314,1 @@\n-                    case 247 -> {\n+                    case SAME_LOCALS_1_STACK_ITEM_EXTENDED -> {\n@@ -317,1 +318,1 @@\n-                    case 248, 249, 250, 251 -> {\n+                    case CHOP_FRAME_START, CHOP_FRAME_START + 1, CHOP_FRAME_END, SAME_FRAME_EXTENDED -> {\n@@ -321,1 +322,1 @@\n-                    case 252, 253, 254 -> {\n+                    case APPEND_FRAME_START, APPEND_FRAME_START + 1, APPEND_FRAME_END -> {\n@@ -323,1 +324,1 @@\n-                        int k = frameType - 251;\n+                        int k = frameType - APPEND_FRAME_START + 1;\n@@ -329,1 +330,1 @@\n-                    case 255 -> {\n+                    case FULL_FRAME -> {\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/classfile\/impl\/CodeImpl.java","additions":9,"deletions":8,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -54,1 +54,1 @@\n-import static java.lang.classfile.attribute.StackMapFrameInfo.VerificationTypeInfo.*;\n+import static jdk.internal.classfile.impl.StackMapGenerator.*;\n@@ -59,5 +59,0 @@\n-    static final int\n-                    EARLY_LARVAL = 246,\n-                    SAME_LOCALS_1_STACK_ITEM_EXTENDED = 247,\n-                    SAME_EXTENDED = 251;\n-    private static final int BASE_FRAMES_UPPER_LIMIT = SAME_LOCALS_1_STACK_ITEM_EXTENDED; \/\/ not inclusive\n@@ -199,1 +194,1 @@\n-                if (diffLocalsSize == 0 && offsetDelta < 64) { \/\/same frame\n+                if (diffLocalsSize == 0 && offsetDelta <= SAME_FRAME_END) { \/\/same frame\n@@ -202,1 +197,1 @@\n-                    out.writeU1U2(251 + diffLocalsSize, offsetDelta);\n+                    out.writeU1U2(SAME_FRAME_EXTENDED + diffLocalsSize, offsetDelta);\n@@ -208,2 +203,2 @@\n-            if (offsetDelta < 64) {  \/\/same locals 1 stack item frame\n-                out.writeU1(64 + offsetDelta);\n+            if (offsetDelta <= SAME_LOCALS_1_STACK_ITEM_FRAME_END  - SAME_LOCALS_1_STACK_ITEM_FRAME_START) {  \/\/same locals 1 stack item frame\n+                out.writeU1(SAME_LOCALS_1_STACK_ITEM_FRAME_START + offsetDelta);\n@@ -211,1 +206,1 @@\n-                out.writeU1U2(247, offsetDelta);\n+                out.writeU1U2(SAME_LOCALS_1_STACK_ITEM_EXTENDED, offsetDelta);\n@@ -217,1 +212,1 @@\n-        out.writeU1U2U2(255, offsetDelta, fr.locals().size());\n+        out.writeU1U2U2(FULL_FRAME, offsetDelta, fr.locals().size());\n@@ -272,1 +267,1 @@\n-            if (frameType < 64) {\n+            if (frameType <= SAME_FRAME_END) {\n@@ -275,2 +270,2 @@\n-            } else if (frameType < 128) {\n-                bci += frameType - 63;\n+            } else if (frameType <= SAME_LOCALS_1_STACK_ITEM_FRAME_END) {\n+                bci += frameType - SAME_LOCALS_1_STACK_ITEM_FRAME_START + 1;\n@@ -279,1 +274,1 @@\n-                if (frameType < BASE_FRAMES_UPPER_LIMIT)\n+                if (frameType < SAME_LOCALS_1_STACK_ITEM_EXTENDED)\n@@ -284,2 +279,2 @@\n-                } else if (frameType < SAME_EXTENDED) {\n-                    locals = locals.subList(0, locals.size() + frameType - SAME_EXTENDED);\n+                } else if (frameType < SAME_FRAME_EXTENDED) {\n+                    locals = locals.subList(0, locals.size() + frameType - SAME_FRAME_EXTENDED);\n@@ -287,1 +282,1 @@\n-                } else if (frameType == SAME_EXTENDED) {\n+                } else if (frameType == SAME_FRAME_EXTENDED) {\n@@ -289,1 +284,1 @@\n-                } else if (frameType < SAME_EXTENDED + 4) {\n+                } else if (frameType <= APPEND_FRAME_END) {\n@@ -291,1 +286,1 @@\n-                    var newLocals = locals.toArray(new VerificationTypeInfo[actSize + frameType - SAME_EXTENDED]);\n+                    var newLocals = locals.toArray(new VerificationTypeInfo[actSize + frameType - SAME_FRAME_EXTENDED]);\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/classfile\/impl\/StackMapDecoder.java","additions":16,"deletions":21,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -166,1 +166,2 @@\n-    private static final int ITEM_TOP = 0,\n+    public static final int\n+            ITEM_TOP = 0,\n@@ -180,1 +181,17 @@\n-            ITEM_DOUBLE_2ND = 14;\n+            ITEM_DOUBLE_2ND = 14,\n+            ITEM_BOGUS = -1;\n+\n+    \/\/ Ranges represented by these constants are inclusive on both ends\n+    public static final int\n+            SAME_FRAME_END = 63,\n+            SAME_LOCALS_1_STACK_ITEM_FRAME_START = 64,\n+            SAME_LOCALS_1_STACK_ITEM_FRAME_END = 127,\n+            RESERVED_END = 245,\n+            EARLY_LARVAL = 246,\n+            SAME_LOCALS_1_STACK_ITEM_EXTENDED = 247,\n+            CHOP_FRAME_START = 248,\n+            CHOP_FRAME_END = 250,\n+            SAME_FRAME_EXTENDED = 251,\n+            APPEND_FRAME_START = 252,\n+            APPEND_FRAME_END = 254,\n+            FULL_FRAME = 255;\n@@ -1348,1 +1365,1 @@\n-                out.writeU1U2(StackMapDecoder.EARLY_LARVAL, unsetFieldsSize);\n+                out.writeU1U2(EARLY_LARVAL, unsetFieldsSize);\n@@ -1362,1 +1379,1 @@\n-                    if (diffLocalsSize == 0 && offsetDelta < 64) { \/\/same frame\n+                    if (diffLocalsSize == 0 && offsetDelta <= SAME_FRAME_END) { \/\/same frame\n@@ -1365,1 +1382,1 @@\n-                        out.writeU1U2(251 + diffLocalsSize, offsetDelta);\n+                        out.writeU1U2(SAME_FRAME_EXTENDED + diffLocalsSize, offsetDelta);\n@@ -1371,2 +1388,2 @@\n-                if (offsetDelta < 64) {  \/\/same locals 1 stack item frame\n-                    out.writeU1(64 + offsetDelta);\n+                if (offsetDelta <= SAME_LOCALS_1_STACK_ITEM_FRAME_END  - SAME_LOCALS_1_STACK_ITEM_FRAME_START) {  \/\/same locals 1 stack item frame\n+                    out.writeU1(SAME_LOCALS_1_STACK_ITEM_FRAME_START + offsetDelta);\n@@ -1374,1 +1391,1 @@\n-                    out.writeU1U2(247, offsetDelta);\n+                    out.writeU1U2(SAME_LOCALS_1_STACK_ITEM_EXTENDED, offsetDelta);\n@@ -1380,1 +1397,1 @@\n-            out.writeU1U2U2(255, offsetDelta, localsSize);\n+            out.writeU1U2U2(FULL_FRAME, offsetDelta, localsSize);\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/classfile\/impl\/StackMapGenerator.java","additions":26,"deletions":9,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -45,0 +45,1 @@\n+import static jdk.internal.classfile.impl.StackMapGenerator.*;\n@@ -459,6 +460,6 @@\n-        if (ft < 64) return 1;\n-        if (ft < 128) return 1 + verificationTypeSize(frame.stack().getFirst());\n-        if (ft > 246) {\n-            if (ft == 247) return 3 + verificationTypeSize(frame.stack().getFirst());\n-            if (ft < 252) return 3;\n-            if (ft < 255) {\n+        if (ft <= SAME_FRAME_END) return 1;\n+        if (ft <= SAME_LOCALS_1_STACK_ITEM_FRAME_END) return 1 + verificationTypeSize(frame.stack().getFirst());\n+        if (ft > RESERVED_END) {\n+            if (ft == SAME_LOCALS_1_STACK_ITEM_EXTENDED) return 3 + verificationTypeSize(frame.stack().getFirst());\n+            if (ft <= SAME_FRAME_EXTENDED) return 3;\n+            if (ft <= APPEND_FRAME_END) {\n@@ -467,1 +468,2 @@\n-                for (int i = loc.size() + 251 - ft; i < loc.size(); i++) {\n+                var k = ft - APPEND_FRAME_START + 1;\n+                for (int i = loc.size() - k; i < loc.size(); i++) {\n@@ -472,1 +474,1 @@\n-            if (ft == 255) {\n+            if (ft == FULL_FRAME) {\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/classfile\/impl\/verifier\/ParserVerifier.java","additions":10,"deletions":8,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -33,3 +33,1 @@\n-import static jdk.internal.classfile.impl.verifier.VerificationType.ITEM_Object;\n-import static jdk.internal.classfile.impl.verifier.VerificationType.ITEM_Uninitialized;\n-import static jdk.internal.classfile.impl.verifier.VerificationType.ITEM_UninitializedThis;\n+import static jdk.internal.classfile.impl.StackMapGenerator.*;\n@@ -167,7 +165,0 @@\n-        private static final int\n-                        EARLY_LARVAL = 246,\n-                        SAME_LOCALS_1_STACK_ITEM_EXTENDED = 247,\n-                        SAME_EXTENDED = 251,\n-                        FULL = 255;\n-        private static final int RESERVED_TAGS_UPPER_LIMIT = EARLY_LARVAL; \/\/ not inclusive\n-\n@@ -266,1 +257,1 @@\n-            if (tag < ITEM_UninitializedThis) {\n+            if (tag < ITEM_UNINITIALIZED_THIS) {\n@@ -269,1 +260,1 @@\n-            if (tag == ITEM_Object) {\n+            if (tag == ITEM_OBJECT) {\n@@ -277,1 +268,1 @@\n-            if (tag == ITEM_UninitializedThis) {\n+            if (tag == ITEM_UNINITIALIZED_THIS) {\n@@ -283,1 +274,1 @@\n-            if (tag == ITEM_Uninitialized) {\n+            if (tag == ITEM_UNINITIALIZED) {\n@@ -334,1 +325,1 @@\n-            if (frame_type < 64) {\n+            if (frame_type <= SAME_FRAME_END) {\n@@ -351,1 +342,1 @@\n-            if (frame_type < 128) {\n+            if (frame_type <= SAME_LOCALS_1_STACK_ITEM_FRAME_END) {\n@@ -353,1 +344,1 @@\n-                    offset = frame_type - 64;\n+                    offset = frame_type - SAME_LOCALS_1_STACK_ITEM_FRAME_START;\n@@ -358,1 +349,1 @@\n-                    offset = _prev_frame.offset() + frame_type - 63;\n+                    offset = _prev_frame.offset() + frame_type - SAME_LOCALS_1_STACK_ITEM_FRAME_START + 1;\n@@ -377,1 +368,1 @@\n-            if (frame_type < RESERVED_TAGS_UPPER_LIMIT) {\n+            if (frame_type <= RESERVED_END) {\n@@ -405,1 +396,1 @@\n-            if (frame_type <= SAME_EXTENDED) {\n+            if (frame_type <= SAME_FRAME_EXTENDED) {\n@@ -408,1 +399,1 @@\n-                int chops = SAME_EXTENDED - frame_type;\n+                int chops = SAME_FRAME_EXTENDED - frame_type;\n@@ -438,2 +429,2 @@\n-            } else if (frame_type < SAME_EXTENDED + 4) {\n-                int appends = frame_type - SAME_EXTENDED;\n+            } else if (frame_type <= APPEND_FRAME_END) {\n+                int appends = frame_type - APPEND_FRAME_START + 1;\n@@ -467,1 +458,1 @@\n-            if (frame_type == FULL) {\n+            if (frame_type == FULL_FRAME) {\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/classfile\/impl\/verifier\/VerificationTable.java","additions":15,"deletions":24,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -1608,1 +1608,1 @@\n-                        tree.vartype = make.Erroneous();\n+                        tree.vartype = make.at(tree.pos()).Erroneous();\n@@ -1615,1 +1615,1 @@\n-                            tree.vartype = make.Erroneous();\n+                            tree.vartype = make.at(tree.pos()).Erroneous();\n@@ -4936,3 +4936,13 @@\n-                    Symbol sym2 = (sym.flags() & Flags.PRIVATE) != 0 ?\n-                        rs.new AccessError(env, site, sym) :\n-                                sym;\n+                    \/\/ JLS 4.9 specifies the members are derived by inheritance.\n+                    \/\/ We skip inducing a whole class by filtering members that\n+                    \/\/ can never be inherited:\n+                    Symbol sym2;\n+                    if (sym.isPrivate()) {\n+                        \/\/ Private members\n+                        sym2 = rs.new AccessError(env, site, sym);\n+                    } else if (sym.owner.isInterface() && sym.kind == MTH && (sym.flags() & STATIC) != 0) {\n+                        \/\/ Interface static methods\n+                        sym2 = rs.new SymbolNotFoundError(ABSENT_MTH);\n+                    } else {\n+                        sym2 = sym;\n+                    }\n@@ -6079,0 +6089,3 @@\n+        } else if (tree.declaredUsingVar()) {\n+            Assert.check(tree.typePos != Position.NOPOS);\n+            tree.vartype = make.at(tree.typePos).Type(type);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Attr.java","additions":18,"deletions":5,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -1005,0 +1005,1 @@\n+            int varTypePos = Position.NOPOS;\n@@ -1009,0 +1010,1 @@\n+                    varTypePos = e.pos;\n@@ -1046,1 +1048,3 @@\n-                JCVariableDecl var = toP(F.at(varPos).VarDef(mods, name, e, null));\n+                JCVariableDecl var = toP(F.at(varPos).VarDef(mods, name, e, null,\n+                  varTypePos != Position.NOPOS ? JCVariableDecl.DeclKind.VAR : JCVariableDecl.DeclKind.EXPLICIT,\n+                  varTypePos));\n@@ -1048,1 +1052,0 @@\n-                    var.startPos = pos;\n@@ -1116,0 +1119,5 @@\n+        if ((lastmode & TYPE) == 0) {\n+            \/\/if the mode was switched to expression while expecting type, wrap with Erroneous:\n+            result = F.Erroneous(List.of(result));\n+        }\n+\n@@ -1443,0 +1451,1 @@\n+        int startMode = mode;\n@@ -1772,0 +1781,3 @@\n+            if (typeArgs != null && (startMode & TYPE) != 0) {\n+                return F.at(pos).TypeApply(F.Erroneous(), typeArgs);\n+            }\n@@ -2190,1 +2202,2 @@\n-                    param.startPos = TreeInfo.getStartPos(param.vartype);\n+                    param.declKind = JCVariableDecl.DeclKind.VAR;\n+                    param.typePos = TreeInfo.getStartPos(param.vartype);\n@@ -3840,1 +3853,1 @@\n-        int startPos = Position.NOPOS;\n+        int varTypePos = Position.NOPOS;\n@@ -3852,0 +3865,1 @@\n+                    varTypePos = elemType.pos;\n@@ -3855,3 +3869,0 @@\n-                    startPos = TreeInfo.getStartPos(mods);\n-                    if (startPos == Position.NOPOS)\n-                        startPos = TreeInfo.getStartPos(type);\n@@ -3863,2 +3874,2 @@\n-        JCVariableDecl result = toP(F.at(pos).VarDef(mods, name, type, init, declaredUsingVar));\n-        result.startPos = startPos;\n+        JCVariableDecl result = toP(F.at(pos).VarDef(mods, name, type, init,\n+          declaredUsingVar ? JCVariableDecl.DeclKind.VAR : JCVariableDecl.DeclKind.EXPLICIT, varTypePos));\n@@ -3985,2 +3996,5 @@\n-        return toP(F.at(pos).VarDef(mods, name, type, null,\n-                type != null && type.hasTag(IDENT) && ((JCIdent)type).name == names.var));\n+        boolean declaredUsingVar = type != null && type.hasTag(IDENT) && ((JCIdent)type).name == names.var;\n+        JCVariableDecl.DeclKind declKind = declaredUsingVar ? JCVariableDecl.DeclKind.VAR :\n+          type != null ? JCVariableDecl.DeclKind.EXPLICIT : JCVariableDecl.DeclKind.IMPLICIT;\n+        int typePos = type != null ? type.pos : pos;\n+        return toP(F.at(pos).VarDef(mods, name, type, null, declKind, typePos));\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/parser\/JavacParser.java","additions":25,"deletions":11,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -613,3 +613,1 @@\n-                if (node.startPos != Position.NOPOS) {\n-                    return node.startPos;\n-                } else if (node.mods.pos != Position.NOPOS) {\n+                if (node.mods.pos != Position.NOPOS) {\n@@ -617,5 +615,1 @@\n-                } else if (node.vartype == null || node.vartype.pos == Position.NOPOS) {\n-                    \/\/if there's no type (partially typed lambda parameter)\n-                    \/\/simply return node position\n-                    return node.pos;\n-                } else {\n+                } else if (node.vartype != null) {\n@@ -623,0 +617,2 @@\n+                } else if (node.typePos != Position.NOPOS) {\n+                    return node.typePos;\n@@ -624,0 +620,1 @@\n+                break;\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/tree\/TreeInfo.java","additions":5,"deletions":8,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -52,7 +52,1 @@\n-  if (LockingMode == LM_MONITOR) {\n-    \/\/ With heavy monitors, we do not use the mark word. Printing the oop only shows \"monitor\" regardless of the\n-    \/\/ locking state.\n-    assert_test_pattern(object, \"monitor\");\n-  } else {\n-    assert_test_pattern(object, pattern);\n-  }\n+  assert_test_pattern(object, pattern);\n@@ -125,5 +119,1 @@\n-  if (LockingMode == LM_LEGACY) {\n-    EXPECT_FALSE(mark.has_locker());\n-  } else if (LockingMode == LM_LIGHTWEIGHT) {\n-    EXPECT_FALSE(mark.is_fast_locked());\n-  }\n+  EXPECT_FALSE(mark.is_fast_locked());\n","filename":"test\/hotspot\/gtest\/oops\/test_markWord.cpp","additions":2,"deletions":12,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -549,0 +549,1 @@\n+ -runtime\/cds\/appcds\/LambdaContainsOldInf.java \\\n@@ -556,1 +557,1 @@\n- -runtime\/cds\/appcds\/dynamicArchive\/ModulePath.java \\\n+ -runtime\/cds\/appcds\/dynamicArchive\/LambdaContainsOldInf.java \\\n@@ -561,0 +562,2 @@\n+ -runtime\/cds\/appcds\/dynamicArchive\/ModulePath.java \\\n+ -runtime\/cds\/appcds\/dynamicArchive\/NestHostOldInf.java \\\n@@ -564,0 +567,1 @@\n+ -runtime\/cds\/appcds\/dynamicArchive\/RedefineCallerClassTest.java \\\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1472,0 +1472,5 @@\n+    public static final String VECTOR_MASK_LANE_IS_SET = PREFIX + \"VECTOR_MASK_LANE_IS_SET\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(VECTOR_MASK_LANE_IS_SET, \"ExtractUB\");\n+    }\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/IRNode.java","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -93,1 +93,1 @@\n-                var classTransform = ClassTransform.transformingMethods(mm -> mm.methodName().stringValue().equals(\"parse\"), methodTransform);\n+                var classTransform = ClassTransform.transformingMethods(mm -> mm.methodName().equalsString(\"parse\"), methodTransform);\n","filename":"test\/hotspot\/jtreg\/runtime\/verifier\/CFLH\/TestVerify.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -263,1 +263,1 @@\n-java\/awt\/Choice\/ChoiceMouseWheelTest\/ChoiceMouseWheelTest.java 6849371 macosx-all,linux-all\n+java\/awt\/Choice\/ChoiceMouseWheelTest\/ChoiceMouseWheelTest.java 8366852 generic-all\n@@ -458,1 +458,0 @@\n-java\/awt\/ScrollPane\/ScrollPositionTest.java 8040070 linux-all\n@@ -811,1 +810,0 @@\n-java\/awt\/event\/MouseEvent\/AltGraphModifierTest\/AltGraphModifierTest.java 8162380 generic-all\n","filename":"test\/jdk\/ProblemList.txt","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -215,1 +215,1 @@\n-            .replaceAll(\"(?m)^(?:COMSPEC|PROMPT|PATHEXT)=.*\\n\",\"\");\n+            .replaceAll(\"(?m)^(?:COMSPEC|PROMPT|PATHEXT|PROCESSOR_ARCHITECTURE)=.*\\n\",\"\");\n@@ -813,0 +813,8 @@\n+    \/* Only used for Windows AArch64 --\n+     * Windows AArch64 adds the variable PROCESSOR_ARCHITECTURE=ARM64 to the environment.\n+     * Remove it from the list of env variables\n+     *\/\n+    private static String removeWindowsAArch64ExpectedVars(String vars) {\n+        return vars.replace(\"PROCESSOR_ARCHITECTURE=ARM64,\", \"\");\n+    }\n+\n@@ -1323,0 +1331,3 @@\n+            if (Windows.is() && Platform.isAArch64()) {\n+                result = removeWindowsAArch64ExpectedVars(result);\n+            }\n@@ -1835,0 +1846,3 @@\n+            if (Windows.is() && Platform.isAArch64()) {\n+                commandOutput = removeWindowsAArch64ExpectedVars(commandOutput);\n+            }\n@@ -1842,1 +1856,5 @@\n-                equal(commandOutput(pb), expected);\n+                commandOutput = commandOutput(pb);\n+                if (Platform.isAArch64()) {\n+                    commandOutput = removeWindowsAArch64ExpectedVars(commandOutput);\n+                }\n+                equal(commandOutput, expected);\n@@ -1894,0 +1912,3 @@\n+            if (Windows.is() && Platform.isAArch64()) {\n+                commandOutput = removeWindowsAArch64ExpectedVars(commandOutput);\n+            }\n","filename":"test\/jdk\/java\/lang\/ProcessBuilder\/Basic.java","additions":23,"deletions":2,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,1 +29,1 @@\n- * @run testng Test8294583\n+ * @run junit Test8294583\n@@ -33,2 +33,3 @@\n-import org.testng.annotations.Test;\n-import static org.testng.Assert.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n@@ -36,1 +37,0 @@\n-@Test\n@@ -39,0 +39,1 @@\n+    @Test\n@@ -45,1 +46,1 @@\n-    @org.testng.annotations.BeforeMethod\n+    @BeforeEach\n","filename":"test\/langtools\/jdk\/jshell\/Test8294583.java","additions":7,"deletions":6,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,1 +29,1 @@\n- * @run testng Test8296012\n+ * @run junit Test8296012\n@@ -33,2 +33,3 @@\n-import org.testng.annotations.Test;\n-import static org.testng.Assert.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n@@ -36,1 +37,0 @@\n-@Test\n@@ -39,0 +39,1 @@\n+    @Test\n@@ -44,1 +45,1 @@\n-    @org.testng.annotations.BeforeMethod\n+    @BeforeEach\n","filename":"test\/langtools\/jdk\/jshell\/Test8296012.java","additions":7,"deletions":6,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,1 @@\n- * @run testng ToolEnablePreviewTest\n+ * @run junit ToolEnablePreviewTest\n@@ -37,3 +37,2 @@\n-import org.testng.annotations.Test;\n-\n-import static org.testng.Assert.assertTrue;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import org.junit.jupiter.api.Test;\n","filename":"test\/langtools\/jdk\/jshell\/ToolEnablePreviewTest.java","additions":4,"deletions":5,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -76,3 +76,3 @@\n-                        b = o instanceof R(\/*missing*\/ s);\n-                        b = o instanceof R2(R(\/*missing*\/ s), String t);\n-                        b = o instanceof R2(R(\/*missing*\/ s), \/*missing*\/ t);\n+                        b = o instanceof R(var s);\n+                        b = o instanceof R2(R(var s), String t);\n+                        b = o instanceof R2(R(var s), var t);\n@@ -80,2 +80,2 @@\n-                        b = o instanceof R2(R(\/*missing*\/ _), \/*missing*\/ _);\n-                        b = o instanceof R2(R(_), \/*missing*\/ t);\n+                        b = o instanceof R2(R(var _), var _);\n+                        b = o instanceof R2(R(_), var t);\n","filename":"test\/langtools\/tools\/javac\/patterns\/PrettyTest.java","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -862,0 +862,7 @@\n+  public native void busyWait(int cpuTimeMs);\n+\n+  \/\/ returns true if supported, false if not\n+  public native boolean cpuSamplerSetOutOfStackWalking(boolean enable);\n+\n+  public native long cpuSamplerOutOfStackWalkingIterations();\n+\n","filename":"test\/lib\/jdk\/test\/whitebox\/WhiteBox.java","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"}]}