{"files":[{"patch":"@@ -56,0 +56,5 @@\n+    java\/time\/chrono\/ChronoLocalDateImpl.java \\\n+    java\/time\/chrono\/MinguoDate.java \\\n+    java\/time\/chrono\/HijrahDate.java \\\n+    java\/time\/chrono\/JapaneseDate.java \\\n+    java\/time\/chrono\/ThaiBuddhistDate.java \\\n@@ -74,1 +79,2 @@\n-        public abstract class => public abstract value class, \\\n+        public abstract class => public abstract value class ; \\\n+        abstract class ChronoLocalDateImpl => abstract value class ChronoLocalDateImpl, \\\n","filename":"make\/modules\/java.base\/gensrc\/GensrcValueClasses.gmk","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2174,6 +2174,1 @@\n-    Label skip;\n-    __ cmp_klass(j_rarg0, rscratch2, rscratch1);\n-    __ br(Assembler::EQ, skip);\n-      __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));\n-    __ bind(skip);\n-\n+    __ ic_check(1);\n@@ -2212,4 +2207,3 @@\n-    st->print_cr(\"\\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\\t# compressed klass\");\n-    if (CompressedKlassPointers::shift() != 0) {\n-      st->print_cr(\"\\tdecode_klass_not_null rscratch1, rscratch1\");\n-    }\n+    st->print_cr(\"\\tldrw rscratch1, [j_rarg0 + oopDesc::klass_offset_in_bytes()]\\t# compressed klass\");\n+    st->print_cr(\"\\tldrw r10, [rscratch2 + CompiledICData::speculated_klass_offset()]\\t# compressed klass\");\n+    st->print_cr(\"\\tcmpw rscratch1, r10\");\n@@ -2217,1 +2211,3 @@\n-   st->print_cr(\"\\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\\t# compressed klass\");\n+    st->print_cr(\"\\tldr rscratch1, [j_rarg0 + oopDesc::klass_offset_in_bytes()]\\t# compressed klass\");\n+    st->print_cr(\"\\tldr r10, [rscratch2 + CompiledICData::speculated_klass_offset()]\\t# compressed klass\");\n+    st->print_cr(\"\\tcmp rscratch1, r10\");\n@@ -2219,1 +2215,0 @@\n-  st->print_cr(\"\\tcmp r0, rscratch1\\t # Inline cache check\");\n@@ -2228,10 +2223,1 @@\n-  Label skip;\n-\n-  \/\/ UseCompressedClassPointers logic are inside cmp_klass\n-  __ cmp_klass(j_rarg0, rscratch2, rscratch1);\n-\n-  \/\/ TODO\n-  \/\/ can we avoid this skip and still use a reloc?\n-  __ br(Assembler::EQ, skip);\n-  __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));\n-  __ bind(skip);\n+  __ ic_check(InteriorEntryAlignment);\n@@ -2599,1 +2585,1 @@\n-bool is_valid_sve_arith_imm_pattern(Node* n, Node* m) {\n+static bool is_valid_sve_arith_imm_pattern(Node* n, Node* m) {\n@@ -2640,1 +2626,1 @@\n-bool is_vector_bitwise_not_pattern(Node* n, Node* m) {\n+static bool is_vector_bitwise_not_pattern(Node* n, Node* m) {\n@@ -2753,4 +2739,0 @@\n-      \/* If we get an out-of-range offset it is a bug in the compiler,\n-         so we assert here. *\/\n-      assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),\n-             \"c2 compiler bug\");\n@@ -3732,1 +3714,1 @@\n-        address stub = CompiledStaticCall::emit_to_interp_stub(cbuf, call);\n+        address stub = CompiledDirectCall::emit_to_interp_stub(cbuf, call);\n@@ -4146,20 +4128,0 @@\n-operand immI_63()\n-%{\n-  predicate(n->get_int() == 63);\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immI_64()\n-%{\n-  predicate(n->get_int() == 64);\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n@@ -4295,22 +4257,0 @@\n-\/\/ 26 bit signed offset -- for pc-relative branches\n-operand immI26()\n-%{\n-  predicate(((-(1 << 25)) <= n->get_int()) && (n->get_int() < (1 << 25)));\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ 19 bit signed offset -- for pc-relative loads\n-operand immI19()\n-%{\n-  predicate(((-(1 << 18)) <= n->get_int()) && (n->get_int() < (1 << 18)));\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n@@ -4339,21 +4279,0 @@\n-\/\/ 12 bit unsigned offset -- for base plus immediate loads\n-operand immIU12()\n-%{\n-  predicate((0 <= n->get_int()) && (n->get_int() < (1 << 12)));\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immLU12()\n-%{\n-  predicate((0 <= n->get_long()) && (n->get_long() < (1 << 12)));\n-  match(ConL);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n@@ -4624,11 +4543,0 @@\n-\/\/ 64 bit unit increment\n-operand immL_1()\n-%{\n-  predicate(n->get_long() == 1);\n-  match(ConL);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n@@ -4646,13 +4554,0 @@\n-\/\/ 32 bit offset of pc in thread anchor\n-\n-operand immL_pc_off()\n-%{\n-  predicate(n->get_long() == in_bytes(JavaThread::frame_anchor_offset()) +\n-                             in_bytes(JavaFrameAnchor::last_Java_pc_offset()));\n-  match(ConL);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n@@ -4747,24 +4642,0 @@\n-\/\/ Pointer Immediate Minus One\n-\/\/ this is used when we want to write the current PC to the thread anchor\n-operand immP_M1()\n-%{\n-  predicate(n->get_ptr() == -1);\n-  match(ConP);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Pointer Immediate Minus Two\n-\/\/ this is used when we want to write the current PC to the thread anchor\n-operand immP_M2()\n-%{\n-  predicate(n->get_ptr() == -2);\n-  match(ConP);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n@@ -5035,22 +4906,0 @@\n-\/\/ Long 64 bit Register R2 only\n-operand iRegL_R2()\n-%{\n-  constraint(ALLOC_IN_RC(r2_reg));\n-  match(RegL);\n-  match(iRegLNoSp);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Long 64 bit Register R3 only\n-operand iRegL_R3()\n-%{\n-  constraint(ALLOC_IN_RC(r3_reg));\n-  match(RegL);\n-  match(iRegLNoSp);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n@@ -5068,11 +4917,0 @@\n-\/\/ Pointer 64 bit Register FP only\n-operand iRegP_FP()\n-%{\n-  constraint(ALLOC_IN_RC(fp_reg));\n-  match(RegP);\n-  \/\/ match(iRegP);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n@@ -5137,27 +4975,0 @@\n-operand iRegN_R0()\n-%{\n-  constraint(ALLOC_IN_RC(r0_reg));\n-  match(iRegN);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand iRegN_R2()\n-%{\n-  constraint(ALLOC_IN_RC(r2_reg));\n-  match(iRegN);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand iRegN_R3()\n-%{\n-  constraint(ALLOC_IN_RC(r3_reg));\n-  match(iRegN);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n@@ -5314,216 +5125,0 @@\n-operand vRegD_V8()\n-%{\n-  constraint(ALLOC_IN_RC(v8_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V9()\n-%{\n-  constraint(ALLOC_IN_RC(v9_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V10()\n-%{\n-  constraint(ALLOC_IN_RC(v10_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V11()\n-%{\n-  constraint(ALLOC_IN_RC(v11_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V12()\n-%{\n-  constraint(ALLOC_IN_RC(v12_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V13()\n-%{\n-  constraint(ALLOC_IN_RC(v13_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V14()\n-%{\n-  constraint(ALLOC_IN_RC(v14_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V15()\n-%{\n-  constraint(ALLOC_IN_RC(v15_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V16()\n-%{\n-  constraint(ALLOC_IN_RC(v16_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V17()\n-%{\n-  constraint(ALLOC_IN_RC(v17_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V18()\n-%{\n-  constraint(ALLOC_IN_RC(v18_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V19()\n-%{\n-  constraint(ALLOC_IN_RC(v19_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V20()\n-%{\n-  constraint(ALLOC_IN_RC(v20_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V21()\n-%{\n-  constraint(ALLOC_IN_RC(v21_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V22()\n-%{\n-  constraint(ALLOC_IN_RC(v22_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V23()\n-%{\n-  constraint(ALLOC_IN_RC(v23_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V24()\n-%{\n-  constraint(ALLOC_IN_RC(v24_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V25()\n-%{\n-  constraint(ALLOC_IN_RC(v25_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V26()\n-%{\n-  constraint(ALLOC_IN_RC(v26_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V27()\n-%{\n-  constraint(ALLOC_IN_RC(v27_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V28()\n-%{\n-  constraint(ALLOC_IN_RC(v28_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V29()\n-%{\n-  constraint(ALLOC_IN_RC(v29_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V30()\n-%{\n-  constraint(ALLOC_IN_RC(v30_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vRegD_V31()\n-%{\n-  constraint(ALLOC_IN_RC(v31_reg));\n-  match(RegD);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n@@ -5631,9 +5226,0 @@\n-operand lr_RegP(iRegP reg)\n-%{\n-  constraint(ALLOC_IN_RC(lr_reg)); \/\/ link_reg\n-  match(reg);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n@@ -5714,14 +5300,0 @@\n-operand indOffI(iRegP reg, immIOffset off)\n-%{\n-  constraint(ALLOC_IN_RC(ptr_reg));\n-  match(AddP reg off);\n-  op_cost(0);\n-  format %{ \"[$reg, $off]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index(0xffffffff);\n-    scale(0x0);\n-    disp($off);\n-  %}\n-%}\n-\n@@ -5798,14 +5370,0 @@\n-operand indOffL(iRegP reg, immLoffset off)\n-%{\n-  constraint(ALLOC_IN_RC(ptr_reg));\n-  match(AddP reg off);\n-  op_cost(0);\n-  format %{ \"[$reg, $off]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index(0xffffffff);\n-    scale(0x0);\n-    disp($off);\n-  %}\n-%}\n-\n@@ -5988,16 +5546,0 @@\n-\n-\/\/ AArch64 opto stubs need to write to the pc slot in the thread anchor\n-operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)\n-%{\n-  constraint(ALLOC_IN_RC(ptr_reg));\n-  match(AddP reg off);\n-  op_cost(0);\n-  format %{ \"[$reg, $off]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index(0xffffffff);\n-    scale(0x0);\n-    disp($off);\n-  %}\n-%}\n-\n@@ -8337,1 +7879,1 @@\n-            \"dmb ishld\" %}\n+            \"dmb ish\" %}\n@@ -8391,1 +7933,1 @@\n-            \"dmb ishst\\n\\tdmb ishld\" %}\n+            \"dmb ish\" %}\n@@ -8395,2 +7937,1 @@\n-    __ membar(Assembler::StoreStore);\n-    __ membar(Assembler::LoadStore);\n+    __ membar(Assembler::LoadStore|Assembler::StoreStore);\n@@ -16603,0 +16144,1 @@\n+  predicate(LockingMode != LM_LIGHTWEIGHT);\n@@ -16606,3 +16148,1 @@\n-  \/\/ TODO\n-  \/\/ identify correct cost\n-  format %{ \"fastlock $object,$box\\t! kills $tmp,$tmp2\" %}\n+  format %{ \"fastlock $object,$box\\t! kills $tmp,$tmp2,$tmp3\" %}\n@@ -16620,0 +16160,1 @@\n+  predicate(LockingMode != LM_LIGHTWEIGHT);\n@@ -16633,0 +16174,31 @@\n+instruct cmpFastLockLightweight(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2, iRegPNoSp tmp3)\n+%{\n+  predicate(LockingMode == LM_LIGHTWEIGHT);\n+  match(Set cr (FastLock object box));\n+  effect(TEMP tmp, TEMP tmp2, TEMP tmp3);\n+\n+  ins_cost(5 * INSN_COST);\n+  format %{ \"fastlock $object,$box\\t! kills $tmp,$tmp2,$tmp3\" %}\n+\n+  ins_encode %{\n+    __ fast_lock_lightweight($object$$Register, $tmp$$Register, $tmp2$$Register, $tmp3$$Register);\n+  %}\n+\n+  ins_pipe(pipe_serial);\n+%}\n+\n+instruct cmpFastUnlockLightweight(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2, iRegPNoSp tmp3)\n+%{\n+  predicate(LockingMode == LM_LIGHTWEIGHT);\n+  match(Set cr (FastUnlock object box));\n+  effect(TEMP tmp, TEMP tmp2, TEMP tmp3);\n+\n+  ins_cost(5 * INSN_COST);\n+  format %{ \"fastunlock $object,$box\\t! kills $tmp, $tmp2, $tmp3\" %}\n+\n+  ins_encode %{\n+    __ fast_unlock_lightweight($object$$Register, $tmp$$Register, $tmp2$$Register, $tmp3$$Register);\n+  %}\n+\n+  ins_pipe(pipe_serial);\n+%}\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":48,"deletions":476,"binary":false,"changes":524,"status":"modified"},{"patch":"@@ -121,4 +121,0 @@\n-\n-  JNIEXPORT void das1(uintptr_t insn) {\n-    das(insn, 1);\n-  }\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -333,1 +333,1 @@\n-      new SimpleExceptionStub(Runtime1::throw_identity_exception_id, LIR_OprFact::illegalOpr, state_for(x)) :\n+      new SimpleExceptionStub(Runtime1::throw_identity_exception_id, obj.result(), state_for(x)) :\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRGenerator_aarch64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -113,1 +113,2 @@\n-    CPU_MODEL_AMPERE_1A = 0xac4  \/* CPU implementer is CPU_AMPERE *\/\n+    CPU_MODEL_AMPERE_1A = 0xac4, \/* CPU implementer is CPU_AMPERE *\/\n+    CPU_MODEL_AMPERE_1B = 0xac5  \/* AMPERE_1B core Implements ARMv8.7 with CSSC, MTE, SM3\/SM4 extensions *\/\n@@ -173,0 +174,1 @@\n+  constexpr static bool supports_recursive_lightweight_locking() { return true; }\n","filename":"src\/hotspot\/cpu\/aarch64\/vm_version_aarch64.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -3676,1 +3676,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FVM, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FVM, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -3686,1 +3686,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FVM, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FVM, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -3696,1 +3696,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FVM, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FVM, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -3706,1 +3706,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FVM, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FVM, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -4217,1 +4217,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -4601,1 +4601,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -4661,1 +4661,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -5161,0 +5161,27 @@\n+void Assembler::vpmadd52luq(XMMRegister dst, XMMRegister src1, Address src2, int vector_len) {\n+  assert ((VM_Version::supports_avxifma() && vector_len <= AVX_256bit) || (VM_Version::supports_avx512ifma() && (vector_len == AVX_512bit || VM_Version::supports_avx512vl())), \"\");\n+\n+  InstructionMark im(this);\n+  InstructionAttr attributes(vector_len, \/* rex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ false, \/* uses_vl *\/ true);\n+\n+  if (VM_Version::supports_avx512ifma()) {\n+    attributes.set_is_evex_instruction();\n+    attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n+  }\n+  vex_prefix(src2, src1->encoding(), dst->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  emit_int8((unsigned char)0xB4);\n+  emit_operand(dst, src2, 0);\n+}\n+\n+void Assembler::vpmadd52luq(XMMRegister dst, XMMRegister src1, XMMRegister src2, int vector_len) {\n+  assert ((VM_Version::supports_avxifma() && vector_len <= AVX_256bit) || (VM_Version::supports_avx512ifma() && (vector_len == AVX_512bit || VM_Version::supports_avx512vl())), \"\");\n+\n+  InstructionAttr attributes(vector_len, \/* rex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ false, \/* uses_vl *\/ true);\n+\n+  if (VM_Version::supports_avx512ifma()) {\n+    attributes.set_is_evex_instruction();\n+  }\n+  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  emit_int16((unsigned char)0xB4, (0xC0 | encode));\n+}\n+\n@@ -5178,0 +5205,27 @@\n+void Assembler::vpmadd52huq(XMMRegister dst, XMMRegister src1, Address src2, int vector_len) {\n+  assert ((VM_Version::supports_avxifma() && vector_len <= AVX_256bit) || (VM_Version::supports_avx512ifma() && (vector_len == AVX_512bit || VM_Version::supports_avx512vl())), \"\");\n+\n+  InstructionMark im(this);\n+  InstructionAttr attributes(vector_len, \/* rex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ false, \/* uses_vl *\/ true);\n+\n+  if (VM_Version::supports_avx512ifma()) {\n+    attributes.set_is_evex_instruction();\n+    attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n+  }\n+  vex_prefix(src2, src1->encoding(), dst->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  emit_int8((unsigned char)0xB5);\n+  emit_operand(dst, src2, 0);\n+}\n+\n+void Assembler::vpmadd52huq(XMMRegister dst, XMMRegister src1, XMMRegister src2, int vector_len) {\n+  assert ((VM_Version::supports_avxifma() && vector_len <= AVX_256bit) || (VM_Version::supports_avx512ifma() && (vector_len == AVX_512bit || VM_Version::supports_avx512vl())), \"\");\n+\n+  InstructionAttr attributes(vector_len, \/* rex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ false, \/* uses_vl *\/ true);\n+\n+  if (VM_Version::supports_avx512ifma()) {\n+    attributes.set_is_evex_instruction();\n+  }\n+  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  emit_int16((unsigned char)0xB5, (0xC0 | encode));\n+}\n+\n@@ -5419,1 +5473,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -5648,1 +5702,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -6154,1 +6208,1 @@\n-  int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes);\n+  int encode = simd_prefix_and_encode(dst, src, src, VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes);\n@@ -6753,1 +6807,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -6786,1 +6840,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -6797,1 +6851,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -6837,1 +6891,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -6848,1 +6902,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -6866,1 +6920,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -6899,1 +6953,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -6910,1 +6964,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -6934,1 +6988,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -6944,1 +6998,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -6984,1 +7038,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -6995,1 +7049,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -7048,1 +7102,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -7067,1 +7121,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -7085,1 +7139,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -7110,1 +7164,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -7120,1 +7174,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -7146,1 +7200,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -7157,1 +7211,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -7199,1 +7253,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -7210,1 +7264,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -7235,1 +7289,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -7246,1 +7300,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -7374,1 +7428,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -7384,1 +7438,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -7576,1 +7630,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -7586,1 +7640,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -7666,1 +7720,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -7676,1 +7730,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -8152,1 +8206,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -8270,1 +8324,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -8337,1 +8391,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -8368,1 +8422,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -8396,1 +8450,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -8411,1 +8465,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -8440,1 +8494,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -8469,1 +8523,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -8494,1 +8548,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -8616,1 +8670,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -8641,1 +8695,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9176,0 +9230,7 @@\n+void Assembler::vpunpckhqdq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n+  assert(UseAVX > 0, \"requires some form of AVX\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  emit_int16(0x6D, (0xC0 | encode));\n+}\n+\n@@ -9183,0 +9244,7 @@\n+void Assembler::vpunpcklqdq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n+  assert(UseAVX > 0, \"requires some form of AVX\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  emit_int16(0x6C, (0xC0 | encode));\n+}\n+\n@@ -9200,1 +9268,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9227,1 +9295,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9256,1 +9324,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9285,1 +9353,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9314,1 +9382,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9343,1 +9411,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9370,1 +9438,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9397,1 +9465,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9426,1 +9494,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9455,1 +9523,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9484,1 +9552,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9513,1 +9581,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9540,1 +9608,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9569,1 +9637,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9596,1 +9664,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9625,1 +9693,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9654,1 +9722,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9683,1 +9751,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9712,1 +9780,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9742,1 +9810,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9771,1 +9839,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9794,1 +9862,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9809,1 +9877,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9823,1 +9891,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9838,1 +9906,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9853,1 +9921,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9869,1 +9937,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9884,1 +9952,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9900,1 +9968,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -9929,1 +9997,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_NObit);\n@@ -10653,1 +10721,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n@@ -10684,1 +10752,1 @@\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":150,"deletions":82,"binary":false,"changes":232,"status":"modified"},{"patch":"@@ -1920,0 +1920,2 @@\n+  void vpmadd52luq(XMMRegister dst, XMMRegister src1, XMMRegister src2, int vector_len);\n+  void vpmadd52luq(XMMRegister dst, XMMRegister src1, Address src2, int vector_len);\n@@ -1922,0 +1924,2 @@\n+  void vpmadd52huq(XMMRegister dst, XMMRegister src1, XMMRegister src2, int vector_len);\n+  void vpmadd52huq(XMMRegister dst, XMMRegister src1, Address src2, int vector_len);\n@@ -2016,0 +2020,2 @@\n+  void vpunpcklqdq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n+\n@@ -2025,0 +2031,1 @@\n+  void vpunpckhqdq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -342,1 +342,1 @@\n-                              LIR_OprFact::illegalOpr, state_for(x))\n+                              obj.result(), state_for(x))\n@@ -1235,0 +1235,1 @@\n+#ifndef _LP64\n@@ -1237,1 +1238,1 @@\n-LIR_Opr fixed_register_for(BasicType type) {\n+static LIR_Opr fixed_register_for(BasicType type) {\n@@ -1246,0 +1247,1 @@\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRGenerator_x86.cpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"runtime\/globals.hpp\"\n@@ -39,0 +40,3 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/powerOfTwo.hpp\"\n+#include \"utilities\/sizes.hpp\"\n@@ -582,0 +586,1 @@\n+  assert(LockingMode != LM_LIGHTWEIGHT, \"lightweight locking should use fast_lock_lightweight\");\n@@ -633,1 +638,2 @@\n-  } else if (LockingMode == LM_LEGACY) {\n+  } else {\n+    assert(LockingMode == LM_LEGACY, \"must be\");\n@@ -652,4 +658,0 @@\n-  } else {\n-    assert(LockingMode == LM_LIGHTWEIGHT, \"\");\n-    lightweight_lock(objReg, tmpReg, thread, scrReg, NO_COUNT);\n-    jmp(COUNT);\n@@ -786,0 +788,1 @@\n+  assert(LockingMode != LM_LIGHTWEIGHT, \"lightweight locking should use fast_unlock_lightweight\");\n@@ -816,17 +819,0 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    \/\/ If the owner is ANONYMOUS, we need to fix it -  in an outline stub.\n-    testb(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), (int32_t) ObjectMonitor::ANONYMOUS_OWNER);\n-#ifdef _LP64\n-    if (!Compile::current()->output()->in_scratch_emit_size()) {\n-      C2HandleAnonOMOwnerStub* stub = new (Compile::current()->comp_arena()) C2HandleAnonOMOwnerStub(tmpReg, boxReg);\n-      Compile::current()->output()->add_stub(stub);\n-      jcc(Assembler::notEqual, stub->entry());\n-      bind(stub->continuation());\n-    } else\n-#endif\n-    {\n-      \/\/ We can't easily implement this optimization on 32 bit because we don't have a thread register.\n-      \/\/ Call the slow-path instead.\n-      jcc(Assembler::notEqual, NO_COUNT);\n-    }\n-  }\n@@ -954,1 +940,1 @@\n-  if (LockingMode != LM_MONITOR) {\n+  if (LockingMode == LM_LEGACY) {\n@@ -956,9 +942,3 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n-      mov(boxReg, tmpReg);\n-      lightweight_unlock(objReg, boxReg, tmpReg, NO_COUNT);\n-      jmp(COUNT);\n-    } else if (LockingMode == LM_LEGACY) {\n-      movptr(tmpReg, Address (boxReg, 0));      \/\/ re-fetch\n-      lock();\n-      cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n-    }\n+    movptr(tmpReg, Address (boxReg, 0));      \/\/ re-fetch\n+    lock();\n+    cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n@@ -967,0 +947,1 @@\n+\n@@ -987,0 +968,241 @@\n+void C2_MacroAssembler::fast_lock_lightweight(Register obj, Register box, Register rax_reg,\n+                                              Register t, Register thread) {\n+  assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+  assert(rax_reg == rax, \"Used for CAS\");\n+  assert_different_registers(obj, box, rax_reg, t, thread);\n+\n+  \/\/ Handle inflated monitor.\n+  Label inflated;\n+  \/\/ Finish fast lock successfully. ZF value is irrelevant.\n+  Label locked;\n+  \/\/ Finish fast lock unsuccessfully. MUST jump with ZF == 0\n+  Label slow_path;\n+\n+  if (DiagnoseSyncOnValueBasedClasses != 0) {\n+    load_klass(rax_reg, obj, t);\n+    movl(rax_reg, Address(rax_reg, Klass::access_flags_offset()));\n+    testl(rax_reg, JVM_ACC_IS_VALUE_BASED_CLASS);\n+    jcc(Assembler::notZero, slow_path);\n+  }\n+\n+  const Register mark = t;\n+\n+  { \/\/ Lightweight Lock\n+\n+    Label push;\n+\n+    const Register top = box;\n+\n+    \/\/ Load the mark.\n+    movptr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+\n+    \/\/ Prefetch top.\n+    movl(top, Address(thread, JavaThread::lock_stack_top_offset()));\n+\n+    \/\/ Check for monitor (0b10).\n+    testptr(mark, markWord::monitor_value);\n+    jcc(Assembler::notZero, inflated);\n+\n+    \/\/ Check if lock-stack is full.\n+    cmpl(top, LockStack::end_offset() - 1);\n+    jcc(Assembler::greater, slow_path);\n+\n+    \/\/ Check if recursive.\n+    cmpptr(obj, Address(thread, top, Address::times_1, -oopSize));\n+    jccb(Assembler::equal, push);\n+\n+    \/\/ Try to lock. Transition lock bits 0b01 => 0b00\n+    movptr(rax_reg, mark);\n+    orptr(rax_reg, markWord::unlocked_value);\n+    andptr(mark, ~(int32_t)markWord::unlocked_value);\n+    lock(); cmpxchgptr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    jcc(Assembler::notEqual, slow_path);\n+\n+    bind(push);\n+    \/\/ After successful lock, push object on lock-stack.\n+    movptr(Address(thread, top), obj);\n+    addl(Address(thread, JavaThread::lock_stack_top_offset()), oopSize);\n+    jmpb(locked);\n+  }\n+\n+  { \/\/ Handle inflated monitor.\n+    bind(inflated);\n+\n+    const Register tagged_monitor = mark;\n+\n+    \/\/ CAS owner (null => current thread).\n+    xorptr(rax_reg, rax_reg);\n+    lock(); cmpxchgptr(thread, Address(tagged_monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n+    jccb(Assembler::equal, locked);\n+\n+    \/\/ Check if recursive.\n+    cmpptr(thread, rax_reg);\n+    jccb(Assembler::notEqual, slow_path);\n+\n+    \/\/ Recursive.\n+    increment(Address(tagged_monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n+  }\n+\n+  bind(locked);\n+  increment(Address(thread, JavaThread::held_monitor_count_offset()));\n+  \/\/ Set ZF = 1\n+  xorl(rax_reg, rax_reg);\n+\n+#ifdef ASSERT\n+  \/\/ Check that locked label is reached with ZF set.\n+  Label zf_correct;\n+  jccb(Assembler::zero, zf_correct);\n+  stop(\"Fast Lock ZF != 1\");\n+#endif\n+\n+  bind(slow_path);\n+#ifdef ASSERT\n+  \/\/ Check that slow_path label is reached with ZF not set.\n+  jccb(Assembler::notZero, zf_correct);\n+  stop(\"Fast Lock ZF != 0\");\n+  bind(zf_correct);\n+#endif\n+  \/\/ C2 uses the value of ZF to determine the continuation.\n+}\n+\n+void C2_MacroAssembler::fast_unlock_lightweight(Register obj, Register reg_rax, Register t, Register thread) {\n+  assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+  assert(reg_rax == rax, \"Used for CAS\");\n+  assert_different_registers(obj, reg_rax, t);\n+\n+  \/\/ Handle inflated monitor.\n+  Label inflated, inflated_check_lock_stack;\n+  \/\/ Finish fast unlock successfully.  MUST jump with ZF == 1\n+  Label unlocked;\n+\n+  \/\/ Assume success.\n+  decrement(Address(thread, JavaThread::held_monitor_count_offset()));\n+\n+  const Register mark = t;\n+  const Register top = reg_rax;\n+\n+  Label dummy;\n+  C2FastUnlockLightweightStub* stub = nullptr;\n+\n+  if (!Compile::current()->output()->in_scratch_emit_size()) {\n+    stub = new (Compile::current()->comp_arena()) C2FastUnlockLightweightStub(obj, mark, reg_rax, thread);\n+    Compile::current()->output()->add_stub(stub);\n+  }\n+\n+  Label& push_and_slow_path = stub == nullptr ? dummy : stub->push_and_slow_path();\n+  Label& check_successor = stub == nullptr ? dummy : stub->check_successor();\n+\n+  { \/\/ Lightweight Unlock\n+\n+    \/\/ Load top.\n+    movl(top, Address(thread, JavaThread::lock_stack_top_offset()));\n+\n+    \/\/ Prefetch mark.\n+    movptr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+\n+    \/\/ Check if obj is top of lock-stack.\n+    cmpptr(obj, Address(thread, top, Address::times_1, -oopSize));\n+    \/\/ Top of lock stack was not obj. Must be monitor.\n+    jcc(Assembler::notEqual, inflated_check_lock_stack);\n+\n+    \/\/ Pop lock-stack.\n+    DEBUG_ONLY(movptr(Address(thread, top, Address::times_1, -oopSize), 0);)\n+    subl(Address(thread, JavaThread::lock_stack_top_offset()), oopSize);\n+\n+    \/\/ Check if recursive.\n+    cmpptr(obj, Address(thread, top, Address::times_1, -2 * oopSize));\n+    jcc(Assembler::equal, unlocked);\n+\n+    \/\/ We elide the monitor check, let the CAS fail instead.\n+\n+    \/\/ Try to unlock. Transition lock bits 0b00 => 0b01\n+    movptr(reg_rax, mark);\n+    andptr(reg_rax, ~(int32_t)markWord::lock_mask);\n+    orptr(mark, markWord::unlocked_value);\n+    lock(); cmpxchgptr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    jcc(Assembler::notEqual, push_and_slow_path);\n+    jmp(unlocked);\n+  }\n+\n+\n+  { \/\/ Handle inflated monitor.\n+    bind(inflated_check_lock_stack);\n+#ifdef ASSERT\n+    Label check_done;\n+    subl(top, oopSize);\n+    cmpl(top, in_bytes(JavaThread::lock_stack_base_offset()));\n+    jcc(Assembler::below, check_done);\n+    cmpptr(obj, Address(thread, top));\n+    jccb(Assembler::notEqual, inflated_check_lock_stack);\n+    stop(\"Fast Unlock lock on stack\");\n+    bind(check_done);\n+    testptr(mark, markWord::monitor_value);\n+    jccb(Assembler::notZero, inflated);\n+    stop(\"Fast Unlock not monitor\");\n+#endif\n+\n+    bind(inflated);\n+\n+    \/\/ mark contains the tagged ObjectMonitor*.\n+    const Register monitor = mark;\n+\n+#ifndef _LP64\n+    \/\/ Check if recursive.\n+    xorptr(reg_rax, reg_rax);\n+    orptr(reg_rax, Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n+    jcc(Assembler::notZero, check_successor);\n+\n+    \/\/ Check if the entry lists are empty.\n+    movptr(reg_rax, Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n+    orptr(reg_rax, Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n+    jcc(Assembler::notZero, check_successor);\n+\n+    \/\/ Release lock.\n+    movptr(Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), NULL_WORD);\n+#else \/\/ _LP64\n+    Label recursive;\n+\n+    \/\/ Check if recursive.\n+    cmpptr(Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)), 0);\n+    jccb(Assembler::notEqual, recursive);\n+\n+    \/\/ Check if the entry lists are empty.\n+    movptr(reg_rax, Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n+    orptr(reg_rax, Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n+    jcc(Assembler::notZero, check_successor);\n+\n+    \/\/ Release lock.\n+    movptr(Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), NULL_WORD);\n+    jmpb(unlocked);\n+\n+    \/\/ Recursive unlock.\n+    bind(recursive);\n+    decrement(Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n+    xorl(t, t);\n+#endif\n+  }\n+\n+  bind(unlocked);\n+  if (stub != nullptr) {\n+    bind(stub->unlocked_continuation());\n+  }\n+\n+#ifdef ASSERT\n+  \/\/ Check that unlocked label is reached with ZF set.\n+  Label zf_correct;\n+  jccb(Assembler::zero, zf_correct);\n+  stop(\"Fast Unlock ZF != 1\");\n+#endif\n+\n+  if (stub != nullptr) {\n+    bind(stub->slow_path_continuation());\n+  }\n+#ifdef ASSERT\n+  \/\/ Check that stub->continuation() label is reached with ZF not set.\n+  jccb(Assembler::notZero, zf_correct);\n+  stop(\"Fast Unlock ZF != 0\");\n+  bind(zf_correct);\n+#endif\n+  \/\/ C2 uses the value of ZF to determine the continuation.\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":254,"deletions":32,"binary":false,"changes":286,"status":"modified"},{"patch":"@@ -47,0 +47,4 @@\n+  void fast_lock_lightweight(Register obj, Register box, Register rax_reg,\n+                             Register t, Register thread);\n+  void fast_unlock_lightweight(Register obj, Register reg_rax, Register t, Register thread);\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -297,1 +297,1 @@\n-\n+    \/\/ ECX = 0\n@@ -306,0 +306,7 @@\n+    \/\/ ECX = 1\n+    __ movl(rax, 7);\n+    __ movl(rcx, 1);\n+    __ cpuid();\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::sef_cpuid7_ecx1_offset())));\n+    __ movl(Address(rsi, 0), rax);\n+\n@@ -812,1 +819,1 @@\n-    _features = feature_flags(); \/\/ These can be changed by VM settings\n+    _features = _cpuid_info.feature_flags(); \/\/ These can be changed by VM settings\n@@ -962,1 +969,1 @@\n-  if (UseAVX < 2)\n+  if (UseAVX < 2) {\n@@ -964,0 +971,2 @@\n+    _features &= ~CPU_AVX_IFMA;\n+  }\n@@ -993,0 +1002,1 @@\n+      _features &= ~CPU_AVX_IFMA;\n@@ -1350,1 +1360,1 @@\n-  if (supports_avx512ifma() && supports_avx512vlbw() && MaxVectorSize >= 64) {\n+  if ((supports_avx512ifma() && supports_avx512vlbw()) || supports_avxifma())  {\n@@ -2896,1 +2906,1 @@\n-uint64_t VM_Version::feature_flags() {\n+uint64_t VM_Version::CpuidInfo::feature_flags() const {\n@@ -2898,1 +2908,1 @@\n-  if (_cpuid_info.std_cpuid1_edx.bits.cmpxchg8 != 0)\n+  if (std_cpuid1_edx.bits.cmpxchg8 != 0)\n@@ -2900,1 +2910,1 @@\n-  if (_cpuid_info.std_cpuid1_edx.bits.cmov != 0)\n+  if (std_cpuid1_edx.bits.cmov != 0)\n@@ -2902,1 +2912,1 @@\n-  if (_cpuid_info.std_cpuid1_edx.bits.clflush != 0)\n+  if (std_cpuid1_edx.bits.clflush != 0)\n@@ -2910,2 +2920,2 @@\n-  if (_cpuid_info.std_cpuid1_edx.bits.fxsr != 0 || (is_amd_family() &&\n-      _cpuid_info.ext_cpuid1_edx.bits.fxsr != 0))\n+  if (std_cpuid1_edx.bits.fxsr != 0 || (is_amd_family() &&\n+      ext_cpuid1_edx.bits.fxsr != 0))\n@@ -2916,2 +2926,2 @@\n-  if (_cpuid_info.std_cpuid1_edx.bits.mmx != 0 || (is_amd_family() &&\n-      _cpuid_info.ext_cpuid1_edx.bits.mmx != 0))\n+  if (std_cpuid1_edx.bits.mmx != 0 || (is_amd_family() &&\n+      ext_cpuid1_edx.bits.mmx != 0))\n@@ -2919,1 +2929,1 @@\n-  if (_cpuid_info.std_cpuid1_edx.bits.sse != 0)\n+  if (std_cpuid1_edx.bits.sse != 0)\n@@ -2921,1 +2931,1 @@\n-  if (_cpuid_info.std_cpuid1_edx.bits.sse2 != 0)\n+  if (std_cpuid1_edx.bits.sse2 != 0)\n@@ -2923,1 +2933,1 @@\n-  if (_cpuid_info.std_cpuid1_ecx.bits.sse3 != 0)\n+  if (std_cpuid1_ecx.bits.sse3 != 0)\n@@ -2925,1 +2935,1 @@\n-  if (_cpuid_info.std_cpuid1_ecx.bits.ssse3 != 0)\n+  if (std_cpuid1_ecx.bits.ssse3 != 0)\n@@ -2927,1 +2937,1 @@\n-  if (_cpuid_info.std_cpuid1_ecx.bits.sse4_1 != 0)\n+  if (std_cpuid1_ecx.bits.sse4_1 != 0)\n@@ -2929,1 +2939,1 @@\n-  if (_cpuid_info.std_cpuid1_ecx.bits.sse4_2 != 0)\n+  if (std_cpuid1_ecx.bits.sse4_2 != 0)\n@@ -2931,1 +2941,1 @@\n-  if (_cpuid_info.std_cpuid1_ecx.bits.popcnt != 0)\n+  if (std_cpuid1_ecx.bits.popcnt != 0)\n@@ -2933,4 +2943,4 @@\n-  if (_cpuid_info.std_cpuid1_ecx.bits.avx != 0 &&\n-      _cpuid_info.std_cpuid1_ecx.bits.osxsave != 0 &&\n-      _cpuid_info.xem_xcr0_eax.bits.sse != 0 &&\n-      _cpuid_info.xem_xcr0_eax.bits.ymm != 0) {\n+  if (std_cpuid1_ecx.bits.avx != 0 &&\n+      std_cpuid1_ecx.bits.osxsave != 0 &&\n+      xem_xcr0_eax.bits.sse != 0 &&\n+      xem_xcr0_eax.bits.ymm != 0) {\n@@ -2939,1 +2949,1 @@\n-    if (_cpuid_info.std_cpuid1_ecx.bits.f16c != 0)\n+    if (std_cpuid1_ecx.bits.f16c != 0)\n@@ -2941,1 +2951,1 @@\n-    if (_cpuid_info.sef_cpuid7_ebx.bits.avx2 != 0)\n+    if (sef_cpuid7_ebx.bits.avx2 != 0) {\n@@ -2943,4 +2953,7 @@\n-    if (_cpuid_info.sef_cpuid7_ebx.bits.avx512f != 0 &&\n-        _cpuid_info.xem_xcr0_eax.bits.opmask != 0 &&\n-        _cpuid_info.xem_xcr0_eax.bits.zmm512 != 0 &&\n-        _cpuid_info.xem_xcr0_eax.bits.zmm32 != 0) {\n+      if (sef_cpuid7_ecx1_eax.bits.avx_ifma != 0)\n+        result |= CPU_AVX_IFMA;\n+    }\n+    if (sef_cpuid7_ebx.bits.avx512f != 0 &&\n+        xem_xcr0_eax.bits.opmask != 0 &&\n+        xem_xcr0_eax.bits.zmm512 != 0 &&\n+        xem_xcr0_eax.bits.zmm32 != 0) {\n@@ -2948,1 +2961,1 @@\n-      if (_cpuid_info.sef_cpuid7_ebx.bits.avx512cd != 0)\n+      if (sef_cpuid7_ebx.bits.avx512cd != 0)\n@@ -2950,1 +2963,1 @@\n-      if (_cpuid_info.sef_cpuid7_ebx.bits.avx512dq != 0)\n+      if (sef_cpuid7_ebx.bits.avx512dq != 0)\n@@ -2952,1 +2965,1 @@\n-      if (_cpuid_info.sef_cpuid7_ebx.bits.avx512ifma != 0)\n+      if (sef_cpuid7_ebx.bits.avx512ifma != 0)\n@@ -2954,1 +2967,1 @@\n-      if (_cpuid_info.sef_cpuid7_ebx.bits.avx512pf != 0)\n+      if (sef_cpuid7_ebx.bits.avx512pf != 0)\n@@ -2956,1 +2969,1 @@\n-      if (_cpuid_info.sef_cpuid7_ebx.bits.avx512er != 0)\n+      if (sef_cpuid7_ebx.bits.avx512er != 0)\n@@ -2958,1 +2971,1 @@\n-      if (_cpuid_info.sef_cpuid7_ebx.bits.avx512bw != 0)\n+      if (sef_cpuid7_ebx.bits.avx512bw != 0)\n@@ -2960,1 +2973,1 @@\n-      if (_cpuid_info.sef_cpuid7_ebx.bits.avx512vl != 0)\n+      if (sef_cpuid7_ebx.bits.avx512vl != 0)\n@@ -2962,1 +2975,1 @@\n-      if (_cpuid_info.sef_cpuid7_ecx.bits.avx512_vpopcntdq != 0)\n+      if (sef_cpuid7_ecx.bits.avx512_vpopcntdq != 0)\n@@ -2964,1 +2977,1 @@\n-      if (_cpuid_info.sef_cpuid7_ecx.bits.avx512_vpclmulqdq != 0)\n+      if (sef_cpuid7_ecx.bits.avx512_vpclmulqdq != 0)\n@@ -2966,1 +2979,1 @@\n-      if (_cpuid_info.sef_cpuid7_ecx.bits.vaes != 0)\n+      if (sef_cpuid7_ecx.bits.vaes != 0)\n@@ -2968,1 +2981,1 @@\n-      if (_cpuid_info.sef_cpuid7_ecx.bits.gfni != 0)\n+      if (sef_cpuid7_ecx.bits.gfni != 0)\n@@ -2970,1 +2983,1 @@\n-      if (_cpuid_info.sef_cpuid7_ecx.bits.avx512_vnni != 0)\n+      if (sef_cpuid7_ecx.bits.avx512_vnni != 0)\n@@ -2972,1 +2985,1 @@\n-      if (_cpuid_info.sef_cpuid7_ecx.bits.avx512_bitalg != 0)\n+      if (sef_cpuid7_ecx.bits.avx512_bitalg != 0)\n@@ -2974,1 +2987,1 @@\n-      if (_cpuid_info.sef_cpuid7_ecx.bits.avx512_vbmi != 0)\n+      if (sef_cpuid7_ecx.bits.avx512_vbmi != 0)\n@@ -2976,1 +2989,1 @@\n-      if (_cpuid_info.sef_cpuid7_ecx.bits.avx512_vbmi2 != 0)\n+      if (sef_cpuid7_ecx.bits.avx512_vbmi2 != 0)\n@@ -2980,1 +2993,1 @@\n-  if (_cpuid_info.std_cpuid1_ecx.bits.hv != 0)\n+  if (std_cpuid1_ecx.bits.hv != 0)\n@@ -2982,1 +2995,1 @@\n-  if (_cpuid_info.sef_cpuid7_ebx.bits.bmi1 != 0)\n+  if (sef_cpuid7_ebx.bits.bmi1 != 0)\n@@ -2984,1 +2997,1 @@\n-  if (_cpuid_info.std_cpuid1_edx.bits.tsc != 0)\n+  if (std_cpuid1_edx.bits.tsc != 0)\n@@ -2986,1 +2999,1 @@\n-  if (_cpuid_info.ext_cpuid7_edx.bits.tsc_invariance != 0)\n+  if (ext_cpuid7_edx.bits.tsc_invariance != 0)\n@@ -2988,1 +3001,1 @@\n-  if (_cpuid_info.std_cpuid1_ecx.bits.aes != 0)\n+  if (std_cpuid1_ecx.bits.aes != 0)\n@@ -2990,1 +3003,1 @@\n-  if (_cpuid_info.sef_cpuid7_ebx.bits.erms != 0)\n+  if (sef_cpuid7_ebx.bits.erms != 0)\n@@ -2992,1 +3005,1 @@\n-  if (_cpuid_info.sef_cpuid7_edx.bits.fast_short_rep_mov != 0)\n+  if (sef_cpuid7_edx.bits.fast_short_rep_mov != 0)\n@@ -2994,1 +3007,1 @@\n-  if (_cpuid_info.std_cpuid1_ecx.bits.clmul != 0)\n+  if (std_cpuid1_ecx.bits.clmul != 0)\n@@ -2996,1 +3009,1 @@\n-  if (_cpuid_info.sef_cpuid7_ebx.bits.rtm != 0)\n+  if (sef_cpuid7_ebx.bits.rtm != 0)\n@@ -2998,1 +3011,1 @@\n-  if (_cpuid_info.sef_cpuid7_ebx.bits.adx != 0)\n+  if (sef_cpuid7_ebx.bits.adx != 0)\n@@ -3000,1 +3013,1 @@\n-  if (_cpuid_info.sef_cpuid7_ebx.bits.bmi2 != 0)\n+  if (sef_cpuid7_ebx.bits.bmi2 != 0)\n@@ -3002,1 +3015,1 @@\n-  if (_cpuid_info.sef_cpuid7_ebx.bits.sha != 0)\n+  if (sef_cpuid7_ebx.bits.sha != 0)\n@@ -3004,1 +3017,1 @@\n-  if (_cpuid_info.std_cpuid1_ecx.bits.fma != 0)\n+  if (std_cpuid1_ecx.bits.fma != 0)\n@@ -3006,1 +3019,1 @@\n-  if (_cpuid_info.sef_cpuid7_ebx.bits.clflushopt != 0)\n+  if (sef_cpuid7_ebx.bits.clflushopt != 0)\n@@ -3008,1 +3021,1 @@\n-  if (_cpuid_info.ext_cpuid1_edx.bits.rdtscp != 0)\n+  if (ext_cpuid1_edx.bits.rdtscp != 0)\n@@ -3010,1 +3023,1 @@\n-  if (_cpuid_info.sef_cpuid7_ecx.bits.rdpid != 0)\n+  if (sef_cpuid7_ecx.bits.rdpid != 0)\n@@ -3015,2 +3028,2 @@\n-    if ((_cpuid_info.ext_cpuid1_edx.bits.tdnow != 0) ||\n-        (_cpuid_info.ext_cpuid1_ecx.bits.prefetchw != 0))\n+    if ((ext_cpuid1_edx.bits.tdnow != 0) ||\n+        (ext_cpuid1_ecx.bits.prefetchw != 0))\n@@ -3018,1 +3031,1 @@\n-    if (_cpuid_info.ext_cpuid1_ecx.bits.lzcnt != 0)\n+    if (ext_cpuid1_ecx.bits.lzcnt != 0)\n@@ -3020,1 +3033,1 @@\n-    if (_cpuid_info.ext_cpuid1_ecx.bits.sse4a != 0)\n+    if (ext_cpuid1_ecx.bits.sse4a != 0)\n@@ -3026,1 +3039,1 @@\n-    if (_cpuid_info.ext_cpuid1_ecx.bits.lzcnt != 0) {\n+    if (ext_cpuid1_ecx.bits.lzcnt != 0) {\n@@ -3029,1 +3042,1 @@\n-    if (_cpuid_info.ext_cpuid1_ecx.bits.prefetchw != 0) {\n+    if (ext_cpuid1_ecx.bits.prefetchw != 0) {\n@@ -3032,1 +3045,1 @@\n-    if (_cpuid_info.sef_cpuid7_ebx.bits.clwb != 0) {\n+    if (sef_cpuid7_ebx.bits.clwb != 0) {\n@@ -3035,1 +3048,1 @@\n-    if (_cpuid_info.sef_cpuid7_edx.bits.serialize != 0)\n+    if (sef_cpuid7_edx.bits.serialize != 0)\n@@ -3044,1 +3057,1 @@\n-    if (_cpuid_info.ext_cpuid1_ecx.bits.lzcnt != 0) {\n+    if (ext_cpuid1_ecx.bits.lzcnt != 0) {\n@@ -3047,1 +3060,1 @@\n-    if (_cpuid_info.ext_cpuid1_ecx.bits.prefetchw != 0) {\n+    if (ext_cpuid1_ecx.bits.prefetchw != 0) {\n@@ -3053,1 +3066,1 @@\n-  if (_cpuid_info.sef_cpuid7_ecx.bits.pku != 0) {\n+  if (sef_cpuid7_ecx.bits.pku != 0) {\n@@ -3056,1 +3069,1 @@\n-  if (_cpuid_info.sef_cpuid7_ecx.bits.ospke != 0) {\n+  if (sef_cpuid7_ecx.bits.ospke != 0) {\n@@ -3061,1 +3074,1 @@\n-  if (_cpuid_info.sef_cpuid7_ecx.bits.cet_ss != 0) {\n+  if (sef_cpuid7_ecx.bits.cet_ss != 0) {\n@@ -3064,1 +3077,1 @@\n-  if (_cpuid_info.sef_cpuid7_edx.bits.cet_ibt != 0) {\n+  if (sef_cpuid7_edx.bits.cet_ibt != 0) {\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":87,"deletions":74,"binary":false,"changes":161,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -284,0 +284,9 @@\n+  union SefCpuid7Ecx1Eax {\n+    uint32_t value;\n+    struct {\n+      uint32_t             : 23,\n+                  avx_ifma : 1,\n+                           : 8;\n+    } bits;\n+  };\n+\n@@ -396,1 +405,2 @@\n-    decl(AVX512_FP16,       \"avx512_fp16\",       59) \/* AVX512 FP16 ISA support*\/\n+    decl(AVX_IFMA,          \"avx_ifma\",          59) \/* 256-bit VEX-coded variant of AVX512-IFMA*\/ \\\n+    decl(AVX512_FP16,       \"avx512_fp16\",       60) \/* AVX512 FP16 ISA support*\/\n@@ -434,1 +444,2 @@\n-  struct CpuidInfo {\n+  class CpuidInfo {\n+  public:\n@@ -454,0 +465,1 @@\n+    \/\/ ECX = 0 before calling cpuid()\n@@ -458,0 +470,2 @@\n+    \/\/ ECX = 1 before calling cpuid()\n+    SefCpuid7Ecx1Eax sef_cpuid7_ecx1_eax;\n@@ -528,0 +542,25 @@\n+\n+    uint64_t feature_flags() const;\n+\n+    \/\/ Asserts\n+    void assert_is_initialized() const {\n+      assert(std_cpuid1_eax.bits.family != 0, \"VM_Version not initialized\");\n+    }\n+\n+    \/\/ Extractors\n+    uint32_t extended_cpu_family() const {\n+      uint32_t result = std_cpuid1_eax.bits.family;\n+      result += std_cpuid1_eax.bits.ext_family;\n+      return result;\n+    }\n+\n+    uint32_t extended_cpu_model() const {\n+      uint32_t result = std_cpuid1_eax.bits.model;\n+      result |= std_cpuid1_eax.bits.ext_model << 4;\n+      return result;\n+    }\n+\n+    uint32_t cpu_stepping() const {\n+      uint32_t result = std_cpuid1_eax.bits.stepping;\n+      return result;\n+    }\n@@ -535,17 +574,0 @@\n-  static uint32_t extended_cpu_family() {\n-    uint32_t result = _cpuid_info.std_cpuid1_eax.bits.family;\n-    result += _cpuid_info.std_cpuid1_eax.bits.ext_family;\n-    return result;\n-  }\n-\n-  static uint32_t extended_cpu_model() {\n-    uint32_t result = _cpuid_info.std_cpuid1_eax.bits.model;\n-    result |= _cpuid_info.std_cpuid1_eax.bits.ext_model << 4;\n-    return result;\n-  }\n-\n-  static uint32_t cpu_stepping() {\n-    uint32_t result = _cpuid_info.std_cpuid1_eax.bits.stepping;\n-    return result;\n-  }\n-\n@@ -559,1 +581,0 @@\n-  static uint64_t feature_flags();\n@@ -569,0 +590,1 @@\n+  static ByteSize sef_cpuid7_ecx1_offset() { return byte_offset_of(CpuidInfo, sef_cpuid7_ecx1_eax); }\n@@ -600,5 +622,0 @@\n-  \/\/ Asserts\n-  static void assert_is_initialized() {\n-    assert(_cpuid_info.std_cpuid1_eax.bits.family != 0, \"VM_Version not initialized\");\n-  }\n-\n@@ -620,0 +637,4 @@\n+  static void     assert_is_initialized() { _cpuid_info.assert_is_initialized(); }\n+  static uint32_t extended_cpu_family()   { return _cpuid_info.extended_cpu_family(); }\n+  static uint32_t extended_cpu_model()    { return _cpuid_info.extended_cpu_model(); }\n+  static uint32_t cpu_stepping()          { return _cpuid_info.cpu_stepping(); }\n@@ -676,0 +697,1 @@\n+  static bool supports_avxifma()      { return (_features & CPU_AVX_IFMA) != 0; }\n@@ -777,0 +799,4 @@\n+  constexpr static bool supports_recursive_lightweight_locking() {\n+    return true;\n+  }\n+\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.hpp","additions":52,"deletions":26,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -1361,1 +1361,1 @@\n-Assembler::Width widthForType(BasicType bt) {\n+static Assembler::Width widthForType(BasicType bt) {\n@@ -3933,0 +3933,3 @@\n+    if ((UseAVX == 0) && ($dst$$XMMRegister != $src$$XMMRegister)) {\n+      __ pxor($dst$$XMMRegister, $dst$$XMMRegister);\n+    }\n@@ -3938,11 +3941,0 @@\n-instruct roundD_mem(legRegD dst, memory src, immU8 rmode) %{\n-  match(Set dst (RoundDoubleMode (LoadD src) rmode));\n-  format %{ \"roundsd $dst,$src\" %}\n-  ins_cost(150);\n-  ins_encode %{\n-    assert(UseSSE >= 4, \"required\");\n-    __ roundsd($dst$$XMMRegister, $src$$Address, $rmode$$constant);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n@@ -9732,15 +9724,0 @@\n-instruct vlshift_mem_masked(vec dst, memory src2, kReg mask) %{\n-  match(Set dst (LShiftVS (Binary dst (LoadVector src2)) mask));\n-  match(Set dst (LShiftVI (Binary dst (LoadVector src2)) mask));\n-  match(Set dst (LShiftVL (Binary dst (LoadVector src2)) mask));\n-  format %{ \"vplshift_masked $dst, $dst, $src2, $mask\\t! lshift masked operation\" %}\n-  ins_encode %{\n-    int vlen_enc = vector_length_encoding(this);\n-    BasicType bt = Matcher::vector_element_basic_type(this);\n-    int opc = this->ideal_Opcode();\n-    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n-                   $dst$$XMMRegister, $src2$$Address, true, vlen_enc);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n@@ -9794,15 +9771,0 @@\n-instruct vrshift_mem_masked(vec dst, memory src2, kReg mask) %{\n-  match(Set dst (RShiftVS (Binary dst (LoadVector src2)) mask));\n-  match(Set dst (RShiftVI (Binary dst (LoadVector src2)) mask));\n-  match(Set dst (RShiftVL (Binary dst (LoadVector src2)) mask));\n-  format %{ \"vprshift_masked $dst, $dst, $src2, $mask\\t! rshift masked operation\" %}\n-  ins_encode %{\n-    int vlen_enc = vector_length_encoding(this);\n-    BasicType bt = Matcher::vector_element_basic_type(this);\n-    int opc = this->ideal_Opcode();\n-    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n-                   $dst$$XMMRegister, $src2$$Address, true, vlen_enc);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n@@ -9856,15 +9818,0 @@\n-instruct vurshift_mem_masked(vec dst, memory src2, kReg mask) %{\n-  match(Set dst (URShiftVS (Binary dst (LoadVector src2)) mask));\n-  match(Set dst (URShiftVI (Binary dst (LoadVector src2)) mask));\n-  match(Set dst (URShiftVL (Binary dst (LoadVector src2)) mask));\n-  format %{ \"vpurshift_masked $dst, $dst, $src2, $mask\\t! urshift masked operation\" %}\n-  ins_encode %{\n-    int vlen_enc = vector_length_encoding(this);\n-    BasicType bt = Matcher::vector_element_basic_type(this);\n-    int opc = this->ideal_Opcode();\n-    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n-                   $dst$$XMMRegister, $src2$$Address, true, vlen_enc);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":4,"deletions":57,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -1502,0 +1502,18 @@\n+void InstructForm::forms_do(FormClosure *f) {\n+  if (_cisc_spill_alternate) f->do_form(_cisc_spill_alternate);\n+  if (_short_branch_form) f->do_form(_short_branch_form);\n+  _localNames.forms_do(f);\n+  if (_matrule) f->do_form(_matrule);\n+  if (_opcode) f->do_form(_opcode);\n+  if (_insencode) f->do_form(_insencode);\n+  if (_constant) f->do_form(_constant);\n+  if (_attribs) f->do_form(_attribs);\n+  if (_predicate) f->do_form(_predicate);\n+  _effects.forms_do(f);\n+  if (_exprule) f->do_form(_exprule);\n+  if (_rewrule) f->do_form(_rewrule);\n+  if (_format) f->do_form(_format);\n+  if (_peephole) f->do_form(_peephole);\n+  assert(_components.count() == 0, \"skip components\");\n+}\n+\n@@ -1619,0 +1637,8 @@\n+\n+void EncodeForm::forms_do(FormClosure* f) {\n+  const char *name;\n+  for (_eclasses.reset(); (name = _eclasses.iter()) != nullptr;) {\n+    f->do_form((EncClass*)_encClass[name]);\n+  }\n+}\n+\n@@ -1709,0 +1735,9 @@\n+void EncClass::forms_do(FormClosure *f) {\n+  _parameter_type.reset();\n+  const char *type = _parameter_type.iter();\n+  for ( ; type != nullptr ; type = _parameter_type.iter() ) {\n+    f->do_form_by_name(type);\n+  }\n+  _localNames.forms_do(f);\n+}\n+\n@@ -1839,0 +1874,9 @@\n+void InsEncode::forms_do(FormClosure *f) {\n+  _encoding.reset();\n+  NameAndList *encoding = (NameAndList*)_encoding.iter();\n+  for( ; encoding != nullptr; encoding = (NameAndList*)_encoding.iter() ) {\n+    \/\/ just check name, other operands will be checked as instruction parameters\n+    f->do_form_by_name(encoding->name());\n+  }\n+}\n+\n@@ -1972,0 +2016,13 @@\n+void ExpandRule::forms_do(FormClosure *f) {\n+  NameAndList *expand_instr = nullptr;\n+  \/\/ Iterate over the instructions 'node' expands into\n+  for(reset_instructions(); (expand_instr = iter_instructions()) != nullptr; ) {\n+    f->do_form_by_name(expand_instr->name());\n+  }\n+  _newopers.reset();\n+  const char* oper = _newopers.iter();\n+  for(; oper != nullptr; oper = _newopers.iter()) {\n+    f->do_form_by_name(oper);\n+  }\n+}\n+\n@@ -1988,0 +2045,6 @@\n+void RewriteRule::forms_do(FormClosure *f) {\n+  if (_condition) f->do_form(_condition);\n+  if (_instrs) f->do_form(_instrs);\n+  if (_opers) f->do_form(_opers);\n+}\n+\n@@ -2070,0 +2133,7 @@\n+void OpClassForm::forms_do(FormClosure* f) {\n+  const char *name;\n+  for(_oplst.reset(); (name = _oplst.iter()) != nullptr;) {\n+    f->do_form_by_name(name);\n+  }\n+}\n+\n@@ -2695,0 +2765,16 @@\n+void OperandForm::forms_do(FormClosure* f) {\n+  if (_matrule)    f->do_form(_matrule);\n+  if (_interface)  f->do_form(_interface);\n+  if (_attribs)    f->do_form(_attribs);\n+  if (_predicate)  f->do_form(_predicate);\n+  if (_constraint) f->do_form(_constraint);\n+  if (_construct)  f->do_form(_construct);\n+  if (_format)     f->do_form(_format);\n+  _localNames.forms_do(f);\n+  const char* opclass = nullptr;\n+  for ( _classes.reset(); (opclass = _classes.iter()) != nullptr; ) {\n+    f->do_form_by_name(opclass);\n+  }\n+  assert(_components.count() == 0, \"skip _compnets\");\n+}\n+\n@@ -2716,0 +2802,4 @@\n+void Constraint::forms_do(FormClosure *f) {\n+  f->do_form_by_name(_arg);\n+}\n+\n@@ -3543,0 +3633,6 @@\n+void MatchNode::forms_do(FormClosure *f) {\n+  f->do_form_by_name(_name);\n+  if (_lChild) f->do_form(_lChild);\n+  if (_rChild) f->do_form(_rChild);\n+}\n+\n@@ -3612,0 +3708,1 @@\n+\n@@ -4339,0 +4436,12 @@\n+void MatchRule::forms_do(FormClosure* f) {\n+  \/\/ keep sync with MatchNode::forms_do\n+  f->do_form_by_name(_name);\n+  if (_lChild) f->do_form(_lChild);\n+  if (_rChild) f->do_form(_rChild);\n+\n+  \/\/ handle next rule\n+  if (_next) {\n+    f->do_form(_next);\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":109,"deletions":0,"binary":false,"changes":109,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -189,1 +189,1 @@\n-    \/\/ See \"TEMP notes: What are these?\" in archiveHeapWriter.hpp\n+    \/\/ Used by CDSHeapVerifier.\n@@ -194,0 +194,6 @@\n+\n+    \/\/ One or more fields in this object are pointing to non-null oops.\n+    bool _has_oop_pointers;\n+\n+    \/\/ One or more fields in this object are pointing to MetaspaceObj\n+    bool _has_native_pointers;\n@@ -195,1 +201,1 @@\n-    CachedOopInfo(oop orig_referrer)\n+    CachedOopInfo(oop orig_referrer, bool has_oop_pointers)\n@@ -197,1 +203,3 @@\n-        _buffer_offset(0) {}\n+        _buffer_offset(0),\n+        _has_oop_pointers(has_oop_pointers),\n+        _has_native_pointers(false) {}\n@@ -201,0 +209,3 @@\n+    bool has_oop_pointers()         const { return _has_oop_pointers; }\n+    bool has_native_pointers()      const { return _has_native_pointers; }\n+    void set_has_native_pointers()        { _has_native_pointers = true; }\n@@ -240,1 +251,1 @@\n-  static CachedOopInfo make_cached_oop_info();\n+  static CachedOopInfo make_cached_oop_info(oop obj);\n@@ -371,0 +382,3 @@\n+  static bool has_oop_pointers(oop obj);\n+  static bool has_native_pointers(oop obj);\n+  static void set_has_native_pointers(oop obj);\n","filename":"src\/hotspot\/share\/cds\/heapShared.hpp","additions":19,"deletions":5,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -823,1 +823,1 @@\n-      && super_type->super() != nullptr \/* Super is not j.l.Object *\/) {\n+      && super_type->name() != vmSymbols::java_lang_Object()) {\n@@ -3372,2 +3372,2 @@\n-u2 ClassFileParser::parse_classfile_preload_attribute(const ClassFileStream* const cfs,\n-                                                                   const u1* const preload_attribute_start,\n+u2 ClassFileParser::parse_classfile_loadable_descriptors_attribute(const ClassFileStream* const cfs,\n+                                                                   const u1* const loadable_descriptors_attribute_start,\n@@ -3377,2 +3377,2 @@\n-  if (preload_attribute_start != nullptr) {\n-    cfs->set_current(preload_attribute_start);\n+  if (loadable_descriptors_attribute_start != nullptr) {\n+    cfs->set_current(loadable_descriptors_attribute_start);\n@@ -3383,2 +3383,2 @@\n-  Array<u2>* const preload_classes = MetadataFactory::new_array<u2>(_loader_data, size, CHECK_0);\n-  _preload_classes = preload_classes;\n+  Array<u2>* const loadable_descriptors = MetadataFactory::new_array<u2>(_loader_data, size, CHECK_0);\n+  _loadable_descriptors = loadable_descriptors;\n@@ -3389,1 +3389,1 @@\n-      const u2 class_info_index = cfs->get_u2_fast();\n+      const u2 descriptor_index = cfs->get_u2_fast();\n@@ -3391,4 +3391,14 @@\n-        valid_klass_reference_at(class_info_index),\n-        \"Preload class_info_index %u has bad constant type in class file %s\",\n-        class_info_index, CHECK_0);\n-      preload_classes->at_put(index++, class_info_index);\n+        valid_symbol_at(descriptor_index),\n+        \"LoadableDescriptors descriptor_index %u has bad constant type in class file %s\",\n+        descriptor_index, CHECK_0);\n+      Symbol* descriptor = _cp->symbol_at(descriptor_index);\n+      bool valid = legal_field_signature(descriptor, CHECK_0);\n+      if(!valid) {\n+        ResourceMark rm(THREAD);\n+        Exceptions::fthrow(THREAD_AND_LOCATION,\n+          vmSymbols::java_lang_ClassFormatError(),\n+          \"Descriptor from LoadableDescriptors attribute at index \\\"%d\\\" in class %s has illegal signature \\\"%s\\\"\",\n+          descriptor_index, _class_name->as_C_string(), descriptor->as_C_string());\n+        return 0;\n+      }\n+      loadable_descriptors->at_put(index++, descriptor_index);\n@@ -3567,2 +3577,1 @@\n-      RecordComponent::allocate(_loader_data, name_index, descriptor_index,\n-                                attributes_count, generic_sig_index,\n+      RecordComponent::allocate(_loader_data, name_index, descriptor_index, generic_sig_index,\n@@ -3689,2 +3698,2 @@\n-  \/\/ Set _preload_classes attribute to default sentinel\n-  _preload_classes = Universe::the_empty_short_array();\n+  \/\/ Set _loadable_descriptors attribute to default sentinel\n+  _loadable_descriptors = Universe::the_empty_short_array();\n@@ -3697,1 +3706,1 @@\n-  bool parsed_preload_attribute = false;\n+  bool parsed_loadable_descriptors_attribute = false;\n@@ -3723,2 +3732,2 @@\n-  const u1* preload_attribute_start = nullptr;\n-  u4  preload_attribute_length = 0;\n+  const u1* loadable_descriptors_attribute_start = nullptr;\n+  u4  loadable_descriptors_attribute_length = 0;\n@@ -3951,3 +3960,3 @@\n-            if (EnableValhalla && tag == vmSymbols::tag_preload()) {\n-              if (parsed_preload_attribute) {\n-                classfile_parse_error(\"Multiple Preload attributes in class file %s\", CHECK);\n+            if (EnableValhalla && tag == vmSymbols::tag_loadable_descriptors()) {\n+              if (parsed_loadable_descriptors_attribute) {\n+                classfile_parse_error(\"Multiple LoadableDescriptors attributes in class file %s\", CHECK);\n@@ -3956,3 +3965,3 @@\n-              parsed_preload_attribute = true;\n-              preload_attribute_start = cfs->current();\n-              preload_attribute_length = attribute_length;\n+              parsed_loadable_descriptors_attribute = true;\n+              loadable_descriptors_attribute_start = cfs->current();\n+              loadable_descriptors_attribute_length = attribute_length;\n@@ -4040,2 +4049,2 @@\n-  if (parsed_preload_attribute) {\n-    const u2 num_classes = parse_classfile_preload_attribute(\n+  if (parsed_loadable_descriptors_attribute) {\n+    const u2 num_classes = parse_classfile_loadable_descriptors_attribute(\n@@ -4043,1 +4052,1 @@\n-                            preload_attribute_start,\n+                            loadable_descriptors_attribute_start,\n@@ -4047,2 +4056,2 @@\n-        preload_attribute_length == sizeof(num_classes) + sizeof(u2) * num_classes,\n-        \"Wrong Preload attribute length in class file %s\", CHECK);\n+        loadable_descriptors_attribute_length == sizeof(num_classes) + sizeof(u2) * num_classes,\n+        \"Wrong LoadableDescriptors attribute length in class file %s\", CHECK);\n@@ -4117,1 +4126,1 @@\n-  this_klass->set_preload_classes(_preload_classes);\n+  this_klass->set_loadable_descriptors(_loadable_descriptors);\n@@ -4308,19 +4317,0 @@\n-void ClassFileParser::throwInlineTypeLimitation(THREAD_AND_LOCATION_DECL,\n-                                                const char* msg,\n-                                                const Symbol* name,\n-                                                const Symbol* sig) const {\n-\n-  ResourceMark rm(THREAD);\n-  if (name == nullptr || sig == nullptr) {\n-    Exceptions::fthrow(THREAD_AND_LOCATION_ARGS,\n-        vmSymbols::java_lang_ClassFormatError(),\n-        \"class: %s - %s\", _class_name->as_C_string(), msg);\n-  }\n-  else {\n-    Exceptions::fthrow(THREAD_AND_LOCATION_ARGS,\n-        vmSymbols::java_lang_ClassFormatError(),\n-        \"\\\"%s\\\" sig: \\\"%s\\\" class: %s - %s\", name->as_C_string(), sig->as_C_string(),\n-        _class_name->as_C_string(), msg);\n-  }\n-}\n-\n@@ -4361,5 +4351,0 @@\n-      if (ik->is_inline_klass()) {\n-        JavaThread *THREAD = JavaThread::current();\n-        throwInlineTypeLimitation(THREAD_AND_LOCATION, \"Inline Types do not support Cloneable\");\n-        return;\n-      }\n@@ -4407,1 +4392,1 @@\n-  \/\/ Inline types are only supported by class file version 61.65535 and later\n+  \/\/ Inline types are only supported by class file version 67.65535 and later\n@@ -4733,0 +4718,2 @@\n+  const bool valid_value_class = is_identity || is_interface ||\n+                                 (supports_inline_types() && (!is_identity && (is_abstract || is_final)));\n@@ -4737,1 +4724,2 @@\n-      (!is_interface && major_gte_1_5 && is_annotation)) {\n+      (!is_interface && major_gte_1_5 && is_annotation) ||\n+      (!valid_value_class)) {\n@@ -4740,1 +4728,3 @@\n-    if (!is_identity)  class_note = \" (a value class)\";\n+    if (!valid_value_class) {\n+      class_note = \" (a value class must be final or else abstract)\";\n+    }\n@@ -4840,1 +4830,0 @@\n-  const bool is_abstract = class_access_flags.is_abstract();\n@@ -4844,0 +4833,7 @@\n+  const char* error_msg = \"\";\n+\n+  \/\/ There is some overlap in the checks that apply, for example interface fields\n+  \/\/ must be static, static fields can't be strict, and therefore interfaces can't\n+  \/\/ have strict fields. So we don't have to check every possible invalid combination\n+  \/\/ individually as long as all are covered. Once we have found an illegal combination\n+  \/\/ we can stop checking.\n@@ -4848,0 +4844,1 @@\n+      error_msg = \"field cannot be strict and static\";\n@@ -4849,1 +4846,1 @@\n-    if (is_strict && !is_final) {\n+    else if (is_strict && !is_final) {\n@@ -4851,0 +4848,1 @@\n+      error_msg = \"strict field must be final\";\n@@ -4854,11 +4852,13 @@\n-  if (is_interface) {\n-    if (!is_public || !is_static || !is_final || is_private ||\n-        is_protected || is_volatile || is_transient ||\n-        (major_gte_1_5 && is_enum)) {\n-      is_illegal = true;\n-    }\n-  } else { \/\/ not interface\n-    if (has_illegal_visibility(flags) || (is_final && is_volatile)) {\n-      is_illegal = true;\n-    } else {\n-      if (!is_identity_class && !is_abstract && !is_static && !is_final) {\n+  if (!is_illegal) {\n+    if (is_interface) {\n+      if (!is_public || !is_static || !is_final || is_private ||\n+          is_protected || is_volatile || is_transient ||\n+          (major_gte_1_5 && is_enum)) {\n+        is_illegal = true;\n+        error_msg = \"interface fields must be public, static and final, and may be synthetic\";\n+      }\n+    } else { \/\/ not interface\n+      if (has_illegal_visibility(flags)) {\n+        is_illegal = true;\n+        error_msg = \"invalid visibility flags for class field\";\n+      } else if (is_final && is_volatile) {\n@@ -4866,0 +4866,1 @@\n+        error_msg = \"fields cannot be final and volatile\";\n@@ -4868,1 +4869,1 @@\n-          \/* non-static value class fields must be be strict *\/\n+          error_msg = \"value class fields must be either strict or static\";\n@@ -4880,2 +4881,2 @@\n-      \"Illegal field modifiers in class %s: 0x%X\",\n-      _class_name->as_C_string(), flags);\n+      \"Illegal field modifiers (%s) in class %s: 0x%X\",\n+      error_msg, _class_name->as_C_string(), flags);\n@@ -4908,1 +4909,0 @@\n-  const bool is_value_class  = !class_access_flags.is_identity_class();\n@@ -4971,14 +4971,6 @@\n-    if (is_value_class && is_initializer) {\n-      Exceptions::fthrow(\n-        THREAD_AND_LOCATION,\n-        vmSymbols::java_lang_ClassFormatError(),\n-        \"Method <init> is not allowed in value class %s\",\n-        _class_name->as_C_string());\n-    } else {\n-      Exceptions::fthrow(\n-        THREAD_AND_LOCATION,\n-        vmSymbols::java_lang_ClassFormatError(),\n-        \"Method %s in class %s%s has illegal modifiers: 0x%X\",\n-        name->as_C_string(), _class_name->as_C_string(),\n-        class_note, flags);\n-    }\n+    Exceptions::fthrow(\n+      THREAD_AND_LOCATION,\n+      vmSymbols::java_lang_ClassFormatError(),\n+      \"Method %s in class %s%s has illegal modifiers: 0x%X\",\n+      name->as_C_string(), _class_name->as_C_string(),\n+      class_note, flags);\n@@ -5041,4 +5033,4 @@\n-bool ClassFileParser::is_class_in_preload_attribute(Symbol *klass) {\n-  if (_preload_classes == nullptr) return false;\n-  for (int i = 0; i < _preload_classes->length(); i++) {\n-        Symbol* class_name = _cp->klass_at_noresolve(_preload_classes->at(i));\n+bool ClassFileParser::is_class_in_loadable_descriptors_attribute(Symbol *klass) {\n+  if (_loadable_descriptors == nullptr) return false;\n+  for (int i = 0; i < _loadable_descriptors->length(); i++) {\n+        Symbol* class_name = _cp->symbol_at(_loadable_descriptors->at(i));\n@@ -5315,0 +5307,10 @@\n+bool ClassFileParser::legal_field_signature(const Symbol* signature, TRAPS) const {\n+  const char* const bytes = (const char*)signature->bytes();\n+  const unsigned int length = signature->utf8_length();\n+  const char* const p = skip_over_field_signature(bytes, false, length, CHECK_false);\n+\n+  if (p == nullptr || (p - bytes) != (int)length) {\n+    return false;\n+  }\n+  return true;\n+}\n@@ -5590,1 +5592,1 @@\n-  assert(nullptr == _preload_classes, \"invariant\");\n+  assert(nullptr == _loadable_descriptors, \"invariant\");\n@@ -5864,1 +5866,1 @@\n-  _preload_classes(nullptr),\n+  _loadable_descriptors(nullptr),\n@@ -5968,1 +5970,1 @@\n-  _preload_classes = nullptr;\n+  _loadable_descriptors = nullptr;\n@@ -6023,2 +6025,2 @@\n-  if (_preload_classes != nullptr && _preload_classes != Universe::the_empty_short_array()) {\n-    MetadataFactory::free_array<u2>(_loader_data, _preload_classes);\n+  if (_loadable_descriptors != nullptr && _loadable_descriptors != Universe::the_empty_short_array()) {\n+    MetadataFactory::free_array<u2>(_loader_data, _loadable_descriptors);\n@@ -6368,0 +6370,5 @@\n+    if (_super_klass->is_final()) {\n+      classfile_icce_error(\"class %s cannot inherit from final class %s\", _super_klass, THREAD);\n+      return;\n+    }\n+\n@@ -6391,3 +6398,2 @@\n-    if (_super_klass != nullptr  \/\/ not j.l.Object\n-              && _parsed_annotations->has_annotation(ClassAnnotationCollector::_jdk_internal_LooselyConsistentValue)\n-              && (_super_klass == vmClasses::Object_klass() || !_super_klass->must_be_atomic())) {\n+    if (_parsed_annotations->has_annotation(ClassAnnotationCollector::_jdk_internal_LooselyConsistentValue)\n+        && (_super_klass == vmClasses::Object_klass() || !_super_klass->must_be_atomic())) {\n@@ -6396,1 +6402,2 @@\n-    if (_parsed_annotations->has_annotation(ClassAnnotationCollector::_jdk_internal_ImplicitlyConstructible)) {\n+    if (_parsed_annotations->has_annotation(ClassAnnotationCollector::_jdk_internal_ImplicitlyConstructible)\n+        && (_super_klass == vmClasses::Object_klass() || _super_klass->is_implicitly_constructible())) {\n@@ -6544,1 +6551,1 @@\n-        \/\/ Preloading classes for nullable fields that are listed in the Preload attribute\n+        \/\/ Preloading classes for nullable fields that are listed in the LoadableDescriptors attribute\n@@ -6547,2 +6554,2 @@\n-        if (name != _class_name && is_class_in_preload_attribute(name)) {\n-          log_info(class, preload)(\"Preloading class %s during loading of class %s. Cause: field type in Preload attribute\", name->as_C_string(), _class_name->as_C_string());\n+        if (name != _class_name && is_class_in_loadable_descriptors_attribute(sig)) {\n+          log_info(class, preload)(\"Preloading class %s during loading of class %s. Cause: field type in LoadableDescriptors attribute\", name->as_C_string(), _class_name->as_C_string());\n@@ -6554,1 +6561,1 @@\n-              log_info(class, preload)(\"Preloading of class %s during loading of class %s (cause: field type in Preload attribute) succeeded\", name->as_C_string(), _class_name->as_C_string());\n+              log_info(class, preload)(\"Preloading of class %s during loading of class %s (cause: field type in LoadableDescriptors attribute) succeeded\", name->as_C_string(), _class_name->as_C_string());\n@@ -6557,1 +6564,1 @@\n-              log_warning(class, preload)(\"Preloading class %s during loading of class %s (cause: field type in Preload attribute) but loaded class is not a value class\", name->as_C_string(), _class_name->as_C_string());\n+              log_warning(class, preload)(\"Preloading class %s during loading of class %s (cause: field type in LoadableDescriptors attribute) but loaded class is not a value class\", name->as_C_string(), _class_name->as_C_string());\n@@ -6560,1 +6567,1 @@\n-            log_warning(class, preload)(\"Preloading of class %s during loading of class %s (cause: field type in Preload attribute) failed : %s\",\n+            log_warning(class, preload)(\"Preloading of class %s during loading of class %s (cause: field type in LoadableDescriptors attribute) failed : %s\",\n@@ -6563,1 +6570,1 @@\n-          \/\/ Loads triggered by the preload attribute are speculative, failures must not impact loading of current class\n+          \/\/ Loads triggered by the LoadableDescriptors attribute are speculative, failures must not impact loading of current class\n@@ -6575,1 +6582,1 @@\n-      access_flags().is_abstract() && !access_flags().is_identity_class(),\n+      access_flags().is_abstract() && !access_flags().is_identity_class() && !access_flags().is_interface(),\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":118,"deletions":111,"binary":false,"changes":229,"status":"modified"},{"patch":"@@ -135,1 +135,1 @@\n-  Array<u2>* _preload_classes;\n+  Array<u2>* _loadable_descriptors;\n@@ -362,2 +362,2 @@\n-  u2 parse_classfile_preload_attribute(const ClassFileStream* const cfs,\n-                                                    const u1* const preload_attribute_start,\n+  u2 parse_classfile_loadable_descriptors_attribute(const ClassFileStream* const cfs,\n+                                                    const u1* const loadable_descriptors_attribute_start,\n@@ -484,5 +484,0 @@\n-  void throwInlineTypeLimitation(THREAD_AND_LOCATION_DECL,\n-                                 const char* msg,\n-                                 const Symbol* name = nullptr,\n-                                 const Symbol* sig  = nullptr) const;\n-\n@@ -499,0 +494,2 @@\n+  bool legal_field_signature(const Symbol* signature, TRAPS) const;\n+\n@@ -604,0 +601,1 @@\n+  \/\/ Being an inline type means being a concrete value class\n@@ -623,1 +621,1 @@\n-  bool is_class_in_preload_attribute(Symbol *klass);\n+  bool is_class_in_loadable_descriptors_attribute(Symbol *klass);\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.hpp","additions":7,"deletions":9,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -189,1 +189,1 @@\n-  template(tag_preload,                               \"Preload\")                                  \\\n+  template(tag_loadable_descriptors,                  \"LoadableDescriptors\")                      \\\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -31,0 +31,2 @@\n+#include \"gc\/g1\/g1HeapRegion.inline.hpp\"\n+#include \"gc\/g1\/g1HeapRegionManager.inline.hpp\"\n@@ -32,2 +34,0 @@\n-#include \"gc\/g1\/heapRegion.inline.hpp\"\n-#include \"gc\/g1\/heapRegionManager.inline.hpp\"\n@@ -109,1 +109,1 @@\n-      return _cm->top_at_rebuild_start(hr->hrm_index()) != nullptr;\n+      return _cm->top_at_rebuild_start(hr) != nullptr;\n@@ -236,1 +236,1 @@\n-                             HR_FORMAT_PARAMS(hr), p2i(pb), p2i(_cm->top_at_rebuild_start(hr->hrm_index())), p2i(hr->top_at_mark_start()));\n+                             HR_FORMAT_PARAMS(hr), p2i(pb), p2i(_cm->top_at_rebuild_start(hr)), p2i(_cm->top_at_mark_start(hr)));\n@@ -253,1 +253,1 @@\n-      if (scan_from_pb_to_tars(hr, pb, _cm->top_at_rebuild_start(hr->hrm_index()))) {\n+      if (scan_from_pb_to_tars(hr, pb, _cm->top_at_rebuild_start(hr))) {\n@@ -279,1 +279,1 @@\n-                              HR_FORMAT_PARAMS(hr), p2i(pb), p2i(_cm->top_at_rebuild_start(hr->hrm_index())));\n+                              HR_FORMAT_PARAMS(hr), p2i(pb), p2i(_cm->top_at_rebuild_start(hr)));\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentRebuildAndScrub.cpp","additions":6,"deletions":6,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -450,0 +450,1 @@\n+  method->method_holder()->initialize(CHECK_false); \/\/ Ensure class ValueObjectMethods is initialized\n@@ -987,2 +988,14 @@\n-JRT_ENTRY(void, InterpreterRuntime::throw_identity_exception(JavaThread* current))\n-  THROW(vmSymbols::java_lang_IdentityException());\n+JRT_ENTRY(void, InterpreterRuntime::throw_identity_exception(JavaThread* current, oopDesc* obj))\n+  Klass* klass = cast_to_oop(obj)->klass();\n+  ResourceMark rm(THREAD);\n+  const char* desc = \"Cannot synchronize on an instance of value class \";\n+  const char* className = klass->external_name();\n+  size_t msglen = strlen(desc) + strlen(className) + 1;\n+  char* message = NEW_RESOURCE_ARRAY(char, msglen);\n+  if (nullptr == message) {\n+    \/\/ Out of memory: can't create detailed error message\n+    THROW_MSG(vmSymbols::java_lang_IdentityException(), className);\n+  } else {\n+    jio_snprintf(message, msglen, \"%s%s\", desc, className);\n+    THROW_MSG(vmSymbols::java_lang_IdentityException(), message);\n+  }\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":15,"deletions":2,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"cds\/archiveUtils.hpp\"\n@@ -187,13 +188,10 @@\n-    ResourceMark rm(THREAD);\n-    JavaThread *jt = JavaThread::cast(THREAD);\n-    {\n-      \/\/ Atomic creation of array_klasses\n-      MutexLocker ma(THREAD, MultiArray_lock);\n-\n-      \/\/ Check if update has already taken place\n-      if (value_array_klasses() == nullptr) {\n-        ArrayKlass* k;\n-        if (flat_array()) {\n-          k = FlatArrayKlass::allocate_klass(this, CHECK_NULL);\n-        } else {\n-          k = ObjArrayKlass::allocate_objArray_klass(class_loader_data(), 1, this, true, CHECK_NULL);\n+    \/\/ Atomic creation of array_klasses\n+    RecursiveLocker rl(MultiArray_lock, THREAD);\n+\n+    \/\/ Check if update has already taken place\n+    if (value_array_klasses() == nullptr) {\n+      ArrayKlass* k;\n+      if (flat_array()) {\n+        k = FlatArrayKlass::allocate_klass(this, CHECK_NULL);\n+      } else {\n+        k = ObjArrayKlass::allocate_objArray_klass(class_loader_data(), 1, this, true, CHECK_NULL);\n@@ -201,3 +199,2 @@\n-        }\n-        \/\/ use 'release' to pair with lock-free load\n-        Atomic::release_store(adr_value_array_klasses(), k);\n+      \/\/ use 'release' to pair with lock-free load\n+      Atomic::release_store(adr_value_array_klasses(), k);\n@@ -321,0 +318,1 @@\n+    *((Array<SigEntry>**)adr_extended_sig()) = nullptr;\n@@ -324,0 +322,1 @@\n+    *((Array<VMRegPair>**)adr_return_regs()) = nullptr;\n@@ -526,0 +525,4 @@\n+  \/\/ update it to point to the \"buffered\" copy of this class.\n+  _adr_inlineklass_fixed_block = inlineklass_static_block();\n+  ArchivePtrMarker::mark_pointer((address*)&_adr_inlineklass_fixed_block);\n+\n@@ -545,4 +548,0 @@\n-  \/\/ We are no longer bookkeeping pointer to fixed block during serialization, hence reinitializing\n-  \/\/ fixed block address since its size was already accounted by InstanceKlass::size() and it will\n-  \/\/ anyways be part of shared archive.\n-  _adr_inlineklass_fixed_block = inlineklass_static_block();\n","filename":"src\/hotspot\/share\/oops\/inlineKlass.cpp","additions":19,"deletions":20,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -303,1 +303,1 @@\n-  Array<u2>* _preload_classes;\n+  Array<u2>* _loadable_descriptors;\n@@ -373,2 +373,1 @@\n-  \/\/ Query if this class implements jl.NonTearable or was\n-  \/\/ mentioned in the JVM option ForceNonTearable.\n+  \/\/ Query if this class is mentioned in the JVM option ForceNonTearable.\n@@ -377,1 +376,1 @@\n-  \/\/ It inherits from supers along with NonTearable.\n+  \/\/ It inherits from supers.\n@@ -454,1 +453,1 @@\n-  bool is_class_in_preload_attribute(Symbol* name) const;\n+  bool is_class_in_loadable_descriptors_attribute(Symbol* name) const;\n@@ -466,2 +465,2 @@\n-  Array<u2>* preload_classes() const { return _preload_classes; }\n-  void set_preload_classes(Array<u2>* c) { _preload_classes = c; }\n+  Array<u2>* loadable_descriptors() const { return _loadable_descriptors; }\n+  void set_loadable_descriptors(Array<u2>* c) { _loadable_descriptors = c; }\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":6,"deletions":7,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -306,0 +306,3 @@\n+\n+  static Node* build_min_max_int(Node* a, Node* b, bool is_max);\n+  static Node* build_min_max_long(PhaseGVN* phase, Node* a, Node* b, bool is_max);\n","filename":"src\/hotspot\/share\/opto\/addnode.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -60,0 +60,1 @@\n+#include \"opto\/locknode.hpp\"\n@@ -655,1 +656,0 @@\n-                  _failure_reason(nullptr),\n@@ -956,1 +956,0 @@\n-    _failure_reason(nullptr),\n@@ -2024,1 +2023,3 @@\n-    _inline_type_nodes.at(i)->as_InlineType()->make_scalar_in_safepoints(&igvn);\n+    InlineTypeNode* vt = _inline_type_nodes.at(i)->as_InlineType();\n+    vt->make_scalar_in_safepoints(&igvn);\n+    igvn.record_for_igvn(vt);\n@@ -4919,1 +4920,1 @@\n-  if (_failure_reason == nullptr) {\n+  if (_failure_reason.get() == nullptr) {\n@@ -4921,1 +4922,1 @@\n-    _failure_reason = reason;\n+    _failure_reason.set(reason);\n@@ -4993,4 +4994,2 @@\n-    \/\/ TODO 8325106 Fix comment\n-    \/\/ Do not fold the subtype check to an array klass pointer comparison for [V? arrays.\n-    \/\/ [QMyValue is a subtype of [LMyValue but the klass for [QMyValue is not equal to\n-    \/\/ the klass for [LMyValue. Perform a full test.\n+    \/\/ Do not fold the subtype check to an array klass pointer comparison for null-able inline type arrays\n+    \/\/ because null-free [LMyValue <: null-able [LMyValue but the klasses are different. Perform a full test.\n@@ -5404,0 +5403,2 @@\n+    AbstractLockNode* alock = locks.at(0);\n+    BoxLockNode* box = alock->box_node()->as_BoxLock();\n@@ -5408,0 +5409,14 @@\n+      BoxLockNode* this_box = lock->box_node()->as_BoxLock();\n+      if (this_box != box) {\n+        \/\/ Locking regions (BoxLock) could be Unbalanced here:\n+        \/\/  - its coarsened locks were eliminated in earlier\n+        \/\/    macro nodes elimination followed by loop unroll\n+        \/\/  - it is OSR locking region (no Lock node)\n+        \/\/ Preserve Unbalanced status in such cases.\n+        if (!this_box->is_unbalanced()) {\n+          this_box->set_coarsened();\n+        }\n+        if (!box->is_unbalanced()) {\n+          box->set_coarsened();\n+        }\n+      }\n@@ -5485,0 +5500,32 @@\n+\/\/ Mark locking regions (identified by BoxLockNode) as unbalanced if\n+\/\/ locks coarsening optimization removed Lock\/Unlock nodes from them.\n+\/\/ Such regions become unbalanced because coarsening only removes part\n+\/\/ of Lock\/Unlock nodes in region. As result we can't execute other\n+\/\/ locks elimination optimizations which assume all code paths have\n+\/\/ corresponding pair of Lock\/Unlock nodes - they are balanced.\n+void Compile::mark_unbalanced_boxes() const {\n+  int count = coarsened_count();\n+  for (int i = 0; i < count; i++) {\n+    Node_List* locks_list = _coarsened_locks.at(i);\n+    uint size = locks_list->size();\n+    if (size > 0) {\n+      AbstractLockNode* alock = locks_list->at(0)->as_AbstractLock();\n+      BoxLockNode* box = alock->box_node()->as_BoxLock();\n+      if (alock->is_coarsened()) {\n+        \/\/ coarsened_locks_consistent(), which is called before this method, verifies\n+        \/\/ that the rest of Lock\/Unlock nodes on locks_list are also coarsened.\n+        assert(!box->is_eliminated(), \"regions with coarsened locks should not be marked as eliminated\");\n+        for (uint j = 1; j < size; j++) {\n+          assert(locks_list->at(j)->as_AbstractLock()->is_coarsened(), \"only coarsened locks are expected here\");\n+          BoxLockNode* this_box = locks_list->at(j)->as_AbstractLock()->box_node()->as_BoxLock();\n+          if (box != this_box) {\n+            assert(!this_box->is_eliminated(), \"regions with coarsened locks should not be marked as eliminated\");\n+            box->set_unbalanced();\n+            this_box->set_unbalanced();\n+          }\n+        }\n+      }\n+    }\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":56,"deletions":9,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"gc\/shared\/c2\/barrierSetC2.hpp\"\n@@ -57,2 +58,2 @@\n-  \/\/ TODO 8325106 why can't we gvn larvals?\n-  virtual bool cmp(const Node &n) const { return TypeNode::cmp(n) && !((InlineTypeNode&)n)._is_larval && !_is_larval; }\n+  \/\/ Don't GVN larvals because the inputs might be updated\n+  virtual bool cmp(const Node &n) const { return TypeNode::cmp(n) && !(n.isa_InlineType()->_is_larval || _is_larval); }\n@@ -119,1 +120,1 @@\n-  bool is_larval() { return _is_larval; }\n+  bool is_larval() const { return _is_larval; }\n@@ -137,1 +138,1 @@\n-  void store_flat(GraphKit* kit, Node* base, Node* ptr, ciInstanceKlass* holder = nullptr, int holder_offset = 0, DecoratorSet decorators = IN_HEAP | MO_UNORDERED) const;\n+  void store_flat(GraphKit* kit, Node* base, Node* ptr, ciInstanceKlass* holder, int holder_offset, DecoratorSet decorators) const;\n@@ -139,1 +140,1 @@\n-  void store(GraphKit* kit, Node* base, Node* ptr, ciInstanceKlass* holder, int holder_offset = 0, DecoratorSet decorators = IN_HEAP | MO_UNORDERED, int offset = -1) const;\n+  void store(GraphKit* kit, Node* base, Node* ptr, ciInstanceKlass* holder, int holder_offset = 0, int offset = -1, DecoratorSet decorators = C2_TIGHTLY_COUPLED_ALLOC | IN_HEAP | MO_UNORDERED) const;\n","filename":"src\/hotspot\/share\/opto\/inlinetypenode.hpp","additions":6,"deletions":5,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -4412,2 +4412,0 @@\n-          AllocateArrayNode* alloc = AllocateArrayNode::Ideal_array_allocation(obj);\n-          alloc->set_null_free();\n@@ -4836,0 +4834,2 @@\n+  \/\/ Don't intrinsify hashcode on inline types for now.\n+  \/\/ The \"is locked\" runtime check below also serves as inline type check and goes to the slow path.\n@@ -5308,1 +5308,0 @@\n-\/\/ TODO 8325106 Remove this and corresponding tests. Flatness is not a property of the Class anymore with JEP 401.\n@@ -5392,0 +5391,6 @@\n+    if (obj_type->is_inlinetypeptr()) {\n+      \/\/ If the object to clone is an inline type, we can simply return it (i.e. a nop) since inline types have\n+      \/\/ no identity.\n+      set_result(obj);\n+      return true;\n+    }\n@@ -5629,2 +5634,2 @@\n-  \/\/ TODO 8325106 why can't we check via the type of the const klass node?\n-  if (alloc->is_null_free()) {\n+  const TypeAryKlassPtr* ary_klass_ptr = alloc->in(AllocateNode::KlassNode)->bottom_type()->is_aryklassptr();\n+  if (ary_klass_ptr->is_null_free()) {\n@@ -5634,1 +5639,1 @@\n-    ciArrayKlass* klass = alloc->in(AllocateNode::KlassNode)->bottom_type()->is_aryklassptr()->exact_klass()->as_array_klass();\n+    ciArrayKlass* klass = ary_klass_ptr->exact_klass()->as_array_klass();\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":11,"deletions":6,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -48,1 +48,1 @@\n-#include \"opto\/superword.hpp\"\n+#include \"opto\/vectorization.hpp\"\n@@ -795,2 +795,2 @@\n-  jlong stride_con = head->stride_con();\n-  assert(stride_con != 0, \"missed some peephole opt\");\n+  jlong stride_con_long = head->stride_con();\n+  assert(stride_con_long != 0, \"missed some peephole opt\");\n@@ -798,1 +798,1 @@\n-  if (stride_con != (jint)stride_con) {\n+  if (stride_con_long != (jint)stride_con_long || stride_con_long == min_jint) {\n@@ -802,0 +802,1 @@\n+  jint stride_con = checked_cast<jint>(stride_con_long);\n@@ -943,1 +944,2 @@\n-  Node* inner_iters_actual = MaxNode::unsigned_min(inner_iters_max, inner_iters_limit, TypeInteger::make(0, iters_limit, Type::WidenMin, bt), _igvn);\n+  const TypeInteger* inner_iters_actual_range = TypeInteger::make(0, iters_limit, Type::WidenMin, bt);\n+  Node* inner_iters_actual = MaxNode::unsigned_min(inner_iters_max, inner_iters_limit, inner_iters_actual_range, _igvn);\n@@ -949,0 +951,7 @@\n+    \/\/ When the inner loop is transformed to a counted loop, a loop limit check is not expected to be needed because\n+    \/\/ the loop limit is less or equal to max_jint - stride - 1 (if stride is positive but a similar argument exists for\n+    \/\/ a negative stride). We add a CastII here to guarantee that, when the counted loop is created in a subsequent loop\n+    \/\/ opts pass, an accurate range of values for the limits is found.\n+    const TypeInt* inner_iters_actual_int_range = TypeInt::make(0, iters_limit, Type::WidenMin);\n+    inner_iters_actual_int = new CastIINode(outer_head, inner_iters_actual_int, inner_iters_actual_int_range, ConstraintCastNode::UnconditionalDependency);\n+    _igvn.register_new_node_with_optimizer(inner_iters_actual_int);\n@@ -961,1 +970,1 @@\n-  Node* int_stride = _igvn.intcon(checked_cast<int>(stride_con));\n+  Node* int_stride = _igvn.intcon(stride_con);\n@@ -1056,1 +1065,1 @@\n-  transform_long_range_checks(checked_cast<int>(stride_con), range_checks, outer_phi, inner_iters_actual_int,\n+  transform_long_range_checks(stride_con, range_checks, outer_phi, inner_iters_actual_int,\n@@ -1093,1 +1102,1 @@\n-int PhaseIdealLoop::extract_long_range_checks(const IdealLoopTree* loop, jlong stride_con, int iters_limit, PhiNode* phi,\n+int PhaseIdealLoop::extract_long_range_checks(const IdealLoopTree* loop, jint stride_con, int iters_limit, PhiNode* phi,\n@@ -1109,1 +1118,3 @@\n-            original_iters_limit \/ ABS(scale * stride_con) >= min_iters) {\n+            scale != min_jlong &&\n+            original_iters_limit \/ ABS(scale) >= min_iters * ABS(stride_con)) {\n+          assert(scale == (jint)scale, \"scale should be an int\");\n@@ -4362,2 +4373,2 @@\n-  for (int i = 0; i < C->template_assertion_predicate_count(); i++) {\n-    Node* opaque4 = C->template_assertion_predicate_opaq_node(i);\n+  for (int i = C->template_assertion_predicate_count(); i > 0; i--) {\n+    Node* opaque4 = C->template_assertion_predicate_opaq_node(i - 1);\n@@ -4866,1 +4877,1 @@\n-  \/\/ Convert scalar to superword operations at the end of all loop opts.\n+  \/\/ Auto-vectorize main-loop\n@@ -4869,2 +4880,4 @@\n-    \/\/ SuperWord transform\n-    SuperWord sw(this);\n+\n+    \/\/ Shared data structures for all AutoVectorizations, to reduce allocations\n+    \/\/ of large arrays.\n+    VSharedData vshared;\n@@ -4873,11 +4886,9 @@\n-      if (lpt->is_counted()) {\n-        CountedLoopNode *cl = lpt->_head->as_CountedLoop();\n-        if (cl->is_main_loop()) {\n-          if (!sw.transform_loop(lpt, true)) {\n-            \/\/ Instigate more unrolling for optimization when vectorization fails.\n-            if (cl->has_passed_slp()) {\n-              C->set_major_progress();\n-              cl->set_notpassed_slp();\n-              cl->mark_do_unroll_only();\n-            }\n-          }\n+      AutoVectorizeStatus status = auto_vectorize(lpt, vshared);\n+\n+      if (status == AutoVectorizeStatus::TriedAndFailed) {\n+        \/\/ We tried vectorization, but failed. From now on only unroll the loop.\n+        CountedLoopNode* cl = lpt->_head->as_CountedLoop();\n+        if (cl->has_passed_slp()) {\n+          C->set_major_progress();\n+          cl->set_notpassed_slp();\n+          cl->mark_do_unroll_only();\n@@ -4889,1 +4900,1 @@\n-  \/\/ Move UnorderedReduction out of counted loop. Can be introduced by SuperWord.\n+  \/\/ Move UnorderedReduction out of counted loop. Can be introduced by AutoVectorization.\n@@ -5074,1 +5085,1 @@\n-int compare_tree(IdealLoopTree* const& a, IdealLoopTree* const& b) {\n+static int compare_tree(IdealLoopTree* const& a, IdealLoopTree* const& b) {\n@@ -5966,24 +5977,0 @@\n-  CountedLoopNode* CountedLoopNode::pre_loop_head() const {\n-    assert(is_main_loop(), \"Only main loop has pre loop\");\n-    assert(_pre_loop_end != nullptr && _pre_loop_end->loopnode() != nullptr,\n-           \"should find head from pre loop end\");\n-    return _pre_loop_end->loopnode();\n-  }\n-\n-  CountedLoopEndNode* CountedLoopNode::pre_loop_end() {\n-#ifdef ASSERT\n-    assert(is_main_loop(), \"Only main loop has pre loop\");\n-    assert(_pre_loop_end != nullptr, \"should be set when fetched\");\n-    Node* found_pre_end = find_pre_loop_end();\n-    assert(_pre_loop_end == found_pre_end && _pre_loop_end == pre_loop_head()->loopexit(),\n-           \"should find the pre loop end and must be the same result\");\n-#endif\n-    return _pre_loop_end;\n-  }\n-\n-  void CountedLoopNode::set_pre_loop_end(CountedLoopEndNode* pre_loop_end) {\n-    assert(is_main_loop(), \"Only main loop has pre loop\");\n-    assert(pre_loop_end, \"must be valid\");\n-    _pre_loop_end = pre_loop_end;\n-  }\n-\n","filename":"src\/hotspot\/share\/opto\/loopnode.cpp","additions":38,"deletions":51,"binary":false,"changes":89,"status":"modified"},{"patch":"@@ -41,9 +41,4 @@\n-\/\/\n-\/\/                  S U P E R W O R D   T R A N S F O R M\n-\/\/=============================================================================\n-\n-\/\/------------------------------SuperWord---------------------------\n-SuperWord::SuperWord(PhaseIdealLoop* phase) :\n-  _phase(phase),\n-  _arena(phase->C->comp_arena()),\n-  _igvn(phase->_igvn),\n+SuperWord::SuperWord(const VLoopAnalyzer &vloop_analyzer) :\n+  _vloop_analyzer(vloop_analyzer),\n+  _vloop(vloop_analyzer.vloop()),\n+  _arena(mtCompiler),\n@@ -51,6 +46,2 @@\n-  _bb_idx(arena(), (int)(1.10 * phase->C->unique()), 0, 0), \/\/ node idx to index in bb\n-  _block(arena(), 8,  0, nullptr),                          \/\/ nodes in current block\n-  _mem_slice_head(arena(), 8,  0, nullptr),                 \/\/ memory slice heads\n-  _mem_slice_tail(arena(), 8,  0, nullptr),                 \/\/ memory slice tails\n-  _node_info(arena(), 8,  0, SWNodeInfo::initial),          \/\/ info needed per node\n-  _clone_map(phase->C->clone_map()),                        \/\/ map of nodes created in cloning\n+  _node_info(arena(), _vloop.estimated_body_length(), 0, SWNodeInfo::initial), \/\/ info needed per node\n+  _clone_map(phase()->C->clone_map()),                      \/\/ map of nodes created in cloning\n@@ -58,9 +49,1 @@\n-  _dg(_arena),                                              \/\/ dependence graph\n-  _nlist(arena(), 8, 0, nullptr),                           \/\/ scratch list of nodes\n-  _lpt(nullptr),                                            \/\/ loop tree node\n-  _lp(nullptr),                                             \/\/ CountedLoopNode\n-  _loop_reductions(arena()),                                \/\/ reduction nodes in the current loop\n-  _bb(nullptr),                                             \/\/ basic block\n-  _iv(nullptr),                                             \/\/ induction var\n-  _early_return(true),                                      \/\/ analysis evaluations routine\n-  _do_vector_loop(phase->C->do_vector_loop()),              \/\/ whether to do vectorization\/simd style\n+  _do_vector_loop(phase()->C->do_vector_loop()),            \/\/ whether to do vectorization\/simd style\n@@ -73,57 +56,5 @@\n-\/\/------------------------------transform_loop---------------------------\n-bool SuperWord::transform_loop(IdealLoopTree* lpt, bool do_optimization) {\n-  assert(_phase->C->do_superword(), \"SuperWord option should be enabled\");\n-  \/\/ SuperWord only works with power of two vector sizes.\n-  int vector_width = Matcher::vector_width_in_bytes(T_BYTE);\n-  if (vector_width < 2 || !is_power_of_2(vector_width)) {\n-    return false;\n-  }\n-\n-  assert(lpt->_head->is_CountedLoop(), \"must be\");\n-  CountedLoopNode *cl = lpt->_head->as_CountedLoop();\n-\n-  if (!cl->is_valid_counted_loop(T_INT)) {\n-    return false; \/\/ skip malformed counted loop\n-  }\n-\n-  \/\/ Initialize simple data used by reduction marking early.\n-  set_lpt(lpt);\n-  set_lp(cl);\n-  \/\/ For now, define one block which is the entire loop body.\n-  set_bb(cl);\n-\n-  if (SuperWordReductions) {\n-    mark_reductions();\n-  }\n-\n-  \/\/ skip any loop that has not been assigned max unroll by analysis\n-  if (do_optimization) {\n-    if (SuperWordLoopUnrollAnalysis && cl->slp_max_unroll() == 0) {\n-      return false;\n-    }\n-  }\n-\n-  \/\/ Check for no control flow in body (other than exit)\n-  Node *cl_exit = cl->loopexit();\n-  if (cl->is_main_loop() && (cl_exit->in(0) != lpt->_head)) {\n-    #ifndef PRODUCT\n-      if (is_trace_superword_precondition()) {\n-        tty->print_cr(\"SuperWord::transform_loop: loop too complicated, cl_exit->in(0) != lpt->_head\");\n-        tty->print(\"cl_exit %d\", cl_exit->_idx); cl_exit->dump();\n-        tty->print(\"cl_exit->in(0) %d\", cl_exit->in(0)->_idx); cl_exit->in(0)->dump();\n-        tty->print(\"lpt->_head %d\", lpt->_head->_idx); lpt->_head->dump();\n-        lpt->dump_head();\n-      }\n-    #endif\n-    return false;\n-  }\n-\n-  \/\/ Make sure the are no extra control users of the loop backedge\n-  if (cl->back_control()->outcnt() != 1) {\n-    return false;\n-  }\n-\n-  \/\/ Skip any loops already optimized by slp\n-  if (cl->is_vectorized_loop()) {\n-    return false;\n-  }\n+void SuperWord::unrolling_analysis(const VLoop &vloop, int &local_loop_unroll_factor) {\n+  IdealLoopTree* lpt    = vloop.lpt();\n+  CountedLoopNode* cl   = vloop.cl();\n+  Node* cl_exit         = vloop.cl_exit();\n+  PhaseIdealLoop* phase = vloop.phase();\n@@ -131,30 +62,1 @@\n-  if (cl->is_unroll_only()) {\n-    return false;\n-  }\n-\n-  if (cl->is_main_loop()) {\n-    \/\/ Check for pre-loop ending with CountedLoopEnd(Bool(Cmp(x,Opaque1(limit))))\n-    CountedLoopEndNode* pre_end = cl->find_pre_loop_end();\n-    if (pre_end == nullptr) {\n-      return false;\n-    }\n-    Node* pre_opaq1 = pre_end->limit();\n-    if (pre_opaq1->Opcode() != Op_Opaque1) {\n-      return false;\n-    }\n-    cl->set_pre_loop_end(pre_end);\n-  }\n-\n-  init(); \/\/ initialize data structures\n-\n-  bool success = true;\n-  if (do_optimization) {\n-    assert(_packset.length() == 0, \"packset must be empty\");\n-    success = SLP_extract();\n-  }\n-  return success;\n-}\n-\n-\/\/------------------------------early unrolling analysis------------------------------\n-void SuperWord::unrolling_analysis(int &local_loop_unroll_factor) {\n-  size_t ignored_size = lpt()->_body.size();\n+  size_t ignored_size = lpt->_body.size();\n@@ -164,2 +66,0 @@\n-  CountedLoopNode *cl = lpt()->_head->as_CountedLoop();\n-  Node *cl_exit = cl->loopexit_or_null();\n@@ -168,1 +68,1 @@\n-  for (uint i = 0; i < lpt()->_body.size(); i++) {\n+  for (uint i = 0; i < lpt->_body.size(); i++) {\n@@ -176,2 +76,2 @@\n-  for (uint i = 0; i < lpt()->_body.size(); i++) {\n-    Node* n = lpt()->_body.at(i);\n+  for (uint i = 0; i < lpt->_body.size(); i++) {\n+    Node* n = lpt->_body.at(i);\n@@ -192,1 +92,1 @@\n-        if (lpt()->is_loop_exit(iff)) {\n+        if (lpt->is_loop_exit(iff)) {\n@@ -236,1 +136,1 @@\n-      Node* n_ctrl = _phase->get_ctrl(adr);\n+      Node* n_ctrl = phase->get_ctrl(adr);\n@@ -239,1 +139,1 @@\n-      if (n_ctrl != nullptr && lpt()->is_member(_phase->get_loop(n_ctrl))) {\n+      if (n_ctrl != nullptr && lpt->is_member(phase->get_loop(n_ctrl))) {\n@@ -247,1 +147,1 @@\n-          VPointer p1(current, phase(), lpt(), &nstack, true);\n+          VPointer p1(current, vloop, &nstack);\n@@ -254,2 +154,2 @@\n-          for (uint j = 0; j < lpt()->_body.size(); j++) {\n-            Node* cur_node = lpt()->_body.at(j);\n+          for (uint j = 0; j < lpt->_body.size(); j++) {\n+            Node* cur_node = lpt->_body.at(j);\n@@ -272,1 +172,1 @@\n-    for (uint i = 0; i < lpt()->_body.size(); i++) {\n+    for (uint i = 0; i < lpt->_body.size(); i++) {\n@@ -276,1 +176,1 @@\n-      Node* n = lpt()->_body.at(i);\n+      Node* n = lpt->_body.at(i);\n@@ -316,1 +216,1 @@\n-              if (!in->is_Mem() && in_bb(in) && in->bottom_type()->basic_type() == T_INT) {\n+              if (!in->is_Mem() && vloop.in_bb(in) && in->bottom_type()->basic_type() == T_INT) {\n@@ -320,1 +220,1 @@\n-                  if (!in_bb(use) && use->bottom_type()->basic_type() != bt) {\n+                  if (!vloop.in_bb(use) && use->bottom_type()->basic_type() != bt) {\n@@ -352,1 +252,1 @@\n-bool SuperWord::is_reduction(const Node* n) {\n+bool VLoopReductions::is_reduction(const Node* n) {\n@@ -366,1 +266,1 @@\n-bool SuperWord::is_reduction_operator(const Node* n) {\n+bool VLoopReductions::is_reduction_operator(const Node* n) {\n@@ -371,1 +271,1 @@\n-bool SuperWord::in_reduction_cycle(const Node* n, uint input) {\n+bool VLoopReductions::in_reduction_cycle(const Node* n, uint input) {\n@@ -388,1 +288,1 @@\n-Node* SuperWord::original_input(const Node* n, uint i) {\n+Node* VLoopReductions::original_input(const Node* n, uint i) {\n@@ -400,3 +300,3 @@\n-void SuperWord::mark_reductions() {\n-\n-  _loop_reductions.clear();\n+void VLoopReductions::mark_reductions() {\n+  assert(_loop_reductions.is_empty(), \"must not yet be computed\");\n+  CountedLoopNode* cl = _vloop.cl();\n@@ -406,2 +306,2 @@\n-  for (DUIterator_Fast imax, i = lp()->fast_outs(imax); i < imax; i++) {\n-    const Node* phi = lp()->fast_out(i);\n+  for (DUIterator_Fast imax, i = cl->fast_outs(imax); i < imax; i++) {\n+    const Node* phi = cl->fast_out(i);\n@@ -414,1 +314,1 @@\n-    if (phi == iv()) {\n+    if (phi == _vloop.iv()) {\n@@ -438,2 +338,3 @@\n-          first, input, lpt()->_body.size(),\n-          [&](const Node* n) { return n->Opcode() == first->Opcode() && in_bb(n); },\n+          first, input, _vloop.lpt()->_body.size(),\n+          [&](const Node* n) { return n->Opcode() == first->Opcode() &&\n+                                      _vloop.in_bb(n); },\n@@ -458,1 +359,1 @@\n-        if (!in_bb(u)) {\n+        if (!_vloop.in_bb(u)) {\n@@ -485,0 +386,28 @@\n+bool SuperWord::transform_loop() {\n+  assert(phase()->C->do_superword(), \"SuperWord option should be enabled\");\n+  assert(cl()->is_main_loop(), \"SLP should only work on main loops\");\n+#ifndef PRODUCT\n+  if (is_trace_superword_any()) {\n+    tty->print_cr(\"\\nSuperWord::transform_loop:\");\n+    lpt()->dump_head();\n+    cl()->dump();\n+  }\n+#endif\n+\n+  if (!SLP_extract()) {\n+#ifndef PRODUCT\n+    if (is_trace_superword_any()) {\n+      tty->print_cr(\"\\nSuperWord::transform_loop failed: SuperWord::SLP_extract did not vectorize\");\n+    }\n+#endif\n+    return false;\n+  }\n+\n+#ifndef PRODUCT\n+  if (is_trace_superword_any()) {\n+    tty->print_cr(\"\\nSuperWord::transform_loop: success\");\n+  }\n+#endif\n+  return true;\n+}\n+\n@@ -520,27 +449,1 @@\n-  CountedLoopNode* cl = lpt()->_head->as_CountedLoop();\n-  assert(cl->is_main_loop(), \"SLP should only work on main loops\");\n-\n-  \/\/ Find memory slices\n-  find_memory_slices();\n-\n-  if (!is_marked_reduction_loop() &&\n-      _mem_slice_head.is_empty()) {\n-#ifndef PRODUCT\n-    if (is_trace_superword_any()) {\n-      tty->print_cr(\"\\nNo reductions or memory slices found, abort SuperWord.\");\n-      tty->cr();\n-    }\n-#endif\n-    return false;\n-  }\n-\n-  \/\/ Ready the block\n-  if (!construct_bb()) {\n-#ifndef PRODUCT\n-    if (is_trace_superword_any()) {\n-      tty->print_cr(\"\\nSuperWord::construct_bb failed: abort SuperWord\");\n-      tty->cr();\n-    }\n-#endif\n-    return false;\n-  }\n+  assert(cl()->is_main_loop(), \"SLP should only work on main loops\");\n@@ -551,9 +454,0 @@\n-  \/\/ build _dg\n-  dependence_graph();\n-\n-  \/\/ compute function depth(Node*)\n-  compute_max_depth();\n-\n-  \/\/ Compute vector element types\n-  compute_vector_element_type();\n-\n@@ -573,3 +467,1 @@\n-  extend_packlist();\n-\n-  combine_packs();\n+  extend_packset_with_more_pairs_by_following_use_and_def();\n@@ -577,1 +469,1 @@\n-  filter_packs_for_alignment();\n+  combine_pairs_to_longer_packs();\n@@ -581,1 +473,11 @@\n-  filter_packs();\n+  split_packs_at_use_def_boundaries();  \/\/ a first time: create natural boundaries\n+  split_packs_only_implemented_with_smaller_size();\n+  split_packs_to_break_mutual_dependence();\n+  split_packs_at_use_def_boundaries();  \/\/ again: propagate split of other packs\n+\n+  \/\/ Now we only remove packs:\n+  filter_packs_for_power_of_2_size();\n+  filter_packs_for_mutual_independence();\n+  filter_packs_for_alignment();\n+  filter_packs_for_implemented();\n+  filter_packs_for_profitable();\n@@ -598,2 +500,2 @@\n-  for (int i = 0; i < _block.length(); i++) {\n-    Node* n = _block.at(i);\n+  for (int i = 0; i < body().length(); i++) {\n+    Node* n = body().at(i);\n@@ -632,1 +534,1 @@\n-    VPointer align_to_ref_p(mem_ref, phase(), lpt(), nullptr, false);\n+    VPointer align_to_ref_p(mem_ref, _vloop);\n@@ -638,1 +540,1 @@\n-        VPointer p2(s, phase(), lpt(), nullptr, false);\n+        VPointer p2(s, _vloop);\n@@ -697,1 +599,1 @@\n-    VPointer p1(s1, phase(), lpt(), nullptr, false);\n+    VPointer p1(s1, _vloop);\n@@ -701,1 +603,1 @@\n-        VPointer p2(s2, phase(), lpt(), nullptr, false);\n+        VPointer p2(s2, _vloop);\n@@ -722,1 +624,1 @@\n-      VPointer p(s, phase(), lpt(), nullptr, false);\n+      VPointer p(s, _vloop);\n@@ -745,1 +647,1 @@\n-        VPointer p(s, phase(), lpt(), nullptr, false);\n+        VPointer p(s, _vloop);\n@@ -818,1 +720,1 @@\n-  VPointer align_to_ref_p(mem_ref, phase(), lpt(), nullptr, false);\n+  VPointer align_to_ref_p(mem_ref, _vloop);\n@@ -847,77 +749,4 @@\n-\/\/---------------------------dependence_graph---------------------------\n-\/\/ Construct dependency graph.\n-\/\/ Add dependence edges to load\/store nodes for memory dependence\n-\/\/    A.out()->DependNode.in(1) and DependNode.out()->B.prec(x)\n-void SuperWord::dependence_graph() {\n-  CountedLoopNode *cl = lpt()->_head->as_CountedLoop();\n-  assert(cl->is_main_loop(), \"SLP should only work on main loops\");\n-\n-  \/\/ First, assign a dependence node to each memory node\n-  for (int i = 0; i < _block.length(); i++ ) {\n-    Node *n = _block.at(i);\n-    if (n->is_Mem() || n->is_memory_phi()) {\n-      _dg.make_node(n);\n-    }\n-  }\n-\n-  \/\/ For each memory slice, create the dependences\n-  for (int i = 0; i < _mem_slice_head.length(); i++) {\n-    Node* n      = _mem_slice_head.at(i);\n-    Node* n_tail = _mem_slice_tail.at(i);\n-\n-    \/\/ Get slice in predecessor order (last is first)\n-    mem_slice_preds(n_tail, n, _nlist);\n-\n-    \/\/ Make the slice dependent on the root\n-    DepMem* slice = _dg.dep(n);\n-    _dg.make_edge(_dg.root(), slice);\n-\n-    \/\/ Create a sink for the slice\n-    DepMem* slice_sink = _dg.make_node(nullptr);\n-    _dg.make_edge(slice_sink, _dg.tail());\n-\n-    \/\/ Now visit each pair of memory ops, creating the edges\n-    for (int j = _nlist.length() - 1; j >= 0 ; j--) {\n-      Node* s1 = _nlist.at(j);\n-\n-      \/\/ If no dependency yet, use slice\n-      if (_dg.dep(s1)->in_cnt() == 0) {\n-        _dg.make_edge(slice, s1);\n-      }\n-      VPointer p1(s1->as_Mem(), phase(), lpt(), nullptr, false);\n-      bool sink_dependent = true;\n-      for (int k = j - 1; k >= 0; k--) {\n-        Node* s2 = _nlist.at(k);\n-        if (s1->is_Load() && s2->is_Load())\n-          continue;\n-        VPointer p2(s2->as_Mem(), phase(), lpt(), nullptr, false);\n-\n-        int cmp = p1.cmp(p2);\n-        if (!VPointer::not_equal(cmp)) {\n-          \/\/ Possibly same address\n-          _dg.make_edge(s1, s2);\n-          sink_dependent = false;\n-        }\n-      }\n-      if (sink_dependent) {\n-        _dg.make_edge(s1, slice_sink);\n-      }\n-    }\n-\n-#ifndef PRODUCT\n-    if (is_trace_superword_dependence_graph()) {\n-      tty->print_cr(\"\\nDependence graph for slice: %d\", n->_idx);\n-      for (int q = 0; q < _nlist.length(); q++) {\n-        _dg.print(_nlist.at(q));\n-      }\n-      tty->cr();\n-    }\n-#endif\n-\n-    _nlist.clear();\n-  }\n-}\n-\n-void SuperWord::find_memory_slices() {\n-  assert(_mem_slice_head.length() == 0, \"mem_slice_head is empty\");\n-  assert(_mem_slice_tail.length() == 0, \"mem_slice_tail is empty\");\n+void VLoopMemorySlices::find_memory_slices() {\n+  assert(_heads.is_empty(), \"not yet computed\");\n+  assert(_tails.is_empty(), \"not yet computed\");\n+  CountedLoopNode* cl = _vloop.cl();\n@@ -926,3 +755,3 @@\n-  for (DUIterator_Fast imax, i = lp()->fast_outs(imax); i < imax; i++) {\n-    PhiNode* phi = lp()->fast_out(i)->isa_Phi();\n-    if (phi != nullptr && in_bb(phi) && phi->is_memory_phi()) {\n+  for (DUIterator_Fast imax, i = cl->fast_outs(imax); i < imax; i++) {\n+    PhiNode* phi = cl->fast_out(i)->isa_Phi();\n+    if (phi != nullptr && _vloop.in_bb(phi) && phi->is_memory_phi()) {\n@@ -931,2 +760,2 @@\n-        _mem_slice_head.push(phi);\n-        _mem_slice_tail.push(phi_tail->as_Mem());\n+        _heads.push(phi);\n+        _tails.push(phi_tail->as_Mem());\n@@ -937,1 +766,1 @@\n-  NOT_PRODUCT( if (is_trace_superword_memory_slices()) { print_memory_slices(); } )\n+  NOT_PRODUCT( if (_vloop.is_trace_memory_slices()) { print(); } )\n@@ -941,6 +770,6 @@\n-void SuperWord::print_memory_slices() {\n-  tty->print_cr(\"\\nSuperWord::print_memory_slices: %s\",\n-                _mem_slice_head.length() > 0 ? \"\" : \"NONE\");\n-  for (int m = 0; m < _mem_slice_head.length(); m++) {\n-    tty->print(\"%6d \", m);  _mem_slice_head.at(m)->dump();\n-    tty->print(\"       \");  _mem_slice_tail.at(m)->dump();\n+void VLoopMemorySlices::print() const {\n+  tty->print_cr(\"\\nVLoopMemorySlices::print: %s\",\n+                heads().length() > 0 ? \"\" : \"NONE\");\n+  for (int m = 0; m < heads().length(); m++) {\n+    tty->print(\"%6d \", m);  heads().at(m)->dump();\n+    tty->print(\"       \");  tails().at(m)->dump();\n@@ -951,5 +780,4 @@\n-\/\/---------------------------mem_slice_preds---------------------------\n-\/\/ Return a memory slice (node list) in predecessor order starting at \"start\"\n-void SuperWord::mem_slice_preds(Node* start, Node* stop, GrowableArray<Node*> &preds) {\n-  assert(preds.length() == 0, \"start empty\");\n-  Node* n = start;\n+\/\/ Get all memory nodes of a slice, in reverse order\n+void VLoopMemorySlices::get_slice_in_reverse_order(PhiNode* head, MemNode* tail, GrowableArray<MemNode*> &slice) const {\n+  assert(slice.is_empty(), \"start empty\");\n+  Node* n = tail;\n@@ -958,1 +786,1 @@\n-    assert(in_bb(n), \"must be in block\");\n+    assert(_vloop.in_bb(n), \"must be in block\");\n@@ -962,2 +790,2 @@\n-        if (in_bb(out)) {\n-          preds.push(out);\n+        if (_vloop.in_bb(out)) {\n+          slice.push(out->as_Load());\n@@ -967,1 +795,1 @@\n-        if (out->is_MergeMem() && !in_bb(out)) {\n+        if (out->is_MergeMem() && !_vloop.in_bb(out)) {\n@@ -970,1 +798,1 @@\n-        } else if (out->is_memory_phi() && !in_bb(out)) {\n+        } else if (out->is_memory_phi() && !_vloop.in_bb(out)) {\n@@ -980,2 +808,2 @@\n-    if (n == stop) break;\n-    preds.push(n);\n+    if (n == head) { break; }\n+    slice.push(n->as_Mem());\n@@ -988,5 +816,5 @@\n-  if (is_trace_superword_memory_slices()) {\n-    tty->print_cr(\"\\nSuperWord::mem_slice_preds:\");\n-    stop->dump();\n-    for (int j = preds.length() - 1; j >= 0 ; j--) {\n-      preds.at(j)->dump();\n+  if (_vloop.is_trace_memory_slices()) {\n+    tty->print_cr(\"\\nVLoopMemorySlices::get_slice_in_reverse_order:\");\n+    head->dump();\n+    for (int j = slice.length() - 1; j >= 0 ; j--) {\n+      slice.at(j)->dump();\n@@ -1014,1 +842,3 @@\n-  if (isomorphic(s1, s2)) {\n+  \/\/ Forbid anything that looks like a PopulateIndex to be packed. It does not need to be packed,\n+  \/\/ and will still be vectorized by SuperWord::vector_opd.\n+  if (isomorphic(s1, s2) && !is_populate_index(s1, s2)) {\n@@ -1063,2 +893,2 @@\n-  VPointer p1(s1->as_Mem(), phase(), lpt(), nullptr, false);\n-  VPointer p2(s2->as_Mem(), phase(), lpt(), nullptr, false);\n+  VPointer p1(s1->as_Mem(), _vloop);\n+  VPointer p2(s2->as_Mem(), _vloop);\n@@ -1093,1 +923,12 @@\n-\/\/------------------------------independent---------------------------\n+\/\/ Look for pattern n1 = (iv + c) and n2 = (iv + c + 1), which may lead to PopulateIndex vector node.\n+\/\/ We skip the pack creation of these nodes. They will be vectorized by SuperWord::vector_opd.\n+bool SuperWord::is_populate_index(const Node* n1, const Node* n2) const {\n+  return n1->is_Add() &&\n+         n2->is_Add() &&\n+         n1->in(1) == iv() &&\n+         n2->in(1) == iv() &&\n+         n1->in(2)->is_Con() &&\n+         n2->in(2)->is_Con() &&\n+         n2->in(2)->get_int() - n1->in(2)->get_int() == 1;\n+}\n+\n@@ -1095,1 +936,1 @@\n-bool SuperWord::independent(Node* s1, Node* s2) {\n+bool VLoopDependencyGraph::independent(Node* s1, Node* s2) const {\n@@ -1116,1 +957,1 @@\n-    for (DepPreds preds(n, _dg); !preds.done(); preds.next()) {\n+    for (PredsIterator preds(*this, n); !preds.done(); preds.next()) {\n@@ -1118,1 +959,1 @@\n-      if (in_bb(pred) && depth(pred) >= min_d) {\n+      if (_vloop.in_bb(pred) && depth(pred) >= min_d) {\n@@ -1137,1 +978,1 @@\n-bool SuperWord::mutually_independent(Node_List* nodes) const {\n+bool VLoopDependencyGraph::mutually_independent(const Node_List* nodes) const {\n@@ -1146,1 +987,1 @@\n-    nodes_set.set(bb_idx(n));\n+    nodes_set.set(_body.bb_idx(n));\n@@ -1150,1 +991,1 @@\n-    for (DepPreds preds(n, _dg); !preds.done(); preds.next()) {\n+    for (PredsIterator preds(*this, n); !preds.done(); preds.next()) {\n@@ -1152,2 +993,2 @@\n-      if (in_bb(pred) && depth(pred) >= min_d) {\n-        if (nodes_set.test(bb_idx(pred))) {\n+      if (_vloop.in_bb(pred) && depth(pred) >= min_d) {\n+        if (nodes_set.test(_body.bb_idx(pred))) {\n@@ -1186,15 +1027,9 @@\n-\/\/------------------------------reduction---------------------------\n-\/\/ Is there a data path between s1 and s2 and the nodes reductions?\n-bool SuperWord::reduction(Node* s1, Node* s2) {\n-  bool retValue = false;\n-  int d1 = depth(s1);\n-  int d2 = depth(s2);\n-  if (d2 > d1) {\n-    if (is_marked_reduction(s1) && is_marked_reduction(s2)) {\n-      \/\/ This is an ordered set, so s1 should define s2\n-      for (DUIterator_Fast imax, i = s1->fast_outs(imax); i < imax; i++) {\n-        Node* t1 = s1->fast_out(i);\n-        if (t1 == s2) {\n-          \/\/ both nodes are reductions and connected\n-          retValue = true;\n-        }\n+bool VLoopReductions::is_marked_reduction_pair(Node* s1, Node* s2) const {\n+  if (is_marked_reduction(s1) &&\n+      is_marked_reduction(s2)) {\n+    \/\/ This is an ordered set, so s1 should define s2\n+    for (DUIterator_Fast imax, i = s1->fast_outs(imax); i < imax; i++) {\n+      Node* t1 = s1->fast_out(i);\n+      if (t1 == s2) {\n+        \/\/ both nodes are reductions and connected\n+        return true;\n@@ -1204,2 +1039,1 @@\n-\n-  return retValue;\n+  return false;\n@@ -1218,9 +1052,1 @@\n-\/\/------------------------------data_size---------------------------\n-int SuperWord::data_size(Node* s) {\n-  int bsize = type2aelembytes(velt_basic_type(s));\n-  assert(bsize != 0, \"valid size\");\n-  return bsize;\n-}\n-\n-\/\/------------------------------extend_packlist---------------------------\n-void SuperWord::extend_packlist() {\n+void SuperWord::extend_packset_with_more_pairs_by_following_use_and_def() {\n@@ -1248,1 +1074,1 @@\n-    tty->print_cr(\"\\nAfter Superword::extend_packlist\");\n+    tty->print_cr(\"\\nAfter Superword::extend_packset_with_more_pairs_by_following_use_and_def\");\n@@ -1355,1 +1181,1 @@\n-      if (t2->Opcode() == Op_AddI && t2 == _lp->as_CountedLoop()->incr()) continue; \/\/ don't mess with the iv\n+      if (t2->Opcode() == Op_AddI && t2 == cl()->incr()) continue; \/\/ don't mess with the iv\n@@ -1534,2 +1360,1 @@\n-\/\/------------------------------combine_packs---------------------------\n-void SuperWord::combine_packs() {\n+void SuperWord::combine_pairs_to_longer_packs() {\n@@ -1538,0 +1363,1 @@\n+  assert(!_packset.is_empty(), \"packset not empty\");\n@@ -1540,0 +1366,1 @@\n+    assert(_packset.at(i)->size() == 2, \"all packs are pairs\");\n@@ -1565,9 +1392,5 @@\n-  \/\/ Split packs which have size greater then max vector size.\n-  for (int i = 0; i < _packset.length(); i++) {\n-    Node_List* p1 = _packset.at(i);\n-    if (p1 != nullptr) {\n-      uint max_vlen = max_vector_size_in_def_use_chain(p1->at(0)); \/\/ Max elements in vector\n-      assert(is_power_of_2(max_vlen), \"sanity\");\n-      uint psize = p1->size();\n-      if (!is_power_of_2(psize)) {\n-        \/\/ We currently only support power-of-2 sizes for vectors.\n+  \/\/ Remove all nullptr from packset\n+  compress_packset();\n+\n+  assert(!_packset.is_empty(), \"must have combined some packs\");\n+\n@@ -1575,5 +1398,4 @@\n-        if (is_trace_superword_rejections()) {\n-          tty->cr();\n-          tty->print_cr(\"WARNING: Removed pack[%d] with size that is not a power of 2:\", i);\n-          print_pack(p1);\n-        }\n+  if (is_trace_superword_packset()) {\n+    tty->print_cr(\"\\nAfter Superword::combine_pairs_to_longer_packs\");\n+    print_packset();\n+  }\n@@ -1581,14 +1403,18 @@\n-        _packset.at_put(i, nullptr);\n-        continue;\n-      }\n-      if (psize > max_vlen) {\n-        Node_List* pack = new Node_List();\n-        for (uint j = 0; j < psize; j++) {\n-          pack->push(p1->at(j));\n-          if (pack->size() >= max_vlen) {\n-            assert(is_power_of_2(pack->size()), \"sanity\");\n-            _packset.append(pack);\n-            pack = new Node_List();\n-          }\n-        }\n-        _packset.at_put(i, nullptr);\n+}\n+\n+SuperWord::SplitStatus SuperWord::split_pack(const char* split_name,\n+                                             Node_List* pack,\n+                                             SplitTask task)\n+{\n+  uint pack_size = pack->size();\n+\n+  if (task.is_unchanged()) {\n+    return SplitStatus::make_unchanged(pack);\n+  }\n+\n+  if (task.is_rejected()) {\n+#ifndef PRODUCT\n+      if (is_trace_superword_rejections()) {\n+        tty->cr();\n+        tty->print_cr(\"WARNING: Removed pack during split: %s:\", task.message());\n+        print_pack(pack);\n@@ -1596,0 +1422,4 @@\n+#endif\n+    for (uint i = 0; i < pack_size; i++) {\n+      Node* n = pack->at(i);\n+      set_my_pack(n, nullptr);\n@@ -1597,0 +1427,1 @@\n+    return SplitStatus::make_rejected();\n@@ -1599,26 +1430,7 @@\n-  \/\/ We know that the nodes in a pair pack were independent - this gives us independence\n-  \/\/ at distance 1. But now that we may have more than 2 nodes in a pack, we need to check\n-  \/\/ if they are all mutually independent. If there is a dependence we remove the pack.\n-  \/\/ This is better than giving up completely - we can have partial vectorization if some\n-  \/\/ are rejected and others still accepted.\n-  \/\/\n-  \/\/ Examples with dependence at distance 1 (pack pairs are not created):\n-  \/\/ for (int i ...) { v[i + 1] = v[i] + 5; }\n-  \/\/ for (int i ...) { v[i] = v[i - 1] + 5; }\n-  \/\/\n-  \/\/ Example with independence at distance 1, but dependence at distance 2 (pack pairs are\n-  \/\/ created and we need to filter them out now):\n-  \/\/ for (int i ...) { v[i + 2] = v[i] + 5; }\n-  \/\/ for (int i ...) { v[i] = v[i - 2] + 5; }\n-  \/\/\n-  \/\/ Note: dependencies are created when a later load may reference the same memory location\n-  \/\/ as an earlier store. This happens in \"read backward\" or \"store forward\" cases. On the\n-  \/\/ other hand, \"read forward\" or \"store backward\" cases do not have such dependencies:\n-  \/\/ for (int i ...) { v[i] = v[i + 1] + 5; }\n-  \/\/ for (int i ...) { v[i - 1] = v[i] + 5; }\n-  for (int i = 0; i < _packset.length(); i++) {\n-    Node_List* p = _packset.at(i);\n-    if (p != nullptr) {\n-      \/\/ reductions are trivially connected\n-      if (!is_marked_reduction(p->at(0)) &&\n-          !mutually_independent(p)) {\n+  uint split_size = task.split_size();\n+  assert(0 < split_size && split_size < pack_size, \"split_size must be in range\");\n+\n+  \/\/ Split the size\n+  uint new_size = split_size;\n+  uint old_size = pack_size - new_size;\n+\n@@ -1626,6 +1438,6 @@\n-        if (is_trace_superword_rejections()) {\n-          tty->cr();\n-          tty->print_cr(\"WARNING: Found dependency at distance greater than 1.\");\n-          tty->print_cr(\"In pack[%d]\", i);\n-          print_pack(p);\n-        }\n+  if (is_trace_superword_packset()) {\n+    tty->cr();\n+    tty->print_cr(\"INFO: splitting pack (sizes: %d %d): %s:\",\n+                  old_size, new_size, task.message());\n+    print_pack(pack);\n+  }\n@@ -1633,1 +1445,9 @@\n-        _packset.at_put(i, nullptr);\n+\n+  \/\/ Are both sizes too small to be a pack?\n+  if (old_size < 2 && new_size < 2) {\n+    assert(old_size == 1 && new_size == 1, \"implied\");\n+#ifndef PRODUCT\n+      if (is_trace_superword_rejections()) {\n+        tty->cr();\n+        tty->print_cr(\"WARNING: Removed size 2 pack, cannot be split: %s:\", task.message());\n+        print_pack(pack);\n@@ -1635,0 +1455,4 @@\n+#endif\n+    for (uint i = 0; i < pack_size; i++) {\n+      Node* n = pack->at(i);\n+      set_my_pack(n, nullptr);\n@@ -1636,0 +1460,1 @@\n+    return SplitStatus::make_rejected();\n@@ -1638,2 +1463,78 @@\n-  \/\/ Remove all nullptr from packset\n-  compress_packset();\n+  \/\/ Just pop off a single node?\n+  if (new_size < 2) {\n+    assert(new_size == 1 && old_size >= 2, \"implied\");\n+    Node* n = pack->pop();\n+    set_my_pack(n, nullptr);\n+#ifndef PRODUCT\n+      if (is_trace_superword_rejections()) {\n+        tty->cr();\n+        tty->print_cr(\"WARNING: Removed node from pack, because of split: %s:\", task.message());\n+        n->dump();\n+      }\n+#endif\n+    return SplitStatus::make_modified(pack);\n+  }\n+\n+  \/\/ Just remove a single node at front?\n+  if (old_size < 2) {\n+    assert(old_size == 1 && new_size >= 2, \"implied\");\n+    Node* n = pack->at(0);\n+    pack->remove(0);\n+    set_my_pack(n, nullptr);\n+#ifndef PRODUCT\n+      if (is_trace_superword_rejections()) {\n+        tty->cr();\n+        tty->print_cr(\"WARNING: Removed node from pack, because of split: %s:\", task.message());\n+        n->dump();\n+      }\n+#endif\n+    return SplitStatus::make_modified(pack);\n+  }\n+\n+  \/\/ We will have two packs\n+  assert(old_size >= 2 && new_size >= 2, \"implied\");\n+  Node_List* new_pack = new Node_List(new_size);\n+\n+  for (uint i = 0; i < new_size; i++) {\n+    Node* n = pack->at(old_size + i);\n+    new_pack->push(n);\n+    set_my_pack(n, new_pack);\n+  }\n+\n+  for (uint i = 0; i < new_size; i++) {\n+    pack->pop();\n+  }\n+\n+  \/\/ We assume that new_pack is more \"stable\" (i.e. will have to be split less than new_pack).\n+  \/\/ Put \"pack\" second, so that we insert it later in the list, and iterate over it again sooner.\n+  return SplitStatus::make_split(new_pack, pack);\n+}\n+\n+template <typename SplitStrategy>\n+void SuperWord::split_packs(const char* split_name,\n+                            SplitStrategy strategy) {\n+  bool changed;\n+  do {\n+    changed = false;\n+    int new_packset_length = 0;\n+    for (int i = 0; i < _packset.length(); i++) {\n+      Node_List* pack = _packset.at(i);\n+      assert(pack != nullptr && pack->size() >= 2, \"no nullptr, at least size 2\");\n+      SplitTask task = strategy(pack);\n+      SplitStatus status = split_pack(split_name, pack, task);\n+      changed |= !status.is_unchanged();\n+      Node_List* first_pack = status.first_pack();\n+      Node_List* second_pack = status.second_pack();\n+      _packset.at_put(i, nullptr); \/\/ take out pack\n+      if (first_pack != nullptr) {\n+        \/\/ The first pack can be put at the current position\n+        assert(i >= new_packset_length, \"only move packs down\");\n+        _packset.at_put(new_packset_length++, first_pack);\n+      }\n+      if (second_pack != nullptr) {\n+        \/\/ The second node has to be appended at the end\n+        _packset.append(second_pack);\n+      }\n+    }\n+    _packset.trunc_to(new_packset_length);\n+  } while (changed);\n@@ -1643,1 +1544,83 @@\n-    tty->print_cr(\"\\nAfter Superword::combine_packs\");\n+    tty->print_cr(\"\\nAfter %s\", split_name);\n+    print_packset();\n+  }\n+#endif\n+}\n+\n+\/\/ Split packs at boundaries where left and right have different use or def packs.\n+void SuperWord::split_packs_at_use_def_boundaries() {\n+  split_packs(\"SuperWord::split_packs_at_use_def_boundaries\",\n+               [&](const Node_List* pack) {\n+                 uint pack_size = pack->size();\n+                 uint boundary = find_use_def_boundary(pack);\n+                 assert(boundary < pack_size, \"valid boundary %d\", boundary);\n+                 if (boundary != 0) {\n+                   return SplitTask::make_split(pack_size - boundary, \"found a use\/def boundary\");\n+                 }\n+                 return SplitTask::make_unchanged();\n+               });\n+}\n+\n+\/\/ Split packs that are only implemented with a smaller pack size. Also splits packs\n+\/\/ such that they eventually have power of 2 size.\n+void SuperWord::split_packs_only_implemented_with_smaller_size() {\n+  split_packs(\"SuperWord::split_packs_only_implemented_with_smaller_size\",\n+               [&](const Node_List* pack) {\n+                 uint pack_size = pack->size();\n+                 uint implemented_size = max_implemented_size(pack);\n+                 if (implemented_size == 0)  {\n+                   return SplitTask::make_rejected(\"not implemented at any smaller size\");\n+                 }\n+                 assert(is_power_of_2(implemented_size), \"power of 2 size or zero: %d\", implemented_size);\n+                 if (implemented_size != pack_size) {\n+                   return SplitTask::make_split(implemented_size, \"only implemented at smaller size\");\n+                 }\n+                 return SplitTask::make_unchanged();\n+               });\n+}\n+\n+\/\/ Split packs that have a mutual dependency, until all packs are mutually_independent.\n+void SuperWord::split_packs_to_break_mutual_dependence() {\n+  split_packs(\"SuperWord::split_packs_to_break_mutual_dependence\",\n+               [&](const Node_List* pack) {\n+                 uint pack_size = pack->size();\n+                 assert(is_power_of_2(pack_size), \"ensured by earlier splits %d\", pack_size);\n+                 if (!is_marked_reduction(pack->at(0)) &&\n+                     !mutually_independent(pack)) {\n+                   \/\/ As a best guess, we split the pack in half. This way, we iteratively make the\n+                   \/\/ packs smaller, until there is no dependency.\n+                   return SplitTask::make_split(pack_size >> 1, \"was not mutually independent\");\n+                 }\n+                 return SplitTask::make_unchanged();\n+               });\n+}\n+\n+template <typename FilterPredicate>\n+void SuperWord::filter_packs(const char* filter_name,\n+                             const char* error_message,\n+                             FilterPredicate filter) {\n+  int new_packset_length = 0;\n+  for (int i = 0; i < _packset.length(); i++) {\n+    Node_List* pack = _packset.at(i);\n+    assert(pack != nullptr, \"no nullptr in packset\");\n+    if (filter(pack)) {\n+      assert(i >= new_packset_length, \"only move packs down\");\n+      _packset.at_put(new_packset_length++, pack);\n+    } else {\n+      remove_pack_at(i);\n+#ifndef PRODUCT\n+      if (is_trace_superword_rejections()) {\n+        tty->cr();\n+        tty->print_cr(\"WARNING: Removed pack: %s:\", error_message);\n+        print_pack(pack);\n+      }\n+#endif\n+    }\n+  }\n+\n+  assert(_packset.length() >= new_packset_length, \"filter only reduces number of packs\");\n+  _packset.trunc_to(new_packset_length);\n+\n+#ifndef PRODUCT\n+  if (is_trace_superword_packset() && filter_name != nullptr) {\n+    tty->print_cr(\"\\nAfter %s:\", filter_name);\n@@ -1649,0 +1632,38 @@\n+void SuperWord::filter_packs_for_power_of_2_size() {\n+  filter_packs(\"SuperWord::filter_packs_for_power_of_2_size\",\n+               \"size is not a power of 2\",\n+               [&](const Node_List* pack) {\n+                 return is_power_of_2(pack->size());\n+               });\n+}\n+\n+\/\/ We know that the nodes in a pair pack were independent - this gives us independence\n+\/\/ at distance 1. But now that we may have more than 2 nodes in a pack, we need to check\n+\/\/ if they are all mutually independent. If there is a dependence we remove the pack.\n+\/\/ This is better than giving up completely - we can have partial vectorization if some\n+\/\/ are rejected and others still accepted.\n+\/\/\n+\/\/ Examples with dependence at distance 1 (pack pairs are not created):\n+\/\/ for (int i ...) { v[i + 1] = v[i] + 5; }\n+\/\/ for (int i ...) { v[i] = v[i - 1] + 5; }\n+\/\/\n+\/\/ Example with independence at distance 1, but dependence at distance 2 (pack pairs are\n+\/\/ created and we need to filter them out now):\n+\/\/ for (int i ...) { v[i + 2] = v[i] + 5; }\n+\/\/ for (int i ...) { v[i] = v[i - 2] + 5; }\n+\/\/\n+\/\/ Note: dependencies are created when a later load may reference the same memory location\n+\/\/ as an earlier store. This happens in \"read backward\" or \"store forward\" cases. On the\n+\/\/ other hand, \"read forward\" or \"store backward\" cases do not have such dependencies:\n+\/\/ for (int i ...) { v[i] = v[i + 1] + 5; }\n+\/\/ for (int i ...) { v[i - 1] = v[i] + 5; }\n+void SuperWord::filter_packs_for_mutual_independence() {\n+  filter_packs(\"SuperWord::filter_packs_for_mutual_independence\",\n+               \"found dependency between nodes at distance greater than 1\",\n+               [&](const Node_List* pack) {\n+                 \/\/ reductions are trivially connected\n+                 return is_marked_reduction(pack->at(0)) ||\n+                        mutually_independent(pack);\n+               });\n+}\n+\n@@ -1650,1 +1671,1 @@\n-const AlignmentSolution* SuperWord::pack_alignment_solution(Node_List* pack) {\n+const AlignmentSolution* SuperWord::pack_alignment_solution(const Node_List* pack) {\n@@ -1654,2 +1675,2 @@\n-  VPointer mem_ref_p(mem_ref, phase(), lpt(), nullptr, false);\n-  const CountedLoopEndNode* pre_end = lp()->pre_loop_end();\n+  VPointer mem_ref_p(mem_ref, _vloop);\n+  const CountedLoopEndNode* pre_end = _vloop.pre_loop_end();\n@@ -1694,16 +1715,12 @@\n-  for (int i = 0; i < _packset.length(); i++) {\n-    Node_List* p = _packset.at(i);\n-    if (p != nullptr) {\n-      if (p->at(0)->is_Load() || p->at(0)->is_Store()) {\n-        mem_ops_count++;\n-        \/\/ Find solution for pack p, and filter with current solution.\n-        const AlignmentSolution* s = pack_alignment_solution(p);\n-        const AlignmentSolution* intersect = current->filter(s);\n-#ifndef PRODUCT\n-        if (is_trace_align_vector()) {\n-          tty->print(\"  solution for pack:         \");\n-          s->print();\n-          tty->print(\"  intersection with current: \");\n-          intersect->print();\n-        }\n-#endif\n+  filter_packs(\"SuperWord::filter_packs_for_alignment\",\n+               \"rejected by AlignVector (strict alignment requirement)\",\n+               [&](const Node_List* pack) {\n+                 \/\/ Only memops need to be aligned.\n+                 if (!pack->at(0)->is_Load() &&\n+                     !pack->at(0)->is_Store()) {\n+                   return true; \/\/ accept all non memops\n+                 }\n+\n+                 mem_ops_count++;\n+                 const AlignmentSolution* s = pack_alignment_solution(pack);\n+                 const AlignmentSolution* intersect = current->filter(s);\n@@ -1712,6 +1729,6 @@\n-        if (intersect->is_empty()) {\n-          \/\/ Solution failed or is not compatible, remove pack i.\n-          if (is_trace_superword_rejections() || is_trace_align_vector()) {\n-            tty->print_cr(\"Rejected by AlignVector:\");\n-            p->at(0)->dump();\n-          }\n+                 if (is_trace_align_vector()) {\n+                   tty->print(\"  solution for pack:         \");\n+                   s->print();\n+                   tty->print(\"  intersection with current: \");\n+                   intersect->print();\n+                 }\n@@ -1720,9 +1737,8 @@\n-          _packset.at_put(i, nullptr);\n-          mem_ops_rejected++;\n-        } else {\n-          \/\/ Solution is compatible.\n-          current = intersect;\n-        }\n-      }\n-    }\n-  }\n+                 if (intersect->is_empty()) {\n+                   mem_ops_rejected++;\n+                   return false; \/\/ reject because of empty solution\n+                 }\n+\n+                 current = intersect;\n+                 return true; \/\/ accept because of non-empty solution\n+               });\n@@ -1745,10 +1761,0 @@\n-\n-  \/\/ Remove all nullptr from packset\n-  compress_packset();\n-\n-#ifndef PRODUCT\n-  if (is_trace_superword_packset() || is_trace_align_vector()) {\n-    tty->print_cr(\"\\nAfter Superword::filter_packs_for_alignment\");\n-    print_packset();\n-  }\n-#endif\n@@ -1772,1 +1778,1 @@\n-\/\/ point where a node is only in one pack (after combine_packs).\n+\/\/ point where a node is only in one pack (after combine_pairs_to_longer_packs).\n@@ -1791,17 +1797,16 @@\n-\/\/------------------------------filter_packs---------------------------\n-\/\/ Remove packs that are not implemented or not profitable.\n-void SuperWord::filter_packs() {\n-  \/\/ Remove packs that are not implemented\n-  for (int i = _packset.length() - 1; i >= 0; i--) {\n-    Node_List* pk = _packset.at(i);\n-    bool impl = implemented(pk);\n-    if (!impl) {\n-#ifndef PRODUCT\n-      if (is_trace_superword_rejections()) {\n-        tty->print_cr(\"Unimplemented\");\n-        pk->at(0)->dump();\n-      }\n-#endif\n-      remove_pack_at(i);\n-    }\n-    Node *n = pk->at(0);\n+\/\/ Remove packs that are not implemented\n+void SuperWord::filter_packs_for_implemented() {\n+  filter_packs(\"SuperWord::filter_packs_for_implemented\",\n+               \"Unimplemented\",\n+               [&](const Node_List* pack) {\n+                 return implemented(pack, pack->size());\n+               });\n+}\n+\n+\/\/ Remove packs that are not profitable.\n+void SuperWord::filter_packs_for_profitable() {\n+  \/\/ Count the number of reductions vs other vector ops, for the\n+  \/\/ reduction profitability heuristic.\n+  for (int i = 0; i < _packset.length(); i++) {\n+    Node_List* pack = _packset.at(i);\n+    Node* n = pack->at(0);\n@@ -1816,16 +1821,10 @@\n-  bool changed;\n-  do {\n-    changed = false;\n-    for (int i = _packset.length() - 1; i >= 0; i--) {\n-      Node_List* pk = _packset.at(i);\n-      bool prof = profitable(pk);\n-      if (!prof) {\n-#ifndef PRODUCT\n-        if (is_trace_superword_rejections()) {\n-          tty->print_cr(\"Unprofitable\");\n-          pk->at(0)->dump();\n-        }\n-#endif\n-        remove_pack_at(i);\n-        changed = true;\n-      }\n+  while (true) {\n+    int old_packset_length = _packset.length();\n+    filter_packs(nullptr, \/\/ don't dump each time\n+                 \"not profitable\",\n+                 [&](const Node_List* pack) {\n+                   return profitable(pack);\n+                 });\n+    \/\/ Repeat until stable\n+    if (old_packset_length == _packset.length()) {\n+      break;\n@@ -1833,1 +1832,1 @@\n-  } while (changed);\n+  }\n@@ -1837,1 +1836,1 @@\n-    tty->print_cr(\"\\nAfter Superword::filter_packs\");\n+    tty->print_cr(\"\\nAfter Superword::filter_packs_for_profitable\");\n@@ -1844,3 +1843,3 @@\n-\/\/------------------------------implemented---------------------------\n-\/\/ Can code be generated for pack p?\n-bool SuperWord::implemented(Node_List* p) {\n+\/\/ Can code be generated for the pack, restricted to size nodes?\n+bool SuperWord::implemented(const Node_List* pack, uint size) {\n+  assert(size >= 2 && size <= pack->size() && is_power_of_2(size), \"valid size\");\n@@ -1848,1 +1847,1 @@\n-  Node* p0 = p->at(0);\n+  Node* p0 = pack->at(0);\n@@ -1851,1 +1850,0 @@\n-    uint size = p->size();\n@@ -1893,0 +1891,16 @@\n+\/\/ Find the maximal implemented size smaller or equal to the packs size\n+uint SuperWord::max_implemented_size(const Node_List* pack) {\n+  uint size = round_down_power_of_2(pack->size());\n+  if (implemented(pack, size)) {\n+    return size;\n+  } else {\n+    \/\/ Iteratively divide size by 2, and check.\n+    for (uint s = size >> 1; s >= 2; s >>= 1) {\n+      if (implemented(pack, s)) {\n+        return s;\n+      }\n+    }\n+    return 0; \/\/ not implementable at all\n+  }\n+}\n+\n@@ -1906,1 +1920,1 @@\n-bool SuperWord::same_inputs(Node_List* p, int idx) {\n+bool SuperWord::same_inputs(const Node_List* p, int idx) {\n@@ -1922,1 +1936,1 @@\n-bool SuperWord::profitable(Node_List* p) {\n+bool SuperWord::profitable(const Node_List* p) {\n@@ -1942,1 +1956,1 @@\n-      \/\/ Unmark reduction if no parent pack or if not enough work\n+      \/\/ No parent pack or not enough work\n@@ -1944,1 +1958,0 @@\n-      _loop_reductions.remove(p0->_idx);\n@@ -1974,2 +1987,2 @@\n-                ((use->is_Phi() && use->in(0) == _lpt->_head) ||\n-                 (!_lpt->is_member(_phase->get_loop(_phase->ctrl_or_self(use))) && i == p->size()-1))) {\n+                ((use->is_Phi() && use->in(0) == lpt()->_head) ||\n+                 (!lpt()->is_member(phase()->get_loop(phase()->ctrl_or_self(use))) && i == p->size()-1))) {\n@@ -2047,2 +2060,2 @@\n-  for (int i = 0; i < _block.length(); i++) {\n-    Node* n = _block.at(i);\n+  for (int i = 0; i < body().length(); i++) {\n+    Node* n = body().at(i);\n@@ -2056,1 +2069,1 @@\n-\/\/ The PacksetGraph combines the DepPreds graph with the packset. In the PackSet\n+\/\/ The PacksetGraph combines the dependency graph with the packset. In the PackSet\n@@ -2061,5 +2074,5 @@\n-\/\/ For any edge (n1, n2) in DepPreds, we add an edge to the PacksetGraph for the\n-\/\/ PacksetGraph nodes corresponding to n1 and n2.\n-\/\/ We work from the DepPreds graph, because it gives us all the data-dependencies,\n-\/\/ as well as more refined memory-dependencies than the C2 graph. DepPreds does\n-\/\/ not have cycles. But packing nodes can introduce cyclic dependencies. Example:\n+\/\/ For any edge (n1, n2) in the dependency graph, we add an edge to the PacksetGraph for\n+\/\/ the PacksetGraph nodes corresponding to n1 and n2.\n+\/\/ We work from the dependency graph, because it gives us all the data-dependencies,\n+\/\/ as well as more refined memory-dependencies than the C2 graph. The dependency graph\n+\/\/ does not have cycles. But packing nodes can introduce cyclic dependencies. Example:\n@@ -2129,1 +2142,1 @@\n-  \/\/ Create nodes (from packs and scalar-nodes), and add edges, based on DepPreds.\n+  \/\/ Create nodes (from packs and scalar-nodes), and add edges, based on the dependency graph.\n@@ -2131,3 +2144,2 @@\n-    const GrowableArray<Node_List*> &packset = _slp->packset();\n-    const GrowableArray<Node*> &block = _slp->block();\n-    const DepGraph &dg = _slp->dg();\n+    const GrowableArray<Node_List*>& packset = _slp->packset();\n+    const GrowableArray<Node*>& body = _slp->body();\n@@ -2148,2 +2160,2 @@\n-    for (int i = 0; i < block.length(); i++) {\n-      Node* n = block.at(i);\n+    for (int i = 0; i < body.length(); i++) {\n+      Node* n = body.at(i);\n@@ -2170,1 +2182,1 @@\n-        for (DepPreds preds(n, dg); !preds.done(); preds.next()) {\n+        for (VLoopDependencyGraph::PredsIterator preds(_slp->dependency_graph(), n); !preds.done(); preds.next()) {\n@@ -2176,1 +2188,1 @@\n-          \/\/ Only add edges once, and only for mapped nodes (in block)\n+          \/\/ Only add edges once, and only for mapped nodes (in body)\n@@ -2186,2 +2198,2 @@\n-    for (int i = 0; i < block.length(); i++) {\n-      Node* n = block.at(i);\n+    for (int i = 0; i < body.length(); i++) {\n+      Node* n = body.at(i);\n@@ -2192,1 +2204,1 @@\n-      for (DepPreds preds(n, dg); !preds.done(); preds.next()) {\n+      for (VLoopDependencyGraph::PredsIterator preds(_slp->dependency_graph(), n); !preds.done(); preds.next()) {\n@@ -2195,1 +2207,1 @@\n-        \/\/ Only add edges for mapped nodes (in block)\n+        \/\/ Only add edges for mapped nodes (in body)\n@@ -2256,1 +2268,1 @@\n-    const GrowableArray<Node*> &block = _slp->block();\n+    const GrowableArray<Node*> &body = _slp->body();\n@@ -2269,2 +2281,2 @@\n-        for (int i = 0; i < block.length(); i++) {\n-          Node* n = block.at(i);\n+        for (int i = 0; i < body.length(); i++) {\n+          Node* n = body.at(i);\n@@ -2283,1 +2295,1 @@\n-\/\/ (1) Build the PacksetGraph. It combines the DepPreds graph with the\n+\/\/ (1) Build the PacksetGraph. It combines the dependency graph with the\n@@ -2330,1 +2342,1 @@\n-  _phase->C->print_method(PHASE_SUPERWORD1_BEFORE_SCHEDULE, 4, cl);\n+  phase()->C->print_method(PHASE_SUPERWORD1_BEFORE_SCHEDULE, 4, cl);\n@@ -2340,1 +2352,1 @@\n-  int max_slices = _phase->C->num_alias_types();\n+  int max_slices = phase()->C->num_alias_types();\n@@ -2348,0 +2360,2 @@\n+  const GrowableArray<PhiNode*>& mem_slice_head = _vloop_analyzer.memory_slices().heads();\n+\n@@ -2349,2 +2363,2 @@\n-  for (int i = 0; i < _mem_slice_head.length(); i++) {\n-    Node* phi  = _mem_slice_head.at(i);\n+  for (int i = 0; i < mem_slice_head.length(); i++) {\n+    Node* phi  = mem_slice_head.at(i);\n@@ -2352,1 +2366,1 @@\n-    int alias_idx = _phase->C->get_alias_index(phi->adr_type());\n+    int alias_idx = phase()->C->get_alias_index(phi->adr_type());\n@@ -2365,1 +2379,1 @@\n-    int alias_idx = _phase->C->get_alias_index(n->adr_type());\n+    int alias_idx = phase()->C->get_alias_index(n->adr_type());\n@@ -2374,1 +2388,1 @@\n-      _igvn.replace_input_of(n, MemNode::Memory, current_state);\n+      igvn().replace_input_of(n, MemNode::Memory, current_state);\n@@ -2385,3 +2399,3 @@\n-  for (int i = 0; i < _mem_slice_head.length(); i++) {\n-    Node* phi  = _mem_slice_head.at(i);\n-    int alias_idx = _phase->C->get_alias_index(phi->adr_type());\n+  for (int i = 0; i < mem_slice_head.length(); i++) {\n+    Node* phi  = mem_slice_head.at(i);\n+    int alias_idx = phase()->C->get_alias_index(phi->adr_type());\n@@ -2392,1 +2406,1 @@\n-    _igvn.replace_input_of(phi, 2, current_state);\n+    igvn().replace_input_of(phi, 2, current_state);\n@@ -2411,1 +2425,1 @@\n-          _igvn.replace_input_of(use, j, current_state);\n+          igvn().replace_input_of(use, j, current_state);\n@@ -2428,1 +2442,1 @@\n-  Compile* C = _phase->C;\n+  Compile* C = phase()->C;\n@@ -2439,1 +2453,1 @@\n-  _phase->C->print_method(PHASE_SUPERWORD2_BEFORE_OUTPUT, 4, cl);\n+  phase()->C->print_method(PHASE_SUPERWORD2_BEFORE_OUTPUT, 4, cl);\n@@ -2448,2 +2462,2 @@\n-  for (int i = 0; i < _block.length(); i++) {\n-    Node* n = _block.at(i);\n+  for (int i = 0; i < body().length(); i++) {\n+    Node* n = body().at(i);\n@@ -2467,1 +2481,1 @@\n-          VPointer p_store(mem->as_Mem(), phase(), lpt(), nullptr, false);\n+          VPointer p_store(mem->as_Mem(), _vloop);\n@@ -2601,1 +2615,1 @@\n-        ConINode* bol_test_node  = _igvn.intcon((int)bol_test);\n+        ConINode* bol_test_node  = igvn().intcon((int)bol_test);\n@@ -2605,3 +2619,3 @@\n-        _igvn.register_new_node_with_optimizer(mask);\n-        _phase->set_ctrl(mask, _phase->get_ctrl(p->at(0)));\n-        _igvn._worklist.push(mask);\n+        igvn().register_new_node_with_optimizer(mask);\n+        phase()->set_ctrl(mask, phase()->get_ctrl(p->at(0)));\n+        igvn()._worklist.push(mask);\n@@ -2680,2 +2694,2 @@\n-        _igvn.register_new_node_with_optimizer(longval);\n-        _phase->set_ctrl(longval, _phase->get_ctrl(first));\n+        igvn().register_new_node_with_optimizer(longval);\n+        phase()->set_ctrl(longval, phase()->get_ctrl(first));\n@@ -2728,3 +2742,2 @@\n-      _block.at_put(i, vn);\n-      _igvn.register_new_node_with_optimizer(vn);\n-      _phase->set_ctrl(vn, _phase->get_ctrl(first));\n+      igvn().register_new_node_with_optimizer(vn);\n+      phase()->set_ctrl(vn, phase()->get_ctrl(first));\n@@ -2733,1 +2746,1 @@\n-        _igvn.replace_node(pm, vn);\n+        igvn().replace_node(pm, vn);\n@@ -2735,1 +2748,1 @@\n-      _igvn._worklist.push(vn);\n+      igvn()._worklist.push(vn);\n@@ -2745,1 +2758,1 @@\n-  }\/\/for (int i = 0; i < _block.length(); i++)\n+  }\/\/for (int i = 0; i < body().length(); i++)\n@@ -2774,1 +2787,1 @@\n-  _phase->C->print_method(PHASE_SUPERWORD3_AFTER_OUTPUT, 4, cl);\n+  phase()->C->print_method(PHASE_SUPERWORD3_AFTER_OUTPUT, 4, cl);\n@@ -2797,1 +2810,1 @@\n-    Node* vn = new PopulateIndexNode(iv(), _igvn.intcon(1), vt);\n+    Node* vn = new PopulateIndexNode(iv(), igvn().intcon(1), vt);\n@@ -2799,2 +2812,2 @@\n-    _igvn.register_new_node_with_optimizer(vn);\n-    _phase->set_ctrl(vn, _phase->get_ctrl(opd));\n+    igvn().register_new_node_with_optimizer(vn);\n+    phase()->set_ctrl(vn, phase()->get_ctrl(opd));\n@@ -2821,1 +2834,1 @@\n-          _igvn.register_new_node_with_optimizer(cnt);\n+          igvn().register_new_node_with_optimizer(cnt);\n@@ -2826,1 +2839,1 @@\n-          _igvn.register_new_node_with_optimizer(cnt);\n+          igvn().register_new_node_with_optimizer(cnt);\n@@ -2828,2 +2841,2 @@\n-          _igvn.register_new_node_with_optimizer(cnt);\n-          _phase->set_ctrl(cnt, _phase->get_ctrl(opd));\n+          igvn().register_new_node_with_optimizer(cnt);\n+          phase()->set_ctrl(cnt, phase()->get_ctrl(opd));\n@@ -2838,2 +2851,2 @@\n-      _igvn.register_new_node_with_optimizer(cnt);\n-      _phase->set_ctrl(cnt, _phase->get_ctrl(opd));\n+      igvn().register_new_node_with_optimizer(cnt);\n+      phase()->set_ctrl(cnt, phase()->get_ctrl(opd));\n@@ -2857,2 +2870,2 @@\n-         _igvn.register_new_node_with_optimizer(conv);\n-         _phase->set_ctrl(conv, _phase->get_ctrl(opd));\n+         igvn().register_new_node_with_optimizer(conv);\n+         phase()->set_ctrl(conv, phase()->get_ctrl(opd));\n@@ -2866,2 +2879,2 @@\n-    _igvn.register_new_node_with_optimizer(vn);\n-    _phase->set_ctrl(vn, _phase->get_ctrl(opd));\n+    igvn().register_new_node_with_optimizer(vn);\n+    phase()->set_ctrl(vn, phase()->get_ctrl(opd));\n@@ -2896,2 +2909,2 @@\n-  _igvn.register_new_node_with_optimizer(pk);\n-  _phase->set_ctrl(pk, _phase->get_ctrl(opd));\n+  igvn().register_new_node_with_optimizer(pk);\n+  phase()->set_ctrl(pk, phase()->get_ctrl(opd));\n@@ -2932,0 +2945,88 @@\n+\/\/ Check if n_super's pack uses are a superset of n_sub's pack uses.\n+bool SuperWord::has_use_pack_superset(const Node* n_super, const Node* n_sub) const {\n+  Node_List* pack = my_pack(n_super);\n+  assert(pack != nullptr && pack == my_pack(n_sub), \"must have the same pack\");\n+\n+  \/\/ For all uses of n_sub that are in a pack (use_sub) ...\n+  for (DUIterator_Fast jmax, j = n_sub->fast_outs(jmax); j < jmax; j++) {\n+    Node* use_sub = n_sub->fast_out(j);\n+    Node_List* pack_use_sub = my_pack(use_sub);\n+    if (pack_use_sub == nullptr) { continue; }\n+\n+    \/\/ ... and all input edges: use_sub->in(i) == n_sub.\n+    uint start, end;\n+    VectorNode::vector_operands(use_sub, &start, &end);\n+    for (uint i = start; i < end; i++) {\n+      if (use_sub->in(i) != n_sub) { continue; }\n+\n+      \/\/ Check if n_super has any use use_super in the same pack ...\n+      bool found = false;\n+      for (DUIterator_Fast kmax, k = n_super->fast_outs(kmax); k < kmax; k++) {\n+        Node* use_super = n_super->fast_out(k);\n+        Node_List* pack_use_super = my_pack(use_super);\n+        if (pack_use_sub != pack_use_super) { continue; }\n+\n+        \/\/ ... and where there is an edge use_super->in(i) == n_super.\n+        \/\/ For MulAddS2I it is expected to have defs over different input edges.\n+        if (use_super->in(i) != n_super && !VectorNode::is_muladds2i(use_super)) { continue; }\n+\n+        found = true;\n+        break;\n+      }\n+      if (!found) {\n+        \/\/ n_sub has a use-edge (use_sub->in(i) == n_sub) with use_sub in a packset,\n+        \/\/ but n_super does not have any edge (use_super->in(i) == n_super) with\n+        \/\/ use_super in the same packset. Hence, n_super does not have a use pack\n+        \/\/ superset of n_sub.\n+        return false;\n+      }\n+    }\n+  }\n+  \/\/ n_super has all edges that n_sub has.\n+  return true;\n+}\n+\n+\/\/ Find a boundary in the pack, where left and right have different pack uses and defs.\n+\/\/ This is a natural boundary to split a pack, to ensure that use and def packs match.\n+\/\/ If no boundary is found, return zero.\n+uint SuperWord::find_use_def_boundary(const Node_List* pack) const {\n+  Node* p0 = pack->at(0);\n+  Node* p1 = pack->at(1);\n+\n+  const bool is_reduction_pack = reduction(p0, p1);\n+\n+  \/\/ Inputs range\n+  uint start, end;\n+  VectorNode::vector_operands(p0, &start, &end);\n+\n+  for (int i = pack->size() - 2; i >= 0; i--) {\n+    \/\/ For all neighbours\n+    Node* n0 = pack->at(i + 0);\n+    Node* n1 = pack->at(i + 1);\n+\n+\n+    \/\/ 1. Check for matching defs\n+    for (uint j = start; j < end; j++) {\n+      Node* n0_in = n0->in(j);\n+      Node* n1_in = n1->in(j);\n+      \/\/ No boundary if:\n+      \/\/ 1) the same packs OR\n+      \/\/ 2) reduction edge n0->n1 or n1->n0\n+      if (my_pack(n0_in) != my_pack(n1_in) &&\n+          !((n0 == n1_in || n1 == n0_in) && is_reduction_pack)) {\n+        return i + 1;\n+      }\n+    }\n+\n+    \/\/ 2. Check for matching uses: equal if both are superset of the other.\n+    \/\/    Reductions have no pack uses, so they match trivially on the use packs.\n+    if (!is_reduction_pack &&\n+        !(has_use_pack_superset(n0, n1) &&\n+          has_use_pack_superset(n1, n0))) {\n+      return i + 1;\n+    }\n+  }\n+\n+  return 0;\n+}\n+\n@@ -3009,4 +3110,3 @@\n-\/\/------------------------------construct_bb---------------------------\n-\/\/ Construct reverse postorder list of block members\n-bool SuperWord::construct_bb() {\n-  assert(_block.length() == 0,          \"block is empty\");\n+\/\/ Return nullptr if success, else failure message\n+VStatus VLoopBody::construct() {\n+  assert(_body.is_empty(), \"body is empty\");\n@@ -3018,3 +3118,3 @@\n-  int block_count = 0;\n-  for (uint i = 0; i < lpt()->_body.size(); i++) {\n-    Node* n = lpt()->_body.at(i);\n+  int body_count = 0;\n+  for (uint i = 0; i < _vloop.lpt()->_body.size(); i++) {\n+    Node* n = _vloop.lpt()->_body.at(i);\n@@ -3022,2 +3122,2 @@\n-    if (in_bb(n)) {\n-      block_count++;\n+    if (_vloop.in_bb(n)) {\n+      body_count++;\n@@ -3030,2 +3130,2 @@\n-        if (is_trace_superword_any()) {\n-          tty->print_cr(\"SuperWord::construct_bb: fails because of unhandled node:\");\n+        if (_vloop.is_trace_body()) {\n+          tty->print_cr(\"VLoopBody::construct: fails because of unhandled node:\");\n@@ -3035,1 +3135,1 @@\n-        return false;\n+        return VStatus::make_failure(VLoopBody::FAILURE_NODE_NOT_ALLOWED);\n@@ -3038,1 +3138,0 @@\n-#ifdef ASSERT\n@@ -3043,1 +3142,1 @@\n-          if (def != nullptr && in_bb(def)) {\n+          if (def != nullptr && _vloop.in_bb(def)) {\n@@ -3048,2 +3147,7 @@\n-        assert(found, \"every non-cfg node must have an input that is also inside the loop\");\n-      }\n+        if (!found) {\n+          \/\/ If all inputs to a data-node are outside the loop, the node itself should be outside the loop.\n+#ifndef PRODUCT\n+          if (_vloop.is_trace_body()) {\n+            tty->print_cr(\"VLoopBody::construct: fails because data node in loop has no input in loop:\");\n+            n->dump();\n+          }\n@@ -3051,0 +3155,3 @@\n+          return VStatus::make_failure(VLoopBody::FAILURE_UNEXPECTED_CTRL);\n+        }\n+      }\n@@ -3054,1 +3161,1 @@\n-  \/\/ Create a reverse-post-order list of nodes in block\n+  \/\/ Create a reverse-post-order list of nodes in body\n@@ -3060,2 +3167,2 @@\n-  visited.set(bb_idx(bb()));\n-  stack.push(bb());\n+  visited.set(bb_idx(_vloop.cl()));\n+  stack.push(_vloop.cl());\n@@ -3064,1 +3171,1 @@\n-  int rpo_idx = block_count - 1;\n+  int rpo_idx = body_count - 1;\n@@ -3074,1 +3181,1 @@\n-        if (in_bb(use) && !visited.test(bb_idx(use)) &&\n+        if (_vloop.in_bb(use) && !visited.test(bb_idx(use)) &&\n@@ -3076,1 +3183,1 @@\n-            (!use->is_Phi() || n == bb())) {\n+            (!use->is_Phi() || n == _vloop.cl())) {\n@@ -3084,1 +3191,1 @@\n-        _block.at_put_grow(rpo_idx, n);\n+        _body.at_put_grow(rpo_idx, n);\n@@ -3094,3 +3201,3 @@\n-  \/\/ Create real map of block indices for nodes\n-  for (int j = 0; j < _block.length(); j++) {\n-    Node* n = _block.at(j);\n+  \/\/ Create real map of body indices for nodes\n+  for (int j = 0; j < _body.length(); j++) {\n+    Node* n = _body.at(j);\n@@ -3101,2 +3208,2 @@\n-  if (is_trace_superword_info()) {\n-    print_bb();\n+  if (_vloop.is_trace_body()) {\n+    print();\n@@ -3106,2 +3213,2 @@\n-  assert(rpo_idx == -1 && block_count == _block.length(), \"all block members found\");\n-  return true;\n+  assert(rpo_idx == -1 && body_count == _body.length(), \"all body members found\");\n+  return VStatus::make_success();\n@@ -3112,1 +3219,1 @@\n-  Node* last = _block.at(_block.length() - 1);\n+  Node* last = body().at(body().length() - 1);\n@@ -3116,35 +3223,0 @@\n-\/\/------------------------------compute_max_depth---------------------------\n-\/\/ Compute max depth for expressions from beginning of block\n-\/\/ Use to prune search paths during test for independence.\n-void SuperWord::compute_max_depth() {\n-  int ct = 0;\n-  bool again;\n-  do {\n-    again = false;\n-    for (int i = 0; i < _block.length(); i++) {\n-      Node* n = _block.at(i);\n-      if (!n->is_Phi()) {\n-        int d_orig = depth(n);\n-        int d_in   = 0;\n-        for (DepPreds preds(n, _dg); !preds.done(); preds.next()) {\n-          Node* pred = preds.current();\n-          if (in_bb(pred)) {\n-            d_in = MAX2(d_in, depth(pred));\n-          }\n-        }\n-        if (d_in + 1 != d_orig) {\n-          set_depth(n, d_in + 1);\n-          again = true;\n-        }\n-      }\n-    }\n-    ct++;\n-  } while (again);\n-\n-#ifndef PRODUCT\n-  if (is_trace_superword_dependence_graph()) {\n-    tty->print_cr(\"compute_max_depth iterated: %d times\", ct);\n-  }\n-#endif\n-}\n-\n@@ -3200,8 +3272,1 @@\n-\/\/-------------------------compute_vector_element_type-----------------------\n-\/\/ Compute necessary vector element type for expressions\n-\/\/ This propagates backwards a narrower integer type when the\n-\/\/ upper bits of the value are not needed.\n-\/\/ Example:  char a,b,c;  a = b + c;\n-\/\/ Normally the type of the add is integer, but for packed character\n-\/\/ operations the type of the add needs to be char.\n-void SuperWord::compute_vector_element_type() {\n+void VLoopTypes::compute_vector_element_type() {\n@@ -3209,2 +3274,2 @@\n-  if (is_trace_superword_vector_element_type()) {\n-    tty->print_cr(\"\\ncompute_velt_type:\");\n+  if (_vloop.is_trace_vector_element_type()) {\n+    tty->print_cr(\"\\nVLoopTypes::compute_vector_element_type:\");\n@@ -3214,0 +3279,6 @@\n+  const GrowableArray<Node*>& body = _body.body();\n+\n+  assert(_velt_type.is_empty(), \"must not yet be computed\");\n+  \/\/ reserve space\n+  _velt_type.at_put_grow(body.length()-1, nullptr);\n+\n@@ -3215,2 +3286,2 @@\n-  for (int i = 0; i < _block.length(); i++) {\n-    Node* n = _block.at(i);\n+  for (int i = 0; i < body.length(); i++) {\n+    Node* n = body.at(i);\n@@ -3222,2 +3293,2 @@\n-  for (int i = _block.length() - 1; i >= 0; i--) {\n-    Node* n = _block.at(i);\n+  for (int i = body.length() - 1; i >= 0; i--) {\n+    Node* n = body.at(i);\n@@ -3233,1 +3304,3 @@\n-        if (!in->is_Mem() && in_bb(in) && velt_type(in)->basic_type() == T_INT &&\n+        if (!in->is_Mem() &&\n+            _vloop.in_bb(in) &&\n+            velt_type(in)->basic_type() == T_INT &&\n@@ -3238,1 +3311,1 @@\n-            if (!in_bb(use) || !same_velt_type(use, n)) {\n+            if (!_vloop.in_bb(use) || !same_velt_type(use, n)) {\n@@ -3255,1 +3328,3 @@\n-              if (load->is_Load() && in_bb(load) && (velt_type(load)->basic_type() == T_INT)) {\n+              if (load->is_Load() &&\n+                  _vloop.in_bb(load) &&\n+                  (velt_type(load)->basic_type() == T_INT)) {\n@@ -3271,2 +3346,2 @@\n-  for (int i = 0; i < _block.length(); i++) {\n-    Node* n = _block.at(i);\n+  for (int i = 0; i < body.length(); i++) {\n+    Node* n = body.at(i);\n@@ -3279,2 +3354,3 @@\n-      assert(in_bb(nn->in(1)) || in_bb(nn->in(2)), \"one of the inputs must be in the loop too\");\n-      if (in_bb(nn->in(1))) {\n+      assert(_vloop.in_bb(nn->in(1)) || _vloop.in_bb(nn->in(2)),\n+             \"one of the inputs must be in the loop, too\");\n+      if (_vloop.in_bb(nn->in(1))) {\n@@ -3288,3 +3364,3 @@\n-  if (is_trace_superword_vector_element_type()) {\n-    for (int i = 0; i < _block.length(); i++) {\n-      Node* n = _block.at(i);\n+  if (_vloop.is_trace_vector_element_type()) {\n+    for (int i = 0; i < body.length(); i++) {\n+      Node* n = body.at(i);\n@@ -3307,1 +3383,1 @@\n-  VPointer p(s, phase(), lpt(), nullptr, false);\n+  VPointer p(s, _vloop);\n@@ -3329,2 +3405,1 @@\n-\/\/---------------------------container_type---------------------------\n-const Type* SuperWord::container_type(Node* n) {\n+const Type* VLoopTypes::container_type(Node* n) const {\n@@ -3349,1 +3424,1 @@\n-  const Type* t = _igvn.type(n);\n+  const Type* t = _vloop.phase()->igvn().type(n);\n@@ -3358,0 +3433,1 @@\n+\n@@ -3366,12 +3442,3 @@\n-bool SuperWord::same_velt_type(Node* n1, Node* n2) {\n-  const Type* vt1 = velt_type(n1);\n-  const Type* vt2 = velt_type(n2);\n-  if (vt1->basic_type() == T_INT && vt2->basic_type() == T_INT) {\n-    \/\/ Compare vectors element sizes for integer types.\n-    return data_size(n1) == data_size(n2);\n-  }\n-  return vt1 == vt2;\n-}\n-\n-bool SuperWord::same_memory_slice(MemNode* best_align_to_mem_ref, MemNode* mem_ref) const {\n-  return _phase->C->get_alias_index(mem_ref->adr_type()) == _phase->C->get_alias_index(best_align_to_mem_ref->adr_type());\n+bool VLoopMemorySlices::same_memory_slice(MemNode* m1, MemNode* m2) const {\n+  return _vloop.phase()->C->get_alias_index(m1->adr_type()) ==\n+         _vloop.phase()->C->get_alias_index(m2->adr_type());\n@@ -3401,1 +3468,1 @@\n-  _packset.remove_at(pos);\n+  _packset.at_put(pos, nullptr);\n@@ -3457,1 +3524,1 @@\n-  assert(lp()->is_main_loop(), \"can only do alignment for main loop\");\n+  assert(cl()->is_main_loop(), \"can only do alignment for main loop\");\n@@ -3460,1 +3527,1 @@\n-  Opaque1Node* pre_opaq = lp()->pre_loop_end()->limit()->as_Opaque1();\n+  Opaque1Node* pre_opaq = _vloop.pre_loop_end()->limit()->as_Opaque1();\n@@ -3466,1 +3533,1 @@\n-  Node* pre_ctrl = lp()->pre_loop_head()->in(LoopNode::EntryControl);\n+  Node* pre_ctrl = _vloop.pre_loop_head()->in(LoopNode::EntryControl);\n@@ -3470,1 +3537,1 @@\n-  assert(orig_limit != nullptr && _igvn.type(orig_limit) != Type::TOP, \"\");\n+  assert(orig_limit != nullptr && igvn().type(orig_limit) != Type::TOP, \"\");\n@@ -3472,1 +3539,1 @@\n-  VPointer align_to_ref_p(align_to_ref, phase(), lpt(), nullptr, false);\n+  VPointer align_to_ref_p(align_to_ref, _vloop);\n@@ -3666,1 +3733,1 @@\n-  Node* xboi = _igvn.intcon(is_sub ? -offset : offset);\n+  Node* xboi = igvn().intcon(is_sub ? -offset : offset);\n@@ -3671,1 +3738,1 @@\n-    if (_igvn.type(invar)->isa_long()) {\n+    if (igvn().type(invar)->isa_long()) {\n@@ -3676,1 +3743,1 @@\n-      _igvn.register_new_node_with_optimizer(invar);\n+      igvn().register_new_node_with_optimizer(invar);\n@@ -3684,2 +3751,2 @@\n-    _igvn.register_new_node_with_optimizer(xboi);\n-    _phase->set_ctrl(xboi, pre_ctrl);\n+    igvn().register_new_node_with_optimizer(xboi);\n+    phase()->set_ctrl(xboi, pre_ctrl);\n@@ -3695,1 +3762,1 @@\n-    _igvn.register_new_node_with_optimizer(xbase);\n+    igvn().register_new_node_with_optimizer(xbase);\n@@ -3699,1 +3766,1 @@\n-    _igvn.register_new_node_with_optimizer(xbase);\n+    igvn().register_new_node_with_optimizer(xbase);\n@@ -3707,2 +3774,2 @@\n-    _igvn.register_new_node_with_optimizer(xboi);\n-    _phase->set_ctrl(xboi, pre_ctrl);\n+    igvn().register_new_node_with_optimizer(xboi);\n+    phase()->set_ctrl(xboi, pre_ctrl);\n@@ -3715,1 +3782,1 @@\n-  Node* log2_abs_scale = _igvn.intcon(exact_log2(abs(scale)));\n+  Node* log2_abs_scale = igvn().intcon(exact_log2(abs(scale)));\n@@ -3717,2 +3784,2 @@\n-  _igvn.register_new_node_with_optimizer(XBOI);\n-  _phase->set_ctrl(XBOI, pre_ctrl);\n+  igvn().register_new_node_with_optimizer(XBOI);\n+  phase()->set_ctrl(XBOI, pre_ctrl);\n@@ -3732,2 +3799,2 @@\n-  _igvn.register_new_node_with_optimizer(XBOI_OP_old_limit);\n-  _phase->set_ctrl(XBOI_OP_old_limit, pre_ctrl);\n+  igvn().register_new_node_with_optimizer(XBOI_OP_old_limit);\n+  phase()->set_ctrl(XBOI_OP_old_limit, pre_ctrl);\n@@ -3742,1 +3809,1 @@\n-  Node* mask_AW = _igvn.intcon(AW-1);\n+  Node* mask_AW = igvn().intcon(AW-1);\n@@ -3744,2 +3811,2 @@\n-  _igvn.register_new_node_with_optimizer(adjust_pre_iter);\n-  _phase->set_ctrl(adjust_pre_iter, pre_ctrl);\n+  igvn().register_new_node_with_optimizer(adjust_pre_iter);\n+  phase()->set_ctrl(adjust_pre_iter, pre_ctrl);\n@@ -3758,2 +3825,2 @@\n-  _igvn.register_new_node_with_optimizer(new_limit);\n-  _phase->set_ctrl(new_limit, pre_ctrl);\n+  igvn().register_new_node_with_optimizer(new_limit);\n+  phase()->set_ctrl(new_limit, pre_ctrl);\n@@ -3767,2 +3834,2 @@\n-  _igvn.register_new_node_with_optimizer(constrained_limit);\n-  _phase->set_ctrl(constrained_limit, pre_ctrl);\n+  igvn().register_new_node_with_optimizer(constrained_limit);\n+  phase()->set_ctrl(constrained_limit, pre_ctrl);\n@@ -3772,16 +3839,1 @@\n-  _igvn.replace_input_of(pre_opaq, 1, constrained_limit);\n-}\n-\n-\/\/------------------------------init---------------------------\n-void SuperWord::init() {\n-  _dg.init();\n-  _packset.clear();\n-  _block.clear();\n-  _mem_slice_head.clear();\n-  _mem_slice_tail.clear();\n-  _node_info.clear();\n-  _align_to_ref = nullptr;\n-  _race_possible = 0;\n-  _early_return = false;\n-  _num_work_vecs = 0;\n-  _num_reductions = 0;\n+  igvn().replace_input_of(pre_opaq, 1, constrained_limit);\n@@ -3813,2 +3865,1 @@\n-\/\/------------------------------print_bb---------------------------\n-void SuperWord::print_bb() {\n+void VLoopBody::print() const {\n@@ -3817,2 +3868,2 @@\n-  for (int i = 0; i < _block.length(); i++) {\n-    Node* n = _block.at(i);\n+  for (int i = 0; i < body().length(); i++) {\n+    Node* n = body().at(i);\n@@ -3820,1 +3871,1 @@\n-    if (n) {\n+    if (n != nullptr) {\n@@ -3824,1 +3875,1 @@\n-#endif\n+#endif\n@@ -3839,135 +3890,0 @@\n-\n-\/\/ ============================ DepGraph ===========================\n-\n-\/\/------------------------------make_node---------------------------\n-\/\/ Make a new dependence graph node for an ideal node.\n-DepMem* DepGraph::make_node(Node* node) {\n-  DepMem* m = new (_arena) DepMem(node);\n-  if (node != nullptr) {\n-    assert(_map.at_grow(node->_idx) == nullptr, \"one init only\");\n-    _map.at_put_grow(node->_idx, m);\n-  }\n-  return m;\n-}\n-\n-\/\/------------------------------make_edge---------------------------\n-\/\/ Make a new dependence graph edge from dpred -> dsucc\n-DepEdge* DepGraph::make_edge(DepMem* dpred, DepMem* dsucc) {\n-  DepEdge* e = new (_arena) DepEdge(dpred, dsucc, dsucc->in_head(), dpred->out_head());\n-  dpred->set_out_head(e);\n-  dsucc->set_in_head(e);\n-  return e;\n-}\n-\n-\/\/ ========================== DepMem ========================\n-\n-\/\/------------------------------in_cnt---------------------------\n-int DepMem::in_cnt() {\n-  int ct = 0;\n-  for (DepEdge* e = _in_head; e != nullptr; e = e->next_in()) ct++;\n-  return ct;\n-}\n-\n-\/\/------------------------------out_cnt---------------------------\n-int DepMem::out_cnt() {\n-  int ct = 0;\n-  for (DepEdge* e = _out_head; e != nullptr; e = e->next_out()) ct++;\n-  return ct;\n-}\n-\n-\/\/------------------------------print-----------------------------\n-void DepMem::print() {\n-#ifndef PRODUCT\n-  tty->print(\"  DepNode %d (\", _node->_idx);\n-  for (DepEdge* p = _in_head; p != nullptr; p = p->next_in()) {\n-    Node* pred = p->pred()->node();\n-    tty->print(\" %d\", pred != nullptr ? pred->_idx : 0);\n-  }\n-  tty->print(\") [\");\n-  for (DepEdge* s = _out_head; s != nullptr; s = s->next_out()) {\n-    Node* succ = s->succ()->node();\n-    tty->print(\" %d\", succ != nullptr ? succ->_idx : 0);\n-  }\n-  tty->print_cr(\" ]\");\n-#endif\n-}\n-\n-\/\/ =========================== DepEdge =========================\n-\n-\/\/------------------------------DepPreds---------------------------\n-void DepEdge::print() {\n-#ifndef PRODUCT\n-  tty->print_cr(\"DepEdge: %d [ %d ]\", _pred->node()->_idx, _succ->node()->_idx);\n-#endif\n-}\n-\n-\/\/ =========================== DepPreds =========================\n-\/\/ Iterator over predecessor edges in the dependence graph.\n-\n-\/\/------------------------------DepPreds---------------------------\n-DepPreds::DepPreds(Node* n, const DepGraph& dg) {\n-  _n = n;\n-  _done = false;\n-  if (_n->is_Store() || _n->is_Load()) {\n-    _next_idx = MemNode::Address;\n-    _end_idx  = n->req();\n-    _dep_next = dg.dep(_n)->in_head();\n-  } else if (_n->is_Mem()) {\n-    _next_idx = 0;\n-    _end_idx  = 0;\n-    _dep_next = dg.dep(_n)->in_head();\n-  } else {\n-    _next_idx = 1;\n-    _end_idx  = _n->req();\n-    _dep_next = nullptr;\n-  }\n-  next();\n-}\n-\n-\/\/------------------------------next---------------------------\n-void DepPreds::next() {\n-  if (_dep_next != nullptr) {\n-    _current  = _dep_next->pred()->node();\n-    _dep_next = _dep_next->next_in();\n-  } else if (_next_idx < _end_idx) {\n-    _current  = _n->in(_next_idx++);\n-  } else {\n-    _done = true;\n-  }\n-}\n-\n-\/\/ =========================== DepSuccs =========================\n-\/\/ Iterator over successor edges in the dependence graph.\n-\n-\/\/------------------------------DepSuccs---------------------------\n-DepSuccs::DepSuccs(Node* n, DepGraph& dg) {\n-  _n = n;\n-  _done = false;\n-  if (_n->is_Load()) {\n-    _next_idx = 0;\n-    _end_idx  = _n->outcnt();\n-    _dep_next = dg.dep(_n)->out_head();\n-  } else if (_n->is_Mem() || _n->is_memory_phi()) {\n-    _next_idx = 0;\n-    _end_idx  = 0;\n-    _dep_next = dg.dep(_n)->out_head();\n-  } else {\n-    _next_idx = 0;\n-    _end_idx  = _n->outcnt();\n-    _dep_next = nullptr;\n-  }\n-  next();\n-}\n-\n-\/\/-------------------------------next---------------------------\n-void DepSuccs::next() {\n-  if (_dep_next != nullptr) {\n-    _current  = _dep_next->succ()->node();\n-    _dep_next = _dep_next->next_out();\n-  } else if (_next_idx < _end_idx) {\n-    _current  = _n->raw_out(_next_idx++);\n-  } else {\n-    _done = true;\n-  }\n-}\n-\n","filename":"src\/hotspot\/share\/opto\/superword.cpp","additions":767,"deletions":851,"binary":false,"changes":1618,"status":"modified"},{"patch":"@@ -43,0 +43,1 @@\n+#include \"code\/compiledIC.hpp\"\n@@ -66,1 +67,0 @@\n-#include \"oops\/compiledICHolder.hpp\"\n@@ -216,2 +216,0 @@\n-  nonstatic_field(CompiledICHolder,            _holder_metadata,                              Metadata*)                             \\\n-  nonstatic_field(CompiledICHolder,            _holder_klass,                                 Klass*)                                \\\n@@ -731,1 +729,0 @@\n-  nonstatic_field(ciEnv,                       _failure_reason,                               const char*)                           \\\n@@ -1167,1 +1164,0 @@\n-  declare_toplevel_type(CompiledICHolder)                                 \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -76,0 +76,1 @@\n+@SuppressWarnings(\"serial\")\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Float16.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -235,0 +235,1 @@\n+        AVX_IFMA,\n","filename":"src\/jdk.internal.vm.ci\/share\/classes\/jdk\/vm\/ci\/amd64\/AMD64.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -895,0 +895,5 @@\n+    public static final String MAX_VL = VECTOR_PREFIX + \"MAX_VL\" + POSTFIX;\n+    static {\n+        vectorNode(MAX_VL, \"MaxV\", TYPE_LONG);\n+    }\n+\n@@ -970,0 +975,5 @@\n+    public static final String MIN_VL = VECTOR_PREFIX + \"MIN_VL\" + POSTFIX;\n+    static {\n+        vectorNode(MIN_VL, \"MinV\", TYPE_LONG);\n+    }\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/IRNode.java","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"}]}