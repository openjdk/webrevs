{"files":[{"patch":"@@ -63,0 +63,4 @@\n+java.base-FLAT-LAYOUT-VALUE-CLASS-REPLACEMENTS := \\\n+    java\/lang\/Float16.java \\\n+    #\n+\n@@ -66,0 +70,3 @@\n+java.base-FLAT-LAYOUT-VALUE-CLASS-FILES := \\\n+    $(foreach f, $(java.base-FLAT-LAYOUT-VALUE-CLASS-REPLACEMENTS), $(addprefix $(TOPDIR)\/src\/java.base\/share\/classes\/, $(f)))\n+\n@@ -76,0 +83,9 @@\n+$(eval $(call SetupTextFileProcessing, JAVA_BASE_FLAT_LAYOUT_VALUECLASS_REPLACEMENTS, \\\n+    SOURCE_FILES := $(java.base-FLAT-LAYOUT-VALUE-CLASS-FILES), \\\n+    SOURCE_BASE_DIR := $(TOPDIR)\/src\/java.base\/share\/classes, \\\n+    OUTPUT_DIR := $(SUPPORT_OUTPUTDIR)\/gensrc-valueclasses\/java.base\/, \\\n+    REPLACEMENTS := \\\n+        public final class => @jdk.internal.vm.annotation.ImplicitlyConstructible\\n@jdk.internal.vm.annotation.NullRestrictedArray\\npublic final value class ; \\\n+        public abstract class => public abstract value class, \\\n+))\n+\n@@ -77,0 +93,1 @@\n+TARGETS += $(JAVA_BASE_FLAT_LAYOUT_VALUECLASS_REPLACEMENTS)\n","filename":"make\/modules\/java.base\/gensrc\/GensrcValueClasses.gmk","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -2302,1 +2302,14 @@\n-      break;\n+    break;\n+    case Op_AddHF:\n+    case Op_SubHF:\n+    case Op_MulHF:\n+    case Op_DivHF:\n+    case Op_MinHF:\n+    case Op_MaxHF:\n+      \/\/ Half-precision floating point scalar operations require FEAT_FP16\n+      \/\/ to be available. FEAT_FP16 is enabled if both \"fphp\" and \"asimdhp\"\n+      \/\/ features are supported.\n+      if (!VM_Version::supports_fphp() || !VM_Version::supports_asimdhp()) {\n+        return false;\n+    }\n+    break;\n@@ -13634,0 +13647,15 @@\n+\/\/ Half-precision floating point add operation\n+instruct addHF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{\n+  match(Set dst (AddHF src1 src2));\n+\n+  format %{ \"faddh   $dst, $src1, $src2\" %}\n+\n+  ins_encode %{\n+    __ faddh(as_FloatRegister($dst$$reg),\n+             as_FloatRegister($src1$$reg),\n+             as_FloatRegister($src2$$reg));\n+  %}\n+\n+  ins_pipe(fp_dop_reg_reg_s);\n+%}\n+\n@@ -13664,0 +13692,15 @@\n+instruct subHF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{\n+  match(Set dst (SubHF src1 src2));\n+\n+  ins_cost(INSN_COST * 5);\n+  format %{ \"fsubh   $dst, $src1, $src2\" %}\n+\n+  ins_encode %{\n+    __ fsubh(as_FloatRegister($dst$$reg),\n+             as_FloatRegister($src1$$reg),\n+             as_FloatRegister($src2$$reg));\n+  %}\n+\n+  ins_pipe(fp_dop_reg_reg_s);\n+%}\n+\n@@ -13694,0 +13737,15 @@\n+instruct mulHF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{\n+  match(Set dst (MulHF src1 src2));\n+\n+  ins_cost(INSN_COST * 6);\n+  format %{ \"fmulh   $dst, $src1, $src2\" %}\n+\n+  ins_encode %{\n+    __ fmulh(as_FloatRegister($dst$$reg),\n+             as_FloatRegister($src1$$reg),\n+             as_FloatRegister($src2$$reg));\n+  %}\n+\n+  ins_pipe(fp_dop_reg_reg_s);\n+%}\n+\n@@ -13865,0 +13923,23 @@\n+\/\/ Math.max(HF)\n+instruct maxHF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{\n+  match(Set dst (MaxHF src1 src2));\n+  format %{ \"fmaxh   $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    __ fmaxh(as_FloatRegister($dst$$reg),\n+             as_FloatRegister($src1$$reg),\n+             as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(fp_dop_reg_reg_s);\n+%}\n+\n+\/\/ Math.min(HF)\n+instruct minHF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{\n+  match(Set dst (MinHF src1 src2));\n+  format %{ \"fminh   $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    __ fminh(as_FloatRegister($dst$$reg),\n+             as_FloatRegister($src1$$reg),\n+             as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(fp_dop_reg_reg_s);\n+%}\n@@ -13922,0 +14003,14 @@\n+instruct divHF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{\n+  match(Set dst (DivHF src1  src2));\n+\n+  ins_cost(INSN_COST * 18);\n+  format %{ \"fdivh   $dst, $src1, $src2\" %}\n+\n+  ins_encode %{\n+    __ fdivh(as_FloatRegister($dst$$reg),\n+             as_FloatRegister($src1$$reg),\n+             as_FloatRegister($src2$$reg));\n+  %}\n+\n+  ins_pipe(fp_div_s);\n+%}\n@@ -17071,0 +17166,39 @@\n+\/\/----------------------------- Reinterpret ----------------------------------\n+\n+instruct reinterpretHF2S(iRegINoSp dst, vRegF src) %{\n+  match(Set dst (ReinterpretHF2S src));\n+  format %{ \"reinterpretHF2S $dst, $src\" %}\n+  ins_encode %{\n+    __ smov($dst$$Register, $src$$FloatRegister, __ H, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reinterpretS2HF(vRegF dst, iRegINoSp src) %{\n+  match(Set dst (ReinterpretS2HF src));\n+  format %{ \"reinterpretS2HF $dst, $src\" %}\n+  ins_encode %{\n+    __ mov($dst$$FloatRegister, __ H, 0, $src$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct convF2HFAndS2HF(vRegF dst, vRegF src)\n+%{\n+  match(Set dst (ReinterpretS2HF (ConvF2HF src)));\n+  format %{ \"convF2HFAndS2HF $dst, $src\" %}\n+  ins_encode %{\n+    __ fcvtsh($dst$$FloatRegister, $src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reinterpretHF2SAndHF2F(vRegF dst, vRegF src)\n+%{\n+  match(Set dst (ConvHF2F (ReinterpretHF2S src)));\n+  format %{ \"reinterpretHF2SAndHF2F $dst, $src\" %}\n+  ins_encode %{\n+    __ fcvths($dst$$FloatRegister, $src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":135,"deletions":1,"binary":false,"changes":136,"status":"modified"},{"patch":"@@ -244,0 +244,13 @@\n+\/\/ This method is used to generate Advanced SIMD data processing instructions\n+void Assembler::adv_simd_three_same(Instruction_aarch64 &current_insn, FloatRegister Vd,\n+                                    SIMD_Arrangement T, FloatRegister Vn, FloatRegister Vm,\n+                                    int op1, int op2, int op3) {\n+  assert(T == T4H || T == T8H || T == T2S || T == T4S || T == T2D, \"invalid arrangement\");\n+  int op22 = (T == T2S || T == T4S) ? 0b0 : 0b1;\n+  int op21 = (T == T4H || T == T8H) ? 0b0 : 0b1;\n+  int op14 = (T == T4H || T == T8H) ? 0b00 : 0b11;\n+  f(0, 31), f((int)T & 1, 30), f(op1, 29), f(0b01110, 28, 24), f(op2, 23);\n+  f(op22, 22); f(op21, 21), rf(Vm, 16), f(op14, 15, 14), f(op3, 13, 10),\n+  rf(Vn, 5), rf(Vd, 0);\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.cpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -1192,1 +1192,2 @@\n-  CodeStub* slow_path = new NewObjectArrayStub(klass_reg, len, reg, info, x->is_null_free());\n+  bool is_null_free = x->is_null_free() ||  x->klass()->has_flat_layout();\n+  CodeStub* slow_path = new NewObjectArrayStub(klass_reg, len, reg, info, is_null_free);\n@@ -1198,1 +1199,1 @@\n-  __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_OBJECT, klass_reg, slow_path, x->is_null_free());\n+  __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_OBJECT, klass_reg, slow_path, is_null_free);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRGenerator_aarch64.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -127,0 +127,2 @@\n+    decl(FPHP,          fphp,          9)     \\\n+    decl(ASIMDHP,       asimdhp,       10)    \\\n","filename":"src\/hotspot\/cpu\/aarch64\/vm_version_aarch64.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3161,0 +3161,16 @@\n+void Assembler::vmovw(XMMRegister dst, Register src) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionAttr attributes(AVX_128bit, false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_MAP5, &attributes);\n+  emit_int16(0x6E, (0xC0 | encode));\n+}\n+\n+void Assembler::vmovw(Register dst, XMMRegister src) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionAttr attributes(AVX_128bit, false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(src->encoding(), 0, dst->encoding(), VEX_SIMD_66, VEX_OPCODE_MAP5, &attributes);\n+  emit_int16(0x7E, (0xC0 | encode));\n+}\n+\n@@ -7429,0 +7445,96 @@\n+void Assembler::evaddph(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionAttr attributes(vector_len, false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_MAP5, &attributes);\n+  emit_int16(0x58, (0xC0 | encode));\n+}\n+\n+void Assembler::evsubph(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionAttr attributes(vector_len, false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_MAP5, &attributes);\n+  emit_int16(0x5C, (0xC0 | encode));\n+}\n+\n+void Assembler::evmulph(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionAttr attributes(vector_len, false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_MAP5, &attributes);\n+  emit_int16(0x59, (0xC0 | encode));\n+}\n+\n+void Assembler::evminph(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionAttr attributes(vector_len, false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_MAP5, &attributes);\n+  emit_int16(0x5D, (0xC0 | encode));\n+}\n+\n+void Assembler::evmaxph(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionAttr attributes(vector_len, false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_MAP5, &attributes);\n+  emit_int16(0x5F, (0xC0 | encode));\n+}\n+\n+void Assembler::evdivph(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionAttr attributes(vector_len, false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_MAP5, &attributes);\n+  emit_int16(0x5E, (0xC0 | encode));\n+}\n+\n+void Assembler::eaddsh(XMMRegister dst, XMMRegister nds, XMMRegister src) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionAttr attributes(AVX_128bit, false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_F3, VEX_OPCODE_MAP5, &attributes);\n+  emit_int16(0x58, (0xC0 | encode));\n+}\n+\n+void Assembler::esubsh(XMMRegister dst, XMMRegister nds, XMMRegister src) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionAttr attributes(AVX_128bit, false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_F3, VEX_OPCODE_MAP5, &attributes);\n+  emit_int16(0x5C, (0xC0 | encode));\n+}\n+\n+void Assembler::edivsh(XMMRegister dst, XMMRegister nds, XMMRegister src) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionAttr attributes(AVX_128bit, false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_F3, VEX_OPCODE_MAP5, &attributes);\n+  emit_int16(0x5E, (0xC0 | encode));\n+}\n+\n+void Assembler::emulsh(XMMRegister dst, XMMRegister nds, XMMRegister src) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionAttr attributes(AVX_128bit, false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_F3, VEX_OPCODE_MAP5, &attributes);\n+  emit_int16(0x59, (0xC0 | encode));\n+}\n+\n+void Assembler::emaxsh(XMMRegister dst, XMMRegister nds, XMMRegister src) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionAttr attributes(AVX_128bit, false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_F3, VEX_OPCODE_MAP5, &attributes);\n+  emit_int16(0x5F, (0xC0 | encode));\n+}\n+\n+void Assembler::eminsh(XMMRegister dst, XMMRegister nds, XMMRegister src) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionAttr attributes(AVX_128bit, false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_F3, VEX_OPCODE_MAP5, &attributes);\n+  emit_int16(0x5D, (0xC0 | encode));\n+}\n+\n@@ -11612,1 +11724,1 @@\n-  \/\/ of form {0F, 0F_38, 0F_3A}\n+  \/\/ of form {0F, 0F_38, 0F_3A, MAP5}\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":113,"deletions":1,"binary":false,"changes":114,"status":"modified"},{"patch":"@@ -551,0 +551,1 @@\n+    VEX_OPCODE_MAP5  = 0x5,\n@@ -1658,0 +1659,3 @@\n+  void vmovw(XMMRegister dst, Register src);\n+  void vmovw(Register dst, XMMRegister src);\n+\n@@ -2411,0 +2415,12 @@\n+  void eaddsh(XMMRegister dst, XMMRegister nds, XMMRegister src);\n+  void esubsh(XMMRegister dst, XMMRegister nds, XMMRegister src);\n+  void emulsh(XMMRegister dst, XMMRegister nds, XMMRegister src);\n+  void edivsh(XMMRegister dst, XMMRegister nds, XMMRegister src);\n+  void emaxsh(XMMRegister dst, XMMRegister nds, XMMRegister src);\n+  void eminsh(XMMRegister dst, XMMRegister nds, XMMRegister src);\n+  void evaddph(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n+  void evsubph(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n+  void evdivph(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n+  void evmulph(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n+  void evminph(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n+  void evmaxph(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":16,"deletions":0,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -1384,1 +1384,2 @@\n-  CodeStub* slow_path = new NewObjectArrayStub(klass_reg, len, reg, info, x->is_null_free());\n+  bool is_null_free = x->is_null_free() || x->klass()->has_flat_layout();\n+  CodeStub* slow_path = new NewObjectArrayStub(klass_reg, len, reg, info, is_null_free);\n@@ -1389,1 +1390,1 @@\n-  __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_OBJECT, klass_reg, slow_path, x->is_null_free());\n+  __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_OBJECT, klass_reg, slow_path, is_null_free);\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRGenerator_x86.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -6526,0 +6526,24 @@\n+\n+void C2_MacroAssembler::efp16sh(int opcode, XMMRegister dst, XMMRegister src1, XMMRegister src2) {\n+  switch(opcode) {\n+    case Op_AddHF: eaddsh(dst, src1, src2); break;\n+    case Op_SubHF: esubsh(dst, src1, src2); break;\n+    case Op_MulHF: emulsh(dst, src1, src2); break;\n+    case Op_DivHF: edivsh(dst, src1, src2); break;\n+    case Op_MaxHF: eminsh(dst, src1, src2); break;\n+    case Op_MinHF: emaxsh(dst, src1, src2); break;\n+    default: assert(false, \"%s\", NodeClassNames[opcode]); break;\n+  }\n+}\n+\n+void C2_MacroAssembler::evfp16ph(int opcode, XMMRegister dst, XMMRegister src1, XMMRegister src2, int vlen_enc) {\n+  switch(opcode) {\n+    case Op_AddVHF: evaddph(dst, src1, src2, vlen_enc); break;\n+    case Op_SubVHF: evsubph(dst, src1, src2, vlen_enc); break;\n+    case Op_MulVHF: evmulph(dst, src1, src2, vlen_enc); break;\n+    case Op_DivVHF: evdivph(dst, src1, src2, vlen_enc); break;\n+    case Op_MaxVHF: evminph(dst, src1, src2, vlen_enc); break;\n+    case Op_MinVHF: evmaxph(dst, src1, src2, vlen_enc); break;\n+    default: assert(false, \"%s\", NodeClassNames[opcode]); break;\n+  }\n+}\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":24,"deletions":0,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -504,0 +504,4 @@\n+  void efp16sh(int opcode, XMMRegister dst, XMMRegister src1, XMMRegister src2);\n+\n+  void evfp16ph(int opcode, XMMRegister dst, XMMRegister src1, XMMRegister src2, int vlen_enc);\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -966,0 +966,1 @@\n+    _features &= ~CPU_AVX512_FP16;\n@@ -1002,0 +1003,1 @@\n+      _features &= ~CPU_AVX512_FP16;\n@@ -3048,0 +3050,3 @@\n+\n+    if (_cpuid_info.sef_cpuid7_edx.bits.avx512_fp16 != 0)\n+      result |= CPU_AVX512_FP16;\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -278,1 +278,3 @@\n-                           : 11;\n+                           : 2,\n+              avx512_fp16  : 1,\n+                           : 8;\n@@ -403,1 +405,2 @@\n-    decl(AVX_IFMA,          \"avx_ifma\",          59) \/* 256-bit VEX-coded variant of AVX512-IFMA*\/\n+    decl(AVX_IFMA,          \"avx_ifma\",          59) \/* 256-bit VEX-coded variant of AVX512-IFMA*\/ \\\n+    decl(AVX512_FP16,       \"avx512_fp16\",       60) \/* AVX512 FP16 ISA support*\/\n@@ -720,0 +723,1 @@\n+  static bool supports_avx512_fp16()  { return (_features & CPU_AVX512_FP16) != 0; }\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.hpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1466,0 +1466,12 @@\n+    case Op_AddHF:\n+    case Op_SubHF:\n+    case Op_MulHF:\n+    case Op_DivHF:\n+    case Op_MaxHF:\n+    case Op_MinHF:\n+    case Op_ReinterpretS2HF:\n+    case Op_ReinterpretHF2S:\n+      if (!VM_Version::supports_avx512_fp16()) {\n+        return false;\n+      }\n+      break;\n@@ -1730,0 +1742,10 @@\n+    case Op_AddVHF:\n+    case Op_SubVHF:\n+    case Op_MulVHF:\n+    case Op_DivVHF:\n+    case Op_MaxVHF:\n+    case Op_MinVHF:\n+      if (!VM_Version::supports_avx512_fp16()) {\n+        return false;\n+      }\n+      break;\n@@ -10132,0 +10154,64 @@\n+\n+instruct reinterpretS2H (regF dst, rRegI src)\n+%{\n+  match(Set dst (ReinterpretS2HF src));\n+  format %{ \"vmovw $dst, $src\" %}\n+  ins_encode %{\n+    __ vmovw($dst$$XMMRegister, $src$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct convF2HFAndS2HF (regF dst, regF src)\n+%{\n+  match(Set dst (ReinterpretS2HF (ConvF2HF src)));\n+  format %{ \"convF2HFAndS2HF $dst, $src\" %}\n+  ins_encode %{\n+    __ vcvtps2ph($dst$$XMMRegister, $src$$XMMRegister, 0x04, Assembler::AVX_128bit);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reinterpretH2S (rRegI dst, regF src)\n+%{\n+  match(Set dst (ReinterpretHF2S src));\n+  format %{ \"vmovw $dst, $src\" %}\n+  ins_encode %{\n+    __ vmovw($dst$$Register, $src$$XMMRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct fp16_scalar_ops (regF dst, regF src1, regF src2)\n+%{\n+  match(Set dst (AddHF src1 src2));\n+  match(Set dst (SubHF src1 src2));\n+  match(Set dst (MulHF src1 src2));\n+  match(Set dst (DivHF src1 src2));\n+  match(Set dst (MinHF src1 src2));\n+  match(Set dst (MaxHF src1 src2));\n+  format %{ \"efp16sh $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n+    __ efp16sh(opcode, $dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct fp16_vector_ops (vec dst, vec src1, vec src2)\n+%{\n+  match(Set dst (AddVHF src1 src2));\n+  match(Set dst (SubVHF src1 src2));\n+  match(Set dst (MulVHF src1 src2));\n+  match(Set dst (DivVHF src1 src2));\n+  match(Set dst (MaxVHF src1 src2));\n+  match(Set dst (MinVHF src1 src2));\n+  format %{ \"evfp16ph $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    int opcode = this->ideal_Opcode();\n+    __ evfp16ph(opcode, $dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vlen_enc);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":86,"deletions":0,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -3954,1 +3954,1 @@\n-    \"AddI\",\"AddL\",\"AddF\",\"AddD\",\n+    \"AddI\",\"AddL\",\"AddHF\",\"AddF\",\"AddD\",\n@@ -3956,2 +3956,2 @@\n-    \"MaxI\",\"MinI\",\"MaxF\",\"MinF\",\"MaxD\",\"MinD\",\n-    \"MulI\",\"MulL\",\"MulF\",\"MulD\",\n+    \"MaxI\",\"MinI\",\"MaxHF\",\"MinHF\",\"MaxF\",\"MinF\",\"MaxD\",\"MinD\",\n+    \"MulI\",\"MulL\",\"MulHF\",\"MulF\",\"MulD\",\n@@ -3963,2 +3963,2 @@\n-    \"AddVB\", \"AddVS\", \"AddVI\", \"AddVL\", \"AddVF\", \"AddVD\",\n-    \"MulVB\", \"MulVS\", \"MulVI\", \"MulVL\", \"MulVF\", \"MulVD\",\n+    \"AddVB\", \"AddVS\", \"AddVI\", \"AddVL\", \"AddVHF\", \"AddVF\", \"AddVD\",\n+    \"MulVB\", \"MulVS\", \"MulVI\", \"MulVL\", \"MulVHF\", \"MulVF\", \"MulVD\",\n@@ -3966,1 +3966,1 @@\n-    \"MaxV\", \"MinV\"\n+    \"MaxVHF\", \"MinVHF\", \"MaxV\", \"MinV\"\n@@ -4193,0 +4193,1 @@\n+        strcmp(opType,\"DivHF\")==0 ||\n@@ -4332,4 +4333,4 @@\n-    \"AddVB\",\"AddVS\",\"AddVI\",\"AddVL\",\"AddVF\",\"AddVD\",\n-    \"SubVB\",\"SubVS\",\"SubVI\",\"SubVL\",\"SubVF\",\"SubVD\",\n-    \"MulVB\",\"MulVS\",\"MulVI\",\"MulVL\",\"MulVF\",\"MulVD\",\n-    \"DivVF\",\"DivVD\",\n+    \"AddVB\",\"AddVHF\", \"AddVS\",\"AddVI\",\"AddVL\",\"AddVF\",\"AddVD\",\n+    \"SubVB\",\"SubVS\",\"SubVI\",\"SubVL\", \"SubVHF\", \"SubVF\",\"SubVD\",\n+    \"MulVB\",\"MulVS\",\"MulVI\",\"MulVL\", \"MulVHF\", \"MulVF\",\"MulVD\",\n+    \"DivVHF\",\"DivVF\",\"DivVD\",\n@@ -4340,1 +4341,1 @@\n-    \"MaxV\", \"MinV\",\n+    \"MaxV\", \"MinV\", \"MinVHF\", \"MaxVHF\",\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":12,"deletions":11,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -419,0 +419,1 @@\n+  static void restore_loader_data() NOT_CDS_JAVA_HEAP_RETURN;\n","filename":"src\/hotspot\/share\/cds\/heapShared.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -959,0 +959,1 @@\n+    _jdk_internal_NullRestrictedArray,\n@@ -2076,0 +2077,4 @@\n+    case VM_SYMBOL_ENUM_NAME(jdk_internal_vm_annotation_NullRestrictedArray_signature): {\n+      if (_location != _in_class)   break; \/\/ only allow for classes\n+      return _jdk_internal_NullRestrictedArray;\n+    }\n@@ -4681,0 +4686,7 @@\n+bool ClassFileParser::is_jdk_internal_class_sig(const char* sig) const {\n+  if (strstr(sig, vmSymbols::java_lang_Float16_signature()->as_C_string())) {\n+    return true;\n+  }\n+  return false;\n+}\n+\n@@ -5626,0 +5638,3 @@\n+  if (_has_null_restricted_array) {\n+    ik->set_has_null_restricted_array();\n+  }\n@@ -5902,0 +5917,1 @@\n+  _has_null_restricted_array(false),\n@@ -6390,0 +6406,7 @@\n+    if (_parsed_annotations->has_annotation(ClassAnnotationCollector::_jdk_internal_NullRestrictedArray)) {\n+      _has_null_restricted_array = true;\n+    }\n+    \/\/ Implicit constructibility and null restriction are sufficient to guarantee atomic updates to value based boxed primitives.\n+    if (_parsed_annotations->has_annotation(ClassAnnotationCollector::_jdk_internal_ValueBased) && _has_null_restricted_array && _is_implicitly_constructible) {\n+      _must_be_atomic = false;\n+    }\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":23,"deletions":0,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -216,0 +216,1 @@\n+  bool _has_null_restricted_array;\n@@ -225,0 +226,2 @@\n+  bool is_jdk_internal_class_sig(const char* sig) const;\n+\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -84,0 +84,2 @@\n+  template(java_lang_Float16,                         \"java\/lang\/Float16\")                        \\\n+  template(java_lang_Float16_signature,               \"Ljava\/lang\/Float16;\")                      \\\n@@ -276,0 +278,1 @@\n+  template(jdk_internal_vm_annotation_NullRestrictedArray_signature,         \"Ljdk\/internal\/vm\/annotation\/NullRestrictedArray;\") \\\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -91,2 +91,3 @@\n-    \/\/ has been aborted for any reason.\n-    bool yield_if_necessary() {\n+    \/\/ has been aborted for any reason. Yielded is set if there has been an actual\n+    \/\/ yield for a pause.\n+    bool yield_if_necessary(bool& yielded) {\n@@ -95,1 +96,1 @@\n-        _cm->do_yield_check();\n+        yielded = _cm->do_yield_check();\n@@ -125,1 +126,2 @@\n-        bool mark_aborted = yield_if_necessary();\n+        bool yielded;\n+        bool mark_aborted = yield_if_necessary(yielded);\n@@ -193,1 +195,2 @@\n-        bool mark_aborted = yield_if_necessary();\n+        bool yielded;\n+        bool mark_aborted = yield_if_necessary(yielded);\n@@ -213,1 +216,2 @@\n-        bool mark_aborted = yield_if_necessary();\n+        bool yielded = true;\n+        bool mark_aborted = yield_if_necessary(yielded);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentRebuildAndScrub.cpp","additions":10,"deletions":6,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -381,0 +381,1 @@\n+  arrayOop obj = nullptr;\n@@ -382,1 +383,9 @@\n-  arrayOop obj = oopFactory::new_objArray(klass, size, CHECK);\n+  bool has_flat_layout = klass->is_inline_klass() &&\n+    InstanceKlass::cast(klass)->is_implicitly_constructible() &&\n+    InstanceKlass::cast(klass)->has_null_restricted_array() &&\n+    !InstanceKlass::cast(klass)->must_be_atomic();\n+  if (has_flat_layout) {\n+    obj = oopFactory::new_valueArray(klass, size, CHECK);\n+  } else {\n+    obj = oopFactory::new_objArray(klass, size, CHECK);\n+  }\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -552,0 +552,3 @@\n+  if (vmSymbols::java_lang_Float16() == name()) {\n+    Arguments::set_enable_preview();\n+  }\n","filename":"src\/hotspot\/share\/oops\/inlineKlass.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -383,0 +383,3 @@\n+  bool has_null_restricted_array() const   { return _misc_flags.has_null_restricted_array(); }\n+  void set_has_null_restricted_array()     { _misc_flags.set_has_null_restricted_array(true); }\n+\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -141,0 +141,8 @@\n+\/\/------------------------------AddHFNode---------------------------------------\n+\/\/ Add 2 half-precision floats\n+class AddHFNode : public AddFNode {\n+public:\n+  AddHFNode( Node *in1, Node *in2 ) : AddFNode(in1,in2) {}\n+  virtual int Opcode() const;\n+};\n+\n@@ -401,0 +409,20 @@\n+\/\/------------------------------MaxHFNode--------------------------------------\n+\/\/ Maximum of 2 half floats.\n+class MaxHFNode : public MaxFNode {\n+public:\n+  MaxHFNode(Node* in1, Node* in2) : MaxFNode(in1, in2) {}\n+  virtual int Opcode() const;\n+  int max_opcode() const { return Op_MaxHF; }\n+  int min_opcode() const { return Op_MinHF; }\n+};\n+\n+\/\/------------------------------MinHFNode---------------------------------------\n+\/\/ Minimum of 2 half floats.\n+class MinHFNode : public MinFNode {\n+public:\n+  MinHFNode(Node* in1, Node* in2) : MinFNode(in1, in2) {}\n+  virtual int Opcode() const;\n+  int max_opcode() const { return Op_MaxHF; }\n+  int min_opcode() const { return Op_MinHF; }\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/addnode.hpp","additions":28,"deletions":0,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -3682,0 +3682,6 @@\n+  case Op_AddHF:\n+  case Op_SubHF:\n+  case Op_MulHF:\n+  case Op_DivHF:\n+  case Op_MaxHF:\n+  case Op_MinHF:\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -62,3 +62,0 @@\n-  \/\/ Get the klass defining the field layout of the inline type\n-  ciInlineKlass* inline_klass() const { return type()->inline_klass(); }\n-\n@@ -89,0 +86,3 @@\n+  \/\/ Get the klass defining the field layout of the inline type\n+  ciInlineKlass* inline_klass() const { return type()->inline_klass(); }\n+\n","filename":"src\/hotspot\/share\/opto\/inlinetypenode.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -548,0 +548,6 @@\n+  case vmIntrinsics::_add_float16:\n+  case vmIntrinsics::_subtract_float16:\n+  case vmIntrinsics::_multiply_float16:\n+  case vmIntrinsics::_divide_float16:\n+  case vmIntrinsics::_max_float16:\n+  case vmIntrinsics::_min_float16:              return inline_fp16_operations(intrinsic_id());\n@@ -5058,0 +5064,35 @@\n+bool LibraryCallKit::inline_fp16_operations(vmIntrinsics::ID id) {\n+  if (!Matcher::match_rule_supported(Op_ReinterpretS2HF) ||\n+      !Matcher::match_rule_supported(Op_ReinterpretHF2S)) {\n+    return false;\n+  }\n+\n+  Node* result = nullptr;\n+  Node* val1 = argument(0);  \/\/ receiver\n+  Node* val2 = argument(1);  \/\/ argument\n+  if (!val1->is_InlineType() || !val2->is_InlineType()) {\n+    return false;\n+  }\n+\n+  Node* fld1 = _gvn.transform(new ReinterpretS2HFNode(val1->as_InlineType()->field_value(0)));\n+  Node* fld2 = _gvn.transform(new ReinterpretS2HFNode(val2->as_InlineType()->field_value(0)));\n+\n+  switch (id) {\n+  case vmIntrinsics::_add_float16:       result = _gvn.transform(new AddHFNode(fld1, fld2));    break;\n+  case vmIntrinsics::_subtract_float16:  result = _gvn.transform(new SubHFNode(fld1, fld2));    break;\n+  case vmIntrinsics::_multiply_float16:  result = _gvn.transform(new MulHFNode(fld1, fld2));    break;\n+  case vmIntrinsics::_divide_float16:    result = _gvn.transform(new DivHFNode(0, fld1, fld2)); break;\n+  case vmIntrinsics::_max_float16:       result = _gvn.transform(new MaxHFNode(fld1, fld2));    break;\n+  case vmIntrinsics::_min_float16:       result = _gvn.transform(new MinHFNode(fld1, fld2));    break;\n+\n+  default:\n+    fatal_unexpected_iid(id);\n+    break;\n+  }\n+  InlineTypeNode* box = InlineTypeNode::make_uninitialized(_gvn, val1->as_InlineType()->inline_klass(), true);\n+  Node* short_result  = _gvn.transform(new ReinterpretHF2SNode(result));\n+  box->set_field_value(0, short_result);\n+  set_result(_gvn.transform(box));\n+  return true;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":41,"deletions":0,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -6286,0 +6286,1 @@\n+    case Op_DivHF:\n","filename":"src\/hotspot\/share\/opto\/loopnode.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2705,0 +2705,7 @@\n+      } else if (opc == Op_ReinterpretS2HF || opc == Op_ReinterpretHF2S) {\n+        assert(n->req() == 2, \"only one input expected\");\n+        BasicType bt = velt_basic_type(n);\n+        const TypeVect* vt = TypeVect::make(bt, vlen);\n+        Node* in = vector_opd(p, 1);\n+        vn = VectorReinterpretNode::make(in, vt, vt);\n+        vlen_in_bytes = vn->as_Vector()->length_in_bytes();\n@@ -3399,0 +3406,1 @@\n+  int opc = n->Opcode();\n@@ -3407,1 +3415,1 @@\n-    if (n->Opcode() == Op_LoadUB) {\n+    if (opc == Op_LoadUB) {\n@@ -3417,0 +3425,9 @@\n+\n+  \/\/ First check if the node is a float16 node returning a \"Short\" type.\n+  \/\/ If it is, then it needs to be checked before the next condition.\n+  \/\/ Else it might return TypeInt::INT for float16 nodes instead of TypeInt::SHORT\n+  \/\/ which could cause assertion errors in VectorCastNode::opcode().\n+  if (opc == Op_ReinterpretHF2S || VectorNode::is_float16_node(opc)) {\n+    return TypeInt::SHORT;\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/superword.cpp","additions":18,"deletions":1,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -1415,0 +1415,1 @@\n+  declare_c2_type(AddHFNode, AddNode)                                     \\\n@@ -1428,0 +1429,2 @@\n+  declare_c2_type(MaxHFNode, MaxFNode)                                    \\\n+  declare_c2_type(MinHFNode, MinFNode)                                    \\\n@@ -1433,0 +1436,2 @@\n+  declare_c2_type(ReinterpretS2HFNode, Node)                              \\\n+  declare_c2_type(ReinterpretHF2SNode, Node)                              \\\n@@ -1529,0 +1534,1 @@\n+  declare_c2_type(DivHFNode, DivFNode)                                    \\\n@@ -1625,0 +1631,1 @@\n+  declare_c2_type(MulHFNode, MulFNode)                                    \\\n@@ -1646,0 +1653,1 @@\n+  declare_c2_type(SubHFNode, SubFNode)                                    \\\n@@ -1691,0 +1699,1 @@\n+  declare_c2_type(AddVHFNode, VectorNode)                                 \\\n@@ -1698,0 +1707,1 @@\n+  declare_c2_type(SubVHFNode, VectorNode)                                 \\\n@@ -1706,0 +1716,1 @@\n+  declare_c2_type(MulVHFNode, VectorNode)                                 \\\n@@ -1722,0 +1733,1 @@\n+  declare_c2_type(DivVHFNode, VectorNode)                                 \\\n@@ -1748,0 +1760,2 @@\n+  declare_c2_type(MaxVHFNode, VectorNode)                                 \\\n+  declare_c2_type(MinVHFNode, VectorNode)                                 \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -0,0 +1,1198 @@\n+\/*\n+ * Copyright (c) 2023, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package java.lang;\n+\n+import java.lang.invoke.MethodHandles;\n+import java.lang.constant.Constable;\n+import java.lang.constant.ConstantDesc;\n+import java.util.Optional;\n+\n+import jdk.internal.math.FloatConsts;\n+import jdk.internal.math.FloatingDecimal;\n+import jdk.internal.math.FloatToDecimal;\n+import jdk.internal.vm.annotation.IntrinsicCandidate;\n+\n+import static java.lang.Float.float16ToFloat;\n+import static java.lang.Float.floatToFloat16;\n+\n+\/**\n+ * The {@code Float16} is a primitive value class holding 16-bit data\n+ * in IEEE 754 binary16 format.\n+ *\n+ * <p>Binary16 Format:<br>\n+ *   S EEEEE  MMMMMMMMMM<br>\n+ *   Sign        - 1 bit<br>\n+ *   Exponent    - 5 bits<br>\n+ *   Significand - 10 bits (does not include the <i>implicit bit<\/i> inferred from the exponent, see {@link #PRECISION})<br>\n+ *\n+ * <p>This is a <a href=\"https:\/\/openjdk.org\/jeps\/401\">primitive value class<\/a> and its objects are\n+ * identity-less non-nullable value objects.\n+ *\n+ * <p>Unless otherwise specified, the methods in this class use a\n+ * <em>rounding policy<\/em> (JLS {@jls 15.4}) of {@linkplain\n+ * java.math.RoundingMode#HALF_EVEN round to nearest}.\n+ *\n+ * @apiNote\n+ * The methods in this class generally have analogous methods in\n+ * either {@link Float}\/{@link Double} or {@link Math}\/{@link\n+ * StrictMath}. Unless otherwise specified, the handling of special\n+ * floating-point values such as {@linkplain #isNaN(Float16) NaN}\n+ * values, {@linkplain #isInfinite(Float16) infinities}, and signed\n+ * zeros of methods in this class is wholly analogous to the handling\n+ * of equivalent cases by methods in {@code Float}, {@code Double},\n+ * {@code Math}, etc.\n+ *\n+ * @author Jatin Bhateja\n+ * @since 20.00\n+ *\/\n+\n+\/\/ Currently Float16 is a value based class but in future will be aligned with\n+\/\/ Enhanced Primitive Boxes described by JEP-402 (https:\/\/openjdk.org\/jeps\/402)\n+@jdk.internal.MigratedValueClass\n+@jdk.internal.ValueBased\n+@SuppressWarnings(\"serial\")\n+public final class Float16\n+    extends Number\n+    implements Comparable<Float16> {\n+    private final short value;\n+    private static final long serialVersionUID = 16; \/\/ Not needed for a value class?\n+\n+    \/\/ Functionality for future consideration:\n+    \/\/ float16ToShortBits that normalizes NaNs, c.f. floatToIntBits vs floatToRawIntBits\n+    \/\/ copysign\n+    \/\/ scalb\n+    \/\/ nextUp \/ nextDown\n+    \/\/ IEEEremainder \/ remainder operator remainder\n+    \/\/ signum\n+    \/\/ valueOf(BigDecimal) -- main implementation could be package private in BigDecimal\n+\n+   \/**\n+    * Returns a {@code Float16} instance wrapping IEEE 754 binary16\n+    * encoded {@code short} value.\n+    *\n+    * @param  bits a short value.\n+    *\/\n+    private Float16 (short bits ) {\n+        this.value = bits;\n+    }\n+\n+    \/\/ Do *not* define any public constructors\n+\n+    \/**\n+     * A constant holding the positive infinity of type {@code\n+     * Float16}.\n+     *\n+     * @see Float#POSITIVE_INFINITY\n+     * @see Double#POSITIVE_INFINITY\n+     *\/\n+    public static final Float16 POSITIVE_INFINITY = valueOf(Float.POSITIVE_INFINITY);\n+\n+    \/**\n+     * A constant holding the negative infinity of type {@code\n+     * Float16}.\n+     *\n+     * @see Float#NEGATIVE_INFINITY\n+     * @see Double#NEGATIVE_INFINITY\n+     *\/\n+    public static final Float16 NEGATIVE_INFINITY = valueOf(Float.NEGATIVE_INFINITY);\n+\n+    \/**\n+     * A constant holding a Not-a-Number (NaN) value of type {@code\n+     * Float16}.\n+     *\n+     * @see Float#NaN\n+     * @see Double#NaN\n+     *\/\n+    public static final Float16 NaN = valueOf(Float.NaN);\n+\n+    \/**\n+     * A constant holding the largest positive finite value of type\n+     * {@code Float16},\n+     * (2-2<sup>-10<\/sup>)&middot;2<sup>15<\/sup>, numerically equal to 65504.0.\n+     *\n+     * @see Float#MAX_VALUE\n+     * @see Double#MAX_VALUE\n+     *\/\n+    public static final Float16 MAX_VALUE = valueOf(0x1.ffcp15f);\n+\n+    \/**\n+     * A constant holding the smallest positive normal value of type\n+     * {@code Float16}, 2<sup>-14<\/sup>.\n+     *\n+     * @see Float#MIN_NORMAL\n+     * @see Double#MIN_NORMAL\n+     *\/\n+    public static final Float16 MIN_NORMAL = valueOf(0x1.0p-14f);\n+\n+    \/**\n+     * A constant holding the smallest positive nonzero value of type\n+     * {@code Float16}, 2<sup>-24<\/sup>.\n+     *\n+     * @see Float#MIN_VALUE\n+     * @see Double#MIN_VALUE\n+     *\/\n+    public static final Float16 MIN_VALUE = valueOf(0x1.0p-24f);\n+\n+    \/**\n+     * The number of bits used to represent a {@code Float16} value,\n+     * {@value}.\n+     *\n+     * @see Float#SIZE\n+     * @see Double#SIZE\n+     *\/\n+    public static final int SIZE = 16;\n+\n+    \/**\n+     * The number of bits in the significand of a {@code Float16}\n+     * value, {@value}.  This corresponds to parameter N in section\n+     * {@jls 4.2.3} of <cite>The Java Language Specification<\/cite>.\n+     *\n+     * @see Float#PRECISION\n+     * @see Double#PRECISION\n+     *\/\n+    public static final int PRECISION = 11;\n+\n+    \/**\n+     * Maximum exponent a finite {@code Float16} variable may have,\n+     * {@value}. It is equal to the value returned by {@code\n+     * Float16.getExponent(Float16.MAX_VALUE)}.\n+     *\n+     * @see Float#MAX_EXPONENT\n+     * @see Double#MAX_EXPONENT\n+     *\/\n+    public static final int MAX_EXPONENT = (1 << (SIZE - PRECISION - 1)) - 1; \/\/ 15\n+\n+    \/**\n+     * Minimum exponent a normalized {@code Float16} variable may\n+     * have, {@value}.  It is equal to the value returned by {@code\n+     * Float16.getExponent(Float16.MIN_NORMAL)}.\n+     *\n+     * @see Float#MIN_EXPONENT\n+     * @see Double#MIN_EXPONENT\n+     *\/\n+    public static final int MIN_EXPONENT = 1 - MAX_EXPONENT; \/\/ -14\n+\n+    \/**\n+     * The number of bytes used to represent a {@code Float16} value,\n+     * {@value}.\n+     *\n+     * @see Float#BYTES\n+     * @see Double#BYTES\n+     *\/\n+    public static final int BYTES = SIZE \/ Byte.SIZE;\n+\n+    \/**\n+     * Returns a string representation of the {@code Float16}\n+     * argument.\n+     *\n+     * @implSpec\n+     * The current implementation acts as this {@code Float16} were\n+     * {@linkplain #floatValue() converted} to {@code float} and then\n+     * the string for that {@code float} returned. This behavior is\n+     * expected to change to accommodate the precision of {@code\n+     * Float16}.\n+     *\n+     * @param   f16   the {@code Float16} to be converted.\n+     * @return a string representation of the argument.\n+     * @see java.lang.Float#toString(float)\n+     *\/\n+    public static String toString(Float16 f16) {\n+        \/\/ FIXME -- update for Float16 precision\n+        return FloatToDecimal.toString(f16.floatValue());\n+    }\n+\n+    \/**\n+     * Returns a hexadecimal string representation of the {@code\n+     * Float16} argument.\n+     *\n+     * The behavior of this class is analogous to {@link\n+     * Float#toHexString(float)} except that an exponent value of\n+     * {@code \"p14\"} is used for subnormal {@code Float16} values.\n+     *\n+     * @param   f16   the {@code Float16} to be converted.\n+     * @return a hex string representation of the argument.\n+     *\n+     * @see Float#toHexString(float)\n+     * @see Double#toHexString(double)\n+     *\/\n+    public static String toHexString(Float16 f16) {\n+        float f = f16.floatValue();\n+        if (Math.abs(f) < float16ToFloat(MIN_NORMAL.value)\n+            &&  f != 0.0f ) {\/\/ Float16 subnormal\n+            \/\/ Adjust exponent to create subnormal double, then\n+            \/\/ replace subnormal double exponent with subnormal Float16\n+            \/\/ exponent\n+            String s = Double.toHexString(Math.scalb((double)f,\n+                                                     \/* -1022+14 *\/\n+                                                     Double.MIN_EXPONENT-\n+                                                     MIN_EXPONENT));\n+            return s.replaceFirst(\"p-1022$\", \"p-14\");\n+        } else {\/\/ double string will be the same as Float16 string\n+            return Double.toHexString(f);\n+        }\n+    }\n+\n+    \/\/ -----------------------\n+\n+   \/**\n+    * {@return the value of an {@code int} converted to {@code\n+    * Float16}}\n+    *\n+    * @param  value an {@code int} value.\n+    *\n+    * @apiNote\n+    * This method corresponds to the convertFromInt operation defined\n+    * in IEEE 754.\n+    *\/\n+    public static Float16 valueOf(int value) {\n+        \/\/ int -> double conversion is exact\n+        return valueOf((double)value);\n+    }\n+\n+   \/**\n+    * {@return the value of a {@code long} converted to {@code Float16}}\n+    *\n+    * @apiNote\n+    * This method corresponds to the convertFromInt operation defined\n+    * in IEEE 754.\n+    *\n+    * @param  value a {@code long} value.\n+    *\/\n+    public static Float16 valueOf(long value) {\n+        if (value < -65_504L) {\n+            return NEGATIVE_INFINITY;\n+        } else {\n+            if (value > 65_504L) {\n+                return NEGATIVE_INFINITY;\n+            }\n+            \/\/ Remaining range of long, the integers in approx. +\/-\n+            \/\/ 2^16, all fit in a float so the correct conversion can\n+            \/\/ be done via an intermediate float conversion.\n+            return valueOf((float)value);\n+        }\n+    }\n+\n+   \/**\n+    * {@return a {@code Float16} value rounded from the {@code float}\n+    * argument using the round to nearest rounding policy}\n+    *\n+    * @apiNote\n+    * This method corresponds to the convertFormat operation defined\n+    * in IEEE 754.\n+    *\n+    * @param  f a {@code float}\n+    *\/\n+    public static Float16 valueOf(float f) {\n+        return new Float16(Float.floatToFloat16(f));\n+    }\n+\n+   \/**\n+    * {@return a {@code Float16} value rounded from the {@code double}\n+    * argument using the round to nearest rounding policy}\n+    *\n+    * @apiNote\n+    * This method corresponds to the convertFormat operation defined\n+    * in IEEE 754.\n+    *\n+    * @param  d a {@code double}\n+    *\/\n+    public static Float16 valueOf(double d) {\n+        long doppel = Double.doubleToRawLongBits(d);\n+\n+        short sign_bit = (short)((doppel & 0x8000_0000_0000_0000L) >> 48);\n+\n+        if (Double.isNaN(d)) {\n+            \/\/ Have existing float code handle any attempts to\n+            \/\/ preserve NaN bits.\n+            return valueOf((float)d);\n+        }\n+\n+        double abs_d = Math.abs(d);\n+\n+        \/\/ The overflow threshold is binary16 MAX_VALUE + 1\/2 ulp\n+        if (abs_d >= (0x1.ffcp15 + 0x0.002p15) ) {\n+             \/\/ correctly signed infinity\n+            return new Float16((short)(sign_bit | 0x7c00));\n+        }\n+\n+        \/\/ Smallest magnitude nonzero representable binary16 value\n+        \/\/ is equal to 0x1.0p-24; half-way and smaller rounds to zero.\n+        if (abs_d <= 0x1.0p-24d * 0.5d) { \/\/ Covers double zeros and subnormals.\n+            return new Float16(sign_bit); \/\/ Positive or negative zero\n+        }\n+\n+        \/\/ Dealing with finite values in exponent range of binary16\n+        \/\/ (when rounding is done, could still round up)\n+        int exp = Math.getExponent(d);\n+        assert -25 <= exp && exp <= 15;\n+\n+        \/\/ For binary16 subnormals, beside forcing exp to -15, retain\n+        \/\/ the difference expdelta = E_min - exp.  This is the excess\n+        \/\/ shift value, in addition to 42, to be used in the\n+        \/\/ computations below.  Further the (hidden) msb with value 1\n+        \/\/ in d must be involved as well.\n+        int expdelta = 0;\n+        long msb = 0x0000_0000_0000_0000L;\n+        if (exp < -14) {\n+            expdelta = -14 - exp; \/\/ FIXME?\n+            exp = -15;\n+            msb = 0x0010_0000_0000_0000L; \/\/ should be 0x0020_... ?\n+        }\n+        long f_signif_bits = doppel & 0x000f_ffff_ffff_ffffL | msb;\n+\n+        \/\/ Significand bits as if using rounding to zero (truncation).\n+        short signif_bits = (short)(f_signif_bits >> (42 + expdelta));\n+\n+        \/\/ For round to nearest even, determining whether or not to\n+        \/\/ round up (in magnitude) is a function of the least\n+        \/\/ significant bit (LSB), the next bit position (the round\n+        \/\/ position), and the sticky bit (whether there are any\n+        \/\/ nonzero bits in the exact result to the right of the round\n+        \/\/ digit). An increment occurs in three cases:\n+        \/\/\n+        \/\/ LSB  Round Sticky\n+        \/\/ 0    1     1\n+        \/\/ 1    1     0\n+        \/\/ 1    1     1\n+        \/\/ See \"Computer Arithmetic Algorithms,\" Koren, Table 4.9\n+\n+        long lsb    = f_signif_bits & (1L << 42 + expdelta);\n+        long round  = f_signif_bits & (1L << 41 + expdelta);\n+        long sticky = f_signif_bits & ((1L << 41 + expdelta) - 1);\n+\n+        if (round != 0 && ((lsb | sticky) != 0 )) {\n+            signif_bits++;\n+        }\n+\n+        \/\/ No bits set in significand beyond the *first* exponent bit,\n+        \/\/ not just the significand; quantity is added to the exponent\n+        \/\/ to implement a carry out from rounding the significand.\n+        assert (0xf800 & signif_bits) == 0x0;\n+\n+        return new Float16((short)(sign_bit | ( ((exp + 15) << 10) + signif_bits ) ));\n+    }\n+\n+    \/**\n+     * Returns a {@code Float16} holding the floating-point value\n+     * represented by the argument string.\n+     *\n+     * @implSpec\n+     * The current implementation acts as if the string were\n+     * {@linkplain Double#parseDouble(String) parsed} as a {@code\n+     * double} and then {@linkplain #valueOf(double) converted} to\n+     * {@code Float16}. This behavior is expected to change to\n+     * accommodate the precision of {@code Float16}.\n+     *\n+     * @param  s the string to be parsed.\n+     * @return the {@code Float16} value represented by the string\n+     *         argument.\n+     * @throws NullPointerException  if the string is null\n+     * @throws NumberFormatException if the string does not contain a\n+     *               parsable {@code Float16}.\n+     * @see    java.lang.Float#valueOf(String)\n+     *\/\n+    public static Float16 valueOf(String s) throws NumberFormatException {\n+        \/\/ TOOD: adjust precision of parsing if needed\n+        return valueOf(Double.parseDouble(s));\n+    }\n+\n+    \/\/    \/**\n+    \/\/     * ...\n+    \/\/     * @see BigDecimal#floatValue()\n+    \/\/     * @see BigDecimal#doubleValue()\n+    \/\/     *\/\n+    \/\/    public static Float16 valueOf(BigDecimal bd)\n+\n+\n+    \/**\n+     * Returns {@code true} if the specified number is a\n+     * Not-a-Number (NaN) value, {@code false} otherwise.\n+     *\n+     * @apiNote\n+     * This method corresponds to the isNaN operation defined in IEEE\n+     * 754.\n+     *\n+     * @param   f16   the value to be tested.\n+     * @return  {@code true} if the argument is NaN;\n+     *          {@code false} otherwise.\n+     *\n+     * @see Float#isNaN(float)\n+     * @see Double#isNaN(double)\n+     *\/\n+    public static boolean isNaN(Float16 f16) {\n+        return Float.isNaN(f16.floatValue());\n+    }\n+\n+    \/**\n+     * Returns {@code true} if the specified number is infinitely\n+     * large in magnitude, {@code false} otherwise.\n+     *\n+     * @apiNote\n+     * This method corresponds to the isInfinite operation defined in\n+     * IEEE 754.\n+     *\n+     * @param   f16   the value to be tested.\n+     * @return  {@code true} if the argument is positive infinity or\n+     *          negative infinity; {@code false} otherwise.\n+     *\n+     * @see Float#isInfinite(float)\n+     * @see Double#isInfinite(double)\n+     *\/\n+    public static boolean isInfinite(Float16 f16) {\n+        return Float.isInfinite(f16.floatValue());\n+    }\n+\n+    \/**\n+     * Returns {@code true} if the argument is a finite floating-point\n+     * value; returns {@code false} otherwise (for NaN and infinity\n+     * arguments).\n+     *\n+     * @apiNote\n+     * This method corresponds to the isFinite operation defined in\n+     * IEEE 754.\n+     *\n+     * @param f16 the {@code Float16} value to be tested\n+     * @return {@code true} if the argument is a finite\n+     * floating-point value, {@code false} otherwise.\n+     *\n+     * @see Float#isFinite(float)\n+     * @see Double#isFinite(double)\n+     *\/\n+    public static boolean isFinite(Float16 f16) {\n+        return Float.isFinite(f16.floatValue());\n+     }\n+\n+    \/\/ Skipping for now\n+    \/\/ public boolean isNaN()\n+    \/\/ public boolean isInfinite() {\n+\n+    \/**\n+     * {@return the value of this {@code Float16} as a {@code byte} after\n+     * a narrowing primitive conversion}\n+     *\n+     * @jls 5.1.3 Narrowing Primitive Conversion\n+     *\/\n+    @Override\n+    public byte byteValue() {\n+        return (byte)floatValue();\n+    }\n+\n+    \/**\n+     * {@return a string representation of this {@code Float16}}\n+     *\n+     * @implSpec\n+     * This method returns the result of {@code Float16.toString(this)}.\n+     *\/\n+    public String toString() {\n+        return toString(this);\n+    }\n+\n+    \/**\n+     * {@return the value of this {@code Float16} as a {@code short}\n+     * after a narrowing primitive conversion}\n+     *\n+     * @jls 5.1.3 Narrowing Primitive Conversion\n+     *\/\n+    @Override\n+    public short shortValue() {\n+        return (short)floatValue();\n+    }\n+\n+    \/**\n+     * {@return the value of this {@code Float16} as an {@code int} after\n+     * a narrowing primitive conversion}\n+     *\n+     * @jls 5.1.3 Narrowing Primitive Conversion\n+     *\/\n+    @Override\n+    public int intValue() {\n+        return (int)floatValue();\n+    }\n+\n+    \/**\n+     * {@return value of this {@code Float16} as a {@code long} after a\n+     * narrowing primitive conversion}\n+     *\n+     * @jls 5.1.3 Narrowing Primitive Conversion\n+     *\/\n+    @Override\n+    public long longValue() {\n+        return (long)floatValue();\n+    }\n+\n+    \/**\n+     * {@return the value of this {@code Float16} as a {@code float}\n+     * after a widening primitive conversion}\n+     *\n+     * @apiNote\n+     * This method corresponds to the convertFormat operation defined\n+     * in IEEE 754.\n+     *\n+     * @jls 5.1.2 Widening Primitive Conversion\n+     *\/\n+    @Override\n+    public float floatValue() {\n+        return float16ToFloat(value);\n+    }\n+\n+    \/**\n+     * {@return the value of this {@code Float16} as a {@code double}\n+     * after a widening primitive conversion}\n+     *\n+     * @apiNote\n+     * This method corresponds to the convertFormat operation defined\n+     * in IEEE 754.\n+     *\n+     * @jls 5.1.2 Widening Primitive Conversion\n+     *\/\n+    @Override\n+    public double doubleValue() {\n+        return (double)floatValue();\n+    }\n+\n+    \/\/ Skipping for now:\n+    \/\/ public int hashCode()\n+    \/\/ public static int hashCode(Float16 value)\n+    \/\/ public boolean equals(Object obj)\n+\n+    \/**\n+     * Returns a representation of the specified floating-point value\n+     * according to the IEEE 754 floating-point binary16 bit layout.\n+     *\n+     * @param   f16   a {@code Float16} floating-point number.\n+     * @return the bits that represent the floating-point number.\n+     *\n+     * @see Float#floatToRawIntBits(float)\n+     * @see Double#doubleToRawLongBits(double)\n+     *\/\n+    public static short float16ToRawShortBits(Float16 f16) {\n+        return f16.value;\n+    }\n+\n+    \/**\n+     * Returns the {@code Float16} value corresponding to a given bit\n+     * representation.\n+     *\n+     * @param   bits   any {@code short} integer.\n+     * @return  the {@code Float16} floating-point value with the same\n+     *          bit pattern.\n+     *\n+     * @see Float#intBitsToFloat(int)\n+     * @see Double#longBitsToDouble(long)\n+     *\/\n+    public static Float16 shortBitsToFloat16(short bits) {\n+        return new Float16(bits);\n+    }\n+\n+    \/**\n+     * Compares two {@code Float16} objects numerically.\n+     *\n+     * This method imposes a total order on {@code Float16} objects\n+     * with two differences compared to the incomplete order defined by\n+     * the Java language numerical comparison operators ({@code <, <=,\n+     * ==, >=, >}) on {@code float} and {@code double} values.\n+     *\n+     * <ul><li> A NaN is <em>unordered<\/em> with respect to other\n+     *          values and unequal to itself under the comparison\n+     *          operators.  This method chooses to define {@code\n+     *          Float16.NaN} to be equal to itself and greater than all\n+     *          other {@code Float16} values (including {@code\n+     *          Float16.POSITIVE_INFINITY}).\n+     *\n+     *      <li> Positive zero and negative zero compare equal\n+     *      numerically, but are distinct and distinguishable values.\n+     *      This method chooses to define positive zero\n+     *      to be greater than negative zero.\n+     * <\/ul>\n+     *\n+     * @param   anotherFloat16   the {@code Float16} to be compared.\n+     * @return  the value {@code 0} if {@code anotherFloat16} is\n+     *          numerically equal to this {@code Float16}; a value\n+     *          less than {@code 0} if this {@code Float16}\n+     *          is numerically less than {@code anotherFloat16};\n+     *          and a value greater than {@code 0} if this\n+     *          {@code Float16} is numerically greater than\n+     *          {@code anotherFloat16}.\n+     *\n+     * @see Float#compareTo(Float)\n+     * @see Double#compareTo(Double)\n+     * @jls 15.20.1 Numerical Comparison Operators {@code <}, {@code <=}, {@code >}, and {@code >=}\n+     *\/\n+    @Override\n+    public int compareTo(Float16 anotherFloat16) {\n+        return compare(this, anotherFloat16);\n+    }\n+\n+    \/**\n+     * Compares the two specified {@code Float16} values.\n+     *\n+     * @param   f1        the first {@code Float16} to compare\n+     * @param   f2        the second {@code Float16} to compare\n+     * @return  the value {@code 0} if {@code f1} is\n+     *          numerically equal to {@code f2}; a value less than\n+     *          {@code 0} if {@code f1} is numerically less than\n+     *          {@code f2}; and a value greater than {@code 0}\n+     *          if {@code f1} is numerically greater than\n+     *          {@code f2}.\n+     *\n+     * @see Float#compare(float, float)\n+     * @see Double#compare(double, double)\n+     *\/\n+    public static int compare(Float16 f1, Float16 f2) {\n+        return Float.compare(f1.floatValue(), f2.floatValue());\n+    }\n+\n+    \/**\n+     * Returns the larger of two {@code Float16} values.\n+     *\n+     * @apiNote\n+     * This method corresponds to the maximum operation defined in\n+     * IEEE 754.\n+     *\n+     * @param a the first operand\n+     * @param b the second operand\n+     * @return the greater of {@code a} and {@code b}\n+     * @see java.util.function.BinaryOperator\n+     * @see Math#max(float, float)\n+     * @see Math#max(double, double)\n+     *\/\n+    @IntrinsicCandidate\n+    public static Float16 max(Float16 a, Float16 b) {\n+        return shortBitsToFloat16(floatToFloat16(Math.max(a.floatValue(),\n+                                                          b.floatValue() )));\n+    }\n+\n+    \/**\n+     * Returns the smaller of two {@code Float16} values.\n+     *\n+     * @apiNote\n+     * This method corresponds to the minimum operation defined in\n+     * IEEE 754.\n+     *\n+     * @param a the first operand\n+     * @param b the second operand\n+     * @return the smaller of {@code a} and {@code b}\n+     * @see java.util.function.BinaryOperator\n+     * @see Math#min(float, float)\n+     * @see Math#min(double, double)\n+     *\/\n+    @IntrinsicCandidate\n+    public static Float16 min(Float16 a, Float16 b) {\n+        return shortBitsToFloat16(floatToFloat16(Math.min(a.floatValue(),\n+                                                          b.floatValue()) ));\n+    }\n+\n+    \/\/ Skipping for now\n+    \/\/ public Optional<Float16> describeConstable()\n+    \/\/ public Float16 resolveConstantDesc(MethodHandles.Lookup lookup)\n+\n+    \/*\n+     * Note: for the basic arithmetic operations {+, -, *, \/} and\n+     * square root, among binary interchange formats (binary16,\n+     * binary32 a.k.a. float, binary64 a.k.a double, etc.) the \"2p + 2\"\n+     * property holds. That is, if one format has p bits of precision,\n+     * if the next larger format has at least 2p + 2 bits of\n+     * precision, arithmetic on the smaller format can be implemented by:\n+     *\n+     * 1) converting each argument to the wider format\n+     * 2) performing the operation in the wider format\n+     * 3) converting the result from 2) to the narrower format\n+     *\n+     * For example, this property hold between the formats used for the\n+     * float and double types. Therefore, the following is a valid\n+     * implementation of a float addition:\n+     *\n+     * float add(float addend, float augend) {\n+     *     return (float)((double)addend + (double)augend);\n+     * }\n+     *\n+     * The same property holds between the float16 format and\n+     * float. Therefore, the software implementations of Float16 {+,\n+     * -, *, \/} and square root below use the technique of widening\n+     * the Float16 arguments to float, performing the operation in\n+     * float arithmetic, and then rounding the float result to\n+     * Float16.\n+     *\n+     * For discussion and derivation of this property see:\n+     *\n+     * \"When Is Double Rounding Innocuous?\" by Samuel Figueroa\n+     * ACM SIGNUM Newsletter, Volume 30 Issue 3, pp 21-26\n+     * https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/221332.221334\n+     *\n+     * Figueroa's write-up refers to lecture notes by W. Kahan. Those\n+     * lectures notes are assumed to be these ones by Kahan and\n+     * others:\n+     *\n+     * https:\/\/www.arithmazium.org\/classroom\/lib\/Lecture_08_notes_slides.pdf\n+     * https:\/\/www.arithmazium.org\/classroom\/lib\/Lecture_09_notes_slides.pdf\n+     *\/\n+\n+    \/**\n+     * Adds two {@code Float16} values together as per the {@code +}\n+     * operator semantics using the round to nearest rounding policy.\n+     *\n+     * The handling of signed zeros, NaNs, infinities, and other\n+     * special cases by this method is the same as for the handling of\n+     * those cases by the built-in {@code +} operator for\n+     * floating-point addition (JLS {@jls 15.18.2}).\n+     *\n+     * @apiNote This method corresponds to the addition operation\n+     * defined in IEEE 754.\n+     *\n+     * @param addend the first operand\n+     * @param augend the second operand\n+     * @return the sum of the operands\n+     *\n+     * @jls 15.4 Floating-point Expressions\n+     *\/\n+    @IntrinsicCandidate\n+    public static Float16 add(Float16 addend, Float16 augend) {\n+        return valueOf(addend.floatValue() + augend.floatValue());\n+    }\n+\n+    \/**\n+     * Subtracts two {@code Float16} values as per the {@code -}\n+     * operator semantics using the round to nearest rounding policy.\n+     *\n+     * The handling of signed zeros, NaNs, infinities, and other\n+     * special cases by this method is the same as for the handling of\n+     * those cases by the built-in {@code -} operator for\n+     * floating-point subtraction (JLS {@jls 15.18.2}).\n+     *\n+     * @apiNote This method corresponds to the subtraction operation\n+     * defined in IEEE 754.\n+     *\n+     * @param minuend the first operand\n+     * @param  subtrahend the second operand\n+     * @return the difference of the operands\n+     *\n+     * @jls 15.4 Floating-point Expressions\n+     *\/\n+    @IntrinsicCandidate\n+    public static Float16 subtract(Float16 minuend, Float16 subtrahend) {\n+        return valueOf(minuend.floatValue() - subtrahend.floatValue());\n+    }\n+\n+    \/**\n+     * Multiplies two {@code Float16} values as per the {@code *}\n+     * operator semantics using the round to nearest rounding policy.\n+     *\n+     * The handling of signed zeros, NaNs, and infinities, other\n+     * special cases by this method is the same as for the handling of\n+     * those cases by the built-in {@code *} operator for\n+     * floating-point multiplication (JLS {@jls 15.17.1}).\n+     *\n+     * @apiNote This method corresponds to the multiplication\n+     * operation defined in IEEE 754.\n+     *\n+     * @param multiplier the first operand\n+     * @param multiplicand the second operand\n+     * @return the product of the operands\n+     *\n+     * @jls 15.4 Floating-point Expressions\n+     *\/\n+    @IntrinsicCandidate\n+    public static Float16 multiply(Float16 multiplier, Float16 multiplicand) {\n+        return valueOf(multiplier.floatValue() * multiplicand.floatValue());\n+    }\n+\n+    \/**\n+     * Divides two {@code Float16} values as per the {@code \/}\n+     * operator semantics using the round to nearest rounding policy.\n+     *\n+     * The handling of signed zeros, NaNs, and infinities, other\n+     * special cases by this method is the same as for the handling of\n+     * those cases by the built-in {@code \/} operator for\n+     * floating-point division (JLS {@jls 15.17.2}).\n+     *\n+     * @apiNote This method corresponds to the division\n+     * operation defined in IEEE 754.\n+     *\n+     * @param dividend the first operand\n+     * @param divisor the second operand\n+     * @return the quotient of the operands\n+     *\n+     * @jls 15.4 Floating-point Expressions\n+     *\/\n+    @IntrinsicCandidate\n+    public static Float16 divide(Float16 dividend, Float16 divisor) {\n+        return valueOf(dividend.floatValue() \/ divisor.floatValue());\n+    }\n+\n+    \/**\n+     * {@return the square root of the operand} The square root is\n+     * computed using the round to nearest rounding policy.\n+     *\n+     * The handling of zeros, NaN, infinities, and negative arguments\n+     * by this method is analogous to the handling of those cases by\n+     * {@link Math#sqrt(double)}.\n+     *\n+     * @apiNote\n+     * This method corresponds to the squareRoot operation defined in\n+     * IEEE 754.\n+     *\n+     * @param radicand the argument to have its square root taken\n+     *\n+     * @see Math#sqrt(float)\n+     * @see Math#sqrt(double)\n+     *\/\n+    \/\/ @IntrinsicCandidate\n+    public static Float16 sqrt(Float16 radicand) {\n+        \/\/ Rounding path of sqrt(Float16 -> double) -> Float16 is fine\n+        \/\/ for preserving the correct final value. The conversion\n+        \/\/ Float16 -> double preserves the exact numerical value. The\n+        \/\/ of the double -> Float16 conversion also benefits from the\n+        \/\/ 2p+2 property of IEEE 754 arithmetic.\n+        return valueOf(Math.sqrt(radicand.doubleValue()));\n+    }\n+\n+    \/**\n+     * Returns the fused multiply add of the three arguments; that is,\n+     * returns the exact product of the first two arguments summed\n+     * with the third argument and then rounded once to the nearest\n+     * {@code Float16}.\n+     *\n+     * The handling of zeros, NaN, infinities, and other special cases\n+     * by this method is analogous to the handling of those cases by\n+     * {@link Math#fma(float, float, float)}.\n+     *\n+     * @apiNote This method corresponds to the fusedMultiplyAdd\n+     * operation defined in IEEE 754.\n+     *\n+     * @param a a value\n+     * @param b a value\n+     * @param c a value\n+     *\n+     * @return (<i>a<\/i>&nbsp;&times;&nbsp;<i>b<\/i>&nbsp;+&nbsp;<i>c<\/i>)\n+     * computed, as if with unlimited range and precision, and rounded\n+     * once to the nearest {@code Float16} value\n+     *\n+     * @see Math#fma(float, float, float)\n+     * @see Math#fma(double, double, double)\n+     *\/\n+    \/\/ @IntrinsicCandidate\n+    public static Float16 fma(Float16 a, Float16 b, Float16 c) {\n+        \/*\n+         * The double format has sufficient precision that a Float16\n+         * fma can be computed by doing the arithmetic in double, with\n+         * one rounding error for the sum, and then a second rounding\n+         * error to round the product-sum to Float16. In pseudocode,\n+         * this method is equivalent to the following code, assuming\n+         * casting was defined between Float16 and double:\n+         *\n+         * double product = (double)a * (double)b;  \/\/ Always exact\n+         * double productSum = product + (double)c;\n+         * return (Float16)produdctSum;\n+         *\n+         * (Note that a similar relationship does *not* hold between\n+         * the double format and computing a float fma.)\n+         *\n+         * Below is a sketch of the proof that simple double\n+         * arithmetic can be used to implement a correctly rounded\n+         * Float16 fma.\n+         *\n+         * ----------------------\n+         *\n+         * As preliminaries, the handling of NaN and Infinity\n+         * arguments falls out as a consequence of general operation\n+         * of non-finite values by double * and +. Any NaN argument to\n+         * fma will lead to a NaN result, infinities will propagate or\n+         * get turned into NaN as appropriate, etc.\n+         *\n+         * One or more zero arguments are also handled correctly,\n+         * including the propagation of the sign of zero if all three\n+         * arguments are zero.\n+         *\n+         * The double format has 53 logical bits of precision and its\n+         * exponent range goes from -1022 to 1023. The Float16 format\n+         * has 11 bits of logical precision and its exponent range\n+         * goes from -14 to 15. Therefore, the individual powers of 2\n+         * representable in the Float16 format range from the\n+         * subnormal 2^(-24), MIN_VALUE, to 2^15, the leading bit\n+         * position of MAX_VALUE.\n+         *\n+         * In cases where the numerical value of (a * b) + c is\n+         * computed exactly in a double, after a single rounding to\n+         * Float16, the result is necessarily correct since the one\n+         * double -> Float16 conversion is the only source of\n+         * numerical error. The operation as implemented in those\n+         * cases would be equivalent to rounding the infinitely precise\n+         * value to the result format, etc.\n+         *\n+         * However, for some inputs, the intermediate product-sum will\n+         * *not* be exact and additional analysis is needed to justify\n+         * not having any corrective computation to compensate for\n+         * intermediate rounding errors.\n+         *\n+         * The following analysis will rely on the range of bit\n+         * positions representable in the intermediate\n+         * product-sum.\n+         *\n+         * For the product a*b of Float16 inputs, the range of\n+         * exponents for nonzero finite results goes from 2^(-48)\n+         * (from MIN_VALUE squared) to 2^31 (from the exact value of\n+         * MAX_VALUE squared). This full range of exponent positions,\n+         * (31 -(-48) + 1 ) = 80 exceeds the precision of\n+         * double. However, only the product a*b can exceed the\n+         * exponent range of Float16. Therefore, there are three main\n+         * cases to consider:\n+         *\n+         * 1) Large exponent product, exponent > Float16.MAX_EXPONENT\n+         *\n+         * The magnitude of the overflow threshold for Float16 is:\n+         *\n+         * MAX_VALUE + 1\/2 * ulp(MAX_VALUE) =  0x1.ffcp15 + 0x0.002p15 = 0x1.ffep15\n+         *\n+         * Therefore, for any product greater than or equal in\n+         * magnitude to (0x1.ffep15 + MAX_VALUE) = 0x1.ffdp16, the\n+         * final fma result will certainly overflow to infinity (under\n+         * round to nearest) since adding in c = -MAX_VALUE will still\n+         * be at or above the overflow threshold.\n+         *\n+         * If the exponent of the product is 15 or 16, the smallest\n+         * subnormal Float16 is 2^-24 and the ~40 bit wide range bit\n+         * positions would fit in a single double exactly.\n+         *\n+         * 2) Exponent of product is within the range of _normal_\n+         * Float16 values; Float16.MIN_EXPONENT <=  exponent <= Float16.MAX_EXPONENT\n+         *\n+         * The exact product has at most 22 contiguous bits in its\n+         * logical significand. The third number being added in has at\n+         * most 11 contiguous bits in its significand and the lowest\n+         * bit position that could be set is 2^(-24). Therefore, when\n+         * the product has the maximum in-range exponent, 2^15, a\n+         * single double has enough precision to hold down to the\n+         * smallest subnormal bit position, 15 - (-24) + 1 = 40 <\n+         * 53. If the product was large and rounded up, increasing the\n+         * exponent, when the third operand was added, this would\n+         * cause the exponent to go up to 16, which is within the\n+         * range of double, so the product-sum is exact and will be\n+         * correct when rounded to Float16.\n+         *\n+         * 3) Exponent of product is in the range of subnormal values or smaller,\n+         * exponent < Float16.MIN_EXPONENT\n+         *\n+         * The smallest exponent possible in a product is 2^(-48).\n+         * For moderately sized Float16 values added to the product,\n+         * with an exponent of about 4, the sum will not be\n+         * exact. Therefore, an analysis is needed to determine if the\n+         * double-rounding is benign or would lead to a different\n+         * final Float16 result. Double rounding can lead to a\n+         * different result in two cases:\n+         *\n+         * 1) The first rounding from the exact value to the extended\n+         * precision (here `double`) happens to be directed _toward_ 0\n+         * to a value exactly midway between two adjacent working\n+         * precision (here `Float16`) values, followed by a second\n+         * rounding from there which again happens to be directed\n+         * _toward_ 0 to one of these values (the one with lesser\n+         * magnitude).  A single rounding from the exact value to the\n+         * working precision, in contrast, rounds to the value with\n+         * larger magnitude.\n+         *\n+         * 2) Symmetrically, the first rounding to the extended\n+         * precision happens to be directed _away_ from 0 to a value\n+         * exactly midway between two adjacent working precision\n+         * values, followed by a second rounding from there which\n+         * again happens to be directed _away_ from 0 to one of these\n+         * values (the one with larger magnitude).  However, a single\n+         * rounding from the exact value to the working precision\n+         * rounds to the value with lesser magnitude.\n+         *\n+         * If the double rounding occurs in other cases, it is\n+         * innocuous, returning the same value as a single rounding to\n+         * the final format. Therefore, it is sufficient to show that\n+         * the first rounding to double does not occur at the midpoint\n+         * of two adjacent Float16 values:\n+         *\n+         * 1) If a, b and c have the same sign, the sum a*b + c has a\n+         * significand with a large gap of 20 or more 0s between the\n+         * bits of the significand of c to the left (at most 11 bits)\n+         * and those of the product a*b to the right (at most 22\n+         * bits).  The rounding bit for the final working precision of\n+         * `float16` is the leftmost 0 in the gap.\n+         *\n+         *   a) If rounding to `double` is directed toward 0, all the\n+         *   0s in the gap are preserved, thus the `Float16` rounding\n+         *   bit is unaffected and remains 0. This means that the\n+         *   `double` value is _not_ the midpoint of two adjacent\n+         *   `float16` values, so double rounding is harmless.\n+         *\n+         *   b) If rounding to `double` is directed away form 0, the\n+         *   rightmost 0 in the gap might be replaced by a 1, but the\n+         *   others are unaffected, including the `float16` rounding\n+         *   bit. Again, this shows that the `double` value is _not_\n+         *   the midpoint of two adjacent `float16` values, and double\n+         *   rounding is innocuous.\n+         *\n+         * 2) If a, b and c have opposite signs, in the sum a*b + c\n+         * the long gap of 0s above is replaced by a long gap of\n+         * 1s. The `float16` rounding bit is the leftmost 1 in the\n+         * gap, or the second leftmost 1 iff c is a power of 2. In\n+         * both cases, the rounding bit is followed by at least\n+         * another 1.\n+         *\n+         *   a) If rounding to `double` is directed toward 0, the\n+         *   `float16` rounding bit and its follower are preserved and\n+         *   both 1, so the `double` value is _not_ the midpoint of\n+         *   two adjacent `float16` values, and double rounding is\n+         *   harmless.\n+         *\n+         *   b) If rounding to `double` is directed away from 0, the\n+         *   `float16` rounding bit and its follower are either\n+         *   preserved (both 1), or both switch to 0. Either way, the\n+         *   `double` value is again _not_ the midpoint of two\n+         *   adjacent `float16` values, and double rounding is\n+         *   harmless.\n+         *\/\n+\n+        \/\/ product is numerically exact in float before the cast to\n+        \/\/ double; not necessary to widen to double before the\n+        \/\/ multiply.\n+        double product = (double)(a.floatValue() * b.floatValue());\n+        return valueOf(product + c.doubleValue());\n+    }\n+\n+    \/**\n+     * {@return the negation of the argument}\n+     *\n+     * Special cases:\n+     * <ul>\n+     * <li> If the argument is zero, the result is a zero with the\n+     * opposite sign as the argument.\n+     * <li> If the argument is infinite, the result is an infinity\n+     * with the opposite sign as the argument.\n+     * <li> If the argument is a NaN, the result is a NaN.\n+     * <\/ul>\n+     *\n+     * @apiNote\n+     * This method corresponds to the negate operation defined in IEEE\n+     * 754.\n+     *\n+     * @param f16 the value to be negated\n+     * @jls 15.15.4 Unary Minus Operator {@code -}\n+     *\/\n+    \/\/ @IntrinsicCandidate\n+    public static Float16 negate(Float16 f16) {\n+        \/\/ Negate sign bit only. Per IEEE 754-2019 section 5.5.1,\n+        \/\/ negate is a bit-level operation and not a logical\n+        \/\/ operation. Therefore, in this case do _not_ use the float\n+        \/\/ unary minus as an implementation as that is not guaranteed\n+        \/\/ to flip the sign bit of a NaN.\n+        return shortBitsToFloat16((short)(f16.value ^ (short)0x0000_8000));\n+    }\n+\n+    \/**\n+     * {@return the absolute value of the argument}\n+     *\n+     * The handling of zeros, NaN, and infinities by this method is\n+     * analogous to the handling of those cases by {@link\n+     * Math#abs(float)}.\n+     *\n+     * @param f16 the argument whose absolute value is to be determined\n+     *\n+     * @see Math#abs(float)\n+     * @see Math#abs(double)\n+     *\/\n+    \/\/ @IntrinsicCandidate\n+    public static Float16 abs(Float16 f16) {\n+        \/\/ Zero out sign bit. Per IEE 754-2019 section 5.5.1, abs is a\n+        \/\/ bit-level operation and not a logical operation.\n+        return shortBitsToFloat16((short)(f16.value & (short)0x0000_7FFF));\n+    }\n+\n+    \/**\n+     * Returns the unbiased exponent used in the representation of a\n+     * {@code Float16}.\n+     *\n+     * <ul>\n+     * <li>If the argument is NaN or infinite, then the result is\n+     * {@link Float16#MAX_EXPONENT} + 1.\n+     * <li>If the argument is zero or subnormal, then the result is\n+     * {@link Float16#MIN_EXPONENT} - 1.\n+     * <\/ul>\n+     *\n+     * @apiNote\n+     * This method is analogous to the logB operation defined in IEEE\n+     * 754, but returns a different value on subnormal arguments.\n+     *\n+     * @param f16 a {@code Float16} value\n+     * @return the unbiased exponent of the argument\n+     *\n+     * @see Math#getExponent(float)\n+     * @see Math#getExponent(double)\n+     *\/\n+    public static int getExponent(Float16 f16) {\n+        return getExponent0(f16.value);\n+    }\n+\n+    \/**\n+     * From the bitwise representation of a float16, mask out exponent\n+     * bits, shift to the right and then subtract out float16's bias\n+     * adjust, 15, to get true exponent value.\n+     *\/\n+    \/*package*\/ static int getExponent0(short bits) {\n+        \/\/ package private to be usable in java.lang.Float.\n+        int bin16ExpBits     = 0x0000_7c00 & bits;     \/\/ Five exponent bits.\n+        return (bin16ExpBits >> (PRECISION - 1)) - 15;\n+    }\n+\n+    \/**\n+     * Returns the size of an ulp of the argument.  An ulp, unit in\n+     * the last place, of a {@code Float16} value is the positive\n+     * distance between this floating-point value and the {@code\n+     * Float16} value next larger in magnitude.  Note that for non-NaN\n+     * <i>x<\/i>, <code>ulp(-<i>x<\/i>) == ulp(<i>x<\/i>)<\/code>.\n+     *\n+     * <p>Special Cases:\n+     * <ul>\n+     * <li> If the argument is NaN, then the result is NaN.\n+     * <li> If the argument is positive or negative infinity, then the\n+     * result is positive infinity.\n+     * <li> If the argument is positive or negative zero, then the result is\n+     * {@code Float16.MIN_VALUE}.\n+     * <li> If the argument is &plusmn;{@code Float16.MAX_VALUE}, then\n+     * the result is equal to 2<sup>5<\/sup>, 32.0.\n+     * <\/ul>\n+     *\n+     * @param f16 the floating-point value whose ulp is to be returned\n+     * @return the size of an ulp of the argument\n+     *\/\n+    public static Float16 ulp(Float16 f16) {\n+        int exp = getExponent(f16);\n+\n+        return switch(exp) {\n+        case MAX_EXPONENT + 1 -> abs(f16);          \/\/ NaN or infinity\n+        case MIN_EXPONENT - 1 -> Float16.MIN_VALUE; \/\/ zero or subnormal\n+        default -> {\n+            assert exp <= MAX_EXPONENT && exp >= MIN_EXPONENT;\n+            \/\/ ulp(x) is usually 2^(SIGNIFICAND_WIDTH-1)*(2^ilogb(x))\n+            \/\/ Let float -> float16 conversion handle encoding issues.\n+            yield valueOf(Math.scalb(1.0f, exp - (PRECISION - 1)));\n+        }\n+        };\n+    }\n+}\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Float16.java","additions":1198,"deletions":0,"binary":false,"changes":1198,"status":"added"},{"patch":"@@ -236,0 +236,1 @@\n+        AVX512_FP16,\n","filename":"src\/jdk.internal.vm.ci\/share\/classes\/jdk\/vm\/ci\/amd64\/AMD64.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -222,0 +222,5 @@\n+    public static final String ADD_HF = PREFIX + \"ADD_HF\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(ADD_HF, \"AddHF\");\n+    }\n+\n@@ -237,0 +242,5 @@\n+    public static final String ADD_VHF = PREFIX + \"ADD_VHF\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(ADD_VHF, \"AddVHF\");\n+    }\n+\n@@ -465,0 +475,5 @@\n+    public static final String CONV_HF2F = PREFIX + \"CONV_HF2F\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(CONV_HF2F, \"ConvHF2F\");\n+    }\n+\n@@ -875,0 +890,5 @@\n+    public static final String MAX_VHF = PREFIX + \"MAX_VHF\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(MAX_VHF, \"MaxVHF\");\n+    }\n+\n@@ -925,0 +945,10 @@\n+    public static final String MIN_HF = PREFIX + \"MIN_HF\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(MIN_HF, \"MinHF\");\n+    }\n+\n+    public static final String MAX_HF = PREFIX + \"MAX_HF\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(MAX_HF, \"MaxHF\");\n+    }\n+\n@@ -940,0 +970,5 @@\n+    public static final String MIN_VHF = PREFIX + \"MIN_VHF\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(MIN_VHF, \"MinVHF\");\n+    }\n+\n@@ -976,0 +1011,5 @@\n+    public static final String MUL_HF = PREFIX + \"MUL_HF\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(MUL_HF, \"MulHF\");\n+    }\n+\n@@ -1001,0 +1041,5 @@\n+    public static final String MUL_VHF = PREFIX + \"MUL_VHF\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(MUL_VHF, \"MulVHF\");\n+    }\n+\n@@ -1160,0 +1205,10 @@\n+    public static final String REINTERPRET_S2HF = PREFIX + \"REINTERPRET_S2HF\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(REINTERPRET_S2HF, \"ReinterpretS2HF\");\n+    }\n+\n+    public static final String REINTERPRET_HF2S = PREFIX + \"REINTERPRET_HF2S\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(REINTERPRET_HF2S, \"ReinterpretHF2S\");\n+    }\n+\n@@ -1462,0 +1517,5 @@\n+    public static final String SUB_HF = PREFIX + \"SUB_HF\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(SUB_HF, \"SubHF\");\n+    }\n+\n@@ -1497,0 +1557,5 @@\n+    public static final String SUB_VHF = PREFIX + \"SUB_VHF\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(SUB_VHF, \"SubVHF\");\n+    }\n+\n@@ -1512,0 +1577,10 @@\n+    public static final String DIV_HF = PREFIX + \"DIV_HF\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(DIV_HF, \"DivHF\");\n+    }\n+\n+    public static final String DIV_VHF = PREFIX + \"DIV_VHF\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(DIV_VHF, \"DivVHF\");\n+    }\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/IRNode.java","additions":75,"deletions":0,"binary":false,"changes":75,"status":"modified"}]}