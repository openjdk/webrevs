{"files":[{"patch":"@@ -7977,0 +7977,15 @@\n+instruct castI2N(iRegNNoSp dst, iRegI src) %{\n+  match(Set dst (CastI2N src));\n+\n+  ins_cost(INSN_COST);\n+  format %{ \"mov $dst, $src\\t# int -> narrow ptr\" %}\n+\n+  ins_encode %{\n+    if ($dst$$reg != $src$$reg) {\n+      __ mov(as_Register($dst$$reg), as_Register($src$$reg));\n+    }\n+  %}\n+\n+  ins_pipe(ialu_reg);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -64,1 +64,2 @@\n-                               Register tmp2) {\n+                               Register tmp2,\n+                               RegSet preserve = RegSet()) {\n@@ -71,0 +72,3 @@\n+  for (RegSetIterator<Register> reg = preserve.begin(); *reg != noreg; ++reg) {\n+    stub->preserve(*reg);\n+  }\n@@ -76,0 +80,88 @@\n+\/\/ TODO 8341767 (same applies to g1StoreLSpecialTwoOops)\n+\/\/ - Can we use an unbound register for src?\n+\/\/ - Do no set\/overwrite barrier data here, also handle G1C2BarrierPostNotNull\n+\/\/ - Is the zero-extend really required in all the places?\n+\/\/ - Move this into the .m4?\n+instruct g1StoreLSpecialOneOop(indirect mem, iRegL_R11 src, immI off, iRegPNoSp tmp1, iRegPNoSp tmp2, iRegPNoSp tmp3, iRegPNoSp tmp4, rFlagsReg cr)\n+%{\n+  predicate(UseG1GC);\n+  match(Set mem (StoreLSpecial mem (Binary src off)));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, KILL cr);\n+  ins_cost(INSN_COST);\n+  format %{ \"str  $src, $mem\\t# g1StoreLSpecialOneOop\" %}\n+  ins_encode %{\n+    ((MachNode*)this)->set_barrier_data(G1C2BarrierPre | G1C2BarrierPost);\n+\n+    \/\/ Adjust address to point to narrow oop\n+    __ add($tmp4$$Register, $mem$$Register, $off$$constant);\n+    write_barrier_pre(masm, this,\n+                      $tmp4$$Register \/* obj *\/,\n+                      $tmp1$$Register \/* pre_val *\/,\n+                      $tmp2$$Register \/* tmp1 *\/,\n+                      $tmp3$$Register \/* tmp2 *\/,\n+                      RegSet::of($mem$$Register, $src$$Register, $tmp4$$Register) \/* preserve *\/);\n+\n+    __ str($src$$Register, $mem$$Register);\n+\n+    \/\/ Shift long value to extract the narrow oop field value and zero-extend it\n+    __ lsr($src$$Register, $src$$Register, $off$$constant << LogBitsPerByte);\n+    __ ubfm($src$$Register, $src$$Register, 0, 31);\n+\n+    write_barrier_post(masm, this,\n+                       $tmp4$$Register \/* store_addr *\/,\n+                       $src$$Register \/* new_val *\/,\n+                       $tmp2$$Register \/* tmp1 *\/,\n+                       $tmp3$$Register \/* tmp2 *\/);\n+  %}\n+  ins_pipe(istore_reg_mem);\n+%}\n+\n+instruct g1StoreLSpecialTwoOops(indirect mem, iRegL_R11 src, iRegPNoSp tmp1, iRegPNoSp tmp2, iRegPNoSp tmp3, iRegPNoSp tmp4, rFlagsReg cr)\n+%{\n+  predicate(UseG1GC);\n+  match(Set mem (StoreLSpecial mem src));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, KILL cr);\n+  ins_cost(INSN_COST);\n+  format %{ \"str  $src, $mem\\t# g1StoreLSpecialTwoOops\" %}\n+  ins_encode %{\n+    ((MachNode*)this)->set_barrier_data(G1C2BarrierPre | G1C2BarrierPost);\n+\n+    write_barrier_pre(masm, this,\n+                      $mem$$Register \/* obj *\/,\n+                      $tmp1$$Register \/* pre_val *\/,\n+                      $tmp2$$Register \/* tmp1 *\/,\n+                      $tmp3$$Register \/* tmp2 *\/,\n+                      RegSet::of($mem$$Register, $src$$Register) \/* preserve *\/);\n+    \/\/ Adjust address to point to the second narrow oop in the long value\n+    __ add($tmp4$$Register, $mem$$Register, 4);\n+    write_barrier_pre(masm, this,\n+                      $tmp4$$Register \/* obj *\/,\n+                      $tmp1$$Register \/* pre_val *\/,\n+                      $tmp2$$Register \/* tmp1 *\/,\n+                      $tmp3$$Register \/* tmp2 *\/,\n+                      RegSet::of($mem$$Register, $src$$Register, $tmp4$$Register) \/* preserve *\/);\n+\n+    __ str($src$$Register, $mem$$Register);\n+\n+    \/\/ Zero-extend first narrow oop to long\n+    __ ubfm($tmp1$$Register, $src$$Register, 0, 31);\n+\n+    \/\/ Shift long value to extract the second narrow oop field value\n+    __ lsr($src$$Register, $src$$Register, 32);\n+\n+    write_barrier_post(masm, this,\n+                       $mem$$Register \/* store_addr *\/,\n+                       $tmp1$$Register \/* new_val *\/,\n+                       $tmp2$$Register \/* tmp1 *\/,\n+                       $tmp3$$Register \/* tmp2 *\/,\n+                       RegSet::of($tmp1$$Register, $tmp4$$Register) \/* preserve *\/);\n+    write_barrier_post(masm, this,\n+                       $tmp4$$Register \/* store_addr *\/,\n+                       $src$$Register \/* new_val *\/,\n+                       $tmp2$$Register \/* tmp1 *\/,\n+                       $tmp3$$Register \/* tmp2 *\/);\n+  %}\n+  ins_pipe(istore_reg_mem);\n+%}\n+\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/g1\/g1_aarch64.ad","additions":93,"deletions":1,"binary":false,"changes":94,"status":"modified"},{"patch":"@@ -3132,1 +3132,4 @@\n-\n+  if (vk->has_nullable_atomic_layout()) {\n+    \/\/ Zero the null marker (setting it to 1 would be better but would require an additional register)\n+    __ strb(zr, Address(r0, vk->null_marker_offset()));\n+  }\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -63,1 +63,2 @@\n-                               Register tmp2) {\n+                               Register tmp2,\n+                               RegSet preserve = RegSet()) {\n@@ -70,0 +71,3 @@\n+  for (RegSetIterator<Register> reg = preserve.begin(); *reg != noreg; ++reg) {\n+    stub->preserve(*reg);\n+  }\n@@ -104,0 +108,85 @@\n+\/\/ TODO 8341767 (same applies to g1StoreLSpecialTwoOops)\n+\/\/ - Can we use an unbound register for src?\n+\/\/ - Do no set\/overwrite barrier data here, also handle G1C2BarrierPostNotNull\n+\/\/ - Is the zero-extend really required in all the places?\n+instruct g1StoreLSpecialOneOop(memory mem, rdx_RegL src, immI off, rRegP tmp1, rRegP tmp2, rRegP tmp3, rFlagsReg cr)\n+%{\n+  predicate(UseG1GC);\n+  match(Set mem (StoreLSpecial mem (Binary src off)));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, USE_KILL src, KILL cr);\n+  format %{ \"movq    $mem, $src\\t# g1StoreLSpecialOneOop\" %}\n+  ins_encode %{\n+    ((MachNode*)this)->set_barrier_data(G1C2BarrierPre | G1C2BarrierPost);\n+\n+    __ lea($tmp1$$Register, $mem$$Address);\n+    \/\/ Adjust address to point to narrow oop\n+    __ addq($tmp1$$Register, $off$$constant);\n+    write_barrier_pre(masm, this,\n+                      $tmp1$$Register \/* obj *\/,\n+                      $tmp2$$Register \/* pre_val *\/,\n+                      $tmp3$$Register \/* tmp *\/,\n+                      RegSet::of($tmp1$$Register, $src$$Register) \/* preserve *\/);\n+\n+    __ movq($mem$$Address, $src$$Register);\n+\n+    \/\/ Shift long value to extract the narrow oop field value and zero-extend it\n+    __ shrq($src$$Register, $off$$constant << LogBitsPerByte);\n+    __ movl($src$$Register, $src$$Register);\n+\n+    write_barrier_post(masm, this,\n+                       $tmp1$$Register \/* store_addr *\/,\n+                       $src$$Register \/* new_val *\/,\n+                       $tmp3$$Register \/* tmp1 *\/,\n+                       $tmp2$$Register \/* tmp2 *\/);\n+  %}\n+  ins_pipe(ialu_mem_reg);\n+%}\n+\n+instruct g1StoreLSpecialTwoOops(memory mem, rdx_RegL src, rRegP tmp1, rRegP tmp2, rRegP tmp3, rRegP tmp4, rFlagsReg cr)\n+%{\n+  predicate(UseG1GC);\n+  match(Set mem (StoreLSpecial mem src));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, KILL cr);\n+  format %{ \"movq    $mem, $src\\t# g1StoreLSpecialTwoOops\" %}\n+  ins_encode %{\n+    ((MachNode*)this)->set_barrier_data(G1C2BarrierPre | G1C2BarrierPost);\n+\n+    __ lea($tmp1$$Register, $mem$$Address);\n+    write_barrier_pre(masm, this,\n+                      $tmp1$$Register \/* obj *\/,\n+                      $tmp2$$Register \/* pre_val *\/,\n+                      $tmp3$$Register \/* tmp *\/,\n+                      RegSet::of($tmp1$$Register, $src$$Register) \/* preserve *\/);\n+    \/\/ Adjust address to point to the second narrow oop in the long value\n+    __ addq($tmp1$$Register, 4);\n+    write_barrier_pre(masm, this,\n+                      $tmp1$$Register \/* obj *\/,\n+                      $tmp2$$Register \/* pre_val *\/,\n+                      $tmp3$$Register \/* tmp *\/,\n+                      RegSet::of($tmp1$$Register, $src$$Register) \/* preserve *\/);\n+\n+    __ movq($mem$$Address, $src$$Register);\n+\n+    \/\/ Zero-extend first narrow oop to long\n+    __ movl($tmp4$$Register, $src$$Register);\n+\n+    \/\/ Shift long value to extract the second narrow oop field value\n+    __ shrq($src$$Register, 32);\n+\n+    write_barrier_post(masm, this,\n+                       $tmp1$$Register \/* store_addr *\/,\n+                       $src$$Register \/* new_val *\/,\n+                       $tmp3$$Register \/* tmp1 *\/,\n+                       $tmp2$$Register \/* tmp2 *\/,\n+                       RegSet::of($tmp1$$Register, $tmp4$$Register) \/* preserve *\/);\n+    \/\/ Adjust address again to point to the first narrow oop in the long value\n+    __ subq($tmp1$$Register, 4);\n+    write_barrier_post(masm, this,\n+                       $tmp1$$Register \/* store_addr *\/,\n+                       $tmp4$$Register \/* new_val *\/,\n+                       $tmp3$$Register \/* tmp1 *\/,\n+                       $tmp2$$Register \/* tmp2 *\/);\n+  %}\n+  ins_pipe(ialu_mem_reg);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/gc\/g1\/g1_x86_64.ad","additions":90,"deletions":1,"binary":false,"changes":91,"status":"modified"},{"patch":"@@ -3921,1 +3921,4 @@\n-\n+  if (vk->has_nullable_atomic_layout()) {\n+    \/\/ Set the null marker\n+    __ movb(Address(rax, vk->null_marker_offset()), 1);\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -5923,0 +5923,13 @@\n+instruct castI2N(rRegN dst, rRegI src)\n+%{\n+  match(Set dst (CastI2N src));\n+\n+  format %{ \"movq    $dst, $src\\t# int -> narrow ptr\" %}\n+  ins_encode %{\n+    if ($dst$$reg != $src$$reg) {\n+      __ movl($dst$$Register, $src$$Register);\n+    }\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ XXX\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -284,0 +284,1 @@\n+  if( strcmp(opType,\"StoreLSpecial\")==0)  return Form::idealL;\n","filename":"src\/hotspot\/share\/adlc\/forms.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -781,0 +781,1 @@\n+       !strcmp(_matrule->_rChild->_opType,\"CastI2N\")      ||\n@@ -3645,1 +3646,1 @@\n-    \"StoreI\",\"StoreL\",\"StoreP\",\"StoreN\",\"StoreNKlass\",\"StoreD\",\"StoreF\" ,\n+    \"StoreI\",\"StoreL\",\"StoreLSpecial\",\"StoreP\",\"StoreN\",\"StoreNKlass\",\"StoreD\",\"StoreF\" ,\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1823,9 +1823,21 @@\n-  for (int i = 0; i < vk->nof_nonstatic_fields(); i++) {\n-    ciField* inner_field = vk->nonstatic_field_at(i);\n-    assert(!inner_field->is_flat(), \"the iteration over nested fields is handled by the loop itself\");\n-    int off = inner_field->offset_in_bytes() - vk->first_field_offset();\n-    LoadField* load = new LoadField(src, src_off + off, inner_field, false, state_before, false);\n-    Value replacement = append(load);\n-    StoreField* store = new StoreField(dest, dest_off + off, inner_field, replacement, false, state_before, false);\n-    store->set_enclosing_field(enclosing_field);\n-    append(store);\n+  for (int i = 0; i < vk->nof_declared_nonstatic_fields(); i++) {\n+    ciField* field = vk->declared_nonstatic_field_at(i);\n+    int offset = field->offset_in_bytes() - vk->first_field_offset();\n+    if (field->is_flat()) {\n+      bool needs_atomic_access = !field->is_null_free() || field->is_volatile();\n+      assert(!needs_atomic_access, \"Atomic access in non-atomic container\");\n+      copy_inline_content(field->type()->as_inline_klass(), src, src_off + offset, dest, dest_off + offset, state_before, enclosing_field);\n+      if (!field->is_null_free()) {\n+        \/\/ Nullable, copy the null marker using Unsafe because null markers are no real fields\n+        int null_marker_offset = field->null_marker_offset() - vk->first_field_offset();\n+        Value offset = append(new Constant(new LongConstant(src_off + null_marker_offset)));\n+        Value nm = append(new UnsafeGet(T_BOOLEAN, src, offset, false));\n+        offset = append(new Constant(new LongConstant(dest_off + null_marker_offset)));\n+        append(new UnsafePut(T_BOOLEAN, dest, offset, nm, false));\n+      }\n+    } else {\n+      Value value = append(new LoadField(src, src_off + offset, field, false, state_before, false));\n+      StoreField* store = new StoreField(dest, dest_off + offset, field, value, false, state_before, false);\n+      store->set_enclosing_field(enclosing_field);\n+      append(store);\n+    }\n@@ -1889,1 +1901,1 @@\n-        \/\/ Loading from a field of an empty inline type. Just return the default instance.\n+        \/\/ Loading from a field of an empty, null-free inline type. Just return the default instance.\n@@ -1917,1 +1929,1 @@\n-        \/\/ Storing to a field of an empty inline type. Ignore.\n+        \/\/ Storing to a field of an empty, null-free inline type. Ignore.\n@@ -1936,1 +1948,1 @@\n-          \/\/ Loading from a field of an empty inline type. Just return the default instance.\n+          \/\/ Loading from a field of an empty, null-free inline type. Just return the default instance.\n@@ -2009,23 +2021,10 @@\n-        } else {  \/\/ field is flat\n-          \/\/ Look at the next bytecode to check if we can delay the field access\n-          bool can_delay_access = false;\n-          ciBytecodeStream s(method());\n-          s.force_bci(bci());\n-          s.next();\n-          if (s.cur_bc() == Bytecodes::_getfield && !needs_patching) {\n-            ciField* next_field = s.get_field(will_link);\n-            bool next_needs_patching = !next_field->holder()->is_loaded() ||\n-                                       !next_field->will_link(method(), Bytecodes::_getfield) ||\n-                                       PatchALot;\n-            can_delay_access = C1UseDelayedFlattenedFieldReads && !next_needs_patching;\n-          }\n-          if (can_delay_access) {\n-            if (has_pending_load_indexed()) {\n-              pending_load_indexed()->update(field, offset - field->holder()->as_inline_klass()->first_field_offset());\n-            } else if (has_pending_field_access()) {\n-              pending_field_access()->inc_offset(offset - field->holder()->as_inline_klass()->first_field_offset());\n-            } else {\n-              null_check(obj);\n-              DelayedFieldAccess* dfa = new DelayedFieldAccess(obj, field->holder(), field->offset_in_bytes(), state_before);\n-              set_pending_field_access(dfa);\n-            }\n+        } else {\n+          \/\/ Flat field\n+          assert(!needs_patching, \"Can't patch flat inline type field access\");\n+          ciInlineKlass* inline_klass = field->type()->as_inline_klass();\n+          bool is_naturally_atomic = inline_klass->nof_declared_nonstatic_fields() <= 1;\n+          bool needs_atomic_access = !field->is_null_free() || (field->is_volatile() && !is_naturally_atomic);\n+          if (needs_atomic_access) {\n+            assert(!has_pending_field_access(), \"Pending field accesses are not supported\");\n+            LoadField* load = new LoadField(obj, offset, field, false, state_before, needs_patching);\n+            push(type, append(load));\n@@ -2033,10 +2032,24 @@\n-            ciInlineKlass* inline_klass = field->type()->as_inline_klass();\n-            scope()->set_wrote_final();\n-            scope()->set_wrote_fields();\n-            bool need_membar = false;\n-            if (inline_klass->is_initialized() && inline_klass->is_empty()) {\n-              apush(append(new Constant(new InstanceConstant(inline_klass->default_instance()))));\n-              if (has_pending_field_access()) {\n-                set_pending_field_access(nullptr);\n-              } else if (has_pending_load_indexed()) {\n-                set_pending_load_indexed(nullptr);\n+            assert(field->is_null_free(), \"must be null-free\");\n+            \/\/ Look at the next bytecode to check if we can delay the field access\n+            bool can_delay_access = false;\n+            ciBytecodeStream s(method());\n+            s.force_bci(bci());\n+            s.next();\n+            if (s.cur_bc() == Bytecodes::_getfield && !needs_patching) {\n+              ciField* next_field = s.get_field(will_link);\n+              bool next_needs_patching = !next_field->holder()->is_loaded() ||\n+                                         !next_field->will_link(method(), Bytecodes::_getfield) ||\n+                                         PatchALot;\n+              \/\/ We can't update the offset for atomic accesses\n+              bool next_needs_atomic_access = !next_field->is_null_free() || next_field->is_volatile();\n+              can_delay_access = C1UseDelayedFlattenedFieldReads && !next_needs_patching && !next_needs_atomic_access;\n+            }\n+            if (can_delay_access) {\n+              if (has_pending_load_indexed()) {\n+                pending_load_indexed()->update(field, offset - field->holder()->as_inline_klass()->first_field_offset());\n+              } else if (has_pending_field_access()) {\n+                pending_field_access()->inc_offset(offset - field->holder()->as_inline_klass()->first_field_offset());\n+              } else {\n+                null_check(obj);\n+                DelayedFieldAccess* dfa = new DelayedFieldAccess(obj, field->holder(), field->offset_in_bytes(), state_before);\n+                set_pending_field_access(dfa);\n@@ -2044,10 +2057,0 @@\n-            } else if (has_pending_load_indexed()) {\n-              assert(!needs_patching, \"Can't patch delayed field access\");\n-              pending_load_indexed()->update(field, offset - field->holder()->as_inline_klass()->first_field_offset());\n-              NewInstance* vt = new NewInstance(inline_klass, pending_load_indexed()->state_before(), false, true);\n-              _memory->new_instance(vt);\n-              pending_load_indexed()->load_instr()->set_vt(vt);\n-              apush(append_split(vt));\n-              append(pending_load_indexed()->load_instr());\n-              set_pending_load_indexed(nullptr);\n-              need_membar = true;\n@@ -2055,12 +2058,20 @@\n-              if (has_pending_field_access()) {\n-                state_before = pending_field_access()->state_before();\n-              }\n-              NewInstance* new_instance = new NewInstance(inline_klass, state_before, false, true);\n-              _memory->new_instance(new_instance);\n-              apush(append_split(new_instance));\n-              assert(!needs_patching, \"Can't patch flat inline type field access\");\n-              if (has_pending_field_access()) {\n-                copy_inline_content(inline_klass, pending_field_access()->obj(),\n-                                    pending_field_access()->offset() + field->offset_in_bytes() - field->holder()->as_inline_klass()->first_field_offset(),\n-                                    new_instance, inline_klass->first_field_offset(), state_before);\n-                set_pending_field_access(nullptr);\n+              scope()->set_wrote_final();\n+              scope()->set_wrote_fields();\n+              bool need_membar = false;\n+              if (field->is_null_free() && inline_klass->is_initialized() && inline_klass->is_empty()) {\n+                apush(append(new Constant(new InstanceConstant(inline_klass->default_instance()))));\n+                if (has_pending_field_access()) {\n+                  set_pending_field_access(nullptr);\n+                } else if (has_pending_load_indexed()) {\n+                  set_pending_load_indexed(nullptr);\n+                }\n+              } else if (has_pending_load_indexed()) {\n+                assert(!needs_patching, \"Can't patch delayed field access\");\n+                pending_load_indexed()->update(field, offset - field->holder()->as_inline_klass()->first_field_offset());\n+                NewInstance* vt = new NewInstance(inline_klass, pending_load_indexed()->state_before(), false, true);\n+                _memory->new_instance(vt);\n+                pending_load_indexed()->load_instr()->set_vt(vt);\n+                apush(append_split(vt));\n+                append(pending_load_indexed()->load_instr());\n+                set_pending_load_indexed(nullptr);\n+                need_membar = true;\n@@ -2068,1 +2079,21 @@\n-                copy_inline_content(inline_klass, obj, field->offset_in_bytes(), new_instance, inline_klass->first_field_offset(), state_before);\n+                if (has_pending_field_access()) {\n+                  state_before = pending_field_access()->state_before();\n+                }\n+                NewInstance* new_instance = new NewInstance(inline_klass, state_before, false, true);\n+                _memory->new_instance(new_instance);\n+                apush(append_split(new_instance));\n+                if (has_pending_field_access()) {\n+                  copy_inline_content(inline_klass, pending_field_access()->obj(),\n+                                      pending_field_access()->offset() + field->offset_in_bytes() - field->holder()->as_inline_klass()->first_field_offset(),\n+                                      new_instance, inline_klass->first_field_offset(), state_before);\n+                  set_pending_field_access(nullptr);\n+                } else {\n+                  copy_inline_content(inline_klass, obj, field->offset_in_bytes(), new_instance, inline_klass->first_field_offset(), state_before);\n+                }\n+                need_membar = true;\n+              }\n+              if (need_membar) {\n+                \/\/ If we allocated a new instance ensure the stores to copy the\n+                \/\/ field contents are visible before any subsequent store that\n+                \/\/ publishes this reference.\n+                append(new MemBar(lir_membar_storestore));\n@@ -2070,7 +2101,0 @@\n-              need_membar = true;\n-            }\n-            if (need_membar) {\n-              \/\/ If we allocated a new instance ensure the stores to copy the\n-              \/\/ field contents are visible before any subsequent store that\n-              \/\/ publishes this reference.\n-              append(new MemBar(lir_membar_storestore));\n@@ -2094,1 +2118,1 @@\n-        \/\/ Storing to a field of an empty inline type. Ignore.\n+        \/\/ Storing to a field of an empty, null-free inline type. Ignore.\n@@ -2107,0 +2131,1 @@\n+        \/\/ Flat field\n@@ -2109,1 +2134,11 @@\n-        copy_inline_content(inline_klass, val, inline_klass->first_field_offset(), obj, offset, state_before, field);\n+        bool is_naturally_atomic = inline_klass->nof_declared_nonstatic_fields() <= 1;\n+        bool needs_atomic_access = !field->is_null_free() || (field->is_volatile() && !is_naturally_atomic);\n+        if (needs_atomic_access) {\n+          if (field->is_null_free()) {\n+            null_check(val);\n+          }\n+          append(new StoreField(obj, offset, field, val, false, state_before, needs_patching));\n+        } else {\n+          assert(field->is_null_free(), \"must be null-free\");\n+          copy_inline_content(inline_klass, val, inline_klass->first_field_offset(), obj, offset, state_before, field);\n+        }\n","filename":"src\/hotspot\/share\/c1\/c1_GraphBuilder.cpp","additions":112,"deletions":77,"binary":false,"changes":189,"status":"modified"},{"patch":"@@ -850,2 +850,1 @@\n-            ValueStack* state_before, bool needs_patching,\n-            ciInlineKlass* inline_klass = nullptr, Value default_value = nullptr )\n+            ValueStack* state_before, bool needs_patching)\n","filename":"src\/hotspot\/share\/c1\/c1_Instruction.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1638,0 +1638,8 @@\n+\/\/ Returns a int\/long value with the null marker bit set\n+static LIR_Opr null_marker_mask(BasicType bt, ciField* field) {\n+  assert(field->null_marker_offset() != -1, \"field does not have null marker\");\n+  int nm_offset = field->null_marker_offset() - field->offset_in_bytes();\n+  jlong null_marker = 1ULL << (nm_offset << LogBitsPerByte);\n+  return (bt == T_LONG) ? LIR_OprFact::longConst(null_marker) : LIR_OprFact::intConst(null_marker);\n+}\n+\n@@ -1667,0 +1675,1 @@\n+  ciField* field = x->field();\n@@ -1668,1 +1677,1 @@\n-  bool is_volatile = x->field()->is_volatile();\n+  bool is_volatile = field->is_volatile();\n@@ -1689,10 +1698,2 @@\n-  if (is_volatile || needs_patching) {\n-    \/\/ load item if field is volatile (fewer special cases for volatiles)\n-    \/\/ load item if field not initialized\n-    \/\/ load item if field not constant\n-    \/\/ because of code patching we cannot inline constants\n-    if (field_type == T_BYTE || field_type == T_BOOLEAN) {\n-      value.load_byte_item();\n-    } else  {\n-      value.load_item();\n-    }\n+  if (field->is_flat()) {\n+    value.load_item();\n@@ -1700,1 +1701,13 @@\n-    value.load_for_store(field_type);\n+    if (is_volatile || needs_patching) {\n+      \/\/ load item if field is volatile (fewer special cases for volatiles)\n+      \/\/ load item if field not initialized\n+      \/\/ load item if field not constant\n+      \/\/ because of code patching we cannot inline constants\n+      if (field_type == T_BYTE || field_type == T_BOOLEAN) {\n+        value.load_byte_item();\n+      } else  {\n+        value.load_item();\n+      }\n+    } else {\n+      value.load_for_store(field_type);\n+    }\n@@ -1729,0 +1742,43 @@\n+  if (field->is_flat()) {\n+    ciInlineKlass* vk = field->type()->as_inline_klass();\n+\n+#ifdef ASSERT\n+    bool is_naturally_atomic = vk->nof_declared_nonstatic_fields() <= 1;\n+    bool needs_atomic_access = !field->is_null_free() || (field->is_volatile() && !is_naturally_atomic);\n+    assert(needs_atomic_access, \"No atomic access required\");\n+    \/\/ ZGC does not support compressed oops, so only one oop can be in the payload which is written by a \"normal\" oop store.\n+    assert(!vk->contains_oops() || !UseZGC, \"ZGC does not support embedded oops in flat fields\");\n+#endif\n+\n+    \/\/ Zero the payload\n+    BasicType bt = vk->payload_size_to_basic_type();\n+    LIR_Opr payload = new_register((bt == T_LONG) ? bt : T_INT);\n+    LIR_Opr zero = (bt == T_LONG) ? LIR_OprFact::longConst(0) : LIR_OprFact::intConst(0);\n+    __ move(zero, payload);\n+\n+    bool is_constant_null = value.is_constant() && value.value()->is_null_obj();\n+    if (!is_constant_null) {\n+      LabelObj* L_isNull = new LabelObj();\n+      bool needs_null_check = !value.is_constant() || value.value()->is_null_obj();\n+      if (needs_null_check) {\n+        __ cmp(lir_cond_equal, value.result(), LIR_OprFact::oopConst(nullptr));\n+        __ branch(lir_cond_equal, L_isNull->label());\n+      }\n+      \/\/ Load payload (if not empty) and set null marker (if not null-free)\n+      if (!vk->is_empty()) {\n+        access_load_at(decorators, bt, value, LIR_OprFact::intConst(vk->first_field_offset()), payload);\n+      }\n+      if (!field->is_null_free()) {\n+        __ logical_or(payload, null_marker_mask(bt, field), payload);\n+      }\n+      if (needs_null_check) {\n+        __ branch_destination(L_isNull->label());\n+      }\n+    }\n+    access_store_at(decorators, bt, object, LIR_OprFact::intConst(x->offset()), payload,\n+                    \/\/ Make sure to emit an implicit null check and pass the information\n+                    \/\/ that this is a flat store that might require gc barriers for oop fields.\n+                    info != nullptr ? new CodeEmitInfo(info) : nullptr, info, vk);\n+    return;\n+  }\n+\n@@ -2046,1 +2102,2 @@\n-                                   CodeEmitInfo* patch_info, CodeEmitInfo* store_emit_info) {\n+                                   CodeEmitInfo* patch_info, CodeEmitInfo* store_emit_info,\n+                                   ciInlineKlass* vk) {\n@@ -2048,1 +2105,1 @@\n-  LIRAccess access(this, decorators, base, offset, type, patch_info, store_emit_info);\n+  LIRAccess access(this, decorators, base, offset, type, patch_info, store_emit_info, vk);\n@@ -2099,0 +2156,1 @@\n+  ciField* field = x->field();\n@@ -2100,1 +2158,1 @@\n-  bool is_volatile = x->field()->is_volatile();\n+  bool is_volatile = field->is_volatile();\n@@ -2151,0 +2209,37 @@\n+  if (field->is_flat()) {\n+    ciInlineKlass* vk = field->type()->as_inline_klass();\n+#ifdef ASSERT\n+    bool is_naturally_atomic = vk->nof_declared_nonstatic_fields() <= 1;\n+    bool needs_atomic_access = !field->is_null_free() || (field->is_volatile() && !is_naturally_atomic);\n+    assert(needs_atomic_access, \"No atomic access required\");\n+    assert(x->state_before() != nullptr, \"Needs state before\");\n+#endif\n+\n+    \/\/ Allocate buffer (we can't easily do this conditionally on the null check below\n+    \/\/ because branches added in the LIR are opaque to the register allocator).\n+    NewInstance* buffer = new NewInstance(vk, x->state_before(), false, true);\n+    do_NewInstance(buffer);\n+    LIRItem dest(buffer, this);\n+\n+    \/\/ Copy the payload to the buffer\n+    BasicType bt = vk->payload_size_to_basic_type();\n+    LIR_Opr payload = new_register((bt == T_LONG) ? bt : T_INT);\n+    access_load_at(decorators, bt, object, LIR_OprFact::intConst(field->offset_in_bytes()), payload,\n+                   \/\/ Make sure to emit an implicit null check\n+                   info ? new CodeEmitInfo(info) : nullptr, info);\n+    access_store_at(decorators, bt, dest, LIR_OprFact::intConst(vk->first_field_offset()), payload);\n+\n+    if (field->is_null_free()) {\n+      set_result(x, buffer->operand());\n+    } else {\n+      \/\/ Check the null marker and set result to null if it's not set\n+      __ logical_and(payload, null_marker_mask(bt, field), payload);\n+      __ cmp(lir_cond_equal, payload, (bt == T_LONG) ? LIR_OprFact::longConst(0) : LIR_OprFact::intConst(0));\n+      __ cmove(lir_cond_equal, LIR_OprFact::oopConst(nullptr), buffer->operand(), rlock_result(x), T_OBJECT);\n+    }\n+\n+    \/\/ Ensure the copy is visible before any subsequent store that publishes the buffer.\n+    __ membar_storestore();\n+    return;\n+  }\n+\n@@ -2156,1 +2251,0 @@\n-  ciField* field = x->field();\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":110,"deletions":16,"binary":false,"changes":126,"status":"modified"},{"patch":"@@ -312,1 +312,1 @@\n-                       CodeEmitInfo* patch_info = nullptr, CodeEmitInfo* store_emit_info = nullptr);\n+                       CodeEmitInfo* patch_info = nullptr, CodeEmitInfo* store_emit_info = nullptr, ciInlineKlass* vk = nullptr);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -381,1 +381,1 @@\n-  if (h->is_inline_klass() &&  InlineKlass::cast(h)->is_empty_inline_type()) {\n+  if (h->is_inline_klass() && InlineKlass::cast(h)->is_empty_inline_type()) {\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -109,0 +109,1 @@\n+  _null_marker_offset = -1;\n@@ -224,1 +225,1 @@\n-  assert(field->holder()->is_inlinetype(), \"should only be used for inline type field flattening\");\n+  assert(field->holder()->is_inlinetype() || field->holder()->is_abstract(), \"should only be used for inline type field flattening\");\n@@ -243,0 +244,1 @@\n+  _null_marker_offset = field->_null_marker_offset;\n@@ -290,1 +292,1 @@\n-  Klass* field_holder = fd->field_holder();\n+  InstanceKlass* field_holder = fd->field_holder();\n@@ -295,0 +297,6 @@\n+  if (fd->has_null_marker()) {\n+    InlineLayoutInfo* li = field_holder->inline_layout_info_adr(fd->index());\n+    _null_marker_offset = li->null_marker_offset();\n+  } else {\n+    _null_marker_offset = -1;\n+  }\n@@ -495,0 +503,1 @@\n+  tty->print(\" null_marker_offset=%s\", bool_to_str(_null_marker_offset));\n","filename":"src\/hotspot\/share\/ci\/ciField.cpp","additions":11,"deletions":2,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -55,0 +55,1 @@\n+  int              _null_marker_offset;\n@@ -178,0 +179,1 @@\n+  int null_marker_offset       () const { return _null_marker_offset; }\n","filename":"src\/hotspot\/share\/ci\/ciField.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -100,1 +100,1 @@\n-  return nof_nonstatic_fields() == 0;\n+  return nof_declared_nonstatic_fields() == 0;\n@@ -106,0 +106,2 @@\n+  VM_ENTRY_MARK;\n+  const Array<SigEntry>* sig_vk = get_InlineKlass()->extended_sig();\n@@ -107,3 +109,6 @@\n-  for (int j = 0; j < nof_nonstatic_fields(); j++) {\n-    ciField* field = nonstatic_field_at(j);\n-    slots += type2size[field->type()->basic_type()];\n+  for (int i = 0; i < sig_vk->length(); i++) {\n+    BasicType bt = sig_vk->at(i)._bt;\n+    if (bt == T_METADATA || bt == T_VOID) {\n+      continue;\n+    }\n+    slots += type2size[bt];\n@@ -115,4 +120,3 @@\n-  GUARDED_VM_ENTRY(\n-    oop default_value = to_InlineKlass()->default_value();\n-    return CURRENT_ENV->get_instance(default_value);\n-  )\n+  VM_ENTRY_MARK;\n+  oop default_value = to_InlineKlass()->default_value();\n+  return CURRENT_ENV->get_instance(default_value);\n@@ -141,0 +145,18 @@\n+\/\/ Convert payload size in bytes to corresponding BasicType\n+BasicType ciInlineKlass::payload_size_to_basic_type() const {\n+  VM_ENTRY_MARK\n+  int size = get_InlineKlass()->payload_size_in_bytes();\n+  BasicType bt;\n+  if (size == sizeof(jlong)) {\n+    bt = T_LONG;\n+  } else if (size == sizeof(jint)) {\n+    bt = T_INT;\n+  } else if (size == sizeof(jshort)) {\n+    bt = T_SHORT;\n+  } else if (size == sizeof(jbyte)) {\n+    bt = T_BYTE;\n+  } else {\n+    assert(false, \"Unsupported size: %d\", size);\n+  }\n+  return bt;\n+}\n","filename":"src\/hotspot\/share\/ci\/ciInlineKlass.cpp","additions":30,"deletions":8,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -91,0 +91,2 @@\n+  int nullable_size_in_bytes() const;\n+  BasicType payload_size_to_basic_type() const;\n","filename":"src\/hotspot\/share\/ci\/ciInlineKlass.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -539,1 +539,1 @@\n-  if (flen == 0) {\n+  if (flen == 0 && !is_inlinetype()) {\n","filename":"src\/hotspot\/share\/ci\/ciInstanceKlass.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1153,4 +1153,0 @@\n-          } else if (field_signature[0] == JVM_SIGNATURE_ARRAY) {\n-            Klass* kelem = resolve_klass(field_signature + 1, CHECK_(true));\n-            parse_klass(CHECK_(true)); \/\/ eat up the array class name\n-            value = oopFactory::new_flatArray(kelem, length, LayoutKind::NON_ATOMIC_FLAT, CHECK_(true)); \/\/ TODO FIXME fix the hard coded layout kind\n","filename":"src\/hotspot\/share\/ci\/ciReplay.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -215,1 +215,0 @@\n-  bool _has_null_marker_offsets;\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -3815,0 +3815,4 @@\n+      \/\/ If the entry has a non-default sort_offset, it must be a null marker\n+      if ((*sig)._sort_offset != (*sig)._offset) {\n+        stream->print(\" (null marker)\");\n+      }\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -73,0 +73,1 @@\n+  ciInlineKlass* _vk; \/\/ For flat, atomic accesses that might require GC barriers on oop fields\n@@ -77,1 +78,1 @@\n-            CodeEmitInfo* patch_emit_info = nullptr, CodeEmitInfo* access_emit_info = nullptr) :\n+            CodeEmitInfo* patch_emit_info = nullptr, CodeEmitInfo* access_emit_info = nullptr, ciInlineKlass* vk = nullptr) :\n@@ -85,1 +86,2 @@\n-    _access_emit_info(access_emit_info) {}\n+    _access_emit_info(access_emit_info),\n+    _vk(vk) {}\n@@ -107,0 +109,1 @@\n+  ciInlineKlass* vk() const              { return _vk; }\n","filename":"src\/hotspot\/share\/gc\/shared\/c1\/barrierSetC1.hpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -40,0 +40,15 @@\n+  \/\/ Is this a flat, atomic access that might require gc barriers on oop fields?\n+  ciInlineKlass* vk = access.vk();\n+  if (vk != nullptr && vk->has_object_fields()) {\n+    \/\/ Add pre-barriers for oop fields\n+    for (int i = 0; i < vk->nof_nonstatic_fields(); i++) {\n+      ciField* field = vk->nonstatic_field_at(i);\n+      if (!field->type()->is_primitive_type()) {\n+        int off = access.offset().opr().as_jint() + field->offset_in_bytes() - vk->first_field_offset();\n+        LIRAccess inner_access(access.gen(), decorators, access.base(), LIR_OprFact::intConst(off), field->type()->basic_type(), access.patch_emit_info(), access.access_emit_info());\n+        pre_barrier(inner_access, resolve_address(inner_access, false),\n+                    LIR_OprFact::illegalOpr \/* pre_val *\/, inner_access.patch_emit_info());\n+      }\n+    }\n+  }\n+\n@@ -52,0 +67,25 @@\n+\n+  if (vk != nullptr && vk->has_object_fields()) {\n+    \/\/ Add post-barriers for oop fields\n+    for (int i = 0; i < vk->nof_nonstatic_fields(); i++) {\n+      ciField* field = vk->nonstatic_field_at(i);\n+      if (!field->type()->is_primitive_type()) {\n+        int inner_off = field->offset_in_bytes() - vk->first_field_offset();\n+        int off = access.offset().opr().as_jint() + inner_off;\n+        LIRAccess inner_access(access.gen(), decorators, access.base(), LIR_OprFact::intConst(off), field->type()->basic_type(), access.patch_emit_info(), access.access_emit_info());\n+\n+        \/\/ Shift long value to extract the narrow oop field value and zero-extend\n+        LIR_Opr field_val = access.gen()->new_register(T_LONG);\n+        access.gen()->lir()->unsigned_shift_right(value,\n+                                                  LIR_OprFact::intConst(inner_off << LogBitsPerByte),\n+                                                  field_val, LIR_Opr::illegalOpr());\n+        LIR_Opr mask = access.gen()->load_immediate((julong) max_juint, T_LONG);\n+        access.gen()->lir()->logical_and(field_val, mask, field_val);\n+        LIR_Opr oop_val = access.gen()->new_register(T_OBJECT);\n+        access.gen()->lir()->move(field_val, oop_val);\n+\n+        assert(!is_array && !on_anonymous, \"not suppported\");\n+        post_barrier(inner_access, access.base().opr(), oop_val);\n+      }\n+    }\n+  }\n","filename":"src\/hotspot\/share\/gc\/shared\/c1\/modRefBarrierSetC1.cpp","additions":40,"deletions":0,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -151,0 +151,1 @@\n+  const InlineTypeNode* _vt; \/\/ For flat, atomic accesses that might require GC barriers on oop fields\n@@ -157,1 +158,1 @@\n-                Node* ctl = nullptr) :\n+                Node* ctl = nullptr, const InlineTypeNode* vt = nullptr) :\n@@ -160,1 +161,2 @@\n-    _ctl(ctl) {\n+    _ctl(ctl),\n+    _vt (vt) {\n@@ -166,0 +168,1 @@\n+  const InlineTypeNode* vt() const { return _vt; }\n","filename":"src\/hotspot\/share\/gc\/shared\/c2\/barrierSetC2.hpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -45,1 +45,6 @@\n-  if (!access.is_oop() || tightly_coupled_alloc || (!in_heap && !anonymous)) {\n+  const InlineTypeNode* vt = nullptr;\n+  if (access.is_parse_access() && static_cast<C2ParseAccess&>(access).vt() != nullptr) {\n+    vt = static_cast<C2ParseAccess&>(access).vt();\n+  }\n+\n+  if (vt == nullptr && (!access.is_oop() || tightly_coupled_alloc || (!in_heap && !anonymous))) {\n@@ -59,2 +64,27 @@\n-  post_barrier(kit, kit->control(), access.raw_access(), access.base(), adr, adr_idx, val.node(),\n-               access.type(), use_precise);\n+\n+  \/\/ TODO 8341767\n+  \/\/ - We actually only need the post barrier once for non-arrays (same for C1, right)?\n+  \/\/ - Value is only needed to determine if we are storing null. Maybe we can go with a simple boolean?\n+  if (vt != nullptr) {\n+    for (uint i = 0; i < vt->field_count(); ++i) {\n+      ciType* type = vt->field_type(i);\n+      if (!type->is_primitive_type()) {\n+        assert(!is_array, \"array access not supported\");\n+        ciInlineKlass* vk = vt->bottom_type()->inline_klass();\n+        int field_offset = vt->field_offset(i) - vk->first_field_offset();\n+        Node* value = vt->field_value(i);\n+        Node* field_adr = kit->basic_plus_adr(access.base(), adr, field_offset);\n+\n+        ciField* field = vk->get_field_by_offset(vt->field_offset(i), false);\n+        assert(field != nullptr, \"field not found\");\n+        adr_type = kit->C->alias_type(field)->adr_type();\n+        adr_idx = kit->C->get_alias_index(adr_type);\n+\n+        post_barrier(kit, kit->control(), nullptr, access.base(), field_adr, adr_idx, value,\n+                     type->basic_type(), use_precise);\n+      }\n+    }\n+  } else {\n+    post_barrier(kit, kit->control(), access.raw_access(), access.base(), adr, adr_idx, val.node(),\n+                 access.type(), use_precise);\n+  }\n","filename":"src\/hotspot\/share\/gc\/shared\/c2\/modRefBarrierSetC2.cpp","additions":33,"deletions":3,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -300,0 +300,8 @@\n+\n+  bool is_null_free_inline_type() {\n+    return _current_stream.is_null_free_inline_type();\n+  }\n+\n+  int null_marker_offset() {\n+    return _current_stream.null_marker_offset();\n+  }\n","filename":"src\/hotspot\/share\/oops\/fieldStreams.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -421,1 +421,1 @@\n-int InlineKlass::collect_fields(GrowableArray<SigEntry>* sig, int base_off) {\n+int InlineKlass::collect_fields(GrowableArray<SigEntry>* sig, float& max_offset, int base_off, int null_marker_offset) {\n@@ -424,0 +424,1 @@\n+  max_offset = base_off;\n@@ -430,0 +431,4 @@\n+      int field_null_marker_offset = -1;\n+      if (!fs.is_null_free_inline_type()) {\n+        field_null_marker_offset = base_off + fs.null_marker_offset() - (base_off > 0 ? first_field_offset() : 0);\n+      }\n@@ -431,1 +436,1 @@\n-      count += InlineKlass::cast(vk)->collect_fields(sig, offset);\n+      count += InlineKlass::cast(vk)->collect_fields(sig, max_offset, offset, field_null_marker_offset);\n@@ -437,0 +442,7 @@\n+    if (fs.field_descriptor().field_holder() != this) {\n+      \/\/ Inherited field, add an empty wrapper to this to distinguish it from a \"local\" field\n+      \/\/ with a different offset and avoid false adapter sharing. TODO 8348547 Is this sufficient?\n+      SigEntry::add_entry(sig, T_METADATA, name(), base_off);\n+      SigEntry::add_entry(sig, T_VOID, name(), offset);\n+    }\n+    max_offset = MAX2(max_offset, (float)offset);\n@@ -439,0 +451,6 @@\n+  \/\/ Null markers are no real fields, add them manually at the end (C2 relies on this) of the flat fields\n+  if (null_marker_offset != -1) {\n+    max_offset += 0.1f; \/\/ We add the markers \"in-between\" because they are no real fields\n+    SigEntry::add_entry(sig, T_BOOLEAN, name(), null_marker_offset, max_offset);\n+    count++;\n+  }\n@@ -454,1 +472,2 @@\n-    int nb_fields = collect_fields(&sig_vk);\n+    float max_offset = 0;\n+    int nb_fields = collect_fields(&sig_vk, max_offset);\n","filename":"src\/hotspot\/share\/oops\/inlineKlass.cpp","additions":22,"deletions":3,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -226,1 +226,1 @@\n-  int collect_fields(GrowableArray<SigEntry>* sig, int base_off = 0);\n+  int collect_fields(GrowableArray<SigEntry>* sig, float& max_offset, int base_off = 0, int null_marker_offset = -1);\n","filename":"src\/hotspot\/share\/oops\/inlineKlass.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -527,1 +527,1 @@\n-    tty->cr();\n+    st->cr();\n","filename":"src\/hotspot\/share\/oops\/methodData.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -517,2 +517,7 @@\n-          cifield = iklass->nonstatic_field_at(0);\n-          cifield->print_name_on(st);\n+          if (0 < (uint)iklass->nof_nonstatic_fields()) {\n+            cifield = iklass->nonstatic_field_at(0);\n+            cifield->print_name_on(st);\n+          } else {\n+            \/\/ Must be a null marker\n+            st->print(\"null marker\");\n+          }\n@@ -527,2 +532,7 @@\n-            cifield = iklass->nonstatic_field_at(j);\n-            cifield->print_name_on(st);\n+            if (j < (uint)iklass->nof_nonstatic_fields()) {\n+              cifield = iklass->nonstatic_field_at(j);\n+              cifield->print_name_on(st);\n+            } else {\n+              \/\/ Must be a null marker\n+              st->print(\"null marker\");\n+            }\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":14,"deletions":4,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -221,0 +221,9 @@\n+\/\/ Cast an integer to a narrow oop\n+class CastI2NNode : public Node {\n+  public:\n+  CastI2NNode(Node* ctrl, Node* n) : Node(ctrl, n) { }\n+  virtual int Opcode() const;\n+  virtual uint ideal_reg() const { return Op_RegN; }\n+  virtual const Type* bottom_type() const { return TypeNarrowOop::BOTTOM; }\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/castnode.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -72,0 +72,1 @@\n+macro(CastI2N)\n@@ -352,0 +353,1 @@\n+macro(StoreLSpecial)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -68,0 +68,1 @@\n+#include \"opto\/movenode.hpp\"\n@@ -3718,0 +3719,1 @@\n+  case Op_StoreLSpecial:\n@@ -5819,0 +5821,2 @@\n+  } else if (bt == T_FLOAT) {\n+    result = new MoveI2FNode(value);\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1601,1 +1601,2 @@\n-    case Op_CastX2P: {\n+    case Op_CastX2P:\n+    case Op_CastI2N: {\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1436,0 +1436,3 @@\n+      case Op_CastI2N:\n+        early->add_inst(self);\n+        continue;\n","filename":"src\/hotspot\/share\/opto\/gcm.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1689,1 +1689,2 @@\n-                                bool safe_for_replace) {\n+                                bool safe_for_replace,\n+                                const InlineTypeNode* vt) {\n@@ -1712,1 +1713,1 @@\n-  C2ParseAccess access(this, decorators | C2_WRITE_ACCESS, bt, obj, addr);\n+  C2ParseAccess access(this, decorators | C2_WRITE_ACCESS, bt, obj, addr, nullptr, vt);\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -622,1 +622,2 @@\n-                        bool safe_for_replace = true);\n+                        bool safe_for_replace = true,\n+                        const InlineTypeNode* vt = nullptr);\n","filename":"src\/hotspot\/share\/opto\/graphKit.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,0 +31,1 @@\n+#include \"opto\/convertnode.hpp\"\n@@ -33,0 +34,2 @@\n+#include \"opto\/movenode.hpp\"\n+#include \"opto\/narrowptrnode.hpp\"\n@@ -195,0 +198,22 @@\n+\/\/ Get the value of the null marker at the given offset.\n+Node* InlineTypeNode::null_marker_by_offset(int offset, int holder_offset) const {\n+  \/\/ Search through the null markers of all flat fields\n+  for (uint i = 0; i < field_count(); ++i) {\n+    if (field_is_flat(i)) {\n+      InlineTypeNode* value = field_value(i)->as_InlineType();\n+      if (!field_is_null_free(i)) {\n+        int nm_offset = holder_offset + field_null_marker_offset(i);\n+        if (nm_offset == offset) {\n+          return value->get_is_init();\n+        }\n+      }\n+      int flat_holder_offset = holder_offset + field_offset(i) - value->inline_klass()->first_field_offset();\n+      Node* nm_value = value->null_marker_by_offset(offset, flat_holder_offset);\n+      if (nm_value != nullptr) {\n+        return nm_value;\n+      }\n+    }\n+  }\n+  return nullptr;\n+}\n+\n@@ -197,1 +222,9 @@\n-Node* InlineTypeNode::field_value_by_offset(int offset, bool recursive) const {\n+Node* InlineTypeNode::field_value_by_offset(int offset, bool recursive, bool search_null_marker) const {\n+  \/\/ First check if we are loading a null marker which is not a real field\n+  if (recursive && search_null_marker) {\n+    Node* value = null_marker_by_offset(offset);\n+    if (value != nullptr){\n+      return value;\n+    }\n+  }\n+\n@@ -199,1 +232,1 @@\n-  \/\/ corresponding InlineTypeNode input and 'sub_offset' is the offset in flattened inline type.\n+  \/\/ corresponding InlineTypeNode input and 'sub_offset' is the offset in the flattened inline type.\n@@ -209,1 +242,1 @@\n-      return vt->field_value_by_offset(sub_offset, recursive);\n+      return vt->field_value_by_offset(sub_offset, recursive, false);\n@@ -260,0 +293,37 @@\n+bool InlineTypeNode::field_is_volatile(uint index) const {\n+  assert(index < field_count(), \"index out of bounds\");\n+  ciField* field = inline_klass()->declared_nonstatic_field_at(index);\n+  assert(!field->is_flat() || field->type()->is_inlinetype(), \"must be an inline type\");\n+  return field->is_volatile();\n+}\n+\n+int InlineTypeNode::field_null_marker_offset(uint index) const {\n+  assert(index < field_count(), \"index out of bounds\");\n+  ciField* field = inline_klass()->declared_nonstatic_field_at(index);\n+  assert(field->is_flat(), \"must be an inline type\");\n+  return field->null_marker_offset();\n+}\n+\n+uint InlineTypeNode::add_fields_to_safepoint(Unique_Node_List& worklist, Node_List& null_markers, SafePointNode* sfpt) {\n+  uint cnt = 0;\n+  for (uint i = 0; i < field_count(); ++i) {\n+    Node* value = field_value(i);\n+    if (field_is_flat(i)) {\n+      InlineTypeNode* vt = value->as_InlineType();\n+      cnt += vt->add_fields_to_safepoint(worklist, null_markers, sfpt);\n+      if (!field_is_null_free(i)) {\n+        null_markers.push(vt->get_is_init());\n+        cnt++;\n+      }\n+      continue;\n+    }\n+    if (value->is_InlineType()) {\n+      \/\/ Add inline type to the worklist to process later\n+      worklist.push(value);\n+    }\n+    sfpt->add_req(value);\n+    cnt++;\n+  }\n+  return cnt;\n+}\n+\n@@ -273,2 +343,0 @@\n-  ciInlineKlass* vk = inline_klass();\n-  uint nfields = vk->nof_nonstatic_fields();\n@@ -276,1 +344,0 @@\n-  \/\/ Replace safepoint edge by SafePointScalarObjectNode and add field values\n@@ -279,8 +346,4 @@\n-  SafePointScalarObjectNode* sobj = new SafePointScalarObjectNode(type()->isa_instptr(),\n-                                                                  nullptr,\n-                                                                  first_ind,\n-                                                                  sfpt->jvms()->depth(),\n-                                                                  nfields);\n-  sobj->init_req(0, igvn->C->root());\n-  \/\/ Nullable inline types have an IsInit field that needs\n-  \/\/ to be checked before using the field values.\n+\n+  \/\/ Iterate over the inline type fields in order of increasing offset and add the\n+  \/\/ field values to the safepoint. Nullable inline types have an IsInit field that\n+  \/\/ needs to be checked before using the field values.\n@@ -293,10 +356,5 @@\n-  \/\/ Iterate over the inline type fields in order of increasing\n-  \/\/ offset and add the field values to the safepoint.\n-  for (uint j = 0; j < nfields; ++j) {\n-    int offset = vk->nonstatic_field_at(j)->offset_in_bytes();\n-    Node* value = field_value_by_offset(offset, true \/* include flat inline type fields *\/);\n-    if (value->is_InlineType()) {\n-      \/\/ Add inline type field to the worklist to process later\n-      worklist.push(value);\n-    }\n-    sfpt->add_req(value);\n+  Node_List null_markers;\n+  uint nfields = add_fields_to_safepoint(worklist, null_markers, sfpt);\n+  \/\/ Add null markers after the field values\n+  for (uint i = 0; i < null_markers.size(); ++i) {\n+    sfpt->add_req(null_markers.at(i));\n@@ -305,0 +363,7 @@\n+  \/\/ Replace safepoint edge by SafePointScalarObjectNode\n+  SafePointScalarObjectNode* sobj = new SafePointScalarObjectNode(type()->isa_instptr(),\n+                                                                  nullptr,\n+                                                                  first_ind,\n+                                                                  sfpt->jvms()->depth(),\n+                                                                  nfields);\n+  sobj->init_req(0, igvn->C->root());\n@@ -458,1 +523,4 @@\n-      value = make_from_flat_impl(kit, ft->as_inline_klass(), base, ptr, holder, offset, decorators, visited);\n+      bool needs_atomic_access = !null_free || field_is_volatile(i);\n+      assert(!needs_atomic_access, \"Atomic access in non-atomic container\");\n+      int nm_offset = field_is_null_free(i) ? -1 : (holder_offset + field_null_marker_offset(i));\n+      value = make_from_flat_impl(kit, ft->as_inline_klass(), base, ptr, holder, offset, false, nm_offset, decorators, visited);\n@@ -501,1 +569,134 @@\n-void InlineTypeNode::store_flat(GraphKit* kit, Node* base, Node* ptr, ciInstanceKlass* holder, int holder_offset, DecoratorSet decorators) const {\n+\/\/ Get a field value from the payload by shifting it according to the offset\n+static Node* get_payload_value(PhaseGVN* gvn, Node* payload, BasicType bt, BasicType val_bt, int offset) {\n+  \/\/ Shift to the right position in the long value\n+  assert((offset + type2aelembytes(val_bt)) <= type2aelembytes(bt), \"Value does not fit into payload\");\n+  Node* value = nullptr;\n+  Node* shift_val = gvn->intcon(offset << LogBitsPerByte);\n+  if (bt == T_LONG) {\n+    value = gvn->transform(new URShiftLNode(payload, shift_val));\n+    value = gvn->transform(new ConvL2INode(value));\n+  } else {\n+    value = gvn->transform(new URShiftINode(payload, shift_val));\n+  }\n+\n+  if (val_bt == T_INT || val_bt == T_OBJECT) {\n+    return value;\n+  } else {\n+    \/\/ Make sure to zero unused bits in the 32-bit value\n+    return Compile::narrow_value(val_bt, value, nullptr, gvn, true);\n+  }\n+}\n+\n+\/\/ Convert a payload value to field values\n+void InlineTypeNode::convert_from_payload(GraphKit* kit, BasicType bt, Node* payload, int holder_offset, bool null_free, int null_marker_offset) {\n+  PhaseGVN* gvn = &kit->gvn();\n+  Node* value = nullptr;\n+  if (!null_free) {\n+    \/\/ Get the null marker\n+    value = get_payload_value(gvn, payload, bt, T_BOOLEAN, null_marker_offset);\n+    set_req(IsInit, value);\n+  }\n+  \/\/ Iterate over the fields and get their values from the payload\n+  for (uint i = 0; i < field_count(); ++i) {\n+    ciType* ft = field_type(i);\n+    int offset = holder_offset + field_offset(i) - inline_klass()->first_field_offset();\n+    if (field_is_flat(i)) {\n+      null_marker_offset = holder_offset + field_null_marker_offset(i) - inline_klass()->first_field_offset();\n+      InlineTypeNode* vt = make_uninitialized(*gvn, ft->as_inline_klass(), field_is_null_free(i));\n+      vt->convert_from_payload(kit, bt, payload, offset, field_is_null_free(i), null_marker_offset);\n+      value = gvn->transform(vt);\n+    } else {\n+      value = get_payload_value(gvn, payload, bt, ft->basic_type(), offset);\n+      if (!ft->is_primitive_type()) {\n+        \/\/ Narrow oop field\n+        assert(UseCompressedOops && bt == T_LONG, \"Naturally atomic\");\n+        const Type* val_type = Type::get_const_type(ft)->make_narrowoop();\n+        value = gvn->transform(new CastI2NNode(kit->control(), value));\n+        value = gvn->transform(new DecodeNNode(value, val_type));\n+        \/\/ TODO 8341767 Should we add the membar to the CastI2N and give it a type?\n+        value = gvn->transform(new CastPPNode(kit->control(), value, Type::get_const_type(ft), ConstraintCastNode::UnconditionalDependency));\n+        \/\/ Prevent the CastI2N from floating below a safepoint\n+        kit->insert_mem_bar(Op_MemBarVolatile, value);\n+\n+        if (ft->is_inlinetype()) {\n+          GrowableArray<ciType*> visited;\n+          value = make_from_oop_impl(kit, value, ft->as_inline_klass(), field_is_null_free(i), visited);\n+        }\n+      }\n+    }\n+    set_field_value(i, value);\n+  }\n+}\n+\n+\/\/ Set a field value in the payload by shifting it according to the offset\n+static Node* set_payload_value(PhaseGVN* gvn, Node* payload, BasicType bt, Node* value, BasicType val_bt, int offset) {\n+  assert((offset + type2aelembytes(val_bt)) <= type2aelembytes(bt), \"Value does not fit into payload\");\n+\n+  \/\/ Make sure to zero unused bits in the 32-bit value\n+  if (val_bt == T_BYTE || val_bt == T_BOOLEAN) {\n+    value = gvn->transform(new AndINode(value, gvn->intcon(0xFF)));\n+  } else if (val_bt == T_CHAR || val_bt == T_SHORT) {\n+    value = gvn->transform(new AndINode(value, gvn->intcon(0xFFFF)));\n+  } else if (val_bt == T_FLOAT) {\n+    value = gvn->transform(new MoveF2INode(value));\n+  } else {\n+    assert(val_bt == T_INT, \"Unsupported type: %s\", type2name(val_bt));\n+  }\n+\n+  Node* shift_val = gvn->intcon(offset << LogBitsPerByte);\n+  if (bt == T_LONG) {\n+    \/\/ Convert to long and remove the sign bit (the backend will fold this and emit a zero extend i2l)\n+    value = gvn->transform(new ConvI2LNode(value));\n+    value = gvn->transform(new AndLNode(value, gvn->longcon(0xFFFFFFFF)));\n+\n+    Node* shift_value = gvn->transform(new LShiftLNode(value, shift_val));\n+    payload = new OrLNode(shift_value, payload);\n+  } else {\n+    Node* shift_value = gvn->transform(new LShiftINode(value, shift_val));\n+    payload = new OrINode(shift_value, payload);\n+  }\n+  return gvn->transform(payload);\n+}\n+\n+\/\/ Convert the field values to a payload value of type 'bt'\n+Node* InlineTypeNode::convert_to_payload(GraphKit* kit, BasicType bt, Node* payload, int holder_offset, bool null_free, int null_marker_offset, int& oop_off_1, int& oop_off_2) const {\n+  PhaseGVN* gvn = &kit->gvn();\n+  Node* value = nullptr;\n+  if (!null_free) {\n+    \/\/ Set the null marker\n+    value = get_is_init();\n+    payload = set_payload_value(gvn, payload, bt, value, T_BYTE, null_marker_offset);\n+  }\n+  \/\/ Iterate over the fields and add their values to the payload\n+  for (uint i = 0; i < field_count(); ++i) {\n+    value = field_value(i);\n+    int inner_offset = field_offset(i) - inline_klass()->first_field_offset();\n+    int offset = holder_offset + inner_offset;\n+    if (field_is_flat(i)) {\n+      null_marker_offset = holder_offset + field_null_marker_offset(i) - inline_klass()->first_field_offset();\n+      payload = value->as_InlineType()->convert_to_payload(kit, bt, payload, offset, field_is_null_free(i), null_marker_offset, oop_off_1, oop_off_2);\n+    } else {\n+      ciType* ft = field_type(i);\n+      BasicType field_bt = ft->basic_type();\n+      if (!ft->is_primitive_type()) {\n+        \/\/ Narrow oop field\n+        assert(UseCompressedOops && bt == T_LONG, \"Naturally atomic\");\n+        if (oop_off_1 == -1) {\n+          oop_off_1 = inner_offset;\n+        } else {\n+          assert(oop_off_2 == -1, \"already set\");\n+          oop_off_2 = inner_offset;\n+        }\n+        const Type* val_type = Type::get_const_type(ft)->make_narrowoop();\n+        value = gvn->transform(new EncodePNode(value, val_type));\n+        value = gvn->transform(new CastP2XNode(kit->control(), value));\n+        value = gvn->transform(new ConvL2INode(value));\n+        field_bt = T_INT;\n+      }\n+      payload = set_payload_value(gvn, payload, bt, value, field_bt, offset);\n+    }\n+  }\n+  return payload;\n+}\n+\n+void InlineTypeNode::store_flat(GraphKit* kit, Node* base, Node* ptr, ciInstanceKlass* holder, int holder_offset, bool atomic, int null_marker_offset, DecoratorSet decorators) const {\n@@ -505,0 +706,51 @@\n+  bool null_free = (null_marker_offset == -1);\n+\n+  if (atomic) {\n+#ifdef ASSERT\n+    bool is_naturally_atomic = inline_klass()->is_empty() || (null_free && inline_klass()->nof_declared_nonstatic_fields() == 1);\n+    assert(!is_naturally_atomic, \"No atomic access required\");\n+#endif\n+    \/\/ Convert to a payload value <= 64-bit and write atomically.\n+    \/\/ The payload might contain at most two oop fields that must be narrow because otherwise they would be 64-bit\n+    \/\/ in size and would then be written by a \"normal\" oop store. If the payload contains oops, its size is always\n+    \/\/ 64-bit because the next smaller size would be 32-bit which could only hold one narrow oop that would then be\n+    \/\/ written by a normal narrow oop store. These properties are asserted in 'convert_to_payload'.\n+    BasicType bt = inline_klass()->payload_size_to_basic_type();\n+    Node* payload = (bt == T_LONG) ? kit->longcon(0) : kit->intcon(0);\n+    int oop_off_1 = -1;\n+    int oop_off_2 = -1;\n+    payload = convert_to_payload(kit, bt, payload, 0, null_free, null_marker_offset - holder_offset, oop_off_1, oop_off_2);\n+    Node* adr = kit->basic_plus_adr(base, ptr, holder_offset);\n+    if (!UseG1GC || oop_off_1 == -1) {\n+      \/\/ No oop fields or no late barrier expansion. Emit an atomic store of the payload and add GC barriers if needed.\n+      assert(oop_off_2 == -1 || !UseG1GC, \"sanity\");\n+      \/\/ ZGC does not support compressed oops, so only one oop can be in the payload which is written by a \"normal\" oop store.\n+      assert((oop_off_1 == -1 && oop_off_2 == -1) || !UseZGC, \"ZGC does not support embedded oops in flat fields\");\n+      const Type* val_type = Type::get_const_basic_type(bt);\n+      bool is_array = (kit->gvn().type(base)->isa_aryptr() != nullptr);\n+      decorators |= C2_MISMATCHED;\n+      kit->access_store_at(base, adr, TypeRawPtr::BOTTOM, payload, val_type, bt, is_array ? (decorators | IS_ARRAY) : decorators, true, this);\n+    } else {\n+      \/\/ Contains oops and requires late barrier expansion. Emit a special store node that allows to emit GC barriers in the backend.\n+      assert(UseG1GC, \"Unexpected GC\");\n+      assert(bt == T_LONG, \"Unexpected payload type\");\n+      const TypePtr* adr_type = TypeRawPtr::BOTTOM;\n+      Node* mem = kit->memory(adr_type);\n+      \/\/ If one oop, set the offset (if no offset is set, two oops are assumed by the backend)\n+      Node* oop_offset = (oop_off_2 == -1) ? kit->intcon(oop_off_1) : nullptr;\n+      Node* st = kit->gvn().transform(new StoreLSpecialNode(kit->control(), mem, adr, adr_type, payload, oop_offset, MemNode::unordered));\n+      kit->set_memory(st, adr_type);\n+    }\n+    \/\/ Prevent loads from floating above this mismatched store\n+    kit->insert_mem_bar(Op_MemBarCPUOrder);\n+    return;\n+  }\n+\n+  if (!null_free) {\n+    \/\/ Nullable, store the null marker\n+    Node* adr = kit->basic_plus_adr(base, ptr, null_marker_offset);\n+    const TypePtr* adr_type = kit->gvn().type(adr)->isa_ptr();\n+    int alias_idx = kit->C->get_alias_index(adr_type);\n+    kit->store_to_memory(kit->control(), adr, get_is_init(), T_BOOLEAN, alias_idx, MemNode::unordered);\n+  }\n+\n@@ -523,1 +775,4 @@\n-      value->as_InlineType()->store_flat(kit, base, ptr, holder, offset, decorators);\n+      bool needs_atomic_access = !field_is_null_free(i) || field_is_volatile(i);\n+      assert(!needs_atomic_access, \"Atomic access in non-atomic container\");\n+      int nm_offset = field_is_null_free(i) ? -1 : (holder_offset + field_null_marker_offset(i));\n+      value->as_InlineType()->store_flat(kit, base, ptr, holder, offset, false, nm_offset, decorators);\n@@ -649,0 +904,10 @@\n+static void replace_proj(Compile* C, CallNode* call, uint& proj_idx, Node* value, BasicType bt) {\n+  ProjNode* pn = call->proj_out_or_null(proj_idx);\n+  if (pn != nullptr) {\n+    C->gvn_replace_by(pn, value);\n+    C->initial_gvn()->hash_delete(pn);\n+    pn->set_req(0, C->top());\n+  }\n+  proj_idx += type2size[bt];\n+}\n+\n@@ -654,18 +919,20 @@\n-  ciInlineKlass* vk = inline_klass();\n-  for (DUIterator_Fast imax, i = call->fast_outs(imax); i < imax; i++) {\n-    ProjNode* pn = call->fast_out(i)->as_Proj();\n-    uint con = pn->_con;\n-    Node* field = nullptr;\n-    if (con == TypeFunc::Parms) {\n-      field = get_oop();\n-    } else if (con == (call->tf()->range_cc()->cnt() - 1)) {\n-      field = get_is_init();\n-    } else if (con > TypeFunc::Parms) {\n-      uint field_nb = con - (TypeFunc::Parms+1);\n-      int extra = 0;\n-      for (uint j = 0; j < field_nb - extra; j++) {\n-        ciField* f = vk->nonstatic_field_at(j);\n-        BasicType bt = f->type()->basic_type();\n-        if (bt == T_LONG || bt == T_DOUBLE) {\n-          extra++;\n-        }\n+  uint proj_idx = TypeFunc::Parms;\n+  \/\/ Replace oop projection\n+  replace_proj(C, call, proj_idx, get_oop(), T_OBJECT);\n+  \/\/ Replace field projections\n+  replace_field_projs(C, call, proj_idx);\n+  \/\/ Replace is_init projection\n+  replace_proj(C, call, proj_idx, get_is_init(), T_BOOLEAN);\n+  assert(proj_idx == call->tf()->range_cc()->cnt(), \"missed a projection\");\n+}\n+\n+void InlineTypeNode::replace_field_projs(Compile* C, CallNode* call, uint& proj_idx) {\n+  for (uint i = 0; i < field_count(); ++i) {\n+    Node* value = field_value(i);\n+    if (field_is_flat(i)) {\n+      InlineTypeNode* vt = value->as_InlineType();\n+      \/\/ Replace field projections for flat field\n+      vt->replace_field_projs(C, call, proj_idx);\n+      if (!field_is_null_free(i)) {\n+        \/\/ Replace is_init projection for nullable field\n+        replace_proj(C, call, proj_idx, vt->get_is_init(), T_BOOLEAN);\n@@ -673,8 +940,1 @@\n-      ciField* f = vk->nonstatic_field_at(field_nb - extra);\n-      field = field_value_by_offset(f->offset_in_bytes(), true);\n-    }\n-    if (field != nullptr) {\n-      C->gvn_replace_by(pn, field);\n-      C->initial_gvn()->hash_delete(pn);\n-      pn->set_req(0, C->top());\n-      --i; --imax;\n+      continue;\n@@ -682,0 +942,2 @@\n+    \/\/ Replace projection for field value\n+    replace_proj(C, call, proj_idx, value, field_type(i)->basic_type());\n@@ -949,1 +1211,2 @@\n-InlineTypeNode* InlineTypeNode::make_from_flat(GraphKit* kit, ciInlineKlass* vk, Node* obj, Node* ptr, ciInstanceKlass* holder, int holder_offset, DecoratorSet decorators) {\n+InlineTypeNode* InlineTypeNode::make_from_flat(GraphKit* kit, ciInlineKlass* vk, Node* obj, Node* ptr, ciInstanceKlass* holder, int holder_offset,\n+                                               bool atomic, int null_marker_offset, DecoratorSet decorators) {\n@@ -952,1 +1215,1 @@\n-  return make_from_flat_impl(kit, vk, obj, ptr, holder, holder_offset, decorators, visited);\n+  return make_from_flat_impl(kit, vk, obj, ptr, holder, holder_offset, atomic, null_marker_offset, decorators, visited);\n@@ -956,1 +1219,2 @@\n-InlineTypeNode* InlineTypeNode::make_from_flat_impl(GraphKit* kit, ciInlineKlass* vk, Node* obj, Node* ptr, ciInstanceKlass* holder, int holder_offset, DecoratorSet decorators, GrowableArray<ciType*>& visited) {\n+InlineTypeNode* InlineTypeNode::make_from_flat_impl(GraphKit* kit, ciInlineKlass* vk, Node* obj, Node* ptr, ciInstanceKlass* holder, int holder_offset,\n+                                                    bool atomic, int null_marker_offset, DecoratorSet decorators, GrowableArray<ciType*>& visited) {\n@@ -962,1 +1226,26 @@\n-  InlineTypeNode* vt = make_uninitialized(kit->gvn(), vk);\n+  bool null_free = (null_marker_offset == -1);\n+  InlineTypeNode* vt = make_uninitialized(kit->gvn(), vk, null_free);\n+\n+  if (atomic) {\n+    \/\/ Read atomically and convert from payload\n+#ifdef ASSERT\n+    bool is_naturally_atomic = vk->is_empty() || (null_free && vk->nof_declared_nonstatic_fields() == 1);\n+    assert(!is_naturally_atomic, \"No atomic access required\");\n+#endif\n+    BasicType bt = vk->payload_size_to_basic_type();\n+    decorators |= C2_MISMATCHED | C2_CONTROL_DEPENDENT_LOAD;\n+    Node* adr = kit->basic_plus_adr(obj, ptr, holder_offset);\n+    const Type* val_type = Type::get_const_basic_type(bt);\n+    bool is_array = (kit->gvn().type(obj)->isa_aryptr() != nullptr);\n+    Node* payload = kit->access_load_at(obj, adr, TypeRawPtr::BOTTOM, val_type, bt, is_array ? (decorators | IS_ARRAY) : decorators, kit->control());\n+    vt->convert_from_payload(kit, bt, payload, 0, null_free, null_marker_offset - holder_offset);\n+    return kit->gvn().transform(vt)->as_InlineType();\n+  }\n+\n+  if (!null_free) {\n+    \/\/ Nullable, read the null marker\n+    Node* adr = kit->basic_plus_adr(obj, ptr, null_marker_offset);\n+    Node* is_init = kit->make_load(kit->control(), adr, TypeInt::BOOL, T_BOOLEAN, MemNode::unordered);\n+    vt->set_req(IsInit, is_init);\n+  }\n+\n@@ -1124,0 +1413,4 @@\n+      if (!field_is_null_free(i)) {\n+        assert(field_null_marker_offset(i) != -1, \"inconsistency\");\n+        n->init_req(base_input++, arg->as_InlineType()->get_is_init());\n+      }\n@@ -1182,1 +1475,1 @@\n-      InlineTypeNode* vt = make_uninitialized(gvn, type->as_inline_klass());\n+      InlineTypeNode* vt = make_uninitialized(gvn, type->as_inline_klass(), field_is_null_free(i));\n@@ -1184,0 +1477,13 @@\n+      if (!field_is_null_free(i)) {\n+        assert(field_null_marker_offset(i) != -1, \"inconsistency\");\n+        Node* is_init = nullptr;\n+        if (multi->is_Start()) {\n+          is_init = gvn.transform(new ParmNode(multi->as_Start(), base_input));\n+        } else if (in) {\n+          is_init = multi->as_Call()->in(base_input);\n+        } else {\n+          is_init = gvn.transform(new ProjNode(multi->as_Call(), base_input));\n+        }\n+        vt->set_req(IsInit, is_init);\n+        base_input++;\n+      }\n","filename":"src\/hotspot\/share\/opto\/inlinetypenode.cpp","additions":365,"deletions":59,"binary":false,"changes":424,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2016, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -66,0 +66,1 @@\n+  uint add_fields_to_safepoint(Unique_Node_List& worklist, Node_List& null_markers, SafePointNode* sfpt);\n@@ -86,1 +87,4 @@\n-  static InlineTypeNode* make_from_flat_impl(GraphKit* kit, ciInlineKlass* vk, Node* obj, Node* ptr, ciInstanceKlass* holder, int holder_offset, DecoratorSet decorators, GrowableArray<ciType*>& visited);\n+  static InlineTypeNode* make_from_flat_impl(GraphKit* kit, ciInlineKlass* vk, Node* obj, Node* ptr, ciInstanceKlass* holder, int holder_offset, bool atomic, int null_marker_offset, DecoratorSet decorators, GrowableArray<ciType*>& visited);\n+\n+  void convert_from_payload(GraphKit* kit, BasicType bt, Node* payload, int holder_offset, bool null_free, int null_marker_offset);\n+  Node* convert_to_payload(GraphKit* kit, BasicType bt, Node* payload, int holder_offset, bool null_free, int null_marker_offset, int& oop_off_1, int& oop_off_2) const;\n@@ -96,1 +100,2 @@\n-  static InlineTypeNode* make_from_flat(GraphKit* kit, ciInlineKlass* vk, Node* obj, Node* ptr, ciInstanceKlass* holder = nullptr, int holder_offset = 0, DecoratorSet decorators = IN_HEAP | MO_UNORDERED);\n+  static InlineTypeNode* make_from_flat(GraphKit* kit, ciInlineKlass* vk, Node* obj, Node* ptr, ciInstanceKlass* holder = nullptr, int holder_offset = 0,\n+                                        bool atomic = false, int null_marker_offset = -1, DecoratorSet decorators = IN_HEAP | MO_UNORDERED);\n@@ -125,1 +130,2 @@\n-  Node*         field_value_by_offset(int offset, bool recursive = false) const;\n+  Node*         field_value_by_offset(int offset, bool recursive = false, bool search_null_marker = true) const;\n+  Node*         null_marker_by_offset(int offset, int holder_offset = 0) const;\n@@ -133,0 +139,2 @@\n+  bool          field_is_volatile(uint index) const;\n+  int           field_null_marker_offset(uint index) const;\n@@ -138,1 +146,1 @@\n-  void store_flat(GraphKit* kit, Node* base, Node* ptr, ciInstanceKlass* holder, int holder_offset, DecoratorSet decorators) const;\n+  void store_flat(GraphKit* kit, Node* base, Node* ptr, ciInstanceKlass* holder, int holder_offset, bool atomic, int null_marker_offset, DecoratorSet decorators) const;\n@@ -151,0 +159,1 @@\n+  void replace_field_projs(Compile* C, CallNode* call, uint& proj_idx);\n","filename":"src\/hotspot\/share\/opto\/inlinetypenode.hpp","additions":14,"deletions":5,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -198,0 +198,1 @@\n+    case Op_StoreLSpecial:\n@@ -754,0 +755,1 @@\n+        case Op_StoreLSpecial:\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2598,1 +2598,1 @@\n-          p = InlineTypeNode::make_from_flat(this, inline_klass, base, base, holder, offset, decorators);\n+          p = InlineTypeNode::make_from_flat(this, inline_klass, base, base, holder, offset, false, -1, decorators);\n@@ -2600,1 +2600,1 @@\n-          p = InlineTypeNode::make_from_flat(this, inline_klass, base, adr, nullptr, 0, decorators);\n+          p = InlineTypeNode::make_from_flat(this, inline_klass, base, adr, nullptr, 0, false, -1, decorators);\n@@ -2651,1 +2651,1 @@\n-        val->as_InlineType()->store_flat(this, base, base, holder, offset, decorators);\n+        val->as_InlineType()->store_flat(this, base, base, holder, offset, false, -1, decorators);\n@@ -2653,1 +2653,1 @@\n-        val->as_InlineType()->store_flat(this, base, adr, nullptr, 0, decorators);\n+        val->as_InlineType()->store_flat(this, base, adr, nullptr, 0, false, -1, decorators);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -499,0 +499,5 @@\n+  \/\/ Never rematerialize CastI2N because it might \"hide\" narrow oops from a safepoint\n+  if (ideal_Opcode() == Op_CastI2N) {\n+    return false;\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/machnode.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -570,1 +570,1 @@\n-\/\/ Search the last value stored into the inline type's fields.\n+\/\/ Search the last value stored into the inline type's fields (for flat arrays).\n@@ -582,0 +582,5 @@\n+      \/\/ TODO 8341767 Fix this\n+      \/\/ assert(vt->field_is_null_free(i), \"Unexpected nullable flat field\");\n+      if (!vt->field_is_null_free(i)) {\n+        return nullptr;\n+      }\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2609,0 +2609,8 @@\n+    case Op_StoreLSpecial: {\n+      if (n->req() > (MemNode::ValueIn + 1) && n->in(MemNode::ValueIn + 1) != nullptr) {\n+        Node* pair = new BinaryNode(n->in(MemNode::ValueIn), n->in(MemNode::ValueIn + 1));\n+        n->set_req(MemNode::ValueIn, pair);\n+        n->del_req(MemNode::ValueIn + 1);\n+      }\n+      break;\n+    }\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1292,1 +1292,1 @@\n-  if (base != nullptr && base->is_InlineType() && offset > oopDesc::klass_offset_in_bytes()) {\n+  if (!is_mismatched_access() && base != nullptr && base->is_InlineType() && offset > oopDesc::klass_offset_in_bytes()) {\n@@ -1897,0 +1897,1 @@\n+        && !(phase->type(address)->is_inlinetypeptr() && is_mismatched_access())\n@@ -3378,0 +3379,1 @@\n+             (st->adr_type()->isa_aryptr() && st->adr_type()->is_aryptr()->is_flat()) || \/\/ TODO 8343835\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -715,0 +715,19 @@\n+\/\/ Special StoreL for flat stores that emits GC barriers for field at 'oop_off' in the backend\n+class StoreLSpecialNode : public StoreNode {\n+\n+public:\n+  StoreLSpecialNode(Node* c, Node* mem, Node* adr, const TypePtr* at, Node* val, Node* oop_off, MemOrd mo)\n+    : StoreNode(c, mem, adr, at, val, mo) {\n+    set_mismatched_access();\n+    if (oop_off != nullptr) {\n+      add_req(oop_off);\n+    }\n+  }\n+  virtual int Opcode() const;\n+  virtual BasicType memory_type() const { return T_LONG; }\n+\n+  virtual uint match_edge(uint idx) const { return idx == MemNode::Address ||\n+                                                   idx == MemNode::ValueIn ||\n+                                                   idx == MemNode::ValueIn + 1; }\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/memnode.hpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -262,1 +262,1 @@\n-        stored_value_casted->as_InlineType()->store_flat(this, array, adr, nullptr, 0, MO_UNORDERED | IN_HEAP | IS_ARRAY);\n+        stored_value_casted->as_InlineType()->store_flat(this, array, adr, nullptr, 0, false, -1, MO_UNORDERED | IN_HEAP | IS_ARRAY);\n@@ -328,1 +328,1 @@\n-            null_checked_stored_value_casted->as_InlineType()->store_flat(this, casted_array, casted_adr, nullptr, 0, MO_UNORDERED | IN_HEAP | IS_ARRAY);\n+            null_checked_stored_value_casted->as_InlineType()->store_flat(this, casted_array, casted_adr, nullptr, 0, false, -1, MO_UNORDERED | IN_HEAP | IS_ARRAY);\n","filename":"src\/hotspot\/share\/opto\/parse2.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -154,1 +154,4 @@\n-    ld = InlineTypeNode::make_from_flat(this, field_klass->as_inline_klass(), obj, obj, field->holder(), offset);\n+    ciInlineKlass* vk = field->type()->as_inline_klass();\n+    bool is_naturally_atomic = vk->is_empty() || (field->is_null_free() && vk->nof_declared_nonstatic_fields() == 1);\n+    bool needs_atomic_access = (!field->is_null_free() || field->is_volatile()) && !is_naturally_atomic;\n+    ld = InlineTypeNode::make_from_flat(this, field_klass->as_inline_klass(), obj, obj, field->holder(), offset, needs_atomic_access, field->null_marker_offset());\n@@ -270,0 +273,1 @@\n+    ciInlineKlass* vk = field->type()->as_inline_klass();\n@@ -271,1 +275,1 @@\n-      val = InlineTypeNode::make_from_oop(this, val, field->type()->as_inline_klass());\n+      val = InlineTypeNode::make_from_oop(this, val, vk, field->is_null_free());\n@@ -274,1 +278,3 @@\n-    val->as_InlineType()->store_flat(this, obj, obj, field->holder(), offset, IN_HEAP | MO_UNORDERED);\n+    bool is_naturally_atomic = vk->is_empty() || (field->is_null_free() && vk->nof_declared_nonstatic_fields() == 1);\n+    bool needs_atomic_access = (!field->is_null_free() || field->is_volatile()) && !is_naturally_atomic;\n+    val->as_InlineType()->store_flat(this, obj, obj, field->holder(), offset, needs_atomic_access, field->null_marker_offset(), IN_HEAP | MO_UNORDERED);\n","filename":"src\/hotspot\/share\/opto\/parse3.cpp","additions":9,"deletions":3,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2197,7 +2197,16 @@\n-  for (int j = 0; j < vk->nof_nonstatic_fields(); j++) {\n-    ciField* field = vk->nonstatic_field_at(j);\n-    BasicType bt = field->type()->basic_type();\n-    const Type* ft = Type::get_const_type(field->type());\n-    field_array[pos++] = ft;\n-    if (type2size[bt] == 2) {\n-      field_array[pos++] = Type::HALF;\n+  for (int i = 0; i < vk->nof_declared_nonstatic_fields(); i++) {\n+    ciField* field = vk->declared_nonstatic_field_at(i);\n+    if (field->is_flat()) {\n+      collect_inline_fields(field->type()->as_inline_klass(), field_array, pos);\n+      if (!field->is_null_free()) {\n+        \/\/ Use T_INT instead of T_BOOLEAN here because the upper bits can contain garbage if the holder\n+        \/\/ is null and C2 will only zero them for T_INT assuming that T_BOOLEAN is already canonicalized.\n+        field_array[pos++] = Type::get_const_basic_type(T_INT);\n+      }\n+    } else {\n+      BasicType bt = field->type()->basic_type();\n+      const Type* ft = Type::get_const_type(field->type());\n+      field_array[pos++] = ft;\n+      if (type2size[bt] == 2) {\n+        field_array[pos++] = Type::HALF;\n+      }\n@@ -2235,0 +2244,1 @@\n+      assert(pos == (TypeFunc::Parms + arg_cnt), \"out of bounds\");\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":17,"deletions":7,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -1504,0 +1504,1 @@\n+  bool _is_null_free;\n@@ -1505,1 +1506,1 @@\n-  ReassignedField() : _offset(0), _type(T_ILLEGAL), _klass(nullptr), _is_flat(false) { }\n+  ReassignedField() : _offset(0), _type(T_ILLEGAL), _klass(nullptr), _is_flat(false), _is_null_free(false) { }\n@@ -1514,1 +1515,1 @@\n-static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal, int base_offset, TRAPS) {\n+static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal, int base_offset, GrowableArray<int>* null_marker_offsets, TRAPS) {\n@@ -1523,8 +1524,5 @@\n-        if (fs.is_null_free_inline_type()) {\n-          if (fs.is_flat()) {\n-            field._is_flat = true;\n-            \/\/ Resolve klass of flat inline type field\n-            field._klass = InlineKlass::cast(klass->get_inline_type_field_klass(fs.index()));\n-          } else {\n-            field._type = T_OBJECT;  \/\/ Can be removed once Q-descriptors have been removed.\n-          }\n+        if (fs.is_flat()) {\n+          field._is_flat = true;\n+          field._is_null_free = fs.is_null_free_inline_type();\n+          \/\/ Resolve klass of flat inline type field\n+          field._klass = InlineKlass::cast(klass->get_inline_type_field_klass(fs.index()));\n@@ -1538,0 +1536,6 @@\n+  \/\/ Keep track of null marker offset for flat fields\n+  bool set_null_markers = false;\n+  if (null_marker_offsets == nullptr) {\n+    set_null_markers = true;\n+    null_marker_offsets = new GrowableArray<int>();\n+  }\n@@ -1547,1 +1551,5 @@\n-      svIndex = reassign_fields_by_klass(vk, fr, reg_map, sv, svIndex, obj, skip_internal, offset, CHECK_0);\n+      svIndex = reassign_fields_by_klass(vk, fr, reg_map, sv, svIndex, obj, skip_internal, offset, null_marker_offsets, CHECK_0);\n+      if (!fields->at(i)._is_null_free) {\n+        int nm_offset = offset + InlineKlass::cast(vk)->null_marker_offset();\n+        null_marker_offsets->append(nm_offset);\n+      }\n@@ -1625,0 +1633,8 @@\n+  if (set_null_markers) {\n+    \/\/ The null marker values come after all the field values in the debug info\n+    for (int i = 0; i < null_marker_offsets->length(); ++i) {\n+      int offset = null_marker_offsets->at(i);\n+      jbyte is_init = (jbyte)StackValue::create_stack_value(fr, reg_map, sv->field_at(svIndex++))->get_jint();\n+      obj->byte_field_put(offset, is_init);\n+    }\n+  }\n@@ -1638,1 +1654,1 @@\n-    reassign_fields_by_klass(vk, fr, reg_map, val->as_ObjectValue(), 0, (oop)obj, skip_internal, offset, CHECK);\n+    reassign_fields_by_klass(vk, fr, reg_map, val->as_ObjectValue(), 0, (oop)obj, skip_internal, offset, nullptr, CHECK);\n@@ -1687,1 +1703,1 @@\n-      reassign_fields_by_klass(ik, fr, reg_map, sv, 0, obj(), skip_internal, 0, CHECK);\n+      reassign_fields_by_klass(ik, fr, reg_map, sv, 0, obj(), skip_internal, 0, nullptr, CHECK);\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":29,"deletions":13,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -165,1 +165,0 @@\n-        \/\/ Print fields of flat fields (recursively)\n@@ -167,0 +166,12 @@\n+        st->print(\"Flat inline type field '%s':\", vk->name()->as_C_string());\n+        if (!is_null_free_inline_type()) {\n+          assert(has_null_marker(), \"should have null marker\");\n+          InlineLayoutInfo* li = field_holder()->inline_layout_info_adr(index());\n+          int nm_offset = li->null_marker_offset();\n+          if (obj->byte_field_acquire(nm_offset) == 0) {\n+            st->print(\" null\");\n+            return;\n+          }\n+        }\n+        st->cr();\n+        \/\/ Print fields of flat field (recursively)\n@@ -169,1 +180,0 @@\n-        st->print_cr(\"Flat inline type field:\");\n","filename":"src\/hotspot\/share\/runtime\/fieldDescriptor.cpp","additions":12,"deletions":2,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2591,1 +2591,1 @@\n-    SigEntry::add_entry(obj_args.sig(), T_OBJECT, nullptr);\n+    SigEntry::add_entry(obj_args.sig(), T_OBJECT);\n@@ -2596,1 +2596,1 @@\n-    SigEntry::add_entry(int_args.sig(), T_INT, nullptr);\n+    SigEntry::add_entry(int_args.sig(), T_INT);\n@@ -2601,2 +2601,2 @@\n-    SigEntry::add_entry(obj_int_args.sig(), T_OBJECT, nullptr);\n-    SigEntry::add_entry(obj_int_args.sig(), T_INT, nullptr);\n+    SigEntry::add_entry(obj_int_args.sig(), T_OBJECT);\n+    SigEntry::add_entry(obj_int_args.sig(), T_INT);\n@@ -2607,2 +2607,2 @@\n-    SigEntry::add_entry(obj_obj_args.sig(), T_OBJECT, nullptr);\n-    SigEntry::add_entry(obj_obj_args.sig(), T_OBJECT, nullptr);\n+    SigEntry::add_entry(obj_obj_args.sig(), T_OBJECT);\n+    SigEntry::add_entry(obj_obj_args.sig(), T_OBJECT);\n@@ -2871,2 +2871,3 @@\n-              _sig_cc->insert_before(last+1, SigEntry(T_BOOLEAN, -1, nullptr));\n-              _sig_cc_ro->insert_before(last_ro+1, SigEntry(T_BOOLEAN, -1, nullptr));\n+              \/\/ Set the sort_offset so that the field is detected as null marker by nmethod::print_nmethod_labels.\n+              _sig_cc->insert_before(last+1, SigEntry(T_BOOLEAN, -1, 0));\n+              _sig_cc_ro->insert_before(last_ro+1, SigEntry(T_BOOLEAN, -1, 0));\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":9,"deletions":8,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -690,2 +690,5 @@\n-void SigEntry::add_entry(GrowableArray<SigEntry>* sig, BasicType bt, Symbol* symbol, int offset) {\n-  sig->append(SigEntry(bt, offset, symbol));\n+void SigEntry::add_entry(GrowableArray<SigEntry>* sig, BasicType bt, Symbol* symbol, int offset, float sort_offset) {\n+  if (sort_offset == -1) {\n+    sort_offset = offset;\n+  }\n+  sig->append(SigEntry(bt, offset, sort_offset, symbol));\n@@ -693,1 +696,1 @@\n-    sig->append(SigEntry(T_VOID, offset, symbol)); \/\/ Longs and doubles take two stack slots\n+    sig->append(SigEntry(T_VOID, offset, sort_offset, symbol)); \/\/ Longs and doubles take two stack slots\n","filename":"src\/hotspot\/share\/runtime\/signature.cpp","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -580,3 +580,4 @@\n-  BasicType _bt;\n-  int _offset;\n-  Symbol* _symbol;\n+  BasicType _bt;      \/\/ Basic type of the argument\n+  int _offset;        \/\/ Offset of the field in its value class holder for scalarized arguments (-1 otherwise). Used for packing and unpacking.\n+  float _sort_offset; \/\/ Offset used for sorting\n+  Symbol* _symbol;    \/\/ Symbol for printing\n@@ -585,1 +586,1 @@\n-    : _bt(T_ILLEGAL), _offset(-1), _symbol(NULL) {}\n+    : _bt(T_ILLEGAL), _offset(-1), _sort_offset(-1), _symbol(NULL) {}\n@@ -587,2 +588,2 @@\n-  SigEntry(BasicType bt, int offset, Symbol* symbol)\n-    : _bt(bt), _offset(offset), _symbol(symbol) {}\n+  SigEntry(BasicType bt, int offset = -1, float sort_offset = -1, Symbol* symbol = nullptr)\n+    : _bt(bt), _offset(offset), _sort_offset(sort_offset), _symbol(symbol) {}\n@@ -591,0 +592,3 @@\n+    if (e1->_sort_offset != e2->_sort_offset) {\n+      return e1->_sort_offset - e2->_sort_offset;\n+    }\n@@ -612,1 +616,1 @@\n-  static void add_entry(GrowableArray<SigEntry>* sig, BasicType bt, Symbol* symbol, int offset = -1);\n+  static void add_entry(GrowableArray<SigEntry>* sig, BasicType bt, Symbol* symbol = nullptr, int offset = -1, float sort_offset = -1);\n","filename":"src\/hotspot\/share\/runtime\/signature.hpp","additions":11,"deletions":7,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -78,1 +78,3 @@\n-compiler\/c2\/irTests\/scalarReplacement\/ScalarReplacementWithGCBarrierTests.java  8342488 generic-all\n+compiler\/c2\/irTests\/scalarReplacement\/ScalarReplacementWithGCBarrierTests.java 8342488 generic-all\n+compiler\/c2\/TestMergeStores.java#id1 8348959 generic-all\n+\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -164,1 +164,1 @@\n-                arrays[i] = new int[1024];\n+                arrays[j] = new int[1024];\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestArrayCopyWithOops.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -63,0 +63,17 @@\n+ *\n+ * @run main\/othervm -XX:+NullableFieldFlattening\n+ *                   -XX:+UnlockDiagnosticVMOptions -XX:+StressGCM -XX:+StressLCM\n+ *                   compiler.valhalla.inlinetypes.TestBufferTearing\n+ * @run main\/othervm -XX:+NullableFieldFlattening\n+ *                   -XX:+UnlockDiagnosticVMOptions -XX:+StressGCM -XX:+StressLCM\n+ *                   -XX:+IgnoreUnrecognizedVMOptions -XX:+AlwaysIncrementalInline\n+ *                   compiler.valhalla.inlinetypes.TestBufferTearing\n+ * @run main\/othervm -XX:+NullableFieldFlattening\n+ *                   -XX:CompileCommand=dontinline,*::incrementAndCheck*\n+ *                   -XX:+UnlockDiagnosticVMOptions -XX:+StressGCM -XX:+StressLCM\n+ *                   compiler.valhalla.inlinetypes.TestBufferTearing\n+ * @run main\/othervm -XX:+NullableFieldFlattening\n+ *                   -XX:CompileCommand=dontinline,*::incrementAndCheck*\n+ *                   -XX:+UnlockDiagnosticVMOptions -XX:+StressGCM -XX:+StressLCM\n+ *                   -XX:+IgnoreUnrecognizedVMOptions -XX:+AlwaysIncrementalInline\n+ *                   compiler.valhalla.inlinetypes.TestBufferTearing\n@@ -68,2 +85,3 @@\n-    int x;\n-    int y;\n+    \/\/ Make sure the payload size is <= 64-bit to enable flattening\n+    short x;\n+    short y;\n@@ -85,1 +103,1 @@\n-    MyValue(int x, int y) {\n+    MyValue(short x, short y) {\n@@ -92,1 +110,1 @@\n-        return new MyValue(x + 1, y + 1);\n+        return new MyValue((short)(x + 1), (short)(y + 1));\n@@ -98,2 +116,2 @@\n-        U.putInt(vt, X_OFFSET, x + 1);\n-        U.putInt(vt, Y_OFFSET, y + 1);\n+        U.putShort(vt, X_OFFSET, (short)(x + 1));\n+        U.putShort(vt, Y_OFFSET, (short)(y + 1));\n@@ -105,0 +123,1 @@\n+    \/\/ Null-free, volatile -> atomic access\n@@ -106,1 +125,1 @@\n-    static MyValue vtField1;\n+    volatile static MyValue field1;\n@@ -108,2 +127,8 @@\n-    MyValue vtField2;\n-    MyValue[] vtField3 = (MyValue[])ValueClass.newNullRestrictedArray(MyValue.class, 1);\n+    volatile MyValue field2;\n+\n+    \/\/ Nullable fields are always atomic\n+    static MyValue field3 = new MyValue((short)0, (short)0);\n+    MyValue field4 = new MyValue((short)0, (short)0);\n+\n+    MyValue[] array1 = (MyValue[])ValueClass.newNullRestrictedArray(MyValue.class, 1);\n+    MyValue[] array2 = new MyValue[] { new MyValue((short)0, (short)0) };\n@@ -133,1 +158,0 @@\n-        \/\/ TODO: Fix commented out tests which fail after JDK-8345995\n@@ -136,8 +160,14 @@\n-                test.vtField1 = test.vtField1.incrementAndCheck();\n-\/\/                test.vtField2 = test.vtField2.incrementAndCheck();\n-                test.vtField3[0] = test.vtField3[0].incrementAndCheck();\n-\n-                test.vtField1 = test.vtField1.incrementAndCheckUnsafe();\n-\/\/                test.vtField2 = test.vtField2.incrementAndCheckUnsafe();\n-                test.vtField3[0] = test.vtField3[0].incrementAndCheckUnsafe();\n-\n+                test.field1 = test.field1.incrementAndCheck();\n+                test.field2 = test.field2.incrementAndCheck();\n+                test.field3 = test.field3.incrementAndCheck();\n+                test.field4 = test.field4.incrementAndCheck();\n+                \/\/ TODO 8341767 Re-enable once we support flat array element accesses\n+                \/\/test.array1[0] = test.array1[0].incrementAndCheck();\n+                \/\/test.array2[0] = test.array2[0].incrementAndCheck();\n+\n+                test.field1 = test.field1.incrementAndCheckUnsafe();\n+                test.field2 = test.field2.incrementAndCheckUnsafe();\n+                test.field3 = test.field3.incrementAndCheckUnsafe();\n+                test.field4 = test.field4.incrementAndCheckUnsafe();\n+                \/\/test.array1[0] = test.array1[0].incrementAndCheckUnsafe();\n+                \/\/test.array2[0] = test.array2[0].incrementAndCheckUnsafe();\n@@ -145,3 +175,6 @@\n-                    test.vtField1 = (MyValue)incrementAndCheck_mh.invokeExact(test.vtField1);\n-\/\/                    test.vtField2 = (MyValue)incrementAndCheck_mh.invokeExact(test.vtField2);\n-                    test.vtField3[0] = (MyValue)incrementAndCheck_mh.invokeExact(test.vtField3[0]);\n+                    test.field1 = (MyValue)incrementAndCheck_mh.invokeExact(test.field1);\n+                    test.field2 = (MyValue)incrementAndCheck_mh.invokeExact(test.field2);\n+                    test.field3 = (MyValue)incrementAndCheck_mh.invokeExact(test.field1);\n+                    test.field4 = (MyValue)incrementAndCheck_mh.invokeExact(test.field2);\n+                    \/\/test.array1[0] = (MyValue)incrementAndCheck_mh.invokeExact(test.array1[0]);\n+                    \/\/test.array2[0] = (MyValue)incrementAndCheck_mh.invokeExact(test.array2[0]);\n@@ -149,1 +182,1 @@\n-                    throw new RuntimeException(\"Invoke failed\", t);\n+                    throw new RuntimeException(\"Test failed\", t);\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestBufferTearing.java","additions":55,"deletions":22,"binary":false,"changes":77,"status":"modified"},{"patch":"@@ -0,0 +1,998 @@\n+\/*\n+ * Copyright (c) 2024, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import jdk.internal.value.ValueClass;\n+import jdk.internal.vm.annotation.ImplicitlyConstructible;\n+import jdk.internal.vm.annotation.LooselyConsistentValue;\n+import jdk.internal.vm.annotation.NullRestricted;\n+\n+import jdk.test.lib.Asserts;\n+\n+\/*\n+ * @test\n+ * @key randomness\n+ * @summary Test support for null markers in flat fields.\n+ * @library \/test\/lib \/\n+ * @requires (os.simpleArch == \"x64\" | os.simpleArch == \"aarch64\")\n+ * @enablePreview\n+ * @modules java.base\/jdk.internal.value\n+ *          java.base\/jdk.internal.vm.annotation\n+ * @run main\/othervm compiler.valhalla.inlinetypes.TestFieldNullMarkers\n+ * @run main\/othervm -Xbatch -XX:+NullableFieldFlattening -XX:+AtomicFieldFlattening\n+ *                   compiler.valhalla.inlinetypes.TestFieldNullMarkers\n+ * @run main\/othervm -Xbatch -XX:+NullableFieldFlattening -XX:+AtomicFieldFlattening\n+ *                   -XX:CompileCommand=dontinline,*::testHelper*\n+ *                   compiler.valhalla.inlinetypes.TestFieldNullMarkers\n+ * @run main\/othervm -Xbatch -XX:+NullableFieldFlattening -XX:+AtomicFieldFlattening\n+ *                   -XX:+InlineTypeReturnedAsFields -XX:+InlineTypePassFieldsAsArgs\n+ *                   compiler.valhalla.inlinetypes.TestFieldNullMarkers\n+ * @run main\/othervm -Xbatch -XX:+NullableFieldFlattening -XX:+AtomicFieldFlattening\n+ *                   -XX:-InlineTypeReturnedAsFields -XX:-InlineTypePassFieldsAsArgs\n+ *                   compiler.valhalla.inlinetypes.TestFieldNullMarkers\n+ * @run main\/othervm -Xbatch -XX:+NullableFieldFlattening -XX:+AtomicFieldFlattening\n+ *                   -XX:+InlineTypeReturnedAsFields -XX:-InlineTypePassFieldsAsArgs\n+ *                   compiler.valhalla.inlinetypes.TestFieldNullMarkers\n+ * @run main\/othervm -Xbatch -XX:+NullableFieldFlattening -XX:+AtomicFieldFlattening\n+ *                   -XX:-InlineTypeReturnedAsFields -XX:+InlineTypePassFieldsAsArgs\n+ *                   compiler.valhalla.inlinetypes.TestFieldNullMarkers\n+ *\/\n+\n+public class TestFieldNullMarkers {\n+\n+    \/\/ Value class with two nullable flat fields\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue1 {\n+        byte x;\n+        MyValue2 val1;\n+        MyValue2 val2;\n+\n+        public MyValue1(byte x, MyValue2 val1, MyValue2 val2) {\n+            this.x = x;\n+            this.val1 = val1;\n+            this.val2 = val2;\n+        }\n+\n+        public String toString() {\n+            return \"x = \" + x + \", val1 = [\" + val1 + \"], val2 = [\" + val2 + \"]\";\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static abstract value class MyAbstract1 {\n+        byte x;\n+\n+        public MyAbstract1(byte x) {\n+            this.x = x;\n+        }\n+    }\n+\n+    \/\/ Empty value class inheriting single field from abstract super class\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue2 extends MyAbstract1 {\n+        public MyValue2(byte x) {\n+            super(x);\n+        }\n+\n+        public String toString() {\n+            return \"x = \" + x;\n+        }\n+    }\n+\n+    \/\/ Value class with a hole in the payload that will be used for the null marker\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue3 {\n+        byte x;\n+        \/\/ Hole that will be used by the null marker\n+        int i;\n+\n+        public MyValue3(byte x) {\n+            this.x = x;\n+            this.i = x;\n+        }\n+\n+        public String toString() {\n+            return \"x = \" + x + \", i = \" + i;\n+        }\n+    }\n+\n+    \/\/ Value class with two nullable flat fields that have their null markers *not* at the end of the payload\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue4 {\n+        MyValue3 val1;\n+        MyValue3 val2;\n+\n+        public MyValue4(MyValue3 val1, MyValue3 val2) {\n+            this.val1 = val1;\n+            this.val2 = val2;\n+        }\n+\n+        public String toString() {\n+            return \"val1 = [\" + val1 + \"], val2 = [\" + val2 + \"]\";\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue5_3 {\n+        byte x;\n+\n+        public MyValue5_3(byte x) {\n+            this.x = x;\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue5_2 {\n+        byte x;\n+        MyValue5_3 val;\n+\n+        public MyValue5_2(byte x, MyValue5_3 val) {\n+            this.x = x;\n+            this.val = val;\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue5_1 {\n+        byte x;\n+        MyValue5_2 val;\n+\n+        public MyValue5_1(byte x, MyValue5_2 val) {\n+            this.x = x;\n+            this.val = val;\n+        }\n+    }\n+\n+    \/\/ Value class with deep nesting of nullable flat fields\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue5 {\n+        byte x;\n+        MyValue5_1 val;\n+\n+        public MyValue5(byte x, MyValue5_1 val) {\n+            this.x = x;\n+            this.val = val;\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValueEmpty {\n+\n+    }\n+\n+    \/\/ Value class with flat field of empty value class\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue6 {\n+        MyValueEmpty val;\n+\n+        public MyValue6(MyValueEmpty val) {\n+            this.val = val;\n+        }\n+    }\n+\n+    \/\/ Same as MyValue6 but one more level of nested flat fields\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue7 {\n+        MyValue6 val;\n+\n+        public MyValue7(MyValue6 val) {\n+            this.val = val;\n+        }\n+    }\n+\n+    \/\/ Some more field types\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue8 {\n+        byte b;\n+\n+        public MyValue8(byte b) {\n+            this.b = b;\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue9 {\n+        short s;\n+\n+        public MyValue9(short s) {\n+            this.s = s;\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue10 {\n+        int i;\n+\n+        public MyValue10(int i) {\n+            this.i = i;\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue11 {\n+        float f;\n+\n+        public MyValue11(float f) {\n+            this.f = f;\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue12 {\n+        char c;\n+\n+        public MyValue12(char c) {\n+            this.c = c;\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue13 {\n+        boolean b;\n+\n+        public MyValue13(boolean b) {\n+            this.b = b;\n+        }\n+    }\n+\n+    \/\/ Test value class with nullable and null-free fields\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue14 {\n+        @NullRestricted\n+        MyValue8 nullfree;\n+        MyValue8 nullable;\n+\n+        public MyValue14(MyValue8 nullfree, MyValue8 nullable) {\n+            this.nullfree = nullfree;\n+            this.nullable = nullable;\n+        }\n+    }\n+\n+    static class MyClass {\n+        int x;\n+\n+        public MyClass(int x) {\n+            this.x = x;\n+        }\n+    }\n+\n+    \/\/ Value class with oop field\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue15 {\n+        MyClass obj;\n+\n+        public MyValue15(MyClass obj) {\n+            this.obj = obj;\n+        }\n+    }\n+\n+    \/\/ Value class with two oop fields\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue16 {\n+        MyClass obj1;\n+        MyClass obj2;\n+\n+        public MyValue16(MyClass obj1, MyClass obj2) {\n+            this.obj1 = obj1;\n+            this.obj2 = obj2;\n+        }\n+    }\n+\n+    \/\/ Value class with oop field and primitive fields\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyValue17 {\n+        byte b1;\n+        MyClass obj;\n+        byte b2;\n+\n+        public MyValue17(MyClass obj, byte b1, byte b2) {\n+            this.obj = obj;\n+            this.b1 = b1;\n+            this.b2 = b2;\n+        }\n+    }\n+\n+    MyValue1 field1; \/\/ Not flat\n+    MyValue4 field2; \/\/ Not flat\n+    MyValue5 field3; \/\/ Flat\n+    MyValue6 field4; \/\/ Flat\n+    MyValue7 field5; \/\/ Flat\n+    MyValue8 field6; \/\/ Flat\n+    MyValue9 field7; \/\/ Flat\n+    MyValue10 field8; \/\/ Flat\n+    MyValue11 field9; \/\/ Flat\n+    MyValue12 field10; \/\/ Flat\n+    MyValue13 field11; \/\/ Flat\n+\n+    @NullRestricted\n+    volatile MyValue8 field12;\n+\n+    @NullRestricted\n+    MyValue14 field13;          \/\/ Null-free, flat\n+    volatile MyValue14 field14; \/\/ Nullable, atomic, flat\n+    MyValue14 field15;          \/\/ Nullable, (atomic), flat\n+    @NullRestricted\n+    volatile MyValue14 field16; \/\/ Null-free, atomic, flat\n+\n+    @NullRestricted\n+    volatile MyValue15 field17;\n+    MyValue15 field18;\n+    @NullRestricted\n+    volatile MyValue16 field19;\n+    @NullRestricted\n+    volatile MyValue17 field20;\n+    MyValue17 field21;\n+\n+    static final MyValue1 VAL1 = new MyValue1((byte)42, new MyValue2((byte)43), null);\n+    static final MyValue4 VAL4 = new MyValue4(new MyValue3((byte)42), null);\n+    static final MyValue5 VAL5 = new MyValue5((byte)42, new MyValue5_1((byte)43, new MyValue5_2((byte)44, new MyValue5_3((byte)45))));\n+    static final MyValue6 VAL6 = new MyValue6(new MyValueEmpty());\n+    static final MyValue7 VAL7 = new MyValue7(new MyValue6(new MyValueEmpty()));\n+\n+    \/\/ Test that the calling convention is keeping track of the null marker\n+    public MyValue1 testHelper1(MyValue1 val) {\n+        return val;\n+    }\n+\n+    public void testSet1(MyValue1 val) {\n+        field1 = testHelper1(val);\n+    }\n+\n+    public MyValue1 testGet1() {\n+        return field1;\n+    }\n+\n+    public void testDeopt1(byte x, MyValue1 neverNull, MyValue1 alwaysNull, boolean deopt) {\n+        MyValue2 val2 = new MyValue2(x);\n+        MyValue1 val1 = new MyValue1(x, val2, val2);\n+        if (deopt) {\n+            Asserts.assertEQ(val1.x, x);\n+            Asserts.assertEQ(val1.val1, val2);\n+            Asserts.assertEQ(val1.val2, val2);\n+            Asserts.assertEQ(neverNull.x, x);\n+            Asserts.assertEQ(neverNull.val1, val2);\n+            Asserts.assertEQ(neverNull.val2, val2);\n+            Asserts.assertEQ(alwaysNull.x, x);\n+            Asserts.assertEQ(alwaysNull.val1, null);\n+            Asserts.assertEQ(alwaysNull.val2, null);\n+        }\n+    }\n+\n+    public void testOSR() {\n+        \/\/ Trigger OSR\n+        for (int i = 0; i < 100_000; ++i) {\n+            field1 = null;\n+            Asserts.assertEQ(field1, null);\n+            MyValue2 val2 = new MyValue2((byte)i);\n+            MyValue1 val = new MyValue1((byte)i, val2, null);\n+            field1 = val;\n+            Asserts.assertEQ(field1.x, (byte)i);\n+            Asserts.assertEQ(field1.val1, val2);\n+            Asserts.assertEQ(field1.val2, null);\n+        }\n+    }\n+\n+    public boolean testACmp(MyValue2 val2) {\n+        return field1.val1 == val2;\n+    }\n+\n+    \/\/ Test that the calling convention is keeping track of the null marker\n+    public MyValue4 testHelper2(MyValue4 val) {\n+        return val;\n+    }\n+\n+    public void testSet2(MyValue4 val) {\n+        field2 = testHelper2(val);\n+    }\n+\n+    public MyValue4 testGet2() {\n+        return field2;\n+    }\n+\n+    public void testDeopt2(byte x, MyValue4 neverNull, MyValue4 alwaysNull, boolean deopt) {\n+        MyValue3 val3 = new MyValue3(x);\n+        MyValue4 val4 = new MyValue4(val3, null);\n+        if (deopt) {\n+            Asserts.assertEQ(val4.val1, val3);\n+            Asserts.assertEQ(val4.val2, null);\n+            Asserts.assertEQ(neverNull.val1, val3);\n+            Asserts.assertEQ(neverNull.val2, val3);\n+            Asserts.assertEQ(alwaysNull.val1, null);\n+            Asserts.assertEQ(alwaysNull.val2, null);\n+        }\n+    }\n+\n+    \/\/ Test that the calling convention is keeping track of the null marker\n+    public MyValue5 testHelper3(MyValue5 val) {\n+        return val;\n+    }\n+\n+    public void testSet3(MyValue5 val) {\n+        field3 = testHelper3(val);\n+    }\n+\n+    public MyValue5 testGet3() {\n+        return field3;\n+    }\n+\n+    public void testDeopt3(byte x, MyValue5 val6, MyValue5 val7, MyValue5 val8, MyValue5 val9, boolean deopt) {\n+        MyValue5 val1 = new MyValue5(x, new MyValue5_1(x, new MyValue5_2(x, new MyValue5_3(x))));\n+        MyValue5 val2 = new MyValue5(x, new MyValue5_1(x, new MyValue5_2(x, null)));\n+        MyValue5 val3 = new MyValue5(x, new MyValue5_1(x, null));\n+        MyValue5 val4 = new MyValue5(x, null);\n+        MyValue5 val5 = null;\n+        if (deopt) {\n+            Asserts.assertEQ(val1.x, x);\n+            Asserts.assertEQ(val1.val.x, x);\n+            Asserts.assertEQ(val1.val.val.x, x);\n+            Asserts.assertEQ(val1.val.val.val.x, x);\n+            Asserts.assertEQ(val2.x, x);\n+            Asserts.assertEQ(val2.val.x, x);\n+            Asserts.assertEQ(val2.val.val.x, x);\n+            Asserts.assertEQ(val2.val.val.val, null);\n+            Asserts.assertEQ(val3.x, x);\n+            Asserts.assertEQ(val3.val.x, x);\n+            Asserts.assertEQ(val3.val.val, null);\n+            Asserts.assertEQ(val4.x, x);\n+            Asserts.assertEQ(val4.val, null);\n+            Asserts.assertEQ(val5, null);\n+\n+            Asserts.assertEQ(val6.x, x);\n+            Asserts.assertEQ(val6.val.x, x);\n+            Asserts.assertEQ(val6.val.val.x, x);\n+            Asserts.assertEQ(val6.val.val.val.x, x);\n+            Asserts.assertEQ(val7.x, x);\n+            Asserts.assertEQ(val7.val.x, x);\n+            Asserts.assertEQ(val7.val.val.x, x);\n+            Asserts.assertEQ(val7.val.val.val, null);\n+            Asserts.assertEQ(val8.x, x);\n+            Asserts.assertEQ(val8.val.x, x);\n+            Asserts.assertEQ(val8.val.val, null);\n+            Asserts.assertEQ(val9.x, x);\n+            Asserts.assertEQ(val9.val, null);\n+        }\n+    }\n+\n+    \/\/ Test that the calling convention is keeping track of the null marker\n+    public MyValue6 testHelper4(MyValue6 val) {\n+        return val;\n+    }\n+\n+    public void testSet4(MyValue6 val) {\n+        field4 = testHelper4(val);\n+    }\n+\n+    public MyValue6 testGet4() {\n+        return field4;\n+    }\n+\n+    public void testDeopt4(MyValue6 val4, MyValue6 val5, MyValue6 val6, boolean deopt) {\n+        MyValue6 val1 = new MyValue6(new MyValueEmpty());\n+        MyValue6 val2 = new MyValue6(null);\n+        MyValue6 val3 = null;\n+        if (deopt) {\n+            Asserts.assertEQ(val1.val, new MyValueEmpty());\n+            Asserts.assertEQ(val2.val, null);\n+            Asserts.assertEQ(val3, null);\n+\n+            Asserts.assertEQ(val4.val, new MyValueEmpty());\n+            Asserts.assertEQ(val5.val, null);\n+            Asserts.assertEQ(val6, null);\n+        }\n+    }\n+\n+    \/\/ Test that the calling convention is keeping track of the null marker\n+    public MyValue7 testHelper5(MyValue7 val) {\n+        return val;\n+    }\n+\n+    public void testSet5(MyValue7 val) {\n+        field5 = testHelper5(val);\n+    }\n+\n+    public MyValue7 testGet5() {\n+        return field5;\n+    }\n+\n+    public void testDeopt5(MyValue7 val5, MyValue7 val6, MyValue7 val7, MyValue7 val8, boolean deopt) {\n+        MyValue7 val1 = new MyValue7(new MyValue6(new MyValueEmpty()));\n+        MyValue7 val2 = new MyValue7(new MyValue6(null));\n+        MyValue7 val3 = new MyValue7(null);\n+        MyValue7 val4 = null;\n+        if (deopt) {\n+            Asserts.assertEQ(val1.val, new MyValue6(new MyValueEmpty()));\n+            Asserts.assertEQ(val2.val, new MyValue6(null));\n+            Asserts.assertEQ(val3.val, null);\n+            Asserts.assertEQ(val4, null);\n+\n+            Asserts.assertEQ(val5.val, new MyValue6(new MyValueEmpty()));\n+            Asserts.assertEQ(val6.val, new MyValue6(null));\n+            Asserts.assertEQ(val7.val, null);\n+            Asserts.assertEQ(val8, null);\n+        }\n+    }\n+\n+    @ImplicitlyConstructible\n+    @LooselyConsistentValue\n+    static value class MyHolderClass8 {\n+        MyValue8 val8;\n+\n+        public MyHolderClass8(MyValue8 val8) {\n+            this.val8 = val8;\n+        }\n+    }\n+\n+    \/\/ Test support for null markers in scalar replaced flat (null-free) array\n+    public static void testFlatArray1(boolean trap) {\n+        MyHolderClass8[] array = (MyHolderClass8[])ValueClass.newNullRestrictedArray(MyHolderClass8.class, 2);\n+        MyValue8 val8 = new MyValue8((byte)42);\n+        array[0] = new MyHolderClass8(val8);\n+        array[1] = new MyHolderClass8(null);\n+        if (trap) {\n+            Asserts.assertEQ(array[0].val8, val8);\n+            Asserts.assertEQ(array[1].val8, null);\n+        }\n+    }\n+\n+    \/\/ Make sure that flat field accesses contain a (implicit) null check\n+    public static void testNPE1() {\n+        TestFieldNullMarkers t = null;\n+        try {\n+            MyValue8 v = t.field6;\n+            throw new RuntimeException(\"No NPE thrown!\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    public static void testNPE2() {\n+        TestFieldNullMarkers t = null;\n+        try {\n+            t.field6 = null;\n+            throw new RuntimeException(\"No NPE thrown!\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    public void checkFields(int i) {\n+        Asserts.assertEQ(field6.b, (byte)i);\n+        Asserts.assertEQ(field7.s, (short)i);\n+        Asserts.assertEQ(field8.i, i);\n+        Asserts.assertEQ(field9.f, (float)i);\n+        Asserts.assertEQ(field10.c, (char)i);\n+        Asserts.assertEQ(field11.b, (i % 2) == 0);\n+    }\n+\n+    \/\/ Test that writing and reading a (signed) byte stays in bounds\n+    public void testBounds(int i) {\n+        MyValue8 val = new MyValue8((byte)i);\n+        field6 = val;\n+        int b = field6.b;\n+        if (b < -128 || b > 127) {\n+            throw new RuntimeException(\"Byte value out of bounds: \" + b);\n+        }\n+    }\n+\n+    static void produceGarbage() {\n+        for (int i = 0; i < 100; ++i) {\n+            Object[] arrays = new Object[1024];\n+            for (int j = 0; j < arrays.length; j++) {\n+                arrays[j] = new int[1024];\n+            }\n+        }\n+        System.gc();\n+    }\n+\n+    \/\/ Test that barriers are emitted when writing flat, atomic fields with oops\n+    public void testWriteOopFields1(MyValue15 val) {\n+        field17 = val;\n+        field18 = val;\n+    }\n+\n+    public void testWriteOopFields2(MyValue16 val) {\n+        field19 = val;\n+    }\n+\n+    public void testWriteOopFields3(MyValue17 val) {\n+        field20 = val;\n+        field21 = val;\n+    }\n+\n+    public static void main(String[] args) {\n+        TestFieldNullMarkers t = new TestFieldNullMarkers();\n+        t.testOSR();\n+\n+        final int LIMIT = 50_000;\n+        for (int i = -50_000; i < LIMIT; ++i) {\n+            t.field1 = null;\n+            Asserts.assertEQ(t.testGet1(), null);\n+\n+            boolean useNull = (i % 2) == 0;\n+            MyValue2 val2 = useNull ? null : new MyValue2((byte)i);\n+            MyValue1 val = new MyValue1((byte)i, val2, val2);\n+            t.field1 = val;\n+            Asserts.assertEQ(t.testGet1().x, val.x);\n+            Asserts.assertEQ(t.testGet1().val1, val2);\n+            Asserts.assertEQ(t.testGet1().val2, val2);\n+\n+            Asserts.assertTrue(t.testACmp(val2));\n+\n+            t.testSet1(null);\n+            Asserts.assertEQ(t.field1, null);\n+\n+            t.testSet1(val);\n+            Asserts.assertEQ(t.field1.x, val.x);\n+            Asserts.assertEQ(t.field1.val1, val2);\n+            Asserts.assertEQ(t.field1.val2, val2);\n+\n+            t.testDeopt1((byte)i, null, null, false);\n+\n+            t.field2 = null;\n+            Asserts.assertEQ(t.testGet2(), null);\n+\n+            MyValue3 val3 = useNull ? null : new MyValue3((byte)i);\n+            MyValue4 val4 = new MyValue4(val3, val3);\n+            t.field2 = val4;\n+            Asserts.assertEQ(t.testGet2().val1, val3);\n+            Asserts.assertEQ(t.testGet2().val2, val3);\n+\n+            t.testSet2(null);\n+            Asserts.assertEQ(t.testGet2(), null);\n+\n+            t.testSet2(val4);\n+            Asserts.assertEQ(t.testGet2().val1, val3);\n+            Asserts.assertEQ(t.testGet2().val2, val3);\n+\n+            t.testDeopt2((byte)i, null, null, false);\n+\n+            t.field3 = null;\n+            Asserts.assertEQ(t.testGet3(), null);\n+\n+            boolean useNull_1 = (i % 4) == 0;\n+            boolean useNull_2 = (i % 4) == 1;\n+            boolean useNull_3 = (i % 4) == 2;\n+            MyValue5_3 val5_3 = useNull_3 ? null : new MyValue5_3((byte)i);\n+            MyValue5_2 val5_2 = useNull_2 ? null : new MyValue5_2((byte)i, val5_3);\n+            MyValue5_1 val5_1 = useNull_1 ? null : new MyValue5_1((byte)i, val5_2);\n+            MyValue5 val5 = new MyValue5((byte)i, val5_1);\n+            t.field3 = val5;\n+            Asserts.assertEQ(t.testGet3().x, val5.x);\n+            if (useNull_1) {\n+                Asserts.assertEQ(t.testGet3().val, null);\n+            } else {\n+                Asserts.assertEQ(t.testGet3().val.x, val5_1.x);\n+                if (useNull_2) {\n+                    Asserts.assertEQ(t.testGet3().val.val, null);\n+                } else {\n+                    Asserts.assertEQ(t.testGet3().val.val.x, val5_2.x);\n+                    if (useNull_3) {\n+                        Asserts.assertEQ(t.testGet3().val.val.val, null);\n+                    } else {\n+                        Asserts.assertEQ(t.testGet3().val.val.val.x, val5_3.x);\n+                    }\n+                }\n+            }\n+\n+            t.testSet3(null);\n+            Asserts.assertEQ(t.field3, null);\n+\n+            t.testSet3(val5);\n+            Asserts.assertEQ(t.testGet3().x, val5.x);\n+            if (useNull_1) {\n+                Asserts.assertEQ(t.testGet3().val, null);\n+            } else {\n+                Asserts.assertEQ(t.testGet3().val.x, val5_1.x);\n+                if (useNull_2) {\n+                    Asserts.assertEQ(t.testGet3().val.val, null);\n+                } else {\n+                    Asserts.assertEQ(t.testGet3().val.val.x, val5_2.x);\n+                    if (useNull_3) {\n+                        Asserts.assertEQ(t.testGet3().val.val.val, null);\n+                    } else {\n+                        Asserts.assertEQ(t.testGet3().val.val.val.x, val5_3.x);\n+                    }\n+                }\n+            }\n+            t.testDeopt3((byte)i, null, null, null, null, false);\n+\n+            t.field4 = null;\n+            Asserts.assertEQ(t.testGet4(), null);\n+\n+            MyValueEmpty empty = useNull ? null : new MyValueEmpty();\n+            MyValue6 val6 = new MyValue6(empty);\n+            t.field4 = val6;\n+            Asserts.assertEQ(t.testGet4().val, empty);\n+\n+            t.testSet4(null);\n+            Asserts.assertEQ(t.testGet4(), null);\n+\n+            t.testSet4(val6);\n+            Asserts.assertEQ(t.testGet4().val, empty);\n+\n+            t.testDeopt4(null, null, null, false);\n+\n+            t.field5 = null;\n+            Asserts.assertEQ(t.testGet5(), null);\n+\n+            empty = ((i % 3) == 0) ? null : new MyValueEmpty();\n+            val6 = ((i % 3) == 1) ? null : new MyValue6(empty);\n+            MyValue7 val7 = new MyValue7(val6);\n+            t.field5 = val7;\n+            Asserts.assertEQ(t.testGet5().val, val6);\n+\n+            t.testSet5(null);\n+            Asserts.assertEQ(t.testGet5(), null);\n+\n+            t.testSet5(val7);\n+            Asserts.assertEQ(t.testGet5().val, val6);\n+\n+            t.testDeopt5(null, null, null, null, false);\n+\n+            \/\/ Check accesses with constant value\n+            t.field1 = VAL1;\n+            Asserts.assertEQ(t.field1.x, VAL1.x);\n+            Asserts.assertEQ(t.field1.val1, VAL1.val1);\n+            Asserts.assertEQ(t.field1.val2, VAL1.val2);\n+\n+            t.field2 = VAL4;\n+            Asserts.assertEQ(t.field2.val1, VAL4.val1);\n+            Asserts.assertEQ(t.field2.val2, VAL4.val2);\n+\n+            t.field3 = VAL5;\n+            Asserts.assertEQ(t.field3.x, VAL5.x);\n+            Asserts.assertEQ(t.field3.val.x, VAL5.val.x);\n+            Asserts.assertEQ(t.field3.val.val.x, VAL5.val.val.x);\n+            Asserts.assertEQ(t.field3.val.val.val.x, VAL5.val.val.val.x);\n+\n+            t.field4 = VAL6;\n+            Asserts.assertEQ(t.field4.val, VAL6.val);\n+\n+            t.field5 = VAL7;\n+            Asserts.assertEQ(t.field5.val, VAL7.val);\n+\n+            \/\/ Some more values classes with different flavors of primitive fields\n+            t.field6 = null;\n+            Asserts.assertEQ(t.field6, null);\n+            t.field6 = new MyValue8((byte)i);\n+            Asserts.assertEQ(t.field6.b, (byte)i);\n+            t.field7 = null;\n+            Asserts.assertEQ(t.field7, null);\n+            t.field7 = new MyValue9((short)i);\n+            Asserts.assertEQ(t.field7.s, (short)i);\n+            t.field8 = null;\n+            Asserts.assertEQ(t.field8, null);\n+            t.field8 = new MyValue10(i);\n+            Asserts.assertEQ(t.field8.i, i);\n+            t.field9 = null;\n+            Asserts.assertEQ(t.field9, null);\n+            t.field9 = new MyValue11((float)i);\n+            Asserts.assertEQ(t.field9.f, (float)i);\n+            t.field10 = null;\n+            Asserts.assertEQ(t.field10, null);\n+            t.field10 = new MyValue12((char)i);\n+            Asserts.assertEQ(t.field10.c, (char)i);\n+            t.field11 = null;\n+            Asserts.assertEQ(t.field11, null);\n+            t.field11 = new MyValue13((i % 2) == 0);\n+            Asserts.assertEQ(t.field11.b, (i % 2) == 0);\n+\n+            \/\/ Write the fields again and check that we don't overwrite other fields\n+            t.checkFields(i);\n+            t.field6 = new MyValue8((byte)i);\n+            t.checkFields(i);\n+            t.field7 = new MyValue9((short)i);\n+            t.checkFields(i);\n+            t.field8 = new MyValue10(i);\n+            t.checkFields(i);\n+            t.field9 = new MyValue11((float)i);\n+            t.checkFields(i);\n+            t.field10 = new MyValue12((char)i);\n+            t.checkFields(i);\n+            t.field11 = new MyValue13((i % 2) == 0);\n+            t.checkFields(i);\n+\n+            \/\/ Test flat (null-free) arrays\n+            testFlatArray1(false);\n+\n+            testNPE1();\n+            testNPE2();\n+\n+            t.testBounds(i);\n+\n+            \/\/ Null-free, flat, atomic\n+            MyValue8 val8 = new MyValue8((byte)i);\n+            t.field12 = val8;\n+            Asserts.assertEQ(t.field12.b, (byte)i);\n+\n+            try {\n+                t.field12 = null;\n+                throw new RuntimeException(\"No NPE thrown\");\n+            } catch (NullPointerException npe) {\n+                \/\/ Expected\n+            }\n+\n+            \/\/ Null-free, flat with both nullable and null-free fields\n+            t.field13 = new MyValue14(val8, val8);\n+            Asserts.assertEQ(t.field13.nullfree, val8);\n+            Asserts.assertEQ(t.field13.nullable, val8);\n+\n+            t.field13 = new MyValue14(val8, null);\n+            Asserts.assertEQ(t.field13.nullfree, val8);\n+            Asserts.assertEQ(t.field13.nullable, null);\n+\n+            try {\n+                t.field13 = new MyValue14(null, null);\n+                throw new RuntimeException(\"No NPE thrown\");\n+            } catch (NullPointerException npe) {\n+                \/\/ Expected\n+            }\n+            try {\n+                t.field13 = null;\n+                throw new RuntimeException(\"No NPE thrown\");\n+            } catch (NullPointerException npe) {\n+                \/\/ Expected\n+            }\n+\n+            \/\/ Nullable, atomic, flat with both nullable and null-free fields\n+            t.field14 = null;\n+            Asserts.assertEQ(t.field14, null);\n+\n+            t.field14 = new MyValue14(val8, val8);\n+            Asserts.assertEQ(t.field14.nullfree, val8);\n+            Asserts.assertEQ(t.field14.nullable, val8);\n+\n+            t.field14 = new MyValue14(val8, null);\n+            Asserts.assertEQ(t.field14.nullfree, val8);\n+            Asserts.assertEQ(t.field14.nullable, null);\n+\n+            try {\n+                t.field14 = new MyValue14(null, null);\n+                throw new RuntimeException(\"No NPE thrown\");\n+            } catch (NullPointerException npe) {\n+                \/\/ Expected\n+            }\n+\n+            \/\/ Nullable, (atomic), flat with both nullable and null-free fields\n+            t.field15 = null;\n+            Asserts.assertEQ(t.field15, null);\n+\n+            t.field15 = new MyValue14(val8, val8);\n+            Asserts.assertEQ(t.field15.nullfree, val8);\n+            Asserts.assertEQ(t.field15.nullable, val8);\n+\n+            t.field15 = new MyValue14(val8, null);\n+            Asserts.assertEQ(t.field15.nullfree, val8);\n+            Asserts.assertEQ(t.field15.nullable, null);\n+\n+            try {\n+                t.field15 = new MyValue14(null, null);\n+                throw new RuntimeException(\"No NPE thrown\");\n+            } catch (NullPointerException npe) {\n+                \/\/ Expected\n+            }\n+\n+            \/\/ Null-free, atomic, flat with both nullable and null-free fields\n+            t.field16 = new MyValue14(val8, val8);\n+            Asserts.assertEQ(t.field16.nullfree, val8);\n+            Asserts.assertEQ(t.field16.nullable, val8);\n+\n+            t.field16 = new MyValue14(val8, null);\n+            Asserts.assertEQ(t.field16.nullfree, val8);\n+            Asserts.assertEQ(t.field16.nullable, null);\n+\n+            try {\n+                t.field16 = new MyValue14(null, null);\n+                throw new RuntimeException(\"No NPE thrown\");\n+            } catch (NullPointerException npe) {\n+                \/\/ Expected\n+            }\n+            try {\n+                t.field16 = null;\n+                throw new RuntimeException(\"No NPE thrown\");\n+            } catch (NullPointerException npe) {\n+                \/\/ Expected\n+            }\n+\n+            MyValue15 val15 = new MyValue15(new MyClass(i));\n+            t.testWriteOopFields1(val15);\n+            if (i > (LIMIT - 50)) {\n+                \/\/ After warmup, produce some garbage to trigger GC\n+                produceGarbage();\n+            }\n+            Asserts.assertEQ(t.field17.obj.x, i);\n+            Asserts.assertEQ(t.field18.obj.x, i);\n+\n+            MyValue16 val16 = new MyValue16(new MyClass(i), new MyClass(i));\n+            t.testWriteOopFields2(val16);\n+            if (i > (LIMIT - 50)) {\n+                \/\/ After warmup, produce some garbage to trigger GC\n+                produceGarbage();\n+            }\n+            Asserts.assertEQ(t.field19.obj1.x, i);\n+            Asserts.assertEQ(t.field19.obj2.x, i);\n+\n+            MyValue17 val17 = new MyValue17(new MyClass(i), (byte)i, (byte)i);\n+            t.testWriteOopFields3(val17);\n+            if (i > (LIMIT - 50)) {\n+                \/\/ After warmup, produce some garbage to trigger GC\n+                produceGarbage();\n+            }\n+            Asserts.assertEQ(t.field20.obj.x, i);\n+            Asserts.assertEQ(t.field20.b1, (byte)i);\n+            Asserts.assertEQ(t.field20.b2, (byte)i);\n+            Asserts.assertEQ(t.field21.obj.x, i);\n+            Asserts.assertEQ(t.field21.b1, (byte)i);\n+            Asserts.assertEQ(t.field21.b2, (byte)i);\n+        }\n+\n+        \/\/ Trigger deoptimization to check that re-materialization takes the null marker into account\n+        byte x = (byte)42;\n+        t.testDeopt1(x, new MyValue1(x, new MyValue2(x), new MyValue2(x)), new MyValue1(x, null, null), true);\n+        t.testDeopt2(x, new MyValue4(new MyValue3(x), new MyValue3(x)), new MyValue4(null, null), true);\n+\n+        MyValue5 val1 = new MyValue5(x, new MyValue5_1(x, new MyValue5_2(x, new MyValue5_3(x))));\n+        MyValue5 val2 = new MyValue5(x, new MyValue5_1(x, new MyValue5_2(x, null)));\n+        MyValue5 val3 = new MyValue5(x, new MyValue5_1(x, null));\n+        MyValue5 val4 = new MyValue5(x, null);\n+        t.testDeopt3(x, val1, val2, val3, val4, true);\n+\n+        MyValue6 val5 = new MyValue6(new MyValueEmpty());\n+        MyValue6 val6 = new MyValue6(null);\n+        MyValue6 val7 = null;\n+        t.testDeopt4(val5, val6, val7, true);\n+\n+        MyValue7 val8 = new MyValue7(new MyValue6(new MyValueEmpty()));\n+        MyValue7 val9 = new MyValue7(new MyValue6(null));\n+        MyValue7 val10 = new MyValue7(null);\n+        MyValue7 val11 = null;\n+        t.testDeopt5(val8, val9, val10, val11, false);\n+\n+        testFlatArray1(true);\n+    }\n+}\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestFieldNullMarkers.java","additions":998,"deletions":0,"binary":false,"changes":998,"status":"added"},{"patch":"@@ -49,0 +49,1 @@\n+ * @requires vm.opt.AbortVMOnCompilationFailure != true\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestMethodHandles.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -51,2 +51,2 @@\n- * @run main\/othervm -XX:FlatArrayElementMaxSize=-1 -XX:InlineFieldMaxFlatSize=-1 -XX:+AtomicFieldFlattening -XX:+NullableFieldFlattening runtime.valhalla.inlinetypes.FlatArraysTest\n- * @run main\/othervm -XX:FlatArrayElementMaxSize=0 -XX:+AtomicFieldFlattening -XX:+NullableFieldFlattening runtime.valhalla.inlinetypes.FlatArraysTest\n+ * @run main\/othervm -Xint -XX:FlatArrayElementMaxSize=-1 -XX:InlineFieldMaxFlatSize=-1 -XX:+AtomicFieldFlattening -XX:+NullableFieldFlattening runtime.valhalla.inlinetypes.FlatArraysTest\n+ * @run main\/othervm -Xint -XX:FlatArrayElementMaxSize=0 -XX:+AtomicFieldFlattening -XX:+NullableFieldFlattening runtime.valhalla.inlinetypes.FlatArraysTest\n@@ -54,0 +54,3 @@\n+\n+\/\/ TODO 8341767 Remove -Xint\n+\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/FlatArraysTest.java","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+ * @requires vm.flagless\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/InlineTypeDensity.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -31,1 +31,1 @@\n- * @run main\/othervm -Xint -XX:+EnableNullableFieldFlattening -XX:+UnlockDiagnosticVMOptions -XX:+PrintInlineLayout NullableFlatFieldTest\n+ * @run main\/othervm -XX:+NullableFieldFlattening -XX:+UnlockDiagnosticVMOptions -XX:+PrintInlineLayout NullableFlatFieldTest\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/NullableFlatFieldTest.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -38,1 +38,1 @@\n- * @run main\/othervm -XX:+NullableFieldFlattening -XX:FlatArrayElementMaxSize=-1 -XX:InlineFieldMaxFlatSize=-1 -XX:+PrintInlineLayout -XX:+NullableFieldFlattening runtime.valhalla.inlinetypes.UnsafeTest\n+ * @run main\/othervm -Xint -XX:+NullableFieldFlattening -XX:FlatArrayElementMaxSize=-1 -XX:InlineFieldMaxFlatSize=-1 -XX:+PrintInlineLayout -XX:+NullableFieldFlattening runtime.valhalla.inlinetypes.UnsafeTest\n@@ -41,0 +41,2 @@\n+\/\/ TODO 8341767 Remove -Xint\n+\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/UnsafeTest.java","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -50,0 +50,1 @@\n+ * @requires vm.flagless\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/ValueTearing.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -295,1 +295,0 @@\n-    Collections.addAll(argsList, \"-Xint\");\n@@ -306,1 +305,1 @@\n-    Collections.addAll(argsList, \"-XX:+EnableNullableFieldFlattening\");\n+    Collections.addAll(argsList, \"-XX:+NullableFieldFlattening\");\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/field_layout\/NullMarkersTest.java","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"}]}