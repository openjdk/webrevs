{"files":[{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2014, 2024, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2014, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -99,1 +99,1 @@\n-MAN_SUBDIRS += share\/man\n+MAN_SUBDIRS += share\/man windows\/man\n@@ -191,2 +191,3 @@\n-$(MODULE_DEPS_MAKEFILE): $(MODULE_INFOS) \\\n-    $(call DependOnVariable, MODULE_INFOS, $(MAKESUPPORT_OUTPUTDIR)\/MODULE_INFOS.vardeps)\n+ifeq ($(GENERATE_MODULE_DEPS_FILE), true)\n+  $(MODULE_DEPS_MAKEFILE): $(MODULE_INFOS) \\\n+      $(call DependOnVariable, MODULE_INFOS, $(MAKESUPPORT_OUTPUTDIR)\/MODULE_INFOS.vardeps)\n@@ -225,0 +226,1 @@\n+endif\n","filename":"make\/common\/Modules.gmk","additions":6,"deletions":4,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -3,1 +3,1 @@\n- * Copyright (c) 2014, 2024, Red Hat Inc. All rights reserved.\n+ * Copyright (c) 2014, 2025, Red Hat Inc. All rights reserved.\n@@ -205,1 +205,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"call_stub\");\n+    StubGenStubId stub_id = StubGenStubId::call_stub_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -440,1 +441,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"catch_exception\");\n+    StubGenStubId stub_id = StubGenStubId::catch_exception_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -495,1 +497,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"forward exception\");\n+    StubGenStubId stub_id = StubGenStubId::forward_exception_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -584,2 +587,2 @@\n-\n-    StubCodeMark mark(this, \"StubRoutines\", \"verify_oop\");\n+    StubGenStubId stub_id = StubGenStubId::verify_oop_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -633,1 +636,1 @@\n-  address generate_iota_indices(const char *stub_name) {\n+  address generate_iota_indices(StubGenStubId stub_id) {\n@@ -635,1 +638,1 @@\n-    StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+    StubCodeMark mark(this, stub_id);\n@@ -678,1 +681,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"zero_blocks\");\n+    StubGenStubId stub_id = StubGenStubId::zero_blocks_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -817,2 +821,33 @@\n-  void generate_copy_longs(DecoratorSet decorators, BasicType type, Label &start, Register s, Register d, Register count,\n-                           copy_direction direction) {\n+  void generate_copy_longs(StubGenStubId stub_id, DecoratorSet decorators, Label &start, Register s, Register d, Register count) {\n+    BasicType type;\n+    copy_direction direction;\n+\n+    switch (stub_id) {\n+    case copy_byte_f_id:\n+      direction = copy_forwards;\n+      type = T_BYTE;\n+      break;\n+    case copy_byte_b_id:\n+      direction = copy_backwards;\n+      type = T_BYTE;\n+      break;\n+    case copy_oop_f_id:\n+      direction = copy_forwards;\n+      type = T_OBJECT;\n+      break;\n+    case copy_oop_b_id:\n+      direction = copy_backwards;\n+      type = T_OBJECT;\n+      break;\n+    case copy_oop_uninit_f_id:\n+      direction = copy_forwards;\n+      type = T_OBJECT;\n+      break;\n+    case copy_oop_uninit_b_id:\n+      direction = copy_backwards;\n+      type = T_OBJECT;\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n+\n@@ -833,5 +868,0 @@\n-    const char *stub_name;\n-    if (direction == copy_forwards)\n-      stub_name = \"forward_copy_longs\";\n-    else\n-      stub_name = \"backward_copy_longs\";\n@@ -841,1 +871,1 @@\n-    StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+    StubCodeMark mark(this, stub_id);\n@@ -1496,4 +1526,5 @@\n-  \/\/   aligned - true => Input and output aligned on a HeapWord == 8-byte boundary\n-  \/\/             ignored\n-  \/\/   is_oop  - true => oop array, so generate store check code\n-  \/\/   name    - stub name string\n+  \/\/   stub_id - is used to name the stub and identify all details of\n+  \/\/             how to perform the copy.\n+  \/\/\n+  \/\/   entry - is assigned to the stub's post push entry point unless\n+  \/\/           it is null\n@@ -1510,3 +1541,3 @@\n-  \/\/ Side Effects:\n-  \/\/   disjoint_int_copy_entry is set to the no-overlap entry point\n-  \/\/   used by generate_conjoint_int_oop_copy().\n+  \/\/ Side Effects: entry is set to the (post push) entry point so it\n+  \/\/               can be used by the corresponding conjoint copy\n+  \/\/               method\n@@ -1514,2 +1545,1 @@\n-  address generate_disjoint_copy(int size, bool aligned, bool is_oop, address *entry,\n-                                  const char *name, bool dest_uninitialized = false) {\n+  address generate_disjoint_copy(StubGenStubId stub_id, address *entry) {\n@@ -1518,0 +1548,81 @@\n+    int size;\n+    bool aligned;\n+    bool is_oop;\n+    bool dest_uninitialized;\n+    switch (stub_id) {\n+    case jbyte_disjoint_arraycopy_id:\n+      size = sizeof(jbyte);\n+      aligned = false;\n+      is_oop = false;\n+      dest_uninitialized = false;\n+      break;\n+    case arrayof_jbyte_disjoint_arraycopy_id:\n+      size = sizeof(jbyte);\n+      aligned = true;\n+      is_oop = false;\n+      dest_uninitialized = false;\n+      break;\n+    case jshort_disjoint_arraycopy_id:\n+      size = sizeof(jshort);\n+      aligned = false;\n+      is_oop = false;\n+      dest_uninitialized = false;\n+      break;\n+    case arrayof_jshort_disjoint_arraycopy_id:\n+      size = sizeof(jshort);\n+      aligned = true;\n+      is_oop = false;\n+      dest_uninitialized = false;\n+      break;\n+    case jint_disjoint_arraycopy_id:\n+      size = sizeof(jint);\n+      aligned = false;\n+      is_oop = false;\n+      dest_uninitialized = false;\n+      break;\n+    case arrayof_jint_disjoint_arraycopy_id:\n+      size = sizeof(jint);\n+      aligned = true;\n+      is_oop = false;\n+      dest_uninitialized = false;\n+      break;\n+    case jlong_disjoint_arraycopy_id:\n+      \/\/ since this is always aligned we can (should!) use the same\n+      \/\/ stub as for case arrayof_jlong_disjoint_arraycopy\n+      ShouldNotReachHere();\n+      break;\n+    case arrayof_jlong_disjoint_arraycopy_id:\n+      size = sizeof(jlong);\n+      aligned = true;\n+      is_oop = false;\n+      dest_uninitialized = false;\n+      break;\n+    case oop_disjoint_arraycopy_id:\n+      size = UseCompressedOops ? sizeof (jint) : sizeof (jlong);\n+      aligned = !UseCompressedOops;\n+      is_oop = true;\n+      dest_uninitialized = false;\n+      break;\n+    case arrayof_oop_disjoint_arraycopy_id:\n+      size = UseCompressedOops ? sizeof (jint) : sizeof (jlong);\n+      aligned = !UseCompressedOops;\n+      is_oop = true;\n+      dest_uninitialized = false;\n+      break;\n+    case oop_disjoint_arraycopy_uninit_id:\n+      size = UseCompressedOops ? sizeof (jint) : sizeof (jlong);\n+      aligned = !UseCompressedOops;\n+      is_oop = true;\n+      dest_uninitialized = true;\n+      break;\n+    case arrayof_oop_disjoint_arraycopy_uninit_id:\n+      size = UseCompressedOops ? sizeof (jint) : sizeof (jlong);\n+      aligned = !UseCompressedOops;\n+      is_oop = true;\n+      dest_uninitialized = true;\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+      break;\n+    }\n+\n@@ -1519,1 +1630,1 @@\n-    StubCodeMark mark(this, \"StubRoutines\", name);\n+    StubCodeMark mark(this, stub_id);\n@@ -1566,4 +1677,10 @@\n-  \/\/   aligned - true => Input and output aligned on a HeapWord == 8-byte boundary\n-  \/\/             ignored\n-  \/\/   is_oop  - true => oop array, so generate store check code\n-  \/\/   name    - stub name string\n+  \/\/   stub_id - is used to name the stub and identify all details of\n+  \/\/             how to perform the copy.\n+  \/\/\n+  \/\/   nooverlap_target - identifes the (post push) entry for the\n+  \/\/             corresponding disjoint copy routine which can be\n+  \/\/             jumped to if the ranges do not actually overlap\n+  \/\/\n+  \/\/   entry - is assigned to the stub's post push entry point unless\n+  \/\/           it is null\n+  \/\/\n@@ -1580,3 +1697,5 @@\n-  address generate_conjoint_copy(int size, bool aligned, bool is_oop, address nooverlap_target,\n-                                 address *entry, const char *name,\n-                                 bool dest_uninitialized = false) {\n+  \/\/ Side Effects:\n+  \/\/   entry is set to the no-overlap entry point so it can be used by\n+  \/\/   some other conjoint copy method\n+  \/\/\n+  address generate_conjoint_copy(StubGenStubId stub_id, address nooverlap_target, address *entry) {\n@@ -1585,1 +1704,81 @@\n-    StubCodeMark mark(this, \"StubRoutines\", name);\n+    int size;\n+    bool aligned;\n+    bool is_oop;\n+    bool dest_uninitialized;\n+    switch (stub_id) {\n+    case jbyte_arraycopy_id:\n+      size = sizeof(jbyte);\n+      aligned = false;\n+      is_oop = false;\n+      dest_uninitialized = false;\n+      break;\n+    case arrayof_jbyte_arraycopy_id:\n+      size = sizeof(jbyte);\n+      aligned = true;\n+      is_oop = false;\n+      dest_uninitialized = false;\n+      break;\n+    case jshort_arraycopy_id:\n+      size = sizeof(jshort);\n+      aligned = false;\n+      is_oop = false;\n+      dest_uninitialized = false;\n+      break;\n+    case arrayof_jshort_arraycopy_id:\n+      size = sizeof(jshort);\n+      aligned = true;\n+      is_oop = false;\n+      dest_uninitialized = false;\n+      break;\n+    case jint_arraycopy_id:\n+      size = sizeof(jint);\n+      aligned = false;\n+      is_oop = false;\n+      dest_uninitialized = false;\n+      break;\n+    case arrayof_jint_arraycopy_id:\n+      size = sizeof(jint);\n+      aligned = true;\n+      is_oop = false;\n+      dest_uninitialized = false;\n+      break;\n+    case jlong_arraycopy_id:\n+      \/\/ since this is always aligned we can (should!) use the same\n+      \/\/ stub as for case arrayof_jlong_disjoint_arraycopy\n+      ShouldNotReachHere();\n+      break;\n+    case arrayof_jlong_arraycopy_id:\n+      size = sizeof(jlong);\n+      aligned = true;\n+      is_oop = false;\n+      dest_uninitialized = false;\n+      break;\n+    case oop_arraycopy_id:\n+      size = UseCompressedOops ? sizeof (jint) : sizeof (jlong);\n+      aligned = !UseCompressedOops;\n+      is_oop = true;\n+      dest_uninitialized = false;\n+      break;\n+    case arrayof_oop_arraycopy_id:\n+      size = UseCompressedOops ? sizeof (jint) : sizeof (jlong);\n+      aligned = !UseCompressedOops;\n+      is_oop = true;\n+      dest_uninitialized = false;\n+      break;\n+    case oop_arraycopy_uninit_id:\n+      size = UseCompressedOops ? sizeof (jint) : sizeof (jlong);\n+      aligned = !UseCompressedOops;\n+      is_oop = true;\n+      dest_uninitialized = true;\n+      break;\n+    case arrayof_oop_arraycopy_uninit_id:\n+      size = UseCompressedOops ? sizeof (jint) : sizeof (jlong);\n+      aligned = !UseCompressedOops;\n+      is_oop = true;\n+      dest_uninitialized = true;\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n+\n+    StubCodeMark mark(this, stub_id);\n@@ -1631,164 +1830,0 @@\n-}\n-\n-  \/\/ Arguments:\n-  \/\/   aligned - true => Input and output aligned on a HeapWord == 8-byte boundary\n-  \/\/             ignored\n-  \/\/   name    - stub name string\n-  \/\/\n-  \/\/ Inputs:\n-  \/\/   c_rarg0   - source array address\n-  \/\/   c_rarg1   - destination array address\n-  \/\/   c_rarg2   - element count, treated as ssize_t, can be zero\n-  \/\/\n-  \/\/ If 'from' and\/or 'to' are aligned on 4-, 2-, or 1-byte boundaries,\n-  \/\/ we let the hardware handle it.  The one to eight bytes within words,\n-  \/\/ dwords or qwords that span cache line boundaries will still be loaded\n-  \/\/ and stored atomically.\n-  \/\/\n-  \/\/ Side Effects:\n-  \/\/   disjoint_byte_copy_entry is set to the no-overlap entry point  \/\/\n-  \/\/ If 'from' and\/or 'to' are aligned on 4-, 2-, or 1-byte boundaries,\n-  \/\/ we let the hardware handle it.  The one to eight bytes within words,\n-  \/\/ dwords or qwords that span cache line boundaries will still be loaded\n-  \/\/ and stored atomically.\n-  \/\/\n-  \/\/ Side Effects:\n-  \/\/   disjoint_byte_copy_entry is set to the no-overlap entry point\n-  \/\/   used by generate_conjoint_byte_copy().\n-  \/\/\n-  address generate_disjoint_byte_copy(bool aligned, address* entry, const char *name) {\n-    const bool not_oop = false;\n-    return generate_disjoint_copy(sizeof (jbyte), aligned, not_oop, entry, name);\n-  }\n-\n-  \/\/ Arguments:\n-  \/\/   aligned - true => Input and output aligned on a HeapWord == 8-byte boundary\n-  \/\/             ignored\n-  \/\/   name    - stub name string\n-  \/\/\n-  \/\/ Inputs:\n-  \/\/   c_rarg0   - source array address\n-  \/\/   c_rarg1   - destination array address\n-  \/\/   c_rarg2   - element count, treated as ssize_t, can be zero\n-  \/\/\n-  \/\/ If 'from' and\/or 'to' are aligned on 4-, 2-, or 1-byte boundaries,\n-  \/\/ we let the hardware handle it.  The one to eight bytes within words,\n-  \/\/ dwords or qwords that span cache line boundaries will still be loaded\n-  \/\/ and stored atomically.\n-  \/\/\n-  address generate_conjoint_byte_copy(bool aligned, address nooverlap_target,\n-                                      address* entry, const char *name) {\n-    const bool not_oop = false;\n-    return generate_conjoint_copy(sizeof (jbyte), aligned, not_oop, nooverlap_target, entry, name);\n-  }\n-\n-  \/\/ Arguments:\n-  \/\/   aligned - true => Input and output aligned on a HeapWord == 8-byte boundary\n-  \/\/             ignored\n-  \/\/   name    - stub name string\n-  \/\/\n-  \/\/ Inputs:\n-  \/\/   c_rarg0   - source array address\n-  \/\/   c_rarg1   - destination array address\n-  \/\/   c_rarg2   - element count, treated as ssize_t, can be zero\n-  \/\/\n-  \/\/ If 'from' and\/or 'to' are aligned on 4- or 2-byte boundaries, we\n-  \/\/ let the hardware handle it.  The two or four words within dwords\n-  \/\/ or qwords that span cache line boundaries will still be loaded\n-  \/\/ and stored atomically.\n-  \/\/\n-  \/\/ Side Effects:\n-  \/\/   disjoint_short_copy_entry is set to the no-overlap entry point\n-  \/\/   used by generate_conjoint_short_copy().\n-  \/\/\n-  address generate_disjoint_short_copy(bool aligned,\n-                                       address* entry, const char *name) {\n-    const bool not_oop = false;\n-    return generate_disjoint_copy(sizeof (jshort), aligned, not_oop, entry, name);\n-  }\n-\n-  \/\/ Arguments:\n-  \/\/   aligned - true => Input and output aligned on a HeapWord == 8-byte boundary\n-  \/\/             ignored\n-  \/\/   name    - stub name string\n-  \/\/\n-  \/\/ Inputs:\n-  \/\/   c_rarg0   - source array address\n-  \/\/   c_rarg1   - destination array address\n-  \/\/   c_rarg2   - element count, treated as ssize_t, can be zero\n-  \/\/\n-  \/\/ If 'from' and\/or 'to' are aligned on 4- or 2-byte boundaries, we\n-  \/\/ let the hardware handle it.  The two or four words within dwords\n-  \/\/ or qwords that span cache line boundaries will still be loaded\n-  \/\/ and stored atomically.\n-  \/\/\n-  address generate_conjoint_short_copy(bool aligned, address nooverlap_target,\n-                                       address *entry, const char *name) {\n-    const bool not_oop = false;\n-    return generate_conjoint_copy(sizeof (jshort), aligned, not_oop, nooverlap_target, entry, name);\n-\n-  }\n-  \/\/ Arguments:\n-  \/\/   aligned - true => Input and output aligned on a HeapWord == 8-byte boundary\n-  \/\/             ignored\n-  \/\/   name    - stub name string\n-  \/\/\n-  \/\/ Inputs:\n-  \/\/   c_rarg0   - source array address\n-  \/\/   c_rarg1   - destination array address\n-  \/\/   c_rarg2   - element count, treated as ssize_t, can be zero\n-  \/\/\n-  \/\/ If 'from' and\/or 'to' are aligned on 4-byte boundaries, we let\n-  \/\/ the hardware handle it.  The two dwords within qwords that span\n-  \/\/ cache line boundaries will still be loaded and stored atomically.\n-  \/\/\n-  \/\/ Side Effects:\n-  \/\/   disjoint_int_copy_entry is set to the no-overlap entry point\n-  \/\/   used by generate_conjoint_int_oop_copy().\n-  \/\/\n-  address generate_disjoint_int_copy(bool aligned, address *entry,\n-                                         const char *name, bool dest_uninitialized = false) {\n-    const bool not_oop = false;\n-    return generate_disjoint_copy(sizeof (jint), aligned, not_oop, entry, name);\n-  }\n-\n-  \/\/ Arguments:\n-  \/\/   aligned - true => Input and output aligned on a HeapWord == 8-byte boundary\n-  \/\/             ignored\n-  \/\/   name    - stub name string\n-  \/\/\n-  \/\/ Inputs:\n-  \/\/   c_rarg0   - source array address\n-  \/\/   c_rarg1   - destination array address\n-  \/\/   c_rarg2   - element count, treated as ssize_t, can be zero\n-  \/\/\n-  \/\/ If 'from' and\/or 'to' are aligned on 4-byte boundaries, we let\n-  \/\/ the hardware handle it.  The two dwords within qwords that span\n-  \/\/ cache line boundaries will still be loaded and stored atomically.\n-  \/\/\n-  address generate_conjoint_int_copy(bool aligned, address nooverlap_target,\n-                                     address *entry, const char *name,\n-                                     bool dest_uninitialized = false) {\n-    const bool not_oop = false;\n-    return generate_conjoint_copy(sizeof (jint), aligned, not_oop, nooverlap_target, entry, name);\n-  }\n-\n-\n-  \/\/ Arguments:\n-  \/\/   aligned - true => Input and output aligned on a HeapWord boundary == 8 bytes\n-  \/\/             ignored\n-  \/\/   name    - stub name string\n-  \/\/\n-  \/\/ Inputs:\n-  \/\/   c_rarg0   - source array address\n-  \/\/   c_rarg1   - destination array address\n-  \/\/   c_rarg2   - element count, treated as size_t, can be zero\n-  \/\/\n-  \/\/ Side Effects:\n-  \/\/   disjoint_oop_copy_entry or disjoint_long_copy_entry is set to the\n-  \/\/   no-overlap entry point used by generate_conjoint_long_oop_copy().\n-  \/\/\n-  address generate_disjoint_long_copy(bool aligned, address *entry,\n-                                          const char *name, bool dest_uninitialized = false) {\n-    const bool not_oop = false;\n-    return generate_disjoint_copy(sizeof (jlong), aligned, not_oop, entry, name);\n@@ -1797,58 +1832,0 @@\n-  \/\/ Arguments:\n-  \/\/   aligned - true => Input and output aligned on a HeapWord boundary == 8 bytes\n-  \/\/             ignored\n-  \/\/   name    - stub name string\n-  \/\/\n-  \/\/ Inputs:\n-  \/\/   c_rarg0   - source array address\n-  \/\/   c_rarg1   - destination array address\n-  \/\/   c_rarg2   - element count, treated as size_t, can be zero\n-  \/\/\n-  address generate_conjoint_long_copy(bool aligned,\n-                                      address nooverlap_target, address *entry,\n-                                      const char *name, bool dest_uninitialized = false) {\n-    const bool not_oop = false;\n-    return generate_conjoint_copy(sizeof (jlong), aligned, not_oop, nooverlap_target, entry, name);\n-  }\n-\n-  \/\/ Arguments:\n-  \/\/   aligned - true => Input and output aligned on a HeapWord boundary == 8 bytes\n-  \/\/             ignored\n-  \/\/   name    - stub name string\n-  \/\/\n-  \/\/ Inputs:\n-  \/\/   c_rarg0   - source array address\n-  \/\/   c_rarg1   - destination array address\n-  \/\/   c_rarg2   - element count, treated as size_t, can be zero\n-  \/\/\n-  \/\/ Side Effects:\n-  \/\/   disjoint_oop_copy_entry or disjoint_long_copy_entry is set to the\n-  \/\/   no-overlap entry point used by generate_conjoint_long_oop_copy().\n-  \/\/\n-  address generate_disjoint_oop_copy(bool aligned, address *entry,\n-                                     const char *name, bool dest_uninitialized) {\n-    const bool is_oop = true;\n-    const int size = UseCompressedOops ? sizeof (jint) : sizeof (jlong);\n-    return generate_disjoint_copy(size, aligned, is_oop, entry, name, dest_uninitialized);\n-  }\n-\n-  \/\/ Arguments:\n-  \/\/   aligned - true => Input and output aligned on a HeapWord boundary == 8 bytes\n-  \/\/             ignored\n-  \/\/   name    - stub name string\n-  \/\/\n-  \/\/ Inputs:\n-  \/\/   c_rarg0   - source array address\n-  \/\/   c_rarg1   - destination array address\n-  \/\/   c_rarg2   - element count, treated as size_t, can be zero\n-  \/\/\n-  address generate_conjoint_oop_copy(bool aligned,\n-                                     address nooverlap_target, address *entry,\n-                                     const char *name, bool dest_uninitialized) {\n-    const bool is_oop = true;\n-    const int size = UseCompressedOops ? sizeof (jint) : sizeof (jlong);\n-    return generate_conjoint_copy(size, aligned, is_oop, nooverlap_target, entry,\n-                                  name, dest_uninitialized);\n-  }\n-\n-\n@@ -1892,2 +1869,12 @@\n-  address generate_checkcast_copy(const char *name, address *entry,\n-                                  bool dest_uninitialized = false) {\n+  address generate_checkcast_copy(StubGenStubId stub_id, address *entry) {\n+    bool dest_uninitialized;\n+    switch (stub_id) {\n+    case checkcast_arraycopy_id:\n+      dest_uninitialized = false;\n+      break;\n+    case checkcast_arraycopy_uninit_id:\n+      dest_uninitialized = true;\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n@@ -1927,1 +1914,1 @@\n-    StubCodeMark mark(this, \"StubRoutines\", name);\n+    StubCodeMark mark(this, stub_id);\n@@ -2099,2 +2086,1 @@\n-  address generate_unsafe_copy(const char *name,\n-                               address byte_copy_entry,\n+  address generate_unsafe_copy(address byte_copy_entry,\n@@ -2104,0 +2090,2 @@\n+    StubGenStubId stub_id = StubGenStubId::unsafe_arraycopy_id;\n+\n@@ -2108,1 +2096,1 @@\n-    StubCodeMark mark(this, \"StubRoutines\", name);\n+    StubCodeMark mark(this, stub_id);\n@@ -2152,2 +2140,1 @@\n-  address generate_generic_copy(const char *name,\n-                                address byte_copy_entry, address short_copy_entry,\n+  address generate_generic_copy(address byte_copy_entry, address short_copy_entry,\n@@ -2156,0 +2143,1 @@\n+    StubGenStubId stub_id = StubGenStubId::generic_arraycopy_id;\n@@ -2173,1 +2161,1 @@\n-    StubCodeMark mark(this, \"StubRoutines\", name);\n+    StubCodeMark mark(this, stub_id);\n@@ -2432,1 +2420,33 @@\n-  address generate_fill(BasicType t, bool aligned, const char *name) {\n+  address generate_fill(StubGenStubId stub_id) {\n+    BasicType t;\n+    bool aligned;\n+\n+    switch (stub_id) {\n+    case jbyte_fill_id:\n+      t = T_BYTE;\n+      aligned = false;\n+      break;\n+    case jshort_fill_id:\n+      t = T_SHORT;\n+      aligned = false;\n+      break;\n+    case jint_fill_id:\n+      t = T_INT;\n+      aligned = false;\n+      break;\n+    case arrayof_jbyte_fill_id:\n+      t = T_BYTE;\n+      aligned = true;\n+      break;\n+    case arrayof_jshort_fill_id:\n+      t = T_SHORT;\n+      aligned = true;\n+      break;\n+    case arrayof_jint_fill_id:\n+      t = T_INT;\n+      aligned = true;\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    };\n+\n@@ -2434,1 +2454,1 @@\n-    StubCodeMark mark(this, \"StubRoutines\", name);\n+    StubCodeMark mark(this, stub_id);\n@@ -2576,1 +2596,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"_data_cache_writeback\");\n+    StubGenStubId stub_id = StubGenStubId::data_cache_writeback_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -2592,1 +2613,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"_data_cache_writeback_sync\");\n+    StubGenStubId stub_id = StubGenStubId::data_cache_writeback_sync_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -2618,2 +2640,2 @@\n-    generate_copy_longs(IN_HEAP | IS_ARRAY, T_BYTE, copy_f, r0, r1, r15, copy_forwards);\n-    generate_copy_longs(IN_HEAP | IS_ARRAY, T_BYTE, copy_b, r0, r1, r15, copy_backwards);\n+    generate_copy_longs(StubGenStubId::copy_byte_f_id, IN_HEAP | IS_ARRAY, copy_f, r0, r1, r15);\n+    generate_copy_longs(StubGenStubId::copy_byte_b_id, IN_HEAP | IS_ARRAY, copy_b, r0, r1, r15);\n@@ -2621,2 +2643,2 @@\n-    generate_copy_longs(IN_HEAP | IS_ARRAY, T_OBJECT, copy_obj_f, r0, r1, r15, copy_forwards);\n-    generate_copy_longs(IN_HEAP | IS_ARRAY, T_OBJECT, copy_obj_b, r0, r1, r15, copy_backwards);\n+    generate_copy_longs(StubGenStubId::copy_oop_f_id, IN_HEAP | IS_ARRAY, copy_obj_f, r0, r1, r15);\n+    generate_copy_longs(StubGenStubId::copy_oop_b_id, IN_HEAP | IS_ARRAY, copy_obj_b, r0, r1, r15);\n@@ -2624,2 +2646,2 @@\n-    generate_copy_longs(IN_HEAP | IS_ARRAY | IS_DEST_UNINITIALIZED, T_OBJECT, copy_obj_uninit_f, r0, r1, r15, copy_forwards);\n-    generate_copy_longs(IN_HEAP | IS_ARRAY | IS_DEST_UNINITIALIZED, T_OBJECT, copy_obj_uninit_b, r0, r1, r15, copy_backwards);\n+    generate_copy_longs(StubGenStubId::copy_oop_uninit_f_id, IN_HEAP | IS_ARRAY | IS_DEST_UNINITIALIZED, copy_obj_uninit_f, r0, r1, r15);\n+    generate_copy_longs(StubGenStubId::copy_oop_uninit_b_id, IN_HEAP | IS_ARRAY | IS_DEST_UNINITIALIZED, copy_obj_uninit_b, r0, r1, r15);\n@@ -2631,9 +2653,4 @@\n-    StubRoutines::_jbyte_disjoint_arraycopy         = generate_disjoint_byte_copy(false, &entry,\n-                                                                                  \"jbyte_disjoint_arraycopy\");\n-    StubRoutines::_jbyte_arraycopy                  = generate_conjoint_byte_copy(false, entry,\n-                                                                                  &entry_jbyte_arraycopy,\n-                                                                                  \"jbyte_arraycopy\");\n-    StubRoutines::_arrayof_jbyte_disjoint_arraycopy = generate_disjoint_byte_copy(true, &entry,\n-                                                                                  \"arrayof_jbyte_disjoint_arraycopy\");\n-    StubRoutines::_arrayof_jbyte_arraycopy          = generate_conjoint_byte_copy(true, entry, nullptr,\n-                                                                                  \"arrayof_jbyte_arraycopy\");\n+    StubRoutines::_jbyte_disjoint_arraycopy         = generate_disjoint_copy(StubGenStubId::jbyte_disjoint_arraycopy_id, &entry);\n+    StubRoutines::_jbyte_arraycopy                  = generate_conjoint_copy(StubGenStubId::jbyte_arraycopy_id, entry, &entry_jbyte_arraycopy);\n+    StubRoutines::_arrayof_jbyte_disjoint_arraycopy = generate_disjoint_copy(StubGenStubId::arrayof_jbyte_disjoint_arraycopy_id, &entry);\n+    StubRoutines::_arrayof_jbyte_arraycopy          = generate_conjoint_copy(StubGenStubId::arrayof_jbyte_arraycopy_id, entry, nullptr);\n@@ -2643,9 +2660,4 @@\n-    StubRoutines::_jshort_disjoint_arraycopy         = generate_disjoint_short_copy(false, &entry,\n-                                                                                    \"jshort_disjoint_arraycopy\");\n-    StubRoutines::_jshort_arraycopy                  = generate_conjoint_short_copy(false, entry,\n-                                                                                    &entry_jshort_arraycopy,\n-                                                                                    \"jshort_arraycopy\");\n-    StubRoutines::_arrayof_jshort_disjoint_arraycopy = generate_disjoint_short_copy(true, &entry,\n-                                                                                    \"arrayof_jshort_disjoint_arraycopy\");\n-    StubRoutines::_arrayof_jshort_arraycopy          = generate_conjoint_short_copy(true, entry, nullptr,\n-                                                                                    \"arrayof_jshort_arraycopy\");\n+    StubRoutines::_jshort_disjoint_arraycopy         = generate_disjoint_copy(StubGenStubId::jshort_disjoint_arraycopy_id, &entry);\n+    StubRoutines::_jshort_arraycopy                  = generate_conjoint_copy(StubGenStubId::jshort_arraycopy_id, entry, &entry_jshort_arraycopy);\n+    StubRoutines::_arrayof_jshort_disjoint_arraycopy = generate_disjoint_copy(StubGenStubId::arrayof_jshort_disjoint_arraycopy_id, &entry);\n+    StubRoutines::_arrayof_jshort_arraycopy          = generate_conjoint_copy(StubGenStubId::arrayof_jshort_arraycopy_id, entry, nullptr);\n@@ -2655,4 +2667,2 @@\n-    StubRoutines::_arrayof_jint_disjoint_arraycopy = generate_disjoint_int_copy(true, &entry,\n-                                                                                \"arrayof_jint_disjoint_arraycopy\");\n-    StubRoutines::_arrayof_jint_arraycopy          = generate_conjoint_int_copy(true, entry, &entry_jint_arraycopy,\n-                                                                                \"arrayof_jint_arraycopy\");\n+    StubRoutines::_arrayof_jint_disjoint_arraycopy = generate_disjoint_copy(StubGenStubId::arrayof_jint_disjoint_arraycopy_id, &entry);\n+    StubRoutines::_arrayof_jint_arraycopy          = generate_conjoint_copy(StubGenStubId::arrayof_jint_arraycopy_id, entry, &entry_jint_arraycopy);\n@@ -2661,5 +2671,2 @@\n-    StubRoutines::_jint_disjoint_arraycopy         = generate_disjoint_int_copy(false, &entry,\n-                                                                                \"jint_disjoint_arraycopy\");\n-    StubRoutines::_jint_arraycopy                  = generate_conjoint_int_copy(false, entry,\n-                                                                                &entry_jint_arraycopy,\n-                                                                                \"jint_arraycopy\");\n+    StubRoutines::_jint_disjoint_arraycopy         = generate_disjoint_copy(StubGenStubId::jint_disjoint_arraycopy_id, &entry);\n+    StubRoutines::_jint_arraycopy                  = generate_conjoint_copy(StubGenStubId::jint_arraycopy_id, entry, &entry_jint_arraycopy);\n@@ -2669,4 +2676,2 @@\n-    StubRoutines::_arrayof_jlong_disjoint_arraycopy = generate_disjoint_long_copy(true, &entry,\n-                                                                                  \"arrayof_jlong_disjoint_arraycopy\");\n-    StubRoutines::_arrayof_jlong_arraycopy          = generate_conjoint_long_copy(true, entry, &entry_jlong_arraycopy,\n-                                                                                  \"arrayof_jlong_arraycopy\");\n+    StubRoutines::_arrayof_jlong_disjoint_arraycopy = generate_disjoint_copy(StubGenStubId::arrayof_jlong_disjoint_arraycopy_id, &entry);\n+    StubRoutines::_arrayof_jlong_arraycopy          = generate_conjoint_copy(StubGenStubId::arrayof_jlong_arraycopy_id, entry, &entry_jlong_arraycopy);\n@@ -2683,2 +2688,1 @@\n-        = generate_disjoint_oop_copy(aligned, &entry, \"arrayof_oop_disjoint_arraycopy\",\n-                                     \/*dest_uninitialized*\/false);\n+        = generate_disjoint_copy(StubGenStubId::arrayof_oop_disjoint_arraycopy_id, &entry);\n@@ -2686,2 +2690,1 @@\n-        = generate_conjoint_oop_copy(aligned, entry, &entry_oop_arraycopy, \"arrayof_oop_arraycopy\",\n-                                     \/*dest_uninitialized*\/false);\n+        = generate_conjoint_copy(StubGenStubId::arrayof_oop_arraycopy_id, entry, &entry_oop_arraycopy);\n@@ -2690,2 +2693,1 @@\n-        = generate_disjoint_oop_copy(aligned, &entry, \"arrayof_oop_disjoint_arraycopy_uninit\",\n-                                     \/*dest_uninitialized*\/true);\n+        = generate_disjoint_copy(StubGenStubId::arrayof_oop_disjoint_arraycopy_uninit_id, &entry);\n@@ -2693,2 +2695,1 @@\n-        = generate_conjoint_oop_copy(aligned, entry, nullptr, \"arrayof_oop_arraycopy_uninit\",\n-                                     \/*dest_uninitialized*\/true);\n+        = generate_conjoint_copy(StubGenStubId::arrayof_oop_arraycopy_uninit_id, entry, nullptr);\n@@ -2702,3 +2703,2 @@\n-    StubRoutines::_checkcast_arraycopy        = generate_checkcast_copy(\"checkcast_arraycopy\", &entry_checkcast_arraycopy);\n-    StubRoutines::_checkcast_arraycopy_uninit = generate_checkcast_copy(\"checkcast_arraycopy_uninit\", nullptr,\n-                                                                        \/*dest_uninitialized*\/true);\n+    StubRoutines::_checkcast_arraycopy        = generate_checkcast_copy(StubGenStubId::checkcast_arraycopy_id, &entry_checkcast_arraycopy);\n+    StubRoutines::_checkcast_arraycopy_uninit = generate_checkcast_copy(StubGenStubId::checkcast_arraycopy_uninit_id, nullptr);\n@@ -2706,2 +2706,1 @@\n-    StubRoutines::_unsafe_arraycopy    = generate_unsafe_copy(\"unsafe_arraycopy\",\n-                                                              entry_jbyte_arraycopy,\n+    StubRoutines::_unsafe_arraycopy    = generate_unsafe_copy(entry_jbyte_arraycopy,\n@@ -2712,2 +2711,1 @@\n-    StubRoutines::_generic_arraycopy   = generate_generic_copy(\"generic_arraycopy\",\n-                                                               entry_jbyte_arraycopy,\n+    StubRoutines::_generic_arraycopy   = generate_generic_copy(entry_jbyte_arraycopy,\n@@ -2720,6 +2718,6 @@\n-    StubRoutines::_jbyte_fill = generate_fill(T_BYTE, false, \"jbyte_fill\");\n-    StubRoutines::_jshort_fill = generate_fill(T_SHORT, false, \"jshort_fill\");\n-    StubRoutines::_jint_fill = generate_fill(T_INT, false, \"jint_fill\");\n-    StubRoutines::_arrayof_jbyte_fill = generate_fill(T_BYTE, true, \"arrayof_jbyte_fill\");\n-    StubRoutines::_arrayof_jshort_fill = generate_fill(T_SHORT, true, \"arrayof_jshort_fill\");\n-    StubRoutines::_arrayof_jint_fill = generate_fill(T_INT, true, \"arrayof_jint_fill\");\n+    StubRoutines::_jbyte_fill = generate_fill(StubGenStubId::jbyte_fill_id);\n+    StubRoutines::_jshort_fill = generate_fill(StubGenStubId::jshort_fill_id);\n+    StubRoutines::_jint_fill = generate_fill(StubGenStubId::jint_fill_id);\n+    StubRoutines::_arrayof_jbyte_fill = generate_fill(StubGenStubId::arrayof_jbyte_fill_id);\n+    StubRoutines::_arrayof_jshort_fill = generate_fill(StubGenStubId::arrayof_jshort_fill_id);\n+    StubRoutines::_arrayof_jint_fill = generate_fill(StubGenStubId::arrayof_jint_fill_id);\n@@ -2739,1 +2737,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"aescrypt_encryptBlock\");\n+    StubGenStubId stub_id = StubGenStubId::aescrypt_encryptBlock_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -2772,1 +2771,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"aescrypt_decryptBlock\");\n+    StubGenStubId stub_id = StubGenStubId::aescrypt_decryptBlock_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -2810,1 +2810,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"cipherBlockChaining_encryptAESCrypt\");\n+    StubGenStubId stub_id = StubGenStubId::cipherBlockChaining_encryptAESCrypt_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -2914,1 +2915,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"cipherBlockChaining_decryptAESCrypt\");\n+    StubGenStubId stub_id = StubGenStubId::cipherBlockChaining_decryptAESCrypt_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -3100,1 +3102,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"counterMode_AESCrypt\");\n+    StubGenStubId stub_id = StubGenStubId::counterMode_AESCrypt_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -3309,1 +3312,2 @@\n-     StubCodeMark mark(this, \"StubRoutines\", \"galoisCounterMode_AESCrypt\");\n+    StubGenStubId stub_id = StubGenStubId::galoisCounterMode_AESCrypt_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -3518,1 +3522,12 @@\n-  address generate_md5_implCompress(bool multi_block, const char *name) {\n+  address generate_md5_implCompress(StubGenStubId stub_id) {\n+    bool multi_block;\n+    switch (stub_id) {\n+    case md5_implCompress_id:\n+      multi_block = false;\n+      break;\n+    case md5_implCompressMB_id:\n+      multi_block = true;\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n@@ -3520,1 +3535,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", name);\n+\n+    StubCodeMark mark(this, stub_id);\n@@ -3659,1 +3675,13 @@\n-  address generate_sha1_implCompress(bool multi_block, const char *name) {\n+  address generate_sha1_implCompress(StubGenStubId stub_id) {\n+    bool multi_block;\n+    switch (stub_id) {\n+    case sha1_implCompress_id:\n+      multi_block = false;\n+      break;\n+    case sha1_implCompressMB_id:\n+      multi_block = true;\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n+\n@@ -3661,1 +3689,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", name);\n+\n+    StubCodeMark mark(this, stub_id);\n@@ -3751,1 +3780,13 @@\n-  address generate_sha256_implCompress(bool multi_block, const char *name) {\n+  address generate_sha256_implCompress(StubGenStubId stub_id) {\n+    bool multi_block;\n+    switch (stub_id) {\n+    case sha256_implCompress_id:\n+      multi_block = false;\n+      break;\n+    case sha256_implCompressMB_id:\n+      multi_block = true;\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n+\n@@ -3770,0 +3811,1 @@\n+\n@@ -3771,1 +3813,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", name);\n+\n+    StubCodeMark mark(this, stub_id);\n@@ -3893,1 +3936,13 @@\n-  address generate_sha512_implCompress(bool multi_block, const char *name) {\n+  address generate_sha512_implCompress(StubGenStubId stub_id) {\n+    bool multi_block;\n+    switch (stub_id) {\n+    case sha512_implCompress_id:\n+      multi_block = false;\n+      break;\n+    case sha512_implCompressMB_id:\n+      multi_block = true;\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n+\n@@ -3925,1 +3980,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", name);\n+\n+    StubCodeMark mark(this, stub_id);\n@@ -4041,1 +4097,13 @@\n-  address generate_sha3_implCompress(bool multi_block, const char *name) {\n+  address generate_sha3_implCompress(StubGenStubId stub_id) {\n+    bool multi_block;\n+    switch (stub_id) {\n+    case sha3_implCompress_id:\n+      multi_block = false;\n+      break;\n+    case sha3_implCompressMB_id:\n+      multi_block = true;\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n+\n@@ -4054,1 +4122,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", name);\n+\n+    StubCodeMark mark(this, stub_id);\n@@ -4271,1 +4340,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"updateBytesCRC32\");\n+    StubGenStubId stub_id = StubGenStubId::updateBytesCRC32_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -4296,3 +4366,3 @@\n-  \/\/ ChaCha20 block function.  This version parallelizes by loading\n-  \/\/ individual 32-bit state elements into vectors for four blocks\n-  \/\/ (e.g. all four blocks' worth of state[0] in one register, etc.)\n+  \/\/ ChaCha20 block function.  This version parallelizes 4 quarter\n+  \/\/ round operations at a time.  It uses 16 SIMD registers to\n+  \/\/ produce 4 blocks of key stream.\n@@ -4301,1 +4371,1 @@\n-  \/\/ keystream (byte[1024]) = c_rarg1\n+  \/\/ keystream (byte[256]) = c_rarg1\n@@ -4303,2 +4373,27 @@\n-  address generate_chacha20Block_blockpar() {\n-    Label L_twoRounds, L_cc20_const;\n+  \/\/\n+  \/\/ In this approach, we load the 512-bit start state sequentially into\n+  \/\/ 4 128-bit vectors.  We then make 4 4-vector copies of that starting\n+  \/\/ state, with each successive set of 4 vectors having a +1 added into\n+  \/\/ the first 32-bit lane of the 4th vector in that group (the counter).\n+  \/\/ By doing this, we can perform the block function on 4 512-bit blocks\n+  \/\/ within one run of this intrinsic.\n+  \/\/ The alignment of the data across the 4-vector group is such that at\n+  \/\/ the start it is already aligned for the first round of each two-round\n+  \/\/ loop iteration.  In other words, the corresponding lanes of each vector\n+  \/\/ will contain the values needed for that quarter round operation (e.g.\n+  \/\/ elements 0\/4\/8\/12, 1\/5\/9\/13, 2\/6\/10\/14, etc.).\n+  \/\/ In between each full round, a lane shift must occur.  Within a loop\n+  \/\/ iteration, between the first and second rounds, the 2nd, 3rd, and 4th\n+  \/\/ vectors are rotated left 32, 64 and 96 bits, respectively.  The result\n+  \/\/ is effectively a diagonal orientation in columnar form.  After the\n+  \/\/ second full round, those registers are left-rotated again, this time\n+  \/\/ 96, 64, and 32 bits - returning the vectors to their columnar organization.\n+  \/\/ After all 10 iterations, the original state is added to each 4-vector\n+  \/\/ working state along with the add mask, and the 4 vector groups are\n+  \/\/ sequentially written to the memory dedicated for the output key stream.\n+  \/\/\n+  \/\/ For a more detailed explanation, see Goll and Gueron, \"Vectorization of\n+  \/\/ ChaCha Stream Cipher\", 2014 11th Int. Conf. on Information Technology:\n+  \/\/ New Generations, Las Vegas, NV, USA, April 2014, DOI: 10.1109\/ITNG.2014.33\n+  address generate_chacha20Block_qrpar() {\n+    Label L_Q_twoRounds, L_Q_cc20_const;\n@@ -4306,2 +4401,2 @@\n-    \/\/ onto FloatRegisters.  The first 128 bits are a counter add overlay\n-    \/\/ that adds +0\/+1\/+2\/+3 to the vector holding replicated state[12].\n+    \/\/ onto SIMD registers.  The first 128 bits are a counter add overlay\n+    \/\/ that adds +1\/+0\/+0\/+0 to the vectors holding replicated state[12].\n@@ -4309,3 +4404,4 @@\n-    __ BIND(L_cc20_const);\n-    __ emit_int64(0x0000000100000000UL);\n-    __ emit_int64(0x0000000300000002UL);\n+    \/\/ on 32-bit lanes within a SIMD register.\n+    __ BIND(L_Q_cc20_const);\n+    __ emit_int64(0x0000000000000001UL);\n+    __ emit_int64(0x0000000000000000UL);\n@@ -4316,1 +4412,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"chacha20Block\");\n+    StubGenStubId stub_id = StubGenStubId::chacha20Block_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -4320,1 +4417,0 @@\n-    int i, j;\n@@ -4326,6 +4422,23 @@\n-    const FloatRegister stateFirst = v0;\n-    const FloatRegister stateSecond = v1;\n-    const FloatRegister stateThird = v2;\n-    const FloatRegister stateFourth = v3;\n-    const FloatRegister origCtrState = v28;\n-    const FloatRegister scratch = v29;\n+    const FloatRegister aState = v0;\n+    const FloatRegister bState = v1;\n+    const FloatRegister cState = v2;\n+    const FloatRegister dState = v3;\n+    const FloatRegister a1Vec = v4;\n+    const FloatRegister b1Vec = v5;\n+    const FloatRegister c1Vec = v6;\n+    const FloatRegister d1Vec = v7;\n+    \/\/ Skip the callee-saved registers v8 - v15\n+    const FloatRegister a2Vec = v16;\n+    const FloatRegister b2Vec = v17;\n+    const FloatRegister c2Vec = v18;\n+    const FloatRegister d2Vec = v19;\n+    const FloatRegister a3Vec = v20;\n+    const FloatRegister b3Vec = v21;\n+    const FloatRegister c3Vec = v22;\n+    const FloatRegister d3Vec = v23;\n+    const FloatRegister a4Vec = v24;\n+    const FloatRegister b4Vec = v25;\n+    const FloatRegister c4Vec = v26;\n+    const FloatRegister d4Vec = v27;\n+    const FloatRegister scratch = v28;\n+    const FloatRegister addMask = v29;\n@@ -4334,30 +4447,32 @@\n-    \/\/ Organize SIMD registers in an array that facilitates\n-    \/\/ putting repetitive opcodes into loop structures.  It is\n-    \/\/ important that each grouping of 4 registers is monotonically\n-    \/\/ increasing to support the requirements of multi-register\n-    \/\/ instructions (e.g. ld4r, st4, etc.)\n-    const FloatRegister workSt[16] = {\n-         v4,  v5,  v6,  v7, v16, v17, v18, v19,\n-        v20, v21, v22, v23, v24, v25, v26, v27\n-    };\n-\n-    \/\/ Load from memory and interlace across 16 SIMD registers,\n-    \/\/ With each word from memory being broadcast to all lanes of\n-    \/\/ each successive SIMD register.\n-    \/\/      Addr(0) -> All lanes in workSt[i]\n-    \/\/      Addr(4) -> All lanes workSt[i + 1], etc.\n-    __ mov(tmpAddr, state);\n-    for (i = 0; i < 16; i += 4) {\n-      __ ld4r(workSt[i], workSt[i + 1], workSt[i + 2], workSt[i + 3], __ T4S,\n-          __ post(tmpAddr, 16));\n-    }\n-\n-    \/\/ Pull in constant data.  The first 16 bytes are the add overlay\n-    \/\/ which is applied to the vector holding the counter (state[12]).\n-    \/\/ The second 16 bytes is the index register for the 8-bit left\n-    \/\/ rotation tbl instruction.\n-    __ adr(tmpAddr, L_cc20_const);\n-    __ ldpq(origCtrState, lrot8Tbl, Address(tmpAddr));\n-    __ addv(workSt[12], __ T4S, workSt[12], origCtrState);\n-\n-    \/\/ Set up the 10 iteration loop and perform all 8 quarter round ops\n+    \/\/ Load the initial state in the first 4 quadword registers,\n+    \/\/ then copy the initial state into the next 4 quadword registers\n+    \/\/ that will be used for the working state.\n+    __ ld1(aState, bState, cState, dState, __ T16B, Address(state));\n+\n+    \/\/ Load the index register for 2 constant 128-bit data fields.\n+    \/\/ The first represents the +1\/+0\/+0\/+0 add mask.  The second is\n+    \/\/ the 8-bit left rotation.\n+    __ adr(tmpAddr, L_Q_cc20_const);\n+    __ ldpq(addMask, lrot8Tbl, Address(tmpAddr));\n+\n+    __ mov(a1Vec, __ T16B, aState);\n+    __ mov(b1Vec, __ T16B, bState);\n+    __ mov(c1Vec, __ T16B, cState);\n+    __ mov(d1Vec, __ T16B, dState);\n+\n+    __ mov(a2Vec, __ T16B, aState);\n+    __ mov(b2Vec, __ T16B, bState);\n+    __ mov(c2Vec, __ T16B, cState);\n+    __ addv(d2Vec, __ T4S, d1Vec, addMask);\n+\n+    __ mov(a3Vec, __ T16B, aState);\n+    __ mov(b3Vec, __ T16B, bState);\n+    __ mov(c3Vec, __ T16B, cState);\n+    __ addv(d3Vec, __ T4S, d2Vec, addMask);\n+\n+    __ mov(a4Vec, __ T16B, aState);\n+    __ mov(b4Vec, __ T16B, bState);\n+    __ mov(c4Vec, __ T16B, cState);\n+    __ addv(d4Vec, __ T4S, d3Vec, addMask);\n+\n+    \/\/ Set up the 10 iteration loop\n@@ -4365,19 +4480,38 @@\n-    __ BIND(L_twoRounds);\n-\n-    __ cc20_quarter_round(workSt[0], workSt[4], workSt[8], workSt[12],\n-        scratch, lrot8Tbl);\n-    __ cc20_quarter_round(workSt[1], workSt[5], workSt[9], workSt[13],\n-        scratch, lrot8Tbl);\n-    __ cc20_quarter_round(workSt[2], workSt[6], workSt[10], workSt[14],\n-        scratch, lrot8Tbl);\n-    __ cc20_quarter_round(workSt[3], workSt[7], workSt[11], workSt[15],\n-        scratch, lrot8Tbl);\n-\n-    __ cc20_quarter_round(workSt[0], workSt[5], workSt[10], workSt[15],\n-        scratch, lrot8Tbl);\n-    __ cc20_quarter_round(workSt[1], workSt[6], workSt[11], workSt[12],\n-        scratch, lrot8Tbl);\n-    __ cc20_quarter_round(workSt[2], workSt[7], workSt[8], workSt[13],\n-        scratch, lrot8Tbl);\n-    __ cc20_quarter_round(workSt[3], workSt[4], workSt[9], workSt[14],\n-        scratch, lrot8Tbl);\n+    __ BIND(L_Q_twoRounds);\n+\n+    \/\/ The first set of operations on the vectors covers the first 4 quarter\n+    \/\/ round operations:\n+    \/\/  Qround(state, 0, 4, 8,12)\n+    \/\/  Qround(state, 1, 5, 9,13)\n+    \/\/  Qround(state, 2, 6,10,14)\n+    \/\/  Qround(state, 3, 7,11,15)\n+    __ cc20_quarter_round(a1Vec, b1Vec, c1Vec, d1Vec, scratch, lrot8Tbl);\n+    __ cc20_quarter_round(a2Vec, b2Vec, c2Vec, d2Vec, scratch, lrot8Tbl);\n+    __ cc20_quarter_round(a3Vec, b3Vec, c3Vec, d3Vec, scratch, lrot8Tbl);\n+    __ cc20_quarter_round(a4Vec, b4Vec, c4Vec, d4Vec, scratch, lrot8Tbl);\n+\n+    \/\/ Shuffle the b1Vec\/c1Vec\/d1Vec to reorganize the state vectors to\n+    \/\/ diagonals. The a1Vec does not need to change orientation.\n+    __ cc20_shift_lane_org(b1Vec, c1Vec, d1Vec, true);\n+    __ cc20_shift_lane_org(b2Vec, c2Vec, d2Vec, true);\n+    __ cc20_shift_lane_org(b3Vec, c3Vec, d3Vec, true);\n+    __ cc20_shift_lane_org(b4Vec, c4Vec, d4Vec, true);\n+\n+    \/\/ The second set of operations on the vectors covers the second 4 quarter\n+    \/\/ round operations, now acting on the diagonals:\n+    \/\/  Qround(state, 0, 5,10,15)\n+    \/\/  Qround(state, 1, 6,11,12)\n+    \/\/  Qround(state, 2, 7, 8,13)\n+    \/\/  Qround(state, 3, 4, 9,14)\n+    __ cc20_quarter_round(a1Vec, b1Vec, c1Vec, d1Vec, scratch, lrot8Tbl);\n+    __ cc20_quarter_round(a2Vec, b2Vec, c2Vec, d2Vec, scratch, lrot8Tbl);\n+    __ cc20_quarter_round(a3Vec, b3Vec, c3Vec, d3Vec, scratch, lrot8Tbl);\n+    __ cc20_quarter_round(a4Vec, b4Vec, c4Vec, d4Vec, scratch, lrot8Tbl);\n+\n+    \/\/ Before we start the next iteration, we need to perform shuffles\n+    \/\/ on the b\/c\/d vectors to move them back to columnar organizations\n+    \/\/ from their current diagonal orientation.\n+    __ cc20_shift_lane_org(b1Vec, c1Vec, d1Vec, false);\n+    __ cc20_shift_lane_org(b2Vec, c2Vec, d2Vec, false);\n+    __ cc20_shift_lane_org(b3Vec, c3Vec, d3Vec, false);\n+    __ cc20_shift_lane_org(b4Vec, c4Vec, d4Vec, false);\n@@ -4387,27 +4521,34 @@\n-    __ cbnz(loopCtr, L_twoRounds);\n-\n-    __ mov(tmpAddr, state);\n-\n-    \/\/ Add the starting state back to the post-loop keystream\n-    \/\/ state.  We read\/interlace the state array from memory into\n-    \/\/ 4 registers similar to what we did in the beginning.  Then\n-    \/\/ add the counter overlay onto workSt[12] at the end.\n-    for (i = 0; i < 16; i += 4) {\n-      __ ld4r(stateFirst, stateSecond, stateThird, stateFourth, __ T4S,\n-          __ post(tmpAddr, 16));\n-      __ addv(workSt[i], __ T4S, workSt[i], stateFirst);\n-      __ addv(workSt[i + 1], __ T4S, workSt[i + 1], stateSecond);\n-      __ addv(workSt[i + 2], __ T4S, workSt[i + 2], stateThird);\n-      __ addv(workSt[i + 3], __ T4S, workSt[i + 3], stateFourth);\n-    }\n-    __ addv(workSt[12], __ T4S, workSt[12], origCtrState);    \/\/ Add ctr mask\n-\n-    \/\/ Write to key stream, storing the same element out of workSt[0..15]\n-    \/\/ to consecutive 4-byte offsets in the key stream buffer, then repeating\n-    \/\/ for the next element position.\n-    for (i = 0; i < 4; i++) {\n-      for (j = 0; j < 16; j += 4) {\n-        __ st4(workSt[j], workSt[j + 1], workSt[j + 2], workSt[j + 3], __ S, i,\n-            __ post(keystream, 16));\n-      }\n-    }\n+    __ cbnz(loopCtr, L_Q_twoRounds);\n+\n+    \/\/ Once the counter reaches zero, we fall out of the loop\n+    \/\/ and need to add the initial state back into the working state\n+    \/\/ represented by the a\/b\/c\/d1Vec registers.  This is destructive\n+    \/\/ on the dState register but we no longer will need it.\n+    __ addv(a1Vec, __ T4S, a1Vec, aState);\n+    __ addv(b1Vec, __ T4S, b1Vec, bState);\n+    __ addv(c1Vec, __ T4S, c1Vec, cState);\n+    __ addv(d1Vec, __ T4S, d1Vec, dState);\n+\n+    __ addv(a2Vec, __ T4S, a2Vec, aState);\n+    __ addv(b2Vec, __ T4S, b2Vec, bState);\n+    __ addv(c2Vec, __ T4S, c2Vec, cState);\n+    __ addv(dState, __ T4S, dState, addMask);\n+    __ addv(d2Vec, __ T4S, d2Vec, dState);\n+\n+    __ addv(a3Vec, __ T4S, a3Vec, aState);\n+    __ addv(b3Vec, __ T4S, b3Vec, bState);\n+    __ addv(c3Vec, __ T4S, c3Vec, cState);\n+    __ addv(dState, __ T4S, dState, addMask);\n+    __ addv(d3Vec, __ T4S, d3Vec, dState);\n+\n+    __ addv(a4Vec, __ T4S, a4Vec, aState);\n+    __ addv(b4Vec, __ T4S, b4Vec, bState);\n+    __ addv(c4Vec, __ T4S, c4Vec, cState);\n+    __ addv(dState, __ T4S, dState, addMask);\n+    __ addv(d4Vec, __ T4S, d4Vec, dState);\n+\n+    \/\/ Write the final state back to the result buffer\n+    __ st1(a1Vec, b1Vec, c1Vec, d1Vec, __ T16B, __ post(keystream, 64));\n+    __ st1(a2Vec, b2Vec, c2Vec, d2Vec, __ T16B, __ post(keystream, 64));\n+    __ st1(a3Vec, b3Vec, c3Vec, d3Vec, __ T16B, __ post(keystream, 64));\n+    __ st1(a4Vec, b4Vec, c4Vec, d4Vec, __ T16B, __ post(keystream, 64));\n@@ -4438,1 +4579,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"updateBytesCRC32C\");\n+    StubGenStubId stub_id = StubGenStubId::updateBytesCRC32C_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -4476,1 +4618,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"updateBytesAdler32\");\n+    StubGenStubId stub_id = StubGenStubId::updateBytesAdler32_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -4697,1 +4840,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"multiplyToLen\");\n+    StubGenStubId stub_id = StubGenStubId::multiplyToLen_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -4729,1 +4873,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"squareToLen\");\n+    StubGenStubId stub_id = StubGenStubId::squareToLen_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -4762,1 +4907,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"mulAdd\");\n+    StubGenStubId stub_id = StubGenStubId::mulAdd_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -4792,1 +4938,2 @@\n-    StubCodeMark mark(this,  \"StubRoutines\", \"bigIntegerRightShiftWorker\");\n+    StubGenStubId stub_id = StubGenStubId::bigIntegerRightShiftWorker_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -4914,1 +5061,2 @@\n-    StubCodeMark mark(this,  \"StubRoutines\", \"bigIntegerLeftShiftWorker\");\n+    StubGenStubId stub_id = StubGenStubId::bigIntegerLeftShiftWorker_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -5022,1 +5170,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"count_positives\");\n+    StubGenStubId stub_id = StubGenStubId::count_positives_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -5283,1 +5432,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"large_array_equals\");\n+    StubGenStubId stub_id = StubGenStubId::large_array_equals_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -5408,1 +5558,1 @@\n-    const char *mark_name = \"\";\n+    StubGenStubId stub_id;\n@@ -5411,1 +5561,1 @@\n-      mark_name = \"_large_arrays_hashcode_boolean\";\n+      stub_id = StubGenStubId::large_arrays_hashcode_boolean_id;\n@@ -5414,1 +5564,1 @@\n-      mark_name = \"_large_arrays_hashcode_byte\";\n+      stub_id = StubGenStubId::large_arrays_hashcode_byte_id;\n@@ -5417,1 +5567,1 @@\n-      mark_name = \"_large_arrays_hashcode_char\";\n+      stub_id = StubGenStubId::large_arrays_hashcode_char_id;\n@@ -5420,1 +5570,1 @@\n-      mark_name = \"_large_arrays_hashcode_short\";\n+      stub_id = StubGenStubId::large_arrays_hashcode_short_id;\n@@ -5423,1 +5573,1 @@\n-      mark_name = \"_large_arrays_hashcode_int\";\n+      stub_id = StubGenStubId::large_arrays_hashcode_int_id;\n@@ -5426,2 +5576,2 @@\n-      mark_name = \"_large_arrays_hashcode_incorrect_type\";\n-      __ should_not_reach_here();\n+      stub_id = StubGenStubId::NO_STUBID;\n+      ShouldNotReachHere();\n@@ -5430,1 +5580,1 @@\n-    StubCodeMark mark(this, \"StubRoutines\", mark_name);\n+    StubCodeMark mark(this, stub_id);\n@@ -5663,1 +5813,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", isCos ? \"libmDcos\" : \"libmDsin\");\n+    StubGenStubId stub_id = (isCos ? StubGenStubId::dcos_id : StubGenStubId::dsin_id);\n+    StubCodeMark mark(this, stub_id);\n@@ -5714,3 +5865,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", isLU\n-        ? \"compare_long_string_different_encoding LU\"\n-        : \"compare_long_string_different_encoding UL\");\n+    StubGenStubId stub_id = (isLU ? StubGenStubId::compare_long_string_LU_id : StubGenStubId::compare_long_string_UL_id);\n+    StubCodeMark mark(this, stub_id);\n@@ -5825,1 +5975,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"float16ToFloat\");\n+    StubGenStubId stub_id = StubGenStubId::hf2f_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -5838,1 +5989,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"floatToFloat16\");\n+    StubGenStubId stub_id = StubGenStubId::f2hf_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -5848,1 +6000,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"nmethod_entry_barrier\");\n+    StubGenStubId stub_id = StubGenStubId::method_entry_barrier_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -5913,3 +6066,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", isLL\n-        ? \"compare_long_string_same_encoding LL\"\n-        : \"compare_long_string_same_encoding UU\");\n+    StubGenStubId stub_id = (isLL ? StubGenStubId::compare_long_string_LL_id : StubGenStubId::compare_long_string_UU_id);\n+    StubCodeMark mark(this, stub_id);\n@@ -6045,0 +6197,9 @@\n+    StubGenStubId stub_id;\n+    switch (mode) {\n+      case LL: stub_id = StubGenStubId::compare_long_string_LL_id;  break;\n+      case LU: stub_id = StubGenStubId::compare_long_string_LU_id; break;\n+      case UL: stub_id = StubGenStubId::compare_long_string_UL_id; break;\n+      case UU: stub_id = StubGenStubId::compare_long_string_UU_id; break;\n+      default: ShouldNotReachHere();\n+    }\n+\n@@ -6080,10 +6241,1 @@\n-    const char* stubname;\n-    switch (mode) {\n-      case LL: stubname = \"compare_long_string_same_encoding LL\";      break;\n-      case LU: stubname = \"compare_long_string_different_encoding LU\"; break;\n-      case UL: stubname = \"compare_long_string_different_encoding UL\"; break;\n-      case UU: stubname = \"compare_long_string_same_encoding UU\";      break;\n-      default: ShouldNotReachHere();\n-    }\n-\n-    StubCodeMark mark(this, \"StubRoutines\", stubname);\n+    StubCodeMark mark(this, stub_id);\n@@ -6181,3 +6333,14 @@\n-    const char* stubName = str1_isL\n-        ? (str2_isL ? \"indexof_linear_ll\" : \"indexof_linear_ul\")\n-        : \"indexof_linear_uu\";\n+    StubGenStubId stub_id;\n+    if (str1_isL) {\n+      if (str2_isL) {\n+        stub_id = StubGenStubId::string_indexof_linear_ll_id;\n+      } else {\n+        stub_id = StubGenStubId::string_indexof_linear_ul_id;\n+      }\n+    } else {\n+      if (str2_isL) {\n+        ShouldNotReachHere();\n+      } else {\n+        stub_id = StubGenStubId::string_indexof_linear_uu_id;\n+      }\n+    }\n@@ -6185,1 +6348,1 @@\n-    StubCodeMark mark(this, \"StubRoutines\", stubName);\n+    StubCodeMark mark(this, stub_id);\n@@ -6483,1 +6646,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"large_byte_array_inflate\");\n+    StubGenStubId stub_id = StubGenStubId::large_byte_array_inflate_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -6548,1 +6712,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"ghash_processBlocks\");\n+    StubGenStubId stub_id = StubGenStubId::ghash_processBlocks_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -6614,1 +6779,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"ghash_processBlocks_wide\");\n+    StubGenStubId stub_id = StubGenStubId::ghash_processBlocks_wide_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -6725,1 +6891,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"encodeBlock\");\n+    StubGenStubId stub_id = StubGenStubId::base64_encodeBlock_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -6993,1 +7160,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"decodeBlock\");\n+    StubGenStubId stub_id = StubGenStubId::base64_decodeBlock_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -7109,1 +7277,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"spin_wait\");\n+    StubGenStubId stub_id = StubGenStubId::spin_wait_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -7118,2 +7287,3 @@\n-  address generate_lookup_secondary_supers_table_stub(u1 super_klass_index) {\n-    StubCodeMark mark(this, \"StubRoutines\", \"lookup_secondary_supers_table\");\n+  void generate_lookup_secondary_supers_table_stub() {\n+    StubGenStubId stub_id = StubGenStubId::lookup_secondary_supers_table_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -7121,1 +7291,0 @@\n-    address start = __ pc();\n@@ -7133,10 +7302,11 @@\n-    Label L_success;\n-    __ enter();\n-    __ lookup_secondary_supers_table_const(r_sub_klass, r_super_klass,\n-                                           r_array_base, r_array_length, r_array_index,\n-                                           vtemp, result, super_klass_index,\n-                                           \/*stub_is_near*\/true);\n-    __ leave();\n-    __ ret(lr);\n-\n-    return start;\n+    for (int slot = 0; slot < Klass::SECONDARY_SUPERS_TABLE_SIZE; slot++) {\n+      StubRoutines::_lookup_secondary_supers_table_stubs[slot] = __ pc();\n+      Label L_success;\n+      __ enter();\n+      __ lookup_secondary_supers_table_const(r_sub_klass, r_super_klass,\n+                                             r_array_base, r_array_length, r_array_index,\n+                                             vtemp, result, slot,\n+                                             \/*stub_is_near*\/true);\n+      __ leave();\n+      __ ret(lr);\n+    }\n@@ -7147,1 +7317,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"lookup_secondary_supers_table_slow_path\");\n+    StubGenStubId stub_id = StubGenStubId::lookup_secondary_supers_table_slow_path_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -7300,2 +7471,2 @@\n-\n-    StubCodeMark mark(this, \"StubRoutines\", \"atomic entry points\");\n+    StubGenStubId stub_id = StubGenStubId::atomic_entry_points_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -7461,1 +7632,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"Cont thaw\");\n+    StubGenStubId stub_id = StubGenStubId::cont_thaw_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -7471,1 +7643,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"cont return barrier\");\n+    StubGenStubId stub_id = StubGenStubId::cont_returnBarrier_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -7482,1 +7655,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"cont return barrier exception handler\");\n+    StubGenStubId stub_id = StubGenStubId::cont_returnBarrierExc_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -7492,1 +7666,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\",\"Continuation preempt stub\");\n+    StubGenStubId stub_id = StubGenStubId::cont_preempt_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -7574,1 +7749,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"poly1305_processBlocks\");\n+    StubGenStubId stub_id = StubGenStubId::poly1305_processBlocks_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -7688,1 +7864,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"upcall stub exception handler\");\n+    StubGenStubId stub_id = StubGenStubId::upcall_stub_exception_handler_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -7705,1 +7882,2 @@\n-    StubCodeMark mark(this, \"StubRoutines\", \"upcall_stub_load_target\");\n+    StubGenStubId stub_id = StubGenStubId::upcall_stub_load_target_id;\n+    StubCodeMark mark(this, stub_id);\n@@ -8830,3 +9008,2 @@\n-    if (UsePoly1305Intrinsics) {\n-      StubRoutines::_poly1305_processBlocks = generate_poly1305_processBlocks();\n-    }\n+    StubRoutines::_upcall_stub_exception_handler = generate_upcall_stub_exception_handler();\n+    StubRoutines::_upcall_stub_load_target = generate_upcall_stub_load_target();\n@@ -8844,4 +9021,1 @@\n-        for (int slot = 0; slot < Klass::SECONDARY_SUPERS_TABLE_SIZE; slot++) {\n-          StubRoutines::_lookup_secondary_supers_table_stubs[slot]\n-            = generate_lookup_secondary_supers_table_stub(slot);\n-        }\n+        generate_lookup_secondary_supers_table_stub();\n@@ -8852,3 +9026,0 @@\n-    StubRoutines::_upcall_stub_exception_handler = generate_upcall_stub_exception_handler();\n-    StubRoutines::_upcall_stub_load_target = generate_upcall_stub_load_target();\n-\n@@ -8862,1 +9033,1 @@\n-      StubRoutines::aarch64::_vector_iota_indices = generate_iota_indices(\"iota_indices\");\n+      StubRoutines::aarch64::_vector_iota_indices = generate_iota_indices(StubGenStubId::vector_iota_indices_id);\n@@ -8906,1 +9077,2 @@\n-      StubCodeMark mark(this, \"StubRoutines\", \"montgomeryMultiply\");\n+      StubGenStubId stub_id = StubGenStubId::montgomeryMultiply_id;\n+      StubCodeMark mark(this, stub_id);\n@@ -8912,1 +9084,2 @@\n-      StubCodeMark mark(this, \"StubRoutines\", \"montgomerySquare\");\n+      StubGenStubId stub_id = StubGenStubId::montgomerySquare_id;\n+      StubCodeMark mark(this, stub_id);\n@@ -8924,1 +9097,1 @@\n-      StubRoutines::_chacha20Block = generate_chacha20Block_blockpar();\n+      StubRoutines::_chacha20Block = generate_chacha20Block_qrpar();\n@@ -8952,2 +9125,2 @@\n-      StubRoutines::_md5_implCompress      = generate_md5_implCompress(false,    \"md5_implCompress\");\n-      StubRoutines::_md5_implCompressMB    = generate_md5_implCompress(true,     \"md5_implCompressMB\");\n+      StubRoutines::_md5_implCompress      = generate_md5_implCompress(StubGenStubId::md5_implCompress_id);\n+      StubRoutines::_md5_implCompressMB    = generate_md5_implCompress(StubGenStubId::md5_implCompressMB_id);\n@@ -8956,2 +9129,2 @@\n-      StubRoutines::_sha1_implCompress     = generate_sha1_implCompress(false,   \"sha1_implCompress\");\n-      StubRoutines::_sha1_implCompressMB   = generate_sha1_implCompress(true,    \"sha1_implCompressMB\");\n+      StubRoutines::_sha1_implCompress     = generate_sha1_implCompress(StubGenStubId::sha1_implCompress_id);\n+      StubRoutines::_sha1_implCompressMB   = generate_sha1_implCompress(StubGenStubId::sha1_implCompressMB_id);\n@@ -8960,2 +9133,2 @@\n-      StubRoutines::_sha256_implCompress   = generate_sha256_implCompress(false, \"sha256_implCompress\");\n-      StubRoutines::_sha256_implCompressMB = generate_sha256_implCompress(true,  \"sha256_implCompressMB\");\n+      StubRoutines::_sha256_implCompress   = generate_sha256_implCompress(StubGenStubId::sha256_implCompress_id);\n+      StubRoutines::_sha256_implCompressMB = generate_sha256_implCompress(StubGenStubId::sha256_implCompressMB_id);\n@@ -8964,2 +9137,2 @@\n-      StubRoutines::_sha512_implCompress   = generate_sha512_implCompress(false, \"sha512_implCompress\");\n-      StubRoutines::_sha512_implCompressMB = generate_sha512_implCompress(true,  \"sha512_implCompressMB\");\n+      StubRoutines::_sha512_implCompress   = generate_sha512_implCompress(StubGenStubId::sha512_implCompress_id);\n+      StubRoutines::_sha512_implCompressMB = generate_sha512_implCompress(StubGenStubId::sha512_implCompressMB_id);\n@@ -8968,2 +9141,6 @@\n-      StubRoutines::_sha3_implCompress     = generate_sha3_implCompress(false,   \"sha3_implCompress\");\n-      StubRoutines::_sha3_implCompressMB   = generate_sha3_implCompress(true,    \"sha3_implCompressMB\");\n+      StubRoutines::_sha3_implCompress     = generate_sha3_implCompress(StubGenStubId::sha3_implCompress_id);\n+      StubRoutines::_sha3_implCompressMB   = generate_sha3_implCompress(StubGenStubId::sha3_implCompressMB_id);\n+    }\n+\n+    if (UsePoly1305Intrinsics) {\n+      StubRoutines::_poly1305_processBlocks = generate_poly1305_processBlocks();\n@@ -8981,3 +9158,3 @@\n-  StubGenerator(CodeBuffer* code, StubsKind kind) : StubCodeGenerator(code) {\n-    switch(kind) {\n-    case Initial_stubs:\n+  StubGenerator(CodeBuffer* code, StubGenBlobId blob_id) : StubCodeGenerator(code, blob_id) {\n+    switch(blob_id) {\n+    case initial_id:\n@@ -8986,1 +9163,1 @@\n-     case Continuation_stubs:\n+     case continuation_id:\n@@ -8989,1 +9166,1 @@\n-    case Compiler_stubs:\n+    case compiler_id:\n@@ -8992,1 +9169,1 @@\n-    case Final_stubs:\n+    case final_id:\n@@ -8996,1 +9173,1 @@\n-      fatal(\"unexpected stubs kind: %d\", kind);\n+      fatal(\"unexpected blob id: %d\", blob_id);\n@@ -9002,2 +9179,2 @@\n-void StubGenerator_generate(CodeBuffer* code, StubCodeGenerator::StubsKind kind) {\n-  StubGenerator g(code, kind);\n+void StubGenerator_generate(CodeBuffer* code, StubGenBlobId blob_id) {\n+  StubGenerator g(code, blob_id);\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":721,"deletions":544,"binary":false,"changes":1265,"status":"modified"},{"patch":"@@ -3,1 +3,1 @@\n- * Copyright (c) 2012, 2024 SAP SE. All rights reserved.\n+ * Copyright (c) 2012, 2025 SAP SE. All rights reserved.\n@@ -51,1 +51,1 @@\n-const ConditionRegister LIR_Assembler::BOOL_RESULT = CCR5;\n+const ConditionRegister LIR_Assembler::BOOL_RESULT = CR5;\n@@ -159,2 +159,2 @@\n-        __ cmpdi(CCR0, R0, 0);\n-        __ bne(CCR0, L);\n+        __ cmpdi(CR0, R0, 0);\n+        __ bne(CR0, L);\n@@ -413,1 +413,1 @@\n-    __ cmpwi(CCR0, Rdivisor, -1);\n+    __ cmpwi(CR0, Rdivisor, -1);\n@@ -415,1 +415,1 @@\n-    __ cmpdi(CCR0, Rdivisor, -1);\n+    __ cmpdi(CR0, Rdivisor, -1);\n@@ -417,1 +417,1 @@\n-  __ bne(CCR0, regular);\n+  __ bne(CR0, regular);\n@@ -600,1 +600,1 @@\n-      __ fcmpu(CCR0, rsrc, rsrc);\n+      __ fcmpu(CR0, rsrc, rsrc);\n@@ -607,1 +607,1 @@\n-      __ bso(CCR0, L);\n+      __ bso(CR0, L);\n@@ -624,1 +624,1 @@\n-      __ fcmpu(CCR0, rsrc, rsrc);\n+      __ fcmpu(CR0, rsrc, rsrc);\n@@ -631,1 +631,1 @@\n-      __ bso(CCR0, L);\n+      __ bso(CR0, L);\n@@ -1533,1 +1533,1 @@\n-      __ fcmpu(CCR0, left->as_float_reg(), right->as_float_reg());\n+      __ fcmpu(CR0, left->as_float_reg(), right->as_float_reg());\n@@ -1535,1 +1535,1 @@\n-      __ fcmpu(CCR0, left->as_double_reg(), right->as_double_reg());\n+      __ fcmpu(CR0, left->as_double_reg(), right->as_double_reg());\n@@ -1541,1 +1541,1 @@\n-    __ cmpd(CCR0, left->as_register_lo(), right->as_register_lo());\n+    __ cmpd(CR0, left->as_register_lo(), right->as_register_lo());\n@@ -1896,2 +1896,2 @@\n-    __ cmpwi(CCR0, R3_RET, 0);\n-    __ bc_far_optimized(Assembler::bcondCRbiIs1, __ bi0(CCR0, Assembler::less), *stub->entry());\n+    __ cmpwi(CR0, R3_RET, 0);\n+    __ bc_far_optimized(Assembler::bcondCRbiIs1, __ bi0(CR0, Assembler::less), *stub->entry());\n@@ -1913,1 +1913,1 @@\n-    ConditionRegister combined_check = CCR1, tmp_check = CCR1;\n+    ConditionRegister combined_check = CR1, tmp_check = CR1;\n@@ -1918,1 +1918,1 @@\n-      tmp_check = CCR0;\n+      tmp_check = CR0;\n@@ -1926,1 +1926,1 @@\n-      tmp_check = CCR0;\n+      tmp_check = CR0;\n@@ -1932,1 +1932,1 @@\n-      tmp_check = CCR0;\n+      tmp_check = CR0;\n@@ -1963,2 +1963,2 @@\n-      __ cmpwi(CCR0, tmp2, Klass::_lh_neutral_value);\n-      __ bge(CCR0, slow);\n+      __ cmpwi(CR0, tmp2, Klass::_lh_neutral_value);\n+      __ bge(CR0, slow);\n@@ -1970,2 +1970,2 @@\n-      __ cmpwi(CCR0, tmp2, Klass::_lh_neutral_value);\n-      __ bge(CCR0, slow);\n+      __ cmpwi(CR0, tmp2, Klass::_lh_neutral_value);\n+      __ bge(CR0, slow);\n@@ -1982,2 +1982,2 @@\n-    __ cmpld(CCR0, tmp2, tmp);\n-    __ ble(CCR0, slow);\n+    __ cmpld(CR0, tmp2, tmp);\n+    __ ble(CR0, slow);\n@@ -1990,2 +1990,2 @@\n-    __ cmpld(CCR0, tmp2, tmp);\n-    __ ble(CCR0, slow);\n+    __ cmpld(CR0, tmp2, tmp);\n+    __ ble(CR0, slow);\n@@ -2006,2 +2006,2 @@\n-      __ cmp_klasses_from_objects(CCR0, src, dst, tmp, tmp2);\n-      __ beq(CCR0, cont);\n+      __ cmp_klasses_from_objects(CR0, src, dst, tmp, tmp2);\n+      __ beq(CR0, cont);\n@@ -2027,1 +2027,1 @@\n-      __ beq(CCR0, cont);\n+      __ beq(CR0, cont);\n@@ -2047,2 +2047,2 @@\n-          __ cmpw(CCR0, tmp, tmp2);\n-          __ bne(CCR0, slow);\n+          __ cmpw(CR0, tmp, tmp2);\n+          __ bne(CR0, slow);\n@@ -2083,2 +2083,2 @@\n-          __ cmpwi(CCR0, R3_RET, 0);\n-          __ bne(CCR0, failed);\n+          __ cmpwi(CR0, R3_RET, 0);\n+          __ bne(CR0, failed);\n@@ -2095,2 +2095,2 @@\n-        __ cmpwi(CCR0, R3_RET, 0);\n-        __ beq(CCR0, *stub->continuation());\n+        __ cmpwi(CR0, R3_RET, 0);\n+        __ beq(CR0, *stub->continuation());\n@@ -2129,1 +2129,1 @@\n-    __ cmp_klass(CCR0, dst, tmp, R11_scratch1, R12_scratch2);\n+    __ cmp_klass(CR0, dst, tmp, R11_scratch1, R12_scratch2);\n@@ -2131,3 +2131,3 @@\n-      __ bne(CCR0, halt);\n-      __ cmp_klass(CCR0, src, tmp, R11_scratch1, R12_scratch2);\n-      __ beq(CCR0, known_ok);\n+      __ bne(CR0, halt);\n+      __ cmp_klass(CR0, src, tmp, R11_scratch1, R12_scratch2);\n+      __ beq(CR0, known_ok);\n@@ -2135,3 +2135,3 @@\n-      __ beq(CCR0, known_ok);\n-      __ cmpw(CCR0, src, dst);\n-      __ beq(CCR0, known_ok);\n+      __ beq(CR0, known_ok);\n+      __ cmpw(CR0, src, dst);\n+      __ beq(CR0, known_ok);\n@@ -2272,2 +2272,2 @@\n-    __ cmpwi(CCR0, op->tmp1()->as_register(), InstanceKlass::fully_initialized);\n-    __ bc_far_optimized(Assembler::bcondCRbiIs0, __ bi0(CCR0, Assembler::equal), *op->stub()->entry());\n+    __ cmpwi(CR0, op->tmp1()->as_register(), InstanceKlass::fully_initialized);\n+    __ bc_far_optimized(Assembler::bcondCRbiIs0, __ bi0(CR0, Assembler::equal), *op->stub()->entry());\n@@ -2320,2 +2320,2 @@\n-    __ cmpd(CCR0, recv, tmp1);\n-    __ bne(CCR0, next_test);\n+    __ cmpd(CR0, recv, tmp1);\n+    __ bne(CR0, next_test);\n@@ -2335,2 +2335,2 @@\n-    __ cmpdi(CCR0, tmp1, 0);\n-    __ bne(CCR0, next_test);\n+    __ cmpdi(CR0, tmp1, 0);\n+    __ bne(CR0, next_test);\n@@ -2397,2 +2397,2 @@\n-    __ cmpdi(CCR0, obj, 0);\n-    __ bne(CCR0, not_null);\n+    __ cmpdi(CR0, obj, 0);\n+    __ bne(CR0, not_null);\n@@ -2415,2 +2415,2 @@\n-    __ cmpdi(CCR0, obj, 0);\n-    __ beq(CCR0, *obj_is_null);\n+    __ cmpdi(CR0, obj, 0);\n+    __ beq(CR0, *obj_is_null);\n@@ -2430,2 +2430,2 @@\n-    __ cmpd(CCR0, k_RInfo, klass_RInfo);\n-    __ beq(CCR0, *success);\n+    __ cmpd(CR0, k_RInfo, klass_RInfo);\n+    __ beq(CR0, *success);\n@@ -2465,1 +2465,1 @@\n-      __ beq(CCR0, *success);\n+      __ beq(CR0, *success);\n@@ -2504,2 +2504,2 @@\n-      __ cmpdi(CCR0, value, 0);\n-      __ bne(CCR0, not_null);\n+      __ cmpdi(CR0, value, 0);\n+      __ bne(CR0, not_null);\n@@ -2522,2 +2522,2 @@\n-      __ cmpdi(CCR0, value, 0);\n-      __ beq(CCR0, done);\n+      __ cmpdi(CR0, value, 0);\n+      __ beq(CR0, done);\n@@ -2546,1 +2546,1 @@\n-    __ beq(CCR0, done);\n+    __ beq(CR0, done);\n@@ -3027,1 +3027,1 @@\n-    __ bne_predict_not_taken(CCR0, Lretry);\n+    __ bne_predict_not_taken(CR0, Lretry);\n@@ -3029,1 +3029,1 @@\n-    __ bne(                  CCR0, Lretry);\n+    __ bne(                  CR0, Lretry);\n@@ -3066,2 +3066,2 @@\n-      __ cmpdi(CCR0, obj, 0);\n-      __ bne(CCR0, Lupdate);\n+      __ cmpdi(CR0, obj, 0);\n+      __ bne(CR0, Lupdate);\n@@ -3077,2 +3077,2 @@\n-        __ cmpdi(CCR0, obj, 0);\n-        __ beq(CCR0, Ldone);\n+        __ cmpdi(CR0, obj, 0);\n+        __ beq(CR0, Ldone);\n@@ -3083,2 +3083,2 @@\n-    __ cmpdi(CCR0, obj, 0);\n-    __ bne(CCR0, Lupdate);\n+    __ cmpdi(CR0, obj, 0);\n+    __ bne(CR0, Lupdate);\n@@ -3100,2 +3100,2 @@\n-      __ cmpd(CCR0, klass, R0);\n-      __ beq(CCR0, ok);\n+      __ cmpd(CR0, klass, R0);\n+      __ beq(CR0, ok);\n@@ -3121,1 +3121,1 @@\n-        __ cmpd(CCR1, R0, klass);\n+        __ cmpd(CR1, R0, klass);\n@@ -3123,1 +3123,1 @@\n-        \/\/beq(CCR1, do_nothing);\n+        \/\/beq(CR1, do_nothing);\n@@ -3127,3 +3127,3 @@\n-        \/\/bne(CCR0, do_nothing);\n-        __ crorc(CCR0, Assembler::equal, CCR1, Assembler::equal); \/\/ cr0 eq = cr1 eq or cr0 ne\n-        __ beq(CCR0, Lnext);\n+        \/\/bne(CR0, do_nothing);\n+        __ crorc(CR0, Assembler::equal, CR1, Assembler::equal); \/\/ cr0 eq = cr1 eq or cr0 ne\n+        __ beq(CR0, Lnext);\n@@ -3134,1 +3134,1 @@\n-          __ beq(CCR0, Ldo_update); \/\/ First time here. Set profile type.\n+          __ beq(CR0, Ldo_update); \/\/ First time here. Set profile type.\n@@ -3144,1 +3144,1 @@\n-        __ bne(CCR0, Lnext);\n+        __ bne(CR0, Lnext);\n@@ -3160,1 +3160,1 @@\n-        __ cmpd(CCR1, R0, klass);\n+        __ cmpd(CR1, R0, klass);\n@@ -3162,1 +3162,1 @@\n-        __ beq(CCR1, Lnext);\n+        __ beq(CR1, Lnext);\n@@ -3167,1 +3167,1 @@\n-          __ beq(CCR0, ok); \/\/ First time here.\n+          __ beq(CR0, ok); \/\/ First time here.\n@@ -3181,1 +3181,1 @@\n-        __ bne(CCR0, Lnext);\n+        __ bne(CR0, Lnext);\n","filename":"src\/hotspot\/cpu\/ppc\/c1_LIRAssembler_ppc.cpp","additions":83,"deletions":83,"binary":false,"changes":166,"status":"modified"},{"patch":"@@ -3,1 +3,1 @@\n- * Copyright (c) 2012, 2024 SAP SE. All rights reserved.\n+ * Copyright (c) 2012, 2025 SAP SE. All rights reserved.\n@@ -129,1 +129,1 @@\n-    beq(CCR0, L);\n+    beq(CR0, L);\n@@ -132,1 +132,1 @@\n-    bne(CCR0, L);\n+    bne(CR0, L);\n@@ -153,2 +153,2 @@\n-    cmpdi(CCR0, Rthr_state_addr, 0);\n-    beq(CCR0, Lno_early_ret);\n+    cmpdi(CR0, Rthr_state_addr, 0);\n+    beq(CR0, Lno_early_ret);\n@@ -157,2 +157,2 @@\n-    cmpwi(CCR0, R0, JvmtiThreadState::earlyret_pending);\n-    bne(CCR0, Lno_early_ret);\n+    cmpwi(CR0, R0, JvmtiThreadState::earlyret_pending);\n+    bne(CR0, Lno_early_ret);\n@@ -232,1 +232,1 @@\n-      beq(CCR0, dispatch);\n+      beq(CR0, dispatch);\n@@ -531,2 +531,2 @@\n-  cmpd(CCR0, index, R0);\n-  blt(CCR0, index_ok);\n+  cmpd(CR0, index, R0);\n+  blt(CR0, index_ok);\n@@ -595,2 +595,2 @@\n-    cmpdi(CCR0, Rarray, 0);\n-    beq(CCR0, LisNull);\n+    cmpdi(CR0, Rarray, 0);\n+    beq(CR0, LisNull);\n@@ -608,1 +608,1 @@\n-  cmplw(CCR0, Rindex, Rlength);\n+  cmplw(CR0, Rindex, Rlength);\n@@ -610,1 +610,1 @@\n-  blt(CCR0, LnotOOR);\n+  blt(CR0, LnotOOR);\n@@ -690,2 +690,2 @@\n-    testbitdi(CCR0, R0, Raccess_flags, JVM_ACC_SYNCHRONIZED_BIT);\n-    beq(CCR0, Lunlocked);\n+    testbitdi(CR0, R0, Raccess_flags, JVM_ACC_SYNCHRONIZED_BIT);\n+    beq(CR0, Lunlocked);\n@@ -693,2 +693,2 @@\n-    cmpwi(CCR0, Rdo_not_unlock_flag, 0);\n-    bne(CCR0, Lno_unlock);\n+    cmpwi(CR0, Rdo_not_unlock_flag, 0);\n+    bne(CR0, Lno_unlock);\n@@ -708,2 +708,2 @@\n-    cmpdi(CCR0, R0, 0);\n-    bne(CCR0, Lunlock);\n+    cmpdi(CR0, R0, 0);\n+    bne(CR0, Lunlock);\n@@ -743,1 +743,1 @@\n-      ble(CCR0, Lno_unlock);\n+      ble(CR0, Lno_unlock);\n@@ -762,2 +762,2 @@\n-      cmpdi(CCR0, Rcurrent_obj, 0);\n-      bne(CCR0, Lexception);\n+      cmpdi(CR0, Rcurrent_obj, 0);\n+      bne(CR0, Lexception);\n@@ -819,2 +819,2 @@\n-  cmpwi(CCR0, ret_type, T_INT);\n-  beq(CCR0, done);\n+  cmpwi(CR0, ret_type, T_INT);\n+  beq(CR0, done);\n@@ -822,2 +822,2 @@\n-  cmpwi(CCR0, ret_type, T_BOOLEAN);\n-  bne(CCR0, notBool);\n+  cmpwi(CR0, ret_type, T_BOOLEAN);\n+  bne(CR0, notBool);\n@@ -828,2 +828,2 @@\n-  cmpwi(CCR0, ret_type, T_BYTE);\n-  bne(CCR0, notByte);\n+  cmpwi(CR0, ret_type, T_BYTE);\n+  bne(CR0, notByte);\n@@ -834,2 +834,2 @@\n-  cmpwi(CCR0, ret_type, T_CHAR);\n-  bne(CCR0, notChar);\n+  cmpwi(CR0, ret_type, T_CHAR);\n+  bne(CR0, notChar);\n@@ -840,2 +840,2 @@\n-  \/\/ cmpwi(CCR0, ret_type, T_SHORT);  \/\/ all that's left\n-  \/\/ bne(CCR0, done);\n+  \/\/ cmpwi(CR0, ret_type, T_SHORT);  \/\/ all that's left\n+  \/\/ bne(CR0, done);\n@@ -896,2 +896,2 @@\n-    cmpwi(CCR0, R0, StackOverflow::stack_guard_enabled);\n-    beq_predict_taken(CCR0, no_reserved_zone_enabling);\n+    cmpwi(CR0, R0, StackOverflow::stack_guard_enabled);\n+    beq_predict_taken(CR0, no_reserved_zone_enabling);\n@@ -905,2 +905,2 @@\n-    cmpld(CCR0, R11_scratch1, R0);\n-    blt_predict_taken(CCR0, no_reserved_zone_enabling);\n+    cmpld(CR0, R11_scratch1, R0);\n+    blt_predict_taken(CR0, no_reserved_zone_enabling);\n@@ -964,2 +964,2 @@\n-      testbitdi(CCR0, R0, tmp, exact_log2(KlassFlags::_misc_is_value_based_class));\n-      bne(CCR0, slow_case);\n+      testbitdi(CR0, R0, tmp, exact_log2(KlassFlags::_misc_is_value_based_class));\n+      bne(CR0, slow_case);\n@@ -992,2 +992,2 @@\n-      \/\/ CmpxchgX sets CCR0 to cmpX(current, displaced).\n-      cmpxchgd(\/*flag=*\/CCR0,\n+      \/\/ CmpxchgX sets CR0 to cmpX(current, displaced).\n+      cmpxchgd(\/*flag=*\/CR0,\n@@ -1024,1 +1024,1 @@\n-      bne(CCR0, slow_case);\n+      bne(CR0, slow_case);\n@@ -1090,2 +1090,2 @@\n-      cmpdi(CCR0, header, 0);\n-      beq(CCR0, free_slot); \/\/ recursive unlock\n+      cmpdi(CR0, header, 0);\n+      beq(CR0, free_slot); \/\/ recursive unlock\n@@ -1111,2 +1111,2 @@\n-      \/\/ CmpxchgX sets CCR0 to cmpX(current, monitor).\n-      cmpxchgd(\/*flag=*\/CCR0,\n+      \/\/ CmpxchgX sets CR0 to cmpX(current, monitor).\n+      cmpxchgd(\/*flag=*\/CR0,\n@@ -1173,2 +1173,2 @@\n-    cmpwi(CCR0, Rinterp_only, 0);\n-    beq(CCR0, done);\n+    cmpwi(CR0, Rinterp_only, 0);\n+    beq(CR0, done);\n@@ -1183,2 +1183,2 @@\n-    cmpdi(CCR0, Rtarget_addr, 0);\n-    bne(CCR0, Lok);\n+    cmpdi(CR0, Rtarget_addr, 0);\n+    bne(CR0, Lok);\n@@ -1214,1 +1214,1 @@\n-  cmpd(CCR0, R21_sender_SP, Rscratch1);\n+  cmpd(CR0, R21_sender_SP, Rscratch1);\n@@ -1237,2 +1237,2 @@\n-  cmpdi(CCR0, R28_mdx, 0);\n-  beq(CCR0, zero_continue);\n+  cmpdi(CR0, R28_mdx, 0);\n+  beq(CR0, zero_continue);\n@@ -1253,2 +1253,2 @@\n-  cmpd(CCR0, R11_scratch1, R14_bcp);\n-  beq(CCR0, verify_continue);\n+  cmpd(CR0, R11_scratch1, R14_bcp);\n+  beq(CR0, verify_continue);\n@@ -1337,2 +1337,2 @@\n-  cmpd(CCR0,  value, test_out);\n-  bne(CCR0, not_equal_continue);\n+  cmpd(CR0,  value, test_out);\n+  bne(CR0, not_equal_continue);\n@@ -1494,2 +1494,2 @@\n-    cmpdi(CCR0, Rreceiver, 0);\n-    bne(CCR0, not_null);\n+    cmpdi(CR0, Rreceiver, 0);\n+    bne(CR0, not_null);\n@@ -1684,2 +1684,2 @@\n-        cmpdi(CCR0, scratch1, 0);\n-        beq(CCR0, found_null);\n+        cmpdi(CR0, scratch1, 0);\n+        beq(CR0, found_null);\n@@ -1694,2 +1694,2 @@\n-      cmpdi(CCR0, scratch1, 0);\n-      beq(CCR0, found_null);\n+      cmpdi(CR0, scratch1, 0);\n+      beq(CR0, found_null);\n@@ -1737,1 +1737,1 @@\n-  cmpdi(CCR0, obj, 0);\n+  cmpdi(CR0, obj, 0);\n@@ -1739,1 +1739,1 @@\n-  beq(CCR0, do_update);\n+  beq(CR0, do_update);\n@@ -1745,1 +1745,1 @@\n-  cmpd(CCR1, R0, klass);\n+  cmpd(CR1, R0, klass);\n@@ -1747,1 +1747,1 @@\n-  \/\/beq(CCR1, do_nothing);\n+  \/\/beq(CR1, do_nothing);\n@@ -1751,3 +1751,3 @@\n-  \/\/bne(CCR0, do_nothing);\n-  crorc(CCR0, Assembler::equal, CCR1, Assembler::equal); \/\/ cr0 eq = cr1 eq or cr0 ne\n-  beq(CCR0, do_nothing);\n+  \/\/bne(CR0, do_nothing);\n+  crorc(CR0, Assembler::equal, CR1, Assembler::equal); \/\/ cr0 eq = cr1 eq or cr0 ne\n+  beq(CR0, do_nothing);\n@@ -1757,1 +1757,1 @@\n-  beq(CCR0, do_update); \/\/ First time here. Set profile type.\n+  beq(CR0, do_update); \/\/ First time here. Set profile type.\n@@ -1788,2 +1788,2 @@\n-    cmpwi(CCR0, tmp1, is_virtual ? DataLayout::virtual_call_type_data_tag : DataLayout::call_type_data_tag);\n-    bne(CCR0, profile_continue);\n+    cmpwi(CR0, tmp1, is_virtual ? DataLayout::virtual_call_type_data_tag : DataLayout::call_type_data_tag);\n+    bne(CR0, profile_continue);\n@@ -1800,1 +1800,1 @@\n-          cmpdi(CCR0, tmp1, (i+1)*TypeStackSlotEntries::per_arg_count());\n+          cmpdi(CR0, tmp1, (i+1)*TypeStackSlotEntries::per_arg_count());\n@@ -1802,1 +1802,1 @@\n-          blt(CCR0, done);\n+          blt(CR0, done);\n@@ -1868,6 +1868,6 @@\n-      cmpwi(CCR0, tmp1, Bytecodes::_invokedynamic);\n-      cmpwi(CCR1, tmp1, Bytecodes::_invokehandle);\n-      cror(CCR0, Assembler::equal, CCR1, Assembler::equal);\n-      cmpwi(CCR1, tmp2, static_cast<int>(vmIntrinsics::_compiledLambdaForm));\n-      cror(CCR0, Assembler::equal, CCR1, Assembler::equal);\n-      bne(CCR0, profile_continue);\n+      cmpwi(CR0, tmp1, Bytecodes::_invokedynamic);\n+      cmpwi(CR1, tmp1, Bytecodes::_invokehandle);\n+      cror(CR0, Assembler::equal, CR1, Assembler::equal);\n+      cmpwi(CR1, tmp2, static_cast<int>(vmIntrinsics::_compiledLambdaForm));\n+      cror(CR0, Assembler::equal, CR1, Assembler::equal);\n+      bne(CR0, profile_continue);\n@@ -1893,2 +1893,2 @@\n-    cmpwi(CCR0, tmp1, 0);\n-    blt(CCR0, profile_continue);\n+    cmpwi(CR0, tmp1, 0);\n+    blt(CR0, profile_continue);\n@@ -1939,1 +1939,1 @@\n-    cmpdi(CCR0, entry_offset, off_base + delta);\n+    cmpdi(CR0, entry_offset, off_base + delta);\n@@ -1941,1 +1941,1 @@\n-    bge(CCR0, loop);\n+    bge(CR0, loop);\n@@ -1978,1 +1978,1 @@\n-    beq(CCR0, copy_slot_finished);                     \/\/ Nothing to copy.\n+    beq(CR0, copy_slot_finished);                     \/\/ Nothing to copy.\n@@ -2118,2 +2118,2 @@\n-  cmpdi(CCR0, Rexception, 0);\n-  beq(CCR0, Ldone);\n+  cmpdi(CR0, Rexception, 0);\n+  beq(CR0, Ldone);\n@@ -2171,1 +2171,1 @@\n-  DEBUG_ONLY(cmpdi(CCR0, R0, 0));\n+  DEBUG_ONLY(cmpdi(CR0, R0, 0));\n@@ -2189,2 +2189,2 @@\n-  cmpdi(CCR0, R0, 0);\n-  beq(CCR0, not_preempted);\n+  cmpdi(CR0, R0, 0);\n+  beq(CR0, not_preempted);\n@@ -2218,2 +2218,2 @@\n-    cmpd(CCR0, R12_scratch2, R11_scratch1);\n-    beq(CCR0, ok);\n+    cmpd(CR0, R12_scratch2, R11_scratch1);\n+    beq(CR0, ok);\n@@ -2301,2 +2301,2 @@\n-    cmpdi(CCR0, R0, frame::top_ijava_frame_abi_size + frame::ijava_state_size);\n-    bge(CCR0, Lok);\n+    cmpdi(CR0, R0, frame::top_ijava_frame_abi_size + frame::ijava_state_size);\n+    bge(CR0, Lok);\n@@ -2315,2 +2315,2 @@\n-  cmpdi(CCR0, Rcounters, 0);\n-  bne(CCR0, has_counters);\n+  cmpdi(CR0, Rcounters, 0);\n+  bne(CR0, has_counters);\n@@ -2320,2 +2320,2 @@\n-  cmpdi(CCR0, Rcounters, 0);\n-  beq(CCR0, skip); \/\/ No MethodCounters, OutOfMemory.\n+  cmpdi(CR0, Rcounters, 0);\n+  beq(CR0, skip); \/\/ No MethodCounters, OutOfMemory.\n@@ -2401,1 +2401,1 @@\n-  bne(CCR0, test);\n+  bne(CR0, test);\n@@ -2445,2 +2445,2 @@\n-    cmpwi(CCR0, R0, 0);\n-    beq(CCR0, jvmti_post_done);\n+    cmpwi(CR0, R0, 0);\n+    beq(CR0, jvmti_post_done);\n@@ -2479,2 +2479,2 @@\n-    cmpwi(CCR0, R0, 0);\n-    beq(CCR0, jvmti_post_done);\n+    cmpwi(CR0, R0, 0);\n+    beq(CR0, jvmti_post_done);\n","filename":"src\/hotspot\/cpu\/ppc\/interp_masm_ppc_64.cpp","additions":104,"deletions":104,"binary":false,"changes":208,"status":"modified"},{"patch":"@@ -9932,2 +9932,2 @@\n-    const_or_pre_comp_const_index[1] = *(uint32_t *)StubRoutines::_crc32c_table_addr;\n-    const_or_pre_comp_const_index[0] = *((uint32_t *)StubRoutines::_crc32c_table_addr+1);\n+    const_or_pre_comp_const_index[1] = *(uint32_t *)StubRoutines::crc32c_table_addr();\n+    const_or_pre_comp_const_index[0] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 1);\n@@ -9935,2 +9935,2 @@\n-    const_or_pre_comp_const_index[3] = *((uint32_t *)StubRoutines::_crc32c_table_addr + 2);\n-    const_or_pre_comp_const_index[2] = *((uint32_t *)StubRoutines::_crc32c_table_addr + 3);\n+    const_or_pre_comp_const_index[3] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 2);\n+    const_or_pre_comp_const_index[2] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 3);\n@@ -9938,2 +9938,2 @@\n-    const_or_pre_comp_const_index[5] = *((uint32_t *)StubRoutines::_crc32c_table_addr + 4);\n-    const_or_pre_comp_const_index[4] = *((uint32_t *)StubRoutines::_crc32c_table_addr + 5);\n+    const_or_pre_comp_const_index[5] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 4);\n+    const_or_pre_comp_const_index[4] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 5);\n@@ -10012,2 +10012,2 @@\n-    const_or_pre_comp_const_index[1] = *(uint32_t *)StubRoutines::_crc32c_table_addr;\n-    const_or_pre_comp_const_index[0] = *((uint32_t *)StubRoutines::_crc32c_table_addr + 1);\n+    const_or_pre_comp_const_index[1] = *(uint32_t *)StubRoutines::crc32c_table_addr();\n+    const_or_pre_comp_const_index[0] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 1);\n@@ -10015,2 +10015,2 @@\n-    const_or_pre_comp_const_index[3] = *((uint32_t *)StubRoutines::_crc32c_table_addr + 2);\n-    const_or_pre_comp_const_index[2] = *((uint32_t *)StubRoutines::_crc32c_table_addr + 3);\n+    const_or_pre_comp_const_index[3] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 2);\n+    const_or_pre_comp_const_index[2] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 3);\n@@ -10018,2 +10018,2 @@\n-    const_or_pre_comp_const_index[5] = *((uint32_t *)StubRoutines::_crc32c_table_addr + 4);\n-    const_or_pre_comp_const_index[4] = *((uint32_t *)StubRoutines::_crc32c_table_addr + 5);\n+    const_or_pre_comp_const_index[5] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 4);\n+    const_or_pre_comp_const_index[4] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 5);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":12,"deletions":12,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -193,1 +193,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"call_stub\");\n+  StubGenStubId stub_id = StubGenStubId::call_stub_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -431,1 +432,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"catch_exception\");\n+  StubGenStubId stub_id = StubGenStubId::catch_exception_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -486,1 +488,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"forward exception\");\n+  StubGenStubId stub_id = StubGenStubId::forward_exception_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -549,1 +552,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"orderaccess_fence\");\n+  StubGenStubId stub_id = StubGenStubId::fence_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -564,1 +568,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"get_previous_sp\");\n+  StubGenStubId stub_id = StubGenStubId::get_previous_sp_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -582,1 +587,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"verify_mxcsr\");\n+  StubGenStubId stub_id = StubGenStubId::verify_mxcsr_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -613,1 +619,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"f2i_fixup\");\n+  StubGenStubId stub_id = StubGenStubId::f2i_fixup_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -651,1 +658,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"f2l_fixup\");\n+  StubGenStubId stub_id = StubGenStubId::f2l_fixup_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -688,1 +696,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"d2i_fixup\");\n+  StubGenStubId stub_id = StubGenStubId::d2i_fixup_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -735,1 +744,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"d2l_fixup\");\n+  StubGenStubId stub_id = StubGenStubId::d2l_fixup_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -781,1 +791,1 @@\n-address StubGenerator::generate_count_leading_zeros_lut(const char *stub_name) {\n+address StubGenerator::generate_count_leading_zeros_lut() {\n@@ -783,1 +793,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+  StubGenStubId stub_id = StubGenStubId::vector_count_leading_zeros_lut_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -798,1 +809,1 @@\n-address StubGenerator::generate_popcount_avx_lut(const char *stub_name) {\n+address StubGenerator::generate_popcount_avx_lut() {\n@@ -800,1 +811,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+  StubGenStubId stub_id = StubGenStubId::vector_popcount_lut_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -815,1 +827,1 @@\n-address StubGenerator::generate_iota_indices(const char *stub_name) {\n+address StubGenerator::generate_iota_indices() {\n@@ -817,1 +829,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+  StubGenStubId stub_id = StubGenStubId::vector_iota_indices_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -876,1 +889,1 @@\n-address StubGenerator::generate_vector_reverse_bit_lut(const char *stub_name) {\n+address StubGenerator::generate_vector_reverse_bit_lut() {\n@@ -878,1 +891,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+  StubGenStubId stub_id = StubGenStubId::vector_reverse_bit_lut_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -893,1 +907,1 @@\n-address StubGenerator::generate_vector_reverse_byte_perm_mask_long(const char *stub_name) {\n+address StubGenerator::generate_vector_reverse_byte_perm_mask_long() {\n@@ -895,1 +909,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+  StubGenStubId stub_id = StubGenStubId::vector_reverse_byte_perm_mask_long_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -910,1 +925,1 @@\n-address StubGenerator::generate_vector_reverse_byte_perm_mask_int(const char *stub_name) {\n+address StubGenerator::generate_vector_reverse_byte_perm_mask_int() {\n@@ -912,1 +927,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+  StubGenStubId stub_id = StubGenStubId::vector_reverse_byte_perm_mask_int_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -927,1 +943,1 @@\n-address StubGenerator::generate_vector_reverse_byte_perm_mask_short(const char *stub_name) {\n+address StubGenerator::generate_vector_reverse_byte_perm_mask_short() {\n@@ -929,1 +945,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+  StubGenStubId stub_id = StubGenStubId::vector_reverse_byte_perm_mask_short_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -944,1 +961,1 @@\n-address StubGenerator::generate_vector_byte_shuffle_mask(const char *stub_name) {\n+address StubGenerator::generate_vector_byte_shuffle_mask() {\n@@ -946,1 +963,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+  StubGenStubId stub_id = StubGenStubId::vector_byte_shuffle_mask_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -957,1 +975,1 @@\n-address StubGenerator::generate_fp_mask(const char *stub_name, int64_t mask) {\n+address StubGenerator::generate_fp_mask(StubGenStubId stub_id, int64_t mask) {\n@@ -959,1 +977,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+  StubCodeMark mark(this, stub_id);\n@@ -968,1 +986,12 @@\n-address StubGenerator::generate_compress_perm_table(const char *stub_name, int32_t esize) {\n+address StubGenerator::generate_compress_perm_table(StubGenStubId stub_id) {\n+  int esize;\n+  switch (stub_id) {\n+  case compress_perm_table32_id:\n+    esize = 32;\n+    break;\n+  case compress_perm_table64_id:\n+    esize = 64;\n+    break;\n+  default:\n+    ShouldNotReachHere();\n+  }\n@@ -970,1 +999,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+  StubCodeMark mark(this, stub_id);\n@@ -1012,1 +1041,12 @@\n-address StubGenerator::generate_expand_perm_table(const char *stub_name, int32_t esize) {\n+address StubGenerator::generate_expand_perm_table(StubGenStubId stub_id) {\n+  int esize;\n+  switch (stub_id) {\n+  case expand_perm_table32_id:\n+    esize = 32;\n+    break;\n+  case expand_perm_table64_id:\n+    esize = 64;\n+    break;\n+  default:\n+    ShouldNotReachHere();\n+  }\n@@ -1014,1 +1054,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+  StubCodeMark mark(this, stub_id);\n@@ -1054,1 +1094,1 @@\n-address StubGenerator::generate_vector_mask(const char *stub_name, int64_t mask) {\n+address StubGenerator::generate_vector_mask(StubGenStubId stub_id, int64_t mask) {\n@@ -1056,1 +1096,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+  StubCodeMark mark(this, stub_id);\n@@ -1071,1 +1111,1 @@\n-address StubGenerator::generate_vector_byte_perm_mask(const char *stub_name) {\n+address StubGenerator::generate_vector_byte_perm_mask() {\n@@ -1073,1 +1113,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+  StubGenStubId stub_id = StubGenStubId::vector_byte_perm_mask_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -1088,1 +1129,1 @@\n-address StubGenerator::generate_vector_fp_mask(const char *stub_name, int64_t mask) {\n+address StubGenerator::generate_vector_fp_mask(StubGenStubId stub_id, int64_t mask) {\n@@ -1090,1 +1131,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+  StubCodeMark mark(this, stub_id);\n@@ -1105,1 +1146,1 @@\n-address StubGenerator::generate_vector_custom_i32(const char *stub_name, Assembler::AvxVectorLen len,\n+address StubGenerator::generate_vector_custom_i32(StubGenStubId stub_id, Assembler::AvxVectorLen len,\n@@ -1111,1 +1152,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+  StubCodeMark mark(this, stub_id);\n@@ -1155,1 +1196,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"verify_oop\");\n+  StubGenStubId stub_id = StubGenStubId::verify_oop_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -1352,1 +1394,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"_data_cache_writeback\");\n+  StubGenStubId stub_id = StubGenStubId::data_cache_writeback_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -1369,1 +1412,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"_data_cache_writeback_sync\");\n+  StubGenStubId stub_id = StubGenStubId::data_cache_writeback_sync_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -1390,1 +1434,12 @@\n-address StubGenerator::generate_md5_implCompress(bool multi_block, const char *name) {\n+address StubGenerator::generate_md5_implCompress(StubGenStubId stub_id) {\n+  bool multi_block;\n+  switch (stub_id) {\n+  case md5_implCompress_id:\n+    multi_block = false;\n+    break;\n+  case md5_implCompressMB_id:\n+    multi_block = true;\n+    break;\n+  default:\n+    ShouldNotReachHere();\n+  }\n@@ -1392,1 +1447,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubCodeMark mark(this, stub_id);\n@@ -1428,1 +1483,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"upper_word_mask\");\n+  StubGenStubId stub_id = StubGenStubId::upper_word_mask_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -1439,1 +1495,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"shuffle_byte_flip_mask\");\n+  StubGenStubId stub_id = StubGenStubId::shuffle_byte_flip_mask_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -1450,1 +1507,12 @@\n-address StubGenerator::generate_sha1_implCompress(bool multi_block, const char *name) {\n+address StubGenerator::generate_sha1_implCompress(StubGenStubId stub_id) {\n+  bool multi_block;\n+  switch (stub_id) {\n+  case sha1_implCompress_id:\n+    multi_block = false;\n+    break;\n+  case sha1_implCompressMB_id:\n+    multi_block = true;\n+    break;\n+  default:\n+    ShouldNotReachHere();\n+  }\n@@ -1452,1 +1520,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubCodeMark mark(this, stub_id);\n@@ -1487,1 +1555,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"pshuffle_byte_flip_mask\");\n+  StubGenStubId stub_id = StubGenStubId::pshuffle_byte_flip_mask_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -1514,1 +1583,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"pshuffle_byte_flip_mask_sha512\");\n+  StubGenStubId stub_id = StubGenStubId::pshuffle_byte_flip_mask_sha512_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -1533,1 +1603,12 @@\n-address StubGenerator::generate_sha256_implCompress(bool multi_block, const char *name) {\n+address StubGenerator::generate_sha256_implCompress(StubGenStubId stub_id) {\n+  bool multi_block;\n+  switch (stub_id) {\n+  case sha256_implCompress_id:\n+    multi_block = false;\n+    break;\n+  case sha256_implCompressMB_id:\n+    multi_block = true;\n+    break;\n+  default:\n+    ShouldNotReachHere();\n+  }\n@@ -1536,1 +1617,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubCodeMark mark(this, stub_id);\n@@ -1575,1 +1656,12 @@\n-address StubGenerator::generate_sha512_implCompress(bool multi_block, const char *name) {\n+address StubGenerator::generate_sha512_implCompress(StubGenStubId stub_id) {\n+  bool multi_block;\n+  switch (stub_id) {\n+  case sha512_implCompress_id:\n+    multi_block = false;\n+    break;\n+  case sha512_implCompressMB_id:\n+    multi_block = true;\n+    break;\n+  default:\n+    ShouldNotReachHere();\n+  }\n@@ -1579,1 +1671,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubCodeMark mark(this, stub_id);\n@@ -1614,1 +1706,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"shuffle_base64\");\n+  StubGenStubId stub_id = StubGenStubId::shuffle_base64_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -1633,1 +1726,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"avx2_shuffle_base64\");\n+  StubGenStubId stub_id = StubGenStubId::avx2_shuffle_base64_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -1646,1 +1740,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"avx2_input_mask_base64\");\n+  StubGenStubId stub_id = StubGenStubId::avx2_input_mask_base64_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -1659,1 +1754,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"avx2_lut_base64\");\n+  StubGenStubId stub_id = StubGenStubId::avx2_lut_base64_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -1678,1 +1774,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"encoding_table_base64\");\n+  StubGenStubId stub_id = StubGenStubId::encoding_table_base64_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -1711,1 +1808,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"implEncode\");\n+  StubGenStubId stub_id = StubGenStubId::base64_encodeBlock_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -2093,1 +2191,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"lookup_lo_base64\");\n+  StubGenStubId stub_id = StubGenStubId::lookup_lo_base64_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -2112,1 +2211,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"lookup_hi_base64\");\n+  StubGenStubId stub_id = StubGenStubId::lookup_hi_base64_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -2130,1 +2230,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"lookup_lo_base64url\");\n+  StubGenStubId stub_id = StubGenStubId::lookup_lo_base64url_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -2149,1 +2250,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"lookup_hi_base64url\");\n+  StubGenStubId stub_id = StubGenStubId::lookup_hi_base64url_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -2168,1 +2270,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"pack_vec_base64\");\n+  StubGenStubId stub_id = StubGenStubId::pack_vec_base64_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -2187,1 +2290,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"join_0_1_base64\");\n+  StubGenStubId stub_id = StubGenStubId::join_0_1_base64_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -2206,1 +2310,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"join_1_2_base64\");\n+  StubGenStubId stub_id = StubGenStubId::join_1_2_base64_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -2225,1 +2330,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"join_2_3_base64\");\n+  StubGenStubId stub_id = StubGenStubId::join_2_3_base64_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -2244,1 +2350,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"AVX2_tables_base64\");\n+  StubGenStubId stub_id = StubGenStubId::avx2_decode_tables_base64_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -2278,1 +2385,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"AVX2_tables_URL_base64\");\n+  StubGenStubId stub_id = StubGenStubId::avx2_decode_lut_tables_base64_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -2317,1 +2425,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"decoding_table_base64\");\n+  StubGenStubId stub_id = StubGenStubId::decoding_table_base64_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -2399,1 +2508,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"implDecode\");\n+  StubGenStubId stub_id = StubGenStubId::base64_decodeBlock_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -2932,1 +3042,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"updateBytesCRC32\");\n+  StubGenStubId stub_id = StubGenStubId::updateBytesCRC32_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -2988,1 +3099,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"updateBytesCRC32C\");\n+  StubGenStubId stub_id = StubGenStubId::updateBytesCRC32C_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -3068,1 +3180,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"multiplyToLen\");\n+  StubGenStubId stub_id = StubGenStubId::multiplyToLen_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -3124,1 +3237,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"vectorizedMismatch\");\n+  StubGenStubId stub_id = StubGenStubId::vectorizedMismatch_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -3175,1 +3289,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"squareToLen\");\n+  StubGenStubId stub_id = StubGenStubId::squareToLen_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -3210,1 +3325,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"nmethod_entry_barrier\");\n+  StubGenStubId stub_id = StubGenStubId::method_entry_barrier_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -3299,1 +3415,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"mulAdd\");\n+  StubGenStubId stub_id = StubGenStubId::mulAdd_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -3340,1 +3457,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"bigIntegerRightShiftWorker\");\n+  StubGenStubId stub_id = StubGenStubId::bigIntegerRightShiftWorker_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -3475,1 +3593,2 @@\n-  StubCodeMark mark(this,  \"StubRoutines\", \"bigIntegerLeftShiftWorker\");\n+  StubGenStubId stub_id = StubGenStubId::bigIntegerLeftShiftWorker_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -3623,1 +3742,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"float16ToFloat\");\n+  StubGenStubId stub_id = StubGenStubId::hf2f_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -3648,1 +3768,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"floatToFloat16\");\n+  StubGenStubId stub_id = StubGenStubId::f2hf_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -3663,1 +3784,1 @@\n-address StubGenerator::generate_cont_thaw(const char* label, Continuation::thaw_kind kind) {\n+address StubGenerator::generate_cont_thaw(StubGenStubId stub_id) {\n@@ -3666,4 +3787,24 @@\n-  bool return_barrier = Continuation::is_thaw_return_barrier(kind);\n-  bool return_barrier_exception = Continuation::is_thaw_return_barrier_exception(kind);\n-\n-  StubCodeMark mark(this, \"StubRoutines\", label);\n+  bool return_barrier;\n+  bool return_barrier_exception;\n+  Continuation::thaw_kind kind;\n+\n+  switch (stub_id) {\n+  case cont_thaw_id:\n+    return_barrier = false;\n+    return_barrier_exception = false;\n+    kind = Continuation::thaw_top;\n+    break;\n+  case cont_returnBarrier_id:\n+    return_barrier = true;\n+    return_barrier_exception = false;\n+    kind = Continuation::thaw_return_barrier;\n+    break;\n+  case cont_returnBarrierExc_id:\n+    return_barrier = true;\n+    return_barrier_exception = true;\n+    kind = Continuation::thaw_return_barrier_exception;\n+    break;\n+  default:\n+    ShouldNotReachHere();\n+  }\n+  StubCodeMark mark(this, stub_id);\n@@ -3787,1 +3928,1 @@\n-  return generate_cont_thaw(\"Cont thaw\", Continuation::thaw_top);\n+  return generate_cont_thaw(StubGenStubId::cont_thaw_id);\n@@ -3793,1 +3934,1 @@\n-  return generate_cont_thaw(\"Cont thaw return barrier\", Continuation::thaw_return_barrier);\n+  return generate_cont_thaw(StubGenStubId::cont_returnBarrier_id);\n@@ -3797,1 +3938,1 @@\n-  return generate_cont_thaw(\"Cont thaw return barrier exception\", Continuation::thaw_return_barrier_exception);\n+  return generate_cont_thaw(StubGenStubId::cont_returnBarrierExc_id);\n@@ -3802,1 +3943,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\",\"Continuation preempt stub\");\n+  StubGenStubId stub_id = StubGenStubId::cont_preempt_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -3832,1 +3974,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"upcall stub exception handler\");\n+  StubGenStubId stub_id = StubGenStubId::upcall_stub_exception_handler_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -3852,1 +3995,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"upcall_stub_load_target\");\n+  StubGenStubId stub_id = StubGenStubId::upcall_stub_load_target_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -3870,4 +4014,3 @@\n-address StubGenerator::generate_lookup_secondary_supers_table_stub(u1 super_klass_index) {\n-  StubCodeMark mark(this, \"StubRoutines\", \"lookup_secondary_supers_table\");\n-\n-  address start = __ pc();\n+void StubGenerator::generate_lookup_secondary_supers_table_stub() {\n+  StubGenStubId stub_id = StubGenStubId::lookup_secondary_supers_table_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -3880,7 +4023,8 @@\n-  __ lookup_secondary_supers_table_const(r_sub_klass, r_super_klass,\n-                                         rdx, rcx, rbx, r11, \/\/ temps\n-                                         result,\n-                                         super_klass_index);\n-  __ ret(0);\n-\n-  return start;\n+  for (int slot = 0; slot < Klass::SECONDARY_SUPERS_TABLE_SIZE; slot++) {\n+    StubRoutines::_lookup_secondary_supers_table_stubs[slot] = __ pc();\n+    __ lookup_secondary_supers_table_const(r_sub_klass, r_super_klass,\n+                                           rdx, rcx, rbx, r11, \/\/ temps\n+                                           result,\n+                                           slot);\n+    __ ret(0);\n+  }\n@@ -3891,1 +4035,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", \"lookup_secondary_supers_table\");\n+  StubGenStubId stub_id = StubGenStubId::lookup_secondary_supers_table_slow_path_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -3974,4 +4119,4 @@\n-  StubRoutines::x86::_float_sign_mask       = generate_fp_mask(\"float_sign_mask\",  0x7FFFFFFF7FFFFFFF);\n-  StubRoutines::x86::_float_sign_flip       = generate_fp_mask(\"float_sign_flip\",  0x8000000080000000);\n-  StubRoutines::x86::_double_sign_mask      = generate_fp_mask(\"double_sign_mask\", 0x7FFFFFFFFFFFFFFF);\n-  StubRoutines::x86::_double_sign_flip      = generate_fp_mask(\"double_sign_flip\", 0x8000000000000000);\n+  StubRoutines::x86::_float_sign_mask       = generate_fp_mask(StubGenStubId::float_sign_mask_id,  0x7FFFFFFF7FFFFFFF);\n+  StubRoutines::x86::_float_sign_flip       = generate_fp_mask(StubGenStubId::float_sign_flip_id,  0x8000000080000000);\n+  StubRoutines::x86::_double_sign_mask      = generate_fp_mask(StubGenStubId::double_sign_mask_id, 0x7FFFFFFFFFFFFFFF);\n+  StubRoutines::x86::_double_sign_flip      = generate_fp_mask(StubGenStubId::double_sign_flip_id, 0x8000000000000000);\n@@ -4167,4 +4312,0 @@\n-  \/\/ data cache line writeback\n-  StubRoutines::_data_cache_writeback = generate_data_cache_writeback();\n-  StubRoutines::_data_cache_writeback_sync = generate_data_cache_writeback_sync();\n-\n@@ -4179,0 +4320,9 @@\n+#ifdef COMPILER2\n+  if (UseSecondarySupersTable) {\n+    StubRoutines::_lookup_secondary_supers_table_slow_path_stub = generate_lookup_secondary_supers_table_slow_path_stub();\n+    if (! InlineSecondarySupersTest) {\n+      generate_lookup_secondary_supers_table_stub();\n+    }\n+  }\n+#endif \/\/ COMPILER2\n+\n@@ -4192,11 +4342,11 @@\n-  StubRoutines::x86::_vector_float_sign_mask = generate_vector_mask(\"vector_float_sign_mask\", 0x7FFFFFFF7FFFFFFF);\n-  StubRoutines::x86::_vector_float_sign_flip = generate_vector_mask(\"vector_float_sign_flip\", 0x8000000080000000);\n-  StubRoutines::x86::_vector_double_sign_mask = generate_vector_mask(\"vector_double_sign_mask\", 0x7FFFFFFFFFFFFFFF);\n-  StubRoutines::x86::_vector_double_sign_flip = generate_vector_mask(\"vector_double_sign_flip\", 0x8000000000000000);\n-  StubRoutines::x86::_vector_all_bits_set = generate_vector_mask(\"vector_all_bits_set\", 0xFFFFFFFFFFFFFFFF);\n-  StubRoutines::x86::_vector_int_mask_cmp_bits = generate_vector_mask(\"vector_int_mask_cmp_bits\", 0x0000000100000001);\n-  StubRoutines::x86::_vector_short_to_byte_mask = generate_vector_mask(\"vector_short_to_byte_mask\", 0x00ff00ff00ff00ff);\n-  StubRoutines::x86::_vector_byte_perm_mask = generate_vector_byte_perm_mask(\"vector_byte_perm_mask\");\n-  StubRoutines::x86::_vector_int_to_byte_mask = generate_vector_mask(\"vector_int_to_byte_mask\", 0x000000ff000000ff);\n-  StubRoutines::x86::_vector_int_to_short_mask = generate_vector_mask(\"vector_int_to_short_mask\", 0x0000ffff0000ffff);\n-  StubRoutines::x86::_vector_32_bit_mask = generate_vector_custom_i32(\"vector_32_bit_mask\", Assembler::AVX_512bit,\n+  StubRoutines::x86::_vector_float_sign_mask = generate_vector_mask(StubGenStubId::vector_float_sign_mask_id, 0x7FFFFFFF7FFFFFFF);\n+  StubRoutines::x86::_vector_float_sign_flip = generate_vector_mask(StubGenStubId::vector_float_sign_flip_id, 0x8000000080000000);\n+  StubRoutines::x86::_vector_double_sign_mask = generate_vector_mask(StubGenStubId::vector_double_sign_mask_id, 0x7FFFFFFFFFFFFFFF);\n+  StubRoutines::x86::_vector_double_sign_flip = generate_vector_mask(StubGenStubId::vector_double_sign_flip_id, 0x8000000000000000);\n+  StubRoutines::x86::_vector_all_bits_set = generate_vector_mask(StubGenStubId::vector_all_bits_set_id, 0xFFFFFFFFFFFFFFFF);\n+  StubRoutines::x86::_vector_int_mask_cmp_bits = generate_vector_mask(StubGenStubId::vector_int_mask_cmp_bits_id, 0x0000000100000001);\n+  StubRoutines::x86::_vector_short_to_byte_mask = generate_vector_mask(StubGenStubId::vector_short_to_byte_mask_id, 0x00ff00ff00ff00ff);\n+  StubRoutines::x86::_vector_byte_perm_mask = generate_vector_byte_perm_mask();\n+  StubRoutines::x86::_vector_int_to_byte_mask = generate_vector_mask(StubGenStubId::vector_int_to_byte_mask_id, 0x000000ff000000ff);\n+  StubRoutines::x86::_vector_int_to_short_mask = generate_vector_mask(StubGenStubId::vector_int_to_short_mask_id, 0x0000ffff0000ffff);\n+  StubRoutines::x86::_vector_32_bit_mask = generate_vector_custom_i32(StubGenStubId::vector_32_bit_mask_id, Assembler::AVX_512bit,\n@@ -4204,1 +4354,1 @@\n-  StubRoutines::x86::_vector_64_bit_mask = generate_vector_custom_i32(\"vector_64_bit_mask\", Assembler::AVX_512bit,\n+  StubRoutines::x86::_vector_64_bit_mask = generate_vector_custom_i32(StubGenStubId::vector_64_bit_mask_id, Assembler::AVX_512bit,\n@@ -4206,11 +4356,11 @@\n-  StubRoutines::x86::_vector_int_shuffle_mask = generate_vector_mask(\"vector_int_shuffle_mask\", 0x0302010003020100);\n-  StubRoutines::x86::_vector_byte_shuffle_mask = generate_vector_byte_shuffle_mask(\"vector_byte_shuffle_mask\");\n-  StubRoutines::x86::_vector_short_shuffle_mask = generate_vector_mask(\"vector_short_shuffle_mask\", 0x0100010001000100);\n-  StubRoutines::x86::_vector_long_shuffle_mask = generate_vector_mask(\"vector_long_shuffle_mask\", 0x0000000100000000);\n-  StubRoutines::x86::_vector_long_sign_mask = generate_vector_mask(\"vector_long_sign_mask\", 0x8000000000000000);\n-  StubRoutines::x86::_vector_iota_indices = generate_iota_indices(\"iota_indices\");\n-  StubRoutines::x86::_vector_count_leading_zeros_lut = generate_count_leading_zeros_lut(\"count_leading_zeros_lut\");\n-  StubRoutines::x86::_vector_reverse_bit_lut = generate_vector_reverse_bit_lut(\"reverse_bit_lut\");\n-  StubRoutines::x86::_vector_reverse_byte_perm_mask_long = generate_vector_reverse_byte_perm_mask_long(\"perm_mask_long\");\n-  StubRoutines::x86::_vector_reverse_byte_perm_mask_int = generate_vector_reverse_byte_perm_mask_int(\"perm_mask_int\");\n-  StubRoutines::x86::_vector_reverse_byte_perm_mask_short = generate_vector_reverse_byte_perm_mask_short(\"perm_mask_short\");\n+  StubRoutines::x86::_vector_int_shuffle_mask = generate_vector_mask(StubGenStubId::vector_int_shuffle_mask_id, 0x0302010003020100);\n+  StubRoutines::x86::_vector_byte_shuffle_mask = generate_vector_byte_shuffle_mask();\n+  StubRoutines::x86::_vector_short_shuffle_mask = generate_vector_mask(StubGenStubId::vector_short_shuffle_mask_id, 0x0100010001000100);\n+  StubRoutines::x86::_vector_long_shuffle_mask = generate_vector_mask(StubGenStubId::vector_long_shuffle_mask_id, 0x0000000100000000);\n+  StubRoutines::x86::_vector_long_sign_mask = generate_vector_mask(StubGenStubId::vector_long_sign_mask_id, 0x8000000000000000);\n+  StubRoutines::x86::_vector_iota_indices = generate_iota_indices();\n+  StubRoutines::x86::_vector_count_leading_zeros_lut = generate_count_leading_zeros_lut();\n+  StubRoutines::x86::_vector_reverse_bit_lut = generate_vector_reverse_bit_lut();\n+  StubRoutines::x86::_vector_reverse_byte_perm_mask_long = generate_vector_reverse_byte_perm_mask_long();\n+  StubRoutines::x86::_vector_reverse_byte_perm_mask_int = generate_vector_reverse_byte_perm_mask_int();\n+  StubRoutines::x86::_vector_reverse_byte_perm_mask_short = generate_vector_reverse_byte_perm_mask_short();\n@@ -4219,4 +4369,4 @@\n-    StubRoutines::x86::_compress_perm_table32 = generate_compress_perm_table(\"compress_perm_table32\", 32);\n-    StubRoutines::x86::_compress_perm_table64 = generate_compress_perm_table(\"compress_perm_table64\", 64);\n-    StubRoutines::x86::_expand_perm_table32 = generate_expand_perm_table(\"expand_perm_table32\", 32);\n-    StubRoutines::x86::_expand_perm_table64 = generate_expand_perm_table(\"expand_perm_table64\", 64);\n+    StubRoutines::x86::_compress_perm_table32 = generate_compress_perm_table(StubGenStubId::compress_perm_table32_id);\n+    StubRoutines::x86::_compress_perm_table64 = generate_compress_perm_table(StubGenStubId::compress_perm_table64_id);\n+    StubRoutines::x86::_expand_perm_table32 = generate_expand_perm_table(StubGenStubId::expand_perm_table32_id);\n+    StubRoutines::x86::_expand_perm_table64 = generate_expand_perm_table(StubGenStubId::expand_perm_table64_id);\n@@ -4227,1 +4377,1 @@\n-    StubRoutines::x86::_vector_popcount_lut = generate_popcount_avx_lut(\"popcount_lut\");\n+    StubRoutines::x86::_vector_popcount_lut = generate_popcount_avx_lut();\n@@ -4238,0 +4388,4 @@\n+  \/\/ data cache line writeback\n+  StubRoutines::_data_cache_writeback = generate_data_cache_writeback();\n+  StubRoutines::_data_cache_writeback_sync = generate_data_cache_writeback_sync();\n+\n@@ -4258,2 +4412,2 @@\n-    StubRoutines::_md5_implCompress = generate_md5_implCompress(false, \"md5_implCompress\");\n-    StubRoutines::_md5_implCompressMB = generate_md5_implCompress(true, \"md5_implCompressMB\");\n+    StubRoutines::_md5_implCompress = generate_md5_implCompress(StubGenStubId::md5_implCompress_id);\n+    StubRoutines::_md5_implCompressMB = generate_md5_implCompress(StubGenStubId::md5_implCompressMB_id);\n@@ -4265,2 +4419,2 @@\n-    StubRoutines::_sha1_implCompress = generate_sha1_implCompress(false, \"sha1_implCompress\");\n-    StubRoutines::_sha1_implCompressMB = generate_sha1_implCompress(true, \"sha1_implCompressMB\");\n+    StubRoutines::_sha1_implCompress = generate_sha1_implCompress(StubGenStubId::sha1_implCompress_id);\n+    StubRoutines::_sha1_implCompressMB = generate_sha1_implCompress(StubGenStubId::sha1_implCompressMB_id);\n@@ -4279,2 +4433,2 @@\n-    StubRoutines::_sha256_implCompress = generate_sha256_implCompress(false, \"sha256_implCompress\");\n-    StubRoutines::_sha256_implCompressMB = generate_sha256_implCompress(true, \"sha256_implCompressMB\");\n+    StubRoutines::_sha256_implCompress = generate_sha256_implCompress(StubGenStubId::sha256_implCompress_id);\n+    StubRoutines::_sha256_implCompressMB = generate_sha256_implCompress(StubGenStubId::sha256_implCompressMB_id);\n@@ -4286,2 +4440,2 @@\n-    StubRoutines::_sha512_implCompress = generate_sha512_implCompress(false, \"sha512_implCompress\");\n-    StubRoutines::_sha512_implCompressMB = generate_sha512_implCompress(true, \"sha512_implCompressMB\");\n+    StubRoutines::_sha512_implCompress = generate_sha512_implCompress(StubGenStubId::sha512_implCompress_id);\n+    StubRoutines::_sha512_implCompressMB = generate_sha512_implCompress(StubGenStubId::sha512_implCompressMB_id);\n@@ -4329,8 +4483,0 @@\n-  if (UseSecondarySupersTable) {\n-    StubRoutines::_lookup_secondary_supers_table_slow_path_stub = generate_lookup_secondary_supers_table_slow_path_stub();\n-    if (! InlineSecondarySupersTest) {\n-      for (int slot = 0; slot < Klass::SECONDARY_SUPERS_TABLE_SIZE; slot++) {\n-        StubRoutines::_lookup_secondary_supers_table_stubs[slot] = generate_lookup_secondary_supers_table_stub(slot);\n-      }\n-    }\n-  }\n@@ -4435,19 +4581,18 @@\n-StubGenerator::StubGenerator(CodeBuffer* code, StubsKind kind) : StubCodeGenerator(code) {\n-    DEBUG_ONLY( _regs_in_thread = false; )\n-    switch(kind) {\n-    case Initial_stubs:\n-      generate_initial_stubs();\n-      break;\n-     case Continuation_stubs:\n-      generate_continuation_stubs();\n-      break;\n-    case Compiler_stubs:\n-      generate_compiler_stubs();\n-      break;\n-    case Final_stubs:\n-      generate_final_stubs();\n-      break;\n-    default:\n-      fatal(\"unexpected stubs kind: %d\", kind);\n-      break;\n-    };\n+StubGenerator::StubGenerator(CodeBuffer* code, StubGenBlobId blob_id) : StubCodeGenerator(code, blob_id) {\n+  switch(blob_id) {\n+  case initial_id:\n+    generate_initial_stubs();\n+    break;\n+  case continuation_id:\n+    generate_continuation_stubs();\n+    break;\n+  case compiler_id:\n+    generate_compiler_stubs();\n+    break;\n+  case final_id:\n+    generate_final_stubs();\n+    break;\n+  default:\n+    fatal(\"unexpected blob id: %d\", blob_id);\n+    break;\n+  };\n@@ -4456,2 +4601,2 @@\n-void StubGenerator_generate(CodeBuffer* code, StubCodeGenerator::StubsKind kind) {\n-  StubGenerator g(code, kind);\n+void StubGenerator_generate(CodeBuffer* code, StubGenBlobId blob_id) {\n+  StubGenerator g(code, blob_id);\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":325,"deletions":180,"binary":false,"changes":505,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,0 +31,1 @@\n+#include \"runtime\/stubRoutines.hpp\"\n@@ -90,4 +91,4 @@\n-  address generate_count_leading_zeros_lut(const char *stub_name);\n-  address generate_popcount_avx_lut(const char *stub_name);\n-  address generate_iota_indices(const char *stub_name);\n-  address generate_vector_reverse_bit_lut(const char *stub_name);\n+  address generate_count_leading_zeros_lut();\n+  address generate_popcount_avx_lut();\n+  address generate_iota_indices();\n+  address generate_vector_reverse_bit_lut();\n@@ -95,4 +96,4 @@\n-  address generate_vector_reverse_byte_perm_mask_long(const char *stub_name);\n-  address generate_vector_reverse_byte_perm_mask_int(const char *stub_name);\n-  address generate_vector_reverse_byte_perm_mask_short(const char *stub_name);\n-  address generate_vector_byte_shuffle_mask(const char *stub_name);\n+  address generate_vector_reverse_byte_perm_mask_long();\n+  address generate_vector_reverse_byte_perm_mask_int();\n+  address generate_vector_reverse_byte_perm_mask_short();\n+  address generate_vector_byte_shuffle_mask();\n@@ -100,1 +101,1 @@\n-  address generate_fp_mask(const char *stub_name, int64_t mask);\n+  address generate_fp_mask(StubGenStubId stub_id, int64_t mask);\n@@ -102,1 +103,1 @@\n-  address generate_compress_perm_table(const char *stub_name, int32_t esize);\n+  address generate_compress_perm_table(StubGenStubId stub_id);\n@@ -104,1 +105,1 @@\n-  address generate_expand_perm_table(const char *stub_name, int32_t esize);\n+  address generate_expand_perm_table(StubGenStubId stub_id);\n@@ -106,1 +107,1 @@\n-  address generate_vector_mask(const char *stub_name, int64_t mask);\n+  address generate_vector_mask(StubGenStubId stub_id, int64_t mask);\n@@ -108,1 +109,1 @@\n-  address generate_vector_byte_perm_mask(const char *stub_name);\n+  address generate_vector_byte_perm_mask();\n@@ -110,1 +111,1 @@\n-  address generate_vector_fp_mask(const char *stub_name, int64_t mask);\n+  address generate_vector_fp_mask(StubGenStubId stub_id, int64_t mask);\n@@ -112,1 +113,1 @@\n-  address generate_vector_custom_i32(const char *stub_name, Assembler::AvxVectorLen len,\n+  address generate_vector_custom_i32(StubGenStubId stub_id, Assembler::AvxVectorLen len,\n@@ -182,2 +183,1 @@\n-  address generate_disjoint_copy_avx3_masked(address* entry, const char *name, int shift,\n-                                             bool aligned, bool is_oop, bool dest_uninitialized);\n+  address generate_disjoint_copy_avx3_masked(StubGenStubId stub_id, address* entry);\n@@ -185,3 +185,2 @@\n-  address generate_conjoint_copy_avx3_masked(address* entry, const char *name, int shift,\n-                                             address nooverlap_target, bool aligned, bool is_oop,\n-                                             bool dest_uninitialized);\n+  address generate_conjoint_copy_avx3_masked(StubGenStubId stub_id, address* entry,\n+                                             address nooverlap_target);\n@@ -228,1 +227,1 @@\n-  address generate_disjoint_byte_copy(bool aligned, address* entry, const char *name);\n+  address generate_disjoint_byte_copy(address* entry);\n@@ -230,2 +229,1 @@\n-  address generate_conjoint_byte_copy(bool aligned, address nooverlap_target,\n-                                      address* entry, const char *name);\n+  address generate_conjoint_byte_copy(address nooverlap_target, address* entry);\n@@ -233,1 +231,1 @@\n-  address generate_disjoint_short_copy(bool aligned, address *entry, const char *name);\n+  address generate_disjoint_short_copy(address *entry);\n@@ -235,1 +233,1 @@\n-  address generate_fill(BasicType t, bool aligned, const char *name);\n+  address generate_fill(StubGenStubId stub_id);\n@@ -237,12 +235,7 @@\n-  address generate_conjoint_short_copy(bool aligned, address nooverlap_target,\n-                                       address *entry, const char *name);\n-  address generate_disjoint_int_oop_copy(bool aligned, bool is_oop, address* entry,\n-                                         const char *name, bool dest_uninitialized = false);\n-  address generate_conjoint_int_oop_copy(bool aligned, bool is_oop, address nooverlap_target,\n-                                         address *entry, const char *name,\n-                                         bool dest_uninitialized = false);\n-  address generate_disjoint_long_oop_copy(bool aligned, bool is_oop, address *entry,\n-                                          const char *name, bool dest_uninitialized = false);\n-  address generate_conjoint_long_oop_copy(bool aligned, bool is_oop,\n-                                          address nooverlap_target, address *entry,\n-                                          const char *name, bool dest_uninitialized = false);\n+  address generate_conjoint_short_copy(address nooverlap_target, address *entry);\n+  address generate_disjoint_int_oop_copy(StubGenStubId stub_id, address* entry);\n+  address generate_conjoint_int_oop_copy(StubGenStubId stub_id, address nooverlap_target,\n+                                         address *entry);\n+  address generate_disjoint_long_oop_copy(StubGenStubId stub_id, address* entry);\n+  address generate_conjoint_long_oop_copy(StubGenStubId stub_id, address nooverlap_target,\n+                                          address *entry);\n@@ -258,2 +251,1 @@\n-  address generate_checkcast_copy(const char *name, address *entry,\n-                                  bool dest_uninitialized = false);\n+  address generate_checkcast_copy(StubGenStubId stub_id, address *entry);\n@@ -267,2 +259,1 @@\n-  address generate_unsafe_copy(const char *name,\n-                               address byte_copy_entry, address short_copy_entry,\n+  address generate_unsafe_copy(address byte_copy_entry, address short_copy_entry,\n@@ -277,1 +268,1 @@\n-  address generate_unsafe_setmemory(const char *name, address byte_copy_entry);\n+  address generate_unsafe_setmemory(address byte_copy_entry);\n@@ -291,2 +282,1 @@\n-  address generate_generic_copy(const char *name,\n-                                address byte_copy_entry, address short_copy_entry,\n+  address generate_generic_copy(address byte_copy_entry, address short_copy_entry,\n@@ -307,1 +297,1 @@\n-  address generate_md5_implCompress(bool multi_block, const char *name);\n+  address generate_md5_implCompress(StubGenStubId stub_id);\n@@ -314,1 +304,1 @@\n-  address generate_sha1_implCompress(bool multi_block, const char *name);\n+  address generate_sha1_implCompress(StubGenStubId stub_id);\n@@ -318,2 +308,2 @@\n-  address generate_sha256_implCompress(bool multi_block, const char *name);\n-  address generate_sha512_implCompress(bool multi_block, const char *name);\n+  address generate_sha256_implCompress(StubGenStubId stub_id);\n+  address generate_sha512_implCompress(StubGenStubId stub_id);\n@@ -502,1 +492,1 @@\n-  address generate_sha3_implCompress(bool multiBlock, const char *name);\n+  address generate_sha3_implCompress(StubGenStubId stub_id);\n@@ -598,1 +588,1 @@\n-  address generate_cont_thaw(const char* label, Continuation::thaw_kind kind);\n+  address generate_cont_thaw(StubGenStubId stub_id);\n@@ -607,0 +597,2 @@\n+  \/\/ TODO -- delete this as it is not implemented?\n+  \/\/\n@@ -635,1 +627,1 @@\n-  address generate_lookup_secondary_supers_table_stub(u1 super_klass_index);\n+  void generate_lookup_secondary_supers_table_stub();\n@@ -648,2 +640,2 @@\n- public:\n-  StubGenerator(CodeBuffer* code, StubsKind kind);\n+public:\n+  StubGenerator(CodeBuffer* code, StubGenBlobId blob_id);\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.hpp","additions":46,"deletions":54,"binary":false,"changes":100,"status":"modified"},{"patch":"@@ -87,19 +87,11 @@\n-  StubRoutines::_jbyte_disjoint_arraycopy  = generate_disjoint_byte_copy(false, &entry,\n-                                                                         \"jbyte_disjoint_arraycopy\");\n-  StubRoutines::_jbyte_arraycopy           = generate_conjoint_byte_copy(false, entry, &entry_jbyte_arraycopy,\n-                                                                         \"jbyte_arraycopy\");\n-\n-  StubRoutines::_jshort_disjoint_arraycopy = generate_disjoint_short_copy(false, &entry,\n-                                                                          \"jshort_disjoint_arraycopy\");\n-  StubRoutines::_jshort_arraycopy          = generate_conjoint_short_copy(false, entry, &entry_jshort_arraycopy,\n-                                                                          \"jshort_arraycopy\");\n-\n-  StubRoutines::_jint_disjoint_arraycopy   = generate_disjoint_int_oop_copy(false, false, &entry,\n-                                                                            \"jint_disjoint_arraycopy\");\n-  StubRoutines::_jint_arraycopy            = generate_conjoint_int_oop_copy(false, false, entry,\n-                                                                            &entry_jint_arraycopy, \"jint_arraycopy\");\n-\n-  StubRoutines::_jlong_disjoint_arraycopy  = generate_disjoint_long_oop_copy(false, false, &entry,\n-                                                                             \"jlong_disjoint_arraycopy\");\n-  StubRoutines::_jlong_arraycopy           = generate_conjoint_long_oop_copy(false, false, entry,\n-                                                                             &entry_jlong_arraycopy, \"jlong_arraycopy\");\n+  StubRoutines::_jbyte_disjoint_arraycopy  = generate_disjoint_byte_copy(&entry);\n+  StubRoutines::_jbyte_arraycopy           = generate_conjoint_byte_copy(entry, &entry_jbyte_arraycopy);\n+\n+  StubRoutines::_jshort_disjoint_arraycopy = generate_disjoint_short_copy(&entry);\n+  StubRoutines::_jshort_arraycopy          = generate_conjoint_short_copy(entry, &entry_jshort_arraycopy);\n+\n+  StubRoutines::_jint_disjoint_arraycopy   = generate_disjoint_int_oop_copy(StubGenStubId::jint_disjoint_arraycopy_id, &entry);\n+  StubRoutines::_jint_arraycopy            = generate_conjoint_int_oop_copy(StubGenStubId::jint_arraycopy_id, entry, &entry_jint_arraycopy);\n+\n+  StubRoutines::_jlong_disjoint_arraycopy  = generate_disjoint_long_oop_copy(StubGenStubId::jlong_disjoint_arraycopy_id, &entry);\n+  StubRoutines::_jlong_arraycopy           = generate_conjoint_long_oop_copy(StubGenStubId::jlong_arraycopy_id, entry, &entry_jlong_arraycopy);\n@@ -107,10 +99,4 @@\n-    StubRoutines::_oop_disjoint_arraycopy  = generate_disjoint_int_oop_copy(false, true, &entry,\n-                                                                            \"oop_disjoint_arraycopy\");\n-    StubRoutines::_oop_arraycopy           = generate_conjoint_int_oop_copy(false, true, entry,\n-                                                                            &entry_oop_arraycopy, \"oop_arraycopy\");\n-    StubRoutines::_oop_disjoint_arraycopy_uninit  = generate_disjoint_int_oop_copy(false, true, &entry,\n-                                                                                   \"oop_disjoint_arraycopy_uninit\",\n-                                                                                   \/*dest_uninitialized*\/true);\n-    StubRoutines::_oop_arraycopy_uninit           = generate_conjoint_int_oop_copy(false, true, entry,\n-                                                                                   nullptr, \"oop_arraycopy_uninit\",\n-                                                                                   \/*dest_uninitialized*\/true);\n+    StubRoutines::_oop_disjoint_arraycopy  = generate_disjoint_int_oop_copy(StubGenStubId::oop_disjoint_arraycopy_id, &entry);\n+    StubRoutines::_oop_arraycopy           = generate_conjoint_int_oop_copy(StubGenStubId::oop_arraycopy_id, entry, &entry_oop_arraycopy);\n+    StubRoutines::_oop_disjoint_arraycopy_uninit  = generate_disjoint_int_oop_copy(StubGenStubId::oop_disjoint_arraycopy_uninit_id, &entry);\n+    StubRoutines::_oop_arraycopy_uninit           = generate_conjoint_int_oop_copy(StubGenStubId::oop_arraycopy_uninit_id, entry, nullptr);\n@@ -118,18 +104,10 @@\n-    StubRoutines::_oop_disjoint_arraycopy  = generate_disjoint_long_oop_copy(false, true, &entry,\n-                                                                             \"oop_disjoint_arraycopy\");\n-    StubRoutines::_oop_arraycopy           = generate_conjoint_long_oop_copy(false, true, entry,\n-                                                                             &entry_oop_arraycopy, \"oop_arraycopy\");\n-    StubRoutines::_oop_disjoint_arraycopy_uninit  = generate_disjoint_long_oop_copy(false, true, &entry,\n-                                                                                    \"oop_disjoint_arraycopy_uninit\",\n-                                                                                    \/*dest_uninitialized*\/true);\n-    StubRoutines::_oop_arraycopy_uninit           = generate_conjoint_long_oop_copy(false, true, entry,\n-                                                                                    nullptr, \"oop_arraycopy_uninit\",\n-                                                                                    \/*dest_uninitialized*\/true);\n-  }\n-\n-  StubRoutines::_checkcast_arraycopy        = generate_checkcast_copy(\"checkcast_arraycopy\", &entry_checkcast_arraycopy);\n-  StubRoutines::_checkcast_arraycopy_uninit = generate_checkcast_copy(\"checkcast_arraycopy_uninit\", nullptr,\n-                                                                      \/*dest_uninitialized*\/true);\n-\n-  StubRoutines::_unsafe_arraycopy    = generate_unsafe_copy(\"unsafe_arraycopy\",\n-                                                            entry_jbyte_arraycopy,\n+    StubRoutines::_oop_disjoint_arraycopy  = generate_disjoint_long_oop_copy(StubGenStubId::oop_disjoint_arraycopy_id, &entry);\n+    StubRoutines::_oop_arraycopy           = generate_conjoint_long_oop_copy(StubGenStubId::oop_arraycopy_id, entry, &entry_oop_arraycopy);\n+    StubRoutines::_oop_disjoint_arraycopy_uninit  = generate_disjoint_long_oop_copy(StubGenStubId::oop_disjoint_arraycopy_uninit_id, &entry);\n+    StubRoutines::_oop_arraycopy_uninit           = generate_conjoint_long_oop_copy(StubGenStubId::oop_arraycopy_uninit_id, entry, nullptr);\n+  }\n+\n+  StubRoutines::_checkcast_arraycopy        = generate_checkcast_copy(StubGenStubId::checkcast_arraycopy_id, &entry_checkcast_arraycopy);\n+  StubRoutines::_checkcast_arraycopy_uninit = generate_checkcast_copy(StubGenStubId::checkcast_arraycopy_uninit_id, nullptr);\n+\n+  StubRoutines::_unsafe_arraycopy    = generate_unsafe_copy(entry_jbyte_arraycopy,\n@@ -139,2 +117,1 @@\n-  StubRoutines::_generic_arraycopy   = generate_generic_copy(\"generic_arraycopy\",\n-                                                             entry_jbyte_arraycopy,\n+  StubRoutines::_generic_arraycopy   = generate_generic_copy(entry_jbyte_arraycopy,\n@@ -147,6 +124,6 @@\n-  StubRoutines::_jbyte_fill = generate_fill(T_BYTE, false, \"jbyte_fill\");\n-  StubRoutines::_jshort_fill = generate_fill(T_SHORT, false, \"jshort_fill\");\n-  StubRoutines::_jint_fill = generate_fill(T_INT, false, \"jint_fill\");\n-  StubRoutines::_arrayof_jbyte_fill = generate_fill(T_BYTE, true, \"arrayof_jbyte_fill\");\n-  StubRoutines::_arrayof_jshort_fill = generate_fill(T_SHORT, true, \"arrayof_jshort_fill\");\n-  StubRoutines::_arrayof_jint_fill = generate_fill(T_INT, true, \"arrayof_jint_fill\");\n+  StubRoutines::_jbyte_fill = generate_fill(StubGenStubId::jbyte_fill_id);\n+  StubRoutines::_jshort_fill = generate_fill(StubGenStubId::jshort_fill_id);\n+  StubRoutines::_jint_fill = generate_fill(StubGenStubId::jint_fill_id);\n+  StubRoutines::_arrayof_jbyte_fill = generate_fill(StubGenStubId::arrayof_jbyte_fill_id);\n+  StubRoutines::_arrayof_jshort_fill = generate_fill(StubGenStubId::arrayof_jshort_fill_id);\n+  StubRoutines::_arrayof_jint_fill = generate_fill(StubGenStubId::arrayof_jint_fill_id);\n@@ -154,1 +131,1 @@\n-  StubRoutines::_unsafe_setmemory = generate_unsafe_setmemory(\"unsafe_setmemory\", StubRoutines::_jbyte_fill);\n+  StubRoutines::_unsafe_setmemory = generate_unsafe_setmemory(StubRoutines::_jbyte_fill);\n@@ -510,3 +487,42 @@\n-address StubGenerator::generate_disjoint_copy_avx3_masked(address* entry, const char *name,\n-                                                          int shift, bool aligned, bool is_oop,\n-                                                          bool dest_uninitialized) {\n+address StubGenerator::generate_disjoint_copy_avx3_masked(StubGenStubId stub_id, address* entry) {\n+  \/\/ aligned is always false -- x86_64 always uses the unaligned code\n+  const bool aligned = false;\n+  int shift;\n+  bool is_oop;\n+  bool dest_uninitialized;\n+\n+  switch (stub_id) {\n+  case jbyte_disjoint_arraycopy_id:\n+    shift = 0;\n+    is_oop = false;\n+    dest_uninitialized = false;\n+    break;\n+  case jshort_disjoint_arraycopy_id:\n+    shift = 1;\n+    is_oop = false;\n+    dest_uninitialized = false;\n+    break;\n+  case jint_disjoint_arraycopy_id:\n+    shift = 2;\n+    is_oop = false;\n+    dest_uninitialized = false;\n+    break;\n+  case jlong_disjoint_arraycopy_id:\n+    shift = 3;\n+    is_oop = false;\n+    dest_uninitialized = false;\n+    break;\n+  case oop_disjoint_arraycopy_id:\n+    shift = (UseCompressedOops ? 2 : 3);\n+    is_oop = true;\n+    dest_uninitialized = false;\n+    break;\n+  case oop_disjoint_arraycopy_uninit_id:\n+    shift = (UseCompressedOops ? 2 : 3);\n+    is_oop = true;\n+    dest_uninitialized = true;\n+    break;\n+  default:\n+    ShouldNotReachHere();\n+  }\n+\n@@ -514,1 +530,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubCodeMark mark(this, stub_id);\n@@ -809,3 +825,42 @@\n-address StubGenerator::generate_conjoint_copy_avx3_masked(address* entry, const char *name, int shift,\n-                                                          address nooverlap_target, bool aligned,\n-                                                          bool is_oop, bool dest_uninitialized) {\n+address StubGenerator::generate_conjoint_copy_avx3_masked(StubGenStubId stub_id, address* entry, address nooverlap_target) {\n+  \/\/ aligned is always false -- x86_64 always uses the unaligned code\n+  const bool aligned = false;\n+  int shift;\n+  bool is_oop;\n+  bool dest_uninitialized;\n+\n+  switch (stub_id) {\n+  case jbyte_arraycopy_id:\n+    shift = 0;\n+    is_oop = false;\n+    dest_uninitialized = false;\n+    break;\n+  case jshort_arraycopy_id:\n+    shift = 1;\n+    is_oop = false;\n+    dest_uninitialized = false;\n+    break;\n+  case jint_arraycopy_id:\n+    shift = 2;\n+    is_oop = false;\n+    dest_uninitialized = false;\n+    break;\n+  case jlong_arraycopy_id:\n+    shift = 3;\n+    is_oop = false;\n+    dest_uninitialized = false;\n+    break;\n+  case oop_arraycopy_id:\n+    shift = (UseCompressedOops ? 2 : 3);\n+    is_oop = true;\n+    dest_uninitialized = false;\n+    break;\n+  case oop_arraycopy_uninit_id:\n+    shift = (UseCompressedOops ? 2 : 3);\n+    is_oop = true;\n+    dest_uninitialized = true;\n+    break;\n+  default:\n+    ShouldNotReachHere();\n+  }\n+\n@@ -813,1 +868,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubCodeMark mark(this, stub_id);\n@@ -1265,3 +1320,1 @@\n-\/\/   aligned - true => Input and output aligned on a HeapWord == 8-byte boundary\n-\/\/             ignored\n-\/\/   name    - stub name string\n+\/\/   entry     - location for return of (post-push) entry\n@@ -1280,1 +1333,1 @@\n-\/\/   disjoint_byte_copy_entry is set to the no-overlap entry point\n+\/\/   entry is set to the no-overlap entry point\n@@ -1283,1 +1336,4 @@\n-address StubGenerator::generate_disjoint_byte_copy(bool aligned, address* entry, const char *name) {\n+address StubGenerator::generate_disjoint_byte_copy(address* entry) {\n+  StubGenStubId stub_id = StubGenStubId::jbyte_disjoint_arraycopy_id;\n+  \/\/ aligned is always false -- x86_64 always uses the unaligned code\n+  const bool aligned = false;\n@@ -1286,2 +1342,1 @@\n-     return generate_disjoint_copy_avx3_masked(entry, \"jbyte_disjoint_arraycopy_avx3\", 0,\n-                                               aligned, false, false);\n+    return generate_disjoint_copy_avx3_masked(stub_id, entry);\n@@ -1291,1 +1346,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubCodeMark mark(this, stub_id);\n@@ -1386,3 +1441,2 @@\n-\/\/   aligned - true => Input and output aligned on a HeapWord == 8-byte boundary\n-\/\/             ignored\n-\/\/   name    - stub name string\n+\/\/   entry     - location for return of (post-push) entry\n+\/\/   nooverlap_target - entry to branch to if no overlap detected\n@@ -1400,2 +1454,4 @@\n-address StubGenerator::generate_conjoint_byte_copy(bool aligned, address nooverlap_target,\n-                                                   address* entry, const char *name) {\n+address StubGenerator::generate_conjoint_byte_copy(address nooverlap_target, address* entry) {\n+  StubGenStubId stub_id = StubGenStubId::jbyte_arraycopy_id;\n+  \/\/ aligned is always false -- x86_64 always uses the unaligned code\n+  const bool aligned = false;\n@@ -1404,2 +1460,1 @@\n-     return generate_conjoint_copy_avx3_masked(entry, \"jbyte_conjoint_arraycopy_avx3\", 0,\n-                                               nooverlap_target, aligned, false, false);\n+    return generate_conjoint_copy_avx3_masked(stub_id, entry, nooverlap_target);\n@@ -1409,1 +1464,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubCodeMark mark(this, stub_id);\n@@ -1496,3 +1551,1 @@\n-\/\/   aligned - true => Input and output aligned on a HeapWord == 8-byte boundary\n-\/\/             ignored\n-\/\/   name    - stub name string\n+\/\/   entry     - location for return of (post-push) entry\n@@ -1511,1 +1564,1 @@\n-\/\/   disjoint_short_copy_entry is set to the no-overlap entry point\n+\/\/   entry is set to the no-overlap entry point\n@@ -1514,1 +1567,4 @@\n-address StubGenerator::generate_disjoint_short_copy(bool aligned, address *entry, const char *name) {\n+address StubGenerator::generate_disjoint_short_copy(address *entry) {\n+  StubGenStubId stub_id = StubGenStubId::jshort_disjoint_arraycopy_id;\n+  \/\/ aligned is always false -- x86_64 always uses the unaligned code\n+  const bool aligned = false;\n@@ -1517,2 +1573,1 @@\n-     return generate_disjoint_copy_avx3_masked(entry, \"jshort_disjoint_arraycopy_avx3\", 1,\n-                                               aligned, false, false);\n+    return generate_disjoint_copy_avx3_masked(stub_id, entry);\n@@ -1523,1 +1578,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubCodeMark mark(this, stub_id);\n@@ -1610,1 +1665,33 @@\n-address StubGenerator::generate_fill(BasicType t, bool aligned, const char *name) {\n+address StubGenerator::generate_fill(StubGenStubId stub_id) {\n+  BasicType t;\n+  bool aligned;\n+\n+  switch (stub_id) {\n+  case jbyte_fill_id:\n+    t = T_BYTE;\n+    aligned = false;\n+    break;\n+  case jshort_fill_id:\n+    t = T_SHORT;\n+    aligned = false;\n+    break;\n+  case jint_fill_id:\n+    t = T_INT;\n+    aligned = false;\n+    break;\n+  case arrayof_jbyte_fill_id:\n+    t = T_BYTE;\n+    aligned = true;\n+    break;\n+  case arrayof_jshort_fill_id:\n+    t = T_SHORT;\n+    aligned = true;\n+    break;\n+  case arrayof_jint_fill_id:\n+    t = T_INT;\n+    aligned = true;\n+    break;\n+  default:\n+    ShouldNotReachHere();\n+  }\n+\n@@ -1612,1 +1699,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubCodeMark mark(this, stub_id);\n@@ -1639,3 +1726,2 @@\n-\/\/   aligned - true => Input and output aligned on a HeapWord == 8-byte boundary\n-\/\/             ignored\n-\/\/   name    - stub name string\n+\/\/   entry     - location for return of (post-push) entry\n+\/\/   nooverlap_target - entry to branch to if no overlap detected\n@@ -1653,2 +1739,4 @@\n-address StubGenerator::generate_conjoint_short_copy(bool aligned, address nooverlap_target,\n-                                                    address *entry, const char *name) {\n+address StubGenerator::generate_conjoint_short_copy(address nooverlap_target, address *entry) {\n+  StubGenStubId stub_id = StubGenStubId::jshort_arraycopy_id;\n+  \/\/ aligned is always false -- x86_64 always uses the unaligned code\n+  const bool aligned = false;\n@@ -1657,2 +1745,1 @@\n-     return generate_conjoint_copy_avx3_masked(entry, \"jshort_conjoint_arraycopy_avx3\", 1,\n-                                               nooverlap_target, aligned, false, false);\n+    return generate_conjoint_copy_avx3_masked(stub_id, entry, nooverlap_target);\n@@ -1661,0 +1748,1 @@\n+\n@@ -1662,1 +1750,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubCodeMark mark(this, stub_id);\n@@ -1741,4 +1829,3 @@\n-\/\/   aligned - true => Input and output aligned on a HeapWord == 8-byte boundary\n-\/\/             ignored\n-\/\/   is_oop  - true => oop array, so generate store check code\n-\/\/   name    - stub name string\n+\/\/   stub_id   - unqiue id for stub to generate\n+\/\/   entry     - location for return of (post-push) entry\n+\/\/   is_oop    - true => oop array, so generate store check code\n@@ -1759,2 +1846,24 @@\n-address StubGenerator::generate_disjoint_int_oop_copy(bool aligned, bool is_oop, address* entry,\n-                                                      const char *name, bool dest_uninitialized) {\n+address StubGenerator::generate_disjoint_int_oop_copy(StubGenStubId stub_id, address* entry) {\n+  \/\/ aligned is always false -- x86_64 always uses the unaligned code\n+  const bool aligned = false;\n+  bool is_oop;\n+  bool dest_uninitialized;\n+  switch (stub_id) {\n+  case StubGenStubId::jint_disjoint_arraycopy_id:\n+    is_oop = false;\n+    dest_uninitialized = false;\n+    break;\n+  case StubGenStubId::oop_disjoint_arraycopy_id:\n+    assert(UseCompressedOops, \"inconsistent oop copy size!\");\n+    is_oop = true;\n+    dest_uninitialized = false;\n+    break;\n+  case StubGenStubId::oop_disjoint_arraycopy_uninit_id:\n+    assert(UseCompressedOops, \"inconsistent oop copy size!\");\n+    is_oop = true;\n+    dest_uninitialized = true;\n+    break;\n+  default:\n+    ShouldNotReachHere();\n+  }\n+\n@@ -1764,2 +1873,1 @@\n-     return generate_disjoint_copy_avx3_masked(entry, \"jint_disjoint_arraycopy_avx3\", 2,\n-                                               aligned, is_oop, dest_uninitialized);\n+    return generate_disjoint_copy_avx3_masked(stub_id, entry);\n@@ -1770,1 +1878,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubCodeMark mark(this, stub_id);\n@@ -1856,2 +1964,2 @@\n-\/\/   aligned - true => Input and output aligned on a HeapWord == 8-byte boundary\n-\/\/             ignored\n+\/\/   entry     - location for return of (post-push) entry\n+\/\/   nooverlap_target - entry to branch to if no overlap detected\n@@ -1859,1 +1967,0 @@\n-\/\/   name    - stub name string\n@@ -1870,3 +1977,24 @@\n-address StubGenerator::generate_conjoint_int_oop_copy(bool aligned, bool is_oop, address nooverlap_target,\n-                                                      address *entry, const char *name,\n-                                                      bool dest_uninitialized) {\n+address StubGenerator::generate_conjoint_int_oop_copy(StubGenStubId stub_id, address nooverlap_target, address *entry) {\n+  \/\/ aligned is always false -- x86_64 always uses the unaligned code\n+  const bool aligned = false;\n+  bool is_oop;\n+  bool dest_uninitialized;\n+  switch (stub_id) {\n+  case StubGenStubId::jint_arraycopy_id:\n+    is_oop = false;\n+    dest_uninitialized = false;\n+    break;\n+  case StubGenStubId::oop_arraycopy_id:\n+    assert(UseCompressedOops, \"inconsistent oop copy size!\");\n+    is_oop = true;\n+    dest_uninitialized = false;\n+    break;\n+  case StubGenStubId::oop_arraycopy_uninit_id:\n+    assert(UseCompressedOops, \"inconsistent oop copy size!\");\n+    is_oop = true;\n+    dest_uninitialized = true;\n+    break;\n+  default:\n+    ShouldNotReachHere();\n+  }\n+\n@@ -1876,2 +2004,1 @@\n-     return generate_conjoint_copy_avx3_masked(entry, \"jint_conjoint_arraycopy_avx3\", 2,\n-                                               nooverlap_target, aligned, is_oop, dest_uninitialized);\n+    return generate_conjoint_copy_avx3_masked(stub_id, entry, nooverlap_target);\n@@ -1880,0 +2007,1 @@\n+\n@@ -1881,1 +2009,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubCodeMark mark(this, stub_id);\n@@ -1971,4 +2099,1 @@\n-\/\/   aligned - true => Input and output aligned on a HeapWord boundary == 8 bytes\n-\/\/             ignored\n-\/\/   is_oop  - true => oop array, so generate store check code\n-\/\/   name    - stub name string\n+\/\/   entry     - location for return of (post-push) entry\n@@ -1985,2 +2110,24 @@\n-address StubGenerator::generate_disjoint_long_oop_copy(bool aligned, bool is_oop, address *entry,\n-                                                       const char *name, bool dest_uninitialized) {\n+address StubGenerator::generate_disjoint_long_oop_copy(StubGenStubId stub_id, address *entry) {\n+  \/\/ aligned is always false -- x86_64 always uses the unaligned code\n+  const bool aligned = false;\n+  bool is_oop;\n+  bool dest_uninitialized;\n+  switch (stub_id) {\n+  case StubGenStubId::jlong_disjoint_arraycopy_id:\n+    is_oop = false;\n+    dest_uninitialized = false;\n+    break;\n+  case StubGenStubId::oop_disjoint_arraycopy_id:\n+    assert(!UseCompressedOops, \"inconsistent oop copy size!\");\n+    is_oop = true;\n+    dest_uninitialized = false;\n+    break;\n+  case StubGenStubId::oop_disjoint_arraycopy_uninit_id:\n+    assert(!UseCompressedOops, \"inconsistent oop copy size!\");\n+    is_oop = true;\n+    dest_uninitialized = true;\n+    break;\n+  default:\n+    ShouldNotReachHere();\n+  }\n+\n@@ -1990,2 +2137,1 @@\n-     return generate_disjoint_copy_avx3_masked(entry, \"jlong_disjoint_arraycopy_avx3\", 3,\n-                                               aligned, is_oop, dest_uninitialized);\n+    return generate_disjoint_copy_avx3_masked(stub_id, entry);\n@@ -1994,0 +2140,1 @@\n+\n@@ -1995,1 +2142,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubCodeMark mark(this, stub_id);\n@@ -2087,2 +2234,2 @@\n-\/\/   aligned - true => Input and output aligned on a HeapWord boundary == 8 bytes\n-\/\/             ignored\n+\/\/   entry     - location for return of (post-push) entry\n+\/\/   nooverlap_target - entry to branch to if no overlap detected\n@@ -2090,1 +2237,0 @@\n-\/\/   name    - stub name string\n@@ -2097,3 +2243,24 @@\n-address StubGenerator::generate_conjoint_long_oop_copy(bool aligned, bool is_oop, address nooverlap_target,\n-                                                       address *entry, const char *name,\n-                                                       bool dest_uninitialized) {\n+address StubGenerator::generate_conjoint_long_oop_copy(StubGenStubId stub_id, address nooverlap_target, address *entry) {\n+  \/\/ aligned is always false -- x86_64 always uses the unaligned code\n+  const bool aligned = false;\n+  bool is_oop;\n+  bool dest_uninitialized;\n+  switch (stub_id) {\n+  case StubGenStubId::jlong_arraycopy_id:\n+    is_oop = false;\n+    dest_uninitialized = false;\n+    break;\n+  case StubGenStubId::oop_arraycopy_id:\n+    assert(!UseCompressedOops, \"inconsistent oop copy size!\");\n+    is_oop = true;\n+    dest_uninitialized = false;\n+    break;\n+  case StubGenStubId::oop_arraycopy_uninit_id:\n+    assert(!UseCompressedOops, \"inconsistent oop copy size!\");\n+    is_oop = true;\n+    dest_uninitialized = true;\n+    break;\n+  default:\n+    ShouldNotReachHere();\n+  }\n+\n@@ -2103,2 +2270,1 @@\n-     return generate_conjoint_copy_avx3_masked(entry, \"jlong_conjoint_arraycopy_avx3\", 3,\n-                                               nooverlap_target, aligned, is_oop, dest_uninitialized);\n+    return generate_conjoint_copy_avx3_masked(stub_id, entry, nooverlap_target);\n@@ -2107,0 +2273,1 @@\n+\n@@ -2108,1 +2275,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubCodeMark mark(this, stub_id);\n@@ -2227,1 +2394,13 @@\n-address StubGenerator::generate_checkcast_copy(const char *name, address *entry, bool dest_uninitialized) {\n+address StubGenerator::generate_checkcast_copy(StubGenStubId stub_id, address *entry) {\n+\n+  bool dest_uninitialized;\n+  switch (stub_id) {\n+  case StubGenStubId::checkcast_arraycopy_id:\n+    dest_uninitialized = false;\n+    break;\n+  case StubGenStubId::checkcast_arraycopy_uninit_id:\n+    dest_uninitialized = true;\n+    break;\n+  default:\n+    ShouldNotReachHere();\n+  }\n@@ -2257,1 +2436,1 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubCodeMark mark(this, stub_id);\n@@ -2433,2 +2612,1 @@\n-address StubGenerator::generate_unsafe_copy(const char *name,\n-                                            address byte_copy_entry, address short_copy_entry,\n+address StubGenerator::generate_unsafe_copy(address byte_copy_entry, address short_copy_entry,\n@@ -2448,1 +2626,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubGenStubId stub_id = StubGenStubId::unsafe_arraycopy_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -2581,2 +2760,1 @@\n-address StubGenerator::generate_unsafe_setmemory(const char *name,\n-                                                 address unsafe_byte_fill) {\n+address StubGenerator::generate_unsafe_setmemory(address unsafe_byte_fill) {\n@@ -2584,1 +2762,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubGenStubId stub_id = StubGenStubId::unsafe_setmemory_id;\n+  StubCodeMark mark(this, stub_id);\n@@ -2727,2 +2906,1 @@\n-address StubGenerator::generate_generic_copy(const char *name,\n-                                             address byte_copy_entry, address short_copy_entry,\n+address StubGenerator::generate_generic_copy(address byte_copy_entry, address short_copy_entry,\n@@ -2754,1 +2932,2 @@\n-  StubCodeMark mark(this, \"StubRoutines\", name);\n+  StubGenStubId stub_id = StubGenStubId::generic_arraycopy_id;\n+  StubCodeMark mark(this, stub_id);\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64_arraycopy.cpp","additions":324,"deletions":145,"binary":false,"changes":469,"status":"modified"},{"patch":"@@ -81,1 +81,1 @@\n-  if (HeapShared::can_write()) {\n+  if (CDSConfig::is_dumping_heap()) {\n@@ -102,1 +102,1 @@\n-  assert(HeapShared::can_write(), \"sanity\");\n+  assert(CDSConfig::is_dumping_heap(), \"sanity\");\n","filename":"src\/hotspot\/share\/cds\/archiveHeapWriter.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -50,0 +50,1 @@\n+bool CDSConfig::_disable_heap_dumping = false;\n@@ -561,0 +562,2 @@\n+\/\/ If an incompatible VM options is found, return a text message that explains why\n+static const char* check_options_incompatible_with_dumping_heap() {\n@@ -562,0 +565,36 @@\n+  if (!UseCompressedClassPointers) {\n+    return \"UseCompressedClassPointers must be true\";\n+  }\n+\n+  \/\/ Almost all GCs support heap region dump, except ZGC (so far).\n+  if (UseZGC) {\n+    return \"ZGC is not supported\";\n+  }\n+\n+  return nullptr;\n+#else\n+  return \"JVM not configured for writing Java heap objects\";\n+#endif\n+}\n+\n+void CDSConfig::log_reasons_for_not_dumping_heap() {\n+  const char* reason;\n+\n+  assert(!is_dumping_heap(), \"sanity\");\n+\n+  if (_disable_heap_dumping) {\n+    reason = \"Programmatically disabled\";\n+  } else {\n+    reason = check_options_incompatible_with_dumping_heap();\n+  }\n+\n+  assert(reason != nullptr, \"sanity\");\n+  log_info(cds)(\"Archived java heap is not supported: %s\", reason);\n+}\n+\n+#if INCLUDE_CDS_JAVA_HEAP\n+bool CDSConfig::are_vm_options_incompatible_with_dumping_heap() {\n+  return check_options_incompatible_with_dumping_heap() != nullptr;\n+}\n+\n+\n@@ -567,2 +606,7 @@\n-  \/\/ heap dump is not supported in dynamic dump\n-  return is_dumping_static_archive() && HeapShared::can_write();\n+  if (!is_dumping_static_archive() \/\/ heap dump is not supported in dynamic dump\n+      || are_vm_options_incompatible_with_dumping_heap()\n+      || _disable_heap_dumping) {\n+    return false;\n+  }\n+\n+  return true;\n","filename":"src\/hotspot\/share\/cds\/cdsConfig.cpp","additions":46,"deletions":2,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2023, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -52,0 +52,1 @@\n+  static bool  _disable_heap_dumping;\n@@ -127,0 +128,4 @@\n+  static bool are_vm_options_incompatible_with_dumping_heap() NOT_CDS_JAVA_HEAP_RETURN_(true);\n+  static void log_reasons_for_not_dumping_heap();\n+\n+  static void disable_heap_dumping()                         { CDS_ONLY(_disable_heap_dumping = true); }\n","filename":"src\/hotspot\/share\/cds\/cdsConfig.hpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1677,1 +1677,1 @@\n-    assert(HeapShared::can_write(), \"sanity\");\n+    assert(CDSConfig::is_dumping_heap(), \"sanity\");\n@@ -2600,0 +2600,7 @@\n+\n+#if INCLUDE_JVMTI\n+    if (Arguments::has_jdwp_agent()) {\n+      log_error(cds)(\"CDS archive has aot-linked classes. It cannot be used with JDWP agent\");\n+      return false;\n+    }\n+#endif\n","filename":"src\/hotspot\/share\/cds\/filemap.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -89,1 +89,0 @@\n-bool HeapShared::_disable_writing = false;\n@@ -239,3 +238,0 @@\n-    if (!HeapShared::can_write()) {\n-      return nullptr;\n-    }\n@@ -717,1 +713,1 @@\n-  assert(HeapShared::can_write(), \"must be\");\n+  assert(CDSConfig::is_dumping_heap(), \"must be\");\n@@ -1877,1 +1873,1 @@\n-  assert(HeapShared::can_write(), \"must be\");\n+  assert(CDSConfig::is_dumping_heap(), \"must be\");\n@@ -1966,1 +1962,1 @@\n-  if (HeapShared::can_write()) {\n+  if (CDSConfig::is_dumping_heap()) {\n","filename":"src\/hotspot\/share\/cds\/heapShared.cpp","additions":3,"deletions":7,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -321,1 +321,4 @@\n-  _symbol_rs = MemoryReserver::reserve(symbol_rs_size, mtClassShared);\n+  _symbol_rs = MemoryReserver::reserve(symbol_rs_size,\n+                                       os::vm_allocation_granularity(),\n+                                       os::vm_page_size(),\n+                                       mtClassShared);\n@@ -554,1 +557,1 @@\n-  void dump_java_heap_objects(GrowableArray<Klass*>* klasses) NOT_CDS_JAVA_HEAP_RETURN;\n+  void dump_java_heap_objects();\n@@ -655,1 +658,1 @@\n-  if (HeapShared::can_write() && _extra_interned_strings != nullptr) {\n+  if (CDSConfig::is_dumping_heap() && _extra_interned_strings != nullptr) {\n@@ -677,1 +680,1 @@\n-  dump_java_heap_objects(_builder.klasses());\n+  dump_java_heap_objects();\n@@ -1045,2 +1048,1 @@\n-#if INCLUDE_CDS_JAVA_HEAP\n-void VM_PopulateDumpSharedSpace::dump_java_heap_objects(GrowableArray<Klass*>* klasses) {\n+void VM_PopulateDumpSharedSpace::dump_java_heap_objects() {\n@@ -1051,7 +1053,5 @@\n-  if (!HeapShared::can_write()) {\n-    log_info(cds)(\n-      \"Archived java heap is not supported as UseG1GC \"\n-      \"and UseCompressedClassPointers are required.\"\n-      \"Current settings: UseG1GC=%s, UseCompressedClassPointers=%s.\",\n-      BOOL_TO_STR(UseG1GC), BOOL_TO_STR(UseCompressedClassPointers));\n-    return;\n+\n+  if (CDSConfig::is_dumping_heap()) {\n+    HeapShared::write_heap(&_heap_info);\n+  } else {\n+    CDSConfig::log_reasons_for_not_dumping_heap();\n@@ -1059,2 +1059,0 @@\n-  HeapShared::write_heap(&_heap_info);\n-#endif \/\/ INCLUDE_CDS_JAVA_HEAP\n","filename":"src\/hotspot\/share\/cds\/metaspaceShared.cpp","additions":13,"deletions":15,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -4687,1 +4687,2 @@\n-int java_lang_invoke_CallSite::_context_offset;\n+int java_lang_invoke_CallSite::_vmdependencies_offset;\n+int java_lang_invoke_CallSite::_last_cleanup_offset;\n@@ -4691,1 +4692,0 @@\n-  macro(_context_offset, k, \"context\", java_lang_invoke_MethodHandleNatives_CallSiteContext_signature, false)\n@@ -4696,0 +4696,1 @@\n+  CALLSITE_INJECTED_FIELDS(INJECTED_FIELD_COMPUTE_OFFSET);\n@@ -4701,0 +4702,1 @@\n+  CALLSITE_INJECTED_FIELDS(INJECTED_FIELD_SERIALIZE_OFFSET);\n@@ -4704,1 +4706,1 @@\n-oop java_lang_invoke_CallSite::context_no_keepalive(oop call_site) {\n+DependencyContext java_lang_invoke_CallSite::vmdependencies(oop call_site) {\n@@ -4706,3 +4708,4 @@\n-\n-  oop dep_oop = call_site->obj_field_access<AS_NO_KEEPALIVE>(_context_offset);\n-  return dep_oop;\n+  nmethodBucket* volatile* vmdeps_addr = call_site->field_addr<nmethodBucket* volatile>(_vmdependencies_offset);\n+  volatile uint64_t* last_cleanup_addr = call_site->field_addr<volatile uint64_t>(_last_cleanup_offset);\n+  DependencyContext dep_ctx(vmdeps_addr, last_cleanup_addr);\n+  return dep_ctx;\n@@ -4729,24 +4732,0 @@\n-\/\/ Support for java_lang_invoke_MethodHandleNatives_CallSiteContext\n-\n-int java_lang_invoke_MethodHandleNatives_CallSiteContext::_vmdependencies_offset;\n-int java_lang_invoke_MethodHandleNatives_CallSiteContext::_last_cleanup_offset;\n-\n-void java_lang_invoke_MethodHandleNatives_CallSiteContext::compute_offsets() {\n-  InstanceKlass* k = vmClasses::Context_klass();\n-  CALLSITECONTEXT_INJECTED_FIELDS(INJECTED_FIELD_COMPUTE_OFFSET);\n-}\n-\n-#if INCLUDE_CDS\n-void java_lang_invoke_MethodHandleNatives_CallSiteContext::serialize_offsets(SerializeClosure* f) {\n-  CALLSITECONTEXT_INJECTED_FIELDS(INJECTED_FIELD_SERIALIZE_OFFSET);\n-}\n-#endif\n-\n-DependencyContext java_lang_invoke_MethodHandleNatives_CallSiteContext::vmdependencies(oop call_site) {\n-  assert(java_lang_invoke_MethodHandleNatives_CallSiteContext::is_instance(call_site), \"\");\n-  nmethodBucket* volatile* vmdeps_addr = call_site->field_addr<nmethodBucket* volatile>(_vmdependencies_offset);\n-  volatile uint64_t* last_cleanup_addr = call_site->field_addr<volatile uint64_t>(_last_cleanup_offset);\n-  DependencyContext dep_ctx(vmdeps_addr, last_cleanup_addr);\n-  return dep_ctx;\n-}\n-\n@@ -5402,1 +5381,0 @@\n-  f(java_lang_invoke_MethodHandleNatives_CallSiteContext) \\\n@@ -5468,2 +5446,1 @@\n-        klass == vmClasses::MemberName_klass() ||\n-        klass == vmClasses::Context_klass()) {\n+        klass == vmClasses::MemberName_klass()) {\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":10,"deletions":33,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -1418,0 +1418,3 @@\n+#define CALLSITE_INJECTED_FIELDS(macro) \\\n+  macro(java_lang_invoke_CallSite, vmdependencies, intptr_signature, false) \\\n+  macro(java_lang_invoke_CallSite, last_cleanup, long_signature, false)\n@@ -1424,1 +1427,2 @@\n-  static int _context_offset;\n+  static int _vmdependencies_offset;\n+  static int _last_cleanup_offset;\n@@ -1435,1 +1439,1 @@\n-  static oop context_no_keepalive(oop site);\n+  static DependencyContext vmdependencies(oop call_site);\n@@ -1445,1 +1449,0 @@\n-  static int context_offset() { CHECK_INIT(_context_offset); }\n@@ -1470,29 +1473,0 @@\n-\/\/ Interface to java.lang.invoke.MethodHandleNatives$CallSiteContext objects\n-\n-#define CALLSITECONTEXT_INJECTED_FIELDS(macro) \\\n-  macro(java_lang_invoke_MethodHandleNatives_CallSiteContext, vmdependencies, intptr_signature, false) \\\n-  macro(java_lang_invoke_MethodHandleNatives_CallSiteContext, last_cleanup, long_signature, false)\n-\n-class DependencyContext;\n-\n-class java_lang_invoke_MethodHandleNatives_CallSiteContext : AllStatic {\n-  friend class JavaClasses;\n-\n-private:\n-  static int _vmdependencies_offset;\n-  static int _last_cleanup_offset;\n-\n-  static void compute_offsets();\n-\n-public:\n-  static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;\n-  \/\/ Accessors\n-  static DependencyContext vmdependencies(oop context);\n-\n-  \/\/ Testers\n-  static bool is_subclass(Klass* klass) {\n-    return klass->is_subclass_of(vmClasses::Context_klass());\n-  }\n-  static bool is_instance(oop obj);\n-};\n-\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.hpp","additions":6,"deletions":32,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -430,6 +430,16 @@\n-  \/\/ If class_name is already loaded, just return the superclass or superinterface.\n-  \/\/ Make sure there's a placeholder for the class_name before resolving.\n-  \/\/ This is used as a claim that this thread is currently loading superclass\/classloader\n-  \/\/ and for ClassCircularity checks.\n-\n-  Dictionary* dictionary = loader_data->dictionary();\n+\n+  if (is_superclass) {\n+    InstanceKlass* klassk = loader_data->dictionary()->find_class(THREAD, class_name);\n+    if (klassk != nullptr) {\n+      \/\/ We can come here for two reasons:\n+      \/\/ (a) RedefineClasses -- the class is already loaded\n+      \/\/ (b) Rarely, the class might have been loaded by a parallel thread\n+      \/\/ We can do a quick check against the already assigned superclass's name and loader.\n+      InstanceKlass* superk = klassk->java_super();\n+      if (superk != nullptr &&\n+          superk->name() == next_name &&\n+          superk->class_loader() == class_loader()) {\n+        return superk;\n+      }\n+    }\n+  }\n@@ -442,17 +452,6 @@\n-    InstanceKlass* klassk = dictionary->find_class(THREAD, class_name);\n-    InstanceKlass* quicksuperk;\n-    \/\/ To support parallel loading: if class is done loading, just return the superclass\n-    \/\/ if the next_name matches class->super()->name() and if the class loaders match.\n-    \/\/ Otherwise, a LinkageError will be thrown later.\n-    if (klassk != nullptr && is_superclass &&\n-       ((quicksuperk = klassk->java_super()) != nullptr) &&\n-       ((quicksuperk->name() == next_name) &&\n-         (quicksuperk->class_loader() == class_loader()))) {\n-      return quicksuperk;\n-    } else {\n-      \/\/ Must check ClassCircularity before checking if superclass is already loaded.\n-      PlaceholderEntry* probe = PlaceholderTable::get_entry(class_name, loader_data);\n-      if (probe && probe->check_seen_thread(THREAD, PlaceholderTable::DETECT_CIRCULARITY)) {\n-          log_circularity_error(class_name, probe);\n-          throw_circularity_error = true;\n-      }\n+\n+    \/\/ Must check ClassCircularity before resolving next_name (superclass or interface).\n+    PlaceholderEntry* probe = PlaceholderTable::get_entry(class_name, loader_data);\n+    if (probe != nullptr && probe->check_seen_thread(THREAD, PlaceholderTable::DETECT_CIRCULARITY)) {\n+        log_circularity_error(class_name, probe);\n+        throw_circularity_error = true;\n@@ -461,0 +460,3 @@\n+    \/\/ Make sure there's a placeholder for the class_name before resolving.\n+    \/\/ This is used as a claim that this thread is currently loading superclass\/classloader\n+    \/\/ and for ClassCircularity checks.\n@@ -508,2 +510,1 @@\n-  \/\/ This passes true to is_superclass even though it might not be the super class in order to perform the\n-  \/\/ optimization anyway.\n+  \/\/ This passes false to is_superclass to skip doing the unlikely optimization.\n@@ -513,1 +514,1 @@\n-                                                                       true,\n+                                                                       false,\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":27,"deletions":26,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -126,1 +126,0 @@\n-  do_klass(Context_klass,                               java_lang_invoke_MethodHandleNatives_CallSiteContext  ) \\\n","filename":"src\/hotspot\/share\/classfile\/vmClassMacros.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -332,1 +332,0 @@\n-  template(java_lang_invoke_MethodHandleNatives_CallSiteContext, \"java\/lang\/invoke\/MethodHandleNatives$CallSiteContext\") \\\n@@ -336,1 +335,0 @@\n-  template(java_lang_invoke_MethodHandleNatives_CallSiteContext_signature, \"Ljava\/lang\/invoke\/MethodHandleNatives$CallSiteContext;\") \\\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -636,0 +636,3 @@\n+  develop(bool, VerifyNoNewIrreducibleLoops, false,                         \\\n+          \"Verify that no new irreducible loops are created after parsing\") \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/opto\/c2_globals.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -440,0 +440,1 @@\n+  assert(status != RegionNode::LoopStatus::MaybeIrreducibleEntry || !is_Loop(), \"LoopNode is never irreducible entry.\");\n@@ -443,4 +444,7 @@\n-#ifdef ASSERT\n-void RegionNode::verify_can_be_irreducible_entry() const {\n-  assert(loop_status() == RegionNode::LoopStatus::MaybeIrreducibleEntry, \"must be marked irreducible\");\n-  assert(!is_Loop(), \"LoopNode cannot be irreducible loop entry\");\n+\/\/ A Region can only be an irreducible entry if:\n+\/\/ - It is marked as \"maybe irreducible entry\". Any other loop status would guarantee\n+\/\/   that it is never an irreducible loop entry.\n+\/\/ - And it is not a LoopNode, those are guaranteed to be reducible loop entries.\n+bool RegionNode::can_be_irreducible_entry() const {\n+  return loop_status() == RegionNode::LoopStatus::MaybeIrreducibleEntry &&\n+         !is_Loop();\n@@ -448,1 +452,0 @@\n-#endif \/\/ASSERT\n","filename":"src\/hotspot\/share\/opto\/cfgnode.cpp","additions":8,"deletions":5,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -122,1 +122,1 @@\n-  DEBUG_ONLY(void verify_can_be_irreducible_entry() const;)\n+  bool can_be_irreducible_entry() const;\n","filename":"src\/hotspot\/share\/opto\/cfgnode.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -725,10 +725,0 @@\n-  JavaThreadInObjectWaitState jtiows(thread, ms != 0);\n-  if (JvmtiExport::should_post_monitor_wait()) {\n-    JvmtiExport::post_monitor_wait(thread, obj(), ms);\n-\n-    \/\/ The current thread already owns the monitor and it has not yet\n-    \/\/ been added to the wait queue so the current thread cannot be\n-    \/\/ made the successor. This means that the JVMTI_EVENT_MONITOR_WAIT\n-    \/\/ event handler cannot accidentally consume an unpark() meant for\n-    \/\/ the ParkEvent associated with this ObjectMonitor.\n-  }\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":0,"deletions":10,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -943,7 +943,1 @@\n-  oop context = java_lang_invoke_CallSite::context_no_keepalive(call_site);\n-  DependencyContext deps = java_lang_invoke_MethodHandleNatives_CallSiteContext::vmdependencies(context);\n-  \/\/ Try to purge stale entries on updates.\n-  \/\/ Since GC doesn't clean dependency contexts rooted at CallSiteContext objects,\n-  \/\/ in order to avoid memory leak, stale entries are purged whenever a dependency list\n-  \/\/ is changed (both on addition and removal). Though memory reclamation is delayed,\n-  \/\/ it avoids indefinite memory usage growth.\n+  DependencyContext deps = java_lang_invoke_CallSite::vmdependencies(call_site);\n@@ -954,2 +948,1 @@\n-  oop context = java_lang_invoke_CallSite::context_no_keepalive(call_site);\n-  DependencyContext deps = java_lang_invoke_MethodHandleNatives_CallSiteContext::vmdependencies(context);\n+  DependencyContext deps = java_lang_invoke_CallSite::vmdependencies(call_site);\n@@ -967,2 +960,1 @@\n-    oop context = java_lang_invoke_CallSite::context_no_keepalive(call_site());\n-    DependencyContext deps = java_lang_invoke_MethodHandleNatives_CallSiteContext::vmdependencies(context);\n+    DependencyContext deps = java_lang_invoke_CallSite::vmdependencies(call_site());\n@@ -1335,17 +1327,0 @@\n-\/\/ It is called by a Cleaner object which ensures that dropped CallSites properly\n-\/\/ deallocate their dependency information.\n-JVM_ENTRY(void, MHN_clearCallSiteContext(JNIEnv* env, jobject igcls, jobject context_jh)) {\n-  Handle context(THREAD, JNIHandles::resolve_non_null(context_jh));\n-  DeoptimizationScope deopt_scope;\n-  {\n-    NoSafepointVerifier nsv;\n-    MutexLocker ml(THREAD, CodeCache_lock, Mutex::_no_safepoint_check_flag);\n-    DependencyContext deps = java_lang_invoke_MethodHandleNatives_CallSiteContext::vmdependencies(context());\n-    deps.remove_and_mark_for_deoptimization_all_dependents(&deopt_scope);\n-    \/\/ This is assumed to be an 'atomic' operation by verification.\n-    \/\/ So keep it under lock for now.\n-    deopt_scope.deoptimize_marked();\n-  }\n-}\n-JVM_END\n-\n@@ -1398,1 +1373,0 @@\n-#define CTX   JLINV \"MethodHandleNatives$CallSiteContext;\"\n@@ -1414,1 +1388,0 @@\n-  {CC \"clearCallSiteContext\",      CC \"(\" CTX \")V\",                          FN_PTR(MHN_clearCallSiteContext)},\n","filename":"src\/hotspot\/share\/prims\/methodHandles.cpp","additions":3,"deletions":30,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -2299,1 +2299,1 @@\n-  return HeapShared::can_write();\n+  return !CDSConfig::are_vm_options_incompatible_with_dumping_heap();\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -106,0 +106,1 @@\n+bool   Arguments::_has_jdwp_agent               = false;\n@@ -2010,1 +2011,1 @@\n-#if !INCLUDE_JVMTI\n+#if !INCLUDE_JVMTI || INCLUDE_CDS\n@@ -2369,0 +2370,4 @@\n+#elif INCLUDE_CDS\n+        if (valid_jdwp_agent(name, is_absolute_path)) {\n+          _has_jdwp_agent = true;\n+        }\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -257,0 +257,3 @@\n+  \/\/ jdwp\n+  static bool _has_jdwp_agent;\n+\n@@ -510,0 +513,3 @@\n+  \/\/ jdwp\n+  static bool has_jdwp_agent() { return _has_jdwp_agent; }\n+\n","filename":"src\/hotspot\/share\/runtime\/arguments.hpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -3,1 +3,1 @@\n- * Copyright (c) 2024, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2025, Red Hat, Inc. All rights reserved.\n@@ -50,0 +50,2 @@\n+\/\/ client macro to operate on shared stubs\n+\/\/\n@@ -76,0 +78,2 @@\n+\/\/ client macro to operate on c1 stubs\n+\/\/\n@@ -146,0 +150,2 @@\n+\/\/ client macro to operate on c2 stubs\n+\/\/\n@@ -178,1 +184,748 @@\n-\/\/ generate a stub or blob id enum tag from a name\n+\/\/ Stub Generator Blobs and Stubs Overview\n+\/\/\n+\/\/ StubGenerator stubs do not require their own individual blob. They\n+\/\/ are generated in batches into one of four distinct BufferBlobs:\n+\/\/\n+\/\/ 1) Initial stubs\n+\/\/ 2) Continuation stubs\n+\/\/ 3) Compiler stubs\n+\/\/ 4) Final stubs\n+\/\/\n+\/\/ Creation of each successive BufferBlobs is staged to ensure that\n+\/\/ specific VM subsystems required by those stubs are suitably\n+\/\/ initialized before generated code attempt to reference data or\n+\/\/ addresses exported by those subsystems. The sequencing of\n+\/\/ initialization must be taken into account when adding a new stub\n+\/\/ declaration.\n+\/\/\n+\/\/ StubGenerator stubs are declared using template macros, one set of\n+\/\/ declarations per blob (see below), with arch-specific stubs for any\n+\/\/ gven blob declared after generic stubs for that blob. Blobs are\n+\/\/ created in a fixed order during startup, which is reflected in the\n+\/\/ order of the declaration set. Stubs within a blob are currently\n+\/\/ created in an order determined by the arch-specific generator code\n+\/\/ which may not reflect the order of stub declarations. It is not\n+\/\/ straightforward to enforce a strict ordering. not least because\n+\/\/ arch-specific stub creation may need to be interleaved with generic\n+\/\/ stub creation.\n+\/\/\n+\/\/ Blob and stub declaration templates are used to generate a variety\n+\/\/ of C++ code elements needed to manage stubs.\n+\/\/\n+\/\/ Blob identifiers:\n+\/\/\n+\/\/ public enum StubGenBlobId is generated to identify each of the\n+\/\/ StubGenerator blobs in blob declaration order. This enum is\n+\/\/ provided for use by client code to identify a specific blob. For a\n+\/\/ blob declared with name <blob_name> the associated enum value is\n+\/\/ StubGenBlobId::<blob_name>_id.\n+\/\/\n+\/\/ Global stub identifiers:\n+\/\/\n+\/\/ public enum StubGenStubId is generated to identify all declared\n+\/\/ stubs across all blobs, sorted first by blob declaration order and\n+\/\/ then within a blob by stub declaration order, generic stubs before\n+\/\/ arch-specific stubs. This enum is provided for use by client code\n+\/\/ to identify a specific stub, independent of the blob it belongs to.\n+\/\/ For a stub declared with name <stub_name> the associated enum value\n+\/\/ is StubGenStubId::<stub_name>_id.\n+\/\/\n+\/\/ Blob-local stub identifiers:\n+\/\/\n+\/\/ For each blob <blob_name>, public enum StubGenStubId_<blob_name> is\n+\/\/ generated to enumerate all stubs within the blob in stub\n+\/\/ declaration order, generic stubs before arch-specific stubs. This\n+\/\/ enum is provided only in a non-product build and is intended for\n+\/\/ internal use by class StubRoutines to validate stub declarations.\n+\/\/ For a stub declared with name <stub_name> belonging to blob\n+\/\/ <blob_name> the associated enum value is\n+\/\/ StubGenStubId::<blob_name>_<stub_name>_id.\n+\/\/\n+\/\/ Stub names and associated getters:\n+\/\/\n+\/\/ Two private static fields are generated to hold the names of the\n+\/\/ four generated blobs and all the generated stubs.\n+\/\/\n+\/\/  const char* StubRoutines::_blob_names[];\n+\/\/  const char* StubRoutines::_stub_names[];\n+\/\/\n+\/\/ The entry in _blob_names for a blob declared with name <blob_name>\n+\/\/ will be \"<blob_name>\".\n+\/\/\n+\/\/ The entry in _stub_names for a stub declared with name <stub_name>\n+\/\/ will be \"<stub_name>\".\n+\/\/\n+\/\/ Corresponding public static lookup methods are generated to allow\n+\/\/ names to be looked up by blob or global stub id.\n+\/\/\n+\/\/  const char* StubRoutines::get_blob_name(StubGenBlobId id)\n+\/\/  const char* StubRoutines::get_stub_name(StubGenStubId id)\n+\/\/\n+\/\/ These name lookup methods should be used by generic and\n+\/\/ cpu-specific client code to ensure that blobs and stubs are\n+\/\/ identified consistently.\n+\/\/\n+\/\/ Blob code buffer sizes:\n+\/\/\n+\/\/ An enumeration enum platform_dependent_constants is generated in\n+\/\/ the architecture specific StubRoutines header. For each blob named\n+\/\/ <nnn> an associated enum tag is generated which defines the\n+\/\/ relevant size\n+\/\/\n+\/\/  _<nnn>_stubs_code_size      = <size>,\n+\/\/\n+\/\/ For example,\n+\/\/\n+\/\/ enum platform_dependent_constants {\n+\/\/   _initial_stubs_code_size      = 10000,\n+\/\/   _continuation_stubs_code_size =  2000,\n+\/\/   . . .\n+\/\/\n+\/\/ Blob fields and associated getters:\n+\/\/\n+\/\/ For each blob named <nnn> a private field declaration will be\n+\/\/ generated: static field address StubRoutines::_<nnn>_stubs_code and\n+\/\/ a declaration provided to initialise it to nullptr. A corresponding\n+\/\/ public getter method address StubRoutines::_<nnn>_stubs_code() will\n+\/\/ be generated.\n+\/\/\n+\/\/ Blob initialization routines:\n+\/\/\n+\/\/ For each blob named <nnn> an initalization function is defined\n+\/\/ which allows clients to schedule blob and stub generation during\n+\/\/ JVM bootstrap:\n+\/\/\n+\/\/ void <nnn>_stubs_init() { StubRoutines::initialize_<nnn>_stubs(); }\n+\/\/\n+\/\/ A declaration and definition of each underlying implementation\n+\/\/ method StubRoutines::initialize_<nnn>_stubs() is also generated.\n+\/\/\n+\/\/ Stub entry points and associated getters:\n+\/\/\n+\/\/ Some generated stubs require their main entry point and, possibly,\n+\/\/ auxiliary entry points to be stored in fields declared either as\n+\/\/ members of class SharedRuntime. For stubs that are specific to a\n+\/\/ given cpu, the field needs to be declared in an arch-specific inner\n+\/\/ class of SharedRuntime.\n+\/\/\n+\/\/ For a generic stub named <nnn> the corresponding main entry usually\n+\/\/ has the same name: static field address StubRoutines::_<nnn> modulo\n+\/\/ an _ prefix.  An associated getter method is also generated, again\n+\/\/ normally using the same name: address StubRoutines::<nnn>() e.g.\n+\/\/\n+\/\/  class StubRoutines {\n+\/\/    . . .\n+\/\/    static address _aescrypt_encryptBlock;\n+\/\/    . . .\n+\/\/    address aescrypt_encryptBlock() { return _aescrypt_encryptBlock; }\n+\/\/\n+\/\/ Multiple fields and getters may be generated where a stub has more\n+\/\/ than one entry point, each provided with their own unique field and\n+\/\/ getter name e.g.\n+\/\/\n+\/\/    . . .\n+\/\/    static address _call_stub;\n+\/\/    static address _call_stub_return_address;\n+\/\/    . . .\n+\/\/    static address call_stub_entry() { return _call_stub; }\n+\/\/    static address call_stub_return_address() { return _call_stub_return_address; }\n+\/\/\n+\/\/ In special cases a stub may declare a (compile-time) fixed size\n+\/\/ array of entries, in which case an address array field is\n+\/\/ generated,along with a getter that accepts an index as argument:\n+\/\/\n+\/\/    . . .\n+\/\/   static address _lookup_secondary_supers_table[Klass::SECONDARY_SUPERS_TABLE_SIZE];\n+\/\/   . . .\n+\/\/   static address lookup_secondary_supers_table(int i);\n+\/\/\n+\/\/ CPU-specific stub entry points and associated getters:\n+\/\/\n+\/\/ For an arch-specific stub with name <nnn> belonging to architecture\n+\/\/ <arch> private field address StubRoutines::<arch>::_<nnn> is\n+\/\/ generated to hold the entry address. An associated public getter\n+\/\/ method address StubRoutines::<arch>::<nnn>() is also generated e.g.\n+\/\/\n+\/\/  class StubRoutines {\n+\/\/    . . .\n+\/\/    class x86 {\n+\/\/      . . .\n+\/\/      static address _f2i_fixup;\n+\/\/      . . .\n+\/\/      static address f2i_fixup() { return _f2i_fixup; }\n+\/\/      static void set_f2i_fixup(address a) { _f2i_fixup = a; }\n+\/\/\n+\n+\n+\/\/--------------------------------------------------\n+\/\/ Stub Generator Blob, Stub and Entry Declarations\n+\/\/ -------------------------------------------------\n+\/\/\n+\/\/ The formal declarations of blobs, stubs and entries provided below\n+\/\/ are used to schedule application of template macros that either\n+\/\/ declare or define the C++ code we need to manage those blobs, stubs\n+\/\/ and entries.\n+\/\/\n+\/\/ All ports employ the same blobs. However, the organization of the\n+\/\/ stubs and entry points in a blob can vary from one port to the\n+\/\/ next. A template macro is provided to specify the details of each\n+\/\/ blob, including generic and arch-specific variations.\n+\/\/\n+\/\/ If you want to define a new stub or entry then you can do so by\n+\/\/ adding suitable declarations within the scope of the relevant blob.\n+\/\/ For the blob with name BLOB_NAME add your declarations to macro\n+\/\/ STUBGEN_<BLOB_NAME>_STUBS_DO. Generic stubs and entries are\n+\/\/ declared using the do_stub, do_entry and do_entry_init and\n+\/\/ array_entry templates (see below for full details). The do_blob\n+\/\/ and end_blob templates should never need to be modified.\n+\/\/\n+\/\/ Some stubs and their associated entries are architecture-specific.\n+\/\/ They need to be declared in the architecture-specific header file\n+\/\/ src\/cpu\/<arch>stubDecolaration_<arch>.cpp. For the blob with name\n+\/\/ BLOB_NAME the correspnding declarations macro are provided by macro\n+\/\/ STUBGEN_<BLOB_NAME>_STUBS_ARCH_DO. Arch-specific stubs and entries\n+\/\/ are declared using the do_stub, do_arch_entry and\n+\/\/ do_arch_entry_init templates (see below for details). An\n+\/\/ architecure also needs to specify architecture parameters used when\n+\/\/ creating each blob. These are defined using the do_arch_blob\n+\/\/ template (see below).\n+\/\/\n+\/\/ Note, the client macro STUBGEN_ALL_DO is provided to allow client\n+\/\/ code to iterate over all blob, stub or entry declarations. It has\n+\/\/ only been split into separate per-blob generic submacros,\n+\/\/ STUBGEN_<BLOB_NAME>_BLOBS_DO and arch-specific per-blob submacros\n+\/\/ STUBGEN_<BLOB_NAME>_BLOBS_ARCH_DO for convenience, to make it\n+\/\/ easier to manage definitions. The blob_specific sub-macros should\n+\/\/ not be called directly by client code (in class StubRoutines and\n+\/\/ StubGenerator),\n+\/\/\n+\/\/ A client wishing to generate blob, stub or entry code elements is\n+\/\/ expected to pass template macros as arguments to STUBGEN_ALL_DO.\n+\/\/ This will schedule code generation code for whatever C++ code\n+\/\/ elements are required to implement a declaration or definition\n+\/\/ relevant to each blob, stub or entry. Alternatively, a client can\n+\/\/ operate on a subset of the declarations by calling macros\n+\/\/ STUBGEN_BLOBS_DO, STUBGEN_STUBS_DO, STUBGEN_BLOBS_STUBS_DO,\n+\/\/ STUBGEN_ENTRIES_DO and STUBGEN_ARCH_ENTRIES_DO.\n+\/\/\n+\/\/ The do_blob and end_blob templates receive a blob name as argument.\n+\/\/\n+\/\/ do_blob(blob_name)\n+\/\/ end_blob(blob_name)\n+\/\/\n+\/\/ do_blob is primarily used to define a global enum tag for a blob\n+\/\/ and an associated constant string name, both for use by client\n+\/\/ code.\n+\/\/\n+\/\/ end_blob is provided for use in combination with do_blob to to open\n+\/\/ and close a blob-local enum type identifying all stubs within a\n+\/\/ given blob. This enum is private to the stub management code and\n+\/\/ used to validate correct use of stubs within a given blob.\n+\/\/\n+\/\/ The do_stub template receives a blob name and stub name as argument.\n+\/\/\n+\/\/ do_stub(blob_name, stub_name)\n+\/\/\n+\/\/ do_stub is primarily used to define a global enum tag for a stub\n+\/\/ and a constant string name, both for use by client code. It is also\n+\/\/ used to declare a tag within the blob-local enum type used to\n+\/\/ validate correct use of stubs within their declared blob. Finally,\n+\/\/ it is also used to declare a name for each stub.\n+\/\/\n+\/\/ The do_entry and do_entry_array templates receive 4 or 5 arguments\n+\/\/\n+\/\/ do_entry(blob_name, stub_name, field_name, getter_name)\n+\/\/\n+\/\/ do_entry_init(blob_name, stub_name, field_name, getter_name, init_function)\n+\/\/\n+\/\/ do_entry_array(blob_name, stub_name, field_name, getter_name, count)\n+\/\/\n+\/\/ do_entry is used to declare or define a static field of class\n+\/\/ StubRoutines with type address that stores a specific entry point\n+\/\/ for a given stub. n.b. the number of entries associated with a stub\n+\/\/ is often one but it can be more than one and, in a few special\n+\/\/ cases, it is zero. do_entry is also used to declare and define an\n+\/\/ associated getter method for the field. do_entry is used to declare\n+\/\/ fields that should be initialized to nullptr.\n+\/\/\n+\/\/ do_entry_init is used when the field needs to be initialized a\n+\/\/ specific function or method .\n+\/\/\n+\/\/ do_entry_array is used for the special case where a stub employs an\n+\/\/ array to store multiple entries which are stored at generate time\n+\/\/ and subsequently accessed using an associated index (e.g. the\n+\/\/ secondary supers table stub which has 63 qassociated entries).\n+\/\/ Note that this distinct from the case where a stub generates\n+\/\/ multiple entries each of them stored in its own named field with\n+\/\/ its own named getter. In the latter case multiple do_entry or\n+\/\/ do_entry_init declarations are associated with the stub.\n+\/\/\n+\/\/ blob_name and stub_name are the names of the blob and stub to which\n+\/\/ the entry belongs.\n+\/\/\n+\/\/ field_name is prefixed with a leading '_' to produce the name of\n+\/\/ the field used to store an entry address for the stub. For stubs\n+\/\/ with one entry field_name is normally, but not always, the same as\n+\/\/ stub_name.  Obviously when a stub has multiple entries secondary\n+\/\/ names must be different to stub_name. For normal entry declarations\n+\/\/ the field type is address. For do_entry_array declarations the field\n+\/\/ type is an address[] whose size is defined by then parameter.\n+\/\/\n+\/\/ getter_name is the name of a getter that is generated to allow\n+\/\/ access to the field. It is normally, but not always, the same as\n+\/\/ stub_name. For normal entry declarations the getter signature is\n+\/\/ (void).  For do_entry_array declarations the getter signature is\n+\/\/ (int).\n+\/\/\n+\/\/ init_function is the name of an function or method which should be\n+\/\/ assigned to the field as a default value (n.b. fields declared\n+\/\/ using do_entry are intialised to nullptr, array fields declared\n+\/\/ using do_entry_array have their elements initalized to nullptr).\n+\/\/\n+\/\/ Architecture-specific blob details need to be specified using the\n+\/\/ do_arch_blob template\n+\/\/\n+\/\/ do_arch_blob(blob_name, size)\n+\/\/\n+\/\/ Currently, the do_arch_blob macro is only used to define the size\n+\/\/ of the code buffer into which blob-specific stub code is to be\n+\/\/ generated.\n+\/\/\n+\/\/ Architecture-specific entries need to be declared using the\n+\/\/ do_arch_entry template\n+\/\/\n+\/\/ do_arch_entry(arch, blob_name, stub_name, field_name, getter_name)\n+\/\/\n+\/\/ do_arch_entry_init(arch, blob_name, stub_name, field_name,\n+\/\/                    getter_name, init_function)\n+\/\/\n+\/\/ The only difference between these templates and the generic ones is\n+\/\/ that they receive an extra argument which identifies the current\n+\/\/ architecture e.g. x86, aarch64 etc.\n+\/\/\n+\/\/ Currently there is no support for a do_arch_array_entry template.\n+\n+\/\/ Include arch-specific stub and entry declarations and make sure the\n+\/\/ relevant template macros ahve been defined\n+\n+#include CPU_HEADER(stubDeclarations)\n+\n+#ifndef STUBGEN_INITIAL_BLOBS_ARCH_DO\n+#error \"Arch-specific directory failed to declare required initial stubs and entries\"\n+#endif\n+\n+#ifndef STUBGEN_CONTINUATION_BLOBS_ARCH_DO\n+#error \"Arch-specific directory failed to declare required continuation stubs and entries\"\n+#endif\n+\n+#ifndef STUBGEN_COMPILER_BLOBS_ARCH_DO\n+#error \"Arch-specific directory failed to declare required compiler stubs and entries\"\n+#endif\n+\n+#ifndef STUBGEN_FINAL_BLOBS_ARCH_DO\n+#error \"Arch-specific directory failed to declare required final stubs and entries\"\n+#endif\n+\n+\/\/ Iterator macros to apply templates to all relevant blobs, stubs and\n+\/\/ entries. Clients should use STUBGEN_ALL_DO, STUBGEN_BLOBS_DO,\n+\/\/ STUBGEN_STUBS_DO, STUBGEN_BLOBS_STUBS_DO, STUBGEN_ENTRIES_DO,\n+\/\/ STUBGEN_ARCH_BLOBS_DO and STUBGEN_ARCH_ENTRIES_DO.\n+\/\/\n+\/\/ n.b. Client macros appear after the STUBGEN_<BLOB_NAME>_BLOBS_DO\n+\/\/ submacros which follow next. These submacros are not intended to be\n+\/\/ called directly. They serve to define the main client macro\n+\/\/ STUBGEN_ALL_DO and, from there, the other more specific client\n+\/\/ macros. n.b. multiple, 'per-blob' submacros are used to declare\n+\/\/ each group of stubs and entries, because that makes it simpler to\n+\/\/ lookup and update related elements. If you need to update these\n+\/\/ submacros to change the list of stubs or entries be sure to locate\n+\/\/ stubs within the correct blob and locate entry declarations\n+\/\/ immediately after their associated stub declaration.\n+\n+#define STUBGEN_INITIAL_BLOBS_DO(do_blob, end_blob,                     \\\n+                                 do_stub,                               \\\n+                                 do_entry, do_entry_init,               \\\n+                                 do_entry_array,                        \\\n+                                 do_arch_blob,                          \\\n+                                 do_arch_entry, do_arch_entry_init)     \\\n+  do_blob(initial)                                                      \\\n+  do_stub(initial, call_stub)                                           \\\n+  do_entry(initial, call_stub, call_stub_entry, call_stub_entry)        \\\n+  do_entry(initial, call_stub, call_stub_return_address,                \\\n+           call_stub_return_address)                                    \\\n+  do_stub(initial, forward_exception)                                   \\\n+  do_entry(initial, forward_exception, forward_exception_entry,         \\\n+           forward_exception_entry)                                     \\\n+  do_stub(initial, catch_exception)                                     \\\n+  do_entry(initial, catch_exception, catch_exception_entry,             \\\n+           catch_exception_entry)                                       \\\n+  do_stub(initial, fence)                                               \\\n+  do_entry(initial, fence, fence_entry, fence_entry)                    \\\n+  do_stub(initial, atomic_xchg)                                         \\\n+  do_entry(initial, atomic_xchg, atomic_xchg_entry, atomic_xchg_entry)  \\\n+  do_stub(initial, atomic_cmpxchg)                                      \\\n+  do_entry(initial, atomic_cmpxchg, atomic_cmpxchg_entry,               \\\n+           atomic_cmpxchg_entry)                                        \\\n+  do_stub(initial, atomic_cmpxchg_long)                                 \\\n+  do_entry(initial, atomic_cmpxchg_long, atomic_cmpxchg_long_entry,     \\\n+           atomic_cmpxchg_long_entry)                                   \\\n+  do_stub(initial, updateBytesCRC32)                                    \\\n+  do_entry(initial, updateBytesCRC32, updateBytesCRC32,                 \\\n+           updateBytesCRC32)                                            \\\n+  do_entry(initial, updateBytesCRC32, crc_table_adr, crc_table_addr)    \\\n+  do_stub(initial, updateBytesCRC32C)                                   \\\n+  do_entry(initial, updateBytesCRC32C, updateBytesCRC32C,               \\\n+           updateBytesCRC32C)                                           \\\n+  do_entry(initial, updateBytesCRC32C, crc32c_table_addr,               \\\n+           crc32c_table_addr)                                           \\\n+  do_stub(initial, f2hf)                                                \\\n+  do_entry(initial, f2hf, f2hf, f2hf_adr)                               \\\n+  do_stub(initial, hf2f)                                                \\\n+  do_entry(initial, hf2f, hf2f, hf2f_adr)                               \\\n+  do_stub(initial, dexp)                                                \\\n+  do_entry(initial, dexp, dexp, dexp)                                   \\\n+  do_stub(initial, dlog)                                                \\\n+  do_entry(initial, dlog, dlog, dlog)                                   \\\n+  do_stub(initial, dlog10)                                              \\\n+  do_entry(initial, dlog10, dlog10, dlog10)                             \\\n+  do_stub(initial, dpow)                                                \\\n+  do_entry(initial, dpow, dpow, dpow)                                   \\\n+  do_stub(initial, dsin)                                                \\\n+  do_entry(initial, dsin, dsin, dsin)                                   \\\n+  do_stub(initial, dcos)                                                \\\n+  do_entry(initial, dcos, dcos, dcos)                                   \\\n+  do_stub(initial, dtan)                                                \\\n+  do_entry(initial, dtan, dtan, dtan)                                   \\\n+  do_stub(initial, dtanh)                                               \\\n+  do_entry(initial, dtanh, dtanh, dtanh)                                \\\n+  do_stub(initial, fmod)                                                \\\n+  do_entry(initial, fmod, fmod, fmod)                                   \\\n+  \/* following generic entries should really be x86_32 only *\/          \\\n+  do_stub(initial, dlibm_sin_cos_huge)                                  \\\n+  do_entry(initial, dlibm_sin_cos_huge, dlibm_sin_cos_huge,             \\\n+           dlibm_sin_cos_huge)                                          \\\n+  do_stub(initial, dlibm_reduce_pi04l)                                  \\\n+  do_entry(initial, dlibm_reduce_pi04l, dlibm_reduce_pi04l,             \\\n+           dlibm_reduce_pi04l)                                          \\\n+  do_stub(initial, dlibm_tan_cot_huge)                                  \\\n+  do_entry(initial, dlibm_tan_cot_huge, dlibm_tan_cot_huge,             \\\n+           dlibm_tan_cot_huge)                                          \\\n+  \/* merge in stubs and entries declared in arch header *\/              \\\n+  STUBGEN_INITIAL_BLOBS_ARCH_DO(do_stub, do_arch_blob,                  \\\n+                                do_arch_entry, do_arch_entry_init)      \\\n+  end_blob(initial)                                                     \\\n+\n+\n+#define STUBGEN_CONTINUATION_BLOBS_DO(do_blob, end_blob,                \\\n+                                      do_stub,                          \\\n+                                      do_entry, do_entry_init,          \\\n+                                      do_entry_array,                   \\\n+                                      do_arch_blob,                     \\\n+                                      do_arch_entry, do_arch_entry_init) \\\n+  do_blob(continuation)                                                 \\\n+  do_stub(continuation, cont_thaw)                                      \\\n+  do_entry(continuation, cont_thaw, cont_thaw, cont_thaw)               \\\n+  do_stub(continuation, cont_preempt)                                   \\\n+  do_entry(continuation, cont_prempt, cont_preempt_stub,                \\\n+           cont_preempt_stub)                                           \\\n+  do_stub(continuation, cont_returnBarrier)                             \\\n+  do_entry(continuation, cont_returnBarrier, cont_returnBarrier,        \\\n+           cont_returnBarrier)                                          \\\n+  do_stub(continuation, cont_returnBarrierExc)                          \\\n+  do_entry(continuation, cont_returnBarrierExc, cont_returnBarrierExc,  \\\n+           cont_returnBarrierExc)                                       \\\n+  \/* merge in stubs and entries declared in arch header *\/              \\\n+  STUBGEN_CONTINUATION_BLOBS_ARCH_DO(do_stub,  do_arch_blob,            \\\n+                                     do_arch_entry, do_arch_entry_init) \\\n+  end_blob(continuation)                                                \\\n+\n+\n+#define STUBGEN_COMPILER_BLOBS_DO(do_blob, end_blob,                    \\\n+                                  do_stub,                              \\\n+                                  do_entry, do_entry_init,              \\\n+                                  do_entry_array,                       \\\n+                                  do_arch_blob,                         \\\n+                                  do_arch_entry, do_arch_entry_init)    \\\n+  do_blob(compiler)                                                     \\\n+  do_stub(compiler, atomic_add)                                         \\\n+  do_entry(compiler, atomic_add, atomic_add_entry, atomic_add_entry)    \\\n+  do_stub(compiler, array_sort)                                         \\\n+  do_entry(compiler, array_sort, array_sort, select_arraysort_function) \\\n+  do_stub(compiler, array_partition)                                    \\\n+  do_entry(compiler, array_partition, array_partition,                  \\\n+           select_array_partition_function)                             \\\n+  do_stub(compiler, aescrypt_encryptBlock)                              \\\n+  do_entry(compiler, aescrypt_encryptBlock, aescrypt_encryptBlock,      \\\n+           aescrypt_encryptBlock)                                       \\\n+  do_stub(compiler, aescrypt_decryptBlock)                              \\\n+  do_entry(compiler, aescrypt_decryptBlock, aescrypt_decryptBlock,      \\\n+           aescrypt_decryptBlock)                                       \\\n+  do_stub(compiler, cipherBlockChaining_encryptAESCrypt)                \\\n+  do_entry(compiler, cipherBlockChaining_encryptAESCrypt,               \\\n+           cipherBlockChaining_encryptAESCrypt,                         \\\n+           cipherBlockChaining_encryptAESCrypt)                         \\\n+  do_stub(compiler, cipherBlockChaining_decryptAESCrypt)                \\\n+  do_entry(compiler, cipherBlockChaining_decryptAESCrypt,               \\\n+           cipherBlockChaining_decryptAESCrypt,                         \\\n+           cipherBlockChaining_decryptAESCrypt)                         \\\n+  do_stub(compiler, electronicCodeBook_encryptAESCrypt)                 \\\n+  do_entry(compiler, electronicCodeBook_encryptAESCrypt,                \\\n+           electronicCodeBook_encryptAESCrypt,                          \\\n+           electronicCodeBook_encryptAESCrypt)                          \\\n+  do_stub(compiler, electronicCodeBook_decryptAESCrypt)                 \\\n+  do_entry(compiler, electronicCodeBook_decryptAESCrypt,                \\\n+           electronicCodeBook_decryptAESCrypt,                          \\\n+           electronicCodeBook_decryptAESCrypt)                          \\\n+  do_stub(compiler, counterMode_AESCrypt)                               \\\n+  do_entry(compiler, counterMode_AESCrypt, counterMode_AESCrypt,        \\\n+           counterMode_AESCrypt)                                        \\\n+  do_stub(compiler, galoisCounterMode_AESCrypt)                         \\\n+  do_entry(compiler, galoisCounterMode_AESCrypt,                        \\\n+           galoisCounterMode_AESCrypt, galoisCounterMode_AESCrypt)      \\\n+  do_stub(compiler, ghash_processBlocks)                                \\\n+  do_entry(compiler, ghash_processBlocks, ghash_processBlocks,          \\\n+           ghash_processBlocks)                                         \\\n+  do_stub(compiler, chacha20Block)                                      \\\n+  do_entry(compiler, chacha20Block, chacha20Block, chacha20Block)       \\\n+  do_stub(compiler, data_cache_writeback)                               \\\n+  do_entry(compiler, data_cache_writeback, data_cache_writeback,        \\\n+           data_cache_writeback)                                        \\\n+  do_stub(compiler, data_cache_writeback_sync)                          \\\n+  do_entry(compiler, data_cache_writeback_sync,                         \\\n+           data_cache_writeback_sync, data_cache_writeback_sync)        \\\n+  do_stub(compiler, base64_encodeBlock)                                 \\\n+  do_entry(compiler, base64_encodeBlock, base64_encodeBlock,            \\\n+           base64_encodeBlock)                                          \\\n+  do_stub(compiler, base64_decodeBlock)                                 \\\n+  do_entry(compiler, base64_decodeBlock, base64_decodeBlock,            \\\n+           base64_decodeBlock)                                          \\\n+  do_stub(compiler, poly1305_processBlocks)                             \\\n+  do_entry(compiler, poly1305_processBlocks, poly1305_processBlocks,    \\\n+           poly1305_processBlocks)                                      \\\n+  do_stub(compiler, intpoly_montgomeryMult_P256)                        \\\n+  do_entry(compiler, intpoly_montgomeryMult_P256,                       \\\n+           intpoly_montgomeryMult_P256, intpoly_montgomeryMult_P256)    \\\n+  do_stub(compiler, intpoly_assign)                                     \\\n+  do_entry(compiler, intpoly_assign, intpoly_assign, intpoly_assign)    \\\n+  do_stub(compiler, md5_implCompress)                                   \\\n+  do_entry(compiler, md5_implCompress, md5_implCompress,                \\\n+           md5_implCompress)                                            \\\n+  do_stub(compiler, md5_implCompressMB)                                 \\\n+  do_entry(compiler, md5_implCompressMB, md5_implCompressMB,            \\\n+           md5_implCompressMB)                                          \\\n+  do_stub(compiler, sha1_implCompress)                                  \\\n+  do_entry(compiler, sha1_implCompress, sha1_implCompress,              \\\n+           sha1_implCompress)                                           \\\n+  do_stub(compiler, sha1_implCompressMB)                                \\\n+  do_entry(compiler, sha1_implCompressMB, sha1_implCompressMB,          \\\n+           sha1_implCompressMB)                                         \\\n+  do_stub(compiler, sha256_implCompress)                                \\\n+  do_entry(compiler, sha256_implCompress, sha256_implCompress,          \\\n+           sha256_implCompress)                                         \\\n+  do_stub(compiler, sha256_implCompressMB)                              \\\n+  do_entry(compiler, sha256_implCompressMB, sha256_implCompressMB,      \\\n+           sha256_implCompressMB)                                       \\\n+  do_stub(compiler, sha512_implCompress)                                \\\n+  do_entry(compiler, sha512_implCompress, sha512_implCompress,          \\\n+           sha512_implCompress)                                         \\\n+  do_stub(compiler, sha512_implCompressMB)                              \\\n+  do_entry(compiler, sha512_implCompressMB, sha512_implCompressMB,      \\\n+           sha512_implCompressMB)                                       \\\n+  do_stub(compiler, sha3_implCompress)                                  \\\n+  do_entry(compiler, sha3_implCompress, sha3_implCompress,              \\\n+           sha3_implCompress)                                           \\\n+  do_stub(compiler, sha3_implCompressMB)                                \\\n+  do_entry(compiler, sha3_implCompressMB, sha3_implCompressMB,          \\\n+           sha3_implCompressMB)                                         \\\n+  do_stub(compiler, updateBytesAdler32)                                 \\\n+  do_entry(compiler, updateBytesAdler32, updateBytesAdler32,            \\\n+           updateBytesAdler32)                                          \\\n+  do_stub(compiler, multiplyToLen)                                      \\\n+  do_entry(compiler, multiplyToLen, multiplyToLen, multiplyToLen)       \\\n+  do_stub(compiler, squareToLen)                                        \\\n+  do_entry(compiler, squareToLen, squareToLen, squareToLen)             \\\n+  do_stub(compiler, mulAdd)                                             \\\n+  do_entry(compiler, mulAdd, mulAdd, mulAdd)                            \\\n+  do_stub(compiler, montgomeryMultiply)                                 \\\n+  do_entry(compiler, montgomeryMultiply, montgomeryMultiply,            \\\n+           montgomeryMultiply)                                          \\\n+  do_stub(compiler, montgomerySquare)                                   \\\n+  do_entry(compiler, montgomerySquare, montgomerySquare,                \\\n+           montgomerySquare)                                            \\\n+  do_stub(compiler, bigIntegerRightShiftWorker)                         \\\n+  do_entry(compiler, bigIntegerRightShiftWorker,                        \\\n+           bigIntegerRightShiftWorker, bigIntegerRightShift)            \\\n+  do_stub(compiler, bigIntegerLeftShiftWorker)                          \\\n+  do_entry(compiler, bigIntegerLeftShiftWorker,                         \\\n+           bigIntegerLeftShiftWorker, bigIntegerLeftShift)              \\\n+  \/* merge in stubs and entries declared in arch header *\/              \\\n+  STUBGEN_COMPILER_BLOBS_ARCH_DO(do_stub,  do_arch_blob,                \\\n+                                     do_arch_entry, do_arch_entry_init) \\\n+  end_blob(compiler)                                                    \\\n+\n+\n+#define STUBGEN_FINAL_BLOBS_DO(do_blob, end_blob,                       \\\n+                               do_stub,                                 \\\n+                               do_entry, do_entry_init,                 \\\n+                               do_entry_array,                          \\\n+                               do_arch_blob,                            \\\n+                               do_arch_entry, do_arch_entry_init)       \\\n+  do_blob(final)                                                        \\\n+  do_stub(final, verify_oop)                                            \\\n+  do_entry(final, verify_oop, verify_oop_subroutine_entry,              \\\n+           verify_oop_subroutine_entry)                                 \\\n+  do_stub(final, jbyte_arraycopy)                                       \\\n+  do_entry_init(final, jbyte_arraycopy, jbyte_arraycopy,                \\\n+                jbyte_arraycopy, StubRoutines::jbyte_copy)              \\\n+  do_stub(final, jshort_arraycopy)                                      \\\n+  do_entry_init(final, jshort_arraycopy, jshort_arraycopy,              \\\n+                jshort_arraycopy, StubRoutines::jshort_copy)            \\\n+  do_stub(final, jint_arraycopy)                                        \\\n+  do_entry_init(final, jint_arraycopy, jint_arraycopy,                  \\\n+                jint_arraycopy, StubRoutines::jint_copy)                \\\n+  do_stub(final, jlong_arraycopy)                                       \\\n+  do_entry_init(final, jlong_arraycopy, jlong_arraycopy,                \\\n+                jlong_arraycopy, StubRoutines::jlong_copy)              \\\n+  do_stub(final, oop_arraycopy)                                         \\\n+  do_entry_init(final, oop_arraycopy, oop_arraycopy,                    \\\n+                oop_arraycopy_entry, StubRoutines::oop_copy)            \\\n+  do_stub(final, oop_arraycopy_uninit)                                  \\\n+  do_entry_init(final, oop_arraycopy_uninit, oop_arraycopy_uninit,      \\\n+                oop_arraycopy_uninit_entry,                             \\\n+                StubRoutines::oop_copy_uninit)                          \\\n+  do_stub(final, jbyte_disjoint_arraycopy)                              \\\n+  do_entry_init(final, jbyte_disjoint_arraycopy,                        \\\n+                jbyte_disjoint_arraycopy, jbyte_disjoint_arraycopy,     \\\n+                StubRoutines::jbyte_copy)                               \\\n+  do_stub(final, jshort_disjoint_arraycopy)                             \\\n+  do_entry_init(final, jshort_disjoint_arraycopy,                       \\\n+                jshort_disjoint_arraycopy, jshort_disjoint_arraycopy,   \\\n+                StubRoutines::jshort_copy)                              \\\n+  do_stub(final, jint_disjoint_arraycopy)                               \\\n+  do_entry_init(final, jint_disjoint_arraycopy,                         \\\n+                jint_disjoint_arraycopy, jint_disjoint_arraycopy,       \\\n+                StubRoutines::jint_copy)                                \\\n+  do_stub(final, jlong_disjoint_arraycopy)                              \\\n+  do_entry_init(final, jlong_disjoint_arraycopy,                        \\\n+                jlong_disjoint_arraycopy, jlong_disjoint_arraycopy,     \\\n+                StubRoutines::jlong_copy)                               \\\n+  do_stub(final, oop_disjoint_arraycopy)                                \\\n+  do_entry_init(final, oop_disjoint_arraycopy, oop_disjoint_arraycopy,  \\\n+                oop_disjoint_arraycopy_entry, StubRoutines::oop_copy)   \\\n+  do_stub(final, oop_disjoint_arraycopy_uninit)                         \\\n+  do_entry_init(final, oop_disjoint_arraycopy_uninit,                   \\\n+                oop_disjoint_arraycopy_uninit,                          \\\n+                oop_disjoint_arraycopy_uninit_entry,                    \\\n+                StubRoutines::oop_copy_uninit)                          \\\n+  do_stub(final, arrayof_jbyte_arraycopy)                               \\\n+  do_entry_init(final, arrayof_jbyte_arraycopy,                         \\\n+                arrayof_jbyte_arraycopy, arrayof_jbyte_arraycopy,       \\\n+                StubRoutines::arrayof_jbyte_copy)                       \\\n+  do_stub(final, arrayof_jshort_arraycopy)                              \\\n+  do_entry_init(final, arrayof_jshort_arraycopy,                        \\\n+                arrayof_jshort_arraycopy, arrayof_jshort_arraycopy,     \\\n+                StubRoutines::arrayof_jshort_copy)                      \\\n+  do_stub(final, arrayof_jint_arraycopy)                                \\\n+  do_entry_init(final, arrayof_jint_arraycopy, arrayof_jint_arraycopy,  \\\n+                arrayof_jint_arraycopy,                                 \\\n+                StubRoutines::arrayof_jint_copy)                        \\\n+  do_stub(final, arrayof_jlong_arraycopy)                               \\\n+  do_entry_init(final, arrayof_jlong_arraycopy,                         \\\n+                arrayof_jlong_arraycopy, arrayof_jlong_arraycopy,       \\\n+                StubRoutines::arrayof_jlong_copy)                       \\\n+  do_stub(final, arrayof_oop_arraycopy)                                 \\\n+  do_entry_init(final, arrayof_oop_arraycopy, arrayof_oop_arraycopy,    \\\n+                arrayof_oop_arraycopy, StubRoutines::arrayof_oop_copy)  \\\n+  do_stub(final, arrayof_oop_arraycopy_uninit)                          \\\n+  do_entry_init(final, arrayof_oop_arraycopy_uninit,                    \\\n+                arrayof_oop_arraycopy_uninit,                           \\\n+                arrayof_oop_arraycopy_uninit,                           \\\n+                StubRoutines::arrayof_oop_copy_uninit)                  \\\n+  do_stub(final, arrayof_jbyte_disjoint_arraycopy)                      \\\n+  do_entry_init(final, arrayof_jbyte_disjoint_arraycopy,                \\\n+                arrayof_jbyte_disjoint_arraycopy,                       \\\n+                arrayof_jbyte_disjoint_arraycopy,                       \\\n+                StubRoutines::arrayof_jbyte_copy)                       \\\n+  do_stub(final, arrayof_jshort_disjoint_arraycopy)                     \\\n+  do_entry_init(final, arrayof_jshort_disjoint_arraycopy,               \\\n+                arrayof_jshort_disjoint_arraycopy,                      \\\n+                arrayof_jshort_disjoint_arraycopy,                      \\\n+                StubRoutines::arrayof_jshort_copy)                      \\\n+  do_stub(final, arrayof_jint_disjoint_arraycopy)                       \\\n+  do_entry_init(final, arrayof_jint_disjoint_arraycopy,                 \\\n+                arrayof_jint_disjoint_arraycopy,                        \\\n+                arrayof_jint_disjoint_arraycopy,                        \\\n+                StubRoutines::arrayof_jint_copy)                        \\\n+  do_stub(final, arrayof_jlong_disjoint_arraycopy)                      \\\n+  do_entry_init(final, arrayof_jlong_disjoint_arraycopy,                \\\n+                arrayof_jlong_disjoint_arraycopy,                       \\\n+                arrayof_jlong_disjoint_arraycopy,                       \\\n+                StubRoutines::arrayof_jlong_copy)                       \\\n+  do_stub(final, arrayof_oop_disjoint_arraycopy)                        \\\n+  do_entry_init(final, arrayof_oop_disjoint_arraycopy,                  \\\n+                arrayof_oop_disjoint_arraycopy,                         \\\n+                arrayof_oop_disjoint_arraycopy_entry,                   \\\n+                StubRoutines::arrayof_oop_copy)                         \\\n+  do_stub(final, arrayof_oop_disjoint_arraycopy_uninit)                 \\\n+  do_entry_init(final, arrayof_oop_disjoint_arraycopy_uninit,           \\\n+                arrayof_oop_disjoint_arraycopy_uninit,                  \\\n+                arrayof_oop_disjoint_arraycopy_uninit_entry,            \\\n+                StubRoutines::arrayof_oop_copy_uninit)                  \\\n+  do_stub(final, checkcast_arraycopy)                                   \\\n+  do_entry(final, checkcast_arraycopy, checkcast_arraycopy,             \\\n+           checkcast_arraycopy_entry)                                   \\\n+  do_stub(final, checkcast_arraycopy_uninit)                            \\\n+  do_entry(final, checkcast_arraycopy_uninit,                           \\\n+           checkcast_arraycopy_uninit,                                  \\\n+           checkcast_arraycopy_uninit_entry)                            \\\n+  do_stub(final, unsafe_arraycopy)                                      \\\n+  do_entry(final, unsafe_arraycopy, unsafe_arraycopy, unsafe_arraycopy) \\\n+  do_stub(final, generic_arraycopy)                                     \\\n+  do_entry(final, generic_arraycopy, generic_arraycopy,                 \\\n+           generic_arraycopy)                                           \\\n+  do_stub(final, unsafe_setmemory)                                      \\\n+  do_entry(final, unsafe_setmemory, unsafe_setmemory, unsafe_setmemory) \\\n+  do_stub(final, jbyte_fill)                                            \\\n+  do_entry(final, jbyte_fill, jbyte_fill, jbyte_fill)                   \\\n+  do_stub(final, jshort_fill)                                           \\\n+  do_entry(final, jshort_fill, jshort_fill, jshort_fill)                \\\n+  do_stub(final, jint_fill)                                             \\\n+  do_entry(final, jint_fill, jint_fill, jint_fill)                      \\\n+  do_stub(final, arrayof_jbyte_fill)                                    \\\n+  do_entry(final, arrayof_jbyte_fill, arrayof_jbyte_fill,               \\\n+           arrayof_jbyte_fill)                                          \\\n+  do_stub(final, arrayof_jshort_fill)                                   \\\n+  do_entry(final, arrayof_jshort_fill, arrayof_jshort_fill,             \\\n+           arrayof_jshort_fill)                                         \\\n+  do_stub(final, arrayof_jint_fill)                                     \\\n+  do_entry(final, arrayof_jint_fill, arrayof_jint_fill,                 \\\n+           arrayof_jint_fill)                                           \\\n+  do_stub(final, method_entry_barrier)                                  \\\n+  do_entry(final, method_entry_barrier, method_entry_barrier,           \\\n+           method_entry_barrier)                                        \\\n+  do_stub(final, vectorizedMismatch) \/* only used by x86! *\/            \\\n+  do_entry(final, vectorizedMismatch, vectorizedMismatch,               \\\n+           vectorizedMismatch)                                          \\\n+  do_stub(final, upcall_stub_exception_handler)                         \\\n+  do_entry(final, upcall_stub_exception_handler,                        \\\n+           upcall_stub_exception_handler,                               \\\n+           upcall_stub_exception_handler)                               \\\n+  do_stub(final, upcall_stub_load_target)                               \\\n+  do_entry(final, upcall_stub_load_target, upcall_stub_load_target,     \\\n+           upcall_stub_load_target)                                     \\\n+  do_stub(final, lookup_secondary_supers_table)                         \\\n+  do_entry_array(final, lookup_secondary_supers_table,                  \\\n+                 lookup_secondary_supers_table_stubs,                   \\\n+                 lookup_secondary_supers_table_stub,                    \\\n+                 Klass::SECONDARY_SUPERS_TABLE_SIZE)                    \\\n+  do_stub(final, lookup_secondary_supers_table_slow_path)               \\\n+  do_entry(final, lookup_secondary_supers_table_slow_path,              \\\n+           lookup_secondary_supers_table_slow_path_stub,                \\\n+           lookup_secondary_supers_table_slow_path_stub)                \\\n+  \/* merge in stubs and entries declared in arch header *\/              \\\n+  STUBGEN_FINAL_BLOBS_ARCH_DO(do_stub,  do_arch_blob,                   \\\n+                              do_arch_entry, do_arch_entry_init)        \\\n+  end_blob(final)                                                       \\\n+\n+\n+\/\/ Convenience macros for use by template implementations\n@@ -182,1 +935,1 @@\n-\/\/ generate a stub field name\n+\/\/ emit a runtime or stubgen stub field name\n@@ -186,1 +939,1 @@\n-\/\/ generate a blob field name\n+\/\/ emit a runtime blob field name\n@@ -190,0 +943,133 @@\n+\/\/ emit a stubgen blob field name\n+\n+#define STUBGEN_BLOB_FIELD_NAME(base) _ ## base ## _stubs_code\n+\n+\/\/ Convenience templates that emit nothing\n+\n+\/\/ ignore do_blob(blob_name, type) declarations\n+#define DO_BLOB_EMPTY2(blob_name, type)\n+\n+\/\/ ignore do_blob(blob_name) and end_blob(blob_name) declarations\n+#define DO_BLOB_EMPTY1(blob_name)\n+\n+\/\/ ignore do_stub(name, fancy_jump, pass_tls, return_pc) declarations\n+#define DO_STUB_EMPTY4(name, fancy_jump, pass_tls, return_pc)\n+\n+\/\/ ignore do_jvmti_stub(name) declarations\n+#define DO_JVMTI_STUB_EMPTY1(stub_name)\n+\n+\/\/ ignore do_stub(blob_name, stub_name) declarations\n+#define DO_STUB_EMPTY2(blob_name, stub_name)\n+\n+\/\/ ignore do_entry(blob_name, stub_name, fieldname, getter_name) declarations\n+#define DO_ENTRY_EMPTY4(blob_name, stub_name, fieldname, getter_name)\n+\n+\/\/ ignore do_entry(blob_name, stub_name, fieldname, getter_name, init_function) and\n+\/\/ do_entry_array(blob_name, stub_name, fieldname, getter_name, count) declarations\n+#define DO_ENTRY_EMPTY5(blob_name, stub_name, fieldname, getter_name, init_function)\n+\n+\/\/ ignore do_arch_blob(blob_name, size) declarations\n+#define DO_ARCH_BLOB_EMPTY2(arch, size)\n+\n+\/\/ ignore do_arch_entry(arch, blob_name, stub_name, fieldname, getter_name) declarations\n+#define DO_ARCH_ENTRY_EMPTY5(arch, blob_name, stub_name, field_name, getter_name)\n+\n+\/\/ ignore do_arch_entry(arch, blob_name, stub_name, fieldname, getter_name, init_function) declarations\n+#define DO_ARCH_ENTRY_EMPTY6(arch, blob_name, stub_name, field_name, getter_name, init_function)\n+\n+\/\/ The whole shebang!\n+\/\/\n+\/\/ client macro for emitting StubGenerator blobs, stubs and entries\n+\n+#define STUBGEN_ALL_DO(do_blob, end_blob,                               \\\n+                       do_stub,                                         \\\n+                       do_entry, do_entry_init,                         \\\n+                       do_entry_array,                                  \\\n+                       do_arch_blob,                                    \\\n+                       do_arch_entry, do_arch_entry_init)               \\\n+  STUBGEN_INITIAL_BLOBS_DO(do_blob, end_blob,                           \\\n+                           do_stub,                                     \\\n+                           do_entry, do_entry_init,                     \\\n+                           do_entry_array,                              \\\n+                           do_arch_blob,                                \\\n+                           do_arch_entry, do_arch_entry_init)           \\\n+  STUBGEN_CONTINUATION_BLOBS_DO(do_blob, end_blob,                      \\\n+                                do_stub,                                \\\n+                                do_entry, do_entry_init,                \\\n+                                do_entry_array,                         \\\n+                                do_arch_blob,                           \\\n+                                do_arch_entry, do_arch_entry_init)      \\\n+  STUBGEN_COMPILER_BLOBS_DO(do_blob, end_blob,                          \\\n+                            do_stub,                                    \\\n+                            do_entry, do_entry_init,                    \\\n+                            do_entry_array,                             \\\n+                            do_arch_blob,                               \\\n+                            do_arch_entry, do_arch_entry_init)          \\\n+  STUBGEN_FINAL_BLOBS_DO(do_blob, end_blob,                             \\\n+                         do_stub,                                       \\\n+                         do_entry, do_entry_init,                       \\\n+                         do_entry_array,                                \\\n+                         do_arch_blob,                                  \\\n+                         do_arch_entry, do_arch_entry_init)             \\\n+\n+\/\/ client macro to operate only on StubGenerator blobs\n+\n+#define STUBGEN_BLOBS_DO(do_blob)                                       \\\n+  STUBGEN_ALL_DO(do_blob, DO_BLOB_EMPTY1,                               \\\n+                 DO_STUB_EMPTY2,                                        \\\n+                 DO_ENTRY_EMPTY4, DO_ENTRY_EMPTY5,                      \\\n+                 DO_ENTRY_EMPTY5,                                       \\\n+                 DO_ARCH_BLOB_EMPTY2,                                   \\\n+                 DO_ARCH_ENTRY_EMPTY5, DO_ARCH_ENTRY_EMPTY6)            \\\n+\n+\/\/ client macro to operate only on StubGenerator stubs\n+\n+#define STUBGEN_STUBS_DO(do_stub)                                       \\\n+  STUBGEN_ALL_DO(DO_BLOB_EMPTY1, DO_BLOB_EMPTY1,                        \\\n+                 do_stub,                                               \\\n+                 DO_ENTRY_EMPTY4, DO_ENTRY_EMPTY5,                      \\\n+                 DO_ENTRY_EMPTY5,                                       \\\n+                 DO_ARCH_BLOB_EMPTY2,                                   \\\n+                 DO_ARCH_ENTRY_EMPTY5, DO_ARCH_ENTRY_EMPTY6)            \\\n+\n+\/\/ client macro to operate only on StubGenerator blobs and stubs\n+\n+#define STUBGEN_BLOBS_STUBS_DO(do_blob, end_blob, do_stub)              \\\n+  STUBGEN_ALL_DO(do_blob, end_blob,                                     \\\n+                 do_stub,                                               \\\n+                 DO_ENTRY_EMPTY4, DO_ENTRY_EMPTY5,                      \\\n+                 DO_ENTRY_EMPTY5,                                       \\\n+                 DO_ARCH_BLOB_EMPTY2,                                   \\\n+                 DO_ARCH_ENTRY_EMPTY5,DO_ARCH_ENTRY_EMPTY6)             \\\n+\n+\/\/ client macro to operate only on StubGenerator entries\n+\n+#define STUBGEN_ENTRIES_DO(do_entry, do_entry_init, do_entry_array)     \\\n+  STUBGEN_ALL_DO(DO_BLOB_EMPTY1, DO_BLOB_EMPTY1,                        \\\n+                 DO_STUB_EMPTY2,                                        \\\n+                 do_entry, do_entry_init,                               \\\n+                 do_entry_array,                                        \\\n+                 DO_ARCH_BLOB_EMPTY2,                                   \\\n+                 DO_ARCH_ENTRY_EMPTY5, DO_ARCH_ENTRY_EMPTY6)            \\\n+\n+\n+\/\/ client macro to operate only on StubGenerator arch blobs\n+\n+#define STUBGEN_ARCH_BLOBS_DO(do_arch_blob)                             \\\n+  STUBGEN_ALL_DO(DO_BLOB_EMPTY1, DO_BLOB_EMPTY1,                        \\\n+                 DO_STUB_EMPTY2,                                        \\\n+                 DO_ENTRY_EMPTY4, DO_ENTRY_EMPTY5,                      \\\n+                 DO_ENTRY_EMPTY5,                                       \\\n+                 do_arch_blob,                                          \\\n+                 DO_ARCH_ENTRY_EMPTY5, DO_ARCH_ENTRY_EMPTY6)            \\\n+\n+\/\/ client macro to operate only on StubGenerator arch entries\n+\n+#define STUBGEN_ARCH_ENTRIES_DO(do_arch_entry, do_arch_entry_init)      \\\n+  STUBGEN_ALL_DO(DO_BLOB_EMPTY1, DO_BLOB_EMPTY1,                        \\\n+                 DO_STUB_EMPTY2,                                        \\\n+                 DO_ENTRY_EMPTY4, DO_ENTRY_EMPTY5,                      \\\n+                 DO_ENTRY_EMPTY5,                                       \\\n+                 DO_ARCH_BLOB_EMPTY2,                                   \\\n+                 do_arch_entry, do_arch_entry_init)                     \\\n+\n","filename":"src\/hotspot\/share\/runtime\/stubDeclarations.hpp","additions":890,"deletions":4,"binary":false,"changes":894,"status":"modified"},{"patch":"@@ -48,2 +48,2 @@\n-\/\/ Implementation of StubRoutines - for a description\n-\/\/ of how to extend it, see the header file.\n+\/\/ Implementation of StubRoutines - for a description of how to\n+\/\/ declare new blobs, stubs and entries , see stubDefinitions.hpp.\n@@ -51,1 +51,1 @@\n-\/\/ Class Variables\n+\/\/ define arrays to hold stub and blob names\n@@ -53,4 +53,1 @@\n-BufferBlob* StubRoutines::_initial_stubs_code                   = nullptr;\n-BufferBlob* StubRoutines::_final_stubs_code                     = nullptr;\n-BufferBlob* StubRoutines::_compiler_stubs_code                  = nullptr;\n-BufferBlob* StubRoutines::_continuation_stubs_code              = nullptr;\n+\/\/ use a template to generate the initializer for the blob names array\n@@ -58,2 +55,2 @@\n-address StubRoutines::_call_stub_return_address                 = nullptr;\n-address StubRoutines::_call_stub_entry                          = nullptr;\n+#define DEFINE_BLOB_NAME(blob_name)             \\\n+  # blob_name,\n@@ -61,84 +58,3 @@\n-address StubRoutines::_catch_exception_entry                    = nullptr;\n-address StubRoutines::_forward_exception_entry                  = nullptr;\n-jint    StubRoutines::_verify_oop_count                         = 0;\n-address StubRoutines::_verify_oop_subroutine_entry              = nullptr;\n-address StubRoutines::_atomic_xchg_entry                        = nullptr;\n-address StubRoutines::_atomic_cmpxchg_entry                     = nullptr;\n-address StubRoutines::_atomic_cmpxchg_long_entry                = nullptr;\n-address StubRoutines::_atomic_add_entry                         = nullptr;\n-address StubRoutines::_fence_entry                              = nullptr;\n-\n-\/\/ Compiled code entry points default values\n-\/\/ The default functions don't have separate disjoint versions.\n-address StubRoutines::_jbyte_arraycopy          = CAST_FROM_FN_PTR(address, StubRoutines::jbyte_copy);\n-address StubRoutines::_jshort_arraycopy         = CAST_FROM_FN_PTR(address, StubRoutines::jshort_copy);\n-address StubRoutines::_jint_arraycopy           = CAST_FROM_FN_PTR(address, StubRoutines::jint_copy);\n-address StubRoutines::_jlong_arraycopy          = CAST_FROM_FN_PTR(address, StubRoutines::jlong_copy);\n-address StubRoutines::_oop_arraycopy            = CAST_FROM_FN_PTR(address, StubRoutines::oop_copy);\n-address StubRoutines::_oop_arraycopy_uninit     = CAST_FROM_FN_PTR(address, StubRoutines::oop_copy_uninit);\n-address StubRoutines::_jbyte_disjoint_arraycopy          = CAST_FROM_FN_PTR(address, StubRoutines::jbyte_copy);\n-address StubRoutines::_jshort_disjoint_arraycopy         = CAST_FROM_FN_PTR(address, StubRoutines::jshort_copy);\n-address StubRoutines::_jint_disjoint_arraycopy           = CAST_FROM_FN_PTR(address, StubRoutines::jint_copy);\n-address StubRoutines::_jlong_disjoint_arraycopy          = CAST_FROM_FN_PTR(address, StubRoutines::jlong_copy);\n-address StubRoutines::_oop_disjoint_arraycopy            = CAST_FROM_FN_PTR(address, StubRoutines::oop_copy);\n-address StubRoutines::_oop_disjoint_arraycopy_uninit     = CAST_FROM_FN_PTR(address, StubRoutines::oop_copy_uninit);\n-\n-address StubRoutines::_arrayof_jbyte_arraycopy  = CAST_FROM_FN_PTR(address, StubRoutines::arrayof_jbyte_copy);\n-address StubRoutines::_arrayof_jshort_arraycopy = CAST_FROM_FN_PTR(address, StubRoutines::arrayof_jshort_copy);\n-address StubRoutines::_arrayof_jint_arraycopy   = CAST_FROM_FN_PTR(address, StubRoutines::arrayof_jint_copy);\n-address StubRoutines::_arrayof_jlong_arraycopy  = CAST_FROM_FN_PTR(address, StubRoutines::arrayof_jlong_copy);\n-address StubRoutines::_arrayof_oop_arraycopy    = CAST_FROM_FN_PTR(address, StubRoutines::arrayof_oop_copy);\n-address StubRoutines::_arrayof_oop_arraycopy_uninit      = CAST_FROM_FN_PTR(address, StubRoutines::arrayof_oop_copy_uninit);\n-address StubRoutines::_arrayof_jbyte_disjoint_arraycopy  = CAST_FROM_FN_PTR(address, StubRoutines::arrayof_jbyte_copy);\n-address StubRoutines::_arrayof_jshort_disjoint_arraycopy = CAST_FROM_FN_PTR(address, StubRoutines::arrayof_jshort_copy);\n-address StubRoutines::_arrayof_jint_disjoint_arraycopy   = CAST_FROM_FN_PTR(address, StubRoutines::arrayof_jint_copy);\n-address StubRoutines::_arrayof_jlong_disjoint_arraycopy  = CAST_FROM_FN_PTR(address, StubRoutines::arrayof_jlong_copy);\n-address StubRoutines::_arrayof_oop_disjoint_arraycopy    = CAST_FROM_FN_PTR(address, StubRoutines::arrayof_oop_copy);\n-address StubRoutines::_arrayof_oop_disjoint_arraycopy_uninit  = CAST_FROM_FN_PTR(address, StubRoutines::arrayof_oop_copy_uninit);\n-\n-address StubRoutines::_data_cache_writeback              = nullptr;\n-address StubRoutines::_data_cache_writeback_sync         = nullptr;\n-\n-address StubRoutines::_checkcast_arraycopy               = nullptr;\n-address StubRoutines::_checkcast_arraycopy_uninit        = nullptr;\n-address StubRoutines::_unsafe_arraycopy                  = nullptr;\n-address StubRoutines::_generic_arraycopy                 = nullptr;\n-\n-address StubRoutines::_unsafe_setmemory                  = nullptr;\n-\n-address StubRoutines::_jbyte_fill;\n-address StubRoutines::_jshort_fill;\n-address StubRoutines::_jint_fill;\n-address StubRoutines::_arrayof_jbyte_fill;\n-address StubRoutines::_arrayof_jshort_fill;\n-address StubRoutines::_arrayof_jint_fill;\n-\n-address StubRoutines::_aescrypt_encryptBlock               = nullptr;\n-address StubRoutines::_aescrypt_decryptBlock               = nullptr;\n-address StubRoutines::_cipherBlockChaining_encryptAESCrypt = nullptr;\n-address StubRoutines::_cipherBlockChaining_decryptAESCrypt = nullptr;\n-address StubRoutines::_electronicCodeBook_encryptAESCrypt  = nullptr;\n-address StubRoutines::_electronicCodeBook_decryptAESCrypt  = nullptr;\n-address StubRoutines::_counterMode_AESCrypt                = nullptr;\n-address StubRoutines::_galoisCounterMode_AESCrypt          = nullptr;\n-address StubRoutines::_ghash_processBlocks                 = nullptr;\n-address StubRoutines::_chacha20Block                       = nullptr;\n-address StubRoutines::_base64_encodeBlock                  = nullptr;\n-address StubRoutines::_base64_decodeBlock                  = nullptr;\n-address StubRoutines::_poly1305_processBlocks              = nullptr;\n-address StubRoutines::_intpoly_montgomeryMult_P256         = nullptr;\n-address StubRoutines::_intpoly_assign                      = nullptr;\n-\n-address StubRoutines::_md5_implCompress      = nullptr;\n-address StubRoutines::_md5_implCompressMB    = nullptr;\n-address StubRoutines::_sha1_implCompress     = nullptr;\n-address StubRoutines::_sha1_implCompressMB   = nullptr;\n-address StubRoutines::_sha256_implCompress   = nullptr;\n-address StubRoutines::_sha256_implCompressMB = nullptr;\n-address StubRoutines::_sha512_implCompress   = nullptr;\n-address StubRoutines::_sha512_implCompressMB = nullptr;\n-address StubRoutines::_sha3_implCompress     = nullptr;\n-address StubRoutines::_sha3_implCompressMB   = nullptr;\n-\n-address StubRoutines::_updateBytesCRC32 = nullptr;\n-address StubRoutines::_crc_table_adr =    nullptr;\n+const char* StubRoutines::_blob_names[StubGenBlobId::NUM_BLOBIDS] = {\n+  STUBGEN_BLOBS_DO(DEFINE_BLOB_NAME)\n+};\n@@ -146,1 +62,1 @@\n-address StubRoutines::_string_indexof_array[4]   =    { nullptr };\n+#undef DEFINE_BLOB_NAME\n@@ -148,26 +64,2 @@\n-address StubRoutines::_crc32c_table_addr = nullptr;\n-address StubRoutines::_updateBytesCRC32C = nullptr;\n-address StubRoutines::_updateBytesAdler32 = nullptr;\n-\n-address StubRoutines::_multiplyToLen = nullptr;\n-address StubRoutines::_squareToLen = nullptr;\n-address StubRoutines::_mulAdd = nullptr;\n-address StubRoutines::_montgomeryMultiply = nullptr;\n-address StubRoutines::_montgomerySquare = nullptr;\n-address StubRoutines::_bigIntegerRightShiftWorker = nullptr;\n-address StubRoutines::_bigIntegerLeftShiftWorker = nullptr;\n-\n-address StubRoutines::_vectorizedMismatch = nullptr;\n-\n-address StubRoutines::_dexp = nullptr;\n-address StubRoutines::_dlog = nullptr;\n-address StubRoutines::_dlog10 = nullptr;\n-address StubRoutines::_fmod = nullptr;\n-address StubRoutines::_dpow = nullptr;\n-address StubRoutines::_dsin = nullptr;\n-address StubRoutines::_dcos = nullptr;\n-address StubRoutines::_dlibm_sin_cos_huge = nullptr;\n-address StubRoutines::_dlibm_reduce_pi04l = nullptr;\n-address StubRoutines::_dlibm_tan_cot_huge = nullptr;\n-address StubRoutines::_dtan = nullptr;\n-address StubRoutines::_dtanh = nullptr;\n+#define DEFINE_STUB_NAME(blob_name, stub_name)          \\\n+  # stub_name ,                                         \\\n@@ -175,2 +67,20 @@\n-address StubRoutines::_load_inline_type_fields_in_regs = nullptr;\n-address StubRoutines::_store_inline_type_fields_to_buf = nullptr;\n+\/\/ use a template to generate the initializer for the stub names array\n+const char* StubRoutines::_stub_names[StubGenStubId::NUM_STUBIDS] = {\n+  STUBGEN_STUBS_DO(DEFINE_STUB_NAME)\n+};\n+\n+#undef DEFINE_STUB_NAME\n+\n+\/\/ Define fields used to store blobs\n+\n+#define DEFINE_BLOB_FIELD(blob_name) \\\n+  BufferBlob* StubRoutines:: STUBGEN_BLOB_FIELD_NAME(blob_name) = nullptr;\n+\n+STUBGEN_BLOBS_DO(DEFINE_BLOB_FIELD)\n+\n+#undef DEFINE_BLOB_FIELD\n+\n+\/\/ Define fields used to store stub entries\n+\n+#define DEFINE_ENTRY_FIELD(blob_name, stub_name, field_name, getter_name) \\\n+  address StubRoutines:: STUB_FIELD_NAME(field_name) = nullptr;\n@@ -178,2 +88,2 @@\n-address StubRoutines::_f2hf = nullptr;\n-address StubRoutines::_hf2f = nullptr;\n+#define DEFINE_ENTRY_FIELD_INIT(blob_name, stub_name, field_name, getter_name, init_function) \\\n+  address StubRoutines:: STUB_FIELD_NAME(field_name) = CAST_FROM_FN_PTR(address, init_function);\n@@ -181,0 +91,12 @@\n+#define DEFINE_ENTRY_FIELD_ARRAY(blob_name, stub_name, field_name, getter_name, count) \\\n+  address StubRoutines:: STUB_FIELD_NAME(field_name)[count] = { nullptr };\n+\n+STUBGEN_ENTRIES_DO(DEFINE_ENTRY_FIELD, DEFINE_ENTRY_FIELD_INIT, DEFINE_ENTRY_FIELD_ARRAY)\n+\n+#undef DEFINE_ENTRY_FIELD_ARRAY\n+#undef DEFINE_ENTRY_FIELD_INIT\n+#undef DEFINE_ENTRY_FIELD\n+\n+jint    StubRoutines::_verify_oop_count                         = 0;\n+\n+address StubRoutines::_string_indexof_array[4]   =    { nullptr };\n@@ -184,3 +106,55 @@\n-address StubRoutines::_method_entry_barrier = nullptr;\n-address StubRoutines::_array_sort = nullptr;\n-address StubRoutines::_array_partition  = nullptr;\n+const char* StubRoutines::get_blob_name(StubGenBlobId id) {\n+  assert(0 <= id && id < StubGenBlobId::NUM_BLOBIDS, \"invalid blob id\");\n+  return _blob_names[id];\n+}\n+\n+const char* StubRoutines::get_stub_name(StubGenStubId id) {\n+  assert(0 <= id && id < StubGenStubId::NUM_STUBIDS, \"invalid stub id\");\n+  return _stub_names[id];\n+}\n+\n+#ifdef ASSERT\n+\n+\/\/ array holding start and end indices for stub ids associated with a\n+\/\/ given blob. Given a blob with id (StubGenBlobId) blob_id for any\n+\/\/ stub with id (StubGenStubId) stub_id declared within the blob:\n+\/\/ _blob_offsets[blob_id] <= stub_id < _blob_offsets[blob_id+1]\n+\n+static int _blob_limits[StubGenBlobId::NUM_BLOBIDS + 1];\n+\n+\/\/ macro used to compute blob limits\n+#define BLOB_COUNT(blob_name)                                           \\\n+  counter += StubGenStubId_ ## blob_name :: NUM_STUBIDS_ ## blob_name;  \\\n+  _blob_limits[++index] = counter;                                      \\\n+\n+\/\/ macro that checks stubs are associated with the correct blobs\n+#define STUB_VERIFY(blob_name, stub_name)                               \\\n+  localStubId = (int) (StubGenStubId_ ## blob_name :: blob_name ## _ ## stub_name ## _id); \\\n+  globalStubId = (int) (StubGenStubId:: stub_name ## _id);              \\\n+  blobId = (int) (StubGenBlobId:: blob_name ## _id);                    \\\n+  assert((globalStubId >= _blob_limits[blobId] &&                       \\\n+          globalStubId < _blob_limits[blobId+1]),                       \\\n+         \"stub \" # stub_name \" uses incorrect blob name \" # blob_name); \\\n+  assert(globalStubId == _blob_limits[blobId] + localStubId,            \\\n+         \"stub \" # stub_name \" id found at wrong offset!\");             \\\n+\n+bool verifyStubIds() {\n+  \/\/ first compute the blob limits\n+  int counter = 0;\n+  int index = 0;\n+  \/\/ populate offsets table with cumulative total of local enum counts\n+  STUBGEN_BLOBS_DO(BLOB_COUNT);\n+\n+  \/\/ ensure 1) global stub ids lie in the range of the associated blob\n+  \/\/ and 2) each blob's base + local stub id == global stub id\n+  int globalStubId, blobId, localStubId;\n+  STUBGEN_STUBS_DO(STUB_VERIFY);\n+  return true;\n+}\n+\n+#undef BLOB_COUNT\n+#undef STUB_VERIFY\n+\n+\/\/ ensure we verify the blob ids when this compile unit is first entered\n+bool _verified_stub_ids = verifyStubIds();\n+\n@@ -188,4 +162,1 @@\n-address StubRoutines::_cont_thaw          = nullptr;\n-address StubRoutines::_cont_returnBarrier = nullptr;\n-address StubRoutines::_cont_returnBarrierExc = nullptr;\n-address StubRoutines::_cont_preempt_stub = nullptr;\n+\/\/ macro used by stub to blob translation\n@@ -193,2 +164,3 @@\n-address StubRoutines::_upcall_stub_exception_handler = nullptr;\n-address StubRoutines::_upcall_stub_load_target = nullptr;\n+#define BLOB_CHECK_OFFSET(blob_name)                                \\\n+  if (id < _blob_limits[((int)blobId) + 1]) { return blobId; }      \\\n+  blobId = StubGenBlobId:: blob_name ## _id;                        \\\n@@ -196,2 +168,19 @@\n-address StubRoutines::_lookup_secondary_supers_table_slow_path_stub = nullptr;\n-address StubRoutines::_lookup_secondary_supers_table_stubs[Klass::SECONDARY_SUPERS_TABLE_SIZE] = { nullptr };\n+\/\/ translate a global stub id to an associated blob id based on the\n+\/\/ computed blob limits\n+\n+StubGenBlobId StubRoutines::stub_to_blob(StubGenStubId stubId) {\n+  int id = (int)stubId;\n+  assert(id > ((int)StubGenStubId::NO_STUBID) && id < ((int)StubGenStubId::NUM_STUBIDS), \"stub id out of range!\");\n+  \/\/ start with no blob to catch stub id == -1\n+  StubGenBlobId blobId = StubGenBlobId::NO_BLOBID;\n+  STUBGEN_BLOBS_DO(BLOB_CHECK_OFFSET);\n+  \/\/ if we reach here we should have the last blob id\n+  assert(blobId == StubGenBlobId::NUM_BLOBIDS - 1, \"unexpected blob id\");\n+  return blobId;\n+}\n+\n+#endif \/\/ ASSERT\n+\n+\/\/ TODO: update with 8343767\n+address StubRoutines::_load_inline_type_fields_in_regs = nullptr;\n+address StubRoutines::_store_inline_type_fields_to_buf = nullptr;\n@@ -206,1 +195,1 @@\n-extern void StubGenerator_generate(CodeBuffer* code, StubCodeGenerator::StubsKind kind); \/\/ only interface to generators\n+extern void StubGenerator_generate(CodeBuffer* code, StubGenBlobId blob_id); \/\/ only interface to generators\n@@ -234,1 +223,1 @@\n-static BufferBlob* initialize_stubs(StubCodeGenerator::StubsKind kind,\n+static BufferBlob* initialize_stubs(StubGenBlobId blob_id,\n@@ -248,1 +237,1 @@\n-  StubGenerator_generate(&buffer, kind);\n+  StubGenerator_generate(&buffer, blob_id);\n@@ -263,7 +252,13 @@\n-void StubRoutines::initialize_initial_stubs() {\n-  if (_initial_stubs_code == nullptr) {\n-    _initial_stubs_code = initialize_stubs(StubCodeGenerator::Initial_stubs,\n-                                           _initial_stubs_code_size, 10,\n-                                           \"StubRoutines generation initial stubs\",\n-                                           \"StubRoutines (initial stubs)\",\n-                                           \"_initial_stubs_code_size\");\n+#define DEFINE_BLOB_INIT_METHOD(blob_name)                              \\\n+  void StubRoutines::initialize_ ## blob_name ## _stubs() {             \\\n+    if (STUBGEN_BLOB_FIELD_NAME(blob_name) == nullptr) {                \\\n+      StubGenBlobId blob_id = StubGenBlobId:: STUB_ID_NAME(blob_name);  \\\n+      int size = _ ## blob_name ## _code_size;                          \\\n+      int max_aligned_size = 10;                                        \\\n+      const char* timer_msg = \"StubRoutines generation \" # blob_name \" stubs\"; \\\n+      const char* name = \"StubRoutines (\" # blob_name \"stubs)\";         \\\n+      const char* assert_msg = \"_\" # blob_name \"_code_size\";            \\\n+      STUBGEN_BLOB_FIELD_NAME(blob_name) =                              \\\n+        initialize_stubs(blob_id, size, max_aligned_size, timer_msg,    \\\n+                         name, assert_msg);                             \\\n+    }                                                                   \\\n@@ -271,19 +266,1 @@\n-}\n-void StubRoutines::initialize_continuation_stubs() {\n-  if (_continuation_stubs_code == nullptr) {\n-    _continuation_stubs_code = initialize_stubs(StubCodeGenerator::Continuation_stubs,\n-                                           _continuation_stubs_code_size, 10,\n-                                           \"StubRoutines generation continuation stubs\",\n-                                           \"StubRoutines (continuation stubs)\",\n-                                           \"_continuation_stubs_code_size\");\n-  }\n-}\n-void StubRoutines::initialize_compiler_stubs() {\n-  if (_compiler_stubs_code == nullptr) {\n-    _compiler_stubs_code = initialize_stubs(StubCodeGenerator::Compiler_stubs,\n-                                           _compiler_stubs_code_size, 100,\n-                                           \"StubRoutines generation compiler stubs\",\n-                                           \"StubRoutines (compiler stubs)\",\n-                                           \"_compiler_stubs_code_size\");\n-  }\n-}\n+STUBGEN_BLOBS_DO(DEFINE_BLOB_INIT_METHOD)\n@@ -293,8 +270,6 @@\n-void StubRoutines::initialize_final_stubs() {\n-  if (_final_stubs_code == nullptr) {\n-    _final_stubs_code = initialize_stubs(StubCodeGenerator::Final_stubs,\n-                                         _final_stubs_code_size, 10,\n-                                         \"StubRoutines generation final stubs\",\n-                                         \"StubRoutines (final stubs)\",\n-                                         \"_final_stubs_code_size\");\n-  }\n+#undef DEFINE_BLOB_INIT_METHOD\n+\n+\n+#define DEFINE_BLOB_INIT_FUNCTION(blob_name)            \\\n+void blob_name ## _stubs_init()  {                      \\\n+  StubRoutines::initialize_ ## blob_name ## _stubs();   \\\n@@ -303,3 +278,10 @@\n-void initial_stubs_init()      { StubRoutines::initialize_initial_stubs(); }\n-void continuation_stubs_init() { StubRoutines::initialize_continuation_stubs(); }\n-void final_stubs_init()        { StubRoutines::initialize_final_stubs(); }\n+STUBGEN_BLOBS_DO(DEFINE_BLOB_INIT_FUNCTION)\n+\n+#undef DEFINE_BLOB_INIT_FUNCTION\n+\n+\/*\n+ * we generate the underlying driver method but this wrapper is needed\n+ * to perform special handling depending on where the compiler init\n+ * gets called from. it ought to be possible to remove this at some\n+ * point and have adeterminate ordered init.\n+ *\/\n@@ -322,0 +304,1 @@\n+\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":158,"deletions":175,"binary":false,"changes":333,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -34,0 +34,1 @@\n+#include \"runtime\/stubDeclarations.hpp\"\n@@ -153,0 +154,45 @@\n+\/\/ declare stubgen blob id enum\n+\n+#define BLOB_ENUM_DECLARE(blob_name) \\\n+  STUB_ID_NAME(blob_name),\n+\n+enum StubGenBlobId : int {\n+  NO_BLOBID = -1,\n+  STUBGEN_BLOBS_DO(BLOB_ENUM_DECLARE)\n+  NUM_BLOBIDS\n+};\n+\n+#undef BLOB_ENUM_DECLARE\n+\n+\/\/ declare blob local stub id enums\n+\n+#define BLOB_LOCAL_ENUM_START(blob_name)        \\\n+  enum StubGenStubId_ ## blob_name {            \\\n+    NO_STUBID_ ## blob_name = -1,\n+\n+#define BLOB_LOCAL_ENUM_END(blob_name)   \\\n+    NUM_STUBIDS_ ## blob_name            \\\n+  };\n+\n+#define BLOB_LOCAL_STUB_ENUM_DECLARE(blob_name, stub_name) \\\n+  blob_name ## _ ## stub_name ## _id,\n+\n+STUBGEN_BLOBS_STUBS_DO(BLOB_LOCAL_ENUM_START, BLOB_LOCAL_ENUM_END, BLOB_LOCAL_STUB_ENUM_DECLARE)\n+\n+#undef BLOB_LOCAL_ENUM_START\n+#undef BLOB_LOCAL_ENUM_END\n+#undef BLOB_LOCAL_STUB_ENUM_DECLARE\n+\n+\/\/ declare global stub id enum\n+\n+#define STUB_ENUM_DECLARE(blob_name, stub_name) \\\n+  STUB_ID_NAME(stub_name) ,\n+\n+enum StubGenStubId : int {\n+  NO_STUBID = -1,\n+  STUBGEN_STUBS_DO(STUB_ENUM_DECLARE)\n+  NUM_STUBIDS\n+};\n+\n+#undef STUB_ENUM_DECLARE\n+\n@@ -155,1 +201,1 @@\n- public:\n+public:\n@@ -158,0 +204,4 @@\n+  friend class VMStructs;\n+#if INCLUDE_JVMCI\n+  friend class JVMCIVMStructs;\n+#endif\n@@ -161,96 +211,1 @@\n-  static jint    _verify_oop_count;\n-  static address _verify_oop_subroutine_entry;\n-\n-  static address _call_stub_return_address;                \/\/ the return PC, when returning to a call stub\n-  static address _call_stub_entry;\n-  static address _forward_exception_entry;\n-  static address _catch_exception_entry;\n-\n-  static address _atomic_xchg_entry;\n-  static address _atomic_cmpxchg_entry;\n-  static address _atomic_cmpxchg_long_entry;\n-  static address _atomic_add_entry;\n-  static address _fence_entry;\n-\n-  static BufferBlob* _initial_stubs_code;                  \/\/ code buffer for initial routines\n-  static BufferBlob* _continuation_stubs_code;             \/\/ code buffer for continuation stubs\n-  static BufferBlob* _compiler_stubs_code;                 \/\/ code buffer for C2 intrinsics\n-  static BufferBlob* _final_stubs_code;                    \/\/ code buffer for all other routines\n-\n-  static address _array_sort;\n-  static address _array_partition;\n-  \/\/ Leaf routines which implement arraycopy and their addresses\n-  \/\/ arraycopy operands aligned on element type boundary\n-  static address _jbyte_arraycopy;\n-  static address _jshort_arraycopy;\n-  static address _jint_arraycopy;\n-  static address _jlong_arraycopy;\n-  static address _oop_arraycopy, _oop_arraycopy_uninit;\n-  static address _jbyte_disjoint_arraycopy;\n-  static address _jshort_disjoint_arraycopy;\n-  static address _jint_disjoint_arraycopy;\n-  static address _jlong_disjoint_arraycopy;\n-  static address _oop_disjoint_arraycopy, _oop_disjoint_arraycopy_uninit;\n-\n-  \/\/ arraycopy operands aligned on zero'th element boundary\n-  \/\/ These are identical to the ones aligned aligned on an\n-  \/\/ element type boundary, except that they assume that both\n-  \/\/ source and destination are HeapWord aligned.\n-  static address _arrayof_jbyte_arraycopy;\n-  static address _arrayof_jshort_arraycopy;\n-  static address _arrayof_jint_arraycopy;\n-  static address _arrayof_jlong_arraycopy;\n-  static address _arrayof_oop_arraycopy, _arrayof_oop_arraycopy_uninit;\n-  static address _arrayof_jbyte_disjoint_arraycopy;\n-  static address _arrayof_jshort_disjoint_arraycopy;\n-  static address _arrayof_jint_disjoint_arraycopy;\n-  static address _arrayof_jlong_disjoint_arraycopy;\n-  static address _arrayof_oop_disjoint_arraycopy, _arrayof_oop_disjoint_arraycopy_uninit;\n-\n-  \/\/ cache line writeback\n-  static address _data_cache_writeback;\n-  static address _data_cache_writeback_sync;\n-\n-  \/\/ these are recommended but optional:\n-  static address _checkcast_arraycopy, _checkcast_arraycopy_uninit;\n-  static address _unsafe_arraycopy;\n-  static address _generic_arraycopy;\n-\n-  static address _unsafe_setmemory;\n-\n-  static address _jbyte_fill;\n-  static address _jshort_fill;\n-  static address _jint_fill;\n-  static address _arrayof_jbyte_fill;\n-  static address _arrayof_jshort_fill;\n-  static address _arrayof_jint_fill;\n-\n-  static address _aescrypt_encryptBlock;\n-  static address _aescrypt_decryptBlock;\n-  static address _cipherBlockChaining_encryptAESCrypt;\n-  static address _cipherBlockChaining_decryptAESCrypt;\n-  static address _electronicCodeBook_encryptAESCrypt;\n-  static address _electronicCodeBook_decryptAESCrypt;\n-  static address _counterMode_AESCrypt;\n-  static address _galoisCounterMode_AESCrypt;\n-  static address _ghash_processBlocks;\n-  static address _chacha20Block;\n-  static address _base64_encodeBlock;\n-  static address _base64_decodeBlock;\n-  static address _poly1305_processBlocks;\n-  static address _intpoly_montgomeryMult_P256;\n-  static address _intpoly_assign;\n-\n-  static address _md5_implCompress;\n-  static address _md5_implCompressMB;\n-  static address _sha1_implCompress;\n-  static address _sha1_implCompressMB;\n-  static address _sha256_implCompress;\n-  static address _sha256_implCompressMB;\n-  static address _sha512_implCompress;\n-  static address _sha512_implCompressMB;\n-  static address _sha3_implCompress;\n-  static address _sha3_implCompressMB;\n-\n-  static address _updateBytesCRC32;\n-  static address _crc_table_adr;\n+\/\/ declare blob and stub name storage and associated lookup methods\n@@ -258,1 +213,4 @@\n-  static address _string_indexof_array[4];\n+private:\n+  static bool _inited_names;\n+  static const char* _blob_names[StubGenBlobId::NUM_BLOBIDS];\n+  static const char* _stub_names[StubGenStubId::NUM_STUBIDS];\n@@ -260,36 +218,4 @@\n-  static address _crc32c_table_addr;\n-  static address _updateBytesCRC32C;\n-  static address _updateBytesAdler32;\n-\n-  static address _multiplyToLen;\n-  static address _squareToLen;\n-  static address _mulAdd;\n-  static address _montgomeryMultiply;\n-  static address _montgomerySquare;\n-  static address _bigIntegerRightShiftWorker;\n-  static address _bigIntegerLeftShiftWorker;\n-\n-  static address _vectorizedMismatch;\n-\n-  static address _dexp;\n-  static address _dlog;\n-  static address _dlog10;\n-  static address _dpow;\n-  static address _dsin;\n-  static address _dcos;\n-  static address _dlibm_sin_cos_huge;\n-  static address _dlibm_reduce_pi04l;\n-  static address _dlibm_tan_cot_huge;\n-  static address _dtan;\n-  static address _dtanh;\n-  static address _fmod;\n-\n-  static address _f2hf;\n-  static address _hf2f;\n-\n-  static address _method_entry_barrier;\n-\n-  static address _cont_thaw;\n-  static address _cont_returnBarrier;\n-  static address _cont_returnBarrierExc;\n-  static address _cont_preempt_stub;\n+public:\n+  static bool init_names();\n+  static const char* get_blob_name(StubGenBlobId id);\n+  static const char* get_stub_name(StubGenStubId id);\n@@ -297,2 +223,1 @@\n-  static address _load_inline_type_fields_in_regs;\n-  static address _store_inline_type_fields_to_buf;\n+\/\/ declare blob fields\n@@ -300,3 +225,2 @@\n-  \/\/ Vector Math Routines\n-  static address _vector_f_math[VectorSupport::NUM_VEC_SIZES][VectorSupport::NUM_VECTOR_OP_MATH];\n-  static address _vector_d_math[VectorSupport::NUM_VEC_SIZES][VectorSupport::NUM_VECTOR_OP_MATH];\n+#define DECLARE_BLOB_FIELD(blob_name) \\\n+  static BufferBlob* STUBGEN_BLOB_FIELD_NAME(blob_name);\n@@ -304,2 +228,2 @@\n-  static address _upcall_stub_exception_handler;\n-  static address _upcall_stub_load_target;\n+private:\n+  STUBGEN_BLOBS_DO(DECLARE_BLOB_FIELD);\n@@ -307,2 +231,1 @@\n-  static address _lookup_secondary_supers_table_stubs[];\n-  static address _lookup_secondary_supers_table_slow_path_stub;\n+#undef DECLARE_BLOB_FIELD\n@@ -310,6 +233,1 @@\n- public:\n-  \/\/ Initialization\/Testing\n-  static void    initialize_initial_stubs();               \/\/ must happen before universe::genesis\n-  static void    initialize_continuation_stubs();          \/\/ must happen after  universe::genesis\n-  static void    initialize_compiler_stubs();              \/\/ must happen after  universe::genesis\n-  static void    initialize_final_stubs();                 \/\/ must happen after  universe::genesis\n+\/\/ declare fields to store entry addresses\n@@ -317,1 +235,2 @@\n-  static bool is_stub_code(address addr)                   { return contains(addr); }\n+#define DECLARE_ENTRY_FIELD(blob_name, stub_name, field_name, getter_name) \\\n+  static address STUB_FIELD_NAME(field_name);\n@@ -319,7 +238,2 @@\n-  static bool contains(address addr) {\n-    return\n-      (_initial_stubs_code      != nullptr && _initial_stubs_code->blob_contains(addr))  ||\n-      (_continuation_stubs_code != nullptr && _continuation_stubs_code->blob_contains(addr)) ||\n-      (_compiler_stubs_code     != nullptr && _compiler_stubs_code->blob_contains(addr)) ||\n-      (_final_stubs_code        != nullptr && _final_stubs_code->blob_contains(addr)) ;\n-  }\n+#define DECLARE_ENTRY_FIELD_INIT(blob_name, stub_name, field_name, getter_name, init_function) \\\n+  DECLARE_ENTRY_FIELD(blob_name, stub_name, field_name, getter_name)\n@@ -327,4 +241,2 @@\n-  static RuntimeBlob* initial_stubs_code()      { return _initial_stubs_code; }\n-  static RuntimeBlob* continuation_stubs_code() { return _continuation_stubs_code; }\n-  static RuntimeBlob* compiler_stubs_code()     { return _compiler_stubs_code; }\n-  static RuntimeBlob* final_stubs_code()        { return _final_stubs_code; }\n+#define DECLARE_ENTRY_FIELD_ARRAY(blob_name, stub_name, field_name, getter_name, count) \\\n+  static address STUB_FIELD_NAME(field_name)[count];\n@@ -332,5 +244,35 @@\n-  \/\/ Debugging\n-  static jint    verify_oop_count()                        { return _verify_oop_count; }\n-  static jint*   verify_oop_count_addr()                   { return &_verify_oop_count; }\n-  \/\/ a subroutine for debugging the GC\n-  static address verify_oop_subroutine_entry_address()     { return (address)&_verify_oop_subroutine_entry; }\n+private:\n+  STUBGEN_ENTRIES_DO(DECLARE_ENTRY_FIELD, DECLARE_ENTRY_FIELD_INIT, DECLARE_ENTRY_FIELD_ARRAY);\n+\n+#undef DECLARE_ENTRY_FIELD_ARRAY\n+#undef DECLARE_ENTRY_FIELD_INIT\n+#undef DECLARE_ENTRY_FIELD\n+\n+\/\/ declare getters and setters for entry addresses\n+\n+#define DEFINE_ENTRY_GETTER(blob_name, stub_name, field_name, getter_name) \\\n+  static address getter_name() { return STUB_FIELD_NAME(field_name); } \\\n+\n+#define DEFINE_ENTRY_GETTER_INIT(blob_name, stub_name, field_name, getter_name, init_function) \\\n+  DEFINE_ENTRY_GETTER(blob_name, stub_name, field_name, getter_name)\n+\n+#define DEFINE_ENTRY_GETTER_ARRAY(blob_name, stub_name, field_name, getter_name, count) \\\n+  static address getter_name(int idx) {                                 \\\n+    assert(idx < count, \"out of bounds\");                               \\\n+    return STUB_FIELD_NAME(field_name)[idx];                            \\\n+  }                                                                     \\\n+\n+public:\n+  STUBGEN_ENTRIES_DO(DEFINE_ENTRY_GETTER, DEFINE_ENTRY_GETTER_INIT, DEFINE_ENTRY_GETTER_ARRAY);\n+\n+#undef DEFINE_ENTRY_GETTER_ARRAY\n+#undef DEFINE_ENTRY_GETTER_INIT\n+#undef DEFINE_ENTRY_GETTER\n+\n+public:\n+\n+#define DECLARE_BLOB_INIT_METHOD(blob_name)     \\\n+  static void initialize_ ## blob_name ## _stubs();\n+\n+  static address _load_inline_type_fields_in_regs;\n+  static address _store_inline_type_fields_to_buf;\n@@ -338,1 +280,5 @@\n-  static address catch_exception_entry()                   { return _catch_exception_entry; }\n+  STUBGEN_BLOBS_DO(DECLARE_BLOB_INIT_METHOD)\n+\n+#undef DECLARE_BLOB_INIT_METHOD\n+\n+public:\n@@ -352,1 +298,12 @@\n-  static CallStub call_stub()                              { return CAST_TO_FN_PTR(CallStub, _call_stub_entry); }\n+  static jint    _verify_oop_count;\n+\n+public:\n+  \/\/ this is used by x86_64 to expose string index stubs to the opto\n+  \/\/ library as a target to a call planted before back end lowering.\n+  \/\/ all other arches plant the call to the stub during back end\n+  \/\/ lowering and use arch-specific entries. we really need to\n+  \/\/ rationalise this at some point.\n+\n+  static address _string_indexof_array[4];\n+\n+  \/* special case: stub employs array of entries *\/\n@@ -354,2 +311,3 @@\n-  \/\/ Exceptions\n-  static address forward_exception_entry()                 { return _forward_exception_entry; }\n+  \/\/ Vector Math Routines\n+  static address _vector_f_math[VectorSupport::NUM_VEC_SIZES][VectorSupport::NUM_VECTOR_OP_MATH];\n+  static address _vector_d_math[VectorSupport::NUM_VEC_SIZES][VectorSupport::NUM_VECTOR_OP_MATH];\n@@ -357,5 +315,35 @@\n-  static address atomic_xchg_entry()                       { return _atomic_xchg_entry; }\n-  static address atomic_cmpxchg_entry()                    { return _atomic_cmpxchg_entry; }\n-  static address atomic_cmpxchg_long_entry()               { return _atomic_cmpxchg_long_entry; }\n-  static address atomic_add_entry()                        { return _atomic_add_entry; }\n-  static address fence_entry()                             { return _fence_entry; }\n+  static bool is_stub_code(address addr)                   { return contains(addr); }\n+\n+  \/\/ generate code to implement method contains\n+\n+#define CHECK_ADDRESS_IN_BLOB(blob_name) \\\n+  blob = STUBGEN_BLOB_FIELD_NAME(blob_name); \\\n+  if (blob != nullptr && blob->blob_contains(addr)) { return true; }\n+\n+  static bool contains(address addr) {\n+    BufferBlob *blob;\n+    STUBGEN_BLOBS_DO(CHECK_ADDRESS_IN_BLOB)\n+    return false;\n+  }\n+#undef CHECK_ADDRESS_IN_BLOB\n+\/\/ define getters for stub code blobs\n+\n+#define DEFINE_BLOB_GETTER(blob_name) \\\n+  static RuntimeBlob* blob_name ## _stubs_code() { return _ ## blob_name ## _stubs_code; }\n+\n+  STUBGEN_BLOBS_DO(DEFINE_BLOB_GETTER);\n+\n+#undef DEFINE_BLOB_GETTER\n+\n+#ifdef ASSERT\n+  \/\/ provide a translation from stub id to its associated blob id\n+  static StubGenBlobId stub_to_blob(StubGenStubId stubId);\n+#endif\n+\n+  \/\/ Debugging\n+  static jint    verify_oop_count()                        { return _verify_oop_count; }\n+  static jint*   verify_oop_count_addr()                   { return &_verify_oop_count; }\n+  \/\/ a subroutine for debugging the GC\n+  static address verify_oop_subroutine_entry_address()     { return (address)&_verify_oop_subroutine_entry; }\n+\n+  static CallStub call_stub()                              { return CAST_TO_FN_PTR(CallStub, _call_stub_entry); }\n@@ -365,4 +353,0 @@\n-  static address jbyte_arraycopy()  { return _jbyte_arraycopy; }\n-  static address jshort_arraycopy() { return _jshort_arraycopy; }\n-  static address jint_arraycopy()   { return _jint_arraycopy; }\n-  static address jlong_arraycopy()  { return _jlong_arraycopy; }\n@@ -372,4 +356,1 @@\n-  static address jbyte_disjoint_arraycopy()  { return _jbyte_disjoint_arraycopy; }\n-  static address jshort_disjoint_arraycopy() { return _jshort_disjoint_arraycopy; }\n-  static address jint_disjoint_arraycopy()   { return _jint_disjoint_arraycopy; }\n-  static address jlong_disjoint_arraycopy()  { return _jlong_disjoint_arraycopy; }\n+\n@@ -380,4 +361,0 @@\n-  static address arrayof_jbyte_arraycopy()  { return _arrayof_jbyte_arraycopy; }\n-  static address arrayof_jshort_arraycopy() { return _arrayof_jshort_arraycopy; }\n-  static address arrayof_jint_arraycopy()   { return _arrayof_jint_arraycopy; }\n-  static address arrayof_jlong_arraycopy()  { return _arrayof_jlong_arraycopy; }\n@@ -388,4 +365,0 @@\n-  static address arrayof_jbyte_disjoint_arraycopy()  { return _arrayof_jbyte_disjoint_arraycopy; }\n-  static address arrayof_jshort_disjoint_arraycopy() { return _arrayof_jshort_disjoint_arraycopy; }\n-  static address arrayof_jint_disjoint_arraycopy()   { return _arrayof_jint_disjoint_arraycopy; }\n-  static address arrayof_jlong_disjoint_arraycopy()  { return _arrayof_jlong_disjoint_arraycopy; }\n@@ -395,2 +368,0 @@\n-  static address data_cache_writeback()              { return _data_cache_writeback; }\n-  static address data_cache_writeback_sync()         { return _data_cache_writeback_sync; }\n@@ -406,1 +377,0 @@\n-  static address unsafe_arraycopy()     { return _unsafe_arraycopy; }\n@@ -411,2 +381,0 @@\n-  static address unsafe_setmemory()     { return _unsafe_setmemory; }\n-\n@@ -416,74 +384,0 @@\n-  static address generic_arraycopy()   { return _generic_arraycopy; }\n-  static address select_arraysort_function() { return _array_sort; }\n-  static address select_array_partition_function() { return _array_partition; }\n-\n-  static address jbyte_fill()          { return _jbyte_fill; }\n-  static address jshort_fill()         { return _jshort_fill; }\n-  static address jint_fill()           { return _jint_fill; }\n-  static address arrayof_jbyte_fill()  { return _arrayof_jbyte_fill; }\n-  static address arrayof_jshort_fill() { return _arrayof_jshort_fill; }\n-  static address arrayof_jint_fill()   { return _arrayof_jint_fill; }\n-\n-  static address aescrypt_encryptBlock()                { return _aescrypt_encryptBlock; }\n-  static address aescrypt_decryptBlock()                { return _aescrypt_decryptBlock; }\n-  static address cipherBlockChaining_encryptAESCrypt()  { return _cipherBlockChaining_encryptAESCrypt; }\n-  static address cipherBlockChaining_decryptAESCrypt()  { return _cipherBlockChaining_decryptAESCrypt; }\n-  static address electronicCodeBook_encryptAESCrypt()   { return _electronicCodeBook_encryptAESCrypt; }\n-  static address electronicCodeBook_decryptAESCrypt()   { return _electronicCodeBook_decryptAESCrypt; }\n-  static address poly1305_processBlocks()               { return _poly1305_processBlocks; }\n-  static address intpoly_montgomeryMult_P256()          { return _intpoly_montgomeryMult_P256; }\n-  static address intpoly_assign()        { return _intpoly_assign; }\n-  static address counterMode_AESCrypt()  { return _counterMode_AESCrypt; }\n-  static address ghash_processBlocks()   { return _ghash_processBlocks; }\n-  static address chacha20Block()         { return _chacha20Block; }\n-  static address base64_encodeBlock()    { return _base64_encodeBlock; }\n-  static address base64_decodeBlock()    { return _base64_decodeBlock; }\n-  static address md5_implCompress()      { return _md5_implCompress; }\n-  static address md5_implCompressMB()    { return _md5_implCompressMB; }\n-  static address sha1_implCompress()     { return _sha1_implCompress; }\n-  static address sha1_implCompressMB()   { return _sha1_implCompressMB; }\n-  static address sha256_implCompress()   { return _sha256_implCompress; }\n-  static address sha256_implCompressMB() { return _sha256_implCompressMB; }\n-  static address sha512_implCompress()   { return _sha512_implCompress; }\n-  static address sha512_implCompressMB() { return _sha512_implCompressMB; }\n-  static address sha3_implCompress()     { return _sha3_implCompress; }\n-  static address sha3_implCompressMB()   { return _sha3_implCompressMB; }\n-\n-  static address updateBytesCRC32()    { return _updateBytesCRC32; }\n-  static address crc_table_addr()      { return _crc_table_adr; }\n-\n-  static address crc32c_table_addr()   { return _crc32c_table_addr; }\n-  static address updateBytesCRC32C()   { return _updateBytesCRC32C; }\n-  static address updateBytesAdler32()  { return _updateBytesAdler32; }\n-\n-  static address multiplyToLen()       { return _multiplyToLen; }\n-  static address squareToLen()         { return _squareToLen; }\n-  static address mulAdd()              { return _mulAdd; }\n-  static address montgomeryMultiply()  { return _montgomeryMultiply; }\n-  static address montgomerySquare()    { return _montgomerySquare; }\n-  static address bigIntegerRightShift() { return _bigIntegerRightShiftWorker; }\n-  static address bigIntegerLeftShift()  { return _bigIntegerLeftShiftWorker; }\n-  static address galoisCounterMode_AESCrypt()   { return _galoisCounterMode_AESCrypt; }\n-\n-  static address vectorizedMismatch()  { return _vectorizedMismatch; }\n-\n-  static address dexp()                { return _dexp; }\n-  static address dlog()                { return _dlog; }\n-  static address dlog10()              { return _dlog10; }\n-  static address dpow()                { return _dpow; }\n-  static address fmod()                { return _fmod; }\n-  static address dsin()                { return _dsin; }\n-  static address dcos()                { return _dcos; }\n-  static address dlibm_reduce_pi04l()  { return _dlibm_reduce_pi04l; }\n-  static address dlibm_sin_cos_huge()  { return _dlibm_sin_cos_huge; }\n-  static address dlibm_tan_cot_huge()  { return _dlibm_tan_cot_huge; }\n-  static address dtan()                { return _dtan; }\n-  static address dtanh()               { return _dtanh; }\n-\n-  \/\/ These are versions of the java.lang.Float::floatToFloat16() and float16ToFloat()\n-  \/\/ methods which perform the same operations as the intrinsic version.\n-  \/\/ They are used for constant folding in JIT compiler to ensure equivalence.\n-  \/\/\n-  static address f2hf_adr()            { return _f2hf; }\n-  static address hf2f_adr()            { return _hf2f; }\n-\n@@ -503,28 +397,0 @@\n-  static address method_entry_barrier() { return _method_entry_barrier; }\n-\n-  static address cont_thaw()           { return _cont_thaw; }\n-  static address cont_returnBarrier()  { return _cont_returnBarrier; }\n-  static address cont_returnBarrierExc(){return _cont_returnBarrierExc; }\n-  static address cont_preempt_stub()   { return _cont_preempt_stub; }\n-\n-  static address upcall_stub_exception_handler() {\n-    assert(_upcall_stub_exception_handler != nullptr, \"not implemented\");\n-    return _upcall_stub_exception_handler;\n-  }\n-\n-  static address upcall_stub_load_target() {\n-    assert(_upcall_stub_load_target != nullptr, \"not implemented\");\n-    return _upcall_stub_load_target;\n-  }\n-\n-  static address lookup_secondary_supers_table_stub(u1 slot) {\n-    assert(slot < Klass::SECONDARY_SUPERS_TABLE_SIZE, \"out of bounds\");\n-    assert(_lookup_secondary_supers_table_stubs[slot] != nullptr, \"not implemented\");\n-    return _lookup_secondary_supers_table_stubs[slot];\n-  }\n-\n-  static address lookup_secondary_supers_table_slow_path_stub() {\n-    assert(_lookup_secondary_supers_table_slow_path_stub != nullptr, \"not implemented\");\n-    return _lookup_secondary_supers_table_slow_path_stub;\n-  }\n-\n@@ -533,3 +399,2 @@\n-  \/\/\n-  \/\/ Default versions of the above arraycopy functions for platforms which do\n-  \/\/ not have specialized versions\n+  \/\/ Default versions of some of the arraycopy functions for platforms\n+  \/\/ which do not have specialized versions\n@@ -553,0 +418,1 @@\n+\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.hpp","additions":168,"deletions":302,"binary":false,"changes":470,"status":"modified"},{"patch":"@@ -65,0 +65,1 @@\n+#include \"utilities\/globalCounter.inline.hpp\"\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -74,25 +74,0 @@\n-    \/** Represents a context to track nmethod dependencies on CallSite instance target. *\/\n-    static class CallSiteContext implements Runnable {\n-        \/\/@Injected JVM_nmethodBucket* vmdependencies;\n-        \/\/@Injected jlong last_cleanup;\n-\n-        static CallSiteContext make(CallSite cs) {\n-            final CallSiteContext newContext = new CallSiteContext();\n-            \/\/ CallSite instance is tracked by a Cleanable which clears native\n-            \/\/ structures allocated for CallSite context. Though the CallSite can\n-            \/\/ become unreachable, its Context is retained by the Cleanable instance\n-            \/\/ (which is referenced from Cleaner instance which is referenced from\n-            \/\/ CleanerFactory class) until cleanup is performed.\n-            CleanerFactory.cleaner().register(cs, newContext);\n-            return newContext;\n-        }\n-\n-        @Override\n-        public void run() {\n-            MethodHandleNatives.clearCallSiteContext(this);\n-        }\n-    }\n-\n-    \/** Invalidate all recorded nmethods. *\/\n-    private static native void clearCallSiteContext(CallSiteContext context);\n-\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/MethodHandleNatives.java","additions":0,"deletions":25,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -214,1 +214,1 @@\n-        int aoffset = UNSAFE.arrayBaseOffset(arrayClass);\n+        int aoffset = (int) UNSAFE.arrayBaseOffset(arrayClass);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/VarHandles.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1366,1 +1366,1 @@\n-            int aoffset = UNSAFE.arrayBaseOffset(arrayClass);\n+            int aoffset = (int) UNSAFE.arrayBaseOffset(arrayClass);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/X-VarHandle.java.template","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1247,0 +1247,3 @@\n+     * <p>\n+     * The static type is @code long} to emphasize that long arithmetic should\n+     * always be used for offset calculations to avoid overflows.\n@@ -1248,1 +1251,1 @@\n-    public static final int INVALID_FIELD_OFFSET = -1;\n+    public static final long INVALID_FIELD_OFFSET = -1;\n@@ -1376,0 +1379,4 @@\n+     * <p>\n+     * The return value is in the range of a {@code int}.  The return type is\n+     * {@code long} to emphasize that long arithmetic should always be used\n+     * for offset calculations to avoid overflows.\n@@ -1380,1 +1387,1 @@\n-    public int arrayBaseOffset(Class<?> arrayClass) {\n+    public long arrayBaseOffset(Class<?> arrayClass) {\n@@ -1390,1 +1397,1 @@\n-    public static final int ARRAY_BOOLEAN_BASE_OFFSET\n+    public static final long ARRAY_BOOLEAN_BASE_OFFSET\n@@ -1394,1 +1401,1 @@\n-    public static final int ARRAY_BYTE_BASE_OFFSET\n+    public static final long ARRAY_BYTE_BASE_OFFSET\n@@ -1398,1 +1405,1 @@\n-    public static final int ARRAY_SHORT_BASE_OFFSET\n+    public static final long ARRAY_SHORT_BASE_OFFSET\n@@ -1402,1 +1409,1 @@\n-    public static final int ARRAY_CHAR_BASE_OFFSET\n+    public static final long ARRAY_CHAR_BASE_OFFSET\n@@ -1406,1 +1413,1 @@\n-    public static final int ARRAY_INT_BASE_OFFSET\n+    public static final long ARRAY_INT_BASE_OFFSET\n@@ -1410,1 +1417,1 @@\n-    public static final int ARRAY_LONG_BASE_OFFSET\n+    public static final long ARRAY_LONG_BASE_OFFSET\n@@ -1414,1 +1421,1 @@\n-    public static final int ARRAY_FLOAT_BASE_OFFSET\n+    public static final long ARRAY_FLOAT_BASE_OFFSET\n@@ -1418,1 +1425,1 @@\n-    public static final int ARRAY_DOUBLE_BASE_OFFSET\n+    public static final long ARRAY_DOUBLE_BASE_OFFSET\n@@ -1422,1 +1429,1 @@\n-    public static final int ARRAY_OBJECT_BASE_OFFSET\n+    public static final long ARRAY_OBJECT_BASE_OFFSET\n@@ -1431,0 +1438,3 @@\n+     * <p>\n+     * The computation of the actual memory offset should always use {@code\n+     * long} arithmetic to avoid overflows.\n@@ -4301,1 +4311,1 @@\n-    private native int arrayBaseOffset0(Class<?> arrayClass);\n+    private native int arrayBaseOffset0(Class<?> arrayClass); \/\/ public version returns long to promote correct arithmetic\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/misc\/Unsafe.java","additions":22,"deletions":12,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -112,0 +112,1 @@\n+    private final Log log;\n@@ -128,0 +129,1 @@\n+        log = Log.instance(context);\n@@ -135,0 +137,1 @@\n+        this.log = other.log;\n@@ -442,1 +445,0 @@\n-     * @param log warning destination\n@@ -445,2 +447,2 @@\n-    public void logIfEnabled(Log log, LintWarning warning) {\n-        logIfEnabled(log, null, warning);\n+    public void logIfEnabled(LintWarning warning) {\n+        logIfEnabled(null, warning);\n@@ -452,1 +454,0 @@\n-     * @param log warning destination\n@@ -456,1 +457,1 @@\n-    public void logIfEnabled(Log log, DiagnosticPosition pos, LintWarning warning) {\n+    public void logIfEnabled(DiagnosticPosition pos, LintWarning warning) {\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Lint.java","additions":6,"deletions":5,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -1979,1 +1979,1 @@\n-            env.info.lint.logIfEnabled(log, tree.pos(), LintWarnings.AttemptToSynchronizeOnInstanceOfValueBasedClass);\n+            env.info.lint.logIfEnabled(tree.pos(), LintWarnings.AttemptToSynchronizeOnInstanceOfValueBasedClass);\n@@ -2085,1 +2085,1 @@\n-                env.info.lint.logIfEnabled(log, pos, LintWarnings.TryResourceThrowsInterruptedExc(resource));\n+                env.info.lint.logIfEnabled(pos, LintWarnings.TryResourceThrowsInterruptedExc(resource));\n@@ -4486,1 +4486,1 @@\n-            env.info.lint.logIfEnabled(log, tree, LintWarnings.TryExplicitCloseCall);\n+            env.info.lint.logIfEnabled(tree, LintWarnings.TryExplicitCloseCall);\n@@ -4513,1 +4513,1 @@\n-                chk.lint.logIfEnabled(log, tree, LintWarnings.StaticNotQualifiedByType(sym.kind.kindName(), sym.owner));\n+                chk.lint.logIfEnabled(tree, LintWarnings.StaticNotQualifiedByType(sym.kind.kindName(), sym.owner));\n@@ -4515,1 +4515,1 @@\n-                chk.lint.logIfEnabled(log, tree, LintWarnings.StaticNotQualifiedByType2(sym.kind.kindName()));\n+                chk.lint.logIfEnabled(tree, LintWarnings.StaticNotQualifiedByType2(sym.kind.kindName()));\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Attr.java","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -294,1 +294,1 @@\n-        lint.logIfEnabled(log, pos, LintWarnings.RestrictedMethod(sym.enclClass(), sym));\n+        lint.logIfEnabled(pos, LintWarnings.RestrictedMethod(sym.enclClass(), sym));\n@@ -658,1 +658,1 @@\n-                lint.logIfEnabled(log, tree.pos(), LintWarnings.RedundantCast(tree.clazz.type));\n+                lint.logIfEnabled(tree.pos(), LintWarnings.RedundantCast(tree.clazz.type));\n@@ -1014,1 +1014,1 @@\n-            lint.logIfEnabled(log, tree, LintWarnings.VarargsRedundantTrustmeAnno(\n+            lint.logIfEnabled(tree, LintWarnings.VarargsRedundantTrustmeAnno(\n@@ -1410,1 +1410,1 @@\n-            deferredLintHandler.report(_ -> lint.logIfEnabled(log, pos, LintWarnings.Strictfp));\n+            deferredLintHandler.report(_ -> lint.logIfEnabled(pos, LintWarnings.Strictfp));\n@@ -1629,1 +1629,1 @@\n-            lint.logIfEnabled(log, tree.pos(), LintWarnings.RawClassUse(tree.type, tree.type.tsym.type));\n+            lint.logIfEnabled(tree.pos(), LintWarnings.RawClassUse(tree.type, tree.type.tsym.type));\n@@ -1953,1 +1953,1 @@\n-            lint.logIfEnabled(log, TreeInfo.diagnosticPositionFor(m, tree),\n+            lint.logIfEnabled(TreeInfo.diagnosticPositionFor(m, tree),\n@@ -4225,1 +4225,1 @@\n-                deferredLintHandler.report(_ -> lint.logIfEnabled(log, pos, LintWarnings.DivZero));\n+                deferredLintHandler.report(_ -> lint.logIfEnabled(pos, LintWarnings.DivZero));\n@@ -4239,1 +4239,1 @@\n-                lint.logIfEnabled(log, pos, LintWarnings.PossibleLossOfPrecision(found, req)));\n+                lint.logIfEnabled(pos, LintWarnings.PossibleLossOfPrecision(found, req)));\n@@ -4248,1 +4248,1 @@\n-            lint.logIfEnabled(log, tree.thenpart.pos(), LintWarnings.EmptyIf);\n+            lint.logIfEnabled(tree.thenpart.pos(), LintWarnings.EmptyIf);\n@@ -4395,1 +4395,1 @@\n-            lint.logIfEnabled(log, pos,\n+            lint.logIfEnabled(pos,\n@@ -4439,1 +4439,1 @@\n-                                lint.logIfEnabled(log, pos, LintWarnings.MissingExplicitCtor(c, pkg, modle)));\n+                                lint.logIfEnabled(pos, LintWarnings.MissingExplicitCtor(c, pkg, modle)));\n@@ -4475,1 +4475,1 @@\n-                        Check.this.lint.logIfEnabled(log, pos(), LintWarnings.VarargsUnsafeUseVarargsParam(method.params.last()));\n+                        Check.this.lint.logIfEnabled(pos(), LintWarnings.VarargsUnsafeUseVarargsParam(method.params.last()));\n@@ -4774,1 +4774,1 @@\n-                lint.logIfEnabled(log, pos, LintWarnings.ModuleNotFound(msym)));\n+                lint.logIfEnabled(pos, LintWarnings.ModuleNotFound(msym)));\n@@ -4782,1 +4782,1 @@\n-                lint.logIfEnabled(log, pos, LintWarnings.PackageEmptyOrNotFound(packge)));\n+                lint.logIfEnabled(pos, LintWarnings.PackageEmptyOrNotFound(packge)));\n@@ -4792,1 +4792,1 @@\n-                    lint.logIfEnabled(log, pos, LintWarnings.RequiresAutomatic);\n+                    lint.logIfEnabled(pos, LintWarnings.RequiresAutomatic);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Check.java","additions":15,"deletions":15,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -747,1 +747,1 @@\n-                    lint.logIfEnabled(log, l.tail.head.pos(),\n+                    lint.logIfEnabled(l.tail.head.pos(),\n@@ -1255,1 +1255,1 @@\n-                    lint.logIfEnabled(log, TreeInfo.diagEndPos(tree.finalizer),\n+                    lint.logIfEnabled(TreeInfo.diagEndPos(tree.finalizer),\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Flow.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -868,1 +868,1 @@\n-                        lint.logIfEnabled(log,\n+                        lint.logIfEnabled(\n@@ -1635,1 +1635,1 @@\n-            lint.logIfEnabled(log, LintWarnings.RuntimeVisibleInvisibleParamAnnotationsMismatch(currentClassFile));\n+            lint.logIfEnabled(LintWarnings.RuntimeVisibleInvisibleParamAnnotationsMismatch(currentClassFile));\n@@ -2101,1 +2101,1 @@\n-                    lint.logIfEnabled(log, LintWarnings.AnnotationMethodNotFound(container, name));\n+                    lint.logIfEnabled(LintWarnings.AnnotationMethodNotFound(container, name));\n@@ -2103,1 +2103,1 @@\n-                    lint.logIfEnabled(log, LintWarnings.AnnotationMethodNotFoundReason(container,\n+                    lint.logIfEnabled(LintWarnings.AnnotationMethodNotFoundReason(container,\n@@ -2981,1 +2981,1 @@\n-        lint.logIfEnabled(log, LintWarnings.RuntimeInvisibleParameterAnnotations(currentClassFile));\n+        lint.logIfEnabled(LintWarnings.RuntimeInvisibleParameterAnnotations(currentClassFile));\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/jvm\/ClassReader.java","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -652,1 +652,1 @@\n-                        lint.logIfEnabled(log, LintWarnings.ProcDuplicateSupportedAnnotation(annotationPattern,\n+                        lint.logIfEnabled(LintWarnings.ProcDuplicateSupportedAnnotation(annotationPattern,\n@@ -665,1 +665,1 @@\n-                    lint.logIfEnabled(log, LintWarnings.ProcRedundantTypesWithWildcard(p.getClass().getName()));\n+                    lint.logIfEnabled(LintWarnings.ProcRedundantTypesWithWildcard(p.getClass().getName()));\n@@ -673,1 +673,1 @@\n-                            lint.logIfEnabled(log, LintWarnings.ProcDuplicateOptionName(optionName,\n+                            lint.logIfEnabled(LintWarnings.ProcDuplicateOptionName(optionName,\n@@ -1690,1 +1690,1 @@\n-        lint.logIfEnabled(log, LintWarnings.ProcMalformedSupportedString(s, p.getClass().getName()));\n+        lint.logIfEnabled(LintWarnings.ProcMalformedSupportedString(s, p.getClass().getName()));\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/processing\/JavacProcessingEnvironment.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -866,1 +866,1 @@\n-    public static final int INVALID_FIELD_OFFSET = jdk.internal.misc.Unsafe.INVALID_FIELD_OFFSET;\n+    public static final int INVALID_FIELD_OFFSET = (int) jdk.internal.misc.Unsafe.INVALID_FIELD_OFFSET;\n@@ -1009,1 +1009,1 @@\n-        return theInternalUnsafe.arrayBaseOffset(arrayClass);\n+        return (int) theInternalUnsafe.arrayBaseOffset(arrayClass);\n@@ -1017,1 +1017,1 @@\n-    public static final int ARRAY_BOOLEAN_BASE_OFFSET = jdk.internal.misc.Unsafe.ARRAY_BOOLEAN_BASE_OFFSET;\n+    public static final int ARRAY_BOOLEAN_BASE_OFFSET = (int) jdk.internal.misc.Unsafe.ARRAY_BOOLEAN_BASE_OFFSET;\n@@ -1024,1 +1024,1 @@\n-    public static final int ARRAY_BYTE_BASE_OFFSET = jdk.internal.misc.Unsafe.ARRAY_BYTE_BASE_OFFSET;\n+    public static final int ARRAY_BYTE_BASE_OFFSET = (int) jdk.internal.misc.Unsafe.ARRAY_BYTE_BASE_OFFSET;\n@@ -1031,1 +1031,1 @@\n-    public static final int ARRAY_SHORT_BASE_OFFSET = jdk.internal.misc.Unsafe.ARRAY_SHORT_BASE_OFFSET;\n+    public static final int ARRAY_SHORT_BASE_OFFSET = (int) jdk.internal.misc.Unsafe.ARRAY_SHORT_BASE_OFFSET;\n@@ -1038,1 +1038,1 @@\n-    public static final int ARRAY_CHAR_BASE_OFFSET = jdk.internal.misc.Unsafe.ARRAY_CHAR_BASE_OFFSET;\n+    public static final int ARRAY_CHAR_BASE_OFFSET = (int) jdk.internal.misc.Unsafe.ARRAY_CHAR_BASE_OFFSET;\n@@ -1045,1 +1045,1 @@\n-    public static final int ARRAY_INT_BASE_OFFSET = jdk.internal.misc.Unsafe.ARRAY_INT_BASE_OFFSET;\n+    public static final int ARRAY_INT_BASE_OFFSET = (int) jdk.internal.misc.Unsafe.ARRAY_INT_BASE_OFFSET;\n@@ -1052,1 +1052,1 @@\n-    public static final int ARRAY_LONG_BASE_OFFSET = jdk.internal.misc.Unsafe.ARRAY_LONG_BASE_OFFSET;\n+    public static final int ARRAY_LONG_BASE_OFFSET = (int) jdk.internal.misc.Unsafe.ARRAY_LONG_BASE_OFFSET;\n@@ -1059,1 +1059,1 @@\n-    public static final int ARRAY_FLOAT_BASE_OFFSET = jdk.internal.misc.Unsafe.ARRAY_FLOAT_BASE_OFFSET;\n+    public static final int ARRAY_FLOAT_BASE_OFFSET = (int) jdk.internal.misc.Unsafe.ARRAY_FLOAT_BASE_OFFSET;\n@@ -1066,1 +1066,1 @@\n-    public static final int ARRAY_DOUBLE_BASE_OFFSET = jdk.internal.misc.Unsafe.ARRAY_DOUBLE_BASE_OFFSET;\n+    public static final int ARRAY_DOUBLE_BASE_OFFSET = (int) jdk.internal.misc.Unsafe.ARRAY_DOUBLE_BASE_OFFSET;\n@@ -1073,1 +1073,1 @@\n-    public static final int ARRAY_OBJECT_BASE_OFFSET = jdk.internal.misc.Unsafe.ARRAY_OBJECT_BASE_OFFSET;\n+    public static final int ARRAY_OBJECT_BASE_OFFSET = (int) jdk.internal.misc.Unsafe.ARRAY_OBJECT_BASE_OFFSET;\n","filename":"src\/jdk.unsupported\/share\/classes\/sun\/misc\/Unsafe.java","additions":12,"deletions":12,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -83,0 +83,2 @@\n+compiler\/arguments\/TestCodeEntryAlignment.java 8349102 generic-all\n+\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2013, 2024, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2013, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -541,0 +541,1 @@\n+ -runtime\/cds\/appcds\/customLoader\/CustomClassListDump.java \\\n@@ -542,0 +543,1 @@\n+ -runtime\/cds\/appcds\/customLoader\/OldClassAndInf.java \\\n@@ -547,0 +549,2 @@\n+ -runtime\/cds\/appcds\/dynamicArchive\/LambdaCustomLoader.java \\\n+ -runtime\/cds\/appcds\/dynamicArchive\/LambdaForOldInfInBaseArchive.java \\\n@@ -549,0 +553,3 @@\n+ -runtime\/cds\/appcds\/dynamicArchive\/OldClassAndInf.java \\\n+ -runtime\/cds\/appcds\/dynamicArchive\/OldClassInBaseArchive.java \\\n+ -runtime\/cds\/appcds\/dynamicArchive\/OldClassVerifierTrouble.java \\\n@@ -568,0 +575,7 @@\n+ -runtime\/cds\/appcds\/NestHostOldInf.java \\\n+ -runtime\/cds\/appcds\/OldClassTest.java \\\n+ -runtime\/cds\/appcds\/OldClassWithjsr.java \\\n+ -runtime\/cds\/appcds\/OldInfExtendsInfDefMeth.java \\\n+ -runtime\/cds\/appcds\/OldSuperClass.java \\\n+ -runtime\/cds\/appcds\/OldSuperInfIndirect.java \\\n+ -runtime\/cds\/appcds\/OldSuperInf.java \\\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -640,1 +640,1 @@\n-    private static final int TEST33_BASE_OFFSET;\n+    private static final long TEST33_BASE_OFFSET;\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestIntrinsics.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -465,0 +465,1 @@\n+java\/awt\/Headless\/HeadlessMalfunctionTest.java 8349099 generic-all\n@@ -471,1 +472,0 @@\n-java\/awt\/Robot\/ScreenCaptureRobotTest.java 8344581 macosx-all\n","filename":"test\/jdk\/ProblemList.txt","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2016, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -456,1 +456,3 @@\n-     * @return true if this VM can write Java heap objects into the CDS archive\n+     * @return true if it's possible for \"java -Xshare:dump\" to write Java heap objects\n+     *         with the current set of jtreg VM options. For example, false will be returned\n+     *         if -XX:-UseCompressedClassPointers is specified,\n","filename":"test\/jtreg-ext\/requires\/VMProps.java","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"}]}