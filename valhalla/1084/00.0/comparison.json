{"files":[{"patch":"@@ -747,0 +747,1 @@\n+    TARGET := build-test-lib, \\\n@@ -750,0 +751,6 @@\n+$(eval $(call SetupTarget, test-image-lib, \\\n+    MAKEFILE := test\/BuildTestLib, \\\n+    TARGET := test-image-lib, \\\n+    DEPS := build-test-lib, \\\n+))\n+\n@@ -784,1 +791,1 @@\n-    DEPS := interim-langtools exploded-image, \\\n+    DEPS := interim-langtools exploded-image build-test-lib, \\\n@@ -1267,1 +1274,1 @@\n-    test-image-lib-native\n+    test-image-lib test-image-lib-native\n","filename":"make\/Main.gmk","additions":9,"deletions":2,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -1209,1 +1209,1 @@\n-            revision: \"3.0-15-jdk-asm+1.0\",\n+            revision: \"3.0-16-jdk-asm+1.0\",\n","filename":"make\/conf\/jib-profiles.js","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -231,0 +231,1 @@\n+JVM_VirtualThreadDisableSuspend\n","filename":"make\/data\/hotspot-symbols\/symbols-unix","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -56,1 +56,2 @@\n-JMH_COMPILE_JARS := $(JMH_CORE_JAR) $(JMH_GENERATOR_JAR)\n+WHITEBOX_JAR := $(SUPPORT_OUTPUTDIR)\/test\/lib\/wb.jar\n+JMH_COMPILE_JARS := $(JMH_CORE_JAR) $(JMH_GENERATOR_JAR) $(WHITEBOX_JAR)\n@@ -59,2 +60,0 @@\n-MICROBENCHMARK_CLASSPATH := $(call PathList, $(JMH_COMPILE_JARS))\n-\n@@ -95,2 +94,3 @@\n-    CLASSPATH := $(MICROBENCHMARK_CLASSPATH), \\\n-    DISABLED_WARNINGS := restricted this-escape processing rawtypes unchecked cast serial preview deprecation, \\\n+    CLASSPATH := $(JMH_COMPILE_JARS), \\\n+    DISABLED_WARNINGS := restricted this-escape processing rawtypes cast \\\n+        serial preview unchecked deprecation, \\\n@@ -99,2 +99,1 @@\n-    JAVAC_FLAGS := --add-exports java.base\/sun.security.util=ALL-UNNAMED \\\n-        --add-exports java.base\/sun.invoke.util=ALL-UNNAMED \\\n+    JAVAC_FLAGS := \\\n@@ -102,0 +101,2 @@\n+        --add-exports java.base\/jdk.internal.event=ALL-UNNAMED \\\n+        --add-exports java.base\/jdk.internal.foreign=ALL-UNNAMED \\\n@@ -103,1 +104,1 @@\n-        --add-exports java.base\/jdk.internal.org.objectweb.asm=ALL-UNNAMED \\\n+        --add-exports java.base\/jdk.internal.org.objectweb.asm=ALL-UNNAMED \\\n@@ -106,3 +107,2 @@\n-        --add-exports java.base\/jdk.internal.misc=ALL-UNNAMED \\\n-        --add-exports java.base\/jdk.internal.event=ALL-UNNAMED \\\n-        --add-exports java.base\/jdk.internal.foreign=ALL-UNNAMED \\\n+        --add-exports java.base\/sun.invoke.util=ALL-UNNAMED \\\n+        --add-exports java.base\/sun.security.util=ALL-UNNAMED \\\n@@ -111,1 +111,1 @@\n-    JAVA_FLAGS := --add-modules jdk.unsupported --limit-modules java.management \\\n+    JAVA_FLAGS := \\\n@@ -113,1 +113,3 @@\n-        --enable-preview, \\\n+        --add-modules jdk.unsupported \\\n+        --enable-preview \\\n+        --limit-modules java.management, \\\n","filename":"make\/test\/BuildMicrobenchmark.gmk","additions":15,"deletions":13,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -26,0 +26,6 @@\n+################################################################################\n+# This file builds the Java components of testlib.\n+# It also covers the test-image part, where the built files are copied to the\n+# test image.\n+################################################################################\n+\n@@ -32,0 +38,4 @@\n+################################################################################\n+# Targets for building the test lib jars\n+################################################################################\n+\n@@ -51,1 +61,1 @@\n-    EXCLUDES := jdk\/test\/lib\/containers jdk\/test\/lib\/security, \\\n+    EXCLUDES := jdk\/test\/lib\/containers jdk\/test\/lib\/security org, \\\n@@ -55,1 +65,1 @@\n-    DISABLED_WARNINGS := try deprecation rawtypes unchecked serial cast removal preview, \\\n+    DISABLED_WARNINGS := try deprecation rawtypes unchecked serial cast removal preview varargs, \\\n@@ -61,0 +71,6 @@\n+        --add-exports jdk.compiler\/com.sun.tools.javac.api=ALL-UNNAMED \\\n+        --add-exports jdk.compiler\/com.sun.tools.javac.code=ALL-UNNAMED \\\n+        --add-exports jdk.compiler\/com.sun.tools.javac.comp=ALL-UNNAMED \\\n+        --add-exports jdk.compiler\/com.sun.tools.javac.main=ALL-UNNAMED \\\n+        --add-exports jdk.compiler\/com.sun.tools.javac.tree=ALL-UNNAMED \\\n+        --add-exports jdk.compiler\/com.sun.tools.javac.util=ALL-UNNAMED \\\n@@ -66,1 +82,14 @@\n-##########################################################################################\n+build-test-lib: $(TARGETS)\n+\n+################################################################################\n+# Targets for building test-image.\n+################################################################################\n+\n+# Copy the jars to the test image.\n+$(eval $(call SetupCopyFiles, COPY_LIBTEST_JARS, \\\n+    DEST := $(TEST_IMAGE_DIR)\/lib-test, \\\n+    FILES := $(BUILD_WB_JAR_JAR) $(BUILD_TEST_LIB_JAR_JAR), \\\n+))\n+#\n+\n+test-image-lib: $(COPY_LIBTEST_JARS)\n@@ -68,1 +97,1 @@\n-all: $(TARGETS)\n+all: build-test-lib\n@@ -70,1 +99,1 @@\n-.PHONY: default all\n+.PHONY: default all build-test-lib test-image-lib\n","filename":"make\/test\/BuildTestLib.gmk","additions":34,"deletions":5,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2015, 2023, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2015, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -861,0 +861,5 @@\n+ifeq ($(call And, $(call isTargetOs, linux) $(call isTargetCpu, aarch64)), false)\n+  BUILD_HOTSPOT_JTREG_EXCLUDE += libTestSVEWithJNI.c\n+endif\n+\n+\n","filename":"make\/test\/JtregNativeHotspot.gmk","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -8272,0 +8272,18 @@\n+\/\/ ============================================================================\n+\/\/ VerifyVectorAlignment Instruction\n+\n+instruct verify_vector_alignment(iRegP addr, immL_positive_bitmaskI mask, rFlagsReg cr) %{\n+  match(Set addr (VerifyVectorAlignment addr mask));\n+  effect(KILL cr);\n+  format %{ \"verify_vector_alignment $addr $mask \\t! verify alignment\" %}\n+  ins_encode %{\n+    Label Lskip;\n+    \/\/ check if masked bits of addr are zero\n+    __ tst($addr$$Register, $mask$$constant);\n+    __ br(Assembler::EQ, Lskip);\n+    __ stop(\"verify_vector_alignment found a misaligned vector memory access\");\n+    __ bind(Lskip);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":19,"deletions":1,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -287,1 +287,2 @@\n-      __ ldp(r19, r20, Address(OSR_buf, slot_offset));\n+      __ ldr(r19, Address(OSR_buf, slot_offset));\n+      __ ldr(r20, Address(OSR_buf, slot_offset + BytesPerWord));\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -162,2 +162,0 @@\n-  const ImmutableOopMap* get_oop_map() const;\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/frame_aarch64.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -201,1 +201,1 @@\n-  assert(!ret || ret && cb() == other.cb() && _deopt_state == other._deopt_state, \"inconsistent construction\");\n+  assert(!ret || (cb() == other.cb() && _deopt_state == other._deopt_state), \"inconsistent construction\");\n@@ -365,14 +365,0 @@\n-inline const ImmutableOopMap* frame::get_oop_map() const {\n-  if (_cb == nullptr) return nullptr;\n-  if (_cb->oop_maps() != nullptr) {\n-    NativePostCallNop* nop = nativePostCallNop_at(_pc);\n-    if (nop != nullptr && nop->displacement() != 0) {\n-      int slot = ((nop->displacement() >> 24) & 0xff);\n-      return _cb->oop_map_for_slot(slot, _pc);\n-    }\n-    const ImmutableOopMap* oop_map = OopMapSet::find_map(this);\n-    return oop_map;\n-  }\n-  return nullptr;\n-}\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/frame_aarch64.inline.hpp","additions":2,"deletions":16,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -314,1 +314,1 @@\n-  uint stk_args = 0; \/\/ inc by 2 each time\n+  uint stk_args = 0;\n@@ -326,0 +326,1 @@\n+        stk_args = align_up(stk_args, 2);\n@@ -327,1 +328,1 @@\n-        stk_args += 2;\n+        stk_args += 1;\n@@ -344,0 +345,1 @@\n+        stk_args = align_up(stk_args, 2);\n@@ -352,0 +354,1 @@\n+        stk_args = align_up(stk_args, 2);\n@@ -353,1 +356,1 @@\n-        stk_args += 2;\n+        stk_args += 1;\n@@ -361,0 +364,1 @@\n+        stk_args = align_up(stk_args, 2);\n@@ -371,1 +375,1 @@\n-  return align_up(stk_args, 2);\n+  return stk_args;\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":8,"deletions":4,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -3893,5 +3893,3 @@\n-  \/\/ make sure klass is initialized & doesn't have finalizer\n-  \/\/ make sure klass is fully initialized\n-  __ ldrb(rscratch1, Address(r4, InstanceKlass::init_state_offset()));\n-  __ cmp(rscratch1, (u1)InstanceKlass::fully_initialized);\n-  __ br(Assembler::NE, slow_case);\n+  \/\/ make sure klass is initialized\n+  assert(VM_Version::supports_fast_class_init_checks(), \"Optimization requires support for fast class initialization checks\");\n+  __ clinit_barrier(r4, rscratch1, nullptr \/*L_fast_path*\/, &slow_case);\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":3,"deletions":5,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2008, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2008, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -2647,2 +2647,2 @@\n-  assert(src->is_double_cpu() && dest->is_address() ||\n-         src->is_address() && dest->is_double_cpu(),\n+  assert((src->is_double_cpu() && dest->is_address()) ||\n+         (src->is_address() && dest->is_double_cpu()),\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRAssembler_arm.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1527,0 +1527,2 @@\n+  void kxnorwl(KRegister dst, KRegister src1, KRegister src2);\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -5255,2 +5255,2 @@\n-  assert(vec_enc == AVX_128bit && VM_Version::supports_avx() ||\n-         vec_enc == AVX_256bit && (VM_Version::supports_avx2() || type2aelembytes(bt) >= 4), \"\");\n+  assert((vec_enc == AVX_128bit && VM_Version::supports_avx()) ||\n+         (vec_enc == AVX_256bit && (VM_Version::supports_avx2() || type2aelembytes(bt) >= 4)), \"\");\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -155,2 +155,0 @@\n-  const ImmutableOopMap* get_oop_map() const;\n-\n","filename":"src\/hotspot\/cpu\/x86\/frame_x86.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -187,1 +187,1 @@\n-  assert(!ret || ret && cb() == other.cb() && _deopt_state == other._deopt_state, \"inconsistent construction\");\n+  assert(!ret || (ret && cb() == other.cb() && _deopt_state == other._deopt_state), \"inconsistent construction\");\n@@ -349,14 +349,0 @@\n-inline const ImmutableOopMap* frame::get_oop_map() const {\n-  if (_cb == nullptr) return nullptr;\n-  if (_cb->oop_maps() != nullptr) {\n-    NativePostCallNop* nop = nativePostCallNop_at(_pc);\n-    if (nop != nullptr && nop->displacement() != 0) {\n-      int slot = ((nop->displacement() >> 24) & 0xff);\n-      return _cb->oop_map_for_slot(slot, _pc);\n-    }\n-    const ImmutableOopMap* oop_map = OopMapSet::find_map(this);\n-    return oop_map;\n-  }\n-  return nullptr;\n-}\n-\n","filename":"src\/hotspot\/cpu\/x86\/frame_x86.inline.hpp","additions":2,"deletions":16,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -1885,86 +1885,0 @@\n-void MacroAssembler::cvtss2sd(XMMRegister dst, XMMRegister src) {\n-  if ((UseAVX > 0) && (dst != src)) {\n-    xorpd(dst, dst);\n-  }\n-  Assembler::cvtss2sd(dst, src);\n-}\n-\n-void MacroAssembler::cvtss2sd(XMMRegister dst, Address src) {\n-  if (UseAVX > 0) {\n-    xorpd(dst, dst);\n-  }\n-  Assembler::cvtss2sd(dst, src);\n-}\n-\n-void MacroAssembler::cvtsd2ss(XMMRegister dst, XMMRegister src) {\n-  if ((UseAVX > 0) && (dst != src)) {\n-    xorps(dst, dst);\n-  }\n-  Assembler::cvtsd2ss(dst, src);\n-}\n-\n-void MacroAssembler::cvtsd2ss(XMMRegister dst, Address src) {\n-  if (UseAVX > 0) {\n-    xorps(dst, dst);\n-  }\n-  Assembler::cvtsd2ss(dst, src);\n-}\n-\n-void MacroAssembler::cvtsi2sdl(XMMRegister dst, Register src) {\n-  if (UseAVX > 0) {\n-    xorpd(dst, dst);\n-  }\n-  Assembler::cvtsi2sdl(dst, src);\n-}\n-\n-void MacroAssembler::cvtsi2sdl(XMMRegister dst, Address src) {\n-  if (UseAVX > 0) {\n-    xorpd(dst, dst);\n-  }\n-  Assembler::cvtsi2sdl(dst, src);\n-}\n-\n-void MacroAssembler::cvtsi2ssl(XMMRegister dst, Register src) {\n-  if (UseAVX > 0) {\n-    xorps(dst, dst);\n-  }\n-  Assembler::cvtsi2ssl(dst, src);\n-}\n-\n-void MacroAssembler::cvtsi2ssl(XMMRegister dst, Address src) {\n-  if (UseAVX > 0) {\n-    xorps(dst, dst);\n-  }\n-  Assembler::cvtsi2ssl(dst, src);\n-}\n-\n-#ifdef _LP64\n-void MacroAssembler::cvtsi2sdq(XMMRegister dst, Register src) {\n-  if (UseAVX > 0) {\n-    xorpd(dst, dst);\n-  }\n-  Assembler::cvtsi2sdq(dst, src);\n-}\n-\n-void MacroAssembler::cvtsi2sdq(XMMRegister dst, Address src) {\n-  if (UseAVX > 0) {\n-    xorpd(dst, dst);\n-  }\n-  Assembler::cvtsi2sdq(dst, src);\n-}\n-\n-void MacroAssembler::cvtsi2ssq(XMMRegister dst, Register src) {\n-  if (UseAVX > 0) {\n-    xorps(dst, dst);\n-  }\n-  Assembler::cvtsi2ssq(dst, src);\n-}\n-\n-void MacroAssembler::cvtsi2ssq(XMMRegister dst, Address src) {\n-  if (UseAVX > 0) {\n-    xorps(dst, dst);\n-  }\n-  Assembler::cvtsi2ssq(dst, src);\n-}\n-#endif  \/\/ _LP64\n-\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":0,"deletions":86,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -148,2 +148,2 @@\n-        op == 0x0F && (branch[1] & 0xF0) == 0x80 \/* jcc *\/ ||\n-        op == 0xC7 && branch[1] == 0xF8 \/* xbegin *\/,\n+        (op == 0x0F && (branch[1] & 0xF0) == 0x80) \/* jcc *\/ ||\n+        (op == 0xC7 && branch[1] == 0xF8) \/* xbegin *\/,\n@@ -863,17 +863,0 @@\n-\n-  \/\/ cvt instructions\n-  void cvtss2sd(XMMRegister dst, XMMRegister src);\n-  void cvtss2sd(XMMRegister dst, Address src);\n-  void cvtsd2ss(XMMRegister dst, XMMRegister src);\n-  void cvtsd2ss(XMMRegister dst, Address src);\n-  void cvtsi2sdl(XMMRegister dst, Register src);\n-  void cvtsi2sdl(XMMRegister dst, Address src);\n-  void cvtsi2ssl(XMMRegister dst, Register src);\n-  void cvtsi2ssl(XMMRegister dst, Address src);\n-#ifdef _LP64\n-  void cvtsi2sdq(XMMRegister dst, Register src);\n-  void cvtsi2sdq(XMMRegister dst, Address src);\n-  void cvtsi2ssq(XMMRegister dst, Register src);\n-  void cvtsi2ssq(XMMRegister dst, Address src);\n-#endif\n-\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":2,"deletions":19,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -531,2 +531,1 @@\n-  \/\/ return value can be odd number of VMRegImpl stack slots make multiple of 2\n-  return align_up(stack, 2);\n+  return stack;\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -502,1 +502,1 @@\n-  uint stk_args = 0; \/\/ inc by 2 each time\n+  uint stk_args = 0;\n@@ -514,0 +514,1 @@\n+        stk_args = align_up(stk_args, 2);\n@@ -515,1 +516,1 @@\n-        stk_args += 2;\n+        stk_args += 1;\n@@ -532,0 +533,1 @@\n+        stk_args = align_up(stk_args, 2);\n@@ -540,0 +542,1 @@\n+        stk_args = align_up(stk_args, 2);\n@@ -541,1 +544,1 @@\n-        stk_args += 2;\n+        stk_args += 1;\n@@ -549,0 +552,1 @@\n+        stk_args = align_up(stk_args, 2);\n@@ -559,1 +563,1 @@\n-  return align_up(stk_args, 2);\n+  return stk_args;\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":8,"deletions":4,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -2337,1 +2337,1 @@\n-  const Address  dp_mem(rbp, 6 * wordSize);  \/\/ length is on stack on Win64\n+  const Address dp_mem(rbp, 6 * wordSize);  \/\/ length is on stack on Win64\n@@ -2559,0 +2559,1 @@\n+    __ addq(length, start_offset);\n@@ -2563,0 +2564,1 @@\n+    __ subq(length, start_offset);\n@@ -4366,2 +4368,3 @@\n-  \/\/ Load x86_64_sort library on supported hardware to enable avx512 sort and partition intrinsics\n-  if (VM_Version::is_intel() && VM_Version::supports_avx512dq()) {\n+  \/\/ Load x86_64_sort library on supported hardware to enable SIMD sort and partition intrinsics\n+\n+  if (VM_Version::is_intel() && (VM_Version::supports_avx512dq() || VM_Version::supports_avx2())) {\n@@ -4374,1 +4377,1 @@\n-    \/\/ Get addresses for avx512 sort and partition routines\n+    \/\/ Get addresses for SIMD sort and partition routines\n@@ -4378,1 +4381,1 @@\n-      snprintf(ebuf_, sizeof(ebuf_), \"avx512_sort\");\n+      snprintf(ebuf_, sizeof(ebuf_), VM_Version::supports_avx512dq() ? \"avx512_sort\" : \"avx2_sort\");\n@@ -4381,1 +4384,1 @@\n-      snprintf(ebuf_, sizeof(ebuf_), \"avx512_partition\");\n+      snprintf(ebuf_, sizeof(ebuf_), VM_Version::supports_avx512dq() ? \"avx512_partition\" : \"avx2_partition\");\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":10,"deletions":7,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -4341,1 +4341,5 @@\n-  \/\/ make sure klass is initialized & doesn't have finalizer\n+  \/\/ make sure klass is initialized\n+#ifdef _LP64\n+  assert(VM_Version::supports_fast_class_init_checks(), \"must support fast class initialization checks\");\n+  __ clinit_barrier(rcx, r15_thread, nullptr \/*L_fast_path*\/, &slow_case);\n+#else\n@@ -4345,0 +4349,1 @@\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/templateTable_x86.cpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -861,1 +861,1 @@\n-    (_model == 0x97 || _model == 0xAC || _model == 0xAF)) {\n+    (_model == 0x97 || _model == 0xAA || _model == 0xAC || _model == 0xAF)) {\n@@ -1133,0 +1133,1 @@\n+#ifdef _LP64\n@@ -1148,0 +1149,7 @@\n+#else\n+  \/\/ No support currently for ChaCha20 intrinsics on 32-bit platforms\n+  if (UseChaCha20Intrinsics) {\n+      warning(\"ChaCha20 intrinsics are not available on this CPU.\");\n+      FLAG_SET_DEFAULT(UseChaCha20Intrinsics, false);\n+  }\n+#endif \/\/ _LP64\n@@ -1173,1 +1181,1 @@\n-  if (supports_sha() LP64_ONLY(|| supports_avx2() && supports_bmi2())) {\n+  if (supports_sha() LP64_ONLY(|| (supports_avx2() && supports_bmi2()))) {\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":11,"deletions":3,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2011, 2023, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2011, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -2535,2 +2535,2 @@\n-         (src_lo & 1) == 0 && (src_lo + 1) == src_hi &&\n-         (dst_lo & 1) == 0 && (dst_lo + 1) == dst_hi,\n+         ((src_lo & 1) == 0 && (src_lo + 1) == src_hi &&\n+          (dst_lo & 1) == 0 && (dst_lo + 1) == dst_hi),\n@@ -4090,2 +4090,0 @@\n-    assert(UseAVX >= 2, \"sanity\");\n-\n@@ -4094,8 +4092,1 @@\n-\n-    assert(Matcher::vector_length_in_bytes(this) >= 16, \"sanity\");\n-\n-    if (vlen_enc == Assembler::AVX_128bit) {\n-      __ movdqu($mask$$XMMRegister, ExternalAddress(vector_all_bits_set()), noreg);\n-    } else {\n-      __ vmovdqu($mask$$XMMRegister, ExternalAddress(vector_all_bits_set()), noreg);\n-    }\n+    __ vpcmpeqd($mask$$XMMRegister, $mask$$XMMRegister, $mask$$XMMRegister, vlen_enc);\n@@ -4109,0 +4100,1 @@\n+\n@@ -4115,2 +4107,0 @@\n-    assert(UseAVX > 2, \"sanity\");\n-\n@@ -4119,4 +4109,1 @@\n-\n-    assert(!is_subword_type(elem_bt), \"sanity\"); \/\/ T_INT, T_LONG, T_FLOAT, T_DOUBLE\n-\n-    __ kmovwl($ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), noreg);\n+    __ kxnorwl($ktmp$$KRegister, $ktmp$$KRegister, $ktmp$$KRegister);\n@@ -4130,0 +4117,1 @@\n+  predicate(VM_Version::supports_avx512vl() || Matcher::vector_length_in_bytes(n) == 64);\n@@ -9014,0 +9002,15 @@\n+instruct verify_vector_alignment(rRegP addr, immL32 mask, rFlagsReg cr) %{\n+  match(Set addr (VerifyVectorAlignment addr mask));\n+  effect(KILL cr);\n+  format %{ \"verify_vector_alignment $addr $mask \\t! verify alignment\" %}\n+  ins_encode %{\n+    Label Lskip;\n+    \/\/ check if masked bits of addr are zero\n+    __ testq($addr$$Register, $mask$$constant);\n+    __ jccb(Assembler::equal, Lskip);\n+    __ stop(\"verify_vector_alignment found a misaligned vector memory access\");\n+    __ bind(Lskip);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":22,"deletions":19,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -11142,1 +11142,1 @@\n-  predicate( UseSSE==1 || UseSSE>=2 && !UseXmmI2F );\n+  predicate( UseSSE==1 || ( UseSSE>=2 && !UseXmmI2F ));\n@@ -13161,1 +13161,1 @@\n-  predicate( UseSSE<=1 && _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge );\n+  predicate( UseSSE<=1 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n@@ -13171,1 +13171,1 @@\n-  predicate( UseSSE>=2 && _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge );\n+  predicate( UseSSE>=2 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n@@ -13180,1 +13180,1 @@\n-  predicate( UseSSE==0 && _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge );\n+  predicate( UseSSE==0 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n@@ -13189,1 +13189,1 @@\n-  predicate( UseSSE>=1 && _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge );\n+  predicate( UseSSE>=1 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n@@ -13352,1 +13352,1 @@\n-  predicate( UseSSE<=1 && _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne );\n+  predicate( UseSSE<=1 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n@@ -13362,1 +13362,1 @@\n-  predicate( UseSSE>=2 && _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne );\n+  predicate( UseSSE>=2 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n@@ -13371,1 +13371,1 @@\n-  predicate( UseSSE==0 && _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne );\n+  predicate( UseSSE==0 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n@@ -13380,1 +13380,1 @@\n-  predicate( UseSSE>=1 && _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne );\n+  predicate( UseSSE>=1 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n@@ -13571,1 +13571,1 @@\n-  predicate( UseSSE<=1 && _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt );\n+  predicate( UseSSE<=1 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n@@ -13581,1 +13581,1 @@\n-  predicate( UseSSE>=2 && _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt );\n+  predicate( UseSSE>=2 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n@@ -13590,1 +13590,1 @@\n-  predicate( UseSSE==0 && _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt );\n+  predicate( UseSSE==0 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n@@ -13600,1 +13600,1 @@\n-  predicate( UseSSE>=1 && _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt );\n+  predicate( UseSSE>=1 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":14,"deletions":14,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -10142,1 +10142,1 @@\n-  effect(TEMP dst);\n+\n@@ -10164,1 +10164,1 @@\n-  effect(TEMP dst);\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -797,0 +797,1 @@\n+       !strcmp(_matrule->_rChild->_opType,\"VerifyVectorAlignment\")||\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"compiler\/compilationFailureInfo.hpp\"\n@@ -40,0 +41,1 @@\n+#include \"compiler\/compiler_globals.hpp\"\n@@ -79,1 +81,0 @@\n-static uint totalInstructionNodes = 0;\n@@ -392,4 +393,0 @@\n-  if (method()->is_synchronized()) {\n-    set_has_monitors(true);\n-  }\n-\n@@ -497,1 +494,0 @@\n-  totalInstructionNodes += Instruction::number_of_instructions();\n@@ -584,1 +580,1 @@\n-, _has_monitors(false)\n+, _has_monitors(method->is_synchronized() || method->has_monitor_bytecodes())\n@@ -587,0 +583,1 @@\n+, _first_failure_details(nullptr)\n@@ -637,1 +634,1 @@\n-\n+  delete _first_failure_details;\n@@ -663,0 +660,3 @@\n+    if (CaptureBailoutInformation) {\n+      _first_failure_details = new CompilationFailureInfo(msg);\n+    }\n","filename":"src\/hotspot\/share\/c1\/c1_Compilation.cpp","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+class CompilationFailureInfo;\n@@ -89,0 +90,1 @@\n+  CompilationFailureInfo* _first_failure_details; \/\/ Details for the first failure happening during compilation\n@@ -217,0 +219,1 @@\n+  const CompilationFailureInfo* first_failure_details() const { return _first_failure_details; }\n","filename":"src\/hotspot\/share\/c1\/c1_Compilation.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -75,1 +75,1 @@\n-  intptr_t out_preserve = SharedRuntime::java_calling_convention(sig_bt, regs, sizeargs);\n+  intptr_t out_preserve = align_up(SharedRuntime::java_calling_convention(sig_bt, regs, sizeargs), 2);\n","filename":"src\/hotspot\/share\/c1\/c1_FrameMap.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -1419,2 +1419,2 @@\n-         (i->as_Goto()->sux_at(0) == tsux  && i->as_Goto()->is_safepoint() == tsux->bci() < stream()->cur_bci()) ||\n-         (i->as_Goto()->sux_at(0) == fsux  && i->as_Goto()->is_safepoint() == fsux->bci() < stream()->cur_bci()),\n+         (i->as_Goto()->sux_at(0) == tsux  && i->as_Goto()->is_safepoint() == (tsux->bci() < stream()->cur_bci())) ||\n+         (i->as_Goto()->sux_at(0) == fsux  && i->as_Goto()->is_safepoint() == (fsux->bci() < stream()->cur_bci())),\n@@ -1555,1 +1555,1 @@\n-          assert(res->as_Goto()->is_safepoint() == sw.dest_offset_at(i) < 0, \"safepoint state of Goto returned by canonicalizer incorrect\");\n+          assert(res->as_Goto()->is_safepoint() == (sw.dest_offset_at(i) < 0), \"safepoint state of Goto returned by canonicalizer incorrect\");\n@@ -1604,1 +1604,1 @@\n-          assert(res->as_Goto()->is_safepoint() == sw.pair_at(i).offset() < 0, \"safepoint state of Goto returned by canonicalizer incorrect\");\n+          assert(res->as_Goto()->is_safepoint() == (sw.pair_at(i).offset() < 0), \"safepoint state of Goto returned by canonicalizer incorrect\");\n@@ -2583,1 +2583,0 @@\n-  compilation()->set_has_monitors(true);\n@@ -3783,0 +3782,9 @@\n+static void set_flags_for_inlined_callee(Compilation* compilation, ciMethod* callee) {\n+  if (callee->has_reserved_stack_access()) {\n+    compilation->set_has_reserved_stack_access(true);\n+  }\n+  if (callee->is_synchronized() || callee->has_monitor_bytecodes()) {\n+    compilation->set_has_monitors(true);\n+  }\n+}\n+\n@@ -3799,3 +3807,1 @@\n-      if (callee->has_reserved_stack_access()) {\n-        compilation()->set_has_reserved_stack_access(true);\n-      }\n+      set_flags_for_inlined_callee(compilation(), callee);\n@@ -3812,3 +3818,1 @@\n-      if (callee->has_reserved_stack_access()) {\n-        compilation()->set_has_reserved_stack_access(true);\n-      }\n+      set_flags_for_inlined_callee(compilation(), callee);\n@@ -3832,3 +3836,1 @@\n-    if (callee->has_reserved_stack_access()) {\n-      compilation()->set_has_reserved_stack_access(true);\n-    }\n+    set_flags_for_inlined_callee(compilation(), callee);\n@@ -4741,1 +4743,3 @@\n-  vmap()->print();\n+  if (UseLocalValueNumbering) {\n+    vmap()->print();\n+  }\n","filename":"src\/hotspot\/share\/c1\/c1_GraphBuilder.cpp","additions":20,"deletions":16,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -4860,2 +4860,2 @@\n-    assert (kind == fixedKind && fixed->from() <= any->from() ||\n-            kind == anyKind   && any->from() <= fixed->from(), \"wrong interval!!!\");\n+    assert((kind == fixedKind && fixed->from() <= any->from()) ||\n+           (kind == anyKind   && any->from() <= fixed->from()), \"wrong interval!!!\");\n","filename":"src\/hotspot\/share\/c1\/c1_LinearScan.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -64,1 +64,1 @@\n-    assert(tag == t->type()->tag() || tag == objectTag && t->type()->tag() == addressTag, \"types must correspond\");\n+    assert(tag == t->type()->tag() || (tag == objectTag && t->type()->tag() == addressTag), \"types must correspond\");\n","filename":"src\/hotspot\/share\/c1\/c1_ValueStack.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -278,0 +278,2 @@\n+  \/* The compiler assumes, in many places, that methods are at most 1MB. *\/ \\\n+  \/* Therefore, we restrict this flag to at most 1MB.                    *\/ \\\n@@ -280,1 +282,1 @@\n-          range(0, max_jint)                                                \\\n+          range(0, 1*M)                                                     \\\n","filename":"src\/hotspot\/share\/c1\/c1_globals.hpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -58,1 +58,1 @@\n-  static bool check_vm_args_consistency(bool mode_flag_cmd_line) NOT_CDS_RETURN_(false);\n+  static bool check_vm_args_consistency(bool mode_flag_cmd_line) NOT_CDS_RETURN_(true);\n","filename":"src\/hotspot\/share\/cds\/cdsConfig.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -647,6 +647,8 @@\n-    assert(ent->in_named_module(), \"must be\");\n-    bool cond = strcmp(file, ent->name()) == 0;\n-    log_debug(class, path)(\"get_module_shared_path_index (%d) %s : %s = %s\", i,\n-                           location->as_C_string(), ent->name(), cond ? \"same\" : \"different\");\n-    if (cond) {\n-      return i;\n+    if (!ent->is_non_existent()) {\n+      assert(ent->in_named_module(), \"must be\");\n+      bool cond = strcmp(file, ent->name()) == 0;\n+      log_debug(class, path)(\"get_module_shared_path_index (%d) %s : %s = %s\", i,\n+                             location->as_C_string(), ent->name(), cond ? \"same\" : \"different\");\n+      if (cond) {\n+        return i;\n+      }\n@@ -1540,1 +1542,1 @@\n-bool FileMapRegion::check_region_crc() const {\n+bool FileMapRegion::check_region_crc(char* base) const {\n@@ -1549,2 +1551,2 @@\n-  assert(mapped_base() != nullptr, \"must be initialized\");\n-  int crc = ClassLoader::crc32(0, mapped_base(), (jint)sz);\n+  assert(base != nullptr, \"must be initialized\");\n+  int crc = ClassLoader::crc32(0, base, (jint)sz);\n@@ -1835,4 +1837,1 @@\n-  r->set_mapped_from_file(false);\n-  r->set_mapped_base(base);\n-\n-  if (VerifySharedSpaces && !r->check_region_crc()) {\n+  if (VerifySharedSpaces && !r->check_region_crc(base)) {\n@@ -1842,0 +1841,3 @@\n+  r->set_mapped_from_file(false);\n+  r->set_mapped_base(base);\n+\n@@ -1878,0 +1880,1 @@\n+      return MAP_ARCHIVE_SUCCESS;\n@@ -1892,0 +1895,5 @@\n+\n+    if (VerifySharedSpaces && !r->check_region_crc(requested_addr)) {\n+      return MAP_ARCHIVE_OTHER_FAILURE;\n+    }\n+\n@@ -1894,3 +1902,1 @@\n-  }\n-  if (VerifySharedSpaces && !r->check_region_crc()) {\n-    return MAP_ARCHIVE_OTHER_FAILURE;\n+    return MAP_ARCHIVE_SUCCESS;\n@@ -1899,2 +1905,0 @@\n-\n-  return MAP_ARCHIVE_SUCCESS;\n@@ -1918,2 +1922,1 @@\n-  r->set_mapped_base(bitmap_base);\n-  if (VerifySharedSpaces && !r->check_region_crc()) {\n+  if (VerifySharedSpaces && !r->check_region_crc(bitmap_base)) {\n@@ -1928,0 +1931,1 @@\n+  r->set_mapped_base(bitmap_base);\n@@ -2203,2 +2207,1 @@\n-  r->set_mapped_base(base);\n-  if (VerifySharedSpaces && !r->check_region_crc()) {\n+  if (VerifySharedSpaces && !r->check_region_crc(base)) {\n@@ -2210,0 +2213,2 @@\n+  r->set_mapped_base(base);\n+\n","filename":"src\/hotspot\/share\/cds\/filemap.cpp","additions":27,"deletions":22,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -93,0 +93,1 @@\n+  bool is_non_existent()  const { return _type == non_existent_entry; }\n@@ -174,1 +175,1 @@\n-  bool check_region_crc() const;\n+  bool check_region_crc(char* base) const;\n","filename":"src\/hotspot\/share\/cds\/filemap.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -369,1 +369,1 @@\n-  CompileTask* task() { return _task; }\n+  CompileTask* task() const { return _task; }\n@@ -451,1 +451,1 @@\n-  void* compiler_data() { return _compiler_data; }\n+  void* compiler_data() const { return _compiler_data; }\n","filename":"src\/hotspot\/share\/ci\/ciEnv.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -1370,1 +1370,1 @@\n-  assert(k == nullptr || k->is_klass() && k->is_array_klass(), \"should be array klass\");\n+  assert(k == nullptr || (k->is_klass() && k->is_array_klass()), \"should be array klass\");\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -603,0 +603,1 @@\n+  do_intrinsic(_notifyJvmtiVThreadDisableSuspend, java_lang_VirtualThread, notifyJvmtiDisableSuspend_name, bool_void_signature, F_RN) \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -427,0 +427,1 @@\n+  template(notifyJvmtiDisableSuspend_name,            \"notifyJvmtiDisableSuspend\")                \\\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -167,1 +167,1 @@\n-  blob->purge();\n+  blob->purge(true \/* free_code_cache_data *\/, true \/* unregister_nmethod *\/);\n@@ -176,1 +176,1 @@\n-void CodeBlob::purge(bool free_code_cache_data) {\n+void CodeBlob::purge(bool free_code_cache_data, bool unregister_nmethod) {\n","filename":"src\/hotspot\/share\/code\/codeBlob.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -146,1 +146,1 @@\n-  virtual void purge(bool free_code_cache_data = true);\n+  virtual void purge(bool free_code_cache_data, bool unregister_nmethod);\n","filename":"src\/hotspot\/share\/code\/codeBlob.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -131,0 +131,1 @@\n+#ifdef ASSERT\n@@ -134,1 +135,2 @@\n-    _call->set_destination_mt_safe(entry_point);\n+#endif\n+  _call->set_destination_mt_safe(entry_point);\n@@ -294,1 +296,1 @@\n-  if (TraceICs) {\n+  {\n@@ -297,1 +299,1 @@\n-    tty->print_cr (\"IC@\" INTPTR_FORMAT \": to megamorphic %s entry: \" INTPTR_FORMAT,\n+    log_trace(inlinecache)(\"IC@\" INTPTR_FORMAT \": to megamorphic %s entry: \" INTPTR_FORMAT,\n@@ -367,1 +369,1 @@\n-  if (TraceInlineCacheClearing || TraceICs) {\n+  if (TraceInlineCacheClearing) {\n@@ -371,0 +373,1 @@\n+  log_trace(inlinecache)(\"IC@\" INTPTR_FORMAT \": set to clean\", p2i(instruction_address()));\n@@ -436,3 +439,3 @@\n-      if (TraceICs) {\n-         ResourceMark rm(thread);\n-         tty->print_cr (\"IC@\" INTPTR_FORMAT \": monomorphic to interpreter: %s\",\n+      {\n+        ResourceMark rm(thread);\n+        log_trace(inlinecache)(\"IC@\" INTPTR_FORMAT \": monomorphic to interpreter: %s\",\n@@ -452,1 +455,1 @@\n-      if (TraceICs) {\n+      {\n@@ -454,1 +457,1 @@\n-         tty->print_cr (\"IC@\" INTPTR_FORMAT \": monomorphic to interpreter via icholder \", p2i(instruction_address()));\n+         log_trace(inlinecache)(\"IC@\" INTPTR_FORMAT \": monomorphic to interpreter via icholder \", p2i(instruction_address()));\n@@ -482,1 +485,1 @@\n-    if (TraceICs) {\n+    {\n@@ -485,1 +488,1 @@\n-      tty->print_cr (\"IC@\" INTPTR_FORMAT \": monomorphic to compiled (rcvr klass = %s) %s\",\n+      log_trace(inlinecache)(\"IC@\" INTPTR_FORMAT \": monomorphic to compiled (rcvr klass = %s) %s\",\n@@ -612,1 +615,1 @@\n-  if (TraceICs) {\n+  {\n@@ -614,1 +617,1 @@\n-    tty->print_cr(\"%s@\" INTPTR_FORMAT \": set_to_compiled \" INTPTR_FORMAT,\n+    log_trace(inlinecache)(\"%s@\" INTPTR_FORMAT \": set_to_compiled \" INTPTR_FORMAT,\n","filename":"src\/hotspot\/share\/code\/compiledIC.cpp","additions":16,"deletions":13,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -177,1 +177,1 @@\n-  virtual void purge(bool free_code_cache_data = true) = 0;\n+  virtual void purge(bool free_code_cache_data, bool unregister_nmethod) = 0;\n","filename":"src\/hotspot\/share\/code\/compiledMethod.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1149,4 +1149,1 @@\n-  } else if (((oopmap_slot & 0xff) == oopmap_slot) && ((offset & 0xffffff) == offset)) {\n-    jint value = (oopmap_slot << 24) | (jint) offset;\n-    nop->patch(value);\n-  } else {\n+  } else if (!nop->patch(oopmap_slot, offset)) {\n@@ -1456,1 +1453,3 @@\n-void nmethod::purge(bool free_code_cache_data) {\n+void nmethod::purge(bool free_code_cache_data, bool unregister_nmethod) {\n+  assert(!free_code_cache_data, \"must only call not freeing code cache data\");\n+\n@@ -1476,1 +1475,4 @@\n-  Universe::heap()->unregister_nmethod(this);\n+  if (unregister_nmethod) {\n+    Universe::heap()->unregister_nmethod(this);\n+  }\n+\n@@ -1479,4 +1481,1 @@\n-  CodeBlob::purge();\n-  if (free_code_cache_data) {\n-    CodeCache::free(this);\n-  }\n+  CodeBlob::purge(free_code_cache_data, unregister_nmethod);\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":9,"deletions":10,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -532,1 +532,1 @@\n-  void purge(bool free_code_cache_data = true);\n+  void purge(bool free_code_cache_data, bool unregister_nmethod);\n","filename":"src\/hotspot\/share\/code\/nmethod.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1791,1 +1791,1 @@\n-    blob->purge();\n+    blob->purge(true \/* free_code_cache_data *\/, true \/* unregister_nmethod *\/);\n","filename":"src\/hotspot\/share\/compiler\/compileBroker.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -98,1 +98,1 @@\n-  const size_t padding_elem_num = (DEFAULT_CACHE_LINE_SIZE \/ sizeof(size_t));\n+  const size_t padding_elem_num = (DEFAULT_PADDING_SIZE \/ sizeof(size_t));\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -419,2 +419,2 @@\n-  _region_start(nullptr),\n-  DEBUG_ONLY(_region_end(nullptr) COMMA)\n+  _heap_start(nullptr),\n+  DEBUG_ONLY(_heap_end(nullptr) COMMA)\n@@ -429,1 +429,1 @@\n-bool ParallelCompactData::initialize(MemRegion covered_region)\n+bool ParallelCompactData::initialize(MemRegion reserved_heap)\n@@ -431,3 +431,3 @@\n-  _region_start = covered_region.start();\n-  const size_t region_size = covered_region.word_size();\n-  DEBUG_ONLY(_region_end = _region_start + region_size;)\n+  _heap_start = reserved_heap.start();\n+  const size_t heap_size = reserved_heap.word_size();\n+  DEBUG_ONLY(_heap_end = _heap_start + heap_size;)\n@@ -435,1 +435,1 @@\n-  assert(region_align_down(_region_start) == _region_start,\n+  assert(region_align_down(_heap_start) == _heap_start,\n@@ -438,1 +438,1 @@\n-  bool result = initialize_region_data(region_size) && initialize_block_data();\n+  bool result = initialize_region_data(heap_size) && initialize_block_data();\n@@ -471,1 +471,1 @@\n-bool ParallelCompactData::initialize_region_data(size_t region_size)\n+bool ParallelCompactData::initialize_region_data(size_t heap_size)\n@@ -473,2 +473,1 @@\n-  assert((region_size & RegionSizeOffsetMask) == 0,\n-         \"region size not a multiple of RegionSize\");\n+  assert(is_aligned(heap_size, RegionSize), \"precondition\");\n@@ -476,1 +475,1 @@\n-  const size_t count = region_size >> Log2RegionSize;\n+  const size_t count = heap_size >> Log2RegionSize;\n@@ -534,1 +533,1 @@\n-  const size_t obj_ofs = pointer_delta(addr, _region_start);\n+  const size_t obj_ofs = pointer_delta(addr, _heap_start);\n@@ -1773,0 +1772,1 @@\n+                              false \/* unregister_nmethods_during_purge *\/,\n@@ -2082,0 +2082,4 @@\n+    {\n+      GCTraceTime(Debug, gc, phases) ur(\"Unregister NMethods\", &_gc_timer);\n+      ParallelScavengeHeap::heap()->prune_unlinked_nmethods();\n+    }\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":17,"deletions":13,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -177,2 +177,0 @@\n-  ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();\n-\n@@ -182,2 +180,0 @@\n-  uint queue_size = claimed_stack_depth()->max_elems();\n-\n@@ -280,3 +276,1 @@\n-    if (PSScavenge::should_scavenge(p)) {\n-      claim_or_forward_depth(p);\n-    }\n+    claim_or_forward_depth(p);\n","filename":"src\/hotspot\/share\/gc\/parallel\/psPromotionManager.cpp","additions":1,"deletions":7,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2158,1 +2158,1 @@\n-              assert(c->is_Loop() && j == LoopNode::LoopBackControl || _phase->C->has_irreducible_loop() || has_never_branch(_phase->C->root()), \"\");\n+              assert((c->is_Loop() && j == LoopNode::LoopBackControl) || _phase->C->has_irreducible_loop() || has_never_branch(_phase->C->root()), \"\");\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/c2\/shenandoahSupport.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -360,1 +360,1 @@\n-        assert(obj != fwd || _heap->cancelled_gc(), \"must be forwarded\");\n+        shenandoah_assert_forwarded_except(elem_ptr, obj, _heap->cancelled_gc());\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahBarrierSet.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -42,0 +42,2 @@\n+  static void clone_obj_array(objArrayOop src, objArrayOop dst, size_t size);\n+\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrierSet.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -428,1 +428,1 @@\n-class ZStoreBarrierOopClosure : public BasicOopIterateClosure {\n+class ZColorStoreGoodOopClosure : public BasicOopIterateClosure {\n@@ -434,2 +434,1 @@\n-    ZBarrier::store_barrier_on_heap_oop_field(p, false \/* heal *\/);\n-    *p = ZAddress::store_good(addr);\n+    Atomic::store(p, ZAddress::store_good(addr));\n@@ -458,0 +457,11 @@\n+  if (dst->is_objArray()) {\n+    \/\/ Cloning an object array is similar to performing array copy.\n+    \/\/ If an array is large enough to have its allocation segmented,\n+    \/\/ this operation might require GC barriers. However, the intrinsics\n+    \/\/ for cloning arrays transform the clone to an optimized allocation\n+    \/\/ and arraycopy sequence, so the performance of this runtime call\n+    \/\/ does not matter for object arrays.\n+    clone_obj_array(objArrayOop(src), objArrayOop(dst), size);\n+    return;\n+  }\n+\n@@ -465,1 +475,1 @@\n-  assert(ZHeap::heap()->is_young(to_zaddress(dst)), \"ZColorStoreGoodOopClosure is only valid for young objects\");\n+  assert(dst->is_typeArray() || ZHeap::heap()->is_young(to_zaddress(dst)), \"ZColorStoreGoodOopClosure is only valid for young objects\");\n@@ -468,1 +478,1 @@\n-  ZStoreBarrierOopClosure cl_sg;\n+  ZColorStoreGoodOopClosure cl_sg;\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrierSet.inline.hpp","additions":15,"deletions":5,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -1172,0 +1172,3 @@\n+JNIEXPORT void JNICALL\n+JVM_VirtualThreadDisableSuspend(JNIEnv* env, jobject vthread, jboolean enter);\n+\n","filename":"src\/hotspot\/share\/include\/jvm.h","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -541,1 +541,1 @@\n-              this_size < has_size && *fp == '\\0', \/\/ last field can be short\n+              (this_size < has_size && *fp == '\\0'), \/\/ last field can be short\n","filename":"src\/hotspot\/share\/interpreter\/bytecodes.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -125,0 +125,2 @@\n+  static_field(CompilerToVM::Data,             _should_notify_object_alloc,            int*)                                         \\\n+                                                                                                                                     \\\n@@ -223,0 +225,1 @@\n+  JVMTI_ONLY(nonstatic_field(JavaThread,       _is_disable_suspend,                           bool))                                 \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -100,0 +100,1 @@\n+  LOG_TAG(inlinecache)\\\n","filename":"src\/hotspot\/share\/logging\/logTag.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -347,1 +347,1 @@\n-      _fillerArrayKlassObj = TypeArrayKlass::create_klass(T_INT, \"Ljdk\/internal\/vm\/FillerArray;\", CHECK);\n+      _fillerArrayKlassObj = TypeArrayKlass::create_klass(T_INT, \"[Ljdk\/internal\/vm\/FillerElement;\", CHECK);\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -56,2 +56,2 @@\n-\/\/ * atomic_xchg: Atomically swap a new value at an address if previous value matched the compared value.\n-\/\/ * atomic_xchg_at: Atomically swap a new value at an internal pointer address if previous value matched the compared value.\n+\/\/ * atomic_xchg: Atomically swap a new value at an address without checking the previous value.\n+\/\/ * atomic_xchg_at: Atomically swap a new value at an internal pointer address without checking the previous value.\n@@ -87,1 +87,1 @@\n-\/\/ The implementation of step 1-4 resides in in accessBackend.hpp, to allow selected\n+\/\/ The implementation of step 1-4 resides in accessBackend.hpp, to allow selected\n@@ -91,2 +91,1 @@\n-\/\/ access.inline.hpp. The accesses that are allowed through the access.hpp file\n-\/\/ must be instantiated in access.cpp using the INSTANTIATE_HPP_ACCESS macro.\n+\/\/ access.inline.hpp.\n","filename":"src\/hotspot\/share\/oops\/access.hpp","additions":4,"deletions":5,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -542,1 +542,1 @@\n-    assert(offset == 0 || offset >= second_part && offset <= operands->length(), \"oob (3)\");\n+    assert(offset == 0 || (offset >= second_part && offset <= operands->length()), \"oob (3)\");\n","filename":"src\/hotspot\/share\/oops\/constantPool.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -339,1 +339,1 @@\n-  assert(is_native() && bcp == code_base() || contains(bcp) || VMError::is_error_reported(),\n+  assert((is_native() && bcp == code_base()) || contains(bcp) || VMError::is_error_reported(),\n@@ -373,1 +373,1 @@\n-  assert(is_native() && bcp == code_base() || contains(bcp), \"bcp doesn't belong to this method\");\n+  assert((is_native() && bcp == code_base()) || contains(bcp), \"bcp doesn't belong to this method\");\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -412,1 +412,2 @@\n-  int num_stack_arg_slots() const { return constMethod()->num_stack_arg_slots(); }\n+  int num_stack_arg_slots(bool rounded = true) const {\n+    return rounded ? align_up(constMethod()->num_stack_arg_slots(), 2) : constMethod()->num_stack_arg_slots(); }\n","filename":"src\/hotspot\/share\/oops\/method.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -58,2 +58,0 @@\n-class FilteringClosure;\n-\n","filename":"src\/hotspot\/share\/oops\/oop.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -256,0 +256,16 @@\n+bool AddNode::is_not(PhaseGVN* phase, Node* n, BasicType bt) {\n+  return n->Opcode() == Op_Xor(bt) && phase->type(n->in(2)) == TypeInteger::minus_1(bt);\n+}\n+\n+AddNode* AddNode::make_not(PhaseGVN* phase, Node* n, BasicType bt) {\n+  switch (bt) {\n+    case T_INT:\n+      return new XorINode(n, phase->intcon(-1));\n+    case T_LONG:\n+      return new XorLNode(n, phase->longcon(-1L));\n+    default:\n+      fatal(\"Not implemented for %s\", type2name(bt));\n+  }\n+  return nullptr;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/addnode.cpp","additions":17,"deletions":1,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -96,0 +96,4 @@\n+  develop(bool, VerifyAlignVector, false,                                   \\\n+          \"Check that vector stores\/loads are aligned if AlignVector\"       \\\n+          \"is enabled.\")                                                    \\\n+                                                                            \\\n@@ -368,1 +372,1 @@\n-          \"5=all details printed. \"                                         \\\n+          \"6=all details printed. \"                                         \\\n@@ -371,1 +375,1 @@\n-          range(-1, 5)                                                      \\\n+          range(-1, 6)                                                      \\\n","filename":"src\/hotspot\/share\/opto\/c2_globals.hpp","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -37,0 +37,1 @@\n+#include \"runtime\/globals_extension.hpp\"\n@@ -67,0 +68,7 @@\n+#ifdef ASSERT\n+  if (!AlignVector && VerifyAlignVector) {\n+    warning(\"VerifyAlignVector disabled because AlignVector is not enabled.\");\n+    FLAG_SET_CMDLINE(VerifyAlignVector, false);\n+  }\n+#endif\n+\n@@ -832,0 +840,1 @@\n+  case vmIntrinsics::_notifyJvmtiVThreadDisableSuspend:\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -1024,2 +1024,2 @@\n-    assert(is_CallStaticJava()  && cg->is_mh_late_inline() ||\n-           is_CallDynamicJava() && cg->is_virtual_late_inline(), \"mismatch\");\n+    assert((is_CallStaticJava()  && cg->is_mh_late_inline()) ||\n+           (is_CallDynamicJava() && cg->is_virtual_late_inline()), \"mismatch\");\n@@ -1862,2 +1862,2 @@\n-             length_type->is_con() && narrow_length_type->is_con() &&\n-                (narrow_length_type->_hi <= length_type->_lo) ||\n+             (length_type->is_con() && narrow_length_type->is_con() &&\n+              (narrow_length_type->_hi <= length_type->_lo)) ||\n@@ -1876,2 +1876,1 @@\n-        length = new CastIINode(length, narrow_length_type);\n-        length->set_req(TypeFunc::Control, init->proj_out_or_null(TypeFunc::Control));\n+        length = new CastIINode(init->proj_out_or_null(TypeFunc::Control), length, narrow_length_type);\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":6,"deletions":7,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -147,41 +147,1 @@\n-Node* ConstraintCastNode::make_cast(int opcode, Node* c, Node* n, const Type* t, DependencyType dependency,\n-                                    const TypeTuple* extra_types) {\n-  switch(opcode) {\n-  case Op_CastII: {\n-    Node* cast = new CastIINode(n, t, dependency, false, extra_types);\n-    cast->set_req(0, c);\n-    return cast;\n-  }\n-  case Op_CastLL: {\n-    Node* cast = new CastLLNode(n, t, dependency, extra_types);\n-    cast->set_req(0, c);\n-    return cast;\n-  }\n-  case Op_CastPP: {\n-    Node* cast = new CastPPNode(n, t, dependency, extra_types);\n-    cast->set_req(0, c);\n-    return cast;\n-  }\n-  case Op_CastFF: {\n-    Node* cast = new CastFFNode(n, t, dependency, extra_types);\n-    cast->set_req(0, c);\n-    return cast;\n-  }\n-  case Op_CastDD: {\n-    Node* cast = new CastDDNode(n, t, dependency, extra_types);\n-    cast->set_req(0, c);\n-    return cast;\n-  }\n-  case Op_CastVV: {\n-    Node* cast = new CastVVNode(n, t, dependency, extra_types);\n-    cast->set_req(0, c);\n-    return cast;\n-  }\n-  case Op_CheckCastPP: return new CheckCastPPNode(c, n, t, dependency, extra_types);\n-  default:\n-    fatal(\"Bad opcode %d\", opcode);\n-  }\n-  return nullptr;\n-}\n-\n-Node* ConstraintCastNode::make(Node* c, Node *n, const Type *t, DependencyType dependency, BasicType bt) {\n+Node* ConstraintCastNode::make_cast_for_basic_type(Node* c, Node* n, const Type* t, DependencyType dependency, BasicType bt) {\n@@ -189,6 +149,4 @@\n-  case T_INT: {\n-    return make_cast(Op_CastII, c, n, t, dependency, nullptr);\n-  }\n-  case T_LONG: {\n-    return make_cast(Op_CastLL, c, n, t, dependency, nullptr);\n-  }\n+  case T_INT:\n+    return new CastIINode(c, n, t, dependency);\n+  case T_LONG:\n+    return new CastLLNode(c, n, t, dependency);\n@@ -291,1 +249,1 @@\n-  Node* n = ConstraintCastNode::make(control, parent, type, dependency, bt);\n+  Node* n = ConstraintCastNode::make_cast_for_basic_type(control, parent, type, dependency, bt);\n@@ -547,2 +505,1 @@\n-  Node* cast= nullptr;\n-    cast = make_cast(Op_CastII, c, in, type, dependency, types);\n+    return new CastIINode(c, in, type, dependency, false, types);\n@@ -551,1 +508,1 @@\n-    cast = make_cast(Op_CastLL, c, in, type, dependency, types);\n+    return new CastLLNode(c, in, type, dependency, types);\n@@ -553,1 +510,1 @@\n-    cast = make_cast(Op_CastFF, c, in, type, dependency, types);\n+    return new CastFFNode(c, in, type, dependency, types);\n@@ -555,1 +512,1 @@\n-    cast = make_cast(Op_CastDD, c, in, type, dependency, types);\n+    return new CastDDNode(c, in, type, dependency, types);\n@@ -557,1 +514,1 @@\n-    cast = make_cast(Op_CastVV, c, in, type, dependency, types);\n+    return new CastVVNode(c, in, type, dependency, types);\n@@ -559,1 +516,1 @@\n-    cast = make_cast(Op_CastPP, c, in, type, dependency, types);\n+    return new CastPPNode(c, in, type, dependency, types);\n@@ -561,1 +518,1 @@\n-  return cast;\n+  fatal(\"unreachable. Invalid cast type.\");\n","filename":"src\/hotspot\/share\/opto\/castnode.cpp","additions":13,"deletions":56,"binary":false,"changes":69,"status":"modified"},{"patch":"@@ -57,1 +57,1 @@\n-  ConstraintCastNode(Node* n, const Type* t, ConstraintCastNode::DependencyType dependency,\n+  ConstraintCastNode(Node* ctrl, Node* n, const Type* t, ConstraintCastNode::DependencyType dependency,\n@@ -61,0 +61,1 @@\n+    init_req(0, ctrl);\n@@ -71,2 +72,1 @@\n-  static Node* make_cast(int opcode, Node* c, Node* n, const Type* t, DependencyType dependency, const TypeTuple* extra_types);\n-  static Node* make(Node* c, Node *n, const Type *t, DependencyType dependency, BasicType bt);\n+  static Node* make_cast_for_basic_type(Node* c, Node* n, const Type* t, DependencyType dependency, BasicType bt);\n@@ -105,1 +105,1 @@\n-    : ConstraintCastNode(n, t, dependency, types), _range_check_dependency(range_check_dependency) {\n+    : ConstraintCastNode(nullptr, n, t, dependency, types), _range_check_dependency(range_check_dependency) {\n@@ -108,2 +108,2 @@\n-  CastIINode(Node* ctrl, Node* n, const Type* t, DependencyType dependency = RegularDependency, bool range_check_dependency = false)\n-    : ConstraintCastNode(n, t, dependency, nullptr), _range_check_dependency(range_check_dependency) {\n+  CastIINode(Node* ctrl, Node* n, const Type* t, DependencyType dependency = RegularDependency, bool range_check_dependency = false, const TypeTuple* types = nullptr)\n+    : ConstraintCastNode(ctrl, n, t, dependency, types), _range_check_dependency(range_check_dependency) {\n@@ -111,1 +111,0 @@\n-    init_req(0, ctrl);\n@@ -134,7 +133,2 @@\n-  CastLLNode(Node* ctrl, Node* n, const Type* t, DependencyType dependency = RegularDependency)\n-    : ConstraintCastNode(n, t, dependency, nullptr) {\n-    init_class_id(Class_CastLL);\n-    init_req(0, ctrl);\n-  }\n-  CastLLNode(Node* n, const Type* t, DependencyType dependency = RegularDependency, const TypeTuple* types = nullptr)\n-          : ConstraintCastNode(n, t, dependency, types) {\n+  CastLLNode(Node* ctrl, Node* n, const Type* t, DependencyType dependency = RegularDependency, const TypeTuple* types = nullptr)\n+          : ConstraintCastNode(ctrl, n, t, dependency, types) {\n@@ -152,2 +146,2 @@\n-  CastFFNode(Node* n, const Type* t, DependencyType dependency = RegularDependency, const TypeTuple* types = nullptr)\n-          : ConstraintCastNode(n, t, dependency, types) {\n+  CastFFNode(Node* ctrl, Node* n, const Type* t, DependencyType dependency = RegularDependency, const TypeTuple* types = nullptr)\n+          : ConstraintCastNode(ctrl, n, t, dependency, types) {\n@@ -162,2 +156,2 @@\n-  CastDDNode(Node* n, const Type* t, DependencyType dependency = RegularDependency, const TypeTuple* types = nullptr)\n-          : ConstraintCastNode(n, t, dependency, types) {\n+  CastDDNode(Node* ctrl, Node* n, const Type* t, DependencyType dependency = RegularDependency, const TypeTuple* types = nullptr)\n+          : ConstraintCastNode(ctrl, n, t, dependency, types) {\n@@ -172,2 +166,2 @@\n-  CastVVNode(Node* n, const Type* t, DependencyType dependency = RegularDependency, const TypeTuple* types = nullptr)\n-          : ConstraintCastNode(n, t, dependency, types) {\n+  CastVVNode(Node* ctrl, Node* n, const Type* t, DependencyType dependency = RegularDependency, const TypeTuple* types = nullptr)\n+          : ConstraintCastNode(ctrl, n, t, dependency, types) {\n@@ -185,2 +179,2 @@\n-  CastPPNode (Node *n, const Type *t, DependencyType dependency = RegularDependency, const TypeTuple* types = nullptr)\n-    : ConstraintCastNode(n, t, dependency, types) {\n+  CastPPNode (Node* ctrl, Node* n, const Type* t, DependencyType dependency = RegularDependency, const TypeTuple* types = nullptr)\n+    : ConstraintCastNode(ctrl, n, t, dependency, types) {\n@@ -196,2 +190,2 @@\n-  CheckCastPPNode(Node *c, Node *n, const Type *t, DependencyType dependency = RegularDependency, const TypeTuple* types = nullptr)\n-    : ConstraintCastNode(n, t, dependency, types) {\n+  CheckCastPPNode(Node* ctrl, Node* n, const Type* t, DependencyType dependency = RegularDependency, const TypeTuple* types = nullptr)\n+    : ConstraintCastNode(ctrl, n, t, dependency, types) {\n@@ -199,1 +193,0 @@\n-    init_req(0, c);\n","filename":"src\/hotspot\/share\/opto\/castnode.hpp","additions":18,"deletions":25,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -2209,2 +2209,1 @@\n-          cast = ConstraintCastNode::make_cast(Op_CastPP, r, uin, phi_type, ConstraintCastNode::StrongDependency,\n-                                               extra_types);\n+          cast = new CastPPNode(r, uin, phi_type, ConstraintCastNode::StrongDependency, extra_types);\n@@ -2220,2 +2219,1 @@\n-            cast = ConstraintCastNode::make_cast(Op_CastPP, r, uin, TypePtr::NOTNULL,\n-                                                 ConstraintCastNode::StrongDependency, extra_types);\n+            cast = new CastPPNode(r, uin, TypePtr::NOTNULL, ConstraintCastNode::StrongDependency, extra_types);\n@@ -2233,2 +2231,1 @@\n-            cast = ConstraintCastNode::make_cast(Op_CheckCastPP, r, n, phi_type, ConstraintCastNode::StrongDependency,\n-                                                 extra_types);\n+            cast = new CheckCastPPNode(r, n, phi_type, ConstraintCastNode::StrongDependency, extra_types);\n@@ -2237,2 +2234,1 @@\n-            cast = ConstraintCastNode::make_cast(Op_CastPP, r, uin, phi_type, ConstraintCastNode::StrongDependency,\n-                                                 extra_types);\n+            cast = new CastPPNode(r, uin, phi_type, ConstraintCastNode::StrongDependency, extra_types);\n","filename":"src\/hotspot\/share\/opto\/cfgnode.cpp","additions":4,"deletions":8,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -1792,1 +1792,1 @@\n-Node *PhaseChaitin::find_base_for_derived( Node **derived_base_map, Node *derived, uint &maxlrg ) {\n+Node* PhaseChaitin::find_base_for_derived(Node** derived_base_map, Node* derived, uint& maxlrg) {\n@@ -1794,1 +1794,1 @@\n-  if( derived_base_map[derived->_idx] )\n+  if (derived_base_map[derived->_idx]) {\n@@ -1796,0 +1796,10 @@\n+  }\n+\n+#ifdef ASSERT\n+  if (derived->is_Mach() && derived->as_Mach()->ideal_Opcode() == Op_VerifyVectorAlignment) {\n+    \/\/ Bypass the verification node\n+    Node* base = find_base_for_derived(derived_base_map, derived->in(1), maxlrg);\n+    derived_base_map[derived->_idx] = base;\n+    return base;\n+  }\n+#endif\n","filename":"src\/hotspot\/share\/opto\/chaitin.cpp","additions":13,"deletions":3,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -454,0 +454,1 @@\n+macro(VerifyVectorAlignment)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -32,0 +32,1 @@\n+#include \"compiler\/compilationFailureInfo.hpp\"\n@@ -35,0 +36,1 @@\n+#include \"compiler\/compiler_globals.hpp\"\n@@ -654,0 +656,1 @@\n+                  _first_failure_details(nullptr),\n@@ -758,1 +761,1 @@\n-    initial_gvn()->transform_no_reclaim(top());\n+    initial_gvn()->transform(top());\n@@ -953,0 +956,1 @@\n+    _first_failure_details(nullptr),\n@@ -1005,1 +1009,1 @@\n-    gvn.transform_no_reclaim(top());\n+    gvn.transform(top());\n@@ -1016,0 +1020,5 @@\n+Compile::~Compile() {\n+  delete _print_inlining_stream;\n+  delete _first_failure_details;\n+};\n+\n@@ -1068,0 +1077,4 @@\n+#ifndef PRODUCT\n+  Copy::zero_to_bytes(_igv_phase_iter, sizeof(_igv_phase_iter));\n+#endif\n+\n@@ -1083,1 +1096,1 @@\n-    if (has_method() && (_directive->VectorizeOption || _directive->VectorizeDebugOption)) {\n+    if (has_method() && _directive->VectorizeOption) {\n@@ -2891,0 +2904,1 @@\n+  print_method(PHASE_BEFORE_CCP1, 2);\n@@ -3470,0 +3484,2 @@\n+\n+    print_method(PHASE_REGISTER_ALLOCATION, 2);\n@@ -3487,0 +3503,1 @@\n+    print_method(PHASE_BLOCK_ORDERING, 3);\n@@ -3494,0 +3511,1 @@\n+    print_method(PHASE_PEEPHOLE, 3);\n@@ -3500,0 +3518,1 @@\n+    print_method(PHASE_POSTALLOC_EXPAND, 3);\n@@ -3629,2 +3648,2 @@\n-            n->is_Load() && (n->as_Load()->bottom_type()->isa_oopptr() ||\n-                             LoadNode::is_immutable_value(n->in(MemNode::Address))),\n+            (n->is_Load() && (n->as_Load()->bottom_type()->isa_oopptr() ||\n+                              LoadNode::is_immutable_value(n->in(MemNode::Address)))),\n@@ -4202,0 +4221,25 @@\n+#ifdef ASSERT\n+    \/\/ Add VerifyVectorAlignment node between adr and load \/ store.\n+    if (VerifyAlignVector && Matcher::has_match_rule(Op_VerifyVectorAlignment)) {\n+      bool must_verify_alignment = n->is_LoadVector() ? n->as_LoadVector()->must_verify_alignment() :\n+                                                        n->as_StoreVector()->must_verify_alignment();\n+      if (must_verify_alignment) {\n+        jlong vector_width = n->is_LoadVector() ? n->as_LoadVector()->memory_size() :\n+                                                  n->as_StoreVector()->memory_size();\n+        \/\/ The memory access should be aligned to the vector width in bytes.\n+        \/\/ However, the underlying array is possibly less well aligned, but at least\n+        \/\/ to ObjectAlignmentInBytes. Hence, even if multiple arrays are accessed in\n+        \/\/ a loop we can expect at least the following alignment:\n+        jlong guaranteed_alignment = MIN2(vector_width, (jlong)ObjectAlignmentInBytes);\n+        assert(2 <= guaranteed_alignment && guaranteed_alignment <= 64, \"alignment must be in range\");\n+        assert(is_power_of_2(guaranteed_alignment), \"alignment must be power of 2\");\n+        \/\/ Create mask from alignment. e.g. 0b1000 -> 0b0111\n+        jlong mask = guaranteed_alignment - 1;\n+        Node* mask_con = ConLNode::make(mask);\n+        VerifyVectorAlignmentNode* va = new VerifyVectorAlignmentNode(n->in(MemNode::Address), mask_con);\n+        n->set_req(MemNode::Address, va);\n+      }\n+    }\n+#endif\n+    break;\n+\n@@ -4870,0 +4914,3 @@\n+    if (CaptureBailoutInformation) {\n+      _first_failure_details = new CompilationFailureInfo(reason);\n+    }\n@@ -4992,1 +5039,0 @@\n-    value = new CastIINode(value, itype, carry_dependency ? ConstraintCastNode::StrongDependency : ConstraintCastNode::RegularDependency, true \/* range check dependency *\/);\n@@ -4997,1 +5043,1 @@\n-    value->set_req(0, ctrl);\n+    value = new CastIINode(ctrl, value, itype, carry_dependency ? ConstraintCastNode::StrongDependency : ConstraintCastNode::RegularDependency, true \/* range check dependency *\/);\n@@ -5654,0 +5700,4 @@\n+  int iter = ++_igv_phase_iter[cpt];\n+  if (iter > 1) {\n+    ss.print(\" %d\", iter);\n+  }\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":58,"deletions":8,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -57,0 +57,1 @@\n+class CompilationFailureInfo;\n@@ -349,0 +350,1 @@\n+  uint                  _igv_phase_iter[PHASE_NUM_TYPES]; \/\/ Counters for IGV phase iterations\n@@ -371,0 +373,1 @@\n+  CompilationFailureInfo* _first_failure_details; \/\/ Details for the first failure happening during compilation\n@@ -541,0 +544,1 @@\n+  void reset_igv_phase_iter(CompilerPhaseType cpt) { _igv_phase_iter[cpt] = 0; }\n@@ -836,0 +840,1 @@\n+  const CompilationFailureInfo* first_failure_details() const { return _first_failure_details; }\n@@ -1152,3 +1157,1 @@\n-  ~Compile() {\n-    delete _print_inlining_stream;\n-  };\n+  ~Compile();\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -1151,1 +1151,1 @@\n-         (n_ptn != nullptr) && (n_ptn->ideal_node() != nullptr),\n+         ((n_ptn != nullptr) && (n_ptn->ideal_node() != nullptr)),\n@@ -3940,1 +3940,1 @@\n-                 tn_t != nullptr && !tinst->maybe_java_subtype_of(tn_t),\n+                 (tn_t != nullptr && !tinst->maybe_java_subtype_of(tn_t)),\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -196,1 +196,1 @@\n-  _gvn.transform_no_reclaim(call);\n+  _gvn.transform(call);\n","filename":"src\/hotspot\/share\/opto\/generateOptoStub.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1503,2 +1503,1 @@\n-  Node *cast = new CastPPNode(obj,t_not_null);\n-  cast->init_req(0, control());\n+  Node* cast = new CastPPNode(control(), obj,t_not_null);\n@@ -1628,0 +1627,5 @@\n+    if (ld->is_DecodeN()) {\n+      \/\/ Also record the actual load (LoadN) in case ld is DecodeN\n+      assert(ld->in(1)->Opcode() == Op_LoadN, \"Assumption invalid: input to DecodeN is not LoadN\");\n+      record_for_igvn(ld->in(1));\n+    }\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -153,2 +153,3 @@\n-  assert(!is_decoden || (val->in(0) == nullptr) && val->is_Mach() &&\n-         (val->as_Mach()->ideal_Opcode() == Op_DecodeN), \"sanity\");\n+  assert(!is_decoden ||\n+         ((val->in(0) == nullptr) && val->is_Mach() &&\n+          (val->as_Mach()->ideal_Opcode() == Op_DecodeN)), \"sanity\");\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -500,1 +500,2 @@\n-  case vmIntrinsics::_notifyJvmtiVThreadHideFrames: return inline_native_notify_jvmti_hide();\n+  case vmIntrinsics::_notifyJvmtiVThreadHideFrames:     return inline_native_notify_jvmti_hide();\n+  case vmIntrinsics::_notifyJvmtiVThreadDisableSuspend: return inline_native_notify_jvmti_sync();\n@@ -882,2 +883,1 @@\n-    Node* ccast = new CastIINode(index, TypeInt::POS);\n-    ccast->set_req(0, control());\n+    Node* ccast = new CastIINode(control(), index, TypeInt::POS);\n@@ -1150,1 +1150,3 @@\n-  Node* casted_length = ConstraintCastNode::make(control(), length, TypeInteger::make(0, upper_bound, Type::WidenMax, bt), ConstraintCastNode::RegularDependency, bt);\n+  Node* casted_length = ConstraintCastNode::make_cast_for_basic_type(\n+      control(), length, TypeInteger::make(0, upper_bound, Type::WidenMax, bt),\n+      ConstraintCastNode::RegularDependency, bt);\n@@ -1178,1 +1180,3 @@\n-  Node* result = ConstraintCastNode::make(control(), index, TypeInteger::make(0, upper_bound, Type::WidenMax, bt), ConstraintCastNode::RegularDependency, bt);\n+  Node* result = ConstraintCastNode::make_cast_for_basic_type(\n+      control(), index, TypeInteger::make(0, upper_bound, Type::WidenMax, bt),\n+      ConstraintCastNode::RegularDependency, bt);\n@@ -3156,0 +3160,23 @@\n+\/\/ Always update the is_disable_suspend bit.\n+bool LibraryCallKit::inline_native_notify_jvmti_sync() {\n+  if (!DoJVMTIVirtualThreadTransitions) {\n+    return true;\n+  }\n+  IdealKit ideal(this);\n+\n+  {\n+    \/\/ unconditionally update the is_disable_suspend bit in current JavaThread\n+    Node* thread = ideal.thread();\n+    Node* arg = _gvn.transform(argument(1)); \/\/ argument for notification\n+    Node* addr = basic_plus_adr(thread, in_bytes(JavaThread::is_disable_suspend_offset()));\n+    const TypePtr *addr_type = _gvn.type(addr)->isa_ptr();\n+\n+    sync_kit(ideal);\n+    access_store_at(nullptr, addr, addr_type, arg, _gvn.type(arg), T_BOOLEAN, IN_NATIVE | MO_UNORDERED);\n+    ideal.sync_kit(this);\n+  }\n+  final_sync(ideal);\n+\n+  return true;\n+}\n+\n@@ -4551,2 +4578,1 @@\n-      Node* cast = new CastPPNode(klass_node, akls);\n-      cast->init_req(0, control());\n+      Node* cast = new CastPPNode(control(), klass_node, akls);\n@@ -5738,0 +5764,4 @@\n+    \/\/ Disable the intrinsic if the CPU does not support SIMD sort\n+    if (!Matcher::supports_simd_sort(bt)) {\n+      return false;\n+    }\n@@ -5791,0 +5821,4 @@\n+  \/\/ Disable the intrinsic if the CPU does not support SIMD sort\n+  if (!Matcher::supports_simd_sort(bt)) {\n+    return false;\n+  }\n@@ -6283,2 +6317,1 @@\n-       Node *cast = new CastPPNode(z, TypePtr::NOTNULL);\n-       cast->init_req(0, control());\n+       Node* cast = new CastPPNode(control(), z, TypePtr::NOTNULL);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":42,"deletions":9,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -272,0 +272,1 @@\n+  bool inline_native_notify_jvmti_sync();\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -202,2 +202,0 @@\n-  C->set_has_monitors(true);\n-\n@@ -221,4 +219,0 @@\n-  \/\/ need to set it for monitor exit as well.\n-  \/\/ OSR compiled methods can start with lock taken\n-  C->set_has_monitors(true);\n-\n","filename":"src\/hotspot\/share\/opto\/locknode.cpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -170,0 +170,2 @@\n+  C->print_method(PHASE_BEFORE_LOOP_UNSWITCHING, 4, head);\n+\n@@ -249,0 +251,2 @@\n+  C->print_method(PHASE_AFTER_LOOP_UNSWITCHING, 4, head_clone);\n+\n","filename":"src\/hotspot\/share\/opto\/loopUnswitch.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -800,11 +800,3 @@\n-  float infrequent_prob = PROB_UNLIKELY_MAG(3);\n-  \/\/ Ignore cost and blocks frequency if CMOVE can be moved outside the loop.\n-  if (used_inside_loop) {\n-    if (cost >= ConditionalMoveLimit) return nullptr; \/\/ Too much goo\n-\n-    \/\/ BlockLayoutByFrequency optimization moves infrequent branch\n-    \/\/ from hot path. No point in CMOV'ing in such case (110 is used\n-    \/\/ instead of 100 to take into account not exactness of float value).\n-    if (BlockLayoutByFrequency) {\n-      infrequent_prob = MAX2(infrequent_prob, (float)BlockLayoutMinDiamondPercentage\/110.0f);\n-    }\n+  \/\/ Ignore cost if CMOVE can be moved outside the loop.\n+  if (used_inside_loop && cost >= ConditionalMoveLimit) {\n+    return nullptr;\n@@ -814,0 +806,1 @@\n+  constexpr float infrequent_prob = PROB_UNLIKELY_MAG(2);\n@@ -816,2 +809,1 @@\n-  } else if (iff->_prob < infrequent_prob ||\n-      iff->_prob > (1.0f - infrequent_prob))\n+  } else if (iff->_prob < infrequent_prob || iff->_prob > (1.0f - infrequent_prob)) {\n@@ -819,0 +811,1 @@\n+  }\n@@ -1617,0 +1610,4 @@\n+    C->print_method(PHASE_BEFORE_SPLIT_IF, 4, iff);\n+    if ((PrintOpto && VerifyLoopOptimizations) || TraceLoopOpts) {\n+      tty->print_cr(\"Split-If\");\n+    }\n@@ -1618,0 +1615,1 @@\n+    C->print_method(PHASE_AFTER_SPLIT_IF, 4, iff);\n@@ -3809,0 +3807,3 @@\n+\n+  C->print_method(PHASE_BEFORE_PARTIAL_PEELING, 4, head);\n+\n@@ -4103,0 +4104,3 @@\n+\n+  C->print_method(PHASE_AFTER_PARTIAL_PEELING, 4, new_head_clone);\n+\n","filename":"src\/hotspot\/share\/opto\/loopopts.cpp","additions":17,"deletions":13,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -360,0 +360,7 @@\n+#ifdef ASSERT\n+  if (base != nullptr && base->is_Mach() && base->as_Mach()->ideal_Opcode() == Op_VerifyVectorAlignment) {\n+    \/\/ For VerifyVectorAlignment we just pass the type through\n+    return base->bottom_type()->is_ptr();\n+  }\n+#endif\n+\n","filename":"src\/hotspot\/share\/opto\/machnode.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -325,1 +325,1 @@\n-        adr = _igvn.transform(new CastPPNode(adr, adr_type));\n+        adr = _igvn.transform(new CastPPNode(ctl, adr, adr_type));\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -5054,1 +5054,1 @@\n-         alias_idx == Compile::AliasIdxBot && !Compile::current()->do_aliasing(),\n+         (alias_idx == Compile::AliasIdxBot && !Compile::current()->do_aliasing()),\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -794,1 +794,1 @@\n-           _oop_alias_idx == Compile::AliasIdxBot && !Compile::current()->do_aliasing(),\n+           (_oop_alias_idx == Compile::AliasIdxBot && !Compile::current()->do_aliasing()),\n","filename":"src\/hotspot\/share\/opto\/memnode.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -625,0 +625,7 @@\n+  \/\/ Convert \"(~a) & (~b)\" into \"~(a | b)\"\n+  if (AddNode::is_not(phase, in(1), T_INT) && AddNode::is_not(phase, in(2), T_INT)) {\n+    Node* or_a_b = new OrINode(in(1)->in(1), in(2)->in(1));\n+    Node* tn = phase->transform(or_a_b);\n+    return AddNode::make_not(phase, tn, T_INT);\n+  }\n+\n@@ -773,0 +780,7 @@\n+  \/\/ Convert \"(~a) & (~b)\" into \"~(a | b)\"\n+  if (AddNode::is_not(phase, in(1), T_LONG) && AddNode::is_not(phase, in(2), T_LONG)) {\n+    Node* or_a_b = new OrLNode(in(1)->in(1), in(2)->in(1));\n+    Node* tn = phase->transform(or_a_b);\n+    return AddNode::make_not(phase, tn, T_LONG);\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/mulnode.cpp","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -185,0 +185,1 @@\n+class VerifyVectorAlignmentNode;\n@@ -455,1 +456,1 @@\n-    assert( i == 0 && this == n ||\n+    assert( (i == 0 && this == n) ||\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -419,2 +419,5 @@\n-  bool is_normal_parse() const  { return _entry_bci == InvocationEntryBci; }\n-  bool is_osr_parse() const     { return _entry_bci != InvocationEntryBci; }\n+  bool is_osr_parse() const {\n+    assert(_entry_bci != UnknownBci, \"uninitialized _entry_bci\");\n+    return _entry_bci != InvocationEntryBci;\n+  }\n+  bool is_normal_parse() const  { return !is_osr_parse(); }\n","filename":"src\/hotspot\/share\/opto\/parse.hpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -408,2 +408,0 @@\n-  _entry_bci = InvocationEntryBci;\n-  _tf = nullptr;\n@@ -414,2 +412,3 @@\n-  debug_only(_block_count = -1);\n-  debug_only(_blocks = (Block*)-1);\n+  DEBUG_ONLY(_entry_bci = UnknownBci);\n+  DEBUG_ONLY(_block_count = -1);\n+  DEBUG_ONLY(_blocks = (Block*)-1);\n@@ -419,2 +418,1 @@\n-    JVMState* ilt_caller = is_osr_parse() ? caller->caller() : caller;\n-    InlineTree::find_subtree_from_root(C->ilt(), ilt_caller, parse_method);\n+    InlineTree::find_subtree_from_root(C->ilt(), caller, parse_method);\n@@ -430,1 +428,1 @@\n-  if (parse_method->is_synchronized()) {\n+  if (parse_method->is_synchronized() || parse_method->has_monitor_bytecodes()) {\n@@ -434,12 +432,0 @@\n-  _tf = TypeFunc::make(method());\n-  _flow = method()->get_flow_analysis();\n-  if (_flow->failing()) {\n-    assert(false, \"type flow failed during parsing\");\n-    C->record_method_not_compilable(_flow->failure_reason());\n-  }\n-\n-#ifndef PRODUCT\n-  if (_flow->has_irreducible_entry()) {\n-    C->set_parsed_irreducible_loop(true);\n-  }\n-#endif\n@@ -514,0 +500,1 @@\n+    _tf = C->tf();     \/\/ the OSR entry type is different\n@@ -516,5 +503,11 @@\n-    if (_flow->failing()) {\n-      \/\/ TODO Adding a trap due to an unloaded return type in ciTypeFlow::StateVector::do_invoke\n-      \/\/ can lead to this. Re-enable once 8284443 is fixed.\n-      \/\/ assert(false, \"type flow analysis failed for OSR compilation\");\n-      C->record_method_not_compilable(_flow->failure_reason());\n+  } else {\n+    _tf = TypeFunc::make(method());\n+    _entry_bci = InvocationEntryBci;\n+    _flow = method()->get_flow_analysis();\n+  }\n+\n+  if (_flow->failing()) {\n+    \/\/ TODO Adding a trap due to an unloaded return type in ciTypeFlow::StateVector::do_invoke\n+    \/\/ can lead to this. Re-enable once 8284443 is fixed.\n+    \/\/assert(false, \"type flow analysis failed during parsing\");\n+    C->record_method_not_compilable(_flow->failure_reason());\n@@ -523,1 +516,5 @@\n-        tty->print_cr(\"OSR @%d type flow bailout: %s\", _entry_bci, _flow->failure_reason());\n+        if (is_osr_parse()) {\n+          tty->print_cr(\"OSR @%d type flow bailout: %s\", _entry_bci, _flow->failure_reason());\n+        } else {\n+          tty->print_cr(\"type flow bailout: %s\", _flow->failure_reason());\n+        }\n@@ -531,2 +528,0 @@\n-    }\n-    _tf = C->tf();     \/\/ the OSR entry type is different\n@@ -544,0 +539,4 @@\n+  if (_flow->has_irreducible_entry()) {\n+    C->set_parsed_irreducible_loop(true);\n+  }\n+\n@@ -732,1 +731,1 @@\n-        Node* result = _gvn.transform_no_reclaim(control());\n+        Node* result = _gvn.transform(control());\n@@ -955,1 +954,1 @@\n-  initial_gvn()->transform_no_reclaim(ret);\n+  initial_gvn()->transform(ret);\n@@ -974,1 +973,1 @@\n-  initial_gvn()->transform_no_reclaim(exit);\n+  initial_gvn()->transform(exit);\n@@ -1592,1 +1591,1 @@\n-    tty->print(\"Parsing block #%d at bci [%d,%d), successors: \",\n+    tty->print(\"Parsing block #%d at bci [%d,%d), successors:\",\n@@ -1595,1 +1594,1 @@\n-      tty->print((( i < ns) ? \" %d\" : \" %d(e)\"), b->successor_at(i)->rpo());\n+      tty->print((( i < ns) ? \" %d\" : \" %d(exception block)\"), b->successor_at(i)->rpo());\n@@ -1598,1 +1597,1 @@\n-      tty->print(\"  lphd\");\n+      tty->print(\"  loop head\");\n@@ -1884,1 +1883,1 @@\n-        Node* result = _gvn.transform_no_reclaim(r);\n+        Node* result = _gvn.transform(r);\n@@ -1960,1 +1959,1 @@\n-          map()->set_req(j, _gvn.transform_no_reclaim(vtm));\n+          map()->set_req(j, _gvn.transform(vtm));\n@@ -1975,1 +1974,1 @@\n-          map()->set_req(j, _gvn.transform_no_reclaim(phi));\n+          map()->set_req(j, _gvn.transform(phi));\n@@ -2053,1 +2052,1 @@\n-        p = _gvn.transform_no_reclaim(phi);\n+        p = _gvn.transform(phi);\n@@ -2061,1 +2060,1 @@\n-    m->set_base_memory( _gvn.transform_no_reclaim(base) );\n+    m->set_base_memory(_gvn.transform(base));\n","filename":"src\/hotspot\/share\/opto\/parse1.cpp","additions":37,"deletions":38,"binary":false,"changes":75,"status":"modified"},{"patch":"@@ -2483,1 +2483,1 @@\n-        ccast = new CastIINode(val, tboth);\n+        ccast = new CastIINode(control(), val, tboth);\n@@ -2486,1 +2486,1 @@\n-        ccast = new CastPPNode(val, tboth);\n+        ccast = new CastPPNode(control(), val, tboth);\n@@ -2517,1 +2517,0 @@\n-    ccast->set_req(0, control());\n@@ -3540,1 +3539,1 @@\n-  constexpr int perBytecode = 5;\n+  constexpr int perBytecode = 6;\n","filename":"src\/hotspot\/share\/opto\/parse2.cpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -673,7 +673,0 @@\n-\/\/------------------------------transform--------------------------------------\n-\/\/ Return a node which computes the same function as this node, but in a\n-\/\/ faster or cheaper fashion.\n-Node *PhaseGVN::transform( Node *n ) {\n-  return transform_no_reclaim(n);\n-}\n-\n@@ -683,1 +676,1 @@\n-Node *PhaseGVN::transform_no_reclaim(Node *n) {\n+Node* PhaseGVN::transform(Node* n) {\n@@ -695,1 +688,1 @@\n-      dump_infinite_loop_info(i, \"PhaseGVN::transform_no_reclaim\");\n+      dump_infinite_loop_info(i, \"PhaseGVN::transform\");\n@@ -897,1 +890,1 @@\n-    C->print_method(PHASE_AFTER_ITER_GVN_STEP, 4, n);\n+    C->print_method(PHASE_AFTER_ITER_GVN_STEP, 5, n);\n@@ -1028,0 +1021,1 @@\n+  NOT_PRODUCT(C->reset_igv_phase_iter(PHASE_AFTER_ITER_GVN_STEP);)\n","filename":"src\/hotspot\/share\/opto\/phaseX.cpp","additions":4,"deletions":10,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -418,2 +418,2 @@\n-  Node  *transform( Node *n );\n-  Node  *transform_no_reclaim( Node *n );\n+  Node* transform(Node* n);\n+\n","filename":"src\/hotspot\/share\/opto\/phaseX.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -31,47 +31,73 @@\n-  flags(BEFORE_STRINGOPTS,            \"Before StringOpts\") \\\n-  flags(AFTER_STRINGOPTS,             \"After StringOpts\") \\\n-  flags(BEFORE_REMOVEUSELESS,         \"Before RemoveUseless\") \\\n-  flags(AFTER_PARSING,                \"After Parsing\") \\\n-  flags(BEFORE_ITER_GVN,              \"Before Iter GVN\") \\\n-  flags(ITER_GVN1,                    \"Iter GVN 1\") \\\n-  flags(AFTER_ITER_GVN_STEP,          \"After Iter GVN Step\") \\\n-  flags(AFTER_ITER_GVN,               \"After Iter GVN\") \\\n-  flags(INCREMENTAL_INLINE_STEP,      \"Incremental Inline Step\") \\\n-  flags(INCREMENTAL_INLINE_CLEANUP,   \"Incremental Inline Cleanup\") \\\n-  flags(INCREMENTAL_INLINE,           \"Incremental Inline\") \\\n-  flags(INCREMENTAL_BOXING_INLINE,    \"Incremental Boxing Inline\") \\\n-  flags(EXPAND_VUNBOX,                \"Expand VectorUnbox\") \\\n-  flags(SCALARIZE_VBOX,               \"Scalarize VectorBox\") \\\n-  flags(INLINE_VECTOR_REBOX,          \"Inline Vector Rebox Calls\") \\\n-  flags(EXPAND_VBOX,                  \"Expand VectorBox\") \\\n-  flags(ELIMINATE_VBOX_ALLOC,         \"Eliminate VectorBoxAllocate\") \\\n-  flags(ITER_GVN_BEFORE_EA,           \"Iter GVN before EA\") \\\n-  flags(ITER_GVN_AFTER_VECTOR,        \"Iter GVN after vector box elimination\") \\\n-  flags(BEFORE_BEAUTIFY_LOOPS,        \"Before beautify loops\") \\\n-  flags(AFTER_BEAUTIFY_LOOPS,         \"After beautify loops\") \\\n-  flags(BEFORE_CLOOPS,                \"Before CountedLoop\") \\\n-  flags(AFTER_CLOOPS,                 \"After CountedLoop\") \\\n-  flags(PHASEIDEAL_BEFORE_EA,         \"PhaseIdealLoop before EA\") \\\n-  flags(AFTER_EA,                     \"After Escape Analysis\") \\\n-  flags(ITER_GVN_AFTER_EA,            \"Iter GVN after EA\") \\\n-  flags(ITER_GVN_AFTER_ELIMINATION,   \"Iter GVN after eliminating allocations and locks\") \\\n-  flags(PHASEIDEALLOOP1,              \"PhaseIdealLoop 1\") \\\n-  flags(PHASEIDEALLOOP2,              \"PhaseIdealLoop 2\") \\\n-  flags(PHASEIDEALLOOP3,              \"PhaseIdealLoop 3\") \\\n-  flags(CCP1,                         \"PhaseCCP 1\") \\\n-  flags(ITER_GVN2,                    \"Iter GVN 2\") \\\n-  flags(PHASEIDEALLOOP_ITERATIONS,    \"PhaseIdealLoop iterations\") \\\n-  flags(MACRO_EXPANSION,              \"Macro expand\") \\\n-  flags(BARRIER_EXPANSION,            \"Barrier expand\") \\\n-  flags(OPTIMIZE_FINISHED,            \"Optimize finished\") \\\n-  flags(BEFORE_MATCHING,              \"Before matching\") \\\n-  flags(MATCHING,                     \"After matching\") \\\n-  flags(GLOBAL_CODE_MOTION,           \"Global code motion\") \\\n-  flags(MACH_ANALYSIS,                \"After mach analysis\") \\\n-  flags(FINAL_CODE,                   \"Final Code\") \\\n-  flags(END,                          \"End\") \\\n-  flags(FAILURE,                      \"Failure\") \\\n-  flags(SPLIT_INLINES_ARRAY,          \"Split inlines array\") \\\n-  flags(SPLIT_INLINES_ARRAY_IGVN,     \"IGVN after split inlines array\") \\\n-  flags(ALL,                          \"All\") \\\n-  flags(DEBUG,                        \"Debug\")\n+  flags(BEFORE_STRINGOPTS,              \"Before StringOpts\") \\\n+  flags(AFTER_STRINGOPTS,               \"After StringOpts\") \\\n+  flags(BEFORE_REMOVEUSELESS,           \"Before RemoveUseless\") \\\n+  flags(AFTER_PARSING,                  \"After Parsing\") \\\n+  flags(BEFORE_ITER_GVN,                \"Before Iter GVN\") \\\n+  flags(ITER_GVN1,                      \"Iter GVN 1\") \\\n+  flags(AFTER_ITER_GVN_STEP,            \"After Iter GVN Step\") \\\n+  flags(AFTER_ITER_GVN,                 \"After Iter GVN\") \\\n+  flags(INCREMENTAL_INLINE_STEP,        \"Incremental Inline Step\") \\\n+  flags(INCREMENTAL_INLINE_CLEANUP,     \"Incremental Inline Cleanup\") \\\n+  flags(INCREMENTAL_INLINE,             \"Incremental Inline\") \\\n+  flags(INCREMENTAL_BOXING_INLINE,      \"Incremental Boxing Inline\") \\\n+  flags(EXPAND_VUNBOX,                  \"Expand VectorUnbox\") \\\n+  flags(SCALARIZE_VBOX,                 \"Scalarize VectorBox\") \\\n+  flags(INLINE_VECTOR_REBOX,            \"Inline Vector Rebox Calls\") \\\n+  flags(EXPAND_VBOX,                    \"Expand VectorBox\") \\\n+  flags(ELIMINATE_VBOX_ALLOC,           \"Eliminate VectorBoxAllocate\") \\\n+  flags(ITER_GVN_BEFORE_EA,             \"Iter GVN before EA\") \\\n+  flags(ITER_GVN_AFTER_VECTOR,          \"Iter GVN after vector box elimination\") \\\n+  flags(BEFORE_BEAUTIFY_LOOPS,          \"Before beautify loops\") \\\n+  flags(AFTER_BEAUTIFY_LOOPS,           \"After beautify loops\") \\\n+  flags(BEFORE_LOOP_UNROLLING,          \"Before Loop Unrolling\") \\\n+  flags(AFTER_LOOP_UNROLLING,           \"After Loop Unrolling\") \\\n+  flags(BEFORE_SPLIT_IF,                \"Before Split-If\") \\\n+  flags(AFTER_SPLIT_IF,                 \"After Split-If\") \\\n+  flags(BEFORE_LOOP_PREDICATION_IC,     \"Before Loop Predication IC\") \\\n+  flags(AFTER_LOOP_PREDICATION_IC,      \"After Loop Predication IC\") \\\n+  flags(BEFORE_LOOP_PREDICATION_RC,     \"Before Loop Predication RC\") \\\n+  flags(AFTER_LOOP_PREDICATION_RC,      \"After Loop Predication RC\") \\\n+  flags(BEFORE_PARTIAL_PEELING,         \"Before Partial Peeling\") \\\n+  flags(AFTER_PARTIAL_PEELING,          \"After Partial Peeling\") \\\n+  flags(BEFORE_LOOP_PEELING,            \"Before Loop Peeling\") \\\n+  flags(AFTER_LOOP_PEELING,             \"After Loop Peeling\") \\\n+  flags(BEFORE_LOOP_UNSWITCHING,        \"Before Loop Unswitching\") \\\n+  flags(AFTER_LOOP_UNSWITCHING,         \"After Loop Unswitching\") \\\n+  flags(BEFORE_RANGE_CHECK_ELIMINATION, \"Before Range Check Elimination\") \\\n+  flags(AFTER_RANGE_CHECK_ELIMINATION,  \"After Range Check Elimination\") \\\n+  flags(BEFORE_PRE_MAIN_POST,           \"Before Pre\/Main\/Post Loops\") \\\n+  flags(AFTER_PRE_MAIN_POST,            \"After Pre\/Main\/Post Loops\") \\\n+  flags(SUPERWORD1_BEFORE_SCHEDULE,     \"Superword 1, Before Schedule\") \\\n+  flags(SUPERWORD2_BEFORE_OUTPUT,       \"Superword 2, Before Output\") \\\n+  flags(SUPERWORD3_AFTER_OUTPUT,        \"Superword 3, After Output\") \\\n+  flags(BEFORE_CLOOPS,                  \"Before CountedLoop\") \\\n+  flags(AFTER_CLOOPS,                   \"After CountedLoop\") \\\n+  flags(PHASEIDEAL_BEFORE_EA,           \"PhaseIdealLoop before EA\") \\\n+  flags(AFTER_EA,                       \"After Escape Analysis\") \\\n+  flags(ITER_GVN_AFTER_EA,              \"Iter GVN after EA\") \\\n+  flags(ITER_GVN_AFTER_ELIMINATION,     \"Iter GVN after eliminating allocations and locks\") \\\n+  flags(PHASEIDEALLOOP1,                \"PhaseIdealLoop 1\") \\\n+  flags(PHASEIDEALLOOP2,                \"PhaseIdealLoop 2\") \\\n+  flags(PHASEIDEALLOOP3,                \"PhaseIdealLoop 3\") \\\n+  flags(BEFORE_CCP1,                    \"Before PhaseCCP 1\") \\\n+  flags(CCP1,                           \"PhaseCCP 1\") \\\n+  flags(ITER_GVN2,                      \"Iter GVN 2\") \\\n+  flags(PHASEIDEALLOOP_ITERATIONS,      \"PhaseIdealLoop iterations\") \\\n+  flags(MACRO_EXPANSION,                \"Macro expand\") \\\n+  flags(BARRIER_EXPANSION,              \"Barrier expand\") \\\n+  flags(OPTIMIZE_FINISHED,              \"Optimize finished\") \\\n+  flags(BEFORE_MATCHING,                \"Before matching\") \\\n+  flags(MATCHING,                       \"After matching\") \\\n+  flags(GLOBAL_CODE_MOTION,             \"Global code motion\") \\\n+  flags(REGISTER_ALLOCATION,            \"Register Allocation\") \\\n+  flags(BLOCK_ORDERING,                 \"Block Ordering\") \\\n+  flags(PEEPHOLE,                       \"Peephole\") \\\n+  flags(POSTALLOC_EXPAND,               \"Post-Allocation Expand\") \\\n+  flags(MACH_ANALYSIS,                  \"After mach analysis\") \\\n+  flags(FINAL_CODE,                     \"Final Code\") \\\n+  flags(END,                            \"End\") \\\n+  flags(FAILURE,                        \"Failure\") \\\n+  flags(SPLIT_INLINES_ARRAY,            \"Split inlines array\") \\\n+  flags(SPLIT_INLINES_ARRAY_IGVN,       \"IGVN after split inlines array\") \\\n+  flags(ALL,                            \"All\") \\\n+  flags(DEBUG,                          \"Debug\")\n","filename":"src\/hotspot\/share\/opto\/phasetype.hpp","additions":73,"deletions":47,"binary":false,"changes":120,"status":"modified"},{"patch":"@@ -595,6 +595,0 @@\n-  if (PrintOpto && VerifyLoopOptimizations) {\n-    tty->print_cr(\"Split-if\");\n-  }\n-  if (TraceLoopOpts) {\n-    tty->print_cr(\"SplitIf\");\n-  }\n","filename":"src\/hotspot\/share\/opto\/split_if.cpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -4862,1 +4862,1 @@\n-    return this_one->_klass->is_subtype_of(other->_klass);\n+    return this_one->klass()->is_subtype_of(other->klass());\n@@ -6383,1 +6383,1 @@\n-  return this_one->_klass->is_subtype_of(other->_klass) && this_one->_interfaces->contains(other->_interfaces);\n+  return this_one->klass()->is_subtype_of(other->klass()) && this_one->_interfaces->contains(other->_interfaces);\n@@ -6398,1 +6398,1 @@\n-  return this_one->_klass->equals(other->_klass) && this_one->_interfaces->eq(other->_interfaces);\n+  return this_one->klass()->equals(other->klass()) && this_one->_interfaces->eq(other->_interfaces);\n@@ -6412,1 +6412,1 @@\n-    return !this_exact && this_one->_klass->equals(ciEnv::current()->Object_klass())  && other->_interfaces->contains(this_one->_interfaces);\n+    return !this_exact && this_one->klass()->equals(ciEnv::current()->Object_klass())  && other->_interfaces->contains(this_one->_interfaces);\n@@ -6421,1 +6421,1 @@\n-  if (!this_one->_klass->is_subtype_of(other->_klass) && !other->_klass->is_subtype_of(this_one->_klass)) {\n+  if (!this_one->klass()->is_subtype_of(other->klass()) && !other->klass()->is_subtype_of(this_one->klass())) {\n@@ -6426,1 +6426,1 @@\n-    return this_one->_klass->is_subtype_of(other->_klass) && this_one->_interfaces->contains(other->_interfaces);\n+    return this_one->klass()->is_subtype_of(other->klass()) && this_one->_interfaces->contains(other->_interfaces);\n@@ -6546,1 +6546,1 @@\n-ciKlass* TypeAryPtr::compute_klass(DEBUG_ONLY(bool verify)) const {\n+ciKlass* TypeAryPtr::compute_klass() const {\n@@ -6572,22 +6572,1 @@\n-    \/\/ Cannot compute array klass directly from basic type,\n-    \/\/ since subtypes of TypeInt all have basic type T_INT.\n-#ifdef ASSERT\n-    if (verify && el->isa_int()) {\n-      \/\/ Check simple cases when verifying klass.\n-      BasicType bt = T_ILLEGAL;\n-      if (el == TypeInt::BYTE) {\n-        bt = T_BYTE;\n-      } else if (el == TypeInt::SHORT) {\n-        bt = T_SHORT;\n-      } else if (el == TypeInt::CHAR) {\n-        bt = T_CHAR;\n-      } else if (el == TypeInt::INT) {\n-        bt = T_INT;\n-      } else {\n-        return _klass; \/\/ just return specified klass\n-      }\n-      return ciTypeArrayKlass::make(bt);\n-    }\n-#endif\n-    assert(!el->isa_int(),\n-           \"integral arrays must be pre-equipped with a class\");\n+    assert(!el->isa_int(), \"integral arrays must be pre-equipped with a class\");\n@@ -6918,1 +6897,1 @@\n-    return this_one->_klass->is_subtype_of(other->_klass);\n+    return this_one->klass()->is_subtype_of(other->klass());\n@@ -6950,2 +6929,1 @@\n-    assert(this_one->_klass != nullptr && other->_klass != nullptr, \"\");\n-    return this_one->_klass->equals(other->_klass);\n+    return this_one->klass()->equals(other->klass());\n@@ -6971,1 +6949,1 @@\n-    return other->_klass->equals(ciEnv::current()->Object_klass()) && other->_interfaces->intersection_with(this_one->_interfaces)->eq(other->_interfaces);\n+    return other->klass()->equals(ciEnv::current()->Object_klass()) && other->_interfaces->intersection_with(this_one->_interfaces)->eq(other->_interfaces);\n@@ -6990,1 +6968,1 @@\n-    return this_one->_klass->is_subtype_of(other->_klass);\n+    return this_one->klass()->is_subtype_of(other->klass());\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":12,"deletions":34,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -1484,1 +1484,1 @@\n-  ciKlass* compute_klass(DEBUG_ONLY(bool verify = false)) const;\n+  ciKlass* compute_klass() const;\n","filename":"src\/hotspot\/share\/opto\/type.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -491,1 +491,1 @@\n-    vec_field_ld = gvn.transform(new CastPPNode(vec_field_ld, payload_type));\n+    vec_field_ld = gvn.transform(new CastPPNode(nullptr, vec_field_ld, payload_type));\n","filename":"src\/hotspot\/share\/opto\/vector.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -4047,2 +4047,0 @@\n-#else\n-  fatal(\"Should only be called with JVMTI enabled\");\n@@ -4064,2 +4062,0 @@\n-#else\n-  fatal(\"Should only be called with JVMTI enabled\");\n@@ -4083,2 +4079,0 @@\n-#else\n-  fatal(\"Should only be called with JVMTI enabled\");\n@@ -4102,2 +4096,0 @@\n-#else\n-  fatal(\"Should only be called with JVMTI enabled\");\n@@ -4117,2 +4109,14 @@\n-#else\n-  fatal(\"Should only be called with JVMTI enabled\");\n+#endif\n+JVM_END\n+\n+\/\/ Notification from VirtualThread about disabling JVMTI Suspend in a sync critical section.\n+\/\/ Needed to avoid deadlocks with JVMTI suspend mechanism.\n+JVM_ENTRY(void, JVM_VirtualThreadDisableSuspend(JNIEnv* env, jobject vthread, jboolean enter))\n+#if INCLUDE_JVMTI\n+  if (!DoJVMTIVirtualThreadTransitions) {\n+    assert(!JvmtiExport::can_support_virtual_threads(), \"sanity check\");\n+    return;\n+  }\n+  assert(thread->is_disable_suspend() != (bool)enter,\n+         \"nested or unbalanced monitor enter\/exit is not allowed\");\n+  thread->toggle_is_disable_suspend();\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":14,"deletions":10,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -526,1 +526,4 @@\n-  Copy::fill_to_memory_atomic(p, sz, value);\n+  {\n+    GuardUnsafeAccess guard(thread);\n+    Copy::fill_to_memory_atomic(p, sz, value);\n+  }\n","filename":"src\/hotspot\/share\/prims\/unsafe.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -319,1 +319,0 @@\n-  assert((strncmp(property, \"-D\", 2) != 0), \"Unexpected leading -D\");\n@@ -529,7 +528,1 @@\n-  { \"DoReserveCopyInSuperWord\",     JDK_Version::undefined(), JDK_Version::jdk(22), JDK_Version::jdk(23) },\n-  { \"UseCounterDecay\",              JDK_Version::undefined(), JDK_Version::jdk(22), JDK_Version::jdk(23) },\n-\n-#ifdef LINUX\n-  { \"UseHugeTLBFS\",                 JDK_Version::undefined(), JDK_Version::jdk(22), JDK_Version::jdk(23) },\n-  { \"UseSHM\",                       JDK_Version::undefined(), JDK_Version::jdk(22), JDK_Version::jdk(23) },\n-#endif\n+  { \"AdaptiveSizePolicyCollectionCostMargin\",   JDK_Version::undefined(), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n@@ -2298,4 +2291,0 @@\n-#if INCLUDE_CDS\n-      MetaspaceShared::disable_optimized_module_handling();\n-      log_info(cds)(\"optimized module handling: disabled because bootclasspath was appended\");\n-#endif\n@@ -2671,3 +2660,0 @@\n-    \/\/ -Xnoagent\n-    } else if (match_option(option, \"-Xnoagent\")) {\n-      warning(\"Option -Xnoagent was deprecated in JDK 22 and will likely be removed in a future release.\");\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":1,"deletions":15,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -1483,1 +1483,1 @@\n-      assert(stack_arg_slots ==  m->num_stack_arg_slots(), \"\");\n+      assert(stack_arg_slots ==  m->num_stack_arg_slots(false \/* rounded *\/), \"\");\n","filename":"src\/hotspot\/share\/runtime\/frame.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -93,0 +93,2 @@\n+  const ImmutableOopMap* get_oop_map() const;\n+\n","filename":"src\/hotspot\/share\/runtime\/frame.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -549,1 +549,2 @@\n-          \"Dump heap to file before any major stop-the-world GC\")           \\\n+          \"Dump heap to file before any major stop-the-world GC \"           \\\n+          \"(also see FullGCHeapDumpLimit)\")                                 \\\n@@ -552,1 +553,7 @@\n-          \"Dump heap to file after any major stop-the-world GC\")            \\\n+          \"Dump heap to file after any major stop-the-world GC \"            \\\n+          \"(also see FullGCHeapDumpLimit)\")                                 \\\n+                                                                            \\\n+  product(uint, FullGCHeapDumpLimit, 0, MANAGEABLE,                         \\\n+          \"Limit the number of heap dumps triggered by \"                    \\\n+          \"HeapDumpBeforeFullGC or HeapDumpAfterFullGC \"                    \\\n+          \"(0 means no limit)\")                                             \\\n@@ -891,3 +898,0 @@\n-  develop(bool, TraceICs, false,                                            \\\n-          \"Trace inline cache changes\")                                     \\\n-                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":9,"deletions":5,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -444,0 +444,1 @@\n+  _is_disable_suspend(false),\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -321,0 +321,1 @@\n+  bool                  _is_disable_suspend;             \/\/ JVMTI suspend is temporarily disabled; used on current thread only\n@@ -651,0 +652,3 @@\n+  bool is_disable_suspend() const                { return _is_disable_suspend; }\n+  void toggle_is_disable_suspend()               { _is_disable_suspend = !_is_disable_suspend; };\n+\n@@ -819,0 +823,1 @@\n+  static ByteSize is_disable_suspend_offset()        { return byte_offset_of(JavaThread, _is_disable_suspend); }\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2084,1 +2084,1 @@\n-  int comp_args_on_stack = java_calling_convention(sig_bt, regs_without_member_name, total_args_passed - 1);\n+  java_calling_convention(sig_bt, regs_without_member_name, total_args_passed - 1);\n@@ -3473,1 +3473,1 @@\n-      int comp_args_on_stack = SharedRuntime::java_calling_convention(sig_bt, regs, total_args_passed);\n+      SharedRuntime::java_calling_convention(sig_bt, regs, total_args_passed);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -183,1 +183,0 @@\n-  _stack_arg_slots = align_up(_stack_arg_slots, 2);\n@@ -240,1 +239,0 @@\n-#if defined(PPC64) || defined(S390)\n@@ -244,0 +242,4 @@\n+#if defined(PPC64) || defined(S390)\n+      _stack_arg_slots += 1;\n+#else\n+      _stack_arg_slots = align_up(_stack_arg_slots, 2);\n@@ -245,0 +247,1 @@\n+#endif \/\/ defined(PPC64) || defined(S390)\n@@ -247,1 +250,0 @@\n-#endif \/\/ defined(PPC64) || defined(S390)\n@@ -255,2 +257,1 @@\n-      PPC64_ONLY(_stack_arg_slots = align_up(_stack_arg_slots, 2));\n-      S390_ONLY(_stack_arg_slots = align_up(_stack_arg_slots, 2));\n+      _stack_arg_slots = align_up(_stack_arg_slots, 2);\n@@ -261,1 +262,0 @@\n-#if defined(PPC64) || defined(S390)\n@@ -265,0 +265,4 @@\n+#if defined(PPC64) || defined(S390)\n+      _stack_arg_slots += 1;\n+#else\n+      _stack_arg_slots = align_up(_stack_arg_slots, 2);\n@@ -266,0 +270,1 @@\n+#endif \/\/ defined(PPC64) || defined(S390)\n@@ -268,1 +273,0 @@\n-#endif \/\/ defined(PPC64) || defined(S390)\n@@ -273,2 +277,1 @@\n-      PPC64_ONLY(_stack_arg_slots = align_up(_stack_arg_slots, 2));\n-      S390_ONLY(_stack_arg_slots = align_up(_stack_arg_slots, 2));\n+      _stack_arg_slots = align_up(_stack_arg_slots, 2);\n","filename":"src\/hotspot\/share\/runtime\/signature.cpp","additions":12,"deletions":9,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -854,0 +854,7 @@\n+PerfMapDCmd::PerfMapDCmd(outputStream* output, bool heap) :\n+             DCmdWithParser(output, heap),\n+  _filename(\"filename\", \"Name of the map file\", \"STRING\", false)\n+{\n+  _dcmdparser.add_dcmd_argument(&_filename);\n+}\n+\n@@ -855,1 +862,1 @@\n-  CodeCache::write_perf_map();\n+  CodeCache::write_perf_map(_filename.value());\n","filename":"src\/hotspot\/share\/services\/diagnosticCommand.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -605,1 +605,3 @@\n-class PerfMapDCmd : public DCmd {\n+class PerfMapDCmd : public DCmdWithParser {\n+protected:\n+  DCmdArgument<char*> _filename;\n@@ -607,1 +609,2 @@\n-  PerfMapDCmd(outputStream* output, bool heap) : DCmd(output, heap) {}\n+  static int num_arguments() { return 1; }\n+  PerfMapDCmd(outputStream* output, bool heap);\n","filename":"src\/hotspot\/share\/services\/diagnosticCommand.hpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1977,0 +1977,19 @@\n+\/\/ Support class used to generate HPROF_GC_CLASS_DUMP records\n+\n+class ClassDumper : public KlassClosure {\n+ private:\n+  AbstractDumpWriter* _writer;\n+  AbstractDumpWriter* writer() const { return _writer; }\n+\n+ public:\n+  ClassDumper(AbstractDumpWriter* writer) : _writer(writer) {}\n+\n+  void do_klass(Klass* k) {\n+    if (k->is_instance_klass()) {\n+      DumperSupport::dump_instance_class(writer(), k);\n+    } else {\n+      DumperSupport::dump_array_class(writer(), k);\n+    }\n+  }\n+};\n+\n@@ -2126,0 +2145,13 @@\n+  static bool is_vthread_mounted(oop vt) {\n+    \/\/ The code should be consistent with the \"mounted virtual thread\" case\n+    \/\/ (VM_HeapDumper::dump_stack_traces(), ThreadDumper::get_top_frame()).\n+    \/\/ I.e. virtual thread is mounted if its carrierThread is not null\n+    \/\/ and is_vthread_mounted() for the carrier thread returns true.\n+    oop carrier_thread = java_lang_VirtualThread::carrier_thread(vt);\n+    if (carrier_thread == nullptr) {\n+      return false;\n+    }\n+    JavaThread* java_thread = java_lang_Thread::thread(carrier_thread);\n+    return java_thread->is_vthread_mounted();\n+  }\n+\n@@ -2364,0 +2396,6 @@\n+\/\/ Callback to dump thread-related data for unmounted virtual threads;\n+\/\/ implemented by VM_HeapDumper.\n+class UnmountedVThreadDumper {\n+ public:\n+  virtual void dump_vthread(oop vt, AbstractDumpWriter* segment_writer) = 0;\n+};\n@@ -2365,3 +2403,1 @@\n-class VM_HeapDumper;\n-\n-\/\/ Support class using when iterating over the heap.\n+\/\/ Support class used when iterating over the heap.\n@@ -2372,0 +2408,1 @@\n+  UnmountedVThreadDumper* _vthread_dumper;\n@@ -2376,3 +2413,2 @@\n-  HeapObjectDumper(AbstractDumpWriter* writer) {\n-    _writer = writer;\n-  }\n+  HeapObjectDumper(AbstractDumpWriter* writer, UnmountedVThreadDumper* vthread_dumper)\n+    : _writer(writer), _vthread_dumper(vthread_dumper) {}\n@@ -2399,0 +2435,6 @@\n+    \/\/ If we encounter an unmounted virtual thread it needs to be dumped explicitly\n+    \/\/ (mounted virtual threads are dumped with their carriers).\n+    if (java_lang_VirtualThread::is_instance(o)\n+        && ThreadDumper::should_dump_vthread(o) && !ThreadDumper::is_vthread_mounted(o)) {\n+      _vthread_dumper->dump_vthread(o, writer());\n+    }\n@@ -2414,0 +2456,2 @@\n+   Mutex* _global_writer_lock;\n+\n@@ -2417,0 +2461,2 @@\n+   bool   _started; \/\/ VM dumper started and acquired global writer lock\n+\n@@ -2419,1 +2465,6 @@\n-     _lock(new (std::nothrow) PaddedMonitor(Mutex::safepoint, \"DumperController_lock\")),\n+     \/\/ _lock and _global_writer_lock are used for synchronization between GC worker threads inside safepoint,\n+     \/\/ so we lock with _no_safepoint_check_flag.\n+     \/\/ signal_start() acquires _lock when global writer is locked,\n+     \/\/ its rank must be less than _global_writer_lock rank.\n+     _lock(new (std::nothrow) PaddedMonitor(Mutex::nosafepoint - 1, \"DumperController_lock\")),\n+     _global_writer_lock(new (std::nothrow) Mutex(Mutex::nosafepoint, \"DumpWriter_lock\")),\n@@ -2421,1 +2472,8 @@\n-     _complete_number(0) { }\n+     _complete_number(0),\n+     _started(false)\n+   {}\n+\n+   ~DumperController() {\n+     delete _lock;\n+     delete _global_writer_lock;\n+   }\n@@ -2423,1 +2481,21 @@\n-   ~DumperController() { delete _lock; }\n+   \/\/ parallel (non VM) dumpers must wait until VM dumper acquires global writer lock\n+   void wait_for_start_signal() {\n+     MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+     while (_started == false) {\n+       ml.wait();\n+     }\n+   }\n+\n+   void signal_start() {\n+     MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+     _started = true;\n+     ml.notify_all();\n+   }\n+\n+   void lock_global_writer() {\n+     _global_writer_lock->lock_without_safepoint_check();\n+   }\n+\n+   void unlock_global_writer() {\n+     _global_writer_lock->unlock();\n+   }\n@@ -2453,1 +2531,1 @@\n-  void merge_file(char* path);\n+  void merge_file(const char* path);\n@@ -2466,0 +2544,4 @@\n+\n+  \/\/ returns path for the parallel DumpWriter (resource allocated)\n+  static char* get_writer_path(const char* base_path, int seq);\n+\n@@ -2468,0 +2550,16 @@\n+char* DumpMerger::get_writer_path(const char* base_path, int seq) {\n+  \/\/ approximate required buffer size\n+  size_t buf_size = strlen(base_path)\n+                    + 2                 \/\/ \".p\"\n+                    + 10                \/\/ number (that's enough for 2^32 parallel dumpers)\n+                    + 1;                \/\/ '\\0'\n+\n+  char* path = NEW_RESOURCE_ARRAY(char, buf_size);\n+  memset(path, 0, buf_size);\n+\n+  os::snprintf(path, buf_size, \"%s.p%d\", base_path, seq);\n+\n+  return path;\n+}\n+\n+\n@@ -2490,2 +2588,1 @@\n-void DumpMerger::merge_file(char* path) {\n-  assert(!SafepointSynchronize::is_at_safepoint(), \"merging happens outside safepoint\");\n+void DumpMerger::merge_file(const char* path) {\n@@ -2528,2 +2625,1 @@\n-void DumpMerger::merge_file(char* path) {\n-  assert(!SafepointSynchronize::is_at_safepoint(), \"merging happens outside safepoint\");\n+void DumpMerger::merge_file(const char* path) {\n@@ -2554,1 +2650,0 @@\n-  assert(!SafepointSynchronize::is_at_safepoint(), \"merging happens outside safepoint\");\n@@ -2564,3 +2659,2 @@\n-  char path[JVM_MAXPATHLEN];\n-    memset(path, 0, JVM_MAXPATHLEN);\n-    os::snprintf(path, JVM_MAXPATHLEN, \"%s.p%d\", _path, i);\n+    ResourceMark rm;\n+    const char* path = get_writer_path(_path, i);\n@@ -2597,1 +2691,1 @@\n-class VM_HeapDumper : public VM_GC_Operation, public WorkerTask {\n+class VM_HeapDumper : public VM_GC_Operation, public WorkerTask, public UnmountedVThreadDumper {\n@@ -2621,2 +2715,3 @@\n-  \/\/ worker id of VMDumper thread.\n-  static const size_t VMDumperWorkerId = 0;\n+\n+  \/\/ Dumper id of VMDumper thread.\n+  static const int VMDumperId = 0;\n@@ -2624,1 +2719,5 @@\n-  static bool is_vm_dumper(uint worker_id) { return worker_id == VMDumperWorkerId; }\n+  static bool is_vm_dumper(int dumper_id) { return dumper_id == VMDumperId; }\n+  \/\/ the 1st dumper calling get_next_dumper_id becomes VM dumper\n+  int get_next_dumper_id() {\n+    return Atomic::fetch_then_add(&_dump_seq, 1);\n+  }\n@@ -2643,4 +2742,1 @@\n-  \/\/ create dump writer for every parallel dump thread\n-  DumpWriter* create_local_writer();\n-\n-  \/\/ writes a HPROF_LOAD_CLASS record\n+  \/\/ writes a HPROF_LOAD_CLASS record to global writer\n@@ -2649,4 +2745,1 @@\n-  \/\/ writes a HPROF_GC_CLASS_DUMP record for the given class\n-  static void do_class_dump(Klass* k);\n-\n-  void dump_threads();\n+  void dump_threads(AbstractDumpWriter* writer);\n@@ -2664,1 +2757,1 @@\n-  void dump_stack_traces();\n+  void dump_stack_traces(AbstractDumpWriter* writer);\n@@ -2682,1 +2775,1 @@\n-    _dump_seq = 0;\n+    _dump_seq = VMDumperId;\n@@ -2716,1 +2809,1 @@\n-  bool can_parallel_dump(WorkerThreads* workers);\n+  void prepare_parallel_dump(WorkerThreads* workers);\n@@ -2724,0 +2817,3 @@\n+\n+  \/\/ UnmountedVThreadDumper implementation\n+  void dump_vthread(oop vt, AbstractDumpWriter* segment_writer);\n@@ -2767,9 +2863,0 @@\n-\/\/ writes a HPROF_GC_CLASS_DUMP record for the given class\n-void VM_HeapDumper::do_class_dump(Klass* k) {\n-  if (k->is_instance_klass()) {\n-    DumperSupport::dump_instance_class(writer(), k);\n-  } else {\n-    DumperSupport::dump_array_class(writer(), k);\n-  }\n-}\n-\n@@ -2778,5 +2865,5 @@\n-void VM_HeapDumper::dump_threads() {\n-    for (int i = 0; i < _thread_dumpers_count; i++) {\n-        _thread_dumpers[i]->dump_thread_obj(writer());\n-        _thread_dumpers[i]->dump_stack_refs(writer());\n-    }\n+void VM_HeapDumper::dump_threads(AbstractDumpWriter* writer) {\n+  for (int i = 0; i < _thread_dumpers_count; i++) {\n+    _thread_dumpers[i]->dump_thread_obj(writer);\n+    _thread_dumpers[i]->dump_stack_refs(writer);\n+  }\n@@ -2796,2 +2883,1 @@\n-bool VM_HeapDumper::can_parallel_dump(WorkerThreads* workers) {\n-  bool can_parallel = true;\n+void VM_HeapDumper::prepare_parallel_dump(WorkerThreads* workers) {\n@@ -2803,10 +2889,1 @@\n-    can_parallel = false;\n-    \/\/ check if we have extra path room to accommodate segmented heap files\n-    const char* base_path = writer()->get_file_path();\n-    assert(base_path != nullptr, \"sanity check\");\n-    if ((strlen(base_path) + 7\/*.p\\d\\d\\d\\d\\0*\/) >= JVM_MAXPATHLEN) {\n-      _num_dumper_threads = 1;\n-      can_parallel = false;\n-    } else {\n-      _num_dumper_threads = clamp(num_requested_dump_threads, 2U, num_active_workers);\n-    }\n+    _num_dumper_threads = clamp(num_requested_dump_threads, 2U, num_active_workers);\n@@ -2815,1 +2892,2 @@\n-\n+  _dumper_controller = new (std::nothrow) DumperController(_num_dumper_threads);\n+  bool can_parallel = _num_dumper_threads > 1;\n@@ -2820,1 +2898,0 @@\n-  return can_parallel;\n@@ -2868,2 +2945,4 @@\n-  if (!can_parallel_dump(workers)) {\n-    work(VMDumperWorkerId);\n+  prepare_parallel_dump(workers);\n+\n+  if (!is_parallel_dump()) {\n+    work(VMDumperId);\n@@ -2871,2 +2950,0 @@\n-    uint heap_only_dumper_threads = _num_dumper_threads - 1 \/* VMDumper thread *\/;\n-    _dumper_controller = new (std::nothrow) DumperController(heap_only_dumper_threads);\n@@ -2884,17 +2961,0 @@\n-\/\/ prepare DumpWriter for every parallel dump thread\n-DumpWriter* VM_HeapDumper::create_local_writer() {\n-  char* path = NEW_RESOURCE_ARRAY(char, JVM_MAXPATHLEN);\n-  memset(path, 0, JVM_MAXPATHLEN);\n-\n-  \/\/ generate segmented heap file path\n-  const char* base_path = writer()->get_file_path();\n-  \/\/ share global compressor, local DumpWriter is not responsible for its life cycle\n-  AbstractCompressor* compressor = writer()->compressor();\n-  int seq = Atomic::fetch_then_add(&_dump_seq, 1);\n-  os::snprintf(path, JVM_MAXPATHLEN, \"%s.p%d\", base_path, seq);\n-\n-  \/\/ create corresponding writer for that\n-  DumpWriter* local_writer = new DumpWriter(path, writer()->is_overwrite(), compressor);\n-  return local_writer;\n-}\n-\n@@ -2903,1 +2963,11 @@\n-  if (is_vm_dumper(worker_id)) {\n+  int dumper_id = get_next_dumper_id();\n+\n+  if (is_vm_dumper(dumper_id)) {\n+    \/\/ lock global writer, it will be unlocked after VM Dumper finishes with non-heap data\n+    _dumper_controller->lock_global_writer();\n+    _dumper_controller->signal_start();\n+  } else {\n+    _dumper_controller->wait_for_start_signal();\n+  }\n+\n+  if (is_vm_dumper(dumper_id)) {\n@@ -2932,1 +3002,1 @@\n-    dump_stack_traces();\n+    dump_stack_traces(writer());\n@@ -2934,1 +3004,3 @@\n-    \/\/ HPROF_HEAP_DUMP\/HPROF_HEAP_DUMP_SEGMENT starts here\n+    \/\/ unlock global writer, so parallel dumpers can dump stack traces of unmounted virtual threads\n+    _dumper_controller->unlock_global_writer();\n+  }\n@@ -2936,55 +3008,42 @@\n-    \/\/ Writes HPROF_GC_CLASS_DUMP records\n-    {\n-      LockedClassesDo locked_dump_class(&do_class_dump);\n-      ClassLoaderDataGraph::classes_do(&locked_dump_class);\n-    }\n-\n-    \/\/ HPROF_GC_ROOT_THREAD_OBJ + frames + jni locals\n-    dump_threads();\n-\n-    \/\/ HPROF_GC_ROOT_JNI_GLOBAL\n-    JNIGlobalsDumper jni_dumper(writer());\n-    JNIHandles::oops_do(&jni_dumper);\n-    \/\/ technically not jni roots, but global roots\n-    \/\/ for things like preallocated throwable backtraces\n-    Universe::vm_global()->oops_do(&jni_dumper);\n-    \/\/ HPROF_GC_ROOT_STICKY_CLASS\n-    \/\/ These should be classes in the null class loader data, and not all classes\n-    \/\/ if !ClassUnloading\n-    StickyClassDumper class_dumper(writer());\n-    ClassLoaderData::the_null_class_loader_data()->classes_do(&class_dumper);\n-  }\n-\n-  \/\/ Heap iteration.\n-  \/\/ writes HPROF_GC_INSTANCE_DUMP records.\n-  \/\/ After each sub-record is written check_segment_length will be invoked\n-  \/\/ to check if the current segment exceeds a threshold. If so, a new\n-  \/\/ segment is started.\n-  \/\/ The HPROF_GC_CLASS_DUMP and HPROF_GC_INSTANCE_DUMP are the vast bulk\n-  \/\/ of the heap dump.\n-  if (!is_parallel_dump()) {\n-    assert(is_vm_dumper(worker_id), \"must be\");\n-    \/\/ == Serial dump\n-    ResourceMark rm;\n-    TraceTime timer(\"Dump heap objects\", TRACETIME_LOG(Info, heapdump));\n-    HeapObjectDumper obj_dumper(writer());\n-    Universe::heap()->object_iterate(&obj_dumper);\n-    writer()->finish_dump_segment();\n-    \/\/ Writes the HPROF_HEAP_DUMP_END record because merge does not happen in serial dump\n-    DumperSupport::end_of_dump(writer());\n-    inlined_objects()->dump_flat_arrays(writer());\n-    writer()->flush();\n-    inlined_objects()->release();\n-  } else {\n-    \/\/ == Parallel dump\n-    ResourceMark rm;\n-    TraceTime timer(\"Dump heap objects in parallel\", TRACETIME_LOG(Info, heapdump));\n-    DumpWriter* local_writer = is_vm_dumper(worker_id) ? writer() : create_local_writer();\n-    if (!local_writer->has_error()) {\n-      HeapObjectDumper obj_dumper(local_writer);\n-      _poi->object_iterate(&obj_dumper, worker_id);\n-      local_writer->finish_dump_segment();\n-      local_writer->flush();\n-    }\n-    if (is_vm_dumper(worker_id)) {\n-      _dumper_controller->wait_all_dumpers_complete();\n+  \/\/ HPROF_HEAP_DUMP\/HPROF_HEAP_DUMP_SEGMENT starts here\n+\n+  ResourceMark rm;\n+  \/\/ share global compressor, local DumpWriter is not responsible for its life cycle\n+  DumpWriter segment_writer(DumpMerger::get_writer_path(writer()->get_file_path(), dumper_id),\n+                            writer()->is_overwrite(), writer()->compressor());\n+  if (!segment_writer.has_error()) {\n+    if (is_vm_dumper(dumper_id)) {\n+      \/\/ dump some non-heap subrecords to heap dump segment\n+      TraceTime timer(\"Dump non-objects (part 2)\", TRACETIME_LOG(Info, heapdump));\n+      \/\/ Writes HPROF_GC_CLASS_DUMP records\n+      ClassDumper class_dumper(&segment_writer);\n+      ClassLoaderDataGraph::classes_do(&class_dumper);\n+\n+      \/\/ HPROF_GC_ROOT_THREAD_OBJ + frames + jni locals\n+      dump_threads(&segment_writer);\n+\n+      \/\/ HPROF_GC_ROOT_JNI_GLOBAL\n+      JNIGlobalsDumper jni_dumper(&segment_writer);\n+      JNIHandles::oops_do(&jni_dumper);\n+      \/\/ technically not jni roots, but global roots\n+      \/\/ for things like preallocated throwable backtraces\n+      Universe::vm_global()->oops_do(&jni_dumper);\n+      \/\/ HPROF_GC_ROOT_STICKY_CLASS\n+      \/\/ These should be classes in the null class loader data, and not all classes\n+      \/\/ if !ClassUnloading\n+      StickyClassDumper stiky_class_dumper(&segment_writer);\n+      ClassLoaderData::the_null_class_loader_data()->classes_do(&stiky_class_dumper);\n+    }\n+\n+    \/\/ Heap iteration.\n+    \/\/ writes HPROF_GC_INSTANCE_DUMP records.\n+    \/\/ After each sub-record is written check_segment_length will be invoked\n+    \/\/ to check if the current segment exceeds a threshold. If so, a new\n+    \/\/ segment is started.\n+    \/\/ The HPROF_GC_CLASS_DUMP and HPROF_GC_INSTANCE_DUMP are the vast bulk\n+    \/\/ of the heap dump.\n+\n+    TraceTime timer(is_parallel_dump() ? \"Dump heap objects in parallel\" : \"Dump heap objects\", TRACETIME_LOG(Info, heapdump));\n+    HeapObjectDumper obj_dumper(&segment_writer, this);\n+    if (!is_parallel_dump()) {\n+      Universe::heap()->object_iterate(&obj_dumper);\n@@ -2992,3 +3051,2 @@\n-      _dumper_controller->dumper_complete(local_writer, writer());\n-      delete local_writer;\n-      return;\n+      \/\/ == Parallel dump\n+      _poi->object_iterate(&obj_dumper, worker_id);\n@@ -2996,0 +3054,15 @@\n+\n+    segment_writer.finish_dump_segment();\n+    segment_writer.flush();\n+  }\n+\n+  _dumper_controller->dumper_complete(&segment_writer, writer());\n+\n+  if (is_vm_dumper(dumper_id)) {\n+    _dumper_controller->wait_all_dumpers_complete();\n+\n+    \/\/ flush global writer\n+    writer()->flush();\n+\n+    \/\/ At this point, all fragments of the heapdump have been written to separate files.\n+    \/\/ We need to merge them into a complete heapdump and write HPROF_HEAP_DUMP_END at that time.\n@@ -2997,2 +3070,0 @@\n-  \/\/ At this point, all fragments of the heapdump have been written to separate files.\n-  \/\/ We need to merge them into a complete heapdump and write HPROF_HEAP_DUMP_END at that time.\n@@ -3001,1 +3072,1 @@\n-void VM_HeapDumper::dump_stack_traces() {\n+void VM_HeapDumper::dump_stack_traces(AbstractDumpWriter* writer) {\n@@ -3003,4 +3074,4 @@\n-  DumperSupport::write_header(writer(), HPROF_TRACE, 3 * sizeof(u4));\n-  writer()->write_u4((u4)STACK_TRACE_ID);\n-  writer()->write_u4(0);                    \/\/ thread number\n-  writer()->write_u4(0);                    \/\/ frame count\n+  DumperSupport::write_header(writer, HPROF_TRACE, 3 * sizeof(u4));\n+  writer->write_u4((u4)STACK_TRACE_ID);\n+  writer->write_u4(0);                    \/\/ thread number\n+  writer->write_u4(0);                    \/\/ frame count\n@@ -3030,1 +3101,1 @@\n-        thread_dumper->dump_stack_traces(writer(), _klass_map);\n+        thread_dumper->dump_stack_traces(writer, _klass_map);\n@@ -3040,1 +3111,1 @@\n-      thread_dumper->dump_stack_traces(writer(), _klass_map);\n+      thread_dumper->dump_stack_traces(writer, _klass_map);\n@@ -3045,0 +3116,16 @@\n+void VM_HeapDumper::dump_vthread(oop vt, AbstractDumpWriter* segment_writer) {\n+  \/\/ unmounted vthread has no JavaThread\n+  ThreadDumper thread_dumper(ThreadDumper::ThreadType::UnmountedVirtual, nullptr, vt);\n+  thread_dumper.init_serial_nums(&_thread_serial_num, &_frame_serial_num);\n+\n+  \/\/ write HPROF_TRACE\/HPROF_FRAME records to global writer\n+  _dumper_controller->lock_global_writer();\n+  thread_dumper.dump_stack_traces(writer(), _klass_map);\n+  _dumper_controller->unlock_global_writer();\n+\n+  \/\/ write HPROF_GC_ROOT_THREAD_OBJ\/HPROF_GC_ROOT_JAVA_FRAME\/HPROF_GC_ROOT_JNI_LOCAL subrecord\n+  \/\/ to segment writer\n+  thread_dumper.dump_thread_obj(segment_writer);\n+  thread_dumper.dump_stack_refs(segment_writer);\n+}\n+\n@@ -3086,3 +3173,1 @@\n-  \/\/ For serial dump, once VM_HeapDumper completes, the whole heap dump process\n-  \/\/ is done, no further phases needed. For parallel dump, the whole heap dump\n-  \/\/ process is done in two phases\n+  \/\/ Heap dump process is done in two phases\n@@ -3095,13 +3180,14 @@\n-  if (dumper.is_parallel_dump()) {\n-    DumpMerger merger(path, &writer, dumper.inlined_objects(), dumper.dump_seq());\n-    Thread* current_thread = Thread::current();\n-    if (current_thread->is_AttachListener_thread()) {\n-      \/\/ perform heapdump file merge operation in the current thread prevents us\n-      \/\/ from occupying the VM Thread, which in turn affects the occurrence of\n-      \/\/ GC and other VM operations.\n-      merger.do_merge();\n-    } else {\n-      \/\/ otherwise, performs it by VM thread\n-      VM_HeapDumpMerge op(&merger);\n-      VMThread::execute(&op);\n-    }\n+\n+  DumpMerger merger(path, &writer, dumper.inlined_objects(), dumper.dump_seq());\n+  Thread* current_thread = Thread::current();\n+  if (current_thread->is_AttachListener_thread()) {\n+    \/\/ perform heapdump file merge operation in the current thread prevents us\n+    \/\/ from occupying the VM Thread, which in turn affects the occurrence of\n+    \/\/ GC and other VM operations.\n+    merger.do_merge();\n+  } else {\n+    \/\/ otherwise, performs it by VM thread\n+    VM_HeapDumpMerge op(&merger);\n+    VMThread::execute(&op);\n+  }\n+  if (writer.error() != nullptr) {\n","filename":"src\/hotspot\/share\/services\/heapDumper.cpp","additions":254,"deletions":168,"binary":false,"changes":422,"status":"modified"},{"patch":"@@ -605,1 +605,1 @@\n-\/\/ The expected size in bytes of a cache line, used to pad data structures.\n+\/\/ The expected size in bytes of a cache line.\n@@ -610,0 +610,5 @@\n+\/\/ The default padding size for data structures to avoid false sharing.\n+#ifndef DEFAULT_PADDING_SIZE\n+#error \"Platform should define DEFAULT_PADDING_SIZE\"\n+#endif\n+\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -265,1 +265,2 @@\n-     * information about modifiers and type parameters.\n+     * information about modifiers, {@link #isSealed() sealed}\/{@code\n+     * non-sealed} status, and type parameters.\n@@ -320,0 +321,5 @@\n+                \/\/ A class cannot be strictfp and sealed\/non-sealed so\n+                \/\/ it is sufficient to check for sealed-ness after all\n+                \/\/ modifiers are printed.\n+                addSealingInfo(modifiers, sb);\n+\n@@ -353,0 +359,43 @@\n+    private void addSealingInfo(int modifiers, StringBuilder sb) {\n+        \/\/ A class can be final XOR sealed XOR non-sealed.\n+        if (Modifier.isFinal(modifiers)) {\n+            return; \/\/ no-op\n+        } else {\n+            if (isSealed()) {\n+                sb.append(\"sealed \");\n+                return;\n+            } else {\n+                \/\/ Check for sealed ancestor, which implies this class\n+                \/\/ is non-sealed.\n+                if (hasSealedAncestor(this)) {\n+                    sb.append(\"non-sealed \");\n+                }\n+            }\n+        }\n+    }\n+\n+    private boolean hasSealedAncestor(Class<?> clazz) {\n+        \/\/ From JLS 8.1.1.2:\n+        \/\/ \"It is a compile-time error if a class has a sealed direct\n+        \/\/ superclass or a sealed direct superinterface, and is not\n+        \/\/ declared final, sealed, or non-sealed either explicitly or\n+        \/\/ implicitly.\n+        \/\/ Thus, an effect of the sealed keyword is to force all\n+        \/\/ direct subclasses to explicitly declare whether they are\n+        \/\/ final, sealed, or non-sealed. This avoids accidentally\n+        \/\/ exposing a sealed class hierarchy to unwanted subclassing.\"\n+\n+        \/\/ Therefore, will just check direct superclass and\n+        \/\/ superinterfaces.\n+        var superclass = clazz.getSuperclass();\n+        if (superclass != null && superclass.isSealed()) {\n+            return true;\n+        }\n+        for (var superinterface : clazz.getInterfaces()) {\n+            if (superinterface.isSealed()) {\n+                return true;\n+            }\n+        }\n+        return false;\n+    }\n+\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Class.java","additions":50,"deletions":1,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1994, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1994, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -61,0 +61,1 @@\n+import java.util.Locale;\n@@ -817,0 +818,4 @@\n+     * <p>\n+     * Additional locale-related system properties defined by the\n+     * {@link Locale##default_locale Default Locale} section in the {@code Locale}\n+     * class description may also be obtained with this method.\n@@ -2378,1 +2383,1 @@\n-                Thread.blockedOn(b);\n+                Thread.currentThread().blockedOn(b);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/System.java","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1844,1 +1844,1 @@\n-         * @see Lookup#privateLookupIn\n+         * @see MethodHandles#privateLookupIn\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/MethodHandles.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+import java.util.ArrayList;\n@@ -1313,1 +1314,1 @@\n-        public List<Symbol> permitted;\n+        private java.util.List<PermittedClassWithPos> permitted;\n@@ -1317,0 +1318,2 @@\n+        private record PermittedClassWithPos(Symbol permittedClass, int pos) {}\n+\n@@ -1325,1 +1328,1 @@\n-            this.permitted = List.nil();\n+            this.permitted = new ArrayList<>();\n@@ -1337,0 +1340,31 @@\n+        public void addPermittedSubclass(ClassSymbol csym, int pos) {\n+            Assert.check(!isPermittedExplicit);\n+            \/\/ we need to insert at the right pos\n+            PermittedClassWithPos element = new PermittedClassWithPos(csym, pos);\n+            int index = Collections.binarySearch(permitted, element, java.util.Comparator.comparing(PermittedClassWithPos::pos));\n+            if (index < 0) {\n+                index = -index - 1;\n+            }\n+            permitted.add(index, element);\n+        }\n+\n+        public boolean isPermittedSubclass(Symbol csym) {\n+            for (PermittedClassWithPos permittedClassWithPos : permitted) {\n+                if (permittedClassWithPos.permittedClass.equals(csym)) {\n+                    return true;\n+                }\n+            }\n+            return false;\n+        }\n+\n+        public void clearPermittedSubclasses() {\n+            permitted.clear();\n+        }\n+\n+        public void setPermittedSubclasses(List<Symbol> permittedSubs) {\n+            permitted.clear();\n+            for (Symbol csym : permittedSubs) {\n+                permitted.add(new PermittedClassWithPos(csym, 0));\n+            }\n+        }\n+\n@@ -1653,1 +1687,1 @@\n-            return permitted.map(s -> s.type);\n+            return permitted.stream().map(s -> s.permittedClass().type).collect(List.collector());\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Symbol.java","additions":37,"deletions":3,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -1712,1 +1712,1 @@\n-                    return sealedOne.permitted.stream().allMatch(sym -> areDisjoint((ClassSymbol)sym, other));\n+                    return sealedOne.getPermittedSubclasses().stream().allMatch(type -> areDisjoint((ClassSymbol)type.tsym, other));\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Types.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -5407,1 +5407,1 @@\n-                        c.permitted.isEmpty()) {\n+                        c.getPermittedSubclasses().isEmpty()) {\n@@ -5414,1 +5414,1 @@\n-                    for (Symbol subTypeSym : c.permitted) {\n+                    for (Type subType : c.getPermittedSubclasses()) {\n@@ -5416,1 +5416,1 @@\n-                        if (subTypeSym.type.getTag() == TYPEVAR) {\n+                        if (subType.getTag() == TYPEVAR) {\n@@ -5418,2 +5418,2 @@\n-                            log.error(TreeInfo.diagnosticPositionFor(subTypeSym, env.tree),\n-                                    Errors.InvalidPermitsClause(Fragments.IsATypeVariable(subTypeSym.type)));\n+                            log.error(TreeInfo.diagnosticPositionFor(subType.tsym, env.tree),\n+                                    Errors.InvalidPermitsClause(Fragments.IsATypeVariable(subType)));\n@@ -5421,2 +5421,2 @@\n-                        if (subTypeSym.isAnonymous() && !c.isEnum()) {\n-                            log.error(TreeInfo.diagnosticPositionFor(subTypeSym, env.tree),  Errors.LocalClassesCantExtendSealed(Fragments.Anonymous));\n+                        if (subType.tsym.isAnonymous() && !c.isEnum()) {\n+                            log.error(TreeInfo.diagnosticPositionFor(subType.tsym, env.tree),  Errors.LocalClassesCantExtendSealed(Fragments.Anonymous));\n@@ -5424,1 +5424,1 @@\n-                        if (permittedTypes.contains(subTypeSym)) {\n+                        if (permittedTypes.contains(subType.tsym)) {\n@@ -5427,1 +5427,1 @@\n-                                            .filter(permittedExpr -> TreeInfo.diagnosticPositionFor(subTypeSym, permittedExpr, true) != null)\n+                                            .filter(permittedExpr -> TreeInfo.diagnosticPositionFor(subType.tsym, permittedExpr, true) != null)\n@@ -5429,1 +5429,1 @@\n-                            log.error(pos, Errors.InvalidPermitsClause(Fragments.IsDuplicated(subTypeSym.type)));\n+                            log.error(pos, Errors.InvalidPermitsClause(Fragments.IsDuplicated(subType)));\n@@ -5431,1 +5431,1 @@\n-                            permittedTypes.add(subTypeSym);\n+                            permittedTypes.add(subType.tsym);\n@@ -5434,2 +5434,2 @@\n-                            if (subTypeSym.packge() != c.packge()) {\n-                                log.error(TreeInfo.diagnosticPositionFor(subTypeSym, env.tree),\n+                            if (subType.tsym.packge() != c.packge()) {\n+                                log.error(TreeInfo.diagnosticPositionFor(subType.tsym, env.tree),\n@@ -5439,2 +5439,2 @@\n-                        } else if (subTypeSym.packge().modle != c.packge().modle) {\n-                            log.error(TreeInfo.diagnosticPositionFor(subTypeSym, env.tree),\n+                        } else if (subType.tsym.packge().modle != c.packge().modle) {\n+                            log.error(TreeInfo.diagnosticPositionFor(subType.tsym, env.tree),\n@@ -5444,2 +5444,2 @@\n-                        if (subTypeSym == c.type.tsym || types.isSuperType(subTypeSym.type, c.type)) {\n-                            log.error(TreeInfo.diagnosticPositionFor(subTypeSym, ((JCClassDecl)env.tree).permitting),\n+                        if (subType.tsym == c.type.tsym || types.isSuperType(subType, c.type)) {\n+                            log.error(TreeInfo.diagnosticPositionFor(subType.tsym, ((JCClassDecl)env.tree).permitting),\n@@ -5447,1 +5447,1 @@\n-                                            subTypeSym == c.type.tsym ?\n+                                            subType.tsym == c.type.tsym ?\n@@ -5449,1 +5449,1 @@\n-                                                    Fragments.MustNotBeSupertype(subTypeSym.type)\n+                                                    Fragments.MustNotBeSupertype(subType)\n@@ -5453,1 +5453,1 @@\n-                            boolean thisIsASuper = types.directSupertypes(subTypeSym.type)\n+                            boolean thisIsASuper = types.directSupertypes(subType)\n@@ -5457,2 +5457,2 @@\n-                                log.error(TreeInfo.diagnosticPositionFor(subTypeSym, env.tree),\n-                                        Errors.InvalidPermitsClause(Fragments.DoesntExtendSealed(subTypeSym.type)));\n+                                log.error(TreeInfo.diagnosticPositionFor(subType.tsym, env.tree),\n+                                        Errors.InvalidPermitsClause(Fragments.DoesntExtendSealed(subType)));\n@@ -5493,1 +5493,1 @@\n-                            if (!supertypeSym.permitted.contains(c.type.tsym)) {\n+                            if (!supertypeSym.isPermittedSubclass(c.type.tsym)) {\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Attr.java","additions":23,"deletions":23,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -813,0 +813,4 @@\n+        if (tree.type.isErroneous()) {\n+            \/\/error recovery - ignore erroneous member references\n+            return ;\n+        }\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/ThisEscapeAnalyzer.java","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -921,1 +921,1 @@\n-                            supClass.permitted = supClass.permitted.append(sym);\n+                            supClass.addPermittedSubclass(sym, tree.pos);\n@@ -934,1 +934,1 @@\n-                sym.permitted = permittedSubtypeSymbols.toList();\n+                sym.setPermittedSubclasses(permittedSubtypeSymbols.toList());\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/TypeEnter.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1313,1 +1313,1 @@\n-                        ((ClassSymbol)sym).permitted = subtypes.toList();\n+                        ((ClassSymbol)sym).setPermittedSubclasses(subtypes.toList());\n@@ -2817,1 +2817,1 @@\n-        if (parameterNameIndicesMp != null\n+        if (parameterNameIndicesMp != null && mpIndex < parameterNameIndicesMp.length\n@@ -2945,1 +2945,1 @@\n-        if (c.permitted != null && !c.permitted.isEmpty()) {\n+        if (!c.getPermittedSubclasses().isEmpty()) {\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/jvm\/ClassReader.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -936,1 +936,1 @@\n-        if (csym.permitted.nonEmpty()) {\n+        if (csym.getPermittedSubclasses().nonEmpty()) {\n@@ -938,3 +938,3 @@\n-            databuf.appendChar(csym.permitted.size());\n-            for (Symbol c : csym.permitted) {\n-                databuf.appendChar(poolWriter.putClass((ClassSymbol) c));\n+            databuf.appendChar(csym.getPermittedSubclasses().size());\n+            for (Type t : csym.getPermittedSubclasses()) {\n+                databuf.appendChar(poolWriter.putClass((ClassSymbol) t.tsym));\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/jvm\/ClassWriter.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -981,0 +981,14 @@\n+    protected JCExpression parseIntersectionType(int pos, JCExpression firstType) {\n+        JCExpression t = firstType;\n+        int pos1 = pos;\n+        List<JCExpression> targets = List.of(t);\n+        while (token.kind == AMP) {\n+            accept(AMP);\n+            targets = targets.prepend(parseType());\n+        }\n+        if (targets.length() > 1) {\n+            t = toP(F.at(pos1).TypeIntersection(targets.reverse()));\n+        }\n+        return t;\n+    }\n+\n@@ -1351,9 +1365,1 @@\n-                       int pos1 = pos;\n-                       List<JCExpression> targets = List.of(t = parseType());\n-                       while (token.kind == AMP) {\n-                           accept(AMP);\n-                           targets = targets.prepend(parseType());\n-                       }\n-                       if (targets.length() > 1) {\n-                           t = toP(F.at(pos1).TypeIntersection(targets.reverse()));\n-                       }\n+                       t = parseIntersectionType(pos, parseType());\n@@ -2875,0 +2881,1 @@\n+                    case BYTE, CHAR, SHORT, INT, LONG, FLOAT, DOUBLE, VOID, BOOLEAN:\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/parser\/JavacParser.java","additions":16,"deletions":9,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -1646,1 +1646,1 @@\n-                    node.sym.permitted = List.nil();\n+                    node.sym.clearPermittedSubclasses();\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/processing\/JavacProcessingEnvironment.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -1075,17 +1075,0 @@\n-void\n-debugMonitorTimedWait(jrawMonitorID monitor, jlong millis)\n-{\n-    jvmtiError error;\n-    error = JVMTI_FUNC_PTR(gdata->jvmti,RawMonitorWait)\n-        (gdata->jvmti, monitor, millis);\n-    if (error == JVMTI_ERROR_INTERRUPT) {\n-        \/* See comment above *\/\n-        handleInterrupt();\n-        error = JVMTI_ERROR_NONE;\n-    }\n-    error = ignore_vm_death(error);\n-    if (error != JVMTI_ERROR_NONE) {\n-        EXIT_ERROR(error, \"on raw monitor timed wait\");\n-    }\n-}\n-\n","filename":"src\/jdk.jdwp.agent\/share\/native\/libjdwp\/util.c","additions":1,"deletions":18,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -75,2 +75,0 @@\n-compiler\/codecache\/CheckLargePages.java 8319795 linux-x64\n-\n@@ -88,0 +86,5 @@\n+gc\/TestAllocHumongousFragment.java#adaptive 8298781 generic-all\n+gc\/TestAllocHumongousFragment.java#aggressive 8298781 generic-all\n+gc\/TestAllocHumongousFragment.java#iu-aggressive 8298781 generic-all\n+gc\/TestAllocHumongousFragment.java#g1 8298781 generic-all\n+gc\/TestAllocHumongousFragment.java#static 8298781 generic-all\n@@ -89,3 +92,0 @@\n-gc\/stress\/gclocker\/TestGCLockerWithParallel.java 8180622 generic-all\n-gc\/stress\/gclocker\/TestGCLockerWithSerial.java 8180622 generic-all\n-gc\/stress\/gclocker\/TestGCLockerWithShenandoah.java 8180622 generic-all\n@@ -108,0 +108,1 @@\n+runtime\/CompressedOops\/CompressedClassPointers.java 8322943 aix-ppc64\n@@ -118,1 +119,0 @@\n-runtime\/CompressedOops\/CompressedClassPointers.java 8317610 linux-x64,windows-x64\n@@ -144,1 +144,1 @@\n-serviceability\/attach\/ConcAttachTest.java 8290043,8318866 linux-all,macosx-all\n+serviceability\/attach\/ConcAttachTest.java 8290043 linux-all\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -375,1 +375,0 @@\n-  gc\/stress\/gclocker\/TestGCLockerWithShenandoah.java \\\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -301,0 +301,5 @@\n+    public static final String OR = PREFIX + \"OR\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(OR, \"Or(I|L)\");\n+    }\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/IRNode.java","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -138,0 +138,1 @@\n+                    \"AlignVector\",\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/TestFramework.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -105,1 +105,1 @@\n-            OutputAnalyzer oa = ProcessTools.executeTestJvm(arg);\n+            OutputAnalyzer oa = ProcessTools.executeTestJava(arg);\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestArrayAccessDeopt.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1904,1 +1904,1 @@\n-                OutputAnalyzer oa = ProcessTools.executeTestJvm(cmds);\n+                OutputAnalyzer oa = ProcessTools.executeTestJava(cmds);\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestNewAcmp.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -56,1 +56,1 @@\n-            OutputAnalyzer oa = ProcessTools.executeTestJvm(arg);\n+            OutputAnalyzer oa = ProcessTools.executeTestJava(arg);\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestUnresolvedInlineClass.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3,1 +3,1 @@\n-# Copyright (c) 2009, 2023, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2009, 2024, Oracle and\/or its affiliates. All rights reserved.\n","filename":"test\/jdk\/ProblemList.txt","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -26,1 +26,1 @@\n- * @bug 6298888 6992705 8161500 6304578\n+ * @bug 6298888 6992705 8161500 6304578 8322878\n@@ -28,1 +28,0 @@\n- * @author Joseph D. Darcy\n@@ -43,0 +42,2 @@\n+    private static record PlatformTestCase(Class<?> clazz, String expected) {}\n+\n@@ -49,13 +50,27 @@\n-        Map<Class<?>, String> testCases =\n-            Map.of(int.class,                          \"int\",\n-                   void.class,                         \"void\",\n-                   args.getClass(),                    \"java.lang.String[]\",\n-                   nested.getClass(),                  \"java.lang.String[][]\",\n-                   intArray.getClass(),                \"int[][]\",\n-                   java.lang.Enum.class,               \"public abstract class java.lang.Enum<E extends java.lang.Enum<E>>\",\n-                   java.util.Map.class,                \"public abstract interface java.util.Map<K,V>\",\n-                   java.util.EnumMap.class,            \"public class java.util.EnumMap<K extends java.lang.Enum<K>,V>\",\n-                   java.util.EventListenerProxy.class, \"public abstract class java.util.EventListenerProxy<T extends java.util.EventListener>\");\n-\n-        for (Map.Entry<Class<?>, String> testCase : testCases.entrySet()) {\n-            failures += checkToGenericString(testCase.getKey(), testCase.getValue());\n+       List<PlatformTestCase> platformTestCases =\n+           List.of(new PlatformTestCase(int.class,           \"int\"),\n+                   new PlatformTestCase(void.class,          \"void\"),\n+                   new PlatformTestCase(args.getClass(),     \"java.lang.String[]\"),\n+                   new PlatformTestCase(nested.getClass(),   \"java.lang.String[][]\"),\n+                   new PlatformTestCase(intArray.getClass(), \"int[][]\"),\n+\n+                   new PlatformTestCase(java.lang.Enum.class,\n+                                        \"public abstract class java.lang.Enum<E extends java.lang.Enum<E>>\"),\n+                   new PlatformTestCase(java.util.Map.class,\n+                                        \"public abstract interface java.util.Map<K,V>\"),\n+                   new PlatformTestCase(java.util.EnumMap.class,\n+                                        \"public class java.util.EnumMap<K extends java.lang.Enum<K>,V>\"),\n+                   new PlatformTestCase(java.util.EventListenerProxy.class,\n+                                        \"public abstract class java.util.EventListenerProxy<T extends java.util.EventListener>\"),\n+\n+                   \/\/ Sealed class\n+                   new PlatformTestCase(java.lang.ref.Reference.class,\n+                                     \"public abstract sealed class java.lang.ref.Reference<T>\"),\n+                   \/\/ non-sealed class\n+                   new PlatformTestCase(java.lang.ref.WeakReference.class,\n+                                     \"public non-sealed class java.lang.ref.WeakReference<T>\")\n+                   );\n+\n+        for (PlatformTestCase platformTestCase : platformTestCases) {\n+            failures += checkToGenericString(platformTestCase.clazz,\n+                                             platformTestCase.expected);\n@@ -77,1 +92,27 @@\n-                                     AValueClass.class)) {\n+                                     AValueClass.class,\n+\n+                                     SealedRootClass.class,\n+                                     SealedRootClass.ChildA.class,\n+                                     SealedRootClass.ChildB.class,\n+                                     SealedRootClass.ChildB.GrandChildAB.class,\n+                                     SealedRootClass.ChildC.class,\n+                                     SealedRootClass.ChildC.GrandChildACA.class,\n+                                     SealedRootClass.ChildC.GrandChildACB.class,\n+                                     SealedRootClass.ChildC.GrandChildACC.class,\n+                                     SealedRootClass.ChildC.GrandChildACC.GreatGrandChildACCA.class,\n+                                     SealedRootClass.ChildC.GrandChildACC.GreatGrandChildACCB.class,\n+\n+                                     SealedRootIntf.class,\n+                                     SealedRootIntf.ChildA.class,\n+                                     SealedRootIntf.ChildB.class,\n+                                     SealedRootIntf.ChildB.GrandChildAB.class,\n+                                     SealedRootIntf.ChildC.class,\n+                                     SealedRootIntf.ChildC.GrandChildACA.class,\n+                                     SealedRootIntf.ChildC.GrandChildACB.class,\n+                                     SealedRootIntf.ChildC.GrandChildACC.class,\n+                                     SealedRootIntf.ChildC.GrandChildACC.GreatGrandChildACCA.class,\n+                                     SealedRootIntf.ChildC.GrandChildACC.GreatGrandChildACCB.class,\n+                                     SealedRootIntf.IntfA.class,\n+                                     SealedRootIntf.IntfA.IntfAImpl.class,\n+                                     SealedRootIntf.IntfB.class,\n+                                     SealedRootIntf.IntfB.IntfAImpl.class)) {\n@@ -114,1 +155,4 @@\n-@ExpectedGenericString(\"enum AnotherEnum\")\n+\/\/ If an enum class has a specialized enum constant, that is compiled\n+\/\/ by having the enum class as being sealed rather than final. See JLS\n+\/\/ 8.9 Enum Classes.\n+@ExpectedGenericString(\"sealed enum AnotherEnum\")\n@@ -121,0 +165,92 @@\n+\n+\/\/ Test cases for sealed\/non-sealed _class_ hierarchy.\n+@ExpectedGenericString(\"sealed class SealedRootClass\")\n+sealed class SealedRootClass\n+    permits\n+    SealedRootClass.ChildA,\n+    SealedRootClass.ChildB,\n+    SealedRootClass.ChildC {\n+\n+    @ExpectedGenericString(\"final class SealedRootClass$ChildA\")\n+    final class ChildA extends SealedRootClass {}\n+\n+    @ExpectedGenericString(\"sealed class SealedRootClass$ChildB\")\n+    sealed class ChildB extends SealedRootClass permits SealedRootClass.ChildB.GrandChildAB {\n+        @ExpectedGenericString(\"final class SealedRootClass$ChildB$GrandChildAB\")\n+        final class GrandChildAB extends ChildB {}\n+    }\n+\n+    @ExpectedGenericString(\"non-sealed class SealedRootClass$ChildC\")\n+    non-sealed class ChildC extends SealedRootClass {\n+        \/\/ The subclasses of ChildC do not themselves have to be\n+        \/\/ sealed, non-sealed, or final.\n+        @ExpectedGenericString(\"class SealedRootClass$ChildC$GrandChildACA\")\n+        class GrandChildACA extends ChildC {}\n+\n+        @ExpectedGenericString(\"final class SealedRootClass$ChildC$GrandChildACB\")\n+        final class GrandChildACB extends ChildC {}\n+\n+        @ExpectedGenericString(\"sealed class SealedRootClass$ChildC$GrandChildACC\")\n+        sealed class GrandChildACC extends ChildC {\n+            @ExpectedGenericString(\"final class SealedRootClass$ChildC$GrandChildACC$GreatGrandChildACCA\")\n+            final class GreatGrandChildACCA extends GrandChildACC {}\n+\n+            @ExpectedGenericString(\"non-sealed class SealedRootClass$ChildC$GrandChildACC$GreatGrandChildACCB\")\n+            non-sealed class GreatGrandChildACCB extends GrandChildACC {}\n+        }\n+    }\n+}\n+\n+\/\/ Test cases for sealed\/non-sealed _interface_ hierarchy.\n+@ExpectedGenericString(\"abstract sealed interface SealedRootIntf\")\n+sealed interface SealedRootIntf\n+    permits\n+    SealedRootIntf.ChildA,\n+    SealedRootIntf.ChildB,\n+    SealedRootIntf.ChildC,\n+\n+    SealedRootIntf.IntfA,\n+    SealedRootIntf.IntfB {\n+\n+    @ExpectedGenericString(\"public static final class SealedRootIntf$ChildA\")\n+    final class ChildA implements SealedRootIntf {}\n+\n+    @ExpectedGenericString(\"public static sealed class SealedRootIntf$ChildB\")\n+    sealed class ChildB implements SealedRootIntf permits SealedRootIntf.ChildB.GrandChildAB {\n+        @ExpectedGenericString(\"final class SealedRootIntf$ChildB$GrandChildAB\")\n+        final class GrandChildAB extends ChildB {}\n+    }\n+\n+    @ExpectedGenericString(\"public static non-sealed class SealedRootIntf$ChildC\")\n+    non-sealed class ChildC implements SealedRootIntf {\n+        \/\/ The subclasses of ChildC do not themselves have to be\n+        \/\/ sealed, non-sealed, or final.\n+        @ExpectedGenericString(\"class SealedRootIntf$ChildC$GrandChildACA\")\n+        class GrandChildACA extends ChildC {}\n+\n+        @ExpectedGenericString(\"final class SealedRootIntf$ChildC$GrandChildACB\")\n+        final class GrandChildACB extends ChildC {}\n+\n+        @ExpectedGenericString(\"sealed class SealedRootIntf$ChildC$GrandChildACC\")\n+        sealed class GrandChildACC extends ChildC {\n+            @ExpectedGenericString(\"final class SealedRootIntf$ChildC$GrandChildACC$GreatGrandChildACCA\")\n+            final class GreatGrandChildACCA extends GrandChildACC {}\n+\n+            @ExpectedGenericString(\"non-sealed class SealedRootIntf$ChildC$GrandChildACC$GreatGrandChildACCB\")\n+            non-sealed class GreatGrandChildACCB extends GrandChildACC {}\n+        }\n+    }\n+\n+    @ExpectedGenericString(\"public abstract static sealed interface SealedRootIntf$IntfA\")\n+    sealed interface IntfA extends  SealedRootIntf {\n+        @ExpectedGenericString(\"public static non-sealed class SealedRootIntf$IntfA$IntfAImpl\")\n+        non-sealed class IntfAImpl implements IntfA {}\n+    }\n+\n+    @ExpectedGenericString(\"public abstract static non-sealed interface SealedRootIntf$IntfB\")\n+    non-sealed interface IntfB extends  SealedRootIntf {\n+        \/\/ Check that non-sealing can be allowed with a second superinterface being sealed.\n+        @ExpectedGenericString(\"public static non-sealed class SealedRootIntf$IntfB$IntfAImpl\")\n+        non-sealed class IntfAImpl implements IntfB, IntfA  {}\n+    }\n+}\n","filename":"test\/jdk\/java\/lang\/Class\/GenericStringTest.java","additions":153,"deletions":17,"binary":false,"changes":170,"status":"modified"},{"patch":"@@ -76,2 +76,0 @@\n-tools\/javac\/lambda\/bytecode\/TestLambdaBytecodeTargetRelease14.java              8312534    linux-i586     fails with assert \"g1ConcurrentMark.cpp: Overflow during reference processing\"\n-tools\/javac\/varargs\/warning\/Warn5.java                                          8312534    linux-i586     fails with assert \"g1ConcurrentMark.cpp: Overflow during reference processing\"\n","filename":"test\/langtools\/ProblemList.txt","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -433,5 +433,0 @@\n-                        case 'Q': {\n-                            System.out.println(\"WARNING: (getInlinedInstanceSize) field \"\n-                                    + getClazz().getName() + \".\" + f.getName()\n-                                    + \" is not inlined, but has Q-signature: \" + f.getSignature());\n-                        } \/\/ continue as 'L' object\n","filename":"test\/lib\/jdk\/test\/lib\/hprof\/model\/JavaClass.java","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -269,4 +269,0 @@\n-                        case 'Q': {\n-                            warn(\"(parseFields) field \" + getClazz().getName() + \".\" + f.getName()\n-                                    + \" is not inlined, but has Q-signature: \" + f.getSignature());\n-                        } \/\/ continue as 'L' object\n","filename":"test\/lib\/jdk\/test\/lib\/hprof\/model\/JavaObject.java","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -361,4 +361,0 @@\n-                    case 'Q': {\n-                        InlinedJavaObject obj = (InlinedJavaObject)things[i];\n-                        result.append(obj);\n-                    }\n","filename":"test\/lib\/jdk\/test\/lib\/hprof\/model\/JavaValueArray.java","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"}]}