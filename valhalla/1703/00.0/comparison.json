{"files":[{"patch":"@@ -411,21 +411,0 @@\n-  # Try to enable CDS\n-  AC_MSG_CHECKING([for local Boot JDK Class Data Sharing (CDS)])\n-  BOOT_JDK_CDS_ARCHIVE=$CONFIGURESUPPORT_OUTPUTDIR\/classes.jsa\n-  UTIL_ADD_JVM_ARG_IF_OK([-XX:+UnlockDiagnosticVMOptions -XX:-VerifySharedSpaces -XX:SharedArchiveFile=$BOOT_JDK_CDS_ARCHIVE],boot_jdk_cds_args,[$JAVA])\n-\n-  if test \"x$boot_jdk_cds_args\" != x; then\n-    # Try creating a CDS archive\n-    $JAVA $boot_jdk_cds_args -Xshare:dump > \/dev\/null 2>&1\n-    if test $? -eq 0; then\n-      BOOTJDK_USE_LOCAL_CDS=true\n-      AC_MSG_RESULT([yes, created])\n-    else\n-      # Generation failed, don't use CDS.\n-      BOOTJDK_USE_LOCAL_CDS=false\n-      AC_MSG_RESULT([no, creation failed])\n-    fi\n-  else\n-    BOOTJDK_USE_LOCAL_CDS=false\n-    AC_MSG_RESULT([no, -XX:SharedArchiveFile not supported])\n-  fi\n-\n@@ -450,8 +429,0 @@\n-  if test \"x$BOOTJDK_USE_LOCAL_CDS\" = xtrue; then\n-    # Use our own CDS archive\n-    UTIL_ADD_JVM_ARG_IF_OK([$boot_jdk_cds_args -Xshare:auto],boot_jdk_jvmargs,[$JAVA])\n-  else\n-    # Otherwise optimistically use the system-wide one, if one is present\n-    UTIL_ADD_JVM_ARG_IF_OK([-Xshare:auto],boot_jdk_jvmargs,[$JAVA])\n-  fi\n-\n","filename":"make\/autoconf\/boot-jdk.m4","additions":0,"deletions":29,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -1177,3 +1177,3 @@\n-            version: \"8\",\n-            build_number: \"2\",\n-            file: \"bundles\/jtreg-8+2.zip\",\n+            version: \"8.1\",\n+            build_number: \"1\",\n+            file: \"bundles\/jtreg-8.1+1.zip\",\n","filename":"make\/conf\/jib-profiles.js","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -642,2 +642,0 @@\n-  str(last_java_sp, Address(rthread, JavaThread::last_Java_sp_offset()));\n-\n@@ -648,0 +646,3 @@\n+\n+  \/\/ We must set sp last.\n+  str(last_java_sp, Address(rthread, JavaThread::last_Java_sp_offset()));\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2376,1 +2376,1 @@\n-  Label resolved, clinit_barrier_slow;\n+  Label L_clinit_barrier_slow, L_done;\n@@ -2391,1 +2391,11 @@\n-  __ br(Assembler::EQ, resolved);\n+\n+  \/\/ Class initialization barrier for static methods\n+  if (VM_Version::supports_fast_class_init_checks() && bytecode() == Bytecodes::_invokestatic) {\n+    __ br(Assembler::NE, L_clinit_barrier_slow);\n+    __ ldr(temp, Address(Rcache, in_bytes(ResolvedMethodEntry::method_offset())));\n+    __ load_method_holder(temp, temp);\n+    __ clinit_barrier(temp, rscratch1, &L_done, \/*L_slow_path*\/ nullptr);\n+    __ bind(L_clinit_barrier_slow);\n+  } else {\n+    __ br(Assembler::EQ, L_done);\n+  }\n@@ -2395,1 +2405,0 @@\n-  __ bind(clinit_barrier_slow);\n@@ -2404,8 +2413,1 @@\n-  __ bind(resolved);\n-\n-  \/\/ Class initialization barrier for static methods\n-  if (VM_Version::supports_fast_class_init_checks() && bytecode() == Bytecodes::_invokestatic) {\n-    __ ldr(temp, Address(Rcache, in_bytes(ResolvedMethodEntry::method_offset())));\n-    __ load_method_holder(temp, temp);\n-    __ clinit_barrier(temp, rscratch1, nullptr, &clinit_barrier_slow);\n-  }\n+  __ bind(L_done);\n@@ -2420,1 +2422,1 @@\n-  Label resolved;\n+  Label L_clinit_barrier_slow, L_done;\n@@ -2439,1 +2441,13 @@\n-  __ br(Assembler::EQ, resolved);\n+\n+  \/\/ Class initialization barrier for static fields\n+  if (VM_Version::supports_fast_class_init_checks() &&\n+      (bytecode() == Bytecodes::_getstatic || bytecode() == Bytecodes::_putstatic)) {\n+    const Register field_holder = temp;\n+\n+    __ br(Assembler::NE, L_clinit_barrier_slow);\n+    __ ldr(field_holder, Address(Rcache, in_bytes(ResolvedFieldEntry::field_holder_offset())));\n+    __ clinit_barrier(field_holder, rscratch1, &L_done, \/*L_slow_path*\/ nullptr);\n+    __ bind(L_clinit_barrier_slow);\n+  } else {\n+    __ br(Assembler::EQ, L_done);\n+  }\n@@ -2442,0 +2456,1 @@\n+  \/\/ Class initialization barrier slow path lands here as well.\n@@ -2448,1 +2463,1 @@\n-  __ bind(resolved);\n+  __ bind(L_done);\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":29,"deletions":14,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -151,0 +151,2 @@\n+  product(bool, TrapBasedNMethodEntryBarriers, true, DIAGNOSTIC,            \\\n+          \"Raise and handle SIGTRAP if nmethod entry barrier armed.\")       \\\n","filename":"src\/hotspot\/cpu\/ppc\/globals_ppc.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2172,1 +2172,1 @@\n-  Label resolved, clinit_barrier_slow;\n+  Label L_clinit_barrier_slow, L_done;\n@@ -2189,1 +2189,11 @@\n-  __ beq(temp, t0, resolved);  \/\/ have we resolved this bytecode?\n+\n+  \/\/ Class initialization barrier for static methods\n+  if (VM_Version::supports_fast_class_init_checks() && bytecode() == Bytecodes::_invokestatic) {\n+    __ bne(temp, t0, L_clinit_barrier_slow);  \/\/ have we resolved this bytecode?\n+    __ ld(temp, Address(Rcache, in_bytes(ResolvedMethodEntry::method_offset())));\n+    __ load_method_holder(temp, temp);\n+    __ clinit_barrier(temp, t0, &L_done, \/*L_slow_path*\/ nullptr);\n+    __ bind(L_clinit_barrier_slow);\n+  } else {\n+    __ beq(temp, t0, L_done);  \/\/ have we resolved this bytecode?\n+  }\n@@ -2193,2 +2203,0 @@\n-  __ bind(clinit_barrier_slow);\n-\n@@ -2203,8 +2211,1 @@\n-  __ bind(resolved);\n-\n-  \/\/ Class initialization barrier for static methods\n-  if (VM_Version::supports_fast_class_init_checks() && bytecode() == Bytecodes::_invokestatic) {\n-    __ ld(temp, Address(Rcache, in_bytes(ResolvedMethodEntry::method_offset())));\n-    __ load_method_holder(temp, temp);\n-    __ clinit_barrier(temp, t0, nullptr, &clinit_barrier_slow);\n-  }\n+  __ bind(L_done);\n@@ -2219,1 +2220,1 @@\n-  Label resolved;\n+  Label L_clinit_barrier_slow, L_done;\n@@ -2223,3 +2224,3 @@\n-  case Bytecodes::_nofast_getfield: code = Bytecodes::_getfield; break;\n-  case Bytecodes::_nofast_putfield: code = Bytecodes::_putfield; break;\n-  default: break;\n+    case Bytecodes::_nofast_getfield: code = Bytecodes::_getfield; break;\n+    case Bytecodes::_nofast_putfield: code = Bytecodes::_putfield; break;\n+    default: break;\n@@ -2239,1 +2240,13 @@\n-  __ beq(temp, t0, resolved);\n+\n+  \/\/ Class initialization barrier for static fields\n+  if (VM_Version::supports_fast_class_init_checks() &&\n+      (bytecode() == Bytecodes::_getstatic || bytecode() == Bytecodes::_putstatic)) {\n+    const Register field_holder = temp;\n+\n+    __ bne(temp, t0, L_clinit_barrier_slow);\n+    __ ld(field_holder, Address(Rcache, in_bytes(ResolvedFieldEntry::field_holder_offset())));\n+    __ clinit_barrier(field_holder, t0, &L_done, \/*L_slow_path*\/ nullptr);\n+    __ bind(L_clinit_barrier_slow);\n+  } else {\n+    __ beq(temp, t0, L_done);\n+  }\n@@ -2242,0 +2255,1 @@\n+  \/\/ Class initialization barrier slow path lands here as well.\n@@ -2248,1 +2262,1 @@\n-  __ bind(resolved);\n+  __ bind(L_done);\n","filename":"src\/hotspot\/cpu\/riscv\/templateTable_riscv.cpp","additions":32,"deletions":18,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -2306,2 +2306,1 @@\n-  Label L_clinit_barrier_slow;\n-  Label resolved;\n+  Label L_clinit_barrier_slow, L_done;\n@@ -2325,12 +2324,0 @@\n-  __ jcc(Assembler::equal, resolved);\n-\n-  \/\/ resolve first time through\n-  \/\/ Class initialization barrier slow path lands here as well.\n-  __ bind(L_clinit_barrier_slow);\n-  address entry = CAST_FROM_FN_PTR(address, InterpreterRuntime::resolve_from_cache);\n-  __ movl(temp, code);\n-  __ call_VM(noreg, entry, temp);\n-  \/\/ Update registers with resolved info\n-  __ load_method_entry(cache, index);\n-\n-  __ bind(resolved);\n@@ -2343,0 +2330,1 @@\n+    __ jcc(Assembler::notEqual, L_clinit_barrier_slow);\n@@ -2345,1 +2333,4 @@\n-    __ clinit_barrier(klass, nullptr \/*L_fast_path*\/, &L_clinit_barrier_slow);\n+    __ clinit_barrier(klass, &L_done, \/*L_slow_path*\/ nullptr);\n+    __ bind(L_clinit_barrier_slow);\n+  } else {\n+    __ jcc(Assembler::equal, L_done);\n@@ -2347,0 +2338,9 @@\n+\n+  \/\/ resolve first time through\n+  \/\/ Class initialization barrier slow path lands here as well.\n+  address entry = CAST_FROM_FN_PTR(address, InterpreterRuntime::resolve_from_cache);\n+  __ movl(temp, code);\n+  __ call_VM(noreg, entry, temp);\n+  \/\/ Update registers with resolved info\n+  __ load_method_entry(cache, index);\n+  __ bind(L_done);\n@@ -2350,2 +2350,2 @@\n-                                            Register cache,\n-                                            Register index) {\n+                                                      Register cache,\n+                                                      Register index) {\n@@ -2355,1 +2355,1 @@\n-  Label resolved;\n+  Label L_clinit_barrier_slow, L_done;\n@@ -2372,1 +2372,13 @@\n-  __ jcc(Assembler::equal, resolved);\n+\n+  \/\/ Class initialization barrier for static fields\n+  if (VM_Version::supports_fast_class_init_checks() &&\n+      (bytecode() == Bytecodes::_getstatic || bytecode() == Bytecodes::_putstatic)) {\n+    const Register field_holder = temp;\n+\n+    __ jcc(Assembler::notEqual, L_clinit_barrier_slow);\n+    __ movptr(field_holder, Address(cache, in_bytes(ResolvedFieldEntry::field_holder_offset())));\n+    __ clinit_barrier(field_holder, &L_done, \/*L_slow_path*\/ nullptr);\n+    __ bind(L_clinit_barrier_slow);\n+  } else {\n+    __ jcc(Assembler::equal, L_done);\n+  }\n@@ -2375,0 +2387,1 @@\n+  \/\/ Class initialization barrier slow path lands here as well.\n@@ -2380,2 +2393,1 @@\n-\n-  __ bind(resolved);\n+  __ bind(L_done);\n","filename":"src\/hotspot\/cpu\/x86\/templateTable_x86.cpp","additions":33,"deletions":21,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -65,1 +65,1 @@\n-static const int stub_size = 2000;\n+static const int stub_size = 2550;\n@@ -76,0 +76,1 @@\n+  typedef void (*getCPUIDBrandString_stub_t)(void*);\n@@ -80,0 +81,1 @@\n+static getCPUIDBrandString_stub_t getCPUIDBrandString_stub = nullptr;\n@@ -2134,0 +2136,2 @@\n+  getCPUIDBrandString_stub = CAST_TO_FN_PTR(getCPUIDBrandString_stub_t,\n+                                     g.generate_getCPUIDBrandString());\n@@ -2190,9 +2194,0 @@\n-static BufferBlob* cpuid_brand_string_stub_blob;\n-static const int   cpuid_brand_string_stub_size = 550;\n-\n-extern \"C\" {\n-  typedef void (*getCPUIDBrandString_stub_t)(void*);\n-}\n-\n-static getCPUIDBrandString_stub_t getCPUIDBrandString_stub = nullptr;\n-\n@@ -2491,13 +2486,0 @@\n-void VM_Version::initialize_tsc(void) {\n-  ResourceMark rm;\n-\n-  cpuid_brand_string_stub_blob = BufferBlob::create(\"getCPUIDBrandString_stub\", cpuid_brand_string_stub_size);\n-  if (cpuid_brand_string_stub_blob == nullptr) {\n-    vm_exit_during_initialization(\"Unable to allocate getCPUIDBrandString_stub\");\n-  }\n-  CodeBuffer c(cpuid_brand_string_stub_blob);\n-  VM_Version_StubGenerator g(&c);\n-  getCPUIDBrandString_stub = CAST_TO_FN_PTR(getCPUIDBrandString_stub_t,\n-                                   g.generate_getCPUIDBrandString());\n-}\n-\n@@ -2592,1 +2574,6 @@\n-  int threads_per_package = threads_per_core() * cores_per_cpu();\n+  int threads_per_package = _cpuid_info.tpl_cpuidB1_ebx.bits.logical_cpus;\n+  if (threads_per_package == 0) {\n+    \/\/ Fallback code to avoid div by zero in subsequent code.\n+    \/\/ CPUID 0Bh (ECX = 1) might return 0 on older AMD processor (EPYC 7763 at least)\n+    threads_per_package = threads_per_core() * cores_per_cpu();\n+  }\n@@ -2746,0 +2733,4 @@\n+  if (supports_hybrid()) {\n+      WRITE_TO_BUF(\"Hybrid Architecture\");\n+  }\n+\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":15,"deletions":24,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -658,4 +658,2 @@\n-  int bytes = src_info->size_in_bytes();\n-  char* dest;\n-  char* oldtop;\n-  char* newtop;\n+  int bytes = src_info->size_in_bytes(); \/\/ word-aligned\n+  size_t alignment = SharedSpaceObjectAlignment; \/\/ alignment for the dest pointer\n@@ -663,1 +661,1 @@\n-  oldtop = dump_region->top();\n+  char* oldtop = dump_region->top();\n@@ -674,7 +672,4 @@\n-    \/\/ Allocate space for the future InstanceKlass with proper alignment\n-    const size_t alignment =\n-      UseCompressedClassPointers ?\n-        nth_bit(ArchiveBuilder::precomputed_narrow_klass_shift()) :\n-        SharedSpaceObjectAlignment;\n-#else\n-      SharedSpaceObjectAlignment;\n+    \/\/ More strict alignments needed for UseCompressedClassPointers\n+    if (UseCompressedClassPointers) {\n+      alignment = nth_bit(ArchiveBuilder::precomputed_narrow_klass_shift());\n+    }\n@@ -683,3 +678,4 @@\n-    dest = dump_region->allocate(bytes, alignment);\n-  } else {\n-    dest = dump_region->allocate(bytes);\n+  } else if (src_info->msotype() == MetaspaceObj::SymbolType) {\n+    \/\/ Symbols may be allocated by using AllocateHeap, so their sizes\n+    \/\/ may be less than size_in_bytes() indicates.\n+    bytes = ((Symbol*)src)->byte_size();\n@@ -687,1 +683,1 @@\n-  newtop = dump_region->top();\n+  char* dest = dump_region->allocate(bytes, alignment);\n@@ -716,0 +712,1 @@\n+  char* newtop = dump_region->top();\n","filename":"src\/hotspot\/share\/cds\/archiveBuilder.cpp","additions":13,"deletions":16,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -2498,203 +2498,0 @@\n-\/\/ Look at the method's handlers.  If the bci is in the handler's try block\n-\/\/ then check if the handler_pc is already on the stack.  If not, push it\n-\/\/ unless the handler has already been scanned.\n-void ClassVerifier::push_handlers(ExceptionTable* exhandlers,\n-                                  GrowableArray<u4>* handler_list,\n-                                  GrowableArray<u4>* handler_stack,\n-                                  u4 bci) {\n-  int exlength = exhandlers->length();\n-  for(int x = 0; x < exlength; x++) {\n-    if (bci >= exhandlers->start_pc(x) && bci < exhandlers->end_pc(x)) {\n-      u4 exhandler_pc = exhandlers->handler_pc(x);\n-      if (!handler_list->contains(exhandler_pc)) {\n-        handler_stack->append_if_missing(exhandler_pc);\n-        handler_list->append(exhandler_pc);\n-      }\n-    }\n-  }\n-}\n-\n-\/\/ Return TRUE if all code paths starting with start_bc_offset end in\n-\/\/ bytecode athrow or loop.\n-bool ClassVerifier::ends_in_athrow(u4 start_bc_offset) {\n-  ResourceMark rm;\n-  \/\/ Create bytecode stream.\n-  RawBytecodeStream bcs(method());\n-  int code_length = method()->code_size();\n-  bcs.set_start(start_bc_offset);\n-\n-  \/\/ Create stack for storing bytecode start offsets for if* and *switch.\n-  GrowableArray<u4>* bci_stack = new GrowableArray<u4>(30);\n-  \/\/ Create stack for handlers for try blocks containing this handler.\n-  GrowableArray<u4>* handler_stack = new GrowableArray<u4>(30);\n-  \/\/ Create list of handlers that have been pushed onto the handler_stack\n-  \/\/ so that handlers embedded inside of their own TRY blocks only get\n-  \/\/ scanned once.\n-  GrowableArray<u4>* handler_list = new GrowableArray<u4>(30);\n-  \/\/ Create list of visited branch opcodes (goto* and if*).\n-  GrowableArray<u4>* visited_branches = new GrowableArray<u4>(30);\n-  ExceptionTable exhandlers(_method());\n-\n-  while (true) {\n-    if (bcs.is_last_bytecode()) {\n-      \/\/ if no more starting offsets to parse or if at the end of the\n-      \/\/ method then return false.\n-      if ((bci_stack->is_empty()) || (bcs.end_bci() == code_length))\n-        return false;\n-      \/\/ Pop a bytecode starting offset and scan from there.\n-      bcs.set_start(bci_stack->pop());\n-    }\n-    Bytecodes::Code opcode = bcs.raw_next();\n-    int bci = bcs.bci();\n-\n-    \/\/ If the bytecode is in a TRY block, push its handlers so they\n-    \/\/ will get parsed.\n-    push_handlers(&exhandlers, handler_list, handler_stack, bci);\n-\n-    switch (opcode) {\n-      case Bytecodes::_if_icmpeq:\n-      case Bytecodes::_if_icmpne:\n-      case Bytecodes::_if_icmplt:\n-      case Bytecodes::_if_icmpge:\n-      case Bytecodes::_if_icmpgt:\n-      case Bytecodes::_if_icmple:\n-      case Bytecodes::_ifeq:\n-      case Bytecodes::_ifne:\n-      case Bytecodes::_iflt:\n-      case Bytecodes::_ifge:\n-      case Bytecodes::_ifgt:\n-      case Bytecodes::_ifle:\n-      case Bytecodes::_if_acmpeq:\n-      case Bytecodes::_if_acmpne:\n-      case Bytecodes::_ifnull:\n-      case Bytecodes::_ifnonnull: {\n-        int target = bcs.dest();\n-        if (visited_branches->contains(bci)) {\n-          if (bci_stack->is_empty()) {\n-            if (handler_stack->is_empty()) {\n-              return true;\n-            } else {\n-              \/\/ Parse the catch handlers for try blocks containing athrow.\n-              bcs.set_start(handler_stack->pop());\n-            }\n-          } else {\n-            \/\/ Pop a bytecode starting offset and scan from there.\n-            bcs.set_start(bci_stack->pop());\n-          }\n-        } else {\n-          if (target > bci) { \/\/ forward branch\n-            if (target >= code_length) return false;\n-            \/\/ Push the branch target onto the stack.\n-            bci_stack->push(target);\n-            \/\/ then, scan bytecodes starting with next.\n-            bcs.set_start(bcs.next_bci());\n-          } else { \/\/ backward branch\n-            \/\/ Push bytecode offset following backward branch onto the stack.\n-            bci_stack->push(bcs.next_bci());\n-            \/\/ Check bytecodes starting with branch target.\n-            bcs.set_start(target);\n-          }\n-          \/\/ Record target so we don't branch here again.\n-          visited_branches->append(bci);\n-        }\n-        break;\n-        }\n-\n-      case Bytecodes::_goto:\n-      case Bytecodes::_goto_w: {\n-        int target = (opcode == Bytecodes::_goto ? bcs.dest() : bcs.dest_w());\n-        if (visited_branches->contains(bci)) {\n-          if (bci_stack->is_empty()) {\n-            if (handler_stack->is_empty()) {\n-              return true;\n-            } else {\n-              \/\/ Parse the catch handlers for try blocks containing athrow.\n-              bcs.set_start(handler_stack->pop());\n-            }\n-          } else {\n-            \/\/ Been here before, pop new starting offset from stack.\n-            bcs.set_start(bci_stack->pop());\n-          }\n-        } else {\n-          if (target >= code_length) return false;\n-          \/\/ Continue scanning from the target onward.\n-          bcs.set_start(target);\n-          \/\/ Record target so we don't branch here again.\n-          visited_branches->append(bci);\n-        }\n-        break;\n-        }\n-\n-      \/\/ Check that all switch alternatives end in 'athrow' bytecodes. Since it\n-      \/\/ is  difficult to determine where each switch alternative ends, parse\n-      \/\/ each switch alternative until either hit a 'return', 'athrow', or reach\n-      \/\/ the end of the method's bytecodes.  This is gross but should be okay\n-      \/\/ because:\n-      \/\/ 1. tableswitch and lookupswitch byte codes in handlers for ctor explicit\n-      \/\/    constructor invocations should be rare.\n-      \/\/ 2. if each switch alternative ends in an athrow then the parsing should be\n-      \/\/    short.  If there is no athrow then it is bogus code, anyway.\n-      case Bytecodes::_lookupswitch:\n-      case Bytecodes::_tableswitch:\n-        {\n-          address aligned_bcp = align_up(bcs.bcp() + 1, jintSize);\n-          int default_offset = Bytes::get_Java_u4(aligned_bcp) + bci;\n-          int keys, delta;\n-          if (opcode == Bytecodes::_tableswitch) {\n-            jint low = (jint)Bytes::get_Java_u4(aligned_bcp + jintSize);\n-            jint high = (jint)Bytes::get_Java_u4(aligned_bcp + 2*jintSize);\n-            \/\/ This is invalid, but let the regular bytecode verifier\n-            \/\/ report this because the user will get a better error message.\n-            if (low > high) return true;\n-            keys = high - low + 1;\n-            delta = 1;\n-          } else {\n-            keys = (int)Bytes::get_Java_u4(aligned_bcp + jintSize);\n-            delta = 2;\n-          }\n-          \/\/ Invalid, let the regular bytecode verifier deal with it.\n-          if (keys < 0) return true;\n-\n-          \/\/ Push the offset of the next bytecode onto the stack.\n-          bci_stack->push(bcs.next_bci());\n-\n-          \/\/ Push the switch alternatives onto the stack.\n-          for (int i = 0; i < keys; i++) {\n-            int target = bci + (jint)Bytes::get_Java_u4(aligned_bcp+(3+i*delta)*jintSize);\n-            if (target > code_length) return false;\n-            bci_stack->push(target);\n-          }\n-\n-          \/\/ Start bytecode parsing for the switch at the default alternative.\n-          if (default_offset > code_length) return false;\n-          bcs.set_start(default_offset);\n-          break;\n-        }\n-\n-      case Bytecodes::_return:\n-        return false;\n-\n-      case Bytecodes::_athrow:\n-        {\n-          if (bci_stack->is_empty()) {\n-            if (handler_stack->is_empty()) {\n-              return true;\n-            } else {\n-              \/\/ Parse the catch handlers for try blocks containing athrow.\n-              bcs.set_start(handler_stack->pop());\n-            }\n-          } else {\n-            \/\/ Pop a bytecode offset and starting scanning from there.\n-            bcs.set_start(bci_stack->pop());\n-          }\n-        }\n-        break;\n-\n-      default:\n-        ;\n-    } \/\/ end switch\n-  } \/\/ end while loop\n-\n-  return false;\n-}\n-\n@@ -2732,19 +2529,0 @@\n-      ExceptionTable exhandlers(_method());\n-      int exlength = exhandlers.length();\n-      for(int i = 0; i < exlength; i++) {\n-        u2 start_pc = exhandlers.start_pc(i);\n-        u2 end_pc = exhandlers.end_pc(i);\n-\n-        if (bci >= start_pc && bci < end_pc) {\n-          if (!ends_in_athrow(exhandlers.handler_pc(i))) {\n-            verify_error(ErrorContext::bad_code(bci),\n-              \"Bad <init> method call from after the start of a try block\");\n-            return;\n-          } else if (log_is_enabled(Debug, verification)) {\n-            ResourceMark rm(THREAD);\n-            log_debug(verification)(\"Survived call to ends_in_athrow(): %s\",\n-                                          current_class()->name()->as_C_string());\n-          }\n-        }\n-      }\n-\n","filename":"src\/hotspot\/share\/classfile\/verifier.cpp","additions":0,"deletions":222,"binary":false,"changes":222,"status":"modified"},{"patch":"@@ -360,11 +360,0 @@\n-  \/\/ Used by ends_in_athrow() to push all handlers that contain bci onto the\n-  \/\/ handler_stack, if the handler has not already been pushed on the stack.\n-  void push_handlers(ExceptionTable* exhandlers,\n-                     GrowableArray<u4>* handler_list,\n-                     GrowableArray<u4>* handler_stack,\n-                     u4 bci);\n-\n-  \/\/ Returns true if all paths starting with start_bc_offset end in athrow\n-  \/\/ bytecode or loop.\n-  bool ends_in_athrow(u4 start_bc_offset);\n-\n","filename":"src\/hotspot\/share\/classfile\/verifier.hpp","additions":0,"deletions":11,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -60,0 +60,1 @@\n+#include \"gc\/shared\/parallelCleaning.hpp\"\n@@ -1160,0 +1161,34 @@\n+class PSParallelCleaningTask : public WorkerTask {\n+  bool                    _unloading_occurred;\n+  CodeCacheUnloadingTask  _code_cache_task;\n+  \/\/ Prune dead klasses from subklass\/sibling\/implementor lists.\n+  KlassCleaningTask       _klass_cleaning_task;\n+\n+public:\n+  PSParallelCleaningTask(bool unloading_occurred) :\n+    WorkerTask(\"PS Parallel Cleaning\"),\n+    _unloading_occurred(unloading_occurred),\n+    _code_cache_task(unloading_occurred),\n+    _klass_cleaning_task() {}\n+\n+  void work(uint worker_id) {\n+#if INCLUDE_JVMCI\n+    if (EnableJVMCI && worker_id == 0) {\n+      \/\/ Serial work; only first worker.\n+      \/\/ Clean JVMCI metadata handles.\n+      JVMCI::do_unloading(_unloading_occurred);\n+    }\n+#endif\n+\n+    \/\/ Do first pass of code cache cleaning.\n+    _code_cache_task.work(worker_id);\n+\n+    \/\/ Clean all klasses that were not unloaded.\n+    \/\/ The weak metadata in klass doesn't need to be\n+    \/\/ processed if there was no unloading.\n+    if (_unloading_occurred) {\n+      _klass_cleaning_task.work();\n+    }\n+  }\n+};\n+\n@@ -1208,1 +1243,1 @@\n-    ClassUnloadingContext ctx(1 \/* num_nmethod_unlink_workers *\/,\n+    ClassUnloadingContext ctx(active_gc_threads \/* num_nmethod_unlink_workers *\/,\n@@ -1212,1 +1247,0 @@\n-    bool unloading_occurred;\n@@ -1217,1 +1251,1 @@\n-      unloading_occurred = SystemDictionary::do_unloading(&_gc_timer);\n+      bool unloading_occurred = SystemDictionary::do_unloading(&_gc_timer);\n@@ -1219,2 +1253,2 @@\n-      \/\/ Unload nmethods.\n-      CodeCache::do_unloading(unloading_occurred);\n+      PSParallelCleaningTask task{unloading_occurred};\n+      ParallelScavengeHeap::heap()->workers().run_task(&task);\n@@ -1236,6 +1270,0 @@\n-\n-    \/\/ Prune dead klasses from subklass\/sibling\/implementor lists.\n-    Klass::clean_weak_klass_links(unloading_occurred);\n-\n-    \/\/ Clean JVMCI metadata handles.\n-    JVMCI_ONLY(JVMCI::do_unloading(unloading_occurred));\n@@ -1338,0 +1366,1 @@\n+  ThreadsClaimTokenScope                     _threads_claim_token_scope;\n@@ -1353,0 +1382,1 @@\n+    _threads_claim_token_scope(),\n@@ -1358,5 +1388,0 @@\n-    Threads::change_thread_claim_token();\n-  }\n-\n-  ~PSAdjustTask() {\n-    Threads::assert_all_threads_claimed();\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":41,"deletions":16,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -439,2 +439,0 @@\n- *  caller: initiating class. The initiating class may be null when a security\n- *          manager is not installed.\n@@ -443,2 +441,2 @@\n-JVM_FindClassFromCaller(JNIEnv *env, const char *name, jboolean init,\n-                        jobject loader, jclass caller);\n+JVM_FindClassFromLoader(JNIEnv *env, const char *name, jboolean init,\n+                        jobject loader);\n","filename":"src\/hotspot\/share\/include\/jvm.h","additions":2,"deletions":4,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -785,5 +785,1 @@\n-    if (is_static) {\n-      get_code = Bytecodes::_getstatic;\n-    } else {\n-      get_code = Bytecodes::_getfield;\n-    }\n+    get_code = ((is_static) ? Bytecodes::_getstatic : Bytecodes::_getfield);\n@@ -791,1 +787,1 @@\n-        put_code = ((is_static) ? Bytecodes::_putstatic : Bytecodes::_putfield);\n+      put_code = ((is_static) ? Bytecodes::_putstatic : Bytecodes::_putfield);\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":2,"deletions":6,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -399,0 +399,6 @@\n+  \/\/ Collapse addition of the same terms into multiplications.\n+  Node* collapsed = Ideal_collapse_variable_times_con(phase, bt);\n+  if (collapsed != nullptr) {\n+    return collapsed; \/\/ Skip AddNode::Ideal() since it may now be a multiplication node.\n+  }\n+\n@@ -402,0 +408,167 @@\n+\/\/ Try to collapse addition of the same terms into a single multiplication. On success, a new MulNode is returned.\n+\/\/ Examples of this conversion includes:\n+\/\/   - a + a + ... + a => CON*a\n+\/\/   - (a * CON) + a   => (CON + 1) * a\n+\/\/   - a + (a * CON)   => (CON + 1) * a\n+\/\/\n+\/\/ We perform such conversions incrementally during IGVN by transforming left most nodes first and work up to the root\n+\/\/ of the expression. In other words, we convert, at each iteration:\n+\/\/        a + a + a + ... + a\n+\/\/     => 2*a + a + ... + a\n+\/\/     => 3*a + ... + a\n+\/\/     => n*a\n+\/\/\n+\/\/ Due to the iterative nature of IGVN, MulNode transformed from first few AddNode terms may be further transformed into\n+\/\/ power-of-2 pattern. (e.g., 2 * a => a << 1, 3 * a => (a << 2) + a). We can't guarantee we'll always pick up\n+\/\/ transformed power-of-2 patterns when term `a` is complex.\n+\/\/\n+\/\/ Note this also converts, for example, original expression `(a*3) + a` into `4*a` and `(a<<2) + a` into `5*a`. A more\n+\/\/ generalized pattern `(a*b) + (a*c)` into `a*(b + c)` is handled by AddNode::IdealIL().\n+Node* AddNode::Ideal_collapse_variable_times_con(PhaseGVN* phase, BasicType bt) {\n+  \/\/ We need to make sure that the current AddNode is not part of a MulNode that has already been optimized to a\n+  \/\/ power-of-2 addition (e.g., 3 * a => (a << 2) + a). Without this check, GVN would keep trying to optimize the same\n+  \/\/ node and can't progress. For example, 3 * a => (a << 2) + a => 3 * a => (a << 2) + a => ...\n+  if (Multiplication::find_power_of_two_addition_pattern(this, bt).is_valid()) {\n+    return nullptr;\n+  }\n+\n+  Node* lhs = in(1);\n+  Node* rhs = in(2);\n+\n+  Multiplication mul = Multiplication::find_collapsible_addition_patterns(lhs, rhs, bt);\n+  if (!mul.is_valid_with(rhs)) {\n+    \/\/ Swap lhs and rhs then try again\n+    mul = Multiplication::find_collapsible_addition_patterns(rhs, lhs, bt);\n+    if (!mul.is_valid_with(lhs)) {\n+      return nullptr;\n+    }\n+  }\n+\n+  Node* con;\n+  if (bt == T_INT) {\n+    con = phase->intcon(java_add(static_cast<jint>(mul.multiplier()), 1));\n+  } else {\n+    con = phase->longcon(java_add(mul.multiplier(), CONST64(1)));\n+  }\n+\n+  return MulNode::make(con, mul.variable(), bt);\n+}\n+\n+\/\/ Find a pattern of collapsable additions that can be converted to a multiplication.\n+\/\/ When matching the LHS `a * CON`, we match with best efforts by looking for the following patterns:\n+\/\/     - (1) Simple addition:       LHS = a + a\n+\/\/     - (2) Simple lshift:         LHS = a << CON\n+\/\/     - (3) Simple multiplication: LHS = CON * a\n+\/\/     - (4) Power-of-two addition: LHS = (a << CON1) + (a << CON2)\n+AddNode::Multiplication AddNode::Multiplication::find_collapsible_addition_patterns(const Node* a, const Node* pattern, BasicType bt) {\n+  \/\/ (1) Simple addition pattern (e.g., lhs = a + a)\n+  Multiplication mul = find_simple_addition_pattern(a, bt);\n+  if (mul.is_valid_with(pattern)) {\n+    return mul;\n+  }\n+\n+  \/\/ (2) Simple lshift pattern (e.g., lhs = a << CON)\n+  mul = find_simple_lshift_pattern(a, bt);\n+  if (mul.is_valid_with(pattern)) {\n+    return mul;\n+  }\n+\n+  \/\/ (3) Simple multiplication pattern (e.g., lhs = CON * a)\n+  mul = find_simple_multiplication_pattern(a, bt);\n+  if (mul.is_valid_with(pattern)) {\n+    return mul;\n+  }\n+\n+  \/\/ (4) Power-of-two addition pattern (e.g., lhs = (a << CON1) + (a << CON2))\n+  \/\/ While multiplications can be potentially optimized to power-of-2 subtractions (e.g., a * 7 => (a << 3) - a),\n+  \/\/ (x - y) + y => x is already handled by the Identity() methods. So, we don't need to check for that pattern here.\n+  mul = find_power_of_two_addition_pattern(a, bt);\n+  if (mul.is_valid_with(pattern)) {\n+    return mul;\n+  }\n+\n+  \/\/ We've tried everything.\n+  return make_invalid();\n+}\n+\n+\/\/ Try to match `n = a + a`. On success, return a struct with `.valid = true`, `variable = a`, and `multiplier = 2`.\n+\/\/ The method matches `n` for pattern: a + a.\n+AddNode::Multiplication AddNode::Multiplication::find_simple_addition_pattern(const Node* n, BasicType bt) {\n+  if (n->Opcode() == Op_Add(bt) && n->in(1) == n->in(2)) {\n+    return Multiplication(n->in(1), 2);\n+  }\n+\n+  return make_invalid();\n+}\n+\n+\/\/ Try to match `n = a << CON`. On success, return a struct with `.valid = true`, `variable = a`, and\n+\/\/ `multiplier = 1 << CON`.\n+\/\/ Match `n` for pattern: a << CON.\n+\/\/ Note that the power-of-2 multiplication optimization could potentially convert a MulNode to this pattern.\n+AddNode::Multiplication AddNode::Multiplication::find_simple_lshift_pattern(const Node* n, BasicType bt) {\n+  \/\/ Note that power-of-2 multiplication optimization could potentially convert a MulNode to this pattern\n+  if (n->Opcode() == Op_LShift(bt) && n->in(2)->is_Con()) {\n+    Node* con = n->in(2);\n+    if (!con->is_top()) {\n+      return Multiplication(n->in(1), java_shift_left(1, con->get_int(), bt));\n+    }\n+  }\n+\n+  return make_invalid();\n+}\n+\n+\/\/ Try to match `n = CON * a`. On success, return a struct with `.valid = true`, `variable = a`, and `multiplier = CON`.\n+\/\/ Match `n` for patterns: CON * a\n+\/\/ Note that `CON` will always be the second input node of a Mul node canonicalized by Ideal(). If this is not the case,\n+\/\/ `n` has not been processed by iGVN. So we skip the optimization for the current add node and wait for to be added to\n+\/\/ the queue again.\n+AddNode::Multiplication AddNode::Multiplication::find_simple_multiplication_pattern(const Node* n, BasicType bt) {\n+  if (n->Opcode() == Op_Mul(bt) && n->in(2)->is_Con()) {\n+    Node* con = n->in(2);\n+    Node* base = n->in(1);\n+\n+    if (!con->is_top()) {\n+      return Multiplication(base, con->get_integer_as_long(bt));\n+    }\n+  }\n+\n+  return make_invalid();\n+}\n+\n+\/\/ Try to match `n = (a << CON1) + (a << CON2)`. On success, return a struct with `.valid = true`, `variable = a`, and\n+\/\/ `multiplier = (1 << CON1) + (1 << CON2)`.\n+\/\/ Match `n` for patterns:\n+\/\/     - (1) (a << CON) + (a << CON)\n+\/\/     - (2) (a << CON) + a\n+\/\/     - (3) a + (a << CON)\n+\/\/     - (4) a + a\n+\/\/ Note that one or both of the term of the addition could simply be `a` (i.e., a << 0) as in pattern (4).\n+AddNode::Multiplication AddNode::Multiplication::find_power_of_two_addition_pattern(const Node* n, BasicType bt) {\n+  if (n->Opcode() == Op_Add(bt) && n->in(1) != n->in(2)) {\n+    const Multiplication lhs = find_simple_lshift_pattern(n->in(1), bt);\n+    const Multiplication rhs = find_simple_lshift_pattern(n->in(2), bt);\n+\n+    \/\/ Pattern (1)\n+    {\n+      const Multiplication res = lhs.add(rhs);\n+      if (res.is_valid()) {\n+        return res;\n+      }\n+    }\n+\n+    \/\/ Pattern (2)\n+    if (lhs.is_valid_with(n->in(2))) {\n+      return Multiplication(lhs.variable(), java_add(lhs.multiplier(), CONST64(1)));\n+    }\n+\n+    \/\/ Pattern (3)\n+    if (rhs.is_valid_with(n->in(1))) {\n+      return Multiplication(rhs.variable(), java_add(rhs.multiplier(), CONST64(1)));\n+    }\n+\n+    \/\/ Pattern (4), which is equivalent to a simple addition pattern\n+    return find_simple_addition_pattern(n, bt);\n+  }\n+\n+  return make_invalid();\n+}\n","filename":"src\/hotspot\/share\/opto\/addnode.cpp","additions":173,"deletions":0,"binary":false,"changes":173,"status":"modified"},{"patch":"@@ -327,1 +327,1 @@\n-  virtual int required_outcnt() const = 0;\n+  virtual uint required_outcnt() const = 0;\n@@ -449,1 +449,1 @@\n-  virtual int required_outcnt() const { return 2; }\n+  virtual uint required_outcnt() const { return 2; }\n@@ -607,1 +607,1 @@\n-  virtual int required_outcnt() const { return _size; }\n+  virtual uint required_outcnt() const { return _size; }\n@@ -732,1 +732,1 @@\n-  virtual int required_outcnt() const { return 2; }\n+  virtual uint required_outcnt() const { return 2; }\n","filename":"src\/hotspot\/share\/opto\/cfgnode.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1559,3 +1559,0 @@\n-  \/\/ Move an unordered Reduction out of loop if possible\n-  void move_unordered_reduction_out_of_loop(IdealLoopTree* loop);\n-\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -4731,205 +4731,0 @@\n-\/\/ Returns true if the Reduction node is unordered.\n-static bool is_unordered_reduction(Node* n) {\n-  return n->is_Reduction() && !n->as_Reduction()->requires_strict_order();\n-}\n-\n-\/\/ Having ReductionNodes in the loop is expensive. They need to recursively\n-\/\/ fold together the vector values, for every vectorized loop iteration. If\n-\/\/ we encounter the following pattern, we can vector accumulate the values\n-\/\/ inside the loop, and only have a single UnorderedReduction after the loop.\n-\/\/\n-\/\/ Note: UnorderedReduction represents a ReductionNode which does not require\n-\/\/ calculating in strict order.\n-\/\/\n-\/\/ CountedLoop     init\n-\/\/          |        |\n-\/\/          +------+ | +-----------------------+\n-\/\/                 | | |                       |\n-\/\/                PhiNode (s)                  |\n-\/\/                  |                          |\n-\/\/                  |          Vector          |\n-\/\/                  |            |             |\n-\/\/               UnorderedReduction (first_ur) |\n-\/\/                  |                          |\n-\/\/                 ...         Vector          |\n-\/\/                  |            |             |\n-\/\/               UnorderedReduction (last_ur)  |\n-\/\/                       |                     |\n-\/\/                       +---------------------+\n-\/\/\n-\/\/ We patch the graph to look like this:\n-\/\/\n-\/\/ CountedLoop   identity_vector\n-\/\/         |         |\n-\/\/         +-------+ | +---------------+\n-\/\/                 | | |               |\n-\/\/                PhiNode (v)          |\n-\/\/                   |                 |\n-\/\/                   |         Vector  |\n-\/\/                   |           |     |\n-\/\/                 VectorAccumulator   |\n-\/\/                   |                 |\n-\/\/                  ...        Vector  |\n-\/\/                   |           |     |\n-\/\/      init       VectorAccumulator   |\n-\/\/        |          |     |           |\n-\/\/     UnorderedReduction  +-----------+\n-\/\/\n-\/\/ We turned the scalar (s) Phi into a vectorized one (v). In the loop, we\n-\/\/ use vector_accumulators, which do the same reductions, but only element\n-\/\/ wise. This is a single operation per vector_accumulator, rather than many\n-\/\/ for a UnorderedReduction. We can then reduce the last vector_accumulator\n-\/\/ after the loop, and also reduce the init value into it.\n-\/\/\n-\/\/ We can not do this with all reductions. Some reductions do not allow the\n-\/\/ reordering of operations (for example float addition\/multiplication require\n-\/\/ strict order).\n-void PhaseIdealLoop::move_unordered_reduction_out_of_loop(IdealLoopTree* loop) {\n-  assert(!C->major_progress() && loop->is_counted() && loop->is_innermost(), \"sanity\");\n-\n-  \/\/ Find all Phi nodes with an unordered Reduction on backedge.\n-  CountedLoopNode* cl = loop->_head->as_CountedLoop();\n-  for (DUIterator_Fast jmax, j = cl->fast_outs(jmax); j < jmax; j++) {\n-    Node* phi = cl->fast_out(j);\n-    \/\/ We have a phi with a single use, and an unordered Reduction on the backedge.\n-    if (!phi->is_Phi() || phi->outcnt() != 1 || !is_unordered_reduction(phi->in(2))) {\n-      continue;\n-    }\n-\n-    ReductionNode* last_ur = phi->in(2)->as_Reduction();\n-    assert(!last_ur->requires_strict_order(), \"must be\");\n-\n-    \/\/ Determine types\n-    const TypeVect* vec_t = last_ur->vect_type();\n-    uint vector_length    = vec_t->length();\n-    BasicType bt          = vec_t->element_basic_type();\n-\n-    \/\/ Convert opcode from vector-reduction -> scalar -> normal-vector-op\n-    const int sopc        = VectorNode::scalar_opcode(last_ur->Opcode(), bt);\n-    const int vopc        = VectorNode::opcode(sopc, bt);\n-    if (!Matcher::match_rule_supported_vector(vopc, vector_length, bt)) {\n-        DEBUG_ONLY( last_ur->dump(); )\n-        assert(false, \"do not have normal vector op for this reduction\");\n-        continue; \/\/ not implemented -> fails\n-    }\n-\n-    \/\/ Traverse up the chain of unordered Reductions, checking that it loops back to\n-    \/\/ the phi. Check that all unordered Reductions only have a single use, except for\n-    \/\/ the last (last_ur), which only has phi as a use in the loop, and all other uses\n-    \/\/ are outside the loop.\n-    ReductionNode* current = last_ur;\n-    ReductionNode* first_ur = nullptr;\n-    while (true) {\n-      assert(!current->requires_strict_order(), \"sanity\");\n-\n-      \/\/ Expect no ctrl and a vector_input from within the loop.\n-      Node* ctrl = current->in(0);\n-      Node* vector_input = current->in(2);\n-      if (ctrl != nullptr || get_ctrl(vector_input) != cl) {\n-        DEBUG_ONLY( current->dump(1); )\n-        assert(false, \"reduction has ctrl or bad vector_input\");\n-        break; \/\/ Chain traversal fails.\n-      }\n-\n-      assert(current->vect_type() != nullptr, \"must have vector type\");\n-      if (current->vect_type() != last_ur->vect_type()) {\n-        \/\/ Reductions do not have the same vector type (length and element type).\n-        break; \/\/ Chain traversal fails.\n-      }\n-\n-      \/\/ Expect single use of an unordered Reduction, except for last_ur.\n-      if (current == last_ur) {\n-        \/\/ Expect all uses to be outside the loop, except phi.\n-        for (DUIterator_Fast kmax, k = current->fast_outs(kmax); k < kmax; k++) {\n-          Node* use = current->fast_out(k);\n-          if (use != phi && ctrl_or_self(use) == cl) {\n-            DEBUG_ONLY( current->dump(-1); )\n-            assert(false, \"reduction has use inside loop\");\n-            \/\/ Should not be allowed by SuperWord::mark_reductions\n-            return; \/\/ bail out of optimization\n-          }\n-        }\n-      } else {\n-        if (current->outcnt() != 1) {\n-          break; \/\/ Chain traversal fails.\n-        }\n-      }\n-\n-      \/\/ Expect another unordered Reduction or phi as the scalar input.\n-      Node* scalar_input = current->in(1);\n-      if (is_unordered_reduction(scalar_input) &&\n-          scalar_input->Opcode() == current->Opcode()) {\n-        \/\/ Move up the unordered Reduction chain.\n-        current = scalar_input->as_Reduction();\n-        assert(!current->requires_strict_order(), \"must be\");\n-      } else if (scalar_input == phi) {\n-        \/\/ Chain terminates at phi.\n-        first_ur = current;\n-        current = nullptr;\n-        break; \/\/ Success.\n-      } else {\n-        \/\/ scalar_input is neither phi nor a matching reduction\n-        \/\/ Can for example be scalar reduction when we have\n-        \/\/ partial vectorization.\n-        break; \/\/ Chain traversal fails.\n-      }\n-    }\n-    if (current != nullptr) {\n-      \/\/ Chain traversal was not successful.\n-      continue;\n-    }\n-    assert(first_ur != nullptr, \"must have successfully terminated chain traversal\");\n-\n-    Node* identity_scalar = ReductionNode::make_identity_con_scalar(_igvn, sopc, bt);\n-    set_root_as_ctrl(identity_scalar);\n-    VectorNode* identity_vector = VectorNode::scalar2vector(identity_scalar, vector_length, bt);\n-    register_new_node(identity_vector, C->root());\n-    assert(vec_t == identity_vector->vect_type(), \"matching vector type\");\n-    VectorNode::trace_new_vector(identity_vector, \"Unordered Reduction\");\n-\n-    \/\/ Turn the scalar phi into a vector phi.\n-    _igvn.rehash_node_delayed(phi);\n-    Node* init = phi->in(1); \/\/ Remember init before replacing it.\n-    phi->set_req_X(1, identity_vector, &_igvn);\n-    phi->as_Type()->set_type(vec_t);\n-    _igvn.set_type(phi, vec_t);\n-\n-    \/\/ Traverse down the chain of unordered Reductions, and replace them with vector_accumulators.\n-    current = first_ur;\n-    while (true) {\n-      \/\/ Create vector_accumulator to replace current.\n-      Node* last_vector_accumulator = current->in(1);\n-      Node* vector_input            = current->in(2);\n-      VectorNode* vector_accumulator = VectorNode::make(vopc, last_vector_accumulator, vector_input, vec_t);\n-      register_new_node(vector_accumulator, cl);\n-      _igvn.replace_node(current, vector_accumulator);\n-      VectorNode::trace_new_vector(vector_accumulator, \"Unordered Reduction\");\n-      if (current == last_ur) {\n-        break;\n-      }\n-      current = vector_accumulator->unique_out()->as_Reduction();\n-      assert(!current->requires_strict_order(), \"must be\");\n-    }\n-\n-    \/\/ Create post-loop reduction.\n-    Node* last_accumulator = phi->in(2);\n-    Node* post_loop_reduction = ReductionNode::make(sopc, nullptr, init, last_accumulator, bt);\n-\n-    \/\/ Take over uses of last_accumulator that are not in the loop.\n-    for (DUIterator i = last_accumulator->outs(); last_accumulator->has_out(i); i++) {\n-      Node* use = last_accumulator->out(i);\n-      if (use != phi && use != post_loop_reduction) {\n-        assert(ctrl_or_self(use) != cl, \"use must be outside loop\");\n-        use->replace_edge(last_accumulator, post_loop_reduction,  &_igvn);\n-        --i;\n-      }\n-    }\n-    register_new_node(post_loop_reduction, get_late_ctrl(post_loop_reduction, cl));\n-    VectorNode::trace_new_vector(post_loop_reduction, \"Unordered Reduction\");\n-\n-    assert(last_accumulator->outcnt() == 2, \"last_accumulator has 2 uses: phi and post_loop_reduction\");\n-    assert(post_loop_reduction->outcnt() > 0, \"should have taken over all non loop uses of last_accumulator\");\n-    assert(phi->outcnt() == 1, \"accumulator is the only use of phi\");\n-  }\n-}\n-\n","filename":"src\/hotspot\/share\/opto\/loopopts.cpp","additions":0,"deletions":205,"binary":false,"changes":205,"status":"modified"},{"patch":"@@ -1019,1 +1019,1 @@\n-static bool mask_shift_amount(PhaseGVN* phase, const Node* shift_node, uint nBits, int& real_shift, int& masked_shift) {\n+static bool mask_shift_amount(PhaseGVN* phase, const Node* shift_node, uint nBits, int& real_shift, uint& masked_shift) {\n@@ -1028,1 +1028,1 @@\n-static bool mask_shift_amount(PhaseGVN* phase, const Node* shift_node, uint nBits, int& masked_shift) {\n+static bool mask_shift_amount(PhaseGVN* phase, const Node* shift_node, uint nBits, uint& masked_shift) {\n@@ -1035,1 +1035,1 @@\n-static int mask_and_replace_shift_amount(PhaseGVN* phase, Node* shift_node, uint nBits) {\n+static uint mask_and_replace_shift_amount(PhaseGVN* phase, Node* shift_node, uint nBits) {\n@@ -1037,1 +1037,1 @@\n-  int masked_shift;\n+  uint masked_shift;\n@@ -1044,1 +1044,1 @@\n-    if (real_shift != masked_shift) {\n+    if (real_shift != (int)masked_shift) {\n@@ -1069,1 +1069,1 @@\n-static Node* collapse_nested_shift_left(PhaseGVN* phase, const Node* outer_shift, int con_outer, BasicType bt) {\n+static Node* collapse_nested_shift_left(PhaseGVN* phase, const Node* outer_shift, uint con_outer, BasicType bt) {\n@@ -1076,2 +1076,2 @@\n-  int nbits = static_cast<int>(bits_per_java_integer(bt));\n-  int con_inner;\n+  uint nbits = bits_per_java_integer(bt);\n+  uint con_inner;\n@@ -1102,6 +1102,1 @@\n-  int count = 0;\n-  if (const_shift_count(phase, this, &count) && (count & (BitsPerJavaInteger - 1)) == 0) {\n-    \/\/ Shift by a multiple of 32 does nothing\n-    return in(1);\n-  }\n-  return this;\n+  return IdentityIL(phase, T_INT);\n@@ -1110,8 +1105,2 @@\n-\/\/------------------------------Ideal------------------------------------------\n-\/\/ If the right input is a constant, and the left input is an add of a\n-\/\/ constant, flatten the tree: (X+con1)<<con0 ==> X<<con0 + con1<<con0\n-\/\/\n-\/\/ Also collapse nested left-shifts with constant rhs:\n-\/\/ (X << con1) << con2 ==> X << (con1 + con2)\n-Node *LShiftINode::Ideal(PhaseGVN *phase, bool can_reshape) {\n-  int con = mask_and_replace_shift_amount(phase, this, BitsPerJavaInteger);\n+Node* LShiftNode::IdealIL(PhaseGVN* phase, bool can_reshape, BasicType bt) {\n+  uint con = mask_and_replace_shift_amount(phase, this, bits_per_java_integer(bt));\n@@ -1122,2 +1111,3 @@\n-  \/\/ Left input is an add?\n-  Node *add1 = in(1);\n+  \/\/ If the right input is a constant, and the left input is an add of a\n+  \/\/ constant, flatten the tree: (X+con1)<<con0 ==> X<<con0 + con1<<con0\n+  Node* add1 = in(1);\n@@ -1125,2 +1115,2 @@\n-  if( add1_op == Op_AddI ) {    \/\/ Left input is an add?\n-    assert( add1 != add1->in(1), \"dead loop in LShiftINode::Ideal\" );\n+  if (add1_op == Op_Add(bt)) {    \/\/ Left input is an add?\n+    assert(add1 != add1->in(1), \"dead loop in LShiftINode::Ideal\");\n@@ -1130,1 +1120,1 @@\n-    if( con < 16 ) {\n+    if (bt != T_INT || con < 16) {\n@@ -1132,1 +1122,1 @@\n-      if (add1->in(1) == add1->in(2)) {\n+      if (con != (bits_per_java_integer(bt) - 1) && add1->in(1) == add1->in(2)) {\n@@ -1134,1 +1124,1 @@\n-        \/\/ In general, this optimization cannot be applied for c0 == 31 since\n+        \/\/ In general, this optimization cannot be applied for c0 == 31 (for LShiftI) since\n@@ -1136,1 +1126,6 @@\n-        return new LShiftINode(add1->in(1), phase->intcon(con + 1));\n+        \/\/ or c0 != 63 (for LShiftL) because:\n+        \/\/ (x + x) << 63 = 2x << 63, while\n+        \/\/ (x + x) << 63 --transform--> x << 64 = x << 0 = x (!= 2x << 63, for example for x = 1)\n+        \/\/ According to the Java spec, chapter 15.19, we only consider the six lowest-order bits of the right-hand operand\n+        \/\/ (i.e. \"right-hand operand\" & 0b111111). Therefore, x << 64 is the same as x << 0 (64 = 0b10000000 & 0b0111111 = 0).\n+        return LShiftNode::make(add1->in(1), phase->intcon(con + 1), bt);\n@@ -1140,2 +1135,2 @@\n-      const TypeInt *t12 = phase->type(add1->in(2))->isa_int();\n-      if( t12 && t12->is_con() ){ \/\/ Left input is an add of a con?\n+      const TypeInteger* t12 = phase->type(add1->in(2))->isa_integer(bt);\n+      if (t12 != nullptr && t12->is_con()) { \/\/ Left input is an add of a con?\n@@ -1143,1 +1138,1 @@\n-        Node *lsh = phase->transform( new LShiftINode( add1->in(1), in(2) ) );\n+        Node* lsh = phase->transform(LShiftNode::make(add1->in(1), in(2), bt));\n@@ -1145,1 +1140,1 @@\n-        return new AddINode( lsh, phase->intcon(t12->get_con() << con));\n+        return AddNode::make(lsh, phase->integercon(java_shift_left(t12->get_con_as_long(bt), con, bt), bt), bt);\n@@ -1151,1 +1146,1 @@\n-  if (add1_op == Op_RShiftI || add1_op == Op_URShiftI) {\n+  if (add1_op == Op_RShift(bt) || add1_op == Op_URShift(bt)) {\n@@ -1156,1 +1151,1 @@\n-    if (add1Con > 0 && con == add1Con) {\n+    if (add1Con > 0 && con == (uint)add1Con) {\n@@ -1158,1 +1153,1 @@\n-      return new AndINode(add1->in(1), phase->intcon(java_negate(jint(1 << con))));\n+      return  MulNode::make_and(add1->in(1), phase->integercon(java_negate(java_shift_left(1, con, bt), bt), bt), bt);\n@@ -1161,1 +1156,1 @@\n-      if (add1Con > 0 && add1Con < BitsPerJavaInteger) {\n+      if (add1Con > 0 && (uint)add1Con < bits_per_java_integer(bt)) {\n@@ -1165,1 +1160,1 @@\n-          if (con > add1Con) {\n+          if (con > (uint)add1Con) {\n@@ -1167,2 +1162,2 @@\n-            Node* lshift = phase->transform(new LShiftINode(add1->in(1), phase->intcon(con - add1Con)));\n-            return new AndINode(lshift, phase->intcon(java_negate(jint(1 << con))));\n+            Node* lshift = phase->transform(LShiftNode::make(add1->in(1), phase->intcon(con - add1Con), bt));\n+            return MulNode::make_and(lshift, phase->integercon(java_negate(java_shift_left(1, con, bt), bt), bt), bt);\n@@ -1170,1 +1165,1 @@\n-            assert(con < add1Con, \"must be (%d < %d)\", con, add1Con);\n+            assert(con < (uint)add1Con, \"must be (%d < %d)\", con, add1Con);\n@@ -1175,2 +1170,2 @@\n-            if (add1_op == Op_RShiftI) {\n-              rshift = phase->transform(new RShiftINode(add1->in(1), phase->intcon(add1Con - con)));\n+            if (add1_op == Op_RShift(bt)) {\n+              rshift = phase->transform(RShiftNode::make(add1->in(1), phase->intcon(add1Con - con), bt));\n@@ -1178,1 +1173,1 @@\n-              rshift = phase->transform(new URShiftINode(add1->in(1), phase->intcon(add1Con - con)));\n+              rshift = phase->transform(URShiftNode::make(add1->in(1), phase->intcon(add1Con - con), bt));\n@@ -1181,1 +1176,1 @@\n-            return new AndINode(rshift, phase->intcon(java_negate(jint(1 << con))));\n+            return MulNode::make_and(rshift, phase->integercon(java_negate(java_shift_left(1,  con, bt)), bt), bt);\n@@ -1191,2 +1186,2 @@\n-  if (add1_op == Op_AndI) {\n-    Node *add2 = add1->in(1);\n+  if (add1_op == Op_And(bt)) {\n+    Node* add2 = add1->in(1);\n@@ -1194,1 +1189,1 @@\n-    if (add2_op == Op_RShiftI || add2_op == Op_URShiftI) {\n+    if (add2_op == Op_RShift(bt) || add2_op == Op_URShift(bt)) {\n@@ -1198,2 +1193,2 @@\n-        Node* y_sh = phase->transform(new LShiftINode(add1->in(2), phase->intcon(con)));\n-        return new AndINode(add2->in(1), y_sh);\n+        Node* y_sh = phase->transform(LShiftNode::make(add1->in(2), phase->intcon(con), bt));\n+        return MulNode::make_and(add2->in(1), y_sh, bt);\n@@ -1204,1 +1199,1 @@\n-      if (add2Con > 0 && add2Con < BitsPerJavaInteger) {\n+      if (add2Con > 0 && (uint)add2Con < bits_per_java_integer(bt)) {\n@@ -1209,1 +1204,1 @@\n-          Node* x_sh = phase->transform(new LShiftINode(add2, phase->intcon(con)));\n+          Node* x_sh = phase->transform(LShiftNode::make(add2, phase->intcon(con), bt));\n@@ -1211,1 +1206,1 @@\n-          Node* y_sh = phase->transform(new LShiftINode(add1->in(2), phase->intcon(con)));\n+          Node* y_sh = phase->transform(LShiftNode::make(add1->in(2), phase->intcon(con), bt));\n@@ -1213,1 +1208,1 @@\n-          return new AndINode(x_sh, y_sh);\n+          return MulNode::make_and(x_sh, y_sh, bt);\n@@ -1223,4 +1218,6 @@\n-  const jint bits_mask = right_n_bits(BitsPerJavaInteger-con);\n-  if( add1_op == Op_AndI &&\n-      phase->type(add1->in(2)) == TypeInt::make( bits_mask ) )\n-    return new LShiftINode( add1->in(1), in(2) );\n+  const jlong bits_mask = max_unsigned_integer(bt) >> con;\n+  assert(bt != T_INT || bits_mask == right_n_bits(bits_per_java_integer(bt)-con), \"inconsistent\");\n+  if (add1_op == Op_And(bt) &&\n+      phase->type(add1->in(2)) == TypeInteger::make(bits_mask, bt)) {\n+    return LShiftNode::make(add1->in(1), in(2), bt);\n+  }\n@@ -1228,1 +1225,1 @@\n-  \/\/ Performs:\n+  \/\/ Collapse nested left-shifts with constant rhs:\n@@ -1230,1 +1227,1 @@\n-  Node* doubleShift = collapse_nested_shift_left(phase, this, con, T_INT);\n+  Node* doubleShift = collapse_nested_shift_left(phase, this, con, bt);\n@@ -1238,5 +1235,8 @@\n-\/\/------------------------------Value------------------------------------------\n-\/\/ A LShiftINode shifts its input2 left by input1 amount.\n-const Type* LShiftINode::Value(PhaseGVN* phase) const {\n-  const Type *t1 = phase->type( in(1) );\n-  const Type *t2 = phase->type( in(2) );\n+\/\/------------------------------Ideal------------------------------------------\n+Node* LShiftINode::Ideal(PhaseGVN *phase, bool can_reshape) {\n+  return IdealIL(phase, can_reshape, T_INT);\n+}\n+\n+const Type* LShiftNode::ValueIL(PhaseGVN* phase, BasicType bt) const {\n+  const Type* t1 = phase->type(in(1));\n+  const Type* t2 = phase->type(in(2));\n@@ -1244,2 +1244,6 @@\n-  if( t1 == Type::TOP ) return Type::TOP;\n-  if( t2 == Type::TOP ) return Type::TOP;\n+  if (t1 == Type::TOP) {\n+    return Type::TOP;\n+  }\n+  if (t2 == Type::TOP) {\n+    return Type::TOP;\n+  }\n@@ -1248,1 +1252,3 @@\n-  if( t1 == TypeInt::ZERO ) return TypeInt::ZERO;\n+  if (t1 == TypeInteger::zero(bt)) {\n+    return TypeInteger::zero(bt);\n+  }\n@@ -1250,1 +1256,3 @@\n-  if( t2 == TypeInt::ZERO ) return t1;\n+  if (t2 == TypeInt::ZERO) {\n+    return t1;\n+  }\n@@ -1253,3 +1261,4 @@\n-  if( (t1 == TypeInt::INT) || (t2 == TypeInt::INT) ||\n-      (t1 == Type::BOTTOM) || (t2 == Type::BOTTOM) )\n-    return TypeInt::INT;\n+  if ((t1 == TypeInteger::bottom(bt)) || (t2 == TypeInt::INT) ||\n+      (t1 == Type::BOTTOM) || (t2 == Type::BOTTOM)) {\n+    return TypeInteger::bottom(bt);\n+  }\n@@ -1257,2 +1266,2 @@\n-  const TypeInt *r1 = t1->is_int(); \/\/ Handy access\n-  const TypeInt *r2 = t2->is_int(); \/\/ Handy access\n+  const TypeInteger* r1 = t1->is_integer(bt); \/\/ Handy access\n+  const TypeInt* r2 = t2->is_int(); \/\/ Handy access\n@@ -1260,2 +1269,3 @@\n-  if (!r2->is_con())\n-    return TypeInt::INT;\n+  if (!r2->is_con()) {\n+    return TypeInteger::bottom(bt);\n+  }\n@@ -1264,3 +1274,5 @@\n-  shift &= BitsPerJavaInteger-1;  \/\/ semantics of Java shifts\n-  \/\/ Shift by a multiple of 32 does nothing:\n-  if (shift == 0)  return t1;\n+  shift &= bits_per_java_integer(bt) - 1;  \/\/ semantics of Java shifts\n+  \/\/ Shift by a multiple of 32\/64 does nothing:\n+  if (shift == 0) {\n+    return t1;\n+  }\n@@ -1271,3 +1283,10 @@\n-    jint lo = r1->_lo, hi = r1->_hi;\n-    if (((lo << shift) >> shift) == lo &&\n-        ((hi << shift) >> shift) == hi) {\n+    jlong lo = r1->lo_as_long(), hi = r1->hi_as_long();\n+#ifdef ASSERT\n+    if (bt == T_INT) {\n+      jint lo_int = r1->is_int()->_lo, hi_int = r1->is_int()->_hi;\n+      assert((java_shift_right(java_shift_left(lo, shift, bt),  shift, bt) == lo) == (((lo_int << shift) >> shift) == lo_int), \"inconsistent\");\n+      assert((java_shift_right(java_shift_left(hi, shift, bt),  shift, bt) == hi) == (((hi_int << shift) >> shift) == hi_int), \"inconsistent\");\n+    }\n+#endif\n+    if (java_shift_right(java_shift_left(lo, shift, bt),  shift, bt) == lo &&\n+        java_shift_right(java_shift_left(hi, shift, bt), shift, bt) == hi) {\n@@ -1275,3 +1294,3 @@\n-      return TypeInt::make((jint)lo << (jint)shift,\n-                           (jint)hi << (jint)shift,\n-                           MAX2(r1->_widen,r2->_widen));\n+      return TypeInteger::make(java_shift_left(lo, shift, bt),\n+                               java_shift_left(hi,  shift, bt),\n+                               MAX2(r1->_widen, r2->_widen), bt);\n@@ -1279,1 +1298,1 @@\n-    return TypeInt::INT;\n+    return TypeInteger::bottom(bt);\n@@ -1282,1 +1301,1 @@\n-  return TypeInt::make( (jint)r1->get_con() << (jint)shift );\n+  return TypeInteger::make(java_shift_left(r1->get_con_as_long(bt), shift, bt), bt);\n@@ -1285,3 +1304,6 @@\n-\/\/=============================================================================\n-\/\/------------------------------Identity---------------------------------------\n-Node* LShiftLNode::Identity(PhaseGVN* phase) {\n+\/\/------------------------------Value------------------------------------------\n+const Type* LShiftINode::Value(PhaseGVN* phase) const {\n+  return ValueIL(phase, T_INT);\n+}\n+\n+Node* LShiftNode::IdentityIL(PhaseGVN* phase, BasicType bt) {\n@@ -1289,2 +1311,2 @@\n-  if (const_shift_count(phase, this, &count) && (count & (BitsPerJavaLong - 1)) == 0) {\n-    \/\/ Shift by a multiple of 64 does nothing\n+  if (const_shift_count(phase, this, &count) && (count & (bits_per_java_integer(bt) - 1)) == 0) {\n+    \/\/ Shift by a multiple of 32\/64 does nothing\n@@ -1296,124 +1318,5 @@\n-\/\/------------------------------Ideal------------------------------------------\n-\/\/ If the right input is a constant, and the left input is an add of a\n-\/\/ constant, flatten the tree: (X+con1)<<con0 ==> X<<con0 + con1<<con0\n-\/\/\n-\/\/ Also collapse nested left-shifts with constant rhs:\n-\/\/ (X << con1) << con2 ==> X << (con1 + con2)\n-Node *LShiftLNode::Ideal(PhaseGVN *phase, bool can_reshape) {\n-  int con = mask_and_replace_shift_amount(phase, this, BitsPerJavaLong);\n-  if (con == 0) {\n-    return nullptr;\n-  }\n-\n-  \/\/ Left input is an add?\n-  Node *add1 = in(1);\n-  int add1_op = add1->Opcode();\n-  if( add1_op == Op_AddL ) {    \/\/ Left input is an add?\n-    \/\/ Avoid dead data cycles from dead loops\n-    assert( add1 != add1->in(1), \"dead loop in LShiftLNode::Ideal\" );\n-\n-    \/\/ Left input is an add of the same number?\n-    if (con != (BitsPerJavaLong - 1) && add1->in(1) == add1->in(2)) {\n-      \/\/ Convert \"(x + x) << c0\" into \"x << (c0 + 1)\"\n-      \/\/ Can only be applied if c0 != 63 because:\n-      \/\/ (x + x) << 63 = 2x << 63, while\n-      \/\/ (x + x) << 63 --transform--> x << 64 = x << 0 = x (!= 2x << 63, for example for x = 1)\n-      \/\/ According to the Java spec, chapter 15.19, we only consider the six lowest-order bits of the right-hand operand\n-      \/\/ (i.e. \"right-hand operand\" & 0b111111). Therefore, x << 64 is the same as x << 0 (64 = 0b10000000 & 0b0111111 = 0).\n-      return new LShiftLNode(add1->in(1), phase->intcon(con + 1));\n-    }\n-\n-    \/\/ Left input is an add of a constant?\n-    const TypeLong *t12 = phase->type(add1->in(2))->isa_long();\n-    if( t12 && t12->is_con() ){ \/\/ Left input is an add of a con?\n-      \/\/ Compute X << con0\n-      Node *lsh = phase->transform( new LShiftLNode( add1->in(1), in(2) ) );\n-      \/\/ Compute X<<con0 + (con1<<con0)\n-      return new AddLNode( lsh, phase->longcon(t12->get_con() << con));\n-    }\n-  }\n-\n-  \/\/ Check for \"(x >> C1) << C2\"\n-  if (add1_op == Op_RShiftL || add1_op == Op_URShiftL) {\n-    int add1Con = 0;\n-    const_shift_count(phase, add1, &add1Con);\n-\n-    \/\/ Special case C1 == C2, which just masks off low bits\n-    if (add1Con > 0 && con == add1Con) {\n-      \/\/ Convert to \"(x & -(1 << C2))\"\n-      return new AndLNode(add1->in(1), phase->longcon(java_negate(jlong(CONST64(1) << con))));\n-    } else {\n-      \/\/ Wait until the right shift has been sharpened to the correct count\n-      if (add1Con > 0 && add1Con < BitsPerJavaLong) {\n-        \/\/ As loop parsing can produce LShiftI nodes, we should wait until the graph is fully formed\n-        \/\/ to apply optimizations, otherwise we can inadvertently stop vectorization opportunities.\n-        if (phase->is_IterGVN()) {\n-          if (con > add1Con) {\n-            \/\/ Creates \"(x << (C2 - C1)) & -(1 << C2)\"\n-            Node* lshift = phase->transform(new LShiftLNode(add1->in(1), phase->intcon(con - add1Con)));\n-            return new AndLNode(lshift, phase->longcon(java_negate(jlong(CONST64(1) << con))));\n-          } else {\n-            assert(con < add1Con, \"must be (%d < %d)\", con, add1Con);\n-            \/\/ Creates \"(x >> (C1 - C2)) & -(1 << C2)\"\n-\n-            \/\/ Handle logical and arithmetic shifts\n-            Node* rshift;\n-            if (add1_op == Op_RShiftL) {\n-              rshift = phase->transform(new RShiftLNode(add1->in(1), phase->intcon(add1Con - con)));\n-            } else {\n-              rshift = phase->transform(new URShiftLNode(add1->in(1), phase->intcon(add1Con - con)));\n-            }\n-\n-            return new AndLNode(rshift, phase->longcon(java_negate(jlong(CONST64(1) << con))));\n-          }\n-        } else {\n-          phase->record_for_igvn(this);\n-        }\n-      }\n-    }\n-  }\n-\n-  \/\/ Check for \"((x >> C1) & Y) << C2\"\n-  if (add1_op == Op_AndL) {\n-    Node* add2 = add1->in(1);\n-    int add2_op = add2->Opcode();\n-    if (add2_op == Op_RShiftL || add2_op == Op_URShiftL) {\n-      \/\/ Special case C1 == C2, which just masks off low bits\n-      if (add2->in(2) == in(2)) {\n-        \/\/ Convert to \"(x & (Y << C2))\"\n-        Node* y_sh = phase->transform(new LShiftLNode(add1->in(2), phase->intcon(con)));\n-        return new AndLNode(add2->in(1), y_sh);\n-      }\n-\n-      int add2Con = 0;\n-      const_shift_count(phase, add2, &add2Con);\n-      if (add2Con > 0 && add2Con < BitsPerJavaLong) {\n-        if (phase->is_IterGVN()) {\n-          \/\/ Convert to \"((x >> C1) << C2) & (Y << C2)\"\n-\n-          \/\/ Make \"(x >> C1) << C2\", which will get folded away by the rule above\n-          Node* x_sh = phase->transform(new LShiftLNode(add2, phase->intcon(con)));\n-          \/\/ Make \"Y << C2\", which will simplify when Y is a constant\n-          Node* y_sh = phase->transform(new LShiftLNode(add1->in(2), phase->intcon(con)));\n-\n-          return new AndLNode(x_sh, y_sh);\n-        } else {\n-          phase->record_for_igvn(this);\n-        }\n-      }\n-    }\n-  }\n-\n-  \/\/ Check for ((x & ((CONST64(1)<<(64-c0))-1)) << c0) which ANDs off high bits\n-  \/\/ before shifting them away.\n-  const jlong bits_mask = jlong(max_julong >> con);\n-  if( add1_op == Op_AndL &&\n-      phase->type(add1->in(2)) == TypeLong::make( bits_mask ) )\n-    return new LShiftLNode( add1->in(1), in(2) );\n-\n-  \/\/ Performs:\n-  \/\/ (X << con1) << con2 ==> X << (con1 + con2)\n-  Node* doubleShift = collapse_nested_shift_left(phase, this, con, T_LONG);\n-  if (doubleShift != nullptr) {\n-    return doubleShift;\n-  }\n+\/\/=============================================================================\n+\/\/------------------------------Identity---------------------------------------\n+Node* LShiftLNode::Identity(PhaseGVN* phase) {\n+  return IdentityIL(phase, T_LONG);\n+}\n@@ -1421,1 +1324,3 @@\n-  return nullptr;\n+\/\/------------------------------Ideal------------------------------------------\n+Node* LShiftLNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  return IdealIL(phase, can_reshape, T_LONG);\n@@ -1425,43 +1330,1 @@\n-\/\/ A LShiftLNode shifts its input2 left by input1 amount.\n-  const Type *t1 = phase->type( in(1) );\n-  const Type *t2 = phase->type( in(2) );\n-  \/\/ Either input is TOP ==> the result is TOP\n-  if( t1 == Type::TOP ) return Type::TOP;\n-  if( t2 == Type::TOP ) return Type::TOP;\n-\n-  \/\/ Left input is ZERO ==> the result is ZERO.\n-  if( t1 == TypeLong::ZERO ) return TypeLong::ZERO;\n-  \/\/ Shift by zero does nothing\n-  if( t2 == TypeInt::ZERO ) return t1;\n-\n-  \/\/ Either input is BOTTOM ==> the result is BOTTOM\n-  if( (t1 == TypeLong::LONG) || (t2 == TypeInt::INT) ||\n-      (t1 == Type::BOTTOM) || (t2 == Type::BOTTOM) )\n-    return TypeLong::LONG;\n-\n-  const TypeLong *r1 = t1->is_long(); \/\/ Handy access\n-  const TypeInt  *r2 = t2->is_int();  \/\/ Handy access\n-\n-  if (!r2->is_con())\n-    return TypeLong::LONG;\n-\n-  uint shift = r2->get_con();\n-  shift &= BitsPerJavaLong - 1;  \/\/ semantics of Java shifts\n-  \/\/ Shift by a multiple of 64 does nothing:\n-  if (shift == 0)  return t1;\n-\n-  \/\/ If the shift is a constant, shift the bounds of the type,\n-  \/\/ unless this could lead to an overflow.\n-  if (!r1->is_con()) {\n-    jlong lo = r1->_lo, hi = r1->_hi;\n-    if (((lo << shift) >> shift) == lo &&\n-        ((hi << shift) >> shift) == hi) {\n-      \/\/ No overflow.  The range shifts up cleanly.\n-      return TypeLong::make((jlong)lo << (jint)shift,\n-                            (jlong)hi << (jint)shift,\n-                            MAX2(r1->_widen,r2->_widen));\n-    }\n-    return TypeLong::LONG;\n-  }\n-\n-  return TypeLong::make( (jlong)r1->get_con() << (jint)shift );\n+  return ValueIL(phase, T_LONG);\n@@ -1705,0 +1568,12 @@\n+URShiftNode* URShiftNode::make(Node* in1, Node* in2, BasicType bt) {\n+  switch (bt) {\n+    case T_INT:\n+      return new URShiftINode(in1, in2);\n+    case T_LONG:\n+      return new URShiftLNode(in1, in2);\n+    default:\n+      fatal(\"Not implemented for %s\", type2name(bt));\n+  }\n+  return nullptr;\n+}\n+\n@@ -1740,1 +1615,1 @@\n-Node *URShiftINode::Ideal(PhaseGVN *phase, bool can_reshape) {\n+Node* URShiftINode::Ideal(PhaseGVN* phase, bool can_reshape) {\n@@ -1904,1 +1779,1 @@\n-Node *URShiftLNode::Ideal(PhaseGVN *phase, bool can_reshape) {\n+Node* URShiftLNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n","filename":"src\/hotspot\/share\/opto\/mulnode.cpp","additions":138,"deletions":263,"binary":false,"changes":401,"status":"modified"},{"patch":"@@ -2109,0 +2109,1 @@\n+Op_IL(RShift)\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -978,4 +978,3 @@\n-\/\/ Find a class with this name in this loader, using the caller's protection domain.\n-JVM_ENTRY(jclass, JVM_FindClassFromCaller(JNIEnv* env, const char* name,\n-                                          jboolean init, jobject loader,\n-                                          jclass caller))\n+\/\/ Find a class with this name in this loader.\n+JVM_ENTRY(jclass, JVM_FindClassFromLoader(JNIEnv* env, const char* name,\n+                                          jboolean init, jobject loader))\n@@ -987,1 +986,0 @@\n-  oop from_class = JNIHandles::resolve(caller);\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":3,"deletions":5,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1652,1 +1652,1 @@\n-  if (JvmtiExport::has_frame_pops(thread)) {\n+  if (!cont.entry()->is_virtual_thread() && JvmtiExport::has_frame_pops(thread)) {\n","filename":"src\/hotspot\/share\/runtime\/continuationFreezeThaw.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -102,1 +102,1 @@\n-static uintx chunk_oops_do(OopClosure* f, Chunk* chunk, char* chunk_top) {\n+static void chunk_oops_do(OopClosure* f, Chunk* chunk, char* chunk_top) {\n@@ -105,3 +105,1 @@\n-  uintx handles_visited = top - bottom;\n-  \/\/ during GC phase 3, a handle may be a forward pointer that\n-  \/\/ is not yet valid, so loosen the assertion\n+\n@@ -112,1 +110,0 @@\n-  return handles_visited;\n@@ -116,2 +113,2 @@\n-  uintx handles_visited = 0;\n-  handles_visited += chunk_oops_do(f, _chunk, _hwm);\n+  chunk_oops_do(f, _chunk, _hwm);\n+\n@@ -122,1 +119,1 @@\n-    handles_visited += chunk_oops_do(f, k, k->top());\n+    chunk_oops_do(f, k, k->top());\n@@ -125,2 +122,0 @@\n-\n-  if (_prev != nullptr) _prev->oops_do(f);\n","filename":"src\/hotspot\/share\/runtime\/handles.cpp","additions":5,"deletions":10,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -190,1 +190,0 @@\n-  HandleArea* _prev;          \/\/ link to outer (older) area\n@@ -193,1 +192,1 @@\n-  HandleArea(MemTag mem_tag, HandleArea* prev) : Arena(mem_tag, Tag::tag_ha, Chunk::tiny_size) {\n+  HandleArea(MemTag mem_tag) : Arena(mem_tag, Tag::tag_ha, Chunk::tiny_size) {\n@@ -196,1 +195,0 @@\n-    _prev = prev;\n","filename":"src\/hotspot\/share\/runtime\/handles.hpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -165,5 +165,0 @@\n-  LogTarget(Trace, safepoint) lt;\n-  if (lt.is_enabled()) {\n-    LogStream ls(lt);\n-    cur_state->print_on(&ls);\n-  }\n@@ -227,0 +222,2 @@\n+  log_trace(safepoint)(\"%d total threads, waiting for %d threads to block\", nof_threads, still_running);\n+\n@@ -237,0 +234,2 @@\n+    log_trace(safepoint)(\"Checking thread status\");\n+\n@@ -247,0 +246,2 @@\n+        log_trace(safepoint)(\"Thread \" INTPTR_FORMAT \" [%d] is now blocked\",\n+                             p2i(cur_tss->thread()), cur_tss->thread()->osthread()->thread_id());\n@@ -253,0 +254,2 @@\n+        log_trace(safepoint)(\"Thread \" INTPTR_FORMAT \" [%d] is still running\",\n+                             p2i(cur_tss->thread()), cur_tss->thread()->osthread()->thread_id());\n@@ -262,0 +265,1 @@\n+      log_trace(safepoint)(\"Waiting for %d threads to block\", still_running);\n@@ -336,0 +340,1 @@\n+  log_trace(safepoint)(\"Suspending GC threads\");\n@@ -340,0 +345,1 @@\n+  log_trace(safepoint)(\"Blocking threads from starting\/exiting\");\n@@ -348,2 +354,0 @@\n-  log_debug(safepoint)(\"Safepoint synchronization initiated using %s wait barrier. (%d threads)\", _wait_barrier->description(), nof_threads);\n-\n@@ -368,0 +372,1 @@\n+  log_trace(safepoint)(\"Arming safepoint using %s wait barrier\", _wait_barrier->description());\n@@ -475,0 +480,1 @@\n+  log_trace(safepoint)(\"Disarming safepoint\");\n@@ -477,0 +483,1 @@\n+  log_trace(safepoint)(\"Resuming GC threads\");\n@@ -555,0 +562,3 @@\n+  log_trace(safepoint)(\"Blocking thread \" INTPTR_FORMAT \" [%d]\",\n+                       p2i(thread), thread->osthread()->thread_id());\n+\n@@ -598,0 +608,3 @@\n+\n+  log_trace(safepoint)(\"Unblocking thread \" INTPTR_FORMAT \" [%d]\",\n+                       p2i(thread), thread->osthread()->thread_id());\n@@ -978,0 +991,1 @@\n+  log_debug(safepoint)(\"Safepoint synchronization initiated\");\n@@ -986,0 +1000,1 @@\n+  log_debug(safepoint)(\"Safepoint synchronization complete\");\n@@ -990,0 +1005,1 @@\n+  log_debug(safepoint)(\"Leaving safepoint\");\n@@ -1024,0 +1040,1 @@\n+  log_debug(safepoint)(\"Safepoint complete\");\n","filename":"src\/hotspot\/share\/runtime\/safepoint.cpp","additions":24,"deletions":7,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -75,0 +75,1 @@\n+#include \"runtime\/osThread.hpp\"\n@@ -686,2 +687,5 @@\n-  log_debug(safepoint)(\"... found polling page %s exception at pc = \"\n-                       INTPTR_FORMAT \", stub =\" INTPTR_FORMAT,\n+  log_trace(safepoint)(\"Polling page exception: thread = \" INTPTR_FORMAT \" [%d], pc = \"\n+                       INTPTR_FORMAT \" (%s), stub = \" INTPTR_FORMAT,\n+                       p2i(Thread::current()),\n+                       Thread::current()->osthread()->thread_id(),\n+                       p2i(pc),\n@@ -689,1 +693,1 @@\n-                       (intptr_t)pc, (intptr_t)stub);\n+                       p2i(stub));\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"utilities\/checkedCast.hpp\"\n@@ -1269,0 +1270,26 @@\n+inline jlong java_negate(jlong v, BasicType bt) {\n+  if (bt == T_INT) {\n+    return java_negate(checked_cast<jint>(v));\n+  }\n+  assert(bt == T_LONG, \"int or long only\");\n+  return java_negate(v);\n+}\n+\n+\/\/ Some convenient bit shift operations that accepts a BasicType as the last\n+\/\/ argument. These avoid potential mistakes with overloaded functions only\n+\/\/ distinguished by lhs argument type.\n+#define JAVA_INTEGER_SHIFT_BASIC_TYPE(FUNC)            \\\n+inline jlong FUNC(jlong lhs, jint rhs, BasicType bt) { \\\n+  if (bt == T_INT) {                                   \\\n+    return FUNC(checked_cast<jint>(lhs), rhs);         \\\n+  }                                                    \\\n+  assert(bt == T_LONG, \"unsupported basic type\");      \\\n+  return FUNC(lhs, rhs);                              \\\n+}\n+\n+JAVA_INTEGER_SHIFT_BASIC_TYPE(java_shift_left)\n+JAVA_INTEGER_SHIFT_BASIC_TYPE(java_shift_right)\n+JAVA_INTEGER_SHIFT_BASIC_TYPE(java_shift_right_unsigned)\n+\n+#undef JAVA_INTERGER_SHIFT_BASIC_TYPE\n+\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":27,"deletions":0,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -484,1 +484,1 @@\n-        return forName0(className, true, loader, caller);\n+        return forName0(className, true, loader);\n@@ -565,1 +565,1 @@\n-        return forName0(name, initialize, loader, null);\n+        return forName0(name, initialize, loader);\n@@ -570,2 +570,1 @@\n-                                            ClassLoader loader,\n-                                            Class<?> caller)\n+                                            ClassLoader loader)\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Class.java","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -433,2 +433,2 @@\n-                                                     \/* -1022+126 *\/\n-                                                     Double.MIN_EXPONENT-\n+                                                     \/\/ -1022 + 126\n+                                                     Double.MIN_EXPONENT -\n@@ -436,1 +436,3 @@\n-            return s.replaceFirst(\"p-1022$\", \"p-126\");\n+            \/\/ The char sequence \"-1022\" can only appear in the\n+            \/\/ representation of the exponent, not in the (hex) significand.\n+            return s.replace(\"-1022\", \"-126\");\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Float.java","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1558,7 +1558,0 @@\n-    \/\/ Return TRUE if all code paths starting with start_bc_offset end in\n-    \/\/ bytecode athrow or loop.\n-    boolean ends_in_athrow(int start_bc_offset) {\n-        log_info(\"unimplemented VerifierImpl.ends_in_athrow\");\n-        return true;\n-    }\n-\n@@ -1582,10 +1575,0 @@\n-                for(var exhandler : _method.exceptionTable()) {\n-                    int start_pc = exhandler[0];\n-                    int end_pc = exhandler[1];\n-\n-                    if (bci >= start_pc && bci < end_pc) {\n-                        if (!ends_in_athrow(exhandler[2])) {\n-                            verifyError(\"Bad <init> method call from after the start of a try block\");\n-                        }\n-                    }\n-                }\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/classfile\/impl\/verifier\/VerifierImpl.java","additions":0,"deletions":17,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -1690,0 +1690,5 @@\n+    public static final String POPCOUNT_I = PREFIX + \"POPCOUNT_I\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(POPCOUNT_I, \"PopCountI\");\n+    }\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/IRNode.java","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -68,1 +68,1 @@\n-            Pattern.compile(\".*Internal Error \\\\(0x2a\\\\).*\")\n+            Pattern.compile(\".*Internal Error \\\\(0xdeadbeef\\\\).*\")\n","filename":"test\/hotspot\/jtreg\/runtime\/ErrorHandling\/UncaughtNativeExceptionTest.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2022, 2024, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2022, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -33,2 +33,0 @@\n-javax\/management\/remote\/mandatory\/connection\/BrokenConnectionTest.java 8308035 windows-x64\n-\n@@ -37,2 +35,0 @@\n-javax\/management\/remote\/mandatory\/loading\/RMIDownloadTest.java 8308366 windows-x64\n-\n","filename":"test\/jdk\/ProblemList-Virtual.txt","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -766,1 +766,0 @@\n-jdk\/jfr\/jvm\/TestWaste.java                                      8282427 generic-all\n","filename":"test\/jdk\/ProblemList.txt","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -328,2 +328,1 @@\n-    jdk\/internal\/jrtfs \\\n-    sun\/tools\/jrunscript\n+    jdk\/internal\/jrtfs\n@@ -334,1 +333,0 @@\n-    -sun\/tools\/jrunscript \\\n","filename":"test\/jdk\/TEST.groups","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -386,0 +386,1 @@\n+        vmOptFinalFlag(map, \"UseAdaptiveSizePolicy\");\n","filename":"test\/jtreg-ext\/requires\/VMProps.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2011, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2011, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,0 @@\n- * @author  Joseph D. Darcy\n","filename":"test\/langtools\/tools\/javac\/processing\/model\/TestSourceVersion.java","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -0,0 +1,246 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package jdk.test.lib.os.linux;\n+\n+import java.math.BigInteger;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.nio.file.StandardCopyOption;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+public class Smaps {\n+\n+    \/\/ List of memory ranges\n+    private List<Range> ranges;\n+\n+    protected Smaps(List<Range> ranges) {\n+        this.ranges = ranges;\n+    }\n+\n+    \/\/ Search for a range including the given address.\n+    public Range getRange(String addr) {\n+        BigInteger laddr = new BigInteger(addr.substring(2), 16);\n+        for (Range range : ranges) {\n+            if (range.includes(laddr)) {\n+                return range;\n+            }\n+        }\n+\n+        return null;\n+    }\n+\n+    public static Smaps parseSelf() throws Exception {\n+        return parse(Path.of(\"\/proc\/self\/smaps\"));\n+    }\n+\n+    public static Smaps parse(Path smaps) throws Exception {\n+        return new Parser(smaps).parse();\n+    }\n+\n+    \/\/ This is a simple smaps parser; it will recognize smaps section start lines\n+    \/\/  (e.g. \"40fa00000-439b80000 rw-p 00000000 00:00 0 \") and look for keywords inside the section.\n+    \/\/ Section will be finished and written into a RangeWithPageSize when either the next section is found\n+    \/\/  or the end of file is encountered.\n+    private static class Parser {\n+\n+        private static final Pattern SECTION_START_PATT = Pattern.compile(\"^([a-f0-9]+)-([a-f0-9]+) [\\\\-rwpsx]{4}.*\");\n+        private static final Pattern KERNEL_PAGESIZE_PATT = Pattern.compile(\"^KernelPageSize:\\\\s*(\\\\d*) kB\");\n+        private static final Pattern THP_ELIGIBLE_PATT = Pattern.compile(\"^THPeligible:\\\\s+(\\\\d*)\");\n+        private static final Pattern VMFLAGS_PATT = Pattern.compile(\"^VmFlags: ([\\\\w\\\\? ]*)\");\n+\n+        String start;\n+        String end;\n+        String ps;\n+        String thpEligible;\n+        String vmFlags;\n+\n+        List<Range> ranges;\n+        Path smaps;\n+\n+        Parser(Path smaps) {\n+            this.ranges = new LinkedList<Range>();\n+            this.smaps = smaps;\n+            super();\n+            reset();\n+        }\n+\n+        void reset() {\n+            start = null;\n+            end = null;\n+            ps = null;\n+            thpEligible = null;\n+            vmFlags = null;\n+        }\n+\n+        public void finish() {\n+            if (start != null) {\n+                Range range = new Range(start, end, ps, thpEligible, vmFlags);\n+                ranges.add(range);\n+                reset();\n+            }\n+        }\n+\n+        public void eatNext(String line) {\n+            \/\/  For better debugging experience call finish here before the debug() call.\n+            Matcher matSectionStart = SECTION_START_PATT.matcher(line);\n+            if (matSectionStart.matches()) {\n+                finish();\n+            }\n+\n+            if (matSectionStart.matches()) {\n+                start = matSectionStart.group(1);\n+                end = matSectionStart.group(2);\n+                ps = null;\n+                vmFlags = null;\n+                return;\n+            } else {\n+                Matcher matKernelPageSize = KERNEL_PAGESIZE_PATT.matcher(line);\n+                if (matKernelPageSize.matches()) {\n+                    ps = matKernelPageSize.group(1);\n+                    return;\n+                }\n+                Matcher matTHPEligible = THP_ELIGIBLE_PATT.matcher(line);\n+                if (matTHPEligible.matches()) {\n+                    thpEligible = matTHPEligible.group(1);\n+                    return;\n+                }\n+                Matcher matVmFlags = VMFLAGS_PATT.matcher(line);\n+                if (matVmFlags.matches()) {\n+                    vmFlags = matVmFlags.group(1);\n+                    return;\n+                }\n+            }\n+        }\n+\n+        \/\/ Copy smaps locally\n+        \/\/ (To minimize chances of concurrent modification when parsing, as well as helping with error analysis)\n+        private Path copySmaps() throws Exception {\n+            Path copy = Paths.get(\"smaps-copy-\" +  ProcessHandle.current().pid() + \"-\" + System.nanoTime() + \".txt\");\n+            Files.copy(smaps, copy, StandardCopyOption.REPLACE_EXISTING);\n+            return copy;\n+        }\n+\n+        \/\/ Parse \/proc\/self\/smaps\n+        public Smaps parse() throws Exception {\n+            Path smapsCopy = copySmaps();\n+            Files.lines(smapsCopy).forEach(this::eatNext);\n+\n+            \/\/ Finish up the last range\n+            this.finish();\n+\n+            \/\/ Return a Smaps object with the parsed ranges\n+            return new Smaps(ranges);\n+        }\n+    }\n+\n+    \/\/ Class used to store information about memory ranges parsed\n+    \/\/ from \/proc\/self\/smaps. The file contain a lot of information\n+    \/\/ about the different mappings done by an application, but the\n+    \/\/ lines we care about are:\n+    \/\/ 700000000-73ea00000 rw-p 00000000 00:00 0\n+    \/\/ ...\n+    \/\/ KernelPageSize:        4 kB\n+    \/\/ ...\n+    \/\/ THPeligible:           0\n+    \/\/ ...\n+    \/\/ VmFlags: rd wr mr mw me ac sd\n+    \/\/\n+    \/\/ We use the VmFlags to know what kind of huge pages are used.\n+    \/\/ For transparent huge pages the KernelPageSize field will not\n+    \/\/ report the large page size.\n+    public static class Range {\n+\n+        private BigInteger start;\n+        private BigInteger end;\n+        private long pageSize;\n+        private boolean thpEligible;\n+        private boolean vmFlagHG;\n+        private boolean vmFlagHT;\n+        private boolean isTHP;\n+\n+        public Range(String start, String end, String pageSize, String thpEligible, String vmFlags) {\n+            \/\/ Note: since we insist on kernels >= 3.8, all the following information should be present\n+            \/\/  (none of the input strings be null).\n+            this.start = new BigInteger(start, 16);\n+            this.end = new BigInteger(end, 16);\n+            this.pageSize = Long.parseLong(pageSize);\n+            this.thpEligible = thpEligible == null ? false : (Integer.parseInt(thpEligible) == 1);\n+\n+            vmFlagHG = false;\n+            vmFlagHT = false;\n+            \/\/ Check if the vmFlags line include:\n+            \/\/ * ht - Meaning the range is mapped using explicit huge pages.\n+            \/\/ * hg - Meaning the range is madvised huge.\n+            for (String flag : vmFlags.split(\" \")) {\n+                if (flag.equals(\"ht\")) {\n+                    vmFlagHT = true;\n+                } else if (flag.equals(\"hg\")) {\n+                    vmFlagHG = true;\n+                }\n+            }\n+\n+            \/\/ When the THP policy is 'always' instead of 'madvise, the vmFlagHG property is false,\n+            \/\/ therefore also check thpEligible. If this is still causing problems in the future,\n+            \/\/ we might have to check the AnonHugePages field.\n+\n+            isTHP = vmFlagHG || this.thpEligible;\n+        }\n+\n+        public BigInteger getStart() {\n+            return start;\n+        }\n+\n+        public BigInteger getEnd() {\n+            return end;\n+        }\n+\n+        public long getPageSize() {\n+            return pageSize;\n+        }\n+\n+        public boolean isTransparentHuge() {\n+            return isTHP;\n+        }\n+\n+        public boolean isExplicitHuge() {\n+            return vmFlagHT;\n+        }\n+\n+        public boolean includes(BigInteger addr) {\n+            boolean isGreaterThanOrEqualStart = start.compareTo(addr) <= 0;\n+            boolean isLessThanEnd = addr.compareTo(end) < 0;\n+\n+            return isGreaterThanOrEqualStart && isLessThanEnd;\n+        }\n+\n+        public String toString() {\n+            return \"[\" + start.toString(16) + \", \" + end.toString(16) + \") \" +\n+                    \"pageSize=\" + pageSize + \"KB isTHP=\" + isTHP + \" isHUGETLB=\" + vmFlagHT;\n+        }\n+    }\n+}\n","filename":"test\/lib\/jdk\/test\/lib\/os\/linux\/Smaps.java","additions":246,"deletions":0,"binary":false,"changes":246,"status":"added"}]}