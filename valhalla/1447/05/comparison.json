{"files":[{"patch":"@@ -725,1 +725,1 @@\n-    if (!call->tf()->returns_inline_type_as_fields() && is_mh_late_inline() &&\n+    if (!call->tf()->returns_inline_type_as_fields() &&\n","filename":"src\/hotspot\/share\/opto\/callGenerator.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2846,0 +2846,11 @@\n+  {\n+    \/\/ Eliminate some macro nodes before EA to reduce analysis pressure\n+    PhaseMacroExpand mexp(igvn);\n+    mexp.eliminate_macro_nodes();\n+    if (failing()) {\n+      return;\n+    }\n+    igvn.set_delay_transform(false);\n+    print_method(PHASE_ITER_GVN_AFTER_ELIMINATION, 2);\n+  }\n+\n@@ -2852,1 +2863,13 @@\n-      if (failing())  return;\n+      if (failing()) {\n+        return;\n+      }\n+      print_method(PHASE_PHASEIDEAL_BEFORE_EA, 2);\n+\n+      \/\/ Eliminate some macro nodes before EA to reduce analysis pressure\n+      PhaseMacroExpand mexp(igvn);\n+      mexp.eliminate_macro_nodes();\n+      if (failing()) {\n+        return;\n+      }\n+      igvn.set_delay_transform(false);\n+      print_method(PHASE_ITER_GVN_AFTER_ELIMINATION, 2);\n@@ -2854,0 +2877,1 @@\n+\n@@ -2855,1 +2879,0 @@\n-    print_method(PHASE_PHASEIDEAL_BEFORE_EA, 2);\n@@ -2873,2 +2896,3 @@\n-        if (failing()) return;\n-\n+        if (failing()) {\n+          return;\n+        }\n@@ -2876,3 +2900,0 @@\n-        igvn.optimize();\n-        if (failing()) return;\n-\n@@ -2979,0 +3000,7 @@\n+    PhaseMacroExpand mex(igvn);\n+    \/\/ Last attempt to eliminate macro nodes.\n+    mex.eliminate_macro_nodes();\n+    if (failing()) {\n+      return;\n+    }\n+\n@@ -2980,1 +3008,0 @@\n-    PhaseMacroExpand  mex(igvn);\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":35,"deletions":8,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"classfile\/vmIntrinsics.hpp\"\n@@ -91,0 +92,58 @@\n+static bool arg_can_be_larval(ciMethod* callee, int arg_idx) {\n+  if (callee->is_object_constructor() && arg_idx == 0) {\n+    return true;\n+  }\n+\n+  if (arg_idx != 1 || callee->intrinsic_id() == vmIntrinsicID::_none) {\n+    return false;\n+  }\n+\n+  switch (callee->intrinsic_id()) {\n+    case vmIntrinsicID::_finishPrivateBuffer:\n+    case vmIntrinsicID::_putBoolean:\n+    case vmIntrinsicID::_putBooleanOpaque:\n+    case vmIntrinsicID::_putBooleanRelease:\n+    case vmIntrinsicID::_putBooleanVolatile:\n+    case vmIntrinsicID::_putByte:\n+    case vmIntrinsicID::_putByteOpaque:\n+    case vmIntrinsicID::_putByteRelease:\n+    case vmIntrinsicID::_putByteVolatile:\n+    case vmIntrinsicID::_putChar:\n+    case vmIntrinsicID::_putCharOpaque:\n+    case vmIntrinsicID::_putCharRelease:\n+    case vmIntrinsicID::_putCharUnaligned:\n+    case vmIntrinsicID::_putCharVolatile:\n+    case vmIntrinsicID::_putShort:\n+    case vmIntrinsicID::_putShortOpaque:\n+    case vmIntrinsicID::_putShortRelease:\n+    case vmIntrinsicID::_putShortUnaligned:\n+    case vmIntrinsicID::_putShortVolatile:\n+    case vmIntrinsicID::_putInt:\n+    case vmIntrinsicID::_putIntOpaque:\n+    case vmIntrinsicID::_putIntRelease:\n+    case vmIntrinsicID::_putIntUnaligned:\n+    case vmIntrinsicID::_putIntVolatile:\n+    case vmIntrinsicID::_putLong:\n+    case vmIntrinsicID::_putLongOpaque:\n+    case vmIntrinsicID::_putLongRelease:\n+    case vmIntrinsicID::_putLongUnaligned:\n+    case vmIntrinsicID::_putLongVolatile:\n+    case vmIntrinsicID::_putFloat:\n+    case vmIntrinsicID::_putFloatOpaque:\n+    case vmIntrinsicID::_putFloatRelease:\n+    case vmIntrinsicID::_putFloatVolatile:\n+    case vmIntrinsicID::_putDouble:\n+    case vmIntrinsicID::_putDoubleOpaque:\n+    case vmIntrinsicID::_putDoubleRelease:\n+    case vmIntrinsicID::_putDoubleVolatile:\n+    case vmIntrinsicID::_putReference:\n+    case vmIntrinsicID::_putReferenceOpaque:\n+    case vmIntrinsicID::_putReferenceRelease:\n+    case vmIntrinsicID::_putReferenceVolatile:\n+    case vmIntrinsicID::_putValue:\n+      return true;\n+    default:\n+      return false;\n+  }\n+}\n+\n@@ -648,0 +707,9 @@\n+  \/\/ Scalarize value objects passed into this invocation if we know that they are not larval\n+  for (int arg_idx = 0; arg_idx < nargs; arg_idx++) {\n+    if (arg_can_be_larval(callee, arg_idx)) {\n+      continue;\n+    }\n+\n+    cast_to_non_larval(peek(nargs - 1 - arg_idx));\n+  }\n+\n@@ -810,5 +878,0 @@\n-    if (rtype->is_inlinetype() && !peek()->is_InlineType()) {\n-      Node* retnode = pop();\n-      retnode = InlineTypeNode::make_from_oop(this, retnode, rtype->as_inline_klass());\n-      push_node(T_OBJECT, retnode);\n-    }\n@@ -816,45 +879,7 @@\n-    \/\/ Note that:\n-    \/\/ - The caller map is the state just before the call of the currently parsed method with all arguments\n-    \/\/   on the stack. Therefore, we have caller_map->arg(0) == this.\n-    \/\/ - local(0) contains the updated receiver after calling an inline type constructor.\n-    \/\/ - Abstract value classes are not ciInlineKlass instances and thus abstract_value_klass->is_inlinetype() is false.\n-    \/\/   We use the bottom type of the receiver node to determine if we have a value class or not.\n-    const bool is_current_method_inline_type_constructor =\n-        \/\/ Is current method a constructor (i.e <init>)?\n-        _method->is_object_constructor() &&\n-        \/\/ Is the holder of the current constructor method an inline type?\n-        _caller->map()->argument(_caller, 0)->bottom_type()->is_inlinetypeptr();\n-    assert(!is_current_method_inline_type_constructor || !cg->method()->is_object_constructor() || receiver != nullptr,\n-           \"must have valid receiver after calling another constructor\");\n-    if (is_current_method_inline_type_constructor &&\n-        \/\/ Is the just called method an inline type constructor?\n-        cg->method()->is_object_constructor() && receiver->bottom_type()->is_inlinetypeptr() &&\n-         \/\/ AND:\n-         \/\/ 1) ... invoked on the same receiver? Then it's another constructor on the same object doing the initialization.\n-        (receiver == _caller->map()->argument(_caller, 0) ||\n-         \/\/ 2) ... abstract? Then it's the call to the super constructor which eventually calls Object.<init> to\n-         \/\/                    finish the initialization of this larval.\n-         cg->method()->holder()->is_abstract() ||\n-         \/\/ 3) ... Object.<init>? Then we know it's the final call to finish the larval initialization. Other\n-         \/\/        Object.<init> calls would have a non-inline-type receiver which we already excluded in the check above.\n-         cg->method()->holder()->is_java_lang_Object())\n-        ) {\n-      assert(local(0)->is_InlineType() && receiver->bottom_type()->is_inlinetypeptr() && receiver->is_InlineType() &&\n-             _caller->map()->argument(_caller, 0)->bottom_type()->inline_klass() == receiver->bottom_type()->inline_klass(),\n-             \"Unexpected receiver\");\n-      InlineTypeNode* updated_receiver = local(0)->as_InlineType();\n-      InlineTypeNode* cloned_updated_receiver = updated_receiver->clone_if_required(&_gvn, _map);\n-      cloned_updated_receiver->set_is_larval(false);\n-      cloned_updated_receiver = _gvn.transform(cloned_updated_receiver)->as_InlineType();\n-      \/\/ Receiver updated by the just called constructor. We need to update the map to make the effect visible. After\n-      \/\/ the super() call, only the updated receiver in local(0) will be used from now on. Therefore, we do not need\n-      \/\/ to update the original receiver 'receiver' but only the 'updated_receiver'.\n-      replace_in_map(updated_receiver, cloned_updated_receiver);\n-\n-      if (_caller->has_method()) {\n-        \/\/ If the current method is inlined, we also need to update the exit map to propagate the updated receiver\n-        \/\/ to the caller map.\n-        Node* receiver_in_caller = _caller->map()->argument(_caller, 0);\n-        assert(receiver_in_caller->bottom_type()->inline_klass() == receiver->bottom_type()->inline_klass(),\n-               \"Receiver type mismatch\");\n-        _exits.map()->replace_edge(receiver_in_caller, cloned_updated_receiver, &_gvn);\n+    if (!rtype->is_void() && cg->method()->intrinsic_id() != vmIntrinsicID::_makePrivateBuffer) {\n+      Node* retnode = peek();\n+      const Type* rettype = gvn().type(retnode);\n+      if (rettype->is_inlinetypeptr() && !retnode->is_InlineType()) {\n+        retnode = InlineTypeNode::make_from_oop(this, retnode, rettype->inline_klass());\n+        dec_sp(1);\n+        push(retnode);\n@@ -863,0 +888,11 @@\n+\n+    if (cg->method()->is_object_constructor() && receiver != nullptr && gvn().type(receiver)->is_inlinetypeptr()) {\n+      InlineTypeNode* non_larval = InlineTypeNode::make_from_oop(this, receiver, gvn().type(receiver)->inline_klass());\n+      \/\/ Relinquish the oop input, we will delay the allocation to the point it is needed, see the\n+      \/\/ comments in InlineTypeNode::Ideal for more details\n+      non_larval = non_larval->clone_if_required(&gvn(), nullptr);\n+      non_larval->set_oop(gvn(), null());\n+      non_larval->set_is_buffered(gvn(), false);\n+      non_larval = gvn().transform(non_larval)->as_InlineType();\n+      map()->replace_edge(receiver, non_larval);\n+    }\n","filename":"src\/hotspot\/share\/opto\/doCall.cpp","additions":86,"deletions":50,"binary":false,"changes":136,"status":"modified"},{"patch":"@@ -993,8 +993,1 @@\n-        Node* val = in_map->in(k + j);\n-        \/\/ Check if there's a larval that has been written in the callee state (constructor) and update it in the caller state\n-        if (callee_jvms != nullptr && val->is_InlineType() && val->as_InlineType()->is_larval() &&\n-            callee_jvms->method()->is_object_constructor() && val == in_map->argument(in_jvms, 0) &&\n-            val->bottom_type()->is_inlinetypeptr()) {\n-          val = callee_jvms->map()->local(callee_jvms, 0); \/\/ Receiver\n-        }\n-        call->set_req(p++, val);\n+        call->set_req(p++, in_map->in(k + j));\n@@ -1012,8 +1005,1 @@\n-        Node* val = in_map->in(k + j);\n-        \/\/ Check if there's a larval that has been written in the callee state (constructor) and update it in the caller state\n-        if (callee_jvms != nullptr && val->is_InlineType() && val->as_InlineType()->is_larval() &&\n-            callee_jvms->method()->is_object_constructor() && val == in_map->argument(in_jvms, 0) &&\n-            val->bottom_type()->is_inlinetypeptr()) {\n-          val = callee_jvms->map()->local(callee_jvms, 0); \/\/ Receiver\n-        }\n-        call->set_req(p++, val);\n+        call->set_req(p++, in_map->in(k + j));\n@@ -1518,0 +1504,11 @@\n+Node* GraphKit::cast_to_non_larval(Node* obj) {\n+  const Type* obj_type = gvn().type(obj);\n+  if (obj->is_InlineType() || !obj_type->is_inlinetypeptr()) {\n+    return obj;\n+  }\n+\n+  Node* new_obj = InlineTypeNode::make_from_oop(this, obj, obj_type->inline_klass());\n+  replace_in_map(obj, new_obj);\n+  return new_obj;\n+}\n+\n@@ -1923,22 +1920,1 @@\n-      InlineTypeNode* inline_type = arg->as_InlineType();\n-      const ciMethod* method = call->method();\n-      ciInstanceKlass* holder = method->holder();\n-      const bool is_receiver = (i == TypeFunc::Parms);\n-      const bool is_abstract_or_object_klass_constructor = method->is_object_constructor() &&\n-                                                           (holder->is_abstract() || holder->is_java_lang_Object());\n-      const bool is_larval_receiver_on_super_constructor = is_receiver && is_abstract_or_object_klass_constructor;\n-      bool must_init_buffer = true;\n-      \/\/ We always need to buffer inline types when they are escaping. However, we can skip the actual initialization\n-      \/\/ of the buffer if the inline type is a larval because we are going to update the buffer anyway which requires\n-      \/\/ us to create a new one. But there is one special case where we are still required to initialize the buffer:\n-      \/\/ When we have a larval receiver invoked on an abstract (value class) constructor or the Object constructor (that\n-      \/\/ is not going to be inlined). After this call, the larval is completely initialized and thus not a larval anymore.\n-      \/\/ We therefore need to force an initialization of the buffer to not lose all the field writes so far in case the\n-      \/\/ buffer needs to be used (e.g. to read from when deoptimizing at runtime) or further updated in abstract super\n-      \/\/ value class constructors which could have more fields to be initialized. Note that we do not need to\n-      \/\/ initialize the buffer when invoking another constructor in the same class on a larval receiver because we\n-      \/\/ have not initialized any fields, yet (this is done completely by the other constructor call).\n-      if (inline_type->is_larval() && !is_larval_receiver_on_super_constructor) {\n-        must_init_buffer = false;\n-      }\n-      arg = inline_type->buffer(this, true, must_init_buffer);\n+      arg = arg->as_InlineType()->buffer(this, true);\n@@ -2021,14 +1997,0 @@\n-  \/\/ We just called the constructor on a value type receiver. Reload it from the buffer\n-  ciMethod* method = call->method();\n-  if (method->is_object_constructor() && !method->holder()->is_java_lang_Object()) {\n-    InlineTypeNode* inline_type_receiver = call->in(TypeFunc::Parms)->isa_InlineType();\n-    if (inline_type_receiver != nullptr) {\n-      assert(inline_type_receiver->is_larval(), \"must be larval\");\n-      assert(inline_type_receiver->is_allocated(&gvn()), \"larval must be buffered\");\n-      InlineTypeNode* reloaded = InlineTypeNode::make_from_oop(this, inline_type_receiver->get_oop(),\n-                                                               inline_type_receiver->bottom_type()->inline_klass());\n-      assert(!reloaded->is_larval(), \"should not be larval anymore\");\n-      replace_in_map(inline_type_receiver, reloaded);\n-    }\n-  }\n-\n@@ -3461,1 +3423,1 @@\n-Node* GraphKit::gen_checkcast(Node* obj, Node* superklass, Node* *failure_control, bool null_free) {\n+Node* GraphKit::gen_checkcast(Node* obj, Node* superklass, Node* *failure_control, bool null_free, bool maybe_larval) {\n@@ -3477,0 +3439,3 @@\n+  \/\/ Else it must be a non-larval object\n+  obj = cast_to_non_larval(obj);\n+\n@@ -3707,1 +3672,1 @@\n-    if (toop->is_inlinetypeptr()) {\n+    if (toop->is_inlinetypeptr() && !maybe_larval) {\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":19,"deletions":54,"binary":false,"changes":73,"status":"modified"},{"patch":"@@ -453,0 +453,7 @@\n+  \/\/ If a larval object appears multiple times in the JVMS and we encounter a loop, they will\n+  \/\/ become multiple Phis and we cannot change all of them to non-larval when we invoke the\n+  \/\/ constructor on one. The other case is that we don't know whether a parameter of an OSR\n+  \/\/ compilation is larval or not. If such a maybe-larval object is passed into an operation that\n+  \/\/ does not permit larval objects, we can be sure that it is not larval and scalarize it if it\n+  \/\/ is a value object.\n+  Node* cast_to_non_larval(Node* obj);\n@@ -817,1 +824,1 @@\n-  Node* gen_checkcast(Node *subobj, Node* superkls, Node* *failure_control = nullptr, bool null_free = false);\n+  Node* gen_checkcast(Node *subobj, Node* superkls, Node* *failure_control = nullptr, bool null_free = false, bool maybe_larval = false);\n","filename":"src\/hotspot\/share\/opto\/graphKit.hpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -331,12 +331,0 @@\n-  \/\/ We should not scalarize larvals in debug info of their constructor calls because their fields could still be\n-  \/\/ updated. If we scalarize and update the fields in the constructor, the updates won't be visible in the caller after\n-  \/\/ deoptimization because the scalarized field values are local to the caller. We need to use a buffer to make the\n-  \/\/ updates visible to the outside.\n-  if (is_larval() && sfpt->is_CallJava() && sfpt->as_CallJava()->method() != nullptr &&\n-      sfpt->as_CallJava()->method()->is_object_constructor() && bottom_type()->is_inlinetypeptr() &&\n-      sfpt->in(TypeFunc::Parms) == this) {\n-    \/\/ Receiver is always buffered because it's passed as oop, see special case in CompiledEntrySignature::compute_calling_conventions().\n-    assert(is_allocated(igvn), \"receiver must be allocated\");\n-    return;\n-  }\n-\n@@ -907,1 +895,1 @@\n-InlineTypeNode* InlineTypeNode::buffer(GraphKit* kit, bool safe_for_replace, bool must_init) {\n+InlineTypeNode* InlineTypeNode::buffer(GraphKit* kit, bool safe_for_replace) {\n@@ -958,0 +946,1 @@\n+    store(kit, alloc_oop, alloc_oop, vk);\n@@ -959,16 +948,5 @@\n-    if (must_init) {\n-      \/\/ Either not a larval or a larval receiver on which we are about to invoke an abstract value class constructor\n-      \/\/ or the Object constructor which is not inlined. It is therefore escaping, and we must initialize the buffer\n-      \/\/ because we have not done this, yet, for larvals (see else case).\n-      store(kit, alloc_oop, alloc_oop, vk);\n-\n-      \/\/ Do not let stores that initialize this buffer be reordered with a subsequent\n-      \/\/ store that would make this buffer accessible by other threads.\n-      AllocateNode* alloc = AllocateNode::Ideal_allocation(alloc_oop);\n-      assert(alloc != nullptr, \"must have an allocation node\");\n-      kit->insert_mem_bar(Op_MemBarStoreStore, alloc->proj_out_or_null(AllocateNode::RawAddress));\n-    } else {\n-      \/\/ We do not need to initialize the buffer because a larval could still be updated which will create a new buffer.\n-      \/\/ Once the larval escapes, we will initialize the buffer (must_init set).\n-      assert(is_larval(), \"only larvals can possibly skip the initialization of their buffer\");\n-    }\n+    \/\/ Do not let stores that initialize this buffer be reordered with a subsequent\n+    \/\/ store that would make this buffer accessible by other threads.\n+    AllocateNode* alloc = AllocateNode::Ideal_allocation(alloc_oop);\n+    assert(alloc != nullptr, \"must have an allocation node\");\n+    kit->insert_mem_bar(Op_MemBarStoreStore, alloc->proj_out_or_null(AllocateNode::RawAddress));\n@@ -1104,0 +1082,2 @@\n+  Node* is_buffered = get_is_buffered();\n+\n@@ -1115,1 +1095,11 @@\n-  \/\/ Use base oop if fields are loaded from memory\n+  \/\/ Use base oop if fields are loaded from memory, don't do so if base is the CheckCastPP of an\n+  \/\/ allocation because the only case we load from a naked CheckCastPP is when we exit a\n+  \/\/ constructor of an inline type and we want to relinquish the larval oop there. This has a\n+  \/\/ couple of benefits:\n+  \/\/ - The allocation is likely to be elided earlier if it is not an input of an InlineTypeNode.\n+  \/\/ - The InlineTypeNode without an allocation input is more likely to be GVN-ed. This may emerge\n+  \/\/   when we try to clone a value object.\n+  \/\/ - The buffering, if needed, is delayed until it is required. This new allocation, since it is\n+  \/\/   created from an InlineTypeNode, is recognized as not having a unique identity and in the\n+  \/\/   future, we can move them around more freely such as hoisting out of loops. This is not true\n+  \/\/   for the old allocation since larval value objects do have unique identities.\n@@ -1117,4 +1107,6 @@\n-  if (base != nullptr && get_oop() != base && !phase->type(base)->maybe_null()) {\n-    set_oop(*phase, base);\n-    assert(is_allocated(phase), \"should now be allocated\");\n-    return this;\n+  if (base != nullptr && !base->is_InlineType() && !phase->type(base)->maybe_null() && AllocateNode::Ideal_allocation(base) == nullptr) {\n+    if (oop != base || phase->type(is_buffered) != TypeInt::ONE) {\n+      set_oop(*phase, base);\n+      set_is_buffered(*phase);\n+      return this;\n+    }\n@@ -1157,1 +1149,1 @@\n-InlineTypeNode* InlineTypeNode::make_all_zero(PhaseGVN& gvn, ciInlineKlass* vk, bool is_larval) {\n+InlineTypeNode* InlineTypeNode::make_all_zero(PhaseGVN& gvn, ciInlineKlass* vk) {\n@@ -1160,1 +1152,1 @@\n-  return make_all_zero_impl(gvn, vk, visited, is_larval);\n+  return make_all_zero_impl(gvn, vk, visited);\n@@ -1163,1 +1155,1 @@\n-InlineTypeNode* InlineTypeNode::make_all_zero_impl(PhaseGVN& gvn, ciInlineKlass* vk, GrowableArray<ciType*>& visited, bool is_larval) {\n+InlineTypeNode* InlineTypeNode::make_all_zero_impl(PhaseGVN& gvn, ciInlineKlass* vk, GrowableArray<ciType*>& visited) {\n@@ -1168,1 +1160,0 @@\n-  vt->set_is_larval(is_larval);\n@@ -1220,1 +1211,1 @@\n-InlineTypeNode* InlineTypeNode::make_from_oop(GraphKit* kit, Node* oop, ciInlineKlass* vk, bool is_larval) {\n+InlineTypeNode* InlineTypeNode::make_from_oop(GraphKit* kit, Node* oop, ciInlineKlass* vk) {\n@@ -1223,1 +1214,1 @@\n-  return make_from_oop_impl(kit, oop, vk, visited, is_larval);\n+  return make_from_oop_impl(kit, oop, vk, visited);\n@@ -1226,1 +1217,1 @@\n-InlineTypeNode* InlineTypeNode::make_from_oop_impl(GraphKit* kit, Node* oop, ciInlineKlass* vk, GrowableArray<ciType*>& visited, bool is_larval) {\n+InlineTypeNode* InlineTypeNode::make_from_oop_impl(GraphKit* kit, Node* oop, ciInlineKlass* vk, GrowableArray<ciType*>& visited) {\n@@ -1234,8 +1225,0 @@\n-    \/\/ TODO 8335256 Re-enable assert and fix OSR code\n-    \/\/ Issue triggers with TestValueConstruction.java and -XX:Tier0BackedgeNotifyFreqLog=0 -XX:Tier2BackedgeNotifyFreqLog=0 -XX:Tier3BackedgeNotifyFreqLog=0 -XX:Tier2BackEdgeThreshold=1 -XX:Tier3BackEdgeThreshold=1 -XX:Tier4BackEdgeThreshold=1 -Xbatch -XX:-TieredCompilation\n-    \/\/ assert(!is_larval || oop->as_InlineType()->is_larval(), \"must be larval\");\n-    if (is_larval && !oop->as_InlineType()->is_larval()) {\n-      vt = oop->clone()->as_InlineType();\n-      vt->set_is_larval(true);\n-      return gvn.transform(vt)->as_InlineType();\n-    }\n@@ -1243,1 +1226,3 @@\n-  } else if (gvn.type(oop)->maybe_null()) {\n+  }\n+\n+  if (gvn.type(oop)->maybe_null()) {\n@@ -1257,1 +1242,0 @@\n-    vt->set_is_larval(is_larval);\n@@ -1276,1 +1260,0 @@\n-    vt->set_is_larval(is_larval);\n@@ -1473,60 +1456,0 @@\n-InlineTypeNode* InlineTypeNode::make_larval(GraphKit* kit, bool allocate) const {\n-  ciInlineKlass* vk = inline_klass();\n-  InlineTypeNode* res = make_uninitialized(kit->gvn(), vk);\n-  for (uint i = 1; i < req(); ++i) {\n-    res->set_req(i, in(i));\n-  }\n-\n-  if (allocate) {\n-    \/\/ Re-execute if buffering triggers deoptimization\n-    PreserveReexecuteState preexecs(kit);\n-    kit->jvms()->set_should_reexecute(true);\n-    Node* klass_node = kit->makecon(TypeKlassPtr::make(vk));\n-    Node* alloc_oop  = kit->new_instance(klass_node, nullptr, nullptr, true);\n-    AllocateNode* alloc = AllocateNode::Ideal_allocation(alloc_oop);\n-    alloc->_larval = true;\n-\n-    store(kit, alloc_oop, alloc_oop, vk);\n-    res->set_oop(kit->gvn(), alloc_oop);\n-  }\n-  \/\/ TODO 8239003\n-  \/\/res->set_type(TypeInlineType::make(vk, true));\n-  res = kit->gvn().transform(res)->as_InlineType();\n-  assert(!allocate || res->is_allocated(&kit->gvn()), \"must be allocated\");\n-  return res;\n-}\n-\n-InlineTypeNode* InlineTypeNode::finish_larval(GraphKit* kit) const {\n-  Node* obj = get_oop();\n-  Node* mark_addr = kit->basic_plus_adr(obj, oopDesc::mark_offset_in_bytes());\n-  Node* mark = kit->make_load(nullptr, mark_addr, TypeX_X, TypeX_X->basic_type(), MemNode::unordered);\n-  mark = kit->gvn().transform(new AndXNode(mark, kit->MakeConX(~markWord::larval_bit_in_place)));\n-  kit->store_to_memory(kit->control(), mark_addr, mark, TypeX_X->basic_type(), MemNode::unordered);\n-\n-  \/\/ Do not let stores that initialize this buffer be reordered with a subsequent\n-  \/\/ store that would make this buffer accessible by other threads.\n-  AllocateNode* alloc = AllocateNode::Ideal_allocation(obj);\n-  assert(alloc != nullptr, \"must have an allocation node\");\n-  kit->insert_mem_bar(Op_MemBarStoreStore, alloc->proj_out_or_null(AllocateNode::RawAddress));\n-\n-  ciInlineKlass* vk = inline_klass();\n-  InlineTypeNode* res = make_uninitialized(kit->gvn(), vk);\n-  for (uint i = 1; i < req(); ++i) {\n-    res->set_req(i, in(i));\n-  }\n-  \/\/ TODO 8239003\n-  \/\/res->set_type(TypeInlineType::make(vk, false));\n-  res = kit->gvn().transform(res)->as_InlineType();\n-  return res;\n-}\n-\n-bool InlineTypeNode::is_larval(PhaseGVN* gvn) const {\n-  if (!is_allocated(gvn)) {\n-    return false;\n-  }\n-\n-  Node* oop = get_oop();\n-  AllocateNode* alloc = AllocateNode::Ideal_allocation(oop);\n-  return alloc != nullptr && alloc->_larval;\n-}\n-\n@@ -1534,3 +1457,0 @@\n-  if (is_larval() || is_larval(phase)) {\n-    return nullptr;\n-  }\n@@ -1741,4 +1661,0 @@\n-  \/\/ TODO 8332886 Really needed? GVN is disabled anyway.\n-  if (is_larval()) {\n-    return;\n-  }\n@@ -1841,8 +1757,0 @@\n-\n-#ifndef PRODUCT\n-void InlineTypeNode::dump_spec(outputStream* st) const {\n-  if (_is_larval) {\n-    st->print(\" #larval\");\n-  }\n-}\n-#endif \/\/ NOT PRODUCT\n","filename":"src\/hotspot\/share\/opto\/inlinetypenode.cpp","additions":35,"deletions":127,"binary":false,"changes":162,"status":"modified"},{"patch":"@@ -44,1 +44,0 @@\n-    _is_larval = false;\n@@ -55,7 +54,0 @@\n-  bool _is_larval;\n-\n-  virtual uint hash() const { return TypeNode::hash() + _is_larval; }\n-  \/\/ Don't GVN larvals because the inputs might be updated\n-  virtual bool cmp(const Node &n) const { return TypeNode::cmp(n) && !(n.isa_InlineType()->_is_larval || _is_larval); }\n-  virtual uint size_of() const { return sizeof(*this); }\n-\n@@ -70,3 +62,0 @@\n-  \/\/ Checks if the inline type oop is an allocated buffer with larval state\n-  bool is_larval(PhaseGVN* gvn) const;\n-\n@@ -81,2 +70,2 @@\n-  static InlineTypeNode* make_all_zero_impl(PhaseGVN& gvn, ciInlineKlass* vk, GrowableArray<ciType*>& visited, bool is_larval = false);\n-  static InlineTypeNode* make_from_oop_impl(GraphKit* kit, Node* oop, ciInlineKlass* vk, GrowableArray<ciType*>& visited, bool is_larval = false);\n+  static InlineTypeNode* make_all_zero_impl(PhaseGVN& gvn, ciInlineKlass* vk, GrowableArray<ciType*>& visited);\n+  static InlineTypeNode* make_from_oop_impl(GraphKit* kit, Node* oop, ciInlineKlass* vk, GrowableArray<ciType*>& visited);\n@@ -91,1 +80,1 @@\n-  static InlineTypeNode* make_all_zero(PhaseGVN& gvn, ciInlineKlass* vk, bool is_larval = false);\n+  static InlineTypeNode* make_all_zero(PhaseGVN& gvn, ciInlineKlass* vk);\n@@ -95,1 +84,1 @@\n-  static InlineTypeNode* make_from_oop(GraphKit* kit, Node* oop, ciInlineKlass* vk, bool is_larval = false);\n+  static InlineTypeNode* make_from_oop(GraphKit* kit, Node* oop, ciInlineKlass* vk);\n@@ -118,3 +107,0 @@\n-  void set_is_larval(bool is_larval) { _is_larval = is_larval; }\n-  bool is_larval() const { return _is_larval; }\n-\n@@ -152,1 +138,1 @@\n-  InlineTypeNode* buffer(GraphKit* kit, bool safe_for_replace = true, bool must_init = true);\n+  InlineTypeNode* buffer(GraphKit* kit, bool safe_for_replace = true);\n@@ -168,3 +154,0 @@\n-  InlineTypeNode* make_larval(GraphKit* kit, bool allocate) const;\n-  InlineTypeNode* finish_larval(GraphKit* kit) const;\n-\n@@ -181,2 +164,0 @@\n-\n-  NOT_PRODUCT(void dump_spec(outputStream* st) const;)\n","filename":"src\/hotspot\/share\/opto\/inlinetypenode.hpp","additions":5,"deletions":24,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -2428,0 +2428,1 @@\n+    assert(!is_store, \"InlineTypeNodes are non-larval value objects\");\n@@ -2429,2 +2430,4 @@\n-    if (is_store) {\n-      if (!vt->is_allocated(&_gvn)) {\n+    if (offset->is_Con()) {\n+      long off = find_long_con(offset, 0);\n+      ciInlineKlass* vk = vt->type()->inline_klass();\n+      if ((long)(int)off != off || !vk->contains_field_offset(off)) {\n@@ -2433,8 +2436,0 @@\n-      base = vt->get_oop();\n-    } else {\n-      if (offset->is_Con()) {\n-        long off = find_long_con(offset, 0);\n-        ciInlineKlass* vk = vt->type()->inline_klass();\n-        if ((long)(int)off != off || !vk->contains_field_offset(off)) {\n-          return false;\n-        }\n@@ -2442,13 +2437,10 @@\n-        ciField* field = vk->get_non_flat_field_by_offset(off);\n-        if (field != nullptr) {\n-          BasicType bt = type2field[field->type()->basic_type()];\n-          if (bt == T_ARRAY || bt == T_NARROWOOP) {\n-            bt = T_OBJECT;\n-          }\n-          if (bt == type && (!field->is_flat() || field->type() == inline_klass)) {\n-            Node* value = vt->field_value_by_offset(off, false);\n-            if (value->is_InlineType()) {\n-              value = value->as_InlineType()->adjust_scalarization_depth(this);\n-            }\n-            set_result(value);\n-            return true;\n+      ciField* field = vk->get_non_flat_field_by_offset(off);\n+      if (field != nullptr) {\n+        BasicType bt = type2field[field->type()->basic_type()];\n+        if (bt == T_ARRAY || bt == T_NARROWOOP) {\n+          bt = T_OBJECT;\n+        }\n+        if (bt == type && (!field->is_flat() || field->type() == inline_klass)) {\n+          Node* value = vt->field_value_by_offset(off, false);\n+          if (value->is_InlineType()) {\n+            value = value->as_InlineType()->adjust_scalarization_depth(this);\n@@ -2456,0 +2448,2 @@\n+          set_result(value);\n+          return true;\n@@ -2458,7 +2452,0 @@\n-      {\n-        \/\/ Re-execute the unsafe access if allocation triggers deoptimization.\n-        PreserveReexecuteState preexecs(this);\n-        jvms()->set_should_reexecute(true);\n-        vt = vt->buffer(this);\n-      }\n-      base = vt->get_oop();\n@@ -2466,0 +2453,7 @@\n+    {\n+      \/\/ Re-execute the unsafe access if allocation triggers deoptimization.\n+      PreserveReexecuteState preexecs(this);\n+      jvms()->set_should_reexecute(true);\n+      vt = vt->buffer(this);\n+    }\n+    base = vt->get_oop();\n@@ -2699,6 +2693,0 @@\n-  if (argument(1)->is_InlineType() && is_store) {\n-    InlineTypeNode* value = InlineTypeNode::make_from_oop(this, base, _gvn.type(argument(1))->inline_klass());\n-    value = value->make_larval(this, false);\n-    replace_in_map(argument(1), value);\n-  }\n-\n@@ -2769,1 +2757,1 @@\n-  set_result(InlineTypeNode::make_from_oop(this, buffer, type->inline_klass(), false));\n+  set_result(InlineTypeNode::make_from_oop(this, buffer, type->inline_klass()));\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":25,"deletions":37,"binary":false,"changes":62,"status":"modified"},{"patch":"@@ -1034,2 +1034,0 @@\n-  assert(safepoints.length() == 0 || !res_type->is_inlinetypeptr() || C->has_circular_inline_type(),\n-         \"Inline type allocations should have been scalarized earlier\");\n@@ -1294,2 +1292,0 @@\n-      assert(!inline_alloc || C->has_circular_inline_type(),\n-             \"Inline type allocations should have been scalarized earlier\");\n@@ -2903,1 +2899,1 @@\n-  if (C->macro_count() == 0)\n+  if (C->macro_count() == 0) {\n@@ -2905,0 +2901,1 @@\n+  }\n@@ -2907,7 +2904,5 @@\n-  \/\/ Before elimination may re-mark (change to Nested or NonEscObj)\n-  \/\/ all associated (same box and obj) lock and unlock nodes.\n-  int cnt = C->macro_count();\n-  for (int i=0; i < cnt; i++) {\n-    Node *n = C->macro_node(i);\n-    if (n->is_AbstractLock()) { \/\/ Lock and Unlock nodes\n-      mark_eliminated_locking_nodes(n->as_AbstractLock());\n+  int iteration = 0;\n+  while (C->macro_count() > 0) {\n+    if (iteration++ > 100) {\n+      assert(false, \"Too slow convergence of macro elimination\");\n+      break;\n@@ -2915,10 +2910,0 @@\n-  }\n-  \/\/ Re-marking may break consistency of Coarsened locks.\n-  if (!C->coarsened_locks_consistent()) {\n-    return; \/\/ recompile without Coarsened locks if broken\n-  } else {\n-    \/\/ After coarsened locks are eliminated locking regions\n-    \/\/ become unbalanced. We should not execute any more\n-    \/\/ locks elimination optimizations on them.\n-    C->mark_unbalanced_boxes();\n-  }\n@@ -2926,15 +2911,7 @@\n-  \/\/ First, attempt to eliminate locks\n-  bool progress = true;\n-  while (progress) {\n-    progress = false;\n-    for (int i = C->macro_count(); i > 0; i = MIN2(i - 1, C->macro_count())) { \/\/ more than 1 element can be eliminated at once\n-      Node* n = C->macro_node(i - 1);\n-      bool success = false;\n-      DEBUG_ONLY(int old_macro_count = C->macro_count();)\n-      if (n->is_AbstractLock()) {\n-        success = eliminate_locking_node(n->as_AbstractLock());\n-#ifndef PRODUCT\n-        if (success && PrintOptoStatistics) {\n-          Atomic::inc(&PhaseMacroExpand::_monitor_objects_removed_counter);\n-        }\n-#endif\n+    \/\/ Before elimination may re-mark (change to Nested or NonEscObj)\n+    \/\/ all associated (same box and obj) lock and unlock nodes.\n+    int cnt = C->macro_count();\n+    for (int i=0; i < cnt; i++) {\n+      Node *n = C->macro_node(i);\n+      if (n->is_AbstractLock()) { \/\/ Lock and Unlock nodes\n+        mark_eliminated_locking_nodes(n->as_AbstractLock());\n@@ -2942,2 +2919,0 @@\n-      assert(success == (C->macro_count() < old_macro_count), \"elimination reduces macro count\");\n-      progress = progress || success;\n@@ -2945,6 +2920,11 @@\n-  }\n-  \/\/ Next, attempt to eliminate allocations\n-  _has_locks = false;\n-  progress = true;\n-  while (progress) {\n-    progress = false;\n+    \/\/ Re-marking may break consistency of Coarsened locks.\n+    if (!C->coarsened_locks_consistent()) {\n+      return; \/\/ recompile without Coarsened locks if broken\n+    } else {\n+      \/\/ After coarsened locks are eliminated locking regions\n+      \/\/ become unbalanced. We should not execute any more\n+      \/\/ locks elimination optimizations on them.\n+      C->mark_unbalanced_boxes();\n+    }\n+\n+    bool progress = false;\n@@ -2974,2 +2954,6 @@\n-        assert(!n->as_AbstractLock()->is_eliminated(), \"sanity\");\n-        _has_locks = true;\n+        success = eliminate_locking_node(n->as_AbstractLock());\n+#ifndef PRODUCT\n+        if (success && PrintOptoStatistics) {\n+          Atomic::inc(&PhaseMacroExpand::_monitor_objects_removed_counter);\n+        }\n+#endif\n@@ -3001,0 +2985,16 @@\n+\n+    \/\/ Ensure the graph after PhaseMacroExpand::eliminate_macro_nodes is canonical (no igvn\n+    \/\/ transformation is pending). If an allocation is used only in safepoints, elimination of\n+    \/\/ other macro nodes can remove all these safepoints, allowing the allocation to be removed.\n+    \/\/ Hence after igvn we retry removing macro nodes if some progress that has been made in this\n+    \/\/ iteration.\n+    _igvn.set_delay_transform(false);\n+    _igvn.optimize();\n+    if (C->failing()) {\n+      return;\n+    }\n+    _igvn.set_delay_transform(true);\n+\n+    if (!progress) {\n+      break;\n+    }\n@@ -3018,3 +3018,0 @@\n-  \/\/ Last attempt to eliminate macro nodes.\n-  eliminate_macro_nodes();\n-  if (C->failing())  return true;\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":47,"deletions":50,"binary":false,"changes":97,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -86,3 +86,0 @@\n-  \/\/ Additional data collected during macro expansion\n-  bool _has_locks;\n-\n@@ -217,1 +214,1 @@\n-  PhaseMacroExpand(PhaseIterGVN &igvn) : Phase(Macro_Expand), _igvn(igvn), _has_locks(false) {\n+  PhaseMacroExpand(PhaseIterGVN &igvn) : Phase(Macro_Expand), _igvn(igvn) {\n","filename":"src\/hotspot\/share\/opto\/macro.hpp","additions":2,"deletions":5,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -146,26 +146,0 @@\n-\/\/ If call is a constructor call on receiver, returns the class which declares the target method,\n-\/\/ else returns nullptr. This information can then be used to deduce if call modifies a field of\n-\/\/ receiver. Specifically, if the field is declared in a class that is a subclass of the one\n-\/\/ declaring the constructor, then the field is set inside the constructor, else the field must be\n-\/\/ set before the constructor invocation. E.g. A field Super.x will be set during the execution of\n-\/\/ Sub::<init>, while a field Sub.y must be set before Super::<init> is invoked.\n-static ciInstanceKlass* find_constructor_call_method_holder(Node* call, Node* receiver) {\n-  if (!call->is_CallJava()) {\n-    return nullptr;\n-  }\n-\n-  ciMethod* target = call->as_CallJava()->method();\n-  if (target == nullptr || !target->is_object_constructor()) {\n-    return nullptr;\n-  }\n-\n-  assert(call->req() > TypeFunc::Parms, \"constructor must have at least 1 argument\");\n-  Node* parm = call->in(TypeFunc::Parms)->uncast();\n-  receiver = receiver->uncast();\n-  if (parm == receiver || (parm->is_InlineType() && parm->as_InlineType()->get_oop()->uncast() == receiver)) {\n-    return target->holder();\n-  }\n-\n-  return nullptr;\n-}\n-\n@@ -181,36 +155,0 @@\n-\/\/ Try to find a better memory input for a load from a strict final field of an object that is\n-\/\/ allocated in the current compilation unit, or is the first parameter when we are in a\n-\/\/ constructor\n-static Node* optimize_strict_final_load_memory_from_local_object(ciField* field, ProjNode* base_uncasted) {\n-  if (!EnableValhalla) {\n-    \/\/ In this method we depends on the fact that strict fields are set before the invocation of\n-    \/\/ super(), I'm not sure if this is true without Valhalla\n-    return nullptr;\n-  }\n-\n-  \/\/ The node that can be passed into a constructor\n-  Node* base = base_uncasted;\n-  if (!base_uncasted->is_Parm()) {\n-    assert(base_uncasted->_con == AllocateNode::RawAddress && base_uncasted->in(0)->is_Allocate(), \"must be the RawAddress of an AllocateNode\");\n-    base = base_uncasted->in(0)->as_Allocate()->result_cast();\n-    assert(base != nullptr && base->in(1) == base_uncasted, \"must find a valid base\");\n-  }\n-\n-  \/\/ Try to see if there is a constructor call on the base\n-  for (DUIterator_Fast imax, i = base->fast_outs(imax); i < imax; i++) {\n-    Node* out = base->fast_out(i);\n-    ciInstanceKlass* target_holder = find_constructor_call_method_holder(out, base);\n-    if (target_holder == nullptr) {\n-      continue;\n-    } else if (target_holder->is_subclass_of(field->holder())) {\n-      return find_call_fallthrough_mem_output(out->as_CallJava());\n-    } else {\n-      Node* res = out->in(TypeFunc::Memory);\n-      assert(res != nullptr, \"should have a memory input\");\n-      return res;\n-    }\n-  }\n-\n-  return nullptr;\n-}\n-\n@@ -229,1 +167,0 @@\n-      \/\/ The result of an AllocateNode, try to find the constructor call\n@@ -231,1 +168,1 @@\n-      return optimize_strict_final_load_memory_from_local_object(field, base_uncasted->as_Proj());\n+      return nullptr;\n@@ -240,1 +177,1 @@\n-        return optimize_strict_final_load_memory_from_local_object(field, base_uncasted->as_Proj());\n+        return nullptr;\n@@ -251,8 +188,24 @@\n-\/\/ Whether a call can modify a strict final field of base_local, given that base_local is allocated\n-\/\/ inside the current compilation unit, or is the first parameter when the compilation root is a\n-\/\/ constructor. This is equivalent to asking whether base_local is the receiver of the constructor\n-\/\/ invocation call and the class declaring the target method is a subclass of the class declaring\n-\/\/ field.\n-static bool call_can_modify_local_object(ciField* field, CallNode* call, Node* base_local) {\n-  ciInstanceKlass* target_holder = find_constructor_call_method_holder(call, base_local);\n-  return target_holder != nullptr && target_holder->is_subclass_of(field->holder());\n+\/\/ Whether a call can modify a strict final field, given that the object is allocated inside the\n+\/\/ current compilation unit, or is the first parameter when the compilation root is a constructor.\n+\/\/ This is equivalent to asking whether 'call' is a constructor invocation and the class declaring\n+\/\/ the target method is a subclass of the class declaring 'field'.\n+static bool call_can_modify_local_object(ciField* field, CallNode* call) {\n+  if (!call->is_CallJava()) {\n+    return false;\n+  }\n+\n+  ciMethod* target = call->as_CallJava()->method();\n+  if (target == nullptr || !target->is_object_constructor()) {\n+    return false;\n+  }\n+\n+  \/\/ If 'field' is declared in a class that is a subclass of the one declaring the constructor,\n+  \/\/ then the field is set inside the constructor, else the field must be set before the\n+  \/\/ constructor invocation. E.g. A field Super.x will be set during the execution of Sub::<init>,\n+  \/\/ while a field Sub.y must be set before Super::<init> is invoked.\n+  \/\/ We can try to be more heroic and decide if the receiver of the constructor invocation is the\n+  \/\/ object from which we are loading from. This, however, may be problematic as deciding if 2\n+  \/\/ nodes are definitely different may not be trivial, especially if the graph is not canonical.\n+  \/\/ As a result, it is made more conservative for now.\n+  assert(call->req() > TypeFunc::Parms, \"constructor must have at least 1 argument\");\n+  return target->holder()->is_subclass_of(field->holder());\n@@ -323,1 +276,1 @@\n-        } else if (is_strict_final_load && base_local != nullptr && !call_can_modify_local_object(field, call, base_local)) {\n+        } else if (is_strict_final_load && base_local != nullptr && !call_can_modify_local_object(field, call)) {\n@@ -1261,1 +1214,0 @@\n-    assert(!vt->is_larval(), \"must not load from a larval object\");\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":27,"deletions":75,"binary":false,"changes":102,"status":"modified"},{"patch":"@@ -484,2 +484,2 @@\n-  PhiNode *ensure_phi(       int idx, bool nocreate = false);\n-  PhiNode *ensure_memory_phi(int idx, bool nocreate = false);\n+  Node*    ensure_phi(       int idx, bool nocreate = false);\n+  PhiNode* ensure_memory_phi(int idx, bool nocreate = false);\n@@ -557,1 +557,0 @@\n-  void set_inline_type_field(Node* obj, ciField* field, Node* val);\n","filename":"src\/hotspot\/share\/opto\/parse.hpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -186,1 +186,5 @@\n-    l = gen_checkcast(l, makecon(tp->as_klass_type()->cast_to_exactness(true)), &bad_type_ctrl);\n+\n+    \/\/ In an OSR compilation, we cannot know if a value object in the incoming state is larval or\n+    \/\/ not. As a result, we must pass maybe_larval == true to not eagerly scalarize the result if\n+    \/\/ the target type is a value class.\n+    l = gen_checkcast(l, makecon(tp->as_klass_type()->cast_to_exactness(true)), &bad_type_ctrl, false, true);\n@@ -625,4 +629,11 @@\n-      \/\/ Create InlineTypeNode from the oop and replace the parameter\n-      bool is_larval = (i == 0) && method()->is_object_constructor() && !method()->holder()->is_java_lang_Object();\n-      Node* vt = InlineTypeNode::make_from_oop(this, parm, t->inline_klass(), is_larval);\n-      replace_in_map(parm, vt);\n+      \/\/ If the parameter is a value object, try to scalarize it if we know that it is not larval.\n+      \/\/ There are 2 cases when a parameter may be larval:\n+      \/\/ - In an OSR compilation, we do not know if a value object in the incoming state is larval\n+      \/\/   or not. We must be conservative and not eagerly scalarize them.\n+      \/\/ - In a normal compilation, all parameters are non-larval except the receiver of a\n+      \/\/   constructor, which must be a larval object.\n+      if (!is_osr_parse() && !(method()->is_object_constructor() && i == 0)) {\n+        \/\/ Create InlineTypeNode from the oop and replace the parameter\n+        Node* vt = InlineTypeNode::make_from_oop(this, parm, t->inline_klass());\n+        replace_in_map(parm, vt);\n+      }\n@@ -1212,5 +1223,1 @@\n-    if (receiver->is_InlineType() && receiver->as_InlineType()->is_larval()) {\n-      \/\/ Replace the larval inline type receiver in the exit map as well to make sure that\n-      \/\/ we can find and update it in Parse::do_call when we are done with the initialization.\n-      _exits.map()->replace_edge(receiver, null_free);\n-    }\n+\n@@ -1785,7 +1792,37 @@\n-        if (n->is_InlineType() && !t->is_inlinetypeptr()) {\n-          \/\/ Allocate inline type in src block to be able to merge it with oop in target block\n-          map()->set_req(j, n->as_InlineType()->buffer(this));\n-        } else if (!n->is_InlineType() && t->is_inlinetypeptr()) {\n-          \/\/ Scalarize null in src block to be able to merge it with inline type in target block\n-          assert(gvn().type(n)->is_zero_type(), \"Should have been scalarized\");\n-          map()->set_req(j, InlineTypeNode::make_null(gvn(), t->inline_klass()));\n+        \/\/ An object can appear in the JVMS as either an oop or an InlineTypeNode. If the merge is\n+        \/\/ an InlineTypeNode, we need all the merge inputs to be InlineTypeNodes. Else, if the\n+        \/\/ merge is an oop, each merge input needs to be either an oop or an buffered\n+        \/\/ InlineTypeNode.\n+        if (!t->is_inlinetypeptr()) {\n+          \/\/ The merge cannot be an InlineTypeNode, ensure the input is buffered if it is an\n+          \/\/ InlineTypeNode\n+          if (n->is_InlineType()) {\n+            map()->set_req(j, n->as_InlineType()->buffer(this));\n+          }\n+        } else {\n+          \/\/ Since the merge is a value object, it can either be an oop or an InlineTypeNode\n+          if (!target->is_merged()) {\n+            \/\/ This is the first processed input of the merge. If it is an InlineTypeNode, the\n+            \/\/ merge will be an InlineTypeNode. Else, try to scalarize so the merge can be\n+            \/\/ scalarized as well. However, we cannot blindly scalarize an inline type oop here\n+            \/\/ since it may be larval\n+            if (!n->is_InlineType() && gvn().type(n)->is_zero_type()) {\n+              \/\/ Null constant implies that this is not a larval object\n+              map()->set_req(j, InlineTypeNode::make_null(gvn(), t->inline_klass()));\n+            }\n+          } else {\n+            Node* phi = target->start_map()->in(j);\n+            if (phi->is_InlineType()) {\n+              \/\/ Larval oops cannot be merged with non-larval ones, and since the merge point is\n+              \/\/ non-larval, n must be non-larval as well. As a result, we can scalarize n to merge\n+              \/\/ into phi\n+              if (!n->is_InlineType()) {\n+                map()->set_req(j, InlineTypeNode::make_from_oop(this, n, t->inline_klass()));\n+              }\n+            } else {\n+              \/\/ The merge is an oop phi, ensure the input is buffered if it is an InlineTypeNode\n+              if (n->is_InlineType()) {\n+                map()->set_req(j, n->as_InlineType()->buffer(this));\n+              }\n+            }\n+          }\n@@ -1893,1 +1930,1 @@\n-      PhiNode* phi;\n+      Node* phi;\n@@ -1895,1 +1932,1 @@\n-        phi = m->as_Phi();\n+        phi = m;\n@@ -1897,1 +1934,1 @@\n-        phi = m->as_InlineType()->get_oop()->as_Phi();\n+        phi = m;\n@@ -1948,1 +1985,1 @@\n-      if (phi != nullptr && phi->bottom_type()->is_inlinetypeptr()) {\n+      if (phi != nullptr && phi->is_InlineType()) {\n@@ -1950,2 +1987,3 @@\n-        m = map()->in(j);\n-        InlineTypeNode* vtm = m->as_InlineType(); \/\/ Current inline type\n+        assert(phi == map()->in(j), \"unexpected value in map\");\n+        assert(phi->as_InlineType()->has_phi_inputs(r), \"\");\n+        InlineTypeNode* vtm = phi->as_InlineType(); \/\/ Current inline type\n@@ -1953,2 +1991,2 @@\n-        assert(vtm->get_oop() == phi, \"Inline type should have Phi input\");\n-        if (TraceOptoParse) {\n+        assert(vtm == phi, \"Inline type should have Phi input\");\n+\n@@ -1956,0 +1994,1 @@\n+        if (TraceOptoParse) {\n@@ -1962,1 +2001,0 @@\n-#endif\n@@ -1964,0 +2002,1 @@\n+#endif\n@@ -1972,1 +2011,1 @@\n-        assert(phi->region() == r, \"\");\n+        assert(phi->as_Phi()->region() == r, \"\");\n@@ -2153,1 +2192,1 @@\n-PhiNode *Parse::ensure_phi(int idx, bool nocreate) {\n+Node* Parse::ensure_phi(int idx, bool nocreate) {\n@@ -2168,1 +2207,1 @@\n-    return vt->get_oop()->as_Phi();\n+    return vt;\n@@ -2209,1 +2248,1 @@\n-    return vt->get_oop()->as_Phi();\n+    return vt;\n@@ -2351,1 +2390,0 @@\n-    assert(!value->is_InlineType() || !value->as_InlineType()->is_larval(), \"returning a larval\");\n","filename":"src\/hotspot\/share\/opto\/parse1.cpp","additions":69,"deletions":31,"binary":false,"changes":100,"status":"modified"},{"patch":"@@ -3409,1 +3409,1 @@\n-    return_current(pop());\n+    return_current(cast_to_non_larval(pop()));\n@@ -3412,2 +3412,0 @@\n-    return_current(pop_pair());\n-    break;\n@@ -3466,1 +3464,1 @@\n-    b = pop();\n+    b = cast_to_non_larval(pop());\n@@ -3495,2 +3493,2 @@\n-    a = pop();\n-    b = pop();\n+    a = cast_to_non_larval(pop());\n+    b = cast_to_non_larval(pop());\n@@ -3602,1 +3600,1 @@\n-    jio_snprintf(buffer, sizeof(buffer), \"Bytecode %d: %s\", bci(), Bytecodes::name(bc()));\n+    jio_snprintf(buffer, sizeof(buffer), \"Bytecode %d: %s, map: %d\", bci(), Bytecodes::name(bc()), map() == nullptr ? -1 : map()->_idx);\n","filename":"src\/hotspot\/share\/opto\/parse2.cpp","additions":5,"deletions":7,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"ci\/ciInstanceKlass.hpp\"\n@@ -50,14 +51,0 @@\n-  ciInstanceKlass* field_holder = field->holder();\n-\n-  if (is_get && is_field && field_holder->is_inlinetype() && peek()->is_InlineType()) {\n-    InlineTypeNode* vt = peek()->as_InlineType();\n-    null_check(vt);\n-    Node* value = vt->field_value_by_offset(field->offset_in_bytes());\n-    if (value->is_InlineType()) {\n-      value = value->as_InlineType()->adjust_scalarization_depth(this);\n-    }\n-    pop();\n-    push_node(field->layout_type(), value);\n-    return;\n-  }\n-\n@@ -73,0 +60,1 @@\n+  ciInstanceKlass* field_holder = field->holder();\n@@ -125,0 +113,1 @@\n+  obj = cast_to_non_larval(obj);\n@@ -142,0 +131,10 @@\n+  if (obj->is_InlineType()) {\n+    InlineTypeNode* vt = obj->as_InlineType();\n+    Node* value = vt->field_value_by_offset(field->offset_in_bytes());\n+    if (value->is_InlineType()) {\n+      value = value->as_InlineType()->adjust_scalarization_depth(this);\n+    }\n+    push_node(field->layout_type(), value);\n+    return;\n+  }\n+\n@@ -247,0 +246,1 @@\n+\n@@ -249,1 +249,0 @@\n-\n@@ -259,4 +258,4 @@\n-  if (obj->is_InlineType()) {\n-    set_inline_type_field(obj, field, val);\n-    return;\n-  }\n+  val = cast_to_non_larval(val);\n+\n+  \/\/ We cannot store into a non-larval object, so obj must not be an InlineTypeNode\n+  assert(!obj->is_InlineType(), \"InlineTypeNodes are non-larval value objects\");\n@@ -332,40 +331,0 @@\n-void Parse::set_inline_type_field(Node* obj, ciField* field, Node* val) {\n-  assert(_method->is_object_constructor(), \"inline type is initialized outside of constructor\");\n-  assert(obj->as_InlineType()->is_larval(), \"must be larval\");\n-  assert(!_gvn.type(obj)->maybe_null(), \"should never be null\");\n-\n-  \/\/ Re-execute if buffering in below code triggers deoptimization.\n-  PreserveReexecuteState preexecs(this);\n-  jvms()->set_should_reexecute(true);\n-  inc_sp(1);\n-\n-  if (!val->is_InlineType() && field->type()->is_inlinetype()) {\n-    \/\/ Scalarize inline type field value\n-    val = InlineTypeNode::make_from_oop(this, val, field->type()->as_inline_klass());\n-  } else if (val->is_InlineType() && !field->is_flat()) {\n-    \/\/ Field value needs to be allocated because it can be merged with a non-inline type.\n-    val = val->as_InlineType()->buffer(this);\n-  }\n-\n-  \/\/ Clone the inline type node and set the new field value\n-  InlineTypeNode* new_vt = obj->as_InlineType()->clone_if_required(&_gvn, _map);\n-  new_vt->set_field_value_by_offset(field->offset_in_bytes(), val);\n-  new_vt = new_vt->adjust_scalarization_depth(this);\n-\n-  \/\/ If the inline type is buffered and the caller might use the buffer, update it.\n-  if (new_vt->is_allocated(&gvn()) && (!_caller->has_method() || C->inlining_incrementally() || _caller->method()->is_object_constructor())) {\n-    new_vt->store(this, new_vt->get_oop(), new_vt->get_oop(), new_vt->bottom_type()->inline_klass(), 0, field->offset_in_bytes());\n-\n-    \/\/ Preserve allocation ptr to create precedent edge to it in membar\n-    \/\/ generated on exit from constructor.\n-    AllocateNode* alloc = AllocateNode::Ideal_allocation(new_vt->get_oop());\n-    if (alloc != nullptr) {\n-      set_alloc_with_final_or_stable(new_vt->get_oop());\n-    }\n-    set_wrote_final(true);\n-  }\n-\n-  replace_in_map(obj, _gvn.transform(new_vt));\n-  return;\n-}\n-\n","filename":"src\/hotspot\/share\/opto\/parse3.cpp","additions":18,"deletions":59,"binary":false,"changes":77,"status":"modified"},{"patch":"@@ -318,5 +318,0 @@\n-  if (klass->is_inlinetype()) {\n-    push(InlineTypeNode::make_all_zero(_gvn, klass->as_inline_klass(), \/* is_larval *\/ true));\n-    return;\n-  }\n-\n","filename":"src\/hotspot\/share\/opto\/parseHelper.cpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -85,1 +85,0 @@\n-compiler\/valhalla\/inlinetypes\/TestAllocationMergeAndFolding.java 8354283 generic-all\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -652,3 +652,1 @@\n-    \/\/ TODO 8332886 Remove the AlwaysIncrementalInline=false condition\n-    @IR(applyIf = {\"AlwaysIncrementalInline\", \"false\"},\n-        counts = {ALLOC, \"= 1\"})\n+    @IR(counts = {ALLOC, \"= 1\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestBasicFunctionality.java","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -26,0 +26,4 @@\n+import java.lang.classfile.Label;\n+import java.lang.invoke.MethodHandle;\n+import java.lang.invoke.MethodHandles;\n+import java.lang.invoke.MethodType;\n@@ -31,0 +35,1 @@\n+import test.java.lang.invoke.lib.InstructionHelper;\n@@ -36,1 +41,1 @@\n- * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/test\/jdk\/java\/lang\/invoke\/common \/\n@@ -38,1 +43,1 @@\n- * @build jdk.test.whitebox.WhiteBox\n+ * @build jdk.test.whitebox.WhiteBox test.java.lang.invoke.lib.InstructionHelper\n@@ -48,1 +53,1 @@\n- * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/test\/jdk\/java\/lang\/invoke\/common \/\n@@ -50,1 +55,1 @@\n- * @build jdk.test.whitebox.WhiteBox\n+ * @build jdk.test.whitebox.WhiteBox test.java.lang.invoke.lib.InstructionHelper\n@@ -60,1 +65,1 @@\n- * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/test\/jdk\/java\/lang\/invoke\/common \/\n@@ -62,1 +67,1 @@\n- * @build jdk.test.whitebox.WhiteBox\n+ * @build jdk.test.whitebox.WhiteBox test.java.lang.invoke.lib.InstructionHelper\n@@ -74,1 +79,1 @@\n- * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/test\/jdk\/java\/lang\/invoke\/common \/\n@@ -76,1 +81,1 @@\n- * @build jdk.test.whitebox.WhiteBox\n+ * @build jdk.test.whitebox.WhiteBox test.java.lang.invoke.lib.InstructionHelper\n@@ -87,1 +92,1 @@\n- * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/test\/jdk\/java\/lang\/invoke\/common \/\n@@ -89,1 +94,1 @@\n- * @build jdk.test.whitebox.WhiteBox\n+ * @build jdk.test.whitebox.WhiteBox test.java.lang.invoke.lib.InstructionHelper\n@@ -100,1 +105,1 @@\n- * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/test\/jdk\/java\/lang\/invoke\/common \/\n@@ -102,1 +107,1 @@\n- * @build jdk.test.whitebox.WhiteBox\n+ * @build jdk.test.whitebox.WhiteBox test.java.lang.invoke.lib.InstructionHelper\n@@ -113,1 +118,1 @@\n- * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/test\/jdk\/java\/lang\/invoke\/common \/\n@@ -115,1 +120,1 @@\n- * @build jdk.test.whitebox.WhiteBox\n+ * @build jdk.test.whitebox.WhiteBox test.java.lang.invoke.lib.InstructionHelper\n@@ -126,1 +131,1 @@\n- * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/test\/jdk\/java\/lang\/invoke\/common \/\n@@ -128,1 +133,1 @@\n- * @build jdk.test.whitebox.WhiteBox\n+ * @build jdk.test.whitebox.WhiteBox test.java.lang.invoke.lib.InstructionHelper\n@@ -139,1 +144,1 @@\n- * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/test\/jdk\/java\/lang\/invoke\/common \/\n@@ -141,1 +146,1 @@\n- * @build jdk.test.whitebox.WhiteBox\n+ * @build jdk.test.whitebox.WhiteBox test.java.lang.invoke.lib.InstructionHelper\n@@ -152,1 +157,1 @@\n- * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/test\/jdk\/java\/lang\/invoke\/common \/\n@@ -154,1 +159,1 @@\n- * @build jdk.test.whitebox.WhiteBox\n+ * @build jdk.test.whitebox.WhiteBox test.java.lang.invoke.lib.InstructionHelper\n@@ -165,1 +170,1 @@\n- * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/test\/jdk\/java\/lang\/invoke\/common \/\n@@ -167,1 +172,1 @@\n- * @build jdk.test.whitebox.WhiteBox\n+ * @build jdk.test.whitebox.WhiteBox test.java.lang.invoke.lib.InstructionHelper\n@@ -179,1 +184,1 @@\n- * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/test\/jdk\/java\/lang\/invoke\/common \/\n@@ -181,1 +186,1 @@\n- * @build jdk.test.whitebox.WhiteBox\n+ * @build jdk.test.whitebox.WhiteBox test.java.lang.invoke.lib.InstructionHelper\n@@ -193,1 +198,1 @@\n- * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/test\/jdk\/java\/lang\/invoke\/common \/\n@@ -195,1 +200,1 @@\n- * @build jdk.test.whitebox.WhiteBox\n+ * @build jdk.test.whitebox.WhiteBox test.java.lang.invoke.lib.InstructionHelper\n@@ -204,0 +209,14 @@\n+\/*\n+ * @test id=StressIncrementalInliningOnStackReplacement\n+ * @key randomness\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/test\/jdk\/java\/lang\/invoke\/common \/\n+ * @enablePreview\n+ * @build jdk.test.whitebox.WhiteBox test.java.lang.invoke.lib.InstructionHelper\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   -XX:-TieredCompilation -XX:+StressIncrementalInlining\n+ *                   -XX:Tier0BackedgeNotifyFreqLog=0 -XX:Tier2BackedgeNotifyFreqLog=0 -XX:Tier3BackedgeNotifyFreqLog=0\n+ *                   -XX:Tier2BackEdgeThreshold=1 -XX:Tier3BackEdgeThreshold=1 -XX:Tier4BackEdgeThreshold=1 -Xbatch\n+ *                   compiler.valhalla.inlinetypes.TestValueConstruction\n+ *\/\n+\n@@ -1641,1 +1660,32 @@\n-    public static void main(String[] args) throws Exception {\n+    private static final MethodHandle MULTIPLE_OCCURRENCES_IN_JVMS = InstructionHelper.buildMethodHandle(MethodHandles.lookup(),\n+            \"multipleOccurrencesInJVMSReturnStack\",\n+            MethodType.methodType(MyValue1.class, int.class),\n+            CODE -> {\n+                Label loopHead = CODE.newLabel();\n+                Label loopExit = CODE.newLabel();\n+                CODE.\n+                        new_(MyValue1.class.describeConstable().get()).\n+                        dup().\n+                        astore(1).\n+                        astore(2).\n+                        iconst_0().\n+                        istore(3).\n+                        labelBinding(loopHead).\n+                        iload(3).\n+                        ldc(100).\n+                        if_icmpge(loopExit).\n+                        iinc(3, 1).\n+                        goto_(loopHead).\n+                        labelBinding(loopExit).\n+                        aload(2).\n+                        iload(0).\n+                        invokespecial(MyValue1.class.describeConstable().get(), \"<init>\", MethodType.methodType(void.class, int.class).describeConstable().get()).\n+                        aload(2).\n+                        areturn();\n+            });\n+\n+    public static MyValue1 testMultipleOccurrencesInJVMS(int x) throws Throwable {\n+        return (MyValue1) MULTIPLE_OCCURRENCES_IN_JVMS.invokeExact(x);\n+    }\n+\n+    public static void main(String[] args) throws Throwable {\n@@ -1707,1 +1757,1 @@\n-    private static void run(int x, boolean doCheck) {\n+    private static void run(int x, boolean doCheck) throws Throwable {\n@@ -1768,0 +1818,1 @@\n+        check(testMultipleOccurrencesInJVMS(x), new MyValue1(x), doCheck);\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestValueConstruction.java","additions":79,"deletions":28,"binary":false,"changes":107,"status":"modified"}]}