{"files":[{"patch":"@@ -27,0 +27,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -72,0 +73,1 @@\n+#include \"opto\/multnode.hpp\"\n@@ -2193,1 +2195,2 @@\n-        if ((n->is_Phi() && n->adr_type() != TypePtr::BOTTOM) || n->is_Mem() || n->adr_type() == TypeAryPtr::INLINES) {\n+        if ((n->is_Phi() && n->adr_type() != TypePtr::BOTTOM) || n->is_Mem() ||\n+            (n->adr_type() == TypeAryPtr::INLINES && !n->is_NarrowMemProj())) {\n@@ -2243,1 +2246,1 @@\n-          assert(n->adr_type() == TypePtr::BOTTOM || (n->Opcode() == Op_Node && n->_idx >= last) || (n->is_Proj() && n->in(0)->is_Initialize()), \"\");\n+          assert(n->adr_type() == TypePtr::BOTTOM || (n->Opcode() == Op_Node && n->_idx >= last) || n->is_NarrowMemProj(), \"\");\n@@ -2247,1 +2250,47 @@\n-          mm = MergeMemNode::make(n);\n+          if (n->is_NarrowMemProj()) {\n+            \/\/ We need 1 NarrowMemProj for each slice of this array\n+            InitializeNode* init = n->in(0)->as_Initialize();\n+            AllocateNode* alloc = init->allocation();\n+            Node* klass_node = alloc->in(AllocateNode::KlassNode);\n+            const TypeAryKlassPtr* klass_type = klass_node->bottom_type()->isa_aryklassptr();\n+            assert(klass_type != nullptr, \"must be an array\");\n+            assert(klass_type->klass_is_exact(), \"must be an exact klass\");\n+            ciArrayKlass* klass = klass_type->exact_klass()->as_array_klass();\n+            assert(klass->is_flat_array_klass(), \"must be a flat array\");\n+            ciInlineKlass* elem_klass = klass->element_klass()->as_inline_klass();\n+            const TypeAryPtr* oop_type = klass_type->as_instance_type()->is_aryptr();\n+            assert(oop_type->klass_is_exact(), \"must be an exact klass\");\n+\n+            Node* base = alloc->in(TypeFunc::Memory);\n+            assert(base->bottom_type() == Type::MEMORY, \"the memory input of AllocateNode must be a memory\");\n+            assert(base->adr_type() == TypePtr::BOTTOM, \"the memory input of AllocateNode must be a bottom memory\");\n+            mm = MergeMemNode::make(base);\n+            mm->set_memory_at(index, mm->empty_memory());\n+            for (int j = 0; j < elem_klass->nof_nonstatic_fields(); j++) {\n+              int field_offset = elem_klass->nonstatic_field_at(j)->offset_in_bytes() - elem_klass->payload_offset();\n+              const TypeAryPtr* field_ptr = oop_type->with_offset(Type::OffsetBot)->with_field_offset(field_offset);\n+              int field_alias_idx = get_alias_index(field_ptr);\n+              assert(field_ptr == get_adr_type(field_alias_idx), \"must match\");\n+              Node* new_proj = new NarrowMemProjNode(init, field_ptr);\n+              igvn.register_new_node_with_optimizer(new_proj);\n+              mm->set_memory_at(field_alias_idx, new_proj);\n+            }\n+            if (!klass->is_elem_null_free()) {\n+              int nm_offset = elem_klass->null_marker_offset_in_payload();\n+              const TypeAryPtr* nm_ptr = oop_type->with_offset(Type::OffsetBot)->with_field_offset(nm_offset);\n+              int nm_alias_idx = get_alias_index(nm_ptr);\n+              assert(nm_ptr == get_adr_type(nm_alias_idx), \"must match\");\n+              Node* new_proj = new NarrowMemProjNode(init, nm_ptr);\n+              igvn.register_new_node_with_optimizer(new_proj);\n+              mm->set_memory_at(nm_alias_idx, new_proj);\n+            }\n+\n+            \/\/ Replace all uses of the old NarrowMemProj with the correct state\n+            MergeMemNode* new_n = MergeMemNode::make(mm);\n+            igvn.register_new_node_with_optimizer(new_n);\n+            igvn.replace_node(n, new_n);\n+          } else {\n+            mm = MergeMemNode::make(n);\n+            mm->set_memory_at(index, mm->empty_memory());\n+          }\n+\n@@ -2261,1 +2310,3 @@\n-              igvn.replace_input_of(m, idx, mm);\n+              Node* new_phi_in = MergeMemNode::make(mm);\n+              igvn.register_new_node_with_optimizer(new_phi_in);\n+              igvn.replace_input_of(m, idx, new_phi_in);\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":55,"deletions":4,"binary":false,"changes":59,"status":"modified"},{"patch":"@@ -4630,1 +4630,4 @@\n-          const TypePtr* new_adr_type = tinst->add_offset(adr_type->offset());\n+          const TypePtr* new_adr_type = tinst->with_offset(adr_type->offset());\n+          if (adr_type->isa_aryptr()) {\n+            new_adr_type = new_adr_type->is_aryptr()->with_field_offset(adr_type->is_aryptr()->field_offset().get());\n+          }\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -46,0 +46,1 @@\n+#include \"opto\/multnode.hpp\"\n@@ -4179,28 +4180,8 @@\n-      const TypeAryPtr* arytype = oop_type->is_aryptr();\n-      if (arytype->is_flat()) {\n-        \/\/ Initially all flat array accesses share a single slice\n-        \/\/ but that changes after parsing. Prepare the memory graph so\n-        \/\/ it can optimize flat array accesses properly once they\n-        \/\/ don't share a single slice.\n-        assert(C->flat_accesses_share_alias(), \"should be set at parse time\");\n-        C->set_flat_accesses_share_alias(false);\n-        ciInlineKlass* vk = arytype->elem()->inline_klass();\n-        for (int i = 0, len = vk->nof_nonstatic_fields(); i < len; i++) {\n-          ciField* field = vk->nonstatic_field_at(i);\n-          if (field->offset_in_bytes() >= TrackedInitializationLimit * HeapWordSize)\n-            continue;  \/\/ do not bother to track really large numbers of fields\n-          int off_in_vt = field->offset_in_bytes() - vk->payload_offset();\n-          const TypePtr* adr_type = arytype->with_field_offset(off_in_vt)->add_offset(Type::OffsetBot);\n-          int fieldidx = C->get_alias_index(adr_type, true);\n-          \/\/ Pass nullptr for init_out. Having per flat array element field memory edges as uses of the Initialize node\n-          \/\/ can result in per flat array field Phis to be created which confuses the logic of\n-          \/\/ Compile::adjust_flat_array_access_aliases().\n-          hook_memory_on_init(*this, fieldidx, minit_in, nullptr);\n-        }\n-        C->set_flat_accesses_share_alias(true);\n-        hook_memory_on_init(*this, C->get_alias_index(TypeAryPtr::INLINES), minit_in, minit_out);\n-      } else {\n-        const TypePtr* telemref = oop_type->add_offset(Type::OffsetBot);\n-        int            elemidx  = C->get_alias_index(telemref);\n-        hook_memory_on_init(*this, elemidx, minit_in, _gvn.transform(new NarrowMemProjNode(init, C->get_adr_type(elemidx))));\n-      }\n+      \/\/ Initially all flat array accesses share a single slice\n+      \/\/ but that changes after parsing. Prepare the memory graph so\n+      \/\/ it can optimize flat array accesses properly once they\n+      \/\/ don't share a single slice.\n+      assert(C->flat_accesses_share_alias(), \"should be set at parse time\");\n+      const TypePtr* telemref = oop_type->add_offset(Type::OffsetBot);\n+      int            elemidx  = C->get_alias_index(telemref);\n+      hook_memory_on_init(*this, elemidx, minit_in, _gvn.transform(new NarrowMemProjNode(init, C->get_adr_type(elemidx))));\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":9,"deletions":28,"binary":false,"changes":37,"status":"modified"}]}