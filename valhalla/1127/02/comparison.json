{"files":[{"patch":"@@ -501,0 +501,7 @@\n+  bool needs_range_check(const TypeInt* size_type, const Node* index) const;\n+  Node* create_speculative_inline_type_array_checks(Node* array, const TypeAryPtr* array_type, const Type*& element_type);\n+  Node* cast_to_speculative_array_type(Node* array, const TypeAryPtr*& array_type, const Type*& element_type);\n+  Node* cast_to_profiled_array_type(Node* const array);\n+  Node* speculate_non_null_free_array(Node* array, const TypeAryPtr*& array_type);\n+  Node* speculate_non_flat_array(Node* array, const TypeAryPtr* array_type);\n+  void create_range_check(Node* idx, Node* ary, const TypeInt* sizetype);\n","filename":"src\/hotspot\/share\/opto\/parse.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -105,2 +105,8 @@\n-      Node* ld = access_load_at(ary, adr, adr_type, elemptr, bt,\n-                                IN_HEAP | IS_ARRAY | C2_CONTROL_DEPENDENT_LOAD);\n+      DecoratorSet decorator_set = IN_HEAP | IS_ARRAY | C2_CONTROL_DEPENDENT_LOAD;\n+      if (needs_range_check(ary_t->size(), idx)) {\n+        \/\/ We've emitted a RangeCheck but now insert an additional check between the range check and the actual load.\n+        \/\/ We cannot pin the load to two separate nodes. Instead, we pin it conservatively here such that it cannot\n+        \/\/ possibly float above the range check at any point.\n+        decorator_set |= C2_UNKNOWN_CONTROL_LOAD;\n+      }\n+      Node* ld = access_load_at(ary, adr, adr_type, elemptr, bt, decorator_set);\n@@ -354,11 +360,0 @@\n-  \/\/ Check for big class initializers with all constant offsets\n-  \/\/ feeding into a known-size array.\n-  const TypeInt* idxtype = _gvn.type(idx)->is_int();\n-  \/\/ See if the highest idx value is less than the lowest array bound,\n-  \/\/ and if the idx value cannot be negative:\n-  bool need_range_check = true;\n-  if (idxtype->_hi < sizetype->_lo && idxtype->_lo >= 0) {\n-    need_range_check = false;\n-    if (C->log() != nullptr)   C->log()->elem(\"observe that='!need_range_check'\");\n-  }\n-\n@@ -376,12 +371,1 @@\n-  \/\/ Do the range check\n-  if (need_range_check) {\n-    Node* tst;\n-    if (sizetype->_hi <= 0) {\n-      \/\/ The greatest array bound is negative, so we can conclude that we're\n-      \/\/ compiling unreachable code, but the unsigned compare trick used below\n-      \/\/ only works with non-negative lengths.  Instead, hack \"tst\" to be zero so\n-      \/\/ the uncommon_trap path will always be taken.\n-      tst = _gvn.intcon(0);\n-    } else {\n-      \/\/ Range is constant in array-oop, so we can use the original state of mem\n-      Node* len = load_array_length(ary);\n+  ary = create_speculative_inline_type_array_checks(ary, arytype, elemtype);\n@@ -389,31 +373,4 @@\n-      \/\/ Test length vs index (standard trick using unsigned compare)\n-      Node* chk = _gvn.transform( new CmpUNode(idx, len) );\n-      BoolTest::mask btest = BoolTest::lt;\n-      tst = _gvn.transform( new BoolNode(chk, btest) );\n-    }\n-    RangeCheckNode* rc = new RangeCheckNode(control(), tst, PROB_MAX, COUNT_UNKNOWN);\n-    _gvn.set_type(rc, rc->Value(&_gvn));\n-    if (!tst->is_Con()) {\n-      record_for_igvn(rc);\n-    }\n-    set_control(_gvn.transform(new IfTrueNode(rc)));\n-    \/\/ Branch to failure if out of bounds\n-    {\n-      PreserveJVMState pjvms(this);\n-      set_control(_gvn.transform(new IfFalseNode(rc)));\n-      if (C->allow_range_check_smearing()) {\n-        \/\/ Do not use builtin_throw, since range checks are sometimes\n-        \/\/ made more stringent by an optimistic transformation.\n-        \/\/ This creates \"tentative\" range checks at this point,\n-        \/\/ which are not guaranteed to throw exceptions.\n-        \/\/ See IfNode::Ideal, is_range_check, adjust_check.\n-        uncommon_trap(Deoptimization::Reason_range_check,\n-                      Deoptimization::Action_make_not_entrant,\n-                      nullptr, \"range_check\");\n-      } else {\n-        \/\/ If we have already recompiled with the range-check-widening\n-        \/\/ heroic optimization turned off, then we must really be throwing\n-        \/\/ range check exceptions.\n-        builtin_throw(Deoptimization::Reason_range_check);\n-      }\n-    }\n+  if (needs_range_check(sizetype, idx)) {\n+    create_range_check(idx, ary, sizetype);\n+  } else if (C->log() != nullptr) {\n+    C->log()->elem(\"observe that='!need_range_check'\");\n@@ -421,0 +378,1 @@\n+\n@@ -424,38 +382,56 @@\n-  \/\/ This could be an access to an inline type array. We can't tell if it's\n-  \/\/ flat or not. Knowing the exact type avoids runtime checks and leads to\n-  \/\/ a much simpler graph shape. Check profile information.\n-  if (!arytype->is_flat() && !arytype->is_not_flat()) {\n-    \/\/ First check the speculative type\n-    Deoptimization::DeoptReason reason = Deoptimization::Reason_speculate_class_check;\n-    ciKlass* array_type = arytype->speculative_type();\n-    if (too_many_traps_or_recompiles(reason) || array_type == nullptr) {\n-      \/\/ No speculative type, check profile data at this bci\n-      array_type = nullptr;\n-      reason = Deoptimization::Reason_class_check;\n-      if (UseArrayLoadStoreProfile && !too_many_traps_or_recompiles(reason)) {\n-        ciKlass* element_type = nullptr;\n-        ProfilePtrKind element_ptr = ProfileMaybeNull;\n-        bool flat_array = true;\n-        bool null_free_array = true;\n-        method()->array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);\n-      }\n-    }\n-    if (array_type != nullptr) {\n-      \/\/ Speculate that this array has the exact type reported by profile data\n-      Node* better_ary = nullptr;\n-      DEBUG_ONLY(Node* old_control = control();)\n-      Node* slow_ctl = type_check_receiver(ary, array_type, 1.0, &better_ary);\n-      if (stopped()) {\n-        \/\/ The check always fails and therefore profile information is incorrect. Don't use it.\n-        assert(old_control == slow_ctl, \"type check should have been removed\");\n-        set_control(slow_ctl);\n-      } else if (!slow_ctl->is_top()) {\n-        { PreserveJVMState pjvms(this);\n-          set_control(slow_ctl);\n-          uncommon_trap_exact(reason, Deoptimization::Action_maybe_recompile);\n-        }\n-        replace_in_map(ary, better_ary);\n-        ary = better_ary;\n-        arytype  = _gvn.type(ary)->is_aryptr();\n-        elemtype = arytype->elem();\n-      }\n+  \/\/ Make array address computation control dependent to prevent it\n+  \/\/ from floating above the range check during loop optimizations.\n+  Node* ptr = array_element_address(ary, idx, type, sizetype, control());\n+  assert(ptr != top(), \"top should go hand-in-hand with stopped\");\n+\n+  return ptr;\n+}\n+\n+\/\/ Check if we need a range check for an array access. This is the case if the index is either negative or if it could\n+\/\/ be greater or equal the smallest possible array size (i.e. out-of-bounds).\n+bool Parse::needs_range_check(const TypeInt* size_type, const Node* index) const {\n+  const TypeInt* index_type = _gvn.type(index)->is_int();\n+  return index_type->_hi >= size_type->_lo || index_type->_lo < 0;\n+}\n+\n+void Parse::create_range_check(Node* idx, Node* ary, const TypeInt* sizetype) {\n+  Node* tst;\n+  if (sizetype->_hi <= 0) {\n+    \/\/ The greatest array bound is negative, so we can conclude that we're\n+    \/\/ compiling unreachable code, but the unsigned compare trick used below\n+    \/\/ only works with non-negative lengths.  Instead, hack \"tst\" to be zero so\n+    \/\/ the uncommon_trap path will always be taken.\n+    tst = _gvn.intcon(0);\n+  } else {\n+    \/\/ Range is constant in array-oop, so we can use the original state of mem\n+    Node* len = load_array_length(ary);\n+\n+    \/\/ Test length vs index (standard trick using unsigned compare)\n+    Node* chk = _gvn.transform(new CmpUNode(idx, len) );\n+    BoolTest::mask btest = BoolTest::lt;\n+    tst = _gvn.transform(new BoolNode(chk, btest) );\n+  }\n+  RangeCheckNode* rc = new RangeCheckNode(control(), tst, PROB_MAX, COUNT_UNKNOWN);\n+  _gvn.set_type(rc, rc->Value(&_gvn));\n+  if (!tst->is_Con()) {\n+    record_for_igvn(rc);\n+  }\n+  set_control(_gvn.transform(new IfTrueNode(rc)));\n+  \/\/ Branch to failure if out of bounds\n+  {\n+    PreserveJVMState pjvms(this);\n+    set_control(_gvn.transform(new IfFalseNode(rc)));\n+    if (C->allow_range_check_smearing()) {\n+      \/\/ Do not use builtin_throw, since range checks are sometimes\n+      \/\/ made more stringent by an optimistic transformation.\n+      \/\/ This creates \"tentative\" range checks at this point,\n+      \/\/ which are not guaranteed to throw exceptions.\n+      \/\/ See IfNode::Ideal, is_range_check, adjust_check.\n+      uncommon_trap(Deoptimization::Reason_range_check,\n+                    Deoptimization::Action_make_not_entrant,\n+                    nullptr, \"range_check\");\n+    } else {\n+      \/\/ If we have already recompiled with the range-check-widening\n+      \/\/ heroic optimization turned off, then we must really be throwing\n+      \/\/ range check exceptions.\n+      builtin_throw(Deoptimization::Reason_range_check);\n@@ -463,0 +439,13 @@\n+  }\n+}\n+\n+\/\/ For inline type arrays, we can use the profiling information for array accesses to speculate on the type, flatness,\n+\/\/ and null-freeness. We can either prepare the speculative type for later uses or emit explicit speculative checks with\n+\/\/ traps now. In the latter case, the speculative type guarantees can avoid additional runtime checks later (e.g.\n+\/\/ non-null-free implies non-flat which allows us to remove flatness checks). This makes the graph simpler.\n+Node* Parse::create_speculative_inline_type_array_checks(Node* array, const TypeAryPtr* array_type,\n+                                                         const Type*& element_type) {\n+  if (!array_type->is_flat() && !array_type->is_not_flat()) {\n+    \/\/ For arrays that might be flat, speculate that the array has the exact type reported in the profile data such that\n+    \/\/ we can rely on a fixed memory layout (i.e. either a flat layout or not).\n+    array = cast_to_speculative_array_type(array, array_type, element_type);\n@@ -464,11 +453,3 @@\n-    \/\/ No need to speculate: feed profile data at this bci for the\n-    \/\/ array to type speculation\n-    ciKlass* array_type = nullptr;\n-    ciKlass* element_type = nullptr;\n-    ProfilePtrKind element_ptr = ProfileMaybeNull;\n-    bool flat_array = true;\n-    bool null_free_array = true;\n-    method()->array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);\n-    if (array_type != nullptr) {\n-      ary = record_profile_for_speculation(ary, array_type, ProfileMaybeNull);\n-    }\n+    \/\/ Array is known to be either flat or not flat. If possible, update the speculative type by using the profile data\n+    \/\/ at this bci.\n+    array = cast_to_profiled_array_type(array);\n@@ -477,32 +458,5 @@\n-  \/\/ We have no exact array type from profile data. Check profile data\n-  \/\/ for a non null-free or non flat array. Non null-free implies non\n-  \/\/ flat so check this one first. Speculating on a non null-free\n-  \/\/ array doesn't help aaload but could be profitable for a\n-  \/\/ subsequent aastore.\n-  if (!arytype->is_null_free() && !arytype->is_not_null_free()) {\n-    bool null_free_array = true;\n-    Deoptimization::DeoptReason reason = Deoptimization::Reason_none;\n-    if (arytype->speculative() != nullptr &&\n-        arytype->speculative()->is_aryptr()->is_not_null_free() &&\n-        !too_many_traps_or_recompiles(Deoptimization::Reason_speculate_class_check)) {\n-      null_free_array = false;\n-      reason = Deoptimization::Reason_speculate_class_check;\n-    } else if (UseArrayLoadStoreProfile && !too_many_traps_or_recompiles(Deoptimization::Reason_class_check)) {\n-      ciKlass* array_type = nullptr;\n-      ciKlass* element_type = nullptr;\n-      ProfilePtrKind element_ptr = ProfileMaybeNull;\n-      bool flat_array = true;\n-      method()->array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);\n-      reason = Deoptimization::Reason_class_check;\n-    }\n-    if (!null_free_array) {\n-      { \/\/ Deoptimize if null-free array\n-        BuildCutout unless(this, null_free_array_test(ary, \/* null_free = *\/ false), PROB_MAX);\n-        uncommon_trap_exact(reason, Deoptimization::Action_maybe_recompile);\n-      }\n-      assert(!stopped(), \"null-free array should have been caught earlier\");\n-      Node* better_ary = _gvn.transform(new CheckCastPPNode(control(), ary, arytype->cast_to_not_null_free()));\n-      replace_in_map(ary, better_ary);\n-      ary = better_ary;\n-      arytype = _gvn.type(ary)->is_aryptr();\n-    }\n+  \/\/ Even though the type does not tell us whether we have an inline type array or not, we can still check the profile data\n+  \/\/ whether we have a non-null-free or non-flat array. Since non-null-free implies non-flat, we check this first.\n+  \/\/ Speculating on a non-null-free array doesn't help aaload but could be profitable for a subsequent aastore.\n+  if (!array_type->is_null_free() && !array_type->is_not_null_free()) {\n+    array = speculate_non_null_free_array(array, array_type);\n@@ -511,11 +465,17 @@\n-  if (!arytype->is_flat() && !arytype->is_not_flat()) {\n-    bool flat_array = true;\n-    Deoptimization::DeoptReason reason = Deoptimization::Reason_none;\n-    if (arytype->speculative() != nullptr &&\n-        arytype->speculative()->is_aryptr()->is_not_flat() &&\n-        !too_many_traps_or_recompiles(Deoptimization::Reason_speculate_class_check)) {\n-      flat_array = false;\n-      reason = Deoptimization::Reason_speculate_class_check;\n-    } else if (UseArrayLoadStoreProfile && !too_many_traps_or_recompiles(reason)) {\n-      ciKlass* array_type = nullptr;\n-      ciKlass* element_type = nullptr;\n+  if (!array_type->is_flat() && !array_type->is_not_flat()) {\n+    array = speculate_non_flat_array(array, array_type);\n+  }\n+  return array;\n+}\n+\n+\/\/ Speculate that the array has the exact type reported in the profile data. We emit a trap when this turns out to be\n+\/\/ wrong. On the fast path, we add a CheckCastPP to use the exact type.\n+Node* Parse::cast_to_speculative_array_type(Node* const array, const TypeAryPtr*& array_type, const Type*& element_type) {\n+  Deoptimization::DeoptReason reason = Deoptimization::Reason_speculate_class_check;\n+  ciKlass* speculative_array_type = array_type->speculative_type();\n+  if (too_many_traps_or_recompiles(reason) || speculative_array_type == nullptr) {\n+    \/\/ No speculative type, check profile data at this bci\n+    speculative_array_type = nullptr;\n+    reason = Deoptimization::Reason_class_check;\n+    if (UseArrayLoadStoreProfile && !too_many_traps_or_recompiles(reason)) {\n+      ciKlass* profiled_element_type = nullptr;\n@@ -523,0 +483,1 @@\n+      bool flat_array = true;\n@@ -524,2 +485,2 @@\n-      method()->array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);\n-      reason = Deoptimization::Reason_class_check;\n+      method()->array_access_profiled_type(bci(), speculative_array_type, profiled_element_type, element_ptr, flat_array,\n+                                           null_free_array);\n@@ -527,3 +488,13 @@\n-    if (!flat_array) {\n-      { \/\/ Deoptimize if flat array\n-        BuildCutout unless(this, flat_array_test(ary, \/* flat = *\/ false), PROB_MAX);\n+  }\n+  if (speculative_array_type != nullptr) {\n+    \/\/ Speculate that this array has the exact type reported by profile data\n+    Node* casted_array = nullptr;\n+    DEBUG_ONLY(Node* old_control = control();)\n+    Node* slow_ctl = type_check_receiver(array, speculative_array_type, 1.0, &casted_array);\n+    if (stopped()) {\n+      \/\/ The check always fails and therefore profile information is incorrect. Don't use it.\n+      assert(old_control == slow_ctl, \"type check should have been removed\");\n+      set_control(slow_ctl);\n+    } else if (!slow_ctl->is_top()) {\n+      { PreserveJVMState pjvms(this);\n+        set_control(slow_ctl);\n@@ -532,5 +503,4 @@\n-      assert(!stopped(), \"flat array should have been caught earlier\");\n-      Node* better_ary = _gvn.transform(new CheckCastPPNode(control(), ary, arytype->cast_to_not_flat()));\n-      replace_in_map(ary, better_ary);\n-      ary = better_ary;\n-      arytype = _gvn.type(ary)->is_aryptr();\n+      replace_in_map(array, casted_array);\n+      array_type = _gvn.type(casted_array)->is_aryptr();\n+      element_type = array_type->elem();\n+      return casted_array;\n@@ -539,0 +509,2 @@\n+  return array;\n+}\n@@ -540,4 +512,13 @@\n-  \/\/ Make array address computation control dependent to prevent it\n-  \/\/ from floating above the range check during loop optimizations.\n-  Node* ptr = array_element_address(ary, idx, type, sizetype, control());\n-  assert(ptr != top(), \"top should go hand-in-hand with stopped\");\n+\/\/ Create a CheckCastPP when the speculative type can improve the current type.\n+Node* Parse::cast_to_profiled_array_type(Node* const array) {\n+  ciKlass* array_type = nullptr;\n+  ciKlass* element_type = nullptr;\n+  ProfilePtrKind element_ptr = ProfileMaybeNull;\n+  bool flat_array = true;\n+  bool null_free_array = true;\n+  method()->array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);\n+  if (array_type != nullptr) {\n+    return record_profile_for_speculation(array, array_type, ProfileMaybeNull);\n+  }\n+  return array;\n+}\n@@ -545,1 +526,31 @@\n-  return ptr;\n+\/\/ Speculate that the array is non-null-free. This will imply non-flatness. We emit a trap when this turns out to be\n+\/\/ wrong. On the fast path, we add a CheckCastPP to use the non-null-free type.\n+Node* Parse::speculate_non_null_free_array(Node* const array, const TypeAryPtr*& array_type) {\n+  bool null_free_array = true;\n+  Deoptimization::DeoptReason reason = Deoptimization::Reason_none;\n+  if (array_type->speculative() != nullptr &&\n+      array_type->speculative()->is_aryptr()->is_not_null_free() &&\n+      !too_many_traps_or_recompiles(Deoptimization::Reason_speculate_class_check)) {\n+    null_free_array = false;\n+    reason = Deoptimization::Reason_speculate_class_check;\n+  } else if (UseArrayLoadStoreProfile && !too_many_traps_or_recompiles(Deoptimization::Reason_class_check)) {\n+    ciKlass* profiled_array_type = nullptr;\n+    ciKlass* profiled_element_type = nullptr;\n+    ProfilePtrKind element_ptr = ProfileMaybeNull;\n+    bool flat_array = true;\n+    method()->array_access_profiled_type(bci(), profiled_array_type, profiled_element_type, element_ptr, flat_array,\n+                                         null_free_array);\n+    reason = Deoptimization::Reason_class_check;\n+  }\n+  if (!null_free_array) {\n+    { \/\/ Deoptimize if null-free array\n+      BuildCutout unless(this, null_free_array_test(array, \/* null_free = *\/ false), PROB_MAX);\n+      uncommon_trap_exact(reason, Deoptimization::Action_maybe_recompile);\n+    }\n+    assert(!stopped(), \"null-free array should have been caught earlier\");\n+    Node* casted_array = _gvn.transform(new CheckCastPPNode(control(), array, array_type->cast_to_not_null_free()));\n+    replace_in_map(array, casted_array);\n+    array_type = _gvn.type(casted_array)->is_aryptr();\n+    return casted_array;\n+  }\n+  return array;\n@@ -548,0 +559,31 @@\n+\/\/ Speculate that the array is non-flat. We emit a trap when this turns out to be wrong. On the fast path, we add a\n+\/\/ CheckCastPP to use the non-flat type.\n+Node* Parse::speculate_non_flat_array(Node* const array, const TypeAryPtr* const array_type) {\n+  bool flat_array = true;\n+  Deoptimization::DeoptReason reason = Deoptimization::Reason_none;\n+  if (array_type->speculative() != nullptr &&\n+      array_type->speculative()->is_aryptr()->is_not_flat() &&\n+      !too_many_traps_or_recompiles(Deoptimization::Reason_speculate_class_check)) {\n+    flat_array = false;\n+    reason = Deoptimization::Reason_speculate_class_check;\n+  } else if (UseArrayLoadStoreProfile && !too_many_traps_or_recompiles(reason)) {\n+    ciKlass* profiled_array_type = nullptr;\n+    ciKlass* profiled_element_type = nullptr;\n+    ProfilePtrKind element_ptr = ProfileMaybeNull;\n+    bool null_free_array = true;\n+    method()->array_access_profiled_type(bci(), profiled_array_type, profiled_element_type, element_ptr, flat_array,\n+                                         null_free_array);\n+    reason = Deoptimization::Reason_class_check;\n+  }\n+  if (!flat_array) {\n+    { \/\/ Deoptimize if flat array\n+      BuildCutout unless(this, flat_array_test(array, \/* flat = *\/ false), PROB_MAX);\n+      uncommon_trap_exact(reason, Deoptimization::Action_maybe_recompile);\n+    }\n+    assert(!stopped(), \"flat array should have been caught earlier\");\n+    Node* casted_array = _gvn.transform(new CheckCastPPNode(control(), array, array_type->cast_to_not_flat()));\n+    replace_in_map(array, casted_array);\n+    return casted_array;\n+  }\n+  return array;\n+}\n","filename":"src\/hotspot\/share\/opto\/parse2.cpp","additions":205,"deletions":163,"binary":false,"changes":368,"status":"modified"},{"patch":"@@ -0,0 +1,76 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/**\n+ * @test\n+ * @key stress randomness\n+ * @bug 8333889\n+ * @summary Test that speculative array access checks do not cause a load to be wrongly hoisted before its range check.\n+ * @run main\/othervm -XX:CompileCommand=dontinline,*::* -XX:CompileCommand=compileonly,*TestSpeculateArrayAccess::test\n+ *                   -Xbatch -XX:+UnlockDiagnosticVMOptions -XX:+StressGCM -XX:StressSeed=1202682944\n+ *                   compiler.valhalla.inlinetypes.TestSpeculateArrayAccess\n+ * @run main\/othervm -XX:CompileCommand=dontinline,*::* -XX:CompileCommand=compileonly,*TestSpeculateArrayAccess::test\n+ *                   -Xbatch -XX:+UnlockDiagnosticVMOptions -XX:+StressGCM\n+ *                   compiler.valhalla.inlinetypes.TestSpeculateArrayAccess\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+\n+public class TestSpeculateArrayAccess {\n+    static Object[] oArr = new Object[100];\n+    static int iFld = 100;\n+\n+    public static void main(String[] args) {\n+        for (int i = 0; i < 100; i++) {\n+            oArr[i] = new Object();\n+        }\n+        iFld = 1;\n+        for (int i = 0; i < 1000; i++) {\n+            test();\n+        }\n+        iFld = -1;\n+\n+        try {\n+            test();\n+        } catch (ArrayIndexOutOfBoundsException e) {\n+            \/\/ Expected.\n+        }\n+    }\n+\n+    static void test() {\n+        Object[] oA = oArr; \/\/ Load here to avoid G1 barriers being expanded inside loop which prevents Loop Predication.\n+        for (float i = 0; i < 100; i++) {\n+            \/\/ RangeCheck -> If-Speculative-Array-Type -> CastII\n+            \/\/\n+            \/\/ At Loop Predication:\n+            \/\/ - RangeCheck not hoisted because loop dependent\n+            \/\/ - If-Speculative-Array-Type hoisted and CastII and LoadN ends up before loop\n+            \/\/\n+            \/\/ Running with -XX:+StressGCM: We could execute the LoadN before entering the loop.\n+            \/\/ This crashes when iFld = -1 because we then access an out-of-bounds element.\n+            Object o = oA[(int)i*iFld];\n+            o.toString(); \/\/ Use the object with its speculated type.\n+        }\n+    }\n+}\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestSpeculateArrayAccess.java","additions":76,"deletions":0,"binary":false,"changes":76,"status":"added"}]}