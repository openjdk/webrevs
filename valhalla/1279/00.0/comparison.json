{"files":[{"patch":"@@ -2715,1 +2715,1 @@\n-      \/* Fix up any out-of-range offsets. *\/\n+      \/\/ Fix up any out-of-range offsets.\n@@ -2756,1 +2756,5 @@\n-      (masm->*insn)(reg, T, Address(base, disp));\n+      \/\/ Fix up any out-of-range offsets.\n+      assert_different_registers(rscratch1, base);\n+      Address addr = Address(base, disp);\n+      addr = __ legitimize_address(addr, (1 << T), rscratch1);\n+      (masm->*insn)(reg, T, addr);\n@@ -2811,1 +2815,1 @@\n-  enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{\n+  enc_class aarch64_enc_ldrsbw(iRegI dst, memory mem) %{\n@@ -2819,1 +2823,1 @@\n-  enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{\n+  enc_class aarch64_enc_ldrsb(iRegI dst, memory mem) %{\n@@ -2827,1 +2831,1 @@\n-  enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{\n+  enc_class aarch64_enc_ldrb(iRegI dst, memory mem) %{\n@@ -2835,1 +2839,1 @@\n-  enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{\n+  enc_class aarch64_enc_ldrb(iRegL dst, memory mem) %{\n@@ -2843,1 +2847,1 @@\n-  enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{\n+  enc_class aarch64_enc_ldrshw(iRegI dst, memory mem) %{\n@@ -2851,1 +2855,1 @@\n-  enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{\n+  enc_class aarch64_enc_ldrsh(iRegI dst, memory mem) %{\n@@ -2859,1 +2863,1 @@\n-  enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{\n+  enc_class aarch64_enc_ldrh(iRegI dst, memory mem) %{\n@@ -2867,1 +2871,1 @@\n-  enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{\n+  enc_class aarch64_enc_ldrh(iRegL dst, memory mem) %{\n@@ -2875,1 +2879,1 @@\n-  enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{\n+  enc_class aarch64_enc_ldrw(iRegI dst, memory mem) %{\n@@ -2883,1 +2887,1 @@\n-  enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{\n+  enc_class aarch64_enc_ldrw(iRegL dst, memory mem) %{\n@@ -2891,1 +2895,1 @@\n-  enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{\n+  enc_class aarch64_enc_ldrsw(iRegL dst, memory mem) %{\n@@ -2899,1 +2903,1 @@\n-  enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{\n+  enc_class aarch64_enc_ldr(iRegL dst, memory mem) %{\n@@ -2907,1 +2911,1 @@\n-  enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{\n+  enc_class aarch64_enc_ldrs(vRegF dst, memory mem) %{\n@@ -2915,1 +2919,1 @@\n-  enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{\n+  enc_class aarch64_enc_ldrd(vRegD dst, memory mem) %{\n@@ -2923,1 +2927,1 @@\n-  enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{\n+  enc_class aarch64_enc_strb(iRegI src, memory mem) %{\n@@ -2931,1 +2935,1 @@\n-  enc_class aarch64_enc_strb0(memory1 mem) %{\n+  enc_class aarch64_enc_strb0(memory mem) %{\n@@ -2938,1 +2942,1 @@\n-  enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{\n+  enc_class aarch64_enc_strh(iRegI src, memory mem) %{\n@@ -2946,1 +2950,1 @@\n-  enc_class aarch64_enc_strh0(memory2 mem) %{\n+  enc_class aarch64_enc_strh0(memory mem) %{\n@@ -2953,1 +2957,1 @@\n-  enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{\n+  enc_class aarch64_enc_strw(iRegI src, memory mem) %{\n@@ -2961,1 +2965,1 @@\n-  enc_class aarch64_enc_strw0(memory4 mem) %{\n+  enc_class aarch64_enc_strw0(memory mem) %{\n@@ -2968,1 +2972,1 @@\n-  enc_class aarch64_enc_str(iRegL src, memory8 mem) %{\n+  enc_class aarch64_enc_str(iRegL src, memory mem) %{\n@@ -2983,1 +2987,1 @@\n-  enc_class aarch64_enc_str0(memory8 mem) %{\n+  enc_class aarch64_enc_str0(memory mem) %{\n@@ -2990,1 +2994,1 @@\n-  enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{\n+  enc_class aarch64_enc_strs(vRegF src, memory mem) %{\n@@ -2998,1 +3002,1 @@\n-  enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{\n+  enc_class aarch64_enc_strd(vRegD src, memory mem) %{\n@@ -3006,1 +3010,1 @@\n-  enc_class aarch64_enc_strb0_ordered(memory4 mem) %{\n+  enc_class aarch64_enc_strb0_ordered(memory mem) %{\n@@ -3208,1 +3212,1 @@\n-  enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{\n+  enc_class aarch64_enc_ldaxr(iRegL dst, memory mem) %{\n@@ -3236,1 +3240,1 @@\n-  enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{\n+  enc_class aarch64_enc_stlxr(iRegLNoSp src, memory mem) %{\n@@ -4195,1 +4199,1 @@\n-\/\/ Offset for scaled or unscaled immediate loads and stores\n+\/\/ Offset for immediate loads and stores\n@@ -4198,51 +4202,1 @@\n-  predicate(Address::offset_ok_for_immed(n->get_int(), 0));\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immIOffset1()\n-%{\n-  predicate(Address::offset_ok_for_immed(n->get_int(), 0));\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immIOffset2()\n-%{\n-  predicate(Address::offset_ok_for_immed(n->get_int(), 1));\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immIOffset4()\n-%{\n-  predicate(Address::offset_ok_for_immed(n->get_int(), 2));\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immIOffset8()\n-%{\n-  predicate(Address::offset_ok_for_immed(n->get_int(), 3));\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immIOffset16()\n-%{\n-  predicate(Address::offset_ok_for_immed(n->get_int(), 4));\n+  predicate(n->get_int() >= -256 && n->get_int() <= 65520);\n@@ -4266,50 +4220,0 @@\n-operand immLoffset1()\n-%{\n-  predicate(Address::offset_ok_for_immed(n->get_long(), 0));\n-  match(ConL);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immLoffset2()\n-%{\n-  predicate(Address::offset_ok_for_immed(n->get_long(), 1));\n-  match(ConL);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immLoffset4()\n-%{\n-  predicate(Address::offset_ok_for_immed(n->get_long(), 2));\n-  match(ConL);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immLoffset8()\n-%{\n-  predicate(Address::offset_ok_for_immed(n->get_long(), 3));\n-  match(ConL);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immLoffset16()\n-%{\n-  predicate(Address::offset_ok_for_immed(n->get_long(), 4));\n-  match(ConL);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n@@ -5228,1 +5132,1 @@\n-operand indOffI1(iRegP reg, immIOffset1 off)\n+operand indOffI(iRegP reg, immIOffset off)\n@@ -5242,113 +5146,1 @@\n-operand indOffI2(iRegP reg, immIOffset2 off)\n-%{\n-  constraint(ALLOC_IN_RC(ptr_reg));\n-  match(AddP reg off);\n-  op_cost(0);\n-  format %{ \"[$reg, $off]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index(0xffffffff);\n-    scale(0x0);\n-    disp($off);\n-  %}\n-%}\n-\n-operand indOffI4(iRegP reg, immIOffset4 off)\n-%{\n-  constraint(ALLOC_IN_RC(ptr_reg));\n-  match(AddP reg off);\n-  op_cost(0);\n-  format %{ \"[$reg, $off]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index(0xffffffff);\n-    scale(0x0);\n-    disp($off);\n-  %}\n-%}\n-\n-operand indOffI8(iRegP reg, immIOffset8 off)\n-%{\n-  constraint(ALLOC_IN_RC(ptr_reg));\n-  match(AddP reg off);\n-  op_cost(0);\n-  format %{ \"[$reg, $off]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index(0xffffffff);\n-    scale(0x0);\n-    disp($off);\n-  %}\n-%}\n-\n-operand indOffI16(iRegP reg, immIOffset16 off)\n-%{\n-  constraint(ALLOC_IN_RC(ptr_reg));\n-  match(AddP reg off);\n-  op_cost(0);\n-  format %{ \"[$reg, $off]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index(0xffffffff);\n-    scale(0x0);\n-    disp($off);\n-  %}\n-%}\n-\n-operand indOffL1(iRegP reg, immLoffset1 off)\n-%{\n-  constraint(ALLOC_IN_RC(ptr_reg));\n-  match(AddP reg off);\n-  op_cost(0);\n-  format %{ \"[$reg, $off]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index(0xffffffff);\n-    scale(0x0);\n-    disp($off);\n-  %}\n-%}\n-\n-operand indOffL2(iRegP reg, immLoffset2 off)\n-%{\n-  constraint(ALLOC_IN_RC(ptr_reg));\n-  match(AddP reg off);\n-  op_cost(0);\n-  format %{ \"[$reg, $off]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index(0xffffffff);\n-    scale(0x0);\n-    disp($off);\n-  %}\n-%}\n-\n-operand indOffL4(iRegP reg, immLoffset4 off)\n-%{\n-  constraint(ALLOC_IN_RC(ptr_reg));\n-  match(AddP reg off);\n-  op_cost(0);\n-  format %{ \"[$reg, $off]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index(0xffffffff);\n-    scale(0x0);\n-    disp($off);\n-  %}\n-%}\n-\n-operand indOffL8(iRegP reg, immLoffset8 off)\n-%{\n-  constraint(ALLOC_IN_RC(ptr_reg));\n-  match(AddP reg off);\n-  op_cost(0);\n-  format %{ \"[$reg, $off]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index(0xffffffff);\n-    scale(0x0);\n-    disp($off);\n-  %}\n-%}\n-\n-operand indOffL16(iRegP reg, immLoffset16 off)\n+operand indOffL(iRegP reg, immLOffset off)\n@@ -5730,4 +5522,1 @@\n-opclass vmem2(indirect, indIndex, indOffI2, indOffL2);\n-opclass vmem4(indirect, indIndex, indOffI4, indOffL4);\n-opclass vmem8(indirect, indIndex, indOffI8, indOffL8);\n-opclass vmem16(indirect, indIndex, indOffI16, indOffL16);\n+opclass vmem(indirect, indIndex, indOffI, indOffL, indOffIN, indOffLN);\n@@ -5745,17 +5534,3 @@\n-opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,\n-                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indirectX2P, indOffX2P);\n-\n-opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,\n-                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indirectX2P, indOffX2P);\n-\n-opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,\n-                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN, indirectX2P, indOffX2P);\n-\n-opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,\n-                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN, indirectX2P, indOffX2P);\n-\n-\/\/ All of the memory operands. For the pipeline description.\n-opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,\n-               indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,\n-               indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN, indirectX2P, indOffX2P);\n-\n+opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI, indOffL,\n+               indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN,\n+               indOffLN, indirectX2P, indOffX2P);\n@@ -6463,1 +6238,1 @@\n-instruct loadB(iRegINoSp dst, memory1 mem)\n+instruct loadB(iRegINoSp dst, memory mem)\n@@ -6477,1 +6252,1 @@\n-instruct loadB2L(iRegLNoSp dst, memory1 mem)\n+instruct loadB2L(iRegLNoSp dst, memory mem)\n@@ -6491,1 +6266,1 @@\n-instruct loadUB(iRegINoSp dst, memory1 mem)\n+instruct loadUB(iRegINoSp dst, memory mem)\n@@ -6505,1 +6280,1 @@\n-instruct loadUB2L(iRegLNoSp dst, memory1 mem)\n+instruct loadUB2L(iRegLNoSp dst, memory mem)\n@@ -6519,1 +6294,1 @@\n-instruct loadS(iRegINoSp dst, memory2 mem)\n+instruct loadS(iRegINoSp dst, memory mem)\n@@ -6533,1 +6308,1 @@\n-instruct loadS2L(iRegLNoSp dst, memory2 mem)\n+instruct loadS2L(iRegLNoSp dst, memory mem)\n@@ -6547,1 +6322,1 @@\n-instruct loadUS(iRegINoSp dst, memory2 mem)\n+instruct loadUS(iRegINoSp dst, memory mem)\n@@ -6561,1 +6336,1 @@\n-instruct loadUS2L(iRegLNoSp dst, memory2 mem)\n+instruct loadUS2L(iRegLNoSp dst, memory mem)\n@@ -6575,1 +6350,1 @@\n-instruct loadI(iRegINoSp dst, memory4 mem)\n+instruct loadI(iRegINoSp dst, memory mem)\n@@ -6589,1 +6364,1 @@\n-instruct loadI2L(iRegLNoSp dst, memory4 mem)\n+instruct loadI2L(iRegLNoSp dst, memory mem)\n@@ -6603,1 +6378,1 @@\n-instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)\n+instruct loadUI2L(iRegLNoSp dst, memory mem, immL_32bits mask)\n@@ -6617,1 +6392,1 @@\n-instruct loadL(iRegLNoSp dst, memory8 mem)\n+instruct loadL(iRegLNoSp dst, memory mem)\n@@ -6631,1 +6406,1 @@\n-instruct loadRange(iRegINoSp dst, memory4 mem)\n+instruct loadRange(iRegINoSp dst, memory mem)\n@@ -6644,1 +6419,1 @@\n-instruct loadP(iRegPNoSp dst, memory8 mem)\n+instruct loadP(iRegPNoSp dst, memory mem)\n@@ -6658,1 +6433,1 @@\n-instruct loadN(iRegNNoSp dst, memory4 mem)\n+instruct loadN(iRegNNoSp dst, memory mem)\n@@ -6672,1 +6447,1 @@\n-instruct loadKlass(iRegPNoSp dst, memory8 mem)\n+instruct loadKlass(iRegPNoSp dst, memory mem)\n@@ -6686,1 +6461,1 @@\n-instruct loadNKlass(iRegNNoSp dst, memory4 mem)\n+instruct loadNKlass(iRegNNoSp dst, memory mem)\n@@ -6700,1 +6475,1 @@\n-instruct loadF(vRegF dst, memory4 mem)\n+instruct loadF(vRegF dst, memory mem)\n@@ -6714,1 +6489,1 @@\n-instruct loadD(vRegD dst, memory8 mem)\n+instruct loadD(vRegD dst, memory mem)\n@@ -6918,1 +6693,1 @@\n-instruct storeimmCM0(immI0 zero, memory1 mem)\n+instruct storeimmCM0(immI0 zero, memory mem)\n@@ -6933,1 +6708,1 @@\n-instruct storeimmCM0_ordered(immI0 zero, memory1 mem)\n+instruct storeimmCM0_ordered(immI0 zero, memory mem)\n@@ -6948,1 +6723,1 @@\n-instruct storeB(iRegIorL2I src, memory1 mem)\n+instruct storeB(iRegIorL2I src, memory mem)\n@@ -6962,1 +6737,1 @@\n-instruct storeimmB0(immI0 zero, memory1 mem)\n+instruct storeimmB0(immI0 zero, memory mem)\n@@ -6976,1 +6751,1 @@\n-instruct storeC(iRegIorL2I src, memory2 mem)\n+instruct storeC(iRegIorL2I src, memory mem)\n@@ -6989,1 +6764,1 @@\n-instruct storeimmC0(immI0 zero, memory2 mem)\n+instruct storeimmC0(immI0 zero, memory mem)\n@@ -7004,1 +6779,1 @@\n-instruct storeI(iRegIorL2I src, memory4 mem)\n+instruct storeI(iRegIorL2I src, memory mem)\n@@ -7017,1 +6792,1 @@\n-instruct storeimmI0(immI0 zero, memory4 mem)\n+instruct storeimmI0(immI0 zero, memory mem)\n@@ -7031,1 +6806,1 @@\n-instruct storeL(iRegL src, memory8 mem)\n+instruct storeL(iRegL src, memory mem)\n@@ -7045,1 +6820,1 @@\n-instruct storeimmL0(immL0 zero, memory8 mem)\n+instruct storeimmL0(immL0 zero, memory mem)\n@@ -7059,1 +6834,1 @@\n-instruct storeP(iRegP src, memory8 mem)\n+instruct storeP(iRegP src, memory mem)\n@@ -7073,1 +6848,1 @@\n-instruct storeimmP0(immP0 zero, memory8 mem)\n+instruct storeimmP0(immP0 zero, memory mem)\n@@ -7087,1 +6862,1 @@\n-instruct storeN(iRegN src, memory4 mem)\n+instruct storeN(iRegN src, memory mem)\n@@ -7100,1 +6875,1 @@\n-instruct storeImmN0(immN0 zero, memory4 mem)\n+instruct storeImmN0(immN0 zero, memory mem)\n@@ -7114,1 +6889,1 @@\n-instruct storeF(vRegF src, memory4 mem)\n+instruct storeF(vRegF src, memory mem)\n@@ -7131,1 +6906,1 @@\n-instruct storeD(vRegD src, memory8 mem)\n+instruct storeD(vRegD src, memory mem)\n@@ -7145,1 +6920,1 @@\n-instruct storeNKlass(iRegN src, memory4 mem)\n+instruct storeNKlass(iRegN src, memory mem)\n@@ -7164,1 +6939,1 @@\n-instruct prefetchalloc( memory8 mem ) %{\n+instruct prefetchalloc( memory mem ) %{\n@@ -7733,1 +7508,1 @@\n-instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{\n+instruct popCountI_mem(iRegINoSp dst, memory mem, vRegF tmp) %{\n@@ -7774,1 +7549,1 @@\n-instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{\n+instruct popCountL_mem(iRegINoSp dst, memory mem, vRegD tmp) %{\n@@ -16076,1 +15851,1 @@\n-    __ fast_lock_lightweight($object$$Register, $tmp$$Register, $tmp2$$Register, $tmp3$$Register);\n+    __ fast_lock_lightweight($object$$Register, $box$$Register, $tmp$$Register, $tmp2$$Register, $tmp3$$Register);\n@@ -16092,1 +15867,1 @@\n-    __ fast_unlock_lightweight($object$$Register, $tmp$$Register, $tmp2$$Register, $tmp3$$Register);\n+    __ fast_unlock_lightweight($object$$Register, $box$$Register, $tmp$$Register, $tmp2$$Register, $tmp3$$Register);\n@@ -16262,0 +16037,13 @@\n+\/\/ Forward exception.\n+instruct ForwardExceptionjmp()\n+%{\n+  match(ForwardException);\n+  ins_cost(CALL_COST);\n+\n+  format %{ \"b forward_exception_stub\" %}\n+  ins_encode %{\n+    __ far_jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+  %}\n+  ins_pipe(pipe_class_call);\n+%}\n+\n@@ -16962,1 +16750,1 @@\n-instruct compressBitsI_memcon(iRegINoSp dst, memory4 mem, immI mask,\n+instruct compressBitsI_memcon(iRegINoSp dst, memory mem, immI mask,\n@@ -16999,1 +16787,1 @@\n-instruct compressBitsL_memcon(iRegLNoSp dst, memory8 mem, immL mask,\n+instruct compressBitsL_memcon(iRegLNoSp dst, memory mem, immL mask,\n@@ -17036,1 +16824,1 @@\n-instruct expandBitsI_memcon(iRegINoSp dst, memory4 mem, immI mask,\n+instruct expandBitsI_memcon(iRegINoSp dst, memory mem, immI mask,\n@@ -17074,1 +16862,1 @@\n-instruct expandBitsL_memcon(iRegINoSp dst, memory8 mem, immL mask,\n+instruct expandBitsL_memcon(iRegINoSp dst, memory mem, immL mask,\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":99,"deletions":311,"binary":false,"changes":410,"status":"modified"},{"patch":"@@ -686,1 +686,1 @@\n-    assert(c->as_jobject() == 0, \"should be\");\n+    assert(c->as_jobject() == nullptr, \"should be\");\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -86,1 +86,1 @@\n-    lightweight_lock(obj, hdr, temp, rscratch2, slow_case);\n+    lightweight_lock(disp_hdr, obj, hdr, temp, rscratch2, slow_case);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -1156,1 +1156,1 @@\n-const char *Runtime1::pd_name_for_address(address entry) { Unimplemented(); return 0; }\n+const char *Runtime1::pd_name_for_address(address entry) { Unimplemented(); }\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_Runtime1_aarch64.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -255,1 +255,1 @@\n-void C2_MacroAssembler::fast_lock_lightweight(Register obj, Register t1,\n+void C2_MacroAssembler::fast_lock_lightweight(Register obj, Register box, Register t1,\n@@ -258,1 +258,1 @@\n-  assert_different_registers(obj, t1, t2, t3);\n+  assert_different_registers(obj, box, t1, t2, t3);\n@@ -267,0 +267,5 @@\n+  if (UseObjectMonitorTable) {\n+    \/\/ Clear cache in case fast locking succeeds.\n+    str(zr, Address(box, BasicLock::object_monitor_cache_offset_in_bytes()));\n+  }\n+\n@@ -275,0 +280,1 @@\n+  const Register t3_t = t3;\n@@ -282,1 +288,0 @@\n-    const Register t3_t = t3;\n@@ -320,3 +325,38 @@\n-    \/\/ mark contains the tagged ObjectMonitor*.\n-    const Register t1_tagged_monitor = t1_mark;\n-    const uintptr_t monitor_tag = markWord::monitor_value;\n+    const Register t1_monitor = t1;\n+\n+    if (!UseObjectMonitorTable) {\n+      assert(t1_monitor == t1_mark, \"should be the same here\");\n+    } else {\n+      Label monitor_found;\n+\n+      \/\/ Load cache address\n+      lea(t3_t, Address(rthread, JavaThread::om_cache_oops_offset()));\n+\n+      const int num_unrolled = 2;\n+      for (int i = 0; i < num_unrolled; i++) {\n+        ldr(t1, Address(t3_t));\n+        cmp(obj, t1);\n+        br(Assembler::EQ, monitor_found);\n+        increment(t3_t, in_bytes(OMCache::oop_to_oop_difference()));\n+      }\n+\n+      Label loop;\n+\n+      \/\/ Search for obj in cache.\n+      bind(loop);\n+\n+      \/\/ Check for match.\n+      ldr(t1, Address(t3_t));\n+      cmp(obj, t1);\n+      br(Assembler::EQ, monitor_found);\n+\n+      \/\/ Search until null encountered, guaranteed _null_sentinel at end.\n+      increment(t3_t, in_bytes(OMCache::oop_to_oop_difference()));\n+      cbnz(t1, loop);\n+      \/\/ Cache Miss, NE set from cmp above, cbnz does not set flags\n+      b(slow_path);\n+\n+      bind(monitor_found);\n+      ldr(t1_monitor, Address(t3_t, OMCache::oop_to_monitor_difference()));\n+    }\n+\n@@ -325,0 +365,5 @@\n+    const ByteSize monitor_tag = in_ByteSize(UseObjectMonitorTable ? 0 : checked_cast<int>(markWord::monitor_value));\n+    const Address owner_address(t1_monitor, ObjectMonitor::owner_offset() - monitor_tag);\n+    const Address recursions_address(t1_monitor, ObjectMonitor::recursions_offset() - monitor_tag);\n+\n+    Label monitor_locked;\n@@ -327,1 +372,1 @@\n-    lea(t2_owner_addr, Address(t1_tagged_monitor, (in_bytes(ObjectMonitor::owner_offset()) - monitor_tag)));\n+    lea(t2_owner_addr, owner_address);\n@@ -332,1 +377,1 @@\n-    br(Assembler::EQ, locked);\n+    br(Assembler::EQ, monitor_locked);\n@@ -339,1 +384,6 @@\n-    increment(Address(t1_tagged_monitor, in_bytes(ObjectMonitor::recursions_offset()) - monitor_tag), 1);\n+    increment(recursions_address, 1);\n+\n+    bind(monitor_locked);\n+    if (UseObjectMonitorTable) {\n+      str(t1_monitor, Address(box, BasicLock::object_monitor_cache_offset_in_bytes()));\n+    }\n@@ -362,2 +412,2 @@\n-void C2_MacroAssembler::fast_unlock_lightweight(Register obj, Register t1, Register t2,\n-                                                Register t3) {\n+void C2_MacroAssembler::fast_unlock_lightweight(Register obj, Register box, Register t1,\n+                                                Register t2, Register t3) {\n@@ -365,1 +415,1 @@\n-  assert_different_registers(obj, t1, t2, t3);\n+  assert_different_registers(obj, box, t1, t2, t3);\n@@ -368,1 +418,1 @@\n-  Label inflated, inflated_load_monitor;\n+  Label inflated, inflated_load_mark;\n@@ -380,0 +430,2 @@\n+    Label push_and_slow_path;\n+\n@@ -386,1 +438,1 @@\n-    br(Assembler::NE, inflated_load_monitor);\n+    br(Assembler::NE, inflated_load_mark);\n@@ -403,1 +455,4 @@\n-    tbnz(t1_mark, exact_log2(markWord::monitor_value), inflated);\n+    \/\/ Because we got here by popping (meaning we pushed in locked)\n+    \/\/ there will be no monitor in the box. So we need to push back the obj\n+    \/\/ so that the runtime can fix any potential anonymous owner.\n+    tbnz(t1_mark, exact_log2(markWord::monitor_value), UseObjectMonitorTable ? push_and_slow_path : inflated);\n@@ -412,0 +467,1 @@\n+    bind(push_and_slow_path);\n@@ -422,1 +478,1 @@\n-    bind(inflated_load_monitor);\n+    bind(inflated_load_mark);\n@@ -443,3 +499,1 @@\n-    \/\/ mark contains the tagged ObjectMonitor*.\n-    const Register t1_monitor = t1_mark;\n-    const uintptr_t monitor_tag = markWord::monitor_value;\n+    const Register t1_monitor = t1;\n@@ -447,2 +501,11 @@\n-    \/\/ Untag the monitor.\n-    sub(t1_monitor, t1_mark, monitor_tag);\n+    if (!UseObjectMonitorTable) {\n+      assert(t1_monitor == t1_mark, \"should be the same here\");\n+\n+      \/\/ Untag the monitor.\n+      add(t1_monitor, t1_mark, -(int)markWord::monitor_value);\n+    } else {\n+      ldr(t1_monitor, Address(box, BasicLock::object_monitor_cache_offset_in_bytes()));\n+      \/\/ null check with Flags == NE, no valid pointer below alignof(ObjectMonitor*)\n+      cmp(t1_monitor, checked_cast<uint8_t>(alignof(ObjectMonitor*)));\n+      br(Assembler::LO, slow_path);\n+    }\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":84,"deletions":21,"binary":false,"changes":105,"status":"modified"},{"patch":"@@ -44,2 +44,2 @@\n-  void fast_lock_lightweight(Register object, Register t1, Register t2, Register t3);\n-  void fast_unlock_lightweight(Register object, Register t1, Register t2, Register t3);\n+  void fast_lock_lightweight(Register object, Register box, Register t1, Register t2, Register t3);\n+  void fast_unlock_lightweight(Register object, Register box, Register t1, Register t2, Register t3);\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -299,1 +299,1 @@\n-  assert(_pc == pc_old || pc == pc_old || pc_old == 0, \"\");\n+  assert(_pc == pc_old || pc == pc_old || pc_old == nullptr, \"\");\n@@ -503,1 +503,1 @@\n-  if (fp() == 0 || (intptr_t(fp()) & (wordSize-1)) != 0) {\n+  if (fp() == nullptr || (intptr_t(fp()) & (wordSize-1)) != 0) {\n@@ -506,1 +506,1 @@\n-  if (sp() == 0 || (intptr_t(sp()) & (wordSize-1)) != 0) {\n+  if (sp() == nullptr || (intptr_t(sp()) & (wordSize-1)) != 0) {\n","filename":"src\/hotspot\/cpu\/aarch64\/frame_aarch64.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -406,1 +406,1 @@\n-  __ ldrw(rscratch2, Address(rscratch1, ClassLoaderData::keep_alive_offset()));\n+  __ ldrw(rscratch2, Address(rscratch1, ClassLoaderData::keep_alive_ref_count_offset()));\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -799,1 +799,1 @@\n-      lightweight_lock(obj_reg, tmp, tmp2, tmp3, slow_case);\n+      lightweight_lock(lock_reg, obj_reg, tmp, tmp2, tmp3, slow_case);\n@@ -859,9 +859,3 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n-      call_VM(noreg,\n-              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter_obj),\n-              obj_reg);\n-    } else {\n-      call_VM(noreg,\n-              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n-              lock_reg);\n-    }\n+    call_VM(noreg,\n+            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n+            lock_reg);\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":4,"deletions":10,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2004, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2004, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -205,1 +205,1 @@\n-    __ lea(rscratch1, ExternalAddress(slow_case_addr));\n+    __ lea(rscratch1, RuntimeAddress(slow_case_addr));\n","filename":"src\/hotspot\/cpu\/aarch64\/jniFastGetField_aarch64.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -222,1 +222,1 @@\n-          assert(target == 0, \"did not expect to relocate target for polling page load\");\n+          assert(target == nullptr, \"did not expect to relocate target for polling page load\");\n@@ -743,1 +743,1 @@\n-    lea(rscratch1, CAST_FROM_FN_PTR(address, SharedRuntime::enable_stack_reserved_zone));\n+    lea(rscratch1, RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::enable_stack_reserved_zone)));\n@@ -751,1 +751,1 @@\n-    lea(rscratch1, RuntimeAddress(StubRoutines::throw_delayed_StackOverflowError_entry()));\n+    lea(rscratch1, RuntimeAddress(SharedRuntime::throw_delayed_StackOverflowError_entry()));\n@@ -1772,2 +1772,2 @@\n-  cmn(r_bitmap, (u1)1);\n-  br(EQ, L_huge);\n+  cmpw(r_array_length, (u1)(Klass::SECONDARY_SUPERS_TABLE_SIZE - 2));\n+  br(GT, L_huge);\n@@ -1925,1 +1925,1 @@\n-  lea(rscratch2, ExternalAddress(StubRoutines::verify_oop_subroutine_entry_address()));\n+  lea(rscratch2, RuntimeAddress(StubRoutines::verify_oop_subroutine_entry_address()));\n@@ -1968,1 +1968,1 @@\n-  lea(rscratch2, ExternalAddress(StubRoutines::verify_oop_subroutine_entry_address()));\n+  lea(rscratch2, RuntimeAddress(StubRoutines::verify_oop_subroutine_entry_address()));\n@@ -7270,1 +7270,1 @@\n-    lea(rscratch1, CAST_FROM_FN_PTR(address, JavaThread::verify_cross_modify_fence_failure));\n+    lea(rscratch1, RuntimeAddress(CAST_FROM_FN_PTR(address, JavaThread::verify_cross_modify_fence_failure)));\n@@ -7566,1 +7566,1 @@\n-void MacroAssembler::lightweight_lock(Register obj, Register t1, Register t2, Register t3, Label& slow) {\n+void MacroAssembler::lightweight_lock(Register basic_lock, Register obj, Register t1, Register t2, Register t3, Label& slow) {\n@@ -7568,1 +7568,1 @@\n-  assert_different_registers(obj, t1, t2, t3, rscratch1);\n+  assert_different_registers(basic_lock, obj, t1, t2, t3, rscratch1);\n@@ -7579,0 +7579,5 @@\n+  if (UseObjectMonitorTable) {\n+    \/\/ Clear cache in case fast locking succeeds.\n+    str(zr, Address(basic_lock, BasicObjectLock::lock_offset() + in_ByteSize((BasicLock::object_monitor_cache_offset_in_bytes()))));\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":15,"deletions":10,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -1722,1 +1722,1 @@\n-  void lightweight_lock(Register obj, Register t1, Register t2, Register t3, Label& slow);\n+  void lightweight_lock(Register basic_lock, Register obj, Register t1, Register t2, Register t3, Label& slow);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -127,1 +127,1 @@\n-  __ far_jump(RuntimeAddress(StubRoutines::throw_AbstractMethodError_entry()));\n+  __ far_jump(RuntimeAddress(SharedRuntime::throw_AbstractMethodError_entry()));\n@@ -458,1 +458,1 @@\n-      __ far_jump(RuntimeAddress(StubRoutines::throw_IncompatibleClassChangeError_entry()));\n+      __ far_jump(RuntimeAddress(SharedRuntime::throw_IncompatibleClassChangeError_entry()));\n","filename":"src\/hotspot\/cpu\/aarch64\/methodHandles_aarch64.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -70,5 +70,5 @@\n-const int StackAlignmentInSlots = StackAlignmentInBytes \/ VMRegImpl::stack_slot_size;\n-\n-class SimpleRuntimeFrame {\n-\n-  public:\n+#ifdef PRODUCT\n+#define BLOCK_COMMENT(str) \/* nothing *\/\n+#else\n+#define BLOCK_COMMENT(str) __ block_comment(str)\n+#endif\n@@ -76,15 +76,1 @@\n-  \/\/ Most of the runtime stubs have this simple frame layout.\n-  \/\/ This class exists to make the layout shared in one place.\n-  \/\/ Offsets are for compiler stack slots, which are jints.\n-  enum layout {\n-    \/\/ The frame sender code expects that rbp will be in the \"natural\" place and\n-    \/\/ will override any oopMap setting for it. We must therefore force the layout\n-    \/\/ so that it agrees with the frame sender code.\n-    \/\/ we don't expect any arg reg save area so aarch64 asserts that\n-    \/\/ frame::arg_reg_save_area_bytes == 0\n-    rfp_off = 0,\n-    rfp_off2,\n-    return_off, return_off2,\n-    framesize\n-  };\n-};\n+const int StackAlignmentInSlots = StackAlignmentInBytes \/ VMRegImpl::stack_slot_size;\n@@ -2113,1 +2099,1 @@\n-      __ lightweight_lock(obj_reg, swap_reg, tmp, lock_tmp, slow_path_lock);\n+      __ lightweight_lock(lock_reg, obj_reg, swap_reg, tmp, lock_tmp, slow_path_lock);\n@@ -2185,10 +2171,2 @@\n-    \/\/ We need an acquire here to ensure that any subsequent load of the\n-    \/\/ global SafepointSynchronize::_state flag is ordered after this load\n-    \/\/ of the thread-local polling word.  We don't want this poll to\n-    \/\/ return false (i.e. not safepointing) and a later poll of the global\n-    \/\/ SafepointSynchronize::_state spuriously to return true.\n-    \/\/\n-    \/\/ This is to avoid a race when we're in a native->Java transition\n-    \/\/ racing the code which wakes up from a safepoint.\n-\n-    __ safepoint_poll(safepoint_in_progress, true \/* at_return *\/, true \/* acquire *\/, false \/* in_nmethod *\/);\n+    \/\/ No need for acquire as Java threads always disarm themselves.\n+    __ safepoint_poll(safepoint_in_progress, true \/* at_return *\/, false \/* acquire *\/, false \/* in_nmethod *\/);\n@@ -2863,191 +2841,0 @@\n-#ifdef COMPILER2\n-\/\/------------------------------generate_uncommon_trap_blob--------------------\n-void SharedRuntime::generate_uncommon_trap_blob() {\n-  \/\/ Allocate space for the code\n-  ResourceMark rm;\n-  \/\/ Setup code generation tools\n-  CodeBuffer buffer(\"uncommon_trap_blob\", 2048, 1024);\n-  MacroAssembler* masm = new MacroAssembler(&buffer);\n-\n-  assert(SimpleRuntimeFrame::framesize % 4 == 0, \"sp not 16-byte aligned\");\n-\n-  address start = __ pc();\n-\n-  \/\/ Push self-frame.  We get here with a return address in LR\n-  \/\/ and sp should be 16 byte aligned\n-  \/\/ push rfp and retaddr by hand\n-  __ protect_return_address();\n-  __ stp(rfp, lr, Address(__ pre(sp, -2 * wordSize)));\n-  \/\/ we don't expect an arg reg save area\n-#ifndef PRODUCT\n-  assert(frame::arg_reg_save_area_bytes == 0, \"not expecting frame reg save area\");\n-#endif\n-  \/\/ compiler left unloaded_class_index in j_rarg0 move to where the\n-  \/\/ runtime expects it.\n-  if (c_rarg1 != j_rarg0) {\n-    __ movw(c_rarg1, j_rarg0);\n-  }\n-\n-  \/\/ we need to set the past SP to the stack pointer of the stub frame\n-  \/\/ and the pc to the address where this runtime call will return\n-  \/\/ although actually any pc in this code blob will do).\n-  Label retaddr;\n-  __ set_last_Java_frame(sp, noreg, retaddr, rscratch1);\n-\n-  \/\/ Call C code.  Need thread but NOT official VM entry\n-  \/\/ crud.  We cannot block on this call, no GC can happen.  Call should\n-  \/\/ capture callee-saved registers as well as return values.\n-  \/\/ Thread is in rdi already.\n-  \/\/\n-  \/\/ UnrollBlock* uncommon_trap(JavaThread* thread, jint unloaded_class_index);\n-  \/\/\n-  \/\/ n.b. 2 gp args, 0 fp args, integral return type\n-\n-  __ mov(c_rarg0, rthread);\n-  __ movw(c_rarg2, (unsigned)Deoptimization::Unpack_uncommon_trap);\n-  __ lea(rscratch1,\n-         RuntimeAddress(CAST_FROM_FN_PTR(address,\n-                                         Deoptimization::uncommon_trap)));\n-  __ blr(rscratch1);\n-  __ bind(retaddr);\n-\n-  \/\/ Set an oopmap for the call site\n-  OopMapSet* oop_maps = new OopMapSet();\n-  OopMap* map = new OopMap(SimpleRuntimeFrame::framesize, 0);\n-\n-  \/\/ location of rfp is known implicitly by the frame sender code\n-\n-  oop_maps->add_gc_map(__ pc() - start, map);\n-\n-  __ reset_last_Java_frame(false);\n-\n-  \/\/ move UnrollBlock* into r4\n-  __ mov(r4, r0);\n-\n-#ifdef ASSERT\n-  { Label L;\n-    __ ldrw(rscratch1, Address(r4, Deoptimization::UnrollBlock::unpack_kind_offset()));\n-    __ cmpw(rscratch1, (unsigned)Deoptimization::Unpack_uncommon_trap);\n-    __ br(Assembler::EQ, L);\n-    __ stop(\"SharedRuntime::generate_uncommon_trap_blob: expected Unpack_uncommon_trap\");\n-    __ bind(L);\n-  }\n-#endif\n-\n-  \/\/ Pop all the frames we must move\/replace.\n-  \/\/\n-  \/\/ Frame picture (youngest to oldest)\n-  \/\/ 1: self-frame (no frame link)\n-  \/\/ 2: deopting frame  (no frame link)\n-  \/\/ 3: caller of deopting frame (could be compiled\/interpreted).\n-\n-  \/\/ Pop self-frame.  We have no frame, and must rely only on r0 and sp.\n-  __ add(sp, sp, (SimpleRuntimeFrame::framesize) << LogBytesPerInt); \/\/ Epilog!\n-\n-  \/\/ Pop deoptimized frame (int)\n-  __ ldrw(r2, Address(r4,\n-                      Deoptimization::UnrollBlock::\n-                      size_of_deoptimized_frame_offset()));\n-  __ sub(r2, r2, 2 * wordSize);\n-  __ add(sp, sp, r2);\n-  __ ldp(rfp, zr, __ post(sp, 2 * wordSize));\n-\n-#ifdef ASSERT\n-  \/\/ Compilers generate code that bang the stack by as much as the\n-  \/\/ interpreter would need. So this stack banging should never\n-  \/\/ trigger a fault. Verify that it does not on non product builds.\n-  __ ldrw(r1, Address(r4,\n-                      Deoptimization::UnrollBlock::\n-                      total_frame_sizes_offset()));\n-  __ bang_stack_size(r1, r2);\n-#endif\n-\n-  \/\/ Load address of array of frame pcs into r2 (address*)\n-  __ ldr(r2, Address(r4,\n-                     Deoptimization::UnrollBlock::frame_pcs_offset()));\n-\n-  \/\/ Load address of array of frame sizes into r5 (intptr_t*)\n-  __ ldr(r5, Address(r4,\n-                     Deoptimization::UnrollBlock::\n-                     frame_sizes_offset()));\n-\n-  \/\/ Counter\n-  __ ldrw(r3, Address(r4,\n-                      Deoptimization::UnrollBlock::\n-                      number_of_frames_offset())); \/\/ (int)\n-\n-  \/\/ Now adjust the caller's stack to make up for the extra locals but\n-  \/\/ record the original sp so that we can save it in the skeletal\n-  \/\/ interpreter frame and the stack walking of interpreter_sender\n-  \/\/ will get the unextended sp value and not the \"real\" sp value.\n-\n-  const Register sender_sp = r8;\n-\n-  __ mov(sender_sp, sp);\n-  __ ldrw(r1, Address(r4,\n-                      Deoptimization::UnrollBlock::\n-                      caller_adjustment_offset())); \/\/ (int)\n-  __ sub(sp, sp, r1);\n-\n-  \/\/ Push interpreter frames in a loop\n-  Label loop;\n-  __ bind(loop);\n-  __ ldr(r1, Address(r5, 0));       \/\/ Load frame size\n-  __ sub(r1, r1, 2 * wordSize);     \/\/ We'll push pc and rfp by hand\n-  __ ldr(lr, Address(r2, 0));       \/\/ Save return address\n-  __ enter();                       \/\/ and old rfp & set new rfp\n-  __ sub(sp, sp, r1);               \/\/ Prolog\n-  __ str(sender_sp, Address(rfp, frame::interpreter_frame_sender_sp_offset * wordSize)); \/\/ Make it walkable\n-  \/\/ This value is corrected by layout_activation_impl\n-  __ str(zr, Address(rfp, frame::interpreter_frame_last_sp_offset * wordSize));\n-  __ mov(sender_sp, sp);          \/\/ Pass sender_sp to next frame\n-  __ add(r5, r5, wordSize);       \/\/ Bump array pointer (sizes)\n-  __ add(r2, r2, wordSize);       \/\/ Bump array pointer (pcs)\n-  __ subsw(r3, r3, 1);            \/\/ Decrement counter\n-  __ br(Assembler::GT, loop);\n-  __ ldr(lr, Address(r2, 0));     \/\/ save final return address\n-  \/\/ Re-push self-frame\n-  __ enter();                     \/\/ & old rfp & set new rfp\n-\n-  \/\/ Use rfp because the frames look interpreted now\n-  \/\/ Save \"the_pc\" since it cannot easily be retrieved using the last_java_SP after we aligned SP.\n-  \/\/ Don't need the precise return PC here, just precise enough to point into this code blob.\n-  address the_pc = __ pc();\n-  __ set_last_Java_frame(sp, rfp, the_pc, rscratch1);\n-\n-  \/\/ Call C code.  Need thread but NOT official VM entry\n-  \/\/ crud.  We cannot block on this call, no GC can happen.  Call should\n-  \/\/ restore return values to their stack-slots with the new SP.\n-  \/\/ Thread is in rdi already.\n-  \/\/\n-  \/\/ BasicType unpack_frames(JavaThread* thread, int exec_mode);\n-  \/\/\n-  \/\/ n.b. 2 gp args, 0 fp args, integral return type\n-\n-  \/\/ sp should already be aligned\n-  __ mov(c_rarg0, rthread);\n-  __ movw(c_rarg1, (unsigned)Deoptimization::Unpack_uncommon_trap);\n-  __ lea(rscratch1, RuntimeAddress(CAST_FROM_FN_PTR(address, Deoptimization::unpack_frames)));\n-  __ blr(rscratch1);\n-\n-  \/\/ Set an oopmap for the call site\n-  \/\/ Use the same PC we used for the last java frame\n-  oop_maps->add_gc_map(the_pc - start, new OopMap(SimpleRuntimeFrame::framesize, 0));\n-\n-  \/\/ Clear fp AND pc\n-  __ reset_last_Java_frame(true);\n-\n-  \/\/ Pop self-frame.\n-  __ leave();                 \/\/ Epilog\n-\n-  \/\/ Jump to interpreter\n-  __ ret(lr);\n-\n-  \/\/ Make sure all code is generated\n-  masm->flush();\n-\n-  _uncommon_trap_blob =  UncommonTrapBlob::create(&buffer, oop_maps,\n-                                                 SimpleRuntimeFrame::framesize >> 1);\n-}\n-#endif \/\/ COMPILER2\n-\n@@ -3266,138 +3053,0 @@\n-#ifdef COMPILER2\n-\/\/ This is here instead of runtime_aarch64_64.cpp because it uses SimpleRuntimeFrame\n-\/\/\n-\/\/------------------------------generate_exception_blob---------------------------\n-\/\/ creates exception blob at the end\n-\/\/ Using exception blob, this code is jumped from a compiled method.\n-\/\/ (see emit_exception_handler in x86_64.ad file)\n-\/\/\n-\/\/ Given an exception pc at a call we call into the runtime for the\n-\/\/ handler in this method. This handler might merely restore state\n-\/\/ (i.e. callee save registers) unwind the frame and jump to the\n-\/\/ exception handler for the nmethod if there is no Java level handler\n-\/\/ for the nmethod.\n-\/\/\n-\/\/ This code is entered with a jmp.\n-\/\/\n-\/\/ Arguments:\n-\/\/   r0: exception oop\n-\/\/   r3: exception pc\n-\/\/\n-\/\/ Results:\n-\/\/   r0: exception oop\n-\/\/   r3: exception pc in caller or ???\n-\/\/   destination: exception handler of caller\n-\/\/\n-\/\/ Note: the exception pc MUST be at a call (precise debug information)\n-\/\/       Registers r0, r3, r2, r4, r5, r8-r11 are not callee saved.\n-\/\/\n-\n-void OptoRuntime::generate_exception_blob() {\n-  assert(!OptoRuntime::is_callee_saved_register(R3_num), \"\");\n-  assert(!OptoRuntime::is_callee_saved_register(R0_num), \"\");\n-  assert(!OptoRuntime::is_callee_saved_register(R2_num), \"\");\n-\n-  assert(SimpleRuntimeFrame::framesize % 4 == 0, \"sp not 16-byte aligned\");\n-\n-  \/\/ Allocate space for the code\n-  ResourceMark rm;\n-  \/\/ Setup code generation tools\n-  CodeBuffer buffer(\"exception_blob\", 2048, 1024);\n-  MacroAssembler* masm = new MacroAssembler(&buffer);\n-\n-  \/\/ TODO check various assumptions made here\n-  \/\/\n-  \/\/ make sure we do so before running this\n-\n-  address start = __ pc();\n-\n-  \/\/ push rfp and retaddr by hand\n-  \/\/ Exception pc is 'return address' for stack walker\n-  __ protect_return_address();\n-  __ stp(rfp, lr, Address(__ pre(sp, -2 * wordSize)));\n-  \/\/ there are no callee save registers and we don't expect an\n-  \/\/ arg reg save area\n-#ifndef PRODUCT\n-  assert(frame::arg_reg_save_area_bytes == 0, \"not expecting frame reg save area\");\n-#endif\n-  \/\/ Store exception in Thread object. We cannot pass any arguments to the\n-  \/\/ handle_exception call, since we do not want to make any assumption\n-  \/\/ about the size of the frame where the exception happened in.\n-  __ str(r0, Address(rthread, JavaThread::exception_oop_offset()));\n-  __ str(r3, Address(rthread, JavaThread::exception_pc_offset()));\n-\n-  \/\/ This call does all the hard work.  It checks if an exception handler\n-  \/\/ exists in the method.\n-  \/\/ If so, it returns the handler address.\n-  \/\/ If not, it prepares for stack-unwinding, restoring the callee-save\n-  \/\/ registers of the frame being removed.\n-  \/\/\n-  \/\/ address OptoRuntime::handle_exception_C(JavaThread* thread)\n-  \/\/\n-  \/\/ n.b. 1 gp arg, 0 fp args, integral return type\n-\n-  \/\/ the stack should always be aligned\n-  address the_pc = __ pc();\n-  __ set_last_Java_frame(sp, noreg, the_pc, rscratch1);\n-  __ mov(c_rarg0, rthread);\n-  __ lea(rscratch1, RuntimeAddress(CAST_FROM_FN_PTR(address, OptoRuntime::handle_exception_C)));\n-  __ blr(rscratch1);\n-  \/\/ handle_exception_C is a special VM call which does not require an explicit\n-  \/\/ instruction sync afterwards.\n-\n-  \/\/ May jump to SVE compiled code\n-  __ reinitialize_ptrue();\n-\n-  \/\/ Set an oopmap for the call site.  This oopmap will only be used if we\n-  \/\/ are unwinding the stack.  Hence, all locations will be dead.\n-  \/\/ Callee-saved registers will be the same as the frame above (i.e.,\n-  \/\/ handle_exception_stub), since they were restored when we got the\n-  \/\/ exception.\n-\n-  OopMapSet* oop_maps = new OopMapSet();\n-\n-  oop_maps->add_gc_map(the_pc - start, new OopMap(SimpleRuntimeFrame::framesize, 0));\n-\n-  __ reset_last_Java_frame(false);\n-\n-  \/\/ Restore callee-saved registers\n-\n-  \/\/ rfp is an implicitly saved callee saved register (i.e. the calling\n-  \/\/ convention will save restore it in prolog\/epilog) Other than that\n-  \/\/ there are no callee save registers now that adapter frames are gone.\n-  \/\/ and we dont' expect an arg reg save area\n-  __ ldp(rfp, r3, Address(__ post(sp, 2 * wordSize)));\n-  __ authenticate_return_address(r3);\n-\n-  \/\/ r0: exception handler\n-\n-  \/\/ We have a handler in r0 (could be deopt blob).\n-  __ mov(r8, r0);\n-\n-  \/\/ Get the exception oop\n-  __ ldr(r0, Address(rthread, JavaThread::exception_oop_offset()));\n-  \/\/ Get the exception pc in case we are deoptimized\n-  __ ldr(r4, Address(rthread, JavaThread::exception_pc_offset()));\n-#ifdef ASSERT\n-  __ str(zr, Address(rthread, JavaThread::exception_handler_pc_offset()));\n-  __ str(zr, Address(rthread, JavaThread::exception_pc_offset()));\n-#endif\n-  \/\/ Clear the exception oop so GC no longer processes it as a root.\n-  __ str(zr, Address(rthread, JavaThread::exception_oop_offset()));\n-\n-  \/\/ r0: exception oop\n-  \/\/ r8:  exception handler\n-  \/\/ r4: exception pc\n-  \/\/ Jump to handler\n-\n-  __ br(r8);\n-\n-  \/\/ Make sure all code is generated\n-  masm->flush();\n-\n-  \/\/ Set exception blob\n-  _exception_blob =  ExceptionBlob::create(&buffer, oop_maps, SimpleRuntimeFrame::framesize >> 1);\n-}\n-\n-#endif \/\/ COMPILER2\n-\n@@ -3516,0 +3165,190 @@\n+\n+\/\/ Continuation point for throwing of implicit exceptions that are\n+\/\/ not handled in the current activation. Fabricates an exception\n+\/\/ oop and initiates normal exception dispatching in this\n+\/\/ frame. Since we need to preserve callee-saved values (currently\n+\/\/ only for C2, but done for C1 as well) we need a callee-saved oop\n+\/\/ map and therefore have to make these stubs into RuntimeStubs\n+\/\/ rather than BufferBlobs.  If the compiler needs all registers to\n+\/\/ be preserved between the fault point and the exception handler\n+\/\/ then it must assume responsibility for that in\n+\/\/ AbstractCompiler::continuation_for_implicit_null_exception or\n+\/\/ continuation_for_implicit_division_by_zero_exception. All other\n+\/\/ implicit exceptions (e.g., NullPointerException or\n+\/\/ AbstractMethodError on entry) are either at call sites or\n+\/\/ otherwise assume that stack unwinding will be initiated, so\n+\/\/ caller saved registers were assumed volatile in the compiler.\n+\n+RuntimeStub* SharedRuntime::generate_throw_exception(const char* name, address runtime_entry) {\n+  \/\/ Information about frame layout at time of blocking runtime call.\n+  \/\/ Note that we only have to preserve callee-saved registers since\n+  \/\/ the compilers are responsible for supplying a continuation point\n+  \/\/ if they expect all registers to be preserved.\n+  \/\/ n.b. aarch64 asserts that frame::arg_reg_save_area_bytes == 0\n+  enum layout {\n+    rfp_off = 0,\n+    rfp_off2,\n+    return_off,\n+    return_off2,\n+    framesize \/\/ inclusive of return address\n+  };\n+\n+  int insts_size = 512;\n+  int locs_size  = 64;\n+\n+  ResourceMark rm;\n+  const char* timer_msg = \"SharedRuntime generate_throw_exception\";\n+  TraceTime timer(timer_msg, TRACETIME_LOG(Info, startuptime));\n+\n+  CodeBuffer code(name, insts_size, locs_size);\n+  OopMapSet* oop_maps  = new OopMapSet();\n+  MacroAssembler* masm = new MacroAssembler(&code);\n+\n+  address start = __ pc();\n+\n+  \/\/ This is an inlined and slightly modified version of call_VM\n+  \/\/ which has the ability to fetch the return PC out of\n+  \/\/ thread-local storage and also sets up last_Java_sp slightly\n+  \/\/ differently than the real call_VM\n+\n+  __ enter(); \/\/ Save FP and LR before call\n+\n+  assert(is_even(framesize\/2), \"sp not 16-byte aligned\");\n+\n+  \/\/ lr and fp are already in place\n+  __ sub(sp, rfp, ((uint64_t)framesize-4) << LogBytesPerInt); \/\/ prolog\n+\n+  int frame_complete = __ pc() - start;\n+\n+  \/\/ Set up last_Java_sp and last_Java_fp\n+  address the_pc = __ pc();\n+  __ set_last_Java_frame(sp, rfp, the_pc, rscratch1);\n+\n+  __ mov(c_rarg0, rthread);\n+  BLOCK_COMMENT(\"call runtime_entry\");\n+  __ mov(rscratch1, runtime_entry);\n+  __ blr(rscratch1);\n+\n+  \/\/ Generate oop map\n+  OopMap* map = new OopMap(framesize, 0);\n+\n+  oop_maps->add_gc_map(the_pc - start, map);\n+\n+  __ reset_last_Java_frame(true);\n+\n+  \/\/ Reinitialize the ptrue predicate register, in case the external runtime\n+  \/\/ call clobbers ptrue reg, as we may return to SVE compiled code.\n+  __ reinitialize_ptrue();\n+\n+  __ leave();\n+\n+  \/\/ check for pending exceptions\n+#ifdef ASSERT\n+  Label L;\n+  __ ldr(rscratch1, Address(rthread, Thread::pending_exception_offset()));\n+  __ cbnz(rscratch1, L);\n+  __ should_not_reach_here();\n+  __ bind(L);\n+#endif \/\/ ASSERT\n+  __ far_jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+\n+  \/\/ codeBlob framesize is in words (not VMRegImpl::slot_size)\n+  RuntimeStub* stub =\n+    RuntimeStub::new_runtime_stub(name,\n+                                  &code,\n+                                  frame_complete,\n+                                  (framesize >> (LogBytesPerWord - LogBytesPerInt)),\n+                                  oop_maps, false);\n+  return stub;\n+}\n+\n+#if INCLUDE_JFR\n+\n+static void jfr_prologue(address the_pc, MacroAssembler* masm, Register thread) {\n+  __ set_last_Java_frame(sp, rfp, the_pc, rscratch1);\n+  __ mov(c_rarg0, thread);\n+}\n+\n+\/\/ The handle is dereferenced through a load barrier.\n+static void jfr_epilogue(MacroAssembler* masm) {\n+  __ reset_last_Java_frame(true);\n+}\n+\n+\/\/ For c2: c_rarg0 is junk, call to runtime to write a checkpoint.\n+\/\/ It returns a jobject handle to the event writer.\n+\/\/ The handle is dereferenced and the return value is the event writer oop.\n+RuntimeStub* SharedRuntime::generate_jfr_write_checkpoint() {\n+  enum layout {\n+    rbp_off,\n+    rbpH_off,\n+    return_off,\n+    return_off2,\n+    framesize \/\/ inclusive of return address\n+  };\n+\n+  int insts_size = 1024;\n+  int locs_size = 64;\n+  CodeBuffer code(\"jfr_write_checkpoint\", insts_size, locs_size);\n+  OopMapSet* oop_maps = new OopMapSet();\n+  MacroAssembler* masm = new MacroAssembler(&code);\n+\n+  address start = __ pc();\n+  __ enter();\n+  int frame_complete = __ pc() - start;\n+  address the_pc = __ pc();\n+  jfr_prologue(the_pc, masm, rthread);\n+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, JfrIntrinsicSupport::write_checkpoint), 1);\n+  jfr_epilogue(masm);\n+  __ resolve_global_jobject(r0, rscratch1, rscratch2);\n+  __ leave();\n+  __ ret(lr);\n+\n+  OopMap* map = new OopMap(framesize, 1); \/\/ rfp\n+  oop_maps->add_gc_map(the_pc - start, map);\n+\n+  RuntimeStub* stub = \/\/ codeBlob framesize is in words (not VMRegImpl::slot_size)\n+    RuntimeStub::new_runtime_stub(\"jfr_write_checkpoint\", &code, frame_complete,\n+                                  (framesize >> (LogBytesPerWord - LogBytesPerInt)),\n+                                  oop_maps, false);\n+  return stub;\n+}\n+\n+\/\/ For c2: call to return a leased buffer.\n+RuntimeStub* SharedRuntime::generate_jfr_return_lease() {\n+  enum layout {\n+    rbp_off,\n+    rbpH_off,\n+    return_off,\n+    return_off2,\n+    framesize \/\/ inclusive of return address\n+  };\n+\n+  int insts_size = 1024;\n+  int locs_size = 64;\n+\n+  CodeBuffer code(\"jfr_return_lease\", insts_size, locs_size);\n+  OopMapSet* oop_maps = new OopMapSet();\n+  MacroAssembler* masm = new MacroAssembler(&code);\n+\n+  address start = __ pc();\n+  __ enter();\n+  int frame_complete = __ pc() - start;\n+  address the_pc = __ pc();\n+  jfr_prologue(the_pc, masm, rthread);\n+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, JfrIntrinsicSupport::return_lease), 1);\n+  jfr_epilogue(masm);\n+\n+  __ leave();\n+  __ ret(lr);\n+\n+  OopMap* map = new OopMap(framesize, 1); \/\/ rfp\n+  oop_maps->add_gc_map(the_pc - start, map);\n+\n+  RuntimeStub* stub = \/\/ codeBlob framesize is in words (not VMRegImpl::slot_size)\n+    RuntimeStub::new_runtime_stub(\"jfr_return_lease\", &code, frame_complete,\n+                                  (framesize >> (LogBytesPerWord - LogBytesPerInt)),\n+                                  oop_maps, false);\n+  return stub;\n+}\n+\n+#endif \/\/ INCLUDE_JFR\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":199,"deletions":360,"binary":false,"changes":559,"status":"modified"},{"patch":"@@ -7070,1 +7070,1 @@\n-    __ lea(rscratch1, ExternalAddress(StubRoutines::throw_StackOverflowError_entry()));\n+    __ lea(rscratch1, RuntimeAddress(SharedRuntime::throw_StackOverflowError_entry()));\n@@ -7330,92 +7330,0 @@\n-#if INCLUDE_JFR\n-\n-  static void jfr_prologue(address the_pc, MacroAssembler* _masm, Register thread) {\n-    __ set_last_Java_frame(sp, rfp, the_pc, rscratch1);\n-    __ mov(c_rarg0, thread);\n-  }\n-\n-  \/\/ The handle is dereferenced through a load barrier.\n-  static void jfr_epilogue(MacroAssembler* _masm) {\n-    __ reset_last_Java_frame(true);\n-  }\n-\n-  \/\/ For c2: c_rarg0 is junk, call to runtime to write a checkpoint.\n-  \/\/ It returns a jobject handle to the event writer.\n-  \/\/ The handle is dereferenced and the return value is the event writer oop.\n-  static RuntimeStub* generate_jfr_write_checkpoint() {\n-    enum layout {\n-      rbp_off,\n-      rbpH_off,\n-      return_off,\n-      return_off2,\n-      framesize \/\/ inclusive of return address\n-    };\n-\n-    int insts_size = 1024;\n-    int locs_size = 64;\n-    CodeBuffer code(\"jfr_write_checkpoint\", insts_size, locs_size);\n-    OopMapSet* oop_maps = new OopMapSet();\n-    MacroAssembler* masm = new MacroAssembler(&code);\n-    MacroAssembler* _masm = masm;\n-\n-    address start = __ pc();\n-    __ enter();\n-    int frame_complete = __ pc() - start;\n-    address the_pc = __ pc();\n-    jfr_prologue(the_pc, _masm, rthread);\n-    __ call_VM_leaf(CAST_FROM_FN_PTR(address, JfrIntrinsicSupport::write_checkpoint), 1);\n-    jfr_epilogue(_masm);\n-    __ resolve_global_jobject(r0, rscratch1, rscratch2);\n-    __ leave();\n-    __ ret(lr);\n-\n-    OopMap* map = new OopMap(framesize, 1); \/\/ rfp\n-    oop_maps->add_gc_map(the_pc - start, map);\n-\n-    RuntimeStub* stub = \/\/ codeBlob framesize is in words (not VMRegImpl::slot_size)\n-      RuntimeStub::new_runtime_stub(\"jfr_write_checkpoint\", &code, frame_complete,\n-                                    (framesize >> (LogBytesPerWord - LogBytesPerInt)),\n-                                    oop_maps, false);\n-    return stub;\n-  }\n-\n-  \/\/ For c2: call to return a leased buffer.\n-  static RuntimeStub* generate_jfr_return_lease() {\n-    enum layout {\n-      rbp_off,\n-      rbpH_off,\n-      return_off,\n-      return_off2,\n-      framesize \/\/ inclusive of return address\n-    };\n-\n-    int insts_size = 1024;\n-    int locs_size = 64;\n-    CodeBuffer code(\"jfr_return_lease\", insts_size, locs_size);\n-    OopMapSet* oop_maps = new OopMapSet();\n-    MacroAssembler* masm = new MacroAssembler(&code);\n-    MacroAssembler* _masm = masm;\n-\n-    address start = __ pc();\n-    __ enter();\n-    int frame_complete = __ pc() - start;\n-    address the_pc = __ pc();\n-    jfr_prologue(the_pc, _masm, rthread);\n-    __ call_VM_leaf(CAST_FROM_FN_PTR(address, JfrIntrinsicSupport::return_lease), 1);\n-    jfr_epilogue(_masm);\n-\n-    __ leave();\n-    __ ret(lr);\n-\n-    OopMap* map = new OopMap(framesize, 1); \/\/ rfp\n-    oop_maps->add_gc_map(the_pc - start, map);\n-\n-    RuntimeStub* stub = \/\/ codeBlob framesize is in words (not VMRegImpl::slot_size)\n-      RuntimeStub::new_runtime_stub(\"jfr_return_lease\", &code, frame_complete,\n-                                    (framesize >> (LogBytesPerWord - LogBytesPerInt)),\n-                                    oop_maps, false);\n-    return stub;\n-  }\n-\n-#endif \/\/ INCLUDE_JFR\n-\n@@ -7437,16 +7345,0 @@\n-  \/\/ Continuation point for throwing of implicit exceptions that are\n-  \/\/ not handled in the current activation. Fabricates an exception\n-  \/\/ oop and initiates normal exception dispatching in this\n-  \/\/ frame. Since we need to preserve callee-saved values (currently\n-  \/\/ only for C2, but done for C1 as well) we need a callee-saved oop\n-  \/\/ map and therefore have to make these stubs into RuntimeStubs\n-  \/\/ rather than BufferBlobs.  If the compiler needs all registers to\n-  \/\/ be preserved between the fault point and the exception handler\n-  \/\/ then it must assume responsibility for that in\n-  \/\/ AbstractCompiler::continuation_for_implicit_null_exception or\n-  \/\/ continuation_for_implicit_division_by_zero_exception. All other\n-  \/\/ implicit exceptions (e.g., NullPointerException or\n-  \/\/ AbstractMethodError on entry) are either at call sites or\n-  \/\/ otherwise assume that stack unwinding will be initiated, so\n-  \/\/ caller saved registers were assumed volatile in the compiler.\n-\n@@ -7456,90 +7348,0 @@\n-  address generate_throw_exception(const char* name,\n-                                   address runtime_entry,\n-                                   Register arg1 = noreg,\n-                                   Register arg2 = noreg) {\n-    \/\/ Information about frame layout at time of blocking runtime call.\n-    \/\/ Note that we only have to preserve callee-saved registers since\n-    \/\/ the compilers are responsible for supplying a continuation point\n-    \/\/ if they expect all registers to be preserved.\n-    \/\/ n.b. aarch64 asserts that frame::arg_reg_save_area_bytes == 0\n-    enum layout {\n-      rfp_off = 0,\n-      rfp_off2,\n-      return_off,\n-      return_off2,\n-      framesize \/\/ inclusive of return address\n-    };\n-\n-    int insts_size = 512;\n-    int locs_size  = 64;\n-\n-    CodeBuffer code(name, insts_size, locs_size);\n-    OopMapSet* oop_maps  = new OopMapSet();\n-    MacroAssembler* masm = new MacroAssembler(&code);\n-\n-    address start = __ pc();\n-\n-    \/\/ This is an inlined and slightly modified version of call_VM\n-    \/\/ which has the ability to fetch the return PC out of\n-    \/\/ thread-local storage and also sets up last_Java_sp slightly\n-    \/\/ differently than the real call_VM\n-\n-    __ enter(); \/\/ Save FP and LR before call\n-\n-    assert(is_even(framesize\/2), \"sp not 16-byte aligned\");\n-\n-    \/\/ lr and fp are already in place\n-    __ sub(sp, rfp, ((uint64_t)framesize-4) << LogBytesPerInt); \/\/ prolog\n-\n-    int frame_complete = __ pc() - start;\n-\n-    \/\/ Set up last_Java_sp and last_Java_fp\n-    address the_pc = __ pc();\n-    __ set_last_Java_frame(sp, rfp, the_pc, rscratch1);\n-\n-    \/\/ Call runtime\n-    if (arg1 != noreg) {\n-      assert(arg2 != c_rarg1, \"clobbered\");\n-      __ mov(c_rarg1, arg1);\n-    }\n-    if (arg2 != noreg) {\n-      __ mov(c_rarg2, arg2);\n-    }\n-    __ mov(c_rarg0, rthread);\n-    BLOCK_COMMENT(\"call runtime_entry\");\n-    __ mov(rscratch1, runtime_entry);\n-    __ blr(rscratch1);\n-\n-    \/\/ Generate oop map\n-    OopMap* map = new OopMap(framesize, 0);\n-\n-    oop_maps->add_gc_map(the_pc - start, map);\n-\n-    __ reset_last_Java_frame(true);\n-\n-    \/\/ Reinitialize the ptrue predicate register, in case the external runtime\n-    \/\/ call clobbers ptrue reg, as we may return to SVE compiled code.\n-    __ reinitialize_ptrue();\n-\n-    __ leave();\n-\n-    \/\/ check for pending exceptions\n-#ifdef ASSERT\n-    Label L;\n-    __ ldr(rscratch1, Address(rthread, Thread::pending_exception_offset()));\n-    __ cbnz(rscratch1, L);\n-    __ should_not_reach_here();\n-    __ bind(L);\n-#endif \/\/ ASSERT\n-    __ far_jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n-\n-    \/\/ codeBlob framesize is in words (not VMRegImpl::slot_size)\n-    RuntimeStub* stub =\n-      RuntimeStub::new_runtime_stub(name,\n-                                    &code,\n-                                    frame_complete,\n-                                    (framesize >> (LogBytesPerWord - LogBytesPerInt)),\n-                                    oop_maps, false);\n-    return stub->entry_point();\n-  }\n-\n@@ -8516,10 +8318,0 @@\n-    \/\/ Build this early so it's available for the interpreter.\n-    StubRoutines::_throw_StackOverflowError_entry =\n-      generate_throw_exception(\"StackOverflowError throw_exception\",\n-                               CAST_FROM_FN_PTR(address,\n-                                                SharedRuntime::throw_StackOverflowError));\n-    StubRoutines::_throw_delayed_StackOverflowError_entry =\n-      generate_throw_exception(\"delayed StackOverflowError throw_exception\",\n-                               CAST_FROM_FN_PTR(address,\n-                                                SharedRuntime::throw_delayed_StackOverflowError));\n-\n@@ -8569,11 +8361,0 @@\n-\n-    JFR_ONLY(generate_jfr_stubs();)\n-  }\n-\n-#if INCLUDE_JFR\n-  void generate_jfr_stubs() {\n-    StubRoutines::_jfr_write_checkpoint_stub = generate_jfr_write_checkpoint();\n-    StubRoutines::_jfr_write_checkpoint = StubRoutines::_jfr_write_checkpoint_stub->entry_point();\n-    StubRoutines::_jfr_return_lease_stub = generate_jfr_return_lease();\n-    StubRoutines::_jfr_return_lease = StubRoutines::_jfr_return_lease_stub->entry_point();\n-#endif \/\/ INCLUDE_JFR\n@@ -8587,17 +8368,0 @@\n-    StubRoutines::_throw_AbstractMethodError_entry =\n-      generate_throw_exception(\"AbstractMethodError throw_exception\",\n-                               CAST_FROM_FN_PTR(address,\n-                                                SharedRuntime::\n-                                                throw_AbstractMethodError));\n-\n-    StubRoutines::_throw_IncompatibleClassChangeError_entry =\n-      generate_throw_exception(\"IncompatibleClassChangeError throw_exception\",\n-                               CAST_FROM_FN_PTR(address,\n-                                                SharedRuntime::\n-                                                throw_IncompatibleClassChangeError));\n-\n-    StubRoutines::_throw_NullPointerException_at_call_entry =\n-      generate_throw_exception(\"NullPointerException at call throw_exception\",\n-                               CAST_FROM_FN_PTR(address,\n-                                                SharedRuntime::\n-                                                throw_NullPointerException_at_call));\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":1,"deletions":237,"binary":false,"changes":238,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -761,2 +761,2 @@\n-  assert(StubRoutines::throw_StackOverflowError_entry() != nullptr, \"stub not yet generated\");\n-  __ far_jump(RuntimeAddress(StubRoutines::throw_StackOverflowError_entry()));\n+  assert(SharedRuntime::throw_StackOverflowError_entry() != nullptr, \"stub not yet generated\");\n+  __ far_jump(RuntimeAddress(SharedRuntime::throw_StackOverflowError_entry()));\n@@ -1346,2 +1346,2 @@\n-    address unsatisfied = (SharedRuntime::native_method_throw_unsatisfied_link_error_entry());\n-    __ mov(rscratch2, unsatisfied);\n+    ExternalAddress unsatisfied(SharedRuntime::native_method_throw_unsatisfied_link_error_entry());\n+    __ lea(rscratch2, unsatisfied);\n@@ -1422,9 +1422,2 @@\n-    \/\/ We need an acquire here to ensure that any subsequent load of the\n-    \/\/ global SafepointSynchronize::_state flag is ordered after this load\n-    \/\/ of the thread-local polling word.  We don't want this poll to\n-    \/\/ return false (i.e. not safepointing) and a later poll of the global\n-    \/\/ SafepointSynchronize::_state spuriously to return true.\n-    \/\/\n-    \/\/ This is to avoid a race when we're in a native->Java transition\n-    \/\/ racing the code which wakes up from a safepoint.\n-    __ safepoint_poll(L, true \/* at_return *\/, true \/* acquire *\/, false \/* in_nmethod *\/);\n+    \/\/ No need for acquire as Java threads always disarm themselves.\n+    __ safepoint_poll(L, true \/* at_return *\/, false \/* acquire *\/, false \/* in_nmethod *\/);\n@@ -1441,1 +1434,1 @@\n-    __ mov(rscratch2, CAST_FROM_FN_PTR(address, JavaThread::check_special_condition_for_native_trans));\n+    __ lea(rscratch2, RuntimeAddress(CAST_FROM_FN_PTR(address, JavaThread::check_special_condition_for_native_trans)));\n@@ -1491,1 +1484,1 @@\n-    __ mov(rscratch2, CAST_FROM_FN_PTR(address, SharedRuntime::reguard_yellow_pages));\n+    __ lea(rscratch2, RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::reguard_yellow_pages)));\n@@ -2094,1 +2087,1 @@\n-  __ bl(Interpreter::trace_code(t->tos_in()));\n+  __ bl(RuntimeAddress(Interpreter::trace_code(t->tos_in())));\n","filename":"src\/hotspot\/cpu\/aarch64\/templateInterpreterGenerator_aarch64.cpp","additions":10,"deletions":17,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -1046,5 +1046,1 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n-      call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter_obj), object);\n-    } else {\n-      call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n-    }\n+    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n","filename":"src\/hotspot\/cpu\/ppc\/interp_masm_ppc_64.cpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1075,10 +1075,3 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    \/\/ for lightweight locking we need to use monitorenter_obj, see interpreterRuntime.cpp\n-    call_VM(noreg,\n-            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter_obj),\n-            object);\n-  } else {\n-    call_VM(noreg,\n-            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n-            monitor);\n-  }\n+  call_VM(noreg,\n+          CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n+          monitor);\n","filename":"src\/hotspot\/cpu\/s390\/interp_masm_s390.cpp","additions":3,"deletions":10,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -70,0 +70,1 @@\n+    lightweight_lock(disp_hdr, obj, hdr, thread, tmp, slow_case);\n@@ -71,2 +72,4 @@\n-    const Register thread = disp_hdr;\n-    get_thread(thread);\n+    \/\/ Implicit null check.\n+    movptr(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    \/\/ Lacking registers and thread on x86_32. Always take slow path.\n+    jmp(slow_case);\n@@ -74,1 +77,0 @@\n-    lightweight_lock(obj, hdr, thread, tmp, slow_case);\n@@ -147,4 +149,2 @@\n-    \/\/ This relies on the implementation of lightweight_unlock being able to handle\n-    \/\/ that the reg_rax and thread Register parameters may alias each other.\n-    get_thread(disp_hdr);\n-    lightweight_unlock(obj, disp_hdr, disp_hdr, hdr, slow_case);\n+    \/\/ Lacking registers and thread on x86_32. Always take slow path.\n+    jmp(slow_case);\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -622,0 +622,5 @@\n+  if (UseObjectMonitorTable) {\n+    \/\/ Clear cache in case fast locking succeeds.\n+    movptr(Address(box, BasicLock::object_monitor_cache_offset_in_bytes()), 0);\n+  }\n+\n@@ -635,1 +640,1 @@\n-    const Register top = box;\n+    const Register top = UseObjectMonitorTable ? rax_reg : box;\n@@ -662,0 +667,4 @@\n+    if (UseObjectMonitorTable) {\n+      \/\/ Need to reload top, clobbered by CAS.\n+      movl(top, Address(thread, JavaThread::lock_stack_top_offset()));\n+    }\n@@ -672,1 +681,44 @@\n-    const Register tagged_monitor = mark;\n+    const Register monitor = t;\n+\n+    if (!UseObjectMonitorTable) {\n+      assert(mark == monitor, \"should be the same here\");\n+    } else {\n+      \/\/ Uses ObjectMonitorTable.  Look for the monitor in the om_cache.\n+      \/\/ Fetch ObjectMonitor* from the cache or take the slow-path.\n+      Label monitor_found;\n+\n+      \/\/ Load cache address\n+      lea(t, Address(thread, JavaThread::om_cache_oops_offset()));\n+\n+      const int num_unrolled = 2;\n+      for (int i = 0; i < num_unrolled; i++) {\n+        cmpptr(obj, Address(t));\n+        jccb(Assembler::equal, monitor_found);\n+        increment(t, in_bytes(OMCache::oop_to_oop_difference()));\n+      }\n+\n+      Label loop;\n+\n+      \/\/ Search for obj in cache.\n+      bind(loop);\n+\n+      \/\/ Check for match.\n+      cmpptr(obj, Address(t));\n+      jccb(Assembler::equal, monitor_found);\n+\n+      \/\/ Search until null encountered, guaranteed _null_sentinel at end.\n+      cmpptr(Address(t), 1);\n+      jcc(Assembler::below, slow_path); \/\/ 0 check, but with ZF=0 when *t == 0\n+      increment(t, in_bytes(OMCache::oop_to_oop_difference()));\n+      jmpb(loop);\n+\n+      \/\/ Cache hit.\n+      bind(monitor_found);\n+      movptr(monitor, Address(t, OMCache::oop_to_monitor_difference()));\n+    }\n+    const ByteSize monitor_tag = in_ByteSize(UseObjectMonitorTable ? 0 : checked_cast<int>(markWord::monitor_value));\n+    const Address recursions_address(monitor, ObjectMonitor::recursions_offset() - monitor_tag);\n+    const Address owner_address(monitor, ObjectMonitor::owner_offset() - monitor_tag);\n+\n+    Label monitor_locked;\n+    \/\/ Lock the monitor.\n@@ -676,2 +728,2 @@\n-    lock(); cmpxchgptr(thread, Address(tagged_monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n-    jccb(Assembler::equal, locked);\n+    lock(); cmpxchgptr(thread, owner_address);\n+    jccb(Assembler::equal, monitor_locked);\n@@ -684,1 +736,7 @@\n-    increment(Address(tagged_monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n+    increment(recursions_address);\n+\n+    bind(monitor_locked);\n+    if (UseObjectMonitorTable) {\n+      \/\/ Cache the monitor for unlock\n+      movptr(Address(box, BasicLock::object_monitor_cache_offset_in_bytes()), monitor);\n+    }\n@@ -726,1 +784,3 @@\n-  const Register top = reg_rax;\n+  const Register monitor = t;\n+  const Register top = UseObjectMonitorTable ? t : reg_rax;\n+  const Register box = reg_rax;\n@@ -738,0 +798,1 @@\n+  Label& slow_path = stub == nullptr ? dummy : stub->slow_path();\n@@ -744,2 +805,4 @@\n-    \/\/ Prefetch mark.\n-    movptr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    if (!UseObjectMonitorTable) {\n+      \/\/ Prefetch mark.\n+      movptr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    }\n@@ -762,0 +825,5 @@\n+    if (UseObjectMonitorTable) {\n+      \/\/ Load mark.\n+      movptr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    }\n+\n@@ -783,0 +851,3 @@\n+    if (UseObjectMonitorTable) {\n+      movptr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    }\n@@ -790,13 +861,14 @@\n-    \/\/ mark contains the tagged ObjectMonitor*.\n-    const Register monitor = mark;\n-\n-#ifndef _LP64\n-    \/\/ Check if recursive.\n-    xorptr(reg_rax, reg_rax);\n-    orptr(reg_rax, Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n-    jcc(Assembler::notZero, check_successor);\n-\n-    \/\/ Check if the entry lists are empty.\n-    movptr(reg_rax, Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n-    orptr(reg_rax, Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n-    jcc(Assembler::notZero, check_successor);\n+    if (!UseObjectMonitorTable) {\n+      assert(mark == monitor, \"should be the same here\");\n+    } else {\n+      \/\/ Uses ObjectMonitorTable.  Look for the monitor in our BasicLock on the stack.\n+      movptr(monitor, Address(box, BasicLock::object_monitor_cache_offset_in_bytes()));\n+      \/\/ null check with ZF == 0, no valid pointer below alignof(ObjectMonitor*)\n+      cmpptr(monitor, alignof(ObjectMonitor*));\n+      jcc(Assembler::below, slow_path);\n+    }\n+    const ByteSize monitor_tag = in_ByteSize(UseObjectMonitorTable ? 0 : checked_cast<int>(markWord::monitor_value));\n+    const Address recursions_address{monitor, ObjectMonitor::recursions_offset() - monitor_tag};\n+    const Address cxq_address{monitor, ObjectMonitor::cxq_offset() - monitor_tag};\n+    const Address EntryList_address{monitor, ObjectMonitor::EntryList_offset() - monitor_tag};\n+    const Address owner_address{monitor, ObjectMonitor::owner_offset() - monitor_tag};\n@@ -804,3 +876,0 @@\n-    \/\/ Release lock.\n-    movptr(Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), NULL_WORD);\n-#else \/\/ _LP64\n@@ -810,1 +879,1 @@\n-    cmpptr(Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)), 0);\n+    cmpptr(recursions_address, 0);\n@@ -814,2 +883,2 @@\n-    movptr(reg_rax, Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n-    orptr(reg_rax, Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n+    movptr(reg_rax, cxq_address);\n+    orptr(reg_rax, EntryList_address);\n@@ -819,1 +888,1 @@\n-    movptr(Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), NULL_WORD);\n+    movptr(owner_address, NULL_WORD);\n@@ -824,1 +893,1 @@\n-    decrement(Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n+    decrement(recursions_address);\n@@ -826,1 +895,0 @@\n-#endif\n@@ -1818,0 +1886,10 @@\n+void C2_MacroAssembler::unordered_reduce_operation_128(BasicType typ, int opcode, XMMRegister dst, XMMRegister src) {\n+  switch (opcode) {\n+    case Op_AddReductionVF: addps(dst, src); break;\n+    case Op_AddReductionVD: addpd(dst, src); break;\n+    case Op_MulReductionVF: mulps(dst, src); break;\n+    case Op_MulReductionVD: mulpd(dst, src); break;\n+    default:                assert(false, \"%s\", NodeClassNames[opcode]);\n+  }\n+}\n+\n@@ -1866,0 +1944,12 @@\n+void C2_MacroAssembler::unordered_reduce_operation_256(BasicType typ, int opcode, XMMRegister dst,  XMMRegister src1, XMMRegister src2) {\n+  int vector_len = Assembler::AVX_256bit;\n+\n+  switch (opcode) {\n+    case Op_AddReductionVF: vaddps(dst, src1, src2, vector_len); break;\n+    case Op_AddReductionVD: vaddpd(dst, src1, src2, vector_len); break;\n+    case Op_MulReductionVF: vmulps(dst, src1, src2, vector_len); break;\n+    case Op_MulReductionVD: vmulpd(dst, src1, src2, vector_len); break;\n+    default:                assert(false, \"%s\", NodeClassNames[opcode]);\n+  }\n+}\n+\n@@ -1884,0 +1974,18 @@\n+void C2_MacroAssembler::unordered_reduce_fp(int opcode, int vlen,\n+                                            XMMRegister dst, XMMRegister src,\n+                                            XMMRegister vtmp1, XMMRegister vtmp2) {\n+  switch (opcode) {\n+    case Op_AddReductionVF:\n+    case Op_MulReductionVF:\n+      unorderedReduceF(opcode, vlen, dst, src, vtmp1, vtmp2);\n+      break;\n+\n+    case Op_AddReductionVD:\n+    case Op_MulReductionVD:\n+      unorderedReduceD(opcode, vlen, dst, src, vtmp1, vtmp2);\n+      break;\n+\n+    default: assert(false, \"%s\", NodeClassNames[opcode]);\n+  }\n+}\n+\n@@ -1986,0 +2094,39 @@\n+void C2_MacroAssembler::unorderedReduceF(int opcode, int vlen, XMMRegister dst, XMMRegister src, XMMRegister vtmp1, XMMRegister vtmp2) {\n+  switch (vlen) {\n+    case 2:\n+      assert(vtmp1 == xnoreg, \"\");\n+      assert(vtmp2 == xnoreg, \"\");\n+      unorderedReduce2F(opcode, dst, src);\n+      break;\n+    case 4:\n+      assert(vtmp2 == xnoreg, \"\");\n+      unorderedReduce4F(opcode, dst, src, vtmp1);\n+      break;\n+    case 8:\n+      unorderedReduce8F(opcode, dst, src, vtmp1, vtmp2);\n+      break;\n+    case 16:\n+      unorderedReduce16F(opcode, dst, src, vtmp1, vtmp2);\n+      break;\n+    default: assert(false, \"wrong vector length\");\n+  }\n+}\n+\n+void C2_MacroAssembler::unorderedReduceD(int opcode, int vlen, XMMRegister dst, XMMRegister src, XMMRegister vtmp1, XMMRegister vtmp2) {\n+  switch (vlen) {\n+    case 2:\n+      assert(vtmp1 == xnoreg, \"\");\n+      assert(vtmp2 == xnoreg, \"\");\n+      unorderedReduce2D(opcode, dst, src);\n+      break;\n+    case 4:\n+      assert(vtmp2 == xnoreg, \"\");\n+      unorderedReduce4D(opcode, dst, src, vtmp1);\n+      break;\n+    case 8:\n+      unorderedReduce8D(opcode, dst, src, vtmp1, vtmp2);\n+      break;\n+    default: assert(false, \"wrong vector length\");\n+  }\n+}\n+\n@@ -2213,0 +2360,23 @@\n+void C2_MacroAssembler::unorderedReduce2F(int opcode, XMMRegister dst, XMMRegister src) {\n+  pshufd(dst, src, 0x1);\n+  reduce_operation_128(T_FLOAT, opcode, dst, src);\n+}\n+\n+void C2_MacroAssembler::unorderedReduce4F(int opcode, XMMRegister dst, XMMRegister src, XMMRegister vtmp) {\n+  pshufd(vtmp, src, 0xE);\n+  unordered_reduce_operation_128(T_FLOAT, opcode, vtmp, src);\n+  unorderedReduce2F(opcode, dst, vtmp);\n+}\n+\n+void C2_MacroAssembler::unorderedReduce8F(int opcode, XMMRegister dst, XMMRegister src, XMMRegister vtmp1, XMMRegister vtmp2) {\n+  vextractf128_high(vtmp1, src);\n+  unordered_reduce_operation_128(T_FLOAT, opcode, vtmp1, src);\n+  unorderedReduce4F(opcode, dst, vtmp1, vtmp2);\n+}\n+\n+void C2_MacroAssembler::unorderedReduce16F(int opcode, XMMRegister dst, XMMRegister src, XMMRegister vtmp1, XMMRegister vtmp2) {\n+  vextractf64x4_high(vtmp2, src);\n+  unordered_reduce_operation_256(T_FLOAT, opcode, vtmp2, vtmp2, src);\n+  unorderedReduce8F(opcode, dst, vtmp2, vtmp1, vtmp2);\n+}\n+\n@@ -2231,0 +2401,17 @@\n+void C2_MacroAssembler::unorderedReduce2D(int opcode, XMMRegister dst, XMMRegister src) {\n+  pshufd(dst, src, 0xE);\n+  reduce_operation_128(T_DOUBLE, opcode, dst, src);\n+}\n+\n+void C2_MacroAssembler::unorderedReduce4D(int opcode, XMMRegister dst, XMMRegister src, XMMRegister vtmp) {\n+  vextractf128_high(vtmp, src);\n+  unordered_reduce_operation_128(T_DOUBLE, opcode, vtmp, src);\n+  unorderedReduce2D(opcode, dst, vtmp);\n+}\n+\n+void C2_MacroAssembler::unorderedReduce8D(int opcode, XMMRegister dst, XMMRegister src, XMMRegister vtmp1, XMMRegister vtmp2) {\n+  vextractf64x4_high(vtmp2, src);\n+  unordered_reduce_operation_256(T_DOUBLE, opcode, vtmp2, vtmp2, src);\n+  unorderedReduce4D(opcode, dst, vtmp2, vtmp1);\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":217,"deletions":30,"binary":false,"changes":247,"status":"modified"},{"patch":"@@ -153,0 +153,3 @@\n+  void unordered_reduce_fp(int opcode, int vlen,\n+                           XMMRegister dst, XMMRegister src,\n+                           XMMRegister vtmp1 = xnoreg, XMMRegister vtmp2 = xnoreg);\n@@ -165,0 +168,2 @@\n+  void unorderedReduceF(int opcode, int vlen, XMMRegister dst, XMMRegister src, XMMRegister vtmp1, XMMRegister vtmp2);\n+  void unorderedReduceD(int opcode, int vlen, XMMRegister dst, XMMRegister src, XMMRegister vtmp1, XMMRegister vtmp2);\n@@ -201,0 +206,6 @@\n+  \/\/ Unordered Float Reduction\n+  void unorderedReduce2F(int opcode, XMMRegister dst, XMMRegister src);\n+  void unorderedReduce4F(int opcode, XMMRegister dst, XMMRegister src, XMMRegister vtmp);\n+  void unorderedReduce8F(int opcode, XMMRegister dst, XMMRegister src, XMMRegister vtmp1, XMMRegister vtmp2);\n+  void unorderedReduce16F(int opcode, XMMRegister dst, XMMRegister src, XMMRegister vtmp1, XMMRegister vtmp2);\n+\n@@ -206,0 +217,5 @@\n+  \/\/ Unordered Double Reduction\n+  void unorderedReduce2D(int opcode, XMMRegister dst, XMMRegister src);\n+  void unorderedReduce4D(int opcode, XMMRegister dst, XMMRegister src, XMMRegister vtmp);\n+  void unorderedReduce8D(int opcode, XMMRegister dst, XMMRegister src, XMMRegister vtmp1, XMMRegister vtmp2);\n+\n@@ -209,0 +225,2 @@\n+  void unordered_reduce_operation_128(BasicType typ, int opcode, XMMRegister dst, XMMRegister src);\n+  void unordered_reduce_operation_256(BasicType typ, int opcode, XMMRegister dst, XMMRegister src1, XMMRegister src2);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -285,1 +285,1 @@\n-  assert(_pc == *pc_addr || pc == *pc_addr || *pc_addr == 0, \"\");\n+  assert(_pc == *pc_addr || pc == *pc_addr || *pc_addr == nullptr, \"\");\n@@ -489,1 +489,1 @@\n-  if (fp() == 0 || (intptr_t(fp()) & (wordSize-1)) != 0) {\n+  if (fp() == nullptr || (intptr_t(fp()) & (wordSize-1)) != 0) {\n@@ -492,1 +492,1 @@\n-  if (sp() == 0 || (intptr_t(sp()) & (wordSize-1)) != 0) {\n+  if (sp() == nullptr || (intptr_t(sp()) & (wordSize-1)) != 0) {\n","filename":"src\/hotspot\/cpu\/x86\/frame_x86.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -441,1 +441,1 @@\n-  __ cmpl(Address(tmp1, ClassLoaderData::keep_alive_offset()), 0);\n+  __ cmpl(Address(tmp1, ClassLoaderData::keep_alive_ref_count_offset()), 0);\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetAssembler_x86.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1335,0 +1335,1 @@\n+      lightweight_lock(lock_reg, obj_reg, swap_reg, thread, tmp_reg, slow_case);\n@@ -1336,2 +1337,2 @@\n-      const Register thread = lock_reg;\n-      get_thread(thread);\n+      \/\/ Lacking registers and thread on x86_32. Always take slow path.\n+      jmp(slow_case);\n@@ -1339,1 +1340,0 @@\n-      lightweight_lock(obj_reg, swap_reg, thread, tmp_reg, slow_case);\n@@ -1405,9 +1405,3 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n-      call_VM(noreg,\n-              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter_obj),\n-              obj_reg);\n-    } else {\n-      call_VM(noreg,\n-              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n-              lock_reg);\n-    }\n+    call_VM(noreg,\n+            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n+            lock_reg);\n@@ -1462,4 +1456,2 @@\n-      \/\/ This relies on the implementation of lightweight_unlock being able to handle\n-      \/\/ that the reg_rax and thread Register parameters may alias each other.\n-      get_thread(swap_reg);\n-      lightweight_unlock(obj_reg, swap_reg, swap_reg, header_reg, slow_case);\n+      \/\/ Lacking registers and thread on x86_32. Always take slow path.\n+      jmp(slow_case);\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":8,"deletions":16,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2004, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2004, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -122,1 +122,1 @@\n-  __ jump (ExternalAddress(slow_case_addr), rscratch1);\n+  __ jump (RuntimeAddress(slow_case_addr), rscratch1);\n@@ -210,1 +210,1 @@\n-  __ jump (ExternalAddress(slow_case_addr), rscratch1);\n+  __ jump (RuntimeAddress(slow_case_addr), rscratch1);\n","filename":"src\/hotspot\/cpu\/x86\/jniFastGetField_x86_64.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1313,1 +1313,1 @@\n-  jump(RuntimeAddress(StubRoutines::throw_delayed_StackOverflowError_entry()));\n+  jump(RuntimeAddress(SharedRuntime::throw_delayed_StackOverflowError_entry()));\n@@ -2343,1 +2343,1 @@\n-\n+  assert(!dst.rspec().reloc()->is_data(), \"should not use ExternalAddress for jump\");\n@@ -2354,1 +2354,1 @@\n-\n+  assert(!dst.rspec().reloc()->is_data(), \"should not use ExternalAddress for jump_cc\");\n@@ -5248,3 +5248,2 @@\n-  assert(Klass::SECONDARY_SUPERS_BITMAP_FULL == ~uintx(0), \"\");\n-  cmpq(r_bitmap, (int32_t)-1); \/\/ sign-extends immediate to 64-bit value\n-  jcc(Assembler::equal, L_huge);\n+  cmpl(r_array_length, (int32_t)Klass::SECONDARY_SUPERS_TABLE_SIZE - 2);\n+  jcc(Assembler::greater, L_huge);\n@@ -11040,1 +11039,1 @@\n-void MacroAssembler::lightweight_lock(Register obj, Register reg_rax, Register thread, Register tmp, Label& slow) {\n+void MacroAssembler::lightweight_lock(Register basic_lock, Register obj, Register reg_rax, Register thread, Register tmp, Label& slow) {\n@@ -11042,1 +11041,1 @@\n-  assert_different_registers(obj, reg_rax, thread, tmp);\n+  assert_different_registers(basic_lock, obj, reg_rax, thread, tmp);\n@@ -11051,0 +11050,5 @@\n+  if (UseObjectMonitorTable) {\n+    \/\/ Clear cache in case fast locking succeeds.\n+    movptr(Address(basic_lock, BasicObjectLock::lock_offset() + in_ByteSize((BasicLock::object_monitor_cache_offset_in_bytes()))), 0);\n+  }\n+\n@@ -11093,3 +11097,0 @@\n-\/\/\n-\/\/ x86_32 Note: reg_rax and thread may alias each other due to limited register\n-\/\/              availiability.\n@@ -11098,2 +11099,1 @@\n-  assert_different_registers(obj, reg_rax, tmp);\n-  LP64_ONLY(assert_different_registers(obj, reg_rax, thread, tmp);)\n+  assert_different_registers(obj, reg_rax, thread, tmp);\n@@ -11139,4 +11139,0 @@\n-  if (thread == reg_rax) {\n-    \/\/ On x86_32 we may lose the thread.\n-    get_thread(thread);\n-  }\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":13,"deletions":17,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -2224,1 +2224,1 @@\n-  void lightweight_lock(Register obj, Register reg_rax, Register thread, Register tmp, Label& slow);\n+  void lightweight_lock(Register basic_lock, Register obj, Register reg_rax, Register thread, Register tmp, Label& slow);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -166,1 +166,1 @@\n-  __ jump(RuntimeAddress(StubRoutines::throw_AbstractMethodError_entry()));\n+  __ jump(RuntimeAddress(SharedRuntime::throw_AbstractMethodError_entry()));\n@@ -517,1 +517,1 @@\n-      __ jump(RuntimeAddress(StubRoutines::throw_IncompatibleClassChangeError_entry()));\n+      __ jump(RuntimeAddress(SharedRuntime::throw_IncompatibleClassChangeError_entry()));\n@@ -579,1 +579,1 @@\n-      if (cur_frame.fp() != 0) {  \/\/ not walkable\n+      if (cur_frame.fp() != nullptr) { \/\/ not walkable\n","filename":"src\/hotspot\/cpu\/x86\/methodHandles_x86.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -46,0 +46,1 @@\n+#include \"runtime\/timerTrace.hpp\"\n@@ -59,0 +60,6 @@\n+#ifdef PRODUCT\n+#define BLOCK_COMMENT(str) \/* nothing *\/\n+#else\n+#define BLOCK_COMMENT(str) __ block_comment(str)\n+#endif \/\/ PRODUCT\n+\n@@ -718,1 +725,1 @@\n-  __ lea(temp_reg, ExternalAddress(code_start));\n+  __ lea(temp_reg, AddressLiteral(code_start, relocInfo::none));\n@@ -721,1 +728,1 @@\n-  __ lea(temp_reg, ExternalAddress(code_end));\n+  __ lea(temp_reg, AddressLiteral(code_end, relocInfo::none));\n@@ -1704,1 +1711,2 @@\n-      __ lightweight_lock(obj_reg, swap_reg, thread, lock_reg, slow_path_lock);\n+      \/\/ Lacking registers and thread on x86_32. Always take slow path.\n+      __ jmp(slow_path_lock);\n@@ -2407,177 +2415,0 @@\n-\n-#ifdef COMPILER2\n-\/\/------------------------------generate_uncommon_trap_blob--------------------\n-void SharedRuntime::generate_uncommon_trap_blob() {\n-  \/\/ allocate space for the code\n-  ResourceMark rm;\n-  \/\/ setup code generation tools\n-  CodeBuffer   buffer(\"uncommon_trap_blob\", 512, 512);\n-  MacroAssembler* masm = new MacroAssembler(&buffer);\n-\n-  enum frame_layout {\n-    arg0_off,      \/\/ thread                     sp + 0 \/\/ Arg location for\n-    arg1_off,      \/\/ unloaded_class_index       sp + 1 \/\/ calling C\n-    arg2_off,      \/\/ exec_mode                  sp + 2\n-    \/\/ The frame sender code expects that rbp will be in the \"natural\" place and\n-    \/\/ will override any oopMap setting for it. We must therefore force the layout\n-    \/\/ so that it agrees with the frame sender code.\n-    rbp_off,       \/\/ callee saved register      sp + 3\n-    return_off,    \/\/ slot for return address    sp + 4\n-    framesize\n-  };\n-\n-  address start = __ pc();\n-\n-  \/\/ Push self-frame.\n-  __ subptr(rsp, return_off*wordSize);     \/\/ Epilog!\n-\n-  \/\/ rbp, is an implicitly saved callee saved register (i.e. the calling\n-  \/\/ convention will save restore it in prolog\/epilog) Other than that\n-  \/\/ there are no callee save registers no that adapter frames are gone.\n-  __ movptr(Address(rsp, rbp_off*wordSize), rbp);\n-\n-  \/\/ Clear the floating point exception stack\n-  __ empty_FPU_stack();\n-\n-  \/\/ set last_Java_sp\n-  __ get_thread(rdx);\n-  __ set_last_Java_frame(rdx, noreg, noreg, nullptr, noreg);\n-\n-  \/\/ Call C code.  Need thread but NOT official VM entry\n-  \/\/ crud.  We cannot block on this call, no GC can happen.  Call should\n-  \/\/ capture callee-saved registers as well as return values.\n-  __ movptr(Address(rsp, arg0_off*wordSize), rdx);\n-  \/\/ argument already in ECX\n-  __ movl(Address(rsp, arg1_off*wordSize),rcx);\n-  __ movl(Address(rsp, arg2_off*wordSize), Deoptimization::Unpack_uncommon_trap);\n-  __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, Deoptimization::uncommon_trap)));\n-\n-  \/\/ Set an oopmap for the call site\n-  OopMapSet *oop_maps = new OopMapSet();\n-  OopMap* map =  new OopMap( framesize, 0 );\n-  \/\/ No oopMap for rbp, it is known implicitly\n-\n-  oop_maps->add_gc_map( __ pc()-start, map);\n-\n-  __ get_thread(rcx);\n-\n-  __ reset_last_Java_frame(rcx, false);\n-\n-  \/\/ Load UnrollBlock into EDI\n-  __ movptr(rdi, rax);\n-\n-#ifdef ASSERT\n-  { Label L;\n-    __ cmpptr(Address(rdi, Deoptimization::UnrollBlock::unpack_kind_offset()),\n-            (int32_t)Deoptimization::Unpack_uncommon_trap);\n-    __ jcc(Assembler::equal, L);\n-    __ stop(\"SharedRuntime::generate_uncommon_trap_blob: expected Unpack_uncommon_trap\");\n-    __ bind(L);\n-  }\n-#endif\n-\n-  \/\/ Pop all the frames we must move\/replace.\n-  \/\/\n-  \/\/ Frame picture (youngest to oldest)\n-  \/\/ 1: self-frame (no frame link)\n-  \/\/ 2: deopting frame  (no frame link)\n-  \/\/ 3: caller of deopting frame (could be compiled\/interpreted).\n-\n-  \/\/ Pop self-frame.  We have no frame, and must rely only on EAX and ESP.\n-  __ addptr(rsp,(framesize-1)*wordSize);     \/\/ Epilog!\n-\n-  \/\/ Pop deoptimized frame\n-  __ movl2ptr(rcx, Address(rdi,Deoptimization::UnrollBlock::size_of_deoptimized_frame_offset()));\n-  __ addptr(rsp, rcx);\n-\n-  \/\/ sp should be pointing at the return address to the caller (3)\n-\n-  \/\/ Pick up the initial fp we should save\n-  \/\/ restore rbp before stack bang because if stack overflow is thrown it needs to be pushed (and preserved)\n-  __ movptr(rbp, Address(rdi, Deoptimization::UnrollBlock::initial_info_offset()));\n-\n-#ifdef ASSERT\n-  \/\/ Compilers generate code that bang the stack by as much as the\n-  \/\/ interpreter would need. So this stack banging should never\n-  \/\/ trigger a fault. Verify that it does not on non product builds.\n-  __ movl(rbx, Address(rdi ,Deoptimization::UnrollBlock::total_frame_sizes_offset()));\n-  __ bang_stack_size(rbx, rcx);\n-#endif\n-\n-  \/\/ Load array of frame pcs into ECX\n-  __ movl(rcx,Address(rdi,Deoptimization::UnrollBlock::frame_pcs_offset()));\n-\n-  __ pop(rsi); \/\/ trash the pc\n-\n-  \/\/ Load array of frame sizes into ESI\n-  __ movptr(rsi,Address(rdi,Deoptimization::UnrollBlock::frame_sizes_offset()));\n-\n-  Address counter(rdi, Deoptimization::UnrollBlock::counter_temp_offset());\n-\n-  __ movl(rbx, Address(rdi, Deoptimization::UnrollBlock::number_of_frames_offset()));\n-  __ movl(counter, rbx);\n-\n-  \/\/ Now adjust the caller's stack to make up for the extra locals\n-  \/\/ but record the original sp so that we can save it in the skeletal interpreter\n-  \/\/ frame and the stack walking of interpreter_sender will get the unextended sp\n-  \/\/ value and not the \"real\" sp value.\n-\n-  Address sp_temp(rdi, Deoptimization::UnrollBlock::sender_sp_temp_offset());\n-  __ movptr(sp_temp, rsp);\n-  __ movl(rbx, Address(rdi, Deoptimization::UnrollBlock::caller_adjustment_offset()));\n-  __ subptr(rsp, rbx);\n-\n-  \/\/ Push interpreter frames in a loop\n-  Label loop;\n-  __ bind(loop);\n-  __ movptr(rbx, Address(rsi, 0));      \/\/ Load frame size\n-  __ subptr(rbx, 2*wordSize);           \/\/ we'll push pc and rbp, by hand\n-  __ pushptr(Address(rcx, 0));          \/\/ save return address\n-  __ enter();                           \/\/ save old & set new rbp,\n-  __ subptr(rsp, rbx);                  \/\/ Prolog!\n-  __ movptr(rbx, sp_temp);              \/\/ sender's sp\n-  \/\/ This value is corrected by layout_activation_impl\n-  __ movptr(Address(rbp, frame::interpreter_frame_last_sp_offset * wordSize), NULL_WORD );\n-  __ movptr(Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize), rbx); \/\/ Make it walkable\n-  __ movptr(sp_temp, rsp);              \/\/ pass to next frame\n-  __ addptr(rsi, wordSize);             \/\/ Bump array pointer (sizes)\n-  __ addptr(rcx, wordSize);             \/\/ Bump array pointer (pcs)\n-  __ decrementl(counter);             \/\/ decrement counter\n-  __ jcc(Assembler::notZero, loop);\n-  __ pushptr(Address(rcx, 0));            \/\/ save final return address\n-\n-  \/\/ Re-push self-frame\n-  __ enter();                           \/\/ save old & set new rbp,\n-  __ subptr(rsp, (framesize-2) * wordSize);   \/\/ Prolog!\n-\n-\n-  \/\/ set last_Java_sp, last_Java_fp\n-  __ get_thread(rdi);\n-  __ set_last_Java_frame(rdi, noreg, rbp, nullptr, noreg);\n-\n-  \/\/ Call C code.  Need thread but NOT official VM entry\n-  \/\/ crud.  We cannot block on this call, no GC can happen.  Call should\n-  \/\/ restore return values to their stack-slots with the new SP.\n-  __ movptr(Address(rsp,arg0_off*wordSize),rdi);\n-  __ movl(Address(rsp,arg1_off*wordSize), Deoptimization::Unpack_uncommon_trap);\n-  __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, Deoptimization::unpack_frames)));\n-  \/\/ Set an oopmap for the call site\n-  oop_maps->add_gc_map( __ pc()-start, new OopMap( framesize, 0 ) );\n-\n-  __ get_thread(rdi);\n-  __ reset_last_Java_frame(rdi, true);\n-\n-  \/\/ Pop self-frame.\n-  __ leave();     \/\/ Epilog!\n-\n-  \/\/ Jump to interpreter\n-  __ ret(0);\n-\n-  \/\/ -------------\n-  \/\/ make sure all code is generated\n-  masm->flush();\n-\n-   _uncommon_trap_blob = UncommonTrapBlob::create(&buffer, oop_maps, framesize);\n-}\n-#endif \/\/ COMPILER2\n-\n@@ -2830,0 +2661,204 @@\n+\n+  \/\/------------------------------------------------------------------------------------------------------------------------\n+  \/\/ Continuation point for throwing of implicit exceptions that are not handled in\n+  \/\/ the current activation. Fabricates an exception oop and initiates normal\n+  \/\/ exception dispatching in this frame.\n+  \/\/\n+  \/\/ Previously the compiler (c2) allowed for callee save registers on Java calls.\n+  \/\/ This is no longer true after adapter frames were removed but could possibly\n+  \/\/ be brought back in the future if the interpreter code was reworked and it\n+  \/\/ was deemed worthwhile. The comment below was left to describe what must\n+  \/\/ happen here if callee saves were resurrected. As it stands now this stub\n+  \/\/ could actually be a vanilla BufferBlob and have now oopMap at all.\n+  \/\/ Since it doesn't make much difference we've chosen to leave it the\n+  \/\/ way it was in the callee save days and keep the comment.\n+\n+  \/\/ If we need to preserve callee-saved values we need a callee-saved oop map and\n+  \/\/ therefore have to make these stubs into RuntimeStubs rather than BufferBlobs.\n+  \/\/ If the compiler needs all registers to be preserved between the fault\n+  \/\/ point and the exception handler then it must assume responsibility for that in\n+  \/\/ AbstractCompiler::continuation_for_implicit_null_exception or\n+  \/\/ continuation_for_implicit_division_by_zero_exception. All other implicit\n+  \/\/ exceptions (e.g., NullPointerException or AbstractMethodError on entry) are\n+  \/\/ either at call sites or otherwise assume that stack unwinding will be initiated,\n+  \/\/ so caller saved registers were assumed volatile in the compiler.\n+RuntimeStub* SharedRuntime::generate_throw_exception(const char* name, address runtime_entry) {\n+\n+  \/\/ Information about frame layout at time of blocking runtime call.\n+  \/\/ Note that we only have to preserve callee-saved registers since\n+  \/\/ the compilers are responsible for supplying a continuation point\n+  \/\/ if they expect all registers to be preserved.\n+  enum layout {\n+    thread_off,    \/\/ last_java_sp\n+    arg1_off,\n+    arg2_off,\n+    rbp_off,       \/\/ callee saved register\n+    ret_pc,\n+    framesize\n+  };\n+\n+  int insts_size = 256;\n+  int locs_size  = 32;\n+\n+  ResourceMark rm;\n+  const char* timer_msg = \"SharedRuntime generate_throw_exception\";\n+  TraceTime timer(timer_msg, TRACETIME_LOG(Info, startuptime));\n+\n+  CodeBuffer code(name, insts_size, locs_size);\n+  OopMapSet* oop_maps  = new OopMapSet();\n+  MacroAssembler* masm = new MacroAssembler(&code);\n+\n+  address start = __ pc();\n+\n+  \/\/ This is an inlined and slightly modified version of call_VM\n+  \/\/ which has the ability to fetch the return PC out of\n+  \/\/ thread-local storage and also sets up last_Java_sp slightly\n+  \/\/ differently than the real call_VM\n+  Register java_thread = rbx;\n+  __ get_thread(java_thread);\n+\n+  __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n+\n+  \/\/ pc and rbp, already pushed\n+  __ subptr(rsp, (framesize-2) * wordSize); \/\/ prolog\n+\n+  \/\/ Frame is now completed as far as size and linkage.\n+\n+  int frame_complete = __ pc() - start;\n+\n+  \/\/ push java thread (becomes first argument of C function)\n+  __ movptr(Address(rsp, thread_off * wordSize), java_thread);\n+  \/\/ Set up last_Java_sp and last_Java_fp\n+  __ set_last_Java_frame(java_thread, rsp, rbp, nullptr, noreg);\n+\n+  \/\/ Call runtime\n+  BLOCK_COMMENT(\"call runtime_entry\");\n+  __ call(RuntimeAddress(runtime_entry));\n+  \/\/ Generate oop map\n+  OopMap* map =  new OopMap(framesize, 0);\n+  oop_maps->add_gc_map(__ pc() - start, map);\n+\n+  \/\/ restore the thread (cannot use the pushed argument since arguments\n+  \/\/ may be overwritten by C code generated by an optimizing compiler);\n+  \/\/ however can use the register value directly if it is callee saved.\n+  __ get_thread(java_thread);\n+\n+  __ reset_last_Java_frame(java_thread, true);\n+\n+  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+\n+  \/\/ check for pending exceptions\n+#ifdef ASSERT\n+  Label L;\n+  __ cmpptr(Address(java_thread, Thread::pending_exception_offset()), NULL_WORD);\n+  __ jcc(Assembler::notEqual, L);\n+  __ should_not_reach_here();\n+  __ bind(L);\n+#endif \/* ASSERT *\/\n+  __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+\n+\n+  RuntimeStub* stub = RuntimeStub::new_runtime_stub(name, &code, frame_complete, framesize, oop_maps, false);\n+  return stub;\n+}\n+\n+#if INCLUDE_JFR\n+\n+static void jfr_prologue(address the_pc, MacroAssembler* masm) {\n+  Register java_thread = rdi;\n+  __ get_thread(java_thread);\n+  __ set_last_Java_frame(java_thread, rsp, rbp, the_pc, noreg);\n+  __ movptr(Address(rsp, 0), java_thread);\n+}\n+\n+\/\/ The handle is dereferenced through a load barrier.\n+static void jfr_epilogue(MacroAssembler* masm) {\n+  Register java_thread = rdi;\n+  __ get_thread(java_thread);\n+  __ reset_last_Java_frame(java_thread, true);\n+}\n+\n+\/\/ For c2: c_rarg0 is junk, call to runtime to write a checkpoint.\n+\/\/ It returns a jobject handle to the event writer.\n+\/\/ The handle is dereferenced and the return value is the event writer oop.\n+RuntimeStub* SharedRuntime::generate_jfr_write_checkpoint() {\n+  enum layout {\n+    FPUState_off         = 0,\n+    rbp_off              = FPUStateSizeInWords,\n+    rdi_off,\n+    rsi_off,\n+    rcx_off,\n+    rbx_off,\n+    saved_argument_off,\n+    saved_argument_off2, \/\/ 2nd half of double\n+    framesize\n+  };\n+\n+  int insts_size = 1024;\n+  int locs_size = 64;\n+  CodeBuffer code(\"jfr_write_checkpoint\", insts_size, locs_size);\n+  OopMapSet* oop_maps = new OopMapSet();\n+  MacroAssembler* masm = new MacroAssembler(&code);\n+\n+  address start = __ pc();\n+  __ enter();\n+  int frame_complete = __ pc() - start;\n+  address the_pc = __ pc();\n+  jfr_prologue(the_pc, masm);\n+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, JfrIntrinsicSupport::write_checkpoint), 1);\n+  jfr_epilogue(masm);\n+  __ resolve_global_jobject(rax, rdi, rdx);\n+  __ leave();\n+  __ ret(0);\n+\n+  OopMap* map = new OopMap(framesize, 1); \/\/ rbp\n+  oop_maps->add_gc_map(the_pc - start, map);\n+\n+  RuntimeStub* stub = \/\/ codeBlob framesize is in words (not VMRegImpl::slot_size)\n+    RuntimeStub::new_runtime_stub(\"jfr_write_checkpoint\", &code, frame_complete,\n+                                  (framesize >> (LogBytesPerWord - LogBytesPerInt)),\n+                                  oop_maps, false);\n+  return stub;\n+}\n+\n+\/\/ For c2: call to return a leased buffer.\n+RuntimeStub* SharedRuntime::generate_jfr_return_lease() {\n+  enum layout {\n+    FPUState_off = 0,\n+    rbp_off = FPUStateSizeInWords,\n+    rdi_off,\n+    rsi_off,\n+    rcx_off,\n+    rbx_off,\n+    saved_argument_off,\n+    saved_argument_off2, \/\/ 2nd half of double\n+    framesize\n+  };\n+\n+  int insts_size = 1024;\n+  int locs_size = 64;\n+  CodeBuffer code(\"jfr_return_lease\", insts_size, locs_size);\n+  OopMapSet* oop_maps = new OopMapSet();\n+  MacroAssembler* masm = new MacroAssembler(&code);\n+\n+  address start = __ pc();\n+  __ enter();\n+  int frame_complete = __ pc() - start;\n+  address the_pc = __ pc();\n+  jfr_prologue(the_pc, masm);\n+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, JfrIntrinsicSupport::return_lease), 1);\n+  jfr_epilogue(masm);\n+  __ leave();\n+  __ ret(0);\n+\n+  OopMap* map = new OopMap(framesize, 1); \/\/ rbp\n+  oop_maps->add_gc_map(the_pc - start, map);\n+\n+  RuntimeStub* stub = \/\/ codeBlob framesize is in words (not VMRegImpl::slot_size)\n+    RuntimeStub::new_runtime_stub(\"jfr_return_lease\", &code, frame_complete,\n+                                  (framesize >> (LogBytesPerWord - LogBytesPerInt)),\n+                                  oop_maps, false);\n+  return stub;\n+}\n+\n+#endif \/\/ INCLUDE_JFR\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":215,"deletions":180,"binary":false,"changes":395,"status":"modified"},{"patch":"@@ -56,0 +56,1 @@\n+#include \"runtime\/timerTrace.hpp\"\n@@ -74,5 +75,5 @@\n-const int StackAlignmentInSlots = StackAlignmentInBytes \/ VMRegImpl::stack_slot_size;\n-\n-class SimpleRuntimeFrame {\n-\n-  public:\n+#ifdef PRODUCT\n+#define BLOCK_COMMENT(str) \/* nothing *\/\n+#else\n+#define BLOCK_COMMENT(str) __ block_comment(str)\n+#endif \/\/ PRODUCT\n@@ -80,13 +81,1 @@\n-  \/\/ Most of the runtime stubs have this simple frame layout.\n-  \/\/ This class exists to make the layout shared in one place.\n-  \/\/ Offsets are for compiler stack slots, which are jints.\n-  enum layout {\n-    \/\/ The frame sender code expects that rbp will be in the \"natural\" place and\n-    \/\/ will override any oopMap setting for it. We must therefore force the layout\n-    \/\/ so that it agrees with the frame sender code.\n-    rbp_off = frame::arg_reg_save_area_bytes\/BytesPerInt,\n-    rbp_off2,\n-    return_off, return_off2,\n-    framesize\n-  };\n-};\n+const int StackAlignmentInSlots = StackAlignmentInBytes \/ VMRegImpl::stack_slot_size;\n@@ -1099,1 +1088,1 @@\n-  __ lea(temp_reg, ExternalAddress(code_start));\n+  __ lea(temp_reg, AddressLiteral(code_start, relocInfo::none));\n@@ -1102,1 +1091,1 @@\n-  __ lea(temp_reg, ExternalAddress(code_end));\n+  __ lea(temp_reg, AddressLiteral(code_end, relocInfo::none));\n@@ -2561,1 +2550,1 @@\n-      __ lightweight_lock(obj_reg, swap_reg, r15_thread, rscratch1, slow_path_lock);\n+      __ lightweight_lock(lock_reg, obj_reg, swap_reg, r15_thread, rscratch1, slow_path_lock);\n@@ -3264,176 +3253,0 @@\n-#ifdef COMPILER2\n-\/\/------------------------------generate_uncommon_trap_blob--------------------\n-void SharedRuntime::generate_uncommon_trap_blob() {\n-  \/\/ Allocate space for the code\n-  ResourceMark rm;\n-  \/\/ Setup code generation tools\n-  CodeBuffer buffer(\"uncommon_trap_blob\", 2048, 1024);\n-  MacroAssembler* masm = new MacroAssembler(&buffer);\n-\n-  assert(SimpleRuntimeFrame::framesize % 4 == 0, \"sp not 16-byte aligned\");\n-\n-  address start = __ pc();\n-\n-  \/\/ Push self-frame.  We get here with a return address on the\n-  \/\/ stack, so rsp is 8-byte aligned until we allocate our frame.\n-  __ subptr(rsp, SimpleRuntimeFrame::return_off << LogBytesPerInt); \/\/ Epilog!\n-\n-  \/\/ No callee saved registers. rbp is assumed implicitly saved\n-  __ movptr(Address(rsp, SimpleRuntimeFrame::rbp_off << LogBytesPerInt), rbp);\n-\n-  \/\/ compiler left unloaded_class_index in j_rarg0 move to where the\n-  \/\/ runtime expects it.\n-  __ movl(c_rarg1, j_rarg0);\n-\n-  __ set_last_Java_frame(noreg, noreg, nullptr, rscratch1);\n-\n-  \/\/ Call C code.  Need thread but NOT official VM entry\n-  \/\/ crud.  We cannot block on this call, no GC can happen.  Call should\n-  \/\/ capture callee-saved registers as well as return values.\n-  \/\/ Thread is in rdi already.\n-  \/\/\n-  \/\/ UnrollBlock* uncommon_trap(JavaThread* thread, jint unloaded_class_index);\n-\n-  __ mov(c_rarg0, r15_thread);\n-  __ movl(c_rarg2, Deoptimization::Unpack_uncommon_trap);\n-  __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, Deoptimization::uncommon_trap)));\n-\n-  \/\/ Set an oopmap for the call site\n-  OopMapSet* oop_maps = new OopMapSet();\n-  OopMap* map = new OopMap(SimpleRuntimeFrame::framesize, 0);\n-\n-  \/\/ location of rbp is known implicitly by the frame sender code\n-\n-  oop_maps->add_gc_map(__ pc() - start, map);\n-\n-  __ reset_last_Java_frame(false);\n-\n-  \/\/ Load UnrollBlock* into rdi\n-  __ mov(rdi, rax);\n-\n-#ifdef ASSERT\n-  { Label L;\n-    __ cmpptr(Address(rdi, Deoptimization::UnrollBlock::unpack_kind_offset()),\n-              Deoptimization::Unpack_uncommon_trap);\n-    __ jcc(Assembler::equal, L);\n-    __ stop(\"SharedRuntime::generate_uncommon_trap_blob: expected Unpack_uncommon_trap\");\n-    __ bind(L);\n-  }\n-#endif\n-\n-  \/\/ Pop all the frames we must move\/replace.\n-  \/\/\n-  \/\/ Frame picture (youngest to oldest)\n-  \/\/ 1: self-frame (no frame link)\n-  \/\/ 2: deopting frame  (no frame link)\n-  \/\/ 3: caller of deopting frame (could be compiled\/interpreted).\n-\n-  \/\/ Pop self-frame.  We have no frame, and must rely only on rax and rsp.\n-  __ addptr(rsp, (SimpleRuntimeFrame::framesize - 2) << LogBytesPerInt); \/\/ Epilog!\n-\n-  \/\/ Pop deoptimized frame (int)\n-  __ movl(rcx, Address(rdi,\n-                       Deoptimization::UnrollBlock::\n-                       size_of_deoptimized_frame_offset()));\n-  __ addptr(rsp, rcx);\n-\n-  \/\/ rsp should be pointing at the return address to the caller (3)\n-\n-  \/\/ Pick up the initial fp we should save\n-  \/\/ restore rbp before stack bang because if stack overflow is thrown it needs to be pushed (and preserved)\n-  __ movptr(rbp, Address(rdi, Deoptimization::UnrollBlock::initial_info_offset()));\n-\n-#ifdef ASSERT\n-  \/\/ Compilers generate code that bang the stack by as much as the\n-  \/\/ interpreter would need. So this stack banging should never\n-  \/\/ trigger a fault. Verify that it does not on non product builds.\n-  __ movl(rbx, Address(rdi ,Deoptimization::UnrollBlock::total_frame_sizes_offset()));\n-  __ bang_stack_size(rbx, rcx);\n-#endif\n-\n-  \/\/ Load address of array of frame pcs into rcx (address*)\n-  __ movptr(rcx, Address(rdi, Deoptimization::UnrollBlock::frame_pcs_offset()));\n-\n-  \/\/ Trash the return pc\n-  __ addptr(rsp, wordSize);\n-\n-  \/\/ Load address of array of frame sizes into rsi (intptr_t*)\n-  __ movptr(rsi, Address(rdi, Deoptimization::UnrollBlock:: frame_sizes_offset()));\n-\n-  \/\/ Counter\n-  __ movl(rdx, Address(rdi, Deoptimization::UnrollBlock:: number_of_frames_offset())); \/\/ (int)\n-\n-  \/\/ Now adjust the caller's stack to make up for the extra locals but\n-  \/\/ record the original sp so that we can save it in the skeletal\n-  \/\/ interpreter frame and the stack walking of interpreter_sender\n-  \/\/ will get the unextended sp value and not the \"real\" sp value.\n-\n-  const Register sender_sp = r8;\n-\n-  __ mov(sender_sp, rsp);\n-  __ movl(rbx, Address(rdi, Deoptimization::UnrollBlock:: caller_adjustment_offset())); \/\/ (int)\n-  __ subptr(rsp, rbx);\n-\n-  \/\/ Push interpreter frames in a loop\n-  Label loop;\n-  __ bind(loop);\n-  __ movptr(rbx, Address(rsi, 0)); \/\/ Load frame size\n-  __ subptr(rbx, 2 * wordSize);    \/\/ We'll push pc and rbp by hand\n-  __ pushptr(Address(rcx, 0));     \/\/ Save return address\n-  __ enter();                      \/\/ Save old & set new rbp\n-  __ subptr(rsp, rbx);             \/\/ Prolog\n-  __ movptr(Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize),\n-            sender_sp);            \/\/ Make it walkable\n-  \/\/ This value is corrected by layout_activation_impl\n-  __ movptr(Address(rbp, frame::interpreter_frame_last_sp_offset * wordSize), NULL_WORD);\n-  __ mov(sender_sp, rsp);          \/\/ Pass sender_sp to next frame\n-  __ addptr(rsi, wordSize);        \/\/ Bump array pointer (sizes)\n-  __ addptr(rcx, wordSize);        \/\/ Bump array pointer (pcs)\n-  __ decrementl(rdx);              \/\/ Decrement counter\n-  __ jcc(Assembler::notZero, loop);\n-  __ pushptr(Address(rcx, 0));     \/\/ Save final return address\n-\n-  \/\/ Re-push self-frame\n-  __ enter();                 \/\/ Save old & set new rbp\n-  __ subptr(rsp, (SimpleRuntimeFrame::framesize - 4) << LogBytesPerInt);\n-                              \/\/ Prolog\n-\n-  \/\/ Use rbp because the frames look interpreted now\n-  \/\/ Save \"the_pc\" since it cannot easily be retrieved using the last_java_SP after we aligned SP.\n-  \/\/ Don't need the precise return PC here, just precise enough to point into this code blob.\n-  address the_pc = __ pc();\n-  __ set_last_Java_frame(noreg, rbp, the_pc, rscratch1);\n-\n-  \/\/ Call C code.  Need thread but NOT official VM entry\n-  \/\/ crud.  We cannot block on this call, no GC can happen.  Call should\n-  \/\/ restore return values to their stack-slots with the new SP.\n-  \/\/ Thread is in rdi already.\n-  \/\/\n-  \/\/ BasicType unpack_frames(JavaThread* thread, int exec_mode);\n-\n-  __ andptr(rsp, -(StackAlignmentInBytes)); \/\/ Align SP as required by ABI\n-  __ mov(c_rarg0, r15_thread);\n-  __ movl(c_rarg1, Deoptimization::Unpack_uncommon_trap);\n-  __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, Deoptimization::unpack_frames)));\n-\n-  \/\/ Set an oopmap for the call site\n-  \/\/ Use the same PC we used for the last java frame\n-  oop_maps->add_gc_map(the_pc - start, new OopMap(SimpleRuntimeFrame::framesize, 0));\n-\n-  \/\/ Clear fp AND pc\n-  __ reset_last_Java_frame(true);\n-\n-  \/\/ Pop self-frame.\n-  __ leave();                 \/\/ Epilog\n-\n-  \/\/ Jump to interpreter\n-  __ ret(0);\n-\n-  \/\/ Make sure all code is generated\n-  masm->flush();\n-\n-  _uncommon_trap_blob =  UncommonTrapBlob::create(&buffer, oop_maps,\n-                                                 SimpleRuntimeFrame::framesize >> 1);\n-}\n-#endif \/\/ COMPILER2\n-\n@@ -3681,0 +3494,95 @@\n+\/\/ Continuation point for throwing of implicit exceptions that are\n+\/\/ not handled in the current activation. Fabricates an exception\n+\/\/ oop and initiates normal exception dispatching in this\n+\/\/ frame. Since we need to preserve callee-saved values (currently\n+\/\/ only for C2, but done for C1 as well) we need a callee-saved oop\n+\/\/ map and therefore have to make these stubs into RuntimeStubs\n+\/\/ rather than BufferBlobs.  If the compiler needs all registers to\n+\/\/ be preserved between the fault point and the exception handler\n+\/\/ then it must assume responsibility for that in\n+\/\/ AbstractCompiler::continuation_for_implicit_null_exception or\n+\/\/ continuation_for_implicit_division_by_zero_exception. All other\n+\/\/ implicit exceptions (e.g., NullPointerException or\n+\/\/ AbstractMethodError on entry) are either at call sites or\n+\/\/ otherwise assume that stack unwinding will be initiated, so\n+\/\/ caller saved registers were assumed volatile in the compiler.\n+RuntimeStub* SharedRuntime::generate_throw_exception(const char* name, address runtime_entry) {\n+  \/\/ Information about frame layout at time of blocking runtime call.\n+  \/\/ Note that we only have to preserve callee-saved registers since\n+  \/\/ the compilers are responsible for supplying a continuation point\n+  \/\/ if they expect all registers to be preserved.\n+  enum layout {\n+    rbp_off = frame::arg_reg_save_area_bytes\/BytesPerInt,\n+    rbp_off2,\n+    return_off,\n+    return_off2,\n+    framesize \/\/ inclusive of return address\n+  };\n+\n+  int insts_size = 512;\n+  int locs_size  = 64;\n+\n+  ResourceMark rm;\n+  const char* timer_msg = \"SharedRuntime generate_throw_exception\";\n+  TraceTime timer(timer_msg, TRACETIME_LOG(Info, startuptime));\n+\n+  CodeBuffer code(name, insts_size, locs_size);\n+  OopMapSet* oop_maps  = new OopMapSet();\n+  MacroAssembler* masm = new MacroAssembler(&code);\n+\n+  address start = __ pc();\n+\n+  \/\/ This is an inlined and slightly modified version of call_VM\n+  \/\/ which has the ability to fetch the return PC out of\n+  \/\/ thread-local storage and also sets up last_Java_sp slightly\n+  \/\/ differently than the real call_VM\n+\n+  __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n+\n+  assert(is_even(framesize\/2), \"sp not 16-byte aligned\");\n+\n+  \/\/ return address and rbp are already in place\n+  __ subptr(rsp, (framesize-4) << LogBytesPerInt); \/\/ prolog\n+\n+  int frame_complete = __ pc() - start;\n+\n+  \/\/ Set up last_Java_sp and last_Java_fp\n+  address the_pc = __ pc();\n+  __ set_last_Java_frame(rsp, rbp, the_pc, rscratch1);\n+  __ andptr(rsp, -(StackAlignmentInBytes));    \/\/ Align stack\n+\n+  \/\/ Call runtime\n+  __ movptr(c_rarg0, r15_thread);\n+  BLOCK_COMMENT(\"call runtime_entry\");\n+  __ call(RuntimeAddress(runtime_entry));\n+\n+  \/\/ Generate oop map\n+  OopMap* map = new OopMap(framesize, 0);\n+\n+  oop_maps->add_gc_map(the_pc - start, map);\n+\n+  __ reset_last_Java_frame(true);\n+\n+  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+\n+  \/\/ check for pending exceptions\n+#ifdef ASSERT\n+  Label L;\n+  __ cmpptr(Address(r15_thread, Thread::pending_exception_offset()), NULL_WORD);\n+  __ jcc(Assembler::notEqual, L);\n+  __ should_not_reach_here();\n+  __ bind(L);\n+#endif \/\/ ASSERT\n+  __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+\n+\n+  \/\/ codeBlob framesize is in words (not VMRegImpl::slot_size)\n+  RuntimeStub* stub =\n+    RuntimeStub::new_runtime_stub(name,\n+                                  &code,\n+                                  frame_complete,\n+                                  (framesize >> (LogBytesPerWord - LogBytesPerInt)),\n+                                  oop_maps, false);\n+  return stub;\n+}\n+\n@@ -3946,134 +3854,0 @@\n-#ifdef COMPILER2\n-\/\/ This is here instead of runtime_x86_64.cpp because it uses SimpleRuntimeFrame\n-\/\/\n-\/\/------------------------------generate_exception_blob---------------------------\n-\/\/ creates exception blob at the end\n-\/\/ Using exception blob, this code is jumped from a compiled method.\n-\/\/ (see emit_exception_handler in x86_64.ad file)\n-\/\/\n-\/\/ Given an exception pc at a call we call into the runtime for the\n-\/\/ handler in this method. This handler might merely restore state\n-\/\/ (i.e. callee save registers) unwind the frame and jump to the\n-\/\/ exception handler for the nmethod if there is no Java level handler\n-\/\/ for the nmethod.\n-\/\/\n-\/\/ This code is entered with a jmp.\n-\/\/\n-\/\/ Arguments:\n-\/\/   rax: exception oop\n-\/\/   rdx: exception pc\n-\/\/\n-\/\/ Results:\n-\/\/   rax: exception oop\n-\/\/   rdx: exception pc in caller or ???\n-\/\/   destination: exception handler of caller\n-\/\/\n-\/\/ Note: the exception pc MUST be at a call (precise debug information)\n-\/\/       Registers rax, rdx, rcx, rsi, rdi, r8-r11 are not callee saved.\n-\/\/\n-\n-void OptoRuntime::generate_exception_blob() {\n-  assert(!OptoRuntime::is_callee_saved_register(RDX_num), \"\");\n-  assert(!OptoRuntime::is_callee_saved_register(RAX_num), \"\");\n-  assert(!OptoRuntime::is_callee_saved_register(RCX_num), \"\");\n-\n-  assert(SimpleRuntimeFrame::framesize % 4 == 0, \"sp not 16-byte aligned\");\n-\n-  \/\/ Allocate space for the code\n-  ResourceMark rm;\n-  \/\/ Setup code generation tools\n-  CodeBuffer buffer(\"exception_blob\", 2048, 1024);\n-  MacroAssembler* masm = new MacroAssembler(&buffer);\n-\n-\n-  address start = __ pc();\n-\n-  \/\/ Exception pc is 'return address' for stack walker\n-  __ push(rdx);\n-  __ subptr(rsp, SimpleRuntimeFrame::return_off << LogBytesPerInt); \/\/ Prolog\n-\n-  \/\/ Save callee-saved registers.  See x86_64.ad.\n-\n-  \/\/ rbp is an implicitly saved callee saved register (i.e., the calling\n-  \/\/ convention will save\/restore it in the prolog\/epilog). Other than that\n-  \/\/ there are no callee save registers now that adapter frames are gone.\n-\n-  __ movptr(Address(rsp, SimpleRuntimeFrame::rbp_off << LogBytesPerInt), rbp);\n-\n-  \/\/ Store exception in Thread object. We cannot pass any arguments to the\n-  \/\/ handle_exception call, since we do not want to make any assumption\n-  \/\/ about the size of the frame where the exception happened in.\n-  \/\/ c_rarg0 is either rdi (Linux) or rcx (Windows).\n-  __ movptr(Address(r15_thread, JavaThread::exception_oop_offset()),rax);\n-  __ movptr(Address(r15_thread, JavaThread::exception_pc_offset()), rdx);\n-\n-  \/\/ This call does all the hard work.  It checks if an exception handler\n-  \/\/ exists in the method.\n-  \/\/ If so, it returns the handler address.\n-  \/\/ If not, it prepares for stack-unwinding, restoring the callee-save\n-  \/\/ registers of the frame being removed.\n-  \/\/\n-  \/\/ address OptoRuntime::handle_exception_C(JavaThread* thread)\n-\n-  \/\/ At a method handle call, the stack may not be properly aligned\n-  \/\/ when returning with an exception.\n-  address the_pc = __ pc();\n-  __ set_last_Java_frame(noreg, noreg, the_pc, rscratch1);\n-  __ mov(c_rarg0, r15_thread);\n-  __ andptr(rsp, -(StackAlignmentInBytes));    \/\/ Align stack\n-  __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, OptoRuntime::handle_exception_C)));\n-\n-  \/\/ Set an oopmap for the call site.  This oopmap will only be used if we\n-  \/\/ are unwinding the stack.  Hence, all locations will be dead.\n-  \/\/ Callee-saved registers will be the same as the frame above (i.e.,\n-  \/\/ handle_exception_stub), since they were restored when we got the\n-  \/\/ exception.\n-\n-  OopMapSet* oop_maps = new OopMapSet();\n-\n-  oop_maps->add_gc_map(the_pc - start, new OopMap(SimpleRuntimeFrame::framesize, 0));\n-\n-  __ reset_last_Java_frame(false);\n-\n-  \/\/ Restore callee-saved registers\n-\n-  \/\/ rbp is an implicitly saved callee-saved register (i.e., the calling\n-  \/\/ convention will save restore it in prolog\/epilog) Other than that\n-  \/\/ there are no callee save registers now that adapter frames are gone.\n-\n-  __ movptr(rbp, Address(rsp, SimpleRuntimeFrame::rbp_off << LogBytesPerInt));\n-\n-  __ addptr(rsp, SimpleRuntimeFrame::return_off << LogBytesPerInt); \/\/ Epilog\n-  __ pop(rdx);                  \/\/ No need for exception pc anymore\n-\n-  \/\/ rax: exception handler\n-\n-  \/\/ We have a handler in rax (could be deopt blob).\n-  __ mov(r8, rax);\n-\n-  \/\/ Get the exception oop\n-  __ movptr(rax, Address(r15_thread, JavaThread::exception_oop_offset()));\n-  \/\/ Get the exception pc in case we are deoptimized\n-  __ movptr(rdx, Address(r15_thread, JavaThread::exception_pc_offset()));\n-#ifdef ASSERT\n-  __ movptr(Address(r15_thread, JavaThread::exception_handler_pc_offset()), NULL_WORD);\n-  __ movptr(Address(r15_thread, JavaThread::exception_pc_offset()), NULL_WORD);\n-#endif\n-  \/\/ Clear the exception oop so GC no longer processes it as a root.\n-  __ movptr(Address(r15_thread, JavaThread::exception_oop_offset()), NULL_WORD);\n-\n-  \/\/ rax: exception oop\n-  \/\/ r8:  exception handler\n-  \/\/ rdx: exception pc\n-  \/\/ Jump to handler\n-\n-  __ jmp(r8);\n-\n-  \/\/ Make sure all code is generated\n-  masm->flush();\n-\n-  \/\/ Set exception blob\n-  _exception_blob =  ExceptionBlob::create(&buffer, oop_maps, SimpleRuntimeFrame::framesize >> 1);\n-}\n-#endif \/\/ COMPILER2\n-\n@@ -4190,0 +3964,91 @@\n+\n+#if INCLUDE_JFR\n+\n+\/\/ For c2: c_rarg0 is junk, call to runtime to write a checkpoint.\n+\/\/ It returns a jobject handle to the event writer.\n+\/\/ The handle is dereferenced and the return value is the event writer oop.\n+RuntimeStub* SharedRuntime::generate_jfr_write_checkpoint() {\n+  enum layout {\n+    rbp_off,\n+    rbpH_off,\n+    return_off,\n+    return_off2,\n+    framesize \/\/ inclusive of return address\n+  };\n+\n+  CodeBuffer code(\"jfr_write_checkpoint\", 1024, 64);\n+  MacroAssembler* masm = new MacroAssembler(&code);\n+  address start = __ pc();\n+\n+  __ enter();\n+  address the_pc = __ pc();\n+\n+  int frame_complete = the_pc - start;\n+\n+  __ set_last_Java_frame(rsp, rbp, the_pc, rscratch1);\n+  __ movptr(c_rarg0, r15_thread);\n+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, JfrIntrinsicSupport::write_checkpoint), 1);\n+  __ reset_last_Java_frame(true);\n+\n+  \/\/ rax is jobject handle result, unpack and process it through a barrier.\n+  __ resolve_global_jobject(rax, r15_thread, c_rarg0);\n+\n+  __ leave();\n+  __ ret(0);\n+\n+  OopMapSet* oop_maps = new OopMapSet();\n+  OopMap* map = new OopMap(framesize, 1);\n+  oop_maps->add_gc_map(frame_complete, map);\n+\n+  RuntimeStub* stub =\n+    RuntimeStub::new_runtime_stub(code.name(),\n+                                  &code,\n+                                  frame_complete,\n+                                  (framesize >> (LogBytesPerWord - LogBytesPerInt)),\n+                                  oop_maps,\n+                                  false);\n+  return stub;\n+}\n+\n+\/\/ For c2: call to return a leased buffer.\n+RuntimeStub* SharedRuntime::generate_jfr_return_lease() {\n+  enum layout {\n+    rbp_off,\n+    rbpH_off,\n+    return_off,\n+    return_off2,\n+    framesize \/\/ inclusive of return address\n+  };\n+\n+  CodeBuffer code(\"jfr_return_lease\", 1024, 64);\n+  MacroAssembler* masm = new MacroAssembler(&code);\n+  address start = __ pc();\n+\n+  __ enter();\n+  address the_pc = __ pc();\n+\n+  int frame_complete = the_pc - start;\n+\n+  __ set_last_Java_frame(rsp, rbp, the_pc, rscratch2);\n+  __ movptr(c_rarg0, r15_thread);\n+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, JfrIntrinsicSupport::return_lease), 1);\n+  __ reset_last_Java_frame(true);\n+\n+  __ leave();\n+  __ ret(0);\n+\n+  OopMapSet* oop_maps = new OopMapSet();\n+  OopMap* map = new OopMap(framesize, 1);\n+  oop_maps->add_gc_map(frame_complete, map);\n+\n+  RuntimeStub* stub =\n+    RuntimeStub::new_runtime_stub(code.name(),\n+                                  &code,\n+                                  frame_complete,\n+                                  (framesize >> (LogBytesPerWord - LogBytesPerInt)),\n+                                  oop_maps,\n+                                  false);\n+  return stub;\n+}\n+\n+#endif \/\/ INCLUDE_JFR\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":196,"deletions":331,"binary":false,"changes":527,"status":"modified"},{"patch":"@@ -51,3 +51,0 @@\n-#if INCLUDE_JFR\n-#include \"jfr\/support\/jfrIntrinsics.hpp\"\n-#endif\n@@ -3721,1 +3718,1 @@\n-  __ jump(ExternalAddress(StubRoutines::throw_StackOverflowError_entry()));\n+  __ jump(RuntimeAddress(SharedRuntime::throw_StackOverflowError_entry()));\n@@ -3797,192 +3794,0 @@\n-#if INCLUDE_JFR\n-\n-\/\/ For c2: c_rarg0 is junk, call to runtime to write a checkpoint.\n-\/\/ It returns a jobject handle to the event writer.\n-\/\/ The handle is dereferenced and the return value is the event writer oop.\n-RuntimeStub* StubGenerator::generate_jfr_write_checkpoint() {\n-  enum layout {\n-    rbp_off,\n-    rbpH_off,\n-    return_off,\n-    return_off2,\n-    framesize \/\/ inclusive of return address\n-  };\n-\n-  CodeBuffer code(\"jfr_write_checkpoint\", 1024, 64);\n-  MacroAssembler* _masm = new MacroAssembler(&code);\n-  address start = __ pc();\n-\n-  __ enter();\n-  address the_pc = __ pc();\n-\n-  int frame_complete = the_pc - start;\n-\n-  __ set_last_Java_frame(rsp, rbp, the_pc, rscratch1);\n-  __ movptr(c_rarg0, r15_thread);\n-  __ call_VM_leaf(CAST_FROM_FN_PTR(address, JfrIntrinsicSupport::write_checkpoint), 1);\n-  __ reset_last_Java_frame(true);\n-\n-  \/\/ rax is jobject handle result, unpack and process it through a barrier.\n-  __ resolve_global_jobject(rax, r15_thread, c_rarg0);\n-\n-  __ leave();\n-  __ ret(0);\n-\n-  OopMapSet* oop_maps = new OopMapSet();\n-  OopMap* map = new OopMap(framesize, 1);\n-  oop_maps->add_gc_map(frame_complete, map);\n-\n-  RuntimeStub* stub =\n-    RuntimeStub::new_runtime_stub(code.name(),\n-                                  &code,\n-                                  frame_complete,\n-                                  (framesize >> (LogBytesPerWord - LogBytesPerInt)),\n-                                  oop_maps,\n-                                  false);\n-  return stub;\n-}\n-\n-\/\/ For c2: call to return a leased buffer.\n-RuntimeStub* StubGenerator::generate_jfr_return_lease() {\n-  enum layout {\n-    rbp_off,\n-    rbpH_off,\n-    return_off,\n-    return_off2,\n-    framesize \/\/ inclusive of return address\n-  };\n-\n-  CodeBuffer code(\"jfr_return_lease\", 1024, 64);\n-  MacroAssembler* _masm = new MacroAssembler(&code);\n-  address start = __ pc();\n-\n-  __ enter();\n-  address the_pc = __ pc();\n-\n-  int frame_complete = the_pc - start;\n-\n-  __ set_last_Java_frame(rsp, rbp, the_pc, rscratch2);\n-  __ movptr(c_rarg0, r15_thread);\n-  __ call_VM_leaf(CAST_FROM_FN_PTR(address, JfrIntrinsicSupport::return_lease), 1);\n-  __ reset_last_Java_frame(true);\n-\n-  __ leave();\n-  __ ret(0);\n-\n-  OopMapSet* oop_maps = new OopMapSet();\n-  OopMap* map = new OopMap(framesize, 1);\n-  oop_maps->add_gc_map(frame_complete, map);\n-\n-  RuntimeStub* stub =\n-    RuntimeStub::new_runtime_stub(code.name(),\n-                                  &code,\n-                                  frame_complete,\n-                                  (framesize >> (LogBytesPerWord - LogBytesPerInt)),\n-                                  oop_maps,\n-                                  false);\n-  return stub;\n-}\n-\n-#endif \/\/ INCLUDE_JFR\n-\n-\/\/ Continuation point for throwing of implicit exceptions that are\n-\/\/ not handled in the current activation. Fabricates an exception\n-\/\/ oop and initiates normal exception dispatching in this\n-\/\/ frame. Since we need to preserve callee-saved values (currently\n-\/\/ only for C2, but done for C1 as well) we need a callee-saved oop\n-\/\/ map and therefore have to make these stubs into RuntimeStubs\n-\/\/ rather than BufferBlobs.  If the compiler needs all registers to\n-\/\/ be preserved between the fault point and the exception handler\n-\/\/ then it must assume responsibility for that in\n-\/\/ AbstractCompiler::continuation_for_implicit_null_exception or\n-\/\/ continuation_for_implicit_division_by_zero_exception. All other\n-\/\/ implicit exceptions (e.g., NullPointerException or\n-\/\/ AbstractMethodError on entry) are either at call sites or\n-\/\/ otherwise assume that stack unwinding will be initiated, so\n-\/\/ caller saved registers were assumed volatile in the compiler.\n-address StubGenerator::generate_throw_exception(const char* name,\n-                                                address runtime_entry,\n-                                                Register arg1,\n-                                                Register arg2) {\n-  \/\/ Information about frame layout at time of blocking runtime call.\n-  \/\/ Note that we only have to preserve callee-saved registers since\n-  \/\/ the compilers are responsible for supplying a continuation point\n-  \/\/ if they expect all registers to be preserved.\n-  enum layout {\n-    rbp_off = frame::arg_reg_save_area_bytes\/BytesPerInt,\n-    rbp_off2,\n-    return_off,\n-    return_off2,\n-    framesize \/\/ inclusive of return address\n-  };\n-\n-  int insts_size = 512;\n-  int locs_size  = 64;\n-\n-  CodeBuffer code(name, insts_size, locs_size);\n-  OopMapSet* oop_maps  = new OopMapSet();\n-  MacroAssembler* _masm = new MacroAssembler(&code);\n-\n-  address start = __ pc();\n-\n-  \/\/ This is an inlined and slightly modified version of call_VM\n-  \/\/ which has the ability to fetch the return PC out of\n-  \/\/ thread-local storage and also sets up last_Java_sp slightly\n-  \/\/ differently than the real call_VM\n-\n-  __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-\n-  assert(is_even(framesize\/2), \"sp not 16-byte aligned\");\n-\n-  \/\/ return address and rbp are already in place\n-  __ subptr(rsp, (framesize-4) << LogBytesPerInt); \/\/ prolog\n-\n-  int frame_complete = __ pc() - start;\n-\n-  \/\/ Set up last_Java_sp and last_Java_fp\n-  address the_pc = __ pc();\n-  __ set_last_Java_frame(rsp, rbp, the_pc, rscratch1);\n-  __ andptr(rsp, -(StackAlignmentInBytes));    \/\/ Align stack\n-\n-  \/\/ Call runtime\n-  if (arg1 != noreg) {\n-    assert(arg2 != c_rarg1, \"clobbered\");\n-    __ movptr(c_rarg1, arg1);\n-  }\n-  if (arg2 != noreg) {\n-    __ movptr(c_rarg2, arg2);\n-  }\n-  __ movptr(c_rarg0, r15_thread);\n-  BLOCK_COMMENT(\"call runtime_entry\");\n-  __ call(RuntimeAddress(runtime_entry));\n-\n-  \/\/ Generate oop map\n-  OopMap* map = new OopMap(framesize, 0);\n-\n-  oop_maps->add_gc_map(the_pc - start, map);\n-\n-  __ reset_last_Java_frame(true);\n-\n-  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-\n-  \/\/ check for pending exceptions\n-#ifdef ASSERT\n-  Label L;\n-  __ cmpptr(Address(r15_thread, Thread::pending_exception_offset()), NULL_WORD);\n-  __ jcc(Assembler::notEqual, L);\n-  __ should_not_reach_here();\n-  __ bind(L);\n-#endif \/\/ ASSERT\n-  __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n-\n-\n-  \/\/ codeBlob framesize is in words (not VMRegImpl::slot_size)\n-  RuntimeStub* stub =\n-    RuntimeStub::new_runtime_stub(name,\n-                                  &code,\n-                                  frame_complete,\n-                                  (framesize >> (LogBytesPerWord - LogBytesPerInt)),\n-                                  oop_maps, false);\n-  return stub->entry_point();\n-}\n-\n@@ -4116,11 +3921,0 @@\n-  \/\/ Build this early so it's available for the interpreter.\n-  StubRoutines::_throw_StackOverflowError_entry =\n-    generate_throw_exception(\"StackOverflowError throw_exception\",\n-                             CAST_FROM_FN_PTR(address,\n-                                              SharedRuntime::\n-                                              throw_StackOverflowError));\n-  StubRoutines::_throw_delayed_StackOverflowError_entry =\n-    generate_throw_exception(\"delayed StackOverflowError throw_exception\",\n-                             CAST_FROM_FN_PTR(address,\n-                                              SharedRuntime::\n-                                              throw_delayed_StackOverflowError));\n@@ -4304,2 +4098,0 @@\n-\n-  JFR_ONLY(generate_jfr_stubs();)\n@@ -4308,9 +4100,0 @@\n-#if INCLUDE_JFR\n-void StubGenerator::generate_jfr_stubs() {\n-  StubRoutines::_jfr_write_checkpoint_stub = generate_jfr_write_checkpoint();\n-  StubRoutines::_jfr_write_checkpoint = StubRoutines::_jfr_write_checkpoint_stub->entry_point();\n-  StubRoutines::_jfr_return_lease_stub = generate_jfr_return_lease();\n-  StubRoutines::_jfr_return_lease = StubRoutines::_jfr_return_lease_stub->entry_point();\n-}\n-#endif\n-\n@@ -4320,21 +4103,0 @@\n-  \/\/ These entry points require SharedInfo::stack0 to be set up in\n-  \/\/ non-core builds and need to be relocatable, so they each\n-  \/\/ fabricate a RuntimeStub internally.\n-  StubRoutines::_throw_AbstractMethodError_entry =\n-    generate_throw_exception(\"AbstractMethodError throw_exception\",\n-                             CAST_FROM_FN_PTR(address,\n-                                              SharedRuntime::\n-                                              throw_AbstractMethodError));\n-\n-  StubRoutines::_throw_IncompatibleClassChangeError_entry =\n-    generate_throw_exception(\"IncompatibleClassChangeError throw_exception\",\n-                             CAST_FROM_FN_PTR(address,\n-                                              SharedRuntime::\n-                                              throw_IncompatibleClassChangeError));\n-\n-  StubRoutines::_throw_NullPointerException_at_call_entry =\n-    generate_throw_exception(\"NullPointerException at call throw_exception\",\n-                             CAST_FROM_FN_PTR(address,\n-                                              SharedRuntime::\n-                                              throw_NullPointerException_at_call));\n-\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":1,"deletions":239,"binary":false,"changes":240,"status":"modified"},{"patch":"@@ -589,10 +589,0 @@\n-#if INCLUDE_JFR\n-  void generate_jfr_stubs();\n-  \/\/ For c2: c_rarg0 is junk, call to runtime to write a checkpoint.\n-  \/\/ It returns a jobject handle to the event writer.\n-  \/\/ The handle is dereferenced and the return value is the event writer oop.\n-  RuntimeStub* generate_jfr_write_checkpoint();\n-  \/\/ For c2: call to runtime to return a buffer lease.\n-  RuntimeStub* generate_jfr_return_lease();\n-#endif \/\/ INCLUDE_JFR\n-\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.hpp","additions":0,"deletions":10,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -218,1 +218,1 @@\n-    ExternalAddress no_overlap(no_overlap_target);\n+    RuntimeAddress no_overlap(no_overlap_target);\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64_arraycopy.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -182,1 +182,1 @@\n-  __ jump(ExternalAddress(Interpreter::throw_exception_entry()));\n+  __ jump(RuntimeAddress(Interpreter::throw_exception_entry()));\n@@ -553,2 +553,2 @@\n-  assert(StubRoutines::throw_StackOverflowError_entry() != nullptr, \"stub not yet generated\");\n-  __ jump(ExternalAddress(StubRoutines::throw_StackOverflowError_entry()));\n+  assert(SharedRuntime::throw_StackOverflowError_entry() != nullptr, \"stub not yet generated\");\n+  __ jump(RuntimeAddress(SharedRuntime::throw_StackOverflowError_entry()));\n","filename":"src\/hotspot\/cpu\/x86\/templateInterpreterGenerator_x86.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -779,1 +779,1 @@\n-  __ jump(ExternalAddress(Interpreter::_throw_ArrayIndexOutOfBoundsException_entry));\n+  __ jump(RuntimeAddress(Interpreter::_throw_ArrayIndexOutOfBoundsException_entry));\n@@ -1186,1 +1186,1 @@\n-  __ jump(ExternalAddress(Interpreter::_throw_ArrayStoreException_entry));\n+  __ jump(RuntimeAddress(Interpreter::_throw_ArrayStoreException_entry));\n@@ -1208,1 +1208,1 @@\n-    __ jump(ExternalAddress(Interpreter::_throw_NullPointerException_entry));\n+    __ jump(RuntimeAddress(Interpreter::_throw_NullPointerException_entry));\n@@ -1231,1 +1231,1 @@\n-    __ jump(ExternalAddress(Interpreter::_throw_ArrayStoreException_entry));\n+    __ jump(RuntimeAddress(Interpreter::_throw_ArrayStoreException_entry));\n@@ -1510,1 +1510,1 @@\n-             ExternalAddress(Interpreter::_throw_ArithmeticException_entry));\n+             RuntimeAddress(Interpreter::_throw_ArithmeticException_entry));\n@@ -1523,1 +1523,1 @@\n-             ExternalAddress(Interpreter::_throw_ArithmeticException_entry));\n+             RuntimeAddress(Interpreter::_throw_ArithmeticException_entry));\n@@ -1536,1 +1536,1 @@\n-             ExternalAddress(Interpreter::_throw_ArithmeticException_entry));\n+             RuntimeAddress(Interpreter::_throw_ArithmeticException_entry));\n@@ -1550,1 +1550,1 @@\n-             ExternalAddress(Interpreter::_throw_ArithmeticException_entry));\n+             RuntimeAddress(Interpreter::_throw_ArithmeticException_entry));\n@@ -4475,1 +4475,1 @@\n-  __ jump(ExternalAddress(Interpreter::_throw_ClassCastException_entry));\n+  __ jump(RuntimeAddress(Interpreter::_throw_ClassCastException_entry));\n@@ -4592,1 +4592,1 @@\n-  __ jump(ExternalAddress(Interpreter::throw_exception_entry()));\n+  __ jump(RuntimeAddress(Interpreter::throw_exception_entry()));\n","filename":"src\/hotspot\/cpu\/x86\/templateTable_x86.cpp","additions":11,"deletions":11,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -56,1 +56,1 @@\n-address VM_Version::_cpuinfo_segv_addr = 0;\n+address VM_Version::_cpuinfo_segv_addr = nullptr;\n@@ -58,1 +58,1 @@\n-address VM_Version::_cpuinfo_cont_addr = 0;\n+address VM_Version::_cpuinfo_cont_addr = nullptr;\n@@ -60,1 +60,1 @@\n-address VM_Version::_cpuinfo_segv_addr_apx = 0;\n+address VM_Version::_cpuinfo_segv_addr_apx = nullptr;\n@@ -62,1 +62,1 @@\n-address VM_Version::_cpuinfo_cont_addr_apx = 0;\n+address VM_Version::_cpuinfo_cont_addr_apx = nullptr;\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -5145,1 +5145,1 @@\n-  predicate(Matcher::vector_length(n->in(2)) <= 4); \/\/ src\n+  predicate(n->as_Reduction()->requires_strict_order() && Matcher::vector_length(n->in(2)) <= 4); \/\/ src\n@@ -5159,1 +5159,1 @@\n-  predicate(Matcher::vector_length(n->in(2)) == 8); \/\/ src\n+  predicate(n->as_Reduction()->requires_strict_order() && Matcher::vector_length(n->in(2)) == 8); \/\/ src\n@@ -5173,1 +5173,1 @@\n-  predicate(Matcher::vector_length(n->in(2)) == 16); \/\/ src\n+  predicate(n->as_Reduction()->requires_strict_order() && Matcher::vector_length(n->in(2)) == 16); \/\/ src\n@@ -5186,0 +5186,69 @@\n+\n+instruct unordered_reduction2F(regF dst, regF src1, vec src2) %{\n+  \/\/ Non-strictly ordered floating-point add\/mul reduction for floats. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add\/mul reduction).\n+  \/\/ src1 contains reduction identity\n+  predicate(!n->as_Reduction()->requires_strict_order() && Matcher::vector_length(n->in(2)) == 2); \/\/ src2\n+  match(Set dst (AddReductionVF src1 src2));\n+  match(Set dst (MulReductionVF src1 src2));\n+  effect(TEMP dst);\n+  format %{ \"vector_reduction_float  $dst,$src1,$src2 ;\" %}\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n+    int vlen = Matcher::vector_length(this, $src2);\n+    __ unordered_reduce_fp(opcode, vlen, $dst$$XMMRegister, $src2$$XMMRegister);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct unordered_reduction4F(regF dst, regF src1, vec src2, vec vtmp) %{\n+  \/\/ Non-strictly ordered floating-point add\/mul reduction for floats. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add\/mul reduction).\n+  \/\/ src1 contains reduction identity\n+  predicate(!n->as_Reduction()->requires_strict_order() && Matcher::vector_length(n->in(2)) == 4); \/\/ src2\n+  match(Set dst (AddReductionVF src1 src2));\n+  match(Set dst (MulReductionVF src1 src2));\n+  effect(TEMP dst, TEMP vtmp);\n+  format %{ \"vector_reduction_float  $dst,$src1,$src2 ; using $vtmp as TEMP\" %}\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n+    int vlen = Matcher::vector_length(this, $src2);\n+    __ unordered_reduce_fp(opcode, vlen, $dst$$XMMRegister, $src2$$XMMRegister, $vtmp$$XMMRegister);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct unordered_reduction8F(regF dst, regF src1, vec src2, vec vtmp1, vec vtmp2) %{\n+  \/\/ Non-strictly ordered floating-point add\/mul reduction for floats. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add\/mul reduction).\n+  \/\/ src1 contains reduction identity\n+  predicate(!n->as_Reduction()->requires_strict_order() && Matcher::vector_length(n->in(2)) == 8); \/\/ src2\n+  match(Set dst (AddReductionVF src1 src2));\n+  match(Set dst (MulReductionVF src1 src2));\n+  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2);\n+  format %{ \"vector_reduction_float $dst,$src1,$src2 ; using $vtmp1, $vtmp2 as TEMP\" %}\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n+    int vlen = Matcher::vector_length(this, $src2);\n+    __ unordered_reduce_fp(opcode, vlen, $dst$$XMMRegister, $src2$$XMMRegister, $vtmp1$$XMMRegister, $vtmp2$$XMMRegister);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct unordered_reduction16F(regF dst, regF src1, legVec src2, legVec vtmp1, legVec vtmp2) %{\n+  \/\/ Non-strictly ordered floating-point add\/mul reduction for floats. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add\/mul reduction).\n+  \/\/ src1 contains reduction identity\n+  predicate(!n->as_Reduction()->requires_strict_order() && Matcher::vector_length(n->in(2)) == 16); \/\/ src2\n+  match(Set dst (AddReductionVF src1 src2));\n+  match(Set dst (MulReductionVF src1 src2));\n+  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2);\n+  format %{ \"vector_reduction_float $dst,$src1,$src2 ; using $vtmp1, $vtmp2 as TEMP\" %}\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n+    int vlen = Matcher::vector_length(this, $src2);\n+    __ unordered_reduce_fp(opcode, vlen, $dst$$XMMRegister, $src2$$XMMRegister, $vtmp1$$XMMRegister, $vtmp2$$XMMRegister);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -5189,1 +5258,1 @@\n-  predicate(Matcher::vector_length(n->in(2)) == 2); \/\/ src\n+  predicate(n->as_Reduction()->requires_strict_order() && Matcher::vector_length(n->in(2)) == 2); \/\/ src\n@@ -5203,1 +5272,1 @@\n-  predicate(Matcher::vector_length(n->in(2)) == 4); \/\/ src\n+  predicate(n->as_Reduction()->requires_strict_order() && Matcher::vector_length(n->in(2)) == 4); \/\/ src\n@@ -5217,1 +5286,1 @@\n-  predicate(Matcher::vector_length(n->in(2)) == 8); \/\/ src\n+  predicate(n->as_Reduction()->requires_strict_order() && Matcher::vector_length(n->in(2)) == 8); \/\/ src\n@@ -5230,0 +5299,51 @@\n+instruct unordered_reduction2D(regD dst, regD src1, vec src2) %{\n+  \/\/ Non-strictly ordered floating-point add\/mul reduction for doubles. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add\/mul reduction).\n+  \/\/ src1 contains reduction identity\n+  predicate(!n->as_Reduction()->requires_strict_order() && Matcher::vector_length(n->in(2)) == 2); \/\/ src2\n+  match(Set dst (AddReductionVD src1 src2));\n+  match(Set dst (MulReductionVD src1 src2));\n+  effect(TEMP dst);\n+  format %{ \"vector_reduction_double $dst,$src1,$src2 ;\" %}\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n+    int vlen = Matcher::vector_length(this, $src2);\n+    __ unordered_reduce_fp(opcode, vlen, $dst$$XMMRegister, $src2$$XMMRegister);\n+%}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct unordered_reduction4D(regD dst, regD src1, vec src2, vec vtmp) %{\n+  \/\/ Non-strictly ordered floating-point add\/mul reduction for doubles. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add\/mul reduction).\n+  \/\/ src1 contains reduction identity\n+  predicate(!n->as_Reduction()->requires_strict_order() && Matcher::vector_length(n->in(2)) == 4); \/\/ src2\n+  match(Set dst (AddReductionVD src1 src2));\n+  match(Set dst (MulReductionVD src1 src2));\n+  effect(TEMP dst, TEMP vtmp);\n+  format %{ \"vector_reduction_double $dst,$src1,$src2 ; using $vtmp as TEMP\" %}\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n+    int vlen = Matcher::vector_length(this, $src2);\n+    __ unordered_reduce_fp(opcode, vlen, $dst$$XMMRegister, $src2$$XMMRegister, $vtmp$$XMMRegister);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct unordered_reduction8D(regD dst, regD src1, legVec src2, legVec vtmp1, legVec vtmp2) %{\n+  \/\/ Non-strictly ordered floating-point add\/mul reduction for doubles. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add\/mul reduction).\n+  \/\/ src1 contains reduction identity\n+  predicate(!n->as_Reduction()->requires_strict_order() && Matcher::vector_length(n->in(2)) == 8); \/\/ src2\n+  match(Set dst (AddReductionVD src1 src2));\n+  match(Set dst (MulReductionVD src1 src2));\n+  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2);\n+  format %{ \"vector_reduction_double $dst,$src1,$src2 ; using $vtmp1, $vtmp2 as TEMP\" %}\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n+    int vlen = Matcher::vector_length(this, $src2);\n+    __ unordered_reduce_fp(opcode, vlen, $dst$$XMMRegister, $src2$$XMMRegister, $vtmp1$$XMMRegister, $vtmp2$$XMMRegister);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":126,"deletions":6,"binary":false,"changes":132,"status":"modified"},{"patch":"@@ -13583,0 +13583,12 @@\n+\/\/ Forward exception.\n+instruct ForwardExceptionjmp()\n+%{\n+  match(ForwardException);\n+\n+  format %{ \"JMP    forward_exception_stub\" %}\n+  ins_encode %{\n+    __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()), noreg);\n+  %}\n+  ins_pipe(pipe_jmp);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -12862,0 +12862,12 @@\n+\/\/ Forward exception.\n+instruct ForwardExceptionjmp()\n+%{\n+  match(ForwardException);\n+\n+  format %{ \"jmp     forward_exception_stub\" %}\n+  ins_encode %{\n+    __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()), noreg);\n+  %}\n+  ins_pipe(pipe_jmp);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -115,1 +115,1 @@\n-static RuntimeStub* generate_empty_runtime_stub(const char* name) {\n+static RuntimeStub* generate_empty_runtime_stub() {\n@@ -127,1 +127,0 @@\n-\n@@ -137,1 +136,5 @@\n-  return generate_empty_runtime_stub(\"resolve_blob\");\n+  return generate_empty_runtime_stub();\n+}\n+\n+RuntimeStub* SharedRuntime::generate_throw_exception(const char* name, address runtime_entry) {\n+  return generate_empty_runtime_stub();\n@@ -153,0 +156,12 @@\n+\n+#if INCLUDE_JFR\n+RuntimeStub* SharedRuntime::generate_jfr_write_checkpoint() {\n+  return nullptr;\n+}\n+\n+RuntimeStub* SharedRuntime::generate_jfr_return_lease() {\n+  return nullptr;\n+}\n+\n+#endif \/\/ INCLUDE_JFR\n+\n","filename":"src\/hotspot\/cpu\/zero\/sharedRuntime_zero.cpp","additions":18,"deletions":3,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -213,9 +213,10 @@\n-  if (_matrule->find_type(\"Goto\",          index)) return true;\n-  if (_matrule->find_type(\"If\",            index)) return true;\n-  if (_matrule->find_type(\"CountedLoopEnd\",index)) return true;\n-  if (_matrule->find_type(\"Return\",        index)) return true;\n-  if (_matrule->find_type(\"Rethrow\",       index)) return true;\n-  if (_matrule->find_type(\"TailCall\",      index)) return true;\n-  if (_matrule->find_type(\"TailJump\",      index)) return true;\n-  if (_matrule->find_type(\"Halt\",          index)) return true;\n-  if (_matrule->find_type(\"Jump\",          index)) return true;\n+  if (_matrule->find_type(\"Goto\",             index)) return true;\n+  if (_matrule->find_type(\"If\",               index)) return true;\n+  if (_matrule->find_type(\"CountedLoopEnd\",   index)) return true;\n+  if (_matrule->find_type(\"Return\",           index)) return true;\n+  if (_matrule->find_type(\"Rethrow\",          index)) return true;\n+  if (_matrule->find_type(\"TailCall\",         index)) return true;\n+  if (_matrule->find_type(\"TailJump\",         index)) return true;\n+  if (_matrule->find_type(\"ForwardException\", index)) return true;\n+  if (_matrule->find_type(\"Halt\",             index)) return true;\n+  if (_matrule->find_type(\"Jump\",             index)) return true;\n@@ -231,6 +232,7 @@\n-  if (_matrule->find_type(\"Goto\",    index)) return true;\n-  if (_matrule->find_type(\"Return\",  index)) return true;\n-  if (_matrule->find_type(\"Rethrow\", index)) return true;\n-  if (_matrule->find_type(\"TailCall\",index)) return true;\n-  if (_matrule->find_type(\"TailJump\",index)) return true;\n-  if (_matrule->find_type(\"Halt\",    index)) return true;\n+  if (_matrule->find_type(\"Goto\",             index)) return true;\n+  if (_matrule->find_type(\"Return\",           index)) return true;\n+  if (_matrule->find_type(\"Rethrow\",          index)) return true;\n+  if (_matrule->find_type(\"TailCall\",         index)) return true;\n+  if (_matrule->find_type(\"TailJump\",         index)) return true;\n+  if (_matrule->find_type(\"ForwardException\", index)) return true;\n+  if (_matrule->find_type(\"Halt\",             index)) return true;\n@@ -379,0 +381,1 @@\n+  if (_matrule->find_type(\"ForwardException\", index)) return true;\n@@ -897,0 +900,1 @@\n+      strcmp(_matrule->_opType,\"ForwardException\")==0 ||\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":19,"deletions":15,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -1667,1 +1667,1 @@\n-       (scope()->wrote_final() ||\n+       (scope()->wrote_final() || scope()->wrote_stable() ||\n@@ -1859,4 +1859,0 @@\n-  if (field->is_final() && code == Bytecodes::_putfield) {\n-    scope()->set_wrote_final();\n-  }\n-\n@@ -1868,0 +1864,6 @@\n+    if (field->is_final()) {\n+      scope()->set_wrote_final();\n+    }\n+    if (field->is_stable()) {\n+      scope()->set_wrote_stable();\n+    }\n","filename":"src\/hotspot\/share\/c1\/c1_GraphBuilder.cpp","additions":7,"deletions":5,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -149,0 +149,1 @@\n+  _wrote_stable       = false;\n","filename":"src\/hotspot\/share\/c1\/c1_IR.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -152,0 +152,1 @@\n+  bool          _wrote_stable;                   \/\/ has written @Stable field\n@@ -190,0 +191,2 @@\n+  void          set_wrote_stable()               { _wrote_stable = true; }\n+  bool          wrote_stable() const             { return _wrote_stable; }\n","filename":"src\/hotspot\/share\/c1\/c1_IR.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -905,2 +905,2 @@\n-  assert(LockingMode == LM_LIGHTWEIGHT || obj == lock->obj(), \"must match\");\n-  SharedRuntime::monitor_enter_helper(obj, LockingMode == LM_LIGHTWEIGHT ? nullptr : lock->lock(), current);\n+  assert(obj == lock->obj(), \"must match\");\n+  SharedRuntime::monitor_enter_helper(obj, lock->lock(), current);\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2100,1 +2100,1 @@\n-        log_info(cds)(\"Cannot use CDS heap data. UseEpsilonGC, UseG1GC, UseSerialGC or UseParallelGC are required.\");\n+        log_info(cds)(\"Cannot use CDS heap data. UseEpsilonGC, UseG1GC, UseSerialGC, UseParallelGC, or UseShenandoahGC are required.\");\n@@ -2253,10 +2253,1 @@\n-  char* base = map_memory(_fd, _full_path, r->file_offset(),\n-                          addr, _mapped_heap_memregion.byte_size(), r->read_only(),\n-                          r->allow_exec());\n-  if (base == nullptr || base != addr) {\n-    dealloc_heap_region();\n-    log_info(cds)(\"UseSharedSpaces: Unable to map at required address in java heap. \"\n-                  INTPTR_FORMAT \", size = \" SIZE_FORMAT \" bytes\",\n-                  p2i(addr), _mapped_heap_memregion.byte_size());\n-    return false;\n-  }\n+  char* base;\n@@ -2264,4 +2255,27 @@\n-  if (VerifySharedSpaces && !r->check_region_crc(base)) {\n-    dealloc_heap_region();\n-    log_info(cds)(\"UseSharedSpaces: mapped heap region is corrupt\");\n-    return false;\n+  if (MetaspaceShared::use_windows_memory_mapping()) {\n+    if (!read_region(MetaspaceShared::hp, addr,\n+                     align_up(_mapped_heap_memregion.byte_size(), os::vm_page_size()),\n+                     \/* do_commit = *\/ true)) {\n+      dealloc_heap_region();\n+      log_error(cds)(\"Failed to read archived heap region into \" INTPTR_FORMAT, p2i(addr));\n+      return false;\n+    }\n+    \/\/ Checks for VerifySharedSpaces is already done inside read_region()\n+    base = addr;\n+  } else {\n+    base = map_memory(_fd, _full_path, r->file_offset(),\n+                      addr, _mapped_heap_memregion.byte_size(), r->read_only(),\n+                      r->allow_exec());\n+    if (base == nullptr || base != addr) {\n+      dealloc_heap_region();\n+      log_info(cds)(\"UseSharedSpaces: Unable to map at required address in java heap. \"\n+                    INTPTR_FORMAT \", size = \" SIZE_FORMAT \" bytes\",\n+                    p2i(addr), _mapped_heap_memregion.byte_size());\n+      return false;\n+    }\n+\n+    if (VerifySharedSpaces && !r->check_region_crc(base)) {\n+      dealloc_heap_region();\n+      log_info(cds)(\"UseSharedSpaces: mapped heap region is corrupt\");\n+      return false;\n+    }\n","filename":"src\/hotspot\/share\/cds\/filemap.cpp","additions":29,"deletions":15,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -1557,1 +1557,0 @@\n-  int i;\n","filename":"src\/hotspot\/share\/cds\/heapShared.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -6272,1 +6272,1 @@\n-        \/\/ Call resolve_super so class circularity is checked\n+        \/\/ Call resolve on the interface class name with class circularity checking\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -145,1 +145,1 @@\n-  _keep_alive((has_class_mirror_holder || h_class_loader.is_null()) ? 1 : 0),\n+  _keep_alive_ref_count((has_class_mirror_holder || h_class_loader.is_null()) ? 1 : 0),\n@@ -349,2 +349,2 @@\n-\/\/ it is being defined, therefore _keep_alive is not volatile or atomic.\n-void ClassLoaderData::inc_keep_alive() {\n+\/\/ it is being defined, therefore _keep_alive_ref_count is not volatile or atomic.\n+void ClassLoaderData::inc_keep_alive_ref_count() {\n@@ -352,2 +352,2 @@\n-    assert(_keep_alive > 0, \"Invalid keep alive increment count\");\n-    _keep_alive++;\n+    assert(_keep_alive_ref_count > 0, \"Invalid keep alive increment count\");\n+    _keep_alive_ref_count++;\n@@ -357,1 +357,1 @@\n-void ClassLoaderData::dec_keep_alive() {\n+void ClassLoaderData::dec_keep_alive_ref_count() {\n@@ -359,3 +359,3 @@\n-    assert(_keep_alive > 0, \"Invalid keep alive decrement count\");\n-    if (_keep_alive == 1) {\n-      \/\/ When the keep_alive counter is 1, the oop handle area is a strong root,\n+    assert(_keep_alive_ref_count > 0, \"Invalid keep alive decrement count\");\n+    if (_keep_alive_ref_count == 1) {\n+      \/\/ When the keep_alive_ref_count counter is 1, the oop handle area is a strong root,\n@@ -368,1 +368,1 @@\n-    _keep_alive--;\n+    _keep_alive_ref_count--;\n@@ -696,2 +696,2 @@\n-  bool alive = keep_alive()         \/\/ null class loader and incomplete non-strong hidden class.\n-      || (_holder.peek() != nullptr);  \/\/ and not cleaned by the GC weak handle processing.\n+  bool alive = (_keep_alive_ref_count > 0) \/\/ null class loader and incomplete non-strong hidden class.\n+      || (_holder.peek() != nullptr);      \/\/ and not cleaned by the GC weak handle processing.\n@@ -1029,1 +1029,1 @@\n-  out->print_cr(\" - keep alive          %d\", _keep_alive);\n+  out->print_cr(\" - _keep_alive_ref_count %d\", _keep_alive_ref_count);\n","filename":"src\/hotspot\/share\/classfile\/classLoaderData.cpp","additions":13,"deletions":13,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2012, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -128,4 +128,4 @@\n-  int _keep_alive;         \/\/ if this CLD is kept alive.\n-                           \/\/ Used for non-strong hidden classes and the\n-                           \/\/ boot class loader. _keep_alive does not need to be volatile or\n-                           \/\/ atomic since there is one unique CLD per non-strong hidden class.\n+  int _keep_alive_ref_count; \/\/ if this CLD should not be considered eligible for unloading.\n+                             \/\/ Used for non-strong hidden classes and the\n+                             \/\/ boot class loader. _keep_alive_ref_count does not need to be volatile or\n+                             \/\/ atomic since there is one unique CLD per non-strong hidden class.\n@@ -208,0 +208,1 @@\n+  \/\/ Resolving the holder keeps this CLD alive for the current GC cycle.\n@@ -209,0 +210,1 @@\n+  void keep_alive() const { (void)holder(); }\n@@ -213,1 +215,1 @@\n-  bool keep_alive() const       { return _keep_alive > 0; }\n+  int keep_alive_ref_count() const { return _keep_alive_ref_count; }\n@@ -306,3 +308,4 @@\n-  \/\/ Used to refcount a non-strong hidden class's s CLD in order to indicate their aliveness.\n-  void inc_keep_alive();\n-  void dec_keep_alive();\n+  \/\/ Used to refcount a non-strong hidden class's CLD in order to force its aliveness during\n+  \/\/ loading, when gc tracing may not find this CLD alive through the holder.\n+  void inc_keep_alive_ref_count();\n+  void dec_keep_alive_ref_count();\n@@ -339,2 +342,2 @@\n-  static ByteSize holder_offset()     { return byte_offset_of(ClassLoaderData, _holder); }\n-  static ByteSize keep_alive_offset() { return byte_offset_of(ClassLoaderData, _keep_alive); }\n+  static ByteSize holder_offset() { return byte_offset_of(ClassLoaderData, _holder); }\n+  static ByteSize keep_alive_ref_count_offset() { return byte_offset_of(ClassLoaderData, _keep_alive_ref_count); }\n","filename":"src\/hotspot\/share\/classfile\/classLoaderData.hpp","additions":14,"deletions":11,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -480,1 +480,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_OutOfMemoryError(), \"could not allocate Unicode string\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_OutOfMemoryError(), \"could not allocate Unicode string\");\n@@ -968,1 +968,1 @@\n-        k->class_loader_data()->inc_keep_alive();\n+        k->class_loader_data()->inc_keep_alive_ref_count();\n@@ -1473,6 +1473,0 @@\n-\n-  \/\/ Init lock is a C union with component_mirror.  Only instanceKlass mirrors have\n-  \/\/ init_lock and only ArrayKlass mirrors have component_mirror.  Since both are oops\n-  \/\/ GC treats them the same.\n-  _init_lock_offset = _component_mirror_offset;\n-\n@@ -1485,1 +1479,0 @@\n-  f->do_u4((u4*)&_init_lock_offset);\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":2,"deletions":9,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -212,0 +212,1 @@\n+  macro(java_lang_Class, init_lock,              object_signature,  false)\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -204,1 +204,1 @@\n-                            Symbol* next_klass_name){\n+                                   Symbol* next_klass_name){\n@@ -261,1 +261,2 @@\n-  assert(action != DETECT_CIRCULARITY || next_klass_name != nullptr, \"must have a super class name\");\n+  assert(action != DETECT_CIRCULARITY || next_klass_name != nullptr,\n+         \"must have a class name for the next step in the class resolution recursion\");\n@@ -300,1 +301,1 @@\n-  if (probe->superThreadQ() == nullptr) {\n+  if (probe->circularityThreadQ() == nullptr) {\n@@ -304,1 +305,1 @@\n-  if ((probe->superThreadQ() == nullptr) && (probe->loadInstanceThreadQ() == nullptr)\n+  if ((probe->circularityThreadQ() == nullptr) && (probe->loadInstanceThreadQ() == nullptr)\n@@ -333,2 +334,2 @@\n-  st->print(\"superThreadQ threads:\");\n-  SeenThread::print_action_queue(superThreadQ(), st);\n+  st->print(\"circularityThreadQ threads:\");\n+  SeenThread::print_action_queue(circularityThreadQ(), st);\n","filename":"src\/hotspot\/share\/classfile\/placeholders.cpp","additions":7,"deletions":6,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -85,3 +85,3 @@\n-  SymbolHandle      _next_klass_name;\n-  JavaThread*       _definer;       \/\/ owner of define token\n-  InstanceKlass*    _instanceKlass; \/\/ InstanceKlass from successful define\n+  SymbolHandle      _next_klass_name;     \/\/ next step in the recursive process of class loading\n+  JavaThread*       _definer;             \/\/ owner of define token\n+  InstanceKlass*    _instanceKlass;       \/\/ InstanceKlass from successful define\n@@ -89,3 +89,3 @@\n-  SeenThread*       _loadInstanceThreadQ;  \/\/ loadInstance thread\n-                                    \/\/ This can't be multiple threads since class loading waits for\n-                                    \/\/ this token to be removed.\n+  SeenThread*       _loadInstanceThreadQ; \/\/ loadInstance thread\n+                                          \/\/ This can't be multiple threads since class loading\n+                                          \/\/ waits for this token to be removed.\n@@ -103,2 +103,2 @@\n-  SeenThread*        superThreadQ()        const { return _circularityThreadQ; }\n-  void               set_superThreadQ(SeenThread* SeenThread) { _circularityThreadQ = SeenThread; }\n+  SeenThread*        circularityThreadQ()  const { return _circularityThreadQ; }\n+  void               set_circularityThreadQ(SeenThread* SeenThread) { _circularityThreadQ = SeenThread; }\n@@ -116,1 +116,1 @@\n-  Symbol*            next_klass_name()           const { return _next_klass_name; }\n+  Symbol*            next_klass_name()     const { return _next_klass_name; }\n","filename":"src\/hotspot\/share\/classfile\/placeholders.hpp","additions":10,"deletions":10,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -265,1 +265,1 @@\n-    THROW_MSG_0(exception, \"No class name given\");\n+    THROW_MSG_NULL(exception, \"No class name given\");\n@@ -405,1 +405,1 @@\n-\/\/ resolve_with_circularity_detection_or_fail adds a DETECT_CIRCULARITY placeholder to the placeholder table before calling\n+\/\/ resolve_with_circularity_detection adds a DETECT_CIRCULARITY placeholder to the placeholder table before calling\n@@ -410,6 +410,6 @@\n-InstanceKlass* SystemDictionary::resolve_with_circularity_detection_or_fail(Symbol* class_name,\n-                                                       Symbol* next_name,\n-                                                       Handle class_loader,\n-                                                       Handle protection_domain,\n-                                                       bool is_superclass,\n-                                                       TRAPS) {\n+InstanceKlass* SystemDictionary::resolve_with_circularity_detection(Symbol* class_name,\n+                                                                    Symbol* next_name,\n+                                                                    Handle class_loader,\n+                                                                    Handle protection_domain,\n+                                                                    bool is_superclass,\n+                                                                    TRAPS) {\n@@ -430,1 +430,1 @@\n-  \/\/ If klass is already loaded, just return the superclass or superinterface.\n+  \/\/ If class_name is already loaded, just return the superclass or superinterface.\n@@ -448,4 +448,4 @@\n-        ((quicksuperk = klassk->java_super()) != nullptr) &&\n-         ((quicksuperk->name() == next_name) &&\n-            (quicksuperk->class_loader() == class_loader()))) {\n-           return quicksuperk;\n+       ((quicksuperk = klassk->java_super()) != nullptr) &&\n+       ((quicksuperk->name() == next_name) &&\n+         (quicksuperk->class_loader() == class_loader()))) {\n+      return quicksuperk;\n@@ -462,1 +462,1 @@\n-      \/\/ Be careful not to exit resolve_super without removing this placeholder.\n+      \/\/ Be careful not to exit resolve_with_circularity_detection without removing this placeholder.\n@@ -508,7 +508,9 @@\n-  \/\/ superk is not used; resolve_super_or_fail is called for circularity check only.\n-  Klass* superk = SystemDictionary::resolve_with_circularity_detection_or_fail(name,\n-                                                          superclassname,\n-                                                          class_loader,\n-                                                          protection_domain,\n-                                                          false,\n-                                                          CHECK);\n+  \/\/ The result superk is not used; resolve_with_circularity_detection is called for circularity check only.\n+  \/\/ This passes true to is_superclass even though it might not be the super class in order to perform the\n+  \/\/ optimization anyway.\n+  Klass* superk = SystemDictionary::resolve_with_circularity_detection(name,\n+                                                                       superclassname,\n+                                                                       class_loader,\n+                                                                       protection_domain,\n+                                                                       true,\n+                                                                       CHECK);\n@@ -581,0 +583,1 @@\n+  DEBUG_ONLY(ResourceMark rm(THREAD));\n@@ -1057,2 +1060,2 @@\n-  Klass *found = resolve_with_circularity_detection_or_fail(klass->name(), super_type->name(),\n-                                       class_loader, protection_domain, is_superclass, CHECK_0);\n+  Klass *found = resolve_with_circularity_detection(klass->name(), super_type->name(),\n+                                                    class_loader, protection_domain, is_superclass, CHECK_0);\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":26,"deletions":23,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -106,0 +106,7 @@\n+  static InstanceKlass* resolve_with_circularity_detection(Symbol* class_name,\n+                                                           Symbol* next_name,\n+                                                           Handle class_loader,\n+                                                           Handle protection_domain,\n+                                                           bool is_superclass,\n+                                                           TRAPS);\n+\n@@ -112,3 +119,5 @@\n-                                              Handle protection_domain,\n-                                              bool is_superclass,\n-                                              TRAPS);\n+                                              Handle protection_domain, bool is_superclass, TRAPS) {\n+    return resolve_with_circularity_detection(class_name, super_name, class_loader, protection_domain,\n+                                              is_superclass, THREAD);\n+  }\n+\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.hpp","additions":13,"deletions":4,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+#include \"gc\/shared\/partialArrayState.hpp\"\n@@ -46,0 +47,1 @@\n+#include \"runtime\/mutexLocker.hpp\"\n@@ -64,1 +66,2 @@\n-                                           G1EvacFailureRegions* evac_failure_regions)\n+                                           G1EvacFailureRegions* evac_failure_regions,\n+                                           PartialArrayStateAllocator* pas_allocator)\n@@ -83,2 +86,2 @@\n-    _partial_objarray_chunk_size(ParGCArrayScanChunk),\n-    _partial_array_stepper(num_workers),\n+    _partial_array_state_allocator(pas_allocator),\n+    _partial_array_stepper(num_workers, ParGCArrayScanChunk),\n@@ -172,1 +175,1 @@\n-void G1ParScanThreadState::verify_task(PartialArrayScanTask task) const {\n+void G1ParScanThreadState::verify_task(PartialArrayState* task) const {\n@@ -174,1 +177,1 @@\n-  oop p = task.to_source_array();\n+  oop p = task->source();\n@@ -183,2 +186,2 @@\n-  } else if (task.is_partial_array_task()) {\n-    verify_task(task.to_partial_array_task());\n+  } else if (task.is_partial_array_state()) {\n+    verify_task(task.to_partial_array_state());\n@@ -226,2 +229,2 @@\n-void G1ParScanThreadState::do_partial_array(PartialArrayScanTask task) {\n-  oop from_obj = task.to_source_array();\n+void G1ParScanThreadState::do_partial_array(PartialArrayState* state) {\n+  oop to_obj = state->destination();\n@@ -229,0 +232,2 @@\n+#ifdef ASSERT\n+  oop from_obj = state->source();\n@@ -232,2 +237,0 @@\n-\n-  oop to_obj = from_obj->forwardee();\n@@ -236,0 +239,2 @@\n+#endif \/\/ ASSERT\n+\n@@ -238,6 +243,9 @@\n-  PartialArrayTaskStepper::Step step\n-    = _partial_array_stepper.next(objArrayOop(from_obj),\n-                                  to_array,\n-                                  _partial_objarray_chunk_size);\n-  for (uint i = 0; i < step._ncreate; ++i) {\n-    push_on_queue(ScannerTask(PartialArrayScanTask(from_obj)));\n+  \/\/ Claim a chunk and get number of additional tasks to enqueue.\n+  PartialArrayTaskStepper::Step step = _partial_array_stepper.next(state);\n+  \/\/ Push any additional partial scan tasks needed.  Pushed before processing\n+  \/\/ the claimed chunk to allow other workers to steal while we're processing.\n+  if (step._ncreate > 0) {\n+    state->add_references(step._ncreate);\n+    for (uint i = 0; i < step._ncreate; ++i) {\n+      push_on_queue(ScannerTask(state));\n+    }\n@@ -248,3 +256,1 @@\n-  \/\/ Process claimed task.  The length of to_array is not correct, but\n-  \/\/ fortunately the iteration ignores the length field and just relies\n-  \/\/ on start\/end.\n+  \/\/ Process claimed task.\n@@ -252,2 +258,4 @@\n-                              step._index,\n-                              step._index + _partial_objarray_chunk_size);\n+                              checked_cast<int>(step._index),\n+                              checked_cast<int>(step._index + _partial_array_stepper.chunk_size()));\n+  \/\/ Release reference to the state, now that we're done with it.\n+  _partial_array_state_allocator->release(_worker_id, state);\n@@ -263,1 +271,0 @@\n-  assert(from_obj != to_obj, \"should not be scanning self-forwarded objects\");\n@@ -268,4 +275,2 @@\n-  PartialArrayTaskStepper::Step step\n-    = _partial_array_stepper.start(objArrayOop(from_obj),\n-                                   to_array,\n-                                   _partial_objarray_chunk_size);\n+  size_t array_length = to_array->length();\n+  PartialArrayTaskStepper::Step step = _partial_array_stepper.start(array_length);\n@@ -275,2 +280,15 @@\n-  for (uint i = 0; i < step._ncreate; ++i) {\n-    push_on_queue(ScannerTask(PartialArrayScanTask(from_obj)));\n+  if (step._ncreate > 0) {\n+    assert(step._index < array_length, \"invariant\");\n+    assert(((array_length - step._index) % _partial_array_stepper.chunk_size()) == 0,\n+           \"invariant\");\n+    PartialArrayState* state =\n+      _partial_array_state_allocator->allocate(_worker_id,\n+                                               from_obj, to_obj,\n+                                               step._index,\n+                                               array_length,\n+                                               step._ncreate);\n+    for (uint i = 0; i < step._ncreate; ++i) {\n+      push_on_queue(ScannerTask(state));\n+    }\n+  } else {\n+    assert(step._index == array_length, \"invariant\");\n@@ -287,3 +305,2 @@\n-  \/\/ module. The length of to_array is not correct, but fortunately\n-  \/\/ the iteration ignores that length field and relies on start\/end.\n-  to_array->oop_iterate_range(&_scanner, 0, step._index);\n+  \/\/ module.\n+  to_array->oop_iterate_range(&_scanner, 0, checked_cast<int>(step._index));\n@@ -300,1 +317,1 @@\n-    do_partial_array(task.to_partial_array_task());\n+    do_partial_array(task.to_partial_array_state());\n@@ -586,1 +603,2 @@\n-                               _evac_failure_regions);\n+                               _evac_failure_regions,\n+                               &_partial_array_state_allocator);\n@@ -719,1 +737,3 @@\n-    _evac_failure_regions(evac_failure_regions) {\n+    _evac_failure_regions(evac_failure_regions),\n+    _partial_array_state_allocator(num_workers)\n+{\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":55,"deletions":35,"binary":false,"changes":90,"status":"modified"},{"patch":"@@ -525,1 +525,1 @@\n-void ParallelCompactData::verify_clear(const PSVirtualSpace* vspace)\n+void ParallelCompactData::verify_clear()\n@@ -527,2 +527,2 @@\n-  const size_t* const beg = (const size_t*)vspace->committed_low_addr();\n-  const size_t* const end = (const size_t*)vspace->committed_high_addr();\n+  const size_t* const beg = (const size_t*) _region_vspace->committed_low_addr();\n+  const size_t* const end = (const size_t*) _region_vspace->committed_high_addr();\n@@ -533,5 +533,0 @@\n-\n-void ParallelCompactData::verify_clear()\n-{\n-  verify_clear(_region_vspace);\n-}\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":3,"deletions":8,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -330,1 +330,1 @@\n-    CodeBuffer cb(blob->content_begin(), (address)C->output()->scratch_locs_memory() - blob->content_begin());\n+    CodeBuffer cb(blob->content_begin(), checked_cast<CodeBuffer::csize_t>((address)C->output()->scratch_locs_memory() - blob->content_begin()));\n","filename":"src\/hotspot\/share\/gc\/z\/c2\/zBarrierSetC2.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -455,1 +455,1 @@\n-  assert_is_valid(to_zaddress(src));\n+  check_is_valid_zaddress(src);\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrierSet.inline.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -80,2 +80,2 @@\n-  const size_t base_offset_in_bytes = arrayOopDesc::base_offset_in_bytes(element_type);\n-  const size_t process_start_offset_in_bytes = align_up(base_offset_in_bytes, BytesPerWord);\n+  const size_t base_offset_in_bytes = (size_t)arrayOopDesc::base_offset_in_bytes(element_type);\n+  const size_t process_start_offset_in_bytes = align_up(base_offset_in_bytes, (size_t)BytesPerWord);\n","filename":"src\/hotspot\/share\/gc\/z\/zObjArrayAllocator.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -78,1 +78,1 @@\n-#include \"runtime\/synchronizer.hpp\"\n+#include \"runtime\/synchronizer.inline.hpp\"\n@@ -902,1 +902,0 @@\n-  assert(LockingMode != LM_LIGHTWEIGHT, \"Should call monitorenter_obj() when using the new lightweight locking\");\n@@ -917,17 +916,0 @@\n-\/\/ NOTE: We provide a separate implementation for the new lightweight locking to workaround a limitation\n-\/\/ of registers in x86_32. This entry point accepts an oop instead of a BasicObjectLock*.\n-\/\/ The problem is that we would need to preserve the register that holds the BasicObjectLock,\n-\/\/ but we are using that register to hold the thread. We don't have enough registers to\n-\/\/ also keep the BasicObjectLock, but we don't really need it anyway, we only need\n-\/\/ the object. See also InterpreterMacroAssembler::lock_object().\n-\/\/ As soon as legacy stack-locking goes away we could remove the other monitorenter() entry\n-\/\/ point, and only use oop-accepting entries (same for monitorexit() below).\n-JRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter_obj(JavaThread* current, oopDesc* obj))\n-  assert(LockingMode == LM_LIGHTWEIGHT, \"Should call monitorenter() when not using the new lightweight locking\");\n-  Handle h_obj(current, cast_to_oop(obj));\n-  assert(Universe::heap()->is_in_or_null(h_obj()),\n-         \"must be null or an object\");\n-  ObjectSynchronizer::enter(h_obj, nullptr, current);\n-  return;\n-JRT_END\n-\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":1,"deletions":19,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -725,0 +725,1 @@\n+  bool has_scoped_access = false;\n@@ -732,0 +733,1 @@\n+    has_scoped_access = stream->read_bool(\"hasScopedAccess\");\n@@ -798,0 +800,1 @@\n+                                        has_scoped_access,\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCodeInstaller.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -552,2 +552,2 @@\n-    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(),\n-        err_msg(\"Expected interface type, got %s\", klass->external_name()));\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(),\n+                   err_msg(\"Expected interface type, got %s\", klass->external_name()));\n@@ -592,1 +592,1 @@\n-    JVMCI_THROW_MSG_0(InternalError, err_msg(\"Primitive type %s should be handled in Java code\", str));\n+    JVMCI_THROW_MSG_NULL(InternalError, err_msg(\"Primitive type %s should be handled in Java code\", str));\n@@ -601,2 +601,2 @@\n-      THROW_MSG_0(vmSymbols::java_lang_Exception(),\n-                  err_msg(\"lookupTypeException: %s\", str));\n+      THROW_MSG_NULL(vmSymbols::java_lang_Exception(),\n+                     err_msg(\"lookupTypeException: %s\", str));\n@@ -620,1 +620,1 @@\n-        JVMCI_THROW_MSG_0(InternalError, err_msg(\"Illegal class loader value: %d\", accessing_klass_loader));\n+        JVMCI_THROW_MSG_NULL(InternalError, err_msg(\"Illegal class loader value: %d\", accessing_klass_loader));\n@@ -663,1 +663,1 @@\n-    BasicType type = JVMCIENV->typeCharToBasicType(type_char, JVMCI_CHECK_0);\n+    BasicType type = JVMCIENV->typeCharToBasicType(type_char, JVMCI_CHECK_NULL);\n@@ -815,1 +815,1 @@\n-    JVMCI_THROW_MSG_0(IllegalArgumentException, err_msg(\"Unexpected constant pool tag at index %d: %d\", index, tag.value()));\n+    JVMCI_THROW_MSG_NULL(IllegalArgumentException, err_msg(\"Unexpected constant pool tag at index %d: %d\", index, tag.value()));\n@@ -1972,1 +1972,1 @@\n-    JVMCI_THROW_0(NullPointerException);\n+    JVMCI_THROW_NULL(NullPointerException);\n@@ -1976,1 +1976,1 @@\n-    JVMCI_THROW_MSG_0(InternalError, err_msg(\"Class %s must be instance klass\", klass->external_name()));\n+    JVMCI_THROW_MSG_NULL(InternalError, err_msg(\"Class %s must be instance klass\", klass->external_name()));\n@@ -1996,1 +1996,1 @@\n-    JVMCI_THROW_0(NullPointerException);\n+    JVMCI_THROW_NULL(NullPointerException);\n@@ -2005,2 +2005,2 @@\n-    JVMCI_THROW_MSG_0(NullPointerException,\n-                    err_msg(\"Component mirror for array class %s is null\", klass->external_name()))\n+    JVMCI_THROW_MSG_NULL(NullPointerException,\n+                         err_msg(\"Component mirror for array class %s is null\", klass->external_name()))\n@@ -2109,1 +2109,1 @@\n-    JVMCI_THROW_0(NullPointerException);\n+    JVMCI_THROW_NULL(NullPointerException);\n@@ -2123,1 +2123,1 @@\n-    JVMCI_THROW_0(NullPointerException);\n+    JVMCI_THROW_NULL(NullPointerException);\n@@ -2168,1 +2168,1 @@\n-    JVMCI_THROW_0(NullPointerException);\n+    JVMCI_THROW_NULL(NullPointerException);\n@@ -2195,1 +2195,1 @@\n-    JVMCI_THROW_0(NullPointerException);\n+    JVMCI_THROW_NULL(NullPointerException);\n@@ -2222,1 +2222,1 @@\n-    JVMCI_THROW_0(NullPointerException);\n+    JVMCI_THROW_NULL(NullPointerException);\n@@ -2349,1 +2349,1 @@\n-    JVMCI_THROW_0(NullPointerException);\n+    JVMCI_THROW_NULL(NullPointerException);\n@@ -2399,1 +2399,1 @@\n-    JVMCI_THROW_0(NullPointerException);\n+    JVMCI_THROW_NULL(NullPointerException);\n@@ -2419,1 +2419,1 @@\n-    JVMCI_THROW_0(NullPointerException);\n+    JVMCI_THROW_NULL(NullPointerException);\n@@ -2438,1 +2438,1 @@\n-    JVMCI_THROW_0(NullPointerException);\n+    JVMCI_THROW_NULL(NullPointerException);\n@@ -2460,1 +2460,1 @@\n-    JVMCI_THROW_0(NullPointerException);\n+    JVMCI_THROW_NULL(NullPointerException);\n@@ -2546,1 +2546,1 @@\n-      JVMCI_THROW_MSG_0(InternalError, err_msg(\"Error initializing JVMCI runtime %d\", runtime->id()));\n+      JVMCI_THROW_MSG_NULL(InternalError, err_msg(\"Error initializing JVMCI runtime %d\", runtime->id()));\n@@ -2551,1 +2551,1 @@\n-    JVMCI_THROW_0(NullPointerException);\n+    JVMCI_THROW_NULL(NullPointerException);\n@@ -2555,1 +2555,1 @@\n-    JVMCI_THROW_MSG_0(IllegalArgumentException, \"clazz is for primitive type\");\n+    JVMCI_THROW_MSG_NULL(IllegalArgumentException, \"clazz is for primitive type\");\n@@ -2590,1 +2590,1 @@\n-          JVMCI_THROW_MSG_0(UnsatisfiedLinkError, err_msg(\"%s [neither %s nor %s exist in %s]\",\n+          JVMCI_THROW_MSG_NULL(UnsatisfiedLinkError, err_msg(\"%s [neither %s nor %s exist in %s]\",\n@@ -2597,1 +2597,1 @@\n-        JVMCI_THROW_MSG_0(UnsatisfiedLinkError, err_msg(\"%s [cannot re-link from \" PTR_FORMAT \" to \" PTR_FORMAT \"]\",\n+        JVMCI_THROW_MSG_NULL(UnsatisfiedLinkError, err_msg(\"%s [cannot re-link from \" PTR_FORMAT \" to \" PTR_FORMAT \"]\",\n@@ -2608,1 +2608,1 @@\n-  typeArrayOop info_oop = oopFactory::new_longArray(4, CHECK_0);\n+  typeArrayOop info_oop = oopFactory::new_longArray(4, CHECK_NULL);\n@@ -2610,1 +2610,1 @@\n-  runtime->init_JavaVM_info(info, JVMCI_CHECK_0);\n+  runtime->init_JavaVM_info(info, JVMCI_CHECK_NULL);\n@@ -3157,2 +3157,2 @@\n-  THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(),\n-              err_msg(\"%d is not a valid thread local id\", id));\n+  THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(),\n+                 err_msg(\"%d is not a valid thread local id\", id));\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.cpp","additions":32,"deletions":32,"binary":false,"changes":64,"status":"modified"},{"patch":"@@ -71,0 +71,2 @@\n+  static_field(CompilerToVM::Data,             SharedRuntime_throw_delayed_StackOverflowError_entry,                                 \\\n+                                                                                       address)                                      \\\n@@ -154,1 +156,1 @@\n-  volatile_nonstatic_field(BasicLock,          _displaced_header,                      markWord)                                     \\\n+  volatile_nonstatic_field(BasicLock,          _metadata,                              uintptr_t)                                    \\\n@@ -244,0 +246,1 @@\n+  nonstatic_field(JavaThread,                  _om_cache,                                     OMCache)                               \\\n@@ -330,2 +333,0 @@\n-  static_field(StubRoutines,                _throw_delayed_StackOverflowError_entry,          address)                               \\\n-                                                                                                                                     \\\n@@ -534,0 +535,2 @@\n+  declare_constant_with_value(\"OMCache::oop_to_oop_difference\", OMCache::oop_to_oop_difference()) \\\n+  declare_constant_with_value(\"OMCache::oop_to_monitor_difference\", OMCache::oop_to_monitor_difference()) \\\n@@ -658,0 +661,1 @@\n+  declare_constant(ConstMethodFlags::_misc_is_scoped)                     \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -133,0 +133,1 @@\n+  LOG_TAG(monitortable) \\\n","filename":"src\/hotspot\/share\/logging\/logTag.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -75,1 +75,1 @@\n-    size_t hs = length_offset_in_bytes() + sizeof(int);\n+    int hs = length_offset_in_bytes() + (int)sizeof(int);\n@@ -78,1 +78,1 @@\n-    static size_t arrayoopdesc_hs = 0;\n+    static int arrayoopdesc_hs = 0;\n@@ -90,1 +90,1 @@\n-                               sizeof(arrayOopDesc);\n+                               (int)sizeof(arrayOopDesc);\n@@ -95,2 +95,2 @@\n-    size_t hs = header_size_in_bytes();\n-    return (int)(element_type_should_be_aligned(type) ? align_up(hs, BytesPerLong) : hs);\n+    int hs = header_size_in_bytes();\n+    return element_type_should_be_aligned(type) ? align_up(hs, BytesPerLong) : hs;\n@@ -141,1 +141,1 @@\n-    size_t hdr_size_in_bytes = base_offset_in_bytes(type);\n+    int hdr_size_in_bytes = base_offset_in_bytes(type);\n@@ -143,1 +143,1 @@\n-    size_t hdr_size_in_words = align_up(hdr_size_in_bytes, HeapWordSize) \/ HeapWordSize;\n+    int hdr_size_in_words = align_up(hdr_size_in_bytes, HeapWordSize) \/ HeapWordSize;\n@@ -146,1 +146,1 @@\n-      align_down((SIZE_MAX\/HeapWordSize - hdr_size_in_words), MinObjAlignment);\n+      align_down((SIZE_MAX\/HeapWordSize - (size_t)hdr_size_in_words), MinObjAlignment);\n@@ -148,1 +148,1 @@\n-      HeapWordSize * max_element_words_per_size_t \/ type2aelembytes(type);\n+      HeapWordSize * max_element_words_per_size_t \/ (size_t)type2aelembytes(type);\n","filename":"src\/hotspot\/share\/oops\/arrayOop.hpp","additions":9,"deletions":9,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -250,4 +250,0 @@\n-  \/\/ _is_marked_dependent can be set concurrently, thus cannot be part of the\n-  \/\/ _misc_flags.\n-  bool            _is_marked_dependent;     \/\/ used for marking during flushing and deoptimization\n-\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -310,0 +310,1 @@\n+    assert(secondaries->length() >= (int)population_count(bitmap), \"must be\");\n@@ -348,5 +349,6 @@\n-  \/\/ For performance reasons we don't use a hashed table unless there\n-  \/\/ are at least two empty slots in it. If there were only one empty\n-  \/\/ slot it'd take a long time to create the table and the resulting\n-  \/\/ search would be no faster than linear probing.\n-  if (length > SECONDARY_SUPERS_TABLE_SIZE - 2) {\n+  \/\/ Invariant: _secondary_supers.length >= population_count(_secondary_supers_bitmap)\n+\n+  \/\/ Don't attempt to hash a table that's completely full, because in\n+  \/\/ the case of an absent interface linear probing would not\n+  \/\/ terminate.\n+  if (length >= SECONDARY_SUPERS_TABLE_SIZE) {\n@@ -792,0 +794,1 @@\n+  assert(secondary_supers()->length() >= (int)population_count(_bitmap), \"must be\");\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":8,"deletions":5,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -309,0 +309,1 @@\n+    assert(!UseObjectMonitorTable, \"Lightweight locking with OM table does not use markWord for monitors\");\n@@ -314,2 +315,5 @@\n-    return LockingMode == LM_LIGHTWEIGHT  ? lockbits == monitor_value   \/\/ monitor?\n-                                          : (lockbits & unlocked_value) == 0; \/\/ monitor | stack-locked?\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      return !UseObjectMonitorTable && lockbits == monitor_value;\n+    }\n+    \/\/ monitor (0b10) | stack-locked (0b00)?\n+    return (lockbits & unlocked_value) == 0;\n@@ -335,0 +339,1 @@\n+    assert(!UseObjectMonitorTable, \"Lightweight locking with OM table does not use markWord for monitors\");\n@@ -339,0 +344,4 @@\n+  markWord set_has_monitor() const {\n+    return markWord((value() & ~lock_mask_in_place) | monitor_value);\n+  }\n+\n","filename":"src\/hotspot\/share\/oops\/markWord.hpp","additions":11,"deletions":2,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -195,1 +195,1 @@\n-          THROW_MSG_0(vmSymbols::java_lang_NegativeArraySizeException(), err_msg(\"%d\", *sizes));\n+          THROW_MSG_NULL(vmSymbols::java_lang_NegativeArraySizeException(), err_msg(\"%d\", *sizes));\n","filename":"src\/hotspot\/share\/oops\/objArrayKlass.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1287,1 +1287,1 @@\n-  address call_addr = SharedRuntime::uncommon_trap_blob()->entry_point();\n+  address call_addr = OptoRuntime::uncommon_trap_blob()->entry_point();\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -154,0 +154,11 @@\n+\/\/------------------------------ForwardExceptionNode---------------------------\n+\/\/ Pop stack frame and jump to StubRoutines::forward_exception_entry()\n+class ForwardExceptionNode : public ReturnNode {\n+public:\n+  ForwardExceptionNode(Node* cntrl, Node* i_o, Node* memory, Node* frameptr, Node* retadr)\n+    : ReturnNode(TypeFunc::Parms, cntrl, i_o, memory, frameptr, retadr) {\n+  }\n+\n+  virtual int Opcode() const;\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/callnode.hpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -464,0 +464,4 @@\n+  AssertionPredicateType assertion_predicate_type() const {\n+    return _assertion_predicate_type;\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/cfgnode.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -188,0 +188,1 @@\n+macro(ForwardException)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -2034,0 +2034,1 @@\n+  case Op_ForwardException:\n@@ -2087,0 +2088,1 @@\n+  case Op_ForwardException:\n@@ -2132,0 +2134,1 @@\n+  case Op_ForwardException:\n","filename":"src\/hotspot\/share\/opto\/gcm.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -258,7 +258,5 @@\n-  Node *exc_target = makecon(TypeRawPtr::make( StubRoutines::forward_exception_entry() ));\n-  Node *to_exc = new TailCallNode(if_not_null,\n-                                  i_o(),\n-                                  exit_memory,\n-                                  frameptr(),\n-                                  returnadr(),\n-                                  exc_target, null());\n+  Node *to_exc = new ForwardExceptionNode(if_not_null,\n+                                          i_o(),\n+                                          exit_memory,\n+                                          frameptr(),\n+                                          returnadr());\n","filename":"src\/hotspot\/share\/opto\/generateOptoStub.cpp","additions":6,"deletions":8,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2317,1 +2317,1 @@\n-  address call_addr = SharedRuntime::uncommon_trap_blob()->entry_point();\n+  address call_addr = OptoRuntime::uncommon_trap_blob()->entry_point();\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1863,1 +1863,1 @@\n-    case AssertionPredicateType::Init_value:\n+    case AssertionPredicateType::InitValue:\n@@ -1866,1 +1866,1 @@\n-    case AssertionPredicateType::Last_value:\n+    case AssertionPredicateType::LastValue:\n","filename":"src\/hotspot\/share\/opto\/ifnode.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -125,1 +125,1 @@\n-          nn->as_MachCall()->entry_point() == SharedRuntime::uncommon_trap_blob()->entry_point()) {\n+          nn->as_MachCall()->entry_point() == OptoRuntime::uncommon_trap_blob()->entry_point()) {\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3373,1 +3373,1 @@\n-                                              StubRoutines::jfr_return_lease(),\n+                                              SharedRuntime::jfr_return_lease(),\n@@ -3572,1 +3572,1 @@\n-                                                  StubRoutines::jfr_write_checkpoint(),\n+                                                  SharedRuntime::jfr_write_checkpoint(),\n@@ -4914,1 +4914,2 @@\n-  \/\/ Test the header to see if it is safe to read w.r.t. locking.\n+  if (!UseObjectMonitorTable) {\n+    \/\/ Test the header to see if it is safe to read w.r.t. locking.\n@@ -4916,12 +4917,12 @@\n-  Node *lock_mask      = _gvn.MakeConX(markWord::inline_type_mask_in_place);\n-  Node *lmasked_header = _gvn.transform(new AndXNode(header, lock_mask));\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    Node *monitor_val   = _gvn.MakeConX(markWord::monitor_value);\n-    Node *chk_monitor   = _gvn.transform(new CmpXNode(lmasked_header, monitor_val));\n-    Node *test_monitor  = _gvn.transform(new BoolNode(chk_monitor, BoolTest::eq));\n-\n-    generate_slow_guard(test_monitor, slow_region);\n-  } else {\n-    Node *unlocked_val      = _gvn.MakeConX(markWord::unlocked_value);\n-    Node *chk_unlocked      = _gvn.transform(new CmpXNode(lmasked_header, unlocked_val));\n-    Node *test_not_unlocked = _gvn.transform(new BoolNode(chk_unlocked, BoolTest::ne));\n+    Node *lock_mask      = _gvn.MakeConX(markWord::inline_type_mask_in_place);\n+    Node *lmasked_header = _gvn.transform(new AndXNode(header, lock_mask));\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      Node *monitor_val   = _gvn.MakeConX(markWord::monitor_value);\n+      Node *chk_monitor   = _gvn.transform(new CmpXNode(lmasked_header, monitor_val));\n+      Node *test_monitor  = _gvn.transform(new BoolNode(chk_monitor, BoolTest::eq));\n+\n+      generate_slow_guard(test_monitor, slow_region);\n+    } else {\n+      Node *unlocked_val      = _gvn.MakeConX(markWord::unlocked_value);\n+      Node *chk_unlocked      = _gvn.transform(new CmpXNode(lmasked_header, unlocked_val));\n+      Node *test_not_unlocked = _gvn.transform(new BoolNode(chk_unlocked, BoolTest::ne));\n@@ -4929,1 +4930,2 @@\n-    generate_slow_guard(test_not_unlocked, slow_region);\n+      generate_slow_guard(test_not_unlocked, slow_region);\n+    }\n@@ -6340,1 +6342,1 @@\n-          (obs->as_CallStaticJava()->entry_point() == SharedRuntime::uncommon_trap_blob()->entry_point())) {\n+          (obs->as_CallStaticJava()->entry_point() == OptoRuntime::uncommon_trap_blob()->entry_point())) {\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":19,"deletions":17,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -960,3 +960,4 @@\n-  Node* clone_assertion_predicate_and_initialize(Node* iff, Node* new_init, Node* new_stride, Node* predicate,\n-                                                 Node* uncommon_proj, Node* control, IdealLoopTree* outer_loop,\n-                                                 Node* input_proj);\n+  Node* clone_template_assertion_predicate(IfNode* iff, Node* new_init, Node* predicate, Node* uncommon_proj, Node* control,\n+                                           IdealLoopTree* outer_loop, Node* input_proj);\n+  IfTrueNode* create_initialized_assertion_predicate(IfNode* template_assertion_predicate, Node* new_init,\n+                                                     Node* new_stride, Node* control);\n@@ -1589,1 +1590,1 @@\n-  static bool is_divisor_counted_loop_phi(const Node* divisor, const Node* loop);\n+  static bool is_divisor_loop_phi(const Node* divisor, const Node* loop);\n@@ -1786,1 +1787,1 @@\n-  void clone_template_assertion_predicate_expression_down(Node* node);\n+  void clone_template_assertion_expression_down(Node* node);\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":6,"deletions":5,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -305,1 +305,1 @@\n-  return is_divisor_counted_loop_phi(divisor, region) &&\n+  return is_divisor_loop_phi(divisor, region) &&\n@@ -309,2 +309,2 @@\n-bool PhaseIdealLoop::is_divisor_counted_loop_phi(const Node* divisor, const Node* loop) {\n-  return loop->is_BaseCountedLoop() && divisor->is_Phi() && divisor->in(0) == loop;\n+bool PhaseIdealLoop::is_divisor_loop_phi(const Node* divisor, const Node* loop) {\n+  return loop->is_Loop() && divisor->is_Phi() && divisor->in(0) == loop;\n","filename":"src\/hotspot\/share\/opto\/loopopts.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -48,3 +48,3 @@\n-jdouble MachOper::constantD() const { ShouldNotReachHere(); return 0.0; }\n-jfloat  MachOper::constantF() const { ShouldNotReachHere(); return 0.0; }\n-jlong   MachOper::constantL() const { ShouldNotReachHere(); return CONST64(0) ; }\n+jdouble MachOper::constantD() const { ShouldNotReachHere(); }\n+jfloat  MachOper::constantF() const { ShouldNotReachHere(); }\n+jlong   MachOper::constantL() const { ShouldNotReachHere(); }\n@@ -65,2 +65,2 @@\n-Label*   MachOper::label()  const { ShouldNotReachHere(); return 0; }\n-intptr_t MachOper::method() const { ShouldNotReachHere(); return 0; }\n+Label*   MachOper::label()  const { ShouldNotReachHere(); }\n+intptr_t MachOper::method() const { ShouldNotReachHere(); }\n@@ -83,1 +83,0 @@\n-  return nullptr;\n@@ -96,1 +95,0 @@\n-  return 5;\n@@ -103,1 +101,0 @@\n-  return opcode() == oper.opcode();\n@@ -210,1 +207,0 @@\n-  return nullptr;\n","filename":"src\/hotspot\/share\/opto\/machnode.cpp","additions":5,"deletions":9,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -839,0 +839,4 @@\n+  \/\/ Input RegMask array shared by all ForwardExceptions\n+  uint forw_exc_edge_cnt = TypeFunc::Parms;\n+  RegMask* forw_exc_rms  = init_input_masks( forw_exc_edge_cnt + soe_cnt, _return_addr_mask, c_frame_ptr_mask );\n+\n@@ -898,0 +902,1 @@\n+      case Op_ForwardException: exit->_in_rms = forw_exc_rms; break;\n@@ -917,0 +922,1 @@\n+      forw_exc_rms [ forw_exc_edge_cnt] = mreg2regmask[i];\n@@ -934,0 +940,1 @@\n+        forw_exc_rms [ forw_exc_edge_cnt].Insert(OptoReg::Name(i+1));\n@@ -946,0 +953,1 @@\n+        forw_exc_rms [ forw_exc_edge_cnt] = RegMask::Empty;\n@@ -960,0 +968,1 @@\n+        forw_exc_rms [ forw_exc_edge_cnt].Insert(OptoReg::Name(i+1));\n@@ -972,0 +981,1 @@\n+        forw_exc_rms [ forw_exc_edge_cnt] = RegMask::Empty;\n@@ -983,0 +993,1 @@\n+      forw_exc_edge_cnt++;\n@@ -986,1 +997,1 @@\n-      for( uint j=1; j < root->req(); j++ )\n+      for (uint j=1; j < root->req(); j++) {\n@@ -988,0 +999,1 @@\n+      }\n@@ -1105,0 +1117,1 @@\n+    case Op_ForwardException:\n@@ -3011,1 +3024,1 @@\n-        call->entry_point() == SharedRuntime::uncommon_trap_blob()->entry_point()) {\n+        call->entry_point() == OptoRuntime::uncommon_trap_blob()->entry_point()) {\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":15,"deletions":2,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -846,0 +846,1 @@\n+#ifdef ASSERT\n@@ -847,0 +848,1 @@\n+#endif\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -765,1 +765,1 @@\n-    ObjectValue* sv = (ObjectValue*) objs->at(i);\n+    ObjectValue* sv = objs->at(i)->as_ObjectValue();\n@@ -804,1 +804,1 @@\n-    ObjectValue* sv = (ObjectValue*) sv_for_node_id(objs, spobj->_idx);\n+    ObjectValue* sv = sv_for_node_id(objs, spobj->_idx);\n@@ -1052,1 +1052,1 @@\n-    ObjectValue* other = (ObjectValue*) sv_for_node_id(objs, n->_idx);\n+    ObjectValue* other = sv_for_node_id(objs, n->_idx);\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -361,1 +361,1 @@\n-  Node*         _alloc_with_final;   \/\/ An allocation node with final field\n+  Node*         _alloc_with_final_or_stable; \/\/ An allocation node with final or @Stable field\n@@ -406,4 +406,4 @@\n-  Node*    alloc_with_final() const   { return _alloc_with_final; }\n-  void set_alloc_with_final(Node* n)  {\n-    assert((_alloc_with_final == nullptr) || (_alloc_with_final == n), \"different init objects?\");\n-    _alloc_with_final = n;\n+  Node*    alloc_with_final_or_stable() const   { return _alloc_with_final_or_stable; }\n+  void set_alloc_with_final_or_stable(Node* n)  {\n+    assert((_alloc_with_final_or_stable == nullptr) || (_alloc_with_final_or_stable == n), \"different init objects?\");\n+    _alloc_with_final_or_stable = n;\n","filename":"src\/hotspot\/share\/opto\/parse.hpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -420,1 +420,1 @@\n-  _alloc_with_final = nullptr;\n+  _alloc_with_final_or_stable = nullptr;\n@@ -1061,2 +1061,2 @@\n-  \/\/ 1. The constructor wrote a final. The effects of all initializations\n-  \/\/    must be committed to memory before any code after the constructor\n+  \/\/ 1. The constructor wrote a final or a @Stable field. All these\n+  \/\/    initializations must be ordered before any code after the constructor\n@@ -1087,1 +1087,1 @@\n-       (wrote_final() ||\n+       (wrote_final() || wrote_stable() ||\n@@ -1090,0 +1090,1 @@\n+    Node* recorded_alloc = alloc_with_final_or_stable();\n@@ -1091,1 +1092,1 @@\n-                          alloc_with_final());\n+                          recorded_alloc);\n@@ -1096,2 +1097,2 @@\n-    if (DoEscapeAnalysis && alloc_with_final()) {\n-      AllocateNode* alloc = AllocateNode::Ideal_allocation(alloc_with_final());\n+    if (DoEscapeAnalysis && (recorded_alloc != nullptr)) {\n+      AllocateNode* alloc = AllocateNode::Ideal_allocation(recorded_alloc);\n@@ -1102,13 +1103,1 @@\n-      tty->print_cr(\" writes finals and needs a memory barrier\");\n-    }\n-  }\n-\n-  \/\/ Any method can write a @Stable field; insert memory barriers\n-  \/\/ after those also. Can't bind predecessor allocation node (if any)\n-  \/\/ with barrier because allocation doesn't always dominate\n-  \/\/ MemBarRelease.\n-  if (wrote_stable()) {\n-    _exits.insert_mem_bar(Op_MemBarRelease);\n-    if (PrintOpto && (Verbose || WizardMode)) {\n-      method()->print_name();\n-      tty->print_cr(\" writes @Stable and needs a memory barrier\");\n+      tty->print_cr(\" writes finals\/@Stable and needs a memory barrier\");\n","filename":"src\/hotspot\/share\/opto\/parse1.cpp","additions":9,"deletions":20,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -307,1 +307,4 @@\n-    \/\/ Note the presence of writes to final non-static fields, so that we\n+    \/\/ If the field is @Stable, we can be in any method, but we only care about\n+    \/\/ constructors at this point.\n+    \/\/\n+    \/\/ Note the presence of writes to final\/@Stable non-static fields, so that we\n@@ -310,3 +313,7 @@\n-    \/\/ Any method can write a @Stable field; insert memory barriers after those also.\n-    if (field->is_final()) {\n-      set_wrote_final(true);\n+    if (field->is_final() || field->is_stable()) {\n+      if (field->is_final()) {\n+        set_wrote_final(true);\n+      }\n+      if (field->is_stable()) {\n+        set_wrote_stable(true);\n+      }\n@@ -316,2 +323,1 @@\n-        \/\/ Can't bind stable with its allocation, only record allocation for final field.\n-        set_alloc_with_final(obj);\n+        set_alloc_with_final_or_stable(obj);\n@@ -320,3 +326,0 @@\n-    if (field->is_stable()) {\n-      set_wrote_stable(true);\n-    }\n@@ -357,1 +360,1 @@\n-      set_alloc_with_final(new_vt->get_oop());\n+      set_alloc_with_final_or_stable(new_vt->get_oop());\n","filename":"src\/hotspot\/share\/opto\/parse3.cpp","additions":13,"deletions":10,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -119,1 +119,2 @@\n-ExceptionBlob* OptoRuntime::_exception_blob;\n+UncommonTrapBlob*   OptoRuntime::_uncommon_trap_blob;\n+ExceptionBlob*      OptoRuntime::_exception_blob;\n@@ -143,0 +144,1 @@\n+  generate_uncommon_trap_blob();\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -172,0 +172,1 @@\n+  static UncommonTrapBlob*   _uncommon_trap_blob;\n@@ -173,0 +174,2 @@\n+\n+  static void generate_uncommon_trap_blob(void);\n@@ -213,0 +216,1 @@\n+  static UncommonTrapBlob* uncommon_trap_blob()                  { return _uncommon_trap_blob; }\n","filename":"src\/hotspot\/share\/opto\/runtime.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -99,1 +99,1 @@\n-  clone_template_assertion_predicate_expression_down(n);\n+  clone_template_assertion_expression_down(n);\n@@ -413,7 +413,7 @@\n-\/\/ 'n' could be a node belonging to a Template Assertion Predicate Expression (i.e. any node between a Template\n-\/\/ Assertion Predicate and its OpaqueLoop* nodes (included)). We cannot simply split this node up since this would\n-\/\/ create a phi node inside the Template Assertion Predicate Expression - making it unrecognizable as such. Therefore,\n-\/\/ we completely clone the entire Template Assertion Predicate Expression \"down\". This ensures that we have an\n-\/\/ untouched copy that is still recognized by the Template Assertion Predicate matching code.\n-void PhaseIdealLoop::clone_template_assertion_predicate_expression_down(Node* node) {\n-  if (!TemplateAssertionPredicateExpressionNode::is_in_expression(node)) {\n+\/\/ 'n' could be a node belonging to a Template Assertion Expression (i.e. any node between a Template Assertion Predicate\n+\/\/ and its OpaqueLoop* nodes (included)). We cannot simply split this node up since this would  create a phi node inside\n+\/\/ the Template Assertion Expression - making it unrecognizable as such. Therefore, we completely clone the entire\n+\/\/ Template Assertion Expression \"down\". This ensures that we have an untouched copy that is still recognized by the\n+\/\/ Template Assertion Predicate matching code.\n+void PhaseIdealLoop::clone_template_assertion_expression_down(Node* node) {\n+  if (!TemplateAssertionExpressionNode::is_in_expression(node)) {\n@@ -423,1 +423,1 @@\n-  TemplateAssertionPredicateExpressionNode template_assertion_predicate_expression_node(node);\n+  TemplateAssertionExpressionNode template_assertion_expression_node(node);\n@@ -426,1 +426,1 @@\n-    TemplateAssertionPredicateExpression template_assertion_predicate_expression(opaque4_node);\n+    TemplateAssertionExpression template_assertion_expression(opaque4_node);\n@@ -428,1 +428,1 @@\n-    Opaque4Node* cloned_opaque4_node = template_assertion_predicate_expression.clone(new_ctrl, this);\n+    Opaque4Node* cloned_opaque4_node = template_assertion_expression.clone(new_ctrl, this);\n@@ -431,1 +431,1 @@\n-  template_assertion_predicate_expression_node.for_each_template_assertion_predicate(clone_expression);\n+  template_assertion_expression_node.for_each_template_assertion_predicate(clone_expression);\n","filename":"src\/hotspot\/share\/opto\/split_if.cpp","additions":12,"deletions":12,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -206,1 +206,1 @@\n-      address call_addr = SharedRuntime::uncommon_trap_blob()->entry_point();\n+      address call_addr = OptoRuntime::uncommon_trap_blob()->entry_point();\n","filename":"src\/hotspot\/share\/opto\/stringopts.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2010, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2010, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -32,1 +32,1 @@\n-\/\/ *.include.hpp, since including them decreased build performance.\n+\/\/ *.inline.hpp, since including them decreased build performance.\n","filename":"src\/hotspot\/share\/precompiled\/precompiled.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1111,1 +1111,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_NoSuchMethodError(), name_str);\n+    THROW_MSG_NULL(vmSymbols::java_lang_NoSuchMethodError(), name_str);\n@@ -1121,1 +1121,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_NoSuchMethodError(), err_msg(\"%s%s.%s%s\", is_static ? \"static \" : \"\", klass->signature_name(), name_str, sig));\n+    THROW_MSG_NULL(vmSymbols::java_lang_NoSuchMethodError(), err_msg(\"%s%s.%s%s\", is_static ? \"static \" : \"\", klass->signature_name(), name_str, sig));\n@@ -1145,1 +1145,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_NoSuchMethodError(), err_msg(\"%s%s.%s%s\", is_static ? \"static \" : \"\", klass->signature_name(), name_str, sig));\n+    THROW_MSG_NULL(vmSymbols::java_lang_NoSuchMethodError(), err_msg(\"%s%s.%s%s\", is_static ? \"static \" : \"\", klass->signature_name(), name_str, sig));\n@@ -1193,1 +1193,1 @@\n-  jni_invoke_nonstatic(env, &jvalue, obj, JNI_VIRTUAL, methodID, &ap, CHECK_0); \\\n+  jni_invoke_nonstatic(env, &jvalue, obj, JNI_VIRTUAL, methodID, &ap, CHECK_(ResultType{})); \\\n@@ -1246,1 +1246,1 @@\n-  jni_invoke_nonstatic(env, &jvalue, obj, JNI_VIRTUAL, methodID, &ap, CHECK_0); \\\n+  jni_invoke_nonstatic(env, &jvalue, obj, JNI_VIRTUAL, methodID, &ap, CHECK_(ResultType{})); \\\n@@ -1297,1 +1297,1 @@\n-  jni_invoke_nonstatic(env, &jvalue, obj, JNI_VIRTUAL, methodID, &ap, CHECK_0); \\\n+  jni_invoke_nonstatic(env, &jvalue, obj, JNI_VIRTUAL, methodID, &ap, CHECK_(ResultType{})); \\\n@@ -1390,1 +1390,1 @@\n-  jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_0); \\\n+  jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_(ResultType{})); \\\n@@ -1443,1 +1443,1 @@\n-  jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_0); \\\n+  jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_(ResultType{})); \\\n@@ -1495,1 +1495,1 @@\n-  jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_0); \\\n+  jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_(ResultType{})); \\\n@@ -1591,1 +1591,1 @@\n-  jni_invoke_static(env, &jvalue, nullptr, JNI_STATIC, methodID, &ap, CHECK_0); \\\n+  jni_invoke_static(env, &jvalue, nullptr, JNI_STATIC, methodID, &ap, CHECK_(ResultType{})); \\\n@@ -1646,2 +1646,2 @@\n-  k->initialize(CHECK_0); \\\n-  jni_invoke_static(env, &jvalue, nullptr, JNI_STATIC, methodID, &ap, CHECK_0); \\\n+  k->initialize(CHECK_(ResultType{})); \\\n+  jni_invoke_static(env, &jvalue, nullptr, JNI_STATIC, methodID, &ap, CHECK_(ResultType{})); \\\n@@ -1700,1 +1700,1 @@\n-  jni_invoke_static(env, &jvalue, nullptr, JNI_STATIC, methodID, &ap, CHECK_0); \\\n+  jni_invoke_static(env, &jvalue, nullptr, JNI_STATIC, methodID, &ap, CHECK_(ResultType{})); \\\n@@ -1799,1 +1799,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_NoSuchFieldError(), err_msg(\"%s.%s %s\", k->external_name(), name, sig));\n+    THROW_MSG_NULL(vmSymbols::java_lang_NoSuchFieldError(), err_msg(\"%s.%s %s\", k->external_name(), name, sig));\n@@ -1809,1 +1809,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_NoSuchFieldError(), err_msg(\"%s.%s %s\", k->external_name(), name, sig));\n+    THROW_MSG_NULL(vmSymbols::java_lang_NoSuchFieldError(), err_msg(\"%s.%s %s\", k->external_name(), name, sig));\n@@ -2045,1 +2045,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_NoSuchFieldError(), (char*) name);\n+    THROW_MSG_NULL(vmSymbols::java_lang_NoSuchFieldError(), (char*) name);\n@@ -2054,1 +2054,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_NoSuchFieldError(), (char*) name);\n+    THROW_MSG_NULL(vmSymbols::java_lang_NoSuchFieldError(), (char*) name);\n@@ -2377,1 +2377,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_ArrayIndexOutOfBoundsException(), ss.as_string());\n+    THROW_MSG_NULL(vmSymbols::java_lang_ArrayIndexOutOfBoundsException(), ss.as_string());\n","filename":"src\/hotspot\/share\/prims\/jni.cpp","additions":18,"deletions":18,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -738,1 +738,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_CloneNotSupportedException(), klass->external_name());\n+    THROW_MSG_NULL(vmSymbols::java_lang_CloneNotSupportedException(), klass->external_name());\n@@ -844,1 +844,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_ClassNotFoundException(), (char*) utf);\n+    THROW_MSG_NULL(vmSymbols::java_lang_ClassNotFoundException(), (char*) utf);\n@@ -1005,1 +1005,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Lookup class is null\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Lookup class is null\");\n@@ -1032,1 +1032,1 @@\n-      THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"classData is only applicable for hidden classes\");\n+      THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"classData is only applicable for hidden classes\");\n@@ -1035,1 +1035,1 @@\n-      THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"dynamic nestmate is only applicable for hidden classes\");\n+      THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"dynamic nestmate is only applicable for hidden classes\");\n@@ -1038,1 +1038,1 @@\n-      THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"an ordinary class must be strongly referenced by its defining loader\");\n+      THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"an ordinary class must be strongly referenced by its defining loader\");\n@@ -1041,1 +1041,1 @@\n-      THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"vm annotations only allowed for hidden classes\");\n+      THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"vm annotations only allowed for hidden classes\");\n@@ -1044,2 +1044,2 @@\n-      THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(),\n-                  err_msg(\"invalid flag 0x%x\", flags));\n+      THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(),\n+                     err_msg(\"invalid flag 0x%x\", flags));\n@@ -1085,1 +1085,1 @@\n-    ik->class_loader_data()->dec_keep_alive();\n+    ik->class_loader_data()->dec_keep_alive_ref_count();\n@@ -1100,1 +1100,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Lookup class and defined class are in different packages\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Lookup class and defined class are in different packages\");\n@@ -1131,1 +1131,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Lookup class is null\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Lookup class is null\");\n@@ -1777,2 +1777,2 @@\n-        THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(),\n-                    \"Wrong type at constant pool index\");\n+        THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(),\n+                       \"Wrong type at constant pool index\");\n@@ -2211,1 +2211,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong type at constant pool index\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong type at constant pool index\");\n@@ -2224,1 +2224,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong type at constant pool index\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong type at constant pool index\");\n@@ -2235,1 +2235,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong type at constant pool index\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong type at constant pool index\");\n@@ -2250,1 +2250,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_RuntimeException(), \"Unable to look up method in target class\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_RuntimeException(), \"Unable to look up method in target class\");\n@@ -2284,1 +2284,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong type at constant pool index\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong type at constant pool index\");\n@@ -2300,1 +2300,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_RuntimeException(), \"Unable to look up field in target class\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_RuntimeException(), \"Unable to look up field in target class\");\n@@ -2333,1 +2333,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong type at constant pool index\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong type at constant pool index\");\n@@ -2384,1 +2384,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong type at constant pool index\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong type at constant pool index\");\n@@ -2452,1 +2452,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong type at constant pool index\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong type at constant pool index\");\n@@ -2466,1 +2466,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong type at constant pool index\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong type at constant pool index\");\n@@ -3407,1 +3407,1 @@\n-    THROW_0(vmSymbols::java_lang_NullPointerException());\n+    THROW_NULL(vmSymbols::java_lang_NullPointerException());\n@@ -3411,1 +3411,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Argument is not an array\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Argument is not an array\");\n@@ -3413,1 +3413,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Argument is not an array of primitive type\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Argument is not an array of primitive type\");\n@@ -3518,1 +3518,1 @@\n-      THROW_HANDLE_0(h_exception);\n+      THROW_HANDLE_NULL(h_exception);\n@@ -3654,1 +3654,1 @@\n-    THROW_0(vmSymbols::java_lang_StackOverflowError());\n+    THROW_NULL(vmSymbols::java_lang_StackOverflowError());\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":29,"deletions":29,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -1368,0 +1368,12 @@\n+\/**\n+ * Throws a java\/lang\/UnsupportedOperationException unconditionally.\n+ * This is required by the specification of VarHandle.{access-mode} if\n+ * invoked directly.\n+ *\/\n+JVM_ENTRY(jobject, VH_UOE(JNIEnv* env, jobject vh, jobjectArray args)) {\n+  THROW_MSG_NULL(vmSymbols::java_lang_UnsupportedOperationException(), \"VarHandle access mode methods cannot be invoked reflectively\");\n+  return nullptr;\n+}\n+JVM_END\n+\n+\n@@ -1407,0 +1419,34 @@\n+static JNINativeMethod VH_methods[] = {\n+  \/\/ UnsupportedOperationException throwers\n+  {CC \"get\",                        CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"set\",                        CC \"([\" OBJ \")V\",       FN_PTR(VH_UOE)},\n+  {CC \"getVolatile\",                CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"setVolatile\",                CC \"([\" OBJ \")V\",       FN_PTR(VH_UOE)},\n+  {CC \"getAcquire\",                 CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"setRelease\",                 CC \"([\" OBJ \")V\",       FN_PTR(VH_UOE)},\n+  {CC \"getOpaque\",                  CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"setOpaque\",                  CC \"([\" OBJ \")V\",       FN_PTR(VH_UOE)},\n+  {CC \"compareAndSet\",              CC \"([\" OBJ \")Z\",       FN_PTR(VH_UOE)},\n+  {CC \"compareAndExchange\",         CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"compareAndExchangeAcquire\",  CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"compareAndExchangeRelease\",  CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"weakCompareAndSetPlain\",     CC \"([\" OBJ \")Z\",       FN_PTR(VH_UOE)},\n+  {CC \"weakCompareAndSet\",          CC \"([\" OBJ \")Z\",       FN_PTR(VH_UOE)},\n+  {CC \"weakCompareAndSetAcquire\",   CC \"([\" OBJ \")Z\",       FN_PTR(VH_UOE)},\n+  {CC \"weakCompareAndSetRelease\",   CC \"([\" OBJ \")Z\",       FN_PTR(VH_UOE)},\n+  {CC \"getAndSet\",                  CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"getAndSetAcquire\",           CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"getAndSetRelease\",           CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"getAndAdd\",                  CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"getAndAddAcquire\",           CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"getAndAddRelease\",           CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"getAndBitwiseOr\",            CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"getAndBitwiseOrAcquire\",     CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"getAndBitwiseOrRelease\",     CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"getAndBitwiseAnd\",           CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"getAndBitwiseAndAcquire\",    CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"getAndBitwiseAndRelease\",    CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"getAndBitwiseXor\",           CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"getAndBitwiseXorAcquire\",    CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)},\n+  {CC \"getAndBitwiseXorRelease\",    CC \"([\" OBJ \")\" OBJ,    FN_PTR(VH_UOE)}\n+};\n@@ -1414,0 +1460,1 @@\n+  assert(vmClasses::VarHandle_klass() != nullptr, \"should be present\");\n@@ -1415,2 +1462,4 @@\n-  oop mirror = vmClasses::MethodHandle_klass()->java_mirror();\n-  jclass MH_class = (jclass) JNIHandles::make_local(THREAD, mirror);\n+  oop mh_mirror = vmClasses::MethodHandle_klass()->java_mirror();\n+  oop vh_mirror = vmClasses::VarHandle_klass()->java_mirror();\n+  jclass MH_class = (jclass) JNIHandles::make_local(THREAD, mh_mirror);\n+  jclass VH_class = (jclass) JNIHandles::make_local(THREAD, vh_mirror);\n@@ -1428,0 +1477,4 @@\n+\n+    status = env->RegisterNatives(VH_class, VH_methods, sizeof(VH_methods)\/sizeof(JNINativeMethod));\n+    guarantee(status == JNI_OK && !env->ExceptionOccurred(),\n+              \"register java.lang.invoke.VarHandle natives\");\n","filename":"src\/hotspot\/share\/prims\/methodHandles.cpp","additions":55,"deletions":2,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -702,1 +702,1 @@\n-    THROW_0(vmSymbols::java_lang_IllegalArgumentException());\n+    THROW_NULL(vmSymbols::java_lang_IllegalArgumentException());\n","filename":"src\/hotspot\/share\/prims\/unsafe.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -596,1 +596,1 @@\n-  THROW_MSG_0(vmSymbols::java_lang_UnsupportedOperationException(), \"WB_G1AuxiliaryMemoryUsage: G1 GC is not enabled\");\n+  THROW_MSG_NULL(vmSymbols::java_lang_UnsupportedOperationException(), \"WB_G1AuxiliaryMemoryUsage: G1 GC is not enabled\");\n@@ -805,0 +805,1 @@\n+    ResourceMark rm(THREAD);\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -507,1 +507,0 @@\n-  { \"UseNotificationThread\",        JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n@@ -516,0 +515,1 @@\n+  { \"UseNotificationThread\",        JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n@@ -1829,0 +1829,4 @@\n+  if (UseObjectMonitorTable) {\n+    FLAG_SET_CMDLINE(UseObjectMonitorTable, false);\n+    warning(\"UseObjectMonitorTable not supported on this platform\");\n+  }\n@@ -1831,0 +1835,6 @@\n+  if (UseObjectMonitorTable && LockingMode != LM_LIGHTWEIGHT) {\n+    \/\/ ObjectMonitorTable requires lightweight locking.\n+    FLAG_SET_CMDLINE(UseObjectMonitorTable, false);\n+    warning(\"UseObjectMonitorTable requires LM_LIGHTWEIGHT\");\n+  }\n+\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":11,"deletions":1,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -69,0 +69,1 @@\n+#include \"runtime\/basicLock.inline.hpp\"\n@@ -81,0 +82,2 @@\n+#include \"runtime\/lightweightSynchronizer.hpp\"\n+#include \"runtime\/lockStack.inline.hpp\"\n@@ -90,1 +93,1 @@\n-#include \"runtime\/synchronizer.hpp\"\n+#include \"runtime\/synchronizer.inline.hpp\"\n@@ -1727,1 +1730,11 @@\n-              mon_info->lock()->set_displaced_header(markWord::unused_mark());\n+              if (LockingMode == LM_LEGACY) {\n+                mon_info->lock()->set_displaced_header(markWord::unused_mark());\n+              } else if (UseObjectMonitorTable) {\n+                mon_info->lock()->clear_object_monitor_cache();\n+              }\n+#ifdef ASSERT\n+              else {\n+                assert(LockingMode == LM_MONITOR || !UseObjectMonitorTable, \"must be\");\n+                mon_info->lock()->set_bad_metadata_deopt();\n+              }\n+#endif\n@@ -1733,0 +1746,1 @@\n+        BasicLock* lock = mon_info->lock();\n@@ -1735,3 +1749,7 @@\n-          \/\/ Inflate the locks instead. Enter then inflate to avoid races with\n-          \/\/ deflation.\n-          ObjectSynchronizer::enter_for(obj, nullptr, deoptee_thread);\n+          \/\/ Entering may create an invalid lock stack. Inflate the lock if it\n+          \/\/ was fast_locked to restore the valid lock stack.\n+          ObjectSynchronizer::enter_for(obj, lock, deoptee_thread);\n+          if (deoptee_thread->lock_stack().contains(obj())) {\n+            LightweightSynchronizer::inflate_fast_locked_object(obj(), ObjectSynchronizer::InflateCause::inflate_cause_vm_internal,\n+                                                                deoptee_thread, thread);\n+          }\n@@ -1739,2 +1757,3 @@\n-          ObjectMonitor* mon = ObjectSynchronizer::inflate_for(deoptee_thread, obj(), ObjectSynchronizer::inflate_cause_vm_internal);\n-          assert(mon->owner() == deoptee_thread, \"must be\");\n+          assert(obj->mark().has_monitor(), \"must be\");\n+          assert(!deoptee_thread->lock_stack().contains(obj()), \"must be\");\n+          assert(ObjectSynchronizer::read_monitor(thread, obj(), obj->mark())->owner() == deoptee_thread, \"must be\");\n@@ -1742,1 +1761,0 @@\n-          BasicLock* lock = mon_info->lock();\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":26,"deletions":8,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -390,0 +390,1 @@\n+#ifdef ASSERT\n@@ -391,0 +392,1 @@\n+#endif\n@@ -441,0 +443,1 @@\n+#ifndef PRODUCT\n@@ -443,0 +446,1 @@\n+#endif\n@@ -496,0 +500,1 @@\n+#ifdef ASSERT\n@@ -499,0 +504,1 @@\n+#endif\n","filename":"src\/hotspot\/share\/runtime\/frame.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -976,3 +976,0 @@\n-  product(bool, UseNotificationThread, true,                                \\\n-          \"(Deprecated) Use Notification Thread\")                           \\\n-                                                                            \\\n@@ -2000,0 +1997,11 @@\n+  product(bool, UseObjectMonitorTable, false, DIAGNOSTIC,                   \\\n+          \"With Lightweight Locking mode, use a table to record inflated \"  \\\n+          \"monitors rather than the first word of the object.\")             \\\n+                                                                            \\\n+  product(int, LightweightFastLockingSpins, 13, DIAGNOSTIC,                 \\\n+          \"Specifies the number of times lightweight fast locking will \"    \\\n+          \"attempt to CAS the markWord before inflating. Between each \"     \\\n+          \"CAS it will spin for exponentially more time, resulting in \"     \\\n+          \"a total number of spins on the order of O(2^value)\")             \\\n+          range(1, 30)                                                      \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":11,"deletions":3,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -130,0 +130,1 @@\n+  \/\/ stub routines in initial blob are referenced by later generated code\n@@ -131,0 +132,2 @@\n+  \/\/ stack overflow exception blob is referenced by the interpreter\n+  SharedRuntime::generate_initial_stubs();\n@@ -148,0 +151,3 @@\n+#if INCLUDE_JFR\n+  SharedRuntime::generate_jfr_stubs();\n+#endif\n","filename":"src\/hotspot\/share\/runtime\/init.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -362,8 +362,0 @@\n-  \/\/ Since the call stub sets up like the interpreter we call the from_interpreted_entry\n-  \/\/ so we can go compiled via a i2c. Otherwise initial entry method will always\n-  \/\/ run interpreted.\n-  address entry_point = method->from_interpreted_entry();\n-  if (JvmtiExport::can_post_interpreter_events() && thread->is_interp_only_mode()) {\n-    entry_point = method->interpreter_entry();\n-  }\n-\n@@ -415,0 +407,12 @@\n+\n+      address entry_point;\n+      {\n+        \/\/ The enter_interp_only_mode use handshake to set interp_only mode\n+        \/\/ so no safepoint should be allowed between is_interp_only_mode() and call\n+        NoSafepointVerifier nsv;\n+        if (JvmtiExport::can_post_interpreter_events() && thread->is_interp_only_mode()) {\n+          entry_point = method->interpreter_entry();\n+        } else {\n+          \/\/ Since the call stub sets up like the interpreter we call the from_interpreted_entry\n+          \/\/ so we can go compiled via a i2c.\n+          entry_point = method->from_interpreted_entry();\n@@ -416,10 +420,13 @@\n-      \/\/ Gets the alternative target (if any) that should be called\n-      Handle alternative_target = args->alternative_target();\n-      if (!alternative_target.is_null()) {\n-        \/\/ Must extract verified entry point from HotSpotNmethod after VM to Java\n-        \/\/ transition in JavaCallWrapper constructor so that it is safe with\n-        \/\/ respect to nmethod sweeping.\n-        address verified_entry_point = (address) HotSpotJVMCI::InstalledCode::entryPoint(nullptr, alternative_target());\n-        if (verified_entry_point != nullptr) {\n-          thread->set_jvmci_alternate_call_target(verified_entry_point);\n-          entry_point = method->adapter()->get_i2c_entry();\n+          \/\/ Gets the alternative target (if any) that should be called\n+          Handle alternative_target = args->alternative_target();\n+          if (!alternative_target.is_null()) {\n+            \/\/ Must extract verified entry point from HotSpotNmethod after VM to Java\n+            \/\/ transition in JavaCallWrapper constructor so that it is safe with\n+            \/\/ respect to nmethod sweeping.\n+            address verified_entry_point = (address) HotSpotJVMCI::InstalledCode::entryPoint(nullptr, alternative_target());\n+            if (verified_entry_point != nullptr) {\n+              thread->set_jvmci_alternate_call_target(verified_entry_point);\n+              entry_point = method->adapter()->get_i2c_entry();\n+            }\n+          }\n+#endif\n@@ -428,1 +435,0 @@\n-#endif\n","filename":"src\/hotspot\/share\/runtime\/javaCalls.cpp","additions":26,"deletions":20,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -508,1 +508,2 @@\n-  _lock_stack(this) {\n+  _lock_stack(this),\n+  _om_cache(this) {\n@@ -807,0 +808,2 @@\n+  om_clear_monitor_cache();\n+\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -64,0 +64,1 @@\n+class ObjectMonitor;\n@@ -1173,0 +1174,1 @@\n+  OMCache _om_cache;\n@@ -1184,0 +1186,7 @@\n+  static ByteSize om_cache_offset()        { return byte_offset_of(JavaThread, _om_cache); }\n+  static ByteSize om_cache_oops_offset()   { return om_cache_offset() + OMCache::entries_offset(); }\n+\n+  void om_set_monitor_cache(ObjectMonitor* monitor);\n+  void om_clear_monitor_cache();\n+  ObjectMonitor* om_get_from_monitor_cache(oop obj);\n+\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -335,1 +335,1 @@\n-    THROW_0(vmSymbols::java_lang_IllegalArgumentException());\n+    THROW_NULL(vmSymbols::java_lang_IllegalArgumentException());\n@@ -344,1 +344,1 @@\n-    THROW_0(vmSymbols::java_lang_NullPointerException());\n+    THROW_NULL(vmSymbols::java_lang_NullPointerException());\n@@ -347,1 +347,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_NegativeArraySizeException(), err_msg(\"%d\", length));\n+    THROW_MSG_NULL(vmSymbols::java_lang_NegativeArraySizeException(), err_msg(\"%d\", length));\n@@ -355,1 +355,1 @@\n-      THROW_0(vmSymbols::java_lang_IllegalArgumentException());\n+      THROW_NULL(vmSymbols::java_lang_IllegalArgumentException());\n@@ -367,1 +367,1 @@\n-    THROW_0(vmSymbols::java_lang_NullPointerException());\n+    THROW_NULL(vmSymbols::java_lang_NullPointerException());\n@@ -372,1 +372,1 @@\n-    THROW_0(vmSymbols::java_lang_IllegalArgumentException());\n+    THROW_NULL(vmSymbols::java_lang_IllegalArgumentException());\n@@ -379,1 +379,1 @@\n-      THROW_MSG_0(vmSymbols::java_lang_NegativeArraySizeException(), err_msg(\"%d\", d));\n+      THROW_MSG_NULL(vmSymbols::java_lang_NegativeArraySizeException(), err_msg(\"%d\", d));\n@@ -393,1 +393,1 @@\n-        THROW_0(vmSymbols::java_lang_IllegalArgumentException());\n+        THROW_NULL(vmSymbols::java_lang_IllegalArgumentException());\n@@ -992,1 +992,1 @@\n-      THROW_0(vmSymbols::java_lang_NullPointerException());\n+      THROW_NULL(vmSymbols::java_lang_NullPointerException());\n@@ -996,1 +996,1 @@\n-      THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"object is not an instance of declaring class\");\n+      THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"object is not an instance of declaring class\");\n@@ -1020,3 +1020,3 @@\n-          THROW_ARG_0(vmSymbols::java_lang_reflect_InvocationTargetException(),\n-                      vmSymbols::throwable_void_signature(),\n-                      &args);\n+          THROW_ARG_NULL(vmSymbols::java_lang_reflect_InvocationTargetException(),\n+                         vmSymbols::throwable_void_signature(),\n+                         &args);\n@@ -1044,3 +1044,3 @@\n-            THROW_ARG_0(vmSymbols::java_lang_reflect_InvocationTargetException(),\n-              vmSymbols::throwable_void_signature(),\n-              &args);\n+            THROW_ARG_NULL(vmSymbols::java_lang_reflect_InvocationTargetException(),\n+                           vmSymbols::throwable_void_signature(),\n+                           &args);\n@@ -1063,1 +1063,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_NoSuchMethodError(), ss.as_string());\n+    THROW_MSG_NULL(vmSymbols::java_lang_NoSuchMethodError(), ss.as_string());\n@@ -1070,2 +1070,2 @@\n-    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(),\n-                \"wrong number of arguments\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(),\n+                   \"wrong number of arguments\");\n@@ -1101,1 +1101,1 @@\n-          THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"argument type mismatch\");\n+          THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"argument type mismatch\");\n@@ -1107,2 +1107,2 @@\n-          THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(),\n-                      \"argument type mismatch\");\n+          THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(),\n+                         \"argument type mismatch\");\n@@ -1133,3 +1133,3 @@\n-    THROW_ARG_0(vmSymbols::java_lang_reflect_InvocationTargetException(),\n-                vmSymbols::throwable_void_signature(),\n-                &args);\n+    THROW_ARG_NULL(vmSymbols::java_lang_reflect_InvocationTargetException(),\n+                   vmSymbols::throwable_void_signature(),\n+                   &args);\n@@ -1164,1 +1164,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_InternalError(), \"invoke\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_InternalError(), \"invoke\");\n@@ -1181,1 +1181,1 @@\n-    THROW_MSG_0(vmSymbols::java_lang_InternalError(), \"invoke\");\n+    THROW_MSG_NULL(vmSymbols::java_lang_InternalError(), \"invoke\");\n","filename":"src\/hotspot\/share\/runtime\/reflection.cpp","additions":28,"deletions":28,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -735,0 +735,5 @@\n+\n+  \/\/ The oops in the monitor cache are cleared to prevent stale cache entries\n+  \/\/ from keeping dead objects alive. Because these oops are always cleared\n+  \/\/ before safepoint operations they are not visited in JavaThread::oops_do.\n+  _thread->om_clear_monitor_cache();\n","filename":"src\/hotspot\/share\/runtime\/safepoint.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -66,0 +66,1 @@\n+#include \"runtime\/basicLock.inline.hpp\"\n@@ -77,1 +78,2 @@\n-#include \"runtime\/synchronizer.hpp\"\n+#include \"runtime\/synchronizer.inline.hpp\"\n+#include \"runtime\/timerTrace.hpp\"\n@@ -84,0 +86,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -94,1 +97,3 @@\n-\/\/ Shared stub locations\n+\/\/ Shared runtime stub routines reside in their own unique blob with a\n+\/\/ single entry point\n+\n@@ -107,3 +112,10 @@\n-#ifdef COMPILER2\n-UncommonTrapBlob*   SharedRuntime::_uncommon_trap_blob;\n-#endif \/\/ COMPILER2\n+RuntimeStub*        SharedRuntime::_throw_AbstractMethodError_blob;\n+RuntimeStub*        SharedRuntime::_throw_IncompatibleClassChangeError_blob;\n+RuntimeStub*        SharedRuntime::_throw_NullPointerException_at_call_blob;\n+RuntimeStub*        SharedRuntime::_throw_StackOverflowError_blob;\n+RuntimeStub*        SharedRuntime::_throw_delayed_StackOverflowError_blob;\n+\n+#if INCLUDE_JFR\n+RuntimeStub*        SharedRuntime::_jfr_write_checkpoint_blob = nullptr;\n+RuntimeStub*        SharedRuntime::_jfr_return_lease_blob = nullptr;\n+#endif\n@@ -114,0 +126,7 @@\n+void SharedRuntime::generate_initial_stubs() {\n+  \/\/ Build this early so it's available for the interpreter.\n+  _throw_StackOverflowError_blob =\n+    generate_throw_exception(\"StackOverflowError throw_exception\",\n+                             CAST_FROM_FN_PTR(address, SharedRuntime::throw_StackOverflowError));\n+}\n+\n@@ -122,0 +141,16 @@\n+  _throw_delayed_StackOverflowError_blob =\n+    generate_throw_exception(\"delayed StackOverflowError throw_exception\",\n+                             CAST_FROM_FN_PTR(address, SharedRuntime::throw_delayed_StackOverflowError));\n+\n+  _throw_AbstractMethodError_blob =\n+    generate_throw_exception(\"AbstractMethodError throw_exception\",\n+                             CAST_FROM_FN_PTR(address, SharedRuntime::throw_AbstractMethodError));\n+\n+  _throw_IncompatibleClassChangeError_blob =\n+    generate_throw_exception(\"IncompatibleClassChangeError throw_exception\",\n+                             CAST_FROM_FN_PTR(address, SharedRuntime::throw_IncompatibleClassChangeError));\n+\n+  _throw_NullPointerException_at_call_blob =\n+    generate_throw_exception(\"NullPointerException at call throw_exception\",\n+                             CAST_FROM_FN_PTR(address, SharedRuntime::throw_NullPointerException_at_call));\n+\n@@ -135,0 +170,1 @@\n+}\n@@ -136,3 +172,9 @@\n-#ifdef COMPILER2\n-  generate_uncommon_trap_blob();\n-#endif \/\/ COMPILER2\n+#if INCLUDE_JFR\n+\/\/------------------------------generate jfr runtime stubs ------\n+void SharedRuntime::generate_jfr_stubs() {\n+  ResourceMark rm;\n+  const char* timer_msg = \"SharedRuntime generate_jfr_stubs\";\n+  TraceTime timer(timer_msg, TRACETIME_LOG(Info, startuptime));\n+\n+  _jfr_write_checkpoint_blob = generate_jfr_write_checkpoint();\n+  _jfr_return_lease_blob = generate_jfr_return_lease();\n@@ -141,0 +183,2 @@\n+#endif \/\/ INCLUDE_JFR\n+\n@@ -879,1 +923,1 @@\n-        return StubRoutines::throw_StackOverflowError_entry();\n+        return SharedRuntime::throw_StackOverflowError_entry();\n@@ -905,1 +949,1 @@\n-            return StubRoutines::throw_NullPointerException_at_call_entry();\n+            return SharedRuntime::throw_NullPointerException_at_call_entry();\n@@ -926,1 +970,1 @@\n-            return StubRoutines::throw_NullPointerException_at_call_entry();\n+            return SharedRuntime::throw_NullPointerException_at_call_entry();\n@@ -937,1 +981,1 @@\n-            return StubRoutines::throw_NullPointerException_at_call_entry();\n+            return SharedRuntime::throw_NullPointerException_at_call_entry();\n@@ -943,1 +987,1 @@\n-            return StubRoutines::throw_NullPointerException_at_call_entry();\n+            return SharedRuntime::throw_NullPointerException_at_call_entry();\n@@ -1529,1 +1573,1 @@\n-  address res = StubRoutines::throw_AbstractMethodError_entry();\n+  address res = SharedRuntime::throw_AbstractMethodError_entry();\n@@ -1986,1 +2030,1 @@\n-    if (ObjectSynchronizer::quick_enter(obj, current, lock)) {\n+    if (ObjectSynchronizer::quick_enter(obj, lock, current)) {\n@@ -2511,1 +2555,1 @@\n-                                                                StubRoutines::throw_AbstractMethodError_entry(),\n+                                                                SharedRuntime::throw_AbstractMethodError_entry(),\n@@ -2892,1 +2936,1 @@\n-                                               StubRoutines::throw_AbstractMethodError_entry(),\n+                                               SharedRuntime::throw_AbstractMethodError_entry(),\n@@ -3339,0 +3383,2 @@\n+      } else if (UseObjectMonitorTable) {\n+        buf[i] = (intptr_t)lock->object_monitor_cache();\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":63,"deletions":17,"binary":false,"changes":80,"status":"modified"},{"patch":"@@ -67,4 +67,0 @@\n-#ifdef COMPILER2\n-  static UncommonTrapBlob*   _uncommon_trap_blob;\n-#endif \/\/ COMPILER2\n-\n@@ -73,0 +69,11 @@\n+  static RuntimeStub*        _throw_AbstractMethodError_blob;\n+  static RuntimeStub*        _throw_IncompatibleClassChangeError_blob;\n+  static RuntimeStub*        _throw_NullPointerException_at_call_blob;\n+  static RuntimeStub*        _throw_StackOverflowError_blob;\n+  static RuntimeStub*        _throw_delayed_StackOverflowError_blob;\n+\n+#if INCLUDE_JFR\n+  static RuntimeStub*        _jfr_write_checkpoint_blob;\n+  static RuntimeStub*        _jfr_return_lease_blob;\n+#endif\n+\n@@ -82,0 +89,1 @@\n+  static RuntimeStub*   generate_throw_exception(const char* name, address runtime_entry);\n@@ -83,0 +91,1 @@\n+  static void generate_initial_stubs(void);\n@@ -84,0 +93,9 @@\n+#if INCLUDE_JFR\n+  static void generate_jfr_stubs(void);\n+  \/\/ For c2: c_rarg0 is junk, call to runtime to write a checkpoint.\n+  \/\/ It returns a jobject handle to the event writer.\n+  \/\/ The handle is dereferenced and the return value is the event writer oop.\n+  static RuntimeStub* generate_jfr_write_checkpoint();\n+  \/\/ For c2: call to runtime to return a buffer lease.\n+  static RuntimeStub* generate_jfr_return_lease();\n+#endif\n@@ -227,5 +245,0 @@\n-#ifdef COMPILER2\n-  static void generate_uncommon_trap_blob(void);\n-  static UncommonTrapBlob* uncommon_trap_blob()                  { return _uncommon_trap_blob; }\n-#endif \/\/ COMPILER2\n-\n@@ -254,0 +267,12 @@\n+  \/\/ Implicit exceptions\n+  static address throw_AbstractMethodError_entry()          { return _throw_AbstractMethodError_blob->entry_point(); }\n+  static address throw_IncompatibleClassChangeError_entry() { return _throw_IncompatibleClassChangeError_blob->entry_point(); }\n+  static address throw_NullPointerException_at_call_entry() { return _throw_NullPointerException_at_call_blob->entry_point(); }\n+  static address throw_StackOverflowError_entry()           { return _throw_StackOverflowError_blob->entry_point(); }\n+  static address throw_delayed_StackOverflowError_entry()   { return _throw_delayed_StackOverflowError_blob->entry_point(); }\n+\n+#if INCLUDE_JFR\n+  static address jfr_write_checkpoint() { return _jfr_write_checkpoint_blob->entry_point(); }\n+  static address jfr_return_lease()     { return _jfr_return_lease_blob->entry_point(); }\n+#endif\n+\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":34,"deletions":9,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"sanitizers\/ub.hpp\"\n@@ -342,0 +343,1 @@\n+  ATTRIBUTE_NO_UBSAN\n","filename":"src\/hotspot\/share\/runtime\/signature.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -64,5 +64,0 @@\n-address StubRoutines::_throw_AbstractMethodError_entry          = nullptr;\n-address StubRoutines::_throw_IncompatibleClassChangeError_entry = nullptr;\n-address StubRoutines::_throw_NullPointerException_at_call_entry = nullptr;\n-address StubRoutines::_throw_StackOverflowError_entry           = nullptr;\n-address StubRoutines::_throw_delayed_StackOverflowError_entry   = nullptr;\n@@ -197,5 +192,0 @@\n-JFR_ONLY(RuntimeStub* StubRoutines::_jfr_write_checkpoint_stub = nullptr;)\n-JFR_ONLY(address StubRoutines::_jfr_write_checkpoint = nullptr;)\n-JFR_ONLY(RuntimeStub* StubRoutines::_jfr_return_lease_stub = nullptr;)\n-JFR_ONLY(address StubRoutines::_jfr_return_lease = nullptr;)\n-\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":0,"deletions":10,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -39,1 +39,28 @@\n-\/\/ points are defined in the platform-specific inner class.\n+\/\/ points are defined in the platform-specific inner class. Most\n+\/\/ routines have a single (main) entry point. However, a few routines\n+\/\/ do provide alternative entry points.\n+\/\/\n+\/\/ Stub routines whose entries are advertised via class StubRoutines\n+\/\/ are generated in batches at well-defined stages during JVM init:\n+\/\/ initial stubs, continuation stubs, compiler stubs, final stubs.\n+\/\/ Each batch is embedded in a single, associated blob (an instance of\n+\/\/ BufferBlob) i.e. the blob to entry relationship is 1-m.\n+\/\/\n+\/\/ Note that this constrasts with the much smaller number of stub\n+\/\/ routines generated via classes SharedRuntime, c1_Runtime1 and\n+\/\/ OptoRuntime. The latter routines are also generated at well-defined\n+\/\/ points during JVM init. However, each stub routine has its own\n+\/\/ unique blob (various subclasses of RuntimeBlob) i.e. the blob to\n+\/\/ entry relationship is 1-1. The difference arises because\n+\/\/ SharedRuntime routines may need to be relocatable or advertise\n+\/\/ properties such as a frame size via their blob.\n+\/\/\n+\/\/ Staging of stub routine generation is needed in order to manage\n+\/\/ init dependencies between 1) stubs and other stubs or 2) stubs and\n+\/\/ other runtime components. For example, some exception throw stubs\n+\/\/ need to be generated before compiler stubs (such as the\n+\/\/ deoptimization stub) so that the latter can invoke the thrwo rotine\n+\/\/ in bail-out code. Likewise, stubs that access objects (such as the\n+\/\/ object array copy stub) need to be created after initialization of\n+\/\/ some GC constants and generation of the GC barrier stubs they might\n+\/\/ need to invoke.\n@@ -52,2 +79,1 @@\n-\/\/    stubRoutines_<os_family>.cpp       stubGenerator_<arch>.cpp\n-\/\/    stubRoutines_<os_arch>.cpp\n+\/\/                                       stubGenerator_<arch>.cpp\n@@ -78,0 +104,2 @@\n+\/\/ 5. ensure the entry is generated in the right blob to satisfy initialization\n+\/\/    dependencies between it and other stubs or runtime components.\n@@ -140,5 +168,0 @@\n-  static address _throw_AbstractMethodError_entry;\n-  static address _throw_IncompatibleClassChangeError_entry;\n-  static address _throw_NullPointerException_at_call_entry;\n-  static address _throw_StackOverflowError_entry;\n-  static address _throw_delayed_StackOverflowError_entry;\n@@ -272,5 +295,0 @@\n-  JFR_ONLY(static RuntimeStub* _jfr_write_checkpoint_stub;)\n-  JFR_ONLY(static address _jfr_write_checkpoint;)\n-  JFR_ONLY(static RuntimeStub* _jfr_return_lease_stub;)\n-  JFR_ONLY(static address _jfr_return_lease;)\n-\n@@ -335,6 +353,0 @@\n-  \/\/ Implicit exceptions\n-  static address throw_AbstractMethodError_entry()         { return _throw_AbstractMethodError_entry; }\n-  static address throw_IncompatibleClassChangeError_entry(){ return _throw_IncompatibleClassChangeError_entry; }\n-  static address throw_NullPointerException_at_call_entry(){ return _throw_NullPointerException_at_call_entry; }\n-  static address throw_StackOverflowError_entry()          { return _throw_StackOverflowError_entry; }\n-  static address throw_delayed_StackOverflowError_entry()  { return _throw_delayed_StackOverflowError_entry; }\n@@ -493,3 +505,0 @@\n-  JFR_ONLY(static address jfr_write_checkpoint() { return _jfr_write_checkpoint; })\n-  JFR_ONLY(static address jfr_return_lease() { return _jfr_return_lease; })\n-\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.hpp","additions":31,"deletions":22,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+#include \"runtime\/basicLock.inline.hpp\"\n@@ -44,0 +45,1 @@\n+#include \"runtime\/lightweightSynchronizer.hpp\"\n@@ -55,1 +57,1 @@\n-#include \"runtime\/synchronizer.hpp\"\n+#include \"runtime\/synchronizer.inline.hpp\"\n@@ -279,0 +281,4 @@\n+\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    LightweightSynchronizer::initialize();\n+  }\n@@ -369,1 +375,5 @@\n-    ObjectMonitor* const mon = mark.monitor();\n+    ObjectMonitor* const mon = read_monitor(current, obj, mark);\n+    if (LockingMode == LM_LIGHTWEIGHT && mon == nullptr) {\n+      \/\/ Racing with inflation\/deflation go slow path\n+      return false;\n+    }\n@@ -396,0 +406,7 @@\n+static bool useHeavyMonitors() {\n+#if defined(X86) || defined(AARCH64) || defined(PPC64) || defined(RISCV64) || defined(S390)\n+  return LockingMode == LM_MONITOR;\n+#else\n+  return false;\n+#endif\n+}\n@@ -403,2 +420,1 @@\n-bool ObjectSynchronizer::quick_enter(oop obj, JavaThread* current,\n-                                     BasicLock * lock) {\n+bool ObjectSynchronizer::quick_enter_legacy(oop obj, BasicLock* lock, JavaThread* current) {\n@@ -406,2 +422,0 @@\n-  NoSafepointVerifier nsv;\n-  if (obj == nullptr) return false;       \/\/ Need to throw NPE\n@@ -410,2 +424,2 @@\n-  if (obj->klass()->is_value_based()) {\n-    return false;\n+  if (useHeavyMonitors()) {\n+    return false;  \/\/ Slow path\n@@ -415,10 +429,1 @@\n-    LockStack& lock_stack = current->lock_stack();\n-    if (lock_stack.is_full()) {\n-      \/\/ Always go into runtime if the lock stack is full.\n-      return false;\n-    }\n-    if (lock_stack.try_recursive_enter(obj)) {\n-      \/\/ Recursive lock successful.\n-      current->inc_held_monitor_count();\n-      return true;\n-    }\n+    return LightweightSynchronizer::quick_enter(obj, lock, current);\n@@ -427,0 +432,2 @@\n+  assert(LockingMode == LM_LEGACY, \"legacy mode below\");\n+\n@@ -430,1 +437,2 @@\n-    ObjectMonitor* const m = mark.monitor();\n+\n+    ObjectMonitor* const m = read_monitor(mark);\n@@ -450,12 +458,10 @@\n-    if (LockingMode != LM_LIGHTWEIGHT) {\n-      \/\/ This Java Monitor is inflated so obj's header will never be\n-      \/\/ displaced to this thread's BasicLock. Make the displaced header\n-      \/\/ non-null so this BasicLock is not seen as recursive nor as\n-      \/\/ being locked. We do this unconditionally so that this thread's\n-      \/\/ BasicLock cannot be mis-interpreted by any stack walkers. For\n-      \/\/ performance reasons, stack walkers generally first check for\n-      \/\/ stack-locking in the object's header, the second check is for\n-      \/\/ recursive stack-locking in the displaced header in the BasicLock,\n-      \/\/ and last are the inflated Java Monitor (ObjectMonitor) checks.\n-      lock->set_displaced_header(markWord::unused_mark());\n-    }\n+    \/\/ This Java Monitor is inflated so obj's header will never be\n+    \/\/ displaced to this thread's BasicLock. Make the displaced header\n+    \/\/ non-null so this BasicLock is not seen as recursive nor as\n+    \/\/ being locked. We do this unconditionally so that this thread's\n+    \/\/ BasicLock cannot be mis-interpreted by any stack walkers. For\n+    \/\/ performance reasons, stack walkers generally first check for\n+    \/\/ stack-locking in the object's header, the second check is for\n+    \/\/ recursive stack-locking in the displaced header in the BasicLock,\n+    \/\/ and last are the inflated Java Monitor (ObjectMonitor) checks.\n+    lock->set_displaced_header(markWord::unused_mark());\n@@ -529,8 +535,0 @@\n-static bool useHeavyMonitors() {\n-#if defined(X86) || defined(AARCH64) || defined(PPC64) || defined(RISCV64) || defined(S390)\n-  return LockingMode == LM_MONITOR;\n-#else\n-  return false;\n-#endif\n-}\n-\n@@ -546,0 +544,5 @@\n+\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    return LightweightSynchronizer::enter_for(obj, lock, locking_thread);\n+  }\n+\n@@ -562,2 +565,1 @@\n-void ObjectSynchronizer::enter(Handle obj, BasicLock* lock, JavaThread* current) {\n-  assert(current == Thread::current(), \"must be\");\n+void ObjectSynchronizer::enter_legacy(Handle obj, BasicLock* lock, JavaThread* current) {\n@@ -585,0 +587,2 @@\n+  assert(LockingMode != LM_LIGHTWEIGHT, \"Use LightweightSynchronizer\");\n+\n@@ -592,55 +596,1 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n-      \/\/ Fast-locking does not use the 'lock' argument.\n-      LockStack& lock_stack = locking_thread->lock_stack();\n-      if (lock_stack.is_full()) {\n-        \/\/ We unconditionally make room on the lock stack by inflating\n-        \/\/ the least recently locked object on the lock stack.\n-\n-        \/\/ About the choice to inflate least recently locked object.\n-        \/\/ First we must chose to inflate a lock, either some lock on\n-        \/\/ the lock-stack or the lock that is currently being entered\n-        \/\/ (which may or may not be on the lock-stack).\n-        \/\/ Second the best lock to inflate is a lock which is entered\n-        \/\/ in a control flow where there are only a very few locks being\n-        \/\/ used, as the costly part of inflated locking is inflation,\n-        \/\/ not locking. But this property is entirely program dependent.\n-        \/\/ Third inflating the lock currently being entered on when it\n-        \/\/ is not present on the lock-stack will result in a still full\n-        \/\/ lock-stack. This creates a scenario where every deeper nested\n-        \/\/ monitorenter must call into the runtime.\n-        \/\/ The rational here is as follows:\n-        \/\/ Because we cannot (currently) figure out the second, and want\n-        \/\/ to avoid the third, we inflate a lock on the lock-stack.\n-        \/\/ The least recently locked lock is chosen as it is the lock\n-        \/\/ with the longest critical section.\n-\n-        log_info(monitorinflation)(\"LockStack capacity exceeded, inflating.\");\n-        ObjectMonitor* monitor = inflate_for(locking_thread, lock_stack.bottom(), inflate_cause_vm_internal);\n-        assert(monitor->owner() == Thread::current(), \"must be owner=\" PTR_FORMAT \" current=\" PTR_FORMAT \" mark=\" PTR_FORMAT,\n-               p2i(monitor->owner()), p2i(Thread::current()), monitor->object()->mark_acquire().value());\n-        assert(!lock_stack.is_full(), \"must have made room here\");\n-      }\n-\n-      markWord mark = obj()->mark_acquire();\n-      while (mark.is_unlocked()) {\n-        \/\/ Retry until a lock state change has been observed. cas_set_mark() may collide with non lock bits modifications.\n-        \/\/ Try to swing into 'fast-locked' state.\n-        assert(!lock_stack.contains(obj()), \"thread must not already hold the lock\");\n-        const markWord locked_mark = mark.set_fast_locked();\n-        const markWord old_mark = obj()->cas_set_mark(locked_mark, mark);\n-        if (old_mark == mark) {\n-          \/\/ Successfully fast-locked, push object to lock-stack and return.\n-          lock_stack.push(obj());\n-          return true;\n-        }\n-        mark = old_mark;\n-      }\n-\n-      if (mark.is_fast_locked() && lock_stack.try_recursive_enter(obj())) {\n-        \/\/ Recursive lock successful.\n-        return true;\n-      }\n-\n-      \/\/ Failed to fast lock.\n-      return false;\n-    } else if (LockingMode == LM_LEGACY) {\n+    if (LockingMode == LM_LEGACY) {\n@@ -679,2 +629,2 @@\n-void ObjectSynchronizer::exit(oop object, BasicLock* lock, JavaThread* current) {\n-  current->dec_held_monitor_count();\n+void ObjectSynchronizer::exit_legacy(oop object, BasicLock* lock, JavaThread* current) {\n+  assert(LockingMode != LM_LIGHTWEIGHT, \"Use LightweightSynchronizer\");\n@@ -687,26 +637,1 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n-      \/\/ Fast-locking does not use the 'lock' argument.\n-      LockStack& lock_stack = current->lock_stack();\n-      if (mark.is_fast_locked() && lock_stack.try_recursive_exit(object)) {\n-        \/\/ Recursively unlocked.\n-        return;\n-      }\n-\n-      if (mark.is_fast_locked() && lock_stack.is_recursive(object)) {\n-        \/\/ This lock is recursive but is not at the top of the lock stack so we're\n-        \/\/ doing an unbalanced exit. We have to fall thru to inflation below and\n-        \/\/ let ObjectMonitor::exit() do the unlock.\n-      } else {\n-        while (mark.is_fast_locked()) {\n-          \/\/ Retry until a lock state change has been observed. cas_set_mark() may collide with non lock bits modifications.\n-          const markWord unlocked_mark = mark.set_unlocked();\n-          const markWord old_mark = object->cas_set_mark(unlocked_mark, mark);\n-          if (old_mark == mark) {\n-            size_t recursions = lock_stack.remove(object) - 1;\n-            assert(recursions == 0, \"must not be recursive here\");\n-            return;\n-          }\n-          mark = old_mark;\n-        }\n-      }\n-    } else if (LockingMode == LM_LEGACY) {\n+    if (LockingMode == LM_LEGACY) {\n@@ -734,1 +659,1 @@\n-            ObjectMonitor* m = mark.monitor();\n+            ObjectMonitor* m = read_monitor(mark);\n@@ -789,2 +714,10 @@\n-    ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_jni_enter);\n-    if (monitor->enter(current)) {\n+    ObjectMonitor* monitor;\n+    bool entered;\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      entered = LightweightSynchronizer::inflate_and_enter(obj(), inflate_cause_jni_enter, current, current) != nullptr;\n+    } else {\n+      monitor = inflate(current, obj(), inflate_cause_jni_enter);\n+      entered = monitor->enter(current);\n+    }\n+\n+    if (entered) {\n@@ -803,3 +736,8 @@\n-  \/\/ The ObjectMonitor* can't be async deflated until ownership is\n-  \/\/ dropped inside exit() and the ObjectMonitor* must be !is_busy().\n-  ObjectMonitor* monitor = inflate(current, obj, inflate_cause_jni_exit);\n+  ObjectMonitor* monitor;\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    monitor = LightweightSynchronizer::inflate_locked_or_imse(obj, inflate_cause_jni_exit, CHECK);\n+  } else {\n+    \/\/ The ObjectMonitor* can't be async deflated until ownership is\n+    \/\/ dropped inside exit() and the ObjectMonitor* must be !is_busy().\n+    monitor = inflate(current, obj, inflate_cause_jni_exit);\n+  }\n@@ -838,0 +776,1 @@\n+\n@@ -844,4 +783,10 @@\n-  \/\/ The ObjectMonitor* can't be async deflated because the _waiters\n-  \/\/ field is incremented before ownership is dropped and decremented\n-  \/\/ after ownership is regained.\n-  ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_wait);\n+\n+  ObjectMonitor* monitor;\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    monitor = LightweightSynchronizer::inflate_locked_or_imse(obj(), inflate_cause_wait, CHECK_0);\n+  } else {\n+    \/\/ The ObjectMonitor* can't be async deflated because the _waiters\n+    \/\/ field is incremented before ownership is dropped and decremented\n+    \/\/ after ownership is regained.\n+    monitor = inflate(current, obj(), inflate_cause_wait);\n+  }\n@@ -864,3 +809,8 @@\n-  ObjectSynchronizer::inflate(THREAD,\n-                              obj(),\n-                              inflate_cause_wait)->wait(millis, false, THREAD);\n+\n+  ObjectMonitor* monitor;\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    monitor = LightweightSynchronizer::inflate_locked_or_imse(obj(), inflate_cause_wait, CHECK);\n+  } else {\n+    monitor = inflate(THREAD, obj(), inflate_cause_wait);\n+  }\n+  monitor->wait(millis, false, THREAD);\n@@ -886,3 +836,9 @@\n-  \/\/ The ObjectMonitor* can't be async deflated until ownership is\n-  \/\/ dropped by the calling thread.\n-  ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_notify);\n+\n+  ObjectMonitor* monitor;\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    monitor = LightweightSynchronizer::inflate_locked_or_imse(obj(), inflate_cause_notify, CHECK);\n+  } else {\n+    \/\/ The ObjectMonitor* can't be async deflated until ownership is\n+    \/\/ dropped by the calling thread.\n+    monitor = inflate(current, obj(), inflate_cause_notify);\n+  }\n@@ -909,3 +865,9 @@\n-  \/\/ The ObjectMonitor* can't be async deflated until ownership is\n-  \/\/ dropped by the calling thread.\n-  ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_notify);\n+\n+  ObjectMonitor* monitor;\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    monitor = LightweightSynchronizer::inflate_locked_or_imse(obj(), inflate_cause_notify, CHECK);\n+  } else {\n+    \/\/ The ObjectMonitor* can't be async deflated until ownership is\n+    \/\/ dropped by the calling thread.\n+    monitor = inflate(current, obj(), inflate_cause_notify);\n+  }\n@@ -1009,1 +971,1 @@\n-static inline intptr_t get_next_hash(Thread* current, oop obj) {\n+static intptr_t get_next_hash(Thread* current, oop obj) {\n@@ -1049,0 +1011,21 @@\n+static intptr_t install_hash_code(Thread* current, oop obj) {\n+  assert(UseObjectMonitorTable && LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+\n+  markWord mark = obj->mark_acquire();\n+  for (;;) {\n+    intptr_t hash = mark.hash();\n+    if (hash != 0) {\n+      return hash;\n+    }\n+\n+    hash = get_next_hash(current, obj);\n+    const markWord old_mark = mark;\n+    const markWord new_mark = old_mark.copy_set_hash(hash);\n+\n+    mark = obj->cas_set_mark(new_mark, old_mark);\n+    if (old_mark == mark) {\n+      return hash;\n+    }\n+  }\n+}\n+\n@@ -1054,0 +1037,5 @@\n+  if (UseObjectMonitorTable) {\n+    \/\/ Since the monitor isn't in the object header, the hash can simply be\n+    \/\/ installed in the object header.\n+    return install_hash_code(current, obj);\n+  }\n@@ -1147,1 +1135,1 @@\n-      uintptr_t v = Atomic::cmpxchg((volatile uintptr_t*)monitor->header_addr(), mark.value(), temp.value());\n+      uintptr_t v = Atomic::cmpxchg(monitor->metadata_addr(), mark.value(), temp.value());\n@@ -1159,1 +1147,1 @@\n-      if (monitor->is_being_async_deflated()) {\n+      if (monitor->is_being_async_deflated() && !UseObjectMonitorTable) {\n@@ -1193,1 +1181,15 @@\n-  if (mark.has_monitor()) {\n+  while (LockingMode == LM_LIGHTWEIGHT && mark.has_monitor()) {\n+    ObjectMonitor* monitor = read_monitor(current, obj, mark);\n+    if (monitor != nullptr) {\n+      return monitor->is_entered(current) != 0;\n+    }\n+    \/\/ Racing with inflation\/deflation, retry\n+    mark = obj->mark_acquire();\n+\n+    if (mark.is_fast_locked()) {\n+      \/\/ Some other thread fast_locked, current could not have held the lock\n+      return false;\n+    }\n+  }\n+\n+  if (LockingMode != LM_LIGHTWEIGHT && mark.has_monitor()) {\n@@ -1197,1 +1199,1 @@\n-    ObjectMonitor* monitor = mark.monitor();\n+    ObjectMonitor* monitor = read_monitor(mark);\n@@ -1221,1 +1223,15 @@\n-  if (mark.has_monitor()) {\n+  while (LockingMode == LM_LIGHTWEIGHT && mark.has_monitor()) {\n+    ObjectMonitor* monitor = read_monitor(Thread::current(), obj, mark);\n+    if (monitor != nullptr) {\n+      return Threads::owning_thread_from_monitor(t_list, monitor);\n+    }\n+    \/\/ Racing with inflation\/deflation, retry\n+    mark = obj->mark_acquire();\n+\n+    if (mark.is_fast_locked()) {\n+      \/\/ Some other thread fast_locked\n+      return Threads::owning_thread_from_object(t_list, h_obj());\n+    }\n+  }\n+\n+  if (LockingMode != LM_LIGHTWEIGHT && mark.has_monitor()) {\n@@ -1225,1 +1241,1 @@\n-    ObjectMonitor* monitor = mark.monitor();\n+    ObjectMonitor* monitor = read_monitor(mark);\n@@ -1437,0 +1453,1 @@\n+  assert(LockingMode != LM_LIGHTWEIGHT, \"only inflate through enter\");\n@@ -1439,1 +1456,1 @@\n-    ObjectMonitor* monitor = mark.monitor();\n+    ObjectMonitor* monitor = read_monitor(mark);\n@@ -1449,4 +1466,2 @@\n-  if (LockingMode == LM_LIGHTWEIGHT && current->is_Java_thread()) {\n-    return inflate_impl(JavaThread::cast(current), obj, cause);\n-  }\n-  return inflate_impl(nullptr, obj, cause);\n+  assert(LockingMode != LM_LIGHTWEIGHT, \"only inflate through enter\");\n+  return inflate_impl(obj, cause);\n@@ -1457,1 +1472,2 @@\n-  return inflate_impl(thread, obj, cause);\n+  assert(LockingMode != LM_LIGHTWEIGHT, \"LM_LIGHTWEIGHT cannot use inflate_for\");\n+  return inflate_impl(obj, cause);\n@@ -1460,1 +1476,1 @@\n-ObjectMonitor* ObjectSynchronizer::inflate_impl(JavaThread* inflating_thread, oop object, const InflateCause cause) {\n+ObjectMonitor* ObjectSynchronizer::inflate_impl(oop object, const InflateCause cause) {\n@@ -1464,8 +1480,1 @@\n-  \/\/ The JavaThread* inflating_thread parameter is only used by LM_LIGHTWEIGHT and requires\n-  \/\/ that the inflating_thread == Thread::current() or is suspended throughout the call by\n-  \/\/ some other mechanism.\n-  \/\/ Even with LM_LIGHTWEIGHT the thread might be nullptr when called from a non\n-  \/\/ JavaThread. (As may still be the case from FastHashCode). However it is only\n-  \/\/ important for the correctness of the LM_LIGHTWEIGHT algorithm that the thread\n-  \/\/ is set when called from ObjectSynchronizer::enter from the owning thread,\n-  \/\/ ObjectSynchronizer::enter_for from any thread, or ObjectSynchronizer::exit.\n+  assert(LockingMode != LM_LIGHTWEIGHT, \"LM_LIGHTWEIGHT cannot use inflate_impl\");\n@@ -1478,7 +1487,1 @@\n-    \/\/ *  inflated     - Just return if using stack-locking.\n-    \/\/                   If using fast-locking and the ObjectMonitor owner\n-    \/\/                   is anonymous and the inflating_thread owns the\n-    \/\/                   object lock, then we make the inflating_thread\n-    \/\/                   the ObjectMonitor owner and remove the lock from\n-    \/\/                   the inflating_thread's lock stack.\n-    \/\/ *  fast-locked  - Coerce it to inflated from fast-locked.\n+    \/\/ *  inflated     - Just return it.\n@@ -1495,6 +1498,0 @@\n-      if (LockingMode == LM_LIGHTWEIGHT && inf->is_owner_anonymous() &&\n-          inflating_thread != nullptr && inflating_thread->lock_stack().contains(object)) {\n-        inf->set_owner_from_anonymous(inflating_thread);\n-        size_t removed = inflating_thread->lock_stack().remove(object);\n-        inf->set_recursions(removed - 1);\n-      }\n@@ -1504,65 +1501,9 @@\n-    if (LockingMode != LM_LIGHTWEIGHT) {\n-      \/\/ New lightweight locking does not use INFLATING.\n-      \/\/ CASE: inflation in progress - inflating over a stack-lock.\n-      \/\/ Some other thread is converting from stack-locked to inflated.\n-      \/\/ Only that thread can complete inflation -- other threads must wait.\n-      \/\/ The INFLATING value is transient.\n-      \/\/ Currently, we spin\/yield\/park and poll the markword, waiting for inflation to finish.\n-      \/\/ We could always eliminate polling by parking the thread on some auxiliary list.\n-      if (mark == markWord::INFLATING()) {\n-        read_stable_mark(object);\n-        continue;\n-      }\n-    }\n-\n-    \/\/ CASE: fast-locked\n-    \/\/ Could be fast-locked either by the inflating_thread or by some other thread.\n-    \/\/\n-    \/\/ Note that we allocate the ObjectMonitor speculatively, _before_\n-    \/\/ attempting to set the object's mark to the new ObjectMonitor. If\n-    \/\/ the inflating_thread owns the monitor, then we set the ObjectMonitor's\n-    \/\/ owner to the inflating_thread. Otherwise, we set the ObjectMonitor's owner\n-    \/\/ to anonymous. If we lose the race to set the object's mark to the\n-    \/\/ new ObjectMonitor, then we just delete it and loop around again.\n-    \/\/\n-    LogStreamHandle(Trace, monitorinflation) lsh;\n-    if (LockingMode == LM_LIGHTWEIGHT && mark.is_fast_locked()) {\n-      ObjectMonitor* monitor = new ObjectMonitor(object);\n-      monitor->set_header(mark.set_unlocked());\n-      bool own = inflating_thread != nullptr && inflating_thread->lock_stack().contains(object);\n-      if (own) {\n-        \/\/ Owned by inflating_thread.\n-        monitor->set_owner_from(nullptr, inflating_thread);\n-      } else {\n-        \/\/ Owned by somebody else.\n-        monitor->set_owner_anonymous();\n-      }\n-      markWord monitor_mark = markWord::encode(monitor);\n-      markWord old_mark = object->cas_set_mark(monitor_mark, mark);\n-      if (old_mark == mark) {\n-        \/\/ Success! Return inflated monitor.\n-        if (own) {\n-          size_t removed = inflating_thread->lock_stack().remove(object);\n-          monitor->set_recursions(removed - 1);\n-        }\n-        \/\/ Once the ObjectMonitor is configured and object is associated\n-        \/\/ with the ObjectMonitor, it is safe to allow async deflation:\n-        _in_use_list.add(monitor);\n-\n-        \/\/ Hopefully the performance counters are allocated on distinct\n-        \/\/ cache lines to avoid false sharing on MP systems ...\n-        OM_PERFDATA_OP(Inflations, inc());\n-        if (log_is_enabled(Trace, monitorinflation)) {\n-          ResourceMark rm;\n-          lsh.print_cr(\"inflate(has_locker): object=\" INTPTR_FORMAT \", mark=\"\n-                       INTPTR_FORMAT \", type='%s'\", p2i(object),\n-                       object->mark().value(), object->klass()->external_name());\n-        }\n-        if (event.should_commit()) {\n-          post_monitor_inflate_event(&event, object, cause);\n-        }\n-        return monitor;\n-      } else {\n-        delete monitor;\n-        continue;  \/\/ Interference -- just retry\n-      }\n+    \/\/ CASE: inflation in progress - inflating over a stack-lock.\n+    \/\/ Some other thread is converting from stack-locked to inflated.\n+    \/\/ Only that thread can complete inflation -- other threads must wait.\n+    \/\/ The INFLATING value is transient.\n+    \/\/ Currently, we spin\/yield\/park and poll the markword, waiting for inflation to finish.\n+    \/\/ We could always eliminate polling by parking the thread on some auxiliary list.\n+    if (mark == markWord::INFLATING()) {\n+      read_stable_mark(object);\n+      continue;\n@@ -1582,0 +1523,1 @@\n+    LogStreamHandle(Trace, monitorinflation) lsh;\n@@ -1583,1 +1525,0 @@\n-      assert(LockingMode != LM_LIGHTWEIGHT, \"cannot happen with new lightweight locking\");\n@@ -1715,0 +1656,1 @@\n+  Thread* current = Thread::current();\n@@ -1721,1 +1663,1 @@\n-    if (mid->deflate_monitor()) {\n+    if (mid->deflate_monitor(current)) {\n@@ -1739,0 +1681,5 @@\n+    if (thread->is_Java_thread()) {\n+      \/\/ Clear OM cache\n+      JavaThread* jt = JavaThread::cast(thread);\n+      jt->om_clear_monitor_cache();\n+    }\n@@ -1885,0 +1832,8 @@\n+#ifdef ASSERT\n+    if (UseObjectMonitorTable) {\n+      for (ObjectMonitor* monitor : delete_list) {\n+        assert(!LightweightSynchronizer::contains_monitor(current, monitor), \"Should have been removed\");\n+      }\n+    }\n+#endif\n+\n@@ -2093,1 +2048,2 @@\n-  if (n->header().value() == 0) {\n+\n+  if (n->metadata() == 0) {\n@@ -2095,1 +2051,1 @@\n-                  \"have non-null _header field.\", p2i(n));\n+                  \"have non-null _metadata (header\/hash) field.\", p2i(n));\n@@ -2098,0 +2054,1 @@\n+\n@@ -2099,17 +2056,21 @@\n-  if (obj != nullptr) {\n-    const markWord mark = obj->mark();\n-    if (!mark.has_monitor()) {\n-      out->print_cr(\"ERROR: monitor=\" INTPTR_FORMAT \": in-use monitor's \"\n-                    \"object does not think it has a monitor: obj=\"\n-                    INTPTR_FORMAT \", mark=\" INTPTR_FORMAT, p2i(n),\n-                    p2i(obj), mark.value());\n-      *error_cnt_p = *error_cnt_p + 1;\n-    }\n-    ObjectMonitor* const obj_mon = mark.monitor();\n-    if (n != obj_mon) {\n-      out->print_cr(\"ERROR: monitor=\" INTPTR_FORMAT \": in-use monitor's \"\n-                    \"object does not refer to the same monitor: obj=\"\n-                    INTPTR_FORMAT \", mark=\" INTPTR_FORMAT \", obj_mon=\"\n-                    INTPTR_FORMAT, p2i(n), p2i(obj), mark.value(), p2i(obj_mon));\n-      *error_cnt_p = *error_cnt_p + 1;\n-    }\n+  if (obj == nullptr) {\n+    return;\n+  }\n+\n+  const markWord mark = obj->mark();\n+  if (!mark.has_monitor()) {\n+    out->print_cr(\"ERROR: monitor=\" INTPTR_FORMAT \": in-use monitor's \"\n+                  \"object does not think it has a monitor: obj=\"\n+                  INTPTR_FORMAT \", mark=\" INTPTR_FORMAT, p2i(n),\n+                  p2i(obj), mark.value());\n+    *error_cnt_p = *error_cnt_p + 1;\n+    return;\n+  }\n+\n+  ObjectMonitor* const obj_mon = read_monitor(Thread::current(), obj, mark);\n+  if (n != obj_mon) {\n+    out->print_cr(\"ERROR: monitor=\" INTPTR_FORMAT \": in-use monitor's \"\n+                  \"object does not refer to the same monitor: obj=\"\n+                  INTPTR_FORMAT \", mark=\" INTPTR_FORMAT \", obj_mon=\"\n+                  INTPTR_FORMAT, p2i(n), p2i(obj), mark.value(), p2i(obj_mon));\n+    *error_cnt_p = *error_cnt_p + 1;\n@@ -2138,1 +2099,1 @@\n-        const markWord mark = monitor->header();\n+        const intptr_t hash = UseObjectMonitorTable ? monitor->hash() : monitor->header().hash();\n@@ -2141,1 +2102,1 @@\n-                   monitor->is_busy(), mark.hash() != 0, monitor->owner() != nullptr,\n+                   monitor->is_busy(), hash != 0, monitor->owner() != nullptr,\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":227,"deletions":266,"binary":false,"changes":493,"status":"modified"},{"patch":"@@ -90,1 +90,2 @@\n-  template(JFRCheckpoint)                         \\\n+  template(JFRSafepointClear)                     \\\n+  template(JFRSafepointWrite)                     \\\n","filename":"src\/hotspot\/share\/runtime\/vmOperation.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -251,1 +251,0 @@\n-  nonstatic_field(InstanceKlass,               _is_marked_dependent,                          bool)                                  \\\n@@ -783,1 +782,1 @@\n-  volatile_nonstatic_field(ObjectMonitor,      _header,                                       markWord)                              \\\n+  volatile_nonstatic_field(ObjectMonitor,      _metadata,                                     uintptr_t)                             \\\n@@ -787,1 +786,1 @@\n-  volatile_nonstatic_field(BasicLock,          _displaced_header,                             markWord)                              \\\n+  volatile_nonstatic_field(BasicLock,          _metadata,                                     uintptr_t)                             \\\n@@ -1429,0 +1428,1 @@\n+  declare_c2_type(ForwardExceptionNode, ReturnNode)                       \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -316,0 +316,3 @@\n+#define THROW_HANDLE_NULL(e)                THROW_HANDLE_(e, nullptr)\n+#define THROW_ARG_NULL(name, signature, arg) THROW_ARG_(name, signature, arg, nullptr)\n+\n","filename":"src\/hotspot\/share\/utilities\/exceptions.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1996, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1996, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -1284,1 +1284,1 @@\n-        if (cl != null && isCustomSubclass()) {\n+        if (isCustomSubclass()) {\n","filename":"src\/java.base\/share\/classes\/java\/io\/ObjectOutputStream.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2627,0 +2627,4 @@\n+            public Object stringConcat1(String[] constants) {\n+                return new StringConcatHelper.Concat1(constants);\n+            }\n+\n","filename":"src\/java.base\/share\/classes\/java\/lang\/System.java","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -70,1 +70,1 @@\n- * Models a classfile attribute {@jvms 4.7}.  Many, though not all, subtypes of\n+ * Models a classfile attribute (JVMS {@jvms 4.7}).  Many, though not all, subtypes of\n","filename":"src\/java.base\/share\/classes\/java\/lang\/classfile\/Attribute.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -29,2 +29,2 @@\n- * modifying Java class files, as specified in Chapter {@jvms 4} of the <cite>Java\n- * Java Virtual Machine Specification<\/cite>.\n+ * modifying Java class files, as specified in Chapter {@jvms 4} of the\n+ * <cite>Java Virtual Machine Specification<\/cite>.\n","filename":"src\/java.base\/share\/classes\/java\/lang\/classfile\/package-info.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -84,14 +84,0 @@\n-    \/\/ Static builders to avoid lambdas\n-    record FieldFlags(int flags) implements Consumer<FieldBuilder> {\n-        @Override\n-        public void accept(FieldBuilder fb) {\n-            fb.withFlags(flags);\n-        }\n-    };\n-    record MethodBody(Consumer<CodeBuilder> code) implements Consumer<MethodBuilder> {\n-        @Override\n-        public void accept(MethodBuilder mb) {\n-            mb.withCode(code);\n-        }\n-    };\n-\n@@ -343,1 +329,1 @@\n-                    clb.withField(argNames[i], argDescs[i], new FieldFlags(ACC_PRIVATE | ACC_FINAL));\n+                    clb.withField(argNames[i], argDescs[i], ACC_PRIVATE | ACC_FINAL);\n@@ -353,1 +339,1 @@\n-                clb.withMethod(interfaceMethodName,\n+                clb.withMethodBody(interfaceMethodName,\n@@ -361,1 +347,1 @@\n-                        clb.withMethod(interfaceMethodName,\n+                        clb.withMethodBody(interfaceMethodName,\n@@ -395,1 +381,1 @@\n-        clb.withField(LAMBDA_INSTANCE_FIELD, lambdaTypeDescriptor, new FieldFlags(ACC_PRIVATE | ACC_STATIC | ACC_FINAL));\n+        clb.withField(LAMBDA_INSTANCE_FIELD, lambdaTypeDescriptor, ACC_PRIVATE | ACC_STATIC | ACC_FINAL);\n@@ -398,1 +384,1 @@\n-        clb.withMethod(CLASS_INIT_NAME, MTD_void, ACC_STATIC, new MethodBody(new Consumer<CodeBuilder>() {\n+        clb.withMethodBody(CLASS_INIT_NAME, MTD_void, ACC_STATIC, new Consumer<>() {\n@@ -408,1 +394,1 @@\n-        }));\n+        });\n@@ -416,2 +402,2 @@\n-        clb.withMethod(INIT_NAME, constructorTypeDesc, ACC_PRIVATE,\n-                new MethodBody(new Consumer<CodeBuilder>() {\n+        clb.withMethodBody(INIT_NAME, constructorTypeDesc, ACC_PRIVATE,\n+                new Consumer<>() {\n@@ -431,1 +417,1 @@\n-                }));\n+                });\n@@ -458,2 +444,2 @@\n-        clb.withMethod(SerializationSupport.NAME_METHOD_WRITE_REPLACE, SerializationSupport.MTD_Object, ACC_PRIVATE | ACC_FINAL,\n-                new MethodBody(new Consumer<CodeBuilder>() {\n+        clb.withMethodBody(SerializationSupport.NAME_METHOD_WRITE_REPLACE, SerializationSupport.MTD_Object, ACC_PRIVATE | ACC_FINAL,\n+                new Consumer<>() {\n@@ -487,1 +473,1 @@\n-                }));\n+                });\n@@ -523,2 +509,2 @@\n-    Consumer<MethodBuilder> forwardingMethod(MethodType methodType) {\n-        return new MethodBody(new Consumer<CodeBuilder>() {\n+    Consumer<CodeBuilder> forwardingMethod(MethodType methodType) {\n+        return new Consumer<>() {\n@@ -561,1 +547,1 @@\n-        });\n+        };\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/InnerClassLambdaMetafactory.java","additions":15,"deletions":29,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,1 @@\n-import jdk.internal.reflect.MethodAccessor;\n+import jdk.internal.access.JavaLangReflectAccess;\n@@ -34,53 +34,3 @@\n-\n-class ReflectAccess implements jdk.internal.access.JavaLangReflectAccess {\n-    public <T> Constructor<T> newConstructor(Class<T> declaringClass,\n-                                             Class<?>[] parameterTypes,\n-                                             Class<?>[] checkedExceptions,\n-                                             int modifiers,\n-                                             int slot,\n-                                             String signature,\n-                                             byte[] annotations,\n-                                             byte[] parameterAnnotations)\n-    {\n-        return new Constructor<>(declaringClass,\n-                                  parameterTypes,\n-                                  checkedExceptions,\n-                                  modifiers,\n-                                  slot,\n-                                  signature,\n-                                  annotations,\n-                                  parameterAnnotations);\n-    }\n-\n-    public MethodAccessor getMethodAccessor(Method m) {\n-        return m.getMethodAccessor();\n-    }\n-\n-    public void setMethodAccessor(Method m, MethodAccessor accessor) {\n-        m.setMethodAccessor(accessor);\n-    }\n-\n-    public ConstructorAccessor getConstructorAccessor(Constructor<?> c) {\n-        return c.getConstructorAccessor();\n-    }\n-\n-    public void setConstructorAccessor(Constructor<?> c,\n-                                       ConstructorAccessor accessor)\n-    {\n-        c.setConstructorAccessor(accessor);\n-    }\n-\n-    public int getConstructorSlot(Constructor<?> c) {\n-        return c.getSlot();\n-    }\n-\n-    public String getConstructorSignature(Constructor<?> c) {\n-        return c.getSignature();\n-    }\n-\n-    public byte[] getConstructorAnnotations(Constructor<?> c) {\n-        return c.getRawAnnotations();\n-    }\n-\n-    public byte[] getConstructorParameterAnnotations(Constructor<?> c) {\n-        return c.getRawParameterAnnotations();\n+final class ReflectAccess implements JavaLangReflectAccess {\n+    public <T> Constructor<T> newConstructorWithAccessor(Constructor<T> original, ConstructorAccessor accessor) {\n+        return original.newWithAccessor(accessor);\n@@ -108,3 +58,0 @@\n-    public Method      leafCopyMethod(Method arg) {\n-        return arg.leafCopy();\n-    }\n","filename":"src\/java.base\/share\/classes\/java\/lang\/reflect\/ReflectAccess.java","additions":5,"deletions":58,"binary":false,"changes":63,"status":"modified"},{"patch":"@@ -59,0 +59,1 @@\n+import java.util.Arrays;\n@@ -98,3 +99,1 @@\n-        private static final MethodHandle NULL_CHECK;\n-        private static final MethodHandle IS_ZERO;\n-        private static final MethodHandle MAPPED_ENUM_LOOKUP;\n+        private static final MethodHandle MAPPED_ENUM_SWITCH;\n@@ -104,7 +103,3 @@\n-                NULL_CHECK = LOOKUP.findStatic(Objects.class, \"isNull\",\n-                                               MethodType.methodType(boolean.class, Object.class));\n-                IS_ZERO = LOOKUP.findStatic(SwitchBootstraps.class, \"isZero\",\n-                                               MethodType.methodType(boolean.class, int.class));\n-                MAPPED_ENUM_LOOKUP = LOOKUP.findStatic(SwitchBootstraps.class, \"mappedEnumLookup\",\n-                                                       MethodType.methodType(int.class, Enum.class, MethodHandles.Lookup.class,\n-                                                                             Class.class, EnumDesc[].class, EnumMap.class));\n+                MAPPED_ENUM_SWITCH = LOOKUP.findStatic(SwitchBootstraps.class, \"mappedEnumSwitch\",\n+                                                       MethodType.methodType(int.class, Enum.class, int.class, MethodHandles.Lookup.class,\n+                                                                             Class.class, EnumDesc[].class, MappedEnumCache.class));\n@@ -214,4 +209,0 @@\n-    private static boolean isZero(int value) {\n-        return value == 0;\n-    }\n-\n@@ -289,1 +280,10 @@\n-        labels = Stream.of(labels).map(l -> convertEnumConstants(lookup, enumClass, l)).toArray();\n+        boolean constantsOnly = true;\n+        int len = labels.length;\n+\n+        for (int i = 0; i < len; i++) {\n+            Object convertedLabel =\n+                    convertEnumConstants(lookup, enumClass, labels[i]);\n+            labels[i] = convertedLabel;\n+            if (constantsOnly)\n+                constantsOnly = convertedLabel instanceof EnumDesc;\n+        }\n@@ -292,1 +292,0 @@\n-        boolean constantsOnly = Stream.of(labels).allMatch(l -> enumClass.isAssignableFrom(EnumDesc.class));\n@@ -299,7 +298,3 @@\n-            MethodHandle body =\n-                    MethodHandles.guardWithTest(MethodHandles.dropArguments(StaticHolders.NULL_CHECK, 0, int.class),\n-                                                MethodHandles.dropArguments(MethodHandles.constant(int.class, -1), 0, int.class, Object.class),\n-                                                MethodHandles.guardWithTest(MethodHandles.dropArguments(StaticHolders.IS_ZERO, 1, Object.class),\n-                                                                            generateTypeSwitch(lookup, invocationType.parameterType(0), labels),\n-                                                                            MethodHandles.insertArguments(StaticHolders.MAPPED_ENUM_LOOKUP, 1, lookup, enumClass, labels, new EnumMap())));\n-            target = MethodHandles.permuteArguments(body, MethodType.methodType(int.class, Object.class, int.class), 1, 0);\n+            EnumDesc<?>[] enumDescLabels =\n+                    Arrays.copyOf(labels, labels.length, EnumDesc[].class);\n+            target = MethodHandles.insertArguments(StaticHolders.MAPPED_ENUM_SWITCH, 2, lookup, enumClass, enumDescLabels, new MappedEnumCache());\n@@ -334,8 +329,4 @@\n-    private static <T extends Enum<T>> int mappedEnumLookup(T value, MethodHandles.Lookup lookup, Class<T> enumClass, EnumDesc<?>[] labels, EnumMap enumMap) {\n-        if (enumMap.map == null) {\n-            T[] constants = SharedSecrets.getJavaLangAccess().getEnumConstantsShared(enumClass);\n-            int[] map = new int[constants.length];\n-            int ordinal = 0;\n-\n-            for (T constant : constants) {\n-                map[ordinal] = labels.length;\n+    private static <T extends Enum<T>> int mappedEnumSwitch(T value, int restartIndex, MethodHandles.Lookup lookup, Class<T> enumClass, EnumDesc<?>[] labels, MappedEnumCache enumCache) throws Throwable {\n+        if (value == null) {\n+            return -1;\n+        }\n@@ -343,4 +334,13 @@\n-                for (int i = 0; i < labels.length; i++) {\n-                    if (Objects.equals(labels[i].constantName(), constant.name())) {\n-                        map[ordinal] = i;\n-                        break;\n+        if (restartIndex != 0) {\n+            MethodHandle generatedSwitch = enumCache.generatedSwitch;\n+            if (generatedSwitch == null) {\n+                synchronized (enumCache) {\n+                    generatedSwitch = enumCache.generatedSwitch;\n+\n+                    if (generatedSwitch == null) {\n+                        generatedSwitch =\n+                                generateTypeSwitch(lookup, enumClass, labels)\n+                                        .asType(MethodType.methodType(int.class,\n+                                                                      Enum.class,\n+                                                                      int.class));\n+                        enumCache.generatedSwitch = generatedSwitch;\n@@ -349,0 +349,6 @@\n+            }\n+\n+            return (int) generatedSwitch.invokeExact(value, restartIndex);\n+        }\n+\n+        int[] constantsMap = enumCache.constantsMap;\n@@ -350,1 +356,26 @@\n-                ordinal++;\n+        if (constantsMap == null) {\n+            synchronized (enumCache) {\n+                constantsMap = enumCache.constantsMap;\n+\n+                if (constantsMap == null) {\n+                    T[] constants = SharedSecrets.getJavaLangAccess()\n+                                                 .getEnumConstantsShared(enumClass);\n+                    constantsMap = new int[constants.length];\n+                    int ordinal = 0;\n+\n+                    for (T constant : constants) {\n+                        constantsMap[ordinal] = labels.length;\n+\n+                        for (int i = 0; i < labels.length; i++) {\n+                            if (Objects.equals(labels[i].constantName(),\n+                                               constant.name())) {\n+                                constantsMap[ordinal] = i;\n+                                break;\n+                            }\n+                        }\n+\n+                        ordinal++;\n+                    }\n+\n+                    enumCache.constantsMap = constantsMap;\n+                }\n@@ -353,1 +384,2 @@\n-        return enumMap.map[value.ordinal()];\n+\n+        return constantsMap[value.ordinal()];\n@@ -398,1 +430,3 @@\n-    private static final class EnumMap {\n+    private static final class MappedEnumCache {\n+        @Stable\n+        public int[] constantsMap;\n@@ -400,1 +434,1 @@\n-        public int[] map;\n+        public MethodHandle generatedSwitch;\n","filename":"src\/java.base\/share\/classes\/java\/lang\/runtime\/SwitchBootstraps.java","additions":73,"deletions":39,"binary":false,"changes":112,"status":"modified"},{"patch":"@@ -450,0 +450,2 @@\n+    Object stringConcat1(String[] constants);\n+\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/access\/JavaLangAccess.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -32,2 +32,1 @@\n-    internals of java.lang.reflect. *\/\n-\n+    internals of java.lang.reflect. Use as a last resort! *\/\n@@ -35,25 +34,5 @@\n-    \/** Creates a new java.lang.reflect.Constructor. Access checks as\n-      per java.lang.reflect.AccessibleObject are not overridden. *\/\n-    public <T> Constructor<T> newConstructor(Class<T> declaringClass,\n-                                             Class<?>[] parameterTypes,\n-                                             Class<?>[] checkedExceptions,\n-                                             int modifiers,\n-                                             int slot,\n-                                             String signature,\n-                                             byte[] annotations,\n-                                             byte[] parameterAnnotations);\n-\n-    \/** Gets the MethodAccessor object for a java.lang.reflect.Method *\/\n-    public MethodAccessor getMethodAccessor(Method m);\n-\n-    \/** Sets the MethodAccessor object for a java.lang.reflect.Method *\/\n-    public void setMethodAccessor(Method m, MethodAccessor accessor);\n-\n-    \/** Gets the ConstructorAccessor object for a\n-        java.lang.reflect.Constructor *\/\n-    public ConstructorAccessor getConstructorAccessor(Constructor<?> c);\n-\n-    \/** Sets the ConstructorAccessor object for a\n-        java.lang.reflect.Constructor *\/\n-    public void setConstructorAccessor(Constructor<?> c,\n-                                       ConstructorAccessor accessor);\n+    \/**\n+     * Creates a new root constructor from the original one, with\n+     * a custom accessor. Used by serialization hooks.\n+     *\/\n+    <T> Constructor<T> newConstructorWithAccessor(Constructor<T> original, ConstructorAccessor accessor);\n@@ -64,12 +43,0 @@\n-    \/** Gets the \"slot\" field from a Constructor (used for serialization) *\/\n-    public int getConstructorSlot(Constructor<?> c);\n-\n-    \/** Gets the \"signature\" field from a Constructor (used for serialization) *\/\n-    public String getConstructorSignature(Constructor<?> c);\n-\n-    \/** Gets the \"annotations\" field from a Constructor (used for serialization) *\/\n-    public byte[] getConstructorAnnotations(Constructor<?> c);\n-\n-    \/** Gets the \"parameterAnnotations\" field from a Constructor (used for serialization) *\/\n-    public byte[] getConstructorParameterAnnotations(Constructor<?> c);\n-\n@@ -82,1 +49,0 @@\n-    \/\/\n@@ -85,1 +51,0 @@\n-    \/\/\n@@ -90,3 +55,0 @@\n-    \/** Makes a copy of this non-root a Method *\/\n-    public Method      leafCopyMethod(Method arg);\n-\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/access\/JavaLangReflectAccess.java","additions":7,"deletions":45,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -678,1 +678,1 @@\n-            AnnotationReader.writeAnnotations(buf, attr.annotations());\n+            AnnotationReader.writeTypeAnnotations(buf, attr.annotations());\n@@ -735,1 +735,1 @@\n-            AnnotationReader.writeAnnotations(buf, attr.annotations());\n+            AnnotationReader.writeTypeAnnotations(buf, attr.annotations());\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/classfile\/impl\/AbstractAttributeMapper.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -510,9 +510,9 @@\n-            case OfString cv -> leafs(\"string\", String.valueOf(cv.constantValue()));\n-            case OfDouble cv -> leafs(\"double\", String.valueOf(cv.constantValue()));\n-            case OfFloat cv -> leafs(\"float\", String.valueOf(cv.constantValue()));\n-            case OfLong cv -> leafs(\"long\", String.valueOf(cv.constantValue()));\n-            case OfInteger cv -> leafs(\"int\", String.valueOf(cv.constantValue()));\n-            case OfShort cv -> leafs(\"short\", String.valueOf(cv.constantValue()));\n-            case OfCharacter cv -> leafs(\"char\", String.valueOf(cv.constantValue()));\n-            case OfByte cv -> leafs(\"byte\", String.valueOf(cv.constantValue()));\n-            case OfBoolean cv -> leafs(\"boolean\", String.valueOf((int)cv.constantValue() != 0));\n+            case OfString cv -> leafs(\"string\", String.valueOf(cv.stringValue()));\n+            case OfDouble cv -> leafs(\"double\", String.valueOf(cv.doubleValue()));\n+            case OfFloat cv -> leafs(\"float\", String.valueOf(cv.floatValue()));\n+            case OfLong cv -> leafs(\"long\", String.valueOf(cv.longValue()));\n+            case OfInt cv -> leafs(\"int\", String.valueOf(cv.intValue()));\n+            case OfShort cv -> leafs(\"short\", String.valueOf(cv.shortValue()));\n+            case OfChar cv -> leafs(\"char\", String.valueOf(cv.charValue()));\n+            case OfByte cv -> leafs(\"byte\", String.valueOf(cv.byteValue()));\n+            case OfBoolean cv -> leafs(\"boolean\", String.valueOf(cv.booleanValue()));\n@@ -1044,1 +1044,1 @@\n-                        .with(leaf(\"annotation class\", a.className().stringValue()),\n+                        .with(leaf(\"annotation class\", a.annotation().className().stringValue()),\n@@ -1046,1 +1046,1 @@\n-                        .with(elementValuePairsToTree(a.elements()))));\n+                        .with(elementValuePairsToTree(a.annotation().elements()))));\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/classfile\/impl\/ClassPrinterImpl.java","additions":12,"deletions":12,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -407,3 +407,1 @@\n-                a.targetPath(), map(a.classSymbol()),\n-                a.elements().stream().map(el -> AnnotationElement.of(el.name(),\n-                        mapAnnotationValue(el.value()))).toList())).toList();\n+                a.targetPath(), mapAnnotation(a.annotation()))).toList();\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/classfile\/impl\/ClassRemapperImpl.java","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-import java.lang.classfile.AnnotationElement;\n@@ -39,1 +38,0 @@\n-import java.lang.classfile.Label;\n@@ -778,52 +776,1 @@\n-                                        Utf8Entry className,\n-                                        List<AnnotationElement> elements) implements TypeAnnotation, Util.Writable {\n-\n-        public UnboundTypeAnnotation(TargetInfo targetInfo, List<TypePathComponent> targetPath,\n-                                     Utf8Entry className, List<AnnotationElement> elements) {\n-            this.targetInfo = targetInfo;\n-            this.targetPath = List.copyOf(targetPath);\n-            this.className = className;\n-            this.elements = List.copyOf(elements);\n-        }\n-\n-        private int labelToBci(LabelContext lr, Label label) {\n-            \/\/helper method to avoid NPE\n-            if (lr == null) throw new IllegalArgumentException(\"Illegal targetType '%s' in TypeAnnotation outside of Code attribute\".formatted(targetInfo.targetType()));\n-            return lr.labelToBci(label);\n-        }\n-\n-        @Override\n-        public void writeTo(BufWriterImpl buf) {\n-            LabelContext lr = buf.labelContext();\n-            \/\/ target_type\n-            buf.writeU1(targetInfo.targetType().targetTypeValue());\n-\n-            \/\/ target_info\n-            switch (targetInfo) {\n-                case TypeParameterTarget tpt -> buf.writeU1(tpt.typeParameterIndex());\n-                case SupertypeTarget st -> buf.writeU2(st.supertypeIndex());\n-                case TypeParameterBoundTarget tpbt -> {\n-                    buf.writeU1(tpbt.typeParameterIndex());\n-                    buf.writeU1(tpbt.boundIndex());\n-                }\n-                case EmptyTarget et -> {\n-                    \/\/ nothing to write\n-                }\n-                case FormalParameterTarget fpt -> buf.writeU1(fpt.formalParameterIndex());\n-                case ThrowsTarget tt -> buf.writeU2(tt.throwsTargetIndex());\n-                case LocalVarTarget lvt -> {\n-                    buf.writeU2(lvt.table().size());\n-                    for (var e : lvt.table()) {\n-                        int startPc = labelToBci(lr, e.startLabel());\n-                        buf.writeU2(startPc);\n-                        buf.writeU2(labelToBci(lr, e.endLabel()) - startPc);\n-                        buf.writeU2(e.index());\n-                    }\n-                }\n-                case CatchTarget ct -> buf.writeU2(ct.exceptionTableIndex());\n-                case OffsetTarget ot -> buf.writeU2(labelToBci(lr, ot.target()));\n-                case TypeArgumentTarget tat -> {\n-                    buf.writeU2(labelToBci(lr, tat.target()));\n-                    buf.writeU1(tat.typeArgumentIndex());\n-                }\n-            }\n+                                        Annotation annotation) implements TypeAnnotation {\n@@ -831,16 +778,2 @@\n-            \/\/ target_path\n-            buf.writeU1(targetPath().size());\n-            for (TypePathComponent component : targetPath()) {\n-                buf.writeU1(component.typePathKind().tag());\n-                buf.writeU1(component.typeArgumentIndex());\n-            }\n-\n-            \/\/ type_index\n-            buf.writeIndex(className);\n-\n-            \/\/ element_value_pairs\n-            buf.writeU2(elements.size());\n-            for (AnnotationElement pair : elements()) {\n-                buf.writeIndex(pair.name());\n-                AnnotationReader.writeAnnotationValue(buf, pair.value());\n-            }\n+        public UnboundTypeAnnotation {\n+            targetPath = List.copyOf(targetPath);\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/classfile\/impl\/UnboundAttribute.java","additions":3,"deletions":70,"binary":false,"changes":73,"status":"modified"},{"patch":"@@ -398,1 +398,1 @@\n-            l += 2 + an.targetInfo().size() + 2 * an.targetPath().size() + annotationSize(an);\n+            l += 2 + an.targetInfo().size() + 2 * an.targetPath().size() + annotationSize(an.annotation());\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/classfile\/impl\/verifier\/ParserVerifier.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -182,35 +182,0 @@\n-    \/** Creates a new java.lang.reflect.Constructor. Access checks as\n-        per java.lang.reflect.AccessibleObject are not overridden. *\/\n-    public Constructor<?> newConstructor(Class<?> declaringClass,\n-                                         Class<?>[] parameterTypes,\n-                                         Class<?>[] checkedExceptions,\n-                                         int modifiers,\n-                                         int slot,\n-                                         String signature,\n-                                         byte[] annotations,\n-                                         byte[] parameterAnnotations)\n-    {\n-        return langReflectAccess.newConstructor(declaringClass,\n-                                                parameterTypes,\n-                                                checkedExceptions,\n-                                                modifiers,\n-                                                slot,\n-                                                signature,\n-                                                annotations,\n-                                                parameterAnnotations);\n-    }\n-\n-    \/** Gets the ConstructorAccessor object for a\n-        java.lang.reflect.Constructor *\/\n-    public ConstructorAccessor getConstructorAccessor(Constructor<?> c) {\n-        return langReflectAccess.getConstructorAccessor(c);\n-    }\n-\n-    \/** Sets the ConstructorAccessor object for a\n-        java.lang.reflect.Constructor *\/\n-    public void setConstructorAccessor(Constructor<?> c,\n-                                       ConstructorAccessor accessor)\n-    {\n-        langReflectAccess.setConstructorAccessor(c, accessor);\n-    }\n-\n@@ -228,1 +193,2 @@\n-        return langReflectAccess.leafCopyMethod(arg);\n+        Method root = langReflectAccess.getRoot(arg);\n+        return langReflectAccess.copyMethod(root);\n@@ -231,1 +197,0 @@\n-\n@@ -382,9 +347,0 @@\n-\n-        Constructor<?> ctor = newConstructor(constructorToCall.getDeclaringClass(),\n-                                             constructorToCall.getParameterTypes(),\n-                                             constructorToCall.getExceptionTypes(),\n-                                             constructorToCall.getModifiers(),\n-                                             langReflectAccess.getConstructorSlot(constructorToCall),\n-                                             langReflectAccess.getConstructorSignature(constructorToCall),\n-                                             langReflectAccess.getConstructorAnnotations(constructorToCall),\n-                                             langReflectAccess.getConstructorParameterAnnotations(constructorToCall));\n@@ -399,1 +355,1 @@\n-            acc = MethodHandleAccessorFactory.newSerializableConstructorAccessor(cl, ctor);\n+            acc = MethodHandleAccessorFactory.newSerializableConstructorAccessor(cl, constructorToCall);\n@@ -401,1 +357,4 @@\n-        setConstructorAccessor(ctor, acc);\n+        \/\/ Unlike other root constructors, this constructor is not copied for mutation\n+        \/\/ but directly mutated, as it is not cached. To cache this constructor,\n+        \/\/ setAccessible call must be done on a copy and return that copy instead.\n+        Constructor<?> ctor = langReflectAccess.newConstructorWithAccessor(constructorToCall, acc);\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/reflect\/ReflectionFactory.java","additions":8,"deletions":49,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -223,1 +223,7 @@\n-        Objects.requireNonNull(key, \"key must not be null\");\n+        return getNoCheckStale(key);\n+    }\n+\n+    \/\/ Internal get(key) without removing stale references that would modify the keyset.\n+    \/\/ Use when iterating or streaming over the keys to avoid ConcurrentModificationException.\n+    private V getNoCheckStale(Object key) {\n+        Objects.requireNonNull(key, \"key must not be null\");\n@@ -295,1 +301,1 @@\n-                .map(k -> new AbstractMap.SimpleEntry<>(k, get(k)))\n+                .map(k -> new AbstractMap.SimpleEntry<>(k, getNoCheckStale(k)))\n@@ -339,1 +345,1 @@\n-                .map(k -> k + \"=\" + get(k))\n+                .map(k -> k + \"=\" + getNoCheckStale(k))\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/util\/ReferencedKeyMap.java","additions":9,"deletions":3,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -54,4 +54,30 @@\n-    \/** The modifier {@code public} *\/          PUBLIC,\n-    \/** The modifier {@code protected} *\/       PROTECTED,\n-    \/** The modifier {@code private} *\/         PRIVATE,\n-    \/** The modifier {@code abstract} *\/        ABSTRACT,\n+    \/**\n+     * The modifier {@code public}\n+     *\n+     * @jls 6.6 Access Control\n+     *\/\n+    PUBLIC,\n+\n+    \/**\n+     * The modifier {@code protected}\n+     *\n+     * @jls 6.6 Access Control\n+     *\/\n+    PROTECTED,\n+\n+    \/**\n+     * The modifier {@code private}\n+     *\n+     * @jls 6.6 Access Control\n+     *\/\n+    PRIVATE,\n+\n+    \/**\n+     * The modifier {@code abstract}\n+     *\n+     * @jls 8.1.1.1 {@code abstract} Classes\n+     * @jls 8.4.3.1 {@code abstract} Methods\n+     * @jls 9.1.1.1 {@code abstract} Interfaces\n+     *\/\n+    ABSTRACT,\n+\n@@ -60,0 +86,2 @@\n+     *\n+     * @jls 9.4 Method Declarations\n@@ -63,1 +91,10 @@\n-    \/** The modifier {@code static} *\/          STATIC,\n+\n+    \/**\n+     * The modifier {@code static}\n+     *\n+     * @jls 8.1.1.4 {@code static} Classes\n+     * @jls 8.3.1.1 {@code static} Fields\n+     * @jls 8.4.3.2 {@code static} Methods\n+     * @jls 9.1.1.3 {@code static} Interfaces\n+     *\/\n+    STATIC,\n@@ -67,0 +104,3 @@\n+     *\n+     * @jls 8.1.1.2 {@code sealed}, {@code non-sealed}, and {@code final} Classes\n+     * @jls 9.1.1.4 {@code sealed} and {@code non-sealed} Interfaces\n@@ -73,0 +113,3 @@\n+     *\n+     * @jls 8.1.1.2 {@code sealed}, {@code non-sealed}, and {@code final} Classes\n+     * @jls 9.1.1.4 {@code sealed} and {@code non-sealed} Interfaces\n@@ -86,0 +129,15 @@\n+    \/**\n+     * The modifier {@code final}\n+     *\n+     * @jls 8.1.1.2 {@code sealed}, {@code non-sealed}, and {@code final} Classes\n+     * @jls 8.3.1.2 {@code final} Fields\n+     * @jls 8.4.3.3 {@code final} Methods\n+     *\/\n+    FINAL,\n+\n+    \/**\n+     * The modifier {@code transient}\n+     *\n+     * @jls 8.3.1.3 {@code transient} Fields\n+     *\/\n+    TRANSIENT,\n@@ -87,6 +145,29 @@\n-    \/** The modifier {@code final} *\/           FINAL,\n-    \/** The modifier {@code transient} *\/       TRANSIENT,\n-    \/** The modifier {@code volatile} *\/        VOLATILE,\n-    \/** The modifier {@code synchronized} *\/    SYNCHRONIZED,\n-    \/** The modifier {@code native} *\/          NATIVE,\n-    \/** The modifier {@code strictfp} *\/        STRICTFP;\n+    \/**\n+     * The modifier {@code volatile}\n+     *\n+     * @jls 8.3.1.4 {@code volatile} Fields\n+     *\/\n+    VOLATILE,\n+\n+    \/**\n+     * The modifier {@code synchronized}\n+     *\n+     * @jls 8.4.3.6 {@code synchronized} Methods\n+     *\/\n+    SYNCHRONIZED,\n+\n+    \/**\n+     * The modifier {@code native}\n+     *\n+     * @jls 8.4.3.4 {@code native} Methods\n+     *\/\n+    NATIVE,\n+\n+    \/**\n+     * The modifier {@code strictfp}\n+     *\n+     * @jls 8.1.1.3 {@code strictfp} Classes\n+     * @jls 8.4.3.5 {@code strictfp} Methods\n+     * @jls 9.1.1.2 {@code strictfp} Interfaces\n+     *\/\n+    STRICTFP;\n","filename":"src\/java.compiler\/share\/classes\/javax\/lang\/model\/element\/Modifier.java","additions":93,"deletions":12,"binary":false,"changes":105,"status":"modified"},{"patch":"@@ -5283,1 +5283,12 @@\n-            Env<AttrContext> errEnv = env.dup(env.tree, env.info.dup());\n+            WriteableScope newScope = env.info.scope;\n+\n+            if (env.tree instanceof JCClassDecl) {\n+                Symbol fakeOwner =\n+                    new MethodSymbol(BLOCK, names.empty, null,\n+                        env.info.scope.owner);\n+                newScope = newScope.dupUnshared(fakeOwner);\n+            }\n+\n+            Env<AttrContext> errEnv =\n+                    env.dup(env.tree,\n+                            env.info.dup(newScope));\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Attr.java","additions":12,"deletions":1,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -1227,3 +1227,11 @@\n-                Type tDesc = types.findDescriptorType(types.capture(t));\n-                Type tDescNoCapture = types.findDescriptorType(t);\n-                Type sDesc = types.findDescriptorType(s);\n+                Type tDesc;\n+                Type tDescNoCapture;\n+                Type sDesc;\n+                try {\n+                    tDesc = types.findDescriptorType(types.capture(t));\n+                    tDescNoCapture = types.findDescriptorType(t);\n+                    sDesc = types.findDescriptorType(s);\n+                } catch (Types.FunctionDescriptorLookupError ex) {\n+                    \/\/ don't report, a more meaningful error should be reported upstream\n+                    return false;\n+                }\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Resolve.java","additions":11,"deletions":3,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -39,1 +39,0 @@\n-import java.util.function.BiFunction;\n@@ -42,0 +41,1 @@\n+import java.util.stream.IntStream;\n@@ -66,0 +66,1 @@\n+import com.sun.tools.javac.resources.CompilerProperties.Errors;\n@@ -2338,3 +2339,11 @@\n-    private static void addTypeAnnotationsToSymbol(\n-            Symbol s, List<Attribute.TypeCompound> attributes) {\n-        new TypeAnnotationSymbolVisitor(attributes).visit(s, null);\n+    private void addTypeAnnotationsToSymbol(Symbol s, List<Attribute.TypeCompound> attributes) {\n+        try {\n+            new TypeAnnotationSymbolVisitor(attributes).visit(s, null);\n+        } catch (CompletionFailure ex) {\n+            JavaFileObject prev = log.useSource(currentClassFile);\n+            try {\n+                log.error(Errors.CantAttachTypeAnnotations(attributes, s.owner, s.name, ex.getDetailValue()));\n+            } finally {\n+                log.useSource(prev);\n+            }\n+        }\n@@ -2488,6 +2497,1 @@\n-            \/\/ Search the structure of the type to find the contained types at each type path\n-            Map<Type, List<Attribute.TypeCompound>> attributesByType = new HashMap<>();\n-            new TypeAnnotationLocator(attributesByPath, attributesByType).visit(type, List.nil());\n-\n-            type = new TypeAnnotationTypeMapping(attributesByType).visit(type, null);\n-            Assert.check(attributesByType.isEmpty(), \"Failed to apply annotations to types\");\n+            type = new TypeAnnotationStructuralTypeMapping(attributesByPath).visit(type, List.nil());\n@@ -2522,2 +2526,4 @@\n-     * Visit all contained types, assembling a type path to represent the current location, and\n-     * record the types at each type path that need to be annotated.\n+     * A type mapping that rewrites the type to include type annotations.\n+     *\n+     * <p>This logic is similar to {@link Type.StructuralTypeMapping}, but also tracks the path to\n+     * the contained types being rewritten, and so cannot easily share the existing logic.\n@@ -2525,2 +2531,3 @@\n-    private static class TypeAnnotationLocator\n-            extends Types.DefaultTypeVisitor<Void, List<TypeAnnotationPosition.TypePathEntry>> {\n+    private static final class TypeAnnotationStructuralTypeMapping\n+            extends Types.TypeMapping<List<TypeAnnotationPosition.TypePathEntry>> {\n+\n@@ -2528,2 +2535,1 @@\n-                          ListBuffer<Attribute.TypeCompound>> attributesByPath;\n-        private final Map<Type, List<Attribute.TypeCompound>> attributesByType;\n+                ListBuffer<Attribute.TypeCompound>> attributesByPath;\n@@ -2531,1 +2537,1 @@\n-        private TypeAnnotationLocator(\n+        private TypeAnnotationStructuralTypeMapping(\n@@ -2533,2 +2539,1 @@\n-                        attributesByPath,\n-                Map<Type, List<Attribute.TypeCompound>> attributesByType) {\n+                    attributesByPath) {\n@@ -2536,1 +2541,0 @@\n-            this.attributesByType = attributesByType;\n@@ -2539,0 +2543,1 @@\n+\n@@ -2540,1 +2545,1 @@\n-        public Void visitClassType(ClassType t, List<TypeAnnotationPosition.TypePathEntry> path) {\n+        public Type visitClassType(ClassType t, List<TypeAnnotationPosition.TypePathEntry> path) {\n@@ -2546,3 +2551,4 @@\n-            List<ClassType> enclosing = List.nil();\n-            for (Type curr = t;\n-                    curr != null && curr != Type.noType;\n+            Type outer = t.getEnclosingType();\n+            Type outer1 = outer != Type.noType ? visit(outer, path) : outer;\n+            for (Type curr = t.getEnclosingType();\n+                    curr != Type.noType;\n@@ -2550,11 +2556,0 @@\n-                enclosing = enclosing.prepend((ClassType) curr);\n-            }\n-            for (ClassType te : enclosing) {\n-                if (te.typarams_field != null) {\n-                    int i = 0;\n-                    for (Type typaram : te.typarams_field) {\n-                        visit(typaram, path.append(new TypeAnnotationPosition.TypePathEntry(\n-                                TypeAnnotationPosition.TypePathEntryKind.TYPE_ARGUMENT, i++)));\n-                    }\n-                }\n-                visitType(te, path);\n@@ -2563,1 +2558,6 @@\n-            return null;\n+            List<Type> typarams = t.getTypeArguments();\n+            List<Type> typarams1 = rewriteTypeParams(path, typarams);\n+            if (outer1 != outer || typarams != typarams1) {\n+                t = new ClassType(outer1, typarams1, t.tsym, t.getMetadata());\n+            }\n+            return reannotate(t, path);\n@@ -2566,5 +2566,6 @@\n-        @Override\n-        public Void visitWildcardType(\n-                WildcardType t, List<TypeAnnotationPosition.TypePathEntry> path) {\n-            visit(t.type, path.append(TypeAnnotationPosition.TypePathEntry.WILDCARD));\n-            return super.visitWildcardType(t, path);\n+        private List<Type> rewriteTypeParams(\n+                List<TypeAnnotationPosition.TypePathEntry> path, List<Type> typarams) {\n+            var i = IntStream.iterate(0, x -> x + 1).iterator();\n+            return typarams.map(typaram -> visit(typaram,\n+                    path.append(new TypeAnnotationPosition.TypePathEntry(\n+                            TypeAnnotationPosition.TypePathEntryKind.TYPE_ARGUMENT, i.nextInt()))));\n@@ -2574,3 +2575,10 @@\n-        public Void visitArrayType(ArrayType t, List<TypeAnnotationPosition.TypePathEntry> path) {\n-            visit(t.elemtype, path.append(TypeAnnotationPosition.TypePathEntry.ARRAY));\n-            return super.visitArrayType(t, path);\n+        public Type visitWildcardType(\n+                WildcardType wt, List<TypeAnnotationPosition.TypePathEntry> path) {\n+            Type t = wt.type;\n+            if (t != null) {\n+                t = visit(t, path.append(TypeAnnotationPosition.TypePathEntry.WILDCARD));\n+            }\n+            if (t != wt.type) {\n+                wt = new WildcardType(t, wt.kind, wt.tsym, wt.bound, wt.getMetadata());\n+            }\n+            return reannotate(wt, path);\n@@ -2580,4 +2588,6 @@\n-        public Void visitType(Type t, List<TypeAnnotationPosition.TypePathEntry> path) {\n-            ListBuffer<Attribute.TypeCompound> attributes = attributesByPath.remove(path);\n-            if (attributes != null) {\n-                attributesByType.put(t, attributes.toList());\n+        public Type visitArrayType(ArrayType t, List<TypeAnnotationPosition.TypePathEntry> path) {\n+            Type elemtype = t.elemtype;\n+            Type elemtype1 =\n+                    visit(elemtype, path.append(TypeAnnotationPosition.TypePathEntry.ARRAY));\n+            if (elemtype1 != elemtype)  {\n+                t = new ArrayType(elemtype1, t.tsym, t.getMetadata());\n@@ -2585,1 +2595,1 @@\n-            return null;\n+            return reannotate(t, path);\n@@ -2587,9 +2597,3 @@\n-    }\n-\n-    \/** A type mapping that rewrites the type to include type annotations. *\/\n-    private static class TypeAnnotationTypeMapping extends Type.StructuralTypeMapping<Void> {\n-        private final Map<Type, List<Attribute.TypeCompound>> attributesByType;\n-\n-        private TypeAnnotationTypeMapping(\n-                Map<Type, List<Attribute.TypeCompound>> attributesByType) {\n-            this.attributesByType = attributesByType;\n+        @Override\n+        public Type visitType(Type t, List<TypeAnnotationPosition.TypePathEntry> path) {\n+            return reannotate(t, path);\n@@ -2599,8 +2603,4 @@\n-        private <T extends Type> Type reannotate(T t, BiFunction<T, Void, Type> f) {\n-            \/\/ We're relying on object identify of Type instances to record where the annotations\n-            \/\/ need to be added, so we have to retrieve the annotations for each type before\n-            \/\/ rewriting it, and then add them after its contained types have been rewritten.\n-            List<Attribute.TypeCompound> attributes = attributesByType.remove(t);\n-            Type mapped = f.apply(t, null);\n-            if (attributes == null) {\n-                return mapped;\n+        Type reannotate(Type type, List<TypeAnnotationPosition.TypePathEntry> path) {\n+            List<Attribute.TypeCompound> attributes = attributesForPath(path);\n+            if (attributes.isEmpty()) {\n+                return type;\n@@ -2610,1 +2610,1 @@\n-            TypeMetadata.Annotations existing = mapped.getMetadata(TypeMetadata.Annotations.class);\n+            TypeMetadata.Annotations existing = type.getMetadata(TypeMetadata.Annotations.class);\n@@ -2613,1 +2613,1 @@\n-                return mapped;\n+                return type;\n@@ -2615,6 +2615,1 @@\n-            return mapped.annotatedType(attributes);\n-        }\n-\n-        @Override\n-        public Type visitClassType(ClassType t, Void unused) {\n-            return reannotate(t, super::visitClassType);\n+            return type.annotatedType(attributes);\n@@ -2623,13 +2618,4 @@\n-        @Override\n-        public Type visitWildcardType(WildcardType t, Void unused) {\n-            return reannotate(t, super::visitWildcardType);\n-        }\n-\n-        @Override\n-        public Type visitArrayType(ArrayType t, Void unused) {\n-            return reannotate(t, super::visitArrayType);\n-        }\n-\n-        @Override\n-        public Type visitType(Type t, Void unused) {\n-            return reannotate(t, (x, u) -> x);\n+        List<Attribute.TypeCompound> attributesForPath(\n+                List<TypeAnnotationPosition.TypePathEntry> path) {\n+            ListBuffer<Attribute.TypeCompound> attributes = attributesByPath.remove(path);\n+            return attributes != null ? attributes.toList() : List.nil();\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/jvm\/ClassReader.java","additions":73,"deletions":87,"binary":false,"changes":160,"status":"modified"},{"patch":"@@ -470,1 +470,1 @@\n-    protected JCErroneous syntaxError(int pos, List<JCTree> errs, Error errorKey) {\n+    protected JCErroneous syntaxError(int pos, List<? extends JCTree> errs, Error errorKey) {\n@@ -4765,0 +4765,6 @@\n+            } else if (isDefiniteStatementStartToken()) {\n+                int startPos = token.pos;\n+                List<JCStatement> statements = blockStatement();\n+                return List.of(syntaxError(startPos,\n+                                           statements,\n+                                           Errors.StatementNotExpected));\n@@ -4942,1 +4948,13 @@\n-        }\n+    }\n+\n+    \/**\n+     * {@return true if and only if the current token is definitelly a token that\n+     *  starts a statement.}\n+     *\/\n+    private boolean isDefiniteStatementStartToken() {\n+        return switch (token.kind) {\n+            case IF, WHILE, DO, SWITCH, RETURN, TRY, FOR, ASSERT, BREAK,\n+                 CONTINUE, THROW -> true;\n+            default -> false;\n+        };\n+    }\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/parser\/JavacParser.java","additions":20,"deletions":2,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -1619,0 +1619,3 @@\n+compiler.err.statement.not.expected=\\\n+    statements not expected outside of methods and initializers\n+\n@@ -2354,0 +2357,5 @@\n+# 0: list of annotation, 1: symbol, 2: name, 3: message segment\n+compiler.err.cant.attach.type.annotations=\\\n+    Cannot attach type annotations {0} to {1}.{2}:\\n\\\n+    {3}\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/resources\/compiler.properties","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -197,0 +197,1 @@\n+    final int constMethodFlagsIsScoped = getConstant(\"ConstMethodFlags::_misc_is_scoped\", Integer.class);\n","filename":"src\/jdk.internal.vm.ci\/share\/classes\/jdk\/vm\/ci\/hotspot\/HotSpotVMConfig.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -466,0 +466,10 @@\n+    \/**\n+     * Returns true if this method has a\n+     * {@code jdk.internal.misc.ScopedMemoryAccess.Scoped} annotation.\n+     *\n+     * @return true if Scoped annotation present, false otherwise.\n+     *\/\n+    default boolean isScoped() {\n+        throw new UnsupportedOperationException();\n+    }\n+\n","filename":"src\/jdk.internal.vm.ci\/share\/classes\/jdk\/vm\/ci\/meta\/ResolvedJavaMethod.java","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -1986,2 +1986,0 @@\n-#ifdef DEBUG\n-\n@@ -2042,2 +2040,0 @@\n-#endif\n-\n","filename":"src\/jdk.jdwp.agent\/share\/native\/libjdwp\/util.c","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -62,0 +62,2 @@\n+compiler\/vectorapi\/VectorRebracket128Test.java#ZSinglegen 8330538 generic-all\n+compiler\/vectorapi\/VectorRebracket128Test.java#ZGenerational 8330538 generic-all\n@@ -64,0 +66,6 @@\n+compiler\/jvmci\/jdk.vm.ci.code.test\/src\/jdk\/vm\/ci\/code\/test\/DataPatchTest.java 8331704 linux-riscv64\n+compiler\/jvmci\/jdk.vm.ci.code.test\/src\/jdk\/vm\/ci\/code\/test\/MaxOopMapStackOffsetTest.java 8331704 linux-riscv64\n+compiler\/jvmci\/jdk.vm.ci.code.test\/src\/jdk\/vm\/ci\/code\/test\/NativeCallTest.java 8331704 linux-riscv64\n+compiler\/jvmci\/jdk.vm.ci.code.test\/src\/jdk\/vm\/ci\/code\/test\/SimpleDebugInfoTest.java 8331704 linux-riscv64\n+compiler\/jvmci\/jdk.vm.ci.code.test\/src\/jdk\/vm\/ci\/code\/test\/SimpleCodeInstallationTest.java 8331704 linux-riscv64\n+compiler\/jvmci\/jdk.vm.ci.code.test\/src\/jdk\/vm\/ci\/code\/test\/VirtualObjectDebugInfoTest.java 8331704 linux-riscv64\n@@ -118,0 +126,1 @@\n+runtime\/Thread\/TestAlwaysPreTouchStacks.java 8335167 macosx-aarch64\n@@ -120,0 +129,1 @@\n+\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -175,0 +175,1 @@\n+    private boolean testClassesOnBootClassPath;\n@@ -326,0 +327,9 @@\n+    \/**\n+     * Add test classes to boot classpath. This adds all classes found on path {@link jdk.test.lib.Utils#TEST_CLASSES}\n+     * to the boot classpath with \"-Xbootclasspath\/a\". This is useful when trying to run tests in a privileged mode.\n+     *\/\n+    public TestFramework addTestClassesToBootClassPath() {\n+        this.testClassesOnBootClassPath = true;\n+        return this;\n+    }\n+\n@@ -759,1 +769,2 @@\n-        TestVMProcess testVMProcess = new TestVMProcess(additionalFlags, testClass, helperClasses, defaultWarmup);\n+        TestVMProcess testVMProcess = new TestVMProcess(additionalFlags, testClass, helperClasses, defaultWarmup,\n+                                                        testClassesOnBootClassPath);\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/TestFramework.java","additions":12,"deletions":1,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -378,1 +378,1 @@\n-java\/awt\/Mouse\/EnterExitEvents\/ResizingFrameTest.java 8005021 macosx-all\n+java\/awt\/Mouse\/EnterExitEvents\/ResizingFrameTest.java 8005021,8332158 macosx-all,linux-x64\n@@ -476,0 +476,5 @@\n+# Wayland related\n+\n+java\/awt\/FullScreen\/FullscreenWindowProps\/FullscreenWindowProps.java 8280991 linux-x64\n+java\/awt\/FullScreen\/SetFullScreenTest.java 8332155 linux-x64\n+\n@@ -521,3 +526,3 @@\n-sun\/management\/jdp\/JdpDefaultsTest.java                         8241865,8308807 linux-aarch64,macosx-all,aix-ppc64\n-sun\/management\/jdp\/JdpJmxRemoteDynamicPortTest.java             8241865,8308807 macosx-all,aix-ppc64\n-sun\/management\/jdp\/JdpSpecificAddressTest.java                  8241865,8308807 macosx-all,aix-ppc64\n+sun\/management\/jdp\/JdpDefaultsTest.java                         8308807 aix-ppc64\n+sun\/management\/jdp\/JdpJmxRemoteDynamicPortTest.java             8308807 aix-ppc64\n+sun\/management\/jdp\/JdpSpecificAddressTest.java                  8308807 aix-ppc64\n@@ -612,1 +617,0 @@\n-com\/sun\/security\/auth\/callback\/TextCallbackHandler\/Password.java 8039280 generic-all\n@@ -619,1 +623,1 @@\n-sun\/security\/pkcs11\/sslecc\/ClientJSSEServerJSSE.java            8316183,8333317 generic-all\n+sun\/security\/pkcs11\/sslecc\/ClientJSSEServerJSSE.java            8316183 linux-ppc64le\n@@ -646,0 +650,1 @@\n+javax\/swing\/plaf\/basic\/BasicDirectoryModel\/LoaderThreadCount.java 8333880 windows-all\n@@ -748,1 +753,1 @@\n-jdk\/jfr\/event\/compiler\/TestCodeSweeper.java                     8225209 generic-all\n+jdk\/jfr\/event\/compiler\/TestCodeSweeper.java                     8338127 generic-all\n@@ -750,3 +755,0 @@\n-jdk\/jfr\/startupargs\/TestStartName.java                          8214685 windows-x64\n-jdk\/jfr\/startupargs\/TestStartDuration.java                      8214685 windows-x64\n-jdk\/jfr\/api\/consumer\/recordingstream\/TestOnEvent.java           8255404 linux-x64,linux-aarch64\n","filename":"test\/jdk\/ProblemList.txt","additions":12,"deletions":10,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -634,1 +634,0 @@\n-    com\/sun\/security\/auth\/callback\/TextCallbackHandler\/Password.java \\\n@@ -663,0 +662,1 @@\n+    com\/sun\/security\/auth\/callback\/TextCallbackHandler\/Password.java \\\n","filename":"test\/jdk\/TEST.groups","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -169,1 +169,1 @@\n-            case AnnotationValue.OfInteger v -> AnnotationValue.of(v.intValue());\n+            case AnnotationValue.OfInt v -> AnnotationValue.of(v.intValue());\n@@ -171,1 +171,1 @@\n-            case AnnotationValue.OfCharacter v -> AnnotationValue.of(v.charValue());\n+            case AnnotationValue.OfChar v -> AnnotationValue.of(v.charValue());\n@@ -183,2 +183,1 @@\n-                        ta.classSymbol(),\n-                        ta.elements().stream().map(ae -> AnnotationElement.of(ae.name().stringValue(), transformAnnotationValue(ae.value()))).toList())).toArray(TypeAnnotation[]::new);\n+                        transformAnnotation(ta.annotation()))).toArray(TypeAnnotation[]::new);\n","filename":"test\/jdk\/jdk\/classfile\/helpers\/RebuildingTransformation.java","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+compiler.err.cant.attach.type.annotations               # bad class file\n","filename":"test\/langtools\/tools\/javac\/diags\/examples.not-yet.txt","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"}]}