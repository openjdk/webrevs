{"files":[{"patch":"@@ -98,1 +98,1 @@\n-JAVADOC_OPTIONS := -use -keywords -notimestamp \\\n+JAVADOC_OPTIONS := -XDignore.symbol.file=true -use -keywords -notimestamp \\\n@@ -101,0 +101,2 @@\n+    -XDenableValueTypes \\\n+    --enable-preview -source $(JDK_SOURCE_TARGET_VERSION) \\\n","filename":"make\/Docs.gmk","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -141,0 +141,1 @@\n+# Param3 - _valhalla, or empty\n@@ -148,2 +149,2 @@\n-  $1_$2_DUMP_EXTRA_ARG := $$($1_$2_COOPS_OPTION) $$($1_$2_COH_OPTION)\n-  $1_$2_DUMP_TYPE      := $(if $(findstring _nocoops, $2),-NOCOOPS,)$(if $(findstring _coh, $2),-COH,)\n+  $1_$2_$3_DUMP_EXTRA_ARG := $$($1_$2_COOPS_OPTION) $$($1_$2_COH_OPTION) $(if $(findstring _valhalla, $3), --enable-preview,)\n+  $1_$2_$3_DUMP_TYPE      := $(if $(findstring _nocoops, $2),-NOCOOPS,)$(if $(findstring _coh, $2),-COH,)$(if $(findstring _valhalla, $3), -VALHALLA,)\n@@ -152,1 +153,1 @@\n-  $1_$2_CDS_DUMP_FLAGS := $(CDS_DUMP_FLAGS) $(if $(filter g1gc, $(JVM_FEATURES_$1)), -XX:+UseG1GC)\n+  $1_$2_$3_CDS_DUMP_FLAGS := $(CDS_DUMP_FLAGS) $(if $(filter g1gc, $(JVM_FEATURES_$1)), -XX:+UseG1GC)\n@@ -155,1 +156,1 @@\n-    $1_$2_CDS_ARCHIVE := bin\/$1\/classes$2.jsa\n+    $1_$2_$3_CDS_ARCHIVE := bin\/$1\/classes$2$3.jsa\n@@ -157,1 +158,1 @@\n-    $1_$2_CDS_ARCHIVE := lib\/$1\/classes$2.jsa\n+    $1_$2_$3_CDS_ARCHIVE := lib\/$1\/classes$2$3.jsa\n@@ -168,3 +169,3 @@\n-  $$(eval $$(call SetupExecute, $1_$2_gen_cds_archive_jdk, \\\n-      WARN := Creating CDS$$($1_$2_DUMP_TYPE) archive for jdk image for $1, \\\n-      INFO := Using CDS flags for $1: $$($1_$2_CDS_DUMP_FLAGS), \\\n+  $$(eval $$(call SetupExecute, $1_$2_$3_gen_cds_archive_jdk, \\\n+      WARN := Creating CDS$$($1_$2_$3_DUMP_TYPE) archive for jdk image for $1, \\\n+      INFO := Using CDS flags for $1: $$($1_$2_$3_CDS_DUMP_FLAGS), \\\n@@ -172,1 +173,1 @@\n-      OUTPUT_FILE := $$(JDK_IMAGE_DIR)\/$$($1_$2_CDS_ARCHIVE), \\\n+      OUTPUT_FILE := $$(JDK_IMAGE_DIR)\/$$($1_$2_$3_CDS_ARCHIVE), \\\n@@ -175,2 +176,2 @@\n-          -XX:SharedArchiveFile=$$(JDK_IMAGE_DIR)\/$$($1_$2_CDS_ARCHIVE) \\\n-          -$1 $$($1_$2_DUMP_EXTRA_ARG) $$($1_$2_CDS_DUMP_FLAGS) $$(LOG_INFO), \\\n+          -XX:SharedArchiveFile=$$(JDK_IMAGE_DIR)\/$$($1_$2_$3_CDS_ARCHIVE) \\\n+          -$1 $$($1_$2_$3_DUMP_EXTRA_ARG) $$($1_$2_$3_CDS_DUMP_FLAGS) $$(LOG_INFO), \\\n@@ -179,1 +180,1 @@\n-  JDK_TARGETS += $$($1_$2_gen_cds_archive_jdk)\n+  JDK_TARGETS += $$($1_$2_$3_gen_cds_archive_jdk)\n@@ -181,3 +182,3 @@\n-  $$(eval $$(call SetupExecute, $1_$2_gen_cds_archive_jre, \\\n-      WARN := Creating CDS$$($1_$2_DUMP_TYPE) archive for jre image for $1, \\\n-      INFO := Using CDS flags for $1: $$($1_$2_CDS_DUMP_FLAGS), \\\n+  $$(eval $$(call SetupExecute, $1_$2_$3_gen_cds_archive_jre, \\\n+      WARN := Creating CDS$$($1_$2_$3_DUMP_TYPE) archive for jre image for $1, \\\n+      INFO := Using CDS flags for $1: $$($1_$2_$3_CDS_DUMP_FLAGS), \\\n@@ -185,1 +186,1 @@\n-      OUTPUT_FILE := $$(JRE_IMAGE_DIR)\/$$($1_$2_CDS_ARCHIVE), \\\n+      OUTPUT_FILE := $$(JRE_IMAGE_DIR)\/$$($1_$2_$3_CDS_ARCHIVE), \\\n@@ -188,2 +189,2 @@\n-          -XX:SharedArchiveFile=$$(JRE_IMAGE_DIR)\/$$($1_$2_CDS_ARCHIVE) \\\n-          -$1 $$($1_$2_DUMP_EXTRA_ARG) $$($1_$2_CDS_DUMP_FLAGS) $$(LOG_INFO), \\\n+          -XX:SharedArchiveFile=$$(JRE_IMAGE_DIR)\/$$($1_$2_$3_CDS_ARCHIVE) \\\n+          -$1 $$($1_$2_$3_DUMP_EXTRA_ARG) $$($1_$2_$3_CDS_DUMP_FLAGS) $$(LOG_INFO), \\\n@@ -192,1 +193,1 @@\n-  JRE_TARGETS += $$($1_$2_gen_cds_archive_jre)\n+  JRE_TARGETS += $$($1_$2_$3_gen_cds_archive_jre)\n@@ -197,1 +198,2 @@\n-    $(eval $(call CreateCDSArchive,$v,)) \\\n+    $(eval $(call CreateCDSArchive,$v,,)) \\\n+    $(eval $(call CreateCDSArchive,$v,,_valhalla)) \\\n@@ -202,1 +204,2 @@\n-      $(eval $(call CreateCDSArchive,$v,_nocoops)) \\\n+      $(eval $(call CreateCDSArchive,$v,_nocoops,)) \\\n+      $(eval $(call CreateCDSArchive,$v,_nocoops,_valhalla)) \\\n","filename":"make\/Images.gmk","additions":24,"deletions":21,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -307,0 +307,4 @@\n+    private static final String MIGRATED_VALUE_CLASS_ANNOTATION =\n+            \"Ljdk\/internal\/MigratedValueClass;\";\n+    private static final String MIGRATED_VALUE_CLASS_ANNOTATION_INTERNAL =\n+            \"Ljdk\/internal\/MigratedValueClass+Annotation;\";\n@@ -317,0 +321,1 @@\n+                    MIGRATED_VALUE_CLASS_ANNOTATION,\n@@ -1029,0 +1034,6 @@\n+        if (MIGRATED_VALUE_CLASS_ANNOTATION.equals(annotationType)) {\n+            \/\/the non-public MigratedValueClass annotation will not be available in ct.sym,\n+            \/\/replace with purely synthetic javac-internal annotation:\n+            annotationType = MIGRATED_VALUE_CLASS_ANNOTATION_INTERNAL;\n+        }\n+\n","filename":"make\/langtools\/src\/classes\/build\/tools\/symbolgenerator\/CreateSymbols.java","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -49,0 +49,21 @@\n+void C2_MacroAssembler::entry_barrier() {\n+  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+  \/\/ Dummy labels for just measuring the code size\n+  Label dummy_slow_path;\n+  Label dummy_continuation;\n+  Label dummy_guard;\n+  Label* slow_path = &dummy_slow_path;\n+  Label* continuation = &dummy_continuation;\n+  Label* guard = &dummy_guard;\n+  if (!Compile::current()->output()->in_scratch_emit_size()) {\n+    \/\/ Use real labels from actual stub when not emitting code for the purpose of measuring its size\n+    C2EntryBarrierStub* stub = new (Compile::current()->comp_arena()) C2EntryBarrierStub();\n+    Compile::current()->output()->add_stub(stub);\n+    slow_path = &stub->entry();\n+    continuation = &stub->continuation();\n+    guard = &stub->guard();\n+  }\n+  \/\/ In the C2 code, we move the non-hot part of nmethod entry barriers out-of-line to a stub.\n+  bs->nmethod_entry_barrier(this, slow_path, continuation, guard);\n+}\n+\n@@ -184,0 +205,5 @@\n+    if (EnableValhalla) {\n+      \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n+      andr(tmp, tmp, ~((int) markWord::inline_type_bit_in_place));\n+    }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":26,"deletions":0,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -331,4 +331,11 @@\n-    __ ldr(j_rarg2, result);\n-    Label is_long, is_float, is_double, exit;\n-    __ ldr(j_rarg1, result_type);\n-    __ cmp(j_rarg1, (u1)T_OBJECT);\n+    \/\/ All of j_rargN may be used to return inline type fields so be careful\n+    \/\/ not to clobber those.\n+    \/\/ SharedRuntime::generate_buffered_inline_type_adapter() knows the register\n+    \/\/ assignment of Rresult below.\n+    Register Rresult = r14, Rresult_type = r15;\n+    __ ldr(Rresult, result);\n+    Label is_long, is_float, is_double, check_prim, exit;\n+    __ ldr(Rresult_type, result_type);\n+    __ cmp(Rresult_type, (u1)T_OBJECT);\n+    __ br(Assembler::EQ, check_prim);\n+    __ cmp(Rresult_type, (u1)T_LONG);\n@@ -336,3 +343,1 @@\n-    __ cmp(j_rarg1, (u1)T_LONG);\n-    __ br(Assembler::EQ, is_long);\n-    __ cmp(j_rarg1, (u1)T_FLOAT);\n+    __ cmp(Rresult_type, (u1)T_FLOAT);\n@@ -340,1 +345,1 @@\n-    __ cmp(j_rarg1, (u1)T_DOUBLE);\n+    __ cmp(Rresult_type, (u1)T_DOUBLE);\n@@ -344,1 +349,1 @@\n-    __ strw(r0, Address(j_rarg2));\n+    __ strw(r0, Address(Rresult));\n@@ -396,0 +401,11 @@\n+    __ BIND(check_prim);\n+    if (InlineTypeReturnedAsFields) {\n+      \/\/ Check for scalarized return value\n+      __ tbz(r0, 0, is_long);\n+      \/\/ Load pack handler address\n+      __ andr(rscratch1, r0, -2);\n+      __ ldr(rscratch1, Address(rscratch1, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+      __ ldr(rscratch1, Address(rscratch1, InlineKlass::pack_handler_jobject_offset()));\n+      __ blr(rscratch1);\n+      __ b(exit);\n+    }\n@@ -398,1 +414,1 @@\n-    __ str(r0, Address(j_rarg2, 0));\n+    __ str(r0, Address(Rresult, 0));\n@@ -402,1 +418,1 @@\n-    __ strs(j_farg0, Address(j_rarg2, 0));\n+    __ strs(j_farg0, Address(Rresult, 0));\n@@ -406,1 +422,1 @@\n-    __ strd(j_farg0, Address(j_rarg2, 0));\n+    __ strd(j_farg0, Address(Rresult, 0));\n@@ -2227,0 +2243,6 @@\n+    \/\/ Check for flat inline type array -> return -1\n+    __ test_flat_array_oop(src, rscratch2, L_failed);\n+\n+    \/\/ Check for null-free (non-flat) inline type array -> handle as object array\n+    __ test_null_free_array_oop(src, rscratch2, L_objArray);\n+\n@@ -11295,0 +11317,128 @@\n+  \/\/ Call here from the interpreter or compiled code to either load\n+  \/\/ multiple returned values from the inline type instance being\n+  \/\/ returned to registers or to store returned values to a newly\n+  \/\/ allocated inline type instance.\n+  address generate_return_value_stub(address destination, const char* name, bool has_res) {\n+    \/\/ We need to save all registers the calling convention may use so\n+    \/\/ the runtime calls read or update those registers. This needs to\n+    \/\/ be in sync with SharedRuntime::java_return_convention().\n+    \/\/ n.b. aarch64 asserts that frame::arg_reg_save_area_bytes == 0\n+    enum layout {\n+      j_rarg7_off = 0, j_rarg7_2,    \/\/ j_rarg7 is r0\n+      j_rarg6_off, j_rarg6_2,\n+      j_rarg5_off, j_rarg5_2,\n+      j_rarg4_off, j_rarg4_2,\n+      j_rarg3_off, j_rarg3_2,\n+      j_rarg2_off, j_rarg2_2,\n+      j_rarg1_off, j_rarg1_2,\n+      j_rarg0_off, j_rarg0_2,\n+\n+      j_farg7_off, j_farg7_2,\n+      j_farg6_off, j_farg6_2,\n+      j_farg5_off, j_farg5_2,\n+      j_farg4_off, j_farg4_2,\n+      j_farg3_off, j_farg3_2,\n+      j_farg2_off, j_farg2_2,\n+      j_farg1_off, j_farg1_2,\n+      j_farg0_off, j_farg0_2,\n+\n+      rfp_off, rfp_off2,\n+      return_off, return_off2,\n+\n+      framesize \/\/ inclusive of return address\n+    };\n+\n+    CodeBuffer code(name, 512, 64);\n+    MacroAssembler* masm = new MacroAssembler(&code);\n+\n+    int frame_size_in_bytes = align_up(framesize*BytesPerInt, 16);\n+    assert(frame_size_in_bytes == framesize*BytesPerInt, \"misaligned\");\n+    int frame_size_in_slots = frame_size_in_bytes \/ BytesPerInt;\n+    int frame_size_in_words = frame_size_in_bytes \/ wordSize;\n+\n+    OopMapSet* oop_maps = new OopMapSet();\n+    OopMap* map = new OopMap(frame_size_in_slots, 0);\n+\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg7_off), j_rarg7->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg6_off), j_rarg6->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg5_off), j_rarg5->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg4_off), j_rarg4->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg3_off), j_rarg3->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg2_off), j_rarg2->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg1_off), j_rarg1->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg0_off), j_rarg0->as_VMReg());\n+\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg0_off), j_farg0->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg1_off), j_farg1->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg2_off), j_farg2->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg3_off), j_farg3->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg4_off), j_farg4->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg5_off), j_farg5->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg6_off), j_farg6->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg7_off), j_farg7->as_VMReg());\n+\n+    address start = __ pc();\n+\n+    __ enter(); \/\/ Save FP and LR before call\n+\n+    __ stpd(j_farg1, j_farg0, Address(__ pre(sp, -2 * wordSize)));\n+    __ stpd(j_farg3, j_farg2, Address(__ pre(sp, -2 * wordSize)));\n+    __ stpd(j_farg5, j_farg4, Address(__ pre(sp, -2 * wordSize)));\n+    __ stpd(j_farg7, j_farg6, Address(__ pre(sp, -2 * wordSize)));\n+\n+    __ stp(j_rarg1, j_rarg0, Address(__ pre(sp, -2 * wordSize)));\n+    __ stp(j_rarg3, j_rarg2, Address(__ pre(sp, -2 * wordSize)));\n+    __ stp(j_rarg5, j_rarg4, Address(__ pre(sp, -2 * wordSize)));\n+    __ stp(j_rarg7, j_rarg6, Address(__ pre(sp, -2 * wordSize)));\n+\n+    int frame_complete = __ offset();\n+\n+    \/\/ Set up last_Java_sp and last_Java_fp\n+    address the_pc = __ pc();\n+    __ set_last_Java_frame(sp, noreg, the_pc, rscratch1);\n+\n+    \/\/ Call runtime\n+    __ mov(c_rarg1, r0);\n+    __ mov(c_rarg0, rthread);\n+\n+    __ mov(rscratch1, destination);\n+    __ blr(rscratch1);\n+\n+    oop_maps->add_gc_map(the_pc - start, map);\n+\n+    __ reset_last_Java_frame(false);\n+\n+    __ ldp(j_rarg7, j_rarg6, Address(__ post(sp, 2 * wordSize)));\n+    __ ldp(j_rarg5, j_rarg4, Address(__ post(sp, 2 * wordSize)));\n+    __ ldp(j_rarg3, j_rarg2, Address(__ post(sp, 2 * wordSize)));\n+    __ ldp(j_rarg1, j_rarg0, Address(__ post(sp, 2 * wordSize)));\n+\n+    __ ldpd(j_farg7, j_farg6, Address(__ post(sp, 2 * wordSize)));\n+    __ ldpd(j_farg5, j_farg4, Address(__ post(sp, 2 * wordSize)));\n+    __ ldpd(j_farg3, j_farg2, Address(__ post(sp, 2 * wordSize)));\n+    __ ldpd(j_farg1, j_farg0, Address(__ post(sp, 2 * wordSize)));\n+\n+    __ leave();\n+\n+    \/\/ check for pending exceptions\n+    Label pending;\n+    __ ldr(rscratch1, Address(rthread, in_bytes(Thread::pending_exception_offset())));\n+    __ cbnz(rscratch1, pending);\n+\n+    if (has_res) {\n+      __ get_vm_result_oop(r0, rthread);\n+    }\n+\n+    __ ret(lr);\n+\n+    __ bind(pending);\n+    __ far_jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+\n+    \/\/ -------------\n+    \/\/ make sure all code is generated\n+    masm->flush();\n+\n+    RuntimeStub* stub = RuntimeStub::new_runtime_stub(name, &code, frame_complete, frame_size_in_words, oop_maps, false);\n+    return stub->entry_point();\n+  }\n+\n@@ -11341,0 +11491,8 @@\n+\n+    if (InlineTypeReturnedAsFields) {\n+      StubRoutines::_load_inline_type_fields_in_regs =\n+         generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::load_inline_type_fields_in_regs), \"load_inline_type_fields_in_regs\", false);\n+      StubRoutines::_store_inline_type_fields_to_buf =\n+         generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::store_inline_type_fields_to_buf), \"store_inline_type_fields_to_buf\", true);\n+    }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":170,"deletions":12,"binary":false,"changes":182,"status":"modified"},{"patch":"@@ -1800,1 +1800,1 @@\n-        assert(ReturnTypeEntry::static_cell_count() < TypeStackSlotEntries::per_arg_count(), \"can't move past ret type\");\n+        assert(SingleTypeEntry::static_cell_count() < TypeStackSlotEntries::per_arg_count(), \"can't move past ret type\");\n@@ -1849,1 +1849,1 @@\n-    Address mdo_ret_addr(mdp, -in_bytes(ReturnTypeEntry::size()));\n+    Address mdo_ret_addr(mdp, -in_bytes(SingleTypeEntry::size()));\n","filename":"src\/hotspot\/cpu\/s390\/interp_masm_s390.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"oops\/constMethodFlags.hpp\"\n@@ -34,0 +35,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -168,1 +170,1 @@\n-        assert(ReturnTypeEntry::static_cell_count() < TypeStackSlotEntries::per_arg_count(), \"can't move past ret type\");\n+        assert(SingleTypeEntry::static_cell_count() < TypeStackSlotEntries::per_arg_count(), \"can't move past ret type\");\n@@ -213,1 +215,1 @@\n-    Address mdo_ret_addr(mdp, -in_bytes(ReturnTypeEntry::size()));\n+    Address mdo_ret_addr(mdp, -in_bytes(SingleTypeEntry::size()));\n@@ -519,1 +521,2 @@\n-                                                  Label& ok_is_subtype) {\n+                                                  Label& ok_is_subtype,\n+                                                  bool profile) {\n@@ -527,1 +530,3 @@\n-  profile_typecheck(rcx, Rsub_klass, rdi); \/\/ blows rcx, reloads rdi\n+  if (profile) {\n+    profile_typecheck(rcx, Rsub_klass, rdi); \/\/ blows rcx, reloads rdi\n+  }\n@@ -828,1 +833,1 @@\n- \/\/ get method access flags\n+  \/\/ get method access flags\n@@ -950,4 +955,2 @@\n-  \/\/ remove activation\n-  \/\/ get sender sp\n-  movptr(rbx,\n-         Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize));\n+    movptr(rbx,\n+               Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize));\n@@ -975,0 +978,40 @@\n+\n+  \/\/ remove activation\n+  \/\/ get sender sp\n+  movptr(rbx,\n+         Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize));\n+\n+  if (state == atos && InlineTypeReturnedAsFields) {\n+    \/\/ Check if we are returning an non-null inline type and load its fields into registers\n+    Label skip;\n+    test_oop_is_not_inline_type(rax, rscratch1, skip);\n+\n+#ifndef _LP64\n+    super_call_VM_leaf(StubRoutines::load_inline_type_fields_in_regs());\n+#else\n+    \/\/ Load fields from a buffered value with an inline class specific handler\n+    load_klass(rdi, rax, rscratch1);\n+    movptr(rdi, Address(rdi, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+    movptr(rdi, Address(rdi, InlineKlass::unpack_handler_offset()));\n+    \/\/ Unpack handler can be null if inline type is not scalarizable in returns\n+    testptr(rdi, rdi);\n+    jcc(Assembler::zero, skip);\n+    call(rdi);\n+#endif\n+#ifdef ASSERT\n+    \/\/ TODO 8284443 Enable\n+    if (StressCallingConvention && false) {\n+      Label skip_stress;\n+      movptr(rscratch1, Address(rbp, frame::interpreter_frame_method_offset * wordSize));\n+      movl(rscratch1, Address(rscratch1, Method::flags_offset()));\n+      testl(rcx, MethodFlags::has_scalarized_return_flag());\n+      jcc(Assembler::zero, skip_stress);\n+      load_klass(rax, rax, rscratch1);\n+      orptr(rax, 1);\n+      bind(skip_stress);\n+    }\n+#endif\n+    \/\/ call above kills the value in rbx. Reload it.\n+    movptr(rbx, Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize));\n+    bind(skip);\n+  }\n@@ -995,0 +1038,54 @@\n+void InterpreterMacroAssembler::allocate_instance(Register klass, Register new_obj,\n+                                                  Register t1, Register t2,\n+                                                  bool clear_fields, Label& alloc_failed) {\n+  MacroAssembler::allocate_instance(klass, new_obj, t1, t2, clear_fields, alloc_failed);\n+  if (DTraceAllocProbes) {\n+    \/\/ Trigger dtrace event for fastpath\n+    push(atos);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, static_cast<int (*)(oopDesc*)>(SharedRuntime::dtrace_object_alloc)), new_obj);\n+    pop(atos);\n+  }\n+}\n+\n+void InterpreterMacroAssembler::read_flat_field(Register entry, Register tmp1, Register tmp2, Register obj) {\n+  Label alloc_failed, done;\n+  const Register alloc_temp = LP64_ONLY(rscratch1) NOT_LP64(rsi);\n+  const Register dst_temp   = LP64_ONLY(rscratch2) NOT_LP64(rdi);\n+  assert_different_registers(obj, entry, tmp1, tmp2, dst_temp, r8, r9);\n+\n+  \/\/ FIXME: code below could be re-written to better use InlineLayoutInfo data structure\n+  \/\/ see aarch64 version\n+\n+  \/\/ Grap the inline field klass\n+  const Register field_klass = tmp1;\n+  load_unsigned_short(tmp2, Address(entry, in_bytes(ResolvedFieldEntry::field_index_offset())));\n+  movptr(tmp1, Address(entry, ResolvedFieldEntry::field_holder_offset()));\n+  get_inline_type_field_klass(tmp1, tmp2, field_klass);\n+\n+  \/\/ allocate buffer\n+  push(obj);  \/\/ push object being read from     \/\/ FIXME spilling on stack could probably be avoided by using tmp2\n+  allocate_instance(field_klass, obj, alloc_temp, dst_temp, false, alloc_failed);\n+\n+  \/\/ Have an oop instance buffer, copy into it\n+  load_unsigned_short(r9, Address(entry, in_bytes(ResolvedFieldEntry::field_index_offset())));\n+  movptr(r8, Address(entry, in_bytes(ResolvedFieldEntry::field_holder_offset())));\n+  inline_layout_info(r8, r9, r8); \/\/ holder, index, info => InlineLayoutInfo into r8\n+\n+  payload_addr(obj, dst_temp, field_klass);\n+  pop(alloc_temp);             \/\/ restore object being read from\n+  load_sized_value(tmp2, Address(entry, in_bytes(ResolvedFieldEntry::field_offset_offset())), sizeof(int), true \/*is_signed*\/);\n+  lea(tmp2, Address(alloc_temp, tmp2));\n+  \/\/ call_VM_leaf, clobbers a few regs, save restore new obj\n+  push(obj);\n+  \/\/ access_value_copy(IS_DEST_UNINITIALIZED, tmp2, dst_temp, field_klass);\n+  flat_field_copy(IS_DEST_UNINITIALIZED, tmp2, dst_temp, r8);\n+  pop(obj);\n+  jmp(done);\n+\n+  bind(alloc_failed);\n+  pop(obj);\n+  call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::read_flat_field),\n+          obj, entry);\n+  get_vm_result_oop(obj);\n+  bind(done);\n+}\n@@ -1040,0 +1137,4 @@\n+      if (EnableValhalla) {\n+        \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n+        andptr(swap_reg, ~((int) markWord::inline_type_bit_in_place));\n+      }\n@@ -1364,1 +1465,1 @@\n-void InterpreterMacroAssembler::profile_not_taken_branch(Register mdp) {\n+void InterpreterMacroAssembler::profile_not_taken_branch(Register mdp, bool acmp) {\n@@ -1376,1 +1477,1 @@\n-    update_mdp_by_constant(mdp, in_bytes(BranchData::branch_data_size()));\n+    update_mdp_by_constant(mdp, acmp ? in_bytes(ACmpData::acmp_data_size()): in_bytes(BranchData::branch_data_size()));\n@@ -1439,1 +1540,1 @@\n-    record_klass_in_profile(receiver, mdp, reg2, true);\n+    record_klass_in_profile(receiver, mdp, reg2);\n@@ -1459,4 +1560,3 @@\n-void InterpreterMacroAssembler::record_klass_in_profile_helper(\n-                                        Register receiver, Register mdp,\n-                                        Register reg2, int start_row,\n-                                        Label& done, bool is_virtual_call) {\n+void InterpreterMacroAssembler::record_klass_in_profile_helper(Register receiver, Register mdp,\n+                                                               Register reg2, int start_row,\n+                                                               Label& done) {\n@@ -1566,3 +1666,1 @@\n-void InterpreterMacroAssembler::record_klass_in_profile(Register receiver,\n-                                                        Register mdp, Register reg2,\n-                                                        bool is_virtual_call) {\n+void InterpreterMacroAssembler::record_klass_in_profile(Register receiver, Register mdp, Register reg2) {\n@@ -1572,1 +1670,1 @@\n-  record_klass_in_profile_helper(receiver, mdp, reg2, 0, done, is_virtual_call);\n+  record_klass_in_profile_helper(receiver, mdp, reg2, 0, done);\n@@ -1649,1 +1747,1 @@\n-      record_klass_in_profile(klass, mdp, reg2, false);\n+      record_klass_in_profile(klass, mdp, reg2);\n@@ -1709,0 +1807,114 @@\n+template <class ArrayData> void InterpreterMacroAssembler::profile_array_type(Register mdp,\n+                                                                              Register array,\n+                                                                              Register tmp) {\n+  if (ProfileInterpreter) {\n+    Label profile_continue;\n+\n+    \/\/ If no method data exists, go to profile_continue.\n+    test_method_data_pointer(mdp, profile_continue);\n+\n+    mov(tmp, array);\n+    profile_obj_type(tmp, Address(mdp, in_bytes(ArrayData::array_offset())));\n+\n+    Label not_flat;\n+    test_non_flat_array_oop(array, tmp, not_flat);\n+\n+    set_mdp_flag_at(mdp, ArrayData::flat_array_byte_constant());\n+\n+    bind(not_flat);\n+\n+    Label not_null_free;\n+    test_non_null_free_array_oop(array, tmp, not_null_free);\n+\n+    set_mdp_flag_at(mdp, ArrayData::null_free_array_byte_constant());\n+\n+    bind(not_null_free);\n+\n+    bind(profile_continue);\n+  }\n+}\n+\n+template void InterpreterMacroAssembler::profile_array_type<ArrayLoadData>(Register mdp,\n+                                                                           Register array,\n+                                                                           Register tmp);\n+template void InterpreterMacroAssembler::profile_array_type<ArrayStoreData>(Register mdp,\n+                                                                            Register array,\n+                                                                            Register tmp);\n+\n+\n+void InterpreterMacroAssembler::profile_multiple_element_types(Register mdp, Register element, Register tmp, const Register tmp2) {\n+  if (ProfileInterpreter) {\n+    Label profile_continue;\n+\n+    \/\/ If no method data exists, go to profile_continue.\n+    test_method_data_pointer(mdp, profile_continue);\n+\n+    Label done, update;\n+    testptr(element, element);\n+    jccb(Assembler::notZero, update);\n+    set_mdp_flag_at(mdp, BitData::null_seen_byte_constant());\n+    jmp(done);\n+\n+    bind(update);\n+    load_klass(tmp, element, rscratch1);\n+\n+    \/\/ Record the object type.\n+    record_klass_in_profile(tmp, mdp, tmp2);\n+\n+    bind(done);\n+\n+    \/\/ The method data pointer needs to be updated.\n+    update_mdp_by_constant(mdp, in_bytes(ArrayStoreData::array_store_data_size()));\n+\n+    bind(profile_continue);\n+  }\n+}\n+\n+void InterpreterMacroAssembler::profile_element_type(Register mdp,\n+                                                     Register element,\n+                                                     Register tmp) {\n+  if (ProfileInterpreter) {\n+    Label profile_continue;\n+\n+    \/\/ If no method data exists, go to profile_continue.\n+    test_method_data_pointer(mdp, profile_continue);\n+\n+    mov(tmp, element);\n+    profile_obj_type(tmp, Address(mdp, in_bytes(ArrayLoadData::element_offset())));\n+\n+    \/\/ The method data pointer needs to be updated.\n+    update_mdp_by_constant(mdp, in_bytes(ArrayLoadData::array_load_data_size()));\n+\n+    bind(profile_continue);\n+  }\n+}\n+\n+void InterpreterMacroAssembler::profile_acmp(Register mdp,\n+                                             Register left,\n+                                             Register right,\n+                                             Register tmp) {\n+  if (ProfileInterpreter) {\n+    Label profile_continue;\n+\n+    \/\/ If no method data exists, go to profile_continue.\n+    test_method_data_pointer(mdp, profile_continue);\n+\n+    mov(tmp, left);\n+    profile_obj_type(tmp, Address(mdp, in_bytes(ACmpData::left_offset())));\n+\n+    Label left_not_inline_type;\n+    test_oop_is_not_inline_type(left, tmp, left_not_inline_type);\n+    set_mdp_flag_at(mdp, ACmpData::left_inline_type_byte_constant());\n+    bind(left_not_inline_type);\n+\n+    mov(tmp, right);\n+    profile_obj_type(tmp, Address(mdp, in_bytes(ACmpData::right_offset())));\n+\n+    Label right_not_inline_type;\n+    test_oop_is_not_inline_type(right, tmp, right_not_inline_type);\n+    set_mdp_flag_at(mdp, ACmpData::right_inline_type_byte_constant());\n+    bind(right_not_inline_type);\n+\n+    bind(profile_continue);\n+  }\n+}\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":233,"deletions":21,"binary":false,"changes":254,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -165,1 +165,1 @@\n-  void gen_subtype_check( Register sub_klass, Label &ok_is_subtype );\n+  void gen_subtype_check(Register sub_klass, Label &ok_is_subtype, bool profile = true);\n@@ -205,0 +205,14 @@\n+  \/\/ Kills t1 and t2, preserves klass, return allocation in new_obj\n+  void allocate_instance(Register klass, Register new_obj,\n+                         Register t1, Register t2,\n+                         bool clear_fields, Label& alloc_failed);\n+\n+  \/\/ Allocate instance in \"obj\" and read in the content of the inline field\n+  \/\/ NOTES:\n+  \/\/   - input holder object via \"obj\", which must be rax,\n+  \/\/     will return new instance via the same reg\n+  \/\/   - assumes holder_klass and valueKlass field klass have both been resolved\n+  void read_flat_field(Register entry,\n+                       Register tmp1, Register tmp2,\n+                       Register obj = rax);\n+\n@@ -224,5 +238,2 @@\n-  void record_klass_in_profile(Register receiver, Register mdp,\n-                               Register reg2, bool is_virtual_call);\n-  void record_klass_in_profile_helper(Register receiver, Register mdp,\n-                                      Register reg2, int start_row,\n-                                      Label& done, bool is_virtual_call);\n+  void record_klass_in_profile(Register receiver, Register mdp, Register reg2);\n+  void record_klass_in_profile_helper(Register receiver, Register mdp, Register reg2, int start_row, Label &done);\n@@ -240,1 +251,1 @@\n-  void profile_not_taken_branch(Register mdp);\n+  void profile_not_taken_branch(Register mdp, bool acmp = false);\n@@ -253,0 +264,5 @@\n+  template <class ArrayData> void profile_array_type(Register mdp, Register array, Register tmp);\n+\n+  void profile_multiple_element_types(Register mdp, Register element, Register tmp, const Register tmp2);\n+  void profile_element_type(Register mdp, Register element, Register tmp);\n+  void profile_acmp(Register mdp, Register left, Register right, Register tmp);\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.hpp","additions":24,"deletions":8,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"asm\/assembler.hpp\"\n@@ -41,0 +42,2 @@\n+#include \"utilities\/macros.hpp\"\n+#include \"vmreg_x86.inline.hpp\"\n@@ -304,4 +307,6 @@\n-  __ movptr(c_rarg0, result);\n-  Label is_long, is_float, is_double, exit;\n-  __ movl(c_rarg1, result_type);\n-  __ cmpl(c_rarg1, T_OBJECT);\n+  __ movptr(r13, result);\n+  Label is_long, is_float, is_double, check_prim, exit;\n+  __ movl(rbx, result_type);\n+  __ cmpl(rbx, T_OBJECT);\n+  __ jcc(Assembler::equal, check_prim);\n+  __ cmpl(rbx, T_LONG);\n@@ -309,3 +314,1 @@\n-  __ cmpl(c_rarg1, T_LONG);\n-  __ jcc(Assembler::equal, is_long);\n-  __ cmpl(c_rarg1, T_FLOAT);\n+  __ cmpl(rbx, T_FLOAT);\n@@ -313,1 +316,1 @@\n-  __ cmpl(c_rarg1, T_DOUBLE);\n+  __ cmpl(rbx, T_DOUBLE);\n@@ -319,1 +322,1 @@\n-    __ cmpl(c_rarg1, T_INT);\n+    __ cmpl(rbx, T_INT);\n@@ -327,1 +330,1 @@\n-  __ movl(Address(c_rarg0, 0), rax);\n+  __ movl(Address(r13, 0), rax);\n@@ -385,0 +388,13 @@\n+  __ BIND(check_prim);\n+  if (InlineTypeReturnedAsFields) {\n+    \/\/ Check for scalarized return value\n+    __ testptr(rax, 1);\n+    __ jcc(Assembler::zero, is_long);\n+    \/\/ Load pack handler address\n+    __ andptr(rax, -2);\n+    __ movptr(rax, Address(rax, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+    __ movptr(rbx, Address(rax, InlineKlass::pack_handler_jobject_offset()));\n+    \/\/ Call pack handler to initialize the buffer\n+    __ call(rbx);\n+    __ jmp(exit);\n+  }\n@@ -386,1 +402,1 @@\n-  __ movq(Address(c_rarg0, 0), rax);\n+  __ movq(Address(r13, 0), rax);\n@@ -390,1 +406,1 @@\n-  __ movflt(Address(c_rarg0, 0), xmm0);\n+  __ movflt(Address(r13, 0), xmm0);\n@@ -394,1 +410,1 @@\n-  __ movdbl(Address(c_rarg0, 0), xmm0);\n+  __ movdbl(Address(r13, 0), xmm0);\n@@ -4068,0 +4084,10 @@\n+  \/\/ Generate these first because they are called from other stubs\n+  if (InlineTypeReturnedAsFields) {\n+    StubRoutines::_load_inline_type_fields_in_regs =\n+      generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::load_inline_type_fields_in_regs),\n+                                 \"load_inline_type_fields_in_regs\", false);\n+    StubRoutines::_store_inline_type_fields_to_buf =\n+      generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::store_inline_type_fields_to_buf),\n+                                 \"store_inline_type_fields_to_buf\", true);\n+  }\n+\n@@ -4120,0 +4146,144 @@\n+\/\/ Call here from the interpreter or compiled code to either load\n+\/\/ multiple returned values from the inline type instance being\n+\/\/ returned to registers or to store returned values to a newly\n+\/\/ allocated inline type instance.\n+\/\/ Register is a class, but it would be assigned numerical value.\n+\/\/ \"0\" is assigned for xmm0. Thus we need to ignore -Wnonnull.\n+PRAGMA_DIAG_PUSH\n+PRAGMA_NONNULL_IGNORED\n+address StubGenerator::generate_return_value_stub(address destination, const char* name, bool has_res) {\n+  \/\/ We need to save all registers the calling convention may use so\n+  \/\/ the runtime calls read or update those registers. This needs to\n+  \/\/ be in sync with SharedRuntime::java_return_convention().\n+  enum layout {\n+    pad_off = frame::arg_reg_save_area_bytes\/BytesPerInt, pad_off_2,\n+    rax_off, rax_off_2,\n+    j_rarg5_off, j_rarg5_2,\n+    j_rarg4_off, j_rarg4_2,\n+    j_rarg3_off, j_rarg3_2,\n+    j_rarg2_off, j_rarg2_2,\n+    j_rarg1_off, j_rarg1_2,\n+    j_rarg0_off, j_rarg0_2,\n+    j_farg0_off, j_farg0_2,\n+    j_farg1_off, j_farg1_2,\n+    j_farg2_off, j_farg2_2,\n+    j_farg3_off, j_farg3_2,\n+    j_farg4_off, j_farg4_2,\n+    j_farg5_off, j_farg5_2,\n+    j_farg6_off, j_farg6_2,\n+    j_farg7_off, j_farg7_2,\n+    rbp_off, rbp_off_2,\n+    return_off, return_off_2,\n+\n+    framesize\n+  };\n+\n+  CodeBuffer buffer(name, 1000, 512);\n+  MacroAssembler* _masm = new MacroAssembler(&buffer);\n+\n+  int frame_size_in_bytes = align_up(framesize*BytesPerInt, 16);\n+  assert(frame_size_in_bytes == framesize*BytesPerInt, \"misaligned\");\n+  int frame_size_in_slots = frame_size_in_bytes \/ BytesPerInt;\n+  int frame_size_in_words = frame_size_in_bytes \/ wordSize;\n+\n+  OopMapSet *oop_maps = new OopMapSet();\n+  OopMap* map = new OopMap(frame_size_in_slots, 0);\n+\n+  map->set_callee_saved(VMRegImpl::stack2reg(rax_off), rax->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_rarg5_off), j_rarg5->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_rarg4_off), j_rarg4->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_rarg3_off), j_rarg3->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_rarg2_off), j_rarg2->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_rarg1_off), j_rarg1->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_rarg0_off), j_rarg0->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg0_off), j_farg0->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg1_off), j_farg1->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg2_off), j_farg2->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg3_off), j_farg3->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg4_off), j_farg4->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg5_off), j_farg5->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg6_off), j_farg6->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg7_off), j_farg7->as_VMReg());\n+\n+  int start = __ offset();\n+\n+  __ subptr(rsp, frame_size_in_bytes - 8 \/* return address*\/);\n+\n+  __ movptr(Address(rsp, rbp_off * BytesPerInt), rbp);\n+  __ movdbl(Address(rsp, j_farg7_off * BytesPerInt), j_farg7);\n+  __ movdbl(Address(rsp, j_farg6_off * BytesPerInt), j_farg6);\n+  __ movdbl(Address(rsp, j_farg5_off * BytesPerInt), j_farg5);\n+  __ movdbl(Address(rsp, j_farg4_off * BytesPerInt), j_farg4);\n+  __ movdbl(Address(rsp, j_farg3_off * BytesPerInt), j_farg3);\n+  __ movdbl(Address(rsp, j_farg2_off * BytesPerInt), j_farg2);\n+  __ movdbl(Address(rsp, j_farg1_off * BytesPerInt), j_farg1);\n+  __ movdbl(Address(rsp, j_farg0_off * BytesPerInt), j_farg0);\n+\n+  __ movptr(Address(rsp, j_rarg0_off * BytesPerInt), j_rarg0);\n+  __ movptr(Address(rsp, j_rarg1_off * BytesPerInt), j_rarg1);\n+  __ movptr(Address(rsp, j_rarg2_off * BytesPerInt), j_rarg2);\n+  __ movptr(Address(rsp, j_rarg3_off * BytesPerInt), j_rarg3);\n+  __ movptr(Address(rsp, j_rarg4_off * BytesPerInt), j_rarg4);\n+  __ movptr(Address(rsp, j_rarg5_off * BytesPerInt), j_rarg5);\n+  __ movptr(Address(rsp, rax_off * BytesPerInt), rax);\n+\n+  int frame_complete = __ offset();\n+\n+  __ set_last_Java_frame(noreg, noreg, nullptr, rscratch1);\n+\n+  __ mov(c_rarg0, r15_thread);\n+  __ mov(c_rarg1, rax);\n+\n+  __ call(RuntimeAddress(destination));\n+\n+  \/\/ Set an oopmap for the call site.\n+\n+  oop_maps->add_gc_map( __ offset() - start, map);\n+\n+  \/\/ clear last_Java_sp\n+  __ reset_last_Java_frame(false);\n+\n+  __ movptr(rbp, Address(rsp, rbp_off * BytesPerInt));\n+  __ movdbl(j_farg7, Address(rsp, j_farg7_off * BytesPerInt));\n+  __ movdbl(j_farg6, Address(rsp, j_farg6_off * BytesPerInt));\n+  __ movdbl(j_farg5, Address(rsp, j_farg5_off * BytesPerInt));\n+  __ movdbl(j_farg4, Address(rsp, j_farg4_off * BytesPerInt));\n+  __ movdbl(j_farg3, Address(rsp, j_farg3_off * BytesPerInt));\n+  __ movdbl(j_farg2, Address(rsp, j_farg2_off * BytesPerInt));\n+  __ movdbl(j_farg1, Address(rsp, j_farg1_off * BytesPerInt));\n+  __ movdbl(j_farg0, Address(rsp, j_farg0_off * BytesPerInt));\n+\n+  __ movptr(j_rarg0, Address(rsp, j_rarg0_off * BytesPerInt));\n+  __ movptr(j_rarg1, Address(rsp, j_rarg1_off * BytesPerInt));\n+  __ movptr(j_rarg2, Address(rsp, j_rarg2_off * BytesPerInt));\n+  __ movptr(j_rarg3, Address(rsp, j_rarg3_off * BytesPerInt));\n+  __ movptr(j_rarg4, Address(rsp, j_rarg4_off * BytesPerInt));\n+  __ movptr(j_rarg5, Address(rsp, j_rarg5_off * BytesPerInt));\n+  __ movptr(rax, Address(rsp, rax_off * BytesPerInt));\n+\n+  __ addptr(rsp, frame_size_in_bytes-8);\n+\n+  \/\/ check for pending exceptions\n+  Label pending;\n+  __ cmpptr(Address(r15_thread, Thread::pending_exception_offset()), (int32_t)NULL_WORD);\n+  __ jcc(Assembler::notEqual, pending);\n+\n+  if (has_res) {\n+    __ get_vm_result_oop(rax);\n+  }\n+\n+  __ ret(0);\n+\n+  __ bind(pending);\n+\n+  __ movptr(rax, Address(r15_thread, Thread::pending_exception_offset()));\n+  __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+\n+  \/\/ -------------\n+  \/\/ make sure all code is generated\n+  _masm->flush();\n+\n+  RuntimeStub* stub = RuntimeStub::new_runtime_stub(name, &buffer, frame_complete, frame_size_in_words, oop_maps, false);\n+  return stub->entry_point();\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":183,"deletions":13,"binary":false,"changes":196,"status":"modified"},{"patch":"@@ -627,0 +627,3 @@\n+  \/\/ interpreter or compiled code marshalling registers to\/from inline type instance\n+  address generate_return_value_stub(address destination, const char* name, bool has_res);\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1807,1 +1807,1 @@\n-  if (!UseFastStosb && UseUnalignedLoadStores) {\n+  if (UseUnalignedLoadStores) {\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -589,0 +589,1 @@\n+, _compiled_entry_signature(method->get_Method())\n@@ -606,1 +607,0 @@\n-\n@@ -609,0 +609,6 @@\n+  {\n+    ResetNoHandleMark rnhm; \/\/ Huh? Required when doing class lookup of the Q-types\n+    \/\/ TODO 8284443 Should only be computed once\n+    _compiled_entry_signature.compute_calling_conventions(false);\n+  }\n+\n","filename":"src\/hotspot\/share\/c1\/c1_Compilation.cpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -591,1 +591,1 @@\n-  if (!src_obj->fast_no_hash_check()) {\n+  if (!src_obj->fast_no_hash_check() && (!(EnableValhalla && src_obj->mark().is_inline_type()))) {\n@@ -595,0 +595,2 @@\n+    } else if (EnableValhalla) {\n+      fake_oop->set_mark(src_klass->prototype_header().copy_set_hash(src_hash));\n","filename":"src\/hotspot\/share\/cds\/archiveHeapWriter.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+#include \"runtime\/globals.hpp\"\n@@ -56,0 +57,3 @@\n+bool CDSConfig::_module_patching_disables_cds = false;\n+bool CDSConfig::_java_base_module_patching_disables_cds = false;\n+\n@@ -127,0 +131,3 @@\n+    if (is_valhalla_preview()) {\n+      tmp.print_raw(\"_valhalla\");\n+    }\n@@ -315,2 +322,1 @@\n-    \"jdk.module.upgrade.path\",\n-    \"jdk.module.patch.0\"\n+    \"jdk.module.upgrade.path\"\n@@ -320,2 +326,1 @@\n-    \"--upgrade-module-path\",\n-    \"--patch-module\"\n+    \"--upgrade-module-path\"\n@@ -344,0 +349,6 @@\n+\n+  if (module_patching_disables_cds()) {\n+    vm_exit_during_initialization(\n+            \"Cannot use the following option when dumping the shared archive\", \"--patch-module\");\n+  }\n+\n@@ -372,0 +383,10 @@\n+\n+  if (module_patching_disables_cds()) {\n+    if (RequireSharedSpaces) {\n+      warning(\"CDS is disabled when the %s option is specified.\", \"--patch-module\");\n+    } else {\n+      log_info(cds)(\"CDS is disabled when the %s option is specified.\", \"--patch-module\");\n+    }\n+    return true;\n+  }\n+\n@@ -525,1 +546,1 @@\n-bool CDSConfig::check_vm_args_consistency(bool patch_mod_javabase, bool mode_flag_cmd_line) {\n+bool CDSConfig::check_vm_args_consistency(bool mode_flag_cmd_line) {\n@@ -589,1 +610,1 @@\n-  if (is_using_archive() && patch_mod_javabase) {\n+  if (is_using_archive() && java_base_module_patching_disables_cds() && module_patching_disables_cds()) {\n@@ -786,0 +807,4 @@\n+  if (is_valhalla_preview()) {\n+    \/\/ Not working yet -- e.g., HeapShared::oop_hash() needs to be implemented for value oops\n+    return false;\n+  }\n","filename":"src\/hotspot\/share\/cds\/cdsConfig.cpp","additions":31,"deletions":6,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -569,1 +569,5 @@\n-  if (k->local_interfaces()->length() != _interfaces->length()) {\n+  const int actual_num_interfaces = k->local_interfaces()->length();\n+  const int specified_num_interfaces = _interfaces->length(); \/\/ specified in classlist\n+  int expected_num_interfaces = actual_num_interfaces;\n+\n+  if (specified_num_interfaces != expected_num_interfaces) {\n@@ -573,1 +577,1 @@\n-          _interfaces->length(), k->local_interfaces()->length());\n+          specified_num_interfaces, expected_num_interfaces);\n","filename":"src\/hotspot\/share\/cds\/classListParser.cpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -31,0 +31,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/inlineKlass.hpp\"\n@@ -32,0 +34,1 @@\n+#include \"oops\/instanceKlass.inline.hpp\"\n@@ -55,0 +58,1 @@\n+\/\/ NOTE: this table must be in-sync with sun.jvm.hotspot.memory.FileMapInfo::populateMetadataTypeArray().\n@@ -64,1 +68,3 @@\n-  f(TypeArrayKlass)\n+  f(TypeArrayKlass) \\\n+  f(FlatArrayKlass) \\\n+  f(InlineKlass)\n","filename":"src\/hotspot\/share\/cds\/cppVtables.cpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -89,0 +89,65 @@\n+inline void CDSMustMatchFlags::do_print(outputStream* st, bool v) {\n+  st->print(\"%s\", v ? \"true\" : \"false\");\n+}\n+\n+inline void CDSMustMatchFlags::do_print(outputStream* st, intx v) {\n+  st->print(\"%zd\", v);\n+}\n+\n+inline void CDSMustMatchFlags::do_print(outputStream* st, uintx v) {\n+  st->print(\"%zu\", v);\n+}\n+\n+inline void CDSMustMatchFlags::do_print(outputStream* st, double v) {\n+  st->print(\"%f\", v);\n+}\n+\n+void CDSMustMatchFlags::init() {\n+  assert(CDSConfig::is_dumping_archive(), \"sanity\");\n+  _max_name_width = 0;\n+\n+#define INIT_CDS_MUST_MATCH_FLAG(n) \\\n+  _v_##n = n; \\\n+  _max_name_width = MAX2(_max_name_width,strlen(#n));\n+  CDS_MUST_MATCH_FLAGS_DO(INIT_CDS_MUST_MATCH_FLAG);\n+#undef INIT_CDS_MUST_MATCH_FLAG\n+}\n+\n+bool CDSMustMatchFlags::runtime_check() const {\n+#define CHECK_CDS_MUST_MATCH_FLAG(n) \\\n+  if (_v_##n != n) { \\\n+    ResourceMark rm; \\\n+    stringStream ss; \\\n+    ss.print(\"VM option %s is different between dumptime (\", #n);  \\\n+    do_print(&ss, _v_ ## n); \\\n+    ss.print(\") and runtime (\"); \\\n+    do_print(&ss, n); \\\n+    ss.print(\")\"); \\\n+    log_info(cds)(\"%s\", ss.as_string()); \\\n+    return false; \\\n+  }\n+  CDS_MUST_MATCH_FLAGS_DO(CHECK_CDS_MUST_MATCH_FLAG);\n+#undef CHECK_CDS_MUST_MATCH_FLAG\n+\n+  return true;\n+}\n+\n+void CDSMustMatchFlags::print_info() const {\n+  LogTarget(Info, cds) lt;\n+  if (lt.is_enabled()) {\n+    LogStream ls(lt);\n+    ls.print_cr(\"Recorded VM flags during dumptime:\");\n+    print(&ls);\n+  }\n+}\n+\n+void CDSMustMatchFlags::print(outputStream* st) const {\n+#define PRINT_CDS_MUST_MATCH_FLAG(n) \\\n+  st->print(\"- %-s \", #n);                   \\\n+  st->sp(int(_max_name_width - strlen(#n))); \\\n+  do_print(st, _v_##n);                      \\\n+  st->cr();\n+  CDS_MUST_MATCH_FLAGS_DO(PRINT_CDS_MUST_MATCH_FLAG);\n+#undef PRINT_CDS_MUST_MATCH_FLAG\n+}\n+\n@@ -238,0 +303,1 @@\n+  _has_valhalla_patched_classes = CDSConfig::is_valhalla_preview();\n@@ -252,0 +318,1 @@\n+  _must_match.init();\n@@ -311,0 +378,2 @@\n+  st->print_cr(\"- has_valhalla_patched_classes    %d\", _has_valhalla_patched_classes);\n+  _must_match.print(st);\n@@ -694,0 +763,4 @@\n+  if (!header()->check_must_match_flags()) {\n+    return false;\n+  }\n+\n@@ -1987,0 +2060,18 @@\n+  if (is_static()) {\n+    const char* err = nullptr;\n+    if (CDSConfig::is_valhalla_preview()) {\n+      if (!_has_valhalla_patched_classes) {\n+        err = \"not created\";\n+      }\n+    } else {\n+      if (_has_valhalla_patched_classes) {\n+        err = \"created\";\n+      }\n+    }\n+    if (err != nullptr) {\n+      log_warning(cds)(\"This archive was %s with --enable-preview -XX:+EnableValhalla. It is \"\n+                         \"incompatible with the current JVM setting\", err);\n+      return false;\n+    }\n+  }\n+\n","filename":"src\/hotspot\/share\/cds\/filemap.cpp","additions":91,"deletions":0,"binary":false,"changes":91,"status":"modified"},{"patch":"@@ -2033,0 +2033,7 @@\n+\n+    if (CDSConfig::is_valhalla_preview() && strcmp(klass_name, \"jdk\/internal\/module\/ArchivedModuleGraph\") == 0) {\n+      \/\/ FIXME -- ArchivedModuleGraph doesn't work when java.base is patched with valhalla classes.\n+      i++;\n+      continue;\n+    }\n+\n","filename":"src\/hotspot\/share\/cds\/heapShared.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -79,0 +79,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/inlineKlass.hpp\"\n@@ -125,1 +127,1 @@\n-\/\/ [0] All classes are loaded in MetaspaceShared::preload_classes(). All metadata are\n+\/\/ [0] All classes are loaded in MetaspaceShared::loadable_descriptors(). All metadata are\n@@ -862,1 +864,1 @@\n-void MetaspaceShared::preload_classes(TRAPS) {\n+void MetaspaceShared::loadable_descriptors(TRAPS) {\n@@ -909,1 +911,1 @@\n-    preload_classes(CHECK);\n+    loadable_descriptors(CHECK);\n@@ -1078,0 +1080,5 @@\n+  if (CDSConfig::is_valhalla_preview()) {\n+    log_info(cds)(\"Archived java heap is not yet supported with Valhalla preview\");\n+    return;\n+  }\n+\n","filename":"src\/hotspot\/share\/cds\/metaspaceShared.cpp","additions":10,"deletions":3,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -83,1 +83,1 @@\n-  static void preload_classes(TRAPS) NOT_CDS_RETURN;\n+  static void loadable_descriptors(TRAPS) NOT_CDS_RETURN;\n","filename":"src\/hotspot\/share\/cds\/metaspaceShared.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -479,1 +480,2 @@\n-      (sym->char_at(1) == JVM_SIGNATURE_ARRAY || sym->char_at(1) == JVM_SIGNATURE_CLASS)) {\n+      (sym->char_at(1) == JVM_SIGNATURE_ARRAY ||\n+       sym->char_at(1) == JVM_SIGNATURE_CLASS )) {\n@@ -492,1 +494,1 @@\n-      return ciObjArrayKlass::make_impl(elem_klass);\n+      return ciArrayKlass::make(elem_klass);\n@@ -518,0 +520,4 @@\n+  int i = 0;\n+  while (sym->char_at(i) == JVM_SIGNATURE_ARRAY) {\n+    i++;\n+  }\n","filename":"src\/hotspot\/share\/ci\/ciEnv.cpp","additions":8,"deletions":2,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -1047,0 +1047,1 @@\n+  bool is_patched = false;\n@@ -1066,2 +1067,16 @@\n-    assert(!CDSConfig::is_dumping_archive(), \"CDS doesn't support --patch-module during dumping\");\n-    stream = search_module_entries(THREAD, _patch_mod_entries, pkg_entry, file_name);\n+    \/\/ At CDS dump time, the --patch-module entries are ignored. That means a\n+    \/\/ class is still loaded from the runtime image even if it might\n+    \/\/ appear in the _patch_mod_entries. The runtime shared class visibility\n+    \/\/ check will determine if a shared class is visible based on the runtime\n+    \/\/ environment, including the runtime --patch-module setting.\n+    if (!CDSConfig::is_valhalla_preview()) {\n+      \/\/ Dynamic dumping requires UseSharedSpaces to be enabled. Since --patch-module\n+      \/\/ is not supported with UseSharedSpaces, we can never come here during dynamic dumping.\n+      assert(!CDSConfig::is_dumping_archive(), \"CDS doesn't support --patch-module during dumping\");\n+    }\n+    if (CDSConfig::is_valhalla_preview() || !CDSConfig::is_dumping_static_archive()) {\n+      stream = search_module_entries(THREAD, _patch_mod_entries, pkg_entry, file_name);\n+      if (stream != nullptr) {\n+        is_patched = true;\n+      }\n+    }\n@@ -1116,0 +1131,6 @@\n+  if (is_patched) {\n+    result->set_shared_classpath_index(0);\n+#if INCLUDE_CDS\n+    result->set_shared_class_loader_type(ClassLoader::BOOT_LOADER);\n+#endif\n+  }\n@@ -1192,0 +1213,4 @@\n+  if (ik->shared_classpath_index() == 0 && ik->is_shared_boot_class()) {\n+    return;\n+  }\n+\n","filename":"src\/hotspot\/share\/classfile\/classLoader.cpp","additions":27,"deletions":2,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -56,0 +56,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -57,1 +59,1 @@\n-#include \"oops\/instanceMirrorKlass.hpp\"\n+#include \"oops\/instanceMirrorKlass.inline.hpp\"\n@@ -1077,1 +1079,9 @@\n-    if (k->is_typeArray_klass()) {\n+    if (k->is_flatArray_klass()) {\n+      Klass* element_klass = (Klass*) FlatArrayKlass::cast(k)->element_klass();\n+      assert(element_klass->is_inline_klass(), \"Must be inline type component\");\n+      if (is_scratch) {\n+        comp_mirror = Handle(THREAD, HeapShared::scratch_java_mirror(element_klass));\n+      } else {\n+        comp_mirror = Handle(THREAD, element_klass->java_mirror());\n+      }\n+    } else if (k->is_typeArray_klass()) {\n@@ -1088,0 +1098,1 @@\n+      oop comp_oop = element_klass->java_mirror();\n@@ -1091,1 +1102,1 @@\n-        comp_mirror = Handle(THREAD, element_klass->java_mirror());\n+        comp_mirror = Handle(THREAD, comp_oop);\n@@ -1147,0 +1158,1 @@\n+\n@@ -1169,3 +1181,3 @@\n-  if (k->class_loader() != nullptr &&\n-      k->class_loader() != SystemDictionary::java_platform_loader() &&\n-      k->class_loader() != SystemDictionary::java_system_loader()) {\n+  if ((k->class_loader() != nullptr &&\n+       k->class_loader() != SystemDictionary::java_platform_loader() &&\n+       k->class_loader() != SystemDictionary::java_system_loader())) {\n@@ -1399,1 +1411,3 @@\n-  if (is_instance)  st->print(\"L\");\n+  if (is_instance)  {\n+    st->print(\"L\");\n+  }\n@@ -1458,0 +1472,4 @@\n+  if (klass->is_flatArray_klass() || (ArrayKlass::cast(klass)->is_null_free_array_klass())) {\n+    \/\/ TODO 8336006 Ignore flat \/ null-free arrays\n+    return;\n+  }\n@@ -2843,1 +2861,1 @@\n-      if (method->name() == vmSymbols::object_initializer_name() &&\n+      if (method->is_object_constructor() &&\n@@ -3202,2 +3220,2 @@\n-  if (m->is_object_initializer()) {\n-    flags |= java_lang_invoke_MemberName::MN_IS_CONSTRUCTOR;\n+  if (m->is_object_constructor()) {\n+    flags |= java_lang_invoke_MemberName::MN_IS_OBJECT_CONSTRUCTOR;\n@@ -3594,1 +3612,1 @@\n-int java_lang_reflect_Field::_trusted_final_offset;\n+int java_lang_reflect_Field::_flags_offset;\n@@ -3604,1 +3622,1 @@\n-  macro(_trusted_final_offset,    k, vmSymbols::trusted_final_name(),    bool_signature,       false); \\\n+  macro(_flags_offset,     k, vmSymbols::flags_name(),     int_signature,    false); \\\n@@ -3669,2 +3687,2 @@\n-void java_lang_reflect_Field::set_trusted_final(oop field) {\n-  field->bool_field_put(_trusted_final_offset, true);\n+void java_lang_reflect_Field::set_flags(oop field, int value) {\n+  field->int_field_put(_flags_offset, value);\n@@ -3973,2 +3991,1 @@\n-int java_lang_boxing_object::_value_offset;\n-int java_lang_boxing_object::_long_value_offset;\n+int* java_lang_boxing_object::_offsets;\n@@ -3976,3 +3993,9 @@\n-#define BOXING_FIELDS_DO(macro) \\\n-  macro(_value_offset,      integerKlass, \"value\", int_signature, false); \\\n-  macro(_long_value_offset, longKlass, \"value\", long_signature, false);\n+#define BOXING_FIELDS_DO(macro)                                                                                                    \\\n+  macro(java_lang_boxing_object::_offsets[T_BOOLEAN - T_BOOLEAN], vmClasses::Boolean_klass(),   \"value\", bool_signature,   false); \\\n+  macro(java_lang_boxing_object::_offsets[T_CHAR - T_BOOLEAN],    vmClasses::Character_klass(), \"value\", char_signature,   false); \\\n+  macro(java_lang_boxing_object::_offsets[T_FLOAT - T_BOOLEAN],   vmClasses::Float_klass(),     \"value\", float_signature,  false); \\\n+  macro(java_lang_boxing_object::_offsets[T_DOUBLE - T_BOOLEAN],  vmClasses::Double_klass(),    \"value\", double_signature, false); \\\n+  macro(java_lang_boxing_object::_offsets[T_BYTE - T_BOOLEAN],    vmClasses::Byte_klass(),      \"value\", byte_signature,   false); \\\n+  macro(java_lang_boxing_object::_offsets[T_SHORT - T_BOOLEAN],   vmClasses::Short_klass(),     \"value\", short_signature,  false); \\\n+  macro(java_lang_boxing_object::_offsets[T_INT - T_BOOLEAN],     vmClasses::Integer_klass(),   \"value\", int_signature,    false); \\\n+  macro(java_lang_boxing_object::_offsets[T_LONG - T_BOOLEAN],    vmClasses::Long_klass(),      \"value\", long_signature,   false);\n@@ -3981,2 +4004,2 @@\n-  InstanceKlass* integerKlass = vmClasses::Integer_klass();\n-  InstanceKlass* longKlass = vmClasses::Long_klass();\n+  assert(T_LONG - T_BOOLEAN == 7, \"Sanity check\");\n+  java_lang_boxing_object::_offsets = NEW_C_HEAP_ARRAY(int, 8, mtInternal);\n@@ -3988,0 +4011,4 @@\n+  if (f->reading()) {\n+    assert(T_LONG - T_BOOLEAN == 7, \"Sanity check\");\n+    java_lang_boxing_object::_offsets = NEW_C_HEAP_ARRAY(int, 8, mtInternal);\n+  }\n@@ -4008,1 +4035,1 @@\n-      box->bool_field_put(_value_offset, value->z);\n+      box->bool_field_put(value_offset(type), value->z);\n@@ -4011,1 +4038,1 @@\n-      box->char_field_put(_value_offset, value->c);\n+      box->char_field_put(value_offset(type), value->c);\n@@ -4014,1 +4041,1 @@\n-      box->float_field_put(_value_offset, value->f);\n+      box->float_field_put(value_offset(type), value->f);\n@@ -4017,1 +4044,1 @@\n-      box->double_field_put(_long_value_offset, value->d);\n+      box->double_field_put(value_offset(type), value->d);\n@@ -4020,1 +4047,1 @@\n-      box->byte_field_put(_value_offset, value->b);\n+      box->byte_field_put(value_offset(type), value->b);\n@@ -4023,1 +4050,1 @@\n-      box->short_field_put(_value_offset, value->s);\n+      box->short_field_put(value_offset(type), value->s);\n@@ -4026,1 +4053,1 @@\n-      box->int_field_put(_value_offset, value->i);\n+      box->int_field_put(value_offset(type), value->i);\n@@ -4029,1 +4056,1 @@\n-      box->long_field_put(_long_value_offset, value->j);\n+      box->long_field_put(value_offset(type), value->j);\n@@ -4051,1 +4078,1 @@\n-    value->z = box->bool_field(_value_offset);\n+    value->z = box->bool_field(value_offset(type));\n@@ -4054,1 +4081,1 @@\n-    value->c = box->char_field(_value_offset);\n+    value->c = box->char_field(value_offset(type));\n@@ -4057,1 +4084,1 @@\n-    value->f = box->float_field(_value_offset);\n+    value->f = box->float_field(value_offset(type));\n@@ -4060,1 +4087,1 @@\n-    value->d = box->double_field(_long_value_offset);\n+    value->d = box->double_field(value_offset(type));\n@@ -4063,1 +4090,1 @@\n-    value->b = box->byte_field(_value_offset);\n+    value->b = box->byte_field(value_offset(type));\n@@ -4066,1 +4093,1 @@\n-    value->s = box->short_field(_value_offset);\n+    value->s = box->short_field(value_offset(type));\n@@ -4069,1 +4096,1 @@\n-    value->i = box->int_field(_value_offset);\n+    value->i = box->int_field(value_offset(type));\n@@ -4072,1 +4099,1 @@\n-    value->j = box->long_field(_long_value_offset);\n+    value->j = box->long_field(value_offset(type));\n@@ -4085,1 +4112,1 @@\n-    box->bool_field_put(_value_offset, value->z);\n+    box->bool_field_put(value_offset(type), value->z);\n@@ -4088,1 +4115,1 @@\n-    box->char_field_put(_value_offset, value->c);\n+    box->char_field_put(value_offset(type), value->c);\n@@ -4091,1 +4118,1 @@\n-    box->float_field_put(_value_offset, value->f);\n+    box->float_field_put(value_offset(type), value->f);\n@@ -4094,1 +4121,1 @@\n-    box->double_field_put(_long_value_offset, value->d);\n+    box->double_field_put(value_offset(type), value->d);\n@@ -4097,1 +4124,1 @@\n-    box->byte_field_put(_value_offset, value->b);\n+    box->byte_field_put(value_offset(type), value->b);\n@@ -4100,1 +4127,1 @@\n-    box->short_field_put(_value_offset, value->s);\n+    box->short_field_put(value_offset(type), value->s);\n@@ -4103,1 +4130,1 @@\n-    box->int_field_put(_value_offset, value->i);\n+    box->int_field_put(value_offset(type), value->i);\n@@ -4106,1 +4133,1 @@\n-    box->long_field_put(_long_value_offset, value->j);\n+    box->long_field_put(value_offset(type), value->j);\n@@ -4502,1 +4529,0 @@\n-\n@@ -4512,1 +4538,1 @@\n-  return (flags(mname) & (MN_IS_METHOD | MN_IS_CONSTRUCTOR)) > 0;\n+  return (flags(mname) & (MN_IS_METHOD | MN_IS_OBJECT_CONSTRUCTOR)) > 0;\n@@ -5505,16 +5531,11 @@\n-#define CHECK_OFFSET(klass_name, cpp_klass_name, field_name, field_sig) \\\n-  valid &= check_offset(klass_name, cpp_klass_name :: _##field_name ## _offset, #field_name, field_sig)\n-\n-#define CHECK_LONG_OFFSET(klass_name, cpp_klass_name, field_name, field_sig) \\\n-  valid &= check_offset(klass_name, cpp_klass_name :: _##long_ ## field_name ## _offset, #field_name, field_sig)\n-\n-  \/\/ Boxed primitive objects (java_lang_boxing_object)\n-\n-  CHECK_OFFSET(\"java\/lang\/Boolean\",   java_lang_boxing_object, value, \"Z\");\n-  CHECK_OFFSET(\"java\/lang\/Character\", java_lang_boxing_object, value, \"C\");\n-  CHECK_OFFSET(\"java\/lang\/Float\",     java_lang_boxing_object, value, \"F\");\n-  CHECK_LONG_OFFSET(\"java\/lang\/Double\", java_lang_boxing_object, value, \"D\");\n-  CHECK_OFFSET(\"java\/lang\/Byte\",      java_lang_boxing_object, value, \"B\");\n-  CHECK_OFFSET(\"java\/lang\/Short\",     java_lang_boxing_object, value, \"S\");\n-  CHECK_OFFSET(\"java\/lang\/Integer\",   java_lang_boxing_object, value, \"I\");\n-  CHECK_LONG_OFFSET(\"java\/lang\/Long\", java_lang_boxing_object, value, \"J\");\n+#define CHECK_OFFSET(klass_name, type, field_sig) \\\n+  valid &= check_offset(klass_name, java_lang_boxing_object::value_offset(type), \"value\", field_sig)\n+\n+  CHECK_OFFSET(\"java\/lang\/Boolean\",   T_BOOLEAN, \"Z\");\n+  CHECK_OFFSET(\"java\/lang\/Character\", T_CHAR,    \"C\");\n+  CHECK_OFFSET(\"java\/lang\/Float\",     T_FLOAT,   \"F\");\n+  CHECK_OFFSET(\"java\/lang\/Double\",    T_DOUBLE,  \"D\");\n+  CHECK_OFFSET(\"java\/lang\/Byte\",      T_BYTE,    \"B\");\n+  CHECK_OFFSET(\"java\/lang\/Short\",     T_SHORT,   \"S\");\n+  CHECK_OFFSET(\"java\/lang\/Integer\",   T_INT,     \"I\");\n+  CHECK_OFFSET(\"java\/lang\/Long\",      T_LONG,    \"J\");\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":84,"deletions":63,"binary":false,"changes":147,"status":"modified"},{"patch":"@@ -264,0 +264,3 @@\n+  case vmIntrinsics::_newNullRestrictedNonAtomicArray:\n+  case vmIntrinsics::_newNullRestrictedAtomicArray:\n+  case vmIntrinsics::_newNullableAtomicArray:\n@@ -328,0 +331,2 @@\n+  case vmIntrinsics::_makePrivateBuffer:\n+  case vmIntrinsics::_finishPrivateBuffer:\n@@ -337,0 +342,2 @@\n+  case vmIntrinsics::_getValue:\n+  case vmIntrinsics::_getFlatValue:\n@@ -346,0 +353,2 @@\n+  case vmIntrinsics::_putValue:\n+  case vmIntrinsics::_putFlatValue:\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.cpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1258,0 +1258,1 @@\n+  SET_ADDRESS(_extrs, SharedRuntime::allocate_inline_types);\n@@ -1306,0 +1307,8 @@\n+    SET_ADDRESS(_extrs, Runtime1::new_null_free_array);\n+    SET_ADDRESS(_extrs, Runtime1::load_flat_array);\n+    SET_ADDRESS(_extrs, Runtime1::store_flat_array);\n+    SET_ADDRESS(_extrs, Runtime1::substitutability_check);\n+    SET_ADDRESS(_extrs, Runtime1::buffer_inline_args);\n+    SET_ADDRESS(_extrs, Runtime1::buffer_inline_args_no_receiver);\n+    SET_ADDRESS(_extrs, Runtime1::throw_identity_exception);\n+    SET_ADDRESS(_extrs, Runtime1::throw_illegal_monitor_state_exception);\n@@ -1339,0 +1348,2 @@\n+    SET_ADDRESS(_extrs, OptoRuntime::load_unknown_inline_C);\n+    SET_ADDRESS(_extrs, OptoRuntime::store_unknown_inline_C);\n@@ -1366,0 +1377,4 @@\n+  if (UseCompressedOops) {\n+    SET_ADDRESS(_extrs, CompressedOops::base_addr());\n+  }\n+\n","filename":"src\/hotspot\/share\/code\/aotCodeCache.cpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"classfile\/systemDictionary.hpp\"\n@@ -47,0 +48,3 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/flatArrayOop.inline.hpp\"\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -78,0 +82,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -225,0 +230,54 @@\n+JRT_ENTRY(void, InterpreterRuntime::read_flat_field(JavaThread* current, oopDesc* obj, ResolvedFieldEntry* entry))\n+  assert(oopDesc::is_oop(obj), \"Sanity check\");\n+  Handle obj_h(THREAD, obj);\n+\n+  InstanceKlass* holder = InstanceKlass::cast(entry->field_holder());\n+  assert(entry->field_holder()->field_is_flat(entry->field_index()), \"Sanity check\");\n+\n+  InlineLayoutInfo* layout_info = holder->inline_layout_info_adr(entry->field_index());\n+  InlineKlass* field_vklass = layout_info->klass();\n+\n+#ifdef ASSERT\n+  fieldDescriptor fd;\n+  bool found = holder->find_field_from_offset(entry->field_offset(), false, &fd);\n+  assert(found, \"Field not found\");\n+  assert(fd.is_flat(), \"Field must be flat\");\n+#endif \/\/ ASSERT\n+\n+  oop res = field_vklass->read_payload_from_addr(obj_h(), entry->field_offset(), layout_info->kind(), CHECK);\n+  current->set_vm_result_oop(res);\n+JRT_END\n+\n+JRT_ENTRY(void, InterpreterRuntime::read_nullable_flat_field(JavaThread* current, oopDesc* obj, ResolvedFieldEntry* entry))\n+  assert(oopDesc::is_oop(obj), \"Sanity check\");\n+  assert(entry->has_null_marker(), \"Otherwise should not get there\");\n+  Handle obj_h(THREAD, obj);\n+\n+  InstanceKlass* holder = entry->field_holder();\n+  int field_index = entry->field_index();\n+  InlineLayoutInfo* li= holder->inline_layout_info_adr(field_index);\n+\n+#ifdef ASSERT\n+  fieldDescriptor fd;\n+  bool found = holder->find_field_from_offset(entry->field_offset(), false, &fd);\n+  assert(found, \"Field not found\");\n+  assert(fd.is_flat(), \"Field must be flat\");\n+#endif \/\/ ASSERT\n+\n+  InlineKlass* field_vklass = InlineKlass::cast(li->klass());\n+  oop res = field_vklass->read_payload_from_addr(obj_h(), entry->field_offset(), li->kind(), CHECK);\n+  current->set_vm_result_oop(res);\n+\n+JRT_END\n+\n+JRT_ENTRY(void, InterpreterRuntime::write_nullable_flat_field(JavaThread* current, oopDesc* obj, oopDesc* value, ResolvedFieldEntry* entry))\n+  assert(oopDesc::is_oop(obj), \"Sanity check\");\n+  Handle obj_h(THREAD, obj);\n+  assert(value == nullptr || oopDesc::is_oop(value), \"Sanity check\");\n+  Handle val_h(THREAD, value);\n+\n+  InstanceKlass* holder = entry->field_holder();\n+  InlineLayoutInfo* li = holder->inline_layout_info_adr(entry->field_index());\n+  InlineKlass* vk = li->klass();\n+  vk->write_value_to_addr(val_h(), ((char*)(oopDesc*)obj_h()) + entry->field_offset(), li->kind(), true, CHECK);\n+JRT_END\n@@ -234,1 +293,1 @@\n-  objArrayOop obj = oopFactory::new_objArray(klass, size, CHECK);\n+  arrayOop obj = oopFactory::new_objArray(klass, size, CHECK);\n@@ -238,0 +297,12 @@\n+JRT_ENTRY(void, InterpreterRuntime::flat_array_load(JavaThread* current, arrayOopDesc* array, int index))\n+  assert(array->is_flatArray(), \"Must be\");\n+  flatArrayOop farray = (flatArrayOop)array;\n+  oop res = farray->read_value_from_flat_array(index, CHECK);\n+  current->set_vm_result_oop(res);\n+JRT_END\n+\n+JRT_ENTRY(void, InterpreterRuntime::flat_array_store(JavaThread* current, oopDesc* val, arrayOopDesc* array, int index))\n+  assert(array->is_flatArray(), \"Must be\");\n+  flatArrayOop farray = (flatArrayOop)array;\n+  farray->write_value_to_flat_array(val, index, CHECK);\n+JRT_END\n@@ -243,2 +314,2 @@\n-  int          i = last_frame.get_index_u2(Bytecodes::_multianewarray);\n-  Klass* klass   = constants->klass_at(i, CHECK);\n+  int i = last_frame.get_index_u2(Bytecodes::_multianewarray);\n+  Klass* klass = constants->klass_at(i, CHECK);\n@@ -273,0 +344,24 @@\n+JRT_ENTRY(jboolean, InterpreterRuntime::is_substitutable(JavaThread* current, oopDesc* aobj, oopDesc* bobj))\n+  assert(oopDesc::is_oop(aobj) && oopDesc::is_oop(bobj), \"must be valid oops\");\n+\n+  Handle ha(THREAD, aobj);\n+  Handle hb(THREAD, bobj);\n+  JavaValue result(T_BOOLEAN);\n+  JavaCallArguments args;\n+  args.push_oop(ha);\n+  args.push_oop(hb);\n+  methodHandle method(current, Universe::is_substitutable_method());\n+  method->method_holder()->initialize(CHECK_false); \/\/ Ensure class ValueObjectMethods is initialized\n+  JavaCalls::call(&result, method, &args, THREAD);\n+  if (HAS_PENDING_EXCEPTION) {\n+    \/\/ Something really bad happened because isSubstitutable() should not throw exceptions\n+    \/\/ If it is an error, just let it propagate\n+    \/\/ If it is an exception, wrap it into an InternalError\n+    if (!PENDING_EXCEPTION->is_a(vmClasses::Error_klass())) {\n+      Handle e(THREAD, PENDING_EXCEPTION);\n+      CLEAR_PENDING_EXCEPTION;\n+      THROW_MSG_CAUSE_(vmSymbols::java_lang_InternalError(), \"Internal error in substitutability test\", e, false);\n+    }\n+  }\n+  return result.get_jboolean();\n+JRT_END\n@@ -616,0 +711,4 @@\n+JRT_ENTRY(void, InterpreterRuntime::throw_InstantiationError(JavaThread* current))\n+  THROW(vmSymbols::java_lang_InstantiationError());\n+JRT_END\n+\n@@ -695,0 +794,1 @@\n+  bool strict_static_final = info.is_strict() && info.is_static() && info.is_final();\n@@ -700,1 +800,5 @@\n-    get_code = ((is_static) ? Bytecodes::_getstatic : Bytecodes::_getfield);\n+    if (is_static) {\n+      get_code = Bytecodes::_getstatic;\n+    } else {\n+      get_code = Bytecodes::_getfield;\n+    }\n@@ -702,1 +806,1 @@\n-      put_code = ((is_static) ? Bytecodes::_putstatic : Bytecodes::_putfield);\n+        put_code = ((is_static) ? Bytecodes::_putstatic : Bytecodes::_putfield);\n@@ -704,0 +808,13 @@\n+    assert(!info.is_strict_static_unset(), \"after initialization, no unset flags\");\n+  } else if (is_static && (info.is_strict_static_unset() || strict_static_final)) {\n+    \/\/ During <clinit>, closely track the state of strict statics.\n+    \/\/ 1. if we are reading an uninitialized strict static, throw\n+    \/\/ 2. if we are writing one, clear the \"unset\" flag\n+    \/\/\n+    \/\/ Note: If we were handling an attempted write of a null to a\n+    \/\/ null-restricted strict static, we would NOT clear the \"unset\"\n+    \/\/ flag.\n+    assert(klass->is_being_initialized(), \"else should have thrown\");\n+    assert(klass->is_reentrant_initialization(THREAD),\n+      \"<clinit> must be running in current thread\");\n+    klass->notify_strict_static_access(info.index(), is_put, CHECK);\n@@ -707,1 +824,4 @@\n-  entry->set_flags(info.access_flags().is_final(), info.access_flags().is_volatile());\n+  entry->set_flags(info.access_flags().is_final(), info.access_flags().is_volatile(),\n+                   info.is_flat(), info.is_null_free_inline_type(),\n+                   info.has_null_marker());\n+\n@@ -754,1 +874,0 @@\n-\n@@ -759,1 +878,0 @@\n-\n@@ -774,0 +892,15 @@\n+JRT_ENTRY(void, InterpreterRuntime::throw_identity_exception(JavaThread* current, oopDesc* obj))\n+  Klass* klass = cast_to_oop(obj)->klass();\n+  ResourceMark rm(THREAD);\n+  const char* desc = \"Cannot synchronize on an instance of value class \";\n+  const char* className = klass->external_name();\n+  size_t msglen = strlen(desc) + strlen(className) + 1;\n+  char* message = NEW_RESOURCE_ARRAY(char, msglen);\n+  if (nullptr == message) {\n+    \/\/ Out of memory: can't create detailed error message\n+    THROW_MSG(vmSymbols::java_lang_IdentityException(), className);\n+  } else {\n+    jio_snprintf(message, msglen, \"%s%s\", desc, className);\n+    THROW_MSG(vmSymbols::java_lang_IdentityException(), message);\n+  }\n+JRT_END\n@@ -1183,0 +1316,1 @@\n+  assert(entry->is_valid(), \"Invalid ResolvedFieldEntry\");\n@@ -1190,0 +1324,1 @@\n+  bool is_flat = entry->is_flat();\n@@ -1198,1 +1333,1 @@\n-  jfieldID fid = jfieldIDWorkaround::to_jfieldID(field_holder, entry->field_offset(), is_static);\n+  jfieldID fid = jfieldIDWorkaround::to_jfieldID(field_holder, entry->field_offset(), is_static, is_flat);\n@@ -1206,0 +1341,1 @@\n+  assert(entry->is_valid(), \"Invalid ResolvedFieldEntry\");\n@@ -1227,0 +1363,1 @@\n+\n@@ -1228,0 +1365,1 @@\n+  bool is_flat = entry->is_flat();\n@@ -1230,1 +1368,1 @@\n-  jfieldID fid = jfieldIDWorkaround::to_jfieldID(ik, entry->field_offset(), is_static);\n+  jfieldID fid = jfieldIDWorkaround::to_jfieldID(ik, entry->field_offset(), is_static, is_flat);\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":148,"deletions":10,"binary":false,"changes":158,"status":"modified"},{"patch":"@@ -89,1 +89,4 @@\n-    if (!mh->is_native() && !mh->is_static() && !mh->is_object_initializer() && !mh->is_static_initializer()) {\n+    if (!mh->is_native() &&\n+        !mh->is_static() &&\n+        !mh->is_object_constructor() &&\n+        !mh->is_class_initializer()) {\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompiler.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -220,1 +220,1 @@\n-  nonstatic_field(InstanceKlass,               _misc_flags._flags,                            u2)                                    \\\n+  nonstatic_field(InstanceKlass,               _misc_flags._flags,                            u4)                                    \\\n@@ -712,0 +712,3 @@\n+  declare_constant(DataLayout::array_store_data_tag)                      \\\n+  declare_constant(DataLayout::array_load_data_tag)                       \\\n+  declare_constant(DataLayout::acmp_data_tag)                             \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"classfile\/symbolTable.hpp\"\n@@ -40,0 +41,1 @@\n+#include \"oops\/objArrayKlass.hpp\"\n@@ -95,2 +97,2 @@\n-ArrayKlass::ArrayKlass(Symbol* name, KlassKind kind) :\n-  Klass(kind),\n+ArrayKlass::ArrayKlass(Symbol* name, KlassKind kind, markWord prototype_header) :\n+Klass(kind, prototype_header),\n@@ -111,0 +113,19 @@\n+Symbol* ArrayKlass::create_element_klass_array_name(Klass* element_klass, TRAPS) {\n+  ResourceMark rm(THREAD);\n+  Symbol* name = nullptr;\n+  char *name_str = element_klass->name()->as_C_string();\n+  int len = element_klass->name()->utf8_length();\n+  char *new_str = NEW_RESOURCE_ARRAY(char, len + 4);\n+  int idx = 0;\n+  new_str[idx++] = JVM_SIGNATURE_ARRAY;\n+  if (element_klass->is_instance_klass()) { \/\/ it could be an array or simple type\n+    new_str[idx++] = JVM_SIGNATURE_CLASS;\n+  }\n+  memcpy(&new_str[idx], name_str, len * sizeof(char));\n+  idx += len;\n+  if (element_klass->is_instance_klass()) {\n+    new_str[idx++] = JVM_SIGNATURE_ENDCLASS;\n+  }\n+  new_str[idx++] = '\\0';\n+  return SymbolTable::new_symbol(new_str);\n+}\n@@ -142,1 +163,1 @@\n-          ObjArrayKlass::allocate_objArray_klass(class_loader_data(), dim + 1, this, CHECK_NULL);\n+      ObjArrayKlass::allocate_objArray_klass(class_loader_data(), dim + 1, this, false, CHECK_NULL);\n@@ -200,0 +221,4 @@\n+oop ArrayKlass::component_mirror() const {\n+  return java_lang_Class::component_mirror(java_mirror());\n+}\n+\n","filename":"src\/hotspot\/share\/oops\/arrayKlass.cpp","additions":28,"deletions":3,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -56,0 +56,1 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n@@ -265,1 +266,1 @@\n-      \/\/ All of these should have been reverted back to ClassIndex before calling\n+      \/\/ All of these should have been reverted back to Unresolved before calling\n@@ -623,0 +624,6 @@\n+void check_is_inline_type(Klass* k, TRAPS) {\n+  if (!k->is_inline_klass()) {\n+    THROW(vmSymbols::java_lang_IncompatibleClassChangeError());\n+  }\n+}\n+\n@@ -660,0 +667,1 @@\n+  bool inline_type_signature = false;\n@@ -668,0 +676,3 @@\n+  if (inline_type_signature) {\n+    name->decrement_refcount();\n+  }\n@@ -676,0 +687,16 @@\n+  if (!HAS_PENDING_EXCEPTION && inline_type_signature) {\n+    check_is_inline_type(k, THREAD);\n+  }\n+\n+  if (!HAS_PENDING_EXCEPTION) {\n+    Klass* bottom_klass = nullptr;\n+    if (k->is_objArray_klass()) {\n+      bottom_klass = ObjArrayKlass::cast(k)->bottom_klass();\n+      assert(bottom_klass != nullptr, \"Should be set\");\n+      assert(bottom_klass->is_instance_klass() || bottom_klass->is_typeArray_klass(), \"Sanity check\");\n+    } else if (k->is_flatArray_klass()) {\n+      bottom_klass = FlatArrayKlass::cast(k)->element_klass();\n+      assert(bottom_klass != nullptr, \"Should be set\");\n+    }\n+  }\n+\n","filename":"src\/hotspot\/share\/oops\/constantPool.cpp","additions":28,"deletions":1,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -213,0 +213,1 @@\n+      invoke_code = Bytecodes::_invokevirtual;\n@@ -228,1 +229,1 @@\n-    method_entry->set_bytecode2(Bytecodes::_invokevirtual);\n+    method_entry->set_bytecode2(invoke_code);\n","filename":"src\/hotspot\/share\/oops\/cpCache.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -72,0 +72,1 @@\n+#include \"oops\/markWord.hpp\"\n@@ -76,0 +77,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -152,0 +154,5 @@\n+void InlineLayoutInfo::metaspace_pointers_do(MetaspaceClosure* it) {\n+  log_trace(cds)(\"Iter(InlineFieldInfo): %p\", this);\n+  it->push(&_klass);\n+}\n+\n@@ -173,0 +180,13 @@\n+bool InstanceKlass::field_is_null_free_inline_type(int index) const {\n+  return field(index).field_flags().is_null_free_inline_type();\n+}\n+\n+bool InstanceKlass::is_class_in_loadable_descriptors_attribute(Symbol* name) const {\n+  if (_loadable_descriptors == nullptr) return false;\n+  for (int i = 0; i < _loadable_descriptors->length(); i++) {\n+        Symbol* class_name = _constants->symbol_at(_loadable_descriptors->at(i));\n+        if (class_name == name) return true;\n+  }\n+  return false;\n+}\n+\n@@ -467,1 +487,2 @@\n-                                       parser.is_interface());\n+                                       parser.is_interface(),\n+                                       parser.is_inline_type());\n@@ -490,0 +511,3 @@\n+  } else if (parser.is_inline_type()) {\n+    \/\/ inline type\n+    ik = new (loader_data, size, use_class_space, THREAD) InlineKlass(parser);\n@@ -506,0 +530,6 @@\n+#ifdef ASSERT\n+  ik->bounds_check((address) ik->start_of_vtable(), false, size);\n+  ik->bounds_check((address) ik->start_of_itable(), false, size);\n+  ik->bounds_check((address) ik->end_of_itable(), true, size);\n+  ik->bounds_check((address) ik->end_of_nonstatic_oop_maps(), true, size);\n+#endif \/\/ASSERT\n@@ -509,0 +539,23 @@\n+#ifndef PRODUCT\n+bool InstanceKlass::bounds_check(address addr, bool edge_ok, intptr_t size_in_bytes) const {\n+  const char* bad = nullptr;\n+  address end = nullptr;\n+  if (addr < (address)this) {\n+    bad = \"before\";\n+  } else if (addr == (address)this) {\n+    if (edge_ok)  return true;\n+    bad = \"just before\";\n+  } else if (addr == (end = (address)this + sizeof(intptr_t) * (size_in_bytes < 0 ? size() : size_in_bytes))) {\n+    if (edge_ok)  return true;\n+    bad = \"just after\";\n+  } else if (addr > end) {\n+    bad = \"after\";\n+  } else {\n+    return true;\n+  }\n+  tty->print_cr(\"%s object bounds: \" INTPTR_FORMAT \" [\" INTPTR_FORMAT \"..\" INTPTR_FORMAT \"]\",\n+      bad, (intptr_t)addr, (intptr_t)this, (intptr_t)end);\n+  Verbose = WizardMode = true; this->print(); \/\/@@\n+  return false;\n+}\n+#endif \/\/PRODUCT\n@@ -536,2 +589,2 @@\n-InstanceKlass::InstanceKlass(const ClassFileParser& parser, KlassKind kind, ReferenceType reference_type) :\n-  Klass(kind),\n+InstanceKlass::InstanceKlass(const ClassFileParser& parser, KlassKind kind, markWord prototype_header, ReferenceType reference_type) :\n+  Klass(kind, prototype_header),\n@@ -548,1 +601,4 @@\n-  _init_thread(nullptr)\n+  _init_thread(nullptr),\n+  _inline_layout_info_array(nullptr),\n+  _loadable_descriptors(nullptr),\n+  _adr_inlineklass_fixed_block(nullptr)\n@@ -555,0 +611,3 @@\n+  if (parser.has_inline_fields()) {\n+    set_has_inline_type_fields();\n+  }\n@@ -694,0 +753,5 @@\n+  if (inline_layout_info_array() != nullptr) {\n+    MetadataFactory::free_array<InlineLayoutInfo>(loader_data, inline_layout_info_array());\n+  }\n+  set_inline_layout_info_array(nullptr);\n+\n@@ -728,0 +792,7 @@\n+  if (loadable_descriptors() != nullptr &&\n+      loadable_descriptors() != Universe::the_empty_short_array() &&\n+      !loadable_descriptors()->is_shared()) {\n+    MetadataFactory::free_array<jushort>(loader_data, loadable_descriptors());\n+  }\n+  set_loadable_descriptors(nullptr);\n+\n@@ -967,0 +1038,101 @@\n+\n+  \/\/ If a class declares a method that uses an inline class as an argument\n+  \/\/ type or return inline type, this inline class must be loaded during the\n+  \/\/ linking of this class because size and properties of the inline class\n+  \/\/ must be known in order to be able to perform inline type optimizations.\n+  \/\/ The implementation below is an approximation of this rule, the code\n+  \/\/ iterates over all methods of the current class (including overridden\n+  \/\/ methods), not only the methods declared by this class. This\n+  \/\/ approximation makes the code simpler, and doesn't change the semantic\n+  \/\/ because classes declaring methods overridden by the current class are\n+  \/\/ linked (and have performed their own pre-loading) before the linking\n+  \/\/ of the current class.\n+\n+\n+  \/\/ Note:\n+  \/\/ Inline class types are loaded during\n+  \/\/ the loading phase (see ClassFileParser::post_process_parsed_stream()).\n+  \/\/ Inline class types used as element types for array creation\n+  \/\/ are not pre-loaded. Their loading is triggered by either anewarray\n+  \/\/ or multianewarray bytecodes.\n+\n+  \/\/ Could it be possible to do the following processing only if the\n+  \/\/ class uses inline types?\n+  if (EnableValhalla) {\n+    ResourceMark rm(THREAD);\n+    for (AllFieldStream fs(this); !fs.done(); fs.next()) {\n+      if (fs.is_null_free_inline_type() && fs.access_flags().is_static()) {\n+        assert(fs.access_flags().is_strict(), \"null-free fields must be strict\");\n+        Symbol* sig = fs.signature();\n+        TempNewSymbol s = Signature::strip_envelope(sig);\n+        if (s != name()) {\n+          log_info(class, preload)(\"Preloading class %s during linking of class %s. Cause: a null-free static field is declared with this type\", s->as_C_string(), name()->as_C_string());\n+          Klass* klass = SystemDictionary::resolve_or_fail(s,\n+                                                          Handle(THREAD, class_loader()), true,\n+                                                          CHECK_false);\n+          if (HAS_PENDING_EXCEPTION) {\n+            log_warning(class, preload)(\"Preloading of class %s during linking of class %s (cause: null-free static field) failed: %s\",\n+                                      s->as_C_string(), name()->as_C_string(), PENDING_EXCEPTION->klass()->name()->as_C_string());\n+            return false; \/\/ Exception is still pending\n+          }\n+          log_info(class, preload)(\"Preloading of class %s during linking of class %s (cause: null-free static field) succeeded\",\n+                                   s->as_C_string(), name()->as_C_string());\n+          assert(klass != nullptr, \"Sanity check\");\n+          if (klass->is_abstract()) {\n+            THROW_MSG_(vmSymbols::java_lang_IncompatibleClassChangeError(),\n+                      err_msg(\"Class %s expects class %s to be concrete value class, but it is an abstract class\",\n+                      name()->as_C_string(),\n+                      InstanceKlass::cast(klass)->external_name()), false);\n+          }\n+          if (!klass->is_inline_klass()) {\n+            THROW_MSG_(vmSymbols::java_lang_IncompatibleClassChangeError(),\n+                       err_msg(\"class %s expects class %s to be a value class but it is an identity class\",\n+                       name()->as_C_string(), klass->external_name()), false);\n+          }\n+          InlineKlass* vk = InlineKlass::cast(klass);\n+          \/\/ the inline_type_field_klasses_array might have been loaded with CDS, so update only if not already set and check consistency\n+          InlineLayoutInfo* li = inline_layout_info_adr(fs.index());\n+          if (li->klass() == nullptr) {\n+            li->set_klass(InlineKlass::cast(vk));\n+            li->set_kind(LayoutKind::REFERENCE);\n+          }\n+          assert(get_inline_type_field_klass(fs.index()) == vk, \"Must match\");\n+        } else {\n+          InlineLayoutInfo* li = inline_layout_info_adr(fs.index());\n+          if (li->klass() == nullptr) {\n+            li->set_klass(InlineKlass::cast(this));\n+            li->set_kind(LayoutKind::REFERENCE);\n+          }\n+          assert(get_inline_type_field_klass(fs.index()) == this, \"Must match\");\n+        }\n+      }\n+    }\n+\n+    \/\/ Aggressively preloading all classes from the LoadableDescriptors attribute\n+    if (loadable_descriptors() != nullptr) {\n+      HandleMark hm(THREAD);\n+      for (int i = 0; i < loadable_descriptors()->length(); i++) {\n+        Symbol* sig = constants()->symbol_at(loadable_descriptors()->at(i));\n+        if (!Signature::has_envelope(sig)) continue;\n+        TempNewSymbol class_name = Signature::strip_envelope(sig);\n+        if (class_name == name()) continue;\n+        log_info(class, preload)(\"Preloading class %s during linking of class %s because of the class is listed in the LoadableDescriptors attribute\", sig->as_C_string(), name()->as_C_string());\n+        oop loader = class_loader();\n+        Klass* klass = SystemDictionary::resolve_or_null(class_name,\n+                                                         Handle(THREAD, loader), THREAD);\n+        if (HAS_PENDING_EXCEPTION) {\n+          CLEAR_PENDING_EXCEPTION;\n+        }\n+        if (klass != nullptr) {\n+          log_info(class, preload)(\"Preloading of class %s during linking of class %s (cause: LoadableDescriptors attribute) succeeded\", class_name->as_C_string(), name()->as_C_string());\n+          if (!klass->is_inline_klass()) {\n+            \/\/ Non value class are allowed by the current spec, but it could be an indication of an issue so let's log a warning\n+              log_warning(class, preload)(\"Preloading class %s during linking of class %s (cause: LoadableDescriptors attribute) but loaded class is not a value class\", class_name->as_C_string(), name()->as_C_string());\n+          }\n+        } else {\n+          log_warning(class, preload)(\"Preloading of class %s during linking of class %s (cause: LoadableDescriptors attribute) failed\", class_name->as_C_string(), name()->as_C_string());\n+        }\n+      }\n+    }\n+  }\n+\n@@ -1271,0 +1443,21 @@\n+  \/\/ Pre-allocating an all-zero value to be used to reset nullable flat storages\n+  if (is_inline_klass()) {\n+      InlineKlass* vk = InlineKlass::cast(this);\n+      if (vk->has_nullable_atomic_layout()) {\n+        oop val = vk->allocate_instance(THREAD);\n+        if (HAS_PENDING_EXCEPTION) {\n+            Handle e(THREAD, PENDING_EXCEPTION);\n+            CLEAR_PENDING_EXCEPTION;\n+            {\n+                EXCEPTION_MARK;\n+                add_initialization_error(THREAD, e);\n+                \/\/ Locks object, set state, and notify all waiting threads\n+                set_initialization_state_and_notify(initialization_error, THREAD);\n+                CLEAR_PENDING_EXCEPTION;\n+            }\n+            THROW_OOP(e());\n+        }\n+        vk->set_null_reset_value(val);\n+      }\n+  }\n+\n@@ -1303,1 +1496,0 @@\n-\n@@ -1324,0 +1516,30 @@\n+\n+    if (has_strict_static_fields() && !HAS_PENDING_EXCEPTION) {\n+      \/\/ Step 9 also verifies that strict static fields have been initialized.\n+      \/\/ Status bits were set in ClassFileParser::post_process_parsed_stream.\n+      \/\/ After <clinit>, bits must all be clear, or else we must throw an error.\n+      \/\/ This is an extremely fast check, so we won't bother with a timer.\n+      assert(fields_status() != nullptr, \"\");\n+      Symbol* bad_strict_static = nullptr;\n+      for (int index = 0; index < fields_status()->length(); index++) {\n+        \/\/ Very fast loop over single byte array looking for a set bit.\n+        if (fields_status()->adr_at(index)->is_strict_static_unset()) {\n+          \/\/ This strict static field has not been set by the class initializer.\n+          \/\/ Note that in the common no-error case, we read no field metadata.\n+          \/\/ We only unpack it when we need to report an error.\n+          FieldInfo fi = field(index);\n+          bad_strict_static = fi.name(constants());\n+          if (debug_logging_enabled) {\n+            ResourceMark rm(jt);\n+            const char* msg = format_strict_static_message(bad_strict_static);\n+            log_debug(class, init)(\"%s\", msg);\n+          } else {\n+            \/\/ If we are not logging, do not bother to look for a second offense.\n+            break;\n+          }\n+        }\n+      }\n+      if (bad_strict_static != nullptr) {\n+        throw_strict_static_exception(bad_strict_static, \"is unset after initialization of\", THREAD);\n+      }\n+    }\n@@ -1376,0 +1598,68 @@\n+void InstanceKlass::notify_strict_static_access(int field_index, bool is_writing, TRAPS) {\n+  guarantee(field_index >= 0 && field_index < fields_status()->length(), \"valid field index\");\n+  DEBUG_ONLY(FieldInfo debugfi = field(field_index));\n+  assert(debugfi.access_flags().is_strict(), \"\");\n+  assert(debugfi.access_flags().is_static(), \"\");\n+  FieldStatus& fs = *fields_status()->adr_at(field_index);\n+  LogTarget(Trace, class, init) lt;\n+  if (lt.is_enabled()) {\n+    ResourceMark rm(THREAD);\n+    LogStream ls(lt);\n+    FieldInfo fi = field(field_index);\n+    ls.print(\"notify %s %s %s%s \",\n+             external_name(), is_writing? \"Write\" : \"Read\",\n+             fs.is_strict_static_unset() ? \"Unset\" : \"(set)\",\n+             fs.is_strict_static_unread() ? \"+Unread\" : \"\");\n+    fi.print(&ls, constants());\n+  }\n+  if (fs.is_strict_static_unset()) {\n+    assert(fs.is_strict_static_unread(), \"ClassFileParser resp.\");\n+    \/\/ If it is not set, there are only two reasonable things we can do here:\n+    \/\/ - mark it set if this is putstatic\n+    \/\/ - throw an error (Read-Before-Write) if this is getstatic\n+\n+    \/\/ The unset state is (or should be) transient, and observable only in one\n+    \/\/ thread during the execution of <clinit>.  Something is wrong here as this\n+    \/\/ should not be possible\n+    guarantee(is_reentrant_initialization(THREAD), \"unscoped access to strict static\");\n+    if (is_writing) {\n+      \/\/ clear the \"unset\" bit, since the field is actually going to be written\n+      fs.update_strict_static_unset(false);\n+    } else {\n+      \/\/ throw an IllegalStateException, since we are reading before writing\n+      \/\/ see also InstanceKlass::initialize_impl, Step 8 (at end)\n+      Symbol* bad_strict_static = field(field_index).name(constants());\n+      throw_strict_static_exception(bad_strict_static, \"is unset before first read in\", CHECK);\n+    }\n+  } else {\n+    \/\/ Ensure no write after read for final strict statics\n+    FieldInfo fi = field(field_index);\n+    bool is_final = fi.access_flags().is_final();\n+    if (is_final) {\n+      \/\/ no final write after read, so observing a constant freezes it, as if <clinit> ended early\n+      \/\/ (maybe we could trust the constant a little earlier, before <clinit> ends)\n+      if (is_writing && !fs.is_strict_static_unread()) {\n+        Symbol* bad_strict_static = fi.name(constants());\n+        throw_strict_static_exception(bad_strict_static, \"is set after read (as final) in\", CHECK);\n+      } else if (!is_writing && fs.is_strict_static_unread()) {\n+        fs.update_strict_static_unread(false);\n+      }\n+    }\n+  }\n+}\n+\n+void InstanceKlass::throw_strict_static_exception(Symbol* field_name, const char* when, TRAPS) {\n+  ResourceMark rm(THREAD);\n+  const char* msg = format_strict_static_message(field_name, when);\n+  THROW_MSG(vmSymbols::java_lang_IllegalStateException(), msg);\n+}\n+\n+const char* InstanceKlass::format_strict_static_message(Symbol* field_name, const char* when) {\n+  stringStream ss;\n+  ss.print(\"Strict static \\\"%s\\\" %s %s\",\n+           field_name->as_C_string(),\n+           when == nullptr ? \"is unset in\" : when,\n+           external_name());\n+  return ss.as_string();\n+}\n+\n@@ -1628,1 +1918,1 @@\n-      ObjArrayKlass* k = ObjArrayKlass::allocate_objArray_klass(class_loader_data(), 1, this, CHECK_NULL);\n+      ObjArrayKlass* k = ObjArrayKlass::allocate_objArray_klass(class_loader_data(), 1, this, false, CHECK_NULL);\n@@ -1635,1 +1925,1 @@\n-  ObjArrayKlass* ak = array_klasses();\n+  ArrayKlass* ak = array_klasses();\n@@ -1642,2 +1932,2 @@\n-  ObjArrayKlass* oak = array_klasses_acquire();\n-  if (oak == nullptr) {\n+  ArrayKlass* ak = array_klasses_acquire();\n+  if (ak == nullptr) {\n@@ -1646,1 +1936,1 @@\n-    return oak->array_klass_or_null(n);\n+    return ak->array_klass_or_null(n);\n@@ -1663,1 +1953,1 @@\n-  if (clinit != nullptr && clinit->has_valid_initializer_flags()) {\n+  if (clinit != nullptr && clinit->is_class_initializer()) {\n@@ -1772,4 +2062,0 @@\n-bool InstanceKlass::contains_field_offset(int offset) {\n-  fieldDescriptor fd;\n-  return find_field_from_offset(offset, false, &fd);\n-}\n@@ -1857,0 +2143,9 @@\n+bool InstanceKlass::contains_field_offset(int offset) {\n+  if (this->is_inline_klass()) {\n+    InlineKlass* vk = InlineKlass::cast(this);\n+    return offset >= vk->payload_offset() && offset < (vk->payload_offset() + vk->payload_size_in_bytes());\n+  } else {\n+    fieldDescriptor fd;\n+    return find_field_from_offset(offset, false, &fd);\n+  }\n+}\n@@ -2240,0 +2535,3 @@\n+    if (name == vmSymbols::object_initializer_name()) {\n+      break;  \/\/ <init> is never inherited\n+    }\n@@ -2638,0 +2936,1 @@\n+  it->push(&_loadable_descriptors);\n@@ -2639,0 +2938,1 @@\n+  it->push(&_inline_layout_info_array, MetaspaceClosure::_writable);\n@@ -2684,1 +2984,1 @@\n-  \/\/ These are not allocated from metaspace. They are safe to set to null.\n+  \/\/ These are not allocated from metaspace. They are safe to set to nullptr.\n@@ -2773,0 +3073,4 @@\n+  if (is_inline_klass()) {\n+    InlineKlass::cast(this)->initialize_calling_convention(CHECK);\n+  }\n+\n@@ -2806,1 +3110,1 @@\n-    assert(this == array_klasses()->bottom_klass(), \"sanity\");\n+    assert(this == ObjArrayKlass::cast(array_klasses())->bottom_klass(), \"sanity\");\n@@ -3003,0 +3307,2 @@\n+  return signature_name_of_carrier(JVM_SIGNATURE_CLASS);\n+}\n@@ -3004,0 +3310,1 @@\n+const char* InstanceKlass::signature_name_of_carrier(char c) const {\n@@ -3010,1 +3317,1 @@\n-  \/\/ Add L as type indicator\n+  \/\/ Add L or Q as type indicator\n@@ -3012,1 +3319,1 @@\n-  dest[dest_index++] = JVM_SIGNATURE_CLASS;\n+  dest[dest_index++] = c;\n@@ -3293,0 +3600,19 @@\n+void InstanceKlass::check_can_be_annotated_with_NullRestricted(InstanceKlass* type, Symbol* container_klass_name, TRAPS) {\n+  assert(type->is_instance_klass(), \"Sanity check\");\n+  if (type->is_identity_class()) {\n+    ResourceMark rm(THREAD);\n+    THROW_MSG(vmSymbols::java_lang_IncompatibleClassChangeError(),\n+              err_msg(\"Class %s expects class %s to be a value class, but it is an identity class\",\n+              container_klass_name->as_C_string(),\n+              type->external_name()));\n+  }\n+\n+  if (type->is_abstract()) {\n+    ResourceMark rm(THREAD);\n+    THROW_MSG(vmSymbols::java_lang_IncompatibleClassChangeError(),\n+              err_msg(\"Class %s expects class %s to be concrete value type, but it is an abstract class\",\n+              container_klass_name->as_C_string(),\n+              type->external_name()));\n+  }\n+}\n+\n@@ -3359,2 +3685,1 @@\n-  \/\/ Remember to strip ACC_SUPER bit\n-  return (access & (~JVM_ACC_SUPER));\n+  return access;\n@@ -3614,1 +3939,4 @@\n-static void print_vtable(intptr_t* start, int len, outputStream* st) {\n+static void print_vtable(address self, intptr_t* start, int len, outputStream* st) {\n+  ResourceMark rm;\n+  int* forward_refs = NEW_RESOURCE_ARRAY(int, len);\n+  for (int i = 0; i < len; i++)  forward_refs[i] = 0;\n@@ -3618,0 +3946,5 @@\n+    if (forward_refs[i] != 0) {\n+      int from = forward_refs[i];\n+      int off = (int) start[from];\n+      st->print(\" (offset %d <= [%d])\", off, from);\n+    }\n@@ -3621,0 +3954,6 @@\n+    } else if (self != nullptr && e > 0 && e < 0x10000) {\n+      address location = self + e;\n+      int index = (int)((intptr_t*)location - start);\n+      st->print(\" (offset %d => [%d])\", (int)e, index);\n+      if (index >= 0 && index < len)\n+        forward_refs[index] = i;\n@@ -3627,1 +3966,22 @@\n-  return print_vtable(reinterpret_cast<intptr_t*>(start), len, st);\n+  return print_vtable(nullptr, reinterpret_cast<intptr_t*>(start), len, st);\n+}\n+\n+template<typename T>\n+ static void print_array_on(outputStream* st, Array<T>* array) {\n+   if (array == nullptr) { st->print_cr(\"nullptr\"); return; }\n+   array->print_value_on(st); st->cr();\n+   if (Verbose || WizardMode) {\n+     for (int i = 0; i < array->length(); i++) {\n+       st->print(\"%d : \", i); array->at(i)->print_value_on(st); st->cr();\n+     }\n+   }\n+ }\n+\n+static void print_array_on(outputStream* st, Array<int>* array) {\n+  if (array == nullptr) { st->print_cr(\"nullptr\"); return; }\n+  array->print_value_on(st); st->cr();\n+  if (Verbose || WizardMode) {\n+    for (int i = 0; i < array->length(); i++) {\n+      st->print(\"%d : %d\", i, array->at(i)); st->cr();\n+    }\n+  }\n@@ -3668,8 +4028,2 @@\n-  st->print(BULLET\"methods:           \"); methods()->print_value_on(st);               st->cr();\n-  if (Verbose || WizardMode) {\n-    Array<Method*>* method_array = methods();\n-    for (int i = 0; i < method_array->length(); i++) {\n-      st->print(\"%d : \", i); method_array->at(i)->print_value(); st->cr();\n-    }\n-  }\n-  st->print(BULLET\"method ordering:   \"); method_ordering()->print_value_on(st);      st->cr();\n+  st->print(BULLET\"methods:           \"); print_array_on(st, methods());\n+  st->print(BULLET\"method ordering:   \"); print_array_on(st, method_ordering());\n@@ -3677,7 +4031,1 @@\n-    st->print(BULLET\"default_methods:   \"); default_methods()->print_value_on(st);    st->cr();\n-    if (Verbose) {\n-      Array<Method*>* method_array = default_methods();\n-      for (int i = 0; i < method_array->length(); i++) {\n-        st->print(\"%d : \", i); method_array->at(i)->print_value(); st->cr();\n-      }\n-    }\n+    st->print(BULLET\"default_methods:   \"); print_array_on(st, default_methods());\n@@ -3743,0 +4091,1 @@\n+  st->print(BULLET\"loadable descriptors:     \"); loadable_descriptors()->print_value_on(st); st->cr();\n@@ -3753,1 +4102,1 @@\n-  if (itable_length() > 0 && (Verbose || WizardMode))  print_vtable(start_of_itable(), itable_length(), st);\n+  if (itable_length() > 0 && (Verbose || WizardMode))  print_vtable(nullptr, start_of_itable(), itable_length(), st);\n@@ -3780,0 +4129,1 @@\n+  for (int i = 0; i < _indent; i++) _st->print(\"  \");\n@@ -3782,1 +4132,1 @@\n-     fd->print_on(_st);\n+     fd->print_on(_st, _base_offset);\n@@ -3785,2 +4135,2 @@\n-     fd->print_on_for(_st, _obj);\n-     _st->cr();\n+     fd->print_on_for(_st, _obj, _indent, _base_offset);\n+     if (!fd->field_flags().is_flat()) _st->cr();\n@@ -3791,1 +4141,1 @@\n-void InstanceKlass::oop_print_on(oop obj, outputStream* st) {\n+void InstanceKlass::oop_print_on(oop obj, outputStream* st, int indent, int base_offset) {\n@@ -3807,1 +4157,1 @@\n-  FieldPrinter print_field(st, obj);\n+  FieldPrinter print_field(st, obj, indent, base_offset);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":394,"deletions":44,"binary":false,"changes":438,"status":"modified"},{"patch":"@@ -277,17 +277,0 @@\n-static markWord make_prototype(const Klass* kls) {\n-  markWord prototype = markWord::prototype();\n-#ifdef _LP64\n-  if (UseCompactObjectHeaders) {\n-    \/\/ With compact object headers, the narrow Klass ID is part of the mark word.\n-    \/\/ We therfore seed the mark word with the narrow Klass ID.\n-    \/\/ Note that only those Klass that can be instantiated have a narrow Klass ID.\n-    \/\/ For those who don't, we leave the klass bits empty and assert if someone\n-    \/\/ tries to use those.\n-    const narrowKlass nk = CompressedKlassPointers::is_encodable(kls) ?\n-        CompressedKlassPointers::encode(const_cast<Klass*>(kls)) : 0;\n-    prototype = prototype.set_narrow_klass(nk);\n-  }\n-#endif\n-  return prototype;\n-}\n-\n@@ -302,2 +285,1 @@\n-Klass::Klass(KlassKind kind) : _kind(kind),\n-                               _prototype_header(make_prototype(this)),\n+Klass::Klass(KlassKind kind, markWord prototype_header) : _kind(kind),\n@@ -305,0 +287,1 @@\n+  set_prototype_header(make_prototype_header(this, prototype_header));\n@@ -318,1 +301,1 @@\n-  int lh = array_layout_helper(tag, hsize, etype, exact_log2(esize));\n+  int lh = array_layout_helper(tag, false, hsize, etype, exact_log2(esize));\n@@ -1031,4 +1014,2 @@\n-     if (UseCompactObjectHeaders) {\n-       st->print(BULLET\"prototype_header: \" INTPTR_FORMAT, _prototype_header.value());\n-       st->cr();\n-     }\n+     st->print(BULLET\"prototype_header: \" INTPTR_FORMAT, _prototype_header.value());\n+     st->cr();\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":5,"deletions":24,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -63,0 +63,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -123,1 +124,0 @@\n-\n@@ -161,0 +161,5 @@\n+address Method::get_c2i_inline_entry() {\n+  assert(adapter() != nullptr, \"must have\");\n+  return adapter()->get_c2i_inline_entry();\n+}\n+\n@@ -166,0 +171,5 @@\n+address Method::get_c2i_unverified_inline_entry() {\n+  assert(adapter() != nullptr, \"must have\");\n+  return adapter()->get_c2i_unverified_inline_entry();\n+}\n+\n@@ -391,1 +401,1 @@\n-  if (!method_holder()->is_rewritten()) {\n+  if (!method_holder()->is_rewritten() || CDSConfig::is_valhalla_preview()) {\n@@ -421,0 +431,2 @@\n+    _from_compiled_inline_entry = _adapter->get_c2i_inline_entry();\n+    _from_compiled_inline_ro_entry = _adapter->get_c2i_inline_ro_entry();\n@@ -676,0 +688,16 @@\n+\/\/ InlineKlass the method is declared to return. This must not\n+\/\/ safepoint as it is called with references live on the stack at\n+\/\/ locations the GC is unaware of.\n+InlineKlass* Method::returns_inline_type(Thread* thread) const {\n+  assert(InlineTypeReturnedAsFields, \"Inline types should never be returned as fields\");\n+  if (is_native()) {\n+    return nullptr;\n+  }\n+  NoSafepointVerifier nsv;\n+  SignatureStream ss(signature());\n+  while (!ss.at_return_type()) {\n+    ss.next();\n+  }\n+  return ss.as_inline_klass(method_holder());\n+}\n+\n@@ -824,0 +852,5 @@\n+  if (has_scalarized_return()) {\n+    \/\/ Don't treat this as (trivial) getter method because the\n+    \/\/ inline type should be returned in a scalarized form.\n+    return false;\n+  }\n@@ -845,0 +878,5 @@\n+  if (has_scalarized_args()) {\n+    \/\/ Don't treat this as (trivial) setter method because the\n+    \/\/ inline type argument should be passed in a scalarized form.\n+    return false;\n+  }\n@@ -855,1 +893,2 @@\n-          Bytecodes::is_return(java_code_at(last_index)));\n+          Bytecodes::is_return(java_code_at(last_index)) &&\n+          !has_scalarized_args());\n@@ -858,6 +897,1 @@\n-bool Method::has_valid_initializer_flags() const {\n-  return (is_static() ||\n-          method_holder()->major_version() < 51);\n-}\n-\n-bool Method::is_static_initializer() const {\n+bool Method::is_class_initializer() const {\n@@ -867,2 +901,3 @@\n-  return name() == vmSymbols::class_initializer_name() &&\n-         has_valid_initializer_flags();\n+  return (name() == vmSymbols::class_initializer_name() &&\n+          (is_static() ||\n+           method_holder()->major_version() < 51));\n@@ -871,2 +906,3 @@\n-bool Method::is_object_initializer() const {\n-   return name() == vmSymbols::object_initializer_name();\n+\/\/ A method named <init>, is a classic object constructor.\n+bool Method::is_object_constructor() const {\n+  return name() == vmSymbols::object_initializer_name();\n@@ -935,1 +971,1 @@\n-  if( constants()->tag_at(klass_index).is_unresolved_klass() ) {\n+  if( constants()->tag_at(klass_index).is_unresolved_klass()) {\n@@ -950,1 +986,3 @@\n-    if (constants()->tag_at(klass_index).is_unresolved_klass()) return false;\n+    if (constants()->tag_at(klass_index).is_unresolved_klass()) {\n+      return false;\n+    }\n@@ -1119,0 +1157,2 @@\n+    _from_compiled_inline_entry = nullptr;\n+    _from_compiled_inline_ro_entry = nullptr;\n@@ -1121,0 +1161,2 @@\n+    _from_compiled_inline_entry = adapter()->get_c2i_inline_entry();\n+    _from_compiled_inline_ro_entry = adapter()->get_c2i_inline_ro_entry();\n@@ -1154,0 +1196,2 @@\n+  _from_compiled_inline_entry = nullptr;\n+  _from_compiled_inline_ro_entry = nullptr;\n@@ -1179,0 +1223,2 @@\n+  set_has_scalarized_args(false);\n+  set_has_scalarized_return(false);\n@@ -1215,0 +1261,3 @@\n+  if (InlineTypeReturnedAsFields && returns_inline_type(THREAD) && !has_scalarized_return()) {\n+    set_has_scalarized_return();\n+  }\n@@ -1266,0 +1315,2 @@\n+  mh->_from_compiled_inline_entry = adapter->get_c2i_inline_entry();\n+  mh->_from_compiled_inline_ro_entry = adapter->get_c2i_inline_ro_entry();\n@@ -1282,0 +1333,12 @@\n+address Method::verified_inline_code_entry() {\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  assert(_from_compiled_inline_entry != nullptr, \"must be set\");\n+  return _from_compiled_inline_entry;\n+}\n+\n+address Method::verified_inline_ro_code_entry() {\n+  DEBUG_ONLY(NoSafepointVerifier nsv;)\n+  assert(_from_compiled_inline_ro_entry != nullptr, \"must be set\");\n+  return _from_compiled_inline_ro_entry;\n+}\n+\n@@ -1313,0 +1376,2 @@\n+  mh->_from_compiled_inline_entry = code->verified_inline_entry_point();\n+  mh->_from_compiled_inline_ro_entry = code->verified_inline_ro_entry_point();\n@@ -1505,0 +1570,2 @@\n+    m->set_from_compiled_inline_entry(m->adapter()->get_c2i_inline_entry());\n+    m->set_from_compiled_inline_ro_entry(m->adapter()->get_c2i_inline_ro_entry());\n@@ -2271,0 +2338,25 @@\n+bool Method::is_scalarized_arg(int idx) const {\n+  if (!has_scalarized_args()) {\n+    return false;\n+  }\n+  \/\/ Search through signature and check if argument is wrapped in T_METADATA\/T_VOID\n+  int depth = 0;\n+  const GrowableArray<SigEntry>* sig = adapter()->get_sig_cc();\n+  for (int i = 0; i < sig->length(); i++) {\n+    BasicType bt = sig->at(i)._bt;\n+    if (bt == T_METADATA) {\n+      depth++;\n+    }\n+    if (idx == 0) {\n+      break; \/\/ Argument found\n+    }\n+    if (bt == T_VOID && (sig->at(i-1)._bt != T_LONG && sig->at(i-1)._bt != T_DOUBLE)) {\n+      depth--;\n+    }\n+    if (depth == 0 && bt != T_LONG && bt != T_DOUBLE) {\n+      idx--; \/\/ Advance to next argument\n+    }\n+  }\n+  return depth != 0;\n+}\n+\n@@ -2303,0 +2395,4 @@\n+#ifdef ASSERT\n+  if (valid_itable_index())\n+    st->print_cr(\" - itable index:      %d\",   itable_index());\n+#endif\n@@ -2310,1 +2406,3 @@\n-  st->print_cr(\" - compiled entry     \" PTR_FORMAT, p2i(from_compiled_entry()));\n+  st->print_cr(\" - compiled entry           \" PTR_FORMAT, p2i(from_compiled_entry()));\n+  st->print_cr(\" - compiled inline entry    \" PTR_FORMAT, p2i(from_compiled_inline_entry()));\n+  st->print_cr(\" - compiled inline ro entry \" PTR_FORMAT, p2i(from_compiled_inline_ro_entry()));\n@@ -2380,0 +2478,1 @@\n+  if (WizardMode) access_flags().print_on(st);\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":115,"deletions":16,"binary":false,"changes":131,"status":"modified"},{"patch":"@@ -149,1 +149,1 @@\n-    st->print(\"flags(%d) \", flags);\n+    st->print(\"flags(%d) %p\/%d\", flags, data(), in_bytes(DataLayout::flags_offset()));\n@@ -219,1 +219,1 @@\n-  assert(TypeStackSlotEntries::per_arg_count() > ReturnTypeEntry::static_cell_count(), \"code to test for arguments\/results broken\");\n+  assert(TypeStackSlotEntries::per_arg_count() > SingleTypeEntry::static_cell_count(), \"code to test for arguments\/results broken\");\n@@ -229,1 +229,1 @@\n-    ret_cell = ReturnTypeEntry::static_cell_count();\n+    ret_cell = SingleTypeEntry::static_cell_count();\n@@ -332,1 +332,1 @@\n-void ReturnTypeEntry::clean_weak_klass_links(bool always_clean) {\n+void SingleTypeEntry::clean_weak_klass_links(bool always_clean) {\n@@ -370,1 +370,1 @@\n-void ReturnTypeEntry::print_data_on(outputStream* st) const {\n+void SingleTypeEntry::print_data_on(outputStream* st) const {\n@@ -531,0 +531,4 @@\n+  if (data()->flags()) {\n+    st->cr();\n+    tab(st);\n+  }\n@@ -656,0 +660,36 @@\n+void ArrayStoreData::print_data_on(outputStream* st, const char* extra) const {\n+  print_shared(st, \"ArrayStore\", extra);\n+  st->cr();\n+  tab(st, true);\n+  st->print(\"array\");\n+  _array.print_data_on(st);\n+  tab(st, true);\n+  st->print(\"element\");\n+  if (null_seen()) {\n+    st->print(\" (null seen)\");\n+  }\n+  tab(st);\n+  print_receiver_data_on(st);\n+}\n+\n+void ArrayLoadData::print_data_on(outputStream* st, const char* extra) const {\n+  print_shared(st, \"ArrayLoad\", extra);\n+  st->cr();\n+  tab(st, true);\n+  st->print(\"array\");\n+  _array.print_data_on(st);\n+  tab(st, true);\n+  st->print(\"element\");\n+  _element.print_data_on(st);\n+}\n+\n+void ACmpData::print_data_on(outputStream* st, const char* extra) const {\n+  BranchData::print_data_on(st, extra);\n+  tab(st, true);\n+  st->print(\"left\");\n+  _left.print_data_on(st);\n+  tab(st, true);\n+  st->print(\"right\");\n+  _right.print_data_on(st);\n+}\n+\n@@ -674,1 +714,0 @@\n-  case Bytecodes::_aastore:\n@@ -680,0 +719,4 @@\n+  case Bytecodes::_aaload:\n+    return ArrayLoadData::static_cell_count();\n+  case Bytecodes::_aastore:\n+    return ArrayStoreData::static_cell_count();\n@@ -719,2 +762,0 @@\n-  case Bytecodes::_if_acmpeq:\n-  case Bytecodes::_if_acmpne:\n@@ -724,0 +765,3 @@\n+  case Bytecodes::_if_acmpne:\n+  case Bytecodes::_if_acmpeq:\n+    return ACmpData::static_cell_count();\n@@ -782,0 +826,1 @@\n+  case Bytecodes::_aaload:\n@@ -998,1 +1043,0 @@\n-  case Bytecodes::_aastore:\n@@ -1007,0 +1051,8 @@\n+  case Bytecodes::_aaload:\n+    cell_count = ArrayLoadData::static_cell_count();\n+    tag = DataLayout::array_load_data_tag;\n+    break;\n+  case Bytecodes::_aastore:\n+    cell_count = ArrayStoreData::static_cell_count();\n+    tag = DataLayout::array_store_data_tag;\n+    break;\n@@ -1078,2 +1130,0 @@\n-  case Bytecodes::_if_acmpeq:\n-  case Bytecodes::_if_acmpne:\n@@ -1085,0 +1135,5 @@\n+  case Bytecodes::_if_acmpeq:\n+  case Bytecodes::_if_acmpne:\n+    cell_count = ACmpData::static_cell_count();\n+    tag = DataLayout::acmp_data_tag;\n+    break;\n@@ -1152,0 +1207,6 @@\n+  case DataLayout::array_store_data_tag:\n+    return ((new ArrayStoreData(this))->cell_count());\n+  case DataLayout::array_load_data_tag:\n+    return ((new ArrayLoadData(this))->cell_count());\n+  case DataLayout::acmp_data_tag:\n+    return ((new ACmpData(this))->cell_count());\n@@ -1186,0 +1247,6 @@\n+  case DataLayout::array_store_data_tag:\n+    return new ArrayStoreData(this);\n+  case DataLayout::array_load_data_tag:\n+    return new ArrayLoadData(this);\n+  case DataLayout::acmp_data_tag:\n+    return new ACmpData(this);\n","filename":"src\/hotspot\/share\/oops\/methodData.cpp","additions":78,"deletions":11,"binary":false,"changes":89,"status":"modified"},{"patch":"@@ -88,0 +88,40 @@\n+Symbol* Symbol::fundamental_name(TRAPS) {\n+  if (char_at(0) == JVM_SIGNATURE_CLASS && ends_with(JVM_SIGNATURE_ENDCLASS)) {\n+    return SymbolTable::new_symbol(this, 1, utf8_length() - 1);\n+  } else {\n+    \/\/ reference count is incremented to be consistent with the behavior with\n+    \/\/ the SymbolTable::new_symbol() call above\n+    this->increment_refcount();\n+    return this;\n+  }\n+}\n+\n+bool Symbol::is_same_fundamental_type(Symbol* s) const {\n+  if (this == s) return true;\n+  if (utf8_length() < 3) return false;\n+  int offset1, offset2, len;\n+  if (ends_with(JVM_SIGNATURE_ENDCLASS)) {\n+    if (char_at(0) != JVM_SIGNATURE_CLASS) return false;\n+    offset1 = 1;\n+    len = utf8_length() - 2;\n+  } else {\n+    offset1 = 0;\n+    len = utf8_length();\n+  }\n+  if (ends_with(JVM_SIGNATURE_ENDCLASS)) {\n+    if (s->char_at(0) != JVM_SIGNATURE_CLASS) return false;\n+    offset2 = 1;\n+  } else {\n+    offset2 = 0;\n+  }\n+  if ((offset2 + len) > s->utf8_length()) return false;\n+  if ((utf8_length() - offset1 * 2) != (s->utf8_length() - offset2 * 2))\n+    return false;\n+  int l = len;\n+  while (l-- > 0) {\n+    if (char_at(offset1 + l) != s->char_at(offset2 + l))\n+      return false;\n+  }\n+  return true;\n+}\n+\n","filename":"src\/hotspot\/share\/oops\/symbol.cpp","additions":40,"deletions":0,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -816,0 +816,6 @@\n+  product(bool, UseArrayLoadStoreProfile, true,                             \\\n+          \"Take advantage of profiling at array load\/store\")                \\\n+                                                                            \\\n+  product(bool, UseACmpProfile, true,                                       \\\n+          \"Take advantage of profiling at acmp\")                            \\\n+                                                                            \\\n@@ -853,0 +859,2 @@\n+  develop(ccstrlist, PrintInlineKlassFields, \"\",                            \\\n+          \"Print fields collected by InlineKlass::collect_fields\")          \\\n","filename":"src\/hotspot\/share\/opto\/c2_globals.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -62,0 +62,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -69,0 +70,1 @@\n+#include \"opto\/movenode.hpp\"\n@@ -408,0 +410,3 @@\n+  if (dead->is_InlineType()) {\n+    remove_inline_type(dead);\n+  }\n@@ -455,0 +460,3 @@\n+    if (n->outcnt() == 0) {\n+      worklist.push(n);\n+    }\n@@ -463,0 +471,6 @@\n+  remove_useless_nodes(_inline_type_nodes,  useful); \/\/ remove useless inline type nodes\n+#ifdef ASSERT\n+  if (_modified_nodes != nullptr) {\n+    _modified_nodes->remove_useless_nodes(useful.member_set());\n+  }\n+#endif\n@@ -649,0 +663,1 @@\n+      _has_circular_inline_type(false),\n@@ -668,0 +683,1 @@\n+      _inline_type_nodes (comp_arena(), 8, 0, nullptr),\n@@ -773,4 +789,2 @@\n-      const TypeTuple *domain = StartOSRNode::osr_domain();\n-      const TypeTuple *range = TypeTuple::make_range(method()->signature());\n-      init_tf(TypeFunc::make(domain, range));\n-      StartNode* s = new StartOSRNode(root(), domain);\n+      init_tf(TypeFunc::make(method(), \/* is_osr_compilation = *\/ true));\n+      StartNode* s = new StartOSRNode(root(), tf()->domain_sig());\n@@ -783,1 +797,1 @@\n-      StartNode* s = new StartNode(root(), tf()->domain());\n+      StartNode* s = new StartNode(root(), tf()->domain_cc());\n@@ -894,0 +908,10 @@\n+  if (needs_stack_repair()) {\n+    \/\/ One extra slot for the special stack increment value\n+    next_slot += 2;\n+  }\n+  \/\/ TODO 8284443 Only reserve extra slot if needed\n+  if (InlineTypeReturnedAsFields) {\n+    \/\/ One extra slot to hold the null marker for a nullable\n+    \/\/ inline type return if we run out of registers.\n+    next_slot += 2;\n+  }\n@@ -931,0 +955,1 @@\n+      _has_circular_inline_type(false),\n@@ -1083,0 +1108,4 @@\n+  _has_flat_accesses = false;\n+  _flat_accesses_share_alias = true;\n+  _scalarize_in_safepoints = false;\n+\n@@ -1367,0 +1396,9 @@\n+  if (ta && ta->is_not_flat()) {\n+    \/\/ Erase not flat property for alias analysis.\n+    tj = ta = ta->cast_to_not_flat(false);\n+  }\n+  if (ta && ta->is_not_null_free()) {\n+    \/\/ Erase not null free property for alias analysis.\n+    tj = ta = ta->cast_to_not_null_free(false);\n+  }\n+\n@@ -1380,0 +1418,2 @@\n+    \/\/ For flat inline type array, each field has its own slice so\n+    \/\/ we must include the field offset.\n@@ -1420,1 +1460,1 @@\n-      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,nullptr,false,offset);\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,nullptr,false,Type::Offset(offset), ta->field_offset());\n@@ -1424,1 +1464,6 @@\n-      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,nullptr,false,offset);\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,nullptr,false,Type::Offset(offset), ta->field_offset());\n+    }\n+    \/\/ Initially all flattened array accesses share a single slice\n+    if (ta->is_flat() && ta->elem() != TypeInstPtr::BOTTOM && _flat_accesses_share_alias) {\n+      const TypeAry* tary = TypeAry::make(TypeInstPtr::BOTTOM, ta->size(), \/* stable= *\/ false, \/* flat= *\/ true);\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,nullptr,false,Type::Offset(offset), Type::Offset(Type::OffsetBot));\n@@ -1431,1 +1476,1 @@\n-      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,aklass,false,offset);\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,aklass,false,Type::Offset(offset), ta->field_offset());\n@@ -1481,1 +1526,1 @@\n-        tj = to = TypeInstPtr::make(TypePtr::BotPTR, env()->Object_klass(), false, nullptr, offset);\n+        tj = to = TypeInstPtr::make(TypePtr::BotPTR, env()->Object_klass(), false, nullptr, Type::Offset(offset));\n@@ -1502,1 +1547,1 @@\n-        assert(tj == TypeInstPtr::make(to->ptr(), canonical_holder, is_known_inst, nullptr, offset, instance_id), \"exact type should be canonical type\");\n+        assert(tj == TypeInstPtr::make(to->ptr(), canonical_holder, is_known_inst, nullptr, Type::Offset(offset), instance_id), \"exact type should be canonical type\");\n@@ -1505,1 +1550,1 @@\n-        tj = to = TypeInstPtr::make(to->ptr(), canonical_holder, is_known_inst, nullptr, offset, instance_id);\n+        tj = to = TypeInstPtr::make(to->ptr(), canonical_holder, is_known_inst, nullptr, Type::Offset(offset), instance_id);\n@@ -1520,1 +1565,1 @@\n-                                       offset);\n+                                       Type::Offset(offset));\n@@ -1526,1 +1571,1 @@\n-        tj = tk = TypeInstKlassPtr::make(TypePtr::NotNull, env()->Object_klass(), offset);\n+        tj = tk = TypeInstKlassPtr::make(TypePtr::NotNull, env()->Object_klass(), Type::Offset(offset));\n@@ -1528,1 +1573,1 @@\n-        tj = tk = TypeAryKlassPtr::make(TypePtr::NotNull, tk->is_aryklassptr()->elem(), k, offset);\n+        tj = tk = TypeAryKlassPtr::make(TypePtr::NotNull, tk->is_aryklassptr()->elem(), k, Type::Offset(offset), tk->is_not_flat(), tk->is_not_null_free(), tk->is_flat(), tk->is_null_free());\n@@ -1531,1 +1576,0 @@\n-\n@@ -1661,1 +1705,1 @@\n-Compile::AliasType* Compile::find_alias_type(const TypePtr* adr_type, bool no_create, ciField* original_field) {\n+Compile::AliasType* Compile::find_alias_type(const TypePtr* adr_type, bool no_create, ciField* original_field, bool uncached) {\n@@ -1666,3 +1710,6 @@\n-  AliasCacheEntry* ace = probe_alias_cache(adr_type);\n-  if (ace->_adr_type == adr_type) {\n-    return alias_type(ace->_index);\n+  AliasCacheEntry* ace = nullptr;\n+  if (!uncached) {\n+    ace = probe_alias_cache(adr_type);\n+    if (ace->_adr_type == adr_type) {\n+      return alias_type(ace->_index);\n+    }\n@@ -1718,0 +1765,1 @@\n+    ciField* field = nullptr;\n@@ -1724,0 +1772,1 @@\n+      const Type* elemtype = flat->is_aryptr()->elem();\n@@ -1725,1 +1774,8 @@\n-        alias_type(idx)->set_element(flat->is_aryptr()->elem());\n+        alias_type(idx)->set_element(elemtype);\n+      }\n+      int field_offset = flat->is_aryptr()->field_offset().get();\n+      if (flat->is_flat() &&\n+          field_offset != Type::OffsetBot) {\n+        ciInlineKlass* vk = elemtype->inline_klass();\n+        field_offset += vk->payload_offset();\n+        field = vk->get_field_by_offset(field_offset, false);\n@@ -1741,0 +1797,2 @@\n+      if (flat->offset() == in_bytes(Klass::layout_helper_offset()))\n+        alias_type(idx)->set_rewritable(false);\n@@ -1751,1 +1809,0 @@\n-      ciField* field;\n@@ -1758,0 +1815,4 @@\n+      } else if (tinst->is_inlinetypeptr()) {\n+        \/\/ Inline type field\n+        ciInlineKlass* vk = tinst->inline_klass();\n+        field = vk->get_field_by_offset(tinst->offset(), false);\n@@ -1762,7 +1823,14 @@\n-      assert(field == nullptr ||\n-             original_field == nullptr ||\n-             (field->holder() == original_field->holder() &&\n-              field->offset_in_bytes() == original_field->offset_in_bytes() &&\n-              field->is_static() == original_field->is_static()), \"wrong field?\");\n-      \/\/ Set field() and is_rewritable() attributes.\n-      if (field != nullptr)  alias_type(idx)->set_field(field);\n+    }\n+    assert(field == nullptr ||\n+           original_field == nullptr ||\n+           (field->holder() == original_field->holder() &&\n+            field->offset_in_bytes() == original_field->offset_in_bytes() &&\n+            field->is_static() == original_field->is_static()), \"wrong field?\");\n+    \/\/ Set field() and is_rewritable() attributes.\n+    if (field != nullptr) {\n+      alias_type(idx)->set_field(field);\n+      if (flat->isa_aryptr()) {\n+        \/\/ Fields of flat arrays are rewritable although they are declared final\n+        assert(flat->is_flat(), \"must be a flat array\");\n+        alias_type(idx)->set_rewritable(true);\n+      }\n@@ -1773,3 +1841,4 @@\n-  ace->_adr_type = adr_type;\n-  ace->_index    = idx;\n-  assert(alias_type(adr_type) == alias_type(idx),  \"type must be installed\");\n+  if (!uncached) {\n+    ace->_adr_type = adr_type;\n+    ace->_index    = idx;\n+    assert(alias_type(adr_type) == alias_type(idx),  \"type must be installed\");\n@@ -1777,6 +1846,7 @@\n-  \/\/ Might as well try to fill the cache for the flattened version, too.\n-  AliasCacheEntry* face = probe_alias_cache(flat);\n-  if (face->_adr_type == nullptr) {\n-    face->_adr_type = flat;\n-    face->_index    = idx;\n-    assert(alias_type(flat) == alias_type(idx), \"flat type must work too\");\n+    \/\/ Might as well try to fill the cache for the flattened version, too.\n+    AliasCacheEntry* face = probe_alias_cache(flat);\n+    if (face->_adr_type == nullptr) {\n+      face->_adr_type = flat;\n+      face->_index    = idx;\n+      assert(alias_type(flat) == alias_type(idx), \"flat type must work too\");\n+    }\n@@ -1904,0 +1974,398 @@\n+void Compile::add_inline_type(Node* n) {\n+  assert(n->is_InlineType(), \"unexpected node\");\n+  _inline_type_nodes.push(n);\n+}\n+\n+void Compile::remove_inline_type(Node* n) {\n+  assert(n->is_InlineType(), \"unexpected node\");\n+  if (_inline_type_nodes.contains(n)) {\n+    _inline_type_nodes.remove(n);\n+  }\n+}\n+\n+\/\/ Does the return value keep otherwise useless inline type allocations alive?\n+static bool return_val_keeps_allocations_alive(Node* ret_val) {\n+  ResourceMark rm;\n+  Unique_Node_List wq;\n+  wq.push(ret_val);\n+  bool some_allocations = false;\n+  for (uint i = 0; i < wq.size(); i++) {\n+    Node* n = wq.at(i);\n+    if (n->outcnt() > 1) {\n+      \/\/ Some other use for the allocation\n+      return false;\n+    } else if (n->is_InlineType()) {\n+      wq.push(n->in(1));\n+    } else if (n->is_Phi()) {\n+      for (uint j = 1; j < n->req(); j++) {\n+        wq.push(n->in(j));\n+      }\n+    } else if (n->is_CheckCastPP() &&\n+               n->in(1)->is_Proj() &&\n+               n->in(1)->in(0)->is_Allocate()) {\n+      some_allocations = true;\n+    } else if (n->is_CheckCastPP()) {\n+      wq.push(n->in(1));\n+    }\n+  }\n+  return some_allocations;\n+}\n+\n+void Compile::process_inline_types(PhaseIterGVN &igvn, bool remove) {\n+  \/\/ Make sure that the return value does not keep an otherwise unused allocation alive\n+  if (tf()->returns_inline_type_as_fields()) {\n+    Node* ret = nullptr;\n+    for (uint i = 1; i < root()->req(); i++) {\n+      Node* in = root()->in(i);\n+      if (in->Opcode() == Op_Return) {\n+        assert(ret == nullptr, \"only one return\");\n+        ret = in;\n+      }\n+    }\n+    if (ret != nullptr) {\n+      Node* ret_val = ret->in(TypeFunc::Parms);\n+      if (igvn.type(ret_val)->isa_oopptr() &&\n+          return_val_keeps_allocations_alive(ret_val)) {\n+        igvn.replace_input_of(ret, TypeFunc::Parms, InlineTypeNode::tagged_klass(igvn.type(ret_val)->inline_klass(), igvn));\n+        assert(ret_val->outcnt() == 0, \"should be dead now\");\n+        igvn.remove_dead_node(ret_val);\n+      }\n+    }\n+  }\n+  if (_inline_type_nodes.length() == 0) {\n+    return;\n+  }\n+  \/\/ Scalarize inline types in safepoint debug info.\n+  \/\/ Delay this until all inlining is over to avoid getting inconsistent debug info.\n+  set_scalarize_in_safepoints(true);\n+  for (int i = _inline_type_nodes.length()-1; i >= 0; i--) {\n+    InlineTypeNode* vt = _inline_type_nodes.at(i)->as_InlineType();\n+    vt->make_scalar_in_safepoints(&igvn);\n+    igvn.record_for_igvn(vt);\n+  }\n+  if (remove) {\n+    \/\/ Remove inline type nodes by replacing them with their oop input\n+    while (_inline_type_nodes.length() > 0) {\n+      InlineTypeNode* vt = _inline_type_nodes.pop()->as_InlineType();\n+      if (vt->outcnt() == 0) {\n+        igvn.remove_dead_node(vt);\n+        continue;\n+      }\n+      for (DUIterator i = vt->outs(); vt->has_out(i); i++) {\n+        DEBUG_ONLY(bool must_be_buffered = false);\n+        Node* u = vt->out(i);\n+        \/\/ Check if any users are blackholes. If so, rewrite them to use either the\n+        \/\/ allocated buffer, or individual components, instead of the inline type node\n+        \/\/ that goes away.\n+        if (u->is_Blackhole()) {\n+          BlackholeNode* bh = u->as_Blackhole();\n+\n+          \/\/ Unlink the old input\n+          int idx = bh->find_edge(vt);\n+          assert(idx != -1, \"The edge should be there\");\n+          bh->del_req(idx);\n+          --i;\n+\n+          if (vt->is_allocated(&igvn)) {\n+            \/\/ Already has the allocated instance, blackhole that\n+            bh->add_req(vt->get_oop());\n+          } else {\n+            \/\/ Not allocated yet, blackhole the components\n+            for (uint c = 0; c < vt->field_count(); c++) {\n+              bh->add_req(vt->field_value(c));\n+            }\n+          }\n+\n+          \/\/ Node modified, record for IGVN\n+          igvn.record_for_igvn(bh);\n+        }\n+#ifdef ASSERT\n+        \/\/ Verify that inline type is buffered when replacing by oop\n+        else if (u->is_InlineType()) {\n+          \/\/ InlineType uses don't need buffering because they are about to be replaced as well\n+        } else if (u->is_Phi()) {\n+          \/\/ TODO 8302217 Remove this once InlineTypeNodes are reliably pushed through\n+        } else {\n+          must_be_buffered = true;\n+        }\n+        if (must_be_buffered && !vt->is_allocated(&igvn)) {\n+          vt->dump(0);\n+          u->dump(0);\n+          assert(false, \"Should have been buffered\");\n+        }\n+#endif\n+      }\n+      igvn.replace_node(vt, vt->get_oop());\n+    }\n+  }\n+  igvn.optimize();\n+}\n+\n+void Compile::adjust_flat_array_access_aliases(PhaseIterGVN& igvn) {\n+  if (!_has_flat_accesses) {\n+    return;\n+  }\n+  \/\/ Initially, all flat array accesses share the same slice to\n+  \/\/ keep dependencies with Object[] array accesses (that could be\n+  \/\/ to a flat array) correct. We're done with parsing so we\n+  \/\/ now know all flat array accesses in this compile\n+  \/\/ unit. Let's move flat array accesses to their own slice,\n+  \/\/ one per element field. This should help memory access\n+  \/\/ optimizations.\n+  ResourceMark rm;\n+  Unique_Node_List wq;\n+  wq.push(root());\n+\n+  Node_List mergememnodes;\n+  Node_List memnodes;\n+\n+  \/\/ Alias index currently shared by all flat memory accesses\n+  int index = get_alias_index(TypeAryPtr::INLINES);\n+\n+  \/\/ Find MergeMem nodes and flat array accesses\n+  for (uint i = 0; i < wq.size(); i++) {\n+    Node* n = wq.at(i);\n+    if (n->is_Mem()) {\n+      const TypePtr* adr_type = nullptr;\n+      adr_type = get_adr_type(get_alias_index(n->adr_type()));\n+      if (adr_type == TypeAryPtr::INLINES) {\n+        memnodes.push(n);\n+      }\n+    } else if (n->is_MergeMem()) {\n+      MergeMemNode* mm = n->as_MergeMem();\n+      if (mm->memory_at(index) != mm->base_memory()) {\n+        mergememnodes.push(n);\n+      }\n+    }\n+    for (uint j = 0; j < n->req(); j++) {\n+      Node* m = n->in(j);\n+      if (m != nullptr) {\n+        wq.push(m);\n+      }\n+    }\n+  }\n+\n+  if (memnodes.size() > 0) {\n+    _flat_accesses_share_alias = false;\n+\n+    \/\/ We are going to change the slice for the flat array\n+    \/\/ accesses so we need to clear the cache entries that refer to\n+    \/\/ them.\n+    for (uint i = 0; i < AliasCacheSize; i++) {\n+      AliasCacheEntry* ace = &_alias_cache[i];\n+      if (ace->_adr_type != nullptr &&\n+          ace->_adr_type->is_flat()) {\n+        ace->_adr_type = nullptr;\n+        ace->_index = (i != 0) ? 0 : AliasIdxTop; \/\/ Make sure the nullptr adr_type resolves to AliasIdxTop\n+      }\n+    }\n+\n+    \/\/ Find what aliases we are going to add\n+    int start_alias = num_alias_types()-1;\n+    int stop_alias = 0;\n+\n+    for (uint i = 0; i < memnodes.size(); i++) {\n+      Node* m = memnodes.at(i);\n+      const TypePtr* adr_type = nullptr;\n+      adr_type = m->adr_type();\n+#ifdef ASSERT\n+      m->as_Mem()->set_adr_type(adr_type);\n+#endif\n+      int idx = get_alias_index(adr_type);\n+      start_alias = MIN2(start_alias, idx);\n+      stop_alias = MAX2(stop_alias, idx);\n+    }\n+\n+    assert(stop_alias >= start_alias, \"should have expanded aliases\");\n+\n+    Node_Stack stack(0);\n+#ifdef ASSERT\n+    VectorSet seen(Thread::current()->resource_area());\n+#endif\n+    \/\/ Now let's fix the memory graph so each flat array access\n+    \/\/ is moved to the right slice. Start from the MergeMem nodes.\n+    uint last = unique();\n+    for (uint i = 0; i < mergememnodes.size(); i++) {\n+      MergeMemNode* current = mergememnodes.at(i)->as_MergeMem();\n+      Node* n = current->memory_at(index);\n+      MergeMemNode* mm = nullptr;\n+      do {\n+        \/\/ Follow memory edges through memory accesses, phis and\n+        \/\/ narrow membars and push nodes on the stack. Once we hit\n+        \/\/ bottom memory, we pop element off the stack one at a\n+        \/\/ time, in reverse order, and move them to the right slice\n+        \/\/ by changing their memory edges.\n+        if ((n->is_Phi() && n->adr_type() != TypePtr::BOTTOM) || n->is_Mem() || n->adr_type() == TypeAryPtr::INLINES) {\n+          assert(!seen.test_set(n->_idx), \"\");\n+          \/\/ Uses (a load for instance) will need to be moved to the\n+          \/\/ right slice as well and will get a new memory state\n+          \/\/ that we don't know yet. The use could also be the\n+          \/\/ backedge of a loop. We put a place holder node between\n+          \/\/ the memory node and its uses. We replace that place\n+          \/\/ holder with the correct memory state once we know it,\n+          \/\/ i.e. when nodes are popped off the stack. Using the\n+          \/\/ place holder make the logic work in the presence of\n+          \/\/ loops.\n+          if (n->outcnt() > 1) {\n+            Node* place_holder = nullptr;\n+            assert(!n->has_out_with(Op_Node), \"\");\n+            for (DUIterator k = n->outs(); n->has_out(k); k++) {\n+              Node* u = n->out(k);\n+              if (u != current && u->_idx < last) {\n+                bool success = false;\n+                for (uint l = 0; l < u->req(); l++) {\n+                  if (!stack.is_empty() && u == stack.node() && l == stack.index()) {\n+                    continue;\n+                  }\n+                  Node* in = u->in(l);\n+                  if (in == n) {\n+                    if (place_holder == nullptr) {\n+                      place_holder = new Node(1);\n+                      place_holder->init_req(0, n);\n+                    }\n+                    igvn.replace_input_of(u, l, place_holder);\n+                    success = true;\n+                  }\n+                }\n+                if (success) {\n+                  --k;\n+                }\n+              }\n+            }\n+          }\n+          if (n->is_Phi()) {\n+            stack.push(n, 1);\n+            n = n->in(1);\n+          } else if (n->is_Mem()) {\n+            stack.push(n, n->req());\n+            n = n->in(MemNode::Memory);\n+          } else {\n+            assert(n->is_Proj() && n->in(0)->Opcode() == Op_MemBarCPUOrder, \"\");\n+            stack.push(n, n->req());\n+            n = n->in(0)->in(TypeFunc::Memory);\n+          }\n+        } else {\n+          assert(n->adr_type() == TypePtr::BOTTOM || (n->Opcode() == Op_Node && n->_idx >= last) || (n->is_Proj() && n->in(0)->is_Initialize()), \"\");\n+          \/\/ Build a new MergeMem node to carry the new memory state\n+          \/\/ as we build it. IGVN should fold extraneous MergeMem\n+          \/\/ nodes.\n+          mm = MergeMemNode::make(n);\n+          igvn.register_new_node_with_optimizer(mm);\n+          while (stack.size() > 0) {\n+            Node* m = stack.node();\n+            uint idx = stack.index();\n+            if (m->is_Mem()) {\n+              \/\/ Move memory node to its new slice\n+              const TypePtr* adr_type = m->adr_type();\n+              int alias = get_alias_index(adr_type);\n+              Node* prev = mm->memory_at(alias);\n+              igvn.replace_input_of(m, MemNode::Memory, prev);\n+              mm->set_memory_at(alias, m);\n+            } else if (m->is_Phi()) {\n+              \/\/ We need as many new phis as there are new aliases\n+              igvn.replace_input_of(m, idx, mm);\n+              if (idx == m->req()-1) {\n+                Node* r = m->in(0);\n+                for (uint j = (uint)start_alias; j <= (uint)stop_alias; j++) {\n+                  const TypePtr* adr_type = get_adr_type(j);\n+                  if (!adr_type->isa_aryptr() || !adr_type->is_flat() || j == (uint)index) {\n+                    continue;\n+                  }\n+                  Node* phi = new PhiNode(r, Type::MEMORY, get_adr_type(j));\n+                  igvn.register_new_node_with_optimizer(phi);\n+                  for (uint k = 1; k < m->req(); k++) {\n+                    phi->init_req(k, m->in(k)->as_MergeMem()->memory_at(j));\n+                  }\n+                  mm->set_memory_at(j, phi);\n+                }\n+                Node* base_phi = new PhiNode(r, Type::MEMORY, TypePtr::BOTTOM);\n+                igvn.register_new_node_with_optimizer(base_phi);\n+                for (uint k = 1; k < m->req(); k++) {\n+                  base_phi->init_req(k, m->in(k)->as_MergeMem()->base_memory());\n+                }\n+                mm->set_base_memory(base_phi);\n+              }\n+            } else {\n+              \/\/ This is a MemBarCPUOrder node from\n+              \/\/ Parse::array_load()\/Parse::array_store(), in the\n+              \/\/ branch that handles flat arrays hidden under\n+              \/\/ an Object[] array. We also need one new membar per\n+              \/\/ new alias to keep the unknown access that the\n+              \/\/ membars protect properly ordered with accesses to\n+              \/\/ known flat array.\n+              assert(m->is_Proj(), \"projection expected\");\n+              Node* ctrl = m->in(0)->in(TypeFunc::Control);\n+              igvn.replace_input_of(m->in(0), TypeFunc::Control, top());\n+              for (uint j = (uint)start_alias; j <= (uint)stop_alias; j++) {\n+                const TypePtr* adr_type = get_adr_type(j);\n+                if (!adr_type->isa_aryptr() || !adr_type->is_flat() || j == (uint)index) {\n+                  continue;\n+                }\n+                MemBarNode* mb = new MemBarCPUOrderNode(this, j, nullptr);\n+                igvn.register_new_node_with_optimizer(mb);\n+                Node* mem = mm->memory_at(j);\n+                mb->init_req(TypeFunc::Control, ctrl);\n+                mb->init_req(TypeFunc::Memory, mem);\n+                ctrl = new ProjNode(mb, TypeFunc::Control);\n+                igvn.register_new_node_with_optimizer(ctrl);\n+                mem = new ProjNode(mb, TypeFunc::Memory);\n+                igvn.register_new_node_with_optimizer(mem);\n+                mm->set_memory_at(j, mem);\n+              }\n+              igvn.replace_node(m->in(0)->as_Multi()->proj_out(TypeFunc::Control), ctrl);\n+            }\n+            if (idx < m->req()-1) {\n+              idx += 1;\n+              stack.set_index(idx);\n+              n = m->in(idx);\n+              break;\n+            }\n+            \/\/ Take care of place holder nodes\n+            if (m->has_out_with(Op_Node)) {\n+              Node* place_holder = m->find_out_with(Op_Node);\n+              if (place_holder != nullptr) {\n+                Node* mm_clone = mm->clone();\n+                igvn.register_new_node_with_optimizer(mm_clone);\n+                Node* hook = new Node(1);\n+                hook->init_req(0, mm);\n+                igvn.replace_node(place_holder, mm_clone);\n+                hook->destruct(&igvn);\n+              }\n+              assert(!m->has_out_with(Op_Node), \"place holder should be gone now\");\n+            }\n+            stack.pop();\n+          }\n+        }\n+      } while(stack.size() > 0);\n+      \/\/ Fix the memory state at the MergeMem we started from\n+      igvn.rehash_node_delayed(current);\n+      for (uint j = (uint)start_alias; j <= (uint)stop_alias; j++) {\n+        const TypePtr* adr_type = get_adr_type(j);\n+        if (!adr_type->isa_aryptr() || !adr_type->is_flat()) {\n+          continue;\n+        }\n+        current->set_memory_at(j, mm);\n+      }\n+      current->set_memory_at(index, current->base_memory());\n+    }\n+    igvn.optimize();\n+  }\n+  print_method(PHASE_SPLIT_INLINES_ARRAY, 2);\n+#ifdef ASSERT\n+  if (!_flat_accesses_share_alias) {\n+    wq.clear();\n+    wq.push(root());\n+    for (uint i = 0; i < wq.size(); i++) {\n+      Node* n = wq.at(i);\n+      assert(n->adr_type() != TypeAryPtr::INLINES, \"should have been removed from the graph\");\n+      for (uint j = 0; j < n->req(); j++) {\n+        Node* m = n->in(j);\n+        if (m != nullptr) {\n+          wq.push(m);\n+        }\n+      }\n+    }\n+  }\n+#endif\n+}\n+\n@@ -2022,1 +2490,1 @@\n-        if (!live_locals.at(i) && !local->is_top() && local != lhs && local!= rhs) {\n+        if (!live_locals.at(i) && !local->is_top() && local != lhs && local != rhs) {\n@@ -2037,1 +2505,1 @@\n-    \/\/ keep the mondified trap for late query\n+    \/\/ keep the modified trap for late query\n@@ -2243,1 +2711,4 @@\n-  assert(_modified_nodes == nullptr, \"not allowed\");\n+#ifdef ASSERT\n+  Unique_Node_List* modified_nodes = _modified_nodes;\n+  _modified_nodes = nullptr;\n+#endif\n@@ -2256,0 +2727,1 @@\n+  DEBUG_ONLY( _modified_nodes = modified_nodes; )\n@@ -2400,0 +2872,5 @@\n+  \/\/ Process inline type nodes now that all inlining is over\n+  process_inline_types(igvn);\n+\n+  adjust_flat_array_access_aliases(igvn);\n+\n@@ -2402,0 +2879,11 @@\n+  if (C->macro_count() > 0) {\n+    \/\/ Eliminate some macro nodes before EA to reduce analysis pressure\n+    PhaseMacroExpand mexp(igvn);\n+    mexp.eliminate_macro_nodes();\n+    if (failing()) {\n+      return;\n+    }\n+    igvn.set_delay_transform(false);\n+    print_method(PHASE_ITER_GVN_AFTER_ELIMINATION, 2);\n+  }\n+\n@@ -2412,1 +2900,14 @@\n-      if (failing())  return;\n+      if (failing()) {\n+        return;\n+      }\n+      print_method(PHASE_PHASEIDEAL_BEFORE_EA, 2);\n+      if (C->macro_count() > 0) {\n+        \/\/ Eliminate some macro nodes before EA to reduce analysis pressure\n+        PhaseMacroExpand mexp(igvn);\n+        mexp.eliminate_macro_nodes();\n+        if (failing()) {\n+          return;\n+        }\n+        igvn.set_delay_transform(false);\n+        print_method(PHASE_ITER_GVN_AFTER_ELIMINATION, 2);\n+      }\n@@ -2414,0 +2915,1 @@\n+\n@@ -2415,1 +2917,0 @@\n-    print_method(PHASE_PHASEIDEAL_BEFORE_EA, 2);\n@@ -2433,2 +2934,3 @@\n-        if (failing()) return;\n-\n+        if (failing()) {\n+          return;\n+        }\n@@ -2436,3 +2938,0 @@\n-        igvn.optimize();\n-        if (failing()) return;\n-\n@@ -2529,0 +3028,8 @@\n+  assert(_late_inlines.length() == 0 || IncrementalInlineMH || IncrementalInlineVirtual, \"not empty\");\n+\n+  if (_late_inlines.length() > 0) {\n+    \/\/ More opportunities to optimize virtual and MH calls.\n+    \/\/ Though it's maybe too late to perform inlining, strength-reducing them to direct calls is still an option.\n+    process_late_inline_calls_no_inline(igvn);\n+  }\n+\n@@ -2531,0 +3038,7 @@\n+    PhaseMacroExpand mex(igvn);\n+    \/\/ Last attempt to eliminate macro nodes.\n+    mex.eliminate_macro_nodes();\n+    if (failing()) {\n+      return;\n+    }\n+\n@@ -2532,1 +3046,0 @@\n-    PhaseMacroExpand  mex(igvn);\n@@ -2540,0 +3053,4 @@\n+  \/\/ Process inline type nodes again and remove them. From here\n+  \/\/ on we don't need to keep track of field values anymore.\n+  process_inline_types(igvn, \/* remove= *\/ true);\n+\n@@ -2556,0 +3073,1 @@\n+  DEBUG_ONLY( _late_inlines.clear(); )\n@@ -2558,9 +3076,0 @@\n-\n-  assert(_late_inlines.length() == 0 || IncrementalInlineMH || IncrementalInlineVirtual, \"not empty\");\n-\n-  if (_late_inlines.length() > 0) {\n-    \/\/ More opportunities to optimize virtual and MH calls.\n-    \/\/ Though it's maybe too late to perform inlining, strength-reducing them to direct calls is still an option.\n-    process_late_inline_calls_no_inline(igvn);\n-    if (failing())  return;\n-  }\n@@ -3339,0 +3848,1 @@\n+  case Op_StoreLSpecial:\n@@ -3882,0 +4392,5 @@\n+  case Op_InlineType: {\n+    n->dump(-1);\n+    assert(false, \"inline type node was not removed\");\n+    break;\n+  }\n@@ -4257,2 +4772,2 @@\n-      if (accessing_method->is_static_initializer() ||\n-          accessing_method->is_object_initializer() ||\n+      if (accessing_method->is_class_initializer() ||\n+          accessing_method->is_object_constructor() ||\n@@ -4266,1 +4781,1 @@\n-      if (accessing_method->is_static_initializer()) {\n+      if (accessing_method->is_class_initializer()) {\n@@ -4336,0 +4851,1 @@\n+               (n->is_Allocate() && i >= AllocateNode::InlineType) ||\n@@ -4338,1 +4854,1 @@\n-              \"only region, phi, arraycopy, unlock or membar nodes have null data edges\");\n+              \"only region, phi, arraycopy, allocate, unlock or membar nodes have null data edges\");\n@@ -4489,0 +5005,7 @@\n+\n+    \/\/ Do not fold the subtype check to an array klass pointer comparison for null-able inline type arrays\n+    \/\/ because null-free [LMyValue <: null-able [LMyValue but the klasses are different. Perform a full test.\n+    if (!superk->is_aryklassptr()->is_null_free() && superk->is_aryklassptr()->elem()->isa_instklassptr() &&\n+        superk->is_aryklassptr()->elem()->is_instklassptr()->instance_klass()->is_inlinetype()) {\n+      return SSC_full_test;\n+    }\n@@ -4970,0 +5493,21 @@\n+Node* Compile::optimize_acmp(PhaseGVN* phase, Node* a, Node* b) {\n+  const TypeInstPtr* ta = phase->type(a)->isa_instptr();\n+  const TypeInstPtr* tb = phase->type(b)->isa_instptr();\n+  if (!EnableValhalla || ta == nullptr || tb == nullptr ||\n+      ta->is_zero_type() || tb->is_zero_type() ||\n+      !ta->can_be_inline_type() || !tb->can_be_inline_type()) {\n+    \/\/ Use old acmp if one operand is null or not an inline type\n+    return new CmpPNode(a, b);\n+  } else if (ta->is_inlinetypeptr() || tb->is_inlinetypeptr()) {\n+    \/\/ We know that one operand is an inline type. Therefore,\n+    \/\/ new acmp will only return true if both operands are nullptr.\n+    \/\/ Check if both operands are null by or'ing the oops.\n+    a = phase->transform(new CastP2XNode(nullptr, a));\n+    b = phase->transform(new CastP2XNode(nullptr, b));\n+    a = phase->transform(new OrXNode(a, b));\n+    return new CmpXNode(a, phase->MakeConX(0));\n+  }\n+  \/\/ Use new acmp\n+  return nullptr;\n+}\n+\n@@ -5325,0 +5869,2 @@\n+  } else if (bt == T_FLOAT) {\n+    result = new MoveI2FNode(value);\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":607,"deletions":61,"binary":false,"changes":668,"status":"modified"},{"patch":"@@ -56,0 +56,1 @@\n+class CallNode;\n@@ -99,0 +100,1 @@\n+class InlineTypeNode;\n@@ -335,0 +337,1 @@\n+  bool                  _has_circular_inline_type; \/\/ True if method loads an inline type with a circular, non-flat field\n@@ -363,0 +366,3 @@\n+  bool                  _has_flat_accesses;     \/\/ Any known flat array accesses?\n+  bool                  _flat_accesses_share_alias; \/\/ Initially all flat array share a single slice\n+  bool                  _scalarize_in_safepoints; \/\/ Scalarize inline types in safepoint debug info\n@@ -381,0 +387,1 @@\n+  GrowableArray<Node*>  _inline_type_nodes;     \/\/ List of InlineType nodes\n@@ -608,0 +615,2 @@\n+  bool              has_circular_inline_type() const { return _has_circular_inline_type; }\n+  void          set_has_circular_inline_type(bool z) { _has_circular_inline_type = z; }\n@@ -640,0 +649,10 @@\n+  void          set_flat_accesses()              { _has_flat_accesses = true; }\n+  bool          flat_accesses_share_alias() const { return _flat_accesses_share_alias; }\n+  void          set_flat_accesses_share_alias(bool z) { _flat_accesses_share_alias = z; }\n+  bool          scalarize_in_safepoints() const { return _scalarize_in_safepoints; }\n+  void          set_scalarize_in_safepoints(bool z) { _scalarize_in_safepoints = z; }\n+\n+  \/\/ Support for scalarized inline type calling convention\n+  bool              has_scalarized_args() const  { return _method != nullptr && _method->has_scalarized_args(); }\n+  bool              needs_stack_repair()  const  { return _method != nullptr && _method->get_Method()->c2_needs_stack_repair(); }\n+\n@@ -775,0 +794,7 @@\n+  \/\/ Keep track of inline type nodes for later processing\n+  void add_inline_type(Node* n);\n+  void remove_inline_type(Node* n);\n+  void process_inline_types(PhaseIterGVN &igvn, bool remove = false);\n+\n+  void adjust_flat_array_access_aliases(PhaseIterGVN& igvn);\n+\n@@ -957,1 +983,1 @@\n-  AliasType*        alias_type(const TypePtr* adr_type, ciField* field = nullptr) { return find_alias_type(adr_type, false, field); }\n+  AliasType*        alias_type(const TypePtr* adr_type, ciField* field = nullptr, bool uncached = false) { return find_alias_type(adr_type, false, field, uncached); }\n@@ -961,1 +987,1 @@\n-  int               get_alias_index(const TypePtr* at)  { return alias_type(at)->index(); }\n+  int               get_alias_index(const TypePtr* at, bool uncached = false) { return alias_type(at, nullptr, uncached)->index(); }\n@@ -1202,1 +1228,1 @@\n-  AliasType* find_alias_type(const TypePtr* adr_type, bool no_create, ciField* field);\n+  AliasType* find_alias_type(const TypePtr* adr_type, bool no_create, ciField* field, bool uncached = false);\n@@ -1292,1 +1318,3 @@\n-  \/\/ Auxiliary methods for randomized fuzzing\/stressing\n+  Node* optimize_acmp(PhaseGVN* phase, Node* a, Node* b);\n+\n+  \/\/ Auxiliary method for randomized fuzzing\/stressing\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":32,"deletions":4,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -236,1 +236,1 @@\n-      for (int i = node->req()-1; i >= 0; --i) {\n+      for (int i = node->len()-1; i >= 0; --i) {\n@@ -1593,0 +1593,3 @@\n+      case Op_CastI2N:\n+        early->add_inst(self);\n+        continue;\n","filename":"src\/hotspot\/share\/opto\/gcm.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -197,0 +197,1 @@\n+    case Op_StoreLSpecial:\n@@ -286,1 +287,1 @@\n-        if (offset == Type::OffsetBot || tptr->_offset == Type::OffsetBot)\n+        if (offset == Type::OffsetBot || tptr->offset() == Type::OffsetBot)\n@@ -288,1 +289,1 @@\n-        offset += tptr->_offset; \/\/ correct if base is offsetted\n+        offset += tptr->offset(); \/\/ correct if base is offsetted\n@@ -325,1 +326,5 @@\n-      Block *inb = get_block_for_node(mach->in(j));\n+      Block* inb = get_block_for_node(mach->in(j));\n+      if (mach->in(j)->is_Con() && mach->in(j)->req() == 1 && inb == get_block_for_node(mach)) {\n+        \/\/ Ignore constant loads scheduled in the same block (we can simply hoist them as well)\n+        continue;\n+      }\n@@ -418,0 +423,21 @@\n+\n+  \/\/ Hoist constant load inputs as well.\n+  for (uint i = 1; i < best->req(); ++i) {\n+    Node* n = best->in(i);\n+    if (n->is_Con() && get_block_for_node(n) == get_block_for_node(best)) {\n+      get_block_for_node(n)->find_remove(n);\n+      block->add_inst(n);\n+      map_node_to_block(n, block);\n+      \/\/ Constant loads may kill flags (for example, when XORing a register).\n+      \/\/ Check for flag-killing projections that also need to be hoisted.\n+      for (DUIterator_Fast jmax, j = n->fast_outs(jmax); j < jmax; j++) {\n+        Node* proj = n->fast_out(j);\n+        if (proj->is_MachProj()) {\n+          get_block_for_node(proj)->find_remove(proj);\n+          block->add_inst(proj);\n+          map_node_to_block(proj, block);\n+        }\n+      }\n+    }\n+  }\n+\n@@ -731,0 +757,1 @@\n+        case Op_StoreLSpecial:\n@@ -891,1 +918,1 @@\n-  uint r_cnt = mcall->tf()->range()->cnt();\n+  uint r_cnt = mcall->tf()->range_cc()->cnt();\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":31,"deletions":4,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -26,0 +26,3 @@\n+#include \"ci\/ciArrayKlass.hpp\"\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n+#include \"ci\/ciInstanceKlass.hpp\"\n@@ -32,0 +35,1 @@\n+#include \"gc\/shared\/c2\/barrierSetC2.hpp\"\n@@ -34,0 +38,1 @@\n+#include \"oops\/accessDecorators.hpp\"\n@@ -35,0 +40,1 @@\n+#include \"oops\/layoutKind.hpp\"\n@@ -43,0 +49,1 @@\n+#include \"opto\/graphKit.hpp\"\n@@ -45,0 +52,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -49,0 +57,1 @@\n+#include \"opto\/opcodes.hpp\"\n@@ -53,0 +62,1 @@\n+#include \"opto\/type.hpp\"\n@@ -61,0 +71,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -318,0 +329,2 @@\n+  case vmIntrinsics::_makePrivateBuffer:        return inline_unsafe_make_private_buffer();\n+  case vmIntrinsics::_finishPrivateBuffer:      return inline_unsafe_finish_private_buffer();\n@@ -327,0 +340,1 @@\n+  case vmIntrinsics::_getValue:                 return inline_unsafe_access(!is_store, T_OBJECT,   Relaxed, false, true);\n@@ -337,0 +351,1 @@\n+  case vmIntrinsics::_putValue:                 return inline_unsafe_access( is_store, T_OBJECT,   Relaxed, false, true);\n@@ -408,0 +423,3 @@\n+  case vmIntrinsics::_getFlatValue:             return inline_unsafe_flat_access(!is_store, Relaxed);\n+  case vmIntrinsics::_putFlatValue:             return inline_unsafe_flat_access( is_store, Relaxed);\n+\n@@ -503,0 +521,1 @@\n+  case vmIntrinsics::_isFlatArray:              return inline_unsafe_isFlatArray();\n@@ -515,0 +534,3 @@\n+  case vmIntrinsics::_newNullRestrictedNonAtomicArray: return inline_newArray(\/* null_free *\/ true, \/* atomic *\/ false);\n+  case vmIntrinsics::_newNullRestrictedAtomicArray: return inline_newArray(\/* null_free *\/ true, \/* atomic *\/ true);\n+  case vmIntrinsics::_newNullableAtomicArray:     return inline_newArray(\/* null_free *\/ false, \/* atomic *\/ true);\n@@ -2312,0 +2334,1 @@\n+  bool null_free = false;\n@@ -2317,0 +2340,1 @@\n+      null_free = alias_type->field()->is_null_free();\n@@ -2325,0 +2349,1 @@\n+      null_free = adr_type->is_aryptr()->is_null_free();\n@@ -2337,0 +2362,3 @@\n+    if (null_free) {\n+      result = result->join_speculative(TypePtr::NOTNULL)->is_oopptr();\n+    }\n@@ -2367,1 +2395,1 @@\n-bool LibraryCallKit::inline_unsafe_access(bool is_store, const BasicType type, const AccessKind kind, const bool unaligned) {\n+bool LibraryCallKit::inline_unsafe_access(bool is_store, const BasicType type, const AccessKind kind, const bool unaligned, const bool is_flat) {\n@@ -2392,1 +2420,1 @@\n-      assert(sig->count() == 2, \"oop getter has 2 arguments\");\n+      assert(sig->count() == 2 || (is_flat && sig->count() == 3), \"oop getter has 2 or 3 arguments\");\n@@ -2398,1 +2426,1 @@\n-      assert(sig->count() == 3, \"oop putter has 3 arguments\");\n+      assert(sig->count() == 3 || (is_flat && sig->count() == 4), \"oop putter has 3 arguments\");\n@@ -2424,0 +2452,49 @@\n+\n+  ciInlineKlass* inline_klass = nullptr;\n+  if (is_flat) {\n+    const TypeInstPtr* cls = _gvn.type(argument(4))->isa_instptr();\n+    if (cls == nullptr || cls->const_oop() == nullptr) {\n+      return false;\n+    }\n+    ciType* mirror_type = cls->const_oop()->as_instance()->java_mirror_type();\n+    if (!mirror_type->is_inlinetype()) {\n+      return false;\n+    }\n+    inline_klass = mirror_type->as_inline_klass();\n+  }\n+\n+  if (base->is_InlineType()) {\n+    assert(!is_store, \"InlineTypeNodes are non-larval value objects\");\n+    InlineTypeNode* vt = base->as_InlineType();\n+    if (offset->is_Con()) {\n+      long off = find_long_con(offset, 0);\n+      ciInlineKlass* vk = vt->type()->inline_klass();\n+      if ((long)(int)off != off || !vk->contains_field_offset(off)) {\n+        return false;\n+      }\n+\n+      ciField* field = vk->get_non_flat_field_by_offset(off);\n+      if (field != nullptr) {\n+        BasicType bt = type2field[field->type()->basic_type()];\n+        if (bt == T_ARRAY || bt == T_NARROWOOP) {\n+          bt = T_OBJECT;\n+        }\n+        if (bt == type && (!field->is_flat() || field->type() == inline_klass)) {\n+          Node* value = vt->field_value_by_offset(off, false);\n+          if (value->is_InlineType()) {\n+            value = value->as_InlineType()->adjust_scalarization_depth(this);\n+          }\n+          set_result(value);\n+          return true;\n+        }\n+      }\n+    }\n+    {\n+      \/\/ Re-execute the unsafe access if allocation triggers deoptimization.\n+      PreserveReexecuteState preexecs(this);\n+      jvms()->set_should_reexecute(true);\n+      vt = vt->buffer(this);\n+    }\n+    base = vt->get_oop();\n+  }\n+\n@@ -2435,1 +2512,1 @@\n-    if (type != T_OBJECT) {\n+    if (type != T_OBJECT && (inline_klass == nullptr || !inline_klass->has_object_fields())) {\n@@ -2453,1 +2530,1 @@\n-  Node* val = is_store ? argument(4) : nullptr;\n+  Node* val = is_store ? argument(4 + (is_flat ? 1 : 0)) : nullptr;\n@@ -2474,1 +2551,29 @@\n-  BasicType bt = alias_type->basic_type();\n+  BasicType bt = T_ILLEGAL;\n+  ciField* field = nullptr;\n+  if (adr_type->isa_instptr()) {\n+    const TypeInstPtr* instptr = adr_type->is_instptr();\n+    ciInstanceKlass* k = instptr->instance_klass();\n+    int off = instptr->offset();\n+    if (instptr->const_oop() != nullptr &&\n+        k == ciEnv::current()->Class_klass() &&\n+        instptr->offset() >= (k->size_helper() * wordSize)) {\n+      k = instptr->const_oop()->as_instance()->java_lang_Class_klass()->as_instance_klass();\n+      field = k->get_field_by_offset(off, true);\n+    } else {\n+      field = k->get_non_flat_field_by_offset(off);\n+    }\n+    if (field != nullptr) {\n+      bt = type2field[field->type()->basic_type()];\n+    }\n+    if (bt != alias_type->basic_type()) {\n+      \/\/ Type mismatch. Is it an access to a nested flat field?\n+      field = k->get_field_by_offset(off, false);\n+      if (field != nullptr) {\n+        bt = type2field[field->type()->basic_type()];\n+      }\n+    }\n+    assert(bt == alias_type->basic_type() || is_flat, \"should match\");\n+  } else {\n+    bt = alias_type->basic_type();\n+  }\n+\n@@ -2497,0 +2602,23 @@\n+  if (is_flat) {\n+    if (adr_type->isa_instptr()) {\n+      if (field == nullptr || field->type() != inline_klass) {\n+        mismatched = true;\n+      }\n+    } else if (adr_type->isa_aryptr()) {\n+      const Type* elem = adr_type->is_aryptr()->elem();\n+      if (!adr_type->is_flat() || elem->inline_klass() != inline_klass) {\n+        mismatched = true;\n+      }\n+    } else {\n+      mismatched = true;\n+    }\n+    if (is_store) {\n+      const Type* val_t = _gvn.type(val);\n+      if (!val_t->is_inlinetypeptr() || val_t->inline_klass() != inline_klass) {\n+        set_map(old_map);\n+        set_sp(old_sp);\n+        return false;\n+      }\n+    }\n+  }\n+\n@@ -2498,1 +2626,1 @@\n-  assert(!mismatched || alias_type->adr_type()->is_oopptr(), \"off-heap access can't be mismatched\");\n+  assert(!mismatched || is_flat || alias_type->adr_type()->is_oopptr(), \"off-heap access can't be mismatched\");\n@@ -2510,4 +2638,6 @@\n-  if (!is_store && type == T_OBJECT) {\n-    const TypeOopPtr* tjp = sharpen_unsafe_type(alias_type, adr_type);\n-    if (tjp != nullptr) {\n-      value_type = tjp;\n+  if (!is_store) {\n+    if (type == T_OBJECT && !is_flat) {\n+      const TypeOopPtr* tjp = sharpen_unsafe_type(alias_type, adr_type);\n+      if (tjp != nullptr) {\n+        value_type = tjp;\n+      }\n@@ -2529,2 +2659,2 @@\n-    ciField* field = alias_type->field();\n-    if (heap_base_oop != top() && field != nullptr && field->is_constant() && !mismatched) {\n+\n+    if (heap_base_oop != top() && field != nullptr && field->is_constant() && !field->is_flat() && !mismatched) {\n@@ -2536,1 +2666,10 @@\n-      p = access_load_at(heap_base_oop, adr, adr_type, value_type, type, decorators);\n+      if (is_flat) {\n+        p = InlineTypeNode::make_from_flat(this, inline_klass, base, adr, adr_type, false, false, true);\n+      } else {\n+        p = access_load_at(heap_base_oop, adr, adr_type, value_type, type, decorators);\n+        const TypeOopPtr* ptr = value_type->make_oopptr();\n+        if (ptr != nullptr && ptr->is_inlinetypeptr()) {\n+          \/\/ Load a non-flattened inline type from memory\n+          p = InlineTypeNode::make_from_oop(this, p, ptr->inline_klass());\n+        }\n+      }\n@@ -2574,1 +2713,220 @@\n-    access_store_at(heap_base_oop, adr, adr_type, val, value_type, type, decorators);\n+    if (is_flat) {\n+      val->as_InlineType()->store_flat(this, base, adr, false, false, true, decorators);\n+    } else {\n+      access_store_at(heap_base_oop, adr, adr_type, val, value_type, type, decorators);\n+    }\n+  }\n+\n+  return true;\n+}\n+\n+bool LibraryCallKit::inline_unsafe_flat_access(bool is_store, AccessKind kind) {\n+#ifdef ASSERT\n+  {\n+    ResourceMark rm;\n+    \/\/ Check the signatures.\n+    ciSignature* sig = callee()->signature();\n+    assert(sig->type_at(0)->basic_type() == T_OBJECT, \"base should be object, but is %s\", type2name(sig->type_at(0)->basic_type()));\n+    assert(sig->type_at(1)->basic_type() == T_LONG, \"offset should be long, but is %s\", type2name(sig->type_at(1)->basic_type()));\n+    assert(sig->type_at(2)->basic_type() == T_INT, \"layout kind should be int, but is %s\", type2name(sig->type_at(3)->basic_type()));\n+    assert(sig->type_at(3)->basic_type() == T_OBJECT, \"value klass should be object, but is %s\", type2name(sig->type_at(4)->basic_type()));\n+    if (is_store) {\n+      assert(sig->return_type()->basic_type() == T_VOID, \"putter must not return a value, but returns %s\", type2name(sig->return_type()->basic_type()));\n+      assert(sig->count() == 5, \"flat putter should have 5 arguments, but has %d\", sig->count());\n+      assert(sig->type_at(4)->basic_type() == T_OBJECT, \"put value should be object, but is %s\", type2name(sig->type_at(5)->basic_type()));\n+    } else {\n+      assert(sig->return_type()->basic_type() == T_OBJECT, \"getter must return an object, but returns %s\", type2name(sig->return_type()->basic_type()));\n+      assert(sig->count() == 4, \"flat getter should have 4 arguments, but has %d\", sig->count());\n+    }\n+ }\n+#endif \/\/ ASSERT\n+\n+  assert(kind == Relaxed, \"Only plain accesses for now\");\n+  if (callee()->is_static()) {\n+    \/\/ caller must have the capability!\n+    return false;\n+  }\n+  C->set_has_unsafe_access(true);\n+\n+  const TypeInstPtr* value_klass_node = _gvn.type(argument(5))->isa_instptr();\n+  if (value_klass_node == nullptr || value_klass_node->const_oop() == nullptr) {\n+    \/\/ parameter valueType is not a constant\n+    return false;\n+  }\n+  ciInlineKlass* value_klass = value_klass_node->const_oop()->as_instance()->java_mirror_type()->as_inline_klass();\n+\n+  const TypeInt* layout_type = _gvn.type(argument(4))->isa_int();\n+  if (layout_type == nullptr || !layout_type->is_con()) {\n+    \/\/ parameter layoutKind is not a constant\n+    return false;\n+  }\n+  assert(layout_type->get_con() >= static_cast<int>(LayoutKind::REFERENCE) &&\n+         layout_type->get_con() <= static_cast<int>(LayoutKind::UNKNOWN),\n+         \"invalid layoutKind %d\", layout_type->get_con());\n+  LayoutKind layout = static_cast<LayoutKind>(layout_type->get_con());\n+  assert(layout == LayoutKind::REFERENCE || layout == LayoutKind::NON_ATOMIC_FLAT ||\n+         layout == LayoutKind::ATOMIC_FLAT || layout == LayoutKind::NULLABLE_ATOMIC_FLAT,\n+         \"unexpected layoutKind %d\", layout_type->get_con());\n+\n+  null_check(argument(0));\n+  if (stopped()) {\n+    return true;\n+  }\n+\n+  Node* base = must_be_not_null(argument(1), true);\n+  Node* offset = argument(2);\n+  const Type* base_type = _gvn.type(base);\n+\n+  Node* ptr;\n+  bool immutable_memory = false;\n+  DecoratorSet decorators = C2_UNSAFE_ACCESS | IN_HEAP | MO_UNORDERED;\n+  if (base_type->isa_instptr()) {\n+    const TypeLong* offset_type = _gvn.type(offset)->isa_long();\n+    if (offset_type == nullptr || !offset_type->is_con()) {\n+      \/\/ Offset into a non-array should be a constant\n+      decorators |= C2_MISMATCHED;\n+    } else {\n+      int offset_con = checked_cast<int>(offset_type->get_con());\n+      ciInstanceKlass* base_klass = base_type->is_instptr()->instance_klass();\n+      ciField* field = base_klass->get_non_flat_field_by_offset(offset_con);\n+      if (field == nullptr) {\n+        assert(!base_klass->is_final(), \"non-existence field at offset %d of class %s\", offset_con, base_klass->name()->as_utf8());\n+        decorators |= C2_MISMATCHED;\n+      } else {\n+        assert(field->type() == value_klass, \"field at offset %d of %s is of type %s, but valueType is %s\",\n+               offset_con, base_klass->name()->as_utf8(), field->type()->name(), value_klass->name()->as_utf8());\n+        immutable_memory = field->is_strict() && field->is_final();\n+\n+        if (base->is_InlineType()) {\n+          assert(!is_store, \"Cannot store into a non-larval value object\");\n+          set_result(base->as_InlineType()->field_value_by_offset(offset_con, false));\n+          return true;\n+        }\n+      }\n+    }\n+\n+    if (base->is_InlineType()) {\n+      assert(!is_store, \"Cannot store into a non-larval value object\");\n+      base = base->as_InlineType()->buffer(this, true);\n+    }\n+    ptr = basic_plus_adr(base, ConvL2X(offset));\n+  } else if (base_type->isa_aryptr()) {\n+    decorators |= IS_ARRAY;\n+    if (layout == LayoutKind::REFERENCE) {\n+      if (!base_type->is_aryptr()->is_not_flat()) {\n+        const TypeAryPtr* array_type = base_type->is_aryptr()->cast_to_not_flat();\n+        Node* new_base = _gvn.transform(new CastPPNode(control(), base, array_type, ConstraintCastNode::StrongDependency));\n+        replace_in_map(base, new_base);\n+        base = new_base;\n+      }\n+      ptr = basic_plus_adr(base, ConvL2X(offset));\n+    } else {\n+      \/\/ Flat array must have an exact type\n+      bool is_null_free = layout != LayoutKind::NULLABLE_ATOMIC_FLAT;\n+      bool is_atomic = layout != LayoutKind::NON_ATOMIC_FLAT;\n+      Node* new_base = cast_to_flat_array(base, value_klass, is_null_free, !is_null_free, is_atomic);\n+      replace_in_map(base, new_base);\n+      base = new_base;\n+      ptr = basic_plus_adr(base, ConvL2X(offset));\n+      const TypeAryPtr* ptr_type = _gvn.type(ptr)->is_aryptr();\n+      if (ptr_type->field_offset().get() != 0) {\n+        ptr = _gvn.transform(new CastPPNode(control(), ptr, ptr_type->with_field_offset(0), ConstraintCastNode::StrongDependency));\n+      }\n+    }\n+  } else {\n+    decorators |= C2_MISMATCHED;\n+    ptr = basic_plus_adr(base, ConvL2X(offset));\n+  }\n+\n+  if (is_store) {\n+    Node* value = argument(6);\n+    const Type* value_type = _gvn.type(value);\n+    if (!value_type->is_inlinetypeptr()) {\n+      value_type = Type::get_const_type(value_klass)->filter_speculative(value_type);\n+      Node* new_value = _gvn.transform(new CastPPNode(control(), value, value_type, ConstraintCastNode::StrongDependency));\n+      new_value = InlineTypeNode::make_from_oop(this, new_value, value_klass);\n+      replace_in_map(value, new_value);\n+      value = new_value;\n+    }\n+\n+    assert(value_type->inline_klass() == value_klass, \"value is of type %s while valueType is %s\", value_type->inline_klass()->name()->as_utf8(), value_klass->name()->as_utf8());\n+    if (layout == LayoutKind::REFERENCE) {\n+      const TypePtr* ptr_type = (decorators & C2_MISMATCHED) != 0 ? TypeRawPtr::BOTTOM : _gvn.type(ptr)->is_ptr();\n+      access_store_at(base, ptr, ptr_type, value, value_type, T_OBJECT, decorators);\n+    } else {\n+      bool atomic = layout != LayoutKind::NON_ATOMIC_FLAT;\n+      bool null_free = layout != LayoutKind::NULLABLE_ATOMIC_FLAT;\n+      value->as_InlineType()->store_flat(this, base, ptr, atomic, immutable_memory, null_free, decorators);\n+    }\n+\n+    return true;\n+  } else {\n+    decorators |= (C2_CONTROL_DEPENDENT_LOAD | C2_UNKNOWN_CONTROL_LOAD);\n+    InlineTypeNode* result;\n+    if (layout == LayoutKind::REFERENCE) {\n+      const TypePtr* ptr_type = (decorators & C2_MISMATCHED) != 0 ? TypeRawPtr::BOTTOM : _gvn.type(ptr)->is_ptr();\n+      Node* oop = access_load_at(base, ptr, ptr_type, Type::get_const_type(value_klass), T_OBJECT, decorators);\n+      result = InlineTypeNode::make_from_oop(this, oop, value_klass);\n+    } else {\n+      bool atomic = layout != LayoutKind::NON_ATOMIC_FLAT;\n+      bool null_free = layout != LayoutKind::NULLABLE_ATOMIC_FLAT;\n+      result = InlineTypeNode::make_from_flat(this, value_klass, base, ptr, atomic, immutable_memory, null_free, decorators);\n+    }\n+\n+    set_result(result);\n+    return true;\n+  }\n+}\n+\n+bool LibraryCallKit::inline_unsafe_make_private_buffer() {\n+  Node* receiver = argument(0);\n+  Node* value = argument(1);\n+\n+  const Type* type = gvn().type(value);\n+  if (!type->is_inlinetypeptr()) {\n+    C->record_method_not_compilable(\"value passed to Unsafe::makePrivateBuffer is not of a constant value type\");\n+    return false;\n+  }\n+\n+  null_check(receiver);\n+  if (stopped()) {\n+    return true;\n+  }\n+\n+  value = null_check(value);\n+  if (stopped()) {\n+    return true;\n+  }\n+\n+  ciInlineKlass* vk = type->inline_klass();\n+  Node* klass = makecon(TypeKlassPtr::make(vk));\n+  Node* obj = new_instance(klass);\n+  AllocateNode::Ideal_allocation(obj)->_larval = true;\n+\n+  assert(value->is_InlineType(), \"must be an InlineTypeNode\");\n+  Node* payload_ptr = basic_plus_adr(obj, vk->payload_offset());\n+  value->as_InlineType()->store_flat(this, obj, payload_ptr, false, true, true, IN_HEAP | MO_UNORDERED);\n+\n+  set_result(obj);\n+  return true;\n+}\n+\n+bool LibraryCallKit::inline_unsafe_finish_private_buffer() {\n+  Node* receiver = argument(0);\n+  Node* buffer = argument(1);\n+\n+  const Type* type = gvn().type(buffer);\n+  if (!type->is_inlinetypeptr()) {\n+    C->record_method_not_compilable(\"value passed to Unsafe::finishPrivateBuffer is not of a constant value type\");\n+    return false;\n+  }\n+\n+  AllocateNode* alloc = AllocateNode::Ideal_allocation(buffer);\n+  if (alloc == nullptr) {\n+    C->record_method_not_compilable(\"value passed to Unsafe::finishPrivateBuffer must be allocated by Unsafe::makePrivateBuffer\");\n+    return false;\n+  }\n+\n+  null_check(receiver);\n+  if (stopped()) {\n+    return true;\n@@ -2577,0 +2935,9 @@\n+  \/\/ Unset the larval bit in the object header\n+  Node* old_header = make_load(control(), buffer, TypeX_X, TypeX_X->basic_type(), MemNode::unordered, LoadNode::Pinned);\n+  Node* new_header = gvn().transform(new AndXNode(old_header, MakeConX(~markWord::larval_bit_in_place)));\n+  access_store_at(buffer, buffer, type->is_ptr(), new_header, TypeX_X, TypeX_X->basic_type(), MO_UNORDERED | IN_HEAP);\n+\n+  \/\/ We must ensure that the buffer is properly published\n+  insert_mem_bar(Op_MemBarStoreStore, alloc->proj_out(AllocateNode::RawAddress));\n+  assert(!type->maybe_null(), \"result of an allocation should not be null\");\n+  set_result(InlineTypeNode::make_from_oop(this, buffer, type->inline_klass()));\n@@ -2785,0 +3152,13 @@\n+    if (oldval != nullptr && oldval->is_InlineType()) {\n+      \/\/ Re-execute the unsafe access if allocation triggers deoptimization.\n+      PreserveReexecuteState preexecs(this);\n+      jvms()->set_should_reexecute(true);\n+      oldval = oldval->as_InlineType()->buffer(this)->get_oop();\n+    }\n+    if (newval != nullptr && newval->is_InlineType()) {\n+      \/\/ Re-execute the unsafe access if allocation triggers deoptimization.\n+      PreserveReexecuteState preexecs(this);\n+      jvms()->set_should_reexecute(true);\n+      newval = newval->as_InlineType()->buffer(this)->get_oop();\n+    }\n+\n@@ -2971,2 +3351,7 @@\n-\n-  Node* obj = new_instance(kls, test);\n+  Node* obj = nullptr;\n+  const TypeInstKlassPtr* tkls = _gvn.type(kls)->isa_instklassptr();\n+  if (tkls != nullptr && tkls->instance_klass()->is_inlinetype()) {\n+    obj = InlineTypeNode::make_all_zero(_gvn, tkls->instance_klass()->as_inline_klass())->buffer(this);\n+  } else {\n+    obj = new_instance(kls, test);\n+  }\n@@ -3753,1 +4138,1 @@\n-  const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS);\n+  const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS, \/* stable= *\/ false, \/* flat= *\/ false, \/* not_flat= *\/ true, \/* not_null_free= *\/ true);\n@@ -3758,1 +4143,1 @@\n-  const Type* objects_type = TypeAryPtr::make(TypePtr::BotPTR, arr0, objects_klass, xk, 0);\n+  const Type* objects_type = TypeAryPtr::make(TypePtr::BotPTR, arr0, objects_klass, xk, TypeAryPtr::Offset(0));\n@@ -3882,9 +4267,0 @@\n-\/\/---------------------------load_mirror_from_klass----------------------------\n-\/\/ Given a klass oop, load its java mirror (a java.lang.Class oop).\n-Node* LibraryCallKit::load_mirror_from_klass(Node* klass) {\n-  Node* p = basic_plus_adr(klass, in_bytes(Klass::java_mirror_offset()));\n-  Node* load = make_load(nullptr, p, TypeRawPtr::NOTNULL, T_ADDRESS, MemNode::unordered);\n-  \/\/ mirror = ((OopHandle)mirror)->resolve();\n-  return access_load(load, TypeInstPtr::MIRROR, T_OBJECT, IN_NATIVE);\n-}\n-\n@@ -3934,0 +4310,1 @@\n+\n@@ -4092,0 +4469,1 @@\n+\n@@ -4107,1 +4485,2 @@\n-  ciType* tm = mirror_con->java_mirror_type();\n+  bool is_null_free_array = false;\n+  ciType* tm = mirror_con->java_mirror_type(&is_null_free_array);\n@@ -4114,1 +4493,5 @@\n-      int static_res = C->static_subtype_check(TypeKlassPtr::make(tm->as_klass(), Type::trust_interfaces), tp->as_klass_type());\n+      const TypeKlassPtr* tklass = TypeKlassPtr::make(tm->as_klass(), Type::trust_interfaces);\n+      if (is_null_free_array) {\n+        tklass = tklass->is_aryklassptr()->cast_to_null_free();\n+      }\n+      int static_res = C->static_subtype_check(tklass, tp->as_klass_type());\n@@ -4143,2 +4526,2 @@\n-  \/\/ Not-subtype or the mirror's klass ptr is null (in case it is a primitive).\n-  enum { _bad_type_path = 1, _prim_path = 2, PATH_LIMIT };\n+  \/\/ Not-subtype or the mirror's klass ptr is nullptr (in case it is a primitive).\n+  enum { _bad_type_path = 1, _prim_path = 2, _npe_path = 3, PATH_LIMIT };\n@@ -4154,0 +4537,2 @@\n+  Node* io = i_o();\n+  Node* mem = merged_memory();\n@@ -4155,0 +4540,1 @@\n+\n@@ -4161,1 +4547,2 @@\n-      region->in(_bad_type_path) != top()) {\n+      region->in(_bad_type_path) != top() ||\n+      region->in(_npe_path) != top()) {\n@@ -4165,0 +4552,3 @@\n+    \/\/ Set IO and memory because gen_checkcast may override them when buffering inline types\n+    set_i_o(io);\n+    set_all_memory(mem);\n@@ -4198,0 +4588,1 @@\n+  RegionNode* prim_region = new RegionNode(2);\n@@ -4200,0 +4591,1 @@\n+  record_for_igvn(prim_region);\n@@ -4224,2 +4616,5 @@\n-    int prim_path = (which_arg == 0 ? _prim_0_path : _prim_1_path);\n-    region->init_req(prim_path, null_ctl);\n+    if (which_arg == 0) {\n+      prim_region->init_req(1, null_ctl);\n+    } else {\n+      region->init_req(_prim_1_path, null_ctl);\n+    }\n@@ -4235,1 +4630,0 @@\n-    \/\/ now we have a successful reference subtype check\n@@ -4242,1 +4636,2 @@\n-  set_control(region->in(_prim_0_path)); \/\/ go back to first null check\n+  \/\/ This path is also used if superc is a value mirror.\n+  set_control(_gvn.transform(prim_region));\n@@ -4247,1 +4642,1 @@\n-    generate_guard(bol_eq, region, PROB_FAIR);\n+    generate_fair_guard(bol_eq, region);\n@@ -4278,2 +4673,1 @@\n-Node* LibraryCallKit::generate_array_guard_common(Node* kls, RegionNode* region,\n-                                                  bool obj_array, bool not_array, Node** obj) {\n+Node* LibraryCallKit::generate_array_guard_common(Node* kls, RegionNode* region, ArrayKind kind, Node** obj) {\n@@ -4285,9 +4679,0 @@\n-  \/\/ If obj_array\/non_array==false\/false:\n-  \/\/ Branch around if the given klass is in fact an array (either obj or prim).\n-  \/\/ If obj_array\/non_array==false\/true:\n-  \/\/ Branch around if the given klass is not an array klass of any kind.\n-  \/\/ If obj_array\/non_array==true\/true:\n-  \/\/ Branch around if the kls is not an oop array (kls is int[], String, etc.)\n-  \/\/ If obj_array\/non_array==true\/false:\n-  \/\/ Branch around if the kls is an oop array (Object[] or subtype)\n-  \/\/\n@@ -4298,4 +4683,11 @@\n-    bool query = (obj_array\n-                  ? Klass::layout_helper_is_objArray(layout_con)\n-                  : Klass::layout_helper_is_array(layout_con));\n-    if (query == not_array) {\n+    bool query = 0;\n+    switch(kind) {\n+      case ObjectArray:    query = Klass::layout_helper_is_objArray(layout_con); break;\n+      case NonObjectArray: query = !Klass::layout_helper_is_objArray(layout_con); break;\n+      case TypeArray:      query = Klass::layout_helper_is_typeArray(layout_con); break;\n+      case AnyArray:       query = Klass::layout_helper_is_array(layout_con); break;\n+      case NonArray:       query = !Klass::layout_helper_is_array(layout_con); break;\n+      default:\n+        ShouldNotReachHere();\n+    }\n+    if (!query) {\n@@ -4311,0 +4703,21 @@\n+  unsigned int value = 0;\n+  BoolTest::mask btest = BoolTest::illegal;\n+  switch(kind) {\n+    case ObjectArray:\n+    case NonObjectArray: {\n+      value = Klass::_lh_array_tag_obj_value;\n+      layout_val = _gvn.transform(new RShiftINode(layout_val, intcon(Klass::_lh_array_tag_shift)));\n+      btest = (kind == ObjectArray) ? BoolTest::eq : BoolTest::ne;\n+      break;\n+    }\n+    case TypeArray: {\n+      value = Klass::_lh_array_tag_type_value;\n+      layout_val = _gvn.transform(new RShiftINode(layout_val, intcon(Klass::_lh_array_tag_shift)));\n+      btest = BoolTest::eq;\n+      break;\n+    }\n+    case AnyArray:    value = Klass::_lh_neutral_value; btest = BoolTest::lt; break;\n+    case NonArray:    value = Klass::_lh_neutral_value; btest = BoolTest::gt; break;\n+    default:\n+      ShouldNotReachHere();\n+  }\n@@ -4312,4 +4725,1 @@\n-  jint  nval = (obj_array\n-                ? (jint)(Klass::_lh_array_tag_type_value\n-                   <<    Klass::_lh_array_tag_shift)\n-                : Klass::_lh_neutral_value);\n+  jint nval = (jint)value;\n@@ -4317,3 +4727,0 @@\n-  BoolTest::mask btest = BoolTest::lt;  \/\/ correct for testing is_[obj]array\n-  \/\/ invert the test if we are looking for a non-array\n-  if (not_array)  btest = BoolTest(btest).negate();\n@@ -4322,1 +4729,1 @@\n-  Node* is_array_ctrl = not_array ? control() : ctrl;\n+  Node* is_array_ctrl = kind == NonArray ? control() : ctrl;\n@@ -4331,0 +4738,59 @@\n+\/\/ public static native Object[] newNullRestrictedAtomicArray(Class<?> componentType, int length, Object initVal);\n+\/\/ public static native Object[] newNullRestrictedNonAtomicArray(Class<?> componentType, int length, Object initVal);\n+\/\/ public static native Object[] newNullableAtomicArray(Class<?> componentType, int length);\n+bool LibraryCallKit::inline_newArray(bool null_free, bool atomic) {\n+  assert(null_free || atomic, \"nullable implies atomic\");\n+  Node* componentType = argument(0);\n+  Node* length = argument(1);\n+  Node* init_val = null_free ? argument(2) : nullptr;\n+\n+  const TypeInstPtr* tp = _gvn.type(componentType)->isa_instptr();\n+  if (tp != nullptr) {\n+    ciInstanceKlass* ik = tp->instance_klass();\n+    if (ik == C->env()->Class_klass()) {\n+      ciType* t = tp->java_mirror_type();\n+      if (t != nullptr && t->is_inlinetype()) {\n+        ciInlineKlass* vk = t->as_inline_klass();\n+        bool flat = vk->maybe_flat_in_array();\n+        if (flat && atomic) {\n+          \/\/ Only flat if we have a corresponding atomic layout\n+          flat = null_free ? vk->has_atomic_layout() : vk->has_nullable_atomic_layout();\n+        }\n+        \/\/ TODO 8350865 refactor\n+        if (flat && !atomic) {\n+          flat = vk->has_non_atomic_layout();\n+        }\n+\n+        \/\/ TOOD 8350865 ZGC needs card marks on initializing oop stores\n+        if (UseZGC && null_free && !flat) {\n+          return false;\n+        }\n+\n+        ciArrayKlass* array_klass = ciArrayKlass::make(t, flat, null_free, atomic);\n+        if (array_klass->is_loaded() && array_klass->element_klass()->as_inline_klass()->is_initialized()) {\n+          const TypeAryKlassPtr* array_klass_type = TypeAryKlassPtr::make(array_klass, Type::trust_interfaces);\n+          if (null_free) {\n+            if (init_val->is_InlineType()) {\n+              if (array_klass_type->is_flat() && init_val->as_InlineType()->is_all_zero(&gvn(), \/* flat *\/ true)) {\n+                \/\/ Zeroing is enough because the init value is the all-zero value\n+                init_val = nullptr;\n+              } else {\n+                init_val = init_val->as_InlineType()->buffer(this);\n+              }\n+            }\n+            \/\/ TODO 8350865 Should we add a check of the init_val type (maybe in debug only + halt)?\n+          }\n+          Node* obj = new_array(makecon(array_klass_type), length, 0, nullptr, false, init_val);\n+          const TypeAryPtr* arytype = gvn().type(obj)->is_aryptr();\n+          assert(arytype->is_null_free() == null_free, \"inconsistency\");\n+          assert(arytype->is_not_null_free() == !null_free, \"inconsistency\");\n+          assert(arytype->is_flat() == flat, \"inconsistency\");\n+          assert(arytype->is_aryptr()->is_not_flat() == !flat, \"inconsistency\");\n+          set_result(obj);\n+          return true;\n+        }\n+      }\n+    }\n+  }\n+  return false;\n+}\n@@ -4333,1 +4799,1 @@\n-\/\/ private static native Object java.lang.reflect.newArray(Class<?> componentType, int length);\n+\/\/ private static native Object java.lang.reflect.Array.newArray(Class<?> componentType, int length);\n@@ -4479,1 +4945,13 @@\n-    Node* not_objArray = generate_non_objArray_guard(klass_node, bailout);\n+    \/\/ Inline type array may have object field that would require a\n+    \/\/ write barrier. Conservatively, go to slow path.\n+    \/\/ TODO 8251971: Optimize for the case when flat src\/dst are later found\n+    \/\/ to not contain oops (i.e., move this check to the macro expansion phase).\n+    BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();\n+    const TypeAryPtr* orig_t = _gvn.type(original)->isa_aryptr();\n+    const TypeKlassPtr* tklass = _gvn.type(klass_node)->is_klassptr();\n+    bool exclude_flat = UseArrayFlattening && bs->array_copy_requires_gc_barriers(true, T_OBJECT, false, false, BarrierSetC2::Parsing) &&\n+                        \/\/ Can src array be flat and contain oops?\n+                        (orig_t == nullptr || (!orig_t->is_not_flat() && (!orig_t->is_flat() || orig_t->elem()->inline_klass()->contains_oops()))) &&\n+                        \/\/ Can dest array be flat and contain oops?\n+                        tklass->can_be_inline_array() && (!tklass->is_flat() || tklass->is_aryklassptr()->elem()->is_instklassptr()->instance_klass()->as_inline_klass()->contains_oops());\n+    Node* not_objArray = exclude_flat ? generate_non_objArray_guard(klass_node, bailout) : generate_typeArray_guard(klass_node, bailout);\n@@ -4483,1 +4961,1 @@\n-      const Type* akls = TypeKlassPtr::make(TypePtr::NotNull, ak, 0\/*offset*\/);\n+      const Type* akls = TypeKlassPtr::make(TypePtr::NotNull, ak, Type::Offset(0));\n@@ -4503,0 +4981,39 @@\n+    \/\/ Handle inline type arrays\n+    bool can_validate = !too_many_traps(Deoptimization::Reason_class_check);\n+    if (!stopped()) {\n+      \/\/ TODO JDK-8329224\n+      if (!orig_t->is_null_free()) {\n+        \/\/ Not statically known to be null free, add a check\n+        generate_fair_guard(null_free_array_test(original), bailout);\n+      }\n+      orig_t = _gvn.type(original)->isa_aryptr();\n+      if (orig_t != nullptr && orig_t->is_flat()) {\n+        \/\/ Src is flat, check that dest is flat as well\n+        if (exclude_flat) {\n+          \/\/ Dest can't be flat, bail out\n+          bailout->add_req(control());\n+          set_control(top());\n+        } else {\n+          generate_fair_guard(flat_array_test(klass_node, \/* flat = *\/ false), bailout);\n+        }\n+        \/\/ TODO 8350865 This is not correct anymore. Write tests and fix logic similar to arraycopy.\n+      } else if (UseArrayFlattening && (orig_t == nullptr || !orig_t->is_not_flat()) &&\n+                 \/\/ If dest is flat, src must be flat as well (guaranteed by src <: dest check if validated).\n+                 ((!tklass->is_flat() && tklass->can_be_inline_array()) || !can_validate)) {\n+        \/\/ Src might be flat and dest might not be flat. Go to the slow path if src is flat.\n+        \/\/ TODO 8251971: Optimize for the case when src\/dest are later found to be both flat.\n+        generate_fair_guard(flat_array_test(load_object_klass(original)), bailout);\n+        if (orig_t != nullptr) {\n+          orig_t = orig_t->cast_to_not_flat();\n+          original = _gvn.transform(new CheckCastPPNode(control(), original, orig_t));\n+        }\n+      }\n+      if (!can_validate) {\n+        \/\/ No validation. The subtype check emitted at macro expansion time will not go to the slow\n+        \/\/ path but call checkcast_arraycopy which can not handle flat\/null-free inline type arrays.\n+        \/\/ TODO 8251971: Optimize for the case when src\/dest are later found to be both flat\/null-free.\n+        generate_fair_guard(flat_array_test(klass_node), bailout);\n+        generate_fair_guard(null_free_array_test(original), bailout);\n+      }\n+    }\n+\n@@ -4548,1 +5065,1 @@\n-      if (!too_many_traps(Deoptimization::Reason_class_check)) {\n+      if (can_validate) {\n@@ -4634,1 +5151,1 @@\n-    const TypeTuple* range = tf->range();\n+    const TypeTuple* range = tf->range_cc();\n@@ -4638,1 +5155,1 @@\n-    tf = TypeFunc::make(tf->domain(), new_range);\n+    tf = TypeFunc::make(tf->domain_cc(), new_range);\n@@ -4695,1 +5212,8 @@\n-  Node* obj = nullptr;\n+  Node* obj = argument(0);\n+\n+  \/\/ Don't intrinsify hashcode on inline types for now.\n+  \/\/ The \"is locked\" runtime check below also serves as inline type check and goes to the slow path.\n+  if (gvn().type(obj)->is_inlinetypeptr()) {\n+    return false;\n+  }\n+\n@@ -4705,1 +5229,0 @@\n-    obj = argument(0);\n@@ -4746,1 +5269,2 @@\n-    Node *lock_mask      = _gvn.MakeConX(markWord::lock_mask_in_place);\n+  \/\/ This also serves as guard against inline types\n+    Node *lock_mask      = _gvn.MakeConX(markWord::inline_type_mask_in_place);\n@@ -4821,1 +5345,10 @@\n-  Node* obj = null_check_receiver();\n+  Node* obj = argument(0);\n+  if (obj->is_InlineType()) {\n+    const Type* t = _gvn.type(obj);\n+    if (t->maybe_null()) {\n+      null_check(obj);\n+    }\n+    set_result(makecon(TypeInstPtr::make(t->inline_klass()->java_mirror())));\n+    return true;\n+  }\n+  obj = null_check_receiver();\n@@ -5173,0 +5706,14 @@\n+\/\/----------------------inline_unsafe_isFlatArray------------------------\n+\/\/ public native boolean Unsafe.isFlatArray(Class<?> arrayClass);\n+\/\/ This intrinsic exploits assumptions made by the native implementation\n+\/\/ (arrayClass is neither null nor primitive) to avoid unnecessary null checks.\n+bool LibraryCallKit::inline_unsafe_isFlatArray() {\n+  Node* cls = argument(1);\n+  Node* p = basic_plus_adr(cls, java_lang_Class::klass_offset());\n+  Node* kls = _gvn.transform(LoadKlassNode::make(_gvn, immutable_memory(), p,\n+                                                 TypeRawPtr::BOTTOM, TypeInstKlassPtr::OBJECT));\n+  Node* result = flat_array_test(kls);\n+  set_result(result);\n+  return true;\n+}\n+\n@@ -5243,1 +5790,2 @@\n-    Node* obj = null_check_receiver();\n+    Node* obj = argument(0);\n+    obj = null_check_receiver();\n@@ -5247,0 +5795,6 @@\n+    if (obj_type->is_inlinetypeptr()) {\n+      \/\/ If the object to clone is an inline type, we can simply return it (i.e. a nop) since inline types have\n+      \/\/ no identity.\n+      set_result(obj);\n+      return true;\n+    }\n@@ -5253,1 +5807,2 @@\n-        obj_type->speculative_type()->is_instance_klass()) {\n+        obj_type->speculative_type()->is_instance_klass() &&\n+        !obj_type->speculative_type()->is_inlinetype()) {\n@@ -5282,0 +5837,1 @@\n+    \/\/ TODO 8350865 For arrays, this might be folded and then not account for atomic arrays\n@@ -5283,0 +5839,5 @@\n+    \/\/ We only go to the fast case code if we pass a number of guards.\n+    \/\/ The paths which do not pass are accumulated in the slow_region.\n+    RegionNode* slow_region = new RegionNode(1);\n+    record_for_igvn(slow_region);\n+\n@@ -5289,3 +5850,0 @@\n-      Node* obj_length = load_array_length(array_obj);\n-      Node* array_size = nullptr; \/\/ Size of the array without object alignment padding.\n-      Node* alloc_obj = new_array(obj_klass, obj_length, 0, &array_size, \/*deoptimize_on_exception=*\/true);\n@@ -5294,20 +5852,7 @@\n-      if (bs->array_copy_requires_gc_barriers(true, T_OBJECT, true, false, BarrierSetC2::Parsing)) {\n-        \/\/ If it is an oop array, it requires very special treatment,\n-        \/\/ because gc barriers are required when accessing the array.\n-        Node* is_obja = generate_objArray_guard(obj_klass, (RegionNode*)nullptr);\n-        if (is_obja != nullptr) {\n-          PreserveJVMState pjvms2(this);\n-          set_control(is_obja);\n-          \/\/ Generate a direct call to the right arraycopy function(s).\n-          \/\/ Clones are always tightly coupled.\n-          ArrayCopyNode* ac = ArrayCopyNode::make(this, true, array_obj, intcon(0), alloc_obj, intcon(0), obj_length, true, false);\n-          ac->set_clone_oop_array();\n-          Node* n = _gvn.transform(ac);\n-          assert(n == ac, \"cannot disappear\");\n-          ac->connect_outputs(this, \/*deoptimize_on_exception=*\/true);\n-\n-          result_reg->init_req(_objArray_path, control());\n-          result_val->init_req(_objArray_path, alloc_obj);\n-          result_i_o ->set_req(_objArray_path, i_o());\n-          result_mem ->set_req(_objArray_path, reset_memory());\n-        }\n+      const TypeAryPtr* ary_ptr = obj_type->isa_aryptr();\n+      if (UseArrayFlattening && bs->array_copy_requires_gc_barriers(true, T_OBJECT, true, false, BarrierSetC2::Expansion) &&\n+          obj_type->can_be_inline_array() &&\n+          (ary_ptr == nullptr || (!ary_ptr->is_not_flat() && (!ary_ptr->is_flat() || ary_ptr->elem()->inline_klass()->contains_oops())))) {\n+        \/\/ Flat inline type array may have object field that would require a\n+        \/\/ write barrier. Conservatively, go to slow path.\n+        generate_fair_guard(flat_array_test(obj_klass), slow_region);\n@@ -5315,7 +5860,0 @@\n-      \/\/ Otherwise, there are no barriers to worry about.\n-      \/\/ (We can dispense with card marks if we know the allocation\n-      \/\/  comes out of eden (TLAB)...  In fact, ReduceInitialCardMarks\n-      \/\/  causes the non-eden paths to take compensating steps to\n-      \/\/  simulate a fresh allocation, so that no further\n-      \/\/  card marks are required in compiled code to initialize\n-      \/\/  the object.)\n@@ -5324,7 +5862,43 @@\n-        copy_to_clone(array_obj, alloc_obj, array_size, true);\n-\n-        \/\/ Present the results of the copy.\n-        result_reg->init_req(_array_path, control());\n-        result_val->init_req(_array_path, alloc_obj);\n-        result_i_o ->set_req(_array_path, i_o());\n-        result_mem ->set_req(_array_path, reset_memory());\n+        Node* obj_length = load_array_length(array_obj);\n+        Node* array_size = nullptr; \/\/ Size of the array without object alignment padding.\n+        Node* alloc_obj = new_array(obj_klass, obj_length, 0, &array_size, \/*deoptimize_on_exception=*\/true);\n+\n+        BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();\n+        if (bs->array_copy_requires_gc_barriers(true, T_OBJECT, true, false, BarrierSetC2::Parsing)) {\n+          \/\/ If it is an oop array, it requires very special treatment,\n+          \/\/ because gc barriers are required when accessing the array.\n+          Node* is_obja = generate_objArray_guard(obj_klass, (RegionNode*)nullptr);\n+          if (is_obja != nullptr) {\n+            PreserveJVMState pjvms2(this);\n+            set_control(is_obja);\n+            \/\/ Generate a direct call to the right arraycopy function(s).\n+            \/\/ Clones are always tightly coupled.\n+            ArrayCopyNode* ac = ArrayCopyNode::make(this, true, array_obj, intcon(0), alloc_obj, intcon(0), obj_length, true, false);\n+            ac->set_clone_oop_array();\n+            Node* n = _gvn.transform(ac);\n+            assert(n == ac, \"cannot disappear\");\n+            ac->connect_outputs(this, \/*deoptimize_on_exception=*\/true);\n+\n+            result_reg->init_req(_objArray_path, control());\n+            result_val->init_req(_objArray_path, alloc_obj);\n+            result_i_o ->set_req(_objArray_path, i_o());\n+            result_mem ->set_req(_objArray_path, reset_memory());\n+          }\n+        }\n+        \/\/ Otherwise, there are no barriers to worry about.\n+        \/\/ (We can dispense with card marks if we know the allocation\n+        \/\/  comes out of eden (TLAB)...  In fact, ReduceInitialCardMarks\n+        \/\/  causes the non-eden paths to take compensating steps to\n+        \/\/  simulate a fresh allocation, so that no further\n+        \/\/  card marks are required in compiled code to initialize\n+        \/\/  the object.)\n+\n+        if (!stopped()) {\n+          copy_to_clone(obj, alloc_obj, array_size, true);\n+\n+          \/\/ Present the results of the copy.\n+          result_reg->init_req(_array_path, control());\n+          result_val->init_req(_array_path, alloc_obj);\n+          result_i_o ->set_req(_array_path, i_o());\n+          result_mem ->set_req(_array_path, reset_memory());\n+        }\n@@ -5334,4 +5908,0 @@\n-    \/\/ We only go to the instance fast case code if we pass a number of guards.\n-    \/\/ The paths which do not pass are accumulated in the slow_region.\n-    RegionNode* slow_region = new RegionNode(1);\n-    record_for_igvn(slow_region);\n@@ -5469,0 +6039,12 @@\n+  int adjustment = 1;\n+  const TypeAryKlassPtr* ary_klass_ptr = alloc->in(AllocateNode::KlassNode)->bottom_type()->is_aryklassptr();\n+  if (ary_klass_ptr->is_null_free()) {\n+    \/\/ A null-free, tightly coupled array allocation can only come from LibraryCallKit::inline_newArray which\n+    \/\/ also requires the componentType and initVal on stack for re-execution.\n+    \/\/ Re-create and push the componentType.\n+    ciArrayKlass* klass = ary_klass_ptr->exact_klass()->as_array_klass();\n+    ciInstance* instance = klass->component_mirror_instance();\n+    const TypeInstPtr* t_instance = TypeInstPtr::make(instance);\n+    sfpt->ins_req(old_jvms->stkoff() + old_jvms->sp(), makecon(t_instance));\n+    adjustment++;\n+  }\n@@ -5470,5 +6052,16 @@\n-  sfpt->ins_req(old_jvms->stkoff() + old_jvms->sp(), alloc->in(AllocateNode::ALength));\n-  old_jvms->set_sp(old_jvms->sp()+1);\n-  old_jvms->set_monoff(old_jvms->monoff()+1);\n-  old_jvms->set_scloff(old_jvms->scloff()+1);\n-  old_jvms->set_endoff(old_jvms->endoff()+1);\n+  sfpt->ins_req(old_jvms->stkoff() + old_jvms->sp() + adjustment - 1, alloc->in(AllocateNode::ALength));\n+  if (ary_klass_ptr->is_null_free()) {\n+    \/\/ Re-create and push the initVal.\n+    Node* init_val = alloc->in(AllocateNode::InitValue);\n+    if (init_val == nullptr) {\n+      init_val = InlineTypeNode::make_all_zero(_gvn, ary_klass_ptr->elem()->is_instklassptr()->instance_klass()->as_inline_klass());\n+    } else if (UseCompressedOops) {\n+      init_val = _gvn.transform(new DecodeNNode(init_val, init_val->bottom_type()->make_ptr()));\n+    }\n+    sfpt->ins_req(old_jvms->stkoff() + old_jvms->sp() + adjustment, init_val);\n+    adjustment++;\n+  }\n+  old_jvms->set_sp(old_jvms->sp() + adjustment);\n+  old_jvms->set_monoff(old_jvms->monoff() + adjustment);\n+  old_jvms->set_scloff(old_jvms->scloff() + adjustment);\n+  old_jvms->set_endoff(old_jvms->endoff() + adjustment);\n@@ -5507,2 +6100,1 @@\n-    CallProjections callprojs;\n-    alloc->extract_projections(&callprojs, true);\n+    CallProjections* callprojs = alloc->extract_projections(true);\n@@ -5511,1 +6103,1 @@\n-    C->gvn_replace_by(callprojs.fallthrough_ioproj, alloc->in(TypeFunc::I_O));\n+    C->gvn_replace_by(callprojs->fallthrough_ioproj, alloc->in(TypeFunc::I_O));\n@@ -5553,1 +6145,1 @@\n-    set_i_o(callprojs.fallthrough_ioproj);\n+    set_i_o(callprojs->fallthrough_ioproj);\n@@ -5891,1 +6483,1 @@\n-    if (src_elem == dest_elem && src_elem == T_OBJECT) {\n+    if (src_elem == dest_elem && top_src->is_flat() == top_dest->is_flat() && src_elem == T_OBJECT) {\n@@ -5918,0 +6510,2 @@\n+          src_type = _gvn.type(src);\n+          top_src = src_type->isa_aryptr();\n@@ -5921,0 +6515,2 @@\n+          dest_type = _gvn.type(dest);\n+          top_dest = dest_type->isa_aryptr();\n@@ -5936,2 +6532,1 @@\n-      can_emit_guards &&\n-      !src->is_top() && !dest->is_top()) {\n+      can_emit_guards && !src->is_top() && !dest->is_top()) {\n@@ -5980,0 +6575,6 @@\n+      slow_region->add_req(not_subtype_ctrl);\n+    }\n+\n+    \/\/ TODO 8350865 Fix below logic. Also handle atomicity.\n+    generate_fair_guard(flat_array_test(src), slow_region);\n+    generate_fair_guard(flat_array_test(dest), slow_region);\n@@ -5981,6 +6582,28 @@\n-      if (not_subtype_ctrl != top()) {\n-        PreserveJVMState pjvms(this);\n-        set_control(not_subtype_ctrl);\n-        uncommon_trap(Deoptimization::Reason_intrinsic,\n-                      Deoptimization::Action_make_not_entrant);\n-        assert(stopped(), \"Should be stopped\");\n+    const TypeKlassPtr* dest_klass_t = _gvn.type(dest_klass)->is_klassptr();\n+    const Type* toop = dest_klass_t->cast_to_exactness(false)->as_instance_type();\n+    src = _gvn.transform(new CheckCastPPNode(control(), src, toop));\n+    src_type = _gvn.type(src);\n+    top_src  = src_type->isa_aryptr();\n+\n+    \/\/ Handle flat inline type arrays (null-free arrays are handled by the subtype check above)\n+    if (!stopped() && UseArrayFlattening) {\n+      \/\/ If dest is flat, src must be flat as well (guaranteed by src <: dest check). Handle flat src here.\n+      assert(top_dest == nullptr || !top_dest->is_flat() || top_src->is_flat(), \"src array must be flat\");\n+      if (top_src != nullptr && top_src->is_flat()) {\n+        \/\/ Src is flat, check that dest is flat as well\n+        if (top_dest != nullptr && !top_dest->is_flat()) {\n+          generate_fair_guard(flat_array_test(dest_klass, \/* flat = *\/ false), slow_region);\n+          \/\/ Since dest is flat and src <: dest, dest must have the same type as src.\n+          top_dest = top_src->cast_to_exactness(false);\n+          assert(top_dest->is_flat(), \"dest must be flat\");\n+          dest = _gvn.transform(new CheckCastPPNode(control(), dest, top_dest));\n+        }\n+      } else if (top_src == nullptr || !top_src->is_not_flat()) {\n+        \/\/ Src might be flat and dest might not be flat. Go to the slow path if src is flat.\n+        \/\/ TODO 8251971: Optimize for the case when src\/dest are later found to be both flat.\n+        assert(top_dest == nullptr || !top_dest->is_flat(), \"dest array must not be flat\");\n+        generate_fair_guard(flat_array_test(src), slow_region);\n+        if (top_src != nullptr) {\n+          top_src = top_src->cast_to_not_flat();\n+          src = _gvn.transform(new CheckCastPPNode(control(), src, top_src));\n+        }\n@@ -5989,0 +6612,1 @@\n+\n@@ -5996,4 +6620,0 @@\n-\n-    const TypeKlassPtr* dest_klass_t = _gvn.type(dest_klass)->is_klassptr();\n-    const Type *toop = dest_klass_t->cast_to_exactness(false)->as_instance_type();\n-    src = _gvn.transform(new CheckCastPPNode(control(), src, toop));\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":756,"deletions":136,"binary":false,"changes":892,"status":"modified"},{"patch":"@@ -46,0 +46,1 @@\n+class UnswitchCandidate;\n@@ -88,1 +89,1 @@\n-       };\n+         FlatArrays            = 1<<18};\n@@ -111,0 +112,1 @@\n+  bool is_flat_arrays() const { return _loop_flags & FlatArrays; }\n@@ -124,0 +126,1 @@\n+  void mark_flat_arrays() { _loop_flags |= FlatArrays; }\n@@ -733,0 +736,1 @@\n+  bool no_unswitch_candidate() const;\n@@ -1478,1 +1482,2 @@\n-  IfNode* find_unswitch_candidate(const IdealLoopTree* loop) const;\n+  IfNode* find_unswitch_candidates(const IdealLoopTree* loop, Node_List& flat_array_checks) const;\n+  IfNode* find_unswitch_candidate_from_idoms(const IdealLoopTree* loop) const;\n@@ -1485,1 +1490,1 @@\n-                                   const UnswitchedLoopSelector& unswitched_loop_selector);\n+                                   const UnswitchCandidate& unswitch_candidate, const IfNode* loop_selector);\n@@ -1493,0 +1498,1 @@\n+                                            const UnswitchCandidate& unswitch_candidate,\n@@ -1632,0 +1638,1 @@\n+  void move_flat_array_check_out_of_loop(Node* n);\n@@ -1633,0 +1640,1 @@\n+  bool flat_array_element_type_check(Node *n);\n@@ -1822,0 +1830,2 @@\n+  void collect_flat_array_checks(const IdealLoopTree* loop, Node_List& flat_array_checks) const;\n+\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":13,"deletions":3,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -54,0 +54,1 @@\n+class MachVEPNode;\n@@ -505,0 +506,30 @@\n+\/\/------------------------------MachVEPNode-----------------------------------\n+\/\/ Machine Inline Type Entry Point Node\n+class MachVEPNode : public MachIdealNode {\n+public:\n+  Label* _verified_entry;\n+\n+  MachVEPNode(Label* verified_entry, bool verified, bool receiver_only) :\n+    _verified_entry(verified_entry),\n+    _verified(verified),\n+    _receiver_only(receiver_only) {\n+    init_class_id(Class_MachVEP);\n+  }\n+  virtual bool cmp(const Node &n) const {\n+    return (_verified_entry == ((MachVEPNode&)n)._verified_entry) &&\n+           (_verified == ((MachVEPNode&)n)._verified) &&\n+           (_receiver_only == ((MachVEPNode&)n)._receiver_only) &&\n+           MachIdealNode::cmp(n);\n+  }\n+  virtual uint size_of() const { return sizeof(*this); }\n+  virtual void emit(C2_MacroAssembler *masm, PhaseRegAlloc* ra_) const;\n+\n+#ifndef PRODUCT\n+  virtual const char* Name() const { return \"InlineType Entry-Point\"; }\n+  virtual void format(PhaseRegAlloc*, outputStream* st) const;\n+#endif\n+private:\n+  bool   _verified;\n+  bool   _receiver_only;\n+};\n+\n@@ -511,1 +542,0 @@\n-  virtual uint size(PhaseRegAlloc *ra_) const;\n@@ -523,1 +553,9 @@\n-  MachPrologNode( ) {}\n+  Label* _verified_entry;\n+\n+  MachPrologNode(Label* verified_entry) : _verified_entry(verified_entry) {\n+    init_class_id(Class_MachProlog);\n+  }\n+  virtual bool cmp(const Node &n) const {\n+    return (_verified_entry == ((MachPrologNode&)n)._verified_entry) && MachIdealNode::cmp(n);\n+  }\n+  virtual uint size_of() const { return sizeof(*this); }\n@@ -525,1 +563,0 @@\n-  virtual uint size(PhaseRegAlloc *ra_) const;\n@@ -542,1 +579,0 @@\n-  virtual uint size(PhaseRegAlloc *ra_) const;\n@@ -931,1 +967,1 @@\n-  NOT_LP64(bool return_value_is_used() const;)\n+  bool return_value_is_used() const;\n@@ -935,0 +971,1 @@\n+  bool returns_scalarized() const;\n","filename":"src\/hotspot\/share\/opto\/machnode.hpp","additions":42,"deletions":5,"binary":false,"changes":47,"status":"modified"},{"patch":"@@ -129,0 +129,4 @@\n+#ifdef ASSERT\n+  void set_adr_type(const TypePtr* adr_type) { _adr_type = adr_type; }\n+#endif\n+\n@@ -268,1 +272,1 @@\n-  const Type* klass_value_common(PhaseGVN* phase) const;\n+  const Type* klass_value_common(PhaseGVN* phase, bool fold_for_arrays) const;\n@@ -520,0 +524,1 @@\n+  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n@@ -529,0 +534,8 @@\n+  bool _fold_for_arrays;\n+\n+  virtual uint size_of() const { return sizeof(*this); }\n+  virtual uint hash() const { return LoadNode::hash() + _fold_for_arrays; }\n+  virtual bool cmp( const Node &n ) const {\n+    return _fold_for_arrays == ((LoadKlassNode&)n)._fold_for_arrays && LoadNode::cmp(n);\n+  }\n+\n@@ -530,2 +543,2 @@\n-  LoadKlassNode(Node* mem, Node* adr, const TypePtr* at, const TypeKlassPtr* tk, MemOrd mo)\n-    : LoadPNode(nullptr, mem, adr, at, tk, mo) {}\n+  LoadKlassNode(Node* mem, Node* adr, const TypePtr* at, const TypeKlassPtr* tk, MemOrd mo, bool fold_for_arrays)\n+    : LoadPNode(nullptr, mem, adr, at, tk, mo), _fold_for_arrays(fold_for_arrays) {}\n@@ -541,1 +554,1 @@\n-                    const TypeKlassPtr* tk = TypeInstKlassPtr::OBJECT);\n+                    const TypeKlassPtr* tk = TypeInstKlassPtr::OBJECT, bool fold_for_arrays = true);\n@@ -553,0 +566,8 @@\n+  bool _fold_for_arrays;\n+\n+  virtual uint size_of() const { return sizeof(*this); }\n+  virtual uint hash() const { return LoadNode::hash() + _fold_for_arrays; }\n+  virtual bool cmp( const Node &n ) const {\n+    return _fold_for_arrays == ((LoadNKlassNode&)n)._fold_for_arrays && LoadNode::cmp(n);\n+  }\n+\n@@ -554,3 +575,3 @@\n-  friend Node* LoadKlassNode::make(PhaseGVN&, Node*, Node*, const TypePtr*, const TypeKlassPtr*);\n-  LoadNKlassNode(Node* mem, Node* adr, const TypePtr* at, const TypeNarrowKlass* tk, MemOrd mo)\n-    : LoadNNode(nullptr, mem, adr, at, tk, mo) {}\n+  friend Node* LoadKlassNode::make(PhaseGVN&, Node*, Node*, const TypePtr*, const TypeKlassPtr*, bool fold_for_arrays);\n+  LoadNKlassNode(Node* mem, Node* adr, const TypePtr* at, const TypeNarrowKlass* tk, MemOrd mo, bool fold_for_arrays)\n+    : LoadNNode(nullptr, mem, adr, at, tk, mo), _fold_for_arrays(fold_for_arrays) {}\n@@ -569,1 +590,0 @@\n-\n@@ -723,0 +743,19 @@\n+\/\/ Special StoreL for flat stores that emits GC barriers for field at 'oop_off' in the backend\n+class StoreLSpecialNode : public StoreNode {\n+\n+public:\n+  StoreLSpecialNode(Node* c, Node* mem, Node* adr, const TypePtr* at, Node* val, Node* oop_off, MemOrd mo)\n+    : StoreNode(c, mem, adr, at, val, mo) {\n+    set_mismatched_access();\n+    if (oop_off != nullptr) {\n+      add_req(oop_off);\n+    }\n+  }\n+  virtual int Opcode() const;\n+  virtual BasicType value_basic_type() const { return T_LONG; }\n+\n+  virtual uint match_edge(uint idx) const { return idx == MemNode::Address ||\n+                                                   idx == MemNode::ValueIn ||\n+                                                   idx == MemNode::ValueIn + 1; }\n+};\n+\n@@ -1078,0 +1117,1 @@\n+  bool _word_copy_only;\n@@ -1079,2 +1119,3 @@\n-  ClearArrayNode( Node *ctrl, Node *arymem, Node *word_cnt, Node *base, bool is_large)\n-    : Node(ctrl,arymem,word_cnt,base), _is_large(is_large) {\n+  ClearArrayNode( Node *ctrl, Node *arymem, Node *word_cnt, Node *base, Node* val, bool is_large)\n+    : Node(ctrl, arymem, word_cnt, base, val), _is_large(is_large),\n+      _word_copy_only(val->bottom_type()->isa_long() && (!val->bottom_type()->is_long()->is_con() || val->bottom_type()->is_long()->get_con() != 0)) {\n@@ -1092,0 +1133,1 @@\n+  bool word_copy_only() const { return _word_copy_only; }\n@@ -1103,0 +1145,2 @@\n+                            Node* val,\n+                            Node* raw_val,\n@@ -1107,0 +1151,2 @@\n+                            Node* val,\n+                            Node* raw_val,\n@@ -1111,0 +1157,1 @@\n+                            Node* raw_val,\n@@ -1162,1 +1209,1 @@\n-  virtual Node *match( const ProjNode *proj, const Matcher *m );\n+  virtual Node *match(const ProjNode *proj, const Matcher *m, const RegMask* mask);\n","filename":"src\/hotspot\/share\/opto\/memnode.hpp","additions":58,"deletions":11,"binary":false,"changes":69,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -566,0 +567,3 @@\n+  if (n->is_InlineType()) {\n+    C->add_inline_type(n);\n+  }\n@@ -626,0 +630,3 @@\n+  if (is_InlineType()) {\n+    compile->remove_inline_type(this);\n+  }\n","filename":"src\/hotspot\/share\/opto\/node.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -47,0 +47,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/flatArrayOop.inline.hpp\"\n@@ -201,0 +203,1 @@\n+const TypeFunc* OptoRuntime::_new_array_nozero_Type               = nullptr;\n@@ -331,1 +334,1 @@\n-JRT_BLOCK_ENTRY(void, OptoRuntime::new_instance_C(Klass* klass, JavaThread* current))\n+JRT_BLOCK_ENTRY(void, OptoRuntime::new_instance_C(Klass* klass, bool is_larval, JavaThread* current))\n@@ -351,1 +354,5 @@\n-    oop result = InstanceKlass::cast(klass)->allocate_instance(THREAD);\n+    instanceOop result = InstanceKlass::cast(klass)->allocate_instance(THREAD);\n+    if (is_larval) {\n+      \/\/ Check if this is a larval buffer allocation\n+      result->set_mark(result->mark().enter_larval_state());\n+    }\n@@ -369,1 +376,1 @@\n-JRT_BLOCK_ENTRY(void, OptoRuntime::new_array_C(Klass* array_type, int len, JavaThread* current))\n+JRT_BLOCK_ENTRY(void, OptoRuntime::new_array_C(Klass* array_type, int len, oopDesc* init_val, JavaThread* current))\n@@ -378,0 +385,1 @@\n+  Handle h_init_val(current, init_val); \/\/ keep the init_val object alive\n@@ -379,1 +387,12 @@\n-  if (array_type->is_typeArray_klass()) {\n+  if (array_type->is_flatArray_klass()) {\n+    Handle holder(current, array_type->klass_holder()); \/\/ keep the array klass alive\n+    FlatArrayKlass* fak = FlatArrayKlass::cast(array_type);\n+    InlineKlass* vk = fak->element_klass();\n+    result = oopFactory::new_flatArray(vk, len, fak->layout_kind(), THREAD);\n+    if (array_type->is_null_free_array_klass() && !h_init_val.is_null()) {\n+      \/\/ Null-free arrays need to be initialized\n+      for (int i = 0; i < len; i++) {\n+        vk->write_value_to_addr(h_init_val(), ((flatArrayOop)result)->value_at_addr(i, fak->layout_helper()), fak->layout_kind(), true, CHECK);\n+      }\n+    }\n+  } else if (array_type->is_typeArray_klass()) {\n@@ -385,5 +404,8 @@\n-    \/\/ Although the oopFactory likes to work with the elem_type,\n-    \/\/ the compiler prefers the array_type, since it must already have\n-    \/\/ that latter value in hand for the fast path.\n-    Klass* elem_type = ObjArrayKlass::cast(array_type)->element_klass();\n-    result = oopFactory::new_objArray(elem_type, len, THREAD);\n+    ObjArrayKlass* array_klass = ObjArrayKlass::cast(array_type);\n+    result = array_klass->allocate(len, THREAD);\n+    if (array_type->is_null_free_array_klass() && !h_init_val.is_null()) {\n+      \/\/ Null-free arrays need to be initialized\n+      for (int i = 0; i < len; i++) {\n+        ((objArrayOop)result)->obj_at_put(i, h_init_val());\n+      }\n+    }\n@@ -587,1 +609,1 @@\n-  const Type **fields = TypeTuple::fields(1);\n+  const Type **fields = TypeTuple::fields(2);\n@@ -589,1 +611,2 @@\n-  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+1, fields);\n+  fields[TypeFunc::Parms+1] = TypeInt::BOOL;        \/\/ is_larval\n+  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+2, fields);\n@@ -632,0 +655,17 @@\n+  \/\/ create input type (domain)\n+  const Type **fields = TypeTuple::fields(3);\n+  fields[TypeFunc::Parms+0] = TypeInstPtr::NOTNULL;   \/\/ element klass\n+  fields[TypeFunc::Parms+1] = TypeInt::INT;       \/\/ array size\n+  fields[TypeFunc::Parms+2] = TypeInstPtr::NOTNULL;       \/\/ init value\n+  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+3, fields);\n+\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(1);\n+  fields[TypeFunc::Parms+0] = TypeRawPtr::NOTNULL; \/\/ Returned oop\n+\n+  const TypeTuple *range = TypeTuple::make(TypeFunc::Parms+1, fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n+\n+static const TypeFunc* make_new_array_nozero_Type() {\n@@ -707,1 +747,1 @@\n-  return TypeFunc::make(domain,range);\n+  return TypeFunc::make(domain, range);\n@@ -2087,1 +2127,1 @@\n-  return TypeFunc::make(domain,range);\n+  return TypeFunc::make(domain, range);\n@@ -2119,1 +2159,1 @@\n-  return TypeFunc::make(domain,range);\n+  return TypeFunc::make(domain, range);\n@@ -2135,1 +2175,1 @@\n-  return TypeFunc::make(domain,range);\n+  return TypeFunc::make(domain, range);\n@@ -2226,0 +2266,1 @@\n+  _new_array_nozero_Type              = make_new_array_nozero_Type();\n@@ -2326,0 +2367,105 @@\n+\n+const TypeFunc *OptoRuntime::store_inline_type_fields_Type() {\n+  \/\/ create input type (domain)\n+  uint total = SharedRuntime::java_return_convention_max_int + SharedRuntime::java_return_convention_max_float*2;\n+  const Type **fields = TypeTuple::fields(total);\n+  \/\/ We don't know the number of returned values and their\n+  \/\/ types. Assume all registers available to the return convention\n+  \/\/ are used.\n+  fields[TypeFunc::Parms] = TypePtr::BOTTOM;\n+  uint i = 1;\n+  for (; i < SharedRuntime::java_return_convention_max_int; i++) {\n+    fields[TypeFunc::Parms+i] = TypeInt::INT;\n+  }\n+  for (; i < total; i+=2) {\n+    fields[TypeFunc::Parms+i] = Type::DOUBLE;\n+    fields[TypeFunc::Parms+i+1] = Type::HALF;\n+  }\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms + total, fields);\n+\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(1);\n+  fields[TypeFunc::Parms+0] = TypeInstPtr::NOTNULL;\n+\n+  const TypeTuple *range = TypeTuple::make(TypeFunc::Parms+1,fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n+\n+const TypeFunc *OptoRuntime::pack_inline_type_Type() {\n+  \/\/ create input type (domain)\n+  uint total = 1 + SharedRuntime::java_return_convention_max_int + SharedRuntime::java_return_convention_max_float*2;\n+  const Type **fields = TypeTuple::fields(total);\n+  \/\/ We don't know the number of returned values and their\n+  \/\/ types. Assume all registers available to the return convention\n+  \/\/ are used.\n+  fields[TypeFunc::Parms] = TypeRawPtr::BOTTOM;\n+  fields[TypeFunc::Parms+1] = TypeRawPtr::BOTTOM;\n+  uint i = 2;\n+  for (; i < SharedRuntime::java_return_convention_max_int+1; i++) {\n+    fields[TypeFunc::Parms+i] = TypeInt::INT;\n+  }\n+  for (; i < total; i+=2) {\n+    fields[TypeFunc::Parms+i] = Type::DOUBLE;\n+    fields[TypeFunc::Parms+i+1] = Type::HALF;\n+  }\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms + total, fields);\n+\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(1);\n+  fields[TypeFunc::Parms+0] = TypeInstPtr::NOTNULL;\n+\n+  const TypeTuple *range = TypeTuple::make(TypeFunc::Parms+1,fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n+\n+JRT_BLOCK_ENTRY(void, OptoRuntime::load_unknown_inline_C(flatArrayOopDesc* array, int index, JavaThread* current))\n+  JRT_BLOCK;\n+  oop buffer = array->read_value_from_flat_array(index, THREAD);\n+  deoptimize_caller_frame(current, HAS_PENDING_EXCEPTION);\n+  current->set_vm_result_oop(buffer);\n+  JRT_BLOCK_END;\n+JRT_END\n+\n+const TypeFunc* OptoRuntime::load_unknown_inline_Type() {\n+  \/\/ create input type (domain)\n+  const Type** fields = TypeTuple::fields(2);\n+  fields[TypeFunc::Parms] = TypeOopPtr::NOTNULL;\n+  fields[TypeFunc::Parms+1] = TypeInt::POS;\n+\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms+2, fields);\n+\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(1);\n+  fields[TypeFunc::Parms] = TypeInstPtr::BOTTOM;\n+\n+  const TypeTuple* range = TypeTuple::make(TypeFunc::Parms+1, fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n+\n+JRT_BLOCK_ENTRY(void, OptoRuntime::store_unknown_inline_C(instanceOopDesc* buffer, flatArrayOopDesc* array, int index, JavaThread* current))\n+  JRT_BLOCK;\n+  array->write_value_to_flat_array(buffer, index, THREAD);\n+  if (HAS_PENDING_EXCEPTION) {\n+      fatal(\"This entry must be changed to be a non-leaf entry because writing to a flat array can now throw an exception\");\n+  }\n+  JRT_BLOCK_END;\n+JRT_END\n+\n+const TypeFunc* OptoRuntime::store_unknown_inline_Type() {\n+  \/\/ create input type (domain)\n+  const Type** fields = TypeTuple::fields(3);\n+  fields[TypeFunc::Parms] = TypeInstPtr::NOTNULL;\n+  fields[TypeFunc::Parms+1] = TypeOopPtr::NOTNULL;\n+  fields[TypeFunc::Parms+2] = TypeInt::POS;\n+\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms+3, fields);\n+\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(0);\n+  const TypeTuple* range = TypeTuple::make(TypeFunc::Parms, fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":161,"deletions":15,"binary":false,"changes":176,"status":"modified"},{"patch":"@@ -138,0 +138,1 @@\n+  static const TypeFunc* _new_array_nozero_Type;\n@@ -227,1 +228,1 @@\n-  static void new_instance_C(Klass* instance_klass, JavaThread* current);\n+  static void new_instance_C(Klass* instance_klass, bool is_larval, JavaThread* current);\n@@ -230,1 +231,1 @@\n-  static void new_array_C(Klass* array_klass, int len, JavaThread* current);\n+  static void new_array_C(Klass* array_klass, int len, oopDesc* init_val, JavaThread* current);\n@@ -274,0 +275,2 @@\n+  static void load_unknown_inline_C(flatArrayOopDesc* array, int index, JavaThread* current);\n+  static void store_unknown_inline_C(instanceOopDesc* buffer, flatArrayOopDesc* array, int index, JavaThread* current);\n@@ -306,0 +309,2 @@\n+  static address load_unknown_inline_Java()              { return _load_unknown_inline_Java; }\n+  static address store_unknown_inline_Java()             { return _store_unknown_inline_Java; }\n@@ -338,1 +343,2 @@\n-    return new_array_Type();\n+    assert(_new_array_nozero_Type != nullptr, \"should be initialized\");\n+    return _new_array_nozero_Type;\n@@ -738,0 +744,6 @@\n+  static const TypeFunc* load_unknown_inline_Type();\n+  static const TypeFunc* store_unknown_inline_Type();\n+\n+  static const TypeFunc* store_inline_type_fields_Type();\n+  static const TypeFunc* pack_inline_type_Type();\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.hpp","additions":15,"deletions":3,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -61,0 +61,1 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n@@ -416,0 +417,162 @@\n+static void validate_array_arguments(Klass* elmClass, jint len, TRAPS) {\n+  if (len < 0) {\n+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), \"Array length is negative\");\n+  }\n+  elmClass->initialize(CHECK);\n+  if (elmClass->is_array_klass() || elmClass->is_identity_class()) {\n+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), \"Element class is not a value class\");\n+  }\n+  if (elmClass->is_abstract()) {\n+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), \"Element class is abstract\");\n+  }\n+}\n+\n+JVM_ENTRY(jarray, JVM_CopyOfSpecialArray(JNIEnv *env, jarray orig, jint from, jint to))\n+  oop o = JNIHandles::resolve_non_null(orig);\n+  assert(o->is_array(), \"Must be\");\n+  oop array = nullptr;\n+  arrayOop org = (arrayOop)o;\n+  arrayHandle oh(THREAD, org);\n+  ArrayKlass* ak = ArrayKlass::cast(org->klass());\n+  InlineKlass* vk = InlineKlass::cast(ak->element_klass());\n+  int len = to - from;  \/\/ length of the new array\n+  if (ak->is_null_free_array_klass()) {\n+    if (from >= org->length() || to > org->length()) {\n+      THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Copying of null-free array with uninitialized elements\");\n+    }\n+  }\n+  if (org->is_flatArray()) {\n+    FlatArrayKlass* fak = FlatArrayKlass::cast(org->klass());\n+    LayoutKind lk = fak->layout_kind();\n+    array = oopFactory::new_flatArray(vk, len, lk, CHECK_NULL);\n+    arrayHandle ah(THREAD, (arrayOop)array);\n+    int end = to < oh()->length() ? to : oh()->length();\n+    for (int i = from; i < end; i++) {\n+      void* src = ((flatArrayOop)oh())->value_at_addr(i, fak->layout_helper());\n+      void* dst = ((flatArrayOop)ah())->value_at_addr(i - from, fak->layout_helper());\n+      vk->copy_payload_to_addr(src, dst, lk, false);\n+    }\n+    array = ah();\n+  } else {\n+    if (org->is_null_free_array()) {\n+      array = oopFactory::new_null_free_objArray(vk, len, CHECK_NULL);\n+    } else {\n+      array = oopFactory::new_objArray(vk, len, CHECK_NULL);\n+    }\n+    int end = to < oh()->length() ? to : oh()->length();\n+    for (int i = from; i < end; i++) {\n+      if (i < ((objArrayOop)oh())->length()) {\n+        ((objArrayOop)array)->obj_at_put(i - from, ((objArrayOop)oh())->obj_at(i));\n+      } else {\n+        assert(!ak->is_null_free_array_klass(), \"Must be a nullable array\");\n+        ((objArrayOop)array)->obj_at_put(i - from, nullptr);\n+      }\n+    }\n+  }\n+  return (jarray) JNIHandles::make_local(THREAD, array);\n+JVM_END\n+\n+JVM_ENTRY(jarray, JVM_NewNullRestrictedNonAtomicArray(JNIEnv *env, jclass elmClass, jint len, jobject initVal))\n+  oop mirror = JNIHandles::resolve_non_null(elmClass);\n+  oop init = JNIHandles::resolve(initVal);\n+  if (init == nullptr) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Initial value cannot be null\");\n+  }\n+  Handle init_h(THREAD, init);\n+  Klass* klass = java_lang_Class::as_Klass(mirror);\n+  if (klass != init_h()->klass()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Type mismatch between array and initial value\");\n+  }\n+  validate_array_arguments(klass, len, CHECK_NULL);\n+  InlineKlass* vk = InlineKlass::cast(klass);\n+  oop array = nullptr;\n+  if (vk->maybe_flat_in_array() && vk->has_non_atomic_layout()) {\n+    array = oopFactory::new_flatArray(vk, len, LayoutKind::NON_ATOMIC_FLAT, CHECK_NULL);\n+    for (int i = 0; i < len; i++) {\n+      ((flatArrayOop)array)->write_value_to_flat_array(init_h(), i, CHECK_NULL);\n+    }\n+  } else {\n+    array = oopFactory::new_null_free_objArray(vk, len, CHECK_NULL);\n+    for (int i = 0; i < len; i++) {\n+      ((objArrayOop)array)->obj_at_put(i, init_h());\n+    }\n+  }\n+  return (jarray) JNIHandles::make_local(THREAD, array);\n+JVM_END\n+\n+JVM_ENTRY(jarray, JVM_NewNullRestrictedAtomicArray(JNIEnv *env, jclass elmClass, jint len, jobject initVal))\n+  oop mirror = JNIHandles::resolve_non_null(elmClass);\n+  oop init = JNIHandles::resolve(initVal);\n+  if (init == nullptr) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Initial value cannot be null\");\n+  }\n+  Handle init_h(THREAD, init);\n+  Klass* klass = java_lang_Class::as_Klass(mirror);\n+  if (klass != init_h()->klass()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Type mismatch between array and initial value\");\n+  }\n+  validate_array_arguments(klass, len, CHECK_NULL);\n+  InlineKlass* vk = InlineKlass::cast(klass);\n+  oop array = nullptr;\n+  if (vk->maybe_flat_in_array() && vk->is_naturally_atomic() && vk->has_non_atomic_layout()) {\n+    array = oopFactory::new_flatArray(vk, len, LayoutKind::NON_ATOMIC_FLAT, CHECK_NULL);\n+    for (int i = 0; i < len; i++) {\n+      ((flatArrayOop)array)->write_value_to_flat_array(init_h(), i, CHECK_NULL);\n+    }\n+  } else if (vk->maybe_flat_in_array() && vk->has_atomic_layout()) {\n+    array = oopFactory::new_flatArray(vk, len, LayoutKind::ATOMIC_FLAT, CHECK_NULL);\n+    for (int i = 0; i < len; i++) {\n+      ((flatArrayOop)array)->write_value_to_flat_array(init_h(), i, CHECK_NULL);\n+    }\n+  } else {\n+    array = oopFactory::new_null_free_objArray(vk, len, CHECK_NULL);\n+    for (int i = 0; i < len; i++) {\n+      \/\/ need a type check here\n+\n+      ((objArrayOop)array)->obj_at_put(i, init_h());\n+    }\n+  }\n+  return (jarray) JNIHandles::make_local(THREAD, array);\n+JVM_END\n+\n+JVM_ENTRY(jarray, JVM_NewNullableAtomicArray(JNIEnv *env, jclass elmClass, jint len))\n+  oop mirror = JNIHandles::resolve_non_null(elmClass);\n+  Klass* klass = java_lang_Class::as_Klass(mirror);\n+  klass->initialize(CHECK_NULL);\n+  validate_array_arguments(klass, len, CHECK_NULL);\n+  InlineKlass* vk = InlineKlass::cast(klass);\n+  oop array = nullptr;\n+  if (vk->maybe_flat_in_array() && vk->has_nullable_atomic_layout()) {\n+    array = oopFactory::new_flatArray(vk, len, LayoutKind::NULLABLE_ATOMIC_FLAT, CHECK_NULL);\n+  } else {\n+    array = oopFactory::new_objArray(vk, len, CHECK_NULL);\n+  }\n+  return (jarray) JNIHandles::make_local(THREAD, array);\n+JVM_END\n+\n+JVM_ENTRY(jboolean, JVM_IsFlatArray(JNIEnv *env, jobject obj))\n+  arrayOop oop = arrayOop(JNIHandles::resolve_non_null(obj));\n+  return oop->is_flatArray();\n+JVM_END\n+\n+JVM_ENTRY(jboolean, JVM_IsNullRestrictedArray(JNIEnv *env, jobject obj))\n+  arrayOop oop = arrayOop(JNIHandles::resolve_non_null(obj));\n+  return oop->is_null_free_array();\n+JVM_END\n+\n+JVM_ENTRY(jboolean, JVM_IsAtomicArray(JNIEnv *env, jobject obj))\n+  \/\/ There are multiple cases where an array can\/must support atomic access:\n+  \/\/   - the array is a reference array\n+  \/\/   - the array uses an atomic flat layout: NULLABLE_ATOMIC_FLAT or ATOMIC_FLAT\n+  \/\/   - the array is flat and its component type is naturally atomic\n+  arrayOop oop = arrayOop(JNIHandles::resolve_non_null(obj));\n+  if (oop->is_objArray()) return true;\n+  if (oop->is_flatArray()) {\n+    FlatArrayKlass* fak = FlatArrayKlass::cast(oop->klass());\n+    if (fak->layout_kind() == LayoutKind::ATOMIC_FLAT || fak->layout_kind() == LayoutKind::NULLABLE_ATOMIC_FLAT) {\n+      return true;\n+    }\n+    if (fak->element_klass()->is_naturally_atomic()) return true;\n+  }\n+  return false;\n+JVM_END\n@@ -624,2 +787,22 @@\n-  return handle == nullptr ? 0 :\n-         checked_cast<jint>(ObjectSynchronizer::FastHashCode (THREAD, JNIHandles::resolve_non_null(handle)));\n+  if (handle == nullptr) {\n+    return 0;\n+  }\n+  oop obj = JNIHandles::resolve_non_null(handle);\n+  if (EnableValhalla && obj->klass()->is_inline_klass()) {\n+      JavaValue result(T_INT);\n+      JavaCallArguments args;\n+      Handle ho(THREAD, obj);\n+      args.push_oop(ho);\n+      methodHandle method(THREAD, Universe::value_object_hash_code_method());\n+      JavaCalls::call(&result, method, &args, THREAD);\n+      if (HAS_PENDING_EXCEPTION) {\n+        if (!PENDING_EXCEPTION->is_a(vmClasses::Error_klass())) {\n+          Handle e(THREAD, PENDING_EXCEPTION);\n+          CLEAR_PENDING_EXCEPTION;\n+          THROW_MSG_CAUSE_(vmSymbols::java_lang_InternalError(), \"Internal error in hashCode\", e, false);\n+        }\n+      }\n+      return result.get_jint();\n+  } else {\n+    return checked_cast<jint>(ObjectSynchronizer::FastHashCode(THREAD, obj));\n+  }\n@@ -673,0 +856,6 @@\n+  if (klass->is_inline_klass()) {\n+    \/\/ Value instances have no identity, so return the current instance instead of allocating a new one\n+    \/\/ Value classes cannot have finalizers, so the method can return immediately\n+    return JNIHandles::make_local(THREAD, obj());\n+  }\n+\n@@ -1167,1 +1356,2 @@\n-    size = InstanceKlass::cast(klass)->local_interfaces()->length();\n+    InstanceKlass* ik = InstanceKlass::cast(klass);\n+    size = ik->local_interfaces()->length();\n@@ -1169,1 +1359,1 @@\n-    assert(klass->is_objArray_klass() || klass->is_typeArray_klass(), \"Illegal mirror klass\");\n+    assert(klass->is_objArray_klass() || klass->is_typeArray_klass() || klass->is_flatArray_klass(), \"Illegal mirror klass\");\n@@ -1180,1 +1370,2 @@\n-      Klass* k = InstanceKlass::cast(klass)->local_interfaces()->at(index);\n+      InstanceKlass* ik = InstanceKlass::cast(klass);\n+      Klass* k = ik->local_interfaces()->at(index);\n@@ -1201,1 +1392,0 @@\n-\n@@ -1685,1 +1875,1 @@\n-    if (want_constructor && !method->is_object_initializer()) {\n+    if (want_constructor && !method->is_object_constructor()) {\n@@ -1689,1 +1879,1 @@\n-        (method->is_object_initializer() || method->is_static_initializer() ||\n+        (method->is_object_constructor() || method->is_class_initializer() ||\n@@ -1717,0 +1907,1 @@\n+        assert(method->is_object_constructor(), \"must be\");\n@@ -1999,1 +2190,1 @@\n-  if (m->is_object_initializer()) {\n+  if (m->is_object_constructor()) {\n@@ -2002,1 +2193,0 @@\n-    \/\/ new_method accepts <clinit> as Method here\n@@ -2452,1 +2642,1 @@\n-  return method->name() == vmSymbols::object_initializer_name();\n+  return method->is_object_constructor();\n@@ -3243,0 +3433,4 @@\n+JVM_LEAF(jboolean, JVM_IsValhallaEnabled(void))\n+  return EnableValhalla ? JNI_TRUE : JNI_FALSE;\n+JVM_END\n+\n@@ -3322,1 +3516,3 @@\n-    objArrayHandle args(THREAD, objArrayOop(JNIHandles::resolve(args0)));\n+    objArrayHandle args(THREAD, (objArrayOop)JNIHandles::resolve(args0));\n+    assert(args() == nullptr || !args->is_flatArray(), \"args are never flat or are they???\");\n+\n@@ -3342,0 +3538,2 @@\n+  objArrayHandle args(THREAD, (objArrayOop)JNIHandles::resolve(args0));\n+  assert(args() == nullptr || !args->is_flatArray(), \"args are never flat or are they???\");\n@@ -3343,1 +3541,0 @@\n-  objArrayHandle args(THREAD, objArrayOop(JNIHandles::resolve(args0)));\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":210,"deletions":13,"binary":false,"changes":223,"status":"modified"},{"patch":"@@ -132,13 +132,16 @@\n-  IS_METHOD            = java_lang_invoke_MemberName::MN_IS_METHOD,\n-  IS_CONSTRUCTOR       = java_lang_invoke_MemberName::MN_IS_CONSTRUCTOR,\n-  IS_FIELD             = java_lang_invoke_MemberName::MN_IS_FIELD,\n-  IS_TYPE              = java_lang_invoke_MemberName::MN_IS_TYPE,\n-  CALLER_SENSITIVE     = java_lang_invoke_MemberName::MN_CALLER_SENSITIVE,\n-  TRUSTED_FINAL        = java_lang_invoke_MemberName::MN_TRUSTED_FINAL,\n-  HIDDEN_MEMBER        = java_lang_invoke_MemberName::MN_HIDDEN_MEMBER,\n-  REFERENCE_KIND_SHIFT = java_lang_invoke_MemberName::MN_REFERENCE_KIND_SHIFT,\n-  REFERENCE_KIND_MASK  = java_lang_invoke_MemberName::MN_REFERENCE_KIND_MASK,\n-  LM_UNCONDITIONAL     = java_lang_invoke_MemberName::MN_UNCONDITIONAL_MODE,\n-  LM_MODULE            = java_lang_invoke_MemberName::MN_MODULE_MODE,\n-  LM_TRUSTED           = java_lang_invoke_MemberName::MN_TRUSTED_MODE,\n-  ALL_KINDS      = IS_METHOD | IS_CONSTRUCTOR | IS_FIELD | IS_TYPE\n+  IS_METHOD             = java_lang_invoke_MemberName::MN_IS_METHOD,\n+  IS_OBJECT_CONSTRUCTOR = java_lang_invoke_MemberName::MN_IS_OBJECT_CONSTRUCTOR,\n+  IS_FIELD              = java_lang_invoke_MemberName::MN_IS_FIELD,\n+  IS_TYPE               = java_lang_invoke_MemberName::MN_IS_TYPE,\n+  CALLER_SENSITIVE      = java_lang_invoke_MemberName::MN_CALLER_SENSITIVE,\n+  TRUSTED_FINAL         = java_lang_invoke_MemberName::MN_TRUSTED_FINAL,\n+  HIDDEN_MEMBER         = java_lang_invoke_MemberName::MN_HIDDEN_MEMBER,\n+  NULL_RESTRICTED       = java_lang_invoke_MemberName::MN_NULL_RESTRICTED_FIELD,\n+  REFERENCE_KIND_SHIFT  = java_lang_invoke_MemberName::MN_REFERENCE_KIND_SHIFT,\n+  REFERENCE_KIND_MASK   = java_lang_invoke_MemberName::MN_REFERENCE_KIND_MASK,\n+  LAYOUT_SHIFT          = java_lang_invoke_MemberName::MN_LAYOUT_SHIFT,\n+  LAYOUT_MASK           = java_lang_invoke_MemberName::MN_LAYOUT_MASK,\n+  LM_UNCONDITIONAL      = java_lang_invoke_MemberName::MN_UNCONDITIONAL_MODE,\n+  LM_MODULE             = java_lang_invoke_MemberName::MN_MODULE_MODE,\n+  LM_TRUSTED            = java_lang_invoke_MemberName::MN_TRUSTED_MODE,\n+  ALL_KINDS      = IS_METHOD | IS_OBJECT_CONSTRUCTOR | IS_FIELD | IS_TYPE\n@@ -155,1 +158,1 @@\n-    flags |= IS_CONSTRUCTOR;\n+    flags |= IS_OBJECT_CONSTRUCTOR;\n@@ -174,1 +177,1 @@\n-    case IS_CONSTRUCTOR:\n+    case IS_OBJECT_CONSTRUCTOR:\n@@ -315,1 +318,1 @@\n-      assert(!m->is_static_initializer(), \"Cannot be static initializer\");\n+      assert(!m->is_class_initializer(), \"Cannot be static initializer\");\n@@ -317,2 +320,2 @@\n-    } else if (m->is_object_initializer()) {\n-      flags |= IS_CONSTRUCTOR | (JVM_REF_invokeSpecial << REFERENCE_KIND_SHIFT);\n+    } else if (m->is_object_constructor()) {\n+      flags |= IS_OBJECT_CONSTRUCTOR | (JVM_REF_invokeSpecial << REFERENCE_KIND_SHIFT);\n@@ -357,0 +360,6 @@\n+  if (fd.is_flat()) {\n+    int layout_kind = (int)fd.layout_kind();\n+    assert((layout_kind & LAYOUT_MASK) == layout_kind, \"Layout information loss\");\n+    flags |= layout_kind << LAYOUT_SHIFT;\n+  }\n+  if (fd.is_null_free_inline_type()) flags |= NULL_RESTRICTED;\n@@ -807,1 +816,1 @@\n-  case IS_CONSTRUCTOR:\n+  case IS_OBJECT_CONSTRUCTOR:\n@@ -813,1 +822,1 @@\n-        if (name == vmSymbols::object_initializer_name()) {\n+        if (name == vmSymbols::object_initializer_name() && type->is_void_method_signature()) {\n@@ -876,1 +885,1 @@\n-  case IS_CONSTRUCTOR:\n+  case IS_OBJECT_CONSTRUCTOR:\n@@ -989,1 +998,1 @@\n-    template(java_lang_invoke_MemberName,MN_IS_CONSTRUCTOR) \\\n+    template(java_lang_invoke_MemberName,MN_IS_OBJECT_CONSTRUCTOR) \\\n@@ -997,0 +1006,2 @@\n+    template(java_lang_invoke_MemberName,MN_LAYOUT_SHIFT) \\\n+    template(java_lang_invoke_MemberName,MN_LAYOUT_MASK) \\\n@@ -1132,1 +1143,1 @@\n-               (flags & ALL_KINDS) == IS_CONSTRUCTOR) {\n+               (flags & ALL_KINDS) == IS_OBJECT_CONSTRUCTOR) {\n","filename":"src\/hotspot\/share\/prims\/methodHandles.cpp","additions":34,"deletions":23,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -78,0 +78,1 @@\n+#include <string.h>\n@@ -1777,1 +1778,0 @@\n-static unsigned int patch_mod_count = 0;\n@@ -1784,1 +1784,1 @@\n-  if (!CDSConfig::check_vm_args_consistency(patch_mod_javabase, mode_flag_cmd_line)) {\n+  if (!CDSConfig::check_vm_args_consistency(mode_flag_cmd_line)) {\n@@ -2083,1 +2083,1 @@\n-      add_patch_mod_prefix(module_name, module_equal + 1);\n+      add_patch_mod_prefix(module_name, module_equal + 1, false \/* no append *\/, false \/* no cds *\/);\n@@ -2085,3 +2085,0 @@\n-      if (!create_numbered_module_property(\"jdk.module.patch\", patch_mod_tail, patch_mod_count++)) {\n-        return JNI_ENOMEM;\n-      }\n@@ -2095,0 +2092,64 @@\n+\/\/ VALUECLASS_STR must match string used in the build\n+#define VALUECLASS_STR \"valueclasses\"\n+#define VALUECLASS_JAR \"-\" VALUECLASS_STR \".jar\"\n+\n+\/\/ Finalize --patch-module args and --enable-preview related to value class module patches.\n+\/\/ Create all numbered properties passing module patches.\n+int Arguments::finalize_patch_module() {\n+  \/\/ If --enable-preview and EnableValhalla is true, each module may have value classes that\n+  \/\/ are to be patched into the module.\n+  \/\/ For each <module>-valueclasses.jar in <JAVA_HOME>\/lib\/valueclasses\/\n+  \/\/ appends the equivalent of --patch-module <module>=<JAVA_HOME>\/lib\/valueclasses\/<module>-valueclasses.jar\n+  if (enable_preview() && EnableValhalla) {\n+    char * valueclasses_dir = AllocateHeap(JVM_MAXPATHLEN, mtArguments);\n+    const char * fileSep = os::file_separator();\n+\n+    jio_snprintf(valueclasses_dir, JVM_MAXPATHLEN, \"%s%slib%s\" VALUECLASS_STR \"%s\",\n+                 Arguments::get_java_home(), fileSep, fileSep, fileSep);\n+    DIR* dir = os::opendir(valueclasses_dir);\n+    if (dir != nullptr) {\n+      char * module_name = AllocateHeap(JVM_MAXPATHLEN, mtArguments);\n+      char * path = AllocateHeap(JVM_MAXPATHLEN, mtArguments);\n+\n+      for (dirent * entry = os::readdir(dir); entry != nullptr; entry = os::readdir(dir)) {\n+        \/\/ Test if file ends-with \"-valueclasses.jar\"\n+        int len = (int)strlen(entry->d_name) - (sizeof(VALUECLASS_JAR) - 1);\n+        if (len <= 0 || strcmp(&entry->d_name[len], VALUECLASS_JAR) != 0) {\n+          continue;         \/\/ too short or not the expected suffix\n+        }\n+\n+        strcpy(module_name, entry->d_name);\n+        module_name[len] = '\\0';     \/\/ truncate to just module-name\n+\n+        jio_snprintf(path, JVM_MAXPATHLEN, \"%s%s\", valueclasses_dir, &entry->d_name);\n+        add_patch_mod_prefix(module_name, path, true \/* append *\/, true \/* cds OK*\/);\n+        log_info(class)(\"--enable-preview appending value classes for module %s: %s\", module_name, entry->d_name);\n+      }\n+      FreeHeap(module_name);\n+      FreeHeap(path);\n+      os::closedir(dir);\n+    }\n+    FreeHeap(valueclasses_dir);\n+  }\n+\n+  \/\/ Create numbered properties for each module that has been patched either\n+  \/\/ by --patch-module or --enable-preview\n+  \/\/ Format is \"jdk.module.patch.<n>=<module_name>=<path>\"\n+  if (_patch_mod_prefix != nullptr) {\n+    char * prop_value = AllocateHeap(JVM_MAXPATHLEN + JVM_MAXPATHLEN + 1, mtArguments);\n+    unsigned int patch_mod_count = 0;\n+\n+    for (GrowableArrayIterator<ModulePatchPath *> it = _patch_mod_prefix->begin();\n+            it != _patch_mod_prefix->end(); ++it) {\n+      jio_snprintf(prop_value, JVM_MAXPATHLEN + JVM_MAXPATHLEN + 1, \"%s=%s\",\n+                   (*it)->module_name(), (*it)->path_string());\n+      if (!create_numbered_module_property(\"jdk.module.patch\", prop_value, patch_mod_count++)) {\n+        FreeHeap(prop_value);\n+        return JNI_ENOMEM;\n+      }\n+    }\n+    FreeHeap(prop_value);\n+  }\n+  return JNI_OK;\n+}\n+\n@@ -2363,0 +2424,4 @@\n+      \/\/ --enable-preview enables Valhalla, EnableValhalla VM option will eventually be removed before integration\n+      if (FLAG_SET_CMDLINE(EnableValhalla, true) != JVMFlag::SUCCESS) {\n+        return JNI_EINVAL;\n+      }\n@@ -2842,10 +2907,5 @@\n-void Arguments::add_patch_mod_prefix(const char* module_name, const char* path) {\n-  \/\/ For java.base check for duplicate --patch-module options being specified on the command line.\n-  \/\/ This check is only required for java.base, all other duplicate module specifications\n-  \/\/ will be checked during module system initialization.  The module system initialization\n-  \/\/ will throw an ExceptionInInitializerError if this situation occurs.\n-  if (strcmp(module_name, JAVA_BASE_NAME) == 0) {\n-    if (patch_mod_javabase) {\n-      vm_exit_during_initialization(\"Cannot specify \" JAVA_BASE_NAME \" more than once to --patch-module\");\n-    } else {\n-      patch_mod_javabase = true;\n+void Arguments::add_patch_mod_prefix(const char* module_name, const char* path, bool allow_append, bool allow_cds) {\n+  if (!allow_cds) {\n+    CDSConfig::set_module_patching_disables_cds();\n+    if (strcmp(module_name, JAVA_BASE_NAME) == 0) {\n+      CDSConfig::set_java_base_module_patching_disables_cds();\n@@ -2860,1 +2920,18 @@\n-  _patch_mod_prefix->push(new ModulePatchPath(module_name, path));\n+  \/\/ Scan patches for matching module\n+  int i = _patch_mod_prefix->find_if([&](ModulePatchPath* patch) {\n+    return (strcmp(module_name, patch->module_name()) == 0);\n+  });\n+  if (i == -1) {\n+    _patch_mod_prefix->push(new ModulePatchPath(module_name, path));\n+  } else {\n+    if (allow_append) {\n+      \/\/ append path to existing module entry\n+      _patch_mod_prefix->at(i)->append_path(path);\n+    } else {\n+      if (strcmp(module_name, JAVA_BASE_NAME) == 0) {\n+        vm_exit_during_initialization(\"Cannot specify \" JAVA_BASE_NAME \" more than once to --patch-module\");\n+      } else {\n+        vm_exit_during_initialization(\"Cannot specify a module more than once to --patch-module\", module_name);\n+      }\n+    }\n+  }\n@@ -2973,1 +3050,2 @@\n-  if (!check_vm_args_consistency()) {\n+  \/\/ finalize --module-patch and related --enable-preview\n+  if (finalize_patch_module() != JNI_OK) {\n@@ -2977,0 +3055,3 @@\n+  if (!check_vm_args_consistency()) {\n+    return JNI_ERR;\n+  }\n@@ -3779,0 +3860,12 @@\n+  if (!EnableValhalla || (is_interpreter_only() && !CDSConfig::is_dumping_archive() && !UseSharedSpaces)) {\n+    \/\/ Disable calling convention optimizations if inline types are not supported.\n+    \/\/ Also these aren't useful in -Xint. However, don't disable them when dumping or using\n+    \/\/ the CDS archive, as the values must match between dumptime and runtime.\n+    FLAG_SET_DEFAULT(InlineTypePassFieldsAsArgs, false);\n+    FLAG_SET_DEFAULT(InlineTypeReturnedAsFields, false);\n+  }\n+  if (!UseNonAtomicValueFlattening && !UseNullableValueFlattening && !UseAtomicValueFlattening) {\n+    \/\/ Flattening is disabled\n+    FLAG_SET_DEFAULT(UseArrayFlattening, false);\n+    FLAG_SET_DEFAULT(UseFieldFlattening, false);\n+  }\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":111,"deletions":18,"binary":false,"changes":129,"status":"modified"},{"patch":"@@ -94,0 +94,1 @@\n+  inline void append_path(const char* path) { _path->append_value(path); }\n@@ -483,1 +484,2 @@\n-  static void add_patch_mod_prefix(const char *module_name, const char *path);\n+  static void add_patch_mod_prefix(const char *module_name, const char *path, bool allow_append, bool allow_cds);\n+  static int finalize_patch_module();\n","filename":"src\/hotspot\/share\/runtime\/arguments.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -816,1 +816,1 @@\n-  develop(bool, PrintFieldLayout, false,                                    \\\n+  product(bool, PrintFieldLayout, false, DIAGNOSTIC,                        \\\n@@ -819,0 +819,24 @@\n+  product(bool, PrintInlineLayout, false, DIAGNOSTIC,                       \\\n+          \"Print field layout for each inline type or class with inline fields\") \\\n+                                                                            \\\n+  product(bool, PrintFlatArrayLayout, false, DIAGNOSTIC,                    \\\n+          \"Print array layout for each inline type array\")                  \\\n+                                                                            \\\n+  product(bool, UseArrayFlattening, true,                                   \\\n+          \"Allow the VM to flatten arrays\")                                 \\\n+                                                                            \\\n+  product(bool, UseFieldFlattening, true,                                   \\\n+          \"Allow the VM to flatten value fields\")                           \\\n+                                                                            \\\n+  product(bool, UseNonAtomicValueFlattening, true,                          \\\n+          \"Allow the JVM to flatten some non-atomic null-free values\")      \\\n+                                                                            \\\n+  product(bool, UseNullableValueFlattening, true,                           \\\n+          \"Allow the JVM to flatten some nullable values\")                  \\\n+                                                                            \\\n+  product(bool, UseAtomicValueFlattening, true,                             \\\n+          \"Allow the JVM to flatten some atomic values\")                    \\\n+                                                                            \\\n+  product(intx, FlatArrayElementMaxOops, 4,                                 \\\n+          \"Max nof embedded object references in an inline type to flatten, <0 no limit\")  \\\n+                                                                            \\\n@@ -1782,0 +1806,3 @@\n+  product(bool, IgnoreAssertUnsetFields, false, DIAGNOSTIC,                           \\\n+          \"Ignore assert_unset_fields\")                                     \\\n+                                                                            \\\n@@ -1953,0 +1980,17 @@\n+  product(bool, EnableValhalla, true,                                       \\\n+          \"Enable experimental Valhalla features\")                          \\\n+                                                                            \\\n+  product_pd(bool, InlineTypePassFieldsAsArgs,                              \\\n+          \"Pass each inline type field as an argument at calls\")            \\\n+                                                                            \\\n+  product_pd(bool, InlineTypeReturnedAsFields,                              \\\n+          \"Return fields instead of an inline type reference\")              \\\n+                                                                            \\\n+  develop(bool, StressCallingConvention, false,                             \\\n+          \"Stress the scalarized calling convention.\")                      \\\n+                                                                            \\\n+  product(ccstrlist, ForceNonTearable, \"\", DIAGNOSTIC,                      \\\n+          \"List of inline classes which are forced to be atomic \"           \\\n+          \"(whitespace and commas separate names, \"                         \\\n+          \"and leading and trailing stars '*' are wildcards)\")              \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":45,"deletions":1,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -48,0 +48,1 @@\n+#include \"memory\/oopFactory.hpp\"\n@@ -50,0 +51,2 @@\n+#include \"oops\/access.hpp\"\n+#include \"oops\/fieldStreams.inline.hpp\"\n@@ -54,0 +57,1 @@\n+#include \"oops\/objArrayOop.inline.hpp\"\n@@ -55,0 +59,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -1193,0 +1198,15 @@\n+  \/\/ Substitutability test implementation piggy backs on static call resolution\n+  Bytecodes::Code code = caller->java_code_at(bci);\n+  if (code == Bytecodes::_if_acmpeq || code == Bytecodes::_if_acmpne) {\n+    bc = Bytecodes::_invokestatic;\n+    methodHandle attached_method(THREAD, extract_attached_method(vfst));\n+    assert(attached_method.not_null(), \"must have attached method\");\n+    vmClasses::ValueObjectMethods_klass()->initialize(CHECK_NH);\n+    LinkResolver::resolve_invoke(callinfo, receiver, attached_method, bc, false, CHECK_NH);\n+#ifdef ASSERT\n+    Method* is_subst = vmClasses::ValueObjectMethods_klass()->find_method(vmSymbols::isSubstitutable_name(), vmSymbols::object_object_boolean_signature());\n+    assert(callinfo.selected_method() == is_subst, \"must be isSubstitutable method\");\n+#endif\n+    return receiver;\n+  }\n+\n@@ -1228,0 +1248,6 @@\n+    } else {\n+      assert(attached_method->has_scalarized_args(), \"invalid use of attached method\");\n+      if (!attached_method->method_holder()->is_inline_klass()) {\n+        \/\/ Ignore the attached method in this case to not confuse below code\n+        attached_method = methodHandle(current, nullptr);\n+      }\n@@ -1236,0 +1262,1 @@\n+  bool check_null_and_abstract = true;\n@@ -1249,2 +1276,3 @@\n-    if (attached_method.is_null()) {\n-      Method* callee = bytecode.static_target(CHECK_NH);\n+    Method* callee = attached_method();\n+    if (callee == nullptr) {\n+      callee = bytecode.static_target(CHECK_NH);\n@@ -1255,7 +1283,17 @@\n-\n-    \/\/ Retrieve from a compiled argument list\n-    receiver = Handle(current, callerFrame.retrieve_receiver(&reg_map2));\n-    assert(oopDesc::is_oop_or_null(receiver()), \"\");\n-\n-    if (receiver.is_null()) {\n-      THROW_(vmSymbols::java_lang_NullPointerException(), nullHandle);\n+    bool caller_is_c1 = callerFrame.is_compiled_frame() && callerFrame.cb()->as_nmethod()->is_compiled_by_c1();\n+    if (!caller_is_c1 && callee->is_scalarized_arg(0)) {\n+      \/\/ If the receiver is an inline type that is passed as fields, no oop is available\n+      \/\/ Resolve the call without receiver null checking.\n+      assert(!callee->mismatch(), \"calls with inline type receivers should never mismatch\");\n+      assert(attached_method.not_null() && !attached_method->is_abstract(), \"must have non-abstract attached method\");\n+      if (bc == Bytecodes::_invokeinterface) {\n+        bc = Bytecodes::_invokevirtual; \/\/ C2 optimistically replaces interface calls by virtual calls\n+      }\n+      check_null_and_abstract = false;\n+    } else {\n+      \/\/ Retrieve from a compiled argument list\n+      receiver = Handle(current, callerFrame.retrieve_receiver(&reg_map2));\n+      assert(oopDesc::is_oop_or_null(receiver()), \"\");\n+      if (receiver.is_null()) {\n+        THROW_(vmSymbols::java_lang_NullPointerException(), nullHandle);\n+      }\n@@ -1268,1 +1306,1 @@\n-    LinkResolver::resolve_invoke(callinfo, receiver, attached_method, bc, CHECK_NH);\n+    LinkResolver::resolve_invoke(callinfo, receiver, attached_method, bc, check_null_and_abstract, CHECK_NH);\n@@ -1277,1 +1315,1 @@\n-  if (has_receiver) {\n+  if (has_receiver && check_null_and_abstract) {\n@@ -1305,1 +1343,1 @@\n-methodHandle SharedRuntime::find_callee_method(TRAPS) {\n+methodHandle SharedRuntime::find_callee_method(bool is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1331,0 +1369,4 @@\n+    \/\/ Calls via mismatching methods are always non-scalarized\n+    if (callinfo.resolved_method()->mismatch() && !is_optimized) {\n+      caller_is_c1 = true;\n+    }\n@@ -1338,1 +1380,1 @@\n-methodHandle SharedRuntime::resolve_helper(bool is_virtual, bool is_optimized, TRAPS) {\n+methodHandle SharedRuntime::resolve_helper(bool is_virtual, bool is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1361,0 +1403,4 @@\n+  \/\/ Calls via mismatching methods are always non-scalarized\n+  if (caller_nm->is_compiled_by_c1() || (call_info.resolved_method()->mismatch() && !is_optimized)) {\n+    caller_is_c1 = true;\n+  }\n@@ -1379,1 +1425,1 @@\n-    tty->print(\"resolving %s%s (%s) call to\",\n+    tty->print(\"resolving %s%s (%s) call%s to\",\n@@ -1381,1 +1427,1 @@\n-               Bytecodes::name(invoke_code));\n+               Bytecodes::name(invoke_code), (caller_is_c1) ? \" from C1\" : \"\");\n@@ -1420,1 +1466,1 @@\n-    inline_cache->update(&call_info, receiver->klass());\n+    inline_cache->update(&call_info, receiver->klass(), caller_is_c1);\n@@ -1424,1 +1470,1 @@\n-    callsite->set(callee_method);\n+    callsite->set(callee_method, caller_is_c1);\n@@ -1444,0 +1490,2 @@\n+  bool is_optimized = false;\n+  bool caller_is_c1 = false;\n@@ -1445,1 +1493,1 @@\n-    callee_method = SharedRuntime::handle_ic_miss_helper(CHECK_NULL);\n+    callee_method = SharedRuntime::handle_ic_miss_helper(is_optimized, caller_is_c1, CHECK_NULL);\n@@ -1450,1 +1498,1 @@\n-  return get_resolved_entry(current, callee_method);\n+  return get_resolved_entry(current, callee_method, false, is_optimized, caller_is_c1);\n@@ -1491,1 +1539,5 @@\n-      return callee->get_c2i_entry();\n+      if (caller_frame.is_interpreted_frame()) {\n+        return callee->get_c2i_inline_entry();\n+      } else {\n+        return callee->get_c2i_entry();\n+      }\n@@ -1497,0 +1549,3 @@\n+  bool is_static_call = false;\n+  bool is_optimized = false;\n+  bool caller_is_c1 = false;\n@@ -1499,1 +1554,1 @@\n-    callee_method = SharedRuntime::reresolve_call_site(CHECK_NULL);\n+    callee_method = SharedRuntime::reresolve_call_site(is_static_call, is_optimized, caller_is_c1, CHECK_NULL);\n@@ -1503,1 +1558,1 @@\n-  return get_resolved_entry(current, callee_method);\n+  return get_resolved_entry(current, callee_method, is_static_call, is_optimized, caller_is_c1);\n@@ -1542,1 +1597,2 @@\n-address SharedRuntime::get_resolved_entry(JavaThread* current, methodHandle callee_method) {\n+address SharedRuntime::get_resolved_entry(JavaThread* current, methodHandle callee_method,\n+                                          bool is_static_call, bool is_optimized, bool caller_is_c1) {\n@@ -1548,2 +1604,11 @@\n-  assert(callee_method->verified_code_entry() != nullptr, \" Jump to zero!\");\n-  return callee_method->verified_code_entry();\n+\n+  if (caller_is_c1) {\n+    assert(callee_method->verified_inline_code_entry() != nullptr, \"Jump to zero!\");\n+    return callee_method->verified_inline_code_entry();\n+  } else if (is_static_call || is_optimized) {\n+    assert(callee_method->verified_code_entry() != nullptr, \"Jump to zero!\");\n+    return callee_method->verified_code_entry();\n+  } else {\n+    assert(callee_method->verified_inline_ro_code_entry() != nullptr, \"Jump to zero!\");\n+    return callee_method->verified_inline_ro_code_entry();\n+  }\n@@ -1555,0 +1620,1 @@\n+  bool caller_is_c1 = false;\n@@ -1557,1 +1623,1 @@\n-    callee_method = SharedRuntime::resolve_helper(false, false, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(false, false, caller_is_c1, CHECK_NULL);\n@@ -1561,1 +1627,1 @@\n-  return get_resolved_entry(current, callee_method);\n+  return get_resolved_entry(current, callee_method, true, false, caller_is_c1);\n@@ -1567,0 +1633,1 @@\n+  bool caller_is_c1 = false;\n@@ -1568,1 +1635,1 @@\n-    callee_method = SharedRuntime::resolve_helper(true, false, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(true, false, caller_is_c1, CHECK_NULL);\n@@ -1572,1 +1639,1 @@\n-  return get_resolved_entry(current, callee_method);\n+  return get_resolved_entry(current, callee_method, false, false, caller_is_c1);\n@@ -1580,0 +1647,1 @@\n+  bool caller_is_c1 = false;\n@@ -1581,1 +1649,1 @@\n-    callee_method = SharedRuntime::resolve_helper(true, true, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(true, true, caller_is_c1, CHECK_NULL);\n@@ -1585,1 +1653,1 @@\n-  return get_resolved_entry(current, callee_method);\n+  return get_resolved_entry(current, callee_method, false, true, caller_is_c1);\n@@ -1588,1 +1656,3 @@\n-methodHandle SharedRuntime::handle_ic_miss_helper(TRAPS) {\n+\n+\n+methodHandle SharedRuntime::handle_ic_miss_helper(bool& is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1606,1 +1676,1 @@\n-    tty->print(\"IC miss (%s) call to\", Bytecodes::name(bc));\n+    tty->print(\"IC miss (%s) call%s to\", Bytecodes::name(bc), (caller_is_c1) ? \" from C1\" : \"\");\n@@ -1638,0 +1708,4 @@\n+  \/\/ Calls via mismatching methods are always non-scalarized\n+  if (caller_nm->is_compiled_by_c1() || call_info.resolved_method()->mismatch()) {\n+    caller_is_c1 = true;\n+  }\n@@ -1641,1 +1715,1 @@\n-  inline_cache->update(&call_info, receiver()->klass());\n+  inline_cache->update(&call_info, receiver()->klass(), caller_is_c1);\n@@ -1652,1 +1726,1 @@\n-methodHandle SharedRuntime::reresolve_call_site(TRAPS) {\n+methodHandle SharedRuntime::reresolve_call_site(bool& is_static_call, bool& is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1662,0 +1736,3 @@\n+  if (caller.is_compiled_frame()) {\n+    caller_is_c1 = caller.cb()->as_nmethod()->is_compiled_by_c1();\n+  }\n@@ -1702,0 +1779,2 @@\n+        is_static_call = false;\n+        is_optimized = false;\n@@ -1704,0 +1783,1 @@\n+            is_static_call = true;\n@@ -1705,0 +1785,1 @@\n+            is_optimized = (iter.type() == relocInfo::opt_virtual_call_type);\n@@ -1709,1 +1790,0 @@\n-\n@@ -1723,2 +1803,1 @@\n-  methodHandle callee_method = find_callee_method(CHECK_(methodHandle()));\n-\n+  methodHandle callee_method = find_callee_method(is_optimized, caller_is_c1, CHECK_(methodHandle()));\n@@ -1731,1 +1810,1 @@\n-    tty->print(\"handle_wrong_method reresolving call to\");\n+    tty->print(\"handle_wrong_method reresolving call%s to\", (caller_is_c1) ? \" from C1\" : \"\");\n@@ -1937,0 +2016,15 @@\n+char* SharedRuntime::generate_identity_exception_message(JavaThread* current, Klass* klass) {\n+  assert(klass->is_inline_klass(), \"Must be a concrete value class\");\n+  const char* desc = \"Cannot synchronize on an instance of value class \";\n+  const char* className = klass->external_name();\n+  size_t msglen = strlen(desc) + strlen(className) + 1;\n+  char* message = NEW_RESOURCE_ARRAY(char, msglen);\n+  if (nullptr == message) {\n+    \/\/ Out of memory: can't create detailed error message\n+    message = const_cast<char*>(klass->external_name());\n+  } else {\n+    jio_snprintf(message, msglen, \"%s%s\", desc, className);\n+  }\n+  return message;\n+}\n+\n@@ -2188,1 +2282,1 @@\n-    _basic_type_bits = 4,\n+    _basic_type_bits = 5,\n@@ -2200,1 +2294,1 @@\n-  AdapterFingerPrint(int total_args_passed, BasicType* sig_bt) {\n+  AdapterFingerPrint(const GrowableArray<SigEntry>* sig, bool has_ro_adapter = false) {\n@@ -2202,0 +2296,1 @@\n+    int total_args_passed = (sig != nullptr) ? sig->length() : 0;\n@@ -2204,0 +2299,2 @@\n+    BasicType prev_bt = T_ILLEGAL;\n+    int vt_count = 0;\n@@ -2206,4 +2303,27 @@\n-      for (int byte = 0; sig_index < total_args_passed && byte < _basic_types_per_int; byte++) {\n-        int bt = adapter_encoding(sig_bt[sig_index++]);\n-        assert((bt & _basic_type_mask) == bt, \"must fit in 4 bits\");\n-        value = (value << _basic_type_bits) | bt;\n+      for (int byte = 0; byte < _basic_types_per_int; byte++) {\n+        BasicType bt = T_ILLEGAL;\n+        if (sig_index < total_args_passed) {\n+          bt = sig->at(sig_index++)._bt;\n+          if (bt == T_METADATA) {\n+            \/\/ Found start of inline type in signature\n+            assert(InlineTypePassFieldsAsArgs, \"unexpected start of inline type\");\n+            if (sig_index == 1 && has_ro_adapter) {\n+              \/\/ With a ro_adapter, replace receiver inline type delimiter by T_VOID to prevent matching\n+              \/\/ with other adapters that have the same inline type as first argument and no receiver.\n+              bt = T_VOID;\n+            }\n+            vt_count++;\n+          } else if (bt == T_VOID && prev_bt != T_LONG && prev_bt != T_DOUBLE) {\n+            \/\/ Found end of inline type in signature\n+            assert(InlineTypePassFieldsAsArgs, \"unexpected end of inline type\");\n+            vt_count--;\n+            assert(vt_count >= 0, \"invalid vt_count\");\n+          } else if (vt_count == 0) {\n+            \/\/ Widen fields that are not part of a scalarized inline type argument\n+            bt = adapter_encoding(bt);\n+          }\n+          prev_bt = bt;\n+        }\n+        int bt_val = (bt == T_ILLEGAL) ? 0 : bt;\n+        assert((bt_val & _basic_type_mask) == bt_val, \"must fit in 4 bits\");\n+        value = (value << _basic_type_bits) | bt_val;\n@@ -2213,0 +2333,1 @@\n+    assert(vt_count == 0, \"invalid vt_count\");\n@@ -2223,1 +2344,1 @@\n-  static int adapter_encoding(BasicType in) {\n+  static BasicType adapter_encoding(BasicType in) {\n@@ -2229,1 +2350,1 @@\n-        \/\/ There are all promoted to T_INT in the calling convention\n+        \/\/ They are all promoted to T_INT in the calling convention\n@@ -2262,0 +2383,1 @@\n+public:\n@@ -2268,1 +2390,2 @@\n-      for (int j = 32 - _basic_type_bits; j >= 0; j -= _basic_type_bits) {\n+      int first_entry = _basic_types_per_int * _basic_type_bits;\n+      for (int j = first_entry; j >= 0; j -= _basic_type_bits) {\n@@ -2278,2 +2401,2 @@\n- public:\n-  static int allocation_size(int total_args_passed, BasicType* sig_bt) {\n+  static int allocation_size(const GrowableArray<SigEntry>* sig) {\n+    int total_args_passed = (sig != nullptr) ? sig->length() : 0;\n@@ -2284,3 +2407,3 @@\n-  static AdapterFingerPrint* allocate(int total_args_passed, BasicType* sig_bt) {\n-    int size_in_bytes = allocation_size(total_args_passed, sig_bt);\n-    return new (size_in_bytes) AdapterFingerPrint(total_args_passed, sig_bt);\n+  static AdapterFingerPrint* allocate(const GrowableArray<SigEntry>* sig, bool has_ro_adapter = false) {\n+    int size_in_bytes = allocation_size(sig);\n+    return new (size_in_bytes) AdapterFingerPrint(sig, has_ro_adapter);\n@@ -2337,7 +2460,4 @@\n-      switch (arg) {\n-        case T_INT:    st.print(\"I\");    break;\n-        case T_LONG:   long_prev = true; break;\n-        case T_FLOAT:  st.print(\"F\");    break;\n-        case T_DOUBLE: st.print(\"D\");    break;\n-        case T_VOID:   break;\n-        default: ShouldNotReachHere();\n+      if (arg == T_LONG) {\n+        long_prev = true;\n+      } else if (arg != T_VOID) {\n+        st.print(\"%c\", type2char((BasicType)arg));\n@@ -2352,51 +2472,0 @@\n-  BasicType* as_basic_type(int& nargs) {\n-    nargs = 0;\n-    GrowableArray<BasicType> btarray;\n-    bool long_prev = false;\n-\n-    iterate_args([&] (int arg) {\n-      if (long_prev) {\n-        long_prev = false;\n-        if (arg == T_VOID) {\n-          btarray.append(T_LONG);\n-        } else {\n-          btarray.append(T_OBJECT); \/\/ it could be T_ARRAY; it shouldn't matter\n-        }\n-      }\n-      switch (arg) {\n-        case T_INT: \/\/ fallthrough\n-        case T_FLOAT: \/\/ fallthrough\n-        case T_DOUBLE:\n-        case T_VOID:\n-          btarray.append((BasicType)arg);\n-          break;\n-        case T_LONG:\n-          long_prev = true;\n-          break;\n-        default: ShouldNotReachHere();\n-      }\n-    });\n-\n-    if (long_prev) {\n-      btarray.append(T_OBJECT);\n-    }\n-\n-    nargs = btarray.length();\n-    BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, nargs);\n-    int index = 0;\n-    GrowableArrayIterator<BasicType> iter = btarray.begin();\n-    while (iter != btarray.end()) {\n-      sig_bt[index++] = *iter;\n-      ++iter;\n-    }\n-    assert(index == btarray.length(), \"sanity check\");\n-#ifdef ASSERT\n-    {\n-      AdapterFingerPrint* compare_fp = AdapterFingerPrint::allocate(nargs, sig_bt);\n-      assert(this->equals(compare_fp), \"sanity check\");\n-      AdapterFingerPrint::deallocate(compare_fp);\n-    }\n-#endif\n-    return sig_bt;\n-  }\n-\n@@ -2451,1 +2520,1 @@\n-AdapterHandlerEntry* AdapterHandlerLibrary::lookup(int total_args_passed, BasicType* sig_bt) {\n+AdapterHandlerEntry* AdapterHandlerLibrary::lookup(const GrowableArray<SigEntry>* sig, bool has_ro_adapter) {\n@@ -2454,1 +2523,1 @@\n-  AdapterFingerPrint* fp = AdapterFingerPrint::allocate(total_args_passed, sig_bt);\n+  AdapterFingerPrint* fp = AdapterFingerPrint::allocate(sig, has_ro_adapter);\n@@ -2516,1 +2585,1 @@\n-static const int AdapterHandlerLibrary_size = 16*K;\n+static const int AdapterHandlerLibrary_size = 48*K;\n@@ -2551,1 +2620,1 @@\n-  _abstract_method_handler = AdapterHandlerLibrary::new_entry(AdapterFingerPrint::allocate(0, nullptr));\n+  _abstract_method_handler = AdapterHandlerLibrary::new_entry(AdapterFingerPrint::allocate(nullptr));\n@@ -2553,3 +2622,2 @@\n-                                             wrong_method_abstract,\n-                                             wrong_method_abstract,\n-                                             nullptr);\n+                                             wrong_method_abstract, wrong_method_abstract, wrong_method_abstract,\n+                                             wrong_method_abstract, wrong_method_abstract);\n@@ -2585,1 +2653,3 @@\n-    _no_arg_handler = create_adapter(no_arg_blob, 0, nullptr);\n+    CompiledEntrySignature no_args;\n+    no_args.compute_calling_conventions();\n+    _no_arg_handler = create_adapter(no_arg_blob, no_args, true);\n@@ -2587,2 +2657,4 @@\n-    BasicType obj_args[] = { T_OBJECT };\n-    _obj_arg_handler = create_adapter(obj_arg_blob, 1, obj_args);\n+    CompiledEntrySignature obj_args;\n+    SigEntry::add_entry(obj_args.sig(), T_OBJECT);\n+    obj_args.compute_calling_conventions();\n+    _obj_arg_handler = create_adapter(obj_arg_blob, obj_args, true);\n@@ -2590,2 +2662,4 @@\n-    BasicType int_args[] = { T_INT };\n-    _int_arg_handler = create_adapter(int_arg_blob, 1, int_args);\n+    CompiledEntrySignature int_args;\n+    SigEntry::add_entry(int_args.sig(), T_INT);\n+    int_args.compute_calling_conventions();\n+    _int_arg_handler = create_adapter(int_arg_blob, int_args, true);\n@@ -2593,2 +2667,5 @@\n-    BasicType obj_int_args[] = { T_OBJECT, T_INT };\n-    _obj_int_arg_handler = create_adapter(obj_int_arg_blob, 2, obj_int_args);\n+    CompiledEntrySignature obj_int_args;\n+    SigEntry::add_entry(obj_int_args.sig(), T_OBJECT);\n+    SigEntry::add_entry(obj_int_args.sig(), T_INT);\n+    obj_int_args.compute_calling_conventions();\n+    _obj_int_arg_handler = create_adapter(obj_int_arg_blob, obj_int_args, true);\n@@ -2596,2 +2673,5 @@\n-    BasicType obj_obj_args[] = { T_OBJECT, T_OBJECT };\n-    _obj_obj_arg_handler = create_adapter(obj_obj_arg_blob, 2, obj_obj_args);\n+    CompiledEntrySignature obj_obj_args;\n+    SigEntry::add_entry(obj_obj_args.sig(), T_OBJECT);\n+    SigEntry::add_entry(obj_obj_args.sig(), T_OBJECT);\n+    obj_obj_args.compute_calling_conventions();\n+    _obj_obj_arg_handler = create_adapter(obj_obj_arg_blob, obj_obj_args, true);\n@@ -2620,1 +2700,1 @@\n-    return _abstract_method_handler;\n+    return nullptr;\n@@ -2627,0 +2707,3 @@\n+      if (InlineTypePassFieldsAsArgs && method->method_holder()->is_inline_klass()) {\n+        return nullptr;\n+      }\n@@ -2630,1 +2713,10 @@\n-      case JVM_SIGNATURE_CLASS:\n+      case JVM_SIGNATURE_CLASS: {\n+        if (InlineTypePassFieldsAsArgs) {\n+          SignatureStream ss(method->signature());\n+          InlineKlass* vk = ss.as_inline_klass(method->method_holder());\n+          if (vk != nullptr) {\n+            return nullptr;\n+          }\n+        }\n+        return _obj_arg_handler;\n+      }\n@@ -2641,1 +2733,1 @@\n-             !method->is_static()) {\n+             !method->is_static() && (!InlineTypePassFieldsAsArgs || !method->method_holder()->is_inline_klass())) {\n@@ -2643,1 +2735,10 @@\n-      case JVM_SIGNATURE_CLASS:\n+      case JVM_SIGNATURE_CLASS: {\n+        if (InlineTypePassFieldsAsArgs) {\n+          SignatureStream ss(method->signature());\n+          InlineKlass* vk = ss.as_inline_klass(method->method_holder());\n+          if (vk != nullptr) {\n+            return nullptr;\n+          }\n+        }\n+        return _obj_obj_arg_handler;\n+      }\n@@ -2657,5 +2758,9 @@\n-class AdapterSignatureIterator : public SignatureIterator {\n- private:\n-  BasicType stack_sig_bt[16];\n-  BasicType* sig_bt;\n-  int index;\n+CompiledEntrySignature::CompiledEntrySignature(Method* method) :\n+  _method(method), _num_inline_args(0), _has_inline_recv(false),\n+  _regs(nullptr), _regs_cc(nullptr), _regs_cc_ro(nullptr),\n+  _args_on_stack(0), _args_on_stack_cc(0), _args_on_stack_cc_ro(0),\n+  _c1_needs_stack_repair(false), _c2_needs_stack_repair(false), _supers(nullptr) {\n+  _sig = new GrowableArray<SigEntry>((method != nullptr) ? method->size_of_parameters() : 1);\n+  _sig_cc = new GrowableArray<SigEntry>((method != nullptr) ? method->size_of_parameters() : 1);\n+  _sig_cc_ro = new GrowableArray<SigEntry>((method != nullptr) ? method->size_of_parameters() : 1);\n+}\n@@ -2663,11 +2768,24 @@\n- public:\n-  AdapterSignatureIterator(Symbol* signature,\n-                           fingerprint_t fingerprint,\n-                           bool is_static,\n-                           int total_args_passed) :\n-    SignatureIterator(signature, fingerprint),\n-    index(0)\n-  {\n-    sig_bt = (total_args_passed <= 16) ? stack_sig_bt : NEW_RESOURCE_ARRAY(BasicType, total_args_passed);\n-    if (!is_static) { \/\/ Pass in receiver first\n-      sig_bt[index++] = T_OBJECT;\n+\/\/ See if we can save space by sharing the same entry for VIEP and VIEP(RO),\n+\/\/ or the same entry for VEP and VIEP(RO).\n+CodeOffsets::Entries CompiledEntrySignature::c1_inline_ro_entry_type() const {\n+  if (!has_scalarized_args()) {\n+    \/\/ VEP\/VIEP\/VIEP(RO) all share the same entry. There's no packing.\n+    return CodeOffsets::Verified_Entry;\n+  }\n+  if (_method->is_static()) {\n+    \/\/ Static methods don't need VIEP(RO)\n+    return CodeOffsets::Verified_Entry;\n+  }\n+\n+  if (has_inline_recv()) {\n+    if (num_inline_args() == 1) {\n+      \/\/ Share same entry for VIEP and VIEP(RO).\n+      \/\/ This is quite common: we have an instance method in an InlineKlass that has\n+      \/\/ no inline type args other than <this>.\n+      return CodeOffsets::Verified_Inline_Entry;\n+    } else {\n+      assert(num_inline_args() > 1, \"must be\");\n+      \/\/ No sharing:\n+      \/\/   VIEP(RO) -- <this> is passed as object\n+      \/\/   VEP      -- <this> is passed as fields\n+      return CodeOffsets::Verified_Inline_Entry_RO;\n@@ -2675,1 +2793,0 @@\n-    do_parameters_on(this);\n@@ -2678,2 +2795,9 @@\n-  BasicType* basic_types() {\n-    return sig_bt;\n+  \/\/ Either a static method, or <this> is not an inline type\n+  if (args_on_stack_cc() != args_on_stack_cc_ro()) {\n+    \/\/ No sharing:\n+    \/\/ Some arguments are passed on the stack, and we have inserted reserved entries\n+    \/\/ into the VEP, but we never insert reserved entries into the VIEP(RO).\n+    return CodeOffsets::Verified_Inline_Entry_RO;\n+  } else {\n+    \/\/ Share same entry for VEP and VIEP(RO).\n+    return CodeOffsets::Verified_Entry;\n@@ -2681,0 +2805,1 @@\n+}\n@@ -2682,3 +2807,39 @@\n-#ifdef ASSERT\n-  int slots() {\n-    return index;\n+\/\/ Returns all super methods (transitive) in classes and interfaces that are overridden by the current method.\n+GrowableArray<Method*>* CompiledEntrySignature::get_supers() {\n+  if (_supers != nullptr) {\n+    return _supers;\n+  }\n+  _supers = new GrowableArray<Method*>();\n+  \/\/ Skip private, static, and <init> methods\n+  if (_method->is_private() || _method->is_static() || _method->is_object_constructor()) {\n+    return _supers;\n+  }\n+  Symbol* name = _method->name();\n+  Symbol* signature = _method->signature();\n+  const Klass* holder = _method->method_holder()->super();\n+  Symbol* holder_name = holder->name();\n+  ThreadInVMfromUnknown tiv;\n+  JavaThread* current = JavaThread::current();\n+  HandleMark hm(current);\n+  Handle loader(current, _method->method_holder()->class_loader());\n+\n+  \/\/ Walk up the class hierarchy and search for super methods\n+  while (holder != nullptr) {\n+    Method* super_method = holder->lookup_method(name, signature);\n+    if (super_method == nullptr) {\n+      break;\n+    }\n+    if (!super_method->is_static() && !super_method->is_private() &&\n+        (!super_method->is_package_private() ||\n+         super_method->method_holder()->is_same_class_package(loader(), holder_name))) {\n+      _supers->push(super_method);\n+    }\n+    holder = super_method->method_holder()->super();\n+  }\n+  \/\/ Search interfaces for super methods\n+  Array<InstanceKlass*>* interfaces = _method->method_holder()->transitive_interfaces();\n+  for (int i = 0; i < interfaces->length(); ++i) {\n+    Method* m = interfaces->at(i)->lookup_method(name, signature);\n+    if (m != nullptr && !m->is_static() && m->is_public()) {\n+      _supers->push(m);\n+    }\n@@ -2686,0 +2847,50 @@\n+  return _supers;\n+}\n+\n+\/\/ Iterate over arguments and compute scalarized and non-scalarized signatures\n+void CompiledEntrySignature::compute_calling_conventions(bool init) {\n+  bool has_scalarized = false;\n+  if (_method != nullptr) {\n+    InstanceKlass* holder = _method->method_holder();\n+    int arg_num = 0;\n+    if (!_method->is_static()) {\n+      \/\/ We shouldn't scalarize 'this' in a value class constructor\n+      if (holder->is_inline_klass() && InlineKlass::cast(holder)->can_be_passed_as_fields() && !_method->is_object_constructor() &&\n+          (init || _method->is_scalarized_arg(arg_num))) {\n+        _sig_cc->appendAll(InlineKlass::cast(holder)->extended_sig());\n+        has_scalarized = true;\n+        _has_inline_recv = true;\n+        _num_inline_args++;\n+      } else {\n+        SigEntry::add_entry(_sig_cc, T_OBJECT, holder->name());\n+      }\n+      SigEntry::add_entry(_sig, T_OBJECT, holder->name());\n+      SigEntry::add_entry(_sig_cc_ro, T_OBJECT, holder->name());\n+      arg_num++;\n+    }\n+    for (SignatureStream ss(_method->signature()); !ss.at_return_type(); ss.next()) {\n+      BasicType bt = ss.type();\n+      if (bt == T_OBJECT) {\n+        InlineKlass* vk = ss.as_inline_klass(holder);\n+        if (vk != nullptr && vk->can_be_passed_as_fields() && (init || _method->is_scalarized_arg(arg_num))) {\n+          \/\/ Check for a calling convention mismatch with super method(s)\n+          bool scalar_super = false;\n+          bool non_scalar_super = false;\n+          GrowableArray<Method*>* supers = get_supers();\n+          for (int i = 0; i < supers->length(); ++i) {\n+            Method* super_method = supers->at(i);\n+            if (super_method->is_scalarized_arg(arg_num)) {\n+              scalar_super = true;\n+            } else {\n+              non_scalar_super = true;\n+            }\n+          }\n+#ifdef ASSERT\n+          \/\/ Randomly enable below code paths for stress testing\n+          bool stress = init && StressCallingConvention;\n+          if (stress && (os::random() & 1) == 1) {\n+            non_scalar_super = true;\n+            if ((os::random() & 1) == 1) {\n+              scalar_super = true;\n+            }\n+          }\n@@ -2687,0 +2898,50 @@\n+          if (non_scalar_super) {\n+            \/\/ Found a super method with a non-scalarized argument. Fall back to the non-scalarized calling convention.\n+            if (scalar_super) {\n+              \/\/ Found non-scalar *and* scalar super methods. We can't handle both.\n+              \/\/ Mark the scalar method as mismatch and re-compile call sites to use non-scalarized calling convention.\n+              for (int i = 0; i < supers->length(); ++i) {\n+                Method* super_method = supers->at(i);\n+                if (super_method->is_scalarized_arg(arg_num) DEBUG_ONLY(|| (stress && (os::random() & 1) == 1))) {\n+                  super_method->set_mismatch();\n+                  MutexLocker ml(Compile_lock, Mutex::_safepoint_check_flag);\n+                  JavaThread* thread = JavaThread::current();\n+                  HandleMark hm(thread);\n+                  methodHandle mh(thread, super_method);\n+                  DeoptimizationScope deopt_scope;\n+                  CodeCache::mark_for_deoptimization(&deopt_scope, mh());\n+                  deopt_scope.deoptimize_marked();\n+                }\n+              }\n+            }\n+            \/\/ Fall back to non-scalarized calling convention\n+            SigEntry::add_entry(_sig_cc, T_OBJECT, ss.as_symbol());\n+            SigEntry::add_entry(_sig_cc_ro, T_OBJECT, ss.as_symbol());\n+          } else {\n+            _num_inline_args++;\n+            has_scalarized = true;\n+            int last = _sig_cc->length();\n+            int last_ro = _sig_cc_ro->length();\n+            _sig_cc->appendAll(vk->extended_sig());\n+            _sig_cc_ro->appendAll(vk->extended_sig());\n+            if (bt == T_OBJECT) {\n+              \/\/ Nullable inline type argument, insert InlineTypeNode::NullMarker field right after T_METADATA delimiter\n+              _sig_cc->insert_before(last+1, SigEntry(T_BOOLEAN, -1, nullptr, true));\n+              _sig_cc_ro->insert_before(last_ro+1, SigEntry(T_BOOLEAN, -1, nullptr, true));\n+            }\n+          }\n+        } else {\n+          SigEntry::add_entry(_sig_cc, T_OBJECT, ss.as_symbol());\n+          SigEntry::add_entry(_sig_cc_ro, T_OBJECT, ss.as_symbol());\n+        }\n+        bt = T_OBJECT;\n+      } else {\n+        SigEntry::add_entry(_sig_cc, ss.type(), ss.as_symbol());\n+        SigEntry::add_entry(_sig_cc_ro, ss.type(), ss.as_symbol());\n+      }\n+      SigEntry::add_entry(_sig, bt, ss.as_symbol());\n+      if (bt != T_VOID) {\n+        arg_num++;\n+      }\n+    }\n+  }\n@@ -2688,1 +2949,8 @@\n- private:\n+  \/\/ Compute the non-scalarized calling convention\n+  _regs = NEW_RESOURCE_ARRAY(VMRegPair, _sig->length());\n+  _args_on_stack = SharedRuntime::java_calling_convention(_sig, _regs);\n+\n+  \/\/ Compute the scalarized calling conventions if there are scalarized inline types in the signature\n+  if (has_scalarized && !_method->is_native()) {\n+    _regs_cc = NEW_RESOURCE_ARRAY(VMRegPair, _sig_cc->length());\n+    _args_on_stack_cc = SharedRuntime::java_calling_convention(_sig_cc, _regs_cc);\n@@ -2690,5 +2958,11 @@\n-  friend class SignatureIterator;  \/\/ so do_parameters_on can call do_type\n-  void do_type(BasicType type) {\n-    sig_bt[index++] = type;\n-    if (type == T_LONG || type == T_DOUBLE) {\n-      sig_bt[index++] = T_VOID; \/\/ Longs & doubles take 2 Java slots\n+    _regs_cc_ro = NEW_RESOURCE_ARRAY(VMRegPair, _sig_cc_ro->length());\n+    _args_on_stack_cc_ro = SharedRuntime::java_calling_convention(_sig_cc_ro, _regs_cc_ro);\n+\n+    _c1_needs_stack_repair = (_args_on_stack_cc < _args_on_stack) || (_args_on_stack_cc_ro < _args_on_stack);\n+    _c2_needs_stack_repair = (_args_on_stack_cc > _args_on_stack) || (_args_on_stack_cc > _args_on_stack_cc_ro);\n+\n+    \/\/ Upper bound on stack arguments to avoid hitting the argument limit and\n+    \/\/ bailing out of compilation (\"unsupported incoming calling sequence\").\n+    \/\/ TODO we need a reasonable limit (flag?) here\n+    if (MAX2(_args_on_stack_cc, _args_on_stack_cc_ro) <= 60) {\n+      return; \/\/ Success\n@@ -2697,1 +2971,132 @@\n-};\n+  \/\/ No scalarized args\n+  _sig_cc = _sig;\n+  _regs_cc = _regs;\n+  _args_on_stack_cc = _args_on_stack;\n+\n+  _sig_cc_ro = _sig;\n+  _regs_cc_ro = _regs;\n+  _args_on_stack_cc_ro = _args_on_stack;\n+}\n+\n+void CompiledEntrySignature::initialize_from_fingerprint(AdapterFingerPrint* fingerprint) {\n+  int value_object_count = 0;\n+  bool is_receiver = true;\n+  BasicType prev_bt = T_ILLEGAL;\n+  bool long_prev = false;\n+  bool has_scalarized_arguments = false;\n+\n+  fingerprint->iterate_args([&] (int arg) {\n+    BasicType bt = (BasicType)arg;\n+    if (long_prev) {\n+      long_prev = false;\n+      BasicType bt_to_add;\n+      if (bt == T_VOID) {\n+        bt_to_add = T_LONG;\n+      } else {\n+        bt_to_add = T_OBJECT; \/\/ it could be T_ARRAY; it shouldn't matter\n+      }\n+      SigEntry::add_entry(_sig_cc, bt_to_add);\n+      SigEntry::add_entry(_sig_cc_ro, bt_to_add);\n+      if (value_object_count == 0) {\n+        SigEntry::add_entry(_sig, bt_to_add);\n+      }\n+    }\n+    switch (bt) {\n+      case T_VOID:\n+        if (is_receiver) {\n+          \/\/ 'this' when ro adapter is available\n+          assert(InlineTypePassFieldsAsArgs, \"unexpected start of inline type\");\n+          value_object_count++;\n+          has_scalarized_arguments = true;\n+          _has_inline_recv = true;\n+          SigEntry::add_entry(_sig, T_OBJECT);\n+          SigEntry::add_entry(_sig_cc, T_METADATA);\n+          SigEntry::add_entry(_sig_cc_ro, T_METADATA);\n+        } else if (prev_bt != T_LONG && prev_bt != T_DOUBLE) {\n+          assert(InlineTypePassFieldsAsArgs, \"unexpected end of inline type\");\n+          value_object_count--;\n+          SigEntry::add_entry(_sig_cc, T_VOID);\n+          SigEntry::add_entry(_sig_cc_ro, T_VOID);\n+          assert(value_object_count >= 0, \"invalid value object count\");\n+        } else {\n+          \/\/ Nothing to add for _sig: We already added an addition T_VOID in add_entry() when adding T_LONG or T_DOUBLE.\n+        }\n+        break;\n+      case T_INT:\n+      case T_FLOAT:\n+      case T_DOUBLE:\n+        if (value_object_count == 0) {\n+          SigEntry::add_entry(_sig, bt);\n+        }\n+        SigEntry::add_entry(_sig_cc, bt);\n+        SigEntry::add_entry(_sig_cc_ro, bt);\n+        break;\n+      case T_LONG:\n+        long_prev = true;\n+        break;\n+      case T_BOOLEAN:\n+      case T_CHAR:\n+      case T_BYTE:\n+      case T_SHORT:\n+      case T_OBJECT:\n+      case T_ARRAY:\n+        assert(value_object_count > 0 && !is_receiver, \"must be value object field\");\n+        SigEntry::add_entry(_sig_cc, bt);\n+        SigEntry::add_entry(_sig_cc_ro, bt);\n+        break;\n+      case T_METADATA:\n+        assert(InlineTypePassFieldsAsArgs, \"unexpected start of inline type\");\n+        value_object_count++;\n+        has_scalarized_arguments = true;\n+        SigEntry::add_entry(_sig, T_OBJECT);\n+        SigEntry::add_entry(_sig_cc, T_METADATA);\n+        SigEntry::add_entry(_sig_cc_ro, T_METADATA);\n+        break;\n+      default: {\n+        fatal(\"Unexpected BasicType: %s\", basictype_to_str(bt));\n+      }\n+    }\n+    prev_bt = bt;\n+    is_receiver = false;\n+  });\n+\n+  if (long_prev) {\n+    \/\/ If previous bt was T_LONG and we reached the end of the signature, we know that it must be a T_OBJECT.\n+    SigEntry::add_entry(_sig, T_OBJECT);\n+    SigEntry::add_entry(_sig_cc, T_OBJECT);\n+    SigEntry::add_entry(_sig_cc_ro, T_OBJECT);\n+  }\n+  assert(value_object_count == 0, \"invalid value object count\");\n+\n+  _regs = NEW_RESOURCE_ARRAY(VMRegPair, _sig->length());\n+  _args_on_stack = SharedRuntime::java_calling_convention(_sig, _regs);\n+\n+  \/\/ Compute the scalarized calling conventions if there are scalarized inline types in the signature\n+  if (has_scalarized_arguments) {\n+    _regs_cc = NEW_RESOURCE_ARRAY(VMRegPair, _sig_cc->length());\n+    _args_on_stack_cc = SharedRuntime::java_calling_convention(_sig_cc, _regs_cc);\n+\n+    _regs_cc_ro = NEW_RESOURCE_ARRAY(VMRegPair, _sig_cc_ro->length());\n+    _args_on_stack_cc_ro = SharedRuntime::java_calling_convention(_sig_cc_ro, _regs_cc_ro);\n+\n+    _c1_needs_stack_repair = (_args_on_stack_cc < _args_on_stack) || (_args_on_stack_cc_ro < _args_on_stack);\n+    _c2_needs_stack_repair = (_args_on_stack_cc > _args_on_stack) || (_args_on_stack_cc > _args_on_stack_cc_ro);\n+  } else {\n+    \/\/ No scalarized args\n+    _sig_cc = _sig;\n+    _regs_cc = _regs;\n+    _args_on_stack_cc = _args_on_stack;\n+\n+    _sig_cc_ro = _sig;\n+    _regs_cc_ro = _regs;\n+    _args_on_stack_cc_ro = _args_on_stack;\n+  }\n+\n+#ifdef ASSERT\n+  {\n+    AdapterFingerPrint* compare_fp = AdapterFingerPrint::allocate(_sig_cc, _has_inline_recv);\n+    assert(fingerprint->equals(compare_fp), \"sanity check\");\n+    AdapterFingerPrint::deallocate(compare_fp);\n+  }\n+#endif\n+}\n@@ -2705,1 +3110,1 @@\n-void AdapterHandlerLibrary::verify_adapter_sharing(int total_args_passed, BasicType* sig_bt, AdapterHandlerEntry* cached_entry) {\n+void AdapterHandlerLibrary::verify_adapter_sharing(CompiledEntrySignature& ces, AdapterHandlerEntry* cached_entry) {\n@@ -2707,1 +3112,1 @@\n-  AdapterHandlerEntry* comparison_entry = create_adapter(comparison_blob, total_args_passed, sig_bt, true);\n+  AdapterHandlerEntry* comparison_entry = create_adapter(comparison_blob, ces, false, true);\n@@ -2730,2 +3135,15 @@\n-  \/\/ Fill in the signature array, for the calling-convention call.\n-  int total_args_passed = method->size_of_parameters(); \/\/ All args on stack\n+  CompiledEntrySignature ces(method());\n+  ces.compute_calling_conventions();\n+  if (ces.has_scalarized_args()) {\n+    if (!method->has_scalarized_args()) {\n+      method->set_has_scalarized_args();\n+    }\n+    if (ces.c1_needs_stack_repair()) {\n+      method->set_c1_needs_stack_repair();\n+    }\n+    if (ces.c2_needs_stack_repair() && !method->c2_needs_stack_repair()) {\n+      method->set_c2_needs_stack_repair();\n+    }\n+  } else if (method->is_abstract()) {\n+    return _abstract_method_handler;\n+  }\n@@ -2733,4 +3151,0 @@\n-  AdapterSignatureIterator si(method->signature(), method->constMethod()->fingerprint(),\n-                              method->is_static(), total_args_passed);\n-  assert(si.slots() == total_args_passed, \"\");\n-  BasicType* sig_bt = si.basic_types();\n@@ -2740,0 +3154,13 @@\n+    if (ces.has_scalarized_args() && method->is_abstract()) {\n+      \/\/ Save a C heap allocated version of the signature for abstract methods with scalarized inline type arguments\n+      address wrong_method_abstract = SharedRuntime::get_handle_wrong_method_abstract_stub();\n+      entry = AdapterHandlerLibrary::new_entry(AdapterFingerPrint::allocate(nullptr));\n+      entry->set_entry_points(SharedRuntime::throw_AbstractMethodError_entry(),\n+                              wrong_method_abstract, wrong_method_abstract, wrong_method_abstract,\n+                              wrong_method_abstract, wrong_method_abstract);\n+      GrowableArray<SigEntry>* heap_sig = new (mtInternal) GrowableArray<SigEntry>(ces.sig_cc_ro()->length(), mtInternal);\n+      heap_sig->appendAll(ces.sig_cc_ro());\n+      entry->set_sig_cc(heap_sig);\n+      return entry;\n+    }\n+\n@@ -2741,1 +3168,1 @@\n-    entry = lookup(total_args_passed, sig_bt);\n+    entry = lookup(ces.sig_cc(), ces.has_inline_recv());\n@@ -2747,1 +3174,1 @@\n-        verify_adapter_sharing(total_args_passed, sig_bt, entry);\n+        verify_adapter_sharing(ces, entry);\n@@ -2751,1 +3178,1 @@\n-      entry = create_adapter(adapter_blob, total_args_passed, sig_bt);\n+      entry = create_adapter(adapter_blob, ces, \/* allocate_code_blob *\/ true);\n@@ -2774,1 +3201,2 @@\n-    handler->set_entry_points(i2c_entry, i2c_entry + offsets[1], i2c_entry + offsets[2], i2c_entry + offsets[3]);\n+    handler->set_entry_points(i2c_entry, i2c_entry + offsets[1], i2c_entry + offsets[2], i2c_entry + offsets[3],\n+                              i2c_entry + offsets[4], i2c_entry + offsets[5], i2c_entry + offsets[6]);\n@@ -2801,2 +3229,2 @@\n-                                                  int total_args_passed,\n-                                                  BasicType* sig_bt,\n+                                                  CompiledEntrySignature& ces,\n+                                                  bool allocate_code_blob,\n@@ -2814,2 +3242,0 @@\n-  VMRegPair stack_regs[16];\n-  VMRegPair* regs = (total_args_passed <= 16) ? stack_regs : NEW_RESOURCE_ARRAY(VMRegPair, total_args_passed);\n@@ -2818,6 +3244,17 @@\n-  int comp_args_on_stack = SharedRuntime::java_calling_convention(sig_bt, regs, total_args_passed);\n-                                         total_args_passed,\n-                                         comp_args_on_stack,\n-                                         sig_bt,\n-                                         regs,\n-                                         handler);\n+                                         ces.args_on_stack(),\n+                                         ces.sig(),\n+                                         ces.regs(),\n+                                         ces.sig_cc(),\n+                                         ces.regs_cc(),\n+                                         ces.sig_cc_ro(),\n+                                         ces.regs_cc_ro(),\n+                                         handler,\n+                                         adapter_blob,\n+                                         allocate_code_blob);\n+\n+  if (ces.has_scalarized_args()) {\n+    \/\/ Save a C heap allocated version of the scalarized signature and store it in the adapter\n+    GrowableArray<SigEntry>* heap_sig = new (mtInternal) GrowableArray<SigEntry>(ces.sig_cc()->length(), mtInternal);\n+    heap_sig->appendAll(ces.sig_cc());\n+    handler->set_sig_cc(heap_sig);\n+  }\n@@ -2834,1 +3271,0 @@\n-  adapter_blob = AdapterBlob::create(&buffer);\n@@ -2846,1 +3282,1 @@\n-    assert(AdapterHandlerEntry::ENTRIES_COUNT == 4, \"sanity\");\n+    assert(AdapterHandlerEntry::ENTRIES_COUNT == 7, \"sanity\");\n@@ -2850,2 +3286,5 @@\n-    entry_offset[2] = handler->get_c2i_unverified_entry() - i2c_entry;\n-    entry_offset[3] = handler->get_c2i_no_clinit_check_entry() - i2c_entry;\n+    entry_offset[2] = handler->get_c2i_inline_entry() - i2c_entry;\n+    entry_offset[3] = handler->get_c2i_inline_ro_entry() - i2c_entry;\n+    entry_offset[4] = handler->get_c2i_unverified_entry() - i2c_entry;\n+    entry_offset[5] = handler->get_c2i_unverified_inline_entry() - i2c_entry;\n+    entry_offset[6] = handler->get_c2i_no_clinit_check_entry() - i2c_entry;\n@@ -2866,2 +3305,2 @@\n-                                                           int total_args_passed,\n-                                                           BasicType* sig_bt,\n+                                                           CompiledEntrySignature& ces,\n+                                                           bool allocate_code_blob,\n@@ -2869,1 +3308,6 @@\n-  AdapterFingerPrint* fp = AdapterFingerPrint::allocate(total_args_passed, sig_bt);\n+  AdapterFingerPrint* fp = AdapterFingerPrint::allocate(ces.sig_cc(), ces.has_inline_recv());\n+#ifdef ASSERT\n+  \/\/ Verify that we can successfully restore the compiled entry signature object.\n+  CompiledEntrySignature ces_verify;\n+  ces_verify.initialize_from_fingerprint(fp);\n+#endif\n@@ -2871,1 +3315,1 @@\n-  if (!generate_adapter_code(adapter_blob, handler, total_args_passed, sig_bt, is_transient)) {\n+  if (!generate_adapter_code(adapter_blob, handler, ces, allocate_code_blob, is_transient)) {\n@@ -2888,1 +3332,1 @@\n-  set_entry_points(nullptr, nullptr, nullptr, nullptr, false);\n+  set_entry_points(nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, false);\n@@ -2974,3 +3418,3 @@\n-    int nargs;\n-    BasicType* bt = _fingerprint->as_basic_type(nargs);\n-    if (!AdapterHandlerLibrary::generate_adapter_code(adapter_blob, this, nargs, bt, \/* is_transient *\/ false)) {\n+    CompiledEntrySignature ces;\n+    ces.initialize_from_fingerprint(_fingerprint);\n+    if (!AdapterHandlerLibrary::generate_adapter_code(adapter_blob, this, ces, true, false)) {\n@@ -3003,13 +3447,26 @@\n-  _no_arg_handler = lookup(0, nullptr);\n-\n-  BasicType obj_args[] = { T_OBJECT };\n-  _obj_arg_handler = lookup(1, obj_args);\n-\n-  BasicType int_args[] = { T_INT };\n-  _int_arg_handler = lookup(1, int_args);\n-\n-  BasicType obj_int_args[] = { T_OBJECT, T_INT };\n-  _obj_int_arg_handler = lookup(2, obj_int_args);\n-\n-  BasicType obj_obj_args[] = { T_OBJECT, T_OBJECT };\n-  _obj_obj_arg_handler = lookup(2, obj_obj_args);\n+  ResourceMark rm;\n+  CompiledEntrySignature no_args;\n+  no_args.compute_calling_conventions();\n+  _no_arg_handler = lookup(no_args.sig_cc(), no_args.has_inline_recv());\n+\n+  CompiledEntrySignature obj_args;\n+  SigEntry::add_entry(obj_args.sig(), T_OBJECT);\n+  obj_args.compute_calling_conventions();\n+  _obj_arg_handler = lookup(obj_args.sig_cc(), obj_args.has_inline_recv());\n+\n+  CompiledEntrySignature int_args;\n+  SigEntry::add_entry(int_args.sig(), T_INT);\n+  int_args.compute_calling_conventions();\n+  _int_arg_handler = lookup(int_args.sig_cc(), int_args.has_inline_recv());\n+\n+  CompiledEntrySignature obj_int_args;\n+  SigEntry::add_entry(obj_int_args.sig(), T_OBJECT);\n+  SigEntry::add_entry(obj_int_args.sig(), T_INT);\n+  obj_int_args.compute_calling_conventions();\n+  _obj_int_arg_handler = lookup(obj_int_args.sig_cc(), obj_int_args.has_inline_recv());\n+\n+  CompiledEntrySignature obj_obj_args;\n+  SigEntry::add_entry(obj_obj_args.sig(), T_OBJECT);\n+  SigEntry::add_entry(obj_obj_args.sig(), T_OBJECT);\n+  obj_obj_args.compute_calling_conventions();\n+  _obj_obj_arg_handler = lookup(obj_obj_args.sig_cc(), obj_obj_args.has_inline_recv());\n@@ -3034,0 +3491,2 @@\n+  assert(base <= _c2i_inline_entry || _c2i_inline_entry == nullptr, \"\");\n+  assert(base <= _c2i_inline_ro_entry || _c2i_inline_ro_entry == nullptr, \"\");\n@@ -3035,0 +3494,1 @@\n+  assert(base <= _c2i_unverified_inline_entry || _c2i_unverified_inline_entry == nullptr, \"\");\n@@ -3047,0 +3507,4 @@\n+  if (_c2i_inline_entry != nullptr)\n+    _c2i_inline_entry += delta;\n+  if (_c2i_inline_ro_entry != nullptr)\n+    _c2i_inline_ro_entry += delta;\n@@ -3049,0 +3513,2 @@\n+  if (_c2i_unverified_inline_entry != nullptr)\n+    _c2i_unverified_inline_entry += delta;\n@@ -3068,0 +3534,3 @@\n+  if (_sig_cc != nullptr) {\n+    delete _sig_cc;\n+  }\n@@ -3155,0 +3624,1 @@\n+      BasicType stack_sig_bt[16];\n@@ -3156,0 +3626,1 @@\n+      BasicType* sig_bt = (total_args_passed <= 16) ? stack_sig_bt : NEW_RESOURCE_ARRAY(BasicType, total_args_passed);\n@@ -3158,5 +3629,13 @@\n-      AdapterSignatureIterator si(method->signature(), method->constMethod()->fingerprint(),\n-                              method->is_static(), total_args_passed);\n-      BasicType* sig_bt = si.basic_types();\n-      assert(si.slots() == total_args_passed, \"\");\n-      BasicType ret_type = si.return_type();\n+      int i = 0;\n+      if (!method->is_static()) {  \/\/ Pass in receiver first\n+        sig_bt[i++] = T_OBJECT;\n+      }\n+      SignatureStream ss(method->signature());\n+      for (; !ss.at_return_type(); ss.next()) {\n+        sig_bt[i++] = ss.type();  \/\/ Collect remaining bits of signature\n+        if (ss.type() == T_LONG || ss.type() == T_DOUBLE) {\n+          sig_bt[i++] = T_VOID;   \/\/ Longs & doubles take 2 Java slots\n+        }\n+      }\n+      assert(i == total_args_passed, \"\");\n+      BasicType ret_type = ss.type();\n@@ -3442,0 +3921,6 @@\n+  if (get_c2i_entry() != nullptr) {\n+    st->print(\" c2iVE: \" INTPTR_FORMAT, p2i(get_c2i_inline_entry()));\n+  }\n+  if (get_c2i_entry() != nullptr) {\n+    st->print(\" c2iVROE: \" INTPTR_FORMAT, p2i(get_c2i_inline_ro_entry()));\n+  }\n@@ -3443,1 +3928,4 @@\n-    st->print(\" c2iUV: \" INTPTR_FORMAT, p2i(get_c2i_unverified_entry()));\n+    st->print(\" c2iUE: \" INTPTR_FORMAT, p2i(get_c2i_unverified_entry()));\n+  }\n+  if (get_c2i_unverified_entry() != nullptr) {\n+    st->print(\" c2iUVE: \" INTPTR_FORMAT, p2i(get_c2i_unverified_inline_entry()));\n@@ -3539,0 +4027,195 @@\n+\n+\/\/ We are at a compiled code to interpreter call. We need backing\n+\/\/ buffers for all inline type arguments. Allocate an object array to\n+\/\/ hold them (convenient because once we're done with it we don't have\n+\/\/ to worry about freeing it).\n+oop SharedRuntime::allocate_inline_types_impl(JavaThread* current, methodHandle callee, bool allocate_receiver, TRAPS) {\n+  assert(InlineTypePassFieldsAsArgs, \"no reason to call this\");\n+  ResourceMark rm;\n+\n+  int nb_slots = 0;\n+  InstanceKlass* holder = callee->method_holder();\n+  allocate_receiver &= !callee->is_static() && holder->is_inline_klass() && callee->is_scalarized_arg(0);\n+  if (allocate_receiver) {\n+    nb_slots++;\n+  }\n+  int arg_num = callee->is_static() ? 0 : 1;\n+  for (SignatureStream ss(callee->signature()); !ss.at_return_type(); ss.next()) {\n+    BasicType bt = ss.type();\n+    if (bt == T_OBJECT && callee->is_scalarized_arg(arg_num)) {\n+      nb_slots++;\n+    }\n+    if (bt != T_VOID) {\n+      arg_num++;\n+    }\n+  }\n+  objArrayOop array_oop = oopFactory::new_objectArray(nb_slots, CHECK_NULL);\n+  objArrayHandle array(THREAD, array_oop);\n+  arg_num = callee->is_static() ? 0 : 1;\n+  int i = 0;\n+  if (allocate_receiver) {\n+    InlineKlass* vk = InlineKlass::cast(holder);\n+    oop res = vk->allocate_instance(CHECK_NULL);\n+    array->obj_at_put(i++, res);\n+  }\n+  for (SignatureStream ss(callee->signature()); !ss.at_return_type(); ss.next()) {\n+    BasicType bt = ss.type();\n+    if (bt == T_OBJECT && callee->is_scalarized_arg(arg_num)) {\n+      InlineKlass* vk = ss.as_inline_klass(holder);\n+      assert(vk != nullptr, \"Unexpected klass\");\n+      oop res = vk->allocate_instance(CHECK_NULL);\n+      array->obj_at_put(i++, res);\n+    }\n+    if (bt != T_VOID) {\n+      arg_num++;\n+    }\n+  }\n+  return array();\n+}\n+\n+JRT_ENTRY(void, SharedRuntime::allocate_inline_types(JavaThread* current, Method* callee_method, bool allocate_receiver))\n+  methodHandle callee(current, callee_method);\n+  oop array = SharedRuntime::allocate_inline_types_impl(current, callee, allocate_receiver, CHECK);\n+  current->set_vm_result_oop(array);\n+  current->set_vm_result_metadata(callee()); \/\/ TODO: required to keep callee live?\n+JRT_END\n+\n+\/\/ We're returning from an interpreted method: load each field into a\n+\/\/ register following the calling convention\n+JRT_LEAF(void, SharedRuntime::load_inline_type_fields_in_regs(JavaThread* current, oopDesc* res))\n+{\n+  assert(res->klass()->is_inline_klass(), \"only inline types here\");\n+  ResourceMark rm;\n+  RegisterMap reg_map(current,\n+                      RegisterMap::UpdateMap::include,\n+                      RegisterMap::ProcessFrames::include,\n+                      RegisterMap::WalkContinuation::skip);\n+  frame stubFrame = current->last_frame();\n+  frame callerFrame = stubFrame.sender(&reg_map);\n+  assert(callerFrame.is_interpreted_frame(), \"should be coming from interpreter\");\n+\n+  InlineKlass* vk = InlineKlass::cast(res->klass());\n+\n+  const Array<SigEntry>* sig_vk = vk->extended_sig();\n+  const Array<VMRegPair>* regs = vk->return_regs();\n+\n+  if (regs == nullptr) {\n+    \/\/ The fields of the inline klass don't fit in registers, bail out\n+    return;\n+  }\n+\n+  int j = 1;\n+  for (int i = 0; i < sig_vk->length(); i++) {\n+    BasicType bt = sig_vk->at(i)._bt;\n+    if (bt == T_METADATA) {\n+      continue;\n+    }\n+    if (bt == T_VOID) {\n+      if (sig_vk->at(i-1)._bt == T_LONG ||\n+          sig_vk->at(i-1)._bt == T_DOUBLE) {\n+        j++;\n+      }\n+      continue;\n+    }\n+    int off = sig_vk->at(i)._offset;\n+    assert(off > 0, \"offset in object should be positive\");\n+    VMRegPair pair = regs->at(j);\n+    address loc = reg_map.location(pair.first(), nullptr);\n+    switch(bt) {\n+    case T_BOOLEAN:\n+      *(jboolean*)loc = res->bool_field(off);\n+      break;\n+    case T_CHAR:\n+      *(jchar*)loc = res->char_field(off);\n+      break;\n+    case T_BYTE:\n+      *(jbyte*)loc = res->byte_field(off);\n+      break;\n+    case T_SHORT:\n+      *(jshort*)loc = res->short_field(off);\n+      break;\n+    case T_INT: {\n+      *(jint*)loc = res->int_field(off);\n+      break;\n+    }\n+    case T_LONG:\n+#ifdef _LP64\n+      *(intptr_t*)loc = res->long_field(off);\n+#else\n+      Unimplemented();\n+#endif\n+      break;\n+    case T_OBJECT:\n+    case T_ARRAY: {\n+      *(oop*)loc = res->obj_field(off);\n+      break;\n+    }\n+    case T_FLOAT:\n+      *(jfloat*)loc = res->float_field(off);\n+      break;\n+    case T_DOUBLE:\n+      *(jdouble*)loc = res->double_field(off);\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n+    j++;\n+  }\n+  assert(j == regs->length(), \"missed a field?\");\n+\n+#ifdef ASSERT\n+  VMRegPair pair = regs->at(0);\n+  address loc = reg_map.location(pair.first(), nullptr);\n+  assert(*(oopDesc**)loc == res, \"overwritten object\");\n+#endif\n+\n+  current->set_vm_result_oop(res);\n+}\n+JRT_END\n+\n+\/\/ We've returned to an interpreted method, the interpreter needs a\n+\/\/ reference to an inline type instance. Allocate it and initialize it\n+\/\/ from field's values in registers.\n+JRT_BLOCK_ENTRY(void, SharedRuntime::store_inline_type_fields_to_buf(JavaThread* current, intptr_t res))\n+{\n+  ResourceMark rm;\n+  RegisterMap reg_map(current,\n+                      RegisterMap::UpdateMap::include,\n+                      RegisterMap::ProcessFrames::include,\n+                      RegisterMap::WalkContinuation::skip);\n+  frame stubFrame = current->last_frame();\n+  frame callerFrame = stubFrame.sender(&reg_map);\n+\n+#ifdef ASSERT\n+  InlineKlass* verif_vk = InlineKlass::returned_inline_klass(reg_map);\n+#endif\n+\n+  if (!is_set_nth_bit(res, 0)) {\n+    \/\/ We're not returning with inline type fields in registers (the\n+    \/\/ calling convention didn't allow it for this inline klass)\n+    assert(!Metaspace::contains((void*)res), \"should be oop or pointer in buffer area\");\n+    current->set_vm_result_oop((oopDesc*)res);\n+    assert(verif_vk == nullptr, \"broken calling convention\");\n+    return;\n+  }\n+\n+  clear_nth_bit(res, 0);\n+  InlineKlass* vk = (InlineKlass*)res;\n+  assert(verif_vk == vk, \"broken calling convention\");\n+  assert(Metaspace::contains((void*)res), \"should be klass\");\n+\n+  \/\/ Allocate handles for every oop field so they are safe in case of\n+  \/\/ a safepoint when allocating\n+  GrowableArray<Handle> handles;\n+  vk->save_oop_fields(reg_map, handles);\n+\n+  \/\/ It's unsafe to safepoint until we are here\n+  JRT_BLOCK;\n+  {\n+    JavaThread* THREAD = current;\n+    oop vt = vk->realloc_result(reg_map, handles, CHECK);\n+    current->set_vm_result_oop(vt);\n+  }\n+  JRT_BLOCK_END;\n+}\n+JRT_END\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":896,"deletions":213,"binary":false,"changes":1109,"status":"modified"},{"patch":"@@ -44,0 +44,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/flatArrayOop.inline.hpp\"\n@@ -48,0 +50,1 @@\n+#include \"runtime\/fieldDescriptor.inline.hpp\"\n@@ -319,0 +322,22 @@\n+ * HPROF_FLAT_ARRAYS        list of flat arrays\n+ *\n+ *               [flat array sub-records]*\n+ *\n+ *               HPROF_FLAT_ARRAY      flat array\n+ *\n+ *                          id         array object ID (dumped as HPROF_GC_PRIM_ARRAY_DUMP)\n+ *                          id         element class ID (dumped by HPROF_GC_CLASS_DUMP)\n+ *\n+ * HPROF_INLINED_FIELDS     decribes inlined fields\n+ *\n+ *               [class with inlined fields sub-records]*\n+ *\n+ *               HPROF_CLASS_WITH_INLINED_FIELDS\n+ *\n+ *                          id         class ID (dumped as HPROF_GC_CLASS_DUMP)\n+ *\n+ *                          u2         number of instance inlined fields (not including super)\n+ *                          [u2,       inlined field index,\n+ *                           u2,       synthetic field count,\n+ *                           id,       original field name,\n+ *                           id]*      inlined field class ID (dumped by HPROF_GC_CLASS_DUMP)\n@@ -356,0 +381,7 @@\n+  \/\/ inlined object support\n+  HPROF_FLAT_ARRAYS             = 0x12,\n+  HPROF_INLINED_FIELDS          = 0x13,\n+  \/\/ inlined object subrecords\n+  HPROF_FLAT_ARRAY                  = 0x01,\n+  HPROF_CLASS_WITH_INLINED_FIELDS   = 0x01,\n+\n@@ -390,0 +422,65 @@\n+\n+class AbstractDumpWriter;\n+\n+class InlinedObjects {\n+\n+  struct ClassInlinedFields {\n+    const Klass *klass;\n+    uintx base_index;   \/\/ base index of the inlined field names (1st field has index base_index+1).\n+    ClassInlinedFields(const Klass *klass = nullptr, uintx base_index = 0) : klass(klass), base_index(base_index) {}\n+\n+    \/\/ For GrowableArray::find_sorted().\n+    static int compare(const ClassInlinedFields& a, const ClassInlinedFields& b) {\n+      return a.klass - b.klass;\n+    }\n+    \/\/ For GrowableArray::sort().\n+    static int compare(ClassInlinedFields* a, ClassInlinedFields* b) {\n+      return compare(*a, *b);\n+    }\n+  };\n+\n+  uintx _min_string_id;\n+  uintx _max_string_id;\n+\n+  GrowableArray<ClassInlinedFields> *_inlined_field_map;\n+\n+  \/\/ counters for classes with inlined fields and for the fields\n+  int _classes_count;\n+  int _inlined_fields_count;\n+\n+  static InlinedObjects *_instance;\n+\n+  static void inlined_field_names_callback(InlinedObjects* _this, const Klass *klass, uintx base_index, int count);\n+\n+  GrowableArray<oop> *_flat_arrays;\n+\n+public:\n+  InlinedObjects()\n+    : _min_string_id(0), _max_string_id(0),\n+    _inlined_field_map(nullptr),\n+    _classes_count(0), _inlined_fields_count(0),\n+    _flat_arrays(nullptr) {\n+  }\n+\n+  static InlinedObjects* get_instance() {\n+    return _instance;\n+  }\n+\n+  void init();\n+  void release();\n+\n+  void dump_inlined_field_names(AbstractDumpWriter *writer);\n+\n+  uintx get_base_index_for(Klass* k);\n+  uintx get_next_string_id(uintx id);\n+\n+  void dump_classed_with_inlined_fields(AbstractDumpWriter* writer);\n+\n+  void add_flat_array(oop array);\n+  void dump_flat_arrays(AbstractDumpWriter* writer);\n+\n+};\n+\n+InlinedObjects *InlinedObjects::_instance = nullptr;\n+\n+\n@@ -746,1 +843,1 @@\n-  \/\/ returns the size of the instance of the given class\n+  \/\/ calculates the total size of the all fields of the given class.\n@@ -759,2 +856,8 @@\n-  \/\/ dump the raw values of the instance fields of the given object\n-  static void dump_instance_fields(AbstractDumpWriter* writer, oop o, DumperClassCacheTableEntry* class_cache_entry);\n+  \/\/ dump the raw values of the instance fields of the given identity or inlined object;\n+  \/\/ for identity objects offset is 0 and 'klass' is o->klass(),\n+  \/\/ for inlined objects offset is the offset in the holder object, 'klass' is inlined object class\n+  static void dump_instance_fields(AbstractDumpWriter* writer, oop o, int offset, DumperClassCacheTable* class_cache, DumperClassCacheTableEntry* class_cache_entry);\n+  \/\/ dump the raw values of the instance fields of the given inlined object;\n+  \/\/ dump_instance_fields wrapper for inlined objects\n+  static void dump_inlined_object_fields(AbstractDumpWriter* writer, oop o, int offset, DumperClassCacheTable* class_cache, DumperClassCacheTableEntry* class_cache_entry);\n+\n@@ -764,1 +867,1 @@\n-  static void dump_instance_field_descriptors(AbstractDumpWriter* writer, Klass* k);\n+  static void dump_instance_field_descriptors(AbstractDumpWriter* writer, InstanceKlass* k, uintx *inlined_fields_index = nullptr);\n@@ -774,0 +877,2 @@\n+  \/\/ creates HPROF_GC_PRIM_ARRAY_DUMP record for the given flat array\n+  static void dump_flat_array(AbstractDumpWriter* writer, flatArrayOop array, DumperClassCacheTable* class_cache);\n@@ -781,0 +886,3 @@\n+  \/\/ extended version to dump flat arrays as primitive arrays;\n+  \/\/ type_size specifies size of the inlined objects.\n+  static int calculate_array_max_length(AbstractDumpWriter* writer, arrayOop array, int type_size, short header_size);\n@@ -796,0 +904,10 @@\n+  \/\/ helper methods for inlined fields.\n+  static bool is_inlined_field(const fieldDescriptor& fld) {\n+    return fld.is_flat();\n+  }\n+  static InlineKlass* get_inlined_field_klass(const fieldDescriptor& fld) {\n+    assert(is_inlined_field(fld), \"must be inlined field\");\n+    InstanceKlass* holder_klass = fld.field_holder();\n+    return InlineKlass::cast(holder_klass->get_inline_type_field_klass(fld.index()));\n+  }\n+\n@@ -820,0 +938,1 @@\n+  GrowableArray<InlineKlass*> _inline_klasses;\n@@ -828,0 +947,3 @@\n+  void push_sig_start_inlined() { _sigs_start.push('Q'); }\n+  bool is_inlined(int field_idx){ return _sigs_start.at(field_idx) == 'Q'; }\n+  InlineKlass* inline_klass(int field_idx) { assert(is_inlined(field_idx), \"Not inlined\"); return _inline_klasses.at(field_idx); }\n@@ -876,2 +998,11 @@\n-          Symbol* sig = fld.signature();\n-          entry->_sigs_start.push(sig->char_at(0));\n+          InlineKlass* inlineKlass = nullptr;\n+          if (DumperSupport::is_inlined_field(fld.field_descriptor())) {\n+            inlineKlass = DumperSupport::get_inlined_field_klass(fld.field_descriptor());\n+            entry->push_sig_start_inlined();\n+            entry->_instance_size += DumperSupport::instance_size(inlineKlass);\n+          } else {\n+            Symbol* sig = fld.signature();\n+            entry->_sigs_start.push(sig->char_at(0));\n+            entry->_instance_size += DumperSupport::sig2size(sig);\n+          }\n+          entry->_inline_klasses.push(inlineKlass);\n@@ -880,1 +1011,0 @@\n-          entry->_instance_size += DumperSupport::sig2size(sig);\n@@ -990,0 +1120,1 @@\n+\n@@ -1048,1 +1179,1 @@\n-\/\/ returns the size of the instance of the given class\n+\/\/ calculates the total size of the all fields of the given class.\n@@ -1056,1 +1187,5 @@\n-        size += sig2size(fld.signature());\n+        if (is_inlined_field(fld.field_descriptor())) {\n+          size += instance_size(get_inlined_field_klass(fld.field_descriptor()));\n+        } else {\n+          size += sig2size(fld.signature());\n+        }\n@@ -1069,0 +1204,2 @@\n+      assert(!is_inlined_field(fldc.field_descriptor()), \"static fields cannot be inlined\");\n+\n@@ -1111,0 +1248,2 @@\n+      assert(!is_inlined_field(fld.field_descriptor()), \"static fields cannot be inlined\");\n+\n@@ -1147,2 +1286,4 @@\n-\/\/ dump the raw values of the instance fields of the given object\n-void DumperSupport::dump_instance_fields(AbstractDumpWriter* writer, oop o, DumperClassCacheTableEntry* class_cache_entry) {\n+\/\/ dump the raw values of the instance fields of the given identity or inlined object;\n+\/\/ for identity objects offset is 0 and 'klass' is o->klass(),\n+\/\/ for inlined objects offset is the offset in the holder object, 'klass' is inlined object class.\n+void DumperSupport::dump_instance_fields(AbstractDumpWriter* writer, oop o, int offset, DumperClassCacheTable* class_cache, DumperClassCacheTableEntry* class_cache_entry) {\n@@ -1151,1 +1292,8 @@\n-    dump_field_value(writer, class_cache_entry->sig_start(idx), o, class_cache_entry->offset(idx));\n+    if (class_cache_entry->is_inlined(idx)) {\n+      InlineKlass* field_klass = class_cache_entry->inline_klass(idx);\n+      int fields_offset = offset + (class_cache_entry->offset(idx) - field_klass->payload_offset());\n+      DumperClassCacheTableEntry* inline_class_cache_entry = class_cache->lookup_or_create(field_klass);\n+      dump_inlined_object_fields(writer, o, fields_offset, class_cache, inline_class_cache_entry);\n+    } else {\n+      dump_field_value(writer, class_cache_entry->sig_start(idx), o, class_cache_entry->offset(idx));\n+    }\n@@ -1155,1 +1303,6 @@\n-\/\/ dumps the definition of the instance fields for a given class\n+void DumperSupport::dump_inlined_object_fields(AbstractDumpWriter* writer, oop o, int offset, DumperClassCacheTable* class_cache, DumperClassCacheTableEntry* class_cache_entry) {\n+  \/\/ the object is inlined, so all its fields are stored without headers.\n+  dump_instance_fields(writer, o, offset, class_cache, class_cache_entry);\n+}\n+\n+\/\/ gets the count of the instance fields for a given class\n@@ -1160,1 +1313,8 @@\n-    if (!fldc.access_flags().is_static()) field_count++;\n+    if (!fldc.access_flags().is_static()) {\n+      if (is_inlined_field(fldc.field_descriptor())) {\n+        \/\/ add \"synthetic\" fields for inlined fields.\n+        field_count += get_instance_fields_count(get_inlined_field_klass(fldc.field_descriptor()));\n+      } else {\n+        field_count++;\n+      }\n+    }\n@@ -1167,2 +1327,8 @@\n-void DumperSupport::dump_instance_field_descriptors(AbstractDumpWriter* writer, Klass* k) {\n-  InstanceKlass* ik = InstanceKlass::cast(k);\n+\/\/ inlined_fields_id is not-nullptr for inlined fields (to get synthetic field name IDs\n+\/\/ by using InlinedObjects::get_next_string_id()).\n+void DumperSupport::dump_instance_field_descriptors(AbstractDumpWriter* writer, InstanceKlass* ik, uintx* inlined_fields_id) {\n+  \/\/ inlined_fields_id != nullptr means ik is a class of inlined field.\n+  \/\/ Inlined field id pointer for this class; lazyly initialized\n+  \/\/ if the class has inlined field(s) and the caller didn't provide inlined_fields_id.\n+  uintx *this_klass_inlined_fields_id = inlined_fields_id;\n+  uintx inlined_id = 0;\n@@ -1173,1 +1339,23 @@\n-      Symbol* sig = fld.signature();\n+      if (is_inlined_field(fld.field_descriptor())) {\n+        \/\/ dump \"synthetic\" fields for inlined fields.\n+        if (this_klass_inlined_fields_id == nullptr) {\n+          inlined_id = InlinedObjects::get_instance()->get_base_index_for(ik);\n+          this_klass_inlined_fields_id = &inlined_id;\n+        }\n+        dump_instance_field_descriptors(writer, get_inlined_field_klass(fld.field_descriptor()), this_klass_inlined_fields_id);\n+      } else {\n+        Symbol* sig = fld.signature();\n+        Symbol* name = nullptr;\n+        \/\/ Use inlined_fields_id provided by caller.\n+        if (inlined_fields_id != nullptr) {\n+          uintx name_id = InlinedObjects::get_instance()->get_next_string_id(*inlined_fields_id);\n+\n+          \/\/ name_id == 0 is returned on error. use original field signature.\n+          if (name_id != 0) {\n+            *inlined_fields_id = name_id;\n+            name = reinterpret_cast<Symbol*>(name_id);\n+          }\n+        }\n+        if (name == nullptr) {\n+          name = fld.name();\n+        }\n@@ -1175,2 +1363,3 @@\n-      writer->write_symbolID(fld.name());   \/\/ name\n-      writer->write_u1(sig2tag(sig));       \/\/ type\n+        writer->write_symbolID(name);         \/\/ name\n+        writer->write_u1(sig2tag(sig));       \/\/ type\n+      }\n@@ -1201,1 +1390,1 @@\n-  dump_instance_fields(writer, o, cache_entry);\n+  dump_instance_fields(writer, o, 0, class_cache, cache_entry);\n@@ -1246,1 +1435,1 @@\n-  writer->write_u4(DumperSupport::instance_size(ik));\n+  writer->write_u4(HeapWordSize * ik->size_helper());\n@@ -1300,4 +1489,1 @@\n-int DumperSupport::calculate_array_max_length(AbstractDumpWriter* writer, arrayOop array, short header_size) {\n-  BasicType type = ArrayKlass::cast(array->klass())->element_type();\n-  assert(type >= T_BOOLEAN && type <= T_OBJECT, \"invalid array element type\");\n-\n+int DumperSupport::calculate_array_max_length(AbstractDumpWriter* writer, arrayOop array, int type_size, short header_size) {\n@@ -1306,7 +1492,0 @@\n-  int type_size;\n-  if (type == T_OBJECT) {\n-    type_size = sizeof(address);\n-  } else {\n-    type_size = type2aelembytes(type);\n-  }\n-\n@@ -1320,0 +1499,1 @@\n+    BasicType type = ArrayKlass::cast(array->klass())->element_type();\n@@ -1326,0 +1506,16 @@\n+int DumperSupport::calculate_array_max_length(AbstractDumpWriter* writer, arrayOop array, short header_size) {\n+  BasicType type = ArrayKlass::cast(array->klass())->element_type();\n+  assert((type >= T_BOOLEAN && type <= T_OBJECT) || type == T_FLAT_ELEMENT, \"invalid array element type\");\n+  int type_size;\n+  if (type == T_OBJECT) {\n+    type_size = sizeof(address);\n+  } else if (type == T_FLAT_ELEMENT) {\n+      \/\/ TODO: FIXME\n+      fatal(\"Not supported yet\"); \/\/ FIXME: JDK-8325678\n+  } else {\n+    type_size = type2aelembytes(type);\n+  }\n+\n+  return calculate_array_max_length(writer, array, type_size, header_size);\n+}\n+\n@@ -1351,0 +1547,41 @@\n+\/\/ creates HPROF_GC_PRIM_ARRAY_DUMP record for the given flat array\n+void DumperSupport::dump_flat_array(AbstractDumpWriter* writer, flatArrayOop array, DumperClassCacheTable* class_cache) {\n+  FlatArrayKlass* array_klass = FlatArrayKlass::cast(array->klass());\n+  InlineKlass* element_klass = array_klass->element_klass();\n+  int element_size = instance_size(element_klass);\n+  \/*                          id         array object ID\n+   *                          u4         stack trace serial number\n+   *                          u4         number of elements\n+   *                          u1         element type\n+   *\/\n+  short header_size = 1 + sizeof(address) + 2 * 4 + 1;\n+\n+  \/\/ TODO: use T_SHORT\/T_INT\/T_LONG if needed to avoid truncation\n+  BasicType type = T_BYTE;\n+  int type_size = type2aelembytes(type);\n+  int length = calculate_array_max_length(writer, array, element_size, header_size);\n+  u4 length_in_bytes = (u4)(length * element_size);\n+  u4 size = header_size + length_in_bytes;\n+\n+  writer->start_sub_record(HPROF_GC_PRIM_ARRAY_DUMP, size);\n+  writer->write_objectID(array);\n+  writer->write_u4(STACK_TRACE_ID);\n+  \/\/ TODO: round up array length for T_SHORT\/T_INT\/T_LONG\n+  writer->write_u4(length * element_size);\n+  writer->write_u1(type2tag(type));\n+\n+  for (int index = 0; index < length; index++) {\n+    \/\/ need offset in the holder to read inlined object. calculate it from flatArrayOop::value_at_addr()\n+    int offset = (int)((address)array->value_at_addr(index, array_klass->layout_helper())\n+                  - cast_from_oop<address>(array));\n+    DumperClassCacheTableEntry* class_cache_entry = class_cache->lookup_or_create(element_klass);\n+    dump_inlined_object_fields(writer, array, offset, class_cache, class_cache_entry);\n+  }\n+\n+  \/\/ TODO: write padding bytes for T_SHORT\/T_INT\/T_LONG\n+\n+  InlinedObjects::get_instance()->add_flat_array(array);\n+\n+  writer->end_sub_record();\n+}\n+\n@@ -1472,0 +1709,264 @@\n+class InlinedFieldNameDumper : public LockedClassesDo {\n+public:\n+  typedef void (*Callback)(InlinedObjects *owner, const Klass *klass, uintx base_index, int count);\n+\n+private:\n+  AbstractDumpWriter* _writer;\n+  InlinedObjects *_owner;\n+  Callback       _callback;\n+  uintx _index;\n+\n+  void dump_inlined_field_names(GrowableArray<Symbol*>* super_names, Symbol* field_name, InlineKlass* klass) {\n+    super_names->push(field_name);\n+    for (HierarchicalFieldStream<JavaFieldStream> fld(klass); !fld.done(); fld.next()) {\n+      if (!fld.access_flags().is_static()) {\n+        if (DumperSupport::is_inlined_field(fld.field_descriptor())) {\n+          dump_inlined_field_names(super_names, fld.name(), DumperSupport::get_inlined_field_klass(fld.field_descriptor()));\n+        } else {\n+          \/\/ get next string ID.\n+          uintx next_index = _owner->get_next_string_id(_index);\n+          if (next_index == 0) {\n+            \/\/ something went wrong (overflow?)\n+            \/\/ stop generation; the rest of inlined objects will have original field names.\n+            return;\n+          }\n+          _index = next_index;\n+\n+          \/\/ Calculate length.\n+          int len = fld.name()->utf8_length();\n+          for (GrowableArrayIterator<Symbol*> it = super_names->begin(); it != super_names->end(); ++it) {\n+            len += (*it)->utf8_length() + 1;    \/\/ +1 for \".\".\n+          }\n+\n+          DumperSupport::write_header(_writer, HPROF_UTF8, oopSize + len);\n+          _writer->write_symbolID(reinterpret_cast<Symbol*>(_index));\n+          \/\/ Write the string value.\n+          \/\/ 1) super_names.\n+          for (GrowableArrayIterator<Symbol*> it = super_names->begin(); it != super_names->end(); ++it) {\n+            _writer->write_raw((*it)->bytes(), (*it)->utf8_length());\n+            _writer->write_u1('.');\n+          }\n+          \/\/ 2) field name.\n+          _writer->write_raw(fld.name()->bytes(), fld.name()->utf8_length());\n+        }\n+      }\n+    }\n+    super_names->pop();\n+  }\n+\n+  void dump_inlined_field_names(Symbol* field_name, InlineKlass* field_klass) {\n+    GrowableArray<Symbol*> super_names(4, mtServiceability);\n+    dump_inlined_field_names(&super_names, field_name, field_klass);\n+  }\n+\n+public:\n+  InlinedFieldNameDumper(AbstractDumpWriter* writer, InlinedObjects* owner, Callback callback)\n+    : _writer(writer), _owner(owner), _callback(callback), _index(0)  {\n+  }\n+\n+  void do_klass(Klass* k) {\n+    if (!k->is_instance_klass()) {\n+      return;\n+    }\n+    InstanceKlass* ik = InstanceKlass::cast(k);\n+    \/\/ if (ik->has_inline_type_fields()) {\n+    \/\/   return;\n+    \/\/ }\n+\n+    uintx base_index = _index;\n+    int count = 0;\n+\n+    for (HierarchicalFieldStream<JavaFieldStream> fld(ik); !fld.done(); fld.next()) {\n+      if (!fld.access_flags().is_static()) {\n+        if (DumperSupport::is_inlined_field(fld.field_descriptor())) {\n+          dump_inlined_field_names(fld.name(), DumperSupport::get_inlined_field_klass(fld.field_descriptor()));\n+          count++;\n+        }\n+      }\n+    }\n+\n+    if (count != 0) {\n+      _callback(_owner, k, base_index, count);\n+    }\n+  }\n+};\n+\n+class InlinedFieldsDumper : public LockedClassesDo {\n+private:\n+  AbstractDumpWriter* _writer;\n+\n+public:\n+  InlinedFieldsDumper(AbstractDumpWriter* writer) : _writer(writer) {}\n+\n+  void do_klass(Klass* k) {\n+    if (!k->is_instance_klass()) {\n+      return;\n+    }\n+    InstanceKlass* ik = InstanceKlass::cast(k);\n+    \/\/ if (ik->has_inline_type_fields()) {\n+    \/\/   return;\n+    \/\/ }\n+\n+    \/\/ We can be at a point where java mirror does not exist yet.\n+    \/\/ So we need to check that the class is at least loaded, to avoid crash from a null mirror.\n+    if (!ik->is_loaded()) {\n+      return;\n+    }\n+\n+    u2 inlined_count = 0;\n+    for (HierarchicalFieldStream<JavaFieldStream> fld(ik); !fld.done(); fld.next()) {\n+      if (!fld.access_flags().is_static()) {\n+        if (DumperSupport::is_inlined_field(fld.field_descriptor())) {\n+          inlined_count++;\n+        }\n+      }\n+    }\n+    if (inlined_count != 0) {\n+      _writer->write_u1(HPROF_CLASS_WITH_INLINED_FIELDS);\n+\n+      \/\/ class ID\n+      _writer->write_classID(ik);\n+      \/\/ number of inlined fields\n+      _writer->write_u2(inlined_count);\n+      u2 index = 0;\n+      for (HierarchicalFieldStream<JavaFieldStream> fld(ik); !fld.done(); fld.next()) {\n+        if (!fld.access_flags().is_static()) {\n+          if (DumperSupport::is_inlined_field(fld.field_descriptor())) {\n+            \/\/ inlined field index\n+            _writer->write_u2(index);\n+            \/\/ synthetic field count\n+            u2 field_count = DumperSupport::get_instance_fields_count(DumperSupport::get_inlined_field_klass(fld.field_descriptor()));\n+            _writer->write_u2(field_count);\n+            \/\/ original field name\n+            _writer->write_symbolID(fld.name());\n+            \/\/ inlined field class ID\n+            _writer->write_classID(DumperSupport::get_inlined_field_klass(fld.field_descriptor()));\n+\n+            index += field_count;\n+          } else {\n+            index++;\n+          }\n+        }\n+      }\n+    }\n+  }\n+};\n+\n+\n+void InlinedObjects::init() {\n+  _instance = this;\n+\n+  struct Closure : public SymbolClosure {\n+    uintx _min_id = max_uintx;\n+    uintx _max_id = 0;\n+    Closure() : _min_id(max_uintx), _max_id(0) {}\n+\n+    void do_symbol(Symbol** p) {\n+      uintx val = reinterpret_cast<uintx>(*p);\n+      if (val < _min_id) {\n+        _min_id = val;\n+      }\n+      if (val > _max_id) {\n+        _max_id = val;\n+      }\n+    }\n+  } closure;\n+\n+  SymbolTable::symbols_do(&closure);\n+\n+  _min_string_id = closure._min_id;\n+  _max_string_id = closure._max_id;\n+}\n+\n+void InlinedObjects::release() {\n+  _instance = nullptr;\n+\n+  if (_inlined_field_map != nullptr) {\n+    delete _inlined_field_map;\n+    _inlined_field_map = nullptr;\n+  }\n+  if (_flat_arrays != nullptr) {\n+    delete _flat_arrays;\n+    _flat_arrays = nullptr;\n+  }\n+}\n+\n+void InlinedObjects::inlined_field_names_callback(InlinedObjects* _this, const Klass* klass, uintx base_index, int count) {\n+  if (_this->_inlined_field_map == nullptr) {\n+    _this->_inlined_field_map = new (mtServiceability) GrowableArray<ClassInlinedFields>(100, mtServiceability);\n+  }\n+  _this->_inlined_field_map->append(ClassInlinedFields(klass, base_index));\n+\n+  \/\/ counters for dumping classes with inlined fields\n+  _this->_classes_count++;\n+  _this->_inlined_fields_count += count;\n+}\n+\n+void InlinedObjects::dump_inlined_field_names(AbstractDumpWriter* writer) {\n+  InlinedFieldNameDumper nameDumper(writer, this, inlined_field_names_callback);\n+  ClassLoaderDataGraph::classes_do(&nameDumper);\n+\n+  if (_inlined_field_map != nullptr) {\n+    \/\/ prepare the map for  get_base_index_for().\n+    _inlined_field_map->sort(ClassInlinedFields::compare);\n+  }\n+}\n+\n+uintx InlinedObjects::get_base_index_for(Klass* k) {\n+  if (_inlined_field_map != nullptr) {\n+    bool found = false;\n+    int idx = _inlined_field_map->find_sorted<ClassInlinedFields, ClassInlinedFields::compare>(ClassInlinedFields(k, 0), found);\n+    if (found) {\n+        return _inlined_field_map->at(idx).base_index;\n+    }\n+  }\n+\n+  \/\/ return max_uintx, so get_next_string_id returns 0.\n+  return max_uintx;\n+}\n+\n+uintx InlinedObjects::get_next_string_id(uintx id) {\n+  if (++id == _min_string_id) {\n+    return _max_string_id + 1;\n+  }\n+  return id;\n+}\n+\n+void InlinedObjects::dump_classed_with_inlined_fields(AbstractDumpWriter* writer) {\n+  if (_classes_count != 0) {\n+    \/\/ Record for each class contains tag(u1), class ID and count(u2)\n+    \/\/ for each inlined field index(u2), synthetic fields count(u2), original field name and class ID\n+    int size = _classes_count * (1 + sizeof(address) + 2)\n+             + _inlined_fields_count * (2 + 2 + sizeof(address) + sizeof(address));\n+    DumperSupport::write_header(writer, HPROF_INLINED_FIELDS, (u4)size);\n+\n+    InlinedFieldsDumper dumper(writer);\n+    ClassLoaderDataGraph::classes_do(&dumper);\n+  }\n+}\n+\n+void InlinedObjects::add_flat_array(oop array) {\n+  if (_flat_arrays == nullptr) {\n+    _flat_arrays = new (mtServiceability) GrowableArray<oop>(100, mtServiceability);\n+  }\n+  _flat_arrays->append(array);\n+}\n+\n+void InlinedObjects::dump_flat_arrays(AbstractDumpWriter* writer) {\n+  if (_flat_arrays != nullptr) {\n+    \/\/ For each flat array the record contains tag (u1), object ID and class ID.\n+    int size = _flat_arrays->length() * (1 + sizeof(address) + sizeof(address));\n+\n+    DumperSupport::write_header(writer, HPROF_FLAT_ARRAYS, (u4)size);\n+    for (GrowableArrayIterator<oop> it = _flat_arrays->begin(); it != _flat_arrays->end(); ++it) {\n+      flatArrayOop array = flatArrayOop(*it);\n+      FlatArrayKlass* array_klass = FlatArrayKlass::cast(array->klass());\n+      InlineKlass* element_klass = array_klass->element_klass();\n+      writer->write_u1(HPROF_FLAT_ARRAY);\n+      writer->write_objectID(array);\n+      writer->write_classID(element_klass);\n+    }\n+  }\n+}\n+\n+\n@@ -2004,0 +2505,2 @@\n+  } else if (o->is_flatArray()) {\n+    DumperSupport::dump_flat_array(writer(), flatArrayOop(o), &_class_cache);\n@@ -2083,0 +2586,1 @@\n+  InlinedObjects*  _inlined_objects;\n@@ -2093,1 +2597,1 @@\n-  DumpMerger(const char* path, DumpWriter* writer, int dump_seq) :\n+  DumpMerger(const char* path, DumpWriter* writer, InlinedObjects* inlined_objects, int dump_seq) :\n@@ -2095,0 +2599,1 @@\n+    _inlined_objects(inlined_objects),\n@@ -2126,0 +2631,1 @@\n+    _inlined_objects->dump_flat_arrays(_writer);\n@@ -2127,0 +2633,1 @@\n+    _inlined_objects->release();\n@@ -2246,0 +2753,4 @@\n+\n+  \/\/ Inlined object support.\n+  InlinedObjects          _inlined_objects;\n+\n@@ -2326,0 +2837,2 @@\n+  InlinedObjects* inlined_objects() { return &_inlined_objects; }\n+\n@@ -2462,0 +2975,7 @@\n+    \/\/ HPROF_UTF8 records for inlined field names.\n+    inlined_objects()->init();\n+    inlined_objects()->dump_inlined_field_names(writer());\n+\n+    \/\/ HPROF_INLINED_FIELDS\n+    inlined_objects()->dump_classed_with_inlined_fields(writer());\n+\n@@ -2661,1 +3181,1 @@\n-  DumpMerger merger(path, &writer, dumper.dump_seq());\n+  DumpMerger merger(path, &writer, dumper.inlined_objects(), dumper.dump_seq());\n","filename":"src\/hotspot\/share\/services\/heapDumper.cpp","additions":554,"deletions":34,"binary":false,"changes":588,"status":"modified"},{"patch":"@@ -29,1 +29,2 @@\n-import java.io.ObjectStreamClass.RecordSupport;\n+import java.io.ObjectStreamClass.ConstructorSupport;\n+import java.io.ObjectStreamClass.ClassDataSlot;\n@@ -34,0 +35,1 @@\n+import java.lang.reflect.InvocationTargetException;\n@@ -38,0 +40,2 @@\n+import java.util.List;\n+import java.util.Locale;\n@@ -213,0 +217,2 @@\n+ * Value objects cannot be `java.io.Externalizable` because value objects are\n+ * immutable and `Externalizable.readExternal` is unable to modify the fields of the value.\n@@ -238,0 +244,4 @@\n+ * <p>Value classes are {@linkplain Serializable} through the use of the serialization proxy pattern.\n+ * See {@linkplain ObjectOutputStream##valueclass-serialization value class serialization} for details.\n+ * When the proxy is deserialized it re-constructs and returns the value object.\n+ *\n@@ -251,0 +261,10 @@\n+    private static final String TRACE_DEST =\n+            System.getProperty(\"TRACE\");\n+\n+    static void TRACE(String format, Object... args) {\n+        if (TRACE_DEST != null) {\n+            var ps = \"OUT\".equals(TRACE_DEST.toUpperCase(Locale.ROOT)) ? System.out : System.err;\n+            ps.println((\"TRACE \" + format).formatted(args));\n+        }\n+    }\n+\n@@ -428,0 +448,8 @@\n+     * <p>Serialization and deserialization of value classes is described in\n+     * {@linkplain ObjectOutputStream##valueclass-serialization value class serialization}.\n+     *\n+     * @implSpec\n+     * When enabled with {@code --enable-preview}, serialization and deserialization of\n+     * Core Library value classes migrated from pre-JEP 401 identity classes is\n+     * implementation specific.\n+     *\n@@ -2110,9 +2138,2 @@\n-        Object obj;\n-        try {\n-            obj = desc.isInstantiable() ? desc.newInstance() : null;\n-        } catch (Exception ex) {\n-            throw new InvalidClassException(desc.forClass().getName(),\n-                                            \"unable to create instance\", ex);\n-        }\n-\n-        passHandle = handles.assign(unshared ? unsharedMarker : obj);\n+        \/\/ Assign the handle and initially set to null or the unsharedMarker\n+        passHandle = handles.assign(unshared ? unsharedMarker : null);\n@@ -2124,11 +2145,12 @@\n-        final boolean isRecord = desc.isRecord();\n-        if (isRecord) {\n-            assert obj == null;\n-            obj = readRecord(desc);\n-            if (!unshared)\n-                handles.setObject(passHandle, obj);\n-        } else if (desc.isExternalizable()) {\n-            readExternalData((Externalizable) obj, desc);\n-        } else {\n-            readSerialData(obj, desc);\n-        }\n+        try {\n+            \/\/ Dispatch on the factory mode to read an object from the stream.\n+            Object obj = switch (desc.factoryMode()) {\n+                case READ_OBJECT_DEFAULT -> readSerialDefaultObject(desc, unshared);\n+                case READ_OBJECT_CUSTOM -> readSerialCustomData(desc, unshared);\n+                case READ_RECORD -> readRecord(desc, unshared);\n+                case READ_EXTERNALIZABLE -> readExternalObject(desc, unshared);\n+                case READ_OBJECT_VALUE -> readObjectValue(desc, unshared);\n+                case READ_NO_LOCAL_CLASS -> readAbsentLocalClass(desc, unshared);\n+                case null -> throw new AssertionError(\"Unknown factoryMode for: \" + desc.getName(),\n+                        resolveEx);\n+            };\n@@ -2136,1 +2158,1 @@\n-        handles.finish(passHandle);\n+            handles.finish(passHandle);\n@@ -2138,15 +2160,16 @@\n-        if (obj != null &&\n-            handles.lookupException(passHandle) == null &&\n-            desc.hasReadResolveMethod())\n-        {\n-            Object rep = desc.invokeReadResolve(obj);\n-            if (unshared && rep.getClass().isArray()) {\n-                rep = cloneArray(rep);\n-            }\n-            if (rep != obj) {\n-                \/\/ Filter the replacement object\n-                if (rep != null) {\n-                    if (rep.getClass().isArray()) {\n-                        filterCheck(rep.getClass(), Array.getLength(rep));\n-                    } else {\n-                        filterCheck(rep.getClass(), -1);\n+            if (obj != null &&\n+                handles.lookupException(passHandle) == null &&\n+                desc.hasReadResolveMethod())\n+            {\n+                Object rep = desc.invokeReadResolve(obj);\n+                if (unshared && rep.getClass().isArray()) {\n+                    rep = cloneArray(rep);\n+                }\n+                if (rep != obj) {\n+                    \/\/ Filter the replacement object\n+                    if (rep != null) {\n+                        if (rep.getClass().isArray()) {\n+                            filterCheck(rep.getClass(), Array.getLength(rep));\n+                        } else {\n+                            filterCheck(rep.getClass(), -1);\n+                        }\n@@ -2154,0 +2177,1 @@\n+                    handles.setObject(passHandle, obj = rep);\n@@ -2155,1 +2179,5 @@\n-                handles.setObject(passHandle, obj = rep);\n+\n+            return obj;\n+        } catch (UncheckedIOException uioe) {\n+            \/\/ Consistent re-throw for nested UncheckedIOExceptions\n+            throw uioe.getCause();\n@@ -2158,0 +2186,1 @@\n+    }\n@@ -2159,1 +2188,43 @@\n-        return obj;\n+    \/**\n+     * {@return a value class instance by invoking its constructor with field values read from the stream.\n+     * The fields of the class in the stream are matched to the local fields and applied to\n+     * the constructor.\n+     * If the stream contains superclasses with serializable fields,\n+     * an InvalidClassException is thrown with an incompatible class change message.\n+     *\n+     * @param desc the class descriptor read from the stream, the local class is a value class\n+     * @param unshared if the object is not to be shared\n+     * @throws InvalidClassException if the stream contains a superclass with serializable fields.\n+     * @throws IOException if there are I\/O errors while reading from the\n+     *         underlying {@code InputStream}\n+     *\/\n+    private Object readObjectValue(ObjectStreamClass desc, boolean unshared) throws IOException {\n+        final ObjectStreamClass localDesc = desc.getLocalDesc();\n+        TRACE(\"readObjectValue: %s, local class: %s\", desc.getName(), localDesc.getName());\n+        \/\/ Check for un-expected fields in superclasses\n+        List<ClassDataSlot> slots = desc.getClassDataLayout();\n+        for (int i = 0; i < slots.size()-1; i++) {\n+            ClassDataSlot slot = slots.get(i);\n+            if (slot.hasData && slot.desc.getFields(false).length > 0) {\n+                throw new InvalidClassException(\"incompatible class change to value class: \" +\n+                        \"stream class has non-empty super type: \" + desc.getName());\n+            }\n+        }\n+        \/\/ Read values for the value class fields\n+        FieldValues fieldValues = new FieldValues(desc, true);\n+\n+        \/\/ Get value object constructor adapted to take primitive value buffer and object array.\n+        MethodHandle consMH = ConstructorSupport.deserializationValueCons(desc);\n+        try {\n+            Object obj = (Object) consMH.invokeExact(fieldValues.primValues, fieldValues.objValues);\n+            if (!unshared)\n+                handles.setObject(passHandle, obj);\n+            return obj;\n+        } catch (Exception e) {\n+            throw new InvalidObjectException(e.getMessage(), e);\n+        } catch (Error e) {\n+            throw e;\n+        } catch (Throwable t) {\n+            throw new InvalidObjectException(\"ReflectiveOperationException \" +\n+                    \"during deserialization\", t);\n+        }\n@@ -2163,1 +2234,3 @@\n-     * If obj is non-null, reads externalizable data by invoking readExternal()\n+     * Creates a new object and invokes its readExternal method to read its contents.\n+     *\n+     * If the class is instantiable, read externalizable data by invoking readExternal()\n@@ -2166,1 +2239,2 @@\n-     * called.\n+     * called.  The new object is entered in the handle table immediately,\n+     * allowing it to leak before it is completely read.\n@@ -2168,1 +2242,1 @@\n-    private void readExternalData(Externalizable obj, ObjectStreamClass desc)\n+    private Object readExternalObject(ObjectStreamClass desc, boolean unshared)\n@@ -2171,0 +2245,17 @@\n+        TRACE(\"readExternalObject: %s\", desc.getName());\n+\n+        \/\/ For Externalizable objects,\n+        \/\/ create the instance, publish the ref, and read the data\n+        Externalizable obj = null;\n+        try {\n+            if (desc.isInstantiable()) {\n+                obj = (Externalizable) desc.newInstance();\n+            }\n+        } catch (Exception ex) {\n+            throw new InvalidClassException(desc.getName(),\n+                    \"unable to create instance\", ex);\n+        }\n+\n+        if (!unshared)\n+            handles.setObject(passHandle, obj);\n+\n@@ -2214,0 +2305,1 @@\n+        return obj;\n@@ -2222,4 +2314,5 @@\n-     **\/\n-    private Object readRecord(ObjectStreamClass desc) throws IOException {\n-        ObjectStreamClass.ClassDataSlot[] slots = desc.getClassDataLayout();\n-        if (slots.length != 1) {\n+     *\/\n+    private Object readRecord(ObjectStreamClass desc, boolean unshared) throws IOException {\n+        TRACE(\"invoking readRecord: %s\", desc.getName());\n+        List<ClassDataSlot> slots = desc.getClassDataLayout();\n+        if (slots.size() != 1) {\n@@ -2227,3 +2320,3 @@\n-            for (int i = 0; i < slots.length-1; i++) {\n-                if (slots[i].hasData) {\n-                    new FieldValues(slots[i].desc, true);\n+            for (int i = 0; i < slots.size()-1; i++) {\n+                if (slots.get(i).hasData) {\n+                    new FieldValues(slots.get(i).desc, true);\n@@ -2243,1 +2336,1 @@\n-        MethodHandle ctrMH = RecordSupport.deserializationCtr(desc);\n+        MethodHandle ctrMH = ConstructorSupport.deserializationCtr(desc);\n@@ -2246,1 +2339,4 @@\n-            return (Object) ctrMH.invokeExact(fieldValues.primValues, fieldValues.objValues);\n+            Object obj = (Object) ctrMH.invokeExact(fieldValues.primValues, fieldValues.objValues);\n+            if (!unshared)\n+                handles.setObject(passHandle, obj);\n+            return obj;\n@@ -2258,1 +2354,53 @@\n-     * Reads (or attempts to skip, if obj is null or is tagged with a\n+     * Construct an object from the stream for a class that has only default read object behaviors.\n+     * For each object, the fields are read before any are assigned.\n+     * The new instance is entered in the handle table if it is unshared,\n+     * allowing it to escape before it is initialized.\n+     * The `readObject` and `readObjectNoData` methods are not present and are not called.\n+     *\n+     * @param desc the class descriptor\n+     * @param unshared true if the object should be shared\n+     * @return the object constructed from the stream data\n+     * @throws IOException if there are I\/O errors while reading from the\n+     *         underlying {@code InputStream}\n+     * @throws InvalidClassException if the instance creation fails\n+     *\/\n+    private Object readSerialDefaultObject(ObjectStreamClass desc, boolean unshared)\n+            throws IOException, InvalidClassException {\n+        if (!desc.isInstantiable()) {\n+            \/\/ No local class to create, read and discard\n+            return readAbsentLocalClass(desc, unshared);\n+        }\n+        TRACE(\"readSerialDefaultObject: %s\", desc.getName());\n+        try {\n+            final Object obj = desc.newInstance();\n+            if (!unshared)\n+                handles.setObject(passHandle, obj);\n+\n+            \/\/ Best effort Failure Atomicity; slotValues will be non-null if field\n+            \/\/ values can be set after reading all field data in the hierarchy.\n+            List<FieldValues> slotValues = desc.getClassDataLayout().stream()\n+                    .filter(s -> s.hasData)\n+                    .map(s1 -> {\n+                        var values = new FieldValues(s1.desc, true);\n+                        finishBlockData(s1.desc);\n+                        return values;\n+                    })\n+                    .toList();\n+\n+            if (handles.lookupException(passHandle) != null) {\n+                return null;    \/\/ some exception for a class, do not return the object\n+            }\n+\n+            \/\/ Check that the types are assignable for all slots before assigning.\n+            slotValues.forEach(v -> v.defaultCheckFieldValues(obj));\n+            slotValues.forEach(v -> v.defaultSetFieldValues(obj));\n+            return obj;\n+        } catch (InstantiationException | InvocationTargetException ex) {\n+            throw new InvalidClassException(desc.forClass().getName(),\n+                    \"unable to create instance\", ex);\n+        }\n+    }\n+\n+\n+    \/**\n+     * Reads (or attempts to skip, if not instantiatable or is tagged with a\n@@ -2260,2 +2408,2 @@\n-     * object in stream, from superclass to subclass.  Expects that passHandle\n-     * is set to obj's handle before this method is called.\n+     * object in stream, from superclass to subclass.\n+     * Expects that passHandle is set to current handle before this method is called.\n@@ -2263,1 +2411,1 @@\n-    private void readSerialData(Object obj, ObjectStreamClass desc)\n+    private Object readSerialCustomData(ObjectStreamClass desc, boolean unshared)\n@@ -2266,16 +2414,3 @@\n-        ObjectStreamClass.ClassDataSlot[] slots = desc.getClassDataLayout();\n-        \/\/ Best effort Failure Atomicity; slotValues will be non-null if field\n-        \/\/ values can be set after reading all field data in the hierarchy.\n-        \/\/ Field values can only be set after reading all data if there are no\n-        \/\/ user observable methods in the hierarchy, readObject(NoData). The\n-        \/\/ top most Serializable class in the hierarchy can be skipped.\n-        FieldValues[] slotValues = null;\n-\n-        boolean hasSpecialReadMethod = false;\n-        for (int i = 1; i < slots.length; i++) {\n-            ObjectStreamClass slotDesc = slots[i].desc;\n-            if (slotDesc.hasReadObjectMethod()\n-                  || slotDesc.hasReadObjectNoDataMethod()) {\n-                hasSpecialReadMethod = true;\n-                break;\n-            }\n+        if (!desc.isInstantiable()) {\n+            \/\/ No local class to create, read and discard\n+            return readAbsentLocalClass(desc, unshared);\n@@ -2283,34 +2418,12 @@\n-        \/\/ No special read methods, can store values and defer setting.\n-        if (!hasSpecialReadMethod)\n-            slotValues = new FieldValues[slots.length];\n-\n-        for (int i = 0; i < slots.length; i++) {\n-            ObjectStreamClass slotDesc = slots[i].desc;\n-            if (slots[i].hasData) {\n-                if (obj == null || handles.lookupException(passHandle) != null) {\n-                    \/\/ Read fields of the current descriptor into a new FieldValues and discard\n-                    new FieldValues(slotDesc, true);\n-                } else if (slotDesc.hasReadObjectMethod()) {\n-                    SerialCallbackContext oldContext = curContext;\n-                    if (oldContext != null)\n-                        oldContext.check();\n-                    try {\n-                        curContext = new SerialCallbackContext(obj, slotDesc);\n-\n-                        bin.setBlockDataMode(true);\n-                        slotDesc.invokeReadObject(obj, this);\n-                    } catch (ClassNotFoundException ex) {\n-                        \/*\n-                         * In most cases, the handle table has already\n-                         * propagated a CNFException to passHandle at this\n-                         * point; this mark call is included to address cases\n-                         * where the custom readObject method has cons'ed and\n-                         * thrown a new CNFException of its own.\n-                         *\/\n-                        handles.markException(passHandle, ex);\n-                    } finally {\n-                        curContext.setUsed();\n-                        if (oldContext!= null)\n-                            oldContext.check();\n-                        curContext = oldContext;\n-                    }\n+        TRACE(\"readSerialCustomData: %s, ex: %s\", desc.getName(), handles.lookupException(passHandle));\n+        try {\n+            Object obj = desc.newInstance();\n+            if (!unshared)\n+                handles.setObject(passHandle, obj);\n+            \/\/ Read data into each of the slots for the class\n+            return readSerialCustomSlots(obj, desc.getClassDataLayout());\n+        } catch (InstantiationException | InvocationTargetException ex) {\n+            throw new InvalidClassException(desc.forClass().getName(),\n+                    \"unable to create instance\", ex);\n+        }\n+    }\n@@ -2319,6 +2432,22 @@\n-                    \/*\n-                     * defaultDataEnd may have been set indirectly by custom\n-                     * readObject() method when calling defaultReadObject() or\n-                     * readFields(); clear it to restore normal read behavior.\n-                     *\/\n-                    defaultDataEnd = false;\n+    \/**\n+     * Reads from the stream using custom or default readObject methods appropriate.\n+     * For each slot, either the custom readObject method or the default reader of fields\n+     * is invoked. Unused slot specific custom data is discarded.\n+     * This function is used by {@link #readSerialCustomData}.\n+     *\n+     * @param obj the object to assign the values to\n+     * @param slots a list of slots to read from the stream\n+     * @return the object being initialized\n+     * @throws IOException if there are I\/O errors while reading from the\n+     *         underlying {@code InputStream}\n+     *\/\n+    private Object readSerialCustomSlots(Object obj, List<ClassDataSlot> slots) throws IOException {\n+        TRACE(\"    readSerialCustomSlots: %s\", slots);\n+\n+        for (ClassDataSlot slot : slots) {\n+            ObjectStreamClass slotDesc = slot.desc;\n+            if (slot.hasData) {\n+                if (slotDesc.hasReadObjectMethod() &&\n+                        handles.lookupException(passHandle) == null) {\n+                    \/\/ Invoke slot custom readObject method\n+                    readSlotViaReadObject(obj, slotDesc);\n@@ -2328,8 +2457,4 @@\n-                    if (slotValues != null) {\n-                        slotValues[i] = values;\n-                    } else if (obj != null) {\n-                        if (handles.lookupException(passHandle) == null) {\n-                            \/\/ passHandle NOT marked with an exception; set field values\n-                            values.defaultCheckFieldValues(obj);\n-                            values.defaultSetFieldValues(obj);\n-                        }\n+                    if (handles.lookupException(passHandle) == null) {\n+                        \/\/ Set the instance fields if no previous exception\n+                        values.defaultCheckFieldValues(obj);\n+                        values.defaultSetFieldValues(obj);\n@@ -2337,6 +2462,1 @@\n-                }\n-\n-                if (slotDesc.hasWriteObjectData()) {\n-                    skipCustomData();\n-                } else {\n-                    bin.setBlockDataMode(false);\n+                    finishBlockData(slotDesc);\n@@ -2345,4 +2465,2 @@\n-                if (obj != null &&\n-                    slotDesc.hasReadObjectNoDataMethod() &&\n-                    handles.lookupException(passHandle) == null)\n-                {\n+                if (slotDesc.hasReadObjectNoDataMethod() &&\n+                        handles.lookupException(passHandle) == null) {\n@@ -2353,0 +2471,2 @@\n+        return obj;\n+    }\n@@ -2354,11 +2474,78 @@\n-        if (obj != null && slotValues != null && handles.lookupException(passHandle) == null) {\n-            \/\/ passHandle NOT marked with an exception\n-            \/\/ Check that the non-primitive types are assignable for all slots\n-            \/\/ before assigning.\n-            for (int i = 0; i < slots.length; i++) {\n-                if (slotValues[i] != null)\n-                    slotValues[i].defaultCheckFieldValues(obj);\n-            }\n-            for (int i = 0; i < slots.length; i++) {\n-                if (slotValues[i] != null)\n-                    slotValues[i].defaultSetFieldValues(obj);\n+    \/**\n+     * Invoke the readObject method of the class to read and store the state from the stream.\n+     *\n+     * @param obj an instance of the class being created, only partially initialized.\n+     * @param slotDesc the ObjectStreamDescriptor for the current class\n+     * @throws IOException if there are I\/O errors while reading from the\n+     *         underlying {@code InputStream}\n+     *\/\n+    private void readSlotViaReadObject(Object obj, ObjectStreamClass slotDesc) throws IOException {\n+        TRACE(\"readSlotViaReadObject: %s\", slotDesc.getName());\n+        assert obj != null : \"readSlotViaReadObject called when obj == null\";\n+\n+        SerialCallbackContext oldContext = curContext;\n+        if (oldContext != null)\n+            oldContext.check();\n+        try {\n+            curContext = new SerialCallbackContext(obj, slotDesc);\n+\n+            bin.setBlockDataMode(true);\n+            slotDesc.invokeReadObject(obj, this);\n+        } catch (ClassNotFoundException ex) {\n+            \/*\n+             * In most cases, the handle table has already\n+             * propagated a CNFException to passHandle at this\n+             * point; this mark call is included to address cases\n+             * where the custom readObject method has cons'ed and\n+             * thrown a new CNFException of its own.\n+             *\/\n+            handles.markException(passHandle, ex);\n+        } finally {\n+            curContext.setUsed();\n+            if (oldContext!= null)\n+                oldContext.check();\n+            curContext = oldContext;\n+        }\n+\n+        \/*\n+         * defaultDataEnd may have been set indirectly by custom\n+         * readObject() method when calling defaultReadObject() or\n+         * readFields(); clear it to restore normal read behavior.\n+         *\/\n+        defaultDataEnd = false;\n+\n+        finishBlockData(slotDesc);\n+    }\n+\n+\n+    \/**\n+     * Read and discard an entire object, leaving a null reference in the HandleTable.\n+     * The descriptor of the class in the stream is used to read the fields from the stream.\n+     * There is no instance in which to store the field values.\n+     * Custom data following the fields of any slot is read and discarded.\n+     * References to nested objects are read and retained in the\n+     * handle table using the regular mechanism.\n+     * Handles later in the stream may refer to the nested objects.\n+     *\n+     * @param desc the stream class descriptor\n+     * @param unshared the unshared flag, ignored since no object is created\n+     * @return null, no object is created\n+     * @throws IOException if there are I\/O errors while reading from the\n+     *         underlying {@code InputStream}\n+     *\/\n+    private Object readAbsentLocalClass(ObjectStreamClass desc, boolean unshared)\n+            throws IOException {\n+        TRACE(\"readAbsentLocalClass: %s\", desc.getName());\n+        desc.getClassDataLayout().stream()\n+                .filter(s -> s.hasData)\n+                .forEach(s2 -> {new FieldValues(s2.desc, true); finishBlockData(s2.desc);});\n+        return null;\n+    }\n+\n+    \/\/ Finish handling of block data by skipping any remaining and setting BlockDataMode = false\n+    private void finishBlockData(ObjectStreamClass slotDesc) throws UncheckedIOException {\n+        try {\n+            if (slotDesc.hasWriteObjectData()) {\n+                skipCustomData();\n+            } else {\n+                bin.setBlockDataMode(false);\n@@ -2366,0 +2553,2 @@\n+        } catch (IOException ioe) {\n+            throw new UncheckedIOException(ioe);\n@@ -2461,0 +2650,1 @@\n+         * @throws UncheckedIOException if any IOException occurs\n@@ -2462,2 +2652,9 @@\n-        FieldValues(ObjectStreamClass desc, boolean recordDependencies) throws IOException {\n-            this.desc = desc;\n+        FieldValues(ObjectStreamClass desc, boolean recordDependencies) throws UncheckedIOException {\n+            try {\n+                this.desc = desc;\n+                TRACE(\"    reading FieldValues: %s\", desc.getName());\n+                int primDataSize = desc.getPrimDataSize();\n+                primValues = (primDataSize > 0) ? new byte[primDataSize] : null;\n+                if (primDataSize > 0) {\n+                    bin.readFully(primValues, 0, primDataSize, false);\n+                }\n@@ -2465,18 +2662,14 @@\n-            int primDataSize = desc.getPrimDataSize();\n-            primValues = (primDataSize > 0) ? new byte[primDataSize] : null;\n-            if (primDataSize > 0) {\n-                bin.readFully(primValues, 0, primDataSize, false);\n-            }\n-            int numObjFields = desc.getNumObjFields();\n-            objValues = (numObjFields > 0) ? new Object[numObjFields] : null;\n-            objHandles = (numObjFields > 0) ? new int[numObjFields] : null;\n-            if (numObjFields > 0) {\n-                int objHandle = passHandle;\n-                ObjectStreamField[] fields = desc.getFields(false);\n-                int numPrimFields = fields.length - objValues.length;\n-                for (int i = 0; i < objValues.length; i++) {\n-                    ObjectStreamField f = fields[numPrimFields + i];\n-                    objValues[i] = readObject0(Object.class, f.isUnshared());\n-                    objHandles[i] = passHandle;\n-                    if (recordDependencies && f.getField() != null) {\n-                        handles.markDependency(objHandle, passHandle);\n+                int numObjFields = desc.getNumObjFields();\n+                objValues = (numObjFields > 0) ? new Object[numObjFields] : null;\n+                objHandles = (numObjFields > 0) ? new int[numObjFields] : null;\n+                if (numObjFields > 0) {\n+                    int objHandle = passHandle;\n+                    ObjectStreamField[] fields = desc.getFields(false);\n+                    int numPrimFields = fields.length - objValues.length;\n+                    for (int i = 0; i < objValues.length; i++) {\n+                        ObjectStreamField f = fields[numPrimFields + i];\n+                        objValues[i] = readObject0(Object.class, f.isUnshared());\n+                        objHandles[i] = passHandle;\n+                        if (recordDependencies && f.getField() != null) {\n+                            handles.markDependency(objHandle, passHandle);\n+                        }\n@@ -2485,0 +2678,1 @@\n+                    passHandle = objHandle;\n@@ -2486,1 +2680,2 @@\n-                passHandle = objHandle;\n+            } catch (IOException ioe) {\n+                throw new UncheckedIOException(ioe);\n","filename":"src\/java.base\/share\/classes\/java\/io\/ObjectInputStream.java","additions":356,"deletions":161,"binary":false,"changes":517,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+import jdk.internal.value.DeserializeConstructor;\n@@ -59,4 +60,12 @@\n- * class; programmers should treat instances that are\n- * {@linkplain #equals(Object) equal} as interchangeable and should not\n- * use instances for synchronization, or unpredictable behavior may\n- * occur. For example, in a future release, synchronization may fail.\n+ * class; programmers should treat instances that are {@linkplain #equals(Object) equal}\n+ * as interchangeable and should not use instances for synchronization, mutexes, or\n+ * with {@linkplain java.lang.ref.Reference object references}.\n+ *\n+ * <div class=\"preview-block\">\n+ *      <div class=\"preview-comment\">\n+ *          When preview features are enabled, {@code Integer} is a {@linkplain Class#isValue value class}.\n+ *          Use of value class instances for synchronization, mutexes, or with\n+ *          {@linkplain java.lang.ref.Reference object references} result in\n+ *          {@link IdentityException}.\n+ *      <\/div>\n+ * <\/div>\n@@ -77,0 +86,1 @@\n+@jdk.internal.MigratedValueClass\n@@ -1002,0 +1012,1 @@\n+    @DeserializeConstructor\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Integer.java","additions":15,"deletions":4,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+import jdk.internal.value.DeserializeConstructor;\n@@ -59,4 +60,13 @@\n- * class; programmers should treat instances that are\n- * {@linkplain #equals(Object) equal} as interchangeable and should not\n- * use instances for synchronization, or unpredictable behavior may\n- * occur. For example, in a future release, synchronization may fail.\n+ * class; programmers should treat instances that are {@linkplain #equals(Object) equal}\n+ * as interchangeable and should not use instances for synchronization, mutexes, or\n+ * with {@linkplain java.lang.ref.Reference object references}.\n+ *\n+ * <div class=\"preview-block\">\n+ *      <div class=\"preview-comment\">\n+ *          When preview features are enabled, {@code Long} is a {@linkplain Class#isValue value class}.\n+ *          Use of value class instances for synchronization, mutexes, or with\n+ *          {@linkplain java.lang.ref.Reference object references} result in\n+ *          {@link IdentityException}.\n+ *      <\/div>\n+ * <\/div>\n+ *\n@@ -77,0 +87,1 @@\n+@jdk.internal.MigratedValueClass\n@@ -995,0 +1006,1 @@\n+    @DeserializeConstructor\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Long.java","additions":16,"deletions":4,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+import java.lang.reflect.ClassFileFormatVersion;\n@@ -490,0 +491,15 @@\n+     * <div class=\"preview-block\">\n+     *      <div class=\"preview-comment\">\n+     *          The \"identity hash code\" of a {@linkplain Class#isValue() value object}\n+     *          is computed by combining the identity hash codes of the value object's fields recursively.\n+     *      <\/div>\n+     * <\/div>\n+     * @apiNote\n+     * <div class=\"preview-block\">\n+     *      <div class=\"preview-comment\">\n+     *          Note that, like ==, this hash code exposes information about a value object's\n+     *          private fields that might otherwise be hidden by an identity object.\n+     *          Developers should be cautious about storing sensitive secrets in value object fields.\n+     *      <\/div>\n+     * <\/div>\n+     *\n@@ -2321,0 +2337,4 @@\n+            public int classFileFormatVersion(Class<?> clazz) {\n+                return clazz.getClassFileVersion();\n+            }\n+\n","filename":"src\/java.base\/share\/classes\/java\/lang\/System.java","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+import java.util.Objects;\n@@ -35,0 +36,8 @@\n+ * <div class=\"preview-block\">\n+ *      <div class=\"preview-comment\">\n+ *          The referent must have {@linkplain Objects#hasIdentity(Object) object identity}.\n+ *          When preview features are enabled, attempts to create a reference\n+ *          to a {@linkplain Class#isValue value object} result in an {@link IdentityException}.\n+ *      <\/div>\n+ * <\/div>\n+ *\n@@ -103,0 +112,2 @@\n+     * @throws IdentityException if the referent is not an\n+     *         {@link java.util.Objects#hasIdentity(Object) identity object}\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/PhantomReference.java","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -35,0 +35,2 @@\n+import java.util.Objects;\n+\n@@ -40,0 +42,8 @@\n+ *\n+ * <div class=\"preview-block\">\n+ *      <div class=\"preview-comment\">\n+ *          The referent must have {@linkplain Objects#hasIdentity(Object) object identity}.\n+ *          When preview features are enabled, attempts to create a reference\n+ *          to a {@linkplain Class#isValue value object} result in an {@link IdentityException}.\n+ *      <\/div>\n+ * <\/div>\n@@ -547,0 +557,3 @@\n+        if (referent != null) {\n+            Objects.requireIdentity(referent);\n+        }\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/Reference.java","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -29,0 +29,2 @@\n+import java.util.Objects;\n+\n@@ -34,0 +36,8 @@\n+ * <div class=\"preview-block\">\n+ *      <div class=\"preview-comment\">\n+ *          The referent must have {@linkplain Objects#hasIdentity(Object) object identity}.\n+ *          When preview features are enabled, attempts to create a reference\n+ *          to a {@linkplain Class#isValue value object} result in an {@link IdentityException}.\n+ *      <\/div>\n+ * <\/div>\n+ *\n@@ -84,0 +94,2 @@\n+     * @throws IdentityException if the referent is not an\n+     *         {@link java.util.Objects#hasIdentity(Object) identity object}\n@@ -97,1 +109,2 @@\n-     *\n+     * @throws IdentityException if the referent is not an\n+     *         {@link java.util.Objects#hasIdentity(Object) identity object}\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/SoftReference.java","additions":14,"deletions":1,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -29,0 +29,2 @@\n+import java.util.Objects;\n+\n@@ -34,0 +36,8 @@\n+ * <div class=\"preview-block\">\n+ *      <div class=\"preview-comment\">\n+ *          The referent must have {@linkplain Objects#hasIdentity(Object) object identity}.\n+ *          When preview features are enabled, attempts to create a reference\n+ *          to a {@linkplain Class#isValue value object} result in an {@link IdentityException}.\n+ *      <\/div>\n+ * <\/div>\n+ *\n@@ -56,0 +66,2 @@\n+     * @throws IdentityException if the referent is not an\n+     *         {@link java.util.Objects#hasIdentity(Object) identity object}\n@@ -68,0 +80,2 @@\n+     * @throws IdentityException if the referent is not an\n+     *         {@link java.util.Objects#hasIdentity(Object) identity object}\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/WeakReference.java","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,1 @@\n-import java.lang.ref.WeakReference;\n+import java.lang.ref.WeakReference;\n@@ -125,0 +125,16 @@\n+ * @apiNote\n+ * <div class=\"preview-block\">\n+ *      <div class=\"preview-comment\">\n+ *          Objects that are {@linkplain Class#isValue() value objects} do not have identity\n+ *          and can not be used as keys in a {@code WeakHashMap}. {@linkplain java.lang.ref.Reference References}\n+ *          such as {@linkplain WeakReference WeakReference} used by {@code WeakhashMap}\n+ *          to hold the key cannot refer to a value object.\n+ *          Methods such as {@linkplain #get get} or {@linkplain #containsKey containsKey}\n+ *          will always return {@code null} or {@code false} respectively.\n+ *          The methods such as {@linkplain #put put}, {@linkplain #putAll putAll},\n+ *          {@linkplain #compute(Object, BiFunction) compute}, and\n+ *          {@linkplain #computeIfAbsent(Object, Function) computeIfAbsent} or any method putting\n+ *          a value object, as a key, throw {@link IdentityException}.\n+ *      <\/div>\n+ * <\/div>\n+ *\n@@ -291,0 +307,2 @@\n+     * The key may be a value object, but it will never be equal to the referent\n+     * so does not need a separate Objects.hasIdentity check.\n@@ -459,0 +477,1 @@\n+     * @throws IdentityException if {@code key} is a value object\n@@ -462,0 +481,1 @@\n+        Objects.requireIdentity(k);\n@@ -549,0 +569,4 @@\n+     * @apiNote If the specified map contains keys that are {@linkplain Objects#isValueObject value objects}\n+     * an {@linkplain IdentityException } is thrown when the first value object key is encountered.\n+     * Zero or more mappings may have already been copied to this map.\n+     *\n@@ -551,0 +575,1 @@\n+     * @throws  IdentityException if any of the {@code keys} is a value object\n","filename":"src\/java.base\/share\/classes\/java\/util\/WeakHashMap.java","additions":27,"deletions":2,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+import java.lang.reflect.ClassFileFormatVersion;\n@@ -618,0 +619,6 @@\n+\n+    \/**\n+     * Returns the class file format version of the class.\n+     *\/\n+    int classFileFormatVersion(Class<?> klass);\n+\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/access\/JavaLangAccess.java","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -67,0 +67,3 @@\n+        @JEP(number=401, title=\"Value Classes and Objects\", status = \"Preview\")\n+        VALUE_OBJECTS,\n+\n@@ -69,1 +72,0 @@\n-\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/javac\/PreviewFeature.java","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -138,1 +138,0 @@\n-\n@@ -268,0 +267,2 @@\n+    exports jdk.internal.value to  \/\/ Needed by Unsafe\n+        jdk.unsupported;\n","filename":"src\/java.base\/share\/classes\/module-info.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -296,0 +296,5 @@\n+        \/**\n+         * Warn about issues related to migration of JDK classes.\n+         *\/\n+        MIGRATION(\"migration\"),\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Lint.java","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -229,2 +229,0 @@\n-    public final Type valueBasedType;\n-    public final Type valueBasedInternalType;\n@@ -247,0 +245,10 @@\n+    \/\/ valhalla\n+    public final Type valueBasedType;\n+    public final Type valueBasedInternalType;\n+    public final Type migratedValueClassType;\n+    public final Type migratedValueClassInternalType;\n+    public final Type strictType;\n+    \/** The symbol representing the finalize method on Object *\/\n+    public final MethodSymbol objectFinalize;\n+    public final Type numberType;\n+\n@@ -539,0 +547,6 @@\n+        throwableType = enterClass(\"java.lang.Throwable\");\n+        objectFinalize = new MethodSymbol(PROTECTED,\n+                names.finalize,\n+                new MethodType(List.nil(), voidType,\n+                        List.of(throwableType), methodClass),\n+                objectType.tsym);\n@@ -547,1 +561,0 @@\n-        throwableType = enterClass(\"java.lang.Throwable\");\n@@ -615,0 +628,3 @@\n+        strictType = enterSyntheticAnnotation(\"jdk.internal.vm.annotation.Strict\");\n+        migratedValueClassType = enterClass(\"jdk.internal.MigratedValueClass\");\n+        migratedValueClassInternalType = enterSyntheticAnnotation(\"jdk.internal.MigratedValueClass+Annotation\");\n@@ -638,0 +654,2 @@\n+        numberType = enterClass(\"java.lang.Number\");\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Symtab.java","additions":21,"deletions":3,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -234,0 +234,15 @@\n+    public boolean isValueClass() {\n+        return false;\n+    }\n+\n+    public boolean isIdentityClass() {\n+        return false;\n+    }\n+\n+    \/\/ Does this type need to be preloaded in the context of the referring class ??\n+    public boolean requiresLoadableDescriptors(Symbol referringClass) {\n+        if (this.tsym == referringClass)\n+            return false; \/\/ pointless\n+        return this.isValueClass() && this.isFinal();\n+    }\n+\n@@ -1180,0 +1195,10 @@\n+        @Override\n+        public boolean isValueClass() {\n+            return tsym != null && tsym.isValueClass();\n+        }\n+\n+        @Override\n+        public boolean isIdentityClass() {\n+            return tsym != null && tsym.isIdentityClass();\n+        }\n+\n@@ -2338,2 +2363,1 @@\n-            super(noType, List.nil(), null);\n-            this.tsym = tsym;\n+            super(noType, List.nil(), tsym, List.nil());\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Type.java","additions":26,"deletions":2,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -187,0 +187,2 @@\n+        allowValueClasses = (!preview.isPreview(Feature.VALUE_CLASSES) || preview.isEnabled()) &&\n+                Feature.VALUE_CLASSES.allowedInSource(source);\n@@ -205,0 +207,4 @@\n+    \/** Are value classes allowed\n+     *\/\n+    private final boolean allowValueClasses;\n+\n@@ -1125,1 +1131,1 @@\n-                            if (TreeInfo.hasAnyConstructorCall(tree)) {\n+                            if (!allowValueClasses && TreeInfo.hasAnyConstructorCall(tree)) {\n@@ -1207,1 +1213,5 @@\n-                        tree.body.stats = tree.body.stats.prepend(supCall);\n+                        if (allowValueClasses && (owner.isValueClass() || owner.hasStrict() || ((owner.flags_field & RECORD) != 0))) {\n+                            tree.body.stats = tree.body.stats.append(supCall);\n+                        } else {\n+                            tree.body.stats = tree.body.stats.prepend(supCall);\n+                        }\n@@ -1317,4 +1327,13 @@\n-                    attribExpr(tree.init, initEnv, v.type);\n-                    if (tree.isImplicitlyTyped()) {\n-                        \/\/fixup local variable type\n-                        v.type = chk.checkLocalVarType(tree, tree.init.type, tree.name);\n+                    boolean previousCtorPrologue = initEnv.info.ctorPrologue;\n+                    try {\n+                        if (v.owner.kind == TYP && !v.isStatic() && v.isStrict()) {\n+                            \/\/ strict instance initializer in a value class\n+                            initEnv.info.ctorPrologue = true;\n+                        }\n+                        attribExpr(tree.init, initEnv, v.type);\n+                        if (tree.isImplicitlyTyped()) {\n+                            \/\/fixup local variable type\n+                            v.type = chk.checkLocalVarType(tree, tree.init.type, tree.name);\n+                        }\n+                    } finally {\n+                        initEnv.info.ctorPrologue = previousCtorPrologue;\n@@ -1441,1 +1460,5 @@\n-            if ((tree.flags & STATIC) != 0) localEnv.info.staticLevel++;\n+            if ((tree.flags & STATIC) != 0) {\n+                localEnv.info.staticLevel++;\n+            } else {\n+                localEnv.info.instanceInitializerBlock = true;\n+            }\n@@ -1954,2 +1977,2 @@\n-        chk.checkRefType(tree.pos(), attribExpr(tree.lock, env));\n-        if (tree.lock.type != null && tree.lock.type.isValueBased()) {\n+        boolean identityType = chk.checkIdentityType(tree.pos(), attribExpr(tree.lock, env));\n+        if (identityType && tree.lock.type != null && tree.lock.type.isValueBased()) {\n@@ -4409,0 +4432,1 @@\n+        Assert.check(site == tree.selected.type);\n@@ -5512,1 +5536,1 @@\n-                } else {\n+                } else if ((c.flags_field & Flags.COMPOUND) == 0) {\n@@ -5550,0 +5574,5 @@\n+                if (c.isValueClass()) {\n+                    Assert.check(env.tree.hasTag(CLASSDEF));\n+                    chk.checkConstraintsOfValueClass((JCClassDecl) env.tree, c);\n+                }\n+\n@@ -5694,1 +5723,1 @@\n-            chk.checkSerialStructure(tree, c);\n+            chk.checkSerialStructure(env, tree, c);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Attr.java","additions":40,"deletions":11,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -184,0 +184,2 @@\n+        allowValueClasses = (!preview.isPreview(Feature.VALUE_CLASSES) || preview.isEnabled()) &&\n+                Feature.VALUE_CLASSES.allowedInSource(source);\n@@ -223,0 +225,4 @@\n+    \/** Are value classes allowed\n+     *\/\n+    private final boolean allowValueClasses;\n+\n@@ -733,0 +739,25 @@\n+    void checkConstraintsOfValueClass(JCClassDecl tree, ClassSymbol c) {\n+        DiagnosticPosition pos = tree.pos();\n+        for (Type st : types.closure(c.type)) {\n+            if (st == null || st.tsym == null || st.tsym.kind == ERR)\n+                continue;\n+            if  (st.tsym == syms.objectType.tsym || st.tsym == syms.recordType.tsym || st.isInterface())\n+                continue;\n+            if (!st.tsym.isAbstract()) {\n+                if (c != st.tsym) {\n+                    log.error(pos, Errors.ConcreteSupertypeForValueClass(c, st));\n+                }\n+                continue;\n+            }\n+            \/\/ dealing with an abstract value or value super class below.\n+            for (Symbol s : st.tsym.members().getSymbols(NON_RECURSIVE)) {\n+                if (s.kind == MTH) {\n+                    if ((s.flags() & (SYNCHRONIZED | STATIC)) == SYNCHRONIZED) {\n+                        log.error(pos, Errors.SuperClassMethodCannotBeSynchronized(s, c, st));\n+                    }\n+                    break;\n+                }\n+            }\n+        }\n+    }\n+\n@@ -790,0 +821,26 @@\n+    \/** Check that type is an identity type, i.e. not a value type.\n+     *  When not discernible statically, give it the benefit of doubt\n+     *  and defer to runtime.\n+     *\n+     *  @param pos           Position to be used for error reporting.\n+     *  @param t             The type to be checked.\n+     *\/\n+    boolean checkIdentityType(DiagnosticPosition pos, Type t) {\n+        if (t.hasTag(TYPEVAR)) {\n+            t = types.skipTypeVars(t, false);\n+        }\n+        if (t.isIntersection()) {\n+            IntersectionClassType ict = (IntersectionClassType)t;\n+            boolean result = true;\n+            for (Type component : ict.getExplicitComponents()) {\n+                result &= checkIdentityType(pos, component);\n+            }\n+            return result;\n+        }\n+        if (t.isPrimitive() || (t.isValueClass() && !t.tsym.isAbstract())) {\n+            typeTagError(pos, diags.fragment(Fragments.TypeReqIdentity), t);\n+            return false;\n+        }\n+        return true;\n+    }\n+\n@@ -1181,2 +1238,11 @@\n-            else\n-                mask = VarFlags;\n+            else {\n+                boolean isInstanceField = (flags & STATIC) == 0;\n+                boolean isInstanceFieldOfValueClass = isInstanceField && sym.owner.type.isValueClass();\n+                boolean isRecordField = isInstanceField && (sym.owner.flags_field & RECORD) != 0;\n+                if (allowValueClasses && (isInstanceFieldOfValueClass || isRecordField)) {\n+                    implicit |= FINAL | STRICT;\n+                    mask = ValueFieldFlags;\n+                } else {\n+                    mask = VarFlags;\n+                }\n+            }\n@@ -1208,1 +1274,2 @@\n-                mask = RecordMethodFlags;\n+                mask = ((sym.owner.flags_field & VALUE_CLASS) != 0 && (flags & Flags.STATIC) == 0) ?\n+                        RecordMethodFlags & ~SYNCHRONIZED : RecordMethodFlags;\n@@ -1210,1 +1277,3 @@\n-                mask = MethodFlags;\n+                \/\/ value objects do not have an associated monitor\/lock\n+                mask = ((sym.owner.flags_field & VALUE_CLASS) != 0 && (flags & Flags.STATIC) == 0) ?\n+                        MethodFlags & ~SYNCHRONIZED : MethodFlags;\n@@ -1227,1 +1296,1 @@\n-                mask = staticOrImplicitlyStatic && allowRecords && (flags & ANNOTATION) == 0 ? StaticLocalFlags : LocalClassFlags;\n+                mask = staticOrImplicitlyStatic && allowRecords && (flags & ANNOTATION) == 0 ? ExtendedStaticLocalClassFlags : ExtendedLocalClassFlags;\n@@ -1243,0 +1312,4 @@\n+            if ((flags & (VALUE_CLASS | SEALED | ABSTRACT)) == (VALUE_CLASS | SEALED) ||\n+                (flags & (VALUE_CLASS | NON_SEALED | ABSTRACT)) == (VALUE_CLASS | NON_SEALED)) {\n+                log.error(pos, Errors.NonAbstractValueClassCantBeSealedOrNonSealed);\n+            }\n@@ -1246,0 +1319,4 @@\n+            if ((flags & (INTERFACE | VALUE_CLASS)) == 0) {\n+                implicit |= IDENTITY_TYPE;\n+            }\n+\n@@ -1247,2 +1324,2 @@\n-                \/\/ enums can't be declared abstract, final, sealed or non-sealed\n-                mask &= ~(ABSTRACT | FINAL | SEALED | NON_SEALED);\n+                \/\/ enums can't be declared abstract, final, sealed or non-sealed or value\n+                mask &= ~(ABSTRACT | FINAL | SEALED | NON_SEALED | VALUE_CLASS);\n@@ -1261,0 +1338,5 @@\n+\n+            \/\/ concrete value classes are implicitly final\n+            if ((flags & (ABSTRACT | INTERFACE | VALUE_CLASS)) == VALUE_CLASS) {\n+                implicit |= FINAL;\n+            }\n@@ -1275,2 +1357,1 @@\n-        }\n-        else if ((sym.kind == TYP ||\n+        } else if ((sym.kind == TYP ||\n@@ -1299,1 +1380,2 @@\n-                 checkDisjoint(pos, flags,\n+                 \/\/ we are using `implicit` here as instance fields of value classes are implicitly final\n+                 checkDisjoint(pos, flags | implicit,\n@@ -1315,1 +1397,7 @@\n-                                ANNOTATION)) {\n+                                ANNOTATION)\n+                && checkDisjoint(pos, flags,\n+                                VALUE_CLASS,\n+                                ANNOTATION)\n+                && checkDisjoint(pos, flags,\n+                                VALUE_CLASS,\n+                                INTERFACE) ) {\n@@ -2127,0 +2215,5 @@\n+        if (allowValueClasses && origin.isValueClass() && names.finalize.equals(m.name)) {\n+            if (m.overrides(syms.objectFinalize, origin, types, false)) {\n+                log.warning(tree.pos(), Warnings.ValueFinalize);\n+            }\n+        }\n@@ -2562,0 +2655,12 @@\n+\n+        Type identitySuper = null;\n+        for (Type t : types.closure(c)) {\n+            if (t != c) {\n+                if (t.isIdentityClass() && (t.tsym.flags() & VALUE_BASED) == 0)\n+                    identitySuper = t;\n+                if (c.isValueClass() && identitySuper != null && identitySuper.tsym != syms.objectType.tsym) { \/\/ Object is special\n+                    log.error(pos, Errors.ValueTypeHasIdentitySuperType(c, identitySuper));\n+                    break;\n+                }\n+            }\n+        }\n@@ -4914,2 +5019,2 @@\n-    public void checkSerialStructure(JCClassDecl tree, ClassSymbol c) {\n-        (new SerialTypeVisitor()).visit(c, tree);\n+    public void checkSerialStructure(Env<AttrContext> env, JCClassDecl tree, ClassSymbol c) {\n+        (new SerialTypeVisitor(env)).visit(c, tree);\n@@ -4946,1 +5051,2 @@\n-        SerialTypeVisitor() {\n+        Env<AttrContext> env;\n+        SerialTypeVisitor(Env<AttrContext> env) {\n@@ -4948,0 +5054,1 @@\n+            this.env = env;\n@@ -5007,0 +5114,1 @@\n+            final boolean[] hasWriteReplace = {false};\n@@ -5081,1 +5189,1 @@\n-                            case \"writeReplace\"     -> checkWriteReplace(tree,e, method);\n+                            case \"writeReplace\"     -> {hasWriteReplace[0] = true; hasAppropriateWriteReplace(tree, method, true);}\n@@ -5092,1 +5200,20 @@\n-\n+            if (!hasWriteReplace[0] &&\n+                    (c.isValueClass() || hasAbstractValueSuperClass(c, Set.of(syms.numberType.tsym))) &&\n+                    !c.isAbstract() && !c.isRecord() &&\n+                    types.unboxedType(c.type) == Type.noType) {\n+                \/\/ we need to check if the class is inheriting an appropriate writeReplace method\n+                MethodSymbol ms = null;\n+                Log.DiagnosticHandler discardHandler = log.new DiscardDiagnosticHandler();\n+                try {\n+                    ms = rs.resolveInternalMethod(env.tree, env, c.type, names.writeReplace, List.nil(), List.nil());\n+                } catch (FatalError fe) {\n+                    \/\/ ignore no method was found\n+                } finally {\n+                    log.popDiagnosticHandler(discardHandler);\n+                }\n+                if (ms == null || !hasAppropriateWriteReplace(p, ms, false)) {\n+                    log.warning(p.pos(),\n+                            c.isValueClass() ? LintWarnings.SerializableValueClassWithoutWriteReplace1 :\n+                                    LintWarnings.SerializableValueClassWithoutWriteReplace2);\n+                }\n+            }\n@@ -5100,0 +5227,16 @@\n+        private boolean hasAbstractValueSuperClass(Symbol c, Set<Symbol> excluding) {\n+            while (c.getKind() == ElementKind.CLASS) {\n+                Type sup = ((ClassSymbol)c).getSuperclass();\n+                if (!sup.hasTag(CLASS) || sup.isErroneous() ||\n+                        sup.tsym == syms.objectType.tsym) {\n+                    return false;\n+                }\n+                \/\/ if it is a value super class it has to be abstract\n+                if (sup.isValueClass() && !excluding.contains(sup.tsym)) {\n+                    return true;\n+                }\n+                c = sup.tsym;\n+            }\n+            return false;\n+        }\n+\n@@ -5223,1 +5366,1 @@\n-            checkReturnType(tree, e, method, syms.voidType);\n+            isExpectedReturnType(tree, method, syms.voidType, true);\n@@ -5225,1 +5368,1 @@\n-            checkExceptions(tree, e, method, syms.ioExceptionType);\n+            hasExpectedExceptions(tree, method, true, syms.ioExceptionType);\n@@ -5229,1 +5372,1 @@\n-        private void checkWriteReplace(JCClassDecl tree, Element e, MethodSymbol method) {\n+        private boolean hasAppropriateWriteReplace(JCClassDecl tree, MethodSymbol method, boolean warn) {\n@@ -5235,4 +5378,4 @@\n-            checkConcreteInstanceMethod(tree, e, method);\n-            checkReturnType(tree, e, method, syms.objectType);\n-            checkNoArgs(tree, e, method);\n-            checkExceptions(tree, e, method, syms.objectStreamExceptionType);\n+            return isConcreteInstanceMethod(tree, method, warn) &&\n+                    isExpectedReturnType(tree, method, syms.objectType, warn) &&\n+                    hasNoArgs(tree, method, warn) &&\n+                    hasExpectedExceptions(tree, method, warn, syms.objectStreamExceptionType);\n@@ -5249,1 +5392,1 @@\n-            checkReturnType(tree, e, method, syms.voidType);\n+            isExpectedReturnType(tree, method, syms.voidType, true);\n@@ -5251,1 +5394,1 @@\n-            checkExceptions(tree, e, method, syms.ioExceptionType, syms.classNotFoundExceptionType);\n+            hasExpectedExceptions(tree, method, true, syms.ioExceptionType, syms.classNotFoundExceptionType);\n@@ -5258,3 +5401,3 @@\n-            checkReturnType(tree, e, method, syms.voidType);\n-            checkNoArgs(tree, e, method);\n-            checkExceptions(tree, e, method, syms.objectStreamExceptionType);\n+            isExpectedReturnType(tree, method, syms.voidType, true);\n+            hasNoArgs(tree, method, true);\n+            hasExpectedExceptions(tree, method, true, syms.objectStreamExceptionType);\n@@ -5270,4 +5413,4 @@\n-            checkConcreteInstanceMethod(tree, e, method);\n-            checkReturnType(tree,e, method, syms.objectType);\n-            checkNoArgs(tree, e, method);\n-            checkExceptions(tree, e, method, syms.objectStreamExceptionType);\n+            isConcreteInstanceMethod(tree, method, true);\n+            isExpectedReturnType(tree, method, syms.objectType, true);\n+            hasNoArgs(tree, method, true);\n+            hasExpectedExceptions(tree, method, true, syms.objectStreamExceptionType);\n@@ -5523,1 +5666,1 @@\n-                        case \"writeReplace\" -> checkWriteReplace(tree, e, method);\n+                        case \"writeReplace\" -> hasAppropriateWriteReplace(tree, method, true);\n@@ -5541,3 +5684,3 @@\n-        void checkConcreteInstanceMethod(JCClassDecl tree,\n-                                         Element enclosing,\n-                                         MethodSymbol method) {\n+        boolean isConcreteInstanceMethod(JCClassDecl tree,\n+                                         MethodSymbol method,\n+                                         boolean warn) {\n@@ -5545,0 +5688,1 @@\n+                if (warn) {\n@@ -5548,0 +5692,2 @@\n+                }\n+                return false;\n@@ -5549,0 +5695,1 @@\n+            return true;\n@@ -5551,4 +5698,4 @@\n-        private void checkReturnType(JCClassDecl tree,\n-                                     Element enclosing,\n-                                     MethodSymbol method,\n-                                     Type expectedReturnType) {\n+        private boolean isExpectedReturnType(JCClassDecl tree,\n+                                          MethodSymbol method,\n+                                          Type expectedReturnType,\n+                                          boolean warn) {\n@@ -5562,2 +5709,3 @@\n-                log.warning(\n-                        TreeInfo.diagnosticPositionFor(method, tree),\n+                if (warn) {\n+                    log.warning(\n+                            TreeInfo.diagnosticPositionFor(method, tree),\n@@ -5566,0 +5714,2 @@\n+                }\n+                return false;\n@@ -5567,0 +5717,1 @@\n+            return true;\n@@ -5604,1 +5755,1 @@\n-        private void checkNoArgs(JCClassDecl tree, Element enclosing, MethodSymbol method) {\n+        boolean hasNoArgs(JCClassDecl tree, MethodSymbol method, boolean warn) {\n@@ -5607,2 +5758,3 @@\n-                log.warning(\n-                        TreeInfo.diagnosticPositionFor(parameters.get(0), tree),\n+                if (warn) {\n+                    log.warning(\n+                            TreeInfo.diagnosticPositionFor(parameters.get(0), tree),\n@@ -5610,0 +5762,2 @@\n+                }\n+                return false;\n@@ -5611,0 +5765,1 @@\n+            return true;\n@@ -5623,4 +5778,4 @@\n-        private void checkExceptions(JCClassDecl tree,\n-                                     Element enclosing,\n-                                     MethodSymbol method,\n-                                     Type... declaredExceptions) {\n+        private boolean hasExpectedExceptions(JCClassDecl tree,\n+                                              MethodSymbol method,\n+                                              boolean warn,\n+                                              Type... declaredExceptions) {\n@@ -5645,2 +5800,3 @@\n-                        log.warning(\n-                                TreeInfo.diagnosticPositionFor(method, tree),\n+                        if (warn) {\n+                            log.warning(\n+                                    TreeInfo.diagnosticPositionFor(method, tree),\n@@ -5649,0 +5805,2 @@\n+                        }\n+                        return false;\n@@ -5652,1 +5810,1 @@\n-            return;\n+            return true;\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Check.java","additions":210,"deletions":52,"binary":false,"changes":262,"status":"modified"},{"patch":"@@ -118,0 +118,1 @@\n+    private final LocalProxyVarsGen localProxyVarsGen;\n@@ -157,0 +158,1 @@\n+        localProxyVarsGen = LocalProxyVarsGen.instance(context);\n@@ -424,39 +426,44 @@\n-        switch ((short)(sym.flags() & AccessFlags)) {\n-        case PRIVATE:\n-            return\n-                (env.enclClass.sym == sym.owner \/\/ fast special case\n-                 ||\n-                 env.enclClass.sym.outermostClass() ==\n-                 sym.owner.outermostClass()\n-                 ||\n-                 privateMemberInPermitsClauseIfAllowed(env, sym))\n-                &&\n-                sym.isInheritedIn(site.tsym, types);\n-        case 0:\n-            return\n-                (env.toplevel.packge == sym.owner.owner \/\/ fast special case\n-                 ||\n-                 env.toplevel.packge == sym.packge())\n-                &&\n-                isAccessible(env, site, checkInner)\n-                &&\n-                sym.isInheritedIn(site.tsym, types)\n-                &&\n-                notOverriddenIn(site, sym);\n-        case PROTECTED:\n-            return\n-                (env.toplevel.packge == sym.owner.owner \/\/ fast special case\n-                 ||\n-                 env.toplevel.packge == sym.packge()\n-                 ||\n-                 isProtectedAccessible(sym, env.enclClass.sym, site)\n-                 ||\n-                 \/\/ OK to select instance method or field from 'super' or type name\n-                 \/\/ (but type names should be disallowed elsewhere!)\n-                 env.info.selectSuper && (sym.flags() & STATIC) == 0 && sym.kind != TYP)\n-                &&\n-                isAccessible(env, site, checkInner)\n-                &&\n-                notOverriddenIn(site, sym);\n-        default: \/\/ this case includes erroneous combinations as well\n-            return isAccessible(env, site, checkInner) && notOverriddenIn(site, sym);\n+        ClassSymbol enclosingCsym = env.enclClass.sym;\n+        try {\n+            switch ((short)(sym.flags() & AccessFlags)) {\n+                case PRIVATE:\n+                    return\n+                            (env.enclClass.sym == sym.owner \/\/ fast special case\n+                                    ||\n+                                    env.enclClass.sym.outermostClass() ==\n+                                    sym.owner.outermostClass()\n+                                    ||\n+                                    privateMemberInPermitsClauseIfAllowed(env, sym))\n+                                &&\n+                                    sym.isInheritedIn(site.tsym, types);\n+                case 0:\n+                    return\n+                            (env.toplevel.packge == sym.owner.owner \/\/ fast special case\n+                                    ||\n+                                    env.toplevel.packge == sym.packge())\n+                                    &&\n+                                    isAccessible(env, site, checkInner)\n+                                    &&\n+                                    sym.isInheritedIn(site.tsym, types)\n+                                    &&\n+                                    notOverriddenIn(site, sym);\n+                case PROTECTED:\n+                    return\n+                            (env.toplevel.packge == sym.owner.owner \/\/ fast special case\n+                                    ||\n+                                    env.toplevel.packge == sym.packge()\n+                                    ||\n+                                    isProtectedAccessible(sym, env.enclClass.sym, site)\n+                                    ||\n+                                    \/\/ OK to select instance method or field from 'super' or type name\n+                                    \/\/ (but type names should be disallowed elsewhere!)\n+                                    env.info.selectSuper && (sym.flags() & STATIC) == 0 && sym.kind != TYP)\n+                                    &&\n+                                    isAccessible(env, site, checkInner)\n+                                    &&\n+                                    notOverriddenIn(site, sym);\n+                default: \/\/ this case includes erroneous combinations as well\n+                    return isAccessible(env, site, checkInner) && notOverriddenIn(site, sym);\n+            }\n+        } finally {\n+            env.enclClass.sym = enclosingCsym;\n@@ -1533,2 +1540,10 @@\n-                    if (env1.info.ctorPrologue && !isAllowedEarlyReference(pos, env1, (VarSymbol)sym))\n-                        return new RefBeforeCtorCalledError(sym);\n+                    if (env1.info.ctorPrologue && !isAllowedEarlyReference(pos, env1, (VarSymbol)sym)) {\n+                        if (!env.tree.hasTag(ASSIGN) || !TreeInfo.isIdentOrThisDotIdent(((JCAssign)env.tree).lhs)) {\n+                            if (!sym.isStrictInstance()) {\n+                                return new RefBeforeCtorCalledError(sym);\n+                            } else {\n+                                localProxyVarsGen.addStrictFieldReadInPrologue(env.enclMethod, sym);\n+                                return sym;\n+                            }\n+                        }\n+                    }\n@@ -4334,1 +4349,0 @@\n-                              kindName(ws.owner),\n@@ -5235,4 +5249,0 @@\n-\n-        boolean internal() {\n-            return internalResolution;\n-        }\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Resolve.java","additions":56,"deletions":46,"binary":false,"changes":102,"status":"modified"},{"patch":"@@ -786,1 +786,1 @@\n-    improperly formed type, some parameters are missing\n+    improperly formed type, some parameters are missing or misplaced\n@@ -2127,0 +2127,8 @@\n+# lint: serial\n+compiler.warn.serializable.value.class.without.write.replace.1=\\\n+    serializable value class does not declare, or inherits, a writeReplace method\n+\n+# lint: serial\n+compiler.warn.serializable.value.class.without.write.replace.2=\\\n+    serializable class does not declare, or inherits, a writeReplace method\n+\n@@ -2847,0 +2855,3 @@\n+compiler.misc.type.req.identity=\\\n+    a type with identity\n+\n@@ -3896,0 +3907,3 @@\n+compiler.misc.bad.access.flags=\\\n+    bad access flags combination: {0}\n+\n@@ -4237,0 +4251,22 @@\n+compiler.misc.feature.value.classes=\\\n+    value classes\n+\n+# 0: type, 1: type\n+compiler.err.value.type.has.identity.super.type=\\\n+    The identity type {1} cannot be a supertype of the value type {0}\n+\n+# 0: symbol, 1: type\n+compiler.err.concrete.supertype.for.value.class=\\\n+    The concrete class {1} is not allowed to be a super class of the value class {0} either directly or indirectly\n+\n+# 0: symbol, 1: symbol, 2: type\n+compiler.err.super.class.method.cannot.be.synchronized=\\\n+    The method {0} in the super class {2} of the value class {1} is synchronized. This is disallowed\n+\n+compiler.err.non.abstract.value.class.cant.be.sealed.or.non.sealed=\\\n+    ''sealed'' or ''non-sealed'' modifiers are only applicable to abstract value classes\n+\n+# 0: symbol\n+compiler.err.strict.field.not.have.been.initialized.before.super=\\\n+    strict field {0} is not initialized before the supertype constructor has been called\n+\n@@ -4267,0 +4303,3 @@\n+\n+compiler.warn.value.finalize=\\\n+    value classes should not have finalize methods, they are not invoked\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/resources\/compiler.properties","additions":40,"deletions":1,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -228,0 +228,3 @@\n+javac.opt.Xlint.desc.migration=\\\n+    Warn about issues related to migration of JDK classes.\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/resources\/javac.properties","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -246,0 +246,1 @@\n+        jdk.jdeps,\n@@ -255,0 +256,1 @@\n+        jdk.jdeps,\n","filename":"src\/jdk.compiler\/share\/classes\/module-info.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -107,0 +107,1 @@\n+runtime\/cds\/appcds\/redefineClass\/RedefineRunningMethods_Shared.java  8304168 generic-all\n@@ -127,0 +128,40 @@\n+\n+# Valhalla\n+runtime\/AccModule\/ConstModule.java 8294051 generic-all\n+runtime\/valhalla\/inlinetypes\/CircularityTest.java 8349037 generic-all\n+runtime\/valhalla\/inlinetypes\/verifier\/StrictInstanceFieldsTest.java CODETOOLS-7904031 generic-all\n+runtime\/valhalla\/inlinetypes\/verifier\/StrictStaticFieldsTest.java CODETOOLS-7904031 generic-all\n+\n+# Valhalla + COH\n+compiler\/c2\/autovectorization\/TestIndexOverflowIR.java                          8348568 generic-all\n+compiler\/c2\/irTests\/TestVectorConditionalMove.java                              8348568 generic-all\n+compiler\/c2\/irTests\/TestVectorizationMismatchedAccess.java                      8348568 generic-all\n+compiler\/c2\/irTests\/TestVectorizationNotRun.java                                8348568 generic-all\n+compiler\/c2\/TestCastX2NotProcessedIGVN.java                                     8348568 generic-all\n+compiler\/loopopts\/superword\/TestAlignVector.java                                8348568 generic-all\n+compiler\/loopopts\/superword\/TestAlignVector.java#NoAlignVector-COH              8348568 generic-all\n+compiler\/loopopts\/superword\/TestAlignVector.java#VerifyAlignVector-COH          8348568 generic-all\n+compiler\/loopopts\/superword\/TestIndependentPacksWithCyclicDependency.java       8348568 generic-all\n+compiler\/loopopts\/superword\/TestMulAddS2I.java                                  8348568 generic-all\n+compiler\/loopopts\/superword\/TestScheduleReordersScalarMemops.java               8348568 generic-all\n+compiler\/loopopts\/superword\/TestSplitPacks.java                                 8348568 generic-all\n+compiler\/loopopts\/superword\/TestUnorderedReductionPartialVectorization.java     8348568 generic-all\n+compiler\/vectorization\/TestFloatConversionsVector.java                          8348568 generic-all\n+compiler\/vectorization\/runner\/ArrayTypeConvertTest.java                         8348568 generic-all\n+compiler\/vectorization\/runner\/LoopCombinedOpTest.java                           8348568 generic-all\n+compiler\/vectorization\/runner\/VectorizationTestRunner.java                      8348568 generic-all\n+runtime\/FieldLayout\/TestOopMapSizeMinimal.java#no_coops_ccptr_coh               8348568 generic-all\n+\n+gc\/stress\/gcbasher\/TestGCBasherWithParallel.java                                8348568 generic-all\n+\n+gtest\/CompressedKlassGtest.java#use-zero-based-encoding-coh                     8348568 generic-all\n+gtest\/CompressedKlassGtest.java#use-zero-based-encoding-coh-large-class-space   8348568 generic-all\n+gtest\/MetaspaceGtests.java#UseCompactObjectHeaders                              8348568 generic-all\n+\n+runtime\/CompressedOops\/CompressedClassPointersEncodingScheme.java               8348568 generic-all\n+runtime\/FieldLayout\/BaseOffsets.java#no-coops-with-coh                          8348568 generic-all\n+runtime\/FieldLayout\/BaseOffsets.java#with-coop--with-coh                        8348568 generic-all\n+runtime\/cds\/TestDefaultArchiveLoading.java#coops_coh                            8348568 generic-all\n+runtime\/cds\/TestDefaultArchiveLoading.java#nocoops_coh                          8348568 generic-all\n+runtime\/cds\/appcds\/TestZGCWithCDS.java                                          8348568 generic-all\n+\n@@ -150,0 +191,31 @@\n+# Valhalla TODO:\n+serviceability\/jvmti\/valhalla\/HeapDump\/HeapDump.java 8317416 generic-all\n+\n+serviceability\/sa\/ClhsdbCDSCore.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbCDSJstackPrintAll.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbFindPC.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbInspect.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbLongConstant.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbJdis.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbJstack.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintAll.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintAs.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintStatics.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbSource.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbSymbol.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbWhere.java 8190936 generic-all\n+serviceability\/sa\/JhsdbThreadInfoTest.java 8190936 generic-all\n+serviceability\/sa\/TestClassDump.java 8190936 generic-all\n+serviceability\/sa\/TestClhsdbJstackLock.java 8190936 generic-all\n+serviceability\/sa\/TestCpoolForInvokeDynamic.java 8190936 generic-all\n+serviceability\/sa\/TestHeapDumpForInvokeDynamic.java 8190936 generic-all\n+serviceability\/sa\/TestHeapDumpForLargeArray.java 8190936 generic-all\n+serviceability\/sa\/TestIntConstant.java 8190936 generic-all\n+serviceability\/sa\/TestJhsdbJstackLock.java 8190936 generic-all\n+serviceability\/sa\/TestJmapCore.java 8190936 generic-all\n+serviceability\/sa\/TestJmapCoreMetaspace.java 8190936 generic-all\n+serviceability\/sa\/TestPrintMdo.java 8190936 generic-all\n+serviceability\/sa\/jmap-hprof\/JMapHProfLargeHeapTest.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbDumpclass.java 8190936 generic-all\n+\n+\n@@ -189,0 +261,2 @@\n+vmTestbase\/vm\/mlvm\/hiddenloader\/stress\/byteMutation\/Test.java 8317172 generic-all\n+\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":74,"deletions":0,"binary":false,"changes":74,"status":"modified"},{"patch":"@@ -49,1 +49,1 @@\n-  runtime\n+  runtime \\\n@@ -65,0 +65,8 @@\n+hotspot_valhalla = \\\n+  runtime\/valhalla \\\n+  compiler\/valhalla \\\n+  serviceability\/jvmti\/valhalla\n+\n+hotspot_valhalla_runtime = \\\n+  runtime\/valhalla\n+\n@@ -214,0 +222,1 @@\n+  compiler\/valhalla\/ \\\n@@ -255,0 +264,7 @@\n+\n+tier1_compiler_no_valhalla = \\\n+  :tier1_compiler_1 \\\n+  :tier1_compiler_2 \\\n+  :tier1_compiler_3 \\\n+  -compiler\/valhalla\n+\n@@ -407,0 +423,4 @@\n+tier1_runtime_no_valhalla = \\\n+  :tier1_runtime \\\n+  -runtime\/valhalla\n+\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":21,"deletions":1,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -72,2 +72,2 @@\n-                                             TestCommon.list(mainClass),\n-                                             unlockArg, logArg, nmtArg);\n+                TestCommon.list(mainClass),\n+                unlockArg, logArg, nmtArg);\n@@ -77,1 +77,1 @@\n-            .assertNormalExit(output -> {\n+                .assertNormalExit(output -> {\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/ArchiveRelocationTest.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -46,0 +46,1 @@\n+        final String noOptimizedModuleHandling = \"optimized module handling: disabled because archive was created without optimized module handling\";\n@@ -64,2 +65,4 @@\n-          .shouldMatch(versionPattern)\n-          .shouldMatch(\"aot,module.*Restored from archive: entry.0x.*name jdk.httpserver\");\n+          .shouldMatch(versionPattern);\n+        if (!oa.contains(noOptimizedModuleHandling)) {\n+            oa.shouldMatch(\"aot,module.*Restored from archive: entry.0x.*name jdk.httpserver\");\n+        }\n@@ -73,2 +76,4 @@\n-          .shouldContain(\"Mismatched values for property jdk.module.main: runtime jdk.compiler dump time jdk.httpserver\")\n-          .shouldContain(subgraphCannotBeUsed);\n+          .shouldContain(\"Mismatched values for property jdk.module.main: runtime jdk.compiler dump time jdk.httpserver\");\n+        if (!oa.contains(noOptimizedModuleHandling)) {\n+            oa.shouldContain(subgraphCannotBeUsed);\n+        }\n@@ -81,2 +86,4 @@\n-          .shouldContain(\"Mismatched values for property jdk.module.main: jdk.httpserver specified during dump time but not during runtime\")\n-          .shouldContain(subgraphCannotBeUsed);\n+          .shouldContain(\"Mismatched values for property jdk.module.main: jdk.httpserver specified during dump time but not during runtime\");\n+        if (!oa.contains(noOptimizedModuleHandling)) {\n+            oa.shouldContain(subgraphCannotBeUsed);\n+        }\n@@ -101,2 +108,4 @@\n-          .shouldMatch(versionPattern)\n-          .shouldContain(subgraphCannotBeUsed);\n+          .shouldMatch(versionPattern);\n+        if (!oa.contains(noOptimizedModuleHandling)) {\n+            oa.shouldContain(subgraphCannotBeUsed);\n+        }\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/jigsaw\/module\/ModuleOption.java","additions":17,"deletions":8,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -141,1 +141,9 @@\n-    jni\/nullCaller\n+    jni\/nullCaller \\\n+    valhalla\n+\n+# valhalla lworld tests\n+jdk_valhalla = \\\n+    java\/lang\/invoke \\\n+    valhalla \\\n+    java\/lang\/instrument\/valhalla\n+\n","filename":"test\/jdk\/TEST.groups","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2010, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2010, 2025, Oracle and\/or its affiliates. All rights reserved.\n","filename":"test\/langtools\/tools\/javac\/diags\/CheckResourceKeys.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+ * @ignore Verifier error\n","filename":"test\/langtools\/tools\/javac\/launcher\/SourceLauncherTest.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"}]}