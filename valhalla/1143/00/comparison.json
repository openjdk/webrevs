{"files":[{"patch":"@@ -83,1 +83,1 @@\n-    \/\/ float16ToShortBits that normalizes NaNs\n+    \/\/ float16ToShortBits that normalizes NaNs, c.f. floatToIntBits vs floatToRawIntBits\n@@ -89,0 +89,1 @@\n+    \/\/ valueOf(BigDecimal) -- main implementation could be package private in BigDecimal\n@@ -715,0 +716,13 @@\n+     *\n+     * For discussion and derivation of this property see:\n+     *\n+     * \"When Is Double Rounding Innocuous?\" by Samuel Figueroa\n+     * ACM SIGNUM Newsletter, Volume 30 Issue 3, pp 21-26\n+     * https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/221332.221334\n+     *\n+     * Figueroa's write-up refers to lecture notes by W. Kahan. Those\n+     * lectures notes are assumed to be these ones by Kahan and\n+     * others:\n+     *\n+     * https:\/\/www.arithmazium.org\/classroom\/lib\/Lecture_08_notes_slides.pdf\n+     * https:\/\/www.arithmazium.org\/classroom\/lib\/Lecture_09_notes_slides.pdf\n@@ -862,30 +876,107 @@\n-        \/\/ A simple scaling up to call a float or double fma doesn't\n-        \/\/ always work as double-rounding can occur and the sticky bit\n-        \/\/ information can be lost for rounding to a Float16 position.\n-        \/\/\n-        \/\/ The quantity:\n-        \/\/\n-        \/\/ convertToDouble(a)*convertToDouble(b) + convertToDouble(c)\n-        \/\/\n-        \/\/ will be an exact double value.\n-        \/\/\n-        \/\/ Note: the above conclusion is *incorrect*. The exponent of\n-        \/\/ the product of a*b can be so large that Float16.MIN_VALUE\n-        \/\/ cannot be held in a single double.\n-        \/\/\n-        \/\/ However, Float16 values with the smallest and largest\n-        \/\/ exponents can be held in a single double with precision to\n-        \/\/ spare. Therefore, all the hard rounding cases should be\n-        \/\/ covered, but some more analysis is needed to verify the\n-        \/\/ correctness of that approach.\n-        \/\/\n-        \/\/ Case analysis is needed with c is large compared to a*b.\n-        \/\/\n-        \/\/ The number of significand\n-        \/\/ bits in double, 53, is greater than the, maximum difference\n-        \/\/ in exponent values between bit positions of minimum and\n-        \/\/ maximum magnitude for Float16. Therefore, performing a*b+c\n-        \/\/ in double and then doing a single rounding of that value to\n-        \/\/ Float16 will implement this operation.\n-\n-        return valueOf( (a.doubleValue() * b.doubleValue()) +  c.doubleValue());\n+        \/*\n+         * In-progress explanation and discussion of the\n+         * implementation. Promoting the input arguments to\n+         * float\/double and calculating (exactProdct + c) in double\n+         * and rounding that double to Float16 is correct for _at\n+         * least_ most sets of arguments. It may be correct for all\n+         * arguments, pending further analysis. If it not correct,\n+         * other computations will be done in those cases.\n+         *\n+         * The 2sum algorithm can be used to extract the low-order\n+         * value of a add\/substract that were rounded away.\n+         *\n+         * -----\n+         *\n+         * When the numerical value of (a*b) + c is stored exactly in\n+         * a double, after a single rounding to Float16, the answer is\n+         * of necessity correct since the one double -> Float16\n+         * conversion is the only source of numerical error.\n+         *\n+         * However, for some inputs, the intermediate product-sum will\n+         * not be exact and additional analysis is needed -- and\n+         * currently underway -- to verify no corrective computation\n+         * is needed to return the proper answer.\n+         *\n+         * The following analysis will rely on the range of bit\n+         * positions representable in the intermediate\n+         * product-sum. For a Float16 value, the bit positions\n+         * representable in the format range from 2^(-14), MIN_VALUE,\n+         * to 2^15, the leading bit position of MAX_VALUE. Including\n+         * the implicit bit, Float16 has 11 bits of precision.\n+         *\n+         * For the double format, there are 53 bits of precision\n+         * (including the implicit bit), and the exponent range goes\n+         * from -1022 to 1023.\n+         *\n+         * For the product a*b of Float16 inputs, the range of\n+         * exponents for nonzero finite results goes from 2^(-28)\n+         * (from MIN_VALUE squared) to 2^31 (from the exact value of\n+         * MAX_VALUE squared). This full range of exponent positions,\n+         * (31 -(-28) + 1 ) = 60 exceeds the precision of\n+         * double. However, only the product a*b can exceed the\n+         * exponent range of Float16. Therefore, there are three main\n+         * cases to consider:\n+         *\n+         * 1) Large exponent product\n+         *\n+         * The magnitude of the overflow threshold for Float16 is:\n+         *\n+         * MAX_VALUE + 1\/2 * ulp(MAX_VALUE) =  0x1.ffcp15 + 0x0.002p15 = 0x1.ffep15\n+         *\n+         * Therefore, any product greater than 0x1.ffep15 + MAX_VALUE\n+         * = 0x1.ffdp16 will certainly overflow (under round to\n+         * nearest) since adding in c = -MAX_VALUE will still be above\n+         * the overflow threshold.\n+         *\n+         * With a precision of 53 bits and much large exponent range,\n+         * even if the product has an exponent of 31, the smallest\n+         * Float16 that could be added in has an exponent of -14,\n+         * which only requires holding 31 -(-14) + 1 = 46 contiguous\n+         * bit positions, which is within the precision of double.\n+         *\n+         * 2) Exponent of product is within the range of normal\n+         * Float16 values\n+         *\n+         * The exact product has at most 22 contiguous bits in its\n+         * logical significand. The third number being added in has\n+         * at most 11 contiguous bits in its significand and the\n+         * lowest bit position that could be set is\n+         * 2^(-14). Therefore, when the product has the maximum\n+         * in-range exponent, 2^15, a single double has enough\n+         * precision to hold down to the smallest subnormal bit\n+         * position, 15 - (-14) + 1 = 30 < 53. If the product was\n+         * large and overflowed when the third operand was added, this\n+         * would cause the exponent to increase to 16, which is within\n+         * the range of double, so the product-sum is exact and will\n+         * be correct when rounded to Float16.\n+         *\n+         * 3) Exponent of product is in the range of subnormal values or smaller.\n+         *\n+         * The smallest exponent possible in a product is 2^(-48). The\n+         * precision of double can then hold other bit positions up to\n+         * -48 + 53 -1 = 4.\n+         *\n+         * Further case analysis to-do.\n+         *\/\n+\n+        \/\/ product is numerically exact\n+        double product = (double)(a.floatValue() * b.floatValue());\n+        double c_double = c.doubleValue();\n+        \/\/ productSum exact in many cases, identify non-exact cases\n+        \/\/ below for further computation.\n+        double productSum = product + c_double;\n+\n+\/\/         if (Double.isFinite(product) &&\n+\/\/             Double.isFinite(c_double) &&\n+\/\/             (product != 0.0) &&\n+\/\/             !exactSum(product, c_double, productSum) ) {\n+\/\/             int productExponent = Math.getExponent(product);\n+\/\/             assert productExponent <= -15;  \/\/ Might be off by one.\n+\/\/             assert Math.getExponent(c_double) >=\n+\/\/                 Math.getExponent(product) + 52 - 10 - 1: \"exponent = \" + Math.getExponent(c_double); \/\/ Might be off by a few\n+\/\/             System.out.println(String.format(\"Extra work? %a * %a + %a => product %a, rounded %a\",\n+\/\/                                              a.floatValue(), b.floatValue(), c.floatValue(),\n+\/\/                                              product, productSum));\n+\/\/             \/\/ throw new UnsupportedOperationException(\"tbd\");\n+\/\/         }\n+        return valueOf(productSum);\n@@ -894,0 +985,15 @@\n+\/\/     private static boolean exactSum(double a, double b, double s) {\n+\/\/         \/\/ 2sum algorithm\n+\/\/         \/\/\n+\/\/         \/\/ After the computation below, the exact sum of (a + b) is in\n+\/\/         \/\/ (s + t) where s contains all the high-order\n+\/\/         \/\/ bits. Therefore, if t is zero, the sum in s itself is\n+\/\/         \/\/ exact.\n+\/\/         double a_prime = s - b;\n+\/\/         double b_prime = s - a_prime;\n+\/\/         double delta_a = a - a_prime;\n+\/\/         double delta_b = b - b_prime;\n+\/\/         double t = delta_a + delta_b;\n+\/\/         return t == 0.0;\n+\/\/     }\n+\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Float16.java","additions":137,"deletions":31,"binary":false,"changes":168,"status":"modified"},{"patch":"@@ -26,1 +26,1 @@\n- * @bug 8329817\n+ * @bug 8329817 8334432\n@@ -383,0 +383,1 @@\n+            testRounding();\n@@ -512,0 +513,50 @@\n+        private static void testRounding() {\n+            final float ulpOneFp16 = ulp(valueOf(1.0f)).floatValue();\n+\n+            float [][] testCases = {\n+                \/\/ The product is equal to\n+                \/\/ (MAX_VALUE + 1\/2 * ulp(MAX_VALUE) + MAX_VALUE = (0x1.ffcp15 + 0x0.002p15)+ 0x1.ffcp15\n+                \/\/ so overflows.\n+                {0x1.3p1f, 0x1.afp15f, -MAX_VAL_FP16,\n+                 InfinityF},\n+\n+                \/\/ Product exactly equals 0x1.ffep15, the overflow\n+                \/\/ threshold; subtracting a non-zero finite value will\n+                \/\/ result in MAX_VALUE, adding zero or a positive\n+                \/\/ value will overflow.\n+                {0x1.2p10f, 0x1.c7p5f, -0x1.0p-14f,\n+                 MAX_VAL_FP16},\n+\n+                {0x1.2p10f, 0x1.c7p5f, -0.0f,\n+                 InfinityF},\n+\n+                {0x1.2p10f, 0x1.c7p5f, +0.0f,\n+                 InfinityF},\n+\n+                {0x1.2p10f, 0x1.c7p5f, +0x1.0p-14f,\n+                 InfinityF},\n+\n+                {0x1.2p10f, 0x1.c7p5f, InfinityF,\n+                 InfinityF},\n+\n+                \/\/ PRECISION bits in the subnormal intermediate product\n+                {0x1.ffcp-14f, 0x1.0p-24f, 0x1.0p13f, \/\/ Can be held exactly\n+                 0x1.0p13f},\n+\n+                {0x1.ffcp-14f, 0x1.0p-24f, 0x1.0p14f, \/\/ *Cannot* be held exactly\n+                 0x1.0p14f},\n+\n+                \/\/ Check values where the exact result cannot be\n+                \/\/ exactly stored in a double.\n+                {0x1.0p-24f, 0x1.0p-24f, 0x1.0p10f,\n+                 0x1.0p10f},\n+\n+                {0x1.0p-24f, 0x1.0p-24f, 0x1.0p14f,\n+                 0x1.0p14f},\n+            };\n+\n+            for (float[] testCase: testCases) {\n+                testFusedMacCase(testCase[0], testCase[1], testCase[2], testCase[3]);\n+            }\n+        }\n+\n","filename":"test\/jdk\/java\/lang\/Float16\/BasicFloat16ArithTests.java","additions":52,"deletions":1,"binary":false,"changes":53,"status":"modified"}]}