{"files":[{"patch":"@@ -877,7 +877,6 @@\n-         * In-progress explanation and discussion of the\n-         * implementation. Promoting the input arguments to\n-         * float\/double and calculating (exactProdct + c) in double\n-         * and rounding that double to Float16 is correct for _at\n-         * least_ most sets of arguments. It may be correct for all\n-         * arguments, pending further analysis. If it not correct,\n-         * other computations will be done in those cases.\n+         * The double format has sufficient precision that a Float16\n+         * fma can be computed by doing the arithmetic in double, with\n+         * one rounding error for the sum, and then a second rounding\n+         * error to round the product-sum to Float16. In pseudocode,\n+         * this method is equivalent to the following code, assuming\n+         * casting was defined between Float16 and double:\n@@ -885,2 +884,3 @@\n-         * The 2sum algorithm can be used to extract the low-order\n-         * value of a add\/substract that were rounded away.\n+         * double product = (double)a * (double)b;  \/\/ Always exact\n+         * double productSum = product + (double)c;\n+         * return (Float16)produdctSum;\n@@ -888,1 +888,2 @@\n-         * -----\n+         * (Note that a similar relationship does *not* hold between\n+         * the double format and computing a float fma.)\n@@ -890,4 +891,35 @@\n-         * When the numerical value of (a*b) + c is stored exactly in\n-         * a double, after a single rounding to Float16, the answer is\n-         * of necessity correct since the one double -> Float16\n-         * conversion is the only source of numerical error.\n+         * Below is a sketch of the proof that simple double\n+         * arithmetic can be used to implement a correctly rounded\n+         * Float16 fma.\n+         *\n+         * ----------------------\n+         *\n+         * As preliminaries, the handling of NaN and Infinity\n+         * arguments falls out as a consequence of general operation\n+         * of non-finite values by double * and +. Any NaN argument to\n+         * fma will lead to a NaN result, infinities will propagate or\n+         * get turned into NaN as appropriate, etc.\n+         *\n+         * One or more zero arguments are also handled correctly,\n+         * including the propagation of the sign of zero if all three\n+         * arguments are zero.\n+         *\n+         * The double format has 53 logical bits of precision and its\n+         * exponent range goes from -1022 to 1023. The Float16 format\n+         * has 11 bits of logical precision and its exponent range\n+         * goes from -14 to 15. Therefore, the bit positions\n+         * representable in the Float16 format range from the\n+         * subnormal 2^(-24), MIN_VALUE, to 2^15, the leading bit\n+         * position of MAX_VALUE.\n+         *\n+         * Consequently, a double can hold the exact sum of any two\n+         * Float16 values as the maximum difference in exponents of\n+         * Float16 values less than the precision width of double.\n+         *\n+         * In cases where the numerical value of (a * b) + c is\n+         * computed exactly in a double, after a single rounding to\n+         * Float16, the result is of necessity correct since the one\n+         * double -> Float16 conversion is the only source of\n+         * numerical error. The operation as implemented in those\n+         * cases would be equivalent to rounding the infinitely precise\n+         * value to the result format, etc.\n@@ -896,3 +928,3 @@\n-         * not be exact and additional analysis is needed -- and\n-         * currently underway -- to verify no corrective computation\n-         * is needed to return the proper answer.\n+         * *not* be exact and additional analysis is needed to justify\n+         * not having any corrective computation to compensate for\n+         * intermediate rounding errors.\n@@ -902,8 +934,1 @@\n-         * product-sum. For a Float16 value, the bit positions\n-         * representable in the format range from 2^(-14), MIN_VALUE,\n-         * to 2^15, the leading bit position of MAX_VALUE. Including\n-         * the implicit bit, Float16 has 11 bits of precision.\n-         *\n-         * For the double format, there are 53 bits of precision\n-         * (including the implicit bit), and the exponent range goes\n-         * from -1022 to 1023.\n+         * product-sum.\n@@ -920,1 +945,1 @@\n-         * 1) Large exponent product\n+         * 1) Large exponent product, exponent > Float16.MAX_EXPONENT\n@@ -931,5 +956,3 @@\n-         * With a precision of 53 bits and much large exponent range,\n-         * even if the product has an exponent of 31, the smallest\n-         * Float16 that could be added in has an exponent of -14,\n-         * which only requires holding 31 -(-14) + 1 = 46 contiguous\n-         * bit positions, which is within the precision of double.\n+         * If the exponent of the product is 15 or 16, the smallest\n+         * subnormal Float16 is 2^-24 and the ~40 bit wide range bit\n+         * positions would fit in a single double exactly.\n@@ -937,2 +960,2 @@\n-         * 2) Exponent of product is within the range of normal\n-         * Float16 values\n+         * 2) Exponent of product is within the range of _normal_\n+         * Float16 values; Float16.MIN_EXPONENT <=  exponent <= Float16.MAX_EXPONENT\n@@ -944,1 +967,1 @@\n-         * 2^(-14). Therefore, when the product has the maximum\n+         * 2^(-24). Therefore, when the product has the maximum\n@@ -947,1 +970,1 @@\n-         * position, 15 - (-14) + 1 = 30 < 53. If the product was\n+         * position, 15 - (-24) + 1 = 40 < 53. If the product was\n@@ -953,1 +976,10 @@\n-         * 3) Exponent of product is in the range of subnormal values or smaller.\n+         * 3) Exponent of product is in the range of subnormal values or smaller,\n+         * exponent < Float16.MIN_EXPONENT\n+         *\n+         * The smallest exponent possible in a product is 2^(-48).\n+         * For moderately sized Float16 values added to the product,\n+         * with a leading exponent of about 4, the sum will not be\n+         * exact. Therefore, an analysis is needed to determine if the\n+         * double-rounding is benign or would lead to a different\n+         * final Float16 result. Double rounding an lead to a\n+         * different result in two cases:\n@@ -955,3 +987,9 @@\n-         * The smallest exponent possible in a product is 2^(-48). The\n-         * precision of double can then hold other bit positions up to\n-         * -48 + 53 -1 = 4.\n+         * 1) The first rounding from the exact value to the extended\n+         * precision (here `double`) happens to be directed _toward_ 0\n+         * to a value exactly midway between two adjacent working\n+         * precision (here `Float16`) values, followed by a second\n+         * rounding from there which again happens to be directed\n+         * _toward_ 0 to one of these values (the one with lesser\n+         * magnitude).  A single rounding from the exact value to the\n+         * working precision, in contrast, rounds to the value with\n+         * larger magnitude.\n@@ -959,1 +997,54 @@\n-         * Further case analysis to-do.\n+         * 2) Symmetrically, the first rounding to the extended\n+         * precision happens to be directed _away_ from 0 to a value\n+         * exactly midway between two adjacent working precision\n+         * values, followed by a second rounding from there which\n+         * again happens to be directed _away_ from 0 to one of these\n+         * values (the one with larger magnitude).  However, a single\n+         * rounding from the exact value to the working precision\n+         * rounds to the value with lesser magnitude.\n+         *\n+         * If the double rounding occurs in other cases, it is\n+         * innocuous, returning the same value as a single rounding to\n+         * the final format. Therefore, it is sufficient to show that\n+         * the first rounding to double does not occur at the midpoint\n+         * of two adjacent Float16 values:\n+         *\n+         * 1) If a, b and c have the same sign, the sum a*b + c has a\n+         * significand with a large gap of 20 or more 0s between the\n+         * bits of the significand of c to the left (at most 11 bits)\n+         * and those of the product a*b to the right (at most 22\n+         * bits).  The rounding bit for the final working precision of\n+         * `float16` is the leftmost 0 in the gap.\n+         *\n+         *   a) If rounding to `double` is directed toward 0, all the\n+         *   0s in the gap are preserved, thus the `Float16` rounding\n+         *   bit is unaffected and remains 0. This means that the\n+         *   `double` value is _not_ the midpoint of two adjacent\n+         *   `float16` values, so double rounding is harmless.\n+         *\n+         *   b) If rounding to `double` is directed away form 0, the\n+         *   rightmost 0 in the gap might be replaced by a 1, but the\n+         *   others are unaffected, including the `float16` rounding\n+         *   bit. Again, this shows that the `double` value is _not_\n+         *   the midpoint of two adjacent `float16` values, and double\n+         *   rounding is innocuous.\n+         *\n+         * 2) If a, b and c have opposite signs, in the sum a*b + c\n+         * the long gap of 0s above is replaced by a long gap of\n+         * 1s. The `float16` rounding bit is the leftmost 1 in the\n+         * gap, or the second leftmost 1 iff c is a power of 2. In\n+         * both cases, the rounding bit is followed by at least\n+         * another 1.\n+         *\n+         *   a) If rounding to `double` is directed toward 0, the\n+         *   `float16` rounding bit and its follower are preserved and\n+         *   both 1, so the `double` value is _not_ the midpoint of\n+         *   two adjacent `float16` values, and double rounding is\n+         *   harmless.\n+         *\n+         *   b) If rounding to `double` is directed away from 0, the\n+         *   `float16` rounding bit and its follower are either\n+         *   preserved (both 1), or both switch to 0. Either way, the\n+         *   `double` value is again _not_ the midpoint of two\n+         *   adjacent `float16` values, and double rounding is\n+         *   harmless.\n@@ -962,1 +1053,3 @@\n-        \/\/ product is numerically exact\n+        \/\/ product is numerically exact in float before the cast to\n+        \/\/ double; not necessary to widen to double before the\n+        \/\/ multiply.\n@@ -964,19 +1057,1 @@\n-        double c_double = c.doubleValue();\n-        \/\/ productSum exact in many cases, identify non-exact cases\n-        \/\/ below for further computation.\n-        double productSum = product + c_double;\n-\n-\/\/         if (Double.isFinite(product) &&\n-\/\/             Double.isFinite(c_double) &&\n-\/\/             (product != 0.0) &&\n-\/\/             !exactSum(product, c_double, productSum) ) {\n-\/\/             int productExponent = Math.getExponent(product);\n-\/\/             assert productExponent <= -15;  \/\/ Might be off by one.\n-\/\/             assert Math.getExponent(c_double) >=\n-\/\/                 Math.getExponent(product) + 52 - 10 - 1: \"exponent = \" + Math.getExponent(c_double); \/\/ Might be off by a few\n-\/\/             System.out.println(String.format(\"Extra work? %a * %a + %a => product %a, rounded %a\",\n-\/\/                                              a.floatValue(), b.floatValue(), c.floatValue(),\n-\/\/                                              product, productSum));\n-\/\/             \/\/ throw new UnsupportedOperationException(\"tbd\");\n-\/\/         }\n-        return valueOf(productSum);\n+        return valueOf(product + c.doubleValue());\n@@ -985,15 +1060,0 @@\n-\/\/     private static boolean exactSum(double a, double b, double s) {\n-\/\/         \/\/ 2sum algorithm\n-\/\/         \/\/\n-\/\/         \/\/ After the computation below, the exact sum of (a + b) is in\n-\/\/         \/\/ (s + t) where s contains all the high-order\n-\/\/         \/\/ bits. Therefore, if t is zero, the sum in s itself is\n-\/\/         \/\/ exact.\n-\/\/         double a_prime = s - b;\n-\/\/         double b_prime = s - a_prime;\n-\/\/         double delta_a = a - a_prime;\n-\/\/         double delta_b = b - b_prime;\n-\/\/         double t = delta_a + delta_b;\n-\/\/         return t == 0.0;\n-\/\/     }\n-\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Float16.java","additions":135,"deletions":75,"binary":false,"changes":210,"status":"modified"},{"patch":"@@ -380,0 +380,1 @@\n+            testZeroNanInfCombos();\n@@ -386,0 +387,18 @@\n+        private static void testZeroNanInfCombos() {\n+            float [] testInputs = {\n+                Float.NaN,\n+                -InfinityF,\n+                +InfinityF,\n+                -0.0f,\n+                +0.0f,\n+            };\n+\n+            for (float i : testInputs) {\n+                for (float j : testInputs) {\n+                    for (float k : testInputs) {\n+                        testFusedMacCase(i, j, k, Math.fma(i, j, k));\n+                    }\n+                }\n+            }\n+        }\n+\n","filename":"test\/jdk\/java\/lang\/Float16\/BasicFloat16ArithTests.java","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"}]}