{"files":[{"patch":"@@ -1659,0 +1659,5 @@\n+    if (!field->is_null_free() && !vk->nullable_atomic_layout_is_natural()) {\n+      bailout(\"missing support for unnatural nullable atomic layout\");\n+      return;\n+    }\n+\n@@ -2106,0 +2111,5 @@\n+    if (!field->is_null_free() && !vk->nullable_atomic_layout_is_natural()) {\n+      bailout(\"missing support for unnatural nullable atomic layout\");\n+      return;\n+    }\n+\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -109,0 +109,5 @@\n+bool ciInlineKlass::nullable_atomic_layout_is_natural() const {\n+  assert(has_nullable_atomic_layout(), \"must have the layout to query its nature\");\n+  GUARDED_VM_ENTRY(return get_InlineKlass()->nullable_atomic_layout_is_natural();)\n+}\n+\n@@ -115,0 +120,1 @@\n+  assert( null_free || nullable_atomic_layout_is_natural(), \"Cannot access the nullable atomic layout naturally\");\n","filename":"src\/hotspot\/share\/ci\/ciInlineKlass.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -78,0 +78,4 @@\n+\n+  \/\/ Whether we can access a nullable atomic field of this type using a single memory instruction.\n+  \/\/ Otherwise, we must access the payload and the null marker parts separately. See InlineKlass.\n+  bool nullable_atomic_layout_is_natural() const;\n","filename":"src\/hotspot\/share\/ci\/ciInlineKlass.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -94,1 +94,1 @@\n-      *alignment = *size;\n+      *alignment = vk->payload_alignment();\n@@ -1147,0 +1147,1 @@\n+    int required_alignment = _payload_alignment;\n@@ -1152,0 +1153,1 @@\n+        required_alignment = MAX2(required_alignment, atomic_size);\n@@ -1194,0 +1196,1 @@\n+        required_alignment = MAX2(required_alignment, nullable_size);\n@@ -1195,4 +1198,12 @@\n-        \/\/ If the nullable layout is rejected, the NULL_MARKER block should be removed\n-        \/\/ from the layout, otherwise it will appear anyway if the layout is printer\n-        if (!_is_empty_inline_class) {  \/\/ empty values don't have a dedicated NULL_MARKER block\n-          _layout->remove_null_marker();\n+        if (_atomic_layout_size_in_bytes > 0 && _nonstatic_oopmap_count == 0) {\n+          \/\/ Don't do this if the payload has an oop, storing null ignores the payload, which may\n+          \/\/ result in the objects there being unnecessarily kept by the GC (a.k.a memory leak)\n+          _nullable_layout_size_in_bytes = _atomic_layout_size_in_bytes + 1;\n+          _null_marker_offset = null_marker_offset;\n+        } else {\n+          \/\/ If the nullable layout is rejected, the NULL_MARKER block should be removed\n+          \/\/ from the layout, otherwise it will appear anyway if the layout is printer\n+          if (!_is_empty_inline_class) {  \/\/ empty values don't have a dedicated NULL_MARKER block\n+            _layout->remove_null_marker();\n+          }\n+          _null_marker_offset = -1;\n@@ -1200,1 +1211,0 @@\n-        _null_marker_offset = -1;\n@@ -1210,7 +1220,1 @@\n-    int required_alignment = _payload_alignment;\n-    if (has_atomic_layout() && _payload_alignment < atomic_layout_size_in_bytes()) {\n-      required_alignment = atomic_layout_size_in_bytes();\n-    }\n-    if (has_nullable_atomic_layout() && _payload_alignment < nullable_layout_size_in_bytes()) {\n-      required_alignment = nullable_layout_size_in_bytes();\n-    }\n+    assert(is_power_of_2(required_alignment), \"%s does not have a valid alignment: %d\", _classname->as_utf8(), required_alignment);\n","filename":"src\/hotspot\/share\/classfile\/fieldLayoutBuilder.cpp","additions":17,"deletions":13,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -43,0 +43,1 @@\n+#include \"oops\/layoutKind.hpp\"\n@@ -49,0 +50,1 @@\n+#include \"runtime\/orderAccess.hpp\"\n@@ -54,0 +56,1 @@\n+#include \"utilities\/powerOfTwo.hpp\"\n@@ -191,1 +194,1 @@\n-    if (is_payload_marked_as_null((address)src)) {\n+      if (is_payload_marked_as_null((address)src)) {\n@@ -197,0 +200,1 @@\n+        assert(nullable_atomic_layout_is_natural(), \"classes with unnatural nullable layout should not contain oops\");\n@@ -203,4 +207,9 @@\n-        \/\/ Copy has to be performed, even if this is an empty value, because of the null marker\n-        mark_payload_as_non_null((address)src);\n-        if (dest_is_initialized) {\n-          HeapAccess<>::value_copy(src, dst, this, lk);\n+        if (!nullable_atomic_layout_is_natural()) {\n+          \/\/ Copy the payload and the null marker separately\n+          if (dest_is_initialized) {\n+            HeapAccess<>::value_copy(src, dst, this, LayoutKind::ATOMIC_FLAT);\n+          } else {\n+            HeapAccess<IS_DEST_UNINITIALIZED>::value_copy(src, dst, this, LayoutKind::ATOMIC_FLAT);\n+          }\n+          OrderAccess::release();\n+          mark_payload_as_non_null((address)dst);\n@@ -208,1 +217,7 @@\n-          HeapAccess<IS_DEST_UNINITIALIZED>::value_copy(src, dst, this, lk);\n+          \/\/ Copy has to be performed, even if this is an empty value, because of the null marker\n+          mark_payload_as_non_null((address)src);\n+          if (dest_is_initialized) {\n+            HeapAccess<>::value_copy(src, dst, this, lk);\n+          } else {\n+            HeapAccess<IS_DEST_UNINITIALIZED>::value_copy(src, dst, this, lk);\n+          }\n@@ -231,0 +246,11 @@\n+  assert(is_layout_supported(lk), \"Unsupported layout\");\n+  if (lk == LayoutKind::NULLABLE_ATOMIC_FLAT && !has_nullable_atomic_layout()) {\n+    \/\/ The 2 accesses acts as if it is a single load if the stores coordinate accordingly\n+    if (is_payload_marked_as_null((address)((char*)(oopDesc*)src + offset))) {\n+      return nullptr;\n+    }\n+\n+    OrderAccess::acquire();\n+    lk = LayoutKind::ATOMIC_FLAT;\n+  }\n+\n","filename":"src\/hotspot\/share\/oops\/inlineKlass.cpp","additions":32,"deletions":6,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"utilities\/powerOfTwo.hpp\"\n@@ -38,0 +39,5 @@\n+\/**\n+  There are 2 ways to access a nullable atomic field or array element. If the payload including the\n+  null marker fits into a jlong, then we can just access the element as a whole. Otherwise, we can\n+  try another strategy, since the payload is only relevant if the null marker is 1. We can achieve\n+  a field that is accessed as if it is atomic even if the access consists of 2 native accesses.\n@@ -39,0 +45,45 @@\n+  A store of a not-null Long into a nullable Long field can be executed as:\n+\n+    store field.value;\n+    release_fence;\n+    store field.null_marker;\n+\n+  and the store of a null into that field will be:\n+\n+    store field.null_marker;\n+\n+  While, a load can be executed as:\n+\n+    load field.null_marker;\n+    acquire_fence;\n+    load field.value;\n+\n+  What we need to prove is that, given n concurrent stores, then:\n+\n+  1. The final state of the memory must be one of the executed stores:\n+    Consider the stores into the null marker:\n+    - If the last state of the null marker is 0, then the field is null\n+    - If the last state of the null marker is 1, then the field is non-null. In this case, only the\n+      threads that store non-null Long objects touch the memory of value. One of which would be the\n+      last state of the memory here. And it is as if we have a single non-null store that is the\n+      last state.\n+\n+  Note that the fences are irrelevant for these conditions.\n+\n+  2. Given a concurrent load, then it must either observe the initial state, or 1 of the\n+     stores that is executing:\n+\n+    - If it observes the null marker being 0, then it observes field being null. In this case, only\n+      the null marker is relevant, and it is trivially atomic.\n+    - If it observes the null marker being 1, then it observes field being non-null. In this case,\n+      if the initial state is null, we must observe the null marker being stored by 1 of the\n+      threads. And since we have fences, we must at least observe the value stored by that thread\n+      (or another thread, the point here is that we cannot observe the value in its initial state).\n+      Otherwise, the original state is non-null, we must observe the initial value or one of the\n+      values stored by the threads that try to store non-null.\n+\n+  As a result, we can see that in any case, the field accesses act as it they are atomic.\n+\n+  Note that a store of null to a flattened field ignores the payload, so we avoid flattening like\n+  this if the class has oop fields because they can leak.\n+*\/\n@@ -160,0 +211,5 @@\n+  bool nullable_atomic_layout_is_natural() const {\n+    assert(has_nullable_atomic_layout(), \"must have the layout the query its nature\");\n+    return is_power_of_2(nullable_atomic_size_in_bytes());\n+  }\n+\n","filename":"src\/hotspot\/share\/oops\/inlineKlass.hpp","additions":56,"deletions":0,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -1567,1 +1567,17 @@\n-  BasicType payload_bt = _vk->atomic_size_to_basic_type(_null_free);\n+  bool payload_no_null_marker = _null_free;\n+  if (!_null_free && !_vk->nullable_atomic_layout_is_natural()) {\n+    \/\/ Cannot access the whole element in 1 instruction, use 2 memory accesses in a way that seems\n+    \/\/ atomic, see InlineKlass\n+    ProjNode* proj_out = proj_out_or_null(TypeFunc::Parms + _vk->nof_nonstatic_fields());\n+    if (proj_out != nullptr) {\n+      Node* null_marker_ptr = kit.basic_plus_adr(base, ptr, _vk->null_marker_offset_in_payload());\n+      const TypePtr* null_marker_ptr_type = null_marker_ptr->Value(&igvn)->is_ptr();\n+      igvn.set_type(null_marker_ptr, null_marker_ptr_type);\n+      Node* null_marker_value = kit.access_load_at(base, null_marker_ptr, null_marker_ptr_type, TypeInt::BOOL, T_BOOLEAN, _decorators);\n+      igvn.replace_node(proj_out, null_marker_value);\n+      kit.insert_mem_bar(Op_MemBarAcquire);\n+    }\n+    payload_no_null_marker = true;\n+  }\n+\n+  BasicType payload_bt = _vk->atomic_size_to_basic_type(payload_no_null_marker);\n@@ -1583,1 +1599,1 @@\n-  expand_projs_atomic(igvn, kit.control(), payload);\n+  expand_projs_atomic(igvn, kit.control(), payload, payload_no_null_marker);\n@@ -1644,2 +1660,2 @@\n-void LoadFlatNode::expand_projs_atomic(PhaseIterGVN& igvn, Node* ctrl, Node* payload) {\n-  BasicType payload_bt = _vk->atomic_size_to_basic_type(_null_free);\n+void LoadFlatNode::expand_projs_atomic(PhaseIterGVN& igvn, Node* ctrl, Node* payload, bool payload_no_null_marker) {\n+  BasicType payload_bt = _vk->atomic_size_to_basic_type(payload_no_null_marker);\n@@ -1659,1 +1675,1 @@\n-  if (!_null_free) {\n+  if (!payload_no_null_marker) {\n@@ -1673,0 +1689,4 @@\n+  if (payload_bt == value_bt) {\n+    return payload;\n+  }\n+\n@@ -1742,1 +1762,1 @@\n-    Node* store = kit.access_store_at(base, field_ptr, field_ptr_type, field_value, igvn.type(field_value), field->type()->basic_type(), _decorators);\n+    kit.access_store_at(base, field_ptr, field_ptr_type, field_value, igvn.type(field_value), field->type()->basic_type(), _decorators);\n@@ -1750,1 +1770,1 @@\n-    Node* store = kit.access_store_at(base, null_marker_ptr, null_marker_ptr_type, null_marker_value, TypeInt::BOOL, T_BOOLEAN, _decorators);\n+    kit.access_store_at(base, null_marker_ptr, null_marker_ptr_type, null_marker_value, TypeInt::BOOL, T_BOOLEAN, _decorators);\n@@ -1778,0 +1798,1 @@\n+  ciInlineKlass* vk = igvn.type(value)->inline_klass();\n@@ -1779,3 +1800,30 @@\n-  int oop_off_1 = -1;\n-  int oop_off_2 = -1;\n-  Node* payload = convert_to_payload(igvn, kit.control(), value, _null_free, oop_off_1, oop_off_2);\n+  if (!_null_free && !vk->nullable_atomic_layout_is_natural()) {\n+    \/\/ Cannot access the whole element in 1 instruction, use 2 memory accesses in a way that seems\n+    \/\/ atomic, see InlineKlass\n+    Node* merge = new RegionNode(3);\n+    igvn.set_type(merge, Type::CONTROL);\n+    igvn.record_for_igvn(merge);\n+    Node* mem_phi = new PhiNode(merge, Type::MEMORY, TypePtr::BOTTOM);\n+    igvn.set_type(mem_phi, Type::MEMORY);\n+    igvn.record_for_igvn(mem_phi);\n+\n+    Node* null_ctl = kit.top();\n+    Node* notnull_value = kit.null_check_oop(value, &null_ctl);\n+    Node* before_mem = kit.reset_memory();\n+    merge->init_req(1, null_ctl);\n+    mem_phi->init_req(1, before_mem);\n+\n+    if (!kit.stopped()) {\n+      kit.set_all_memory(before_mem);\n+      int oop_off_1 = -1;\n+      int oop_off_2 = -1;\n+      Node* payload = convert_to_payload(igvn, kit.control(), value, true, oop_off_1, oop_off_2);\n+      assert(oop_off_1 == -1 && oop_off_2 == -1, \"no oop when nullable atomic layout is not natural\");\n+      BasicType payload_bt = vk->atomic_size_to_basic_type(true);\n+\n+      kit.insert_mem_bar(Op_MemBarCPUOrder);\n+      kit.access_store_at(base, ptr, TypeRawPtr::BOTTOM, payload, Type::get_const_basic_type(payload_bt), payload_bt, _decorators | C2_MISMATCHED, true, value);\n+      kit.insert_mem_bar(Op_MemBarRelease);\n+      merge->init_req(2, kit.control());\n+      mem_phi->init_req(2, kit.reset_memory());\n+    }\n@@ -1783,9 +1831,7 @@\n-  ciInlineKlass* vk = igvn.type(value)->inline_klass();\n-  BasicType payload_bt = vk->atomic_size_to_basic_type(_null_free);\n-  kit.insert_mem_bar(Op_MemBarCPUOrder);\n-  if (!UseG1GC || oop_off_1 == -1) {\n-    \/\/ No oop fields or no late barrier expansion. Emit an atomic store of the payload and add GC barriers if needed.\n-    assert(oop_off_2 == -1 || !UseG1GC, \"sanity\");\n-    \/\/ ZGC does not support compressed oops, so only one oop can be in the payload which is written by a \"normal\" oop store.\n-    assert((oop_off_1 == -1 && oop_off_2 == -1) || !UseZGC, \"ZGC does not support embedded oops in flat fields\");\n-    kit.access_store_at(base, ptr, TypeRawPtr::BOTTOM, payload, Type::get_const_basic_type(payload_bt), payload_bt, _decorators | C2_MISMATCHED, true, value);\n+    kit.set_control(merge);\n+    kit.set_all_memory(mem_phi);\n+    Node* null_marker_ptr = kit.basic_plus_adr(base, ptr, vk->null_marker_offset_in_payload());\n+    const TypePtr* null_marker_ptr_type = null_marker_ptr->Value(&igvn)->is_ptr();\n+    igvn.set_type(null_marker_ptr, null_marker_ptr_type);\n+    Node* null_marker_value = value->get_null_marker();\n+    kit.access_store_at(base, null_marker_ptr, null_marker_ptr_type, null_marker_value, TypeInt::BOOL, T_BOOLEAN, _decorators);\n@@ -1793,9 +1839,24 @@\n-    \/\/ Contains oops and requires late barrier expansion. Emit a special store node that allows to emit GC barriers in the backend.\n-    assert(UseG1GC, \"Unexpected GC\");\n-    assert(payload_bt == T_LONG, \"Unexpected payload type\");\n-    \/\/ If one oop, set the offset (if no offset is set, two oops are assumed by the backend)\n-    Node* oop_offset = (oop_off_2 == -1) ? igvn.intcon(oop_off_1) : nullptr;\n-    Node* mem = kit.reset_memory();\n-    kit.set_all_memory(mem);\n-    Node* store = igvn.transform(new StoreLSpecialNode(kit.control(), mem, ptr, TypeRawPtr::BOTTOM, payload, oop_offset, MemNode::unordered));\n-    kit.set_memory(store, TypeRawPtr::BOTTOM);\n+    int oop_off_1 = -1;\n+    int oop_off_2 = -1;\n+    Node* payload = convert_to_payload(igvn, kit.control(), value, _null_free, oop_off_1, oop_off_2);\n+\n+    BasicType payload_bt = vk->atomic_size_to_basic_type(_null_free);\n+    kit.insert_mem_bar(Op_MemBarCPUOrder);\n+    if (!UseG1GC || oop_off_1 == -1) {\n+      \/\/ No oop fields or no late barrier expansion. Emit an atomic store of the payload and add GC barriers if needed.\n+      assert(oop_off_2 == -1 || !UseG1GC, \"sanity\");\n+      \/\/ ZGC does not support compressed oops, so only one oop can be in the payload which is written by a \"normal\" oop store.\n+      assert((oop_off_1 == -1 && oop_off_2 == -1) || !UseZGC, \"ZGC does not support embedded oops in flat fields\");\n+      kit.access_store_at(base, ptr, TypeRawPtr::BOTTOM, payload, Type::get_const_basic_type(payload_bt), payload_bt, _decorators | C2_MISMATCHED, true, value);\n+    } else {\n+      \/\/ Contains oops and requires late barrier expansion. Emit a special store node that allows to emit GC barriers in the backend.\n+      assert(UseG1GC, \"Unexpected GC\");\n+      assert(payload_bt == T_LONG, \"Unexpected payload type\");\n+      \/\/ If one oop, set the offset (if no offset is set, two oops are assumed by the backend)\n+      Node* oop_offset = (oop_off_2 == -1) ? igvn.intcon(oop_off_1) : nullptr;\n+      Node* mem = kit.reset_memory();\n+      kit.set_all_memory(mem);\n+      Node* store = igvn.transform(new StoreLSpecialNode(kit.control(), mem, ptr, TypeRawPtr::BOTTOM, payload, oop_offset, MemNode::unordered));\n+      kit.set_memory(store, TypeRawPtr::BOTTOM);\n+    }\n+    kit.insert_mem_bar(Op_MemBarCPUOrder);\n@@ -1803,1 +1864,0 @@\n-  kit.insert_mem_bar(Op_MemBarCPUOrder);\n@@ -1861,0 +1921,3 @@\n+  if (payload_bt == val_bt) {\n+    return value;\n+  }\n","filename":"src\/hotspot\/share\/opto\/inlinetypenode.cpp","additions":92,"deletions":29,"binary":false,"changes":121,"status":"modified"},{"patch":"@@ -211,1 +211,1 @@\n-  void expand_projs_atomic(PhaseIterGVN& gvn, Node* ctrl, Node* payload);\n+  void expand_projs_atomic(PhaseIterGVN& gvn, Node* ctrl, Node* payload, bool payload_no_null_marker);\n","filename":"src\/hotspot\/share\/opto\/inlinetypenode.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2911,1 +2911,1 @@\n-      value_type = Type::get_const_type(value_klass)->filter_speculative(value_type);\n+      value_type = Type::get_const_type(value_klass);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1329,0 +1329,33 @@\n+\n+    \/\/ Verify that a nullable j.l.Long can be flattened\n+    static class LongHolder {\n+        Long v;\n+    }\n+\n+    @Test\n+    @IR(applyIfAnd = {\"UseFieldFlattening\", \"true\", \"UseAtomicValueFlattening\", \"true\"}, counts = {IRNode.STORE_L, \"1\", IRNode.STORE_B, \"1\"})\n+    @IR(applyIfAnd = {\"UseFieldFlattening\", \"true\", \"UseAtomicValueFlattening\", \"true\"}, failOn = {IRNode.ALLOC})\n+    public void test49(LongHolder h, long v) {\n+        h.v = v;\n+    }\n+\n+    @Run(test = \"test49\")\n+    public void test49_verifier() {\n+        LongHolder h = new LongHolder();\n+        test49(h, rL);\n+        Asserts.assertEQ(rL, h.v);\n+    }\n+\n+    @Test\n+    @IR(applyIfAnd = {\"UseArrayFlattening\", \"true\", \"UseAtomicValueFlattening\", \"true\"}, counts = {IRNode.STORE_L, \"1\", IRNode.STORE_B, \"1\"})\n+    @IR(applyIfAnd = {\"UseArrayFlattening\", \"true\", \"UseAtomicValueFlattening\", \"true\"}, failOn = {IRNode.ALLOC})\n+    public void test50(Long[] a, long v) {\n+        a[0] = v;\n+    }\n+\n+    @Run(test = \"test50\")\n+    public void test50_verifier() {\n+        Long[] a = new Long[1];\n+        test50(a, rL);\n+        Asserts.assertEQ(rL, a[0]);\n+    }\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestBasicFunctionality.java","additions":33,"deletions":0,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -249,0 +249,13 @@\n+\/**\n+ * A class such that we cannot access its nullable layout with a single\n+ * instruction.\n+ *\/\n+value record MyLargeValueTearing(int x, int y) {\n+    static final MyLargeValueTearing DEFAULT = new MyLargeValueTearing(0, 0);\n+\n+    MyLargeValueTearing incrementAndCheck() {\n+        Asserts.assertEQ(x, y, \"Inconsistent field values\");\n+        return new MyLargeValueTearing(x + 1, y + 1);\n+    }\n+}\n+\n@@ -270,0 +283,2 @@\n+    MyLargeValueTearing field5 = MyLargeValueTearing.DEFAULT;\n+\n@@ -302,0 +317,3 @@\n+    static MyLargeValueTearing[] array13 = new MyLargeValueTearing[] { MyLargeValueTearing.DEFAULT };\n+\n+    static final Unsafe U = Unsafe.getUnsafe();\n@@ -303,0 +321,7 @@\n+    static final Field field5_mirror;\n+    static final long field5_offset;\n+    static final int field5_layout;\n+    static final VarHandle field5_vh;\n+    static final long array13_baseOffset;\n+    static final int array13_layout;\n+    static final VarHandle array13_vh;\n@@ -311,1 +336,9 @@\n-        } catch (NoSuchMethodException | IllegalAccessException e) {\n+\n+            field5_mirror = TestTearing.class.getDeclaredField(\"field5\");\n+            field5_offset = U.objectFieldOffset(field5_mirror);\n+            field5_layout = U.fieldLayout(field5_mirror);\n+            field5_vh = lookup.findVarHandle(TestTearing.class, \"field5\", MyLargeValueTearing.class).withInvokeExactBehavior();\n+            array13_baseOffset = U.arrayInstanceBaseOffset(array13);\n+            array13_layout = U.arrayLayout(array13);\n+            array13_vh = MethodHandles.arrayElementVarHandle(array13.getClass()).withInvokeExactBehavior();\n+        } catch (NoSuchFieldException | NoSuchMethodException | IllegalAccessException e) {\n@@ -354,0 +387,14 @@\n+\n+                \/\/ Occasionally store a null\n+                MyLargeValueTearing field5Value = test.field5;\n+                if (field5Value == null) {\n+                    field5Value = MyLargeValueTearing.DEFAULT;\n+                } else {\n+                    field5Value = field5Value.incrementAndCheck();\n+                }\n+                if ((i & 15) == 0) {\n+                    test.field5 = null;\n+                } else {\n+                    test.field5 = field5Value;\n+                }\n+\n@@ -367,0 +414,13 @@\n+                \/\/ Occasionally store a null\n+                MyLargeValueTearing array13Elem = array13[0];\n+                if (array13Elem == null) {\n+                    array13Elem = MyLargeValueTearing.DEFAULT;\n+                } else {\n+                    array13Elem = array13Elem.incrementAndCheck();\n+                }\n+                if ((i & 15) == 0) {\n+                    array13[0] = null;\n+                } else {\n+                    array13[0] = array13Elem;\n+                }\n+\n@@ -371,0 +431,15 @@\n+\n+                if (field5_layout != 0) {\n+                    field5Value = U.getFlatValue(test, field5_offset, field5_layout, MyLargeValueTearing.class);\n+                    if (field5Value == null) {\n+                        field5Value = MyLargeValueTearing.DEFAULT;\n+                    } else {\n+                        field5Value = field5Value.incrementAndCheck();\n+                    }\n+                    if ((i & 15) == 0) {\n+                        U.putFlatValue(test, field5_offset, field5_layout, MyLargeValueTearing.class, null);\n+                    } else {\n+                        U.putFlatValue(test, field5_offset, field5_layout, MyLargeValueTearing.class, field5Value);\n+                    }\n+                }\n+\n@@ -384,0 +459,14 @@\n+                if (array13_layout != 0) {\n+                    array13Elem = U.getFlatValue(array13, array13_baseOffset, array13_layout, MyLargeValueTearing.class);\n+                    if (array13Elem == null) {\n+                        array13Elem = MyLargeValueTearing.DEFAULT;\n+                    } else {\n+                        array13Elem = array13Elem.incrementAndCheck();\n+                    }\n+                    if ((i & 15) == 0) {\n+                        U.putFlatValue(array13, array13_baseOffset, array13_layout, MyLargeValueTearing.class, null);\n+                    } else {\n+                        U.putFlatValue(array13, array13_baseOffset, array13_layout, MyLargeValueTearing.class, array13Elem);\n+                    }\n+                }\n+\n@@ -389,0 +478,13 @@\n+\n+                    field5Value = (MyLargeValueTearing) field5_vh.get(test);\n+                    if (field5Value == null) {\n+                        field5Value = MyLargeValueTearing.DEFAULT;\n+                    } else {\n+                        field5Value = field5Value.incrementAndCheck();\n+                    }\n+                    if ((i & 15) == 0) {\n+                        field5_vh.set(test, (MyLargeValueTearing) null);\n+                    } else {\n+                        field5_vh.set(test, field5Value);\n+                    }\n+\n@@ -401,0 +503,12 @@\n+\n+                    array13Elem = (MyLargeValueTearing) array13_vh.get(array13, 0);\n+                    if (array13Elem == null) {\n+                        array13Elem = MyLargeValueTearing.DEFAULT;\n+                    } else {\n+                        array13Elem = array13Elem.incrementAndCheck();\n+                    }\n+                    if ((i & 15) == 0) {\n+                        array13_vh.set(array13, 0, (MyLargeValueTearing) null);\n+                    } else {\n+                        array13_vh.set(array13, 0, array13Elem);\n+                    }\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestTearing.java","additions":115,"deletions":1,"binary":false,"changes":116,"status":"modified"}]}