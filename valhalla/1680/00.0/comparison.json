{"files":[{"patch":"@@ -306,1 +306,1 @@\n-  Atomic::inc(&_patching_epoch);\n+  AtomicAccess::inc(&_patching_epoch);\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -117,1 +117,1 @@\n-    return Atomic::load_acquire(guard_addr());\n+    return AtomicAccess::load_acquire(guard_addr());\n@@ -122,1 +122,1 @@\n-      Atomic::release_store(guard_addr(), value);\n+      AtomicAccess::release_store(guard_addr(), value);\n@@ -127,1 +127,1 @@\n-    int old_value = Atomic::load(guard_addr());\n+    int old_value = AtomicAccess::load(guard_addr());\n@@ -132,1 +132,1 @@\n-      int v = Atomic::cmpxchg(guard_addr(), old_value, new_value, memory_order_release);\n+      int v = AtomicAccess::cmpxchg(guard_addr(), old_value, new_value, memory_order_release);\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetNMethod_aarch64.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1700,1 +1700,1 @@\n-  void ghash_processBlocks_wide(address p, Register state, Register subkeyH,\n+  void ghash_processBlocks_wide(Label& p, Register state, Register subkeyH,\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -45,1 +45,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -821,1 +821,1 @@\n-  void generate_copy_longs(StubId stub_id, DecoratorSet decorators, Label &start, Register s, Register d, Register count) {\n+  address generate_copy_longs(StubId stub_id, DecoratorSet decorators, Register s, Register d, Register count) {\n@@ -873,1 +873,1 @@\n-    __ bind(start);\n+    address start = __ pc();\n@@ -913,3 +913,3 @@\n-       use_stride = prefetch > 256;\n-       prefetch = -prefetch;\n-       if (use_stride) __ mov(stride, prefetch);\n+      use_stride = prefetch > 256;\n+      prefetch = -prefetch;\n+      if (use_stride) __ mov(stride, prefetch);\n@@ -1045,3 +1045,3 @@\n-         use_stride = prefetch > 256;\n-         prefetch = -prefetch;\n-         if (use_stride) __ mov(stride, prefetch);\n+        use_stride = prefetch > 256;\n+        prefetch = -prefetch;\n+        if (use_stride) __ mov(stride, prefetch);\n@@ -1056,9 +1056,9 @@\n-       \/\/ allowing for the offset of -8 the store instructions place\n-       \/\/ registers into the target 64 bit block at the following\n-       \/\/ offsets\n-       \/\/\n-       \/\/ t0 at offset 0\n-       \/\/ t1 at offset 8,  t2 at offset 16\n-       \/\/ t3 at offset 24, t4 at offset 32\n-       \/\/ t5 at offset 40, t6 at offset 48\n-       \/\/ t7 at offset 56\n+        \/\/ allowing for the offset of -8 the store instructions place\n+        \/\/ registers into the target 64 bit block at the following\n+        \/\/ offsets\n+        \/\/\n+        \/\/ t0 at offset 0\n+        \/\/ t1 at offset 8,  t2 at offset 16\n+        \/\/ t3 at offset 24, t4 at offset 32\n+        \/\/ t5 at offset 40, t6 at offset 48\n+        \/\/ t7 at offset 56\n@@ -1076,12 +1076,12 @@\n-       \/\/ d was not offset when we started so the registers are\n-       \/\/ written into the 64 bit block preceding d with the following\n-       \/\/ offsets\n-       \/\/\n-       \/\/ t1 at offset -8\n-       \/\/ t3 at offset -24, t0 at offset -16\n-       \/\/ t5 at offset -48, t2 at offset -32\n-       \/\/ t7 at offset -56, t4 at offset -48\n-       \/\/                   t6 at offset -64\n-       \/\/\n-       \/\/ note that this matches the offsets previously noted for the\n-       \/\/ loads\n+        \/\/ d was not offset when we started so the registers are\n+        \/\/ written into the 64 bit block preceding d with the following\n+        \/\/ offsets\n+        \/\/\n+        \/\/ t1 at offset -8\n+        \/\/ t3 at offset -24, t0 at offset -16\n+        \/\/ t5 at offset -48, t2 at offset -32\n+        \/\/ t7 at offset -56, t4 at offset -48\n+        \/\/                   t6 at offset -64\n+        \/\/\n+        \/\/ note that this matches the offsets previously noted for the\n+        \/\/ loads\n@@ -1128,4 +1128,4 @@\n-       \/\/ this is the same as above but copying only 4 longs hence\n-       \/\/ with only one intervening stp between the str instructions\n-       \/\/ but note that the offsets and registers still follow the\n-       \/\/ same pattern\n+        \/\/ this is the same as above but copying only 4 longs hence\n+        \/\/ with only one intervening stp between the str instructions\n+        \/\/ but note that the offsets and registers still follow the\n+        \/\/ same pattern\n@@ -1146,4 +1146,4 @@\n-       \/\/ this is the same as above but copying only 2 longs hence\n-       \/\/ there is no intervening stp between the str instructions\n-       \/\/ but note that the offset and register patterns are still\n-       \/\/ the same\n+        \/\/ this is the same as above but copying only 2 longs hence\n+        \/\/ there is no intervening stp between the str instructions\n+        \/\/ but note that the offset and register patterns are still\n+        \/\/ the same\n@@ -1160,2 +1160,2 @@\n-       \/\/ for forwards copy we need to re-adjust the offsets we\n-       \/\/ applied so that s and d are follow the last words written\n+        \/\/ for forwards copy we need to re-adjust the offsets we\n+        \/\/ applied so that s and d are follow the last words written\n@@ -1163,4 +1163,4 @@\n-       if (direction == copy_forwards) {\n-         __ add(s, s, 16);\n-         __ add(d, d, 8);\n-       }\n+        if (direction == copy_forwards) {\n+          __ add(s, s, 16);\n+          __ add(d, d, 8);\n+        }\n@@ -1171,1 +1171,3 @@\n-      }\n+    }\n+\n+    return start;\n@@ -1225,4 +1227,0 @@\n-  Label copy_f, copy_b;\n-  Label copy_obj_f, copy_obj_b;\n-  Label copy_obj_uninit_f, copy_obj_uninit_b;\n-\n@@ -1466,1 +1464,1 @@\n-        __ bl(copy_f);\n+        __ bl(StubRoutines::aarch64::copy_byte_f());\n@@ -1468,1 +1466,1 @@\n-        __ bl(copy_obj_uninit_f);\n+        __ bl(StubRoutines::aarch64::copy_oop_uninit_f());\n@@ -1470,1 +1468,1 @@\n-        __ bl(copy_obj_f);\n+        __ bl(StubRoutines::aarch64::copy_oop_f());\n@@ -1474,1 +1472,1 @@\n-        __ bl(copy_b);\n+        __ bl(StubRoutines::aarch64::copy_byte_b());\n@@ -1476,1 +1474,1 @@\n-        __ bl(copy_obj_uninit_b);\n+        __ bl(StubRoutines::aarch64::copy_oop_uninit_b());\n@@ -1478,1 +1476,1 @@\n-        __ bl(copy_obj_b);\n+        __ bl(StubRoutines::aarch64::copy_oop_b());\n@@ -1541,3 +1539,3 @@\n-  \/\/ Side Effects: entry is set to the (post push) entry point so it\n-  \/\/               can be used by the corresponding conjoint copy\n-  \/\/               method\n+  \/\/ Side Effects: nopush_entry is set to the (post push) entry point\n+  \/\/               so it can be used by the corresponding conjoint\n+  \/\/               copy method\n@@ -1545,1 +1543,1 @@\n-  address generate_disjoint_copy(StubId stub_id, address *entry) {\n+  address generate_disjoint_copy(StubId stub_id, address *nopush_entry) {\n@@ -1634,2 +1632,2 @@\n-    if (entry != nullptr) {\n-      *entry = __ pc();\n+    if (nopush_entry != nullptr) {\n+      *nopush_entry = __ pc();\n@@ -1698,2 +1696,2 @@\n-  \/\/   entry is set to the no-overlap entry point so it can be used by\n-  \/\/   some other conjoint copy method\n+  \/\/   nopush_entry is set to the no-overlap entry point so it can be\n+  \/\/   used by some other conjoint copy method\n@@ -1701,1 +1699,1 @@\n-  address generate_conjoint_copy(StubId stub_id, address nooverlap_target, address *entry) {\n+  address generate_conjoint_copy(StubId stub_id, address nooverlap_target, address *nopush_entry) {\n@@ -1788,2 +1786,2 @@\n-    if (entry != nullptr) {\n-      *entry = __ pc();\n+    if (nopush_entry != nullptr) {\n+      *nopush_entry = __ pc();\n@@ -1795,0 +1793,1 @@\n+    Label L_overlapping;\n@@ -1797,1 +1796,3 @@\n-    __ br(Assembler::HS, nooverlap_target);\n+    __ br(Assembler::LO, L_overlapping);\n+    __ b(RuntimeAddress(nooverlap_target));\n+    __ bind(L_overlapping);\n@@ -1869,1 +1870,1 @@\n-  address generate_checkcast_copy(StubId stub_id, address *entry) {\n+  address generate_checkcast_copy(StubId stub_id, address *nopush_entry) {\n@@ -1930,2 +1931,2 @@\n-    if (entry != nullptr) {\n-      *entry = __ pc();\n+    if (nopush_entry != nullptr) {\n+      *nopush_entry = __ pc();\n@@ -2749,7 +2750,15 @@\n-    address entry;\n-    address entry_jbyte_arraycopy;\n-    address entry_jshort_arraycopy;\n-    address entry_jint_arraycopy;\n-    address entry_oop_arraycopy;\n-    address entry_jlong_arraycopy;\n-    address entry_checkcast_arraycopy;\n+    \/\/ Some copy stubs publish a normal entry and then a 2nd 'fallback'\n+    \/\/ entry immediately following their stack push. This can be used\n+    \/\/ as a post-push branch target for compatible stubs when they\n+    \/\/ identify a special case that can be handled by the fallback\n+    \/\/ stub e.g a disjoint copy stub may be use as a special case\n+    \/\/ fallback for its compatible conjoint copy stub.\n+    \/\/\n+    \/\/ A no push entry is always returned in the following local and\n+    \/\/ then published by assigning to the appropriate entry field in\n+    \/\/ class StubRoutines. The entry value is then passed to the\n+    \/\/ generator for the compatible stub. That means the entry must be\n+    \/\/ listed when saving to\/restoring from the AOT cache, ensuring\n+    \/\/ that the inter-stub jumps are noted at AOT-cache save and\n+    \/\/ relocated at AOT cache load.\n+    address nopush_entry;\n@@ -2763,2 +2772,4 @@\n-    generate_copy_longs(StubId::stubgen_copy_byte_f_id, IN_HEAP | IS_ARRAY, copy_f, r0, r1, r15);\n-    generate_copy_longs(StubId::stubgen_copy_byte_b_id, IN_HEAP | IS_ARRAY, copy_b, r0, r1, r15);\n+    \/\/ generate and publish arch64-specific bulk copy routines first\n+    \/\/ so we can call them from other copy stubs\n+    StubRoutines::aarch64::_copy_byte_f = generate_copy_longs(StubId::stubgen_copy_byte_f_id, IN_HEAP | IS_ARRAY, r0, r1, r15);\n+    StubRoutines::aarch64::_copy_byte_b = generate_copy_longs(StubId::stubgen_copy_byte_b_id, IN_HEAP | IS_ARRAY, r0, r1, r15);\n@@ -2766,2 +2777,2 @@\n-    generate_copy_longs(StubId::stubgen_copy_oop_f_id, IN_HEAP | IS_ARRAY, copy_obj_f, r0, r1, r15);\n-    generate_copy_longs(StubId::stubgen_copy_oop_b_id, IN_HEAP | IS_ARRAY, copy_obj_b, r0, r1, r15);\n+    StubRoutines::aarch64::_copy_oop_f = generate_copy_longs(StubId::stubgen_copy_oop_f_id, IN_HEAP | IS_ARRAY, r0, r1, r15);\n+    StubRoutines::aarch64::_copy_oop_b = generate_copy_longs(StubId::stubgen_copy_oop_b_id, IN_HEAP | IS_ARRAY, r0, r1, r15);\n@@ -2769,2 +2780,2 @@\n-    generate_copy_longs(StubId::stubgen_copy_oop_uninit_f_id, IN_HEAP | IS_ARRAY | IS_DEST_UNINITIALIZED, copy_obj_uninit_f, r0, r1, r15);\n-    generate_copy_longs(StubId::stubgen_copy_oop_uninit_b_id, IN_HEAP | IS_ARRAY | IS_DEST_UNINITIALIZED, copy_obj_uninit_b, r0, r1, r15);\n+    StubRoutines::aarch64::_copy_oop_uninit_f = generate_copy_longs(StubId::stubgen_copy_oop_uninit_f_id, IN_HEAP | IS_ARRAY | IS_DEST_UNINITIALIZED, r0, r1, r15);\n+    StubRoutines::aarch64::_copy_oop_uninit_b = generate_copy_longs(StubId::stubgen_copy_oop_uninit_b_id, IN_HEAP | IS_ARRAY | IS_DEST_UNINITIALIZED, r0, r1, r15);\n@@ -2776,4 +2787,10 @@\n-    StubRoutines::_jbyte_disjoint_arraycopy         = generate_disjoint_copy(StubId::stubgen_jbyte_disjoint_arraycopy_id, &entry);\n-    StubRoutines::_jbyte_arraycopy                  = generate_conjoint_copy(StubId::stubgen_jbyte_arraycopy_id, entry, &entry_jbyte_arraycopy);\n-    StubRoutines::_arrayof_jbyte_disjoint_arraycopy = generate_disjoint_copy(StubId::stubgen_arrayof_jbyte_disjoint_arraycopy_id, &entry);\n-    StubRoutines::_arrayof_jbyte_arraycopy          = generate_conjoint_copy(StubId::stubgen_arrayof_jbyte_arraycopy_id, entry, nullptr);\n+    StubRoutines::_jbyte_disjoint_arraycopy         = generate_disjoint_copy(StubId::stubgen_jbyte_disjoint_arraycopy_id, &nopush_entry);\n+    \/\/ disjoint nopush entry is needed by conjoint copy\n+    StubRoutines::_jbyte_disjoint_arraycopy_nopush  = nopush_entry;\n+    StubRoutines::_jbyte_arraycopy                  = generate_conjoint_copy(StubId::stubgen_jbyte_arraycopy_id, StubRoutines::_jbyte_disjoint_arraycopy_nopush, &nopush_entry);\n+    \/\/ conjoint nopush entry is needed by generic\/unsafe copy\n+    StubRoutines::_jbyte_arraycopy_nopush = nopush_entry;\n+    StubRoutines::_arrayof_jbyte_disjoint_arraycopy = generate_disjoint_copy(StubId::stubgen_arrayof_jbyte_disjoint_arraycopy_id, &nopush_entry);\n+    \/\/ disjoint arrayof nopush entry is needed by conjoint copy\n+    StubRoutines::_arrayof_jbyte_disjoint_arraycopy_nopush  = nopush_entry;\n+    StubRoutines::_arrayof_jbyte_arraycopy          = generate_conjoint_copy(StubId::stubgen_arrayof_jbyte_arraycopy_id, StubRoutines::_arrayof_jbyte_disjoint_arraycopy_nopush, nullptr);\n@@ -2783,4 +2800,10 @@\n-    StubRoutines::_jshort_disjoint_arraycopy         = generate_disjoint_copy(StubId::stubgen_jshort_disjoint_arraycopy_id, &entry);\n-    StubRoutines::_jshort_arraycopy                  = generate_conjoint_copy(StubId::stubgen_jshort_arraycopy_id, entry, &entry_jshort_arraycopy);\n-    StubRoutines::_arrayof_jshort_disjoint_arraycopy = generate_disjoint_copy(StubId::stubgen_arrayof_jshort_disjoint_arraycopy_id, &entry);\n-    StubRoutines::_arrayof_jshort_arraycopy          = generate_conjoint_copy(StubId::stubgen_arrayof_jshort_arraycopy_id, entry, nullptr);\n+    StubRoutines::_jshort_disjoint_arraycopy         = generate_disjoint_copy(StubId::stubgen_jshort_disjoint_arraycopy_id, &nopush_entry);\n+    \/\/ disjoint nopush entry is needed by conjoint copy\n+    StubRoutines::_jshort_disjoint_arraycopy_nopush  = nopush_entry;\n+    StubRoutines::_jshort_arraycopy                  = generate_conjoint_copy(StubId::stubgen_jshort_arraycopy_id, StubRoutines::_jshort_disjoint_arraycopy_nopush, &nopush_entry);\n+    \/\/ conjoint nopush entry is used by generic\/unsafe copy\n+    StubRoutines::_jshort_arraycopy_nopush = nopush_entry;\n+    StubRoutines::_arrayof_jshort_disjoint_arraycopy = generate_disjoint_copy(StubId::stubgen_arrayof_jshort_disjoint_arraycopy_id, &nopush_entry);\n+    \/\/ disjoint arrayof nopush entry is needed by conjoint copy\n+    StubRoutines::_arrayof_jshort_disjoint_arraycopy_nopush = nopush_entry;\n+    StubRoutines::_arrayof_jshort_arraycopy          = generate_conjoint_copy(StubId::stubgen_arrayof_jshort_arraycopy_id, StubRoutines::_arrayof_jshort_disjoint_arraycopy_nopush, nullptr);\n@@ -2790,2 +2813,4 @@\n-    StubRoutines::_arrayof_jint_disjoint_arraycopy = generate_disjoint_copy(StubId::stubgen_arrayof_jint_disjoint_arraycopy_id, &entry);\n-    StubRoutines::_arrayof_jint_arraycopy          = generate_conjoint_copy(StubId::stubgen_arrayof_jint_arraycopy_id, entry, &entry_jint_arraycopy);\n+    StubRoutines::_arrayof_jint_disjoint_arraycopy = generate_disjoint_copy(StubId::stubgen_arrayof_jint_disjoint_arraycopy_id, &nopush_entry);\n+    \/\/ disjoint arrayof nopush entry is needed by conjoint copy\n+    StubRoutines::_arrayof_jint_disjoint_arraycopy_nopush = nopush_entry;\n+    StubRoutines::_arrayof_jint_arraycopy          = generate_conjoint_copy(StubId::stubgen_arrayof_jint_arraycopy_id, StubRoutines::_arrayof_jint_disjoint_arraycopy_nopush, nullptr);\n@@ -2793,3 +2818,7 @@\n-    \/\/ entry_jint_arraycopy always points to the unaligned version\n-    StubRoutines::_jint_disjoint_arraycopy         = generate_disjoint_copy(StubId::stubgen_jint_disjoint_arraycopy_id, &entry);\n-    StubRoutines::_jint_arraycopy                  = generate_conjoint_copy(StubId::stubgen_jint_arraycopy_id, entry, &entry_jint_arraycopy);\n+    \/\/ jint_arraycopy_nopush always points to the unaligned version\n+    StubRoutines::_jint_disjoint_arraycopy         = generate_disjoint_copy(StubId::stubgen_jint_disjoint_arraycopy_id, &nopush_entry);\n+    \/\/ disjoint nopush entry is needed by conjoint copy\n+    StubRoutines::_jint_disjoint_arraycopy_nopush  = nopush_entry;\n+    StubRoutines::_jint_arraycopy                  = generate_conjoint_copy(StubId::stubgen_jint_arraycopy_id, StubRoutines::_jint_disjoint_arraycopy_nopush, &nopush_entry);\n+    \/\/ conjoint nopush entry is needed by generic\/unsafe copy\n+    StubRoutines::_jint_arraycopy_nopush = nopush_entry;\n@@ -2799,2 +2828,8 @@\n-    StubRoutines::_arrayof_jlong_disjoint_arraycopy = generate_disjoint_copy(StubId::stubgen_arrayof_jlong_disjoint_arraycopy_id, &entry);\n-    StubRoutines::_arrayof_jlong_arraycopy          = generate_conjoint_copy(StubId::stubgen_arrayof_jlong_arraycopy_id, entry, &entry_jlong_arraycopy);\n+    StubRoutines::_arrayof_jlong_disjoint_arraycopy = generate_disjoint_copy(StubId::stubgen_arrayof_jlong_disjoint_arraycopy_id, &nopush_entry);\n+    \/\/ disjoint arrayof nopush entry is needed by conjoint copy\n+    StubRoutines::_arrayof_jlong_disjoint_arraycopy_nopush = nopush_entry;\n+    StubRoutines::_arrayof_jlong_arraycopy          = generate_conjoint_copy(StubId::stubgen_arrayof_jlong_arraycopy_id, StubRoutines::_arrayof_jlong_disjoint_arraycopy_nopush, &nopush_entry);\n+    \/\/ conjoint nopush entry is needed by generic\/unsafe copy\n+    StubRoutines::_jlong_arraycopy_nopush = nopush_entry;\n+    \/\/ disjoint normal\/nopush and conjoint normal entries are not\n+    \/\/ generated since the arrayof versions are the same\n@@ -2802,0 +2837,1 @@\n+    StubRoutines::_jlong_disjoint_arraycopy_nopush = StubRoutines::_arrayof_jlong_disjoint_arraycopy_nopush;\n@@ -2806,5 +2842,3 @@\n-      \/\/ With compressed oops we need unaligned versions; notice that\n-      \/\/ we overwrite entry_oop_arraycopy.\n-      bool aligned = !UseCompressedOops;\n-\n-        = generate_disjoint_copy(StubId::stubgen_arrayof_oop_disjoint_arraycopy_id, &entry);\n+        = generate_disjoint_copy(StubId::stubgen_arrayof_oop_disjoint_arraycopy_id, &nopush_entry);\n+      \/\/ disjoint arrayof nopush entry is needed by conjoint copy\n+      StubRoutines::_arrayof_oop_disjoint_arraycopy_nopush = nopush_entry;\n@@ -2813,1 +2847,3 @@\n-        = generate_conjoint_copy(StubId::stubgen_arrayof_oop_arraycopy_id, entry, &entry_oop_arraycopy);\n+        = generate_conjoint_copy(StubId::stubgen_arrayof_oop_arraycopy_id, StubRoutines::_arrayof_oop_disjoint_arraycopy_nopush, &nopush_entry);\n+      \/\/ conjoint arrayof nopush entry is needed by generic\/unsafe copy\n+      StubRoutines::_oop_arraycopy_nopush = nopush_entry;\n@@ -2816,1 +2852,5 @@\n-        = generate_disjoint_copy(StubId::stubgen_arrayof_oop_disjoint_arraycopy_uninit_id, &entry);\n+        = generate_disjoint_copy(StubId::stubgen_arrayof_oop_disjoint_arraycopy_uninit_id, &nopush_entry);\n+      \/\/ disjoint arrayof+uninit nopush entry is needed by conjoint copy\n+      StubRoutines::_arrayof_oop_disjoint_arraycopy_uninit_nopush = nopush_entry;\n+      \/\/ note that we don't need a returned nopush entry because the\n+      \/\/ generic\/unsafe copy does not cater for uninit arrays.\n@@ -2818,1 +2858,1 @@\n-        = generate_conjoint_copy(StubId::stubgen_arrayof_oop_arraycopy_uninit_id, entry, nullptr);\n+        = generate_conjoint_copy(StubId::stubgen_arrayof_oop_arraycopy_uninit_id, StubRoutines::_arrayof_oop_disjoint_arraycopy_uninit_nopush, nullptr);\n@@ -2821,0 +2861,1 @@\n+    \/\/ for oop copies reuse arrayof entries for non-arrayof cases\n@@ -2822,0 +2863,1 @@\n+    StubRoutines::_oop_disjoint_arraycopy_nopush = StubRoutines::_arrayof_oop_disjoint_arraycopy_nopush;\n@@ -2824,0 +2866,1 @@\n+    StubRoutines::_oop_disjoint_arraycopy_uninit_nopush = StubRoutines::_arrayof_oop_disjoint_arraycopy_uninit_nopush;\n@@ -2826,1 +2869,5 @@\n-    StubRoutines::_checkcast_arraycopy        = generate_checkcast_copy(StubId::stubgen_checkcast_arraycopy_id, &entry_checkcast_arraycopy);\n+    StubRoutines::_checkcast_arraycopy        = generate_checkcast_copy(StubId::stubgen_checkcast_arraycopy_id, &nopush_entry);\n+    \/\/ checkcast nopush entry is needed by generic copy\n+    StubRoutines::_checkcast_arraycopy_nopush = nopush_entry;\n+    \/\/ note that we don't need a returned nopush entry because the\n+    \/\/ generic copy does not cater for uninit arrays.\n@@ -2829,4 +2876,5 @@\n-    StubRoutines::_unsafe_arraycopy    = generate_unsafe_copy(entry_jbyte_arraycopy,\n-                                                              entry_jshort_arraycopy,\n-                                                              entry_jint_arraycopy,\n-                                                              entry_jlong_arraycopy);\n+    \/\/ unsafe arraycopy may fallback on conjoint stubs\n+    StubRoutines::_unsafe_arraycopy    = generate_unsafe_copy(StubRoutines::_jbyte_arraycopy_nopush,\n+                                                              StubRoutines::_jshort_arraycopy_nopush,\n+                                                              StubRoutines::_jint_arraycopy_nopush,\n+                                                              StubRoutines::_jlong_arraycopy_nopush);\n@@ -2834,6 +2882,7 @@\n-    StubRoutines::_generic_arraycopy   = generate_generic_copy(entry_jbyte_arraycopy,\n-                                                               entry_jshort_arraycopy,\n-                                                               entry_jint_arraycopy,\n-                                                               entry_oop_arraycopy,\n-                                                               entry_jlong_arraycopy,\n-                                                               entry_checkcast_arraycopy);\n+    \/\/ generic arraycopy may fallback on conjoint stubs\n+    StubRoutines::_generic_arraycopy   = generate_generic_copy(StubRoutines::_jbyte_arraycopy_nopush,\n+                                                               StubRoutines::_jshort_arraycopy_nopush,\n+                                                               StubRoutines::_jint_arraycopy_nopush,\n+                                                               StubRoutines::_oop_arraycopy_nopush,\n+                                                               StubRoutines::_jlong_arraycopy_nopush,\n+                                                               StubRoutines::_checkcast_arraycopy_nopush);\n@@ -3427,6 +3476,1 @@\n-    address ghash_polynomial = __ pc();\n-    __ emit_int64(0x87);  \/\/ The low-order bits of the field\n-                          \/\/ polynomial (i.e. p = z^7+z^2+z+1)\n-                          \/\/ repeated in the low and high parts of a\n-                          \/\/ 128-bit vector\n-    __ emit_int64(0x87);\n+    Label ghash_polynomial; \/\/ local data generated after code\n@@ -3434,1 +3478,1 @@\n-    __ align(CodeEntryAlignment);\n+   __ align(CodeEntryAlignment);\n@@ -3539,1 +3583,11 @@\n-     return start;\n+\n+    \/\/ bind label and generate polynomial data\n+    __ align(wordSize * 2);\n+    __ bind(ghash_polynomial);\n+    __ emit_int64(0x87);  \/\/ The low-order bits of the field\n+                          \/\/ polynomial (i.e. p = z^7+z^2+z+1)\n+                          \/\/ repeated in the low and high parts of a\n+                          \/\/ 128-bit vector\n+    __ emit_int64(0x87);\n+\n+    return start;\n@@ -4584,10 +4638,0 @@\n-    \/\/ The constant data is broken into two 128-bit segments to be loaded\n-    \/\/ onto FloatRegisters.  The first 128 bits are a counter add overlay\n-    \/\/ that adds +0\/+1\/+2\/+3 to the vector holding replicated state[12].\n-    \/\/ The second 128-bits is a table constant used for 8-bit left rotations.\n-    __ BIND(L_cc20_const);\n-    __ emit_int64(0x0000000100000000UL);\n-    __ emit_int64(0x0000000300000002UL);\n-    __ emit_int64(0x0605040702010003UL);\n-    __ emit_int64(0x0E0D0C0F0A09080BUL);\n-\n@@ -4741,0 +4785,11 @@\n+    \/\/ bind label and generate local constant data used by this stub\n+    \/\/ The constant data is broken into two 128-bit segments to be loaded\n+    \/\/ onto FloatRegisters.  The first 128 bits are a counter add overlay\n+    \/\/ that adds +0\/+1\/+2\/+3 to the vector holding replicated state[12].\n+    \/\/ The second 128-bits is a table constant used for 8-bit left rotations.\n+    __ BIND(L_cc20_const);\n+    __ emit_int64(0x0000000100000000UL);\n+    __ emit_int64(0x0000000300000002UL);\n+    __ emit_int64(0x0605040702010003UL);\n+    __ emit_int64(0x0E0D0C0F0A09080BUL);\n+\n@@ -6061,4 +6116,0 @@\n-    __ BIND(L_F00);\n-    __ emit_int64(0x0f000f000f000f00);\n-    __ emit_int64(0x0f000f000f000f00);\n-\n@@ -6258,0 +6309,5 @@\n+    \/\/ bind label and generate constant data used by this stub\n+    __ BIND(L_F00);\n+    __ emit_int64(0x0f000f000f000f00);\n+    __ emit_int64(0x0f000f000f000f00);\n+\n@@ -9667,8 +9723,1 @@\n-    __ align(wordSize * 2);\n-    address p = __ pc();\n-    __ emit_int64(0x87);  \/\/ The low-order bits of the field\n-                          \/\/ polynomial (i.e. p = z^7+z^2+z+1)\n-                          \/\/ repeated in the low and high parts of a\n-                          \/\/ 128-bit vector\n-    __ emit_int64(0x87);\n-\n+    Label polynomial; \/\/ local data generated at end of stub\n@@ -9686,1 +9735,2 @@\n-    __ ldrq(v24, p);    \/\/ The field polynomial\n+    __ adr(rscratch1, polynomial);\n+    __ ldrq(v24, rscratch1);    \/\/ The field polynomial\n@@ -9726,0 +9776,9 @@\n+    \/\/ bind label and generate local polynomial data\n+    __ align(wordSize * 2);\n+    __ bind(polynomial);\n+    __ emit_int64(0x87);  \/\/ The low-order bits of the field\n+                          \/\/ polynomial (i.e. p = z^7+z^2+z+1)\n+                          \/\/ repeated in the low and high parts of a\n+                          \/\/ 128-bit vector\n+    __ emit_int64(0x87);\n+\n@@ -9734,8 +9793,1 @@\n-    __ align(wordSize * 2);\n-    address p = __ pc();\n-    __ emit_int64(0x87);  \/\/ The low-order bits of the field\n-                          \/\/ polynomial (i.e. p = z^7+z^2+z+1)\n-                          \/\/ repeated in the low and high parts of a\n-                          \/\/ 128-bit vector\n-    __ emit_int64(0x87);\n-\n+    Label polynomial;           \/\/ local data generated after stub\n@@ -9763,1 +9815,1 @@\n-    __ ghash_processBlocks_wide(p, state, subkeyH, data, blocks, unroll);\n+    __ ghash_processBlocks_wide(polynomial, state, subkeyH, data, blocks, unroll);\n@@ -9776,0 +9828,9 @@\n+    \/\/ bind label and generate polynomial data\n+    __ align(wordSize * 2);\n+    __ bind(polynomial);\n+    __ emit_int64(0x87);  \/\/ The low-order bits of the field\n+                          \/\/ polynomial (i.e. p = z^7+z^2+z+1)\n+                          \/\/ repeated in the low and high parts of a\n+                          \/\/ 128-bit vector\n+    __ emit_int64(0x87);\n+\n@@ -9777,0 +9838,1 @@\n+\n@@ -10290,1 +10352,1 @@\n-  \/\/ ARMv8.1 LSE versions of the atomic stubs used by Atomic::PlatformXX.\n+  \/\/ ARMv8.1 LSE versions of the atomic stubs used by AtomicAccess::PlatformXX.\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":220,"deletions":158,"binary":false,"changes":378,"status":"modified"},{"patch":"@@ -68,1 +68,1 @@\n-    jint old_value = Atomic::load(data_addr);\n+    jint old_value = AtomicAccess::load(data_addr);\n@@ -73,1 +73,1 @@\n-      jint v = Atomic::cmpxchg(data_addr, old_value, new_value, memory_order_release);\n+      jint v = AtomicAccess::cmpxchg(data_addr, old_value, new_value, memory_order_release);\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetNMethod_x86.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -79,7 +79,43 @@\n-  address entry;\n-  address entry_jbyte_arraycopy;\n-  address entry_jshort_arraycopy;\n-  address entry_jint_arraycopy;\n-  address entry_oop_arraycopy;\n-  address entry_jlong_arraycopy;\n-  address entry_checkcast_arraycopy;\n+  \/\/ Some copy stubs publish a normal entry and then a 2nd 'fallback'\n+  \/\/ entry immediately following their stack push. This can be used\n+  \/\/ as a post-push branch target for compatible stubs when they\n+  \/\/ identify a special case that can be handled by the fallback\n+  \/\/ stub e.g a disjoint copy stub may be use as a special case\n+  \/\/ fallback for its compatible conjoint copy stub.\n+  \/\/\n+  \/\/ A no push entry is always returned in the following local and\n+  \/\/ then published by assigning to the appropriate entry field in\n+  \/\/ class StubRoutines. The entry value is then passed to the\n+  \/\/ generator for the compatible stub. That means the entry must be\n+  \/\/ listed when saving to\/restoring from the AOT cache, ensuring\n+  \/\/ that the inter-stub jumps are noted at AOT-cache save and\n+  \/\/ relocated at AOT cache load.\n+  address nopush_entry;\n+\n+  StubRoutines::_jbyte_disjoint_arraycopy  = generate_disjoint_byte_copy(&nopush_entry);\n+  \/\/ disjoint nopush entry is needed by conjoint copy\n+  StubRoutines::_jbyte_disjoint_arraycopy_nopush  = nopush_entry;\n+  StubRoutines::_jbyte_arraycopy           = generate_conjoint_byte_copy(StubRoutines::_jbyte_disjoint_arraycopy_nopush, &nopush_entry);\n+  \/\/ conjoint nopush entry is needed by generic\/unsafe copy\n+  StubRoutines::_jbyte_arraycopy_nopush    = nopush_entry;\n+\n+  StubRoutines::_jshort_disjoint_arraycopy = generate_disjoint_short_copy(&nopush_entry);\n+  \/\/ disjoint nopush entry is needed by conjoint copy\n+  StubRoutines::_jshort_disjoint_arraycopy_nopush = nopush_entry;\n+  StubRoutines::_jshort_arraycopy          = generate_conjoint_short_copy(StubRoutines::_jshort_disjoint_arraycopy_nopush, &nopush_entry);\n+  \/\/ conjoint nopush entry is needed by generic\/unsafe copy\n+  StubRoutines::_jshort_arraycopy_nopush   = nopush_entry;\n+\n+  StubRoutines::_jint_disjoint_arraycopy   = generate_disjoint_int_oop_copy(StubId::stubgen_jint_disjoint_arraycopy_id, &nopush_entry);\n+  \/\/ disjoint nopush entry is needed by conjoint copy\n+  StubRoutines::_jint_disjoint_arraycopy_nopush = nopush_entry;\n+  StubRoutines::_jint_arraycopy            = generate_conjoint_int_oop_copy(StubId::stubgen_jint_arraycopy_id, StubRoutines::_jint_disjoint_arraycopy_nopush, &nopush_entry);\n+  \/\/ conjoint nopush entry is needed by generic\/unsafe copy\n+  StubRoutines::_jint_arraycopy_nopush     = nopush_entry;\n+\n+  StubRoutines::_jlong_disjoint_arraycopy  = generate_disjoint_long_oop_copy(StubId::stubgen_jlong_disjoint_arraycopy_id, &nopush_entry);\n+  \/\/ disjoint nopush entry is needed by conjoint copy\n+  StubRoutines::_jlong_disjoint_arraycopy_nopush  = nopush_entry;\n+  StubRoutines::_jlong_arraycopy           = generate_conjoint_long_oop_copy(StubId::stubgen_jlong_arraycopy_id, StubRoutines::_jlong_disjoint_arraycopy_nopush, &nopush_entry);\n+  \/\/ conjoint nopush entry is needed by generic\/unsafe copy\n+  StubRoutines::_jlong_arraycopy_nopush    = nopush_entry;\n@@ -87,15 +123,12 @@\n-  StubRoutines::_jbyte_disjoint_arraycopy  = generate_disjoint_byte_copy(&entry);\n-  StubRoutines::_jbyte_arraycopy           = generate_conjoint_byte_copy(entry, &entry_jbyte_arraycopy);\n-\n-  StubRoutines::_jshort_disjoint_arraycopy = generate_disjoint_short_copy(&entry);\n-  StubRoutines::_jshort_arraycopy          = generate_conjoint_short_copy(entry, &entry_jshort_arraycopy);\n-\n-  StubRoutines::_jint_disjoint_arraycopy   = generate_disjoint_int_oop_copy(StubId::stubgen_jint_disjoint_arraycopy_id, &entry);\n-  StubRoutines::_jint_arraycopy            = generate_conjoint_int_oop_copy(StubId::stubgen_jint_arraycopy_id, entry, &entry_jint_arraycopy);\n-\n-  StubRoutines::_jlong_disjoint_arraycopy  = generate_disjoint_long_oop_copy(StubId::stubgen_jlong_disjoint_arraycopy_id, &entry);\n-  StubRoutines::_jlong_arraycopy           = generate_conjoint_long_oop_copy(StubId::stubgen_jlong_arraycopy_id, entry, &entry_jlong_arraycopy);\n-    StubRoutines::_oop_disjoint_arraycopy  = generate_disjoint_int_oop_copy(StubId::stubgen_oop_disjoint_arraycopy_id, &entry);\n-    StubRoutines::_oop_arraycopy           = generate_conjoint_int_oop_copy(StubId::stubgen_oop_arraycopy_id, entry, &entry_oop_arraycopy);\n-    StubRoutines::_oop_disjoint_arraycopy_uninit  = generate_disjoint_int_oop_copy(StubId::stubgen_oop_disjoint_arraycopy_uninit_id, &entry);\n-    StubRoutines::_oop_arraycopy_uninit           = generate_conjoint_int_oop_copy(StubId::stubgen_oop_arraycopy_uninit_id, entry, nullptr);\n+    StubRoutines::_oop_disjoint_arraycopy  = generate_disjoint_int_oop_copy(StubId::stubgen_oop_disjoint_arraycopy_id, &nopush_entry);\n+    \/\/ disjoint nopush entry is needed by conjoint copy\n+    StubRoutines::_oop_disjoint_arraycopy_nopush  = nopush_entry;\n+    StubRoutines::_oop_arraycopy           = generate_conjoint_int_oop_copy(StubId::stubgen_oop_arraycopy_id, StubRoutines::_oop_disjoint_arraycopy_nopush, &nopush_entry);\n+    \/\/ conjoint nopush entry is needed by generic\/unsafe copy\n+    StubRoutines::_oop_arraycopy_nopush    = nopush_entry;\n+    StubRoutines::_oop_disjoint_arraycopy_uninit  = generate_disjoint_int_oop_copy(StubId::stubgen_oop_disjoint_arraycopy_uninit_id, &nopush_entry);\n+    \/\/ disjoint nopush entry is needed by conjoint copy\n+    StubRoutines::_oop_disjoint_arraycopy_uninit_nopush  = nopush_entry;\n+    \/\/ note that we don't need a returned nopush entry because the\n+    \/\/ generic\/unsafe copy does not cater for uninit arrays.\n+    StubRoutines::_oop_arraycopy_uninit           = generate_conjoint_int_oop_copy(StubId::stubgen_oop_arraycopy_uninit_id, StubRoutines::_oop_disjoint_arraycopy_uninit_nopush, nullptr);\n@@ -104,4 +137,12 @@\n-    StubRoutines::_oop_disjoint_arraycopy  = generate_disjoint_long_oop_copy(StubId::stubgen_oop_disjoint_arraycopy_id, &entry);\n-    StubRoutines::_oop_arraycopy           = generate_conjoint_long_oop_copy(StubId::stubgen_oop_arraycopy_id, entry, &entry_oop_arraycopy);\n-    StubRoutines::_oop_disjoint_arraycopy_uninit  = generate_disjoint_long_oop_copy(StubId::stubgen_oop_disjoint_arraycopy_uninit_id, &entry);\n-    StubRoutines::_oop_arraycopy_uninit           = generate_conjoint_long_oop_copy(StubId::stubgen_oop_arraycopy_uninit_id, entry, nullptr);\n+    StubRoutines::_oop_disjoint_arraycopy  = generate_disjoint_long_oop_copy(StubId::stubgen_oop_disjoint_arraycopy_id, &nopush_entry);\n+    \/\/ disjoint nopush entry is needed by conjoint copy\n+    StubRoutines::_oop_disjoint_arraycopy_nopush  = nopush_entry;\n+    StubRoutines::_oop_arraycopy           = generate_conjoint_long_oop_copy(StubId::stubgen_oop_arraycopy_id, StubRoutines::_oop_disjoint_arraycopy_nopush, &nopush_entry);\n+    \/\/ conjoint nopush entry is needed by generic\/unsafe copy\n+    StubRoutines::_oop_arraycopy_nopush    = nopush_entry;\n+    StubRoutines::_oop_disjoint_arraycopy_uninit  = generate_disjoint_long_oop_copy(StubId::stubgen_oop_disjoint_arraycopy_uninit_id, &nopush_entry);\n+    \/\/ disjoint nopush entry is needed by conjoint copy\n+    StubRoutines::_oop_disjoint_arraycopy_uninit_nopush  = nopush_entry;\n+    \/\/ note that we don't need a returned nopush entry because the\n+    \/\/ generic\/unsafe copy does not cater for uninit arrays.\n+    StubRoutines::_oop_arraycopy_uninit           = generate_conjoint_long_oop_copy(StubId::stubgen_oop_arraycopy_uninit_id, StubRoutines::_oop_disjoint_arraycopy_uninit_nopush, nullptr);\n@@ -110,1 +151,5 @@\n-  StubRoutines::_checkcast_arraycopy        = generate_checkcast_copy(StubId::stubgen_checkcast_arraycopy_id, &entry_checkcast_arraycopy);\n+  StubRoutines::_checkcast_arraycopy        = generate_checkcast_copy(StubId::stubgen_checkcast_arraycopy_id, &nopush_entry);\n+  \/\/ checkcast nopush entry is needed by generic copy\n+  StubRoutines::_checkcast_arraycopy_nopush = nopush_entry;\n+  \/\/ note that we don't need a returned nopush entry because the\n+  \/\/ generic copy does not cater for uninit arrays.\n@@ -113,10 +158,10 @@\n-  StubRoutines::_unsafe_arraycopy    = generate_unsafe_copy(entry_jbyte_arraycopy,\n-                                                            entry_jshort_arraycopy,\n-                                                            entry_jint_arraycopy,\n-                                                            entry_jlong_arraycopy);\n-  StubRoutines::_generic_arraycopy   = generate_generic_copy(entry_jbyte_arraycopy,\n-                                                             entry_jshort_arraycopy,\n-                                                             entry_jint_arraycopy,\n-                                                             entry_oop_arraycopy,\n-                                                             entry_jlong_arraycopy,\n-                                                             entry_checkcast_arraycopy);\n+  StubRoutines::_unsafe_arraycopy    = generate_unsafe_copy(StubRoutines::_jbyte_arraycopy_nopush,\n+                                                            StubRoutines::_jshort_arraycopy_nopush,\n+                                                            StubRoutines::_jint_arraycopy_nopush,\n+                                                            StubRoutines::_jlong_arraycopy_nopush);\n+  StubRoutines::_generic_arraycopy   = generate_generic_copy(StubRoutines::_jbyte_arraycopy_nopush,\n+                                                             StubRoutines::_jshort_arraycopy_nopush,\n+                                                             StubRoutines::_jint_arraycopy_nopush,\n+                                                             StubRoutines::_oop_arraycopy_nopush,\n+                                                             StubRoutines::_jlong_arraycopy_nopush,\n+                                                             StubRoutines::_checkcast_arraycopy_nopush);\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64_arraycopy.cpp","additions":82,"deletions":37,"binary":false,"changes":119,"status":"modified"},{"patch":"@@ -1019,10 +1019,0 @@\n-  \/\/ Currently APX support is only enabled for targets supporting AVX512VL feature.\n-  bool apx_supported = os_supports_apx_egprs() && supports_apx_f() && supports_avx512vl();\n-  if (UseAPX && !apx_supported) {\n-    warning(\"UseAPX is not supported on this CPU, setting it to false\");\n-    FLAG_SET_DEFAULT(UseAPX, false);\n-  }\n-\n-  if (!UseAPX) {\n-    _features.clear_feature(CPU_APX_F);\n-  }\n@@ -1052,0 +1042,1 @@\n+      _features.clear_feature(CPU_APX_F);\n@@ -1071,0 +1062,11 @@\n+    \/\/ Currently APX support is only enabled for targets supporting AVX512VL feature.\n+  bool apx_supported = os_supports_apx_egprs() && supports_apx_f() && supports_avx512vl();\n+  if (UseAPX && !apx_supported) {\n+    warning(\"UseAPX is not supported on this CPU, setting it to false\");\n+    FLAG_SET_DEFAULT(UseAPX, false);\n+  }\n+\n+  if (!UseAPX) {\n+    _features.clear_feature(CPU_APX_F);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":12,"deletions":10,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -59,1 +59,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -49,2 +49,2 @@\n-void AOTLinkedClassBulkLoader::serialize(SerializeClosure* soc, bool is_static_archive) {\n-  AOTLinkedClassTable::get(is_static_archive)->serialize(soc);\n+void AOTLinkedClassBulkLoader::serialize(SerializeClosure* soc) {\n+  AOTLinkedClassTable::get()->serialize(soc);\n@@ -60,1 +60,1 @@\n-    return Atomic::load_acquire(&_all_completed);\n+    return AtomicAccess::load_acquire(&_all_completed);\n@@ -93,1 +93,1 @@\n-  Atomic::release_store(&_all_completed, true);\n+  AtomicAccess::release_store(&_all_completed, true);\n@@ -120,2 +120,2 @@\n-  load_table(AOTLinkedClassTable::for_static_archive(),  class_category, h_loader, CHECK);\n-  load_table(AOTLinkedClassTable::for_dynamic_archive(), class_category, h_loader, CHECK);\n+  AOTLinkedClassTable* table = AOTLinkedClassTable::get();\n+  load_table(table, class_category, h_loader, CHECK);\n@@ -125,3 +125,0 @@\n-  \/\/\n-  \/\/ Only the classes in the static archive can have archived mirrors.\n-  AOTLinkedClassTable* static_table = AOTLinkedClassTable::for_static_archive();\n@@ -134,1 +131,1 @@\n-    init_required_classes_for_loader(h_loader, static_table->boot2(), CHECK);\n+    init_required_classes_for_loader(h_loader, table->boot2(), CHECK);\n@@ -137,1 +134,1 @@\n-    init_required_classes_for_loader(h_loader, static_table->platform(), CHECK);\n+    init_required_classes_for_loader(h_loader, table->platform(), CHECK);\n@@ -140,1 +137,1 @@\n-    init_required_classes_for_loader(h_loader, static_table->app(), CHECK);\n+    init_required_classes_for_loader(h_loader, table->app(), CHECK);\n@@ -336,1 +333,1 @@\n-  init_required_classes_for_loader(Handle(), AOTLinkedClassTable::for_static_archive()->boot(), CHECK);\n+  init_required_classes_for_loader(Handle(), AOTLinkedClassTable::get()->boot(), CHECK);\n@@ -431,2 +428,1 @@\n-    \/\/ Only static archive can have training data.\n-    AOTLinkedClassTable* table = AOTLinkedClassTable::for_static_archive();\n+    AOTLinkedClassTable* table = AOTLinkedClassTable::get();\n","filename":"src\/hotspot\/share\/cds\/aotLinkedClassBulkLoader.cpp","additions":11,"deletions":15,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -506,1 +506,1 @@\n-  AOTLinkedClassBulkLoader::serialize(soc, true);\n+  AOTLinkedClassBulkLoader::serialize(soc);\n@@ -790,1 +790,1 @@\n-      InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(mirror.resolve()));\n+      InstanceKlass* ik = java_lang_Class::as_InstanceKlass(mirror.resolve());\n@@ -817,1 +817,1 @@\n-      InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(mirror.resolve()));\n+      InstanceKlass* ik = java_lang_Class::as_InstanceKlass(mirror.resolve());\n@@ -1306,1 +1306,1 @@\n-    vm_exit_during_initialization(\"Unable to use shared archive.\", nullptr);\n+    vm_exit_during_initialization(\"Unable to use shared archive. Unrecoverable archive loading error (run with -Xlog:aot,cds for details)\", message);\n@@ -1434,0 +1434,1 @@\n+    log_info(cds)(\"Opening of static archive %s failed\", static_archive);\n@@ -2010,1 +2011,1 @@\n-    ArchiveBuilder::serialize_dynamic_archivable_items(&rc);\n+    DynamicArchive::serialize(&rc);\n","filename":"src\/hotspot\/share\/cds\/aotMetaspace.cpp","additions":6,"deletions":5,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -27,1 +27,0 @@\n-#include \"cds\/aotLinkedClassBulkLoader.hpp\"\n@@ -1024,7 +1023,0 @@\n-void ArchiveBuilder::serialize_dynamic_archivable_items(SerializeClosure* soc) {\n-  SymbolTable::serialize_shared_table_header(soc, false);\n-  SystemDictionaryShared::serialize_dictionary_headers(soc, false);\n-  DynamicArchive::serialize_array_klasses(soc);\n-  AOTLinkedClassBulkLoader::serialize(soc, false);\n-}\n-\n","filename":"src\/hotspot\/share\/cds\/archiveBuilder.cpp","additions":0,"deletions":8,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -421,1 +421,1 @@\n-  assert(Atomic::load(&_state) != WORKING, \"Should not be working\");\n+  assert(AtomicAccess::load(&_state) != WORKING, \"Should not be working\");\n@@ -438,1 +438,1 @@\n-    int cur = Atomic::load(&_started_workers);\n+    int cur = AtomicAccess::load(&_started_workers);\n@@ -442,1 +442,1 @@\n-    if (Atomic::cmpxchg(&_started_workers, cur, cur + 1, memory_order_relaxed) == cur) {\n+    if (AtomicAccess::cmpxchg(&_started_workers, cur, cur + 1, memory_order_relaxed) == cur) {\n@@ -450,3 +450,3 @@\n-  assert(Atomic::load(&_state) == UNUSED, \"Should be unused yet\");\n-  assert(Atomic::load(&_task) == nullptr, \"Should not have running tasks\");\n-  Atomic::store(&_state, WORKING);\n+  assert(AtomicAccess::load(&_state) == UNUSED, \"Should be unused yet\");\n+  assert(AtomicAccess::load(&_task) == nullptr, \"Should not have running tasks\");\n+  AtomicAccess::store(&_state, WORKING);\n@@ -460,2 +460,2 @@\n-  assert(Atomic::load(&_state) == WORKING, \"Should be working\");\n-  Atomic::store(&_state, SHUTDOWN);\n+  assert(AtomicAccess::load(&_state) == WORKING, \"Should be working\");\n+  AtomicAccess::store(&_state, SHUTDOWN);\n@@ -478,2 +478,2 @@\n-  Atomic::store(&_finish_tokens, _num_workers + 1);\n-  Atomic::release_store(&_task, task);\n+  AtomicAccess::store(&_finish_tokens, _num_workers + 1);\n+  AtomicAccess::release_store(&_task, task);\n@@ -497,1 +497,1 @@\n-  while (Atomic::load(&_finish_tokens) != 0) {\n+  while (AtomicAccess::load(&_finish_tokens) != 0) {\n@@ -503,1 +503,1 @@\n-  assert(Atomic::load(&_finish_tokens) == 0, \"All tokens are consumed\");\n+  assert(AtomicAccess::load(&_finish_tokens) == 0, \"All tokens are consumed\");\n@@ -509,1 +509,1 @@\n-  ArchiveWorkerTask* task = Atomic::load_acquire(&_task);\n+  ArchiveWorkerTask* task = AtomicAccess::load_acquire(&_task);\n@@ -517,1 +517,1 @@\n-  if (Atomic::sub(&_finish_tokens, 1, memory_order_relaxed) == 1) {\n+  if (AtomicAccess::sub(&_finish_tokens, 1, memory_order_relaxed) == 1) {\n@@ -521,1 +521,1 @@\n-    int last = Atomic::sub(&_finish_tokens, 1, memory_order_relaxed);\n+    int last = AtomicAccess::sub(&_finish_tokens, 1, memory_order_relaxed);\n@@ -528,1 +528,1 @@\n-    int chunk = Atomic::load(&_chunk);\n+    int chunk = AtomicAccess::load(&_chunk);\n@@ -532,1 +532,1 @@\n-    if (Atomic::cmpxchg(&_chunk, chunk, chunk + 1, memory_order_relaxed) == chunk) {\n+    if (AtomicAccess::cmpxchg(&_chunk, chunk, chunk + 1, memory_order_relaxed) == chunk) {\n","filename":"src\/hotspot\/share\/cds\/archiveUtils.cpp","additions":17,"deletions":17,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -780,0 +780,7 @@\n+  if (is_dumping_dynamic_archive() && AOTClassLinking) {\n+    if (FLAG_IS_CMDLINE(AOTClassLinking)) {\n+      log_warning(cds)(\"AOTClassLinking is not supported for dynamic CDS archive\");\n+    }\n+    FLAG_SET_ERGO(AOTClassLinking, false);\n+  }\n+\n@@ -886,1 +893,5 @@\n-  return t != nullptr && (t->is_VM_thread() || t == _dumper_thread);\n+  return t->is_VM_thread() || t == _dumper_thread;\n+}\n+\n+bool CDSConfig::current_thread_is_dumper() {\n+  return Thread::current() == _dumper_thread;\n@@ -1038,5 +1049,4 @@\n-  if (is_dumping_preimage_static_archive()) {\n-    return false;\n-  } else if (is_dumping_dynamic_archive()) {\n-    return is_using_full_module_graph() && AOTClassLinking;\n-  } else if (is_dumping_static_archive()) {\n+  if (is_dumping_classic_static_archive() || is_dumping_final_static_archive()) {\n+    \/\/ FMG is required to guarantee that all cached boot\/platform\/app classes\n+    \/\/ are visible in the production run, so they can be unconditionally\n+    \/\/ loaded during VM bootstrap.\n","filename":"src\/hotspot\/share\/cds\/cdsConfig.cpp","additions":16,"deletions":6,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -232,0 +232,1 @@\n+  static bool current_thread_is_dumper() NOT_CDS_RETURN_(false);\n","filename":"src\/hotspot\/share\/cds\/cdsConfig.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -50,1 +50,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -90,1 +90,1 @@\n-  Atomic::store(&_parsing_thread, Thread::current());\n+  AtomicAccess::store(&_parsing_thread, Thread::current());\n@@ -107,1 +107,1 @@\n-  return Atomic::load(&_parsing_thread) == Thread::current();\n+  return AtomicAccess::load(&_parsing_thread) == Thread::current();\n@@ -111,1 +111,1 @@\n-  Atomic::store(&_parsing_thread, (Thread*)nullptr);\n+  AtomicAccess::store(&_parsing_thread, (Thread*)nullptr);\n","filename":"src\/hotspot\/share\/cds\/classListParser.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -163,1 +163,0 @@\n-      AOTClassLinker::write_to_archive();\n@@ -167,1 +166,1 @@\n-      ArchiveBuilder::serialize_dynamic_archivable_items(&wc);\n+      DynamicArchive::serialize(&wc);\n@@ -420,0 +419,6 @@\n+void DynamicArchive::serialize(SerializeClosure* soc) {\n+  SymbolTable::serialize_shared_table_header(soc, false);\n+  SystemDictionaryShared::serialize_dictionary_headers(soc, false);\n+  soc->do_ptr(&_dynamic_archive_array_klasses);\n+}\n+\n@@ -464,4 +469,0 @@\n-void DynamicArchive::serialize_array_klasses(SerializeClosure* soc) {\n-  soc->do_ptr(&_dynamic_archive_array_klasses);\n-}\n-\n","filename":"src\/hotspot\/share\/cds\/dynamicArchive.cpp","additions":7,"deletions":6,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -86,0 +86,1 @@\n+friend class VMStructs;                \\\n","filename":"src\/hotspot\/share\/ci\/ciClassList.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -3111,1 +3111,2 @@\n-    verify_legal_class_modifiers(flags, CHECK_0);\n+    Symbol* inner_name_symbol = inner_name_index == 0 ? nullptr : cp->symbol_at(inner_name_index);\n+    verify_legal_class_modifiers(flags, inner_name_symbol, inner_name_index == 0, CHECK_0);\n@@ -4454,1 +4455,2 @@\n-void ClassFileParser::verify_legal_class_modifiers(jint flags, TRAPS) const {\n+\/\/ Verify the class modifiers for the current class, or an inner class if inner_name is non-null.\n+void ClassFileParser::verify_legal_class_modifiers(jint flags, Symbol* inner_name, bool is_anonymous_inner_class, TRAPS) const {\n@@ -4490,6 +4492,25 @@\n-    Exceptions::fthrow(\n-      THREAD_AND_LOCATION,\n-      vmSymbols::java_lang_ClassFormatError(),\n-      \"Illegal class modifiers in class %s%s: 0x%X\",\n-      _class_name->as_C_string(), class_note, flags\n-    );\n+    \/\/ Names are all known to be < 64k so we know this formatted message is not excessively large.\n+    if (inner_name == nullptr && !is_anonymous_inner_class) {\n+      Exceptions::fthrow(\n+        THREAD_AND_LOCATION,\n+        vmSymbols::java_lang_ClassFormatError(),\n+        \"Illegal class modifiers in class %s: 0x%X\",\n+        _class_name->as_C_string(), flags\n+      );\n+    } else {\n+      if (is_anonymous_inner_class) {\n+        Exceptions::fthrow(\n+          THREAD_AND_LOCATION,\n+          vmSymbols::java_lang_ClassFormatError(),\n+          \"Illegal class modifiers in anonymous inner class of class %s: 0x%X\",\n+          _class_name->as_C_string(), flags\n+        );\n+      } else {\n+        Exceptions::fthrow(\n+          THREAD_AND_LOCATION,\n+          vmSymbols::java_lang_ClassFormatError(),\n+          \"Illegal class modifiers in inner class %s of class %s: 0x%X\",\n+          inner_name->as_C_string(), _class_name->as_C_string(), flags\n+        );\n+      }\n+    }\n@@ -5871,1 +5892,1 @@\n-  verify_legal_class_modifiers(flags, CHECK);\n+  verify_legal_class_modifiers(flags, nullptr, false, CHECK);\n@@ -6031,2 +6052,2 @@\n-    Atomic::cmpxchg(&counter, (size_t)0, Arguments::default_SharedBaseAddress()); \/\/ initialize it\n-    size_t new_id = Atomic::add(&counter, (size_t)1);\n+    AtomicAccess::cmpxchg(&counter, (size_t)0, Arguments::default_SharedBaseAddress()); \/\/ initialize it\n+    size_t new_id = AtomicAccess::add(&counter, (size_t)1);\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":32,"deletions":11,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -468,4 +468,3 @@\n-  void verify_legal_class_modifiers(jint flags, TRAPS) const;\n-  void verify_legal_field_modifiers(jint flags,\n-                                    AccessFlags class_access_flags,\n-                                    TRAPS) const;\n+  void verify_legal_class_modifiers(jint flags, Symbol* inner_name,\n+                                    bool is_anonymous_inner_class, TRAPS) const;\n+  void verify_legal_field_modifiers(jint flags, AccessFlags class_access_flags, TRAPS) const;\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.hpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -753,1 +753,1 @@\n-      Atomic::release_store(&_first_append_entry_list, new_entry);\n+      AtomicAccess::release_store(&_first_append_entry_list, new_entry);\n","filename":"src\/hotspot\/share\/classfile\/classLoader.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -76,1 +76,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -196,1 +196,1 @@\n-    Atomic::release_store(&_head, next);\n+    AtomicAccess::release_store(&_head, next);\n@@ -200,1 +200,1 @@\n-  Atomic::release_store(&_head->_size, _head->_size + 1);\n+  AtomicAccess::release_store(&_head->_size, _head->_size + 1);\n@@ -206,1 +206,1 @@\n-  Chunk* chunk = Atomic::load_acquire(&_head);\n+  Chunk* chunk = AtomicAccess::load_acquire(&_head);\n@@ -208,1 +208,1 @@\n-    count += Atomic::load(&chunk->_size);\n+    count += AtomicAccess::load(&chunk->_size);\n@@ -221,1 +221,1 @@\n-  Chunk* head = Atomic::load_acquire(&_head);\n+  Chunk* head = AtomicAccess::load_acquire(&_head);\n@@ -224,1 +224,1 @@\n-    oops_do_chunk(f, head, Atomic::load_acquire(&head->_size));\n+    oops_do_chunk(f, head, AtomicAccess::load_acquire(&head->_size));\n@@ -262,1 +262,1 @@\n-  Chunk* chunk = Atomic::load_acquire(&_head);\n+  Chunk* chunk = AtomicAccess::load_acquire(&_head);\n@@ -264,1 +264,1 @@\n-    if (&(chunk->_data[0]) <= oop_handle && oop_handle < &(chunk->_data[Atomic::load(&chunk->_size)])) {\n+    if (&(chunk->_data[0]) <= oop_handle && oop_handle < &(chunk->_data[AtomicAccess::load(&chunk->_size)])) {\n@@ -275,1 +275,1 @@\n-    int old_claim = Atomic::load(&_claim);\n+    int old_claim = AtomicAccess::load(&_claim);\n@@ -280,1 +280,1 @@\n-    if (Atomic::cmpxchg(&_claim, old_claim, new_claim) == old_claim) {\n+    if (AtomicAccess::cmpxchg(&_claim, old_claim, new_claim) == old_claim) {\n@@ -294,1 +294,1 @@\n-    int old_claim = Atomic::load(&_claim);\n+    int old_claim = AtomicAccess::load(&_claim);\n@@ -299,1 +299,1 @@\n-    if (Atomic::cmpxchg(&_claim, old_claim, new_claim) == old_claim) {\n+    if (AtomicAccess::cmpxchg(&_claim, old_claim, new_claim) == old_claim) {\n@@ -387,1 +387,1 @@\n-  for (Klass* k = Atomic::load_acquire(&_klasses); k != nullptr; k = k->next_link()) {\n+  for (Klass* k = AtomicAccess::load_acquire(&_klasses); k != nullptr; k = k->next_link()) {\n@@ -395,1 +395,1 @@\n-  for (Klass* k = Atomic::load_acquire(&_klasses); k != nullptr; k = k->next_link()) {\n+  for (Klass* k = AtomicAccess::load_acquire(&_klasses); k != nullptr; k = k->next_link()) {\n@@ -403,1 +403,1 @@\n-  for (Klass* k = Atomic::load_acquire(&_klasses); k != nullptr; k = k->next_link()) {\n+  for (Klass* k = AtomicAccess::load_acquire(&_klasses); k != nullptr; k = k->next_link()) {\n@@ -412,1 +412,1 @@\n-  for (Klass* k = Atomic::load_acquire(&_klasses); k != nullptr; k = k->next_link()) {\n+  for (Klass* k = AtomicAccess::load_acquire(&_klasses); k != nullptr; k = k->next_link()) {\n@@ -440,1 +440,1 @@\n-  for (Klass* k = Atomic::load_acquire(&_klasses); k != nullptr; k = k->next_link()) {\n+  for (Klass* k = AtomicAccess::load_acquire(&_klasses); k != nullptr; k = k->next_link()) {\n@@ -450,1 +450,1 @@\n-  for (Klass* k = Atomic::load_acquire(&_klasses); k != nullptr; k = k->next_link()) {\n+  for (Klass* k = AtomicAccess::load_acquire(&_klasses); k != nullptr; k = k->next_link()) {\n@@ -512,1 +512,1 @@\n-    NOT_PRODUCT(Atomic::inc(&_dependency_count));\n+    NOT_PRODUCT(AtomicAccess::inc(&_dependency_count));\n@@ -537,1 +537,1 @@\n-    Atomic::release_store(&_klasses, k);\n+    AtomicAccess::release_store(&_klasses, k);\n@@ -651,1 +651,1 @@\n-  ModuleEntryTable* modules = Atomic::load_acquire(&_modules);\n+  ModuleEntryTable* modules = AtomicAccess::load_acquire(&_modules);\n@@ -661,1 +661,1 @@\n-        Atomic::release_store(&_modules, modules);\n+        AtomicAccess::release_store(&_modules, modules);\n@@ -835,1 +835,1 @@\n-  ClassLoaderMetaspace* metaspace = Atomic::load_acquire(&_metaspace);\n+  ClassLoaderMetaspace* metaspace = AtomicAccess::load_acquire(&_metaspace);\n@@ -849,1 +849,1 @@\n-      Atomic::release_store(&_metaspace, metaspace);\n+      AtomicAccess::release_store(&_metaspace, metaspace);\n@@ -1140,1 +1140,1 @@\n-  for (Klass* k = Atomic::load_acquire(&_klasses); k != nullptr; k = k->next_link()) {\n+  for (Klass* k = AtomicAccess::load_acquire(&_klasses); k != nullptr; k = k->next_link()) {\n","filename":"src\/hotspot\/share\/classfile\/classLoaderData.cpp","additions":26,"deletions":26,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -31,1 +31,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n","filename":"src\/hotspot\/share\/classfile\/classLoaderData.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -84,1 +84,1 @@\n-#include \"runtime\/reflectionUtils.hpp\"\n+#include \"runtime\/reflection.hpp\"\n@@ -209,1 +209,1 @@\n-  uint8_t value = Atomic::load(addr);\n+  uint8_t value = AtomicAccess::load(addr);\n@@ -213,1 +213,1 @@\n-    value = Atomic::cmpxchg(addr, old_value, value);\n+    value = AtomicAccess::cmpxchg(addr, old_value, value);\n@@ -995,1 +995,1 @@\n-void java_lang_Class::initialize_mirror_fields(Klass* k,\n+void java_lang_Class::initialize_mirror_fields(InstanceKlass* ik,\n@@ -1010,1 +1010,1 @@\n-  InstanceKlass::cast(k)->do_local_static_fields(&initialize_static_field, mirror, CHECK);\n+  ik->do_local_static_fields(&initialize_static_field, mirror, CHECK);\n@@ -1126,2 +1126,1 @@\n-\n-    initialize_mirror_fields(k, mirror, protection_domain, classData, THREAD);\n+    initialize_mirror_fields(InstanceKlass::cast(k), mirror, protection_domain, classData, THREAD);\n@@ -2171,1 +2170,1 @@\n-  int res = Atomic::cmpxchg(addr, old_state, new_state);\n+  int res = AtomicAccess::cmpxchg(addr, old_state, new_state);\n@@ -2189,1 +2188,1 @@\n-  jboolean vthread_on_list = Atomic::load(addr);\n+  jboolean vthread_on_list = AtomicAccess::load(addr);\n@@ -2191,1 +2190,1 @@\n-    vthread_on_list = Atomic::cmpxchg(addr, (jboolean)JNI_FALSE, (jboolean)JNI_TRUE);\n+    vthread_on_list = AtomicAccess::cmpxchg(addr, (jboolean)JNI_FALSE, (jboolean)JNI_TRUE);\n@@ -2621,1 +2620,1 @@\n-  InstanceKlass* holder = InstanceKlass::cast(java_lang_Class::as_Klass(mirror()));\n+  InstanceKlass* holder = java_lang_Class::as_InstanceKlass(mirror());\n@@ -3000,1 +2999,1 @@\n-    InstanceKlass* holder = InstanceKlass::cast(java_lang_Class::as_Klass(bte._mirror()));\n+    InstanceKlass* holder = java_lang_Class::as_InstanceKlass(bte._mirror());\n@@ -3086,1 +3085,1 @@\n-  InstanceKlass* holder = InstanceKlass::cast(java_lang_Class::as_Klass(bte._mirror()));\n+  InstanceKlass* holder = java_lang_Class::as_InstanceKlass(bte._mirror());\n@@ -3472,1 +3471,1 @@\n-  Klass* klass = vmClasses::reflect_Method_klass();\n+  InstanceKlass* klass = vmClasses::reflect_Method_klass();\n@@ -3475,2 +3474,2 @@\n-  assert(InstanceKlass::cast(klass)->is_initialized(), \"must be initialized\");\n-  return InstanceKlass::cast(klass)->allocate_instance_handle(THREAD);\n+  assert(klass->is_initialized(), \"must be initialized\");\n+  return klass->allocate_instance_handle(THREAD);\n@@ -3773,4 +3772,1 @@\n-int reflect_ConstantPool::_oop_offset;\n-\n-#define CONSTANTPOOL_FIELDS_DO(macro) \\\n-  macro(_oop_offset, k, \"constantPoolOop\", object_signature, false)\n+int reflect_ConstantPool::_vmholder_offset;\n@@ -3780,2 +3776,2 @@\n-  \/\/ The field is called ConstantPool* in the sun.reflect.ConstantPool class.\n-  CONSTANTPOOL_FIELDS_DO(FIELD_COMPUTE_OFFSET);\n+  \/\/ The field is injected and called Object vmholder in the jdk.internal.reflect.ConstantPool class.\n+  CONSTANTPOOL_INJECTED_FIELDS(INJECTED_FIELD_COMPUTE_OFFSET);\n@@ -3786,1 +3782,1 @@\n-  CONSTANTPOOL_FIELDS_DO(FIELD_SERIALIZE_OFFSET);\n+  CONSTANTPOOL_INJECTED_FIELDS(INJECTED_FIELD_SERIALIZE_OFFSET);\n@@ -3939,0 +3935,1 @@\n+  assert(_vmholder_offset != 0, \"Uninitialized vmholder\");\n@@ -3941,1 +3938,1 @@\n-  reflect->obj_field_put(_oop_offset, mirror);\n+  reflect->obj_field_put(_vmholder_offset, mirror);\n@@ -3945,4 +3942,3 @@\n-\n-  oop mirror = reflect->obj_field(_oop_offset);\n-  Klass* k = java_lang_Class::as_Klass(mirror);\n-  assert(k->is_instance_klass(), \"Must be\");\n+  assert(_vmholder_offset != 0, \"Uninitialized vmholder\");\n+  oop mirror = reflect->obj_field(_vmholder_offset);\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(mirror);\n@@ -3955,1 +3951,1 @@\n-  return InstanceKlass::cast(k)->constants();\n+  return ik->constants();\n@@ -4799,1 +4795,1 @@\n-  return Atomic::load_acquire(loader->field_addr<ClassLoaderData*>(_loader_data_offset));\n+  return AtomicAccess::load_acquire(loader->field_addr<ClassLoaderData*>(_loader_data_offset));\n@@ -4811,1 +4807,1 @@\n-  Atomic::release_store(loader->field_addr<ClassLoaderData*>(_loader_data_offset), new_data);\n+  AtomicAccess::release_store(loader->field_addr<ClassLoaderData*>(_loader_data_offset), new_data);\n@@ -5565,1 +5561,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(klass());\n+  InstanceKlass* ik = klass();\n@@ -5591,1 +5587,0 @@\n-  FilteredFieldsMap::initialize();  \/\/ must be done after computing offsets.\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":28,"deletions":33,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -273,2 +273,1 @@\n-\n-  static void initialize_mirror_fields(Klass* k, Handle mirror, Handle protection_domain,\n+  static void initialize_mirror_fields(InstanceKlass* ik, Handle mirror, Handle protection_domain,\n@@ -298,1 +297,1 @@\n-  \/\/ Conversion\n+  \/\/ Conversion -- java_class must not be null. The return value is null only if java_class is a primitive type.\n@@ -300,0 +299,2 @@\n+  static InstanceKlass* as_InstanceKlass(oop java_class);\n+\n@@ -940,0 +941,3 @@\n+#define CONSTANTPOOL_INJECTED_FIELDS(macro)                             \\\n+  macro(reflect_ConstantPool, vmholder, object_signature, false)\n+\n@@ -944,2 +948,3 @@\n-  \/\/ offsets at run-time.\n-  static int _oop_offset;\n+  \/\/ offsets at run-time. This field is the oop offset for the\n+  \/\/ actual constant pool, previously called constantPoolOop.\n+  static int _vmholder_offset;\n@@ -957,1 +962,0 @@\n-  static int oop_offset() { CHECK_INIT(_oop_offset); }\n@@ -1904,1 +1908,1 @@\n-  const bool           may_be_java;\n+  const bool may_be_java;\n@@ -1907,2 +1911,2 @@\n-  Klass* klass() const      { return vmClasses::klass_at(klass_id); }\n-  Symbol* name() const      { return lookup_symbol(name_index); }\n+  InstanceKlass* klass() const { return vmClasses::klass_at(klass_id); }\n+  Symbol* name() const { return lookup_symbol(name_index); }\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.hpp","additions":13,"deletions":9,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -50,1 +50,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -328,1 +328,1 @@\n-  Atomic::inc(&_items_count);\n+  AtomicAccess::inc(&_items_count);\n@@ -332,1 +332,1 @@\n-  Atomic::dec(&_items_count);\n+  AtomicAccess::dec(&_items_count);\n@@ -348,1 +348,1 @@\n-  return Atomic::load_acquire(&_has_work);\n+  return AtomicAccess::load_acquire(&_has_work);\n@@ -352,1 +352,1 @@\n-  return Atomic::load_acquire(&_items_count);\n+  return AtomicAccess::load_acquire(&_items_count);\n@@ -359,1 +359,1 @@\n-    Atomic::store(&_has_work, true);\n+    AtomicAccess::store(&_has_work, true);\n@@ -513,1 +513,1 @@\n-  assert(!Atomic::load_acquire(&_disable_interning_during_cds_dump),\n+  assert(!AtomicAccess::load_acquire(&_disable_interning_during_cds_dump),\n@@ -669,1 +669,1 @@\n-    Atomic::release_store(&_has_work, false);\n+    AtomicAccess::release_store(&_has_work, false);\n@@ -679,1 +679,1 @@\n-  Atomic::release_store(&_has_work, false);\n+  AtomicAccess::release_store(&_has_work, false);\n@@ -969,1 +969,1 @@\n-  DEBUG_ONLY(Atomic::release_store(&_disable_interning_during_cds_dump, true));\n+  DEBUG_ONLY(AtomicAccess::release_store(&_disable_interning_during_cds_dump, true));\n@@ -1108,1 +1108,1 @@\n-  DEBUG_ONLY(Atomic::release_store(&_disable_interning_during_cds_dump, false));\n+  DEBUG_ONLY(AtomicAccess::release_store(&_disable_interning_during_cds_dump, false));\n","filename":"src\/hotspot\/share\/classfile\/stringTable.cpp","additions":11,"deletions":11,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -71,1 +71,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -1178,1 +1178,1 @@\n-  assert(Atomic::add(&ik->_shared_class_load_count, 1) == 1, \"shared class loaded more than once\");\n+  assert(AtomicAccess::add(&ik->_shared_class_load_count, 1) == 1, \"shared class loaded more than once\");\n@@ -1398,1 +1398,1 @@\n-    \/\/ Primitive classes return null since forName() can not be\n+    \/\/ Primitive classes return null since forName() cannot be\n@@ -1401,1 +1401,1 @@\n-      InstanceKlass* k = InstanceKlass::cast(java_lang_Class::as_Klass(obj));\n+      InstanceKlass* k = java_lang_Class::as_InstanceKlass(obj);\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -35,1 +35,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -107,2 +107,2 @@\n-    Atomic::store(&_speculated_klass, (uintptr_t)0);\n-    Atomic::store(&_speculated_method, (Method*)nullptr);\n+    AtomicAccess::store(&_speculated_klass, (uintptr_t)0);\n+    AtomicAccess::store(&_speculated_method, (Method*)nullptr);\n","filename":"src\/hotspot\/share\/code\/compiledIC.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -62,1 +62,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -379,1 +379,1 @@\n-  return Atomic::load(&_next);\n+  return AtomicAccess::load(&_next);\n@@ -383,1 +383,1 @@\n-  Atomic::store(&_next, ec);\n+  AtomicAccess::store(&_next, ec);\n@@ -495,1 +495,1 @@\n-    Atomic::store(&_deoptimization_status, deoptimize_done);\n+    AtomicAccess::store(&_deoptimization_status, deoptimize_done);\n@@ -500,1 +500,1 @@\n-  return Atomic::load_acquire(&_exception_cache);\n+  return AtomicAccess::load_acquire(&_exception_cache);\n@@ -520,1 +520,1 @@\n-        if (Atomic::cmpxchg(&_exception_cache, ec, next) == ec) {\n+        if (AtomicAccess::cmpxchg(&_exception_cache, ec, next) == ec) {\n@@ -530,1 +530,1 @@\n-    if (Atomic::cmpxchg(&_exception_cache, ec, new_entry) == ec) {\n+    if (AtomicAccess::cmpxchg(&_exception_cache, ec, new_entry) == ec) {\n@@ -563,1 +563,1 @@\n-        if (Atomic::cmpxchg(&_exception_cache, curr, next) != curr) {\n+        if (AtomicAccess::cmpxchg(&_exception_cache, curr, next) != curr) {\n@@ -933,1 +933,1 @@\n-          Atomic::store(r->metadata_addr(), (Method*)nullptr);\n+          AtomicAccess::store(r->metadata_addr(), (Method*)nullptr);\n@@ -1945,1 +1945,1 @@\n-  Atomic::store(&_gc_epoch, CodeCache::gc_epoch());\n+  AtomicAccess::store(&_gc_epoch, CodeCache::gc_epoch());\n@@ -1951,1 +1951,1 @@\n-  return Atomic::load(&_gc_epoch) >= CodeCache::previous_completed_gc_marking_cycle();\n+  return AtomicAccess::load(&_gc_epoch) >= CodeCache::previous_completed_gc_marking_cycle();\n@@ -1978,1 +1978,1 @@\n-  Atomic::store(&_state, new_state);\n+  AtomicAccess::store(&_state, new_state);\n@@ -2029,1 +2029,1 @@\n-  if (Atomic::load(&_state) == not_entrant) {\n+  if (AtomicAccess::load(&_state) == not_entrant) {\n@@ -2041,1 +2041,1 @@\n-    if (Atomic::load(&_state) == not_entrant) {\n+    if (AtomicAccess::load(&_state) == not_entrant) {\n@@ -2412,1 +2412,1 @@\n-  uint8_t state = Atomic::load(&_is_unloading_state);\n+  uint8_t state = AtomicAccess::load(&_is_unloading_state);\n@@ -2435,1 +2435,1 @@\n-  uint8_t found_state = Atomic::cmpxchg(&_is_unloading_state, state, new_state, memory_order_relaxed);\n+  uint8_t found_state = AtomicAccess::cmpxchg(&_is_unloading_state, state, new_state, memory_order_relaxed);\n@@ -2448,1 +2448,1 @@\n-  Atomic::store(&_is_unloading_state, state);\n+  AtomicAccess::store(&_is_unloading_state, state);\n@@ -2533,1 +2533,1 @@\n-      (Atomic::replace_if_null(&_oops_do_mark_link, mark_link(this, claim_weak_request_tag)))) {\n+      (AtomicAccess::replace_if_null(&_oops_do_mark_link, mark_link(this, claim_weak_request_tag)))) {\n@@ -2547,1 +2547,1 @@\n-  oops_do_mark_link* old_next = Atomic::cmpxchg(&_oops_do_mark_link, mark_link(nullptr, claim_weak_request_tag), mark_link(this, claim_strong_done_tag));\n+  oops_do_mark_link* old_next = AtomicAccess::cmpxchg(&_oops_do_mark_link, mark_link(nullptr, claim_weak_request_tag), mark_link(this, claim_strong_done_tag));\n@@ -2558,1 +2558,1 @@\n-  oops_do_mark_link* old_next = Atomic::cmpxchg(&_oops_do_mark_link, next, mark_link(this, claim_strong_request_tag));\n+  oops_do_mark_link* old_next = AtomicAccess::cmpxchg(&_oops_do_mark_link, next, mark_link(this, claim_strong_request_tag));\n@@ -2569,1 +2569,1 @@\n-  oops_do_mark_link* old_next = Atomic::cmpxchg(&_oops_do_mark_link, next, mark_link(extract_nmethod(next), claim_strong_done_tag));\n+  oops_do_mark_link* old_next = AtomicAccess::cmpxchg(&_oops_do_mark_link, next, mark_link(extract_nmethod(next), claim_strong_done_tag));\n@@ -2584,1 +2584,1 @@\n-  nmethod* old_head = Atomic::xchg(&_oops_do_mark_nmethods, this);\n+  nmethod* old_head = AtomicAccess::xchg(&_oops_do_mark_nmethods, this);\n@@ -2590,1 +2590,1 @@\n-  if (Atomic::cmpxchg(&_oops_do_mark_link, mark_link(this, claim_weak_request_tag), mark_link(old_head, claim_weak_done_tag)) == mark_link(this, claim_weak_request_tag)) {\n+  if (AtomicAccess::cmpxchg(&_oops_do_mark_link, mark_link(this, claim_weak_request_tag), mark_link(old_head, claim_weak_done_tag)) == mark_link(this, claim_weak_request_tag)) {\n@@ -2601,1 +2601,1 @@\n-  nmethod* old_head = Atomic::xchg(&_oops_do_mark_nmethods, this);\n+  nmethod* old_head = AtomicAccess::xchg(&_oops_do_mark_nmethods, this);\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":24,"deletions":24,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -294,1 +294,1 @@\n-    return Atomic::load(&_deoptimization_status);\n+    return AtomicAccess::load(&_deoptimization_status);\n","filename":"src\/hotspot\/share\/code\/nmethod.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -130,1 +130,1 @@\n-      Atomic::store(&_table[i], (VtableStub*)nullptr);\n+      AtomicAccess::store(&_table[i], (VtableStub*)nullptr);\n@@ -274,1 +274,1 @@\n-  VtableStub* s = Atomic::load(&_table[hash]);\n+  VtableStub* s = AtomicAccess::load(&_table[hash]);\n@@ -285,1 +285,1 @@\n-  s->set_next(Atomic::load(&_table[h]));\n+  s->set_next(AtomicAccess::load(&_table[h]));\n@@ -287,1 +287,1 @@\n-  Atomic::release_store(&_table[h], s);\n+  AtomicAccess::release_store(&_table[h], s);\n@@ -299,1 +299,1 @@\n-  for (s = Atomic::load(&_table[hash]); s != nullptr && s->entry_point() != pc; s = s->next()) {}\n+  for (s = AtomicAccess::load(&_table[hash]); s != nullptr && s->entry_point() != pc; s = s->next()) {}\n@@ -312,1 +312,1 @@\n-    for (VtableStub* s = Atomic::load_acquire(&_table[i]); s != nullptr; s = s->next()) {\n+    for (VtableStub* s = AtomicAccess::load_acquire(&_table[i]); s != nullptr; s = s->next()) {\n@@ -325,1 +325,1 @@\n-    for (VtableStub* s = Atomic::load_acquire(&_table[i]); s != nullptr; s = s->next()) {\n+    for (VtableStub* s = AtomicAccess::load_acquire(&_table[i]); s != nullptr; s = s->next()) {\n","filename":"src\/hotspot\/share\/code\/vtableStubs.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -56,1 +56,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -227,0 +227,4 @@\n+\n+  \/\/ First, disarm the timeout. This still relies on the underlying task.\n+  thread->timeout()->disarm();\n+\n@@ -232,1 +236,0 @@\n-  thread->timeout()->disarm();\n@@ -1590,1 +1593,1 @@\n-    return Atomic::add(CICountNative ? &_native_compilation_id : &_compilation_id, 1);\n+    return AtomicAccess::add(CICountNative ? &_native_compilation_id : &_compilation_id, 1);\n@@ -1592,1 +1595,1 @@\n-    id = Atomic::add(&_osr_compilation_id, 1);\n+    id = AtomicAccess::add(&_osr_compilation_id, 1);\n@@ -1597,1 +1600,1 @@\n-    id = Atomic::add(&_compilation_id, 1);\n+    id = AtomicAccess::add(&_compilation_id, 1);\n@@ -1609,1 +1612,1 @@\n-  return Atomic::add(&_compilation_id, 1);\n+  return AtomicAccess::add(&_compilation_id, 1);\n","filename":"src\/hotspot\/share\/compiler\/compileBroker.cpp","additions":9,"deletions":6,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -38,1 +38,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n","filename":"src\/hotspot\/share\/compiler\/oopMap.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -45,1 +45,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -85,1 +85,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -1302,1 +1302,1 @@\n-    uint counter = Atomic::fetch_then_add(claim_counter, num_regions_per_stripe);\n+    uint counter = AtomicAccess::fetch_then_add(claim_counter, num_regions_per_stripe);\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -30,1 +30,1 @@\n-#include \"gc\/parallel\/psScavenge.inline.hpp\"\n+#include \"gc\/parallel\/psScavenge.hpp\"\n@@ -90,9 +90,0 @@\n-\/\/ Helper functions to get around the circular dependency between\n-\/\/ psScavenge.inline.hpp and psPromotionManager.inline.hpp.\n-bool PSPromotionManager::should_scavenge(oop* p, bool check_to_space) {\n-  return PSScavenge::should_scavenge(p, check_to_space);\n-}\n-bool PSPromotionManager::should_scavenge(narrowOop* p, bool check_to_space) {\n-  return PSScavenge::should_scavenge(p, check_to_space);\n-}\n-\n@@ -216,1 +207,1 @@\n-void PSPromotionManager::drain_stacks_depth(bool totally_drain) {\n+void PSPromotionManager::drain_stacks(bool totally_drain) {\n","filename":"src\/hotspot\/share\/gc\/parallel\/psPromotionManager.cpp","additions":2,"deletions":11,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -34,1 +34,1 @@\n-#include \"gc\/parallel\/psScavenge.inline.hpp\"\n+#include \"gc\/parallel\/psScavenge.hpp\"\n@@ -142,1 +142,2 @@\n-  assert(should_scavenge(&o), \"Sanity\");\n+  assert(PSScavenge::is_obj_in_young(o), \"precondition\");\n+  assert(!PSScavenge::is_obj_in_to_space(o), \"precondition\");\n@@ -238,3 +239,1 @@\n-  assert(should_scavenge(&o), \"Sanity\");\n-\n-  oop new_obj = nullptr;\n+  HeapWord* new_obj_addr = nullptr;\n@@ -263,1 +262,1 @@\n-      new_obj = cast_to_oop(allocate_in_young_gen(klass, new_obj_size, age));\n+      new_obj_addr = allocate_in_young_gen(klass, new_obj_size, age);\n@@ -268,3 +267,3 @@\n-  if (new_obj == nullptr) {\n-    new_obj = cast_to_oop(allocate_in_old_gen(klass, new_obj_size, age));\n-    if (new_obj == nullptr) {\n+  if (new_obj_addr == nullptr) {\n+    new_obj_addr = allocate_in_old_gen(klass, new_obj_size, age);\n+    if (new_obj_addr == nullptr) {\n@@ -276,1 +275,1 @@\n-  assert(new_obj != nullptr, \"allocation should have succeeded\");\n+  assert(new_obj_addr != nullptr, \"allocation should have succeeded\");\n@@ -279,1 +278,1 @@\n-  Copy::aligned_disjoint_words(cast_from_oop<HeapWord*>(o), cast_from_oop<HeapWord*>(new_obj), new_obj_size);\n+  Copy::aligned_disjoint_words(cast_from_oop<HeapWord*>(o), new_obj_addr, new_obj_size);\n@@ -286,1 +285,1 @@\n-  oop forwardee = o->forward_to_atomic(new_obj, test_mark, memory_order_relaxed);\n+  oop forwardee = o->forward_to_atomic(cast_to_oop(new_obj_addr), test_mark, memory_order_relaxed);\n@@ -289,0 +288,1 @@\n+    oop new_obj = cast_to_oop(new_obj_addr);\n@@ -325,1 +325,1 @@\n-      _old_lab.unallocate_object(cast_from_oop<HeapWord*>(new_obj), new_obj_size);\n+      _old_lab.unallocate_object(new_obj_addr, new_obj_size);\n@@ -327,1 +327,1 @@\n-      _young_lab.unallocate_object(cast_from_oop<HeapWord*>(new_obj), new_obj_size);\n+      _young_lab.unallocate_object(new_obj_addr, new_obj_size);\n@@ -337,1 +337,0 @@\n-  assert(should_scavenge(p, true), \"revisiting object?\");\n","filename":"src\/hotspot\/share\/gc\/parallel\/psPromotionManager.inline.hpp","additions":14,"deletions":15,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -30,1 +30,0 @@\n-#include \"gc\/shared\/softRefPolicy.hpp\"\n@@ -107,2 +106,0 @@\n-  SoftRefPolicy _soft_ref_policy;\n-\n@@ -399,3 +396,0 @@\n-  \/\/ Return the SoftRefPolicy for the heap;\n-  SoftRefPolicy* soft_ref_policy() { return &_soft_ref_policy; }\n-\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -121,1 +121,1 @@\n-    if (ShenandoahGenerationalAdaptiveTenuring && !ShenandoahGenerationalCensusAtEvac) {\n+    if (ShenandoahGenerationalAdaptiveTenuring) {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMark.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -372,1 +372,1 @@\n-  size_t new_index = Atomic::add(&_index, (size_t) 1, memory_order_relaxed);\n+  size_t new_index = AtomicAccess::add(&_index, (size_t) 1, memory_order_relaxed);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahScanRemembered.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -342,1 +342,1 @@\n-  Atomic::store(dst, ZAddress::store_good(obj));\n+  AtomicAccess::store(dst, ZAddress::store_good(obj));\n@@ -359,1 +359,1 @@\n-  Atomic::store(dst, ZAddress::store_good(obj));\n+  AtomicAccess::store(dst, ZAddress::store_good(obj));\n@@ -436,1 +436,1 @@\n-    Atomic::store(p, ZAddress::store_good(addr));\n+    AtomicAccess::store(p, ZAddress::store_good(addr));\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrierSet.inline.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -147,1 +147,1 @@\n-    const oop o = Atomic::load(p);\n+    const oop o = AtomicAccess::load(p);\n","filename":"src\/hotspot\/share\/gc\/z\/zHeapIterator.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -60,1 +60,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -598,1 +598,1 @@\n-  Atomic::inc(&_work_nterminateflush);\n+  AtomicAccess::inc(&_work_nterminateflush);\n@@ -614,1 +614,1 @@\n-  if (Atomic::load(&_work_nproactiveflush) == ZMarkProactiveFlushMax) {\n+  if (AtomicAccess::load(&_work_nproactiveflush) == ZMarkProactiveFlushMax) {\n@@ -619,1 +619,1 @@\n-  Atomic::inc(&_work_nproactiveflush);\n+  AtomicAccess::inc(&_work_nproactiveflush);\n","filename":"src\/hotspot\/share\/gc\/z\/zMark.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -62,1 +62,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -428,1 +428,1 @@\n-  Atomic::inc(&Exceptions::_stack_overflow_errors);\n+  AtomicAccess::inc(&Exceptions::_stack_overflow_errors);\n@@ -442,1 +442,1 @@\n-  Atomic::inc(&Exceptions::_stack_overflow_errors);\n+  AtomicAccess::inc(&Exceptions::_stack_overflow_errors);\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -33,1 +33,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -451,1 +451,1 @@\n-  return Atomic::load_acquire(&(_array[i % size]));\n+  return AtomicAccess::load_acquire(&(_array[i % size]));\n@@ -455,1 +455,1 @@\n-  return Atomic::cmpxchg(&_array[i % size], old, entry) == old;\n+  return AtomicAccess::cmpxchg(&_array[i % size], old, entry) == old;\n@@ -565,1 +565,1 @@\n-    OopMapCacheEntry* head = Atomic::load(&_old_entries);\n+    OopMapCacheEntry* head = AtomicAccess::load(&_old_entries);\n@@ -567,1 +567,1 @@\n-    if (Atomic::cmpxchg(&_old_entries, head, entry) == head) {\n+    if (AtomicAccess::cmpxchg(&_old_entries, head, entry) == head) {\n@@ -581,1 +581,1 @@\n-  return Atomic::load(&_old_entries) != nullptr;\n+  return AtomicAccess::load(&_old_entries) != nullptr;\n@@ -595,1 +595,1 @@\n-  OopMapCacheEntry* entry = Atomic::xchg(&_old_entries, (OopMapCacheEntry*)nullptr);\n+  OopMapCacheEntry* entry = AtomicAccess::xchg(&_old_entries, (OopMapCacheEntry*)nullptr);\n","filename":"src\/hotspot\/share\/interpreter\/oopMapCache.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -221,3 +221,3 @@\n-  Atomic::inc(&_count);\n-  Atomic::add(&_codeBlobs_size, cb->size());\n-  Atomic::add(&_codeBlobs_code_size, cb->code_size());\n+  AtomicAccess::inc(&_count);\n+  AtomicAccess::add(&_codeBlobs_size, cb->size());\n+  AtomicAccess::add(&_codeBlobs_code_size, cb->code_size());\n@@ -227,2 +227,2 @@\n-  Atomic::inc(&_methods_compiled);\n-  Atomic::inc(&_global_compilation_ticks);\n+  AtomicAccess::inc(&_methods_compiled);\n+  AtomicAccess::inc(&_global_compilation_ticks);\n@@ -234,1 +234,1 @@\n-    Atomic::inc(&_err_upcalls);\n+    AtomicAccess::inc(&_err_upcalls);\n@@ -263,1 +263,1 @@\n-    Atomic::inc(&_ok_upcalls);\n+    AtomicAccess::inc(&_ok_upcalls);\n@@ -268,1 +268,1 @@\n-  Atomic::inc(&_global_compilation_ticks);\n+  AtomicAccess::inc(&_global_compilation_ticks);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompiler.cpp","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -59,1 +59,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -40,1 +40,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -670,1 +670,1 @@\n-  if (!Atomic::load(&_success)) {\n+  if (!AtomicAccess::load(&_success)) {\n@@ -678,1 +678,1 @@\n-    Atomic::store(&_success, false);\n+    AtomicAccess::store(&_success, false);\n@@ -689,1 +689,1 @@\n-    Atomic::add(&_missed_count, missed_count);\n+    AtomicAccess::add(&_missed_count, missed_count);\n@@ -691,1 +691,1 @@\n-    Atomic::store(&_success, false);\n+    AtomicAccess::store(&_success, false);\n","filename":"src\/hotspot\/share\/memory\/heapInspection.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -262,1 +262,0 @@\n-  bool fix_relocations() const { return _fix_relocations; }\n","filename":"src\/hotspot\/share\/memory\/iterator.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -74,1 +74,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -745,1 +745,1 @@\n-    next = (int)Atomic::add(&_preallocated_out_of_memory_error_avail_count, -1);\n+    next = (int)AtomicAccess::add(&_preallocated_out_of_memory_error_avail_count, -1);\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -35,1 +35,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -144,1 +144,1 @@\n-  return Atomic::load_acquire(reinterpret_cast<const volatile T*>(addr));\n+  return AtomicAccess::load_acquire(reinterpret_cast<const volatile T*>(addr));\n@@ -152,1 +152,1 @@\n-  return Atomic::load_acquire(reinterpret_cast<const volatile T*>(addr));\n+  return AtomicAccess::load_acquire(reinterpret_cast<const volatile T*>(addr));\n@@ -160,1 +160,1 @@\n-  return Atomic::load(reinterpret_cast<const volatile T*>(addr));\n+  return AtomicAccess::load(reinterpret_cast<const volatile T*>(addr));\n@@ -168,1 +168,1 @@\n-  Atomic::release_store_fence(reinterpret_cast<volatile T*>(addr), value);\n+  AtomicAccess::release_store_fence(reinterpret_cast<volatile T*>(addr), value);\n@@ -176,1 +176,1 @@\n-  Atomic::release_store(reinterpret_cast<volatile T*>(addr), value);\n+  AtomicAccess::release_store(reinterpret_cast<volatile T*>(addr), value);\n@@ -184,1 +184,1 @@\n-  Atomic::store(reinterpret_cast<volatile T*>(addr), value);\n+  AtomicAccess::store(reinterpret_cast<volatile T*>(addr), value);\n@@ -192,4 +192,4 @@\n-  return Atomic::cmpxchg(reinterpret_cast<volatile T*>(addr),\n-                         compare_value,\n-                         new_value,\n-                         memory_order_relaxed);\n+  return AtomicAccess::cmpxchg(reinterpret_cast<volatile T*>(addr),\n+                               compare_value,\n+                               new_value,\n+                               memory_order_relaxed);\n@@ -203,4 +203,4 @@\n-  return Atomic::cmpxchg(reinterpret_cast<volatile T*>(addr),\n-                         compare_value,\n-                         new_value,\n-                         memory_order_conservative);\n+  return AtomicAccess::cmpxchg(reinterpret_cast<volatile T*>(addr),\n+                               compare_value,\n+                               new_value,\n+                               memory_order_conservative);\n@@ -214,2 +214,2 @@\n-  return Atomic::xchg(reinterpret_cast<volatile T*>(addr),\n-                      new_value);\n+  return AtomicAccess::xchg(reinterpret_cast<volatile T*>(addr),\n+                            new_value);\n","filename":"src\/hotspot\/share\/oops\/accessBackend.inline.hpp","additions":18,"deletions":18,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -65,1 +65,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -282,1 +282,1 @@\n-  Atomic::release_store(adr, k);\n+  AtomicAccess::release_store(adr, k);\n@@ -726,1 +726,1 @@\n-  Atomic::release_store(adr, k);\n+  AtomicAccess::release_store(adr, k);\n@@ -728,3 +728,3 @@\n-  jbyte old_tag = Atomic::cmpxchg((jbyte*)this_cp->tag_addr_at(cp_index),\n-                                  (jbyte)JVM_CONSTANT_UnresolvedClass,\n-                                  (jbyte)JVM_CONSTANT_Class);\n+  jbyte old_tag = AtomicAccess::cmpxchg((jbyte*)this_cp->tag_addr_at(cp_index),\n+                                        (jbyte)JVM_CONSTANT_UnresolvedClass,\n+                                        (jbyte)JVM_CONSTANT_Class);\n@@ -735,1 +735,1 @@\n-    Atomic::store(adr, (Klass*)nullptr);\n+    AtomicAccess::store(adr, (Klass*)nullptr);\n@@ -1067,3 +1067,3 @@\n-    jbyte old_tag = Atomic::cmpxchg((jbyte*)this_cp->tag_addr_at(cp_index),\n-                                    (jbyte)tag.value(),\n-                                    (jbyte)error_tag);\n+    jbyte old_tag = AtomicAccess::cmpxchg((jbyte*)this_cp->tag_addr_at(cp_index),\n+                                          (jbyte)tag.value(),\n+                                          (jbyte)error_tag);\n","filename":"src\/hotspot\/share\/oops\/constantPool.cpp","additions":10,"deletions":10,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -56,1 +56,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n","filename":"src\/hotspot\/share\/oops\/cpCache.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -34,1 +34,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n","filename":"src\/hotspot\/share\/oops\/cpCache.inline.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -28,1 +28,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n","filename":"src\/hotspot\/share\/oops\/fieldInfo.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -34,1 +34,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -195,1 +195,1 @@\n-  Atomic::fetch_then_or(&flags, mask);\n+  AtomicAccess::fetch_then_or(&flags, mask);\n@@ -199,1 +199,1 @@\n-  Atomic::fetch_then_and(&flags, (u1)(~mask));\n+  AtomicAccess::fetch_then_and(&flags, (u1)(~mask));\n","filename":"src\/hotspot\/share\/oops\/fieldInfo.inline.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -84,1 +84,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -1651,1 +1651,1 @@\n-    InstanceKlass* ikls = Atomic::load_acquire(ik);\n+    InstanceKlass* ikls = AtomicAccess::load_acquire(ik);\n@@ -1667,1 +1667,1 @@\n-    Atomic::release_store(addr, ik);\n+    AtomicAccess::release_store(addr, ik);\n@@ -1988,1 +1988,1 @@\n-  OopMapCache* oop_map_cache = Atomic::load_acquire(&_oop_map_cache);\n+  OopMapCache* oop_map_cache = AtomicAccess::load_acquire(&_oop_map_cache);\n@@ -1992,1 +1992,1 @@\n-    OopMapCache* other = Atomic::cmpxchg(&_oop_map_cache, (OopMapCache*)nullptr, oop_map_cache);\n+    OopMapCache* other = AtomicAccess::cmpxchg(&_oop_map_cache, (OopMapCache*)nullptr, oop_map_cache);\n@@ -2627,1 +2627,1 @@\n-  Atomic::release_store(&jmeths[idnum + 1], new_id);\n+  AtomicAccess::release_store(&jmeths[idnum + 1], new_id);\n@@ -2642,1 +2642,1 @@\n-  return Atomic::load_acquire(&_methods_jmethod_ids);\n+  return AtomicAccess::load_acquire(&_methods_jmethod_ids);\n@@ -2646,1 +2646,1 @@\n-  Atomic::release_store(&_methods_jmethod_ids, jmeths);\n+  AtomicAccess::release_store(&_methods_jmethod_ids, jmeths);\n@@ -2685,1 +2685,1 @@\n-  jmethodID id = Atomic::load_acquire(&jmeths[idnum + 1]);\n+  jmethodID id = AtomicAccess::load_acquire(&jmeths[idnum + 1]);\n@@ -2734,1 +2734,1 @@\n-    jmethodID id = Atomic::load_acquire(&jmeths[idnum + 1]);\n+    jmethodID id = AtomicAccess::load_acquire(&jmeths[idnum + 1]);\n@@ -2738,1 +2738,1 @@\n-      Atomic::release_store(&jmeths[idnum + 1], id);\n+      AtomicAccess::release_store(&jmeths[idnum + 1], id);\n@@ -2791,1 +2791,1 @@\n-      InstanceKlass* impl = Atomic::load_acquire(iklass);\n+      InstanceKlass* impl = AtomicAccess::load_acquire(iklass);\n@@ -2794,1 +2794,1 @@\n-        if (Atomic::cmpxchg(iklass, impl, (InstanceKlass*)nullptr) == impl) {\n+        if (AtomicAccess::cmpxchg(iklass, impl, (InstanceKlass*)nullptr) == impl) {\n@@ -4560,1 +4560,1 @@\n-  Atomic::release_store(&_init_state, state);\n+  AtomicAccess::release_store(&_init_state, state);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":14,"deletions":14,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -602,1 +602,1 @@\n-  JavaThread* init_thread()  { return Atomic::load(&_init_thread); }\n+  JavaThread* init_thread()  { return AtomicAccess::load(&_init_thread); }\n@@ -616,1 +616,1 @@\n-  ClassState  init_state() const           { return Atomic::load_acquire(&_init_state); }\n+  ClassState  init_state() const           { return AtomicAccess::load_acquire(&_init_state); }\n@@ -1195,1 +1195,1 @@\n-    Atomic::store(&_init_thread, thread);\n+    AtomicAccess::store(&_init_thread, thread);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -34,1 +34,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -82,1 +82,1 @@\n-  return Atomic::load_acquire(&_array_klasses);\n+  return AtomicAccess::load_acquire(&_array_klasses);\n@@ -86,1 +86,1 @@\n-  Atomic::release_store(&_array_klasses, k);\n+  AtomicAccess::release_store(&_array_klasses, k);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.inline.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -28,1 +28,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -143,2 +143,2 @@\n-  void atomic_set_bits(u1 bits)   { Atomic::fetch_then_or(&_status, bits); }\n-  void atomic_clear_bits(u1 bits) { Atomic::fetch_then_and(&_status, (u1)(~bits)); }\n+  void atomic_set_bits(u1 bits)   { AtomicAccess::fetch_then_or(&_status, bits); }\n+  void atomic_clear_bits(u1 bits) { AtomicAccess::fetch_then_and(&_status, (u1)(~bits)); }\n","filename":"src\/hotspot\/share\/oops\/instanceKlassFlags.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -53,1 +53,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -603,1 +603,1 @@\n-  for (Klass* chain = Atomic::load_acquire(&_subklass);\n+  for (Klass* chain = AtomicAccess::load_acquire(&_subklass);\n@@ -607,1 +607,1 @@\n-       chain = Atomic::load(&chain->_next_sibling))\n+       chain = AtomicAccess::load(&chain->_next_sibling))\n@@ -624,1 +624,1 @@\n-  for (Klass* chain = Atomic::load(&_next_sibling);\n+  for (Klass* chain = AtomicAccess::load(&_next_sibling);\n@@ -626,1 +626,1 @@\n-       chain = Atomic::load(&chain->_next_sibling)) {\n+       chain = AtomicAccess::load(&chain->_next_sibling)) {\n@@ -643,1 +643,1 @@\n-  Atomic::release_store(&_subklass, s);\n+  AtomicAccess::release_store(&_subklass, s);\n@@ -651,1 +651,1 @@\n-  Atomic::store(&_next_sibling, s);\n+  AtomicAccess::store(&_next_sibling, s);\n@@ -670,1 +670,1 @@\n-    Klass* prev_first_subklass = Atomic::load_acquire(&_super->_subklass);\n+    Klass* prev_first_subklass = AtomicAccess::load_acquire(&_super->_subklass);\n@@ -679,1 +679,1 @@\n-    if (Atomic::cmpxchg(&super->_subklass, prev_first_subklass, this) == prev_first_subklass) {\n+    if (AtomicAccess::cmpxchg(&super->_subklass, prev_first_subklass, this) == prev_first_subklass) {\n@@ -689,1 +689,1 @@\n-    Klass* subklass = Atomic::load_acquire(&_subklass);\n+    Klass* subklass = AtomicAccess::load_acquire(&_subklass);\n@@ -694,1 +694,1 @@\n-    Atomic::cmpxchg(&_subklass, subklass, subklass->next_sibling());\n+    AtomicAccess::cmpxchg(&_subklass, subklass, subklass->next_sibling());\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":11,"deletions":11,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -69,1 +69,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -648,1 +648,1 @@\n-    Atomic::replace_if_null(&method->_method_data, mtd->final_profile());\n+    AtomicAccess::replace_if_null(&method->_method_data, mtd->final_profile());\n@@ -675,1 +675,1 @@\n-  if (!Atomic::replace_if_null(&method->_method_data, method_data)) {\n+  if (!AtomicAccess::replace_if_null(&method->_method_data, method_data)) {\n@@ -726,1 +726,1 @@\n-  return Atomic::replace_if_null(&_method_counters, counters);\n+  return AtomicAccess::replace_if_null(&_method_counters, counters);\n@@ -1416,1 +1416,1 @@\n-  nmethod *code = Atomic::load_acquire(&_code);\n+  nmethod *code = AtomicAccess::load_acquire(&_code);\n@@ -1458,1 +1458,1 @@\n-    Atomic::release_store(&mh->_from_interpreted_entry , mh->get_i2c_entry());\n+    AtomicAccess::release_store(&mh->_from_interpreted_entry , mh->get_i2c_entry());\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":6,"deletions":6,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -34,1 +34,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -37,1 +37,1 @@\n-  return Atomic::load_acquire(&_from_compiled_entry);\n+  return AtomicAccess::load_acquire(&_from_compiled_entry);\n@@ -41,1 +41,1 @@\n-  return Atomic::load_acquire(&_from_compiled_inline_ro_entry);\n+  return AtomicAccess::load_acquire(&_from_compiled_inline_ro_entry);\n@@ -45,1 +45,1 @@\n-  return Atomic::load_acquire(&_from_compiled_inline_entry);\n+  return AtomicAccess::load_acquire(&_from_compiled_inline_entry);\n@@ -49,1 +49,1 @@\n-  return Atomic::load_acquire(&_from_interpreted_entry);\n+  return AtomicAccess::load_acquire(&_from_interpreted_entry);\n@@ -54,1 +54,1 @@\n-  return Atomic::load_acquire(&_code);\n+  return AtomicAccess::load_acquire(&_code);\n","filename":"src\/hotspot\/share\/oops\/method.inline.hpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -41,1 +41,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -960,1 +960,1 @@\n-      FailedSpeculation* old_fs = Atomic::cmpxchg(cursor, (FailedSpeculation*) nullptr, fs);\n+      FailedSpeculation* old_fs = AtomicAccess::cmpxchg(cursor, (FailedSpeculation*) nullptr, fs);\n@@ -1581,1 +1581,1 @@\n-    \/\/ No need for \"Atomic::load_acquire\" ops,\n+    \/\/ No need for \"AtomicAccess::load_acquire\" ops,\n@@ -1708,1 +1708,1 @@\n-    \/\/ No need for \"Atomic::load_acquire\" ops,\n+    \/\/ No need for \"AtomicAccess::load_acquire\" ops,\n@@ -1929,1 +1929,1 @@\n-  Mutex* lock = Atomic::load_acquire(&_extra_data_lock);\n+  Mutex* lock = AtomicAccess::load_acquire(&_extra_data_lock);\n@@ -1933,1 +1933,1 @@\n-    Mutex* old = Atomic::cmpxchg(&_extra_data_lock, (Mutex*)nullptr, lock);\n+    Mutex* old = AtomicAccess::cmpxchg(&_extra_data_lock, (Mutex*)nullptr, lock);\n","filename":"src\/hotspot\/share\/oops\/methodData.cpp","additions":6,"deletions":6,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -32,1 +32,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -187,1 +187,1 @@\n-    return Atomic::load_acquire(&_header._struct._flags);\n+    return AtomicAccess::load_acquire(&_header._struct._flags);\n@@ -220,1 +220,1 @@\n-    } while (compare_value != Atomic::cmpxchg(&_header._struct._flags, compare_value, static_cast<u1>(compare_value | bit)));\n+    } while (compare_value != AtomicAccess::cmpxchg(&_header._struct._flags, compare_value, static_cast<u1>(compare_value | bit)));\n@@ -235,1 +235,1 @@\n-    } while (compare_value != Atomic::cmpxchg(&_header._struct._flags, compare_value, exchange_value));\n+    } while (compare_value != AtomicAccess::cmpxchg(&_header._struct._flags, compare_value, exchange_value));\n","filename":"src\/hotspot\/share\/oops\/methodData.hpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2023, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -94,2 +94,2 @@\n-  void atomic_set_bits(u4 bits)   { Atomic::fetch_then_or(&_status, bits); }\n-  void atomic_clear_bits(u4 bits) { Atomic::fetch_then_and(&_status, ~bits); }\n+  void atomic_set_bits(u4 bits)   { AtomicAccess::fetch_then_or(&_status, bits); }\n+  void atomic_clear_bits(u4 bits) { AtomicAccess::fetch_then_and(&_status, ~bits); }\n","filename":"src\/hotspot\/share\/oops\/methodFlags.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -36,1 +36,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -42,1 +42,1 @@\n-  return Atomic::load_acquire(&_next_refined_array_klass);\n+  return AtomicAccess::load_acquire(&_next_refined_array_klass);\n@@ -46,1 +46,1 @@\n-  Atomic::release_store(&_next_refined_array_klass, k);\n+  AtomicAccess::release_store(&_next_refined_array_klass, k);\n","filename":"src\/hotspot\/share\/oops\/objArrayKlass.inline.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -170,1 +170,1 @@\n-address oopDesc::address_field_acquire(int offset) const              { return Atomic::load_acquire(field_addr<address>(offset)); }\n+address oopDesc::address_field_acquire(int offset) const              { return AtomicAccess::load_acquire(field_addr<address>(offset)); }\n@@ -173,1 +173,1 @@\n-void oopDesc::release_address_field_put(int offset, address value)    { Atomic::release_store(field_addr<address>(offset), value); }\n+void oopDesc::release_address_field_put(int offset, address value)    { AtomicAccess::release_store(field_addr<address>(offset), value); }\n@@ -178,2 +178,2 @@\n-Metadata* oopDesc::metadata_field_acquire(int offset) const           { return Atomic::load_acquire(field_addr<Metadata*>(offset)); }\n-void oopDesc::release_metadata_field_put(int offset, Metadata* value) { Atomic::release_store(field_addr<Metadata*>(offset), value); }\n+Metadata* oopDesc::metadata_field_acquire(int offset) const           { return AtomicAccess::load_acquire(field_addr<Metadata*>(offset)); }\n+void oopDesc::release_metadata_field_put(int offset, Metadata* value) { AtomicAccess::release_store(field_addr<Metadata*>(offset), value); }\n@@ -181,2 +181,2 @@\n-jbyte oopDesc::byte_field_acquire(int offset) const                   { return Atomic::load_acquire(field_addr<jbyte>(offset)); }\n-void oopDesc::release_byte_field_put(int offset, jbyte value)         { Atomic::release_store(field_addr<jbyte>(offset), value); }\n+jbyte oopDesc::byte_field_acquire(int offset) const                   { return AtomicAccess::load_acquire(field_addr<jbyte>(offset)); }\n+void oopDesc::release_byte_field_put(int offset, jbyte value)         { AtomicAccess::release_store(field_addr<jbyte>(offset), value); }\n@@ -184,2 +184,2 @@\n-jchar oopDesc::char_field_acquire(int offset) const                   { return Atomic::load_acquire(field_addr<jchar>(offset)); }\n-void oopDesc::release_char_field_put(int offset, jchar value)         { Atomic::release_store(field_addr<jchar>(offset), value); }\n+jchar oopDesc::char_field_acquire(int offset) const                   { return AtomicAccess::load_acquire(field_addr<jchar>(offset)); }\n+void oopDesc::release_char_field_put(int offset, jchar value)         { AtomicAccess::release_store(field_addr<jchar>(offset), value); }\n@@ -187,2 +187,2 @@\n-jboolean oopDesc::bool_field_acquire(int offset) const                { return Atomic::load_acquire(field_addr<jboolean>(offset)); }\n-void oopDesc::release_bool_field_put(int offset, jboolean value)      { Atomic::release_store(field_addr<jboolean>(offset), jboolean(value & 1)); }\n+jboolean oopDesc::bool_field_acquire(int offset) const                { return AtomicAccess::load_acquire(field_addr<jboolean>(offset)); }\n+void oopDesc::release_bool_field_put(int offset, jboolean value)      { AtomicAccess::release_store(field_addr<jboolean>(offset), jboolean(value & 1)); }\n@@ -190,2 +190,2 @@\n-jint oopDesc::int_field_acquire(int offset) const                     { return Atomic::load_acquire(field_addr<jint>(offset)); }\n-void oopDesc::release_int_field_put(int offset, jint value)           { Atomic::release_store(field_addr<jint>(offset), value); }\n+jint oopDesc::int_field_acquire(int offset) const                     { return AtomicAccess::load_acquire(field_addr<jint>(offset)); }\n+void oopDesc::release_int_field_put(int offset, jint value)           { AtomicAccess::release_store(field_addr<jint>(offset), value); }\n@@ -193,2 +193,2 @@\n-jshort oopDesc::short_field_acquire(int offset) const                 { return Atomic::load_acquire(field_addr<jshort>(offset)); }\n-void oopDesc::release_short_field_put(int offset, jshort value)       { Atomic::release_store(field_addr<jshort>(offset), value); }\n+jshort oopDesc::short_field_acquire(int offset) const                 { return AtomicAccess::load_acquire(field_addr<jshort>(offset)); }\n+void oopDesc::release_short_field_put(int offset, jshort value)       { AtomicAccess::release_store(field_addr<jshort>(offset), value); }\n@@ -196,2 +196,2 @@\n-jlong oopDesc::long_field_acquire(int offset) const                   { return Atomic::load_acquire(field_addr<jlong>(offset)); }\n-void oopDesc::release_long_field_put(int offset, jlong value)         { Atomic::release_store(field_addr<jlong>(offset), value); }\n+jlong oopDesc::long_field_acquire(int offset) const                   { return AtomicAccess::load_acquire(field_addr<jlong>(offset)); }\n+void oopDesc::release_long_field_put(int offset, jlong value)         { AtomicAccess::release_store(field_addr<jlong>(offset), value); }\n@@ -199,2 +199,2 @@\n-jfloat oopDesc::float_field_acquire(int offset) const                 { return Atomic::load_acquire(field_addr<jfloat>(offset)); }\n-void oopDesc::release_float_field_put(int offset, jfloat value)       { Atomic::release_store(field_addr<jfloat>(offset), value); }\n+jfloat oopDesc::float_field_acquire(int offset) const                 { return AtomicAccess::load_acquire(field_addr<jfloat>(offset)); }\n+void oopDesc::release_float_field_put(int offset, jfloat value)       { AtomicAccess::release_store(field_addr<jfloat>(offset), value); }\n@@ -202,2 +202,2 @@\n-jdouble oopDesc::double_field_acquire(int offset) const               { return Atomic::load_acquire(field_addr<jdouble>(offset)); }\n-void oopDesc::release_double_field_put(int offset, jdouble value)     { Atomic::release_store(field_addr<jdouble>(offset), value); }\n+jdouble oopDesc::double_field_acquire(int offset) const               { return AtomicAccess::load_acquire(field_addr<jdouble>(offset)); }\n+void oopDesc::release_double_field_put(int offset, jdouble value)     { AtomicAccess::release_store(field_addr<jdouble>(offset), value); }\n","filename":"src\/hotspot\/share\/oops\/oop.cpp","additions":20,"deletions":20,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -35,1 +35,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n","filename":"src\/hotspot\/share\/oops\/oop.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -40,1 +40,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -54,1 +54,1 @@\n-  return Atomic::load(&_mark);\n+  return AtomicAccess::load(&_mark);\n@@ -58,1 +58,1 @@\n-  return Atomic::load_acquire(&_mark);\n+  return AtomicAccess::load_acquire(&_mark);\n@@ -62,1 +62,1 @@\n-  Atomic::store(&_mark, m);\n+  AtomicAccess::store(&_mark, m);\n@@ -70,1 +70,1 @@\n-  Atomic::release_store((markWord*)(((char*)mem) + mark_offset_in_bytes()), m);\n+  AtomicAccess::release_store((markWord*)(((char*)mem) + mark_offset_in_bytes()), m);\n@@ -74,1 +74,1 @@\n-  Atomic::release_store(&_mark, m);\n+  AtomicAccess::release_store(&_mark, m);\n@@ -78,1 +78,1 @@\n-  return Atomic::cmpxchg(&_mark, old_mark, new_mark);\n+  return AtomicAccess::cmpxchg(&_mark, old_mark, new_mark);\n@@ -82,1 +82,1 @@\n-  return Atomic::cmpxchg(&_mark, old_mark, new_mark, order);\n+  return AtomicAccess::cmpxchg(&_mark, old_mark, new_mark, order);\n@@ -135,1 +135,1 @@\n-      narrowKlass narrow_klass = Atomic::load_acquire(&_metadata._compressed_klass);\n+      narrowKlass narrow_klass = AtomicAccess::load_acquire(&_metadata._compressed_klass);\n@@ -139,1 +139,1 @@\n-      return Atomic::load_acquire(&_metadata._klass);\n+      return AtomicAccess::load_acquire(&_metadata._klass);\n@@ -180,1 +180,1 @@\n-    Atomic::release_store((narrowKlass*)raw_mem,\n+    AtomicAccess::release_store((narrowKlass*)raw_mem,\n@@ -183,1 +183,1 @@\n-    Atomic::release_store((Klass**)raw_mem, k);\n+    AtomicAccess::release_store((Klass**)raw_mem, k);\n@@ -302,2 +302,2 @@\n-inline jint oopDesc::int_field_relaxed(int offset) const            { return Atomic::load(field_addr<jint>(offset)); }\n-inline void oopDesc::int_field_put_relaxed(int offset, jint value)  { Atomic::store(field_addr<jint>(offset), value); }\n+inline jint oopDesc::int_field_relaxed(int offset) const            { return AtomicAccess::load(field_addr<jint>(offset)); }\n+inline void oopDesc::int_field_put_relaxed(int offset, jint value)  { AtomicAccess::store(field_addr<jint>(offset), value); }\n","filename":"src\/hotspot\/share\/oops\/oop.inline.hpp","additions":14,"deletions":14,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -30,1 +30,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -137,2 +137,2 @@\n-  u1 get_code()                 const { return Atomic::load_acquire(&_get_code);      }\n-  u1 put_code()                 const { return Atomic::load_acquire(&_put_code);      }\n+  u1 get_code()                 const { return AtomicAccess::load_acquire(&_get_code);      }\n+  u1 put_code()                 const { return AtomicAccess::load_acquire(&_put_code);      }\n@@ -181,1 +181,1 @@\n-    Atomic::release_store(code, new_code);\n+    AtomicAccess::release_store(code, new_code);\n","filename":"src\/hotspot\/share\/oops\/resolvedFieldEntry.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -36,1 +36,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -338,1 +338,1 @@\n-      found = Atomic::cmpxchg(&_hash_and_refcount, old_value, old_value + 1);\n+      found = AtomicAccess::cmpxchg(&_hash_and_refcount, old_value, old_value + 1);\n@@ -357,1 +357,1 @@\n-    NOT_PRODUCT(Atomic::inc(&_total_count);)\n+    NOT_PRODUCT(AtomicAccess::inc(&_total_count);)\n@@ -377,1 +377,1 @@\n-      found = Atomic::cmpxchg(&_hash_and_refcount, old_value, old_value - 1);\n+      found = AtomicAccess::cmpxchg(&_hash_and_refcount, old_value, old_value - 1);\n@@ -399,1 +399,1 @@\n-      found = Atomic::cmpxchg(&_hash_and_refcount, old_value, pack_hash_and_refcount(hash, PERM_REFCOUNT));\n+      found = AtomicAccess::cmpxchg(&_hash_and_refcount, old_value, pack_hash_and_refcount(hash, PERM_REFCOUNT));\n","filename":"src\/hotspot\/share\/oops\/symbol.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -1580,2 +1580,2 @@\n-    \/\/ capture allstackedness flag before mask is hacked\n-    const int is_allstack = lrg->mask().is_AllStack();\n+    \/\/ capture infinitestackedness flag before mask is hacked\n+    const int is_infinite_stack = lrg->mask().is_infinite_stack();\n@@ -1632,1 +1632,1 @@\n-    \/\/assert(is_allstack == lrg->mask().is_AllStack(), \"nbrs must not change AllStackedness\");\n+    \/\/assert(is_infinite_stack == lrg->mask().is_infinite_stack(), \"nbrs must not change InfiniteStackedness\");\n@@ -1643,1 +1643,1 @@\n-    \/\/ If we fail to color and the AllStack flag is set, trigger\n+    \/\/ If we fail to color and the infinite flag is set, trigger\n@@ -1645,1 +1645,1 @@\n-    if(!OptoReg::is_valid(OptoReg::add(reg,-chunk)) && is_allstack) {\n+    if (!OptoReg::is_valid(OptoReg::add(reg, -chunk)) && is_infinite_stack) {\n@@ -1654,1 +1654,1 @@\n-    else if( OptoReg::is_valid(reg)) {\n+    else if (OptoReg::is_valid(reg)) {\n@@ -1711,1 +1711,1 @@\n-      assert( !orig_mask.is_AllStack(), \"All Stack does not spill\" );\n+      assert( !orig_mask.is_infinite_stack(), \"infinite stack does not spill\" );\n","filename":"src\/hotspot\/share\/opto\/chaitin.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -1201,1 +1201,2 @@\n-const Type* ModINode::Value(PhaseGVN* phase) const {\n+static const Type* mod_value(const PhaseGVN* phase, const Node* in1, const Node* in2, const BasicType bt) {\n+  assert(bt == T_INT || bt == T_LONG, \"unexpected basic type\");\n@@ -1203,4 +1204,4 @@\n-  const Type *t1 = phase->type( in(1) );\n-  const Type *t2 = phase->type( in(2) );\n-  if( t1 == Type::TOP ) return Type::TOP;\n-  if( t2 == Type::TOP ) return Type::TOP;\n+  const Type* t1 = phase->type(in1);\n+  const Type* t2 = phase->type(in2);\n+  if (t1 == Type::TOP) { return Type::TOP; }\n+  if (t2 == Type::TOP) { return Type::TOP; }\n@@ -1210,1 +1211,2 @@\n-  if( t1 == TypeInt::ZERO ) return TypeInt::ZERO;\n+  if (t1 == TypeInteger::zero(bt)) { return t1; }\n+\n@@ -1212,2 +1214,2 @@\n-  if (in(1) == in(2)) {\n-    return TypeInt::ZERO;\n+  if (in1 == in2) {\n+    return TypeInteger::zero(bt);\n@@ -1216,15 +1218,3 @@\n-  \/\/ Either input is BOTTOM ==> the result is the local BOTTOM\n-  const Type *bot = bottom_type();\n-  if( (t1 == bot) || (t2 == bot) ||\n-      (t1 == Type::BOTTOM) || (t2 == Type::BOTTOM) )\n-    return bot;\n-\n-  const TypeInt *i1 = t1->is_int();\n-  const TypeInt *i2 = t2->is_int();\n-  if( !i1->is_con() || !i2->is_con() ) {\n-    if( i1->_lo >= 0 && i2->_lo >= 0 )\n-      return TypeInt::POS;\n-    \/\/ If both numbers are not constants, we know little.\n-    return TypeInt::INT;\n-  }\n-  if( !i2->get_con() ) return TypeInt::POS;\n+  if (t2 == TypeInteger::zero(bt)) {\n+    return Type::TOP;\n+  }\n@@ -1233,4 +1223,45 @@\n-  \/\/ We must be modulo'ing 2 float constants.\n-  \/\/ Check for min_jint % '-1', result is defined to be '0'.\n-  if( i1->get_con() == min_jint && i2->get_con() == -1 )\n-    return TypeInt::ZERO;\n+  const TypeInteger* i1 = t1->is_integer(bt);\n+  const TypeInteger* i2 = t2->is_integer(bt);\n+  if (i1->is_con() && i2->is_con()) {\n+    \/\/ We must be modulo'ing 2 int constants.\n+    \/\/ Special case: min_jlong % '-1' is UB, and e.g., x86 triggers a division error.\n+    \/\/ Any value % -1 is 0, so we can return 0 and avoid that scenario.\n+    if (i2->get_con_as_long(bt) == -1) {\n+      return TypeInteger::zero(bt);\n+    }\n+    return TypeInteger::make(i1->get_con_as_long(bt) % i2->get_con_as_long(bt), bt);\n+  }\n+  \/\/ We checked that t2 is not the zero constant. Hence, at least i2->_lo or i2->_hi must be non-zero,\n+  \/\/ and hence its absoute value is bigger than zero. Hence, the magnitude of the divisor (i.e. the\n+  \/\/ largest absolute value for any value in i2) must be in the range [1, 2^31] or [1, 2^63], depending\n+  \/\/ on the BasicType.\n+  julong divisor_magnitude = MAX2(g_uabs(i2->lo_as_long()), g_uabs(i2->hi_as_long()));\n+  \/\/ JVMS lrem bytecode: \"the magnitude of the result is always less than the magnitude of the divisor\"\n+  \/\/ \"less than\" means we can subtract 1 to get an inclusive upper bound in [0, 2^31-1] or [0, 2^63-1], respectively\n+  jlong hi = static_cast<jlong>(divisor_magnitude - 1);\n+  jlong lo = -hi;\n+  \/\/ JVMS lrem bytecode: \"the result of the remainder operation can be negative only if the dividend\n+  \/\/ is negative and can be positive only if the dividend is positive\"\n+  \/\/ Note that with a dividend with bounds e.g. lo == -4 and hi == -1 can still result in values\n+  \/\/ below lo; i.e., -3 % 3 == 0.\n+  \/\/ That means we cannot restrict the bound that is closer to zero beyond knowing its sign (or zero).\n+  if (i1->hi_as_long() <= 0) {\n+    \/\/ all dividends are not positive, so the result is not positive\n+    hi = 0;\n+    \/\/ if the dividend is known to be closer to zero, use that as a lower limit\n+    lo = MAX2(lo, i1->lo_as_long());\n+  } else if (i1->lo_as_long() >= 0) {\n+    \/\/ all dividends are not negative, so the result is not negative\n+    lo = 0;\n+    \/\/ if the dividend is known to be closer to zero, use that as an upper limit\n+    hi = MIN2(hi, i1->hi_as_long());\n+  } else {\n+    \/\/ Mixed signs, so we don't know the sign of the result, but the result is\n+    \/\/ either the dividend itself or a value closer to zero than the dividend,\n+    \/\/ and it is closer to zero than the divisor.\n+    \/\/ As we know i1->_lo < 0 and i1->_hi > 0, we can use these bounds directly.\n+    lo = MAX2(lo, i1->lo_as_long());\n+    hi = MIN2(hi, i1->hi_as_long());\n+  }\n+  return TypeInteger::make(lo, hi, MAX2(i1->_widen, i2->_widen), bt);\n+}\n@@ -1238,1 +1269,2 @@\n-  return TypeInt::make( i1->get_con() % i2->get_con() );\n+const Type* ModINode::Value(PhaseGVN* phase) const {\n+  return mod_value(phase, in(1), in(2), T_INT);\n@@ -1467,37 +1499,1 @@\n-  \/\/ Either input is TOP ==> the result is TOP\n-  const Type *t1 = phase->type( in(1) );\n-  const Type *t2 = phase->type( in(2) );\n-  if( t1 == Type::TOP ) return Type::TOP;\n-  if( t2 == Type::TOP ) return Type::TOP;\n-\n-  \/\/ We always generate the dynamic check for 0.\n-  \/\/ 0 MOD X is 0\n-  if( t1 == TypeLong::ZERO ) return TypeLong::ZERO;\n-  \/\/ X MOD X is 0\n-  if (in(1) == in(2)) {\n-    return TypeLong::ZERO;\n-  }\n-\n-  \/\/ Either input is BOTTOM ==> the result is the local BOTTOM\n-  const Type *bot = bottom_type();\n-  if( (t1 == bot) || (t2 == bot) ||\n-      (t1 == Type::BOTTOM) || (t2 == Type::BOTTOM) )\n-    return bot;\n-\n-  const TypeLong *i1 = t1->is_long();\n-  const TypeLong *i2 = t2->is_long();\n-  if( !i1->is_con() || !i2->is_con() ) {\n-    if( i1->_lo >= CONST64(0) && i2->_lo >= CONST64(0) )\n-      return TypeLong::POS;\n-    \/\/ If both numbers are not constants, we know little.\n-    return TypeLong::LONG;\n-  }\n-  \/\/ Mod by zero?  Throw exception at runtime!\n-  if( !i2->get_con() ) return TypeLong::POS;\n-\n-  \/\/ We must be modulo'ing 2 float constants.\n-  \/\/ Check for min_jint % '-1', result is defined to be '0'.\n-  if( i1->get_con() == min_jlong && i2->get_con() == -1 )\n-    return TypeLong::ZERO;\n-\n-  return TypeLong::make( i1->get_con() % i2->get_con() );\n+  return mod_value(phase, in(1), in(2), T_LONG);\n","filename":"src\/hotspot\/share\/opto\/divnode.cpp","additions":61,"deletions":65,"binary":false,"changes":126,"status":"modified"},{"patch":"@@ -3197,0 +3197,8 @@\n+        } else if (use->is_LocalVar()) {\n+          Node* phi = use->ideal_node();\n+          if (phi->Opcode() == Op_Phi && reducible_merges.member(phi) && !can_reduce_phi(phi->as_Phi())) {\n+            set_not_scalar_replaceable(jobj NOT_PRODUCT(COMMA \"is merged in a non-reducible phi\"));\n+            reducible_merges.yank(phi);\n+            found_nsr_alloc = true;\n+            break;\n+          }\n@@ -5187,1 +5195,1 @@\n-  tty->print_cr(\"No escape = %d, Arg escape = %d, Global escape = %d\", Atomic::load(&_no_escape_counter), Atomic::load(&_arg_escape_counter), Atomic::load(&_global_escape_counter));\n+  tty->print_cr(\"No escape = %d, Arg escape = %d, Global escape = %d\", AtomicAccess::load(&_no_escape_counter), AtomicAccess::load(&_arg_escape_counter), AtomicAccess::load(&_global_escape_counter));\n@@ -5198,1 +5206,1 @@\n-        Atomic::inc(&ConnectionGraph::_no_escape_counter);\n+        AtomicAccess::inc(&ConnectionGraph::_no_escape_counter);\n@@ -5200,1 +5208,1 @@\n-        Atomic::inc(&ConnectionGraph::_arg_escape_counter);\n+        AtomicAccess::inc(&ConnectionGraph::_arg_escape_counter);\n@@ -5202,1 +5210,1 @@\n-        Atomic::inc(&ConnectionGraph::_global_escape_counter);\n+        AtomicAccess::inc(&ConnectionGraph::_global_escape_counter);\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":12,"deletions":4,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -4034,2 +4034,2 @@\n- *   Atomic::store(&tl->_contextual_tid, java_lang_Thread::tid(thread));\n- *   Atomic::store(&tl->_contextual_thread_excluded, is_excluded);\n+ *   AtomicAccess::store(&tl->_contextual_tid, java_lang_Thread::tid(thread));\n+ *   AtomicAccess::store(&tl->_contextual_thread_excluded, is_excluded);\n@@ -4038,1 +4038,1 @@\n- *     Atomic::store(&tl->_vthread_epoch, vthread_epoch);\n+ *     AtomicAccess::store(&tl->_vthread_epoch, vthread_epoch);\n@@ -4040,1 +4040,1 @@\n- *   Atomic::release_store(&tl->_vthread, true);\n+ *   AtomicAccess::release_store(&tl->_vthread, true);\n@@ -4043,1 +4043,1 @@\n- * Atomic::release_store(&tl->_vthread, false);\n+ * AtomicAccess::release_store(&tl->_vthread, false);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -1870,0 +1870,2 @@\n+  bool would_sink_below_pre_loop_exit(IdealLoopTree* n_loop, Node* ctrl);\n+\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1885,9 +1885,11 @@\n-        if (n->depends_only_on_test()) {\n-          Node* pinned_clone = n->pin_array_access_node();\n-          if (pinned_clone != nullptr) {\n-            \/\/ Pin array access nodes: if this is an array load, it's going to be dependent on a condition that's not a\n-            \/\/ range check for that access. If that condition is replaced by an identical dominating one, then an\n-            \/\/ unpinned load would risk floating above its range check.\n-            register_new_node(pinned_clone, n_ctrl);\n-            maybe_pinned_n = pinned_clone;\n-            _igvn.replace_node(n, pinned_clone);\n+        if (!would_sink_below_pre_loop_exit(loop_ctrl, outside_ctrl)) {\n+          if (n->depends_only_on_test()) {\n+            Node* pinned_clone = n->pin_array_access_node();\n+            if (pinned_clone != nullptr) {\n+              \/\/ Pin array access nodes: if this is an array load, it's going to be dependent on a condition that's not a\n+              \/\/ range check for that access. If that condition is replaced by an identical dominating one, then an\n+              \/\/ unpinned load would risk floating above its range check.\n+              register_new_node(pinned_clone, n_ctrl);\n+              maybe_pinned_n = pinned_clone;\n+              _igvn.replace_node(n, pinned_clone);\n+            }\n@@ -1895,0 +1897,1 @@\n+          _igvn.replace_input_of(maybe_pinned_n, 0, outside_ctrl);\n@@ -1896,1 +1899,0 @@\n-        _igvn.replace_input_of(maybe_pinned_n, 0, outside_ctrl);\n@@ -2104,0 +2106,15 @@\n+\/\/ Sinking a node from a pre loop to its main loop pins the node between the pre and main loops. If that node is input\n+\/\/ to a check that's eliminated by range check elimination, it becomes input to an expression that feeds into the exit\n+\/\/ test of the pre loop above the point in the graph where it's pinned. This results in a broken graph. One way to avoid\n+\/\/ it would be to not eliminate the check in the main loop. Instead, we prevent sinking of the node here so better code\n+\/\/ is generated for the main loop.\n+bool PhaseIdealLoop::would_sink_below_pre_loop_exit(IdealLoopTree* n_loop, Node* ctrl) {\n+  if (n_loop->_head->is_CountedLoop() && n_loop->_head->as_CountedLoop()->is_pre_loop()) {\n+    CountedLoopNode* pre_loop = n_loop->_head->as_CountedLoop();\n+    if (is_dominator(pre_loop->loopexit(), ctrl)) {\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n@@ -2115,8 +2132,2 @@\n-  \/\/ Sinking a node from a pre loop to its main loop pins the node between the pre and main loops. If that node is input\n-  \/\/ to a check that's eliminated by range check elimination, it becomes input to an expression that feeds into the exit\n-  \/\/ test of the pre loop above the point in the graph where it's pinned.\n-  if (n_loop->_head->is_CountedLoop() && n_loop->_head->as_CountedLoop()->is_pre_loop()) {\n-    CountedLoopNode* pre_loop = n_loop->_head->as_CountedLoop();\n-    if (is_dominator(pre_loop->loopexit(), ctrl)) {\n-      return false;\n-    }\n+  if (would_sink_below_pre_loop_exit(n_loop, ctrl)) {\n+    return false;\n","filename":"src\/hotspot\/share\/opto\/loopopts.cpp","additions":29,"deletions":18,"binary":false,"changes":47,"status":"modified"},{"patch":"@@ -144,1 +144,1 @@\n-    Atomic::inc(&PhaseMacroExpand::_GC_barriers_removed_counter);\n+    AtomicAccess::inc(&PhaseMacroExpand::_GC_barriers_removed_counter);\n@@ -3037,1 +3037,1 @@\n-          Atomic::inc(&PhaseMacroExpand::_objs_scalar_replaced_counter);\n+          AtomicAccess::inc(&PhaseMacroExpand::_objs_scalar_replaced_counter);\n@@ -3054,1 +3054,1 @@\n-            Atomic::inc(&PhaseMacroExpand::_monitor_objects_removed_counter);\n+            AtomicAccess::inc(&PhaseMacroExpand::_monitor_objects_removed_counter);\n@@ -3106,1 +3106,1 @@\n-    Atomic::add(&PhaseMacroExpand::_memory_barriers_removed_counter, membar_before - membar_after);\n+    AtomicAccess::add(&PhaseMacroExpand::_memory_barriers_removed_counter, membar_before - membar_after);\n@@ -3341,4 +3341,4 @@\n-  tty->print(\"Objects scalar replaced = %d, \", Atomic::load(&_objs_scalar_replaced_counter));\n-  tty->print(\"Monitor objects removed = %d, \", Atomic::load(&_monitor_objects_removed_counter));\n-  tty->print(\"GC barriers removed = %d, \", Atomic::load(&_GC_barriers_removed_counter));\n-  tty->print_cr(\"Memory barriers removed = %d\", Atomic::load(&_memory_barriers_removed_counter));\n+  tty->print(\"Objects scalar replaced = %d, \", AtomicAccess::load(&_objs_scalar_replaced_counter));\n+  tty->print(\"Monitor objects removed = %d, \", AtomicAccess::load(&_monitor_objects_removed_counter));\n+  tty->print(\"GC barriers removed = %d, \", AtomicAccess::load(&_GC_barriers_removed_counter));\n+  tty->print_cr(\"Memory barriers removed = %d\", AtomicAccess::load(&_memory_barriers_removed_counter));\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -593,1 +593,1 @@\n-  C->FIRST_STACK_mask().set_AllStack();\n+  C->FIRST_STACK_mask().set_infinite_stack();\n@@ -599,1 +599,1 @@\n-  assert(aligned_stack_mask.is_AllStack(), \"should be infinite stack\");\n+  assert(aligned_stack_mask.is_infinite_stack(), \"should be infinite stack\");\n@@ -656,1 +656,1 @@\n-     assert(aligned_stack_mask.is_AllStack(), \"should be infinite stack\");\n+     assert(aligned_stack_mask.is_infinite_stack(), \"should be infinite stack\");\n@@ -671,1 +671,1 @@\n-     assert(aligned_stack_mask.is_AllStack(), \"should be infinite stack\");\n+     assert(aligned_stack_mask.is_infinite_stack(), \"should be infinite stack\");\n@@ -686,1 +686,1 @@\n-     assert(aligned_stack_mask.is_AllStack(), \"should be infinite stack\");\n+     assert(aligned_stack_mask.is_infinite_stack(), \"should be infinite stack\");\n@@ -706,1 +706,1 @@\n-      assert(scalable_stack_mask.is_AllStack(), \"should be infinite stack\");\n+      assert(scalable_stack_mask.is_infinite_stack(), \"should be infinite stack\");\n@@ -720,1 +720,1 @@\n-     assert(scalable_stack_mask.is_AllStack(), \"should be infinite stack\");\n+     assert(scalable_stack_mask.is_infinite_stack(), \"should be infinite stack\");\n@@ -1033,1 +1033,1 @@\n-  STACK_ONLY_mask.set_AllStack();\n+  STACK_ONLY_mask.set_infinite_stack();\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -1226,0 +1226,3 @@\n+  } else if (n->Opcode() == Op_XorV || n->Opcode() == Op_XorVMask) {\n+    \/\/ Condition for XorVMask(VectorMaskCmp(x,y,cond), MaskAll(true)) ==> VectorMaskCmp(x,y,ncond)\n+    return true;\n","filename":"src\/hotspot\/share\/opto\/node.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2698,1 +2698,5 @@\n-  if (use->Opcode() == Op_AddX) {\n+\n+  \/\/ From CastX2PNode::Ideal\n+  \/\/ CastX2P(AddX(x, y))\n+  \/\/ CastX2P(SubX(x, y))\n+  if (use->Opcode() == Op_AddX || use->Opcode() == Op_SubX) {\n","filename":"src\/hotspot\/share\/opto\/phaseX.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -66,1 +66,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -2262,1 +2262,1 @@\n-  } while (Atomic::cmpxchg(&_named_counters, head, c) != head);\n+  } while (AtomicAccess::cmpxchg(&_named_counters, head, c) != head);\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -34,1 +34,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -412,1 +412,1 @@\n-  Atomic::add(&_stropts_total, encountered);\n+  AtomicAccess::add(&_stropts_total, encountered);\n@@ -685,1 +685,1 @@\n-              Atomic::inc(&_stropts_merged);\n+              AtomicAccess::inc(&_stropts_merged);\n@@ -2044,1 +2044,1 @@\n-  Atomic::inc(&_stropts_replaced);\n+  AtomicAccess::inc(&_stropts_replaced);\n","filename":"src\/hotspot\/share\/opto\/stringopts.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -353,1 +353,3 @@\n-  mask negate( ) const { return mask(_test^4); }\n+  mask negate( ) const { return negate_mask(_test); }\n+  \/\/ Return the negative mask for the given mask, for both signed and unsigned comparison.\n+  static mask negate_mask(mask btm) { return mask(btm ^ 4); }\n","filename":"src\/hotspot\/share\/opto\/subnode.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -74,1 +74,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -532,1 +532,1 @@\n-  InstanceKlass* k = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve_non_null(clazz)));\n+  InstanceKlass* k = java_lang_Class::as_InstanceKlass(JNIHandles::resolve_non_null(clazz));\n@@ -3020,1 +3020,1 @@\n-  if (Atomic::cmpxchg(&directBufferSupportInitializeStarted, 0, 1) == 0) {\n+  if (AtomicAccess::cmpxchg(&directBufferSupportInitializeStarted, 0, 1) == 0) {\n@@ -3490,1 +3490,1 @@\n-    Atomic::store(a++, *b++);\n+    AtomicAccess::store(a++, *b++);\n@@ -3606,1 +3606,1 @@\n-  \/\/ We're about to use Atomic::xchg for synchronization.  Some Zero\n+  \/\/ We're about to use AtomicAccess::xchg for synchronization.  Some Zero\n@@ -3613,1 +3613,1 @@\n-    jint b = Atomic::xchg(&a, (jint) 0xdeadbeef);\n+    jint b = AtomicAccess::xchg(&a, (jint) 0xdeadbeef);\n@@ -3615,3 +3615,3 @@\n-    void *d = Atomic::xchg(&c, &b);\n-    assert(a == (jint) 0xdeadbeef && b == (jint) 0xcafebabe, \"Atomic::xchg() works\");\n-    assert(c == &b && d == &a, \"Atomic::xchg() works\");\n+    void *d = AtomicAccess::xchg(&c, &b);\n+    assert(a == (jint) 0xdeadbeef && b == (jint) 0xcafebabe, \"AtomicAccess::xchg() works\");\n+    assert(c == &b && d == &a, \"AtomicAccess::xchg() works\");\n@@ -3628,1 +3628,1 @@\n-  \/\/ We use Atomic::xchg rather than Atomic::add\/dec since on some platforms\n+  \/\/ We use AtomicAccess::xchg rather than AtomicAccess::add\/dec since on some platforms\n@@ -3630,2 +3630,2 @@\n-  \/\/ on a multiprocessor Atomic::xchg does not have this problem.\n-  if (Atomic::xchg(&vm_created, IN_PROGRESS) != NOT_CREATED) {\n+  \/\/ on a multiprocessor AtomicAccess::xchg does not have this problem.\n+  if (AtomicAccess::xchg(&vm_created, IN_PROGRESS) != NOT_CREATED) {\n@@ -3640,1 +3640,1 @@\n-  if (Atomic::xchg(&safe_to_recreate_vm, 0) == 0) {\n+  if (AtomicAccess::xchg(&safe_to_recreate_vm, 0) == 0) {\n@@ -3664,1 +3664,1 @@\n-    Atomic::release_store(&vm_created, COMPLETE);\n+    AtomicAccess::release_store(&vm_created, COMPLETE);\n@@ -3730,1 +3730,1 @@\n-    Atomic::release_store(&vm_created, NOT_CREATED);\n+    AtomicAccess::release_store(&vm_created, NOT_CREATED);\n","filename":"src\/hotspot\/share\/prims\/jni.cpp","additions":15,"deletions":15,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -76,1 +76,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -1019,8 +1019,3 @@\n-    oop from_mirror = JNIHandles::resolve_non_null(from);\n-    Klass* from_class = java_lang_Class::as_Klass(from_mirror);\n-    const char * from_name = from_class->external_name();\n-\n-    oop mirror = JNIHandles::resolve_non_null(result);\n-    Klass* to_class = java_lang_Class::as_Klass(mirror);\n-    const char * to = to_class->external_name();\n-    log_debug(class, resolve)(\"%s %s (verification)\", from_name, to);\n+    const char* from_name = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(from))->external_name();\n+    const char* to_name = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(result))->external_name();\n+    log_debug(class, resolve)(\"%s %s (verification)\", from_name, to_name);\n@@ -1097,2 +1092,2 @@\n-  Klass* lookup_k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(lookup));\n-  \/\/ Lookup class must be a non-null instance\n+  InstanceKlass* lookup_k = java_lang_Class::as_InstanceKlass(JNIHandles::resolve_non_null(lookup));\n+  \/\/ Lookup class must not be a primitive class (whose mirror has a null Klass*)\n@@ -1100,0 +1095,1 @@\n+    \/\/ The error message is wrong. We come here only if lookup is a primitive class\n@@ -1102,1 +1098,0 @@\n-  assert(lookup_k->is_instance_klass(), \"Lookup class must be an instance klass\");\n@@ -1113,1 +1108,1 @@\n-    host_class = InstanceKlass::cast(lookup_k)->nest_host(CHECK_NULL);\n+    host_class = lookup_k->nest_host(CHECK_NULL);\n@@ -1444,1 +1439,1 @@\n-  InstanceKlass* k = InstanceKlass::cast(java_lang_Class::as_Klass(ofMirror));\n+  InstanceKlass* k = java_lang_Class::as_InstanceKlass(ofMirror);\n@@ -1583,1 +1578,0 @@\n-  Klass* k    = java_lang_Class::as_Klass(mirror);\n@@ -1587,1 +1581,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(k);\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(mirror);\n@@ -1623,1 +1617,1 @@\n-  Klass* k = java_lang_Class::as_Klass(mirror);\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(mirror);\n@@ -1625,1 +1619,1 @@\n-  Method* m = InstanceKlass::cast(k)->method_with_idnum(slot);\n+  Method* m = ik->method_with_idnum(slot);\n@@ -1749,1 +1743,1 @@\n-  InstanceKlass* k = InstanceKlass::cast(java_lang_Class::as_Klass(ofMirror));\n+  InstanceKlass* k = java_lang_Class::as_InstanceKlass(ofMirror);\n@@ -1806,3 +1800,1 @@\n-  Klass* c = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(ofClass));\n-  assert(c->is_instance_klass(), \"must be\");\n-  InstanceKlass* ik = InstanceKlass::cast(c);\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve_non_null(ofClass));\n@@ -1850,1 +1842,1 @@\n-  InstanceKlass* k = InstanceKlass::cast(java_lang_Class::as_Klass(ofMirror));\n+  InstanceKlass* k = java_lang_Class::as_InstanceKlass(ofMirror);\n@@ -1930,7 +1922,3 @@\n-  Klass* c = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(current));\n-  assert(c->is_instance_klass(), \"must be\");\n-  InstanceKlass* ck = InstanceKlass::cast(c);\n-  Klass* m = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(member));\n-  assert(m->is_instance_klass(), \"must be\");\n-  InstanceKlass* mk = InstanceKlass::cast(m);\n-  return ck->has_nestmate_access_to(mk, THREAD);\n+  InstanceKlass* c = java_lang_Class::as_InstanceKlass(JNIHandles::resolve_non_null(current));\n+  InstanceKlass* m = java_lang_Class::as_InstanceKlass(JNIHandles::resolve_non_null(member));\n+  return c->has_nestmate_access_to(m, THREAD);\n@@ -1943,4 +1931,2 @@\n-  Klass* c = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(current));\n-  assert(c->is_instance_klass(), \"must be\");\n-  InstanceKlass* ck = InstanceKlass::cast(c);\n-  InstanceKlass* host = ck->nest_host(THREAD);\n+  InstanceKlass* c = java_lang_Class::as_InstanceKlass(JNIHandles::resolve_non_null(current));\n+  InstanceKlass* host = c->nest_host(THREAD);\n@@ -1956,4 +1942,2 @@\n-  Klass* c = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(current));\n-  assert(c->is_instance_klass(), \"must be\");\n-  InstanceKlass* ck = InstanceKlass::cast(c);\n-  InstanceKlass* host = ck->nest_host(THREAD);\n+  InstanceKlass* c = java_lang_Class::as_InstanceKlass(JNIHandles::resolve_non_null(current));\n+  InstanceKlass* host = c->nest_host(THREAD);\n@@ -1962,1 +1946,1 @@\n-                              ck->external_name(), host->external_name());\n+                              c->external_name(), host->external_name());\n@@ -2025,1 +2009,1 @@\n-      assert(host == ck || ck->is_hidden(), \"must be singleton nest or dynamic nestmate\");\n+      assert(host == c || c->is_hidden(), \"must be singleton nest or dynamic nestmate\");\n@@ -2036,3 +2020,2 @@\n-  Klass* c = java_lang_Class::as_Klass(mirror);\n-  assert(c->is_instance_klass(), \"must be\");\n-  InstanceKlass* ik = InstanceKlass::cast(c);\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(mirror);\n+\n@@ -3565,2 +3548,1 @@\n-  Klass* caller_k = java_lang_Class::as_Klass(JNIHandles::resolve(caller));\n-  InstanceKlass* caller_ik = InstanceKlass::cast(caller_k);\n+  InstanceKlass* caller_ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(caller));\n@@ -3573,2 +3555,1 @@\n-  Klass* lambda_k = java_lang_Class::as_Klass(JNIHandles::resolve(lambdaProxyClass));\n-  InstanceKlass* lambda_ik = InstanceKlass::cast(lambda_k);\n+  InstanceKlass* lambda_ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(lambdaProxyClass));\n@@ -3614,2 +3595,1 @@\n-  Klass* caller_k = java_lang_Class::as_Klass(JNIHandles::resolve(caller));\n-  InstanceKlass* caller_ik = InstanceKlass::cast(caller_k);\n+  InstanceKlass* caller_ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(caller));\n@@ -4012,5 +3992,1 @@\n-  assert(!java_lang_Class::as_Klass(mirror)->is_array_klass(), \"unexpected array class\");\n-\n-  Klass* c = java_lang_Class::as_Klass(mirror);\n-  assert(c->is_instance_klass(), \"must be\");\n-  InstanceKlass* ik = InstanceKlass::cast(c);\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(mirror);\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":30,"deletions":54,"binary":false,"changes":84,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+#include \"oops\/fieldStreams.inline.hpp\"\n@@ -71,1 +72,0 @@\n-#include \"runtime\/reflectionUtils.hpp\"\n@@ -2840,1 +2840,1 @@\n-  FilteredJavaFieldStream flds(ik);\n+  JavaFieldStream flds(ik);\n@@ -2842,1 +2842,1 @@\n-  int result_count = flds.field_count();\n+  int result_count = ik->java_fields_count();\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnv.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -60,1 +60,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -4589,1 +4589,1 @@\n-    u8 result = Atomic::cmpxchg(&_id_counter, id, next_id);\n+    u8 result = AtomicAccess::cmpxchg(&_id_counter, id, next_id);\n","filename":"src\/hotspot\/share\/prims\/jvmtiRedefineClasses.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+#include \"oops\/fieldStreams.inline.hpp\"\n@@ -61,1 +62,0 @@\n-#include \"runtime\/reflectionUtils.hpp\"\n@@ -675,2 +675,2 @@\n-    FilteredJavaFieldStream fld(interfaces->at(i));\n-    count += fld.field_count();\n+    count += interfaces->at(i)->java_fields_count();\n+\n@@ -698,2 +698,1 @@\n-    FilteredJavaFieldStream super_fld(super_klass);\n-    index += super_fld.field_count();\n+    index += super_klass->java_fields_count();\n@@ -702,1 +701,1 @@\n-  for (FilteredJavaFieldStream fld(ik); !fld.done(); fld.next(), index++) {\n+  for (JavaFieldStream fld(ik); !fld.done(); fld.next(), index++) {\n@@ -725,2 +724,1 @@\n-    FilteredJavaFieldStream fld(klass);\n-    total_field_number += fld.field_count();\n+    total_field_number += klass->java_fields_count();\n@@ -730,2 +728,2 @@\n-    FilteredJavaFieldStream fld(klass);\n-    int start_index = total_field_number - fld.field_count();\n+    JavaFieldStream fld(klass);\n+    int start_index = total_field_number - klass->java_fields_count();\n","filename":"src\/hotspot\/share\/prims\/jvmtiTagMap.cpp","additions":8,"deletions":10,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -914,1 +914,1 @@\n-      InstanceKlass* defc = InstanceKlass::cast(java_lang_Class::as_Klass(clazz));\n+      InstanceKlass* defc = java_lang_Class::as_InstanceKlass(clazz);\n","filename":"src\/hotspot\/share\/prims\/methodHandles.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -757,1 +757,1 @@\n-  InstanceKlass* k = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve_non_null(clazz)));\n+  InstanceKlass* k = java_lang_Class::as_InstanceKlass(JNIHandles::resolve_non_null(clazz));\n@@ -1067,1 +1067,1 @@\n-  return Atomic::cmpxchg(addr, e, x);\n+  return AtomicAccess::cmpxchg(addr, e, x);\n@@ -1073,1 +1073,1 @@\n-  return Atomic::cmpxchg(addr, e, x);\n+  return AtomicAccess::cmpxchg(addr, e, x);\n@@ -1088,1 +1088,1 @@\n-  return Atomic::cmpxchg(addr, e, x) == e;\n+  return AtomicAccess::cmpxchg(addr, e, x) == e;\n@@ -1094,1 +1094,1 @@\n-  return Atomic::cmpxchg(addr, e, x) == e;\n+  return AtomicAccess::cmpxchg(addr, e, x) == e;\n","filename":"src\/hotspot\/share\/prims\/unsafe.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -80,1 +80,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -1163,1 +1163,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(klass)));\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(klass));\n@@ -1508,1 +1508,0 @@\n-  Universe::heap()->soft_ref_policy()->set_should_clear_all_soft_refs(true);\n@@ -1943,1 +1942,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(klass)));\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(klass));\n@@ -1948,1 +1947,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(klass)));\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(klass));\n@@ -2057,1 +2056,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(klass)));\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(klass));\n@@ -2066,1 +2065,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(klass)));\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(klass));\n@@ -2075,1 +2074,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(klass)));\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(klass));\n@@ -2084,1 +2083,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(klass)));\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(klass));\n@@ -2093,1 +2092,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(klass)));\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(klass));\n@@ -2102,1 +2101,1 @@\n-  InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(klass)));\n+  InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(klass));\n@@ -2414,1 +2413,1 @@\n-      Atomic::inc(&_num_threads_completed);\n+      AtomicAccess::inc(&_num_threads_completed);\n@@ -2481,1 +2480,1 @@\n-    while (Atomic::cmpxchg(&_emulated_lock, 0, 1) != 0) {}\n+    while (AtomicAccess::cmpxchg(&_emulated_lock, 0, 1) != 0) {}\n@@ -2488,1 +2487,1 @@\n-  Atomic::store(&_emulated_lock, 0);\n+  AtomicAccess::store(&_emulated_lock, 0);\n@@ -2496,4 +2495,2 @@\n-  \/\/Get the class of our object\n-  Klass* arg_klass = object->klass();\n-  \/\/Turn it into an instance-klass\n-  InstanceKlass* ik = InstanceKlass::cast(arg_klass);\n+  \/\/Only non-array oops have fields. Don't call this function on arrays!\n+  InstanceKlass* ik = InstanceKlass::cast(object->klass());\n@@ -3181,1 +3178,1 @@\n-      InstanceKlass* ik = InstanceKlass::cast(java_lang_Class::as_Klass(JNIHandles::resolve(wbclass)));\n+      InstanceKlass* ik = java_lang_Class::as_InstanceKlass(JNIHandles::resolve(wbclass));\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":16,"deletions":19,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -67,1 +67,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -141,1 +141,1 @@\n-  Atomic::store(&nm->_deoptimization_status, status);\n+  AtomicAccess::store(&nm->_deoptimization_status, status);\n@@ -1169,1 +1169,1 @@\n-      if (!Atomic::replace_if_null(&_singleton, s)) {\n+      if (!AtomicAccess::replace_if_null(&_singleton, s)) {\n@@ -1232,1 +1232,1 @@\n-      if (!Atomic::replace_if_null(&_singleton, s)) {\n+      if (!AtomicAccess::replace_if_null(&_singleton, s)) {\n@@ -2094,1 +2094,1 @@\n-  if (1 == critical_section || Atomic::cmpxchg(&critical_section, 0, 1) == 1) {\n+  if (1 == critical_section || AtomicAccess::cmpxchg(&critical_section, 0, 1) == 1) {\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -30,1 +30,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n","filename":"src\/hotspot\/share\/runtime\/handles.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -39,1 +39,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -241,1 +241,1 @@\n-  return Atomic::load_acquire(&_init_completed);\n+  return AtomicAccess::load_acquire(&_init_completed);\n@@ -254,1 +254,1 @@\n-  Atomic::release_store(&_init_completed, true);\n+  AtomicAccess::release_store(&_init_completed, true);\n","filename":"src\/hotspot\/share\/runtime\/init.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -60,1 +60,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -1068,1 +1068,1 @@\n-  return Atomic::load(&_exception_oop);\n+  return AtomicAccess::load(&_exception_oop);\n@@ -1072,1 +1072,1 @@\n-  Atomic::store(&_exception_oop, o);\n+  AtomicAccess::store(&_exception_oop, o);\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -186,1 +186,1 @@\n-    \/\/ Use Atomic::load() to prevent data race between concurrent modification and\n+    \/\/ Use AtomicAccess::load() to prevent data race between concurrent modification and\n@@ -189,1 +189,1 @@\n-    return Atomic::load(&_current_pending_monitor);\n+    return AtomicAccess::load(&_current_pending_monitor);\n@@ -192,1 +192,1 @@\n-    Atomic::store(&_current_pending_monitor, monitor);\n+    AtomicAccess::store(&_current_pending_monitor, monitor);\n@@ -202,1 +202,1 @@\n-    return Atomic::load(&_current_waiting_monitor);\n+    return AtomicAccess::load(&_current_waiting_monitor);\n@@ -205,1 +205,1 @@\n-    Atomic::store(&_current_waiting_monitor, monitor);\n+    AtomicAccess::store(&_current_waiting_monitor, monitor);\n@@ -719,1 +719,1 @@\n-    return Atomic::load(&_carrier_thread_suspended);\n+    return AtomicAccess::load(&_carrier_thread_suspended);\n@@ -731,2 +731,2 @@\n-  bool VTMS_transition_mark() const              { return Atomic::load(&_VTMS_transition_mark); }\n-  void set_VTMS_transition_mark(bool val)        { Atomic::store(&_VTMS_transition_mark, val); }\n+  bool VTMS_transition_mark() const              { return AtomicAccess::load(&_VTMS_transition_mark); }\n+  void set_VTMS_transition_mark(bool val)        { AtomicAccess::store(&_VTMS_transition_mark, val); }\n@@ -951,1 +951,1 @@\n-  bool in_critical_atomic() { return Atomic::load(&_jni_active_critical) > 0; }\n+  bool in_critical_atomic() { return AtomicAccess::load(&_jni_active_critical) > 0; }\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":9,"deletions":9,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -378,1 +378,1 @@\n-    Atomic::inc(&_blocks_allocated);\n+    AtomicAccess::inc(&_blocks_allocated);\n@@ -415,1 +415,1 @@\n-      Atomic::dec(&_blocks_allocated);\n+      AtomicAccess::dec(&_blocks_allocated);\n","filename":"src\/hotspot\/share\/runtime\/jniHandles.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1152,1 +1152,1 @@\n-  InstanceKlass* klass = InstanceKlass::cast(java_lang_Class::as_Klass(mirror));\n+  InstanceKlass* klass = java_lang_Class::as_InstanceKlass(mirror);\n@@ -1169,1 +1169,1 @@\n-  InstanceKlass* klass = InstanceKlass::cast(java_lang_Class::as_Klass(mirror));\n+  InstanceKlass* klass = java_lang_Class::as_InstanceKlass(mirror);\n","filename":"src\/hotspot\/share\/runtime\/reflection.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -45,1 +45,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -310,1 +310,1 @@\n-  Atomic::release_store(&_safepoint_counter, _safepoint_counter + 1);\n+  AtomicAccess::release_store(&_safepoint_counter, _safepoint_counter + 1);\n@@ -445,1 +445,1 @@\n-    Atomic::release_store(&_safepoint_counter, _safepoint_counter + 1);\n+    AtomicAccess::release_store(&_safepoint_counter, _safepoint_counter + 1);\n@@ -613,1 +613,1 @@\n-    Atomic::inc(&_nof_threads_hit_polling_page);\n+    AtomicAccess::inc(&_nof_threads_hit_polling_page);\n@@ -689,1 +689,1 @@\n-  return Atomic::load_acquire(&_safepoint_id);\n+  return AtomicAccess::load_acquire(&_safepoint_id);\n@@ -693,1 +693,1 @@\n-  Atomic::release_store(&_safepoint_id, SafepointSynchronize::InactiveSafepointCounter);\n+  AtomicAccess::release_store(&_safepoint_id, SafepointSynchronize::InactiveSafepointCounter);\n@@ -697,1 +697,1 @@\n-  Atomic::release_store(&_safepoint_id, safepoint_id);\n+  AtomicAccess::release_store(&_safepoint_id, safepoint_id);\n","filename":"src\/hotspot\/share\/runtime\/safepoint.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -66,1 +66,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -889,2 +889,2 @@\n-  Klass* k = vmClasses::StackOverflowError_klass();\n-  oop exception_oop = InstanceKlass::cast(k)->allocate_instance(CHECK);\n+  InstanceKlass* k = vmClasses::StackOverflowError_klass();\n+  oop exception_oop = k->allocate_instance(CHECK);\n@@ -904,1 +904,1 @@\n-  Atomic::inc(&Exceptions::_stack_overflow_errors);\n+  AtomicAccess::inc(&Exceptions::_stack_overflow_errors);\n@@ -1425,1 +1425,1 @@\n-  Atomic::inc(addr);\n+  AtomicAccess::inc(addr);\n@@ -1675,1 +1675,1 @@\n-  Atomic::inc(&_ic_miss_ctr);\n+  AtomicAccess::inc(&_ic_miss_ctr);\n@@ -1810,1 +1810,1 @@\n-  Atomic::inc(&_wrong_method_ctr);\n+  AtomicAccess::inc(&_wrong_method_ctr);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -904,0 +904,2 @@\n+  do_entry(final, jbyte_arraycopy, jbyte_arraycopy_nopush,              \\\n+            jbyte_arraycopy_nopush)                                     \\\n@@ -907,0 +909,2 @@\n+  do_entry(final, jshort_arraycopy, jshort_arraycopy_nopush,            \\\n+            jshort_arraycopy_nopush)                                    \\\n@@ -910,0 +914,2 @@\n+  do_entry(final, jint_arraycopy, jint_arraycopy_nopush,                \\\n+            jint_arraycopy_nopush)                                      \\\n@@ -913,0 +919,2 @@\n+  do_entry(final, jlong_arraycopy, jlong_arraycopy_nopush,              \\\n+            jlong_arraycopy_nopush)                                     \\\n@@ -916,0 +924,2 @@\n+  do_entry(final, oop_arraycopy, oop_arraycopy_nopush,                  \\\n+            oop_arraycopy_nopush)                                       \\\n@@ -924,0 +934,3 @@\n+  do_entry(final, jbyte_disjoint_arraycopy,                             \\\n+           jbyte_disjoint_arraycopy_nopush,                             \\\n+           jbyte_disjoint_arraycopy_nopush)                             \\\n@@ -928,0 +941,3 @@\n+  do_entry(final, jshort_disjoint_arraycopy,                            \\\n+           jshort_disjoint_arraycopy_nopush,                            \\\n+           jshort_disjoint_arraycopy_nopush)                            \\\n@@ -932,0 +948,3 @@\n+  do_entry(final, jint_disjoint_arraycopy,                              \\\n+           jint_disjoint_arraycopy_nopush,                              \\\n+           jint_disjoint_arraycopy_nopush)                              \\\n@@ -936,0 +955,3 @@\n+  do_entry(final, jlong_disjoint_arraycopy,                             \\\n+           jlong_disjoint_arraycopy_nopush,                             \\\n+           jlong_disjoint_arraycopy_nopush)                             \\\n@@ -939,0 +961,3 @@\n+  do_entry(final, oop_disjoint_arraycopy,                               \\\n+           oop_disjoint_arraycopy_nopush,                               \\\n+           oop_disjoint_arraycopy_nopush)                               \\\n@@ -944,0 +969,3 @@\n+  do_entry(final, oop_disjoint_arraycopy_uninit,                        \\\n+           oop_disjoint_arraycopy_uninit_nopush,                        \\\n+           oop_disjoint_arraycopy_uninit_nopush)                        \\\n@@ -973,0 +1001,3 @@\n+  do_entry(final, arrayof_jbyte_disjoint_arraycopy,                     \\\n+           arrayof_jbyte_disjoint_arraycopy_nopush,                     \\\n+           arrayof_jbyte_disjoint_arraycopy_nopush)                     \\\n@@ -978,0 +1009,3 @@\n+  do_entry(final, arrayof_jshort_disjoint_arraycopy,                    \\\n+           arrayof_jshort_disjoint_arraycopy_nopush,                    \\\n+           arrayof_jshort_disjoint_arraycopy_nopush)                    \\\n@@ -983,0 +1017,3 @@\n+  do_entry(final, arrayof_jint_disjoint_arraycopy,                      \\\n+           arrayof_jint_disjoint_arraycopy_nopush,                      \\\n+           arrayof_jint_disjoint_arraycopy_nopush)                      \\\n@@ -988,0 +1025,3 @@\n+  do_entry(final, arrayof_jlong_disjoint_arraycopy,                     \\\n+           arrayof_jlong_disjoint_arraycopy_nopush,                     \\\n+           arrayof_jlong_disjoint_arraycopy_nopush)                     \\\n@@ -993,0 +1033,3 @@\n+  do_entry(final, arrayof_oop_disjoint_arraycopy,                       \\\n+           arrayof_oop_disjoint_arraycopy_nopush,                       \\\n+           arrayof_oop_disjoint_arraycopy_nopush)                       \\\n@@ -998,0 +1041,3 @@\n+  do_entry(final, arrayof_oop_disjoint_arraycopy_uninit,                \\\n+           arrayof_oop_disjoint_arraycopy_uninit_nopush,                \\\n+           arrayof_oop_disjoint_arraycopy_uninit_nopush)                \\\n@@ -1001,0 +1047,2 @@\n+  do_entry(final, checkcast_arraycopy, checkcast_arraycopy_nopush,      \\\n+            checkcast_arraycopy_nopush)                                 \\\n","filename":"src\/hotspot\/share\/runtime\/stubDeclarations.hpp","additions":48,"deletions":0,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -36,1 +36,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -73,1 +73,1 @@\n-    head = Atomic::load(&_head);\n+    head = AtomicAccess::load(&_head);\n@@ -75,1 +75,1 @@\n-  } while (Atomic::cmpxchg(&_head, head, m) != head);\n+  } while (AtomicAccess::cmpxchg(&_head, head, m) != head);\n@@ -77,1 +77,1 @@\n-  size_t count = Atomic::add(&_count, 1u, memory_order_relaxed);\n+  size_t count = AtomicAccess::add(&_count, 1u, memory_order_relaxed);\n@@ -80,1 +80,1 @@\n-    old_max = Atomic::load(&_max);\n+    old_max = AtomicAccess::load(&_max);\n@@ -84,1 +84,1 @@\n-  } while (Atomic::cmpxchg(&_max, old_max, count, memory_order_relaxed) != old_max);\n+  } while (AtomicAccess::cmpxchg(&_max, old_max, count, memory_order_relaxed) != old_max);\n@@ -88,1 +88,1 @@\n-  return Atomic::load(&_count);\n+  return AtomicAccess::load(&_count);\n@@ -92,1 +92,1 @@\n-  return Atomic::load(&_max);\n+  return AtomicAccess::load(&_max);\n@@ -113,1 +113,1 @@\n-  ObjectMonitor* m = Atomic::load_acquire(&_head);\n+  ObjectMonitor* m = AtomicAccess::load_acquire(&_head);\n@@ -134,1 +134,1 @@\n-        if (prev == nullptr && Atomic::load(&_head) != m) {\n+        if (prev == nullptr && AtomicAccess::load(&_head) != m) {\n@@ -146,1 +146,1 @@\n-        ObjectMonitor* prev_head = Atomic::cmpxchg(&_head, m, next);\n+        ObjectMonitor* prev_head = AtomicAccess::cmpxchg(&_head, m, next);\n@@ -158,1 +158,1 @@\n-        assert(Atomic::load(&_head) != m, \"Sanity\");\n+        assert(AtomicAccess::load(&_head) != m, \"Sanity\");\n@@ -183,1 +183,1 @@\n-    ObjectMonitor* m = Atomic::load_acquire(&_head);\n+    ObjectMonitor* m = AtomicAccess::load_acquire(&_head);\n@@ -191,1 +191,1 @@\n-  Atomic::sub(&_count, unlinked_count);\n+  AtomicAccess::sub(&_count, unlinked_count);\n@@ -196,1 +196,1 @@\n-  return Iterator(Atomic::load_acquire(&_head));\n+  return Iterator(AtomicAccess::load_acquire(&_head));\n@@ -763,1 +763,1 @@\n-      uintptr_t v = Atomic::cmpxchg(monitor->metadata_addr(), mark.value(), temp.value());\n+      uintptr_t v = AtomicAccess::cmpxchg(monitor->metadata_addr(), mark.value(), temp.value());\n@@ -971,1 +971,1 @@\n-  Atomic::sub(&_in_use_list_ceiling, AvgMonitorsPerThreadEstimate);\n+  AtomicAccess::sub(&_in_use_list_ceiling, AvgMonitorsPerThreadEstimate);\n@@ -975,1 +975,1 @@\n-  Atomic::add(&_in_use_list_ceiling, AvgMonitorsPerThreadEstimate);\n+  AtomicAccess::add(&_in_use_list_ceiling, AvgMonitorsPerThreadEstimate);\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":18,"deletions":18,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -671,0 +671,8 @@\n+  \/******************************************************************************************\/                                       \\\n+  \/* CI (NOTE: these CI fields are retained in VMStructs for the benefit of external tools, *\/                                       \\\n+  \/* to ease their migration to a future alternative.)                                      *\/                                       \\\n+  \/******************************************************************************************\/                                       \\\n+                                                                                                                                     \\\n+  nonstatic_field(CompilerThread,              _env,                                          ciEnv*)                                \\\n+  nonstatic_field(ciEnv,                       _task,                                         CompileTask*)                          \\\n+                                                                                                                                     \\\n@@ -1156,0 +1164,6 @@\n+  \/*********************\/                                                 \\\n+  \/* CI *\/                                                                \\\n+  \/*********************\/                                                 \\\n+                                                                          \\\n+  declare_toplevel_type(ciEnv)                                            \\\n+                                                                          \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2224,2 +2224,2 @@\n-    _thread_serial_num = Atomic::fetch_then_add(thread_counter, 1);\n-    _start_frame_serial_num = Atomic::fetch_then_add(frame_counter, frame_count());\n+    _thread_serial_num = AtomicAccess::fetch_then_add(thread_counter, 1);\n+    _start_frame_serial_num = AtomicAccess::fetch_then_add(frame_counter, frame_count());\n@@ -2766,1 +2766,1 @@\n-    return Atomic::fetch_then_add(&_dump_seq, 1);\n+    return AtomicAccess::fetch_then_add(&_dump_seq, 1);\n","filename":"src\/hotspot\/share\/services\/heapDumper.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -26,1 +26,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n","filename":"src\/hotspot\/share\/utilities\/accessFlags.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,1 +29,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -308,8 +308,8 @@\n-    case 8:  Atomic::store(&to[7], Atomic::load(&from[7]));\n-    case 7:  Atomic::store(&to[6], Atomic::load(&from[6]));\n-    case 6:  Atomic::store(&to[5], Atomic::load(&from[5]));\n-    case 5:  Atomic::store(&to[4], Atomic::load(&from[4]));\n-    case 4:  Atomic::store(&to[3], Atomic::load(&from[3]));\n-    case 3:  Atomic::store(&to[2], Atomic::load(&from[2]));\n-    case 2:  Atomic::store(&to[1], Atomic::load(&from[1]));\n-    case 1:  Atomic::store(&to[0], Atomic::load(&from[0]));\n+    case 8:  AtomicAccess::store(&to[7], AtomicAccess::load(&from[7]));\n+    case 7:  AtomicAccess::store(&to[6], AtomicAccess::load(&from[6]));\n+    case 6:  AtomicAccess::store(&to[5], AtomicAccess::load(&from[5]));\n+    case 5:  AtomicAccess::store(&to[4], AtomicAccess::load(&from[4]));\n+    case 4:  AtomicAccess::store(&to[3], AtomicAccess::load(&from[3]));\n+    case 3:  AtomicAccess::store(&to[2], AtomicAccess::load(&from[2]));\n+    case 2:  AtomicAccess::store(&to[1], AtomicAccess::load(&from[1]));\n+    case 1:  AtomicAccess::store(&to[0], AtomicAccess::load(&from[0]));\n@@ -319,1 +319,1 @@\n-        Atomic::store(to++, Atomic::load(from++));\n+        AtomicAccess::store(to++, AtomicAccess::load(from++));\n","filename":"src\/hotspot\/share\/utilities\/copy.hpp","additions":11,"deletions":11,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -85,0 +85,1 @@\n+import jdk.internal.util.ModifiedUtf;\n@@ -481,0 +482,1 @@\n+        validateClassNameLength(className);\n@@ -563,0 +565,1 @@\n+        validateClassNameLength(name);\n@@ -612,0 +615,3 @@\n+        if (!ModifiedUtf.isValidLengthInConstantPool(name)) {\n+            return null;\n+        }\n@@ -4230,0 +4236,10 @@\n+\n+    \/\/ Validates the length of the class name and throws an exception if it exceeds the maximum allowed length.\n+    private static void validateClassNameLength(String name) throws ClassNotFoundException {\n+        if (!ModifiedUtf.isValidLengthInConstantPool(name)) {\n+            throw new ClassNotFoundException(\n+                    \"Class name length exceeds limit of \"\n+                    + ModifiedUtf.CONSTANT_POOL_UTF8_MAX_BYTES\n+                    + \": \" + name.substring(0,256) + \"...\");\n+        }\n+    }\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Class.java","additions":16,"deletions":0,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -1256,0 +1256,2 @@\n+     * In other words, {@linkplain ##repEquivalence representation\n+     * equivalence} is used to compare the {@code double} values.\n@@ -1469,0 +1471,6 @@\n+     * @apiNote\n+     * One idiom to implement {@linkplain ##repEquivalence\n+     * representation equivalence} on {@code double} values is\n+     * {@snippet lang=\"java\" :\n+     * Double.compare(a, b) == 0\n+     * }\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Double.java","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -885,0 +885,3 @@\n+     * In other words, {@linkplain Double##repEquivalence\n+     * representation equivalence} is used to compare the {@code\n+     * float} values.\n@@ -1290,0 +1293,8 @@\n+     * @apiNote\n+     * One idiom to implement {@linkplain\n+     * Double##repEquivalence representation equivalence} on {@code\n+     * float} values is\n+     * {@snippet lang=\"java\" :\n+     * Float.compare(a, b) == 0\n+     * }\n+     *\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Float.java","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -142,1 +142,6 @@\n-     * Apart from the semantics described above, the precise algorithm\n+     * Note that these rules imply that {@linkplain\n+     * Double##repEquivalence representation equivalence} is used for\n+     * the equality comparison of both primitive floating-point values\n+     * and wrapped floating-point values.\n+     *\n+     * <p>Apart from the semantics described above, the precise algorithm\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Record.java","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -193,1 +193,1 @@\n-    private final byte month;\n+    private final short month;\n@@ -197,1 +197,1 @@\n-    private final byte day;\n+    private final short day;\n@@ -501,2 +501,2 @@\n-        this.month = (byte) month;\n-        this.day = (byte) dayOfMonth;\n+        this.month = (short) month;\n+        this.day = (short) dayOfMonth;\n","filename":"src\/java.base\/share\/classes\/java\/time\/LocalDate.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -157,1 +157,1 @@\n-    private final byte month;\n+    private final int month;\n@@ -161,1 +161,1 @@\n-    private final byte day;\n+    private final int day;\n@@ -330,2 +330,2 @@\n-        this.month = (byte) month;\n-        this.day = (byte) dayOfMonth;\n+        this.month = month;\n+        this.day = dayOfMonth;\n","filename":"src\/java.base\/share\/classes\/java\/time\/MonthDay.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -164,1 +164,1 @@\n-    private final byte month;\n+    private final int month;\n@@ -317,1 +317,1 @@\n-        this.month = (byte) month;\n+        this.month = month;\n","filename":"src\/java.base\/share\/classes\/java\/time\/YearMonth.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2012, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2019, Oracle and\/or its affiliates. All rights reserved.\n@@ -148,1 +148,1 @@\n-    private final transient byte monthOfYear;\n+    private final transient int monthOfYear;\n@@ -152,1 +152,1 @@\n-    private final transient byte dayOfMonth;\n+    private final transient int dayOfMonth;\n@@ -284,2 +284,2 @@\n-        this.monthOfYear = (byte) monthOfYear;\n-        this.dayOfMonth = (byte) dayOfMonth;\n+        this.monthOfYear = monthOfYear;\n+        this.dayOfMonth = dayOfMonth;\n@@ -298,2 +298,2 @@\n-        this.monthOfYear = (byte) dateInfo[1];\n-        this.dayOfMonth = (byte) dateInfo[2];\n+        this.monthOfYear = dateInfo[1];\n+        this.dayOfMonth = dateInfo[2];\n","filename":"src\/java.base\/share\/classes\/java\/time\/chrono\/HijrahDate.java","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -239,1 +239,1 @@\n-                String.format(\"%s out of range of %d: %d\", fieldName, typeName, value));\n+                String.format(\"%s out of range of %s: %d\", fieldName, typeName, value));\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/classfile\/impl\/Util.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -29,1 +29,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n","filename":"test\/hotspot\/gtest\/oops\/test_markWord.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -557,11 +557,1 @@\n- -runtime\/cds\/appcds\/dynamicArchive\/LambdaContainsOldInf.java \\\n- -runtime\/cds\/appcds\/dynamicArchive\/LambdaCustomLoader.java \\\n- -runtime\/cds\/appcds\/dynamicArchive\/LambdaForOldInfInBaseArchive.java \\\n- -runtime\/cds\/appcds\/dynamicArchive\/LambdaInBaseArchive.java \\\n- -runtime\/cds\/appcds\/dynamicArchive\/LambdasInTwoArchives.java \\\n- -runtime\/cds\/appcds\/dynamicArchive\/ModulePath.java \\\n- -runtime\/cds\/appcds\/dynamicArchive\/NestHostOldInf.java \\\n- -runtime\/cds\/appcds\/dynamicArchive\/OldClassAndInf.java \\\n- -runtime\/cds\/appcds\/dynamicArchive\/OldClassInBaseArchive.java \\\n- -runtime\/cds\/appcds\/dynamicArchive\/OldClassVerifierTrouble.java \\\n- -runtime\/cds\/appcds\/dynamicArchive\/RedefineCallerClassTest.java \\\n+ -runtime\/cds\/appcds\/dynamicArchive \\\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":1,"deletions":11,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -955,3 +955,0 @@\n-        if (f.getDeclaringClass().equals(metaAccess.lookupJavaType(ConstantPool.class)) && f.getName().equals(\"constantPoolOop\")) {\n-            return true;\n-        }\n","filename":"test\/hotspot\/jtreg\/compiler\/jvmci\/jdk.vm.ci.runtime.test\/src\/jdk\/vm\/ci\/runtime\/test\/TestResolvedJavaType.java","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2355,0 +2355,5 @@\n+    public static final String VECTOR_MASK_CMP = PREFIX + \"VECTOR_MASK_CMP\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(VECTOR_MASK_CMP, \"VectorMaskCmp\");\n+    }\n+\n@@ -2765,0 +2770,5 @@\n+    public static final String XOR_V = PREFIX + \"XOR_V\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(XOR_V, \"XorV\");\n+    }\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/IRNode.java","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -67,1 +67,1 @@\n-        for (int i = 0; i < 200; i++) {\n+        for (int i = 0; i < 50; i++) {\n","filename":"test\/hotspot\/jtreg\/compiler\/startup\/StartupOutput.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -57,0 +57,1 @@\n+import java.lang.reflect.Array;\n@@ -1368,1 +1369,1 @@\n-            Class.forName(null);\n+            Array.get(null,0);\n","filename":"test\/hotspot\/jtreg\/runtime\/exceptionMsgs\/NullPointerException\/NullPointerExceptionTest.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -263,1 +263,0 @@\n-java\/awt\/Choice\/ChoiceMouseWheelTest\/ChoiceMouseWheelTest.java 8366852 generic-all\n@@ -457,1 +456,0 @@\n-java\/awt\/SplashScreen\/MultiResolutionSplash\/unix\/UnixMultiResolutionSplashTest.java 8203004 linux-all\n@@ -476,1 +474,1 @@\n-java\/awt\/PopupMenu\/PopupMenuLocation.java 8259913,8315878 windows-all,macosx-aarch64\n+java\/awt\/PopupMenu\/PopupMenuLocation.java 8259913 windows-all\n@@ -495,1 +493,0 @@\n-java\/awt\/Window\/GetScreenLocation\/GetScreenLocationTest.java 8225787 linux-x64\n@@ -800,1 +797,0 @@\n-javax\/swing\/JTabbedPane\/bug4666224.java 8144124  macosx-all\n@@ -825,1 +821,0 @@\n-java\/awt\/Focus\/AppletInitialFocusTest\/AppletInitialFocusTest1.java 8256289 windows-x64\n@@ -831,1 +826,0 @@\n-java\/awt\/Focus\/InactiveFocusRace.java 8023263 linux-all\n","filename":"test\/jdk\/ProblemList.txt","additions":1,"deletions":7,"binary":false,"changes":8,"status":"modified"}]}