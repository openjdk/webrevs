{"files":[{"patch":"@@ -55,1 +55,0 @@\n-    JAVAC_FLAGS := --enable-preview, \\\n@@ -63,1 +62,1 @@\n-    EXCLUDES := jdk\/test\/lib\/containers jdk\/test\/lib\/security, \\\n+    EXCLUDES := jdk\/test\/lib\/containers jdk\/test\/lib\/security org, \\\n@@ -67,1 +66,1 @@\n-    DISABLED_WARNINGS := try deprecation rawtypes unchecked serial cast removal preview dangling-doc-comments, \\\n+    DISABLED_WARNINGS := try deprecation rawtypes unchecked serial cast removal preview varargs dangling-doc-comments, \\\n@@ -73,0 +72,6 @@\n+        --add-exports jdk.compiler\/com.sun.tools.javac.api=ALL-UNNAMED \\\n+        --add-exports jdk.compiler\/com.sun.tools.javac.code=ALL-UNNAMED \\\n+        --add-exports jdk.compiler\/com.sun.tools.javac.comp=ALL-UNNAMED \\\n+        --add-exports jdk.compiler\/com.sun.tools.javac.main=ALL-UNNAMED \\\n+        --add-exports jdk.compiler\/com.sun.tools.javac.tree=ALL-UNNAMED \\\n+        --add-exports jdk.compiler\/com.sun.tools.javac.util=ALL-UNNAMED \\\n","filename":"make\/test\/BuildTestLib.gmk","additions":8,"deletions":3,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -1647,0 +1647,3 @@\n+  } else if (_entry_point == nullptr) {\n+    \/\/ See CallLeafNoFPIndirect\n+    return 1 * NativeInstruction::instruction_size;\n@@ -1755,3 +1758,0 @@\n-  \/\/ n.b. frame size includes space for return pc and rfp\n-  const int framesize = C->output()->frame_size_in_bytes();\n-\n@@ -1762,10 +1762,1 @@\n-  if (C->clinit_barrier_on_entry()) {\n-    assert(!C->method()->holder()->is_not_initialized(), \"initialization should have been started\");\n-\n-    Label L_skip_barrier;\n-\n-    __ mov_metadata(rscratch2, C->method()->holder()->constant_encoding());\n-    __ clinit_barrier(rscratch2, rscratch1, &L_skip_barrier);\n-    __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));\n-    __ bind(L_skip_barrier);\n-  }\n+  __ verified_entry(C, 0);\n@@ -1773,2 +1764,2 @@\n-  if (C->max_vector_size() > 0) {\n-    __ reinitialize_ptrue();\n+  if (C->stub_function() == nullptr) {\n+    __ entry_barrier();\n@@ -1777,27 +1768,2 @@\n-  int bangsize = C->output()->bang_size_in_bytes();\n-  if (C->output()->need_stack_bang(bangsize))\n-    __ generate_stack_overflow_check(bangsize);\n-\n-  __ build_frame(framesize);\n-\n-  if (C->stub_function() == nullptr) {\n-    BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-    if (BarrierSet::barrier_set()->barrier_set_nmethod() != nullptr) {\n-      \/\/ Dummy labels for just measuring the code size\n-      Label dummy_slow_path;\n-      Label dummy_continuation;\n-      Label dummy_guard;\n-      Label* slow_path = &dummy_slow_path;\n-      Label* continuation = &dummy_continuation;\n-      Label* guard = &dummy_guard;\n-      if (!Compile::current()->output()->in_scratch_emit_size()) {\n-        \/\/ Use real labels from actual stub when not emitting code for the purpose of measuring its size\n-        C2EntryBarrierStub* stub = new (Compile::current()->comp_arena()) C2EntryBarrierStub();\n-        Compile::current()->output()->add_stub(stub);\n-        slow_path = &stub->entry();\n-        continuation = &stub->continuation();\n-        guard = &stub->guard();\n-      }\n-      \/\/ In the C2 code, we move the non-hot part of nmethod entry barriers out-of-line to a stub.\n-      bs->nmethod_entry_barrier(masm, slow_path, continuation, guard);\n-    }\n+  if (!Compile::current()->output()->in_scratch_emit_size()) {\n+    __ bind(*_verified_entry);\n@@ -1820,6 +1786,0 @@\n-uint MachPrologNode::size(PhaseRegAlloc* ra_) const\n-{\n-  return MachNode::size(ra_); \/\/ too many variables; just compute it\n-                              \/\/ the hard way\n-}\n-\n@@ -1868,1 +1828,1 @@\n-  __ remove_frame(framesize);\n+  __ remove_frame(framesize, C->needs_stack_repair());\n@@ -1887,5 +1847,0 @@\n-uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {\n-  \/\/ Variable size. Determine dynamically.\n-  return MachNode::size(ra_);\n-}\n-\n@@ -2187,1 +2142,42 @@\n-\/\/=============================================================================\n+\/\/\/=============================================================================\n+#ifndef PRODUCT\n+void MachVEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const\n+{\n+  st->print_cr(\"# MachVEPNode\");\n+  if (!_verified) {\n+    st->print_cr(\"\\t load_class\");\n+  } else {\n+    st->print_cr(\"\\t unpack_inline_arg\");\n+  }\n+}\n+#endif\n+\n+void MachVEPNode::emit(C2_MacroAssembler *masm, PhaseRegAlloc* ra_) const\n+{\n+  if (!_verified) {\n+    __ ic_check(1);\n+  } else {\n+    \/\/ insert a nop at the start of the prolog so we can patch in a\n+    \/\/ branch if we need to invalidate the method later\n+    __ nop();\n+\n+    \/\/ TODO 8284443 Avoid creation of temporary frame\n+    if (ra_->C->stub_function() == nullptr) {\n+      __ verified_entry(ra_->C, 0);\n+      __ entry_barrier();\n+      int framesize = ra_->C->output()->frame_slots() << LogBytesPerInt;\n+      __ remove_frame(framesize, false);\n+    }\n+    \/\/ Unpack inline type args passed as oop and then jump to\n+    \/\/ the verified entry point (skipping the unverified entry).\n+    int sp_inc = __ unpack_inline_args(ra_->C, _receiver_only);\n+    \/\/ Emit code for verified entry and save increment for stack repair on return\n+    __ verified_entry(ra_->C, sp_inc);\n+    if (Compile::current()->output()->in_scratch_emit_size()) {\n+      Label dummy_verified_entry;\n+      __ b(dummy_verified_entry);\n+    } else {\n+      __ b(*_verified_entry);\n+    }\n+  }\n+}\n@@ -2189,0 +2185,1 @@\n+\/\/=============================================================================\n@@ -2211,5 +2208,0 @@\n-uint MachUEPNode::size(PhaseRegAlloc* ra_) const\n-{\n-  return MachNode::size(ra_);\n-}\n-\n@@ -3669,0 +3661,31 @@\n+    if (tf()->returns_inline_type_as_fields() && !_method->is_method_handle_intrinsic()) {\n+      \/\/ The last return value is not set by the callee but used to pass IsInit information to compiled code.\n+      \/\/ Search for the corresponding projection, get the register and emit code that initialized it.\n+      uint con = (tf()->range_cc()->cnt() - 1);\n+      for (DUIterator_Fast imax, i = fast_outs(imax); i < imax; i++) {\n+        ProjNode* proj = fast_out(i)->as_Proj();\n+        if (proj->_con == con) {\n+          \/\/ Set IsInit if r0 is non-null (a non-null value is returned buffered or scalarized)\n+          OptoReg::Name optoReg = ra_->get_reg_first(proj);\n+          VMReg reg = OptoReg::as_VMReg(optoReg, ra_->_framesize, OptoReg::reg2stack(ra_->_matcher._new_SP));\n+          Register toReg = reg->is_reg() ? reg->as_Register() : rscratch1;\n+          __ cmp(r0, zr);\n+          __ cset(toReg, Assembler::NE);\n+          if (reg->is_stack()) {\n+            int st_off = reg->reg2stack() * VMRegImpl::stack_slot_size;\n+            __ str(toReg, Address(sp, st_off));\n+          }\n+          break;\n+        }\n+      }\n+      if (return_value_is_used()) {\n+        \/\/ An inline type is returned as fields in multiple registers.\n+        \/\/ R0 either contains an oop if the inline type is buffered or a pointer\n+        \/\/ to the corresponding InlineKlass with the lowest bit set to 1. Zero r0\n+        \/\/ if the lowest bit is set to allow C2 to use the oop after null checking.\n+        \/\/ r0 &= (r0 & 1) - 1\n+        __ andr(rscratch1, r0, 0x1);\n+        __ sub(rscratch1, rscratch1, 0x1);\n+        __ andr(r0, r0, rscratch1);\n+      }\n+    }\n@@ -6676,1 +6699,1 @@\n-    \"mov  $dst, $con\\t# ptr\\n\\t\"\n+    \"mov  $dst, $con\\t# ptr\"\n@@ -7897,0 +7920,15 @@\n+instruct castN2X(iRegLNoSp dst, iRegN src) %{\n+  match(Set dst (CastP2X src));\n+\n+  ins_cost(INSN_COST);\n+  format %{ \"mov $dst, $src\\t# ptr -> long\" %}\n+\n+  ins_encode %{\n+    if ($dst$$reg != $src$$reg) {\n+      __ mov(as_Register($dst$$reg), as_Register($src$$reg));\n+    }\n+  %}\n+\n+  ins_pipe(ialu_reg);\n+%}\n+\n@@ -14718,1 +14756,1 @@\n-instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)\n+instruct clearArray_reg_reg_immL0(iRegL_R11 cnt, iRegP_R10 base, immL0 zero, Universe dummy, rFlagsReg cr)\n@@ -14720,1 +14758,1 @@\n-  match(Set dummy (ClearArray cnt base));\n+  match(Set dummy (ClearArray (Binary cnt base) zero));\n@@ -14737,0 +14775,16 @@\n+instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, iRegL val, Universe dummy, rFlagsReg cr)\n+%{\n+  predicate(((ClearArrayNode*)n)->word_copy_only());\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n+  effect(USE_KILL cnt, USE_KILL base, KILL cr);\n+\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ClearArray $cnt, $base, $val\" %}\n+\n+  ins_encode %{\n+    __ fill_words($base$$Register, $cnt$$Register, $val$$Register);\n+  %}\n+\n+  ins_pipe(pipe_class_memory);\n+%}\n+\n@@ -14740,1 +14794,2 @@\n-            < (uint64_t)(BlockZeroingLowLimit >> LogBytesPerWord));\n+            < (uint64_t)(BlockZeroingLowLimit >> LogBytesPerWord)\n+            && !((ClearArrayNode*)n)->word_copy_only());\n@@ -16071,0 +16126,18 @@\n+\/\/ entry point is null, target holds the address to call\n+instruct CallLeafNoFPIndirect(iRegP target)\n+%{\n+  predicate(n->as_Call()->entry_point() == nullptr);\n+\n+  match(CallLeafNoFP target);\n+\n+  ins_cost(CALL_COST);\n+\n+  format %{ \"CALL, runtime leaf nofp indirect $target\" %}\n+\n+  ins_encode %{\n+    __ blr($target$$Register);\n+  %}\n+\n+  ins_pipe(pipe_class_call);\n+%}\n+\n@@ -16073,0 +16146,2 @@\n+  predicate(n->as_Call()->entry_point() != nullptr);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":139,"deletions":64,"binary":false,"changes":203,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"gc\/shared\/barrierSetRuntime.hpp\"\n@@ -53,0 +54,1 @@\n+\n@@ -90,0 +92,2 @@\n+  bool is_not_null = (decorators & IS_NOT_NULL) != 0;\n+\n@@ -93,5 +97,6 @@\n-    val = val == noreg ? zr : val;\n-      if (UseCompressedOops) {\n-        assert(!dst.uses(val), \"not enough registers\");\n-        if (val != zr) {\n-          __ encode_heap_oop(val);\n+      if (val == noreg) {\n+        assert(!is_not_null, \"inconsistent access\");\n+        if (UseCompressedOops) {\n+          __ strw(zr, dst);\n+        } else {\n+          __ str(zr, dst);\n@@ -100,2 +105,11 @@\n-        __ strw(val, dst);\n-        __ str(val, dst);\n+        if (UseCompressedOops) {\n+          assert(!dst.uses(val), \"not enough registers\");\n+          if (is_not_null) {\n+            __ encode_heap_oop_not_null(val);\n+          } else {\n+            __ encode_heap_oop(val);\n+          }\n+          __ strw(val, dst);\n+        } else {\n+          __ str(val, dst);\n+        }\n@@ -106,0 +120,1 @@\n+      assert(val != noreg, \"not supported\");\n@@ -126,0 +141,13 @@\n+void BarrierSetAssembler::value_copy(MacroAssembler* masm, DecoratorSet decorators,\n+                                     Register src, Register dst, Register value_klass) {\n+  \/\/ value_copy implementation is fairly complex, and there are not any\n+  \/\/ \"short-cuts\" to be made from asm. What there is, appears to have the same\n+  \/\/ cost in C++, so just \"call_VM_leaf\" for now rather than maintain hundreds\n+  \/\/ of hand-rolled instructions...\n+  if (decorators & IS_DEST_UNINITIALIZED) {\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, BarrierSetRuntime::value_copy_is_dest_uninitialized), src, dst, value_klass);\n+  } else {\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, BarrierSetRuntime::value_copy), src, dst, value_klass);\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.cpp","additions":35,"deletions":7,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -108,0 +108,3 @@\n+  virtual void value_copy(MacroAssembler* masm, DecoratorSet decorators,\n+                          Register src, Register dst, Register value_klass);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"oops\/constMethodFlags.hpp\"\n@@ -39,0 +40,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -212,0 +214,63 @@\n+void InterpreterMacroAssembler::allocate_instance(Register klass, Register new_obj,\n+                                                  Register t1, Register t2,\n+                                                  bool clear_fields, Label& alloc_failed) {\n+  MacroAssembler::allocate_instance(klass, new_obj, t1, t2, clear_fields, alloc_failed);\n+  {\n+    SkipIfEqual skip_if(this, &DTraceAllocProbes, 0);\n+    \/\/ Trigger dtrace event for fastpath\n+    push(atos);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, static_cast<int (*)(oopDesc*)>(SharedRuntime::dtrace_object_alloc)), new_obj);\n+    pop(atos);\n+  }\n+}\n+\n+void InterpreterMacroAssembler::read_flat_field(Register holder_klass,\n+                                                Register field_index, Register field_offset,\n+                                                Register temp, Register obj) {\n+  Label alloc_failed, empty_value, done;\n+  const Register src = field_offset;\n+  const Register alloc_temp = rscratch1;\n+  const Register dst_temp   = temp;\n+  assert_different_registers(obj, holder_klass, field_index, field_offset, dst_temp);\n+\n+  \/\/ Grab the inline field klass\n+  push(holder_klass);\n+  const Register field_klass = holder_klass;\n+  get_inline_type_field_klass(holder_klass, field_index, field_klass);\n+\n+  \/\/check for empty value klass\n+  test_klass_is_empty_inline_type(field_klass, dst_temp, empty_value);\n+\n+  \/\/ allocate buffer\n+  push(obj); \/\/ save holder\n+  allocate_instance(field_klass, obj, alloc_temp, dst_temp, false, alloc_failed);\n+\n+  \/\/ Have an oop instance buffer, copy into it\n+  data_for_oop(obj, dst_temp, field_klass);\n+  pop(alloc_temp);             \/\/ restore holder\n+  lea(src, Address(alloc_temp, field_offset));\n+  \/\/ call_VM_leaf, clobbers a few regs, save restore new obj\n+  push(obj);\n+  access_value_copy(IS_DEST_UNINITIALIZED, src, dst_temp, field_klass);\n+  pop(obj);\n+  pop(holder_klass);\n+  b(done);\n+\n+  bind(empty_value);\n+  get_empty_inline_type_oop(field_klass, dst_temp, obj);\n+  pop(holder_klass);\n+  b(done);\n+\n+  bind(alloc_failed);\n+  pop(obj);\n+  pop(holder_klass);\n+  call_VM(obj, CAST_FROM_FN_PTR(address, InterpreterRuntime::read_flat_field),\n+          obj, field_index, holder_klass);\n+\n+  bind(done);\n+\n+  \/\/ Ensure the stores to copy the inline field contents are visible\n+  \/\/ before any subsequent store that publishes this reference.\n+  membar(Assembler::StoreStore);\n+}\n+\n@@ -246,1 +311,2 @@\n-                                                  Label& ok_is_subtype) {\n+                                                  Label& ok_is_subtype,\n+                                                  bool profile) {\n@@ -252,1 +318,3 @@\n-  profile_typecheck(r2, Rsub_klass, r5); \/\/ blows r2, reloads r5\n+  if (profile) {\n+    profile_typecheck(r2, Rsub_klass, r5); \/\/ blows r2, reloads r5\n+  }\n@@ -620,0 +688,1 @@\n+\n@@ -645,0 +714,31 @@\n+  if (state == atos && InlineTypeReturnedAsFields) {\n+    \/\/ Check if we are returning an non-null inline type and load its fields into registers\n+    Label skip;\n+    test_oop_is_not_inline_type(r0, rscratch2, skip);\n+\n+    \/\/ Load fields from a buffered value with an inline class specific handler\n+    load_klass(rscratch1 \/*dst*\/, r0 \/*src*\/);\n+    ldr(rscratch1, Address(rscratch1, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+    ldr(rscratch1, Address(rscratch1, InlineKlass::unpack_handler_offset()));\n+    \/\/ Unpack handler can be null if inline type is not scalarizable in returns\n+    cbz(rscratch1, skip);\n+\n+    blr(rscratch1);\n+#ifdef ASSERT\n+    \/\/ TODO 8284443 Enable\n+    if (StressCallingConvention && false) {\n+      Label skip_stress;\n+      ldr(rscratch1, Address(rfp, frame::interpreter_frame_method_offset * wordSize));\n+      ldrw(rscratch1, Address(rscratch1, Method::flags_offset()));\n+      tstw(rscratch1, MethodFlags::has_scalarized_return_flag());\n+      br(Assembler::EQ, skip_stress);\n+      load_klass(r0, r0);\n+      orr(r0, r0, 1);\n+      bind(skip_stress);\n+    }\n+#endif\n+    bind(skip);\n+    \/\/ Check above kills sender esp in rscratch2. Reload it.\n+    ldr(rscratch2, Address(rfp, frame::interpreter_frame_sender_sp_offset * wordSize));\n+  }\n+\n@@ -705,0 +805,4 @@\n+      if (EnableValhalla) {\n+        \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n+        andr(swap_reg, swap_reg, ~((int) markWord::inline_type_bit_in_place));\n+      }\n@@ -1064,1 +1168,1 @@\n-void InterpreterMacroAssembler::profile_not_taken_branch(Register mdp) {\n+void InterpreterMacroAssembler::profile_not_taken_branch(Register mdp, bool acmp) {\n@@ -1076,1 +1180,1 @@\n-    update_mdp_by_constant(mdp, in_bytes(BranchData::branch_data_size()));\n+    update_mdp_by_constant(mdp, acmp ? in_bytes(ACmpData::acmp_data_size()) : in_bytes(BranchData::branch_data_size()));\n@@ -1399,0 +1503,114 @@\n+template <class ArrayData> void InterpreterMacroAssembler::profile_array_type(Register mdp,\n+                                                                              Register array,\n+                                                                              Register tmp) {\n+  if (ProfileInterpreter) {\n+    Label profile_continue;\n+\n+    \/\/ If no method data exists, go to profile_continue.\n+    test_method_data_pointer(mdp, profile_continue);\n+\n+    mov(tmp, array);\n+    profile_obj_type(tmp, Address(mdp, in_bytes(ArrayData::array_offset())));\n+\n+    Label not_flat;\n+    test_non_flat_array_oop(array, tmp, not_flat);\n+\n+    set_mdp_flag_at(mdp, ArrayData::flat_array_byte_constant());\n+\n+    bind(not_flat);\n+\n+    Label not_null_free;\n+    test_non_null_free_array_oop(array, tmp, not_null_free);\n+\n+    set_mdp_flag_at(mdp, ArrayData::null_free_array_byte_constant());\n+\n+    bind(not_null_free);\n+\n+    bind(profile_continue);\n+  }\n+}\n+\n+template void InterpreterMacroAssembler::profile_array_type<ArrayLoadData>(Register mdp,\n+                                                                           Register array,\n+                                                                           Register tmp);\n+template void InterpreterMacroAssembler::profile_array_type<ArrayStoreData>(Register mdp,\n+                                                                            Register array,\n+                                                                            Register tmp);\n+\n+void InterpreterMacroAssembler::profile_multiple_element_types(Register mdp, Register element, Register tmp, const Register tmp2) {\n+  if (ProfileInterpreter) {\n+    Label profile_continue;\n+\n+    \/\/ If no method data exists, go to profile_continue.\n+    test_method_data_pointer(mdp, profile_continue);\n+\n+    Label done, update;\n+    cbnz(element, update);\n+    set_mdp_flag_at(mdp, BitData::null_seen_byte_constant());\n+    b(done);\n+\n+    bind(update);\n+    load_klass(tmp, element);\n+\n+    \/\/ Record the object type.\n+    record_klass_in_profile(tmp, mdp, tmp2);\n+\n+    bind(done);\n+\n+    \/\/ The method data pointer needs to be updated.\n+    update_mdp_by_constant(mdp, in_bytes(ArrayStoreData::array_store_data_size()));\n+\n+    bind(profile_continue);\n+  }\n+}\n+\n+\n+void InterpreterMacroAssembler::profile_element_type(Register mdp,\n+                                                     Register element,\n+                                                     Register tmp) {\n+  if (ProfileInterpreter) {\n+    Label profile_continue;\n+\n+    \/\/ If no method data exists, go to profile_continue.\n+    test_method_data_pointer(mdp, profile_continue);\n+\n+    mov(tmp, element);\n+    profile_obj_type(tmp, Address(mdp, in_bytes(ArrayLoadData::element_offset())));\n+\n+    \/\/ The method data pointer needs to be updated.\n+    update_mdp_by_constant(mdp, in_bytes(ArrayLoadData::array_load_data_size()));\n+\n+    bind(profile_continue);\n+  }\n+}\n+\n+void InterpreterMacroAssembler::profile_acmp(Register mdp,\n+                                             Register left,\n+                                             Register right,\n+                                             Register tmp) {\n+  if (ProfileInterpreter) {\n+    Label profile_continue;\n+\n+    \/\/ If no method data exists, go to profile_continue.\n+    test_method_data_pointer(mdp, profile_continue);\n+\n+    mov(tmp, left);\n+    profile_obj_type(tmp, Address(mdp, in_bytes(ACmpData::left_offset())));\n+\n+    Label left_not_inline_type;\n+    test_oop_is_not_inline_type(left, tmp, left_not_inline_type);\n+    set_mdp_flag_at(mdp, ACmpData::left_inline_type_byte_constant());\n+    bind(left_not_inline_type);\n+\n+    mov(tmp, right);\n+    profile_obj_type(tmp, Address(mdp, in_bytes(ACmpData::right_offset())));\n+\n+    Label right_not_inline_type;\n+    test_oop_is_not_inline_type(right, tmp, right_not_inline_type);\n+    set_mdp_flag_at(mdp, ACmpData::right_inline_type_byte_constant());\n+    bind(right_not_inline_type);\n+\n+    bind(profile_continue);\n+  }\n+}\n+\n@@ -1653,1 +1871,1 @@\n-        assert(ReturnTypeEntry::static_cell_count() < TypeStackSlotEntries::per_arg_count(), \"can't move past ret type\");\n+        assert(SingleTypeEntry::static_cell_count() < TypeStackSlotEntries::per_arg_count(), \"can't move past ret type\");\n@@ -1699,1 +1917,1 @@\n-    Address mdo_ret_addr(mdp, -in_bytes(ReturnTypeEntry::size()));\n+    Address mdo_ret_addr(mdp, -in_bytes(SingleTypeEntry::size()));\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":224,"deletions":6,"binary":false,"changes":230,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -50,0 +51,1 @@\n+#include \"oops\/resolvedFieldEntry.hpp\"\n@@ -56,0 +58,1 @@\n+#include \"runtime\/signature_cc.hpp\"\n@@ -59,0 +62,1 @@\n+#include \"vmreg_aarch64.inline.hpp\"\n@@ -1174,0 +1178,35 @@\n+void MacroAssembler::get_default_value_oop(Register inline_klass, Register temp_reg, Register obj) {\n+#ifdef ASSERT\n+  {\n+    Label done_check;\n+    test_klass_is_inline_type(inline_klass, temp_reg, done_check);\n+    stop(\"get_default_value_oop from non inline type klass\");\n+    bind(done_check);\n+  }\n+#endif\n+  Register offset = temp_reg;\n+  \/\/ Getting the offset of the pre-allocated default value\n+  ldr(offset, Address(inline_klass, in_bytes(InstanceKlass::adr_inlineklass_fixed_block_offset())));\n+  ldr(offset, Address(offset, in_bytes(InlineKlass::default_value_offset_offset())));\n+\n+  \/\/ Getting the mirror\n+  ldr(obj, Address(inline_klass, in_bytes(Klass::java_mirror_offset())));\n+  resolve_oop_handle(obj, inline_klass, temp_reg);\n+\n+  \/\/ Getting the pre-allocated default value from the mirror\n+  Address field(obj, offset);\n+  load_heap_oop(obj, field, inline_klass, rscratch2);\n+}\n+\n+void MacroAssembler::get_empty_inline_type_oop(Register inline_klass, Register temp_reg, Register obj) {\n+#ifdef ASSERT\n+  {\n+    Label done_check;\n+    test_klass_is_empty_inline_type(inline_klass, temp_reg, done_check);\n+    stop(\"get_empty_value from non-empty inline klass\");\n+    bind(done_check);\n+  }\n+#endif\n+  get_default_value_oop(inline_klass, temp_reg, obj);\n+}\n+\n@@ -1861,1 +1900,5 @@\n-  if (!VerifyOops) return;\n+  if (!VerifyOops || VerifyAdapterSharing) {\n+    \/\/ Below address of the code string confuses VerifyAdapterSharing\n+    \/\/ because it may differ between otherwise equivalent adapters.\n+    return;\n+  }\n@@ -1894,1 +1937,5 @@\n-  if (!VerifyOops) return;\n+  if (!VerifyOops || VerifyAdapterSharing) {\n+    \/\/ Below address of the code string confuses VerifyAdapterSharing\n+    \/\/ because it may differ between otherwise equivalent adapters.\n+    return;\n+  }\n@@ -1992,0 +2039,4 @@\n+void MacroAssembler::super_call_VM_leaf(address entry_point) {\n+  MacroAssembler::call_VM_leaf_base(entry_point, 1);\n+}\n+\n@@ -2037,0 +2088,105 @@\n+void MacroAssembler::test_markword_is_inline_type(Register markword, Label& is_inline_type) {\n+  assert_different_registers(markword, rscratch2);\n+  andr(markword, markword, markWord::inline_type_mask_in_place);\n+  mov(rscratch2, markWord::inline_type_pattern);\n+  cmp(markword, rscratch2);\n+  br(Assembler::EQ, is_inline_type);\n+}\n+\n+void MacroAssembler::test_klass_is_inline_type(Register klass, Register temp_reg, Label& is_inline_type) {\n+  ldrw(temp_reg, Address(klass, Klass::access_flags_offset()));\n+  andr(temp_reg, temp_reg, JVM_ACC_IDENTITY);\n+  cbz(temp_reg, is_inline_type);\n+}\n+\n+void MacroAssembler::test_oop_is_not_inline_type(Register object, Register tmp, Label& not_inline_type) {\n+  assert_different_registers(tmp, rscratch1);\n+  cbz(object, not_inline_type);\n+  const int is_inline_type_mask = markWord::inline_type_pattern;\n+  ldr(tmp, Address(object, oopDesc::mark_offset_in_bytes()));\n+  mov(rscratch1, is_inline_type_mask);\n+  andr(tmp, tmp, rscratch1);\n+  cmp(tmp, rscratch1);\n+  br(Assembler::NE, not_inline_type);\n+}\n+\n+void MacroAssembler::test_klass_is_empty_inline_type(Register klass, Register temp_reg, Label& is_empty_inline_type) {\n+#ifdef ASSERT\n+  {\n+    Label done_check;\n+    test_klass_is_inline_type(klass, temp_reg, done_check);\n+    stop(\"test_klass_is_empty_inline_type with non inline type klass\");\n+    bind(done_check);\n+  }\n+#endif\n+  ldrw(temp_reg, Address(klass, InstanceKlass::misc_flags_offset()));\n+  andr(temp_reg, temp_reg, InstanceKlassFlags::is_empty_inline_type_value());\n+  cbnz(temp_reg, is_empty_inline_type);\n+}\n+\n+void MacroAssembler::test_field_is_null_free_inline_type(Register flags, Register temp_reg, Label& is_null_free_inline_type) {\n+  assert(temp_reg == noreg, \"not needed\"); \/\/ keep signature uniform with x86\n+  tbnz(flags, ResolvedFieldEntry::is_null_free_inline_type_shift, is_null_free_inline_type);\n+}\n+\n+void MacroAssembler::test_field_is_not_null_free_inline_type(Register flags, Register temp_reg, Label& not_null_free_inline_type) {\n+  assert(temp_reg == noreg, \"not needed\"); \/\/ keep signature uniform with x86\n+  tbz(flags, ResolvedFieldEntry::is_null_free_inline_type_shift, not_null_free_inline_type);\n+}\n+\n+void MacroAssembler::test_field_is_flat(Register flags, Register temp_reg, Label& is_flat) {\n+  assert(temp_reg == noreg, \"not needed\"); \/\/ keep signature uniform with x86\n+  tbnz(flags, ResolvedFieldEntry::is_flat_shift, is_flat);\n+}\n+\n+void MacroAssembler::test_field_has_null_marker(Register flags, Register temp_reg, Label& has_null_marker) {\n+  assert(temp_reg == noreg, \"not needed\"); \/\/ keep signature uniform with x86\n+  tbnz(flags, ResolvedFieldEntry::has_null_marker_shift, has_null_marker);\n+}\n+\n+void MacroAssembler::test_oop_prototype_bit(Register oop, Register temp_reg, int32_t test_bit, bool jmp_set, Label& jmp_label) {\n+  Label test_mark_word;\n+  \/\/ load mark word\n+  ldr(temp_reg, Address(oop, oopDesc::mark_offset_in_bytes()));\n+  \/\/ check displaced\n+  tst(temp_reg, markWord::unlocked_value);\n+  br(Assembler::NE, test_mark_word);\n+  \/\/ slow path use klass prototype\n+  load_prototype_header(temp_reg, oop);\n+\n+  bind(test_mark_word);\n+  andr(temp_reg, temp_reg, test_bit);\n+  if (jmp_set) {\n+    cbnz(temp_reg, jmp_label);\n+  } else {\n+    cbz(temp_reg, jmp_label);\n+  }\n+}\n+\n+void MacroAssembler::test_flat_array_oop(Register oop, Register temp_reg, Label& is_flat_array) {\n+  test_oop_prototype_bit(oop, temp_reg, markWord::flat_array_bit_in_place, true, is_flat_array);\n+}\n+\n+void MacroAssembler::test_non_flat_array_oop(Register oop, Register temp_reg,\n+                                                  Label&is_non_flat_array) {\n+  test_oop_prototype_bit(oop, temp_reg, markWord::flat_array_bit_in_place, false, is_non_flat_array);\n+}\n+\n+void MacroAssembler::test_null_free_array_oop(Register oop, Register temp_reg, Label& is_null_free_array) {\n+  test_oop_prototype_bit(oop, temp_reg, markWord::null_free_array_bit_in_place, true, is_null_free_array);\n+}\n+\n+void MacroAssembler::test_non_null_free_array_oop(Register oop, Register temp_reg, Label&is_non_null_free_array) {\n+  test_oop_prototype_bit(oop, temp_reg, markWord::null_free_array_bit_in_place, false, is_non_null_free_array);\n+}\n+\n+void MacroAssembler::test_flat_array_layout(Register lh, Label& is_flat_array) {\n+  tst(lh, Klass::_lh_array_tag_flat_value_bit_inplace);\n+  br(Assembler::NE, is_flat_array);\n+}\n+\n+void MacroAssembler::test_non_flat_array_layout(Register lh, Label& is_non_flat_array) {\n+  tst(lh, Klass::_lh_array_tag_flat_value_bit_inplace);\n+  br(Assembler::EQ, is_non_flat_array);\n+}\n+\n@@ -4819,0 +4975,8 @@\n+void MacroAssembler::load_metadata(Register dst, Register src) {\n+  if (UseCompressedClassPointers) {\n+    ldrw(dst, Address(src, oopDesc::klass_offset_in_bytes()));\n+  } else {\n+    ldr(dst, Address(src, oopDesc::klass_offset_in_bytes()));\n+  }\n+}\n+\n@@ -4894,0 +5058,5 @@\n+void MacroAssembler::load_prototype_header(Register dst, Register src) {\n+  load_klass(dst, src);\n+  ldr(dst, Address(dst, Klass::prototype_header_offset()));\n+}\n+\n@@ -5218,0 +5387,40 @@\n+void MacroAssembler::access_value_copy(DecoratorSet decorators, Register src, Register dst,\n+                                       Register inline_klass) {\n+  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+  bs->value_copy(this, decorators, src, dst, inline_klass);\n+}\n+\n+void MacroAssembler::first_field_offset(Register inline_klass, Register offset) {\n+  ldr(offset, Address(inline_klass, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+  ldrw(offset, Address(offset, InlineKlass::first_field_offset_offset()));\n+}\n+\n+void MacroAssembler::data_for_oop(Register oop, Register data, Register inline_klass) {\n+  \/\/ ((address) (void*) o) + vk->first_field_offset();\n+  Register offset = (data == oop) ? rscratch1 : data;\n+  first_field_offset(inline_klass, offset);\n+  if (data == oop) {\n+    add(data, data, offset);\n+  } else {\n+    lea(data, Address(oop, offset));\n+  }\n+}\n+\n+void MacroAssembler::data_for_value_array_index(Register array, Register array_klass,\n+                                                Register index, Register data) {\n+  assert_different_registers(array, array_klass, index);\n+  assert_different_registers(rscratch1, array, index);\n+\n+  \/\/ array->base() + (index << Klass::layout_helper_log2_element_size(lh));\n+  ldrw(rscratch1, Address(array_klass, Klass::layout_helper_offset()));\n+\n+  \/\/ Klass::layout_helper_log2_element_size(lh)\n+  \/\/ (lh >> _lh_log2_element_size_shift) & _lh_log2_element_size_mask;\n+  lsr(rscratch1, rscratch1, Klass::_lh_log2_element_size_shift);\n+  andr(rscratch1, rscratch1, Klass::_lh_log2_element_size_mask);\n+  lslv(index, index, rscratch1);\n+\n+  add(data, array, index);\n+  add(data, data, arrayOopDesc::base_offset_in_bytes(T_PRIMITIVE_OBJECT));\n+}\n+\n@@ -5294,0 +5503,96 @@\n+\/\/ Object \/ value buffer allocation...\n+void MacroAssembler::allocate_instance(Register klass, Register new_obj,\n+                                       Register t1, Register t2,\n+                                       bool clear_fields, Label& alloc_failed)\n+{\n+  Label done, initialize_header, initialize_object, slow_case, slow_case_no_pop;\n+  Register layout_size = t1;\n+  assert(new_obj == r0, \"needs to be r0\");\n+  assert_different_registers(klass, new_obj, t1, t2);\n+\n+  \/\/ get instance_size in InstanceKlass (scaled to a count of bytes)\n+  ldrw(layout_size, Address(klass, Klass::layout_helper_offset()));\n+  \/\/ test to see if it is malformed in some way\n+  tst(layout_size, Klass::_lh_instance_slow_path_bit);\n+  br(Assembler::NE, slow_case_no_pop);\n+\n+  \/\/ Allocate the instance:\n+  \/\/  If TLAB is enabled:\n+  \/\/    Try to allocate in the TLAB.\n+  \/\/    If fails, go to the slow path.\n+  \/\/    Initialize the allocation.\n+  \/\/    Exit.\n+  \/\/\n+  \/\/  Go to slow path.\n+\n+  if (UseTLAB) {\n+    push(klass);\n+    tlab_allocate(new_obj, layout_size, 0, klass, t2, slow_case);\n+    if (ZeroTLAB || (!clear_fields)) {\n+      \/\/ the fields have been already cleared\n+      b(initialize_header);\n+    } else {\n+      \/\/ initialize both the header and fields\n+      b(initialize_object);\n+    }\n+\n+    if (clear_fields) {\n+      \/\/ The object is initialized before the header.  If the object size is\n+      \/\/ zero, go directly to the header initialization.\n+      bind(initialize_object);\n+      subs(layout_size, layout_size, sizeof(oopDesc));\n+      br(Assembler::EQ, initialize_header);\n+\n+      \/\/ Initialize topmost object field, divide size by 8, check if odd and\n+      \/\/ test if zero.\n+\n+  #ifdef ASSERT\n+      \/\/ make sure instance_size was multiple of 8\n+      Label L;\n+      tst(layout_size, 7);\n+      br(Assembler::EQ, L);\n+      stop(\"object size is not multiple of 8 - adjust this code\");\n+      bind(L);\n+      \/\/ must be > 0, no extra check needed here\n+  #endif\n+\n+      lsr(layout_size, layout_size, LogBytesPerLong);\n+\n+      \/\/ initialize remaining object fields: instance_size was a multiple of 8\n+      {\n+        Label loop;\n+        Register base = t2;\n+\n+        bind(loop);\n+        add(rscratch1, new_obj, layout_size, Assembler::LSL, LogBytesPerLong);\n+        str(zr, Address(rscratch1, sizeof(oopDesc) - 1*oopSize));\n+        subs(layout_size, layout_size, 1);\n+        br(Assembler::NE, loop);\n+      }\n+    } \/\/ clear_fields\n+\n+    \/\/ initialize object header only.\n+    bind(initialize_header);\n+    pop(klass);\n+    Register mark_word = t2;\n+    ldr(mark_word, Address(klass, Klass::prototype_header_offset()));\n+    str(mark_word, Address(new_obj, oopDesc::mark_offset_in_bytes ()));\n+    store_klass_gap(new_obj, zr);  \/\/ zero klass gap for compressed oops\n+    mov(t2, klass);         \/\/ preserve klass\n+    store_klass(new_obj, t2);  \/\/ src klass reg is potentially compressed\n+\n+    \/\/ TODO: Valhalla removed SharedRuntime::dtrace_object_alloc from here ?\n+\n+    b(done);\n+  }\n+\n+  if (UseTLAB) {\n+    bind(slow_case);\n+    pop(klass);\n+  }\n+  bind(slow_case_no_pop);\n+  b(alloc_failed);\n+\n+  bind(done);\n+}\n+\n@@ -5333,0 +5638,14 @@\n+void MacroAssembler::get_inline_type_field_klass(Register klass, Register index, Register inline_klass) {\n+  ldr(inline_klass, Address(klass, InstanceKlass::inline_type_field_klasses_offset()));\n+#ifdef ASSERT\n+  {\n+    Label done;\n+    cbnz(inline_klass, done);\n+    stop(\"get_inline_type_field_klass contains no inline klass\");\n+    bind(done);\n+  }\n+#endif\n+  lea(inline_klass, Address(inline_klass, Array<InlineKlass*>::base_offset_in_bytes()));\n+  ldr(inline_klass, Address(inline_klass, index, Address::lsl(3)));\n+}\n+\n@@ -5458,0 +5777,51 @@\n+void MacroAssembler::remove_frame(int initial_framesize, bool needs_stack_repair) {\n+  if (needs_stack_repair) {\n+    \/\/ Remove the extension of the caller's frame used for inline type unpacking\n+    \/\/\n+    \/\/ Right now the stack looks like this:\n+    \/\/\n+    \/\/ | Arguments from caller     |\n+    \/\/ |---------------------------|  <-- caller's SP\n+    \/\/ | Saved LR #1               |\n+    \/\/ | Saved FP #1               |\n+    \/\/ |---------------------------|\n+    \/\/ | Extension space for       |\n+    \/\/ |   inline arg (un)packing  |\n+    \/\/ |---------------------------|  <-- start of this method's frame\n+    \/\/ | Saved LR #2               |\n+    \/\/ | Saved FP #2               |\n+    \/\/ |---------------------------|  <-- FP\n+    \/\/ | sp_inc                    |\n+    \/\/ | method locals             |\n+    \/\/ |---------------------------|  <-- SP\n+    \/\/\n+    \/\/ There are two copies of FP and LR on the stack. They will be identical\n+    \/\/ unless the caller has been deoptimized, in which case LR #1 will be patched\n+    \/\/ to point at the deopt blob, and LR #2 will still point into the old method.\n+    \/\/\n+    \/\/ The sp_inc stack slot holds the total size of the frame including the\n+    \/\/ extension space minus two words for the saved FP and LR.\n+\n+    int sp_inc_offset = initial_framesize - 3 * wordSize;  \/\/ Immediately below saved LR and FP\n+\n+    ldr(rscratch1, Address(sp, sp_inc_offset));\n+    add(sp, sp, rscratch1);\n+    ldp(rfp, lr, Address(post(sp, 2 * wordSize)));\n+  } else {\n+    remove_frame(initial_framesize);\n+  }\n+}\n+\n+void MacroAssembler::save_stack_increment(int sp_inc, int frame_size) {\n+  int real_frame_size = frame_size + sp_inc;\n+  assert(sp_inc == 0 || sp_inc > 2*wordSize, \"invalid sp_inc value\");\n+  assert(real_frame_size >= 2*wordSize, \"frame size must include FP\/LR space\");\n+  assert((real_frame_size & (StackAlignmentInBytes-1)) == 0, \"frame size not aligned\");\n+\n+  int sp_inc_offset = frame_size - 3 * wordSize;  \/\/ Immediately below saved LR and FP\n+\n+  \/\/ Subtract two words for the saved FP and LR as these will be popped\n+  \/\/ separately. See remove_frame above.\n+  mov(rscratch1, real_frame_size - 2*wordSize);\n+  str(rscratch1, Address(sp, sp_inc_offset));\n+}\n@@ -6367,0 +6737,443 @@\n+#ifdef COMPILER2\n+\/\/ C2 compiled method's prolog code\n+\/\/ Moved here from aarch64.ad to support Valhalla code belows\n+void MacroAssembler::verified_entry(Compile* C, int sp_inc) {\n+  if (C->clinit_barrier_on_entry()) {\n+    assert(!C->method()->holder()->is_not_initialized(), \"initialization should have been started\");\n+\n+    Label L_skip_barrier;\n+\n+    mov_metadata(rscratch2, C->method()->holder()->constant_encoding());\n+    clinit_barrier(rscratch2, rscratch1, &L_skip_barrier);\n+    far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));\n+    bind(L_skip_barrier);\n+  }\n+\n+  if (C->max_vector_size() > 0) {\n+    reinitialize_ptrue();\n+  }\n+\n+  int bangsize = C->output()->bang_size_in_bytes();\n+  if (C->output()->need_stack_bang(bangsize))\n+    generate_stack_overflow_check(bangsize);\n+\n+  \/\/ n.b. frame size includes space for return pc and rfp\n+  const long framesize = C->output()->frame_size_in_bytes();\n+  build_frame(framesize);\n+\n+  if (C->needs_stack_repair()) {\n+    save_stack_increment(sp_inc, framesize);\n+  }\n+\n+  if (VerifyStackAtCalls) {\n+    Unimplemented();\n+  }\n+}\n+#endif \/\/ COMPILER2\n+\n+int MacroAssembler::store_inline_type_fields_to_buf(ciInlineKlass* vk, bool from_interpreter) {\n+  assert(InlineTypeReturnedAsFields, \"Inline types should never be returned as fields\");\n+  \/\/ An inline type might be returned. If fields are in registers we\n+  \/\/ need to allocate an inline type instance and initialize it with\n+  \/\/ the value of the fields.\n+  Label skip;\n+  \/\/ We only need a new buffered inline type if a new one is not returned\n+  tbz(r0, 0, skip);\n+  int call_offset = -1;\n+\n+  \/\/ Be careful not to clobber r1-7 which hold returned fields\n+  \/\/ Also do not use callee-saved registers as these may be live in the interpreter\n+  Register tmp1 = r13, tmp2 = r14, klass = r15, r0_preserved = r12;\n+\n+  \/\/ The following code is similar to allocate_instance but has some slight differences,\n+  \/\/ e.g. object size is always not zero, sometimes it's constant; storing klass ptr after\n+  \/\/ allocating is not necessary if vk != nullptr, etc. allocate_instance is not aware of these.\n+  Label slow_case;\n+  \/\/ 1. Try to allocate a new buffered inline instance either from TLAB or eden space\n+  mov(r0_preserved, r0); \/\/ save r0 for slow_case since *_allocate may corrupt it when allocation failed\n+\n+  if (vk != nullptr) {\n+    \/\/ Called from C1, where the return type is statically known.\n+    movptr(klass, (intptr_t)vk->get_InlineKlass());\n+    jint lh = vk->layout_helper();\n+    assert(lh != Klass::_lh_neutral_value, \"inline class in return type must have been resolved\");\n+    if (UseTLAB && !Klass::layout_helper_needs_slow_path(lh)) {\n+      tlab_allocate(r0, noreg, lh, tmp1, tmp2, slow_case);\n+    } else {\n+      b(slow_case);\n+    }\n+  } else {\n+    \/\/ Call from interpreter. R0 contains ((the InlineKlass* of the return type) | 0x01)\n+    andr(klass, r0, -2);\n+    if (UseTLAB) {\n+      ldrw(tmp2, Address(klass, Klass::layout_helper_offset()));\n+      tst(tmp2, Klass::_lh_instance_slow_path_bit);\n+      br(Assembler::NE, slow_case);\n+      tlab_allocate(r0, tmp2, 0, tmp1, tmp2, slow_case);\n+    } else {\n+      b(slow_case);\n+    }\n+  }\n+  if (UseTLAB) {\n+    \/\/ 2. Initialize buffered inline instance header\n+    Register buffer_obj = r0;\n+    mov(rscratch1, (intptr_t)markWord::inline_type_prototype().value());\n+    str(rscratch1, Address(buffer_obj, oopDesc::mark_offset_in_bytes()));\n+    store_klass_gap(buffer_obj, zr);\n+    if (vk == nullptr) {\n+      \/\/ store_klass corrupts klass, so save it for later use (interpreter case only).\n+      mov(tmp1, klass);\n+    }\n+    store_klass(buffer_obj, klass);\n+    \/\/ 3. Initialize its fields with an inline class specific handler\n+    if (vk != nullptr) {\n+      far_call(RuntimeAddress(vk->pack_handler())); \/\/ no need for call info as this will not safepoint.\n+    } else {\n+      \/\/ tmp1 holds klass preserved above\n+      ldr(tmp1, Address(tmp1, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+      ldr(tmp1, Address(tmp1, InlineKlass::pack_handler_offset()));\n+      blr(tmp1);\n+    }\n+\n+    membar(Assembler::StoreStore);\n+    b(skip);\n+  } else {\n+    \/\/ Must have already branched to slow_case above.\n+    DEBUG_ONLY(should_not_reach_here());\n+  }\n+  bind(slow_case);\n+  \/\/ We failed to allocate a new inline type, fall back to a runtime\n+  \/\/ call. Some oop field may be live in some registers but we can't\n+  \/\/ tell. That runtime call will take care of preserving them\n+  \/\/ across a GC if there's one.\n+  mov(r0, r0_preserved);\n+\n+  if (from_interpreter) {\n+    super_call_VM_leaf(StubRoutines::store_inline_type_fields_to_buf());\n+  } else {\n+    far_call(RuntimeAddress(StubRoutines::store_inline_type_fields_to_buf()));\n+    call_offset = offset();\n+  }\n+  membar(Assembler::StoreStore);\n+\n+  bind(skip);\n+  return call_offset;\n+}\n+\n+\/\/ Move a value between registers\/stack slots and update the reg_state\n+bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[]) {\n+  assert(from->is_valid() && to->is_valid(), \"source and destination must be valid\");\n+  if (reg_state[to->value()] == reg_written) {\n+    return true; \/\/ Already written\n+  }\n+\n+  if (from != to && bt != T_VOID) {\n+    if (reg_state[to->value()] == reg_readonly) {\n+      return false; \/\/ Not yet writable\n+    }\n+    if (from->is_reg()) {\n+      if (to->is_reg()) {\n+        if (from->is_Register() && to->is_Register()) {\n+          mov(to->as_Register(), from->as_Register());\n+        } else if (from->is_FloatRegister() && to->is_FloatRegister()) {\n+          fmovd(to->as_FloatRegister(), from->as_FloatRegister());\n+        } else {\n+          ShouldNotReachHere();\n+        }\n+      } else {\n+        int st_off = to->reg2stack() * VMRegImpl::stack_slot_size;\n+        Address to_addr = Address(sp, st_off);\n+        if (from->is_FloatRegister()) {\n+          if (bt == T_DOUBLE) {\n+             strd(from->as_FloatRegister(), to_addr);\n+          } else {\n+             assert(bt == T_FLOAT, \"must be float\");\n+             strs(from->as_FloatRegister(), to_addr);\n+          }\n+        } else {\n+          str(from->as_Register(), to_addr);\n+        }\n+      }\n+    } else {\n+      Address from_addr = Address(sp, from->reg2stack() * VMRegImpl::stack_slot_size);\n+      if (to->is_reg()) {\n+        if (to->is_FloatRegister()) {\n+          if (bt == T_DOUBLE) {\n+            ldrd(to->as_FloatRegister(), from_addr);\n+          } else {\n+            assert(bt == T_FLOAT, \"must be float\");\n+            ldrs(to->as_FloatRegister(), from_addr);\n+          }\n+        } else {\n+          ldr(to->as_Register(), from_addr);\n+        }\n+      } else {\n+        int st_off = to->reg2stack() * VMRegImpl::stack_slot_size;\n+        ldr(rscratch1, from_addr);\n+        str(rscratch1, Address(sp, st_off));\n+      }\n+    }\n+  }\n+\n+  \/\/ Update register states\n+  reg_state[from->value()] = reg_writable;\n+  reg_state[to->value()] = reg_written;\n+  return true;\n+}\n+\n+\/\/ Calculate the extra stack space required for packing or unpacking inline\n+\/\/ args and adjust the stack pointer\n+int MacroAssembler::extend_stack_for_inline_args(int args_on_stack) {\n+  int sp_inc = args_on_stack * VMRegImpl::stack_slot_size;\n+  sp_inc = align_up(sp_inc, StackAlignmentInBytes);\n+  assert(sp_inc > 0, \"sanity\");\n+\n+  \/\/ Save a copy of the FP and LR here for deoptimization patching and frame walking\n+  stp(rfp, lr, Address(pre(sp, -2 * wordSize)));\n+\n+  \/\/ Adjust the stack pointer. This will be repaired on return by MacroAssembler::remove_frame\n+  if (sp_inc < (1 << 9)) {\n+    sub(sp, sp, sp_inc);   \/\/ Fits in an immediate\n+  } else {\n+    mov(rscratch1, sp_inc);\n+    sub(sp, sp, rscratch1);\n+  }\n+\n+  return sp_inc + 2 * wordSize;  \/\/ Account for the FP\/LR space\n+}\n+\n+\/\/ Read all fields from an inline type oop and store the values in registers\/stack slots\n+bool MacroAssembler::unpack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index,\n+                                          VMReg from, int& from_index, VMRegPair* to, int to_count, int& to_index,\n+                                          RegState reg_state[]) {\n+  assert(sig->at(sig_index)._bt == T_VOID, \"should be at end delimiter\");\n+  assert(from->is_valid(), \"source must be valid\");\n+  bool progress = false;\n+#ifdef ASSERT\n+  const int start_offset = offset();\n+#endif\n+\n+  Label L_null, L_notNull;\n+  \/\/ Don't use r14 as tmp because it's used for spilling (see MacroAssembler::spill_reg_for)\n+  Register tmp1 = r10;\n+  Register tmp2 = r11;\n+  Register fromReg = noreg;\n+  ScalarizedInlineArgsStream stream(sig, sig_index, to, to_count, to_index, -1);\n+  bool done = true;\n+  bool mark_done = true;\n+  VMReg toReg;\n+  BasicType bt;\n+  \/\/ Check if argument requires a null check\n+  bool null_check = false;\n+  VMReg nullCheckReg;\n+  while (stream.next(nullCheckReg, bt)) {\n+    if (sig->at(stream.sig_index())._offset == -1) {\n+      null_check = true;\n+      break;\n+    }\n+  }\n+  stream.reset(sig_index, to_index);\n+  while (stream.next(toReg, bt)) {\n+    assert(toReg->is_valid(), \"destination must be valid\");\n+    int idx = (int)toReg->value();\n+    if (reg_state[idx] == reg_readonly) {\n+      if (idx != from->value()) {\n+        mark_done = false;\n+      }\n+      done = false;\n+      continue;\n+    } else if (reg_state[idx] == reg_written) {\n+      continue;\n+    }\n+    assert(reg_state[idx] == reg_writable, \"must be writable\");\n+    reg_state[idx] = reg_written;\n+    progress = true;\n+\n+    if (fromReg == noreg) {\n+      if (from->is_reg()) {\n+        fromReg = from->as_Register();\n+      } else {\n+        int st_off = from->reg2stack() * VMRegImpl::stack_slot_size;\n+        ldr(tmp1, Address(sp, st_off));\n+        fromReg = tmp1;\n+      }\n+      if (null_check) {\n+        \/\/ Nullable inline type argument, emit null check\n+        cbz(fromReg, L_null);\n+      }\n+    }\n+    int off = sig->at(stream.sig_index())._offset;\n+    if (off == -1) {\n+      assert(null_check, \"Missing null check at\");\n+      if (toReg->is_stack()) {\n+        int st_off = toReg->reg2stack() * VMRegImpl::stack_slot_size;\n+        mov(tmp2, 1);\n+        str(tmp2, Address(sp, st_off));\n+      } else {\n+        mov(toReg->as_Register(), 1);\n+      }\n+      continue;\n+    }\n+    assert(off > 0, \"offset in object should be positive\");\n+    Address fromAddr = Address(fromReg, off);\n+    if (!toReg->is_FloatRegister()) {\n+      Register dst = toReg->is_stack() ? tmp2 : toReg->as_Register();\n+      if (is_reference_type(bt)) {\n+        load_heap_oop(dst, fromAddr, rscratch1, rscratch2);\n+      } else {\n+        bool is_signed = (bt != T_CHAR) && (bt != T_BOOLEAN);\n+        load_sized_value(dst, fromAddr, type2aelembytes(bt), is_signed);\n+      }\n+      if (toReg->is_stack()) {\n+        int st_off = toReg->reg2stack() * VMRegImpl::stack_slot_size;\n+        str(dst, Address(sp, st_off));\n+      }\n+    } else if (bt == T_DOUBLE) {\n+      ldrd(toReg->as_FloatRegister(), fromAddr);\n+    } else {\n+      assert(bt == T_FLOAT, \"must be float\");\n+      ldrs(toReg->as_FloatRegister(), fromAddr);\n+    }\n+  }\n+  if (progress && null_check) {\n+    if (done) {\n+      b(L_notNull);\n+      bind(L_null);\n+      \/\/ Set IsInit field to zero to signal that the argument is null.\n+      \/\/ Also set all oop fields to zero to make the GC happy.\n+      stream.reset(sig_index, to_index);\n+      while (stream.next(toReg, bt)) {\n+        if (sig->at(stream.sig_index())._offset == -1 ||\n+            bt == T_OBJECT || bt == T_ARRAY) {\n+          if (toReg->is_stack()) {\n+            int st_off = toReg->reg2stack() * VMRegImpl::stack_slot_size;\n+            str(zr, Address(sp, st_off));\n+          } else {\n+            mov(toReg->as_Register(), zr);\n+          }\n+        }\n+      }\n+      bind(L_notNull);\n+    } else {\n+      bind(L_null);\n+    }\n+  }\n+\n+  sig_index = stream.sig_index();\n+  to_index = stream.regs_index();\n+\n+  if (mark_done && reg_state[from->value()] != reg_written) {\n+    \/\/ This is okay because no one else will write to that slot\n+    reg_state[from->value()] = reg_writable;\n+  }\n+  from_index--;\n+  assert(progress || (start_offset == offset()), \"should not emit code\");\n+  return done;\n+}\n+\n+\/\/ Pack fields back into an inline type oop\n+bool MacroAssembler::pack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index, int vtarg_index,\n+                                        VMRegPair* from, int from_count, int& from_index, VMReg to,\n+                                        RegState reg_state[], Register val_array) {\n+  assert(sig->at(sig_index)._bt == T_METADATA, \"should be at delimiter\");\n+  assert(to->is_valid(), \"destination must be valid\");\n+\n+  if (reg_state[to->value()] == reg_written) {\n+    skip_unpacked_fields(sig, sig_index, from, from_count, from_index);\n+    return true; \/\/ Already written\n+  }\n+\n+  \/\/ The GC barrier expanded by store_heap_oop below may call into the\n+  \/\/ runtime so use callee-saved registers for any values that need to be\n+  \/\/ preserved. The GC barrier assembler should take care of saving the\n+  \/\/ Java argument registers.\n+  \/\/ TODO 8284443 Isn't it an issue if below code uses r14 as tmp when it contains a spilled value?\n+  \/\/ Be careful with r14 because it's used for spilling (see MacroAssembler::spill_reg_for).\n+  Register val_obj_tmp = r21;\n+  Register from_reg_tmp = r22;\n+  Register tmp1 = r14;\n+  Register tmp2 = r13;\n+  Register tmp3 = r12;\n+  Register val_obj = to->is_stack() ? val_obj_tmp : to->as_Register();\n+\n+  assert_different_registers(val_obj_tmp, from_reg_tmp, tmp1, tmp2, tmp3, val_array);\n+\n+  if (reg_state[to->value()] == reg_readonly) {\n+    if (!is_reg_in_unpacked_fields(sig, sig_index, to, from, from_count, from_index)) {\n+      skip_unpacked_fields(sig, sig_index, from, from_count, from_index);\n+      return false; \/\/ Not yet writable\n+    }\n+    val_obj = val_obj_tmp;\n+  }\n+\n+  int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + vtarg_index * type2aelembytes(T_OBJECT);\n+  load_heap_oop(val_obj, Address(val_array, index), tmp1, tmp2);\n+\n+  ScalarizedInlineArgsStream stream(sig, sig_index, from, from_count, from_index);\n+  VMReg fromReg;\n+  BasicType bt;\n+  Label L_null;\n+  while (stream.next(fromReg, bt)) {\n+    assert(fromReg->is_valid(), \"source must be valid\");\n+    reg_state[fromReg->value()] = reg_writable;\n+\n+    int off = sig->at(stream.sig_index())._offset;\n+    if (off == -1) {\n+      \/\/ Nullable inline type argument, emit null check\n+      Label L_notNull;\n+      if (fromReg->is_stack()) {\n+        int ld_off = fromReg->reg2stack() * VMRegImpl::stack_slot_size;\n+        ldrb(tmp2, Address(sp, ld_off));\n+        cbnz(tmp2, L_notNull);\n+      } else {\n+        cbnz(fromReg->as_Register(), L_notNull);\n+      }\n+      mov(val_obj, 0);\n+      b(L_null);\n+      bind(L_notNull);\n+      continue;\n+    }\n+\n+    assert(off > 0, \"offset in object should be positive\");\n+    size_t size_in_bytes = is_java_primitive(bt) ? type2aelembytes(bt) : wordSize;\n+\n+    \/\/ Pack the scalarized field into the value object.\n+    Address dst(val_obj, off);\n+\n+    if (!fromReg->is_FloatRegister()) {\n+      Register src;\n+      if (fromReg->is_stack()) {\n+        src = from_reg_tmp;\n+        int ld_off = fromReg->reg2stack() * VMRegImpl::stack_slot_size;\n+        load_sized_value(src, Address(sp, ld_off), size_in_bytes, \/* is_signed *\/ false);\n+      } else {\n+        src = fromReg->as_Register();\n+      }\n+      assert_different_registers(dst.base(), src, tmp1, tmp2, tmp3, val_array);\n+      if (is_reference_type(bt)) {\n+        store_heap_oop(dst, src, tmp1, tmp2, tmp3, IN_HEAP | ACCESS_WRITE | IS_DEST_UNINITIALIZED);\n+      } else {\n+        store_sized_value(dst, src, size_in_bytes);\n+      }\n+    } else if (bt == T_DOUBLE) {\n+      strd(fromReg->as_FloatRegister(), dst);\n+    } else {\n+      assert(bt == T_FLOAT, \"must be float\");\n+      strs(fromReg->as_FloatRegister(), dst);\n+    }\n+  }\n+  bind(L_null);\n+  sig_index = stream.sig_index();\n+  from_index = stream.regs_index();\n+\n+  assert(reg_state[to->value()] == reg_writable, \"must have already been read\");\n+  bool success = move_helper(val_obj->as_VMReg(), to, T_OBJECT, reg_state);\n+  assert(success, \"to register must be writeable\");\n+\n+  return true;\n+}\n+\n+VMReg MacroAssembler::spill_reg_for(VMReg reg) {\n+  return (reg->is_FloatRegister()) ? v8->as_VMReg() : r14->as_VMReg();\n+}\n+\n@@ -6758,0 +7571,4 @@\n+  if (EnableValhalla) {\n+    \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n+    andr(mark, mark, ~((int) markWord::inline_type_bit_in_place));\n+  }\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":819,"deletions":2,"binary":false,"changes":821,"status":"modified"},{"patch":"@@ -328,4 +328,11 @@\n-    __ ldr(j_rarg2, result);\n-    Label is_long, is_float, is_double, exit;\n-    __ ldr(j_rarg1, result_type);\n-    __ cmp(j_rarg1, (u1)T_OBJECT);\n+    \/\/ All of j_rargN may be used to return inline type fields so be careful\n+    \/\/ not to clobber those.\n+    \/\/ SharedRuntime::generate_buffered_inline_type_adapter() knows the register\n+    \/\/ assignment of Rresult below.\n+    Register Rresult = r14, Rresult_type = r15;\n+    __ ldr(Rresult, result);\n+    Label is_long, is_float, is_double, check_prim, exit;\n+    __ ldr(Rresult_type, result_type);\n+    __ cmp(Rresult_type, (u1)T_OBJECT);\n+    __ br(Assembler::EQ, check_prim);\n+    __ cmp(Rresult_type, (u1)T_LONG);\n@@ -333,3 +340,1 @@\n-    __ cmp(j_rarg1, (u1)T_LONG);\n-    __ br(Assembler::EQ, is_long);\n-    __ cmp(j_rarg1, (u1)T_FLOAT);\n+    __ cmp(Rresult_type, (u1)T_FLOAT);\n@@ -337,1 +342,1 @@\n-    __ cmp(j_rarg1, (u1)T_DOUBLE);\n+    __ cmp(Rresult_type, (u1)T_DOUBLE);\n@@ -341,1 +346,1 @@\n-    __ strw(r0, Address(j_rarg2));\n+    __ strw(r0, Address(Rresult));\n@@ -393,0 +398,11 @@\n+    __ BIND(check_prim);\n+    if (InlineTypeReturnedAsFields) {\n+      \/\/ Check for scalarized return value\n+      __ tbz(r0, 0, is_long);\n+      \/\/ Load pack handler address\n+      __ andr(rscratch1, r0, -2);\n+      __ ldr(rscratch1, Address(rscratch1, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+      __ ldr(rscratch1, Address(rscratch1, InlineKlass::pack_handler_jobject_offset()));\n+      __ blr(rscratch1);\n+      __ b(exit);\n+    }\n@@ -395,1 +411,1 @@\n-    __ str(r0, Address(j_rarg2, 0));\n+    __ str(r0, Address(Rresult, 0));\n@@ -399,1 +415,1 @@\n-    __ strs(j_farg0, Address(j_rarg2, 0));\n+    __ strs(j_farg0, Address(Rresult, 0));\n@@ -403,1 +419,1 @@\n-    __ strd(j_farg0, Address(j_rarg2, 0));\n+    __ strd(j_farg0, Address(Rresult, 0));\n@@ -2216,0 +2232,6 @@\n+    \/\/ Check for flat inline type array -> return -1\n+    __ test_flat_array_oop(src, rscratch2, L_failed);\n+\n+    \/\/ Check for null-free (non-flat) inline type array -> handle as object array\n+    __ test_null_free_array_oop(src, rscratch2, L_objArray);\n+\n@@ -8349,0 +8371,128 @@\n+  \/\/ Call here from the interpreter or compiled code to either load\n+  \/\/ multiple returned values from the inline type instance being\n+  \/\/ returned to registers or to store returned values to a newly\n+  \/\/ allocated inline type instance.\n+  address generate_return_value_stub(address destination, const char* name, bool has_res) {\n+    \/\/ We need to save all registers the calling convention may use so\n+    \/\/ the runtime calls read or update those registers. This needs to\n+    \/\/ be in sync with SharedRuntime::java_return_convention().\n+    \/\/ n.b. aarch64 asserts that frame::arg_reg_save_area_bytes == 0\n+    enum layout {\n+      j_rarg7_off = 0, j_rarg7_2,    \/\/ j_rarg7 is r0\n+      j_rarg6_off, j_rarg6_2,\n+      j_rarg5_off, j_rarg5_2,\n+      j_rarg4_off, j_rarg4_2,\n+      j_rarg3_off, j_rarg3_2,\n+      j_rarg2_off, j_rarg2_2,\n+      j_rarg1_off, j_rarg1_2,\n+      j_rarg0_off, j_rarg0_2,\n+\n+      j_farg7_off, j_farg7_2,\n+      j_farg6_off, j_farg6_2,\n+      j_farg5_off, j_farg5_2,\n+      j_farg4_off, j_farg4_2,\n+      j_farg3_off, j_farg3_2,\n+      j_farg2_off, j_farg2_2,\n+      j_farg1_off, j_farg1_2,\n+      j_farg0_off, j_farg0_2,\n+\n+      rfp_off, rfp_off2,\n+      return_off, return_off2,\n+\n+      framesize \/\/ inclusive of return address\n+    };\n+\n+    CodeBuffer code(name, 512, 64);\n+    MacroAssembler* masm = new MacroAssembler(&code);\n+\n+    int frame_size_in_bytes = align_up(framesize*BytesPerInt, 16);\n+    assert(frame_size_in_bytes == framesize*BytesPerInt, \"misaligned\");\n+    int frame_size_in_slots = frame_size_in_bytes \/ BytesPerInt;\n+    int frame_size_in_words = frame_size_in_bytes \/ wordSize;\n+\n+    OopMapSet* oop_maps = new OopMapSet();\n+    OopMap* map = new OopMap(frame_size_in_slots, 0);\n+\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg7_off), j_rarg7->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg6_off), j_rarg6->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg5_off), j_rarg5->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg4_off), j_rarg4->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg3_off), j_rarg3->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg2_off), j_rarg2->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg1_off), j_rarg1->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg0_off), j_rarg0->as_VMReg());\n+\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg0_off), j_farg0->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg1_off), j_farg1->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg2_off), j_farg2->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg3_off), j_farg3->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg4_off), j_farg4->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg5_off), j_farg5->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg6_off), j_farg6->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg7_off), j_farg7->as_VMReg());\n+\n+    address start = __ pc();\n+\n+    __ enter(); \/\/ Save FP and LR before call\n+\n+    __ stpd(j_farg1, j_farg0, Address(__ pre(sp, -2 * wordSize)));\n+    __ stpd(j_farg3, j_farg2, Address(__ pre(sp, -2 * wordSize)));\n+    __ stpd(j_farg5, j_farg4, Address(__ pre(sp, -2 * wordSize)));\n+    __ stpd(j_farg7, j_farg6, Address(__ pre(sp, -2 * wordSize)));\n+\n+    __ stp(j_rarg1, j_rarg0, Address(__ pre(sp, -2 * wordSize)));\n+    __ stp(j_rarg3, j_rarg2, Address(__ pre(sp, -2 * wordSize)));\n+    __ stp(j_rarg5, j_rarg4, Address(__ pre(sp, -2 * wordSize)));\n+    __ stp(j_rarg7, j_rarg6, Address(__ pre(sp, -2 * wordSize)));\n+\n+    int frame_complete = __ offset();\n+\n+    \/\/ Set up last_Java_sp and last_Java_fp\n+    address the_pc = __ pc();\n+    __ set_last_Java_frame(sp, noreg, the_pc, rscratch1);\n+\n+    \/\/ Call runtime\n+    __ mov(c_rarg1, r0);\n+    __ mov(c_rarg0, rthread);\n+\n+    __ mov(rscratch1, destination);\n+    __ blr(rscratch1);\n+\n+    oop_maps->add_gc_map(the_pc - start, map);\n+\n+    __ reset_last_Java_frame(false);\n+\n+    __ ldp(j_rarg7, j_rarg6, Address(__ post(sp, 2 * wordSize)));\n+    __ ldp(j_rarg5, j_rarg4, Address(__ post(sp, 2 * wordSize)));\n+    __ ldp(j_rarg3, j_rarg2, Address(__ post(sp, 2 * wordSize)));\n+    __ ldp(j_rarg1, j_rarg0, Address(__ post(sp, 2 * wordSize)));\n+\n+    __ ldpd(j_farg7, j_farg6, Address(__ post(sp, 2 * wordSize)));\n+    __ ldpd(j_farg5, j_farg4, Address(__ post(sp, 2 * wordSize)));\n+    __ ldpd(j_farg3, j_farg2, Address(__ post(sp, 2 * wordSize)));\n+    __ ldpd(j_farg1, j_farg0, Address(__ post(sp, 2 * wordSize)));\n+\n+    __ leave();\n+\n+    \/\/ check for pending exceptions\n+    Label pending;\n+    __ ldr(rscratch1, Address(rthread, in_bytes(Thread::pending_exception_offset())));\n+    __ cbnz(rscratch1, pending);\n+\n+    if (has_res) {\n+      __ get_vm_result(r0, rthread);\n+    }\n+\n+    __ ret(lr);\n+\n+    __ bind(pending);\n+    __ far_jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+\n+    \/\/ -------------\n+    \/\/ make sure all code is generated\n+    masm->flush();\n+\n+    RuntimeStub* stub = RuntimeStub::new_runtime_stub(name, &code, frame_complete, frame_size_in_words, oop_maps, false);\n+    return stub->entry_point();\n+  }\n+\n@@ -8405,0 +8555,8 @@\n+\n+    if (InlineTypeReturnedAsFields) {\n+      StubRoutines::_load_inline_type_fields_in_regs =\n+         generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::load_inline_type_fields_in_regs), \"load_inline_type_fields_in_regs\", false);\n+      StubRoutines::_store_inline_type_fields_to_buf =\n+         generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::store_inline_type_fields_to_buf), \"store_inline_type_fields_to_buf\", true);\n+    }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":170,"deletions":12,"binary":false,"changes":182,"status":"modified"},{"patch":"@@ -175,0 +175,1 @@\n+  case Bytecodes::_fast_vputfield:\n@@ -756,4 +757,4 @@\n-    \/\/ ??? convention: move array into r3 for exception message\n-  __ mov(r3, array);\n-  __ mov(rscratch1, Interpreter::_throw_ArrayIndexOutOfBoundsException_entry);\n-  __ br(rscratch1);\n+  \/\/ ??? convention: move array into r3 for exception message\n+   __ mov(r3, array);\n+   __ mov(rscratch1, Interpreter::_throw_ArrayIndexOutOfBoundsException_entry);\n+   __ br(rscratch1);\n@@ -819,5 +820,20 @@\n-  __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_OBJECT) >> LogBytesPerHeapOop);\n-  do_oop_load(_masm,\n-              Address(r0, r1, Address::uxtw(LogBytesPerHeapOop)),\n-              r0,\n-              IS_ARRAY);\n+  __ profile_array_type<ArrayLoadData>(r2, r0, r4);\n+  if (UseFlatArray) {\n+    Label is_flat_array, done;\n+\n+    __ test_flat_array_oop(r0, r8 \/*temp*\/, is_flat_array);\n+    __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_OBJECT) >> LogBytesPerHeapOop);\n+    do_oop_load(_masm, Address(r0, r1, Address::uxtw(LogBytesPerHeapOop)), r0, IS_ARRAY);\n+\n+    __ b(done);\n+    __ bind(is_flat_array);\n+    __ call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::value_array_load), r0, r1);\n+    \/\/ Ensure the stores to copy the inline field contents are visible\n+    \/\/ before any subsequent store that publishes this reference.\n+    __ membar(Assembler::StoreStore);\n+    __ bind(done);\n+  } else {\n+    __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_OBJECT) >> LogBytesPerHeapOop);\n+    do_oop_load(_masm, Address(r0, r1, Address::uxtw(LogBytesPerHeapOop)), r0, IS_ARRAY);\n+  }\n+  __ profile_element_type(r2, r0, r4);\n@@ -1110,1 +1126,1 @@\n-  Label is_null, ok_is_subtype, done;\n+  Label is_null, is_flat_array, ok_is_subtype, done;\n@@ -1117,2 +1133,4 @@\n-  Address element_address(r3, r4, Address::uxtw(LogBytesPerHeapOop));\n-\n+\n+  __ profile_array_type<ArrayStoreData>(r4, r3, r5);\n+  __ profile_multiple_element_types(r4, r0, r5, r6);\n+\n@@ -1121,0 +1139,2 @@\n+  Address element_address(r3, r4, Address::uxtw(LogBytesPerHeapOop));\n+  \/\/ Be careful not to clobber r4 below\n@@ -1125,0 +1145,8 @@\n+  \/\/ Move array class to r5\n+  __ load_klass(r5, r3);\n+\n+  if (UseFlatArray) {\n+    __ ldrw(r6, Address(r5, Klass::layout_helper_offset()));\n+    __ test_flat_array_layout(r6, is_flat_array);\n+  }\n+\n@@ -1127,4 +1155,3 @@\n-  \/\/ Move superklass into r0\n-  __ load_klass(r0, r3);\n-  __ ldr(r0, Address(r0,\n-                     ObjArrayKlass::element_klass_offset()));\n+\n+  \/\/ Move array element superklass into r0\n+  __ ldr(r0, Address(r5, ObjArrayKlass::element_klass_offset()));\n@@ -1135,1 +1162,3 @@\n-  __ gen_subtype_check(r1, ok_is_subtype);\n+\n+  \/\/ is \"r1 <: r0\" ? (value subclass <: array element superclass)\n+  __ gen_subtype_check(r1, ok_is_subtype, false);\n@@ -1152,1 +1181,12 @@\n-  __ profile_null_seen(r2);\n+  if (EnableValhalla) {\n+    Label is_null_into_value_array_npe, store_null;\n+\n+    \/\/ No way to store null in flat null-free array\n+    __ test_null_free_array_oop(r3, r8, is_null_into_value_array_npe);\n+    __ b(store_null);\n+\n+    __ bind(is_null_into_value_array_npe);\n+    __ b(ExternalAddress(Interpreter::_throw_NullPointerException_entry));\n+\n+    __ bind(store_null);\n+  }\n@@ -1156,0 +1196,41 @@\n+  __ b(done);\n+\n+  if (UseFlatArray) {\n+     Label is_type_ok;\n+    __ bind(is_flat_array); \/\/ Store non-null value to flat\n+\n+    \/\/ Simplistic type check...\n+    \/\/ r0 - value, r2 - index, r3 - array.\n+\n+    \/\/ Profile the not-null value's klass.\n+    \/\/ Load value class\n+     __ load_klass(r1, r0);\n+\n+    \/\/ Move element klass into r7\n+     __ ldr(r7, Address(r5, ArrayKlass::element_klass_offset()));\n+\n+    \/\/ flat value array needs exact type match\n+    \/\/ is \"r1 == r7\" (value subclass == array element superclass)\n+\n+     __ cmp(r7, r1);\n+     __ br(Assembler::EQ, is_type_ok);\n+\n+     __ b(ExternalAddress(Interpreter::_throw_ArrayStoreException_entry));\n+\n+     __ bind(is_type_ok);\n+    \/\/ r1: value's klass\n+    \/\/ r3: array\n+    \/\/ r5: array klass\n+    __ test_klass_is_empty_inline_type(r1, r7, done);\n+\n+    \/\/ calc dst for copy\n+    __ ldrw(r7, at_tos_p1()); \/\/ index\n+    __ data_for_value_array_index(r3, r5, r7, r7);\n+\n+    \/\/ ...and src for copy\n+    __ ldr(r6, at_tos());  \/\/ value\n+    __ data_for_oop(r6, r6, r1);\n+\n+    __ mov(r4, r1);  \/\/ Shuffle arguments to avoid conflict with c_rarg1\n+    __ access_value_copy(IN_HEAP, r6, r7, r4);\n+  }\n@@ -1960,2 +2041,1 @@\n-void TemplateTable::if_acmp(Condition cc)\n-{\n+void TemplateTable::if_acmp(Condition cc) {\n@@ -1964,1 +2044,1 @@\n-  Label not_taken;\n+  Label taken, not_taken;\n@@ -1966,0 +2046,38 @@\n+\n+  __ profile_acmp(r2, r1, r0, r4);\n+\n+  Register is_inline_type_mask = rscratch1;\n+  __ mov(is_inline_type_mask, markWord::inline_type_pattern);\n+\n+  if (EnableValhalla) {\n+    __ cmp(r1, r0);\n+    __ br(Assembler::EQ, (cc == equal) ? taken : not_taken);\n+\n+    \/\/ might be substitutable, test if either r0 or r1 is null\n+    __ andr(r2, r0, r1);\n+    __ cbz(r2, (cc == equal) ? not_taken : taken);\n+\n+    \/\/ and both are values ?\n+    __ ldr(r2, Address(r1, oopDesc::mark_offset_in_bytes()));\n+    __ andr(r2, r2, is_inline_type_mask);\n+    __ ldr(r4, Address(r0, oopDesc::mark_offset_in_bytes()));\n+    __ andr(r4, r4, is_inline_type_mask);\n+    __ andr(r2, r2, r4);\n+    __ cmp(r2,  is_inline_type_mask);\n+    __ br(Assembler::NE, (cc == equal) ? not_taken : taken);\n+\n+    \/\/ same value klass ?\n+    __ load_metadata(r2, r1);\n+    __ load_metadata(r4, r0);\n+    __ cmp(r2, r4);\n+    __ br(Assembler::NE, (cc == equal) ? not_taken : taken);\n+\n+    \/\/ Know both are the same type, let's test for substitutability...\n+    if (cc == equal) {\n+      invoke_is_substitutable(r0, r1, taken, not_taken);\n+    } else {\n+      invoke_is_substitutable(r0, r1, not_taken, taken);\n+    }\n+    __ stop(\"Not reachable\");\n+  }\n+\n@@ -1968,0 +2086,1 @@\n+  __ bind(taken);\n@@ -1970,1 +2089,10 @@\n-  __ profile_not_taken_branch(r0);\n+  __ profile_not_taken_branch(r0, true);\n+}\n+\n+void TemplateTable::invoke_is_substitutable(Register aobj, Register bobj,\n+                                            Label& is_subst, Label& not_subst) {\n+\n+  __ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::is_substitutable), aobj, bobj);\n+  \/\/ Restored... r0 answer, jmp to outcome...\n+  __ cbz(r0, not_subst);\n+  __ b(is_subst);\n@@ -1973,0 +2101,1 @@\n+\n@@ -2582,1 +2711,1 @@\n-  const Register cache     = r4;\n+  const Register cache     = r2;\n@@ -2584,0 +2713,3 @@\n+  const Register klass     = r5;\n+  const Register inline_klass = r7;\n+  const Register field_index = r23;\n@@ -2592,0 +2724,5 @@\n+\n+  \/\/ Valhalla extras\n+  __ load_unsigned_short(field_index, Address(cache, in_bytes(ResolvedFieldEntry::field_index_offset())));\n+  __ ldr(klass, Address(cache, ResolvedFieldEntry::field_holder_offset()));\n+\n@@ -2650,4 +2787,73 @@\n-  do_oop_load(_masm, field, r0, IN_HEAP);\n-  __ push(atos);\n-  if (rc == may_rewrite) {\n-    patch_bytecode(Bytecodes::_fast_agetfield, bc, r1);\n+  if (!EnableValhalla) {\n+    do_oop_load(_masm, field, r0, IN_HEAP);\n+    __ push(atos);\n+    if (rc == may_rewrite) {\n+      patch_bytecode(Bytecodes::_fast_agetfield, bc, r1);\n+    }\n+    __ b(Done);\n+  } else { \/\/ Valhalla\n+    if (is_static) {\n+      __ load_heap_oop(r0, field, rscratch1, rscratch2);\n+      Label is_null_free_inline_type, uninitialized;\n+      \/\/ Issue below if the static field has not been initialized yet\n+      __ test_field_is_null_free_inline_type(flags, noreg \/*temp*\/, is_null_free_inline_type);\n+        \/\/ field is not a null free inline type\n+        __ push(atos);\n+        __ b(Done);\n+      \/\/ field is a null free inline type, must not return null even if uninitialized\n+      __ bind(is_null_free_inline_type);\n+        __ cbz(r0, uninitialized);\n+          __ push(atos);\n+          __ b(Done);\n+        __ bind(uninitialized);\n+          Label slow_case, finish;\n+          __ ldrb(rscratch1, Address(klass, InstanceKlass::init_state_offset()));\n+          __ cmp(rscratch1, (u1)InstanceKlass::fully_initialized);\n+          __ br(Assembler::NE, slow_case);\n+          __ get_default_value_oop(klass, off \/* temp *\/, r0);\n+        __ b(finish);\n+        __ bind(slow_case);\n+          __ call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::uninitialized_static_inline_type_field), obj, cache);\n+          __ bind(finish);\n+          __ verify_oop(r0);\n+          __ push(atos);\n+          __ b(Done);\n+    } else {\n+      Label is_flat, nonnull, is_inline_type, has_null_marker, rewrite_inline;\n+      __ test_field_is_null_free_inline_type(flags, noreg \/*temp*\/, is_inline_type);\n+      __ test_field_has_null_marker(flags, noreg \/*temp*\/, has_null_marker);\n+        \/\/ Non-inline field case\n+        __ load_heap_oop(r0, field, rscratch1, rscratch2);\n+        __ push(atos);\n+        if (rc == may_rewrite) {\n+          patch_bytecode(Bytecodes::_fast_agetfield, bc, r1);\n+        }\n+        __ b(Done);\n+      __ bind(is_inline_type);\n+        __ test_field_is_flat(flags, noreg \/* temp *\/, is_flat);\n+         \/\/ field is not flat\n+          __ load_heap_oop(r0, field, rscratch1, rscratch2);\n+          __ cbnz(r0, nonnull);\n+            __ get_inline_type_field_klass(klass, field_index, inline_klass);\n+            __ get_default_value_oop(inline_klass, klass \/* temp *\/, r0);\n+          __ bind(nonnull);\n+          __ verify_oop(r0);\n+          __ push(atos);\n+          __ b(rewrite_inline);\n+        __ bind(is_flat);\n+        \/\/ field is flat\n+          __ mov(r0, obj);\n+          __ read_flat_field(klass, field_index, off, inline_klass \/* temp *\/, r0);\n+          __ verify_oop(r0);\n+          __ push(atos);\n+          __ b(rewrite_inline);\n+        __ bind(has_null_marker);\n+          call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::read_nullable_flat_field), obj, cache);\n+          __ verify_oop(r0);\n+          __ push(atos);\n+      __ bind(rewrite_inline);\n+      if (rc == may_rewrite) {\n+        patch_bytecode(Bytecodes::_fast_vgetfield, bc, r1);\n+      }\n+      __ b(Done);\n+    }\n@@ -2655,1 +2861,0 @@\n-  __ b(Done);\n@@ -2816,1 +3021,1 @@\n-  const Register flags     = r0;\n+  const Register flags     = r6;\n@@ -2818,0 +3023,1 @@\n+  const Register inline_klass = r5;\n@@ -2824,2 +3030,0 @@\n-  __ mov(r5, flags);\n-\n@@ -2828,1 +3032,1 @@\n-    __ tbz(r5, ResolvedFieldEntry::is_volatile_shift, notVolatile);\n+    __ tbz(flags, ResolvedFieldEntry::is_volatile_shift, notVolatile);\n@@ -2877,8 +3081,60 @@\n-    __ pop(atos);\n-    if (!is_static) pop_and_check_object(obj);\n-    \/\/ Store into the field\n-    do_oop_store(_masm, field, r0, IN_HEAP);\n-    if (rc == may_rewrite) {\n-      patch_bytecode(Bytecodes::_fast_aputfield, bc, r1, true, byte_no);\n-    }\n-    __ b(Done);\n+     if (!EnableValhalla) {\n+      __ pop(atos);\n+      if (!is_static) pop_and_check_object(obj);\n+      \/\/ Store into the field\n+      do_oop_store(_masm, field, r0, IN_HEAP);\n+      if (rc == may_rewrite) {\n+        patch_bytecode(Bytecodes::_fast_aputfield, bc, r1, true, byte_no);\n+      }\n+      __ b(Done);\n+     } else { \/\/ Valhalla\n+      __ pop(atos);\n+      if (is_static) {\n+        Label is_inline_type;\n+         __ test_field_is_not_null_free_inline_type(flags, noreg \/* temp *\/, is_inline_type);\n+         __ null_check(r0);\n+         __ bind(is_inline_type);\n+         do_oop_store(_masm, field, r0, IN_HEAP);\n+         __ b(Done);\n+      } else {\n+        Label is_inline_type, is_flat, has_null_marker, rewrite_not_inline, rewrite_inline;\n+        __ test_field_is_null_free_inline_type(flags, noreg \/*temp*\/, is_inline_type);\n+        __ test_field_has_null_marker(flags, noreg \/*temp*\/, has_null_marker);\n+        \/\/ Not an inline type\n+        pop_and_check_object(obj);\n+        \/\/ Store into the field\n+        do_oop_store(_masm, field, r0, IN_HEAP);\n+        __ bind(rewrite_not_inline);\n+        if (rc == may_rewrite) {\n+          patch_bytecode(Bytecodes::_fast_aputfield, bc, r19, true, byte_no);\n+        }\n+        __ b(Done);\n+        \/\/ Implementation of the inline type semantic\n+        __ bind(is_inline_type);\n+        __ null_check(r0);\n+        __ test_field_is_flat(flags, noreg \/*temp*\/, is_flat);\n+        \/\/ field is not flat\n+        pop_and_check_object(obj);\n+        \/\/ Store into the field\n+        do_oop_store(_masm, field, r0, IN_HEAP);\n+        __ b(rewrite_inline);\n+        __ bind(is_flat);\n+        \/\/ field is flat\n+        pop_and_check_object(obj);\n+        assert_different_registers(r0, inline_klass, obj, off);\n+        __ load_klass(inline_klass, r0);\n+        __ data_for_oop(r0, r0, inline_klass);\n+        __ add(obj, obj, off);\n+        __ access_value_copy(IN_HEAP, r0, obj, inline_klass);\n+        __ b(rewrite_inline);\n+        __ bind(has_null_marker);\n+        assert_different_registers(r0, cache, r19);\n+        pop_and_check_object(r19);\n+        __ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::write_nullable_flat_field), r19, r0, cache);\n+        __ bind(rewrite_inline);\n+        if (rc == may_rewrite) {\n+          patch_bytecode(Bytecodes::_fast_vputfield, bc, r19, true, byte_no);\n+        }\n+        __ b(Done);\n+      }\n+     }  \/\/ Valhalla\n@@ -2989,1 +3245,1 @@\n-    __ tbz(r5, ResolvedFieldEntry::is_volatile_shift, notVolatile);\n+    __ tbz(flags, ResolvedFieldEntry::is_volatile_shift, notVolatile);\n@@ -3023,0 +3279,1 @@\n+    case Bytecodes::_fast_vputfield: \/\/fall through\n@@ -3049,0 +3306,1 @@\n+    case Bytecodes::_fast_vputfield: \/\/fall through\n@@ -3095,0 +3353,23 @@\n+  case Bytecodes::_fast_vputfield:\n+   {\n+      Label is_flat, has_null_marker, done;\n+      __ test_field_has_null_marker(r3, noreg \/* temp *\/, has_null_marker);\n+      __ null_check(r0);\n+      __ test_field_is_flat(r3, noreg \/* temp *\/, is_flat);\n+      \/\/ field is not flat\n+      do_oop_store(_masm, field, r0, IN_HEAP);\n+      __ b(done);\n+      __ bind(is_flat);\n+      \/\/ field is flat\n+      __ load_klass(r4, r0);\n+      __ data_for_oop(r0, r0, r4);\n+      __ lea(rscratch1, field);\n+      __ access_value_copy(IN_HEAP, r0, rscratch1, r4);\n+      __ b(done);\n+      __ bind(has_null_marker);\n+      __ load_field_entry(r4, r1);\n+      __ mov(r1, r2);\n+      __ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::write_nullable_flat_field), r1, r0, r4);\n+      __ bind(done);\n+    }\n+    break;\n@@ -3187,0 +3468,29 @@\n+  case Bytecodes::_fast_vgetfield:\n+    {\n+      Register index = r4, klass = r5, inline_klass = r6, tmp = r7;\n+      Label is_flat, has_null_marker, nonnull, Done;\n+      __ test_field_has_null_marker(r3, noreg \/*temp*\/, has_null_marker);\n+      __ test_field_is_flat(r3, noreg \/* temp *\/, is_flat);\n+        \/\/ field is not flat\n+        __ load_heap_oop(r0, field, rscratch1, rscratch2);\n+        __ cbnz(r0, nonnull);\n+          __ load_unsigned_short(index, Address(r2, in_bytes(ResolvedFieldEntry::field_index_offset())));\n+          __ ldr(klass, Address(r2, in_bytes(ResolvedFieldEntry::field_holder_offset())));\n+          __ get_inline_type_field_klass(klass, index, inline_klass);\n+          __ get_default_value_oop(inline_klass, tmp \/* temp *\/, r0);\n+        __ bind(nonnull);\n+        __ verify_oop(r0);\n+        __ b(Done);\n+      __ bind(is_flat);\n+      \/\/ field is flat\n+        __ load_unsigned_short(index, Address(r2, in_bytes(ResolvedFieldEntry::field_index_offset())));\n+        __ ldr(klass, Address(r2, in_bytes(ResolvedFieldEntry::field_holder_offset())));\n+        __ read_flat_field(klass, index, r1, tmp \/* temp *\/, r0);\n+        __ verify_oop(r0);\n+        __ b(Done);\n+      __ bind(has_null_marker);\n+        call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::read_nullable_flat_field), r0, r2);\n+        __ verify_oop(r0);\n+      __ bind(Done);\n+    }\n+    break;\n@@ -3605,57 +3915,2 @@\n-  \/\/ get instance_size in InstanceKlass (scaled to a count of bytes)\n-  __ ldrw(r3,\n-          Address(r4,\n-                  Klass::layout_helper_offset()));\n-  \/\/ test to see if it is malformed in some way\n-  __ tbnz(r3, exact_log2(Klass::_lh_instance_slow_path_bit), slow_case);\n-\n-  \/\/ Allocate the instance:\n-  \/\/  If TLAB is enabled:\n-  \/\/    Try to allocate in the TLAB.\n-  \/\/    If fails, go to the slow path.\n-  \/\/    Initialize the allocation.\n-  \/\/    Exit.\n-  \/\/\n-  \/\/  Go to slow path.\n-\n-  if (UseTLAB) {\n-    __ tlab_allocate(r0, r3, 0, noreg, r1, slow_case);\n-\n-    if (ZeroTLAB) {\n-      \/\/ the fields have been already cleared\n-      __ b(initialize_header);\n-    }\n-\n-    \/\/ The object is initialized before the header.  If the object size is\n-    \/\/ zero, go directly to the header initialization.\n-    __ sub(r3, r3, sizeof(oopDesc));\n-    __ cbz(r3, initialize_header);\n-\n-    \/\/ Initialize object fields\n-    {\n-      __ add(r2, r0, sizeof(oopDesc));\n-      Label loop;\n-      __ bind(loop);\n-      __ str(zr, Address(__ post(r2, BytesPerLong)));\n-      __ sub(r3, r3, BytesPerLong);\n-      __ cbnz(r3, loop);\n-    }\n-\n-    \/\/ initialize object header only.\n-    __ bind(initialize_header);\n-    __ mov(rscratch1, (intptr_t)markWord::prototype().value());\n-    __ str(rscratch1, Address(r0, oopDesc::mark_offset_in_bytes()));\n-    __ store_klass_gap(r0, zr);  \/\/ zero klass gap for compressed oops\n-    __ store_klass(r0, r4);      \/\/ store klass last\n-\n-    {\n-      SkipIfEqual skip(_masm, &DTraceAllocProbes, false);\n-      \/\/ Trigger dtrace event for fastpath\n-      __ push(atos); \/\/ save the return value\n-      __ call_VM_leaf(\n-           CAST_FROM_FN_PTR(address, static_cast<int (*)(oopDesc*)>(SharedRuntime::dtrace_object_alloc)), r0);\n-      __ pop(atos); \/\/ restore the return value\n-\n-    }\n-    __ b(done);\n-  }\n+  __ allocate_instance(r4, r0, r3, r1, true, slow_case);\n+  __ b(done);\n@@ -3746,0 +4001,3 @@\n+  __ b(done);\n+  __ bind(is_null);\n+\n@@ -3748,4 +4006,1 @@\n-    __ b(done);\n-    __ bind(is_null);\n-  } else {\n-    __ bind(is_null);   \/\/ same as 'done'\n+\n@@ -3872,0 +4127,4 @@\n+  Label is_inline_type;\n+  __ ldr(rscratch1, Address(r0, oopDesc::mark_offset_in_bytes()));\n+  __ test_markword_is_inline_type(rscratch1, is_inline_type);\n+\n@@ -3973,0 +4232,5 @@\n+\n+  __ bind(is_inline_type);\n+  __ call_VM(noreg, CAST_FROM_FN_PTR(address,\n+                    InterpreterRuntime::throw_identity_exception), r0);\n+  __ should_not_reach_here();\n@@ -3983,0 +4247,12 @@\n+  const int is_inline_type_mask = markWord::inline_type_pattern;\n+  Label has_identity;\n+  __ ldr(rscratch1, Address(r0, oopDesc::mark_offset_in_bytes()));\n+  __ mov(rscratch2, is_inline_type_mask);\n+  __ andr(rscratch1, rscratch1, rscratch2);\n+  __ cmp(rscratch1, rscratch2);\n+  __ br(Assembler::NE, has_identity);\n+  __ call_VM(noreg, CAST_FROM_FN_PTR(address,\n+                     InterpreterRuntime::throw_illegal_monitor_state_exception));\n+  __ should_not_reach_here();\n+  __ bind(has_identity);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":378,"deletions":102,"binary":false,"changes":480,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"asm\/macroAssembler.inline.hpp\"\n@@ -30,0 +31,1 @@\n+#include \"gc\/shared\/barrierSetRuntime.hpp\"\n@@ -201,0 +203,13 @@\n+void BarrierSetAssembler::value_copy(MacroAssembler* masm, DecoratorSet decorators,\n+                                     Register src, Register dst, Register value_klass) {\n+  \/\/ value_copy implementation is fairly complex, and there are not any\n+  \/\/ \"short-cuts\" to be made from asm. What there is, appears to have the same\n+  \/\/ cost in C++, so just \"call_VM_leaf\" for now rather than maintain hundreds\n+  \/\/ of hand-rolled instructions...\n+  if (decorators & IS_DEST_UNINITIALIZED) {\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, BarrierSetRuntime::value_copy_is_dest_uninitialized), src, dst, value_klass);\n+  } else {\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, BarrierSetRuntime::value_copy), src, dst, value_klass);\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetAssembler_x86.cpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2019, Oracle and\/or its affiliates. All rights reserved.\n@@ -57,0 +57,3 @@\n+  virtual void value_copy(MacroAssembler* masm, DecoratorSet decorators,\n+                          Register src, Register dst, Register value_klass);\n+\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetAssembler_x86.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2793,0 +2793,33 @@\n+    if (tf()->returns_inline_type_as_fields() && !_method->is_method_handle_intrinsic()) {\n+      \/\/ The last return value is not set by the callee but used to pass IsInit information to compiled code.\n+      \/\/ Search for the corresponding projection, get the register and emit code that initialized it.\n+      uint con = (tf()->range_cc()->cnt() - 1);\n+      for (DUIterator_Fast imax, i = fast_outs(imax); i < imax; i++) {\n+        ProjNode* proj = fast_out(i)->as_Proj();\n+        if (proj->_con == con) {\n+          \/\/ Set IsInit if rax is non-null (a non-null value is returned buffered or scalarized)\n+          OptoReg::Name optoReg = ra_->get_reg_first(proj);\n+          VMReg reg = OptoReg::as_VMReg(optoReg, ra_->_framesize, OptoReg::reg2stack(ra_->_matcher._new_SP));\n+          Register toReg = reg->is_reg() ? reg->as_Register() : rscratch1;\n+          __ testq(rax, rax);\n+          __ setb(Assembler::notZero, toReg);\n+          __ movzbl(toReg, toReg);\n+          if (reg->is_stack()) {\n+            int st_off = reg->reg2stack() * VMRegImpl::stack_slot_size;\n+            __ movq(Address(rsp, st_off), toReg);\n+          }\n+          break;\n+        }\n+      }\n+      if (return_value_is_used()) {\n+        \/\/ An inline type is returned as fields in multiple registers.\n+        \/\/ Rax either contains an oop if the inline type is buffered or a pointer\n+        \/\/ to the corresponding InlineKlass with the lowest bit set to 1. Zero rax\n+        \/\/ if the lowest bit is set to allow C2 to use the oop after null checking.\n+        \/\/ rax &= (rax & 1) - 1\n+        __ movptr(rscratch1, rax);\n+        __ andptr(rscratch1, 0x1);\n+        __ subptr(rscratch1, 0x1);\n+        __ andptr(rax, rscratch1);\n+      }\n+    }\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":33,"deletions":0,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -727,0 +727,11 @@\n+\n+      \/\/ If inline types are passed as fields, use the extended signature\n+      \/\/ which contains the types of all (oop) fields of the inline type.\n+      if (is_compiled_by_c2() && callee->has_scalarized_args()) {\n+        const GrowableArray<SigEntry>* sig = callee->adapter()->get_sig_cc();\n+        assert(sig != nullptr, \"sig should never be null\");\n+        TempNewSymbol tmp_sig = SigEntry::create_symbol(sig);\n+        has_receiver = false; \/\/ The extended signature contains the receiver type\n+        fr.oops_compiled_arguments_do(tmp_sig, has_receiver, has_appendix, reg_map, f);\n+        return;\n+      }\n@@ -1257,0 +1268,4 @@\n+\n+  _inline_entry_point             = entry_point();\n+  _verified_inline_entry_point    = verified_entry_point();\n+  _verified_inline_ro_entry_point = verified_entry_point();\n@@ -1294,1 +1309,1 @@\n-\n+    assert(!method->has_scalarized_args(), \"scalarized native wrappers not supported yet\");\n@@ -1502,0 +1517,3 @@\n+    _inline_entry_point             = code_begin() + offsets->value(CodeOffsets::Inline_Entry);\n+    _verified_inline_entry_point    = code_begin() + offsets->value(CodeOffsets::Verified_Inline_Entry);\n+    _verified_inline_ro_entry_point = code_begin() + offsets->value(CodeOffsets::Verified_Inline_Entry_RO);\n@@ -3665,0 +3683,1 @@\n+  if (pos == inline_entry_point())                                      label = \"[Inline Entry Point]\";\n@@ -3666,0 +3685,2 @@\n+  if (pos == verified_inline_entry_point())                             label = \"[Verified Inline Entry Point]\";\n+  if (pos == verified_inline_ro_entry_point())                          label = \"[Verified Inline Entry Point (RO)]\";\n@@ -3675,0 +3696,10 @@\n+static int maybe_print_entry_label(outputStream* stream, address pos, address entry, const char* label) {\n+  if (pos == entry) {\n+    stream->bol();\n+    stream->print_cr(\"%s\", label);\n+    return 1;\n+  } else {\n+    return 0;\n+  }\n+}\n+\n@@ -3677,33 +3708,12 @@\n-    const char* label = nmethod_section_label(block_begin);\n-    if (label != nullptr) {\n-      stream->bol();\n-      stream->print_cr(\"%s\", label);\n-    }\n-  }\n-\n-  if (block_begin == entry_point()) {\n-    Method* m = method();\n-    if (m != nullptr) {\n-      stream->print(\"  # \");\n-      m->print_value_on(stream);\n-      stream->cr();\n-    }\n-    if (m != nullptr && !is_osr_method()) {\n-      ResourceMark rm;\n-      int sizeargs = m->size_of_parameters();\n-      BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, sizeargs);\n-      VMRegPair* regs   = NEW_RESOURCE_ARRAY(VMRegPair, sizeargs);\n-      {\n-        int sig_index = 0;\n-        if (!m->is_static())\n-          sig_bt[sig_index++] = T_OBJECT; \/\/ 'this'\n-        for (SignatureStream ss(m->signature()); !ss.at_return_type(); ss.next()) {\n-          BasicType t = ss.type();\n-          sig_bt[sig_index++] = t;\n-          if (type2size[t] == 2) {\n-            sig_bt[sig_index++] = T_VOID;\n-          } else {\n-            assert(type2size[t] == 1, \"size is 1 or 2\");\n-          }\n-        }\n-        assert(sig_index == sizeargs, \"\");\n+    int n = 0;\n+    \/\/ Multiple entry points may be at the same position. Print them all.\n+    n += maybe_print_entry_label(stream, block_begin, entry_point(),                    \"[Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, inline_entry_point(),             \"[Inline Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, verified_entry_point(),           \"[Verified Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, verified_inline_entry_point(),    \"[Verified Inline Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, verified_inline_ro_entry_point(), \"[Verified Inline Entry Point (RO)]\");\n+    if (n == 0) {\n+      const char* label = nmethod_section_label(block_begin);\n+      if (label != nullptr) {\n+        stream->bol();\n+        stream->print_cr(\"%s\", label);\n@@ -3711,54 +3721,63 @@\n-      const char* spname = \"sp\"; \/\/ make arch-specific?\n-      SharedRuntime::java_calling_convention(sig_bt, regs, sizeargs);\n-      int stack_slot_offset = this->frame_size() * wordSize;\n-      int tab1 = 14, tab2 = 24;\n-      int sig_index = 0;\n-      int arg_index = (m->is_static() ? 0 : -1);\n-      bool did_old_sp = false;\n-      for (SignatureStream ss(m->signature()); !ss.at_return_type(); ) {\n-        bool at_this = (arg_index == -1);\n-        bool at_old_sp = false;\n-        BasicType t = (at_this ? T_OBJECT : ss.type());\n-        assert(t == sig_bt[sig_index], \"sigs in sync\");\n-        if (at_this)\n-          stream->print(\"  # this: \");\n-        else\n-          stream->print(\"  # parm%d: \", arg_index);\n-        stream->move_to(tab1);\n-        VMReg fst = regs[sig_index].first();\n-        VMReg snd = regs[sig_index].second();\n-        if (fst->is_reg()) {\n-          stream->print(\"%s\", fst->name());\n-          if (snd->is_valid())  {\n-            stream->print(\":%s\", snd->name());\n-          }\n-        } else if (fst->is_stack()) {\n-          int offset = fst->reg2stack() * VMRegImpl::stack_slot_size + stack_slot_offset;\n-          if (offset == stack_slot_offset)  at_old_sp = true;\n-          stream->print(\"[%s+0x%x]\", spname, offset);\n-        } else {\n-          stream->print(\"reg%d:%d??\", (int)(intptr_t)fst, (int)(intptr_t)snd);\n-        }\n-        stream->print(\" \");\n-        stream->move_to(tab2);\n-        stream->print(\"= \");\n-        if (at_this) {\n-          m->method_holder()->print_value_on(stream);\n-        } else {\n-          bool did_name = false;\n-          if (!at_this && ss.is_reference()) {\n-            Symbol* name = ss.as_symbol();\n-            name->print_value_on(stream);\n-            did_name = true;\n-          }\n-          if (!did_name)\n-            stream->print(\"%s\", type2name(t));\n-        }\n-        if (at_old_sp) {\n-          stream->print(\"  (%s of caller)\", spname);\n-          did_old_sp = true;\n-        }\n-        stream->cr();\n-        sig_index += type2size[t];\n-        arg_index += 1;\n-        if (!at_this)  ss.next();\n+    }\n+  }\n+\n+  Method* m = method();\n+  if (m == nullptr || is_osr_method()) {\n+    return;\n+  }\n+\n+  \/\/ Print the name of the method (only once)\n+  address low = MIN4(entry_point(), verified_entry_point(), verified_inline_entry_point(), verified_inline_ro_entry_point());\n+  low = MIN2(low, inline_entry_point());\n+  assert(low != 0, \"sanity\");\n+  if (block_begin == low) {\n+    stream->print(\"  # \");\n+    m->print_value_on(stream);\n+    stream->cr();\n+  }\n+\n+  \/\/ Print the arguments for the 3 types of verified entry points\n+  CompiledEntrySignature ces(m);\n+  ces.compute_calling_conventions(false);\n+  const GrowableArray<SigEntry>* sig_cc;\n+  const VMRegPair* regs;\n+  if (block_begin == verified_entry_point()) {\n+    sig_cc = ces.sig_cc();\n+    regs = ces.regs_cc();\n+  } else if (block_begin == verified_inline_entry_point()) {\n+    sig_cc = ces.sig();\n+    regs = ces.regs();\n+  } else if (block_begin == verified_inline_ro_entry_point()) {\n+    sig_cc = ces.sig_cc_ro();\n+    regs = ces.regs_cc_ro();\n+  } else {\n+    return;\n+  }\n+\n+  bool has_this = !m->is_static();\n+  if (ces.has_inline_recv() && block_begin == verified_entry_point()) {\n+    \/\/ <this> argument is scalarized for verified_entry_point()\n+    has_this = false;\n+  }\n+  const char* spname = \"sp\"; \/\/ make arch-specific?\n+  int stack_slot_offset = this->frame_size() * wordSize;\n+  int tab1 = 14, tab2 = 24;\n+  int sig_index = 0;\n+  int arg_index = has_this ? -1 : 0;\n+  bool did_old_sp = false;\n+  for (ExtendedSignature sig = ExtendedSignature(sig_cc, SigEntryFilter()); !sig.at_end(); ++sig) {\n+    bool at_this = (arg_index == -1);\n+    bool at_old_sp = false;\n+    BasicType t = (*sig)._bt;\n+    if (at_this) {\n+      stream->print(\"  # this: \");\n+    } else {\n+      stream->print(\"  # parm%d: \", arg_index);\n+    }\n+    stream->move_to(tab1);\n+    VMReg fst = regs[sig_index].first();\n+    VMReg snd = regs[sig_index].second();\n+    if (fst->is_reg()) {\n+      stream->print(\"%s\", fst->name());\n+      if (snd->is_valid())  {\n+        stream->print(\":%s\", snd->name());\n@@ -3766,6 +3785,18 @@\n-      if (!did_old_sp) {\n-        stream->print(\"  # \");\n-        stream->move_to(tab1);\n-        stream->print(\"[%s+0x%x]\", spname, stack_slot_offset);\n-        stream->print(\"  (%s of caller)\", spname);\n-        stream->cr();\n+    } else if (fst->is_stack()) {\n+      int offset = fst->reg2stack() * VMRegImpl::stack_slot_size + stack_slot_offset;\n+      if (offset == stack_slot_offset)  at_old_sp = true;\n+      stream->print(\"[%s+0x%x]\", spname, offset);\n+    } else {\n+      stream->print(\"reg%d:%d??\", (int)(intptr_t)fst, (int)(intptr_t)snd);\n+    }\n+    stream->print(\" \");\n+    stream->move_to(tab2);\n+    stream->print(\"= \");\n+    if (at_this) {\n+      m->method_holder()->print_value_on(stream);\n+    } else {\n+      bool did_name = false;\n+      if (is_reference_type(t)) {\n+        Symbol* name = (*sig)._symbol;\n+        name->print_value_on(stream);\n+        did_name = true;\n@@ -3773,0 +3804,2 @@\n+      if (!did_name)\n+        stream->print(\"%s\", type2name(t));\n@@ -3774,0 +3807,14 @@\n+    if (at_old_sp) {\n+      stream->print(\"  (%s of caller)\", spname);\n+      did_old_sp = true;\n+    }\n+    stream->cr();\n+    sig_index += type2size[t];\n+    arg_index += 1;\n+  }\n+  if (!did_old_sp) {\n+    stream->print(\"  # \");\n+    stream->move_to(tab1);\n+    stream->print(\"[%s+0x%x]\", spname, stack_slot_offset);\n+    stream->print(\"  (%s of caller)\", spname);\n+    stream->cr();\n@@ -3897,1 +3944,1 @@\n-      st->print(\" {reexecute=%d rethrow=%d return_oop=%d}\", sd->should_reexecute(), sd->rethrow_exception(), sd->return_oop());\n+      st->print(\" {reexecute=%d rethrow=%d return_oop=%d return_scalarized=%d}\", sd->should_reexecute(), sd->rethrow_exception(), sd->return_oop(), sd->return_scalarized());\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":142,"deletions":95,"binary":false,"changes":237,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"compiler\/compilerDefinitions.hpp\"\n@@ -216,0 +217,4 @@\n+  \/\/ TODO: can these be uint16_t, seem rely on -1 CodeOffset, can change later...\n+  address _inline_entry_point;              \/\/ inline type entry point (unpack all inline type args) with class check\n+  address _verified_inline_entry_point;     \/\/ inline type entry point (unpack all inline type args) without class check\n+  address _verified_inline_ro_entry_point;  \/\/ inline type entry point (unpack receiver only) without class check\n@@ -612,0 +617,3 @@\n+  address inline_entry_point() const              { return _inline_entry_point; }             \/\/ inline type entry point (unpack all inline type args)\n+  address verified_inline_entry_point() const     { return _verified_inline_entry_point; }    \/\/ inline type entry point (unpack all inline type args) without class check\n+  address verified_inline_ro_entry_point() const  { return _verified_inline_ro_entry_point; } \/\/ inline type entry point (only unpack receiver) without class check\n@@ -684,0 +692,10 @@\n+  bool  needs_stack_repair() const {\n+    if (is_compiled_by_c1()) {\n+      return method()->c1_needs_stack_repair();\n+    } else if (is_compiled_by_c2()) {\n+      return method()->c2_needs_stack_repair();\n+    } else {\n+      return false;\n+    }\n+  }\n+\n","filename":"src\/hotspot\/share\/code\/nmethod.hpp","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -1255,1 +1255,1 @@\n-          if (vfst.method()->is_static_initializer() ||\n+        if (vfst.method()->is_class_initializer() ||\n","filename":"src\/hotspot\/share\/compiler\/compileBroker.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -60,1 +60,1 @@\n-static GrowableArray<const char*>* phase_names = nullptr;\n+static GrowableArray<const char*>* _phase_names = nullptr;\n@@ -66,3 +66,3 @@\n-    assert(phase_names != nullptr, \"invariant\");\n-    assert(phase_names->is_nonempty(), \"invariant\");\n-    const u4 nof_entries = phase_names->length();\n+    assert(_phase_names != nullptr, \"invariant\");\n+    assert(_phase_names->is_nonempty(), \"invariant\");\n+    const u4 nof_entries = _phase_names->length();\n@@ -72,1 +72,1 @@\n-      writer.write(phase_names->at(i));\n+      writer.write(_phase_names->at(i));\n@@ -78,2 +78,2 @@\n-  for (int i = 0; i < phase_names->length(); i++) {\n-    const char* name = phase_names->at(i);\n+  for (int i = 0; i < _phase_names->length(); i++) {\n+    const char* name = _phase_names->at(i);\n@@ -92,2 +92,2 @@\n-    if (phase_names == nullptr) {\n-      phase_names = new (mtInternal) GrowableArray<const char*>(100, mtCompiler);\n+    if (_phase_names == nullptr) {\n+      _phase_names = new (mtInternal) GrowableArray<const char*>(100, mtCompiler);\n@@ -104,2 +104,2 @@\n-    index = phase_names->length();\n-    phase_names->append(use_strdup ? os::strdup(phase_name) : phase_name);\n+    index = _phase_names->length();\n+    _phase_names->append(use_strdup ? os::strdup(phase_name) : phase_name);\n","filename":"src\/hotspot\/share\/compiler\/compilerEvent.cpp","additions":11,"deletions":11,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -52,0 +52,4 @@\n+Node* C2ParseAccess::control() const {\n+  return _ctl == nullptr ? _kit->control() : _ctl;\n+}\n+\n@@ -184,1 +188,1 @@\n-    Node* control = control_dependent ? kit->control() : nullptr;\n+    Node* control = control_dependent ? parse_access.control() : nullptr;\n@@ -818,1 +822,1 @@\n-  phase->igvn().replace_node(ac, call);\n+  phase->replace_node(ac, call);\n","filename":"src\/hotspot\/share\/gc\/shared\/c2\/barrierSetC2.cpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -150,0 +150,1 @@\n+  Node* _ctl;\n@@ -155,1 +156,2 @@\n-                BasicType type, Node* base, C2AccessValuePtr& addr) :\n+                BasicType type, Node* base, C2AccessValuePtr& addr,\n+                Node* ctl = nullptr) :\n@@ -157,1 +159,2 @@\n-    _kit(kit) {\n+    _kit(kit),\n+    _ctl(ctl) {\n@@ -162,0 +165,1 @@\n+  Node* control() const;\n@@ -281,1 +285,1 @@\n-  virtual void clone(GraphKit* kit, Node* src, Node* dst, Node* size, bool is_array) const;\n+  virtual void clone(GraphKit* kit, Node* src_base, Node* dst_base, Node* size, bool is_array) const;\n@@ -309,1 +313,1 @@\n-  virtual void eliminate_gc_barrier(PhaseMacroExpand* macro, Node* node) const { }\n+  virtual void eliminate_gc_barrier(PhaseIterGVN* igvn, Node* node) const { }\n","filename":"src\/hotspot\/share\/gc\/shared\/c2\/barrierSetC2.hpp","additions":8,"deletions":4,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -374,2 +374,1 @@\n-  \/\/ May be bootstrapping\n-  oopDesc::set_mark(mem, markWord::prototype());\n+  oopDesc::set_mark(mem, Klass::default_prototype_header(_klass));\n@@ -388,0 +387,6 @@\n+oop ObjBufferAllocator::initialize(HeapWord* mem) const {\n+  oopDesc::set_klass_gap(mem, 0);\n+  return finish(mem);\n+}\n+\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/memAllocator.cpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -95,0 +95,8 @@\n+class ObjBufferAllocator: public MemAllocator {\n+public:\n+  ObjBufferAllocator(Klass* klass, size_t word_size, Thread* thread = Thread::current())\n+    : MemAllocator(klass, word_size, thread) {}\n+  virtual oop initialize(HeapWord* mem) const;\n+};\n+\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/memAllocator.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -436,1 +436,1 @@\n-    if (is_reference_type(bt)) {\n+    if (is_reference_type(bt) && !ary_ptr->is_flat()) {\n@@ -462,1 +462,1 @@\n-        length = phase->transform_later(new SubLNode(length, phase->longcon(1))); \/\/ Size is in longs\n+        length = phase->transform_later(new SubXNode(length, phase->longcon(1))); \/\/ Size is in longs\n@@ -507,1 +507,1 @@\n-  phase->igvn().replace_node(ac, call);\n+  phase->replace_node(ac, call);\n@@ -847,1 +847,2 @@\n-void ZBarrierSetC2::eliminate_gc_barrier(PhaseMacroExpand* macro, Node* node) const {\n+\n+void ZBarrierSetC2::eliminate_gc_barrier(PhaseIterGVN* igvn, Node* node) const {\n","filename":"src\/hotspot\/share\/gc\/z\/c2\/zBarrierSetC2.cpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -135,1 +135,1 @@\n-  virtual void eliminate_gc_barrier(PhaseMacroExpand* macro, Node* node) const;\n+  virtual void eliminate_gc_barrier(PhaseIterGVN* igvn, Node* node) const;\n","filename":"src\/hotspot\/share\/gc\/z\/c2\/zBarrierSetC2.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -521,0 +522,1 @@\n+\n@@ -967,1 +969,2 @@\n-             cmp1->is_SubTypeCheck() || cmp2->is_SubTypeCheck()) {\n+             cmp1->is_SubTypeCheck() || cmp2->is_SubTypeCheck() ||\n+             cmp1->is_FlatArrayCheck() || cmp2->is_FlatArrayCheck()) {\n@@ -1046,1 +1049,1 @@\n-\/\/ note that these functions assume that the _adr_type field is flattened\n+\/\/ note that these functions assume that the _adr_type field is flat\n@@ -1064,1 +1067,1 @@\n-  assert(t != Type::MEMORY || at == flatten_phi_adr_type(at), \"flatten at\");\n+  assert(t != Type::MEMORY || at == flatten_phi_adr_type(at) || (flatten_phi_adr_type(at) == TypeAryPtr::INLINES && Compile::current()->flat_accesses_share_alias()), \"flatten at\");\n@@ -1192,0 +1195,8 @@\n+  \/\/ Flat array element shouldn't get their own memory slice until flat_accesses_share_alias is cleared.\n+  \/\/ It could be the graph has no loads\/stores and flat_accesses_share_alias is never cleared. EA could still\n+  \/\/ creates per element Phis but that wouldn't be a problem as there are no memory accesses for that array.\n+  assert(_adr_type == nullptr || _adr_type->isa_aryptr() == nullptr ||\n+         _adr_type->is_aryptr()->is_known_instance() ||\n+         !_adr_type->is_aryptr()->is_flat() ||\n+         !Compile::current()->flat_accesses_share_alias() ||\n+         _adr_type == TypeAryPtr::INLINES, \"flat array element shouldn't get its own slice yet\");\n@@ -1410,0 +1421,1 @@\n+\n@@ -2030,0 +2042,46 @@\n+\/\/ Push inline type input nodes (and null) down through the phi recursively (can handle data loops).\n+InlineTypeNode* PhiNode::push_inline_types_down(PhaseGVN* phase, bool can_reshape, ciInlineKlass* inline_klass) {\n+  assert(inline_klass != nullptr, \"must be\");\n+  InlineTypeNode* vt = InlineTypeNode::make_null(*phase, inline_klass, \/* transform = *\/ false)->clone_with_phis(phase, in(0), nullptr, !_type->maybe_null());\n+  if (can_reshape) {\n+    \/\/ Replace phi right away to be able to use the inline\n+    \/\/ type node when reaching the phi again through data loops.\n+    PhaseIterGVN* igvn = phase->is_IterGVN();\n+    for (DUIterator_Fast imax, i = fast_outs(imax); i < imax; i++) {\n+      Node* u = fast_out(i);\n+      igvn->rehash_node_delayed(u);\n+      imax -= u->replace_edge(this, vt);\n+      --i;\n+    }\n+    igvn->rehash_node_delayed(this);\n+    assert(outcnt() == 0, \"should be dead now\");\n+  }\n+  ResourceMark rm;\n+  Node_List casts;\n+  for (uint i = 1; i < req(); ++i) {\n+    Node* n = in(i);\n+    while (n->is_ConstraintCast()) {\n+      casts.push(n);\n+      n = n->in(1);\n+    }\n+    if (phase->type(n)->is_zero_type()) {\n+      n = InlineTypeNode::make_null(*phase, inline_klass);\n+    } else if (n->is_Phi()) {\n+      assert(can_reshape, \"can only handle phis during IGVN\");\n+      n = phase->transform(n->as_Phi()->push_inline_types_down(phase, can_reshape, inline_klass));\n+    }\n+    while (casts.size() != 0) {\n+      \/\/ Push the cast(s) through the InlineTypeNode\n+      \/\/ TODO 8302217 Can we avoid cloning? See InlineTypeNode::clone_if_required\n+      Node* cast = casts.pop()->clone();\n+      cast->set_req_X(1, n->as_InlineType()->get_oop(), phase);\n+      n = n->clone();\n+      n->as_InlineType()->set_oop(*phase, phase->transform(cast));\n+      n = phase->transform(n);\n+    }\n+    bool transform = !can_reshape && (i == (req()-1)); \/\/ Transform phis on last merge\n+    vt->merge_with(phase, n->as_InlineType(), i, transform);\n+  }\n+  return vt;\n+}\n+\n@@ -2362,0 +2420,2 @@\n+    \/\/ TODO revisit this with JDK-8247216\n+    bool mergemem_only = true;\n@@ -2374,0 +2434,2 @@\n+      } else {\n+        mergemem_only = false;\n@@ -2378,1 +2440,1 @@\n-    if (!saw_self && adr_type() == TypePtr::BOTTOM)  merge_width = 0;\n+    if (!mergemem_only && !saw_self && adr_type() == TypePtr::BOTTOM)  merge_width = 0;\n@@ -2449,0 +2511,5 @@\n+            if (igvn) {\n+              \/\/ TODO revisit this with JDK-8247216\n+              \/\/ Put 'n' on the worklist because it might be modified by MergeMemStream::iteration_setup\n+              igvn->_worklist.push(n);\n+            }\n@@ -2567,0 +2634,5 @@\n+  Node* inline_type = try_push_inline_types_down(phase, can_reshape);\n+  if (inline_type != this) {\n+    return inline_type;\n+  }\n+\n@@ -2610,0 +2682,84 @@\n+\/\/ Check recursively if inputs are either an inline type, constant null\n+\/\/ or another Phi (including self references through data loops). If so,\n+\/\/ push the inline types down through the phis to enable folding of loads.\n+Node* PhiNode::try_push_inline_types_down(PhaseGVN* phase, const bool can_reshape) {\n+  if (!can_be_inline_type()) {\n+    return this;\n+  }\n+\n+  ciInlineKlass* inline_klass;\n+  if (can_push_inline_types_down(phase, can_reshape, inline_klass)) {\n+    assert(inline_klass != nullptr, \"must be\");\n+    return push_inline_types_down(phase, can_reshape, inline_klass);\n+  }\n+  return this;\n+}\n+\n+bool PhiNode::can_push_inline_types_down(PhaseGVN* phase, const bool can_reshape, ciInlineKlass*& inline_klass) {\n+  if (req() <= 2) {\n+    \/\/ Dead phi.\n+    return false;\n+  }\n+  inline_klass = nullptr;\n+\n+  \/\/ TODO 8302217 We need to prevent endless pushing through\n+  bool only_phi = (outcnt() != 0);\n+  for (DUIterator_Fast imax, i = fast_outs(imax); i < imax; i++) {\n+    Node* n = fast_out(i);\n+    if (n->is_InlineType() && n->in(1) == this) {\n+      return false;\n+    }\n+    if (!n->is_Phi()) {\n+      only_phi = false;\n+    }\n+  }\n+  if (only_phi) {\n+    return false;\n+  }\n+\n+  ResourceMark rm;\n+  Unique_Node_List worklist;\n+  worklist.push(this);\n+  Node_List casts;\n+\n+  for (uint next = 0; next < worklist.size(); next++) {\n+    Node* phi = worklist.at(next);\n+    for (uint i = 1; i < phi->req(); i++) {\n+      Node* n = phi->in(i);\n+      if (n == nullptr) {\n+        return false;\n+      }\n+      while (n->is_ConstraintCast()) {\n+        if (n->in(0) != nullptr && n->in(0)->is_top()) {\n+          \/\/ Will die, don't optimize\n+          return false;\n+        }\n+        casts.push(n);\n+        n = n->in(1);\n+      }\n+      const Type* type = phase->type(n);\n+      if (n->is_InlineType() && (inline_klass == nullptr || inline_klass == type->inline_klass())) {\n+        inline_klass = type->inline_klass();\n+      } else if (n->is_Phi() && can_reshape && n->bottom_type()->isa_ptr()) {\n+        worklist.push(n);\n+      } else if (!type->is_zero_type()) {\n+        return false;\n+      }\n+    }\n+  }\n+  if (inline_klass == nullptr) {\n+    return false;\n+  }\n+\n+  \/\/ Check if cast nodes can be pushed through\n+  const Type* t = Type::get_const_type(inline_klass);\n+  while (casts.size() != 0 && t != nullptr) {\n+    Node* cast = casts.pop();\n+    if (t->filter(cast->bottom_type()) == Type::TOP) {\n+      return false;\n+    }\n+  }\n+\n+  return true;\n+}\n+\n@@ -2992,0 +3148,6 @@\n+\n+  \/\/ CheckCastPPNode::Ideal() for inline types reuses the exception\n+  \/\/ paths of a call to perform an allocation: we can see a Phi here.\n+  if (in(1)->is_Phi()) {\n+    return this;\n+  }\n","filename":"src\/hotspot\/share\/opto\/cfgnode.cpp","additions":166,"deletions":4,"binary":false,"changes":170,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n@@ -27,0 +28,1 @@\n+#include \"classfile\/systemDictionary.hpp\"\n@@ -41,0 +43,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -234,0 +237,2 @@\n+                     ->cast_to_not_flat(t_oop->is_aryptr()->is_not_flat())\n+                     ->cast_to_not_null_free(t_oop->is_aryptr()->is_not_null_free())\n@@ -260,1 +265,1 @@\n-               tp->isa_aryptr() &&        tp->offset() == Type::OffsetBot &&\n+        tp->isa_aryptr() &&        tp->offset() == Type::OffsetBot &&\n@@ -994,1 +999,1 @@\n-    return (eliminate_boxing && non_volatile) || is_stable_ary;\n+    return (eliminate_boxing && non_volatile) || is_stable_ary || tp->is_inlinetypeptr();\n@@ -1051,1 +1056,1 @@\n-      uint shift  = exact_log2(type2aelembytes(ary_elem));\n+      uint shift  = ary_t->is_flat() ? ary_t->flat_log_elem_size() : exact_log2(type2aelembytes(ary_elem));\n@@ -1170,1 +1175,1 @@\n-        const TypeVect* out_vt = as_LoadVector()->vect_type();\n+        const TypeVect* out_vt = is_Load() ? as_LoadVector()->vect_type() : as_StoreVector()->vect_type();\n@@ -1188,0 +1193,5 @@\n+      Node* default_value = ld_alloc->in(AllocateNode::DefaultValue);\n+      if (default_value != nullptr) {\n+        return default_value;\n+      }\n+      assert(ld_alloc->in(AllocateNode::RawDefaultValue) == nullptr, \"default value may not be null\");\n@@ -1255,0 +1265,17 @@\n+  \/\/ Loading from an InlineType? The InlineType has the values of\n+  \/\/ all fields as input. Look for the field with matching offset.\n+  Node* addr = in(Address);\n+  intptr_t offset;\n+  Node* base = AddPNode::Ideal_base_and_offset(addr, phase, offset);\n+  if (base != nullptr && base->is_InlineType() && offset > oopDesc::klass_offset_in_bytes()) {\n+    Node* value = base->as_InlineType()->field_value_by_offset((int)offset, true);\n+    if (value != nullptr) {\n+      if (Opcode() == Op_LoadN) {\n+        \/\/ Encode oop value if we are loading a narrow oop\n+        assert(!phase->type(value)->isa_narrowoop(), \"should already be decoded\");\n+        value = phase->transform(new EncodePNode(value, bottom_type()));\n+      }\n+      return value;\n+    }\n+  }\n+\n@@ -2018,0 +2045,1 @@\n+        && !ary->is_flat()\n@@ -2053,0 +2081,2 @@\n+            \/\/ Default value load\n+            tp->is_instptr()->instance_klass() == ciEnv::current()->Class_klass() ||\n@@ -2058,1 +2088,3 @@\n-    \/\/ Optimize loads from constant fields.\n+    BasicType bt = memory_type();\n+\n+    \/\/ Optimize loads from constant fields.\n@@ -2062,1 +2094,1 @@\n-      const Type* con_type = Type::make_constant_from_field(const_oop->as_instance(), off, is_unsigned(), memory_type());\n+      const Type* con_type = Type::make_constant_from_field(const_oop->as_instance(), off, is_unsigned(), bt);\n@@ -2197,1 +2229,0 @@\n-\n@@ -2200,1 +2231,10 @@\n-    return TypeX::make(markWord::prototype().value());\n+    if (EnableValhalla) {\n+      \/\/ The mark word may contain property bits (inline, flat, null-free)\n+      Node* klass_node = alloc->in(AllocateNode::KlassNode);\n+      const TypeKlassPtr* tkls = phase->type(klass_node)->isa_klassptr();\n+      if (tkls != nullptr && tkls->is_loaded() && tkls->klass_is_exact()) {\n+        return TypeX::make(tkls->exact_klass()->prototype_header().value());\n+      }\n+    } else {\n+      return TypeX::make(markWord::prototype().value());\n+    }\n@@ -2351,1 +2391,2 @@\n-Node* LoadKlassNode::make(PhaseGVN& gvn, Node* ctl, Node* mem, Node* adr, const TypePtr* at, const TypeKlassPtr* tk) {\n+Node* LoadKlassNode::make(PhaseGVN& gvn, Node* ctl, Node* mem, Node* adr, const TypePtr* at,\n+                          const TypeKlassPtr* tk) {\n@@ -2398,1 +2439,2 @@\n-      ciType* t = tinst->java_mirror_type();\n+      bool is_null_free_array = false;\n+      ciType* t = tinst->java_mirror_type(&is_null_free_array);\n@@ -2408,1 +2450,5 @@\n-          return TypeKlassPtr::make(ciArrayKlass::make(t), Type::trust_interfaces);\n+          const TypeKlassPtr* tklass = TypeKlassPtr::make(ciArrayKlass::make(t), Type::trust_interfaces);\n+          if (is_null_free_array) {\n+            tklass = tklass->is_aryklassptr()->cast_to_null_free();\n+          }\n+          return tklass;\n@@ -2415,1 +2461,5 @@\n-        return TypeKlassPtr::make(t->as_klass(), Type::trust_interfaces);\n+        const TypeKlassPtr* tklass = TypeKlassPtr::make(t->as_klass(), Type::trust_interfaces);\n+        if (is_null_free_array) {\n+          tklass = tklass->is_aryklassptr()->cast_to_null_free();\n+        }\n+        return tklass;\n@@ -2427,1 +2477,1 @@\n-  const TypeAryPtr *tary = tp->isa_aryptr();\n+  const TypeAryPtr* tary = tp->isa_aryptr();\n@@ -3401,1 +3451,1 @@\n-  {\n+  if (phase->C->get_adr_type(phase->C->get_alias_index(adr_type())) != TypeAryPtr::INLINES) {\n@@ -3421,0 +3471,1 @@\n+             (Opcode() == Op_StoreL && st->Opcode() == Op_StoreN) ||\n@@ -3529,2 +3580,1 @@\n-  if (result == this &&\n-      ReduceFieldZeroing && phase->type(val)->is_zero_type()) {\n+  if (result == this && ReduceFieldZeroing) {\n@@ -3532,1 +3582,2 @@\n-    if (mem->is_Proj() && mem->in(0)->is_Allocate()) {\n+    if (mem->is_Proj() && mem->in(0)->is_Allocate() &&\n+        (phase->type(val)->is_zero_type() || mem->in(0)->in(AllocateNode::DefaultValue) == val)) {\n@@ -3536,1 +3587,1 @@\n-    if (result == this) {\n+    if (result == this && phase->type(val)->is_zero_type()) {\n@@ -3721,3 +3772,7 @@\n-    Node* mem = my_store->as_MergeMem()->memory_at(oop_alias_idx());\n-    set_req_X(MemNode::OopStore, mem, phase);\n-    return this;\n+    if (oop_alias_idx() != phase->C->get_alias_index(TypeAryPtr::INLINES) ||\n+        phase->C->flat_accesses_share_alias()) {\n+      \/\/ The alias that was recorded is no longer accurate enough.\n+      Node* mem = my_store->as_MergeMem()->memory_at(oop_alias_idx());\n+      set_req_X(MemNode::OopStore, mem, phase);\n+      return this;\n+    }\n@@ -3894,1 +3949,1 @@\n-    return new ClearArrayNode(in(0), in(1), in(2), in(3), true);\n+    return new ClearArrayNode(in(0), in(1), in(2), in(3), in(4), true);\n@@ -3912,1 +3967,1 @@\n-  Node *zero = phase->makecon(TypeLong::ZERO);\n+  Node *val = in(4);\n@@ -3914,1 +3969,1 @@\n-  mem = new StoreLNode(in(0),mem,adr,atp,zero,MemNode::unordered,false);\n+  mem = new StoreLNode(in(0), mem, adr, atp, val, MemNode::unordered, false);\n@@ -3919,1 +3974,1 @@\n-    mem = new StoreLNode(in(0),mem,adr,atp,zero,MemNode::unordered,false);\n+    mem = new StoreLNode(in(0), mem, adr, atp, val, MemNode::unordered, false);\n@@ -3953,0 +4008,2 @@\n+                                   Node* val,\n+                                   Node* raw_val,\n@@ -3963,1 +4020,7 @@\n-    mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase->zerocon(T_INT), T_INT, MemNode::unordered);\n+    if (val != nullptr) {\n+      assert(phase->type(val)->isa_narrowoop(), \"should be narrow oop\");\n+      mem = new StoreNNode(ctl, mem, adr, atp, val, MemNode::unordered);\n+    } else {\n+      assert(raw_val == nullptr, \"val may not be null\");\n+      mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase->zerocon(T_INT), T_INT, MemNode::unordered);\n+    }\n@@ -3970,1 +4033,1 @@\n-  return clear_memory(ctl, mem, dest, phase->MakeConX(offset), end_offset, phase);\n+  return clear_memory(ctl, mem, dest, raw_val, phase->MakeConX(offset), end_offset, phase);\n@@ -3974,0 +4037,1 @@\n+                                   Node* raw_val,\n@@ -3996,1 +4060,4 @@\n-  mem = new ClearArrayNode(ctl, mem, zsize, adr, false);\n+  if (raw_val == nullptr) {\n+    raw_val = phase->MakeConX(0);\n+  }\n+  mem = new ClearArrayNode(ctl, mem, zsize, adr, raw_val, false);\n@@ -4001,0 +4068,2 @@\n+                                   Node* val,\n+                                   Node* raw_val,\n@@ -4015,1 +4084,1 @@\n-    mem = clear_memory(ctl, mem, dest,\n+    mem = clear_memory(ctl, mem, dest, val, raw_val,\n@@ -4022,1 +4091,7 @@\n-    mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase->zerocon(T_INT), T_INT, MemNode::unordered);\n+    if (val != nullptr) {\n+      assert(phase->type(val)->isa_narrowoop(), \"should be narrow oop\");\n+      mem = new StoreNNode(ctl, mem, adr, atp, val, MemNode::unordered);\n+    } else {\n+      assert(raw_val == nullptr, \"val may not be null\");\n+      mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase->zerocon(T_INT), T_INT, MemNode::unordered);\n+    }\n@@ -4168,1 +4243,1 @@\n-Node *MemBarNode::match( const ProjNode *proj, const Matcher *m ) {\n+Node *MemBarNode::match(const ProjNode *proj, const Matcher *m, const RegMask* mask) {\n@@ -4455,1 +4530,3 @@\n-  if (init == nullptr || init->is_complete())  return false;\n+  if (init == nullptr || init->is_complete()) {\n+    return false;\n+  }\n@@ -4633,0 +4710,6 @@\n+                if (base->is_Phi()) {\n+                  \/\/ In rare case, base may be a PhiNode and it may read\n+                  \/\/ the same memory slice between InitializeNode and store.\n+                  failed = true;\n+                  break;\n+                }\n@@ -5219,0 +5302,2 @@\n+                                              allocation()->in(AllocateNode::DefaultValue),\n+                                              allocation()->in(AllocateNode::RawDefaultValue),\n@@ -5278,0 +5363,2 @@\n+                                            allocation()->in(AllocateNode::DefaultValue),\n+                                            allocation()->in(AllocateNode::RawDefaultValue),\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":119,"deletions":32,"binary":false,"changes":151,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -562,0 +563,3 @@\n+  if (n->is_InlineType()) {\n+    C->add_inline_type(n);\n+  }\n@@ -622,0 +626,3 @@\n+  if (is_InlineType()) {\n+    compile->remove_inline_type(this);\n+  }\n","filename":"src\/hotspot\/share\/opto\/node.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -26,0 +26,3 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n+#include \"ci\/ciField.hpp\"\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -52,0 +55,45 @@\n+const Type::Offset Type::Offset::top(Type::OffsetTop);\n+const Type::Offset Type::Offset::bottom(Type::OffsetBot);\n+\n+const Type::Offset Type::Offset::meet(const Type::Offset other) const {\n+  \/\/ Either is 'TOP' offset?  Return the other offset!\n+  if (_offset == OffsetTop) return other;\n+  if (other._offset == OffsetTop) return *this;\n+  \/\/ If either is different, return 'BOTTOM' offset\n+  if (_offset != other._offset) return bottom;\n+  return Offset(_offset);\n+}\n+\n+const Type::Offset Type::Offset::dual() const {\n+  if (_offset == OffsetTop) return bottom;\/\/ Map 'TOP' into 'BOTTOM'\n+  if (_offset == OffsetBot) return top;\/\/ Map 'BOTTOM' into 'TOP'\n+  return Offset(_offset);               \/\/ Map everything else into self\n+}\n+\n+const Type::Offset Type::Offset::add(intptr_t offset) const {\n+  \/\/ Adding to 'TOP' offset?  Return 'TOP'!\n+  if (_offset == OffsetTop || offset == OffsetTop) return top;\n+  \/\/ Adding to 'BOTTOM' offset?  Return 'BOTTOM'!\n+  if (_offset == OffsetBot || offset == OffsetBot) return bottom;\n+  \/\/ Addition overflows or \"accidentally\" equals to OffsetTop? Return 'BOTTOM'!\n+  offset += (intptr_t)_offset;\n+  if (offset != (int)offset || offset == OffsetTop) return bottom;\n+\n+  \/\/ assert( _offset >= 0 && _offset+offset >= 0, \"\" );\n+  \/\/ It is possible to construct a negative offset during PhaseCCP\n+\n+  return Offset((int)offset);        \/\/ Sum valid offsets\n+}\n+\n+void Type::Offset::dump2(outputStream *st) const {\n+  if (_offset == 0) {\n+    return;\n+  } else if (_offset == OffsetTop) {\n+    st->print(\"+top\");\n+  }\n+  else if (_offset == OffsetBot) {\n+    st->print(\"+bot\");\n+  } else if (_offset) {\n+    st->print(\"+%d\", _offset);\n+  }\n+}\n@@ -226,0 +274,3 @@\n+  case T_OBJECT:\n+    return Type::get_const_type(type->unwrap())->join_speculative(type->is_null_free() ? TypePtr::NOTNULL : TypePtr::BOTTOM);\n+\n@@ -538,3 +589,3 @@\n-  TypePtr::NULL_PTR= TypePtr::make(AnyPtr, TypePtr::Null, 0);\n-  TypePtr::NOTNULL = TypePtr::make(AnyPtr, TypePtr::NotNull, OffsetBot);\n-  TypePtr::BOTTOM  = TypePtr::make(AnyPtr, TypePtr::BotPTR, OffsetBot);\n+  TypePtr::NULL_PTR= TypePtr::make(AnyPtr, TypePtr::Null, Offset(0));\n+  TypePtr::NOTNULL = TypePtr::make(AnyPtr, TypePtr::NotNull, Offset::bottom);\n+  TypePtr::BOTTOM  = TypePtr::make(AnyPtr, TypePtr::BotPTR, Offset::bottom);\n@@ -557,1 +608,1 @@\n-                                           false, 0, oopDesc::mark_offset_in_bytes());\n+                                           false, 0, Offset(oopDesc::mark_offset_in_bytes()));\n@@ -559,2 +610,2 @@\n-                                           false, 0, oopDesc::klass_offset_in_bytes());\n-  TypeOopPtr::BOTTOM  = TypeOopPtr::make(TypePtr::BotPTR, OffsetBot, TypeOopPtr::InstanceBot);\n+                                           false, 0, Offset(oopDesc::klass_offset_in_bytes()));\n+  TypeOopPtr::BOTTOM  = TypeOopPtr::make(TypePtr::BotPTR, Offset::bottom, TypeOopPtr::InstanceBot);\n@@ -562,1 +613,1 @@\n-  TypeMetadataPtr::BOTTOM = TypeMetadataPtr::make(TypePtr::BotPTR, nullptr, OffsetBot);\n+  TypeMetadataPtr::BOTTOM = TypeMetadataPtr::make(TypePtr::BotPTR, nullptr, Offset::bottom);\n@@ -585,1 +636,1 @@\n-  TypeAryPtr::RANGE   = TypeAryPtr::make( TypePtr::BotPTR, TypeAry::make(Type::BOTTOM,TypeInt::POS), nullptr \/* current->env()->Object_klass() *\/, false, arrayOopDesc::length_offset_in_bytes());\n+  TypeAryPtr::RANGE   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::BOTTOM,TypeInt::POS), nullptr \/* current->env()->Object_klass() *\/, false, Offset(arrayOopDesc::length_offset_in_bytes()));\n@@ -587,1 +638,1 @@\n-  TypeAryPtr::NARROWOOPS = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeNarrowOop::BOTTOM, TypeInt::POS), nullptr \/*ciArrayKlass::make(o)*\/,  false,  Type::OffsetBot);\n+  TypeAryPtr::NARROWOOPS = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeNarrowOop::BOTTOM, TypeInt::POS), nullptr \/*ciArrayKlass::make(o)*\/,  false,  Offset::bottom);\n@@ -597,1 +648,1 @@\n-    TypeAryPtr::OOPS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInstPtr::BOTTOM,TypeInt::POS), nullptr \/*ciArrayKlass::make(o)*\/,  false,  Type::OffsetBot);\n+    TypeAryPtr::OOPS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInstPtr::BOTTOM,TypeInt::POS), nullptr \/*ciArrayKlass::make(o)*\/,  false,  Offset::bottom);\n@@ -599,7 +650,8 @@\n-  TypeAryPtr::BYTES   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::BYTE      ,TypeInt::POS), ciTypeArrayKlass::make(T_BYTE),   true,  Type::OffsetBot);\n-  TypeAryPtr::SHORTS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::SHORT     ,TypeInt::POS), ciTypeArrayKlass::make(T_SHORT),  true,  Type::OffsetBot);\n-  TypeAryPtr::CHARS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::CHAR      ,TypeInt::POS), ciTypeArrayKlass::make(T_CHAR),   true,  Type::OffsetBot);\n-  TypeAryPtr::INTS    = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::INT       ,TypeInt::POS), ciTypeArrayKlass::make(T_INT),    true,  Type::OffsetBot);\n-  TypeAryPtr::LONGS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeLong::LONG     ,TypeInt::POS), ciTypeArrayKlass::make(T_LONG),   true,  Type::OffsetBot);\n-  TypeAryPtr::FLOATS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::FLOAT        ,TypeInt::POS), ciTypeArrayKlass::make(T_FLOAT),  true,  Type::OffsetBot);\n-  TypeAryPtr::DOUBLES = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::DOUBLE       ,TypeInt::POS), ciTypeArrayKlass::make(T_DOUBLE), true,  Type::OffsetBot);\n+  TypeAryPtr::BYTES   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::BYTE      ,TypeInt::POS), ciTypeArrayKlass::make(T_BYTE),   true,  Offset::bottom);\n+  TypeAryPtr::SHORTS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::SHORT     ,TypeInt::POS), ciTypeArrayKlass::make(T_SHORT),  true,  Offset::bottom);\n+  TypeAryPtr::CHARS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::CHAR      ,TypeInt::POS), ciTypeArrayKlass::make(T_CHAR),   true,  Offset::bottom);\n+  TypeAryPtr::INTS    = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::INT       ,TypeInt::POS), ciTypeArrayKlass::make(T_INT),    true,  Offset::bottom);\n+  TypeAryPtr::LONGS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeLong::LONG     ,TypeInt::POS), ciTypeArrayKlass::make(T_LONG),   true,  Offset::bottom);\n+  TypeAryPtr::FLOATS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::FLOAT        ,TypeInt::POS), ciTypeArrayKlass::make(T_FLOAT),  true,  Offset::bottom);\n+  TypeAryPtr::DOUBLES = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::DOUBLE       ,TypeInt::POS), ciTypeArrayKlass::make(T_DOUBLE), true,  Offset::bottom);\n+  TypeAryPtr::INLINES = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInstPtr::BOTTOM,TypeInt::POS, \/* stable= *\/ false, \/* flat= *\/ true), nullptr, false, Offset::bottom);\n@@ -610,0 +662,1 @@\n+  TypeAryPtr::_array_body_type[T_PRIMITIVE_OBJECT] = TypeAryPtr::OOPS;\n@@ -620,2 +673,2 @@\n-  TypeInstKlassPtr::OBJECT = TypeInstKlassPtr::make(TypePtr::NotNull, current->env()->Object_klass(), 0);\n-  TypeInstKlassPtr::OBJECT_OR_NULL = TypeInstKlassPtr::make(TypePtr::BotPTR, current->env()->Object_klass(), 0);\n+  TypeInstKlassPtr::OBJECT = TypeInstKlassPtr::make(TypePtr::NotNull, current->env()->Object_klass(), Offset(0));\n+  TypeInstKlassPtr::OBJECT_OR_NULL = TypeInstKlassPtr::make(TypePtr::BotPTR, current->env()->Object_klass(), Offset(0));\n@@ -660,0 +713,1 @@\n+  _const_basic_type[T_PRIMITIVE_OBJECT] = TypeInstPtr::BOTTOM;\n@@ -676,0 +730,1 @@\n+  _zero_type[T_PRIMITIVE_OBJECT] = TypePtr::NULL_PTR;\n@@ -946,0 +1001,3 @@\n+\n+  \/\/ Verify that:\n+  \/\/      this meet t == t meet this\n@@ -962,0 +1020,6 @@\n+  \/\/ Verify that:\n+  \/\/      !(t meet this)  meet !t ==\n+  \/\/      (!t join !this) meet !t == !t\n+  \/\/ and\n+  \/\/      !(t meet this)  meet !this ==\n+  \/\/      (!t join !this) meet !this == !this\n@@ -2132,0 +2196,12 @@\n+static void collect_inline_fields(ciInlineKlass* vk, const Type** field_array, uint& pos) {\n+  for (int j = 0; j < vk->nof_nonstatic_fields(); j++) {\n+    ciField* field = vk->nonstatic_field_at(j);\n+    BasicType bt = field->type()->basic_type();\n+    const Type* ft = Type::get_const_type(field->type());\n+    field_array[pos++] = ft;\n+    if (type2size[bt] == 2) {\n+      field_array[pos++] = Type::HALF;\n+    }\n+  }\n+}\n+\n@@ -2134,1 +2210,1 @@\n-const TypeTuple *TypeTuple::make_range(ciSignature* sig, InterfaceHandling interface_handling) {\n+const TypeTuple *TypeTuple::make_range(ciSignature* sig, InterfaceHandling interface_handling, bool ret_vt_fields) {\n@@ -2137,0 +2213,5 @@\n+  if (ret_vt_fields) {\n+    arg_cnt = return_type->as_inline_klass()->inline_arg_slots() + 1;\n+    \/\/ InlineTypeNode::IsInit field used for null checking\n+    arg_cnt++;\n+  }\n@@ -2148,0 +2229,11 @@\n+    if (return_type->is_inlinetype() && ret_vt_fields) {\n+      uint pos = TypeFunc::Parms;\n+      field_array[pos++] = get_const_type(return_type); \/\/ Oop might be null when returning as fields\n+      collect_inline_fields(return_type->as_inline_klass(), field_array, pos);\n+      \/\/ InlineTypeNode::IsInit field used for null checking\n+      field_array[pos++] = get_const_basic_type(T_BOOLEAN);\n+      break;\n+    } else {\n+      field_array[TypeFunc::Parms] = get_const_type(return_type, interface_handling)->join_speculative(TypePtr::BOTTOM);\n+    }\n+    break;\n@@ -2166,2 +2258,10 @@\n-const TypeTuple *TypeTuple::make_domain(ciInstanceKlass* recv, ciSignature* sig, InterfaceHandling interface_handling) {\n-  uint arg_cnt = sig->size();\n+const TypeTuple *TypeTuple::make_domain(ciMethod* method, InterfaceHandling interface_handling, bool vt_fields_as_args) {\n+  ciSignature* sig = method->signature();\n+  uint arg_cnt = sig->size() + (method->is_static() ? 0 : 1);\n+  if (vt_fields_as_args) {\n+    arg_cnt = 0;\n+    assert(method->get_sig_cc() != nullptr, \"Should have scalarized signature\");\n+    for (ExtendedSignature sig_cc = ExtendedSignature(method->get_sig_cc(), SigEntryFilter()); !sig_cc.at_end(); ++sig_cc) {\n+      arg_cnt += type2size[(*sig_cc)._bt];\n+    }\n+  }\n@@ -2170,8 +2270,8 @@\n-  const Type **field_array;\n-  if (recv != nullptr) {\n-    arg_cnt++;\n-    field_array = fields(arg_cnt);\n-    \/\/ Use get_const_type here because it respects UseUniqueSubclasses:\n-    field_array[pos++] = get_const_type(recv, interface_handling)->join_speculative(TypePtr::NOTNULL);\n-  } else {\n-    field_array = fields(arg_cnt);\n+  const Type** field_array = fields(arg_cnt);\n+  if (!method->is_static()) {\n+    ciInstanceKlass* recv = method->holder();\n+    if (vt_fields_as_args && recv->is_inlinetype() && recv->as_inline_klass()->can_be_passed_as_fields() && method->is_scalarized_arg(0)) {\n+      collect_inline_fields(recv->as_inline_klass(), field_array, pos);\n+    } else {\n+      field_array[pos++] = get_const_type(recv, interface_handling)->join_speculative(TypePtr::NOTNULL);\n+    }\n@@ -2183,0 +2283,1 @@\n+    BasicType bt = type->basic_type();\n@@ -2184,1 +2285,1 @@\n-    switch (type->basic_type()) {\n+    switch (bt) {\n@@ -2194,0 +2295,8 @@\n+      if (type->is_inlinetype() && vt_fields_as_args && method->is_scalarized_arg(i + (method->is_static() ? 0 : 1))) {\n+        \/\/ InlineTypeNode::IsInit field used for null checking\n+        field_array[pos++] = get_const_basic_type(T_BOOLEAN);\n+        collect_inline_fields(type->as_inline_klass(), field_array, pos);\n+      } else {\n+        field_array[pos++] = get_const_type(type, interface_handling);\n+      }\n+      break;\n@@ -2210,0 +2319,1 @@\n+  assert(pos == TypeFunc::Parms + arg_cnt, \"wrong number of arguments\");\n@@ -2344,1 +2454,2 @@\n-const TypeAry* TypeAry::make(const Type* elem, const TypeInt* size, bool stable) {\n+const TypeAry* TypeAry::make(const Type* elem, const TypeInt* size, bool stable,\n+                             bool flat, bool not_flat, bool not_null_free) {\n@@ -2349,1 +2460,1 @@\n-  return (TypeAry*)(new TypeAry(elem,size,stable))->hashcons();\n+  return (TypeAry*)(new TypeAry(elem, size, stable, flat, not_flat, not_null_free))->hashcons();\n@@ -2371,1 +2482,4 @@\n-                         _stable && a->_stable);\n+                         _stable && a->_stable,\n+                         _flat && a->_flat,\n+                         _not_flat && a->_not_flat,\n+                         _not_null_free && a->_not_null_free);\n@@ -2384,1 +2498,1 @@\n-  return new TypeAry(_elem->dual(), size_dual, !_stable);\n+  return new TypeAry(_elem->dual(), size_dual, !_stable, !_flat, !_not_flat, !_not_null_free);\n@@ -2393,1 +2507,5 @@\n-    _size == a->_size;\n+    _size == a->_size &&\n+    _flat == a->_flat &&\n+    _not_flat == a->_not_flat &&\n+    _not_null_free == a->_not_null_free;\n+\n@@ -2399,1 +2517,2 @@\n-  return (uint)(uintptr_t)_elem + (uint)(uintptr_t)_size + (uint)(_stable ? 43 : 0);\n+  return (uint)(uintptr_t)_elem + (uint)(uintptr_t)_size + (uint)(_stable ? 43 : 0) +\n+      (uint)(_flat ? 44 : 0) + (uint)(_not_flat ? 45 : 0) + (uint)(_not_null_free ? 46 : 0);\n@@ -2406,1 +2525,1 @@\n-  return make(_elem->remove_speculative(), _size, _stable);\n+  return make(_elem->remove_speculative(), _size, _stable, _flat, _not_flat, _not_null_free);\n@@ -2413,1 +2532,1 @@\n-  return make(_elem->cleanup_speculative(), _size, _stable);\n+  return make(_elem->cleanup_speculative(), _size, _stable, _flat, _not_flat, _not_null_free);\n@@ -2432,0 +2551,5 @@\n+  if (_flat) st->print(\"flat:\");\n+  if (Verbose) {\n+    if (_not_flat) st->print(\"not flat:\");\n+    if (_not_null_free) st->print(\"not null free:\");\n+  }\n@@ -2471,2 +2595,10 @@\n-  if (tinst)\n-    return tinst->instance_klass()->is_final();\n+  if (tinst) {\n+    if (tinst->instance_klass()->is_final()) {\n+      \/\/ Even though MyValue is final, [LMyValue is not exact because null-free [LMyValue is a subtype.\n+      if (tinst->is_inlinetypeptr() && (tinst->ptr() == TypePtr::BotPTR || tinst->ptr() == TypePtr::TopPTR)) {\n+        return false;\n+      }\n+      return true;\n+    }\n+    return false;\n+  }\n@@ -2668,1 +2800,1 @@\n-const TypePtr *TypePtr::make(TYPES t, enum PTR ptr, int offset, const TypePtr* speculative, int inline_depth) {\n+const TypePtr* TypePtr::make(TYPES t, enum PTR ptr, Offset offset, const TypePtr* speculative, int inline_depth) {\n@@ -2682,1 +2814,1 @@\n-  return _offset;\n+  return offset();\n@@ -2753,7 +2885,2 @@\n-int TypePtr::meet_offset( int offset ) const {\n-  \/\/ Either is 'TOP' offset?  Return the other offset!\n-  if( _offset == OffsetTop ) return offset;\n-  if( offset == OffsetTop ) return _offset;\n-  \/\/ If either is different, return 'BOTTOM' offset\n-  if( _offset != offset ) return OffsetBot;\n-  return _offset;\n+Type::Offset TypePtr::meet_offset(int offset) const {\n+  return _offset.meet(Offset(offset));\n@@ -2763,4 +2890,2 @@\n-int TypePtr::dual_offset( ) const {\n-  if( _offset == OffsetTop ) return OffsetBot;\/\/ Map 'TOP' into 'BOTTOM'\n-  if( _offset == OffsetBot ) return OffsetTop;\/\/ Map 'BOTTOM' into 'TOP'\n-  return _offset;               \/\/ Map everything else into self\n+Type::Offset TypePtr::dual_offset() const {\n+  return _offset.dual();\n@@ -2779,13 +2904,2 @@\n-int TypePtr::xadd_offset( intptr_t offset ) const {\n-  \/\/ Adding to 'TOP' offset?  Return 'TOP'!\n-  if( _offset == OffsetTop || offset == OffsetTop ) return OffsetTop;\n-  \/\/ Adding to 'BOTTOM' offset?  Return 'BOTTOM'!\n-  if( _offset == OffsetBot || offset == OffsetBot ) return OffsetBot;\n-  \/\/ Addition overflows or \"accidentally\" equals to OffsetTop? Return 'BOTTOM'!\n-  offset += (intptr_t)_offset;\n-  if (offset != (int)offset || offset == OffsetTop) return OffsetBot;\n-\n-  \/\/ assert( _offset >= 0 && _offset+offset >= 0, \"\" );\n-  \/\/ It is possible to construct a negative offset during PhaseCCP\n-\n-  return (int)offset;        \/\/ Sum valid offsets\n+Type::Offset TypePtr::xadd_offset(intptr_t offset) const {\n+  return _offset.add(offset);\n@@ -2800,1 +2914,1 @@\n-  return make(AnyPtr, _ptr, offset, _speculative, _inline_depth);\n+  return make(AnyPtr, _ptr, Offset(offset), _speculative, _inline_depth);\n@@ -2807,1 +2921,1 @@\n-  return _ptr == a->ptr() && _offset == a->offset() && eq_speculative(a) && _inline_depth == a->_inline_depth;\n+  return _ptr == a->ptr() && _offset == a->_offset && eq_speculative(a) && _inline_depth == a->_inline_depth;\n@@ -2813,1 +2927,1 @@\n-  return (uint)_ptr + (uint)_offset + (uint)hash_speculative() + (uint)_inline_depth;\n+  return (uint)_ptr + (uint)offset() + (uint)hash_speculative() + (uint)_inline_depth;\n@@ -3079,3 +3193,1 @@\n-  if( _offset == OffsetTop ) st->print(\"+top\");\n-  else if( _offset == OffsetBot ) st->print(\"+bot\");\n-  else if( _offset ) st->print(\"+%d\", _offset);\n+  _offset.dump2(st);\n@@ -3116,1 +3228,1 @@\n-  return (_offset != OffsetBot) && !below_centerline(_ptr);\n+  return (_offset != Offset::bottom) && !below_centerline(_ptr);\n@@ -3120,1 +3232,1 @@\n-  return (_offset == OffsetTop) || above_centerline(_ptr);\n+  return (_offset == Offset::top) || above_centerline(_ptr);\n@@ -3512,1 +3624,1 @@\n-TypeOopPtr::TypeOopPtr(TYPES t, PTR ptr, ciKlass* k, const TypeInterfaces* interfaces, bool xk, ciObject* o, int offset,\n+TypeOopPtr::TypeOopPtr(TYPES t, PTR ptr, ciKlass* k, const TypeInterfaces* interfaces, bool xk, ciObject* o, Offset offset, Offset field_offset,\n@@ -3528,2 +3640,2 @@\n-      (offset > 0) && xk && (k != 0) && k->is_instance_klass()) {\n-    _is_ptr_to_boxed_value = k->as_instance_klass()->is_boxed_value_offset(offset);\n+      (offset.get() > 0) && xk && (k != 0) && k->is_instance_klass()) {\n+    _is_ptr_to_boxed_value = k->as_instance_klass()->is_boxed_value_offset(offset.get());\n@@ -3532,2 +3644,2 @@\n-  if (_offset > 0 || _offset == Type::OffsetTop || _offset == Type::OffsetBot) {\n-    if (_offset == oopDesc::klass_offset_in_bytes()) {\n+  if (this->offset() > 0 || this->offset() == Type::OffsetTop || this->offset() == Type::OffsetBot) {\n+    if (this->offset() == oopDesc::klass_offset_in_bytes()) {\n@@ -3539,3 +3651,12 @@\n-    } else if (this->isa_aryptr()) {\n-      _is_ptr_to_narrowoop = (UseCompressedOops && klass()->is_obj_array_klass() &&\n-                             _offset != arrayOopDesc::length_offset_in_bytes());\n+    } else if (UseCompressedOops && this->isa_aryptr() && this->offset() != arrayOopDesc::length_offset_in_bytes()) {\n+      if (klass()->is_obj_array_klass()) {\n+        _is_ptr_to_narrowoop = true;\n+      } else if (klass()->is_flat_array_klass() && field_offset != Offset::top && field_offset != Offset::bottom) {\n+        \/\/ Check if the field of the inline type array element contains oops\n+        ciInlineKlass* vk = klass()->as_flat_array_klass()->element_klass()->as_inline_klass();\n+        int foffset = field_offset.get() + vk->first_field_offset();\n+        ciField* field = vk->get_field_by_offset(foffset, false);\n+        assert(field != nullptr, \"missing field\");\n+        BasicType bt = field->layout_type();\n+        _is_ptr_to_narrowoop = UseCompressedOops && ::is_reference_type(bt);\n+      }\n@@ -3543,1 +3664,0 @@\n-      ciInstanceKlass* ik = klass()->as_instance_klass();\n@@ -3546,1 +3666,1 @@\n-      } else if (_offset == OffsetBot || _offset == OffsetTop) {\n+      } else if (_offset == Offset::bottom || _offset == Offset::top) {\n@@ -3551,3 +3671,2 @@\n-\n-            (_offset == java_lang_Class::klass_offset() ||\n-             _offset == java_lang_Class::array_klass_offset())) {\n+            (this->offset() == java_lang_Class::klass_offset() ||\n+             this->offset() == java_lang_Class::array_klass_offset())) {\n@@ -3559,1 +3678,1 @@\n-                   _offset >= InstanceMirrorKlass::offset_of_static_fields()) {\n+                   this->offset() >= InstanceMirrorKlass::offset_of_static_fields()) {\n@@ -3564,1 +3683,1 @@\n-            field = k->get_field_by_offset(_offset, true);\n+            field = k->get_field_by_offset(this->offset(), true);\n@@ -3575,1 +3694,2 @@\n-          ciField* field = ik->get_field_by_offset(_offset, false);\n+          ciInstanceKlass* ik = klass()->as_instance_klass();\n+          ciField* field = ik->get_field_by_offset(this->offset(), false);\n@@ -3595,2 +3715,2 @@\n-const TypeOopPtr *TypeOopPtr::make(PTR ptr, int offset, int instance_id,\n-                                     const TypePtr* speculative, int inline_depth) {\n+const TypeOopPtr *TypeOopPtr::make(PTR ptr, Offset offset, int instance_id,\n+                                   const TypePtr* speculative, int inline_depth) {\n@@ -3602,1 +3722,1 @@\n-  return (TypeOopPtr*)(new TypeOopPtr(OopPtr, ptr, k, interfaces, xk, o, offset, instance_id, speculative, inline_depth))->hashcons();\n+  return (TypeOopPtr*)(new TypeOopPtr(OopPtr, ptr, k, interfaces, xk, o, offset, Offset::bottom, instance_id, speculative, inline_depth))->hashcons();\n@@ -3627,1 +3747,0 @@\n-\n@@ -3673,1 +3792,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -3715,1 +3834,1 @@\n-  return new TypeOopPtr(_base, dual_ptr(), klass(), _interfaces, klass_is_exact(), const_oop(), dual_offset(), dual_instance_id(), dual_speculative(), dual_inline_depth());\n+  return new TypeOopPtr(_base, dual_ptr(), klass(), _interfaces, klass_is_exact(), const_oop(), dual_offset(), Offset::bottom, dual_instance_id(), dual_speculative(), dual_inline_depth());\n@@ -3720,2 +3839,2 @@\n-const TypeOopPtr* TypeOopPtr::make_from_klass_common(ciKlass* klass, bool klass_change, bool try_for_exact, InterfaceHandling interface_handling) {\n-  if (klass->is_instance_klass()) {\n+const TypeOopPtr* TypeOopPtr::make_from_klass_common(ciKlass *klass, bool klass_change, bool try_for_exact, InterfaceHandling interface_handling) {\n+  if (klass->is_instance_klass() || klass->is_inlinetype()) {\n@@ -3748,1 +3867,1 @@\n-    return TypeInstPtr::make(TypePtr::BotPTR, klass, interfaces, klass_is_exact, nullptr, 0);\n+    return TypeInstPtr::make(TypePtr::BotPTR, klass, interfaces, klass_is_exact, nullptr, Offset(0));\n@@ -3750,5 +3869,13 @@\n-    \/\/ Element is an object array. Recursively call ourself.\n-    ciKlass* eklass = klass->as_obj_array_klass()->element_klass();\n-    const TypeOopPtr *etype = TypeOopPtr::make_from_klass_common(eklass, false, try_for_exact, interface_handling);\n-    bool xk = etype->klass_is_exact();\n-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS);\n+    \/\/ Element is an object or inline type array. Recursively call ourself.\n+    const TypeOopPtr* etype = TypeOopPtr::make_from_klass_common(klass->as_array_klass()->element_klass(), \/* klass_change= *\/ false, try_for_exact, interface_handling);\n+    \/\/ Determine null-free\/flat properties\n+    const TypeOopPtr* exact_etype = etype;\n+    if (etype->can_be_inline_type()) {\n+      \/\/ Use exact type if element can be an inline type\n+      exact_etype = TypeOopPtr::make_from_klass_common(klass->as_array_klass()->element_klass(), \/* klass_change= *\/ true, \/* try_for_exact= *\/ true, interface_handling);\n+    }\n+    bool not_null_free = !exact_etype->can_be_inline_type();\n+    bool not_flat = !UseFlatArray || not_null_free || (exact_etype->is_inlinetypeptr() && !exact_etype->inline_klass()->flat_in_array());\n+    \/\/ Even though MyValue is final, [LMyValue is not exact because null-free [LMyValue is a subtype.\n+    bool xk = etype->klass_is_exact() && !etype->is_inlinetypeptr();\n+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS, \/* stable= *\/ false, \/* flat= *\/ false, not_flat, not_null_free);\n@@ -3757,2 +3884,2 @@\n-    \/\/ slam nulls down in the subarrays.\n-    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, nullptr, xk, 0);\n+    \/\/ slam nullptrs down in the subarrays.\n+    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, nullptr, xk, Offset(0));\n@@ -3763,1 +3890,2 @@\n-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS);\n+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS,\n+                                        \/* stable= *\/ false, \/* flat= *\/ false, \/* not_flat= *\/ true, \/* not_null_free= *\/ true);\n@@ -3766,1 +3894,7 @@\n-    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, true, 0);\n+    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, true, Offset(0));\n+    return arr;\n+  } else if (klass->is_flat_array_klass()) {\n+    const TypeOopPtr* etype = TypeOopPtr::make_from_klass_raw(klass->as_array_klass()->element_klass(), trust_interfaces);\n+    etype = etype->join_speculative(TypePtr::NOTNULL)->is_oopptr();\n+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS, \/* stable= *\/ false, \/* flat= *\/ true);\n+    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, true, Offset(0));\n@@ -3782,2 +3916,2 @@\n-  if (klass->is_instance_klass()) {\n-    \/\/ Element is an instance\n+  if (klass->is_instance_klass() || klass->is_inlinetype()) {\n+    \/\/ Element is an instance or inline type\n@@ -3787,1 +3921,1 @@\n-      return TypeInstPtr::make(TypePtr::NotNull, klass, true, nullptr, 0);\n+      return TypeInstPtr::make(TypePtr::NotNull, klass, true, nullptr, Offset(0));\n@@ -3791,3 +3925,8 @@\n-    const TypeOopPtr *etype =\n-      TypeOopPtr::make_from_klass_raw(klass->as_obj_array_klass()->element_klass(), trust_interfaces);\n-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()));\n+    const TypeOopPtr* etype = TypeOopPtr::make_from_klass_raw(klass->as_array_klass()->element_klass(), trust_interfaces);\n+    bool is_flat = o->as_obj_array()->is_flat();\n+    bool is_null_free = o->as_obj_array()->is_null_free();\n+    if (is_null_free) {\n+      etype = etype->join_speculative(TypePtr::NOTNULL)->is_oopptr();\n+    }\n+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()),\n+                                        \/* stable= *\/ false, \/* flat= *\/ false, \/* not_flat= *\/ !is_flat, \/* not_null_free= *\/ !is_null_free);\n@@ -3798,1 +3937,1 @@\n-      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, 0);\n+      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, Offset(0));\n@@ -3800,1 +3939,1 @@\n-      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, 0);\n+      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, Offset(0));\n@@ -3804,3 +3943,3 @@\n-    const Type* etype =\n-      (Type*)get_const_basic_type(klass->as_type_array_klass()->element_type());\n-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()));\n+    const Type* etype = (Type*)get_const_basic_type(klass->as_type_array_klass()->element_type());\n+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()),\n+                                        \/* stable= *\/ false, \/* flat= *\/ false, \/* not_flat= *\/ true, \/* not_null_free= *\/ true);\n@@ -3810,1 +3949,13 @@\n-      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, 0);\n+      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, Offset(0));\n+    } else {\n+      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, Offset(0));\n+    }\n+  } else if (klass->is_flat_array_klass()) {\n+    const TypeOopPtr* etype = TypeOopPtr::make_from_klass_raw(klass->as_array_klass()->element_klass(), trust_interfaces);\n+    etype = etype->join_speculative(TypePtr::NOTNULL)->is_oopptr();\n+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()), \/* stable= *\/ false, \/* flat= *\/ true);\n+    \/\/ We used to pass NotNull in here, asserting that the sub-arrays\n+    \/\/ are all not-null.  This is not true in generally, as code can\n+    \/\/ slam nullptrs down in the subarrays.\n+    if (make_constant) {\n+      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, Offset(0));\n@@ -3812,1 +3963,1 @@\n-      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, 0);\n+      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, Offset(0));\n@@ -3823,1 +3974,1 @@\n-  assert( _offset >= 0, \"\" );\n+  assert(offset() >= 0, \"\");\n@@ -3825,1 +3976,1 @@\n-  if (_offset != 0) {\n+  if (offset() != 0) {\n@@ -3886,6 +4037,1 @@\n-  switch( _offset ) {\n-  case OffsetTop: st->print(\"+top\"); break;\n-  case OffsetBot: st->print(\"+any\"); break;\n-  case         0: break;\n-  default:        st->print(\"+%d\",_offset); break;\n-  }\n+  _offset.dump2(st);\n@@ -3908,1 +4054,1 @@\n-  return (_offset == 0) && !below_centerline(_ptr);\n+  return (offset() == 0) && !below_centerline(_ptr);\n@@ -3917,1 +4063,1 @@\n-  return make(_ptr, offset, _instance_id, with_offset_speculative(offset), _inline_depth);\n+  return make(_ptr, Offset(offset), _instance_id, with_offset_speculative(offset), _inline_depth);\n@@ -4030,3 +4176,4 @@\n-TypeInstPtr::TypeInstPtr(PTR ptr, ciKlass* k, const TypeInterfaces* interfaces, bool xk, ciObject* o, int off,\n-                         int instance_id, const TypePtr* speculative, int inline_depth)\n-  : TypeOopPtr(InstPtr, ptr, k, interfaces, xk, o, off, instance_id, speculative, inline_depth) {\n+TypeInstPtr::TypeInstPtr(PTR ptr, ciKlass* k, const TypeInterfaces* interfaces, bool xk, ciObject* o, Offset off,\n+                         bool flat_in_array, int instance_id, const TypePtr* speculative, int inline_depth)\n+  : TypeOopPtr(InstPtr, ptr, k, interfaces, xk, o, off, Offset::bottom, instance_id, speculative, inline_depth),\n+    _flat_in_array(flat_in_array) {\n@@ -4037,0 +4184,2 @@\n+  assert(!klass()->flat_in_array() || flat_in_array, \"Should be flat in array\");\n+  assert(!flat_in_array || can_be_inline_type(), \"Only inline types can be flat in array\");\n@@ -4045,1 +4194,2 @@\n-                                     int offset,\n+                                     Offset offset,\n+                                     bool flat_in_array,\n@@ -4067,0 +4217,3 @@\n+  \/\/ Check if this type is known to be flat in arrays\n+  flat_in_array = flat_in_array || k->flat_in_array();\n+\n@@ -4069,1 +4222,1 @@\n-    (TypeInstPtr*)(new TypeInstPtr(ptr, k, interfaces, xk, o ,offset, instance_id, speculative, inline_depth))->hashcons();\n+    (TypeInstPtr*)(new TypeInstPtr(ptr, k, interfaces, xk, o, offset, flat_in_array, instance_id, speculative, inline_depth))->hashcons();\n@@ -4135,1 +4288,1 @@\n-  return make(ptr, klass(), _interfaces, klass_is_exact(), ptr == Constant ? const_oop() : nullptr, _offset, _instance_id, _speculative, _inline_depth);\n+  return make(ptr, klass(), _interfaces, klass_is_exact(), ptr == Constant ? const_oop() : nullptr, _offset, _flat_in_array, _instance_id, _speculative, _inline_depth);\n@@ -4146,1 +4299,1 @@\n-  return make(ptr(), klass(), _interfaces, klass_is_exact, const_oop(), _offset, _instance_id, _speculative, _inline_depth);\n+  return make(ptr(), klass(), _interfaces, klass_is_exact, const_oop(), _offset, _flat_in_array, _instance_id, _speculative, _inline_depth);\n@@ -4152,1 +4305,1 @@\n-  return make(_ptr, klass(),  _interfaces, _klass_is_exact, const_oop(), _offset, instance_id, _speculative, _inline_depth);\n+  return make(_ptr, klass(), _interfaces, _klass_is_exact, const_oop(), _offset, _flat_in_array, instance_id, _speculative, _inline_depth);\n@@ -4159,1 +4312,1 @@\n-  int off = meet_offset(tinst->offset());\n+  Offset off = meet_offset(tinst->offset());\n@@ -4184,1 +4337,1 @@\n-    else if (loaded->ptr() == TypePtr::AnyNull)  { return make(ptr, unloaded->klass(), interfaces, false, nullptr, off, instance_id, speculative, depth); }\n+    else if (loaded->ptr() == TypePtr::AnyNull)  { return make(ptr, unloaded->klass(), interfaces, false, nullptr, off, false, instance_id, speculative, depth); }\n@@ -4245,1 +4398,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -4254,1 +4407,1 @@\n-                  (ptr == Constant ? const_oop() : nullptr), offset, instance_id, speculative, depth);\n+                  (ptr == Constant ? const_oop() : nullptr), offset, flat_in_array(), instance_id, speculative, depth);\n@@ -4270,1 +4423,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -4282,1 +4435,1 @@\n-                  (ptr == Constant ? const_oop() : nullptr), offset, instance_id, speculative, depth);\n+                  (ptr == Constant ? const_oop() : nullptr), offset, flat_in_array(), instance_id, speculative, depth);\n@@ -4310,1 +4463,1 @@\n-    int off = meet_offset(tinst->offset());\n+    Offset off = meet_offset(tinst->offset());\n@@ -4322,0 +4475,1 @@\n+    bool res_flat_in_array = false;\n@@ -4323,1 +4477,1 @@\n-    MeetResult kind = meet_instptr(ptr, interfaces, this, tinst, res_klass, res_xk);\n+    MeetResult kind = meet_instptr(ptr, interfaces, this, tinst, res_klass, res_xk, res_flat_in_array);\n@@ -4364,1 +4518,1 @@\n-      res = make(ptr, res_klass, interfaces, res_xk, o, off, instance_id, speculative, depth);\n+      res = make(ptr, res_klass, interfaces, res_xk, o, off, res_flat_in_array, instance_id, speculative, depth);\n@@ -4376,1 +4530,1 @@\n-                                                            ciKlass*& res_klass, bool& res_xk) {\n+                                                            ciKlass*& res_klass, bool& res_xk, bool& res_flat_in_array) {\n@@ -4379,0 +4533,5 @@\n+  const bool this_flat_in_array = this_type->flat_in_array();\n+  const bool other_flat_in_array = other_type->flat_in_array();\n+  const bool this_not_flat_in_array = this_type->not_flat_in_array();\n+  const bool other_not_flat_in_array = other_type->not_flat_in_array();\n+\n@@ -4389,1 +4548,1 @@\n-  if (ptr != Constant && this_klass->equals(other_klass) && this_xk == other_xk) {\n+  if (ptr != Constant && this_klass->equals(other_klass) && this_xk == other_xk && this_flat_in_array == other_flat_in_array) {\n@@ -4392,0 +4551,1 @@\n+    res_flat_in_array = this_flat_in_array;\n@@ -4425,0 +4585,9 @@\n+  \/\/ Flat in array matrix, yes = y, no = n, maybe = m, top\/empty = T:\n+  \/\/        yes maybe no   -> Super Klass\n+  \/\/   yes   y    y    y\n+  \/\/ maybe   y    m    m\n+  \/\/    no   T    n    n\n+  \/\/    |\n+  \/\/    v\n+  \/\/ Sub Klass\n+\n@@ -4427,0 +4596,1 @@\n+  bool flat_in_array = false;\n@@ -4430,1 +4600,2 @@\n-  } else if (!other_xk && this_type->is_meet_subtype_of(other_type)) {\n+    flat_in_array = below_centerline(ptr) ? (this_flat_in_array && other_flat_in_array) : (this_flat_in_array || other_flat_in_array);\n+  } else if (!other_xk && is_meet_subtype_of(this_type, other_type)) {\n@@ -4433,1 +4604,3 @@\n-  } else if(!this_xk && other_type->is_meet_subtype_of(this_type)) {\n+    bool other_flat_this_maybe_flat = other_flat_in_array && (!this_flat_in_array && !this_not_flat_in_array);\n+    flat_in_array = this_flat_in_array || other_flat_this_maybe_flat;\n+  } else if (!this_xk && is_meet_subtype_of(other_type, this_type)) {\n@@ -4436,0 +4609,2 @@\n+    bool this_flat_other_maybe_flat = this_flat_in_array && (!other_flat_in_array && !other_not_flat_in_array);\n+    flat_in_array = other_flat_in_array || this_flat_other_maybe_flat;\n@@ -4439,1 +4614,2 @@\n-    if (above_centerline(ptr)) { \/\/ both are up?\n+    if (above_centerline(ptr)) {\n+      \/\/ Both types are empty.\n@@ -4443,1 +4619,2 @@\n-      this_type = other_type; \/\/ tinst is down; keep down man\n+      \/\/ this_type is empty while other_type is not. Take other_type.\n+      this_type = other_type;\n@@ -4445,0 +4622,1 @@\n+      flat_in_array = other_flat_in_array;\n@@ -4446,0 +4624,1 @@\n+      \/\/ other_type is empty while this_type is not. Take this_type.\n@@ -4447,1 +4626,1 @@\n-      other_xk = this_xk;\n+      flat_in_array = this_flat_in_array;\n@@ -4449,0 +4628,1 @@\n+      \/\/ this_type and other_type are both non-empty.\n@@ -4460,0 +4640,1 @@\n+    res_flat_in_array = subtype ? flat_in_array : this_flat_in_array;\n@@ -4476,0 +4657,1 @@\n+  res_flat_in_array = this_flat_in_array && other_flat_in_array;\n@@ -4480,0 +4662,4 @@\n+template<class T> bool TypePtr::is_meet_subtype_of(const T* sub_type, const T* super_type) {\n+  return sub_type->is_meet_subtype_of(super_type) && !(super_type->flat_in_array() && sub_type->not_flat_in_array());\n+}\n+\n@@ -4481,1 +4667,1 @@\n-ciType* TypeInstPtr::java_mirror_type() const {\n+ciType* TypeInstPtr::java_mirror_type(bool* is_null_free_array) const {\n@@ -4487,2 +4673,1 @@\n-\n-  return const_oop()->as_instance()->java_mirror_type();\n+  return const_oop()->as_instance()->java_mirror_type(is_null_free_array);\n@@ -4496,1 +4681,1 @@\n-  return new TypeInstPtr(dual_ptr(), klass(), _interfaces, klass_is_exact(), const_oop(), dual_offset(), dual_instance_id(), dual_speculative(), dual_inline_depth());\n+  return new TypeInstPtr(dual_ptr(), klass(), _interfaces, klass_is_exact(), const_oop(), dual_offset(), flat_in_array(), dual_instance_id(), dual_speculative(), dual_inline_depth());\n@@ -4505,0 +4690,1 @@\n+    flat_in_array() == p->flat_in_array() &&\n@@ -4512,1 +4698,1 @@\n-  return klass()->hash() + TypeOopPtr::hash() + _interfaces->hash();\n+  return klass()->hash() + TypeOopPtr::hash() + _interfaces->hash() + (uint)flat_in_array();\n@@ -4566,5 +4752,1 @@\n-  if( _offset ) {               \/\/ Dump offset, if any\n-    if( _offset == OffsetBot )      st->print(\"+any\");\n-    else if( _offset == OffsetTop ) st->print(\"+unknown\");\n-    else st->print(\"+%d\", _offset);\n-  }\n+  _offset.dump2(st);\n@@ -4573,0 +4755,5 @@\n+\n+  if (flat_in_array() && !klass()->is_inlinetype()) {\n+    st->print(\" (flat in array)\");\n+  }\n+\n@@ -4585,1 +4772,1 @@\n-  return make(_ptr, klass(), _interfaces, klass_is_exact(), const_oop(), xadd_offset(offset),\n+  return make(_ptr, klass(), _interfaces, klass_is_exact(), const_oop(), xadd_offset(offset), flat_in_array(),\n@@ -4590,1 +4777,1 @@\n-  return make(_ptr, klass(), _interfaces, klass_is_exact(), const_oop(), offset,\n+  return make(_ptr, klass(), _interfaces, klass_is_exact(), const_oop(), Offset(offset), flat_in_array(),\n@@ -4599,1 +4786,1 @@\n-  return make(_ptr, klass(), _interfaces, klass_is_exact(), const_oop(), _offset,\n+  return make(_ptr, klass(), _interfaces, klass_is_exact(), const_oop(), _offset, flat_in_array(),\n@@ -4607,1 +4794,1 @@\n-  return make(_ptr, klass(), _interfaces, klass_is_exact(), const_oop(), _offset, _instance_id, _speculative, depth);\n+  return make(_ptr, klass(), _interfaces, klass_is_exact(), const_oop(), _offset, flat_in_array(), _instance_id, _speculative, depth);\n@@ -4612,1 +4799,5 @@\n-  return make(_ptr, klass(), _interfaces, klass_is_exact(), const_oop(), _offset, instance_id, _speculative, _inline_depth);\n+  return make(_ptr, klass(), _interfaces, klass_is_exact(), const_oop(), _offset, flat_in_array(), instance_id, _speculative, _inline_depth);\n+}\n+\n+const TypeInstPtr *TypeInstPtr::cast_to_flat_in_array() const {\n+  return make(_ptr, klass(), _interfaces, klass_is_exact(), const_oop(), _offset, true, _instance_id, _speculative, _inline_depth);\n@@ -4626,1 +4817,1 @@\n-  return TypeInstKlassPtr::make(xk ? TypePtr::Constant : TypePtr::NotNull, klass(), _interfaces, 0);\n+  return TypeInstKlassPtr::make(xk ? TypePtr::Constant : TypePtr::NotNull, klass(), _interfaces, Offset(0), flat_in_array());\n@@ -4671,1 +4862,0 @@\n-\n@@ -4703,0 +4893,1 @@\n+const TypeAryPtr *TypeAryPtr::INLINES;\n@@ -4705,1 +4896,1 @@\n-const TypeAryPtr *TypeAryPtr::make(PTR ptr, const TypeAry *ary, ciKlass* k, bool xk, int offset,\n+const TypeAryPtr* TypeAryPtr::make(PTR ptr, const TypeAry *ary, ciKlass* k, bool xk, Offset offset, Offset field_offset,\n@@ -4715,1 +4906,4 @@\n-  return (TypeAryPtr*)(new TypeAryPtr(ptr, nullptr, ary, k, xk, offset, instance_id, false, speculative, inline_depth))->hashcons();\n+  if (k != nullptr && k->is_flat_array_klass() && !ary->_flat) {\n+    k = nullptr;\n+  }\n+  return (TypeAryPtr*)(new TypeAryPtr(ptr, nullptr, ary, k, xk, offset, field_offset, instance_id, false, speculative, inline_depth))->hashcons();\n@@ -4719,1 +4913,1 @@\n-const TypeAryPtr *TypeAryPtr::make(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk, int offset,\n+const TypeAryPtr* TypeAryPtr::make(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk, Offset offset, Offset field_offset,\n@@ -4731,1 +4925,4 @@\n-  return (TypeAryPtr*)(new TypeAryPtr(ptr, o, ary, k, xk, offset, instance_id, is_autobox_cache, speculative, inline_depth))->hashcons();\n+  if (k != nullptr && k->is_flat_array_klass() && !ary->_flat) {\n+    k = nullptr;\n+  }\n+  return (TypeAryPtr*)(new TypeAryPtr(ptr, o, ary, k, xk, offset, field_offset, instance_id, is_autobox_cache, speculative, inline_depth))->hashcons();\n@@ -4737,1 +4934,1 @@\n-  return make(ptr, ptr == Constant ? const_oop() : nullptr, _ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth);\n+  return make(ptr, ptr == Constant ? const_oop() : nullptr, _ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n@@ -4745,1 +4942,1 @@\n-  return make(ptr(), const_oop(), _ary, klass(), klass_is_exact, _offset, _instance_id, _speculative, _inline_depth);\n+  return make(ptr(), const_oop(), _ary, klass(), klass_is_exact, _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n@@ -4751,1 +4948,1 @@\n-  return make(_ptr, const_oop(), _ary, klass(), _klass_is_exact, _offset, instance_id, _speculative, _inline_depth);\n+  return make(_ptr, const_oop(), _ary, klass(), _klass_is_exact, _offset, _field_offset, instance_id, _speculative, _inline_depth, _is_autobox_cache);\n@@ -4807,2 +5004,62 @@\n-  const TypeAry* new_ary = TypeAry::make(elem(), new_size, is_stable());\n-  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth);\n+  const TypeAry* new_ary = TypeAry::make(elem(), new_size, is_stable(), is_flat(), is_not_flat(), is_not_null_free());\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n+}\n+\n+\/\/-------------------------------cast_to_not_flat------------------------------\n+const TypeAryPtr* TypeAryPtr::cast_to_not_flat(bool not_flat) const {\n+  if (not_flat == is_not_flat()) {\n+    return this;\n+  }\n+  assert(!not_flat || !is_flat(), \"inconsistency\");\n+  const TypeAry* new_ary = TypeAry::make(elem(), size(), is_stable(), is_flat(), not_flat, is_not_null_free());\n+  const TypeAryPtr* res = make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n+  \/\/ We keep the speculative part if it contains information about flat-\/nullability.\n+  \/\/ Make sure it's removed if it's not better than the non-speculative type anymore.\n+  if (res->speculative() == res->remove_speculative()) {\n+    return res->remove_speculative();\n+  }\n+  return res;\n+}\n+\n+\/\/-------------------------------cast_to_not_null_free-------------------------\n+const TypeAryPtr* TypeAryPtr::cast_to_not_null_free(bool not_null_free) const {\n+  if (not_null_free == is_not_null_free()) {\n+    return this;\n+  }\n+  assert(!not_null_free || !is_flat(), \"inconsistency\");\n+  const TypeAry* new_ary = TypeAry::make(elem(), size(), is_stable(), is_flat(), \/* not_flat= *\/ not_null_free ? true : is_not_flat(), not_null_free);\n+  const TypeAryPtr* res = make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset,\n+                               _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n+  \/\/ We keep the speculative part if it contains information about flat-\/nullability.\n+  \/\/ Make sure it's removed if it's not better than the non-speculative type anymore.\n+  if (res->speculative() == res->remove_speculative()) {\n+    return res->remove_speculative();\n+  }\n+  return res;\n+}\n+\n+\/\/---------------------------------update_properties---------------------------\n+const TypeAryPtr* TypeAryPtr::update_properties(const TypeAryPtr* from) const {\n+  if ((from->is_flat()          && is_not_flat()) ||\n+      (from->is_not_flat()      && is_flat()) ||\n+      (from->is_null_free()     && is_not_null_free()) ||\n+      (from->is_not_null_free() && is_null_free())) {\n+    return nullptr; \/\/ Inconsistent properties\n+  } else if (from->is_not_null_free()) {\n+    return cast_to_not_null_free(); \/\/ Implies not flat\n+  } else if (from->is_not_flat()) {\n+    return cast_to_not_flat();\n+  }\n+  return this;\n+}\n+\n+jint TypeAryPtr::flat_layout_helper() const {\n+  return klass()->as_flat_array_klass()->layout_helper();\n+}\n+\n+int TypeAryPtr::flat_elem_size() const {\n+  return klass()->as_flat_array_klass()->element_byte_size();\n+}\n+\n+int TypeAryPtr::flat_log_elem_size() const {\n+  return klass()->as_flat_array_klass()->log2_element_size();\n@@ -4824,1 +5081,1 @@\n-  const TypeAry* new_ary = TypeAry::make(elem, size(), stable);\n+  const TypeAry* new_ary = TypeAry::make(elem, size(), stable, is_flat(), is_not_flat(), is_not_null_free());\n@@ -4826,1 +5083,1 @@\n-  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth);\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n@@ -4846,2 +5103,2 @@\n-  const TypeAry* new_ary = TypeAry::make(etype, size(), is_stable());\n-  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth, \/*is_autobox_cache=*\/true);\n+  const TypeAry* new_ary = TypeAry::make(etype, size(), is_stable(), is_flat(), is_not_flat(), is_not_null_free());\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, \/*is_autobox_cache=*\/true);\n@@ -4856,1 +5113,2 @@\n-    TypeOopPtr::eq(p);  \/\/ Check sub-parts\n+    TypeOopPtr::eq(p) &&\/\/ Check sub-parts\n+    _field_offset == p->_field_offset;\n@@ -4862,1 +5120,1 @@\n-  return (uint)(uintptr_t)_ary + TypeOopPtr::hash();\n+  return (uint)(uintptr_t)_ary + TypeOopPtr::hash() + _field_offset.get();\n@@ -4906,1 +5164,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -4915,1 +5173,1 @@\n-                  _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);\n+                  _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);\n@@ -4929,1 +5187,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -4945,1 +5203,1 @@\n-                  _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);\n+                  _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);\n@@ -4959,1 +5217,2 @@\n-    int off = meet_offset(tap->offset());\n+    Offset off = meet_offset(tap->offset());\n+    Offset field_off = meet_field_offset(tap->field_offset());\n@@ -4968,0 +5227,3 @@\n+    bool res_flat = false;\n+    bool res_not_flat = false;\n+    bool res_not_null_free = false;\n@@ -4969,1 +5231,1 @@\n-    if (meet_aryptr(ptr, elem, this, tap, res_klass, res_xk) == NOT_SUBTYPE) {\n+    if (meet_aryptr(ptr, elem, this, tap, res_klass, res_xk, res_flat, res_not_flat, res_not_null_free) == NOT_SUBTYPE) {\n@@ -4971,0 +5233,14 @@\n+    } else if (this->is_flat() != tap->is_flat()) {\n+      \/\/ Meeting flat inline type array with non-flat array. Adjust (field) offset accordingly.\n+      if (tary->_flat) {\n+        \/\/ Result is in a flat representation\n+        off = Offset(is_flat() ? offset() : tap->offset());\n+        field_off = is_flat() ? field_offset() : tap->field_offset();\n+      } else if (below_centerline(ptr)) {\n+        \/\/ Result is in a non-flat representation\n+        off = Offset(flat_offset()).meet(Offset(tap->flat_offset()));\n+        field_off = (field_off == Offset::top) ? Offset::top : Offset::bottom;\n+      } else if (flat_offset() == tap->flat_offset()) {\n+        off = Offset(!is_flat() ? offset() : tap->offset());\n+        field_off = !is_flat() ? field_offset() : tap->field_offset();\n+      }\n@@ -4988,1 +5264,1 @@\n-    return make(ptr, o, TypeAry::make(elem, tary->_size, tary->_stable), res_klass, res_xk, off, instance_id, speculative, depth);\n+    return make(ptr, o, TypeAry::make(elem, tary->_size, tary->_stable, res_flat, res_not_flat, res_not_null_free), res_klass, res_xk, off, field_off, instance_id, speculative, depth);\n@@ -4994,1 +5270,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -5009,2 +5285,2 @@\n-      if (tp->klass()->equals(ciEnv::current()->Object_klass()) && this_interfaces->contains(tp_interfaces) && !tp->klass_is_exact()) {\n-        return TypeAryPtr::make(ptr, _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);\n+      if (tp->klass()->equals(ciEnv::current()->Object_klass()) && this_interfaces->contains(tp_interfaces) && !tp->klass_is_exact() && !tp->flat_in_array()) {\n+        return TypeAryPtr::make(ptr, _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);\n@@ -5016,1 +5292,1 @@\n-        return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), interfaces, false, nullptr,offset, instance_id, speculative, depth);\n+        return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), interfaces, false, nullptr, offset, false, instance_id, speculative, depth);\n@@ -5028,1 +5304,1 @@\n-        if (tp->klass()->equals(ciEnv::current()->Object_klass()) && this_interfaces->contains(tp_interfaces) && !tp->klass_is_exact()) {\n+        if (tp->klass()->equals(ciEnv::current()->Object_klass()) && this_interfaces->contains(tp_interfaces) && !tp->klass_is_exact() && !tp->flat_in_array()) {\n@@ -5031,1 +5307,1 @@\n-                      _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);\n+                      _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);\n@@ -5043,1 +5319,1 @@\n-      return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), interfaces, false, nullptr, offset, instance_id, speculative, depth);\n+      return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), interfaces, false, nullptr, offset, false, instance_id, speculative, depth);\n@@ -5052,2 +5328,2 @@\n-template<class T> TypePtr::MeetResult TypePtr::meet_aryptr(PTR& ptr, const Type*& elem, const T* this_ary,\n-                                                           const T* other_ary, ciKlass*& res_klass, bool& res_xk) {\n+template<class T> TypePtr::MeetResult TypePtr::meet_aryptr(PTR& ptr, const Type*& elem, const T* this_ary, const T* other_ary,\n+                                                           ciKlass*& res_klass, bool& res_xk, bool &res_flat, bool& res_not_flat, bool& res_not_null_free) {\n@@ -5063,0 +5339,6 @@\n+  bool this_flat = this_ary->is_flat();\n+  bool this_not_flat = this_ary->is_not_flat();\n+  bool other_flat = other_ary->is_flat();\n+  bool other_not_flat = other_ary->is_not_flat();\n+  bool this_not_null_free = this_ary->is_not_null_free();\n+  bool other_not_null_free = other_ary->is_not_null_free();\n@@ -5065,0 +5347,4 @@\n+  res_flat = this_flat && other_flat;\n+  res_not_flat = this_not_flat && other_not_flat;\n+  res_not_null_free = this_not_null_free && other_not_null_free;\n+\n@@ -5068,3 +5354,3 @@\n-    if (this_top_or_bottom)\n-      res_klass = other_klass;\n-    else if (other_top_or_bottom || other_klass == this_klass) {\n+      if (this_top_or_bottom) {\n+        res_klass = other_klass;\n+      } else if (other_top_or_bottom || other_klass == this_klass) {\n@@ -5112,0 +5398,3 @@\n+        if (this_ary->is_flat()) {\n+          elem = this_ary->elem();\n+        }\n@@ -5115,1 +5404,1 @@\n-      return result;\n+      break;\n@@ -5119,1 +5408,1 @@\n-      } else if(above_centerline(this_ptr)) {\n+      } else if (above_centerline(this_ptr)) {\n@@ -5124,0 +5413,5 @@\n+        \/\/ Even though MyValue is final, [LMyValue is only exact if the array\n+        \/\/ is null-free due to null-free [LMyValue <: null-able [LMyValue.\n+        if (res_xk && !res_not_null_free) {\n+          res_xk = false;\n+        }\n@@ -5125,1 +5419,1 @@\n-      return result;\n+      break;\n@@ -5132,0 +5426,3 @@\n+        if (other_ary->is_flat()) {\n+          elem = other_ary->elem();\n+        }\n@@ -5135,0 +5432,5 @@\n+        \/\/ Even though MyValue is final, [LMyValue is only exact if the array\n+        \/\/ is null-free due to null-free [LMyValue <: null-able [LMyValue.\n+        if (res_xk && !res_not_null_free) {\n+          res_xk = false;\n+        }\n@@ -5136,1 +5438,1 @@\n-      return result;\n+      break;\n@@ -5149,1 +5451,10 @@\n-  return new TypeAryPtr(dual_ptr(), _const_oop, _ary->dual()->is_ary(),_klass, _klass_is_exact, dual_offset(), dual_instance_id(), is_autobox_cache(), dual_speculative(), dual_inline_depth());\n+  return new TypeAryPtr(dual_ptr(), _const_oop, _ary->dual()->is_ary(), _klass, _klass_is_exact, dual_offset(), dual_field_offset(), dual_instance_id(), is_autobox_cache(), dual_speculative(), dual_inline_depth());\n+}\n+\n+Type::Offset TypeAryPtr::meet_field_offset(const Type::Offset offset) const {\n+  return _field_offset.meet(offset);\n+}\n+\n+\/\/------------------------------dual_offset------------------------------------\n+Type::Offset TypeAryPtr::dual_field_offset() const {\n+  return _field_offset.dual();\n@@ -5177,1 +5488,10 @@\n-  if( _offset != 0 ) {\n+  if (is_flat()) {\n+    st->print(\":flat\");\n+    st->print(\"(\");\n+    _field_offset.dump2(st);\n+    st->print(\")\");\n+  }\n+  if (is_null_free()) {\n+    st->print(\":null_free\");\n+  }\n+  if (offset() != 0) {\n@@ -5180,3 +5500,3 @@\n-    if( _offset == OffsetTop )       st->print(\"+undefined\");\n-    else if( _offset == OffsetBot )  st->print(\"+any\");\n-    else if( _offset < header_size ) st->print(\"+%d\", _offset);\n+    if( _offset == Offset::top )       st->print(\"+undefined\");\n+    else if( _offset == Offset::bottom )  st->print(\"+any\");\n+    else if( offset() < header_size ) st->print(\"+%d\", offset());\n@@ -5188,1 +5508,1 @@\n-        st->print(\"[%d]\", (_offset - header_size)\/elem_size);\n+        st->print(\"[%d]\", (offset() - header_size)\/elem_size);\n@@ -5205,0 +5525,4 @@\n+  \/\/ FIXME: Does this belong here? Or in the meet code itself?\n+  if (is_flat() && is_not_flat()) {\n+    return true;\n+  }\n@@ -5210,1 +5534,1 @@\n-  return make(_ptr, _const_oop, _ary, _klass, _klass_is_exact, xadd_offset(offset), _instance_id, add_offset_speculative(offset), _inline_depth);\n+  return make(_ptr, _const_oop, _ary, _klass, _klass_is_exact, xadd_offset(offset), _field_offset, _instance_id, add_offset_speculative(offset), _inline_depth, _is_autobox_cache);\n@@ -5214,1 +5538,1 @@\n-  return make(_ptr, _const_oop, _ary, _klass, _klass_is_exact, offset, _instance_id, with_offset_speculative(offset), _inline_depth);\n+  return make(_ptr, _const_oop, _ary, _klass, _klass_is_exact, Offset(offset), _field_offset, _instance_id, with_offset_speculative(offset), _inline_depth, _is_autobox_cache);\n@@ -5218,1 +5542,1 @@\n-  return make(_ptr, _const_oop, ary, _klass, _klass_is_exact, _offset, _instance_id, _speculative, _inline_depth);\n+  return make(_ptr, _const_oop, ary, _klass, _klass_is_exact, _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n@@ -5226,1 +5550,14 @@\n-  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _instance_id, nullptr, _inline_depth);\n+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _field_offset, _instance_id, nullptr, _inline_depth, _is_autobox_cache);\n+}\n+\n+const Type* TypeAryPtr::cleanup_speculative() const {\n+  if (speculative() == nullptr) {\n+    return this;\n+  }\n+  \/\/ Keep speculative part if it contains information about flat-\/nullability\n+  const TypeAryPtr* spec_aryptr = speculative()->isa_aryptr();\n+  if (spec_aryptr != nullptr && !above_centerline(spec_aryptr->ptr()) &&\n+      (spec_aryptr->is_not_flat() || spec_aryptr->is_not_null_free())) {\n+    return this;\n+  }\n+  return TypeOopPtr::cleanup_speculative();\n@@ -5233,1 +5570,44 @@\n-  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _instance_id, _speculative, depth);\n+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _field_offset, _instance_id, _speculative, depth, _is_autobox_cache);\n+}\n+\n+const TypeAryPtr* TypeAryPtr::with_field_offset(int offset) const {\n+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, Offset(offset), _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n+}\n+\n+const TypePtr* TypeAryPtr::add_field_offset_and_offset(intptr_t offset) const {\n+  int adj = 0;\n+  if (is_flat() && offset != Type::OffsetBot && offset != Type::OffsetTop) {\n+    if (_offset.get() != OffsetBot && _offset.get() != OffsetTop) {\n+      adj = _offset.get();\n+      offset += _offset.get();\n+    }\n+    uint header = arrayOopDesc::base_offset_in_bytes(T_OBJECT);\n+    if (_field_offset.get() != OffsetBot && _field_offset.get() != OffsetTop) {\n+      offset += _field_offset.get();\n+      if (_offset.get() == OffsetBot || _offset.get() == OffsetTop) {\n+        offset += header;\n+      }\n+    }\n+    if (elem()->make_oopptr()->is_inlinetypeptr() && (offset >= (intptr_t)header || offset < 0)) {\n+      \/\/ Try to get the field of the inline type array element we are pointing to\n+      ciInlineKlass* vk = elem()->inline_klass();\n+      int shift = flat_log_elem_size();\n+      int mask = (1 << shift) - 1;\n+      intptr_t field_offset = ((offset - header) & mask);\n+      ciField* field = vk->get_field_by_offset(field_offset + vk->first_field_offset(), false);\n+      if (field != nullptr) {\n+        return with_field_offset(field_offset)->add_offset(offset - field_offset - adj);\n+      }\n+    }\n+  }\n+  return add_offset(offset - adj);\n+}\n+\n+\/\/ Return offset incremented by field_offset for flat inline type arrays\n+int TypeAryPtr::flat_offset() const {\n+  int offset = _offset.get();\n+  if (offset != Type::OffsetBot && offset != Type::OffsetTop &&\n+      _field_offset != Offset::bottom && _field_offset != Offset::top) {\n+    offset += _field_offset.get();\n+  }\n+  return offset;\n@@ -5238,1 +5618,1 @@\n-  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, instance_id, _speculative, _inline_depth);\n+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _field_offset, instance_id, _speculative, _inline_depth);\n@@ -5243,0 +5623,1 @@\n+\n@@ -5333,1 +5714,0 @@\n-\n@@ -5417,1 +5797,1 @@\n-  return (_offset == 0) && !below_centerline(_ptr);\n+  return (offset() == 0) && !below_centerline(_ptr);\n@@ -5437,1 +5817,1 @@\n-  assert( _offset >= 0, \"\" );\n+  assert(offset() >= 0, \"\");\n@@ -5439,1 +5819,1 @@\n-  if (_offset != 0) {\n+  if (offset() != 0) {\n@@ -5490,1 +5870,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -5518,1 +5898,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -5551,1 +5931,1 @@\n-  switch( _offset ) {\n+  switch (offset()) {\n@@ -5555,1 +5935,1 @@\n-  default:        st->print(\"+%d\",_offset); break;\n+  default:        st->print(\"+%d\",offset()); break;\n@@ -5565,1 +5945,1 @@\n-TypeMetadataPtr::TypeMetadataPtr(PTR ptr, ciMetadata* metadata, int offset):\n+TypeMetadataPtr::TypeMetadataPtr(PTR ptr, ciMetadata* metadata, Offset offset):\n@@ -5570,1 +5950,1 @@\n-  return make(Constant, m, 0);\n+  return make(Constant, m, Offset(0));\n@@ -5573,1 +5953,1 @@\n-  return make(Constant, m, 0);\n+  return make(Constant, m, Offset(0));\n@@ -5578,1 +5958,1 @@\n-const TypeMetadataPtr *TypeMetadataPtr::make(PTR ptr, ciMetadata* m, int offset) {\n+const TypeMetadataPtr* TypeMetadataPtr::make(PTR ptr, ciMetadata* m, Offset offset) {\n@@ -5589,1 +5969,4 @@\n-    if (elem->is_klassptr()->klass_is_exact()) {\n+    if (elem->is_klassptr()->klass_is_exact() &&\n+        \/\/ Even though MyValue is final, [LMyValue is only exact if the array\n+        \/\/ is null-free due to null-free [LMyValue <: null-able [LMyValue.\n+        (is_null_free() || !_ary->_elem->make_oopptr()->is_inlinetypeptr())) {\n@@ -5593,1 +5976,1 @@\n-  return TypeAryKlassPtr::make(xk ? TypePtr::Constant : TypePtr::NotNull, elem, klass(), 0);\n+  return TypeAryKlassPtr::make(xk ? TypePtr::Constant : TypePtr::NotNull, elem, klass(), Offset(0), is_not_flat(), is_not_null_free(), is_null_free());\n@@ -5596,1 +5979,1 @@\n-const TypeKlassPtr* TypeKlassPtr::make(ciKlass *klass, InterfaceHandling interface_handling) {\n+const TypeKlassPtr* TypeKlassPtr::make(ciKlass* klass, InterfaceHandling interface_handling) {\n@@ -5603,1 +5986,1 @@\n-const TypeKlassPtr* TypeKlassPtr::make(PTR ptr, ciKlass* klass, int offset, InterfaceHandling interface_handling) {\n+const TypeKlassPtr* TypeKlassPtr::make(PTR ptr, ciKlass* klass, Offset offset, InterfaceHandling interface_handling) {\n@@ -5611,3 +5994,1 @@\n-\n-\/\/------------------------------TypeKlassPtr-----------------------------------\n-TypeKlassPtr::TypeKlassPtr(TYPES t, PTR ptr, ciKlass* klass, const TypeInterfaces* interfaces, int offset)\n+TypeKlassPtr::TypeKlassPtr(TYPES t, PTR ptr, ciKlass* klass, const TypeInterfaces* interfaces, Offset offset)\n@@ -5616,1 +5997,1 @@\n-         klass->is_type_array_klass() || !klass->as_obj_array_klass()->base_element_klass()->is_interface(), \"no interface here\");\n+         klass->is_type_array_klass() || klass->is_flat_array_klass() || !klass->as_obj_array_klass()->base_element_klass()->is_interface(), \"no interface here\");\n@@ -5655,1 +6036,1 @@\n-  return (_offset == 0) && !below_centerline(_ptr);\n+  return (offset() == 0) && !below_centerline(_ptr);\n@@ -5687,1 +6068,1 @@\n-  assert( _offset >= 0, \"\" );\n+  assert( offset() >= 0, \"\" );\n@@ -5689,1 +6070,1 @@\n-  if (_offset != 0) {\n+  if (offset() != 0) {\n@@ -5733,5 +6114,2 @@\n-\n-  if (_offset) {               \/\/ Dump offset, if any\n-    if (_offset == OffsetBot)      { st->print(\"+any\"); }\n-    else if (_offset == OffsetTop) { st->print(\"+unknown\"); }\n-    else                            { st->print(\"+%d\", _offset); }\n+  if (Verbose) {\n+    if (isa_instklassptr() && is_instklassptr()->flat_in_array()) st->print(\":flat in array\");\n@@ -5739,1 +6117,1 @@\n-\n+  _offset.dump2(st);\n@@ -5755,0 +6133,1 @@\n+    flat_in_array() == p->flat_in_array() &&\n@@ -5759,1 +6138,1 @@\n-  return klass()->hash() + TypeKlassPtr::hash();\n+  return klass()->hash() + TypeKlassPtr::hash() + (uint)flat_in_array();\n@@ -5762,1 +6141,3 @@\n-const TypeInstKlassPtr *TypeInstKlassPtr::make(PTR ptr, ciKlass* k, const TypeInterfaces* interfaces, int offset) {\n+const TypeInstKlassPtr *TypeInstKlassPtr::make(PTR ptr, ciKlass* k, const TypeInterfaces* interfaces, Offset offset, bool flat_in_array) {\n+  flat_in_array = flat_in_array || k->flat_in_array();\n+\n@@ -5764,1 +6145,1 @@\n-    (TypeInstKlassPtr*)(new TypeInstKlassPtr(ptr, k, interfaces, offset))->hashcons();\n+    (TypeInstKlassPtr*)(new TypeInstKlassPtr(ptr, k, interfaces, offset, flat_in_array))->hashcons();\n@@ -5771,2 +6152,2 @@\n-const TypePtr* TypeInstKlassPtr::add_offset( intptr_t offset ) const {\n-  return make( _ptr, klass(), _interfaces, xadd_offset(offset) );\n+const TypePtr *TypeInstKlassPtr::add_offset( intptr_t offset ) const {\n+  return make(_ptr, klass(), _interfaces, xadd_offset(offset), flat_in_array());\n@@ -5776,1 +6157,1 @@\n-  return make(_ptr, klass(), _interfaces, offset);\n+  return make(_ptr, klass(), _interfaces, Offset(offset), flat_in_array());\n@@ -5783,1 +6164,1 @@\n-  return make(ptr, _klass, _interfaces, _offset);\n+  return make(ptr, _klass, _interfaces, _offset, flat_in_array());\n@@ -5799,1 +6180,1 @@\n-  return make(klass_is_exact ? Constant : NotNull, k, _interfaces, _offset);\n+  return make(klass_is_exact ? Constant : NotNull, k, _interfaces, _offset, flat_in_array());\n@@ -5831,1 +6212,1 @@\n-  return TypeInstPtr::make(TypePtr::BotPTR, k, interfaces, xk, nullptr, 0);\n+  return TypeInstPtr::make(TypePtr::BotPTR, k, interfaces, xk, nullptr, Offset(0), flat_in_array() && !klass()->is_inlinetype());\n@@ -5864,1 +6245,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -5872,1 +6253,1 @@\n-      return make( ptr, klass(), _interfaces, offset );\n+      return make(ptr, klass(), _interfaces, offset, flat_in_array());\n@@ -5885,1 +6266,1 @@\n-    return TypePtr::BOTTOM;\n+      return TypePtr::BOTTOM;\n@@ -5905,1 +6286,1 @@\n-    int  off     = meet_offset(tkls->offset());\n+    Offset  off     = meet_offset(tkls->offset());\n@@ -5911,1 +6292,2 @@\n-    switch(meet_instptr(ptr, interfaces, this, tkls, res_klass, res_xk)) {\n+    bool res_flat_in_array = false;\n+    switch(meet_instptr(ptr, interfaces, this, tkls, res_klass, res_xk, res_flat_in_array)) {\n@@ -5919,1 +6301,1 @@\n-        const Type* res = make(ptr, res_klass, interfaces, off);\n+        const Type* res = make(ptr, res_klass, interfaces, off, res_flat_in_array);\n@@ -5928,1 +6310,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -5941,1 +6323,1 @@\n-        return TypeAryKlassPtr::make(ptr, tp->elem(), tp->klass(), offset);\n+        return TypeAryKlassPtr::make(ptr, tp->elem(), tp->klass(), offset, tp->is_not_flat(), tp->is_not_null_free(), tp->is_null_free());\n@@ -5946,1 +6328,1 @@\n-        return make(ptr, ciEnv::current()->Object_klass(), interfaces, offset);\n+        return make(ptr, ciEnv::current()->Object_klass(), interfaces, offset, false);\n@@ -5960,2 +6342,1 @@\n-          return TypeAryKlassPtr::make(ptr,\n-                                       tp->elem(), tp->klass(), offset);\n+          return TypeAryKlassPtr::make(ptr, tp->elem(), tp->klass(), offset, tp->is_not_flat(), tp->is_not_null_free(), tp->is_null_free());\n@@ -5969,1 +6350,1 @@\n-      return make(ptr, ciEnv::current()->Object_klass(), interfaces, offset);\n+      return make(ptr, ciEnv::current()->Object_klass(), interfaces, offset, false);\n@@ -5981,1 +6362,1 @@\n-  return new TypeInstKlassPtr(dual_ptr(), klass(), _interfaces, dual_offset());\n+  return new TypeInstKlassPtr(dual_ptr(), klass(), _interfaces, dual_offset(), flat_in_array());\n@@ -6082,0 +6463,15 @@\n+bool TypeInstKlassPtr::can_be_inline_array() const {\n+  return _klass->equals(ciEnv::current()->Object_klass()) && TypeAryKlassPtr::_array_interfaces->contains(_interfaces);\n+}\n+\n+bool TypeAryKlassPtr::can_be_inline_array() const {\n+  return _elem->isa_instklassptr() && _elem->is_instklassptr()->_klass->can_be_inline_klass();\n+}\n+\n+bool TypeInstPtr::can_be_inline_array() const {\n+  return _klass->equals(ciEnv::current()->Object_klass()) && TypeAryPtr::_array_interfaces->contains(_interfaces);\n+}\n+\n+bool TypeAryPtr::can_be_inline_array() const {\n+  return elem()->make_ptr() && elem()->make_ptr()->isa_instptr() && elem()->make_ptr()->is_instptr()->_klass->can_be_inline_klass();\n+}\n@@ -6083,2 +6479,2 @@\n-const TypeAryKlassPtr *TypeAryKlassPtr::make(PTR ptr, const Type* elem, ciKlass* k, int offset) {\n-  return (TypeAryKlassPtr*)(new TypeAryKlassPtr(ptr, elem, k, offset))->hashcons();\n+const TypeAryKlassPtr *TypeAryKlassPtr::make(PTR ptr, const Type* elem, ciKlass* k, Offset offset, bool not_flat, bool not_null_free, bool null_free) {\n+  return (TypeAryKlassPtr*)(new TypeAryKlassPtr(ptr, elem, k, offset, not_flat, not_null_free, null_free))->hashcons();\n@@ -6087,1 +6483,1 @@\n-const TypeAryKlassPtr *TypeAryKlassPtr::make(PTR ptr, ciKlass* k, int offset, InterfaceHandling interface_handling) {\n+const TypeAryKlassPtr* TypeAryKlassPtr::make(PTR ptr, ciKlass* k, Offset offset, InterfaceHandling interface_handling, bool not_flat, bool not_null_free, bool null_free) {\n@@ -6091,2 +6487,2 @@\n-    const TypeKlassPtr *etype = TypeKlassPtr::make(eklass, interface_handling)->cast_to_exactness(false);\n-    return TypeAryKlassPtr::make(ptr, etype, nullptr, offset);\n+    const TypeKlassPtr* etype = TypeKlassPtr::make(eklass, interface_handling)->cast_to_exactness(false);\n+    return TypeAryKlassPtr::make(ptr, etype, nullptr, offset, not_flat, not_null_free, null_free);\n@@ -6096,1 +6492,5 @@\n-    return TypeAryKlassPtr::make(ptr, etype, k, offset);\n+    return TypeAryKlassPtr::make(ptr, etype, k, offset, not_flat, not_null_free, null_free);\n+  } else if (k->is_flat_array_klass()) {\n+    ciKlass* eklass = k->as_flat_array_klass()->element_klass();\n+    const TypeKlassPtr* etype = TypeKlassPtr::make(eklass);\n+    return TypeAryKlassPtr::make(ptr, etype, k, offset, not_flat, not_null_free, null_free);\n@@ -6103,0 +6503,11 @@\n+const TypeAryKlassPtr* TypeAryKlassPtr::make(PTR ptr, ciKlass* k, Offset offset, InterfaceHandling interface_handling) {\n+  bool null_free = k->as_array_klass()->is_elem_null_free();\n+  bool not_null_free = (ptr == Constant) ? !null_free : !k->is_flat_array_klass() && (k->is_type_array_klass() || !k->as_array_klass()->element_klass()->can_be_inline_klass(false));\n+\n+  bool not_flat = !UseFlatArray || not_null_free || (k->as_array_klass()->element_klass() != nullptr &&\n+                                                     k->as_array_klass()->element_klass()->is_inlinetype() &&\n+                                                     !k->as_array_klass()->element_klass()->flat_in_array());\n+\n+  return TypeAryKlassPtr::make(ptr, k, offset, interface_handling, not_flat, not_null_free, null_free);\n+}\n+\n@@ -6104,1 +6515,1 @@\n-  return TypeAryKlassPtr::make(Constant, klass, 0, interface_handling);\n+  return TypeAryKlassPtr::make(Constant, klass, Offset(0), interface_handling);\n@@ -6113,0 +6524,3 @@\n+    _not_flat == p->_not_flat &&\n+    _not_null_free == p->_not_null_free &&\n+    _null_free == p->_null_free &&\n@@ -6119,1 +6533,2 @@\n-  return (uint)(uintptr_t)_elem + TypeKlassPtr::hash();\n+  return (uint)(uintptr_t)_elem + TypeKlassPtr::hash() + (uint)(_not_flat ? 43 : 0) +\n+      (uint)(_not_null_free ? 44 : 0) + (uint)(_null_free ? 45 : 0);\n@@ -6135,2 +6550,7 @@\n-  if ((tinst = el->isa_instptr()) != nullptr) {\n-    \/\/ Leave k_ary at null.\n+  if (is_flat() && el->is_inlinetypeptr()) {\n+    \/\/ Klass is required by TypeAryPtr::flat_layout_helper() and others\n+    if (el->inline_klass() != nullptr) {\n+      k_ary = ciArrayKlass::make(el->inline_klass(), \/* null_free *\/ true);\n+    }\n+  } else if ((tinst = el->isa_instptr()) != nullptr) {\n+    \/\/ Leave k_ary at nullptr.\n@@ -6138,1 +6558,1 @@\n-    \/\/ Leave k_ary at null.\n+    \/\/ Leave k_ary at nullptr.\n@@ -6186,1 +6606,1 @@\n-    k = ciObjArrayKlass::make(k);\n+    k = ciArrayKlass::make(k, is_null_free());\n@@ -6206,1 +6626,1 @@\n-  return make(_ptr, elem(), klass(), xadd_offset(offset));\n+  return make(_ptr, elem(), klass(), xadd_offset(offset), is_not_flat(), is_not_null_free(), _null_free);\n@@ -6210,1 +6630,1 @@\n-  return make(_ptr, elem(), klass(), offset);\n+  return make(_ptr, elem(), klass(), Offset(offset), is_not_flat(), is_not_null_free(), _null_free);\n@@ -6217,1 +6637,1 @@\n-  return make(ptr, elem(), _klass, _offset);\n+  return make(ptr, elem(), _klass, _offset, is_not_flat(), is_not_null_free(), _null_free);\n@@ -6225,0 +6645,5 @@\n+  \/\/ Even though MyValue is final, [LMyValue is only exact if the array\n+  \/\/ is null-free due to null-free [LMyValue <: null-able [LMyValue.\n+  if (tk->isa_instklassptr() && tk->klass()->is_inlinetype() && !is_null_free()) {\n+    return false;\n+  }\n@@ -6231,1 +6656,4 @@\n-  if (must_be_exact()) return this;  \/\/ cannot clear xk\n+  if (must_be_exact() && !klass_is_exact) return this;  \/\/ cannot clear xk\n+  if (klass_is_exact == this->klass_is_exact()) {\n+    return this;\n+  }\n@@ -6237,1 +6665,16 @@\n-  return make(klass_is_exact ? Constant : NotNull, elem, k, _offset);\n+  bool not_flat = is_not_flat();\n+  bool not_null_free = is_not_null_free();\n+  if (_elem->isa_klassptr()) {\n+    if (klass_is_exact || _elem->isa_aryklassptr()) {\n+      assert(!is_null_free() && !is_flat(), \"null-free (or flat) inline type arrays should always be exact\");\n+      \/\/ An array can't be null-free (or flat) if the klass is exact\n+      not_null_free = true;\n+      not_flat = true;\n+    } else {\n+      \/\/ Klass is not exact (anymore), re-compute null-free\/flat properties\n+      const TypeOopPtr* exact_etype = TypeOopPtr::make_from_klass_unique(_elem->is_instklassptr()->instance_klass());\n+      not_null_free = !exact_etype->can_be_inline_type();\n+      not_flat = !UseFlatArray || not_null_free || (exact_etype->is_inlinetypeptr() && !exact_etype->inline_klass()->flat_in_array());\n+    }\n+  }\n+  return make(klass_is_exact ? Constant : NotNull, elem, k, _offset, not_flat, not_null_free, _null_free);\n@@ -6240,0 +6683,3 @@\n+const TypeAryKlassPtr* TypeAryKlassPtr::cast_to_null_free() const {\n+  return make(_ptr, elem(), klass(), _offset, is_not_flat(), false, true);\n+}\n@@ -6254,1 +6700,5 @@\n-  return TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(el, TypeInt::POS), k, xk, 0);\n+  bool null_free = _null_free;\n+  if (null_free && el->isa_ptr()) {\n+    el = el->is_ptr()->join_speculative(TypePtr::NOTNULL);\n+  }\n+  return TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(el, TypeInt::POS, false, is_flat(), is_not_flat(), is_not_null_free()), k, xk, Offset(0));\n@@ -6288,1 +6738,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -6296,1 +6746,1 @@\n-      return make( ptr, _elem, klass(), offset );\n+      return make(ptr, _elem, klass(), offset, is_not_flat(), is_not_null_free(), is_null_free());\n@@ -6329,1 +6779,1 @@\n-    int off = meet_offset(tap->offset());\n+    Offset off = meet_offset(tap->offset());\n@@ -6331,1 +6781,0 @@\n-\n@@ -6335,1 +6784,5 @@\n-    meet_aryptr(ptr, elem, this, tap, res_klass, res_xk);\n+    bool res_flat = false;\n+    bool res_not_flat = false;\n+    bool res_not_null_free = false;\n+    MeetResult res = meet_aryptr(ptr, elem, this, tap,\n+                                 res_klass, res_xk, res_flat, res_not_flat, res_not_null_free);\n@@ -6337,1 +6790,13 @@\n-    return make(ptr, elem, res_klass, off);\n+    bool null_free = meet_null_free(tap->_null_free);\n+    if (res == NOT_SUBTYPE) {\n+      null_free = false;\n+    } else if (res == SUBTYPE) {\n+      if (above_centerline(tap->ptr()) && !above_centerline(this->ptr())) {\n+        null_free = _null_free;\n+      } else if (above_centerline(this->ptr()) && !above_centerline(tap->ptr())) {\n+        null_free = tap->_null_free;\n+      } else if (above_centerline(this->ptr()) && above_centerline(tap->ptr())) {\n+        null_free = _null_free || tap->_null_free;\n+      }\n+    }\n+    return make(ptr, elem, res_klass, off, res_not_flat, res_not_null_free, null_free);\n@@ -6341,1 +6806,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -6355,1 +6820,1 @@\n-        return TypeAryKlassPtr::make(ptr, _elem, _klass, offset);\n+        return TypeAryKlassPtr::make(ptr, _elem, _klass, offset, is_not_flat(), is_not_null_free(), is_null_free());\n@@ -6360,1 +6825,1 @@\n-        return TypeInstKlassPtr::make(ptr, ciEnv::current()->Object_klass(), interfaces, offset);\n+        return TypeInstKlassPtr::make(ptr, ciEnv::current()->Object_klass(), interfaces, offset, false);\n@@ -6375,1 +6840,1 @@\n-          return make(ptr, _elem, _klass, offset);\n+          return make(ptr, _elem, _klass, offset, is_not_flat(), is_not_null_free(), is_null_free());\n@@ -6383,1 +6848,1 @@\n-      return TypeInstKlassPtr::make(ptr, ciEnv::current()->Object_klass(), interfaces, offset);\n+      return TypeInstKlassPtr::make(ptr, ciEnv::current()->Object_klass(), interfaces, offset, false);\n@@ -6421,0 +6886,3 @@\n+    if (other->is_null_free() && !this_one->is_null_free()) {\n+      return false; \/\/ A nullable array can't be a subtype of a null-free array\n+    }\n@@ -6513,1 +6981,1 @@\n-  return new TypeAryKlassPtr(dual_ptr(), elem()->dual(), klass(), dual_offset());\n+  return new TypeAryKlassPtr(dual_ptr(), elem()->dual(), klass(), dual_offset(), !is_not_flat(), !is_not_null_free(), dual_null_free());\n@@ -6523,1 +6991,1 @@\n-    k = ciObjArrayKlass::make(k);\n+    k = ciArrayKlass::make(k, _null_free);\n@@ -6570,5 +7038,5 @@\n-\n-  if( _offset ) {               \/\/ Dump offset, if any\n-    if( _offset == OffsetBot )      { st->print(\"+any\"); }\n-    else if( _offset == OffsetTop ) { st->print(\"+unknown\"); }\n-    else                            { st->print(\"+%d\", _offset); }\n+  if (is_flat()) st->print(\":flat\");\n+  if (_null_free) st->print(\":null free\");\n+  if (Verbose) {\n+    if (_not_flat) st->print(\":not flat\");\n+    if (_not_null_free) st->print(\":not null free\");\n@@ -6577,0 +7045,2 @@\n+  _offset.dump2(st);\n+\n@@ -6595,2 +7065,14 @@\n-const TypeFunc *TypeFunc::make( const TypeTuple *domain, const TypeTuple *range ) {\n-  return (TypeFunc*)(new TypeFunc(domain,range))->hashcons();\n+const TypeFunc *TypeFunc::make(const TypeTuple *domain_sig, const TypeTuple* domain_cc,\n+                               const TypeTuple *range_sig, const TypeTuple *range_cc) {\n+  return (TypeFunc*)(new TypeFunc(domain_sig, domain_cc, range_sig, range_cc))->hashcons();\n+}\n+\n+const TypeFunc *TypeFunc::make(const TypeTuple *domain, const TypeTuple *range) {\n+  return make(domain, domain, range, range);\n+}\n+\n+\/\/------------------------------osr_domain-----------------------------\n+const TypeTuple* osr_domain() {\n+  const Type **fields = TypeTuple::fields(2);\n+  fields[TypeFunc::Parms+0] = TypeRawPtr::BOTTOM;  \/\/ address of osr buffer\n+  return TypeTuple::make(TypeFunc::Parms+1, fields);\n@@ -6600,1 +7082,1 @@\n-const TypeFunc *TypeFunc::make(ciMethod* method) {\n+const TypeFunc* TypeFunc::make(ciMethod* method, bool is_osr_compilation) {\n@@ -6602,7 +7084,24 @@\n-  const TypeFunc* tf = C->last_tf(method); \/\/ check cache\n-  if (tf != nullptr)  return tf;  \/\/ The hit rate here is almost 50%.\n-  const TypeTuple *domain;\n-  if (method->is_static()) {\n-    domain = TypeTuple::make_domain(nullptr, method->signature(), ignore_interfaces);\n-  } else {\n-    domain = TypeTuple::make_domain(method->holder(), method->signature(), ignore_interfaces);\n+  const TypeFunc* tf = nullptr;\n+  if (!is_osr_compilation) {\n+    tf = C->last_tf(method); \/\/ check cache\n+    if (tf != nullptr)  return tf;  \/\/ The hit rate here is almost 50%.\n+  }\n+  \/\/ Inline types are not passed\/returned by reference, instead each field of\n+  \/\/ the inline type is passed\/returned as an argument. We maintain two views of\n+  \/\/ the argument\/return list here: one based on the signature (with an inline\n+  \/\/ type argument\/return as a single slot), one based on the actual calling\n+  \/\/ convention (with an inline type argument\/return as a list of its fields).\n+  bool has_scalar_args = method->has_scalarized_args() && !is_osr_compilation;\n+  \/\/ Fall back to the non-scalarized calling convention when compiling a call via a mismatching method\n+  if (method != C->method() && method->get_Method()->mismatch()) {\n+    has_scalar_args = false;\n+  }\n+  const TypeTuple* domain_sig = is_osr_compilation ? osr_domain() : TypeTuple::make_domain(method, ignore_interfaces, false);\n+  const TypeTuple* domain_cc = has_scalar_args ? TypeTuple::make_domain(method, ignore_interfaces, true) : domain_sig;\n+  ciSignature* sig = method->signature();\n+  bool has_scalar_ret = !method->is_native() && sig->return_type()->is_inlinetype() && sig->return_type()->as_inline_klass()->can_be_returned_as_fields();\n+  const TypeTuple* range_sig = TypeTuple::make_range(sig, ignore_interfaces, false);\n+  const TypeTuple* range_cc = has_scalar_ret ? TypeTuple::make_range(sig, ignore_interfaces, true) : range_sig;\n+  tf = TypeFunc::make(domain_sig, domain_cc, range_sig, range_cc);\n+  if (!is_osr_compilation) {\n+    C->set_last_tf(method, tf);  \/\/ fill cache\n@@ -6610,3 +7109,0 @@\n-  const TypeTuple *range  = TypeTuple::make_range(method->signature(), ignore_interfaces);\n-  tf = TypeFunc::make(domain, range);\n-  C->set_last_tf(method, tf);  \/\/ fill cache\n@@ -6647,2 +7143,4 @@\n-  return _domain == a->_domain &&\n-    _range == a->_range;\n+  return _domain_sig == a->_domain_sig &&\n+    _domain_cc == a->_domain_cc &&\n+    _range_sig == a->_range_sig &&\n+    _range_cc == a->_range_cc;\n@@ -6654,1 +7152,1 @@\n-  return (uint)(uintptr_t)_domain + (uint)(uintptr_t)_range;\n+  return (uint)(intptr_t)_domain_sig + (uint)(intptr_t)_domain_cc + (uint)(intptr_t)_range_sig + (uint)(intptr_t)_range_cc;\n@@ -6661,1 +7159,1 @@\n-  if( _range->cnt() <= Parms )\n+  if( _range_sig->cnt() <= Parms )\n@@ -6665,2 +7163,2 @@\n-    for (i = Parms; i < _range->cnt()-1; i++) {\n-      _range->field_at(i)->dump2(d,depth,st);\n+    for (i = Parms; i < _range_sig->cnt()-1; i++) {\n+      _range_sig->field_at(i)->dump2(d,depth,st);\n@@ -6669,1 +7167,1 @@\n-    _range->field_at(i)->dump2(d,depth,st);\n+    _range_sig->field_at(i)->dump2(d,depth,st);\n@@ -6678,3 +7176,3 @@\n-  if (Parms < _domain->cnt())\n-    _domain->field_at(Parms)->dump2(d,depth-1,st);\n-  for (uint i = Parms+1; i < _domain->cnt(); i++) {\n+  if (Parms < _domain_sig->cnt())\n+    _domain_sig->field_at(Parms)->dump2(d,depth-1,st);\n+  for (uint i = Parms+1; i < _domain_sig->cnt(); i++) {\n@@ -6682,1 +7180,1 @@\n-    _domain->field_at(i)->dump2(d,depth-1,st);\n+    _domain_sig->field_at(i)->dump2(d,depth-1,st);\n@@ -6702,1 +7200,1 @@\n-  if (range()->cnt() == TypeFunc::Parms) {\n+  if (range_sig()->cnt() == TypeFunc::Parms) {\n@@ -6705,1 +7203,1 @@\n-  return range()->field_at(TypeFunc::Parms)->basic_type();\n+  return range_sig()->field_at(TypeFunc::Parms)->basic_type();\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":834,"deletions":336,"binary":false,"changes":1170,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -30,0 +31,1 @@\n+#include \"runtime\/sharedRuntime.hpp\"\n@@ -139,0 +141,24 @@\n+  class Offset {\n+  private:\n+    int _offset;\n+\n+  public:\n+    explicit Offset(int offset) : _offset(offset) {}\n+\n+    const Offset meet(const Offset other) const;\n+    const Offset dual() const;\n+    const Offset add(intptr_t offset) const;\n+    bool operator==(const Offset& other) const {\n+      return _offset == other._offset;\n+    }\n+    bool operator!=(const Offset& other) const {\n+      return _offset != other._offset;\n+    }\n+    int get() const { return _offset; }\n+\n+    void dump2(outputStream *st) const;\n+\n+    static const Offset top;\n+    static const Offset bottom;\n+  };\n+\n@@ -329,0 +355,3 @@\n+  bool is_inlinetypeptr() const;\n+  virtual ciInlineKlass* inline_klass() const;\n+\n@@ -727,2 +756,2 @@\n-  static const TypeTuple *make_range(ciSignature *sig, InterfaceHandling interface_handling = ignore_interfaces);\n-  static const TypeTuple *make_domain(ciInstanceKlass* recv, ciSignature *sig, InterfaceHandling interface_handling);\n+  static const TypeTuple *make_range(ciSignature* sig, InterfaceHandling interface_handling = ignore_interfaces, bool ret_vt_fields = false);\n+  static const TypeTuple *make_domain(ciMethod* method, InterfaceHandling interface_handling, bool vt_fields_as_args = false);\n@@ -757,2 +786,2 @@\n-  TypeAry(const Type* elem, const TypeInt* size, bool stable) : Type(Array),\n-      _elem(elem), _size(size), _stable(stable) {}\n+  TypeAry(const Type* elem, const TypeInt* size, bool stable, bool flat, bool not_flat, bool not_null_free) : Type(Array),\n+      _elem(elem), _size(size), _stable(stable), _flat(flat), _not_flat(not_flat), _not_null_free(not_null_free) {}\n@@ -769,0 +798,6 @@\n+\n+  \/\/ Inline type array properties\n+  const bool _flat;             \/\/ Array is flat\n+  const bool _not_flat;         \/\/ Array is never flat\n+  const bool _not_null_free;    \/\/ Array is never null-free\n+\n@@ -772,1 +807,2 @@\n-  static const TypeAry* make(const Type* elem, const TypeInt* size, bool stable = false);\n+  static const TypeAry* make(const Type* elem, const TypeInt* size, bool stable = false,\n+                             bool flat = false, bool not_flat = false, bool not_null_free = false);\n@@ -933,1 +969,1 @@\n-  TypePtr(TYPES t, PTR ptr, int offset,\n+  TypePtr(TYPES t, PTR ptr, Offset offset,\n@@ -989,1 +1025,4 @@\n-                                                            const T* other_type, ciKlass*& res_klass, bool& res_xk);\n+                                                            const T* other_type, ciKlass*& res_klass, bool& res_xk, bool& res_flat_array);\n+ private:\n+  template<class T> static bool is_meet_subtype_of(const T* sub_type, const T* super_type);\n+ protected:\n@@ -992,1 +1031,1 @@\n-                                                  ciKlass*& res_klass, bool& res_xk);\n+                                                  ciKlass*& res_klass, bool& res_xk, bool &res_flat, bool &res_not_flat, bool &res_not_null_free);\n@@ -1003,1 +1042,1 @@\n-  const int _offset;            \/\/ Offset into oop, with TOP & BOT\n+  const Offset _offset;         \/\/ Offset into oop, with TOP & BOT\n@@ -1006,1 +1045,1 @@\n-  int offset() const { return _offset; }\n+  int offset() const { return _offset.get(); }\n@@ -1009,1 +1048,1 @@\n-  static const TypePtr *make(TYPES t, PTR ptr, int offset,\n+  static const TypePtr* make(TYPES t, PTR ptr, Offset offset,\n@@ -1018,1 +1057,1 @@\n-  int xadd_offset( intptr_t offset ) const;\n+  Type::Offset xadd_offset(intptr_t offset) const;\n@@ -1021,0 +1060,1 @@\n+  virtual int flat_offset() const { return offset(); }\n@@ -1028,2 +1068,2 @@\n-  int meet_offset( int offset ) const;\n-  int dual_offset( ) const;\n+  Offset meet_offset(int offset) const;\n+  Offset dual_offset() const;\n@@ -1057,0 +1097,8 @@\n+  virtual bool can_be_inline_type() const { return false; }\n+  virtual bool flat_in_array()      const { return false; }\n+  virtual bool not_flat_in_array()  const { return true; }\n+  virtual bool is_flat()            const { return false; }\n+  virtual bool is_not_flat()        const { return false; }\n+  virtual bool is_null_free()       const { return false; }\n+  virtual bool is_not_null_free()   const { return false; }\n+\n@@ -1074,1 +1122,1 @@\n-  TypeRawPtr( PTR ptr, address bits ) : TypePtr(RawPtr,ptr,0), _bits(bits){}\n+  TypeRawPtr(PTR ptr, address bits) : TypePtr(RawPtr,ptr,Offset(0)), _bits(bits){}\n@@ -1110,1 +1158,1 @@\n- TypeOopPtr(TYPES t, PTR ptr, ciKlass* k, const TypeInterfaces* interfaces, bool xk, ciObject* o, int offset, int instance_id,\n+ TypeOopPtr(TYPES t, PTR ptr, ciKlass* k, const TypeInterfaces* interfaces, bool xk, ciObject* o, Offset offset, Offset field_offset, int instance_id,\n@@ -1151,1 +1199,1 @@\n-  virtual ciKlass* klass() const { return _klass;     }\n+  virtual ciKlass* klass() const { return _klass; }\n@@ -1198,1 +1246,1 @@\n-  static const TypeOopPtr* make(PTR ptr, int offset, int instance_id,\n+  static const TypeOopPtr* make(PTR ptr, Offset offset, int instance_id,\n@@ -1217,1 +1265,4 @@\n-  bool is_known_instance_field() const { return is_known_instance() && _offset >= 0; }\n+  bool is_known_instance_field() const { return is_known_instance() && _offset.get() >= 0; }\n+\n+  virtual bool can_be_inline_type() const { return (_klass == nullptr || _klass->can_be_inline_klass(_klass_is_exact)); }\n+  virtual bool can_be_inline_array() const { ShouldNotReachHere(); return false; }\n@@ -1280,2 +1331,3 @@\n-  TypeInstPtr(PTR ptr, ciKlass* k, const TypeInterfaces* interfaces, bool xk, ciObject* o, int off, int instance_id,\n-              const TypePtr* speculative, int inline_depth);\n+  TypeInstPtr(PTR ptr, ciKlass* k, const TypeInterfaces* interfaces, bool xk, ciObject* o, Offset offset,\n+              bool flat_in_array, int instance_id, const TypePtr* speculative,\n+              int inline_depth);\n@@ -1284,1 +1336,1 @@\n-\n+  bool _flat_in_array; \/\/ Type is flat in arrays\n@@ -1303,1 +1355,1 @@\n-    return make(TypePtr::Constant, k, interfaces, true, o, 0, InstanceBot);\n+    return make(TypePtr::Constant, k, interfaces, true, o, Offset(0));\n@@ -1306,1 +1358,1 @@\n-  static const TypeInstPtr *make(ciObject* o, int offset) {\n+  static const TypeInstPtr *make(ciObject* o, Offset offset) {\n@@ -1309,1 +1361,1 @@\n-    return make(TypePtr::Constant, k, interfaces, true, o, offset, InstanceBot);\n+    return make(TypePtr::Constant, k, interfaces, true, o, offset);\n@@ -1315,1 +1367,1 @@\n-    return make(ptr, klass, interfaces, false, nullptr, 0, InstanceBot);\n+    return make(ptr, klass, interfaces, false, nullptr, Offset(0));\n@@ -1321,1 +1373,1 @@\n-    return make(ptr, klass, interfaces, true, nullptr, 0, InstanceBot);\n+    return make(ptr, klass, interfaces, true, nullptr, Offset(0));\n@@ -1325,1 +1377,1 @@\n-  static const TypeInstPtr *make(PTR ptr, ciKlass* klass, int offset) {\n+  static const TypeInstPtr *make(PTR ptr, ciKlass* klass, Offset offset) {\n@@ -1327,1 +1379,1 @@\n-    return make(ptr, klass, interfaces, false, nullptr, offset, InstanceBot);\n+    return make(ptr, klass, interfaces, false, nullptr, offset);\n@@ -1330,1 +1382,3 @@\n-  static const TypeInstPtr *make(PTR ptr, ciKlass* k, const TypeInterfaces* interfaces, bool xk, ciObject* o, int offset,\n+  \/\/ Make a pointer to an oop.\n+  static const TypeInstPtr* make(PTR ptr, ciKlass* k, const TypeInterfaces* interfaces, bool xk, ciObject* o, Offset offset,\n+                                 bool flat_in_array = false,\n@@ -1335,1 +1389,1 @@\n-  static const TypeInstPtr *make(PTR ptr, ciKlass* k, bool xk, ciObject* o, int offset, int instance_id = InstanceBot) {\n+  static const TypeInstPtr *make(PTR ptr, ciKlass* k, bool xk, ciObject* o, Offset offset, int instance_id = InstanceBot) {\n@@ -1337,1 +1391,1 @@\n-    return make(ptr, k, interfaces, xk, o, offset, instance_id);\n+    return make(ptr, k, interfaces, xk, o, offset, false, instance_id);\n@@ -1346,1 +1400,1 @@\n-  ciType* java_mirror_type() const;\n+  ciType* java_mirror_type(bool* is_null_free_array = nullptr) const;\n@@ -1362,0 +1416,4 @@\n+  virtual const TypeInstPtr* cast_to_flat_in_array() const;\n+  virtual bool flat_in_array() const { return _flat_in_array; }\n+  virtual bool not_flat_in_array() const { return !can_be_inline_type() || (_klass->is_inlinetype() && !flat_in_array()); }\n+\n@@ -1369,0 +1427,2 @@\n+  virtual bool can_be_inline_array() const;\n+\n@@ -1393,0 +1453,1 @@\n+  friend class TypeInstPtr;\n@@ -1394,4 +1455,4 @@\n-  TypeAryPtr( PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk,\n-              int offset, int instance_id, bool is_autobox_cache,\n-              const TypePtr* speculative, int inline_depth)\n-    : TypeOopPtr(AryPtr,ptr,k,_array_interfaces,xk,o,offset, instance_id, speculative, inline_depth),\n+  TypeAryPtr(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk,\n+             Offset offset, Offset field_offset, int instance_id, bool is_autobox_cache,\n+             const TypePtr* speculative, int inline_depth)\n+    : TypeOopPtr(AryPtr, ptr, k, _array_interfaces, xk, o, offset, field_offset, instance_id, speculative, inline_depth),\n@@ -1399,1 +1460,2 @@\n-    _is_autobox_cache(is_autobox_cache)\n+    _is_autobox_cache(is_autobox_cache),\n+    _field_offset(field_offset)\n@@ -1405,2 +1467,2 @@\n-        _offset != 0 && _offset != arrayOopDesc::length_offset_in_bytes() &&\n-        _offset != arrayOopDesc::klass_offset_in_bytes()) {\n+        _offset.get() != 0 && _offset.get() != arrayOopDesc::length_offset_in_bytes() &&\n+        _offset.get() != arrayOopDesc::klass_offset_in_bytes()) {\n@@ -1415,0 +1477,6 @@\n+  \/\/ For flat inline type arrays, each field of the inline type in\n+  \/\/ the array has its own memory slice so we need to keep track of\n+  \/\/ which field is accessed\n+  const Offset _field_offset;\n+  Offset meet_field_offset(const Type::Offset offset) const;\n+  Offset dual_field_offset() const;\n@@ -1442,0 +1510,6 @@\n+  \/\/ Inline type array properties\n+  bool is_flat()          const { return _ary->_flat; }\n+  bool is_not_flat()      const { return _ary->_not_flat; }\n+  bool is_null_free()     const { return is_flat() || (_ary->_elem->make_ptr() != nullptr && _ary->_elem->make_ptr()->is_inlinetypeptr() && (_ary->_elem->make_ptr()->ptr() == NotNull || _ary->_elem->make_ptr()->ptr() == AnyNull)); }\n+  bool is_not_null_free() const { return _ary->_not_null_free; }\n+\n@@ -1444,1 +1518,2 @@\n-  static const TypeAryPtr *make(PTR ptr, const TypeAry *ary, ciKlass* k, bool xk, int offset,\n+  static const TypeAryPtr* make(PTR ptr, const TypeAry *ary, ciKlass* k, bool xk, Offset offset,\n+                                Offset field_offset = Offset::bottom,\n@@ -1449,1 +1524,2 @@\n-  static const TypeAryPtr *make(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk, int offset,\n+  static const TypeAryPtr* make(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk, Offset offset,\n+                                Offset field_offset = Offset::bottom,\n@@ -1452,1 +1528,2 @@\n-                                int inline_depth = InlineDepthBottom, bool is_autobox_cache = false);\n+                                int inline_depth = InlineDepthBottom,\n+                                bool is_autobox_cache = false);\n@@ -1471,0 +1548,1 @@\n+  virtual const Type* cleanup_speculative() const;\n@@ -1478,0 +1556,8 @@\n+  \/\/ Inline type array properties\n+  const TypeAryPtr* cast_to_not_flat(bool not_flat = true) const;\n+  const TypeAryPtr* cast_to_not_null_free(bool not_null_free = true) const;\n+  const TypeAryPtr* update_properties(const TypeAryPtr* new_type) const;\n+  jint flat_layout_helper() const;\n+  int flat_elem_size() const;\n+  int flat_log_elem_size() const;\n+\n@@ -1483,1 +1569,8 @@\n-  static jint max_array_length(BasicType etype) ;\n+  static jint max_array_length(BasicType etype);\n+\n+  int flat_offset() const;\n+  const Offset field_offset() const { return _field_offset; }\n+  const TypeAryPtr* with_field_offset(int offset) const;\n+  const TypePtr* add_field_offset_and_offset(intptr_t offset) const;\n+\n+  virtual bool can_be_inline_type() const { return false; }\n@@ -1486,0 +1579,2 @@\n+  virtual bool can_be_inline_array() const;\n+\n@@ -1497,0 +1592,1 @@\n+  static const TypeAryPtr *INLINES;\n@@ -1515,1 +1611,1 @@\n-  TypeMetadataPtr(PTR ptr, ciMetadata* metadata, int offset);\n+  TypeMetadataPtr(PTR ptr, ciMetadata* metadata, Offset offset);\n@@ -1527,1 +1623,1 @@\n-  static const TypeMetadataPtr* make(PTR ptr, ciMetadata* m, int offset);\n+  static const TypeMetadataPtr* make(PTR ptr, ciMetadata* m, Offset offset);\n@@ -1558,1 +1654,1 @@\n-  TypeKlassPtr(TYPES t, PTR ptr, ciKlass* klass, const TypeInterfaces* interfaces, int offset);\n+  TypeKlassPtr(TYPES t, PTR ptr, ciKlass* klass, const TypeInterfaces* interfaces, Offset offset);\n@@ -1597,1 +1693,1 @@\n-  static const TypeKlassPtr *make(PTR ptr, ciKlass* klass, int offset, InterfaceHandling interface_handling = ignore_interfaces);\n+  static const TypeKlassPtr *make(PTR ptr, ciKlass* klass, Offset offset, InterfaceHandling interface_handling = ignore_interfaces);\n@@ -1616,0 +1712,1 @@\n+  virtual bool can_be_inline_array() const { ShouldNotReachHere(); return false; }\n@@ -1650,2 +1747,2 @@\n-  TypeInstKlassPtr(PTR ptr, ciKlass* klass, const TypeInterfaces* interfaces, int offset)\n-    : TypeKlassPtr(InstKlassPtr, ptr, klass, interfaces, offset) {\n+  TypeInstKlassPtr(PTR ptr, ciKlass* klass, const TypeInterfaces* interfaces, Offset offset, bool flat_in_array)\n+    : TypeKlassPtr(InstKlassPtr, ptr, klass, interfaces, offset), _flat_in_array(flat_in_array) {\n@@ -1657,0 +1754,2 @@\n+  const bool _flat_in_array; \/\/ Type is flat in arrays\n+\n@@ -1668,0 +1767,2 @@\n+  virtual bool can_be_inline_type() const { return (_klass == nullptr || _klass->can_be_inline_klass(klass_is_exact())); }\n+\n@@ -1670,1 +1771,1 @@\n-    return make(TypePtr::Constant, k, interfaces, 0);\n+    return make(TypePtr::Constant, k, interfaces, Offset(0));\n@@ -1672,1 +1773,1 @@\n-  static const TypeInstKlassPtr* make(PTR ptr, ciKlass* k, const TypeInterfaces* interfaces, int offset);\n+  static const TypeInstKlassPtr* make(PTR ptr, ciKlass* k, const TypeInterfaces* interfaces, Offset offset, bool flat_in_array = false);\n@@ -1674,1 +1775,1 @@\n-  static const TypeInstKlassPtr* make(PTR ptr, ciKlass* k, int offset) {\n+  static const TypeInstKlassPtr* make(PTR ptr, ciKlass* k, Offset offset) {\n@@ -1695,0 +1796,5 @@\n+  virtual bool flat_in_array() const { return _flat_in_array; }\n+  virtual bool not_flat_in_array() const { return !_klass->can_be_inline_klass() || (_klass->is_inlinetype() && !flat_in_array()); }\n+\n+  virtual bool can_be_inline_array() const;\n+\n@@ -1709,0 +1815,3 @@\n+  const bool _not_flat;      \/\/ Array is never flat\n+  const bool _not_null_free; \/\/ Array is never null-free\n+  const bool _null_free;\n@@ -1711,3 +1820,3 @@\n-  TypeAryKlassPtr(PTR ptr, const Type *elem, ciKlass* klass, int offset)\n-    : TypeKlassPtr(AryKlassPtr, ptr, klass, _array_interfaces, offset), _elem(elem) {\n-    assert(klass == nullptr || klass->is_type_array_klass() || !klass->as_obj_array_klass()->base_element_klass()->is_interface(), \"\");\n+  TypeAryKlassPtr(PTR ptr, const Type *elem, ciKlass* klass, Offset offset, bool not_flat, int not_null_free, bool null_free)\n+    : TypeKlassPtr(AryKlassPtr, ptr, klass, _array_interfaces, offset), _elem(elem), _not_flat(not_flat), _not_null_free(not_null_free), _null_free(null_free) {\n+    assert(klass == nullptr || klass->is_type_array_klass() || klass->is_flat_array_klass() || !klass->as_obj_array_klass()->base_element_klass()->is_interface(), \"\");\n@@ -1722,0 +1831,8 @@\n+  bool dual_null_free() const {\n+    return _null_free;\n+  }\n+\n+  bool meet_null_free(bool other) const {\n+    return _null_free && other;\n+  }\n+\n@@ -1727,1 +1844,1 @@\n-  static const TypeAryKlassPtr *make(PTR ptr, ciKlass* k, int offset, InterfaceHandling interface_handling);\n+  static const TypeAryKlassPtr* make(PTR ptr, ciKlass* k, Offset offset, InterfaceHandling interface_handling, bool not_flat, bool not_null_free, bool null_free);\n@@ -1735,1 +1852,2 @@\n-  static const TypeAryKlassPtr *make(PTR ptr, const Type *elem, ciKlass* k, int offset);\n+  static const TypeAryKlassPtr* make(PTR ptr, const Type* elem, ciKlass* k, Offset offset, bool not_flat, bool not_null_free, bool null_free);\n+  static const TypeAryKlassPtr* make(PTR ptr, ciKlass* k, Offset offset, InterfaceHandling interface_handling);\n@@ -1747,0 +1865,2 @@\n+  const TypeAryKlassPtr* cast_to_null_free() const;\n+\n@@ -1760,0 +1880,6 @@\n+  bool is_flat()          const { return klass() != nullptr && klass()->is_flat_array_klass(); }\n+  bool is_not_flat()      const { return _not_flat; }\n+  bool is_null_free()     const { return _null_free; }\n+  bool is_not_null_free() const { return _not_null_free; }\n+  virtual bool can_be_inline_array() const;\n+\n@@ -1895,1 +2021,2 @@\n-  TypeFunc( const TypeTuple *domain, const TypeTuple *range ) : Type(Function),  _domain(domain), _range(range) {}\n+  TypeFunc(const TypeTuple *domain_sig, const TypeTuple *domain_cc, const TypeTuple *range_sig, const TypeTuple *range_cc)\n+    : Type(Function), _domain_sig(domain_sig), _domain_cc(domain_cc), _range_sig(range_sig), _range_cc(range_cc) {}\n@@ -1901,2 +2028,13 @@\n-  const TypeTuple* const _domain;     \/\/ Domain of inputs\n-  const TypeTuple* const _range;      \/\/ Range of results\n+  \/\/ Domains of inputs: inline type arguments are not passed by\n+  \/\/ reference, instead each field of the inline type is passed as an\n+  \/\/ argument. We maintain 2 views of the argument list here: one\n+  \/\/ based on the signature (with an inline type argument as a single\n+  \/\/ slot), one based on the actual calling convention (with a value\n+  \/\/ type argument as a list of its fields).\n+  const TypeTuple* const _domain_sig;\n+  const TypeTuple* const _domain_cc;\n+  \/\/ Range of results. Similar to domains: an inline type result can be\n+  \/\/ returned in registers in which case range_cc lists all fields and\n+  \/\/ is the actual calling convention.\n+  const TypeTuple* const _range_sig;\n+  const TypeTuple* const _range_cc;\n@@ -1916,5 +2054,8 @@\n-  const TypeTuple* domain() const { return _domain; }\n-  const TypeTuple* range()  const { return _range; }\n-\n-  static const TypeFunc *make(ciMethod* method);\n-  static const TypeFunc *make(ciSignature signature, const Type* extra);\n+  const TypeTuple* domain_sig() const { return _domain_sig; }\n+  const TypeTuple* domain_cc()  const { return _domain_cc; }\n+  const TypeTuple* range_sig()  const { return _range_sig; }\n+  const TypeTuple* range_cc()   const { return _range_cc; }\n+\n+  static const TypeFunc* make(ciMethod* method, bool is_osr_compilation = false);\n+  static const TypeFunc *make(const TypeTuple* domain_sig, const TypeTuple* domain_cc,\n+                              const TypeTuple* range_sig, const TypeTuple* range_cc);\n@@ -1928,0 +2069,2 @@\n+  bool returns_inline_type_as_fields() const { return range_sig() != range_cc(); }\n+\n@@ -2183,0 +2326,8 @@\n+inline bool Type::is_inlinetypeptr() const {\n+  return isa_instptr() != nullptr && is_instptr()->instance_klass()->is_inlinetype();\n+}\n+\n+inline ciInlineKlass* Type::inline_klass() const {\n+  return make_ptr()->is_instptr()->instance_klass()->as_inline_klass();\n+}\n+\n@@ -2209,0 +2360,1 @@\n+#define CmpUXNode    CmpULNode\n@@ -2227,0 +2379,1 @@\n+#define Op_StoreX    Op_StoreL\n@@ -2255,0 +2408,1 @@\n+#define CmpUXNode    CmpUNode\n@@ -2273,0 +2427,1 @@\n+#define Op_StoreX    Op_StoreI\n","filename":"src\/hotspot\/share\/opto\/type.hpp","additions":221,"deletions":66,"binary":false,"changes":287,"status":"modified"},{"patch":"@@ -77,0 +77,1 @@\n+#include <string.h>\n@@ -1788,1 +1789,0 @@\n-unsigned int patch_mod_count = 0;\n@@ -1835,0 +1835,10 @@\n+  if (AMD64_ONLY(false &&) AARCH64_ONLY(false &&) !FLAG_IS_DEFAULT(InlineTypePassFieldsAsArgs)) {\n+    FLAG_SET_CMDLINE(InlineTypePassFieldsAsArgs, false);\n+    warning(\"InlineTypePassFieldsAsArgs is not supported on this platform\");\n+  }\n+\n+  if (AMD64_ONLY(false &&) AARCH64_ONLY(false &&) !FLAG_IS_DEFAULT(InlineTypeReturnedAsFields)) {\n+    FLAG_SET_CMDLINE(InlineTypeReturnedAsFields, false);\n+    warning(\"InlineTypeReturnedAsFields is not supported on this platform\");\n+  }\n+\n@@ -1963,2 +1973,0 @@\n-  bool patch_mod_javabase = false;\n-\n@@ -1978,1 +1986,1 @@\n-  jint result = parse_each_vm_init_arg(vm_options_args, &patch_mod_javabase, JVMFlagOrigin::JIMAGE_RESOURCE);\n+  jint result = parse_each_vm_init_arg(vm_options_args, JVMFlagOrigin::JIMAGE_RESOURCE);\n@@ -1985,1 +1993,1 @@\n-  result = parse_each_vm_init_arg(java_tool_options_args, &patch_mod_javabase, JVMFlagOrigin::ENVIRON_VAR);\n+  result = parse_each_vm_init_arg(java_tool_options_args, JVMFlagOrigin::ENVIRON_VAR);\n@@ -1991,1 +1999,1 @@\n-  result = parse_each_vm_init_arg(cmd_line_args, &patch_mod_javabase, JVMFlagOrigin::COMMAND_LINE);\n+  result = parse_each_vm_init_arg(cmd_line_args, JVMFlagOrigin::COMMAND_LINE);\n@@ -1998,1 +2006,1 @@\n-  result = parse_each_vm_init_arg(java_options_args, &patch_mod_javabase, JVMFlagOrigin::ENVIRON_VAR);\n+  result = parse_each_vm_init_arg(java_options_args, JVMFlagOrigin::ENVIRON_VAR);\n@@ -2019,1 +2027,1 @@\n-  result = finalize_vm_init_args(patch_mod_javabase);\n+  result = finalize_vm_init_args();\n@@ -2074,1 +2082,1 @@\n-int Arguments::process_patch_mod_option(const char* patch_mod_tail, bool* patch_mod_javabase) {\n+int Arguments::process_patch_mod_option(const char* patch_mod_tail) {\n@@ -2090,1 +2098,1 @@\n-      add_patch_mod_prefix(module_name, module_equal + 1, patch_mod_javabase);\n+      add_patch_mod_prefix(module_name, module_equal + 1, false \/* no append *\/, false \/* no cds *\/);\n@@ -2092,3 +2100,0 @@\n-      if (!create_numbered_module_property(\"jdk.module.patch\", patch_mod_tail, patch_mod_count++)) {\n-        return JNI_ENOMEM;\n-      }\n@@ -2102,0 +2107,64 @@\n+\/\/ VALUECLASS_STR must match string used in the build\n+#define VALUECLASS_STR \"valueclasses\"\n+#define VALUECLASS_JAR \"-\" VALUECLASS_STR \".jar\"\n+\n+\/\/ Finalize --patch-module args and --enable-preview related to value class module patches.\n+\/\/ Create all numbered properties passing module patches.\n+int Arguments::finalize_patch_module() {\n+  \/\/ If --enable-preview and EnableValhalla is true, each module may have value classes that\n+  \/\/ are to be patched into the module.\n+  \/\/ For each <module>-valueclasses.jar in <JAVA_HOME>\/lib\/valueclasses\/\n+  \/\/ appends the equivalent of --patch-module <module>=<JAVA_HOME>\/lib\/valueclasses\/<module>-valueclasses.jar\n+  if (enable_preview() && EnableValhalla) {\n+    char * valueclasses_dir = AllocateHeap(JVM_MAXPATHLEN, mtArguments);\n+    const char * fileSep = os::file_separator();\n+\n+    jio_snprintf(valueclasses_dir, JVM_MAXPATHLEN, \"%s%slib%s\" VALUECLASS_STR \"%s\",\n+                 Arguments::get_java_home(), fileSep, fileSep, fileSep);\n+    DIR* dir = os::opendir(valueclasses_dir);\n+    if (dir != nullptr) {\n+      char * module_name = AllocateHeap(JVM_MAXPATHLEN, mtArguments);\n+      char * path = AllocateHeap(JVM_MAXPATHLEN, mtArguments);\n+\n+      for (dirent * entry = os::readdir(dir); entry != nullptr; entry = os::readdir(dir)) {\n+        \/\/ Test if file ends-with \"-valueclasses.jar\"\n+        int len = (int)strlen(entry->d_name) - (sizeof(VALUECLASS_JAR) - 1);\n+        if (len <= 0 || strcmp(&entry->d_name[len], VALUECLASS_JAR) != 0) {\n+          continue;         \/\/ too short or not the expected suffix\n+        }\n+\n+        strcpy(module_name, entry->d_name);\n+        module_name[len] = '\\0';     \/\/ truncate to just module-name\n+\n+        jio_snprintf(path, JVM_MAXPATHLEN, \"%s%s\", valueclasses_dir, &entry->d_name);\n+        add_patch_mod_prefix(module_name, path, true \/* append *\/, true \/* cds OK*\/);\n+        log_info(class)(\"--enable-preview appending value classes for module %s: %s\", module_name, entry->d_name);\n+      }\n+      FreeHeap(module_name);\n+      FreeHeap(path);\n+      os::closedir(dir);\n+    }\n+    FreeHeap(valueclasses_dir);\n+  }\n+\n+  \/\/ Create numbered properties for each module that has been patched either\n+  \/\/ by --patch-module or --enable-preview\n+  \/\/ Format is \"jdk.module.patch.<n>=<module_name>=<path>\"\n+  if (_patch_mod_prefix != nullptr) {\n+    char * prop_value = AllocateHeap(JVM_MAXPATHLEN + JVM_MAXPATHLEN + 1, mtArguments);\n+    unsigned int patch_mod_count = 0;\n+\n+    for (GrowableArrayIterator<ModulePatchPath *> it = _patch_mod_prefix->begin();\n+            it != _patch_mod_prefix->end(); ++it) {\n+      jio_snprintf(prop_value, JVM_MAXPATHLEN + JVM_MAXPATHLEN + 1, \"%s=%s\",\n+                   (*it)->module_name(), (*it)->path_string());\n+      if (!create_numbered_module_property(\"jdk.module.patch\", prop_value, patch_mod_count++)) {\n+        FreeHeap(prop_value);\n+        return JNI_ENOMEM;\n+      }\n+    }\n+    FreeHeap(prop_value);\n+  }\n+  return JNI_OK;\n+}\n+\n@@ -2156,1 +2225,1 @@\n-jint Arguments::parse_each_vm_init_arg(const JavaVMInitArgs* args, bool* patch_mod_javabase, JVMFlagOrigin origin) {\n+jint Arguments::parse_each_vm_init_arg(const JavaVMInitArgs* args, JVMFlagOrigin origin) {\n@@ -2279,1 +2348,1 @@\n-      int res = process_patch_mod_option(tail, patch_mod_javabase);\n+      int res = process_patch_mod_option(tail);\n@@ -2340,0 +2409,4 @@\n+      \/\/ --enable-preview enables Valhalla, EnableValhalla VM option will eventually be removed before integration\n+      if (FLAG_SET_CMDLINE(EnableValhalla, true) != JVMFlag::SUCCESS) {\n+        return JNI_EINVAL;\n+      }\n@@ -2815,10 +2888,5 @@\n-void Arguments::add_patch_mod_prefix(const char* module_name, const char* path, bool* patch_mod_javabase) {\n-  \/\/ For java.base check for duplicate --patch-module options being specified on the command line.\n-  \/\/ This check is only required for java.base, all other duplicate module specifications\n-  \/\/ will be checked during module system initialization.  The module system initialization\n-  \/\/ will throw an ExceptionInInitializerError if this situation occurs.\n-  if (strcmp(module_name, JAVA_BASE_NAME) == 0) {\n-    if (*patch_mod_javabase) {\n-      vm_exit_during_initialization(\"Cannot specify \" JAVA_BASE_NAME \" more than once to --patch-module\");\n-    } else {\n-      *patch_mod_javabase = true;\n+void Arguments::add_patch_mod_prefix(const char* module_name, const char* path, bool allow_append, bool allow_cds) {\n+  if (!allow_cds) {\n+    CDSConfig::set_module_patching_disables_cds();\n+    if (strcmp(module_name, JAVA_BASE_NAME) == 0) {\n+      CDSConfig::set_java_base_module_patching_disables_cds();\n@@ -2833,1 +2901,18 @@\n-  _patch_mod_prefix->push(new ModulePatchPath(module_name, path));\n+  \/\/ Scan patches for matching module\n+  int i = _patch_mod_prefix->find_if([&](ModulePatchPath* patch) {\n+    return (strcmp(module_name, patch->module_name()) == 0);\n+  });\n+  if (i == -1) {\n+    _patch_mod_prefix->push(new ModulePatchPath(module_name, path));\n+  } else {\n+    if (allow_append) {\n+      \/\/ append path to existing module entry\n+      _patch_mod_prefix->at(i)->append_path(path);\n+    } else {\n+      if (strcmp(module_name, JAVA_BASE_NAME) == 0) {\n+        vm_exit_during_initialization(\"Cannot specify \" JAVA_BASE_NAME \" more than once to --patch-module\");\n+      } else {\n+        vm_exit_during_initialization(\"Cannot specify a module more than once to --patch-module\", module_name);\n+      }\n+    }\n+  }\n@@ -2876,1 +2961,1 @@\n-jint Arguments::finalize_vm_init_args(bool patch_mod_javabase) {\n+jint Arguments::finalize_vm_init_args() {\n@@ -2950,1 +3035,6 @@\n-  if (!CDSConfig::check_vm_args_consistency(patch_mod_javabase, mode_flag_cmd_line)) {\n+  \/\/ finalize --module-patch and related --enable-preview\n+  if (finalize_patch_module() != JNI_OK) {\n+    return JNI_ERR;\n+  }\n+\n+  if (!CDSConfig::check_vm_args_consistency(mode_flag_cmd_line)) {\n@@ -3720,0 +3810,7 @@\n+  if (!EnableValhalla || (is_interpreter_only() && !CDSConfig::is_dumping_archive() && !UseSharedSpaces)) {\n+    \/\/ Disable calling convention optimizations if inline types are not supported.\n+    \/\/ Also these aren't useful in -Xint. However, don't disable them when dumping or using\n+    \/\/ the CDS archive, as the values must match between dumptime and runtime.\n+    InlineTypePassFieldsAsArgs = false;\n+    InlineTypeReturnedAsFields = false;\n+  }\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":125,"deletions":28,"binary":false,"changes":153,"status":"modified"},{"patch":"@@ -52,0 +52,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/flatArrayOop.hpp\"\n@@ -57,0 +59,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -345,2 +348,13 @@\n-  bool save_oop_result = chunk->at(0)->scope()->return_oop() && !thread->popframe_forcing_deopt_reexecution() && (exec_mode == Deoptimization::Unpack_deopt);\n-  Handle return_value;\n+  ScopeDesc* scope = chunk->at(0)->scope();\n+  bool save_oop_result = scope->return_oop() && !thread->popframe_forcing_deopt_reexecution() && (exec_mode == Deoptimization::Unpack_deopt);\n+  \/\/ In case of the return of multiple values, we must take care\n+  \/\/ of all oop return values.\n+  GrowableArray<Handle> return_oops;\n+  InlineKlass* vk = nullptr;\n+  if (save_oop_result && scope->return_scalarized()) {\n+    vk = InlineKlass::returned_inline_klass(map);\n+    if (vk != nullptr) {\n+      vk->save_oop_fields(map, return_oops);\n+      save_oop_result = false;\n+    }\n+  }\n@@ -352,1 +366,1 @@\n-    return_value = Handle(thread, result);\n+    return_oops.push(Handle(thread, result));\n@@ -359,1 +373,1 @@\n-  if (objects != nullptr) {\n+  if (objects != nullptr || vk != nullptr) {\n@@ -364,1 +378,8 @@\n-      realloc_failures = Deoptimization::realloc_objects(thread, &deoptee, &map, objects, CHECK_AND_CLEAR_(true));\n+      if (vk != nullptr) {\n+        realloc_failures = Deoptimization::realloc_inline_type_result(vk, map, return_oops, CHECK_AND_CLEAR_(true));\n+      }\n+      if (objects != nullptr) {\n+        realloc_failures = realloc_failures || Deoptimization::realloc_objects(thread, &deoptee, &map, objects, CHECK_AND_CLEAR_(true));\n+        bool skip_internal = (compiled_method != nullptr) && !compiled_method->is_compiled_by_jvmci();\n+        Deoptimization::reassign_fields(&deoptee, &map, objects, realloc_failures, skip_internal, CHECK_AND_CLEAR_(true));\n+      }\n@@ -369,1 +390,8 @@\n-      realloc_failures = Deoptimization::realloc_objects(thread, &deoptee, &map, objects, THREAD);\n+      if (vk != nullptr) {\n+        realloc_failures = Deoptimization::realloc_inline_type_result(vk, map, return_oops, THREAD);\n+      }\n+      if (objects != nullptr) {\n+        realloc_failures = realloc_failures || Deoptimization::realloc_objects(thread, &deoptee, &map, objects, THREAD);\n+        bool skip_internal = (compiled_method != nullptr) && !compiled_method->is_compiled_by_jvmci();\n+        Deoptimization::reassign_fields(&deoptee, &map, objects, realloc_failures, skip_internal, THREAD);\n+      }\n@@ -372,3 +400,1 @@\n-    bool skip_internal = (compiled_method != nullptr) && !compiled_method->is_compiled_by_jvmci();\n-    Deoptimization::reassign_fields(&deoptee, &map, objects, realloc_failures, skip_internal);\n-    if (TraceDeoptimization) {\n+    if (TraceDeoptimization && objects != nullptr) {\n@@ -378,1 +404,1 @@\n-  if (save_oop_result) {\n+  if (save_oop_result || vk != nullptr) {\n@@ -380,1 +406,2 @@\n-    deoptee.set_saved_oop_result(&map, return_value());\n+    assert(return_oops.length() == 1, \"no inline type\");\n+    deoptee.set_saved_oop_result(&map, return_oops.pop()());\n@@ -716,1 +743,1 @@\n-  \/\/ If the sender is deoptimized the we must retrieve the address of the handler\n+  \/\/ If the sender is deoptimized we must retrieve the address of the handler\n@@ -1216,2 +1243,11 @@\n-\n-    oop obj = nullptr;\n+    \/\/ Check if the object may be null and has an additional is_init input that needs\n+    \/\/ to be checked before using the field values. Skip re-allocation if it is null.\n+    if (sv->maybe_null()) {\n+      assert(k->is_inline_klass(), \"must be an inline klass\");\n+      jint is_init = StackValue::create_stack_value(fr, reg_map, sv->is_init())->get_jint();\n+      if (is_init == 0) {\n+        continue;\n+      }\n+    }\n+\n+    oop obj = nullptr;\n@@ -1250,0 +1286,4 @@\n+    } else if (k->is_flatArray_klass()) {\n+      FlatArrayKlass* ak = FlatArrayKlass::cast(k);\n+      \/\/ Inline type array must be zeroed because not all memory is reassigned\n+      obj = ak->allocate(sv->field_size(), THREAD);\n@@ -1279,0 +1319,15 @@\n+\/\/ We're deoptimizing at the return of a call, inline type fields are\n+\/\/ in registers. When we go back to the interpreter, it will expect a\n+\/\/ reference to an inline type instance. Allocate and initialize it from\n+\/\/ the register values here.\n+bool Deoptimization::realloc_inline_type_result(InlineKlass* vk, const RegisterMap& map, GrowableArray<Handle>& return_oops, TRAPS) {\n+  oop new_vt = vk->realloc_result(map, return_oops, THREAD);\n+  if (new_vt == nullptr) {\n+    CLEAR_PENDING_EXCEPTION;\n+    THROW_OOP_(Universe::out_of_memory_error_realloc_objects(), true);\n+  }\n+  return_oops.clear();\n+  return_oops.push(Handle(THREAD, new_vt));\n+  return false;\n+}\n+\n@@ -1444,0 +1499,2 @@\n+  InstanceKlass* _klass;\n+  bool _is_flat;\n@@ -1445,4 +1502,1 @@\n-  ReassignedField() {\n-    _offset = 0;\n-    _type = T_ILLEGAL;\n-  }\n+  ReassignedField() : _offset(0), _type(T_ILLEGAL), _klass(nullptr), _is_flat(false) { }\n@@ -1457,1 +1511,1 @@\n-static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal) {\n+static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal, int base_offset, TRAPS) {\n@@ -1466,0 +1520,9 @@\n+        if (fs.is_null_free_inline_type()) {\n+          if (fs.is_flat()) {\n+            field._is_flat = true;\n+            \/\/ Resolve klass of flat inline type field\n+            field._klass = InlineKlass::cast(klass->get_inline_type_field_klass(fs.index()));\n+          } else {\n+            field._type = T_OBJECT;  \/\/ Can be removed once Q-descriptors have been removed.\n+          }\n+        }\n@@ -1473,0 +1536,11 @@\n+    BasicType type = fields->at(i)._type;\n+    int offset = base_offset + fields->at(i)._offset;\n+    \/\/ Check for flat inline type field before accessing the ScopeValue because it might not have any fields\n+    if (fields->at(i)._is_flat) {\n+      \/\/ Recursively re-assign flat inline type fields\n+      InstanceKlass* vk = fields->at(i)._klass;\n+      assert(vk != nullptr, \"must be resolved\");\n+      offset -= InlineKlass::cast(vk)->first_field_offset(); \/\/ Adjust offset to omit oop header\n+      svIndex = reassign_fields_by_klass(vk, fr, reg_map, sv, svIndex, obj, skip_internal, offset, CHECK_0);\n+      continue; \/\/ Continue because we don't need to increment svIndex\n+    }\n@@ -1475,3 +1549,2 @@\n-    int offset = fields->at(i)._offset;\n-    BasicType type = fields->at(i)._type;\n-      case T_OBJECT: case T_ARRAY:\n+      case T_OBJECT:\n+      case T_ARRAY:\n@@ -1552,0 +1625,14 @@\n+\/\/ restore fields of an eliminated inline type array\n+void Deoptimization::reassign_flat_array_elements(frame* fr, RegisterMap* reg_map, ObjectValue* sv, flatArrayOop obj, FlatArrayKlass* vak, bool skip_internal, TRAPS) {\n+  InlineKlass* vk = vak->element_klass();\n+  assert(vk->flat_array(), \"should only be used for flat inline type arrays\");\n+  \/\/ Adjust offset to omit oop header\n+  int base_offset = arrayOopDesc::base_offset_in_bytes(T_PRIMITIVE_OBJECT) - InlineKlass::cast(vk)->first_field_offset();\n+  \/\/ Initialize all elements of the flat inline type array\n+  for (int i = 0; i < sv->field_size(); i++) {\n+    ScopeValue* val = sv->field_at(i);\n+    int offset = base_offset + (i << Klass::layout_helper_log2_element_size(vak->layout_helper()));\n+    reassign_fields_by_klass(vk, fr, reg_map, val->as_ObjectValue(), 0, (oop)obj, skip_internal, offset, CHECK);\n+  }\n+}\n+\n@@ -1553,1 +1640,1 @@\n-void Deoptimization::reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray<ScopeValue*>* objects, bool realloc_failures, bool skip_internal) {\n+void Deoptimization::reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray<ScopeValue*>* objects, bool realloc_failures, bool skip_internal, TRAPS) {\n@@ -1559,1 +1646,1 @@\n-    assert(obj.not_null() || realloc_failures, \"reallocation was missed\");\n+    assert(obj.not_null() || realloc_failures || sv->maybe_null(), \"reallocation was missed\");\n@@ -1599,1 +1686,4 @@\n-      reassign_fields_by_klass(ik, fr, reg_map, sv, 0, obj(), skip_internal);\n+      reassign_fields_by_klass(ik, fr, reg_map, sv, 0, obj(), skip_internal, 0, CHECK);\n+    } else if (k->is_flatArray_klass()) {\n+      FlatArrayKlass* vak = FlatArrayKlass::cast(k);\n+      reassign_flat_array_elements(fr, reg_map, sv, (flatArrayOop) obj(), vak, skip_internal, CHECK);\n@@ -1774,1 +1864,1 @@\n-  \/\/ Deoptimize only if the frame comes from compile code.\n+  \/\/ Deoptimize only if the frame comes from compiled code.\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":116,"deletions":26,"binary":false,"changes":142,"status":"modified"},{"patch":"@@ -806,1 +806,1 @@\n-  develop(bool, PrintFieldLayout, false,                                    \\\n+  product(bool, PrintFieldLayout, false, DIAGNOSTIC,                        \\\n@@ -809,0 +809,21 @@\n+  product(bool, PrintInlineLayout, false, DIAGNOSTIC,                       \\\n+          \"Print field layout for each inline type or class with inline fields\") \\\n+                                                                            \\\n+  product(bool, PrintFlatArrayLayout, false, DIAGNOSTIC,                    \\\n+          \"Print array layout for each inline type array\")                  \\\n+                                                                            \\\n+  product(intx, FlatArrayElementMaxSize, -1,                                \\\n+          \"Max size for flattening inline array elements, <0 no limit\")     \\\n+                                                                            \\\n+  product(intx, InlineFieldMaxFlatSize, 128,                                \\\n+          \"Max size for flattening inline type fields, <0 no limit\")        \\\n+                                                                            \\\n+  develop(bool, EnableNullableFieldFlattening, false,                       \\\n+          \"Allow the JVM to flatten some nullable fields\")                  \\\n+                                                                            \\\n+  product(intx, FlatArrayElementMaxOops, 4,                                 \\\n+          \"Max nof embedded object references in an inline type to flatten, <0 no limit\")  \\\n+                                                                            \\\n+  product(bool, InlineArrayAtomicAccess, false,                             \\\n+          \"Atomic inline array accesses by-default, for all inline arrays\") \\\n+                                                                            \\\n@@ -1951,0 +1972,17 @@\n+  product(bool, EnableValhalla, true,                                       \\\n+          \"Enable experimental Valhalla features\")                          \\\n+                                                                            \\\n+  product_pd(bool, InlineTypePassFieldsAsArgs,                              \\\n+          \"Pass each inline type field as an argument at calls\")            \\\n+                                                                            \\\n+  product_pd(bool, InlineTypeReturnedAsFields,                              \\\n+          \"Return fields instead of an inline type reference\")              \\\n+                                                                            \\\n+  develop(bool, StressCallingConvention, false,                             \\\n+          \"Stress the scalarized calling convention.\")                      \\\n+                                                                            \\\n+  product(ccstrlist, ForceNonTearable, \"\", DIAGNOSTIC,                      \\\n+          \"List of inline classes which are forced to be atomic \"           \\\n+          \"(whitespace and commas separate names, \"                         \\\n+          \"and leading and trailing stars '*' are wildcards)\")              \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":39,"deletions":1,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -51,0 +51,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -144,0 +144,1 @@\n+  oop           _return_buffered_value; \/\/ buffered value being returned\n@@ -718,0 +719,3 @@\n+  oop return_buffered_value() const              { return _return_buffered_value; }\n+  void set_return_buffered_value(oop val)        { _return_buffered_value = val; }\n+\n@@ -783,0 +787,1 @@\n+  static ByteSize return_buffered_value_offset() { return byte_offset_of(JavaThread, _return_buffered_value); }\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -46,0 +46,1 @@\n+#include \"memory\/oopFactory.hpp\"\n@@ -48,0 +49,2 @@\n+#include \"oops\/access.hpp\"\n+#include \"oops\/fieldStreams.inline.hpp\"\n@@ -52,0 +55,1 @@\n+#include \"oops\/objArrayOop.inline.hpp\"\n@@ -53,0 +57,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -93,1 +98,0 @@\n-address             SharedRuntime::_resolve_static_call_entry;\n@@ -114,1 +118,0 @@\n-  _resolve_static_call_entry           = _resolve_static_call_blob->entry_point();\n@@ -1139,0 +1142,15 @@\n+  \/\/ Substitutability test implementation piggy backs on static call resolution\n+  Bytecodes::Code code = caller->java_code_at(bci);\n+  if (code == Bytecodes::_if_acmpeq || code == Bytecodes::_if_acmpne) {\n+    bc = Bytecodes::_invokestatic;\n+    methodHandle attached_method(THREAD, extract_attached_method(vfst));\n+    assert(attached_method.not_null(), \"must have attached method\");\n+    vmClasses::ValueObjectMethods_klass()->initialize(CHECK_NH);\n+    LinkResolver::resolve_invoke(callinfo, receiver, attached_method, bc, false, CHECK_NH);\n+#ifdef ASSERT\n+    Method* is_subst = vmClasses::ValueObjectMethods_klass()->find_method(vmSymbols::isSubstitutable_name(), vmSymbols::object_object_boolean_signature());\n+    assert(callinfo.selected_method() == is_subst, \"must be isSubstitutable method\");\n+#endif\n+    return receiver;\n+  }\n+\n@@ -1174,0 +1192,6 @@\n+    } else {\n+      assert(attached_method->has_scalarized_args(), \"invalid use of attached method\");\n+      if (!attached_method->method_holder()->is_inline_klass()) {\n+        \/\/ Ignore the attached method in this case to not confuse below code\n+        attached_method = methodHandle(current, nullptr);\n+      }\n@@ -1182,0 +1206,1 @@\n+  bool check_null_and_abstract = true;\n@@ -1195,2 +1220,3 @@\n-    if (attached_method.is_null()) {\n-      Method* callee = bytecode.static_target(CHECK_NH);\n+    Method* callee = attached_method();\n+    if (callee == nullptr) {\n+      callee = bytecode.static_target(CHECK_NH);\n@@ -1201,7 +1227,17 @@\n-\n-    \/\/ Retrieve from a compiled argument list\n-    receiver = Handle(current, callerFrame.retrieve_receiver(&reg_map2));\n-    assert(oopDesc::is_oop_or_null(receiver()), \"\");\n-\n-    if (receiver.is_null()) {\n-      THROW_(vmSymbols::java_lang_NullPointerException(), nullHandle);\n+    bool caller_is_c1 = callerFrame.is_compiled_frame() && callerFrame.cb()->as_nmethod()->is_compiled_by_c1();\n+    if (!caller_is_c1 && callee->is_scalarized_arg(0)) {\n+      \/\/ If the receiver is an inline type that is passed as fields, no oop is available\n+      \/\/ Resolve the call without receiver null checking.\n+      assert(!callee->mismatch(), \"calls with inline type receivers should never mismatch\");\n+      assert(attached_method.not_null() && !attached_method->is_abstract(), \"must have non-abstract attached method\");\n+      if (bc == Bytecodes::_invokeinterface) {\n+        bc = Bytecodes::_invokevirtual; \/\/ C2 optimistically replaces interface calls by virtual calls\n+      }\n+      check_null_and_abstract = false;\n+    } else {\n+      \/\/ Retrieve from a compiled argument list\n+      receiver = Handle(current, callerFrame.retrieve_receiver(&reg_map2));\n+      assert(oopDesc::is_oop_or_null(receiver()), \"\");\n+      if (receiver.is_null()) {\n+        THROW_(vmSymbols::java_lang_NullPointerException(), nullHandle);\n+      }\n@@ -1214,1 +1250,1 @@\n-    LinkResolver::resolve_invoke(callinfo, receiver, attached_method, bc, CHECK_NH);\n+    LinkResolver::resolve_invoke(callinfo, receiver, attached_method, bc, check_null_and_abstract, CHECK_NH);\n@@ -1223,1 +1259,1 @@\n-  if (has_receiver) {\n+  if (has_receiver && check_null_and_abstract) {\n@@ -1251,1 +1287,1 @@\n-methodHandle SharedRuntime::find_callee_method(TRAPS) {\n+methodHandle SharedRuntime::find_callee_method(bool is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1277,0 +1313,4 @@\n+    \/\/ Calls via mismatching methods are always non-scalarized\n+    if (callinfo.resolved_method()->mismatch() && !is_optimized) {\n+      caller_is_c1 = true;\n+    }\n@@ -1284,1 +1324,1 @@\n-methodHandle SharedRuntime::resolve_helper(bool is_virtual, bool is_optimized, TRAPS) {\n+methodHandle SharedRuntime::resolve_helper(bool is_virtual, bool is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1307,0 +1347,4 @@\n+  \/\/ Calls via mismatching methods are always non-scalarized\n+  if (caller_nm->is_compiled_by_c1() || (call_info.resolved_method()->mismatch() && !is_optimized)) {\n+    caller_is_c1 = true;\n+  }\n@@ -1325,1 +1369,1 @@\n-    tty->print(\"resolving %s%s (%s) call to\",\n+    tty->print(\"resolving %s%s (%s) call%s to\",\n@@ -1327,1 +1371,1 @@\n-               Bytecodes::name(invoke_code));\n+               Bytecodes::name(invoke_code), (caller_is_c1) ? \" from C1\" : \"\");\n@@ -1366,1 +1410,1 @@\n-    inline_cache->update(&call_info, receiver->klass());\n+    inline_cache->update(&call_info, receiver->klass(), caller_is_c1);\n@@ -1370,1 +1414,1 @@\n-    callsite->set(callee_method);\n+    callsite->set(callee_method, caller_is_c1);\n@@ -1390,0 +1434,2 @@\n+  bool is_optimized = false;\n+  bool caller_is_c1 = false;\n@@ -1391,1 +1437,1 @@\n-    callee_method = SharedRuntime::handle_ic_miss_helper(CHECK_NULL);\n+    callee_method = SharedRuntime::handle_ic_miss_helper(is_optimized, caller_is_c1, CHECK_NULL);\n@@ -1396,1 +1442,1 @@\n-  return get_resolved_entry(current, callee_method);\n+  return get_resolved_entry(current, callee_method, false, is_optimized, caller_is_c1);\n@@ -1437,1 +1483,5 @@\n-      return callee->get_c2i_entry();\n+      if (caller_frame.is_interpreted_frame()) {\n+        return callee->get_c2i_inline_entry();\n+      } else {\n+        return callee->get_c2i_entry();\n+      }\n@@ -1443,0 +1493,3 @@\n+  bool is_static_call = false;\n+  bool is_optimized = false;\n+  bool caller_is_c1 = false;\n@@ -1445,1 +1498,1 @@\n-    callee_method = SharedRuntime::reresolve_call_site(CHECK_NULL);\n+    callee_method = SharedRuntime::reresolve_call_site(is_static_call, is_optimized, caller_is_c1, CHECK_NULL);\n@@ -1449,1 +1502,1 @@\n-  return get_resolved_entry(current, callee_method);\n+  return get_resolved_entry(current, callee_method, is_static_call, is_optimized, caller_is_c1);\n@@ -1488,1 +1541,2 @@\n-address SharedRuntime::get_resolved_entry(JavaThread* current, methodHandle callee_method) {\n+address SharedRuntime::get_resolved_entry(JavaThread* current, methodHandle callee_method,\n+                                          bool is_static_call, bool is_optimized, bool caller_is_c1) {\n@@ -1494,2 +1548,11 @@\n-  assert(callee_method->verified_code_entry() != nullptr, \" Jump to zero!\");\n-  return callee_method->verified_code_entry();\n+\n+  if (caller_is_c1) {\n+    assert(callee_method->verified_inline_code_entry() != nullptr, \"Jump to zero!\");\n+    return callee_method->verified_inline_code_entry();\n+  } else if (is_static_call || is_optimized) {\n+    assert(callee_method->verified_code_entry() != nullptr, \"Jump to zero!\");\n+    return callee_method->verified_code_entry();\n+  } else {\n+    assert(callee_method->verified_inline_ro_code_entry() != nullptr, \"Jump to zero!\");\n+    return callee_method->verified_inline_ro_code_entry();\n+  }\n@@ -1501,0 +1564,1 @@\n+  bool caller_is_c1 = false;\n@@ -1503,1 +1567,1 @@\n-    callee_method = SharedRuntime::resolve_helper(false, false, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(false, false, caller_is_c1, CHECK_NULL);\n@@ -1507,1 +1571,1 @@\n-  return get_resolved_entry(current, callee_method);\n+  return get_resolved_entry(current, callee_method, true, false, caller_is_c1);\n@@ -1513,0 +1577,1 @@\n+  bool caller_is_c1 = false;\n@@ -1514,1 +1579,1 @@\n-    callee_method = SharedRuntime::resolve_helper(true, false, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(true, false, caller_is_c1, CHECK_NULL);\n@@ -1518,1 +1583,1 @@\n-  return get_resolved_entry(current, callee_method);\n+  return get_resolved_entry(current, callee_method, false, false, caller_is_c1);\n@@ -1526,0 +1591,1 @@\n+  bool caller_is_c1 = false;\n@@ -1527,1 +1593,1 @@\n-    callee_method = SharedRuntime::resolve_helper(true, true, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(true, true, caller_is_c1, CHECK_NULL);\n@@ -1531,1 +1597,1 @@\n-  return get_resolved_entry(current, callee_method);\n+  return get_resolved_entry(current, callee_method, false, true, caller_is_c1);\n@@ -1534,1 +1600,3 @@\n-methodHandle SharedRuntime::handle_ic_miss_helper(TRAPS) {\n+\n+\n+methodHandle SharedRuntime::handle_ic_miss_helper(bool& is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1552,1 +1620,1 @@\n-    tty->print(\"IC miss (%s) call to\", Bytecodes::name(bc));\n+    tty->print(\"IC miss (%s) call%s to\", Bytecodes::name(bc), (caller_is_c1) ? \" from C1\" : \"\");\n@@ -1584,0 +1652,4 @@\n+  \/\/ Calls via mismatching methods are always non-scalarized\n+  if (caller_nm->is_compiled_by_c1() || call_info.resolved_method()->mismatch()) {\n+    caller_is_c1 = true;\n+  }\n@@ -1587,1 +1659,1 @@\n-  inline_cache->update(&call_info, receiver()->klass());\n+  inline_cache->update(&call_info, receiver()->klass(), caller_is_c1);\n@@ -1598,1 +1670,1 @@\n-methodHandle SharedRuntime::reresolve_call_site(TRAPS) {\n+methodHandle SharedRuntime::reresolve_call_site(bool& is_static_call, bool& is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1608,0 +1680,3 @@\n+  if (caller.is_compiled_frame()) {\n+    caller_is_c1 = caller.cb()->as_nmethod()->is_compiled_by_c1();\n+  }\n@@ -1648,0 +1723,2 @@\n+        is_static_call = false;\n+        is_optimized = false;\n@@ -1650,0 +1727,1 @@\n+            is_static_call = true;\n@@ -1651,0 +1729,1 @@\n+            is_optimized = (iter.type() == relocInfo::opt_virtual_call_type);\n@@ -1655,1 +1734,0 @@\n-\n@@ -1669,2 +1747,1 @@\n-  methodHandle callee_method = find_callee_method(CHECK_(methodHandle()));\n-\n+  methodHandle callee_method = find_callee_method(is_optimized, caller_is_c1, CHECK_(methodHandle()));\n@@ -1677,1 +1754,1 @@\n-    tty->print(\"handle_wrong_method reresolving call to\");\n+    tty->print(\"handle_wrong_method reresolving call%s to\", (caller_is_c1) ? \" from C1\" : \"\");\n@@ -1883,0 +1960,15 @@\n+char* SharedRuntime::generate_identity_exception_message(JavaThread* current, Klass* klass) {\n+  assert(klass->is_inline_klass(), \"Must be a concrete value class\");\n+  const char* desc = \"Cannot synchronize on an instance of value class \";\n+  const char* className = klass->external_name();\n+  size_t msglen = strlen(desc) + strlen(className) + 1;\n+  char* message = NEW_RESOURCE_ARRAY(char, msglen);\n+  if (nullptr == message) {\n+    \/\/ Out of memory: can't create detailed error message\n+    message = const_cast<char*>(klass->external_name());\n+  } else {\n+    jio_snprintf(message, msglen, \"%s%s\", desc, className);\n+  }\n+  return message;\n+}\n+\n@@ -2113,1 +2205,1 @@\n-    _basic_type_bits = 4,\n+    _basic_type_bits = 5,\n@@ -2131,1 +2223,1 @@\n-  static int adapter_encoding(BasicType in) {\n+  static BasicType adapter_encoding(BasicType in) {\n@@ -2137,1 +2229,1 @@\n-        \/\/ There are all promoted to T_INT in the calling convention\n+        \/\/ They are all promoted to T_INT in the calling convention\n@@ -2164,1 +2256,1 @@\n-  AdapterFingerPrint(int total_args_passed, BasicType* sig_bt) {\n+  AdapterFingerPrint(const GrowableArray<SigEntry>* sig, bool has_ro_adapter = false) {\n@@ -2167,0 +2259,1 @@\n+    int total_args_passed = (sig != nullptr) ? sig->length() : 0;\n@@ -2184,0 +2277,2 @@\n+    BasicType prev_bt = T_ILLEGAL;\n+    int vt_count = 0;\n@@ -2186,4 +2281,27 @@\n-      for (int byte = 0; sig_index < total_args_passed && byte < _basic_types_per_int; byte++) {\n-        int bt = adapter_encoding(sig_bt[sig_index++]);\n-        assert((bt & _basic_type_mask) == bt, \"must fit in 4 bits\");\n-        value = (value << _basic_type_bits) | bt;\n+      for (int byte = 0; byte < _basic_types_per_int; byte++) {\n+        BasicType bt = T_ILLEGAL;\n+        if (sig_index < total_args_passed) {\n+          bt = sig->at(sig_index++)._bt;\n+          if (bt == T_METADATA) {\n+            \/\/ Found start of inline type in signature\n+            assert(InlineTypePassFieldsAsArgs, \"unexpected start of inline type\");\n+            if (sig_index == 1 && has_ro_adapter) {\n+              \/\/ With a ro_adapter, replace receiver inline type delimiter by T_VOID to prevent matching\n+              \/\/ with other adapters that have the same inline type as first argument and no receiver.\n+              bt = T_VOID;\n+            }\n+            vt_count++;\n+          } else if (bt == T_VOID && prev_bt != T_LONG && prev_bt != T_DOUBLE) {\n+            \/\/ Found end of inline type in signature\n+            assert(InlineTypePassFieldsAsArgs, \"unexpected end of inline type\");\n+            vt_count--;\n+            assert(vt_count >= 0, \"invalid vt_count\");\n+          } else if (vt_count == 0) {\n+            \/\/ Widen fields that are not part of a scalarized inline type argument\n+            bt = adapter_encoding(bt);\n+          }\n+          prev_bt = bt;\n+        }\n+        int bt_val = (bt == T_ILLEGAL) ? 0 : bt;\n+        assert((bt_val & _basic_type_mask) == bt_val, \"must fit in 4 bits\");\n+        value = (value << _basic_type_bits) | bt_val;\n@@ -2193,0 +2311,1 @@\n+    assert(vt_count == 0, \"invalid vt_count\");\n@@ -2257,8 +2376,4 @@\n-        }\n-        switch (v) {\n-          case T_INT:    st.print(\"I\");    break;\n-          case T_LONG:   long_prev = true; break;\n-          case T_FLOAT:  st.print(\"F\");    break;\n-          case T_DOUBLE: st.print(\"D\");    break;\n-          case T_VOID:   break;\n-          default: ShouldNotReachHere();\n+        } else if (v == T_LONG) {\n+          long_prev = true;\n+        } else if (v != T_VOID){\n+          st.print(\"%c\", type2char((BasicType)v));\n@@ -2312,1 +2427,1 @@\n-static AdapterHandlerEntry* lookup(int total_args_passed, BasicType* sig_bt) {\n+static AdapterHandlerEntry* lookup(const GrowableArray<SigEntry>* sig, bool has_ro_adapter = false) {\n@@ -2315,1 +2430,1 @@\n-  AdapterFingerPrint fp(total_args_passed, sig_bt);\n+  AdapterFingerPrint fp(sig, has_ro_adapter);\n@@ -2349,1 +2464,1 @@\n-const int AdapterHandlerLibrary_size = 16*K;\n+const int AdapterHandlerLibrary_size = 48*K;\n@@ -2392,1 +2507,1 @@\n-    _abstract_method_handler = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(0, nullptr),\n+    _abstract_method_handler = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(nullptr),\n@@ -2394,0 +2509,1 @@\n+                                                                wrong_method_abstract, wrong_method_abstract, wrong_method_abstract,\n@@ -2395,4 +2511,8 @@\n-\n-    _no_arg_handler = create_adapter(no_arg_blob, 0, nullptr, true);\n-    BasicType obj_args[] = { T_OBJECT };\n-    _obj_arg_handler = create_adapter(obj_arg_blob, 1, obj_args, true);\n+    CompiledEntrySignature no_args;\n+    no_args.compute_calling_conventions();\n+    _no_arg_handler = create_adapter(no_arg_blob, no_args, true);\n+\n+    CompiledEntrySignature obj_args;\n+    SigEntry::add_entry(obj_args.sig(), T_OBJECT, nullptr);\n+    obj_args.compute_calling_conventions();\n+    _obj_arg_handler = create_adapter(obj_arg_blob, obj_args, true);\n@@ -2402,2 +2522,4 @@\n-    BasicType int_args[] = { T_INT };\n-    _int_arg_handler = create_adapter(int_arg_blob, 1, int_args, true);\n+    CompiledEntrySignature int_args;\n+    SigEntry::add_entry(int_args.sig(), T_INT, nullptr);\n+    int_args.compute_calling_conventions();\n+    _int_arg_handler = create_adapter(int_arg_blob, int_args, true);\n@@ -2405,2 +2527,5 @@\n-    BasicType obj_int_args[] = { T_OBJECT, T_INT };\n-    _obj_int_arg_handler = create_adapter(obj_int_arg_blob, 2, obj_int_args, true);\n+    CompiledEntrySignature obj_int_args;\n+    SigEntry::add_entry(obj_int_args.sig(), T_OBJECT, nullptr);\n+    SigEntry::add_entry(obj_int_args.sig(), T_INT, nullptr);\n+    obj_int_args.compute_calling_conventions();\n+    _obj_int_arg_handler = create_adapter(obj_int_arg_blob, obj_int_args, true);\n@@ -2408,2 +2533,5 @@\n-    BasicType obj_obj_args[] = { T_OBJECT, T_OBJECT };\n-    _obj_obj_arg_handler = create_adapter(obj_obj_arg_blob, 2, obj_obj_args, true);\n+    CompiledEntrySignature obj_obj_args;\n+    SigEntry::add_entry(obj_obj_args.sig(), T_OBJECT, nullptr);\n+    SigEntry::add_entry(obj_obj_args.sig(), T_OBJECT, nullptr);\n+    obj_obj_args.compute_calling_conventions();\n+    _obj_obj_arg_handler = create_adapter(obj_obj_arg_blob, obj_obj_args, true);\n@@ -2417,0 +2545,1 @@\n+  return;\n@@ -2429,0 +2558,2 @@\n+                                                      address c2i_inline_entry,\n+                                                      address c2i_inline_ro_entry,\n@@ -2430,0 +2561,1 @@\n+                                                      address c2i_unverified_inline_entry,\n@@ -2431,3 +2563,2 @@\n-  \/\/ Insert an entry into the table\n-  return new AdapterHandlerEntry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry,\n-                                 c2i_no_clinit_check_entry);\n+  return new AdapterHandlerEntry(fingerprint, i2c_entry, c2i_entry, c2i_inline_entry, c2i_inline_ro_entry, c2i_unverified_entry,\n+                              c2i_unverified_inline_entry, c2i_no_clinit_check_entry);\n@@ -2438,1 +2569,1 @@\n-    return _abstract_method_handler;\n+    return nullptr;\n@@ -2445,0 +2576,3 @@\n+      if (InlineTypePassFieldsAsArgs && method->method_holder()->is_inline_klass()) {\n+        return nullptr;\n+      }\n@@ -2448,1 +2582,10 @@\n-      case JVM_SIGNATURE_CLASS:\n+      case JVM_SIGNATURE_CLASS: {\n+        if (InlineTypePassFieldsAsArgs) {\n+          SignatureStream ss(method->signature());\n+          InlineKlass* vk = ss.as_inline_klass(method->method_holder());\n+          if (vk != nullptr) {\n+            return nullptr;\n+          }\n+        }\n+        return _obj_arg_handler;\n+      }\n@@ -2459,1 +2602,1 @@\n-             !method->is_static()) {\n+             !method->is_static() && (!InlineTypePassFieldsAsArgs || !method->method_holder()->is_inline_klass())) {\n@@ -2461,1 +2604,10 @@\n-      case JVM_SIGNATURE_CLASS:\n+      case JVM_SIGNATURE_CLASS: {\n+        if (InlineTypePassFieldsAsArgs) {\n+          SignatureStream ss(method->signature());\n+          InlineKlass* vk = ss.as_inline_klass(method->method_holder());\n+          if (vk != nullptr) {\n+            return nullptr;\n+          }\n+        }\n+        return _obj_obj_arg_handler;\n+      }\n@@ -2475,5 +2627,9 @@\n-class AdapterSignatureIterator : public SignatureIterator {\n- private:\n-  BasicType stack_sig_bt[16];\n-  BasicType* sig_bt;\n-  int index;\n+CompiledEntrySignature::CompiledEntrySignature(Method* method) :\n+  _method(method), _num_inline_args(0), _has_inline_recv(false),\n+  _regs(nullptr), _regs_cc(nullptr), _regs_cc_ro(nullptr),\n+  _args_on_stack(0), _args_on_stack_cc(0), _args_on_stack_cc_ro(0),\n+  _c1_needs_stack_repair(false), _c2_needs_stack_repair(false), _supers(nullptr) {\n+  _sig = new GrowableArray<SigEntry>((method != nullptr) ? method->size_of_parameters() : 1);\n+  _sig_cc = new GrowableArray<SigEntry>((method != nullptr) ? method->size_of_parameters() : 1);\n+  _sig_cc_ro = new GrowableArray<SigEntry>((method != nullptr) ? method->size_of_parameters() : 1);\n+}\n@@ -2481,11 +2637,24 @@\n- public:\n-  AdapterSignatureIterator(Symbol* signature,\n-                           fingerprint_t fingerprint,\n-                           bool is_static,\n-                           int total_args_passed) :\n-    SignatureIterator(signature, fingerprint),\n-    index(0)\n-  {\n-    sig_bt = (total_args_passed <= 16) ? stack_sig_bt : NEW_RESOURCE_ARRAY(BasicType, total_args_passed);\n-    if (!is_static) { \/\/ Pass in receiver first\n-      sig_bt[index++] = T_OBJECT;\n+\/\/ See if we can save space by sharing the same entry for VIEP and VIEP(RO),\n+\/\/ or the same entry for VEP and VIEP(RO).\n+CodeOffsets::Entries CompiledEntrySignature::c1_inline_ro_entry_type() const {\n+  if (!has_scalarized_args()) {\n+    \/\/ VEP\/VIEP\/VIEP(RO) all share the same entry. There's no packing.\n+    return CodeOffsets::Verified_Entry;\n+  }\n+  if (_method->is_static()) {\n+    \/\/ Static methods don't need VIEP(RO)\n+    return CodeOffsets::Verified_Entry;\n+  }\n+\n+  if (has_inline_recv()) {\n+    if (num_inline_args() == 1) {\n+      \/\/ Share same entry for VIEP and VIEP(RO).\n+      \/\/ This is quite common: we have an instance method in an InlineKlass that has\n+      \/\/ no inline type args other than <this>.\n+      return CodeOffsets::Verified_Inline_Entry;\n+    } else {\n+      assert(num_inline_args() > 1, \"must be\");\n+      \/\/ No sharing:\n+      \/\/   VIEP(RO) -- <this> is passed as object\n+      \/\/   VEP      -- <this> is passed as fields\n+      return CodeOffsets::Verified_Inline_Entry_RO;\n@@ -2493,1 +2662,0 @@\n-    do_parameters_on(this);\n@@ -2496,2 +2664,9 @@\n-  BasicType* basic_types() {\n-    return sig_bt;\n+  \/\/ Either a static method, or <this> is not an inline type\n+  if (args_on_stack_cc() != args_on_stack_cc_ro()) {\n+    \/\/ No sharing:\n+    \/\/ Some arguments are passed on the stack, and we have inserted reserved entries\n+    \/\/ into the VEP, but we never insert reserved entries into the VIEP(RO).\n+    return CodeOffsets::Verified_Inline_Entry_RO;\n+  } else {\n+    \/\/ Share same entry for VEP and VIEP(RO).\n+    return CodeOffsets::Verified_Entry;\n@@ -2499,0 +2674,1 @@\n+}\n@@ -2500,3 +2676,39 @@\n-#ifdef ASSERT\n-  int slots() {\n-    return index;\n+\/\/ Returns all super methods (transitive) in classes and interfaces that are overridden by the current method.\n+GrowableArray<Method*>* CompiledEntrySignature::get_supers() {\n+  if (_supers != nullptr) {\n+    return _supers;\n+  }\n+  _supers = new GrowableArray<Method*>();\n+  \/\/ Skip private, static, and <init> methods\n+  if (_method->is_private() || _method->is_static() || _method->is_object_constructor()) {\n+    return _supers;\n+  }\n+  Symbol* name = _method->name();\n+  Symbol* signature = _method->signature();\n+  const Klass* holder = _method->method_holder()->super();\n+  Symbol* holder_name = holder->name();\n+  ThreadInVMfromUnknown tiv;\n+  JavaThread* current = JavaThread::current();\n+  HandleMark hm(current);\n+  Handle loader(current, _method->method_holder()->class_loader());\n+\n+  \/\/ Walk up the class hierarchy and search for super methods\n+  while (holder != nullptr) {\n+    Method* super_method = holder->lookup_method(name, signature);\n+    if (super_method == nullptr) {\n+      break;\n+    }\n+    if (!super_method->is_static() && !super_method->is_private() &&\n+        (!super_method->is_package_private() ||\n+         super_method->method_holder()->is_same_class_package(loader(), holder_name))) {\n+      _supers->push(super_method);\n+    }\n+    holder = super_method->method_holder()->super();\n+  }\n+  \/\/ Search interfaces for super methods\n+  Array<InstanceKlass*>* interfaces = _method->method_holder()->transitive_interfaces();\n+  for (int i = 0; i < interfaces->length(); ++i) {\n+    Method* m = interfaces->at(i)->lookup_method(name, signature);\n+    if (m != nullptr && !m->is_static() && m->is_public()) {\n+      _supers->push(m);\n+    }\n@@ -2504,0 +2716,50 @@\n+  return _supers;\n+}\n+\n+\/\/ Iterate over arguments and compute scalarized and non-scalarized signatures\n+void CompiledEntrySignature::compute_calling_conventions(bool init) {\n+  bool has_scalarized = false;\n+  if (_method != nullptr) {\n+    InstanceKlass* holder = _method->method_holder();\n+    int arg_num = 0;\n+    if (!_method->is_static()) {\n+      \/\/ We shouldn't scalarize 'this' in a value class constructor\n+      if (holder->is_inline_klass() && InlineKlass::cast(holder)->can_be_passed_as_fields() && !_method->is_object_constructor() &&\n+          (init || _method->is_scalarized_arg(arg_num))) {\n+        _sig_cc->appendAll(InlineKlass::cast(holder)->extended_sig());\n+        has_scalarized = true;\n+        _has_inline_recv = true;\n+        _num_inline_args++;\n+      } else {\n+        SigEntry::add_entry(_sig_cc, T_OBJECT, holder->name());\n+      }\n+      SigEntry::add_entry(_sig, T_OBJECT, holder->name());\n+      SigEntry::add_entry(_sig_cc_ro, T_OBJECT, holder->name());\n+      arg_num++;\n+    }\n+    for (SignatureStream ss(_method->signature()); !ss.at_return_type(); ss.next()) {\n+      BasicType bt = ss.type();\n+      if (bt == T_OBJECT) {\n+        InlineKlass* vk = ss.as_inline_klass(holder);\n+        if (vk != nullptr && vk->can_be_passed_as_fields() && (init || _method->is_scalarized_arg(arg_num))) {\n+          \/\/ Check for a calling convention mismatch with super method(s)\n+          bool scalar_super = false;\n+          bool non_scalar_super = false;\n+          GrowableArray<Method*>* supers = get_supers();\n+          for (int i = 0; i < supers->length(); ++i) {\n+            Method* super_method = supers->at(i);\n+            if (super_method->is_scalarized_arg(arg_num)) {\n+              scalar_super = true;\n+            } else {\n+              non_scalar_super = true;\n+            }\n+          }\n+#ifdef ASSERT\n+          \/\/ Randomly enable below code paths for stress testing\n+          bool stress = init && StressCallingConvention;\n+          if (stress && (os::random() & 1) == 1) {\n+            non_scalar_super = true;\n+            if ((os::random() & 1) == 1) {\n+              scalar_super = true;\n+            }\n+          }\n@@ -2505,0 +2767,50 @@\n+          if (non_scalar_super) {\n+            \/\/ Found a super method with a non-scalarized argument. Fall back to the non-scalarized calling convention.\n+            if (scalar_super) {\n+              \/\/ Found non-scalar *and* scalar super methods. We can't handle both.\n+              \/\/ Mark the scalar method as mismatch and re-compile call sites to use non-scalarized calling convention.\n+              for (int i = 0; i < supers->length(); ++i) {\n+                Method* super_method = supers->at(i);\n+                if (super_method->is_scalarized_arg(arg_num) debug_only(|| (stress && (os::random() & 1) == 1))) {\n+                  super_method->set_mismatch();\n+                  MutexLocker ml(Compile_lock, Mutex::_safepoint_check_flag);\n+                  JavaThread* thread = JavaThread::current();\n+                  HandleMark hm(thread);\n+                  methodHandle mh(thread, super_method);\n+                  DeoptimizationScope deopt_scope;\n+                  CodeCache::mark_for_deoptimization(&deopt_scope, mh());\n+                  deopt_scope.deoptimize_marked();\n+                }\n+              }\n+            }\n+            \/\/ Fall back to non-scalarized calling convention\n+            SigEntry::add_entry(_sig_cc, T_OBJECT, ss.as_symbol());\n+            SigEntry::add_entry(_sig_cc_ro, T_OBJECT, ss.as_symbol());\n+          } else {\n+            _num_inline_args++;\n+            has_scalarized = true;\n+            int last = _sig_cc->length();\n+            int last_ro = _sig_cc_ro->length();\n+            _sig_cc->appendAll(vk->extended_sig());\n+            _sig_cc_ro->appendAll(vk->extended_sig());\n+            if (bt == T_OBJECT) {\n+              \/\/ Nullable inline type argument, insert InlineTypeNode::IsInit field right after T_METADATA delimiter\n+              _sig_cc->insert_before(last+1, SigEntry(T_BOOLEAN, -1, nullptr));\n+              _sig_cc_ro->insert_before(last_ro+1, SigEntry(T_BOOLEAN, -1, nullptr));\n+            }\n+          }\n+        } else {\n+          SigEntry::add_entry(_sig_cc, T_OBJECT, ss.as_symbol());\n+          SigEntry::add_entry(_sig_cc_ro, T_OBJECT, ss.as_symbol());\n+        }\n+        bt = T_OBJECT;\n+      } else {\n+        SigEntry::add_entry(_sig_cc, ss.type(), ss.as_symbol());\n+        SigEntry::add_entry(_sig_cc_ro, ss.type(), ss.as_symbol());\n+      }\n+      SigEntry::add_entry(_sig, bt, ss.as_symbol());\n+      if (bt != T_VOID) {\n+        arg_num++;\n+      }\n+    }\n+  }\n@@ -2506,1 +2818,11 @@\n- private:\n+  \/\/ Compute the non-scalarized calling convention\n+  _regs = NEW_RESOURCE_ARRAY(VMRegPair, _sig->length());\n+  _args_on_stack = SharedRuntime::java_calling_convention(_sig, _regs);\n+\n+  \/\/ Compute the scalarized calling conventions if there are scalarized inline types in the signature\n+  if (has_scalarized && !_method->is_native()) {\n+    _regs_cc = NEW_RESOURCE_ARRAY(VMRegPair, _sig_cc->length());\n+    _args_on_stack_cc = SharedRuntime::java_calling_convention(_sig_cc, _regs_cc);\n+\n+    _regs_cc_ro = NEW_RESOURCE_ARRAY(VMRegPair, _sig_cc_ro->length());\n+    _args_on_stack_cc_ro = SharedRuntime::java_calling_convention(_sig_cc_ro, _regs_cc_ro);\n@@ -2508,5 +2830,8 @@\n-  friend class SignatureIterator;  \/\/ so do_parameters_on can call do_type\n-  void do_type(BasicType type) {\n-    sig_bt[index++] = type;\n-    if (type == T_LONG || type == T_DOUBLE) {\n-      sig_bt[index++] = T_VOID; \/\/ Longs & doubles take 2 Java slots\n+    _c1_needs_stack_repair = (_args_on_stack_cc < _args_on_stack) || (_args_on_stack_cc_ro < _args_on_stack);\n+    _c2_needs_stack_repair = (_args_on_stack_cc > _args_on_stack) || (_args_on_stack_cc > _args_on_stack_cc_ro);\n+\n+    \/\/ Upper bound on stack arguments to avoid hitting the argument limit and\n+    \/\/ bailing out of compilation (\"unsupported incoming calling sequence\").\n+    \/\/ TODO we need a reasonable limit (flag?) here\n+    if (MAX2(_args_on_stack_cc, _args_on_stack_cc_ro) <= 60) {\n+      return; \/\/ Success\n@@ -2515,1 +2840,10 @@\n-};\n+\n+  \/\/ No scalarized args\n+  _sig_cc = _sig;\n+  _regs_cc = _regs;\n+  _args_on_stack_cc = _args_on_stack;\n+\n+  _sig_cc_ro = _sig;\n+  _regs_cc_ro = _regs;\n+  _args_on_stack_cc_ro = _args_on_stack;\n+}\n@@ -2532,2 +2866,15 @@\n-  \/\/ Fill in the signature array, for the calling-convention call.\n-  int total_args_passed = method->size_of_parameters(); \/\/ All args on stack\n+  CompiledEntrySignature ces(method());\n+  ces.compute_calling_conventions();\n+  if (ces.has_scalarized_args()) {\n+    if (!method->has_scalarized_args()) {\n+      method->set_has_scalarized_args();\n+    }\n+    if (ces.c1_needs_stack_repair()) {\n+      method->set_c1_needs_stack_repair();\n+    }\n+    if (ces.c2_needs_stack_repair() && !method->c2_needs_stack_repair()) {\n+      method->set_c2_needs_stack_repair();\n+    }\n+  } else if (method->is_abstract()) {\n+    return _abstract_method_handler;\n+  }\n@@ -2535,4 +2882,0 @@\n-  AdapterSignatureIterator si(method->signature(), method->constMethod()->fingerprint(),\n-                              method->is_static(), total_args_passed);\n-  assert(si.slots() == total_args_passed, \"\");\n-  BasicType* sig_bt = si.basic_types();\n@@ -2542,0 +2885,13 @@\n+    if (ces.has_scalarized_args() && method->is_abstract()) {\n+      \/\/ Save a C heap allocated version of the signature for abstract methods with scalarized inline type arguments\n+      address wrong_method_abstract = SharedRuntime::get_handle_wrong_method_abstract_stub();\n+      entry = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(nullptr),\n+                                               StubRoutines::throw_AbstractMethodError_entry(),\n+                                               wrong_method_abstract, wrong_method_abstract, wrong_method_abstract,\n+                                               wrong_method_abstract, wrong_method_abstract);\n+      GrowableArray<SigEntry>* heap_sig = new (mtInternal) GrowableArray<SigEntry>(ces.sig_cc_ro()->length(), mtInternal);\n+      heap_sig->appendAll(ces.sig_cc_ro());\n+      entry->set_sig_cc(heap_sig);\n+      return entry;\n+    }\n+\n@@ -2543,1 +2899,1 @@\n-    entry = lookup(total_args_passed, sig_bt);\n+    entry = lookup(ces.sig_cc(), ces.has_inline_recv());\n@@ -2549,1 +2905,1 @@\n-        AdapterHandlerEntry* comparison_entry = create_adapter(comparison_blob, total_args_passed, sig_bt, false);\n+        AdapterHandlerEntry* comparison_entry = create_adapter(comparison_blob, ces, false);\n@@ -2559,1 +2915,1 @@\n-    entry = create_adapter(new_adapter, total_args_passed, sig_bt, \/* allocate_code_blob *\/ true);\n+    entry = create_adapter(new_adapter, ces, \/* allocate_code_blob *\/ true);\n@@ -2570,2 +2926,1 @@\n-                                                           int total_args_passed,\n-                                                           BasicType* sig_bt,\n+                                                           CompiledEntrySignature& ces,\n@@ -2580,5 +2935,0 @@\n-  VMRegPair stack_regs[16];\n-  VMRegPair* regs = (total_args_passed <= 16) ? stack_regs : NEW_RESOURCE_ARRAY(VMRegPair, total_args_passed);\n-\n-  \/\/ Get a description of the compiled java calling convention and the largest used (VMReg) stack slot usage\n-  int comp_args_on_stack = SharedRuntime::java_calling_convention(sig_bt, regs, total_args_passed);\n@@ -2592,1 +2942,1 @@\n-  AdapterFingerPrint* fingerprint = new AdapterFingerPrint(total_args_passed, sig_bt);\n+  AdapterFingerPrint* fingerprint = new AdapterFingerPrint(ces.sig_cc(), ces.has_inline_recv());\n@@ -2595,5 +2945,17 @@\n-                                                total_args_passed,\n-                                                comp_args_on_stack,\n-                                                sig_bt,\n-                                                regs,\n-                                                fingerprint);\n+                                                ces.args_on_stack(),\n+                                                ces.sig(),\n+                                                ces.regs(),\n+                                                ces.sig_cc(),\n+                                                ces.regs_cc(),\n+                                                ces.sig_cc_ro(),\n+                                                ces.regs_cc_ro(),\n+                                                fingerprint,\n+                                                new_adapter,\n+                                                allocate_code_blob);\n+\n+  if (ces.has_scalarized_args()) {\n+    \/\/ Save a C heap allocated version of the scalarized signature and store it in the adapter\n+    GrowableArray<SigEntry>* heap_sig = new (mtInternal) GrowableArray<SigEntry>(ces.sig_cc()->length(), mtInternal);\n+    heap_sig->appendAll(ces.sig_cc());\n+    entry->set_sig_cc(heap_sig);\n+  }\n@@ -2610,1 +2972,0 @@\n-  new_adapter = AdapterBlob::create(&buffer);\n@@ -2652,0 +3013,2 @@\n+  assert(base <= _c2i_inline_entry || _c2i_inline_entry == nullptr, \"\");\n+  assert(base <= _c2i_inline_ro_entry || _c2i_inline_ro_entry == nullptr, \"\");\n@@ -2653,0 +3016,1 @@\n+  assert(base <= _c2i_unverified_inline_entry || _c2i_unverified_inline_entry == nullptr, \"\");\n@@ -2665,0 +3029,4 @@\n+  if (_c2i_inline_entry != nullptr)\n+    _c2i_inline_entry += delta;\n+  if (_c2i_inline_ro_entry != nullptr)\n+    _c2i_inline_ro_entry += delta;\n@@ -2667,0 +3035,2 @@\n+  if (_c2i_unverified_inline_entry != nullptr)\n+    _c2i_unverified_inline_entry += delta;\n@@ -2675,0 +3045,3 @@\n+  if (_sig_cc != nullptr) {\n+    delete _sig_cc;\n+  }\n@@ -2761,0 +3134,1 @@\n+      BasicType stack_sig_bt[16];\n@@ -2762,0 +3136,1 @@\n+      BasicType* sig_bt = (total_args_passed <= 16) ? stack_sig_bt : NEW_RESOURCE_ARRAY(BasicType, total_args_passed);\n@@ -2764,5 +3139,13 @@\n-      AdapterSignatureIterator si(method->signature(), method->constMethod()->fingerprint(),\n-                              method->is_static(), total_args_passed);\n-      BasicType* sig_bt = si.basic_types();\n-      assert(si.slots() == total_args_passed, \"\");\n-      BasicType ret_type = si.return_type();\n+      int i = 0;\n+      if (!method->is_static()) {  \/\/ Pass in receiver first\n+        sig_bt[i++] = T_OBJECT;\n+      }\n+      SignatureStream ss(method->signature());\n+      for (; !ss.at_return_type(); ss.next()) {\n+        sig_bt[i++] = ss.type();  \/\/ Collect remaining bits of signature\n+        if (ss.type() == T_LONG || ss.type() == T_DOUBLE) {\n+          sig_bt[i++] = T_VOID;   \/\/ Longs & doubles take 2 Java slots\n+        }\n+      }\n+      assert(i == total_args_passed, \"\");\n+      BasicType ret_type = ss.type();\n@@ -3013,0 +3396,6 @@\n+  if (get_c2i_entry() != nullptr) {\n+    st->print(\" c2iVE: \" INTPTR_FORMAT, p2i(get_c2i_inline_entry()));\n+  }\n+  if (get_c2i_entry() != nullptr) {\n+    st->print(\" c2iVROE: \" INTPTR_FORMAT, p2i(get_c2i_inline_ro_entry()));\n+  }\n@@ -3014,1 +3403,4 @@\n-    st->print(\" c2iUV: \" INTPTR_FORMAT, p2i(get_c2i_unverified_entry()));\n+    st->print(\" c2iUE: \" INTPTR_FORMAT, p2i(get_c2i_unverified_entry()));\n+  }\n+  if (get_c2i_unverified_entry() != nullptr) {\n+    st->print(\" c2iUVE: \" INTPTR_FORMAT, p2i(get_c2i_unverified_inline_entry()));\n@@ -3103,0 +3495,195 @@\n+\n+\/\/ We are at a compiled code to interpreter call. We need backing\n+\/\/ buffers for all inline type arguments. Allocate an object array to\n+\/\/ hold them (convenient because once we're done with it we don't have\n+\/\/ to worry about freeing it).\n+oop SharedRuntime::allocate_inline_types_impl(JavaThread* current, methodHandle callee, bool allocate_receiver, TRAPS) {\n+  assert(InlineTypePassFieldsAsArgs, \"no reason to call this\");\n+  ResourceMark rm;\n+\n+  int nb_slots = 0;\n+  InstanceKlass* holder = callee->method_holder();\n+  allocate_receiver &= !callee->is_static() && holder->is_inline_klass() && callee->is_scalarized_arg(0);\n+  if (allocate_receiver) {\n+    nb_slots++;\n+  }\n+  int arg_num = callee->is_static() ? 0 : 1;\n+  for (SignatureStream ss(callee->signature()); !ss.at_return_type(); ss.next()) {\n+    BasicType bt = ss.type();\n+    if (bt == T_OBJECT && callee->is_scalarized_arg(arg_num)) {\n+      nb_slots++;\n+    }\n+    if (bt != T_VOID) {\n+      arg_num++;\n+    }\n+  }\n+  objArrayOop array_oop = oopFactory::new_objectArray(nb_slots, CHECK_NULL);\n+  objArrayHandle array(THREAD, array_oop);\n+  arg_num = callee->is_static() ? 0 : 1;\n+  int i = 0;\n+  if (allocate_receiver) {\n+    InlineKlass* vk = InlineKlass::cast(holder);\n+    oop res = vk->allocate_instance(CHECK_NULL);\n+    array->obj_at_put(i++, res);\n+  }\n+  for (SignatureStream ss(callee->signature()); !ss.at_return_type(); ss.next()) {\n+    BasicType bt = ss.type();\n+    if (bt == T_OBJECT && callee->is_scalarized_arg(arg_num)) {\n+      InlineKlass* vk = ss.as_inline_klass(holder);\n+      assert(vk != nullptr, \"Unexpected klass\");\n+      oop res = vk->allocate_instance(CHECK_NULL);\n+      array->obj_at_put(i++, res);\n+    }\n+    if (bt != T_VOID) {\n+      arg_num++;\n+    }\n+  }\n+  return array();\n+}\n+\n+JRT_ENTRY(void, SharedRuntime::allocate_inline_types(JavaThread* current, Method* callee_method, bool allocate_receiver))\n+  methodHandle callee(current, callee_method);\n+  oop array = SharedRuntime::allocate_inline_types_impl(current, callee, allocate_receiver, CHECK);\n+  current->set_vm_result(array);\n+  current->set_vm_result_2(callee()); \/\/ TODO: required to keep callee live?\n+JRT_END\n+\n+\/\/ We're returning from an interpreted method: load each field into a\n+\/\/ register following the calling convention\n+JRT_LEAF(void, SharedRuntime::load_inline_type_fields_in_regs(JavaThread* current, oopDesc* res))\n+{\n+  assert(res->klass()->is_inline_klass(), \"only inline types here\");\n+  ResourceMark rm;\n+  RegisterMap reg_map(current,\n+                      RegisterMap::UpdateMap::include,\n+                      RegisterMap::ProcessFrames::include,\n+                      RegisterMap::WalkContinuation::skip);\n+  frame stubFrame = current->last_frame();\n+  frame callerFrame = stubFrame.sender(&reg_map);\n+  assert(callerFrame.is_interpreted_frame(), \"should be coming from interpreter\");\n+\n+  InlineKlass* vk = InlineKlass::cast(res->klass());\n+\n+  const Array<SigEntry>* sig_vk = vk->extended_sig();\n+  const Array<VMRegPair>* regs = vk->return_regs();\n+\n+  if (regs == nullptr) {\n+    \/\/ The fields of the inline klass don't fit in registers, bail out\n+    return;\n+  }\n+\n+  int j = 1;\n+  for (int i = 0; i < sig_vk->length(); i++) {\n+    BasicType bt = sig_vk->at(i)._bt;\n+    if (bt == T_METADATA) {\n+      continue;\n+    }\n+    if (bt == T_VOID) {\n+      if (sig_vk->at(i-1)._bt == T_LONG ||\n+          sig_vk->at(i-1)._bt == T_DOUBLE) {\n+        j++;\n+      }\n+      continue;\n+    }\n+    int off = sig_vk->at(i)._offset;\n+    assert(off > 0, \"offset in object should be positive\");\n+    VMRegPair pair = regs->at(j);\n+    address loc = reg_map.location(pair.first(), nullptr);\n+    switch(bt) {\n+    case T_BOOLEAN:\n+      *(jboolean*)loc = res->bool_field(off);\n+      break;\n+    case T_CHAR:\n+      *(jchar*)loc = res->char_field(off);\n+      break;\n+    case T_BYTE:\n+      *(jbyte*)loc = res->byte_field(off);\n+      break;\n+    case T_SHORT:\n+      *(jshort*)loc = res->short_field(off);\n+      break;\n+    case T_INT: {\n+      *(jint*)loc = res->int_field(off);\n+      break;\n+    }\n+    case T_LONG:\n+#ifdef _LP64\n+      *(intptr_t*)loc = res->long_field(off);\n+#else\n+      Unimplemented();\n+#endif\n+      break;\n+    case T_OBJECT:\n+    case T_ARRAY: {\n+      *(oop*)loc = res->obj_field(off);\n+      break;\n+    }\n+    case T_FLOAT:\n+      *(jfloat*)loc = res->float_field(off);\n+      break;\n+    case T_DOUBLE:\n+      *(jdouble*)loc = res->double_field(off);\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n+    j++;\n+  }\n+  assert(j == regs->length(), \"missed a field?\");\n+\n+#ifdef ASSERT\n+  VMRegPair pair = regs->at(0);\n+  address loc = reg_map.location(pair.first(), nullptr);\n+  assert(*(oopDesc**)loc == res, \"overwritten object\");\n+#endif\n+\n+  current->set_vm_result(res);\n+}\n+JRT_END\n+\n+\/\/ We've returned to an interpreted method, the interpreter needs a\n+\/\/ reference to an inline type instance. Allocate it and initialize it\n+\/\/ from field's values in registers.\n+JRT_BLOCK_ENTRY(void, SharedRuntime::store_inline_type_fields_to_buf(JavaThread* current, intptr_t res))\n+{\n+  ResourceMark rm;\n+  RegisterMap reg_map(current,\n+                      RegisterMap::UpdateMap::include,\n+                      RegisterMap::ProcessFrames::include,\n+                      RegisterMap::WalkContinuation::skip);\n+  frame stubFrame = current->last_frame();\n+  frame callerFrame = stubFrame.sender(&reg_map);\n+\n+#ifdef ASSERT\n+  InlineKlass* verif_vk = InlineKlass::returned_inline_klass(reg_map);\n+#endif\n+\n+  if (!is_set_nth_bit(res, 0)) {\n+    \/\/ We're not returning with inline type fields in registers (the\n+    \/\/ calling convention didn't allow it for this inline klass)\n+    assert(!Metaspace::contains((void*)res), \"should be oop or pointer in buffer area\");\n+    current->set_vm_result((oopDesc*)res);\n+    assert(verif_vk == nullptr, \"broken calling convention\");\n+    return;\n+  }\n+\n+  clear_nth_bit(res, 0);\n+  InlineKlass* vk = (InlineKlass*)res;\n+  assert(verif_vk == vk, \"broken calling convention\");\n+  assert(Metaspace::contains((void*)res), \"should be klass\");\n+\n+  \/\/ Allocate handles for every oop field so they are safe in case of\n+  \/\/ a safepoint when allocating\n+  GrowableArray<Handle> handles;\n+  vk->save_oop_fields(reg_map, handles);\n+\n+  \/\/ It's unsafe to safepoint until we are here\n+  JRT_BLOCK;\n+  {\n+    JavaThread* THREAD = current;\n+    oop vt = vk->realloc_result(reg_map, handles, CHECK);\n+    current->set_vm_result(vt);\n+  }\n+  JRT_BLOCK_END;\n+}\n+JRT_END\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":723,"deletions":136,"binary":false,"changes":859,"status":"modified"},{"patch":"@@ -71,0 +71,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/inlineKlass.hpp\"\n@@ -233,1 +235,1 @@\n-  volatile_nonstatic_field(InstanceKlass,      _array_klasses,                                ObjArrayKlass*)                        \\\n+  volatile_nonstatic_field(InstanceKlass,      _array_klasses,                                ArrayKlass*)                        \\\n@@ -1157,0 +1159,1 @@\n+           declare_type(FlatArrayKlass, ArrayKlass)                       \\\n@@ -1160,0 +1163,1 @@\n+        declare_type(InlineKlass, InstanceKlass)                          \\\n@@ -1537,0 +1541,1 @@\n+  declare_c2_type(MachVEPNode, MachIdealNode)                             \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -628,0 +628,9 @@\n+\/\/----------------------------------------------------------------------------------------------------\n+\/\/ Prototyping\n+\/\/ \"Code Missing Here\" macro, un-define when integrating back from prototyping stage and break\n+\/\/ compilation on purpose (i.e. \"forget me not\")\n+#define PROTOTYPE\n+#ifdef PROTOTYPE\n+#define CMH(m)\n+#endif\n+\n@@ -713,6 +722,7 @@\n-  T_VOID        = 14,\n-  T_ADDRESS     = 15,\n-  T_NARROWOOP   = 16,\n-  T_METADATA    = 17,\n-  T_NARROWKLASS = 18,\n-  T_CONFLICT    = 19, \/\/ for stack value type with conflicting contents\n+  T_PRIMITIVE_OBJECT = 14, \/\/ Not a true BasicType, only use in headers of flat arrays\n+  T_VOID        = 15,\n+  T_ADDRESS     = 16,\n+  T_NARROWOOP   = 17,\n+  T_METADATA    = 18,\n+  T_NARROWKLASS = 19,\n+  T_CONFLICT    = 20, \/\/ for stack value type with conflicting contents\n@@ -733,0 +743,1 @@\n+    F(JVM_SIGNATURE_PRIMITIVE_OBJECT, T_PRIMITIVE_OBJECT, N) \\\n@@ -762,1 +773,1 @@\n-  return (t == T_OBJECT || t == T_ARRAY || (include_narrow_oop && t == T_NARROWOOP));\n+  return (t == T_OBJECT || t == T_ARRAY || t == T_PRIMITIVE_OBJECT || (include_narrow_oop && t == T_NARROWOOP));\n@@ -820,1 +831,2 @@\n-  T_VOID_size        = 0\n+  T_VOID_size        = 0,\n+  T_PRIMITIVE_OBJECT_size = 1\n@@ -850,0 +862,1 @@\n+  T_PRIMITIVE_OBJECT_aelem_bytes = 8,\n@@ -853,0 +866,1 @@\n+  T_PRIMITIVE_OBJECT_aelem_bytes = 4,\n@@ -945,1 +959,1 @@\n-  vtos = 9,             \/\/ tos not cached\n+  vtos = 9,             \/\/ tos not cached,\n@@ -962,1 +976,1 @@\n-    case T_ARRAY  : \/\/ fall through\n+    case T_ARRAY  :   \/\/ fall through\n@@ -1344,0 +1358,6 @@\n+\/\/ TEMP!!!!\n+\/\/ This should be removed after LW2 arrays are implemented (JDK-8220790).\n+\/\/ It's an alias to (EnableValhalla && (FlatArrayElementMaxSize != 0)),\n+\/\/ which is actually not 100% correct, but works for the current set of C1\/C2\n+\/\/ implementation and test cases.\n+#define UseFlatArray (EnableValhalla && (FlatArrayElementMaxSize != 0))\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":30,"deletions":10,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -130,0 +130,6 @@\n+ * Value classes implementing {@link Externalizable} cannot be serialized\n+ * or deserialized, the value object is immutable and the state cannot be restored.\n+ * Use {@link Serializable} {@code writeReplace} to delegate to another serializable\n+ * object such as a record.\n+ *\n+ * Value objects cannot be {@code java.io.Externalizable}.\n@@ -1195,0 +1201,3 @@\n+                if (cl.isValue() && !desc.isInstantiable()) {\n+                    throw new NotSerializableException(cl.getName());\n+                }\n@@ -1450,0 +1459,3 @@\n+                if (desc.forClass().isValue())\n+                    throw new NotSerializableException(\"Externalizable not valid for value class \"\n+                            + desc.forClass().getName());\n","filename":"src\/java.base\/share\/classes\/java\/io\/ObjectOutputStream.java","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -146,1 +146,10 @@\n- * handling methods discussed above are ignored for record types.<p>\n+ * handling methods discussed above, except {@code writeReplace},\n+ * are ignored for record types.<p>\n+ *\n+ * Value classes can implement {@code Serializble} and receive the treatment defined\n+ * by the <a href=\"{@docRoot}\/..\/specs\/serialization\/serial-arch.html#serialization-of-value-objects\">\n+ * <cite>Java Object Serialization Specification,<\/cite> Section 1.14,\n+ * \"Serialization of Value Objects\"<\/a>. Any declarations of the special\n+ * handling methods discussed above, except {@code writeReplace},\n+ * are ignored for value classes. Value classes implementing {@link Externalizable}\n+ * and not using {@code writeReplace} are not supported.<p>\n","filename":"src\/java.base\/share\/classes\/java\/io\/Serializable.java","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -61,1 +61,1 @@\n-                ReferenceClassDescImpl {\n+                ClassDescImpl {\n@@ -165,1 +165,1 @@\n-               : new ReferenceClassDescImpl(descriptor);\n+               : new ClassDescImpl(descriptor);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/constant\/ClassDesc.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -34,1 +34,1 @@\n- * interface, or array type.  A {@linkplain ReferenceClassDescImpl} corresponds to a\n+ * interface, or array type.  A {@linkplain ClassDescImpl} corresponds to a\n@@ -37,1 +37,1 @@\n-final class ReferenceClassDescImpl implements ClassDesc {\n+final class ClassDescImpl implements ClassDesc {\n@@ -49,1 +49,1 @@\n-    ReferenceClassDescImpl(String descriptor) {\n+    ClassDescImpl(String descriptor) {\n@@ -90,2 +90,2 @@\n-     * Returns {@code true} if this {@linkplain ReferenceClassDescImpl} is\n-     * equal to another {@linkplain ReferenceClassDescImpl}.  Equality is\n+     * Returns {@code true} if this {@linkplain ClassDescImpl} is\n+     * equal to another {@linkplain ClassDescImpl}.  Equality is\n","filename":"src\/java.base\/share\/classes\/java\/lang\/constant\/ClassDescImpl.java","additions":5,"deletions":5,"binary":false,"changes":10,"previous_filename":"src\/java.base\/share\/classes\/java\/lang\/constant\/ReferenceClassDescImpl.java","status":"renamed"},{"patch":"@@ -67,1 +67,1 @@\n-    public static final ClassDesc CD_Object = new ReferenceClassDescImpl(\"Ljava\/lang\/Object;\");\n+    public static final ClassDesc CD_Object = new ClassDescImpl(\"Ljava\/lang\/Object;\");\n@@ -70,1 +70,1 @@\n-    public static final ClassDesc CD_String = new ReferenceClassDescImpl(\"Ljava\/lang\/String;\");\n+    public static final ClassDesc CD_String = new ClassDescImpl(\"Ljava\/lang\/String;\");\n@@ -73,1 +73,1 @@\n-    public static final ClassDesc CD_Class = new ReferenceClassDescImpl(\"Ljava\/lang\/Class;\");\n+    public static final ClassDesc CD_Class = new ClassDescImpl(\"Ljava\/lang\/Class;\");\n@@ -76,1 +76,1 @@\n-    public static final ClassDesc CD_Number = new ReferenceClassDescImpl(\"Ljava\/lang\/Number;\");\n+    public static final ClassDesc CD_Number = new ClassDescImpl(\"Ljava\/lang\/Number;\");\n@@ -79,1 +79,1 @@\n-    public static final ClassDesc CD_Integer = new ReferenceClassDescImpl(\"Ljava\/lang\/Integer;\");\n+    public static final ClassDesc CD_Integer = new ClassDescImpl(\"Ljava\/lang\/Integer;\");\n@@ -82,1 +82,1 @@\n-    public static final ClassDesc CD_Long = new ReferenceClassDescImpl(\"Ljava\/lang\/Long;\");\n+    public static final ClassDesc CD_Long = new ClassDescImpl(\"Ljava\/lang\/Long;\");\n@@ -85,1 +85,1 @@\n-    public static final ClassDesc CD_Float = new ReferenceClassDescImpl(\"Ljava\/lang\/Float;\");\n+    public static final ClassDesc CD_Float = new ClassDescImpl(\"Ljava\/lang\/Float;\");\n@@ -88,1 +88,1 @@\n-    public static final ClassDesc CD_Double = new ReferenceClassDescImpl(\"Ljava\/lang\/Double;\");\n+    public static final ClassDesc CD_Double = new ClassDescImpl(\"Ljava\/lang\/Double;\");\n@@ -91,1 +91,1 @@\n-    public static final ClassDesc CD_Short = new ReferenceClassDescImpl(\"Ljava\/lang\/Short;\");\n+    public static final ClassDesc CD_Short = new ClassDescImpl(\"Ljava\/lang\/Short;\");\n@@ -94,1 +94,1 @@\n-    public static final ClassDesc CD_Byte = new ReferenceClassDescImpl(\"Ljava\/lang\/Byte;\");\n+    public static final ClassDesc CD_Byte = new ClassDescImpl(\"Ljava\/lang\/Byte;\");\n@@ -97,1 +97,1 @@\n-    public static final ClassDesc CD_Character = new ReferenceClassDescImpl(\"Ljava\/lang\/Character;\");\n+    public static final ClassDesc CD_Character = new ClassDescImpl(\"Ljava\/lang\/Character;\");\n@@ -100,1 +100,1 @@\n-    public static final ClassDesc CD_Boolean = new ReferenceClassDescImpl(\"Ljava\/lang\/Boolean;\");\n+    public static final ClassDesc CD_Boolean = new ClassDescImpl(\"Ljava\/lang\/Boolean;\");\n@@ -103,1 +103,1 @@\n-    public static final ClassDesc CD_Void = new ReferenceClassDescImpl(\"Ljava\/lang\/Void;\");\n+    public static final ClassDesc CD_Void = new ClassDescImpl(\"Ljava\/lang\/Void;\");\n@@ -106,1 +106,1 @@\n-    public static final ClassDesc CD_Throwable = new ReferenceClassDescImpl(\"Ljava\/lang\/Throwable;\");\n+    public static final ClassDesc CD_Throwable = new ClassDescImpl(\"Ljava\/lang\/Throwable;\");\n@@ -109,1 +109,1 @@\n-    public static final ClassDesc CD_Exception = new ReferenceClassDescImpl(\"Ljava\/lang\/Exception;\");\n+    public static final ClassDesc CD_Exception = new ClassDescImpl(\"Ljava\/lang\/Exception;\");\n@@ -112,1 +112,1 @@\n-    public static final ClassDesc CD_Enum = new ReferenceClassDescImpl(\"Ljava\/lang\/Enum;\");\n+    public static final ClassDesc CD_Enum = new ClassDescImpl(\"Ljava\/lang\/Enum;\");\n@@ -115,1 +115,1 @@\n-    public static final ClassDesc CD_VarHandle = new ReferenceClassDescImpl(\"Ljava\/lang\/invoke\/VarHandle;\");\n+    public static final ClassDesc CD_VarHandle = new ClassDescImpl(\"Ljava\/lang\/invoke\/VarHandle;\");\n@@ -118,1 +118,1 @@\n-    public static final ClassDesc CD_MethodHandles = new ReferenceClassDescImpl(\"Ljava\/lang\/invoke\/MethodHandles;\");\n+    public static final ClassDesc CD_MethodHandles = new ClassDescImpl(\"Ljava\/lang\/invoke\/MethodHandles;\");\n@@ -121,1 +121,1 @@\n-    public static final ClassDesc CD_MethodHandles_Lookup = new ReferenceClassDescImpl(\"Ljava\/lang\/invoke\/MethodHandles$Lookup;\");\n+    public static final ClassDesc CD_MethodHandles_Lookup = new ClassDescImpl(\"Ljava\/lang\/invoke\/MethodHandles$Lookup;\");\n@@ -124,1 +124,1 @@\n-    public static final ClassDesc CD_MethodHandle = new ReferenceClassDescImpl(\"Ljava\/lang\/invoke\/MethodHandle;\");\n+    public static final ClassDesc CD_MethodHandle = new ClassDescImpl(\"Ljava\/lang\/invoke\/MethodHandle;\");\n@@ -127,1 +127,1 @@\n-    public static final ClassDesc CD_MethodType = new ReferenceClassDescImpl(\"Ljava\/lang\/invoke\/MethodType;\");\n+    public static final ClassDesc CD_MethodType = new ClassDescImpl(\"Ljava\/lang\/invoke\/MethodType;\");\n@@ -130,1 +130,1 @@\n-    public static final ClassDesc CD_CallSite = new ReferenceClassDescImpl(\"Ljava\/lang\/invoke\/CallSite;\");\n+    public static final ClassDesc CD_CallSite = new ClassDescImpl(\"Ljava\/lang\/invoke\/CallSite;\");\n@@ -133,1 +133,1 @@\n-    public static final ClassDesc CD_Collection = new ReferenceClassDescImpl(\"Ljava\/util\/Collection;\");\n+    public static final ClassDesc CD_Collection = new ClassDescImpl(\"Ljava\/util\/Collection;\");\n@@ -136,1 +136,1 @@\n-    public static final ClassDesc CD_List = new ReferenceClassDescImpl(\"Ljava\/util\/List;\");\n+    public static final ClassDesc CD_List = new ClassDescImpl(\"Ljava\/util\/List;\");\n@@ -139,1 +139,1 @@\n-    public static final ClassDesc CD_Set = new ReferenceClassDescImpl(\"Ljava\/util\/Set;\");\n+    public static final ClassDesc CD_Set = new ClassDescImpl(\"Ljava\/util\/Set;\");\n@@ -142,1 +142,1 @@\n-    public static final ClassDesc CD_Map = new ReferenceClassDescImpl(\"Ljava\/util\/Map;\");\n+    public static final ClassDesc CD_Map = new ClassDescImpl(\"Ljava\/util\/Map;\");\n@@ -145,1 +145,1 @@\n-    public static final ClassDesc CD_ConstantDesc = new ReferenceClassDescImpl(\"Ljava\/lang\/constant\/ConstantDesc;\");\n+    public static final ClassDesc CD_ConstantDesc = new ClassDescImpl(\"Ljava\/lang\/constant\/ConstantDesc;\");\n@@ -148,1 +148,1 @@\n-    public static final ClassDesc CD_ClassDesc = new ReferenceClassDescImpl(\"Ljava\/lang\/constant\/ClassDesc;\");\n+    public static final ClassDesc CD_ClassDesc = new ClassDescImpl(\"Ljava\/lang\/constant\/ClassDesc;\");\n@@ -151,1 +151,1 @@\n-    public static final ClassDesc CD_EnumDesc = new ReferenceClassDescImpl(\"Ljava\/lang\/Enum$EnumDesc;\");\n+    public static final ClassDesc CD_EnumDesc = new ClassDescImpl(\"Ljava\/lang\/Enum$EnumDesc;\");\n@@ -154,1 +154,1 @@\n-    public static final ClassDesc CD_MethodTypeDesc = new ReferenceClassDescImpl(\"Ljava\/lang\/constant\/MethodTypeDesc;\");\n+    public static final ClassDesc CD_MethodTypeDesc = new ClassDescImpl(\"Ljava\/lang\/constant\/MethodTypeDesc;\");\n@@ -157,1 +157,1 @@\n-    public static final ClassDesc CD_MethodHandleDesc = new ReferenceClassDescImpl(\"Ljava\/lang\/constant\/MethodHandleDesc;\");\n+    public static final ClassDesc CD_MethodHandleDesc = new ClassDescImpl(\"Ljava\/lang\/constant\/MethodHandleDesc;\");\n@@ -160,1 +160,1 @@\n-    public static final ClassDesc CD_DirectMethodHandleDesc = new ReferenceClassDescImpl(\"Ljava\/lang\/constant\/DirectMethodHandleDesc;\");\n+    public static final ClassDesc CD_DirectMethodHandleDesc = new ClassDescImpl(\"Ljava\/lang\/constant\/DirectMethodHandleDesc;\");\n@@ -163,1 +163,1 @@\n-    public static final ClassDesc CD_VarHandleDesc = new ReferenceClassDescImpl(\"Ljava\/lang\/invoke\/VarHandle$VarHandleDesc;\");\n+    public static final ClassDesc CD_VarHandleDesc = new ClassDescImpl(\"Ljava\/lang\/invoke\/VarHandle$VarHandleDesc;\");\n@@ -166,1 +166,1 @@\n-    public static final ClassDesc CD_MethodHandleDesc_Kind = new ReferenceClassDescImpl(\"Ljava\/lang\/constant\/DirectMethodHandleDesc$Kind;\");\n+    public static final ClassDesc CD_MethodHandleDesc_Kind = new ClassDescImpl(\"Ljava\/lang\/constant\/DirectMethodHandleDesc$Kind;\");\n@@ -169,1 +169,1 @@\n-    public static final ClassDesc CD_DynamicConstantDesc = new ReferenceClassDescImpl(\"Ljava\/lang\/constant\/DynamicConstantDesc;\");\n+    public static final ClassDesc CD_DynamicConstantDesc = new ClassDescImpl(\"Ljava\/lang\/constant\/DynamicConstantDesc;\");\n@@ -172,1 +172,1 @@\n-    public static final ClassDesc CD_DynamicCallSiteDesc = new ReferenceClassDescImpl(\"Ljava\/lang\/constant\/DynamicCallSiteDesc;\");\n+    public static final ClassDesc CD_DynamicCallSiteDesc = new ClassDescImpl(\"Ljava\/lang\/constant\/DynamicCallSiteDesc;\");\n@@ -175,1 +175,1 @@\n-    public static final ClassDesc CD_ConstantBootstraps = new ReferenceClassDescImpl(\"Ljava\/lang\/invoke\/ConstantBootstraps;\");\n+    public static final ClassDesc CD_ConstantBootstraps = new ClassDescImpl(\"Ljava\/lang\/invoke\/ConstantBootstraps;\");\n","filename":"src\/java.base\/share\/classes\/java\/lang\/constant\/ConstantDescs.java","additions":37,"deletions":37,"binary":false,"changes":74,"status":"modified"},{"patch":"@@ -70,0 +70,3 @@\n+        @JEP(number=401, title=\"Value Classes and Objects\", status = \"Preview\")\n+        VALUE_OBJECTS,\n+\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/javac\/PreviewFeature.java","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -245,0 +245,5 @@\n+        \/**\n+         * Warn about issues related to migration of JDK classes.\n+         *\/\n+        MIGRATION(\"migration\"),\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Lint.java","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -234,0 +234,15 @@\n+    public boolean isValueClass() {\n+        return false;\n+    }\n+\n+    public boolean isIdentityClass() {\n+        return false;\n+    }\n+\n+    \/\/ Does this type need to be preloaded in the context of the referring class ??\n+    public boolean requiresLoadableDescriptors(Symbol referringClass) {\n+        if (this.tsym == referringClass)\n+            return false; \/\/ pointless\n+        return this.isValueClass() && this.isFinal();\n+    }\n+\n@@ -1177,0 +1192,10 @@\n+        @Override\n+        public boolean isValueClass() {\n+            return tsym != null && tsym.isValueClass();\n+        }\n+\n+        @Override\n+        public boolean isIdentityClass() {\n+            return tsym != null && tsym.isIdentityClass();\n+        }\n+\n@@ -2336,2 +2361,1 @@\n-            super(noType, List.nil(), null);\n-            this.tsym = tsym;\n+            super(noType, List.nil(), tsym, List.nil());\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Type.java","additions":26,"deletions":2,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -383,0 +383,13 @@\n+            if (!c.type.isErroneous()\n+                    && toAnnotate.kind == TYP\n+                    && types.isSameType(c.type, syms.migratedValueClassType)) {\n+                toAnnotate.flags_field |= Flags.MIGRATED_VALUE_CLASS;\n+            }\n+\n+            if (!c.type.isErroneous()\n+                    && toAnnotate.kind == VAR\n+                    && toAnnotate.owner.kind == TYP\n+                    && types.isSameType(c.type, syms.strictType)) {\n+                toAnnotate.flags_field |= Flags.STRICT;\n+            }\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Annotate.java","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -308,0 +308,11 @@\n+\n+        if (!env.info.ctorPrologue &&\n+                v.owner.isValueClass() &&\n+                !env.info.instanceInitializerBlock && \/\/ it is OK instance initializer blocks will go after super() anyways\n+                v.owner.kind == TYP &&\n+                v.owner == env.enclClass.sym &&\n+                (v.flags() & STATIC) == 0 &&\n+                (base == null ||\n+                        TreeInfo.isExplicitThisReference(types, (ClassType)env.enclClass.type, base))) {\n+            log.error(pos, Errors.CantRefAfterCtorCalled(v));\n+        }\n@@ -1185,1 +1196,5 @@\n-                        tree.body.stats = tree.body.stats.prepend(supCall);\n+                        if (owner.isValueClass()) {\n+                            tree.body.stats = tree.body.stats.append(supCall);\n+                        } else {\n+                            tree.body.stats = tree.body.stats.prepend(supCall);\n+                        }\n@@ -1299,4 +1314,13 @@\n-                    attribExpr(tree.init, initEnv, v.type);\n-                    if (tree.isImplicitlyTyped()) {\n-                        \/\/fixup local variable type\n-                        v.type = chk.checkLocalVarType(tree, tree.init.type, tree.name);\n+                    boolean previousCtorPrologue = initEnv.info.ctorPrologue;\n+                    try {\n+                        if (v.owner.kind == TYP && v.owner.isValueClass() && !v.isStatic()) {\n+                            \/\/ strict instance initializer in a value class\n+                            initEnv.info.ctorPrologue = true;\n+                        }\n+                        attribExpr(tree.init, initEnv, v.type);\n+                        if (tree.isImplicitlyTyped()) {\n+                            \/\/fixup local variable type\n+                            v.type = chk.checkLocalVarType(tree, tree.init.type, tree.name);\n+                        }\n+                    } finally {\n+                        initEnv.info.ctorPrologue = previousCtorPrologue;\n@@ -1411,1 +1435,5 @@\n-            if ((tree.flags & STATIC) != 0) localEnv.info.staticLevel++;\n+            if ((tree.flags & STATIC) != 0) {\n+                localEnv.info.staticLevel++;\n+            } else {\n+                localEnv.info.instanceInitializerBlock = true;\n+            }\n@@ -1920,2 +1948,4 @@\n-        chk.checkRefType(tree.pos(), attribExpr(tree.lock, env));\n-        if (env.info.lint.isEnabled(LintCategory.SYNCHRONIZATION) && isValueBased(tree.lock.type)) {\n+        boolean identityType = chk.checkIdentityType(tree.pos(), attribExpr(tree.lock, env));\n+        if (env.info.lint.isEnabled(LintCategory.SYNCHRONIZATION) &&\n+                identityType &&\n+                isValueBased(tree.lock.type)) {\n@@ -1932,1 +1962,0 @@\n-\n@@ -4382,0 +4411,1 @@\n+        Assert.check(site == tree.selected.type);\n@@ -5455,1 +5485,1 @@\n-                } else {\n+                } else if ((c.flags_field & Flags.COMPOUND) == 0) {\n@@ -5493,0 +5523,5 @@\n+                if (c.isValueClass()) {\n+                    Assert.check(env.tree.hasTag(CLASSDEF));\n+                    chk.checkConstraintsOfValueClass((JCClassDecl) env.tree, c);\n+                }\n+\n@@ -5635,1 +5670,1 @@\n-            chk.checkSerialStructure(tree, c);\n+            chk.checkSerialStructure(env, tree, c);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Attr.java","additions":46,"deletions":11,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -31,1 +31,0 @@\n-import java.util.function.Consumer;\n@@ -82,1 +81,0 @@\n-import javax.lang.model.element.ExecutableElement;\n@@ -85,2 +83,0 @@\n-import javax.lang.model.type.TypeMirror;\n-import javax.lang.model.util.ElementFilter;\n@@ -187,0 +183,2 @@\n+        allowValueClasses = (!preview.isPreview(Feature.VALUE_CLASSES) || preview.isEnabled()) &&\n+                Feature.VALUE_CLASSES.allowedInSource(source);\n@@ -230,0 +228,4 @@\n+    \/** Are value classes allowed\n+     *\/\n+    private final boolean allowValueClasses;\n+\n@@ -763,0 +765,25 @@\n+    void checkConstraintsOfValueClass(JCClassDecl tree, ClassSymbol c) {\n+        DiagnosticPosition pos = tree.pos();\n+        for (Type st : types.closure(c.type)) {\n+            if (st == null || st.tsym == null || st.tsym.kind == ERR)\n+                continue;\n+            if  (st.tsym == syms.objectType.tsym || st.tsym == syms.recordType.tsym || st.isInterface())\n+                continue;\n+            if (!st.tsym.isAbstract()) {\n+                if (c != st.tsym) {\n+                    log.error(pos, Errors.ConcreteSupertypeForValueClass(c, st));\n+                }\n+                continue;\n+            }\n+            \/\/ dealing with an abstract value or value super class below.\n+            for (Symbol s : st.tsym.members().getSymbols(NON_RECURSIVE)) {\n+                if (s.kind == MTH) {\n+                    if ((s.flags() & (SYNCHRONIZED | STATIC)) == SYNCHRONIZED) {\n+                        log.error(pos, Errors.SuperClassMethodCannotBeSynchronized(s, c, st));\n+                    }\n+                    break;\n+                }\n+            }\n+        }\n+    }\n+\n@@ -820,0 +847,26 @@\n+    \/** Check that type is an identity type, i.e. not a value type.\n+     *  When not discernible statically, give it the benefit of doubt\n+     *  and defer to runtime.\n+     *\n+     *  @param pos           Position to be used for error reporting.\n+     *  @param t             The type to be checked.\n+     *\/\n+    boolean checkIdentityType(DiagnosticPosition pos, Type t) {\n+        if (t.hasTag(TYPEVAR)) {\n+            t = types.skipTypeVars(t, false);\n+        }\n+        if (t.isIntersection()) {\n+            IntersectionClassType ict = (IntersectionClassType)t;\n+            boolean result = true;\n+            for (Type component : ict.getExplicitComponents()) {\n+                result &= checkIdentityType(pos, component);\n+            }\n+            return result;\n+        }\n+        if (t.isPrimitive() || (t.isValueClass() && !t.tsym.isAbstract())) {\n+            typeTagError(pos, diags.fragment(Fragments.TypeReqIdentity), t);\n+            return false;\n+        }\n+        return true;\n+    }\n+\n@@ -1210,2 +1263,7 @@\n-            else\n-                mask = VarFlags;\n+            else {\n+                boolean isInstanceFieldOfValueClass = sym.owner.type.isValueClass() && (flags & STATIC) == 0;\n+                mask = !isInstanceFieldOfValueClass ? VarFlags : ExtendedVarFlags;\n+                if (isInstanceFieldOfValueClass) {\n+                    implicit |= FINAL | STRICT;\n+                }\n+            }\n@@ -1237,1 +1295,2 @@\n-                mask = RecordMethodFlags;\n+                mask = ((sym.owner.flags_field & VALUE_CLASS) != 0 && (flags & Flags.STATIC) == 0) ?\n+                        RecordMethodFlags & ~SYNCHRONIZED : RecordMethodFlags;\n@@ -1239,1 +1298,3 @@\n-                mask = MethodFlags;\n+                \/\/ value objects do not have an associated monitor\/lock\n+                mask = ((sym.owner.flags_field & VALUE_CLASS) != 0 && (flags & Flags.STATIC) == 0) ?\n+                        MethodFlags & ~SYNCHRONIZED : MethodFlags;\n@@ -1256,1 +1317,1 @@\n-                mask = staticOrImplicitlyStatic && allowRecords && (flags & ANNOTATION) == 0 ? StaticLocalFlags : LocalClassFlags;\n+                mask = staticOrImplicitlyStatic && allowRecords && (flags & ANNOTATION) == 0 ? ExtendedStaticLocalClassFlags : ExtendedLocalClassFlags;\n@@ -1275,0 +1336,4 @@\n+            if ((flags & (INTERFACE | VALUE_CLASS)) == 0) {\n+                implicit |= IDENTITY_TYPE;\n+            }\n+\n@@ -1276,2 +1341,2 @@\n-                \/\/ enums can't be declared abstract, final, sealed or non-sealed\n-                mask &= ~(ABSTRACT | FINAL | SEALED | NON_SEALED);\n+                \/\/ enums can't be declared abstract, final, sealed or non-sealed or value\n+                mask &= ~(ABSTRACT | FINAL | SEALED | NON_SEALED | VALUE_CLASS);\n@@ -1290,0 +1355,5 @@\n+\n+            \/\/ concrete value classes are implicitly final\n+            if ((flags & (ABSTRACT | INTERFACE | VALUE_CLASS)) == VALUE_CLASS) {\n+                implicit |= FINAL;\n+            }\n@@ -1344,1 +1414,10 @@\n-                                ANNOTATION)) {\n+                                ANNOTATION)\n+                && checkDisjoint(pos, flags,\n+                                VALUE_CLASS,\n+                                ANNOTATION)\n+                && checkDisjoint(pos, flags,\n+                                VALUE_CLASS,\n+                                NON_SEALED)\n+                && checkDisjoint(pos, flags,\n+                                VALUE_CLASS,\n+                                INTERFACE) ) {\n@@ -2161,0 +2240,5 @@\n+        if (allowValueClasses && origin.isValueClass() && names.finalize.equals(m.name)) {\n+            if (m.overrides(syms.objectFinalize, origin, types, false)) {\n+                log.warning(tree.pos(), Warnings.ValueFinalize);\n+            }\n+        }\n@@ -2589,0 +2673,12 @@\n+\n+        Type identitySuper = null;\n+        for (Type t : types.closure(c)) {\n+            if (t != c) {\n+                if (t.isIdentityClass() && (t.tsym.flags() & VALUE_BASED) == 0)\n+                    identitySuper = t;\n+                if (c.isValueClass() && identitySuper != null && identitySuper.tsym != syms.objectType.tsym) { \/\/ Object is special\n+                    log.error(pos, Errors.ValueTypeHasIdentitySuperType(c, identitySuper));\n+                    break;\n+                }\n+            }\n+        }\n@@ -4063,1 +4159,1 @@\n-                \/\/ If super()\/this() isn't first, require \"statements before super()\" feature\n+                \/\/ If super()\/this() isn't first, require flexible constructors feature\n@@ -4904,2 +5000,2 @@\n-    public void checkSerialStructure(JCClassDecl tree, ClassSymbol c) {\n-        (new SerialTypeVisitor()).visit(c, tree);\n+    public void checkSerialStructure(Env<AttrContext> env, JCClassDecl tree, ClassSymbol c) {\n+        (new SerialTypeVisitor(env)).visit(c, tree);\n@@ -4936,1 +5032,2 @@\n-        SerialTypeVisitor() {\n+        Env<AttrContext> env;\n+        SerialTypeVisitor(Env<AttrContext> env) {\n@@ -4938,0 +5035,1 @@\n+            this.env = env;\n@@ -4997,0 +5095,1 @@\n+            final boolean[] hasWriteReplace = {false};\n@@ -5071,1 +5170,1 @@\n-                            case \"writeReplace\"     -> checkWriteReplace(tree,e, method);\n+                            case \"writeReplace\"     -> {hasWriteReplace[0] = true; hasAppropriateWriteReplace(tree, method, true);}\n@@ -5082,1 +5181,20 @@\n-\n+            if (!hasWriteReplace[0] &&\n+                    (c.isValueClass() || hasAbstractValueSuperClass(c, Set.of(syms.numberType.tsym))) &&\n+                    !c.isAbstract() && !c.isRecord() &&\n+                    types.unboxedType(c.type) == Type.noType) {\n+                \/\/ we need to check if the class is inheriting an appropriate writeReplace method\n+                MethodSymbol ms = null;\n+                Log.DiagnosticHandler discardHandler = new Log.DiscardDiagnosticHandler(log);\n+                try {\n+                    ms = rs.resolveInternalMethod(env.tree, env, c.type, names.writeReplace, List.nil(), List.nil());\n+                } catch (FatalError fe) {\n+                    \/\/ ignore no method was found\n+                } finally {\n+                    log.popDiagnosticHandler(discardHandler);\n+                }\n+                if (ms == null || !hasAppropriateWriteReplace(p, ms, false)) {\n+                    log.warning(LintCategory.SERIAL, p,\n+                            c.isValueClass() ? Warnings.SerializableValueClassWithoutWriteReplace1 :\n+                                    Warnings.SerializableValueClassWithoutWriteReplace2);\n+                }\n+            }\n@@ -5090,0 +5208,16 @@\n+        private boolean hasAbstractValueSuperClass(Symbol c, Set<Symbol> excluding) {\n+            while (c.getKind() == ElementKind.CLASS) {\n+                Type sup = ((ClassSymbol)c).getSuperclass();\n+                if (!sup.hasTag(CLASS) || sup.isErroneous() ||\n+                        sup.tsym == syms.objectType.tsym) {\n+                    return false;\n+                }\n+                \/\/ if it is a value super class it has to be abstract\n+                if (sup.isValueClass() && !excluding.contains(sup.tsym)) {\n+                    return true;\n+                }\n+                c = sup.tsym;\n+            }\n+            return false;\n+        }\n+\n@@ -5213,1 +5347,1 @@\n-            checkReturnType(tree, e, method, syms.voidType);\n+            isExpectedReturnType(tree, method, syms.voidType, true);\n@@ -5215,1 +5349,1 @@\n-            checkExceptions(tree, e, method, syms.ioExceptionType);\n+            hasExpectedExceptions(tree, method, true, syms.ioExceptionType);\n@@ -5219,1 +5353,1 @@\n-        private void checkWriteReplace(JCClassDecl tree, Element e, MethodSymbol method) {\n+        private boolean hasAppropriateWriteReplace(JCClassDecl tree, MethodSymbol method, boolean warn) {\n@@ -5225,4 +5359,4 @@\n-            checkConcreteInstanceMethod(tree, e, method);\n-            checkReturnType(tree, e, method, syms.objectType);\n-            checkNoArgs(tree, e, method);\n-            checkExceptions(tree, e, method, syms.objectStreamExceptionType);\n+            return isConcreteInstanceMethod(tree, method, warn) &&\n+                    isExpectedReturnType(tree, method, syms.objectType, warn) &&\n+                    hasNoArgs(tree, method, warn) &&\n+                    hasExpectedExceptions(tree, method, warn, syms.objectStreamExceptionType);\n@@ -5239,1 +5373,1 @@\n-            checkReturnType(tree, e, method, syms.voidType);\n+            isExpectedReturnType(tree, method, syms.voidType, true);\n@@ -5241,1 +5375,1 @@\n-            checkExceptions(tree, e, method, syms.ioExceptionType, syms.classNotFoundExceptionType);\n+            hasExpectedExceptions(tree, method, true, syms.ioExceptionType, syms.classNotFoundExceptionType);\n@@ -5248,3 +5382,3 @@\n-            checkReturnType(tree, e, method, syms.voidType);\n-            checkNoArgs(tree, e, method);\n-            checkExceptions(tree, e, method, syms.objectStreamExceptionType);\n+            isExpectedReturnType(tree, method, syms.voidType, true);\n+            hasNoArgs(tree, method, true);\n+            hasExpectedExceptions(tree, method, true, syms.objectStreamExceptionType);\n@@ -5260,4 +5394,4 @@\n-            checkConcreteInstanceMethod(tree, e, method);\n-            checkReturnType(tree,e, method, syms.objectType);\n-            checkNoArgs(tree, e, method);\n-            checkExceptions(tree, e, method, syms.objectStreamExceptionType);\n+            isConcreteInstanceMethod(tree, method, true);\n+            isExpectedReturnType(tree, method, syms.objectType, true);\n+            hasNoArgs(tree, method, true);\n+            hasExpectedExceptions(tree, method, true, syms.objectStreamExceptionType);\n@@ -5513,1 +5647,1 @@\n-                        case \"writeReplace\" -> checkWriteReplace(tree, e, method);\n+                        case \"writeReplace\" -> hasAppropriateWriteReplace(tree, method, true);\n@@ -5531,3 +5665,3 @@\n-        void checkConcreteInstanceMethod(JCClassDecl tree,\n-                                         Element enclosing,\n-                                         MethodSymbol method) {\n+        boolean isConcreteInstanceMethod(JCClassDecl tree,\n+                                         MethodSymbol method,\n+                                         boolean warn) {\n@@ -5535,0 +5669,1 @@\n+                if (warn) {\n@@ -5536,2 +5671,4 @@\n-                                TreeInfo.diagnosticPositionFor(method, tree),\n-                                Warnings.SerialConcreteInstanceMethod(method.getSimpleName()));\n+                            TreeInfo.diagnosticPositionFor(method, tree),\n+                            Warnings.SerialConcreteInstanceMethod(method.getSimpleName()));\n+                }\n+                return false;\n@@ -5539,0 +5676,1 @@\n+            return true;\n@@ -5541,4 +5679,4 @@\n-        private void checkReturnType(JCClassDecl tree,\n-                                     Element enclosing,\n-                                     MethodSymbol method,\n-                                     Type expectedReturnType) {\n+        private boolean isExpectedReturnType(JCClassDecl tree,\n+                                          MethodSymbol method,\n+                                          Type expectedReturnType,\n+                                          boolean warn) {\n@@ -5552,1 +5690,2 @@\n-                log.warning(LintCategory.SERIAL,\n+                if (warn) {\n+                    log.warning(LintCategory.SERIAL,\n@@ -5555,1 +5694,3 @@\n-                                                                      rtype, expectedReturnType));\n+                                    rtype, expectedReturnType));\n+                }\n+                return false;\n@@ -5557,0 +5698,1 @@\n+            return true;\n@@ -5594,1 +5736,1 @@\n-        private void checkNoArgs(JCClassDecl tree, Element enclosing, MethodSymbol method) {\n+        boolean hasNoArgs(JCClassDecl tree, MethodSymbol method, boolean warn) {\n@@ -5597,1 +5739,2 @@\n-                log.warning(LintCategory.SERIAL,\n+                if (warn) {\n+                    log.warning(LintCategory.SERIAL,\n@@ -5600,0 +5743,2 @@\n+                }\n+                return false;\n@@ -5601,0 +5746,1 @@\n+            return true;\n@@ -5613,4 +5759,4 @@\n-        private void checkExceptions(JCClassDecl tree,\n-                                     Element enclosing,\n-                                     MethodSymbol method,\n-                                     Type... declaredExceptions) {\n+        private boolean hasExpectedExceptions(JCClassDecl tree,\n+                                              MethodSymbol method,\n+                                              boolean warn,\n+                                              Type... declaredExceptions) {\n@@ -5635,1 +5781,2 @@\n-                        log.warning(LintCategory.SERIAL,\n+                        if (warn) {\n+                            log.warning(LintCategory.SERIAL,\n@@ -5638,1 +5785,3 @@\n-                                                                             thrownType));\n+                                            thrownType));\n+                        }\n+                        return false;\n@@ -5642,1 +5791,1 @@\n-            return;\n+            return true;\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Check.java","additions":204,"deletions":55,"binary":false,"changes":259,"status":"modified"},{"patch":"@@ -37,1 +37,0 @@\n-import com.sun.tools.javac.code.Scope.ImportScope;\n@@ -56,0 +55,1 @@\n+import static com.sun.tools.javac.code.Flags.SYNCHRONIZED;\n@@ -60,1 +60,0 @@\n-import com.sun.tools.javac.resources.CompilerProperties.Fragments;\n@@ -1118,0 +1117,4 @@\n+\n+            if ((tree.sym.flags() & (INTERFACE | VALUE_CLASS)) == 0) {\n+                tree.sym.flags_field |= IDENTITY_TYPE;\n+            }\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/TypeEnter.java","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -40,0 +40,1 @@\n+import com.sun.tools.javac.code.Flags.Flag;\n@@ -43,0 +44,1 @@\n+import com.sun.tools.javac.parser.Tokens.Comment.CommentStyle;\n@@ -54,0 +56,1 @@\n+import static com.sun.tools.javac.code.Flags.asFlagSet;\n@@ -62,0 +65,1 @@\n+import static com.sun.tools.javac.parser.Tokens.TokenKind.SYNCHRONIZED;\n@@ -201,0 +205,2 @@\n+        this.allowValueClasses = (!preview.isPreview(Feature.VALUE_CLASSES) || preview.isEnabled()) &&\n+                Feature.VALUE_CLASSES.allowedInSource(source);\n@@ -225,0 +231,2 @@\n+        this.allowValueClasses = (!preview.isPreview(Feature.VALUE_CLASSES) || preview.isEnabled()) &&\n+                Feature.VALUE_CLASSES.allowedInSource(source);\n@@ -262,0 +270,4 @@\n+    \/** Switch: are value classes allowed in this source level?\n+     *\/\n+    boolean allowValueClasses;\n+\n@@ -1643,2 +1655,2 @@\n-                        if (!isMode(TYPE) && isUnboundMemberRef()) {\n-                            \/\/this is an unbound method reference whose qualifier\n+                        if (!isMode(TYPE) && isParameterizedTypePrefix()) {\n+                            \/\/this is either an unbound method reference whose qualifier\n@@ -1886,1 +1898,1 @@\n-    boolean isUnboundMemberRef() {\n+    boolean isParameterizedTypePrefix() {\n@@ -2555,2 +2567,2 @@\n-        List<JCAnnotation> newAnnotations = typeAnnotationsOpt();\n-\n+        final JCModifiers mods = modifiersOpt();\n+        List<JCAnnotation> newAnnotations = mods.annotations;\n@@ -2560,0 +2572,3 @@\n+            if (mods.flags != 0) {\n+                log.error(token.pos, Errors.ModNotAllowedHere(asFlagSet(mods.flags)));\n+            }\n@@ -2632,1 +2647,5 @@\n-            return classCreatorRest(newpos, null, typeArgs, t);\n+            JCNewClass newClass = classCreatorRest(newpos, null, typeArgs, t, mods.flags);\n+            if ((newClass.def == null) && (mods.flags != 0)) {\n+                log.error(newClass.pos, Errors.ModNotAllowedHere(asFlagSet(mods.flags)));\n+            }\n+            return newClass;\n@@ -2657,1 +2676,1 @@\n-        return classCreatorRest(newpos, encl, typeArgs, t);\n+        return classCreatorRest(newpos, encl, typeArgs, t, 0);\n@@ -2735,1 +2754,2 @@\n-                                  JCExpression t)\n+                                  JCExpression t,\n+                                  long flags)\n@@ -2743,1 +2763,1 @@\n-            JCModifiers mods = F.at(Position.NOPOS).Modifiers(0);\n+            JCModifiers mods = F.at(Position.NOPOS).Modifiers(flags);\n@@ -2983,0 +3003,5 @@\n+        if ((isValueModifier()) && allowValueClasses) {\n+            checkSourceLevel(Feature.VALUE_CLASSES);\n+            dc = token.docComment();\n+            return List.of(classOrRecordOrInterfaceOrEnumDeclaration(modifiersOpt(), dc));\n+        }\n@@ -3483,1 +3508,4 @@\n-                return variableDeclarators(modifiersOpt(), t, stats, true).toList();\n+                pos = token.pos;\n+                JCModifiers mods = F.at(Position.NOPOS).Modifiers(0);\n+                F.at(pos);\n+                return variableDeclarators(mods, t, stats, true).toList();\n@@ -3580,0 +3608,5 @@\n+                if (isValueModifier()) {\n+                    checkSourceLevel(Feature.VALUE_CLASSES);\n+                    flag = Flags.VALUE_CLASS;\n+                    break;\n+                }\n@@ -3848,0 +3881,7 @@\n+        if (name == names.value) {\n+            if (allowValueClasses) {\n+                return Source.JDK23;\n+            } else if (shouldWarn) {\n+                log.warning(pos, Warnings.RestrictedTypeNotAllowedPreview(name, Source.JDK23));\n+            }\n+        }\n@@ -4931,0 +4971,26 @@\n+    protected boolean isValueModifier() {\n+        if (token.kind == IDENTIFIER && token.name() == names.value) {\n+            boolean isValueModifier = false;\n+            Token next = S.token(1);\n+            switch (next.kind) {\n+                case PRIVATE: case PROTECTED: case PUBLIC: case STATIC: case TRANSIENT:\n+                case FINAL: case ABSTRACT: case NATIVE: case VOLATILE: case SYNCHRONIZED:\n+                case STRICTFP: case MONKEYS_AT: case DEFAULT: case BYTE: case SHORT:\n+                case CHAR: case INT: case LONG: case FLOAT: case DOUBLE: case BOOLEAN: case VOID:\n+                case CLASS: case INTERFACE: case ENUM:\n+                    isValueModifier = true;\n+                    break;\n+                case IDENTIFIER: \/\/ value record R || value value || new value Comparable() {} ??\n+                    if (next.name() == names.record || next.name() == names.value\n+                            || (mode & EXPR) != 0)\n+                        isValueModifier = true;\n+                    break;\n+            }\n+            if (isValueModifier) {\n+                checkSourceLevel(Feature.VALUE_CLASSES);\n+                return true;\n+            }\n+        }\n+        return false;\n+    }\n+\n@@ -4958,1 +5024,3 @@\n-                case IDENTIFIER -> isNonSealedIdentifier(next, currentIsNonSealed ? 3 : 1) || next.name() == names.sealed;\n+                case IDENTIFIER -> isNonSealedIdentifier(next, currentIsNonSealed ? 3 : 1) ||\n+                        next.name() == names.sealed ||\n+                        allowValueClasses && next.name() == names.value;\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/parser\/JavacParser.java","additions":79,"deletions":11,"binary":false,"changes":90,"status":"modified"},{"patch":"@@ -773,1 +773,1 @@\n-    improperly formed type, some parameters are missing\n+    improperly formed type, some parameters are missing or misplaced\n@@ -2068,0 +2068,6 @@\n+compiler.warn.serializable.value.class.without.write.replace.1=\\\n+    serializable value class does not declare, or inherits, a writeReplace method\n+\n+compiler.warn.serializable.value.class.without.write.replace.2=\\\n+    serializable class does not declare, or inherits, a writeReplace method\n+\n@@ -2719,0 +2725,3 @@\n+compiler.misc.type.req.identity=\\\n+    a type with identity\n+\n@@ -3730,0 +3739,3 @@\n+compiler.misc.bad.access.flags=\\\n+    bad access flags combination: {0}\n+\n@@ -4063,0 +4075,19 @@\n+compiler.misc.feature.value.classes=\\\n+    value classes\n+\n+# 0: type, 1: type\n+compiler.err.value.type.has.identity.super.type=\\\n+    The identity type {1} cannot be a supertype of the value type {0}\n+\n+# 0: symbol, 1: type\n+compiler.err.concrete.supertype.for.value.class=\\\n+    The concrete class {1} is not allowed to be a super class of the value class {0} either directly or indirectly\n+\n+# 0: symbol, 1: symbol, 2: type\n+compiler.err.super.class.method.cannot.be.synchronized=\\\n+    The method {0} in the super class {2} of the value class {1} is synchronized. This is disallowed\n+\n+# 0: symbol or name\n+compiler.err.cant.ref.after.ctor.called=\\\n+    cannot reference {0} after supertype constructor has been called\n+\n@@ -4087,0 +4118,3 @@\n+\n+compiler.warn.value.finalize=\\\n+    value classes should not have finalize methods, they are not invoked\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/resources\/compiler.properties","additions":35,"deletions":1,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -228,0 +228,3 @@\n+javac.opt.Xlint.desc.migration=\\\n+    Warn about issues related to migration of JDK classes.\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/resources\/javac.properties","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -240,0 +240,1 @@\n+        jdk.jdeps,\n@@ -249,0 +250,1 @@\n+        jdk.jdeps,\n","filename":"src\/jdk.compiler\/share\/classes\/module-info.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -81,0 +81,2 @@\n+compiler\/c2\/irTests\/scalarReplacement\/AllocationMergesTests.java 8315003 generic-all\n+\n@@ -101,0 +103,1 @@\n+runtime\/cds\/appcds\/redefineClass\/RedefineRunningMethods_Shared.java  8304168 generic-all\n@@ -127,0 +130,5 @@\n+\n+# Valhalla\n+runtime\/AccModule\/ConstModule.java 8294051 generic-all\n+runtime\/valhalla\/inlinetypes\/InlineOops.java#ZGen 8313607 linux-aarch64,macosx-aarch64\n+\n@@ -151,0 +159,31 @@\n+# Valhalla TODO:\n+serviceability\/jvmti\/valhalla\/HeapDump\/HeapDump.java 8317416 generic-all\n+\n+serviceability\/sa\/ClhsdbCDSCore.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbCDSJstackPrintAll.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbFindPC.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbInspect.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbLongConstant.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbJdis.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbJstack.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintAll.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintAs.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintStatics.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbSource.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbSymbol.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbWhere.java 8190936 generic-all\n+serviceability\/sa\/JhsdbThreadInfoTest.java 8190936 generic-all\n+serviceability\/sa\/TestClassDump.java 8190936 generic-all\n+serviceability\/sa\/TestClhsdbJstackLock.java 8190936 generic-all\n+serviceability\/sa\/TestCpoolForInvokeDynamic.java 8190936 generic-all\n+serviceability\/sa\/TestHeapDumpForInvokeDynamic.java 8190936 generic-all\n+serviceability\/sa\/TestHeapDumpForLargeArray.java 8190936 generic-all\n+serviceability\/sa\/TestIntConstant.java 8190936 generic-all\n+serviceability\/sa\/TestJhsdbJstackLock.java 8190936 generic-all\n+serviceability\/sa\/TestJmapCore.java 8190936 generic-all\n+serviceability\/sa\/TestJmapCoreMetaspace.java 8190936 generic-all\n+serviceability\/sa\/TestPrintMdo.java 8190936 generic-all\n+serviceability\/sa\/jmap-hprof\/JMapHProfLargeHeapTest.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbDumpclass.java 8190936 generic-all\n+\n+\n@@ -189,0 +228,2 @@\n+vmTestbase\/vm\/mlvm\/hiddenloader\/stress\/byteMutation\/Test.java 8317172 generic-all\n+\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":41,"deletions":0,"binary":false,"changes":41,"status":"modified"}]}