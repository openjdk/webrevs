{"files":[{"patch":"@@ -66,1 +66,1 @@\n-    DISABLED_WARNINGS := try deprecation rawtypes unchecked serial cast removal preview varargs, \\\n+    DISABLED_WARNINGS := try deprecation rawtypes unchecked serial cast removal preview varargs dangling-doc-comments, \\\n","filename":"make\/test\/BuildTestLib.gmk","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1129,4 +1129,0 @@\n-\/\/ Figure out which register class each belongs in: rc_int, rc_float or\n-\/\/ rc_stack.\n-enum RC { rc_bad, rc_int, rc_float, rc_predicate, rc_stack };\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -38,0 +38,4 @@\n+#ifdef COMPILER2\n+#include \"code\/vmreg.inline.hpp\"\n+#include \"gc\/shared\/c2\/barrierSetC2.hpp\"\n+#endif \/\/ COMPILER2\n@@ -450,0 +454,201 @@\n+\n+#ifdef COMPILER2\n+\n+OptoReg::Name BarrierSetAssembler::encode_float_vector_register_size(const Node* node, OptoReg::Name opto_reg) {\n+  switch (node->ideal_reg()) {\n+    case Op_RegF:\n+      \/\/ No need to refine. The original encoding is already fine to distinguish.\n+      assert(opto_reg % 4 == 0, \"Float register should only occupy a single slot\");\n+      break;\n+    \/\/ Use different encoding values of the same fp\/vector register to help distinguish different sizes.\n+    \/\/ Such as V16. The OptoReg::name and its corresponding slot value are\n+    \/\/ \"V16\": 64, \"V16_H\": 65, \"V16_J\": 66, \"V16_K\": 67.\n+    case Op_RegD:\n+    case Op_VecD:\n+      opto_reg &= ~3;\n+      opto_reg |= 1;\n+      break;\n+    case Op_VecX:\n+      opto_reg &= ~3;\n+      opto_reg |= 2;\n+      break;\n+    case Op_VecA:\n+      opto_reg &= ~3;\n+      opto_reg |= 3;\n+      break;\n+    default:\n+      assert(false, \"unexpected ideal register\");\n+      ShouldNotReachHere();\n+  }\n+  return opto_reg;\n+}\n+\n+OptoReg::Name BarrierSetAssembler::refine_register(const Node* node, OptoReg::Name opto_reg) {\n+  if (!OptoReg::is_reg(opto_reg)) {\n+    return OptoReg::Bad;\n+  }\n+\n+  const VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n+  if (vm_reg->is_FloatRegister()) {\n+    opto_reg = encode_float_vector_register_size(node, opto_reg);\n+  }\n+\n+  return opto_reg;\n+}\n+\n+#undef __\n+#define __ _masm->\n+\n+void SaveLiveRegisters::initialize(BarrierStubC2* stub) {\n+  int index = -1;\n+  GrowableArray<RegisterData> registers;\n+  VMReg prev_vm_reg = VMRegImpl::Bad();\n+\n+  RegMaskIterator rmi(stub->live());\n+  while (rmi.has_next()) {\n+    OptoReg::Name opto_reg = rmi.next();\n+    VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n+\n+    if (vm_reg->is_Register()) {\n+      \/\/ GPR may have one or two slots in regmask\n+      \/\/ Determine whether the current vm_reg is the same physical register as the previous one\n+      if (is_same_register(vm_reg, prev_vm_reg)) {\n+        registers.at(index)._slots++;\n+      } else {\n+        RegisterData reg_data = { vm_reg, 1 };\n+        index = registers.append(reg_data);\n+      }\n+    } else if (vm_reg->is_FloatRegister()) {\n+      \/\/ We have size encoding in OptoReg of stub->live()\n+      \/\/ After encoding, float\/neon\/sve register has only one slot in regmask\n+      \/\/ Decode it to get the actual size\n+      VMReg vm_reg_base = vm_reg->as_FloatRegister()->as_VMReg();\n+      int slots = decode_float_vector_register_size(opto_reg);\n+      RegisterData reg_data = { vm_reg_base, slots };\n+      index = registers.append(reg_data);\n+    } else if (vm_reg->is_PRegister()) {\n+      \/\/ PRegister has only one slot in regmask\n+      RegisterData reg_data = { vm_reg, 1 };\n+      index = registers.append(reg_data);\n+    } else {\n+      assert(false, \"Unknown register type\");\n+      ShouldNotReachHere();\n+    }\n+    prev_vm_reg = vm_reg;\n+  }\n+\n+  \/\/ Record registers that needs to be saved\/restored\n+  for (GrowableArrayIterator<RegisterData> it = registers.begin(); it != registers.end(); ++it) {\n+    RegisterData reg_data = *it;\n+    VMReg vm_reg = reg_data._reg;\n+    int slots = reg_data._slots;\n+    if (vm_reg->is_Register()) {\n+      assert(slots == 1 || slots == 2, \"Unexpected register save size\");\n+      _gp_regs += RegSet::of(vm_reg->as_Register());\n+    } else if (vm_reg->is_FloatRegister()) {\n+      if (slots == 1 || slots == 2) {\n+        _fp_regs += FloatRegSet::of(vm_reg->as_FloatRegister());\n+      } else if (slots == 4) {\n+        _neon_regs += FloatRegSet::of(vm_reg->as_FloatRegister());\n+      } else {\n+        assert(slots == Matcher::scalable_vector_reg_size(T_FLOAT), \"Unexpected register save size\");\n+        _sve_regs += FloatRegSet::of(vm_reg->as_FloatRegister());\n+      }\n+    } else {\n+      assert(vm_reg->is_PRegister() && slots == 1, \"Unknown register type\");\n+      _p_regs += PRegSet::of(vm_reg->as_PRegister());\n+    }\n+  }\n+\n+  \/\/ Remove C-ABI SOE registers, scratch regs and _ref register that will be updated\n+  if (stub->result() != noreg) {\n+    _gp_regs -= RegSet::range(r19, r30) + RegSet::of(r8, r9, stub->result());\n+  } else {\n+    _gp_regs -= RegSet::range(r19, r30) + RegSet::of(r8, r9);\n+  }\n+\n+  \/\/ Remove C-ABI SOE fp registers\n+  _fp_regs -= FloatRegSet::range(v8, v15);\n+}\n+\n+enum RC SaveLiveRegisters::rc_class(VMReg reg) {\n+  if (reg->is_reg()) {\n+    if (reg->is_Register()) {\n+      return rc_int;\n+    } else if (reg->is_FloatRegister()) {\n+      return rc_float;\n+    } else if (reg->is_PRegister()) {\n+      return rc_predicate;\n+    }\n+  }\n+  if (reg->is_stack()) {\n+    return rc_stack;\n+  }\n+  return rc_bad;\n+}\n+\n+bool SaveLiveRegisters::is_same_register(VMReg reg1, VMReg reg2) {\n+  if (reg1 == reg2) {\n+    return true;\n+  }\n+  if (rc_class(reg1) == rc_class(reg2)) {\n+    if (reg1->is_Register()) {\n+      return reg1->as_Register() == reg2->as_Register();\n+    } else if (reg1->is_FloatRegister()) {\n+      return reg1->as_FloatRegister() == reg2->as_FloatRegister();\n+    } else if (reg1->is_PRegister()) {\n+      return reg1->as_PRegister() == reg2->as_PRegister();\n+    }\n+  }\n+  return false;\n+}\n+\n+int SaveLiveRegisters::decode_float_vector_register_size(OptoReg::Name opto_reg) {\n+  switch (opto_reg & 3) {\n+    case 0:\n+      return 1;\n+    case 1:\n+      return 2;\n+    case 2:\n+      return 4;\n+    case 3:\n+      return Matcher::scalable_vector_reg_size(T_FLOAT);\n+    default:\n+      ShouldNotReachHere();\n+      return 0;\n+  }\n+}\n+\n+SaveLiveRegisters::SaveLiveRegisters(MacroAssembler* masm, BarrierStubC2* stub)\n+  : _masm(masm),\n+    _gp_regs(),\n+    _fp_regs(),\n+    _neon_regs(),\n+    _sve_regs(),\n+    _p_regs() {\n+\n+  \/\/ Figure out what registers to save\/restore\n+  initialize(stub);\n+\n+  \/\/ Save registers\n+  __ push(_gp_regs, sp);\n+  __ push_fp(_fp_regs, sp, MacroAssembler::PushPopFp);\n+  __ push_fp(_neon_regs, sp, MacroAssembler::PushPopNeon);\n+  __ push_fp(_sve_regs, sp, MacroAssembler::PushPopSVE);\n+  __ push_p(_p_regs, sp);\n+}\n+\n+SaveLiveRegisters::~SaveLiveRegisters() {\n+  \/\/ Restore registers\n+  __ pop_p(_p_regs, sp);\n+  __ pop_fp(_sve_regs, sp, MacroAssembler::PushPopSVE);\n+  __ pop_fp(_neon_regs, sp, MacroAssembler::PushPopNeon);\n+  __ pop_fp(_fp_regs, sp, MacroAssembler::PushPopFp);\n+\n+  \/\/ External runtime call may clobber ptrue reg\n+  __ reinitialize_ptrue();\n+\n+  __ pop(_gp_regs, sp);\n+}\n+\n+#endif \/\/ COMPILER2\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.cpp","additions":205,"deletions":0,"binary":false,"changes":205,"status":"modified"},{"patch":"@@ -33,0 +33,6 @@\n+#ifdef COMPILER2\n+#include \"opto\/optoreg.hpp\"\n+\n+class BarrierStubC2;\n+class Node;\n+#endif \/\/ COMPILER2\n@@ -135,0 +141,46 @@\n+\n+#ifdef COMPILER2\n+  OptoReg::Name encode_float_vector_register_size(const Node* node,\n+                                                  OptoReg::Name opto_reg);\n+  OptoReg::Name refine_register(const Node* node,\n+                                OptoReg::Name opto_reg);\n+#endif \/\/ COMPILER2\n+};\n+\n+#ifdef COMPILER2\n+\n+\/\/ This class saves and restores the registers that need to be preserved across\n+\/\/ the runtime call represented by a given C2 barrier stub. Use as follows:\n+\/\/ {\n+\/\/   SaveLiveRegisters save(masm, stub);\n+\/\/   ..\n+\/\/   __ blr(...);\n+\/\/   ..\n+\/\/ }\n+class SaveLiveRegisters {\n+private:\n+  struct RegisterData {\n+    VMReg _reg;\n+    int   _slots; \/\/ slots occupied once pushed into stack\n+\n+    \/\/ Used by GrowableArray::find()\n+    bool operator == (const RegisterData& other) {\n+      return _reg == other._reg;\n+    }\n+  };\n+\n+  MacroAssembler* const _masm;\n+  RegSet                _gp_regs;\n+  FloatRegSet           _fp_regs;\n+  FloatRegSet           _neon_regs;\n+  FloatRegSet           _sve_regs;\n+  PRegSet               _p_regs;\n+\n+  static enum RC rc_class(VMReg reg);\n+  static bool is_same_register(VMReg reg1, VMReg reg2);\n+  static int decode_float_vector_register_size(OptoReg::Name opto_reg);\n+\n+public:\n+  void initialize(BarrierStubC2* stub);\n+  SaveLiveRegisters(MacroAssembler* masm, BarrierStubC2* stub);\n+  ~SaveLiveRegisters();\n@@ -137,0 +189,2 @@\n+#endif \/\/ COMPILER2\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.hpp","additions":54,"deletions":0,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -1999,0 +1999,2 @@\n+  \/\/ Prevents stale data from being read after the bytecode is patched to the fast bytecode\n+  membar(MacroAssembler::LoadLoad);\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1602,5 +1602,1 @@\n-  mov(rscratch2, (address)&SharedRuntime::_partial_subtype_ctr);\n-  Address pst_counter_addr(rscratch2);\n-  ldr(rscratch1, pst_counter_addr);\n-  add(rscratch1, rscratch1, 1);\n-  str(rscratch1, pst_counter_addr);\n+  incrementw(ExternalAddress((address)&SharedRuntime::_partial_subtype_ctr));\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -89,4 +89,1 @@\n-    __ lea(rscratch2, ExternalAddress((address)&counter));\n-    __ ldrw(rscratch1, Address(rscratch2));\n-    __ addw(rscratch1, rscratch1, 1);\n-    __ strw(rscratch1, Address(rscratch2));\n+    __ incrementw(ExternalAddress((address)&counter));\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2487,1 +2487,3 @@\n-  __ load_unsigned_byte(tos_state, Address(cache, in_bytes(ResolvedFieldEntry::type_offset())));\n+  if (tos_state != noreg) {\n+    __ load_unsigned_byte(tos_state, Address(cache, in_bytes(ResolvedFieldEntry::type_offset())));\n+  }\n@@ -3330,6 +3332,2 @@\n-  __ push(r0);\n-  \/\/ R1: field offset, R2: TOS, R3: flags\n-  load_resolved_field_entry(r2, r2, r0, r1, r3);\n-  __ pop(r0);\n-  \/\/ Must prevent reordering of the following cp cache loads with bytecode load\n-  __ membar(MacroAssembler::LoadLoad);\n+  \/\/ R1: field offset, R2: field holder, R3: flags\n+  load_resolved_field_entry(r2, r2, noreg, r1, r3);\n@@ -3447,3 +3445,0 @@\n-  \/\/ Must prevent reordering of the following cp cache loads with bytecode load\n-  __ membar(MacroAssembler::LoadLoad);\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":5,"deletions":10,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -39,0 +39,3 @@\n+#ifdef COMPILER2\n+#include \"gc\/shared\/c2\/barrierSetC2.hpp\"\n+#endif \/\/ COMPILER2\n@@ -506,0 +509,277 @@\n+\n+#ifdef COMPILER2\n+\n+#ifdef _LP64\n+\n+OptoReg::Name BarrierSetAssembler::refine_register(const Node* node, OptoReg::Name opto_reg) {\n+  if (!OptoReg::is_reg(opto_reg)) {\n+    return OptoReg::Bad;\n+  }\n+\n+  const VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n+  if (vm_reg->is_XMMRegister()) {\n+    opto_reg &= ~15;\n+    switch (node->ideal_reg()) {\n+    case Op_VecX:\n+      opto_reg |= 2;\n+      break;\n+    case Op_VecY:\n+      opto_reg |= 4;\n+      break;\n+    case Op_VecZ:\n+      opto_reg |= 8;\n+      break;\n+    default:\n+      opto_reg |= 1;\n+      break;\n+    }\n+  }\n+\n+  return opto_reg;\n+}\n+\n+\/\/ We use the vec_spill_helper from the x86.ad file to avoid reinventing this wheel\n+extern void vec_spill_helper(C2_MacroAssembler *masm, bool is_load,\n+                            int stack_offset, int reg, uint ireg, outputStream* st);\n+\n+#undef __\n+#define __ _masm->\n+\n+int SaveLiveRegisters::xmm_compare_register_size(XMMRegisterData* left, XMMRegisterData* right) {\n+  if (left->_size == right->_size) {\n+    return 0;\n+  }\n+\n+  return (left->_size < right->_size) ? -1 : 1;\n+}\n+\n+int SaveLiveRegisters::xmm_slot_size(OptoReg::Name opto_reg) {\n+  \/\/ The low order 4 bytes denote what size of the XMM register is live\n+  return (opto_reg & 15) << 3;\n+}\n+\n+uint SaveLiveRegisters::xmm_ideal_reg_for_size(int reg_size) {\n+  switch (reg_size) {\n+  case 8:\n+    return Op_VecD;\n+  case 16:\n+    return Op_VecX;\n+  case 32:\n+    return Op_VecY;\n+  case 64:\n+    return Op_VecZ;\n+  default:\n+    fatal(\"Invalid register size %d\", reg_size);\n+    return 0;\n+  }\n+}\n+\n+bool SaveLiveRegisters::xmm_needs_vzeroupper() const {\n+  return _xmm_registers.is_nonempty() && _xmm_registers.at(0)._size > 16;\n+}\n+\n+void SaveLiveRegisters::xmm_register_save(const XMMRegisterData& reg_data) {\n+  const OptoReg::Name opto_reg = OptoReg::as_OptoReg(reg_data._reg->as_VMReg());\n+  const uint ideal_reg = xmm_ideal_reg_for_size(reg_data._size);\n+  _spill_offset -= reg_data._size;\n+  C2_MacroAssembler c2_masm(__ code());\n+  vec_spill_helper(&c2_masm, false \/* is_load *\/, _spill_offset, opto_reg, ideal_reg, tty);\n+}\n+\n+void SaveLiveRegisters::xmm_register_restore(const XMMRegisterData& reg_data) {\n+  const OptoReg::Name opto_reg = OptoReg::as_OptoReg(reg_data._reg->as_VMReg());\n+  const uint ideal_reg = xmm_ideal_reg_for_size(reg_data._size);\n+  C2_MacroAssembler c2_masm(__ code());\n+  vec_spill_helper(&c2_masm, true \/* is_load *\/, _spill_offset, opto_reg, ideal_reg, tty);\n+  _spill_offset += reg_data._size;\n+}\n+\n+void SaveLiveRegisters::gp_register_save(Register reg) {\n+  _spill_offset -= 8;\n+  __ movq(Address(rsp, _spill_offset), reg);\n+}\n+\n+void SaveLiveRegisters::opmask_register_save(KRegister reg) {\n+  _spill_offset -= 8;\n+  __ kmov(Address(rsp, _spill_offset), reg);\n+}\n+\n+void SaveLiveRegisters::gp_register_restore(Register reg) {\n+  __ movq(reg, Address(rsp, _spill_offset));\n+  _spill_offset += 8;\n+}\n+\n+void SaveLiveRegisters::opmask_register_restore(KRegister reg) {\n+  __ kmov(reg, Address(rsp, _spill_offset));\n+  _spill_offset += 8;\n+}\n+\n+void SaveLiveRegisters::initialize(BarrierStubC2* stub) {\n+  \/\/ Create mask of caller saved registers that need to\n+  \/\/ be saved\/restored if live\n+  RegMask caller_saved;\n+  caller_saved.Insert(OptoReg::as_OptoReg(rax->as_VMReg()));\n+  caller_saved.Insert(OptoReg::as_OptoReg(rcx->as_VMReg()));\n+  caller_saved.Insert(OptoReg::as_OptoReg(rdx->as_VMReg()));\n+  caller_saved.Insert(OptoReg::as_OptoReg(rsi->as_VMReg()));\n+  caller_saved.Insert(OptoReg::as_OptoReg(rdi->as_VMReg()));\n+  caller_saved.Insert(OptoReg::as_OptoReg(r8->as_VMReg()));\n+  caller_saved.Insert(OptoReg::as_OptoReg(r9->as_VMReg()));\n+  caller_saved.Insert(OptoReg::as_OptoReg(r10->as_VMReg()));\n+  caller_saved.Insert(OptoReg::as_OptoReg(r11->as_VMReg()));\n+\n+  if (stub->result() != noreg) {\n+    caller_saved.Remove(OptoReg::as_OptoReg(stub->result()->as_VMReg()));\n+  }\n+\n+  \/\/ Create mask of live registers\n+  RegMask live = stub->live();\n+\n+  int gp_spill_size = 0;\n+  int opmask_spill_size = 0;\n+  int xmm_spill_size = 0;\n+\n+  \/\/ Record registers that needs to be saved\/restored\n+  RegMaskIterator rmi(live);\n+  while (rmi.has_next()) {\n+    const OptoReg::Name opto_reg = rmi.next();\n+    const VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n+\n+    if (vm_reg->is_Register()) {\n+      if (caller_saved.Member(opto_reg)) {\n+        _gp_registers.append(vm_reg->as_Register());\n+        gp_spill_size += 8;\n+      }\n+    } else if (vm_reg->is_KRegister()) {\n+      \/\/ All opmask registers are caller saved, thus spill the ones\n+      \/\/ which are live.\n+      if (_opmask_registers.find(vm_reg->as_KRegister()) == -1) {\n+        _opmask_registers.append(vm_reg->as_KRegister());\n+        opmask_spill_size += 8;\n+      }\n+    } else if (vm_reg->is_XMMRegister()) {\n+      \/\/ We encode in the low order 4 bits of the opto_reg, how large part of the register is live\n+      const VMReg vm_reg_base = OptoReg::as_VMReg(opto_reg & ~15);\n+      const int reg_size = xmm_slot_size(opto_reg);\n+      const XMMRegisterData reg_data = { vm_reg_base->as_XMMRegister(), reg_size };\n+      const int reg_index = _xmm_registers.find(reg_data);\n+      if (reg_index == -1) {\n+        \/\/ Not previously appended\n+        _xmm_registers.append(reg_data);\n+        xmm_spill_size += reg_size;\n+      } else {\n+        \/\/ Previously appended, update size\n+        const int reg_size_prev = _xmm_registers.at(reg_index)._size;\n+        if (reg_size > reg_size_prev) {\n+          _xmm_registers.at_put(reg_index, reg_data);\n+          xmm_spill_size += reg_size - reg_size_prev;\n+        }\n+      }\n+    } else {\n+      fatal(\"Unexpected register type\");\n+    }\n+  }\n+\n+  \/\/ Sort by size, largest first\n+  _xmm_registers.sort(xmm_compare_register_size);\n+\n+  \/\/ On Windows, the caller reserves stack space for spilling register arguments\n+  const int arg_spill_size = frame::arg_reg_save_area_bytes;\n+\n+  \/\/ Stack pointer must be 16 bytes aligned for the call\n+  _spill_offset = _spill_size = align_up(xmm_spill_size + gp_spill_size + opmask_spill_size + arg_spill_size, 16);\n+}\n+\n+SaveLiveRegisters::SaveLiveRegisters(MacroAssembler* masm, BarrierStubC2* stub)\n+  : _masm(masm),\n+    _gp_registers(),\n+    _opmask_registers(),\n+    _xmm_registers(),\n+    _spill_size(0),\n+    _spill_offset(0) {\n+\n+  \/\/\n+  \/\/ Stack layout after registers have been spilled:\n+  \/\/\n+  \/\/ | ...            | original rsp, 16 bytes aligned\n+  \/\/ ------------------\n+  \/\/ | zmm0 high      |\n+  \/\/ | ...            |\n+  \/\/ | zmm0 low       | 16 bytes aligned\n+  \/\/ | ...            |\n+  \/\/ | ymm1 high      |\n+  \/\/ | ...            |\n+  \/\/ | ymm1 low       | 16 bytes aligned\n+  \/\/ | ...            |\n+  \/\/ | xmmN high      |\n+  \/\/ | ...            |\n+  \/\/ | xmmN low       | 8 bytes aligned\n+  \/\/ | reg0           | 8 bytes aligned\n+  \/\/ | reg1           |\n+  \/\/ | ...            |\n+  \/\/ | regN           | new rsp, if 16 bytes aligned\n+  \/\/ | <padding>      | else new rsp, 16 bytes aligned\n+  \/\/ ------------------\n+  \/\/\n+\n+  \/\/ Figure out what registers to save\/restore\n+  initialize(stub);\n+\n+  \/\/ Allocate stack space\n+  if (_spill_size > 0) {\n+    __ subptr(rsp, _spill_size);\n+  }\n+\n+  \/\/ Save XMM\/YMM\/ZMM registers\n+  for (int i = 0; i < _xmm_registers.length(); i++) {\n+    xmm_register_save(_xmm_registers.at(i));\n+  }\n+\n+  if (xmm_needs_vzeroupper()) {\n+    __ vzeroupper();\n+  }\n+\n+  \/\/ Save general purpose registers\n+  for (int i = 0; i < _gp_registers.length(); i++) {\n+    gp_register_save(_gp_registers.at(i));\n+  }\n+\n+  \/\/ Save opmask registers\n+  for (int i = 0; i < _opmask_registers.length(); i++) {\n+    opmask_register_save(_opmask_registers.at(i));\n+  }\n+}\n+\n+SaveLiveRegisters::~SaveLiveRegisters() {\n+  \/\/ Restore opmask registers\n+  for (int i = _opmask_registers.length() - 1; i >= 0; i--) {\n+    opmask_register_restore(_opmask_registers.at(i));\n+  }\n+\n+  \/\/ Restore general purpose registers\n+  for (int i = _gp_registers.length() - 1; i >= 0; i--) {\n+    gp_register_restore(_gp_registers.at(i));\n+  }\n+\n+  __ vzeroupper();\n+\n+  \/\/ Restore XMM\/YMM\/ZMM registers\n+  for (int i = _xmm_registers.length() - 1; i >= 0; i--) {\n+    xmm_register_restore(_xmm_registers.at(i));\n+  }\n+\n+  \/\/ Free stack space\n+  if (_spill_size > 0) {\n+    __ addptr(rsp, _spill_size);\n+  }\n+}\n+\n+#else \/\/ !_LP64\n+\n+OptoReg::Name BarrierSetAssembler::refine_register(const Node* node, OptoReg::Name opto_reg) {\n+  Unimplemented(); \/\/ This must be implemented to support late barrier expansion.\n+}\n+\n+#endif \/\/ _LP64\n+\n+#endif \/\/ COMPILER2\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetAssembler_x86.cpp","additions":280,"deletions":0,"binary":false,"changes":280,"status":"modified"},{"patch":"@@ -31,0 +31,2 @@\n+#ifdef COMPILER2\n+#include \"opto\/optoreg.hpp\"\n@@ -32,0 +34,3 @@\n+class BarrierStubC2;\n+class Node;\n+#endif \/\/ COMPILER2\n@@ -112,0 +117,53 @@\n+\n+#ifdef COMPILER2\n+  OptoReg::Name refine_register(const Node* node,\n+                                OptoReg::Name opto_reg);\n+#endif \/\/ COMPILER2\n+};\n+\n+#ifdef COMPILER2\n+\n+#ifdef _LP64\n+\n+\/\/ This class saves and restores the registers that need to be preserved across\n+\/\/ the runtime call represented by a given C2 barrier stub. Use as follows:\n+\/\/ {\n+\/\/   SaveLiveRegisters save(masm, stub);\n+\/\/   ..\n+\/\/   __ call(RuntimeAddress(...);\n+\/\/   ..\n+\/\/ }\n+class SaveLiveRegisters {\n+private:\n+  struct XMMRegisterData {\n+    XMMRegister _reg;\n+    int         _size;\n+\n+    \/\/ Used by GrowableArray::find()\n+    bool operator == (const XMMRegisterData& other) {\n+      return _reg == other._reg;\n+    }\n+  };\n+\n+  MacroAssembler* const          _masm;\n+  GrowableArray<Register>        _gp_registers;\n+  GrowableArray<KRegister>       _opmask_registers;\n+  GrowableArray<XMMRegisterData> _xmm_registers;\n+  int                            _spill_size;\n+  int                            _spill_offset;\n+\n+  static int xmm_compare_register_size(XMMRegisterData* left, XMMRegisterData* right);\n+  static int xmm_slot_size(OptoReg::Name opto_reg);\n+  static uint xmm_ideal_reg_for_size(int reg_size);\n+  bool xmm_needs_vzeroupper() const;\n+  void xmm_register_save(const XMMRegisterData& reg_data);\n+  void xmm_register_restore(const XMMRegisterData& reg_data);\n+  void gp_register_save(Register reg);\n+  void opmask_register_save(KRegister reg);\n+  void gp_register_restore(Register reg);\n+  void opmask_register_restore(KRegister reg);\n+  void initialize(BarrierStubC2* stub);\n+\n+public:\n+  SaveLiveRegisters(MacroAssembler* masm, BarrierStubC2* stub);\n+  ~SaveLiveRegisters();\n@@ -114,0 +172,4 @@\n+#endif \/\/ _LP64\n+\n+#endif \/\/ COMPILER2\n+\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetAssembler_x86.hpp","additions":62,"deletions":0,"binary":false,"changes":62,"status":"modified"},{"patch":"@@ -10285,1 +10285,1 @@\n-    assert(0 == Type::cmp(mask1->bottom_type(), mask2->bottom_type()), \"\");\n+    assert(Type::equals(mask1->bottom_type(), mask2->bottom_type()), \"Mask types must be equal\");\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -113,0 +113,5 @@\n+\/\/ Cast from int value to narrow type\n+#define CHECKED_CAST(result, T, thing)      \\\n+  result = static_cast<T>(thing); \\\n+  assert(static_cast<int>(result) == thing, \"failed: %d != %d\", static_cast<int>(result), thing);\n+\n@@ -124,1 +129,2 @@\n-  uint total_size;\n+  uint total_nm_size;\n+  uint total_immut_size;\n@@ -129,2 +135,2 @@\n-  uint scopes_data_size;\n-  uint scopes_pcs_size;\n+  uint oops_size;\n+  uint metadata_size;\n@@ -132,1 +138,3 @@\n-  uint handler_table_size;\n+  uint handler_table_size;\n+  uint scopes_pcs_size;\n+  uint scopes_data_size;\n@@ -138,2 +146,0 @@\n-  uint oops_size;\n-  uint metadata_size;\n@@ -143,1 +149,2 @@\n-    total_size          += nm->size();\n+    total_nm_size       += nm->size();\n+    total_immut_size    += nm->immutable_data_size();\n@@ -163,1 +170,5 @@\n-    if (total_size != 0)          tty->print_cr(\" total in heap  = %u (100%%)\", total_size);\n+    uint total_size = total_nm_size + total_immut_size;\n+    if (total_nm_size != 0) {\n+      tty->print_cr(\" total size      = %u (100%%)\", total_size);\n+      tty->print_cr(\" in CodeCache    = %u (%f%%)\", total_nm_size, (total_nm_size * 100.0f)\/total_size);\n+    }\n@@ -165,12 +176,21 @@\n-    if (nmethod_count != 0)       tty->print_cr(\" header         = %u (%f%%)\", header_size, (header_size * 100.0f)\/total_size);\n-    if (relocation_size != 0)     tty->print_cr(\" relocation     = %u (%f%%)\", relocation_size, (relocation_size * 100.0f)\/total_size);\n-    if (consts_size != 0)         tty->print_cr(\" constants      = %u (%f%%)\", consts_size, (consts_size * 100.0f)\/total_size);\n-    if (insts_size != 0)          tty->print_cr(\" main code      = %u (%f%%)\", insts_size, (insts_size * 100.0f)\/total_size);\n-    if (stub_size != 0)           tty->print_cr(\" stub code      = %u (%f%%)\", stub_size, (stub_size * 100.0f)\/total_size);\n-    if (oops_size != 0)           tty->print_cr(\" oops           = %u (%f%%)\", oops_size, (oops_size * 100.0f)\/total_size);\n-    if (metadata_size != 0)       tty->print_cr(\" metadata       = %u (%f%%)\", metadata_size, (metadata_size * 100.0f)\/total_size);\n-    if (scopes_data_size != 0)    tty->print_cr(\" scopes data    = %u (%f%%)\", scopes_data_size, (scopes_data_size * 100.0f)\/total_size);\n-    if (scopes_pcs_size != 0)     tty->print_cr(\" scopes pcs     = %u (%f%%)\", scopes_pcs_size, (scopes_pcs_size * 100.0f)\/total_size);\n-    if (dependencies_size != 0)   tty->print_cr(\" dependencies   = %u (%f%%)\", dependencies_size, (dependencies_size * 100.0f)\/total_size);\n-    if (handler_table_size != 0)  tty->print_cr(\" handler table  = %u (%f%%)\", handler_table_size, (handler_table_size * 100.0f)\/total_size);\n-    if (nul_chk_table_size != 0)  tty->print_cr(\" nul chk table  = %u (%f%%)\", nul_chk_table_size, (nul_chk_table_size * 100.0f)\/total_size);\n+    if (nmethod_count != 0) {\n+      tty->print_cr(\"   header        = %u (%f%%)\", header_size, (header_size * 100.0f)\/total_nm_size);\n+    }\n+    if (relocation_size != 0) {\n+      tty->print_cr(\"   relocation    = %u (%f%%)\", relocation_size, (relocation_size * 100.0f)\/total_nm_size);\n+    }\n+    if (consts_size != 0) {\n+      tty->print_cr(\"   constants     = %u (%f%%)\", consts_size, (consts_size * 100.0f)\/total_nm_size);\n+    }\n+    if (insts_size != 0) {\n+      tty->print_cr(\"   main code     = %u (%f%%)\", insts_size, (insts_size * 100.0f)\/total_nm_size);\n+    }\n+    if (stub_size != 0) {\n+      tty->print_cr(\"   stub code     = %u (%f%%)\", stub_size, (stub_size * 100.0f)\/total_nm_size);\n+    }\n+    if (oops_size != 0) {\n+      tty->print_cr(\"   oops          = %u (%f%%)\", oops_size, (oops_size * 100.0f)\/total_nm_size);\n+    }\n+    if (metadata_size != 0) {\n+      tty->print_cr(\"   metadata      = %u (%f%%)\", metadata_size, (metadata_size * 100.0f)\/total_nm_size);\n+    }\n@@ -178,2 +198,26 @@\n-    if (speculations_size != 0)   tty->print_cr(\" speculations   = %u (%f%%)\", speculations_size, (speculations_size * 100.0f)\/total_size);\n-    if (jvmci_data_size != 0)     tty->print_cr(\" JVMCI data     = %u (%f%%)\", jvmci_data_size, (jvmci_data_size * 100.0f)\/total_size);\n+    if (jvmci_data_size != 0) {\n+      tty->print_cr(\"   JVMCI data    = %u (%f%%)\", jvmci_data_size, (jvmci_data_size * 100.0f)\/total_nm_size);\n+    }\n+#endif\n+    if (total_immut_size != 0) {\n+      tty->print_cr(\" immutable data  = %u (%f%%)\", total_immut_size, (total_immut_size * 100.0f)\/total_size);\n+    }\n+    if (dependencies_size != 0) {\n+      tty->print_cr(\"   dependencies  = %u (%f%%)\", dependencies_size, (dependencies_size * 100.0f)\/total_immut_size);\n+    }\n+    if (nul_chk_table_size != 0) {\n+      tty->print_cr(\"   nul chk table = %u (%f%%)\", nul_chk_table_size, (nul_chk_table_size * 100.0f)\/total_immut_size);\n+    }\n+    if (handler_table_size != 0) {\n+      tty->print_cr(\"   handler table = %u (%f%%)\", handler_table_size, (handler_table_size * 100.0f)\/total_immut_size);\n+    }\n+    if (scopes_pcs_size != 0) {\n+      tty->print_cr(\"   scopes pcs    = %u (%f%%)\", scopes_pcs_size, (scopes_pcs_size * 100.0f)\/total_immut_size);\n+    }\n+    if (scopes_data_size != 0) {\n+      tty->print_cr(\"   scopes data   = %u (%f%%)\", scopes_data_size, (scopes_data_size * 100.0f)\/total_immut_size);\n+    }\n+#if INCLUDE_JVMCI\n+    if (speculations_size != 0) {\n+      tty->print_cr(\"   speculations  = %u (%f%%)\", speculations_size, (speculations_size * 100.0f)\/total_immut_size);\n+    }\n@@ -211,1 +255,1 @@\n-  uint pc_desc_resets;   \/\/ number of resets (= number of caches)\n+  uint pc_desc_init;     \/\/ number of initialization of cache (= number of caches)\n@@ -226,1 +270,1 @@\n-                  pc_desc_resets,\n+                  pc_desc_init,\n@@ -344,1 +388,1 @@\n-  if (!approximate)\n+  if (!approximate) {\n@@ -346,1 +390,1 @@\n-  else\n+  } else {\n@@ -348,0 +392,1 @@\n+  }\n@@ -350,9 +395,6 @@\n-void PcDescCache::reset_to(PcDesc* initial_pc_desc) {\n-  if (initial_pc_desc == nullptr) {\n-    _pc_descs[0] = nullptr; \/\/ native method; no PcDescs at all\n-    return;\n-  }\n-  NOT_PRODUCT(++pc_nmethod_stats.pc_desc_resets);\n-  \/\/ reset the cache by filling it with benign (non-null) values\n-  assert(initial_pc_desc->pc_offset() < 0, \"must be sentinel\");\n-  for (int i = 0; i < cache_size; i++)\n+void PcDescCache::init_to(PcDesc* initial_pc_desc) {\n+  NOT_PRODUCT(++pc_nmethod_stats.pc_desc_init);\n+  \/\/ initialize the cache by filling it with benign (non-null) values\n+  assert(initial_pc_desc != nullptr && initial_pc_desc->pc_offset() == PcDesc::lower_offset_limit,\n+         \"must start with a sentinel\");\n+  for (int i = 0; i < cache_size; i++) {\n@@ -360,0 +402,1 @@\n+  }\n@@ -363,3 +406,0 @@\n-  NOT_PRODUCT(++pc_nmethod_stats.pc_desc_queries);\n-  NOT_PRODUCT(if (approximate) ++pc_nmethod_stats.pc_desc_approx);\n-\n@@ -378,2 +418,4 @@\n-  if (res == nullptr) return nullptr;  \/\/ native method; no PcDescs at all\n-  if (match_desc(res, pc_offset, approximate)) {\n+  assert(res != nullptr, \"PcDesc cache should be initialized already\");\n+\n+  \/\/ Approximate only here since PcDescContainer::find_pc_desc() checked for exact case.\n+  if (approximate && match_desc(res, pc_offset, approximate)) {\n@@ -399,1 +441,0 @@\n-  MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXWrite, Thread::current());)\n@@ -1118,0 +1159,1 @@\n+  int nmethod_size = CodeBlob::allocation_size(code_buffer, sizeof(nmethod));\n@@ -1119,1 +1161,3 @@\n-  int jvmci_data_size = compiler->is_jvmci() ? jvmci_data->size() : 0;\n+    if (compiler->is_jvmci()) {\n+      nmethod_size += align_up(jvmci_data->size(), oopSize);\n+    }\n@@ -1121,3 +1165,3 @@\n-  int nmethod_size =\n-    CodeBlob::allocation_size(code_buffer, sizeof(nmethod))\n-    + adjust_pcs_size(debug_info->pcs_size())\n+\n+  int immutable_data_size =\n+      adjust_pcs_size(debug_info->pcs_size())\n@@ -1129,1 +1173,0 @@\n-    + align_up(jvmci_data_size                   , oopSize)\n@@ -1132,0 +1175,10 @@\n+\n+  \/\/ First, allocate space for immutable data in C heap.\n+  address immutable_data = nullptr;\n+  if (immutable_data_size > 0) {\n+    immutable_data = (address)os::malloc(immutable_data_size, mtCode);\n+    if (immutable_data == nullptr) {\n+      vm_exit_out_of_memory(immutable_data_size, OOM_MALLOC_ERROR, \"nmethod: no space for immutable data\");\n+      return nullptr;\n+    }\n+  }\n@@ -1136,7 +1189,4 @@\n-    nmethod(method(), compiler->type(), nmethod_size, compile_id, entry_bci, offsets,\n-            orig_pc_offset, debug_info, dependencies, code_buffer, frame_size,\n-            oop_maps,\n-            handler_table,\n-            nul_chk_table,\n-            compiler,\n-            comp_level\n+    nmethod(method(), compiler->type(), nmethod_size, immutable_data_size,\n+            compile_id, entry_bci, immutable_data, offsets, orig_pc_offset,\n+            debug_info, dependencies, code_buffer, frame_size, oop_maps,\n+            handler_table, nul_chk_table, compiler, comp_level\n@@ -1213,2 +1263,6 @@\n-  _entry_offset          = checked_cast<uint16_t>(offsets->value(CodeOffsets::Entry));\n-  _verified_entry_offset = checked_cast<uint16_t>(offsets->value(CodeOffsets::Verified_Entry));\n+  _stub_offset = content_offset() + code_buffer->total_offset_of(code_buffer->stubs());\n+\n+  CHECKED_CAST(_entry_offset,              uint16_t, (offsets->value(CodeOffsets::Entry)));\n+  CHECKED_CAST(_verified_entry_offset,     uint16_t, (offsets->value(CodeOffsets::Verified_Entry)));\n+  CHECKED_CAST(_skipped_instructions_size, uint16_t, (code_buffer->total_skipped_instructions_size()));\n+\n@@ -1218,3 +1272,0 @@\n-  _stub_offset           = content_offset() + code_buffer->total_offset_of(code_buffer->stubs());\n-\n-  _skipped_instructions_size = checked_cast<uint16_t>(code_buffer->total_skipped_instructions_size());\n@@ -1262,0 +1313,1 @@\n+    _pc_desc_container       = nullptr;\n@@ -1281,6 +1333,2 @@\n-    _metadata_offset         = checked_cast<uint16_t>(align_up(code_buffer->total_oop_size(), oopSize));\n-    _dependencies_offset     = checked_cast<uint16_t>(_metadata_offset + align_up(code_buffer->total_metadata_size(), wordSize));\n-    _scopes_pcs_offset       = _dependencies_offset;\n-    _scopes_data_offset      = _scopes_pcs_offset;\n-    _handler_table_offset    = _scopes_data_offset;\n-    _nul_chk_table_offset    = _handler_table_offset;\n+    CHECKED_CAST(_metadata_offset, uint16_t, (align_up(code_buffer->total_oop_size(), oopSize)));\n+    int data_end_offset = _metadata_offset + align_up(code_buffer->total_metadata_size(), wordSize);\n@@ -1288,5 +1336,3 @@\n-    _speculations_offset     = _nul_chk_table_offset;\n-    _jvmci_data_offset       = _speculations_offset;\n-    DEBUG_ONLY( int data_end_offset = _jvmci_data_offset; )\n-#else\n-    DEBUG_ONLY( int data_end_offset = _nul_chk_table_offset; )\n+    \/\/ jvmci_data_size is 0 in native wrapper but we need to set offset\n+    \/\/ to correctly calculate metadata_end address\n+    CHECKED_CAST(_jvmci_data_offset, uint16_t, data_end_offset);\n@@ -1296,1 +1342,10 @@\n-    _pc_desc_container.reset_to(nullptr);\n+    \/\/ native wrapper does not have read-only data but we need unique not null address\n+    _immutable_data          = data_end();\n+    _immutable_data_size     = 0;\n+    _nul_chk_table_offset    = 0;\n+    _handler_table_offset    = 0;\n+    _scopes_pcs_offset       = 0;\n+    _scopes_data_offset      = 0;\n+#if INCLUDE_JVMCI\n+    _speculations_offset     = 0;\n+#endif\n@@ -1364,0 +1419,1 @@\n+  int immutable_data_size,\n@@ -1366,0 +1422,1 @@\n+  address immutable_data,\n@@ -1442,1 +1499,5 @@\n-      _unwind_handler_offset = code_offset() + offsets->value(CodeOffsets::UnwindHandler);\n+      \/\/ C1 generates UnwindHandler at the end of instructions section.\n+      \/\/ Calculate positive offset as distance between the start of stubs section\n+      \/\/ (which is also the end of instructions section) and the start of the handler.\n+      int unwind_handler_offset = code_offset() + offsets->value(CodeOffsets::UnwindHandler);\n+      CHECKED_CAST(_unwind_handler_offset, int16_t, (_stub_offset - unwind_handler_offset));\n@@ -1446,6 +1507,3 @@\n-    _metadata_offset      = checked_cast<uint16_t>(align_up(code_buffer->total_oop_size(), oopSize));\n-    _dependencies_offset  = checked_cast<uint16_t>(_metadata_offset     + align_up(code_buffer->total_metadata_size(), wordSize));\n-    _scopes_pcs_offset    = checked_cast<uint16_t>(_dependencies_offset + align_up((int)dependencies->size_in_bytes(), oopSize));\n-    _scopes_data_offset   = _scopes_pcs_offset    + adjust_pcs_size(debug_info->pcs_size());\n-    _handler_table_offset = _scopes_data_offset   + align_up(debug_info->data_size       (), oopSize);\n-    _nul_chk_table_offset = _handler_table_offset + align_up(handler_table->size_in_bytes(), oopSize);\n+    CHECKED_CAST(_metadata_offset, uint16_t, (align_up(code_buffer->total_oop_size(), oopSize)));\n+    int metadata_end_offset = _metadata_offset + align_up(code_buffer->total_metadata_size(), wordSize);\n+\n@@ -1453,2 +1511,1 @@\n-    _speculations_offset  = _nul_chk_table_offset + align_up(nul_chk_table->size_in_bytes(), oopSize);\n-    _jvmci_data_offset    = _speculations_offset  + align_up(speculations_len, oopSize);\n+    CHECKED_CAST(_jvmci_data_offset, uint16_t, metadata_end_offset);\n@@ -1456,1 +1513,1 @@\n-    DEBUG_ONLY( int data_end_offset = _jvmci_data_offset    + align_up(jvmci_data_size, oopSize); )\n+    DEBUG_ONLY( int data_end_offset = _jvmci_data_offset  + align_up(jvmci_data_size, oopSize); )\n@@ -1458,1 +1515,1 @@\n-    DEBUG_ONLY( int data_end_offset = _nul_chk_table_offset + align_up(nul_chk_table->size_in_bytes(), oopSize); )\n+    DEBUG_ONLY( int data_end_offset = metadata_end_offset; )\n@@ -1463,1 +1520,15 @@\n-    assert((data_offset() + data_end_offset) <= nmethod_size, \"wrong nmethod's size: %d < %d\", nmethod_size, (data_offset() + data_end_offset));\n+    assert((data_offset() + data_end_offset) <= nmethod_size, \"wrong nmethod's size: %d > %d\",\n+           (data_offset() + data_end_offset), nmethod_size);\n+\n+    _immutable_data_size  = immutable_data_size;\n+    if (immutable_data_size > 0) {\n+      assert(immutable_data != nullptr, \"required\");\n+      _immutable_data     = immutable_data;\n+    } else {\n+      \/\/ We need unique not null address\n+      _immutable_data     = data_end();\n+    }\n+    CHECKED_CAST(_nul_chk_table_offset, uint16_t, (align_up((int)dependencies->size_in_bytes(), oopSize)));\n+    CHECKED_CAST(_handler_table_offset, uint16_t, (_nul_chk_table_offset + align_up(nul_chk_table->size_in_bytes(), oopSize)));\n+    _scopes_pcs_offset    = _handler_table_offset + align_up(handler_table->size_in_bytes(), oopSize);\n+    _scopes_data_offset   = _scopes_pcs_offset    + adjust_pcs_size(debug_info->pcs_size());\n@@ -1465,2 +1536,8 @@\n-    \/\/ after _scopes_pcs_offset is set\n-    _pc_desc_container.reset_to(scopes_pcs_begin());\n+#if INCLUDE_JVMCI\n+    _speculations_offset  = _scopes_data_offset   + align_up(debug_info->data_size(), oopSize);\n+    DEBUG_ONLY( int immutable_data_end_offset = _speculations_offset  + align_up(speculations_len, oopSize); )\n+#else\n+    DEBUG_ONLY( int immutable_data_end_offset = _scopes_data_offset + align_up(debug_info->data_size(), oopSize); )\n+#endif\n+    assert(immutable_data_end_offset <= immutable_data_size, \"wrong read-only data size: %d > %d\",\n+           immutable_data_end_offset, immutable_data_size);\n@@ -1468,0 +1545,1 @@\n+    \/\/ Copy code and relocation info\n@@ -1469,1 +1547,1 @@\n-    \/\/ Copy contents of ScopeDescRecorder to nmethod\n+    \/\/ Copy oops and metadata\n@@ -1471,1 +1549,5 @@\n-    debug_info->copy_to(this);\n+    \/\/ Copy PcDesc and ScopeDesc data\n+    debug_info->copy_to(this);\n+\n+    \/\/ Create cache after PcDesc data is copied - it will be used to initialize cache\n+    _pc_desc_container = new PcDescContainer(scopes_pcs_begin());\n@@ -2064,1 +2146,3 @@\n-\n+  if (_pc_desc_container != nullptr) {\n+    delete _pc_desc_container;\n+  }\n@@ -2067,0 +2151,4 @@\n+  if (_immutable_data != data_end()) {\n+    os::free(_immutable_data);\n+    _immutable_data = data_end(); \/\/ Valid not null address\n+  }\n@@ -2639,4 +2727,1 @@\n-static PcDesc* linear_search(const PcDescSearch& search, int pc_offset, bool approximate) {\n-  PcDesc* lower = search.scopes_pcs_begin();\n-  PcDesc* upper = search.scopes_pcs_end();\n-  lower += 1; \/\/ exclude initial sentinel\n+static PcDesc* linear_search(int pc_offset, bool approximate, PcDesc* lower, PcDesc* upper) {\n@@ -2644,1 +2729,4 @@\n-  for (PcDesc* p = lower; p < upper; p++) {\n+  assert(lower != nullptr && lower->pc_offset() == PcDesc::lower_offset_limit,\n+         \"must start with a sentinel\");\n+  \/\/ lower + 1 to exclude initial sentinel\n+  for (PcDesc* p = lower + 1; p < upper; p++) {\n@@ -2647,1 +2735,1 @@\n-      if (res == nullptr)\n+      if (res == nullptr) {\n@@ -2649,1 +2737,1 @@\n-      else\n+      } else {\n@@ -2651,0 +2739,1 @@\n+      }\n@@ -2658,0 +2747,19 @@\n+#ifndef PRODUCT\n+\/\/ Version of method to collect statistic\n+PcDesc* PcDescContainer::find_pc_desc(address pc, bool approximate, address code_begin,\n+                                      PcDesc* lower, PcDesc* upper) {\n+  ++pc_nmethod_stats.pc_desc_queries;\n+  if (approximate) ++pc_nmethod_stats.pc_desc_approx;\n+\n+  PcDesc* desc = _pc_desc_cache.last_pc_desc();\n+  assert(desc != nullptr, \"PcDesc cache should be initialized already\");\n+  if (desc->pc_offset() == (pc - code_begin)) {\n+    \/\/ Cached value matched\n+    ++pc_nmethod_stats.pc_desc_tests;\n+    ++pc_nmethod_stats.pc_desc_repeats;\n+    return desc;\n+  }\n+  return find_pc_desc_internal(pc, approximate, code_begin, lower, upper);\n+}\n+#endif\n+\n@@ -2659,4 +2767,4 @@\n-PcDesc* PcDescContainer::find_pc_desc_internal(address pc, bool approximate, const PcDescSearch& search) {\n-  address base_address = search.code_begin();\n-  if ((pc < base_address) ||\n-      (pc - base_address) >= (ptrdiff_t) PcDesc::upper_offset_limit) {\n+PcDesc* PcDescContainer::find_pc_desc_internal(address pc, bool approximate, address code_begin,\n+                                               PcDesc* lower_incl, PcDesc* upper_incl) {\n+  if ((pc < code_begin) ||\n+      (pc - code_begin) >= (ptrdiff_t) PcDesc::upper_offset_limit) {\n@@ -2665,1 +2773,1 @@\n-  int pc_offset = (int) (pc - base_address);\n+  int pc_offset = (int) (pc - code_begin);\n@@ -2671,1 +2779,1 @@\n-    assert(res == linear_search(search, pc_offset, approximate), \"cache ok\");\n+    assert(res == linear_search(pc_offset, approximate, lower_incl, upper_incl), \"cache ok\");\n@@ -2679,4 +2787,3 @@\n-  PcDesc* lower = search.scopes_pcs_begin();\n-  PcDesc* upper = search.scopes_pcs_end();\n-  upper -= 1; \/\/ exclude final sentinel\n-  if (lower >= upper)  return nullptr;  \/\/ native method; no PcDescs at all\n+  PcDesc* lower = lower_incl;     \/\/ this is initial sentinel\n+  PcDesc* upper = upper_incl - 1; \/\/ exclude final sentinel\n+  if (lower >= upper)  return nullptr;  \/\/ no PcDescs at all\n@@ -2731,1 +2838,1 @@\n-    assert(upper == linear_search(search, pc_offset, approximate), \"search ok\");\n+    assert(upper == linear_search(pc_offset, approximate, lower_incl, upper_incl), \"search mismatch\");\n@@ -2739,1 +2846,1 @@\n-    assert(nullptr == linear_search(search, pc_offset, approximate), \"search ok\");\n+    assert(nullptr == linear_search(pc_offset, approximate, lower_incl, upper_incl), \"search mismatch\");\n@@ -3003,8 +3110,10 @@\n-  if (scopes_data_size  () > 0) st->print_cr(\" scopes data    [\" INTPTR_FORMAT \",\" INTPTR_FORMAT \"] = %d\",\n-                                             p2i(scopes_data_begin()),\n-                                             p2i(scopes_data_end()),\n-                                             scopes_data_size());\n-  if (scopes_pcs_size   () > 0) st->print_cr(\" scopes pcs     [\" INTPTR_FORMAT \",\" INTPTR_FORMAT \"] = %d\",\n-                                             p2i(scopes_pcs_begin()),\n-                                             p2i(scopes_pcs_end()),\n-                                             scopes_pcs_size());\n+#if INCLUDE_JVMCI\n+  if (jvmci_data_size   () > 0) st->print_cr(\" JVMCI data     [\" INTPTR_FORMAT \",\" INTPTR_FORMAT \"] = %d\",\n+                                             p2i(jvmci_data_begin()),\n+                                             p2i(jvmci_data_end()),\n+                                             jvmci_data_size());\n+#endif\n+  if (immutable_data_size() > 0) st->print_cr(\" immutable data [\" INTPTR_FORMAT \",\" INTPTR_FORMAT \"] = %d\",\n+                                             p2i(immutable_data_begin()),\n+                                             p2i(immutable_data_end()),\n+                                             immutable_data_size());\n@@ -3015,4 +3124,0 @@\n-  if (handler_table_size() > 0) st->print_cr(\" handler table  [\" INTPTR_FORMAT \",\" INTPTR_FORMAT \"] = %d\",\n-                                             p2i(handler_table_begin()),\n-                                             p2i(handler_table_end()),\n-                                             handler_table_size());\n@@ -3023,0 +3128,12 @@\n+  if (handler_table_size() > 0) st->print_cr(\" handler table  [\" INTPTR_FORMAT \",\" INTPTR_FORMAT \"] = %d\",\n+                                             p2i(handler_table_begin()),\n+                                             p2i(handler_table_end()),\n+                                             handler_table_size());\n+  if (scopes_pcs_size   () > 0) st->print_cr(\" scopes pcs     [\" INTPTR_FORMAT \",\" INTPTR_FORMAT \"] = %d\",\n+                                             p2i(scopes_pcs_begin()),\n+                                             p2i(scopes_pcs_end()),\n+                                             scopes_pcs_size());\n+  if (scopes_data_size  () > 0) st->print_cr(\" scopes data    [\" INTPTR_FORMAT \",\" INTPTR_FORMAT \"] = %d\",\n+                                             p2i(scopes_data_begin()),\n+                                             p2i(scopes_data_end()),\n+                                             scopes_data_size());\n@@ -3028,4 +3145,0 @@\n-  if (jvmci_data_size   () > 0) st->print_cr(\" JVMCI data     [\" INTPTR_FORMAT \",\" INTPTR_FORMAT \"] = %d\",\n-                                             p2i(jvmci_data_begin()),\n-                                             p2i(jvmci_data_end()),\n-                                             jvmci_data_size());\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":235,"deletions":122,"binary":false,"changes":357,"status":"modified"},{"patch":"@@ -105,1 +105,1 @@\n-  void    reset_to(PcDesc* initial_pc_desc);\n+  void    init_to(PcDesc* initial_pc_desc);\n@@ -111,17 +111,1 @@\n-class PcDescSearch {\n-private:\n-  address _code_begin;\n-  PcDesc* _lower;\n-  PcDesc* _upper;\n-public:\n-  PcDescSearch(address code, PcDesc* lower, PcDesc* upper) :\n-    _code_begin(code), _lower(lower), _upper(upper)\n-  {\n-  }\n-\n-  address code_begin() const { return _code_begin; }\n-  PcDesc* scopes_pcs_begin() const { return _lower; }\n-  PcDesc* scopes_pcs_end() const { return _upper; }\n-};\n-\n-class PcDescContainer {\n+class PcDescContainer : public CHeapObj<mtCode> {\n@@ -131,1 +115,1 @@\n-  PcDescContainer() {}\n+  PcDescContainer(PcDesc* initial_pc_desc) { _pc_desc_cache.init_to(initial_pc_desc); }\n@@ -133,2 +117,2 @@\n-  PcDesc* find_pc_desc_internal(address pc, bool approximate, const PcDescSearch& search);\n-  void    reset_to(PcDesc* initial_pc_desc) { _pc_desc_cache.reset_to(initial_pc_desc); }\n+  PcDesc* find_pc_desc_internal(address pc, bool approximate, address code_begin,\n+                                PcDesc* lower, PcDesc* upper);\n@@ -136,2 +120,3 @@\n-  PcDesc* find_pc_desc(address pc, bool approximate, const PcDescSearch& search) {\n-    address base_address = search.code_begin();\n+  PcDesc* find_pc_desc(address pc, bool approximate, address code_begin, PcDesc* lower, PcDesc* upper)\n+#ifdef PRODUCT\n+  {\n@@ -139,1 +124,3 @@\n-    if (desc != nullptr && desc->pc_offset() == pc - base_address) {\n+    assert(desc != nullptr, \"PcDesc cache should be initialized already\");\n+    if (desc->pc_offset() == (pc - code_begin)) {\n+      \/\/ Cached value matched\n@@ -142,1 +129,1 @@\n-    return find_pc_desc_internal(pc, approximate, search);\n+    return find_pc_desc_internal(pc, approximate, code_begin, lower, upper);\n@@ -144,0 +131,2 @@\n+#endif\n+  ;\n@@ -210,1 +199,4 @@\n-  PcDescContainer _pc_desc_container;\n+  \/\/ nmethod's read-only data\n+  address _immutable_data;\n+\n+  PcDescContainer* _pc_desc_container;\n@@ -230,0 +222,1 @@\n+  int      _immutable_data_size;\n@@ -243,3 +236,4 @@\n-  \/\/ Offset of the unwind handler if it exists\n-  int _unwind_handler_offset;\n-\n+  \/\/ Offset (from insts_end) of the unwind handler if it exists\n+  int16_t  _unwind_handler_offset;\n+  \/\/ Number of arguments passed on the stack\n+  uint16_t _num_stack_arg_slots;\n@@ -248,0 +242,1 @@\n+  \/\/ Offsets in mutable data section\n@@ -250,2 +245,9 @@\n-  uint16_t _dependencies_offset;\n-  uint16_t _scopes_pcs_offset;\n+#if INCLUDE_JVMCI\n+  uint16_t _jvmci_data_offset;\n+#endif\n+\n+  \/\/ Offset in immutable data section\n+  \/\/ _dependencies_offset == 0\n+  uint16_t _nul_chk_table_offset;\n+  uint16_t _handler_table_offset; \/\/ This table could be big in C1 code\n+  int      _scopes_pcs_offset;\n@@ -253,2 +255,0 @@\n-  int      _handler_table_offset;\n-  int      _nul_chk_table_offset;\n@@ -257,1 +257,0 @@\n-  int      _jvmci_data_offset;\n@@ -268,2 +267,0 @@\n-  uint16_t     _num_stack_arg_slots;   \/\/ Number of arguments passed on the stack\n-\n@@ -326,0 +323,1 @@\n+          int immutable_data_size,\n@@ -328,0 +326,1 @@\n+          address immutable_data,\n@@ -367,1 +366,2 @@\n-    return _pc_desc_container.find_pc_desc(pc, approximate, PcDescSearch(code_begin(), scopes_pcs_begin(), scopes_pcs_end()));\n+    if (_pc_desc_container == nullptr) return nullptr; \/\/ native method\n+    return _pc_desc_container->find_pc_desc(pc, approximate, code_begin(), scopes_pcs_begin(), scopes_pcs_end());\n@@ -542,4 +542,1 @@\n-  address unwind_handler_begin  () const { return _unwind_handler_offset != -1 ? (header_begin() + _unwind_handler_offset) : nullptr; }\n-\n-  oop*    oops_begin            () const { return (oop*)    data_begin(); }\n-  oop*    oops_end              () const { return (oop*)   (data_begin() + _metadata_offset)          ; }\n+  address unwind_handler_begin  () const { return _unwind_handler_offset != -1 ? (insts_end() - _unwind_handler_offset) : nullptr; }\n@@ -547,0 +544,3 @@\n+  \/\/ mutable data\n+  oop*    oops_begin            () const { return (oop*)        data_begin(); }\n+  oop*    oops_end              () const { return (oop*)       (data_begin() + _metadata_offset)      ; }\n@@ -548,11 +548,20 @@\n-  Metadata** metadata_end       () const { return (Metadata**) (data_begin() + _dependencies_offset)  ; }\n-\n-  address dependencies_begin    () const { return           data_begin() + _dependencies_offset       ; }\n-  address dependencies_end      () const { return           data_begin() + _scopes_pcs_offset         ; }\n-  PcDesc* scopes_pcs_begin      () const { return (PcDesc*)(data_begin() + _scopes_pcs_offset)        ; }\n-  PcDesc* scopes_pcs_end        () const { return (PcDesc*)(data_begin() + _scopes_data_offset)       ; }\n-  address scopes_data_begin     () const { return           data_begin() + _scopes_data_offset        ; }\n-  address scopes_data_end       () const { return           data_begin() + _handler_table_offset      ; }\n-  address handler_table_begin   () const { return           data_begin() + _handler_table_offset      ; }\n-  address handler_table_end     () const { return           data_begin() + _nul_chk_table_offset      ; }\n-  address nul_chk_table_begin   () const { return           data_begin() + _nul_chk_table_offset      ; }\n+#if INCLUDE_JVMCI\n+  Metadata** metadata_end       () const { return (Metadata**) (data_begin() + _jvmci_data_offset)    ; }\n+  address jvmci_data_begin      () const { return               data_begin() + _jvmci_data_offset     ; }\n+  address jvmci_data_end        () const { return               data_end(); }\n+#else\n+  Metadata** metadata_end       () const { return (Metadata**)  data_end(); }\n+#endif\n+\n+  \/\/ immutable data\n+  address immutable_data_begin  () const { return           _immutable_data; }\n+  address immutable_data_end    () const { return           _immutable_data + _immutable_data_size ; }\n+  address dependencies_begin    () const { return           _immutable_data; }\n+  address dependencies_end      () const { return           _immutable_data + _nul_chk_table_offset; }\n+  address nul_chk_table_begin   () const { return           _immutable_data + _nul_chk_table_offset; }\n+  address nul_chk_table_end     () const { return           _immutable_data + _handler_table_offset; }\n+  address handler_table_begin   () const { return           _immutable_data + _handler_table_offset; }\n+  address handler_table_end     () const { return           _immutable_data + _scopes_pcs_offset   ; }\n+  PcDesc* scopes_pcs_begin      () const { return (PcDesc*)(_immutable_data + _scopes_pcs_offset)  ; }\n+  PcDesc* scopes_pcs_end        () const { return (PcDesc*)(_immutable_data + _scopes_data_offset) ; }\n+  address scopes_data_begin     () const { return           _immutable_data + _scopes_data_offset  ; }\n@@ -561,5 +570,3 @@\n-  address nul_chk_table_end     () const { return           data_begin() + _speculations_offset       ; }\n-  address speculations_begin    () const { return           data_begin() + _speculations_offset       ; }\n-  address speculations_end      () const { return           data_begin() + _jvmci_data_offset         ; }\n-  address jvmci_data_begin      () const { return           data_begin() + _jvmci_data_offset         ; }\n-  address jvmci_data_end        () const { return           data_end(); }\n+  address scopes_data_end       () const { return           _immutable_data + _speculations_offset ; }\n+  address speculations_begin    () const { return           _immutable_data + _speculations_offset ; }\n+  address speculations_end      () const { return            immutable_data_end(); }\n@@ -567,1 +574,1 @@\n-  address nul_chk_table_end     () const { return           data_end(); }\n+  address scopes_data_end       () const { return            immutable_data_end(); }\n@@ -571,10 +578,11 @@\n-  int consts_size       () const { return int(          consts_end       () -           consts_begin       ()); }\n-  int insts_size        () const { return int(          insts_end        () -           insts_begin        ()); }\n-  int stub_size         () const { return int(          stub_end         () -           stub_begin         ()); }\n-  int oops_size         () const { return int((address) oops_end         () - (address) oops_begin         ()); }\n-  int metadata_size     () const { return int((address) metadata_end     () - (address) metadata_begin     ()); }\n-  int scopes_data_size  () const { return int(          scopes_data_end  () -           scopes_data_begin  ()); }\n-  int scopes_pcs_size   () const { return int((intptr_t)scopes_pcs_end   () - (intptr_t)scopes_pcs_begin   ()); }\n-  int dependencies_size () const { return int(          dependencies_end () -           dependencies_begin ()); }\n-  int handler_table_size() const { return int(          handler_table_end() -           handler_table_begin()); }\n-  int nul_chk_table_size() const { return int(          nul_chk_table_end() -           nul_chk_table_begin()); }\n+  int immutable_data_size() const { return _immutable_data_size; }\n+  int consts_size        () const { return int(          consts_end       () -           consts_begin       ()); }\n+  int insts_size         () const { return int(          insts_end        () -           insts_begin        ()); }\n+  int stub_size          () const { return int(          stub_end         () -           stub_begin         ()); }\n+  int oops_size          () const { return int((address) oops_end         () - (address) oops_begin         ()); }\n+  int metadata_size      () const { return int((address) metadata_end     () - (address) metadata_begin     ()); }\n+  int scopes_data_size   () const { return int(          scopes_data_end  () -           scopes_data_begin  ()); }\n+  int scopes_pcs_size    () const { return int((intptr_t)scopes_pcs_end   () - (intptr_t)scopes_pcs_begin   ()); }\n+  int dependencies_size  () const { return int(          dependencies_end () -           dependencies_begin ()); }\n+  int handler_table_size () const { return int(          handler_table_end() -           handler_table_begin()); }\n+  int nul_chk_table_size () const { return int(          nul_chk_table_end() -           nul_chk_table_begin()); }\n@@ -582,2 +590,2 @@\n-  int speculations_size () const { return int(          speculations_end () -           speculations_begin ()); }\n-  int jvmci_data_size   () const { return int(          jvmci_data_end   () -           jvmci_data_begin   ()); }\n+  int speculations_size  () const { return int(          speculations_end () -           speculations_begin ()); }\n+  int jvmci_data_size    () const { return int(          jvmci_data_end   () -           jvmci_data_begin   ()); }\n","filename":"src\/hotspot\/share\/code\/nmethod.hpp","additions":78,"deletions":70,"binary":false,"changes":148,"status":"modified"},{"patch":"@@ -2129,1 +2129,2 @@\n-                                        task->num_inlined_bytecodes());\n+                                        task->num_inlined_bytecodes(),\n+                                        task->arena_bytes());\n","filename":"src\/hotspot\/share\/compiler\/compileBroker.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -137,1 +137,3 @@\n-void CompilerEvent::CompilationEvent::post(EventCompilation& event, int compile_id, CompilerType compiler_type, Method* method, int compile_level, bool success, bool is_osr, int code_size, int inlined_bytecodes) {\n+void CompilerEvent::CompilationEvent::post(EventCompilation& event, int compile_id, CompilerType compiler_type, Method* method,\n+    int compile_level, bool success, bool is_osr, int code_size,\n+    int inlined_bytecodes, size_t arenaBytes) {\n@@ -146,0 +148,1 @@\n+  event.set_arenaBytes(arenaBytes);\n","filename":"src\/hotspot\/share\/compiler\/compilerEvent.cpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -26,0 +26,2 @@\n+#include \"code\/vmreg.inline.hpp\"\n+#include \"gc\/shared\/barrierSet.hpp\"\n@@ -29,0 +31,1 @@\n+#include \"opto\/block.hpp\"\n@@ -34,0 +37,2 @@\n+#include \"opto\/output.hpp\"\n+#include \"opto\/regalloc.hpp\"\n@@ -36,0 +41,1 @@\n+#include CPU_HEADER(gc\/shared\/barrierSetAssembler)\n@@ -84,0 +90,25 @@\n+static BarrierSetC2State* barrier_set_state() {\n+  return reinterpret_cast<BarrierSetC2State*>(Compile::current()->barrier_set_state());\n+}\n+\n+BarrierStubC2::BarrierStubC2(const MachNode* node)\n+  : _node(node),\n+    _entry(),\n+    _continuation() {}\n+\n+RegMask& BarrierStubC2::live() const {\n+  return *barrier_set_state()->live(_node);\n+}\n+\n+Label* BarrierStubC2::entry() {\n+  \/\/ The _entry will never be bound when in_scratch_emit_size() is true.\n+  \/\/ However, we still need to return a label that is not bound now, but\n+  \/\/ will eventually be bound. Any eventually bound label will do, as it\n+  \/\/ will only act as a placeholder, so we return the _continuation label.\n+  return Compile::current()->output()->in_scratch_emit_size() ? &_continuation : &_entry;\n+}\n+\n+Label* BarrierStubC2::continuation() {\n+  return &_continuation;\n+}\n+\n@@ -795,0 +826,73 @@\n+\n+void BarrierSetC2::compute_liveness_at_stubs() const {\n+  ResourceMark rm;\n+  Compile* const C = Compile::current();\n+  Arena* const A = Thread::current()->resource_area();\n+  PhaseCFG* const cfg = C->cfg();\n+  PhaseRegAlloc* const regalloc = C->regalloc();\n+  RegMask* const live = NEW_ARENA_ARRAY(A, RegMask, cfg->number_of_blocks() * sizeof(RegMask));\n+  BarrierSetAssembler* const bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+  Block_List worklist;\n+\n+  for (uint i = 0; i < cfg->number_of_blocks(); ++i) {\n+    new ((void*)(live + i)) RegMask();\n+    worklist.push(cfg->get_block(i));\n+  }\n+\n+  while (worklist.size() > 0) {\n+    const Block* const block = worklist.pop();\n+    RegMask& old_live = live[block->_pre_order];\n+    RegMask new_live;\n+\n+    \/\/ Initialize to union of successors\n+    for (uint i = 0; i < block->_num_succs; i++) {\n+      const uint succ_id = block->_succs[i]->_pre_order;\n+      new_live.OR(live[succ_id]);\n+    }\n+\n+    \/\/ Walk block backwards, computing liveness\n+    for (int i = block->number_of_nodes() - 1; i >= 0; --i) {\n+      const Node* const node = block->get_node(i);\n+\n+      \/\/ Remove def bits\n+      const OptoReg::Name first = bs->refine_register(node, regalloc->get_reg_first(node));\n+      const OptoReg::Name second = bs->refine_register(node, regalloc->get_reg_second(node));\n+      if (first != OptoReg::Bad) {\n+        new_live.Remove(first);\n+      }\n+      if (second != OptoReg::Bad) {\n+        new_live.Remove(second);\n+      }\n+\n+      \/\/ Add use bits\n+      for (uint j = 1; j < node->req(); ++j) {\n+        const Node* const use = node->in(j);\n+        const OptoReg::Name first = bs->refine_register(use, regalloc->get_reg_first(use));\n+        const OptoReg::Name second = bs->refine_register(use, regalloc->get_reg_second(use));\n+        if (first != OptoReg::Bad) {\n+          new_live.Insert(first);\n+        }\n+        if (second != OptoReg::Bad) {\n+          new_live.Insert(second);\n+        }\n+      }\n+\n+       \/\/ If this node tracks liveness, update it\n+      RegMask* const regs = barrier_set_state()->live(node);\n+      if (regs != NULL) {\n+        regs->OR(new_live);\n+      }\n+    }\n+\n+    \/\/ Now at block top, see if we have any changes\n+    new_live.SUBTRACT(old_live);\n+    if (new_live.is_NotEmpty()) {\n+      \/\/ Liveness has refined, update and propagate to prior blocks\n+      old_live.OR(new_live);\n+      for (uint i = 1; i < block->num_preds(); ++i) {\n+        Block* const pred = cfg->get_block_for_node(block->pred(i));\n+        worklist.push(pred);\n+      }\n+    }\n+  }\n+}\n","filename":"src\/hotspot\/share\/gc\/shared\/c2\/barrierSetC2.cpp","additions":104,"deletions":0,"binary":false,"changes":104,"status":"modified"},{"patch":"@@ -212,0 +212,42 @@\n+class BarrierSetC2State : public ArenaObj {\n+protected:\n+  Node_Array                      _live;\n+\n+public:\n+  BarrierSetC2State(Arena* arena) : _live(arena) {}\n+\n+  RegMask* live(const Node* node) {\n+    if (!node->is_Mach() || !needs_liveness_data(node->as_Mach())) {\n+      \/\/ Don't need liveness for non-MachNodes or if the GC doesn't request it\n+      return nullptr;\n+    }\n+    RegMask* live = (RegMask*)_live[node->_idx];\n+    if (live == nullptr) {\n+      live = new (Compile::current()->comp_arena()->AmallocWords(sizeof(RegMask))) RegMask();\n+      _live.map(node->_idx, (Node*)live);\n+    }\n+\n+    return live;\n+  }\n+\n+  virtual bool needs_liveness_data(const MachNode* mach) const = 0;\n+};\n+\n+\/\/ This class represents the slow path in a C2 barrier. It is defined by a\n+\/\/ memory access, an entry point, and a continuation point (typically the end of\n+\/\/ the barrier). It provides a set of registers whose value is live across the\n+\/\/ barrier, and hence must be preserved across runtime calls from the stub.\n+class BarrierStubC2 : public ArenaObj {\n+protected:\n+  const MachNode* _node;\n+  Label           _entry;\n+  Label           _continuation;\n+\n+public:\n+  BarrierStubC2(const MachNode* node);\n+  RegMask& live() const;\n+  Label* entry();\n+  Label* continuation();\n+\n+  virtual Register result() const = 0;\n+};\n@@ -309,0 +351,1 @@\n+  virtual void compute_liveness_at_stubs() const;\n","filename":"src\/hotspot\/share\/gc\/shared\/c2\/barrierSetC2.hpp","additions":43,"deletions":0,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -253,13 +253,0 @@\n-HeapWord* MemAllocator::mem_allocate_inside_tlab(Allocation& allocation) const {\n-  assert(UseTLAB, \"should use UseTLAB\");\n-\n-  \/\/ Try allocating from an existing TLAB.\n-  HeapWord* mem = mem_allocate_inside_tlab_fast();\n-  if (mem != nullptr) {\n-    return mem;\n-  }\n-\n-  \/\/ Try refilling the TLAB and allocating the object in it.\n-  return mem_allocate_inside_tlab_slow(allocation);\n-}\n-\n@@ -334,1 +321,0 @@\n-\n","filename":"src\/hotspot\/share\/gc\/shared\/memAllocator.cpp","additions":0,"deletions":14,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -50,1 +50,0 @@\n-  HeapWord* mem_allocate_inside_tlab(Allocation& allocation) const;\n","filename":"src\/hotspot\/share\/gc\/shared\/memAllocator.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -123,1 +123,1 @@\n-class ZBarrierSetC2State : public ArenaObj {\n+class ZBarrierSetC2State : public BarrierSetC2State {\n@@ -126,1 +126,0 @@\n-  Node_Array                      _live;\n@@ -132,2 +131,2 @@\n-    : _stubs(new (arena) GrowableArray<ZBarrierStubC2*>(arena, 8,  0, nullptr)),\n-      _live(arena),\n+    : BarrierSetC2State(arena),\n+      _stubs(new (arena) GrowableArray<ZBarrierStubC2*>(arena, 8,  0, nullptr)),\n@@ -141,19 +140,3 @@\n-  RegMask* live(const Node* node) {\n-    if (!node->is_Mach()) {\n-      \/\/ Don't need liveness for non-MachNodes\n-      return nullptr;\n-    }\n-\n-    const MachNode* const mach = node->as_Mach();\n-    if (mach->barrier_data() == ZBarrierElided) {\n-      \/\/ Don't need liveness data for nodes without barriers\n-      return nullptr;\n-    }\n-\n-    RegMask* live = (RegMask*)_live[node->_idx];\n-    if (live == nullptr) {\n-      live = new (Compile::current()->comp_arena()->AmallocWords(sizeof(RegMask))) RegMask();\n-      _live.map(node->_idx, (Node*)live);\n-    }\n-\n-    return live;\n+  bool needs_liveness_data(const MachNode* mach) const {\n+    \/\/ Don't need liveness data for nodes without barriers\n+    return mach->barrier_data() != ZBarrierElided;\n@@ -204,24 +187,1 @@\n-ZBarrierStubC2::ZBarrierStubC2(const MachNode* node)\n-  : _node(node),\n-    _entry(),\n-    _continuation() {}\n-\n-Register ZBarrierStubC2::result() const {\n-  return noreg;\n-}\n-\n-RegMask& ZBarrierStubC2::live() const {\n-  return *barrier_set_state()->live(_node);\n-}\n-\n-Label* ZBarrierStubC2::entry() {\n-  \/\/ The _entry will never be bound when in_scratch_emit_size() is true.\n-  \/\/ However, we still need to return a label that is not bound now, but\n-  \/\/ will eventually be bound. Any eventually bound label will do, as it\n-  \/\/ will only act as a placeholder, so we return the _continuation label.\n-  return Compile::current()->output()->in_scratch_emit_size() ? &_continuation : &_entry;\n-}\n-\n-Label* ZBarrierStubC2::continuation() {\n-  return &_continuation;\n-}\n+ZBarrierStubC2::ZBarrierStubC2(const MachNode* node) : BarrierStubC2(node) {}\n@@ -887,74 +847,0 @@\n-\/\/ == Reduced spilling optimization ==\n-\n-void ZBarrierSetC2::compute_liveness_at_stubs() const {\n-  ResourceMark rm;\n-  Compile* const C = Compile::current();\n-  Arena* const A = Thread::current()->resource_area();\n-  PhaseCFG* const cfg = C->cfg();\n-  PhaseRegAlloc* const regalloc = C->regalloc();\n-  RegMask* const live = NEW_ARENA_ARRAY(A, RegMask, cfg->number_of_blocks() * sizeof(RegMask));\n-  ZBarrierSetAssembler* const bs = ZBarrierSet::assembler();\n-  Block_List worklist;\n-\n-  for (uint i = 0; i < cfg->number_of_blocks(); ++i) {\n-    new ((void*)(live + i)) RegMask();\n-    worklist.push(cfg->get_block(i));\n-  }\n-\n-  while (worklist.size() > 0) {\n-    const Block* const block = worklist.pop();\n-    RegMask& old_live = live[block->_pre_order];\n-    RegMask new_live;\n-\n-    \/\/ Initialize to union of successors\n-    for (uint i = 0; i < block->_num_succs; i++) {\n-      const uint succ_id = block->_succs[i]->_pre_order;\n-      new_live.OR(live[succ_id]);\n-    }\n-\n-    \/\/ Walk block backwards, computing liveness\n-    for (int i = block->number_of_nodes() - 1; i >= 0; --i) {\n-      const Node* const node = block->get_node(i);\n-\n-      \/\/ Remove def bits\n-      const OptoReg::Name first = bs->refine_register(node, regalloc->get_reg_first(node));\n-      const OptoReg::Name second = bs->refine_register(node, regalloc->get_reg_second(node));\n-      if (first != OptoReg::Bad) {\n-        new_live.Remove(first);\n-      }\n-      if (second != OptoReg::Bad) {\n-        new_live.Remove(second);\n-      }\n-\n-      \/\/ Add use bits\n-      for (uint j = 1; j < node->req(); ++j) {\n-        const Node* const use = node->in(j);\n-        const OptoReg::Name first = bs->refine_register(use, regalloc->get_reg_first(use));\n-        const OptoReg::Name second = bs->refine_register(use, regalloc->get_reg_second(use));\n-        if (first != OptoReg::Bad) {\n-          new_live.Insert(first);\n-        }\n-        if (second != OptoReg::Bad) {\n-          new_live.Insert(second);\n-        }\n-      }\n-\n-      \/\/ If this node tracks liveness, update it\n-      RegMask* const regs = barrier_set_state()->live(node);\n-      if (regs != nullptr) {\n-        regs->OR(new_live);\n-      }\n-    }\n-\n-    \/\/ Now at block top, see if we have any changes\n-    new_live.SUBTRACT(old_live);\n-    if (new_live.is_NotEmpty()) {\n-      \/\/ Liveness has refined, update and propagate to prior blocks\n-      old_live.OR(new_live);\n-      for (uint i = 1; i < block->num_preds(); ++i) {\n-        Block* const pred = cfg->get_block_for_node(block->pred(i));\n-        worklist.push(pred);\n-      }\n-    }\n-  }\n-}\n","filename":"src\/hotspot\/share\/gc\/z\/c2\/zBarrierSetC2.cpp","additions":7,"deletions":121,"binary":false,"changes":128,"status":"modified"},{"patch":"@@ -44,1 +44,1 @@\n-class ZBarrierStubC2 : public ArenaObj {\n+class ZBarrierStubC2 : public BarrierStubC2 {\n@@ -46,4 +46,0 @@\n-  const MachNode* _node;\n-  Label           _entry;\n-  Label           _continuation;\n-\n@@ -58,4 +54,0 @@\n-  RegMask& live() const;\n-  Label* entry();\n-  Label* continuation();\n-\n@@ -111,1 +103,0 @@\n-  void compute_liveness_at_stubs() const;\n","filename":"src\/hotspot\/share\/gc\/z\/c2\/zBarrierSetC2.hpp","additions":1,"deletions":10,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -2883,1 +2883,1 @@\n-          assert(Type::cmp(vbox->vec_type(), cached_vbox->vec_type()) != 0, \"inconsistent\");\n+          assert(!Type::equals(vbox->vec_type(), cached_vbox->vec_type()), \"inconsistent\");\n@@ -2886,1 +2886,1 @@\n-          assert(Type::cmp(vbox->box_type(), cached_vbox->box_type()) != 0, \"inconsistent\");\n+          assert(!Type::equals(vbox->box_type(), cached_vbox->box_type()), \"inconsistent\");\n","filename":"src\/hotspot\/share\/opto\/cfgnode.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -864,1 +864,1 @@\n-  return !Type::cmp(_type, load._type) &&\n+  return Type::equals(_type, load._type) &&\n@@ -3161,2 +3161,2 @@\n-    assert(shift_out >= 0, \"must be positive\");\n-    return true;\n+    \/\/ The shift must be positive:\n+    return shift_out >= 0;\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -3021,1 +3021,1 @@\n-  return !Type::cmp(_type, ((TypeNode&)n)._type);\n+  return Type::equals(_type, n.as_Type()->_type);\n","filename":"src\/hotspot\/share\/opto\/node.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -453,3 +453,5 @@\n-int Type::cmp( const Type *const t1, const Type *const t2 ) {\n-  if( t1->_base != t2->_base )\n-    return 1;                   \/\/ Missed badly\n+bool Type::equals(const Type* t1, const Type* t2) {\n+  if (t1->_base != t2->_base) {\n+    return false; \/\/ Missed badly\n+  }\n+\n@@ -457,1 +459,1 @@\n-  return !t1->eq(t2);           \/\/ Return ZERO if equal\n+  return t1->eq(t2);\n@@ -487,3 +489,7 @@\n-  _shared_type_dict =\n-    new (shared_type_arena) Dict( (CmpKey)Type::cmp, (Hash)Type::uhash,\n-                                  shared_type_arena, 128 );\n+\n+  \/\/ Map the boolean result of Type::equals into a comparator result that CmpKey expects.\n+  CmpKey type_cmp = [](const void* t1, const void* t2) -> int32_t {\n+    return Type::equals((Type*) t1, (Type*) t2) ? 0 : 1;\n+  };\n+\n+  _shared_type_dict = new (shared_type_arena) Dict(type_cmp, (Hash) Type::uhash, shared_type_arena, 128);\n@@ -802,1 +808,1 @@\n-  if (cmp(this, _dual) == 0) {  \/\/ Handle self-symmetric\n+  if (equals(this, _dual)) {    \/\/ Handle self-symmetric\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":14,"deletions":8,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -186,1 +186,1 @@\n-  \/\/ Structural equality check.  Assumes that cmp() has already compared\n+  \/\/ Structural equality check.  Assumes that equals() has already compared\n@@ -245,1 +245,1 @@\n-  static int cmp( const Type *const t1, const Type *const t2 );\n+  static bool equals(const Type* t1, const Type* t2);\n@@ -248,2 +248,2 @@\n-  bool higher_equal(const Type *t) const {\n-    return !cmp(meet(t),t->remove_speculative());\n+  bool higher_equal(const Type* t) const {\n+    return equals(meet(t), t->remove_speculative());\n@@ -252,2 +252,2 @@\n-  bool higher_equal_speculative(const Type *t) const {\n-    return !cmp(meet_speculative(t),t);\n+  bool higher_equal_speculative(const Type* t) const {\n+    return equals(meet_speculative(t), t);\n","filename":"src\/hotspot\/share\/opto\/type.hpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -505,0 +505,1 @@\n+  { \"DontYieldALot\",                JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -421,1 +421,0 @@\n-  DEBUG_ONLY(GrowableArray<oop> lock_order{0};)\n@@ -431,7 +430,0 @@\n-#ifdef ASSERT\n-      if (LockingMode == LM_LIGHTWEIGHT && !realloc_failures) {\n-        for (MonitorInfo* mi : *monitors) {\n-          lock_order.push(mi->owner());\n-        }\n-      }\n-#endif \/\/ ASSERT\n@@ -469,5 +461,0 @@\n-#ifdef ASSERT\n-  if (LockingMode == LM_LIGHTWEIGHT && !realloc_failures) {\n-    deoptee_thread->lock_stack().verify_consistent_lock_order(lock_order, exec_mode != Deoptimization::Unpack_none);\n-  }\n-#endif \/\/ ASSERT\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":0,"deletions":13,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -701,1 +701,1 @@\n-          \"Throw away obvious excess yield calls\")                          \\\n+             \"(Deprecated) Throw away obvious excess yield calls\")          \\\n@@ -1337,3 +1337,0 @@\n-  develop(intx, DontYieldALotInterval,    10,                               \\\n-          \"Interval between which yields will be dropped (milliseconds)\")   \\\n-                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -454,0 +454,1 @@\n+  _VTMS_transition_mark(false),\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -321,0 +321,1 @@\n+  bool                  _VTMS_transition_mark;           \/\/ used for sync between VTMS transitions and disablers\n@@ -668,0 +669,3 @@\n+  bool VTMS_transition_mark() const              { return Atomic::load(&_VTMS_transition_mark); }\n+  void set_VTMS_transition_mark(bool val)        { Atomic::store(&_VTMS_transition_mark, val); }\n+\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -487,3 +487,0 @@\n-  \/\/ write lock needed because we might update the pc desc cache via PcDescCache::add_pc_desc\n-  MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXWrite, current));\n-\n@@ -1832,1 +1829,2 @@\n-  \/\/ write lock needed because we might update the pc desc cache via PcDescCache::add_pc_desc\n+  \/\/ write lock needed because we might patch call site by set_to_clean()\n+  \/\/ and is_unloading() can modify nmethod's state\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":2,"deletions":4,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -581,1 +581,1 @@\n-  nonstatic_field(nmethod,                     _scopes_pcs_offset,                            u2)                                    \\\n+  nonstatic_field(nmethod,                     _scopes_pcs_offset,                            int)                                    \\\n@@ -583,3 +583,2 @@\n-  nonstatic_field(nmethod,                     _dependencies_offset,                          u2)                                    \\\n-  nonstatic_field(nmethod,                     _handler_table_offset,                         int)                                   \\\n-  nonstatic_field(nmethod,                     _nul_chk_table_offset,                         int)                                   \\\n+  nonstatic_field(nmethod,                     _handler_table_offset,                         u2)                                    \\\n+  nonstatic_field(nmethod,                     _nul_chk_table_offset,                         u2)                                    \\\n@@ -589,0 +588,2 @@\n+  nonstatic_field(nmethod,                     _immutable_data,                               address)                               \\\n+  nonstatic_field(nmethod,                     _immutable_data_size,                          int)                                   \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -40,0 +40,1 @@\n+#include <limits>\n@@ -1127,1 +1128,12 @@\n-template<class T> inline T ABS(T x)                 { return (x > 0) ? x : -x; }\n+#define ABS(x) asserted_abs(x, __FILE__, __LINE__)\n+\n+template<class T> inline T asserted_abs(T x, const char* file, int line) {\n+  bool valid_arg = !(std::is_integral<T>::value && x == std::numeric_limits<T>::min());\n+#ifdef ASSERT\n+  if (!valid_arg) {\n+    report_vm_error(file, line, \"ABS: argument should not allow overflow\");\n+  }\n+#endif\n+  \/\/ Prevent exposure to UB by checking valid_arg here as well.\n+  return (x < 0 && valid_arg) ? -x : x;\n+}\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":13,"deletions":1,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -1036,1 +1036,1 @@\n-        @Deprecated\n+        @Deprecated(forRemoval = true, since = \"1.4\")\n","filename":"src\/java.base\/share\/classes\/java\/io\/ObjectOutputStream.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -71,1 +71,1 @@\n- *     throws IOException\n+ *     throws IOException;\n","filename":"src\/java.base\/share\/classes\/java\/io\/Serializable.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -161,11 +161,1 @@\n-        requireNonNull(descriptor);\n-        if (descriptor.isEmpty()) {\n-            throw new IllegalArgumentException(\n-                    \"not a valid reference type descriptor: \" + descriptor);\n-        }\n-        int depth = ConstantUtils.arrayDepth(descriptor);\n-        if (depth > ConstantUtils.MAX_ARRAY_TYPE_DESC_DIMENSIONS) {\n-            throw new IllegalArgumentException(\n-                    \"Cannot create an array type descriptor with more than \" +\n-                    ConstantUtils.MAX_ARRAY_TYPE_DESC_DIMENSIONS + \" dimensions\");\n-        }\n+        \/\/ implicit null-check\n@@ -173,1 +163,2 @@\n-               ? new PrimitiveClassDescImpl(descriptor)\n+               ? Wrapper.forPrimitiveType(descriptor.charAt(0)).classDescriptor()\n+               \/\/ will throw IAE on descriptor.length == 0 or if array dimensions too long\n@@ -282,1 +273,1 @@\n-        return descriptorString().startsWith(\"[\");\n+        return descriptorString().charAt(0) == '[';\n@@ -300,1 +291,1 @@\n-        return descriptorString().startsWith(\"L\");\n+        return descriptorString().charAt(0) == 'L';\n","filename":"src\/java.base\/share\/classes\/java\/lang\/constant\/ClassDesc.java","additions":6,"deletions":15,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -50,4 +50,3 @@\n-        requireNonNull(descriptor);\n-        int len = ConstantUtils.skipOverFieldSignature(descriptor, 0, descriptor.length(), false);\n-        if (len == 0 || len == 1\n-            || len != descriptor.length())\n+        int dLen = descriptor.length();\n+        int len = ConstantUtils.skipOverFieldSignature(descriptor, 0, dLen, false);\n+        if (len <= 1 || len != dLen)\n","filename":"src\/java.base\/share\/classes\/java\/lang\/constant\/ClassDescImpl.java","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -67,1 +67,1 @@\n-    public static final ClassDesc CD_Object = ClassDesc.of(\"java.lang.Object\");\n+    public static final ClassDesc CD_Object = new ClassDescImpl(\"Ljava\/lang\/Object;\");\n@@ -70,1 +70,1 @@\n-    public static final ClassDesc CD_String = ClassDesc.of(\"java.lang.String\");\n+    public static final ClassDesc CD_String = new ClassDescImpl(\"Ljava\/lang\/String;\");\n@@ -73,1 +73,1 @@\n-    public static final ClassDesc CD_Class = ClassDesc.of(\"java.lang.Class\");\n+    public static final ClassDesc CD_Class = new ClassDescImpl(\"Ljava\/lang\/Class;\");\n@@ -76,1 +76,1 @@\n-    public static final ClassDesc CD_Number = ClassDesc.of(\"java.lang.Number\");\n+    public static final ClassDesc CD_Number = new ClassDescImpl(\"Ljava\/lang\/Number;\");\n@@ -79,1 +79,1 @@\n-    public static final ClassDesc CD_Integer = ClassDesc.of(\"java.lang.Integer\");\n+    public static final ClassDesc CD_Integer = new ClassDescImpl(\"Ljava\/lang\/Integer;\");\n@@ -82,1 +82,1 @@\n-    public static final ClassDesc CD_Long = ClassDesc.of(\"java.lang.Long\");\n+    public static final ClassDesc CD_Long = new ClassDescImpl(\"Ljava\/lang\/Long;\");\n@@ -85,1 +85,1 @@\n-    public static final ClassDesc CD_Float = ClassDesc.of(\"java.lang.Float\");\n+    public static final ClassDesc CD_Float = new ClassDescImpl(\"Ljava\/lang\/Float;\");\n@@ -88,1 +88,1 @@\n-    public static final ClassDesc CD_Double = ClassDesc.of(\"java.lang.Double\");\n+    public static final ClassDesc CD_Double = new ClassDescImpl(\"Ljava\/lang\/Double;\");\n@@ -91,1 +91,1 @@\n-    public static final ClassDesc CD_Short = ClassDesc.of(\"java.lang.Short\");\n+    public static final ClassDesc CD_Short = new ClassDescImpl(\"Ljava\/lang\/Short;\");\n@@ -94,1 +94,1 @@\n-    public static final ClassDesc CD_Byte = ClassDesc.of(\"java.lang.Byte\");\n+    public static final ClassDesc CD_Byte = new ClassDescImpl(\"Ljava\/lang\/Byte;\");\n@@ -97,1 +97,1 @@\n-    public static final ClassDesc CD_Character = ClassDesc.of(\"java.lang.Character\");\n+    public static final ClassDesc CD_Character = new ClassDescImpl(\"Ljava\/lang\/Character;\");\n@@ -100,1 +100,1 @@\n-    public static final ClassDesc CD_Boolean = ClassDesc.of(\"java.lang.Boolean\");\n+    public static final ClassDesc CD_Boolean = new ClassDescImpl(\"Ljava\/lang\/Boolean;\");\n@@ -103,1 +103,1 @@\n-    public static final ClassDesc CD_Void = ClassDesc.of(\"java.lang.Void\");\n+    public static final ClassDesc CD_Void = new ClassDescImpl(\"Ljava\/lang\/Void;\");\n@@ -106,1 +106,1 @@\n-    public static final ClassDesc CD_Throwable = ClassDesc.of(\"java.lang.Throwable\");\n+    public static final ClassDesc CD_Throwable = new ClassDescImpl(\"Ljava\/lang\/Throwable;\");\n@@ -109,1 +109,1 @@\n-    public static final ClassDesc CD_Exception = ClassDesc.of(\"java.lang.Exception\");\n+    public static final ClassDesc CD_Exception = new ClassDescImpl(\"Ljava\/lang\/Exception;\");\n@@ -112,1 +112,1 @@\n-    public static final ClassDesc CD_Enum = ClassDesc.of(\"java.lang.Enum\");\n+    public static final ClassDesc CD_Enum = new ClassDescImpl(\"Ljava\/lang\/Enum;\");\n@@ -115,1 +115,1 @@\n-    public static final ClassDesc CD_VarHandle = ClassDesc.of(\"java.lang.invoke.VarHandle\");\n+    public static final ClassDesc CD_VarHandle = new ClassDescImpl(\"Ljava\/lang\/invoke\/VarHandle;\");\n@@ -118,1 +118,1 @@\n-    public static final ClassDesc CD_MethodHandles = ClassDesc.of(\"java.lang.invoke.MethodHandles\");\n+    public static final ClassDesc CD_MethodHandles = new ClassDescImpl(\"Ljava\/lang\/invoke\/MethodHandles;\");\n@@ -121,1 +121,1 @@\n-    public static final ClassDesc CD_MethodHandles_Lookup = CD_MethodHandles.nested(\"Lookup\");\n+    public static final ClassDesc CD_MethodHandles_Lookup = new ClassDescImpl(\"Ljava\/lang\/invoke\/MethodHandles$Lookup;\");\n@@ -124,1 +124,1 @@\n-    public static final ClassDesc CD_MethodHandle = ClassDesc.of(\"java.lang.invoke.MethodHandle\");\n+    public static final ClassDesc CD_MethodHandle = new ClassDescImpl(\"Ljava\/lang\/invoke\/MethodHandle;\");\n@@ -127,1 +127,1 @@\n-    public static final ClassDesc CD_MethodType = ClassDesc.of(\"java.lang.invoke.MethodType\");\n+    public static final ClassDesc CD_MethodType = new ClassDescImpl(\"Ljava\/lang\/invoke\/MethodType;\");\n@@ -130,1 +130,1 @@\n-    public static final ClassDesc CD_CallSite = ClassDesc.of(\"java.lang.invoke.CallSite\");\n+    public static final ClassDesc CD_CallSite = new ClassDescImpl(\"Ljava\/lang\/invoke\/CallSite;\");\n@@ -133,1 +133,1 @@\n-    public static final ClassDesc CD_Collection = ClassDesc.of(\"java.util.Collection\");\n+    public static final ClassDesc CD_Collection = new ClassDescImpl(\"Ljava\/util\/Collection;\");\n@@ -136,1 +136,1 @@\n-    public static final ClassDesc CD_List = ClassDesc.of(\"java.util.List\");\n+    public static final ClassDesc CD_List = new ClassDescImpl(\"Ljava\/util\/List;\");\n@@ -139,1 +139,1 @@\n-    public static final ClassDesc CD_Set = ClassDesc.of(\"java.util.Set\");\n+    public static final ClassDesc CD_Set = new ClassDescImpl(\"Ljava\/util\/Set;\");\n@@ -142,1 +142,1 @@\n-    public static final ClassDesc CD_Map = ClassDesc.of(\"java.util.Map\");\n+    public static final ClassDesc CD_Map = new ClassDescImpl(\"Ljava\/util\/Map;\");\n@@ -145,1 +145,1 @@\n-    public static final ClassDesc CD_ConstantDesc = ClassDesc.of(\"java.lang.constant.ConstantDesc\");\n+    public static final ClassDesc CD_ConstantDesc = new ClassDescImpl(\"Ljava\/lang\/constant\/ConstantDesc;\");\n@@ -148,1 +148,1 @@\n-    public static final ClassDesc CD_ClassDesc = ClassDesc.of(\"java.lang.constant.ClassDesc\");\n+    public static final ClassDesc CD_ClassDesc = new ClassDescImpl(\"Ljava\/lang\/constant\/ClassDesc;\");\n@@ -151,1 +151,1 @@\n-    public static final ClassDesc CD_EnumDesc = CD_Enum.nested(\"EnumDesc\");\n+    public static final ClassDesc CD_EnumDesc = new ClassDescImpl(\"Ljava\/lang\/Enum$EnumDesc;\");\n@@ -154,1 +154,1 @@\n-    public static final ClassDesc CD_MethodTypeDesc = ClassDesc.of(\"java.lang.constant.MethodTypeDesc\");\n+    public static final ClassDesc CD_MethodTypeDesc = new ClassDescImpl(\"Ljava\/lang\/constant\/MethodTypeDesc;\");\n@@ -157,1 +157,1 @@\n-    public static final ClassDesc CD_MethodHandleDesc = ClassDesc.of(\"java.lang.constant.MethodHandleDesc\");\n+    public static final ClassDesc CD_MethodHandleDesc = new ClassDescImpl(\"Ljava\/lang\/constant\/MethodHandleDesc;\");\n@@ -160,1 +160,1 @@\n-    public static final ClassDesc CD_DirectMethodHandleDesc = ClassDesc.of(\"java.lang.constant.DirectMethodHandleDesc\");\n+    public static final ClassDesc CD_DirectMethodHandleDesc = new ClassDescImpl(\"Ljava\/lang\/constant\/DirectMethodHandleDesc;\");\n@@ -163,1 +163,1 @@\n-    public static final ClassDesc CD_VarHandleDesc = CD_VarHandle.nested(\"VarHandleDesc\");\n+    public static final ClassDesc CD_VarHandleDesc = new ClassDescImpl(\"Ljava\/lang\/invoke\/VarHandle$VarHandleDesc;\");\n@@ -166,1 +166,1 @@\n-    public static final ClassDesc CD_MethodHandleDesc_Kind = CD_DirectMethodHandleDesc.nested(\"Kind\");\n+    public static final ClassDesc CD_MethodHandleDesc_Kind = new ClassDescImpl(\"Ljava\/lang\/constant\/DirectMethodHandleDesc$Kind;\");\n@@ -169,1 +169,1 @@\n-    public static final ClassDesc CD_DynamicConstantDesc = ClassDesc.of(\"java.lang.constant.DynamicConstantDesc\");\n+    public static final ClassDesc CD_DynamicConstantDesc = new ClassDescImpl(\"Ljava\/lang\/constant\/DynamicConstantDesc;\");\n@@ -172,1 +172,1 @@\n-    public static final ClassDesc CD_DynamicCallSiteDesc = ClassDesc.of(\"java.lang.constant.DynamicCallSiteDesc\");\n+    public static final ClassDesc CD_DynamicCallSiteDesc = new ClassDescImpl(\"Ljava\/lang\/constant\/DynamicCallSiteDesc;\");\n@@ -175,1 +175,1 @@\n-    public static final ClassDesc CD_ConstantBootstraps = ClassDesc.of(\"java.lang.invoke.ConstantBootstraps\");\n+    public static final ClassDesc CD_ConstantBootstraps = new ClassDescImpl(\"Ljava\/lang\/invoke\/ConstantBootstraps;\");\n@@ -178,3 +178,3 @@\n-            ConstantDescs.CD_MethodHandles_Lookup,\n-            ConstantDescs.CD_String,\n-            ConstantDescs.CD_MethodType};\n+            CD_MethodHandles_Lookup,\n+            CD_String,\n+            CD_MethodType};\n@@ -183,3 +183,3 @@\n-            ConstantDescs.CD_MethodHandles_Lookup,\n-            ConstantDescs.CD_String,\n-            ConstantDescs.CD_Class};\n+            CD_MethodHandles_Lookup,\n+            CD_String,\n+            CD_Class};\n@@ -239,1 +239,1 @@\n-    public static final ClassDesc CD_int = ClassDesc.ofDescriptor(\"I\");\n+    public static final ClassDesc CD_int = new PrimitiveClassDescImpl(\"I\");\n@@ -242,1 +242,1 @@\n-    public static final ClassDesc CD_long = ClassDesc.ofDescriptor(\"J\");\n+    public static final ClassDesc CD_long = new PrimitiveClassDescImpl(\"J\");\n@@ -245,1 +245,1 @@\n-    public static final ClassDesc CD_float = ClassDesc.ofDescriptor(\"F\");\n+    public static final ClassDesc CD_float = new PrimitiveClassDescImpl(\"F\");\n@@ -248,1 +248,1 @@\n-    public static final ClassDesc CD_double = ClassDesc.ofDescriptor(\"D\");\n+    public static final ClassDesc CD_double = new PrimitiveClassDescImpl(\"D\");\n@@ -251,1 +251,1 @@\n-    public static final ClassDesc CD_short = ClassDesc.ofDescriptor(\"S\");\n+    public static final ClassDesc CD_short = new PrimitiveClassDescImpl(\"S\");\n@@ -254,1 +254,1 @@\n-    public static final ClassDesc CD_byte = ClassDesc.ofDescriptor(\"B\");\n+    public static final ClassDesc CD_byte = new PrimitiveClassDescImpl(\"B\");\n@@ -257,1 +257,1 @@\n-    public static final ClassDesc CD_char = ClassDesc.ofDescriptor(\"C\");\n+    public static final ClassDesc CD_char = new PrimitiveClassDescImpl(\"C\");\n@@ -260,1 +260,1 @@\n-    public static final ClassDesc CD_boolean = ClassDesc.ofDescriptor(\"Z\");\n+    public static final ClassDesc CD_boolean = new PrimitiveClassDescImpl(\"Z\");\n@@ -263,1 +263,1 @@\n-    public static final ClassDesc CD_void = ClassDesc.ofDescriptor(\"V\");\n+    public static final ClassDesc CD_void = new PrimitiveClassDescImpl(\"V\");\n","filename":"src\/java.base\/share\/classes\/java\/lang\/constant\/ConstantDescs.java","additions":53,"deletions":53,"binary":false,"changes":106,"status":"modified"},{"patch":"@@ -85,1 +85,1 @@\n-        @JEP(number=461, title=\"Stream Gatherers\", status=\"Preview\")\n+        @JEP(number=473, title=\"Stream Gatherers\", status=\"Second Preview\")\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/javac\/PreviewFeature.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -183,0 +183,6 @@\n+        \/**\n+         * Warn about\"dangling\" documentation comments,\n+         * not attached to any declaration.\n+         *\/\n+        DANGLING_DOC_COMMENTS(\"dangling-doc-comments\"),\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Lint.java","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1138,0 +1138,1 @@\n+                    sym.apiComplete();\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Type.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -257,1 +257,1 @@\n-                            : deferredLintHandler.immediate();\n+                            : deferredLintHandler.immediate(lint);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Annotate.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -993,1 +993,1 @@\n-            deferredLintHandler.flush(tree.pos());\n+            deferredLintHandler.flush(tree.pos(), lint);\n@@ -1298,1 +1298,1 @@\n-            deferredLintHandler.flush(tree.pos());\n+            deferredLintHandler.flush(tree.pos(), lint);\n@@ -5330,1 +5330,1 @@\n-            deferredLintHandler.flush(env.tree.pos());\n+            deferredLintHandler.flush(env.tree.pos(), lint);\n@@ -5505,1 +5505,1 @@\n-                deferredLintHandler.flush(env.tree);\n+                deferredLintHandler.flush(env.tree, env.info.lint);\n@@ -5560,1 +5560,1 @@\n-            deferredLintHandler.flush(tree.pos());\n+            deferredLintHandler.flush(tree.pos(), lint);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Attr.java","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -678,1 +678,1 @@\n-            deferredLintHandler.report(() -> {\n+            deferredLintHandler.report(_l -> {\n@@ -1432,1 +1432,1 @@\n-            deferredLintHandler.report(() -> {\n+            deferredLintHandler.report(_l -> {\n@@ -3908,1 +3908,1 @@\n-            deferredLintHandler.report(() -> warnDeprecated(pos.get(), s));\n+            deferredLintHandler.report(_l -> warnDeprecated(pos.get(), s));\n@@ -3914,1 +3914,1 @@\n-            deferredLintHandler.report(() -> {\n+            deferredLintHandler.report(_l -> {\n@@ -3933,1 +3933,1 @@\n-                    deferredLintHandler.report(() -> warnPreviewAPI(pos, Warnings.IsPreview(s)));\n+                    deferredLintHandler.report(_l -> warnPreviewAPI(pos, Warnings.IsPreview(s)));\n@@ -3936,1 +3936,1 @@\n-                    deferredLintHandler.report(() -> warnPreviewAPI(pos, Warnings.IsPreviewReflective(s)));\n+                    deferredLintHandler.report(_l -> warnPreviewAPI(pos, Warnings.IsPreviewReflective(s)));\n@@ -3945,1 +3945,1 @@\n-                deferredLintHandler.report(() -> warnDeclaredUsingPreview(pos, s));\n+                deferredLintHandler.report(_l -> warnDeclaredUsingPreview(pos, s));\n@@ -3952,1 +3952,1 @@\n-            deferredLintHandler.report(() -> warnRestrictedAPI(pos, s));\n+            deferredLintHandler.report(_l -> warnRestrictedAPI(pos, s));\n@@ -4201,1 +4201,1 @@\n-                deferredLintHandler.report(() -> warnDivZero(pos));\n+                deferredLintHandler.report(_l -> warnDivZero(pos));\n@@ -4214,1 +4214,1 @@\n-            deferredLintHandler.report(() -> {\n+            deferredLintHandler.report(_l -> {\n@@ -4418,1 +4418,1 @@\n-                            deferredLintHandler.report(() -> {\n+                            deferredLintHandler.report(_l -> {\n@@ -4753,1 +4753,1 @@\n-            deferredLintHandler.report(() -> {\n+            deferredLintHandler.report(_l -> {\n@@ -4763,1 +4763,1 @@\n-            deferredLintHandler.report(() -> {\n+            deferredLintHandler.report(_l -> {\n@@ -4772,1 +4772,1 @@\n-            deferredLintHandler.report(() -> {\n+            deferredLintHandler.report(_l -> {\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Check.java","additions":14,"deletions":14,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -350,1 +350,1 @@\n-            DiagnosticPosition prevLintPos = deferredLintHandler.immediate();\n+            DiagnosticPosition prevLintPos = deferredLintHandler.immediate(lint);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/TypeEnter.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -118,0 +118,6 @@\n+    \/** A map associating \"other nearby documentation comments\"\n+     *  with the preferred documentation comment for a declaration. *\/\n+    protected Map<Comment, List<Comment>> danglingComments = new HashMap<>();\n+    \/** Handler for deferred diagnostics. *\/\n+    protected final DeferredLintHandler deferredLintHandler;\n+\n@@ -188,0 +194,1 @@\n+        this.deferredLintHandler = fac.deferredLintHandler;\n@@ -214,0 +221,1 @@\n+        this.deferredLintHandler = parser.deferredLintHandler;\n@@ -566,0 +574,53 @@\n+    \/** Record nearby documentation comments against the\n+     *  primary documentation comment for a declaration.\n+     *\n+     *  Dangling documentation comments are handled as follows.\n+     *  1. {@code Scanner} adds all doc comments to a queue of\n+     *     recent doc comments. The queue is flushed whenever\n+     *     it is known that the recent doc comments should be\n+     *     ignored and should not cause any warnings.\n+     *  2. The primary documentation comment is the one obtained\n+     *     from the first token of any declaration.\n+     *     (using {@code token.getDocComment()}.\n+     *  3. At the end of the \"signature\" of the declaration\n+     *     (that is, before any initialization or body for the\n+     *     declaration) any other \"recent\" comments are saved\n+     *     in a map using the primary comment as a key,\n+     *     using this method, {@code saveDanglingComments}.\n+     *  4. When the tree node for the declaration is finally\n+     *     available, and the primary comment, if any,\n+     *     is \"attached\", (in {@link #attach}) any related\n+     *     dangling comments are also attached to the tree node\n+     *     by registering them using the {@link #deferredLintHandler}.\n+     *  5. (Later) Warnings may be generated for the dangling\n+     *     comments, subject to the {@code -Xlint} and\n+     *     {@code @SuppressWarnings}.\n+     *\n+     *  @param dc the primary documentation comment\n+     *\/\n+    private void saveDanglingDocComments(Comment dc) {\n+        var recentComments = S.getDocComments();\n+\n+        switch (recentComments.size()) {\n+            case 0:\n+                \/\/ no recent comments\n+                return;\n+\n+            case 1:\n+                if (recentComments.peek() == dc) {\n+                    \/\/ no other recent comments\n+                    recentComments.remove();\n+                    return;\n+                }\n+        }\n+\n+        var lb = new ListBuffer<Comment>();\n+        while (!recentComments.isEmpty()) {\n+            var c = recentComments.remove();\n+            if (c != dc) {\n+                lb.add(c);\n+            }\n+        }\n+        danglingComments.put(dc, lb.toList());\n+    }\n+\n@@ -568,0 +629,4 @@\n+     *  If there are any related \"dangling comments\", register\n+     *  diagnostics to be handled later, when @SuppressWarnings\n+     *  can be taken into account.\n+     *\n@@ -573,1 +638,0 @@\n-\/\/          System.out.println(\"doc comment = \");System.out.println(dc);\/\/DEBUG\n@@ -576,0 +640,47 @@\n+        reportDanglingComments(tree, dc);\n+    }\n+\n+    \/** Reports all dangling comments associated with the\n+     *  primary comment for a declaration against the position\n+     *  of the tree node for a declaration.\n+     *\n+     * @param tree the tree node for the declaration\n+     * @param dc the primary comment for the declaration\n+     *\/\n+    void reportDanglingComments(JCTree tree, Comment dc) {\n+        var list = danglingComments.remove(dc);\n+        if (list != null) {\n+            var prevPos = deferredLintHandler.setPos(tree);\n+            try {\n+                list.forEach(this::reportDanglingDocComment);\n+            } finally {\n+                deferredLintHandler.setPos(prevPos);\n+            }\n+        }\n+    }\n+\n+    \/**\n+     * Reports an individual dangling comment using the {@link #deferredLintHandler}.\n+     * The comment may or not may generate an actual diagnostic, depending on\n+     * the settings for {@code -Xlint} and\/or {@code @SuppressWarnings}.\n+     *\n+     * @param c the comment\n+     *\/\n+    void reportDanglingDocComment(Comment c) {\n+        var pos = c.getPos();\n+        if (pos != null) {\n+            deferredLintHandler.report(lint -> {\n+                if (lint.isEnabled(Lint.LintCategory.DANGLING_DOC_COMMENTS)) {\n+                    log.warning(Lint.LintCategory.DANGLING_DOC_COMMENTS,\n+                            pos, Warnings.DanglingDocComment);\n+                }\n+            });\n+        }\n+    }\n+\n+    \/**\n+     * Ignores any recent documentation comments found by the scanner,\n+     * such as those that cannot be associated with a nearby declaration.\n+     *\/\n+    private void ignoreDanglingComments() {\n+        S.getDocComments().clear();\n@@ -2649,0 +2760,1 @@\n+            ignoreDanglingComments(); \/\/ ignore any comments from before the '{'\n@@ -2701,0 +2813,1 @@\n+        ignoreDanglingComments();   \/\/ ignore any comments from before the '{'\n@@ -2732,0 +2845,1 @@\n+            ignoreDanglingComments();  \/\/ ignore comments not consumed by the statement\n@@ -2803,1 +2917,1 @@\n-                return localVariableDeclarations(mods, t);\n+                return localVariableDeclarations(mods, t, dc);\n@@ -2894,0 +3008,1 @@\n+        dc = token.docComment();\n@@ -2895,1 +3010,0 @@\n-            dc = token.docComment();\n@@ -2908,1 +3022,1 @@\n-                return localVariableDeclarations(mods, t);\n+                return localVariableDeclarations(mods, t, dc);\n@@ -2919,1 +3033,5 @@\n-        private List<JCStatement> localVariableDeclarations(JCModifiers mods, JCExpression type) {\n+        private List<JCStatement> localVariableDeclarations(JCModifiers mods, JCExpression type, Comment dc) {\n+            if (dc != null) {\n+                \/\/ ignore a well-placed doc comment, but save any misplaced ones\n+                saveDanglingDocComments(dc);\n+            }\n@@ -2947,0 +3065,1 @@\n+        ignoreDanglingComments(); \/\/ ignore comments before statement\n@@ -3685,0 +3804,2 @@\n+        saveDanglingDocComments(dc);\n+\n@@ -4264,0 +4385,3 @@\n+\n+        saveDanglingDocComments(dc);\n+\n@@ -4286,0 +4410,3 @@\n+\n+        saveDanglingDocComments(dc);\n+\n@@ -4345,0 +4472,3 @@\n+\n+        saveDanglingDocComments(dc);\n+\n@@ -4390,0 +4520,2 @@\n+        saveDanglingDocComments(dc);\n+\n@@ -4517,0 +4649,3 @@\n+\n+        saveDanglingDocComments(dc);\n+\n@@ -4519,0 +4654,1 @@\n+\n@@ -4623,0 +4759,1 @@\n+                ignoreDanglingComments();   \/\/ no declaration with which dangling comments can be associated\n@@ -4928,0 +5065,3 @@\n+\n+            saveDanglingDocComments(dc);\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/parser\/JavacParser.java","additions":145,"deletions":5,"binary":false,"changes":150,"status":"modified"},{"patch":"@@ -1872,0 +1872,3 @@\n+compiler.warn.dangling.doc.comment=\\\n+    documentation comment is not attached to any declaration\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/resources\/compiler.properties","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 1999, 2022, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 1999, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -192,0 +192,3 @@\n+javac.opt.Xlint.desc.dangling-doc-comments=\\\n+    Warn about dangling documentation comments, not attached to any declaration.\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/resources\/javac.properties","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -156,0 +156,2 @@\n+ * <tr><th scope=\"row\">{@code dangling-doc-comments} <td>issues related to \"dangling\" documentation comments,\n+ *                                                       not attached to a declaration\n","filename":"src\/jdk.compiler\/share\/classes\/module-info.java","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -117,1 +117,0 @@\n-runtime\/os\/TestTransparentHugePageUsage.java 8324776 linux-all\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"}]}