{"files":[{"patch":"@@ -1203,1 +1203,1 @@\n-            revision: \"3.0-16-jdk-asm+1.0\",\n+            revision: \"3.0-17-jdk-asm+1.0\",\n","filename":"make\/conf\/jib-profiles.js","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -5654,1 +5654,1 @@\n-operand cmpOpUEqNeLtGe()\n+operand cmpOpUEqNeLeGt()\n@@ -5659,4 +5659,4 @@\n-  predicate(n->as_Bool()->_test._test == BoolTest::eq\n-            || n->as_Bool()->_test._test == BoolTest::ne\n-            || n->as_Bool()->_test._test == BoolTest::lt\n-            || n->as_Bool()->_test._test == BoolTest::ge);\n+  predicate(n->as_Bool()->_test._test == BoolTest::eq ||\n+            n->as_Bool()->_test._test == BoolTest::ne ||\n+            n->as_Bool()->_test._test == BoolTest::le ||\n+            n->as_Bool()->_test._test == BoolTest::gt);\n@@ -5668,4 +5668,4 @@\n-    less(0xb, \"lt\");\n-    greater_equal(0xa, \"ge\");\n-    less_equal(0xd, \"le\");\n-    greater(0xc, \"gt\");\n+    less(0x3, \"lo\");\n+    greater_equal(0x2, \"hs\");\n+    less_equal(0x9, \"ls\");\n+    greater(0x8, \"hi\");\n@@ -7806,1 +7806,1 @@\n-            \"dmb ish\" %}\n+            \"dmb ishld\" %}\n@@ -7860,1 +7860,1 @@\n-            \"dmb ish\" %}\n+            \"dmb ishst\\n\\tdmb ishld\" %}\n@@ -7864,1 +7864,3 @@\n-    __ membar(Assembler::LoadStore|Assembler::StoreStore);\n+    \/\/ These will be merged if AlwaysMergeDMB is enabled.\n+    __ membar(Assembler::StoreStore);\n+    __ membar(Assembler::LoadStore);\n@@ -15743,1 +15745,1 @@\n-instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{\n+instruct cmpUI_imm0_branch(cmpOpUEqNeLeGt cmp, iRegIorL2I op1, immI0 op2, label labl) %{\n@@ -15752,1 +15754,1 @@\n-    if (cond == Assembler::EQ || cond == Assembler::LS)\n+    if (cond == Assembler::EQ || cond == Assembler::LS) {\n@@ -15754,1 +15756,2 @@\n-    else\n+    } else {\n+      assert(cond == Assembler::NE || cond == Assembler::HI, \"unexpected condition\");\n@@ -15756,0 +15759,1 @@\n+    }\n@@ -15760,1 +15764,1 @@\n-instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{\n+instruct cmpUL_imm0_branch(cmpOpUEqNeLeGt cmp, iRegL op1, immL0 op2, label labl) %{\n@@ -15769,1 +15773,1 @@\n-    if (cond == Assembler::EQ || cond == Assembler::LS)\n+    if (cond == Assembler::EQ || cond == Assembler::LS) {\n@@ -15771,1 +15775,2 @@\n-    else\n+    } else {\n+      assert(cond == Assembler::NE || cond == Assembler::HI, \"unexpected condition\");\n@@ -15773,0 +15778,1 @@\n+    }\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":24,"deletions":18,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -130,0 +130,2 @@\n+  product(bool, AlwaysMergeDMB, true, DIAGNOSTIC,                       \\\n+          \"Always merge DMB instructions in code emission\")             \\\n","filename":"src\/hotspot\/cpu\/aarch64\/globals_aarch64.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2509,7 +2509,27 @@\n-    \/\/ We are merging two memory barrier instructions.  On AArch64 we\n-    \/\/ can do this simply by ORing them together.\n-    bar->set_kind(bar->get_kind() | order_constraint);\n-    BLOCK_COMMENT(\"merged membar\");\n-  } else {\n-    code()->set_last_insn(pc());\n-    dmb(Assembler::barrier(order_constraint));\n+    if (AlwaysMergeDMB) {\n+      bar->set_kind(bar->get_kind() | order_constraint);\n+      BLOCK_COMMENT(\"merged membar(always)\");\n+      return;\n+    }\n+    \/\/ Don't promote DMB ST|DMB LD to DMB (a full barrier) because\n+    \/\/ doing so would introduce a StoreLoad which the caller did not\n+    \/\/ intend\n+    if (bar->get_kind() == order_constraint\n+        || bar->get_kind() == AnyAny\n+        || order_constraint == AnyAny) {\n+      \/\/ We are merging two memory barrier instructions.  On AArch64 we\n+      \/\/ can do this simply by ORing them together.\n+      bar->set_kind(bar->get_kind() | order_constraint);\n+      BLOCK_COMMENT(\"merged membar\");\n+      return;\n+    } else {\n+      \/\/ A special case like \"DMB ST;DMB LD;DMB ST\", the last DMB can be skipped\n+      \/\/ We need check the last 2 instructions\n+      address prev2 = prev - NativeMembar::instruction_size;\n+      if (last != code()->last_label() && nativeInstruction_at(prev2)->is_Membar()) {\n+        NativeMembar *bar2 = NativeMembar_at(prev2);\n+        assert(bar2->get_kind() == order_constraint, \"it should be merged before\");\n+        BLOCK_COMMENT(\"merged membar(elided)\");\n+        return;\n+      }\n+    }\n@@ -2517,0 +2537,2 @@\n+  code()->set_last_insn(pc());\n+  dmb(Assembler::barrier(order_constraint));\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":29,"deletions":7,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -158,0 +158,1 @@\n+    code()->set_last_label(pc());\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -3,1 +3,1 @@\n- * Copyright (c) 2012, 2023 SAP SE. All rights reserved.\n+ * Copyright (c) 2012, 2024 SAP SE. All rights reserved.\n@@ -1830,1 +1830,1 @@\n-  BasicType basic_type = default_type != nullptr ? default_type->element_type()->basic_type() : T_ILLEGAL;\n+  BasicType basic_type = (default_type != nullptr) ? default_type->element_type()->basic_type() : T_ILLEGAL;\n@@ -1835,1 +1835,0 @@\n-  const int frame_resize = frame::native_abi_reg_args_size - sizeof(frame::java_abi); \/\/ C calls need larger frame.\n@@ -1841,1 +1840,1 @@\n-  if (op->expected_type() == nullptr) {\n+  if (default_type == nullptr) {\n@@ -1876,1 +1875,1 @@\n-  assert(default_type != nullptr && default_type->is_array_klass(), \"must be true at this point\");\n+  assert(default_type != nullptr && default_type->is_array_klass() && default_type->is_loaded(), \"must be true at this point\");\n@@ -1971,1 +1970,5 @@\n-    __ b(cont);\n+    if (stub != nullptr) {\n+      __ b(cont);\n+      __ bind(slow);\n+      __ b(*stub->entry());\n+    }\n@@ -2092,0 +2095,2 @@\n+    __ bind(slow);\n+    __ b(*stub->entry());\n@@ -2093,2 +2098,0 @@\n-  __ bind(slow);\n-  __ b(*stub->entry());\n@@ -2107,1 +2110,1 @@\n-    metadata2reg(op->expected_type()->constant_encoding(), tmp);\n+    metadata2reg(default_type->constant_encoding(), tmp);\n@@ -2183,1 +2186,3 @@\n-  __ bind(*stub->continuation());\n+  if (stub != nullptr) {\n+    __ bind(*stub->continuation());\n+  }\n@@ -2304,1 +2309,2 @@\n-                      *op->stub()->entry());\n+                      *op->stub()->entry(),\n+                      op->zero_array());\n","filename":"src\/hotspot\/cpu\/ppc\/c1_LIRAssembler_ppc.cpp","additions":17,"deletions":11,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -200,304 +200,0 @@\n-#if INCLUDE_RTM_OPT\n-\n-\/\/ Update rtm_counters based on abort status\n-\/\/ input: abort_status\n-\/\/        rtm_counters (RTMLockingCounters*)\n-\/\/ flags are killed\n-void C2_MacroAssembler::rtm_counters_update(Register abort_status, Register rtm_counters) {\n-\n-  atomic_incptr(Address(rtm_counters, RTMLockingCounters::abort_count_offset()));\n-  if (PrintPreciseRTMLockingStatistics) {\n-    for (int i = 0; i < RTMLockingCounters::ABORT_STATUS_LIMIT; i++) {\n-      Label check_abort;\n-      testl(abort_status, (1<<i));\n-      jccb(Assembler::equal, check_abort);\n-      atomic_incptr(Address(rtm_counters, RTMLockingCounters::abortX_count_offset() + (i * sizeof(uintx))));\n-      bind(check_abort);\n-    }\n-  }\n-}\n-\n-\/\/ Branch if (random & (count-1) != 0), count is 2^n\n-\/\/ tmp, scr and flags are killed\n-void C2_MacroAssembler::branch_on_random_using_rdtsc(Register tmp, Register scr, int count, Label& brLabel) {\n-  assert(tmp == rax, \"\");\n-  assert(scr == rdx, \"\");\n-  rdtsc(); \/\/ modifies EDX:EAX\n-  andptr(tmp, count-1);\n-  jccb(Assembler::notZero, brLabel);\n-}\n-\n-\/\/ Perform abort ratio calculation, set no_rtm bit if high ratio\n-\/\/ input:  rtm_counters_Reg (RTMLockingCounters* address)\n-\/\/ tmpReg, rtm_counters_Reg and flags are killed\n-void C2_MacroAssembler::rtm_abort_ratio_calculation(Register tmpReg,\n-                                                    Register rtm_counters_Reg,\n-                                                    RTMLockingCounters* rtm_counters,\n-                                                    Metadata* method_data) {\n-  Label L_done, L_check_always_rtm1, L_check_always_rtm2;\n-\n-  if (RTMLockingCalculationDelay > 0) {\n-    \/\/ Delay calculation\n-    movptr(tmpReg, ExternalAddress((address) RTMLockingCounters::rtm_calculation_flag_addr()));\n-    testptr(tmpReg, tmpReg);\n-    jccb(Assembler::equal, L_done);\n-  }\n-  \/\/ Abort ratio calculation only if abort_count > RTMAbortThreshold\n-  \/\/   Aborted transactions = abort_count * 100\n-  \/\/   All transactions = total_count *  RTMTotalCountIncrRate\n-  \/\/   Set no_rtm bit if (Aborted transactions >= All transactions * RTMAbortRatio)\n-\n-  movptr(tmpReg, Address(rtm_counters_Reg, RTMLockingCounters::abort_count_offset()));\n-  cmpptr(tmpReg, RTMAbortThreshold);\n-  jccb(Assembler::below, L_check_always_rtm2);\n-  imulptr(tmpReg, tmpReg, 100);\n-\n-  Register scrReg = rtm_counters_Reg;\n-  movptr(scrReg, Address(rtm_counters_Reg, RTMLockingCounters::total_count_offset()));\n-  imulptr(scrReg, scrReg, RTMTotalCountIncrRate);\n-  imulptr(scrReg, scrReg, RTMAbortRatio);\n-  cmpptr(tmpReg, scrReg);\n-  jccb(Assembler::below, L_check_always_rtm1);\n-  if (method_data != nullptr) {\n-    \/\/ set rtm_state to \"no rtm\" in MDO\n-    mov_metadata(tmpReg, method_data);\n-    lock();\n-    orl(Address(tmpReg, MethodData::rtm_state_offset()), NoRTM);\n-  }\n-  jmpb(L_done);\n-  bind(L_check_always_rtm1);\n-  \/\/ Reload RTMLockingCounters* address\n-  lea(rtm_counters_Reg, ExternalAddress((address)rtm_counters));\n-  bind(L_check_always_rtm2);\n-  movptr(tmpReg, Address(rtm_counters_Reg, RTMLockingCounters::total_count_offset()));\n-  cmpptr(tmpReg, RTMLockingThreshold \/ RTMTotalCountIncrRate);\n-  jccb(Assembler::below, L_done);\n-  if (method_data != nullptr) {\n-    \/\/ set rtm_state to \"always rtm\" in MDO\n-    mov_metadata(tmpReg, method_data);\n-    lock();\n-    orl(Address(tmpReg, MethodData::rtm_state_offset()), UseRTM);\n-  }\n-  bind(L_done);\n-}\n-\n-\/\/ Update counters and perform abort ratio calculation\n-\/\/ input:  abort_status_Reg\n-\/\/ rtm_counters_Reg, flags are killed\n-void C2_MacroAssembler::rtm_profiling(Register abort_status_Reg,\n-                                      Register rtm_counters_Reg,\n-                                      RTMLockingCounters* rtm_counters,\n-                                      Metadata* method_data,\n-                                      bool profile_rtm) {\n-\n-  assert(rtm_counters != nullptr, \"should not be null when profiling RTM\");\n-  \/\/ update rtm counters based on rax value at abort\n-  \/\/ reads abort_status_Reg, updates flags\n-  lea(rtm_counters_Reg, ExternalAddress((address)rtm_counters));\n-  rtm_counters_update(abort_status_Reg, rtm_counters_Reg);\n-  if (profile_rtm) {\n-    \/\/ Save abort status because abort_status_Reg is used by following code.\n-    if (RTMRetryCount > 0) {\n-      push(abort_status_Reg);\n-    }\n-    assert(rtm_counters != nullptr, \"should not be null when profiling RTM\");\n-    rtm_abort_ratio_calculation(abort_status_Reg, rtm_counters_Reg, rtm_counters, method_data);\n-    \/\/ restore abort status\n-    if (RTMRetryCount > 0) {\n-      pop(abort_status_Reg);\n-    }\n-  }\n-}\n-\n-\/\/ Retry on abort if abort's status is 0x6: can retry (0x2) | memory conflict (0x4)\n-\/\/ inputs: retry_count_Reg\n-\/\/       : abort_status_Reg\n-\/\/ output: retry_count_Reg decremented by 1\n-\/\/ flags are killed\n-void C2_MacroAssembler::rtm_retry_lock_on_abort(Register retry_count_Reg, Register abort_status_Reg, Label& retryLabel) {\n-  Label doneRetry;\n-  assert(abort_status_Reg == rax, \"\");\n-  \/\/ The abort reason bits are in eax (see all states in rtmLocking.hpp)\n-  \/\/ 0x6 = conflict on which we can retry (0x2) | memory conflict (0x4)\n-  \/\/ if reason is in 0x6 and retry count != 0 then retry\n-  andptr(abort_status_Reg, 0x6);\n-  jccb(Assembler::zero, doneRetry);\n-  testl(retry_count_Reg, retry_count_Reg);\n-  jccb(Assembler::zero, doneRetry);\n-  pause();\n-  decrementl(retry_count_Reg);\n-  jmp(retryLabel);\n-  bind(doneRetry);\n-}\n-\n-\/\/ Spin and retry if lock is busy,\n-\/\/ inputs: box_Reg (monitor address)\n-\/\/       : retry_count_Reg\n-\/\/ output: retry_count_Reg decremented by 1\n-\/\/       : clear z flag if retry count exceeded\n-\/\/ tmp_Reg, scr_Reg, flags are killed\n-void C2_MacroAssembler::rtm_retry_lock_on_busy(Register retry_count_Reg, Register box_Reg,\n-                                               Register tmp_Reg, Register scr_Reg, Label& retryLabel) {\n-  Label SpinLoop, SpinExit, doneRetry;\n-  int owner_offset = OM_OFFSET_NO_MONITOR_VALUE_TAG(owner);\n-\n-  testl(retry_count_Reg, retry_count_Reg);\n-  jccb(Assembler::zero, doneRetry);\n-  decrementl(retry_count_Reg);\n-  movptr(scr_Reg, RTMSpinLoopCount);\n-\n-  bind(SpinLoop);\n-  pause();\n-  decrementl(scr_Reg);\n-  jccb(Assembler::lessEqual, SpinExit);\n-  movptr(tmp_Reg, Address(box_Reg, owner_offset));\n-  testptr(tmp_Reg, tmp_Reg);\n-  jccb(Assembler::notZero, SpinLoop);\n-\n-  bind(SpinExit);\n-  jmp(retryLabel);\n-  bind(doneRetry);\n-  incrementl(retry_count_Reg); \/\/ clear z flag\n-}\n-\n-\/\/ Use RTM for normal stack locks\n-\/\/ Input: objReg (object to lock)\n-void C2_MacroAssembler::rtm_stack_locking(Register objReg, Register tmpReg, Register scrReg,\n-                                         Register retry_on_abort_count_Reg,\n-                                         RTMLockingCounters* stack_rtm_counters,\n-                                         Metadata* method_data, bool profile_rtm,\n-                                         Label& DONE_LABEL, Label& IsInflated) {\n-  assert(UseRTMForStackLocks, \"why call this otherwise?\");\n-  assert(tmpReg == rax, \"\");\n-  assert(scrReg == rdx, \"\");\n-  Label L_rtm_retry, L_decrement_retry, L_on_abort;\n-\n-  if (RTMRetryCount > 0) {\n-    movl(retry_on_abort_count_Reg, RTMRetryCount); \/\/ Retry on abort\n-    bind(L_rtm_retry);\n-  }\n-  movptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes()));\n-  testptr(tmpReg, markWord::monitor_value);  \/\/ inflated vs stack-locked|neutral\n-  jcc(Assembler::notZero, IsInflated);\n-\n-  if (PrintPreciseRTMLockingStatistics || profile_rtm) {\n-    Label L_noincrement;\n-    if (RTMTotalCountIncrRate > 1) {\n-      \/\/ tmpReg, scrReg and flags are killed\n-      branch_on_random_using_rdtsc(tmpReg, scrReg, RTMTotalCountIncrRate, L_noincrement);\n-    }\n-    assert(stack_rtm_counters != nullptr, \"should not be null when profiling RTM\");\n-    atomic_incptr(ExternalAddress((address)stack_rtm_counters->total_count_addr()), scrReg);\n-    bind(L_noincrement);\n-  }\n-  xbegin(L_on_abort);\n-  movptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes()));       \/\/ fetch markword\n-  andptr(tmpReg, markWord::lock_mask_in_place);     \/\/ look at 2 lock bits\n-  cmpptr(tmpReg, markWord::unlocked_value);         \/\/ bits = 01 unlocked\n-  jcc(Assembler::equal, DONE_LABEL);        \/\/ all done if unlocked\n-\n-  Register abort_status_Reg = tmpReg; \/\/ status of abort is stored in RAX\n-  if (UseRTMXendForLockBusy) {\n-    xend();\n-    movptr(abort_status_Reg, 0x2);   \/\/ Set the abort status to 2 (so we can retry)\n-    jmp(L_decrement_retry);\n-  }\n-  else {\n-    xabort(0);\n-  }\n-  bind(L_on_abort);\n-  if (PrintPreciseRTMLockingStatistics || profile_rtm) {\n-    rtm_profiling(abort_status_Reg, scrReg, stack_rtm_counters, method_data, profile_rtm);\n-  }\n-  bind(L_decrement_retry);\n-  if (RTMRetryCount > 0) {\n-    \/\/ retry on lock abort if abort status is 'can retry' (0x2) or 'memory conflict' (0x4)\n-    rtm_retry_lock_on_abort(retry_on_abort_count_Reg, abort_status_Reg, L_rtm_retry);\n-  }\n-}\n-\n-\/\/ Use RTM for inflating locks\n-\/\/ inputs: objReg (object to lock)\n-\/\/         boxReg (on-stack box address (displaced header location) - KILLED)\n-\/\/         tmpReg (ObjectMonitor address + markWord::monitor_value)\n-void C2_MacroAssembler::rtm_inflated_locking(Register objReg, Register boxReg, Register tmpReg,\n-                                            Register scrReg, Register retry_on_busy_count_Reg,\n-                                            Register retry_on_abort_count_Reg,\n-                                            RTMLockingCounters* rtm_counters,\n-                                            Metadata* method_data, bool profile_rtm,\n-                                            Label& DONE_LABEL) {\n-  assert(UseRTMLocking, \"why call this otherwise?\");\n-  assert(tmpReg == rax, \"\");\n-  assert(scrReg == rdx, \"\");\n-  Label L_rtm_retry, L_decrement_retry, L_on_abort;\n-  int owner_offset = OM_OFFSET_NO_MONITOR_VALUE_TAG(owner);\n-\n-  movptr(Address(boxReg, 0), checked_cast<int32_t>(markWord::unused_mark().value()));\n-  movptr(boxReg, tmpReg); \/\/ Save ObjectMonitor address\n-\n-  if (RTMRetryCount > 0) {\n-    movl(retry_on_busy_count_Reg, RTMRetryCount);  \/\/ Retry on lock busy\n-    movl(retry_on_abort_count_Reg, RTMRetryCount); \/\/ Retry on abort\n-    bind(L_rtm_retry);\n-  }\n-  if (PrintPreciseRTMLockingStatistics || profile_rtm) {\n-    Label L_noincrement;\n-    if (RTMTotalCountIncrRate > 1) {\n-      \/\/ tmpReg, scrReg and flags are killed\n-      branch_on_random_using_rdtsc(tmpReg, scrReg, RTMTotalCountIncrRate, L_noincrement);\n-    }\n-    assert(rtm_counters != nullptr, \"should not be null when profiling RTM\");\n-    atomic_incptr(ExternalAddress((address)rtm_counters->total_count_addr()), scrReg);\n-    bind(L_noincrement);\n-  }\n-  xbegin(L_on_abort);\n-  movptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes()));\n-  movptr(tmpReg, Address(tmpReg, owner_offset));\n-  testptr(tmpReg, tmpReg);\n-  jcc(Assembler::zero, DONE_LABEL);\n-  if (UseRTMXendForLockBusy) {\n-    xend();\n-    jmp(L_decrement_retry);\n-  }\n-  else {\n-    xabort(0);\n-  }\n-  bind(L_on_abort);\n-  Register abort_status_Reg = tmpReg; \/\/ status of abort is stored in RAX\n-  if (PrintPreciseRTMLockingStatistics || profile_rtm) {\n-    rtm_profiling(abort_status_Reg, scrReg, rtm_counters, method_data, profile_rtm);\n-  }\n-  if (RTMRetryCount > 0) {\n-    \/\/ retry on lock abort if abort status is 'can retry' (0x2) or 'memory conflict' (0x4)\n-    rtm_retry_lock_on_abort(retry_on_abort_count_Reg, abort_status_Reg, L_rtm_retry);\n-  }\n-\n-  movptr(tmpReg, Address(boxReg, owner_offset)) ;\n-  testptr(tmpReg, tmpReg) ;\n-  jccb(Assembler::notZero, L_decrement_retry) ;\n-\n-  \/\/ Appears unlocked - try to swing _owner from null to non-null.\n-  \/\/ Invariant: tmpReg == 0.  tmpReg is EAX which is the implicit cmpxchg comparand.\n-#ifdef _LP64\n-  Register threadReg = r15_thread;\n-#else\n-  get_thread(scrReg);\n-  Register threadReg = scrReg;\n-#endif\n-  lock();\n-  cmpxchgptr(threadReg, Address(boxReg, owner_offset)); \/\/ Updates tmpReg\n-\n-  if (RTMRetryCount > 0) {\n-    \/\/ success done else retry\n-    jccb(Assembler::equal, DONE_LABEL) ;\n-    bind(L_decrement_retry);\n-    \/\/ Spin and retry if lock is busy.\n-    rtm_retry_lock_on_busy(retry_on_busy_count_Reg, boxReg, tmpReg, scrReg, L_rtm_retry);\n-  }\n-  else {\n-    bind(L_decrement_retry);\n-  }\n-}\n-\n-#endif \/\/  INCLUDE_RTM_OPT\n-\n@@ -582,4 +278,1 @@\n-                                 RTMLockingCounters* rtm_counters,\n-                                 RTMLockingCounters* stack_rtm_counters,\n-                                 Metadata* method_data,\n-                                 bool use_rtm, bool profile_rtm) {\n+                                 Metadata* method_data) {\n@@ -589,8 +282,3 @@\n-\n-  if (use_rtm) {\n-    assert_different_registers(objReg, boxReg, tmpReg, scrReg, cx1Reg, cx2Reg);\n-  } else {\n-    assert(cx1Reg == noreg, \"\");\n-    assert(cx2Reg == noreg, \"\");\n-    assert_different_registers(objReg, boxReg, tmpReg, scrReg);\n-  }\n+  assert(cx1Reg == noreg, \"\");\n+  assert(cx2Reg == noreg, \"\");\n+  assert_different_registers(objReg, boxReg, tmpReg, scrReg);\n@@ -622,9 +310,0 @@\n-#if INCLUDE_RTM_OPT\n-  if (UseRTMForStackLocks && use_rtm) {\n-    assert(LockingMode != LM_MONITOR, \"LockingMode == 0 (LM_MONITOR) and +UseRTMForStackLocks are mutually exclusive\");\n-    rtm_stack_locking(objReg, tmpReg, scrReg, cx2Reg,\n-                      stack_rtm_counters, method_data, profile_rtm,\n-                      DONE_LABEL, IsInflated);\n-  }\n-#endif \/\/ INCLUDE_RTM_OPT\n-\n@@ -664,8 +343,0 @@\n-#if INCLUDE_RTM_OPT\n-  \/\/ Use the same RTM locking code in 32- and 64-bit VM.\n-  if (use_rtm) {\n-    rtm_inflated_locking(objReg, boxReg, tmpReg, scrReg, cx1Reg, cx2Reg,\n-                         rtm_counters, method_data, profile_rtm, DONE_LABEL);\n-  } else {\n-#endif \/\/ INCLUDE_RTM_OPT\n-\n@@ -732,3 +403,0 @@\n-#if INCLUDE_RTM_OPT\n-  } \/\/ use_rtm()\n-#endif\n@@ -787,1 +455,1 @@\n-void C2_MacroAssembler::fast_unlock(Register objReg, Register boxReg, Register tmpReg, bool use_rtm) {\n+void C2_MacroAssembler::fast_unlock(Register objReg, Register boxReg, Register tmpReg) {\n@@ -794,14 +462,0 @@\n-#if INCLUDE_RTM_OPT\n-  if (UseRTMForStackLocks && use_rtm) {\n-    assert(LockingMode != LM_MONITOR, \"LockingMode == 0 (LM_MONITOR) and +UseRTMForStackLocks are mutually exclusive\");\n-    Label L_regular_unlock;\n-    movptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ fetch markword\n-    andptr(tmpReg, markWord::lock_mask_in_place);                     \/\/ look at 2 lock bits\n-    cmpptr(tmpReg, markWord::unlocked_value);                         \/\/ bits = 01 unlocked\n-    jccb(Assembler::notEqual, L_regular_unlock);                      \/\/ if !HLE RegularLock\n-    xend();                                                           \/\/ otherwise end...\n-    jmp(DONE_LABEL);                                                  \/\/ ... and we're done\n-    bind(L_regular_unlock);\n-  }\n-#endif\n-\n@@ -820,13 +474,0 @@\n-#if INCLUDE_RTM_OPT\n-  if (use_rtm) {\n-    Label L_regular_inflated_unlock;\n-    int owner_offset = OM_OFFSET_NO_MONITOR_VALUE_TAG(owner);\n-    movptr(boxReg, Address(tmpReg, owner_offset));\n-    testptr(boxReg, boxReg);\n-    jccb(Assembler::notZero, L_regular_inflated_unlock);\n-    xend();\n-    jmp(DONE_LABEL);\n-    bind(L_regular_inflated_unlock);\n-  }\n-#endif\n-\n@@ -4523,1 +4164,3 @@\n-                                      XMMRegister vec1, XMMRegister vec2, bool is_char, KRegister mask) {\n+                                      XMMRegister vec1, XMMRegister vec2, bool is_char,\n+                                      KRegister mask, bool expand_ary2) {\n+  \/\/ for expand_ary2, limit is the (smaller) size of the second array.\n@@ -4527,0 +4170,3 @@\n+  assert((!expand_ary2) || ((expand_ary2) && (UseAVX == 2)),\n+         \"Expansion only implemented for AVX2\");\n+\n@@ -4530,0 +4176,3 @@\n+  Address::ScaleFactor scaleFactor = expand_ary2 ? Address::times_2 : Address::times_1;\n+  int scaleIncr = expand_ary2 ? 8 : 16;\n+\n@@ -4565,1 +4214,1 @@\n-    Label COMPARE_WIDE_VECTORS, COMPARE_TAIL;\n+    Label COMPARE_WIDE_VECTORS, COMPARE_WIDE_VECTORS_16, COMPARE_TAIL, COMPARE_TAIL_16;\n@@ -4568,3 +4217,9 @@\n-    andl(result, 0x0000001f);  \/\/   tail count (in bytes)\n-    andl(limit, 0xffffffe0);   \/\/ vector count (in bytes)\n-    jcc(Assembler::zero, COMPARE_TAIL);\n+    if (expand_ary2) {\n+      andl(result, 0x0000000f);  \/\/   tail count (in bytes)\n+      andl(limit, 0xfffffff0);   \/\/ vector count (in bytes)\n+      jcc(Assembler::zero, COMPARE_TAIL);\n+    } else {\n+      andl(result, 0x0000001f);  \/\/   tail count (in bytes)\n+      andl(limit, 0xffffffe0);   \/\/ vector count (in bytes)\n+      jcc(Assembler::zero, COMPARE_TAIL_16);\n+    }\n@@ -4572,1 +4227,1 @@\n-    lea(ary1, Address(ary1, limit, Address::times_1));\n+    lea(ary1, Address(ary1, limit, scaleFactor));\n@@ -4615,2 +4270,6 @@\n-    vmovdqu(vec1, Address(ary1, limit, Address::times_1));\n-    vmovdqu(vec2, Address(ary2, limit, Address::times_1));\n+    vmovdqu(vec1, Address(ary1, limit, scaleFactor));\n+    if (expand_ary2) {\n+      vpmovzxbw(vec2, Address(ary2, limit, Address::times_1), Assembler::AVX_256bit);\n+    } else {\n+      vmovdqu(vec2, Address(ary2, limit, Address::times_1));\n+    }\n@@ -4621,1 +4280,1 @@\n-    addptr(limit, 32);\n+    addptr(limit, scaleIncr * 2);\n@@ -4627,2 +4286,6 @@\n-    vmovdqu(vec1, Address(ary1, result, Address::times_1, -32));\n-    vmovdqu(vec2, Address(ary2, result, Address::times_1, -32));\n+    vmovdqu(vec1, Address(ary1, result, scaleFactor, -32));\n+    if (expand_ary2) {\n+      vpmovzxbw(vec2, Address(ary2, result, Address::times_1, -16), Assembler::AVX_256bit);\n+    } else {\n+      vmovdqu(vec2, Address(ary2, result, Address::times_1, -32));\n+    }\n@@ -4632,2 +4295,28 @@\n-    jccb(Assembler::notZero, FALSE_LABEL);\n-    jmpb(TRUE_LABEL);\n+    jcc(Assembler::notZero, FALSE_LABEL);\n+    jmp(TRUE_LABEL);\n+\n+    bind(COMPARE_TAIL_16); \/\/ limit is zero\n+    movl(limit, result);\n+\n+    \/\/ Compare 16-byte chunks\n+    andl(result, 0x0000000f);  \/\/   tail count (in bytes)\n+    andl(limit, 0xfffffff0);   \/\/ vector count (in bytes)\n+    jcc(Assembler::zero, COMPARE_TAIL);\n+\n+    lea(ary1, Address(ary1, limit, scaleFactor));\n+    lea(ary2, Address(ary2, limit, Address::times_1));\n+    negptr(limit);\n+\n+    bind(COMPARE_WIDE_VECTORS_16);\n+    movdqu(vec1, Address(ary1, limit, scaleFactor));\n+    if (expand_ary2) {\n+      vpmovzxbw(vec2, Address(ary2, limit, Address::times_1), Assembler::AVX_128bit);\n+    } else {\n+      movdqu(vec2, Address(ary2, limit, Address::times_1));\n+    }\n+    pxor(vec1, vec2);\n+\n+    ptest(vec1, vec1);\n+    jcc(Assembler::notZero, FALSE_LABEL);\n+    addptr(limit, scaleIncr);\n+    jcc(Assembler::notZero, COMPARE_WIDE_VECTORS_16);\n@@ -4678,2 +4367,7 @@\n-  andl(limit, 0xfffffffc); \/\/ vector count (in bytes)\n-  jccb(Assembler::zero, COMPARE_CHAR);\n+  if (expand_ary2) {\n+    testl(result, result);\n+    jccb(Assembler::zero, TRUE_LABEL);\n+  } else {\n+    andl(limit, 0xfffffffc); \/\/ vector count (in bytes)\n+    jccb(Assembler::zero, COMPARE_CHAR);\n+  }\n@@ -4681,1 +4375,1 @@\n-  lea(ary1, Address(ary1, limit, Address::times_1));\n+  lea(ary1, Address(ary1, limit, scaleFactor));\n@@ -4686,5 +4380,15 @@\n-  movl(chr, Address(ary1, limit, Address::times_1));\n-  cmpl(chr, Address(ary2, limit, Address::times_1));\n-  jccb(Assembler::notEqual, FALSE_LABEL);\n-  addptr(limit, 4);\n-  jcc(Assembler::notZero, COMPARE_VECTORS);\n+  if (expand_ary2) {\n+    \/\/ There are no \"vector\" operations for bytes to shorts\n+    movzbl(chr, Address(ary2, limit, Address::times_1));\n+    cmpw(Address(ary1, limit, Address::times_2), chr);\n+    jccb(Assembler::notEqual, FALSE_LABEL);\n+    addptr(limit, 1);\n+    jcc(Assembler::notZero, COMPARE_VECTORS);\n+    jmp(TRUE_LABEL);\n+  } else {\n+    movl(chr, Address(ary1, limit, Address::times_1));\n+    cmpl(chr, Address(ary2, limit, Address::times_1));\n+    jccb(Assembler::notEqual, FALSE_LABEL);\n+    addptr(limit, 4);\n+    jcc(Assembler::notZero, COMPARE_VECTORS);\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":89,"deletions":385,"binary":false,"changes":474,"status":"modified"},{"patch":"@@ -41,5 +41,2 @@\n-                 RTMLockingCounters* rtm_counters,\n-                 RTMLockingCounters* stack_rtm_counters,\n-                 Metadata* method_data,\n-                 bool use_rtm, bool profile_rtm);\n-  void fast_unlock(Register obj, Register box, Register tmp, bool use_rtm);\n+                 Metadata* method_data);\n+  void fast_unlock(Register obj, Register box, Register tmp);\n@@ -51,23 +48,0 @@\n-#if INCLUDE_RTM_OPT\n-  void rtm_counters_update(Register abort_status, Register rtm_counters);\n-  void branch_on_random_using_rdtsc(Register tmp, Register scr, int count, Label& brLabel);\n-  void rtm_abort_ratio_calculation(Register tmp, Register rtm_counters_reg,\n-                                   RTMLockingCounters* rtm_counters,\n-                                   Metadata* method_data);\n-  void rtm_profiling(Register abort_status_Reg, Register rtm_counters_Reg,\n-                     RTMLockingCounters* rtm_counters, Metadata* method_data, bool profile_rtm);\n-  void rtm_retry_lock_on_abort(Register retry_count, Register abort_status, Label& retryLabel);\n-  void rtm_retry_lock_on_busy(Register retry_count, Register box, Register tmp, Register scr, Label& retryLabel);\n-  void rtm_stack_locking(Register obj, Register tmp, Register scr,\n-                         Register retry_on_abort_count,\n-                         RTMLockingCounters* stack_rtm_counters,\n-                         Metadata* method_data, bool profile_rtm,\n-                         Label& DONE_LABEL, Label& IsInflated);\n-  void rtm_inflated_locking(Register obj, Register box, Register tmp,\n-                            Register scr, Register retry_on_busy_count,\n-                            Register retry_on_abort_count,\n-                            RTMLockingCounters* rtm_counters,\n-                            Metadata* method_data, bool profile_rtm,\n-                            Label& DONE_LABEL);\n-#endif\n-\n@@ -293,0 +267,1 @@\n+\n@@ -294,3 +269,3 @@\n-  void arrays_equals(bool is_array_equ, Register ary1, Register ary2,\n-                     Register limit, Register result, Register chr,\n-                     XMMRegister vec1, XMMRegister vec2, bool is_char, KRegister mask = knoreg);\n+  void arrays_equals(bool is_array_equ, Register ary1, Register ary2, Register limit,\n+                     Register result, Register chr, XMMRegister vec1, XMMRegister vec2,\n+                     bool is_char, KRegister mask = knoreg, bool expand_ary2 = false);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":6,"deletions":31,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -121,0 +121,4 @@\n+                                                                            \\\n+  product(bool, UseAPX, false, EXPERIMENTAL,                                \\\n+          \"Use Intel Advanced Performance Extensions\")                      \\\n+                                                                            \\\n@@ -157,45 +161,0 @@\n-  \/* Use Restricted Transactional Memory for lock eliding *\/                \\\n-  product(bool, UseRTMLocking, false,                                       \\\n-          \"(Deprecated) Enable RTM lock eliding for inflated locks \"        \\\n-          \"in compiled code\")                                               \\\n-                                                                            \\\n-  product(bool, UseRTMForStackLocks, false, EXPERIMENTAL,                   \\\n-          \"Enable RTM lock eliding for stack locks in compiled code\")       \\\n-                                                                            \\\n-  product(bool, UseRTMDeopt, false,                                         \\\n-          \"(Deprecated) Perform deopt and recompilation based on \"          \\\n-          \"RTM abort ratio\")                                                \\\n-                                                                            \\\n-  product(int, RTMRetryCount, 5,                                            \\\n-          \"(Deprecated) Number of RTM retries on lock abort or busy\")       \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(int, RTMSpinLoopCount, 100, EXPERIMENTAL,                         \\\n-          \"Spin count for lock to become free before RTM retry\")            \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(int, RTMAbortThreshold, 1000, EXPERIMENTAL,                       \\\n-          \"Calculate abort ratio after this number of aborts\")              \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(int, RTMLockingThreshold, 10000, EXPERIMENTAL,                    \\\n-          \"Lock count at which to do RTM lock eliding without \"             \\\n-          \"abort ratio calculation\")                                        \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product(int, RTMAbortRatio, 50, EXPERIMENTAL,                             \\\n-          \"Lock abort ratio at which to stop use RTM lock eliding\")         \\\n-          range(0, 100) \/* natural range *\/                                 \\\n-                                                                            \\\n-  product(int, RTMTotalCountIncrRate, 64, EXPERIMENTAL,                     \\\n-          \"Increment total RTM attempted lock count once every n times\")    \\\n-          range(1, max_jint)                                                \\\n-          constraint(RTMTotalCountIncrRateConstraintFunc,AfterErgo)         \\\n-                                                                            \\\n-  product(intx, RTMLockingCalculationDelay, 0, EXPERIMENTAL,                \\\n-          \"Number of milliseconds to wait before start calculating aborts \" \\\n-          \"for RTM locking\")                                                \\\n-                                                                            \\\n-  product(bool, UseRTMXendForLockBusy, true, EXPERIMENTAL,                  \\\n-          \"Use RTM Xend instead of Xabort when lock busy\")                  \\\n-                                                                            \\\n@@ -240,2 +199,0 @@\n-  product(bool, UseAPX, false, EXPERIMENTAL,                                \\\n-          \"Use Advanced Performance Extensions on x86\")                     \\\n","filename":"src\/hotspot\/cpu\/x86\/globals_x86.hpp","additions":4,"deletions":47,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -33,1 +33,0 @@\n-#include \"runtime\/rtmLocking.hpp\"\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1494,7 +1494,0 @@\n-  if (UseRTMLocking) {\n-    \/\/ Abort RTM transaction before calling JNI\n-    \/\/ because critical section will be large and will be\n-    \/\/ aborted anyway. Also nmethod could be deoptimized.\n-    __ xabort(0);\n-  }\n-\n@@ -2440,5 +2433,0 @@\n-  if (UseRTMLocking) {\n-    \/\/ Abort RTM transaction before possible nmethod deoptimization.\n-    __ xabort(0);\n-  }\n-\n@@ -2627,7 +2615,0 @@\n-  if (UseRTMLocking) {\n-    \/\/ Abort RTM transaction before calling runtime\n-    \/\/ because critical section will be large and will be\n-    \/\/ aborted anyway. Also nmethod could be deoptimized.\n-    __ xabort(0);\n-  }\n-\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":0,"deletions":19,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -2232,7 +2232,0 @@\n-    if (UseRTMLocking) {\n-      \/\/ Abort RTM transaction before calling JNI\n-      \/\/ because critical section will be large and will be\n-      \/\/ aborted anyway. Also nmethod could be deoptimized.\n-      __ xabort(0);\n-    }\n-\n@@ -3198,5 +3191,0 @@\n-  if (UseRTMLocking) {\n-    \/\/ Abort RTM transaction before possible nmethod deoptimization.\n-    __ xabort(0);\n-  }\n-\n@@ -3389,7 +3377,0 @@\n-  if (UseRTMLocking) {\n-    \/\/ Abort RTM transaction before calling runtime\n-    \/\/ because critical section will be large and will be\n-    \/\/ aborted anyway. Also nmethod could be deoptimized.\n-    __ xabort(0);\n-  }\n-\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":0,"deletions":19,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -4414,0 +4414,6 @@\n+#ifdef COMPILER2\n+  if ((UseAVX == 2) && EnableX86ECoreOpts) {\n+    generate_string_indexof(StubRoutines::_string_indexof_array);\n+  }\n+#endif\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -578,0 +578,3 @@\n+#ifdef COMPILER2\n+  void generate_string_indexof(address *fnptrs);\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -59,0 +59,4 @@\n+\/\/ Address of instruction which causes APX specific SEGV\n+address VM_Version::_cpuinfo_segv_addr_apx = 0;\n+\/\/ Address of instruction after the one which causes APX specific SEGV\n+address VM_Version::_cpuinfo_cont_addr_apx = 0;\n@@ -66,0 +70,1 @@\n+  typedef void (*clear_apx_test_state_t)(void);\n@@ -69,0 +74,1 @@\n+static clear_apx_test_state_t clear_apx_test_state_stub = nullptr;\n@@ -105,0 +111,21 @@\n+  address clear_apx_test_state() {\n+#   define __ _masm->\n+    address start = __ pc();\n+    \/\/ EGPRs are call clobbered registers, Explicit clearing of r16 and r31 during signal\n+    \/\/ handling guarantees that preserved register values post signal handling were\n+    \/\/ re-instantiated by operating system and not because they were not modified externally.\n+\n+    \/* FIXME Uncomment following code after OS enablement of\n+    bool save_apx = UseAPX;\n+    VM_Version::set_apx_cpuFeatures();\n+    UseAPX = true;\n+    \/\/ EGPR state save\/restoration.\n+    __ mov64(r16, 0L);\n+    __ mov64(r31, 0L);\n+    UseAPX = save_apx;\n+    VM_Version::clean_cpuFeatures();\n+    *\/\n+    __ ret(0);\n+    return start;\n+  }\n+\n@@ -116,1 +143,2 @@\n-    Label sef_cpuid, ext_cpuid, ext_cpuid1, ext_cpuid5, ext_cpuid7, ext_cpuid8, done, wrapup;\n+    Label sef_cpuid, sefsl1_cpuid, ext_cpuid, ext_cpuid1, ext_cpuid5, ext_cpuid7;\n+    Label ext_cpuid8, done, wrapup, vector_save_restore, apx_save_restore_warning;\n@@ -291,1 +319,1 @@\n-    \/\/ cpuid(0x7) Structured Extended Features\n+    \/\/ cpuid(0x7) Structured Extended Features Enumeration Leaf.\n@@ -306,1 +334,4 @@\n-    \/\/ ECX = 1\n+    \/\/\n+    \/\/ cpuid(0x7) Structured Extended Features Enumeration Sub-Leaf 1.\n+    \/\/\n+    __ bind(sefsl1_cpuid);\n@@ -310,1 +341,1 @@\n-    __ lea(rsi, Address(rbp, in_bytes(VM_Version::sef_cpuid7_ecx1_offset())));\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::sefsl1_cpuid7_offset())));\n@@ -312,0 +343,1 @@\n+    __ movl(Address(rsi, 4), rdx);\n@@ -390,0 +422,40 @@\n+#ifndef PRODUCT\n+    \/\/\n+    \/\/ Check if OS has enabled XGETBV instruction to access XCR0\n+    \/\/ (OSXSAVE feature flag) and CPU supports APX\n+    \/\/\n+    \/\/ To enable APX, check CPUID.EAX=7.ECX=1.EDX[21] bit for HW support\n+    \/\/ and XCRO[19] bit for OS support to save\/restore extended GPR state.\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::sefsl1_cpuid7_offset())));\n+    __ movl(rax, 0x200000);\n+    __ andl(rax, Address(rsi, 4));\n+    __ cmpl(rax, 0x200000);\n+    __ jcc(Assembler::notEqual, vector_save_restore);\n+    \/\/ check _cpuid_info.xem_xcr0_eax.bits.apx_f\n+    __ movl(rax, 0x80000);\n+    __ andl(rax, Address(rbp, in_bytes(VM_Version::xem_xcr0_offset()))); \/\/ xcr0 bits apx_f\n+    __ cmpl(rax, 0x80000);\n+    __ jcc(Assembler::notEqual, vector_save_restore);\n+\n+    \/* FIXME: Uncomment while integrating JDK-8329032\n+    bool save_apx = UseAPX;\n+    VM_Version::set_apx_cpuFeatures();\n+    UseAPX = true;\n+    __ mov64(r16, VM_Version::egpr_test_value());\n+    __ mov64(r31, VM_Version::egpr_test_value());\n+    *\/\n+    __ xorl(rsi, rsi);\n+    VM_Version::set_cpuinfo_segv_addr_apx(__ pc());\n+    \/\/ Generate SEGV\n+    __ movl(rax, Address(rsi, 0));\n+\n+    VM_Version::set_cpuinfo_cont_addr_apx(__ pc());\n+    \/* FIXME: Uncomment after integration of JDK-8329032\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::apx_save_offset())));\n+    __ movq(Address(rsi, 0), r16);\n+    __ movq(Address(rsi, 8), r31);\n+\n+    UseAPX = save_apx;\n+    *\/\n+#endif\n+    __ bind(vector_save_restore);\n@@ -583,0 +655,1 @@\n+\n@@ -943,0 +1016,1 @@\n+\n@@ -966,0 +1040,10 @@\n+    _features &= ~CPU_APX_F;\n+  }\n+\n+  \/\/ Currently APX support is only enabled for targets supporting AVX512VL feature.\n+  bool apx_supported = os_supports_apx_egprs() && supports_apx_f() && supports_avx512vl();\n+  if (UseAPX && !apx_supported) {\n+    warning(\"UseAPX is not supported on this CPU, setting it to false\");\n+    FLAG_SET_DEFAULT(UseAPX, false);\n+  } else if (FLAG_IS_DEFAULT(UseAPX)) {\n+    FLAG_SET_DEFAULT(UseAPX, apx_supported ? true : false);\n@@ -1005,8 +1089,0 @@\n-  \/\/ APX support not enabled yet\n-  if (UseAPX) {\n-    if (!FLAG_IS_DEFAULT(UseAPX)) {\n-        warning(\"APX is not supported on this CPU.\");\n-    }\n-    FLAG_SET_DEFAULT(UseAPX, false);\n-  }\n-\n@@ -1249,49 +1325,0 @@\n-  if (!supports_rtm() && UseRTMLocking) {\n-    vm_exit_during_initialization(\"RTM instructions are not available on this CPU\");\n-  }\n-\n-#if INCLUDE_RTM_OPT\n-  if (UseRTMLocking) {\n-    if (!CompilerConfig::is_c2_enabled()) {\n-      \/\/ Only C2 does RTM locking optimization.\n-      vm_exit_during_initialization(\"RTM locking optimization is not supported in this VM\");\n-    }\n-    if (is_intel_family_core()) {\n-      if ((_model == CPU_MODEL_HASWELL_E3) ||\n-          (_model == CPU_MODEL_HASWELL_E7 && _stepping < 3) ||\n-          (_model == CPU_MODEL_BROADWELL  && _stepping < 4)) {\n-        \/\/ currently a collision between SKL and HSW_E3\n-        if (!UnlockExperimentalVMOptions && UseAVX < 3) {\n-          vm_exit_during_initialization(\"UseRTMLocking is only available as experimental option on this \"\n-                                        \"platform. It must be enabled via -XX:+UnlockExperimentalVMOptions flag.\");\n-        } else {\n-          warning(\"UseRTMLocking is only available as experimental option on this platform.\");\n-        }\n-      }\n-    }\n-    if (!FLAG_IS_CMDLINE(UseRTMLocking)) {\n-      \/\/ RTM locking should be used only for applications with\n-      \/\/ high lock contention. For now we do not use it by default.\n-      vm_exit_during_initialization(\"UseRTMLocking flag should be only set on command line\");\n-    }\n-  } else { \/\/ !UseRTMLocking\n-    if (UseRTMForStackLocks) {\n-      if (!FLAG_IS_DEFAULT(UseRTMForStackLocks)) {\n-        warning(\"UseRTMForStackLocks flag should be off when UseRTMLocking flag is off\");\n-      }\n-      FLAG_SET_DEFAULT(UseRTMForStackLocks, false);\n-    }\n-    if (UseRTMDeopt) {\n-      FLAG_SET_DEFAULT(UseRTMDeopt, false);\n-    }\n-    if (PrintPreciseRTMLockingStatistics) {\n-      FLAG_SET_DEFAULT(PrintPreciseRTMLockingStatistics, false);\n-    }\n-  }\n-#else\n-  if (UseRTMLocking) {\n-    \/\/ Only C2 does RTM locking optimization.\n-    vm_exit_during_initialization(\"RTM locking optimization is not supported in this VM\");\n-  }\n-#endif\n-\n@@ -2146,0 +2173,4 @@\n+void VM_Version::clear_apx_test_state() {\n+  clear_apx_test_state_stub();\n+}\n+\n@@ -2163,0 +2194,2 @@\n+  clear_apx_test_state_stub = CAST_TO_FN_PTR(clear_apx_test_state_t,\n+                                     g.clear_apx_test_state());\n@@ -2961,0 +2994,4 @@\n+  if (sefsl1_cpuid7_edx.bits.apx_f != 0 &&\n+      xem_xcr0_eax.bits.apx_f != 0) {\n+    result |= CPU_APX_F;\n+  }\n@@ -2971,1 +3008,1 @@\n-      if (sef_cpuid7_ecx1_eax.bits.avx_ifma != 0)\n+      if (sefsl1_cpuid7_eax.bits.avx_ifma != 0)\n@@ -3145,0 +3182,11 @@\n+bool VM_Version::os_supports_apx_egprs() {\n+  if (!supports_apx_f()) {\n+    return false;\n+  }\n+  if (_cpuid_info.apx_save[0] != egpr_test_value() ||\n+      _cpuid_info.apx_save[1] != egpr_test_value()) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":110,"deletions":62,"binary":false,"changes":172,"status":"modified"},{"patch":"@@ -13613,18 +13613,1 @@\n-instruct cmpFastLockRTM(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eDXRegI scr, rRegI cx1, rRegI cx2, eRegP thread) %{\n-  predicate(Compile::current()->use_rtm());\n-  match(Set cr (FastLock object box));\n-  effect(TEMP tmp, TEMP scr, TEMP cx1, TEMP cx2, USE_KILL box, TEMP thread);\n-  ins_cost(300);\n-  format %{ \"FASTLOCK $object,$box\\t! kills $box,$tmp,$scr,$cx1,$cx2\" %}\n-  ins_encode %{\n-    __ get_thread($thread$$Register);\n-    __ fast_lock($object$$Register, $box$$Register, $tmp$$Register,\n-                 $scr$$Register, $cx1$$Register, $cx2$$Register, $thread$$Register,\n-                 _rtm_counters, _stack_rtm_counters,\n-                 ((Method*)(ra_->C->method()->constant_encoding()))->method_data(),\n-                 true, ra_->C->profile_rtm());\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-  predicate(LockingMode != LM_LIGHTWEIGHT && !Compile::current()->use_rtm());\n+  predicate(LockingMode != LM_LIGHTWEIGHT);\n@@ -13639,1 +13622,1 @@\n-                 $scr$$Register, noreg, noreg, $thread$$Register, nullptr, nullptr, nullptr, false, false);\n+                 $scr$$Register, noreg, noreg, $thread$$Register, nullptr);\n@@ -13651,1 +13634,1 @@\n-    __ fast_unlock($object$$Register, $box$$Register, $tmp$$Register, ra_->C->use_rtm());\n+    __ fast_unlock($object$$Register, $box$$Register, $tmp$$Register);\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":3,"deletions":20,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -12514,17 +12514,1 @@\n-instruct cmpFastLockRTM(rFlagsReg cr, rRegP object, rbx_RegP box, rax_RegI tmp, rdx_RegI scr, rRegI cx1, rRegI cx2) %{\n-  predicate(Compile::current()->use_rtm());\n-  match(Set cr (FastLock object box));\n-  effect(TEMP tmp, TEMP scr, TEMP cx1, TEMP cx2, USE_KILL box);\n-  ins_cost(300);\n-  format %{ \"fastlock $object,$box\\t! kills $box,$tmp,$scr,$cx1,$cx2\" %}\n-  ins_encode %{\n-    __ fast_lock($object$$Register, $box$$Register, $tmp$$Register,\n-                 $scr$$Register, $cx1$$Register, $cx2$$Register, r15_thread,\n-                 _rtm_counters, _stack_rtm_counters,\n-                 ((Method*)(ra_->C->method()->constant_encoding()))->method_data(),\n-                 true, ra_->C->profile_rtm());\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-  predicate(LockingMode != LM_LIGHTWEIGHT && !Compile::current()->use_rtm());\n+  predicate(LockingMode != LM_LIGHTWEIGHT);\n@@ -12538,1 +12522,1 @@\n-                 $scr$$Register, noreg, noreg, r15_thread, nullptr, nullptr, nullptr, false, false);\n+                 $scr$$Register, noreg, noreg, r15_thread, nullptr);\n@@ -12550,1 +12534,1 @@\n-    __ fast_unlock($object$$Register, $box$$Register, $tmp$$Register, ra_->C->use_rtm());\n+    __ fast_unlock($object$$Register, $box$$Register, $tmp$$Register);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":3,"deletions":19,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -443,0 +443,1 @@\n+  address      _last_label;     \/\/ record last bind label address, it's also the start of current bb.\n@@ -467,0 +468,1 @@\n+    _last_label      = nullptr;\n@@ -520,0 +522,3 @@\n+  \/\/ adjust some internal address during expand\n+  void adjust_internal_address(address from, address to);\n+\n@@ -689,0 +694,3 @@\n+  address last_label() const { return _last_label; }\n+  void set_last_label(address a) { _last_label = a; }\n+\n","filename":"src\/hotspot\/share\/asm\/codeBuffer.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -388,1 +388,1 @@\n-#if defined(X86) || defined(AARCH64) || defined(S390) || defined(RISCV)\n+#if defined(X86) || defined(AARCH64) || defined(S390) || defined(RISCV) || defined(PPC64)\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1041,2 +1041,1 @@\n-                            int immediate_oops_patched,\n-                            RTMState  rtm_state) {\n+                            int immediate_oops_patched) {\n@@ -1099,8 +1098,0 @@\n-#if INCLUDE_RTM_OPT\n-    if (!failing() && (rtm_state != NoRTM) &&\n-        (method()->method_data() != nullptr) &&\n-        (method()->method_data()->rtm_state() != rtm_state)) {\n-      \/\/ Preemptive decompile if rtm state was changed.\n-      record_failure(\"RTM state change invalidated rtm code\");\n-    }\n-#endif\n@@ -1143,3 +1134,0 @@\n-#if INCLUDE_RTM_OPT\n-      nm->set_rtm_state(rtm_state);\n-#endif\n","filename":"src\/hotspot\/share\/ci\/ciEnv.cpp","additions":1,"deletions":13,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -390,2 +390,1 @@\n-                       int                       immediate_oops_patched,\n-                       RTMState                  rtm_state = NoRTM);\n+                       int                       immediate_oops_patched);\n","filename":"src\/hotspot\/share\/ci\/ciEnv.hpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -539,11 +539,0 @@\n-#if INCLUDE_RTM_OPT\n-  \/\/ return cached value\n-  int rtm_state() {\n-    if (is_empty()) {\n-      return NoRTM;\n-    } else {\n-      return get_MethodData()->rtm_state();\n-    }\n-  }\n-#endif\n-\n","filename":"src\/hotspot\/share\/ci\/ciMethodData.hpp","additions":1,"deletions":12,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -1243,3 +1243,0 @@\n-#if INCLUDE_RTM_OPT\n-  _rtm_state                  = NoRTM;\n-#endif\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -268,6 +268,0 @@\n-#if INCLUDE_RTM_OPT\n-  \/\/ RTM state at compile time. Used during deoptimization to decide\n-  \/\/ whether to restart collecting RTM locking abort statistic again.\n-  RTMState _rtm_state;\n-#endif\n-\n@@ -640,6 +634,0 @@\n-#if INCLUDE_RTM_OPT\n-  \/\/ rtm state accessing and manipulating\n-  RTMState  rtm_state() const          { return _rtm_state; }\n-  void set_rtm_state(RTMState state)   { _rtm_state = state; }\n-#endif\n-\n","filename":"src\/hotspot\/share\/code\/nmethod.hpp","additions":0,"deletions":12,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -204,182 +204,0 @@\n-#ifndef PRODUCT\n-const char* PSParallelCompact::space_names[] = {\n-  \"old \", \"eden\", \"from\", \"to  \"\n-};\n-\n-void PSParallelCompact::print_region_ranges() {\n-  if (!log_develop_is_enabled(Trace, gc, compaction)) {\n-    return;\n-  }\n-  Log(gc, compaction) log;\n-  ResourceMark rm;\n-  LogStream ls(log.trace());\n-  Universe::print_on(&ls);\n-  log.trace(\"space  bottom     top        end        new_top\");\n-  log.trace(\"------ ---------- ---------- ---------- ----------\");\n-\n-  for (unsigned int id = 0; id < last_space_id; ++id) {\n-    const MutableSpace* space = _space_info[id].space();\n-    log.trace(\"%u %s \"\n-              SIZE_FORMAT_W(10) \" \" SIZE_FORMAT_W(10) \" \"\n-              SIZE_FORMAT_W(10) \" \" SIZE_FORMAT_W(10) \" \",\n-              id, space_names[id],\n-              summary_data().addr_to_region_idx(space->bottom()),\n-              summary_data().addr_to_region_idx(space->top()),\n-              summary_data().addr_to_region_idx(space->end()),\n-              summary_data().addr_to_region_idx(_space_info[id].new_top()));\n-  }\n-}\n-\n-static void\n-print_generic_summary_region(size_t i, const ParallelCompactData::RegionData* c)\n-{\n-#define REGION_IDX_FORMAT        SIZE_FORMAT_W(7)\n-#define REGION_DATA_FORMAT       SIZE_FORMAT_W(5)\n-\n-  ParallelCompactData& sd = PSParallelCompact::summary_data();\n-  size_t dci = c->destination() ? sd.addr_to_region_idx(c->destination()) : 0;\n-  log_develop_trace(gc, compaction)(\n-      REGION_IDX_FORMAT \" \"\n-      REGION_IDX_FORMAT \" \" PTR_FORMAT \" \"\n-      REGION_DATA_FORMAT \" \" REGION_DATA_FORMAT \" \"\n-      REGION_DATA_FORMAT \" \" REGION_IDX_FORMAT \" %d\",\n-      i, dci, p2i(c->destination()),\n-      c->partial_obj_size(), c->live_obj_size(),\n-      c->data_size(), c->source_region(), c->destination_count());\n-\n-#undef  REGION_IDX_FORMAT\n-#undef  REGION_DATA_FORMAT\n-}\n-\n-void\n-print_generic_summary_data(ParallelCompactData& summary_data,\n-                           HeapWord* const beg_addr,\n-                           HeapWord* const end_addr)\n-{\n-  size_t total_words = 0;\n-  size_t i = summary_data.addr_to_region_idx(beg_addr);\n-  const size_t last = summary_data.addr_to_region_idx(end_addr);\n-  HeapWord* pdest = 0;\n-\n-  while (i < last) {\n-    ParallelCompactData::RegionData* c = summary_data.region(i);\n-    if (c->data_size() != 0 || c->destination() != pdest) {\n-      print_generic_summary_region(i, c);\n-      total_words += c->data_size();\n-      pdest = c->destination();\n-    }\n-    ++i;\n-  }\n-\n-  log_develop_trace(gc, compaction)(\"summary_data_bytes=\" SIZE_FORMAT, total_words * HeapWordSize);\n-}\n-\n-void\n-PSParallelCompact::print_generic_summary_data(ParallelCompactData& summary_data,\n-                                              HeapWord* const beg_addr,\n-                                              HeapWord* const end_addr) {\n-  ::print_generic_summary_data(summary_data,beg_addr, end_addr);\n-}\n-\n-static void\n-print_initial_summary_data(ParallelCompactData& summary_data,\n-                           const MutableSpace* space) {\n-  if (space->top() == space->bottom()) {\n-    return;\n-  }\n-\n-  const size_t region_size = ParallelCompactData::RegionSize;\n-  typedef ParallelCompactData::RegionData RegionData;\n-  HeapWord* const top_aligned_up = summary_data.region_align_up(space->top());\n-  const size_t end_region = summary_data.addr_to_region_idx(top_aligned_up);\n-  const RegionData* c = summary_data.region(end_region - 1);\n-  HeapWord* end_addr = c->destination() + c->data_size();\n-  const size_t live_in_space = pointer_delta(end_addr, space->bottom());\n-\n-  \/\/ Print (and count) the full regions at the beginning of the space.\n-  size_t full_region_count = 0;\n-  size_t i = summary_data.addr_to_region_idx(space->bottom());\n-  while (i < end_region && summary_data.region(i)->data_size() == region_size) {\n-    ParallelCompactData::RegionData* c = summary_data.region(i);\n-    log_develop_trace(gc, compaction)(\n-        SIZE_FORMAT_W(5) \" \" PTR_FORMAT \" \" SIZE_FORMAT_W(5) \" \" SIZE_FORMAT_W(5) \" \" SIZE_FORMAT_W(5) \" \" SIZE_FORMAT_W(5) \" %d\",\n-        i, p2i(c->destination()),\n-        c->partial_obj_size(), c->live_obj_size(),\n-        c->data_size(), c->source_region(), c->destination_count());\n-    ++full_region_count;\n-    ++i;\n-  }\n-\n-  size_t live_to_right = live_in_space - full_region_count * region_size;\n-\n-  double max_reclaimed_ratio = 0.0;\n-  size_t max_reclaimed_ratio_region = 0;\n-  size_t max_dead_to_right = 0;\n-  size_t max_live_to_right = 0;\n-\n-  \/\/ Print the 'reclaimed ratio' for regions while there is something live in\n-  \/\/ the region or to the right of it.  The remaining regions are empty (and\n-  \/\/ uninteresting), and computing the ratio will result in division by 0.\n-  while (i < end_region && live_to_right > 0) {\n-    c = summary_data.region(i);\n-    HeapWord* const region_addr = summary_data.region_to_addr(i);\n-    const size_t used_to_right = pointer_delta(space->top(), region_addr);\n-    const size_t dead_to_right = used_to_right - live_to_right;\n-    const double reclaimed_ratio = double(dead_to_right) \/ live_to_right;\n-\n-    if (reclaimed_ratio > max_reclaimed_ratio) {\n-            max_reclaimed_ratio = reclaimed_ratio;\n-            max_reclaimed_ratio_region = i;\n-            max_dead_to_right = dead_to_right;\n-            max_live_to_right = live_to_right;\n-    }\n-\n-    ParallelCompactData::RegionData* c = summary_data.region(i);\n-    log_develop_trace(gc, compaction)(\n-        SIZE_FORMAT_W(5) \" \" PTR_FORMAT \" \" SIZE_FORMAT_W(5) \" \" SIZE_FORMAT_W(5) \" \" SIZE_FORMAT_W(5) \" \" SIZE_FORMAT_W(5) \" %d\"\n-        \"%12.10f \" SIZE_FORMAT_W(10) \" \" SIZE_FORMAT_W(10),\n-        i, p2i(c->destination()),\n-        c->partial_obj_size(), c->live_obj_size(),\n-        c->data_size(), c->source_region(), c->destination_count(),\n-        reclaimed_ratio, dead_to_right, live_to_right);\n-\n-\n-    live_to_right -= c->data_size();\n-    ++i;\n-  }\n-\n-  \/\/ Any remaining regions are empty.  Print one more if there is one.\n-  if (i < end_region) {\n-    ParallelCompactData::RegionData* c = summary_data.region(i);\n-    log_develop_trace(gc, compaction)(\n-        SIZE_FORMAT_W(5) \" \" PTR_FORMAT \" \" SIZE_FORMAT_W(5) \" \" SIZE_FORMAT_W(5) \" \" SIZE_FORMAT_W(5) \" \" SIZE_FORMAT_W(5) \" %d\",\n-         i, p2i(c->destination()),\n-         c->partial_obj_size(), c->live_obj_size(),\n-         c->data_size(), c->source_region(), c->destination_count());\n-  }\n-\n-  log_develop_trace(gc, compaction)(\"max:  \" SIZE_FORMAT_W(4) \" d2r=\" SIZE_FORMAT_W(10) \" l2r=\" SIZE_FORMAT_W(10) \" max_ratio=%14.12f\",\n-                                    max_reclaimed_ratio_region, max_dead_to_right, max_live_to_right, max_reclaimed_ratio);\n-}\n-\n-static void\n-print_initial_summary_data(ParallelCompactData& summary_data,\n-                           SpaceInfo* space_info) {\n-  if (!log_develop_is_enabled(Trace, gc, compaction)) {\n-    return;\n-  }\n-\n-  unsigned int id = PSParallelCompact::old_space_id;\n-  const MutableSpace* space;\n-  do {\n-    space = space_info[id].space();\n-    print_initial_summary_data(summary_data, space);\n-  } while (++id < PSParallelCompact::eden_space_id);\n-\n-  do {\n-    space = space_info[id].space();\n-    print_generic_summary_data(summary_data, space->bottom(), space->top());\n-  } while (++id < PSParallelCompact::last_space_id);\n-}\n-#endif  \/\/ #ifndef PRODUCT\n-\n@@ -1012,23 +830,0 @@\n-#ifndef PRODUCT\n-void PSParallelCompact::summary_phase_msg(SpaceId dst_space_id,\n-                                          HeapWord* dst_beg, HeapWord* dst_end,\n-                                          SpaceId src_space_id,\n-                                          HeapWord* src_beg, HeapWord* src_end)\n-{\n-  log_develop_trace(gc, compaction)(\n-      \"Summarizing %d [%s] into %d [%s]:  \"\n-      \"src=\" PTR_FORMAT \"-\" PTR_FORMAT \" \"\n-      SIZE_FORMAT \"-\" SIZE_FORMAT \" \"\n-      \"dst=\" PTR_FORMAT \"-\" PTR_FORMAT \" \"\n-      SIZE_FORMAT \"-\" SIZE_FORMAT,\n-      src_space_id, space_names[src_space_id],\n-      dst_space_id, space_names[dst_space_id],\n-      p2i(src_beg), p2i(src_end),\n-      _summary_data.addr_to_region_idx(src_beg),\n-      _summary_data.addr_to_region_idx(src_end),\n-      p2i(dst_beg), p2i(dst_end),\n-      _summary_data.addr_to_region_idx(dst_beg),\n-      _summary_data.addr_to_region_idx(dst_end));\n-}\n-#endif  \/\/ #ifndef PRODUCT\n-\n@@ -1118,2 +913,0 @@\n-    NOT_PRODUCT(summary_phase_msg(dst_space_id, *new_top_addr, dst_space_end,\n-                                  SpaceId(id), space->bottom(), space->top());)\n@@ -1147,3 +940,0 @@\n-      NOT_PRODUCT(summary_phase_msg(dst_space_id,\n-                                    space->bottom(), dst_space_end,\n-                                    SpaceId(id), next_src_addr, space->top());)\n@@ -1159,4 +949,0 @@\n-\n-  log_develop_trace(gc, compaction)(\"Summary_phase:  after final summarization\");\n-  NOT_PRODUCT(print_region_ranges());\n-  NOT_PRODUCT(print_initial_summary_data(_summary_data, _space_info));\n@@ -2130,2 +1916,0 @@\n-  bool issued_a_warning = false;\n-\n@@ -2138,1 +1922,0 @@\n-      issued_a_warning = true;\n@@ -2147,1 +1930,0 @@\n-      issued_a_warning = true;\n@@ -2150,4 +1932,0 @@\n-\n-  if (issued_a_warning) {\n-    print_region_ranges();\n-  }\n@@ -2454,1 +2232,1 @@\n-      closure.complete_region(cm, dest_addr, region_ptr);\n+      closure.complete_region(dest_addr, region_ptr);\n@@ -2497,1 +2275,1 @@\n-      closure.complete_region(cm, dest_addr, region_ptr);\n+      closure.complete_region(dest_addr, region_ptr);\n@@ -2530,1 +2308,1 @@\n-    MoveAndUpdateShadowClosure cl(mark_bitmap(), cm, region_idx, shadow_region);\n+    MoveAndUpdateShadowClosure cl(mark_bitmap(), region_idx, shadow_region);\n@@ -2607,2 +2385,1 @@\n-void MoveAndUpdateClosure::complete_region(ParCompactionManager *cm, HeapWord *dest_addr,\n-                                           PSParallelCompact::RegionData *region_ptr) {\n+void MoveAndUpdateClosure::complete_region(HeapWord* dest_addr, PSParallelCompact::RegionData* region_ptr) {\n@@ -2641,2 +2418,1 @@\n-void MoveAndUpdateShadowClosure::complete_region(ParCompactionManager *cm, HeapWord *dest_addr,\n-                                                 PSParallelCompact::RegionData *region_ptr) {\n+void MoveAndUpdateShadowClosure::complete_region(HeapWord* dest_addr, PSParallelCompact::RegionData* region_ptr) {\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":5,"deletions":229,"binary":false,"changes":234,"status":"modified"},{"patch":"@@ -39,0 +39,6 @@\n+  if (!is_armed(nm)) {\n+    \/\/ Some other thread got here first and healed the oops\n+    \/\/ and disarmed the nmethod. No need to continue.\n+    return true;\n+  }\n+\n@@ -44,2 +50,2 @@\n-    \/\/ Some other thread got here first and healed the oops\n-    \/\/ and disarmed the nmethod.\n+    \/\/ Some other thread managed to complete while we were\n+    \/\/ waiting for lock. No need to continue.\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahBarrierSetNMethod.cpp","additions":8,"deletions":2,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -57,0 +57,3 @@\n+#ifndef PRODUCT\n+    _verify_count = 0;\n+#endif\n","filename":"src\/hotspot\/share\/oops\/klassVtable.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1403,15 +1403,0 @@\n-#if INCLUDE_RTM_OPT\n-  _rtm_state = NoRTM; \/\/ No RTM lock eliding by default\n-  if (UseRTMLocking &&\n-      !CompilerOracle::has_option(mh, CompileCommandEnum::NoRTMLockEliding)) {\n-    if (CompilerOracle::has_option(mh, CompileCommandEnum::UseRTMLockEliding) || !UseRTMDeopt) {\n-      \/\/ Generate RTM lock eliding code without abort ratio calculation code.\n-      _rtm_state = UseRTM;\n-    } else if (UseRTMDeopt) {\n-      \/\/ Generate RTM lock eliding code and include abort ratio calculation\n-      \/\/ code if UseRTMDeopt is on.\n-      _rtm_state = ProfileRTM;\n-    }\n-  }\n-#endif\n-\n","filename":"src\/hotspot\/share\/oops\/methodData.cpp","additions":0,"deletions":15,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -2305,5 +2305,0 @@\n-#if INCLUDE_RTM_OPT\n-  \/\/ State of RTM code generation during compilation of the method\n-  int               _rtm_state;\n-#endif\n-\n@@ -2505,16 +2500,0 @@\n-#if INCLUDE_RTM_OPT\n-  int rtm_state() const {\n-    return _rtm_state;\n-  }\n-  void set_rtm_state(RTMState rstate) {\n-    _rtm_state = (int)rstate;\n-  }\n-  void atomic_set_rtm_state(RTMState rstate) {\n-    Atomic::store(&_rtm_state, (int)rstate);\n-  }\n-\n-  static ByteSize rtm_state_offset() {\n-    return byte_offset_of(MethodData, _rtm_state);\n-  }\n-#endif\n-\n","filename":"src\/hotspot\/share\/oops\/methodData.hpp","additions":0,"deletions":21,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -125,1 +125,1 @@\n-    \/\/ minimum number of natural words needed to hold these bits (no non-heap version)\n+    \/\/ minimum number of bytes needed to hold these bits (no non-heap version)\n@@ -149,2 +149,0 @@\n-  \/\/ length without the _body\n-  size_t effective_length() const { return (size_t)byte_size() - sizeof(Symbol); }\n","filename":"src\/hotspot\/share\/oops\/symbol.hpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -460,3 +460,0 @@\n-  product(bool, PrintPreciseRTMLockingStatistics, false, DIAGNOSTIC,        \\\n-          \"Print per-lock-site statistics of rtm locking in JVM\")           \\\n-                                                                            \\\n","filename":"src\/hotspot\/share\/opto\/c2_globals.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -273,1 +273,0 @@\n-macro(Opaque3)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -731,1 +731,1 @@\n-  if (ProfileTraps RTM_OPT_ONLY( || UseRTMLocking )) {\n+  if (ProfileTraps) {\n@@ -734,1 +734,0 @@\n-    \/\/ Need MDO to record RTM code generation state.\n@@ -1106,1 +1105,0 @@\n-  set_rtm_state(NoRTM); \/\/ No RTM lock eliding by default\n@@ -1109,16 +1107,0 @@\n-#if INCLUDE_RTM_OPT\n-  if (UseRTMLocking && has_method() && (method()->method_data_or_null() != nullptr)) {\n-    int rtm_state = method()->method_data()->rtm_state();\n-    if (method_has_option(CompileCommandEnum::NoRTMLockEliding) || ((rtm_state & NoRTM) != 0)) {\n-      \/\/ Don't generate RTM lock eliding code.\n-      set_rtm_state(NoRTM);\n-    } else if (method_has_option(CompileCommandEnum::UseRTMLockEliding) || ((rtm_state & UseRTM) != 0) || !UseRTMDeopt) {\n-      \/\/ Generate RTM lock eliding code without abort ratio calculation code.\n-      set_rtm_state(UseRTM);\n-    } else if (UseRTMDeopt) {\n-      \/\/ Generate RTM lock eliding code and include abort ratio calculation\n-      \/\/ code if UseRTMDeopt is on.\n-      set_rtm_state(ProfileRTM);\n-    }\n-  }\n-#endif\n@@ -3723,1 +3705,0 @@\n-  case Op_Opaque3:\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":1,"deletions":20,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -361,1 +361,0 @@\n-  RTMState              _rtm_state;             \/\/ State of Restricted Transactional Memory usage\n@@ -679,4 +678,0 @@\n-  RTMState          rtm_state()  const           { return _rtm_state; }\n-  void          set_rtm_state(RTMState s)        { _rtm_state = s; }\n-  bool              use_rtm() const              { return (_rtm_state & NoRTM) == 0; }\n-  bool          profile_rtm() const              { return _rtm_state == ProfileRTM; }\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2239,0 +2239,1 @@\n+                  strcmp(call->as_CallLeaf()->_name, \"stringIndexOf\") == 0 ||\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -3898,3 +3898,0 @@\n-  \/\/ Create the rtm counters for this fast lock if needed.\n-  flock->create_rtm_lock_counter(sync_jvms()); \/\/ sync_jvms used to get current bci\n-\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1215,0 +1215,3 @@\n+  Node* result = nullptr;\n+  bool call_opt_stub = (StubRoutines::_string_indexof_array[ae] != nullptr);\n+\n@@ -1224,1 +1227,10 @@\n-  Node* result = make_indexOf_node(src_start, src_count, tgt_start, tgt_count, result_rgn, result_phi, ae);\n+  if (call_opt_stub) {\n+    Node* call = make_runtime_call(RC_LEAF, OptoRuntime::string_IndexOf_Type(),\n+                                   StubRoutines::_string_indexof_array[ae],\n+                                   \"stringIndexOf\", TypePtr::BOTTOM, src_start,\n+                                   src_count, tgt_start, tgt_count);\n+    result = _gvn.transform(new ProjNode(call, TypeFunc::Parms));\n+  } else {\n+    result = make_indexOf_node(src_start, src_count, tgt_start, tgt_count,\n+                               result_rgn, result_phi, ae);\n+  }\n@@ -1236,1 +1248,1 @@\n-\/\/-----------------------------inline_string_indexOf-----------------------\n+\/\/-----------------------------inline_string_indexOfI-----------------------\n@@ -1244,0 +1256,1 @@\n+\n@@ -1269,0 +1282,3 @@\n+  Node* result = nullptr;\n+\n+  bool call_opt_stub = (StubRoutines::_string_indexof_array[ae] != nullptr);\n@@ -1270,1 +1286,11 @@\n-  Node* result = make_indexOf_node(src_start, src_count, tgt_start, tgt_count, region, phi, ae);\n+  if (call_opt_stub) {\n+    assert(arrayOopDesc::base_offset_in_bytes(T_BYTE) >= 16, \"Needed for indexOf\");\n+    Node* call = make_runtime_call(RC_LEAF, OptoRuntime::string_IndexOf_Type(),\n+                                   StubRoutines::_string_indexof_array[ae],\n+                                   \"stringIndexOf\", TypePtr::BOTTOM, src_start,\n+                                   src_count, tgt_start, tgt_count);\n+    result = _gvn.transform(new ProjNode(call, TypeFunc::Parms));\n+  } else {\n+    result = make_indexOf_node(src_start, src_count, tgt_start, tgt_count,\n+                               region, phi, ae);\n+  }\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":29,"deletions":3,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -209,16 +209,0 @@\n-void FastLockNode::create_rtm_lock_counter(JVMState* state) {\n-#if INCLUDE_RTM_OPT\n-  Compile* C = Compile::current();\n-  if (C->profile_rtm() || (PrintPreciseRTMLockingStatistics && C->use_rtm())) {\n-    RTMLockingNamedCounter* rlnc = (RTMLockingNamedCounter*)\n-           OptoRuntime::new_named_counter(state, NamedCounter::RTMLockingCounter);\n-    _rtm_counters = rlnc->counters();\n-    if (UseRTMForStackLocks) {\n-      rlnc = (RTMLockingNamedCounter*)\n-           OptoRuntime::new_named_counter(state, NamedCounter::RTMLockingCounter);\n-      _stack_rtm_counters = rlnc->counters();\n-    }\n-  }\n-#endif\n-}\n-\n","filename":"src\/hotspot\/share\/opto\/locknode.cpp","additions":0,"deletions":16,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -32,2 +32,0 @@\n-class RTMLockingCounters;\n-\n@@ -133,4 +131,0 @@\n-private:\n-  RTMLockingCounters*       _rtm_counters; \/\/ RTM lock counters for inflated locks\n-  RTMLockingCounters* _stack_rtm_counters; \/\/ RTM lock counters for stack locks\n-\n@@ -141,2 +135,0 @@\n-    _rtm_counters = nullptr;\n-    _stack_rtm_counters = nullptr;\n@@ -156,4 +148,0 @@\n-\n-  void create_rtm_lock_counter(JVMState* state);\n-  RTMLockingCounters*       rtm_counters() const { return _rtm_counters; }\n-  RTMLockingCounters* stack_rtm_counters() const { return _stack_rtm_counters; }\n","filename":"src\/hotspot\/share\/opto\/locknode.hpp","additions":0,"deletions":12,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -1470,1 +1470,1 @@\n-  \/\/ Move UnorderedReduction out of loop if possible\n+  \/\/ Move an unordered Reduction out of loop if possible\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -4621,0 +4621,5 @@\n+\/\/ Returns true if the Reduction node is unordered.\n+static bool is_unordered_reduction(Node* n) {\n+  return n->is_Reduction() && !n->as_Reduction()->requires_strict_order();\n+}\n+\n@@ -4626,0 +4631,3 @@\n+\/\/ Note: UnorderedReduction represents a ReductionNode which does not require\n+\/\/ calculating in strict order.\n+\/\/\n@@ -4665,0 +4673,1 @@\n+\/\/\n@@ -4666,1 +4675,2 @@\n-\/\/ reordering of operations (for example float addition).\n+\/\/ reordering of operations (for example float addition\/multiplication require\n+\/\/ strict order).\n@@ -4670,1 +4680,1 @@\n-  \/\/ Find all Phi nodes with UnorderedReduction on backedge.\n+  \/\/ Find all Phi nodes with an unordered Reduction on backedge.\n@@ -4674,2 +4684,2 @@\n-    \/\/ We have a phi with a single use, and a UnorderedReduction on the backedge.\n-    if (!phi->is_Phi() || phi->outcnt() != 1 || !phi->in(2)->is_UnorderedReduction()) {\n+    \/\/ We have a phi with a single use, and an unordered Reduction on the backedge.\n+    if (!phi->is_Phi() || phi->outcnt() != 1 || !is_unordered_reduction(phi->in(2))) {\n@@ -4679,1 +4689,2 @@\n-    UnorderedReductionNode* last_ur = phi->in(2)->as_UnorderedReduction();\n+    ReductionNode* last_ur = phi->in(2)->as_Reduction();\n+    assert(!last_ur->requires_strict_order(), \"must be\");\n@@ -4696,2 +4707,2 @@\n-    \/\/ Traverse up the chain of UnorderedReductions, checking that it loops back to\n-    \/\/ the phi. Check that all UnorderedReductions only have a single use, except for\n+    \/\/ Traverse up the chain of unordered Reductions, checking that it loops back to\n+    \/\/ the phi. Check that all unordered Reductions only have a single use, except for\n@@ -4700,2 +4711,2 @@\n-    UnorderedReductionNode* current = last_ur;\n-    UnorderedReductionNode* first_ur = nullptr;\n+    ReductionNode* current = last_ur;\n+    ReductionNode* first_ur = nullptr;\n@@ -4703,1 +4714,1 @@\n-      assert(current->is_UnorderedReduction(), \"sanity\");\n+      assert(!current->requires_strict_order(), \"sanity\");\n@@ -4720,1 +4731,1 @@\n-      \/\/ Expect single use of UnorderedReduction, except for last_ur.\n+      \/\/ Expect single use of an unordered Reduction, except for last_ur.\n@@ -4738,1 +4749,1 @@\n-      \/\/ Expect another UnorderedReduction or phi as the scalar input.\n+      \/\/ Expect another unordered Reduction or phi as the scalar input.\n@@ -4740,1 +4751,1 @@\n-      if (scalar_input->is_UnorderedReduction() &&\n+      if (is_unordered_reduction(scalar_input) &&\n@@ -4742,2 +4753,3 @@\n-        \/\/ Move up the UnorderedReduction chain.\n-        current = scalar_input->as_UnorderedReduction();\n+        \/\/ Move up the unordered Reduction chain.\n+        current = scalar_input->as_Reduction();\n+        assert(!current->requires_strict_order(), \"must be\");\n@@ -4767,1 +4779,1 @@\n-    VectorNode::trace_new_vector(identity_vector, \"UnorderedReduction\");\n+    VectorNode::trace_new_vector(identity_vector, \"Unordered Reduction\");\n@@ -4776,1 +4788,1 @@\n-    \/\/ Traverse down the chain of UnorderedReductions, and replace them with vector_accumulators.\n+    \/\/ Traverse down the chain of unordered Reductions, and replace them with vector_accumulators.\n@@ -4785,1 +4797,1 @@\n-      VectorNode::trace_new_vector(vector_accumulator, \"UnorderedReduction\");\n+      VectorNode::trace_new_vector(vector_accumulator, \"Unordered Reduction\");\n@@ -4789,1 +4801,2 @@\n-      current = vector_accumulator->unique_out()->as_UnorderedReduction();\n+      current = vector_accumulator->unique_out()->as_Reduction();\n+      assert(!current->requires_strict_order(), \"must be\");\n@@ -4806,1 +4819,1 @@\n-    VectorNode::trace_new_vector(post_loop_reduction, \"UnorderedReduction\");\n+    VectorNode::trace_new_vector(post_loop_reduction, \"Unordered Reduction\");\n","filename":"src\/hotspot\/share\/opto\/loopopts.cpp","additions":33,"deletions":20,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -58,1 +58,0 @@\n-class RTMLockingCounters;\n@@ -841,2 +840,0 @@\n-  RTMLockingCounters*       _rtm_counters; \/\/ RTM lock counters for inflated locks\n-  RTMLockingCounters* _stack_rtm_counters; \/\/ RTM lock counters for stack locks\n","filename":"src\/hotspot\/share\/opto\/machnode.hpp","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2940,1 +2940,0 @@\n-               n->Opcode() == Op_Opaque3   ||\n@@ -2996,24 +2995,0 @@\n-#if INCLUDE_RTM_OPT\n-      } else if ((n->Opcode() == Op_Opaque3) && ((Opaque3Node*)n)->rtm_opt()) {\n-        assert(C->profile_rtm(), \"should be used only in rtm deoptimization code\");\n-        assert((n->outcnt() == 1) && n->unique_out()->is_Cmp(), \"\");\n-        Node* cmp = n->unique_out();\n-#ifdef ASSERT\n-        \/\/ Validate graph.\n-        assert((cmp->outcnt() == 1) && cmp->unique_out()->is_Bool(), \"\");\n-        BoolNode* bol = cmp->unique_out()->as_Bool();\n-        assert((bol->outcnt() == 1) && bol->unique_out()->is_If() &&\n-               (bol->_test._test == BoolTest::ne), \"\");\n-        IfNode* ifn = bol->unique_out()->as_If();\n-        assert((ifn->outcnt() == 2) &&\n-               ifn->proj_out(1)->is_uncommon_trap_proj(Deoptimization::Reason_rtm_state_change) != nullptr, \"\");\n-#endif\n-        Node* repl = n->in(1);\n-        if (!_has_locks) {\n-          \/\/ Remove RTM state check if there are no locks in the code.\n-          \/\/ Replace input to compare the same value.\n-          repl = (cmp->in(1) == n) ? cmp->in(2) : cmp->in(1);\n-        }\n-        _igvn.replace_node(n, repl);\n-        success = true;\n-#endif\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":0,"deletions":25,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -2934,1 +2934,1 @@\n-\/\/   RangeCheck[i+1]           RangeCheck[i+1]\n+\/\/   RangeCheck[i+3]           RangeCheck[i+3]\n@@ -2941,1 +2941,1 @@\n-\/\/ the optimization, the new StoreI[i+0] is on the passing path of RangeCheck[i+1], and StoreB[i+0] on the\n+\/\/ the optimization, the new StoreI[i+0] is on the passing path of RangeCheck[i+3], and StoreB[i+0] on the\n@@ -2953,1 +2953,1 @@\n-\/\/                              StoreB[i+0]                             StoreB[i+1]     <- second store\n+\/\/                              StoreB[i+1]                             StoreB[i+1]     <- second store\n@@ -2955,1 +2955,1 @@\n-\/\/                              StoreB[i+0]                             StoreB[i+2]\n+\/\/                              StoreB[i+2]                             StoreB[i+2]\n@@ -2957,1 +2957,1 @@\n-\/\/                              StoreB[i+0]                             StoreB[i+3]     <- last store\n+\/\/                              StoreB[i+3]                             StoreB[i+3]     <- last store\n@@ -3120,0 +3120,5 @@\n+#ifndef VM_LITTLE_ENDIAN\n+  \/\/ Pattern: [n1 = base >> (shift + memory_size), n2 = base >> shift]\n+  \/\/ Swapping n1 with n2 gives same pattern as on little endian platforms.\n+  swap(n1, n2);\n+#endif \/\/ !VM_LITTLE_ENDIAN\n@@ -3334,0 +3339,1 @@\n+#ifdef VM_LITTLE_ENDIAN\n@@ -3336,0 +3342,4 @@\n+#else \/\/ VM_LITTLE_ENDIAN\n+      con_i = (mask & con_i) << (i * bits_per_store);\n+      con = con | con_i;\n+#endif \/\/ VM_LITTLE_ENDIAN\n@@ -3343,4 +3353,10 @@\n-    merged_input_value = first->in(MemNode::ValueIn);\n-    Node const* base_last;\n-    jint shift_last;\n-    bool is_true = is_con_RShift(_store->in(MemNode::ValueIn), base_last, shift_last);\n+    Node* hi = _store->in(MemNode::ValueIn);\n+    Node* lo = first->in(MemNode::ValueIn);\n+#ifndef VM_LITTLE_ENDIAN\n+    \/\/ `_store` and `first` are swapped in the diagram above\n+    swap(hi, lo);\n+#endif \/\/ !VM_LITTLE_ENDIAN\n+    Node const* hi_base;\n+    jint hi_shift;\n+    merged_input_value = lo;\n+    bool is_true = is_con_RShift(hi, hi_base, hi_shift);\n@@ -3348,1 +3364,1 @@\n-    if (merged_input_value != base_last && merged_input_value->Opcode() == Op_ConvL2I) {\n+    if (merged_input_value != hi_base && merged_input_value->Opcode() == Op_ConvL2I) {\n@@ -3352,1 +3368,1 @@\n-    if (merged_input_value != base_last) {\n+    if (merged_input_value != hi_base) {\n@@ -3527,1 +3543,0 @@\n-#ifdef VM_LITTLE_ENDIAN\n@@ -3537,1 +3552,0 @@\n-#endif\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":27,"deletions":13,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -182,1 +182,0 @@\n-class UnorderedReductionNode;\n@@ -748,2 +747,1 @@\n-        DEFINE_CLASS_ID(Reduction, Vector, 9)\n-          DEFINE_CLASS_ID(UnorderedReduction, Reduction, 0)\n+        DEFINE_CLASS_ID(Reduction, Vector, 7)\n@@ -1008,1 +1006,0 @@\n-  DEFINE_CLASS_QUERY(UnorderedReduction)\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1391,1 +1391,1 @@\n-  int pad_req   = NativeCall::instruction_size;\n+  int pad_req   = NativeCall::byte_size();\n@@ -3493,2 +3493,1 @@\n-                 SharedRuntime::is_wide_vector(C->max_vector_size()),\n-                 C->rtm_state());\n+                 SharedRuntime::is_wide_vector(C->max_vector_size()));\n@@ -3502,2 +3501,1 @@\n-                               bool              has_wide_vectors,\n-                               RTMState          rtm_state) {\n+                               bool              has_wide_vectors) {\n@@ -3544,2 +3542,1 @@\n-                              0,\n-                              C->rtm_state());\n+                              0);\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":4,"deletions":7,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -512,2 +512,0 @@\n-  void rtm_deopt();\n-\n","filename":"src\/hotspot\/share\/opto\/parse.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -607,3 +607,0 @@\n-\n-    \/\/ Add check to deoptimize the nmethod if RTM state was changed\n-    rtm_deopt();\n@@ -612,1 +609,1 @@\n-  \/\/ Check for bailouts during method entry or RTM state check setup.\n+  \/\/ Check for bailouts during method entry.\n@@ -2359,36 +2356,0 @@\n-\/\/ Add check to deoptimize if RTM state is not ProfileRTM\n-void Parse::rtm_deopt() {\n-#if INCLUDE_RTM_OPT\n-  if (C->profile_rtm()) {\n-    assert(C->has_method(), \"only for normal compilations\");\n-    assert(!C->method()->method_data()->is_empty(), \"MDO is needed to record RTM state\");\n-    assert(depth() == 1, \"generate check only for main compiled method\");\n-\n-    \/\/ Set starting bci for uncommon trap.\n-    set_parse_bci(is_osr_parse() ? osr_bci() : 0);\n-\n-    \/\/ Load the rtm_state from the MethodData.\n-    const TypePtr* adr_type = TypeMetadataPtr::make(C->method()->method_data());\n-    Node* mdo = makecon(adr_type);\n-    int offset = in_bytes(MethodData::rtm_state_offset());\n-    Node* adr_node = basic_plus_adr(mdo, mdo, offset);\n-    Node* rtm_state = make_load(control(), adr_node, TypeInt::INT, T_INT, adr_type, MemNode::unordered);\n-\n-    \/\/ Separate Load from Cmp by Opaque.\n-    \/\/ In expand_macro_nodes() it will be replaced either\n-    \/\/ with this load when there are locks in the code\n-    \/\/ or with ProfileRTM (cmp->in(2)) otherwise so that\n-    \/\/ the check will fold.\n-    Node* profile_state = makecon(TypeInt::make(ProfileRTM));\n-    Node* opq   = _gvn.transform( new Opaque3Node(C, rtm_state, Opaque3Node::RTM_OPT) );\n-    Node* chk   = _gvn.transform( new CmpINode(opq, profile_state) );\n-    Node* tst   = _gvn.transform( new BoolNode(chk, BoolTest::eq) );\n-    \/\/ Branch to failure if state was changed\n-    { BuildCutout unless(this, tst, PROB_ALWAYS);\n-      uncommon_trap(Deoptimization::Reason_rtm_state_change,\n-                    Deoptimization::Action_make_not_entrant);\n-    }\n-  }\n-#endif\n-}\n-\n","filename":"src\/hotspot\/share\/opto\/parse1.cpp","additions":1,"deletions":40,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -1366,0 +1366,21 @@\n+\n+\/\/ String IndexOf function\n+const TypeFunc* OptoRuntime::string_IndexOf_Type() {\n+  int argcnt = 4;\n+\n+  const Type** fields = TypeTuple::fields(argcnt);\n+  int argp = TypeFunc::Parms;\n+  fields[argp++] = TypePtr::NOTNULL;    \/\/ haystack array\n+  fields[argp++] = TypeInt::INT;        \/\/ haystack length\n+  fields[argp++] = TypePtr::NOTNULL;    \/\/ needle array\n+  fields[argp++] = TypeInt::INT;        \/\/ needle length\n+  assert(argp == TypeFunc::Parms + argcnt, \"correct decoding\");\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms+argcnt, fields);\n+\n+  \/\/ result type needed\n+  fields = TypeTuple::fields(1);\n+  fields[TypeFunc::Parms + 0] = TypeInt::INT; \/\/ Index of needle in haystack\n+  const TypeTuple* range = TypeTuple::make(TypeFunc::Parms + 1, fields);\n+  return TypeFunc::make(domain, range);\n+}\n+\n@@ -1844,8 +1865,0 @@\n-#if INCLUDE_RTM_OPT\n-    } else if (c->tag() == NamedCounter::RTMLockingCounter) {\n-      RTMLockingCounters* rlc = ((RTMLockingNamedCounter*)c)->counters();\n-      if (rlc->nonzero()) {\n-        tty->print_cr(\"%s\", c->name());\n-        rlc->print_on(tty);\n-      }\n-#endif\n@@ -1893,6 +1906,1 @@\n-  NamedCounter* c;\n-  if (tag == NamedCounter::RTMLockingCounter) {\n-    c = new RTMLockingNamedCounter(st.freeze());\n-  } else {\n-    c = new NamedCounter(st.freeze(), tag);\n-  }\n+  NamedCounter* c = new NamedCounter(st.freeze(), tag);\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":22,"deletions":14,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-#include \"runtime\/rtmLocking.hpp\"\n@@ -64,2 +63,1 @@\n-    EliminatedLockCounter,\n-    RTMLockingCounter\n+    EliminatedLockCounter\n@@ -101,11 +99,0 @@\n-class RTMLockingNamedCounter : public NamedCounter {\n- private:\n- RTMLockingCounters _counters;\n-\n- public:\n-  RTMLockingNamedCounter(const char *n) :\n-    NamedCounter(n, RTMLockingCounter), _counters() {}\n-\n-  RTMLockingCounters* counters() { return &_counters; }\n-};\n-\n@@ -302,0 +289,1 @@\n+  static const TypeFunc* string_IndexOf_Type();\n","filename":"src\/hotspot\/share\/opto\/runtime.hpp","additions":2,"deletions":14,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -505,1 +505,0 @@\n-  { \"RegisterFinalizersAtInit\",     JDK_Version::jdk(22), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n@@ -511,5 +510,0 @@\n-#if defined(X86)\n-  { \"UseRTMLocking\",                JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n-  { \"UseRTMDeopt\",                  JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n-  { \"RTMRetryCount\",                JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n-#endif \/\/ X86\n@@ -523,26 +517,5 @@\n-  { \"G1ConcRefinementGreenZone\",    JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::jdk(24) },\n-  { \"G1ConcRefinementYellowZone\",   JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::jdk(24) },\n-  { \"G1ConcRefinementRedZone\",      JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::jdk(24) },\n-  { \"G1ConcRefinementThresholdStep\", JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::jdk(24) },\n-  { \"G1UseAdaptiveConcRefinement\",  JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::jdk(24) },\n-  { \"G1ConcRefinementServiceIntervalMillis\", JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::jdk(24) },\n-\n-  { \"G1ConcRSLogCacheSize\",         JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::jdk(24) },\n-  { \"G1ConcRSHotCardLimit\",         JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::jdk(24) },\n-  { \"RefDiscoveryPolicy\",           JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::jdk(24) },\n-\n-  { \"AdaptiveSizePolicyCollectionCostMargin\",   JDK_Version::undefined(), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n-  { \"MaxGCMinorPauseMillis\",        JDK_Version::jdk(8), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n-  { \"MaxRAMFraction\",               JDK_Version::jdk(10),  JDK_Version::jdk(23), JDK_Version::jdk(24) },\n-  { \"MinRAMFraction\",               JDK_Version::jdk(10),  JDK_Version::jdk(23), JDK_Version::jdk(24) },\n-  { \"InitialRAMFraction\",           JDK_Version::jdk(10),  JDK_Version::jdk(23), JDK_Version::jdk(24) },\n-  { \"DefaultMaxRAMFraction\",        JDK_Version::jdk(8),  JDK_Version::jdk(23), JDK_Version::jdk(24) },\n-  { \"TLABStats\",                    JDK_Version::jdk(12), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n-  { \"GCLockerEdenExpansionPercent\", JDK_Version::undefined(), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n-  { \"NUMAPageScanRate\",             JDK_Version::undefined(), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n-  { \"ProcessDistributionStride\",    JDK_Version::undefined(), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n-\n-  { \"ParallelOldDeadWoodLimiterMean\",   JDK_Version::undefined(), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n-  { \"ParallelOldDeadWoodLimiterStdDev\", JDK_Version::undefined(), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n-  { \"UseNeon\",                      JDK_Version::undefined(), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n-  { \"ScavengeBeforeFullGC\",         JDK_Version::undefined(), JDK_Version::jdk(23), JDK_Version::jdk(24) },\n+#if defined(X86)\n+  { \"UseRTMLocking\",                JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n+  { \"UseRTMDeopt\",                  JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n+  { \"RTMRetryCount\",                JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n+#endif \/\/ X86\n@@ -1860,8 +1833,0 @@\n-#endif\n-#if defined(X86) && !defined(ZERO)\n-  if (LockingMode == LM_MONITOR && UseRTMForStackLocks) {\n-    jio_fprintf(defaultStream::error_stream(),\n-                \"LockingMode == 0 (LM_MONITOR) and -XX:+UseRTMForStackLocks are mutually exclusive\\n\");\n-\n-    return false;\n-  }\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":5,"deletions":40,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -2169,2 +2169,1 @@\n-    \/\/ Need MDO to record RTM code generation state.\n-    bool create_if_missing = ProfileTraps RTM_OPT_ONLY( || UseRTMLocking );\n+    bool create_if_missing = ProfileTraps;\n@@ -2518,10 +2517,0 @@\n-#if INCLUDE_RTM_OPT\n-      \/\/ Restart collecting RTM locking abort statistic if the method\n-      \/\/ is recompiled for a reason other than RTM state change.\n-      \/\/ Assume that in new recompiled code the statistic could be different,\n-      \/\/ for example, due to different inlining.\n-      if ((reason != Reason_rtm_state_change) && (trap_mdo != nullptr) &&\n-          UseRTMDeopt && (nm->rtm_state() != ProfileRTM)) {\n-        trap_mdo->atomic_set_rtm_state(ProfileRTM);\n-      }\n-#endif\n@@ -2817,1 +2806,0 @@\n-  \"rtm_state_change\",\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":1,"deletions":13,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -116,1 +116,0 @@\n-    Reason_rtm_state_change,      \/\/ rtm state change detected\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -152,0 +152,2 @@\n+address StubRoutines::_string_indexof_array[4]   =    { nullptr };\n+\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -235,0 +235,2 @@\n+  static address _string_indexof_array[4];\n+\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -112,3 +112,0 @@\n-#if INCLUDE_RTM_OPT\n-#include \"runtime\/rtmLocking.hpp\"\n-#endif\n@@ -806,4 +803,0 @@\n-#if INCLUDE_RTM_OPT\n-  RTMLockingCounters::init();\n-#endif\n-\n@@ -1332,0 +1325,9 @@\n+        const oop thread_oop = p->threadObj();\n+        if (thread_oop != nullptr) {\n+          if (p->is_vthread_mounted()) {\n+            const oop vt = p->vthread();\n+            assert(vt != nullptr, \"vthread should not be null when vthread is mounted\");\n+            st->print_cr(\"   Mounted virtual thread \\\"%s\\\" #\" INT64_FORMAT, JavaThread::name_for(vt), (int64_t)java_lang_Thread::thread_id(vt));\n+            p->print_vthread_stack_on(st);\n+          }\n+        }\n","filename":"src\/hotspot\/share\/runtime\/threads.cpp","additions":9,"deletions":7,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2267,1 +2267,0 @@\n-  declare_constant(Deoptimization::Reason_rtm_state_change)               \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1217,0 +1217,2 @@\n+static constexpr char default_filename[] = \"vm_memory_map_<pid>.txt\";\n+\n@@ -1220,1 +1222,1 @@\n-  _filename(\"-F\", \"file path (defaults: \\\"vm_memory_map_<pid>.txt\\\")\", \"STRING\", false) {\n+  _filename(\"-F\", \"file path\", \"STRING\", false, default_filename) {\n@@ -1226,3 +1228,8 @@\n-  stringStream default_name;\n-  default_name.print(\"vm_memory_map_%d.txt\", os::current_process_id());\n-  const char* name = _filename.is_set() ? _filename.value() : default_name.base();\n+  stringStream defaultname;\n+  const char* name = nullptr;\n+  if (::strcmp(default_filename, _filename.value()) == 0) {\n+    defaultname.print(\"vm_memory_map_%d.txt\", os::current_process_id());\n+    name = defaultname.base();\n+  } else {\n+    name = _filename.value();\n+  }\n","filename":"src\/hotspot\/share\/services\/diagnosticCommand.cpp","additions":11,"deletions":4,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -74,0 +74,1 @@\n+import jdk.internal.constant.ConstantUtils;\n@@ -4759,1 +4760,1 @@\n-                            : Optional.of(ClassDesc.ofDescriptor(descriptorString()));\n+                            : Optional.of(ConstantUtils.classDesc(this));\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Class.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -415,1 +415,2 @@\n-     * The number of bits used to represent a {@code double} value.\n+     * The number of bits used to represent a {@code double} value,\n+     * {@value}.\n@@ -422,3 +423,3 @@\n-     * The number of bits in the significand of a {@code double} value.\n-     * This is the parameter N in section {@jls 4.2.3} of\n-     * <cite>The Java Language Specification<\/cite>.\n+     * The number of bits in the significand of a {@code double}\n+     * value, {@value}.  This is the parameter N in section {@jls\n+     * 4.2.3} of <cite>The Java Language Specification<\/cite>.\n@@ -431,3 +432,3 @@\n-     * Maximum exponent a finite {@code double} variable may have.\n-     * It is equal to the value returned by\n-     * {@code Math.getExponent(Double.MAX_VALUE)}.\n+     * Maximum exponent a finite {@code double} variable may have,\n+     * {@value}.  It is equal to the value returned by {@code\n+     * Math.getExponent(Double.MAX_VALUE)}.\n@@ -440,3 +441,3 @@\n-     * Minimum exponent a normalized {@code double} variable may\n-     * have.  It is equal to the value returned by\n-     * {@code Math.getExponent(Double.MIN_NORMAL)}.\n+     * Minimum exponent a normalized {@code double} variable may have,\n+     * {@value}.  It is equal to the value returned by {@code\n+     * Math.getExponent(Double.MIN_NORMAL)}.\n@@ -449,1 +450,2 @@\n-     * The number of bytes used to represent a {@code double} value.\n+     * The number of bytes used to represent a {@code double} value,\n+     * {@value}.\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Double.java","additions":13,"deletions":11,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -131,1 +131,2 @@\n-     * The number of bits used to represent a {@code float} value.\n+     * The number of bits used to represent a {@code float} value,\n+     * {@value}.\n@@ -138,2 +139,2 @@\n-     * The number of bits in the significand of a {@code float} value.\n-     * This is the parameter N in section {@jls 4.2.3} of\n+     * The number of bits in the significand of a {@code float} value,\n+     * {@value}.  This is the parameter N in section {@jls 4.2.3} of\n@@ -147,2 +148,2 @@\n-     * Maximum exponent a finite {@code float} variable may have.  It\n-     * is equal to the value returned by {@code\n+     * Maximum exponent a finite {@code float} variable may have,\n+     * {@value}.  It is equal to the value returned by {@code\n@@ -156,2 +157,2 @@\n-     * Minimum exponent a normalized {@code float} variable may have.\n-     * It is equal to the value returned by {@code\n+     * Minimum exponent a normalized {@code float} variable may have,\n+     * {@value}.  It is equal to the value returned by {@code\n@@ -165,1 +166,2 @@\n-     * The number of bytes used to represent a {@code float} value.\n+     * The number of bytes used to represent a {@code float} value,\n+     * {@value}.\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Float.java","additions":10,"deletions":8,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -48,0 +48,1 @@\n+import static jdk.internal.constant.ConstantUtils.CD_module_info;\n@@ -395,1 +396,1 @@\n-        return build(ClassDesc.of(\"module-info\"), clb -> {\n+        return build(CD_module_info, clb -> {\n","filename":"src\/java.base\/share\/classes\/java\/lang\/classfile\/ClassFile.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -39,1 +39,0 @@\n-import static jdk.internal.constant.ConstantUtils.dropFirstAndLastChar;\n@@ -168,1 +167,1 @@\n-               ? Wrapper.forPrimitiveType(descriptor.charAt(0)).classDescriptor()\n+               ? Wrapper.forPrimitiveType(descriptor.charAt(0)).basicClassDescriptor()\n@@ -318,1 +317,1 @@\n-                return Wrapper.forBasicType(desc.charAt(1)).classDescriptor();\n+                return Wrapper.forBasicType(desc.charAt(1)).basicClassDescriptor();\n","filename":"src\/java.base\/share\/classes\/java\/lang\/constant\/ClassDesc.java","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -55,0 +55,2 @@\n+\n+import jdk.internal.constant.ConstantUtils;\n@@ -67,0 +69,1 @@\n+import static jdk.internal.constant.ConstantUtils.*;\n@@ -253,1 +256,1 @@\n-            var mt = methodType(m.getReturnType(), JLRA.getExecutableSharedParameterTypes(m), true);\n+            var md = methodTypeDesc(m.getReturnType(), JLRA.getExecutableSharedParameterTypes(m));\n@@ -258,1 +261,1 @@\n-                                                       Arrays.stream(thrown).map(MethodHandleProxies::desc))\n+                                                       Arrays.stream(thrown).map(ConstantUtils::referenceClassDesc))\n@@ -260,1 +263,1 @@\n-            methods.add(new MethodInfo(desc(mt), exceptionTypeDescs, fieldName));\n+            methods.add(new MethodInfo(md, exceptionTypeDescs, fieldName));\n@@ -283,1 +286,2 @@\n-        byte[] template = createTemplate(loader, ClassDesc.of(className), desc(intfc), uniqueName, methods);\n+        byte[] template = createTemplate(loader, binaryNameToDesc(className),\n+                referenceClassDesc(intfc), uniqueName, methods);\n@@ -339,3 +343,3 @@\n-    private static final List<ClassDesc> DEFAULT_RETHROWS = List.of(desc(RuntimeException.class), desc(Error.class));\n-    private static final ClassDesc CD_UndeclaredThrowableException = desc(UndeclaredThrowableException.class);\n-    private static final ClassDesc CD_IllegalAccessException = desc(IllegalAccessException.class);\n+    private static final List<ClassDesc> DEFAULT_RETHROWS = List.of(referenceClassDesc(RuntimeException.class), referenceClassDesc(Error.class));\n+    private static final ClassDesc CD_UndeclaredThrowableException = referenceClassDesc(UndeclaredThrowableException.class);\n+    private static final ClassDesc CD_IllegalAccessException = referenceClassDesc(IllegalAccessException.class);\n@@ -348,2 +352,2 @@\n-    private static final MethodTypeDesc MTD_void_Lookup_MethodHandle_MethodHandle =\n-            desc(MT_void_Lookup_MethodHandle_MethodHandle);\n+    private static final MethodTypeDesc MTD_void_Lookup_MethodHandle_MethodHandle\n+            = methodTypeDesc(MT_void_Lookup_MethodHandle_MethodHandle);\n@@ -535,10 +539,0 @@\n-    private static ClassDesc desc(Class<?> cl) {\n-        return cl.describeConstable().orElseThrow(() -> newInternalError(\"Cannot convert class \"\n-                + cl.getName() + \" to a constant\"));\n-    }\n-\n-    private static MethodTypeDesc desc(MethodType mt) {\n-        return mt.describeConstable().orElseThrow(() -> newInternalError(\"Cannot convert method type \"\n-                + mt + \" to a constant\"));\n-    }\n-\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/MethodHandleProxies.java","additions":13,"deletions":19,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -28,1 +28,0 @@\n-import jdk.internal.foreign.Utils;\n@@ -39,2 +38,0 @@\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ConcurrentMap;\n@@ -50,7 +47,0 @@\n-    static ClassValue<ConcurrentMap<Integer, MethodHandle>> ADDRESS_FACTORIES = new ClassValue<>() {\n-        @Override\n-        protected ConcurrentMap<Integer, MethodHandle> computeValue(Class<?> type) {\n-            return new ConcurrentHashMap<>();\n-        }\n-    };\n-\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/VarHandles.java","additions":0,"deletions":10,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -52,0 +52,2 @@\n+import static jdk.internal.constant.ConstantUtils.*;\n+\n@@ -137,1 +139,1 @@\n-    private ClassEntry classEntry;\n+    private final ClassEntry classEntry;\n@@ -163,1 +165,1 @@\n-    private ProxyGenerator(ClassLoader loader, String className, List<Class<?>> interfaces,\n+    private ProxyGenerator(String className, List<Class<?>> interfaces,\n@@ -166,1 +168,1 @@\n-        this.classEntry = cp.classEntry(ClassDescImpl.ofValidatedBinaryName(className));\n+        this.classEntry = cp.classEntry(ConstantUtils.binaryNameToDesc(className));\n@@ -193,1 +195,1 @@\n-        ProxyGenerator gen = new ProxyGenerator(loader, name, interfaces, accessFlags);\n+        ProxyGenerator gen = new ProxyGenerator(name, interfaces, accessFlags);\n@@ -230,1 +232,1 @@\n-            ces.add(cp.classEntry(ClassDescImpl.ofValidatedBinaryName(t.getName())));\n+            ces.add(cp.classEntry(ConstantUtils.binaryNameToDesc(t.getName())));\n@@ -234,8 +236,0 @@\n-    \/**\n-     * {@return the {@code ClassDesc} of the given type}\n-     * @param type the {@code Class} object\n-     *\/\n-    private static ClassDesc toClassDesc(Class<?> type) {\n-        return ClassDesc.ofDescriptor(type.descriptorString());\n-    }\n-\n@@ -328,1 +322,1 @@\n-            ProxyMethod pm = methods.get(0);\n+            ProxyMethod pm = methods.getFirst();\n@@ -510,1 +504,1 @@\n-                (f) -> new ArrayList<>(3));\n+                _ -> new ArrayList<>(3));\n@@ -540,1 +534,1 @@\n-                (f) -> new ArrayList<>(3));\n+                _ -> new ArrayList<>(3));\n@@ -646,1 +640,0 @@\n-         * @param methodFieldName the fieldName to generate\n@@ -659,5 +652,1 @@\n-            var pTypes = new ClassDesc[parameterTypes.length];\n-            for (int i = 0; i < pTypes.length; i++) {\n-                pTypes[i] = toClassDesc(parameterTypes[i]);\n-            }\n-            MethodTypeDesc desc = MethodTypeDescImpl.ofTrusted(toClassDesc(returnType), pTypes);\n+            var desc = methodTypeDesc(returnType, parameterTypes);\n@@ -674,1 +663,1 @@\n-                                toClassDesc(fromClass),\n+                                referenceClassDesc(fromClass),\n@@ -702,1 +691,1 @@\n-                                cob.exceptionCatch(cob.startLabel(), c1, c1, toClassDesc(exc));\n+                                cob.exceptionCatch(cob.startLabel(), c1, c1, referenceClassDesc(exc));\n@@ -748,1 +737,1 @@\n-                cob.checkcast(toClassDesc(type))\n+                cob.checkcast(referenceClassDesc(type))\n","filename":"src\/java.base\/share\/classes\/java\/lang\/reflect\/ProxyGenerator.java","additions":14,"deletions":25,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -29,1 +29,0 @@\n-import java.lang.classfile.ClassBuilder;\n@@ -54,0 +53,1 @@\n+import jdk.internal.constant.ConstantUtils;\n@@ -62,0 +62,3 @@\n+import static jdk.internal.constant.ConstantUtils.classDesc;\n+import static jdk.internal.constant.ConstantUtils.referenceClassDesc;\n+\n@@ -324,1 +327,1 @@\n-            return EnumDesc.of(enumClassTemplate.describeConstable().orElseThrow(), (String) label);\n+            return EnumDesc.of(referenceClassDesc(enumClassTemplate), (String) label);\n@@ -467,4 +470,1 @@\n-                            cb.instanceOf(Wrapper.forBasicType(classLabel)\n-                                    .wrapperType()\n-                                    .describeConstable()\n-                                    .orElseThrow());\n+                            cb.instanceOf(Wrapper.forBasicType(classLabel).wrapperClassDescriptor());\n@@ -518,1 +518,1 @@\n-                            cb.invokestatic(ExactConversionsSupport.class.describeConstable().orElseThrow(),\n+                            cb.invokestatic(referenceClassDesc(ExactConversionsSupport.class),\n@@ -520,1 +520,1 @@\n-                                    MethodTypeDesc.of(ConstantDescs.CD_boolean, typePair.from.describeConstable().orElseThrow()));\n+                                    MethodTypeDesc.of(ConstantDescs.CD_boolean, classDesc(typePair.from)));\n@@ -556,1 +556,1 @@\n-                    cb.invokeinterface(BiPredicate.class.describeConstable().orElseThrow(),\n+                    cb.invokeinterface(referenceClassDesc(BiPredicate.class),\n@@ -604,1 +604,2 @@\n-                    cb.invokestatic(element.caseLabel().getClass().describeConstable().orElseThrow(),\n+                    var caseLabelWrapper = Wrapper.forWrapperType(element.caseLabel().getClass());\n+                    cb.invokestatic(caseLabelWrapper.wrapperClassDescriptor(),\n@@ -606,2 +607,2 @@\n-                            MethodTypeDesc.of(element.caseLabel().getClass().describeConstable().orElseThrow(),\n-                                    Wrapper.asPrimitiveType(element.caseLabel().getClass()).describeConstable().orElseThrow()));\n+                            MethodTypeDesc.of(caseLabelWrapper.wrapperClassDescriptor(),\n+                                    caseLabelWrapper.basicClassDescriptor()));\n@@ -634,1 +635,1 @@\n-        byte[] classBytes = ClassFile.of().build(ClassDescImpl.ofValidatedBinaryName(typeSwitchClassName(caller.lookupClass())),\n+        byte[] classBytes = ClassFile.of().build(ConstantUtils.binaryNameToDesc(typeSwitchClassName(caller.lookupClass())),\n","filename":"src\/java.base\/share\/classes\/java\/lang\/runtime\/SwitchBootstraps.java","additions":14,"deletions":13,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -69,0 +69,2 @@\n+        assert ConstantUtils.skipOverFieldSignature(descriptor, 0, descriptor.length(), false)\n+                == descriptor.length() : descriptor;\n@@ -72,11 +74,0 @@\n-    \/**\n-     * Creates a {@linkplain ClassDesc} from a pre-validated descriptor string\n-     * for a class or interface type or an array type.\n-     *\n-     * @param descriptor a field descriptor string for a class or interface type\n-     * @jvms 4.3.2 Field Descriptors\n-     *\/\n-    public static ClassDesc ofValidatedBinaryName(String typeSwitchClassName) {\n-        return ofValidated(\"L\" + binaryToInternal(typeSwitchClassName) + \";\");\n-    }\n-\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/constant\/ClassDescImpl.java","additions":2,"deletions":11,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -32,0 +32,2 @@\n+import java.lang.constant.MethodTypeDesc;\n+import java.lang.invoke.MethodType;\n@@ -44,0 +46,1 @@\n+    public static final ClassDesc CD_module_info = binaryNameToDesc(\"module-info\");\n@@ -50,0 +53,72 @@\n+    \/\/ Note:\n+    \/\/ Non-JDK users should create their own utilities that wrap\n+    \/\/ {@code .describeConstable().orElseThrow()} calls;\n+    \/\/ these xxDesc methods has undefined and unsafe exceptional\n+    \/\/ behavior, so they are not suitable as public APIs.\n+\n+    \/**\n+     * Creates a {@linkplain ClassDesc} from a pre-validated binary name\n+     * for a class or interface type. Validated version of {@link\n+     * ClassDesc#of(String)}.\n+     *\n+     * @param binaryName a binary name\n+     *\/\n+    public static ClassDesc binaryNameToDesc(String binaryName) {\n+        return ClassDescImpl.ofValidated(\"L\" + binaryToInternal(binaryName) + \";\");\n+    }\n+\n+    \/**\n+     * Creates a ClassDesc from a Class object, requires that this class\n+     * can always be described nominally, i.e. this class is not a\n+     * hidden class or interface or an array with a hidden component\n+     * type.\n+     *\/\n+    public static ClassDesc classDesc(Class<?> type) {\n+        if (type.isPrimitive()) {\n+            return Wrapper.forPrimitiveType(type).basicClassDescriptor();\n+        }\n+        return referenceClassDesc(type);\n+    }\n+\n+    \/**\n+     * Creates a ClassDesc from a Class object representing a non-hidden\n+     * class or interface or an array type with a non-hidden component type.\n+     *\/\n+    public static ClassDesc referenceClassDesc(Class<?> type) {\n+        return ClassDescImpl.ofValidated(type.descriptorString());\n+    }\n+\n+    \/**\n+     * Creates a MethodTypeDesc from a MethodType object, requires that\n+     * the type can be described nominally, i.e. all of its return\n+     * type and parameter types can be described nominally.\n+     *\/\n+    public static MethodTypeDesc methodTypeDesc(MethodType type) {\n+        var returnDesc = classDesc(type.returnType());\n+        if (type.parameterCount() == 0) {\n+            return MethodTypeDescImpl.ofValidated(returnDesc, EMPTY_CLASSDESC);\n+        }\n+        var paramDescs = new ClassDesc[type.parameterCount()];\n+        for (int i = 0; i < type.parameterCount(); i++) {\n+            paramDescs[i] = classDesc(type.parameterType(i));\n+        }\n+        return MethodTypeDescImpl.ofValidated(returnDesc, paramDescs);\n+    }\n+\n+    \/**\n+     * Creates a MethodTypeDesc from return class and parameter\n+     * class objects, requires that all of them can be described nominally.\n+     * This version is mainly useful for working with Method objects.\n+     *\/\n+    public static MethodTypeDesc methodTypeDesc(Class<?> returnType, Class<?>[] parameterTypes) {\n+        var returnDesc = classDesc(returnType);\n+        if (parameterTypes.length == 0) {\n+            return MethodTypeDescImpl.ofValidated(returnDesc, EMPTY_CLASSDESC);\n+        }\n+        var paramDescs = new ClassDesc[parameterTypes.length];\n+        for (int i = 0; i < parameterTypes.length; i++) {\n+            paramDescs[i] = classDesc(parameterTypes[i]);\n+        }\n+        return MethodTypeDescImpl.ofValidated(returnDesc, paramDescs);\n+    }\n+\n@@ -234,1 +309,1 @@\n-            return Wrapper.forPrimitiveType(descriptor.charAt(start)).classDescriptor();\n+            return Wrapper.forPrimitiveType(descriptor.charAt(start)).basicClassDescriptor();\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/constant\/ConstantUtils.java","additions":76,"deletions":1,"binary":false,"changes":77,"status":"modified"},{"patch":"@@ -54,12 +54,0 @@\n-compiler\/rtm\/locking\/TestRTMAbortRatio.java 8183263 generic-x64,generic-i586\n-compiler\/rtm\/locking\/TestRTMAbortThreshold.java 8183263 generic-x64,generic-i586\n-compiler\/rtm\/locking\/TestRTMAfterNonRTMDeopt.java 8183263 generic-x64,generic-i586\n-compiler\/rtm\/locking\/TestRTMDeoptOnHighAbortRatio.java 8183263 generic-x64,generic-i586\n-compiler\/rtm\/locking\/TestRTMDeoptOnLowAbortRatio.java 8183263 generic-x64,generic-i586\n-compiler\/rtm\/locking\/TestRTMLockingCalculationDelay.java 8183263 generic-x64,generic-i586\n-compiler\/rtm\/locking\/TestRTMLockingThreshold.java 8183263 generic-x64,generic-i586\n-compiler\/rtm\/locking\/TestRTMSpinLoopCount.java 8183263 generic-x64,generic-i586\n-compiler\/rtm\/locking\/TestUseRTMDeopt.java 8183263 generic-x64,generic-i586\n-compiler\/rtm\/locking\/TestUseRTMXendForLockBusy.java 8183263 generic-x64,generic-i586\n-compiler\/rtm\/print\/TestPrintPreciseRTMLockingStatistics.java 8183263 generic-x64,generic-i586\n-\n@@ -84,2 +72,0 @@\n-compiler\/rangechecks\/TestArrayAccessAboveRCAfterRCCastIIEliminated.java 8332369 generic-all\n-\n@@ -124,5 +110,0 @@\n-applications\/jcstress\/accessAtomic.java 8325984 generic-all\n-applications\/jcstress\/acqrel.java 8325984 generic-all\n-applications\/jcstress\/atomicity.java 8325984 generic-all\n-applications\/jcstress\/coherence.java 8325984 generic-all\n-\n@@ -228,1 +209,1 @@\n-vmTestbase\/vm\/mlvm\/meth\/stress\/compiler\/deoptimize\/Test.java#id1 8325905 generic-all\n+vmTestbase\/vm\/mlvm\/meth\/stress\/compiler\/deoptimize\/Test.java#id1 8324756 generic-all\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":1,"deletions":20,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -266,1 +266,0 @@\n-  compiler\/rtm\/ \\\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -381,0 +381,20 @@\n+    public static final String CBNZW_HI = PREFIX + \"CBNZW_HI\" + POSTFIX;\n+    static {\n+        optoOnly(CBNZW_HI, \"cbwhi\");\n+    }\n+\n+    public static final String CBZW_LS = PREFIX + \"CBZW_LS\" + POSTFIX;\n+    static {\n+        optoOnly(CBZW_LS, \"cbwls\");\n+    }\n+\n+    public static final String CBZ_LS = PREFIX + \"CBZ_LS\" + POSTFIX;\n+    static {\n+        optoOnly(CBZ_LS, \"cbls\");\n+    }\n+\n+    public static final String CBZ_HI = PREFIX + \"CBZ_HI\" + POSTFIX;\n+    static {\n+        optoOnly(CBZ_HI, \"cbhi\");\n+    }\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/IRNode.java","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -55,1 +55,4 @@\n-        System.exit(run(argv,System.out) + JCK_STATUS_BASE);\n+        int result = run(argv, System.out);\n+        if (result != 0) {\n+            throw new RuntimeException(\"Test failed\");\n+        }\n","filename":"test\/hotspot\/jtreg\/vmTestbase\/nsk\/jdwp\/ReferenceType\/Interfaces\/interfaces001.java","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -629,0 +629,2 @@\n+security\/infra\/java\/security\/cert\/CertPathValidator\/certification\/CAInterop.java#teliasonerarootcav1  8333640 generic-all\n+\n","filename":"test\/jdk\/ProblemList.txt","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"}]}