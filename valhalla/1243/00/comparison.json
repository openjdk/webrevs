{"files":[{"patch":"@@ -7453,0 +7453,11 @@\n+void Assembler::evaddph(XMMRegister dst, XMMRegister nds, Address src, int vector_len) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FVM, \/* input_size_in_bits *\/ EVEX_NObit);\n+  vex_prefix(src, nds->encoding(), dst->encoding(), VEX_SIMD_NONE, VEX_OPCODE_MAP5, &attributes);\n+  emit_int8(0x58);\n+  emit_operand(dst, src, 0);\n+}\n+\n@@ -7461,0 +7472,11 @@\n+void Assembler::evsubph(XMMRegister dst, XMMRegister nds, Address src, int vector_len) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FVM, \/* input_size_in_bits *\/ EVEX_NObit);\n+  vex_prefix(src, nds->encoding(), dst->encoding(), VEX_SIMD_NONE, VEX_OPCODE_MAP5, &attributes);\n+  emit_int8(0x5C);\n+  emit_operand(dst, src, 0);\n+}\n+\n@@ -7469,0 +7491,11 @@\n+void Assembler::evmulph(XMMRegister dst, XMMRegister nds, Address src, int vector_len) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FVM, \/* input_size_in_bits *\/ EVEX_NObit);\n+  vex_prefix(src, nds->encoding(), dst->encoding(), VEX_SIMD_NONE, VEX_OPCODE_MAP5, &attributes);\n+  emit_int8(0x59);\n+  emit_operand(dst, src, 0);\n+}\n+\n@@ -7477,0 +7510,11 @@\n+void Assembler::evminph(XMMRegister dst, XMMRegister nds, Address src, int vector_len) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FVM, \/* input_size_in_bits *\/ EVEX_NObit);\n+  vex_prefix(src, nds->encoding(), dst->encoding(), VEX_SIMD_NONE, VEX_OPCODE_MAP5, &attributes);\n+  emit_int8(0x5D);\n+  emit_operand(dst, src, 0);\n+}\n+\n@@ -7485,0 +7529,11 @@\n+void Assembler::evmaxph(XMMRegister dst, XMMRegister nds, Address src, int vector_len) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FVM, \/* input_size_in_bits *\/ EVEX_NObit);\n+  vex_prefix(src, nds->encoding(), dst->encoding(), VEX_SIMD_NONE, VEX_OPCODE_MAP5, &attributes);\n+  emit_int8(0x5F);\n+  emit_operand(dst, src, 0);\n+}\n+\n@@ -7493,0 +7548,49 @@\n+void Assembler::evdivph(XMMRegister dst, XMMRegister nds, Address src, int vector_len) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FVM, \/* input_size_in_bits *\/ EVEX_NObit);\n+  vex_prefix(src, nds->encoding(), dst->encoding(), VEX_SIMD_NONE, VEX_OPCODE_MAP5, &attributes);\n+  emit_int8(0x5E);\n+  emit_operand(dst, src, 0);\n+}\n+\n+void Assembler::evsqrtph(XMMRegister dst, XMMRegister src1, int vector_len) {\n+  assert(VM_Version::supports_avx512_fp16(), \"\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src1->encoding(), VEX_SIMD_NONE, VEX_OPCODE_MAP5, &attributes);\n+  emit_int16(0x51, (0xC0 | encode));\n+}\n+\n+void Assembler::evsqrtph(XMMRegister dst, Address src, int vector_len) {\n+  assert(VM_Version::supports_avx512_fp16(), \"\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n+  vex_prefix(src, 0, dst->encoding(), VEX_SIMD_NONE, VEX_OPCODE_MAP5, &attributes);\n+  emit_int8(0x51);\n+  emit_operand(dst, src, 0);\n+}\n+\n+void Assembler::evfmadd132ph(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n+  assert(VM_Version::supports_avx512_fp16(), \"\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_MAP6, &attributes);\n+  emit_int16(0x98, (0xC0 | encode));\n+}\n+\n+void Assembler::evfmadd132ph(XMMRegister dst, XMMRegister nds, Address src, int vector_len) {\n+  assert(VM_Version::supports_avx512_fp16(), \"\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_NObit);\n+  vex_prefix(src, nds->encoding(), dst->encoding(), VEX_SIMD_66, VEX_OPCODE_MAP6, &attributes);\n+  emit_int8(0x98);\n+  emit_operand(dst, src, 0);\n+}\n+\n@@ -7541,0 +7645,16 @@\n+void Assembler::esqrtsh(XMMRegister dst, XMMRegister src) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionAttr attributes(AVX_128bit, false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_F3, VEX_OPCODE_MAP5, &attributes);\n+  emit_int16(0x51, (0xC0 | encode));\n+}\n+\n+void Assembler::efmadd132sh(XMMRegister dst, XMMRegister src1, XMMRegister src2) {\n+  assert(VM_Version::supports_avx512_fp16(), \"\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_66, VEX_OPCODE_MAP6, &attributes);\n+  emit_int16((unsigned char)0x99, (0xC0 | encode));\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":120,"deletions":0,"binary":false,"changes":120,"status":"modified"},{"patch":"@@ -552,0 +552,1 @@\n+    VEX_OPCODE_MAP6  = 0x6,\n@@ -2415,0 +2416,2 @@\n+\n+  \/\/ FP16 instructions\n@@ -2421,0 +2424,3 @@\n+  void esqrtsh(XMMRegister dst, XMMRegister src);\n+  void efmadd132sh(XMMRegister dst, XMMRegister src1, XMMRegister src2);\n+\n@@ -2422,0 +2428,1 @@\n+  void evaddph(XMMRegister dst, XMMRegister nds, Address src, int vector_len);\n@@ -2423,0 +2430,1 @@\n+  void evsubph(XMMRegister dst, XMMRegister nds, Address src, int vector_len);\n@@ -2424,0 +2432,1 @@\n+  void evdivph(XMMRegister dst, XMMRegister nds, Address src, int vector_len);\n@@ -2425,0 +2434,1 @@\n+  void evmulph(XMMRegister dst, XMMRegister nds, Address src, int vector_len);\n@@ -2426,0 +2436,1 @@\n+  void evminph(XMMRegister dst, XMMRegister nds, Address src, int vector_len);\n@@ -2427,0 +2438,5 @@\n+  void evmaxph(XMMRegister dst, XMMRegister nds, Address src, int vector_len);\n+  void evfmadd132ph(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n+  void evfmadd132ph(XMMRegister dst, XMMRegister nds, Address src, int vector_len);\n+  void evsqrtph(XMMRegister dst, XMMRegister src1, int vector_len);\n+  void evsqrtph(XMMRegister dst, Address src1, int vector_len);\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":16,"deletions":0,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -6550,0 +6550,12 @@\n+\n+void C2_MacroAssembler::evfp16ph(int opcode, XMMRegister dst, XMMRegister src1, Address src2, int vlen_enc) {\n+  switch(opcode) {\n+    case Op_AddVHF: evaddph(dst, src1, src2, vlen_enc); break;\n+    case Op_SubVHF: evsubph(dst, src1, src2, vlen_enc); break;\n+    case Op_MulVHF: evmulph(dst, src1, src2, vlen_enc); break;\n+    case Op_DivVHF: evdivph(dst, src1, src2, vlen_enc); break;\n+    case Op_MaxVHF: evminph(dst, src1, src2, vlen_enc); break;\n+    case Op_MinVHF: evmaxph(dst, src1, src2, vlen_enc); break;\n+    default: assert(false, \"%s\", NodeClassNames[opcode]); break;\n+  }\n+}\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -508,0 +508,2 @@\n+  void evfp16ph(int opcode, XMMRegister dst, XMMRegister src1, Address src2, int vlen_enc);\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1466,0 +1466,1 @@\n+    case Op_AbsHF:\n@@ -1467,2 +1468,0 @@\n-    case Op_SubHF:\n-    case Op_MulHF:\n@@ -1470,0 +1469,1 @@\n+    case Op_FmaHF:\n@@ -1472,0 +1472,2 @@\n+    case Op_MulHF:\n+    case Op_NegHF:\n@@ -1474,0 +1476,2 @@\n+    case Op_SubHF:\n+    case Op_SqrtHF:\n@@ -1742,0 +1746,1 @@\n+    case Op_AbsVHF:\n@@ -1743,2 +1748,0 @@\n-    case Op_SubVHF:\n-    case Op_MulVHF:\n@@ -1746,0 +1749,1 @@\n+    case Op_FmaVHF:\n@@ -1748,0 +1752,4 @@\n+    case Op_MulVHF:\n+    case Op_NegVHF:\n+    case Op_SubVHF:\n+    case Op_SqrtVHF:\n@@ -10155,1 +10163,1 @@\n-instruct reinterpretS2H (regF dst, rRegI src)\n+instruct reinterpretS2H(regF dst, rRegI src)\n@@ -10165,1 +10173,1 @@\n-instruct convF2HFAndS2HF (regF dst, regF src)\n+instruct convF2HFAndS2HF(regF dst, regF src)\n@@ -10175,1 +10183,1 @@\n-instruct reinterpretH2S (rRegI dst, regF src)\n+instruct reinterpretH2S(rRegI dst, regF src)\n@@ -10185,1 +10193,38 @@\n-instruct fp16_scalar_ops (regF dst, regF src1, regF src2)\n+instruct scalar_abs_fp16(regF dst, regF src, rRegI rtmp, vec xtmp)\n+%{\n+  match(Set dst (AbsHF src));\n+  effect(TEMP rtmp, TEMP xtmp);\n+  format %{ \"eabssh $dst, $src !\\t using $rtmp and $xtmp as TEMP\" %}\n+  ins_encode %{\n+    __ movl($rtmp$$Register, 0x7FFF);\n+    __ vmovw($xtmp$$XMMRegister, $rtmp$$Register);\n+    __ vpand($dst$$XMMRegister, $src$$XMMRegister, $xtmp$$XMMRegister, Assembler::AVX_128bit);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct scalar_neg_fp16(regF dst, regF src, rRegI rtmp, vec xtmp)\n+%{\n+  match(Set dst (NegHF src));\n+  effect(TEMP rtmp, TEMP xtmp);\n+  format %{ \"enegsh $dst, $src !\\t using $rtmp and $xtmp as TEMP\" %}\n+  ins_encode %{\n+    __ movl($rtmp$$Register, 0x8000);\n+    __ vmovw($xtmp$$XMMRegister, $rtmp$$Register);\n+    __ vpxor($dst$$XMMRegister, $src$$XMMRegister, $xtmp$$XMMRegister, Assembler::AVX_128bit);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct scalar_sqrt_fp16(regF dst, regF src)\n+%{\n+  match(Set dst (SqrtHF src));\n+  format %{ \"esqrtsh $dst, $src\" %}\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n+    __ esqrtsh($dst$$XMMRegister, $src$$XMMRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct scalar_binOps_fp16(regF dst, regF src1, regF src2)\n@@ -10188,2 +10233,0 @@\n-  match(Set dst (SubHF src1 src2));\n-  match(Set dst (MulHF src1 src2));\n@@ -10191,1 +10234,0 @@\n-  match(Set dst (MinHF src1 src2));\n@@ -10193,0 +10235,3 @@\n+  match(Set dst (MinHF src1 src2));\n+  match(Set dst (MulHF src1 src2));\n+  match(Set dst (SubHF src1 src2));\n@@ -10201,1 +10246,99 @@\n-instruct fp16_vector_ops (vec dst, vec src1, vec src2)\n+instruct scalar_fma_fp16(regF dst, regF src1, regF src2)\n+%{\n+  match(Set dst (FmaHF  src2 (Binary dst src1)));\n+  effect(DEF dst);\n+  format %{ \"evfmash $dst, $src1, $src2\\t# $dst = $dst * $src1 + $src2 fma packedH\" %}\n+  ins_cost(150);\n+  ins_encode %{\n+    __ efmadd132sh($dst$$XMMRegister, $src2$$XMMRegister, $src1$$XMMRegister);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vector_abs_fp16_reg(vec dst, vec src, rRegI rtmp, vec xtmp)\n+%{\n+  match(Set dst (AbsVHF src));\n+  format %{ \"evabsph_reg $dst, $src !\\t using $rtmp and $xtmp as TEMP\" %}\n+  effect(TEMP rtmp, TEMP xtmp);\n+  ins_cost(150);\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    __ movl($rtmp$$Register, 0x7FFF7FFF);\n+    __ vpbroadcast(T_FLOAT, $xtmp$$XMMRegister, $rtmp$$Register, vlen_enc);\n+    __ vpand($dst$$XMMRegister, $src$$XMMRegister, $xtmp$$XMMRegister, vlen_enc);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vector_abs_fp16_mem(vec dst, memory src, rRegI rtmp, vec xtmp)\n+%{\n+  match(Set dst (AbsVHF src));\n+  effect(TEMP rtmp, TEMP xtmp);\n+  format %{ \"evabsph_reg $dst, $src !\\t using $rtmp and $xtmp as TEMP\" %}\n+  ins_cost(150);\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    __ movl($rtmp$$Register, 0x7FFF7FFF);\n+    __ vpbroadcast(T_FLOAT, $xtmp$$XMMRegister, $rtmp$$Register, vlen_enc);\n+    __ vpand($dst$$XMMRegister, $xtmp$$XMMRegister, $src$$Address, vlen_enc);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vector_neg_fp16_reg(vec dst, vec src, rRegI rtmp, vec xtmp)\n+%{\n+  match(Set dst (NegVHF src));\n+  effect(TEMP rtmp, TEMP xtmp);\n+  format %{ \"evnegph_reg $dst, $src !\\t using $rtmp and $xtmp as TEMP\" %}\n+  ins_cost(150);\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    __ movl($rtmp$$Register, 0x80008000);\n+    __ vpbroadcast(T_FLOAT, $xtmp$$XMMRegister, $rtmp$$Register, vlen_enc);\n+    __ vpxor($dst$$XMMRegister, $src$$XMMRegister, $xtmp$$XMMRegister, vlen_enc);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vector_neg_fp16_mem(vec dst, memory src, rRegI rtmp, vec xtmp)\n+%{\n+  match(Set dst (NegVHF src));\n+  effect(TEMP rtmp, TEMP xtmp);\n+  format %{ \"evnegph_reg $dst, $src !\\t using $rtmp and $xtmp as TEMP\" %}\n+  ins_cost(150);\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    __ movl($rtmp$$Register, 0x80008000);\n+    __ vpbroadcast(T_FLOAT, $xtmp$$XMMRegister, $rtmp$$Register, vlen_enc);\n+    __ vpxor($dst$$XMMRegister, $xtmp$$XMMRegister, $src$$Address, vlen_enc);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vector_sqrt_fp16_reg(vec dst, vec src)\n+%{\n+  match(Set dst (SqrtVHF src));\n+  format %{ \"evsqrtph_reg $dst, $src\" %}\n+  ins_cost(150);\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    int opcode = this->ideal_Opcode();\n+    __ evsqrtph($dst$$XMMRegister, $src$$Address, vlen_enc);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vector_sqrt_fp16_mem(vec dst, memory src)\n+%{\n+  match(Set dst (SqrtVHF (VectorReinterpret (LoadVector src))));\n+  format %{ \"evsqrtph_mem $dst, $src\" %}\n+  ins_cost(150);\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    int opcode = this->ideal_Opcode();\n+    __ evsqrtph($dst$$XMMRegister, $src$$Address, vlen_enc);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vector_binOps_fp16_reg(vec dst, vec src1, vec src2)\n@@ -10204,2 +10347,0 @@\n-  match(Set dst (SubVHF src1 src2));\n-  match(Set dst (MulVHF src1 src2));\n@@ -10209,1 +10350,4 @@\n-  format %{ \"evfp16ph $dst, $src1, $src2\" %}\n+  match(Set dst (MulVHF src1 src2));\n+  match(Set dst (SubVHF src1 src2));\n+  format %{ \"evbinopfp16_reg $dst, $src1, $src2\" %}\n+  ins_cost(450);\n@@ -10218,0 +10362,44 @@\n+instruct vector_binOps_fp16_mem(vec dst, vec src1, memory src2)\n+%{\n+  match(Set dst (AddVHF src1 (VectorReinterpret (LoadVector src2))));\n+  match(Set dst (DivVHF src1 (VectorReinterpret (LoadVector src2))));\n+  match(Set dst (MaxVHF src1 (VectorReinterpret (LoadVector src2))));\n+  match(Set dst (MinVHF src1 (VectorReinterpret (LoadVector src2))));\n+  match(Set dst (MulVHF src1 (VectorReinterpret (LoadVector src2))));\n+  match(Set dst (SubVHF src1 (VectorReinterpret (LoadVector src2))));\n+  format %{ \"evbinopfp16_mem $dst, $src1, $src2\" %}\n+  ins_cost(150);\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    int opcode = this->ideal_Opcode();\n+    __ evfp16ph(opcode, $dst$$XMMRegister, $src1$$XMMRegister, $src2$$Address, vlen_enc);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vector_fma_fp16_reg(vec dst, vec src1, vec src2)\n+%{\n+  match(Set dst (FmaVHF src2 (Binary dst src1)));\n+  effect(DEF dst);\n+  format %{ \"evfmaph_reg $dst, $src1, $src2\\t# $dst = $dst * $src1 + $src2 fma packedH\" %}\n+  ins_cost(450);\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    __ evfmadd132ph($dst$$XMMRegister, $src2$$XMMRegister, $src1$$XMMRegister, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vector_fmah_fp16_mem(vec dst, memory src1, vec src2)\n+%{\n+  match(Set dst (FmaVHF src2 (Binary dst (VectorReinterpret (LoadVector src1)))));\n+  effect(DEF dst);\n+  format %{ \"evfmaph_mem $dst, $src1, $src2\\t# $dst = $dst * $src1 + $src2 fma packedH\" %}\n+  ins_cost(150);\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    __ evfmadd132ph($dst$$XMMRegister, $src2$$XMMRegister, $src1$$Address, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":203,"deletions":15,"binary":false,"changes":218,"status":"modified"},{"patch":"@@ -150,0 +150,2 @@\n+    @IR(counts = {IRNode.ABS_HF, \"> 0\", IRNode.REINTERPRET_S2HF, \"> 0\", IRNode.REINTERPRET_HF2S, \"> 0\"},\n+        applyIfCPUFeature = {\"avx512_fp16\", \"true\"})\n@@ -161,0 +163,2 @@\n+    @IR(counts = {IRNode.NEG_HF, \"> 0\", IRNode.REINTERPRET_S2HF, \"> 0\", IRNode.REINTERPRET_HF2S, \"> 0\"},\n+        applyIfCPUFeature = {\"avx512_fp16\", \"true\"})\n@@ -172,0 +176,2 @@\n+    @IR(counts = {IRNode.SQRT_HF, \"> 0\", IRNode.REINTERPRET_S2HF, \"> 0\", IRNode.REINTERPRET_HF2S, \"> 0\"},\n+        applyIfCPUFeature = {\"avx512_fp16\", \"true\"})\n@@ -183,0 +189,2 @@\n+    @IR(counts = {IRNode.FMA_HF, \"> 0\", IRNode.REINTERPRET_S2HF, \"> 0\", IRNode.REINTERPRET_HF2S, \"> 0\"},\n+        applyIfCPUFeature = {\"avx512_fp16\", \"true\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/intrinsics\/float16\/TestFP16ScalarOps.java","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -194,1 +194,1 @@\n-        applyIfCPUFeature = {\"sve\", \"true\"})\n+        applyIfCPUFeatureOr = {\"avx512_fp16\", \"true\", \"sve\", \"true\"})\n@@ -216,1 +216,1 @@\n-        applyIfCPUFeature = {\"sve\", \"true\"})\n+        applyIfCPUFeatureOr = {\"avx512_fp16\", \"true\", \"sve\", \"true\"})\n@@ -238,1 +238,1 @@\n-        applyIfCPUFeature = {\"sve\", \"true\"})\n+        applyIfCPUFeatureOr = {\"avx512_fp16\", \"true\", \"sve\", \"true\"})\n@@ -260,1 +260,1 @@\n-        applyIfCPUFeature = {\"sve\", \"true\"})\n+        applyIfCPUFeatureOr = {\"avx512_fp16\", \"true\", \"sve\", \"true\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/TestFloat16VectorOps.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"}]}