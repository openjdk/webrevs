{"files":[{"patch":"@@ -2,0 +2,1 @@\n+<<<<<<< HEAD\n@@ -3,0 +4,4 @@\n+=======\n+ * Copyright (c) 2018, 2022, Red Hat, Inc. All rights reserved.\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n+>>>>>>> d1bc34fb4cbbaea51c470a6bc088e04427ea82d3\n@@ -28,0 +33,1 @@\n+#include \"gc\/shenandoah\/mode\/shenandoahMode.hpp\"\n@@ -75,1 +81,0 @@\n-  \/\/ TODO: can we directly test if bit is set?\n@@ -193,0 +198,10 @@\n+\n+  if (ShenandoahCardBarrier && access.is_oop()) {\n+    DecoratorSet decorators = access.decorators();\n+    bool is_array = (decorators & IS_ARRAY) != 0;\n+    bool on_anonymous = (decorators & ON_UNKNOWN_OOP_REF) != 0;\n+\n+    bool precise = is_array || on_anonymous;\n+    LIR_Opr post_addr = precise ? access.resolved_addr() : access.base().opr();\n+    post_barrier(access, post_addr, value);\n+  }\n@@ -291,0 +306,59 @@\n+\n+void ShenandoahBarrierSetC1::post_barrier(LIRAccess& access, LIR_Opr addr, LIR_Opr new_val) {\n+  assert(ShenandoahCardBarrier, \"Should have been checked by caller\");\n+\n+  DecoratorSet decorators = access.decorators();\n+  LIRGenerator* gen = access.gen();\n+  bool in_heap = (decorators & IN_HEAP) != 0;\n+  if (!in_heap) {\n+    return;\n+  }\n+\n+  BarrierSet* bs = BarrierSet::barrier_set();\n+  ShenandoahBarrierSet* ctbs = barrier_set_cast<ShenandoahBarrierSet>(bs);\n+  CardTable* ct = ctbs->card_table();\n+  LIR_Const* card_table_base = new LIR_Const(ct->byte_map_base());\n+  if (addr->is_address()) {\n+    LIR_Address* address = addr->as_address_ptr();\n+    \/\/ ptr cannot be an object because we use this barrier for array card marks\n+    \/\/ and addr can point in the middle of an array.\n+    LIR_Opr ptr = gen->new_pointer_register();\n+    if (!address->index()->is_valid() && address->disp() == 0) {\n+      __ move(address->base(), ptr);\n+    } else {\n+      assert(address->disp() != max_jint, \"lea doesn't support patched addresses!\");\n+      __ leal(addr, ptr);\n+    }\n+    addr = ptr;\n+  }\n+  assert(addr->is_register(), \"must be a register at this point\");\n+\n+  LIR_Opr tmp = gen->new_pointer_register();\n+  if (two_operand_lir_form) {\n+    __ move(addr, tmp);\n+    __ unsigned_shift_right(tmp, CardTable::card_shift(), tmp);\n+  } else {\n+    __ unsigned_shift_right(addr, CardTable::card_shift(), tmp);\n+  }\n+\n+  LIR_Address* card_addr;\n+  if (gen->can_inline_as_constant(card_table_base)) {\n+    card_addr = new LIR_Address(tmp, card_table_base->as_jint(), T_BYTE);\n+  } else {\n+    card_addr = new LIR_Address(tmp, gen->load_constant(card_table_base), T_BYTE);\n+  }\n+\n+  LIR_Opr dirty = LIR_OprFact::intConst(CardTable::dirty_card_val());\n+  if (UseCondCardMark) {\n+    LIR_Opr cur_value = gen->new_register(T_INT);\n+    __ move(card_addr, cur_value);\n+\n+    LabelObj* L_already_dirty = new LabelObj();\n+    __ cmp(lir_cond_equal, cur_value, dirty);\n+    __ branch(lir_cond_equal, L_already_dirty->label());\n+    __ move(dirty, card_addr);\n+    __ branch_destination(L_already_dirty->label());\n+  } else {\n+    __ move(dirty, card_addr);\n+  }\n+}\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/c1\/shenandoahBarrierSetC1.cpp","additions":75,"deletions":1,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+<<<<<<< HEAD\n@@ -4,0 +5,3 @@\n+=======\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n+>>>>>>> d1bc34fb4cbbaea51c470a6bc088e04427ea82d3\n@@ -28,0 +32,1 @@\n+#include \"gc\/shenandoah\/shenandoahAgeCensus.hpp\"\n@@ -44,0 +49,1 @@\n+  _has_old_regions(false),\n@@ -46,0 +52,1 @@\n+  _live(0),\n@@ -47,0 +54,2 @@\n+  _old_garbage(0),\n+  _preselected_regions(nullptr),\n@@ -87,0 +96,2 @@\n+  assert(!r->is_humongous(), \"Only add regular regions to the collection set\");\n+\n@@ -88,0 +99,14 @@\n+  size_t live    = r->get_live_data_bytes();\n+  size_t garbage = r->garbage();\n+  size_t free    = r->free();\n+  if (r->is_young()) {\n+    _young_bytes_to_evacuate += live;\n+    _young_available_bytes_collected += free;\n+    if (ShenandoahHeap::heap()->mode()->is_generational() && r->age() >= ShenandoahGenerationalHeap::heap()->age_census()->tenuring_threshold()) {\n+      _young_bytes_to_promote += live;\n+    }\n+  } else if (r->is_old()) {\n+    _old_bytes_to_evacuate += live;\n+    _old_garbage += garbage;\n+  }\n+\n@@ -89,1 +114,2 @@\n-  _garbage += r->garbage();\n+  _has_old_regions |= r->is_old();\n+  _garbage += garbage;\n@@ -91,1 +117,1 @@\n-\n+  _live += live;\n@@ -98,0 +124,1 @@\n+\n@@ -107,0 +134,1 @@\n+  _old_garbage = 0;\n@@ -108,0 +136,1 @@\n+  _live = 0;\n@@ -111,0 +140,8 @@\n+\n+  _young_bytes_to_evacuate = 0;\n+  _young_bytes_to_promote = 0;\n+  _old_bytes_to_evacuate = 0;\n+\n+  _young_available_bytes_collected = 0;\n+\n+  _has_old_regions = false;\n@@ -154,1 +191,5 @@\n-  out->print_cr(\"Collection Set : \" SIZE_FORMAT \"\", count());\n+  out->print_cr(\"Collection Set: Regions: \"\n+                SIZE_FORMAT \", Garbage: \" SIZE_FORMAT \"%s, Live: \" SIZE_FORMAT \"%s, Used: \" SIZE_FORMAT \"%s\", count(),\n+                byte_size_in_proper_unit(garbage()), proper_unit_for_byte_size(garbage()),\n+                byte_size_in_proper_unit(live()),    proper_unit_for_byte_size(live()),\n+                byte_size_in_proper_unit(used()),    proper_unit_for_byte_size(used()));\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahCollectionSet.cpp","additions":44,"deletions":3,"binary":false,"changes":47,"status":"modified"},{"patch":"@@ -28,0 +28,2 @@\n+#include \"gc\/shenandoah\/shenandoahAffiliation.hpp\"\n+#include \"gc\/shenandoah\/shenandoahBarrierSet.hpp\"\n@@ -32,0 +34,3 @@\n+#include \"gc\/shenandoah\/shenandoahOldGeneration.hpp\"\n+#include \"gc\/shenandoah\/shenandoahScanRemembered.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahYoungGeneration.hpp\"\n@@ -43,0 +48,1 @@\n+    case ShenandoahFreeSetPartitionId::OldCollector: return \"OldCollector\";\n@@ -51,5 +57,8 @@\n-  log_debug(gc)(\"Mutator range [\" SSIZE_FORMAT \", \" SSIZE_FORMAT \"], Collector range [\" SSIZE_FORMAT \", \" SSIZE_FORMAT \"]\",\n-                _leftmosts[int(ShenandoahFreeSetPartitionId::Mutator)],\n-                _rightmosts[int(ShenandoahFreeSetPartitionId::Mutator)],\n-                _leftmosts[int(ShenandoahFreeSetPartitionId::Collector)],\n-                _rightmosts[int(ShenandoahFreeSetPartitionId::Collector)]);\n+  log_debug(gc)(\"Mutator range [\" SSIZE_FORMAT \", \" SSIZE_FORMAT \"], Collector range [\" SSIZE_FORMAT \", \" SSIZE_FORMAT\n+               \"], Old Collector range [\" SSIZE_FORMAT \", \" SSIZE_FORMAT \"]\",\n+               _leftmosts[int(ShenandoahFreeSetPartitionId::Mutator)],\n+               _rightmosts[int(ShenandoahFreeSetPartitionId::Mutator)],\n+               _leftmosts[int(ShenandoahFreeSetPartitionId::Collector)],\n+               _rightmosts[int(ShenandoahFreeSetPartitionId::Collector)],\n+               _leftmosts[int(ShenandoahFreeSetPartitionId::OldCollector)],\n+               _rightmosts[int(ShenandoahFreeSetPartitionId::OldCollector)]);\n@@ -57,7 +66,10 @@\n-                \"], Empty Collector range [\" SSIZE_FORMAT \", \" SSIZE_FORMAT \"]\",\n-                _leftmosts_empty[int(ShenandoahFreeSetPartitionId::Mutator)],\n-                _rightmosts_empty[int(ShenandoahFreeSetPartitionId::Mutator)],\n-                _leftmosts_empty[int(ShenandoahFreeSetPartitionId::Collector)],\n-                _rightmosts_empty[int(ShenandoahFreeSetPartitionId::Collector)]);\n-\n-  log_debug(gc)(\"%6s: %18s %18s %18s\", \"index\", \"Mutator Bits\", \"Collector Bits\", \"NotFree Bits\");\n+               \"], Empty Collector range [\" SSIZE_FORMAT \", \" SSIZE_FORMAT\n+               \"], Empty Old Collecto range [\" SSIZE_FORMAT \", \" SSIZE_FORMAT \"]\",\n+               _leftmosts_empty[int(ShenandoahFreeSetPartitionId::Mutator)],\n+               _rightmosts_empty[int(ShenandoahFreeSetPartitionId::Mutator)],\n+               _leftmosts_empty[int(ShenandoahFreeSetPartitionId::Collector)],\n+               _rightmosts_empty[int(ShenandoahFreeSetPartitionId::Collector)],\n+               _leftmosts_empty[int(ShenandoahFreeSetPartitionId::OldCollector)],\n+               _rightmosts_empty[int(ShenandoahFreeSetPartitionId::OldCollector)]);\n+\n+  log_debug(gc)(\"%6s: %18s %18s %18s %18s\", \"index\", \"Mutator Bits\", \"Collector Bits\", \"Old Collector Bits\", \"NotFree Bits\");\n@@ -84,1 +96,2 @@\n-  uintx free_bits = mutator_bits | collector_bits;\n+  uintx old_collector_bits = _membership[int(ShenandoahFreeSetPartitionId::OldCollector)].bits_at(aligned_idx);\n+  uintx free_bits = mutator_bits | collector_bits | old_collector_bits;\n@@ -86,2 +99,2 @@\n-  log_debug(gc)(SSIZE_FORMAT_W(6) \": \" SIZE_FORMAT_X_0 \" 0x\" SIZE_FORMAT_X_0 \" 0x\" SIZE_FORMAT_X_0,\n-                aligned_idx, mutator_bits, collector_bits, notfree_bits);\n+  log_debug(gc)(SSIZE_FORMAT_W(6) \": \" SIZE_FORMAT_X_0 \" 0x\" SIZE_FORMAT_X_0 \" 0x\" SIZE_FORMAT_X_0 \" 0x\" SIZE_FORMAT_X_0,\n+               aligned_idx, mutator_bits, collector_bits, old_collector_bits, notfree_bits);\n@@ -95,1 +108,1 @@\n-    _membership{ ShenandoahSimpleBitMap(max_regions), ShenandoahSimpleBitMap(max_regions) }\n+    _membership{ ShenandoahSimpleBitMap(max_regions), ShenandoahSimpleBitMap(max_regions) , ShenandoahSimpleBitMap(max_regions) }\n@@ -165,1 +178,0 @@\n-  _region_counts[int(ShenandoahFreeSetPartitionId::Mutator)] = mutator_region_count;\n@@ -185,0 +197,14 @@\n+void ShenandoahRegionPartitions::establish_old_collector_intervals(idx_t old_collector_leftmost, idx_t old_collector_rightmost,\n+                                                                   idx_t old_collector_leftmost_empty,\n+                                                                   idx_t old_collector_rightmost_empty,\n+                                                                   size_t old_collector_region_count, size_t old_collector_used) {\n+  _leftmosts[int(ShenandoahFreeSetPartitionId::OldCollector)] = old_collector_leftmost;\n+  _rightmosts[int(ShenandoahFreeSetPartitionId::OldCollector)] = old_collector_rightmost;\n+  _leftmosts_empty[int(ShenandoahFreeSetPartitionId::OldCollector)] = old_collector_leftmost_empty;\n+  _rightmosts_empty[int(ShenandoahFreeSetPartitionId::OldCollector)] = old_collector_rightmost_empty;\n+\n+  _region_counts[int(ShenandoahFreeSetPartitionId::OldCollector)] = old_collector_region_count;\n+  _used[int(ShenandoahFreeSetPartitionId::OldCollector)] = old_collector_used;\n+  _capacity[int(ShenandoahFreeSetPartitionId::OldCollector)] = old_collector_region_count * _region_size_bytes;\n+}\n+\n@@ -205,1 +231,1 @@\n-      _leftmosts_empty[int(partition)] = leftmost(partition);\n+      _leftmosts_empty[int(partition)] = _leftmosts[int(partition)];\n@@ -292,1 +318,0 @@\n-\n@@ -296,0 +321,17 @@\n+bool ShenandoahRegionPartitions::is_mutator_partition(ShenandoahFreeSetPartitionId p) {\n+  return (p == ShenandoahFreeSetPartitionId::Mutator);\n+}\n+\n+bool ShenandoahRegionPartitions::is_young_collector_partition(ShenandoahFreeSetPartitionId p) {\n+  return (p == ShenandoahFreeSetPartitionId::Collector);\n+}\n+\n+bool ShenandoahRegionPartitions::is_old_collector_partition(ShenandoahFreeSetPartitionId p) {\n+  return (p == ShenandoahFreeSetPartitionId::OldCollector);\n+}\n+\n+bool ShenandoahRegionPartitions::available_implies_empty(size_t available_in_region) {\n+  return (available_in_region == _region_size_bytes);\n+}\n+\n+\n@@ -298,0 +340,1 @@\n+  ShenandoahHeapRegion* r = ShenandoahHeap::heap()->get_region(idx);\n@@ -302,0 +345,5 @@\n+  assert (_membership[int(orig_partition)].is_set(idx), \"Cannot move from partition unless in partition\");\n+  assert ((r != nullptr) && ((r->is_trash() && (available == _region_size_bytes)) ||\n+                             (r->used() + available == _region_size_bytes)),\n+          \"Used: \" SIZE_FORMAT \" + available: \" SIZE_FORMAT \" should equal region size: \" SIZE_FORMAT,\n+          ShenandoahHeap::heap()->get_region(idx)->used(), available, _region_size_bytes);\n@@ -305,0 +353,2 @@\n+  \/\/                          Mutator empty => Collector\n+  \/\/                          Mutator empty => OldCollector\n@@ -306,0 +356,1 @@\n+  \/\/                          Mutator empty => OldCollector\n@@ -307,8 +358,10 @@\n-  assert (((available <= _region_size_bytes) &&\n-           (((orig_partition == ShenandoahFreeSetPartitionId::Mutator)\n-             && (new_partition == ShenandoahFreeSetPartitionId::Collector)) ||\n-            ((orig_partition == ShenandoahFreeSetPartitionId::Collector)\n-             && (new_partition == ShenandoahFreeSetPartitionId::Mutator)))) ||\n-          ((available == _region_size_bytes) &&\n-           ((orig_partition == ShenandoahFreeSetPartitionId::Mutator)\n-            && (new_partition == ShenandoahFreeSetPartitionId::Collector))), \"Unexpected movement between partitions\");\n+  \/\/                          OldCollector Empty => Mutator\n+  assert ((is_mutator_partition(orig_partition) && is_young_collector_partition(new_partition)) ||\n+          (is_mutator_partition(orig_partition) &&\n+           available_implies_empty(available) && is_old_collector_partition(new_partition)) ||\n+          (is_young_collector_partition(orig_partition) && is_mutator_partition(new_partition)) ||\n+          (is_old_collector_partition(orig_partition)\n+           && available_implies_empty(available) && is_mutator_partition(new_partition)),\n+          \"Unexpected movement between partitions, available: \" SIZE_FORMAT \", _region_size_bytes: \" SIZE_FORMAT\n+          \", orig_partition: %s, new_partition: %s\",\n+          available, _region_size_bytes, partition_name(orig_partition), partition_name(new_partition));\n@@ -317,0 +370,3 @@\n+  assert (_used[int(orig_partition)] >= used,\n+          \"Orig partition used: \" SIZE_FORMAT \" must exceed moved used: \" SIZE_FORMAT \" within region \" SSIZE_FORMAT,\n+          _used[int(orig_partition)], used, idx);\n@@ -485,0 +541,1 @@\n+      case ShenandoahFreeSetPartitionId::OldCollector:\n@@ -574,0 +631,35 @@\n+\n+  \/\/ Performance invariants. Failing these would not break the free partition, but performance would suffer.\n+  assert (leftmost(ShenandoahFreeSetPartitionId::OldCollector) <= _max, \"leftmost in bounds: \"  SSIZE_FORMAT \" < \" SSIZE_FORMAT,\n+          leftmost(ShenandoahFreeSetPartitionId::OldCollector),  _max);\n+  assert (rightmost(ShenandoahFreeSetPartitionId::OldCollector) < _max, \"rightmost in bounds: \"  SSIZE_FORMAT \" < \" SSIZE_FORMAT,\n+          rightmost(ShenandoahFreeSetPartitionId::OldCollector),  _max);\n+\n+  assert (leftmost(ShenandoahFreeSetPartitionId::OldCollector) == _max\n+          || partition_id_matches(leftmost(ShenandoahFreeSetPartitionId::OldCollector),\n+                                  ShenandoahFreeSetPartitionId::OldCollector),\n+          \"leftmost region should be free: \" SSIZE_FORMAT,  leftmost(ShenandoahFreeSetPartitionId::OldCollector));\n+  assert (leftmost(ShenandoahFreeSetPartitionId::OldCollector) == _max\n+          || partition_id_matches(rightmost(ShenandoahFreeSetPartitionId::OldCollector),\n+                                  ShenandoahFreeSetPartitionId::OldCollector),\n+          \"rightmost region should be free: \" SSIZE_FORMAT, rightmost(ShenandoahFreeSetPartitionId::OldCollector));\n+\n+  \/\/ If OldCollector partition is empty, leftmosts will both equal max, rightmosts will both equal zero.\n+  \/\/ Likewise for empty region partitions.\n+  beg_off = leftmosts[int(ShenandoahFreeSetPartitionId::OldCollector)];\n+  end_off = rightmosts[int(ShenandoahFreeSetPartitionId::OldCollector)];\n+  assert (beg_off >= leftmost(ShenandoahFreeSetPartitionId::OldCollector),\n+          \"free regions before the leftmost: \" SSIZE_FORMAT \", bound \" SSIZE_FORMAT,\n+          beg_off, leftmost(ShenandoahFreeSetPartitionId::OldCollector));\n+  assert (end_off <= rightmost(ShenandoahFreeSetPartitionId::OldCollector),\n+          \"free regions past the rightmost: \" SSIZE_FORMAT \", bound \" SSIZE_FORMAT,\n+          end_off, rightmost(ShenandoahFreeSetPartitionId::OldCollector));\n+\n+  beg_off = empty_leftmosts[int(ShenandoahFreeSetPartitionId::OldCollector)];\n+  end_off = empty_rightmosts[int(ShenandoahFreeSetPartitionId::OldCollector)];\n+  assert (beg_off >= _leftmosts_empty[int(ShenandoahFreeSetPartitionId::OldCollector)],\n+          \"free empty regions before the leftmost: \" SSIZE_FORMAT \", bound \" SSIZE_FORMAT,\n+          beg_off, leftmost_empty(ShenandoahFreeSetPartitionId::OldCollector));\n+  assert (end_off <= _rightmosts_empty[int(ShenandoahFreeSetPartitionId::OldCollector)],\n+          \"free empty regions past the rightmost: \" SSIZE_FORMAT \", bound \" SSIZE_FORMAT,\n+          end_off, rightmost_empty(ShenandoahFreeSetPartitionId::OldCollector));\n@@ -581,1 +673,0 @@\n-  _right_to_left_bias(false),\n@@ -587,0 +678,52 @@\n+void ShenandoahFreeSet::add_promoted_in_place_region_to_old_collector(ShenandoahHeapRegion* region) {\n+  shenandoah_assert_heaplocked();\n+  size_t plab_min_size_in_bytes = ShenandoahGenerationalHeap::heap()->plab_min_size() * HeapWordSize;\n+  size_t idx = region->index();\n+  size_t capacity = alloc_capacity(region);\n+  assert(_partitions.membership(idx) == ShenandoahFreeSetPartitionId::NotFree,\n+         \"Regions promoted in place should have been excluded from Mutator partition\");\n+  if (capacity >= plab_min_size_in_bytes) {\n+    _partitions.make_free(idx, ShenandoahFreeSetPartitionId::OldCollector, capacity);\n+    _heap->old_generation()->augment_promoted_reserve(capacity);\n+  }\n+}\n+\n+HeapWord* ShenandoahFreeSet::allocate_from_partition_with_affiliation(ShenandoahFreeSetPartitionId which_partition,\n+                                                                      ShenandoahAffiliation affiliation,\n+                                                                      ShenandoahAllocRequest& req, bool& in_new_region) {\n+  shenandoah_assert_heaplocked();\n+  idx_t rightmost_collector = ((affiliation == ShenandoahAffiliation::FREE)?\n+                               _partitions.rightmost_empty(which_partition): _partitions.rightmost(which_partition));\n+  idx_t leftmost_collector = ((affiliation == ShenandoahAffiliation::FREE)?\n+                              _partitions.leftmost_empty(which_partition): _partitions.leftmost(which_partition));\n+  if (_partitions.alloc_from_left_bias(which_partition)) {\n+    for (idx_t idx = leftmost_collector; idx <= rightmost_collector; ) {\n+      assert(_partitions.in_free_set(which_partition, idx), \"Boundaries or find_prev_last_bit failed: \" SSIZE_FORMAT, idx);\n+      ShenandoahHeapRegion* r = _heap->get_region(idx);\n+      if (r->affiliation() == affiliation) {\n+        HeapWord* result = try_allocate_in(r, req, in_new_region);\n+        if (result != nullptr) {\n+          return result;\n+        }\n+      }\n+      idx = _partitions.find_index_of_next_available_region(which_partition, idx + 1);\n+    }\n+  } else {\n+    for (idx_t idx = rightmost_collector; idx >= leftmost_collector; ) {\n+      assert(_partitions.in_free_set(which_partition, idx),\n+             \"Boundaries or find_prev_last_bit failed: \" SSIZE_FORMAT, idx);\n+      ShenandoahHeapRegion* r = _heap->get_region(idx);\n+      if (r->affiliation() == affiliation) {\n+        HeapWord* result = try_allocate_in(r, req, in_new_region);\n+        if (result != nullptr) {\n+          return result;\n+        }\n+      }\n+      idx = _partitions.find_index_of_previous_available_region(which_partition, idx - 1);\n+    }\n+  }\n+  log_debug(gc, free)(\"Could not allocate collector region with affiliation: %s for request \" PTR_FORMAT,\n+                      shenandoah_affiliation_name(affiliation), p2i(&req));\n+  return nullptr;\n+}\n+\n@@ -592,1 +735,2 @@\n-  \/\/ Leftmost and rightmost bounds provide enough caching to quickly find a region from which to allocate.\n+  \/\/ Leftmost and rightmost bounds provide enough caching to walk bitmap efficiently. Normally,\n+  \/\/ we would find the region to allocate at right away.\n@@ -598,3 +742,20 @@\n-  \/\/ Free set maintains mutator and collector partitions.  Mutator can only allocate from the\n-  \/\/ Mutator partition.  Collector prefers to allocate from the Collector partition, but may steal\n-  \/\/ regions from the Mutator partition if the Collector partition has been depleted.\n+  \/\/ Free set maintains mutator and collector partitions.  Normally, each allocates only from its partition,\n+  \/\/ except in special cases when the collector steals regions from the mutator partition.\n+\n+  \/\/ Overwrite with non-zero (non-NULL) values only if necessary for allocation bookkeeping.\n+  bool allow_new_region = true;\n+  if (_heap->mode()->is_generational()) {\n+    switch (req.affiliation()) {\n+      case ShenandoahAffiliation::OLD_GENERATION:\n+        \/\/ Note: unsigned result from free_unaffiliated_regions() will never be less than zero, but it may equal zero.\n+        if (_heap->old_generation()->free_unaffiliated_regions() <= 0) {\n+          allow_new_region = false;\n+        }\n+        break;\n+\n+      case ShenandoahAffiliation::YOUNG_GENERATION:\n+        \/\/ Note: unsigned result from free_unaffiliated_regions() will never be less than zero, but it may equal zero.\n+        if (_heap->young_generation()->free_unaffiliated_regions() <= 0) {\n+          allow_new_region = false;\n+        }\n+        break;\n@@ -602,0 +763,8 @@\n+      case ShenandoahAffiliation::FREE:\n+        fatal(\"Should request affiliation\");\n+\n+      default:\n+        ShouldNotReachHere();\n+        break;\n+    }\n+  }\n@@ -626,1 +795,1 @@\n-        _right_to_left_bias = (non_empty_on_right > non_empty_on_left);\n+        _partitions.set_bias_from_left_to_right(ShenandoahFreeSetPartitionId::Mutator, (non_empty_on_right < non_empty_on_left));\n@@ -629,1 +798,1 @@\n-      if (_right_to_left_bias) {\n+      if (!_partitions.alloc_from_left_bias(ShenandoahFreeSetPartitionId::Mutator)) {\n@@ -674,0 +843,4 @@\n+    case ShenandoahAllocRequest::_alloc_plab: {\n+      \/\/ PLABs always reside in old-gen and are only allocated during\n+      \/\/ evacuation phase.\n+\n@@ -676,5 +849,11 @@\n-      idx_t leftmost_collector = _partitions.leftmost(ShenandoahFreeSetPartitionId::Collector);\n-      for (idx_t idx = _partitions.rightmost(ShenandoahFreeSetPartitionId::Collector); idx >= leftmost_collector; ) {\n-        assert(_partitions.in_free_set(ShenandoahFreeSetPartitionId::Collector, idx),\n-               \"Boundaries or find_prev_last_bit failed: \" SSIZE_FORMAT, idx);\n-        HeapWord* result = try_allocate_in(_heap->get_region(idx), req, in_new_region);\n+      HeapWord* result;\n+      result = allocate_from_partition_with_affiliation(req.is_old()? ShenandoahFreeSetPartitionId::OldCollector:\n+                                                        ShenandoahFreeSetPartitionId::Collector,\n+                                                        req.affiliation(), req, in_new_region);\n+      if (result != nullptr) {\n+        return result;\n+      } else if (allow_new_region) {\n+        \/\/ Try a free region that is dedicated to GC allocations.\n+        result = allocate_from_partition_with_affiliation(req.is_old()? ShenandoahFreeSetPartitionId::OldCollector:\n+                                                          ShenandoahFreeSetPartitionId::Collector,\n+                                                          ShenandoahAffiliation::FREE, req, in_new_region);\n@@ -684,1 +863,0 @@\n-        idx = _partitions.find_index_of_previous_available_region(ShenandoahFreeSetPartitionId::Collector, idx - 1);\n@@ -691,0 +869,4 @@\n+      if (!allow_new_region && req.is_old() && (_heap->young_generation()->free_unaffiliated_regions() > 0)) {\n+        \/\/ This allows us to flip a mutator region to old_collector\n+        allow_new_region = true;\n+      }\n@@ -692,12 +874,23 @@\n-      \/\/ Try to steal an empty region from the mutator view.\n-      idx_t leftmost_mutator_empty = _partitions.leftmost_empty(ShenandoahFreeSetPartitionId::Mutator);\n-      for (idx_t idx = _partitions.rightmost_empty(ShenandoahFreeSetPartitionId::Mutator); idx >= leftmost_mutator_empty; ) {\n-        assert(_partitions.in_free_set(ShenandoahFreeSetPartitionId::Mutator, idx),\n-               \"Boundaries or find_prev_last_bit failed: \" SSIZE_FORMAT, idx);\n-        ShenandoahHeapRegion* r = _heap->get_region(idx);\n-        if (can_allocate_from(r)) {\n-          flip_to_gc(r);\n-          HeapWord *result = try_allocate_in(r, req, in_new_region);\n-          if (result != nullptr) {\n-            log_debug(gc)(\"Flipped region \" SIZE_FORMAT \" to gc for request: \" PTR_FORMAT, idx, p2i(&req));\n-            return result;\n+      \/\/ We should expand old-gen if this can prevent an old-gen evacuation failure.  We don't care so much about\n+      \/\/ promotion failures since they can be mitigated in a subsequent GC pass.  Would be nice to know if this\n+      \/\/ allocation request is for evacuation or promotion.  Individual threads limit their use of PLAB memory for\n+      \/\/ promotions, so we already have an assurance that any additional memory set aside for old-gen will be used\n+      \/\/ only for old-gen evacuations.\n+      if (allow_new_region) {\n+        \/\/ Try to steal an empty region from the mutator view.\n+        idx_t rightmost_mutator = _partitions.rightmost_empty(ShenandoahFreeSetPartitionId::Mutator);\n+        idx_t leftmost_mutator =  _partitions.leftmost_empty(ShenandoahFreeSetPartitionId::Mutator);\n+        for (idx_t idx = rightmost_mutator; idx >= leftmost_mutator; ) {\n+          assert(_partitions.in_free_set(ShenandoahFreeSetPartitionId::Mutator, idx),\n+                 \"Boundaries or find_prev_last_bit failed: \" SSIZE_FORMAT, idx);\n+          ShenandoahHeapRegion* r = _heap->get_region(idx);\n+          if (can_allocate_from(r)) {\n+            if (req.is_old()) {\n+              flip_to_old_gc(r);\n+            } else {\n+              flip_to_gc(r);\n+            }\n+            \/\/ Region r is entirely empty.  If try_allocat_in fails on region r, something else is really wrong.\n+            \/\/ Don't bother to retry with other regions.\n+            log_debug(gc, free)(\"Flipped region \" SIZE_FORMAT \" to gc for request: \" PTR_FORMAT, idx, p2i(&req));\n+            return try_allocate_in(r, req, in_new_region);\n@@ -705,0 +898,1 @@\n+          idx = _partitions.find_index_of_previous_available_region(ShenandoahFreeSetPartitionId::Mutator, idx - 1);\n@@ -706,1 +900,0 @@\n-        idx = _partitions.find_index_of_previous_available_region(ShenandoahFreeSetPartitionId::Mutator, idx - 1);\n@@ -708,1 +901,0 @@\n-\n@@ -713,0 +905,1 @@\n+    }\n@@ -719,0 +912,50 @@\n+\/\/ This work method takes an argument corresponding to the number of bytes\n+\/\/ free in a region, and returns the largest amount in heapwords that can be allocated\n+\/\/ such that both of the following conditions are satisfied:\n+\/\/\n+\/\/ 1. it is a multiple of card size\n+\/\/ 2. any remaining shard may be filled with a filler object\n+\/\/\n+\/\/ The idea is that the allocation starts and ends at card boundaries. Because\n+\/\/ a region ('s end) is card-aligned, the remainder shard that must be filled is\n+\/\/ at the start of the free space.\n+\/\/\n+\/\/ This is merely a helper method to use for the purpose of such a calculation.\n+size_t ShenandoahFreeSet::get_usable_free_words(size_t free_bytes) const {\n+  \/\/ e.g. card_size is 512, card_shift is 9, min_fill_size() is 8\n+  \/\/      free is 514\n+  \/\/      usable_free is 512, which is decreased to 0\n+  size_t usable_free = (free_bytes \/ CardTable::card_size()) << CardTable::card_shift();\n+  assert(usable_free <= free_bytes, \"Sanity check\");\n+  if ((free_bytes != usable_free) && (free_bytes - usable_free < ShenandoahHeap::min_fill_size() * HeapWordSize)) {\n+    \/\/ After aligning to card multiples, the remainder would be smaller than\n+    \/\/ the minimum filler object, so we'll need to take away another card's\n+    \/\/ worth to construct a filler object.\n+    if (usable_free >= CardTable::card_size()) {\n+      usable_free -= CardTable::card_size();\n+    } else {\n+      assert(usable_free == 0, \"usable_free is a multiple of card_size and card_size > min_fill_size\");\n+    }\n+  }\n+\n+  return usable_free \/ HeapWordSize;\n+}\n+\n+\/\/ Given a size argument, which is a multiple of card size, a request struct\n+\/\/ for a PLAB, and an old region, return a pointer to the allocated space for\n+\/\/ a PLAB which is card-aligned and where any remaining shard in the region\n+\/\/ has been suitably filled by a filler object.\n+\/\/ It is assumed (and assertion-checked) that such an allocation is always possible.\n+HeapWord* ShenandoahFreeSet::allocate_aligned_plab(size_t size, ShenandoahAllocRequest& req, ShenandoahHeapRegion* r) {\n+  assert(_heap->mode()->is_generational(), \"PLABs are only for generational mode\");\n+  assert(r->is_old(), \"All PLABs reside in old-gen\");\n+  assert(!req.is_mutator_alloc(), \"PLABs should not be allocated by mutators.\");\n+  assert(is_aligned(size, CardTable::card_size_in_words()), \"Align by design\");\n+\n+  HeapWord* result = r->allocate_aligned(size, req, CardTable::card_size());\n+  assert(result != nullptr, \"Allocation cannot fail\");\n+  assert(r->top() <= r->end(), \"Allocation cannot span end of region\");\n+  assert(is_aligned(result, CardTable::card_size_in_words()), \"Align by design\");\n+  return result;\n+}\n+\n@@ -724,1 +967,0 @@\n-\n@@ -732,0 +974,28 @@\n+    assert(!r->is_affiliated(), \"New region \" SIZE_FORMAT \" should be unaffiliated\", r->index());\n+    r->set_affiliation(req.affiliation());\n+    if (r->is_old()) {\n+      \/\/ Any OLD region allocated during concurrent coalesce-and-fill does not need to be coalesced and filled because\n+      \/\/ all objects allocated within this region are above TAMS (and thus are implicitly marked).  In case this is an\n+      \/\/ OLD region and concurrent preparation for mixed evacuations visits this region before the start of the next\n+      \/\/ old-gen concurrent mark (i.e. this region is allocated following the start of old-gen concurrent mark but before\n+      \/\/ concurrent preparations for mixed evacuations are completed), we mark this region as not requiring any\n+      \/\/ coalesce-and-fill processing.\n+      r->end_preemptible_coalesce_and_fill();\n+      _heap->old_generation()->clear_cards_for(r);\n+    }\n+    _heap->generation_for(r->affiliation())->increment_affiliated_region_count();\n+\n+#ifdef ASSERT\n+    ShenandoahMarkingContext* const ctx = _heap->complete_marking_context();\n+    assert(ctx->top_at_mark_start(r) == r->bottom(), \"Newly established allocation region starts with TAMS equal to bottom\");\n+    assert(ctx->is_bitmap_clear_range(ctx->top_bitmap(r), r->end()), \"Bitmap above top_bitmap() must be clear\");\n+#endif\n+    log_debug(gc)(\"Using new region (\" SIZE_FORMAT \") for %s (\" PTR_FORMAT \").\",\n+                       r->index(), ShenandoahAllocRequest::alloc_type_to_string(req.type()), p2i(&req));\n+  } else {\n+    assert(r->is_affiliated(), \"Region \" SIZE_FORMAT \" that is not new should be affiliated\", r->index());\n+    if (r->affiliation() != req.affiliation()) {\n+      assert(_heap->mode()->is_generational(), \"Request for %s from %s region should only happen in generational mode.\",\n+             req.affiliation_name(), r->affiliation_name());\n+      return nullptr;\n+    }\n@@ -736,1 +1006,0 @@\n-    \/\/ This is a GCLAB or a TLAB allocation\n@@ -738,12 +1007,23 @@\n-    size_t free = align_down(r->free() >> LogHeapWordSize, MinObjAlignment);\n-    if (adjusted_size > free) {\n-      adjusted_size = free;\n-    }\n-    if (adjusted_size >= req.min_size()) {\n-      result = r->allocate(adjusted_size, req.type());\n-      log_debug(gc)(\"Allocated \" SIZE_FORMAT \" words (adjusted from \" SIZE_FORMAT \") for %s @\" PTR_FORMAT\n-                          \" from %s region \" SIZE_FORMAT \", free bytes remaining: \" SIZE_FORMAT,\n-                          adjusted_size, req.size(), ShenandoahAllocRequest::alloc_type_to_string(req.type()), p2i(result),\n-                          _partitions.partition_membership_name(r->index()), r->index(), r->free());\n-      assert (result != nullptr, \"Allocation must succeed: free \" SIZE_FORMAT \", actual \" SIZE_FORMAT, free, adjusted_size);\n-      req.set_actual_size(adjusted_size);\n+    size_t free = r->free();    \/\/ free represents bytes available within region r\n+    if (req.type() == ShenandoahAllocRequest::_alloc_plab) {\n+      \/\/ This is a PLAB allocation\n+      assert(_heap->mode()->is_generational(), \"PLABs are only for generational mode\");\n+      assert(_partitions.in_free_set(ShenandoahFreeSetPartitionId::OldCollector, r->index()),\n+             \"PLABS must be allocated in old_collector_free regions\");\n+\n+      \/\/ Need to assure that plabs are aligned on multiple of card region\n+      \/\/ Convert free from unaligned bytes to aligned number of words\n+      size_t usable_free = get_usable_free_words(free);\n+      if (adjusted_size > usable_free) {\n+        adjusted_size = usable_free;\n+      }\n+      adjusted_size = align_down(adjusted_size, CardTable::card_size_in_words());\n+      if (adjusted_size >= req.min_size()) {\n+        result = allocate_aligned_plab(adjusted_size, req, r);\n+        assert(result != nullptr, \"allocate must succeed\");\n+        req.set_actual_size(adjusted_size);\n+      } else {\n+        \/\/ Otherwise, leave result == nullptr because the adjusted size is smaller than min size.\n+        log_trace(gc, free)(\"Failed to shrink PLAB request (\" SIZE_FORMAT \") in region \" SIZE_FORMAT \" to \" SIZE_FORMAT\n+                            \" because min_size() is \" SIZE_FORMAT, req.size(), r->index(), adjusted_size, req.min_size());\n+      }\n@@ -751,2 +1031,14 @@\n-      log_trace(gc, free)(\"Failed to shrink TLAB or GCLAB request (\" SIZE_FORMAT \") in region \" SIZE_FORMAT \" to \" SIZE_FORMAT\n-                          \" because min_size() is \" SIZE_FORMAT, req.size(), r->index(), adjusted_size, req.min_size());\n+      \/\/ This is a GCLAB or a TLAB allocation\n+      \/\/ Convert free from unaligned bytes to aligned number of words\n+      free = align_down(free >> LogHeapWordSize, MinObjAlignment);\n+      if (adjusted_size > free) {\n+        adjusted_size = free;\n+      }\n+      if (adjusted_size >= req.min_size()) {\n+        result = r->allocate(adjusted_size, req);\n+        assert (result != nullptr, \"Allocation must succeed: free \" SIZE_FORMAT \", actual \" SIZE_FORMAT, free, adjusted_size);\n+        req.set_actual_size(adjusted_size);\n+      } else {\n+        log_trace(gc, free)(\"Failed to shrink TLAB or GCLAB request (\" SIZE_FORMAT \") in region \" SIZE_FORMAT \" to \" SIZE_FORMAT\n+                            \" because min_size() is \" SIZE_FORMAT, req.size(), r->index(), adjusted_size, req.min_size());\n+      }\n@@ -756,1 +1048,1 @@\n-    result = r->allocate(size, req.type());\n+    result = r->allocate(size, req);\n@@ -759,4 +1051,0 @@\n-      log_debug(gc)(\"Allocated \" SIZE_FORMAT \" words for %s @\" PTR_FORMAT\n-                          \" from %s region \" SIZE_FORMAT \", free bytes remaining: \" SIZE_FORMAT,\n-                          size, ShenandoahAllocRequest::alloc_type_to_string(req.type()), p2i(result),\n-                          _partitions.partition_membership_name(r->index()),  r->index(), r->free());\n@@ -770,0 +1058,1 @@\n+      assert(req.is_young(), \"Mutator allocations always come from young generation.\");\n@@ -775,1 +1064,2 @@\n-      \/\/ evacuation are not updated during evacuation.\n+      \/\/ evacuation are not updated during evacuation.  For both young and old regions r, it is essential that all\n+      \/\/ PLABs be made parsable at the end of evacuation.  This is enabled by retiring all plabs at end of evacuation.\n@@ -777,0 +1067,7 @@\n+      if (r->is_old()) {\n+        _partitions.increase_used(ShenandoahFreeSetPartitionId::OldCollector, req.actual_size() * HeapWordSize);\n+        assert(req.type() != ShenandoahAllocRequest::_alloc_gclab, \"old-gen allocations use PLAB or shared allocation\");\n+        \/\/ for plabs, we'll sort the difference between evac and promotion usage when we retire the plab\n+      } else {\n+        _partitions.increase_used(ShenandoahFreeSetPartitionId::Collector, req.actual_size() * HeapWordSize);\n+      }\n@@ -791,3 +1088,16 @@\n-    _partitions.retire_from_partition(req.is_mutator_alloc()?\n-                                      ShenandoahFreeSetPartitionId::Mutator: ShenandoahFreeSetPartitionId::Collector,\n-                                      idx, r->used());\n+    ShenandoahFreeSetPartitionId orig_partition;\n+    if (req.is_mutator_alloc()) {\n+      orig_partition = ShenandoahFreeSetPartitionId::Mutator;\n+    } else if (req.type() == ShenandoahAllocRequest::_alloc_gclab) {\n+      orig_partition = ShenandoahFreeSetPartitionId::Collector;\n+    } else if (req.type() == ShenandoahAllocRequest::_alloc_plab) {\n+      orig_partition = ShenandoahFreeSetPartitionId::OldCollector;\n+    } else {\n+      assert(req.type() == ShenandoahAllocRequest::_alloc_shared_gc, \"Unexpected allocation type\");\n+      if (req.is_old()) {\n+        orig_partition = ShenandoahFreeSetPartitionId::OldCollector;\n+      } else {\n+        orig_partition = ShenandoahFreeSetPartitionId::Collector;\n+      }\n+    }\n+    _partitions.retire_from_partition(orig_partition, idx, r->used());\n@@ -806,0 +1116,3 @@\n+  assert(req.is_young(), \"Humongous regions always allocated in YOUNG\");\n+  ShenandoahGeneration* generation = _heap->generation_for(req.affiliation());\n+\n@@ -818,1 +1131,1 @@\n-                                                                            start_range, num);\n+                                                                          start_range, num);\n@@ -885,0 +1198,2 @@\n+    r->set_affiliation(req.affiliation());\n+    r->set_update_watermark(r->bottom());\n@@ -887,1 +1202,1 @@\n-\n+  generation->increase_affiliated_region_count(num);\n@@ -900,0 +1215,3 @@\n+  if (remainder != 0) {\n+    req.set_waste(ShenandoahHeapRegion::region_size_words() - remainder);\n+  }\n@@ -905,1 +1223,0 @@\n-    _heap->decrease_used(r->used());\n@@ -935,0 +1252,21 @@\n+void ShenandoahFreeSet::flip_to_old_gc(ShenandoahHeapRegion* r) {\n+  size_t idx = r->index();\n+\n+  assert(_partitions.partition_id_matches(idx, ShenandoahFreeSetPartitionId::Mutator), \"Should be in mutator view\");\n+  assert(can_allocate_from(r), \"Should not be allocated\");\n+\n+  ShenandoahGenerationalHeap* gen_heap = ShenandoahGenerationalHeap::heap();\n+  size_t region_capacity = alloc_capacity(r);\n+  _partitions.move_from_partition_to_partition(idx, ShenandoahFreeSetPartitionId::Mutator,\n+                                               ShenandoahFreeSetPartitionId::OldCollector, region_capacity);\n+  _partitions.assert_bounds();\n+  _heap->old_generation()->augment_evacuation_reserve(region_capacity);\n+  bool transferred = gen_heap->generation_sizer()->transfer_to_old(1);\n+  if (!transferred) {\n+    log_warning(gc, free)(\"Forcing transfer of \" SIZE_FORMAT \" to old reserve.\", idx);\n+    gen_heap->generation_sizer()->force_transfer_to_old(1);\n+  }\n+  \/\/ We do not ensure that the region is no longer trash, relying on try_allocate_in(), which always comes next,\n+  \/\/ to recycle trash before attempting to allocate anything in the region.\n+}\n+\n@@ -957,1 +1295,0 @@\n-}\n@@ -959,1 +1296,5 @@\n-void ShenandoahFreeSet::find_regions_with_alloc_capacity(size_t &cset_regions) {\n+  _alloc_bias_weight = 0;\n+  _partitions.set_bias_from_left_to_right(ShenandoahFreeSetPartitionId::Mutator, true);\n+  _partitions.set_bias_from_left_to_right(ShenandoahFreeSetPartitionId::Collector, false);\n+  _partitions.set_bias_from_left_to_right(ShenandoahFreeSetPartitionId::OldCollector, false);\n+}\n@@ -961,1 +1302,3 @@\n-  cset_regions = 0;\n+void ShenandoahFreeSet::find_regions_with_alloc_capacity(size_t &young_cset_regions, size_t &old_cset_regions,\n+                                                         size_t &first_old_region, size_t &last_old_region,\n+                                                         size_t &old_region_count) {\n@@ -963,0 +1306,7 @@\n+\n+  first_old_region = _heap->num_regions();\n+  last_old_region = 0;\n+  old_region_count = 0;\n+  old_cset_regions = 0;\n+  young_cset_regions = 0;\n+\n@@ -970,1 +1320,0 @@\n-\n@@ -974,1 +1323,9 @@\n-  for (size_t idx = 0; idx < _heap->num_regions(); idx++) {\n+  size_t old_collector_leftmost = max_regions;\n+  size_t old_collector_rightmost = 0;\n+  size_t old_collector_leftmost_empty = max_regions;\n+  size_t old_collector_rightmost_empty = 0;\n+  size_t old_collector_regions = 0;\n+  size_t old_collector_used = 0;\n+\n+  size_t num_regions = _heap->num_regions();\n+  for (size_t idx = 0; idx < num_regions; idx++) {\n@@ -979,1 +1336,13 @@\n-      cset_regions++;\n+      if (region->is_old()) {\n+        old_cset_regions++;\n+      } else {\n+        assert(region->is_young(), \"Trashed region should be old or young\");\n+        young_cset_regions++;\n+      }\n+    } else if (region->is_old()) {\n+      \/\/ count both humongous and regular regions, but don't count trash (cset) regions.\n+      old_region_count++;\n+      if (first_old_region > idx) {\n+        first_old_region = idx;\n+      }\n+      last_old_region = idx;\n@@ -982,0 +1351,1 @@\n+      assert(!region->is_cset(), \"Shouldn't be adding cset regions to the free set\");\n@@ -986,11 +1356,24 @@\n-        _partitions.raw_assign_membership(idx, ShenandoahFreeSetPartitionId::Mutator);\n-\n-        if (idx < mutator_leftmost) {\n-          mutator_leftmost = idx;\n-        }\n-        if (idx > mutator_rightmost) {\n-          mutator_rightmost = idx;\n-        }\n-        if (ac == region_size_bytes) {\n-          if (idx < mutator_leftmost_empty) {\n-            mutator_leftmost_empty = idx;\n+        if (region->is_trash() || !region->is_old()) {\n+          \/\/ Both young and old collected regions (trashed) are placed into the Mutator set\n+          _partitions.raw_assign_membership(idx, ShenandoahFreeSetPartitionId::Mutator);\n+          if (idx < mutator_leftmost) {\n+            mutator_leftmost = idx;\n+          }\n+          if (idx > mutator_rightmost) {\n+            mutator_rightmost = idx;\n+          }\n+          if (ac == region_size_bytes) {\n+            if (idx < mutator_leftmost_empty) {\n+              mutator_leftmost_empty = idx;\n+            }\n+            if (idx > mutator_rightmost_empty) {\n+              mutator_rightmost_empty = idx;\n+            }\n+          }\n+          mutator_regions++;\n+          mutator_used += (region_size_bytes - ac);\n+        } else {\n+          \/\/ !region->is_trash() && region is_old()\n+          _partitions.raw_assign_membership(idx, ShenandoahFreeSetPartitionId::OldCollector);\n+          if (idx < old_collector_leftmost) {\n+            old_collector_leftmost = idx;\n@@ -998,2 +1381,2 @@\n-          if (idx > mutator_rightmost_empty) {\n-            mutator_rightmost_empty = idx;\n+          if (idx > old_collector_rightmost) {\n+            old_collector_rightmost = idx;\n@@ -1001,0 +1384,10 @@\n+          if (ac == region_size_bytes) {\n+            if (idx < old_collector_leftmost_empty) {\n+              old_collector_leftmost_empty = idx;\n+            }\n+            if (idx > old_collector_rightmost_empty) {\n+              old_collector_rightmost_empty = idx;\n+            }\n+          }\n+          old_collector_regions++;\n+          old_collector_used += (region_size_bytes - ac);\n@@ -1002,7 +1395,0 @@\n-        mutator_regions++;\n-        mutator_used += (region_size_bytes - ac);\n-\n-        log_debug(gc)(\n-          \"  Adding Region \" SIZE_FORMAT \" (Free: \" SIZE_FORMAT \"%s, Used: \" SIZE_FORMAT \"%s) to mutator partition\",\n-          idx, byte_size_in_proper_unit(region->free()), proper_unit_for_byte_size(region->free()),\n-          byte_size_in_proper_unit(region->used()), proper_unit_for_byte_size(region->used()));\n@@ -1012,0 +1398,21 @@\n+<<<<<<< HEAD\n+=======\n+  log_debug(gc)(\"  At end of prep_to_rebuild, mutator_leftmost: \" SIZE_FORMAT\n+                \", mutator_rightmost: \" SIZE_FORMAT\n+                \", mutator_leftmost_empty: \" SIZE_FORMAT\n+                \", mutator_rightmost_empty: \" SIZE_FORMAT\n+                \", mutator_regions: \" SIZE_FORMAT\n+                \", mutator_used: \" SIZE_FORMAT,\n+                mutator_leftmost, mutator_rightmost, mutator_leftmost_empty, mutator_rightmost_empty,\n+                mutator_regions, mutator_used);\n+\n+  log_debug(gc)(\"  old_collector_leftmost: \" SIZE_FORMAT\n+                \", old_collector_rightmost: \" SIZE_FORMAT\n+                \", old_collector_leftmost_empty: \" SIZE_FORMAT\n+                \", old_collector_rightmost_empty: \" SIZE_FORMAT\n+                \", old_collector_regions: \" SIZE_FORMAT\n+                \", old_collector_used: \" SIZE_FORMAT,\n+                old_collector_leftmost, old_collector_rightmost, old_collector_leftmost_empty, old_collector_rightmost_empty,\n+                old_collector_regions, old_collector_used);\n+\n+>>>>>>> d1bc34fb4cbbaea51c470a6bc088e04427ea82d3\n@@ -1016,0 +1423,10 @@\n+  rightmost_idx = (old_collector_leftmost == max_regions)? -1: (idx_t) old_collector_rightmost;\n+  rightmost_empty_idx = (old_collector_leftmost_empty == max_regions)? -1: (idx_t) old_collector_rightmost_empty;\n+  _partitions.establish_old_collector_intervals(old_collector_leftmost, rightmost_idx, old_collector_leftmost_empty,\n+                                                rightmost_empty_idx, old_collector_regions, old_collector_used);\n+  log_debug(gc)(\"  After find_regions_with_alloc_capacity(), Mutator range [\" SSIZE_FORMAT \", \" SSIZE_FORMAT \"],\"\n+                \"  Old Collector range [\" SSIZE_FORMAT \", \" SSIZE_FORMAT \"]\",\n+                _partitions.leftmost(ShenandoahFreeSetPartitionId::Mutator),\n+                _partitions.rightmost(ShenandoahFreeSetPartitionId::Mutator),\n+                _partitions.leftmost(ShenandoahFreeSetPartitionId::OldCollector),\n+                _partitions.rightmost(ShenandoahFreeSetPartitionId::OldCollector));\n@@ -1018,1 +1435,5 @@\n-void ShenandoahFreeSet::move_regions_from_collector_to_mutator(size_t max_xfer_regions) {\n+\/\/ Returns number of regions transferred, adds transferred bytes to var argument bytes_transferred\n+size_t ShenandoahFreeSet::transfer_empty_regions_from_collector_set_to_mutator_set(ShenandoahFreeSetPartitionId which_collector,\n+                                                                                   size_t max_xfer_regions,\n+                                                                                   size_t& bytes_transferred) {\n+  shenandoah_assert_heaplocked();\n@@ -1020,2 +1441,38 @@\n-  size_t collector_empty_xfer = 0;\n-  size_t collector_not_empty_xfer = 0;\n+  size_t transferred_regions = 0;\n+  idx_t rightmost = _partitions.rightmost_empty(which_collector);\n+  for (idx_t idx = _partitions.leftmost_empty(which_collector); (transferred_regions < max_xfer_regions) && (idx <= rightmost); ) {\n+    assert(_partitions.in_free_set(which_collector, idx), \"Boundaries or find_first_set_bit failed: \" SSIZE_FORMAT, idx);\n+    \/\/ Note: can_allocate_from() denotes that region is entirely empty\n+    if (can_allocate_from(idx)) {\n+      _partitions.move_from_partition_to_partition(idx, which_collector, ShenandoahFreeSetPartitionId::Mutator, region_size_bytes);\n+      transferred_regions++;\n+      bytes_transferred += region_size_bytes;\n+    }\n+    idx = _partitions.find_index_of_next_available_region(which_collector, idx + 1);\n+  }\n+  return transferred_regions;\n+}\n+\n+\/\/ Returns number of regions transferred, adds transferred bytes to var argument bytes_transferred\n+size_t ShenandoahFreeSet::transfer_non_empty_regions_from_collector_set_to_mutator_set(ShenandoahFreeSetPartitionId collector_id,\n+                                                                                       size_t max_xfer_regions,\n+                                                                                       size_t& bytes_transferred) {\n+  shenandoah_assert_heaplocked();\n+  size_t transferred_regions = 0;\n+  idx_t rightmost = _partitions.rightmost(collector_id);\n+  for (idx_t idx = _partitions.leftmost(collector_id); (transferred_regions < max_xfer_regions) && (idx <= rightmost); ) {\n+    assert(_partitions.in_free_set(collector_id, idx), \"Boundaries or find_first_set_bit failed: \" SSIZE_FORMAT, idx);\n+    size_t ac = alloc_capacity(idx);\n+    if (ac > 0) {\n+      _partitions.move_from_partition_to_partition(idx, collector_id, ShenandoahFreeSetPartitionId::Mutator, ac);\n+      transferred_regions++;\n+      bytes_transferred += ac;\n+    }\n+    idx = _partitions.find_index_of_next_available_region(ShenandoahFreeSetPartitionId::Collector, idx + 1);\n+  }\n+  return transferred_regions;\n+}\n+\n+void ShenandoahFreeSet::move_regions_from_collector_to_mutator(size_t max_xfer_regions) {\n+  size_t collector_xfer = 0;\n+  size_t old_collector_xfer = 0;\n@@ -1028,13 +1485,16 @@\n-    idx_t rightmost = _partitions.rightmost_empty(ShenandoahFreeSetPartitionId::Collector);\n-    for (idx_t idx = _partitions.leftmost_empty(ShenandoahFreeSetPartitionId::Collector);\n-         (max_xfer_regions > 0) && (idx <= rightmost); ) {\n-      assert(_partitions.in_free_set(ShenandoahFreeSetPartitionId::Collector, idx),\n-             \"Boundaries or find_first_set_bit failed: \" SSIZE_FORMAT, idx);\n-      \/\/ Note: can_allocate_from() denotes that region is entirely empty\n-      if (can_allocate_from(idx)) {\n-        _partitions.move_from_partition_to_partition(idx, ShenandoahFreeSetPartitionId::Collector,\n-                                                     ShenandoahFreeSetPartitionId::Mutator, region_size_bytes);\n-        max_xfer_regions--;\n-        collector_empty_xfer += region_size_bytes;\n-      }\n-      idx = _partitions.find_index_of_next_available_region(ShenandoahFreeSetPartitionId::Collector, idx + 1);\n+    max_xfer_regions -=\n+      transfer_empty_regions_from_collector_set_to_mutator_set(ShenandoahFreeSetPartitionId::Collector, max_xfer_regions,\n+                                                               collector_xfer);\n+  }\n+\n+  \/\/ Process empty regions within the OldCollector free partition\n+  if ((max_xfer_regions > 0) &&\n+      (_partitions.leftmost_empty(ShenandoahFreeSetPartitionId::OldCollector)\n+       <= _partitions.rightmost_empty(ShenandoahFreeSetPartitionId::OldCollector))) {\n+    ShenandoahHeapLocker locker(_heap->lock());\n+    size_t old_collector_regions =\n+      transfer_empty_regions_from_collector_set_to_mutator_set(ShenandoahFreeSetPartitionId::OldCollector, max_xfer_regions,\n+                                                               old_collector_xfer);\n+    max_xfer_regions -= old_collector_regions;\n+    if (old_collector_regions > 0) {\n+      ShenandoahGenerationalHeap::cast(_heap)->generation_sizer()->transfer_to_young(old_collector_regions);\n@@ -1048,14 +1508,3 @@\n-    idx_t rightmost = _partitions.rightmost(ShenandoahFreeSetPartitionId::Collector);\n-    for (idx_t idx = _partitions.leftmost(ShenandoahFreeSetPartitionId::Collector);\n-         (max_xfer_regions > 0) && (idx <= rightmost); ) {\n-      assert(_partitions.in_free_set(ShenandoahFreeSetPartitionId::Collector, idx),\n-             \"Boundaries or find_first_set_bit failed: \" SSIZE_FORMAT, idx);\n-      size_t ac = alloc_capacity(idx);\n-      if (ac > 0) {\n-        _partitions.move_from_partition_to_partition(idx, ShenandoahFreeSetPartitionId::Collector,\n-                                                     ShenandoahFreeSetPartitionId::Mutator, ac);\n-        max_xfer_regions--;\n-        collector_not_empty_xfer += ac;\n-      }\n-      idx = _partitions.find_index_of_next_available_region(ShenandoahFreeSetPartitionId::Collector, idx + 1);\n-    }\n+    max_xfer_regions -=\n+      transfer_non_empty_regions_from_collector_set_to_mutator_set(ShenandoahFreeSetPartitionId::Collector, max_xfer_regions,\n+                                                                   collector_xfer);\n@@ -1064,3 +1513,6 @@\n-  size_t collector_xfer = collector_empty_xfer + collector_not_empty_xfer;\n-  log_info(gc, ergo)(\"At start of update refs, moving \" SIZE_FORMAT \"%s to Mutator free partition from Collector Reserve\",\n-                     byte_size_in_proper_unit(collector_xfer), proper_unit_for_byte_size(collector_xfer));\n+  size_t total_xfer = collector_xfer + old_collector_xfer;\n+  log_info(gc, ergo)(\"At start of update refs, moving \" SIZE_FORMAT \"%s to Mutator free set from Collector Reserve (\"\n+                     SIZE_FORMAT \"%s) and from Old Collector Reserve (\" SIZE_FORMAT \"%s)\",\n+                     byte_size_in_proper_unit(total_xfer), proper_unit_for_byte_size(total_xfer),\n+                     byte_size_in_proper_unit(collector_xfer), proper_unit_for_byte_size(collector_xfer),\n+                     byte_size_in_proper_unit(old_collector_xfer), proper_unit_for_byte_size(old_collector_xfer));\n@@ -1069,1 +1521,4 @@\n-void ShenandoahFreeSet::prepare_to_rebuild(size_t &cset_regions) {\n+\n+\/\/ Overwrite arguments to represent the amount of memory in each generation that is about to be recycled\n+void ShenandoahFreeSet::prepare_to_rebuild(size_t &young_cset_regions, size_t &old_cset_regions,\n+                                           size_t &first_old_region, size_t &last_old_region, size_t &old_region_count) {\n@@ -1071,0 +1526,3 @@\n+  \/\/ This resets all state information, removing all regions from all sets.\n+  clear();\n+  log_debug(gc, free)(\"Rebuilding FreeSet\");\n@@ -1072,1 +1530,4 @@\n-  log_debug(gc)(\"Rebuilding FreeSet\");\n+  \/\/ This places regions that have alloc_capacity into the old_collector set if they identify as is_old() or the\n+  \/\/ mutator set otherwise.  All trashed (cset) regions are affiliated young and placed in mutator set.\n+  find_regions_with_alloc_capacity(young_cset_regions, old_cset_regions, first_old_region, last_old_region, old_region_count);\n+}\n@@ -1074,2 +1535,26 @@\n-  \/\/ This places regions that have alloc_capacity into the mutator partition.\n-  find_regions_with_alloc_capacity(cset_regions);\n+void ShenandoahFreeSet::establish_generation_sizes(size_t young_region_count, size_t old_region_count) {\n+  assert(young_region_count + old_region_count == ShenandoahHeap::heap()->num_regions(), \"Sanity\");\n+  if (ShenandoahHeap::heap()->mode()->is_generational()) {\n+    ShenandoahGenerationalHeap* heap = ShenandoahGenerationalHeap::heap();\n+    ShenandoahOldGeneration* old_gen = heap->old_generation();\n+    ShenandoahYoungGeneration* young_gen = heap->young_generation();\n+    size_t region_size_bytes = ShenandoahHeapRegion::region_size_bytes();\n+\n+    size_t original_old_capacity = old_gen->max_capacity();\n+    size_t new_old_capacity = old_region_count * region_size_bytes;\n+    size_t new_young_capacity = young_region_count * region_size_bytes;\n+    old_gen->set_capacity(new_old_capacity);\n+    young_gen->set_capacity(new_young_capacity);\n+\n+    if (new_old_capacity > original_old_capacity) {\n+      size_t region_count = (new_old_capacity - original_old_capacity) \/ region_size_bytes;\n+      log_info(gc)(\"Transfer \" SIZE_FORMAT \" region(s) from %s to %s, yielding increased size: \" PROPERFMT,\n+                   region_count, young_gen->name(), old_gen->name(), PROPERFMTARGS(new_old_capacity));\n+    } else if (new_old_capacity < original_old_capacity) {\n+      size_t region_count = (original_old_capacity - new_old_capacity) \/ region_size_bytes;\n+      log_info(gc)(\"Transfer \" SIZE_FORMAT \" region(s) from %s to %s, yielding increased size: \" PROPERFMT,\n+                   region_count, old_gen->name(), young_gen->name(), PROPERFMTARGS(new_young_capacity));\n+    }\n+    \/\/ This balances generations, so clear any pending request to balance.\n+    old_gen->set_region_balance(0);\n+  }\n@@ -1078,1 +1563,2 @@\n-void ShenandoahFreeSet::finish_rebuild(size_t cset_regions) {\n+void ShenandoahFreeSet::finish_rebuild(size_t young_cset_regions, size_t old_cset_regions, size_t old_region_count,\n+                                       bool have_evacuation_reserves) {\n@@ -1080,0 +1566,1 @@\n+  size_t young_reserve(0), old_reserve(0);\n@@ -1081,9 +1568,3 @@\n-  \/\/ Our desire is to reserve this much memory for future evacuation.  We may end up reserving less, if\n-  \/\/ memory is in short supply.\n-\n-  size_t reserve = _heap->max_capacity() * ShenandoahEvacReserve \/ 100;\n-  size_t available_in_collector_partition = (_partitions.capacity_of(ShenandoahFreeSetPartitionId::Collector)\n-                                             - _partitions.used_by(ShenandoahFreeSetPartitionId::Collector));\n-  size_t additional_reserve;\n-  if (available_in_collector_partition < reserve) {\n-    additional_reserve = reserve - available_in_collector_partition;\n+  if (_heap->mode()->is_generational()) {\n+    compute_young_and_old_reserves(young_cset_regions, old_cset_regions, have_evacuation_reserves,\n+                                   young_reserve, old_reserve);\n@@ -1091,1 +1572,2 @@\n-    additional_reserve = 0;\n+    young_reserve = (_heap->max_capacity() \/ 100) * ShenandoahEvacReserve;\n+    old_reserve = 0;\n@@ -1094,1 +1576,6 @@\n-  reserve_regions(reserve);\n+  \/\/ Move some of the mutator regions in the Collector and OldCollector partitions in order to satisfy\n+  \/\/ young_reserve and old_reserve.\n+  reserve_regions(young_reserve, old_reserve, old_region_count);\n+  size_t young_region_count = _heap->num_regions() - old_region_count;\n+  establish_generation_sizes(young_region_count, old_region_count);\n+  establish_old_collector_alloc_bias();\n@@ -1099,4 +1586,71 @@\n-void ShenandoahFreeSet::rebuild() {\n-  size_t cset_regions;\n-  prepare_to_rebuild(cset_regions);\n-  finish_rebuild(cset_regions);\n+void ShenandoahFreeSet::compute_young_and_old_reserves(size_t young_cset_regions, size_t old_cset_regions,\n+                                                       bool have_evacuation_reserves,\n+                                                       size_t& young_reserve_result, size_t& old_reserve_result) const {\n+  shenandoah_assert_generational();\n+  const size_t region_size_bytes = ShenandoahHeapRegion::region_size_bytes();\n+\n+  ShenandoahOldGeneration* const old_generation = _heap->old_generation();\n+  size_t old_available = old_generation->available();\n+  size_t old_unaffiliated_regions = old_generation->free_unaffiliated_regions();\n+  ShenandoahYoungGeneration* const young_generation = _heap->young_generation();\n+  size_t young_capacity = young_generation->max_capacity();\n+  size_t young_unaffiliated_regions = young_generation->free_unaffiliated_regions();\n+\n+  \/\/ Add in the regions we anticipate to be freed by evacuation of the collection set\n+  old_unaffiliated_regions += old_cset_regions;\n+  young_unaffiliated_regions += young_cset_regions;\n+\n+  \/\/ Consult old-region balance to make adjustments to current generation capacities and availability.\n+  \/\/ The generation region transfers take place after we rebuild.\n+  const ssize_t old_region_balance = old_generation->get_region_balance();\n+  if (old_region_balance != 0) {\n+#ifdef ASSERT\n+    if (old_region_balance > 0) {\n+      assert(old_region_balance <= checked_cast<ssize_t>(old_unaffiliated_regions), \"Cannot transfer regions that are affiliated\");\n+    } else {\n+      assert(0 - old_region_balance <= checked_cast<ssize_t>(young_unaffiliated_regions), \"Cannot transfer regions that are affiliated\");\n+    }\n+#endif\n+\n+    ssize_t xfer_bytes = old_region_balance * checked_cast<ssize_t>(region_size_bytes);\n+    old_available -= xfer_bytes;\n+    old_unaffiliated_regions -= old_region_balance;\n+    young_capacity += xfer_bytes;\n+    young_unaffiliated_regions += old_region_balance;\n+  }\n+\n+  \/\/ All allocations taken from the old collector set are performed by GC, generally using PLABs for both\n+  \/\/ promotions and evacuations.  The partition between which old memory is reserved for evacuation and\n+  \/\/ which is reserved for promotion is enforced using thread-local variables that prescribe intentions for\n+  \/\/ each PLAB's available memory.\n+  if (have_evacuation_reserves) {\n+    \/\/ We are rebuilding at the end of final mark, having already established evacuation budgets for this GC pass.\n+    const size_t promoted_reserve = old_generation->get_promoted_reserve();\n+    const size_t old_evac_reserve = old_generation->get_evacuation_reserve();\n+    young_reserve_result = young_generation->get_evacuation_reserve();\n+    old_reserve_result = promoted_reserve + old_evac_reserve;\n+    assert(old_reserve_result <= old_available,\n+           \"Cannot reserve (\" SIZE_FORMAT \" + \" SIZE_FORMAT\") more OLD than is available: \" SIZE_FORMAT,\n+           promoted_reserve, old_evac_reserve, old_available);\n+  } else {\n+    \/\/ We are rebuilding at end of GC, so we set aside budgets specified on command line (or defaults)\n+    young_reserve_result = (young_capacity * ShenandoahEvacReserve) \/ 100;\n+    \/\/ The auto-sizer has already made old-gen large enough to hold all anticipated evacuations and promotions.\n+    \/\/ Affiliated old-gen regions are already in the OldCollector free set.  Add in the relevant number of\n+    \/\/ unaffiliated regions.\n+    old_reserve_result = old_available;\n+  }\n+\n+  \/\/ Old available regions that have less than PLAB::min_size() of available memory are not placed into the OldCollector\n+  \/\/ free set.  Because of this, old_available may not have enough memory to represent the intended reserve.  Adjust\n+  \/\/ the reserve downward to account for this possibility. This loss is part of the reason why the original budget\n+  \/\/ was adjusted with ShenandoahOldEvacWaste and ShenandoahOldPromoWaste multipliers.\n+  if (old_reserve_result >\n+      _partitions.capacity_of(ShenandoahFreeSetPartitionId::OldCollector) + old_unaffiliated_regions * region_size_bytes) {\n+    old_reserve_result =\n+      _partitions.capacity_of(ShenandoahFreeSetPartitionId::OldCollector) + old_unaffiliated_regions * region_size_bytes;\n+  }\n+\n+  if (young_reserve_result > young_unaffiliated_regions * region_size_bytes) {\n+    young_reserve_result = young_unaffiliated_regions * region_size_bytes;\n+  }\n@@ -1105,1 +1659,6 @@\n-void ShenandoahFreeSet::reserve_regions(size_t to_reserve) {\n+\/\/ Having placed all regions that have allocation capacity into the mutator set if they identify as is_young()\n+\/\/ or into the old collector set if they identify as is_old(), move some of these regions from the mutator set\n+\/\/ into the collector set or old collector set in order to assure that the memory available for allocations within\n+\/\/ the collector set is at least to_reserve and the memory available for allocations within the old collector set\n+\/\/ is at least to_reserve_old.\n+void ShenandoahFreeSet::reserve_regions(size_t to_reserve, size_t to_reserve_old, size_t &old_region_count) {\n@@ -1109,1 +1668,0 @@\n-\n@@ -1115,1 +1673,2 @@\n-    assert (ac > 0, \"Membership in free partition implies has capacity\");\n+    assert (ac > 0, \"Membership in free set implies has capacity\");\n+    assert (!r->is_old() || r->is_trash(), \"Except for trash, mutator_is_free regions should not be affiliated OLD\");\n@@ -1117,0 +1676,1 @@\n+    bool move_to_old_collector = _partitions.available_in(ShenandoahFreeSetPartitionId::OldCollector) < to_reserve_old;\n@@ -1118,2 +1678,3 @@\n-    if (!move_to_collector) {\n-      \/\/ We've satisfied to_reserve\n+\n+    if (!move_to_collector && !move_to_old_collector) {\n+      \/\/ We've satisfied both to_reserve and to_reserved_old\n@@ -1123,0 +1684,20 @@\n+    if (move_to_old_collector) {\n+      \/\/ We give priority to OldCollector partition because we desire to pack OldCollector regions into higher\n+      \/\/ addresses than Collector regions.  Presumably, OldCollector regions are more \"stable\" and less likely to\n+      \/\/ be collected in the near future.\n+      if (r->is_trash() || !r->is_affiliated()) {\n+        \/\/ OLD regions that have available memory are already in the old_collector free set.\n+        _partitions.move_from_partition_to_partition(idx, ShenandoahFreeSetPartitionId::Mutator,\n+                                                     ShenandoahFreeSetPartitionId::OldCollector, ac);\n+        log_debug(gc)(\"  Shifting region \" SIZE_FORMAT \" from mutator_free to old_collector_free\", idx);\n+        log_debug(gc)(\"  Shifted Mutator range [\" SSIZE_FORMAT \", \" SSIZE_FORMAT \"],\"\n+                      \"  Old Collector range [\" SSIZE_FORMAT \", \" SSIZE_FORMAT \"]\",\n+                      _partitions.leftmost(ShenandoahFreeSetPartitionId::Mutator),\n+                      _partitions.rightmost(ShenandoahFreeSetPartitionId::Mutator),\n+                      _partitions.leftmost(ShenandoahFreeSetPartitionId::OldCollector),\n+                      _partitions.rightmost(ShenandoahFreeSetPartitionId::OldCollector));\n+        old_region_count++;\n+        continue;\n+      }\n+    }\n+\n@@ -1135,0 +1716,6 @@\n+      log_debug(gc)(\"  Shifted Mutator range [\" SSIZE_FORMAT \", \" SSIZE_FORMAT \"],\"\n+                    \"  Collector range [\" SSIZE_FORMAT \", \" SSIZE_FORMAT \"]\",\n+                    _partitions.leftmost(ShenandoahFreeSetPartitionId::Mutator),\n+                    _partitions.rightmost(ShenandoahFreeSetPartitionId::Mutator),\n+                    _partitions.leftmost(ShenandoahFreeSetPartitionId::Collector),\n+                    _partitions.rightmost(ShenandoahFreeSetPartitionId::Collector));\n@@ -1139,0 +1726,8 @@\n+<<<<<<< HEAD\n+=======\n+    size_t old_reserve = _partitions.available_in(ShenandoahFreeSetPartitionId::OldCollector);\n+    if (old_reserve < to_reserve_old) {\n+      log_info(gc, free)(\"Wanted \" PROPERFMT \" for old reserve, but only reserved: \" PROPERFMT,\n+                         PROPERFMTARGS(to_reserve_old), PROPERFMTARGS(old_reserve));\n+    }\n+>>>>>>> d1bc34fb4cbbaea51c470a6bc088e04427ea82d3\n@@ -1147,0 +1742,31 @@\n+void ShenandoahFreeSet::establish_old_collector_alloc_bias() {\n+  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  shenandoah_assert_heaplocked();\n+\n+  idx_t left_idx = _partitions.leftmost(ShenandoahFreeSetPartitionId::OldCollector);\n+  idx_t right_idx = _partitions.rightmost(ShenandoahFreeSetPartitionId::OldCollector);\n+  idx_t middle = (left_idx + right_idx) \/ 2;\n+  size_t available_in_first_half = 0;\n+  size_t available_in_second_half = 0;\n+\n+  for (idx_t index = left_idx; index < middle; index++) {\n+    if (_partitions.in_free_set(ShenandoahFreeSetPartitionId::OldCollector, index)) {\n+      ShenandoahHeapRegion* r = heap->get_region((size_t) index);\n+      available_in_first_half += r->free();\n+    }\n+  }\n+  for (idx_t index = middle; index <= right_idx; index++) {\n+    if (_partitions.in_free_set(ShenandoahFreeSetPartitionId::OldCollector, index)) {\n+      ShenandoahHeapRegion* r = heap->get_region(index);\n+      available_in_second_half += r->free();\n+    }\n+  }\n+\n+  \/\/ We desire to first consume the sparsely distributed regions in order that the remaining regions are densely packed.\n+  \/\/ Densely packing regions reduces the effort to search for a region that has sufficient memory to satisfy a new allocation\n+  \/\/ request.  Regions become sparsely distributed following a Full GC, which tends to slide all regions to the front of the\n+  \/\/ heap rather than allowing survivor regions to remain at the high end of the heap where we intend for them to congregate.\n+  _partitions.set_bias_from_left_to_right(ShenandoahFreeSetPartitionId::OldCollector,\n+                                          (available_in_second_half > available_in_first_half));\n+}\n+\n@@ -1164,0 +1790,4 @@\n+    size_t retired_old = 0;\n+    size_t retired_old_humongous = 0;\n+    size_t retired_young = 0;\n+    size_t retired_young_humongous = 0;\n@@ -1165,0 +1795,2 @@\n+    size_t retired_young_waste = 0;\n+    size_t retired_old_waste = 0;\n@@ -1166,1 +1798,1 @@\n-    size_t available_collector = 0;\n+    size_t consumed_old_collector = 0;\n@@ -1168,0 +1800,2 @@\n+    size_t available_old = 0;\n+    size_t available_young = 0;\n@@ -1169,0 +1803,2 @@\n+    size_t available_collector = 0;\n+    size_t available_old_collector = 0;\n@@ -1174,3 +1810,7 @@\n-    log_debug(gc)(\"FreeSet map legend: M:mutator_free C:collector_free H:humongous _:retired\");\n-    log_debug(gc)(\" mutator free range [\" SIZE_FORMAT \"..\" SIZE_FORMAT \"],\"\n-                  \" collector free range [\" SIZE_FORMAT \"..\" SIZE_FORMAT \"]\",\n+\n+    log_debug(gc)(\"FreeSet map legend:\"\n+                       \" M:mutator_free C:collector_free O:old_collector_free\"\n+                       \" H:humongous ~:retired old _:retired young\");\n+    log_debug(gc)(\" mutator free range [\" SIZE_FORMAT \"..\" SIZE_FORMAT \"] allocating from %s, \"\n+                  \" collector free range [\" SIZE_FORMAT \"..\" SIZE_FORMAT \"], \"\n+                  \"old collector free range [\" SIZE_FORMAT \"..\" SIZE_FORMAT \"] allocates from %s\",\n@@ -1179,0 +1819,1 @@\n+                  _partitions.alloc_from_left_bias(ShenandoahFreeSetPartitionId::Mutator)? \"left to right\": \"right to left\",\n@@ -1180,1 +1821,4 @@\n-                  _partitions.rightmost(ShenandoahFreeSetPartitionId::Collector));\n+                  _partitions.rightmost(ShenandoahFreeSetPartitionId::Collector),\n+                  _partitions.leftmost(ShenandoahFreeSetPartitionId::OldCollector),\n+                  _partitions.rightmost(ShenandoahFreeSetPartitionId::OldCollector),\n+                  _partitions.alloc_from_left_bias(ShenandoahFreeSetPartitionId::OldCollector)? \"left to right\": \"right to left\");\n@@ -1190,0 +1834,1 @@\n+        assert(!r->is_old() || r->is_trash(), \"Old regions except trash regions should not be in mutator_free set\");\n@@ -1195,0 +1840,1 @@\n+        assert(!r->is_old() || r->is_trash(), \"Old regions except trash regions should not be in collector_free set\");\n@@ -1198,0 +1844,5 @@\n+      } else if (_partitions.in_free_set(ShenandoahFreeSetPartitionId::OldCollector, i)) {\n+        size_t capacity = alloc_capacity(r);\n+        available_old_collector += capacity;\n+        consumed_old_collector += region_size_bytes - capacity;\n+        buffer[idx] = (capacity == region_size_bytes)? 'O': 'o';\n@@ -1199,1 +1850,7 @@\n-        buffer[idx] = 'h';\n+        if (r->is_old()) {\n+          buffer[idx] = 'H';\n+          retired_old_humongous += region_size_bytes;\n+        } else {\n+          buffer[idx] = 'h';\n+          retired_young_humongous += region_size_bytes;\n+        }\n@@ -1201,1 +1858,9 @@\n-        buffer[idx] = '_';\n+        if (r->is_old()) {\n+          buffer[idx] = '~';\n+          retired_old_waste += alloc_capacity(r);\n+          retired_old += region_size_bytes;\n+        } else {\n+          buffer[idx] = '_';\n+          retired_young_waste += alloc_capacity(r);\n+          retired_young += region_size_bytes;\n+        }\n@@ -1259,1 +1924,0 @@\n-\n@@ -1261,1 +1925,1 @@\n-               byte_size_in_proper_unit(free),          proper_unit_for_byte_size(free),\n+               byte_size_in_proper_unit(total_free),    proper_unit_for_byte_size(total_free),\n@@ -1308,0 +1972,21 @@\n+\n+    if (_heap->mode()->is_generational()) {\n+      size_t max = 0;\n+      size_t total_free = 0;\n+      size_t total_used = 0;\n+\n+      for (idx_t idx = _partitions.leftmost(ShenandoahFreeSetPartitionId::OldCollector);\n+           idx <= _partitions.rightmost(ShenandoahFreeSetPartitionId::OldCollector); idx++) {\n+        if (_partitions.in_free_set(ShenandoahFreeSetPartitionId::OldCollector, idx)) {\n+          ShenandoahHeapRegion *r = _heap->get_region(idx);\n+          size_t free = alloc_capacity(r);\n+          max = MAX2(max, free);\n+          total_free += free;\n+          total_used += r->used();\n+        }\n+      }\n+      ls.print_cr(\" Old Collector Reserve: \" SIZE_FORMAT \"%s, Max: \" SIZE_FORMAT \"%s; Used: \" SIZE_FORMAT \"%s\",\n+                  byte_size_in_proper_unit(total_free), proper_unit_for_byte_size(total_free),\n+                  byte_size_in_proper_unit(max),        proper_unit_for_byte_size(max),\n+                  byte_size_in_proper_unit(total_used), proper_unit_for_byte_size(total_used));\n+    }\n@@ -1319,0 +2004,1 @@\n+      case ShenandoahAllocRequest::_alloc_plab:\n@@ -1350,0 +2036,9 @@\n+  if (_heap->mode()->is_generational()) {\n+    out->print_cr(\"Old Collector Free Set: \" SIZE_FORMAT \"\", _partitions.count(ShenandoahFreeSetPartitionId::OldCollector));\n+    for (idx_t index = _partitions.leftmost(ShenandoahFreeSetPartitionId::OldCollector);\n+         index <= _partitions.rightmost(ShenandoahFreeSetPartitionId::OldCollector); index++) {\n+      if (_partitions.in_free_set(ShenandoahFreeSetPartitionId::OldCollector, index)) {\n+        _heap->get_region(index)->print_on(out);\n+      }\n+    }\n+  }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFreeSet.cpp","additions":870,"deletions":175,"binary":false,"changes":1045,"status":"modified"}]}