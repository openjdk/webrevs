{"files":[{"patch":"@@ -32,0 +32,1 @@\n+#include \"gc\/shenandoah\/shenandoahYoungGeneration.hpp\"\n@@ -87,4 +88,2 @@\n-  size_t capacity    = _generation->soft_max_capacity();\n-  size_t max_cset    = (size_t)((1.0 * capacity \/ 100 * ShenandoahEvacReserve) \/ ShenandoahEvacWaste);\n-  size_t free_target = (capacity \/ 100 * ShenandoahMinFreeThreshold) + max_cset;\n-  size_t min_garbage = (free_target > actual_free ? (free_target - actual_free) : 0);\n+  size_t max_cset    = (ShenandoahHeap::heap()->get_young_evac_reserve() \/ ShenandoahEvacWaste);\n+  size_t capacity    = ShenandoahHeap::heap()->young_generation()->soft_max_capacity();\n@@ -92,4 +91,5 @@\n-  log_info(gc, ergo)(\"Adaptive CSet Selection. Target Free: \" SIZE_FORMAT \"%s, Actual Free: \"\n-                     SIZE_FORMAT \"%s, Max CSet: \" SIZE_FORMAT \"%s, Min Garbage: \" SIZE_FORMAT \"%s\",\n-                     byte_size_in_proper_unit(free_target), proper_unit_for_byte_size(free_target),\n-                     byte_size_in_proper_unit(actual_free), proper_unit_for_byte_size(actual_free),\n+  \/\/ As currently implemented, we are not enforcing that new_garbage > min_garbage\n+  \/\/ size_t free_target = (capacity \/ 100) * ShenandoahMinFreeThreshold + max_cset;\n+  \/\/ size_t min_garbage = (free_target > actual_free ? (free_target - actual_free) : 0);\n+\n+  log_info(gc, ergo)(\"Adaptive CSet Selection. Max CSet: \" SIZE_FORMAT \"%s, Actual Free: \" SIZE_FORMAT \"%s.\",\n@@ -97,1 +97,1 @@\n-                     byte_size_in_proper_unit(min_garbage), proper_unit_for_byte_size(min_garbage));\n+                     byte_size_in_proper_unit(actual_free), proper_unit_for_byte_size(actual_free));\n@@ -103,1 +103,6 @@\n-  size_t cur_garbage = 0;\n+  \/\/ size_t cur_garbage = 0;\n+\n+  \/\/ In generational mode, the sort order within the data array is not strictly descending amounts of garbage.  In\n+  \/\/ particular, regions that have reached tenure age will be sorted into this array before younger regions that contain\n+  \/\/ more garbage.  This represents one of the reasons why we keep looking at regions even after we decide, for example,\n+  \/\/ to exclude one of the regions because it might require evacuation of too much live data.\n@@ -107,0 +112,1 @@\n+    size_t biased_garbage = data[idx]._garbage;\n@@ -109,5 +115,0 @@\n-    size_t new_garbage = cur_garbage + r->garbage();\n-\n-    if (new_cset > max_cset) {\n-      break;\n-    }\n@@ -115,1 +116,23 @@\n-    if ((new_garbage < min_garbage) || (r->garbage() > garbage_threshold)) {\n+    \/\/ As currently implemented, we are not enforcing that new_garbage > min_garbage\n+    \/\/ size_t new_garbage = cur_garbage + r->garbage();\n+\n+    \/\/ Note that live data bytes within a region is not the same as heap_region_size - garbage.  This is because\n+    \/\/ each region contains a combination of used memory (which is garbage plus live) and unused memory, which has not\n+    \/\/ yet been allocated.  It may be the case that the region on this iteration has too much live data to be added to\n+    \/\/ the collection set while one or more regions seen on subsequent iterations of this loop can be added to the collection\n+    \/\/ set because they have smaller live memory, even though they also have smaller garbage (and necessarily a larger\n+    \/\/ amount of unallocated memory).\n+\n+    \/\/ BANDAID: In an earlier version of this code, this was written:\n+    \/\/   if ((new_cset <= max_cset) && ((new_garbage < min_garbage) || (r->garbage() > garbage_threshold)))\n+    \/\/ The problem with the original code is that in some cases the collection set would include hundreds of regions,\n+    \/\/ each with less than 100 bytes of garbage.  Evacuating these regions is counterproductive.\n+\n+    \/\/ TODO: Think about changing the description and defaults for ShenandoahGarbageThreshold and ShenandoahMinFreeThreshold.\n+    \/\/ If \"customers\" want to evacuate regions with smaller amounts of garbage contained therein, they should specify a lower\n+    \/\/ value of ShenandoahGarbageThreshold.  As implemented currently, we may experience back-to-back collections if there is\n+    \/\/ not enough memory to be reclaimed.  Let's not let pursuit of min_garbage drive us to make poor decisions.  Maybe we\n+    \/\/ want yet another global parameter to allow a region to be placed into the collection set if\n+    \/\/ (((new_garbage < min_garbage) && (r->garbage() > ShenandoahSmallerGarbageThreshold)) || (r->garbage() > garbage_threshold))\n+\n+    if ((new_cset <= max_cset) && ((r->garbage() > garbage_threshold) || (r->age() >= InitialTenuringThreshold))) {\n@@ -118,1 +141,3 @@\n-      cur_garbage = new_garbage;\n+      \/\/ cur_garbage = new_garbage;\n+    } else if (biased_garbage == 0) {\n+      break;\n@@ -218,3 +243,0 @@\n-  log_debug(gc)(\"  available adjusted to: \" SIZE_FORMAT \", min_threshold: \" SIZE_FORMAT \", ShenandoahMinFreeThreshold: \" SIZE_FORMAT,\n-                available, min_threshold, ShenandoahMinFreeThreshold);\n-\n@@ -247,0 +269,45 @@\n+  \/\/ ShenandoahAllocSpikeFactor is the percentage of capacity that we endeavor to assure to be free at the end of the GC\n+  \/\/ cycle.\n+  \/\/ TODO: Correct the representation of this quantity\n+  \/\/       (and dive deeper into _gc_time_penalties as this may also need to be corrected)\n+  \/\/\n+  \/\/       Allocation spikes are a characteristic of both the application ahd the JVM configuration.  On the JVM command line,\n+  \/\/       the application developer may want to supply a hint of the nature of spikes that are inherent in the application\n+  \/\/       workload, and this information would normally be independent of heap size (not a percentage thereof).  On the\n+  \/\/       other hand, some allocation spikes are correlated with JVM configuration.  For example, there are allocation\n+  \/\/       spikes at the starts of concurrent marking and evacuation to refresh all local allocation buffers.  The nature\n+  \/\/       of these spikes is determined by LAB min and max sizes and numbers of threads, but also on frequency of GC passes,\n+  \/\/       and on \"periodic\" behavior of these threads  If GC frequency is much higher than the periodic trigger for mutator\n+  \/\/       threads, then many of the mutator threads may be able to \"sit out\" of most GC passes.  Though the thread's stack\n+  \/\/       must be scanned, the thread does not need to refresh its LABs if it sits idle throughout the duration of the GC\n+  \/\/       pass.  The best prediction for this aspect of spikes in allocation patterns is probably recent past history.\n+  \/\/\n+  \/\/  Rationale:\n+  \/\/    The idea is that there is an average allocation rate and there are occassional abnormal bursts (or spikes) of\n+  \/\/    allocations that exceed the average allocation rate.  What do these spikes look like?\n+  \/\/\n+  \/\/    1. At certain phase changes, we may discard large amounts of data and replace it with large numbers of newly\n+  \/\/       allocated objects.  This \"spike\" looks more like a phase change.  We were in steady state at M bytes\/sec\n+  \/\/       allocation rate and now we're in a \"reinitialization phase\" that looks like N bytes\/sec.  We need the \"spike\"\n+  \/\/       accomodation to give us enough runway to recalibrate our \"average allocation rate\".\n+  \/\/\n+  \/\/   2. The typical workload changes.  \"Suddenly\", our typical workload of N TPS increases to N+delta TPS.  This means\n+  \/\/       our average allocation rate needs to be adjusted.  Once again, we need the \"spike\" accomodation to give us\n+  \/\/       enough runway to recalibrate our \"average allocation rate\".\n+  \/\/\n+  \/\/    3. Though there is an \"average\" allocation rate, a given workload's demand for allocation may be very bursty.  We\n+  \/\/       allocate a bunch of LABs during the 5 ms that follow completion of a GC, then we perform no more allocations for\n+  \/\/       the next 150 ms.  It seems we want the \"spike\" to represent the maximum divergence from average within the\n+  \/\/       period of time between consecutive evaluation of the should_start_gc() service.  Here's the thinking:\n+  \/\/\n+  \/\/       a) Between now and the next time I ask whether should_start_gc(), we might experience a spike representing\n+  \/\/          the anticipated burst of allocations.  If that would put us over budget, then we should start GC immediately.\n+  \/\/       b) Between now and the anticipated depletion of allocation pool, there may be two or more bursts of allocations.\n+  \/\/          If there are more than one of these bursts, we can \"approximate\" that these will be separated by spans of\n+  \/\/          time with very little or no allocations so the \"average\" allocation rate should be a suitable approximation\n+  \/\/          of how this will behave.\n+  \/\/\n+  \/\/    For cases 1 and 2, we need to \"quickly\" recalibrate the average allocation rate whenever we detect a change\n+  \/\/    in operation mode.  We want some way to decide that the average rate has changed.  Make average allocation rate\n+  \/\/    computations an independent effort.\n+\n@@ -250,0 +317,9 @@\n+  \/\/ TODO: Account for inherent delays in responding to GC triggers\n+  \/\/  1. It has been observed that delays of 200 ms or greater are common between the moment we return true from should_start_gc()\n+  \/\/     and the moment at which we begin execution of the concurrent reset phase.  Add this time into the calculation of\n+  \/\/     avg_cycle_time below.  (What is \"this time\"?  Perhaps we should remember recent history of this delay for the\n+  \/\/     running workload and use the maximum delay recently seen for \"this time\".)\n+  \/\/  2. The frequency of inquiries to should_start_gc() is adaptive, ranging between ShenandoahControlIntervalMin and\n+  \/\/     ShenandoahControlIntervalMax.  The current control interval (or the max control interval) should also be added into\n+  \/\/     the calculation of avg_cycle_time below.\n+\n@@ -254,0 +330,19 @@\n+\n+  size_t last_live_memory = get_last_live_memory();\n+  size_t penultimate_live_memory = get_penultimate_live_memory();\n+  double original_cycle_time = avg_cycle_time;\n+  if ((penultimate_live_memory < last_live_memory) && (penultimate_live_memory != 0)) {\n+    \/\/ If the live-memory size is growing, our estimates of cycle time are based on lighter workload, so adjust.\n+    \/\/ TODO: Be more precise about how to scale when live memory is growing.  Existing code is a very rough approximation\n+    \/\/ tuned with very limited workload observations.\n+    avg_cycle_time = (avg_cycle_time * 2 * last_live_memory) \/ penultimate_live_memory;\n+  } else {\n+    int degen_cycles = degenerated_cycles_in_a_row();\n+    if (degen_cycles > 0) {\n+      \/\/ If we've degenerated recently, we might be waiting too long between triggers so adjust trigger forward.\n+      \/\/ TODO: Be more precise about how to scale when we've experienced recent degenerated GC.  Existing code is a very\n+      \/\/ rough approximation tuned with very limited workload observations.\n+      avg_cycle_time += degen_cycles * avg_cycle_time;\n+    }\n+  }\n+\n@@ -259,0 +354,5 @@\n+    if (avg_cycle_time > original_cycle_time) {\n+      log_debug(gc)(\"%s: average GC time adjusted from: %.2f ms to %.2f ms because upward trend in live memory retention\",\n+                    _generation->name(), original_cycle_time, avg_cycle_time);\n+    }\n+\n@@ -281,0 +381,1 @@\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahAdaptiveHeuristics.cpp","additions":121,"deletions":20,"binary":false,"changes":141,"status":"modified"},{"patch":"@@ -51,0 +51,4 @@\n+  assert(!ShenandoahHeap::heap()->mode()->is_generational(), \"AggressiveHeuristics not appropriate in generational mode\");\n+\n+  \/\/ Note that there's no bound on collection set size.  If we try to collect too much memory, we'll get an alloc\n+  \/\/ failure during collection and we'll degenerate.\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahAggressiveHeuristics.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -34,0 +34,2 @@\n+#include \"gc\/shenandoah\/shenandoahOldGeneration.hpp\"\n+#include \"gc\/shenandoah\/shenandoahYoungGeneration.hpp\"\n@@ -59,0 +61,2 @@\n+  _live_memory_last_cycle(0),\n+  _live_memory_penultimate_cycle(0),\n@@ -102,0 +106,1 @@\n+  size_t live_memory = 0;\n@@ -105,0 +110,1 @@\n+  size_t remnant_available = 0;\n@@ -126,0 +132,1 @@\n+        live_memory += region->get_live_data_bytes();\n@@ -131,2 +138,1 @@\n-            \/\/ Avoid floating-point math with integer multiply and shift.\n-            garbage = (garbage * ShenandoahTenuredRegionUsageBias) >> ShenandoahTenuredRegionUsageBiasLogBase2;\n+            garbage = (garbage + ShenandoahTenuredRegionUsageBias) * ShenandoahTenuredRegionUsageBias;\n@@ -154,0 +160,2 @@\n+      } else {\n+        live_memory += region->get_live_data_bytes();\n@@ -159,0 +167,2 @@\n+    } else {                      \/\/ region->is_humongous_cont() and !region->is_trash()\n+      live_memory += region->get_live_data_bytes();\n@@ -162,0 +172,2 @@\n+  save_last_live_memory(live_memory);\n+\n@@ -178,0 +190,6 @@\n+\n+      size_t bytes_reserved_for_old_evacuation = collection_set->get_old_bytes_reserved_for_evacuation();\n+      if (bytes_reserved_for_old_evacuation * ShenandoahEvacWaste < heap->get_old_evac_reserve()) {\n+        size_t old_evac_reserve = (size_t) (bytes_reserved_for_old_evacuation * ShenandoahEvacWaste);\n+        heap->set_old_evac_reserve(old_evac_reserve);\n+      }\n@@ -181,0 +199,92 @@\n+    ShenandoahYoungGeneration* young_generation = heap->young_generation();\n+    size_t young_evacuation_reserve = (young_generation->soft_max_capacity() * ShenandoahEvacReserve) \/ 100;\n+\n+    \/\/ At this point, young_generation->available() does not know about recently discovered immediate garbage.\n+    \/\/ What memory it does think to be available is not entirely trustworthy because any available memory associated\n+    \/\/ with a region that is placed into the collection set becomes unavailable when the region is chosen\n+    \/\/ for the collection set.  We'll compute an approximation of young available.  If young_available is zero,\n+    \/\/ we'll need to borrow from old-gen in order to evacuate.  If there's nothing to borrow, we're going to\n+    \/\/ degenerate to full GC.\n+\n+    \/\/ TODO: younng_available can include available (between top() and end()) within each young region that is not\n+    \/\/ part of the collection set.  Making this memory available to the young_evacuation_reserve allows a larger\n+    \/\/ young collection set to be chosen when available memory is under extreme pressure.  Implementing this \"improvement\"\n+    \/\/ is tricky, because the incremental construction of the collection set actually changes the amount of memory\n+    \/\/ available to hold evacuated young-gen objects.  As currently implemented, the memory that is available within\n+    \/\/ non-empty regions that are not selected as part of the collection set can be allocated by the mutator while\n+    \/\/ GC is evacuating and updating references.\n+\n+    size_t region_size_bytes = ShenandoahHeapRegion::region_size_bytes();\n+    size_t free_affiliated_regions = immediate_regions + free_regions;\n+    size_t young_available = (free_affiliated_regions + young_generation->free_unaffiliated_regions()) * region_size_bytes;\n+\n+    size_t regions_available_to_loan = 0;\n+    size_t preapproved_evac_reserve_loan = 0;\n+\n+    if (heap->mode()->is_generational()) {\n+      \/\/  Now that we've primed the collection set, we can figure out how much memory to reserve for evacuation\n+      \/\/  of young-gen objects.\n+      \/\/\n+      \/\/  YoungEvacuationReserve for young generation: how much memory are we reserving to hold the results\n+      \/\/     of evacuating young collection set regions?  This is typically smaller than the total amount\n+      \/\/     of available memory, and is also smaller than the total amount of marked live memory within\n+      \/\/     young-gen.  This value is the minimum of:\n+      \/\/       1. young_gen->available() + (old_gen->available - (OldEvacuationReserve + PromotionReserve))\n+      \/\/       2. young_gen->capacity() * ShenandoahEvacReserve\n+      \/\/\n+      \/\/     Note that any region added to the collection set will be completely evacuated and its memory will\n+      \/\/     be completely recycled at the end of GC.  The recycled memory will be at least as great as the\n+      \/\/     memory borrowed from old-gen.  Enforce that the amount borrowed from old-gen for YoungEvacuationReserve\n+      \/\/     is an integral number of entire heap regions.\n+      \/\/\n+      young_evacuation_reserve -= heap->get_old_evac_reserve();\n+\n+      size_t old_region_borrow_count = 0;\n+\n+      \/\/ Though we cannot know the evacuation_supplement until after we have computed the collection set, we do\n+      \/\/ know that every young-gen region added to the collection set will have a net positive impact on available\n+      \/\/ memory within young-gen, since each contributes a positive amount of garbage to available.  Thus, even\n+      \/\/ without knowing the exact composition of the collection set, we can allow young_evacuation_reserve to\n+      \/\/ exceed young_available if there are empty regions available within old-gen to hold the results of evacuation.\n+\n+      ShenandoahGeneration* old_generation = heap->old_generation();\n+      ShenandoahYoungGeneration* young_generation = heap->young_generation();\n+\n+      \/\/ Not all of what is currently available within young-gen can be reserved to hold the results of young-gen\n+      \/\/ evacuation.  This is because memory available within any heap region that is placed into the collection set\n+      \/\/ is not available to be allocated during evacuation.  To be safe, we assure that all memory required for evacuation\n+      \/\/ is available within \"virgin\" heap regions.\n+\n+      const size_t available_young_regions = free_regions + immediate_regions + young_generation->free_unaffiliated_regions();\n+      const size_t available_old_regions = old_generation->free_unaffiliated_regions();\n+      size_t already_reserved_old_bytes = heap->get_old_evac_reserve() + heap->get_promotion_reserve();\n+      size_t regions_reserved_for_evac_and_promotion = (already_reserved_old_bytes + region_size_bytes - 1) \/ region_size_bytes;\n+      regions_available_to_loan = available_old_regions - regions_reserved_for_evac_and_promotion;\n+\n+      if (available_young_regions * region_size_bytes < young_evacuation_reserve) {\n+        \/\/ Try to borrow old-gen regions in order to avoid shrinking young_evacuation_reserve\n+        size_t loan_request = young_evacuation_reserve - available_young_regions * region_size_bytes;\n+        size_t loaned_region_request = (loan_request + region_size_bytes - 1) \/ region_size_bytes;\n+        if (loaned_region_request > regions_available_to_loan) {\n+          \/\/ Scale back young_evacuation_reserve to consume all available young and old regions.  After the\n+          \/\/ collection set is chosen, we may get some of this memory back for pacing allocations during evacuation\n+          \/\/ and update refs.\n+          loaned_region_request = regions_available_to_loan;\n+          young_evacuation_reserve = (available_young_regions + loaned_region_request) * region_size_bytes;\n+        } else {\n+          \/\/ No need to scale back young_evacuation_reserve.\n+        }\n+        preapproved_evac_reserve_loan = loaned_region_request * region_size_bytes;\n+      } else {\n+        \/\/ No need scale back young_evacuation_reserve and no need to borrow from old-gen.  We may even have some\n+        \/\/ available_young_regions to support allocation pacing.\n+      }\n+\n+    } else if (young_evacuation_reserve > young_available) {\n+      \/\/ In non-generational mode, there's no old-gen memory to borrow from\n+      young_evacuation_reserve = young_available;\n+    }\n+\n+    heap->set_young_evac_reserve(young_evacuation_reserve);\n+    heap->reset_young_evac_expended();\n+\n@@ -184,0 +294,54 @@\n+    size_t young_evacuated_bytes = collection_set->get_young_bytes_reserved_for_evacuation();;\n+    if (young_evacuated_bytes * ShenandoahEvacWaste < young_evacuation_reserve) {\n+      young_evacuation_reserve = (size_t) (young_evacuated_bytes * ShenandoahEvacWaste);\n+      heap->set_young_evac_reserve((size_t) young_evacuation_reserve);\n+    }\n+\n+    \/\/ Now compute the evacuation supplement, which is extra memory borrowed from old-gen that can be allocated\n+    \/\/ by mutators while GC is working on evacuation and update-refs.\n+\n+    \/\/ During evacuation and update refs, we will be able to allocate any memory that is currently available\n+    \/\/ plus any memory that can be borrowed on the collateral of the current collection set, reserving a certain\n+    \/\/ percentage of the anticipated replenishment from collection set memory to be allocated during the subsequent\n+    \/\/ concurrent marking effort.  This is how much I can repay.\n+    size_t potential_supplement_regions = collection_set->get_young_region_count();\n+\n+    \/\/ Though I can repay potential_supplement_regions, I can't borrow them unless they are available in old-gen.\n+    if (potential_supplement_regions > regions_available_to_loan) {\n+      potential_supplement_regions = regions_available_to_loan;\n+    }\n+\n+    size_t potential_evac_supplement;\n+\n+    \/\/ How much of the potential_supplement_regions will be consumed by young_evacuation_reserve: borrowed_evac_regions.\n+    const size_t available_unaffiliated_young_regions = young_generation->free_unaffiliated_regions();\n+    const size_t available_affiliated_regions = free_regions + immediate_regions;\n+    const size_t available_young_regions = available_unaffiliated_young_regions + available_affiliated_regions;\n+    size_t young_evac_regions = (young_evacuation_reserve + region_size_bytes - 1) \/ region_size_bytes;\n+    size_t borrowed_evac_regions = (young_evac_regions > available_young_regions)? young_evac_regions - available_young_regions: 0;\n+\n+    potential_supplement_regions -= borrowed_evac_regions;\n+    potential_evac_supplement = potential_supplement_regions * region_size_bytes;\n+\n+    \/\/ Leave some allocation runway for subsequent concurrent mark phase.\n+    potential_evac_supplement = (potential_evac_supplement * ShenandoahBorrowPercent) \/ 100;\n+\n+    heap->set_alloc_supplement_reserve(potential_evac_supplement);\n+\n+    size_t promotion_budget = heap->get_promotion_reserve();\n+    size_t old_evac_budget = heap->get_old_evac_reserve();\n+    size_t alloc_budget_evac_and_update = potential_evac_supplement + young_available;\n+\n+    \/\/ TODO: young_available, which feeds into alloc_budget_evac_and_update is lacking memory available within\n+    \/\/ existing young-gen regions that were not selected for the collection set.  Add this in and adjust the\n+    \/\/ log message (where it says \"empty-region allocation budget\").\n+\n+    log_info(gc, ergo)(\"Memory reserved for evacuation and update-refs includes promotion budget: \" SIZE_FORMAT\n+                       \"%s, young evacuation budget: \" SIZE_FORMAT \"%s, old evacuation budget: \" SIZE_FORMAT\n+                       \"%s, empty-region allocation budget: \" SIZE_FORMAT \"%s, including supplement: \" SIZE_FORMAT \"%s\",\n+                       byte_size_in_proper_unit(promotion_budget), proper_unit_for_byte_size(promotion_budget),\n+                       byte_size_in_proper_unit(young_evacuation_reserve), proper_unit_for_byte_size(young_evacuation_reserve),\n+                       byte_size_in_proper_unit(old_evac_budget), proper_unit_for_byte_size(old_evac_budget),\n+                       byte_size_in_proper_unit(alloc_budget_evac_and_update),\n+                       proper_unit_for_byte_size(alloc_budget_evac_and_update),\n+                       byte_size_in_proper_unit(potential_evac_supplement), proper_unit_for_byte_size(potential_evac_supplement));\n@@ -185,0 +349,1 @@\n+  \/\/ else, we're going to skip evacuation and update refs because we reclaimed sufficient amounts of immediate garbage.\n@@ -187,1 +352,0 @@\n-\n@@ -330,0 +494,12 @@\n+void ShenandoahHeuristics::save_last_live_memory(size_t live_memory) {\n+  _live_memory_penultimate_cycle = _live_memory_last_cycle;\n+  _live_memory_last_cycle = live_memory;\n+}\n+\n+size_t ShenandoahHeuristics::get_last_live_memory() {\n+  return _live_memory_last_cycle;\n+}\n+\n+size_t ShenandoahHeuristics::get_penultimate_live_memory() {\n+  return _live_memory_penultimate_cycle;\n+}\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahHeuristics.cpp","additions":179,"deletions":3,"binary":false,"changes":182,"status":"modified"},{"patch":"@@ -102,0 +102,3 @@\n+  size_t _live_memory_last_cycle;\n+  size_t _live_memory_penultimate_cycle;\n+\n@@ -131,0 +134,4 @@\n+  uint degenerated_cycles_in_a_row() {\n+    return _degenerated_cycles_in_a_row;\n+  }\n+\n@@ -162,0 +169,4 @@\n+\n+  void save_last_live_memory(size_t live_memory);\n+  size_t get_last_live_memory();\n+  size_t get_penultimate_live_memory();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahHeuristics.hpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -28,0 +28,3 @@\n+#include \"gc\/shenandoah\/shenandoahGeneration.hpp\"\n+#include \"gc\/shenandoah\/shenandoahOldGeneration.hpp\"\n+#include \"gc\/shenandoah\/shenandoahYoungGeneration.hpp\"\n@@ -45,1 +48,0 @@\n-    \/\/ no candidates for inclusion in collection set.\n@@ -49,0 +51,1 @@\n+  ShenandoahHeap* heap = ShenandoahHeap::heap();\n@@ -58,1 +61,1 @@\n-  \/\/ max_old_evacuation_bytes represents an \"arbitrary\" bound on how much evacuation effort is dedicated\n+  \/\/ max_old_evacuation_bytes represents a bound on how much evacuation effort is dedicated\n@@ -60,1 +63,19 @@\n-  const size_t max_old_evacuation_bytes = (size_t) ((double)_generation->soft_max_capacity() \/ 100 * ShenandoahOldEvacReserve);\n+  size_t max_old_evacuation_bytes = (heap->old_generation()->soft_max_capacity() * ShenandoahOldEvacReserve) \/ 100;\n+  const size_t young_evacuation_bytes = (heap->young_generation()->soft_max_capacity() * ShenandoahEvacReserve) \/ 100;\n+  const size_t ratio_bound_on_old_evac_bytes = (young_evacuation_bytes * ShenandoahOldEvacRatioPercent) \/ 100;\n+  if (max_old_evacuation_bytes > ratio_bound_on_old_evac_bytes) {\n+    max_old_evacuation_bytes = ratio_bound_on_old_evac_bytes;\n+  }\n+\n+  \/\/ Usually, old-evacuation is limited by the CPU bounds on effort.  However, it can also be bounded by available\n+  \/\/ memory within old-gen to hold the results of evacuation.  When we are bound by memory availability, we need\n+  \/\/ to account below for the loss of available memory from within each region that is added to the old-gen collection\n+  \/\/ set.\n+  size_t old_available = heap->old_generation()->available();\n+  size_t excess_old_capacity_for_evacuation;\n+  if (max_old_evacuation_bytes > old_available) {\n+    max_old_evacuation_bytes = old_available;\n+    excess_old_capacity_for_evacuation = 0;\n+  } else {\n+    excess_old_capacity_for_evacuation = old_available - max_old_evacuation_bytes;\n+  }\n@@ -67,10 +88,5 @@\n-  \/\/ TODO We should probably enforce this, but there is no enforcement currently.  Key idea: if there is not\n-  \/\/ sufficient memory within old-gen to hold an object that wants to be promoted, defer promotion until a\n-  \/\/ subsequent evacuation pass.  Since enforcement may be expensive, requiring frequent synchronization\n-  \/\/ between mutator and GC threads, here's an alternative \"greedy\" mitigation strategy: Set the parameter's\n-  \/\/ value so overflow is \"very rare\".  In the case that we experience overflow, evacuate what we can from\n-  \/\/ within the old collection set, but don't evacuate everything.  At the end of evacuation, any collection\n-  \/\/ set region that was not fully evacuated cannot be recycled.  It becomes a prime candidate for the next\n-  \/\/ collection set selection.  Here, we'd rather fall back to this contingent behavior than force a full STW\n-  \/\/ collection.\n-  const size_t promotion_budget_bytes = (ShenandoahHeapRegion::region_size_bytes() \/ 2);\n+  \/\/ Key idea: if there is not sufficient memory within old-gen to hold an object that wants to be promoted, defer\n+  \/\/ promotion until a subsequent evacuation pass.  Enforcement is provided at the time PLABs and shared allocations\n+  \/\/ in old-gen memory are requested.\n+\n+  const size_t promotion_budget_bytes = heap->get_promotion_reserve();\n@@ -86,20 +102,3 @@\n-  \/\/ Allow no more evacuation than exists free-space within old-gen memory\n-  size_t old_evacuation_budget = ((_generation->available() > promotion_budget_bytes)\n-                                  ? _generation->available() - promotion_budget_bytes: 0);\n-\n-  \/\/ But if the amount of available free space in old-gen memory exceeds the pacing bound on how much old-gen\n-  \/\/ memory can be evacuated during each evacuation pass, then cut the old-gen evacuation further.  The pacing\n-  \/\/ bound is designed to assure that old-gen evacuations to not excessively slow the evacuation pass in order\n-  \/\/ to assure that young-gen GC cadence is not disrupted.\n-\n-  \/\/ excess_free_capacity represents availability of memory to hold evacuations beyond what is required to hold\n-  \/\/ planned evacuations.  It may go negative if we choose to collect regions with large amounts of free memory.\n-  long long excess_free_capacity;\n-  if (old_evacuation_budget > max_old_evacuation_bytes) {\n-    excess_free_capacity = old_evacuation_budget - max_old_evacuation_bytes;\n-    old_evacuation_budget = max_old_evacuation_bytes;\n-  } else\n-    excess_free_capacity = 0;\n-\n-  log_info(gc)(\"Choose old regions for mixed collection: excess capacity: \" SIZE_FORMAT \"%s, evacuation budget: \" SIZE_FORMAT \"%s\",\n-                byte_size_in_proper_unit((size_t) excess_free_capacity), proper_unit_for_byte_size(excess_free_capacity),\n+  size_t old_evacuation_budget = (size_t) (max_old_evacuation_bytes \/ ShenandoahEvacWaste);\n+\n+  log_info(gc)(\"Choose old regions for mixed collection: old evacuation budget: \" SIZE_FORMAT \"%s\",\n@@ -109,0 +108,1 @@\n+  size_t lost_evacuation_capacity = 0;\n@@ -117,3 +117,0 @@\n-    \/\/ Assuming region r is added to the collection set, what will be the remaining_old_evacuation_budget after\n-    \/\/ accounting for the loss of region r's free() memory.\n-    size_t adjusted_remaining_old_evacuation_budget;\n@@ -123,11 +120,18 @@\n-    excess_free_capacity -= r->free();\n-    \/\/ If subtracting r->free from excess_free_capacity() makes it go negative, that means we are going to have\n-    \/\/ to decrease the evacuation budget.\n-    if (excess_free_capacity < 0) {\n-      if (remaining_old_evacuation_budget < (size_t) -excess_free_capacity) {\n-        \/\/ By setting adjusted_remaining_old_evacuation_budget to 0, we prevent further additions to the old-gen\n-        \/\/ collection set, unless the region has zero live data bytes.\n-        adjusted_remaining_old_evacuation_budget = 0;\n-      } else {\n-        \/\/ Adding negative excess_free_capacity decreases the adjusted_remaining_old_evacuation_budget\n-        adjusted_remaining_old_evacuation_budget = remaining_old_evacuation_budget + excess_free_capacity;\n+    if ((r->get_live_data_bytes() <= remaining_old_evacuation_budget) &&\n+        ((lost_evacuation_capacity + r->free() <= excess_old_capacity_for_evacuation)\n+         || (r->get_live_data_bytes() + r->free() <= remaining_old_evacuation_budget))) {\n+\n+      \/\/ Decrement remaining evacuation budget by bytes that will be copied.  If the cumulative loss of free memory from\n+      \/\/ regions that are to be collected exceeds excess_old_capacity_for_evacuation,  decrease\n+      \/\/ remaining_old_evacuation_budget by this loss as well.\n+      lost_evacuation_capacity += r->free();\n+      remaining_old_evacuation_budget -= r->get_live_data_bytes();\n+      if (lost_evacuation_capacity > excess_old_capacity_for_evacuation) {\n+        \/\/ This is slightly conservative because we really only need to remove from the remaining evacuation budget\n+        \/\/ the amount by which lost_evacution_capacity exceeds excess_old_capacity_for_evacuation, but this is relatively\n+        \/\/ rare event and current thought is to be a bit conservative rather than mess up the math on code that is so\n+        \/\/ difficult to test and maintain...\n+\n+        \/\/ Once we have crossed the threshold of lost_evacuation_capacity exceeding excess_old_capacity_for_evacuation,\n+        \/\/ every subsequent iteration of this loop will further decrease remaining_old_evacuation_budget.\n+        remaining_old_evacuation_budget -= r->free();\n@@ -135,0 +139,4 @@\n+      collection_set->add_region(r);\n+      included_old_regions++;\n+      evacuated_old_bytes += r->get_live_data_bytes();\n+      consume_old_collection_candidate();\n@@ -136,4 +144,0 @@\n-      adjusted_remaining_old_evacuation_budget = remaining_old_evacuation_budget;\n-    }\n-\n-    if (r->get_live_data_bytes() > adjusted_remaining_old_evacuation_budget) {\n@@ -142,5 +146,0 @@\n-    collection_set->add_region(r);\n-    included_old_regions++;\n-    evacuated_old_bytes += r->get_live_data_bytes();\n-    consume_old_collection_candidate();\n-    remaining_old_evacuation_budget = adjusted_remaining_old_evacuation_budget - r->get_live_data_bytes();\n@@ -157,1 +156,4 @@\n-bool ShenandoahOldHeuristics::choose_collection_set(ShenandoahCollectionSet* collection_set, ShenandoahOldHeuristics* old_heuristics) {\n+bool ShenandoahOldHeuristics::choose_collection_set(ShenandoahCollectionSet* collection_set,\n+                                                    ShenandoahOldHeuristics* old_heuristics) {\n+  assert((collection_set == nullptr) && (old_heuristics == nullptr),\n+         \"Expect null arguments in ShenandoahOldHeuristics::choose_collection_set()\");\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahOldHeuristics.cpp","additions":59,"deletions":57,"binary":false,"changes":116,"status":"modified"},{"patch":"@@ -57,1 +57,1 @@\n-  size_t available = MAX2(max_capacity \/ 100 * ShenandoahEvacReserve, actual_free);\n+  size_t available = MAX2((max_capacity \/ 100) * ShenandoahEvacReserve, actual_free);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahPassiveHeuristics.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -61,0 +61,13 @@\n+const char affiliation_code(ShenandoahRegionAffiliation type) {\n+  switch(type) {\n+    case ShenandoahRegionAffiliation::FREE:\n+      return 'F';\n+    case ShenandoahRegionAffiliation::YOUNG_GENERATION:\n+      return 'Y';\n+    case ShenandoahRegionAffiliation::OLD_GENERATION:\n+      return 'O';\n+    default:\n+      ShouldNotReachHere();\n+      return 'X';\n+  }\n+}\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/mode\/shenandoahGenerationalMode.cpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -45,0 +45,1 @@\n+const char affiliation_code(ShenandoahRegionAffiliation type);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/mode\/shenandoahGenerationalMode.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -90,0 +90,9 @@\n+\n+  if (r->affiliation() == YOUNG_GENERATION) {\n+    _young_region_count++;\n+    _young_bytes_to_evacuate += r->get_live_data_bytes();\n+  } else if (r->affiliation() == OLD_GENERATION) {\n+    _old_region_count++;\n+    _old_bytes_to_evacuate += r->get_live_data_bytes();\n+  }\n+\n@@ -114,0 +123,5 @@\n+  _young_region_count = 0;\n+  _old_region_count = 0;\n+  _young_bytes_to_evacuate = 0;\n+  _old_bytes_to_evacuate = 0;\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahCollectionSet.cpp","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -50,0 +50,9 @@\n+  size_t                _immediate_trash;\n+  size_t                _evacuation_reserve; \/\/ How many bytes reserved in generation for evacuation replicas.  This does\n+                                             \/\/ not include bytes reserved for old-generation replicas.  The value is\n+                                             \/\/ conservative in that memory may be reserved for objects that will be promoted.\n+  size_t                _young_bytes_to_evacuate;\n+  size_t                _old_bytes_to_evacuate;\n+\n+  size_t                _young_region_count;\n+  size_t                _old_region_count;\n@@ -81,0 +90,19 @@\n+  inline size_t get_immediate_trash();\n+  inline void set_immediate_trash(size_t immediate_trash);\n+\n+  \/\/ This represents total amount of work to be performed by evacuation, including evacuations to young, to old,\n+  \/\/ and promotions from young to old.  This equals get_young_bytes_reserved_for_evacuation() plus\n+  \/\/ get_old_bytes_reserved_for_evacuation().\n+  inline size_t get_bytes_reserved_for_evacuation();\n+\n+  \/\/ It is not known how many of these bytes will be promoted.\n+  inline size_t get_young_bytes_reserved_for_evacuation();\n+  inline void reserve_young_bytes_for_evacuation(size_t byte_count);\n+\n+  inline size_t get_old_bytes_reserved_for_evacuation();\n+  inline void reserve_old_bytes_for_evacuation(size_t byte_count);\n+\n+  inline size_t get_old_region_count();\n+\n+  inline size_t get_young_region_count();\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahCollectionSet.hpp","additions":28,"deletions":0,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -56,0 +56,28 @@\n+void ShenandoahCollectionSet::set_immediate_trash(size_t immediate_trash) {\n+  _immediate_trash = immediate_trash;\n+}\n+\n+size_t ShenandoahCollectionSet::get_immediate_trash() {\n+  return _immediate_trash;\n+}\n+\n+size_t ShenandoahCollectionSet::get_old_bytes_reserved_for_evacuation() {\n+  return _old_bytes_to_evacuate;\n+}\n+\n+size_t ShenandoahCollectionSet::get_young_bytes_reserved_for_evacuation() {\n+  return _young_bytes_to_evacuate;\n+}\n+\n+size_t ShenandoahCollectionSet::get_bytes_reserved_for_evacuation() {\n+  return _young_bytes_to_evacuate + _old_bytes_to_evacuate;\n+}\n+\n+size_t ShenandoahCollectionSet::get_old_region_count() {\n+  return _old_region_count;\n+}\n+\n+size_t ShenandoahCollectionSet::get_young_region_count() {\n+  return _young_region_count;\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahCollectionSet.inline.hpp","additions":28,"deletions":0,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -78,0 +78,1 @@\n+  ShenandoahHeap::heap()->record_upgrade_to_full();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahCollectorPolicy.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -34,0 +34,2 @@\n+#include \"gc\/shenandoah\/shenandoahOldGeneration.hpp\"\n+#include \"gc\/shenandoah\/shenandoahYoungGeneration.hpp\"\n@@ -89,0 +91,1 @@\n+  heap->start_conc_gc();\n@@ -201,1 +204,2 @@\n-    vmop_entry_final_roots();\n+    \/\/ We chose not to evacuate because we found sufficient immediate garbage.\n+    vmop_entry_final_roots(heap->is_aging_cycle());\n@@ -203,0 +207,29 @@\n+  size_t old_available, young_available;\n+  {\n+    ShenandoahYoungGeneration* young_gen = heap->young_generation();\n+    ShenandoahGeneration* old_gen = heap->old_generation();\n+    ShenandoahHeapLocker locker(heap->lock());\n+\n+    size_t old_usage_before_evac = heap->capture_old_usage(0);\n+    size_t old_usage_now = old_gen->used();\n+    size_t promoted_bytes = old_usage_now - old_usage_before_evac;\n+    heap->set_previous_promotion(promoted_bytes);\n+\n+    young_gen->unadjust_available();\n+    old_gen->unadjust_available();\n+    young_gen->increase_used(heap->get_young_evac_expended());\n+    \/\/ No need to old_gen->increase_used().  That was done when plabs were allocated, accounting for both old evacs and promotions.\n+\n+    young_available = young_gen->adjusted_available();\n+    old_available = old_gen->adjusted_available();\n+\n+    heap->set_alloc_supplement_reserve(0);\n+    heap->set_young_evac_reserve(0);\n+    heap->reset_young_evac_expended();\n+    heap->set_old_evac_reserve(0);\n+    heap->reset_old_evac_expended();\n+    heap->set_promotion_reserve(0);\n+  }\n+  log_info(gc, ergo)(\"At end of concurrent GC, old_available: \" SIZE_FORMAT \"%s, young_available: \" SIZE_FORMAT \"%s\",\n+                     byte_size_in_proper_unit(old_available), proper_unit_for_byte_size(old_available),\n+                     byte_size_in_proper_unit(young_available), proper_unit_for_byte_size(young_available));\n@@ -247,1 +280,1 @@\n-void ShenandoahConcurrentGC::vmop_entry_final_roots() {\n+void ShenandoahConcurrentGC::vmop_entry_final_roots(bool increment_region_ages) {\n@@ -254,1 +287,1 @@\n-  VM_ShenandoahFinalRoots op(this);\n+  VM_ShenandoahFinalRoots op(this, increment_region_ages);\n@@ -634,0 +667,8 @@\n+    \/\/ The collection set is chosen by prepare_regions_and_collection_set().\n+    \/\/\n+    \/\/ TODO: Under severe memory overload conditions that can be checked here, we may want to limit\n+    \/\/ the inclusion of old-gen candidates within the collection set.  This would allow us to prioritize efforts on\n+    \/\/ evacuating young-gen,  This remediation is most appropriate when old-gen availability is very high (so there\n+    \/\/ are negligible negative impacts from delaying completion of old-gen evacuation) and when young-gen collections\n+    \/\/ are \"under duress\" (as signalled by very low availability of memory within young-gen, indicating that\/ young-gen\n+    \/\/ collections are not triggering frequently enough).\n@@ -635,0 +676,21 @@\n+\n+    \/\/ Upon return from prepare_regions_and_collection_set(), certain parameters have been established to govern the\n+    \/\/ evacuation efforts that are about to begin.  In particular:\n+    \/\/\n+    \/\/ heap->get_promotion_reserve() represents the amount of memory within old-gen's available memory that has\n+    \/\/   been set aside to hold objects promoted from young-gen memory.  This represents an estimated percentage\n+    \/\/   of the live young-gen memory within the collection set.  If there is more data ready to be promoted than\n+    \/\/   can fit within this reserve, the promotion of some objects will be deferred until a subsequent evacuation\n+    \/\/   pass.\n+    \/\/\n+    \/\/ heap->get_old_evac_reserve() represents the amount of memory within old-gen's available memory that has been\n+    \/\/  set aside to hold objects evacuated from the old-gen collection set.\n+    \/\/\n+    \/\/ heap->get_young_evac_reserve() represents the amount of memory within young-gen's available memory that has\n+    \/\/  been set aside to hold objects evacuated from the young-gen collection set.  Conservatively, this value\n+    \/\/  equals the entire amount of live young-gen memory within the collection set, even though some of this memory\n+    \/\/  will likely be promoted.\n+    \/\/\n+    \/\/ heap->get_alloc_supplement_reserve() represents the amount of old-gen memory that can be allocated during evacuation\n+    \/\/ and update-refs phases of gc.  The young evacuation reserve has already been removed from this quantity.\n+\n@@ -662,0 +724,14 @@\n+      if (heap->mode()->is_generational()) {\n+        \/\/ Calculate the temporary evacuation allowance supplement to young-gen memory capacity (for allocations\n+        \/\/ and young-gen evacuations).\n+        size_t young_available = heap->young_generation()->adjust_available(heap->get_alloc_supplement_reserve());\n+        \/\/ old_available is memory that can hold promotions and evacuations.  Subtract out the memory that is being\n+        \/\/ loaned for young-gen allocations or evacuations.\n+        size_t old_available = heap->old_generation()->adjust_available(-heap->get_alloc_supplement_reserve());\n+\n+        log_info(gc, ergo)(\"After generational memory budget adjustments, old avaiable: \" SIZE_FORMAT\n+                           \"%s, young_available: \" SIZE_FORMAT \"%s\",\n+                           byte_size_in_proper_unit(old_available), proper_unit_for_byte_size(old_available),\n+                           byte_size_in_proper_unit(young_available), proper_unit_for_byte_size(young_available));\n+      }\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahConcurrentGC.cpp","additions":79,"deletions":3,"binary":false,"changes":82,"status":"modified"},{"patch":"@@ -70,1 +70,1 @@\n-  void vmop_entry_final_roots();\n+  void vmop_entry_final_roots(bool incr_region_ages);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahConcurrentGC.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+#include \"gc\/shenandoah\/shenandoahYoungGeneration.hpp\"\n@@ -227,0 +228,18 @@\n+  if (heap->mode()->is_generational()) {\n+    \/\/ In case degeneration interrupted concurrent evacuation or update references, we need to clean up transient state.\n+    \/\/ Otherwise, these actions have no effect.\n+\n+    heap->young_generation()->unadjust_available();\n+    heap->old_generation()->unadjust_available();\n+    heap->young_generation()->increase_used(heap->get_young_evac_expended());\n+    \/\/ No need to old_gen->increase_used().  That was done when plabs were allocated, accounting for both old evacs and promotions.\n+\n+    heap->set_alloc_supplement_reserve(0);\n+    heap->set_young_evac_reserve(0);\n+    heap->reset_young_evac_expended();\n+    heap->set_old_evac_reserve(0);\n+    heap->reset_old_evac_expended();\n+    heap->set_promotion_reserve(0);\n+\n+  }\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahDegeneratedGC.cpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -97,0 +97,2 @@\n+  \/\/ Overwrite with non-zero (non-NULL) values only if necessary for allocation bookkeeping.\n+\n@@ -100,1 +102,0 @@\n-\n@@ -104,0 +105,1 @@\n+          \/\/ try_allocate_in() increases used if the allocation is successful.\n@@ -115,0 +117,3 @@\n+      \/\/ GCLABs are for evacuation so we must be in evacuation phase.  If this allocation is successful, increment\n+      \/\/ the relevant evac_expended rather than used value.\n+\n@@ -116,0 +121,2 @@\n+      \/\/ PLABs always reside in old-gen and are only allocated during evacuation phase.\n+\n@@ -201,1 +208,1 @@\n-  \/\/ req.size() is in words, free() is in bytes.\n+  \/\/ req.size() is in words, r->free() is in bytes.\n@@ -207,0 +214,4 @@\n+      if ((free != usable_free) && (free - usable_free < ShenandoahHeap::min_fill_size() * HeapWordSize)) {\n+        \/\/ We'll have to add another card's memory to the padding\n+        usable_free -= CardTable::card_size;\n+      }\n@@ -225,0 +236,1 @@\n+      \/\/ This is a GCLAB or a TLAB allocation\n@@ -239,0 +251,4 @@\n+    if ((free != usable_free) && (free - usable_free < ShenandoahHeap::min_fill_size() * HeapWordSize)) {\n+      \/\/ We'll have to add another card's memory to the padding\n+      usable_free -= CardTable::card_size;\n+    }\n@@ -263,0 +279,2 @@\n+      \/\/ Mutator allocations always pull from young gen.\n+      _heap->young_generation()->increase_used(size * HeapWordSize);\n@@ -264,1 +282,3 @@\n-    } else if (req.is_gc_alloc()) {\n+    } else {\n+      \/\/ assert(req.is_gc_alloc(), \"Should be gc_alloc since req wasn't mutator alloc\");\n+\n@@ -273,1 +293,0 @@\n-    }\n@@ -275,4 +294,12 @@\n-    if (r->affiliation() == ShenandoahRegionAffiliation::YOUNG_GENERATION) {\n-      _heap->young_generation()->increase_used(size * HeapWordSize);\n-    } else if (r->affiliation() == ShenandoahRegionAffiliation::OLD_GENERATION) {\n-      _heap->old_generation()->increase_used(size * HeapWordSize);\n+      if (r->affiliation() == ShenandoahRegionAffiliation::YOUNG_GENERATION) {\n+        \/\/ This is either a GCLAB or it is a shared evacuation allocation.  In either case, we expend young evac.\n+        \/\/ At end of update refs, we'll add expended young evac into young_gen->used.  We hide this usage\n+        \/\/ from current accounting because memory reserved for evacuation is not part of adjusted capacity.\n+        _heap->expend_young_evac(size * HeapWordSize);\n+      } else {\n+        assert(r->affiliation() == ShenandoahRegionAffiliation::OLD_GENERATION, \"GC Alloc was not YOUNG so must be OLD\");\n+\n+        assert(req.type() != _alloc_gclab, \"old-gen allocations use PLAB or shared allocation\");\n+        _heap->old_generation()->increase_used(size * HeapWordSize);\n+        \/\/ for plabs, we'll sort the difference between evac and promotion usage when we retire the plab\n+      }\n@@ -281,1 +308,0 @@\n-\n@@ -287,2 +313,3 @@\n-    \/\/ almost-full regions precede the fully-empty region where we want allocate the entire TLAB.\n-    \/\/ TODO: Record first fully-empty region, and use that for large allocations\n+    \/\/ almost-full regions precede the fully-empty region where we want to allocate the entire TLAB.\n+    \/\/ TODO: Record first fully-empty region, and use that for large allocations and\/or organize\n+    \/\/ available free segments within regions for more efficient searches for \"good fit\".\n@@ -429,1 +456,0 @@\n-\n@@ -554,1 +580,1 @@\n-  size_t to_reserve = _heap->max_capacity() \/ 100 * ShenandoahEvacReserve;\n+  size_t to_reserve = (_heap->max_capacity() \/ 100) * ShenandoahEvacReserve;\n@@ -670,0 +696,1 @@\n+  \/\/ Allocation request is known to satisfy all memory budgeting constraints.\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFreeSet.cpp","additions":40,"deletions":13,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -72,3 +72,0 @@\n-  size_t collector_count() const { return _collector_free_bitmap.count_one_bits(); }\n-  size_t mutator_count()   const { return _mutator_free_bitmap.count_one_bits();   }\n-\n@@ -84,0 +81,6 @@\n+  \/\/ Number of regions dedicated to GC allocations (for evacuation or promotion) that are currently free\n+  size_t collector_count() const { return _collector_free_bitmap.count_one_bits(); }\n+\n+  \/\/ Number of regions dedicated to mutator allocations that are currently free\n+  size_t mutator_count()   const { return _mutator_free_bitmap.count_one_bits();   }\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFreeSet.hpp","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -184,0 +184,13 @@\n+  \/\/ There will be no concurrent allocations during full GC so reset these coordination variables.\n+  heap->young_generation()->unadjust_available();\n+  heap->old_generation()->unadjust_available();\n+  heap->young_generation()->increase_used(heap->get_young_evac_expended());\n+  \/\/ No need to old_gen->increase_used().  That was done when plabs were allocated, accounting for both old evacs and promotions.\n+\n+  heap->set_alloc_supplement_reserve(0);\n+  heap->set_young_evac_reserve(0);\n+  heap->reset_young_evac_expended();\n+  heap->set_old_evac_reserve(0);\n+  heap->reset_old_evac_expended();\n+  heap->set_promotion_reserve(0);\n+\n@@ -405,0 +418,4 @@\n+\n+  \/\/ _empty_regions is a thread-local list of heap regions that have been completely emptied by this worker thread's\n+  \/\/ compaction efforts.  The worker thread that drives these efforts adds compacted regions to this list if the\n+  \/\/ region has not been compacted onto itself.\n@@ -491,2 +508,28 @@\n-    if (_from_affiliation == ShenandoahRegionAffiliation::OLD_GENERATION) {\n-      assert(_old_to_region != nullptr, \"_old_to_region should not be NULL when compacting OLD _from_region\");\n+    uint from_region_age = _from_region->age();\n+    uint object_age = p->age();\n+\n+    bool promote_object = false;\n+    if ((_from_affiliation == ShenandoahRegionAffiliation::YOUNG_GENERATION) &&\n+        (from_region_age + object_age > InitialTenuringThreshold)) {\n+      if ((_old_to_region != nullptr) && (_old_compact_point + obj_size > _old_to_region->end())) {\n+        finish_old_region();\n+        _old_to_region = nullptr;\n+      }\n+      if (_old_to_region == nullptr) {\n+        if (_empty_regions_pos < _empty_regions.length()) {\n+          ShenandoahHeapRegion* new_to_region = _empty_regions.at(_empty_regions_pos);\n+          _empty_regions_pos++;\n+          new_to_region->set_affiliation(OLD_GENERATION);\n+          _old_to_region = new_to_region;\n+          _old_compact_point = _old_to_region->bottom();\n+          promote_object = true;\n+        }\n+        \/\/ Else this worker thread does not yet have any empty regions into which this aged object can be promoted so\n+        \/\/ we leave promote_object as false, deferring the promotion.\n+      } else {\n+        promote_object = true;\n+      }\n+    }\n+\n+    if (promote_object || (_from_affiliation == ShenandoahRegionAffiliation::OLD_GENERATION)) {\n+      assert(_old_to_region != nullptr, \"_old_to_region should not be NULL when evacuating to OLD region\");\n@@ -528,1 +571,0 @@\n-\n@@ -530,0 +572,5 @@\n+\n+      \/\/ After full gc compaction, all regions have age 0.  Embed the region's age into the object's age in order to preserve\n+      \/\/ tenuring progress.\n+      _heap->increase_object_age(p, from_region_age + 1);\n+\n@@ -533,1 +580,0 @@\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFullGC.cpp","additions":50,"deletions":4,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"gc\/shenandoah\/shenandoahYoungGeneration.hpp\"\n@@ -63,1 +64,1 @@\n-    _heap(ShenandoahHeap::heap()),\n+     _heap(ShenandoahHeap::heap()),\n@@ -249,0 +250,86 @@\n+\n+\n+    if (heap->mode()->is_generational()) {\n+\n+      \/\/ During initialization and phase changes, it is more likely that fewer objects die young and old-gen\n+      \/\/ memory is not yet full (or is in the process of being replaced).  During these tiems especially, it\n+      \/\/ is beneficial to loan memory from old-gen to young-gen during the evacuation and update-refs phases\n+      \/\/ of execution.\n+\n+      \/\/  PromotionReserve for old generation: how much memory are we reserving to hold the results of\n+      \/\/     promoting young-gen objects that have reached tenure age?  This value is not \"critical\".  If we\n+      \/\/     underestimate, certain promotions will simply be deferred.  The basis of this estimate is\n+      \/\/     historical precedent.  Conservatively, budget this value to be twice the amount of memory\n+      \/\/     promoted in previous GC pass.  Whenever the amount promoted during previous GC is zero,\n+      \/\/     including initial passes before any objects have reached tenure age, use live memory within\n+      \/\/     young-gen memory divided by (ShenandoahTenureAge multiplied by InitialTenuringThreshold) as the\n+      \/\/     the very conservative value of this parameter.  Note that during initialization, there is\n+      \/\/     typically plentiful old-gen memory so it's ok to be conservative with the initial estimates\n+      \/\/     of this value.  But PromotionReserve can be no larger than available memory.  In summary, we\n+      \/\/     compute PromotionReserve as the smaller of:\n+      \/\/      1. old_gen->available\n+      \/\/      2. young_gen->capacity() * ShenandoahEvacReserve\n+      \/\/      3. (bytes promoted by previous promotion) * 2 if (bytes promoted by previous promotion) is not zero\n+      \/\/      4. if (bytes promoted by previous promotion) is zero, divide young_gen->used()\n+      \/\/         by (ShenandoahTenureAge * InitialTenuringThreshold)\n+      \/\/\n+      \/\/     We don't yet know how much live memory.  Inside choose_collection_set(), after it computes live memory,\n+      \/\/     the PromotionReserve may be further reduced.\n+      \/\/\n+      \/\/      5. live bytes in young-gen divided by (ShenandoahTenureAge * InitialTenuringThreshold\n+      \/\/         if the number of bytes promoted by previous promotion is zero\n+      \/\/\n+      ShenandoahGeneration* old_generation = heap->old_generation();\n+      ShenandoahYoungGeneration* young_generation = heap->young_generation();\n+      size_t promotion_reserve = old_generation->available();\n+\n+      size_t max_young_evacuation = (young_generation->soft_max_capacity() * ShenandoahOldEvacReserve) \/ 100;\n+      if (max_young_evacuation < promotion_reserve) {\n+        promotion_reserve = max_young_evacuation;\n+      }\n+\n+      size_t previously_promoted = heap->get_previous_promotion();\n+      if (previously_promoted == 0) {\n+        \/\/ Very conservatively, assume linear population decay (rather than more typical exponential) and assume all of\n+        \/\/ used is live.\n+        size_t proposed_reserve = young_generation->used() \/ (ShenandoahAgingCyclePeriod * InitialTenuringThreshold);\n+        if (promotion_reserve > proposed_reserve) {\n+          promotion_reserve = proposed_reserve;\n+        }\n+      } else if (previously_promoted * 2 < promotion_reserve) {\n+        promotion_reserve = previously_promoted * 2;\n+      }\n+\n+      heap->set_promotion_reserve(promotion_reserve);\n+      heap->capture_old_usage(old_generation->used());\n+\n+      \/\/  OldEvacuationReserve for old generation: how much memory are we reserving to hold the results of\n+      \/\/     evacuating old-gen heap regions?  In order to sustain a consistent pace of young-gen collections,\n+      \/\/     the goal is to maintain a consistent value for this parameter (when the candidate set is not\n+      \/\/     empty).  This value is the minimum of:\n+      \/\/       1. old_gen->available() - PromotionReserve\n+      \/\/       2. (young_gen->capacity() scaled by ShenandoahEvacReserve) scaled by ShenandoahOldEvacRatioPercent\n+\n+      \/\/ Don't reserve for old_evac any more than the memory that is available in old_gen.\n+      size_t old_evacuation_reserve = old_generation->available() - promotion_reserve;\n+\n+      \/\/ Make sure old evacuation is no more than ShenandoahOldEvacRatioPercent of the total evacuation budget.\n+      size_t max_total_evac = (young_generation->soft_max_capacity() * ShenandoahEvacReserve) \/ 100;\n+      size_t max_old_evac_portion = (max_total_evac * ShenandoahOldEvacRatioPercent) \/ 100;\n+\n+      if (old_evacuation_reserve > max_old_evac_portion) {\n+        old_evacuation_reserve = max_old_evac_portion;\n+      }\n+\n+      heap->set_old_evac_reserve(old_evacuation_reserve);\n+      heap->reset_old_evac_expended();\n+\n+      \/\/ Compute YoungEvacuationReserve after we prime the collection set with old-gen candidates.  This depends\n+      \/\/ on how much memory old-gen wants to evacuate.  This is done within _heuristics->choose_collection_set().\n+\n+      \/\/ There's no need to pass this information to ShenandoahFreeSet::rebuild().  The GC allocator automatically borrows\n+      \/\/ memory from mutator regions when necessary.\n+    }\n+\n+    \/\/ The heuristics may consult and\/or change the values of PromotionReserved, OldEvacuationReserved, and\n+    \/\/ YoungEvacuationReserved, all of which are represented in the shared ShenandoahHeap data structure.\n@@ -250,0 +337,17 @@\n+\n+    \/\/  EvacuationAllocationSupplement: This represents memory that can be allocated in excess of young_gen->available()\n+    \/\/     during evacuation and update-refs.  This memory can be temporarily borrowed from old-gen allotment, then\n+    \/\/     repaid at the end of update-refs from the recycled collection set.  After we have computed the collection set\n+    \/\/     based on the parameters established above, we can make additional calculates based on our knowledge of the\n+    \/\/     collection set to determine how much allocation we can allow during the evacuation and update-refs phases\n+    \/\/     of execution.  With full awareness of collection set, we can shrink the values of PromotionReserve,\n+    \/\/     OldEvacuationReserve, and YoungEvacuationReserve.  Then, we can compute EvacuationAllocationReserve as the\n+    \/\/     minimum of:\n+    \/\/       1. old_gen->available - (PromotionReserve + OldEvacuationReserve)\n+    \/\/       2. The replenishment budget (number of regions in collection set - the number of regions already\n+    \/\/          under lien for the YoungEvacuationReserve)\n+    \/\/\n+\n+    \/\/ The possibly revised values are also consulted by the ShenandoahPacer when it establishes pacing parameters\n+    \/\/ for evacuation and update-refs.\n+\n@@ -313,1 +417,1 @@\n-  _heuristics(nullptr) {\n+  _adjusted_capacity(soft_max_capacity), _heuristics(nullptr) {\n@@ -374,0 +478,14 @@\n+size_t ShenandoahGeneration::used_regions() const {\n+  return _affiliated_region_count;\n+}\n+\n+size_t ShenandoahGeneration::free_unaffiliated_regions() const {\n+  size_t result = soft_max_capacity() \/ ShenandoahHeapRegion::region_size_bytes();\n+  if (_affiliated_region_count > result) {\n+    result = 0;                 \/\/ If old-gen is loaning regions to young-gen, affiliated regions may exceed capacity temporarily.\n+  } else {\n+    result -= _affiliated_region_count;\n+  }\n+  return result;\n+}\n+\n@@ -383,0 +501,16 @@\n+\n+size_t ShenandoahGeneration::adjust_available(intptr_t adjustment) {\n+  _adjusted_capacity = soft_max_capacity() + adjustment;\n+  return _adjusted_capacity;\n+}\n+\n+size_t ShenandoahGeneration::unadjust_available() {\n+  _adjusted_capacity = soft_max_capacity();\n+  return _adjusted_capacity;\n+}\n+\n+size_t ShenandoahGeneration::adjusted_available() const {\n+  size_t in_use = used();\n+  size_t capacity = _adjusted_capacity;\n+  return in_use > capacity ? 0 : capacity - in_use;\n+}\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGeneration.cpp","additions":136,"deletions":2,"binary":false,"changes":138,"status":"modified"},{"patch":"@@ -56,0 +56,2 @@\n+  size_t _adjusted_capacity;\n+\n@@ -73,0 +75,1 @@\n+  virtual size_t used_regions() const;\n@@ -74,0 +77,1 @@\n+  virtual size_t free_unaffiliated_regions() const;\n@@ -77,0 +81,11 @@\n+  \/\/ During evacuation and update-refs, some memory may be shifted between generations.  In particular, memory\n+  \/\/ may be loaned by old-gen to young-gen based on the promise the loan will be promptly repaid from the memory reclaimed\n+  \/\/ when the current collection set is recycled.  The capacity adjustment also takes into consideration memory that is\n+  \/\/ set aside within each generation to hold the results of evacuation, but not promotion, into that region.  Promotions\n+  \/\/ into old-gen are bounded by adjusted_available() whereas evacuations into old-gen are pre-committed.\n+  virtual size_t adjusted_available() const;\n+\n+  \/\/ Both of following return new value of available\n+  virtual size_t adjust_available(intptr_t adjustment);\n+  virtual size_t unadjust_available();\n+\n@@ -146,2 +161,0 @@\n-\n-private:\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGeneration.hpp","additions":15,"deletions":2,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -505,0 +505,1 @@\n+  _evacuation_allowance(0),\n@@ -515,0 +516,8 @@\n+  _alloc_supplement_reserve(0),\n+  _promotion_reserve(0),\n+  _old_evac_reserve(0),\n+  _old_evac_expended(0),\n+  _young_evac_reserve(0),\n+  _young_evac_expended(0),\n+  _captured_old_usage(0),\n+  _previous_promotion(0),\n@@ -890,1 +899,1 @@\n-HeapWord* ShenandoahHeap::allocate_from_plab_slow(Thread* thread, size_t size) {\n+HeapWord* ShenandoahHeap::allocate_from_plab_slow(Thread* thread, size_t size, bool is_promotion) {\n@@ -924,0 +933,2 @@\n+  \/\/ allocate_new_plab resets plab_evacuated and plab_promoted and disables promotions if old-gen available is\n+  \/\/ less than the remaining evacuation need.\n@@ -945,0 +956,4 @@\n+\n+  if (is_promotion && !ShenandoahThreadLocalData::allow_plab_promotions(thread)) {\n+    return nullptr;\n+  }\n@@ -948,0 +963,4 @@\n+\/\/ TODO: It is probably most efficient to register all objects (both promotions and evacuations) that were allocated within\n+\/\/ this plab at the time we retire the plab.  A tight registration loop will run within both code and data caches.  This change\n+\/\/ would allow smaller and faster in-line implementation of alloc_from_plab().  Since plabs are aligned on card-table boundaries,\n+\/\/ this object registration loop can be performed without acquiring a lock.\n@@ -952,0 +971,4 @@\n+    Thread* thread = Thread::current();\n+    size_t evacuated = ShenandoahThreadLocalData::get_plab_evacuated(thread);\n+    \/\/ We don't enforce limits on get_plab_promoted(thread).  Promotion uses any memory not required for evacuation.\n+    expend_old_evac(evacuated);\n@@ -998,1 +1021,1 @@\n-  HeapWord* res = allocate_memory(req);\n+  HeapWord* res = allocate_memory(req, false);\n@@ -1011,1 +1034,1 @@\n-  HeapWord* res = allocate_memory(req);\n+  HeapWord* res = allocate_memory(req, false);\n@@ -1024,1 +1047,3 @@\n-  HeapWord* res = allocate_memory(req);\n+  \/\/ Note that allocate_memory() sets a thread-local flag to prohibit further promotions by this thread\n+  \/\/ if we are at risk of exceeding the old-gen evacuation budget.\n+  HeapWord* res = allocate_memory(req, false);\n@@ -1033,1 +1058,3 @@\n-HeapWord* ShenandoahHeap::allocate_memory(ShenandoahAllocRequest& req) {\n+\/\/ is_promotion is true iff this allocation is known for sure to hold the result of young-gen evacuation\n+\/\/ to old-gen.  plab allocates arre not known as such, since they may hold old-gen evacuations.\n+HeapWord* ShenandoahHeap::allocate_memory(ShenandoahAllocRequest& req, bool is_promotion) {\n@@ -1045,1 +1072,1 @@\n-      result = allocate_memory_under_lock(req, in_new_region);\n+      result = allocate_memory_under_lock(req, in_new_region, is_promotion);\n@@ -1063,1 +1090,1 @@\n-      result = allocate_memory_under_lock(req, in_new_region);\n+      result = allocate_memory_under_lock(req, in_new_region, is_promotion);\n@@ -1069,1 +1096,1 @@\n-      result = allocate_memory_under_lock(req, in_new_region);\n+      result = allocate_memory_under_lock(req, in_new_region, is_promotion);\n@@ -1074,1 +1101,1 @@\n-    result = allocate_memory_under_lock(req, in_new_region);\n+    result = allocate_memory_under_lock(req, in_new_region, is_promotion);\n@@ -1112,4 +1139,2 @@\n-HeapWord* ShenandoahHeap::allocate_memory_under_lock(ShenandoahAllocRequest& req, bool& in_new_region) {\n-  if (mode()->is_generational() && req.affiliation() == YOUNG_GENERATION && young_generation()->used() + req.size() >= young_generation()->max_capacity()) {\n-    return nullptr;\n-  }\n+HeapWord* ShenandoahHeap::allocate_memory_under_lock(ShenandoahAllocRequest& req, bool& in_new_region, bool is_promotion) {\n+  size_t requested_bytes = req.size() * HeapWordSize;\n@@ -1118,0 +1143,64 @@\n+  if (mode()->is_generational()) {\n+    if (req.affiliation() == YOUNG_GENERATION) {\n+      if (req.type() == ShenandoahAllocRequest::_alloc_gclab) {\n+        if (requested_bytes + get_young_evac_expended() > get_young_evac_reserve()) {\n+          \/\/ This should only happen if evacuation waste is too low.  Rejecting one thread's request for GCLAB does not\n+          \/\/ necessarily result in failure of the evacuation effort.  A different thread may be able to copy from-space object.\n+\n+          \/\/ TODO: Should we really fail here in the case that there is sufficient memory to allow us to allocate a gclab\n+          \/\/ beyond the young_evac_reserve?  Seems it would be better to take away from mutator allocation budget if this\n+          \/\/ prevents fall-back to full GC in order to recover from failed evacuation.\n+          return nullptr;\n+        }\n+        \/\/ else, there is sufficient memory to allocate this GCLAB so do nothing here.\n+      } else if (req.is_gc_alloc()) {\n+        \/\/ This is a shared alloc for purposes of evacuation.\n+        if (requested_bytes + get_young_evac_expended() > get_young_evac_reserve()) {\n+          \/\/ TODO: Should we really fail here in the case that there is sufficient memory to allow us to allocate a gclab\n+          \/\/ beyond the young_evac_reserve?  Seems it would be better to take away from mutator allocation budget if this\n+          \/\/ prevents fall-back to full GC in order to recover from failed evacuation.\n+          return nullptr;\n+        } else {\n+          \/\/ There is sufficient memory to allocate this shared evacuation object.\n+        }\n+      }  else if (requested_bytes >= young_generation()->adjusted_available()) {\n+        \/\/ We know this is not a GCLAB.  This must be a TLAB or a shared allocation.  Reject the allocation request if\n+        \/\/ exceeds established capacity limits.\n+        return nullptr;\n+      }\n+    } else {                    \/\/ reg.affiliation() == OLD_GENERATION\n+      assert(req.type() != ShenandoahAllocRequest::_alloc_gclab, \"GCLAB pertains only to young-gen memory\");\n+\n+      if (req.type() ==  ShenandoahAllocRequest::_alloc_plab) {\n+        \/\/ We've already retired this thread's previously exhausted PLAB and have accounted for how that PLAB's\n+        \/\/ memory was allotted.\n+        Thread* thread = Thread::current();\n+        ShenandoahThreadLocalData::reset_plab_evacuated(thread);\n+        ShenandoahThreadLocalData::reset_plab_promoted(thread);\n+\n+        \/\/ Conservatively, assume this entire PLAB will be used for promotion.  Act as if we need to serve the\n+        \/\/ rest of evacuation need from as-yet unallocated old-gen memory.\n+        size_t remaining_evac_need = get_old_evac_reserve() - get_old_evac_expended();\n+        size_t evac_available = old_generation()->adjusted_available() - requested_bytes;\n+        if (remaining_evac_need >= evac_available) {\n+          \/\/ Disable promotions within this thread because the entirety of this PLAB must be available to hold\n+          \/\/ old-gen evacuations.\n+          ShenandoahThreadLocalData::disable_plab_promotions(thread);\n+        } else {\n+          ShenandoahThreadLocalData::enable_plab_promotions(thread);\n+        }\n+      } else if (is_promotion) {\n+        \/\/ This is a shared alloc for promotion\n+        Thread* thread = Thread::current();\n+        size_t remaining_evac_need = get_old_evac_reserve() - get_old_evac_expended();\n+        size_t evac_available = old_generation()->adjusted_available() - requested_bytes;\n+        if (remaining_evac_need >= evac_available) {\n+          return nullptr;       \/\/ We need to reserve the remaining memory for evacuation so defer the promotion\n+        }\n+        \/\/ Else, we'll allow the allocation to proceed.  (Since we hold heap lock, the tested condition remains true.)\n+      } else {\n+        \/\/ This is a shared allocation for evacuation.  Memory has already been reserved for this purpose.\n+      }\n+    }\n+  }\n+\n@@ -1119,19 +1208,21 @@\n-  if (result != NULL && req.affiliation() == ShenandoahRegionAffiliation::OLD_GENERATION) {\n-    \/\/ Register the newly allocated object while we're holding the global lock since there's no synchronization\n-    \/\/ built in to the implementation of register_object().  There are potential races when multiple independent\n-    \/\/ threads are allocating objects, some of which might span the same card region.  For example, consider\n-    \/\/ a card table's memory region within which three objects are being allocated by three different threads:\n-    \/\/\n-    \/\/ objects being \"concurrently\" allocated:\n-    \/\/    [-----a------][-----b-----][--------------c------------------]\n-    \/\/            [---- card table memory range --------------]\n-    \/\/\n-    \/\/ Before any objects are allocated, this card's memory range holds no objects.  Note that:\n-    \/\/   allocation of object a wants to set the has-object, first-start, and last-start attributes of the preceding card region.\n-    \/\/   allocation of object b wants to set the has-object, first-start, and last-start attributes of this card region.\n-    \/\/   allocation of object c also wants to set the has-object, first-start, and last-start attributes of this card region.\n-    \/\/\n-    \/\/ The thread allocating b and the thread allocating c can \"race\" in various ways, resulting in confusion, such as last-start\n-    \/\/ representing object b while first-start represents object c.  This is why we need to require all register_object()\n-    \/\/ invocations to be \"mutually exclusive\" with respect to each card's memory range.\n-    ShenandoahHeap::heap()->card_scan()->register_object(result);\n+  if (result != NULL) {\n+    if (req.affiliation() == ShenandoahRegionAffiliation::OLD_GENERATION) {\n+      \/\/ Register the newly allocated object while we're holding the global lock since there's no synchronization\n+      \/\/ built in to the implementation of register_object().  There are potential races when multiple independent\n+      \/\/ threads are allocating objects, some of which might span the same card region.  For example, consider\n+      \/\/ a card table's memory region within which three objects are being allocated by three different threads:\n+      \/\/\n+      \/\/ objects being \"concurrently\" allocated:\n+      \/\/    [-----a------][-----b-----][--------------c------------------]\n+      \/\/            [---- card table memory range --------------]\n+      \/\/\n+      \/\/ Before any objects are allocated, this card's memory range holds no objects.  Note that:\n+      \/\/   allocation of object a wants to set the has-object, first-start, and last-start attributes of the preceding card region.\n+      \/\/   allocation of object b wants to set the has-object, first-start, and last-start attributes of this card region.\n+      \/\/   allocation of object c also wants to set the has-object, first-start, and last-start attributes of this card region.\n+      \/\/\n+      \/\/ The thread allocating b and the thread allocating c can \"race\" in various ways, resulting in confusion, such as last-start\n+      \/\/ representing object b while first-start represents object c.  This is why we need to require all register_object()\n+      \/\/ invocations to be \"mutually exclusive\" with respect to each card's memory range.\n+      ShenandoahHeap::heap()->card_scan()->register_object(result);\n+    }\n@@ -1145,1 +1236,1 @@\n-  return allocate_memory(req);\n+  return allocate_memory(req, false);\n@@ -1388,1 +1479,1 @@\n-    ShenandoahHeap::heap()->retire_plab(gclab);\n+    gclab->retire();\n@@ -2049,0 +2140,3 @@\n+    if (cause == GCCause::_shenandoah_upgrade_to_full_gc) {\n+      _upgraded_to_full = true;\n+    }\n@@ -2440,0 +2534,1 @@\n+  ShenandoahMarkingContext* _ctx;\n@@ -2441,0 +2536,1 @@\n+  bool _is_generational;\n@@ -2443,1 +2539,3 @@\n-  ShenandoahFinalUpdateRefsUpdateRegionStateClosure() : _lock(ShenandoahHeap::heap()->lock()) {}\n+  ShenandoahFinalUpdateRefsUpdateRegionStateClosure(\n+    ShenandoahMarkingContext* ctx) : _ctx(ctx), _lock(ShenandoahHeap::heap()->lock()),\n+                                     _is_generational(ShenandoahHeap::heap()->mode()->is_generational()) { }\n@@ -2446,0 +2544,21 @@\n+\n+    \/\/ Maintenance of region age must follow evacuation in order to account for evacuation allocations within survivor\n+    \/\/ regions.  We consult region age during the subsequent evacuation to determine whether certain objects need to\n+    \/\/ be promoted.\n+    if (_is_generational && r->is_young()) {\n+      HeapWord *tams = _ctx->top_at_mark_start(r);\n+      HeapWord *top = r->top();\n+\n+      \/\/ Allocations move the watermark when top moves.  However compacting\n+      \/\/ objects will sometimes lower top beneath the watermark, after which,\n+      \/\/ attempts to read the watermark will assert out (watermark should not be\n+      \/\/ higher than top).\n+      if (top > tams) {\n+        \/\/ There have been allocations in this region since the start of the cycle.\n+        \/\/ Any objects new to this region must not assimilate elevated age.\n+        r->reset_age();\n+      } else if (ShenandoahHeap::heap()->is_aging_cycle()) {\n+        r->increment_age();\n+      }\n+    }\n+\n@@ -2448,1 +2567,0 @@\n-\n@@ -2475,1 +2593,1 @@\n-    ShenandoahFinalUpdateRefsUpdateRegionStateClosure cl;\n+    ShenandoahFinalUpdateRefsUpdateRegionStateClosure cl (young_generation()->complete_marking_context());\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":155,"deletions":37,"binary":false,"changes":192,"status":"modified"},{"patch":"@@ -153,1 +153,2 @@\n-  bool _mixed_evac;             \/\/ true iff most recent evac included at least one old-gen HeapRegion\n+\n+  bool _mixed_evac;                      \/\/ true iff most recent evac included at least one old-gen HeapRegion\n@@ -156,0 +157,2 @@\n+  size_t _evacuation_allowance;          \/\/ amount by which young-gen usage may temporarily exceed young-gen capacity\n+\n@@ -338,0 +341,56 @@\n+  \/\/ _alloc_supplement_reserve is a supplemental budget for new_memory allocations.  During evacuation and update-references,\n+  \/\/ mutator allocation requests are \"authorized\" iff young_gen->available() plus _alloc_supplement_reserve minus\n+  \/\/ _young_evac_reserve is greater than request size.  The values of _alloc_supplement_reserve and _young_evac_reserve\n+  \/\/ are zero except during evacuation and update-reference phases of GC.  Both of these values are established at\n+  \/\/ the start of evacuation, and they remain constant throughout the duration of these two phases of GC.  Since these\n+  \/\/ two values are constant throughout each GC phases, we introduce a new service into ShenandoahGeneration.  This service\n+  \/\/ provides adjusted_available() based on an adjusted capacity.  At the start of evacuation, we adjust young capacity by\n+  \/\/ adding the amount to be borrowed from old-gen and subtracting the _young_evac_reserve, we adjust old capacity by\n+  \/\/ subtracting the amount to be loaned to young-gen.  At the end of update-refs, we unadjust the capacity of each generation,\n+  \/\/ and add _young_evac_expended to young-gen used.\n+  \/\/\n+  \/\/ We always use adjusted capacities to determine permission to allocate within young and to promote into old.  Note\n+  \/\/ that adjusted capacities equal traditional capacities except during evacuation and update refs.\n+  \/\/\n+  \/\/ During evacuation, we assure that _young_evac_expended does not exceed _young_evac_reserve and that _old_evac_expended\n+  \/\/ does not exceed _old_evac_reserve.  GCLAB allocations do not immediately affect used within the young generation\n+  \/\/ since the adjusted capacity already accounts for the entire evacuation reserve.  Each GCLAB allocations increments\n+  \/\/ _young_evac_expended rather than incrementing the affiliated generation's used value.\n+  \/\/\n+  \/\/ At the end of update references, we perform the following bookkeeping activities:\n+  \/\/\n+  \/\/ 1. Unadjust the capacity within young-gen and old-gen to undo the effects of borrowing memory from old-gen.  Note that\n+  \/\/    the entirety of the collection set is now available, so allocation capacity naturally increase at this time.\n+  \/\/ 2. Increase young_gen->used() by _young_evac_expended.  This represents memory consumed by evacutions from young-gen.\n+  \/\/ 3. Clear (reset to zero) _alloc_supplement_reserve, _young_evac_reserve, _old_evac_reserve, and _promotion_reserve\n+  \/\/\n+  \/\/ _young_evac_reserve and _old_evac_reserve are only non-zero during evacuation and update-references.\n+  \/\/\n+  \/\/ Allocation of young GCLABs assures that _young_evac_expended + request-size < _young_evac_reserved.  If the allocation\n+  \/\/  is authorized, increment _young_evac_expended by request size.  This allocation ignores young_gen->available().\n+  \/\/\n+  \/\/ Allocation of old GCLABs assures that _old_evac_expended + request-size < _old_evac_reserved.  If the allocation\n+  \/\/  is authorized, increment _old_evac_expended by request size.  This allocation ignores old_gen->available().\n+  \/\/\n+  \/\/ Note that the typical total expenditure on evacuation is less than the associated evacuation reserve because we generally\n+  \/\/ reserve ShenandoahEvacWaste (> 1.0) times the anticipated evacuation need.  In the case that there is an excessive amount\n+  \/\/ of waste, it may be that one thread fails to grab a new GCLAB, this does not necessarily doom the associated evacuation\n+  \/\/ effort.  If this happens, the requesting thread blocks until some other thread manages to evacuate the offending object.\n+  \/\/ Only after \"all\" threads fail to evacuate an object do we consider the evacuation effort to have failed.\n+\n+  intptr_t _alloc_supplement_reserve;  \/\/ Bytes reserved for young allocations during evac and update refs\n+  size_t _promotion_reserve;           \/\/ Bytes reserved within old-gen to hold the results of promotion\n+\n+\n+  size_t _old_evac_reserve;            \/\/ Bytes reserved within old-gen to hold evacuated objects from old-gen collection set\n+  size_t _old_evac_expended;           \/\/ Bytes of old-gen memory expended on old-gen evacuations\n+\n+  size_t _young_evac_reserve;          \/\/ Bytes reserved within young-gen to hold evacuated objects from young-gen collection set\n+  size_t _young_evac_expended;         \/\/ Bytes old-gen memory has been expended on young-gen evacuations\n+\n+  size_t _captured_old_usage;          \/\/ What was old usage (bytes) when last captured?\n+\n+  size_t _previous_promotion;          \/\/ Bytes promoted during previous evacuation\n+\n+  bool _upgraded_to_full;\n+\n@@ -341,0 +400,2 @@\n+\n+\n@@ -375,0 +436,32 @@\n+  inline bool upgraded_to_full() { return _upgraded_to_full; }\n+  inline void start_conc_gc() { _upgraded_to_full = false; }\n+  inline void record_upgrade_to_full() { _upgraded_to_full = true; }\n+\n+  inline size_t capture_old_usage(size_t usage);\n+  inline void set_previous_promotion(size_t promoted_bytes);\n+  inline size_t get_previous_promotion() const;\n+\n+  \/\/ Returns previous value\n+  inline size_t set_promotion_reserve(size_t new_val);\n+  inline size_t get_promotion_reserve() const;\n+\n+  \/\/ Returns previous value\n+  inline size_t set_old_evac_reserve(size_t new_val);\n+  inline size_t get_old_evac_reserve() const;\n+\n+  inline void reset_old_evac_expended();\n+  inline size_t expend_old_evac(size_t increment);\n+  inline size_t get_old_evac_expended() const;\n+\n+  \/\/ Returns previous value\n+  inline size_t set_young_evac_reserve(size_t new_val);\n+  inline size_t get_young_evac_reserve() const;\n+\n+  inline void reset_young_evac_expended();\n+  inline size_t expend_young_evac(size_t increment);\n+  inline size_t get_young_evac_expended() const;\n+\n+  \/\/ Returns previous value.  This is a signed value because it is the amount borrowed minus the amount reserved for\n+  \/\/ young-gen evacuation.  In case we cannot borrow much, this value might be negative.\n+  inline intptr_t set_alloc_supplement_reserve(intptr_t new_val);\n+  inline intptr_t get_alloc_supplement_reserve() const;\n@@ -594,1 +687,1 @@\n-  HeapWord* allocate_memory_under_lock(ShenandoahAllocRequest& request, bool& in_new_region);\n+  HeapWord* allocate_memory_under_lock(ShenandoahAllocRequest& request, bool& in_new_region, bool is_promotion);\n@@ -600,2 +693,2 @@\n-  inline HeapWord* allocate_from_plab(Thread* thread, size_t size);\n-  HeapWord* allocate_from_plab_slow(Thread* thread, size_t size);\n+  inline HeapWord* allocate_from_plab(Thread* thread, size_t size, bool is_promotion);\n+  HeapWord* allocate_from_plab_slow(Thread* thread, size_t size, bool is_promotion);\n@@ -605,1 +698,1 @@\n-  HeapWord* allocate_memory(ShenandoahAllocRequest& request);\n+  HeapWord* allocate_memory(ShenandoahAllocRequest& request, bool is_promotion);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.hpp","additions":98,"deletions":5,"binary":false,"changes":103,"status":"modified"},{"patch":"@@ -300,1 +300,1 @@\n-inline HeapWord* ShenandoahHeap::allocate_from_plab(Thread* thread, size_t size) {\n+inline HeapWord* ShenandoahHeap::allocate_from_plab(Thread* thread, size_t size, bool is_promotion) {\n@@ -304,1 +304,3 @@\n-  if (plab == NULL) {\n+  if (is_promotion && !ShenandoahThreadLocalData::allow_plab_promotions(thread)) {\n+    return NULL;\n+  } else if (plab == NULL) {\n@@ -312,1 +314,6 @@\n-    obj = allocate_from_plab_slow(thread, size);\n+    obj = allocate_from_plab_slow(thread, size, is_promotion);\n+  }\n+  if (is_promotion) {\n+    ShenandoahThreadLocalData::add_to_plab_promoted(thread, size * HeapWordSize);\n+  } else {\n+    ShenandoahThreadLocalData::add_to_plab_evacuated(thread, size * HeapWordSize);\n@@ -341,1 +348,1 @@\n-    } else if (mark.age() >= InitialTenuringThreshold) {\n+    } else if (r->age() + mark.age() >= InitialTenuringThreshold) {\n@@ -346,0 +353,1 @@\n+      \/\/ If we failed to promote this aged object, we'll fall through to code below and evacuat to young-gen.\n@@ -353,1 +361,2 @@\n-inline oop ShenandoahHeap::try_evacuate_object(oop p, Thread* thread, ShenandoahHeapRegion* from_region, ShenandoahRegionAffiliation target_gen) {\n+inline oop ShenandoahHeap::try_evacuate_object(oop p, Thread* thread, ShenandoahHeapRegion* from_region,\n+                                               ShenandoahRegionAffiliation target_gen) {\n@@ -357,0 +366,1 @@\n+  bool is_promotion = (target_gen == OLD_GENERATION) && from_region->is_young();\n@@ -368,0 +378,7 @@\n+           if ((copy == nullptr) && (size < ShenandoahThreadLocalData::gclab_size(thread))) {\n+             \/\/ GCLAB allocation failed because we are bumping up against the limit on young evacuation reserve.  Try resetting\n+             \/\/ the desired GCLAB size and retry GCLAB allocation to avoid cascading of shared memory allocations.\n+             ShenandoahThreadLocalData::set_gclab_size(thread, PLAB::min_size());\n+             copy = allocate_from_gclab(thread, size);\n+             \/\/ If we still get nullptr, we'll try a shared allocation below.\n+           }\n@@ -372,1 +389,8 @@\n-             copy = allocate_from_plab(thread, size);\n+             copy = allocate_from_plab(thread, size, is_promotion);\n+             if ((copy == nullptr) && (size < ShenandoahThreadLocalData::plab_size(thread))) {\n+               \/\/ PLAB allocation failed because we are bumping up against the limit on old evacuation reserve.  Try resetting\n+               \/\/ the desired PLAB size and retry PLAB allocation to avoid cascading of shared memory allocations.\n+               ShenandoahThreadLocalData::set_plab_size(thread, PLAB::min_size());\n+               copy = allocate_from_plab(thread, size, is_promotion);\n+               \/\/ If we still get nullptr, we'll try a shared allocation below.\n+             }\n@@ -382,0 +406,1 @@\n+\n@@ -383,0 +408,1 @@\n+      \/\/ If we failed to allocated in LAB, we'll try a shared allocation.\n@@ -384,1 +410,1 @@\n-      copy = allocate_memory(req);\n+      copy = allocate_memory(req, is_promotion);\n@@ -451,0 +477,5 @@\n+            if (is_promotion) {\n+              ShenandoahThreadLocalData::subtract_from_plab_promoted(thread, size * HeapWordSize);\n+            } else {\n+              ShenandoahThreadLocalData::subtract_from_plab_evacuated(thread, size * HeapWordSize);\n+            }\n@@ -564,0 +595,81 @@\n+inline size_t ShenandoahHeap::set_promotion_reserve(size_t new_val) {\n+  size_t orig = _promotion_reserve;\n+  _promotion_reserve = new_val;\n+  return orig;\n+}\n+\n+inline size_t ShenandoahHeap::get_promotion_reserve() const {\n+  return _promotion_reserve;\n+}\n+\n+\/\/ returns previous value\n+size_t ShenandoahHeap::capture_old_usage(size_t old_usage) {\n+  size_t previous_value = _captured_old_usage;\n+  _captured_old_usage = old_usage;\n+  return previous_value;\n+}\n+\n+void ShenandoahHeap::set_previous_promotion(size_t promoted_bytes) {\n+  _previous_promotion = promoted_bytes;\n+}\n+\n+size_t ShenandoahHeap::get_previous_promotion() const {\n+  return _previous_promotion;\n+}\n+\n+inline size_t ShenandoahHeap::set_old_evac_reserve(size_t new_val) {\n+  size_t orig = _old_evac_reserve;\n+  _old_evac_reserve = new_val;\n+  return orig;\n+}\n+\n+inline size_t ShenandoahHeap::get_old_evac_reserve() const {\n+  return _old_evac_reserve;\n+}\n+\n+inline void ShenandoahHeap::reset_old_evac_expended() {\n+  _old_evac_expended = 0;\n+}\n+\n+inline size_t ShenandoahHeap::expend_old_evac(size_t increment) {\n+  _old_evac_expended += increment;\n+  return _old_evac_expended;\n+}\n+\n+inline size_t ShenandoahHeap::get_old_evac_expended() const {\n+  return _old_evac_expended;\n+}\n+\n+inline size_t ShenandoahHeap::set_young_evac_reserve(size_t new_val) {\n+  size_t orig = _young_evac_reserve;\n+  _young_evac_reserve = new_val;\n+  return orig;\n+}\n+\n+inline size_t ShenandoahHeap::get_young_evac_reserve() const {\n+  return _young_evac_reserve;\n+}\n+\n+inline void ShenandoahHeap::reset_young_evac_expended() {\n+  _young_evac_expended = 0;\n+}\n+\n+inline size_t ShenandoahHeap::expend_young_evac(size_t increment) {\n+  _young_evac_expended += increment;\n+  return _young_evac_expended;\n+}\n+\n+inline size_t ShenandoahHeap::get_young_evac_expended() const {\n+  return _young_evac_expended;\n+}\n+\n+inline intptr_t ShenandoahHeap::set_alloc_supplement_reserve(intptr_t new_val) {\n+  intptr_t orig = _alloc_supplement_reserve;\n+  _alloc_supplement_reserve = new_val;\n+  return orig;\n+}\n+\n+inline intptr_t ShenandoahHeap::get_alloc_supplement_reserve() const {\n+  return _alloc_supplement_reserve;\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.inline.hpp","additions":119,"deletions":7,"binary":false,"changes":126,"status":"modified"},{"patch":"@@ -253,1 +253,1 @@\n-  reset_age();\n+  \/\/ Leave age untouched.  We need to consult the age when we are deciding whether to promote evacuated objects.\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeapRegion.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -440,1 +440,2 @@\n-  void increment_age() { if (_age < markWord::max_age) { _age++; } }\n+  void increment_age() { _age++; }\n+  void decrement_age() { if (_age-- == 0) { _age = 0; } }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeapRegion.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -36,1 +36,2 @@\n-\/\/ size is in words.\n+\/\/ size is in words.  It is assumed that this->is_old().  A pad object is allocated, filled, and registered\n+\/\/ if necessary to assure the new allocation is properly aligned.\n@@ -40,0 +41,1 @@\n+  assert(is_old(), \"aligned allocations are only taken from OLD regions to support PLABs\");\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeapRegion.inline.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -63,15 +63,0 @@\n-    if (ShenandoahHeap::heap()->mode()->is_generational()) {\n-      \/\/ Allocations move the watermark when top moves, however compacting\n-      \/\/ objects will sometimes lower top beneath the watermark, after which,\n-      \/\/ attempts to read the watermark will assert out (watermark should not be\n-      \/\/ higher than top). The right way to check for new allocations is to compare\n-      \/\/ top with the TAMS as is done earlier in this function.\n-      if (top > tams) {\n-        \/\/ There have been allocations in this region since the start of the cycle.\n-        \/\/ Any objects new to this region must not assimilate elevated age.\n-        r->reset_age();\n-      } else if (ShenandoahHeap::heap()->is_aging_cycle()) {\n-        r->increment_age();\n-      }\n-    }\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMarkClosures.cpp","additions":0,"deletions":15,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -196,1 +196,1 @@\n-  vmop_entry_final_roots();\n+  vmop_entry_final_roots(false);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahOldGC.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -47,0 +47,1 @@\n+  bool                    _plab_allows_promotion; \/\/ If false, no more promotion by this thread during this evacuation phase.\n@@ -61,0 +62,3 @@\n+  size_t _plab_evacuated;\n+  size_t _plab_promoted;\n+\n@@ -74,0 +78,2 @@\n+    _plab_evacuated(0),\n+    _plab_promoted(0),\n@@ -88,0 +94,1 @@\n+      ShenandoahHeap::heap()->retire_plab(_plab);\n@@ -165,0 +172,44 @@\n+  static void enable_plab_promotions(Thread* thread) {\n+    data(thread)->_plab_allows_promotion = true;\n+  }\n+\n+  static void disable_plab_promotions(Thread* thread) {\n+    data(thread)->_plab_allows_promotion = false;\n+  }\n+\n+  static bool allow_plab_promotions(Thread* thread) {\n+    return data(thread)->_plab_allows_promotion;\n+  }\n+\n+  static void reset_plab_evacuated(Thread* thread) {\n+    data(thread)->_plab_evacuated = 0;\n+  }\n+\n+  static void add_to_plab_evacuated(Thread* thread, size_t increment) {\n+    data(thread)->_plab_evacuated += increment;\n+  }\n+\n+  static void subtract_from_plab_evacuated(Thread* thread, size_t increment) {\n+    data(thread)->_plab_evacuated -= increment;\n+  }\n+\n+  static size_t get_plab_evacuated(Thread* thread) {\n+    return data(thread)->_plab_evacuated;\n+  }\n+\n+  static void reset_plab_promoted(Thread* thread) {\n+    data(thread)->_plab_promoted = 0;\n+  }\n+\n+  static void add_to_plab_promoted(Thread* thread, size_t increment) {\n+    data(thread)->_plab_promoted += increment;\n+  }\n+\n+  static void subtract_from_plab_promoted(Thread* thread, size_t increment) {\n+    data(thread)->_plab_promoted -= increment;\n+  }\n+\n+  static size_t get_plab_promoted(Thread* thread) {\n+    return data(thread)->_plab_promoted;\n+  }\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahThreadLocalData.hpp","additions":51,"deletions":0,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+#include \"gc\/shenandoah\/shenandoahYoungGeneration.hpp\"\n@@ -71,0 +72,1 @@\n+\n@@ -72,0 +74,6 @@\n+  if (_heap->mode()->is_generational() &&\n+      ((_generation->generation_mode() == GLOBAL) || _heap->upgraded_to_full())) {\n+    \/\/ If we just completed a GLOBAL GC, claim credit for completion of young-gen and old-gen GC as well\n+    _heap->young_generation()->heuristics()->record_cycle_end();\n+    _heap->old_generation()->heuristics()->record_cycle_end();\n+  }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahUtils.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -82,0 +82,18 @@\n+  if (_incr_region_ages) {\n+    \/\/ TODO: Do we even care about this?  Do we want to parallelize it?\n+    ShenandoahHeap* heap = ShenandoahHeap::heap();\n+    ShenandoahMarkingContext* ctx = heap->complete_marking_context();\n+\n+    for (size_t i = 0; i < heap->num_regions(); i++) {\n+      ShenandoahHeapRegion *r = heap->get_region(i);\n+      if (r->is_active() && r->is_young()) {\n+        HeapWord* tams = ctx->top_at_mark_start(r);\n+        HeapWord* top = r->top();\n+        if (top > tams) {\n+          r->reset_age();\n+        } else {\n+          r->increment_age();\n+        }\n+      }\n+    }\n+  }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahVMOperations.cpp","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -137,0 +137,1 @@\n+  bool _incr_region_ages;\n@@ -138,1 +139,1 @@\n-  VM_ShenandoahFinalRoots(ShenandoahConcurrentGC* gc) :\n+  VM_ShenandoahFinalRoots(ShenandoahConcurrentGC* gc, bool incr_region_ages) :\n@@ -140,1 +141,1 @@\n-    _gc(gc) {};\n+    _gc(gc), _incr_region_ages(incr_region_ages) {};\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahVMOperations.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -391,1 +391,11 @@\n-    guarantee(stats.used() == generation->used(),\n+    size_t generation_used;\n+    if (generation->generation_mode() == YOUNG) {\n+      \/\/ young_evac_expended is \"usually zero\".  If it is non-zero, this means we are doing evacuation or updating references\n+      \/\/ and young-gen memory that holds the results of evacuation is being temporarily hidden from the usage accounting,\n+      \/\/ so we add it back in here to make verification happy.\n+      generation_used = generation->used() + ShenandoahHeap::heap()->get_young_evac_expended();\n+    } else {\n+      generation_used = generation->used();\n+    }\n+\n+    guarantee(stats.used() == generation_used,\n@@ -394,1 +404,1 @@\n-              byte_size_in_proper_unit(generation->used()), proper_unit_for_byte_size(generation->used()),\n+              byte_size_in_proper_unit(generation_used), proper_unit_for_byte_size(generation_used),\n@@ -777,0 +787,1 @@\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahVerifier.cpp","additions":13,"deletions":2,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -85,0 +85,7 @@\n+\n+ShenandoahHeuristics* ShenandoahYoungGeneration::initialize_heuristics(ShenandoahMode* gc_mode) {\n+  _heuristics = gc_mode->initialize_heuristics(this);\n+  _heuristics->set_guaranteed_gc_interval(ShenandoahGuaranteedYoungGCInterval);\n+  confirm_heuristics_mode();\n+  return _heuristics;\n+}\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahYoungGeneration.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -57,0 +57,3 @@\n+  virtual ShenandoahHeuristics* initialize_heuristics(ShenandoahMode* gc_mode) override;\n+\n+protected:\n@@ -58,0 +61,1 @@\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahYoungGeneration.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -105,4 +105,6 @@\n-          \"How much heap should be free before some heuristics trigger the \"\\\n-          \"initial (learning) cycles. Affects cycle frequency on startup \"  \\\n-          \"and after drastic state changes, e.g. after degenerated\/full \"   \\\n-          \"GC cycles. In percents of (soft) max heap size.\")                \\\n+          \"When less than this amount of memory is free within the\"         \\\n+          \"heap or generation, trigger a learning cycle if we are \"         \\\n+          \"in learning mode.  Learning mode happens during initialization \" \\\n+          \"and following a drastic state change, such as following a \"      \\\n+          \"degenerated or Full GC cycle.  In percents of soft max \"         \\\n+          \"heap size.\")                                                     \\\n@@ -183,0 +185,5 @@\n+  product(uintx, ShenandoahGuaranteedYoungGCInterval, 5*60*1000,  EXPERIMENTAL,  \\\n+          \"Run a collection of the young generation at least this often. \"    \\\n+          \"Heuristics may trigger collections more frequently. Time is in \" \\\n+          \"milliseconds. Setting this to 0 disables the feature.\")          \\\n+                                                                            \\\n@@ -258,4 +265,12 @@\n-          \"How much of heap to reserve for evacuations. Larger values make \"\\\n-          \"GC evacuate more live objects on every cycle, while leaving \"    \\\n-          \"less headroom for application to allocate in. In percents of \"   \\\n-          \"total heap size.\")                                               \\\n+          \"How much of (young-generation) heap to reserve for \"             \\\n+          \"(young-generation) evacuations.  Larger values allow GC to \"     \\\n+          \"evacuate more live objects on every cycle, while leaving \"       \\\n+          \"less headroom for application to allocate while GC is \"          \\\n+          \"evacuating and updating references. This parameter is \"          \\\n+          \"consulted at the of marking, before selecting the collection \"   \\\n+          \"set.  If available memory at this time is smaller than the \"     \\\n+          \"indicated reserve, the bound on collection set size is \"         \\\n+          \"adjusted downward.  The size of a generational mixed \"           \\\n+          \"evacuation collection set (comprised of both young and old \"     \\\n+          \"regions) is also bounded by this parameter.  In percents of \"    \\\n+          \"total (young-generation) heap size.\")                            \\\n@@ -268,1 +283,4 @@\n-          \"GC cycle.\")                                                      \\\n+          \"GC cycle.  Smaller values increase the risk of evacuation \"      \\\n+          \"failures, which will trigger stop-the-world Full GC passes.  \"   \\\n+          \"A minimum value of 1.6 is recommended for Generational \"         \\\n+          \"mode of Shenandoah.\")                                            \\\n@@ -277,4 +295,12 @@\n-  product(double, ShenandoahOldEvacReserve, 5.0, EXPERIMENTAL,              \\\n-          \"How much of old generation to withhold from evacuations. \"       \\\n-           \"Larger values will result in fewer live objects being \"         \\\n-           \"evacuated in the old generation.\")                              \\\n+  product(uintx, ShenandoahOldEvacReserve, 2, EXPERIMENTAL,                 \\\n+          \"How much of old-generation heap to reserve for old-generation \"  \\\n+          \"evacuations.  Larger values allow GC to evacuate more live \"     \\\n+          \"old-generation objects on every cycle, while potentially \"       \\\n+          \"creating greater impact on the cadence at which the young- \"     \\\n+          \"generation allocation pool is replenished.  During mixed \"       \\\n+          \"evacuations, the bound on amount of old-generation heap \"        \\\n+          \"regions included in the collecdtion set is the smaller \"         \\\n+          \"of the quantities specified by this parameter and the \"          \\\n+          \"size of ShenandoahEvacReserve as adjusted by the value of \"      \\\n+          \"ShenandoahOldEvacRatioPercent.  In percents of total \"           \\\n+          \"old-generation heap size.\")                                      \\\n@@ -283,0 +309,19 @@\n+  product(uintx, ShenandoahOldEvacRatioPercent, 12, EXPERIMENTAL,           \\\n+          \"The maximum proportion of evacuation from old-gen memory, as \"   \\\n+          \"a percent ratio.  The default value 12 denotes that no more \"    \\\n+          \"than one eighth (12%) of the collection set evacuation \"         \\\n+          \"workload may be comprised of old-gen heap regions.  A larger \"   \\\n+          \"value allows a smaller number of mixed evacuations to process \"  \\\n+          \"the entire list of old-gen collection candidates at the cost \"   \\\n+          \"of an increased disruption of the normal cadence of young-gen \"  \\\n+          \"collections.  A value of 100 allows a mixed evacuation to \"      \\\n+          \"focus entirely on old-gen memory, allowing no young-gen \"        \\\n+          \"regions to be collected, likely resulting in subsequent \"        \\\n+          \"allocation failures because the allocation pool is not \"         \\\n+          \"replenished.  A value of 0 allows a mixed evacuation to\"         \\\n+          \"focus entirely on young-gen memory, allowing no old-gen \"        \\\n+          \"regions to be collected, likely resulting in subsequent \"        \\\n+          \"promotion failures and triggering of stop-the-world full GC \"    \\\n+          \"events.\")                                                        \\\n+          range(0,100)                                                      \\\n+                                                                            \\\n@@ -408,1 +453,1 @@\n-  product(uintx, ShenandoahTenuredRegionUsageBias, 192, EXPERIMENTAL,       \\\n+  product(uintx, ShenandoahTenuredRegionUsageBias, 16, EXPERIMENTAL,        \\\n@@ -413,5 +458,4 @@\n-          \"be treated as if their contained garbage is the actual \"         \\\n-          \"contained garbage multiplied by \"                                \\\n-          \"(ShenandoahTenuredRegionUsageBias \/ 128 (e.g. 150% for the \"     \\\n-          \"default value) as many times as the region's age meets or \"      \\\n-          \"exceeds the tenure age.  For example, if tenure age is 7, \"      \\\n+          \"be treated as if their contained garbage is the contained \"      \\\n+          \"garbage multiplied by ShenandoahTenuredRegionUsageBias as \"      \\\n+          \"many times as the age of the region meets or exceeds \"           \\\n+          \"tenure age.  For example, if tenure age is 7, \"                  \\\n@@ -419,1 +463,1 @@\n-          \"192, and the region is 12.5% garbage, this region \"              \\\n+          \"16, and the region is 12.5% garbage, this region \"               \\\n@@ -421,3 +465,17 @@\n-          \"1\/8 * 27\/8 = 42.2% when comparing this region to untenured \"     \\\n-          \"regions.\")                                                       \\\n-          range(128, 256)                                                   \\\n+          \"12.5% * 16 * 16 * 16 = 51,200% when comparing this region \"      \\\n+          \" to untenured regions.\")                                         \\\n+          range(1,128)                                                      \\\n+                                                                            \\\n+  product(uintx, ShenandoahBorrowPercent, 30, EXPERIMENTAL,                 \\\n+          \"During evacuation and reference updating in generational \"       \\\n+          \"mode, new allocations are allowed to borrow from old-gen \"       \\\n+          \"memory up to ShenandoahBorrowPercent \/ 100 amount of the \"       \\\n+          \"young-generation content of the current collection set.  \"       \\\n+          \"Any memory borrowed from old-gen during evacuation and \"         \\\n+          \"update-references phases of GC will be repaid from the \"         \\\n+          \"abundance of young-gen memory produced when the collection \"     \\\n+          \"set is recycled at the end of updating references.  The \"        \\\n+          \"default value of 30 reserves 70% of the to-be-reclaimed \"        \\\n+          \"young collection set memory to be allocated during the \"         \\\n+          \"subsequent concurrent mark phase of GC.\")                        \\\n+          range(0, 100)                                                     \\\n@@ -438,3 +496,0 @@\n-\/\/ 2^ShenandoahTenuredRegionUsageBiasLogBase2 is 128\n-#define ShenandoahTenuredRegionUsageBiasLogBase2 7\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoah_globals.hpp","additions":81,"deletions":26,"binary":false,"changes":107,"status":"modified"}]}