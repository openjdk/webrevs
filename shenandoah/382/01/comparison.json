{"files":[{"patch":"@@ -65,1 +65,1 @@\n-  _requested_gc_cause(GCCause::_no_cause_specified),\n+  _requested_gc_cause(GCCause::_no_gc),\n@@ -95,1 +95,1 @@\n-  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n@@ -97,1 +97,1 @@\n-  GCMode default_mode = concurrent_normal;\n+  const GCMode default_mode = concurrent_normal;\n@@ -99,1 +99,0 @@\n-  GCCause::Cause default_cause = GCCause::_shenandoah_concurrent_gc;\n@@ -108,1 +107,1 @@\n-  double shrink_period = (double)ShenandoahUncommitDelay \/ 1000 \/ 10;\n+  const double shrink_period = (double)ShenandoahUncommitDelay \/ 1000 \/ 10;\n@@ -110,1 +109,1 @@\n-  ShenandoahCollectorPolicy* policy = heap->shenandoah_policy();\n+  ShenandoahCollectorPolicy* const policy = heap->shenandoah_policy();\n@@ -119,6 +118,7 @@\n-    bool alloc_failure_pending = _alloc_failure_gc.is_set();\n-    bool humongous_alloc_failure_pending = _humongous_alloc_failure_gc.is_set();\n-    bool is_gc_requested = _gc_requested.is_set();\n-    GCCause::Cause requested_gc_cause = _requested_gc_cause;\n-    bool explicit_gc_requested = is_gc_requested && is_explicit_gc(requested_gc_cause);\n-    bool implicit_gc_requested = is_gc_requested && is_implicit_gc(requested_gc_cause);\n+    const bool alloc_failure_pending = _alloc_failure_gc.is_set();\n+    const bool humongous_alloc_failure_pending = _humongous_alloc_failure_gc.is_set();\n+\n+    GCCause::Cause cause = Atomic::xchg(&_requested_gc_cause, GCCause::_no_gc);\n+\n+    const bool explicit_gc_requested = is_explicit_gc(cause);\n+    const bool implicit_gc_requested = is_implicit_gc(cause);\n@@ -127,1 +127,1 @@\n-    size_t allocs_seen = Atomic::xchg(&_allocs_seen, (size_t)0, memory_order_relaxed);\n+    const size_t allocs_seen = Atomic::xchg(&_allocs_seen, (size_t)0, memory_order_relaxed);\n@@ -130,1 +130,1 @@\n-    bool soft_max_changed = check_soft_max_changed();\n+    const bool soft_max_changed = check_soft_max_changed();\n@@ -134,1 +134,0 @@\n-    GCCause::Cause cause = GCCause::_last_gc_cause;\n@@ -178,1 +177,0 @@\n-      cause = requested_gc_cause;\n@@ -194,1 +192,0 @@\n-      cause = requested_gc_cause;\n@@ -213,1 +210,1 @@\n-      if (_requested_gc_cause == GCCause::_shenandoah_concurrent_gc) {\n+      if (cause == GCCause::_shenandoah_concurrent_gc) {\n@@ -223,0 +220,1 @@\n+\n@@ -224,1 +222,0 @@\n-        cause = GCCause::_shenandoah_concurrent_gc;\n@@ -237,6 +234,0 @@\n-\n-        \/\/ Don't want to spin in this loop and start a cycle every time, so\n-        \/\/ clear requested gc cause. This creates a race with callers of the\n-        \/\/ blocking 'request_gc' method, but there it loops and resets the\n-        \/\/ '_requested_gc_cause' until a full cycle is completed.\n-        _requested_gc_cause = GCCause::_no_gc;\n@@ -257,8 +248,2 @@\n-    \/\/ Blow all soft references on this cycle, if handling allocation failure,\n-    \/\/ either implicit or explicit GC request, or we are requested to do so unconditionally.\n-    if (generation == select_global_generation() && (alloc_failure_pending || implicit_gc_requested || explicit_gc_requested || ShenandoahAlwaysClearSoftRefs)) {\n-      heap->soft_ref_policy()->set_should_clear_all_soft_refs(true);\n-    }\n-\n-    bool gc_requested = (gc_mode() != none);\n-    assert (!gc_requested || cause != GCCause::_last_gc_cause, \"GC cause should be set\");\n+    const bool gc_requested = (gc_mode() != none);\n+    assert (!gc_requested || cause != GCCause::_no_gc, \"GC cause should be set\");\n@@ -267,0 +252,6 @@\n+      \/\/ Blow away all soft references on this cycle, if handling allocation failure,\n+      \/\/ either implicit or explicit GC request, or we are requested to do so unconditionally.\n+      if (generation == select_global_generation() && (alloc_failure_pending || implicit_gc_requested || explicit_gc_requested || ShenandoahAlwaysClearSoftRefs)) {\n+        heap->soft_ref_policy()->set_should_clear_all_soft_refs(true);\n+      }\n+\n@@ -284,1 +275,1 @@\n-      bool was_aging_cycle = heap->is_aging_cycle();\n+      const bool was_aging_cycle = heap->is_aging_cycle();\n@@ -372,1 +363,1 @@\n-      \/\/ Allow allocators to know we have seen this much regions\n+      \/\/ Allow pacer to know we have seen this many allocations\n@@ -398,2 +389,2 @@\n-    \/\/ Don't wait around if there was an allocation failure - start the next cycle immediately.\n-    if (!is_alloc_failure_gc()) {\n+    \/\/ Wait for ShenandoahControlIntervalMax unless there was an allocation failure or another request was made mid-cycle.\n+    if (!is_alloc_failure_gc() && _requested_gc_cause == GCCause::_no_gc) {\n@@ -868,1 +859,1 @@\n-  if (_preemption_requested.is_set() || _gc_requested.is_set() || ShenandoahHeap::heap()->cancelled_gc()) {\n+  if (_preemption_requested.is_set() || _requested_gc_cause != GCCause::_no_gc || ShenandoahHeap::heap()->cancelled_gc()) {\n@@ -872,1 +863,1 @@\n-                          BOOL_TO_STR(_gc_requested.is_set()),\n+                          GCCause::to_string(_requested_gc_cause),\n@@ -878,1 +869,6 @@\n-    _requested_gc_cause = GCCause::_shenandoah_concurrent_gc;\n+    GCCause::Cause existing = Atomic::cmpxchg(&_requested_gc_cause, GCCause::_no_gc, GCCause::_shenandoah_concurrent_gc);\n+    if (existing != GCCause::_no_gc) {\n+      log_debug(gc, thread)(\"Reject request for concurrent gc because another gc is pending: %s\", GCCause::to_string(existing));\n+      return false;\n+    }\n+\n@@ -890,1 +886,0 @@\n-    log_info(gc)(\"Preempting old generation mark to allow %s GC\", shenandoah_generation_name(generation));\n@@ -892,2 +887,7 @@\n-    _requested_gc_cause = GCCause::_shenandoah_concurrent_gc;\n-    _requested_generation = generation;\n+    GCCause::Cause existing = Atomic::cmpxchg(&_requested_gc_cause, GCCause::_no_gc, GCCause::_shenandoah_concurrent_gc);\n+    if (existing != GCCause::_no_gc) {\n+      log_debug(gc, thread)(\"Reject request to interrupt old gc because another gc is pending: %s\", GCCause::to_string(existing));\n+      return false;\n+    }\n+\n+    log_info(gc)(\"Preempting old generation mark to allow %s GC\", shenandoah_generation_name(generation));\n@@ -935,4 +935,7 @@\n-    \/\/ does not take the lock. We need to enforce following order, so that read side sees\n-    \/\/ latest requested gc cause when the flag is set.\n-    _requested_gc_cause = cause;\n-    _gc_requested.set();\n+    \/\/ does not take the lock. This races with the regulator thread to start a concurrent gc\n+    \/\/ and the control thread to clear it at the start of a cycle.\n+    GCCause::Cause existing = Atomic::xchg(&_requested_gc_cause, cause);\n+    if (existing != GCCause::_no_gc) {\n+      log_debug(gc, thread)(\"GC request supersedes existing request: %s\", GCCause::to_string(existing));\n+    }\n+\n@@ -1003,4 +1006,0 @@\n-bool ShenandoahControlThread::is_humongous_alloc_failure_gc() {\n-  return _humongous_alloc_failure_gc.is_set();\n-}\n-\n@@ -1008,1 +1007,0 @@\n-  _gc_requested.unset();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahControlThread.cpp","additions":50,"deletions":52,"binary":false,"changes":102,"status":"modified"},{"patch":"@@ -89,1 +89,0 @@\n-  ShenandoahSharedFlag _gc_requested;\n@@ -95,2 +94,3 @@\n-  GCCause::Cause       _requested_gc_cause;\n-  ShenandoahGenerationType _requested_generation;\n+\n+  GCCause::Cause  _requested_gc_cause;\n+  volatile ShenandoahGenerationType _requested_generation;\n@@ -127,3 +127,0 @@\n-  \/\/ True if humongous allocation failure flag has been set.\n-  bool is_humongous_alloc_failure_gc();\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahControlThread.hpp","additions":3,"deletions":6,"binary":false,"changes":9,"status":"modified"}]}