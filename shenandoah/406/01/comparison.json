{"files":[{"patch":"@@ -31,1 +31,1 @@\n-#include \"gc\/shenandoah\/shenandoahHeap.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahGenerationalHeap.hpp\"\n@@ -33,0 +33,1 @@\n+#include \"gc\/shenandoah\/shenandoahOldGeneration.hpp\"\n@@ -43,1 +44,1 @@\n-  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  auto heap = ShenandoahGenerationalHeap::heap();\n@@ -151,2 +152,2 @@\n-  heap->reserve_promotable_humongous_regions(humongous_regions_promoted);\n-  heap->reserve_promotable_regular_regions(regular_regions_promoted_in_place);\n+  heap->old_generation()->set_expected_humongous_region_promotions(humongous_regions_promoted);\n+  heap->old_generation()->set_expected_regular_region_promotions(regular_regions_promoted_in_place);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahGenerationalHeuristics.cpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -30,1 +30,1 @@\n-#include \"gc\/shenandoah\/shenandoahHeap.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahGenerationalHeap.hpp\"\n@@ -82,1 +82,1 @@\n-  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  auto heap = ShenandoahGenerationalHeap::heap();\n@@ -89,1 +89,3 @@\n-  size_t max_young_cset = (size_t) (heap->get_young_evac_reserve() \/ ShenandoahEvacWaste);\n+  size_t young_evac_reserve = heap->young_generation()->get_evacuation_reserve();\n+  size_t old_evac_reserve = heap->old_generation()->get_evacuation_reserve();\n+  size_t max_young_cset = (size_t) (young_evac_reserve \/ ShenandoahEvacWaste);\n@@ -91,1 +93,1 @@\n-  size_t max_old_cset = (size_t) (heap->get_old_evac_reserve() \/ ShenandoahOldEvacWaste);\n+  size_t max_old_cset = (size_t) (old_evac_reserve \/ ShenandoahOldEvacWaste);\n@@ -171,2 +173,2 @@\n-    heap->set_young_evac_reserve(heap->get_young_evac_reserve() - regions_transferred_to_old * region_size_bytes);\n-    heap->set_old_evac_reserve(heap->get_old_evac_reserve() + regions_transferred_to_old * region_size_bytes);\n+    heap->young_generation()->set_evacuation_reserve(young_evac_reserve - regions_transferred_to_old * region_size_bytes);\n+    heap->old_generation()->set_evacuation_reserve(old_evac_reserve + regions_transferred_to_old * region_size_bytes);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahGlobalHeuristics.cpp","additions":8,"deletions":6,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -30,2 +30,1 @@\n-#include \"gc\/shenandoah\/shenandoahHeap.hpp\"\n-#include \"gc\/shenandoah\/shenandoahHeapRegion.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahGenerationalHeap.hpp\"\n@@ -35,3 +34,0 @@\n-#define BYTES_FORMAT    SIZE_FORMAT \"%s\"\n-#define FORMAT_BYTES(b) byte_size_in_proper_unit(b), proper_unit_for_byte_size(b)\n-\n@@ -75,1 +71,1 @@\n-  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  auto heap = ShenandoahGenerationalHeap::heap();\n@@ -91,1 +87,2 @@\n-  size_t old_evacuation_budget = (size_t) ((double) heap->get_old_evac_reserve() \/ ShenandoahOldEvacWaste);\n+  const size_t old_evacuation_reserve = heap->old_generation()->get_evacuation_reserve();\n+  const size_t old_evacuation_budget = (size_t) ((double) old_evacuation_reserve \/ ShenandoahOldEvacWaste);\n@@ -224,2 +221,2 @@\n-                   \"Old evacuation budget: \" BYTES_FORMAT \", Remaining evacuation budget: \" BYTES_FORMAT\n-                   \", Lost capacity: \" BYTES_FORMAT\n+                   \"Old evacuation budget: \" PROPERFMT \", Remaining evacuation budget: \" PROPERFMT\n+                   \", Lost capacity: \" PROPERFMT\n@@ -227,3 +224,3 @@\n-                   FORMAT_BYTES(heap->get_old_evac_reserve()),\n-                   FORMAT_BYTES(remaining_old_evacuation_budget),\n-                   FORMAT_BYTES(lost_evacuation_capacity),\n+                   PROPERFMTARGS(old_evacuation_reserve),\n+                   PROPERFMTARGS(remaining_old_evacuation_budget),\n+                   PROPERFMTARGS(lost_evacuation_capacity),\n@@ -312,0 +309,1 @@\n+  const size_t num_regions = heap->num_regions();\n@@ -314,1 +312,0 @@\n-  size_t num_regions = heap->num_regions();\n@@ -426,2 +423,2 @@\n-    size_t first_unselected_old_region = candidates[_last_old_collection_candidate]._region->index();\n-    size_t last_unselected_old_region = candidates[cand_idx - 1]._region->index();\n+    const size_t first_unselected_old_region = candidates[_last_old_collection_candidate]._region->index();\n+    const size_t last_unselected_old_region = candidates[cand_idx - 1]._region->index();\n@@ -433,1 +430,1 @@\n-    size_t bound_on_additional_regions = cand_idx \/ MAX_FRACTION_OF_HUMONGOUS_DEFRAG_REGIONS;\n+    const size_t bound_on_additional_regions = cand_idx \/ MAX_FRACTION_OF_HUMONGOUS_DEFRAG_REGIONS;\n@@ -441,2 +438,2 @@\n-      size_t region_garbage = candidates[_last_old_collection_candidate]._region->garbage();\n-      size_t region_free = r->free();\n+      const size_t region_garbage = candidates[_last_old_collection_candidate]._region->garbage();\n+      const size_t region_free = r->free();\n@@ -456,3 +453,3 @@\n-  size_t collectable_garbage = immediate_garbage + candidates_garbage;\n-  size_t old_candidates = _last_old_collection_candidate;\n-  size_t mixed_evac_live = old_candidates * region_size_bytes - (candidates_garbage + unfragmented);\n+  const size_t collectable_garbage = immediate_garbage + candidates_garbage;\n+  const size_t old_candidates = _last_old_collection_candidate;\n+  const size_t mixed_evac_live = old_candidates * region_size_bytes - (candidates_garbage + unfragmented);\n@@ -559,3 +556,3 @@\n-    size_t old_gen_capacity = _old_generation->max_capacity();\n-    size_t heap_capacity = heap->capacity();\n-    double percent = percent_of(old_gen_capacity, heap_capacity);\n+    const size_t old_gen_capacity = _old_generation->max_capacity();\n+    const size_t heap_capacity = heap->capacity();\n+    const double percent = percent_of(old_gen_capacity, heap_capacity);\n@@ -568,2 +565,2 @@\n-    size_t used = _old_generation->used();\n-    size_t used_regions_size = _old_generation->used_regions_size();\n+    const size_t used = _old_generation->used();\n+    const size_t used_regions_size = _old_generation->used_regions_size();\n@@ -572,1 +569,1 @@\n-    size_t used_regions = _old_generation->used_regions();\n+    const size_t used_regions = _old_generation->used_regions();\n@@ -578,2 +575,2 @@\n-    size_t span_of_old_regions = (last_old_region >= first_old_region)? last_old_region + 1 - first_old_region: 0;\n-    size_t fragmented_free = used_regions_size - used;\n+    const size_t span_of_old_regions = (last_old_region >= first_old_region)? last_old_region + 1 - first_old_region: 0;\n+    const size_t fragmented_free = used_regions_size - used;\n@@ -592,3 +589,4 @@\n-    size_t current_usage = _old_generation->used();\n-    size_t trigger_threshold = _old_generation->usage_trigger_threshold();\n-    size_t heap_size = heap->capacity();\n+    const size_t current_usage = _old_generation->used();\n+    const size_t trigger_threshold = _old_generation->usage_trigger_threshold();\n+    const size_t heap_size = heap->capacity();\n+    const size_t ignore_threshold = (ShenandoahIgnoreOldGrowthBelowPercentage * heap_size) \/ 100;\n@@ -596,1 +594,0 @@\n-    size_t ignore_threshold = (ShenandoahIgnoreOldGrowthBelowPercentage * heap_size) \/ 100;\n@@ -607,2 +604,2 @@\n-      size_t live_at_previous_old = _old_generation->get_live_bytes_after_last_mark();\n-      double percent_growth = percent_of(current_usage - live_at_previous_old, live_at_previous_old);\n+      const size_t live_at_previous_old = _old_generation->get_live_bytes_after_last_mark();\n+      const double percent_growth = percent_of(current_usage - live_at_previous_old, live_at_previous_old);\n@@ -658,4 +655,0 @@\n-\n-\n-#undef BYTES_FORMAT\n-#undef FORMAT_BYTES\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahOldHeuristics.cpp","additions":32,"deletions":39,"binary":false,"changes":71,"status":"modified"},{"patch":"@@ -30,1 +30,1 @@\n-#include \"gc\/shenandoah\/shenandoahHeap.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahGenerationalHeap.hpp\"\n@@ -32,0 +32,1 @@\n+#include \"gc\/shenandoah\/shenandoahOldGeneration.hpp\"\n@@ -81,1 +82,1 @@\n-  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  auto heap = ShenandoahGenerationalHeap::heap();\n@@ -90,1 +91,1 @@\n-  size_t max_cset = (size_t) (heap->get_young_evac_reserve() \/ ShenandoahEvacWaste);\n+  size_t max_cset = (size_t) (heap->young_generation()->get_evacuation_reserve() \/ ShenandoahEvacWaste);\n@@ -126,1 +127,1 @@\n-  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  auto heap = ShenandoahGenerationalHeap::heap();\n@@ -130,1 +131,1 @@\n-  if (ShenandoahMinimumOldMarkTimeMs > 0 && ShenandoahHeap::heap()->is_concurrent_old_mark_in_progress()) {\n+  if (ShenandoahMinimumOldMarkTimeMs > 0 && heap->is_concurrent_old_mark_in_progress()) {\n@@ -148,1 +149,1 @@\n-  size_t promo_potential = heap->get_promotion_potential();\n+  size_t promo_potential = heap->old_generation()->get_promotion_potential();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahYoungHeuristics.cpp","additions":7,"deletions":6,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"gc\/shenandoah\/shenandoahGenerationalHeap.hpp\"\n@@ -233,5 +234,2 @@\n-    bool success;\n-    size_t region_xfer;\n-    const char* region_destination;\n-    ShenandoahYoungGeneration* young_gen = heap->young_generation();\n-    ShenandoahGeneration* old_gen = heap->old_generation();\n+\n+    ShenandoahGenerationalHeap::TransferResult result;\n@@ -239,25 +237,5 @@\n-      ShenandoahHeapLocker locker(heap->lock());\n-\n-      size_t old_region_surplus = heap->get_old_region_surplus();\n-      size_t old_region_deficit = heap->get_old_region_deficit();\n-      if (old_region_surplus) {\n-        success = heap->generation_sizer()->transfer_to_young(old_region_surplus);\n-        region_destination = \"young\";\n-        region_xfer = old_region_surplus;\n-      } else if (old_region_deficit) {\n-        success = heap->generation_sizer()->transfer_to_old(old_region_deficit);\n-        region_destination = \"old\";\n-        region_xfer = old_region_deficit;\n-        if (!success) {\n-          ((ShenandoahOldHeuristics *) old_gen->heuristics())->trigger_cannot_expand();\n-        }\n-      } else {\n-        region_destination = \"none\";\n-        region_xfer = 0;\n-        success = true;\n-      }\n-      heap->set_old_region_surplus(0);\n-      heap->set_old_region_deficit(0);\n-      heap->set_young_evac_reserve(0);\n-      heap->set_old_evac_reserve(0);\n-      heap->set_promoted_reserve(0);\n+      ShenandoahGenerationalHeap* gen_heap = ShenandoahGenerationalHeap::heap();\n+      ShenandoahHeapLocker locker(gen_heap->lock());\n+\n+      result = gen_heap->balance_generations();\n+      gen_heap->reset_generation_reserves();\n@@ -266,8 +244,5 @@\n-    \/\/ Report outside the heap lock\n-    size_t young_available = young_gen->available();\n-    size_t old_available = old_gen->available();\n-    log_info(gc, ergo)(\"After cleanup, %s \" SIZE_FORMAT \" regions to %s to prepare for next gc, old available: \"\n-                       SIZE_FORMAT \"%s, young_available: \" SIZE_FORMAT \"%s\",\n-                       success? \"successfully transferred\": \"failed to transfer\", region_xfer, region_destination,\n-                       byte_size_in_proper_unit(old_available), proper_unit_for_byte_size(old_available),\n-                       byte_size_in_proper_unit(young_available), proper_unit_for_byte_size(young_available));\n+    LogTarget(Info, gc, ergo) lt;\n+    if (lt.is_enabled()) {\n+      LogStream ls(lt);\n+      result.print_on(\"Concurrent GC\", &ls);\n+    }\n@@ -768,3 +743,1 @@\n-      size_t humongous_regions_promoted = heap->get_promotable_humongous_regions();\n-      size_t regular_regions_promoted_in_place = heap->get_regular_regions_promoted_in_place();\n-      if (!heap->collection_set()->is_empty() || (humongous_regions_promoted + regular_regions_promoted_in_place > 0)) {\n+      if (!heap->collection_set()->is_empty() || heap->old_generation()->has_in_place_promotions()) {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahConcurrentGC.cpp","additions":14,"deletions":41,"binary":false,"changes":55,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"gc\/shenandoah\/shenandoahGenerationalHeap.hpp\"\n@@ -293,20 +294,5 @@\n-        size_t old_region_surplus = heap->get_old_region_surplus();\n-        size_t old_region_deficit = heap->get_old_region_deficit();\n-        bool success;\n-        size_t region_xfer;\n-        const char* region_destination;\n-        if (old_region_surplus) {\n-          region_xfer = old_region_surplus;\n-          region_destination = \"young\";\n-          success = heap->generation_sizer()->transfer_to_young(old_region_surplus);\n-        } else if (old_region_deficit) {\n-          region_xfer = old_region_surplus;\n-          region_destination = \"old\";\n-          success = heap->generation_sizer()->transfer_to_old(old_region_deficit);\n-          if (!success) {\n-            heap->old_heuristics()->trigger_cannot_expand();\n-          }\n-        } else {\n-          region_destination = \"none\";\n-          region_xfer = 0;\n-          success = true;\n+        auto result = ShenandoahGenerationalHeap::heap()->balance_generations();\n+        LogTarget(Info, gc, ergo) lt;\n+        if (lt.is_enabled()) {\n+          LogStream ls(lt);\n+          result.print_on(\"Degenerated GC\", &ls);\n@@ -314,11 +300,0 @@\n-\n-        size_t young_available = heap->young_generation()->available();\n-        size_t old_available = heap->old_generation()->available();\n-        log_info(gc, ergo)(\"After cleanup, %s \" SIZE_FORMAT \" regions to %s to prepare for next gc, old available: \"\n-                           SIZE_FORMAT \"%s, young_available: \" SIZE_FORMAT \"%s\",\n-                           success? \"successfully transferred\": \"failed to transfer\", region_xfer, region_destination,\n-                           byte_size_in_proper_unit(old_available), proper_unit_for_byte_size(old_available),\n-                           byte_size_in_proper_unit(young_available), proper_unit_for_byte_size(young_available));\n-\n-        heap->set_old_region_surplus(0);\n-        heap->set_old_region_deficit(0);\n@@ -334,3 +309,1 @@\n-    heap->set_young_evac_reserve(0);\n-    heap->set_old_evac_reserve(0);\n-    heap->set_promoted_reserve(0);\n+    ShenandoahGenerationalHeap::heap()->reset_generation_reserves();\n@@ -400,3 +373,1 @@\n-  size_t humongous_regions_promoted = heap->get_promotable_humongous_regions();\n-  size_t regular_regions_promoted_in_place = heap->get_regular_regions_promoted_in_place();\n-  if (!heap->collection_set()->is_empty() || (humongous_regions_promoted + regular_regions_promoted_in_place > 0)) {\n+  if (!heap->collection_set()->is_empty() || heap->old_generation()->has_in_place_promotions()) {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahDegeneratedGC.cpp","additions":8,"deletions":37,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -467,1 +467,1 @@\n-    _heap->augment_promo_reserve(capacity);\n+    _heap->old_generation()->augment_promoted_reserve(capacity);\n@@ -1002,1 +1002,1 @@\n-  _heap->augment_old_evac_reserve(region_capacity);\n+  _heap->old_generation()->augment_evacuation_reserve(region_capacity);\n@@ -1164,1 +1164,1 @@\n-void ShenandoahFreeSet::rebuild(size_t young_cset_regions, size_t old_cset_regions) {\n+void ShenandoahFreeSet::rebuild(size_t young_cset_regions, size_t old_cset_regions, bool have_evacuation_reserves) {\n@@ -1169,6 +1169,8 @@\n-  size_t old_capacity = _heap->old_generation()->max_capacity();\n-  size_t old_available = _heap->old_generation()->available();\n-  size_t old_unaffiliated_regions = _heap->old_generation()->free_unaffiliated_regions();\n-  size_t young_capacity = _heap->young_generation()->max_capacity();\n-  size_t young_available = _heap->young_generation()->available();\n-  size_t young_unaffiliated_regions = _heap->young_generation()->free_unaffiliated_regions();\n+  ShenandoahOldGeneration* old_generation = _heap->old_generation();\n+  size_t old_capacity = old_generation->max_capacity();\n+  size_t old_available = old_generation->available();\n+  size_t old_unaffiliated_regions = old_generation->free_unaffiliated_regions();\n+  ShenandoahYoungGeneration* young_generation = _heap->young_generation();\n+  size_t young_capacity = young_generation->max_capacity();\n+  size_t young_available = young_generation->available();\n+  size_t young_unaffiliated_regions = young_generation->free_unaffiliated_regions();\n@@ -1183,2 +1185,2 @@\n-  size_t old_region_surplus = _heap->get_old_region_surplus();\n-  size_t old_region_deficit = _heap->get_old_region_deficit();\n+  size_t old_region_surplus = old_generation->get_region_surplus();\n+  size_t old_region_deficit = old_generation->get_region_deficit();\n@@ -1216,1 +1218,1 @@\n-    if (_heap->has_evacuation_reserve_quantities()) {\n+    if (have_evacuation_reserves) {\n@@ -1218,2 +1220,5 @@\n-      young_reserve = _heap->get_young_evac_reserve();\n-      old_reserve = _heap->get_promoted_reserve() + _heap->get_old_evac_reserve();\n+\n+      size_t promoted_reserve = old_generation->get_promoted_reserve();\n+      size_t old_evac_reserve = old_generation->get_evacuation_reserve();\n+      young_reserve = young_generation->get_evacuation_reserve();\n+      old_reserve = promoted_reserve + old_evac_reserve;\n@@ -1222,1 +1227,1 @@\n-             _heap->get_promoted_reserve(), _heap->get_old_evac_reserve(), old_available);\n+             promoted_reserve, old_evac_reserve, old_available);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFreeSet.cpp","additions":20,"deletions":15,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -195,1 +195,15 @@\n-  void rebuild(size_t young_cset_regions, size_t old_cset_regions);\n+\n+  \/\/ At the end of final mark, but before we begin evacuating, heuristics calculate how much memory is required to\n+  \/\/ hold the results of evacuating to young-gen and to old-gen.  These quantities, stored in reserves for their,\n+  \/\/ respective generations, are consulted prior to rebuilding the free set (ShenandoahFreeSet) in preparation for\n+  \/\/ evacuation.  When the free set is rebuilt, we make sure to reserve sufficient memory in the collector and\n+  \/\/ old_collector sets to hold evacuations, if have_evacuation_reserves is true.  The other time we rebuild the free\n+  \/\/ set is at the end of GC, as we prepare to idle GC until the next trigger.  In this case, have_evacuation_reserves\n+  \/\/ is false because we don't yet know how much memory will need to be evacuated in the next GC cycle.  When\n+  \/\/ have_evacuation_reserves is false, the free set rebuild operation reserves for the collector and old_collector sets\n+  \/\/ based on alternative mechanisms, such as ShenandoahEvacReserve, ShenandoahOldEvacReserve, and\n+  \/\/ ShenandoahOldCompactionReserve.  In a future planned enhancement, the reserve for old_collector set when the\n+  \/\/ evacuation reserves are unknown, is based in part on anticipated promotion as determined by analysis of live data\n+  \/\/ found during the previous GC pass which is one less than the current tenure age.\n+  void rebuild(size_t young_cset_regions, size_t old_cset_regions, bool have_evacuation_reserves = false);\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFreeSet.hpp","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -137,1 +137,1 @@\n-    ShenandoahGenerationalFullGC::prepare(heap);\n+    ShenandoahGenerationalFullGC::prepare();\n@@ -1191,4 +1191,1 @@\n-      \/\/ In case this Full GC resulted from degeneration, clear the tally on anticipated promotion.\n-      heap->clear_promotion_potential();\n-      \/\/ Invoke this in case we are able to transfer memory from OLD to YOUNG.\n-      heap->compute_old_generation_balance(0, 0);\n+      ShenandoahGenerationalFullGC::compute_balances();\n@@ -1196,0 +1193,1 @@\n+\n@@ -1201,1 +1199,1 @@\n-      ShenandoahGenerationalFullGC::balance_generations_after_rebuilding_free_set(heap);\n+      ShenandoahGenerationalFullGC::balance_generations_after_rebuilding_free_set();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFullGC.cpp","additions":4,"deletions":6,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -30,1 +30,1 @@\n-#include \"gc\/shenandoah\/shenandoahHeap.hpp\"\n+#include \"gc\/shenandoah\/shenandoahGenerationalHeap.hpp\"\n@@ -154,0 +154,12 @@\n+void ShenandoahGeneration::set_evacuation_reserve(size_t new_val) {\n+  _evacuation_reserve = new_val;\n+}\n+\n+size_t ShenandoahGeneration::get_evacuation_reserve() const {\n+  return _evacuation_reserve;\n+}\n+\n+void ShenandoahGeneration::augment_evacuation_reserve(size_t increment) {\n+  _evacuation_reserve += increment;\n+}\n+\n@@ -234,1 +246,1 @@\n-  ShenandoahGeneration* const old_generation = heap->old_generation();\n+  ShenandoahOldGeneration* const old_generation = heap->old_generation();\n@@ -338,4 +350,3 @@\n-\n-  heap->set_young_evac_reserve(young_evacuation_reserve);\n-  heap->set_old_evac_reserve(old_evacuation_reserve);\n-  heap->set_promoted_reserve(consumed_by_advance_promotion);\n+  young_generation->set_evacuation_reserve(young_evacuation_reserve);\n+  old_generation->set_evacuation_reserve(old_evacuation_reserve);\n+  old_generation->set_promoted_reserve(consumed_by_advance_promotion);\n@@ -367,2 +378,2 @@\n-  const ShenandoahOldGeneration* const old_generation = heap->old_generation();\n-  const ShenandoahYoungGeneration* const young_generation = heap->young_generation();\n+  ShenandoahOldGeneration* const old_generation = heap->old_generation();\n+  ShenandoahYoungGeneration* const young_generation = heap->young_generation();\n@@ -372,1 +383,1 @@\n-  size_t old_evacuation_reserve = heap->get_old_evac_reserve();\n+  size_t old_evacuation_reserve = old_generation->get_evacuation_reserve();\n@@ -384,1 +395,1 @@\n-    heap->set_old_evac_reserve(old_evacuation_reserve);\n+    old_generation->set_evacuation_reserve(old_evacuation_reserve);\n@@ -395,1 +406,1 @@\n-  heap->set_young_evac_reserve(young_evacuated_reserve_used);\n+  young_generation->set_evacuation_reserve(young_evacuated_reserve_used);\n@@ -460,2 +471,2 @@\n-  heap->set_promoted_reserve(total_promotion_reserve);\n-  heap->reset_promoted_expended();\n+  old_generation->set_promoted_reserve(total_promotion_reserve);\n+  old_generation->reset_promoted_expended();\n@@ -511,2 +522,1 @@\n-  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n-  assert(heap->mode()->is_generational(), \"Only in generational mode\");\n+  auto const heap = ShenandoahGenerationalHeap::heap();\n@@ -637,2 +647,3 @@\n-  heap->set_pad_for_promote_in_place(promote_in_place_pad);\n-  heap->set_promotion_potential(promo_potential);\n+\n+  heap->old_generation()->set_pad_for_promote_in_place(promote_in_place_pad);\n+  heap->old_generation()->set_promotion_potential(promo_potential);\n@@ -735,2 +746,1 @@\n-  \/\/ Freeset construction uses reserve quantities if they are valid\n-  heap->set_evacuation_reserve_quantities(true);\n+\n@@ -746,1 +756,2 @@\n-    heap->free_set()->rebuild(young_cset_regions, old_cset_regions);\n+    \/\/ Free set construction uses reserve quantities, because they are known to be valid here\n+    heap->free_set()->rebuild(young_cset_regions, old_cset_regions, true);\n@@ -748,1 +759,0 @@\n-  heap->set_evacuation_reserve_quantities(false);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGeneration.cpp","additions":31,"deletions":21,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -62,0 +62,3 @@\n+  \/\/ Bytes reserved within this generation to hold evacuated objects from the collection set\n+  size_t _evacuation_reserve;\n+\n@@ -110,0 +113,5 @@\n+  \/\/ see description in field declaration\n+  void set_evacuation_reserve(size_t new_val);\n+  size_t get_evacuation_reserve() const;\n+  void augment_evacuation_reserve(size_t increment);\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGeneration.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -122,1 +122,1 @@\n-      bool old_gen_evacuation_failed = heap->clear_old_evacuation_failure();\n+      bool old_gen_evacuation_failed = heap->old_generation()->clear_failed_evacuation();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalControlThread.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/shenandoah\/shenandoahGenerationalHeap.hpp\"\n@@ -52,1 +53,2 @@\n-void ShenandoahGenerationalFullGC::prepare(ShenandoahHeap* heap) {\n+void ShenandoahGenerationalFullGC::prepare() {\n+  auto heap = ShenandoahGenerationalHeap::heap();\n@@ -114,24 +116,6 @@\n-void ShenandoahGenerationalFullGC::balance_generations_after_rebuilding_free_set(ShenandoahHeap* heap) {\n-  bool success;\n-  size_t region_xfer;\n-  const char* region_destination;\n-  ShenandoahYoungGeneration* young_gen = heap->young_generation();\n-  ShenandoahGeneration* old_gen = heap->old_generation();\n-\n-  size_t old_region_surplus = heap->get_old_region_surplus();\n-  size_t old_region_deficit = heap->get_old_region_deficit();\n-  if (old_region_surplus) {\n-    success = heap->generation_sizer()->transfer_to_young(old_region_surplus);\n-    region_destination = \"young\";\n-    region_xfer = old_region_surplus;\n-  } else if (old_region_deficit) {\n-    success = heap->generation_sizer()->transfer_to_old(old_region_deficit);\n-    region_destination = \"old\";\n-    region_xfer = old_region_deficit;\n-    if (!success) {\n-      ((ShenandoahOldHeuristics *) old_gen->heuristics())->trigger_cannot_expand();\n-    }\n-  } else {\n-    region_destination = \"none\";\n-    region_xfer = 0;\n-    success = true;\n+void ShenandoahGenerationalFullGC::balance_generations_after_rebuilding_free_set() {\n+  auto result = ShenandoahGenerationalHeap::heap()->balance_generations();\n+  LogTarget(Info, gc, ergo) lt;\n+  if (lt.is_enabled()) {\n+    LogStream ls(lt);\n+    result.print_on(\"Full GC\", &ls);\n@@ -139,8 +123,0 @@\n-  heap->set_old_region_surplus(0);\n-  heap->set_old_region_deficit(0);\n-  size_t young_available = young_gen->available();\n-  size_t old_available = old_gen->available();\n-  log_info(gc, ergo)(\"After cleanup, %s \" SIZE_FORMAT \" regions to %s to prepare for next gc, old available: \"\n-                     PROPERFMT \", young_available: \" PROPERFMT,\n-                     success? \"successfully transferred\": \"failed to transfer\", region_xfer, region_destination,\n-                     PROPERFMTARGS(old_available), PROPERFMTARGS(young_available));\n@@ -196,0 +172,9 @@\n+void ShenandoahGenerationalFullGC::compute_balances() {\n+  auto heap = ShenandoahGenerationalHeap::heap();\n+\n+  \/\/ In case this Full GC resulted from degeneration, clear the tally on anticipated promotion.\n+  heap->old_generation()->set_promotion_potential(0);\n+  \/\/ Invoke this in case we are able to transfer memory from OLD to YOUNG.\n+  heap->compute_old_generation_balance(0, 0);\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalFullGC.cpp","additions":18,"deletions":33,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -39,1 +39,1 @@\n-  static void prepare(ShenandoahHeap* heap);\n+  static void prepare();\n@@ -53,0 +53,5 @@\n+  \/\/ This will compute the target size for the old generation. It will be expressed in terms of\n+  \/\/ a region surplus and deficit, which will be redistributed accordingly after rebuilding the\n+  \/\/ free set.\n+  static void compute_balances();\n+\n@@ -59,1 +64,1 @@\n-  static void balance_generations_after_rebuilding_free_set(ShenandoahHeap* heap);\n+  static void balance_generations_after_rebuilding_free_set();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalFullGC.hpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"gc\/shenandoah\/shenandoahMemoryPool.hpp\"\n@@ -69,0 +70,1 @@\n+  shenandoah_assert_generational();\n@@ -73,0 +75,4 @@\n+ShenandoahGenerationalHeap::ShenandoahGenerationalHeap(ShenandoahCollectorPolicy* policy) :\n+  ShenandoahHeap(policy),\n+  _regulator_thread(nullptr) { }\n+\n@@ -78,3 +84,17 @@\n-ShenandoahGenerationalHeap::ShenandoahGenerationalHeap(ShenandoahCollectorPolicy* policy) :\n-  ShenandoahHeap(policy),\n-  _regulator_thread(nullptr) { }\n+void ShenandoahGenerationalHeap::initialize_serviceability() {\n+  assert(mode()->is_generational(), \"Only for the generational mode\");\n+  _young_gen_memory_pool = new ShenandoahYoungGenMemoryPool(this);\n+  _old_gen_memory_pool = new ShenandoahOldGenMemoryPool(this);\n+  cycle_memory_manager()->add_pool(_young_gen_memory_pool);\n+  cycle_memory_manager()->add_pool(_old_gen_memory_pool);\n+  stw_memory_manager()->add_pool(_young_gen_memory_pool);\n+  stw_memory_manager()->add_pool(_old_gen_memory_pool);\n+}\n+\n+GrowableArray<MemoryPool*> ShenandoahGenerationalHeap::memory_pools() {\n+  assert(mode()->is_generational(), \"Only for the generational mode\");\n+  GrowableArray<MemoryPool*> memory_pools(2);\n+  memory_pools.append(_young_gen_memory_pool);\n+  memory_pools.append(_old_gen_memory_pool);\n+  return memory_pools;\n+}\n@@ -99,0 +119,150 @@\n+\n+ShenandoahGenerationalHeap::TransferResult ShenandoahGenerationalHeap::balance_generations() {\n+  shenandoah_assert_heaplocked_or_safepoint();\n+\n+  ShenandoahOldGeneration* old_gen = old_generation();\n+  const size_t old_region_surplus = old_gen->get_region_surplus();\n+  const size_t old_region_deficit = old_gen->get_region_deficit();\n+  old_gen->set_region_surplus(0);\n+  old_gen->set_region_deficit(0);\n+\n+  if (old_region_surplus) {\n+    bool success = generation_sizer()->transfer_to_young(old_region_surplus);\n+    return TransferResult {\n+      success, old_region_surplus, \"young\"\n+    };\n+  }\n+\n+  if (old_region_deficit) {\n+    const bool success = generation_sizer()->transfer_to_old(old_region_deficit);\n+    if (!success) {\n+      old_gen->handle_failed_transfer();\n+    }\n+    return TransferResult {\n+      success, old_region_deficit, \"old\"\n+    };\n+  }\n+\n+  return TransferResult {true, 0, \"none\"};\n+}\n+\n+\/\/ Make sure old-generation is large enough, but no larger than is necessary, to hold mixed evacuations\n+\/\/ and promotions, if we anticipate either. Any deficit is provided by the young generation, subject to\n+\/\/ xfer_limit, and any surplus is transferred to the young generation.\n+\/\/ xfer_limit is the maximum we're able to transfer from young to old.\n+void ShenandoahGenerationalHeap::compute_old_generation_balance(size_t old_xfer_limit, size_t old_cset_regions) {\n+\n+  \/\/ We can limit the old reserve to the size of anticipated promotions:\n+  \/\/ max_old_reserve is an upper bound on memory evacuated from old and promoted to old,\n+  \/\/ clamped by the old generation space available.\n+  \/\/\n+  \/\/ Here's the algebra.\n+  \/\/ Let SOEP = ShenandoahOldEvacRatioPercent,\n+  \/\/     OE = old evac,\n+  \/\/     YE = young evac, and\n+  \/\/     TE = total evac = OE + YE\n+  \/\/ By definition:\n+  \/\/            SOEP\/100 = OE\/TE\n+  \/\/                     = OE\/(OE+YE)\n+  \/\/  => SOEP\/(100-SOEP) = OE\/((OE+YE)-OE)      \/\/ componendo-dividendo: If a\/b = c\/d, then a\/(b-a) = c\/(d-c)\n+  \/\/                     = OE\/YE\n+  \/\/  =>              OE = YE*SOEP\/(100-SOEP)\n+\n+  \/\/ We have to be careful in the event that SOEP is set to 100 by the user.\n+  assert(ShenandoahOldEvacRatioPercent <= 100, \"Error\");\n+  const size_t old_available = old_generation()->available();\n+  \/\/ The free set will reserve this amount of memory to hold young evacuations\n+  const size_t young_reserve = (young_generation()->max_capacity() * ShenandoahEvacReserve) \/ 100;\n+\n+  \/\/ In the case that ShenandoahOldEvacRatioPercent equals 100, max_old_reserve is limited only by xfer_limit.\n+\n+  const size_t bound_on_old_reserve = old_available + old_xfer_limit + young_reserve;\n+  const size_t max_old_reserve = (ShenandoahOldEvacRatioPercent == 100)?\n+                                 bound_on_old_reserve: MIN2((young_reserve * ShenandoahOldEvacRatioPercent) \/ (100 - ShenandoahOldEvacRatioPercent),\n+                                                            bound_on_old_reserve);\n+\n+  const size_t region_size_bytes = ShenandoahHeapRegion::region_size_bytes();\n+\n+  \/\/ Decide how much old space we should reserve for a mixed collection\n+  size_t reserve_for_mixed = 0;\n+  const size_t mixed_candidates = old_heuristics()->unprocessed_old_collection_candidates();\n+  const bool doing_mixed = (mixed_candidates > 0);\n+  if (doing_mixed) {\n+    \/\/ We want this much memory to be unfragmented in order to reliably evacuate old.  This is conservative because we\n+    \/\/ may not evacuate the entirety of unprocessed candidates in a single mixed evacuation.\n+    const size_t max_evac_need = (size_t)\n+            (old_heuristics()->unprocessed_old_collection_candidates_live_memory() * ShenandoahOldEvacWaste);\n+    assert(old_available >= old_generation()->free_unaffiliated_regions() * region_size_bytes,\n+           \"Unaffiliated available must be less than total available\");\n+    const size_t old_fragmented_available =\n+            old_available - old_generation()->free_unaffiliated_regions() * region_size_bytes;\n+    reserve_for_mixed = max_evac_need + old_fragmented_available;\n+    if (reserve_for_mixed > max_old_reserve) {\n+      reserve_for_mixed = max_old_reserve;\n+    }\n+  }\n+\n+  \/\/ Decide how much space we should reserve for promotions from young\n+  size_t reserve_for_promo = 0;\n+  const size_t promo_load = old_generation()->get_promotion_potential();\n+  const bool doing_promotions = promo_load > 0;\n+  if (doing_promotions) {\n+    \/\/ We're promoting and have a bound on the maximum amount that can be promoted\n+    assert(max_old_reserve >= reserve_for_mixed, \"Sanity\");\n+    const size_t available_for_promotions = max_old_reserve - reserve_for_mixed;\n+    reserve_for_promo = MIN2((size_t)(promo_load * ShenandoahPromoEvacWaste), available_for_promotions);\n+  }\n+\n+  \/\/ This is the total old we want to ideally reserve\n+  const size_t old_reserve = reserve_for_mixed + reserve_for_promo;\n+  assert(old_reserve <= max_old_reserve, \"cannot reserve more than max for old evacuations\");\n+\n+  \/\/ We now check if the old generation is running a surplus or a deficit.\n+  size_t old_region_deficit = 0;\n+  size_t old_region_surplus = 0;\n+\n+  const size_t max_old_available = old_generation()->available() + old_cset_regions * region_size_bytes;\n+  if (max_old_available >= old_reserve) {\n+    \/\/ We are running a surplus, so the old region surplus can go to young\n+    const size_t old_surplus = max_old_available - old_reserve;\n+    old_region_surplus = old_surplus \/ region_size_bytes;\n+    const size_t unaffiliated_old_regions = old_generation()->free_unaffiliated_regions() + old_cset_regions;\n+    old_region_surplus = MIN2(old_region_surplus, unaffiliated_old_regions);\n+  } else {\n+    \/\/ We are running a deficit which we'd like to fill from young.\n+    \/\/ Ignore that this will directly impact young_generation()->max_capacity(),\n+    \/\/ indirectly impacting young_reserve and old_reserve.  These computations are conservative.\n+    const size_t old_need = old_reserve - max_old_available;\n+    \/\/ The old region deficit (rounded up) will come from young\n+    old_region_deficit = (old_need + region_size_bytes - 1) \/ region_size_bytes;\n+\n+    \/\/ Round down the regions we can transfer from young to old. If we're running short\n+    \/\/ on young-gen memory, we restrict the xfer. Old-gen collection activities will be\n+    \/\/ curtailed if the budget is restricted.\n+    const size_t max_old_region_xfer = old_xfer_limit \/ region_size_bytes;\n+    old_region_deficit = MIN2(old_region_deficit, max_old_region_xfer);\n+  }\n+  assert(old_region_deficit == 0 || old_region_surplus == 0, \"Only surplus or deficit, never both\");\n+\n+  old_generation()->set_region_surplus(old_region_surplus);\n+  old_generation()->set_region_deficit(old_region_deficit);\n+}\n+\n+void ShenandoahGenerationalHeap::reset_generation_reserves() {\n+  young_generation()->set_evacuation_reserve(0);\n+  old_generation()->set_evacuation_reserve(0);\n+  old_generation()->set_promoted_reserve(0);\n+}\n+\n+void ShenandoahGenerationalHeap::TransferResult::print_on(const char* when, outputStream* ss) const {\n+  auto heap = ShenandoahGenerationalHeap::heap();\n+  ShenandoahYoungGeneration* const young_gen = heap->young_generation();\n+  ShenandoahOldGeneration* const old_gen = heap->old_generation();\n+  const size_t young_available = young_gen->available();\n+  const size_t old_available = old_gen->available();\n+  ss->print_cr(\"After %s, %s \" SIZE_FORMAT \" regions to %s to prepare for next gc, old available: \"\n+                     PROPERFMT \", young_available: \" PROPERFMT,\n+                     when,\n+                     success? \"successfully transferred\": \"failed to transfer\", region_count, region_destination,\n+                     PROPERFMTARGS(old_available), PROPERFMTARGS(young_available));\n+}\n\\ No newline at end of file\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalHeap.cpp","additions":173,"deletions":3,"binary":false,"changes":176,"status":"modified"},{"patch":"@@ -41,1 +41,6 @@\n-  ShenandoahRegulatorThread* regulator_thread() const             { return _regulator_thread;  }\n+  \/\/ ---------- Serviceability\n+  \/\/\n+  void initialize_serviceability() override;\n+  GrowableArray<MemoryPool*> memory_pools() override;\n+\n+  ShenandoahRegulatorThread* regulator_thread() const { return _regulator_thread;  }\n@@ -47,0 +52,19 @@\n+  \/\/ Used for logging the result of a region transfer outside of the heap lock\n+  struct TransferResult {\n+    bool success;\n+    size_t region_count;\n+    const char* region_destination;\n+\n+    void print_on(const char* when, outputStream* ss) const;\n+  };\n+\n+  \/\/ Zeros out the evacuation and promotion reserves\n+  void reset_generation_reserves();\n+\n+  \/\/ Computes the optimal size for the old generation, represented as a surplus or deficit of old regions\n+  void compute_old_generation_balance(size_t old_xfer_limit, size_t old_cset_regions);\n+\n+  \/\/ Transfers surplus old regions to young, or takes regions from young to satisfy old region deficit\n+  TransferResult balance_generations();\n+\n+\n@@ -50,1 +74,0 @@\n-private:\n@@ -52,0 +75,3 @@\n+\n+  MemoryPool* _young_gen_memory_pool;\n+  MemoryPool* _old_gen_memory_pool;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalHeap.hpp","additions":28,"deletions":2,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -50,0 +50,1 @@\n+#include \"gc\/shenandoah\/shenandoahGenerationalHeap.hpp\"\n@@ -589,1 +590,0 @@\n-  _promotion_potential(0),\n@@ -601,3 +601,0 @@\n-  _promoted_reserve(0),\n-  _old_evac_reserve(0),\n-  _young_evac_reserve(0),\n@@ -605,1 +602,0 @@\n-  _has_evacuation_reserve_quantities(false),\n@@ -621,2 +617,0 @@\n-  _young_gen_memory_pool(nullptr),\n-  _old_gen_memory_pool(nullptr),\n@@ -627,2 +621,0 @@\n-  _old_regions_surplus(0),\n-  _old_regions_deficit(0),\n@@ -974,64 +966,0 @@\n-void ShenandoahHeap::handle_old_evacuation(HeapWord* obj, size_t words, bool promotion) {\n-  \/\/ Only register the copy of the object that won the evacuation race.\n-  card_scan()->register_object_without_lock(obj);\n-\n-  \/\/ Mark the entire range of the evacuated object as dirty.  At next remembered set scan,\n-  \/\/ we will clear dirty bits that do not hold interesting pointers.  It's more efficient to\n-  \/\/ do this in batch, in a background GC thread than to try to carefully dirty only cards\n-  \/\/ that hold interesting pointers right now.\n-  card_scan()->mark_range_as_dirty(obj, words);\n-\n-  if (promotion) {\n-    \/\/ This evacuation was a promotion, track this as allocation against old gen\n-    old_generation()->increase_allocated(words * HeapWordSize);\n-  }\n-}\n-\n-void ShenandoahHeap::handle_old_evacuation_failure() {\n-  if (_old_gen_oom_evac.try_set()) {\n-    log_info(gc)(\"Old gen evac failure.\");\n-  }\n-}\n-\n-void ShenandoahHeap::report_promotion_failure(Thread* thread, size_t size) {\n-  \/\/ We squelch excessive reports to reduce noise in logs.\n-  const size_t MaxReportsPerEpoch = 4;\n-  static size_t last_report_epoch = 0;\n-  static size_t epoch_report_count = 0;\n-\n-  size_t promotion_reserve;\n-  size_t promotion_expended;\n-\n-  size_t gc_id = control_thread()->get_gc_id();\n-\n-  if ((gc_id != last_report_epoch) || (epoch_report_count++ < MaxReportsPerEpoch)) {\n-    {\n-      \/\/ Promotion failures should be very rare.  Invest in providing useful diagnostic info.\n-      ShenandoahHeapLocker locker(lock());\n-      promotion_reserve = get_promoted_reserve();\n-      promotion_expended = get_promoted_expended();\n-    }\n-    PLAB* plab = ShenandoahThreadLocalData::plab(thread);\n-    size_t words_remaining = (plab == nullptr)? 0: plab->words_remaining();\n-    const char* promote_enabled = ShenandoahThreadLocalData::allow_plab_promotions(thread)? \"enabled\": \"disabled\";\n-    ShenandoahGeneration* old_gen = old_generation();\n-    size_t old_capacity = old_gen->max_capacity();\n-    size_t old_usage = old_gen->used();\n-    size_t old_free_regions = old_gen->free_unaffiliated_regions();\n-\n-    log_info(gc, ergo)(\"Promotion failed, size \" SIZE_FORMAT \", has plab? %s, PLAB remaining: \" SIZE_FORMAT\n-                       \", plab promotions %s, promotion reserve: \" SIZE_FORMAT \", promotion expended: \" SIZE_FORMAT\n-                       \", old capacity: \" SIZE_FORMAT \", old_used: \" SIZE_FORMAT \", old unaffiliated regions: \" SIZE_FORMAT,\n-                       size * HeapWordSize, plab == nullptr? \"no\": \"yes\",\n-                       words_remaining * HeapWordSize, promote_enabled, promotion_reserve, promotion_expended,\n-                       old_capacity, old_usage, old_free_regions);\n-\n-    if ((gc_id == last_report_epoch) && (epoch_report_count >= MaxReportsPerEpoch)) {\n-      log_info(gc, ergo)(\"Squelching additional promotion failure reports for current epoch\");\n-    } else if (gc_id != last_report_epoch) {\n-      last_report_epoch = gc_id;\n-      epoch_report_count = 1;\n-    }\n-  }\n-}\n-\n@@ -1202,1 +1130,1 @@\n-    unexpend_promoted(not_promoted);\n+    old_generation()->unexpend_promoted(not_promoted);\n@@ -1243,102 +1171,0 @@\n-\/\/ Make sure old-generation is large enough, but no larger than is necessary, to hold mixed evacuations\n-\/\/ and promotions, if we anticipate either. Any deficit is provided by the young generation, subject to\n-\/\/ xfer_limit, and any surplus is transferred to the young generation.\n-\/\/ xfer_limit is the maximum we're able to transfer from young to old.\n-void ShenandoahHeap::compute_old_generation_balance(size_t old_xfer_limit, size_t old_cset_regions) {\n-\n-  \/\/ We can limit the old reserve to the size of anticipated promotions:\n-  \/\/ max_old_reserve is an upper bound on memory evacuated from old and promoted to old,\n-  \/\/ clamped by the old generation space available.\n-  \/\/\n-  \/\/ Here's the algebra.\n-  \/\/ Let SOEP = ShenandoahOldEvacRatioPercent,\n-  \/\/     OE = old evac,\n-  \/\/     YE = young evac, and\n-  \/\/     TE = total evac = OE + YE\n-  \/\/ By definition:\n-  \/\/            SOEP\/100 = OE\/TE\n-  \/\/                     = OE\/(OE+YE)\n-  \/\/  => SOEP\/(100-SOEP) = OE\/((OE+YE)-OE)      \/\/ componendo-dividendo: If a\/b = c\/d, then a\/(b-a) = c\/(d-c)\n-  \/\/                     = OE\/YE\n-  \/\/  =>              OE = YE*SOEP\/(100-SOEP)\n-\n-  \/\/ We have to be careful in the event that SOEP is set to 100 by the user.\n-  assert(ShenandoahOldEvacRatioPercent <= 100, \"Error\");\n-  const size_t old_available = old_generation()->available();\n-  \/\/ The free set will reserve this amount of memory to hold young evacuations\n-  const size_t young_reserve = (young_generation()->max_capacity() * ShenandoahEvacReserve) \/ 100;\n-\n-  \/\/ In the case that ShenandoahOldEvacRatioPercent equals 100, max_old_reserve is limited only by xfer_limit.\n-\n-  const size_t bound_on_old_reserve = old_available + old_xfer_limit + young_reserve;\n-  const size_t max_old_reserve = (ShenandoahOldEvacRatioPercent == 100)?\n-    bound_on_old_reserve: MIN2((young_reserve * ShenandoahOldEvacRatioPercent) \/ (100 - ShenandoahOldEvacRatioPercent),\n-                               bound_on_old_reserve);\n-\n-  const size_t region_size_bytes = ShenandoahHeapRegion::region_size_bytes();\n-\n-  \/\/ Decide how much old space we should reserve for a mixed collection\n-  size_t reserve_for_mixed = 0;\n-  const size_t mixed_candidates = old_heuristics()->unprocessed_old_collection_candidates();\n-  const bool doing_mixed = (mixed_candidates > 0);\n-  if (doing_mixed) {\n-    \/\/ We want this much memory to be unfragmented in order to reliably evacuate old.  This is conservative because we\n-    \/\/ may not evacuate the entirety of unprocessed candidates in a single mixed evacuation.\n-    size_t max_evac_need = (size_t)\n-      (old_heuristics()->unprocessed_old_collection_candidates_live_memory() * ShenandoahOldEvacWaste);\n-    assert(old_available >= old_generation()->free_unaffiliated_regions() * region_size_bytes,\n-           \"Unaffiliated available must be less than total available\");\n-    size_t old_fragmented_available =\n-      old_available - old_generation()->free_unaffiliated_regions() * region_size_bytes;\n-    reserve_for_mixed = max_evac_need + old_fragmented_available;\n-    if (reserve_for_mixed > max_old_reserve) {\n-      reserve_for_mixed = max_old_reserve;\n-    }\n-  }\n-\n-  \/\/ Decide how much space we should reserve for promotions from young\n-  size_t reserve_for_promo = 0;\n-  const size_t promo_load = get_promotion_potential();\n-  const bool doing_promotions = promo_load > 0;\n-  if (doing_promotions) {\n-    \/\/ We're promoting and have a bound on the maximum amount that can be promoted\n-    assert(max_old_reserve >= reserve_for_mixed, \"Sanity\");\n-    const size_t available_for_promotions = max_old_reserve - reserve_for_mixed;\n-    reserve_for_promo = MIN2((size_t)(promo_load * ShenandoahPromoEvacWaste), available_for_promotions);\n-  }\n-\n-  \/\/ This is the total old we want to ideally reserve\n-  const size_t old_reserve = reserve_for_mixed + reserve_for_promo;\n-  assert(old_reserve <= max_old_reserve, \"cannot reserve more than max for old evacuations\");\n-\n-  \/\/ We now check if the old generation is running a surplus or a deficit.\n-  size_t old_region_deficit = 0;\n-  size_t old_region_surplus = 0;\n-\n-  const size_t max_old_available = old_generation()->available() + old_cset_regions * region_size_bytes;\n-  if (max_old_available >= old_reserve) {\n-    \/\/ We are running a surplus, so the old region surplus can go to young\n-    const size_t old_surplus = max_old_available - old_reserve;\n-    old_region_surplus = old_surplus \/ region_size_bytes;\n-    const size_t unaffiliated_old_regions = old_generation()->free_unaffiliated_regions() + old_cset_regions;\n-    old_region_surplus = MIN2(old_region_surplus, unaffiliated_old_regions);\n-  } else {\n-    \/\/ We are running a deficit which we'd like to fill from young.\n-    \/\/ Ignore that this will directly impact young_generation()->max_capacity(),\n-    \/\/ indirectly impacting young_reserve and old_reserve.  These computations are conservative.\n-    const size_t old_need = old_reserve - max_old_available;\n-    \/\/ The old region deficit (rounded up) will come from young\n-    old_region_deficit = (old_need + region_size_bytes - 1) \/ region_size_bytes;\n-\n-    \/\/ Round down the regions we can transfer from young to old. If we're running short\n-    \/\/ on young-gen memory, we restrict the xfer. Old-gen collection activities will be\n-    \/\/ curtailed if the budget is restricted.\n-    const size_t max_old_region_xfer = old_xfer_limit \/ region_size_bytes;\n-    old_region_deficit = MIN2(old_region_deficit, max_old_region_xfer);\n-  }\n-  assert(old_region_deficit == 0 || old_region_surplus == 0, \"Only surplus or deficit, never both\");\n-\n-  set_old_region_surplus(old_region_surplus);\n-  set_old_region_deficit(old_region_deficit);\n-}\n-\n@@ -1515,2 +1341,2 @@\n-          size_t promotion_avail = get_promoted_reserve();\n-          size_t promotion_expended = get_promoted_expended();\n+          size_t promotion_avail = old_generation()->get_promoted_reserve();\n+          size_t promotion_expended = old_generation()->get_promoted_expended();\n@@ -1519,1 +1345,1 @@\n-            if (get_old_evac_reserve() == 0) {\n+            if (old_generation()->get_evacuation_reserve() == 0) {\n@@ -1530,2 +1356,2 @@\n-          size_t promotion_avail = get_promoted_reserve();\n-          size_t promotion_expended = get_promoted_expended();\n+          size_t promotion_avail = old_generation()->get_promoted_reserve();\n+          size_t promotion_expended = old_generation()->get_promoted_expended();\n@@ -1562,1 +1388,1 @@\n-              if (get_promoted_expended() + actual_size <= get_promoted_reserve()) {\n+              if (old_generation()->get_promoted_expended() + actual_size <= old_generation()->get_promoted_reserve()) {\n@@ -1566,2 +1392,1 @@\n-                expend_promoted(actual_size);\n-                assert(get_promoted_expended() <= get_promoted_reserve(), \"Do not expend more promotion than budgeted\");\n+                old_generation()->expend_promoted(actual_size);\n@@ -1582,2 +1407,1 @@\n-            expend_promoted(requested_bytes);\n-            assert(get_promoted_expended() <= get_promoted_reserve(), \"Do not expend more promotion than budgeted\");\n+            old_generation()->expend_promoted(requested_bytes);\n@@ -1872,0 +1696,177 @@\n+\/\/ try_evacuate_object registers the object and dirties the associated remembered set information when evacuating\n+\/\/ to OLD_GENERATION.\n+oop ShenandoahHeap::try_evacuate_object(oop p, Thread* thread, ShenandoahHeapRegion* from_region,\n+                                               ShenandoahAffiliation target_gen) {\n+  bool alloc_from_lab = true;\n+  bool has_plab = false;\n+  HeapWord* copy = nullptr;\n+  size_t size = p->size();\n+  bool is_promotion = (target_gen == OLD_GENERATION) && from_region->is_young();\n+\n+#ifdef ASSERT\n+  if (ShenandoahOOMDuringEvacALot &&\n+      (os::random() & 1) == 0) { \/\/ Simulate OOM every ~2nd slow-path call\n+    copy = nullptr;\n+  } else {\n+#endif\n+    if (UseTLAB) {\n+      switch (target_gen) {\n+        case YOUNG_GENERATION: {\n+          copy = allocate_from_gclab(thread, size);\n+          if ((copy == nullptr) && (size < ShenandoahThreadLocalData::gclab_size(thread))) {\n+            \/\/ GCLAB allocation failed because we are bumping up against the limit on young evacuation reserve.  Try resetting\n+            \/\/ the desired GCLAB size and retry GCLAB allocation to avoid cascading of shared memory allocations.\n+            ShenandoahThreadLocalData::set_gclab_size(thread, PLAB::min_size());\n+            copy = allocate_from_gclab(thread, size);\n+            \/\/ If we still get nullptr, we'll try a shared allocation below.\n+          }\n+          break;\n+        }\n+        case OLD_GENERATION: {\n+          PLAB* plab = ShenandoahThreadLocalData::plab(thread);\n+          if (plab != nullptr) {\n+            has_plab = true;\n+          }\n+          copy = allocate_from_plab(thread, size, is_promotion);\n+          if ((copy == nullptr) && (size < ShenandoahThreadLocalData::plab_size(thread)) &&\n+              ShenandoahThreadLocalData::plab_retries_enabled(thread)) {\n+            \/\/ PLAB allocation failed because we are bumping up against the limit on old evacuation reserve or because\n+            \/\/ the requested object does not fit within the current plab but the plab still has an \"abundance\" of memory,\n+            \/\/ where abundance is defined as >= PLAB::min_size().  In the former case, we try resetting the desired\n+            \/\/ PLAB size and retry PLAB allocation to avoid cascading of shared memory allocations.\n+\n+            \/\/ In this situation, PLAB memory is precious.  We'll try to preserve our existing PLAB by forcing\n+            \/\/ this particular allocation to be shared.\n+            if (plab->words_remaining() < PLAB::min_size()) {\n+              ShenandoahThreadLocalData::set_plab_size(thread, PLAB::min_size());\n+              copy = allocate_from_plab(thread, size, is_promotion);\n+              \/\/ If we still get nullptr, we'll try a shared allocation below.\n+              if (copy == nullptr) {\n+                \/\/ If retry fails, don't continue to retry until we have success (probably in next GC pass)\n+                ShenandoahThreadLocalData::disable_plab_retries(thread);\n+              }\n+            }\n+            \/\/ else, copy still equals nullptr.  this causes shared allocation below, preserving this plab for future needs.\n+          }\n+          break;\n+        }\n+        default: {\n+          ShouldNotReachHere();\n+          break;\n+        }\n+      }\n+    }\n+\n+    if (copy == nullptr) {\n+      \/\/ If we failed to allocate in LAB, we'll try a shared allocation.\n+      if (!is_promotion || !has_plab || (size > PLAB::min_size())) {\n+        ShenandoahAllocRequest req = ShenandoahAllocRequest::for_shared_gc(size, target_gen);\n+        copy = allocate_memory(req, is_promotion);\n+        alloc_from_lab = false;\n+      }\n+      \/\/ else, we leave copy equal to nullptr, signaling a promotion failure below if appropriate.\n+      \/\/ We choose not to promote objects smaller than PLAB::min_size() by way of shared allocations, as this is too\n+      \/\/ costly.  Instead, we'll simply \"evacuate\" to young-gen memory (using a GCLAB) and will promote in a future\n+      \/\/ evacuation pass.  This condition is denoted by: is_promotion && has_plab && (size <= PLAB::min_size())\n+    }\n+#ifdef ASSERT\n+  }\n+#endif\n+\n+  if (copy == nullptr) {\n+    if (target_gen == OLD_GENERATION) {\n+      assert(mode()->is_generational(), \"Should only be here in generational mode.\");\n+      if (from_region->is_young()) {\n+        \/\/ Signal that promotion failed. Will evacuate this old object somewhere in young gen.\n+        old_generation()->handle_failed_promotion(thread, size);\n+        return nullptr;\n+      } else {\n+        \/\/ Remember that evacuation to old gen failed. We'll want to trigger a full gc to recover from this\n+        \/\/ after the evacuation threads have finished.\n+        old_generation()->handle_failed_evacuation();\n+      }\n+    }\n+\n+    control_thread()->handle_alloc_failure_evac(size);\n+\n+    _oom_evac_handler.handle_out_of_memory_during_evacuation();\n+\n+    return ShenandoahBarrierSet::resolve_forwarded(p);\n+  }\n+\n+  \/\/ Copy the object:\n+  _evac_tracker->begin_evacuation(thread, size * HeapWordSize);\n+  Copy::aligned_disjoint_words(cast_from_oop<HeapWord*>(p), copy, size);\n+\n+  oop copy_val = cast_to_oop(copy);\n+\n+  if (mode()->is_generational() && target_gen == YOUNG_GENERATION && is_aging_cycle()) {\n+    ShenandoahHeap::increase_object_age(copy_val, from_region->age() + 1);\n+  }\n+\n+  \/\/ Try to install the new forwarding pointer.\n+  ContinuationGCSupport::relativize_stack_chunk(copy_val);\n+\n+  oop result = ShenandoahForwarding::try_update_forwardee(p, copy_val);\n+  if (result == copy_val) {\n+    \/\/ Successfully evacuated. Our copy is now the public one!\n+    _evac_tracker->end_evacuation(thread, size * HeapWordSize);\n+    if (mode()->is_generational()) {\n+      if (target_gen == OLD_GENERATION) {\n+        old_generation()->handle_evacuation(copy, size, from_region->is_young());\n+      } else {\n+        \/\/ When copying to the old generation above, we don't care\n+        \/\/ about recording object age in the census stats.\n+        assert(target_gen == YOUNG_GENERATION, \"Error\");\n+        \/\/ We record this census only when simulating pre-adaptive tenuring behavior, or\n+        \/\/ when we have been asked to record the census at evacuation rather than at mark\n+        if (ShenandoahGenerationalCensusAtEvac || !ShenandoahGenerationalAdaptiveTenuring) {\n+          _evac_tracker->record_age(thread, size * HeapWordSize, ShenandoahHeap::get_object_age(copy_val));\n+        }\n+      }\n+    }\n+    shenandoah_assert_correct(nullptr, copy_val);\n+    return copy_val;\n+  }  else {\n+    \/\/ Failed to evacuate. We need to deal with the object that is left behind. Since this\n+    \/\/ new allocation is certainly after TAMS, it will be considered live in the next cycle.\n+    \/\/ But if it happens to contain references to evacuated regions, those references would\n+    \/\/ not get updated for this stale copy during this cycle, and we will crash while scanning\n+    \/\/ it the next cycle.\n+    if (alloc_from_lab) {\n+      \/\/ For LAB allocations, it is enough to rollback the allocation ptr. Either the next\n+      \/\/ object will overwrite this stale copy, or the filler object on LAB retirement will\n+      \/\/ do this.\n+      switch (target_gen) {\n+        case YOUNG_GENERATION: {\n+          ShenandoahThreadLocalData::gclab(thread)->undo_allocation(copy, size);\n+          break;\n+        }\n+        case OLD_GENERATION: {\n+          ShenandoahThreadLocalData::plab(thread)->undo_allocation(copy, size);\n+          if (is_promotion) {\n+            ShenandoahThreadLocalData::subtract_from_plab_promoted(thread, size * HeapWordSize);\n+          } else {\n+            ShenandoahThreadLocalData::subtract_from_plab_evacuated(thread, size * HeapWordSize);\n+          }\n+          break;\n+        }\n+        default: {\n+          ShouldNotReachHere();\n+          break;\n+        }\n+      }\n+    } else {\n+      \/\/ For non-LAB allocations, we have no way to retract the allocation, and\n+      \/\/ have to explicitly overwrite the copy with the filler object. With that overwrite,\n+      \/\/ we have to keep the fwdptr initialized and pointing to our (stale) copy.\n+      assert(size >= ShenandoahHeap::min_fill_size(), \"previously allocated object known to be larger than min_size\");\n+      fill_with_object(copy, size);\n+      shenandoah_assert_correct(nullptr, copy_val);\n+      \/\/ For non-LAB allocations, the object has already been registered\n+    }\n+    shenandoah_assert_correct(nullptr, result);\n+    return result;\n+  }\n+}\n+\n@@ -2500,4 +2501,0 @@\n-void ShenandoahHeap::set_evacuation_reserve_quantities(bool is_valid) {\n-  _has_evacuation_reserve_quantities = is_valid;\n-}\n-\n@@ -3181,1 +3178,1 @@\n-    compute_old_generation_balance(allocation_runway, old_cset_regions);\n+    ShenandoahGenerationalHeap::heap()->compute_old_generation_balance(allocation_runway, old_cset_regions);\n@@ -3342,12 +3339,3 @@\n-  if (mode()->is_generational()) {\n-    _young_gen_memory_pool = new ShenandoahYoungGenMemoryPool(this);\n-    _old_gen_memory_pool = new ShenandoahOldGenMemoryPool(this);\n-    _cycle_memory_manager.add_pool(_young_gen_memory_pool);\n-    _cycle_memory_manager.add_pool(_old_gen_memory_pool);\n-    _stw_memory_manager.add_pool(_young_gen_memory_pool);\n-    _stw_memory_manager.add_pool(_old_gen_memory_pool);\n-  } else {\n-    _memory_pool = new ShenandoahMemoryPool(this);\n-    _cycle_memory_manager.add_pool(_memory_pool);\n-    _stw_memory_manager.add_pool(_memory_pool);\n-  }\n+  _memory_pool = new ShenandoahMemoryPool(this);\n+  _cycle_memory_manager.add_pool(_memory_pool);\n+  _stw_memory_manager.add_pool(_memory_pool);\n@@ -3365,6 +3353,1 @@\n-  if (mode()->is_generational()) {\n-    memory_pools.append(_young_gen_memory_pool);\n-    memory_pools.append(_old_gen_memory_pool);\n-  } else {\n-    memory_pools.append(_memory_pool);\n-  }\n+  memory_pools.append(_memory_pool);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":192,"deletions":209,"binary":false,"changes":401,"status":"modified"},{"patch":"@@ -226,4 +226,0 @@\n-  size_t _promotion_potential;\n-  size_t _pad_for_promote_in_place;    \/\/ bytes of filler\n-  size_t _promotable_humongous_regions;\n-  size_t _regular_regions_promoted_in_place;\n@@ -372,15 +368,0 @@\n-  \/\/ TODO: Revisit the following comment.  It may not accurately represent the true behavior when evacuations fail due to\n-  \/\/ difficulty finding memory to hold evacuated objects.\n-  \/\/\n-  \/\/ Note that the typical total expenditure on evacuation is less than the associated evacuation reserve because we generally\n-  \/\/ reserve ShenandoahEvacWaste (> 1.0) times the anticipated evacuation need.  In the case that there is an excessive amount\n-  \/\/ of waste, it may be that one thread fails to grab a new GCLAB, this does not necessarily doom the associated evacuation\n-  \/\/ effort.  If this happens, the requesting thread blocks until some other thread manages to evacuate the offending object.\n-  \/\/ Only after \"all\" threads fail to evacuate an object do we consider the evacuation effort to have failed.\n-\n-  size_t _promoted_reserve;            \/\/ Bytes reserved within old-gen to hold the results of promotion\n-  volatile size_t _promoted_expended;  \/\/ Bytes of old-gen memory expended on promotions\n-\n-  size_t _old_evac_reserve;            \/\/ Bytes reserved within old-gen to hold evacuated objects from old-gen collection set\n-  size_t _young_evac_reserve;          \/\/ Bytes reserved within young-gen to hold evacuated objects from young-gen collection set\n-\n@@ -389,14 +370,0 @@\n-  \/\/ At the end of final mark, but before we begin evacuating, heuristics calculate how much memory is required to\n-  \/\/ hold the results of evacuating to young-gen and to old-gen.  These quantitites, stored in _promoted_reserve,\n-  \/\/ _old_evac_reserve, and _young_evac_reserve, are consulted prior to rebuilding the free set (ShenandoahFreeSet)\n-  \/\/ in preparation for evacuation.  When the free set is rebuilt, we make sure to reserve sufficient memory in the\n-  \/\/ collector and old_collector sets to hold if _has_evacuation_reserve_quantities is true.  The other time we\n-  \/\/ rebuild the freeset is at the end of GC, as we prepare to idle GC until the next trigger.  In this case,\n-  \/\/ _has_evacuation_reserve_quantities is false because we don't yet know how much memory will need to be evacuated\n-  \/\/ in the next GC cycle.  When _has_evacuation_reserve_quantities is false, the free set rebuild operation reserves\n-  \/\/ for the collector and old_collector sets based on alternative mechanisms, such as ShenandoahEvacReserve,\n-  \/\/ ShenandoahOldEvacReserve, and ShenandoahOldCompactionReserve.  In a future planned enhancement, the reserve\n-  \/\/ for old_collector set when not _has_evacuation_reserve_quantities is based in part on anticipated promotion as\n-  \/\/ determined by analysis of live data found during the previous GC pass which is one less than the current tenure age.\n-  bool _has_evacuation_reserve_quantities;\n-\n@@ -420,1 +387,0 @@\n-  void set_evacuation_reserve_quantities(bool is_valid);\n@@ -436,1 +402,1 @@\n-  inline bool has_evacuation_reserve_quantities() const;\n+\n@@ -453,34 +419,0 @@\n-  inline void clear_promotion_potential() { _promotion_potential = 0; };\n-  inline void set_promotion_potential(size_t val) { _promotion_potential = val; };\n-  inline size_t get_promotion_potential() { return _promotion_potential; };\n-\n-  inline void set_pad_for_promote_in_place(size_t pad) { _pad_for_promote_in_place = pad; }\n-  inline size_t get_pad_for_promote_in_place() { return _pad_for_promote_in_place; }\n-\n-  inline void reserve_promotable_humongous_regions(size_t region_count) { _promotable_humongous_regions = region_count; }\n-  inline void reserve_promotable_regular_regions(size_t region_count) { _regular_regions_promoted_in_place = region_count; }\n-\n-  inline size_t get_promotable_humongous_regions() { return _promotable_humongous_regions; }\n-  inline size_t get_regular_regions_promoted_in_place() { return _regular_regions_promoted_in_place; }\n-\n-  \/\/ Returns previous value\n-  inline size_t set_promoted_reserve(size_t new_val);\n-  inline size_t get_promoted_reserve() const;\n-  inline void augment_promo_reserve(size_t increment);\n-\n-  inline void reset_promoted_expended();\n-  inline size_t expend_promoted(size_t increment);\n-  inline size_t unexpend_promoted(size_t decrement);\n-  inline size_t get_promoted_expended();\n-\n-  \/\/ Returns previous value\n-  inline size_t set_old_evac_reserve(size_t new_val);\n-  inline size_t get_old_evac_reserve() const;\n-  inline void augment_old_evac_reserve(size_t increment);\n-\n-  \/\/ Returns previous value\n-  inline size_t set_young_evac_reserve(size_t new_val);\n-  inline size_t get_young_evac_reserve() const;\n-\n-  inline void reset_generation_reserves();\n-\n@@ -593,1 +525,1 @@\n-  ShenandoahEvacuationTracker* evac_tracker()    const { return  _evac_tracker;     }\n+  ShenandoahEvacuationTracker* evac_tracker()    const { return _evac_tracker;      }\n@@ -605,3 +537,0 @@\n-  MemoryPool*                  _young_gen_memory_pool;\n-  MemoryPool*                  _old_gen_memory_pool;\n-\n@@ -723,4 +652,0 @@\n-  \/\/ How many bytes to transfer between old and young after we have finished recycling collection set regions?\n-  size_t _old_regions_surplus;\n-  size_t _old_regions_deficit;\n-\n@@ -758,6 +683,0 @@\n-  inline void set_old_region_surplus(size_t surplus) { _old_regions_surplus = surplus; };\n-  inline void set_old_region_deficit(size_t deficit) { _old_regions_deficit = deficit; };\n-\n-  inline size_t get_old_region_surplus() { return _old_regions_surplus; };\n-  inline size_t get_old_region_deficit() { return _old_regions_deficit; };\n-\n@@ -817,5 +736,0 @@\n-  ShenandoahSharedFlag _old_gen_oom_evac;\n-\n-  inline oop try_evacuate_object(oop src, Thread* thread, ShenandoahHeapRegion* from_region, ShenandoahAffiliation target_gen);\n-  void handle_old_evacuation(HeapWord* obj, size_t words, bool promotion);\n-  void handle_old_evacuation_failure();\n@@ -823,0 +737,1 @@\n+  oop try_evacuate_object(oop src, Thread* thread, ShenandoahHeapRegion* from_region, ShenandoahAffiliation target_gen);\n@@ -824,1 +739,0 @@\n-  void report_promotion_failure(Thread* thread, size_t size);\n@@ -844,2 +758,0 @@\n-  inline bool clear_old_evacuation_failure();\n-\n@@ -859,2 +771,0 @@\n-  void compute_old_generation_balance(size_t old_xfer_limit, size_t old_cset_regions);\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.hpp","additions":3,"deletions":93,"binary":false,"changes":96,"status":"modified"},{"patch":"@@ -46,1 +46,0 @@\n-#include \"gc\/shenandoah\/shenandoahScanRemembered.inline.hpp\"\n@@ -375,177 +374,0 @@\n-\/\/ try_evacuate_object registers the object and dirties the associated remembered set information when evacuating\n-\/\/ to OLD_GENERATION.\n-inline oop ShenandoahHeap::try_evacuate_object(oop p, Thread* thread, ShenandoahHeapRegion* from_region,\n-                                               ShenandoahAffiliation target_gen) {\n-  bool alloc_from_lab = true;\n-  bool has_plab = false;\n-  HeapWord* copy = nullptr;\n-  size_t size = p->size();\n-  bool is_promotion = (target_gen == OLD_GENERATION) && from_region->is_young();\n-\n-#ifdef ASSERT\n-  if (ShenandoahOOMDuringEvacALot &&\n-      (os::random() & 1) == 0) { \/\/ Simulate OOM every ~2nd slow-path call\n-        copy = nullptr;\n-  } else {\n-#endif\n-    if (UseTLAB) {\n-      switch (target_gen) {\n-        case YOUNG_GENERATION: {\n-           copy = allocate_from_gclab(thread, size);\n-           if ((copy == nullptr) && (size < ShenandoahThreadLocalData::gclab_size(thread))) {\n-             \/\/ GCLAB allocation failed because we are bumping up against the limit on young evacuation reserve.  Try resetting\n-             \/\/ the desired GCLAB size and retry GCLAB allocation to avoid cascading of shared memory allocations.\n-             ShenandoahThreadLocalData::set_gclab_size(thread, PLAB::min_size());\n-             copy = allocate_from_gclab(thread, size);\n-             \/\/ If we still get nullptr, we'll try a shared allocation below.\n-           }\n-           break;\n-        }\n-        case OLD_GENERATION: {\n-           PLAB* plab = ShenandoahThreadLocalData::plab(thread);\n-           if (plab != nullptr) {\n-             has_plab = true;\n-           }\n-           copy = allocate_from_plab(thread, size, is_promotion);\n-           if ((copy == nullptr) && (size < ShenandoahThreadLocalData::plab_size(thread)) &&\n-               ShenandoahThreadLocalData::plab_retries_enabled(thread)) {\n-             \/\/ PLAB allocation failed because we are bumping up against the limit on old evacuation reserve or because\n-             \/\/ the requested object does not fit within the current plab but the plab still has an \"abundance\" of memory,\n-             \/\/ where abundance is defined as >= PLAB::min_size().  In the former case, we try resetting the desired\n-             \/\/ PLAB size and retry PLAB allocation to avoid cascading of shared memory allocations.\n-\n-             \/\/ In this situation, PLAB memory is precious.  We'll try to preserve our existing PLAB by forcing\n-             \/\/ this particular allocation to be shared.\n-             if (plab->words_remaining() < PLAB::min_size()) {\n-               ShenandoahThreadLocalData::set_plab_size(thread, PLAB::min_size());\n-               copy = allocate_from_plab(thread, size, is_promotion);\n-               \/\/ If we still get nullptr, we'll try a shared allocation below.\n-               if (copy == nullptr) {\n-                 \/\/ If retry fails, don't continue to retry until we have success (probably in next GC pass)\n-                 ShenandoahThreadLocalData::disable_plab_retries(thread);\n-               }\n-             }\n-             \/\/ else, copy still equals nullptr.  this causes shared allocation below, preserving this plab for future needs.\n-           }\n-           break;\n-        }\n-        default: {\n-          ShouldNotReachHere();\n-          break;\n-        }\n-      }\n-    }\n-\n-    if (copy == nullptr) {\n-      \/\/ If we failed to allocate in LAB, we'll try a shared allocation.\n-      if (!is_promotion || !has_plab || (size > PLAB::min_size())) {\n-        ShenandoahAllocRequest req = ShenandoahAllocRequest::for_shared_gc(size, target_gen);\n-        copy = allocate_memory(req, is_promotion);\n-        alloc_from_lab = false;\n-      }\n-      \/\/ else, we leave copy equal to nullptr, signaling a promotion failure below if appropriate.\n-      \/\/ We choose not to promote objects smaller than PLAB::min_size() by way of shared allocations, as this is too\n-      \/\/ costly.  Instead, we'll simply \"evacuate\" to young-gen memory (using a GCLAB) and will promote in a future\n-      \/\/ evacuation pass.  This condition is denoted by: is_promotion && has_plab && (size <= PLAB::min_size())\n-    }\n-#ifdef ASSERT\n-  }\n-#endif\n-\n-  if (copy == nullptr) {\n-    if (target_gen == OLD_GENERATION) {\n-      assert(mode()->is_generational(), \"Should only be here in generational mode.\");\n-      if (from_region->is_young()) {\n-        \/\/ Signal that promotion failed. Will evacuate this old object somewhere in young gen.\n-        report_promotion_failure(thread, size);\n-        return nullptr;\n-      } else {\n-        \/\/ Remember that evacuation to old gen failed. We'll want to trigger a full gc to recover from this\n-        \/\/ after the evacuation threads have finished.\n-        handle_old_evacuation_failure();\n-      }\n-    }\n-\n-    control_thread()->handle_alloc_failure_evac(size);\n-\n-    _oom_evac_handler.handle_out_of_memory_during_evacuation();\n-\n-    return ShenandoahBarrierSet::resolve_forwarded(p);\n-  }\n-\n-  \/\/ Copy the object:\n-  _evac_tracker->begin_evacuation(thread, size * HeapWordSize);\n-  Copy::aligned_disjoint_words(cast_from_oop<HeapWord*>(p), copy, size);\n-\n-  oop copy_val = cast_to_oop(copy);\n-\n-  if (mode()->is_generational() && target_gen == YOUNG_GENERATION && is_aging_cycle()) {\n-    ShenandoahHeap::increase_object_age(copy_val, from_region->age() + 1);\n-  }\n-\n-  \/\/ Try to install the new forwarding pointer.\n-  ContinuationGCSupport::relativize_stack_chunk(copy_val);\n-\n-  oop result = ShenandoahForwarding::try_update_forwardee(p, copy_val);\n-  if (result == copy_val) {\n-    \/\/ Successfully evacuated. Our copy is now the public one!\n-    _evac_tracker->end_evacuation(thread, size * HeapWordSize);\n-    if (mode()->is_generational()) {\n-      if (target_gen == OLD_GENERATION) {\n-        handle_old_evacuation(copy, size, from_region->is_young());\n-      } else {\n-        \/\/ When copying to the old generation above, we don't care\n-        \/\/ about recording object age in the census stats.\n-        assert(target_gen == YOUNG_GENERATION, \"Error\");\n-        \/\/ We record this census only when simulating pre-adaptive tenuring behavior, or\n-        \/\/ when we have been asked to record the census at evacuation rather than at mark\n-        if (ShenandoahGenerationalCensusAtEvac || !ShenandoahGenerationalAdaptiveTenuring) {\n-          _evac_tracker->record_age(thread, size * HeapWordSize, ShenandoahHeap::get_object_age(copy_val));\n-        }\n-      }\n-    }\n-    shenandoah_assert_correct(nullptr, copy_val);\n-    return copy_val;\n-  }  else {\n-    \/\/ Failed to evacuate. We need to deal with the object that is left behind. Since this\n-    \/\/ new allocation is certainly after TAMS, it will be considered live in the next cycle.\n-    \/\/ But if it happens to contain references to evacuated regions, those references would\n-    \/\/ not get updated for this stale copy during this cycle, and we will crash while scanning\n-    \/\/ it the next cycle.\n-    if (alloc_from_lab) {\n-       \/\/ For LAB allocations, it is enough to rollback the allocation ptr. Either the next\n-       \/\/ object will overwrite this stale copy, or the filler object on LAB retirement will\n-       \/\/ do this.\n-       switch (target_gen) {\n-         case YOUNG_GENERATION: {\n-             ShenandoahThreadLocalData::gclab(thread)->undo_allocation(copy, size);\n-            break;\n-         }\n-         case OLD_GENERATION: {\n-            ShenandoahThreadLocalData::plab(thread)->undo_allocation(copy, size);\n-            if (is_promotion) {\n-              ShenandoahThreadLocalData::subtract_from_plab_promoted(thread, size * HeapWordSize);\n-            } else {\n-              ShenandoahThreadLocalData::subtract_from_plab_evacuated(thread, size * HeapWordSize);\n-            }\n-            break;\n-         }\n-         default: {\n-           ShouldNotReachHere();\n-           break;\n-         }\n-       }\n-    } else {\n-      \/\/ For non-LAB allocations, we have no way to retract the allocation, and\n-      \/\/ have to explicitly overwrite the copy with the filler object. With that overwrite,\n-      \/\/ we have to keep the fwdptr initialized and pointing to our (stale) copy.\n-      assert(size >= ShenandoahHeap::min_fill_size(), \"previously allocated object known to be larger than min_size\");\n-      fill_with_object(copy, size);\n-      shenandoah_assert_correct(nullptr, copy_val);\n-      \/\/ For non-LAB allocations, the object has already been registered\n-    }\n-    shenandoah_assert_correct(nullptr, result);\n-    return result;\n-  }\n-}\n-\n@@ -600,4 +422,0 @@\n-inline bool ShenandoahHeap::clear_old_evacuation_failure() {\n-  return _old_gen_oom_evac.try_unset();\n-}\n-\n@@ -712,4 +530,0 @@\n-inline bool ShenandoahHeap::has_evacuation_reserve_quantities() const {\n-  return _has_evacuation_reserve_quantities;\n-}\n-\n@@ -768,60 +582,0 @@\n-inline size_t ShenandoahHeap::set_promoted_reserve(size_t new_val) {\n-  size_t orig = _promoted_reserve;\n-  _promoted_reserve = new_val;\n-  return orig;\n-}\n-\n-inline size_t ShenandoahHeap::get_promoted_reserve() const {\n-  return _promoted_reserve;\n-}\n-\n-inline size_t ShenandoahHeap::set_old_evac_reserve(size_t new_val) {\n-  size_t orig = _old_evac_reserve;\n-  _old_evac_reserve = new_val;\n-  return orig;\n-}\n-\n-inline size_t ShenandoahHeap::get_old_evac_reserve() const {\n-  return _old_evac_reserve;\n-}\n-\n-inline void ShenandoahHeap::augment_old_evac_reserve(size_t increment) {\n-  _old_evac_reserve += increment;\n-}\n-\n-inline void ShenandoahHeap::augment_promo_reserve(size_t increment) {\n-  _promoted_reserve += increment;\n-}\n-\n-inline void ShenandoahHeap::reset_promoted_expended() {\n-  Atomic::store(&_promoted_expended, (size_t) 0);\n-}\n-\n-inline size_t ShenandoahHeap::expend_promoted(size_t increment) {\n-  return Atomic::add(&_promoted_expended, increment);\n-}\n-\n-inline size_t ShenandoahHeap::unexpend_promoted(size_t decrement) {\n-  return Atomic::sub(&_promoted_expended, decrement);\n-}\n-\n-inline size_t ShenandoahHeap::get_promoted_expended() {\n-  return Atomic::load(&_promoted_expended);\n-}\n-\n-inline size_t ShenandoahHeap::set_young_evac_reserve(size_t new_val) {\n-  size_t orig = _young_evac_reserve;\n-  _young_evac_reserve = new_val;\n-  return orig;\n-}\n-\n-inline size_t ShenandoahHeap::get_young_evac_reserve() const {\n-  return _young_evac_reserve;\n-}\n-\n-inline void ShenandoahHeap::reset_generation_reserves() {\n-  set_young_evac_reserve(0);\n-  set_old_evac_reserve(0);\n-  set_promoted_reserve(0);\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.inline.hpp","additions":0,"deletions":246,"binary":false,"changes":246,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/shenandoah\/shenandoahGenerationalHeap.hpp\"\n@@ -40,2 +41,0 @@\n-\n-\n@@ -88,1 +87,1 @@\n-  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  auto heap = ShenandoahGenerationalHeap::heap();\n@@ -151,1 +150,1 @@\n-  \/\/ We do not rebuild_free following increments of old marking because memory has not been reclaimed..  However, we may\n+  \/\/ We do not rebuild_free following increments of old marking because memory has not been reclaimed. However, we may\n@@ -156,5 +155,1 @@\n-  bool success;\n-  size_t region_xfer;\n-  const char* region_destination;\n-  ShenandoahYoungGeneration* young_gen = heap->young_generation();\n-  ShenandoahGeneration* old_gen = heap->old_generation();\n+  ShenandoahGenerationalHeap::TransferResult result;\n@@ -163,21 +158,1 @@\n-\n-    size_t old_region_surplus = heap->get_old_region_surplus();\n-    size_t old_region_deficit = heap->get_old_region_deficit();\n-    if (old_region_surplus) {\n-      success = heap->generation_sizer()->transfer_to_young(old_region_surplus);\n-      region_destination = \"young\";\n-      region_xfer = old_region_surplus;\n-    } else if (old_region_deficit) {\n-      success = heap->generation_sizer()->transfer_to_old(old_region_deficit);\n-      region_destination = \"old\";\n-      region_xfer = old_region_deficit;\n-      if (!success) {\n-        ((ShenandoahOldHeuristics *) old_gen->heuristics())->trigger_cannot_expand();\n-      }\n-    } else {\n-      region_destination = \"none\";\n-      region_xfer = 0;\n-      success = true;\n-    }\n-    heap->set_old_region_surplus(0);\n-    heap->set_old_region_deficit(0);\n+    result = heap->balance_generations();\n@@ -186,8 +161,5 @@\n-  \/\/ Report outside the heap lock\n-  size_t young_available = young_gen->available();\n-  size_t old_available = old_gen->available();\n-  log_info(gc, ergo)(\"After old marking finished, %s \" SIZE_FORMAT \" regions to %s to prepare for next gc, old available: \"\n-                     SIZE_FORMAT \"%s, young_available: \" SIZE_FORMAT \"%s\",\n-                     success? \"successfully transferred\": \"failed to transfer\", region_xfer, region_destination,\n-                     byte_size_in_proper_unit(old_available), proper_unit_for_byte_size(old_available),\n-                     byte_size_in_proper_unit(young_available), proper_unit_for_byte_size(young_available));\n+  LogTarget(Info, gc, ergo) lt;\n+  if (lt.is_enabled()) {\n+    LogStream ls(lt);\n+    result.print_on(\"Old Mark\", &ls);\n+  }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahOldGC.cpp","additions":10,"deletions":38,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -30,3 +30,0 @@\n-#include \"gc\/shenandoah\/heuristics\/shenandoahAdaptiveHeuristics.hpp\"\n-#include \"gc\/shenandoah\/heuristics\/shenandoahAggressiveHeuristics.hpp\"\n-#include \"gc\/shenandoah\/heuristics\/shenandoahCompactHeuristics.hpp\"\n@@ -34,1 +31,0 @@\n-#include \"gc\/shenandoah\/heuristics\/shenandoahStaticHeuristics.hpp\"\n@@ -37,0 +33,1 @@\n+#include \"gc\/shenandoah\/shenandoahGenerationalHeap.hpp\"\n@@ -41,1 +38,0 @@\n-#include \"gc\/shenandoah\/shenandoahMark.inline.hpp\"\n@@ -46,1 +42,0 @@\n-#include \"gc\/shenandoah\/shenandoahStringDedup.hpp\"\n@@ -50,1 +45,0 @@\n-#include \"prims\/jvmtiTagMap.hpp\"\n@@ -177,0 +171,9 @@\n+    _old_heuristics(nullptr),\n+    _region_surplus(0),\n+    _region_deficit(0),\n+    _promoted_reserve(0),\n+    _promoted_expended(0),\n+    _promotion_potential(0),\n+    _pad_for_promote_in_place(0),\n+    _promotable_humongous_regions(0),\n+    _promotable_regular_regions(0),\n@@ -186,0 +189,33 @@\n+void ShenandoahOldGeneration::set_promoted_reserve(size_t new_val) {\n+  shenandoah_assert_heaplocked_or_safepoint();\n+  _promoted_reserve = new_val;\n+}\n+\n+size_t ShenandoahOldGeneration::get_promoted_reserve() const {\n+  return _promoted_reserve;\n+}\n+\n+void ShenandoahOldGeneration::augment_promoted_reserve(size_t increment) {\n+  shenandoah_assert_heaplocked_or_safepoint();\n+  _promoted_reserve += increment;\n+}\n+\n+void ShenandoahOldGeneration::reset_promoted_expended() {\n+  shenandoah_assert_heaplocked_or_safepoint();\n+  Atomic::store(&_promoted_expended, (size_t) 0);\n+}\n+\n+size_t ShenandoahOldGeneration::expend_promoted(size_t increment) {\n+  shenandoah_assert_heaplocked_or_safepoint();\n+  assert(get_promoted_expended() + increment <= get_promoted_reserve(), \"Do not expend more promotion than budgeted\");\n+  return Atomic::add(&_promoted_expended, increment);\n+}\n+\n+size_t ShenandoahOldGeneration::unexpend_promoted(size_t decrement) {\n+  return Atomic::sub(&_promoted_expended, decrement);\n+}\n+\n+size_t ShenandoahOldGeneration::get_promoted_expended() {\n+  return Atomic::load(&_promoted_expended);\n+}\n+\n@@ -198,0 +234,4 @@\n+void ShenandoahOldGeneration::handle_failed_transfer() {\n+  _old_heuristics->trigger_cannot_expand();\n+}\n+\n@@ -469,0 +509,64 @@\n+\n+void ShenandoahOldGeneration::handle_failed_evacuation() {\n+  if (_failed_evacuation.try_set()) {\n+    log_info(gc)(\"Old gen evac failure.\");\n+  }\n+}\n+\n+void ShenandoahOldGeneration::handle_failed_promotion(Thread* thread, size_t size) {\n+  \/\/ We squelch excessive reports to reduce noise in logs.\n+  const size_t MaxReportsPerEpoch = 4;\n+  static size_t last_report_epoch = 0;\n+  static size_t epoch_report_count = 0;\n+  auto heap = ShenandoahGenerationalHeap::heap();\n+\n+  size_t promotion_reserve;\n+  size_t promotion_expended;\n+\n+  const size_t gc_id = heap->control_thread()->get_gc_id();\n+\n+  if ((gc_id != last_report_epoch) || (epoch_report_count++ < MaxReportsPerEpoch)) {\n+    {\n+      \/\/ Promotion failures should be very rare.  Invest in providing useful diagnostic info.\n+      ShenandoahHeapLocker locker(heap->lock());\n+      promotion_reserve = get_promoted_reserve();\n+      promotion_expended = get_promoted_expended();\n+    }\n+    PLAB* const plab = ShenandoahThreadLocalData::plab(thread);\n+    const size_t words_remaining = (plab == nullptr)? 0: plab->words_remaining();\n+    const char* promote_enabled = ShenandoahThreadLocalData::allow_plab_promotions(thread)? \"enabled\": \"disabled\";\n+\n+    log_info(gc, ergo)(\"Promotion failed, size \" SIZE_FORMAT \", has plab? %s, PLAB remaining: \" SIZE_FORMAT\n+                       \", plab promotions %s, promotion reserve: \" SIZE_FORMAT \", promotion expended: \" SIZE_FORMAT\n+                       \", old capacity: \" SIZE_FORMAT \", old_used: \" SIZE_FORMAT \", old unaffiliated regions: \" SIZE_FORMAT,\n+                       size * HeapWordSize, plab == nullptr? \"no\": \"yes\",\n+                       words_remaining * HeapWordSize, promote_enabled, promotion_reserve, promotion_expended,\n+                       max_capacity(), used(), free_unaffiliated_regions());\n+\n+    if ((gc_id == last_report_epoch) && (epoch_report_count >= MaxReportsPerEpoch)) {\n+      log_info(gc, ergo)(\"Squelching additional promotion failure reports for current epoch\");\n+    } else if (gc_id != last_report_epoch) {\n+      last_report_epoch = gc_id;\n+      epoch_report_count = 1;\n+    }\n+  }\n+}\n+\n+void ShenandoahOldGeneration::handle_evacuation(HeapWord* obj, size_t words, bool promotion) {\n+  auto heap = ShenandoahGenerationalHeap::heap();\n+  auto card_scan = heap->card_scan();\n+\n+  \/\/ Only register the copy of the object that won the evacuation race.\n+  card_scan->register_object_without_lock(obj);\n+\n+  \/\/ Mark the entire range of the evacuated object as dirty.  At next remembered set scan,\n+  \/\/ we will clear dirty bits that do not hold interesting pointers.  It's more efficient to\n+  \/\/ do this in batch, in a background GC thread than to try to carefully dirty only cards\n+  \/\/ that hold interesting pointers right now.\n+  card_scan->mark_range_as_dirty(obj, words);\n+\n+  if (promotion) {\n+    \/\/ This evacuation was a promotion, track this as allocation against old gen\n+    increase_allocated(words * HeapWordSize);\n+  }\n+}\n\\ No newline at end of file\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahOldGeneration.cpp","additions":111,"deletions":7,"binary":false,"changes":118,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/shenandoah\/shenandoahSharedVariables.hpp\"\n@@ -39,0 +40,39 @@\n+  \/\/ After determining the desired size of the old generation (see compute_old_generation_balance), these\n+  \/\/ quantities represent the number of regions above (surplus) or below (deficit) that size.\n+  \/\/ These values are computed prior to the actual exchange of any regions. These may never both\n+  \/\/ be positive simultaneously.\n+  size_t _region_surplus;\n+  size_t _region_deficit;\n+\n+  \/\/ Set when evacuation in the old generation fails. When this is set, the control thread will initiate a\n+  \/\/ full GC instead of a futile degenerated cycle.\n+  ShenandoahSharedFlag _failed_evacuation;\n+\n+  \/\/ Bytes reserved within old-gen to hold the results of promotion. This is separate from\n+  \/\/ and in addition to the evacuation reserve for intra-generation evacuations (ShenandoahGeneration::_evacuation_reserve).\n+  size_t _promoted_reserve;\n+\n+  \/\/ Bytes of old-gen memory expended on promotions. This may be modified concurrently\n+  \/\/ by mutators and gc workers when promotion LABs are retired during evacuation. It\n+  \/\/ is therefore always accessed through atomic operations. This is increased when a\n+  \/\/ PLAB is allocated for promotions. The value is decreased by the amount of memory\n+  \/\/ remaining in a PLAB when it is retired.\n+  size_t _promoted_expended;\n+\n+  \/\/ Represents the quantity of live bytes we expect to promote in place during the next\n+  \/\/ evacuation cycle. This value is used by the young heuristic to trigger mixed collections.\n+  \/\/ It is also used when computing the optimum size for the old generation.\n+  size_t _promotion_potential;\n+\n+  \/\/ When a region is selected to be promoted in place, the remaining free memory is filled\n+  \/\/ in to prevent additional allocations (preventing premature promotion of newly allocated\n+  \/\/ objects. This field records the total amount of padding used for such regions.\n+  size_t _pad_for_promote_in_place;\n+\n+  \/\/ During construction of the collection set, we keep track of regions that are eligible\n+  \/\/ for promotion in place. These fields track the count of those humongous and regular regions.\n+  \/\/ This data is used to force the evacuation phase even when the collection set is otherwise\n+  \/\/ empty.\n+  size_t _promotable_humongous_regions;\n+  size_t _promotable_regular_regions;\n+\n@@ -50,0 +90,55 @@\n+  \/\/ See description in field declaration\n+  void set_promoted_reserve(size_t new_val);\n+  size_t get_promoted_reserve() const;\n+\n+  \/\/ The promotion reserve is increased when rebuilding the free set transfers a region to the old generation\n+  void augment_promoted_reserve(size_t increment);\n+\n+  \/\/ This zeros out the expended promotion count after the promotion reserve is computed\n+  void reset_promoted_expended();\n+\n+  \/\/ This is incremented when allocations are made to copy promotions into the old generation\n+  size_t expend_promoted(size_t increment);\n+\n+  \/\/ This is used to return unused memory from a retired promotion LAB\n+  size_t unexpend_promoted(size_t decrement);\n+\n+  \/\/ This is used on the allocation path to gate promotions that would exceed the reserve\n+  size_t get_promoted_expended();\n+\n+  \/\/ See description in field declaration\n+  void set_region_surplus(size_t surplus) { _region_surplus = surplus; };\n+  void set_region_deficit(size_t deficit) { _region_deficit = deficit; };\n+  size_t get_region_surplus() const { return _region_surplus; };\n+  size_t get_region_deficit() const { return _region_deficit; };\n+\n+  \/\/ See description in field declaration\n+  void set_promotion_potential(size_t val) { _promotion_potential = val; };\n+  size_t get_promotion_potential() const { return _promotion_potential; };\n+\n+  \/\/ See description in field declaration\n+  void set_pad_for_promote_in_place(size_t pad) { _pad_for_promote_in_place = pad; }\n+  size_t get_pad_for_promote_in_place() const { return _pad_for_promote_in_place; }\n+\n+  \/\/ See description in field declaration\n+  void set_expected_humongous_region_promotions(size_t region_count) { _promotable_humongous_regions = region_count; }\n+  void set_expected_regular_region_promotions(size_t region_count) { _promotable_regular_regions = region_count; }\n+  bool has_in_place_promotions() const { return (_promotable_humongous_regions + _promotable_regular_regions) > 0; }\n+\n+  \/\/ This will signal the heuristic to trigger an old generation collection\n+  void handle_failed_transfer();\n+\n+  \/\/ This will signal the control thread to run a full GC instead of a futile degenerated gc\n+  void handle_failed_evacuation();\n+\n+  \/\/ This logs that an evacuation to the old generation has failed\n+  void handle_failed_promotion(Thread* thread, size_t size);\n+\n+  \/\/ A successful evacuation re-dirties the cards and registers the object with the remembered set\n+  void handle_evacuation(HeapWord* obj, size_t words, bool promotion);\n+\n+  \/\/ Clear the flag after it is consumed by the control thread\n+  bool clear_failed_evacuation() {\n+    return _failed_evacuation.try_unset();\n+  }\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahOldGeneration.hpp","additions":95,"deletions":0,"binary":false,"changes":95,"status":"modified"},{"patch":"@@ -414,1 +414,1 @@\n-      size_t pad = ShenandoahHeap::heap()->get_pad_for_promote_in_place();\n+      size_t pad = heap->old_generation()->get_pad_for_promote_in_place();\n@@ -860,1 +860,1 @@\n-      heap_used = _heap->used() + _heap->get_pad_for_promote_in_place();\n+      heap_used = _heap->used() + _heap->old_generation()->get_pad_for_promote_in_place();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahVerifier.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -88,1 +88,1 @@\n-    _heap->set_old_evac_reserve(_heap->old_generation()->soft_max_capacity() \/ 4);\n+    _heap->old_generation()->set_evacuation_reserve(_heap->old_generation()->soft_max_capacity() \/ 4);\n","filename":"test\/hotspot\/gtest\/gc\/shenandoah\/test_shenandoahOldHeuristic.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}