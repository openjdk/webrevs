{"files":[{"patch":"@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -27,0 +26,1 @@\n+#include \"precompiled.hpp\"\n@@ -208,0 +208,28 @@\n+\/\/  Rationale:\n+\/\/    The idea is that there is an average allocation rate and there are occasional abnormal bursts (or spikes) of\n+\/\/    allocations that exceed the average allocation rate.  What do these spikes look like?\n+\/\/\n+\/\/    1. At certain phase changes, we may discard large amounts of data and replace it with large numbers of newly\n+\/\/       allocated objects.  This \"spike\" looks more like a phase change.  We were in steady state at M bytes\/sec\n+\/\/       allocation rate and now we're in a \"reinitialization phase\" that looks like N bytes\/sec.  We need the \"spike\"\n+\/\/       accommodation to give us enough runway to recalibrate our \"average allocation rate\".\n+\/\/\n+\/\/   2. The typical workload changes.  \"Suddenly\", our typical workload of N TPS increases to N+delta TPS.  This means\n+\/\/       our average allocation rate needs to be adjusted.  Once again, we need the \"spike\" accomodation to give us\n+\/\/       enough runway to recalibrate our \"average allocation rate\".\n+\/\/\n+\/\/    3. Though there is an \"average\" allocation rate, a given workload's demand for allocation may be very bursty.  We\n+\/\/       allocate a bunch of LABs during the 5 ms that follow completion of a GC, then we perform no more allocations for\n+\/\/       the next 150 ms.  It seems we want the \"spike\" to represent the maximum divergence from average within the\n+\/\/       period of time between consecutive evaluation of the should_start_gc() service.  Here's the thinking:\n+\/\/\n+\/\/       a) Between now and the next time I ask whether should_start_gc(), we might experience a spike representing\n+\/\/          the anticipated burst of allocations.  If that would put us over budget, then we should start GC immediately.\n+\/\/       b) Between now and the anticipated depletion of allocation pool, there may be two or more bursts of allocations.\n+\/\/          If there are more than one of these bursts, we can \"approximate\" that these will be separated by spans of\n+\/\/          time with very little or no allocations so the \"average\" allocation rate should be a suitable approximation\n+\/\/          of how this will behave.\n+\/\/\n+\/\/    For cases 1 and 2, we need to \"quickly\" recalibrate the average allocation rate whenever we detect a change\n+\/\/    in operation mode.  We want some way to decide that the average rate has changed, while keeping average\n+\/\/    allocation rate computation independent.\n@@ -241,28 +269,0 @@\n-  \/\/  Rationale:\n-  \/\/    The idea is that there is an average allocation rate and there are occasional abnormal bursts (or spikes) of\n-  \/\/    allocations that exceed the average allocation rate.  What do these spikes look like?\n-  \/\/\n-  \/\/    1. At certain phase changes, we may discard large amounts of data and replace it with large numbers of newly\n-  \/\/       allocated objects.  This \"spike\" looks more like a phase change.  We were in steady state at M bytes\/sec\n-  \/\/       allocation rate and now we're in a \"reinitialization phase\" that looks like N bytes\/sec.  We need the \"spike\"\n-  \/\/       accommodation to give us enough runway to recalibrate our \"average allocation rate\".\n-  \/\/\n-  \/\/   2. The typical workload changes.  \"Suddenly\", our typical workload of N TPS increases to N+delta TPS.  This means\n-  \/\/       our average allocation rate needs to be adjusted.  Once again, we need the \"spike\" accomodation to give us\n-  \/\/       enough runway to recalibrate our \"average allocation rate\".\n-  \/\/\n-  \/\/    3. Though there is an \"average\" allocation rate, a given workload's demand for allocation may be very bursty.  We\n-  \/\/       allocate a bunch of LABs during the 5 ms that follow completion of a GC, then we perform no more allocations for\n-  \/\/       the next 150 ms.  It seems we want the \"spike\" to represent the maximum divergence from average within the\n-  \/\/       period of time between consecutive evaluation of the should_start_gc() service.  Here's the thinking:\n-  \/\/\n-  \/\/       a) Between now and the next time I ask whether should_start_gc(), we might experience a spike representing\n-  \/\/          the anticipated burst of allocations.  If that would put us over budget, then we should start GC immediately.\n-  \/\/       b) Between now and the anticipated depletion of allocation pool, there may be two or more bursts of allocations.\n-  \/\/          If there are more than one of these bursts, we can \"approximate\" that these will be separated by spans of\n-  \/\/          time with very little or no allocations so the \"average\" allocation rate should be a suitable approximation\n-  \/\/          of how this will behave.\n-  \/\/\n-  \/\/    For cases 1 and 2, we need to \"quickly\" recalibrate the average allocation rate whenever we detect a change\n-  \/\/    in operation mode.  We want some way to decide that the average rate has changed.  Make average allocation rate\n-  \/\/    computations an independent effort.\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahAdaptiveHeuristics.cpp","additions":29,"deletions":29,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -143,0 +143,4 @@\n+  \/\/ A conservative minimum threshold of free space that we'll try to maintain when possible.\n+  \/\/ For example, we might trigger a concurrent gc if we are likely to drop below\n+  \/\/ this threshold, or we might consider this when dynamically resizing generations\n+  \/\/ in the generational case. Controlled by global flag ShenandoahMinFreeThreshold.\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahAdaptiveHeuristics.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -43,24 +43,0 @@\n-  \/\/ The logic for cset selection in adaptive is as follows:\n-  \/\/\n-  \/\/   1. We cannot get cset larger than available free space. Otherwise we guarantee OOME\n-  \/\/      during evacuation, and thus guarantee full GC. In practice, we also want to let\n-  \/\/      application to allocate something. This is why we limit CSet to some fraction of\n-  \/\/      available space. In non-overloaded heap, max_cset would contain all plausible candidates\n-  \/\/      over garbage threshold.\n-  \/\/\n-  \/\/   2. We should not get cset too low so that free threshold would not be met right\n-  \/\/      after the cycle. Otherwise we get back-to-back cycles for no reason if heap is\n-  \/\/      too fragmented. In non-overloaded non-fragmented heap min_garbage would be around zero.\n-  \/\/\n-  \/\/ Therefore, we start by sorting the regions by garbage. Then we unconditionally add the best candidates\n-  \/\/ before we meet min_garbage. Then we add all candidates that fit with a garbage threshold before\n-  \/\/ we hit max_cset. When max_cset is hit, we terminate the cset selection. Note that in this scheme,\n-  \/\/ ShenandoahGarbageThreshold is the soft threshold which would be ignored until min_garbage is hit.\n-\n-  \/\/ In generational mode, the sort order within the data array is not strictly descending amounts of garbage.  In\n-  \/\/ particular, regions that have reached tenure age will be sorted into this array before younger regions that contain\n-  \/\/ more garbage.  This represents one of the reasons why we keep looking at regions even after we decide, for example,\n-  \/\/ to exclude one of the regions because it might require evacuation of too much live data.\n-\n-\n-\n@@ -70,3 +46,1 @@\n-  size_t cur_young_garbage = add_preselected_regions_to_collection_set(cset, data, size);\n-\n-  choose_global_collection_set(cset, data, size, actual_free, cur_young_garbage);\n+  choose_global_collection_set(cset, data, size, actual_free, 0 \/* cur_young_garbage *\/);\n@@ -129,4 +103,1 @@\n-    if (cset->is_preselected(r->index())) {\n-      fatal(\"There should be no preselected regions during GLOBAL GC\");\n-      continue;\n-    }\n+    assert(!cset->is_preselected(r->index()), \"There should be no preselected regions during GLOBAL GC\");\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahGlobalHeuristics.cpp","additions":2,"deletions":31,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -45,1 +45,2 @@\n-  \/\/ The logic for cset selection in adaptive is as follows:\n+  \/\/ See comments in ShenandoahAdaptiveHeuristics::choose_collection_set_from_regiondata():\n+  \/\/ we do the same here, but with the following adjustments for generational mode:\n@@ -47,19 +48,5 @@\n-  \/\/   1. We cannot get cset larger than available free space. Otherwise we guarantee OOME\n-  \/\/      during evacuation, and thus guarantee full GC. In practice, we also want to let\n-  \/\/      application to allocate something. This is why we limit CSet to some fraction of\n-  \/\/      available space. In non-overloaded heap, max_cset would contain all plausible candidates\n-  \/\/      over garbage threshold.\n-  \/\/\n-  \/\/   2. We should not get cset too low so that free threshold would not be met right\n-  \/\/      after the cycle. Otherwise we get back-to-back cycles for no reason if heap is\n-  \/\/      too fragmented. In non-overloaded non-fragmented heap min_garbage would be around zero.\n-  \/\/\n-  \/\/ Therefore, we start by sorting the regions by garbage. Then we unconditionally add the best candidates\n-  \/\/ before we meet min_garbage. Then we add all candidates that fit with a garbage threshold before\n-  \/\/ we hit max_cset. When max_cset is hit, we terminate the cset selection. Note that in this scheme,\n-  \/\/ ShenandoahGarbageThreshold is the soft threshold which would be ignored until min_garbage is hit.\n-\n-  \/\/ In generational mode, the sort order within the data array is not strictly descending amounts of garbage.  In\n-  \/\/ particular, regions that have reached tenure age will be sorted into this array before younger regions that contain\n-  \/\/ more garbage.  This represents one of the reasons why we keep looking at regions even after we decide, for example,\n-  \/\/ to exclude one of the regions because it might require evacuation of too much live data.\n+  \/\/ In generational mode, the sort order within the data array is not strictly descending amounts\n+  \/\/ of garbage. In particular, regions that have reached tenure age will be sorted into this\n+  \/\/ array before younger regions that typically contain more garbage. This is one reason why,\n+  \/\/ for example, we continue examining regions even after rejecting a region that has\n+  \/\/ more live data than we can evacuate.\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahYoungHeuristics.cpp","additions":7,"deletions":20,"binary":false,"changes":27,"status":"modified"}]}