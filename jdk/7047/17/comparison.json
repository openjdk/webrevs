{"files":[{"patch":"@@ -32,0 +32,1 @@\n+#include \"gc\/g1\/g1HeapRegionChunk.inline.hpp\"\n@@ -44,0 +45,1 @@\n+  G1HeapRegionChunk* _chunk;\n@@ -45,0 +47,1 @@\n+  size_t _marked_objects;\n@@ -51,0 +54,1 @@\n+                                 G1HeapRegionChunk* chunk,\n@@ -56,0 +60,1 @@\n+    _chunk(chunk),\n@@ -57,0 +62,1 @@\n+    _marked_objects(0),\n@@ -58,2 +64,4 @@\n-    _worker_id(worker_id),\n-    _last_forwarded_object_end(hr->bottom()) { }\n+    _worker_id(worker_id) {\n+    _last_forwarded_object_end = _chunk->include_first_obj_in_region() ?\n+                                 _hr->bottom() : _chunk->first_obj_in_chunk();\n+  }\n@@ -61,1 +69,2 @@\n-  size_t marked_bytes() { return _marked_words * HeapWordSize; }\n+  size_t marked_words() const { return _marked_words; }\n+  size_t marked_objects() const { return _marked_objects; }\n@@ -95,0 +104,1 @@\n+    _marked_objects++;\n@@ -140,1 +150,1 @@\n-    zap_dead_objects(_last_forwarded_object_end, _hr->top());\n+    zap_dead_objects(_last_forwarded_object_end, _chunk->next_obj_in_region());\n@@ -144,3 +154,1 @@\n-class RemoveSelfForwardPtrHRClosure: public HeapRegionClosure {\n-  G1CollectedHeap* _g1h;\n-  uint _worker_id;\n+class RemoveSelfForwardPtrHRChunkClosure : public G1HeapRegionChunkClosure {\n@@ -148,1 +156,7 @@\n-  G1EvacFailureRegions* _evac_failure_regions;\n+  \/\/ Caches the currently accumulated number of live\/marked words found in this heap region.\n+  \/\/ Avoids direct (frequent) atomic operations on the HeapRegion's marked words.\n+  class RegionMarkedWordsCache {\n+    G1CollectedHeap* _g1h;\n+    const uint _uninitialized_idx;\n+    uint _region_idx;\n+    size_t _marked_words;\n@@ -150,1 +164,3 @@\n-  G1GCPhaseTimes* _phase_times;\n+    void note_self_forwarding_removal_end_par() {\n+      _g1h->region_at(_region_idx)->note_self_forwarding_removal_end_par(_marked_words * BytesPerWord);\n+    }\n@@ -152,8 +168,30 @@\n-public:\n-  RemoveSelfForwardPtrHRClosure(uint worker_id,\n-                                G1EvacFailureRegions* evac_failure_regions) :\n-    _g1h(G1CollectedHeap::heap()),\n-    _worker_id(worker_id),\n-    _evac_failure_regions(evac_failure_regions),\n-    _phase_times(G1CollectedHeap::heap()->phase_times()) {\n-  }\n+  public:\n+    RegionMarkedWordsCache():\n+      _g1h(G1CollectedHeap::heap()),\n+      _uninitialized_idx(_g1h->max_regions()),\n+      _region_idx(_uninitialized_idx),\n+      _marked_words(0) { }\n+\n+    void add(uint region_idx, size_t marked_words) {\n+      if (_region_idx == _uninitialized_idx) {\n+        _region_idx = region_idx;\n+        _marked_words = marked_words;\n+      } else if (_region_idx == region_idx) {\n+        _marked_words += marked_words;\n+      } else {\n+        note_self_forwarding_removal_end_par();\n+        _region_idx = region_idx;\n+        _marked_words = marked_words;\n+      }\n+    }\n+\n+    void flush() {\n+      if (_region_idx != _uninitialized_idx) {\n+        note_self_forwarding_removal_end_par();\n+      }\n+    }\n+  };\n+\n+  G1CollectedHeap* _g1h;\n+  uint _worker_id;\n+  RegionMarkedWordsCache _region_marked_words_cache;\n@@ -161,3 +199,4 @@\n-  size_t remove_self_forward_ptr_by_walking_hr(HeapRegion* hr,\n-                                               bool during_concurrent_start) {\n-    RemoveSelfForwardPtrObjClosure rspc(hr,\n+  void remove_self_forward_ptr_by_walking_chunk(G1HeapRegionChunk* chunk) {\n+    bool during_concurrent_start = _g1h->collector_state()->in_concurrent_start_gc();\n+    RemoveSelfForwardPtrObjClosure rspc(chunk->heap_region(),\n+                                        chunk,\n@@ -169,2 +208,4 @@\n-    G1CMBitMap* bitmap = const_cast<G1CMBitMap*>(_g1h->concurrent_mark()->prev_mark_bitmap());\n-    hr->apply_to_marked_objects(bitmap, &rspc);\n+    chunk->apply_to_marked_objects(&rspc);\n+    uint current_region_idx = chunk->heap_region()->hrm_index();\n+    _region_marked_words_cache.add(current_region_idx, rspc.marked_words());\n+\n@@ -172,1 +213,3 @@\n-    rspc.zap_remainder();\n+    if (!chunk->empty()) {\n+      rspc.zap_remainder();\n+    }\n@@ -174,1 +217,3 @@\n-    return rspc.marked_bytes();\n+    G1GCPhaseTimes* p = _g1h->phase_times();\n+    p->record_or_add_thread_work_item(G1GCPhaseTimes::RemoveSelfForwardsInChunks, _worker_id, rspc.marked_words(), G1GCPhaseTimes::RemoveSelfForwardObjectsBytes);\n+    p->record_or_add_thread_work_item(G1GCPhaseTimes::RemoveSelfForwardsInChunks, _worker_id, rspc.marked_objects(), G1GCPhaseTimes::RemoveSelfForwardObjectsNum);\n@@ -177,22 +222,5 @@\n-  bool do_heap_region(HeapRegion *hr) {\n-    assert(!hr->is_pinned(), \"Unexpected pinned region at index %u\", hr->hrm_index());\n-    assert(hr->in_collection_set(), \"bad CS\");\n-    assert(_evac_failure_regions->contains(hr->hrm_index()), \"precondition\");\n-\n-    hr->clear_index_in_opt_cset();\n-\n-    bool during_concurrent_start = _g1h->collector_state()->in_concurrent_start_gc();\n-    bool during_concurrent_mark = _g1h->collector_state()->mark_or_rebuild_in_progress();\n-\n-    hr->note_self_forwarding_removal_start(during_concurrent_start,\n-                                           during_concurrent_mark);\n-\n-    _phase_times->record_or_add_thread_work_item(G1GCPhaseTimes::RestoreRetainedRegions,\n-                                                   _worker_id,\n-                                                   1,\n-                                                   G1GCPhaseTimes::RestoreRetainedRegionsNum);\n-\n-    size_t live_bytes = remove_self_forward_ptr_by_walking_hr(hr, during_concurrent_start);\n-\n-    hr->rem_set()->clean_code_roots(hr);\n-    hr->rem_set()->clear_locked(true);\n+public:\n+  RemoveSelfForwardPtrHRChunkClosure(uint worker_id) :\n+    _g1h(G1CollectedHeap::heap()),\n+    _worker_id(worker_id) {\n+  }\n@@ -200,2 +228,3 @@\n-    hr->note_self_forwarding_removal_end(live_bytes);\n-    _g1h->verifier()->check_bitmaps(\"Self-Forwarding Ptr Removal\", hr);\n+  void do_heap_region_chunk(G1HeapRegionChunk* chunk) override {\n+    remove_self_forward_ptr_by_walking_chunk(chunk);\n+  }\n@@ -203,1 +232,2 @@\n-    return false;\n+  void sync_last_region_data() {\n+    _region_marked_words_cache.flush();\n@@ -210,1 +240,0 @@\n-  _hrclaimer(_g1h->workers()->active_workers()),\n@@ -214,1 +243,4 @@\n-  RemoveSelfForwardPtrHRClosure rsfp_cl(worker_id, _evac_failure_regions);\n+  RemoveSelfForwardPtrHRChunkClosure chunk_closure(worker_id);\n+\n+  \/\/ Iterate through all chunks in regions that failed evacuation during the entire collection.\n+  _evac_failure_regions->par_iterate_chunks_in_regions(&chunk_closure, worker_id);\n@@ -216,2 +248,1 @@\n-  \/\/ Iterate through all regions that failed evacuation during the entire collection.\n-  _evac_failure_regions->par_iterate(&rsfp_cl, &_hrclaimer, worker_id);\n+  chunk_closure.sync_last_region_data();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailure.cpp","additions":84,"deletions":53,"binary":false,"changes":137,"status":"modified"},{"patch":"@@ -41,1 +41,0 @@\n-  HeapRegionClaimer _hrclaimer;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailure.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, Huawei Technologies Co., Ltd. All rights reserved.\n+ * Copyright (c) 2021, 2022, Huawei Technologies Co., Ltd. All rights reserved.\n@@ -27,1 +27,2 @@\n-#include \"gc\/g1\/g1CollectedHeap.hpp\"\n+#include \"gc\/g1\/g1BatchedTask.hpp\"\n+#include \"gc\/g1\/g1CollectedHeap.inline.hpp\"\n@@ -29,0 +30,1 @@\n+#include \"gc\/g1\/g1HeapRegionChunk.hpp\"\n@@ -37,2 +39,3 @@\n-  _evac_failure_regions_cur_length(0),\n-  _max_regions(0) { }\n+  _chunks_in_regions(nullptr),\n+  _evac_failure_regions_cur_length(0) {\n+}\n@@ -42,0 +45,1 @@\n+  assert(_chunks_in_regions == nullptr, \"not cleaned up\");\n@@ -46,3 +50,3 @@\n-  _max_regions = max_regions;\n-  _regions_failed_evacuation.resize(_max_regions);\n-  _evac_failure_regions = NEW_C_HEAP_ARRAY(uint, _max_regions, mtGC);\n+  _regions_failed_evacuation.resize(max_regions);\n+  _evac_failure_regions = NEW_C_HEAP_ARRAY(uint, max_regions, mtGC);\n+  _chunks_in_regions = new (NEW_C_HEAP_OBJ(G1ScanChunksInHeapRegions, mtGC)) G1ScanChunksInHeapRegions();\n@@ -53,0 +57,4 @@\n+\n+  FREE_C_HEAP_OBJ(_chunks_in_regions);\n+  _chunks_in_regions = nullptr;\n+\n@@ -55,1 +63,4 @@\n-  _max_regions = 0; \/\/ To have any record() attempt fail in the future.\n+}\n+\n+bool G1EvacFailureRegions::contains(uint region_idx) const {\n+  return _regions_failed_evacuation.par_at(region_idx, memory_order_relaxed);\n@@ -59,1 +70,1 @@\n-                                       HeapRegionClaimer* _hrclaimer,\n+                                       HeapRegionClaimer* hrclaimer,\n@@ -62,1 +73,1 @@\n-                                                     _hrclaimer,\n+                                                     hrclaimer,\n@@ -68,3 +79,72 @@\n-bool G1EvacFailureRegions::contains(uint region_idx) const {\n-  assert(region_idx < _max_regions, \"must be\");\n-  return _regions_failed_evacuation.par_at(region_idx, memory_order_relaxed);\n+void G1EvacFailureRegions::initialize_chunks(uint num_workers) {\n+  _chunks_in_regions->initialize(_evac_failure_regions,\n+                                 Atomic::load(&_evac_failure_regions_cur_length),\n+                                 num_workers);\n+}\n+\n+void G1EvacFailureRegions::par_iterate_chunks_in_regions(G1HeapRegionChunkClosure* chunk_closure,\n+                                                         uint worker_id) const {\n+  _chunks_in_regions->par_iterate_chunks_in_regions(chunk_closure, worker_id);\n+}\n+\n+class PrepareEvacFailureRegionTask : public G1AbstractSubTask {\n+  G1EvacFailureRegions* _evac_failure_regions;\n+  uint _num_workers;\n+  HeapRegionClaimer _claimer;\n+\n+  class PrepareEvacFailureRegionClosure : public HeapRegionClosure {\n+    const G1EvacFailureRegions* _evac_failure_regions;\n+    uint _worker_id;\n+\n+    void prepare_region(uint region_idx, uint worker_id) {\n+      G1CollectedHeap* g1h = G1CollectedHeap::heap();\n+      G1GCPhaseTimes* p = g1h->phase_times();\n+      HeapRegion* hr = g1h->region_at(region_idx);\n+      assert(!hr->is_pinned(), \"Unexpected pinned region at index %u\", hr->hrm_index());\n+      assert(hr->in_collection_set(), \"bad CS\");\n+      assert(_evac_failure_regions->contains(hr->hrm_index()), \"precondition\");\n+\n+      p->record_or_add_thread_work_item(G1GCPhaseTimes::RestoreRetainedRegions,\n+                                        worker_id,\n+                                        1,\n+                                        G1GCPhaseTimes::RestoreRetainedRegionsNum);\n+\n+      HeapRegionRemSet* rem_set = hr->rem_set();\n+      rem_set->clean_code_roots(hr);\n+      rem_set->clear_locked(true);\n+    }\n+\n+  public:\n+    PrepareEvacFailureRegionClosure(G1EvacFailureRegions* evac_failure_regions, uint worker_id) :\n+      _evac_failure_regions(evac_failure_regions),\n+      _worker_id(worker_id) { }\n+\n+    bool do_heap_region(HeapRegion* r) override {\n+      assert(_evac_failure_regions->contains(r->hrm_index()), \"precondition\");\n+      prepare_region(r->hrm_index(), _worker_id);\n+      return false;\n+    }\n+  };\n+\n+public:\n+  PrepareEvacFailureRegionTask(G1EvacFailureRegions* evac_failure_regions, uint num_workers) :\n+    G1AbstractSubTask(G1GCPhaseTimes::PrepareRetainedRegions),\n+    _evac_failure_regions(evac_failure_regions),\n+    _num_workers(num_workers),\n+    _claimer(_num_workers) {\n+  }\n+\n+  double worker_cost() const override {\n+    return 1.0;\n+  }\n+\n+  void do_work(uint worker_id) override {\n+    PrepareEvacFailureRegionClosure closure(_evac_failure_regions, worker_id);\n+    _evac_failure_regions->par_iterate(&closure, &_claimer, worker_id);\n+  }\n+};\n+\n+G1AbstractSubTask* G1EvacFailureRegions::create_prepare_regions_task() {\n+  WorkerThreads* workers = G1CollectedHeap::heap()->workers();\n+  uint num_workers = clamp(_evac_failure_regions_cur_length, 1u, workers->active_workers());\n+  return new PrepareEvacFailureRegionTask(this, num_workers);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureRegions.cpp","additions":93,"deletions":13,"binary":false,"changes":106,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, Huawei Technologies Co., Ltd. All rights reserved.\n+ * Copyright (c) 2021, 2022, Huawei Technologies Co., Ltd. All rights reserved.\n@@ -31,0 +31,3 @@\n+class G1AbstractSubTask;\n+class G1HeapRegionChunkClosure;\n+class G1ScanChunksInHeapRegions;\n@@ -42,0 +45,2 @@\n+  \/\/ Scans chunks in evacuation failure regions\n+  G1ScanChunksInHeapRegions* _chunks_in_regions;\n@@ -44,2 +49,0 @@\n-  \/\/ Maximum of regions number.\n-  uint _max_regions;\n@@ -58,1 +61,1 @@\n-                   HeapRegionClaimer* _hrclaimer,\n+                   HeapRegionClaimer* hrclaimer,\n@@ -60,0 +63,7 @@\n+  void initialize_chunks(uint active_workers);\n+  \/\/ Iterate through all chunks in regions that failed evacuation during the entire collection.\n+  void par_iterate_chunks_in_regions(G1HeapRegionChunkClosure* chunk_closure,\n+                                     uint worker_id) const;\n+\n+  \/\/ Return a G1AbstractSubTask which does necessary preparation for evacuation failure regions\n+  G1AbstractSubTask* create_prepare_regions_task();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureRegions.hpp","additions":14,"deletions":4,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, Huawei Technologies Co., Ltd. All rights reserved.\n+ * Copyright (c) 2021, 2022, Huawei Technologies Co., Ltd. All rights reserved.\n@@ -29,0 +29,1 @@\n+#include \"gc\/g1\/g1HeapRegionChunk.hpp\"\n@@ -30,1 +31,0 @@\n-#include \"utilities\/bitMap.inline.hpp\"\n@@ -33,1 +33,0 @@\n-  assert(region_idx < _max_regions, \"must be\");\n@@ -39,0 +38,6 @@\n+\n+    G1CollectedHeap* g1h = G1CollectedHeap::heap();\n+    HeapRegion* hr = g1h->region_at(region_idx);\n+    G1CollectorState* state = g1h->collector_state();\n+    hr->note_self_forwarding_removal_start(state->in_concurrent_start_gc(),\n+                                           state->mark_or_rebuild_in_progress());\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureRegions.inline.hpp","additions":8,"deletions":3,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -105,0 +105,1 @@\n+  _gc_par_phases[PrepareRetainedRegions] = new WorkerDataArray<double>(\"PrepareRetainedRegions\", \"Prepare Retained Regions (ms):\", max_gc_threads);\n@@ -106,0 +107,2 @@\n+  _gc_par_phases[RemoveSelfForwardsInChunks] = new WorkerDataArray<double>(\"RemoveSelfForwardsInChunks\", \"Remove Self Forwards In Chunks (ms):\", max_gc_threads);\n+  _gc_par_phases[PrepareChunks] = new WorkerDataArray<double>(\"PrepareChunks\", \"Prepare Chunks (ms):\", max_gc_threads);\n@@ -115,0 +118,1 @@\n+  _gc_par_phases[VerifyAfterSelfForwardingPtrRemoval] = new WorkerDataArray<double>(\"VerifyAfterSelfForwardingPtrRemoval\", \"Verify Retained Regions (ms):\", max_gc_threads);\n@@ -137,0 +141,5 @@\n+  _gc_par_phases[RemoveSelfForwardsInChunks]->create_thread_work_items(\"Forward Chunks:\", RemoveSelfForwardChunksNum);\n+  _gc_par_phases[RemoveSelfForwardsInChunks]->create_thread_work_items(\"Empty Forward Chunks:\", RemoveSelfForwardEmptyChunksNum);\n+  _gc_par_phases[RemoveSelfForwardsInChunks]->create_thread_work_items(\"Forward Objects:\", RemoveSelfForwardObjectsNum);\n+  _gc_par_phases[RemoveSelfForwardsInChunks]->create_thread_work_items(\"Forward Bytes:\", RemoveSelfForwardObjectsBytes);\n+\n@@ -485,0 +494,1 @@\n+    debug_phase(_gc_par_phases[PrepareRetainedRegions], 1);\n@@ -486,0 +496,2 @@\n+    debug_phase(_gc_par_phases[PrepareChunks], 2);\n+    debug_phase(_gc_par_phases[RemoveSelfForwardsInChunks], 2);\n@@ -493,0 +505,3 @@\n+    if (G1VerifyBitmaps) {\n+      debug_phase(_gc_par_phases[VerifyAfterSelfForwardingPtrRemoval], 1);\n+    }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1GCPhaseTimes.cpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -80,0 +80,1 @@\n+    PrepareRetainedRegions,\n@@ -81,0 +82,2 @@\n+    RemoveSelfForwardsInChunks,\n+    PrepareChunks,\n@@ -90,0 +93,1 @@\n+    VerifyAfterSelfForwardingPtrRemoval,\n@@ -151,0 +155,7 @@\n+  enum RemoveSelfForwardsInChunksWorkItems {\n+    RemoveSelfForwardChunksNum,\n+    RemoveSelfForwardEmptyChunksNum,\n+    RemoveSelfForwardObjectsNum,\n+    RemoveSelfForwardObjectsBytes,\n+  };\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1GCPhaseTimes.hpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -0,0 +1,99 @@\n+\/*\n+ * Copyright (c) 2022, Huawei Technologies Co. Ltd. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+\n+#include \"gc\/g1\/g1CollectedHeap.inline.hpp\"\n+#include \"gc\/g1\/g1ConcurrentMarkBitMap.inline.hpp\"\n+#include \"gc\/g1\/g1HeapRegionChunk.hpp\"\n+#include \"gc\/g1\/heapRegion.hpp\"\n+\n+G1HeapRegionChunk::G1HeapRegionChunk(HeapRegion* region, uint chunk_idx, uint chunk_size, const G1CMBitMap* const bitmap) :\n+  _chunk_size(chunk_size),\n+  _region(region),\n+  _chunk_idx(chunk_idx),\n+  _bitmap(bitmap) {\n+\n+  HeapWord* top = _region->top();\n+  HeapWord* bottom = _region->bottom();\n+  _start = MIN2(top, bottom + _chunk_idx * _chunk_size);\n+  _limit = MIN2(top, bottom + (_chunk_idx + 1) * _chunk_size);\n+  _first_obj_in_chunk = _bitmap->get_next_marked_addr(_start, _limit);\n+  _next_obj_in_region = _bitmap->get_next_marked_addr(_limit, top);\n+  \/\/ There is marked obj in this chunk\n+  bool marked_obj_in_this_chunk = _start <= _first_obj_in_chunk && _first_obj_in_chunk < _limit;\n+  _include_first_obj_in_region = marked_obj_in_this_chunk\n+                                 && _bitmap->get_next_marked_addr(bottom, _limit) >= _start;\n+}\n+\n+bool G1ScanChunksInHeapRegions::claim_chunk(uint chunk_id) {\n+  return _chunks.par_set_bit(chunk_id);\n+}\n+\n+void G1ScanChunksInHeapRegions::process_chunk(G1HeapRegionChunkClosure* chunk_closure, uint chunk_id, uint worker_id) {\n+  G1CollectedHeap* glh = G1CollectedHeap::heap();\n+  G1GCPhaseTimes* p = glh->phase_times();\n+\n+  \/\/ Prepare and analyze assigned chunk.\n+  Ticks chunk_prepare_start = Ticks::now();\n+  uint region_idx = _evac_failure_regions[chunk_id \/ _chunks_per_region];\n+  G1HeapRegionChunk chunk(glh->region_at(region_idx), chunk_id % _chunks_per_region, _chunk_size, _bitmap);\n+  p->record_or_add_time_secs(G1GCPhaseTimes::PrepareChunks, worker_id, (Ticks::now() - chunk_prepare_start).seconds());\n+\n+  if (chunk.empty()) {\n+    p->record_or_add_thread_work_item(G1GCPhaseTimes::RemoveSelfForwardsInChunks, worker_id, 1, G1GCPhaseTimes::RemoveSelfForwardEmptyChunksNum);\n+    return;\n+  }\n+  p->record_or_add_thread_work_item(G1GCPhaseTimes::RemoveSelfForwardsInChunks, worker_id, 1, G1GCPhaseTimes::RemoveSelfForwardChunksNum);\n+\n+  \/\/ Process the chunk.\n+  Ticks start = Ticks::now();\n+  chunk_closure->do_heap_region_chunk(&chunk);\n+  p->record_or_add_time_secs(G1GCPhaseTimes::RemoveSelfForwardsInChunks, worker_id, (Ticks::now() - start).seconds());\n+}\n+\n+G1ScanChunksInHeapRegions::G1ScanChunksInHeapRegions() :\n+  _bitmap(G1CollectedHeap::heap()->concurrent_mark()->prev_mark_bitmap()),\n+  _chunks(mtGC) { }\n+\n+void G1ScanChunksInHeapRegions::initialize(const uint* evac_failure_regions, uint evac_failure_regions_length, uint num_workers) {\n+  _evac_failure_regions = evac_failure_regions;\n+\n+  _chunks_per_region = next_power_of_2(num_workers * G1RemoveSelfForwardPtrsThreadLoadFactor \/ evac_failure_regions_length);\n+  _chunk_size = static_cast<uint>(G1HeapRegionSize \/ _chunks_per_region);\n+  log_debug(gc, ergo)(\"Initializing removing self forwards with %u chunks per region given %u workers\", _chunks_per_region, num_workers);\n+\n+  _chunks.resize(_chunks_per_region * evac_failure_regions_length);\n+}\n+\n+void G1ScanChunksInHeapRegions::par_iterate_chunks_in_regions(G1HeapRegionChunkClosure* chunk_closure, uint worker_id) {\n+  const uint total_workers = G1CollectedHeap::heap()->workers()->active_workers();\n+  const uint start_chunk_id = worker_id * static_cast<uint>(_chunks.size()) \/ total_workers;\n+  for (uint i = 0; i < _chunks.size(); i++) {\n+    const uint chunk_id = (start_chunk_id + i) % _chunks.size();\n+    if (claim_chunk(chunk_id)) {\n+      process_chunk(chunk_closure, chunk_id, worker_id);\n+    }\n+  }\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeapRegionChunk.cpp","additions":99,"deletions":0,"binary":false,"changes":99,"status":"added"},{"patch":"@@ -0,0 +1,92 @@\n+\/*\n+ * Copyright (c) 2022, Huawei Technologies Co. Ltd. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1HEAPREGIONCHUNK_HPP\n+#define SHARE_GC_G1_G1HEAPREGIONCHUNK_HPP\n+\n+#include \"runtime\/atomic.hpp\"\n+#include \"utilities\/bitMap.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+\n+class G1CMBitMap;\n+class HeapRegion;\n+\n+\/\/ Unit of work for removing self forwards in regions.\n+class G1HeapRegionChunk {\n+  const uint _chunk_size;\n+  HeapRegion* _region;\n+  \/\/ chunk index in a region, zero based.\n+  uint _chunk_idx;\n+  const G1CMBitMap* const _bitmap;\n+\n+  \/\/ _start < _first_obj_in_chunk <= _limit <= _next_obj_in_region\n+  HeapWord * _start;\n+  HeapWord * _limit;\n+  HeapWord * _first_obj_in_chunk;\n+  HeapWord * _next_obj_in_region;\n+\n+  bool _include_first_obj_in_region;\n+\n+public:\n+  G1HeapRegionChunk(HeapRegion* region, uint chunk_idx, uint chunk_size, const G1CMBitMap* const bitmap);\n+\n+  \/\/ All objects that failed evacuation has been marked in the prev bitmap.\n+  \/\/ Use the bitmap to apply the above closure to all failing objects.\n+  template<typename ApplyToMarkedClosure>\n+  void apply_to_marked_objects(ApplyToMarkedClosure* closure);\n+\n+  HeapRegion* heap_region() const { return _region;}\n+\n+  HeapWord* first_obj_in_chunk() const { return _first_obj_in_chunk; }\n+\n+  HeapWord* next_obj_in_region() const { return _next_obj_in_region; }\n+\n+  bool empty() const { return _first_obj_in_chunk >= _limit; }\n+\n+  bool include_first_obj_in_region() const { return _include_first_obj_in_region; }\n+};\n+\n+class G1HeapRegionChunkClosure {\n+public:\n+  virtual void do_heap_region_chunk(G1HeapRegionChunk* c) = 0;\n+};\n+\n+class G1ScanChunksInHeapRegions {\n+  const G1CMBitMap* const _bitmap;\n+  CHeapBitMap _chunks;\n+  const uint* _evac_failure_regions;\n+  uint _chunks_per_region;\n+  uint _chunk_size;\n+\n+  bool claim_chunk(uint id);\n+  void process_chunk(G1HeapRegionChunkClosure* chunk_closure, uint chunk_id, uint worker_id);\n+\n+public:\n+  G1ScanChunksInHeapRegions();\n+  void initialize(const uint* evac_failure_regions, uint evac_failure_regions_length, uint num_workers);\n+\n+  void par_iterate_chunks_in_regions(G1HeapRegionChunkClosure* chunk_closure, const uint worker_id);\n+};\n+\n+#endif \/\/SHARE_GC_G1_G1HEAPREGIONCHUNK_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeapRegionChunk.hpp","additions":92,"deletions":0,"binary":false,"changes":92,"status":"added"},{"patch":"@@ -0,0 +1,50 @@\n+\/*\n+ * Copyright (c) 2022, Huawei Technologies Co. Ltd. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1HEAPREGIONCHUNK_INLINE_HPP\n+#define SHARE_GC_G1_G1HEAPREGIONCHUNK_INLINE_HPP\n+\n+#include \"gc\/g1\/g1HeapRegionChunk.hpp\"\n+#include \"gc\/shared\/markBitMap.inline.hpp\"\n+#include \"runtime\/prefetch.hpp\"\n+\n+template<typename ApplyToMarkedClosure>\n+inline void G1HeapRegionChunk::apply_to_marked_objects(ApplyToMarkedClosure* closure) {\n+  HeapWord* next_addr = _first_obj_in_chunk;\n+\n+  while (next_addr < _limit) {\n+    Prefetch::write(next_addr, PrefetchScanIntervalInBytes);\n+    \/\/ This explicit is_marked check is a way to avoid\n+    \/\/ some extra work done by get_next_marked_addr for\n+    \/\/ the case where next_addr is marked.\n+    if (_bitmap->is_marked(next_addr)) {\n+      oop current = cast_to_oop(next_addr);\n+      next_addr += closure->apply(current);\n+    } else {\n+      next_addr = _bitmap->get_next_marked_addr(next_addr, _limit);\n+    }\n+  }\n+}\n+\n+#endif \/\/SHARE_GC_G1_G1HEAPREGIONCHUNK_INLINE_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeapRegionChunk.inline.hpp","additions":50,"deletions":0,"binary":false,"changes":50,"status":"added"},{"patch":"@@ -103,0 +103,1 @@\n+  const char* _task_name;\n@@ -105,1 +106,1 @@\n-  RemoveSelfForwardPtrsTask(G1EvacFailureRegions* evac_failure_regions) :\n+  RemoveSelfForwardPtrsTask(G1EvacFailureRegions* evac_failure_regions, const char* task_name) :\n@@ -108,1 +109,2 @@\n-    _evac_failure_regions(evac_failure_regions) { }\n+    _evac_failure_regions(evac_failure_regions),\n+    _task_name(task_name) { }\n@@ -112,1 +114,1 @@\n-    return _evac_failure_regions->num_regions_failed_evacuation();\n+    return _evac_failure_regions->num_regions_failed_evacuation() * G1RemoveSelfForwardPtrsWorkerCost;\n@@ -118,0 +120,4 @@\n+\n+  void initialize_chunks(uint num_workers) {\n+    _evac_failure_regions->initialize_chunks(num_workers);\n+  }\n@@ -120,0 +126,2 @@\n+const char* G1PostEvacuateCollectionSetCleanupTask1::_name = \"Post Evacuate Cleanup 1\";\n+\n@@ -122,1 +130,1 @@\n-  G1BatchedTask(\"Post Evacuate Cleanup 1\", G1CollectedHeap::heap()->phase_times())\n+  G1BatchedTask(_name, G1CollectedHeap::heap()->phase_times())\n@@ -131,0 +139,1 @@\n+  add_parallel_task(G1CollectedHeap::heap()->rem_set()->create_cleanup_after_scan_heap_roots_task());\n@@ -132,1 +141,7 @@\n-    add_parallel_task(new RemoveSelfForwardPtrsTask(evac_failure_regions));\n+    add_parallel_task(evac_failure_regions->create_prepare_regions_task());\n+\n+    RemoveSelfForwardPtrsTask* remove_self_forward_task = new RemoveSelfForwardPtrsTask(evac_failure_regions, _name);\n+    add_parallel_task(remove_self_forward_task);\n+\n+    uint num_workers = clamp(num_workers_estimate(), 1u, G1CollectedHeap::heap()->workers()->active_workers());\n+    remove_self_forward_task->initialize_chunks(num_workers);\n@@ -134,1 +149,0 @@\n-  add_parallel_task(G1CollectedHeap::heap()->rem_set()->create_cleanup_after_scan_heap_roots_task());\n@@ -360,0 +374,34 @@\n+class G1PostEvacuateCollectionSetCleanupTask2::VerifyAfterSelfForwardingPtrRemovalTask : public G1AbstractSubTask {\n+  G1EvacFailureRegions* _evac_failure_regions;\n+  HeapRegionClaimer _claimer;\n+\n+  class VerifyRegionClosure : public HeapRegionClosure {\n+  public:\n+    bool do_heap_region(HeapRegion* hr) override {\n+      G1CollectedHeap::heap()->verifier()->check_bitmaps(\"Self-Forwarding Ptr Removal\", hr);\n+      return false;\n+    }\n+  };\n+\n+public:\n+  VerifyAfterSelfForwardingPtrRemovalTask(G1EvacFailureRegions* evac_failure_regions) :\n+    G1AbstractSubTask(G1GCPhaseTimes::VerifyAfterSelfForwardingPtrRemoval),\n+    _evac_failure_regions(evac_failure_regions),\n+    _claimer(0) {\n+    assert(G1VerifyBitmaps && _evac_failure_regions->evacuation_failed(), \"precondition\");\n+  }\n+\n+  void set_max_workers(uint max_workers) override {\n+    _claimer.set_n_workers(max_workers);\n+  }\n+\n+  double worker_cost() const override {\n+    return _evac_failure_regions->num_regions_failed_evacuation();\n+  }\n+\n+  void do_work(uint worker_id) override {\n+    VerifyRegionClosure closure;\n+    _evac_failure_regions->par_iterate(&closure, &_claimer, worker_id);\n+  }\n+};\n+\n@@ -682,0 +730,3 @@\n+    if (G1VerifyBitmaps) {\n+      add_parallel_task(new VerifyAfterSelfForwardingPtrRemovalTask(evac_failure_regions));\n+    }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGCPostEvacuateTasks.cpp","additions":57,"deletions":6,"binary":false,"changes":63,"status":"modified"},{"patch":"@@ -42,1 +42,0 @@\n-\/\/ - Remove Self Forwards (on evacuation failure)\n@@ -44,0 +43,1 @@\n+\/\/ - Remove Self Forwards (on evacuation failure)\n@@ -50,0 +50,1 @@\n+  static const char* _name;\n@@ -60,0 +61,1 @@\n+\/\/ - Verify Retained Regions (on evacuation failure)\n@@ -71,0 +73,1 @@\n+  class VerifyAfterSelfForwardingPtrRemovalTask;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGCPostEvacuateTasks.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -382,0 +382,10 @@\n+  product(uint, G1RemoveSelfForwardPtrsWorkerCost, 2, DIAGNOSTIC,           \\\n+          \"The factor for per region work cost to remove self forwardee \"   \\\n+          \"for evecuation failure regions.\")                                \\\n+          range(1, 16)                                                      \\\n+                                                                            \\\n+  product(uint, G1RemoveSelfForwardPtrsThreadLoadFactor, 16, DIAGNOSTIC,    \\\n+          \"The factor for per worker thread load to remove self forwardee \" \\\n+          \"for evecuation failure regions.\")                                \\\n+          range(1, 1024)                                                    \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/gc\/g1\/g1_globals.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -277,0 +277,2 @@\n+  clear_index_in_opt_cset();\n+\n@@ -281,0 +283,1 @@\n+  _prev_top_at_mark_start = top();\n@@ -297,5 +300,2 @@\n-void HeapRegion::note_self_forwarding_removal_end(size_t marked_bytes) {\n-  assert(marked_bytes <= used(),\n-         \"marked: \" SIZE_FORMAT \" used: \" SIZE_FORMAT, marked_bytes, used());\n-  _prev_top_at_mark_start = top();\n-  _prev_marked_bytes = marked_bytes;\n+void HeapRegion::note_self_forwarding_removal_end_par(size_t marked_bytes) {\n+  Atomic::add(&_prev_marked_bytes, marked_bytes, memory_order_relaxed);\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -504,3 +504,3 @@\n-  \/\/ Notify the region that we have finished processing self-forwarded\n-  \/\/ objects during evac failure handling.\n-  void note_self_forwarding_removal_end(size_t marked_bytes);\n+  \/\/ Notify the region that we have partially finished processing self-forwarded\n+  \/\/ objects during evacuation failure handling.\n+  void note_self_forwarding_removal_end_par(size_t marked_bytes);\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"}]}