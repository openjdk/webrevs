{"files":[{"patch":"@@ -110,1 +110,2 @@\n-  uint dummy = 0;\n+  uint regions_ready_for_refresh = 0u;\n+  uint32_t old_epoch_id = AtomicAccess::load(&_epoch_id);\n@@ -112,1 +113,1 @@\n-  HeapWord* obj = attempt_allocation_in_alloc_regions(req, in_new_region, alloc_start_index(), dummy);\n+  HeapWord* obj = attempt_allocation_in_alloc_regions(req, in_new_region, alloc_start_index(), regions_ready_for_refresh);\n@@ -117,1 +118,1 @@\n-  return attempt_allocation_slow(req, in_new_region);\n+  return attempt_allocation_slow(req, in_new_region, regions_ready_for_refresh, old_epoch_id);\n@@ -121,1 +122,1 @@\n-HeapWord* ShenandoahAllocator<ALLOC_PARTITION>::attempt_allocation_slow(ShenandoahAllocRequest& req, bool& in_new_region) {\n+HeapWord* ShenandoahAllocator<ALLOC_PARTITION>::attempt_allocation_slow(ShenandoahAllocRequest& req, bool& in_new_region, uint regions_ready_for_refresh, uint32_t old_epoch_id) {\n@@ -123,6 +124,9 @@\n-  uint regions_ready_for_refresh = 0u;\n-  \/\/ Attempt to allocate in shared alloc regions after taking heap lock,\n-  \/\/ because other mutator may have refreshed shared alloc regions\n-  HeapWord* obj = attempt_allocation_in_alloc_regions<true \/*holding heap lock*\/>(req, in_new_region, alloc_start_index(), regions_ready_for_refresh);\n-  if (obj != nullptr) {\n-    return obj;\n+  HeapWord* obj = nullptr;\n+  if (old_epoch_id != _epoch_id) {\n+    \/\/ After taking heap lock, attempt to allocate in shared alloc regions again\n+    \/\/ if alloc regions have been refreshed by other thread while current thread waits to take heap lock.\n+    regions_ready_for_refresh = 0u; \/\/reset regions_ready_for_refresh to 0.\n+    obj = attempt_allocation_in_alloc_regions<true \/*holding heap lock*\/>(req, in_new_region, alloc_start_index(), regions_ready_for_refresh);\n+    if (obj != nullptr) {\n+      return obj;\n+    }\n@@ -202,1 +206,2 @@\n-    } else if (r == nullptr || !r->is_active_alloc_region()) {\n+    } else {\n+      \/\/ Empty shared alloc region slot is always ready for refresh\n@@ -265,1 +270,1 @@\n-    if (region == nullptr ||  !region->is_active_alloc_region() || free_bytes \/ HeapWordSize < PLAB::min_size()) {\n+    if (region == nullptr || free_bytes \/ HeapWordSize < PLAB::min_size()) {\n@@ -267,3 +272,1 @@\n-        if (region->is_active_alloc_region()) {\n-          region->unset_active_alloc_region();\n-        }\n+        region->unset_active_alloc_region();\n@@ -290,0 +293,1 @@\n+      int refreshed_regions = 0;\n@@ -308,0 +312,6 @@\n+        refreshed_regions++;\n+      }\n+\n+      if (refreshed_regions > 0) {\n+        \/\/ Increase _epoch_id by 1 when any of alloc regions has been refreshed.\n+        AtomicAccess::inc(&_epoch_id);\n@@ -345,4 +355,2 @@\n-      if (r->is_active_alloc_region()) {\n-        r->unset_active_alloc_region();\n-      }\n-      AtomicAccess::store(&alloc_region.address, static_cast<ShenandoahHeapRegion*>(nullptr));\n+      r->unset_active_alloc_region();\n+      alloc_region.address = nullptr;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahAllocator.cpp","additions":27,"deletions":19,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"gc\/shenandoah\/shenandoahPadding.hpp\"\n@@ -53,0 +54,4 @@\n+  shenandoah_padding(0);\n+  volatile uint32_t                  _epoch_id = 0u; \/\/ epoch id of _alloc_regions, increase by 1 whenever refresh _alloc_regions.\n+  shenandoah_padding(1);\n+\n@@ -66,1 +71,1 @@\n-  HeapWord* attempt_allocation_slow(ShenandoahAllocRequest& req, bool& in_new_region);\n+  HeapWord* attempt_allocation_slow(ShenandoahAllocRequest& req, bool& in_new_region, uint regions_ready_for_refresh, uint32_t old_epoch_id);\n@@ -68,2 +73,4 @@\n-  \/\/ Attempt to allocate from a region in free set, rather than from any of shared alloc regions.\n-  \/\/ Caller have to hold heap lock.\n+  \/\/ Attempt to allocate from a region in free set, rather than from any of shared alloc regions, it might be called in the conditions below:\n+  \/\/   1. _alloc_region_count is explicitly set to 0 to disable CAS allocator;\n+  \/\/   2. all the shared alloc regions are not ready to retire, nor have enough space for allocation.\n+  \/\/ Caller has to hold heap lock.\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahAllocator.hpp","additions":10,"deletions":3,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -173,1 +173,1 @@\n-  for (;;) {\n+  for (;\/*Always return in the loop*\/;) {\n@@ -196,1 +196,1 @@\n-  for (;;) {\n+  for (;\/*Always return in the loop*\/;) {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeapRegion.inline.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"}]}