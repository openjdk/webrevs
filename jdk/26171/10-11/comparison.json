{"files":[{"patch":"@@ -1193,42 +1193,1 @@\n-PaddedEnd<ShenandoahDirectlyAllocatableRegionAffinity::Affinity>* ShenandoahDirectlyAllocatableRegionAffinity::_affinity = nullptr;\n-THREAD_LOCAL Thread* ShenandoahDirectlyAllocatableRegionAffinity::_self = DIRECTLY_ALLOCATABLE_REGION_UNKNOWN_SELF;\n-THREAD_LOCAL uint ShenandoahDirectlyAllocatableRegionAffinity::_index = 0;\n-\n-uint ShenandoahDirectlyAllocatableRegionAffinity::index_slow() {\n-  \/\/ Set current thread\n-  if (_self == DIRECTLY_ALLOCATABLE_REGION_UNKNOWN_SELF) {\n-    _self = Thread::current();\n-  }\n-\n-  \/\/ Create a new random index where the thread will start allocation\n-  _index = static_cast<uint>(os::random()) % ShenandoahDirectlyAllocatableRegionCount;\n-\n-  \/\/ Update affinity table\n-  _affinity[_index]._thread = _self;\n-\n-  return _index;\n-}\n-\n-void ShenandoahDirectlyAllocatableRegionAffinity::initialize() {\n-  assert(_affinity == nullptr, \"Already initialized\");\n-  _affinity = PaddedArray<Affinity, mtGC>::create_unfreeable(ShenandoahDirectlyAllocatableRegionCount);\n-  for (uint32_t i = 0; i < ShenandoahDirectlyAllocatableRegionCount; i++) {\n-    _affinity[i]._thread = DIRECTLY_ALLOCATABLE_REGION_UNKNOWN_AFFINITY;\n-  }\n-}\n-\n-uint ShenandoahDirectlyAllocatableRegionAffinity::index() {\n-  assert(_affinity != nullptr, \"Not initialized\");\n-  \/\/ Fast path\n-  if (_affinity[_index]._thread == _self) {\n-    return _index;\n-  }\n-\n-  \/\/ Slow path\n-  return index_slow();\n-}\n-\n-void ShenandoahDirectlyAllocatableRegionAffinity::set_index(uint index) {\n-  _index = index;\n-  _affinity[_index]._thread = _self;\n-}\n+THREAD_LOCAL uint ShenandoahFreeSet::_alloc_region_index = UINT_MAX;\n@@ -1258,1 +1217,0 @@\n-  ShenandoahDirectlyAllocatableRegionAffinity::initialize();\n@@ -3399,1 +3357,1 @@\n-  uint start_idx = ShenandoahDirectlyAllocatableRegionAffinity::index();\n+  uint start_idx = alloc_region_index();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFreeSet.cpp","additions":2,"deletions":44,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -419,23 +419,0 @@\n-#define DIRECTLY_ALLOCATABLE_REGION_UNKNOWN_AFFINITY ((Thread*)-1)\n-#define DIRECTLY_ALLOCATABLE_REGION_UNKNOWN_SELF     ((Thread*)-2)\n-\/\/ When mutator threads allocate from directly allocatable regions, ideally the allocation should be evenly\n-\/\/ distributed to all the directly allocatable regions, random is the best portable option for this, but with random\n-\/\/ distribution it may worsen memory locality, e.g. two consecutive allocation from same thread are randomly\n-\/\/ distributed to different allocatable regions. ShenandoahDirectlyAllocatableRegionAffinity solves\/mitigates\n-\/\/ the memory locality issue.\n-\/\/ The idea and code is borrowed from ZGC's CPU affinity, but with random number instead of CPU id.\n-class ShenandoahDirectlyAllocatableRegionAffinity : public AllStatic {\n-  struct Affinity {\n-    Thread* _thread;\n-  };\n-\n-  static PaddedEnd<Affinity>* _affinity;\n-  static THREAD_LOCAL Thread* _self;\n-  static THREAD_LOCAL uint    _index;\n-  static uint index_slow();\n-public:\n-  static void initialize();\n-  static uint index();\n-  static void set_index(uint index);\n-};\n-\n@@ -484,0 +461,1 @@\n+  static THREAD_LOCAL uint _alloc_region_index;\n@@ -706,0 +684,7 @@\n+  static uint alloc_region_index() {\n+    if (_alloc_region_index == UINT_MAX) {\n+      _alloc_region_index = abs(os::random()) % ShenandoahDirectlyAllocatableRegionCount;\n+    }\n+    return _alloc_region_index;\n+  }\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFreeSet.hpp","additions":8,"deletions":23,"binary":false,"changes":31,"status":"modified"}]}