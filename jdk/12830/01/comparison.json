{"files":[{"patch":"@@ -196,22 +196,8 @@\n-HeapWord*\n-G1CollectedHeap::humongous_obj_allocate_initialize_regions(HeapRegion* first_hr,\n-                                                           uint num_regions,\n-                                                           size_t word_size) {\n-  assert(first_hr != NULL, \"pre-condition\");\n-  assert(is_humongous(word_size), \"word_size should be humongous\");\n-  assert(num_regions * HeapRegion::GrainWords >= word_size, \"pre-condition\");\n-\n-  \/\/ Index of last region in the series.\n-  uint first = first_hr->hrm_index();\n-  uint last = first + num_regions - 1;\n-\n-  \/\/ We need to initialize the region(s) we just discovered. This is\n-  \/\/ a bit tricky given that it can happen concurrently with\n-  \/\/ refinement threads refining cards on these regions and\n-  \/\/ potentially wanting to refine the BOT as they are scanning\n-  \/\/ those cards (this can happen shortly after a cleanup; see CR\n-  \/\/ 6991377). So we have to set up the region(s) carefully and in\n-  \/\/ a specific order.\n-\n-  \/\/ The word size sum of all the regions we will allocate.\n-  size_t word_size_sum = (size_t) num_regions * HeapRegion::GrainWords;\n+void G1CollectedHeap::reset_humongous_metadata(HeapRegion* first_hr,\n+                                               uint num_regions,\n+                                               size_t word_size,\n+                                               bool update_remsets) {\n+  \/\/ Calculate the new top of the humongous object.\n+  HeapWord* obj_top = first_hr->bottom() + word_size;\n+  \/\/ The word size sum of all the regions used\n+  size_t word_size_sum = num_regions * HeapRegion::GrainWords;\n@@ -220,20 +206,2 @@\n-  \/\/ The passed in hr will be the \"starts humongous\" region. The header\n-  \/\/ of the new object will be placed at the bottom of this region.\n-  HeapWord* new_obj = first_hr->bottom();\n-  \/\/ This will be the new top of the new object.\n-  HeapWord* obj_top = new_obj + word_size;\n-\n-  \/\/ First, we need to zero the header of the space that we will be\n-  \/\/ allocating. When we update top further down, some refinement\n-  \/\/ threads might try to scan the region. By zeroing the header we\n-  \/\/ ensure that any thread that will try to scan the region will\n-  \/\/ come across the zero klass word and bail out.\n-  \/\/\n-  \/\/ NOTE: It would not have been correct to have used\n-  \/\/ CollectedHeap::fill_with_object() and make the space look like\n-  \/\/ an int array. The thread that is doing the allocation will\n-  \/\/ later update the object header to a potentially different array\n-  \/\/ type and, for a very short period of time, the klass and length\n-  \/\/ fields will be inconsistent. This could cause a refinement\n-  \/\/ thread to calculate the object size incorrectly.\n-  Copy::fill_to_words(new_obj, oopDesc::header_size(), 0);\n+  \/\/ How many words memory we \"waste\" which cannot hold a filler object.\n+  size_t words_not_fillable = 0;\n@@ -241,1 +209,1 @@\n-  \/\/ Next, pad out the unused tail of the last region with filler\n+  \/\/ Pad out the unused tail of the last region with filler\n@@ -243,2 +211,0 @@\n-  \/\/ How many words we use for filler objects.\n-  size_t word_fill_size = word_size_sum - word_size;\n@@ -246,2 +212,2 @@\n-  \/\/ How many words memory we \"waste\" which cannot hold a filler object.\n-  size_t words_not_fillable = 0;\n+  \/\/ How many words can we use for filler objects.\n+  size_t words_fillable = word_size_sum - word_size;\n@@ -249,3 +215,3 @@\n-  if (word_fill_size >= min_fill_size()) {\n-    fill_with_objects(obj_top, word_fill_size);\n-  } else if (word_fill_size > 0) {\n+  if (words_fillable >= G1CollectedHeap::min_fill_size()) {\n+    G1CollectedHeap::fill_with_objects(obj_top, words_fillable);\n+  } else {\n@@ -253,2 +219,2 @@\n-    words_not_fillable = word_fill_size;\n-    word_fill_size = 0;\n+    words_not_fillable = words_fillable;\n+    words_fillable = 0;\n@@ -261,5 +227,12 @@\n-  first_hr->set_starts_humongous(obj_top, word_fill_size);\n-  _policy->remset_tracker()->update_at_allocate(first_hr);\n-  \/\/ Then, if there are any, we will set up the \"continues\n-  \/\/ humongous\" regions.\n-  HeapRegion* hr = NULL;\n+  first_hr->hr_clear(false \/* clear_space *\/);\n+  first_hr->set_starts_humongous(obj_top, words_fillable);\n+\n+  if (update_remsets) {\n+    _policy->remset_tracker()->update_at_allocate(first_hr);\n+  }\n+\n+  \/\/ Indices of first and last regions in the series.\n+  uint first = first_hr->hrm_index();\n+  uint last = first + num_regions - 1;\n+\n+  HeapRegion* hr = nullptr;\n@@ -268,0 +241,1 @@\n+    hr->hr_clear(false \/* clear_space *\/);\n@@ -269,1 +243,3 @@\n-    _policy->remset_tracker()->update_at_allocate(hr);\n+    if (update_remsets) {\n+      _policy->remset_tracker()->update_at_allocate(hr);\n+    }\n@@ -300,0 +276,21 @@\n+}\n+\n+HeapWord*\n+G1CollectedHeap::humongous_obj_allocate_initialize_regions(HeapRegion* first_hr,\n+                                                           uint num_regions,\n+                                                           size_t word_size) {\n+  assert(first_hr != NULL, \"pre-condition\");\n+  assert(is_humongous(word_size), \"word_size should be humongous\");\n+  assert(num_regions * HeapRegion::GrainWords >= word_size, \"pre-condition\");\n+\n+  \/\/ Index of last region in the series.\n+  uint first = first_hr->hrm_index();\n+  uint last = first + num_regions - 1;\n+\n+  \/\/ We need to initialize the region(s) we just discovered. This is\n+  \/\/ a bit tricky given that it can happen concurrently with\n+  \/\/ refinement threads refining cards on these regions and\n+  \/\/ potentially wanting to refine the BOT as they are scanning\n+  \/\/ those cards (this can happen shortly after a cleanup; see CR\n+  \/\/ 6991377). So we have to set up the region(s) carefully and in\n+  \/\/ a specific order.\n@@ -301,1 +298,26 @@\n-  increase_used((word_size_sum - words_not_fillable) * HeapWordSize);\n+  \/\/ The passed in hr will be the \"starts humongous\" region. The header\n+  \/\/ of the new object will be placed at the bottom of this region.\n+  HeapWord* new_obj = first_hr->bottom();\n+\n+  \/\/ First, we need to zero the header of the space that we will be\n+  \/\/ allocating. When we update top further down, some refinement\n+  \/\/ threads might try to scan the region. By zeroing the header we\n+  \/\/ ensure that any thread that will try to scan the region will\n+  \/\/ come across the zero klass word and bail out.\n+  \/\/\n+  \/\/ NOTE: It would not have been correct to have used\n+  \/\/ CollectedHeap::fill_with_object() and make the space look like\n+  \/\/ an int array. The thread that is doing the allocation will\n+  \/\/ later update the object header to a potentially different array\n+  \/\/ type and, for a very short period of time, the klass and length\n+  \/\/ fields will be inconsistent. This could cause a refinement\n+  \/\/ thread to calculate the object size incorrectly.\n+  Copy::fill_to_words(new_obj, oopDesc::header_size(), 0);\n+\n+  \/\/ Next, update the metadata for the regions.\n+  reset_humongous_metadata(first_hr, num_regions, word_size, true);\n+\n+  HeapRegion* last_hr = region_at(last);\n+  size_t used = byte_size(first_hr->bottom(), last_hr->top());\n+\n+  increase_used(used);\n@@ -304,1 +326,1 @@\n-    hr = region_at(i);\n+    HeapRegion *hr = region_at(i);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":82,"deletions":60,"binary":false,"changes":142,"status":"modified"},{"patch":"@@ -609,0 +609,5 @@\n+  void reset_humongous_metadata(HeapRegion* first_hr,\n+                                uint num_regions,\n+                                size_t word_size,\n+                                bool update_remsets);\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -43,1 +43,1 @@\n-#include \"gc\/shared\/preservedMarks.hpp\"\n+#include \"gc\/shared\/preservedMarks.inline.hpp\"\n@@ -122,0 +122,1 @@\n+    _has_humongous(false),\n@@ -126,0 +127,1 @@\n+    _humongous_compaction_point(this),\n@@ -128,0 +130,1 @@\n+    _humongous_compaction_regions(8),\n@@ -158,0 +161,1 @@\n+\n@@ -249,0 +253,2 @@\n+\n+  _heap->print_heap_after_full_collection();\n@@ -346,0 +352,6 @@\n+\n+    if (scope()->do_maximal_compaction() &&\n+        has_humongous() &&\n+        serial_compaction_point()->has_regions()) {\n+      phase2d_prepare_humongous_compaction();\n+    }\n@@ -421,0 +433,29 @@\n+void G1FullCollector::phase2d_prepare_humongous_compaction() {\n+  GCTraceTime(Debug, gc, phases) debug(\"Phase 2: Prepare humongous compaction\", scope()->timer());\n+  G1FullGCCompactionPoint* serial_cp = serial_compaction_point();\n+  assert(serial_cp->has_regions(), \"Sanity!\" );\n+\n+  uint last_serial_target = serial_cp->current_region()->hrm_index();\n+  uint region_index = last_serial_target + 1;\n+  uint max_reserved_regions = _heap->max_reserved_regions();\n+\n+  G1FullGCCompactionPoint* humongous_cp = humongous_compaction_point();\n+\n+  while (region_index < max_reserved_regions) {\n+    HeapRegion* hr = _heap->region_at_or_null(region_index);\n+\n+    if (hr == nullptr) {\n+      region_index++;\n+      continue;\n+    } else if (hr->is_starts_humongous()) {\n+      uint num_regions = humongous_cp->forward_humongous(hr);\n+      region_index += num_regions; \/\/ Skip over the continues humongous regions.\n+      continue;\n+    } else if (is_compaction_target(region_index)) {\n+      \/\/ Add the region to the humongous compaction point.\n+      humongous_cp->add(hr);\n+    }\n+    region_index++;\n+  }\n+}\n+\n@@ -439,0 +480,5 @@\n+\n+  if (!_humongous_compaction_regions.is_empty()) {\n+    assert(scope()->do_maximal_compaction(), \"Only compact humongous during maximal compaction\");\n+    task.humongous_compaction();\n+  }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullCollector.cpp","additions":47,"deletions":1,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -79,0 +79,1 @@\n+  bool                      _has_humongous;\n@@ -85,0 +86,1 @@\n+  G1FullGCCompactionPoint   _humongous_compaction_point;\n@@ -88,0 +90,1 @@\n+  GrowableArrayCHeap<HeapRegion*, mtGC> _humongous_compaction_regions;\n@@ -118,0 +121,1 @@\n+  G1FullGCCompactionPoint* humongous_compaction_point() { return &_humongous_compaction_point; }\n@@ -137,0 +141,1 @@\n+  inline void update_from_skip_compacting_to_compacting(uint region_idx);\n@@ -144,0 +149,3 @@\n+  inline void add_humongous_region(HeapRegion* hr);\n+  inline GrowableArrayCHeap<HeapRegion*, mtGC>& humongous_compaction_regions();\n+\n@@ -146,0 +154,3 @@\n+  inline void set_has_humongous();\n+  inline bool has_humongous();\n+\n@@ -153,0 +164,1 @@\n+  void phase2d_prepare_humongous_compaction();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullCollector.hpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -64,0 +64,5 @@\n+void G1FullCollector::update_from_skip_compacting_to_compacting(uint region_idx) {\n+  DEBUG_ONLY(_region_attr_table.verify_is_skip_compacting(region_idx);)\n+  _region_attr_table.set_compacting(region_idx);\n+}\n+\n@@ -82,0 +87,18 @@\n+void G1FullCollector::set_has_humongous() {\n+  if (!_has_humongous) {\n+    _has_humongous = true;\n+  }\n+}\n+\n+bool G1FullCollector::has_humongous() {\n+  return _has_humongous;\n+}\n+\n+void G1FullCollector::add_humongous_region(HeapRegion* hr) {\n+  _humongous_compaction_regions.append(hr);\n+}\n+\n+GrowableArrayCHeap<HeapRegion*, mtGC>& G1FullCollector::humongous_compaction_regions() {\n+  return _humongous_compaction_regions;\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullCollector.inline.hpp","additions":23,"deletions":0,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -45,10 +45,1 @@\n-    HeapWord* destination = cast_from_oop<HeapWord*>(obj->forwardee());\n-\n-    \/\/ copy object and reinit its mark\n-    HeapWord* obj_addr = cast_from_oop<HeapWord*>(obj);\n-    assert(obj_addr != destination, \"everything in this pass should be moving\");\n-    Copy::aligned_conjoint_words(obj_addr, destination, size);\n-\n-    \/\/ There is no need to transform stack chunks - marking already did that.\n-    cast_to_oop(destination)->init_mark();\n-    assert(cast_to_oop(destination)->klass() != NULL, \"should have a class\");\n+    G1FullGCCompactTask::copy_object_to_new_location(obj);\n@@ -63,0 +54,15 @@\n+void G1FullGCCompactTask::copy_object_to_new_location(oop obj) {\n+  assert(obj->is_forwarded(), \"Sanity!\");\n+  assert(obj->forwardee() != obj, \"Object must have a new location\");\n+\n+  size_t size = obj->size();\n+  \/\/ Copy object and reinit its mark.\n+  HeapWord* obj_addr = cast_from_oop<HeapWord*>(obj);\n+  HeapWord* destination = cast_from_oop<HeapWord*>(obj->forwardee());\n+  Copy::aligned_conjoint_words(obj_addr, destination, size);\n+\n+  \/\/ There is no need to transform stack chunks - marking already did that.\n+  cast_to_oop(destination)->init_mark();\n+  assert(cast_to_oop(destination)->klass() != nullptr, \"should have a class\");\n+}\n+\n@@ -101,0 +107,46 @@\n+\n+void G1FullGCCompactTask::humongous_compaction() {\n+  GCTraceTime(Debug, gc, phases) tm(\"Phase 4: Humonguous Compaction\", collector()->scope()->timer());\n+\n+  for (HeapRegion* hr : collector()->humongous_compaction_regions()) {\n+    assert(collector()->is_compaction_target(hr->hrm_index()), \"Sanity\");\n+    compact_humongous_obj(hr);\n+  }\n+}\n+\n+void G1FullGCCompactTask::compact_humongous_obj(HeapRegion* src_hr) {\n+  assert(src_hr->is_starts_humongous(), \"Should be start region of the humongous object\");\n+\n+  oop obj = cast_to_oop(src_hr->bottom());\n+  size_t word_size = obj->size();\n+\n+  uint num_regions = (uint)G1CollectedHeap::humongous_obj_size_in_regions(word_size);\n+  HeapWord* destination = cast_from_oop<HeapWord*>(obj->forwardee());\n+\n+  assert(collector()->mark_bitmap()->is_marked(obj), \"Should only compact marked objects\");\n+  collector()->mark_bitmap()->clear(obj);\n+\n+  copy_object_to_new_location(obj);\n+\n+  uint dest_start_idx = _g1h->addr_to_region(destination);\n+  \/\/ Update the metadata for the destination regions.\n+  _g1h->reset_humongous_metadata(_g1h->region_at(dest_start_idx), num_regions, word_size, false);\n+\n+  \/\/ Free the source regions that do not overlap with the destination regions.\n+  uint src_start_idx = src_hr->hrm_index();\n+  free_non_overlapping_regions(src_start_idx, dest_start_idx, num_regions);\n+}\n+\n+void G1FullGCCompactTask::free_non_overlapping_regions(uint src_start_idx, uint dest_start_idx, uint num_regions) {\n+  uint dest_end_idx = dest_start_idx + num_regions -1;\n+  uint src_end_idx  = src_start_idx + num_regions - 1;\n+\n+  uint non_overlapping_start = dest_end_idx < src_start_idx ?\n+                               src_start_idx :\n+                               dest_end_idx + 1;\n+\n+  for (uint i = non_overlapping_start; i <= src_end_idx; ++i) {\n+    HeapRegion* hr = _g1h->region_at(i);\n+    _g1h->free_humongous_region(hr, nullptr);\n+  }\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactTask.cpp","additions":62,"deletions":10,"binary":false,"changes":72,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+  G1CollectedHeap* _g1h;\n@@ -43,0 +44,4 @@\n+  void compact_humongous_obj(HeapRegion* hr);\n+  void free_non_overlapping_regions(uint src_start_idx, uint dest_start_idx, uint num_regions);\n+\n+  static void copy_object_to_new_location(oop obj);\n@@ -48,1 +53,3 @@\n-    _claimer(collector->workers()) { }\n+    _claimer(collector->workers()),\n+    _g1h(G1CollectedHeap::heap()) { }\n+\n@@ -51,0 +58,1 @@\n+  void humongous_compaction();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactTask.hpp","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/shared\/preservedMarks.inline.hpp\"\n@@ -133,0 +134,83 @@\n+\n+void G1FullGCCompactionPoint::add_humongous(HeapRegion* hr) {\n+  assert(hr->is_starts_humongous(), \"Sanity!\");\n+\n+  _collector->add_humongous_region(hr);\n+\n+  G1CollectedHeap* g1h = G1CollectedHeap::heap();\n+  do {\n+    add(hr);\n+    _collector->update_from_skip_compacting_to_compacting(hr->hrm_index());\n+    hr = g1h->next_region_in_humongous(hr);\n+  } while (hr != nullptr);\n+}\n+\n+uint G1FullGCCompactionPoint::forward_humongous(HeapRegion* hr) {\n+  assert(hr->is_starts_humongous(), \"Sanity!\");\n+\n+  oop obj = cast_to_oop(hr->bottom());\n+  size_t obj_size = obj->size();\n+  uint num_regions = (uint)G1CollectedHeap::humongous_obj_size_in_regions(obj_size);\n+\n+  if (!has_regions()) {\n+    return num_regions;\n+  }\n+\n+  \/\/ Find contiguous compaction target regions for the humongous object.\n+  Pair<uint, uint> range = find_contiguous_before(hr, num_regions);\n+  uint range_begin = range.first;\n+  uint range_end = range.second;\n+\n+  if (range_begin == range_end) {\n+    \/\/ No contiguous compaction target regions found, so the object cannot be moved.\n+    return num_regions;\n+  }\n+\n+  \/\/ Preserve the mark for the humongous object as the region was initially not compacting.\n+  _collector->marker(0)->preserved_stack()->push_if_necessary(obj, obj->mark());\n+\n+  HeapRegion* dest_hr = _compaction_regions->at(range_begin);\n+  obj->forward_to(cast_to_oop(dest_hr->bottom()));\n+  assert(obj->is_forwarded(), \"Object must be forwarded!\");\n+\n+  \/\/ Add the humongous object regions to the compaction point.\n+  add_humongous(hr);\n+\n+  \/\/ Remove covered regions from compaction target candidates.\n+  _compaction_regions->remove_range(range_begin, (range_begin + num_regions));\n+\n+  return num_regions;\n+}\n+\n+Pair<uint, uint> G1FullGCCompactionPoint::find_contiguous_before(HeapRegion* hr, uint num_regions) {\n+  assert(num_regions > 0, \"Sanity!\");\n+  assert(has_regions(), \"Sanity!\");\n+\n+  if (num_regions == 1) {\n+    \/\/ If only one region, return the first region.\n+    return Pair<uint, uint> (0, 1);\n+  }\n+\n+  uint contiguous_region_count = 1;\n+\n+  uint range_end = 1;\n+  uint range_limit = (uint)_compaction_regions->length();\n+\n+  for (; range_end < range_limit; range_end++) {\n+    if (contiguous_region_count == num_regions) {\n+      break;\n+    }\n+    \/\/ Check if the current region and the previous region are contiguous.\n+    bool regions_are_contiguous = (_compaction_regions->at(range_end)->hrm_index() - _compaction_regions->at(range_end - 1)->hrm_index()) == 1;\n+    contiguous_region_count = regions_are_contiguous ? contiguous_region_count + 1 : 1;\n+  }\n+\n+  if (contiguous_region_count < num_regions &&\n+      hr->hrm_index() -  _compaction_regions->at(range_end-1)->hrm_index() != 1) {\n+    \/\/ We reached the end but the final region is not contiguous with the target region,\n+    \/\/ reset the length to 1.\n+    contiguous_region_count = 1;\n+  }\n+  \/\/ Return the indices of the first and last contiguous regions.\n+  return Pair<uint, uint> (range_end - contiguous_region_count, range_end - 1);\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactionPoint.cpp","additions":84,"deletions":0,"binary":false,"changes":84,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"utilities\/pair.hpp\"\n@@ -46,0 +47,1 @@\n+  Pair<uint, uint> find_contiguous_before(HeapRegion* hr, uint num_regions);\n@@ -56,0 +58,1 @@\n+  uint forward_humongous(HeapRegion* hr);\n@@ -57,0 +60,1 @@\n+  void add_humongous(HeapRegion* hr);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactionPoint.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -87,0 +87,2 @@\n+  void verify_is_skip_compacting(uint idx) { assert(get_by_index(idx) == SkipCompacting, \"invariant\"); }\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCHeapRegionAttr.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -92,0 +92,2 @@\n+      } else {\n+        _collector->set_has_humongous();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCPrepareTask.inline.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -119,3 +119,1 @@\n-  assert(_humongous_start_region == NULL,\n-         \"we should have already filtered out humongous regions\");\n-\n+  set_top(bottom());\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.cpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -184,2 +184,0 @@\n-  assert(!is_pinned(), \"must be\");\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.inline.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -257,1 +257,9 @@\n-    for (int i = 0, j = idx; j < length(); i++, j++) {\n+    remove_range(0, idx);\n+  }\n+\n+  \/\/ Remove all elements in the range [start - end). The order is preserved.\n+  void remove_range(int start, int end) {\n+    assert(0 <= start, \"illegal index\");\n+    assert(start < end && end <= _len, \"erase called with invalid range\");\n+\n+    for (int i = start, j = end; j < length(); i++, j++) {\n@@ -260,1 +268,1 @@\n-    trunc_to(length() - idx);\n+    trunc_to(length() - (end - start));\n","filename":"src\/hotspot\/share\/utilities\/growableArray.hpp","additions":10,"deletions":2,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,0 +2,1 @@\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -167,0 +168,12 @@\n+ \/*\n+ * @test id=g1\n+ * @summary Make sure G1 can recover from humongous allocation fragmentation\n+ * @key randomness\n+ * @requires vm.gc.G1\n+ * @library \/test\/lib\n+ *\n+ * @run main\/othervm -Xlog:gc+region=trace -XX:+UnlockDiagnosticVMOptions -XX:+UnlockExperimentalVMOptions -Xmx1g -Xms1g\n+ *      -XX:VerifyGCType=full -XX:+VerifyDuringGC -XX:+VerifyAfterGC\n+ *      TestAllocHumongousFragment\n+ *\/\n+\n","filename":"test\/hotspot\/jtreg\/gc\/TestAllocHumongousFragment.java","additions":13,"deletions":0,"binary":false,"changes":13,"previous_filename":"test\/hotspot\/jtreg\/gc\/shenandoah\/TestAllocHumongousFragment.java","status":"renamed"}]}