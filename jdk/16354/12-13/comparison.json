{"files":[{"patch":"@@ -1575,34 +1575,0 @@\n-void C2_MacroAssembler::vgather8b_masked(BasicType elem_bt, XMMRegister dst,\n-                                         Register base, Register idx_base,\n-                                         Register mask, Register midx,\n-                                         Register rtmp, int vlen_enc) {\n-  vpxor(dst, dst, dst, vlen_enc);\n-  if (elem_bt == T_SHORT) {\n-    Label case0, case1, case2, case3;\n-    Label *larr[] = {&case0, &case1, &case2, &case3};\n-    for (int i = 0; i < 4; i++) {\n-      \/\/ dst[i] = mask ? src[index[i]] : 0\n-      btq(mask, midx);\n-      jccb(Assembler::carryClear, *larr[i]);\n-      movl(rtmp, Address(idx_base, i * 4));\n-      pinsrw(dst, Address(base, rtmp, Address::times_2), i);\n-      bind(*larr[i]);\n-      incq(midx);\n-    }\n-  } else {\n-    assert(elem_bt == T_BYTE, \"\");\n-    Label case0, case1, case2, case3, case4, case5, case6, case7;\n-    Label *larr[] = {&case0, &case1, &case2, &case3,\n-                     &case4, &case5, &case6, &case7};\n-    for (int i = 0; i < 8; i++) {\n-      \/\/ dst[i] = mask ? src[index[i]] : 0\n-      btq(mask, midx);\n-      jccb(Assembler::carryClear, *larr[i]);\n-      movl(rtmp, Address(idx_base, i * 4));\n-      pinsrb(dst, Address(base, rtmp), i);\n-      bind(*larr[i]);\n-      incq(midx);\n-    }\n-  }\n-}\n-\n@@ -1613,1 +1579,1 @@\n-                                                Register midx, Register rtmp,\n+                                                Register mask_idx, Register rtmp,\n@@ -1618,1 +1584,1 @@\n-    Label *larr[] = {&case0, &case1, &case2, &case3};\n+    Label* larr[] = {&case0, &case1, &case2, &case3};\n@@ -1620,2 +1586,2 @@\n-      \/\/ dst[i] = mask ? src[offset + index[i]] : 0\n-      btq(mask, midx);\n+      \/\/ dst[i] = mask[i] ? src[offset + idx_base[i]] : 0\n+      btq(mask, mask_idx);\n@@ -1624,1 +1590,3 @@\n-      addl(rtmp, offset);\n+      if (offset != noreg) {\n+        addl(rtmp, offset);\n+      }\n@@ -1627,1 +1595,1 @@\n-      incq(midx);\n+      incq(mask_idx);\n@@ -1632,1 +1600,1 @@\n-    Label *larr[] = {&case0, &case1, &case2, &case3,\n+    Label* larr[] = {&case0, &case1, &case2, &case3,\n@@ -1635,2 +1603,2 @@\n-      \/\/ dst[i] = mask ? src[offset + index[i]] : 0\n-      btq(mask, midx);\n+      \/\/ dst[i] = mask[i] ? src[offset + idx_base[i]] : 0\n+      btq(mask, mask_idx);\n@@ -1639,1 +1607,3 @@\n-      addl(rtmp, offset);\n+      if (offset != noreg) {\n+        addl(rtmp, offset);\n+      }\n@@ -1642,1 +1612,1 @@\n-      incq(midx);\n+      incq(mask_idx);\n@@ -1648,20 +1618,0 @@\n-void C2_MacroAssembler::vgather8b(BasicType elem_bt, XMMRegister dst,\n-                                  Register base, Register idx_base,\n-                                  Register rtmp, int vlen_enc) {\n-  vpxor(dst, dst, dst, vlen_enc);\n-  if (elem_bt == T_SHORT) {\n-    for (int i = 0; i < 4; i++) {\n-      \/\/ dst[i] = src[index[i]]\n-      movl(rtmp, Address(idx_base, i * 4));\n-      pinsrw(dst, Address(base, rtmp, Address::times_2), i);\n-    }\n-  } else {\n-    assert(elem_bt == T_BYTE, \"\");\n-    for (int i = 0; i < 8; i++) {\n-      \/\/ dst[i] = src[index[i]]\n-      movl(rtmp, Address(idx_base, i * 4));\n-      pinsrb(dst, Address(base, rtmp), i);\n-    }\n-  }\n-}\n-\n@@ -1675,1 +1625,1 @@\n-      \/\/ dst[i] = src[offset + index[i]]\n+      \/\/ dst[i] = src[offset + idx_base[i]]\n@@ -1677,1 +1627,3 @@\n-      addl(rtmp, offset);\n+      if (offset != noreg) {\n+        addl(rtmp, offset);\n+      }\n@@ -1683,1 +1635,1 @@\n-      \/\/ dst[i] = src[offset + index[i]]\n+      \/\/ dst[i] = src[offset + idx_base[i]]\n@@ -1685,1 +1637,3 @@\n-      addl(rtmp, offset);\n+      if (offset != noreg) {\n+        addl(rtmp, offset);\n+      }\n@@ -1692,2 +1646,4 @@\n- * Gather loop first packs 4 short \/ 8 byte values from gather indices\n- * into quadword lane and then permutes quadword lane into appropriate\n+ * Gather using hybrid algorithm which initially partially unrolls scalar loop\n+ * to accumulates values from gather indices into a quad-word(64bit) slice, a\n+ * slice may hold 8 bytes or 4 short values. This is followed by a vector\n+ * permutation to place the slice into appropriate vector lanes\n@@ -1695,1 +1651,1 @@\n- * algorithm in detail:-\n+ * algorithm in detail:\n@@ -1707,1 +1663,1 @@\n- * to assembled quadword gets right shifted by two lane position.\n+ * to gathered quadword gets right shifted by two lane position.\n@@ -1715,1 +1671,1 @@\n-                                        Register midx, Register length,\n+                                        Register mask_idx, Register length,\n@@ -1723,1 +1679,1 @@\n-  vpsubd(xtmp2, xtmp1, xtmp2 ,vlen_enc);\n+  vpsubd(xtmp2, xtmp1, xtmp2, vlen_enc);\n@@ -1727,6 +1683,2 @@\n-    if (offset == noreg) {\n-      if (mask == noreg) {\n-        vgather8b(elem_ty, xtmp3, base, idx_base, rtmp, vlen_enc);\n-      } else {\n-        LP64_ONLY(vgather8b_masked(elem_ty, xtmp3, base, idx_base, mask, midx, rtmp, vlen_enc));\n-      }\n+    if (mask == noreg) {\n+      vgather8b_offset(elem_ty, xtmp3, base, idx_base, offset, rtmp, vlen_enc);\n@@ -1734,5 +1686,1 @@\n-      if (mask == noreg) {\n-        vgather8b_offset(elem_ty, xtmp3, base, idx_base, offset, rtmp, vlen_enc);\n-      } else {\n-        LP64_ONLY(vgather8b_masked_offset(elem_ty, xtmp3, base, idx_base, offset, mask, midx, rtmp, vlen_enc));\n-      }\n+      LP64_ONLY(vgather8b_masked_offset(elem_ty, xtmp3, base, idx_base, offset, mask, mask_idx, rtmp, vlen_enc));\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":34,"deletions":86,"binary":false,"changes":120,"status":"modified"},{"patch":"@@ -505,3 +505,0 @@\n-  void vgather8b_masked(BasicType elem_bt, XMMRegister dst, Register base, Register idx_base,\n-                        Register mask, Register midx, Register rtmp, int vlen_enc);\n-\n@@ -511,3 +508,0 @@\n-\n-  void vgather8b(BasicType elem_bt, XMMRegister dst, Register base, Register idx_base, Register rtmp, int vlen_enc);\n-\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -4111,1 +4111,1 @@\n-instruct vgather_subwordLE8B(vec dst, memory mem, rRegP idx, immI_0 offset, rRegP tmp, rRegI rtmp) %{\n+instruct vgather_subwordLE8B(vec dst, memory mem, rRegP idx_base, immI_0 offset, rRegP tmp, rRegI rtmp) %{\n@@ -4113,1 +4113,1 @@\n-  match(Set dst (LoadVectorGather mem (Binary idx offset)));\n+  match(Set dst (LoadVectorGather mem (Binary idx_base offset)));\n@@ -4115,1 +4115,1 @@\n-  format %{ \"vector_gatherLE8 $dst, $mem, $idx\\t! using $tmp and $rtmp as TEMP\" %}\n+  format %{ \"vector_gatherLE8 $dst, $mem, $idx_base\\t! using $tmp and $rtmp as TEMP\" %}\n@@ -4120,1 +4120,1 @@\n-    __ vgather8b(elem_bt, $dst$$XMMRegister, $tmp$$Register, $idx$$Register, $rtmp$$Register, vlen_enc);\n+    __ vgather8b_offset(elem_bt, $dst$$XMMRegister, $tmp$$Register, $idx_base$$Register, noreg, $rtmp$$Register, vlen_enc);\n@@ -4125,1 +4125,1 @@\n-instruct vgather_subwordGT8B(vec dst, memory mem, rRegP idx, immI_0 offset, rRegP tmp, rRegP idx_base_temp,\n+instruct vgather_subwordGT8B(vec dst, memory mem, rRegP idx_base, immI_0 offset, rRegP tmp, rRegP idx_base_temp,\n@@ -4128,1 +4128,1 @@\n-  match(Set dst (LoadVectorGather mem (Binary idx offset)));\n+  match(Set dst (LoadVectorGather mem (Binary idx_base offset)));\n@@ -4130,1 +4130,1 @@\n-  format %{ \"vector_gatherGT8 $dst, $mem, $idx\\t! using $tmp, $idx_base_temp, $xtmp1, $xtmp2, $xtmp3, $rtmp and $length as TEMP\" %}\n+  format %{ \"vector_gatherGT8 $dst, $mem, $idx_base\\t! using $tmp, $idx_base_temp, $xtmp1, $xtmp2, $xtmp3, $rtmp and $length as TEMP\" %}\n@@ -4136,1 +4136,1 @@\n-    __ movptr($idx_base_temp$$Register, $idx$$Register);\n+    __ movptr($idx_base_temp$$Register, $idx_base$$Register);\n@@ -4143,1 +4143,1 @@\n-instruct vgather_subwordLE8B_off(vec dst, memory mem, rRegP idx, rRegI offset, rRegP tmp, rRegI rtmp, rFlagsReg cr) %{\n+instruct vgather_subwordLE8B_off(vec dst, memory mem, rRegP idx_base, rRegI offset, rRegP tmp, rRegI rtmp, rFlagsReg cr) %{\n@@ -4145,1 +4145,1 @@\n-  match(Set dst (LoadVectorGather mem (Binary idx offset)));\n+  match(Set dst (LoadVectorGather mem (Binary idx_base offset)));\n@@ -4147,1 +4147,1 @@\n-  format %{ \"vector_gatherLE8 $dst, $mem, $idx, $offset\\t! using $tmp and $rtmp as TEMP\" %}\n+  format %{ \"vector_gatherLE8_off $dst, $mem, $idx_base, $offset\\t! using $tmp and $rtmp as TEMP\" %}\n@@ -4152,1 +4152,1 @@\n-    __ vgather8b_offset(elem_bt, $dst$$XMMRegister, $tmp$$Register, $idx$$Register, $offset$$Register, $rtmp$$Register, vlen_enc);\n+    __ vgather8b_offset(elem_bt, $dst$$XMMRegister, $tmp$$Register, $idx_base$$Register, $offset$$Register, $rtmp$$Register, vlen_enc);\n@@ -4158,1 +4158,1 @@\n-instruct vgather_subwordGT8B_off(vec dst, memory mem, rRegP idx, rRegI offset, rRegP tmp, rRegP idx_base_temp,\n+instruct vgather_subwordGT8B_off(vec dst, memory mem, rRegP idx_base, rRegI offset, rRegP tmp, rRegP idx_base_temp,\n@@ -4161,1 +4161,1 @@\n-  match(Set dst (LoadVectorGather mem (Binary idx offset)));\n+  match(Set dst (LoadVectorGather mem (Binary idx_base offset)));\n@@ -4163,1 +4163,1 @@\n-  format %{ \"vector_gatherGT8 $dst, $mem, $idx, $offset\\t! using $tmp, $idx_base_temp, $xtmp1, $xtmp2, $xtmp3, $rtmp and $length as TEMP\" %}\n+  format %{ \"vector_gatherGT8_off $dst, $mem, $idx_base, $offset\\t! using $tmp, $idx_base_temp, $xtmp1, $xtmp2, $xtmp3, $rtmp and $length as TEMP\" %}\n@@ -4169,1 +4169,1 @@\n-    __ movptr($idx_base_temp$$Register, $idx$$Register);\n+    __ movptr($idx_base_temp$$Register, $idx_base$$Register);\n@@ -4178,1 +4178,1 @@\n-instruct vgather_masked_subwordLE8B_avx3(vec dst, memory mem, rRegP idx, immI_0 offset, kReg mask, rRegL midx, rRegP tmp, rRegI rtmp, rRegL rtmp2, rFlagsReg cr) %{\n+instruct vgather_masked_subwordLE8B_avx3(vec dst, memory mem, rRegP idx_base, immI_0 offset, kReg mask, rRegL mask_idx, rRegP tmp, rRegI rtmp, rRegL rtmp2, rFlagsReg cr) %{\n@@ -4180,3 +4180,3 @@\n-  match(Set dst (LoadVectorGatherMasked mem (Binary idx (Binary mask offset))));\n-  effect(TEMP midx, TEMP tmp, TEMP rtmp, TEMP rtmp2, KILL cr);\n-  format %{ \"vector_masked_gatherLE8 $dst, $mem, $idx, $mask\\t! using $midx, $tmp, $rtmp and $rtmp2 as TEMP\" %}\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx_base (Binary mask offset))));\n+  effect(TEMP mask_idx, TEMP tmp, TEMP rtmp, TEMP rtmp2, KILL cr);\n+  format %{ \"vector_masked_gatherLE8 $dst, $mem, $idx_base, $mask\\t! using $mask_idx, $tmp, $rtmp and $rtmp2 as TEMP\" %}\n@@ -4186,1 +4186,1 @@\n-    __ xorq($midx$$Register, $midx$$Register);\n+    __ xorq($mask_idx$$Register, $mask_idx$$Register);\n@@ -4189,1 +4189,1 @@\n-    __ vgather8b_masked(elem_bt, $dst$$XMMRegister, $tmp$$Register, $idx$$Register, $rtmp2$$Register, $midx$$Register, $rtmp$$Register, vlen_enc);\n+    __ vgather8b_masked_offset(elem_bt, $dst$$XMMRegister, $tmp$$Register, $idx_base$$Register, noreg, $rtmp2$$Register, $mask_idx$$Register, $rtmp$$Register, vlen_enc);\n@@ -4194,2 +4194,2 @@\n-instruct vgather_masked_subwordGT8B_avx3(vec dst, memory mem, rRegP idx, immI_0 offset, kReg mask, rRegP tmp, rRegP idx_base_temp,\n-                                         vec xtmp1, vec xtmp2, vec xtmp3, rRegI rtmp, rRegL rtmp2, rRegL midx, rRegI length, rFlagsReg cr) %{\n+instruct vgather_masked_subwordGT8B_avx3(vec dst, memory mem, rRegP idx_base, immI_0 offset, kReg mask, rRegP tmp, rRegP idx_base_temp,\n+                                         vec xtmp1, vec xtmp2, vec xtmp3, rRegI rtmp, rRegL rtmp2, rRegL mask_idx, rRegI length, rFlagsReg cr) %{\n@@ -4197,3 +4197,3 @@\n-  match(Set dst (LoadVectorGatherMasked mem (Binary idx (Binary mask offset))));\n-  effect(TEMP_DEF dst, TEMP tmp, TEMP idx_base_temp, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP rtmp, TEMP rtmp2, TEMP midx, TEMP length, KILL cr);\n-  format %{ \"vector_gatherGT8_masked $dst, $mem, $idx, $mask\\t! using $tmp, $idx_base_temp, $xtmp1, $xtmp2, $xtmp3, $rtmp, $rtmp2, $midx and $length as TEMP\" %}\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx_base (Binary mask offset))));\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP idx_base_temp, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP rtmp, TEMP rtmp2, TEMP mask_idx, TEMP length, KILL cr);\n+  format %{ \"vector_gatherGT8_masked $dst, $mem, $idx_base, $mask\\t! using $tmp, $idx_base_temp, $xtmp1, $xtmp2, $xtmp3, $rtmp, $rtmp2, $mask_idx and $length as TEMP\" %}\n@@ -4204,1 +4204,1 @@\n-    __ xorq($midx$$Register, $midx$$Register);\n+    __ xorq($mask_idx$$Register, $mask_idx$$Register);\n@@ -4206,1 +4206,1 @@\n-    __ movptr($idx_base_temp$$Register, $idx$$Register);\n+    __ movptr($idx_base_temp$$Register, $idx_base$$Register);\n@@ -4209,1 +4209,1 @@\n-                       $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $rtmp$$Register, $midx$$Register, $length$$Register, vector_len, vlen_enc);\n+                       $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $rtmp$$Register, $mask_idx$$Register, $length$$Register, vector_len, vlen_enc);\n@@ -4214,1 +4214,1 @@\n-instruct vgather_masked_subwordLE8B_off_avx3(vec dst, memory mem, rRegP idx, rRegI offset, kReg mask, rRegL midx, rRegP tmp, rRegI rtmp, rRegL rtmp2, rFlagsReg cr) %{\n+instruct vgather_masked_subwordLE8B_off_avx3(vec dst, memory mem, rRegP idx_base, rRegI offset, kReg mask, rRegL mask_idx, rRegP tmp, rRegI rtmp, rRegL rtmp2, rFlagsReg cr) %{\n@@ -4216,3 +4216,3 @@\n-  match(Set dst (LoadVectorGatherMasked mem (Binary idx (Binary mask offset))));\n-  effect(TEMP midx, TEMP tmp, TEMP rtmp, TEMP rtmp2, KILL cr);\n-  format %{ \"vector_masked_gatherLE8_off $dst, $mem, $idx, $offset, $mask\\t! using $midx, $tmp, $rtmp and $rtmp2 as TEMP\" %}\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx_base (Binary mask offset))));\n+  effect(TEMP mask_idx, TEMP tmp, TEMP rtmp, TEMP rtmp2, KILL cr);\n+  format %{ \"vector_masked_gatherLE8_off $dst, $mem, $idx_base, $offset, $mask\\t! using $mask_idx, $tmp, $rtmp and $rtmp2 as TEMP\" %}\n@@ -4222,1 +4222,1 @@\n-    __ xorq($midx$$Register, $midx$$Register);\n+    __ xorq($mask_idx$$Register, $mask_idx$$Register);\n@@ -4225,2 +4225,2 @@\n-    __ vgather8b_masked_offset(elem_bt, $dst$$XMMRegister, $tmp$$Register, $idx$$Register, $offset$$Register,\n-                                $rtmp2$$Register, $midx$$Register, $rtmp$$Register, vlen_enc);\n+    __ vgather8b_masked_offset(elem_bt, $dst$$XMMRegister, $tmp$$Register, $idx_base$$Register, $offset$$Register,\n+                                $rtmp2$$Register, $mask_idx$$Register, $rtmp$$Register, vlen_enc);\n@@ -4231,2 +4231,2 @@\n-instruct vgather_masked_subwordGT8B_off_avx3(vec dst, memory mem, rRegP idx, rRegI offset, kReg mask, rRegP tmp, rRegP idx_base_temp,\n-                                             vec xtmp1, vec xtmp2, vec xtmp3, rRegI rtmp, rRegL rtmp2, rRegL midx, rRegI length, rFlagsReg cr) %{\n+instruct vgather_masked_subwordGT8B_off_avx3(vec dst, memory mem, rRegP idx_base, rRegI offset, kReg mask, rRegP tmp, rRegP idx_base_temp,\n+                                             vec xtmp1, vec xtmp2, vec xtmp3, rRegI rtmp, rRegL rtmp2, rRegL mask_idx, rRegI length, rFlagsReg cr) %{\n@@ -4234,3 +4234,3 @@\n-  match(Set dst (LoadVectorGatherMasked mem (Binary idx (Binary mask offset))));\n-  effect(TEMP_DEF dst, TEMP tmp, TEMP idx_base_temp, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP rtmp, TEMP rtmp2, TEMP midx, TEMP length, KILL cr);\n-  format %{ \"vector_gatherGT8_masked_off $dst, $mem, $idx, $offset, $mask\\t! using $tmp, $idx_base_temp, $xtmp1, $xtmp2, $xtmp3, $rtmp, $rtmp2, $midx and $length as TEMP\" %}\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx_base (Binary mask offset))));\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP idx_base_temp, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP rtmp, TEMP rtmp2, TEMP mask_idx, TEMP length, KILL cr);\n+  format %{ \"vector_gatherGT8_masked_off $dst, $mem, $idx_base, $offset, $mask\\t! using $tmp, $idx_base_temp, $xtmp1, $xtmp2, $xtmp3, $rtmp, $rtmp2, $mask_idx and $length as TEMP\" %}\n@@ -4241,1 +4241,1 @@\n-    __ xorq($midx$$Register, $midx$$Register);\n+    __ xorq($mask_idx$$Register, $mask_idx$$Register);\n@@ -4243,1 +4243,1 @@\n-    __ movptr($idx_base_temp$$Register, $idx$$Register);\n+    __ movptr($idx_base_temp$$Register, $idx_base$$Register);\n@@ -4246,1 +4246,1 @@\n-                       $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $rtmp$$Register, $midx$$Register, $length$$Register, vector_len, vlen_enc);\n+                       $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $rtmp$$Register, $mask_idx$$Register, $length$$Register, vector_len, vlen_enc);\n@@ -4251,1 +4251,1 @@\n-instruct vgather_masked_subwordLE8B_avx2(vec dst, memory mem, rRegP idx, immI_0 offset, vec mask, rRegI midx, rRegP tmp, rRegI rtmp, rRegI rtmp2, rFlagsReg cr) %{\n+instruct vgather_masked_subwordLE8B_avx2(vec dst, memory mem, rRegP idx_base, immI_0 offset, vec mask, rRegI mask_idx, rRegP tmp, rRegI rtmp, rRegI rtmp2, rFlagsReg cr) %{\n@@ -4253,3 +4253,3 @@\n-  match(Set dst (LoadVectorGatherMasked mem (Binary idx (Binary mask offset))));\n-  effect(TEMP midx, TEMP tmp, TEMP rtmp, TEMP rtmp2, KILL cr);\n-  format %{ \"vector_masked_gatherLE8 $dst, $mem, $idx, $mask\\t! using $midx, $tmp, $rtmp and $rtmp2 as TEMP\" %}\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx_base (Binary mask offset))));\n+  effect(TEMP mask_idx, TEMP tmp, TEMP rtmp, TEMP rtmp2, KILL cr);\n+  format %{ \"vector_masked_gatherLE8 $dst, $mem, $idx_base, $mask\\t! using $mask_idx, $tmp, $rtmp and $rtmp2 as TEMP\" %}\n@@ -4262,2 +4262,2 @@\n-      __ movl($midx$$Register, 0x55555555);\n-      __ pextl($rtmp2$$Register, $rtmp2$$Register, $midx$$Register);\n+      __ movl($mask_idx$$Register, 0x55555555);\n+      __ pextl($rtmp2$$Register, $rtmp2$$Register, $mask_idx$$Register);\n@@ -4265,2 +4265,2 @@\n-    __ xorl($midx$$Register, $midx$$Register);\n-    __ vgather8b_masked(elem_bt, $dst$$XMMRegister, $tmp$$Register, $idx$$Register, $rtmp2$$Register, $midx$$Register, $rtmp$$Register, vlen_enc);\n+    __ xorl($mask_idx$$Register, $mask_idx$$Register);\n+    __ vgather8b_masked_offset(elem_bt, $dst$$XMMRegister, $tmp$$Register, $idx_base$$Register, noreg, $rtmp2$$Register, $mask_idx$$Register, $rtmp$$Register, vlen_enc);\n@@ -4271,2 +4271,2 @@\n-instruct vgather_masked_subwordGT8B_avx2(vec dst, memory mem, rRegP idx, immI_0 offset, vec mask, rRegP tmp, rRegP idx_base_temp,\n-                                         vec xtmp1, vec xtmp2, vec xtmp3, rRegI rtmp, rRegI rtmp2, rRegI midx, rRegI length, rFlagsReg cr) %{\n+instruct vgather_masked_subwordGT8B_avx2(vec dst, memory mem, rRegP idx_base, immI_0 offset, vec mask, rRegP tmp, rRegP idx_base_temp,\n+                                         vec xtmp1, vec xtmp2, vec xtmp3, rRegI rtmp, rRegI rtmp2, rRegI mask_idx, rRegI length, rFlagsReg cr) %{\n@@ -4274,3 +4274,3 @@\n-  match(Set dst (LoadVectorGatherMasked mem (Binary idx (Binary mask offset))));\n-  effect(TEMP_DEF dst, TEMP tmp, TEMP idx_base_temp, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP rtmp, TEMP rtmp2, TEMP midx, TEMP length, KILL cr);\n-  format %{ \"vector_gatherGT8_masked $dst, $mem, $idx, $mask\\t! using $tmp, $idx_base_temp, $xtmp1, $xtmp2, $xtmp3, $rtmp, $rtmp2, $midx and $length as TEMP\" %}\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx_base (Binary mask offset))));\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP idx_base_temp, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP rtmp, TEMP rtmp2, TEMP mask_idx, TEMP length, KILL cr);\n+  format %{ \"vector_gatherGT8_masked $dst, $mem, $idx_base, $mask\\t! using $tmp, $idx_base_temp, $xtmp1, $xtmp2, $xtmp3, $rtmp, $rtmp2, $mask_idx and $length as TEMP\" %}\n@@ -4282,1 +4282,1 @@\n-    __ movptr($idx_base_temp$$Register, $idx$$Register);\n+    __ movptr($idx_base_temp$$Register, $idx_base$$Register);\n@@ -4285,2 +4285,2 @@\n-      __ movl($midx$$Register, 0x55555555);\n-      __ pextl($rtmp2$$Register, $rtmp2$$Register, $midx$$Register);\n+      __ movl($mask_idx$$Register, 0x55555555);\n+      __ pextl($rtmp2$$Register, $rtmp2$$Register, $mask_idx$$Register);\n@@ -4288,1 +4288,1 @@\n-    __ xorl($midx$$Register, $midx$$Register);\n+    __ xorl($mask_idx$$Register, $mask_idx$$Register);\n@@ -4290,1 +4290,1 @@\n-                       $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $rtmp$$Register, $midx$$Register, $length$$Register, vector_len, vlen_enc);\n+                       $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $rtmp$$Register, $mask_idx$$Register, $length$$Register, vector_len, vlen_enc);\n@@ -4295,1 +4295,1 @@\n-instruct vgather_masked_subwordLE8B_off_avx2(vec dst, memory mem, rRegP idx, rRegI offset, vec mask, rRegI midx, rRegP tmp, rRegI rtmp, rRegI rtmp2, rFlagsReg cr) %{\n+instruct vgather_masked_subwordLE8B_off_avx2(vec dst, memory mem, rRegP idx_base, rRegI offset, vec mask, rRegI mask_idx, rRegP tmp, rRegI rtmp, rRegI rtmp2, rFlagsReg cr) %{\n@@ -4297,3 +4297,3 @@\n-  match(Set dst (LoadVectorGatherMasked mem (Binary idx (Binary mask offset))));\n-  effect(TEMP midx, TEMP tmp, TEMP rtmp, TEMP rtmp2, KILL cr);\n-  format %{ \"vector_masked_gatherLE8_off $dst, $mem, $idx, $offset, $mask\\t! using $midx, $tmp, $rtmp and $rtmp2 as TEMP\" %}\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx_base (Binary mask offset))));\n+  effect(TEMP mask_idx, TEMP tmp, TEMP rtmp, TEMP rtmp2, KILL cr);\n+  format %{ \"vector_masked_gatherLE8_off $dst, $mem, $idx_base, $offset, $mask\\t! using $mask_idx, $tmp, $rtmp and $rtmp2 as TEMP\" %}\n@@ -4306,2 +4306,2 @@\n-      __ movl($midx$$Register, 0x55555555);\n-      __ pextl($rtmp2$$Register, $rtmp2$$Register, $midx$$Register);\n+      __ movl($mask_idx$$Register, 0x55555555);\n+      __ pextl($rtmp2$$Register, $rtmp2$$Register, $mask_idx$$Register);\n@@ -4309,3 +4309,3 @@\n-    __ xorl($midx$$Register, $midx$$Register);\n-    __ vgather8b_masked_offset(elem_bt, $dst$$XMMRegister, $tmp$$Register, $idx$$Register, $offset$$Register,\n-                                $rtmp2$$Register, $midx$$Register, $rtmp$$Register, vlen_enc);\n+    __ xorl($mask_idx$$Register, $mask_idx$$Register);\n+    __ vgather8b_masked_offset(elem_bt, $dst$$XMMRegister, $tmp$$Register, $idx_base$$Register, $offset$$Register,\n+                                $rtmp2$$Register, $mask_idx$$Register, $rtmp$$Register, vlen_enc);\n@@ -4316,2 +4316,2 @@\n-instruct vgather_masked_subwordGT8B_off_avx2(vec dst, memory mem, rRegP idx, rRegI offset, vec mask, rRegP tmp, rRegP idx_base_temp,\n-                                             vec xtmp1, vec xtmp2, vec xtmp3, rRegI rtmp, rRegI rtmp2, rRegI midx, rRegI length, rFlagsReg cr) %{\n+instruct vgather_masked_subwordGT8B_off_avx2(vec dst, memory mem, rRegP idx_base, rRegI offset, vec mask, rRegP tmp, rRegP idx_base_temp,\n+                                             vec xtmp1, vec xtmp2, vec xtmp3, rRegI rtmp, rRegI rtmp2, rRegI mask_idx, rRegI length, rFlagsReg cr) %{\n@@ -4319,3 +4319,3 @@\n-  match(Set dst (LoadVectorGatherMasked mem (Binary idx (Binary mask offset))));\n-  effect(TEMP_DEF dst, TEMP tmp, TEMP idx_base_temp, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP rtmp, TEMP rtmp2, TEMP midx, TEMP length, KILL cr);\n-  format %{ \"vector_gatherGT8_masked_off $dst, $mem, $idx, $offset, $mask\\t! using $tmp, $idx_base_temp, $xtmp1, $xtmp2, $xtmp3, $rtmp, $rtmp2, $midx and $length as TEMP\" %}\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx_base (Binary mask offset))));\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP idx_base_temp, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP rtmp, TEMP rtmp2, TEMP mask_idx, TEMP length, KILL cr);\n+  format %{ \"vector_gatherGT8_masked_off $dst, $mem, $idx_base, $offset, $mask\\t! using $tmp, $idx_base_temp, $xtmp1, $xtmp2, $xtmp3, $rtmp, $rtmp2, $mask_idx and $length as TEMP\" %}\n@@ -4326,1 +4326,1 @@\n-    __ xorl($midx$$Register, $midx$$Register);\n+    __ xorl($mask_idx$$Register, $mask_idx$$Register);\n@@ -4328,1 +4328,1 @@\n-    __ movptr($idx_base_temp$$Register, $idx$$Register);\n+    __ movptr($idx_base_temp$$Register, $idx_base$$Register);\n@@ -4331,2 +4331,2 @@\n-      __ movl($midx$$Register, 0x55555555);\n-      __ pextl($rtmp2$$Register, $rtmp2$$Register, $midx$$Register);\n+      __ movl($mask_idx$$Register, 0x55555555);\n+      __ pextl($rtmp2$$Register, $rtmp2$$Register, $mask_idx$$Register);\n@@ -4334,1 +4334,1 @@\n-    __ xorl($midx$$Register, $midx$$Register);\n+    __ xorl($mask_idx$$Register, $mask_idx$$Register);\n@@ -4336,1 +4336,1 @@\n-                       $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $rtmp$$Register, $midx$$Register, $length$$Register, vector_len, vlen_enc);\n+                       $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $rtmp$$Register, $mask_idx$$Register, $length$$Register, vector_len, vlen_enc);\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":83,"deletions":83,"binary":false,"changes":166,"status":"modified"}]}