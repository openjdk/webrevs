{"files":[{"patch":"@@ -478,1 +478,1 @@\n-          \"Use policy to limit of proportion of time spent in GC \"          \\\n+          \"Use policy to limit proportion of time spent in GC \"             \\\n","filename":"src\/hotspot\/share\/gc\/shared\/gc_globals.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -57,0 +57,1 @@\n+\n@@ -72,0 +73,5 @@\n+  \/\/ We use this as the time period for tracking minimum mutator utilization (MMU).\n+  if (FLAG_IS_DEFAULT(GCPauseIntervalMillis)) {\n+    FLAG_SET_DEFAULT(GCPauseIntervalMillis, 5000);\n+  }\n+\n@@ -180,0 +186,8 @@\n+\n+  \/\/ If ParallelGCThreads is greater than active_processor_count, use ShenandoahGCTimeLimit as GCTimeLimit\n+  uint active_processors = os::initial_active_processor_count();\n+  uint gc_time_limit = ((active_processors < ParallelGCThreads)?\n+                        ShenandoahGCTimeLimit: (ShenandoahGCTimeLimit * ParallelGCThreads) \/ active_processors);\n+  FLAG_SET_DEFAULT(GCTimeLimit, gc_time_limit);\n+  log_info(gc)(\"GCTimeLimit set to %u based on ShenandoahGCTimeLimit: %u, ParallelGCThreads: %u, active_processors: %u)\",\n+               GCTimeLimit, ShenandoahGCTimeLimit, ParallelGCThreads, active_processors);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahArguments.cpp","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -404,0 +404,4 @@\n+  if (!heap->cancelled_gc()) {\n+    ShenandoahMmuTracker* mmu_tracker = heap->mmu_tracker();\n+    mmu_tracker->record_global(get_gc_id());\n+  }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahControlThread.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -52,0 +52,1 @@\n+  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n@@ -53,0 +54,1 @@\n+  heap->mmu_tracker()->record_degenerated(GCId::current());\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahDegeneratedGC.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -103,0 +103,1 @@\n+  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n@@ -109,2 +110,1 @@\n-  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n-\n+  heap->mmu_tracker()->record_full(GCId::current());\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFullGC.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -443,0 +443,7 @@\n+  _gc_historical_utilization = NEW_C_HEAP_ARRAY(double, GCOverheadLimitThreshold, mtGC);\n+  _gc_historical_duration = NEW_C_HEAP_ARRAY(double, GCOverheadLimitThreshold, mtGC);\n+  for (uint i = 0; i < GCOverheadLimitThreshold; i++) {\n+    _gc_historical_utilization[i] = 0.0;\n+    _gc_historical_duration[i] = 0.0;\n+  }\n+\n@@ -509,0 +516,3 @@\n+  _gcu_historical(0.0),\n+  _gc_history_first(0),\n+  _gc_no_progress_count_at_last_oom(-1),\n@@ -548,1 +558,1 @@\n-                                                ParallelGCThreads);\n+                                                     ParallelGCThreads);\n@@ -651,0 +661,2 @@\n+  _mmu_tracker.initialize();\n+\n@@ -864,1 +876,18 @@\n-HeapWord* ShenandoahHeap::allocate_memory(ShenandoahAllocRequest& req) {\n+\/\/ This captures GC utilization at end of each GC pass for purposes of detecting GC overhead exceeded.\n+void ShenandoahHeap::report_gc_utilization(double utilization, double duration) {\n+  _gc_historical_utilization[_gc_history_first] = utilization;\n+  _gc_historical_duration[_gc_history_first] = duration;\n+  _gc_history_first++;\n+  if (_gc_history_first >= GCOverheadLimitThreshold) {\n+    _gc_history_first = 0;\n+  }\n+  double weighted_sum = 0.0;\n+  double total_duration = 0.0;\n+  for (uint i = 0; i < GCOverheadLimitThreshold; i++) {\n+    weighted_sum += _gc_historical_utilization[i] * _gc_historical_duration[i];\n+    total_duration += _gc_historical_duration[i];\n+  }\n+  _gcu_historical = ((total_duration > 0)? weighted_sum \/ total_duration: 0.0);\n+}\n+\n+HeapWord* ShenandoahHeap::allocate_memory(ShenandoahAllocRequest& req, bool* gc_overhead_limit_was_exceeded) {\n@@ -879,11 +908,33 @@\n-    \/\/ Check that gc overhead is not exceeded.\n-    \/\/\n-    \/\/ Shenandoah will grind along for quite a while allocating one\n-    \/\/ object at a time using shared (non-tlab) allocations. This check\n-    \/\/ is testing that the GC overhead limit has not been exceeded.\n-    \/\/ This will notify the collector to start a cycle, but will raise\n-    \/\/ an OOME to the mutator if the last Full GCs have not made progress.\n-    if (result == nullptr && !req.is_lab_alloc() && get_gc_no_progress_count() > ShenandoahNoProgressThreshold) {\n-      control_thread()->handle_alloc_failure(req, false);\n-      return nullptr;\n-    }\n+    \/\/ It might happen that one of the threads requesting allocation would unblock way later after GC happened, only\n+    \/\/ to fail a second allocation request because other threads have already depleted the free storage.  Repeatedly\n+    \/\/ retry the allocation after blocking until the control thread has had a chance to perform more GC.\n+\n+    if (result == nullptr) {\n+      intptr_t no_progress_count = get_gc_no_progress_count();\n+      intptr_t no_progress_count_at_last_oom = get_gc_no_progress_count_at_last_oom();\n+      if (no_progress_count_at_last_oom >= 0) {\n+        \/\/ The rationale for only immediately throwing OOM if !is_lab_alloc is that lab_allocs are speculative\n+        \/\/ allocations.  The mutator has not yet demanded this memory, so it would be inappropriate to penalize\n+        \/\/ the mutator with an OOM.  Note that a typical mutator response to a failed lab alloc will be to\n+        \/\/ request a shared alloc, so the mutator will eventually see an OOM when it demands the shared alloc.\n+        \/\/\n+        \/\/ TODO: experiment with immediately throwing the OOM even for lab allocs.  does this cause premature OOM?\n+        if (!req.is_lab_alloc() &&\n+            no_progress_count >= (intptr_t) (no_progress_count_at_last_oom + ShenandoahNoProgressThreshold)) {\n+          \/\/ We've experienced ShenandoahNoProgressThreshold consecutive GCs without progress following an\n+          \/\/ initial OOM condition.  We've provided plenty of opportunity for the application to recover\n+          \/\/ from its OOM situation, and it hasn't.  Don't waste any more efforts on urgent GC.\n+          \/\/\n+          \/\/ Note that a successful allocation following an initial OOM is not sufficient to end our counting\n+          \/\/ of consecutive unproductive GCs following an initial OOM condition.  Even after an unproductive\n+          \/\/ GC, we may be able to allocate a small number of small objects.  But we won't be able to allocate\n+          \/\/ large objects or large numbers of objects between GCs until we begin to experience productive GCs.\n+          \/\/\n+          \/\/ Note that even if we no longer trigger GCs in response to failed allocation request, GCs will still\n+          \/\/ be triggered by heuristics, and these GCs may eventually recover from the low-memory situation.\n+          if (UseGCOverheadLimit && (gc_overhead_limit_was_exceeded != nullptr)) {\n+            *gc_overhead_limit_was_exceeded = true;\n+          }\n+          return nullptr;\n+        }\n+      }\n@@ -891,12 +942,67 @@\n-    \/\/ Block until control thread reacted, then retry allocation.\n-    \/\/\n-    \/\/ It might happen that one of the threads requesting allocation would unblock\n-    \/\/ way later after GC happened, only to fail the second allocation, because\n-    \/\/ other threads have already depleted the free storage. In this case, a better\n-    \/\/ strategy is to try again, as long as GC makes progress (or until at least\n-    \/\/ one full GC has completed).\n-    size_t original_count = shenandoah_policy()->full_gc_count();\n-    while (result == nullptr\n-        && (get_gc_no_progress_count() == 0 || original_count == shenandoah_policy()->full_gc_count())) {\n-      control_thread()->handle_alloc_failure(req);\n-      result = allocate_memory_under_lock(req, in_new_region);\n+      size_t original_count = shenandoah_policy()->full_gc_count();\n+      if (UseGCOverheadLimit) {\n+        \/\/ \"Use policy to limit proportion of time spent in GC before an OutOfMemory error is thrown.\"\n+        \/\/\n+        \/\/ But this policy alone is not sufficient.  In some cases, heuristics limit the number of threads dedicated to\n+        \/\/ STW degenerated and Full GCs.  In other cases, contention with other applications running on the same\n+        \/\/ host may prevent GC threads from consuming the full CPU time to which they might be entitled.  Both scenarios\n+        \/\/ may prevent GC overhead from reaching the threshold required by GC in order to exceed the threshold.\n+\n+        do {\n+          control_thread()->handle_alloc_failure(req);\n+          result = allocate_memory_under_lock(req, in_new_region);\n+\n+          \/\/ A first failure to allocate may happen due to unfortunate timing in that memory just happens to have been\n+          \/\/ consumed by other threads by the time my request arrives.  If we fail a second time after giving GC an opportunity\n+          \/\/ to clean up memory, we should return nullptr.\n+\n+          \/\/ We are careful to not cascade the throwing of OOM.  Some applications are written to allow a first OOM \"handler\"\n+          \/\/ to clean up memory so that other threads will not experience OOM.  Waiting for a second failure to allocate\n+          \/\/ allows the memory cleanup efforts of a first thread to be realized.  If memory is successfully reclaimed by a\n+          \/\/ subsequent concurrent GC, the gc overhead will typically decrease before this quantity is sampled again.\n+\n+          \/\/ This strategy is not perfect.  If the first OOM thread is too slow to clean up memory, or it does not\n+          \/\/ clean up enough memory, or if other threads consume all of the newly available memory before this thread\n+          \/\/ has an opportunity to repeat its request, the current thread will also experience OOM.\n+\n+        } while ((result == nullptr) && !gc_overhead_exceeds_limit() && (original_count == shenandoah_policy()->full_gc_count()));\n+\n+        \/\/ With Shenandoah, there are two mechanisms to detect violation of the limit: CPU time or a full GC with no progress.\n+        if (result == nullptr) {\n+          intptr_t no_progess_count = get_gc_no_progress_count();\n+          intptr_t no_progress_count_at_last_oom = get_gc_no_progress_count_at_last_oom();\n+          if (no_progress_count_at_last_oom == -1) {\n+            capture_gc_no_progress_count_at_last_oom();\n+          }\n+          if ((gc_overhead_limit_was_exceeded != nullptr) &&\n+              (gc_overhead_exceeds_limit() ||\n+               ((original_count != shenandoah_policy()->full_gc_count()) && (no_progress_count != 0)))) {\n+            *gc_overhead_limit_was_exceeded = true;\n+          }\n+        }\n+      } else {\n+        \/\/ Retry allocation request until at least one full GC has completed\n+\n+        do {\n+          control_thread()->handle_alloc_failure(req);\n+          result = allocate_memory_under_lock(req, in_new_region);\n+\n+          \/\/ A first failure to allocate may happen due to unfortunate timing in that memory just happens to have been\n+          \/\/ consumed by other threads by the time my request arrives.  If we fail a second time after giving GC an opportunity\n+          \/\/ to clean up memory, we should return nullptr (triggering an OutOfMemoryError) if there has been at least one full\n+          \/\/ GC collection, whether or not that Full GC had good progress.\n+\n+          \/\/ This strategy is not perfect.  If the full gc made good progress and replenished the free pool, but other threads\n+          \/\/ consumed all available memory before this thread was able to satisfy its allocation request, we will throw OOM\n+          \/\/ even though we may have been able to satisfy our allocation request following yet another GC.  If this happens,\n+          \/\/ we are operating too close to the edge, and an OOM is appropriate.\n+\n+        } while (result == nullptr && (original_count == shenandoah_policy()->full_gc_count()));\n+\n+        if (result == nullptr) {\n+          intptr_t no_progress_count_at_last_oom = get_gc_no_progress_count_at_last_oom();\n+          if (no_progress_count_at_last_oom == -1) {\n+            capture_gc_no_progress_count_at_last_oom();\n+          }\n+        }\n+      }\n@@ -907,2 +1013,3 @@\n-      log_debug(gc, alloc)(\"Thread: %s, Result: \" PTR_FORMAT \", Request: %s, Size: \" SIZE_FORMAT \", Original: \" SIZE_FORMAT \", Latest: \" SIZE_FORMAT,\n-                           Thread::current()->name(), p2i(result), req.type_string(), req.size(), original_count, get_gc_no_progress_count());\n+      log_debug(gc, alloc)(\"Thread: %s, Result: \" PTR_FORMAT \", Request: %s, Size: \" SIZE_FORMAT \", Full count: \" SIZE_FORMAT \", Latest: \" SIZE_FORMAT,\n+                           Thread::current()->name(), p2i(result), req.type_string(), req.size(),\n+                           shenandoah_policy()->full_gc_count(), get_gc_no_progress_count());\n@@ -952,1 +1059,1 @@\n-                                        bool*  gc_overhead_limit_was_exceeded) {\n+                                       bool*  gc_overhead_limit_was_exceeded) {\n@@ -954,1 +1061,1 @@\n-  return allocate_memory(req);\n+  return allocate_memory(req, gc_overhead_limit_was_exceeded);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":136,"deletions":29,"binary":false,"changes":165,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"gc\/shared\/gc_globals.hpp\"\n@@ -37,0 +38,1 @@\n+#include \"gc\/shenandoah\/shenandoahMmuTracker.hpp\"\n@@ -250,0 +252,2 @@\n+  inline ShenandoahMmuTracker* mmu_tracker() { return &_mmu_tracker; };\n+\n@@ -296,1 +300,13 @@\n-  \/\/ This updates the singlular, global gc state. This must happen on a safepoint.\n+  double*   _gc_historical_utilization;\n+  double*   _gc_historical_duration;\n+  double    _gcu_historical;\n+  size_t    _gc_history_first;\n+  intptr_t  _gc_no_progress_count_at_last_oom;\n+\n+  void capture_gc_no_progress_count_at_last_oom();\n+  intptr_t get_gc_no_progress_count_at_last_oom() const;\n+\n+  void set_gc_state_all_threads(char state);\n+  void set_gc_state_mask(uint mask, bool value);\n+\n+  \/\/ This updates the singular, global gc state. This must happen on a safepoint.\n@@ -401,0 +417,2 @@\n+  ShenandoahMmuTracker       _mmu_tracker;\n+\n@@ -535,0 +553,4 @@\n+  inline bool gc_overhead_exceeds_limit() {\n+    double target_threshold = GCTimeLimit \/ 100.0;\n+    return (_gcu_historical > target_threshold);\n+  }\n@@ -537,1 +559,1 @@\n-  HeapWord* allocate_memory(ShenandoahAllocRequest& request);\n+  HeapWord* allocate_memory(ShenandoahAllocRequest& request, bool* gc_overhead_limit_was_exceeded = nullptr);\n@@ -556,0 +578,1 @@\n+  void report_gc_utilization(double utilization, double duration);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.hpp","additions":25,"deletions":2,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -78,1 +78,1 @@\n-\n+  Atomic::store(&_gc_no_progress_count_at_last_oom, (intptr_t) -1);\n@@ -80,0 +80,1 @@\n+\n@@ -88,0 +89,9 @@\n+inline void ShenandoahHeap::capture_gc_no_progress_count_at_last_oom() {\n+  intptr_t no_progress_count = get_gc_no_progress_count();\n+  Atomic::store(&_gc_no_progress_count_at_last_oom, no_progress_count);\n+}\n+\n+inline intptr_t ShenandoahHeap::get_gc_no_progress_count_at_last_oom() const {\n+  return Atomic::load(&_gc_no_progress_count_at_last_oom);\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.inline.hpp","additions":11,"deletions":1,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -0,0 +1,157 @@\n+\/*\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+#include \"precompiled.hpp\"\n+\n+#include \"gc\/shenandoah\/shenandoahAsserts.hpp\"\n+#include \"gc\/shenandoah\/shenandoahMmuTracker.hpp\"\n+#include \"gc\/shenandoah\/shenandoahHeap.inline.hpp\"\n+#include \"logging\/log.hpp\"\n+#include \"runtime\/os.hpp\"\n+#include \"runtime\/task.hpp\"\n+\n+class ShenandoahMmuTask : public PeriodicTask {\n+  ShenandoahMmuTracker* _mmu_tracker;\n+public:\n+  explicit ShenandoahMmuTask(ShenandoahMmuTracker* mmu_tracker) :\n+    PeriodicTask(GCPauseIntervalMillis), _mmu_tracker(mmu_tracker) {}\n+\n+  void task() override {\n+    _mmu_tracker->report();\n+  }\n+};\n+\n+class ThreadTimeAccumulator : public ThreadClosure {\n+ public:\n+  size_t total_time;\n+  ThreadTimeAccumulator() : total_time(0) {}\n+  void do_thread(Thread* thread) override {\n+    total_time += os::thread_cpu_time(thread);\n+  }\n+};\n+\n+ShenandoahMmuTracker::ShenandoahMmuTracker() :\n+    _most_recent_timestamp(0.0),\n+    _most_recent_gc_time(0.0),\n+    _most_recent_gcu(0.0),\n+    _most_recent_mutator_time(0.0),\n+    _most_recent_mu(0.0),\n+    _most_recent_periodic_time_stamp(0.0),\n+    _most_recent_periodic_gc_time(0.0),\n+    _most_recent_periodic_mutator_time(0.0),\n+    _mmu_periodic_task(new ShenandoahMmuTask(this)) {\n+}\n+\n+ShenandoahMmuTracker::~ShenandoahMmuTracker() {\n+  _mmu_periodic_task->disenroll();\n+  delete _mmu_periodic_task;\n+}\n+\n+void ShenandoahMmuTracker::fetch_cpu_times(double &gc_time, double &mutator_time) {\n+  ThreadTimeAccumulator cl;\n+  \/\/ We include only the gc threads because those are the only threads\n+  \/\/ we are responsible for.\n+  ShenandoahHeap::heap()->gc_threads_do(&cl);\n+  double most_recent_gc_thread_time = double(cl.total_time) \/ NANOSECS_PER_SEC;\n+  gc_time = most_recent_gc_thread_time;\n+\n+  double process_real_time(0.0), process_user_time(0.0), process_system_time(0.0);\n+  bool valid = os::getTimesSecs(&process_real_time, &process_user_time, &process_system_time);\n+  assert(valid, \"sanity\");\n+  mutator_time =(process_user_time + process_system_time) - most_recent_gc_thread_time;\n+}\n+\n+void ShenandoahMmuTracker::update_utilization(size_t gcid, const char* msg) {\n+  double current = os::elapsedTime();\n+  _most_recent_gcid = gcid;\n+  _most_recent_is_full = false;\n+\n+  if (gcid == 0) {\n+    fetch_cpu_times(_most_recent_gc_time, _most_recent_mutator_time);\n+\n+    _most_recent_timestamp = current;\n+  } else {\n+    double gc_cycle_period = current - _most_recent_timestamp;\n+    _most_recent_timestamp = current;\n+\n+    double gc_thread_time, mutator_thread_time;\n+    fetch_cpu_times(gc_thread_time, mutator_thread_time);\n+    double gc_time = gc_thread_time - _most_recent_gc_time;\n+    _most_recent_gc_time = gc_thread_time;\n+    _most_recent_gcu = gc_time \/ (_active_processors * gc_cycle_period);\n+    double mutator_time = mutator_thread_time - _most_recent_mutator_time;\n+    _most_recent_mutator_time = mutator_thread_time;\n+    _most_recent_mu = mutator_time \/ (_active_processors * gc_cycle_period);\n+    ShenandoahHeap::heap()->report_gc_utilization(_most_recent_gcu, gc_cycle_period);\n+    log_info(gc, ergo)(\"At end of %s: GCU: %.1f%%, MU: %.1f%% during period of %.3fs\",\n+                       msg, _most_recent_gcu * 100, _most_recent_mu * 100, gc_cycle_period);\n+  }\n+}\n+\n+void ShenandoahMmuTracker::record_global(size_t gcid) {\n+  update_utilization(gcid, \"Concurrent Global GC\");\n+}\n+\n+void ShenandoahMmuTracker::record_degenerated(size_t gcid) {\n+  if ((gcid == _most_recent_gcid) && _most_recent_is_full) {\n+    \/\/ Do nothing.  This is a redundant recording for the full gc that just completed.\n+    \/\/ TODO: avoid making the call to record_degenerated() in the case that this degenerated upgraded to full gc.\n+  } else {\n+    update_utilization(gcid, \"Degenerated Global GC\");\n+  }\n+}\n+\n+void ShenandoahMmuTracker::record_full(size_t gcid) {\n+  update_utilization(gcid, \"Full GC\");\n+  _most_recent_is_full = true;\n+}\n+\n+void ShenandoahMmuTracker::report() {\n+  \/\/ This is only called by the periodic thread.\n+  double current = os::elapsedTime();\n+  double time_delta = current - _most_recent_periodic_time_stamp;\n+  _most_recent_periodic_time_stamp = current;\n+\n+  double gc_time, mutator_time;\n+  fetch_cpu_times(gc_time, mutator_time);\n+\n+  double gc_delta = gc_time - _most_recent_periodic_gc_time;\n+  _most_recent_periodic_gc_time = gc_time;\n+\n+  double mutator_delta = mutator_time - _most_recent_periodic_mutator_time;\n+  _most_recent_periodic_mutator_time = mutator_time;\n+\n+  double mu = mutator_delta \/ (_active_processors * time_delta);\n+  double gcu = gc_delta \/ (_active_processors * time_delta);\n+  log_info(gc)(\"Periodic Sample: GCU = %.3f%%, MU = %.3f%% during most recent %.1fs\", gcu * 100, mu * 100, time_delta);\n+}\n+\n+void ShenandoahMmuTracker::initialize() {\n+  \/\/ initialize static data\n+  _active_processors = os::initial_active_processor_count();\n+\n+  _most_recent_periodic_time_stamp = os::elapsedTime();\n+  fetch_cpu_times(_most_recent_periodic_gc_time, _most_recent_periodic_mutator_time);\n+  _mmu_periodic_task->enroll();\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMmuTracker.cpp","additions":157,"deletions":0,"binary":false,"changes":157,"status":"added"},{"patch":"@@ -0,0 +1,94 @@\n+\/*\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_SHENANDOAH_SHENANDOAHMMUTRACKER_HPP\n+#define SHARE_GC_SHENANDOAH_SHENANDOAHMMUTRACKER_HPP\n+\n+#include \"runtime\/mutex.hpp\"\n+#include \"utilities\/numberSeq.hpp\"\n+\n+class ShenandoahMmuTask;\n+\n+\/**\n+ * This class is responsible for tracking the (minimum) mutator\n+ * utilization (MMU). MMU is defined as the percentage of CPU time available\n+ * to mutator threads over an arbitrary fixed interval of time. This interval\n+ * defaults to 5 seconds and is configured by GCPauseIntervalMillis.  MMU is\n+ * measured by summing all of the time given to the GC threads and comparing\n+ * this to the total CPU time for the process. There are OS APIs to support\n+ * this on all major platforms.\n+ *\/\n+class ShenandoahMmuTracker {\n+private:\n+  \/\/ These variables hold recent snapshots of cumulative quantities that are used for calculating\n+  \/\/ CPU time consumed by GC and mutator threads during each GC cycle.\n+  double _most_recent_timestamp;\n+  double _most_recent_gc_time;\n+  double _most_recent_gcu;\n+  double _most_recent_mutator_time;\n+  double _most_recent_mu;\n+\n+  \/\/ These variables hold recent snapshots of cumulative quantities that are used for reporting\n+  \/\/ periodic consumption of CPU time by GC and mutator threads.\n+  double _most_recent_periodic_time_stamp;\n+  double _most_recent_periodic_gc_time;\n+  double _most_recent_periodic_mutator_time;\n+\n+  size_t _most_recent_gcid;\n+  uint _active_processors;\n+\n+  bool _most_recent_is_full;\n+\n+  ShenandoahMmuTask* _mmu_periodic_task;\n+  TruncatedSeq _mmu_average;\n+\n+  void update_utilization(size_t gcid, const char* msg);\n+  static void fetch_cpu_times(double &gc_time, double &mutator_time);\n+\n+public:\n+  explicit ShenandoahMmuTracker();\n+  ~ShenandoahMmuTracker();\n+\n+  \/\/ This enrolls the periodic task after everything is initialized.\n+  void initialize();\n+\n+  \/\/ At completion of each GC cycle (not including interrupted cycles), we invoke one of the following to record the\n+  \/\/ GC utilization during this cycle.  Incremental efforts spent in an interrupted GC cycle will be accumulated into\n+  \/\/ the CPU time reports for the subsequent completed [degenerated or full] GC cycle.\n+  \/\/\n+  \/\/ We may redundantly record degen and full in the case that a degen upgrades to full.  When this happens, we will invoke\n+  \/\/ both record_full() and record_degenerated() with the same value of gcid.  record_full() is called first and the log\n+  \/\/ reports such a cycle as a FULL cycle.\n+  void record_global(size_t gcid);\n+  void record_full(size_t gcid);\n+  void record_degenerated(size_t gcid);\n+\n+  \/\/ This is called by the periodic task timer. The interval is defined by\n+  \/\/ GCPauseIntervalMillis and defaults to 5 seconds. This method computes\n+  \/\/ the MMU over the elapsed interval and records it in a running average.\n+  void report();\n+};\n+\n+\n+#endif \/\/SHARE_GC_SHENANDOAH_SHENANDOAHMMUTRACKER_HPP\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMmuTracker.hpp","additions":94,"deletions":0,"binary":false,"changes":94,"status":"added"},{"patch":"@@ -290,3 +290,8 @@\n-          \"After this number of consecutive Full GCs fail to make \"         \\\n-          \"progress, Shenandoah will raise out of memory errors. Note \"     \\\n-          \"that progress is determined by ShenandoahCriticalFreeThreshold\") \\\n+          \"After this number of consecutive Full GCs following an \"         \\\n+          \"initial out-of-memory condition fail to make progress, \"         \\\n+          \"Shenandoah will throw additional OutOfMemoryErrors without \"     \\\n+          \"further attempts to perform GC.  This delay represented by \"     \\\n+          \"this parameter provides an opportunity for application threads \" \\\n+          \"discard live memory in response to the initially thrown \"        \\\n+          \"OutOfMemoryError exception.  Note that progress is \"             \\\n+          \"determined by ShenandoahCriticalFreeThreshold\")                  \\\n@@ -334,0 +339,8 @@\n+  product(uint, ShenandoahGCTimeLimit, 90, EXPERIMENTAL,                    \\\n+          \"The percentage of CPU consumed by GC at which GC considers \"     \\\n+          \"itself to have exceeded the reasonable threshold.  This \"        \\\n+          \"replaces GCTimeLimit.  The denominator is calculated from \"      \\\n+          \"authorized ParallelGCThreads as a fraction of total available \"  \\\n+          \"CPU cores.\")                                                     \\\n+          range(0, 100)                                                     \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoah_globals.hpp","additions":16,"deletions":3,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -57,0 +57,2 @@\n+\n+        try {\n@@ -70,0 +72,4 @@\n+        } catch (Throwable t) {\n+          String msg = t.getMessage() + \", conc: \" + conc + \", par: \" + par;\n+          throw new RuntimeException(msg);\n+        }\n","filename":"test\/hotspot\/jtreg\/gc\/shenandoah\/options\/TestThreadCounts.java","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"}]}