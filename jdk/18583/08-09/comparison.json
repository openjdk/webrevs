{"files":[{"patch":"@@ -479,1 +479,0 @@\n-  void montgomeryMultiply(const Register aLimbs, const Register bLimbs, const Register rLimbs);\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -52,10 +52,0 @@\n-ATTRIBUTE_ALIGNED(64) uint64_t BROADCAST5[] = {\n-  0x0000000000000004ULL, 0x0000000000000004ULL,\n-  0x0000000000000004ULL, 0x0000000000000004ULL,\n-  0x0000000000000004ULL, 0x0000000000000004ULL,\n-  0x0000000000000004ULL, 0x0000000000000004ULL,\n-};\n-static address broadcast_5() {\n-  return (address)BROADCAST5;\n-}\n-\n@@ -86,1 +76,2 @@\n- * Reference: Shay Gueron and Vlad Krasnov \"Fast Prime Field Elliptic Curve Cryptography with 256 Bit Primes\"\n+ * Reference [1]: Shay Gueron and Vlad Krasnov\n+ *    \"Fast Prime Field Elliptic Curve Cryptography with 256 Bit Primes\"\n@@ -145,3 +136,3 @@\n-void StubGenerator::montgomeryMultiply(const Register aLimbs, const Register bLimbs, const Register rLimbs) {\n-  Register t0 = r13;\n-  Register rscratch = r13;\n+void montgomeryMultiply(const Register aLimbs, const Register bLimbs, const Register rLimbs, const Register tmp, MacroAssembler* _masm) {\n+  Register t0 = tmp;\n+  Register rscratch = tmp;\n@@ -157,3 +148,2 @@\n-  XMMRegister N = xmm12;\n-  XMMRegister select = xmm13;\n-  XMMRegister carry = xmm14;\n+  XMMRegister N    = xmm12;\n+  XMMRegister carry = xmm13;\n@@ -161,1 +151,1 @@\n-  \/\/ Constants\n+  \/\/ \/\/ Constants\n@@ -165,5 +155,3 @@\n-  XMMRegister mask52 = xmm23;\n-  XMMRegister broadcast5 = xmm24;\n-  KRegister limb0 = k1;\n-  KRegister limb5 = k2;\n-  KRegister allLimbs = k3;\n+  XMMRegister mask52  = xmm23;\n+  KRegister limb0    = k1;\n+  KRegister allLimbs = k2;\n@@ -173,2 +161,0 @@\n-  __ mov64(t0, 0x10);\n-  __ kmovql(limb5, t0);\n@@ -179,1 +165,0 @@\n-  __ evmovdquq(broadcast5, allLimbs, ExternalAddress(broadcast_5()), false, Assembler::AVX_512bit, rscratch);\n@@ -185,2 +170,2 @@\n-  \/\/ A = load(*aLimbs)\n-  __ evmovdquq(A, Address(aLimbs, 8), Assembler::AVX_256bit);                          \/\/ Acc1 = load(*a)\n+  \/\/ A = load(*aLimbs) \/\/ masked evmovdquq() can be slow. Instead load full 256bit, and compbine with 64bit\n+  __ evmovdquq(A, Address(aLimbs, 8), Assembler::AVX_256bit);\n@@ -260,11 +245,0 @@\n-  \/\/ Save all 'SOE' registers\n-  __ push(rbx);\n-  #ifdef _WIN64\n-  __ push(rsi);\n-  __ push(rdi);\n-  #endif\n-  __ push(r12);\n-  __ push(r13);\n-  __ push(r14);\n-  __ push(r15);\n-\n@@ -272,34 +246,7 @@\n-  const Register aLimbs  = rdi;\n-  const Register bLimbs  = rsi;\n-  const Register rLimbs  = rdx;\n-\n-  \/\/ Normalize input\n-  \/\/ pseudo-signature: void poly1305_processBlocks(byte[] input, int length, int[5] accumulator, int[5] R)\n-  \/\/ a, b, r pointers point at first array element\n-  \/\/ java headers bypassed in LibraryCallKit::inline_poly1305_processBlocks\n-  #ifdef _WIN64\n-  \/\/ c_rarg0 - rcx\n-  \/\/ c_rarg1 - rdx\n-  \/\/ c_rarg2 - r8\n-  __ mov(aLimbs, c_rarg0);\n-  __ mov(bLimbs, c_rarg1);\n-  __ mov(rLimbs, c_rarg2);\n-  #else\n-  \/\/ Already in place\n-  \/\/ c_rarg0 - rdi\n-  \/\/ c_rarg1 - rsi\n-  \/\/ c_rarg2 - rdx\n-  #endif\n-\n-  montgomeryMultiply(aLimbs, bLimbs, rLimbs);\n-\n-  __ pop(r15);\n-  __ pop(r14);\n-  __ pop(r13);\n-  __ pop(r12);\n-  #ifdef _WIN64\n-  __ pop(rdi);\n-  __ pop(rsi);\n-  #endif\n-  __ pop(rbx);\n-  __ mov64(rax, 0x1); \/\/ Return 1 (Step 6 skipped in montgomeryMultiply)\n+  const Register aLimbs  = c_rarg0; \/\/ rdi | rcx\n+  const Register bLimbs  = c_rarg1; \/\/ rsi | rdx\n+  const Register rLimbs  = c_rarg2; \/\/ rdx | r8\n+  const Register tmp     = r9;\n+\n+  montgomeryMultiply(aLimbs, bLimbs, rLimbs, tmp, _masm);\n+  __ mov64(rax, 0x1); \/\/ Return 1 (Fig. 5, Step 6 [1] skipped in montgomeryMultiply)\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64_poly_mont.cpp","additions":20,"deletions":73,"binary":false,"changes":93,"status":"modified"},{"patch":"@@ -1370,1 +1370,1 @@\n-  if (supports_avx512ifma() && supports_avx512vlbw() && MaxVectorSize >= 64) {\n+  if (supports_avx512ifma() && supports_avx512vlbw()) {\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -7556,2 +7556,0 @@\n-  address stubAddr;\n-  const char *stubName;\n@@ -7560,3 +7558,2 @@\n-  stubAddr = StubRoutines::intpoly_assign();\n-  stubName = \"intpoly_assign\";\n-\n+  const char *stubName = \"intpoly_assign\";\n+  address stubAddr = StubRoutines::intpoly_assign();\n@@ -7564,1 +7561,0 @@\n-  if (stopped())  return true;\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":2,"deletions":6,"binary":false,"changes":8,"status":"modified"}]}