{"files":[{"patch":"@@ -271,0 +271,10 @@\n+  \/\/ Generate 'unsafe' set memory stub\n+  \/\/ Though just as safe as the other stubs, it takes an unscaled\n+  \/\/ size_t argument instead of an element count.\n+  \/\/\n+  \/\/ Examines the alignment of the operands and dispatches\n+  \/\/ to an int, short, or byte copy loop.\n+  address generate_unsafe_setmemory(const char *name, address byte_fill_entry,\n+                                    address short_fill_entry,\n+                                    address int_fill_entry);\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -155,0 +155,5 @@\n+  StubRoutines::_unsafe_setmemory    = generate_unsafe_setmemory(\"unsafe_setmemory\",\n+                                                                 StubRoutines::_arrayof_jbyte_fill,\n+                                                                 StubRoutines::_arrayof_jshort_fill,\n+                                                                 StubRoutines::_arrayof_jint_fill);\n+\n@@ -2479,0 +2484,61 @@\n+\/\/  Generate 'unsafe' set memory stub\n+\/\/  Though just as safe as the other stubs, it takes an unscaled\n+\/\/  size_t argument instead of an element count.\n+\/\/\n+\/\/  Input:\n+\/\/    c_rarg0   - destination array address\n+\/\/    c_rarg1   - byte count (size_t)\n+\/\/    c_rarg2   - byte value\n+\/\/\n+\/\/ Examines the alignment of the operands and dispatches\n+\/\/ to an int, short, or byte fill loop.\n+\/\/\n+address StubGenerator::generate_unsafe_setmemory(const char *name,\n+                                                 address byte_fill_entry,\n+                                                 address short_fill_entry,\n+                                                 address int_fill_entry) {\n+  Label L_int_aligned, L_short_aligned, L_begin;\n+\n+  \/\/ Input registers\n+  const Register dest        = c_rarg0;  \/\/ destination array address\n+  const Register size        = c_rarg1;  \/\/ byte count (size_t)\n+  const Register value       = c_rarg2;  \/\/ byte value to fill\n+\n+  \/\/ Register used as a temp\n+  const Register bits        = rax;      \/\/ test copy of low bits\n+\n+  __ align(CodeEntryAlignment);\n+  StubCodeMark mark(this, \"StubRoutines\", name);\n+  address start = __ pc();\n+\n+  \/\/ bump this on entry, not on exit:\n+  INC_COUNTER_NP(SharedRuntime::_unsafe_set_memory_ctr, rscratch1);\n+\n+  \/\/ *_fill_entry requires broadcasted bytes\n+  __ movzbl(bits, value);\n+  __ mov64(value, 0x0101010101010101);\n+  __ imulq(value, bits);\n+\n+  __ mov(bits, dest);\n+  __ orptr(bits, size);\n+\n+  \/\/ Generated fill routines expect a different argument order\n+  __ xchgq(size, value);\n+\n+  __ testb(bits, BytesPerInt-1);\n+  __ jccb(Assembler::zero, L_int_aligned);\n+\n+  __ testb(bits, BytesPerShort-1);\n+  __ jump_cc(Assembler::notZero, RuntimeAddress(byte_fill_entry));\n+\n+  __ BIND(L_short_aligned);\n+  __ shrptr(value, LogBytesPerShort); \/\/ size => short_count\n+  __ jump(RuntimeAddress(short_fill_entry));\n+\n+  __ BIND(L_int_aligned);\n+  __ shrptr(value, LogBytesPerInt); \/\/ size => int_count\n+  __ jump(RuntimeAddress(int_fill_entry));\n+\n+  return start;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64_arraycopy.cpp","additions":66,"deletions":0,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -151,0 +151,3 @@\n+    \/\/ Shared code tests for \"null\" to discover the stub is not generated.\n+    StubRoutines::_unsafe_setmemory          = nullptr;\n+\n","filename":"src\/hotspot\/cpu\/zero\/stubGenerator_zero.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -509,0 +509,3 @@\n+  case vmIntrinsics::_setMemory:\n+    if (!InlineUnsafeOps) return true;\n+    break;\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -623,0 +623,3 @@\n+  do_intrinsic(_setMemory,                jdk_internal_misc_Unsafe,     setMemory_name,  setMemory_signature,          F_RN)     \\\n+   do_name(     setMemory_name,                                         \"setMemory0\")                                            \\\n+   do_signature(setMemory_signature,                                    \"(Ljava\/lang\/Object;JJB)V\")                              \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -345,0 +345,1 @@\n+  static_field(StubRoutines,                _unsafe_setmemory,                                address)                               \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -260,0 +260,3 @@\n+  case vmIntrinsics::_setMemory:\n+    if (StubRoutines::unsafe_setmemory() == nullptr) return false;\n+    break;\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -510,0 +510,1 @@\n+  case vmIntrinsics::_setMemory:                return inline_unsafe_setMemory();\n@@ -4944,0 +4945,51 @@\n+\n+  return true;\n+}\n+\n+bool LibraryCallKit::inline_unsafe_setMemory() {\n+  if (callee()->is_static())  return false;  \/\/ caller must have the capability!\n+  null_check_receiver();  \/\/ null-check receiver\n+  if (stopped())  return true;\n+\n+  C->set_has_unsafe_access(true);  \/\/ Mark eventual nmethod as \"unsafe\".\n+\n+  \/\/ printf(\"In inline_unsafe_setMemory\\n\");\n+\n+  Node* dst_base =         argument(1);  \/\/ type: oop\n+  Node* dst_off  = ConvL2X(argument(2)); \/\/ type: long\n+  Node* size     = ConvL2X(argument(4)); \/\/ type: long\n+  Node* byte     =         argument(6);  \/\/ type: byte\n+\n+  assert(Unsafe_field_offset_to_byte_offset(11) == 11,\n+         \"fieldOffset must be byte-scaled\");\n+\n+  Node* dst_addr = make_unsafe_address(dst_base, dst_off);\n+\n+  Node* thread = _gvn.transform(new ThreadLocalNode());\n+  Node* doing_unsafe_access_addr = basic_plus_adr(top(), thread, in_bytes(JavaThread::doing_unsafe_access_offset()));\n+  BasicType doing_unsafe_access_bt = T_BYTE;\n+  assert((sizeof(bool) * CHAR_BIT) == 8, \"not implemented\");\n+\n+  \/\/ update volatile field\n+  store_to_memory(control(), doing_unsafe_access_addr, intcon(1), doing_unsafe_access_bt, Compile::AliasIdxRaw, MemNode::unordered);\n+\n+  int flags = RC_LEAF | RC_NO_FP;\n+\n+  const TypePtr* dst_type = TypePtr::BOTTOM;\n+\n+  \/\/ Adjust memory effects of the runtime call based on input values.\n+  if (!has_wide_mem(_gvn, dst_addr, dst_base)) {\n+    dst_type = _gvn.type(dst_addr)->is_ptr(); \/\/ narrow out memory\n+\n+    flags |= RC_NARROW_MEM; \/\/ narrow in memory\n+  }\n+\n+  \/\/ Call it.  Note that the length argument is not scaled.\n+  make_runtime_call(flags,\n+                    OptoRuntime::make_setmemory_Type(),\n+                    StubRoutines::unsafe_setmemory(),\n+                    \"unsafe_setmemory\",\n+                    dst_type,\n+                    dst_addr, size XTOP, byte);\n+\n+  store_to_memory(control(), doing_unsafe_access_addr, intcon(0), doing_unsafe_access_bt, Compile::AliasIdxRaw, MemNode::unordered);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":52,"deletions":0,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -235,0 +235,2 @@\n+  bool inline_unsafe_setMemory();\n+\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -775,0 +775,20 @@\n+const TypeFunc* OptoRuntime::make_setmemory_Type() {\n+  \/\/ create input type (domain)\n+  int num_args      = 4;\n+  int argcnt = num_args;\n+  const Type** fields = TypeTuple::fields(argcnt);\n+  int argp = TypeFunc::Parms;\n+  fields[argp++] = TypePtr::NOTNULL;    \/\/ dest\n+  fields[argp++] = TypeLong::LONG;      \/\/ size\n+  fields[argp++] = Type::HALF;          \/\/ size\n+  fields[argp++] = TypeInt::INT;        \/\/ bytevalue\n+  assert(argp == TypeFunc::Parms+argcnt, \"correct decoding\");\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms+argcnt, fields);\n+\n+  \/\/ no result type needed\n+  fields = TypeTuple::fields(1);\n+  fields[TypeFunc::Parms+0] = nullptr; \/\/ void\n+  const TypeTuple* range = TypeTuple::make(TypeFunc::Parms, fields);\n+  return TypeFunc::make(domain, range);\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -269,0 +269,2 @@\n+  static const TypeFunc* make_setmemory_Type();\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -391,0 +391,1 @@\n+\n@@ -396,1 +397,6 @@\n-    Copy::fill_to_memory_atomic(p, sz, value);\n+    if (StubRoutines::unsafe_setmemory() != nullptr) {\n+      MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXExec, thread));\n+      StubRoutines::UnsafeSetMemory_stub()(p, sz, value);\n+    } else {\n+      Copy::fill_to_memory_atomic(p, sz, value);\n+    }\n","filename":"src\/hotspot\/share\/prims\/unsafe.cpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -180,0 +180,2 @@\n+uint SharedRuntime::_unsafe_set_memory_ctr=0;\n+\n@@ -1992,0 +1994,2 @@\n+  if (_unsafe_set_memory_ctr) tty->print_cr(\"%5u unsafe set memorys\", _unsafe_set_memory_ctr);\n+\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -545,0 +545,2 @@\n+  static uint _unsafe_set_memory_ctr;      \/\/ Slow-path includes alignment checks\n+\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -112,0 +112,2 @@\n+address StubRoutines::_unsafe_setmemory                  = nullptr;\n+\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -196,0 +196,2 @@\n+  static address _unsafe_setmemory;\n+\n@@ -384,0 +386,5 @@\n+  static address unsafe_setmemory()     { return _unsafe_setmemory; }\n+\n+  typedef void (*UnsafeSetMemoryStub)(const void* src, size_t count, char byte);\n+  static UnsafeSetMemoryStub UnsafeSetMemory_stub()         { return CAST_TO_FN_PTR(UnsafeSetMemoryStub,  _unsafe_setmemory); }\n+\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -211,48 +211,0 @@\n-\n-\/\/ Fill bytes; larger units are filled atomically if everything is aligned.\n-void Copy::fill_to_memory_atomic(void* to, size_t size, jubyte value) {\n-  address dst = (address) to;\n-  uintptr_t bits = (uintptr_t) to | (uintptr_t) size;\n-  if (bits % sizeof(jlong) == 0) {\n-    jlong fill = (julong)( (jubyte)value ); \/\/ zero-extend\n-    if (fill != 0) {\n-      fill += fill << 8;\n-      fill += fill << 16;\n-      fill += fill << 32;\n-    }\n-    \/\/Copy::fill_to_jlongs_atomic((jlong*) dst, size \/ sizeof(jlong));\n-    for (uintptr_t off = 0; off < size; off += sizeof(jlong)) {\n-      *(jlong*)(dst + off) = fill;\n-    }\n-  } else if (bits % sizeof(jint) == 0) {\n-    jint fill = (juint)( (jubyte)value ); \/\/ zero-extend\n-    if (fill != 0) {\n-      fill += fill << 8;\n-      fill += fill << 16;\n-    }\n-    \/\/Copy::fill_to_jints_atomic((jint*) dst, size \/ sizeof(jint));\n-    for (uintptr_t off = 0; off < size; off += sizeof(jint)) {\n-      *(jint*)(dst + off) = fill;\n-    }\n-  } else if (bits % sizeof(jshort) == 0) {\n-    jshort fill = (jushort)( (jubyte)value ); \/\/ zero-extend\n-    fill += (jshort)(fill << 8);\n-    \/\/Copy::fill_to_jshorts_atomic((jshort*) dst, size \/ sizeof(jshort));\n-    for (uintptr_t off = 0; off < size; off += sizeof(jshort)) {\n-      *(jshort*)(dst + off) = fill;\n-    }\n-  } else {\n-    \/\/ Not aligned, so no need to be atomic.\n-#ifdef MUSL_LIBC\n-    \/\/ This code is used by Unsafe and may hit the next page after truncation of mapped memory.\n-    \/\/ Therefore, we use volatile to prevent compilers from replacing the loop by memset which\n-    \/\/ may not trigger SIGBUS as needed (observed on Alpine Linux x86_64)\n-    jbyte fill = value;\n-    for (uintptr_t off = 0; off < size; off += sizeof(jbyte)) {\n-      *(volatile jbyte*)(dst + off) = fill;\n-    }\n-#else\n-    Copy::fill_to_bytes(dst, size, value);\n-#endif\n-  }\n-}\n","filename":"src\/hotspot\/share\/utilities\/copy.cpp","additions":0,"deletions":48,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -285,1 +285,50 @@\n-  static void fill_to_memory_atomic(void* to, size_t size, jubyte value = 0);\n+\n+  \/\/ Fill bytes; larger units are filled atomically if everything is aligned.\n+  inline static void fill_to_memory_atomic(void* to, size_t size,\n+                                           jubyte value) {\n+    address dst = (address)to;\n+    uintptr_t bits = (uintptr_t)to | (uintptr_t)size;\n+    if (bits % sizeof(jlong) == 0) {\n+      jlong fill = (julong)((jubyte)value);  \/\/ zero-extend\n+      if (fill != 0) {\n+        fill += fill << 8;\n+        fill += fill << 16;\n+        fill += fill << 32;\n+      }\n+      \/\/ Copy::fill_to_jlongs_atomic((jlong*) dst, size \/ sizeof(jlong));\n+      for (uintptr_t off = 0; off < size; off += sizeof(jlong)) {\n+        *(jlong*)(dst + off) = fill;\n+      }\n+    } else if (bits % sizeof(jint) == 0) {\n+      jint fill = (juint)((jubyte)value);  \/\/ zero-extend\n+      if (fill != 0) {\n+        fill += fill << 8;\n+        fill += fill << 16;\n+      }\n+      \/\/ Copy::fill_to_jints_atomic((jint*) dst, size \/ sizeof(jint));\n+      for (uintptr_t off = 0; off < size; off += sizeof(jint)) {\n+        *(jint*)(dst + off) = fill;\n+      }\n+    } else if (bits % sizeof(jshort) == 0) {\n+      jshort fill = (jushort)((jubyte)value);  \/\/ zero-extend\n+      fill += (jshort)(fill << 8);\n+      \/\/ Copy::fill_to_jshorts_atomic((jshort*) dst, size \/ sizeof(jshort));\n+      for (uintptr_t off = 0; off < size; off += sizeof(jshort)) {\n+        *(jshort*)(dst + off) = fill;\n+      }\n+    } else {\n+      \/\/ Not aligned, so no need to be atomic.\n+#ifdef MUSL_LIBC\n+      \/\/ This code is used by Unsafe and may hit the next page after truncation\n+      \/\/ of mapped memory. Therefore, we use volatile to prevent compilers from\n+      \/\/ replacing the loop by memset which may not trigger SIGBUS as needed\n+      \/\/ (observed on Alpine Linux x86_64)\n+      jbyte fill = value;\n+      for (uintptr_t off = 0; off < size; off += sizeof(jbyte)) {\n+        *(volatile jbyte*)(dst + off) = fill;\n+      }\n+#else\n+      Copy::fill_to_bytes(dst, size, value);\n+#endif\n+    }\n+  }\n@@ -303,1 +352,0 @@\n-\n","filename":"src\/hotspot\/share\/utilities\/copy.hpp","additions":50,"deletions":2,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -3827,0 +3827,1 @@\n+    @IntrinsicCandidate\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/misc\/Unsafe.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -210,0 +210,5 @@\n+        \/\/ long seed = 6742745864802755133L;\n+        long seed = random.nextLong();\n+        random.setSeed(seed);\n+        System.out.println(\"Seed set to \"+ seed);\n+\n","filename":"test\/jdk\/sun\/misc\/CopyMemory.java","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -0,0 +1,70 @@\n+package org.openjdk.bench.java.lang.foreign;\n+\n+import sun.misc.Unsafe;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Setup;\n+import java.lang.foreign.Arena;\n+import java.lang.foreign.MemorySegment;\n+\n+import java.util.concurrent.TimeUnit;\n+\n+@BenchmarkMode(Mode.AverageTime)\n+@Warmup(iterations = 5, time = 500, timeUnit = TimeUnit.MILLISECONDS)\n+@Measurement(iterations = 10, time = 500, timeUnit = TimeUnit.MILLISECONDS)\n+@State(org.openjdk.jmh.annotations.Scope.Thread)\n+@OutputTimeUnit(TimeUnit.NANOSECONDS)\n+@Fork(value = 3, jvmArgsAppend = {\"--enable-native-access=ALL-UNNAMED\"})\n+public class MemorySegmentZeroUnsafe {\n+\n+    static final Unsafe UNSAFE = Utils.unsafe;\n+    long src;\n+\n+    @Param({\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"15\", \"16\", \"63\", \"64\", \"255\", \"256\"})\n+    public int size;\n+\n+    @Param({\"true\", \"false\"})\n+    public boolean aligned;\n+\n+    private MemorySegment segment;\n+    private long address;\n+\n+    @Setup\n+    public void setup() throws Throwable {\n+        Arena arena = Arena.global();\n+        long alignment = 1;\n+        \/\/ this complex logic is to ensure that if in the future we decide to batch writes with different\n+        \/\/ batches based on alignment, we would spot it here\n+        if (size == 2 || size == 3) {\n+            alignment = 2;\n+        } else if (size >= 4 && size <= 7) {\n+            alignment = 4;\n+        } else {\n+            alignment = 8;\n+        }\n+        if (aligned) {\n+            segment = arena.allocate(size, alignment);\n+        } else {\n+            \/\/ forcibly misaligned in both address AND size, given that would be the worst case\n+            segment = arena.allocate(size + 1, alignment).asSlice(1);\n+        }\n+        address = segment.address();\n+    }\n+\n+    @Benchmark\n+    public void panama() {\n+        segment.fill((byte) 0);\n+    }\n+\n+    @Benchmark\n+    public void unsafe() {\n+        UNSAFE.setMemory(address, size, (byte) 0);\n+    }\n+}\n","filename":"test\/micro\/org\/openjdk\/bench\/java\/lang\/foreign\/MemorySegmentZeroUnsafe.java","additions":70,"deletions":0,"binary":false,"changes":70,"status":"added"}]}