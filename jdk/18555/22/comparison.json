{"files":[{"patch":"@@ -8336,1 +8336,1 @@\n-      UnsafeCopyMemory::create_table(8);\n+      UnsafeCopyMemory::create_table(8 + 4); \/\/ 8 for copyMemory; 4 for setMemory\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2008, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2008, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -3138,1 +3138,1 @@\n-      UnsafeCopyMemory::create_table(32);\n+      UnsafeCopyMemory::create_table(32 + 4); \/\/ 32 for copyMemory; 4 for setMemory\n","filename":"src\/hotspot\/cpu\/arm\/stubGenerator_arm.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -4749,1 +4749,1 @@\n-      UnsafeCopyMemory::create_table(8);\n+      UnsafeCopyMemory::create_table(8 + 4); \/\/ 8 for copyMemory; 4 for setMemory\n","filename":"src\/hotspot\/cpu\/ppc\/stubGenerator_ppc.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -5483,1 +5483,1 @@\n-      UnsafeCopyMemory::create_table(8);\n+      UnsafeCopyMemory::create_table(8 + 4); \/\/ 8 for copyMemory; 4 for setMemory\n","filename":"src\/hotspot\/cpu\/riscv\/stubGenerator_riscv.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -937,0 +937,1 @@\n+    case 0xD6: \/\/ movq\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -5968,1 +5968,1 @@\n-  cmpl(count, 2<<shift); \/\/ Short arrays (< 8 bytes) fill by element\n+  cmpptr(count, 2<<shift); \/\/ Short arrays (< 8 bytes) fill by element\n@@ -5988,1 +5988,1 @@\n-    subl(count, 1<<(shift-1));\n+    subptr(count, 1<<(shift-1));\n@@ -5994,1 +5994,1 @@\n-    subl(count, 8 << shift);\n+    subptr(count, 8 << shift);\n@@ -6005,1 +6005,1 @@\n-    subl(count, 8 << shift);\n+    subptr(count, 8 << shift);\n@@ -6008,1 +6008,1 @@\n-    addl(count, 8 << shift);\n+    addptr(count, 8 << shift);\n@@ -6020,1 +6020,1 @@\n-    subl(count, 1 << (shift + 1));\n+    subptr(count, 1 << (shift + 1));\n@@ -6031,1 +6031,1 @@\n-      subl(count, 1<<shift);\n+      subptr(count, 1<<shift);\n@@ -6045,1 +6045,1 @@\n-          cmpl(count, VM_Version::avx3_threshold());\n+          cmpptr(count, VM_Version::avx3_threshold());\n@@ -6050,1 +6050,1 @@\n-          subl(count, 16 << shift);\n+          subptr(count, 16 << shift);\n@@ -6057,1 +6057,1 @@\n-          subl(count, 16 << shift);\n+          subptr(count, 16 << shift);\n@@ -6067,1 +6067,1 @@\n-        subl(count, 16 << shift);\n+        subptr(count, 16 << shift);\n@@ -6075,1 +6075,1 @@\n-        subl(count, 16 << shift);\n+        subptr(count, 16 << shift);\n@@ -6079,1 +6079,1 @@\n-        addl(count, 8 << shift);\n+        addptr(count, 8 << shift);\n@@ -6083,1 +6083,1 @@\n-        subl(count, 8 << shift);\n+        subptr(count, 8 << shift);\n@@ -6093,1 +6093,1 @@\n-        subl(count, 8 << shift);\n+        subptr(count, 8 << shift);\n@@ -6110,1 +6110,1 @@\n-        subl(count, 8 << shift);\n+        subptr(count, 8 << shift);\n@@ -6115,1 +6115,1 @@\n-      addl(count, 8 << shift);\n+      addptr(count, 8 << shift);\n@@ -6126,1 +6126,1 @@\n-      subl(count, 1 << (shift + 1));\n+      subptr(count, 1 << (shift + 1));\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":18,"deletions":18,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -4125,1 +4125,1 @@\n-      UnsafeCopyMemory::create_table(16);\n+      UnsafeCopyMemory::create_table(16 + 4); \/\/ 16 for copyMemory; 4 for setMemory\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_32.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -4013,1 +4013,1 @@\n-    UnsafeCopyMemory::create_table(16);\n+    UnsafeCopyMemory::create_table(16 + 4); \/\/ 16 for copyMemory; 4 for setMemory\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -271,0 +271,8 @@\n+  \/\/ Generate 'unsafe' set memory stub\n+  \/\/ Though just as safe as the other stubs, it takes an unscaled\n+  \/\/ size_t argument instead of an element count.\n+  \/\/\n+  \/\/ Examines the alignment of the operands and dispatches\n+  \/\/ to an int, short, or byte copy loop.\n+  address generate_unsafe_setmemory(const char *name, address byte_copy_entry);\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -155,0 +155,2 @@\n+  StubRoutines::_unsafe_setmemory = generate_unsafe_setmemory(\"unsafe_setmemory\", StubRoutines::_jbyte_fill);\n+\n@@ -1623,1 +1625,5 @@\n-  __ generate_fill(t, aligned, to, value, r11, rax, xmm0);\n+  {\n+    \/\/ Add set memory mark to protect against unsafe accesses faulting\n+    UnsafeCopyMemoryMark(this, ((t == T_BYTE) && !aligned), true);\n+    __ generate_fill(t, aligned, to, value, r11, rax, xmm0);\n+  }\n@@ -2480,0 +2486,196 @@\n+\/\/ Static enum for helper\n+enum USM_TYPE {USM_SHORT, USM_DWORD, USM_QUADWORD};\n+\/\/ Helper for generate_unsafe_setmemory\n+\/\/\n+\/\/ Atomically fill an array of memory using 2-, 4-, or 8-byte chunks\n+static void do_setmemory_atomic_loop(USM_TYPE type, Register dest,\n+                                     Register size, Register wide_value,\n+                                     Register tmp, Label& L_exit,\n+                                     MacroAssembler *_masm) {\n+  Label L_Loop, L_Tail, L_TailLoop;\n+\n+  int shiftval = 0;\n+  int incr = 0;\n+\n+  switch (type) {\n+    case USM_SHORT:\n+      shiftval = 1;\n+      incr = 16;\n+      break;\n+    case USM_DWORD:\n+      shiftval = 2;\n+      incr = 32;\n+      break;\n+    case USM_QUADWORD:\n+      shiftval = 3;\n+      incr = 64;\n+      break;\n+  }\n+\n+  \/\/ At this point, we know the lower bits of size are zero\n+  __ shrq(size, shiftval);\n+  \/\/ size now has number of X-byte chunks (2, 4 or 8)\n+\n+  \/\/ Number of (8*X)-byte chunks into tmp\n+  __ movq(tmp, size);\n+  __ shrq(tmp, 3);\n+  __ jccb(Assembler::zero, L_Tail);\n+\n+  __ BIND(L_Loop);\n+\n+  \/\/ Unroll 8 stores\n+  for (int i = 0; i < 8; i++) {\n+    switch (type) {\n+      case USM_SHORT:\n+        __ movw(Address(dest, (2 * i)), wide_value);\n+        break;\n+      case USM_DWORD:\n+        __ movl(Address(dest, (4 * i)), wide_value);\n+        break;\n+      case USM_QUADWORD:\n+        __ movq(Address(dest, (8 * i)), wide_value);\n+        break;\n+    }\n+  }\n+  __ addq(dest, incr);\n+  __ decrementq(tmp);\n+  __ jccb(Assembler::notZero, L_Loop);\n+\n+  __ BIND(L_Tail);\n+\n+  \/\/ Find number of remaining X-byte chunks\n+  __ andq(size, 0x7);\n+\n+  \/\/ If zero, then we're done\n+  __ jccb(Assembler::zero, L_exit);\n+\n+  __ BIND(L_TailLoop);\n+\n+    switch (type) {\n+      case USM_SHORT:\n+        __ movw(Address(dest, 0), wide_value);\n+        break;\n+      case USM_DWORD:\n+        __ movl(Address(dest, 0), wide_value);\n+        break;\n+      case USM_QUADWORD:\n+        __ movq(Address(dest, 0), wide_value);\n+        break;\n+    }\n+  __ addq(dest, incr >> 3);\n+  __ decrementq(size);\n+  __ jccb(Assembler::notZero, L_TailLoop);\n+}\n+\n+\/\/  Generate 'unsafe' set memory stub\n+\/\/  Though just as safe as the other stubs, it takes an unscaled\n+\/\/  size_t (# bytes) argument instead of an element count.\n+\/\/\n+\/\/  Input:\n+\/\/    c_rarg0   - destination array address\n+\/\/    c_rarg1   - byte count (size_t)\n+\/\/    c_rarg2   - byte value\n+\/\/\n+\/\/ Examines the alignment of the operands and dispatches\n+\/\/ to an int, short, or byte fill loop.\n+\/\/\n+address StubGenerator::generate_unsafe_setmemory(const char *name,\n+                                                 address unsafe_byte_fill) {\n+  __ align(CodeEntryAlignment);\n+  StubCodeMark mark(this, \"StubRoutines\", name);\n+  address start = __ pc();\n+  __ enter();   \/\/ required for proper stackwalking of RuntimeStub frame\n+\n+  assert(unsafe_byte_fill != nullptr, \"Invalid call\");\n+\n+  \/\/ bump this on entry, not on exit:\n+  INC_COUNTER_NP(SharedRuntime::_unsafe_set_memory_ctr, rscratch1);\n+\n+  {\n+    Label L_exit, L_fillQuadwords, L_fillDwords, L_fillBytes;\n+\n+    const Register dest = c_rarg0;\n+    const Register size = c_rarg1;\n+    const Register byteVal = c_rarg2;\n+    const Register wide_value = rax;\n+    const Register rScratch1 = r10;\n+\n+    assert_different_registers(dest, size, byteVal, wide_value, rScratch1);\n+\n+    \/\/     fill_to_memory_atomic(unsigned char*, unsigned long, unsigned char)\n+\n+    __ testq(size, size);\n+    __ jcc(Assembler::zero, L_exit);\n+\n+    \/\/ Propagate byte to full Register\n+    __ movzbl(rScratch1, byteVal);\n+    __ mov64(wide_value, 0x0101010101010101ULL);\n+    __ imulq(wide_value, rScratch1);\n+\n+    \/\/ Check for pointer & size alignment\n+    __ movq(rScratch1, dest);\n+    __ orq(rScratch1, size);\n+\n+    __ testb(rScratch1, 7);\n+    __ jcc(Assembler::equal, L_fillQuadwords);\n+\n+    __ testb(rScratch1, 3);\n+    __ jcc(Assembler::equal, L_fillDwords);\n+\n+    __ testb(rScratch1, 1);\n+    __ jcc(Assembler::notEqual, L_fillBytes);\n+\n+    \/\/ Fill words\n+    {\n+      Label L_wordsTail, L_wordsLoop, L_wordsTailLoop;\n+      UnsafeCopyMemoryMark usmm(this, true, true);\n+\n+      \/\/ At this point, we know the lower bit of size is zero and a\n+      \/\/ multiple of 2\n+      do_setmemory_atomic_loop(USM_SHORT, dest, size, wide_value, rScratch1,\n+                               L_exit, _masm);\n+    }\n+    __ jmp(L_exit);\n+\n+    __ BIND(L_fillQuadwords);\n+\n+    \/\/ Fill QUADWORDs\n+    {\n+      Label L_qwordLoop, L_qwordsTail, L_qwordsTailLoop;\n+      UnsafeCopyMemoryMark usmm(this, true, true);\n+\n+      \/\/ At this point, we know the lower 3 bits of size are zero and a\n+      \/\/ multiple of 8\n+      do_setmemory_atomic_loop(USM_QUADWORD, dest, size, wide_value, rScratch1,\n+                               L_exit, _masm);\n+    }\n+    __ BIND(L_exit);\n+\n+    __ leave();   \/\/ required for proper stackwalking of RuntimeStub frame\n+    __ ret(0);\n+\n+    __ BIND(L_fillDwords);\n+\n+    \/\/ Fill DWORDs\n+    {\n+      Label L_dwordLoop, L_dwordsTail, L_dwordsTailLoop;\n+      UnsafeCopyMemoryMark usmm(this, true, true);\n+\n+      \/\/ At this point, we know the lower 2 bits of size are zero and a\n+      \/\/ multiple of 4\n+      do_setmemory_atomic_loop(USM_DWORD, dest, size, wide_value, rScratch1,\n+                               L_exit, _masm);\n+    }\n+    __ jmp(L_exit);\n+\n+    __ BIND(L_fillBytes);\n+    \/\/ Set up for tail call to previously generated byte fill routine\n+    \/\/ Parameter order is (ptr, byteVal, size)\n+    __ xchgq(c_rarg1, c_rarg2);\n+    __ leave();    \/\/ Clear effect of enter()\n+    __ jump(RuntimeAddress(unsafe_byte_fill));\n+  }\n+\n+  return start;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64_arraycopy.cpp","additions":204,"deletions":2,"binary":false,"changes":206,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -151,0 +151,3 @@\n+    \/\/ Shared code tests for \"null\" to discover the stub is not generated.\n+    StubRoutines::_unsafe_setmemory          = nullptr;\n+\n","filename":"src\/hotspot\/cpu\/zero\/stubGenerator_zero.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2798,2 +2798,2 @@\n-      bool is_unsafe_arraycopy = (in_native || in_java) && UnsafeCopyMemory::contains_pc(pc);\n-      if (((in_vm || in_native || is_unsafe_arraycopy) && thread->doing_unsafe_access()) ||\n+      bool is_unsafe_memory_access = (in_native || in_java) && UnsafeCopyMemory::contains_pc(pc);\n+      if (((in_vm || in_native || is_unsafe_memory_access) && thread->doing_unsafe_access()) ||\n@@ -2802,1 +2802,1 @@\n-        if (is_unsafe_arraycopy) {\n+        if (is_unsafe_memory_access) {\n","filename":"src\/hotspot\/os\/windows\/os_windows.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -343,2 +343,2 @@\n-        bool is_unsafe_arraycopy = (thread->doing_unsafe_access() && UnsafeCopyMemory::contains_pc(pc));\n-        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_arraycopy) {\n+        bool is_unsafe_memory_access = (thread->doing_unsafe_access() && UnsafeCopyMemory::contains_pc(pc));\n+        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_memory_access) {\n@@ -346,1 +346,1 @@\n-          if (is_unsafe_arraycopy) {\n+          if (is_unsafe_memory_access) {\n","filename":"src\/hotspot\/os_cpu\/aix_ppc\/os_aix_ppc.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -260,2 +260,2 @@\n-        bool is_unsafe_arraycopy = (thread->doing_unsafe_access() && UnsafeCopyMemory::contains_pc(pc));\n-        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_arraycopy) {\n+        bool is_unsafe_memory_access = (thread->doing_unsafe_access() && UnsafeCopyMemory::contains_pc(pc));\n+        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_memory_access) {\n@@ -263,1 +263,1 @@\n-          if (is_unsafe_arraycopy) {\n+          if (is_unsafe_memory_access) {\n","filename":"src\/hotspot\/os_cpu\/bsd_aarch64\/os_bsd_aarch64.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -444,2 +444,2 @@\n-        bool is_unsafe_arraycopy = thread->doing_unsafe_access() && UnsafeCopyMemory::contains_pc(pc);\n-        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_arraycopy) {\n+        bool is_unsafe_memory_access = thread->doing_unsafe_access() && UnsafeCopyMemory::contains_pc(pc);\n+        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_memory_access) {\n@@ -447,1 +447,1 @@\n-          if (is_unsafe_arraycopy) {\n+          if (is_unsafe_memory_access) {\n@@ -452,3 +452,1 @@\n-      }\n-      else\n-\n+      } else\n@@ -456,1 +454,1 @@\n-      if (sig == SIGFPE  &&\n+      if (sig == SIGFPE &&\n","filename":"src\/hotspot\/os_cpu\/bsd_x86\/os_bsd_x86.cpp","additions":5,"deletions":7,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -243,2 +243,2 @@\n-        bool is_unsafe_arraycopy = (thread->doing_unsafe_access() && UnsafeCopyMemory::contains_pc(pc));\n-        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_arraycopy) {\n+        bool is_unsafe_memory_access = (thread->doing_unsafe_access() && UnsafeCopyMemory::contains_pc(pc));\n+        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_memory_access) {\n@@ -246,1 +246,1 @@\n-          if (is_unsafe_arraycopy) {\n+          if (is_unsafe_memory_access) {\n","filename":"src\/hotspot\/os_cpu\/linux_aarch64\/os_linux_aarch64.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -327,1 +327,3 @@\n-        if ((nm != nullptr && nm->has_unsafe_access()) || (thread->doing_unsafe_access() && UnsafeCopyMemory::contains_pc(pc))) {\n+        if ((nm != nullptr && nm->has_unsafe_access()) ||\n+            (thread->doing_unsafe_access() &&\n+             UnsafeCopyMemory::contains_pc(pc))) {\n@@ -332,6 +334,9 @@\n-          \/\/ Determination of interpreter\/vtable stub\/compiled code null exception\n-          CodeBlob* cb = CodeCache::find_blob(pc);\n-          if (cb != nullptr) {\n-            stub = SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::IMPLICIT_NULL);\n-          }\n-      } else if (sig == SIGILL && *(int *)pc == NativeInstruction::not_entrant_illegal_instruction) {\n+        \/\/ Determination of interpreter\/vtable stub\/compiled code null exception\n+        CodeBlob* cb = CodeCache::find_blob(pc);\n+        if (cb != nullptr) {\n+          stub = SharedRuntime::continuation_for_implicit_exception(\n+              thread, pc, SharedRuntime::IMPLICIT_NULL);\n+        }\n+      } else if (sig == SIGILL &&\n+                 *(int*)pc ==\n+                     NativeInstruction::not_entrant_illegal_instruction) {\n","filename":"src\/hotspot\/os_cpu\/linux_arm\/os_linux_arm.cpp","additions":12,"deletions":7,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -358,2 +358,2 @@\n-        bool is_unsafe_arraycopy = (thread->doing_unsafe_access() && UnsafeCopyMemory::contains_pc(pc));\n-        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_arraycopy) {\n+        bool is_unsafe_memory_access = (thread->doing_unsafe_access() && UnsafeCopyMemory::contains_pc(pc));\n+        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_memory_access) {\n@@ -361,1 +361,1 @@\n-          if (is_unsafe_arraycopy) {\n+          if (is_unsafe_memory_access) {\n","filename":"src\/hotspot\/os_cpu\/linux_ppc\/os_linux_ppc.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -233,2 +233,2 @@\n-        bool is_unsafe_arraycopy = (thread->doing_unsafe_access() && UnsafeCopyMemory::contains_pc(pc));\n-        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_arraycopy) {\n+        bool is_unsafe_memory_access = (thread->doing_unsafe_access() && UnsafeCopyMemory::contains_pc(pc));\n+        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_memory_access) {\n@@ -236,1 +236,1 @@\n-          if (is_unsafe_arraycopy) {\n+          if (is_unsafe_memory_access) {\n","filename":"src\/hotspot\/os_cpu\/linux_riscv\/os_linux_riscv.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -263,2 +263,2 @@\n-        bool is_unsafe_arraycopy = thread->doing_unsafe_access() && UnsafeCopyMemory::contains_pc(pc);\n-        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_arraycopy) {\n+        bool is_unsafe_memory_access = thread->doing_unsafe_access() && UnsafeCopyMemory::contains_pc(pc);\n+        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_memory_access) {\n@@ -266,1 +266,1 @@\n-          if (is_unsafe_arraycopy) {\n+          if (is_unsafe_memory_access) {\n@@ -271,3 +271,1 @@\n-      }\n-      else\n-\n+      } else\n@@ -275,1 +273,1 @@\n-      if (sig == SIGFPE  &&\n+      if (sig == SIGFPE &&\n","filename":"src\/hotspot\/os_cpu\/linux_x86\/os_linux_x86.cpp","additions":5,"deletions":7,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -509,0 +509,3 @@\n+  case vmIntrinsics::_setMemory:\n+    if (!InlineUnsafeOps) return true;\n+    break;\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -623,0 +623,3 @@\n+  do_intrinsic(_setMemory,                jdk_internal_misc_Unsafe,     setMemory_name,  setMemory_signature,          F_RN)     \\\n+   do_name(     setMemory_name,                                         \"setMemory0\")                                            \\\n+   do_signature(setMemory_signature,                                    \"(Ljava\/lang\/Object;JJB)V\")                              \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -345,0 +345,1 @@\n+  static_field(StubRoutines,                _unsafe_setmemory,                                address)                               \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -260,0 +260,3 @@\n+  case vmIntrinsics::_setMemory:\n+    if (StubRoutines::unsafe_setmemory() == nullptr) return false;\n+    break;\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -510,0 +510,1 @@\n+  case vmIntrinsics::_setMemory:                return inline_unsafe_setMemory();\n@@ -4947,0 +4948,51 @@\n+\n+  return true;\n+}\n+\n+\/\/ unsafe_setmemory(void *base, ulong offset, size_t length, char fill_value);\n+\/\/ Fill 'length' bytes starting from 'base[offset]' with 'fill_value'\n+bool LibraryCallKit::inline_unsafe_setMemory() {\n+  if (callee()->is_static())  return false;  \/\/ caller must have the capability!\n+  null_check_receiver();  \/\/ null-check receiver\n+  if (stopped())  return true;\n+\n+  C->set_has_unsafe_access(true);  \/\/ Mark eventual nmethod as \"unsafe\".\n+\n+  Node* dst_base =         argument(1);  \/\/ type: oop\n+  Node* dst_off  = ConvL2X(argument(2)); \/\/ type: long\n+  Node* size     = ConvL2X(argument(4)); \/\/ type: long\n+  Node* byte     =         argument(6);  \/\/ type: byte\n+\n+  assert(Unsafe_field_offset_to_byte_offset(11) == 11,\n+         \"fieldOffset must be byte-scaled\");\n+\n+  Node* dst_addr = make_unsafe_address(dst_base, dst_off);\n+\n+  Node* thread = _gvn.transform(new ThreadLocalNode());\n+  Node* doing_unsafe_access_addr = basic_plus_adr(top(), thread, in_bytes(JavaThread::doing_unsafe_access_offset()));\n+  BasicType doing_unsafe_access_bt = T_BYTE;\n+  assert((sizeof(bool) * CHAR_BIT) == 8, \"not implemented\");\n+\n+  \/\/ update volatile field\n+  store_to_memory(control(), doing_unsafe_access_addr, intcon(1), doing_unsafe_access_bt, Compile::AliasIdxRaw, MemNode::unordered);\n+\n+  int flags = RC_LEAF | RC_NO_FP;\n+\n+  const TypePtr* dst_type = TypePtr::BOTTOM;\n+\n+  \/\/ Adjust memory effects of the runtime call based on input values.\n+  if (!has_wide_mem(_gvn, dst_addr, dst_base)) {\n+    dst_type = _gvn.type(dst_addr)->is_ptr(); \/\/ narrow out memory\n+\n+    flags |= RC_NARROW_MEM; \/\/ narrow in memory\n+  }\n+\n+  \/\/ Call it.  Note that the length argument is not scaled.\n+  make_runtime_call(flags,\n+                    OptoRuntime::make_setmemory_Type(),\n+                    StubRoutines::unsafe_setmemory(),\n+                    \"unsafe_setmemory\",\n+                    dst_type,\n+                    dst_addr, size XTOP, byte);\n+\n+  store_to_memory(control(), doing_unsafe_access_addr, intcon(0), doing_unsafe_access_bt, Compile::AliasIdxRaw, MemNode::unordered);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":52,"deletions":0,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -234,0 +234,1 @@\n+  bool inline_unsafe_setMemory();\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -774,0 +774,23 @@\n+\/\/ Takes as parameters:\n+\/\/ void *dest\n+\/\/ long size\n+\/\/ uchar byte\n+const TypeFunc* OptoRuntime::make_setmemory_Type() {\n+  \/\/ create input type (domain)\n+  int argcnt = NOT_LP64(3) LP64_ONLY(4);\n+  const Type** fields = TypeTuple::fields(argcnt);\n+  int argp = TypeFunc::Parms;\n+  fields[argp++] = TypePtr::NOTNULL;        \/\/ dest\n+  fields[argp++] = TypeX_X;                 \/\/ size\n+  LP64_ONLY(fields[argp++] = Type::HALF);  \/\/ size\n+  fields[argp++] = TypeInt::UBYTE;          \/\/ bytevalue\n+  assert(argp == TypeFunc::Parms+argcnt, \"correct decoding\");\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms+argcnt, fields);\n+\n+  \/\/ no result type needed\n+  fields = TypeTuple::fields(1);\n+  fields[TypeFunc::Parms+0] = nullptr; \/\/ void\n+  const TypeTuple* range = TypeTuple::make(TypeFunc::Parms, fields);\n+  return TypeFunc::make(domain, range);\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":23,"deletions":0,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -269,0 +269,2 @@\n+  static const TypeFunc* make_setmemory_Type();\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -396,1 +396,6 @@\n-    Copy::fill_to_memory_atomic(p, sz, value);\n+    if (StubRoutines::unsafe_setmemory() != nullptr) {\n+      MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXExec, thread));\n+      StubRoutines::UnsafeSetMemory_stub()(p, sz, value);\n+    } else {\n+      Copy::fill_to_memory_atomic(p, sz, value);\n+    }\n","filename":"src\/hotspot\/share\/prims\/unsafe.cpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -179,0 +179,1 @@\n+uint SharedRuntime::_unsafe_set_memory_ctr=0;\n@@ -544,1 +545,0 @@\n-\n@@ -1972,0 +1972,1 @@\n+  if (_unsafe_set_memory_ctr) tty->print_cr(\"%5u unsafe set memorys\", _unsafe_set_memory_ctr);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -546,0 +546,2 @@\n+  static uint _unsafe_set_memory_ctr;      \/\/ Slow-path includes alignment checks\n+\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -112,0 +112,2 @@\n+address StubRoutines::_unsafe_setmemory                  = nullptr;\n+\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -196,0 +196,2 @@\n+  static address _unsafe_setmemory;\n+\n@@ -384,0 +386,5 @@\n+  static address unsafe_setmemory()     { return _unsafe_setmemory; }\n+\n+  typedef void (*UnsafeSetMemoryStub)(const void* src, size_t count, char byte);\n+  static UnsafeSetMemoryStub UnsafeSetMemory_stub()         { return CAST_TO_FN_PTR(UnsafeSetMemoryStub,  _unsafe_setmemory); }\n+\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2006, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2006, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -214,2 +214,2 @@\n-  address dst = (address) to;\n-  uintptr_t bits = (uintptr_t) to | (uintptr_t) size;\n+  address dst = (address)to;\n+  uintptr_t bits = (uintptr_t)to | (uintptr_t)size;\n@@ -217,1 +217,1 @@\n-    jlong fill = (julong)( (jubyte)value ); \/\/ zero-extend\n+    jlong fill = (julong)((jubyte)value);  \/\/ zero-extend\n@@ -223,1 +223,1 @@\n-    \/\/Copy::fill_to_jlongs_atomic((jlong*) dst, size \/ sizeof(jlong));\n+    \/\/ Copy::fill_to_jlongs_atomic((jlong*) dst, size \/ sizeof(jlong));\n@@ -228,1 +228,1 @@\n-    jint fill = (juint)( (jubyte)value ); \/\/ zero-extend\n+    jint fill = (juint)((jubyte)value);  \/\/ zero-extend\n@@ -233,1 +233,1 @@\n-    \/\/Copy::fill_to_jints_atomic((jint*) dst, size \/ sizeof(jint));\n+    \/\/ Copy::fill_to_jints_atomic((jint*) dst, size \/ sizeof(jint));\n@@ -238,1 +238,1 @@\n-    jshort fill = (jushort)( (jubyte)value ); \/\/ zero-extend\n+    jshort fill = (jushort)((jubyte)value);  \/\/ zero-extend\n@@ -240,1 +240,1 @@\n-    \/\/Copy::fill_to_jshorts_atomic((jshort*) dst, size \/ sizeof(jshort));\n+    \/\/ Copy::fill_to_jshorts_atomic((jshort*) dst, size \/ sizeof(jshort));\n@@ -247,3 +247,4 @@\n-    \/\/ This code is used by Unsafe and may hit the next page after truncation of mapped memory.\n-    \/\/ Therefore, we use volatile to prevent compilers from replacing the loop by memset which\n-    \/\/ may not trigger SIGBUS as needed (observed on Alpine Linux x86_64)\n+    \/\/ This code is used by Unsafe and may hit the next page after truncation\n+    \/\/ of mapped memory. Therefore, we use volatile to prevent compilers from\n+    \/\/ replacing the loop by memset which may not trigger SIGBUS as needed\n+    \/\/ (observed on Alpine Linux x86_64)\n","filename":"src\/hotspot\/share\/utilities\/copy.cpp","additions":13,"deletions":12,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n","filename":"src\/hotspot\/share\/utilities\/copy.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3827,0 +3827,1 @@\n+    @IntrinsicCandidate\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/misc\/Unsafe.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -0,0 +1,93 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+ package org.openjdk.bench.java.lang.foreign;\n+\n+import sun.misc.Unsafe;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Setup;\n+import java.lang.foreign.Arena;\n+import java.lang.foreign.MemorySegment;\n+\n+import java.util.concurrent.TimeUnit;\n+\n+@BenchmarkMode(Mode.AverageTime)\n+@Warmup(iterations = 5, time = 500, timeUnit = TimeUnit.MILLISECONDS)\n+@Measurement(iterations = 10, time = 500, timeUnit = TimeUnit.MILLISECONDS)\n+@State(org.openjdk.jmh.annotations.Scope.Thread)\n+@OutputTimeUnit(TimeUnit.NANOSECONDS)\n+@Fork(value = 3, jvmArgsAppend = {\"--enable-native-access=ALL-UNNAMED\"})\n+public class MemorySegmentZeroUnsafe {\n+\n+    static final Unsafe UNSAFE = Utils.unsafe;\n+    long src;\n+\n+    @Param({\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"15\", \"16\", \"63\", \"64\", \"255\", \"256\"})\n+    public int size;\n+\n+    @Param({\"true\", \"false\"})\n+    public boolean aligned;\n+\n+    private MemorySegment segment;\n+    private long address;\n+\n+    @Setup\n+    public void setup() throws Throwable {\n+        Arena arena = Arena.global();\n+        long alignment = 1;\n+        \/\/ this complex logic is to ensure that if in the future we decide to batch writes with different\n+        \/\/ batches based on alignment, we would spot it here\n+        if (size == 2 || size == 3) {\n+            alignment = 2;\n+        } else if (size >= 4 && size <= 7) {\n+            alignment = 4;\n+        } else {\n+            alignment = 8;\n+        }\n+        if (aligned) {\n+            segment = arena.allocate(size, alignment);\n+        } else {\n+            \/\/ forcibly misaligned in both address AND size, given that would be the worst case\n+            segment = arena.allocate(size + 1, alignment).asSlice(1);\n+        }\n+        address = segment.address();\n+    }\n+\n+    @Benchmark\n+    public void panama() {\n+        segment.fill((byte) 0);\n+    }\n+\n+    @Benchmark\n+    public void unsafe() {\n+        UNSAFE.setMemory(address, size, (byte) 0);\n+    }\n+}\n","filename":"test\/micro\/org\/openjdk\/bench\/java\/lang\/foreign\/MemorySegmentZeroUnsafe.java","additions":93,"deletions":0,"binary":false,"changes":93,"status":"added"}]}