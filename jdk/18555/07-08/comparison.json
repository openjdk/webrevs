{"files":[{"patch":"@@ -8339,0 +8339,5 @@\n+    \/\/ Initialize table for fill memory check.\n+    if (UnsafeCopyMemory::_table == nullptr) {\n+      UnsafeCopyMemory::create_table(8);\n+    }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -3141,0 +3141,4 @@\n+    if (UnsafeSetMemory::_table == nullptr) {\n+      UnsafeSetMemory::create_table(32);\n+    }\n+\n","filename":"src\/hotspot\/cpu\/arm\/stubGenerator_arm.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -4752,0 +4752,4 @@\n+    if (UnsafeSetMemory::_table == nullptr) {\n+      UnsafeSetMemory::create_table(8);\n+    }\n+\n","filename":"src\/hotspot\/cpu\/ppc\/stubGenerator_ppc.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -5486,0 +5486,4 @@\n+    if (UnsafeSetMemory::_table == nullptr) {\n+      UnsafeSetMemory::create_table(8);\n+    }\n+\n","filename":"src\/hotspot\/cpu\/riscv\/stubGenerator_riscv.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -4128,0 +4128,5 @@\n+    \/\/ Initialize table for fill memory check.\n+    if (UnsafeSetMemory::_table == nullptr) {\n+      UnsafeSetMemory::create_table(8);\n+    }\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_32.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -155,1 +155,1 @@\n-#ifdef _LP64\n+\/\/ #ifdef _LP64\n@@ -158,1 +158,1 @@\n-#endif\n+\/\/ #endif\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64_arraycopy.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -344,1 +344,2 @@\n-        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_arraycopy) {\n+        bool is_unsafe_setmemory = (thread->doing_unsafe_access() && UnsafeSetMemory::contains_pc(pc));\n+        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_arraycopy || is_unsafe_setmemory) {\n@@ -349,0 +350,3 @@\n+          if (is_unsafe_setmemory) {\n+            next_pc = UnsafeSetMemory::page_error_continue_pc(pc);\n+          }\n@@ -374,0 +378,3 @@\n+        if (UnsafeSetMemory::contains_pc(pc)) {\n+          next_pc = UnsafeSetMemory::page_error_continue_pc(pc);\n+        }\n","filename":"src\/hotspot\/os_cpu\/aix_ppc\/os_aix_ppc.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -261,1 +261,2 @@\n-        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_arraycopy) {\n+        bool is_unsafe_setmemory = (thread->doing_unsafe_access() && UnsafeSetMemory::contains_pc(pc));\n+        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_arraycopy || is_unsafe_setmemory) {\n@@ -266,0 +267,3 @@\n+          if (is_unsafe_setmemory) {\n+            next_pc = UnsafeSetMemory::page_error_continue_pc(pc);\n+          }\n@@ -305,0 +309,3 @@\n+      if (UnsafeSetMemory::contains_pc(pc)) {\n+        next_pc = UnsafeSetMemory::page_error_continue_pc(pc);\n+      }\n","filename":"src\/hotspot\/os_cpu\/bsd_aarch64\/os_bsd_aarch64.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -244,0 +244,1 @@\n+        bool is_unsafe_setmemory = (thread->doing_unsafe_access() && UnsafeSetMemory::contains_pc(pc));\n@@ -249,0 +250,3 @@\n+          if (is_unsafe_setmemory) {\n+            next_pc = UnsafeSetMemory::page_error_continue_pc(pc);\n+          }\n@@ -292,0 +296,3 @@\n+      if (UnsafeSetMemory::contains_pc(pc)) {\n+        next_pc = UnsafeSetMemory::page_error_continue_pc(pc);\n+      }\n","filename":"src\/hotspot\/os_cpu\/linux_aarch64\/os_linux_aarch64.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -327,1 +327,4 @@\n-        if ((nm != nullptr && nm->has_unsafe_access()) || (thread->doing_unsafe_access() && UnsafeCopyMemory::contains_pc(pc))) {\n+        if ((nm != nullptr && nm->has_unsafe_access()) ||\n+            (thread->doing_unsafe_access() &&\n+             (UnsafeCopyMemory::contains_pc(pc) ||\n+              UnsafeSetMemory::contains_pc(pc)))) {\n@@ -332,6 +335,9 @@\n-          \/\/ Determination of interpreter\/vtable stub\/compiled code null exception\n-          CodeBlob* cb = CodeCache::find_blob(pc);\n-          if (cb != nullptr) {\n-            stub = SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::IMPLICIT_NULL);\n-          }\n-      } else if (sig == SIGILL && *(int *)pc == NativeInstruction::not_entrant_illegal_instruction) {\n+        \/\/ Determination of interpreter\/vtable stub\/compiled code null exception\n+        CodeBlob* cb = CodeCache::find_blob(pc);\n+        if (cb != nullptr) {\n+          stub = SharedRuntime::continuation_for_implicit_exception(\n+              thread, pc, SharedRuntime::IMPLICIT_NULL);\n+        }\n+      } else if (sig == SIGILL &&\n+                 *(int*)pc ==\n+                     NativeInstruction::not_entrant_illegal_instruction) {\n@@ -365,0 +371,3 @@\n+    if (UnsafeSetMemory::contains_pc(pc)) {\n+      next_pc = UnsafeSetMemory::page_error_continue_pc(pc);\n+    }\n","filename":"src\/hotspot\/os_cpu\/linux_arm\/os_linux_arm.cpp","additions":16,"deletions":7,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -359,1 +359,2 @@\n-        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_arraycopy) {\n+        bool is_unsafe_setmemory = (thread->doing_unsafe_access() && UnsafeSetMemory::contains_pc(pc));\n+        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_arraycopy || is_unsafe_setmemory) {\n@@ -364,0 +365,3 @@\n+          if (is_unsafe_setmemory) {\n+            next_pc = UnsafeSetMemory::page_error_continue_pc(pc);\n+          }\n@@ -385,0 +389,3 @@\n+        if (UnsafeSetMemory::contains_pc(pc)) {\n+          next_pc = UnsafeSetMemory::page_error_continue_pc(pc);\n+        }\n","filename":"src\/hotspot\/os_cpu\/linux_ppc\/os_linux_ppc.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -234,1 +234,2 @@\n-        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_arraycopy) {\n+        bool is_unsafe_setmemory = (thread->doing_unsafe_access() && UnsafeSetMemory::contains_pc(pc));\n+        if ((nm != nullptr && nm->has_unsafe_access()) || is_unsafe_arraycopy || is_unsafe_setmemory) {\n@@ -239,0 +240,3 @@\n+          if (is_unsafe_setmemory) {\n+            next_pc = UnsafeSetMemory::page_error_continue_pc(pc);\n+          }\n@@ -278,0 +282,3 @@\n+      if (UnsafeSetMemory::contains_pc(pc)) {\n+        next_pc = UnsafeSetMemory::page_error_continue_pc(pc);\n+      }\n","filename":"src\/hotspot\/os_cpu\/linux_riscv\/os_linux_riscv.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -211,0 +211,49 @@\n+\n+\/\/ Fill bytes; larger units are filled atomically if everything is aligned.\n+void Copy::fill_to_memory_atomic(void* to, size_t size, jubyte value) {\n+  address dst = (address)to;\n+  uintptr_t bits = (uintptr_t)to | (uintptr_t)size;\n+  if (bits % sizeof(jlong) == 0) {\n+    jlong fill = (julong)((jubyte)value);  \/\/ zero-extend\n+    if (fill != 0) {\n+      fill += fill << 8;\n+      fill += fill << 16;\n+      fill += fill << 32;\n+    }\n+    \/\/ Copy::fill_to_jlongs_atomic((jlong*) dst, size \/ sizeof(jlong));\n+    for (uintptr_t off = 0; off < size; off += sizeof(jlong)) {\n+      *(jlong*)(dst + off) = fill;\n+    }\n+  } else if (bits % sizeof(jint) == 0) {\n+    jint fill = (juint)((jubyte)value);  \/\/ zero-extend\n+    if (fill != 0) {\n+      fill += fill << 8;\n+      fill += fill << 16;\n+    }\n+    \/\/ Copy::fill_to_jints_atomic((jint*) dst, size \/ sizeof(jint));\n+    for (uintptr_t off = 0; off < size; off += sizeof(jint)) {\n+      *(jint*)(dst + off) = fill;\n+    }\n+  } else if (bits % sizeof(jshort) == 0) {\n+    jshort fill = (jushort)((jubyte)value);  \/\/ zero-extend\n+    fill += (jshort)(fill << 8);\n+    \/\/ Copy::fill_to_jshorts_atomic((jshort*) dst, size \/ sizeof(jshort));\n+    for (uintptr_t off = 0; off < size; off += sizeof(jshort)) {\n+      *(jshort*)(dst + off) = fill;\n+    }\n+  } else {\n+    \/\/ Not aligned, so no need to be atomic.\n+#ifdef MUSL_LIBC\n+    \/\/ This code is used by Unsafe and may hit the next page after truncation\n+    \/\/ of mapped memory. Therefore, we use volatile to prevent compilers from\n+    \/\/ replacing the loop by memset which may not trigger SIGBUS as needed\n+    \/\/ (observed on Alpine Linux x86_64)\n+    jbyte fill = value;\n+    for (uintptr_t off = 0; off < size; off += sizeof(jbyte)) {\n+      *(volatile jbyte*)(dst + off) = fill;\n+    }\n+#else\n+    Copy::fill_to_bytes(dst, size, value);\n+#endif\n+  }\n+}\n","filename":"src\/hotspot\/share\/utilities\/copy.cpp","additions":49,"deletions":0,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -285,51 +285,2 @@\n-\n-  \/\/ Fill bytes; larger units are filled atomically if everything is aligned.\n-  inline static void fill_to_memory_atomic(void* to, size_t size,\n-                                           jubyte value) {\n-    address dst = (address)to;\n-    uintptr_t bits = (uintptr_t)to | (uintptr_t)size;\n-    if (bits % sizeof(jlong) == 0) {\n-      jlong fill = (julong)((jubyte)value);  \/\/ zero-extend\n-      if (fill != 0) {\n-        fill += fill << 8;\n-        fill += fill << 16;\n-        fill += fill << 32;\n-      }\n-      \/\/ Copy::fill_to_jlongs_atomic((jlong*) dst, size \/ sizeof(jlong));\n-      for (uintptr_t off = 0; off < size; off += sizeof(jlong)) {\n-        *(jlong*)(dst + off) = fill;\n-      }\n-    } else if (bits % sizeof(jint) == 0) {\n-      jint fill = (juint)((jubyte)value);  \/\/ zero-extend\n-      if (fill != 0) {\n-        fill += fill << 8;\n-        fill += fill << 16;\n-      }\n-      \/\/ Copy::fill_to_jints_atomic((jint*) dst, size \/ sizeof(jint));\n-      for (uintptr_t off = 0; off < size; off += sizeof(jint)) {\n-        *(jint*)(dst + off) = fill;\n-      }\n-    } else if (bits % sizeof(jshort) == 0) {\n-      jshort fill = (jushort)((jubyte)value);  \/\/ zero-extend\n-      fill += (jshort)(fill << 8);\n-      \/\/ Copy::fill_to_jshorts_atomic((jshort*) dst, size \/ sizeof(jshort));\n-      for (uintptr_t off = 0; off < size; off += sizeof(jshort)) {\n-        *(jshort*)(dst + off) = fill;\n-      }\n-    } else {\n-      \/\/ Not aligned, so no need to be atomic.\n-#ifdef MUSL_LIBC\n-      \/\/ This code is used by Unsafe and may hit the next page after truncation\n-      \/\/ of mapped memory. Therefore, we use volatile to prevent compilers from\n-      \/\/ replacing the loop by memset which may not trigger SIGBUS as needed\n-      \/\/ (observed on Alpine Linux x86_64)\n-      jbyte fill = value;\n-      for (uintptr_t off = 0; off < size; off += sizeof(jbyte)) {\n-        *(volatile jbyte*)(dst + off) = fill;\n-      }\n-#else\n-      Copy::fill_to_bytes(dst, size, value);\n-#endif\n-    }\n-  }\n-\n+  static void fill_to_memory_atomic(void* to, size_t size, jubyte value = 0);\n+  \n","filename":"src\/hotspot\/share\/utilities\/copy.hpp","additions":2,"deletions":51,"binary":false,"changes":53,"status":"modified"}]}