{"files":[{"patch":"@@ -616,1 +616,1 @@\n-     * is OK given, a secondary check (in awaitWork) needed to cover\n+     * is OK given, a secondary check (in deactivate) needed to cover\n@@ -624,5 +624,5 @@\n-     * and elsewhere.  Those in awaitWork are set to small values that\n-     * only cover near-miss scenarios for inactivate\/activate races.\n-     * Because idle workers are often not yet blocked (parked), we use\n-     * the WorkQueue parker field to advertise that a waiter actually\n-     * needs unparking upon signal.\n+     * and elsewhere; set to small values that only cover near-miss\n+     * scenarios for deactivate\/reactivate races.  Because idle workers\n+     * are often not yet blocked (parked), we use the WorkQueue parker\n+     * field to advertise that a waiter actually needs unparking upon\n+     * signal.\n@@ -679,1 +679,4 @@\n-     * period given by field keepAlive.\n+     * period given by field keepAlive (default 60sec), which applies\n+     * to the first timeout of a fully populated pool. Subsequent (or\n+     * other) cases use delays such that, if still quiescent, all will\n+     * be released before one additional keepAlive unit elapses.\n@@ -889,16 +892,18 @@\n-     * For class ForkJoinPool, it is usually more effective to order\n-     * fields such that the most commonly accessed fields are unlikely\n-     * to share cache lines with adjacent objects under JVM layout\n-     * rules. For class WorkQueue, an embedded @Contended region\n-     * segregates fields most heavily updated by owners from those\n-     * most commonly read by stealers or other management.  Initial\n-     * sizing and resizing of WorkQueue arrays is an even more\n-     * delicate tradeoff because the best strategy systematically\n-     * varies across garbage collectors. Small arrays are better for\n-     * locality and reduce GC scan time, but large arrays reduce both\n-     * direct false-sharing and indirect cases due to GC bookkeeping\n-     * (cardmarks etc), and reduce the number of resizes, which are\n-     * not especially fast because they require atomic transfers.\n-     * Currently, arrays are initialized to be fairly small but early\n-     * resizes rapidly increase size by more than a factor of two\n-     * until very large.  (Maintenance note: any changes in fields,\n+     * We isolate the ForkJoinPool.ctl field that otherwise causes the\n+     * most false-sharing misses with respect to other fields. Also,\n+     * ForkJoinPool fields are ordered such that fields less prone to\n+     * contention effects are first, offsetting those that otherwise\n+     * would be, while also reducing total footprint vs using\n+     * multiple @Contended regions, which tends to slow down\n+     * less-contended applications. For class WorkQueue, an\n+     * embedded @Contended region segregates fields most heavily\n+     * updated by owners from those most commonly read by stealers or\n+     * other management.  Initial sizing and resizing of WorkQueue\n+     * arrays is an even more delicate tradeoff because the best\n+     * strategy systematically varies across garbage collectors. Small\n+     * arrays are better for locality and reduce GC scan time, but\n+     * large arrays reduce both direct false-sharing and indirect\n+     * cases due to GC bookkeeping (cardmarks etc), and reduce the\n+     * number of resizes, which are not especially fast because they\n+     * require atomic transfers.  Currently, arrays are initialized to\n+     * be fairly small.  (Maintenance note: any changes in fields,\n@@ -1038,1 +1043,2 @@\n-    static final long WMASK           = ~(((long)SMASK) << 48); \/\/ id bits only\n+    static final long HMASK           = ((((long)SMASK) << 32) |\n+                                         (((long)SMASK) << 16)); \/\/ history bits\n@@ -1298,1 +1304,1 @@\n-            int s = top, b = base, cap, m, room; ForkJoinTask<?>[] a;\n+            int s = top, b = base, cap, m, room, newCap; ForkJoinTask<?>[] a;\n@@ -1311,17 +1317,14 @@\n-            if (room == 0) {                          \/\/ resize for next time\n-                int newCap;                           \/\/ rapidly grow until large\n-                if ((newCap = (cap < 1 << 24) ? cap << 2 : cap << 1) > 0) {\n-                    ForkJoinTask<?>[] newArray = null;\n-                    try {\n-                        newArray = new ForkJoinTask<?>[newCap];\n-                    } catch (OutOfMemoryError ex) {\n-                    }\n-                    if (newArray != null) {           \/\/ else throw on next push\n-                        int newMask = newCap - 1;     \/\/ poll old, push to new\n-                        for (int k = s, j = cap; j > 0; --j, --k) {\n-                            if ((newArray[k & newMask] =\n-                                 (ForkJoinTask<?>)U.getAndSetReference(\n-                                     a, slotOffset(k & m), null)) == null)\n-                                break;                \/\/ lost to pollers\n-                        }\n-                        updateArray(newArray);        \/\/ fully fenced\n+            if (room == 0 && (newCap = cap << 1) > 0) {\n+                ForkJoinTask<?>[] newArray = null;\n+                try {                                 \/\/ resize for next time\n+                    newArray = new ForkJoinTask<?>[newCap];\n+                } catch (OutOfMemoryError ex) {\n+                }\n+                if (newArray != null) {               \/\/ else throw on next push\n+                    int newMask = newCap - 1;         \/\/ poll old, push to new\n+                    for (int k = s, j = cap; j > 0; --j, --k) {\n+                        ForkJoinTask<?> u;\n+                        if ((u = (ForkJoinTask<?>)U.getAndSetReference(\n+                                 a, slotOffset(k & m), null)) == null)\n+                            break;                    \/\/ lost to pollers\n+                        newArray[k & newMask] = u;\n@@ -1329,0 +1332,1 @@\n+                    updateArray(newArray);            \/\/ fully fenced\n@@ -1333,2 +1337,1 @@\n-            if ((room == 0 || room >= m || a[m & (s - 1)] == null) &&\n-                pool != null)\n+            if ((room == 0 || a[m & (s - 1)] == null) && pool != null)\n@@ -1679,0 +1682,2 @@\n+    volatile int runState;               \/\/ versioned, lockable\n+    @jdk.internal.vm.annotation.Contended(\"fjpctl\") \/\/ segregate\n@@ -1680,0 +1685,1 @@\n+    @jdk.internal.vm.annotation.Contended(\"fjpctl\") \/\/ colocate\n@@ -1681,1 +1687,0 @@\n-    volatile int runState;               \/\/ versioned, lockable\n@@ -1879,2 +1884,2 @@\n-        else if ((int)c == 0)             \/\/ was dropped on timeout\n-            replaceable = false;\n+        else if ((int)c != 0)\n+            replaceable = true;           \/\/ signal below to cascade timeouts\n@@ -2003,4 +2008,1 @@\n-                else if (compareAndSetCtl(c, c) &&        \/\/ confirm\n-                         casRunState(e, (e & SHUTDOWN) != 0 ? e | STOP : e)) {\n-                    if ((e & SHUTDOWN) != 0)              \/\/ enable termination\n-                        interruptAll();\n+                else if ((e & SHUTDOWN) == 0)\n@@ -2008,0 +2010,3 @@\n+                else if (compareAndSetCtl(c, c) && casRunState(e, e | STOP)) {\n+                    interruptAll();                       \/\/ confirmed\n+                    return true;                          \/\/ enable termination\n@@ -2024,1 +2029,2 @@\n-            for (long window = NO_HISTORY | (r >>> 16);;) {\n+            long window = (long)((r >>> 16) & SMASK) | NO_HISTORY;\n+            do {\n@@ -2026,9 +2032,4 @@\n-                if ((runState & STOP) != 0)                 \/\/ terminating\n-                    break;\n-                if (window == (window = scan(w, window & WMASK, r)) &&\n-                    window >= 0L && phase != (phase = awaitWork(w, phase))) {\n-                    if ((phase & IDLE) != 0)\n-                        break;                              \/\/ worker exit\n-                    window = NO_HISTORY | (window & SMASK); \/\/ clear history\n-                }\n-             }\n+            } while ((runState & STOP) == 0 &&\n+                     ((window != (window = scan(w, window, r)) || window < 0L ||\n+                       ((phase = deactivate(w, phase)) & IDLE) == 0 ||\n+                       ((phase = awaitWork(w, phase)) & IDLE) == 0)));\n@@ -2051,0 +2052,1 @@\n+        long next = window & ~RESCAN;\n@@ -2063,2 +2065,2 @@\n-                                if (window >= 0L && a[nk] != null)\n-                                    window |= RESCAN;\n+                                if (next >= 0L && a[nk] != null)\n+                                    next |= RESCAN;\n@@ -2069,1 +2071,1 @@\n-                                            a, slotOffset(k), t, null))) {\n+                                           a, slotOffset(k), t, null))) {\n@@ -2071,3 +2073,2 @@\n-                            long pw = window, nw = ((pw << 16) | j) & WMASK;\n-                            window = nw | RESCAN;\n-                            if ((nw != pw || (short)(nw >>> 32) != j) &&\n+                            next = RESCAN | ((window << 16) & HMASK) | j;\n+                            if (((short)(next >>> 32) != j || next != window) &&\n@@ -2086,1 +2087,1 @@\n-        return window;\n+        return next;\n@@ -2090,1 +2091,2 @@\n-     * Tries to inactivate, and if successful, awaits signal or termination.\n+     * Deactivates w, reactivating on contention, already signalled,\n+     * or possible missed signal.\n@@ -2093,2 +2095,2 @@\n-     * @param p current phase\n-     * @return current phase, with IDLE set if worker should exit\n+     * @param phase current phase\n+     * @return phase on exit\n@@ -2096,19 +2098,11 @@\n-    private int awaitWork(WorkQueue w, int p) {\n-        if (w != null) {\n-            int idlePhase = p + IDLE, nextPhase = p + (IDLE << 1);\n-            long pc = ctl, qc = (nextPhase & LMASK) | ((pc - RC_UNIT) & UMASK);\n-            w.stackPred = (int)pc;                   \/\/ set ctl stack link\n-            w.phase = idlePhase;                     \/\/ try to inactivate\n-            if (!compareAndSetCtl(pc, qc))           \/\/ contended enque\n-                return w.phase = p;                  \/\/ back out\n-            int ac = (short)(qc >>> RC_SHIFT);\n-            boolean quiescent = (ac <= 0 && quiescent());\n-            if ((runState & STOP) != 0)\n-                return idlePhase;\n-            int spins = ac + ((((int)(qc >>> TC_SHIFT)) & SMASK) << 1);\n-            while ((p = w.phase) == idlePhase && --spins > 0)\n-                Thread.onSpinWait();  \/\/ spin for approx #accesses to signal\n-            if (p == idlePhase) {\n-                long deadline = (!quiescent ? 0L :   \/\/ timeout for trim\n-                                 System.currentTimeMillis() + keepAlive);\n-                WorkQueue[] qs = queues;\n+    private int deactivate(WorkQueue w, int phase) {\n+        int idle = phase | IDLE, p = idle, active = idle + IDLE;\n+        if (phase != idle && w != null) {\n+            long pc = ctl, qc = (active & LMASK) | ((pc - RC_UNIT) & UMASK);\n+            w.stackPred = (int)pc;                  \/\/ set ctl stack link\n+            w.phase = idle;                         \/\/ try to deactivate\n+            if (!compareAndSetCtl(pc, qc))          \/\/ contended enque\n+                p = w.phase = phase;                \/\/ back out\n+            else if ((runState & SHUTDOWN) == 0 || (qc & RC_MASK) > 0L ||\n+                     !quiescent() || (runState & STOP) == 0) {\n+                WorkQueue[] qs = queues;            \/\/ recheck queues\n@@ -2116,1 +2110,1 @@\n-                for (int i = 0; i < n; ++i) {        \/\/ recheck queues\n+                for (int i = -n; i < n; ++i) {\n@@ -2118,5 +2112,6 @@\n-                    if ((q = qs[i]) != null &&\n-                        (a = q.array) != null && (cap = a.length) > 0 &&\n-                        a[q.base & (cap - 1)] != null &&\n-                        ctl == qc && compareAndSetCtl(qc, pc)) {\n-                        w.phase = (int)qc;           \/\/ release\n+                    if ((p = w.phase) == active)    \/\/ precede, then interleave\n+                        break;                      \/\/  with signal checks\n+                    if (i >= 0 && (q = qs[i]) != null && (a = q.array) != null &&\n+                        (cap = a.length) > 0 && a[q.base & (cap - 1)] != null &&\n+                        qc == ctl && qc == compareAndExchangeCtl(qc, pc)) {\n+                        p = w.phase = active;       \/\/ may have missed signal\n@@ -2125,0 +2120,1 @@\n+                    Thread.onSpinWait();            \/\/ reduce memory traffic\n@@ -2126,22 +2122,41 @@\n-                if ((p = w.phase) == idlePhase) {    \/\/ emulate LockSupport.park\n-                    LockSupport.setCurrentBlocker(this);\n-                    w.parker = Thread.currentThread();\n-                    for (;;) {\n-                        if ((runState & STOP) != 0 || (p = w.phase) != idlePhase)\n-                            break;\n-                        U.park(quiescent, deadline);\n-                        if ((p = w.phase) != idlePhase || (runState & STOP) != 0)\n-                            break;\n-                        Thread.interrupted();        \/\/ clear for next park\n-                        if (quiescent && TIMEOUT_SLOP >\n-                            deadline - System.currentTimeMillis()) {\n-                            long sp = w.stackPred & LMASK;\n-                            long c = ctl, nc = sp | (UMASK & (c - TC_UNIT));\n-                            if (((int)c & SMASK) == (idlePhase & SMASK) &&\n-                                compareAndSetCtl(c, nc)) {\n-                                w.source = DEREGISTERED;\n-                                w.phase = (int)c;\n-                                break;\n-                            }\n-                            deadline += keepAlive;   \/\/ not head; reset timer\n-                        }\n+            }\n+        }\n+        return p;\n+    }\n+\n+    \/**\n+     * Awaits signal or termination.\n+     *\n+     * @param w the worker (may be null if already terminated)\n+     * @param p current phase with IDLE known to be set\n+     * @return current phase, with IDLE set if worker should exit\n+     *\/\n+    private int awaitWork(WorkQueue w, int p) {\n+        int active = p + IDLE;\n+        long deadline = 0L, c = ctl;                \/\/ use timeout if trimmable\n+        if ((c & RC_MASK) <= 0L && ((int)c & SMASK) == (active & SMASK)) {\n+            int nt = (short)(c >>> TC_SHIFT);       \/\/ all idle and w is ctl top\n+            long delay = keepAlive;                 \/\/ scale if not at target\n+            if (nt != (nt = Math.max(nt, parallelism)) && nt > 0)\n+                delay = Math.max(TIMEOUT_SLOP, delay \/ nt);\n+            if ((deadline = delay + System.currentTimeMillis()) == 0L)\n+                deadline = 1L;                      \/\/ avoid zero\n+        }\n+        if ((runState & STOP) == 0 && w != null && (p = w.phase) != active) {\n+            LockSupport.setCurrentBlocker(this);    \/\/ emulate LockSupport.park\n+            w.parker = Thread.currentThread();\n+            for (;;) {\n+                if ((runState & STOP) != 0 || (p = w.phase) == active)\n+                    break;\n+                U.park(deadline != 0L, deadline);\n+                if ((p = w.phase) == active || (runState & STOP) != 0)\n+                    break;\n+                Thread.interrupted();               \/\/ clear for next park\n+                if (deadline != 0L &&               \/\/ try to trim on timeout\n+                    deadline - System.currentTimeMillis() < TIMEOUT_SLOP) {\n+                    long sp = w.stackPred & LMASK, qc = ctl;\n+                    if (((int)qc & SMASK) == (active & SMASK) &&\n+                        compareAndSetCtl(qc, sp | (UMASK & (qc - TC_UNIT)))) {\n+                        w.source = DEREGISTERED;\n+                        w.phase = active;\n+                        break;\n@@ -2149,2 +2164,1 @@\n-                    w.parker = null;\n-                    LockSupport.setCurrentBlocker(null);\n+                    deadline = 0L;                  \/\/ no longer trimmable\n@@ -2153,0 +2167,2 @@\n+            w.parker = null;\n+            LockSupport.setCurrentBlocker(null);\n@@ -3102,1 +3118,7 @@\n-        return task.join();\n+        try {\n+            return task.join();\n+        } catch (RuntimeException | Error unchecked) {\n+            throw unchecked;\n+        } catch (Exception checked) {\n+            throw new RuntimeException(checked);\n+        }\n","filename":"src\/java.base\/share\/classes\/java\/util\/concurrent\/ForkJoinPool.java","additions":143,"deletions":121,"binary":false,"changes":264,"status":"modified"}]}