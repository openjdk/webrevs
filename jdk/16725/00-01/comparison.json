{"files":[{"patch":"@@ -892,19 +892,22 @@\n-     * For class ForkJoinPool, it is usually more effective to order\n-     * fields such that the most commonly accessed fields are unlikely\n-     * to share cache lines with adjacent objects under JVM layout\n-     * rules. For class WorkQueue, an embedded @Contended region\n-     * segregates fields most heavily updated by owners from those\n-     * most commonly read by stealers or other management.  Initial\n-     * sizing and resizing of WorkQueue arrays is an even more\n-     * delicate tradeoff because the best strategy systematically\n-     * varies across garbage collectors. Small arrays are better for\n-     * locality and reduce GC scan time, but large arrays reduce both\n-     * direct false-sharing and indirect cases due to GC bookkeeping\n-     * (cardmarks etc), and reduce the number of resizes, which are\n-     * not especially fast because they require atomic transfers.\n-     * Currently, arrays are initialized to be fairly small but early\n-     * resizes rapidly increase size by more than a factor of two\n-     * until very large.  (Maintenance note: any changes in fields,\n-     * queues, or their uses, or JVM layout policies, must be\n-     * accompanied by re-evaluation of these placement and sizing\n-     * decisions.)\n+     * We isolate the ForkJoinPool.ctl field that otherwise causes the\n+     * most false-sharing misses with respect to other fields. Also,\n+     * ForkJoinPool fields are ordered such that fields less prone to\n+     * contention effects are first, offsetting those that otherwise\n+     * would be, while also reducing total footprint vs using\n+     * multiple @Contended regions, which tends to slow down\n+     * less-contended applications. For class WorkQueue, an\n+     * embedded @Contended region segregates fields most heavily\n+     * updated by owners from those most commonly read by stealers or\n+     * other management.  Initial sizing and resizing of WorkQueue\n+     * arrays is an even more delicate tradeoff because the best\n+     * strategy systematically varies across garbage collectors. Small\n+     * arrays are better for locality and reduce GC scan time, but\n+     * large arrays reduce both direct false-sharing and indirect\n+     * cases due to GC bookkeeping (cardmarks etc), and reduce the\n+     * number of resizes, which are not especially fast because they\n+     * require atomic transfers.  Currently, arrays are initialized to\n+     * be fairly small but early resizes rapidly increase size by more\n+     * than a factor of two until very large.  (Maintenance note: any\n+     * changes in fields, queues, or their uses, or JVM layout\n+     * policies, must be accompanied by re-evaluation of these\n+     * placement and sizing decisions.)\n@@ -1682,0 +1685,2 @@\n+    volatile int runState;               \/\/ versioned, lockable\n+    @jdk.internal.vm.annotation.Contended(\"fjpctl\") \/\/ segregate\n@@ -1683,0 +1688,1 @@\n+    @jdk.internal.vm.annotation.Contended(\"fjpctl\") \/\/ colocate\n@@ -1684,1 +1690,0 @@\n-    volatile int runState;               \/\/ versioned, lockable\n@@ -2006,4 +2011,1 @@\n-                else if (compareAndSetCtl(c, c) &&        \/\/ confirm\n-                         casRunState(e, (e & SHUTDOWN) != 0 ? e | STOP : e)) {\n-                    if ((e & SHUTDOWN) != 0)              \/\/ enable termination\n-                        interruptAll();\n+                else if ((e & SHUTDOWN) == 0)\n@@ -2011,0 +2013,3 @@\n+                else if (compareAndSetCtl(c, c) && casRunState(e, e | STOP)) {\n+                    interruptAll();                       \/\/ confirmed\n+                    return true;                          \/\/ enable termination\n@@ -2100,4 +2105,5 @@\n-        if ((p & IDLE) != 0 || w == null)       \/\/ already terminating\n-            return p;\n-        int nextPhase = p + (IDLE << 1);\n-        long pc = ctl, qc = (nextPhase & LMASK) | ((pc - RC_UNIT) & UMASK);\n+        int idlePhase, nextPhase;\n+        if ((idlePhase = p | IDLE) == p || w == null)\n+            return p;                           \/\/ already terminating\n+        long pc = ctl, qc = (((nextPhase = p + (IDLE << 1)) & LMASK) |\n+                             ((pc - RC_UNIT) & UMASK));\n@@ -2105,1 +2111,1 @@\n-        w.phase = p | IDLE;                     \/\/ try to inactivate\n+        w.phase = idlePhase;                    \/\/ try to inactivate\n@@ -2110,1 +2116,1 @@\n-        for (int l = n, r = nextPhase; l > 0; --l, ++r) {\n+        for (int l = -n, r = nextPhase; l < n; ++l, ++r) {\n@@ -2112,0 +2118,1 @@\n+            U.loadFence();\n@@ -2116,0 +2123,1 @@\n+            Thread.onSpinWait();                \/\/ reduce memory traffic\n@@ -2118,1 +2126,0 @@\n-            Thread.onSpinWait();                \/\/ reduce memory traffic\n@@ -2123,4 +2130,4 @@\n-            int nt = (short)(qc >>> TC_SHIFT), np = parallelism;\n-            long delay = keepAlive;\n-            if (np != nt)                       \/\/ scale if not at target\n-                delay = Math.max(TIMEOUT_SLOP, delay \/ Math.max(2, np));\n+            int nt = (short)(qc >>> TC_SHIFT);\n+            long delay = keepAlive;             \/\/ scale if not at target\n+            if (nt != (nt = Math.max(nt, parallelism)) && nt > 0)\n+                delay = Math.max(TIMEOUT_SLOP, delay \/ nt);\n@@ -3101,1 +3108,9 @@\n-        return task.join();\n+        try {\n+            return task.join();\n+        } catch (RuntimeException rex) {\n+            throw rex;\n+        } catch (Error eex) {\n+            throw eex;\n+        } catch (Exception ex) {\n+            throw new RuntimeException(ex);\n+        }\n","filename":"src\/java.base\/share\/classes\/java\/util\/concurrent\/ForkJoinPool.java","additions":51,"deletions":36,"binary":false,"changes":87,"status":"modified"}]}