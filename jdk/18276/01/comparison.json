{"files":[{"patch":"@@ -45,1 +45,0 @@\n-  _packset(arena(), 8,  0, nullptr),                        \/\/ packs for the current block\n@@ -49,1 +48,5 @@\n-  _race_possible(false),                                    \/\/ cases where SDMU is true\n+  _pairset(&_arena, _vloop_analyzer),\n+  _packset(&_arena, _vloop_analyzer\n+           NOT_PRODUCT(COMMA is_trace_superword_packset())\n+           NOT_PRODUCT(COMMA is_trace_superword_rejections())\n+           ),\n@@ -457,1 +460,1 @@\n-  if (_packset.length() == 0) {\n+  if (_pairset.is_empty()) {\n@@ -467,1 +470,1 @@\n-  extend_packset_with_more_pairs_by_following_use_and_def();\n+  extend_pairset_with_more_pairs_by_following_use_and_def();\n@@ -471,2 +474,0 @@\n-  construct_my_pack_map();\n-\n@@ -478,1 +479,0 @@\n-  \/\/ Now we only remove packs:\n@@ -558,3 +558,0 @@\n-            Node_List* pair = new Node_List();\n-            pair->push(s1);\n-            pair->push(s2);\n@@ -562,1 +559,1 @@\n-              _packset.append(pair);\n+              _pairset.add_pair(s1, s2);\n@@ -578,2 +575,2 @@\n-  assert(_packset.is_empty() || align_to_mem_ref != nullptr,\n-         \"packset empty or we find the alignment reference\");\n+  assert(_pairset.is_empty() || align_to_mem_ref != nullptr,\n+         \"pairset empty or we find the alignment reference\");\n@@ -584,1 +581,1 @@\n-    print_packset();\n+    _pairset.print();\n@@ -846,1 +843,1 @@\n-      if (!exists_at(s1, 0) && !exists_at(s2, 1)) {\n+      if (!_pairset.has_left(s1) && !_pairset.has_right(s2)) {\n@@ -862,12 +859,0 @@\n-\/\/------------------------------exists_at---------------------------\n-\/\/ Does s exist in a pack at position pos?\n-bool SuperWord::exists_at(Node* s, uint pos) {\n-  for (int i = 0; i < _packset.length(); i++) {\n-    Node_List* p = _packset.at(i);\n-    if (p->at(pos) == s) {\n-      return true;\n-    }\n-  }\n-  return false;\n-}\n-\n@@ -876,1 +861,1 @@\n-bool SuperWord::are_adjacent_refs(Node* s1, Node* s2) {\n+bool SuperWord::are_adjacent_refs(Node* s1, Node* s2) const {\n@@ -1027,1 +1012,1 @@\n-bool VLoopReductions::is_marked_reduction_pair(Node* s1, Node* s2) const {\n+bool VLoopReductions::is_marked_reduction_pair(const Node* s1, const Node* s2) const {\n@@ -1052,2 +1037,2 @@\n-\/\/ Extend packset by following use->def and def->use links from pack members.\n-void SuperWord::extend_packset_with_more_pairs_by_following_use_and_def() {\n+\/\/ Extend pairset by following use->def and def->use links from pair members.\n+void SuperWord::extend_pairset_with_more_pairs_by_following_use_and_def() {\n@@ -1056,1 +1041,0 @@\n-    packset_sort(_packset.length());\n@@ -1058,4 +1042,6 @@\n-    for (int i = 0; i < _packset.length(); i++) {\n-      Node_List* p = _packset.at(i);\n-      changed |= follow_use_defs(p);\n-      changed |= follow_def_uses(p);\n+    \/\/ Iterate the pairs in insertion order.\n+    for (int i = 0; i < _pairset.length(); i++) {\n+      Node* s1 = _pairset.left_at(i);\n+      Node* s2 = _pairset.right_at(i);\n+      changed |= extend_pairset_with_more_pairs_by_following_def(s1, s2);\n+      changed |= extend_pairset_with_more_pairs_by_following_use(s1, s2);\n@@ -1065,5 +1051,11 @@\n-  if (_race_possible) {\n-    for (int i = 0; i < _packset.length(); i++) {\n-      Node_List* p = _packset.at(i);\n-      order_def_uses(p);\n-    }\n+  \/\/ During extend_pairset_with_more_pairs_by_following_use, we may have re-ordered the\n+  \/\/ inputs of some nodes, when calling order_inputs_of_uses_to_match_def_pair. If a def\n+  \/\/ node has multiple uses, we may have re-ordered some of the inputs one use after\n+  \/\/ packing another use with the old order. Now that we have all pairs, we must ensure\n+  \/\/ that the order between the pairs is matching again. Since the PairSetIterator visits\n+  \/\/ all pair-chains from left-to-right, we essencially impose the order of the first\n+  \/\/ element on all other elements in the pair-chain.\n+  for (PairSetIterator pair(_pairset); !pair.done(); pair.next()) {\n+    Node* s1 = pair.left();\n+    Node* s2 = pair.right();\n+    order_inputs_of_all_use_pairs_to_match_def_pair(s1, s2);\n@@ -1074,2 +1066,2 @@\n-    tty->print_cr(\"\\nAfter Superword::extend_packset_with_more_pairs_by_following_use_and_def\");\n-    print_packset();\n+    tty->print_cr(\"\\nAfter Superword::extend_pairset_with_more_pairs_by_following_use_and_def\");\n+    _pairset.print();\n@@ -1096,6 +1088,2 @@\n-\/\/------------------------------follow_use_defs---------------------------\n-\/\/ Extend the packset by visiting operand definitions of nodes in pack p\n-bool SuperWord::follow_use_defs(Node_List* p) {\n-  assert(p->size() == 2, \"just checking\");\n-  Node* s1 = p->at(0);\n-  Node* s2 = p->at(1);\n+bool SuperWord::extend_pairset_with_more_pairs_by_following_def(Node* s1, Node* s2) {\n+  assert(_pairset.has_pair(s1, s2), \"(s1, s2) must be a pair\");\n@@ -1109,1 +1097,1 @@\n-    tty->print_cr(\"SuperWord::follow_use_defs: s1 %d, align %d\",\n+    tty->print_cr(\"SuperWord::extend_pairset_with_more_pairs_by_following_def: s1 %d, align %d\",\n@@ -1126,5 +1114,2 @@\n-      if (est_savings(t1, t2) >= 0) {\n-        Node_List* pair = new Node_List();\n-        pair->push(t1);\n-        pair->push(t2);\n-        _packset.append(pair);\n+      if (estimate_cost_savings_when_packing_pair(t1, t2) >= 0) {\n+        _pairset.add_pair(t1, t2);\n@@ -1133,1 +1118,1 @@\n-          tty->print_cr(\"SuperWord::follow_use_defs: set_alignment(%d, %d, %d)\",\n+          tty->print_cr(\"SuperWord::extend_pairset_with_more_pairs_by_following_def: set_alignment(%d, %d, %d)\",\n@@ -1145,7 +1130,2 @@\n-\/\/------------------------------follow_def_uses---------------------------\n-\/\/ Extend the packset by visiting uses of nodes in pack p\n-bool SuperWord::follow_def_uses(Node_List* p) {\n-  bool changed = false;\n-  Node* s1 = p->at(0);\n-  Node* s2 = p->at(1);\n-  assert(p->size() == 2, \"just checking\");\n+bool SuperWord::extend_pairset_with_more_pairs_by_following_use(Node* s1, Node* s2) {\n+  assert(_pairset.has_pair(s1, s2), \"(s1, s2) must be a pair\");\n@@ -1160,1 +1140,1 @@\n-    tty->print_cr(\"SuperWord::follow_def_uses: s1 %d, align %d\",\n+    tty->print_cr(\"SuperWord::extend_pairset_with_more_pairs_by_following_use: s1 %d, align %d\",\n@@ -1164,0 +1144,1 @@\n+  bool changed = false;\n@@ -1165,1 +1146,0 @@\n-  int num_s1_uses = 0;\n@@ -1170,1 +1150,0 @@\n-    num_s1_uses++;\n@@ -1182,2 +1161,1 @@\n-      if (!opnd_positions_match(s1, t1, s2, t2))\n-        continue;\n+      if (order_inputs_of_uses_to_match_def_pair(s1, s2, t1, t2) != PairOrderStatus::Ordered) { continue; }\n@@ -1187,1 +1165,1 @@\n-        int my_savings = est_savings(t1, t2);\n+        int my_savings = estimate_cost_savings_when_packing_pair(t1, t2);\n@@ -1197,3 +1175,0 @@\n-  if (num_s1_uses > 1) {\n-    _race_possible = true;\n-  }\n@@ -1201,4 +1176,1 @@\n-    Node_List* pair = new Node_List();\n-    pair->push(u1);\n-    pair->push(u2);\n-    _packset.append(pair);\n+    _pairset.add_pair(u1, u2);\n@@ -1207,1 +1179,1 @@\n-      tty->print_cr(\"SuperWord::follow_def_uses: set_alignment(%d, %d, %d)\",\n+      tty->print_cr(\"SuperWord::extend_pairset_with_more_pairs_by_following_use: set_alignment(%d, %d, %d)\",\n@@ -1217,4 +1189,4 @@\n-\/\/------------------------------order_def_uses---------------------------\n-\/\/ For extended packsets, ordinally arrange uses packset by major component\n-void SuperWord::order_def_uses(Node_List* p) {\n-  Node* s1 = p->at(0);\n+\/\/ For a pair (def1. def2), find all use packs (use1, use2), and ensure that their inputs have an order\n+\/\/ that matches the (def1, def2) pair.\n+void SuperWord::order_inputs_of_all_use_pairs_to_match_def_pair(Node* def1, Node* def2) {\n+  assert(_pairset.has_pair(def1, def2), \"(def1, def2) must be a pair\");\n@@ -1222,1 +1194,1 @@\n-  if (s1->is_Store()) return;\n+  if (def1->is_Store()) return;\n@@ -1225,1 +1197,1 @@\n-  if (is_marked_reduction(s1)) return;\n+  if (is_marked_reduction(def1)) return;\n@@ -1227,2 +1199,2 @@\n-  for (DUIterator_Fast imax, i = s1->fast_outs(imax); i < imax; i++) {\n-    Node* t1 = s1->fast_out(i);\n+  for (DUIterator_Fast imax, i = def1->fast_outs(imax); i < imax; i++) {\n+    Node* use1 = def1->fast_out(i);\n@@ -1231,1 +1203,1 @@\n-    if (!t1->is_Add() && !t1->is_Mul() && !VectorNode::is_muladds2i(t1)) {\n+    if (!use1->is_Add() && !use1->is_Mul() && !VectorNode::is_muladds2i(use1)) {\n@@ -1235,18 +1207,5 @@\n-    \/\/ Now find t1's packset\n-    Node_List* p2 = nullptr;\n-    for (int j = 0; j < _packset.length(); j++) {\n-      p2 = _packset.at(j);\n-      Node* first = p2->at(0);\n-      if (t1 == first) {\n-        break;\n-      }\n-      p2 = nullptr;\n-    }\n-    \/\/ Arrange all sub components by the major component\n-    if (p2 != nullptr) {\n-      for (uint j = 1; j < p->size(); j++) {\n-        Node* d1 = p->at(j);\n-        Node* u1 = p2->at(j);\n-        opnd_positions_match(s1, t1, d1, u1);\n-      }\n-    }\n+    \/\/ Find pair (use1, use2)\n+    Node* use2 = _pairset.get_right_or_null_for(use1);\n+    if (use2 == nullptr) { break; }\n+\n+    order_inputs_of_uses_to_match_def_pair(def1, def2, use1, use2);\n@@ -1256,8 +1215,40 @@\n-\/\/---------------------------opnd_positions_match-------------------------\n-\/\/ Is the use of d1 in u1 at the same operand position as d2 in u2?\n-bool SuperWord::opnd_positions_match(Node* d1, Node* u1, Node* d2, Node* u2) {\n-  \/\/ check reductions to see if they are marshalled to represent the reduction\n-  \/\/ operator in a specified opnd\n-  if (is_marked_reduction(u1) && is_marked_reduction(u2)) {\n-    \/\/ ensure reductions have phis and reduction definitions feeding the 1st operand\n-    Node* first = u1->in(2);\n+\/\/ For a def-pair (def1, def2), and their use-nodes (use1, use2):\n+\/\/ Ensure that the input order of (use1, use2) matches the order of (def1, def2).\n+\/\/\n+\/\/ We have different cases:\n+\/\/\n+\/\/ 1. Reduction (use1, use2): must always reduce left-to-right. Make sure that we have pattern:\n+\/\/\n+\/\/    phi\/reduction x1  phi\/reduction x2                    phi\/reduction x1\n+\/\/                | |               | |    and hopefully:               | |\n+\/\/                use1              use2                                use1 x2\n+\/\/                                                                         | |\n+\/\/                                                                         use2\n+\/\/\n+\/\/ 2: Inputs of (use1, use2) already match (def1, def2), i.e. for all input indices i:\n+\/\/\n+\/\/    use1->in(i) == def1 || use2->in(def2)   ->    use1->in(i) == def1 && use2->in(def2)\n+\/\/\n+\/\/ 3: Add\/Mul (use1, use2): we can try to swap edges:\n+\/\/\n+\/\/     def1 x1   x2 def2           def1 x1   def2 x2\n+\/\/        | |     | |       ==>       | |       | |\n+\/\/        use1    use2                use1      use2\n+\/\/\n+\/\/ 4: MulAddS2I (use1, use2): we can try to swap edges:\n+\/\/\n+\/\/    (x1 * x2) + (x3 * x4)    ==>  4.a: (x2 * x1) + (x4 * x3)\n+\/\/                                  4.b: (x4 * x3) + (x2 * x1)\n+\/\/                                  4.c: (x3 * x4) + (x1 * x2)\n+\/\/\n+\/\/    Note: MulAddS2I with its 4 inputs is too complicated, if there is any mismatch, we always\n+\/\/          return PairOrderStatus::Unknown.\n+\/\/          Therefore, extend_pairset_with_more_pairs_by_following_use cannot extend to MulAddS2I,\n+\/\/          but there is a chance that extend_pairset_with_more_pairs_by_following_def can do it.\n+\/\/\n+SuperWord::PairOrderStatus SuperWord::order_inputs_of_uses_to_match_def_pair(Node* def1, Node* def2, Node* use1, Node* use2) {\n+  assert(_pairset.has_pair(def1, def2), \"(def1, def2) must be a pair\");\n+\n+  \/\/ 1. Reduction\n+  if (is_marked_reduction(use1) && is_marked_reduction(use2)) {\n+    Node* first = use1->in(2);\n@@ -1265,1 +1256,1 @@\n-      u1->swap_edges(1, 2);\n+      use1->swap_edges(1, 2);\n@@ -1267,2 +1258,1 @@\n-    \/\/ ensure reductions have phis and reduction definitions feeding the 1st operand\n-    first = u2->in(2);\n+    first = use2->in(2);\n@@ -1270,1 +1260,1 @@\n-      u2->swap_edges(1, 2);\n+      use2->swap_edges(1, 2);\n@@ -1272,1 +1262,1 @@\n-    return true;\n+    return PairOrderStatus::Ordered;\n@@ -1275,2 +1265,2 @@\n-  uint ct = u1->req();\n-  if (ct != u2->req()) return false;\n+  uint ct = use1->req();\n+  if (ct != use2->req()) { return PairOrderStatus::Unordered; };\n@@ -1280,2 +1270,2 @@\n-    for (i1++; i1 < ct; i1++) if (u1->in(i1) == d1) break;\n-    for (i2++; i2 < ct; i2++) if (u2->in(i2) == d2) break;\n+    for (i1++; i1 < ct; i1++) { if (use1->in(i1) == def1) { break; } }\n+    for (i2++; i2 < ct; i2++) { if (use2->in(i2) == def2) { break; } }\n@@ -1283,4 +1273,5 @@\n-      if ((i1 == (3-i2)) && (u2->is_Add() || u2->is_Mul())) {\n-        \/\/ Further analysis relies on operands position matching.\n-        u2->swap_edges(i1, i2);\n-      } else if (VectorNode::is_muladds2i(u2) && u1 != u2) {\n+      if ((i1 == (3-i2)) && (use2->is_Add() || use2->is_Mul())) {\n+        \/\/ 3. Add\/Mul: swap edges, and hope the other position matches too.\n+        use2->swap_edges(i1, i2);\n+      } else if (VectorNode::is_muladds2i(use2) && use1 != use2) {\n+        \/\/ 4.a\/b: MulAddS2I.\n@@ -1288,2 +1279,2 @@\n-          u2->swap_edges(1, 2);\n-          u2->swap_edges(3, 4);\n+          use2->swap_edges(1, 2);\n+          use2->swap_edges(3, 4);\n@@ -1292,2 +1283,2 @@\n-          u2->swap_edges(2, 3);\n-          u2->swap_edges(1, 4);\n+          use2->swap_edges(2, 3);\n+          use2->swap_edges(1, 4);\n@@ -1295,1 +1286,1 @@\n-        return false; \/\/ Just swap the edges, the muladds2i nodes get packed in follow_use_defs\n+        return PairOrderStatus::Unknown;\n@@ -1297,1 +1288,2 @@\n-        return false;\n+        \/\/ The inputs are not ordered, and we cannot do anything about it.\n+        return PairOrderStatus::Unordered;\n@@ -1299,4 +1291,5 @@\n-    } else if (i1 == i2 && VectorNode::is_muladds2i(u2) && u1 != u2) {\n-      u2->swap_edges(1, 3);\n-      u2->swap_edges(2, 4);\n-      return false; \/\/ Just swap the edges, the muladds2i nodes get packed in follow_use_defs\n+    } else if (i1 == i2 && VectorNode::is_muladds2i(use2) && use1 != use2) {\n+      \/\/ 4.c: MulAddS2I.\n+      use2->swap_edges(1, 3);\n+      use2->swap_edges(2, 4);\n+      return PairOrderStatus::Unknown;\n@@ -1305,1 +1298,3 @@\n-  return true;\n+\n+  \/\/ 2. All inputs match.\n+  return PairOrderStatus::Ordered;\n@@ -1308,3 +1303,2 @@\n-\/\/------------------------------est_savings---------------------------\n-\/\/ Estimate the savings from executing s1 and s2 as a pack\n-int SuperWord::est_savings(Node* s1, Node* s2) {\n+\/\/ Estimate the savings from executing s1 and s2 as a pair.\n+int SuperWord::estimate_cost_savings_when_packing_pair(const Node* s1, const Node* s2) const {\n@@ -1313,0 +1307,4 @@\n+  auto adjacent_profit = [&] (Node* s1, Node* s2) { return 2; };\n+  auto pack_cost       = [&] (int ct) { return ct; };\n+  auto unpack_cost     = [&] (int ct) { return ct; };\n+\n@@ -1320,1 +1318,1 @@\n-      } else if (!in_packset(x1, x2)) {\n+      } else if (!_pairset.has_pair(x1, x2)) {\n@@ -1332,12 +1330,11 @@\n-    Node* s1_use = s1->fast_out(i);\n-    for (int j = 0; j < _packset.length(); j++) {\n-      Node_List* p = _packset.at(j);\n-      if (p->at(0) == s1_use) {\n-        for (DUIterator_Fast kmax, k = s2->fast_outs(kmax); k < kmax; k++) {\n-          Node* s2_use = s2->fast_out(k);\n-          if (p->at(p->size()-1) == s2_use) {\n-            ct++;\n-            if (are_adjacent_refs(s1_use, s2_use)) {\n-              save_use += adjacent_profit(s1_use, s2_use);\n-            }\n-          }\n+    Node* use1 = s1->fast_out(i);\n+\n+    \/\/ Find pair (use1, use2)\n+    Node* use2 = _pairset.get_right_or_null_for(use1);\n+    if (use2 == nullptr) { continue; }\n+\n+    for (DUIterator_Fast kmax, k = s2->fast_outs(kmax); k < kmax; k++) {\n+      if (use2 == s2->fast_out(k)) {\n+        ct++;\n+        if (are_adjacent_refs(use1, use2)) {\n+          save_use += adjacent_profit(use1, use2);\n@@ -1355,6 +1352,1 @@\n-\/\/------------------------------costs---------------------------\n-int SuperWord::adjacent_profit(Node* s1, Node* s2) { return 2; }\n-int SuperWord::pack_cost(int ct)   { return ct; }\n-int SuperWord::unpack_cost(int ct) { return ct; }\n-\n-\/\/ Combine packs A and B with A.last == B.first into A.first..,A.last,B.second,..B.last\n+\/\/ Combine pairs (n1, n2), (n2, n3), ... into pack (n1, n2, n3 ...)\n@@ -1363,5 +1355,2 @@\n-  assert(!_packset.is_empty(), \"packset not empty\");\n-  for (int i = 0; i < _packset.length(); i++) {\n-    assert(_packset.at(i) != nullptr, \"no nullptr in packset\");\n-    assert(_packset.at(i)->size() == 2, \"all packs are pairs\");\n-  }\n+  assert(!_pairset.is_empty(), \"pairset not empty\");\n+  assert(_packset.is_empty(), \"packset not empty\");\n@@ -1370,19 +1359,13 @@\n-  bool changed = true;\n-  \/\/ Combine packs regardless max vector size.\n-  while (changed) {\n-    changed = false;\n-    for (int i = 0; i < _packset.length(); i++) {\n-      Node_List* p1 = _packset.at(i);\n-      if (p1 == nullptr) continue;\n-      \/\/ Because of sorting we can start at i + 1\n-      for (int j = i + 1; j < _packset.length(); j++) {\n-        Node_List* p2 = _packset.at(j);\n-        if (p2 == nullptr) continue;\n-        if (p1->at(p1->size()-1) == p2->at(0)) {\n-          for (uint k = 1; k < p2->size(); k++) {\n-            p1->push(p2->at(k));\n-          }\n-          _packset.at_put(j, nullptr);\n-          changed = true;\n-        }\n-      }\n+  \/\/ Iterate pair-chain by pair-chain, each from left-most to right-most.\n+  Node_List* pack = nullptr;\n+  for (PairSetIterator pair(_pairset); !pair.done(); pair.next()) {\n+    Node* s1 = pair.left();\n+    Node* s2 = pair.right();\n+    if (_pairset.is_left_in_a_left_most_pair(s1)) {\n+      pack = new (arena()) Node_List(arena());\n+      pack->push(s1);\n+    }\n+    pack->push(s2);\n+    if (_pairset.is_right_in_a_right_most_pair(s2)) {\n+      _packset.add_pack(pack);\n+      pack = nullptr;\n@@ -1391,3 +1374,1 @@\n-\n-  \/\/ Remove all nullptr from packset\n-  compress_packset();\n+  assert(pack == nullptr, \"finished the last pack\");\n@@ -1400,1 +1381,1 @@\n-    print_packset();\n+    _packset.print();\n@@ -1405,3 +1386,3 @@\n-SuperWord::SplitStatus SuperWord::split_pack(const char* split_name,\n-                                             Node_List* pack,\n-                                             SplitTask task)\n+SplitStatus PackSet::split_pack(const char* split_name,\n+                                Node_List* pack,\n+                                SplitTask task)\n@@ -1419,1 +1400,1 @@\n-        tty->print_cr(\"WARNING: Removed pack during split: %s:\", task.message());\n+        tty->print_cr(\"WARNING: Removed pack: %s:\", task.message());\n@@ -1425,1 +1406,1 @@\n-      set_my_pack(n, nullptr);\n+      set_pack(n, nullptr);\n@@ -1458,1 +1439,1 @@\n-      set_my_pack(n, nullptr);\n+      set_pack(n, nullptr);\n@@ -1467,1 +1448,1 @@\n-    set_my_pack(n, nullptr);\n+    set_pack(n, nullptr);\n@@ -1483,1 +1464,1 @@\n-    set_my_pack(n, nullptr);\n+    set_pack(n, nullptr);\n@@ -1501,1 +1482,1 @@\n-    set_my_pack(n, new_pack);\n+    set_pack(n, new_pack);\n@@ -1514,2 +1495,2 @@\n-void SuperWord::split_packs(const char* split_name,\n-                            SplitStrategy strategy) {\n+void PackSet::split_packs(const char* split_name,\n+                          SplitStrategy strategy) {\n@@ -1520,2 +1501,2 @@\n-    for (int i = 0; i < _packset.length(); i++) {\n-      Node_List* pack = _packset.at(i);\n+    for (int i = 0; i < _packs.length(); i++) {\n+      Node_List* pack = _packs.at(i);\n@@ -1528,1 +1509,1 @@\n-      _packset.at_put(i, nullptr); \/\/ take out pack\n+      _packs.at_put(i, nullptr); \/\/ take out pack\n@@ -1532,1 +1513,1 @@\n-        _packset.at_put(new_packset_length++, first_pack);\n+        _packs.at_put(new_packset_length++, first_pack);\n@@ -1536,1 +1517,1 @@\n-        _packset.append(second_pack);\n+        _packs.append(second_pack);\n@@ -1539,1 +1520,1 @@\n-    _packset.trunc_to(new_packset_length);\n+    _packs.trunc_to(new_packset_length);\n@@ -1545,1 +1526,1 @@\n-    print_packset();\n+    print();\n@@ -1552,10 +1533,10 @@\n-  split_packs(\"SuperWord::split_packs_at_use_def_boundaries\",\n-               [&](const Node_List* pack) {\n-                 uint pack_size = pack->size();\n-                 uint boundary = find_use_def_boundary(pack);\n-                 assert(boundary < pack_size, \"valid boundary %d\", boundary);\n-                 if (boundary != 0) {\n-                   return SplitTask::make_split(pack_size - boundary, \"found a use\/def boundary\");\n-                 }\n-                 return SplitTask::make_unchanged();\n-               });\n+  auto split_strategy = [&](const Node_List* pack) {\n+    uint pack_size = pack->size();\n+    uint boundary = find_use_def_boundary(pack);\n+    assert(boundary < pack_size, \"valid boundary %d\", boundary);\n+    if (boundary != 0) {\n+      return SplitTask::make_split(pack_size - boundary, \"found a use\/def boundary\");\n+    }\n+    return SplitTask::make_unchanged();\n+  };\n+  _packset.split_packs(\"SuperWord::split_packs_at_use_def_boundaries\", split_strategy);\n@@ -1567,13 +1548,13 @@\n-  split_packs(\"SuperWord::split_packs_only_implemented_with_smaller_size\",\n-               [&](const Node_List* pack) {\n-                 uint pack_size = pack->size();\n-                 uint implemented_size = max_implemented_size(pack);\n-                 if (implemented_size == 0)  {\n-                   return SplitTask::make_rejected(\"not implemented at any smaller size\");\n-                 }\n-                 assert(is_power_of_2(implemented_size), \"power of 2 size or zero: %d\", implemented_size);\n-                 if (implemented_size != pack_size) {\n-                   return SplitTask::make_split(implemented_size, \"only implemented at smaller size\");\n-                 }\n-                 return SplitTask::make_unchanged();\n-               });\n+  auto split_strategy = [&](const Node_List* pack) {\n+    uint pack_size = pack->size();\n+    uint implemented_size = max_implemented_size(pack);\n+    if (implemented_size == 0)  {\n+      return SplitTask::make_rejected(\"not implemented at any smaller size\");\n+    }\n+    assert(is_power_of_2(implemented_size), \"power of 2 size or zero: %d\", implemented_size);\n+    if (implemented_size != pack_size) {\n+      return SplitTask::make_split(implemented_size, \"only implemented at smaller size\");\n+    }\n+    return SplitTask::make_unchanged();\n+  };\n+  _packset.split_packs(\"SuperWord::split_packs_only_implemented_with_smaller_size\", split_strategy);\n@@ -1584,12 +1565,12 @@\n-  split_packs(\"SuperWord::split_packs_to_break_mutual_dependence\",\n-               [&](const Node_List* pack) {\n-                 uint pack_size = pack->size();\n-                 assert(is_power_of_2(pack_size), \"ensured by earlier splits %d\", pack_size);\n-                 if (!is_marked_reduction(pack->at(0)) &&\n-                     !mutually_independent(pack)) {\n-                   \/\/ As a best guess, we split the pack in half. This way, we iteratively make the\n-                   \/\/ packs smaller, until there is no dependency.\n-                   return SplitTask::make_split(pack_size >> 1, \"was not mutually independent\");\n-                 }\n-                 return SplitTask::make_unchanged();\n-               });\n+  auto split_strategy = [&](const Node_List* pack) {\n+    uint pack_size = pack->size();\n+    assert(is_power_of_2(pack_size), \"ensured by earlier splits %d\", pack_size);\n+    if (!is_marked_reduction(pack->at(0)) &&\n+        !mutually_independent(pack)) {\n+      \/\/ As a best guess, we split the pack in half. This way, we iteratively make the\n+      \/\/ packs smaller, until there is no dependency.\n+      return SplitTask::make_split(pack_size >> 1, \"was not mutually independent\");\n+    }\n+    return SplitTask::make_unchanged();\n+  };\n+  _packset.split_packs(\"SuperWord::split_packs_to_break_mutual_dependence\", split_strategy);\n@@ -1599,2 +1580,2 @@\n-void SuperWord::filter_packs(const char* filter_name,\n-                             const char* error_message,\n+void PackSet::filter_packs(const char* filter_name,\n+                             const char* rejection_message,\n@@ -1602,4 +1583,1 @@\n-  int new_packset_length = 0;\n-  for (int i = 0; i < _packset.length(); i++) {\n-    Node_List* pack = _packset.at(i);\n-    assert(pack != nullptr, \"no nullptr in packset\");\n+  auto split_strategy = [&](const Node_List* pack) {\n@@ -1607,2 +1585,1 @@\n-      assert(i >= new_packset_length, \"only move packs down\");\n-      _packset.at_put(new_packset_length++, pack);\n+      return SplitTask::make_unchanged();\n@@ -1610,8 +1587,1 @@\n-      remove_pack_at(i);\n-#ifndef PRODUCT\n-      if (is_trace_superword_rejections()) {\n-        tty->cr();\n-        tty->print_cr(\"WARNING: Removed pack: %s:\", error_message);\n-        print_pack(pack);\n-      }\n-#endif\n+      return SplitTask::make_rejected(rejection_message);\n@@ -1619,11 +1589,2 @@\n-  }\n-\n-  assert(_packset.length() >= new_packset_length, \"filter only reduces number of packs\");\n-  _packset.trunc_to(new_packset_length);\n-\n-#ifndef PRODUCT\n-  if (is_trace_superword_packset() && filter_name != nullptr) {\n-    tty->print_cr(\"\\nAfter %s:\", filter_name);\n-    print_packset();\n-  }\n-#endif\n+  };\n+  split_packs(filter_name, split_strategy);\n@@ -1633,5 +1594,5 @@\n-  filter_packs(\"SuperWord::filter_packs_for_power_of_2_size\",\n-               \"size is not a power of 2\",\n-               [&](const Node_List* pack) {\n-                 return is_power_of_2(pack->size());\n-               });\n+  auto filter = [&](const Node_List* pack) {\n+    return is_power_of_2(pack->size());\n+  };\n+  _packset.filter_packs(\"SuperWord::filter_packs_for_power_of_2_size\",\n+                        \"size is not a power of 2\", filter);\n@@ -1661,7 +1622,7 @@\n-  filter_packs(\"SuperWord::filter_packs_for_mutual_independence\",\n-               \"found dependency between nodes at distance greater than 1\",\n-               [&](const Node_List* pack) {\n-                 \/\/ reductions are trivially connected\n-                 return is_marked_reduction(pack->at(0)) ||\n-                        mutually_independent(pack);\n-               });\n+  auto filter = [&](const Node_List* pack) {\n+    \/\/ reductions are trivially connected\n+    return is_marked_reduction(pack->at(0)) ||\n+           mutually_independent(pack);\n+  };\n+  _packset.filter_packs(\"SuperWord::filter_packs_for_mutual_independence\",\n+                        \"found dependency between nodes at distance greater than 1\", filter);\n@@ -1716,8 +1677,6 @@\n-  filter_packs(\"SuperWord::filter_packs_for_alignment\",\n-               \"rejected by AlignVector (strict alignment requirement)\",\n-               [&](const Node_List* pack) {\n-                 \/\/ Only memops need to be aligned.\n-                 if (!pack->at(0)->is_Load() &&\n-                     !pack->at(0)->is_Store()) {\n-                   return true; \/\/ accept all non memops\n-                 }\n+  auto filter = [&](const Node_List* pack) {\n+    \/\/ Only memops need to be aligned.\n+    if (!pack->at(0)->is_Load() &&\n+        !pack->at(0)->is_Store()) {\n+      return true; \/\/ accept all non memops\n+    }\n@@ -1725,3 +1684,3 @@\n-                 mem_ops_count++;\n-                 const AlignmentSolution* s = pack_alignment_solution(pack);\n-                 const AlignmentSolution* intersect = current->filter(s);\n+    mem_ops_count++;\n+    const AlignmentSolution* s = pack_alignment_solution(pack);\n+    const AlignmentSolution* intersect = current->filter(s);\n@@ -1730,6 +1689,6 @@\n-                 if (is_trace_align_vector()) {\n-                   tty->print(\"  solution for pack:         \");\n-                   s->print();\n-                   tty->print(\"  intersection with current: \");\n-                   intersect->print();\n-                 }\n+    if (is_trace_align_vector()) {\n+      tty->print(\"  solution for pack:         \");\n+      s->print();\n+      tty->print(\"  intersection with current: \");\n+      intersect->print();\n+    }\n@@ -1737,4 +1696,4 @@\n-                 if (intersect->is_empty()) {\n-                   mem_ops_rejected++;\n-                   return false; \/\/ reject because of empty solution\n-                 }\n+    if (intersect->is_empty()) {\n+      mem_ops_rejected++;\n+      return false; \/\/ reject because of empty solution\n+    }\n@@ -1742,3 +1701,6 @@\n-                 current = intersect;\n-                 return true; \/\/ accept because of non-empty solution\n-               });\n+    current = intersect;\n+    return true; \/\/ accept because of non-empty solution\n+  };\n+\n+  _packset.filter_packs(\"SuperWord::filter_packs_for_alignment\",\n+                        \"rejected by AlignVector (strict alignment requirement)\", filter);\n@@ -1763,34 +1725,0 @@\n-\/\/ Compress packset, such that it has no nullptr entries\n-void SuperWord::compress_packset() {\n-  int j = 0;\n-  for (int i = 0; i < _packset.length(); i++) {\n-    Node_List* p = _packset.at(i);\n-    if (p != nullptr) {\n-      _packset.at_put(j, p);\n-      j++;\n-    }\n-  }\n-  _packset.trunc_to(j);\n-}\n-\n-\/\/-----------------------------construct_my_pack_map--------------------------\n-\/\/ Construct the map from nodes to packs.  Only valid after the\n-\/\/ point where a node is only in one pack (after combine_pairs_to_longer_packs).\n-void SuperWord::construct_my_pack_map() {\n-  for (int i = 0; i < _packset.length(); i++) {\n-    Node_List* p = _packset.at(i);\n-    for (uint j = 0; j < p->size(); j++) {\n-      Node* s = p->at(j);\n-#ifdef ASSERT\n-      if (my_pack(s) != nullptr) {\n-        s->dump(1);\n-        tty->print_cr(\"packs[%d]:\", i);\n-        print_pack(p);\n-        assert(false, \"only in one pack\");\n-      }\n-#endif\n-      set_my_pack(s, p);\n-    }\n-  }\n-}\n-\n@@ -1799,5 +1727,5 @@\n-  filter_packs(\"SuperWord::filter_packs_for_implemented\",\n-               \"Unimplemented\",\n-               [&](const Node_List* pack) {\n-                 return implemented(pack, pack->size());\n-               });\n+  auto filter = [&](const Node_List* pack) {\n+    return implemented(pack, pack->size());\n+  };\n+  _packset.filter_packs(\"SuperWord::filter_packs_for_implemented\",\n+                        \"Unimplemented\", filter);\n@@ -1821,20 +1749,5 @@\n-  while (true) {\n-    int old_packset_length = _packset.length();\n-    filter_packs(nullptr, \/\/ don't dump each time\n-                 \"not profitable\",\n-                 [&](const Node_List* pack) {\n-                   return profitable(pack);\n-                 });\n-    \/\/ Repeat until stable\n-    if (old_packset_length == _packset.length()) {\n-      break;\n-    }\n-  }\n-\n-#ifndef PRODUCT\n-  if (is_trace_superword_packset()) {\n-    tty->print_cr(\"\\nAfter Superword::filter_packs_for_profitable\");\n-    print_packset();\n-    tty->cr();\n-  }\n-#endif\n+  auto filter = [&](const Node_List* pack) {\n+    return profitable(pack);\n+  };\n+  _packset.filter_packs(\"Superword::filter_packs_for_profitable\",\n+                        \"not profitable\", filter);\n@@ -1844,1 +1757,1 @@\n-bool SuperWord::implemented(const Node_List* pack, uint size) {\n+bool SuperWord::implemented(const Node_List* pack, uint size) const {\n@@ -1920,1 +1833,1 @@\n-bool SuperWord::same_inputs(const Node_List* p, int idx) {\n+bool SuperWord::same_inputs(const Node_List* p, int idx) const {\n@@ -1936,1 +1849,1 @@\n-bool SuperWord::profitable(const Node_List* p) {\n+bool SuperWord::profitable(const Node_List* p) const {\n@@ -1954,1 +1867,1 @@\n-    Node_List* second_pk = my_pack(second_in);\n+    Node_List* second_pk = _packset.pack(second_in);\n@@ -1967,1 +1880,1 @@\n-    Node_List* cnt_pk = my_pack(cnt);\n+    Node_List* cnt_pk = _packset.pack(cnt);\n@@ -2020,1 +1933,1 @@\n-    if (bol == nullptr || my_pack(bol) == nullptr) {\n+    if (bol == nullptr || _packset.pack(bol) == nullptr) {\n@@ -2025,1 +1938,1 @@\n-    if (cmp == nullptr || my_pack(cmp) == nullptr) {\n+    if (cmp == nullptr || _packset.pack(cmp) == nullptr) {\n@@ -2033,2 +1946,4 @@\n-void SuperWord::verify_packs() {\n-  \/\/ Verify independence at pack level.\n+void SuperWord::verify_packs() const {\n+  _packset.verify();\n+\n+  \/\/ All packs must be:\n@@ -2036,3 +1951,5 @@\n-    Node_List* p = _packset.at(i);\n-    if (!is_marked_reduction(p->at(0)) &&\n-        !mutually_independent(p)) {\n+    Node_List* pack = _packset.at(i);\n+\n+    \/\/ 1. Mutually independent (or a reduction).\n+    if (!is_marked_reduction(pack->at(0)) &&\n+        !mutually_independent(pack)) {\n@@ -2040,1 +1957,1 @@\n-      print_pack(p);\n+      _packset.print_pack(pack);\n@@ -2043,0 +1960,14 @@\n+\n+    \/\/ 2. Implemented.\n+    if (!implemented(pack, pack->size())) {\n+      tty->print_cr(\"FAILURE: nodes not implementable in pack[%d]\", i);\n+      _packset.print_pack(pack);\n+      assert(false, \"pack not implementable\");\n+    }\n+\n+    \/\/ 3. Profitable.\n+    if (!profitable(pack)) {\n+      tty->print_cr(\"FAILURE: nodes not profitable in pack[%d]\", i);\n+      _packset.print_pack(pack);\n+      assert(false, \"pack not profitable\");\n+    }\n@@ -2044,0 +1975,1 @@\n+}\n@@ -2045,1 +1977,2 @@\n-  \/\/ Verify all nodes in packset have my_pack set correctly.\n+void PackSet::verify() const {\n+  \/\/ Verify all nodes in packset have pack set correctly.\n@@ -2048,2 +1981,2 @@\n-  for (int i = 0; i < _packset.length(); i++) {\n-    Node_List* p = _packset.at(i);\n+  for (int i = 0; i < _packs.length(); i++) {\n+    Node_List* p = _packs.at(i);\n@@ -2052,1 +1985,1 @@\n-      assert(in_bb(n), \"only nodes in bb can be in packset\");\n+      assert(_vloop.in_bb(n), \"only nodes in bb can be in packset\");\n@@ -2054,1 +1987,1 @@\n-      assert(my_pack(n) == p, \"n has consisten packset info\");\n+      assert(pack(n) == p, \"n has consisten packset info\");\n@@ -2059,3 +1992,3 @@\n-  \/\/ Check that no other node has my_pack set.\n-  for (int i = 0; i < body().length(); i++) {\n-    Node* n = body().at(i);\n+  \/\/ Check that no other node has pack set.\n+  for (int i = 0; i < _body.body().length(); i++) {\n+    Node* n = _body.body().at(i);\n@@ -2063,1 +1996,1 @@\n-      assert(my_pack(n) == nullptr, \"should not have pack if not in packset\");\n+      assert(pack(n) == nullptr, \"should not have pack if not in packset\");\n@@ -2090,1 +2023,1 @@\n-  GrowableArray<Node*> _pid_to_node;       \/\/ one node per pid, find rest via my_pack\n+  GrowableArray<Node*> _pid_to_node;       \/\/ one node per pid, find rest via _packset.pack\n@@ -2144,1 +2077,1 @@\n-    const GrowableArray<Node_List*>& packset = _slp->packset();\n+    const PackSet& packset = _slp->packset();\n@@ -2153,1 +2086,1 @@\n-        assert(_slp->my_pack(n) == p, \"matching packset\");\n+        assert(packset.pack(n) == p, \"matching packset\");\n@@ -2169,1 +2102,1 @@\n-        assert(_slp->my_pack(n) == nullptr, \"no packset\");\n+        assert(packset.pack(n) == nullptr, \"no packset\");\n@@ -2235,1 +2168,1 @@\n-      Node_List* p = _slp->my_pack(n);\n+      Node_List* p = _slp->packset().pack(n);\n@@ -2443,1 +2376,1 @@\n-  if (_packset.length() == 0) {\n+  if (_packset.is_empty()) {\n@@ -2464,1 +2397,1 @@\n-    Node_List* p = my_pack(n);\n+    Node_List* p = _packset.pack(n);\n@@ -2554,1 +2487,1 @@\n-        Node_List* p_bol = my_pack(bol);\n+        Node_List* p_bol = _packset.pack(bol);\n@@ -2567,1 +2500,1 @@\n-        Node_List* p_cmp = my_pack(cmp);\n+        Node_List* p_cmp = _packset.pack(cmp);\n@@ -2886,1 +2819,1 @@\n-    if (my_pack(in) != nullptr) {\n+    if (_packset.pack(in) != nullptr) {\n@@ -2894,1 +2827,1 @@\n-      if (my_pack(in2) != nullptr) {\n+      if (_packset.pack(in2) != nullptr) {\n@@ -2927,1 +2860,1 @@\n-            Node_List* p_use = my_pack(use);\n+            Node_List* p_use = _packset.pack(use);\n@@ -2940,2 +2873,2 @@\n-  Node_List* pack = my_pack(n_super);\n-  assert(pack != nullptr && pack == my_pack(n_sub), \"must have the same pack\");\n+  Node_List* pack = _packset.pack(n_super);\n+  assert(pack != nullptr && pack == _packset.pack(n_sub), \"must have the same pack\");\n@@ -2946,1 +2879,1 @@\n-    Node_List* pack_use_sub = my_pack(use_sub);\n+    Node_List* pack_use_sub = _packset.pack(use_sub);\n@@ -2959,1 +2892,1 @@\n-        Node_List* pack_use_super = my_pack(use_super);\n+        Node_List* pack_use_super = _packset.pack(use_super);\n@@ -3008,1 +2941,1 @@\n-      if (my_pack(n0_in) != my_pack(n1_in) &&\n+      if (_packset.pack(n0_in) != _packset.pack(n1_in) &&\n@@ -3028,2 +2961,2 @@\n-bool SuperWord::is_vector_use(Node* use, int u_idx) {\n-  Node_List* u_pk = my_pack(use);\n+bool SuperWord::is_vector_use(Node* use, int u_idx) const {\n+  Node_List* u_pk = _packset.pack(use);\n@@ -3033,1 +2966,1 @@\n-  Node_List* d_pk = my_pack(def);\n+  Node_List* d_pk = _packset.pack(def);\n@@ -3216,1 +3149,1 @@\n-BasicType SuperWord::longer_type_for_conversion(Node* n) {\n+BasicType SuperWord::longer_type_for_conversion(Node* n) const {\n@@ -3430,43 +3363,0 @@\n-\/\/------------------------------in_packset---------------------------\n-\/\/ Are s1 and s2 in a pack pair and ordered as s1,s2?\n-bool SuperWord::in_packset(Node* s1, Node* s2) {\n-  for (int i = 0; i < _packset.length(); i++) {\n-    Node_List* p = _packset.at(i);\n-    assert(p->size() == 2, \"must be\");\n-    if (p->at(0) == s1 && p->at(p->size()-1) == s2) {\n-      return true;\n-    }\n-  }\n-  return false;\n-}\n-\n-\/\/------------------------------remove_pack_at---------------------------\n-\/\/ Remove the pack at position pos in the packset\n-void SuperWord::remove_pack_at(int pos) {\n-  Node_List* p = _packset.at(pos);\n-  for (uint i = 0; i < p->size(); i++) {\n-    Node* s = p->at(i);\n-    set_my_pack(s, nullptr);\n-  }\n-  _packset.at_put(pos, nullptr);\n-}\n-\n-void SuperWord::packset_sort(int n) {\n-  \/\/ simple bubble sort so that we capitalize with O(n) when its already sorted\n-  do {\n-    int max_swap_index = 0;\n-    for (int i = 1; i < n; i++) {\n-      Node_List* q_low = _packset.at(i-1);\n-      Node_List* q_i = _packset.at(i);\n-\n-      \/\/ only swap when we find something to swap\n-      if (alignment(q_low->at(0)) > alignment(q_i->at(0))) {\n-        *(_packset.adr_at(i)) = q_low;\n-        *(_packset.adr_at(i-1)) = q_i;\n-        max_swap_index = i;\n-      }\n-    }\n-    n = max_swap_index;\n-  } while (n > 1);\n-}\n-\n@@ -3825,2 +3715,0 @@\n-\/\/------------------------------print_packset---------------------------\n-void SuperWord::print_packset() {\n@@ -3828,5 +3716,24 @@\n-  tty->print_cr(\"packset\");\n-  for (int i = 0; i < _packset.length(); i++) {\n-    tty->print_cr(\"Pack: %d\", i);\n-    Node_List* p = _packset.at(i);\n-    if (p == nullptr) {\n+void PairSet::print() const {\n+  tty->print_cr(\"\\nPairSet::print: %d pairs\", length());\n+  int chain = 0;\n+  int chain_index = 0;\n+  for (PairSetIterator pair(*this); !pair.done(); pair.next()) {\n+    Node* n1 = pair.left();\n+    Node* n2 = pair.right();\n+    if (is_left_in_a_left_most_pair(n1)) {\n+      chain_index = 0;\n+      tty->print_cr(\" Pair-chain %d:\", chain++);\n+      tty->print(\"  %3d: \", chain_index++);\n+      n1->dump();\n+    }\n+    tty->print(\"  %3d: \", chain_index++);\n+    n2->dump();\n+  }\n+}\n+\n+void PackSet::print() const {\n+  tty->print_cr(\"\\nPackSet::print: %d packs\", _packs.length());\n+  for (int i = 0; i < _packs.length(); i++) {\n+    tty->print_cr(\" Pack: %d\", i);\n+    Node_List* pack = _packs.at(i);\n+    if (pack == nullptr) {\n@@ -3835,1 +3742,1 @@\n-      print_pack(p);\n+      print_pack(pack);\n@@ -3838,1 +3745,0 @@\n-#endif\n@@ -3841,4 +3747,4 @@\n-\/\/------------------------------print_pack---------------------------\n-void SuperWord::print_pack(Node_List* p) {\n-  for (uint i = 0; i < p->size(); i++) {\n-    print_stmt(p->at(i));\n+void PackSet::print_pack(Node_List* pack) const {\n+  for (uint i = 0; i < pack->size(); i++) {\n+    tty->print(\"  %3d: \", i);\n+    pack->at(i)->dump();\n@@ -3847,0 +3753,1 @@\n+#endif\n@@ -3861,8 +3768,0 @@\n-\/\/------------------------------print_stmt---------------------------\n-void SuperWord::print_stmt(Node* s) {\n-#ifndef PRODUCT\n-  tty->print(\" align: %d \\t\", alignment(s));\n-  s->dump();\n-#endif\n-}\n-\n","filename":"src\/hotspot\/share\/opto\/superword.cpp","additions":367,"deletions":468,"binary":false,"changes":835,"status":"modified"},{"patch":"@@ -60,0 +60,266 @@\n+\/\/ The PairSet is a set of pairs. These are later combined to packs,\n+\/\/ and stored in the PackSet.\n+class PairSet : public StackObj {\n+private:\n+  const VLoop& _vloop;\n+  const VLoopBody& _body;\n+\n+  \/\/ Doubly-linked pairs. If not linked: -1\n+  GrowableArray<int> _left_to_right; \/\/ bb_idx -> bb_idx\n+  GrowableArray<int> _right_to_left; \/\/ bb_idx -> bb_idx\n+\n+  \/\/ List of all left elements bb_idx, in the order of pair addition.\n+  GrowableArray<int> _lefts_in_insertion_order;\n+\n+public:\n+  \/\/ Initialize empty, i.e. all not linked (-1).\n+  PairSet(Arena* arena, const VLoopAnalyzer& vloop_analyzer) :\n+    _vloop(vloop_analyzer.vloop()),\n+    _body(vloop_analyzer.body()),\n+    _left_to_right(arena, _body.body().length(), _body.body().length(), -1),\n+    _right_to_left(arena, _body.body().length(), _body.body().length(), -1),\n+    _lefts_in_insertion_order(arena, 8, 0, 0) {}\n+\n+  const VLoopBody& body() const { return _body; }\n+  bool is_empty() const { return _lefts_in_insertion_order.is_empty(); }\n+  bool has_left(int i)  const { return _left_to_right.at(i) != -1; }\n+  bool has_right(int i) const { return _right_to_left.at(i) != -1; }\n+  bool has_left(const Node* n)  const { return _vloop.in_bb(n) && has_left( _body.bb_idx(n)); }\n+  bool has_right(const Node* n) const { return _vloop.in_bb(n) && has_right(_body.bb_idx(n)); }\n+  bool has_pair(const Node* n1, const Node* n2) const { return has_left(n1) && get_right_for(n1) == n2; }\n+  bool is_left_in_a_left_most_pair(int i)   const { return has_left(i) && !has_right(i); }\n+  bool is_right_in_a_right_most_pair(int i) const { return !has_left(i) && has_right(i); }\n+  bool is_left_in_a_left_most_pair(const Node* n)   const { return is_left_in_a_left_most_pair( _body.bb_idx(n)); }\n+  bool is_right_in_a_right_most_pair(const Node* n) const { return is_right_in_a_right_most_pair(_body.bb_idx(n)); }\n+  int get_right_for(int i) const { return _left_to_right.at(i); }\n+  Node* get_right_for(const Node* n) const { return _body.body().at(get_right_for(_body.bb_idx(n))); }\n+  Node* get_right_or_null_for(const Node* n) const { return has_left(n) ? get_right_for(n) : nullptr; }\n+\n+  \/\/ To access elements in insertion order:\n+  int length() const { return _lefts_in_insertion_order.length(); }\n+  Node* left_at(int i)  const { return _body.body().at(_lefts_in_insertion_order.at(i)); }\n+  Node* right_at(int i) const { return _body.body().at(get_right_for(_lefts_in_insertion_order.at(i))); }\n+\n+  void add_pair(Node* n1, Node* n2) {\n+    assert(n1 != nullptr && n2 != nullptr && n1 != n2, \"no nullptr, and different nodes\");\n+    assert(!has_left(n1) && !has_right(n2), \"cannot be left twice, or right twice\");\n+    int bb_idx_1 = _body.bb_idx(n1);\n+    int bb_idx_2 = _body.bb_idx(n2);\n+    _left_to_right.at_put(bb_idx_1, bb_idx_2);\n+    _right_to_left.at_put(bb_idx_2, bb_idx_1);\n+    _lefts_in_insertion_order.append(bb_idx_1);\n+    assert(has_left(n1) && has_right(n2), \"must be set now\");\n+  }\n+\n+  NOT_PRODUCT(void print() const;)\n+};\n+\n+\/\/ Iterate over the PairSet, pair-chain by pair-chain.\n+\/\/ A pair-chain starts with a \"left-most\" pair (n1, n2), where n1 is never a right-element\n+\/\/ in any pair. We walk a chain: (n2, n3), (n3, n4) ... until we hit a \"right-most\" pair\n+\/\/ where the right-element is never a left-element of any pair.\n+\/\/ These pair-chains will later be combined into packs by combine_pairs_to_longer_packs.\n+class PairSetIterator : public StackObj {\n+private:\n+  const PairSet& _pairset;\n+  const VLoopBody& _body;\n+\n+  int _chain_start_bb_idx; \/\/ bb_idx of left-element in the left-most pair.\n+  int _current_bb_idx;     \/\/ bb_idx of left-element of the current pair.\n+  const int _end_bb_idx;\n+\n+public:\n+  PairSetIterator(const PairSet& pairset) :\n+    _pairset(pairset), _body(pairset.body()),\n+    _chain_start_bb_idx(-1), _current_bb_idx(-1),\n+    _end_bb_idx(_body.body().length())\n+  {\n+    next_chain();\n+  }\n+\n+  bool done() const { return _chain_start_bb_idx >= _end_bb_idx; }\n+\n+  Node* left() const {\n+    return _body.body().at(_current_bb_idx);\n+  }\n+\n+  Node* right() const {\n+    int bb_idx_2 = _pairset.get_right_for(_current_bb_idx);\n+    return _body.body().at(bb_idx_2);\n+  }\n+\n+  \/\/ Try to keep walking on the current pair-chain, else find a new pair-chain.\n+  void next() {\n+    assert(_pairset.has_left(_current_bb_idx), \"current was valid\");\n+    _current_bb_idx = _pairset.get_right_for(_current_bb_idx);\n+    if (!_pairset.has_left(_current_bb_idx)) {\n+      next_chain();\n+    }\n+  }\n+\n+private:\n+  void next_chain() {\n+    do {\n+      _chain_start_bb_idx++;\n+    } while (!done() && !_pairset.is_left_in_a_left_most_pair(_chain_start_bb_idx));\n+    _current_bb_idx = _chain_start_bb_idx;\n+  }\n+};\n+\n+class SplitTask {\n+private:\n+  enum Kind {\n+    \/\/ The lambda method for split_packs can return one of these tasks:\n+    Unchanged, \/\/ The pack is left in the packset, unchanged.\n+    Rejected,  \/\/ The pack is removed from the packset.\n+    Split,     \/\/ Split away split_size nodes from the end of the pack.\n+  };\n+  const Kind _kind;\n+  const uint _split_size;\n+  const char* _message;\n+\n+  SplitTask(const Kind kind, const uint split_size, const char* message) :\n+      _kind(kind), _split_size(split_size), _message(message)\n+  {\n+    assert(message != nullptr, \"must have message\");\n+    assert(_kind != Unchanged || split_size == 0, \"unchanged task conditions\");\n+    assert(_kind != Rejected  || split_size == 0, \"reject task conditions\");\n+    assert(_kind != Split     || split_size != 0, \"split task conditions\");\n+  }\n+\n+public:\n+  static SplitTask make_split(const uint split_size, const char* message) {\n+    return SplitTask(Split, split_size, message);\n+  }\n+\n+  static SplitTask make_unchanged() {\n+    return SplitTask(Unchanged, 0, \"unchanged\");\n+  }\n+\n+  static SplitTask make_rejected(const char* message) {\n+    return SplitTask(Rejected, 0, message);\n+  }\n+\n+  bool is_unchanged() const { return _kind == Unchanged; }\n+  bool is_rejected() const { return _kind == Rejected; }\n+  bool is_split() const { return _kind == Split; }\n+  const char* message() const { return _message; }\n+\n+  uint split_size() const {\n+    assert(is_split(), \"only split tasks have split_size\");\n+    return _split_size;\n+  }\n+};\n+\n+class SplitStatus {\n+private:\n+  enum Kind {\n+    \/\/ After split_pack, we have:                              first_pack   second_pack\n+    Unchanged, \/\/ The pack is left in the pack, unchanged.     old_pack     nullptr\n+    Rejected,  \/\/ The pack is removed from the packset.        nullptr      nullptr\n+    Modified,  \/\/ The pack had some nodes removed.             old_pack     nullptr\n+    Split,     \/\/ The pack was split into two packs.           pack1        pack2\n+  };\n+  Kind _kind;\n+  Node_List* _first_pack;\n+  Node_List* _second_pack;\n+\n+  SplitStatus(Kind kind, Node_List* first_pack, Node_List* second_pack) :\n+    _kind(kind), _first_pack(first_pack), _second_pack(second_pack)\n+  {\n+    assert(_kind != Unchanged || (first_pack != nullptr && second_pack == nullptr), \"unchanged status conditions\");\n+    assert(_kind != Rejected  || (first_pack == nullptr && second_pack == nullptr), \"rejected status conditions\");\n+    assert(_kind != Modified  || (first_pack != nullptr && second_pack == nullptr), \"modified status conditions\");\n+    assert(_kind != Split     || (first_pack != nullptr && second_pack != nullptr), \"split status conditions\");\n+  }\n+\n+public:\n+  static SplitStatus make_unchanged(Node_List* old_pack) {\n+    return SplitStatus(Unchanged, old_pack, nullptr);\n+  }\n+\n+  static SplitStatus make_rejected() {\n+    return SplitStatus(Rejected, nullptr, nullptr);\n+  }\n+\n+  static SplitStatus make_modified(Node_List* first_pack) {\n+    return SplitStatus(Modified, first_pack, nullptr);\n+  }\n+\n+  static SplitStatus make_split(Node_List* first_pack, Node_List* second_pack) {\n+    return SplitStatus(Split, first_pack, second_pack);\n+  }\n+\n+  bool is_unchanged() const { return _kind == Unchanged; }\n+  Node_List* first_pack() const { return _first_pack; }\n+  Node_List* second_pack() const { return _second_pack; }\n+};\n+\n+class PackSet : public StackObj {\n+private:\n+  const VLoop& _vloop;\n+  const VLoopBody& _body;\n+\n+  \/\/ The \"packset\" proper: an array of \"packs\"\n+  GrowableArray<Node_List*> _packs;\n+\n+  \/\/ Mapping from nodes to their pack: bb_idx -> pack\n+  GrowableArray<Node_List*> _node_to_pack;\n+\n+  NOT_PRODUCT(const bool _trace_packset;)\n+  NOT_PRODUCT(const bool _trace_rejections;)\n+\n+public:\n+  \/\/ Initialize empty, i.e. no packs, and unmapped (nullptr).\n+  PackSet(Arena* arena, const VLoopAnalyzer& vloop_analyzer\n+          NOT_PRODUCT(COMMA bool trace_packset COMMA bool trace_rejections)\n+          ) :\n+    _vloop(vloop_analyzer.vloop()),\n+    _body(vloop_analyzer.body()),\n+    _packs(arena, 8, 0, nullptr),\n+    _node_to_pack(arena, _body.body().length(), _body.body().length(), nullptr)\n+    NOT_PRODUCT(COMMA _trace_packset(trace_packset))\n+    NOT_PRODUCT(COMMA _trace_rejections(trace_rejections))\n+    {}\n+\n+  \/\/ Accessors to iterate over packs.\n+  int length() const { return _packs.length(); }\n+  bool is_empty() const { return _packs.is_empty(); }\n+  Node_List* at(int i) const { return _packs.at(i); }\n+\n+private:\n+  void set_pack(const Node* n, Node_List* pack) { _node_to_pack.at_put(_body.bb_idx(n), pack); }\n+public:\n+  Node_List* pack(const Node* n) const { return !_vloop.in_bb(n) ? nullptr : _node_to_pack.at(_body.bb_idx(n)); }\n+\n+  void add_pack(Node_List* pack) {\n+    _packs.append(pack);\n+    for (uint i = 0; i < pack->size(); i++) {\n+      Node* n = pack->at(i);\n+      assert(this->pack(n) == nullptr, \"not yet in a pack\");\n+      set_pack(n, pack);\n+    }\n+  }\n+\n+private:\n+  SplitStatus split_pack(const char* split_name, Node_List* pack, SplitTask task);\n+public:\n+  template <typename SplitStrategy>\n+  void split_packs(const char* split_name, SplitStrategy strategy);\n+\n+  template <typename FilterPredicate>\n+  void filter_packs(const char* filter_name,\n+                    const char* rejection_message,\n+                    FilterPredicate filter);\n+\n+  void clear() { _packs.clear(); }\n+\n+private:\n+  NOT_PRODUCT(bool is_trace_superword_packset() const { return _trace_packset; })\n+  NOT_PRODUCT(bool is_trace_superword_rejections() const { return _trace_rejections; })\n+public:\n+  DEBUG_ONLY(void verify() const;)\n+  NOT_PRODUCT(void print() const;)\n+  NOT_PRODUCT(void print_pack(Node_List* pack) const;)\n+};\n+\n@@ -67,1 +333,0 @@\n-  Node_List*  _my_pack;   \/\/ pack containing this node\n@@ -69,1 +334,1 @@\n-  SWNodeInfo() : _alignment(-1), _my_pack(nullptr) {}\n+  SWNodeInfo() : _alignment(-1) {}\n@@ -86,2 +351,0 @@\n-  GrowableArray<Node_List*> _packset;    \/\/ Packs for the current block\n-\n@@ -92,0 +355,3 @@\n+  PairSet _pairset;\n+  PackSet _packset;\n+\n@@ -115,1 +381,1 @@\n-  bool reduction(Node* n1, Node* n2) const {\n+  bool reduction(const Node* n1, const Node* n2) const {\n@@ -222,1 +488,1 @@\n-  const GrowableArray<Node_List*>& packset() const { return _packset; }\n+  const PackSet& packset()   const { return _packset; }\n@@ -224,1 +490,0 @@\n-  bool           _race_possible;   \/\/ In cases where SDMU is true\n@@ -243,1 +508,1 @@\n-  int alignment(Node* n)                     { return _node_info.adr_at(bb_idx(n))->_alignment; }\n+  int alignment(Node* n) const               { return _node_info.adr_at(bb_idx(n))->_alignment; }\n@@ -246,5 +511,0 @@\n-  \/\/ my_pack\n- public:\n-  Node_List* my_pack(const Node* n)     const { return !in_bb(n) ? nullptr : _node_info.adr_at(bb_idx(n))->_my_pack; }\n- private:\n-  void set_my_pack(Node* n, Node_List* p)     { int i = bb_idx(n); grow_node_info(i); _node_info.adr_at(i)->_my_pack = p; }\n@@ -254,1 +514,1 @@\n-  bool same_inputs(const Node_List* p, int idx);\n+  bool same_inputs(const Node_List* p, int idx) const;\n@@ -270,2 +530,0 @@\n-  \/\/ Does s exist in a pack at position pos?\n-  bool exists_at(Node* s, uint pos);\n@@ -273,1 +531,1 @@\n-  bool are_adjacent_refs(Node* s1, Node* s2);\n+  bool are_adjacent_refs(Node* s1, Node* s2) const;\n@@ -282,2 +540,0 @@\n-  \/\/ Extend packset by following use->def and def->use links from pack members.\n-  void extend_packset_with_more_pairs_by_following_use_and_def();\n@@ -285,94 +541,0 @@\n-  \/\/ Extend the packset by visiting operand definitions of nodes in pack p\n-  bool follow_use_defs(Node_List* p);\n-  \/\/ Extend the packset by visiting uses of nodes in pack p\n-  bool follow_def_uses(Node_List* p);\n-  \/\/ For extended packsets, ordinally arrange uses packset by major component\n-  void order_def_uses(Node_List* p);\n-  \/\/ Estimate the savings from executing s1 and s2 as a pack\n-  int est_savings(Node* s1, Node* s2);\n-  int adjacent_profit(Node* s1, Node* s2);\n-  int pack_cost(int ct);\n-  int unpack_cost(int ct);\n-\n-  \/\/ Combine packs A and B with A.last == B.first into A.first..,A.last,B.second,..B.last\n-  void combine_pairs_to_longer_packs();\n-\n-  class SplitTask {\n-  private:\n-    enum Kind {\n-      \/\/ The lambda method for split_packs can return one of these tasks:\n-      Unchanged, \/\/ The pack is left in the packset, unchanged.\n-      Rejected,  \/\/ The pack is removed from the packset.\n-      Split,     \/\/ Split away split_size nodes from the end of the pack.\n-    };\n-    const Kind _kind;\n-    const uint _split_size;\n-    const char* _message;\n-\n-    SplitTask(const Kind kind, const uint split_size, const char* message) :\n-        _kind(kind), _split_size(split_size), _message(message)\n-    {\n-      assert(message != nullptr, \"must have message\");\n-      assert(_kind != Unchanged || split_size == 0, \"unchanged task conditions\");\n-      assert(_kind != Rejected  || split_size == 0, \"reject task conditions\");\n-      assert(_kind != Split     || split_size != 0, \"split task conditions\");\n-    }\n-\n-  public:\n-    static SplitTask make_split(const uint split_size, const char* message) {\n-      return SplitTask(Split, split_size, message);\n-    }\n-\n-    static SplitTask make_unchanged() {\n-      return SplitTask(Unchanged, 0, \"unchanged\");\n-    }\n-\n-    static SplitTask make_rejected(const char* message) {\n-      return SplitTask(Rejected, 0, message);\n-    }\n-\n-    bool is_unchanged() const { return _kind == Unchanged; }\n-    bool is_rejected() const { return _kind == Rejected; }\n-    bool is_split() const { return _kind == Split; }\n-    const char* message() const { return _message; }\n-\n-    uint split_size() const {\n-      assert(is_split(), \"only split tasks have split_size\");\n-      return _split_size;\n-    }\n-  };\n-\n-  class SplitStatus {\n-  private:\n-    enum Kind {\n-      \/\/ After split_pack, we have:                              first_pack   second_pack\n-      Unchanged, \/\/ The pack is left in the pack, unchanged.     old_pack     nullptr\n-      Rejected,  \/\/ The pack is removed from the packset.        nullptr      nullptr\n-      Modified,  \/\/ The pack had some nodes removed.             old_pack     nullptr\n-      Split,     \/\/ The pack was split into two packs.           pack1        pack2\n-    };\n-    Kind _kind;\n-    Node_List* _first_pack;\n-    Node_List* _second_pack;\n-\n-    SplitStatus(Kind kind, Node_List* first_pack, Node_List* second_pack) :\n-      _kind(kind), _first_pack(first_pack), _second_pack(second_pack)\n-    {\n-      assert(_kind != Unchanged || (first_pack != nullptr && second_pack == nullptr), \"unchanged status conditions\");\n-      assert(_kind != Rejected  || (first_pack == nullptr && second_pack == nullptr), \"rejected status conditions\");\n-      assert(_kind != Modified  || (first_pack != nullptr && second_pack == nullptr), \"modified status conditions\");\n-      assert(_kind != Split     || (first_pack != nullptr && second_pack != nullptr), \"split status conditions\");\n-    }\n-\n-  public:\n-    static SplitStatus make_unchanged(Node_List* old_pack) {\n-      return SplitStatus(Unchanged, old_pack, nullptr);\n-    }\n-\n-    static SplitStatus make_rejected() {\n-      return SplitStatus(Rejected, nullptr, nullptr);\n-    }\n-\n-    static SplitStatus make_modified(Node_List* first_pack) {\n-      return SplitStatus(Modified, first_pack, nullptr);\n-    }\n@@ -380,3 +542,7 @@\n-    static SplitStatus make_split(Node_List* first_pack, Node_List* second_pack) {\n-      return SplitStatus(Split, first_pack, second_pack);\n-    }\n+  void extend_pairset_with_more_pairs_by_following_use_and_def();\n+  bool extend_pairset_with_more_pairs_by_following_def(Node* s1, Node* s2);\n+  bool extend_pairset_with_more_pairs_by_following_use(Node* s1, Node* s2);\n+  void order_inputs_of_all_use_pairs_to_match_def_pair(Node* def1, Node* def2);\n+  enum PairOrderStatus { Ordered, Unordered, Unknown };\n+  PairOrderStatus order_inputs_of_uses_to_match_def_pair(Node* def1, Node* def2, Node* use1, Node* use2);\n+  int estimate_cost_savings_when_packing_pair(const Node* s1, const Node* s2) const;\n@@ -384,8 +550,1 @@\n-    bool is_unchanged() const { return _kind == Unchanged; }\n-    Node_List* first_pack() const { return _first_pack; }\n-    Node_List* second_pack() const { return _second_pack; }\n-  };\n-\n-  SplitStatus split_pack(const char* split_name, Node_List* pack, SplitTask task);\n-  template <typename SplitStrategy>\n-  void split_packs(const char* split_name, SplitStrategy strategy);\n+  void combine_pairs_to_longer_packs();\n@@ -397,5 +556,0 @@\n-  \/\/ Filter out packs with various filter predicates\n-  template <typename FilterPredicate>\n-  void filter_packs(const char* filter_name,\n-                    const char* error_message,\n-                    FilterPredicate filter);\n@@ -404,1 +558,0 @@\n-  \/\/ Ensure all packs are aligned, if AlignVector is on.\n@@ -406,1 +559,0 @@\n-  \/\/ Find the set of alignment solutions for load\/store pack.\n@@ -408,5 +560,0 @@\n-  \/\/ Compress packset, such that it has no nullptr entries.\n-  void compress_packset();\n-  \/\/ Construct the map from nodes to packs.\n-  void construct_my_pack_map();\n-  \/\/ Remove packs that are not implemented.\n@@ -414,1 +561,0 @@\n-  \/\/ Remove packs that are not profitable.\n@@ -416,3 +562,3 @@\n-  \/\/ Verify that for every pack, all nodes are mutually independent.\n-  \/\/ Also verify that packset and my_pack are consistent.\n-  DEBUG_ONLY(void verify_packs();)\n+\n+  DEBUG_ONLY(void verify_packs() const;)\n+\n@@ -430,1 +576,1 @@\n-  bool implemented(const Node_List* pack, uint size);\n+  bool implemented(const Node_List* pack, uint size) const;\n@@ -435,1 +581,2 @@\n-  bool profitable(const Node_List* p);\n+  bool profitable(const Node_List* p) const;\n+\n@@ -443,0 +590,1 @@\n+\n@@ -444,1 +592,1 @@\n-  bool is_vector_use(Node* use, int u_idx);\n+  bool is_vector_use(Node* use, int u_idx) const;\n@@ -448,2 +596,0 @@\n-  \/\/ Compute max depth for expressions from beginning of block\n-  void compute_max_depth();\n@@ -451,1 +597,1 @@\n-  BasicType longer_type_for_conversion(Node* n);\n+  BasicType longer_type_for_conversion(Node* n) const;\n@@ -454,4 +600,1 @@\n-  \/\/ Are s1 and s2 in a pack pair and ordered as s1,s2?\n-  bool in_packset(Node* s1, Node* s2);\n-  \/\/ Remove the pack at position pos in the packset\n-  void remove_pack_at(int pos);\n+\n@@ -463,9 +606,0 @@\n-  \/\/ Is the use of d1 in u1 at the same operand position as d2 in u2?\n-  bool opnd_positions_match(Node* d1, Node* u1, Node* d2, Node* u2);\n-\n-  \/\/ print methods\n-  void print_packset();\n-  void print_pack(Node_List* p);\n-  void print_stmt(Node* s);\n-\n-  void packset_sort(int n);\n","filename":"src\/hotspot\/share\/opto\/superword.hpp","additions":293,"deletions":159,"binary":false,"changes":452,"status":"modified"},{"patch":"@@ -278,1 +278,1 @@\n-  bool is_marked_reduction_pair(Node* s1, Node* s2) const;\n+  bool is_marked_reduction_pair(const Node* s1, const Node* s2) const;\n","filename":"src\/hotspot\/share\/opto\/vectorization.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -429,1 +429,1 @@\n-bool VectorNode::is_muladds2i(Node* n) {\n+bool VectorNode::is_muladds2i(const Node* n) {\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -105,1 +105,1 @@\n-  static bool is_muladds2i(Node* n);\n+  static bool is_muladds2i(const Node* n);\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -39,1 +39,1 @@\n-    static final int RANGE = 1024;\n+    static final int RANGE = 1024*16;\n@@ -44,0 +44,1 @@\n+    static int[] ioutArr = new int[RANGE];\n@@ -47,0 +48,5 @@\n+    static final int[] GOLDEN_D;\n+    static final int[] GOLDEN_E;\n+    static final int[] GOLDEN_F;\n+    static final int[] GOLDEN_G;\n+    static final int[] GOLDEN_H;\n@@ -56,0 +62,5 @@\n+        GOLDEN_D = testd();\n+        GOLDEN_E = teste();\n+        GOLDEN_F = testf();\n+        GOLDEN_G = testg();\n+        GOLDEN_H = testh();\n@@ -68,1 +79,1 @@\n-    @Run(test = {\"testa\", \"testb\", \"testc\"})\n+    @Run(test = {\"testa\", \"testb\", \"testc\", \"testd\", \"teste\", \"testf\", \"testg\", \"testh\"})\n@@ -73,1 +84,6 @@\n-        compare(testb(), GOLDEN_C, \"testc\");\n+        compare(testc(), GOLDEN_C, \"testc\");\n+        compare(testd(), GOLDEN_D, \"testd\");\n+        compare(teste(), GOLDEN_E, \"teste\");\n+        compare(testf(), GOLDEN_F, \"testf\");\n+        compare(testg(), GOLDEN_G, \"testg\");\n+        compare(testh(), GOLDEN_H, \"testh\");\n@@ -136,0 +152,95 @@\n+\n+    @Test\n+    @IR(applyIfCPUFeature = {\"sse2\", \"true\"},\n+        applyIfPlatform = {\"64-bit\", \"true\"},\n+        counts = {IRNode.MUL_ADD_S2I, \"> 0\", IRNode.MUL_ADD_VS2VI, \"> 0\"})\n+    @IR(applyIfCPUFeature = {\"asimd\", \"true\"},\n+        applyIf = {\"MaxVectorSize\", \"16\"}, \/\/ AD file requires vector_length = 16\n+        counts = {IRNode.MUL_ADD_S2I, \"> 0\", IRNode.MUL_ADD_VS2VI, \"> 0\"})\n+    @IR(applyIfCPUFeature = {\"avx512_vnni\", \"true\"},\n+        counts = {IRNode.MUL_ADD_S2I, \"> 0\", IRNode.MUL_ADD_VS2VI_VNNI, \"> 0\"})\n+    public static int[] testd() {\n+        int[] out = ioutArr;\n+        for (int i = 0; i < ITER-2; i+=2) {\n+            \/\/ Unrolled, with the same structure.\n+            out[i+0] += ((sArr1[2*i+0] * sArr2[2*i+0]) + (sArr1[2*i+1] * sArr2[2*i+1]));\n+            out[i+1] += ((sArr1[2*i+2] * sArr2[2*i+2]) + (sArr1[2*i+3] * sArr2[2*i+3]));\n+        }\n+        return out;\n+    }\n+\n+    @Test\n+    @IR(applyIfCPUFeature = {\"sse2\", \"true\"},\n+        applyIfPlatform = {\"64-bit\", \"true\"},\n+        counts = {IRNode.MUL_ADD_S2I, \"> 0\", IRNode.MUL_ADD_VS2VI, \"> 0\"})\n+    @IR(applyIfCPUFeature = {\"asimd\", \"true\"},\n+        applyIf = {\"MaxVectorSize\", \"16\"}, \/\/ AD file requires vector_length = 16\n+        counts = {IRNode.MUL_ADD_S2I, \"> 0\", IRNode.MUL_ADD_VS2VI, \"> 0\"})\n+    @IR(applyIfCPUFeature = {\"avx512_vnni\", \"true\"},\n+        counts = {IRNode.MUL_ADD_S2I, \"> 0\", IRNode.MUL_ADD_VS2VI_VNNI, \"> 0\"})\n+    public static int[] teste() {\n+        int[] out = ioutArr;\n+        for (int i = 0; i < ITER-2; i+=2) {\n+            \/\/ Unrolled, with some swaps.\n+            out[i+0] += ((sArr1[2*i+0] * sArr2[2*i+0]) + (sArr1[2*i+1] * sArr2[2*i+1]));\n+            out[i+1] += ((sArr2[2*i+2] * sArr1[2*i+2]) + (sArr1[2*i+3] * sArr2[2*i+3])); \/\/ swap(1 2)\n+        }\n+        return out;\n+    }\n+\n+    @Test\n+    @IR(applyIfCPUFeature = {\"sse2\", \"true\"},\n+        applyIfPlatform = {\"64-bit\", \"true\"},\n+        counts = {IRNode.MUL_ADD_S2I, \"> 0\", IRNode.MUL_ADD_VS2VI, \"> 0\"})\n+    @IR(applyIfCPUFeature = {\"asimd\", \"true\"},\n+        applyIf = {\"MaxVectorSize\", \"16\"}, \/\/ AD file requires vector_length = 16\n+        counts = {IRNode.MUL_ADD_S2I, \"> 0\", IRNode.MUL_ADD_VS2VI, \"> 0\"})\n+    @IR(applyIfCPUFeature = {\"avx512_vnni\", \"true\"},\n+        counts = {IRNode.MUL_ADD_S2I, \"> 0\", IRNode.MUL_ADD_VS2VI_VNNI, \"> 0\"})\n+    public static int[] testf() {\n+        int[] out = ioutArr;\n+        for (int i = 0; i < ITER-2; i+=2) {\n+            \/\/ Unrolled, with some swaps.\n+            out[i+0] += ((sArr1[2*i+0] * sArr2[2*i+0]) + (sArr1[2*i+1] * sArr2[2*i+1]));\n+            out[i+1] += ((sArr2[2*i+2] * sArr1[2*i+2]) + (sArr2[2*i+3] * sArr1[2*i+3])); \/\/ swap(1 2), swap(3 4)\n+        }\n+        return out;\n+    }\n+\n+    @Test\n+    @IR(applyIfCPUFeature = {\"sse2\", \"true\"},\n+        applyIfPlatform = {\"64-bit\", \"true\"},\n+        counts = {IRNode.MUL_ADD_S2I, \"> 0\", IRNode.MUL_ADD_VS2VI, \"> 0\"})\n+    @IR(applyIfCPUFeature = {\"asimd\", \"true\"},\n+        applyIf = {\"MaxVectorSize\", \"16\"}, \/\/ AD file requires vector_length = 16\n+        counts = {IRNode.MUL_ADD_S2I, \"> 0\", IRNode.MUL_ADD_VS2VI, \"> 0\"})\n+    @IR(applyIfCPUFeature = {\"avx512_vnni\", \"true\"},\n+        counts = {IRNode.MUL_ADD_S2I, \"> 0\", IRNode.MUL_ADD_VS2VI_VNNI, \"> 0\"})\n+    public static int[] testg() {\n+        int[] out = ioutArr;\n+        for (int i = 0; i < ITER-2; i+=2) {\n+            \/\/ Unrolled, with some swaps.\n+            out[i+0] += ((sArr1[2*i+0] * sArr2[2*i+0]) + (sArr1[2*i+1] * sArr2[2*i+1]));\n+            out[i+1] += ((sArr1[2*i+3] * sArr2[2*i+3]) + (sArr1[2*i+2] * sArr2[2*i+2])); \/\/ swap(1 3), swap(2 4)\n+        }\n+        return out;\n+    }\n+\n+    @Test\n+    @IR(applyIfCPUFeature = {\"sse2\", \"true\"},\n+        applyIfPlatform = {\"64-bit\", \"true\"},\n+        counts = {IRNode.MUL_ADD_S2I, \"> 0\", IRNode.MUL_ADD_VS2VI, \"> 0\"})\n+    @IR(applyIfCPUFeature = {\"asimd\", \"true\"},\n+        applyIf = {\"MaxVectorSize\", \"16\"}, \/\/ AD file requires vector_length = 16\n+        counts = {IRNode.MUL_ADD_S2I, \"> 0\", IRNode.MUL_ADD_VS2VI, \"> 0\"})\n+    @IR(applyIfCPUFeature = {\"avx512_vnni\", \"true\"},\n+        counts = {IRNode.MUL_ADD_S2I, \"> 0\", IRNode.MUL_ADD_VS2VI_VNNI, \"> 0\"})\n+    public static int[] testh() {\n+        int[] out = ioutArr;\n+        for (int i = 0; i < ITER-2; i+=2) {\n+            \/\/ Unrolled, with some swaps.\n+            out[i+0] += ((sArr1[2*i+0] * sArr2[2*i+0]) + (sArr1[2*i+1] * sArr2[2*i+1]));\n+            out[i+1] += ((sArr2[2*i+3] * sArr1[2*i+3]) + (sArr2[2*i+2] * sArr1[2*i+2])); \/\/ swap(1 4), swap(2 3)\n+        }\n+        return out;\n+    }\n","filename":"test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestMulAddS2I.java","additions":114,"deletions":3,"binary":false,"changes":117,"status":"modified"}]}