{"files":[{"patch":"@@ -57,1 +57,1 @@\n-    private static final int NATIVE_THRESHOLD_MISMATCH = powerOfPropertyOr(\"mismatch\", Architecture.isAARCH64() ? 31 : 5);\n+    private static final int NATIVE_THRESHOLD_MISMATCH = powerOfPropertyOr(\"mismatch\", 6);\n@@ -200,42 +200,6 @@\n-        \/\/ Currently, we do not benefit from super-word optimization on Aarch64 so\n-        \/\/ instead we manually unroll the loop.\n-        \/\/ This gives about 20% performance increase for large values of `length`.\n-        \/\/ On non-Aarch64 architectures, the unroll code will be eliminated at compile time.\n-        if (Architecture.isAARCH64() && NATIVE_THRESHOLD_MISMATCH > 64) {\n-\n-            \/\/ 0...X...000000\n-            final int bulkLimit = length & (NATIVE_THRESHOLD_MISMATCH - 64);\n-            for (; offset < bulkLimit; offset += 64) {\n-                \/\/ Manually unroll looping in chunks of 64 bytes\n-\n-                \/\/ The creation of long arrays will be optimized away\n-                final long[] s = new long[8];\n-                \/\/ Grouping reads from the same source together improves performance\n-                s[0] = SCOPED_MEMORY_ACCESS.getLongUnaligned(src.sessionImpl(), src.unsafeGetBase(), src.unsafeGetOffset() + srcFromOffset + offset,      !Architecture.isLittleEndian());\n-                s[1] = SCOPED_MEMORY_ACCESS.getLongUnaligned(src.sessionImpl(), src.unsafeGetBase(), src.unsafeGetOffset() + srcFromOffset + offset +  8, !Architecture.isLittleEndian());\n-                s[2] = SCOPED_MEMORY_ACCESS.getLongUnaligned(src.sessionImpl(), src.unsafeGetBase(), src.unsafeGetOffset() + srcFromOffset + offset + 16, !Architecture.isLittleEndian());\n-                s[3] = SCOPED_MEMORY_ACCESS.getLongUnaligned(src.sessionImpl(), src.unsafeGetBase(), src.unsafeGetOffset() + srcFromOffset + offset + 24, !Architecture.isLittleEndian());\n-                s[4] = SCOPED_MEMORY_ACCESS.getLongUnaligned(src.sessionImpl(), src.unsafeGetBase(), src.unsafeGetOffset() + srcFromOffset + offset + 32, !Architecture.isLittleEndian());\n-                s[5] = SCOPED_MEMORY_ACCESS.getLongUnaligned(src.sessionImpl(), src.unsafeGetBase(), src.unsafeGetOffset() + srcFromOffset + offset + 40, !Architecture.isLittleEndian());\n-                s[6] = SCOPED_MEMORY_ACCESS.getLongUnaligned(src.sessionImpl(), src.unsafeGetBase(), src.unsafeGetOffset() + srcFromOffset + offset + 48, !Architecture.isLittleEndian());\n-                s[7] = SCOPED_MEMORY_ACCESS.getLongUnaligned(src.sessionImpl(), src.unsafeGetBase(), src.unsafeGetOffset() + srcFromOffset + offset + 56, !Architecture.isLittleEndian());\n-\n-                final long[] d = new long[8];\n-                d[0] = SCOPED_MEMORY_ACCESS.getLongUnaligned(dst.sessionImpl(), dst.unsafeGetBase(), dst.unsafeGetOffset() + dstFromOffset + offset,      !Architecture.isLittleEndian());\n-                d[1] = SCOPED_MEMORY_ACCESS.getLongUnaligned(dst.sessionImpl(), dst.unsafeGetBase(), dst.unsafeGetOffset() + dstFromOffset + offset +  8, !Architecture.isLittleEndian());\n-                d[2] = SCOPED_MEMORY_ACCESS.getLongUnaligned(dst.sessionImpl(), dst.unsafeGetBase(), dst.unsafeGetOffset() + dstFromOffset + offset + 16, !Architecture.isLittleEndian());\n-                d[3] = SCOPED_MEMORY_ACCESS.getLongUnaligned(dst.sessionImpl(), dst.unsafeGetBase(), dst.unsafeGetOffset() + dstFromOffset + offset + 24, !Architecture.isLittleEndian());\n-                d[4] = SCOPED_MEMORY_ACCESS.getLongUnaligned(dst.sessionImpl(), dst.unsafeGetBase(), dst.unsafeGetOffset() + dstFromOffset + offset + 32, !Architecture.isLittleEndian());\n-                d[5] = SCOPED_MEMORY_ACCESS.getLongUnaligned(dst.sessionImpl(), dst.unsafeGetBase(), dst.unsafeGetOffset() + dstFromOffset + offset + 40, !Architecture.isLittleEndian());\n-                d[6] = SCOPED_MEMORY_ACCESS.getLongUnaligned(dst.sessionImpl(), dst.unsafeGetBase(), dst.unsafeGetOffset() + dstFromOffset + offset + 48, !Architecture.isLittleEndian());\n-                d[7] = SCOPED_MEMORY_ACCESS.getLongUnaligned(dst.sessionImpl(), dst.unsafeGetBase(), dst.unsafeGetOffset() + dstFromOffset + offset + 56, !Architecture.isLittleEndian());\n-\n-                \/\/ Explicitly checking each index retains performance\n-                if (s[0] != d[0]) { return start + offset +      mismatch(s[0], d[0]); }\n-                if (s[1] != d[1]) { return start + offset +  8 + mismatch(s[1], d[1]); }\n-                if (s[2] != d[2]) { return start + offset + 16 + mismatch(s[2], d[2]); }\n-                if (s[3] != d[3]) { return start + offset + 24 + mismatch(s[3], d[3]); }\n-                if (s[4] != d[4]) { return start + offset + 32 + mismatch(s[4], d[4]); }\n-                if (s[5] != d[5]) { return start + offset + 40 + mismatch(s[5], d[5]); }\n-                if (s[6] != d[6]) { return start + offset + 48 + mismatch(s[6], d[6]); }\n-                if (s[7] != d[7]) { return start + offset + 56 + mismatch(s[7], d[7]); }\n+        final int limit = length & (NATIVE_THRESHOLD_MISMATCH - 8);\n+        for (; offset < limit; offset += 8) {\n+            final long s = SCOPED_MEMORY_ACCESS.getLongUnaligned(src.sessionImpl(), src.unsafeGetBase(), src.unsafeGetOffset() + srcFromOffset + offset, !Architecture.isLittleEndian());\n+            final long d = SCOPED_MEMORY_ACCESS.getLongUnaligned(dst.sessionImpl(), dst.unsafeGetBase(), dst.unsafeGetOffset() + dstFromOffset + offset, !Architecture.isLittleEndian());\n+            if (s != d) {\n+                return start + offset + mismatch(s, d);\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/foreign\/SegmentBulkOperations.java","additions":7,"deletions":43,"binary":false,"changes":50,"status":"modified"}]}