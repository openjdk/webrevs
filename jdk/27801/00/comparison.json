{"files":[{"patch":"@@ -1,57 +0,0 @@\n-\/*\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2014, Red Hat Inc. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef CPU_AARCH64_BYTES_AARCH64_HPP\n-#define CPU_AARCH64_BYTES_AARCH64_HPP\n-\n-#include \"memory\/allStatic.hpp\"\n-#include \"utilities\/byteswap.hpp\"\n-\n-class Bytes: AllStatic {\n- public:\n-  \/\/ Efficient reading and writing of unaligned unsigned data in platform-specific byte ordering\n-  \/\/ (no special code is needed since x86 CPUs can access unaligned data)\n-  static inline u2   get_native_u2(address p)         { return *(u2*)p; }\n-  static inline u4   get_native_u4(address p)         { return *(u4*)p; }\n-  static inline u8   get_native_u8(address p)         { return *(u8*)p; }\n-\n-  static inline void put_native_u2(address p, u2 x)   { *(u2*)p = x; }\n-  static inline void put_native_u4(address p, u4 x)   { *(u4*)p = x; }\n-  static inline void put_native_u8(address p, u8 x)   { *(u8*)p = x; }\n-\n-\n-  \/\/ Efficient reading and writing of unaligned unsigned data in Java\n-  \/\/ byte ordering (i.e. big-endian ordering). Byte-order reversal is\n-  \/\/ needed since x86 CPUs use little-endian format.\n-  static inline u2   get_Java_u2(address p)           { return byteswap(get_native_u2(p)); }\n-  static inline u4   get_Java_u4(address p)           { return byteswap(get_native_u4(p)); }\n-  static inline u8   get_Java_u8(address p)           { return byteswap(get_native_u8(p)); }\n-\n-  static inline void put_Java_u2(address p, u2 x)     { put_native_u2(p, byteswap(x)); }\n-  static inline void put_Java_u4(address p, u4 x)     { put_native_u4(p, byteswap(x)); }\n-  static inline void put_Java_u8(address p, u8 x)     { put_native_u8(p, byteswap(x)); }\n-};\n-\n-#endif \/\/ CPU_AARCH64_BYTES_AARCH64_HPP\n","filename":"src\/hotspot\/cpu\/aarch64\/bytes_aarch64.hpp","additions":0,"deletions":57,"binary":false,"changes":57,"status":"deleted"},{"patch":"@@ -1,180 +0,0 @@\n-\/*\n- * Copyright (c) 2008, 2022, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef CPU_ARM_BYTES_ARM_HPP\n-#define CPU_ARM_BYTES_ARM_HPP\n-\n-#include \"memory\/allStatic.hpp\"\n-#include \"utilities\/macros.hpp\"\n-\n-#ifndef VM_LITTLE_ENDIAN\n-#define VM_LITTLE_ENDIAN  1\n-#endif\n-\n-class Bytes: AllStatic {\n-\n- public:\n-  static inline u2 get_Java_u2(address p) {\n-    return (u2(p[0]) << 8) | u2(p[1]);\n-  }\n-\n-  static inline u4 get_Java_u4(address p) {\n-    return u4(p[0]) << 24 |\n-           u4(p[1]) << 16 |\n-           u4(p[2]) <<  8 |\n-           u4(p[3]);\n-  }\n-\n-  static inline u8 get_Java_u8(address p) {\n-    return u8(p[0]) << 56 |\n-           u8(p[1]) << 48 |\n-           u8(p[2]) << 40 |\n-           u8(p[3]) << 32 |\n-           u8(p[4]) << 24 |\n-           u8(p[5]) << 16 |\n-           u8(p[6]) <<  8 |\n-           u8(p[7]);\n-  }\n-\n-  static inline void put_Java_u2(address p, u2 x) {\n-    p[0] = x >> 8;\n-    p[1] = x;\n-  }\n-\n-  static inline void put_Java_u4(address p, u4 x) {\n-    ((u1*)p)[0] = x >> 24;\n-    ((u1*)p)[1] = x >> 16;\n-    ((u1*)p)[2] = x >>  8;\n-    ((u1*)p)[3] = x;\n-  }\n-\n-  static inline void put_Java_u8(address p, u8 x) {\n-    ((u1*)p)[0] = x >> 56;\n-    ((u1*)p)[1] = x >> 48;\n-    ((u1*)p)[2] = x >> 40;\n-    ((u1*)p)[3] = x >> 32;\n-    ((u1*)p)[4] = x >> 24;\n-    ((u1*)p)[5] = x >> 16;\n-    ((u1*)p)[6] = x >>  8;\n-    ((u1*)p)[7] = x;\n-  }\n-\n-#ifdef VM_LITTLE_ENDIAN\n-\n-  static inline u2 get_native_u2(address p) {\n-    return (intptr_t(p) & 1) == 0 ? *(u2*)p : u2(p[0]) | (u2(p[1]) << 8);\n-  }\n-\n-  static inline u4 get_native_u4(address p) {\n-    switch (intptr_t(p) & 3) {\n-      case 0:  return *(u4*)p;\n-      case 2:  return u4(((u2*)p)[0]) |\n-                      u4(((u2*)p)[1]) << 16;\n-      default: return u4(p[0])       |\n-                      u4(p[1]) <<  8 |\n-                      u4(p[2]) << 16 |\n-                      u4(p[3]) << 24;\n-    }\n-  }\n-\n-  static inline u8 get_native_u8(address p) {\n-    switch (intptr_t(p) & 7) {\n-      case 0:  return *(u8*)p;\n-      case 4:  return u8(((u4*)p)[0]) |\n-                      u8(((u4*)p)[1]) << 32;\n-      case 2:  return u8(((u2*)p)[0])       |\n-                      u8(((u2*)p)[1]) << 16 |\n-                      u8(((u2*)p)[2]) << 32 |\n-                      u8(((u2*)p)[3]) << 48;\n-      default: return u8(p[0])       |\n-                      u8(p[1]) <<  8 |\n-                      u8(p[2]) << 16 |\n-                      u8(p[3]) << 24 |\n-                      u8(p[4]) << 32 |\n-                      u8(p[5]) << 40 |\n-                      u8(p[6]) << 48 |\n-                      u8(p[7]) << 56;\n-    }\n-  }\n-\n-  static inline void put_native_u2(address p, u2 x) {\n-    if ((intptr_t(p) & 1) == 0) {\n-      *(u2*)p = x;\n-    } else {\n-      p[0] = x;\n-      p[1] = x >> 8;\n-    }\n-  }\n-\n-  static inline void put_native_u4(address p, u4 x) {\n-    switch (intptr_t(p) & 3) {\n-      case 0:  *(u4*)p = x;\n-               break;\n-      case 2:  ((u2*)p)[0] = x;\n-               ((u2*)p)[1] = x >> 16;\n-               break;\n-      default: ((u1*)p)[0] = x;\n-               ((u1*)p)[1] = x >>  8;\n-               ((u1*)p)[2] = x >> 16;\n-               ((u1*)p)[3] = x >> 24;\n-               break;\n-    }\n-  }\n-\n-  static inline void put_native_u8(address p, u8 x) {\n-    switch (intptr_t(p) & 7) {\n-      case 0:  *(u8*)p = x;\n-               break;\n-      case 4:  ((u4*)p)[0] = x;\n-               ((u4*)p)[1] = x >> 32;\n-               break;\n-      case 2:  ((u2*)p)[0] = x;\n-               ((u2*)p)[1] = x >> 16;\n-               ((u2*)p)[2] = x >> 32;\n-               ((u2*)p)[3] = x >> 48;\n-               break;\n-      default: ((u1*)p)[0] = x;\n-               ((u1*)p)[1] = x >>  8;\n-               ((u1*)p)[2] = x >> 16;\n-               ((u1*)p)[3] = x >> 24;\n-               ((u1*)p)[4] = x >> 32;\n-               ((u1*)p)[5] = x >> 40;\n-               ((u1*)p)[6] = x >> 48;\n-               ((u1*)p)[7] = x >> 56;\n-    }\n-  }\n-\n-#else\n-\n-  static inline u2 get_native_u2(address p) { return get_Java_u2(p); }\n-  static inline u4 get_native_u4(address p) { return get_Java_u4(p); }\n-  static inline u8 get_native_u8(address p) { return get_Java_u8(p); }\n-  static inline void put_native_u2(address p, u2 x) { put_Java_u2(p, x); }\n-  static inline void put_native_u4(address p, u4 x) { put_Java_u4(p, x); }\n-  static inline void put_native_u8(address p, u8 x) { put_Java_u8(p, x); }\n-\n-#endif \/\/ VM_LITTLE_ENDIAN\n-};\n-\n-#endif \/\/ CPU_ARM_BYTES_ARM_HPP\n","filename":"src\/hotspot\/cpu\/arm\/bytes_arm.hpp","additions":0,"deletions":180,"binary":false,"changes":180,"status":"deleted"},{"patch":"@@ -1,260 +0,0 @@\n-\/*\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2012, 2022 SAP SE. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef CPU_PPC_BYTES_PPC_HPP\n-#define CPU_PPC_BYTES_PPC_HPP\n-\n-#include \"memory\/allStatic.hpp\"\n-#include \"utilities\/byteswap.hpp\"\n-\n-class Bytes: AllStatic {\n- public:\n-  \/\/ Efficient reading and writing of unaligned unsigned data in platform-specific byte ordering\n-  \/\/ PowerPC needs to check for alignment.\n-\n-  \/\/ Can I count on address always being a pointer to an unsigned char? Yes.\n-\n-#if defined(VM_LITTLE_ENDIAN)\n-\n-  static inline u2   get_native_u2(address p) {\n-    return (intptr_t(p) & 1) == 0\n-             ?   *(u2*)p\n-             :   ( u2(p[1]) << 8 )\n-               | ( u2(p[0])      );\n-  }\n-\n-  static inline u4   get_native_u4(address p) {\n-    switch (intptr_t(p) & 3) {\n-     case 0:  return *(u4*)p;\n-\n-     case 2:  return (  u4( ((u2*)p)[1] ) << 16  )\n-                   | (  u4( ((u2*)p)[0] )        );\n-\n-    default:  return ( u4(p[3]) << 24 )\n-                   | ( u4(p[2]) << 16 )\n-                   | ( u4(p[1]) <<  8 )\n-                   |   u4(p[0]);\n-    }\n-  }\n-\n-  static inline u8   get_native_u8(address p) {\n-    switch (intptr_t(p) & 7) {\n-      case 0:  return *(u8*)p;\n-\n-      case 4:  return (  u8( ((u4*)p)[1] ) << 32  )\n-                    | (  u8( ((u4*)p)[0] )        );\n-\n-      case 2:  return (  u8( ((u2*)p)[3] ) << 48  )\n-                    | (  u8( ((u2*)p)[2] ) << 32  )\n-                    | (  u8( ((u2*)p)[1] ) << 16  )\n-                    | (  u8( ((u2*)p)[0] )        );\n-\n-     default:  return ( u8(p[7]) << 56 )\n-                    | ( u8(p[6]) << 48 )\n-                    | ( u8(p[5]) << 40 )\n-                    | ( u8(p[4]) << 32 )\n-                    | ( u8(p[3]) << 24 )\n-                    | ( u8(p[2]) << 16 )\n-                    | ( u8(p[1]) <<  8 )\n-                    |   u8(p[0]);\n-    }\n-  }\n-\n-\n-\n-  static inline void put_native_u2(address p, u2 x) {\n-    if ( (intptr_t(p) & 1) == 0 )  *(u2*)p = x;\n-    else {\n-      p[1] = x >> 8;\n-      p[0] = x;\n-    }\n-  }\n-\n-  static inline void put_native_u4(address p, u4 x) {\n-    switch ( intptr_t(p) & 3 ) {\n-    case 0:  *(u4*)p = x;\n-              break;\n-\n-    case 2:  ((u2*)p)[1] = x >> 16;\n-             ((u2*)p)[0] = x;\n-             break;\n-\n-    default: ((u1*)p)[3] = x >> 24;\n-             ((u1*)p)[2] = x >> 16;\n-             ((u1*)p)[1] = x >>  8;\n-             ((u1*)p)[0] = x;\n-             break;\n-    }\n-  }\n-\n-  static inline void put_native_u8(address p, u8 x) {\n-    switch ( intptr_t(p) & 7 ) {\n-    case 0:  *(u8*)p = x;\n-             break;\n-\n-    case 4:  ((u4*)p)[1] = x >> 32;\n-             ((u4*)p)[0] = x;\n-             break;\n-\n-    case 2:  ((u2*)p)[3] = x >> 48;\n-             ((u2*)p)[2] = x >> 32;\n-             ((u2*)p)[1] = x >> 16;\n-             ((u2*)p)[0] = x;\n-             break;\n-\n-    default: ((u1*)p)[7] = x >> 56;\n-             ((u1*)p)[6] = x >> 48;\n-             ((u1*)p)[5] = x >> 40;\n-             ((u1*)p)[4] = x >> 32;\n-             ((u1*)p)[3] = x >> 24;\n-             ((u1*)p)[2] = x >> 16;\n-             ((u1*)p)[1] = x >>  8;\n-             ((u1*)p)[0] = x;\n-    }\n-  }\n-\n-  \/\/ Efficient reading and writing of unaligned unsigned data in Java byte ordering (i.e. big-endian ordering)\n-  \/\/ (no byte-order reversal is needed since Power CPUs are big-endian oriented).\n-  static inline u2   get_Java_u2(address p) { return byteswap(get_native_u2(p)); }\n-  static inline u4   get_Java_u4(address p) { return byteswap(get_native_u4(p)); }\n-  static inline u8   get_Java_u8(address p) { return byteswap(get_native_u8(p)); }\n-\n-  static inline void put_Java_u2(address p, u2 x)     { put_native_u2(p, byteswap(x)); }\n-  static inline void put_Java_u4(address p, u4 x)     { put_native_u4(p, byteswap(x)); }\n-  static inline void put_Java_u8(address p, u8 x)     { put_native_u8(p, byteswap(x)); }\n-\n-#else \/\/ !defined(VM_LITTLE_ENDIAN)\n-\n-  static inline u2   get_native_u2(address p) {\n-    return (intptr_t(p) & 1) == 0\n-             ?   *(u2*)p\n-             :   ( u2(p[0]) << 8 )\n-               | ( u2(p[1])      );\n-  }\n-\n-  static inline u4   get_native_u4(address p) {\n-    switch (intptr_t(p) & 3) {\n-     case 0:  return *(u4*)p;\n-\n-     case 2:  return (  u4( ((u2*)p)[0] ) << 16  )\n-                   | (  u4( ((u2*)p)[1] )        );\n-\n-    default:  return ( u4(p[0]) << 24 )\n-                   | ( u4(p[1]) << 16 )\n-                   | ( u4(p[2]) <<  8 )\n-                   |   u4(p[3]);\n-    }\n-  }\n-\n-  static inline u8   get_native_u8(address p) {\n-    switch (intptr_t(p) & 7) {\n-      case 0:  return *(u8*)p;\n-\n-      case 4:  return (  u8( ((u4*)p)[0] ) << 32  )\n-                    | (  u8( ((u4*)p)[1] )        );\n-\n-      case 2:  return (  u8( ((u2*)p)[0] ) << 48  )\n-                    | (  u8( ((u2*)p)[1] ) << 32  )\n-                    | (  u8( ((u2*)p)[2] ) << 16  )\n-                    | (  u8( ((u2*)p)[3] )        );\n-\n-     default:  return ( u8(p[0]) << 56 )\n-                    | ( u8(p[1]) << 48 )\n-                    | ( u8(p[2]) << 40 )\n-                    | ( u8(p[3]) << 32 )\n-                    | ( u8(p[4]) << 24 )\n-                    | ( u8(p[5]) << 16 )\n-                    | ( u8(p[6]) <<  8 )\n-                    |   u8(p[7]);\n-    }\n-  }\n-\n-\n-\n-  static inline void put_native_u2(address p, u2 x) {\n-    if ( (intptr_t(p) & 1) == 0 ) { *(u2*)p = x; }\n-    else {\n-      p[0] = x >> 8;\n-      p[1] = x;\n-    }\n-  }\n-\n-  static inline void put_native_u4(address p, u4 x) {\n-    switch ( intptr_t(p) & 3 ) {\n-    case 0:  *(u4*)p = x;\n-              break;\n-\n-    case 2:  ((u2*)p)[0] = x >> 16;\n-             ((u2*)p)[1] = x;\n-             break;\n-\n-    default: ((u1*)p)[0] = x >> 24;\n-             ((u1*)p)[1] = x >> 16;\n-             ((u1*)p)[2] = x >>  8;\n-             ((u1*)p)[3] = x;\n-             break;\n-    }\n-  }\n-\n-  static inline void put_native_u8(address p, u8 x) {\n-    switch ( intptr_t(p) & 7 ) {\n-    case 0:  *(u8*)p = x;\n-             break;\n-\n-    case 4:  ((u4*)p)[0] = x >> 32;\n-             ((u4*)p)[1] = x;\n-             break;\n-\n-    case 2:  ((u2*)p)[0] = x >> 48;\n-             ((u2*)p)[1] = x >> 32;\n-             ((u2*)p)[2] = x >> 16;\n-             ((u2*)p)[3] = x;\n-             break;\n-\n-    default: ((u1*)p)[0] = x >> 56;\n-             ((u1*)p)[1] = x >> 48;\n-             ((u1*)p)[2] = x >> 40;\n-             ((u1*)p)[3] = x >> 32;\n-             ((u1*)p)[4] = x >> 24;\n-             ((u1*)p)[5] = x >> 16;\n-             ((u1*)p)[6] = x >>  8;\n-             ((u1*)p)[7] = x;\n-    }\n-  }\n-\n-  \/\/ Efficient reading and writing of unaligned unsigned data in Java byte ordering (i.e. big-endian ordering)\n-  \/\/ (no byte-order reversal is needed since Power CPUs are big-endian oriented).\n-  static inline u2   get_Java_u2(address p) { return get_native_u2(p); }\n-  static inline u4   get_Java_u4(address p) { return get_native_u4(p); }\n-  static inline u8   get_Java_u8(address p) { return get_native_u8(p); }\n-\n-  static inline void put_Java_u2(address p, u2 x)     { put_native_u2(p, x); }\n-  static inline void put_Java_u4(address p, u4 x)     { put_native_u4(p, x); }\n-  static inline void put_Java_u8(address p, u8 x)     { put_native_u8(p, x); }\n-\n-#endif \/\/ VM_LITTLE_ENDIAN\n-};\n-\n-#endif \/\/ CPU_PPC_BYTES_PPC_HPP\n","filename":"src\/hotspot\/cpu\/ppc\/bytes_ppc.hpp","additions":0,"deletions":260,"binary":false,"changes":260,"status":"deleted"},{"patch":"@@ -1,167 +0,0 @@\n-\/*\n- * Copyright (c) 1997, 2019, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2012, 2016 SAP SE. All rights reserved.\n- * Copyright (c) 2020, 2022, Huawei Technologies Co., Ltd. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef CPU_RISCV_BYTES_RISCV_HPP\n-#define CPU_RISCV_BYTES_RISCV_HPP\n-\n-#include \"memory\/allStatic.hpp\"\n-#include \"utilities\/byteswap.hpp\"\n-\n-class Bytes: AllStatic {\n- public:\n-  \/\/ Efficient reading and writing of unaligned unsigned data in platform-specific byte ordering\n-  \/\/ RISCV needs to check for alignment.\n-\n-  static inline u2 get_native_u2(address p) {\n-    if ((intptr_t(p) & 1) == 0) {\n-      return *(u2*)p;\n-    } else {\n-      return ((u2)(p[1]) << 8) |\n-             ((u2)(p[0]));\n-    }\n-  }\n-\n-  static inline u4 get_native_u4(address p) {\n-    switch (intptr_t(p) & 3) {\n-      case 0:\n-        return *(u4*)p;\n-\n-      case 2:\n-        return ((u4)(((u2*)p)[1]) << 16) |\n-               ((u4)(((u2*)p)[0]));\n-\n-      default:\n-        return ((u4)(p[3]) << 24) |\n-               ((u4)(p[2]) << 16) |\n-               ((u4)(p[1]) <<  8) |\n-               ((u4)(p[0]));\n-    }\n-  }\n-\n-  static inline u8 get_native_u8(address p) {\n-    switch (intptr_t(p) & 7) {\n-      case 0:\n-        return *(u8*)p;\n-\n-      case 4:\n-        return ((u8)(((u4*)p)[1]) << 32) |\n-               ((u8)(((u4*)p)[0]));\n-\n-      case 2:\n-      case 6:\n-        return ((u8)(((u2*)p)[3]) << 48) |\n-               ((u8)(((u2*)p)[2]) << 32) |\n-               ((u8)(((u2*)p)[1]) << 16) |\n-               ((u8)(((u2*)p)[0]));\n-\n-      default:\n-        return ((u8)(p[7]) << 56) |\n-               ((u8)(p[6]) << 48) |\n-               ((u8)(p[5]) << 40) |\n-               ((u8)(p[4]) << 32) |\n-               ((u8)(p[3]) << 24) |\n-               ((u8)(p[2]) << 16) |\n-               ((u8)(p[1]) <<  8) |\n-               ((u8)(p[0]));\n-    }\n-  }\n-\n-  static inline void put_native_u2(address p, u2 x) {\n-    if ((intptr_t(p) & 1) == 0) {\n-      *(u2*)p = x;\n-    } else {\n-      p[1] = x >> 8;\n-      p[0] = x;\n-    }\n-  }\n-\n-  static inline void put_native_u4(address p, u4 x) {\n-    switch (intptr_t(p) & 3) {\n-      case 0:\n-        *(u4*)p = x;\n-        break;\n-\n-      case 2:\n-        ((u2*)p)[1] = x >> 16;\n-        ((u2*)p)[0] = x;\n-        break;\n-\n-      default:\n-        ((u1*)p)[3] = x >> 24;\n-        ((u1*)p)[2] = x >> 16;\n-        ((u1*)p)[1] = x >>  8;\n-        ((u1*)p)[0] = x;\n-        break;\n-    }\n-  }\n-\n-  static inline void put_native_u8(address p, u8 x) {\n-    switch (intptr_t(p) & 7) {\n-      case 0:\n-        *(u8*)p = x;\n-        break;\n-\n-      case 4:\n-        ((u4*)p)[1] = x >> 32;\n-        ((u4*)p)[0] = x;\n-        break;\n-\n-      case 2:\n-      case 6:\n-        ((u2*)p)[3] = x >> 48;\n-        ((u2*)p)[2] = x >> 32;\n-        ((u2*)p)[1] = x >> 16;\n-        ((u2*)p)[0] = x;\n-        break;\n-\n-      default:\n-        ((u1*)p)[7] = x >> 56;\n-        ((u1*)p)[6] = x >> 48;\n-        ((u1*)p)[5] = x >> 40;\n-        ((u1*)p)[4] = x >> 32;\n-        ((u1*)p)[3] = x >> 24;\n-        ((u1*)p)[2] = x >> 16;\n-        ((u1*)p)[1] = x >>  8;\n-        ((u1*)p)[0] = x;\n-        break;\n-    }\n-  }\n-\n-#ifndef VM_LITTLE_ENDIAN\n-#error RISC-V is little endian, the preprocessor macro VM_LITTLE_ENDIAN should be defined.\n-#endif\n-\n-  \/\/ Efficient reading and writing of unaligned unsigned data in Java byte ordering (i.e. big-endian ordering)\n-  static inline u2 get_Java_u2(address p) { return byteswap(get_native_u2(p)); }\n-  static inline u4 get_Java_u4(address p) { return byteswap(get_native_u4(p)); }\n-  static inline u8 get_Java_u8(address p) { return byteswap(get_native_u8(p)); }\n-\n-  static inline void put_Java_u2(address p, u2 x) { put_native_u2(p, byteswap(x)); }\n-  static inline void put_Java_u4(address p, u4 x) { put_native_u4(p, byteswap(x)); }\n-  static inline void put_Java_u8(address p, u8 x) { put_native_u8(p, byteswap(x)); }\n-};\n-\n-#endif \/\/ CPU_RISCV_BYTES_RISCV_HPP\n","filename":"src\/hotspot\/cpu\/riscv\/bytes_riscv.hpp","additions":0,"deletions":167,"binary":false,"changes":167,"status":"deleted"},{"patch":"@@ -1,63 +0,0 @@\n-\/*\n- * Copyright (c) 2016, 2022, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2016, 2022 SAP SE. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef CPU_S390_BYTES_S390_HPP\n-#define CPU_S390_BYTES_S390_HPP\n-\n-#include \"memory\/allStatic.hpp\"\n-\n-class Bytes: AllStatic {\n- public:\n-  \/\/ Efficient reading and writing of unaligned unsigned data in\n-  \/\/ platform-specific byte ordering.\n-\n-  \/\/ Use regular load and store for unaligned access.\n-  \/\/\n-  \/\/ On z\/Architecture, unaligned loads and stores are supported when using the\n-  \/\/ \"traditional\" load (LH, L\/LY, LG) and store (STH, ST\/STY, STG) instructions.\n-  \/\/ The penalty for unaligned access is just very few (two or three) ticks,\n-  \/\/ plus another few (two or three) ticks if the access crosses a cache line boundary.\n-  \/\/\n-  \/\/ In short, it makes no sense on z\/Architecture to piecemeal get or put unaligned data.\n-\n-  static inline u2   get_native_u2(address p) { return *(u2*)p; }\n-  static inline u4   get_native_u4(address p) { return *(u4*)p; }\n-  static inline u8   get_native_u8(address p) { return *(u8*)p; }\n-\n-  static inline void put_native_u2(address p, u2 x) { *(u2*)p = x; }\n-  static inline void put_native_u4(address p, u4 x) { *(u4*)p = x; }\n-  static inline void put_native_u8(address p, u8 x) { *(u8*)p = x; }\n-\n-  \/\/ Efficient reading and writing of unaligned unsigned data in Java byte ordering (i.e. big-endian ordering)\n-  static inline u2   get_Java_u2(address p) { return get_native_u2(p); }\n-  static inline u4   get_Java_u4(address p) { return get_native_u4(p); }\n-  static inline u8   get_Java_u8(address p) { return get_native_u8(p); }\n-\n-  static inline void put_Java_u2(address p, u2 x) { put_native_u2(p, x); }\n-  static inline void put_Java_u4(address p, u4 x) { put_native_u4(p, x); }\n-  static inline void put_Java_u8(address p, u8 x) { put_native_u8(p, x); }\n-};\n-\n-#endif \/\/ CPU_S390_BYTES_S390_HPP\n","filename":"src\/hotspot\/cpu\/s390\/bytes_s390.hpp","additions":0,"deletions":63,"binary":false,"changes":63,"status":"deleted"},{"patch":"@@ -1,101 +0,0 @@\n-\/*\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef CPU_X86_BYTES_X86_HPP\n-#define CPU_X86_BYTES_X86_HPP\n-\n-#include \"memory\/allStatic.hpp\"\n-#include \"utilities\/align.hpp\"\n-#include \"utilities\/byteswap.hpp\"\n-#include \"utilities\/macros.hpp\"\n-\n-class Bytes: AllStatic {\n- public:\n-  \/\/ Efficient reading and writing of unaligned unsigned data in platform-specific byte ordering\n-  template <typename T>\n-  static inline T get_native(const void* p) {\n-    assert(p != nullptr, \"null pointer\");\n-\n-    T x;\n-\n-    if (is_aligned(p, sizeof(T))) {\n-      x = *(T*)p;\n-    } else {\n-      memcpy(&x, p, sizeof(T));\n-    }\n-\n-    return x;\n-  }\n-\n-  template <typename T>\n-  static inline void put_native(void* p, T x) {\n-    assert(p != nullptr, \"null pointer\");\n-\n-    if (is_aligned(p, sizeof(T))) {\n-      *(T*)p = x;\n-    } else {\n-      memcpy(p, &x, sizeof(T));\n-    }\n-  }\n-\n-  static inline u2   get_native_u2(address p)         { return get_native<u2>((void*)p); }\n-  static inline u4   get_native_u4(address p)         { return get_native<u4>((void*)p); }\n-  static inline u8   get_native_u8(address p)         { return get_native<u8>((void*)p); }\n-  static inline void put_native_u2(address p, u2 x)   { put_native<u2>((void*)p, x); }\n-  static inline void put_native_u4(address p, u4 x)   { put_native<u4>((void*)p, x); }\n-  static inline void put_native_u8(address p, u8 x)   { put_native<u8>((void*)p, x); }\n-\n-  \/\/ Efficient reading and writing of unaligned unsigned data in Java\n-  \/\/ byte ordering (i.e. big-endian ordering). Byte-order reversal is\n-  \/\/ needed since x86 CPUs use little-endian format.\n-  template <typename T>\n-  static inline T get_Java(const address p) {\n-    T x = get_native<T>(p);\n-\n-    if (Endian::is_Java_byte_ordering_different()) {\n-      x = byteswap(x);\n-    }\n-\n-    return x;\n-  }\n-\n-  template <typename T>\n-  static inline void put_Java(address p, T x) {\n-    if (Endian::is_Java_byte_ordering_different()) {\n-      x = byteswap(x);\n-    }\n-\n-    put_native<T>(p, x);\n-  }\n-\n-  static inline u2   get_Java_u2(address p)           { return get_Java<u2>(p); }\n-  static inline u4   get_Java_u4(address p)           { return get_Java<u4>(p); }\n-  static inline u8   get_Java_u8(address p)           { return get_Java<u8>(p); }\n-\n-  static inline void put_Java_u2(address p, u2 x)     { put_Java<u2>(p, x); }\n-  static inline void put_Java_u4(address p, u4 x)     { put_Java<u4>(p, x); }\n-  static inline void put_Java_u8(address p, u8 x)     { put_Java<u8>(p, x); }\n-};\n-\n-#endif \/\/ CPU_X86_BYTES_X86_HPP\n","filename":"src\/hotspot\/cpu\/x86\/bytes_x86.hpp","additions":0,"deletions":101,"binary":false,"changes":101,"status":"deleted"},{"patch":"@@ -1,145 +0,0 @@\n-\/*\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright 2007, 2008, 2009 Red Hat, Inc.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef CPU_ZERO_BYTES_ZERO_HPP\n-#define CPU_ZERO_BYTES_ZERO_HPP\n-\n-#include \"memory\/allStatic.hpp\"\n-\n-typedef union unaligned {\n-  u4 u;\n-  u2 us;\n-  u8 ul;\n-} __attribute__((packed)) unaligned;\n-\n-class Bytes: AllStatic {\n- public:\n-  \/\/ Efficient reading and writing of unaligned unsigned data in\n-  \/\/ platform-specific byte ordering.\n-  static inline u2 get_native_u2(address p){\n-    unaligned *up = (unaligned *) p;\n-    return up->us;\n-  }\n-\n-  static inline u4 get_native_u4(address p) {\n-    unaligned *up = (unaligned *) p;\n-    return up->u;\n-  }\n-\n-  static inline u8 get_native_u8(address p) {\n-    unaligned *up = (unaligned *) p;\n-    return up->ul;\n-  }\n-\n-  static inline void put_native_u2(address p, u2 x) {\n-    unaligned *up = (unaligned *) p;\n-    up->us = x;\n-  }\n-\n-  static inline void put_native_u4(address p, u4 x) {\n-    unaligned *up = (unaligned *) p;\n-    up->u = x;\n-  }\n-\n-  static inline void put_native_u8(address p, u8 x) {\n-    unaligned *up = (unaligned *) p;\n-    up->ul = x;\n-  }\n-\n-  \/\/ Efficient reading and writing of unaligned unsigned data in Java\n-  \/\/ byte ordering (i.e. big-endian ordering).\n-#ifdef VM_LITTLE_ENDIAN\n-  \/\/ Byte-order reversal is needed\n-  static inline u2 get_Java_u2(address p) {\n-    return (u2(p[0]) << 8) |\n-           (u2(p[1])     );\n-  }\n-  static inline u4 get_Java_u4(address p) {\n-    return (u4(p[0]) << 24) |\n-           (u4(p[1]) << 16) |\n-           (u4(p[2]) <<  8) |\n-           (u4(p[3])      );\n-  }\n-  static inline u8 get_Java_u8(address p) {\n-    u4 hi, lo;\n-    hi = (u4(p[0]) << 24) |\n-         (u4(p[1]) << 16) |\n-         (u4(p[2]) <<  8) |\n-         (u4(p[3])      );\n-    lo = (u4(p[4]) << 24) |\n-         (u4(p[5]) << 16) |\n-         (u4(p[6]) <<  8) |\n-         (u4(p[7])      );\n-    return u8(lo) | (u8(hi) << 32);\n-  }\n-\n-  static inline void put_Java_u2(address p, u2 x) {\n-    p[0] = x >> 8;\n-    p[1] = x;\n-  }\n-  static inline void put_Java_u4(address p, u4 x) {\n-    p[0] = x >> 24;\n-    p[1] = x >> 16;\n-    p[2] = x >> 8;\n-    p[3] = x;\n-  }\n-  static inline void put_Java_u8(address p, u8 x) {\n-    u4 hi, lo;\n-    lo = x;\n-    hi = x >> 32;\n-    p[0] = hi >> 24;\n-    p[1] = hi >> 16;\n-    p[2] = hi >> 8;\n-    p[3] = hi;\n-    p[4] = lo >> 24;\n-    p[5] = lo >> 16;\n-    p[6] = lo >> 8;\n-    p[7] = lo;\n-  }\n-#else\n-  \/\/ No byte-order reversal is needed\n-  static inline u2 get_Java_u2(address p) {\n-    return get_native_u2(p);\n-  }\n-  static inline u4 get_Java_u4(address p) {\n-    return get_native_u4(p);\n-  }\n-  static inline u8 get_Java_u8(address p) {\n-    return get_native_u8(p);\n-  }\n-\n-  static inline void put_Java_u2(address p, u2 x) {\n-    put_native_u2(p, x);\n-  }\n-  static inline void put_Java_u4(address p, u4 x) {\n-    put_native_u4(p, x);\n-  }\n-  static inline void put_Java_u8(address p, u8 x) {\n-    put_native_u8(p, x);\n-  }\n-#endif \/\/ VM_LITTLE_ENDIAN\n-};\n-\n-#endif \/\/ CPU_ZERO_BYTES_ZERO_HPP\n","filename":"src\/hotspot\/cpu\/zero\/bytes_zero.hpp","additions":0,"deletions":145,"binary":false,"changes":145,"status":"deleted"},{"patch":"@@ -28,1 +28,4 @@\n-#include \"utilities\/macros.hpp\"\n+#include \"memory\/allStatic.hpp\"\n+#include \"utilities\/byteswap.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/unalignedAccess.hpp\"\n@@ -51,1 +54,50 @@\n-#include CPU_HEADER(bytes)\n+class Bytes : AllStatic {\n+ public:\n+  \/\/ Efficient reading and writing of unaligned unsigned data in platform-specific byte ordering.\n+  template <typename T>\n+  static inline T get_native(const void* p) {\n+    return UnalignedAccess::load<T>(p);\n+  }\n+\n+  template <typename T>\n+  static inline void put_native(void* p, T x) {\n+    UnalignedAccess::store<T>(p, x);\n+  }\n+\n+  static inline u2   get_native_u2(address p)         { return get_native<u2>(p); }\n+  static inline u4   get_native_u4(address p)         { return get_native<u4>(p); }\n+  static inline u8   get_native_u8(address p)         { return get_native<u8>(p); }\n+  static inline void put_native_u2(address p, u2 x)   { put_native<u2>(p, x); }\n+  static inline void put_native_u4(address p, u4 x)   { put_native<u4>(p, x); }\n+  static inline void put_native_u8(address p, u8 x)   { put_native<u8>(p, x); }\n+\n+  \/\/ Efficient reading and writing of unaligned unsigned data in Java\n+  \/\/ byte ordering (i.e. big-endian ordering).\n+  template <typename T>\n+  static inline T get_Java(const address p) {\n+    T x = get_native<T>(p);\n+\n+    if (Endian::is_Java_byte_ordering_different()) {\n+      x = byteswap(x);\n+    }\n+\n+    return x;\n+  }\n+\n+  template <typename T>\n+  static inline void put_Java(address p, T x) {\n+    if (Endian::is_Java_byte_ordering_different()) {\n+      x = byteswap(x);\n+    }\n+\n+    put_native<T>(p, x);\n+  }\n+\n+  static inline u2   get_Java_u2(address p)           { return get_Java<u2>(p); }\n+  static inline u4   get_Java_u4(address p)           { return get_Java<u4>(p); }\n+  static inline u8   get_Java_u8(address p)           { return get_Java<u8>(p); }\n+\n+  static inline void put_Java_u2(address p, u2 x)     { put_Java<u2>(p, x); }\n+  static inline void put_Java_u4(address p, u4 x)     { put_Java<u4>(p, x); }\n+  static inline void put_Java_u8(address p, u8 x)     { put_Java<u8>(p, x); }\n+};\n","filename":"src\/hotspot\/share\/utilities\/bytes.hpp","additions":54,"deletions":2,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -0,0 +1,177 @@\n+\/*\n+ * Copyright (c) 2025 Google and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_UTILITIES_UNALIGNED_ACCESS_HPP\n+#define SHARE_UTILITIES_UNALIGNED_ACCESS_HPP\n+\n+#include \"memory\/allStatic.hpp\"\n+#include \"utilities\/debug.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/macros.hpp\"\n+\n+#ifdef ADDRESS_SANITIZER\n+\/\/ ASan, HWAsan, MSan, and TSan have special support for unaligned access.\n+\/\/ If we ever support the others, update the above ifdef.\n+#define SANITIZER_HAS_UNALIGNED_ACCESS 1\n+#endif\n+\n+#ifdef SANITIZER_HAS_UNALIGNED_ACCESS\n+#include <sanitizer\/common_interface_defs.h>\n+#endif\n+\n+#include <cstdint>\n+#include <cstring>\n+#include <type_traits>\n+\n+\/\/ Provides access to unaligned data.\n+class UnalignedAccess : AllStatic {\n+ public:\n+  template<typename T>\n+  static void store(void* ptr, T value) {\n+    STATIC_ASSERT(std::is_trivially_copyable<T>::value);\n+    STATIC_ASSERT(std::is_trivially_default_constructible<T>::value);\n+    assert(ptr != nullptr, \"nullptr\");\n+    StoreImpl<sizeof(T)>{}(static_cast<T*>(ptr), value);\n+  }\n+\n+  template<typename T>\n+  static T load(const void* ptr) {\n+    STATIC_ASSERT(std::is_trivially_copyable<T>::value);\n+    STATIC_ASSERT(std::is_trivially_default_constructible<T>::value);\n+    assert(ptr != nullptr, \"nullptr\");\n+    return LoadImpl<sizeof(T)>{}(static_cast<const T*>(ptr));\n+  }\n+\n+ private:\n+  template<size_t byte_size> struct StoreImpl;\n+  template<size_t byte_size> struct LoadImpl;\n+};\n+\n+template<>\n+struct StoreImpl<1> {\n+  template<typename T>\n+  void operator()(T* ptr, T value) const {\n+    STATIC_ASSERT(sizeof(T) == sizeof(uint8_t));\n+    *ptr = value;\n+  }\n+};\n+\n+template<>\n+struct LoadImpl<1> {\n+  template<typename T>\n+  T operator()(const T* ptr) const {\n+    STATIC_ASSERT(sizeof(T) == sizeof(uint8_t));\n+    return *ptr;\n+  }\n+};\n+\n+#ifdef SANITIZER_HAS_UNALIGNED_ACCESS\n+template<>\n+struct StoreImpl<2> {\n+  template<typename T>\n+  void operator()(T* ptr, T value) const {\n+    STATIC_ASSERT(sizeof(T) == sizeof(uint16_t));\n+    __sanitizer_unaligned_store16(ptr, static_cast<uint16_t>(value));\n+  }\n+};\n+\n+template<>\n+struct StoreImpl<4> {\n+  template<typename T>\n+  void operator()(T* ptr, T value) const {\n+    STATIC_ASSERT(sizeof(T) == sizeof(uint32_t));\n+    __sanitizer_unaligned_store32(ptr, static_cast<uint32_t>(value));\n+  }\n+};\n+\n+template<>\n+struct StoreImpl<8> {\n+  template<typename T>\n+  void operator()(T* ptr, T value) const {\n+    STATIC_ASSERT(sizeof(T) == sizeof(uint64_t));\n+    __sanitizer_unaligned_store64(ptr, static_cast<uint64_t>(value));\n+  }\n+};\n+\n+template<>\n+struct LoadImpl<2> {\n+  template<typename T>\n+  T operator()(const T* ptr) const {\n+    STATIC_ASSERT(sizeof(T) == sizeof(uint16_t));\n+    return static_cast<T>(__sanitizer_unaligned_load16(ptr));\n+  }\n+};\n+\n+template<>\n+struct LoadImpl<4> {\n+  template<typename T>\n+  T operator()(const T* ptr) const {\n+    STATIC_ASSERT(sizeof(T) == sizeof(uint32_t));\n+    return static_cast<T>(__sanitizer_unaligned_load32(ptr));\n+  }\n+};\n+\n+template<>\n+struct LoadImpl<8> {\n+  template<typename T>\n+  T operator()(const T* ptr) const {\n+    STATIC_ASSERT(sizeof(T) == sizeof(uint64_t));\n+    return static_cast<T>(__sanitizer_unaligned_load64(ptr));\n+  }\n+};\n+#endif\n+\n+template<size_t byte_size>\n+struct StoreImpl {\n+  template<typename T>\n+  void operator()(T* ptr, T value) const {\n+    STATIC_ASSERT(sizeof(T) == byte_size);\n+    STATIC_ASSERT(byte_size != 0);  \/\/ Incomplete type\n+    \/\/ The only portable way to implement unaligned stores is to use memcpy.\n+    \/\/ Fortunately all decent compilers are able to inline this and avoid\n+    \/\/ the actual call to memcpy. On platforms which allow unaligned access,\n+    \/\/ the compiler will emit a normal store instruction.\n+    memcpy(ptr, &value, sizeof(T));\n+  }\n+};\n+\n+template<size_t byte_size>\n+struct LoadImpl {\n+  template<typename T>\n+  T operator()(const T* ptr) const {\n+    STATIC_ASSERT(sizeof(T) == byte_size);\n+    STATIC_ASSERT(byte_size != 0);  \/\/ Incomplete type\n+    \/\/ The only portable way to implement unaligned loads is to use memcpy.\n+    \/\/ Fortunately all decent compilers are able to inline this and avoid\n+    \/\/ the actual call to memcpy. On platforms which allow unaligned access,\n+    \/\/ the compiler will emit a normal load instruction.\n+    T value;\n+    memcpy(&value, ptr, sizeof(T));\n+    return value;\n+  }\n+};\n+\n+#undef SANITIZER_HAS_UNALIGNED_ACCESS\n+\n+#endif \/\/ SHARE_UTILITIES_UNALIGNED_ACCESS_HPP\n","filename":"src\/hotspot\/share\/utilities\/unalignedAccess.hpp","additions":177,"deletions":0,"binary":false,"changes":177,"status":"added"}]}