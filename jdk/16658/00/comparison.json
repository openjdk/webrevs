{"files":[{"patch":"@@ -1717,0 +1717,39 @@\n+void C2_MacroAssembler::expand_bits_v(Register dst, Register src, Register mask, bool is_long) {\n+  Assembler::SEW sew = is_long ? Assembler::e64 : Assembler::e32;\n+  \/\/ intrinsic is enabled when MaxVectorSize >= 16\n+  Assembler::LMUL lmul = is_long ? Assembler::m4 : Assembler::m2;\n+  long len = is_long ? 64 : 32;\n+\n+  \/\/ load the src data(in bits) to be expanded.\n+  vsetivli(x0, 1, sew, Assembler::m1);\n+  vmv_s_x(v0, src);\n+  \/\/ reset the src data(in bytes) to zero.\n+  mv(t0, len);\n+  vsetvli(x0, t0, Assembler::e8, lmul);\n+  vmv_v_i(v4, 0);\n+  \/\/ convert the src data from bits to bytes.\n+  vmerge_vim(v4, v4, 1); \/\/ v0 as implicit mask vector\n+  vmv_v_i(v12, 0);\n+  \/\/ reset the dst data(in bytes) to zero.\n+  vsetivli(x0, 1, sew, Assembler::m1);\n+  \/\/ load the mask data(in bits).\n+  vmv_s_x(v0, mask);\n+  \/\/ expand the src data(in bytes) to dst(in bytes).\n+  vsetvli(x0, t0, Assembler::e8, lmul);\n+  viota_m(v8, v0);\n+  vrgather_vv(v12, v4, v8, VectorMask::v0_t); \/\/ v0 as implicit mask vector\n+  \/\/ convert the dst data from bytes to bits.\n+  vmseq_vi(v0, v12, 1);\n+  \/\/ store result back.\n+  vsetivli(x0, 1, sew, Assembler::m1);\n+  vmv_x_s(dst, v0);\n+}\n+\n+void C2_MacroAssembler::expand_bits_i_v(Register dst, Register src, Register mask) {\n+  expand_bits_v(dst, src, mask, \/* is_long *\/ false);\n+}\n+\n+void C2_MacroAssembler::expand_bits_l_v(Register dst, Register src, Register mask) {\n+  expand_bits_v(dst, src, mask, \/* is_long *\/ true);\n+}\n+\n","filename":"src\/hotspot\/cpu\/riscv\/c2_MacroAssembler_riscv.cpp","additions":39,"deletions":0,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -43,0 +43,1 @@\n+  void expand_bits_v(Register dst, Register src, Register mask, bool is_long);\n@@ -170,0 +171,3 @@\n+  \/\/ expand bits, i.e. j.l.Integer\/Long::expand.\n+  void expand_bits_i_v(Register dst, Register src, Register mask);\n+  void expand_bits_l_v(Register dst, Register src, Register mask);\n","filename":"src\/hotspot\/cpu\/riscv\/c2_MacroAssembler_riscv.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -937,0 +937,20 @@\n+\/\/ class for vector register v12\n+reg_class v12_reg(\n+    V12, V12_H, V12_J, V12_K\n+);\n+\n+\/\/ class for vector register v13\n+reg_class v13_reg(\n+    V13, V13_H, V13_J, V13_K\n+);\n+\n+\/\/ class for vector register v14\n+reg_class v14_reg(\n+    V14, V14_H, V14_J, V14_K\n+);\n+\n+\/\/ class for vector register v15\n+reg_class v15_reg(\n+    V15, V15_H, V15_J, V15_K\n+);\n+\n@@ -1896,0 +1916,1 @@\n+    case Op_ExpandBits:   \/\/ fall through\n@@ -3515,0 +3536,40 @@\n+operand vReg_V12()\n+%{\n+  constraint(ALLOC_IN_RC(v12_reg));\n+  match(VecA);\n+  match(vReg);\n+  op_cost(0);\n+  format %{ %}\n+  interface(REG_INTER);\n+%}\n+\n+operand vReg_V13()\n+%{\n+  constraint(ALLOC_IN_RC(v13_reg));\n+  match(VecA);\n+  match(vReg);\n+  op_cost(0);\n+  format %{ %}\n+  interface(REG_INTER);\n+%}\n+\n+operand vReg_V14()\n+%{\n+  constraint(ALLOC_IN_RC(v14_reg));\n+  match(VecA);\n+  match(vReg);\n+  op_cost(0);\n+  format %{ %}\n+  interface(REG_INTER);\n+%}\n+\n+operand vReg_V15()\n+%{\n+  constraint(ALLOC_IN_RC(v15_reg));\n+  match(VecA);\n+  match(vReg);\n+  op_cost(0);\n+  format %{ %}\n+  interface(REG_INTER);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/riscv\/riscv.ad","additions":61,"deletions":0,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -2887,1 +2887,0 @@\n-  predicate(UseRVV);\n@@ -2914,1 +2913,0 @@\n-  predicate(UseRVV);\n@@ -2938,0 +2936,57 @@\n+\/\/ ExpandBits of Long & Integer\n+\n+instruct expandBitsI(iRegINoSp dst, iRegIorL2I src, iRegIorL2I mask, vRegMask_V0 v0,\n+                     vReg_V4 v4, vReg_V5 v5, vReg_V8 v8, vReg_V9 v9, vReg_V12 v12, vReg_V13 v13) %{\n+  match(Set dst (ExpandBits src mask));\n+  effect(TEMP v0, TEMP v4, TEMP v5, TEMP v8, TEMP v9, TEMP v12, TEMP v13);\n+  format %{ \"vsetivli x0, 1, e32, m1, tu, mu\\t#@expandBitsI\\n\\t\"\n+            \"vmv.s.x $v0, $src\\n\\t\"\n+            \"mv t0, 32\\n\\t\"\n+            \"vsetvli x0, t0, e8, m2, tu, mu\\n\\t\"\n+            \"vmv.v.i $v4, 0\\n\\t\"\n+            \"vmerge.vim $v4, $v4, 1, $v0\\n\\t\"\n+            \"vmv.v.i $v12, 0\\n\\t\"\n+            \"vsetivli x0, 1, e32, m1, tu, mu\\n\\t\"\n+            \"vmv.s.x $v0, $mask\\n\\t\"\n+            \"vsetvli x0, t0, e8, m2, tu, mu\\n\\t\"\n+            \"viota.m $v8, $v0\\n\\t\"\n+            \"vrgather.vv $v12, $v4, $v8, $v0.t\\n\\t\"\n+            \"vmseq.vi $v0, $v12, 1\\n\\t\"\n+            \"vsetivli x0, 1, e32, m1, tu, mu\\n\\t\"\n+            \"vmv.x.s $dst, $v0\\t#@expandBitsI\\n\\t\"\n+          %}\n+  ins_encode %{\n+    __ expand_bits_i_v(as_Register($dst$$reg), as_Register($src$$reg), as_Register($mask$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct expandBitsL(iRegLNoSp dst, iRegL src, iRegL mask, vRegMask_V0 v0,\n+                      vReg_V4 v4, vReg_V5 v5, vReg_V6 v6, vReg_V7 v7,\n+                      vReg_V8 v8, vReg_V9 v9, vReg_V10 v10, vReg_V11 v11,\n+                      vReg_V12 v12, vReg_V13 v13, vReg_V14 v14, vReg_V15 v15) %{\n+  match(Set dst (ExpandBits src mask));\n+  effect(TEMP v0, TEMP v4, TEMP v5, TEMP v6, TEMP v7, TEMP v8, TEMP v9, TEMP v10, TEMP v11,\n+         TEMP v12, TEMP v13, TEMP v14, TEMP v15);\n+  format %{ \"vsetivli x0, 1, e64, m1, tu, mu\\t#@expandBitsL\\n\\t\"\n+            \"vmv.s.x $v0, $src\\n\\t\"\n+            \"mv t0, 64\\n\\t\"\n+            \"vsetvli x0, t0, e8, m4, tu, mu\\n\\t\"\n+            \"vmv.v.i $v4, 0\\n\\t\"\n+            \"vmerge.vim $v4, $v4, 1, $v0\\n\\t\"\n+            \"vmv.v.i $v12, 0\\n\\t\"\n+            \"vsetivli x0, 1, e64, m1, tu, mu\\n\\t\"\n+            \"vmv.s.x $v0, $mask\\n\\t\"\n+            \"vsetvli x0, t0, e8, m4, tu, mu\\n\\t\"\n+            \"viota.m $v8, $v0\\n\\t\"\n+            \"vrgather.vv $v12, $v4, $v8, $v0.t\\n\\t\"\n+            \"vmseq.vi $v0, $v12, 1\\n\\t\"\n+            \"vsetivli x0, 1, e64, m1, tu, mu\\n\\t\"\n+            \"vmv.x.s $dst, $v0\\t#@expandBitsL\\n\\t\"\n+          %}\n+  ins_encode %{\n+    __ expand_bits_l_v(as_Register($dst$$reg), as_Register($src$$reg), as_Register($mask$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/riscv\/riscv_v.ad","additions":57,"deletions":2,"binary":false,"changes":59,"status":"modified"},{"patch":"@@ -33,1 +33,2 @@\n- *            (os.arch==\"aarch64\" & vm.cpu.features ~= \".*svebitperm.*\"))\n+ *            (os.arch==\"aarch64\" & vm.cpu.features ~= \".*svebitperm.*\") |\n+ *            (os.arch==\"riscv64\" & vm.cpu.features ~= \".*v.*\"))\n","filename":"test\/hotspot\/jtreg\/compiler\/intrinsics\/TestBitShuffleOpers.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"}]}